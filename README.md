# arxiv-daily
 Automated deployment @ 2024-12-12 20:39:55 Asia/Taipei
> Welcome to contribute! Add your topics and keywords in [`topic.yml`](https://github.com/jawatech/arxiv-daily-in-place/blob/main/database/topic.yml).
> You can also view historical data through the [storage](https://github.com/jawatech/arxiv-daily-in-place/blob/main/database/storage).

## AI

### Medical explainable AI
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-11-30**|**2-Factor Retrieval for Improved Human-AI Decision Making in Radiology**|Jim Solomon et.al.|[2412.00372v1](http://arxiv.org/abs/2412.00372v1)|null|
|**2024-11-28**|**Mapping Public Perception of Artificial Intelligence: Expectations, Risk-Benefit Tradeoffs, and Value As Determinants for Societal Acceptance**|Philipp Brauner et.al.|[2411.19356v1](http://arxiv.org/abs/2411.19356v1)|null|
|**2024-11-26**|**Explainable AI for Classifying UTI Risk Groups Using a Real-World Linked EHR and Pathology Lab Dataset**|Yujie Dai et.al.|[2411.17645v1](http://arxiv.org/abs/2411.17645v1)|null|
|**2024-11-18**|**Exploring the Requirements of Clinicians for Explainable AI Decision Support Systems in Intensive Care**|Jeffrey N. Clark et.al.|[2411.11774v1](http://arxiv.org/abs/2411.11774v1)|null|
|**2024-11-15**|**Artificial Intelligence in Pediatric Echocardiography: Exploring Challenges, Opportunities, and Clinical Applications with Explainable AI and Federated Learning**|Mohammed Yaseen Jabarulla et.al.|[2411.10255v1](http://arxiv.org/abs/2411.10255v1)|null|
|**2024-11-01**|**Enhancing Osteoporosis Detection: An Explainable Multi-Modal Learning Framework with Feature Fusion and Variable Clustering**|Mehdi Hosseini Chagahi et.al.|[2411.00916v2](http://arxiv.org/abs/2411.00916v2)|null|
|**2024-10-25**|**A Review of Deep Learning Approaches for Non-Invasive Cognitive Impairment Detection**|Muath Alsuhaibani et.al.|[2410.19898v1](http://arxiv.org/abs/2410.19898v1)|null|
|**2024-10-23**|**An Ontology-Enabled Approach For User-Centered and Knowledge-Enabled Explanations of AI Systems**|Shruthi Chari et.al.|[2410.17504v1](http://arxiv.org/abs/2410.17504v1)|[link](https://github.com/tetherless-world/metaexplainer)|
|**2024-10-22**|**Contrasting Attitudes Towards Current and Future AI Applications for Computerised Interpretation of ECG: A Clinical Stakeholder Interview Study**|Lukas Hughes-Noehrer et.al.|[2410.16879v1](http://arxiv.org/abs/2410.16879v1)|null|
|**2024-10-19**|**Pathologist-like explainable AI for interpretable Gleason grading in prostate cancer**|Gesa Mittmann et.al.|[2410.15012v1](http://arxiv.org/abs/2410.15012v1)|null|
|**2024-10-15**|**Explainable AI Methods for Multi-Omics Analysis: A Survey**|Ahmad Hussein et.al.|[2410.11910v1](http://arxiv.org/abs/2410.11910v1)|null|
|**2024-10-14**|**Study on the Helpfulness of Explainable Artificial Intelligence**|Tobias Labarta et.al.|[2410.11896v1](http://arxiv.org/abs/2410.11896v1)|[link](https://github.com/tlabarta/helpfulnessofxai)|
|**2024-10-12**|**Use of What-if Scenarios to Help Explain Artificial Intelligence Models for Neonatal Health**|Abdullah Mamun et.al.|[2410.09635v1](http://arxiv.org/abs/2410.09635v1)|[link](https://github.com/ab9mamun/aimen)|
|**2024-10-10**|**Artificial intelligence techniques in inherited retinal diseases: A review**|Han Trinh et.al.|[2410.09105v1](http://arxiv.org/abs/2410.09105v1)|null|
|**2024-10-07**|**CasiMedicos-Arg: A Medical Question Answering Dataset Annotated with Explanatory Argumentative Structures**|Ekaterina Sviridova et.al.|[2410.05235v2](http://arxiv.org/abs/2410.05235v2)|[link](https://github.com/ixa-ehu/antidote-casimedicos)|
|**2024-10-01**|**Explainable Diagnosis Prediction through Neuro-Symbolic Integration**|Qiuhao Lu et.al.|[2410.01855v1](http://arxiv.org/abs/2410.01855v1)|null|
|**2024-10-01**|**Easydiagnos: a framework for accurate feature selection for automatic diagnosis in smart healthcare**|Prasenjit Maji et.al.|[2410.00366v1](http://arxiv.org/abs/2410.00366v1)|null|
|**2024-09-20**|**Dermatologist-like explainable AI enhances melanoma diagnosis accuracy: eye-tracking study**|Tirtha Chanda et.al.|[2409.13476v1](http://arxiv.org/abs/2409.13476v1)|null|
|**2024-09-19**|**Explainable AI for Autism Diagnosis: Identifying Critical Brain Regions Using fMRI Data**|Suryansh Vidya et.al.|[2409.15374v1](http://arxiv.org/abs/2409.15374v1)|null|
|**2024-09-19**|**Improving Prototypical Parts Abstraction for Case-Based Reasoning Explanations Designed for the Kidney Stone Type Recognition**|Daniel Flores-Araiza et.al.|[2409.12883v1](http://arxiv.org/abs/2409.12883v1)|null|
|**2024-09-18**|**Towards Interpretable End-Stage Renal Disease (ESRD) Prediction: Utilizing Administrative Claims Data with Explainable AI Techniques**|Yubo Li et.al.|[2409.12087v3](http://arxiv.org/abs/2409.12087v3)|null|
|**2024-09-09**|**Explainable AI: Definition and attributes of a good explanation for health AI**|Evangelia Kyrimi et.al.|[2409.15338v1](http://arxiv.org/abs/2409.15338v1)|null|
|**2024-08-30**|**Exploring the Effect of Explanation Content and Format on User Comprehension and Trust**|Antonio Rago et.al.|[2408.17401v1](http://arxiv.org/abs/2408.17401v1)|null|
|**2024-08-29**|**A Survey for Large Language Models in Biomedicine**|Chong Wang et.al.|[2409.00133v1](http://arxiv.org/abs/2409.00133v1)|null|
|**2024-08-27**|**Aligning XAI with EU Regulations for Smart Biomedical Devices: A Methodology for Compliance Analysis**|Francesco Sovrano et.al.|[2408.15121v1](http://arxiv.org/abs/2408.15121v1)|null|
|**2024-08-24**|**Towards Case-based Interpretability for Medical Federated Learning**|Laura Latorre et.al.|[2408.13626v1](http://arxiv.org/abs/2408.13626v1)|null|
|**2024-08-22**|**AI in radiological imaging of soft-tissue and bone tumours: a systematic review evaluating against CLAIM and FUTURE-AI guidelines**|Douwe J. Spaanderman et.al.|[2408.12491v1](http://arxiv.org/abs/2408.12491v1)|null|
|**2024-08-14**|**Evaluating Explainable AI Methods in Deep Learning Models for Early Detection of Cerebral Palsy**|Kimji N. Pellano et.al.|[2409.00001v1](http://arxiv.org/abs/2409.00001v1)|null|
|**2024-08-06**|**MicroXercise: A Micro-Level Comparative and Explainable System for Remote Physical Therapy**|Hanchen David Wang et.al.|[2408.11837v1](http://arxiv.org/abs/2408.11837v1)|null|
|**2024-08-05**|**The Literature Review Network: An Explainable Artificial Intelligence for Systematic Literature Reviews, Meta-analyses, and Method Development**|Joshua Morriss et.al.|[2408.05239v1](http://arxiv.org/abs/2408.05239v1)|null|
|**2024-08-05**|**Enhancing Medical Learning and Reasoning Systems: A Boxology-Based Comparative Analysis of Design Patterns**|Chi Him Ng et.al.|[2408.02709v1](http://arxiv.org/abs/2408.02709v1)|null|
|**2024-08-05**|**Bayesian Kolmogorov Arnold Networks (Bayesian_KANs): A Probabilistic Approach to Enhance Accuracy and Interpretability**|Masoud Muhammed Hassan et.al.|[2408.02706v1](http://arxiv.org/abs/2408.02706v1)|null|
|**2024-07-26**|**MLtoGAI: Semantic Web based with Machine Learning for Enhanced Disease Prediction and Personalized Recommendations using Generative AI**|Shyam Dongre et.al.|[2407.20284v1](http://arxiv.org/abs/2407.20284v1)|null|
|**2024-07-25**|**Introducing Î´-XAI: a novel sensitivity-based method for local AI explanations**|Alessandro De Carlo et.al.|[2407.18343v2](http://arxiv.org/abs/2407.18343v2)|null|
|**2024-07-24**|**Enhanced Deep Learning Methodologies and MRI Selection Techniques for Dementia Diagnosis in the Elderly Population**|Nikolaos Ntampakis et.al.|[2407.17324v2](http://arxiv.org/abs/2407.17324v2)|null|
|**2024-07-24**|**Using Large Language Models to Compare Explainable Models for Smart Home Human Activity Recognition**|Michele Fiori et.al.|[2408.06352v1](http://arxiv.org/abs/2408.06352v1)|null|
|**2024-07-21**|**Explainable AI-based Intrusion Detection System for Industry 5.0: An Overview of the Literature, associated Challenges, the existing Solutions, and Potential Research Directions**|Naseem Khan et.al.|[2408.03335v1](http://arxiv.org/abs/2408.03335v1)|null|
|**2024-07-18**|**A Comparative Study on Automatic Coding of Medical Letters with Explainability**|Jamie Glen et.al.|[2407.13638v1](http://arxiv.org/abs/2407.13638v1)|[link](https://github.com/Glenj01/Medical-Coding)|
|**2024-07-09**|**Explainable AI for Enhancing Efficiency of DL-based Channel Estimation**|Abdul Karim Gizzini et.al.|[2407.07009v1](http://arxiv.org/abs/2407.07009v1)|null|
|**2024-07-07**|**Explainable AI: Comparative Analysis of Normal and Dilated ResNet Models for Fundus Disease Classification**|P. N. Karthikayan et.al.|[2407.05440v2](http://arxiv.org/abs/2407.05440v2)|null|
|**2024-07-03**|**A Survey on Trustworthiness in Foundation Models for Medical Image Analysis**|Congzhen Shi et.al.|[2407.15851v2](http://arxiv.org/abs/2407.15851v2)|null|
|**2024-07-01**|**The Impact of an XAI-Augmented Approach on Binary Classification with Scarce Data**|Ximing Wen et.al.|[2407.06206v1](http://arxiv.org/abs/2407.06206v1)|null|
|**2024-06-28**|**Can GPT-4 Help Detect Quit Vaping Intentions? An Exploration of Automatic Data Annotation Approach**|Sai Krishna Revanth Vuruma et.al.|[2407.00167v1](http://arxiv.org/abs/2407.00167v1)|null|
|**2024-06-25**|**Towards Compositional Interpretability for XAI**|Sean Tull et.al.|[2406.17583v1](http://arxiv.org/abs/2406.17583v1)|null|
|**2024-06-17**|**Slicing Through Bias: Explaining Performance Gaps in Medical Image Analysis using Slice Discovery Methods**|Vincent Olesen et.al.|[2406.12142v2](http://arxiv.org/abs/2406.12142v2)|[link](https://github.com/volesen/slicing-through-bias)|
|**2024-06-11**|**Unlocking the Potential of Metaverse in Innovative and Immersive Digital Health**|Fatemeh Ebrahimzadeh et.al.|[2406.07114v2](http://arxiv.org/abs/2406.07114v2)|null|
|**2024-06-10**|**AI-Driven Predictive Analytics Approach for Early Prognosis of Chronic Kidney Disease Using Ensemble Learning and Explainable AI**|K M Tawsik Jawad et.al.|[2406.06728v1](http://arxiv.org/abs/2406.06728v1)|null|
|**2024-06-10**|**Explainable AI for Mental Disorder Detection via Social Media: A survey and outlook**|Yusif Ibrahimov et.al.|[2406.05984v1](http://arxiv.org/abs/2406.05984v1)|null|
|**2024-06-09**|**Methodology and Real-World Applications of Dynamic Uncertain Causality Graph for Clinical Diagnosis with Explainability and Invariance**|Zhan Zhang et.al.|[2406.05746v1](http://arxiv.org/abs/2406.05746v1)|null|
|**2024-06-07**|**Advancing Histopathology-Based Breast Cancer Diagnosis: Insights into Multi-Modality and Explainability**|Faseela Abdullakutty et.al.|[2406.12897v1](http://arxiv.org/abs/2406.12897v1)|null|
|**2024-06-07**|**Revisiting Attention Weights as Interpretations of Message-Passing Neural Networks**|Yong-Min Shin et.al.|[2406.04612v1](http://arxiv.org/abs/2406.04612v1)|[link](https://github.com/jordan7186/gatt)|
|**2024-06-04**|**Using Explainable AI for EEG-based Reduced Montage Neonatal Seizure Detection**|Dinuka Sandun Udayantha et.al.|[2406.16908v3](http://arxiv.org/abs/2406.16908v3)|[link](https://github.com/dinuka-1999/braineocare)|
|**2024-06-01**|**Breast Cancer Diagnosis: A Comprehensive Exploration of Explainable Artificial Intelligence (XAI) Techniques**|Samita Bai et.al.|[2406.00532v1](http://arxiv.org/abs/2406.00532v1)|null|
|**2024-06-01**|**Unveiling Hidden Factors: Explainable AI for Feature Boosting in Speech Emotion Recognition**|Alaa Nfissi et.al.|[2406.01624v2](http://arxiv.org/abs/2406.01624v2)|[link](https://github.com/alaanfissi/unveiling-hidden-factors-explainable-ai-for-feature-boosting-in-speech-emotion-recognition)|
|**2024-05-31**|**The Explanation Necessity for Healthcare AI**|Michail Mamalakis et.al.|[2406.00216v1](http://arxiv.org/abs/2406.00216v1)|null|
|**2024-05-29**|**Interdisciplinary Expertise to Advance Equitable Explainable AI**|Chloe R. Bennett et.al.|[2406.18563v1](http://arxiv.org/abs/2406.18563v1)|null|
|**2024-05-27**|**"It depends": Configuring AI to Improve Clinical Usefulness Across Contexts**|Hubert D. ZajÄc et.al.|[2407.11978v1](http://arxiv.org/abs/2407.11978v1)|null|
|**2024-05-26**|**Improving Health Professionals' Onboarding with AI and XAI for Trustworthy Human-AI Collaborative Decision Making**|Min Hun Lee et.al.|[2405.16424v1](http://arxiv.org/abs/2405.16424v1)|null|
|**2024-05-26**|**Exploring Nutritional Impact on Alzheimer's Mortality: An Explainable AI Approach**|Ziming Liu et.al.|[2405.17502v1](http://arxiv.org/abs/2405.17502v1)|null|
|**2024-05-24**|**Explainable AI Enhances Glaucoma Referrals, Yet the Human-AI Team Still Falls Short of the AI Alone**|Catalina Gomez et.al.|[2407.11974v1](http://arxiv.org/abs/2407.11974v1)|null|
|**2024-05-23**|**Decoding Decision Reasoning: A Counterfactual-Powered Model for Knowledge Discovery**|Yingying Fang et.al.|[2406.18552v1](http://arxiv.org/abs/2406.18552v1)|null|
|**2024-05-21**|**The Role of Emotions in Informational Support Question-Response Pairs in Online Health Communities: A Multimodal Deep Learning Approach**|Mohsen Jozani et.al.|[2405.13099v1](http://arxiv.org/abs/2405.13099v1)|null|
|**2024-05-17**|**ChatGPT in Classrooms: Transforming Challenges into Opportunities in Education**|Harris Bin Munawar et.al.|[2405.10645v1](http://arxiv.org/abs/2405.10645v1)|null|
|**2024-05-13**|**Evaluating the Explainable AI Method Grad-CAM for Breath Classification on Newborn Time Series Data**|Camelia Oprea et.al.|[2405.07590v1](http://arxiv.org/abs/2405.07590v1)|null|
|**2024-05-10**|**XAI4LLM. Let Machine Learning Models and LLMs Collaborate for Enhanced In-Context Learning in Healthcare**|Fatemeh Nazary et.al.|[2405.06270v3](http://arxiv.org/abs/2405.06270v3)|null|
|**2024-05-09**|**To Trust or Not to Trust: Towards a novel approach to measure trust for XAI systems**|Miquel MirÃ³-Nicolau et.al.|[2405.05766v1](http://arxiv.org/abs/2405.05766v1)|null|
|**2024-05-05**|**Region-specific Risk Quantification for Interpretable Prognosis of COVID-19**|Zhusi Zhong et.al.|[2405.02815v1](http://arxiv.org/abs/2405.02815v1)|[link](https://github.com/zzs95/RSP_COVID)|
|**2024-04-26**|**Rad4XCNN: a new agnostic method for post-hoc global explanation of CNN-derived features by means of radiomics**|Francesco Prinzi et.al.|[2405.02334v1](http://arxiv.org/abs/2405.02334v1)|null|
|**2024-04-25**|**Attributing Responsibility in AI-Induced Incidents: A Computational Reflective Equilibrium Framework for Accountability**|Yunfei Ge et.al.|[2404.16957v1](http://arxiv.org/abs/2404.16957v1)|null|
|**2024-04-19**|**Explainable AI for Fair Sepsis Mortality Predictive Model**|Chia-Hsuan Chang et.al.|[2404.13139v1](http://arxiv.org/abs/2404.13139v1)|null|
|**2024-04-19**|**Multi Class Depression Detection Through Tweets using Artificial Intelligence**|Muhammad Osama Nusrat et.al.|[2404.13104v1](http://arxiv.org/abs/2404.13104v1)|[link](https://github.com/mnusrat786/masters-thesis)|
|**2024-04-19**|**COIN: Counterfactual inpainting for weakly supervised semantic segmentation for medical images**|Dmytro Shvetsov et.al.|[2404.12832v2](http://arxiv.org/abs/2404.12832v2)|[link](https://github.com/dmytro-shvetsov/counterfactual-search)|
|**2024-04-15**|**Hybrid Intelligence for Digital Humanities**|Victor de Boer et.al.|[2406.15374v1](http://arxiv.org/abs/2406.15374v1)|null|
|**2024-04-14**|**Ethical Framework for Responsible Foundational Models in Medical Imaging**|Abhijit Das et.al.|[2406.11868v1](http://arxiv.org/abs/2406.11868v1)|null|
|**2024-04-09**|**Advancements in Radiomics and Artificial Intelligence for Thyroid Cancer Diagnosis**|Milad Yousefi et.al.|[2404.07239v1](http://arxiv.org/abs/2404.07239v1)|null|
|**2024-04-06**|**Predictive Modeling for Breast Cancer Classification in the Context of Bangladeshi Patients: A Supervised Machine Learning Approach with Explainable AI**|Taminul Islam et.al.|[2404.04686v1](http://arxiv.org/abs/2404.04686v1)|null|
|**2024-04-05**|**Enhancing Breast Cancer Diagnosis in Mammography: Evaluation and Integration of Convolutional Neural Networks and Explainable AI**|Maryam Ahmed et.al.|[2404.03892v3](http://arxiv.org/abs/2404.03892v3)|null|
|**2024-03-30**|**Advancing Multimodal Data Fusion in Pain Recognition: A Strategy Leveraging Statistical Correlation and Human-Centered Perspectives**|Xingrui Gu et.al.|[2404.00320v2](http://arxiv.org/abs/2404.00320v2)|null|
|**2024-03-26**|**Addressing Social Misattributions of Large Language Models: An HCXAI-based Approach**|Andrea Ferrario et.al.|[2403.17873v1](http://arxiv.org/abs/2403.17873v1)|null|
|**2024-03-26**|**Clinical Domain Knowledge-Derived Template Improves Post Hoc AI Explanations in Pneumothorax Classification**|Han Yuan et.al.|[2403.18871v1](http://arxiv.org/abs/2403.18871v1)|[link](https://github.com/han-yuan-med/template-explanation)|
|**2024-03-03**|**Enhancing Neural Machine Translation of Low-Resource Languages: Corpus Development, Human Evaluation and Explainable AI Architectures**|SÃ©amus Lankford et.al.|[2403.01580v1](http://arxiv.org/abs/2403.01580v1)|null|
|**2024-02-28**|**Cause and Effect: Can Large Language Models Truly Understand Causality?**|Swagata Ashwani et.al.|[2402.18139v3](http://arxiv.org/abs/2402.18139v3)|null|
|**2024-02-28**|**Artificial Intelligence and Diabetes Mellitus: An Inside Look Through the Retina**|Yasin Sadeghi Bazargani et.al.|[2402.18600v1](http://arxiv.org/abs/2402.18600v1)|null|
|**2024-02-22**|**Multi-stakeholder Perspective on Responsible Artificial Intelligence and Acceptability in Education**|A. J. Karran et.al.|[2402.15027v2](http://arxiv.org/abs/2402.15027v2)|null|
|**2024-02-12**|**Deciphering Heartbeat Signatures: A Vision Transformer Approach to Explainable Atrial Fibrillation Detection from ECG Signals**|Aruna Mohan et.al.|[2402.09474v2](http://arxiv.org/abs/2402.09474v2)|null|
|**2024-02-05**|**Illuminate: A novel approach for depression detection with explainable analysis and proactive therapy using prompt engineering**|Aryan Agrawal et.al.|[2402.05127v1](http://arxiv.org/abs/2402.05127v1)|null|
|**2024-01-24**|**Information That Matters: Exploring Information Needs of People Affected by Algorithmic Decisions**|TimothÃ©e Schmude et.al.|[2401.13324v6](http://arxiv.org/abs/2401.13324v6)|null|
|**2024-01-02**|**Evaluating Large Language Models on the GMAT: Implications for the Future of Business Education**|Vahid Ashrafimoghari et.al.|[2401.02985v1](http://arxiv.org/abs/2401.02985v1)|null|
|**2023-12-29**|**XAI for In-hospital Mortality Prediction via Multimodal ICU Data**|Xingqiao Li et.al.|[2312.17624v1](http://arxiv.org/abs/2312.17624v1)|[link](https://github.com/lixingqiao/xai-icu)|
|**2023-12-22**|**Joining Forces for Pathology Diagnostics with AI Assistance: The EMPAIA Initiative**|Norman Zerbe et.al.|[2401.09450v2](http://arxiv.org/abs/2401.09450v2)|null|
|**2023-12-18**|**Robust Stochastic Graph Generator for Counterfactual Explanations**|Mario Alfonso Prado-Romero et.al.|[2312.11747v2](http://arxiv.org/abs/2312.11747v2)|null|
|**2023-12-10**|**Evaluating the Utility of Model Explanations for Model Development**|Shawn Im et.al.|[2312.06032v1](http://arxiv.org/abs/2312.06032v1)|null|
|**2023-12-05**|**Building Trustworthy NeuroSymbolic AI Systems: Consistency, Reliability, Explainability, and Safety**|Manas Gaur et.al.|[2312.06798v1](http://arxiv.org/abs/2312.06798v1)|null|
|**2023-12-04**|**Class-Discriminative Attention Maps for Vision Transformers**|Lennart Brocki et.al.|[2312.02364v3](http://arxiv.org/abs/2312.02364v3)|null|
|**2023-11-28**|**Deployment of a Robust and Explainable Mortality Prediction Model: The COVID-19 Pandemic and Beyond**|Jacob R. Epifano et.al.|[2311.17133v1](http://arxiv.org/abs/2311.17133v1)|null|
|**2023-11-27**|**Variational Autoencoders for Feature Exploration and Malignancy Prediction of Lung Lesions**|Benjamin Keel et.al.|[2311.15719v1](http://arxiv.org/abs/2311.15719v1)|[link](https://github.com/benkeel/vae_lung_lesion_bmvc)|
|**2023-11-24**|**MRxaI: Black-Box Explainability for Image Classifiers in a Medical Setting**|Nathan Blake et.al.|[2311.14471v1](http://arxiv.org/abs/2311.14471v1)|null|
|**2023-11-21**|**Moderating Model Marketplaces: Platform Governance Puzzles for AI Intermediaries**|Robert Gorwa et.al.|[2311.12573v3](http://arxiv.org/abs/2311.12573v3)|null|
|**2023-11-20**|**Ovarian Cancer Data Analysis using Deep Learning: A Systematic Review from the Perspectives of Key Features of Data Analysis and AI Assurance**|Muta Tah Hira et.al.|[2311.11932v1](http://arxiv.org/abs/2311.11932v1)|null|
|**2023-11-18**|**Representing visual classification as a linear combination of words**|Shobhit Agarwal et.al.|[2311.10933v1](http://arxiv.org/abs/2311.10933v1)|[link](https://github.com/lotterlab/task_word_explainability)|

#### Abstracts
##### **2-Factor Retrieval for Improved Human-AI Decision Making in Radiology**
2412.00372v1 by Jim Solomon, Laleh Jalilian, Alexander Vilesov, Meryl Mathew, Tristan Grogan, Arash Bedayat, Achuta Kadambi

Human-machine teaming in medical AI requires us to understand to what degree
a trained clinician should weigh AI predictions. While previous work has shown
the potential of AI assistance at improving clinical predictions, existing
clinical decision support systems either provide no explainability of their
predictions or use techniques like saliency and Shapley values, which do not
allow for physician-based verification. To address this gap, this study
compares previously used explainable AI techniques with a newly proposed
technique termed '2-factor retrieval (2FR)', which is a combination of
interface design and search retrieval that returns similarly labeled data
without processing this data. This results in a 2-factor security blanket
where: (a) correct images need to be retrieved by the AI; and (b) humans should
associate the retrieved images with the current pathology under test. We find
that when tested on chest X-ray diagnoses, 2FR leads to increases in clinician
accuracy, with particular improvements when clinicians are radiologists and
have low confidence in their decision. Our results highlight the importance of
understanding how different modes of human-AI decision making may impact
clinician accuracy in clinical decision support systems.

æè¦ï¼äººæ©åä½å¨é«ç AI ä¸­ï¼éè¦æåçè§£åéè¨ç·´çè¨åºé«çå¨å¤å¤§ç¨åº¦ä¸æéè¦ AI é æ¸¬ãéç¶ååçç ç©¶é¡¯ç¤º AI è¼å©å¨æ¹åè¨åºé æ¸¬æ¹é¢çæ½åï¼ä½ç¾æçè¨åºæ±ºç­æ¯æ´ç³»çµ±ï¼è¦ä¸å°±æ²ææä¾é æ¸¬çå¯è§£éæ§ï¼è¦ä¸å°±æ¯ä½¿ç¨åé¡¯èæ§å Shapley å¼ä¹é¡çæè¡ï¼éäºæè¡ä¸åè¨±åºæ¼é«ççé©è­ãçºäºè§£æ±ºéåå·®è·ï¼æ¬ç ç©¶å°ååä½¿ç¨çå¯è§£é AI æè¡èä¸ç¨®æ°æåºçç¨±çºã2 å å­æª¢ç´¢ (2FR)ãçæè¡é²è¡æ¯è¼ï¼å¾èæ¯ä¸ç¨®ä»é¢è¨­è¨åæå°æª¢ç´¢ççµåï¼å®æå³åæ¨ç±¤ç¸ä¼¼çè³æï¼èä¸æèçéäºè³æãéæç¢çä¸å 2 å å­å®å¨æ©å¶ï¼å¶ä¸­ï¼(a) æ­£ç¢ºçå½±åéè¦ç± AI æª¢ç´¢ï¼(b) äººé¡æå°æª¢ç´¢çå½±åèæ­£å¨æ¸¬è©¦ä¸­çççè¯æ³èµ·ä¾ãæåç¼ç¾ï¼ç¶å¨è¸é¨ X åè¨ºæ·ä¸é²è¡æ¸¬è©¦æï¼2FR ææé«è¨åºé«ççæºç¢ºåº¦ï¼ç¹å¥æ¯å¨è¨åºé«çæ¯æ¾å°ç§é«çä¸å°å¶æ±ºç­ä¿¡å¿ä¸è¶³æï¼ææé¡¯èçæ¹åãæåççµæå¼·èª¿äºçè§£äººæ©æ±ºç­çä¸åæ¨¡å¼å¦ä½å½±é¿è¨åºé«çå¨è¨åºæ±ºç­æ¯æ´ç³»çµ±ä¸­çæºç¢ºæ§çéè¦æ§ã

##### **Mapping Public Perception of Artificial Intelligence: Expectations, Risk-Benefit Tradeoffs, and Value As Determinants for Societal Acceptance**
2411.19356v1 by Philipp Brauner, Felix Glawe, Gian Luca Liehner, Luisa Vervier, Martina Ziefle

Understanding public perception of artificial intelligence (AI) and the
tradeoffs between potential risks and benefits is crucial, as these perceptions
might shape policy decisions, influence innovation trajectories for successful
market strategies, and determine individual and societal acceptance of AI
technologies. Using a representative sample of 1100 participants from Germany,
this study examines mental models of AI. Participants quantitatively evaluated
71 statements about AI's future capabilities (e.g., autonomous driving, medical
care, art, politics, warfare, and societal divides), assessing the expected
likelihood of occurrence, perceived risks, benefits, and overall value. We
present rankings of these projections alongside visual mappings illustrating
public risk-benefit tradeoffs. While many scenarios were deemed likely,
participants often associated them with high risks, limited benefits, and low
overall value. Across all scenarios, 96.4% ($r^2=96.4\%$) of the variance in
value assessment can be explained by perceived risks ($\beta=-.504$) and
perceived benefits ($\beta=+.710$), with no significant relation to expected
likelihood. Demographics and personality traits influenced perceptions of
risks, benefits, and overall evaluations, underscoring the importance of
increasing AI literacy and tailoring public information to diverse user needs.
These findings provide actionable insights for researchers, developers, and
policymakers by highlighting critical public concerns and individual factors
essential to align AI development with individual values.

æè¦ï¼<paragraph>äºè§£å¬ç¾å°äººå·¥æºæ§ (AI) çèªç¥ä»¥åæ½å¨é¢¨éªèå¥½èä¹éçæ¬è¡¡è³ééè¦ï¼å çºéäºèªç¥å¯è½æå½±é¿æ¿ç­æ±ºç­ãå½±é¿æåå¸å ´ç­ç¥çåµæ°è»è·¡ï¼ä¸¦æ±ºå®åäººåç¤¾æå° AI æè¡çæ¥ååº¦ãæ¬ç ç©¶ä½¿ç¨ä¾èªå¾·åç 1100 ååèèçä»£è¡¨æ§æ¨£æ¬ï¼æ¢è¨äº AI çå¿æºæ¨¡åãåèèå° 71 é éæ¼ AI æªä¾è½åçé³è¿°ï¼ä¾å¦ï¼èªåé§é§ãé«çä¿å¥ãèè¡ãæ¿æ²»ãæ°ç­åç¤¾æåæ­§ï¼é²è¡äºå®éè©ä¼°ï¼è©ä¼°é æçç¼çå¯è½æ§ãæç¥é¢¨éªãå¥½èåæ´é«å¹å¼ãæåå±ç¤ºäºéäºé æ¸¬çæåï¼ä¸¦éä¸è¦è¦ºåæ å°ï¼èªªæäºå¬ç¾çé¢¨éªæ¶çæ¬è¡¡ãåç®¡è¨±å¤å ´æ¯è¢«èªçºæ¯å¯è½çï¼ä½åèèéå¸¸å°å®åèé«é¢¨éªãæéçå¥½èåä½æ´é«å¹å¼è¯ç¹«èµ·ä¾ãå¨ææå ´æ¯ä¸­ï¼96.4% ($r^2=96.4\%$) çå¹å¼è©ä¼°å·®ç°å¯ä»¥ç¨æç¥é¢¨éª ($\beta=-.504$) åæç¥å¥½è ($\beta=+.710$) ä¾è§£éï¼èé æçå¯è½æ§æ²æé¡¯èéä¿ãäººå£çµ±è¨åäººæ ¼ç¹è³ªå½±é¿äºå°é¢¨éªãå¥½èåæ´é«è©ä¼°ççæ³ï¼éå¸é¡¯äºæé« AI ç´ é¤åæ ¹æä¸åçä½¿ç¨èéæ±èª¿æ´å¬å±è³è¨çéè¦æ§ãéäºç¼ç¾ééå¼·èª¿ééµçå¬å±éæ³¨åèåäººå¹å¼è§ä¸è´ç AI éç¼å¿ä¸å¯å°çåäººå ç´ ï¼çºç ç©¶äººå¡ãéç¼äººå¡åæ¿ç­å¶å®èæä¾äºå¯è¡çè¦è§£ã</paragraph>

##### **Explainable AI for Classifying UTI Risk Groups Using a Real-World Linked EHR and Pathology Lab Dataset**
2411.17645v1 by Yujie Dai, Brian Sullivan, Axel Montout, Amy Dillon, Chris Waller, Peter Acs, Rachel Denholm, Philip Williams, Alastair D Hay, Raul Santos-Rodriguez, Andrew Dowsey

The use of machine learning and AI on electronic health records (EHRs) holds
substantial potential for clinical insight. However, this approach faces
significant challenges due to data heterogeneity, sparsity, temporal
misalignment, and limited labeled outcomes. In this context, we leverage a
linked EHR dataset of approximately one million de-identified individuals from
Bristol, North Somerset, and South Gloucestershire, UK, to characterize urinary
tract infections (UTIs) and develop predictive models focused on data quality,
fairness and transparency. A comprehensive data pre-processing and curation
pipeline transforms the raw EHR data into a structured format suitable for AI
modeling. Given the limited availability and biases of ground truth UTI
outcomes, we introduce a UTI risk estimation framework informed by clinical
expertise to estimate UTI risk across individual patient timelines. Using this
framework, we built pairwise XGBoost models to differentiate UTI risk
categories with explainable AI techniques to identify key predictors while
ensuring interpretability. Our findings reveal differences in clinical and
demographic factors across risk groups, offering insights into UTI risk
stratification and progression. This study demonstrates the added value of
AI-driven insights into UTI clinical decision-making while prioritizing
interpretability, transparency, and fairness, underscoring the importance of
sound data practices in advancing health outcomes.

æè¦ï¼æ©å¨å­¸ç¿åäººå·¥æºæ§å¨é»å­å¥åº·ç´é (EHR) ä¸çæç¨å·æ
è¨åºè¦è§£çå·¨å¤§æ½åãç¶èï¼éç¨®æ¹æ³ç±æ¼è³æç°è³ªæ§ãç¨çæ§ãæéé¯ä½åæ¨è¨çµææéï¼å æ­¤é¢è¨éå¤§ææ°ãå¨æ­¤èæ¯ä¸ï¼æåå©ç¨ä¾èªè±åå¸éæ¯æãåè©é»å¡ç¹é¡ååæ ¼æ´æ¯ç¹é¡çå¤§ç´ä¸ç¾è¬åå»è­å¥ååäººçé£çµå¼ EHR è³æéï¼ä»¥æè¿°æ³å°¿éææ (UTI) ä¸¦éç¼å°æ³¨æ¼è³æåè³ªãå¬å¹³æ§åéæåº¦çé æ¸¬æ¨¡åãå¨é¢çè³æåèçåæ´çç®¡éå°åå§ EHR è³æè½æçºé©å AI å»ºæ¨¡ççµæ§åæ ¼å¼ãéæ¼å¯¦é UTI çµæçå¯ç¨æ§æéååè¦ï¼æåå¼å¥äºä¸åç±è¨åºå°æ¥­ç¥è­æä¾è³è¨ç UTI é¢¨éªè©ä¼°æ¶æ§ï¼ä»¥ä¼°è¨åäººæ£èæéç·ä¸ç UTI é¢¨éªãä½¿ç¨æ­¤æ¶æ§ï¼æåå»ºç«äºæå°ç XGBoost æ¨¡åï¼ä»¥åå UTI é¢¨éªé¡å¥ï¼ä¸¦ä½¿ç¨å¯è§£éç AI æè¡ä¾è­å¥ééµé æ¸¬å å­ï¼åæç¢ºä¿å¯è§£éæ§ãæåçç ç©¶çµææ­ç¤ºäºä¸åé¢¨éªç¾¤çµçè¨åºåäººå£çµ±è¨å ç´ çå·®ç°ï¼æä¾äºå° UTI é¢¨éªåå±¤åé²å±çè¦è§£ãæ¬ç ç©¶å±ç¤ºäº AI é©åçè¦è§£å¨ UTI è¨åºæ±ºç­ä¸­çéå å¹å¼ï¼åæåªåèæ®å¯è§£éæ§ãéæåº¦åå¬å¹³æ§ï¼å¼·èª¿äºå¥å¨è³æå¯¦åå¨ä¿é²å¥åº·çµæä¸­çéè¦æ§ã

##### **Exploring the Requirements of Clinicians for Explainable AI Decision Support Systems in Intensive Care**
2411.11774v1 by Jeffrey N. Clark, Matthew Wragg, Emily Nielsen, Miquel Perello-Nieto, Nawid Keshtmand, Michael Ambler, Shiv Sharma, Christopher P. Bourdeaux, Amberly Brigden, Raul Santos-Rodriguez

There is a growing need to understand how digital systems can support
clinical decision-making, particularly as artificial intelligence (AI) models
become increasingly complex and less human-interpretable. This complexity
raises concerns about trustworthiness, impacting safe and effective adoption of
such technologies. Improved understanding of decision-making processes and
requirements for explanations coming from decision support tools is a vital
component in providing effective explainable solutions. This is particularly
relevant in the data-intensive, fast-paced environments of intensive care units
(ICUs). To explore these issues, group interviews were conducted with seven ICU
clinicians, representing various roles and experience levels. Thematic analysis
revealed three core themes: (T1) ICU decision-making relies on a wide range of
factors, (T2) the complexity of patient state is challenging for shared
decision-making, and (T3) requirements and capabilities of AI decision support
systems. We include design recommendations from clinical input, providing
insights to inform future AI systems for intensive care.

æè¦ï¼é¨èäººå·¥æºæ§ (AI) æ¨¡åè®å¾è¶ä¾è¶è¤éï¼ä¸è¶ä¾è¶é£ä»¥è¢«äººçè§£ï¼äºè§£æ¸ä½ç³»çµ±å¦ä½æ¯æ´è¨åºæ±ºç­çéæ±ä¹æ¥çå¢å ãéç¨®è¤éæ§å¼ç¼äºå°å¯ä¿¡åº¦ççæ®ï¼å½±é¿äºæ­¤é¡æè¡çå®å¨ä¸æææ¡ç¨ãæ¹åå°æ±ºç­å¶å®æµç¨ççè§£ï¼ä»¥åå°æ±ºç­æ¯æ´å·¥å·ææä¾èªªæçè¦æ±ï¼æ¯æä¾ææå¯è§£éè§£æ±ºæ¹æ¡çéè¦çµæé¨åãéå¨è³æå¯éãå¿«ç¯å¥çå è­·çæ¿ (ICU) ç°å¢ä¸­ç¹å¥ç¸éãçºäºæ¢è¨éäºåé¡ï¼å°ä¸ä½ ICU è¨åºé«å¸«é²è¡äºå°çµè¨ªè«ï¼éäºé«å¸«ä»£è¡¨äºä¸åçè§è²åç¶é©å±¤ç´ãä¸»é¡åææ­é²äºä¸åæ ¸å¿ä¸»é¡ï¼(T1) ICU æ±ºç­å¶å®ä¾è³´æ¼å»£æ³çå ç´ ï¼(T2) çæ£çæçè¤éæ§å°å±åæ±ºç­å¶å®æ§æææ°ï¼ä»¥å (T3) AI æ±ºç­æ¯æ´ç³»çµ±çè¦æ±åè½åãæåç´å¥äºè¨åºè¼¸å¥çè¨­è¨å»ºè­°ï¼æä¾è¦è§£ä»¥æä¾è³è¨çµ¦æªä¾ç¨æ¼å è­·ç AI ç³»çµ±ã

##### **Artificial Intelligence in Pediatric Echocardiography: Exploring Challenges, Opportunities, and Clinical Applications with Explainable AI and Federated Learning**
2411.10255v1 by Mohammed Yaseen Jabarulla, Theodor Uden, Thomas Jack, Philipp Beerbaum, Steffen Oeltze-Jafra

Pediatric heart diseases present a broad spectrum of congenital and acquired
diseases. More complex congenital malformations require a differentiated and
multimodal decision-making process, usually including echocardiography as a
central imaging method. Artificial intelligence (AI) offers considerable
promise for clinicians by facilitating automated interpretation of pediatric
echocardiography data. However, adapting AI technologies for pediatric
echocardiography analysis has challenges such as limited public data
availability, data privacy, and AI model transparency. Recently, researchers
have focused on disruptive technologies, such as federated learning (FL) and
explainable AI (XAI), to improve automatic diagnostic and decision support
workflows. This study offers a comprehensive overview of the limitations and
opportunities of AI in pediatric echocardiography, emphasizing the synergistic
workflow and role of XAI and FL, identifying research gaps, and exploring
potential future developments. Additionally, three relevant clinical use cases
demonstrate the functionality of XAI and FL with a focus on (i) view
recognition, (ii) disease classification, (iii) segmentation of cardiac
structures, and (iv) quantitative assessment of cardiac function.

æè¦ï¼å°åå¿èç¾çåç¾åå¤©æ§èå¾å¤©æ§ç¾ççå»£æ³åè­ãè¼è¤éçåå¤©æ§ç¸å½¢éè¦ä¸åå·®ç°åä¸å¤æ¨¡å¼çæ±ºç­éç¨ï¼éå¸¸åæ¬è¶é³æ³¢æª¢æ¥ä½çºä¸»è¦çå½±åæ¹æ³ãäººå·¥æºæ§ (AI) çºè¨åºé«çæä¾äºç¸ç¶å¤§çå¸æï¼å çºå®å¯ä»¥ä¿é²å°åè¶é³æ³¢æª¢æ¥è³æçèªååè§£è®ãç¶èï¼å°äººå·¥æºæ§æè¡æç¨æ¼å°åè¶é³æ³¢æª¢æ¥åææè¨±å¤ææ°ï¼ä¾å¦æéçå¬éè³æå¯ç¨æ§ãè³æé±ç§åäººå·¥æºæ§æ¨¡åéæåº¦ãæè¿ï¼ç ç©¶äººå¡å°æ³¨æ¼ç ´å£æ§æè¡ï¼ä¾å¦è¯åå­¸ç¿ (FL) åå¯è§£éäººå·¥æºæ§ (XAI)ï¼ä»¥æ¹åèªåè¨ºæ·åæ±ºç­æ¯æ´å·¥ä½æµç¨ãæ¬ç ç©¶æä¾äºäººå·¥æºæ§å¨å°åè¶é³æ³¢æª¢æ¥ä¸­çéå¶åæ©æçå¨é¢æ¦è¿°ï¼å¼·èª¿äº XAI å FL çååå·¥ä½æµç¨åè§è²ï¼æ¾åºç ç©¶å·®è·ä¸¦æ¢è¨æ½å¨çæªä¾ç¼å±ãæ­¤å¤ï¼ä¸åç¸éçè¨åºä½¿ç¨æ¡ä¾å±ç¤ºäº XAI å FL çåè½ï¼éé»å¨æ¼ (i) æª¢è¦è¾¨è­ã(ii) ç¾çåé¡ã(iii) å¿èçµæ§åå²å (iv) å¿èåè½çéåè©ä¼°ã

##### **Enhancing Osteoporosis Detection: An Explainable Multi-Modal Learning Framework with Feature Fusion and Variable Clustering**
2411.00916v2 by Mehdi Hosseini Chagahi, Saeed Mohammadi Dashtaki, Niloufar Delfan, Nadia Mohammadi, Alireza Samari, Behzad Moshiri, Md. Jalil Piran, Oliver Faust

Osteoporosis is a common condition that increases fracture risk, especially
in older adults. Early diagnosis is vital for preventing fractures, reducing
treatment costs, and preserving mobility. However, healthcare providers face
challenges like limited labeled data and difficulties in processing medical
images. This study presents a novel multi-modal learning framework that
integrates clinical and imaging data to improve diagnostic accuracy and model
interpretability. The model utilizes three pre-trained networks-VGG19,
InceptionV3, and ResNet50-to extract deep features from X-ray images. These
features are transformed using PCA to reduce dimensionality and focus on the
most relevant components. A clustering-based selection process identifies the
most representative components, which are then combined with preprocessed
clinical data and processed through a fully connected network (FCN) for final
classification. A feature importance plot highlights key variables, showing
that Medical History, BMI, and Height were the main contributors, emphasizing
the significance of patient-specific data. While imaging features were
valuable, they had lower importance, indicating that clinical data are crucial
for accurate predictions. This framework promotes precise and interpretable
predictions, enhancing transparency and building trust in AI-driven diagnoses
for clinical integration.

æè¦ï¼éª¨è³ªçé¬çæ¯ä¸ç¨®å¸¸è¦çç¾çï¼æå¢å éª¨æçé¢¨éªï¼ç¹å¥æ¯èå¹´äººãæ©æè¨ºæ·å°æ¼é é²éª¨æãéä½æ²»çææ¬åç¶­æè¡åè½åè³ééè¦ãç¶èï¼é«çä¿å¥æä¾èé¢è¨èæ¨è¨æ¸ææéåèçé«å­¸å½±åå°é£ç­ææ°ãæ¬ç ç©¶æåºäºä¸åæ°ç©çå¤æ¨¡å¼å­¸ç¿æ¡æ¶ï¼è©²æ¡æ¶æ´åäºè¨åºåå½±åæ¸æï¼ä»¥æé«è¨ºæ·æºç¢ºæ§åæ¨¡åå¯è§£éæ§ãè©²æ¨¡åå©ç¨ä¸åé è¨ç·´çç¶²è·¯ï¼VGG19ãInceptionV3 å ResNet50ï¼å¾ X å°ç·å½±åä¸­æåæ·±åº¦ç¹å¾µãéäºç¹å¾µä½¿ç¨ PCA è½æä»¥éä½ç¶­åº¦ä¸¦å°æ³¨æ¼æç¸éççµæé¨åãåºæ¼èé¡çé¸æéç¨è­å¥åºæå·ä»£è¡¨æ§ççµæé¨åï¼ç¶å¾å°éäºçµæé¨åèé èççè¨åºæ¸æçµåï¼ä¸¦ééå¨é£æ¥ç¶²è·¯ (FCN) é²è¡æçµåé¡ãç¹å¾µéè¦æ§åçªåºäºééµè®æ¸ï¼è¡¨æçå²ãBMI åèº«é«æ¯ä¸»è¦è²¢ç»å ç´ ï¼å¼·èª¿äºæ£èç¹å®æ¸æçéè¦æ§ãéç¶å½±åç¹å¾µå¾æå¹å¼ï¼ä½å®åçéè¦æ§è¼ä½ï¼éè¡¨æè¨åºæ¸æå°æ¼æºç¢ºé æ¸¬è³ééè¦ãæ­¤æ¡æ¶ä¿è¿äºæºç¢ºä¸å¯è§£éçé æ¸¬ï¼æé«äºéæåº¦ï¼ä¸¦å»ºç«äºå° AI é©åè¨ºæ·å¨è¨åºæ´åä¸­çä¿¡ä»»ã

##### **A Review of Deep Learning Approaches for Non-Invasive Cognitive Impairment Detection**
2410.19898v1 by Muath Alsuhaibani, Ali Pourramezan Fard, Jian Sun, Farida Far Poor, Peter S. Pressman, Mohammad H. Mahoor

This review paper explores recent advances in deep learning approaches for
non-invasive cognitive impairment detection. We examine various non-invasive
indicators of cognitive decline, including speech and language, facial, and
motoric mobility. The paper provides an overview of relevant datasets,
feature-extracting techniques, and deep-learning architectures applied to this
domain. We have analyzed the performance of different methods across modalities
and observed that speech and language-based methods generally achieved the
highest detection performance. Studies combining acoustic and linguistic
features tended to outperform those using a single modality. Facial analysis
methods showed promise for visual modalities but were less extensively studied.
Most papers focused on binary classification (impaired vs. non-impaired), with
fewer addressing multi-class or regression tasks. Transfer learning and
pre-trained language models emerged as popular and effective techniques,
especially for linguistic analysis. Despite significant progress, several
challenges remain, including data standardization and accessibility, model
explainability, longitudinal analysis limitations, and clinical adaptation.
Lastly, we propose future research directions, such as investigating
language-agnostic speech analysis methods, developing multi-modal diagnostic
systems, and addressing ethical considerations in AI-assisted healthcare. By
synthesizing current trends and identifying key obstacles, this review aims to
guide further development of deep learning-based cognitive impairment detection
systems to improve early diagnosis and ultimately patient outcomes.

æè¦ï¼æ¬ç¯è©è«æ¢è¨äºæ·±åº¦å­¸ç¿æ¹æ³å¨éä¾µå¥å¼èªç¥åè½éç¤æª¢æ¸¬ä¸çææ°é²å±ãæåæª¢è¦äºåç¨®éä¾µå¥å¼çèªç¥è¡°éææ¨ï¼åæ¬èªè¨åèªè¨ãé¢é¨åéåæ©è½ãæ¬ææ¦è¿°äºèæ­¤é åç¸éçè³æéãç¹å¾µæåæè¡åæ·±åº¦å­¸ç¿æ¶æ§ãæååæäºä¸åæ¹æ³å¨ä¸åæ¹å¼ä¸çè¡¨ç¾ï¼ä¸¦è§å¯å°åºæ¼èªè¨åèªè¨çæ¹æ³éå¸¸è½éå°æé«çæª¢æ¸¬è¡¨ç¾ãçµåè²å­¸åèªè¨ç¹å¾µçç ç©¶å¾å¾åªæ¼ä½¿ç¨å®ä¸æ¹å¼çç ç©¶ãé¢é¨åææ¹æ³é¡¯ç¤ºåºè¦è¦ºæ¹å¼çæ½åï¼ä½ç ç©¶è¼å°ãå¤§å¤æ¸è«æå°æ³¨æ¼äºååé¡ï¼åæèæªåæï¼ï¼è¼å°æ¢è¨å¤é¡æåæ­¸ä»»åãé·ç§»å­¸ç¿åé è¨ç·´èªè¨æ¨¡åå·²æçºæµè¡ä¸ææçæè¡ï¼ç¹å¥æ¯å°æ¼èªè¨åæãåç®¡åå¾äºéå¤§é²å±ï¼ä½ä»å­å¨ä¸äºææ°ï¼åæ¬è³ææ¨æºååå¯åæ§ãæ¨¡åå¯è§£éæ§ãç¸±ååæéå¶åè¨åºé©ææ§ãæå¾ï¼æåæåºäºæªä¾çç ç©¶æ¹åï¼ä¾å¦èª¿æ¥èèªè¨ç¡éçèªé³åææ¹æ³ãéç¼å¤æ¨¡å¼è¨ºæ·ç³»çµ±ï¼ä»¥åè§£æ±ºäººå·¥æºæ§è¼å©é«çä¿å¥ä¸­çå«çèéãééç¶åç®åçè¶¨å¢åæ¾åºééµéç¤ï¼æ¬ç¯è©è«æ¨å¨å¼å°æ·±åº¦å­¸ç¿çºåºç¤çèªç¥åè½éç¤æª¢æ¸¬ç³»çµ±çé²ä¸æ­¥ç¼å±ï¼ä»¥æ¹åæ©æè¨ºæ·ï¼ä¸¦æçµæ¹åæ£èçæ²»ççµæã

##### **An Ontology-Enabled Approach For User-Centered and Knowledge-Enabled Explanations of AI Systems**
2410.17504v1 by Shruthi Chari

Explainable Artificial Intelligence (AI) focuses on helping humans understand
the working of AI systems or their decisions and has been a cornerstone of AI
for decades. Recent research in explainability has focused on explaining the
workings of AI models or model explainability. There have also been several
position statements and review papers detailing the needs of end-users for
user-centered explainability but fewer implementations. Hence, this thesis
seeks to bridge some gaps between model and user-centered explainability. We
create an explanation ontology (EO) to represent literature-derived explanation
types via their supporting components. We implement a knowledge-augmented
question-answering (QA) pipeline to support contextual explanations in a
clinical setting. Finally, we are implementing a system to combine explanations
from different AI methods and data modalities. Within the EO, we can represent
fifteen different explanation types, and we have tested these representations
in six exemplar use cases. We find that knowledge augmentations improve the
performance of base large language models in the contextualized QA, and the
performance is variable across disease groups. In the same setting, clinicians
also indicated that they prefer to see actionability as one of the main foci in
explanations. In our explanations combination method, we plan to use similarity
metrics to determine the similarity of explanations in a chronic disease
detection setting. Overall, through this thesis, we design methods that can
support knowledge-enabled explanations across different use cases, accounting
for the methods in today's AI era that can generate the supporting components
of these explanations and domain knowledge sources that can enhance them.

æè¦ï¼å¯è§£éäººå·¥æºæ§ï¼AIï¼å°æ³¨æ¼åå©äººé¡äºè§£ AI ç³»çµ±éä½æå¶æ±ºç­ï¼æ¸åå¹´ä¾ä¸ç´æ¯ AI çåºç³ãæè¿çå¯è§£éæ§ç ç©¶å°æ³¨æ¼è§£é AI æ¨¡åææ¨¡åå¯è§£éæ§çéä½ãä¹æå¹¾ä»½ç«å ´è²æåè©è«è«æè©³ç´°èªªæäºæçµä½¿ç¨èå°ä»¥ä½¿ç¨èçºä¸­å¿çå¯è§£éæ§çéæ±ï¼ä½å¯¦ä½è¼å°ãå æ­¤ï¼æ¬è«ææ¨å¨å½è£æ¨¡ååä»¥ä½¿ç¨èçºä¸­å¿çå¯è§£éæ§ä¹éçä¸äºå·®è·ãæåå»ºç«ä¸åè§£éæ¬é«ï¼EOï¼ä»¥ééå¶æ¯æ´åä»¶ä¾è¡¨ç¤ºå¾æç»ä¸­è¡ççè§£éé¡åãæåå¯¦ä½ä¸åç¥è­å¢å¼·çåç­ï¼QAï¼ç®¡ç·ï¼ä»¥å¨è¨åºç°å¢ä¸­æ¯æ´æå¢è§£éãæå¾ï¼æåæ­£å¨å¯¦ä½ä¸åç³»çµ±ï¼ä»¥çµåä¾èªä¸å AI æ¹æ³åè³ææ¨¡å¼çè§£éãå¨ EO ä¸­ï¼æåå¯ä»¥è¡¨ç¤º 15 ç¨®ä¸åçè§£éé¡åï¼ä¸¦ä¸æåå·²å¨å­åç¯ä¾ä½¿ç¨æ¡ä¾ä¸­æ¸¬è©¦éäºè¡¨ç¤ºãæåç¼ç¾ï¼ç¥è­å¢å¼·æ¹åäºåºç¤å¤§åèªè¨æ¨¡åå¨æå¢å QA ä¸­çæè½ï¼ä¸¦ä¸æè½å ç¾çç¾¤çµèç°ãå¨ç¸åçç°å¢ä¸­ï¼è¨åºé«çä¹è¡¨ç¤ºä»åå¸æå°å¯æä½æ§è¦çºè§£éä¸­çä¸»è¦ç¦é»ä¹ä¸ãå¨æåçè§£éçµåæ¹æ³ä¸­ï¼æåè¨ç«ä½¿ç¨ç¸ä¼¼æ§ææ¨ä¾ç¢ºå®æ¢æ§çåµæ¸¬ç°å¢ä¸­è§£éçç¸ä¼¼æ§ãç¸½é«èè¨ï¼ééæ¬è«æï¼æåè¨­è¨äºå¯ä»¥å¨ä¸åä½¿ç¨æ¡ä¾ä¸­æ¯æ´ç¥è­åç¨è§£éçæ¹æ³ï¼èéå°ç¶ä» AI æä»£ä¸­å¯ä»¥ç¢çéäºè§£éçæ¯æ´åä»¶åå¯ä»¥å¢å¼·éäºè§£éçé åç¥è­ä¾æºçæ¹æ³ã

##### **Contrasting Attitudes Towards Current and Future AI Applications for Computerised Interpretation of ECG: A Clinical Stakeholder Interview Study**
2410.16879v1 by Lukas Hughes-Noehrer, Leda Channer, Gabriel Strain, Gregory Yates, Richard Body, Caroline Jay

Objectives: To investigate clinicians' attitudes towards current automated
interpretation of ECG and novel AI technologies and their perception of
computer-assisted interpretation. Materials and Methods: We conducted a series
of interviews with clinicians in the UK. Our study: (i) explores the potential
for AI, specifically future 'human-like' computing approaches, to facilitate
ECG interpretation and support clinical decision making, and (ii) elicits their
opinions about the importance of explainability and trustworthiness of AI
algorithms. Results: We performed inductive thematic analysis on interview
transcriptions from 23 clinicians and identified the following themes: (i) a
lack of trust in current systems, (ii) positive attitudes towards future AI
applications and requirements for these, (iii) the relationship between the
accuracy and explainability of algorithms, and (iv) opinions on education,
possible deskilling, and the impact of AI on clinical competencies. Discussion:
Clinicians do not trust current computerised methods, but welcome future 'AI'
technologies. Where clinicians trust future AI interpretation to be accurate,
they are less concerned that it is explainable. They also preferred ECG
interpretation that demonstrated the results of the algorithm visually. Whilst
clinicians do not fear job losses, they are concerned about deskilling and the
need to educate the workforce to use AI responsibly. Conclusion: Clinicians are
positive about the future application of AI in clinical decision-making.
Accuracy is a key factor of uptake and visualisations are preferred over
current computerised methods. This is viewed as a potential means of training
and upskilling, in contrast to the deskilling that automation might be
perceived to bring.

æè¦ï¼<paragraph>ç®çï¼èª¿æ¥è¨åºé«çå°ç®åèªååå¿é»åè§£è®åæ°çäººå·¥æºæ§æè¡çæåº¦ï¼ä»¥åä»åå°é»è¦è¼å©è§£è®ççæ³ãææåæ¹æ³ï¼æåå°è±åçè¨åºé«çé²è¡äºä¸ç³»åè¨ªè«ãæåçç ç©¶ï¼(i) æ¢è¨äººå·¥æºæ§çæ½åï¼ç¹å¥æ¯æªä¾çãé¡äººé¡ãéç®æ¹æ³ï¼ä»¥ä¿é²å¿é»åè§£è®ä¸¦æ¯æè¨åºæ±ºç­å¶å®ï¼ä»¥å (ii) å¾µæ±ä»åå°äººå·¥æºæ§æ¼ç®æ³çå¯è§£éæ§åå¯ä¿¡åº¦ççæ³ãçµæï¼æåå° 23 ä½è¨åºé«ççè¨ªè«è¨éé²è¡äºæ­¸ç´ä¸»é¡åæï¼ä¸¦æ¾åºä»¥ä¸ä¸»é¡ï¼(i) å°ç®åç³»çµ±ç¼ºä¹ä¿¡ä»»ï¼(ii) å°æªä¾äººå·¥æºæ§æç¨åå°éäºæç¨çè¦æ±ææ­£é¢æåº¦ï¼(iii) æ¼ç®æ³çæºç¢ºæ§åå¯è§£éæ§ä¹éçéä¿ï¼ä»¥å (iv) å°æè²ãå¯è½çæè½éåï¼ä»¥åäººå·¥æºæ§å°è¨åºè½åçå½±é¿ççæ³ãè¨è«ï¼è¨åºé«çä¸ä¿¡ä»»ç®åçé»è¦åæ¹æ³ï¼ä½æ­¡è¿æªä¾çãäººå·¥æºæ§ãæè¡ãå¨è¨åºé«çç¸ä¿¡æªä¾ç AI è§£è®æºç¢ºçææ³ä¸ï¼ä»åä¸å¤ªæå¿å®æ¯å¦å¯è§£éãä»åä¹æ¯è¼åæ­¡è½ä»¥è¦è¦ºæ¹å¼åç¾æ¼ç®æ³çµæçå¿é»åè§£è®ãéç¶è¨åºé«çä¸å®³æå¤±æ¥­ï¼ä½ä»åæå¿æè½éåï¼ä»¥åéè¦æè²å¡å·¥è² è²¬ä»»å°ä½¿ç¨äººå·¥æºæ§ãçµè«ï¼è¨åºé«çå°äººå·¥æºæ§å¨è¨åºæ±ºç­å¶å®ä¸­çæªä¾æç¨ææ­£é¢æåº¦ãæºç¢ºæ§æ¯æ¡ç¨äººå·¥æºæ§çä¸åééµå ç´ ï¼èè¦è¦ºåæ¯ç®åçé»è¦åæ¹æ³æ´åéçãéè¢«è¦çºä¸ç¨®æ½å¨çå¹è¨åæåæè½çæ¹æ³ï¼èèªååå¯è½å¸¶ä¾çæè½éåå½¢æå°æ¯ã</paragraph>

##### **Pathologist-like explainable AI for interpretable Gleason grading in prostate cancer**
2410.15012v1 by Gesa Mittmann, Sara Laiouar-Pedari, Hendrik A. Mehrtens, Sarah HaggenmÃ¼ller, Tabea-Clara Bucher, Tirtha Chanda, Nadine T. Gaisa, Mathias Wagner, Gilbert Georg Klamminger, Tilman T. Rau, Christina Neppl, Eva Maria CompÃ©rat, Andreas Gocht, Monika HÃ¤mmerle, Niels J. Rupp, Jula Westhoff, Irene KrÃ¼cken, Maximillian Seidl, Christian M. SchÃ¼rch, Marcus Bauer, Wiebke Solass, Yu Chun Tam, Florian Weber, Rainer Grobholz, Jaroslaw Augustyniak, Thomas Kalinski, Christian HÃ¶rner, Kirsten D. Mertz, Constanze DÃ¶ring, Andreas Erbersdobler, Gabriele Deubler, Felix Bremmer, Ulrich Sommer, Michael Brodhun, Jon Griffin, Maria Sarah L. Lenon, Kiril Trpkov, Liang Cheng, Fei Chen, Angelique Levi, Guoping Cai, Tri Q. Nguyen, Ali Amin, Alessia Cimadamore, Ahmed Shabaik, Varsha Manucha, Nazeel Ahmad, Nidia Messias, Francesca Sanguedolce, Diana Taheri, Ezra Baraban, Liwei Jia, Rajal B. Shah, Farshid Siadat, Nicole Swarbrick, Kyung Park, Oudai Hassan, Siamak Sakhaie, Michelle R. Downes, Hiroshi Miyamoto, Sean R. Williamson, Tim Holland-Letz, Carolin V. Schneider, Jakob Nikolas Kather, Yuri Tolkach, Titus J. Brinker

The aggressiveness of prostate cancer, the most common cancer in men
worldwide, is primarily assessed based on histopathological data using the
Gleason scoring system. While artificial intelligence (AI) has shown promise in
accurately predicting Gleason scores, these predictions often lack inherent
explainability, potentially leading to distrust in human-machine interactions.
To address this issue, we introduce a novel dataset of 1,015 tissue microarray
core images, annotated by an international group of 54 pathologists. The
annotations provide detailed localized pattern descriptions for Gleason grading
in line with international guidelines. Utilizing this dataset, we develop an
inherently explainable AI system based on a U-Net architecture that provides
predictions leveraging pathologists' terminology. This approach circumvents
post-hoc explainability methods while maintaining or exceeding the performance
of methods trained directly for Gleason pattern segmentation (Dice score: 0.713
$\pm$ 0.003 trained on explanations vs. 0.691 $\pm$ 0.010 trained on Gleason
patterns). By employing soft labels during training, we capture the intrinsic
uncertainty in the data, yielding strong results in Gleason pattern
segmentation even in the context of high interobserver variability. With the
release of this dataset, we aim to encourage further research into segmentation
in medical tasks with high levels of subjectivity and to advance the
understanding of pathologists' reasoning processes.

æè¦ï¼ååèºçæ¯å¨çç·æ§æå¸¸è¦çççï¼å¶æ¡æ§ç¨åº¦ä¸»è¦æ ¹æ Gleason è©åç³»çµ±ä½¿ç¨çµç¹ççå­¸æ¸æé²è¡è©ä¼°ãéç¶äººå·¥æºæ§ (AI) å¨æºç¢ºé æ¸¬ Gleason è©åæ¹é¢å·²å±ç¾æ½åï¼ä½éäºé æ¸¬éå¸¸ç¼ºä¹å§å¨çå¯è§£éæ§ï¼å¯è½æå°è´å°äººæ©äºåçä¸ä¿¡ä»»ãçºäºè§£æ±ºéååé¡ï¼æåå¼é²äºä¸åç± 54 ä½ççå­¸å®¶çµæçåéåéè¨»è§£ç 1,015 åçµç¹å¾®é£åæ ¸å¿å½±åçæ°ç©è³æéãéäºè¨»è§£æä¾äºè©³ç´°çå±é¨æ¨¡å¼æè¿°ï¼ç¨æ¼ç¬¦ååéæºåç Gleason åç´ãå©ç¨éåè³æéï¼æåéç¼äºä¸ååºæ¼ U-Net æ¶æ§çå§å¨å¯è§£é AI ç³»çµ±ï¼è©²ç³»çµ±æä¾äºå©ç¨ççå­¸å®¶è¡èªé²è¡é æ¸¬ãéç¨®æ¹æ³è¦é¿äºäºå¾å¯è§£éæ§æ¹æ³ï¼åæç¶­ææè¶è¶äºç´æ¥è¨ç·´ç¨æ¼ Gleason æ¨¡å¼åå²çæ¹æ³çæè½ï¼Dice åæ¸ï¼0.713 Â± 0.003ï¼è¨ç·´æ¼è§£éï¼ç¸å°æ¼ 0.691 Â± 0.010ï¼è¨ç·´æ¼ Gleason æ¨¡å¼ï¼ãééå¨è¨ç·´æéæ¡ç¨è»æ¨ç±¤ï¼æåææäºè³æä¸­çå§å¨ä¸ç¢ºå®æ§ï¼å³ä½¿å¨è§å¯èéè®ç°æ§é«çææ³ä¸ï¼ä¹è½å¨ Gleason æ¨¡å¼åå²ä¸­ç¢çå¼·å¤§ççµæãéééåºéåè³æéï¼æåæ¨å¨é¼åµé²ä¸æ­¥ç ç©¶ä¸»è§æ§é«çé«çä»»åä¸­çåå²ï¼ä¸¦å¢é²å°ççå­¸å®¶æ¨çéç¨ççè§£ã

##### **Explainable AI Methods for Multi-Omics Analysis: A Survey**
2410.11910v1 by Ahmad Hussein, Mukesh Prasad, Ali Braytee

Advancements in high-throughput technologies have led to a shift from
traditional hypothesis-driven methodologies to data-driven approaches.
Multi-omics refers to the integrative analysis of data derived from multiple
'omes', such as genomics, proteomics, transcriptomics, metabolomics, and
microbiomics. This approach enables a comprehensive understanding of biological
systems by capturing different layers of biological information. Deep learning
methods are increasingly utilized to integrate multi-omics data, offering
insights into molecular interactions and enhancing research into complex
diseases. However, these models, with their numerous interconnected layers and
nonlinear relationships, often function as black boxes, lacking transparency in
decision-making processes. To overcome this challenge, explainable artificial
intelligence (xAI) methods are crucial for creating transparent models that
allow clinicians to interpret and work with complex data more effectively. This
review explores how xAI can improve the interpretability of deep learning
models in multi-omics research, highlighting its potential to provide
clinicians with clear insights, thereby facilitating the effective application
of such models in clinical settings.

æè¦ï¼é«ééæè¡çé²æ­¥å°è´å¾å³çµ±çåè¨­é©åæ¹æ³è½è®çºè³æé©åçæ¹æ³ãå¤çµå­¸æ¯ææ´ååæä¾èªå¤åãçµå­¸ãçè³æï¼ä¾å¦åºå çµå­¸ãèç½è³ªçµå­¸ãè½éçµå­¸ãä»£è¬çµå­¸åå¾®çç©çµå­¸ãæ­¤æ¹æ³ééæ·åçç©è³è¨çä¸åå±¤é¢ï¼è½å¨é¢äºè§£çç©ç³»çµ±ãæ·±åº¦å­¸ç¿æ¹æ³æä¾æå¸¸è¢«ç¨æ¼æ´åå¤çµå­¸è³æï¼æä¾åå­äº¤äºä½ç¨çæ´å¯åï¼ä¸¦å å¼·å°è¤éç¾ççç ç©¶ãç¶èï¼éäºæ¨¡åå·æè¨±å¤ç¸äºé£æ¥çå±¤ç´åéç·æ§éä¿ï¼éå¸¸æåé»çå­ä¸æ¨£éä½ï¼ç¼ºä¹æ±ºç­éç¨çéæåº¦ãçºäºåææ­¤ææ°ï¼å¯è§£éäººå·¥æºæ§ (xAI) æ¹æ³å°æ¼å»ºç«éææ¨¡åè³ééè¦ï¼è®è¨åºé«çå¯ä»¥æ´ææå°è§£éåèçè¤éè³æãæ­¤è©è«æ¢è¨ xAI å¦ä½è½æ¹åå¤çµå­¸ç ç©¶ä¸­æ·±åº¦å­¸ç¿æ¨¡åçå¯è§£éæ§ï¼å¼·èª¿å¶æä¾è¨åºé«çæç¢ºè¦è§£çæ½åï¼é²èä¿é²æ­¤é¡æ¨¡åå¨è¨åºç°å¢ä¸­çæææç¨ã

##### **Study on the Helpfulness of Explainable Artificial Intelligence**
2410.11896v1 by Tobias Labarta, Elizaveta Kulicheva, Ronja Froelian, Christian GeiÃler, Xenia Melman, Julian von Klitzing

Explainable Artificial Intelligence (XAI) is essential for building advanced
machine learning-powered applications, especially in critical domains such as
medical diagnostics or autonomous driving. Legal, business, and ethical
requirements motivate using effective XAI, but the increasing number of
different methods makes it challenging to pick the right ones. Further, as
explanations are highly context-dependent, measuring the effectiveness of XAI
methods without users can only reveal a limited amount of information,
excluding human factors such as the ability to understand it. We propose to
evaluate XAI methods via the user's ability to successfully perform a proxy
task, designed such that a good performance is an indicator for the explanation
to provide helpful information. In other words, we address the helpfulness of
XAI for human decision-making. Further, a user study on state-of-the-art
methods was conducted, showing differences in their ability to generate trust
and skepticism and the ability to judge the rightfulness of an AI decision
correctly. Based on the results, we highly recommend using and extending this
approach for more objective-based human-centered user studies to measure XAI
performance in an end-to-end fashion.

æè¦ï¼å¯è§£éäººå·¥æºæ§ (XAI) å°æ¼å»ºæ§åé²çæ©å¨å­¸ç¿é©åæç¨ç¨å¼è³ééè¦ï¼ç¹å¥æ¯å¨é«çè¨ºæ·æèªåé§é§ç­ééµé åãæ³å¾ãåæ¥­åå«çè¦æ±ä¿ä½¿ä½¿ç¨ææç XAIï¼ä½æ¸éæ¥çå¢å çä¸åæ¹æ³ä½¿å¾æé¸æ­£ç¢ºçæ¹æ³å·æææ°æ§ãæ­¤å¤ï¼ç±æ¼è§£éé«åº¦ä¾è³´æ¼èæ¯ï¼å¨æ²æä½¿ç¨èçææ³ä¸è¡¡é XAI æ¹æ³çæææ§åªè½æ­ç¤ºæéçè³è¨ï¼æé¤äººé¡å ç´ ï¼ä¾å¦çè§£å®çè½åãæåå»ºè­°ééä½¿ç¨èæåå·è¡ä»£çä»»åçè½åä¾è©ä¼° XAI æ¹æ³ï¼è¨­è¨ä½¿å¾è¯å¥½çå·è¡è¡¨ç¾æ¯è§£éæä¾æç¨è³è¨çææ¨ãæå¥è©±èªªï¼æåæ¢è¨ XAI å°äººé¡æ±ºç­å¶å®çå¹«å©ãæ­¤å¤ï¼å°æåé²çæ¹æ³é²è¡ä½¿ç¨èç ç©¶ï¼é¡¯ç¤ºåºå®åå¨ç¢çä¿¡ä»»åæ·ççè½åä»¥åæ­£ç¢ºå¤æ· AI æ±ºç­æ¯å¦æ­£ç¢ºçè½åæ¹é¢å­å¨å·®ç°ãæ ¹æçµæï¼æåå¼·çå»ºè­°ä½¿ç¨åæ´åéç¨®æ¹æ³ï¼ä»¥é²è¡æ´å¤ä»¥ç®æ¨çºåºç¤çäººçºä¸­å¿ä½¿ç¨èç ç©¶ï¼ä»¥çµç«¯å°çµç«¯çæ¹å¼è¡¡é XAI æè½ã

##### **Use of What-if Scenarios to Help Explain Artificial Intelligence Models for Neonatal Health**
2410.09635v1 by Abdullah Mamun, Lawrence D. Devoe, Mark I. Evans, David W. Britt, Judith Klein-Seetharaman, Hassan Ghasemzadeh

Early detection of intrapartum risk enables interventions to potentially
prevent or mitigate adverse labor outcomes such as cerebral palsy. Currently,
there is no accurate automated system to predict such events to assist with
clinical decision-making. To fill this gap, we propose "Artificial Intelligence
(AI) for Modeling and Explaining Neonatal Health" (AIMEN), a deep learning
framework that not only predicts adverse labor outcomes from maternal, fetal,
obstetrical, and intrapartum risk factors but also provides the model's
reasoning behind the predictions made. The latter can provide insights into
what modifications in the input variables of the model could have changed the
predicted outcome. We address the challenges of imbalance and small datasets by
synthesizing additional training data using Adaptive Synthetic Sampling
(ADASYN) and Conditional Tabular Generative Adversarial Networks (CTGAN). AIMEN
uses an ensemble of fully-connected neural networks as the backbone for its
classification with the data augmentation supported by either ADASYN or CTGAN.
AIMEN, supported by CTGAN, outperforms AIMEN supported by ADASYN in
classification. AIMEN can predict a high risk for adverse labor outcomes with
an average F1 score of 0.784. It also provides counterfactual explanations that
can be achieved by changing 2 to 3 attributes on average. Resources available:
https://github.com/ab9mamun/AIMEN.

æè¦ï¼ç¢ç¨ä¸­é¢¨éªçæ©æåµæ¸¬æå©æ¼é²è¡å¹²é æªæ½ï¼ä»¥é é²ææ¸è¼ä¸å©ççç¢çµæï¼ä¾å¦è¦æ§éº»çºãç®åï¼æ²ææºç¢ºçèªååç³»çµ±å¯ä»¥é æ¸¬æ­¤é¡äºä»¶ï¼ä»¥åå©è¨åºæ±ºç­ãçºäºå¡«è£éä¸ç©ºç½ï¼æåæåºãç¨æ¼å»ºæ¨¡åè§£éæ°çåå¥åº·çäººå·¥æºæ§ã(AIMEN)ï¼éæ¯ä¸åæ·±åº¦å­¸ç¿æ¶æ§ï¼å®ä¸åå¯ä»¥æ ¹æå­ç¢å©¦ãèåãç¢ç§åç¢ç¨é¢¨éªå ç´ é æ¸¬ä¸å©ççç¢çµæï¼éè½æä¾æ¨¡åååºé æ¸¬èå¾çåå ãå¾èå¯ä»¥æä¾è¦è§£ï¼èªªææ¨¡åè¼¸å¥è®æ¸ä¸­çåªäºä¿®æ¹å¯è½ææ¹è®é æ¸¬çµæãæåééä½¿ç¨é©ææ§åææ½æ¨£ (ADASYN) åæ¢ä»¶è¡¨æ ¼çæå°æç¶²è·¯ (CTGAN) ä¾åæé¡å¤çè¨ç·´è³æï¼ä»¥è§£æ±ºä¸å¹³è¡¡åå°åè³æéçææ°ãAIMEN ä½¿ç¨å¨é£æ¥ç¥ç¶ç¶²è·¯çéåä½çºå¶åé¡çéª¨å¹¹ï¼ä¸¦éé ADASYN æ CTGAN æ¯æ´è³ææ´åãç± CTGAN æ¯æ´ç AIMEN å¨åé¡æ¹é¢åªæ¼ç± ADASYN æ¯æ´ç AIMENãAIMEN å¯ä»¥é æ¸¬ä¸å©ççç¢çµæçé«é¢¨éªï¼å¹³å F1 åæ¸çº 0.784ãå®éæä¾åäºå¯¦è§£éï¼å¯ééå¹³åè®æ´ 2 è³ 3 åå±¬æ§ä¾éæãå¯ç¨è³æºï¼https://github.com/ab9mamun/AIMENã

##### **Artificial intelligence techniques in inherited retinal diseases: A review**
2410.09105v1 by Han Trinh, Jordan Vice, Jason Charng, Zahra Tajbakhsh, Khyber Alam, Fred K. Chen, Ajmal Mian

Inherited retinal diseases (IRDs) are a diverse group of genetic disorders
that lead to progressive vision loss and are a major cause of blindness in
working-age adults. The complexity and heterogeneity of IRDs pose significant
challenges in diagnosis, prognosis, and management. Recent advancements in
artificial intelligence (AI) offer promising solutions to these challenges.
However, the rapid development of AI techniques and their varied applications
have led to fragmented knowledge in this field. This review consolidates
existing studies, identifies gaps, and provides an overview of AI's potential
in diagnosing and managing IRDs. It aims to structure pathways for advancing
clinical applications by exploring AI techniques like machine learning and deep
learning, particularly in disease detection, progression prediction, and
personalized treatment planning. Special focus is placed on the effectiveness
of convolutional neural networks in these areas. Additionally, the integration
of explainable AI is discussed, emphasizing its importance in clinical settings
to improve transparency and trust in AI-based systems. The review addresses the
need to bridge existing gaps in focused studies on AI's role in IRDs, offering
a structured analysis of current AI techniques and outlining future research
directions. It concludes with an overview of the challenges and opportunities
in deploying AI for IRDs, highlighting the need for interdisciplinary
collaboration and the continuous development of robust, interpretable AI models
to advance clinical applications.

æè¦ï¼éºå³æ§è¦ç¶²èç¾ç (IRD) æ¯ä¸çµå¤æ¨£åçéºå³ç¾çï¼
æå°è´è¦åéæ¼¸åªå¤±ï¼æ¯å·¥ä½å¹´é½¡æäººå¤±æçä¸»è¦åå ãIRD çè¤éæ§åç°è³ªæ§å°è¨ºæ·ãé å¾åç®¡çæåºäºéå¤§ææ°ãæè¿äººå·¥æºè½ (AI) çé²æ­¥çºéäºææ°æä¾äºæå¸æçè§£æ±ºæ¹æ¡ã
ç¶èï¼AI æè¡çå¿«éç¼å±åå¶å¤ç¨®æç¨å°è´äºè©²é åçç¥è­åæ£ãæ¬ç¶è¿°æ´åäºç¾æç ç©¶ï¼æ¾åºå·®è·ï¼ä¸¦æ¦è¿°äº AI å¨è¨ºæ·åç®¡ç IRD ä¸­çæ½åãå®æ¨å¨ééæ¢ç´¢æ©å¨å­¸ç¿åæ·±åº¦å­¸ç¿ç­ AI æè¡ï¼ç¹å¥æ¯å¨ç¾çæª¢æ¸¬ãé²ç¨é æ¸¬ååæ§åæ²»çè¨åä¸­ï¼çºæ¨é²è¨åºæç¨æ§å»ºéå¾ãç¹å¥éæ³¨éäºé åä¸­å·ç©ç¥ç¶ç¶²è·¯çæææ§ãæ­¤å¤ï¼è¨è«äºå¯è§£é AI çæ´åï¼å¼·èª¿äºå¶å¨è¨åºç°å¢ä¸­æé«éæåº¦åå°åºæ¼ AI çç³»çµ±çä¿¡ä»»çéè¦æ§ãè©²ç¶è¿°è§£æ±ºäºå½å AI å¨ IRD ä¸­ä½ç¨çéé»ç ç©¶ä¸­ç¾æå·®è·çå¿è¦æ§ï¼æä¾äºå°ç¶å AI æè¡ççµæ§ååæï¼ä¸¦æ¦è¿°äºæªä¾çç ç©¶æ¹åãæå¾æ¦è¿°äºå¨ IRD ä¸­é¨ç½² AI çææ°åæ©éï¼å¼·èª¿äºè·¨å­¸ç§åä½åæçºéç¼å¼·å¤§ãå¯è§£éç AI æ¨¡åä»¥æ¨é²è¨åºæç¨çå¿è¦æ§ã

##### **CasiMedicos-Arg: A Medical Question Answering Dataset Annotated with Explanatory Argumentative Structures**
2410.05235v2 by Ekaterina Sviridova, Anar Yeginbergen, Ainara Estarrona, Elena Cabrio, Serena Villata, Rodrigo Agerri

Explaining Artificial Intelligence (AI) decisions is a major challenge
nowadays in AI, in particular when applied to sensitive scenarios like medicine
and law. However, the need to explain the rationale behind decisions is a main
issue also for human-based deliberation as it is important to justify
\textit{why} a certain decision has been taken. Resident medical doctors for
instance are required not only to provide a (possibly correct) diagnosis, but
also to explain how they reached a certain conclusion. Developing new tools to
aid residents to train their explanation skills is therefore a central
objective of AI in education. In this paper, we follow this direction, and we
present, to the best of our knowledge, the first multilingual dataset for
Medical Question Answering where correct and incorrect diagnoses for a clinical
case are enriched with a natural language explanation written by doctors. These
explanations have been manually annotated with argument components (i.e.,
premise, claim) and argument relations (i.e., attack, support), resulting in
the Multilingual CasiMedicos-Arg dataset which consists of 558 clinical cases
in four languages (English, Spanish, French, Italian) with explanations, where
we annotated 5021 claims, 2313 premises, 2431 support relations, and 1106
attack relations. We conclude by showing how competitive baselines perform over
this challenging dataset for the argument mining task.

æè¦ï¼è§£éäººå·¥æºæ§ (AI) çæ±ºç­æ¯ç¾å¨ AI çä¸é éå¤§ææ°ï¼ç¹å¥æ¯æç¨æ¼åé«å­¸åæ³å¾ç­æææå¢æãç¶èï¼è§£éæ±ºç­èå¾çç±çéæ±ä¹æ¯åºæ¼äººé¡çèéçä¸åä¸»è¦åé¡ï¼å çºæå¿è¦è­æçºä»éº¼ååºæåæ±ºç­ãä¾å¦ï¼ä½é¢é«å¸«ä¸åéè¦æä¾ï¼å¯è½æ¯æ­£ç¢ºçï¼è¨ºæ·ï¼ééè¦è§£éä»åå¦ä½éææåçµè«ãå æ­¤ï¼éç¼æ°çå·¥å·ä¾å¹«å©ä½é¢é«å¸«è¨ç·´ä»åçè§£éæå·§æ¯æè²ä¸­ AI çä¸é æ ¸å¿ç®æ¨ãå¨æ¬æä¸­ï¼æåéµå¾ªéåæ¹åï¼ä¸¦ä¸æ ¹ææåçäºè§£ï¼æåºç¬¬ä¸åå¤èªè¨é«å­¸åç­è³æéï¼å¶ä¸­è¨åºçä¾çæ­£ç¢ºåä¸æ­£ç¢ºè¨ºæ·é½éæç±é«çæ°å¯«çèªç¶èªè¨è§£éãéäºè§£éå·²ä½¿ç¨è«è­çµæï¼å³åæãä¸»å¼µï¼åè«è­éä¿ï¼å³æ»æãæ¯æï¼é²è¡æåè¨»è§£ï¼ç¢çå¤èªè¨ CasiMedicos-Arg è³æéï¼å¶ä¸­åå« 558 åå·æè§£éçåç¨®èªè¨ï¼è±èªãè¥¿ç­çèªãæ³èªãç¾©å¤§å©èªï¼çè¨åºçä¾ï¼æåè¨»è§£äº 5021 åä¸»å¼µã2313 ååæã2431 åæ¯æéä¿å 1106 åæ»æéä¿ãæåæå¾å±ç¤ºäºç«¶ç­åºæºå¦ä½éå°è«è­æ¢åä»»åå·è¡æ­¤å·ææ°æ§çè³æéã

##### **Explainable Diagnosis Prediction through Neuro-Symbolic Integration**
2410.01855v1 by Qiuhao Lu, Rui Li, Elham Sagheb, Andrew Wen, Jinlian Wang, Liwei Wang, Jungwei W. Fan, Hongfang Liu

Diagnosis prediction is a critical task in healthcare, where timely and
accurate identification of medical conditions can significantly impact patient
outcomes. Traditional machine learning and deep learning models have achieved
notable success in this domain but often lack interpretability which is a
crucial requirement in clinical settings. In this study, we explore the use of
neuro-symbolic methods, specifically Logical Neural Networks (LNNs), to develop
explainable models for diagnosis prediction. Essentially, we design and
implement LNN-based models that integrate domain-specific knowledge through
logical rules with learnable thresholds. Our models, particularly
$M_{\text{multi-pathway}}$ and $M_{\text{comprehensive}}$, demonstrate superior
performance over traditional models such as Logistic Regression, SVM, and
Random Forest, achieving higher accuracy (up to 80.52\%) and AUROC scores (up
to 0.8457) in the case study of diabetes prediction. The learned weights and
thresholds within the LNN models provide direct insights into feature
contributions, enhancing interpretability without compromising predictive
power. These findings highlight the potential of neuro-symbolic approaches in
bridging the gap between accuracy and explainability in healthcare AI
applications. By offering transparent and adaptable diagnostic models, our work
contributes to the advancement of precision medicine and supports the
development of equitable healthcare solutions. Future research will focus on
extending these methods to larger and more diverse datasets to further validate
their applicability across different medical conditions and populations.

æè¦ï¼è¨ºæ·é æ¸¬æ¯é«çä¿å¥ä¸­çä¸é ééµä»»åï¼åæä¸æºç¢ºå°è­å¥é«ççæ³æå°æ£èççµæç¢çéå¤§å½±é¿ãå³çµ±æ©å¨å­¸ç¿åæ·±åº¦å­¸ç¿æ¨¡åå·²å¨æ­¤é ååå¾é¡¯èæåï¼ä½éå¸¸ç¼ºä¹å¯è§£éæ§ï¼éæ¯è¨åºç°å¢ä¸­çééµè¦æ±ãå¨æ¬ç ç©¶ä¸­ï¼æåæ¢è¨äºç¥ç¶ç¬¦èæ¹æ³ï¼ç¹å¥æ¯éè¼¯ç¥ç¶ç¶²è·¯ (LNN)ï¼ä»¥éç¼å¯è§£éçè¨ºæ·é æ¸¬æ¨¡åãåºæ¬ä¸ï¼æåè¨­è¨ä¸¦å¯¦ä½äºåºæ¼ LNN çæ¨¡åï¼è©²æ¨¡åéééè¼¯è¦ååå¯å­¸ç¿çé¾å¼æ´åé åç¹å®çç¥è­ãæåçæ¨¡åï¼ç¹å¥æ¯ $M_{\text{multi-pathway}}$ å $M_{\text{comprehensive}}$ï¼è¡¨ç¾åºåªæ¼å³çµ±æ¨¡åï¼å¦éè¼¯è¿´æ­¸ãSVM åé¨æ©æ£®æï¼çåè¶æè½ï¼å¨ç³å°¿çé æ¸¬çæ¡ä¾ç ç©¶ä¸­ï¼éå°äºæ´é«çæºç¢ºåº¦ï¼é«é 80.52%ï¼å AUROC åæ¸ï¼é«é 0.8457ï¼ãLNN æ¨¡åä¸­å­¸ç¿çæ¬éåé¾å¼æä¾äºå°ç¹å¾µè²¢ç»çç´æ¥è¦è§£ï¼å¢å¼·äºå¯è§£éæ§ï¼åæä¸æå®³é æ¸¬è½åãéäºç¼ç¾çªé¡¯äºç¥ç¶ç¬¦èæ¹æ³å¨å½åé«çä¿å¥ AI æç¨ä¸­æºç¢ºæ§åå¯è§£éæ§å·®è·æ¹é¢çæ½åãééæä¾éæä¸é©ææ§å¼·çè¨ºæ·æ¨¡åï¼æåçç ç©¶æå©æ¼ç²¾æºé«ççé²æ­¥ï¼ä¸¦æ¯æ´å¬å¹³é«çä¿å¥è§£æ±ºæ¹æ¡çéç¼ãæªä¾çç ç©¶å°å°æ³¨æ¼å°éäºæ¹æ³æ´å±å°æ´å¤§ä¸æ´å¤æ¨£åçè³æéï¼ä»¥é²ä¸æ­¥é©è­å¶å¨ä¸åé«ççæ³åäººç¾¤ä¸­çé©ç¨æ§ã

##### **Easydiagnos: a framework for accurate feature selection for automatic diagnosis in smart healthcare**
2410.00366v1 by Prasenjit Maji, Amit Kumar Mondal, Hemanta Kumar Mondal, Saraju P. Mohanty

The rapid advancements in artificial intelligence (AI) have revolutionized
smart healthcare, driving innovations in wearable technologies, continuous
monitoring devices, and intelligent diagnostic systems. However, security,
explainability, robustness, and performance optimization challenges remain
critical barriers to widespread adoption in clinical environments. This
research presents an innovative algorithmic method using the Adaptive Feature
Evaluator (AFE) algorithm to improve feature selection in healthcare datasets
and overcome problems. AFE integrating Genetic Algorithms (GA), Explainable
Artificial Intelligence (XAI), and Permutation Combination Techniques (PCT),
the algorithm optimizes Clinical Decision Support Systems (CDSS), thereby
enhancing predictive accuracy and interpretability. The proposed method is
validated across three diverse healthcare datasets using six distinct machine
learning algorithms, demonstrating its robustness and superiority over
conventional feature selection techniques. The results underscore the
transformative potential of AFE in smart healthcare, enabling personalized and
transparent patient care. Notably, the AFE algorithm, when combined with a
Multi-layer Perceptron (MLP), achieved an accuracy of up to 98.5%, highlighting
its capability to improve clinical decision-making processes in real-world
healthcare applications.

æè¦ï¼äººå·¥æºæ§ (AI) çå¿«éé²å±å¾¹åºæ¹è®äºæºæ§é«çä¿å¥ï¼æ¨åäºå¯ç©¿æ´æè¡ãæçºç£æ§è£ç½®åæºæ§è¨ºæ·ç³»çµ±çåµæ°ãç¶èï¼å®å¨æ§ãå¯è§£éæ§ãç©©å¥æ§åæè½æä½³åææ°ä»ç¶æ¯è¨åºç°å¢ä¸­å»£æ³æ¡ç¨çééµéç¤ãæ¬ç ç©¶æåºä¸ååµæ°çæ¼ç®æ³æ¹æ³ï¼ä½¿ç¨èªé©æç¹å¾µè©ä¼°å¨ (AFE) æ¼ç®æ³ä¾æ¹åé«çä¿å¥è³æéä¸­çç¹å¾µé¸åä¸¦åæåé¡ãAFE æ´åäºéºå³æ¼ç®æ³ (GA)ãå¯è§£éäººå·¥æºæ§ (XAI) åæåçµåæè¡ (PCT)ï¼è©²æ¼ç®æ³æä½³åäºè¨åºæ±ºç­æ¯æ´ç³»çµ± (CDSS)ï¼å¾èæé«äºé æ¸¬æºç¢ºæ§åå¯è§£éæ§ãææåºçæ¹æ³ä½¿ç¨å­ç¨®ä¸åçæ©å¨å­¸ç¿æ¼ç®æ³é©è­äºä¸åä¸åçé«çä¿å¥è³æéï¼è­æäºå¶ç©©å¥æ§ååªæ¼å³çµ±ç¹å¾µé¸åæè¡ãçµæå¼·èª¿äº AFE å¨æºæ§é«çä¿å¥ä¸­çè½è®æ½åï¼å¯¦ç¾äºåäººååéæçæ£èç§è­·ãå¼å¾æ³¨æçæ¯ï¼AFE æ¼ç®æ³èå¤å±¤æç¥å¨ (MLP) çµåä½¿ç¨æï¼æºç¢ºåº¦é«é 98.5%ï¼çªé¡¯äºå¶æ¹åå¯¦éé«çä¿å¥æç¨ä¸­è¨åºæ±ºç­å¶å®æµç¨çè½åã

##### **Dermatologist-like explainable AI enhances melanoma diagnosis accuracy: eye-tracking study**
2409.13476v1 by Tirtha Chanda, Sarah Haggenmueller, Tabea-Clara Bucher, Tim Holland-Letz, Harald Kittler, Philipp Tschandl, Markus V. Heppt, Carola Berking, Jochen S. Utikal, Bastian Schilling, Claudia Buerger, Cristian Navarrete-Dechent, Matthias Goebeler, Jakob Nikolas Kather, Carolin V. Schneider, Benjamin Durani, Hendrike Durani, Martin Jansen, Juliane Wacker, Joerg Wacker, Reader Study Consortium, Titus J. Brinker

Artificial intelligence (AI) systems have substantially improved
dermatologists' diagnostic accuracy for melanoma, with explainable AI (XAI)
systems further enhancing clinicians' confidence and trust in AI-driven
decisions. Despite these advancements, there remains a critical need for
objective evaluation of how dermatologists engage with both AI and XAI tools.
In this study, 76 dermatologists participated in a reader study, diagnosing 16
dermoscopic images of melanomas and nevi using an XAI system that provides
detailed, domain-specific explanations. Eye-tracking technology was employed to
assess their interactions. Diagnostic performance was compared with that of a
standard AI system lacking explanatory features. Our findings reveal that XAI
systems improved balanced diagnostic accuracy by 2.8 percentage points relative
to standard AI. Moreover, diagnostic disagreements with AI/XAI systems and
complex lesions were associated with elevated cognitive load, as evidenced by
increased ocular fixations. These insights have significant implications for
clinical practice, the design of AI tools for visual tasks, and the broader
development of XAI in medical diagnostics.

æè¦ï¼äººå·¥æºæ§ (AI) ç³»çµ±å·²å¤§å¹æ¹åç®èç§é«å¸«å°é»è²ç´ ç¤çè¨ºæ·æºç¢ºåº¦ï¼èå¯è§£é AI (XAI) ç³»çµ±é²ä¸æ­¥æåè¨åºé«å¸«å° AI é©åæ±ºç­çä¿¡å¿èä¿¡è³´ãåç®¡æéäºé²å±ï¼å°æ¼ç®èç§é«å¸«å¦ä½ä½¿ç¨ AI å XAI å·¥å·ï¼ä»æå®¢è§è©ä¼°çè¿«åéæ±ãå¨éé ç ç©¶ä¸­ï¼76 ä½ç®èç§é«å¸«åèäºä¸é è®èç ç©¶ï¼ä½¿ç¨ XAI ç³»çµ±è¨ºæ· 16 å¼µé»è²ç´ ç¤åç£çç®èé¡å½±åï¼è©²ç³»çµ±æä¾è©³ç´°çé åç¹å®èªªæãæ¡ç¨ç¼çè¿½è¹¤æè¡ä¾è©ä¼°ä»åçäºåãå°è¨ºæ·è¡¨ç¾èç¼ºä¹èªªæåè½çæ¨æº AI ç³»çµ±é²è¡æ¯è¼ãæåçç ç©¶çµæé¡¯ç¤ºï¼XAI ç³»çµ±ç¸è¼æ¼æ¨æº AIï¼å°å¹³è¡¡è¨ºæ·æºç¢ºåº¦æåäº 2.8 åç¾åé»ãæ­¤å¤ï¼è AI/XAI ç³»çµ±çè¨ºæ·åæ­§åè¤éççç¶èèªç¥è² æåé«æéï¼éç±å¢å çç¼çæ³¨è¦æ¬¡æ¸æè­å¯¦ãéäºè¦è§£å°è¨åºå¯¦åãè¦è¦ºä»»å AI å·¥å·çè¨­è¨åé«å­¸è¨ºæ·ä¸­ XAI çå»£æ³ç¼å±å·æéå¤§æç¾©ã

##### **Explainable AI for Autism Diagnosis: Identifying Critical Brain Regions Using fMRI Data**
2409.15374v1 by Suryansh Vidya, Kush Gupta, Amir Aly, Andy Wills, Emmanuel Ifeachor, Rohit Shankar

Early diagnosis and intervention for Autism Spectrum Disorder (ASD) has been
shown to significantly improve the quality of life of autistic individuals.
However, diagnostics methods for ASD rely on assessments based on clinical
presentation that are prone to bias and can be challenging to arrive at an
early diagnosis. There is a need for objective biomarkers of ASD which can help
improve diagnostic accuracy. Deep learning (DL) has achieved outstanding
performance in diagnosing diseases and conditions from medical imaging data.
Extensive research has been conducted on creating models that classify ASD
using resting-state functional Magnetic Resonance Imaging (fMRI) data. However,
existing models lack interpretability. This research aims to improve the
accuracy and interpretability of ASD diagnosis by creating a DL model that can
not only accurately classify ASD but also provide explainable insights into its
working. The dataset used is a preprocessed version of the Autism Brain Imaging
Data Exchange (ABIDE) with 884 samples. Our findings show a model that can
accurately classify ASD and highlight critical brain regions differing between
ASD and typical controls, with potential implications for early diagnosis and
understanding of the neural basis of ASD. These findings are validated by
studies in the literature that use different datasets and modalities,
confirming that the model actually learned characteristics of ASD and not just
the dataset. This study advances the field of explainable AI in medical imaging
by providing a robust and interpretable model, thereby contributing to a future
with objective and reliable ASD diagnostics.

æè¦ï¼èªéçè­ç³»éç¤ (ASD) çæ©æè¨ºæ·åä»å¥å·²è¢«è­å¯¦è½é¡¯èæ¹åèªéçæ£èççæ´»åè³ªãç¶èï¼ASD çè¨ºæ·æ¹æ³ä¾è³´æ¼åºæ¼è¨åºè¡¨ç¾çè©ä¼°ï¼å®¹æç¢çåè¦ï¼ä¸å¯è½é£ä»¥ååºæ©æè¨ºæ·ãæå¿è¦æ¾åº ASD çå®¢è§çç©æ¨è¨ï¼ä»¥å¹«å©æé«è¨ºæ·æºç¢ºæ§ãæ·±åº¦å­¸ç¿ (DL) å¨å¾é«å­¸å½±åè³æè¨ºæ·ç¾çåççæ¹é¢åå¾ååºçè¡¨ç¾ãå·²ç¶éå°å»ºç«ä½¿ç¨éæåè½æ§ç£æ¯é å½± (fMRI) è³æå° ASD é²è¡åé¡çæ¨¡åé²è¡å»£æ³çç ç©¶ãç¶èï¼ç¾æçæ¨¡åç¼ºä¹å¯è§£éæ§ãæ¬ç ç©¶æ¨å¨ééå»ºç«ä¸åä¸åè½æºç¢ºåé¡ ASDï¼éè½æä¾å¯è§£éè¦è§£èªªæå¶éä½åçç DL æ¨¡åï¼ä¾æ¹å ASD è¨ºæ·çæºç¢ºæ§åå¯è§£éæ§ãæä½¿ç¨çè³æéæ¯èªéçå¤§è¦å½±åè³æäº¤æ (ABIDE) çé èççæ¬ï¼åå« 884 åæ¨£æ¬ãæåçç ç©¶çµæé¡¯ç¤ºï¼è©²æ¨¡åè½æºç¢ºåé¡ ASDï¼ä¸¦å¼·èª¿ ASD èå¸åå°ç§çµä¹éå­å¨å·®ç°çééµè¦åï¼å°æ¼ ASD çæ©æè¨ºæ·åç¥ç¶åºç¤ççè§£å·ææ½å¨çæç¾©ãéäºç ç©¶çµæå·²ç±ä½¿ç¨ä¸åè³æéåæ¹å¼çæç»ç ç©¶é©è­ï¼è­å¯¦è©²æ¨¡åå¯¦éä¸å­¸ç¿äº ASD çç¹å¾µï¼èä¸ååæ¯è³æéãæ¬ç ç©¶ééæä¾ä¸åå¼·å¥ä¸å¯è§£éçæ¨¡åï¼æ¨åäºé«å­¸å½±åä¸­å¯è§£é AI çé åï¼å¾èçºæªä¾æä¾å®¢è§ä¸å¯é ç ASD è¨ºæ·ååºè²¢ç»ã

##### **Improving Prototypical Parts Abstraction for Case-Based Reasoning Explanations Designed for the Kidney Stone Type Recognition**
2409.12883v1 by Daniel Flores-Araiza, Francisco Lopez-Tiro, ClÃ©ment Larose, Salvador Hinojosa, Andres Mendez-Vazquez, Miguel Gonzalez-Mendoza, Gilberto Ochoa-Ruiz, Christian Daul

The in-vivo identification of the kidney stone types during an ureteroscopy
would be a major medical advance in urology, as it could reduce the time of the
tedious renal calculi extraction process, while diminishing infection risks.
Furthermore, such an automated procedure would make possible to prescribe
anti-recurrence treatments immediately. Nowadays, only few experienced
urologists are able to recognize the kidney stone types in the images of the
videos displayed on a screen during the endoscopy. Thus, several deep learning
(DL) models have recently been proposed to automatically recognize the kidney
stone types using ureteroscopic images. However, these DL models are of black
box nature whicl limits their applicability in clinical settings. This
contribution proposes a case-based reasoning DL model which uses prototypical
parts (PPs) and generates local and global descriptors. The PPs encode for each
class (i.e., kidney stone type) visual feature information (hue, saturation,
intensity and textures) similar to that used by biologists. The PPs are
optimally generated due a new loss function used during the model training.
Moreover, the local and global descriptors of PPs allow to explain the
decisions ("what" information, "where in the images") in an understandable way
for biologists and urologists. The proposed DL model has been tested on a
database including images of the six most widespread kidney stone types. The
overall average classification accuracy was 90.37. When comparing this results
with that of the eight other DL models of the kidney stone state-of-the-art, it
can be seen that the valuable gain in explanability was not reached at the
expense of accuracy which was even slightly increased with respect to that
(88.2) of the best method of the literature. These promising and interpretable
results also encourage urologists to put their trust in AI-based solutions.

æè¦ï¼å°¿è·¯é¡æª¢æ¥ä¸­èçµç³é¡åçé«å§è­å¥å°æ¯æ³å°¿ç§çä¸é éå¤§é²å±ï¼å çºå®å¯ä»¥æ¸å°ç¹ç£çèçµç³ååºéç¨çæéï¼åæéä½ææé¢¨éªãæ­¤å¤ï¼éç¨®èªååç¨åºå°ä½¿ç«å³éç«æå¾©ç¼æ²»çæçºå¯è½ãå¦ä»ï¼åªæå°æ¸ç¶é©è±å¯çæ³å°¿ç§é«çè½å¤ å¨å§è¦é¡æª¢æ¥æéå±å¹ä¸é¡¯ç¤ºçè¦é »ååä¸­è­å¥èçµç³é¡åãå æ­¤ï¼æè¿å·²æåºå¤ç¨®æ·±åº¦å­¸ç¿ (DL) æ¨¡åï¼ä»¥ä½¿ç¨è¼¸å°¿ç®¡é¡ååèªåè­å¥èçµç³é¡åãç¶èï¼éäº DL æ¨¡åæ¬è³ªä¸æ¯é»çå­ï¼ééå¶äºå®åå¨è¨åºç°å¢ä¸­çæç¨æ§ãæ¬ææåºäºä¸ååºæ¼æ¡ä¾æ¨çç DL æ¨¡åï¼å®ä½¿ç¨ååé¨å (PP) ä¸¦çæå±é¨åå¨å±æè¿°ç¬¦ãPP çºæ¯ç¨®é¡åï¼å³èçµç³é¡åï¼ç·¨ç¢¼è¦è¦ºç¹å¾µä¿¡æ¯ï¼è²èª¿ãé£½ååº¦ãå¼·åº¦åç´çï¼ï¼é¡ä¼¼æ¼çç©å­¸å®¶ä½¿ç¨çä¿¡æ¯ãç±æ¼å¨æ¨¡åè¨ç·´æéä½¿ç¨çæ°æå¤±å½æ¸ï¼PP å¾å°äºæä½³çæãæ­¤å¤ï¼PP çå±é¨åå¨å±æè¿°ç¬¦åè¨±ä»¥çç©å­¸å®¶åæ³å°¿ç§é«çå¯ä»¥çè§£çæ¹å¼è§£éæ±ºç­ï¼âä»éº¼âä¿¡æ¯ï¼âååä¸­çä»éº¼ä½ç½®âï¼ãææåºç DL æ¨¡åå·²å¨ä¸ååå«å­ç¨®æå»£æ³çèçµç³é¡åååçæ¸æåº«ä¸é²è¡äºæ¸¬è©¦ãç¸½é«å¹³ååé¡æºç¢ºççº 90.37ãå°æ­¤çµæèèçµç³æåé²çå«åå¶ä» DL æ¨¡åççµæé²è¡æ¯è¼æï¼å¯ä»¥çåºï¼å¯è§£éæ§çå¯¶è²´å¢çä¸¦æªä»¥æºç¢ºæ§çºä»£å¹ï¼çè³ç¥æå¢å èæç»ä¸­æå¥½çæ¹æ³ (88.2) ç¸æ¯ãéäºæå¸æä¸å¯è§£éççµæä¹é¼åµæ³å°¿ç§é«çç¸ä¿¡åºæ¼äººå·¥æºè½çè§£æ±ºæ¹æ¡ã

##### **Towards Interpretable End-Stage Renal Disease (ESRD) Prediction: Utilizing Administrative Claims Data with Explainable AI Techniques**
2409.12087v3 by Yubo Li, Saba Al-Sayouri, Rema Padman

This study explores the potential of utilizing administrative claims data,
combined with advanced machine learning and deep learning techniques, to
predict the progression of Chronic Kidney Disease (CKD) to End-Stage Renal
Disease (ESRD). We analyze a comprehensive, 10-year dataset provided by a major
health insurance organization to develop prediction models for multiple
observation windows using traditional machine learning methods such as Random
Forest and XGBoost as well as deep learning approaches such as Long Short-Term
Memory (LSTM) networks. Our findings demonstrate that the LSTM model,
particularly with a 24-month observation window, exhibits superior performance
in predicting ESRD progression, outperforming existing models in the
literature. We further apply SHapley Additive exPlanations (SHAP) analysis to
enhance interpretability, providing insights into the impact of individual
features on predictions at the individual patient level. This study underscores
the value of leveraging administrative claims data for CKD management and
predicting ESRD progression.

æè¦ï¼æ¬ç ç©¶æ¢è¨å©ç¨è¡æ¿ç³å ±è³æï¼çµååé²æ©å¨å­¸ç¿èæ·±åº¦å­¸ç¿æè¡ï¼é æ¸¬æ¢æ§èèç (CKD) é²å±è³æ«æèèç¾ç (ESRD) çå¯è½æ§ãæååæä¸å®¶å¤§åå¥åº·ä¿éªçµç¹æä¾ç 10 å¹´ç¶åè³æéï¼ä½¿ç¨å³çµ±æ©å¨å­¸ç¿æ¹æ³ï¼ä¾å¦é¨æ©æ£®æå XGBoostï¼ä»¥åæ·±åº¦å­¸ç¿æ¹æ³ï¼ä¾å¦é·æç­æè¨æ¶ (LSTM) ç¶²è·¯ï¼éç¼å¤åè§å¯è¦çªçé æ¸¬æ¨¡åãæåçç ç©¶çµæé¡¯ç¤ºï¼LSTM æ¨¡åï¼å°¤å¶æ¯ 24 åæè§å¯è¦çªï¼å¨é æ¸¬ ESRD é²å±æ¹é¢è¡¨ç¾åªç°ï¼åªæ¼æç»ä¸­çç¾ææ¨¡åãæåé²ä¸æ­¥æç¨ SHapley å¯å æ§è§£é (SHAP) åæä»¥å¢å¼·å¯è§£éæ§ï¼æ·±å¥äºè§£åå¥ç¹å¾µå°åå¥æ£èå±¤ç´é æ¸¬çå½±é¿ãæ¬ç ç©¶å¼·èª¿äºå©ç¨è¡æ¿ç³å ±è³æé²è¡ CKD ç®¡çåé æ¸¬ ESRD é²å±çå¹å¼ã

##### **Explainable AI: Definition and attributes of a good explanation for health AI**
2409.15338v1 by Evangelia Kyrimi, Scott McLachlan, Jared M Wohlgemut, Zane B Perkins, David A. Lagnado, William Marsh, the ExAIDSS Expert Group

Proposals of artificial intelligence (AI) solutions based on increasingly
complex and accurate predictive models are becoming ubiquitous across many
disciplines. As the complexity of these models grows, transparency and users'
understanding often diminish. This suggests that accurate prediction alone is
insufficient for making an AI-based solution truly useful. In the development
of healthcare systems, this introduces new issues related to accountability and
safety. Understanding how and why an AI system makes a recommendation may
require complex explanations of its inner workings and reasoning processes.
Although research on explainable AI (XAI) has significantly increased in recent
years and there is high demand for XAI in medicine, defining what constitutes a
good explanation remains ad hoc, and providing adequate explanations continues
to be challenging. To fully realize the potential of AI, it is critical to
address two fundamental questions about explanations for safety-critical AI
applications, such as health-AI: (1) What is an explanation in health-AI? and
(2) What are the attributes of a good explanation in health-AI? In this study,
we examined published literature and gathered expert opinions through a
two-round Delphi study. The research outputs include (1) a definition of what
constitutes an explanation in health-AI and (2) a comprehensive list of
attributes that characterize a good explanation in health-AI.

æè¦ï¼é¨èè¶ä¾è¶è¤éä¸æºç¢ºçé æ¸¬æ¨¡åï¼åºæ¼äººå·¥æºæ§ (AI) è§£æ±ºæ¹æ¡çææ¡å¨è¨±å¤é åä¸­è®å¾ç¡èä¸å¨ãé¨èéäºæ¨¡åè¤éæ§çå¢å ï¼éæåº¦åä½¿ç¨èççè§£åå¾å¾æéä½ãéè¡¨ç¤ºåææºç¢ºçé æ¸¬ä¸¦ä¸è¶³ä»¥è® AI è§£æ±ºæ¹æ¡çæ­£æç¨ãå¨é«çä¿å¥ç³»çµ±çéç¼ä¸­ï¼éå¼å¥äºèåè²¬å¶åå®å¨æ§ç¸éçæ°åé¡ãç­è§£ AI ç³»çµ±å¦ä½ä»¥åçºä½æåºå»ºè­°å¯è½éè¦å°å¶å§é¨éä½åæ¨çéç¨é²è¡è¤éçèªªæãåç®¡è¿å¹´ä¾å°å¯è§£é AI (XAI) çç ç©¶å·²å¤§å¹å¢å ï¼ä¸é«å­¸é åå° XAI æå¾é«çéæ±ï¼ä½å®ç¾©ä»éº¼æ§æä¸åå¥½çè§£éä»æ¯è¨ææ§çï¼èæä¾é©ç¶çè§£éä»ç¶å·æææ°æ§ãçºäºååç¼æ® AI çæ½åï¼å°æ¼å®å¨ééµå AI æç¨ï¼ä¾å¦å¥åº· AIï¼çè§£éï¼æ¢è¨å©ååºæ¬åé¡è³ééè¦ï¼(1) ä»éº¼æ¯å¥åº· AI ä¸­çè§£éï¼ä»¥å (2) å¥åº· AI ä¸­ä¸åå¥½çè§£éæåªäºå±¬æ§ï¼å¨æ¬ç ç©¶ä¸­ï¼æåæª¢è¦äºå·²ç¼è¡¨çæç»ï¼ä¸¦ééå©è¼ªå¾·ç¾è²ç ç©¶æ¶éäºå°å®¶æè¦ãç ç©¶ææåæ¬ï¼(1) å¥åº· AI ä¸­ä»éº¼æ§æè§£éçå®ç¾©ï¼ä»¥å (2) å¥åº· AI ä¸­ä¸åå¥½è§£éçå±¬æ§æ¸å®ã

##### **Exploring the Effect of Explanation Content and Format on User Comprehension and Trust**
2408.17401v1 by Antonio Rago, Bence Palfi, Purin Sukpanichnant, Hannibal Nabli, Kavyesh Vivek, Olga Kostopoulou, James Kinross, Francesca Toni

In recent years, various methods have been introduced for explaining the
outputs of "black-box" AI models. However, it is not well understood whether
users actually comprehend and trust these explanations. In this paper, we focus
on explanations for a regression tool for assessing cancer risk and examine the
effect of the explanations' content and format on the user-centric metrics of
comprehension and trust. Regarding content, we experiment with two explanation
methods: the popular SHAP, based on game-theoretic notions and thus potentially
complex for everyday users to comprehend, and occlusion-1, based on feature
occlusion which may be more comprehensible. Regarding format, we present SHAP
explanations as charts (SC), as is conventional, and occlusion-1 explanations
as charts (OC) as well as text (OT), to which their simpler nature also lends
itself. The experiments amount to user studies questioning participants, with
two different levels of expertise (the general population and those with some
medical training), on their subjective and objective comprehension of and trust
in explanations for the outputs of the regression tool. In both studies we
found a clear preference in terms of subjective comprehension and trust for
occlusion-1 over SHAP explanations in general, when comparing based on content.
However, direct comparisons of explanations when controlling for format only
revealed evidence for OT over SC explanations in most cases, suggesting that
the dominance of occlusion-1 over SHAP explanations may be driven by a
preference for text over charts as explanations. Finally, we found no evidence
of a difference between the explanation types in terms of objective
comprehension. Thus overall, the choice of the content and format of
explanations needs careful attention, since in some contexts format, rather
than content, may play the critical role in improving user experience.

æè¦ï¼<paragraph>è¿å¹´ä¾ï¼å·²ç¶å¼é²åç¨®æ¹æ³ä¾è§£éãé»ç®±ãAI æ¨¡åçè¼¸åºãç¶èï¼ç®åä¸¦ä¸æ¸æ¥ä½¿ç¨èæ¯å¦å¯¦éçè§£åä¿¡ä»»éäºè§£éãå¨æ¬æä¸­ï¼æåå°æ³¨æ¼è©ä¼°ççé¢¨éªçåæ­¸å·¥å·çè§£éï¼ä¸¦æ¢è¨è§£éçå§å®¹åæ ¼å¼å°ä»¥ä½¿ç¨èçºä¸­å¿ççè§£åä¿¡ä»»ææ¨çå½±é¿ãéæ¼å§å®¹ï¼æåå¯¦é©äºå©ç¨®è§£éæ¹æ³ï¼æµè¡ç SHAPï¼åºæ¼åå¼è«æ¦å¿µï¼å æ­¤å°æ¼æ¥å¸¸ä½¿ç¨èä¾èªªå¯è½å¾è¤éï¼ä»¥ååºæ¼ç¹å¾µé®è½ç occlusion-1ï¼å¯è½æ´ææ¼çè§£ãéæ¼æ ¼å¼ï¼æåå° SHAP è§£éåç¾çºåè¡¨ (SC)ï¼éæ¯æ£ä¾ï¼èå° occlusion-1 è§£éåç¾çºåè¡¨ (OC) ä»¥åæå­ (OT)ï¼å¶è¼çºç°¡å®çæ§è³ªä¹é©ç¨æ¼æ­¤ãéäºå¯¦é©ç­åæ¼ä½¿ç¨èç ç©¶ï¼è©¢ååèèï¼å·æå©ç¨®ä¸åç¨åº¦çå°æ¥­ç¥è­ï¼ä¸è¬æ°ç¾åå·åä¸äºé«å­¸è¨ç·´çäººï¼ï¼ä»åå°åæ­¸å·¥å·è¼¸åºè§£éçä¸»è§åå®¢è§çè§£åä¿¡ä»»ãå¨å©é ç ç©¶ä¸­ï¼æåç¼ç¾ï¼å¨åºæ¼å§å®¹é²è¡æ¯è¼æï¼ä¸è¬ä¾èªªï¼occlusion-1 åªæ¼ SHAP è§£éï¼å¨ä¸»è§çè§£åä¿¡ä»»æ¹é¢ææé¡¯çåå¥½ãç¶èï¼å¨åæ§å¶æ ¼å¼çææ³ä¸ç´æ¥æ¯è¼è§£éï¼å¨å¤§å¤æ¸ææ³ä¸åªé¡¯ç¤º OT åªæ¼ SC è§£éçè­æï¼éè¡¨æ occlusion-1 åªæ¼ SHAP è§£éçä¸»å°å°ä½å¯è½æ¯ç±åå¥½æå­èéåè¡¨ä½çºè§£éæé©åçãæå¾ï¼æåæ²æç¼ç¾è§£éé¡åå¨å®¢è§çè§£æ¹é¢çå·®ç°è­æãå æ­¤ï¼ç¸½é«èè¨ï¼å°è§£éçå§å®¹åæ ¼å¼çé¸æéè¦ä»ç´°æ³¨æï¼å çºå¨æäºææ³ä¸ï¼æ ¼å¼èéå§å®¹ï¼å¯è½å¨æ¹åä½¿ç¨èé«é©æ¹é¢ç¼æ®ééµä½ç¨ã</paragraph>

##### **A Survey for Large Language Models in Biomedicine**
2409.00133v1 by Chong Wang, Mengyao Li, Junjun He, Zhongruo Wang, Erfan Darzi, Zan Chen, Jin Ye, Tianbin Li, Yanzhou Su, Jing Ke, Kaili Qu, Shuxin Li, Yi Yu, Pietro LiÃ², Tianyun Wang, Yu Guang Wang, Yiqing Shen

Recent breakthroughs in large language models (LLMs) offer unprecedented
natural language understanding and generation capabilities. However, existing
surveys on LLMs in biomedicine often focus on specific applications or model
architectures, lacking a comprehensive analysis that integrates the latest
advancements across various biomedical domains. This review, based on an
analysis of 484 publications sourced from databases including PubMed, Web of
Science, and arXiv, provides an in-depth examination of the current landscape,
applications, challenges, and prospects of LLMs in biomedicine, distinguishing
itself by focusing on the practical implications of these models in real-world
biomedical contexts. Firstly, we explore the capabilities of LLMs in zero-shot
learning across a broad spectrum of biomedical tasks, including diagnostic
assistance, drug discovery, and personalized medicine, among others, with
insights drawn from 137 key studies. Then, we discuss adaptation strategies of
LLMs, including fine-tuning methods for both uni-modal and multi-modal LLMs to
enhance their performance in specialized biomedical contexts where zero-shot
fails to achieve, such as medical question answering and efficient processing
of biomedical literature. Finally, we discuss the challenges that LLMs face in
the biomedicine domain including data privacy concerns, limited model
interpretability, issues with dataset quality, and ethics due to the sensitive
nature of biomedical data, the need for highly reliable model outputs, and the
ethical implications of deploying AI in healthcare. To address these
challenges, we also identify future research directions of LLM in biomedicine
including federated learning methods to preserve data privacy and integrating
explainable AI methodologies to enhance the transparency of LLMs.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) çææ°çªç ´æä¾äºåææªæçèªç¶èªè¨çè§£åçæè½åãç¶èï¼ç¾æéæ¼çç©é«å­¸ä¸­ LLM çèª¿æ¥éå¸¸å°æ³¨æ¼ç¹å®æç¨ææ¨¡åæ¶æ§ï¼ç¼ºä¹æ´ååç¨®çç©é«å­¸é åææ°é²å±çå¨é¢åæãæ¬ç¶è¿°åºæ¼å°ä¾èª PubMedãWeb of Science å arXiv ç­æ¸æåº«ç 484 ç¯åºçç©çåæï¼æ·±å¥æ¢è¨äºçç©é«å­¸ä¸­ LLM çç¶åç¾æ³ãæç¨ãææ°ååæ¯ï¼å¶ç¹é»æ¯éæ³¨éäºæ¨¡åå¨ç¾å¯¦ä¸ççç©é«å­¸èæ¯ä¸­çå¯¦éæç¨ãé¦åï¼æåæ¢è¨äº LLM å¨å»£æ³ççç©é«å­¸ä»»åä¸­çé¶æ¬¡å­¸ç¿è½åï¼åæ¬è¨ºæ·è¼å©ãè¥ç©ç¼ç¾ååæ§åé«çç­ï¼ä¸¦å¾ 137 é ééµç ç©¶ä¸­æ±²åè¦è§£ãç¶å¾ï¼æåè¨è«äº LLM çé©æç­ç¥ï¼åæ¬å®æ¨¡æåå¤æ¨¡æ LLM çå¾®èª¿æ¹æ³ï¼ä»¥å¢å¼·å®åå¨é¶æ¬¡å­¸ç¿ç¡æ³å¯¦ç¾çå°æ¥­çç©é«å­¸èæ¯ä¸­çæ§è½ï¼ä¾å¦é«çåé¡è§£ç­åçç©é«å­¸æç»çææèçãæå¾ï¼æåè¨è«äº LLM å¨çç©é«å­¸é åé¢è¨çææ°ï¼åæ¬æ¸æé±ç§åé¡ãæ¨¡åå¯è§£éæ§æéãæ¸æéè³ªéåé¡ä»¥åç±æ¼çç©é«å­¸æ¸æçæææ§ãå°é«åº¦å¯é æ¨¡åè¼¸åºçéæ±ä»¥åå¨é«çä¿å¥ä¸­é¨ç½² AI çå«çå½±é¿èç¢ççå«çåé¡ãçºäºæå°éäºææ°ï¼æåéç¢ºå®äºçç©é«å­¸ä¸­ LLM æªä¾çç ç©¶æ¹åï¼åæ¬ç¨æ¼ä¿è­·æ¸æé±ç§çè¯åå­¸ç¿æ¹æ³ä»¥åæ´åå¯è§£é AI æ¹æ³ä»¥å¢å¼· LLM çéæåº¦ã

##### **Aligning XAI with EU Regulations for Smart Biomedical Devices: A Methodology for Compliance Analysis**
2408.15121v1 by Francesco Sovrano, Michael Lognoul, Giulia Vilone

Significant investment and development have gone into integrating Artificial
Intelligence (AI) in medical and healthcare applications, leading to advanced
control systems in medical technology. However, the opacity of AI systems
raises concerns about essential characteristics needed in such sensitive
applications, like transparency and trustworthiness. Our study addresses these
concerns by investigating a process for selecting the most adequate Explainable
AI (XAI) methods to comply with the explanation requirements of key EU
regulations in the context of smart bioelectronics for medical devices. The
adopted methodology starts with categorising smart devices by their control
mechanisms (open-loop, closed-loop, and semi-closed-loop systems) and delving
into their technology. Then, we analyse these regulations to define their
explainability requirements for the various devices and related goals.
Simultaneously, we classify XAI methods by their explanatory objectives. This
allows for matching legal explainability requirements with XAI explanatory
goals and determining the suitable XAI algorithms for achieving them. Our
findings provide a nuanced understanding of which XAI algorithms align better
with EU regulations for different types of medical devices. We demonstrate this
through practical case studies on different neural implants, from chronic
disease management to advanced prosthetics. This study fills a crucial gap in
aligning XAI applications in bioelectronics with stringent provisions of EU
regulations. It provides a practical framework for developers and researchers,
ensuring their AI innovations advance healthcare technology and adhere to legal
and ethical standards.

æè¦ï¼äººå·¥æºæ§ï¼AIï¼å¨é«çåä¿å¥æç¨ä¸­æå¥äºå¤§éçæè³åéç¼ï¼é²èå°è´é«çæè¡ä¸­çåé²æ§å¶ç³»çµ±ãç¶èï¼AI ç³»çµ±çä¸éææ§å¼ç¼äºå°æ­¤é¡æææç¨ä¸­æéåºæ¬ç¹æ§çææï¼ä¾å¦éæåº¦åå¯ä¿¡åº¦ãæåçç ç©¶ééèª¿æ¥ä¸åç¨åºä¾è§£æ±ºéäºåé¡ï¼ç¨æ¼é¸ææååçå¯è§£é AIï¼XAIï¼æ¹æ³ï¼ä»¥ç¬¦åæ­çæ³è¦å¨é«çå¨æçæºæ§åçç©é»å­å­¸ä¸­çèªªæè¦æ±ãæ¡ç¨çæ¹æ³å¾ééå¶æ§å¶æ©å¶ï¼éè¿´è·¯ãéè¿´è·¯ååéè¿´è·¯ç³»çµ±ï¼å°æºæ§åè£ç½®é²è¡åé¡ï¼ä¸¦æ·±å¥æ¢è¨å¶æè¡éå§ãç¶å¾ï¼æååæéäºæ³è¦ä»¥å®ç¾©å¶å°åç¨®è£ç½®åç¸éç®æ¨çå¯è§£éæ§è¦æ±ãåæï¼æåééå¶èªªæç®æ¨å° XAI æ¹æ³é²è¡åé¡ãéåè¨±å°æ³å¾å¯è§£éæ§è¦æ±è XAI èªªæç®æ¨ç¸å¹éï¼ä¸¦ç¢ºå®é©ç¶ç XAI æ¼ç®æ³ä¾éæå®åãæåçç ç©¶çµææä¾äºå°åªäº XAI æ¼ç®æ³æ´ç¬¦åæ­çæ³è¦ä»¥é©ç¨æ¼ä¸åé¡åçé«çå¨æçç´°ç·»çè§£ãæåééä¸åç¥ç¶æ¤å¥ç©çå¯¦éæ¡ä¾ç ç©¶ä¾è­æéä¸é»ï¼å¾æ¢æ§ç¾çç®¡çå°åé²çç¾©è¢ãéé ç ç©¶å¡«è£äºå°çç©é»å­å­¸ä¸­ç XAI æç¨èæ­çæ³è¦çå´æ ¼è¦å®ç¸ç¬¦çéè¦ç©ºç½ãå®çºéç¼äººå¡åç ç©¶äººå¡æä¾äºä¸åå¯¦ç¨çæ¶æ§ï¼ç¢ºä¿å¶ AI åµæ°è½ä¿é²é«çæè¡ä¸¦éµå®æ³å¾åéå¾·æ¨æºã

##### **Towards Case-based Interpretability for Medical Federated Learning**
2408.13626v1 by Laura Latorre, Liliana Petrychenko, Regina Beets-Tan, Taisiya Kopytova, Wilson Silva

We explore deep generative models to generate case-based explanations in a
medical federated learning setting. Explaining AI model decisions through
case-based interpretability is paramount to increasing trust and allowing
widespread adoption of AI in clinical practice. However, medical AI training
paradigms are shifting towards federated learning settings in order to comply
with data protection regulations. In a federated scenario, past data is
inaccessible to the current user. Thus, we use a deep generative model to
generate synthetic examples that protect privacy and explain decisions. Our
proof-of-concept focuses on pleural effusion diagnosis and uses publicly
available Chest X-ray data.

æè¦ï¼æåæ¢ç´¢æ·±åº¦çææ¨¡åï¼å¨é«çè¯é¦å­¸ç¿è¨­ç½®ä¸­çæåºæ¼æ¡ä¾çèªªæãééåºæ¼æ¡ä¾çå¯è§£éæ§ä¾è§£é AI æ¨¡åæ±ºç­ï¼å°æ¼å¢å ä¿¡ä»»ä¸¦åè¨± AI å¨è¨åºå¯¦åä¸­å»£æ³æ¡ç¨è³ééè¦ãç¶èï¼é«ç AI è¨ç·´ç¯ä¾æ­£è½åè¯é¦å­¸ç¿è¨­ç½®ï¼ä»¥ç¬¦åè³æä¿è­·æ³è¦ãå¨è¯é¦æå¢ä¸­ï¼éå»çè³æå°ç®åçä½¿ç¨èèè¨æ¯ç¡æ³åå¾çãå æ­¤ï¼æåä½¿ç¨æ·±åº¦çææ¨¡åä¾ç¢çä¿è­·é±ç§åè§£éæ±ºç­çåæç¯ä¾ãæåçæ¦å¿µé©è­èéæ¼è¸èç©æ¶²è¨ºæ·ï¼ä¸¦ä½¿ç¨å¬éå¯åå¾çè¸é¨ X åè³æã

##### **AI in radiological imaging of soft-tissue and bone tumours: a systematic review evaluating against CLAIM and FUTURE-AI guidelines**
2408.12491v1 by Douwe J. Spaanderman, Matthew Marzetti, Xinyi Wan, Andrew F. Scarsbrook, Philip Robinson, Edwin H. G. Oei, Jacob J. Visser, Robert Hemke, Kirsten van Langevelde, David F. Hanff, Geert J. L. H. van Leenders, Cornelis Verhoef, Dirk J. GruÃ¼hagen, Wiro J. Niessen, Stefan Klein, Martijn P. A. Starmans

Soft-tissue and bone tumours (STBT) are rare, diagnostically challenging
lesions with variable clinical behaviours and treatment approaches. This
systematic review provides an overview of Artificial Intelligence (AI) methods
using radiological imaging for diagnosis and prognosis of these tumours,
highlighting challenges in clinical translation, and evaluating study alignment
with the Checklist for AI in Medical Imaging (CLAIM) and the FUTURE-AI
international consensus guidelines for trustworthy and deployable AI to promote
the clinical translation of AI methods. The review covered literature from
several bibliographic databases, including papers published before 17/07/2024.
Original research in peer-reviewed journals focused on radiology-based AI for
diagnosing or prognosing primary STBT was included. Exclusion criteria were
animal, cadaveric, or laboratory studies, and non-English papers. Abstracts
were screened by two of three independent reviewers for eligibility. Eligible
papers were assessed against guidelines by one of three independent reviewers.
The search identified 15,015 abstracts, from which 325 articles were included
for evaluation. Most studies performed moderately on CLAIM, averaging a score
of 28.9$\pm$7.5 out of 53, but poorly on FUTURE-AI, averaging 5.1$\pm$2.1 out
of 30. Imaging-AI tools for STBT remain at the proof-of-concept stage,
indicating significant room for improvement. Future efforts by AI developers
should focus on design (e.g. define unmet clinical need, intended clinical
setting and how AI would be integrated in clinical workflow), development (e.g.
build on previous work, explainability), evaluation (e.g. evaluating and
addressing biases, evaluating AI against best practices), and data
reproducibility and availability (making documented code and data publicly
available). Following these recommendations could improve clinical translation
of AI methods.

æè¦ï¼è»çµç¹åéª¨éª¼è«ç¤ï¼STBTï¼æ¯ç½è¦ãè¨ºæ·å·æææ°æ§ççç¶ï¼å¶è¨åºè¡çºåæ²»çæ¹æ³åä¸ç¸åãéç¯ç³»çµ±æ§åé¡§æä¾äºä½¿ç¨æ¾å°å½±åé²è¡è¨ºæ·åé å¾çäººå·¥æºæ§ (AI) æ¹æ³çæ¦è§ï¼éé»èªªæäºè¨åºè½è­¯çææ°ï¼ä¸¦è©ä¼°ç ç©¶èé«çå½±å AI æ ¸æ¥è¡¨ (CLAIM) å FUTURE-AI å¯ä¿¡è³´ä¸å¯é¨ç½² AI çåéå±è­æºåçä¸è´æ§ï¼ä»¥ä¿é² AI æ¹æ³çè¨åºè½è­¯ãéç¯åé¡§æ¶µèäºå¹¾åæ¸ç®è³æåº«ä¸­çæç»ï¼åæ¬å¨ 2024 å¹´ 7 æ 17 æ¥ä¹åç¼è¡¨çè«æãç´å¥äºä»¥æ¾å°çºåºç¤ç AI è¨ºæ·æé å¾åç¼æ§ STBT çåè¡è©å¯©æåä¸­çåå§ç ç©¶ãæé¤æ¨æºæ¯åç©ãå±é«æå¯¦é©å®¤ç ç©¶ï¼ä»¥åéè±æè«æãæè¦ç±ä¸ä½ç¨ç«å¯©æ¥å¡ä¸­çå©ä½ç¯©é¸è³æ ¼ãåæ ¼çè«æç±ä¸ä½ç¨ç«å¯©æ¥å¡ä¸­çä¸ä½æ ¹ææºåé²è¡è©ä¼°ãæç´¢è­å¥åº 15,015 ç¯æè¦ï¼å¶ä¸­ 325 ç¯æç« è¢«ç´å¥è©ä¼°ãå¤§å¤æ¸ç ç©¶å¨ CLAIM ä¸­è¡¨ç¾ä¸­ç­ï¼å¹³åå¾åçº 53 åä¸­ç 28.9Â±7.5 åï¼ä½å¨ FUTURE-AI ä¸­è¡¨ç¾ä¸ä½³ï¼å¹³åå¾åçº 30 åä¸­ç 5.1Â±2.1 åãSTBT çå½±å AI å·¥å·ä»èæ¼æ¦å¿µé©è­éæ®µï¼è¡¨ææé¡¯èçæ¹é²ç©ºéãAI éç¼äººå¡æªä¾çåªåæéä¸­å¨è¨­è¨ï¼ä¾å¦å®ç¾©æªæ»¿è¶³çè¨åºéæ±ãé æçè¨åºç°å¢ä»¥å AI å¦ä½æ´åå°è¨åºå·¥ä½æµç¨ä¸­ï¼ãéç¼ï¼ä¾å¦å»ºç«å¨ååçå·¥ä½ãå¯è§£éæ§ï¼ãè©ä¼°ï¼ä¾å¦è©ä¼°åè§£æ±ºåå·®ãè©ä¼° AI èæä½³å¯¦åï¼ãä»¥åæ¸æå¯è¤è£½æ§åå¯ç¨æ§ï¼å¬éæä¾æä»¶åçä»£ç¢¼åæ¸æï¼ãéµå¾ªéäºå»ºè­°å¯ä»¥æ¹å AI æ¹æ³çè¨åºè½è­¯ã

##### **Evaluating Explainable AI Methods in Deep Learning Models for Early Detection of Cerebral Palsy**
2409.00001v1 by Kimji N. Pellano, Inga StrÃ¼mke, Daniel Groos, Lars Adde, Espen Alexander F. Ihlen

Early detection of Cerebral Palsy (CP) is crucial for effective intervention
and monitoring. This paper tests the reliability and applicability of
Explainable AI (XAI) methods using a deep learning method that predicts CP by
analyzing skeletal data extracted from video recordings of infant movements.
Specifically, we use XAI evaluation metrics -- namely faithfulness and
stability -- to quantitatively assess the reliability of Class Activation
Mapping (CAM) and Gradient-weighted Class Activation Mapping (Grad-CAM) in this
specific medical application. We utilize a unique dataset of infant movements
and apply skeleton data perturbations without distorting the original dynamics
of the infant movements. Our CP prediction model utilizes an ensemble approach,
so we evaluate the XAI metrics performances for both the overall ensemble and
the individual models. Our findings indicate that both XAI methods effectively
identify key body points influencing CP predictions and that the explanations
are robust against minor data perturbations. Grad-CAM significantly outperforms
CAM in the RISv metric, which measures stability in terms of velocity. In
contrast, CAM performs better in the RISb metric, which relates to bone
stability, and the RRS metric, which assesses internal representation
robustness. Individual models within the ensemble show varied results, and
neither CAM nor Grad-CAM consistently outperform the other, with the ensemble
approach providing a representation of outcomes from its constituent models.

æè¦ï¼è¦æ§éº»çº (CP) çæ©æåµæ¸¬å°æ¼ææçä»å¥åç£æ¸¬è³ééè¦ãæ¬ææ¸¬è©¦äºå¯è§£é AI (XAI) æ¹æ³çå¯é æ§åé©ç¨æ§ï¼ä½¿ç¨æ·±åº¦å­¸ç¿æ¹æ³ï¼ééåæå¾å¬°ååä½å½±çè¨éä¸­æåçéª¨éª¼è³æä¾é æ¸¬ CPãå·é«ä¾èªªï¼æåä½¿ç¨ XAI è©ä¼°ææ¨ï¼å³å¿ å¯¦åº¦åç©©å®æ§ï¼ä¾éåè©ä¼°é¡å¥æ¿æ´»æ å° (CAM) åæ¢¯åº¦å æ¬é¡å¥æ¿æ´»æ å° (Grad-CAM) å¨éåç¹å®é«çæç¨ä¸­çå¯é æ§ãæåå©ç¨ä¸åç¨ç¹çå¬°ååä½è³æéï¼ä¸¦æç¨éª¨éª¼è³ææ¾åï¼èä¸ææ­æ²å¬°ååä½çåå§ååãæåç CP é æ¸¬æ¨¡åå©ç¨æ´é«æ¹æ³ï¼å æ­¤æåè©ä¼°äºæ´é«æ´é«ååå¥æ¨¡åç XAI ææ¨è¡¨ç¾ãæåçç ç©¶çµæè¡¨æï¼å©ç¨® XAI æ¹æ³é½è½ææè­å¥å½±é¿ CP é æ¸¬çééµèº«é«é¨ä½ï¼ä¸¦ä¸éäºè§£éå°æ¼å¾®å°çè³ææ¾åå·æé­¯æ£æ§ãGrad-CAM å¨ RISv ææ¨ä¸­é¡¯èåªæ¼ CAMï¼è©²ææ¨è¡¡ééåº¦æ¹é¢çç©©å®æ§ãç¸æ¯ä¹ä¸ï¼CAM å¨ RISb ææ¨ä¸­è¡¨ç¾å¾æ´å¥½ï¼è©²ææ¨èéª¨éª¼ç©©å®æ§æéï¼è RRS ææ¨åè©ä¼°å§é¨è¡¨ç¤ºçé­¯æ£æ§ãæ´é«ä¸­çåå¥æ¨¡åé¡¯ç¤ºåºä¸åççµæï¼CAM å Grad-CAM é½ä¸ä¸è´å°åªæ¼å¦ä¸ç¨®ï¼æ´é«æ¹æ³æä¾äºå¶çµææ¨¡åçµæçè¡¨ç¤ºã

##### **MicroXercise: A Micro-Level Comparative and Explainable System for Remote Physical Therapy**
2408.11837v1 by Hanchen David Wang, Nibraas Khan, Anna Chen, Nilanjan Sarkar, Pamela Wisniewski, Meiyi Ma

Recent global estimates suggest that as many as 2.41 billion individuals have
health conditions that would benefit from rehabilitation services. Home-based
Physical Therapy (PT) faces significant challenges in providing interactive
feedback and meaningful observation for therapists and patients. To fill this
gap, we present MicroXercise, which integrates micro-motion analysis with
wearable sensors, providing therapists and patients with a comprehensive
feedback interface, including video, text, and scores. Crucially, it employs
multi-dimensional Dynamic Time Warping (DTW) and attribution-based explainable
methods to analyze the existing deep learning neural networks in monitoring
exercises, focusing on a high granularity of exercise. This synergistic
approach is pivotal, providing output matching the input size to precisely
highlight critical subtleties and movements in PT, thus transforming complex AI
analysis into clear, actionable feedback. By highlighting these micro-motions
in different metrics, such as stability and range of motion, MicroXercise
significantly enhances the understanding and relevance of feedback for
end-users. Comparative performance metrics underscore its effectiveness over
traditional methods, such as a 39% and 42% improvement in Feature Mutual
Information (FMI) and Continuity. MicroXercise is a step ahead in home-based
physical therapy, providing a technologically advanced and intuitively helpful
solution to enhance patient care and outcomes.

æè¦ï¼æè¿çå¨çä¼°è¨è¡¨æï¼å¤é 24.1 åäººæ
å¥åº·çæ³å¯å¾å¾©å¥æåä¸­åçãå±å®¶
ç©çæ²»ç (PT) å¨æä¾äºåå¼
åé¥åææç¾©çè§å¯æ¹é¢é¢è¨éå¤§ææ°ï¼ä¾æ²»çå¸«åæ£èä½¿ç¨ãçºäºå¡«è£é
åç¼ºå£ï¼æåæåº MicroXerciseï¼å®å°å¾®åä½åæè
å¯ç©¿æ´å¼ææ¸¬å¨æ´åå¨ä¸èµ·ï¼çºæ²»çå¸«åæ£èæä¾ä¸åå¨é¢ç
åé¥ä»é¢ï¼åæ¬å½±çãæå­ååæ¸ãè³ééè¦çæ¯ï¼å®æ¡ç¨
å¤ç¶­åææéè¦æ´ (DTW) ååºæ¼æ­¸å çå¯è§£é
æ¹æ³ä¾åæç£æ§éåä¸­ç¾æçæ·±åº¦å­¸ç¿ç¥ç¶ç¶²è·¯ï¼å°æ³¨æ¼éåçé«ç²åº¦ãéç¨®åå
æ¹æ³è³ééè¦ï¼æä¾èè¼¸å¥å¤§å°å¹éçè¼¸åºï¼ä»¥ç²¾ç¢ºå°
çªåº PT ä¸­ééµçç´°å¾®å·®å¥ååä½ï¼å¾èå°è¤éç AI
åæè½æçºæ¸æ°ãå¯æä½çåé¥ãééå¨ä¸åææ¨ä¸­çªé¡¯éäºå¾®åä½ï¼ä¾å¦ç©©å®æ§ååä½ç¯åï¼MicroXercise
é¡¯èæåæçµä½¿ç¨èå°åé¥ççè§£åç¸éæ§ãæ¯è¼æè½ææ¨å¼·èª¿å¶åªæ¼
å³çµ±æ¹æ³çæææ§ï¼ä¾å¦ç¹å¾µäºæ è³è¨ (FMI) åé£çºæ§åå¥æåäº 39% å 42%ãMicroXercise å¨å±å®¶
ç©çæ²»çæ¹é¢æ´é²ä¸æ­¥ï¼æä¾æè¡åé²ä¸ç´è¦ºæç¨ç
è§£æ±ºæ¹æ¡ï¼ä»¥æåæ£èç§è­·åçµæã

##### **The Literature Review Network: An Explainable Artificial Intelligence for Systematic Literature Reviews, Meta-analyses, and Method Development**
2408.05239v1 by Joshua Morriss, Tod Brindle, Jessica Bah RÃ¶sman, Daniel Reibsamen, Andreas Enz

Systematic literature reviews are the highest quality of evidence in
research. However, the review process is hindered by significant resource and
data constraints. The Literature Review Network (LRN) is the first of its kind
explainable AI platform adhering to PRISMA 2020 standards, designed to automate
the entire literature review process. LRN was evaluated in the domain of
surgical glove practices using 3 search strings developed by experts to query
PubMed. A non-expert trained all LRN models. Performance was benchmarked
against an expert manual review. Explainability and performance metrics
assessed LRN's ability to replicate the experts' review. Concordance was
measured with the Jaccard index and confusion matrices. Researchers were
blinded to the other's results until study completion. Overlapping studies were
integrated into an LRN-generated systematic review. LRN models demonstrated
superior classification accuracy without expert training, achieving 84.78% and
85.71% accuracy. The highest performance model achieved high interrater
reliability (k = 0.4953) and explainability metrics, linking 'reduce',
'accident', and 'sharp' with 'double-gloving'. Another LRN model covered 91.51%
of the relevant literature despite diverging from the non-expert's judgments (k
= 0.2174), with the terms 'latex', 'double' (gloves), and 'indication'. LRN
outperformed the manual review (19,920 minutes over 11 months), reducing the
entire process to 288.6 minutes over 5 days. This study demonstrates that
explainable AI does not require expert training to successfully conduct
PRISMA-compliant systematic literature reviews like an expert. LRN summarized
the results of surgical glove studies and identified themes that were nearly
identical to the clinical researchers' findings. Explainable AI can accurately
expedite our understanding of clinical practices, potentially revolutionizing
healthcare research.

æè¦ï¼ç³»çµ±æ§æç»åé¡§æ¯ç ç©¶ä¸­è­æåè³ªæé«çãç¶èï¼åé¡§éç¨åå°é¡¯èè³æºåè³æéå¶çé»ç¤ãæç»åé¡§ç¶²è·¯ (LRN) æ¯ç¬¬ä¸åéµå¾ª PRISMA 2020 æ¨æºçå¯è§£é AI å¹³å°ï¼æ¨å¨èªååæ´åæç»åé¡§éç¨ãLRN å¨å¤ç§æå¥å¯¦åé åä¸­é²è¡è©ä¼°ï¼ä½¿ç¨å°å®¶éç¼ç 3 åæå°å­ä¸²ä¾æ¥è©¢ PubMedãéå°å®¶è¨ç·´ææ LRN æ¨¡åãæè½ä»¥å°å®¶æååé¡§ä½çºåºæºãå¯è§£éæ§åæè½ææ¨è©ä¼° LRN è¤è£½å°å®¶åé¡§çè½åãä¸è´æ§ä»¥ Jaccard ææ¸åæ··æ·ç©é£æ¸¬éãç ç©¶äººå¡å¨ç ç©¶å®æåå°å½¼æ­¤ççµæä¿å¯ãéççç ç©¶æ´åå° LRN çæçç³»çµ±æ§åé¡§ä¸­ãLRN æ¨¡åå¨æ²æå°å®¶è¨ç·´çææ³ä¸å±ç¾åºåªç°çåé¡æºç¢ºçï¼éå° 84.78% å 85.71% çæºç¢ºçãæè½æé«çæ¨¡åéå°äºé«è©åèéä¿¡è³´åº¦ (k = 0.4953) åå¯è§£éæ§ææ¨ï¼å°ãæ¸å°ãããæå¤ãåãé³å©ãèãééæ´æå¥ãé£çµå¨ä¸èµ·ãå¦ä¸å LRN æ¨¡åæ¶µèäº 91.51% çç¸éæç»ï¼åç®¡èéå°å®¶çå¤æ·ä¸å (k = 0.2174)ï¼ä½åå«äºãä¹³è ãããééãï¼æå¥ï¼åãé©æçãç­è©å½ãLRN åªæ¼æååé¡§ï¼11 åæè¶é 19,920 åéï¼ï¼å°æ´åéç¨ç¸®ç­çº 5 å¤©è¶é 288.6 åéãéé ç ç©¶é¡¯ç¤ºï¼å¯è§£éç AI ä¸éè¦å°å®¶è¨ç·´å³å¯æåé²è¡å°å®¶ç­ç´ç PRISMA ç¸å®¹ç³»çµ±æ§æç»åé¡§ãLRN ç¸½çµäºå¤ç§æå¥ç ç©¶ççµæï¼ä¸¦æ¾åºèè¨åºç ç©¶äººå¡ç¼ç¾å¹¾ä¹ç¸åçä¸»é¢ãå¯è§£éç AI å¯ä»¥æºç¢ºå°å å¿«æåå°è¨åºå¯¦åççè§£ï¼ææ½åé©æ°é«çä¿å¥ç ç©¶ã

##### **Enhancing Medical Learning and Reasoning Systems: A Boxology-Based Comparative Analysis of Design Patterns**
2408.02709v1 by Chi Him Ng

This study analyzes hybrid AI systems' design patterns and their
effectiveness in clinical decision-making using the boxology framework. It
categorizes and copares various architectures combining machine learning and
rule-based reasoning to provide insights into their structural foundations and
healthcare applications. Addressing two main questions, how to categorize these
systems againts established design patterns and how to extract insights through
comparative analysis, the study uses design patterns from software engineering
to understand and optimize healthcare AI systems. Boxology helps identify
commonalities and create reusable solutions, enhancing these systems'
scalability, reliability, and performance. Five primary architectures are
examined: REML, MLRB, RBML, RMLT, and PERML. Each has unique strengths and
weaknesses, highlighting the need for tailored approaches in clinical tasks.
REML excels in high-accuracy prediction for datasets with limited data; MLRB in
handling large datasets and complex data integration; RBML in explainability
and trustworthiness; RMLT in managing high-dimensional data; and PERML, though
limited in analysis, shows promise in urgent care scenarios. The study
introduces four new patterns, creates five abstract categorization patterns,
and refines those five further to specific systems. These contributions enhance
Boxlogy's taxonomical organization and offer novel approaches to integrating
expert knowledge with machine learning. Boxology's structured, modular apporach
offers significant advantages in developing and analyzing hybrid AI systems,
revealing commonalities, and promoting reusable solutions. In conclusion, this
study underscores hybrid AI systems' crucial role in advancing healthcare and
Boxology's potential to drive further innovation in AI integration, ultimately
improving clinical decision support and patient outcomes.

æè¦ï¼æ¬ç ç©¶ä½¿ç¨çå­å­¸æ¡æ¶åææ··åäººå·¥æºæ§ç³»çµ±çè¨­è¨æ¨¡å¼åå¶å¨è¨åºæ±ºç­ä¸­çæææ§ãå®åé¡ä¸¦æ¯è¼çµåæ©å¨å­¸ç¿ååºæ¼è¦åçæ¨ççåç¨®æ¶æ§ï¼ä»¥æ·±å¥äºè§£å¶çµæ§åºç¤åé«çä¿å¥æç¨ãéå°å©åä¸»è¦åé¡ï¼å¦ä½æ ¹ææ¢å®çè¨­è¨æ¨¡å¼å°éäºç³»çµ±é²è¡åé¡ï¼ä»¥åå¦ä½ééæ¯è¼åææåè¦è§£ï¼æ¬ç ç©¶ä½¿ç¨è»é«å·¥ç¨ä¸­çè¨­è¨æ¨¡å¼ä¾äºè§£ååªåé«çä¿å¥äººå·¥æºæ§ç³»çµ±ãçå­å­¸æå©æ¼è­å¥å±æ§ä¸¦å»ºç«å¯éè¤ä½¿ç¨çè§£æ±ºæ¹æ¡ï¼å¾èå¢å¼·éäºç³»çµ±çå¯æ´åæ§ãå¯é æ§åæè½ãæª¢æ¥äºäºç¨®ä¸»è¦çæ¶æ§ï¼REMLãMLRBãRBMLãRMLT å PERMLãæ¯ç¨®æ¶æ§é½æç¨ç¹çåªç¼ºé»ï¼å¼·èª¿äºå¨è¨åºä»»åä¸­éè¦éèº«æé çæ¹æ³ãREML å¨è³ææéçè³æéä¸­è¡¨ç¾åºé«ç²¾åº¦çé æ¸¬ï¼MLRB å¨èçå¤§åè³æéåè¤éè³ææ´åæ¹é¢è¡¨ç¾åºè²ï¼RBML å¨å¯è§£éæ§åå¯ä¿¡åº¦æ¹é¢è¡¨ç¾åºè²ï¼RMLT å¨ç®¡çé«ç¶­è³ææ¹é¢è¡¨ç¾åºè²ï¼è PERML åç®¡å¨åææ¹é¢æéï¼ä½å¨ç·æ¥ç§è­·å ´æ¯ä¸­è¡¨ç¾åºæ½åãæ¬ç ç©¶å¼å¥äºåç¨®æ°æ¨¡å¼ï¼å»ºç«äºäºç¨®æ½è±¡åé¡æ¨¡å¼ï¼ä¸¦é²ä¸æ­¥å°éäºç¨®æ¨¡å¼ç´°åçºå·é«çç³»çµ±ãéäºè²¢ç»å¢å¼·äºçå­å­¸çåé¡çµç¹ï¼ä¸¦æä¾äºå°å°å®¶ç¥è­èæ©å¨å­¸ç¿æ´åçæ°æ¹æ³ãçå­å­¸ççµæ§åãæ¨¡çµåæ¹æ³å¨éç¼ååææ··åäººå·¥æºæ§ç³»çµ±ãæ­ç¤ºå±æ§ä»¥åæ¨å»£å¯éè¤ä½¿ç¨çè§£æ±ºæ¹æ¡æ¹é¢å·æé¡¯èåªå¢ãç¸½ä¹ï¼æ¬ç ç©¶å¼·èª¿äºæ··åäººå·¥æºæ§ç³»çµ±å¨æ¨é²é«çä¿å¥ä¸­çééµä½ç¨ï¼ä»¥åçå­å­¸å¨æ¨åäººå·¥æºæ§æ´åé²ä¸æ­¥åµæ°æ¹é¢çæ½åï¼æçµæ¹åè¨åºæ±ºç­æ¯æ´åæ£èçæ²»çææã

##### **Bayesian Kolmogorov Arnold Networks (Bayesian_KANs): A Probabilistic Approach to Enhance Accuracy and Interpretability**
2408.02706v1 by Masoud Muhammed Hassan

Because of its strong predictive skills, deep learning has emerged as an
essential tool in many industries, including healthcare. Traditional deep
learning models, on the other hand, frequently lack interpretability and omit
to take prediction uncertainty into account two crucial components of clinical
decision making. In order to produce explainable and uncertainty aware
predictions, this study presents a novel framework called Bayesian Kolmogorov
Arnold Networks (BKANs), which combines the expressive capacity of Kolmogorov
Arnold Networks with Bayesian inference. We employ BKANs on two medical
datasets, which are widely used benchmarks for assessing machine learning
models in medical diagnostics: the Pima Indians Diabetes dataset and the
Cleveland Heart Disease dataset. Our method provides useful insights into
prediction confidence and decision boundaries and outperforms traditional deep
learning models in terms of prediction accuracy. Moreover, BKANs' capacity to
represent aleatoric and epistemic uncertainty guarantees doctors receive more
solid and trustworthy decision support. Our Bayesian strategy improves the
interpretability of the model and considerably minimises overfitting, which is
important for tiny and imbalanced medical datasets, according to experimental
results. We present possible expansions to further use BKANs in more
complicated multimodal datasets and address the significance of these
discoveries for future research in building reliable AI systems for healthcare.
This work paves the way for a new paradigm in deep learning model deployment in
vital sectors where transparency and reliability are crucial.

æè¦ï¼ç±æ¼å¶å¼·å¤§çé æ¸¬è½åï¼æ·±åº¦å­¸ç¿å·²æçºè¨±å¤ç¢æ¥­ä¸­ä¸å¯æç¼ºçå·¥å·ï¼åæ¬é«çä¿å¥ãç¶èï¼å³çµ±çæ·±åº¦å­¸ç¿æ¨¡åéå¸¸ç¼ºä¹å¯è§£éæ§ï¼ä¸¦ä¸å¿½ç¥äºå°é æ¸¬ä¸ç¢ºå®æ§ç´å¥èéï¼èéå©åå ç´ æ¯è¨åºæ±ºç­å¶å®çééµçµæé¨åãçºäºç¢çå¯è§£éä¸å·æä¸ç¢ºå®æ§æè­çé æ¸¬ï¼æ¬ç ç©¶æåºäºä¸ååçºè²æ°æ¯ç¾è«å¥æ´å¤«é¿è«¾å¾·ç¶²è·¯ (BKAN) çæ°æ¶æ§ï¼å®çµåäºæ¯ç¾è«å¥æ´å¤«é¿è«¾å¾·ç¶²è·¯çè¡¨éè½åèè²æ°æ¨è«ãæåå¨å©åé«å­¸è³æéä¸ä½¿ç¨ BKANï¼éäºè³æéæ¯è©ä¼°æ©å¨å­¸ç¿æ¨¡åå¨é«å­¸è¨ºæ·ä¸­çå»£æ³ä½¿ç¨åºæºï¼ç®é¦¬å°ç¬¬å®äººç³å°¿çè³æéååéå¤«è­å¿èçè³æéãæåçæ¨¡åæä¾äºå°é æ¸¬ä¿¡å¿åæ±ºç­éççæçè¦è§£ï¼ä¸¦ä¸å¨é æ¸¬æºç¢ºåº¦æ¹é¢åªæ¼å³çµ±çæ·±åº¦å­¸ç¿æ¨¡åãæ­¤å¤ï¼BKAN è¡¨ç¾é¨æ©åèªè­ä¸ç¢ºå®æ§çè½åï¼å¯ç¢ºä¿é«çç²å¾æ´å¯é ä¸å¼å¾ä¿¡è³´çæ±ºç­æ¯æ´ãæ ¹æå¯¦é©çµæï¼æåçè²æ°ç­ç¥æé«äºæ¨¡åçå¯è§£éæ§ï¼ä¸¦å¤§å¹æ¸å°äºéåº¦æ¬åï¼éå°æ¼å°åä¸ä¸å¹³è¡¡çé«å­¸è³æééå¸¸éè¦ãæåæåºäºå¯è½çæ´ååè½ï¼ä»¥é²ä¸æ­¥å° BKAN ç¨æ¼æ´è¤éçå¤æ¨¡å¼è³æéï¼ä¸¦æ¢è¨éäºç¼ç¾å°æ¼æªä¾å»ºç«å¯é çé«çä¿å¥ AI ç³»çµ±ç ç©¶çéè¦æ§ãéé å·¥ä½çºæ·±åº¦å­¸ç¿æ¨¡åé¨ç½²å¨éæåº¦åå¯é æ§è³ééè¦çéè¦é åä¸­éåäºä¸åæ°çå¸ç¯ã

##### **MLtoGAI: Semantic Web based with Machine Learning for Enhanced Disease Prediction and Personalized Recommendations using Generative AI**
2407.20284v1 by Shyam Dongre, Ritesh Chandra, Sonali Agarwal

In modern healthcare, addressing the complexities of accurate disease
prediction and personalized recommendations is both crucial and challenging.
This research introduces MLtoGAI, which integrates Semantic Web technology with
Machine Learning (ML) to enhance disease prediction and offer user-friendly
explanations through ChatGPT. The system comprises three key components: a
reusable disease ontology that incorporates detailed knowledge about various
diseases, a diagnostic classification model that uses patient symptoms to
detect specific diseases accurately, and the integration of Semantic Web Rule
Language (SWRL) with ontology and ChatGPT to generate clear, personalized
health advice. This approach significantly improves prediction accuracy and
ensures results that are easy to understand, addressing the complexity of
diseases and diverse symptoms. The MLtoGAI system demonstrates substantial
advancements in accuracy and user satisfaction, contributing to developing more
intelligent and accessible healthcare solutions. This innovative approach
combines the strengths of ML algorithms with the ability to provide
transparent, human-understandable explanations through ChatGPT, achieving
significant improvements in prediction accuracy and user comprehension. By
leveraging semantic technology and explainable AI, the system enhances the
accuracy of disease prediction and ensures that the recommendations are
relevant and easily understood by individual patients. Our research highlights
the potential of integrating advanced technologies to overcome existing
challenges in medical diagnostics, paving the way for future developments in
intelligent healthcare systems. Additionally, the system is validated using 200
synthetic patient data records, ensuring robust performance and reliability.

æè¦ï¼å¨ç¾ä»£é«çä¿å¥ä¸­ï¼è§£æ±ºæºç¢ºç¾çé æ¸¬ååæ§åå»ºè­°çè¤éæ§æ¢è³ééè¦åå·æææ°æ§ãæ¬ç ç©¶å¼å¥äº MLtoGAIï¼å®å°èªç¾©ç¶²è·¯æè¡èæ©å¨å­¸ç¿ (ML) ç¸çµåï¼ä»¥å¢å¼·ç¾çé æ¸¬ä¸¦éé ChatGPT æä¾ä½¿ç¨èååçèªªæãè©²ç³»çµ±åå«ä¸åééµçµæé¨åï¼ä¸åå¯éè¤ä½¿ç¨çç¾çæ¬ä½ï¼å¶ä¸­åå«æéåç¨®ç¾ççè©³ç´°ç¥è­ï¼ä¸åè¨ºæ·åé¡æ¨¡åï¼å®ä½¿ç¨æ£èççä¾æºç¢ºæª¢æ¸¬ç¹å®ç¾çï¼ä»¥åèªç¾©ç¶²è·¯è¦åèªè¨ (SWRL) èæ¬ä½å ChatGPT çæ´åï¼ä»¥ç¢çæ¸æ°ãåæ§åçå¥åº·å»ºè­°ãéç¨®æ¹æ³é¡¯èæé«äºé æ¸¬æºç¢ºæ§ï¼ä¸¦ç¢ºä¿äºææ¼çè§£ççµæï¼è§£æ±ºäºç¾çåä¸åçççè¤éæ§ãMLtoGAI ç³»çµ±å±ç¤ºäºæºç¢ºæ§åä½¿ç¨èæ»¿æåº¦çå¯¦è³ªæ§é²æ­¥ï¼æå©æ¼éç¼æ´æºæ§ä¸æ´ææ¼åå¾çé«çä¿å¥è§£æ±ºæ¹æ¡ãéç¨®åµæ°çæ¹æ³çµåäº ML æ¼ç®æ³çåªé»ï¼ä»¥åéé ChatGPT æä¾éæä¸äººé¡å¯ä»¥çè§£çèªªæçè½åï¼å¨é æ¸¬æºç¢ºæ§åä½¿ç¨èçè§£æ¹é¢åå¾äºé¡¯èçé²æ­¥ãééå©ç¨èªç¾©æè¡åå¯è§£éç AIï¼è©²ç³»çµ±æé«äºç¾çé æ¸¬çæºç¢ºæ§ï¼ä¸¦ç¢ºä¿äºå»ºè­°èåå¥æ£èç¸éä¸ææ¼çè§£ãæåçç ç©¶å¼·èª¿äºæ´ååé²æè¡ä»¥åæé«çè¨ºæ·ä¸­ç¾æææ°çæ½åï¼çºæºæ§é«çä¿å¥ç³»çµ±çæªä¾ç¼å±éªè·¯ãæ­¤å¤ï¼è©²ç³»çµ±ä½¿ç¨ 200 ååææ£èè³æè¨éé²è¡é©è­ï¼ç¢ºä¿äºç©©å¥çæè½åå¯é æ§ã

##### **Introducing Î´-XAI: a novel sensitivity-based method for local AI explanations**
2407.18343v2 by Alessandro De Carlo, Enea Parimbelli, Nicola Melillo, Giovanna Nicora

Explainable Artificial Intelligence (XAI) is central to the debate on
integrating Artificial Intelligence (AI) and Machine Learning (ML) algorithms
into clinical practice. High-performing AI/ML models, such as ensemble learners
and deep neural networks, often lack interpretability, hampering clinicians'
trust in their predictions. To address this, XAI techniques are being developed
to describe AI/ML predictions in human-understandable terms. One promising
direction is the adaptation of sensitivity analysis (SA) and global sensitivity
analysis (GSA), which inherently rank model inputs by their impact on
predictions. Here, we introduce a novel delta-XAI method that provides local
explanations of ML model predictions by extending the delta index, a GSA
metric. The delta-XAI index assesses the impact of each feature's value on the
predicted output for individual instances in both regression and classification
problems. We formalize the delta-XAI index and provide code for its
implementation. The delta-XAI method was evaluated on simulated scenarios using
linear regression models, with Shapley values serving as a benchmark. Results
showed that the delta-XAI index is generally consistent with Shapley values,
with notable discrepancies in models with highly impactful or extreme feature
values. The delta-XAI index demonstrated higher sensitivity in detecting
dominant features and handling extreme feature values. Qualitatively, the
delta-XAI provides intuitive explanations by leveraging probability density
functions, making feature rankings clearer and more explainable for
practitioners. Overall, the delta-XAI method appears promising for robustly
obtaining local explanations of ML model predictions. Further investigations in
real-world clinical settings will be conducted to evaluate its impact on
AI-assisted clinical workflows.

æè¦ï¼å¯è§£éäººå·¥æºæ§ (XAI) æ¯å°äººå·¥æºæ§ (AI) åæ©å¨å­¸ç¿ (ML) æ¼ç®æ³æ´åå°è¨åºå¯¦åä¸­çè¾¯è«æ ¸å¿ãé«å·è¡æè½ç AI/ML æ¨¡åï¼ä¾å¦æ´é«å­¸ç¿å¨åæ·±åº¦ç¥ç¶ç¶²è·¯ï¼éå¸¸ç¼ºä¹å¯è§£éæ§ï¼é»ç¤è¨åºé«çå°å¶é æ¸¬çä¿¡ä»»ãçºäºè§£æ±ºéååé¡ï¼æ­£å¨éç¼ XAI æè¡ï¼ä»¥äººé¡å¯ä»¥çè§£çè¡èªæè¿° AI/ML é æ¸¬ãä¸åæå¸æçæ¹åæ¯æ¡ç¨ææåº¦åæ (SA) åå¨çææåº¦åæ (GSA)ï¼å®åæ¬è³ªä¸æä¾ææ¨¡åè¼¸å¥å°é æ¸¬çå½±é¿ä¾å°å¶é²è¡æåãå¨æ­¤ï¼æåä»ç´¹ä¸ç¨®æ°ç delta-XAI æ¹æ³ï¼ééæ´å GSA ææ¨ delta ææ¸ä¾æä¾ ML æ¨¡åé æ¸¬çå±é¨è§£éãdelta-XAI ææ¸è©ä¼°æ¯åç¹å¾µå¼å°åæ­¸ååé¡åé¡ä¸­åå¥ä¾é çé æ¸¬è¼¸åºä¹å½±é¿ãæåå° delta-XAI ææ¸å½¢å¼åï¼ä¸¦æä¾å¶å¯¦ä½çç¨å¼ç¢¼ãä½¿ç¨ç·æ§åæ­¸æ¨¡åå°æ¨¡æ¬æå¢è©ä¼° delta-XAI æ¹æ³ï¼ä¸¦ä»¥ Shapley å¼ä½çºåºæºãçµæé¡¯ç¤º delta-XAI ææ¸éå¸¸è Shapley å¼ä¸è´ï¼ä½å¨å·æé«åº¦å½±é¿åææ¥µç«¯ç¹å¾µå¼çæ¨¡åä¸­å­å¨é¡¯èå·®ç°ãdelta-XAI ææ¸å¨åµæ¸¬ä¸»è¦ç¹å¾µåèçæ¥µç«¯ç¹å¾µå¼æ¹é¢è¡¨ç¾åºæ´é«çææåº¦ãå®æ§å°ä¾èªªï¼delta-XAI ééå©ç¨æ©çå¯åº¦å½æ¸æä¾ç´è§çè§£éï¼ä½¿ç¹å¾µæåæ´æ¸æ°ä¸å°å¾æ¥­äººå¡ä¾èªªæ´å·å¯è§£éæ§ãç¸½é«èè¨ï¼delta-XAI æ¹æ³å°æ¼ç©©å¥å°åå¾ ML æ¨¡åé æ¸¬çå±é¨è§£éä¼¼ä¹å¾æå¸æãå°å¨çå¯¦ä¸ççè¨åºç°å¢ä¸­é²è¡é²ä¸æ­¥èª¿æ¥ï¼ä»¥è©ä¼°å¶å° AI è¼å©è¨åºå·¥ä½æµç¨çå½±é¿ã

##### **Enhanced Deep Learning Methodologies and MRI Selection Techniques for Dementia Diagnosis in the Elderly Population**
2407.17324v2 by Nikolaos Ntampakis, Konstantinos Diamantaras, Ioanna Chouvarda, Vasileios Argyriou, Panagiotis Sarigianndis

Dementia, a debilitating neurological condition affecting millions worldwide,
presents significant diagnostic challenges. In this work, we introduce a novel
methodology for the classification of demented and non-demented elderly
patients using 3D brain Magnetic Resonance Imaging (MRI) scans. Our approach
features a unique technique for selectively processing MRI slices, focusing on
the most relevant brain regions and excluding less informative sections. This
methodology is complemented by a confidence-based classification committee
composed of three custom deep learning models: Dem3D ResNet, Dem3D CNN, and
Dem3D EfficientNet. These models work synergistically to enhance
decision-making accuracy, leveraging their collective strengths. Tested on the
Open Access Series of Imaging Studies(OASIS) dataset, our method achieved an
impressive accuracy of 94.12%, surpassing existing methodologies. Furthermore,
validation on the Alzheimer's Disease Neuroimaging Initiative (ADNI) dataset
confirmed the robustness and generalizability of our approach. The use of
explainable AI (XAI) techniques and comprehensive ablation studies further
substantiate the effectiveness of our techniques, providing insights into the
decision-making process and the importance of our methodology. This research
offers a significant advancement in dementia diagnosis, providing a highly
accurate and efficient tool for clinical applications.

æè¦ï¼å¤±æºçæ¯ä¸ç¨®å½±é¿å¨çæ¸ç¾è¬äººçè¡°å¼±æ§ç¥ç¶ç¾çï¼å¨è¨ºæ·ä¸å·æéå¤§ææ°ãå¨éé å·¥ä½ä¸­ï¼æåæåºäºä¸ç¨®æ°çæ¹æ³ï¼ç¨æ¼å°å¤±æºåéå¤±æºèå¹´æ£èé²è¡åé¡ï¼ä½¿ç¨ 3D å¤§è¦ç£æ¯é å½± (MRI) ææãæåçåæ³æ¡ç¨äºä¸ç¨®ç¨ç¹æè¡ï¼ç¨æ¼é¸ææ§èç MRI åçï¼éé»éæ³¨æç¸éçå¤§è¦ååï¼ä¸¦æé¤ä¿¡æ¯éè¼å°çé¨åãéç¨®æ¹æ³ç±ä¸ååºæ¼ä¿¡å¿çåé¡å§å¡æè£åï¼è©²å§å¡æç±ä¸åèªå®ç¾©æ·±åº¦å­¸ç¿æ¨¡åçµæï¼Dem3D ResNetãDem3D CNN å Dem3D EfficientNetãéäºæ¨¡åååå·¥ä½ä»¥å¢å¼·æ±ºç­çæºç¢ºæ§ï¼å©ç¨å®åçéé«åªå¢ãå¨å½±åç ç©¶éæ¾å­åç³»å (OASIS) è³æéä¸é²è¡æ¸¬è©¦ï¼æåçæ¨¡åéå°äº 94.12% çé©äººæºç¢ºåº¦ï¼è¶éäºç¾ææ¹æ³ãæ­¤å¤ï¼å¨é¿è²æµ·é»çç¥ç¶å½±åå¡è­° (ADNI) è³æéä¸çé©è­è­å¯¦äºæåæ¹æ³çç©©å¥æ§åæ®éæ§ãå¯è§£é AI (XAI) æè¡åå¨é¢çæ¶èç ç©¶é²ä¸æ­¥è­å¯¦äºæåæè¡çæææ§ï¼æä¾äºå°æ±ºç­éç¨åæåæ¹æ³éè¦æ§çè¦è§£ãéé ç ç©¶çºå¤±æºçè¨ºæ·æä¾äºéå¤§é²å±ï¼çºè¨åºæç¨æä¾äºä¸åé«åº¦æºç¢ºä¸é«æçå·¥å·ã

##### **Using Large Language Models to Compare Explainable Models for Smart Home Human Activity Recognition**
2408.06352v1 by Michele Fiori, Gabriele Civitarese, Claudio Bettini

Recognizing daily activities with unobtrusive sensors in smart environments
enables various healthcare applications. Monitoring how subjects perform
activities at home and their changes over time can reveal early symptoms of
health issues, such as cognitive decline. Most approaches in this field use
deep learning models, which are often seen as black boxes mapping sensor data
to activities. However, non-expert users like clinicians need to trust and
understand these models' outputs. Thus, eXplainable AI (XAI) methods for Human
Activity Recognition have emerged to provide intuitive natural language
explanations from these models. Different XAI methods generate different
explanations, and their effectiveness is typically evaluated through user
surveys, that are often challenging in terms of costs and fairness. This paper
proposes an automatic evaluation method using Large Language Models (LLMs) to
identify, in a pool of candidates, the best XAI approach for non-expert users.
Our preliminary results suggest that LLM evaluation aligns with user surveys.

æè¦ï¼èç±æºæ§ç°å¢ä¸­ä¸å¼äººæ³¨ç®çææ¸¬å¨è¾¨è­æ¥å¸¸æ´»åï¼è½åç¨åç¨®é«çä¿å¥æç¨ãç£æ§åè©¦èå¨å®¶ä¸­å¦ä½å·è¡æ´»åï¼ä»¥åå¶é¨èæéçè®åï¼å¯ä»¥æ­ç¤ºå¥åº·åé¡çæ©æççï¼ä¾å¦èªç¥è½åä¸éãæ­¤é åä¸­çå¤§å¤æ¸æ¹æ³é½ä½¿ç¨æ·±åº¦å­¸ç¿æ¨¡åï¼éäºæ¨¡åéå¸¸è¢«è¦çºå°ææ¸¬å¨è³æå°æè³æ´»åçé»çå­ãç¶èï¼éå°å®¶ä½¿ç¨èï¼ä¾å¦è¨åºé«å¸«ï¼éè¦ä¿¡ä»»ä¸¦äºè§£éäºæ¨¡åçè¼¸åºãå æ­¤ï¼äººé¡æ´»åè¾¨è­çå¯è§£é AI (XAI) æ¹æ³æéèçï¼ä»¥æä¾ä¾èªéäºæ¨¡åçç´è¦ºèªç¶èªè¨èªªæãä¸åç XAI æ¹æ³æç¢çä¸åçèªªæï¼èå¶æææ§éå¸¸ééä½¿ç¨èèª¿æ¥ä¾è©ä¼°ï¼éå¨ææ¬åå¬å¹³æ§æ¹é¢éå¸¸å·æææ°æ§ãæ¬ææåºä½¿ç¨å¤§åèªè¨æ¨¡å (LLM) çèªåè©ä¼°æ¹æ³ï¼ä»¥å¨åé¸èä¸­æ¾åºæé©åéå°å®¶ä½¿ç¨èç XAI æ¹æ³ãæåçåæ­¥çµæè¡¨æï¼LLM è©ä¼°èä½¿ç¨èèª¿æ¥ä¸è´ã

##### **Explainable AI-based Intrusion Detection System for Industry 5.0: An Overview of the Literature, associated Challenges, the existing Solutions, and Potential Research Directions**
2408.03335v1 by Naseem Khan, Kashif Ahmad, Aref Al Tamimi, Mohammed M. Alani, Amine Bermak, Issa Khalil

Industry 5.0, which focuses on human and Artificial Intelligence (AI)
collaboration for performing different tasks in manufacturing, involves a
higher number of robots, Internet of Things (IoTs) devices and
interconnections, Augmented/Virtual Reality (AR), and other smart devices. The
huge involvement of these devices and interconnection in various critical
areas, such as economy, health, education and defense systems, poses several
types of potential security flaws. AI itself has been proven a very effective
and powerful tool in different areas of cybersecurity, such as intrusion
detection, malware detection, and phishing detection, among others. Just as in
many application areas, cybersecurity professionals were reluctant to accept
black-box ML solutions for cybersecurity applications. This reluctance pushed
forward the adoption of eXplainable Artificial Intelligence (XAI) as a tool
that helps explain how decisions are made in ML-based systems. In this survey,
we present a comprehensive study of different XAI-based intrusion detection
systems for industry 5.0, and we also examine the impact of explainability and
interpretability on Cybersecurity practices through the lens of Adversarial
XIDS (Adv-XIDS) approaches. Furthermore, we analyze the possible opportunities
and challenges in XAI cybersecurity systems for industry 5.0 that elicit future
research toward XAI-based solutions to be adopted by high-stakes industry 5.0
applications. We believe this rigorous analysis will establish a foundational
framework for subsequent research endeavors within the specified domain.

æè¦ï¼å·¥æ¥­ 5.0 èéæ¼äººé¡èäººå·¥æºæ§ (AI) åä½å·è¡è£½é ä¸­çä¸åä»»åï¼æ¶åæ´å¤æ©å¨äººãç©è¯ç¶² (IoT) è£ç½®åäºé£ãæ´å¢/èæ¬å¯¦å¢ (AR) åå¶ä»æºæ§è£ç½®ãéäºè£ç½®åäºé£å¨ç¶æ¿ãé«çä¿å¥ãæè²ååé²ç³»çµ±ç­åç¨®ééµé åçå»£æ³åèï¼å¼ç¼äºå¤ç¨®é¡åçæ½å¨å®å¨æ¼æ´ãAI æ¬èº«å·²è¢«è­ææ¯ç¶²è·¯å®å¨ä¸åé åä¸­éå¸¸ææä¸å¼·å¤§çå·¥å·ï¼ä¾å¦å¥ä¾µåµæ¸¬ãæ¡æè»é«åµæ¸¬åç¶²è·¯é£é­åµæ¸¬ç­ãå°±åå¨è¨±å¤æç¨é åä¸æ¨£ï¼ç¶²è·¯å®å¨å°æ¥­äººå¡ä¸é¡ææ¥åé»ç ML è§£æ±ºæ¹æ¡ä¾æç¨æ¼ç¶²è·¯å®å¨ãéç¨®ä¸é¡æä¿ä½¿å¯è§£éäººå·¥æºæ§ (XAI) ä½çºä¸ç¨®å·¥å·è¢«æ¡ç¨ï¼æå©æ¼èªªæå¨åºæ¼ ML çç³»çµ±ä¸­å¦ä½ååºæ±ºç­ãå¨éé èª¿æ¥ä¸­ï¼æåå°å·¥æ¥­ 5.0 çä¸ååºæ¼ XAI çå¥ä¾µåµæ¸¬ç³»çµ±é²è¡äºå¨é¢çç ç©¶ï¼ä¸¦ä¸æåä¹ééå°æå¼ XIDS (Adv-XIDS) æ¹æ³çè§é»ä¾æ¢è¨å¯è§£éæ§åå¯è©®éæ§å°ç¶²è·¯å®å¨å¯¦åçå½±é¿ãæ­¤å¤ï¼æååæäºå·¥æ¥­ 5.0 ç XAI ç¶²è·¯å®å¨ç³»çµ±ä¸­å¯è½å­å¨çæ©æåææ°ï¼å¼ç¼äºæªä¾éå° XAI åºç¤è§£æ±ºæ¹æ¡çç ç©¶ï¼ä»¥ä¾é«é¢¨éªçå·¥æ¥­ 5.0 æç¨æ¡ç¨ãæåç¸ä¿¡éé å´è¬¹çåæå°çºæå®é åå§çå¾çºç ç©¶å·¥ä½å»ºç«åºç¤æ¶æ§ã

##### **A Comparative Study on Automatic Coding of Medical Letters with Explainability**
2407.13638v1 by Jamie Glen, Lifeng Han, Paul Rayson, Goran Nenadic

This study aims to explore the implementation of Natural Language Processing
(NLP) and machine learning (ML) techniques to automate the coding of medical
letters with visualised explainability and light-weighted local computer
settings. Currently in clinical settings, coding is a manual process that
involves assigning codes to each condition, procedure, and medication in a
patient's paperwork (e.g., 56265001 heart disease using SNOMED CT code). There
are preliminary research on automatic coding in this field using
state-of-the-art ML models; however, due to the complexity and size of the
models, the real-world deployment is not achieved. To further facilitate the
possibility of automatic coding practice, we explore some solutions in a local
computer setting; in addition, we explore the function of explainability for
transparency of AI models. We used the publicly available MIMIC-III database
and the HAN/HLAN network models for ICD code prediction purposes. We also
experimented with the mapping between ICD and SNOMED CT knowledge bases. In our
experiments, the models provided useful information for 97.98\% of codes. The
result of this investigation can shed some light on implementing automatic
clinical coding in practice, such as in hospital settings, on the local
computers used by clinicians , project page
\url{https://github.com/Glenj01/Medical-Coding}.

æè¦ï¼æ¬ç ç©¶æ¨å¨æ¢è¨å°èªç¶èªè¨èç (NLP) åæ©å¨å­¸ç¿ (ML) æè¡å¯¦ä½æ¼é«çä¿¡å½ç·¨ç¢¼èªååï¼ä¸¦å·åè¦è¦ºåèªªæè½ååè¼éåçæ¬å°é»è¦è¨­å®ãç®åå¨è¨åºç°å¢ä¸­ï¼ç·¨ç¢¼æ¯ä¸ç¨®æåæµç¨ï¼æ¶åçºçæ£æä»¶ä¸­çæ¯é ççãç¨åºåè¥ç©ææ´¾ä»£ç¢¼ (ä¾å¦ï¼ä½¿ç¨ SNOMED CT ä»£ç¢¼ 56265001 è¡¨ç¤ºå¿èç)ãæ­¤é åæä½¿ç¨ææ° ML æ¨¡åé²è¡èªåç·¨ç¢¼çåæ­¥ç ç©¶ï¼ç¶èï¼ç±æ¼æ¨¡åçè¤éæ§åå¤§å°ï¼ä¸¦æªå¯¦ç¾å¯¦éé¨ç½²ãçºäºé²ä¸æ­¥ä¿é²èªåç·¨ç¢¼å¯¦åçå¯è½æ§ï¼æåå¨æ¬å°é»è¦è¨­å®ä¸­æ¢è¨äºä¸äºè§£æ±ºæ¹æ¡ï¼æ­¤å¤ï¼æåæ¢è¨äºèªªæåè½å¨ AI æ¨¡åéæåº¦ä¸­çåè½ãæåä½¿ç¨å¬éç MIMIC-III è³æåº«å HAN/HLAN ç¶²è·¯æ¨¡åé²è¡ ICD ä»£ç¢¼é æ¸¬ãæåéè©¦é©äº ICD å SNOMED CT ç¥è­åº«ä¹éçå°æãå¨æåçå¯¦é©ä¸­ï¼éäºæ¨¡åæä¾äº 97.98% ä»£ç¢¼çæç¨è³è¨ãéé èª¿æ¥çµæå¯ä»¥çºå¯¦åä¸­çèªåè¨åºç·¨ç¢¼å¯¦ä½æä¾ä¸äºè¦è§£ï¼ä¾å¦å¨é«é¢ç°å¢ä¸­ï¼ç±è¨åºé«çä½¿ç¨çæ¬å°é»è¦ï¼å°æ¡é é¢ \url{https://github.com/Glenj01/Medical-Coding}ã

##### **Explainable AI for Enhancing Efficiency of DL-based Channel Estimation**
2407.07009v1 by Abdul Karim Gizzini, Yahia Medjahdi, Ali J. Ghandour, Laurent Clavier

The support of artificial intelligence (AI) based decision-making is a key
element in future 6G networks, where the concept of native AI will be
introduced. Moreover, AI is widely employed in different critical applications
such as autonomous driving and medical diagnosis. In such applications, using
AI as black-box models is risky and challenging. Hence, it is crucial to
understand and trust the decisions taken by these models. Tackling this issue
can be achieved by developing explainable AI (XAI) schemes that aim to explain
the logic behind the black-box model behavior, and thus, ensure its efficient
and safe deployment. Recently, we proposed a novel perturbation-based XAI-CHEST
framework that is oriented toward channel estimation in wireless
communications. The core idea of the XAI-CHEST framework is to identify the
relevant model inputs by inducing high noise on the irrelevant ones. This
manuscript provides the detailed theoretical foundations of the XAI-CHEST
framework. In particular, we derive the analytical expressions of the XAI-CHEST
loss functions and the noise threshold fine-tuning optimization problem. Hence
the designed XAI-CHEST delivers a smart input feature selection methodology
that can further improve the overall performance while optimizing the
architecture of the employed model. Simulation results show that the XAI-CHEST
framework provides valid interpretations, where it offers an improved bit error
rate performance while reducing the required computational complexity in
comparison to the classical DL-based channel estimation.

æè¦ï¼äººå·¥æºè½ (AI) æ¯æçæ±ºç­å¶å®æ¯æªä¾ 6G ç¶²è·¯ä¸­çééµåç´ ï¼å¶ä¸­å°å¼å¥åç AI çæ¦å¿µãæ­¤å¤ï¼AI å»£æ³ç¨æ¼ä¸åçééµæç¨ä¸­ï¼ä¾å¦èªåé§é§åé«çè¨ºæ·ãå¨éäºæç¨ä¸­ï¼ä½¿ç¨ AI ä½çºé»çæ¨¡åæ¯æé¢¨éªä¸å·æææ°æ§çãå æ­¤ï¼çè§£åä¿¡ä»»éäºæ¨¡åååºçæ±ºç­è³ééè¦ãè§£æ±ºæ­¤åé¡çæ¹æ³æ¯éç¼å¯è§£é AI (XAI) æ¶æ§ï¼æ¨å¨è§£éé»çæ¨¡åè¡çºèå¾çéè¼¯ï¼å¾èç¢ºä¿å¶ææä¸å®å¨çé¨ç½²ãæè¿ï¼æåæåºäºä¸åæ°çåºæ¼æ¾åç XAI-CHEST æ¡æ¶ï¼è©²æ¡æ¶é¢åç¡ç·éä¿¡ä¸­çä¿¡éä¼°è¨ãXAI-CHEST æ¡æ¶çæ ¸å¿ææ³æ¯ééå¨ç¡éè¼¸å¥ä¸å¼å¥é«åªè²ä¾è­å¥ç¸éæ¨¡åè¼¸å¥ãéä»½æç¨¿æä¾äº XAI-CHEST æ¡æ¶çè©³ç´°çè«åºç¤ãç¹å¥æ¯ï¼æåæ¨å°äº XAI-CHEST æå¤±å½æ¸ååªè²é¾å¼å¾®èª¿åªååé¡çè§£æè¡¨éå¼ãå æ­¤ï¼è¨­è¨ç XAI-CHEST æä¾äºä¸ç¨®æºè½è¼¸å¥ç¹å¾µé¸ææ¹æ³ï¼å¯ä»¥å¨åªåæç¨æ¨¡åçæ¶æ§çåæé²ä¸æ­¥æé«æ´é«æ§è½ãæ¨¡æ¬çµæè¡¨æï¼XAI-CHEST æ¡æ¶æä¾äºææçè§£éï¼å¨éä½æéçè¨ç®è¤éåº¦çåæï¼æä¾äºæ¹é²çæ¯ç¹é¯èª¤çæ§è½ï¼èéèåºæ¼å³çµ± DL çä¿¡éä¼°è¨ç¸æ¯ã

##### **Explainable AI: Comparative Analysis of Normal and Dilated ResNet Models for Fundus Disease Classification**
2407.05440v2 by P. N. Karthikayan, Yoga Sri Varshan V, Hitesh Gupta Kattamuri, Umarani Jayaraman

This paper presents dilated Residual Network (ResNet) models for disease
classification from retinal fundus images. Dilated convolution filters are used
to replace normal convolution filters in the higher layers of the ResNet model
(dilated ResNet) in order to improve the receptive field compared to the normal
ResNet model for disease classification. This study introduces
computer-assisted diagnostic tools that employ deep learning, enhanced with
explainable AI techniques. These techniques aim to make the tool's
decision-making process transparent, thereby enabling medical professionals to
understand and trust the AI's diagnostic decision. They are particularly
relevant in today's healthcare landscape, where there is a growing demand for
transparency in AI applications to ensure their reliability and ethical use.
The dilated ResNet is used as a replacement for the normal ResNet to enhance
the classification accuracy of retinal eye diseases and reduce the required
computing time. The dataset used in this work is the Ocular Disease Intelligent
Recognition (ODIR) dataset which is a structured ophthalmic database with eight
classes covering most of the common retinal eye diseases. The evaluation
metrics used in this work include precision, recall, accuracy, and F1 score. In
this work, a comparative study has been made between normal ResNet models and
dilated ResNet models on five variants namely ResNet-18, ResNet-34, ResNet-50,
ResNet-101, and ResNet-152. The dilated ResNet model shows promising results as
compared to normal ResNet with an average F1 score of 0.71, 0.70, 0.69, 0.67,
and 0.70 respectively for the above respective variants in ODIR multiclass
disease classification.

æè¦ï¼è¿ç¯è®ºææåºäºç¨äºä»è§ç½èç¼åºå¾åè¿è¡ç¾çåç±»çæ©å¼ æ®å·®ç½ç» (ResNet) æ¨¡åãæ©å¼ å·ç§¯æ»¤æ³¢å¨ç¨äºæ¿æ¢ ResNet æ¨¡åè¾é«å±ä¸­çæ­£å¸¸å·ç§¯æ»¤æ³¢å¨ï¼æ©å¼  ResNetï¼ï¼ä»¥æ¹åæç¥åºï¼ä»èéå¯¹ç¾çåç±»å¯¹æ­£å¸¸ ResNet æ¨¡åè¿è¡æ¹è¿ãæ¬ç ç©¶å¼å¥äºéç¨æ·±åº¦å­¦ä¹ çè®¡ç®æºè¾å©è¯æ­å·¥å·ï¼å¹¶éè¿å¯è§£éç AI ææ¯è¿è¡äºå¢å¼ºãè¿äºææ¯æ¨å¨ä½¿è¯¥å·¥å·çå³ç­è¿ç¨éæåï¼ä»èä½¿å»å­¦ä¸ä¸äººå£«è½å¤çè§£åä¿¡ä»» AI çè¯æ­å³ç­ãå®ä»¬ä¸å½ä»çå»çä¿å¥é¢åå°¤ä¸ºç¸å³ï¼å¨è¯¥é¢åï¼å¯¹ AI åºç¨çéæåº¦éæ±ä¸æ­å¢é¿ï¼ä»¥ç¡®ä¿å¶å¯é æ§ååä¹éå¾·çä½¿ç¨ãæ©å¼  ResNet ç¨ä½æ­£å¸¸ ResNet çæ¿ä»£åï¼ä»¥æé«è§ç½èç¼é¨ç¾ççåç±»åç¡®æ§å¹¶åå°æéçè®¡ç®æ¶é´ãæ¬å·¥ä½ä¸­ä½¿ç¨çæ°æ®éæ¯ç¼ç§ç¾çæºè½è¯å« (ODIR) æ°æ®éï¼è¿æ¯ä¸ä¸ªç»æåçç¼ç§æ°æ®åºï¼åå«å«ç±»æ¶µçå¤§å¤æ°å¸¸è§è§ç½èç¼é¨ç¾çãæ¬å·¥ä½ä¸­ä½¿ç¨çè¯ä¼°ææ åæ¬ç²¾ç¡®åº¦ãå¬åçãåç¡®åº¦å F1 å¾åãå¨è¿é¡¹å·¥ä½ä¸­ï¼å¯¹ ResNet-18ãResNet-34ãResNet-50ãResNet-101 å ResNet-152 äºä¸ªåä½çæ­£å¸¸ ResNet æ¨¡ååæ©å¼  ResNet æ¨¡åè¿è¡äºæ¯è¾ç ç©¶ãä¸æ­£å¸¸ ResNet ç¸æ¯ï¼æ©å¼  ResNet æ¨¡åæ¾ç¤ºåºæå¸æçç»æï¼å¨ ODIR å¤ç±»ç¾çåç±»ä¸­ï¼ä¸è¿°åä¸ªåä½çå¹³å F1 å¾åä¸º 0.71ã0.70ã0.69ã0.67 å 0.70ã

##### **A Survey on Trustworthiness in Foundation Models for Medical Image Analysis**
2407.15851v2 by Congzhen Shi, Ryan Rezai, Jiaxi Yang, Qi Dou, Xiaoxiao Li

The rapid advancement of foundation models in medical imaging represents a
significant leap toward enhancing diagnostic accuracy and personalized
treatment. However, the deployment of foundation models in healthcare
necessitates a rigorous examination of their trustworthiness, encompassing
privacy, robustness, reliability, explainability, and fairness. The current
body of survey literature on foundation models in medical imaging reveals
considerable gaps, particularly in the area of trustworthiness. Additionally,
existing surveys on the trustworthiness of foundation models do not adequately
address their specific variations and applications within the medical imaging
domain. This survey aims to fill that gap by presenting a novel taxonomy of
foundation models used in medical imaging and analyzing the key motivations for
ensuring their trustworthiness. We review current research on foundation models
in major medical imaging applications, focusing on segmentation, medical report
generation, medical question and answering (Q\&A), and disease diagnosis. These
areas are highlighted because they have seen a relatively mature and
substantial number of foundation models compared to other applications. We
focus on literature that discusses trustworthiness in medical image analysis
manuscripts. We explore the complex challenges of building trustworthy
foundation models for each application, summarizing current concerns and
strategies for enhancing trustworthiness. Furthermore, we examine the potential
of these models to revolutionize patient care. Our analysis underscores the
imperative for advancing towards trustworthy AI in medical image analysis,
advocating for a balanced approach that fosters innovation while ensuring
ethical and equitable healthcare delivery.

æè¦ï¼åºç¤æ¨¡åå¨é«å­¸å½±åæ¹é¢çå¿«éé²å±ï¼ä»£è¡¨èå¨å å¼·è¨ºæ·æºç¢ºæ§ååäººåæ²»çæ¹é¢éåºä¸å¤§æ­¥ãç¶èï¼åºç¤æ¨¡åå¨é«çä¿å¥ä¸­çé¨ç½²éè¦å°å¶å¯ä¿¡åº¦é²è¡å´æ ¼çå¯©æ¥ï¼åæ¬é±ç§ãç©©å¥æ§ãå¯é æ§ãå¯è§£éæ§åå¬å¹³æ§ãç®åéæ¼é«å­¸å½±åä¸­åºç¤æ¨¡åçèª¿æ¥æç»ä¸­é¡¯ç¤ºåºç¸ç¶å¤§çå·®è·ï¼ç¹å¥æ¯å¨å¯ä¿¡åº¦æ¹é¢ãæ­¤å¤ï¼ç¾æéæ¼åºç¤æ¨¡åå¯ä¿¡åº¦çèª¿æ¥ä¸¦æªååè§£æ±ºå¶å¨é«å­¸å½±åé åä¸­çç¹å®è®ååæç¨ãæ¬èª¿æ¥æ¨å¨ééæåºé«å­¸å½±åä¸­ä½¿ç¨çåºç¤æ¨¡åçæ°åé¡æ³ä¸¦åæç¢ºä¿å¶å¯ä¿¡åº¦çééµåæ©ï¼ä¾å¡«è£éä¸ç©ºç½ãæååé¡§äºåºç¤æ¨¡åå¨ä¸»è¦é«å­¸å½±åæç¨ä¸­çç¶åç ç©¶ï¼éé»éæ³¨åå²ãé«çå ±åçæãé«çåé¡ååç­ (Q&A) ä»¥åç¾çè¨ºæ·ãéäºé åä¹æä»¥è¢«å¼·èª¿ï¼æ¯å çºèå¶ä»æç¨ç¸æ¯ï¼å®åå·²ç¶çå°ç¸å°æçä¸å¤§éçåºç¤æ¨¡åãæåå°æ³¨æ¼æ¢è¨é«å­¸å½±ååææç¨¿ä¸­å¯ä¿¡åº¦çæç»ãæåæ¢è¨äºçºæ¯åæç¨æ§å»ºå¯ä¿¡åºç¤æ¨¡åçè¤éææ°ï¼ç¸½çµäºç¶åéæ³¨é»åå¢å¼·å¯ä¿¡åº¦çç­ç¥ãæ­¤å¤ï¼æåæ¢è¨äºéäºæ¨¡åå¨é©æ°æ£èè­·çæ¹é¢çæ½åãæåçåæå¼·èª¿äºå¨é«å­¸å½±ååæä¸­æèå¯ä¿¡è³´çäººå·¥æºæ§éé²çå¿è¦æ§ï¼ä¸¦å¡å°ä¸ç¨®å¹³è¡¡çæ¹æ³ï¼æ¢è½ä¿é²åµæ°ï¼åè½ç¢ºä¿éå¾·åå¬å¹³çé«çä¿å¥æåã

##### **The Impact of an XAI-Augmented Approach on Binary Classification with Scarce Data**
2407.06206v1 by Ximing Wen, Rosina O. Weber, Anik Sen, Darryl Hannan, Steven C. Nesbit, Vincent Chan, Alberto Goffi, Michael Morris, John C. Hunninghake, Nicholas E. Villalobos, Edward Kim, Christopher J. MacLellan

Point-of-Care Ultrasound (POCUS) is the practice of clinicians conducting and
interpreting ultrasound scans right at the patient's bedside. However, the
expertise needed to interpret these images is considerable and may not always
be present in emergency situations. This reality makes algorithms such as
machine learning classifiers extremely valuable to augment human decisions.
POCUS devices are becoming available at a reasonable cost in the size of a
mobile phone. The challenge of turning POCUS devices into life-saving tools is
that interpretation of ultrasound images requires specialist training and
experience. Unfortunately, the difficulty to obtain positive training images
represents an important obstacle to building efficient and accurate
classifiers. Hence, the problem we try to investigate is how to explore
strategies to increase accuracy of classifiers trained with scarce data. We
hypothesize that training with a few data instances may not suffice for
classifiers to generalize causing them to overfit. Our approach uses an
Explainable AI-Augmented approach to help the algorithm learn more from less
and potentially help the classifier better generalize.

æè¦ï¼åºéè¶é³æ³¢ (POCUS) æ¯è¨åºé«å¸«å¨æ£èåºéé²è¡åè§£è®è¶é³æ³¢ææçå¯¦åãç¶èï¼è§£è®éäºå½±åæéçå°æ¥­ç¥è­ç¸ç¶å¯è§ï¼èä¸å¨ç·æ¥ææ³ä¸å¯è½ä¸¦éé¨æå·åãéç¨®ç¾å¯¦ææ³ä½¿å¾æ©å¨å­¸ç¿åé¡å¨ç­æ¼ç®æ³å°æ¼å å¼·äººé¡æ±ºç­è®å¾æ¥µçºæå¹å¼ãPOCUS è£ç½®æ­£ä»¥åçææ¬æ¨åºï¼å°ºå¯¸çºææ©å¤§å°ãå° POCUS è£ç½®è½è®çºæçå·¥å·çææ°å¨æ¼ï¼è§£è®è¶é³æ³¢å½±åéè¦å°éè¨ç·´åç¶é©ãä¸å¹¸çæ¯ï¼åå¾æ­£åè¨ç·´å½±åçå°é£åº¦ä»£è¡¨èå»ºç½®ææçä¸æºç¢ºçåé¡å¨çä¸å¤§éç¤ãå æ­¤ï¼æååè©¦æ¢è¨çåé¡æ¯å¦ä½æ¢ç´¢ç­ç¥ï¼ä»¥æé«ä½¿ç¨ç¨çè³æè¨ç·´çåé¡å¨çæºç¢ºåº¦ãæååè¨­ä½¿ç¨å°æ¸è³æå¯¦ä¾é²è¡è¨ç·´å¯è½ä¸è¶³ä»¥è®åé¡å¨æ¦æ¬ï¼å°è´å®åéåº¦æ¬åãæåçåæ³ä½¿ç¨å¯è§£é AI å¢å¼·æ¹æ³ï¼ä»¥åå©æ¼ç®æ³å¾è¼å°çè³æä¸­å­¸ç¿æ´å¤ï¼ä¸¦æ½å¨åå©åé¡å¨æ´å¥½å°æ¦æ¬ã

##### **Can GPT-4 Help Detect Quit Vaping Intentions? An Exploration of Automatic Data Annotation Approach**
2407.00167v1 by Sai Krishna Revanth Vuruma, Dezhi Wu, Saborny Sen Gupta, Lucas Aust, Valerie Lookingbill, Wyatt Bellamy, Yang Ren, Erin Kasson, Li-Shiun Chen, Patricia Cavazos-Rehg, Dian Hu, Ming Huang

In recent years, the United States has witnessed a significant surge in the
popularity of vaping or e-cigarette use, leading to a notable rise in cases of
e-cigarette and vaping use-associated lung injury (EVALI) that caused
hospitalizations and fatalities during the EVALI outbreak in 2019, highlighting
the urgency to comprehend vaping behaviors and develop effective strategies for
cessation. Due to the ubiquity of social media platforms, over 4.7 billion
users worldwide use them for connectivity, communications, news, and
entertainment with a significant portion of the discourse related to health,
thereby establishing social media data as an invaluable organic data resource
for public health research. In this study, we extracted a sample dataset from
one vaping sub-community on Reddit to analyze users' quit-vaping intentions.
Leveraging OpenAI's latest large language model GPT-4 for sentence-level quit
vaping intention detection, this study compares the outcomes of this model
against layman and clinical expert annotations. Using different prompting
strategies such as zero-shot, one-shot, few-shot and chain-of-thought
prompting, we developed 8 prompts with varying levels of detail to explain the
task to GPT-4 and also evaluated the performance of the strategies against each
other. These preliminary findings emphasize the potential of GPT-4 in social
media data analysis, especially in identifying users' subtle intentions that
may elude human detection.

æè¦ï¼è¿å¹´ä¾ï¼ç¾åè¦è­äºé»å­çæé»å­é¦è¸ä½¿ç¨çå¤§å¹æ¿å¢ï¼å°è´é»å­çåé»å­çä½¿ç¨ç¸éèºæå· (EVALI) çä¾é¡¯èå¢å ï¼å¨ 2019 å¹´ EVALI çç¼æéé æä½é¢åæ­»äº¡ï¼å¸é¡¯äºçè§£é»å­çè¡çºåå¶å®æææè¸ç­ç¥çè¿«åæ§ãç±æ¼ç¤¾ç¾¤åªé«å¹³å°çæ®åï¼å¨çè¶é 47 åä½¿ç¨èä½¿ç¨å®åé²è¡é£çµãæºéãæ°èåå¨æ¨ï¼å¶ä¸­å¾å¤§ä¸é¨åèå¥åº·ç¸éï¼å æ­¤å°ç¤¾ç¾¤åªé«è³æå»ºç«çºå¬å±è¡çç ç©¶ä¸­ç¡å¹çææ©è³æè³æºãå¨æ¬ç ç©¶ä¸­ï¼æåå¾ Reddit ä¸ä¸åé»å­çå­ç¤¾ç¾¤ä¸­æåä¸åç¯ä¾è³æéï¼ä»¥åæä½¿ç¨èçæé»å­çæåãå©ç¨ OpenAI ææ°çå¤§åèªè¨æ¨¡å GPT-4 é²è¡å¥å­å±¤ç´çæé»å­çæååµæ¸¬ï¼æ¬ç ç©¶æ¯è¼äºæ­¤æ¨¡åççµæèå¤è¡äººåè¨åºå°å®¶è¨»è§£ãä½¿ç¨ä¸åçæç¤ºç­ç¥ï¼ä¾å¦é¶æ¬¡å­¸ç¿ãä¸æ¬¡å­¸ç¿ãå°æ¬¡å­¸ç¿åæèéæç¤ºï¼æåéç¼äº 8 åæç¤ºï¼è©³ç´°ç¨åº¦ä¸åï¼å GPT-4 è§£éä»»åï¼ä¸¦è©ä¼°éäºç­ç¥å½¼æ­¤ä¹éçæè½ãéäºåæ­¥ç¼ç¾å¼·èª¿äº GPT-4 å¨ç¤¾ç¾¤åªé«è³æåæä¸­çæ½åï¼ç¹å¥æ¯å¨è­å¥äººé¡åµæ¸¬å¯è½ç¡æ³å¯è¦ºçä½¿ç¨èå¾®å¦æåæ¹é¢ã

##### **Towards Compositional Interpretability for XAI**
2406.17583v1 by Sean Tull, Robin Lorenz, Stephen Clark, Ilyas Khan, Bob Coecke

Artificial intelligence (AI) is currently based largely on black-box machine
learning models which lack interpretability. The field of eXplainable AI (XAI)
strives to address this major concern, being critical in high-stakes areas such
as the finance, legal and health sectors.
  We present an approach to defining AI models and their interpretability based
on category theory. For this we employ the notion of a compositional model,
which sees a model in terms of formal string diagrams which capture its
abstract structure together with its concrete implementation. This
comprehensive view incorporates deterministic, probabilistic and quantum
models. We compare a wide range of AI models as compositional models, including
linear and rule-based models, (recurrent) neural networks, transformers, VAEs,
and causal and DisCoCirc models.
  Next we give a definition of interpretation of a model in terms of its
compositional structure, demonstrating how to analyse the interpretability of a
model, and using this to clarify common themes in XAI. We find that what makes
the standard 'intrinsically interpretable' models so transparent is brought out
most clearly diagrammatically. This leads us to the more general notion of
compositionally-interpretable (CI) models, which additionally include, for
instance, causal, conceptual space, and DisCoCirc models.
  We next demonstrate the explainability benefits of CI models. Firstly, their
compositional structure may allow the computation of other quantities of
interest, and may facilitate inference from the model to the modelled
phenomenon by matching its structure. Secondly, they allow for diagrammatic
explanations for their behaviour, based on influence constraints, diagram
surgery and rewrite explanations. Finally, we discuss many future directions
for the approach, raising the question of how to learn such meaningfully
structured models in practice.

æè¦ï¼<paragraph>äººå·¥æºæ§ï¼AIï¼ç®åå¨å¾å¤§ç¨åº¦ä¸ä¾è³´æ¼ç¼ºä¹å¯è§£éæ§çé»çæ©å¨å­¸ç¿æ¨¡åãå¯è§£éæ§äººå·¥æºæ§ï¼XAIï¼é åè´åæ¼è§£æ±ºéåä¸»è¦åé¡ï¼éå¨éèãæ³å¾åå¥åº·ç­é«é¢¨éªé åè³ééè¦ã
æåæåºäºä¸ç¨®åºæ¼ç¯çè«å®ç¾© AI æ¨¡ååå¶å¯è§£éæ§çæ¹æ³ãçºæ­¤ï¼æåæ¡ç¨çµåæ¨¡åçæ¦å¿µï¼å®ä»¥å½¢å¼å¼¦åçå½¢å¼çå¾æ¨¡åï¼éäºå¼¦åæç²äºæ¨¡åçæ½è±¡çµæ§åå¶å·é«å¯¦ç¾ãéç¨®ç¶åè§é»åå«äºç¢ºå®æ§ãæ¦çæ§åéå­æ¨¡åãæåå°åç¨® AI æ¨¡åä½çºçµåæ¨¡åé²è¡æ¯è¼ï¼åæ¬ç·æ§ååºæ¼è¦åçæ¨¡åãï¼éè¿´ï¼ç¥ç¶ç¶²è·¯ãTransformerãVAEï¼ä»¥åå æå DisCoCirc æ¨¡åã
æ¥ä¸ä¾ï¼æåæ ¹ææ¨¡åççµåçµæ§çµ¦åºæ¨¡åè§£éçå®ç¾©ï¼å±ç¤ºå¦ä½åææ¨¡åçå¯è§£éæ§ï¼ä¸¦ä½¿ç¨å®ä¾æ¾æ¸ XAI ä¸­çå¸¸è¦ä¸»é¡ãæåç¼ç¾ï¼è®æ¨æºçãå§å¨å¯è§£éãæ¨¡åå¦æ­¤éæçåå å¨åè¡¨ä¸­è¡¨ç¾å¾æçºæ¸æ¥ãéå¼å°æåå¾åºæ´ä¸è¬ççµåå¯è§£éï¼CIï¼æ¨¡åæ¦å¿µï¼å®å¦å¤éåæ¬å æãæ¦å¿µç©ºéå DisCoCirc æ¨¡åã
æ¥ä¸ä¾ï¼æåå±ç¤ºäº CI æ¨¡åçå¯è§£éæ§åªå¢ãé¦åï¼å®åççµåçµæ§åè¨±è¨ç®å¶ä»æèè¶£çéï¼ä¸¦å¯è½ééå¹éæ¨¡åççµæ§ä¾ä¿é²å¾æ¨¡åå°è¢«å»ºæ¨¡ç¾è±¡çæ¨çãå¶æ¬¡ï¼å®ååè¨±å°å¶è¡çºé²è¡åè§£èªªæï¼éäºèªªæåºæ¼å½±é¿ç´æãåè§£æè¡åéå¯«èªªæãæå¾ï¼æåè¨è«äºéç¨®æ¹æ³çè¨±å¤æªä¾æ¹åï¼æåºäºå¦ä½å¨å¯¦è¸ä¸­å­¸ç¿éç¨®ææç¾©ççµæ§åæ¨¡åçåé¡ã</paragraph>

##### **Slicing Through Bias: Explaining Performance Gaps in Medical Image Analysis using Slice Discovery Methods**
2406.12142v2 by Vincent Olesen, Nina Weng, Aasa Feragen, Eike Petersen

Machine learning models have achieved high overall accuracy in medical image
analysis. However, performance disparities on specific patient groups pose
challenges to their clinical utility, safety, and fairness. This can affect
known patient groups - such as those based on sex, age, or disease subtype - as
well as previously unknown and unlabeled groups. Furthermore, the root cause of
such observed performance disparities is often challenging to uncover,
hindering mitigation efforts. In this paper, to address these issues, we
leverage Slice Discovery Methods (SDMs) to identify interpretable
underperforming subsets of data and formulate hypotheses regarding the cause of
observed performance disparities. We introduce a novel SDM and apply it in a
case study on the classification of pneumothorax and atelectasis from chest
x-rays. Our study demonstrates the effectiveness of SDMs in hypothesis
formulation and yields an explanation of previously observed but unexplained
performance disparities between male and female patients in widely used chest
X-ray datasets and models. Our findings indicate shortcut learning in both
classification tasks, through the presence of chest drains and ECG wires,
respectively. Sex-based differences in the prevalence of these shortcut
features appear to cause the observed classification performance gap,
representing a previously underappreciated interaction between shortcut
learning and model fairness analyses.

æè¦ï¼æ©å¨å­¸ç¿æ¨¡åå¨é«å­¸å½±ååæä¸­å·²éå°æ´é«é«æºç¢ºåº¦ãç¶èï¼ç¹å®æ£èç¾¤é«çæè½å·®ç°å°å¶è¨åºæç¨ãå®å¨æ§èå¬å¹³æ§æ§æææ°ãéå¯è½æå½±é¿å·²ç¥çæ£èç¾¤é«ï¼ä¾å¦åºæ¼æ§å¥ãå¹´é½¡æç¾çäºåï¼ä»¥åååæªç¥ä¸æªæ¨ç±¤çç¾¤é«ãæ­¤å¤ï¼æ­¤é¡è§å¯å°çæè½å·®ç°çæ ¹æ¬åå éå¸¸é£ä»¥ç¼ç¾ï¼é»ç¤äºç·©è§£æªæ½ãå¨æ¬æä¸­ï¼çºäºè§£æ±ºéäºåé¡ï¼æåå©ç¨åçç¼ç¾æ¹æ³ (SDM) ä¾è­å¥å¯è§£éçè³ææè½ä¸ä½³å­éï¼ä¸¦éå°è§å¯å°çæè½å·®ç°åå å¶å®åè¨­ãæåå¼å¥ä¸ç¨®æ°ç SDMï¼ä¸¦å¨è¸é¨ X åçä¸­èºçåèºä¸å¼µåé¡çæ¡ä¾ç ç©¶ä¸­æç¨å®ãæåçç ç©¶è­æäº SDM å¨åè¨­å¶å®ä¸­çæææ§ï¼ä¸¦å°å»£æ³ä½¿ç¨çè¸é¨ X åçè³æéåæ¨¡åä¸­ååè§å¯å°ä½ç¡æ³è§£éçç·æ§åå¥³æ§æ£èä¹éçæè½å·®ç°æä¾äºè§£éãæåçç¼ç¾è¡¨æï¼å¨åé¡ä»»åä¸­ï¼ééè¸èå¼æµç®¡åå¿é»åå°ç·çå­å¨ï¼å­å¨æ·å¾å­¸ç¿ãéäºæ·å¾ç¹å¾µççè¡çå­å¨åºæ¼æ§å¥çå·®ç°ï¼ä¼¼ä¹æå°è´è§å¯å°çåé¡æè½å·®è·ï¼éä»£è¡¨æ·å¾å­¸ç¿åæ¨¡åå¬å¹³æ§åæä¹éååæªåå°éè¦çäº¤äºä½ç¨ã

##### **Unlocking the Potential of Metaverse in Innovative and Immersive Digital Health**
2406.07114v2 by Fatemeh Ebrahimzadeh, Ramin Safa

The concept of Metaverse has attracted a lot of attention in various fields
and one of its important applications is health and treatment. The Metaverse
has enormous potential to transform healthcare by changing patient care,
medical education, and the way teaching/learning and research are done. The
purpose of this research is to provide an introduction to the basic concepts
and fundamental technologies of the Metaverse. This paper examines the pros and
cons of the Metaverse in healthcare context and analyzes its potential from the
technology and AI perspective. In particular, the role of machine learning
methods is discussed; We will explain how machine learning algorithms can be
applied to the Metaverse generated data to gain better insights in healthcare
applications. Additionally, we examine the future visions of the Metaverse in
health delivery, by examining emerging technologies such as blockchain and also
addressing privacy concerns. The findings of this study contribute to a deeper
understanding of the applications of Metaverse in healthcare and its potential
to revolutionize the delivery of medical services.

æè¦ï¼åå®å®çæ¦å¿µå¨ååé åé½ååéæ³¨ï¼å¶éè¦æç¨ä¹ä¸ä¾¿æ¯é«çä¿å¥ãåå®å®æå·¨å¤§çæ½åééæ¹è®çæ£ç§è­·ãé«å­¸æè²ï¼ä»¥åæå­¸/å­¸ç¿åç ç©¶çæ¹å¼ä¾è½åé«çä¿å¥ãæ¬ç ç©¶çç®çæ¯æä¾åå®å®åºæ¬æ¦å¿µååºç¤æè¡çä»ç´¹ãæ¬ææ¢è¨äºåå®å®å¨é«çä¿å¥èæ¯ä¸çåªç¼ºé»ï¼ä¸¦å¾æè¡å AI çè§åº¦åæå¶æ½åãç¹å¥æ¯ï¼è¨è«äºæ©å¨å­¸ç¿æ¹æ³çè§è²ï¼æåå°èªªæå¦ä½å°æ©å¨å­¸ç¿æ¼ç®æ³æç¨æ¼åå®å®ç¢ççè³æï¼ä»¥ç²å¾é«çä¿å¥æç¨æ¹é¢çæ´ä½³è¦è§£ãæ­¤å¤ï¼æåééæ¢è¨åå¡éç­æ°èæè¡ï¼ä¸¦è§£æ±ºé±ç§åé¡ï¼ä¾æ¢è¨åå®å®å¨é«çä¿å¥æ¹é¢çæªä¾é¡æ¯ãæ¬ç ç©¶çç¼ç¾æå©æ¼æ´æ·±å¥å°äºè§£åå®å®å¨é«çä¿å¥ä¸­çæç¨ï¼ä»¥åå¶å¨é«çæåæä¾æ¹é¢ç¼æ®é©å½æ§è®é©çæ½åã

##### **AI-Driven Predictive Analytics Approach for Early Prognosis of Chronic Kidney Disease Using Ensemble Learning and Explainable AI**
2406.06728v1 by K M Tawsik Jawad, Anusha Verma, Fathi Amsaad

Chronic Kidney Disease (CKD) is one of the widespread Chronic diseases with
no known ultimo cure and high morbidity. Research demonstrates that progressive
Chronic Kidney Disease (CKD) is a heterogeneous disorder that significantly
impacts kidney structure and functions, eventually leading to kidney failure.
With the progression of time, chronic kidney disease has moved from a
life-threatening disease affecting few people to a common disorder of varying
severity. The goal of this research is to visualize dominating features,
feature scores, and values exhibited for early prognosis and detection of CKD
using ensemble learning and explainable AI. For that, an AI-driven predictive
analytics approach is proposed to aid clinical practitioners in prescribing
lifestyle modifications for individual patients to reduce the rate of
progression of this disease. Our dataset is collected on body vitals from
individuals with CKD and healthy subjects to develop our proposed AI-driven
solution accurately. In this regard, blood and urine test results are provided,
and ensemble tree-based machine-learning models are applied to predict unseen
cases of CKD. Our research findings are validated after lengthy consultations
with nephrologists. Our experiments and interpretation results are compared
with existing explainable AI applications in various healthcare domains,
including CKD. The comparison shows that our developed AI models, particularly
the Random Forest model, have identified more features as significant
contributors than XgBoost. Interpretability (I), which measures the ratio of
important to masked features, indicates that our XgBoost model achieved a
higher score, specifically a Fidelity of 98\%, in this metric and naturally in
the FII index compared to competing models.

æè¦ï¼æ¢æ§èèçï¼CKDï¼æ¯ä¸ç¨®å»£æ³çæ¢æ§ç¾çï¼æ²æå·²ç¥çæçµçæ³ä¸ç¼ççå¾é«ãç ç©¶è¡¨æï¼é²è¡æ§æ¢æ§èèçï¼CKDï¼æ¯ä¸ç¨®ç°è³ªæ§ç¾çï¼æé¡¯èå½±é¿èèçµæ§ååè½ï¼æçµå°è´èè¡°ç«­ãé¨èæéçæ¨ç§»ï¼æ¢æ§èèçå·²å¾å½±é¿å°æ¸äººçè´å½ç¾çè½è®çºä¸ç¨®å´éç¨åº¦ä¸åçå¸¸è¦ç¾çãæ¬ç ç©¶çç®æ¨æ¯ä½¿ç¨éæå­¸ç¿åå¯è§£éç AI é²è¡æ©æé å¾å CKD æª¢æ¸¬ï¼ä¸¦è¦è¦ºåä¸»å°ç¹å¾µãç¹å¾µåæ¸åè¡¨ç¾åºçå¼ãçºæ­¤ï¼æåºäºä¸ç¨® AI é©åçé æ¸¬åææ¹æ³ï¼ä»¥å¹«å©è¨åºé«ççºåå¥æ£èéå·çæ´»æ¹å¼ä¿®æ¹å»ºè­°ï¼ä»¥éä½éç¨®ç¾ççé²å±éåº¦ãæåçæ¸æéæ¯å¾ CKD æ£èåå¥åº·åè©¦èçèº«é«çå½é«å¾µä¸­æ¶éçï¼ä»¥æºç¢ºéç¼æåæåºç AI é©åçè§£æ±ºæ¹æ¡ãå¨éæ¹é¢ï¼æä¾äºè¡æ¶²åå°¿æ¶²æª¢æ¸¬çµæï¼ä¸¦æç¨åºæ¼éææ¨¹çæ©å¨å­¸ç¿æ¨¡åä¾é æ¸¬æªç¼ç¾ç CKD çä¾ãæåçç ç©¶çµæç¶éèèèç§é«ççé·æè«®è©¢å¾å¾å°é©è­ãæåçå¯¦é©åè§£éçµæèåç¨®é«çä¿å¥é åä¸­ç¾æçå¯è§£é AI æç¨é²è¡äºæ¯è¼ï¼åæ¬ CKDãæ¯è¼è¡¨æï¼æåéç¼ç AI æ¨¡åï¼ç¹å¥æ¯é¨æ©æ£®ææ¨¡åï¼å·²ç¶ç¢ºå®äºæ¯ XgBoost æ´å¤ä½çºéè¦è²¢ç»èçç¹å¾µãå¯è§£éæ§ (I) è¡¡ééè¦ç¹å¾µèæ©èç¹å¾µçæ¯çï¼è¡¨ææåç XgBoost æ¨¡åå¨éåææ¨ä¸­ç²å¾äºæ´é«çåæ¸ï¼ç¹å¥æ¯ 98% çä¿çåº¦ï¼ä¸¦ä¸å¨ FII ææ¸ä¸­èªç¶é«æ¼ç«¶ç­æ¨¡åã

##### **Explainable AI for Mental Disorder Detection via Social Media: A survey and outlook**
2406.05984v1 by Yusif Ibrahimov, Tarique Anwar, Tommy Yuan

Mental health constitutes a complex and pervasive global challenge, affecting
millions of lives and often leading to severe consequences. In this paper, we
conduct a thorough survey to explore the intersection of data science,
artificial intelligence, and mental healthcare, focusing on the recent
developments of mental disorder detection through online social media (OSM). A
significant portion of the population actively engages in OSM platforms,
creating a vast repository of personal data that holds immense potential for
mental health analytics. The paper navigates through traditional diagnostic
methods, state-of-the-art data- and AI-driven research studies, and the
emergence of explainable AI (XAI) models for mental healthcare. We review
state-of-the-art machine learning methods, particularly those based on modern
deep learning, while emphasising the need for explainability in healthcare AI
models. The experimental design section provides insights into prevalent
practices, including available datasets and evaluation approaches. We also
identify key issues and challenges in the field and propose promising future
research directions. As mental health decisions demand transparency,
interpretability, and ethical considerations, this paper contributes to the
ongoing discourse on advancing XAI in mental healthcare through social media.
The comprehensive overview presented here aims to guide researchers,
practitioners, and policymakers in developing the area of mental disorder
detection.

æè¦ï¼å¿çå¥åº·æ§æäºä¸é è¤éä¸æ®éçå¨çææ°ï¼å½±é¿äºæ¸ç¾è¬äººççæ´»ï¼ä¸¦ç¶å¸¸å°è´å´éçå¾æãå¨æ¬æä¸­ï¼æåé²è¡äºä¸é å¾¹åºçèª¿æ¥ï¼ä»¥æ¢ç´¢æ¸æç§å­¸ãäººå·¥æºæ§åå¿çä¿å¥çäº¤éï¼éé»éæ³¨ééç·ä¸ç¤¾äº¤åªé« (OSM) é²è¡å¿çç¾çæª¢æ¸¬çææ°ç¼å±ãå¾å¤§ä¸é¨åäººå£ç©æ¥µåè OSM å¹³å°ï¼åµé äºä¸åé¾å¤§çäººå¡è³æåº«ï¼å°å¿çå¥åº·åæå·æå·¨å¤§çæ½åãæ¬ææ¢è¨äºå³çµ±çè¨ºæ·æ¹æ³ãæåé²çè³æå AI é©åçç ç©¶ï¼ä»¥åå¿çä¿å¥ä¸­å¯è§£é AI (XAI) æ¨¡åçåºç¾ãæååé¡§äºæåé²çæ©å¨å­¸ç¿æ¹æ³ï¼ç¹å¥æ¯é£äºåºæ¼ç¾ä»£æ·±åº¦å­¸ç¿çæ¹æ³ï¼åæå¼·èª¿äºé«çä¿å¥ AI æ¨¡åä¸­å¯è§£éæ§çå¿è¦æ§ãå¯¦é©è¨­è¨é¨åæä¾äºå°æ®éåæ³çè¦è§£ï¼åæ¬å¯ç¨çè³æéåè©ä¼°æ¹æ³ãæåéæ¾åºè©²é åçä¸»è¦åé¡åææ°ï¼ä¸¦æåºäºæå¸æçæªä¾ç ç©¶æ¹åãç±æ¼å¿çå¥åº·æ±ºç­éè¦éæåº¦ãå¯è§£éæ§åéå¾·èéï¼æ¬ææå©æ¼æ¨é²å¿çä¿å¥ä¸­ééç¤¾äº¤åªé«æ¨é² XAI çæçºè¨è«ãéè£¡æåºçå¨é¢æ¦è¿°æ¨å¨å¼å°ç ç©¶äººå¡ãå¾æ¥­äººå¡åæ¿ç­å¶å®èç¼å±å¿çç¾çæª¢æ¸¬é åã

##### **Methodology and Real-World Applications of Dynamic Uncertain Causality Graph for Clinical Diagnosis with Explainability and Invariance**
2406.05746v1 by Zhan Zhang, Qin Zhang, Yang Jiao, Lin Lu, Lin Ma, Aihua Liu, Xiao Liu, Juan Zhao, Yajun Xue, Bing Wei, Mingxia Zhang, Ru Gao, Hong Zhao, Jie Lu, Fan Li, Yang Zhang, Yiming Wang, Lei Zhang, Fengwei Tian, Jie Hu, Xin Gou

AI-aided clinical diagnosis is desired in medical care. Existing deep
learning models lack explainability and mainly focus on image analysis. The
recently developed Dynamic Uncertain Causality Graph (DUCG) approach is
causality-driven, explainable, and invariant across different application
scenarios, without problems of data collection, labeling, fitting, privacy,
bias, generalization, high cost and high energy consumption. Through close
collaboration between clinical experts and DUCG technicians, 46 DUCG models
covering 54 chief complaints were constructed. Over 1,000 diseases can be
diagnosed without triage. Before being applied in real-world, the 46 DUCG
models were retrospectively verified by third-party hospitals. The verified
diagnostic precisions were no less than 95%, in which the diagnostic precision
for every disease including uncommon ones was no less than 80%. After
verifications, the 46 DUCG models were applied in the real-world in China. Over
one million real diagnosis cases have been performed, with only 17 incorrect
diagnoses identified. Due to DUCG's transparency, the mistakes causing the
incorrect diagnoses were found and corrected. The diagnostic abilities of the
clinicians who applied DUCG frequently were improved significantly. Following
the introduction to the earlier presented DUCG methodology, the recommendation
algorithm for potential medical checks is presented and the key idea of DUCG is
extracted.

æè¦ï¼<paragraph>é«çç§è­·ä¸­éè¦ AI è¼å©çè¨åºè¨ºæ·ãç¾æçæ·±åº¦å­¸ç¿æ¨¡åç¼ºä¹å¯è§£éæ§ï¼ä¸¦ä¸ä¸»è¦å°æ³¨æ¼å½±ååæãæè¿éç¼çåæä¸ç¢ºå®å æéä¿å (DUCG) æ¹æ³æ¯å æé©åçãå¯è§£éçï¼ä¸¦ä¸å¨ä¸åçæç¨å ´æ¯ä¸­æ¯ä¸è®çï¼æ²æè³ææ¶éãæ¨è¨ãæ¬åãé±ç§ãåè¦ãæ¦åãé«ææ¬åé«è½èçåé¡ãééè¨åºå°å®¶å DUCG æè¡äººå¡ä¹éçå¯ååä½ï¼æ§å»ºäºæ¶µè 54 åä¸»è¨´ç 46 å DUCG æ¨¡åãå¯ä»¥å¨æ²æåæµçææ³ä¸è¨ºæ·åº 1,000 å¤ç¨®ç¾çãå¨æç¨æ¼å¯¦éä¸çä¹åï¼46 å DUCG æ¨¡åå·²ç±ç¬¬ä¸æ¹é«é¢åæº¯æ§é©è­ãé©è­çè¨ºæ·ç²¾åº¦ä¸ä½æ¼ 95%ï¼å¶ä¸­åæ¬ç½è¦ç¾çå¨å§çæ¯ç¨®ç¾ççè¨ºæ·ç²¾åº¦ä¸ä½æ¼ 80%ãé©è­å¾ï¼46 å DUCG æ¨¡åå·²å¨ä¸­åå¯¦éæç¨ãå·²ç¶å·è¡äºè¶éä¸ç¾è¬åçå¯¦è¨ºæ·æ¡ä¾ï¼åç¼ç¾ 17 åä¸æ­£ç¢ºçè¨ºæ·ãç±æ¼ DUCG çéææ§ï¼ç¼ç¾ä¸¦ç³¾æ­£äºå°è´ä¸æ­£ç¢ºè¨ºæ·çé¯èª¤ãé »ç¹æç¨ DUCG çè¨åºé«ççè¨ºæ·è½åå¾å°äºé¡¯èæé«ãå¨ä»ç´¹äºåé¢æåºç DUCG æ¹æ³è«ä¹å¾ï¼æåºäºæ½å¨å¥åº·æª¢æ¥çæ¨è¦æ¼ç®æ³ï¼ä¸¦æåäº DUCG çééµææ³ã</paragraph>

##### **Advancing Histopathology-Based Breast Cancer Diagnosis: Insights into Multi-Modality and Explainability**
2406.12897v1 by Faseela Abdullakutty, Younes Akbari, Somaya Al-Maadeed, Ahmed Bouridane, Rifat Hamoudi

It is imperative that breast cancer is detected precisely and timely to
improve patient outcomes. Diagnostic methodologies have traditionally relied on
unimodal approaches; however, medical data analytics is integrating diverse
data sources beyond conventional imaging. Using multi-modal techniques,
integrating both image and non-image data, marks a transformative advancement
in breast cancer diagnosis. The purpose of this review is to explore the
burgeoning field of multimodal techniques, particularly the fusion of
histopathology images with non-image data. Further, Explainable AI (XAI) will
be used to elucidate the decision-making processes of complex algorithms,
emphasizing the necessity of explainability in diagnostic processes. This
review utilizes multi-modal data and emphasizes explainability to enhance
diagnostic accuracy, clinician confidence, and patient engagement, ultimately
fostering more personalized treatment strategies for breast cancer, while also
identifying research gaps in multi-modality and explainability, guiding future
studies, and contributing to the strategic direction of the field.

æè¦ï¼ç²¾ç¢ºä¸åæå°åµæ¸¬ä¹³çå°æ¼æ¹åæ£èé å¾è³ééè¦ãè¨ºæ·æ¹æ³å³çµ±ä¸ä¾è³´æ¼å®ä¸æ¨¡å¼æ¹æ³ï¼ç¶èï¼é«çè³æåææ­£å¨æ´åè¶è¶å³çµ±å½±åçåç¨®è³æä¾æºãä½¿ç¨æ´åå½±ååéå½±åè³æçå¤æ¨¡å¼æè¡ï¼æ¨èªèä¹³çè¨ºæ·çè®é©æ§é²å±ãæ¬ç¯ç¶è¿°çç®çæ¯æ¢è¨å¤æ¨¡å¼æè¡çæ°èé åï¼ç¹å¥æ¯å°çµç¹ççå­¸å½±åèéå½±åè³æèåãæ­¤å¤ï¼å¯è§£éäººå·¥æºæ§ (XAI) å°ç¨æ¼é¡æè¤éæ¼ç®æ³çæ±ºç­éç¨ï¼å¼·èª¿è¨ºæ·éç¨ä¸­å¯è§£éæ§çå¿è¦æ§ãæ¬ç¶è¿°å©ç¨å¤æ¨¡å¼è³æä¸¦å¼·èª¿å¯è§£éæ§ï¼ä»¥æé«è¨ºæ·æºç¢ºæ§ãè¨åºé«å¸«çä¿¡å¿åæ£èåèåº¦ï¼æçµä¿é²ä¹³çæ´åäººåçæ²»çç­ç¥ï¼åæä¹æ¾åºå¤æ¨¡å¼åå¯è§£éæ§çç ç©¶å·®è·ï¼å¼å°æªä¾çç ç©¶ï¼ä¸¦çºè©²é åçç­ç¥æ¹åååºè²¢ç»ã

##### **Revisiting Attention Weights as Interpretations of Message-Passing Neural Networks**
2406.04612v1 by Yong-Min Shin, Siqing Li, Xin Cao, Won-Yong Shin

The self-attention mechanism has been adopted in several widely-used
message-passing neural networks (MPNNs) (e.g., GATs), which adaptively controls
the amount of information that flows along the edges of the underlying graph.
This usage of attention has made such models a baseline for studies on
explainable AI (XAI) since interpretations via attention have been popularized
in various domains (e.g., natural language processing and computer vision).
However, existing studies often use naive calculations to derive attribution
scores from attention, and do not take the precise and careful calculation of
edge attribution into consideration. In our study, we aim to fill the gap
between the widespread usage of attention-enabled MPNNs and their potential in
largely under-explored explainability, a topic that has been actively
investigated in other areas. To this end, as the first attempt, we formalize
the problem of edge attribution from attention weights in GNNs. Then, we
propose GATT, an edge attribution calculation method built upon the computation
tree. Through comprehensive experiments, we demonstrate the effectiveness of
our proposed method when evaluating attributions from GATs. Conversely, we
empirically validate that simply averaging attention weights over graph
attention layers is insufficient to interpret the GAT model's behavior. Code is
publicly available at https://github.com/jordan7186/GAtt/tree/main.

æè¦ï¼èªæ³¨æåæ©å¶å·²è¢«æ¡ç¨æ¼å¤åå»£æ³ä½¿ç¨çè¨æ¯å³éç¥ç¶ç¶²è·¯ (MPNN)ï¼ä¾å¦ GATï¼ï¼å®å¯ä»¥èªé©æå°æ§å¶æ²¿èåºå±¤åå½¢éç·£æµåçè³è¨éãéç¨®æ³¨æåçä½¿ç¨ä½¿å¾æ­¤é¡æ¨¡åæçºå¯è§£é AI (XAI) ç ç©¶çåºç·ï¼å çºééæ³¨æåçè©®éå·²å¨åç¨®é åï¼ä¾å¦èªç¶èªè¨èçåé»è¦è¦è¦ºï¼ä¸­æ®åãç¶èï¼ç¾æçç ç©¶éå¸¸ä½¿ç¨å¤©ççè¨ç®æ¹æ³å¾æ³¨æåä¸­æ¨å°åºæ­¸å åæ¸ï¼ä¸¦ä¸æ²æèæ®å°éç·£æ­¸å çç²¾ç¢ºä¸ä»ç´°çè¨ç®ãå¨æåçç ç©¶ä¸­ï¼æåæ¨å¨å¡«è£æ³¨æååç¨ MPNN çå»£æ³ä½¿ç¨èå®åå¨å¾å¤§ç¨åº¦ä¸æªè¢«ååæ¢ç´¢çå¯è§£éæ§ä¹éçå·®è·ï¼éåä¸»é¡å·²å¨å¶ä»é åç©æ¥µç ç©¶ãçºæ­¤ï¼ä½çºç¬¬ä¸æ¬¡åè©¦ï¼æåå° GNN ä¸­æ³¨æåæ¬éçéç·£æ­¸å åé¡å½¢å¼åãç¶å¾ï¼æåæåº GATTï¼ä¸ç¨®å»ºç«å¨è¨ç®æ¨¹ä¸çéç·£æ­¸å è¨ç®æ¹æ³ãééå¨é¢çå¯¦é©ï¼æåå±ç¤ºäºæåæåºçæ¹æ³å¨è©ä¼° GAT çæ­¸å ææå·æçææãç¸åå°ï¼æåæç¶é©é©è­äºåå°åæ³¨æåå±¤ä¸çæ³¨æåæ¬éåå¹³åå¼ä¸è¶³ä»¥è©®é GAT æ¨¡åçè¡çºãç¨å¼ç¢¼å·²å¬éæ¼ https://github.com/jordan7186/GAtt/tree/mainã

##### **Using Explainable AI for EEG-based Reduced Montage Neonatal Seizure Detection**
2406.16908v3 by Dinuka Sandun Udayantha, Kavindu Weerasinghe, Nima Wickramasinghe, Akila Abeyratne, Kithmin Wickremasinghe, Jithangi Wanigasinghe, Anjula De Silva, Chamira U. S. Edussooriya

The neonatal period is the most vulnerable time for the development of
seizures. Seizures in the immature brain lead to detrimental consequences,
therefore require early diagnosis. The gold-standard for neonatal seizure
detection currently relies on continuous video-EEG monitoring; which involves
recording multi-channel electroencephalogram (EEG) alongside real-time video
monitoring within a neonatal intensive care unit (NICU). However, video-EEG
monitoring technology requires clinical expertise and is often limited to
technologically advanced and resourceful settings. Cost-effective new
techniques could help the medical fraternity make an accurate diagnosis and
advocate treatment without delay. In this work, a novel explainable deep
learning model to automate the neonatal seizure detection process with a
reduced EEG montage is proposed, which employs convolutional nets, graph
attention layers, and fully connected layers. Beyond its ability to detect
seizures in real-time with a reduced montage, this model offers the unique
advantage of real-time interpretability. By evaluating the performance on the
Zenodo dataset with 10-fold cross-validation, the presented model achieves an
absolute improvement of 8.31% and 42.86% in area under curve (AUC) and recall,
respectively.

æè¦ï¼æ°çåææ¯å¤§è¦ç¼è²æèå¼±çææï¼å®¹æåºç¾ç²çç¼ä½ãå¤§è¦ç¼è²ä¸æçæåºç¾ç²çç¼ä½æé æä¸è¯å¾æï¼å æ­¤éè¦åæ©è¨ºæ·ãç®åæ°çåç²çç¼ä½çé»éæ¨æºä¾è³´æ¼é£çºçè¦è¨è¦é»å (EEG) ç£æ¸¬ï¼å¶ä¸­åæ¬å¨æ°çåå è­·çæ¿ (NICU) å§åæé²è¡å¤é »éè¦é»å (EEG) è¨éåå³æè¦è¨ç£æ§ãç¶èï¼è¦è¨è¦é»åç£æ§æè¡éè¦è¨åºå°æ¥­ç¥è­ï¼èä¸éå¸¸åéæ¼æè¡åé²ä¸è³æºè±å¯çç°å¢ãå·ææ¬æççæ°æè¡å¯ä»¥å¹«å©é«ççæºç¢ºè¨ºæ·ä¸¦ç«å³æå¡æ²»çãå¨éé å·¥ä½ä¸­ï¼æåºäºä¸åæ°ç©çå¯è§£éæ·±åº¦å­¸ç¿æ¨¡åï¼ä»¥èªååæ°çåç²çç¼ä½åµæ¸¬éç¨ï¼ä¸¦æ¡ç¨æ¸å°çè¦é»åè£ç½®ï¼å¶ä¸­æ¡ç¨äºå·ç©ç¥ç¶ç¶²è·¯ãåå½¢æ³¨æåå±¤åå¨é£æ¥å±¤ãé¤äºè½å¤ ä½¿ç¨æ¸å°çè£ç½®å³æåµæ¸¬ç²çç¼ä½å¤ï¼æ­¤æ¨¡åéæä¾äºå³æå¯è§£éæ§çç¨ç¹åªå¢ãééå¨ Zenodo è³æéä¸ä½¿ç¨ 10 åäº¤åé©è­è©ä¼°æè½ï¼ææåºçæ¨¡åå¨æ²ç·ä¸é¢ç© (AUC) åå¬åçæ¹é¢åå¥éå°äº 8.31% å 42.86% ççµå°æ¹åã

##### **Breast Cancer Diagnosis: A Comprehensive Exploration of Explainable Artificial Intelligence (XAI) Techniques**
2406.00532v1 by Samita Bai, Sidra Nasir, Rizwan Ahmed Khan, Sheeraz Arif, Alexandre Meyer, Hubert Konik

Breast cancer (BC) stands as one of the most common malignancies affecting
women worldwide, necessitating advancements in diagnostic methodologies for
better clinical outcomes. This article provides a comprehensive exploration of
the application of Explainable Artificial Intelligence (XAI) techniques in the
detection and diagnosis of breast cancer. As Artificial Intelligence (AI)
technologies continue to permeate the healthcare sector, particularly in
oncology, the need for transparent and interpretable models becomes imperative
to enhance clinical decision-making and patient care. This review discusses the
integration of various XAI approaches, such as SHAP, LIME, Grad-CAM, and
others, with machine learning and deep learning models utilized in breast
cancer detection and classification. By investigating the modalities of breast
cancer datasets, including mammograms, ultrasounds and their processing with
AI, the paper highlights how XAI can lead to more accurate diagnoses and
personalized treatment plans. It also examines the challenges in implementing
these techniques and the importance of developing standardized metrics for
evaluating XAI's effectiveness in clinical settings. Through detailed analysis
and discussion, this article aims to highlight the potential of XAI in bridging
the gap between complex AI models and practical healthcare applications,
thereby fostering trust and understanding among medical professionals and
improving patient outcomes.

æè¦ï¼ä¹³ç (BC) æ¯å½±é¿å¨çå¥³æ§æå¸¸è¦çæ¡æ§è«ç¤ä¹ä¸ï¼å æ­¤éè¦é²æ­¥çè¨ºæ·æ¹æ³ï¼ä»¥æ¹åè¨åºçµæãæ¬æå¨é¢æ¢è¨äºå¯è§£éäººå·¥æºæ§ (XAI) æè¡å¨ä¹³çåµæ¸¬åè¨ºæ·ä¸­çæç¨ãé¨èäººå·¥æºæ§ (AI) æè¡æçºæ»²éé«çä¿å¥é åï¼ç¹å¥æ¯å¨è«ç¤å­¸ä¸­ï¼éæä¸å¯è§£éçæ¨¡åéæ±è®å¾å¢å¨å¿è¡ï¼ä»¥å¢å¼·è¨åºæ±ºç­å¶å®åæ£èç§è­·ãæ­¤ç¯è©è«æ¢è¨äºåç¨® XAI æ¹æ³çæ´åï¼ä¾å¦ SHAPãLIMEãGrad-CAM ç­ï¼ä»¥åç¨æ¼ä¹³çåµæ¸¬ååé¡çæ©å¨å­¸ç¿åæ·±åº¦å­¸ç¿æ¨¡åãééæ¢è¨ä¹³çè³æéçæ¨¡å¼ï¼åæ¬ä¹³æ¿æå½±ãè¶é³æ³¢åå¶å¨ AI ä¸­çèçï¼æ¬æéé»èªªæ XAI å¦ä½è½å°è´æ´æºç¢ºçè¨ºæ·ååäººåæ²»çè¨ç«ãå®ä¹æ¢è¨äºå¯¦æ½éäºæè¡çææ°ï¼ä»¥åå¶å®æ¨æºåè©éææ¨ä»¥è©ä¼° XAI å¨è¨åºç°å¢ä¸­çæææ§çéè¦æ§ãééè©³ç´°çåæåè¨è«ï¼æ¬ææ¨å¨å¼·èª¿ XAI å¨ç¸®å°è¤é AI æ¨¡åèå¯¦åé«çä¿å¥æç¨ä¹éå·®è·çæ½åï¼é²èä¿é²é«çå°æ¥­äººå¡ä¹éçä¿¡ä»»èçè§£ï¼ä¸¦æ¹åæ£èççµæã

##### **Unveiling Hidden Factors: Explainable AI for Feature Boosting in Speech Emotion Recognition**
2406.01624v2 by Alaa Nfissi, Wassim Bouachir, Nizar Bouguila, Brian Mishara

Speech emotion recognition (SER) has gained significant attention due to its
several application fields, such as mental health, education, and
human-computer interaction. However, the accuracy of SER systems is hindered by
high-dimensional feature sets that may contain irrelevant and redundant
information. To overcome this challenge, this study proposes an iterative
feature boosting approach for SER that emphasizes feature relevance and
explainability to enhance machine learning model performance. Our approach
involves meticulous feature selection and analysis to build efficient SER
systems. In addressing our main problem through model explainability, we employ
a feature evaluation loop with Shapley values to iteratively refine feature
sets. This process strikes a balance between model performance and
transparency, which enables a comprehensive understanding of the model's
predictions. The proposed approach offers several advantages, including the
identification and removal of irrelevant and redundant features, leading to a
more effective model. Additionally, it promotes explainability, facilitating
comprehension of the model's predictions and the identification of crucial
features for emotion determination. The effectiveness of the proposed method is
validated on the SER benchmarks of the Toronto emotional speech set (TESS),
Berlin Database of Emotional Speech (EMO-DB), Ryerson Audio-Visual Database of
Emotional Speech and Song (RAVDESS), and Surrey Audio-Visual Expressed Emotion
(SAVEE) datasets, outperforming state-of-the-art methods. To the best of our
knowledge, this is the first work to incorporate model explainability into an
SER framework. The source code of this paper is publicly available via this
https://github.com/alaaNfissi/Unveiling-Hidden-Factors-Explainable-AI-for-Feature-Boosting-in-Speech-Emotion-Recognition.

æè¦ï¼èªé³æç·è¾¨è­ (SER) ç±æ¼å¶å¨å¿çå¥åº·ãæè²åäººæ©äºåç­å¤åæç¨é åèååéæ³¨ãç¶èï¼SER ç³»çµ±çæºç¢ºæ§åå°é«ç¶­ç¹å¾µéçé»ç¤ï¼éäºç¹å¾µéå¯è½åå«ä¸ç¸éååé¤çè³è¨ãçºäºåæéåææ°ï¼æ¬ç ç©¶æåºäºä¸ç¨®ç¨æ¼ SER çè¿­ä»£ç¹å¾µæåæ¹æ³ï¼è©²æ¹æ³å¼·èª¿ç¹å¾µç¸éæ§åå¯è§£éæ§ï¼ä»¥å¢å¼·æ©å¨å­¸ç¿æ¨¡åçæè½ãæåçåæ³æ¶åä»ç´°çç¹å¾µé¸æååæï¼ä»¥å»ºç«é«æç SER ç³»çµ±ãçºäºééæ¨¡åå¯è§£éæ§è§£æ±ºæåçæ ¸å¿åé¡ï¼æåæ¡ç¨äºå·æ Shapley å¼çç¹å¾µè©ä¼°è¿´åï¼ä»¥åè¦æ¹åç¹å¾µéãéåéç¨å¨æ¨¡åæè½åéæåº¦ä¹éåå¾å¹³è¡¡ï¼éä½¿å¾æåè½å¤ å¨é¢äºè§£æ¨¡åçé æ¸¬ãææåºçæ¹æ³æä¾äºå¤é åªé»ï¼åæ¬è­å¥åç§»é¤ä¸ç¸éååé¤çç¹å¾µï¼å¾èå»ºç«æ´ææçæ¨¡åãæ­¤å¤ï¼å®ä¿é²äºå¯è§£éæ§ï¼æå©æ¼çè§£æ¨¡åçé æ¸¬ä»¥åè­å¥æç·æ±ºå®çééµç¹å¾µãææåºçæ¹æ³çæææ§å·²å¨å¤å«å¤æç·èªé³é (TESS)ãæææç·èªé³è³æåº« (EMO-DB)ãè³´ç¾æ£®é³è¨è¦è¦ºæç·èªé³åæ­æ²è³æåº« (RAVDESS) åè©éé³è¨è¦è¦ºè¡¨éæç· (SAVEE) è³æéç SER åºæºä¸å¾å°é©è­ï¼å¶æè½åªæ¼ç¾ææ¹æ³ãææåæç¥ï¼éæ¯ç¬¬ä¸åå°æ¨¡åå¯è§£éæ§ç´å¥ SER æ¶æ§çç ç©¶ãæ¬æçåå§ç¢¼å¯ééæ­¤é£çµå¬éåå¾ï¼https://github.com/alaaNfissi/Unveiling-Hidden-Factors-Explainable-AI-for-Feature-Boosting-in-Speech-Emotion-Recognitionã

##### **The Explanation Necessity for Healthcare AI**
2406.00216v1 by Michail Mamalakis, HÃ©loÃ¯se de Vareilles, Graham Murray, Pietro Lio, John Suckling

Explainability is often critical to the acceptable implementation of
artificial intelligence (AI). Nowhere is this more important than healthcare
where decision-making directly impacts patients and trust in AI systems is
essential. This trust is often built on the explanations and interpretations
the AI provides. Despite significant advancements in AI interpretability, there
remains the need for clear guidelines on when and to what extent explanations
are necessary in the medical context. We propose a novel categorization system
with four distinct classes of explanation necessity, guiding the level of
explanation required: patient or sample (local) level, cohort or dataset
(global) level, or both levels. We introduce a mathematical formulation that
distinguishes these categories and offers a practical framework for researchers
to determine the necessity and depth of explanations required in medical AI
applications. Three key factors are considered: the robustness of the
evaluation protocol, the variability of expert observations, and the
representation dimensionality of the application. In this perspective, we
address the question: When does an AI medical application need to be explained,
and at what level of detail?

æè¦ï¼å¯è§£éæ§éå¸¸å¯¹äºäººå·¥æºè½ (AI) çå¯æ¥åå®æ½è³å³éè¦ãå¨å»çä¿å¥é¢åï¼è¿ä¸ç¹å°¤ä¸ºéè¦ï¼å ä¸ºå³ç­ç´æ¥å½±åæ£èï¼å¹¶ä¸å¯¹ AI ç³»ç»çä¿¡ä»»è³å³éè¦ãè¿ç§ä¿¡ä»»éå¸¸å»ºç«å¨ AI æä¾çè§£éåè¯ éä¹ä¸ãå°½ç®¡ AI å¯è§£éæ§åå¾äºéå¤§è¿å±ï¼ä½ä»ç¶éè¦æç¡®çæå¯¼æ¹éï¼è¯´æå¨å»çç¯å¢ä¸­ä½æ¶ä»¥åå¨å¤å¤§ç¨åº¦ä¸éè¦è§£éãæä»¬æåºäºä¸ç§æ°é¢çåç±»ç³»ç»ï¼è¯¥ç³»ç»å·æåç§ä¸åçè§£éå¿è¦æ§ç±»å«ï¼æå¯¼æéçè§£éçº§å«ï¼æ£èææ ·æ¬ï¼å±é¨ï¼çº§å«ãéåææ°æ®éï¼å¨å±ï¼çº§å«ï¼æä¸¤ä¸ªçº§å«ãæä»¬å¼å¥äºä¸ä¸ªæ°å­¦å¬å¼ï¼è¯¥å¬å¼åºåäºè¿äºç±»å«ï¼å¹¶ä¸ºç ç©¶äººåæä¾äºä¸ä¸ªå®ç¨æ¡æ¶ï¼ä»¥ç¡®å®å»ç AI åºç¨ä¸­æéçè§£éçå¿è¦æ§åæ·±åº¦ãèèäºä¸ä¸ªå³é®å ç´ ï¼è¯ä¼°åè®®çç¨³å¥æ§ãä¸å®¶è§å¯çå¯åæ§ä»¥ååºç¨ç¨åºçè¡¨ç¤ºç»´æ°ãä»è¿ä¸ªè§åº¦æ¥çï¼æä»¬è§£å³äºè¿ä¸ªé®é¢ï¼AI å»çåºç¨ä½æ¶éè¦è§£éï¼ä»¥åéè¦è§£éå°ä½ç§ç¨åº¦ï¼

##### **Interdisciplinary Expertise to Advance Equitable Explainable AI**
2406.18563v1 by Chloe R. Bennett, Heather Cole-Lewis, Stephanie Farquhar, Naama Haamel, Boris Babenko, Oran Lang, Mat Fleck, Ilana Traynis, Charles Lau, Ivor Horn, Courtney Lyles

The field of artificial intelligence (AI) is rapidly influencing health and
healthcare, but bias and poor performance persists for populations who face
widespread structural oppression. Previous work has clearly outlined the need
for more rigorous attention to data representativeness and model performance to
advance equity and reduce bias. However, there is an opportunity to also
improve the explainability of AI by leveraging best practices of social
epidemiology and health equity to help us develop hypotheses for associations
found. In this paper, we focus on explainable AI (XAI) and describe a framework
for interdisciplinary expert panel review to discuss and critically assess AI
model explanations from multiple perspectives and identify areas of bias and
directions for future research. We emphasize the importance of the
interdisciplinary expert panel to produce more accurate, equitable
interpretations which are historically and contextually informed.
Interdisciplinary panel discussions can help reduce bias, identify potential
confounders, and identify opportunities for additional research where there are
gaps in the literature. In turn, these insights can suggest opportunities for
AI model improvement.

æè¦ï¼äººå·¥æºæ§ (AI) é åæ­£å¿«éå½±é¿èå¥åº·èé«çä¿å¥ï¼ä½å°æ¼é¢è¨å»£æ³çµæ§æ§å£è¿«çäººç¾¤ä¾èªªï¼åè¦åä¸è¯è¡¨ç¾ä¾ç¶å­å¨ãååçç ç©¶å·²æ¸æ¥èªªæï¼éè¦æ´å´æ ¼å°æ³¨æè³æä»£è¡¨æ§åæ¨¡åæè½ï¼ä»¥ä¿é²å¬å¹³æ§ä¸¦æ¸å°åè¦ãç¶èï¼æåææ©æéééç¨ç¤¾ææµè¡çå­¸åå¥åº·å¬å¹³çæä½³å¯¦åï¼ä¾æ¹å AI çå¯è§£éæ§ï¼ä»¥å¹«å©æåéå°ç¼ç¾çéè¯æ§ï¼ç¼å±åè¨­ãå¨æ¬æä¸­ï¼æåå°æ³¨æ¼å¯è§£é AI (XAI)ï¼ä¸¦æè¿°ä¸åè·¨é åå°å®¶å°çµå¯©æ¥æ¶æ§ï¼ä»¥å¾å¤éè§é»è¨è«åæ¹å¤æ§è©ä¼° AI æ¨¡åçè§£éï¼ä¸¦æ¾åºåè¦é ååæªä¾ç ç©¶çæ¹åãæåå¼·èª¿è·¨é åå°å®¶å°çµå°æ¼ç¢çæ´æºç¢ºãå¬å¹³çè©®éè³ééè¦ï¼èéäºè©®éæ¯æ ¹ææ­·å²åèçµ¡èä¾çãè·¨é åå°çµè¨è«æå©æ¼æ¸å°åè¦ãæ¾åºæ½å¨çæ··æ·å ç´ ï¼ä¸¦å¨æç»ä¸­æç¼ºå£ææ¾åºé¡å¤ç ç©¶çæ©æãåéä¾ï¼éäºè¦è§£å¯ä»¥å»ºè­° AI æ¨¡åæ¹é²çæ©æã

##### **"It depends": Configuring AI to Improve Clinical Usefulness Across Contexts**
2407.11978v1 by Hubert D. ZajÄc, Jorge M. N. Ribeiro, Silvia Ingala, Simona Gentile, Ruth Wanjohi, Samuel N. Gitau, Jonathan F. Carlsen, Michael B. Nielsen, Tariq O. Andersen

Artificial Intelligence (AI) repeatedly match or outperform radiologists in
lab experiments. However, real-world implementations of radiological AI-based
systems are found to provide little to no clinical value. This paper explores
how to design AI for clinical usefulness in different contexts. We conducted 19
design sessions and design interventions with 13 radiologists from 7 clinical
sites in Denmark and Kenya, based on three iterations of a functional AI-based
prototype. Ten sociotechnical dependencies were identified as crucial for the
design of AI in radiology. We conceptualised four technical dimensions that
must be configured to the intended clinical context of use: AI functionality,
AI medical focus, AI decision threshold, and AI Explainability. We present four
design recommendations on how to address dependencies pertaining to the medical
knowledge, clinic type, user expertise level, patient context, and user
situation that condition the configuration of these technical dimensions.

æè¦ï¼äººå·¥æºæ§ï¼AIï¼å¨å¯¦é©å®¤å¯¦é©ä¸­ä¸æ·å°èæ¾å°ç§é«å¸«å¹æµæè¡¨ç¾å¾æ´åºè²ãç¶èï¼ç¼ç¾æ¾å°ç§ AI çºåºç¤ç³»çµ±çå¯¦éå·è¡å¹¾ä¹æ²ææä¾è¨åºå¹å¼ãæ¬ææ¢è¨å¦ä½çº AI è¨­è¨å¨ä¸åæå¢ä¸­è¨åºä¸çæç¨ãæåæ ¹æåè½æ§ AI çºåºç¤ååçä¸æ¬¡è¿­ä»£ï¼å¨ä¸¹éº¥åè¯äºç 7 åè¨åºå ´åè 13 ä½æ¾å°ç§é«å¸«é²è¡äº 19 æ¬¡è¨­è¨æè­°åè¨­è¨ä»å¥ãååç¤¾ææè¡ä¾è³´éä¿è¢«èªçºå°æ¼æ¾å°ç§ä¸­ AI çè¨­è¨è³ééè¦ãæåæ¦å¿µåäºååæè¡é¢åï¼å¿é æ ¹æé æçè¨åºä½¿ç¨æå¢é²è¡è¨­å®ï¼AI åè½ãAI é«çéé»ãAI æ±ºç­éæª»ï¼ä»¥å AI å¯è§£éæ§ãæåæåºåé è¨­è¨å»ºè­°ï¼èªªæå¦ä½èçèé«çç¥è­ãè¨ºæé¡åãä½¿ç¨èå°æ¥­ç¥è­ç­ç´ãæ£èæå¢ï¼ä»¥åå½±é¿éäºæè¡é¢åè¨­å®çä½¿ç¨èæå¢ç¸éçä¾è³´éä¿ã

##### **Improving Health Professionals' Onboarding with AI and XAI for Trustworthy Human-AI Collaborative Decision Making**
2405.16424v1 by Min Hun Lee, Silvana Xin Yi Choo, Shamala D/O Thilarajah

With advanced AI/ML, there has been growing research on explainable AI (XAI)
and studies on how humans interact with AI and XAI for effective human-AI
collaborative decision-making. However, we still have a lack of understanding
of how AI systems and XAI should be first presented to users without technical
backgrounds. In this paper, we present the findings of semi-structured
interviews with health professionals (n=12) and students (n=4) majoring in
medicine and health to study how to improve onboarding with AI and XAI. For the
interviews, we built upon human-AI interaction guidelines to create onboarding
materials of an AI system for stroke rehabilitation assessment and AI
explanations and introduce them to the participants. Our findings reveal that
beyond presenting traditional performance metrics on AI, participants desired
benchmark information, the practical benefits of AI, and interaction trials to
better contextualize AI performance, and refine the objectives and performance
of AI. Based on these findings, we highlight directions for improving
onboarding with AI and XAI and human-AI collaborative decision-making.

æè¦ï¼é¨èåé²ç AI/MLï¼å°å¯è§£é AI (XAI) çç ç©¶ä¸æ·å¢å ï¼ä»¥åéæ¼äººé¡å¦ä½è AI å XAI äºåä»¥é²è¡ææçäººå·¥æºæ§åä½æ±ºç­å¶å®ãç¶èï¼æåä»ç¶ç¼ºä¹å° AI ç³»çµ±å XAI æå¦ä½é¦ååç¾çµ¦æ²ææè¡èæ¯çç¨æ¶çäºè§£ãå¨æ¬æä¸­ï¼æåå±ç¤ºäºèé«çå°æ¥­äººå¡ (n=12) åä¸»ä¿®é«å­¸åå¥åº·çå­¸ç (n=4) é²è¡åçµæ§åè¨ªè«ççµæï¼ä»¥ç ç©¶å¦ä½æ¹å AI å XAI çå¥éãå°æ¼è¨ªè«ï¼æåå»ºç«å¨äººæ©äºåæºåä¹ä¸ï¼çºä¸­é¢¨åº·å¾©è©ä¼°å AI è§£éç AI ç³»çµ±åµå»ºå¥éææï¼ä¸¦å°å®åä»ç´¹çµ¦åèèãæåçç ç©¶çµæè¡¨æï¼é¤äºåç¾å³çµ±ç AI æ§è½ææ¨å¤ï¼åèèéå¸æåºåä¿¡æ¯ãAI çå¯¦éå¥½èä»¥åäº¤äºè©¦é©ï¼ä»¥æ´å¥½å°å° AI æ§è½æå¢åï¼ä¸¦å®å AI çç®æ¨åæ§è½ãæ ¹æéäºç¼ç¾ï¼æåå¼·èª¿äºæ¹é² AI å XAI ä»¥åäººæ©åä½æ±ºç­å¶å®çå¥éæ¹åã

##### **Exploring Nutritional Impact on Alzheimer's Mortality: An Explainable AI Approach**
2405.17502v1 by Ziming Liu, Longjian Liu, Robert E. Heidel, Xiaopeng Zhao

This article uses machine learning (ML) and explainable artificial
intelligence (XAI) techniques to investigate the relationship between
nutritional status and mortality rates associated with Alzheimers disease (AD).
The Third National Health and Nutrition Examination Survey (NHANES III)
database is employed for analysis. The random forest model is selected as the
base model for XAI analysis, and the Shapley Additive Explanations (SHAP)
method is used to assess feature importance. The results highlight significant
nutritional factors such as serum vitamin B12 and glycated hemoglobin. The
study demonstrates the effectiveness of random forests in predicting AD
mortality compared to other diseases. This research provides insights into the
impact of nutrition on AD and contributes to a deeper understanding of disease
progression.

æè¦ï¼æ¬æä½¿ç¨æ©å¨å­¸ç¿ (ML) åå¯è§£éäººå·¥æºæ§ (XAI) æè¡ä¾æ¢è¨çé¤çæ³èé¿è²æµ·é»ç (AD) ç¸éçæ­»äº¡çä¹éçéä¿ãæ¡ç¨ç¬¬ä¸æ¬¡å¨åå¥åº·èçé¤æª¢æ¥èª¿æ¥ (NHANES III) è³æåº«é²è¡åæãé¸æé¨æ©æ£®ææ¨¡åä½çº XAI åæçåºç¤æ¨¡åï¼ä¸¦ä½¿ç¨ Shapley Additive Explanations (SHAP) æ¹æ³ä¾è©ä¼°ç¹å¾µéè¦æ§ãçµæçªé¡¯äºéè¦ççé¤å ç´ ï¼ä¾å¦è¡æ¸ç¶­çç´  B12 åç³åè¡ç´èç½ãè©²ç ç©¶è­æäºé¨æ©æ£®æå¨é æ¸¬ AD æ­»äº¡çæ¹é¢ç¸è¼æ¼å¶ä»ç¾ççæææ§ãæ¬ç ç©¶æä¾äºçé¤å° AD çå½±é¿çè¦è§£ï¼ä¸¦æå©æ¼æ´æ·±å¥å°äºè§£ç¾ççé²å±ã

##### **Explainable AI Enhances Glaucoma Referrals, Yet the Human-AI Team Still Falls Short of the AI Alone**
2407.11974v1 by Catalina Gomez, Ruolin Wang, Katharina Breininger, Corinne Casey, Chris Bradley, Mitchell Pavlak, Alex Pham, Jithin Yohannan, Mathias Unberath

Primary care providers are vital for initial triage and referrals to
specialty care. In glaucoma, asymptomatic and fast progression can lead to
vision loss, necessitating timely referrals to specialists. However, primary
eye care providers may not identify urgent cases, potentially delaying care.
Artificial Intelligence (AI) offering explanations could enhance their referral
decisions. We investigate how various AI explanations help providers
distinguish between patients needing immediate or non-urgent specialist
referrals. We built explainable AI algorithms to predict glaucoma surgery needs
from routine eyecare data as a proxy for identifying high-risk patients. We
incorporated intrinsic and post-hoc explainability and conducted an online
study with optometrists to assess human-AI team performance, measuring referral
accuracy and analyzing interactions with AI, including agreement rates, task
time, and user experience perceptions. AI support enhanced referral accuracy
among 87 participants (59.9%/50.8% with/without AI), though Human-AI teams
underperformed compared to AI alone. Participants believed they included AI
advice more when using the intrinsic model, and perceived it more useful and
promising. Without explanations, deviations from AI recommendations increased.
AI support did not increase workload, confidence, and trust, but reduced
challenges. On a separate test set, our black-box and intrinsic models achieved
an accuracy of 77% and 71%, respectively, in predicting surgical outcomes. We
identify opportunities of human-AI teaming for glaucoma management in primary
eye care, noting that while AI enhances referral accuracy, it also shows a
performance gap compared to AI alone, even with explanations. Human involvement
remains essential in medical decision making, underscoring the need for future
research to optimize collaboration, ensuring positive experiences and safe AI
use.

æè¦ï¼<paragraph>åç´ä¿å¥æä¾èå°æ¼æåçåæµåè½è¨ºå°å°ç§ç§è­·è³ééè¦ãå¨éåç¼çææ³ä¸ï¼ç¡ççä¸å¿«éæ¡åå¯è½å°è´è¦ååªå¤±ï¼å æ­¤éè¦åæè½è¨ºçµ¦å°å®¶ãç¶èï¼åç´ç¼ç§ä¿å¥æä¾èå¯è½ç¡æ³è­å¥ç·æ¥ææ³ï¼å¯è½æå»¶èª¤ç§è­·ãæä¾è§£éçäººå·¥æºæ§ (AI) å¯ä»¥å å¼·ä»åçè½è¨ºæ±ºç­ãæåç ç©¶åç¨® AI è§£éå¦ä½å¹«å©æä¾èååéè¦ç«å³æéç·æ¥å°ç§è½è¨ºçæ£èãæåå»ºç«äºè§£éæ§ AI æ¼ç®æ³ï¼ä»¥å¾ä¾è¡ç¼ç§è­·çè³æé æ¸¬éåç¼æè¡éæ±ï¼ä½çºè­å¥é«é¢¨éªæ£èçä»£çãæåç´å¥äºå§å¨åäºå¾è§£éæ§ï¼ä¸¦èé©åå¸«é²è¡äºä¸é ç·ä¸ç ç©¶ï¼ä»¥è©ä¼°äººæ©åéçè¡¨ç¾ï¼è¡¡éè½è¨ºæºç¢ºåº¦ä¸¦åæè AI çäºåï¼åæ¬åæçãä»»åæéåä½¿ç¨èé«é©æç¥ãå¨ 87 ååèèä¸­ï¼AI æ¯æ´æé«äºè½è¨ºæºç¢ºåº¦ï¼ä½¿ç¨ AI/æªä½¿ç¨çæ¯ä¾çº 59.9%/50.8%ï¼ï¼åç®¡äººæ©åéçè¡¨ç¾ä¸å¦å®ç¨ä½¿ç¨ AIãåèèèªçºä»åå¨ä½¿ç¨å§å¨æ¨¡åææ´å¤å°ç´å¥äº AI å»ºè­°ï¼ä¸¦èªçºå®æ´æç¨ä¸æ´æå¸æãæ²æè§£éï¼AI å»ºè­°çåå·®æå¢å ãAI æ¯æ´ä¸¦æªå¢å å·¥ä½éãä¿¡å¿åä¿¡ä»»ï¼ä½æ¸å°äºææ°ãå¨ä¸åå®ç¨çæ¸¬è©¦éä¸­ï¼æåçé»çå­åå§å¨æ¨¡åå¨é æ¸¬æè¡çµææ¹é¢åå¥éå°äº 77% å 71% çæºç¢ºåº¦ãæåæ¾åºå¨åç´ç¼ç§ä¿å¥ä¸­ï¼äººæ©åéåä½ç®¡çéåç¼çæ©æï¼ä¸¦æ³¨æå°éç¶ AI æé«äºè½è¨ºæºç¢ºåº¦ï¼ä½å³ä½¿æè§£éï¼å®ä¹é¡¯ç¤ºåºèå®ç¨ä½¿ç¨ AI ç¸æ¯çæè½å·®è·ãäººé¡åèå¨é«çæ±ºç­ä¸­ä»ç¶è³ééè¦ï¼éå¼·èª¿äºæªä¾ç ç©¶åªååä½ãç¢ºä¿æ­£é¢ç¶é©åå®å¨ä½¿ç¨ AI çå¿è¦æ§ã</paragraph>

##### **Decoding Decision Reasoning: A Counterfactual-Powered Model for Knowledge Discovery**
2406.18552v1 by Yingying Fang, Zihao Jin, Xiaodan Xing, Simon Walsh, Guang Yang

In medical imaging, particularly in early disease detection and prognosis
tasks, discerning the rationale behind an AI model's predictions is crucial for
evaluating the reliability of its decisions. Conventional explanation methods
face challenges in identifying discernible decisive features in medical image
classifications, where discriminative features are subtle or not immediately
apparent. To bridge this gap, we propose an explainable model that is equipped
with both decision reasoning and feature identification capabilities. Our
approach not only detects influential image patterns but also uncovers the
decisive features that drive the model's final predictions. By implementing our
method, we can efficiently identify and visualise class-specific features
leveraged by the data-driven model, providing insights into the decision-making
processes of deep learning models. We validated our model in the demanding
realm of medical prognosis task, demonstrating its efficacy and potential in
enhancing the reliability of AI in healthcare and in discovering new knowledge
in diseases where prognostic understanding is limited.

æè¦ï¼å¨é«å­¸å½±åä¸­ï¼ç¹å¥æ¯å¨æ©æç¾çæª¢æ¸¬åé å¾ä»»åä¸­ï¼è¾¨å¥ AI æ¨¡åé æ¸¬èå¾çåçå°æ¼è©ä¼°å¶æ±ºç­çå¯é æ§è³ééè¦ãå³çµ±çè§£éæ¹æ³å¨è­å¥é«å­¸å½±ååé¡ä¸­å¯è­å¥çæ±ºå®æ§ç¹å¾µæé¢è¨ææ°ï¼å¶ä¸­åå¥æ§ç¹å¾µå¾å¾®å¦æä¸¦ä¸æé¡¯ãçºäºå½åéä¸å·®è·ï¼æåæåºäºä¸åå¯è§£éçæ¨¡åï¼è©²æ¨¡åå·åæ±ºç­æ¨çåç¹å¾µè­å¥è½åãæåçåæ³ä¸åæª¢æ¸¬æå½±é¿åçå½±åæ¨¡å¼ï¼éæ­ç¤ºäºæ¨åæ¨¡åæçµé æ¸¬çæ±ºå®æ§ç¹å¾µãééå¯¦æ½æåçæ¨¡åï¼æåå¯ä»¥ææè­å¥åè¦è¦ºåç±æ¸æé©åæ¨¡åå©ç¨çé¡ç¹å®ç¹å¾µï¼å¾èæ·±å¥äºè§£æ·±åº¦å­¸ç¿æ¨¡åçæ±ºç­éç¨ãæåå¨è¦æ±å´æ ¼çé«å­¸é å¾ä»»åé åé©è­äºæåçæ¨¡åï¼å±ç¤ºäºå¶å¨æé« AI å¨é«çä¿å¥ä¸­çå¯é æ§åç¼ç¾é å¾çè§£åéç¾ççæ°ç¥è­æ¹é¢çåæåæ½åã

##### **The Role of Emotions in Informational Support Question-Response Pairs in Online Health Communities: A Multimodal Deep Learning Approach**
2405.13099v1 by Mohsen Jozani, Jason A. Williams, Ahmed Aleroud, Sarbottam Bhagat

This study explores the relationship between informational support seeking
questions, responses, and helpfulness ratings in online health communities. We
created a labeled data set of question-response pairs and developed multimodal
machine learning and deep learning models to reliably predict informational
support questions and responses. We employed explainable AI to reveal the
emotions embedded in informational support exchanges, demonstrating the
importance of emotion in providing informational support. This complex
interplay between emotional and informational support has not been previously
researched. The study refines social support theory and lays the groundwork for
the development of user decision aids. Further implications are discussed.

æè¦ï¼æ¬ç ç©¶æ¢è¨ç·ä¸å¥åº·ç¤¾ç¾¤ä¸­å°æ±è³è¨æ¯æçåé¡ãåæï¼ä»¥åæå¹«å©çè©åä¹éçéä¿ãæåå»ºç«äºä¸çµæ¨è¨çåç­éå°è³æéï¼ä¸¦éç¼äºå¤æ¨¡ææ©å¨å­¸ç¿åæ·±åº¦å­¸ç¿æ¨¡åï¼ä»¥å¯é å°é æ¸¬è³è¨æ¯æåé¡ååæãæåæ¡ç¨å¯è§£éç AI ä¾æ­ç¤ºè³è¨æ¯æäº¤æµä¸­èå«çæç·ï¼è­ææç·å¨æä¾è³è¨æ¯æä¸­çéè¦æ§ãéç¨®æç·æ¯æåè³è¨æ¯æä¹éçè¤éäº¤äºä½ç¨ä»¥åä¸¦æªè¢«ç ç©¶éãæ¬ç ç©¶æ¹é²äºç¤¾ææ¯æçè«ï¼ä¸¦çºä½¿ç¨èæ±ºç­è¼å©å·¥å·çéç¼å¥ å®äºåºç¤ãè¨è«äºé²ä¸æ­¥çå½±é¿ã

##### **ChatGPT in Classrooms: Transforming Challenges into Opportunities in Education**
2405.10645v1 by Harris Bin Munawar, Nikolaos Misirlis

In the era of exponential technology growth, one unexpected guest has claimed
a seat in classrooms worldwide, Artificial Intelligence. Generative AI, such as
ChatGPT, promises a revolution in education, yet it arrives with a double-edged
sword. Its potential for personalized learning is offset by issues of cheating,
inaccuracies, and educators struggling to incorporate it effectively into their
lesson design. We are standing on the brink of this educational frontier, and
it is clear that we need to navigate this terrain with a lot of care. This is a
major challenge that could undermine the integrity and value of our educational
process. So, how can we turn these challenges into opportunities? When used
inappropriately, AI tools can become the perfect tool for the cut copy paste
mentality, and quickly begin to corrode critical thinking, creativity, and deep
understanding, the most important skills in our rapidly changing world.
Teachers feel that they are not equipped to leverage this technology, widening
the digital divide among educators and institutions. Addressing these concerns
calls for an in depth research approach. We will employ empirical research,
drawing on the Technology Acceptance Model, to assess the attitudes toward
generative AI among educators and students. Understanding their perceptions,
usage patterns, and hurdles is the first crucial step in creating an effective
solution. The present study will be used as a process manual for future
researchers to apply, running their own data, based on the steps explained here

æè¦ï¼å¨ç§æé£éç¼å±çæä»£ï¼ä¸ä½æå¤çè¨ªå®¢å·²å¨å¨çæå®¤ä¸­ä½æä¸å¸­ä¹å°ï¼é£å°±æ¯äººå·¥æºæ§ãçæå¼ AIï¼ä¾å¦ ChatGPTï¼æ¿è«¾å¨æè²é åæèµ·ä¸å ´é©å½ï¼ä½å®å»æ¯ä¸æéé¢åãå®å¨åäººåå­¸ç¿æ¹é¢çæ½åï¼å»å ä½å¼ãä¸æºç¢ºä»¥åæè²å·¥ä½èé£ä»¥å°å¶ææèå¥æå­¸è¨­è¨ç­åé¡èæµé·ãæåæ­£ç«å¨éæè²åæ²¿çéç·£ï¼é¡¯ç¶æåéè¦éå¸¸å°å¿å°æ¢ç´¢éçé åãéæ¯ä¸åéå¤§çææ°ï¼å¯è½ææå®³æåæè²éç¨çå®æ´æ§åå¹å¼ãé£éº¼ï¼æåå¦ä½å°éäºææ°è½åçºæ©éï¼ç¶ä¸é©ç¶å°ä½¿ç¨æï¼AI å·¥å·å¯è½ææçºè¤è£½è²¼ä¸å¿æçå®ç¾å·¥å·ï¼ä¸¦è¿éèèæ¹å¤æ§æç¶­ãåµé ååæ·±å¥çè§£ï¼éäºé½æ¯æåå¿«éè®åçä¸çä¸­æéè¦çæè½ãæå¸«åè¦ºå¾ä»åæ²æè½åå©ç¨éé æè¡ï¼éæ´å¤§äºæè²å·¥ä½èåæ©æ§ä¹éçæ¸ä½é´»æºãè§£æ±ºéäºåé¡éè¦æ·±å¥çç ç©¶æ¹æ³ãæåå°æ¡ç¨å¯¦è­ç ç©¶ï¼åéæè¡æ¥åæ¨¡åï¼ä¾è©ä¼°æè²å·¥ä½èåå­¸çå°çæå¼ AI çæåº¦ãäºè§£ä»åççæ³ãä½¿ç¨æ¨¡å¼åéç¤æ¯åµé ææè§£æ±ºæ¹æ¡çç¬¬ä¸åééµæ­¥é©ãæ¬ç ç©¶å°ä½çºæªä¾ç ç©¶äººå¡æç¨çæµç¨æåï¼æ ¹ææ­¤èèªªæçæ­¥é©éè¡ä»åèªå·±çæ¸æ

##### **Evaluating the Explainable AI Method Grad-CAM for Breath Classification on Newborn Time Series Data**
2405.07590v1 by Camelia Oprea, Mike GrÃ¼ne, Mateusz Buglowski, Lena Olivier, Thorsten Orlikowsky, Stefan Kowalewski, Mark Schoberer, AndrÃ© Stollenwerk

With the digitalization of health care systems, artificial intelligence
becomes more present in medicine. Especially machine learning shows great
potential for complex tasks such as time series classification, usually at the
cost of transparency and comprehensibility. This leads to a lack of trust by
humans and thus hinders its active usage. Explainable artificial intelligence
tries to close this gap by providing insight into the decision-making process,
the actual usefulness of its different methods is however unclear. This paper
proposes a user study based evaluation of the explanation method Grad-CAM with
application to a neural network for the classification of breaths in time
series neonatal ventilation data. We present the perceived usefulness of the
explainability method by different stakeholders, exposing the difficulty to
achieve actual transparency and the wish for more in-depth explanations by many
of the participants.

æè¦ï¼é¨èé«çä¿å¥ç³»çµ±çæ¸ä½åï¼äººå·¥æºæ§å¨é«å­¸é åä¸­è®å¾æ´å æ®åãç¹å¥æ¯æ©å¨å­¸ç¿å¨æéåºååé¡ç­è¤éä»»åä¸­å±ç¾åºæ¥µå¤§çæ½åï¼ä½éå¸¸æ¯ä»¥éæåº¦åå¯çè§£æ§çºä»£å¹ãéå°è´äººé¡ç¼ºä¹ä¿¡ä»»ï¼å¾èé»ç¤äºå¶ç©æ¥µä½¿ç¨ãå¯è§£éçäººå·¥æºæ§è©¦åééæä¾å°æ±ºç­éç¨çæ´å¯ä¾å½è£éä¸å·®è·ï¼ä½å¶ä¸åæ¹æ³çå¯¦éæç¨å°ä¸æ¸æ¥ãæ¬ææåºäºä¸ååºæ¼ä½¿ç¨èç ç©¶çè©ä¼°ï¼å¶ä¸­åå«äº Grad-CAM è§£éæ¹æ³ï¼ä¸¦å°å¶æç¨æ¼ç¥ç¶ç¶²è·¯ä»¥åé¡æéåºåæ°çåå¼å¸æ¸æä¸­çå¼å¸ãæåå±ç¤ºäºä¸åå©çç¸éèå°å¯è§£éæ§æ¹æ³çæç¥æç¨ï¼æ­ç¤ºäºå¯¦ç¾å¯¦ééæåº¦çé£åº¦ï¼ä»¥åè¨±å¤åèèå¸æç²å¾æ´æ·±å¥çè§£éã

##### **XAI4LLM. Let Machine Learning Models and LLMs Collaborate for Enhanced In-Context Learning in Healthcare**
2405.06270v3 by Fatemeh Nazary, Yashar Deldjoo, Tommaso Di Noia, Eugenio di Sciascio

The integration of Large Language Models (LLMs) into healthcare diagnostics
offers a promising avenue for clinical decision-making. This study outlines the
development of a novel method for zero-shot/few-shot in-context learning (ICL)
by integrating medical domain knowledge using a multi-layered structured
prompt. We also explore the efficacy of two communication styles between the
user and LLMs: the Numerical Conversational (NC) style, which processes data
incrementally, and the Natural Language Single-Turn (NL-ST) style, which
employs long narrative prompts.
  Our study systematically evaluates the diagnostic accuracy and risk factors,
including gender bias and false negative rates, using a dataset of 920 patient
records in various few-shot scenarios. Results indicate that traditional
clinical machine learning (ML) models generally outperform LLMs in zero-shot
and few-shot settings. However, the performance gap narrows significantly when
employing few-shot examples alongside effective explainable AI (XAI) methods as
sources of domain knowledge. Moreover, with sufficient time and an increased
number of examples, the conversational style (NC) nearly matches the
performance of ML models. Most notably, LLMs demonstrate comparable or superior
cost-sensitive accuracy relative to ML models.
  This research confirms that, with appropriate domain knowledge and tailored
communication strategies, LLMs can significantly enhance diagnostic processes.
The findings highlight the importance of optimizing the number of training
examples and communication styles to improve accuracy and reduce biases in LLM
applications.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) èé«çè¨ºæ·æ´å
çºè¨åºæ±ºç­æä¾äºä¸åæåæ¯çéå¾ãæ¬ç ç©¶æ¦è¿°äºä¸ç¨®æ°ç©æ¹æ³çéç¼ï¼ç¨æ¼é¶æ¬¡å­¸ç¿/å°éå­¸ç¿æå¢å­¸ç¿ (ICL)ï¼æ¹æ³æ¯ä½¿ç¨å¤å±¤çµæ§åæç¤ºæ´åé«çé åç¥è­ãæåéæ¢è¨äºä½¿ç¨èè LLM ä¹éå©ç¨®æºéæ¹å¼çåæï¼æ¸å¼å°è©± (NC) æ¹å¼ï¼å®æéæ­¥èçè³æï¼ä»¥åèªç¶èªè¨å®åå (NL-ST) æ¹å¼ï¼å®æä½¿ç¨é·ç¯æäºæç¤ºã
æåçç ç©¶ç³»çµ±æ§å°è©ä¼°äºè¨ºæ·æºç¢ºæ§åé¢¨éªå å­ï¼åæ¬æ§å¥åè¦ååé°æ§çï¼ä½¿ç¨äºä¸ååå« 920 åæ£èè¨éçè³æéï¼æ¡ç¨åç¨®å°éå­¸ç¿æå¢ãçµæè¡¨æï¼å³çµ±çè¨åºæ©å¨å­¸ç¿ (ML) æ¨¡åéå¸¸å¨é¶æ¬¡å­¸ç¿åå°éå­¸ç¿è¨­å®ä¸­è¡¨ç¾åªæ¼ LLMãç¶èï¼ç¶ä½¿ç¨å°éå­¸ç¿ç¯ä¾ä»¥åææçå¯è§£é AI (XAI) æ¹æ³ä½çºé åç¥è­ä¾æºæï¼æè½å·®è·æé¡¯èç¸®å°ãæ­¤å¤ï¼é¨èæéåè¶³åç¯ä¾æ¸éå¢å ï¼å°è©±æ¹å¼ (NC) å¹¾ä¹å¯ä»¥åª²ç¾ ML æ¨¡åçæè½ãæå¼å¾æ³¨æçæ¯ï¼LLM ç¸å°æ¼ ML æ¨¡åå±ç¾åºç¸ç¶ææ´ä½³çææ¬æææºç¢ºåº¦ã
æ¬ç ç©¶è­å¯¦ï¼ééé©ç¶çé åç¥è­åéèº«æé çæºéç­ç¥ï¼LLM å¯ä»¥é¡¯èå¢å¼·è¨ºæ·ç¨åºãéäºç¼ç¾çªé¡¯äºæä½³åè¨ç·´ç¯ä¾æ¸éåæºéæ¹å¼çéè¦æ§ï¼ä»¥æé«æºç¢ºåº¦ä¸¦æ¸å° LLM æç¨ä¸­çåå·®ã

##### **To Trust or Not to Trust: Towards a novel approach to measure trust for XAI systems**
2405.05766v1 by Miquel MirÃ³-Nicolau, Gabriel MoyÃ -Alcover, Antoni Jaume-i-CapÃ³, Manuel GonzÃ¡lez-Hidalgo, Maria Gemma Sempere Campello, Juan Antonio Palmer Sancho

The increasing reliance on Deep Learning models, combined with their inherent
lack of transparency, has spurred the development of a novel field of study
known as eXplainable AI (XAI) methods. These methods seek to enhance the trust
of end-users in automated systems by providing insights into the rationale
behind their decisions. This paper presents a novel approach for measuring user
trust in XAI systems, allowing their refinement. Our proposed metric combines
both performance metrics and trust indicators from an objective perspective. To
validate this novel methodology, we conducted a case study in a realistic
medical scenario: the usage of XAI system for the detection of pneumonia from
x-ray images.

æè¦ï¼é¨èå°æ·±åº¦å­¸ç¿æ¨¡åä¾è³´æ§çå¢å ï¼å ä¸å¶åºæçéæåº¦ä¸è¶³ï¼ä¿ä½¿ä¸åæ°çç ç©¶é åç¼å±ï¼ç¨±çºå¯è§£é AI (XAI) æ¹æ³ãéäºæ¹æ³æ¨å¨ééæ·±å¥äºè§£æ±ºç­èå¾çåçï¼ä¾æåæçµä½¿ç¨èå°èªååç³»çµ±çä¿¡è³´ãæ¬ææåºäºä¸ç¨®è¡¡éä½¿ç¨èå° XAI ç³»çµ±ä¿¡è³´åº¦çæ°ç©æ¹æ³ï¼åè¨±å°å¶é²è¡æ¹é²ãæåæåºçææ¨çµåäºå®¢è§è§é»ä¸çæè½ææ¨åä¿¡è³´ææ¨ãçºäºé©è­éåæ°ç©çæ¹æ³ï¼æåå¨ä¸åçå¯¦çé«çå ´æ¯ä¸­é²è¡äºä¸åæ¡ä¾ç ç©¶ï¼ä½¿ç¨ XAI ç³»çµ±å¾ X åå½±åä¸­åµæ¸¬èºçã

##### **Region-specific Risk Quantification for Interpretable Prognosis of COVID-19**
2405.02815v1 by Zhusi Zhong, Jie Li, Zhuoqi Ma, Scott Collins, Harrison Bai, Paul Zhang, Terrance Healey, Xinbo Gao, Michael K. Atalay, Zhicheng Jiao

The COVID-19 pandemic has strained global public health, necessitating
accurate diagnosis and intervention to control disease spread and reduce
mortality rates. This paper introduces an interpretable deep survival
prediction model designed specifically for improved understanding and trust in
COVID-19 prognosis using chest X-ray (CXR) images. By integrating a large-scale
pretrained image encoder, Risk-specific Grad-CAM, and anatomical region
detection techniques, our approach produces regional interpretable outcomes
that effectively capture essential disease features while focusing on rare but
critical abnormal regions. Our model's predictive results provide enhanced
clarity and transparency through risk area localization, enabling clinicians to
make informed decisions regarding COVID-19 diagnosis with better understanding
of prognostic insights. We evaluate the proposed method on a multi-center
survival dataset and demonstrate its effectiveness via quantitative and
qualitative assessments, achieving superior C-indexes (0.764 and 0.727) and
time-dependent AUCs (0.799 and 0.691). These results suggest that our
explainable deep survival prediction model surpasses traditional survival
analysis methods in risk prediction, improving interpretability for clinical
decision making and enhancing AI system trustworthiness.

æè¦ï¼COVID-19 ç«æå°å¨çå¬å±è¡çé æå£åï¼å¿é é²è¡æºç¢ºçè¨ºæ·åå¹²é ï¼ä»¥æ§å¶ç¾çå³æ­ä¸¦éä½æ­»äº¡çãæ¬æä»ç´¹äºä¸åå¯è§£éçæ·±åº¦çå­é æ¸¬æ¨¡åï¼å°éè¨­è¨ç¨æ¼ééè¸é¨ X å (CXR) å½±åæ¹åå° COVID-19 é å¾ççè§£åä¿¡è³´ãééæ´åå¤§è¦æ¨¡é è¨ç·´å½±åç·¨ç¢¼å¨ãé¢¨éªç¹å® Grad-CAM åè§£ååååµæ¸¬æè¡ï¼æåçåæ³ç¢çååå¯è§£éççµæï¼ææææå¿è¦çç¾çç¹å¾µï¼åæå°æ³¨æ¼ç½è¦ä½ééµçç°å¸¸ååãæåçæ¨¡åé æ¸¬çµæééé¢¨éªååå®ä½æä¾å¢å¼·çæ¸æ°åº¦åéæåº¦ï¼è®è¨åºé«çè½å¤ å¨æ´äºè§£é å¾è¦è§£çææ³ä¸ï¼å°± COVID-19 è¨ºæ·ååºææºçæ±ºç­ãæåå¨å¤ä¸­å¿çå­è³æéä¸è©ä¼°ææåºçæ¹æ³ï¼ä¸¦éééååè³ªåè©ä¼°è­æå¶æææ§ï¼éå°åªç°ç C ææ¸ï¼0.764 å 0.727ï¼åæéç¸é AUCï¼0.799 å 0.691ï¼ãéäºçµæè¡¨æï¼æåå¯è§£éçæ·±åº¦çå­é æ¸¬æ¨¡åå¨é¢¨éªé æ¸¬æ¹é¢è¶è¶å³çµ±ççå­åææ¹æ³ï¼æåè¨åºæ±ºç­çè§£éæ§ï¼ä¸¦å¢å¼· AI ç³»çµ±çä¿¡è³´åº¦ã

##### **Rad4XCNN: a new agnostic method for post-hoc global explanation of CNN-derived features by means of radiomics**
2405.02334v1 by Francesco Prinzi, Carmelo Militello, Calogero Zarcaro, Tommaso Vincenzo Bartolotta, Salvatore Gaglio, Salvatore Vitabile

In the last years, artificial intelligence (AI) in clinical decision support
systems (CDSS) played a key role in harnessing machine learning and deep
learning architectures. Despite their promising capabilities, the lack of
transparency and explainability of AI models poses significant challenges,
particularly in medical contexts where reliability is a mandatory aspect.
Achieving transparency without compromising predictive accuracy remains a key
challenge. This paper presents a novel method, namely Rad4XCNN, to enhance the
predictive power of CNN-derived features with the interpretability inherent in
radiomic features. Rad4XCNN diverges from conventional methods based on
saliency map, by associating intelligible meaning to CNN-derived features by
means of Radiomics, offering new perspectives on explanation methods beyond
visualization maps. Using a breast cancer classification task as a case study,
we evaluated Rad4XCNN on ultrasound imaging datasets, including an online
dataset and two in-house datasets for internal and external validation. Some
key results are: i) CNN-derived features guarantee more robust accuracy when
compared against ViT-derived and radiomic features; ii) conventional
visualization map methods for explanation present several pitfalls; iii)
Rad4XCNN does not sacrifice model accuracy for their explainability; iv)
Rad4XCNN provides global explanation insights enabling the physician to analyze
the model outputs and findings. In addition, we highlight the importance of
integrating interpretability into AI models for enhanced trust and adoption in
clinical practice, emphasizing how our method can mitigate some concerns
related to explainable AI methods.

æè¦ï¼<paragraph>å¨éå»å¹¾å¹´ï¼è¨åºæ±ºç­æ¯æ´ç³»çµ± (CDSS) ä¸­çäººå·¥æºæ§ (AI) å¨å©ç¨æ©å¨å­¸ç¿åæ·±åº¦å­¸ç¿æ¶æ§æ¹é¢ç¼æ®äºééµä½ç¨ãåç®¡ AI æ¨¡åå·æä»¤äººæ»¿æçè½åï¼ä½ç¼ºä¹éæåº¦åå¯è§£éæ§ï¼ç¹å¥æ¯å¨å¯é æ§çºå¿è¦èéçé«çèæ¯ä¸ï¼éå¸¶ä¾äºéå¤§çææ°ãå¨ä¸å½±é¿é æ¸¬ç²¾æºåº¦çææ³ä¸å¯¦ç¾éæåº¦ä»ç¶æ¯ä¸é ééµææ°ãæ¬ææåºäºä¸ç¨®æ°æ¹æ³ï¼å³ Rad4XCNNï¼ä»¥å¢å¼· CNN è¡çç¹å¾µçé æ¸¬è½åï¼åæå·åæ¾å°ç¹å¾µåºæçå¯è§£éæ§ãRad4XCNN ä¸åæ¼åºæ¼é¡¯èæ§åçå³çµ±æ¹æ³ï¼å®ééæ¾å°çµå­¸å°å¯çè§£çå«ç¾©è CNN è¡çç¹å¾µéè¯èµ·ä¾ï¼çºè¶è¶è¦è¦ºååè¡¨çè§£éæ¹æ³æä¾äºæ°çè§é»ãæåä»¥ä¹³çåé¡ä»»åä½çºæ¡ä¾ç ç©¶ï¼å¨è¶é³æ³¢å½±åè³æéä¸è©ä¼° Rad4XCNNï¼åæ¬ä¸åç·ä¸è³æéåå©åç¨æ¼å§é¨åå¤é¨é©è­çå§é¨è³æéãä¸äºééµçµæå¦ä¸ï¼i) è ViT è¡çç¹å¾µåæ¾å°ç¹å¾µç¸æ¯ï¼CNN è¡çç¹å¾µä¿è­äºæ´ç©©å¥çæºç¢ºåº¦ï¼ii) å³çµ±çè¦è¦ºååè§£éæ¹æ³å­å¨ä¸äºç¼ºé·ï¼iii) Rad4XCNN æ²æç§ç²æ¨¡åæºç¢ºåº¦ä¾æåå¶å¯è§£éæ§ï¼iv) Rad4XCNN æä¾äºå¨å±è§£éè¦è§£ï¼ä½¿é«å¸«è½å¤ åææ¨¡åè¼¸åºåç¼ç¾ãæ­¤å¤ï¼æåå¼·èª¿å°å¯è§£éæ§æ´åå° AI æ¨¡åä¸­å°æ¼å¢å¼·è¨åºå¯¦åä¸­çä¿¡ä»»åæ¡ç¨è³ééè¦ï¼ä¸¦å¼·èª¿äºæåçæ¹æ³å¦ä½è½ç·©è§£èå¯è§£é AI æ¹æ³ç¸éçä¸äºçæ®ã</paragraph>

##### **Attributing Responsibility in AI-Induced Incidents: A Computational Reflective Equilibrium Framework for Accountability**
2404.16957v1 by Yunfei Ge, Quanyan Zhu

The pervasive integration of Artificial Intelligence (AI) has introduced
complex challenges in the responsibility and accountability in the event of
incidents involving AI-enabled systems. The interconnectivity of these systems,
ethical concerns of AI-induced incidents, coupled with uncertainties in AI
technology and the absence of corresponding regulations, have made traditional
responsibility attribution challenging. To this end, this work proposes a
Computational Reflective Equilibrium (CRE) approach to establish a coherent and
ethically acceptable responsibility attribution framework for all stakeholders.
The computational approach provides a structured analysis that overcomes the
limitations of conceptual approaches in dealing with dynamic and multifaceted
scenarios, showcasing the framework's explainability, coherence, and adaptivity
properties in the responsibility attribution process. We examine the pivotal
role of the initial activation level associated with claims in equilibrium
computation. Using an AI-assisted medical decision-support system as a case
study, we illustrate how different initializations lead to diverse
responsibility distributions. The framework offers valuable insights into
accountability in AI-induced incidents, facilitating the development of a
sustainable and resilient system through continuous monitoring, revision, and
reflection.

æè¦ï¼é¨èäººå·¥æºæ§ (AI) çæ®åæ´åï¼å¨æ¶å AI é©åç³»çµ±çäºæä¸­ï¼è²¬ä»»åç¾©åæ­¸å±¬ç¢çäºè¤éçææ°ãéäºç³»çµ±çäºé£æ§ãAI å¼ç¼äºæçå«çåé¡ï¼å ä¸ AI æè¡çä¸ç¢ºå®æ§åç¼ºä¹ç¸ææ³è¦ï¼ä½¿å¾å³çµ±è²¬ä»»æ­¸å±¬é¢è¨ææ°ãçºæ­¤ï¼æ¬ç ç©¶æåºäºä¸ç¨®è¨ç®åæåè¡¡ (CRE) æ¹æ³ï¼ä»¥å»ºç«ä¸åé£è²«ä¸å¨å«çä¸å¯æ¥åçè²¬ä»»æ­¸å±¬æ¶æ§ï¼é©ç¨æ¼ææå©å®³éä¿äººãè¨ç®æ¹æ³æä¾äºçµæ§åçåæï¼åæäºæ¦å¿µæ¹æ³å¨èçåæä¸å¤é¢åæå¢æçéå¶ï¼å±ç¤ºäºè©²æ¶æ§å¨è²¬ä»»æ­¸å±¬éç¨ä¸­å·åçå¯è§£éæ§ãé£è²«æ§åé©ææ§ãæåæ¢è¨äºèåè¡¡è¨ç®ä¸­ç´¢è³ ç¸éçåå§ååå±¤ç´çééµä½ç¨ãæåä»¥ AI è¼å©é«çæ±ºç­æ¯æ´ç³»çµ±çºæ¡ä¾ç ç©¶ï¼èªªæä¸åçåå§åå¦ä½å°è´ä¸åçè²¬ä»»åéãè©²æ¶æ§æä¾äºå° AI å¼ç¼äºæä¸­åè²¬å¶çå¯¶è²´è¦è§£ï¼ééæçºç£æ§ãä¿®è¨ååæï¼ä¿é²äºæ°¸çºä¸æéæ§çç³»çµ±ç¼å±ã

##### **Explainable AI for Fair Sepsis Mortality Predictive Model**
2404.13139v1 by Chia-Hsuan Chang, Xiaoyang Wang, Christopher C. Yang

Artificial intelligence supports healthcare professionals with predictive
modeling, greatly transforming clinical decision-making. This study addresses
the crucial need for fairness and explainability in AI applications within
healthcare to ensure equitable outcomes across diverse patient demographics. By
focusing on the predictive modeling of sepsis-related mortality, we propose a
method that learns a performance-optimized predictive model and then employs
the transfer learning process to produce a model with better fairness. Our
method also introduces a novel permutation-based feature importance algorithm
aiming at elucidating the contribution of each feature in enhancing fairness on
predictions. Unlike existing explainability methods concentrating on explaining
feature contribution to predictive performance, our proposed method uniquely
bridges the gap in understanding how each feature contributes to fairness. This
advancement is pivotal, given sepsis's significant mortality rate and its role
in one-third of hospital deaths. Our method not only aids in identifying and
mitigating biases within the predictive model but also fosters trust among
healthcare stakeholders by improving the transparency and fairness of model
predictions, thereby contributing to more equitable and trustworthy healthcare
delivery.

æè¦ï¼äººå·¥æºæ§ééé æ¸¬æ¨¡ååå©é«çå°æ¥­äººå¡ï¼å¤§å¹è½è®äºè¨åºæ±ºç­å¶å®ãæ¬ç ç©¶æ¢è¨äºå¨é«çä¿å¥ä¸­ä½¿ç¨äººå·¥æºæ§æç¨ç¨å¼æå¬å¹³æ§åå¯è§£éæ§çééµéæ±ï¼ä»¥ç¢ºä¿å¨ä¸åçæ£èäººå£çµ±è¨è³æä¸­ç²å¾å¬å¹³ççµæãééå°æ³¨æ¼æè¡çç¸éæ­»äº¡ççé æ¸¬æ¨¡åï¼æåæåºäºä¸ç¨®æ¹æ³ï¼è©²æ¹æ³æå­¸ç¿ä¸åæè½æä½³åçé æ¸¬æ¨¡åï¼ç¶å¾æ¡ç¨è½ç§»å­¸ç¿éç¨ä¾ç¢çä¸åå·ææ´å¥½å¬å¹³æ§çæ¨¡åãæåçæ¨¡åéå¼å¥äºä¸ç¨®æ°ç©çåºæ¼æåçç¹å¾µéè¦æ§æ¼ç®æ³ï¼æ¨å¨é¡ææ¯åç¹å¾µå¨å¢å¼·é æ¸¬å¬å¹³æ§æ¹é¢çè²¢ç»ãèç¾æçå¯è§£éæ§æ¹æ³å°æ³¨æ¼è§£éç¹å¾µå°é æ¸¬æè½çè²¢ç»ä¸åï¼æåæåºçæ¹æ³ç¨ç¹å°å½è£äºçè§£æ¯åç¹å¾µå¦ä½æå©æ¼å¬å¹³æ§çå·®è·ãéé é²å±è³ééè¦ï¼å çºæè¡ççæ­»äº¡çå¾é«ï¼ä¸å¨ä¸åä¹ä¸çé«é¢æ­»äº¡ä¸­æ®æ¼èè§è²ãæåçæ¨¡åä¸åæå©æ¼è­å¥åæ¸è¼é æ¸¬æ¨¡åä¸­çåå·®ï¼éè½ééæé«æ¨¡åé æ¸¬çéæåº¦åå¬å¹³æ§ä¾å¹é¤é«çä¿å¥å©çç¸éèä¹éçä¿¡ä»»ï¼é²èæå©æ¼æä¾æ´å¬å¹³ä¸å¼å¾ä¿¡è³´çé«çä¿å¥æåã

##### **Multi Class Depression Detection Through Tweets using Artificial Intelligence**
2404.13104v1 by Muhammad Osama Nusrat, Waseem Shahzad, Saad Ahmed Jamal

Depression is a significant issue nowadays. As per the World Health
Organization (WHO), in 2023, over 280 million individuals are grappling with
depression. This is a huge number; if not taken seriously, these numbers will
increase rapidly. About 4.89 billion individuals are social media users. People
express their feelings and emotions on platforms like Twitter, Facebook,
Reddit, Instagram, etc. These platforms contain valuable information which can
be used for research purposes. Considerable research has been conducted across
various social media platforms. However, certain limitations persist in these
endeavors. Particularly, previous studies were only focused on detecting
depression and the intensity of depression in tweets. Also, there existed
inaccuracies in dataset labeling. In this research work, five types of
depression (Bipolar, major, psychotic, atypical, and postpartum) were predicted
using tweets from the Twitter database based on lexicon labeling. Explainable
AI was used to provide reasoning by highlighting the parts of tweets that
represent type of depression. Bidirectional Encoder Representations from
Transformers (BERT) was used for feature extraction and training. Machine
learning and deep learning methodologies were used to train the model. The BERT
model presented the most promising results, achieving an overall accuracy of
0.96.

æè¦ï¼ç¾ä»ï¼æé¬±çæ¯ä¸åéè¦çè­°é¡ãæ ¹æä¸çè¡ççµç¹ (WHO) çè³æï¼å¨ 2023 å¹´ï¼è¶é 2.8 åäººæ­£å¨èæé¬±çæé¬¥ãéæ¯ä¸åé¾å¤§çæ¸å­ï¼å¦æä¸èªççå¾ï¼éäºæ¸å­å°æå¿«éå¢å ãå¤§ç´æ 48.9 åäººæ¯ç¤¾ç¾¤åªé«ä½¿ç¨èãäººåå¨ TwitterãFacebookãRedditãInstagram ç­å¹³å°ä¸è¡¨éèªå·±çæååæç·ãéäºå¹³å°åå«æå¹å¼çè³è¨ï¼å¯ç¨æ¼ç ç©¶ç®çãå·²ç¶å¨åç¨®ç¤¾ç¾¤åªé«å¹³å°ä¸é²è¡äºå¤§éçç ç©¶ãç¶èï¼éäºåªåä»å­å¨æäºéå¶ãç¹å¥æ¯ï¼ååçç ç©¶åå°æ³¨æ¼åµæ¸¬æ¨æä¸­çæé¬±çåæé¬±ççå¼·åº¦ãæ­¤å¤ï¼è³æéæ¨ç±¤ä¸­å­å¨ä¸æºç¢ºçææ³ãå¨éé ç ç©¶å·¥ä½ä¸­ï¼ä½¿ç¨åºæ¼è©å½æ¨ç±¤ç Twitter è³æåº«ä¸­çæ¨æé æ¸¬äºäºç¨®é¡åçæé¬±çï¼éæ¥µåãéåº¦ãç²¾ç¥çåãéå¸ååç¢å¾ï¼ãå¯è§£éç AI ç¨æ¼ééå¼·èª¿ä»£è¡¨æé¬±çé¡åçæ¨æé¨åä¾æä¾æ¨çãå¾ Transformersï¼BERTï¼ä¸­æåçéåç·¨ç¢¼å¨è¡¨ç¤ºç¨æ¼ç¹å¾µæååè¨ç·´ãæ©å¨å­¸ç¿åæ·±åº¦å­¸ç¿æ¹æ³ç¨æ¼è¨ç·´æ¨¡åãBERT æ¨¡ååç¾åºææå¸æççµæï¼éå° 0.96 çæ´é«æºç¢ºåº¦ã

##### **COIN: Counterfactual inpainting for weakly supervised semantic segmentation for medical images**
2404.12832v2 by Dmytro Shvetsov, Joonas Ariva, Marharyta Domnich, Raul Vicente, Dmytro Fishman

Deep learning is dramatically transforming the field of medical imaging and
radiology, enabling the identification of pathologies in medical images,
including computed tomography (CT) and X-ray scans. However, the performance of
deep learning models, particularly in segmentation tasks, is often limited by
the need for extensive annotated datasets. To address this challenge, the
capabilities of weakly supervised semantic segmentation are explored through
the lens of Explainable AI and the generation of counterfactual explanations.
The scope of this research is development of a novel counterfactual inpainting
approach (COIN) that flips the predicted classification label from abnormal to
normal by using a generative model. For instance, if the classifier deems an
input medical image X as abnormal, indicating the presence of a pathology, the
generative model aims to inpaint the abnormal region, thus reversing the
classifier's original prediction label. The approach enables us to produce
precise segmentations for pathologies without depending on pre-existing
segmentation masks. Crucially, image-level labels are utilized, which are
substantially easier to acquire than creating detailed segmentation masks. The
effectiveness of the method is demonstrated by segmenting synthetic targets and
actual kidney tumors from CT images acquired from Tartu University Hospital in
Estonia. The findings indicate that COIN greatly surpasses established
attribution methods, such as RISE, ScoreCAM, and LayerCAM, as well as an
alternative counterfactual explanation method introduced by Singla et al. This
evidence suggests that COIN is a promising approach for semantic segmentation
of tumors in CT images, and presents a step forward in making deep learning
applications more accessible and effective in healthcare, where annotated data
is scarce.

æè¦ï¼æ·±åº¦å­¦ä¹ æ­£å¤§å¹è½è®é«å­¸å½±ååæ¾å°ç·å­¸é åï¼è½è¾¨è­é«å­¸å½±åä¸­çççï¼åæ¬é»è¦æ·å±¤ææ (CT) å X åææãç¶èï¼æ·±åº¦å­¸ç¿æ¨¡åçæè½ï¼ç¹å¥æ¯å¨åå²ä»»åä¸­ï¼å¸¸å¸¸åå°å»£æ³è¨»è§£è³æééæ±çéå¶ãçºäºæå°æ­¤ææ°ï¼ééå¯è§£é AI ååäºå¯¦è§£éçç¢çï¼æ¢ç´¢å¼±ç£ç£èªæåå²çè½åãæ¬ç ç©¶çç¯åæ¯éç¼ä¸ç¨®æ°çåäºå¯¦å§ææ¹æ³ (COIN)ï¼è©²æ¹æ³ä½¿ç¨çææ¨¡åå°é æ¸¬çåé¡æ¨ç±¤å¾ç°å¸¸ç¿»è½çºæ­£å¸¸ãä¾å¦ï¼å¦æåé¡å¨å°è¼¸å¥çé«å­¸å½±å X è¦çºç°å¸¸ï¼è¡¨ç¤ºå­å¨ççï¼åçææ¨¡åæ¨å¨å§æç°å¸¸ååï¼å¾èéè½åé¡å¨çåå§é æ¸¬æ¨ç±¤ãæ­¤æ¹æ³ä½¿æåè½å¤ ç¢ççççç²¾ç¢ºåå²ï¼èç¡éä¾è³´æ¼é åå­å¨çåå²é®ç½©ãè³ééè¦çæ¯ï¼å©ç¨å½±åå±¤ç´æ¨ç±¤ï¼éæ¯å»ºç«è©³ç´°çåå²é®ç½©å®¹æåå¾ãè©²æ¹æ³çæææ§ééåå²åæç®æ¨åå¾ææ²å°¼äºå¡ç¾åå¤§å­¸é«é¢åå¾ç CT å½±åä¸­çå¯¦éèèè«ç¤ä¾è­æãç ç©¶çµæè¡¨æï¼COIN é é è¶éå·²å»ºç«çæ­¸å æ¹æ³ï¼ä¾å¦ RISEãScoreCAM å LayerCAMï¼ä»¥å Singla ç­äººæåºçå¦ä¸ç¨®åäºå¯¦è§£éæ¹æ³ãæ­¤è­æè¡¨æï¼COIN æ¯ä¸ç¨®å¾æåéç CT å½±åä¸­è«ç¤èªæåå²æ¹æ³ï¼ä¸¦å¨é«çä¿å¥ä¸­è®æ·±åº¦å­¸ç¿æç¨æ´ææ¼åå¾åæ´ææçéé²ä¸æ­¥ï¼å¶ä¸­è¨»è§£è³æå¾ç¨å°ã

##### **Hybrid Intelligence for Digital Humanities**
2406.15374v1 by Victor de Boer, Lise Stork

In this paper, we explore the synergies between Digital Humanities (DH) as a
discipline and Hybrid Intelligence (HI) as a research paradigm. In DH research,
the use of digital methods and specifically that of Artificial Intelligence is
subject to a set of requirements and constraints. We argue that these are
well-supported by the capabilities and goals of HI. Our contribution includes
the identification of five such DH requirements: Successful AI systems need to
be able to 1) collaborate with the (human) scholar; 2) support data criticism;
3) support tool criticism; 4) be aware of and cater to various perspectives and
5) support distant and close reading. We take the CARE principles of Hybrid
Intelligence (collaborative, adaptive, responsible and explainable) as
theoretical framework and map these to the DH requirements. In this mapping, we
include example research projects. We finally address how insights from DH can
be applied to HI and discuss open challenges for the combination of the two
disciplines.

æè¦ï¼å¨æ¬æä¸­ï¼æåæ¢è¨æ¸ä½äººæå­¸ç§ (DH) ä½çºä¸éå­¸ç§èæ··åæºè½ (HI) ä½çºä¸åç ç©¶å¸ç¯ä¹éçååä½ç¨ãå¨ DH ç ç©¶ä¸­ï¼æ¸ä½æ¹æ³çä½¿ç¨ï¼ç¹å¥æ¯äººå·¥æºæ§çä½¿ç¨ï¼åå°ä¸ç³»åè¦æ±åéå¶ãæåèªçºéäºè¦æ±åéå¶ç²å¾ HI çè½ååç®æ¨çååæ¯æãæåçè²¢ç»åæ¬æ¾åºäºåéæ¨£ç DH è¦æ±ï¼æåç AI ç³»çµ±éè¦è½å¤  1) èï¼äººé¡ï¼å­¸èåä½ï¼2) æ¯æ´è³ææ¹è©ï¼3) æ¯æ´å·¥å·æ¹è©ï¼4) å¯è¦ºä¸¦è¿ååç¨®è§é»ï¼5) æ¯æ´é è·åè¿è·é¢é±è®ãæåå°æ··åæºè½ç CARE ååï¼åä½ãé©æãè² è²¬åå¯è§£éï¼ä½çºçè«æ¶æ§ï¼ä¸¦å°éäºååå°æå° DH è¦æ±ãå¨æ­¤å°æä¸­ï¼æåç´å¥ç¯ä¾ç ç©¶å°æ¡ãæå¾ï¼æåæ¢è¨å¦ä½å° DH çè¦è§£æç¨æ¼ HIï¼ä¸¦è¨è«çµåéå©åå­¸ç§çéæ¾ææ°ã

##### **Ethical Framework for Responsible Foundational Models in Medical Imaging**
2406.11868v1 by Abhijit Das, Debesh Jha, Jasmer Sanjotra, Onkar Susladkar, Suramyaa Sarkar, Ashish Rauniyar, Nikhil Tomar, Vanshali Sharma, Ulas Bagci

Foundational models (FMs) have tremendous potential to revolutionize medical
imaging. However, their deployment in real-world clinical settings demands
extensive ethical considerations. This paper aims to highlight the ethical
concerns related to FMs and propose a framework to guide their responsible
development and implementation within medicine. We meticulously examine ethical
issues such as privacy of patient data, bias mitigation, algorithmic
transparency, explainability and accountability. The proposed framework is
designed to prioritize patient welfare, mitigate potential risks, and foster
trust in AI-assisted healthcare.

æè¦ï¼åºç¤æ¨¡å (FM) å·æå¾¹åºæ¹è®é«å­¸å½±åçå·¨å¤§æ½åãç¶èï¼å®åå¨ç¾å¯¦ä¸çè¨åºç°å¢ä¸­çé¨ç½²éè¦å»£æ³çå«çèéãæ¬ææ¨å¨å¼·èª¿è FM ç¸éçå«çåé¡ï¼ä¸¦æåºä¸åæ¡æ¶ä¾æå°å®åå¨é«å­¸ä¸­çè² è²¬ä»»éç¼åå¯¦æ½ãæåä»ç´°å¯©æ¥äºå«çåé¡ï¼ä¾å¦æ£èæ¸æé±ç§ãåå·®ç·©è§£ãæ¼ç®æ³éæåº¦ãå¯è§£éæ§ååè²¬å¶ãææåºçæ¡æ¶æ¨å¨åªåèæ®æ£èç¦å©ãæ¸è¼æ½å¨é¢¨éªï¼ä¸¦å¹é¤å° AI è¼å©é«çä¿å¥çä¿¡ä»»ã

##### **Advancements in Radiomics and Artificial Intelligence for Thyroid Cancer Diagnosis**
2404.07239v1 by Milad Yousefi, Shadi Farabi Maleki, Ali Jafarizadeh, Mahya Ahmadpour Youshanlui, Aida Jafari, Siamak Pedrammehr, Roohallah Alizadehsani, Ryszard Tadeusiewicz, Pawel Plawiak

Thyroid cancer is an increasing global health concern that requires advanced
diagnostic methods. The application of AI and radiomics to thyroid cancer
diagnosis is examined in this review. A review of multiple databases was
conducted in compliance with PRISMA guidelines until October 2023. A
combination of keywords led to the discovery of an English academic publication
on thyroid cancer and related subjects. 267 papers were returned from the
original search after 109 duplicates were removed. Relevant studies were
selected according to predetermined criteria after 124 articles were eliminated
based on an examination of their abstract and title. After the comprehensive
analysis, an additional six studies were excluded. Among the 28 included
studies, radiomics analysis, which incorporates ultrasound (US) images,
demonstrated its effectiveness in diagnosing thyroid cancer. Various results
were noted, some of the studies presenting new strategies that outperformed the
status quo. The literature has emphasized various challenges faced by AI
models, including interpretability issues, dataset constraints, and operator
dependence. The synthesized findings of the 28 included studies mentioned the
need for standardization efforts and prospective multicenter studies to address
these concerns. Furthermore, approaches to overcome these obstacles were
identified, such as advances in explainable AI technology and personalized
medicine techniques. The review focuses on how AI and radiomics could transform
the diagnosis and treatment of thyroid cancer. Despite challenges, future
research on multidisciplinary cooperation, clinical applicability validation,
and algorithm improvement holds the potential to improve patient outcomes and
diagnostic precision in the treatment of thyroid cancer.

æè¦ï¼ç²çèºçæ¯ä¸ç¨®æ¥çå´éçå¨çå¥åº·åé¡ï¼éè¦åé²çè¨ºæ·æ¹æ³ãæ¬ç¯è©è«æ¢è¨äºäººå·¥æºè½èæ¾å°ç¹å¾µåæå¨ç²çèºçè¨ºæ·ä¸­çæç¨ãå¨ç¬¦å PRISMA æåçææ³ä¸ï¼å°å¤åè³æåº«é²è¡äºåé¡§ï¼ç´å° 2023 å¹´ 10 æãééçµåééµå­ï¼ç¼ç¾äºä¸ç¯éæ¼ç²çèºçåç¸éä¸»é¡çè±æå­¸è¡åºçç©ãå¨ç§»é¤ 109 ç¯éè¤æç»å¾ï¼åå§æå°å±åå³ 267 ç¯è«æãå¨æ ¹æé åç¢ºå®çæ¨æºï¼æ·æ±°äº 124 ç¯æç« çæè¦åæ¨é¡å¾ï¼é¸åºäºç¸éç ç©¶ãå¨é²è¡å¨é¢åæå¾ï¼é¡å¤æé¤äºå­é ç ç©¶ãå¨ç´å¥ç 28 é ç ç©¶ä¸­ï¼çµåè¶é³æ³¢ (US) å½±åçæ¾å°ç¹å¾µåæï¼è­æäºå¶å¨è¨ºæ·ç²çèºçæ¹é¢çæææ§ãç ç©¶çµæä¸ä¸ï¼æäºç ç©¶æåºäºåªæ¼ç¾ççæ°ç­ç¥ãæç»å¼·èª¿äºäººå·¥æºè½æ¨¡åé¢è¨çåç¨®ææ°ï¼åæ¬å¯è§£éæ§åé¡ãè³æééå¶åæä½å¡ä¾è³´æ§ã28 é ç´å¥ç ç©¶çç¶åç¼ç¾æå°ï¼éè¦æ¨æºåå·¥ä½ååç»æ§å¤ä¸­å¿ç ç©¶ä¾è§£æ±ºéäºåé¡ãæ­¤å¤ï¼éç¢ºå®äºåæéäºéç¤çæ¹æ³ï¼ä¾å¦å¯è§£éäººå·¥æºè½æè¡ååäººåé«çæè¡çé²æ­¥ãæ¬ç¯è©è«éé»æ¢è¨äºäººå·¥æºè½åæ¾å°ç¹å¾µåæå¦ä½è½è®ç²çèºççè¨ºæ·åæ²»çãåç®¡å­å¨ææ°ï¼ä½æªä¾å°å¤å­¸ç§åä½ãè¨åºé©ç¨æ§é©è­åæ¼ç®æ³æ¹é²çç ç©¶ï¼ä»ææ½åæ¹åç²çèºçæ²»çä¸­çæ£èé å¾åè¨ºæ·ç²¾æºåº¦ã

##### **Predictive Modeling for Breast Cancer Classification in the Context of Bangladeshi Patients: A Supervised Machine Learning Approach with Explainable AI**
2404.04686v1 by Taminul Islam, Md. Alif Sheakh, Mst. Sazia Tahosin, Most. Hasna Hena, Shopnil Akash, Yousef A. Bin Jardan, Gezahign Fentahun Wondmie, Hiba-Allah Nafidi, Mohammed Bourhia

Breast cancer has rapidly increased in prevalence in recent years, making it
one of the leading causes of mortality worldwide. Among all cancers, it is by
far the most common. Diagnosing this illness manually requires significant time
and expertise. Since detecting breast cancer is a time-consuming process,
preventing its further spread can be aided by creating machine-based forecasts.
Machine learning and Explainable AI are crucial in classification as they not
only provide accurate predictions but also offer insights into how the model
arrives at its decisions, aiding in the understanding and trustworthiness of
the classification results. In this study, we evaluate and compare the
classification accuracy, precision, recall, and F-1 scores of five different
machine learning methods using a primary dataset (500 patients from Dhaka
Medical College Hospital). Five different supervised machine learning
techniques, including decision tree, random forest, logistic regression, naive
bayes, and XGBoost, have been used to achieve optimal results on our dataset.
Additionally, this study applied SHAP analysis to the XGBoost model to
interpret the model's predictions and understand the impact of each feature on
the model's output. We compared the accuracy with which several algorithms
classified the data, as well as contrasted with other literature in this field.
After final evaluation, this study found that XGBoost achieved the best model
accuracy, which is 97%.

æè¦ï¼<paragraph>è¿å¹´ä¾ï¼ä¹³çççè¡çè¿éå¢å ï¼ä½¿å¶æçºå¨çä¸»è¦çæ­»äº¡åå ä¹ä¸ãå¨ææççä¸­ï¼ä¹³çè¿ä»çºæ­¢æ¯æå¸¸è¦çãæåè¨ºæ·æ­¤ç¾çéè¦å¤§éçæéåå°æ¥­ç¥è­ãç±æ¼ä¹³ççæª¢æ¸¬éç¨èæï¼å æ­¤ééå»ºç«æ©å¨å­¸ç¿æ¨¡åä¾é æ¸¬ï¼æå©æ¼é²æ­¢å¶é²ä¸æ­¥æ´æ£ãæ©å¨å­¸ç¿åå¯è§£é AI å¨åé¡ä¸­è³ééè¦ï¼å çºå®åä¸åå¯ä»¥æä¾æºç¢ºçé æ¸¬ï¼éå¯ä»¥æ·±å¥äºè§£æ¨¡åå¦ä½ååºæ±ºç­ï¼æå©æ¼çè§£åä¿¡è³´åé¡çµæãå¨æ­¤ç ç©¶ä¸­ï¼æåè©ä¼°ä¸¦æ¯è¼äºäºç¨®ä¸åçæ©å¨å­¸ç¿æ¹æ³çåé¡æºç¢ºåº¦ãç²¾ç¢ºåº¦ãå¬åçå F1 åæ¸ï¼ä½¿ç¨äºä¸åä¸»è¦çè³æéï¼éå¡é«å­¸é¢é«é¢ç 500 åæ£èï¼ãäºç¨®ä¸åçç£ç£å¼æ©å¨å­¸ç¿æè¡ï¼åæ¬æ±ºç­æ¨¹ãé¨æ©æ£®æãéè¼¯è¿´æ­¸ãæ´ç´ è²æ°å XGBoostï¼å·²ç¨æ¼å¨æåçè³æéä¸åå¾æä½³çµæãæ­¤å¤ï¼æ¬ç ç©¶å° SHAP åææç¨æ¼ XGBoost æ¨¡åï¼ä»¥è§£éæ¨¡åçé æ¸¬ä¸¦äºè§£æ¯åç¹å¾µå°æ¨¡åè¼¸åºçå½±é¿ãæåæ¯è¼äºå¹¾ç¨®æ¼ç®æ³å°è³æé²è¡åé¡çæºç¢ºåº¦ï¼ä¸¦èè©²é åçå¶ä»æç»é²è¡å°æ¯ãå¨æå¾è©ä¼°å¾ï¼æ¬ç ç©¶ç¼ç¾ XGBoost éå°äºæä½³çæ¨¡åæºç¢ºåº¦ï¼çº 97%ã</paragraph>

##### **Enhancing Breast Cancer Diagnosis in Mammography: Evaluation and Integration of Convolutional Neural Networks and Explainable AI**
2404.03892v3 by Maryam Ahmed, Tooba Bibi, Rizwan Ahmed Khan, Sidra Nasir

The Deep learning (DL) models for diagnosing breast cancer from mammographic
images often operate as "black boxes", making it difficult for healthcare
professionals to trust and understand their decision-making processes. The
study presents an integrated framework combining Convolutional Neural Networks
(CNNs) and Explainable Artificial Intelligence (XAI) for the enhanced diagnosis
of breast cancer using the CBIS-DDSM dataset. The methodology encompasses an
elaborate data preprocessing pipeline and advanced data augmentation techniques
to counteract dataset limitations and transfer learning using pre-trained
networks such as VGG-16, Inception-V3 and ResNet was employed. A focal point of
our study is the evaluation of XAI's effectiveness in interpreting model
predictions, highlighted by utilizing the Hausdorff measure to assess the
alignment between AI-generated explanations and expert annotations
quantitatively. This approach is critical for XAI in promoting trustworthiness
and ethical fairness in AI-assisted diagnostics. The findings from our research
illustrate the effective collaboration between CNNs and XAI in advancing
diagnostic methods for breast cancer, thereby facilitating a more seamless
integration of advanced AI technologies within clinical settings. By enhancing
the interpretability of AI driven decisions, this work lays the groundwork for
improved collaboration between AI systems and medical practitioners, ultimately
enriching patient care. Furthermore, the implications of our research extended
well beyond the current methodologies. It encourages further research into how
to combine multimodal data and improve AI explanations to meet the needs of
clinical practice.

æè¦ï¼æ·±åº¦å­¸ç¿ (DL) ç¨æ¼å¾ä¹³æ¿æå½±è¡å½±åè¨ºæ·ä¹³ççæ¨¡åéå¸¸ä»¥ãé»çå­ãæ¹å¼éä½ï¼éä½¿å¾é«çä¿å¥å°æ¥­äººå¡é£ä»¥ä¿¡ä»»åçè§£å¶æ±ºç­éç¨ãæ¬ç ç©¶æåºä¸åæ´åæ¶æ§ï¼çµåå·ç©ç¥ç¶ç¶²è·¯ (CNN) åå¯è§£éäººå·¥æºæ§ (XAI)ï¼ä»¥ä½¿ç¨ CBIS-DDSM è³æéå¢å¼·ä¹³ççè¨ºæ·ãæ¹æ³åå«ä¸åç²¾ç´°çè³æåèçç®¡ç·åé²éè³ææ´åæè¡ï¼ä»¥å°æè³æééå¶ï¼ä¸¦æ¡ç¨é åè¨ç·´çç¶²è·¯ï¼ä¾å¦ VGG-16ãInception-V3 å ResNetï¼é²è¡é·ç§»å­¸ç¿ãæåç ç©¶çéé»æ¯è©ä¼° XAI å¨è§£éæ¨¡åé æ¸¬ä¸­çæææ§ï¼éé»å©ç¨è±ªæ¯å¤å¤«æ¸¬åº¦éåè©ä¼° AI çæçè§£éåå°å®¶è¨»è§£ä¹éçä¸è´æ§ãéç¨®æ¹æ³å°æ¼ XAI å¨ä¿é² AI è¼å©è¨ºæ·ä¸­çå¯ä¿¡åº¦åå«çå¬å¹³æ§è³ééè¦ãæåç ç©¶çç¼ç¾èªªæäº CNN å XAI å¨æ¨é²ä¹³çè¨ºæ·æ¹æ³ä¸­çææåä½ï¼å¾èä¿é²äºåé² AI æè¡å¨è¨åºç°å¢ä¸­çæ´é æ¢æ´åãééå¢å¼· AI é©åæ±ºç­çå¯è§£éæ§ï¼éé å·¥ä½çº AI ç³»çµ±åé«çå¾æ¥­äººå¡ä¹éçæ¹ååä½å¥ å®äºåºç¤ï¼æçµè±å¯äºæ£èç§è­·ãæ­¤å¤ï¼æåç ç©¶çå½±é¿é é è¶åºäºç®åçæè¡ãå®é¼åµé²ä¸æ­¥ç ç©¶å¦ä½çµåå¤æ¨¡å¼è³æä¸¦æ¹å AI è§£éï¼ä»¥æ»¿è¶³è¨åºå¯¦åçéæ±ã

##### **Advancing Multimodal Data Fusion in Pain Recognition: A Strategy Leveraging Statistical Correlation and Human-Centered Perspectives**
2404.00320v2 by Xingrui Gu, Zhixuan Wang, Irisa Jin, Zekun Wu

This research presents a novel multimodal data fusion methodology for pain
behavior recognition, integrating statistical correlation analysis with
human-centered insights. Our approach introduces two key innovations: 1)
integrating data-driven statistical relevance weights into the fusion strategy
to effectively utilize complementary information from heterogeneous modalities,
and 2) incorporating human-centric movement characteristics into multimodal
representation learning for detailed modeling of pain behaviors. Validated
across various deep learning architectures, our method demonstrates superior
performance and broad applicability. We propose a customizable framework that
aligns each modality with a suitable classifier based on statistical
significance, advancing personalized and effective multimodal fusion.
Furthermore, our methodology provides explainable analysis of multimodal data,
contributing to interpretable and explainable AI in healthcare. By highlighting
the importance of data diversity and modality-specific representations, we
enhance traditional fusion techniques and set new standards for recognizing
complex pain behaviors. Our findings have significant implications for
promoting patient-centered healthcare interventions and supporting explainable
clinical decision-making.

æè¦ï¼æ¬ç ç©¶æåºäºä¸ç¨®åµæ°çå¤æ¨¡ææ¸æèåæ¹æ³ï¼ç¨æ¼ç¼çè¡çºè­å¥ï¼å°çµ±è¨ç¸éåæèä»¥äººçºä¸­å¿çè¦è§£ç¸çµåãæåçåæ³å¼å¥äºå©é ééµåµæ°ï¼1) å°æ¸æé©åççµ±è¨ç¸éæ¬éæ´åå°èåç­ç¥ä¸­ï¼ä»¥ææå©ç¨ä¾èªç°è³ªæ¨¡æçè£åä¿¡æ¯ï¼ä»¥å 2) å°ä»¥äººçºä¸­å¿çéåç¹å¾µç´å¥å¤æ¨¡æè¡¨ç¤ºå­¸ç¿ä¸­ï¼ä»¥è©³ç´°å»ºæ¨¡ç¼çè¡çºãæåçæ¨¡åå¨åç¨®æ·±åº¦å­¸ç¿æ¶æ§ä¸­å¾å°é©è­ï¼å±ç¤ºäºåè¶çæ§è½åå»£æ³çé©ç¨æ§ãæåæåºäºä¸åå¯èªå®ç¾©çæ¡æ¶ï¼æ ¹æçµ±è¨é¡¯èæ§å°æ¯åæ¨¡æèåé©çåé¡å¨å°é½ï¼æ¨é²åæ§ååææçå¤æ¨¡æèåãæ­¤å¤ï¼æåçæ¨¡åæä¾å°å¤æ¨¡ææ¸æçå¯è§£éåæï¼æå©æ¼é«çä¿å¥ä¸­çå¯è§£éåå¯è§£é AIãééå¼·èª¿æ¸æå¤æ¨£æ§åæ¨¡æç¹å®è¡¨ç¤ºçéè¦æ§ï¼æåå¢å¼·äºå³çµ±çèåæè¡ï¼ä¸¦çºè­å¥è¤éçç¼çè¡çºè¨­å®äºæ°çæ¨æºãæåçç¼ç¾å°ä¿é²ä»¥æ£èçºä¸­å¿çé«çä¿å¥å¹²é åæ¯æå¯è§£éçè¨åºæ±ºç­å¶å®å·æéè¦æç¾©ã

##### **Addressing Social Misattributions of Large Language Models: An HCXAI-based Approach**
2403.17873v1 by Andrea Ferrario, Alberto Termine, Alessandro Facchini

Human-centered explainable AI (HCXAI) advocates for the integration of social
aspects into AI explanations. Central to the HCXAI discourse is the Social
Transparency (ST) framework, which aims to make the socio-organizational
context of AI systems accessible to their users. In this work, we suggest
extending the ST framework to address the risks of social misattributions in
Large Language Models (LLMs), particularly in sensitive areas like mental
health. In fact LLMs, which are remarkably capable of simulating roles and
personas, may lead to mismatches between designers' intentions and users'
perceptions of social attributes, risking to promote emotional manipulation and
dangerous behaviors, cases of epistemic injustice, and unwarranted trust. To
address these issues, we propose enhancing the ST framework with a fifth
'W-question' to clarify the specific social attributions assigned to LLMs by
its designers and users. This addition aims to bridge the gap between LLM
capabilities and user perceptions, promoting the ethically responsible
development and use of LLM-based technology.

æè¦ï¼ä»¥äººä¸ºæ¬çå¯è§£é AI (HCXAI) å¡å¯¼å°ç¤¾ä¼å±é¢æ´åå° AI è§£éä¸­ãHCXAI è¯è¯­çæ ¸å¿æ¯ç¤¾ä¼éæåº¦ (ST) æ¡æ¶ï¼å¶ç®æ æ¯è®© AI ç³»ç»çç¤¾ä¼ç»ç»èæ¯å¯¹ç¨æ·æ¥è¯´æ¯å¯çè§£çãå¨è¿é¡¹å·¥ä½ä¸­ï¼æä»¬å»ºè®®æ©å± ST æ¡æ¶ä»¥è§£å³å¤§åè¯­è¨æ¨¡å (LLM) ä¸­ç¤¾ä¼éè¯¯å½å çé£é©ï¼å°¤å¶æ¯å¨å¿çå¥åº·ç­ææé¢åãäºå®ä¸ï¼LLM è½å¤åºè²å°æ¨¡æè§è²åäººæ ¼ï¼è¿å¯è½å¯¼è´è®¾è®¡èçæå¾åç¨æ·å¯¹ç¤¾ä¼å±æ§çè®¤ç¥ä¹é´åºç°ééï¼ä»èæé£é©ä¿è¿æç»ªæçºµåå±é©è¡ä¸ºãè®¤ç¥ä¸å¬æ­£åä¸åççä¿¡ä»»ãä¸ºäºè§£å³è¿äºé®é¢ï¼æä»¬å»ºè®®ç¨ç¬¬äºä¸ªâW é®é¢âæ¥å¢å¼º ST æ¡æ¶ï¼ä»¥æç¡®è®¾è®¡èåç¨æ·èµäº LLM çå·ä½ç¤¾ä¼å±æ§ãæ­¤è¡¥åæ¨å¨å¼¥å LLM è½ååç¨æ·è®¤ç¥ä¹é´çå·®è·ï¼ä¿è¿åºäº LLM çææ¯å¨éå¾·ä¸è´è´£ä»»å°å¼ååä½¿ç¨ã

##### **Clinical Domain Knowledge-Derived Template Improves Post Hoc AI Explanations in Pneumothorax Classification**
2403.18871v1 by Han Yuan, Chuan Hong, Pengtao Jiang, Gangming Zhao, Nguyen Tuan Anh Tran, Xinxing Xu, Yet Yen Yan, Nan Liu

Background: Pneumothorax is an acute thoracic disease caused by abnormal air
collection between the lungs and chest wall. To address the opaqueness often
associated with deep learning (DL) models, explainable artificial intelligence
(XAI) methods have been introduced to outline regions related to pneumothorax
diagnoses made by DL models. However, these explanations sometimes diverge from
actual lesion areas, highlighting the need for further improvement. Method: We
propose a template-guided approach to incorporate the clinical knowledge of
pneumothorax into model explanations generated by XAI methods, thereby
enhancing the quality of these explanations. Utilizing one lesion delineation
created by radiologists, our approach first generates a template that
represents potential areas of pneumothorax occurrence. This template is then
superimposed on model explanations to filter out extraneous explanations that
fall outside the template's boundaries. To validate its efficacy, we carried
out a comparative analysis of three XAI methods with and without our template
guidance when explaining two DL models in two real-world datasets. Results: The
proposed approach consistently improved baseline XAI methods across twelve
benchmark scenarios built on three XAI methods, two DL models, and two
datasets. The average incremental percentages, calculated by the performance
improvements over the baseline performance, were 97.8% in Intersection over
Union (IoU) and 94.1% in Dice Similarity Coefficient (DSC) when comparing model
explanations and ground-truth lesion areas. Conclusions: In the context of
pneumothorax diagnoses, we proposed a template-guided approach for improving AI
explanations. We anticipate that our template guidance will forge a fresh
approach to elucidating AI models by integrating clinical domain expertise.

æè¦ï¼<paragraph>èæ¯ï¼æ°£è¸æ¯ä¸ç¨®å èºé¨èè¸å£ä¹éç°å¸¸éæ°£æå¼èµ·çæ¥æ§è¸èç¾çãçºäºè§£æ±ºæ·±åº¦å­¸ç¿ï¼DLï¼æ¨¡åç¶å¸¸ä¼´é¨çä¸éææ§ï¼å¯è§£éäººå·¥æºæ§ï¼XAIï¼æ¹æ³å·²è¢«å¼å¥ï¼ç¨æ¼æ¦è¿°è DL æ¨¡åååºçæ°£è¸è¨ºæ·ç¸éçååãç¶èï¼éäºè§£éæææèå¯¦éçç¶ååææåºå¥ï¼çªé¡¯åºé²ä¸æ­¥æ¹é²çå¿è¦æ§ãæ¹æ³ï¼æåæåºäºä¸ç¨®æ¨¡æ¿å¼å°å¼æ¹æ³ï¼å°æ°£è¸çè¨åºç¥è­ç´å¥ XAI æ¹æ³ç¢ççæ¨¡åè§£éä¸­ï¼å¾èæåéäºè§£éçåè³ªãå©ç¨æ¾å°ç§é«å¸«å»ºç«ççç¶æç¹ªï¼æåçåæ³é¦åç¢çä¸åæ¨¡æ¿ï¼ç¨æ¼è¡¨ç¤ºæ°£è¸å¯è½ç¼ççååãç¶å¾å°æ­¤æ¨¡æ¿çå å¨æ¨¡åè§£éä¸ï¼ä»¥ç¯©é¸åºè¶åºæ¨¡æ¿éççç¡éè§£éãçºäºé©è­å¶æåï¼æåå°ä¸ç¨® XAI æ¹æ³é²è¡äºæ¯è¼åæï¼å¨å©åçå¯¦ä¸çè³æéä¸­è§£éå©å DL æ¨¡åæï¼åå¥æ¡ç¨åä¸æ¡ç¨æåçæ¨¡æ¿å¼å°ãçµæï¼ææåºçæ¹æ³å¨å»ºç«æ¼ä¸ç¨® XAI æ¹æ³ãå©å DL æ¨¡ååå©åè³æéçåäºç¨®åºæºæå¢ä¸­ï¼å§çµæ¹åäºåºæº XAI æ¹æ³ãå¨æ¯è¼æ¨¡åè§£éåçå¯¦çç¶ååæï¼ééåºæºæè½çæè½æ¹é²è¨ç®åºçå¹³åå¢éç¾åæ¯çºäº¤éæ¯ï¼IoUï¼ç 97.8% åéª°å­ç¸ä¼¼æ§ä¿æ¸ï¼DSCï¼ç 94.1%ãçµè«ï¼å¨æ°£è¸è¨ºæ·çèæ¯ä¸ï¼æåæåºäºä¸ç¨®æ¨¡æ¿å¼å°å¼æ¹æ³ï¼ç¨æ¼æ¹å AI è§£éãæåé ææåçæ¨¡æ¿å¼å°å°ééæ´åè¨åºé åå°æ¥­ç¥è­ï¼çºé¡æ AI æ¨¡åå»ºç«ä¸ç¨®æ°æ¹æ³ã</paragraph>

##### **Enhancing Neural Machine Translation of Low-Resource Languages: Corpus Development, Human Evaluation and Explainable AI Architectures**
2403.01580v1 by SÃ©amus Lankford

In the current machine translation (MT) landscape, the Transformer
architecture stands out as the gold standard, especially for high-resource
language pairs. This research delves into its efficacy for low-resource
language pairs including both the English$\leftrightarrow$Irish and
English$\leftrightarrow$Marathi language pairs. Notably, the study identifies
the optimal hyperparameters and subword model type to significantly improve the
translation quality of Transformer models for low-resource language pairs.
  The scarcity of parallel datasets for low-resource languages can hinder MT
development. To address this, gaHealth was developed, the first bilingual
corpus of health data for the Irish language. Focusing on the health domain,
models developed using this in-domain dataset exhibited very significant
improvements in BLEU score when compared with models from the LoResMT2021
Shared Task. A subsequent human evaluation using the multidimensional quality
metrics error taxonomy showcased the superior performance of the Transformer
system in reducing both accuracy and fluency errors compared to an RNN-based
counterpart.
  Furthermore, this thesis introduces adaptNMT and adaptMLLM, two open-source
applications streamlined for the development, fine-tuning, and deployment of
neural machine translation models. These tools considerably simplify the setup
and evaluation process, making MT more accessible to both developers and
translators. Notably, adaptNMT, grounded in the OpenNMT ecosystem, promotes
eco-friendly natural language processing research by highlighting the
environmental footprint of model development. Fine-tuning of MLLMs by adaptMLLM
demonstrated advancements in translation performance for two low-resource
language pairs: English$\leftrightarrow$Irish and
English$\leftrightarrow$Marathi, compared to baselines from the LoResMT2021
Shared Task.

æè¦ï¼<paragraph>å¨ç¶åæ©å¨ç¿»è­¯ (MT) é åä¸­ï¼Transformer æ¶æ§è«ç©èåºï¼æçºé»éæ¨æºï¼ç¹å¥æ¯å°æ¼é«è³æºèªè¨å°ãæ¬ç ç©¶æ¢è¨å¶å°ä½è³æºèªè¨å°çæè½ï¼åæ¬è±èªâæç¾è­èªåè±èªâé¦¬æå°èªèªè¨å°ãå¼å¾æ³¨æçæ¯ï¼æ¬ç ç©¶è­å¥åºæä½³è¶åæ¸åå­è©æ¨¡åé¡åï¼ä»¥é¡¯èæé« Transformer æ¨¡åå°ä½è³æºèªè¨å°çç¿»è­¯åè³ªã
ä½è³æºèªè¨çå¹³è¡è³æéçç¨ç¼ºæé»ç¤ MT çç¼å±ãçºäºè§£æ±ºéååé¡ï¼éç¼äº gaHealthï¼éæ¯æç¾è­èªçç¬¬ä¸åéèªå¥åº·è³æèªæåº«ãå°æ³¨æ¼å¥åº·é åï¼ä½¿ç¨æ­¤åå§è³æééç¼çæ¨¡åå¨ BLEU å¾åæ¹é¢è¡¨ç¾åºéå¸¸é¡¯èçé²æ­¥ï¼è LoResMT2021 å±äº«ä»»åä¸­çæ¨¡åç¸æ¯ãé¨å¾ä½¿ç¨å¤ç¶­åè³ªææ¨é¯èª¤åé¡æ³é²è¡çäººå·¥è©ä¼°é¡¯ç¤ºï¼èåºæ¼ RNN çå°ææ¨¡åç¸æ¯ï¼Transformer ç³»çµ±å¨æ¸å°æºç¢ºæ§åæµæ¢æ§é¯èª¤æ¹é¢è¡¨ç¾åºåªç°çæ§è½ã
æ­¤å¤ï¼æ¬è«æä»ç´¹äº adaptNMT å adaptMLLMï¼éå©åéæºæç¨ç¨å¼ç°¡åäºç¥ç¶æ©å¨ç¿»è­¯æ¨¡åçéç¼ãå¾®èª¿åé¨ç½²ãéäºå·¥å·å¤§å¹ç°¡åäºè¨­å®åè©ä¼°æµç¨ï¼è® MT æ´å®¹æè®éç¼äººå¡åç¿»è­¯äººå¡ä½¿ç¨ãå¼å¾æ³¨æçæ¯ï¼adaptNMT ä»¥ OpenNMT çæç³»çµ±çºåºç¤ï¼ééå¼·èª¿æ¨¡åéç¼çç°å¢è¶³è·¡ä¾ä¿é²çæåå¥½çèªç¶èªè¨èçç ç©¶ãè LoResMT2021 å±äº«ä»»åä¸­çåºæºç¸æ¯ï¼adaptMLLM å° MLLM çå¾®èª¿è­æäºè±èªâæç¾è­èªåè±èªâé¦¬æå°èªéå©åä½è³æºèªè¨å°çç¿»è­¯æ§è½é²æ­¥ã</paragraph>

##### **Cause and Effect: Can Large Language Models Truly Understand Causality?**
2402.18139v3 by Swagata Ashwani, Kshiteesh Hegde, Nishith Reddy Mannuru, Mayank Jindal, Dushyant Singh Sengar, Krishna Chaitanya Rao Kathala, Dishant Banga, Vinija Jain, Aman Chadha

With the rise of Large Language Models(LLMs), it has become crucial to
understand their capabilities and limitations in deciphering and explaining the
complex web of causal relationships that language entails. Current methods use
either explicit or implicit causal reasoning, yet there is a strong need for a
unified approach combining both to tackle a wide array of causal relationships
more effectively. This research proposes a novel architecture called Context
Aware Reasoning Enhancement with Counterfactual Analysis(CARE CA) framework to
enhance causal reasoning and explainability. The proposed framework
incorporates an explicit causal detection module with ConceptNet and
counterfactual statements, as well as implicit causal detection through LLMs.
Our framework goes one step further with a layer of counterfactual explanations
to accentuate LLMs understanding of causality. The knowledge from ConceptNet
enhances the performance of multiple causal reasoning tasks such as causal
discovery, causal identification and counterfactual reasoning. The
counterfactual sentences add explicit knowledge of the not caused by scenarios.
By combining these powerful modules, our model aims to provide a deeper
understanding of causal relationships, enabling enhanced interpretability.
Evaluation of benchmark datasets shows improved performance across all metrics,
such as accuracy, precision, recall, and F1 scores. We also introduce
CausalNet, a new dataset accompanied by our code, to facilitate further
research in this domain.

æè¦ï¼é¨èå¤§åèªè¨æ¨¡å (LLM) çèèµ·ï¼äºè§£å®åå¨è§£ç¢¼åè§£éèªè¨æèå«çè¤éå æéä¿ç¶²è·¯ä¸­çè½ååéå¶è®å¾è³ééè¦ãç®åçæè¡ä½¿ç¨æç¢ºæé±å«çå ææ¨çï¼ä½å¼·çéè¦ä¸ç¨®çµ±ä¸çæ¹æ³ï¼çµåå©èä»¥æ´ææå°èçå»£æ³çå æéä¿ãæ¬ç ç©¶æåºäºä¸ç¨®ç¨±çºæå¢æç¥æ¨çå¢å¼·èåäºå¯¦åæ (CARE CA) æ¡æ¶çæ°æ¶æ§ï¼ä»¥å¢å¼·å ææ¨çåå¯è§£éæ§ãæåºçæ¡æ¶çµåäºä½¿ç¨ ConceptNet ååäºå¯¦é³è¿°çæç¢ºå ææª¢æ¸¬æ¨¡çµï¼ä»¥åéé LLM é²è¡çé±å«å ææª¢æ¸¬ãæåçæ¡æ¶æ´é²ä¸æ­¥ï¼å å¥ä¸å±¤åäºå¯¦è§£éï¼ä»¥å¼·èª¿ LLM å°å æéä¿ççè§£ãä¾èª ConceptNet çç¥è­å¢å¼·äºå¤é å ææ¨çä»»åçå·è¡ï¼ä¾å¦å æç¼ç¾ãå æè­å¥ååäºå¯¦æ¨çãåäºå¯¦å¥å å¥äºæªç±æå¢é æçæç¢ºç¥è­ãééçµåéäºå¼·å¤§çæ¨¡çµï¼æåçæ¨¡åæ¨å¨æä¾å°å æéä¿æ´æ·±å¥ççè§£ï¼å¯¦ç¾å¢å¼·çå¯è§£éæ§ãåºæºè³æéçè©ä¼°é¡¯ç¤ºå¨ææææ¨ï¼ä¾å¦æºç¢ºåº¦ãç²¾ç¢ºåº¦ãå¬åçå F1 åæ¸ï¼ä¸é½æææåãæåéå¼å¥äº CausalNetï¼ä¸åæ°çè³æéï¼ä¸¦éä¸äºæåçç¨å¼ç¢¼ï¼ä»¥ä¿é²å¨éåé åçé²ä¸æ­¥ç ç©¶ã

##### **Artificial Intelligence and Diabetes Mellitus: An Inside Look Through the Retina**
2402.18600v1 by Yasin Sadeghi Bazargani, Majid Mirzaei, Navid Sobhi, Mirsaeed Abdollahi, Ali Jafarizadeh, Siamak Pedrammehr, Roohallah Alizadehsani, Ru San Tan, Sheikh Mohammed Shariful Islam, U. Rajendra Acharya

Diabetes mellitus (DM) predisposes patients to vascular complications.
Retinal images and vasculature reflect the body's micro- and macrovascular
health. They can be used to diagnose DM complications, including diabetic
retinopathy (DR), neuropathy, nephropathy, and atherosclerotic cardiovascular
disease, as well as forecast the risk of cardiovascular events. Artificial
intelligence (AI)-enabled systems developed for high-throughput detection of DR
using digitized retinal images have become clinically adopted. Beyond DR
screening, AI integration also holds immense potential to address challenges
associated with the holistic care of the patient with DM. In this work, we aim
to comprehensively review the literature for studies on AI applications based
on retinal images related to DM diagnosis, prognostication, and management. We
will describe the findings of holistic AI-assisted diabetes care, including but
not limited to DR screening, and discuss barriers to implementing such systems,
including issues concerning ethics, data privacy, equitable access, and
explainability. With the ability to evaluate the patient's health status vis a
vis DM complication as well as risk prognostication of future cardiovascular
complications, AI-assisted retinal image analysis has the potential to become a
central tool for modern personalized medicine in patients with DM.

æè¦ï¼ç³å°¿çï¼DMï¼ä½¿æ£èå®¹æåºç¾è¡ç®¡ä½µç¼çã
è¦ç¶²èå½±ååè¡ç®¡åæ èº«é«çå¾®è¡ç®¡åå·¨è¡ç®¡å¥åº·çæ³ãå®åå¯ç¨æ¼è¨ºæ·ç³å°¿çä½µç¼çï¼åæ¬ç³å°¿çè¦ç¶²èçè®ï¼DRï¼ãç¥ç¶çè®ãèçååèç²¥æ¨£ç¡¬åæ§å¿è¡ç®¡ç¾çï¼ä»¥åé æ¸¬å¿è¡ç®¡äºä»¶çé¢¨éªãçºä½¿ç¨æ¸ä½åè¦ç¶²èå½±åé²è¡é«éé DR æª¢æ¸¬èéç¼çäººå·¥æºæ§ï¼AIï¼åç¨ç³»çµ±å·²å¨è¨åºæ¡ç¨ãé¤äº DR ç¯©æª¢å¤ï¼AI æ´åä¹å·æå·¨å¤§çæ½åä¾æå°èç³å°¿çæ£èæ´é«ç§è­·ç¸éçææ°ãå¨éé å·¥ä½ä¸­ï¼æåæ¨å¨å¨é¢åé¡§åºæ¼è¦ç¶²èå½±åç AI æç¨ç¸éç ç©¶çæç»ï¼éäºç ç©¶èç³å°¿ççè¨ºæ·ãé å¾åç®¡çæéãæåå°æè¿°æ´é« AI è¼å©ç³å°¿çç§è­·çç¼ç¾ï¼åæ¬ä½ä¸éæ¼ DR ç¯©æª¢ï¼ä¸¦è¨è«å¯¦æ½æ­¤é¡ç³»çµ±çéç¤ï¼åæ¬èå«çãè³æé±ç§ãå¬å¹³å­ååå¯è§£éæ§æéçåé¡ãééè©ä¼°æ£èçå¥åº·çæ³ï¼åæèéç³å°¿çä½µç¼çä»¥åæªä¾å¿è¡ç®¡ä½µç¼ççé¢¨éªé å¾ï¼AI è¼å©è¦ç¶²èå½±ååæææ½åæçºç³å°¿çæ£èç¾ä»£ååäººåé«ççä¸­å¿å·¥å·ã

##### **Multi-stakeholder Perspective on Responsible Artificial Intelligence and Acceptability in Education**
2402.15027v2 by A. J. Karran, P. Charland, J-T. Martineau, A. Ortiz de Guinea Lopez de Arana, AM. Lesage, S. Senecal, P-M. Leger

This study investigates the acceptability of different artificial
intelligence (AI) applications in education from a multi-stakeholder
perspective, including students, teachers, and parents. Acknowledging the
transformative potential of AI in education, it addresses concerns related to
data privacy, AI agency, transparency, explainability and the ethical
deployment of AI. Through a vignette methodology, participants were presented
with four scenarios where AI's agency, transparency, explainability, and
privacy were manipulated. After each scenario, participants completed a survey
that captured their perceptions of AI's global utility, individual usefulness,
justice, confidence, risk, and intention to use each scenario's AI if
available. The data collection comprising a final sample of 1198
multi-stakeholder participants was distributed through a partner institution
and social media campaigns and focused on individual responses to four AI use
cases. A mediation analysis of the data indicated that acceptance and trust in
AI varies significantly across stakeholder groups. We found that the key
mediators between high and low levels of AI's agency, transparency, and
explainability, as well as the intention to use the different educational AI,
included perceived global utility, justice, and confidence. The study
highlights that the acceptance of AI in education is a nuanced and multifaceted
issue that requires careful consideration of specific AI applications and their
characteristics, in addition to the diverse stakeholders' perceptions.

æè¦ï¼éé ç ç©¶å¾å¤åå©å®³éä¿äººçè§åº¦æ¢è¨ä¸åçäººå·¥æºæ§ (AI) æç¨å¨æè²ä¸çå¯æ¥åæ§ï¼åæ¬å­¸çãèå¸«åå®¶é·ãæ¿èª AI å¨æè²ä¸çè½åæ½åï¼å®è§£æ±ºäºèè³æé±ç§ãAI ä»£çãéæåº¦ãå¯è§£éæ§å AI çéå¾·é¨ç½²ç¸éççæ®ãééå°ææ²æ¹æ³ï¼åèèè¢«åç¾äºåç¨®æå¢ï¼å¶ä¸­ AI çä»£çãéæåº¦ãå¯è§£éæ§åé±ç§åå°æç¸±ãå¨æ¯åæå¢å¾ï¼åèèå®æäºä¸é èª¿æ¥ï¼è©²èª¿æ¥ææäºä»åå° AI çæ´é«æç¨ãåäººæç¨ãæ­£ç¾©ãä¿¡å¿ãé¢¨éªåå¦æå¯ç¨ï¼ä½¿ç¨æ¯åæå¢ç AI çæåççæ³ãè³æèéåå«ä¾èªåä½æ©æ§åç¤¾ç¾¤åªé«æ´»åç 1198 ä½å¤å©å®³éä¿äººåèèçæçµæ¨£æ¬ï¼ä¸¦å°æ³¨æ¼å°åå AI ä½¿ç¨æ¡ä¾çåå¥åæãå°è³æçèª¿è§£åæè¡¨æï¼å° AI çæ¥ååº¦åä¿¡ä»»å¨å©å®³éä¿äººåé«ä¹éæé¡¯èå·®ç°ãæåç¼ç¾ï¼AI çä»£çãéæåº¦åå¯è§£éæ§é«ä½ç¨åº¦ä¹éçééµèª¿è§£èï¼ä»¥åä½¿ç¨ä¸åæè² AI çæåï¼åæ¬æç¥å°çæ´é«æç¨ãæ­£ç¾©åä¿¡å¿ãéé ç ç©¶å¼·èª¿ï¼æ¥å AI å¨æè²ä¸çæç¨æ¯ä¸åå¾®å¦ä¸å¤é¢åçåé¡ï¼é¤äºä¸åçå©å®³éä¿äººççæ³å¤ï¼ééè¦ä»ç´°èæ®å·é«ç AI æç¨åå¶ç¹å¾µã

##### **Deciphering Heartbeat Signatures: A Vision Transformer Approach to Explainable Atrial Fibrillation Detection from ECG Signals**
2402.09474v2 by Aruna Mohan, Danne Elbers, Or Zilbershot, Fatemeh Afghah, David Vorchheimer

Remote patient monitoring based on wearable single-lead electrocardiogram
(ECG) devices has significant potential for enabling the early detection of
heart disease, especially in combination with artificial intelligence (AI)
approaches for automated heart disease detection. There have been prior studies
applying AI approaches based on deep learning for heart disease detection.
However, these models are yet to be widely accepted as a reliable aid for
clinical diagnostics, in part due to the current black-box perception
surrounding many AI algorithms. In particular, there is a need to identify the
key features of the ECG signal that contribute toward making an accurate
diagnosis, thereby enhancing the interpretability of the model. In the present
study, we develop a vision transformer approach to identify atrial fibrillation
based on single-lead ECG data. A residual network (ResNet) approach is also
developed for comparison with the vision transformer approach. These models are
applied to the Chapman-Shaoxing dataset to classify atrial fibrillation, as
well as another common arrhythmia, sinus bradycardia, and normal sinus rhythm
heartbeats. The models enable the identification of the key regions of the
heartbeat that determine the resulting classification, and highlight the
importance of P-waves and T-waves, as well as heartbeat duration and signal
amplitude, in distinguishing normal sinus rhythm from atrial fibrillation and
sinus bradycardia.

æè¦ï¼<paragraph>åºæ¼å¯ç©¿æ´å¼å®å°ç¨å¿é»å (ECG) è£ç½®çé ç«¯çæ£ç£æ¸¬å¨æ©æåµæ¸¬å¿èç¾çæ¹é¢å·æé¡¯èçæ½åï¼ç¹å¥æ¯èç¨æ¼èªååå¿èç¾çåµæ¸¬çäººå·¥æºæ§ (AI) æ¹æ³çµåä½¿ç¨æãååå·²æç ç©¶æç¨åºæ¼æ·±åº¦å­¸ç¿ç AI æ¹æ³é²è¡å¿èç¾çåµæ¸¬ãç¶èï¼éäºæ¨¡åå°æªè¢«å»£æ³æ¥åçºè¨åºè¨ºæ·çå¯é è¼å©å·¥å·ï¼é¨ååå å¨æ¼åç¹è¨±å¤ AI æ¼ç®æ³çç¶åé»ç®±æç¥ãç¹å¥æ¯ï¼æå¿è¦æ¾åºæå©æ¼ååºæºç¢ºè¨ºæ·ç ECG è¨èééµç¹å¾µï¼å¾èå¢å¼·æ¨¡åçå¯è§£éæ§ãå¨æ¬ç ç©¶ä¸­ï¼æåéç¼äºä¸ç¨®è¦è¦ºè½æå¨æ¹æ³ï¼ä»¥æ ¹æå®å°ç¨ ECG è³ææ¾åºå¿æ¿é¡«åãæ®å·®ç¶²è·¯ (ResNet) æ¹æ³ä¹å·²éç¼åºä¾ï¼ä»¥ä¾¿èè¦è¦ºè½æå¨æ¹æ³é²è¡æ¯è¼ãéäºæ¨¡åæç¨æ¼ Chapman-Shaoxing è³æéï¼ä»¥åé¡å¿æ¿é¡«åï¼ä»¥åå¦ä¸ç¨®å¸¸è¦çå¿å¾ä¸æ´ï¼ç«æ§å¿åéç·©ï¼åæ­£å¸¸ç«æ§å¿å¾çå¿è·³ãéäºæ¨¡åè½å¤ æ¾åºæ±ºå®æçµåé¡çå¿è·³ééµååï¼ä¸¦å¼·èª¿ P æ³¢å T æ³¢ï¼ä»¥åå¿è·³æçºæéåè¨èæ¯å¹å¨ååæ­£å¸¸ç«æ§å¿å¾èå¿æ¿é¡«ååç«æ§å¿åéç·©æ¹é¢çéè¦æ§ã</paragraph>

##### **Illuminate: A novel approach for depression detection with explainable analysis and proactive therapy using prompt engineering**
2402.05127v1 by Aryan Agrawal

This paper introduces a novel paradigm for depression detection and treatment
using advanced Large Language Models (LLMs): Generative Pre-trained Transformer
4 (GPT-4), Llama 2 chat, and Gemini. These LLMs are fine-tuned with specialized
prompts to diagnose, explain, and suggest therapeutic interventions for
depression. A unique few-shot prompting method enhances the models' ability to
analyze and explain depressive symptoms based on the DSM-5 criteria. In the
interaction phase, the models engage in empathetic dialogue management, drawing
from resources like PsychDB and a Cognitive Behavioral Therapy (CBT) Guide,
fostering supportive interactions with individuals experiencing major
depressive disorders. Additionally, the research introduces the Illuminate
Database, enriched with various CBT modules, aiding in personalized therapy
recommendations. The study evaluates LLM performance using metrics such as F1
scores, Precision, Recall, Cosine similarity, and Recall-Oriented Understudy
for Gisting Evaluation (ROUGE) across different test sets, demonstrating their
effectiveness. This comprehensive approach blends cutting-edge AI with
established psychological methods, offering new possibilities in mental health
care and showcasing the potential of LLMs in revolutionizing depression
diagnosis and treatment strategies.

æè¦ï¼æ¬æä»ç´¹äºä¸ç¨®ä½¿ç¨åé²å¤§åèªè¨æ¨¡å (LLM) é²è¡æé¬±çåµæ¸¬åæ²»ççæ°æ¨¡å¼ï¼çæå¼é è¨ç·´Transformer 4 (GPT-4)ãLlama 2 èå¤©æ©å¨äººå Geminiãéäº LLM ç¶éå¾®èª¿ï¼å·åå°æ¥­æç¤ºï¼å¯è¨ºæ·ãè§£éä¸¦å»ºè­°æé¬±ççæ²»çä»å¥æ¹æ³ãä¸ç¨®ç¨ç¹çå°æ¬¡æç¤ºæ¹æ³å¢å¼·äºæ¨¡åæ ¹æ DSM-5 æ¨æºåæåè§£éæé¬±çççè½åãå¨äºåéæ®µï¼éäºæ¨¡åæåèåçå¿å°è©±ç®¡çï¼å¾ PsychDB åèªç¥è¡çºçæ³ (CBT) æåç­è³æºä¸­æ±²åï¼ä¿é²èç¶æ­·éåº¦æé¬±ççäººåçæ¯ææ§äºåãæ­¤å¤ï¼éé ç ç©¶éä»ç´¹äº Illuminate è³æåº«ï¼å¶ä¸­åå«åç¨® CBT æ¨¡çµï¼æå©æ¼åæ§åæ²»çå»ºè­°ãéé ç ç©¶ä½¿ç¨ F1 åæ¸ãæºç¢ºçãå¬åçãé¤å¼¦ç¸ä¼¼åº¦åé¢åå¬åçç Gisting è©ä¼°æ¿èº« (ROUGE) ç­ææ¨ï¼å¨ä¸åçæ¸¬è©¦éä¸­è©ä¼° LLM çè¡¨ç¾ï¼è­æäºå®åçæææ§ãéç¨®ç¶åæ¹æ³çµåäºå°ç«¯ç AI èæ¢å®çå¿çæ¹æ³ï¼çºå¿çä¿å¥æä¾äºæ°çå¯è½æ§ï¼ä¸¦å±ç¤ºäº LLM å¨é©æ°æé¬±çè¨ºæ·åæ²»çç­ç¥æ¹é¢çæ½åã

##### **Information That Matters: Exploring Information Needs of People Affected by Algorithmic Decisions**
2401.13324v6 by TimothÃ©e Schmude, Laura Koesten, Torsten MÃ¶ller, Sebastian Tschiatschek

Every AI system that makes decisions about people has a group of stakeholders
that are personally affected by these decisions. However, explanations of AI
systems rarely address the information needs of this stakeholder group, who
often are AI novices. This creates a gap between conveyed information and
information that matters to those who are impacted by the system's decisions,
such as domain experts and decision subjects. To address this, we present the
"XAI Novice Question Bank," an extension of the XAI Question Bank containing a
catalog of information needs from AI novices in two use cases: employment
prediction and health monitoring. The catalog covers the categories of data,
system context, system usage, and system specifications. We gathered
information needs through task-based interviews where participants asked
questions about two AI systems to decide on their adoption and received verbal
explanations in response. Our analysis showed that participants' confidence
increased after receiving explanations but that their understanding faced
challenges. These included difficulties in locating information and in
assessing their own understanding, as well as attempts to outsource
understanding. Additionally, participants' prior perceptions of the systems'
risks and benefits influenced their information needs. Participants who
perceived high risks sought explanations about the intentions behind a system's
deployment, while those who perceived low risks rather asked about the system's
operation. Our work aims to support the inclusion of AI novices in
explainability efforts by highlighting their information needs, aims, and
challenges. We summarize our findings as five key implications that can inform
the design of future explanations for lay stakeholder audiences.

æè¦ï¼<paragraph>æ¯åå°äººååºæ±ºå®ç AI ç³»çµ±é½æä¸ç¾¤å©å®³éä¿äºº
åå°éäºæ±ºå®çè¦ªèº«å½±é¿ãç¶èï¼AI
ç³»çµ±çè§£éå¾å°è½æ»¿è¶³éç¾¤å©å®³éä¿äººçè³è¨éæ±ï¼èä»å
éå¸¸é½æ¯ AI æ°æãéé æäºå³éè³è¨è
åå°ç³»çµ±æ±ºç­å½±é¿çäººå£«ï¼ä¾å¦é åå°å®¶åæ±ºç­ä¸»é«ï¼éè¦çè³è¨ä¹éçè½å·®ãçºäºè§£æ±ºéååé¡ï¼æåæåºäº
ãXAI æ°æåé¡åº«ãï¼å®æ¯ XAI åé¡åº«çå»¶ä¼¸ï¼åå«ä¾èª AI æ°æå¨å©åä½¿ç¨æ¡ä¾ä¸­çè³è¨éæ±ç®éï¼å°±æ¥­
é æ¸¬åå¥åº·ç£æ¸¬ãç®éæ¶µèäºè³æã
ç³»çµ±èæ¯ãç³»çµ±ä½¿ç¨åç³»çµ±è¦æ ¼ç­é¡å¥ãæåééä»»ååè¨ªè«æ¶éè³è¨éæ±ï¼åèèå¨è¨ªè«ä¸­è©¢åäºå©å AI ç³»çµ±çåé¡ï¼ä»¥æ±ºå®æ¯å¦æ¡ç¨å®åï¼ä¸¦æ¶å°å£é ­
è§£éä½çºåæãæåçåæé¡¯ç¤ºï¼åèèå¨æ¶å°è§£éå¾ä¿¡å¿æææåï¼ä½ä»åççè§£å»é¢è¨ææ°ãéäºææ°åæ¬é£ä»¥æ¾å°è³è¨åè©ä¼°èªå·±ççè§£ï¼ä»¥åè©¦åå¤å
çè§£ãæ­¤å¤ï¼åèèå°ç³»çµ±é¢¨éªåå¥½èçåååé¥å½±é¿äºä»åçè³è¨éæ±ãèªçºé¢¨éªé«çåèèå°æ±è§£éç³»çµ±é¨ç½²èå¾çæåï¼èèªçºé¢¨éªä½çäººåè©¢åç³»çµ±ç
æä½ãæåçç ç©¶æ¨å¨ééå¼·èª¿ AI æ°æçè³è¨éæ±ãç®æ¨å
ææ°ï¼ä¾æ¯æå° AI æ°æç´å¥å¯è§£éæ§å·¥ä½ä¸­ãæåå°æåçç ç©¶çµæç¸½çµçºäºåééµåç¤ºï¼éäºåç¤ºå¯ä»¥çºæªä¾éå°éå°æ¥­å©å®³éä¿äººåç¾çè§£éè¨­è¨æä¾åèã</paragraph>

##### **Evaluating Large Language Models on the GMAT: Implications for the Future of Business Education**
2401.02985v1 by Vahid Ashrafimoghari, Necdet GÃ¼rkan, Jordan W. Suchow

The rapid evolution of artificial intelligence (AI), especially in the domain
of Large Language Models (LLMs) and generative AI, has opened new avenues for
application across various fields, yet its role in business education remains
underexplored. This study introduces the first benchmark to assess the
performance of seven major LLMs, OpenAI's models (GPT-3.5 Turbo, GPT-4, and
GPT-4 Turbo), Google's models (PaLM 2, Gemini 1.0 Pro), and Anthropic's models
(Claude 2 and Claude 2.1), on the GMAT, which is a key exam in the admission
process for graduate business programs. Our analysis shows that most LLMs
outperform human candidates, with GPT-4 Turbo not only outperforming the other
models but also surpassing the average scores of graduate students at top
business schools. Through a case study, this research examines GPT-4 Turbo's
ability to explain answers, evaluate responses, identify errors, tailor
instructions, and generate alternative scenarios. The latest LLM versions,
GPT-4 Turbo, Claude 2.1, and Gemini 1.0 Pro, show marked improvements in
reasoning tasks compared to their predecessors, underscoring their potential
for complex problem-solving. While AI's promise in education, assessment, and
tutoring is clear, challenges remain. Our study not only sheds light on LLMs'
academic potential but also emphasizes the need for careful development and
application of AI in education. As AI technology advances, it is imperative to
establish frameworks and protocols for AI interaction, verify the accuracy of
AI-generated content, ensure worldwide access for diverse learners, and create
an educational environment where AI supports human expertise. This research
sets the stage for further exploration into the responsible use of AI to enrich
educational experiences and improve exam preparation and assessment methods.

æè¦ï¼äººå·¥æºæ§ (AI) çå¿«éæ¼é²ï¼å°¤å¶æ¯å¨å¤§åèªè¨æ¨¡å (LLM) åçæå¼ AI çé åï¼çºååé åçæç¨éåäºæ°éå¾ï¼ä½å¶å¨åæ¥­æè²ä¸­çè§è²ä»æªè¢«ååæ¢è¨ãæ¬ç ç©¶é¦æ¬¡å¼å¥äºåºæºï¼ç¨ä»¥è©ä¼°ä¸åä¸»è¦ LLM çæè½ï¼åæ¬ OpenAI çæ¨¡å (GPT-3.5 TurboãGPT-4 å GPT-4 Turbo)ãGoogle çæ¨¡å (PaLM 2ãGemini 1.0 Pro) å Anthropic çæ¨¡å (Claude 2 å Claude 2.1)ï¼éäºæ¨¡åå°ç¨æ¼ç ç©¶çåæ¥­èª²ç¨å¥å­¸ç¨åºä¸­çééµèè©¦ GMATãæåçåæé¡¯ç¤ºï¼å¤§å¤æ¸ LLM çè¡¨ç¾é½åªæ¼äººé¡èçï¼å¶ä¸­ GPT-4 Turbo ä¸ååªæ¼å¶ä»æ¨¡åï¼æ´è¶è¶äºé å°åå­¸é¢çç ç©¶çå¹³ååæ¸ãééæ¡ä¾ç ç©¶ï¼æ¬ç ç©¶æ¢è¨äº GPT-4 Turbo å¨è§£éç­æ¡ãè©ä¼°åæãè¾¨è­é¯èª¤ãèª¿æ´èªªæåç¢çæ¿ä»£æå¢æ¹é¢çè½åãèåä¸ä»£çæ¬ç¸æ¯ï¼ææ°ç LLM çæ¬ GPT-4 TurboãClaude 2.1 å Gemini 1.0 Pro å¨æ¨çä»»åæ¹é¢æé¡¯èçé²æ­¥ï¼å¸é¡¯äºå¶å¨è§£æ±ºè¤éåé¡æ¹é¢çæ½åãåç®¡ AI å¨æè²ãè©éåè¼å°æ¹é¢çæ¿è«¾å¾æç¢ºï¼ä½ä»æææ°å­å¨ãæåçç ç©¶ä¸åé¡æäº LLM çå­¸è¡æ½åï¼ä¹å¼·èª¿äºå¨æè²ä¸­å¯©æéç¼åæç¨ AI çå¿è¦æ§ãé¨è AI æè¡çé²æ­¥ï¼å»ºç« AI äºåçæ¶æ§ååå®ãé©è­ AI çæçå§å®¹çæºç¢ºæ§ãç¢ºä¿å¨çåå°å¤åå­¸ç¿èçå­åæ¬ï¼ä»¥ååµé ä¸å AI æ¯æäººé¡å°æ¥­ç¥è­çæè²ç°å¢è³ééè¦ãæ¬ç ç©¶çºé²ä¸æ­¥æ¢ç´¢è² è²¬ä»»å°ä½¿ç¨ AI ä¾è±å¯æè²é«é©ä¸¦æ¹åèè©¦æºååè©éæ¹æ³å¥ å®äºåºç¤ã

##### **XAI for In-hospital Mortality Prediction via Multimodal ICU Data**
2312.17624v1 by Xingqiao Li, Jindong Gu, Zhiyong Wang, Yancheng Yuan, Bo Du, Fengxiang He

Predicting in-hospital mortality for intensive care unit (ICU) patients is
key to final clinical outcomes. AI has shown advantaged accuracy but suffers
from the lack of explainability. To address this issue, this paper proposes an
eXplainable Multimodal Mortality Predictor (X-MMP) approaching an efficient,
explainable AI solution for predicting in-hospital mortality via multimodal ICU
data. We employ multimodal learning in our framework, which can receive
heterogeneous inputs from clinical data and make decisions. Furthermore, we
introduce an explainable method, namely Layer-Wise Propagation to Transformer,
as a proper extension of the LRP method to Transformers, producing explanations
over multimodal inputs and revealing the salient features attributed to
prediction. Moreover, the contribution of each modality to clinical outcomes
can be visualized, assisting clinicians in understanding the reasoning behind
decision-making. We construct a multimodal dataset based on MIMIC-III and
MIMIC-III Waveform Database Matched Subset. Comprehensive experiments on
benchmark datasets demonstrate that our proposed framework can achieve
reasonable interpretation with competitive prediction accuracy. In particular,
our framework can be easily transferred to other clinical tasks, which
facilitates the discovery of crucial factors in healthcare research.

æè¦ï¼é æ¸¬å è­·çæ¿ (ICU) çæ£çé¢å§æ­»äº¡çæ¯æçµè¨åºçµæçééµãAI å·²å±ç¾åºåªç°çæºç¢ºåº¦ï¼ä½å»ç¼ºä¹å¯è§£éæ§ãçºäºè§£æ±ºéååé¡ï¼æ¬ææåºäºä¸åå¯è§£éçå¤æ¨¡å¼æ­»äº¡çé æ¸¬å¨ (X-MMP)ï¼æ¡ç¨ææä¸å¯è§£éç AI æ¹å¼ï¼èç±å¤æ¨¡å¼ ICU è³æä¾é æ¸¬é¢å§æ­»äº¡çãæåå¨æ¶æ§ä¸­æ¡ç¨å¤æ¨¡å¼å­¸ç¿ï¼å¯ä»¥æ¥æ¶ä¾èªè¨åºè³æçç°è³ªè¼¸å¥ä¸¦ååºæ±ºç­ãæ­¤å¤ï¼æåå¼å¥äºä¸åå¯è§£éçæ¹æ³ï¼ä¹å°±æ¯åå±¤å³æ­è³ Transformerï¼ä½çº LRP æ¹æ³é©ç¶å°å»¶ä¼¸è³ Transformerï¼å°å¤æ¨¡å¼è¼¸å¥ç¢çè§£éï¼ä¸¦æ­é²æ­¸å æ¼é æ¸¬çé¡¯èç¹å¾µãæ­¤å¤ï¼æ¯åæ¨¡å¼å°è¨åºçµæçè²¢ç»å¯ä»¥è¦è¦ºåï¼åå©è¨åºé«å¸«äºè§£æ±ºç­èå¾ççç±ãæåæ ¹æ MIMIC-III å MIMIC-III æ³¢å½¢è³æåº«æ¯å°å­éå»ºæ§äºä¸åå¤æ¨¡å¼è³æéãå¨åºæºè³æéä¸çå¨é¢å¯¦é©è­æï¼æåæåºçæ¶æ§å¯ä»¥éæåççè©®éï¼ä¸¦å·åç«¶ç­åçé æ¸¬æºç¢ºåº¦ãç¹å¥æ¯ï¼æåçæ¶æ§å¯ä»¥è¼é¬å°è½ç§»å°å¶ä»è¨åºä»»åï¼éæå©æ¼å¨é«çä¿å¥ç ç©¶ä¸­ç¼ç¾ééµå ç´ ã

##### **Joining Forces for Pathology Diagnostics with AI Assistance: The EMPAIA Initiative**
2401.09450v2 by Norman Zerbe, Lars Ole Schwen, Christian GeiÃler, Katja Wiesemann, Tom Bisson, Peter Boor, Rita Carvalho, Michael Franz, Christoph Jansen, Tim-Rasmus Kiehl, BjÃ¶rn Lindequist, Nora Charlotte Pohlan, Sarah Schmell, Klaus Strohmenger, Falk Zakrzewski, Markus Plass, Michael Takla, Tobias KÃ¼ster, AndrÃ© Homeyer, Peter Hufnagl

Over the past decade, artificial intelligence (AI) methods in pathology have
advanced substantially. However, integration into routine clinical practice has
been slow due to numerous challenges, including technical and regulatory
hurdles in translating research results into clinical diagnostic products and
the lack of standardized interfaces. The open and vendor-neutral EMPAIA
initiative addresses these challenges. Here, we provide an overview of EMPAIA's
achievements and lessons learned. EMPAIA integrates various stakeholders of the
pathology AI ecosystem, i.e., pathologists, computer scientists, and industry.
In close collaboration, we developed technical interoperability standards,
recommendations for AI testing and product development, and explainability
methods. We implemented the modular and open-source EMPAIA platform and
successfully integrated 14 AI-based image analysis apps from 8 different
vendors, demonstrating how different apps can use a single standardized
interface. We prioritized requirements and evaluated the use of AI in real
clinical settings with 14 different pathology laboratories in Europe and Asia.
In addition to technical developments, we created a forum for all stakeholders
to share information and experiences on digital pathology and AI. Commercial,
clinical, and academic stakeholders can now adopt EMPAIA's common open-source
interfaces, providing a unique opportunity for large-scale standardization and
streamlining of processes. Further efforts are needed to effectively and
broadly establish AI assistance in routine laboratory use. To this end, a
sustainable infrastructure, the non-profit association EMPAIA International,
has been established to continue standardization and support broad
implementation and advocacy for an AI-assisted digital pathology future.

æè¦ï¼å¨éå»çåå¹´ä¸­ï¼ççå­¸ä¸­çäººå·¥æºæ§ (AI) æ¹æ³å·²å¤§å¹é²æ­¥ãç¶èï¼ç±æ¼è¨±å¤ææ°ï¼åæ¬å°ç ç©¶çµæè½åçºè¨åºè¨ºæ·ç¢åå¨æè¡åæ³è¦æ¹é¢çéç¤ï¼ä»¥åç¼ºä¹æ¨æºåä»é¢ï¼å°è´æ´åå°å¸¸è¦è¨åºå¯¦åä¸­é²å±ç·©æ¢ãéæ¾ä¸èä¾æåç¡éç EMPAIA è¨ç«æå°äºéäºææ°ãå¨æ­¤ï¼æåæä¾ EMPAIA çæå°±åç¶é©æè¨çæ¦è¿°ãEMPAIA æ´åäºççå­¸ AI çæç³»çµ±çååå©å®³éä¿äººï¼å³ççå­¸å®¶ãé»è¦ç§å­¸å®¶åç¢æ¥­ãå¨å¯ååä½ä¸ï¼æåå¶å®äºæè¡äºéæ§æ¨æºãAI æ¸¬è©¦åç¢åéç¼å»ºè­°ï¼ä»¥åå¯è§£éæ§æ¹æ³ãæåå¯¦ä½äºæ¨¡çµåä¸éæ¾åå§ç¢¼ç EMPAIA å¹³èºï¼ä¸¦æåæ´åäºä¾èª 8 åä¸åä¾æåç 14 ååºæ¼ AI çå½±ååææç¨ç¨å¼ï¼å±ç¤ºäºä¸åçæç¨ç¨å¼å¦ä½ä½¿ç¨å®ä¸çæ¨æºåä»é¢ãæååªåèæ®éæ±ï¼ä¸¦è©ä¼°äº AI å¨æ­æ´²åäºæ´²ç 14 åä¸åççå¯¦é©å®¤ä¸­çå¯¦éè¨åºæç¨ãé¤äºæè¡éç¼å¤ï¼æåéçºææå©å®³éä¿äººå»ºç«äºä¸åè«å£ï¼ä»¥åäº«æ¸ä½ççå­¸å AI çè³è¨åç¶é©ãåæ¥­ãè¨åºåå­¸è¡å©å®³éä¿äººç¾å¨å¯ä»¥æ¡ç¨ EMPAIA çå¸¸è¦éæ¾åå§ç¢¼ä»é¢ï¼éçºå¤§è¦æ¨¡æ¨æºååç°¡åæµç¨æä¾äºç¨ç¹çæ©æãéè¦é²ä¸æ­¥çåªåæè½ææä¸å»£æ³å°å»ºç«ä¾è¡å¯¦é©å®¤ä½¿ç¨ä¸­ç AI è¼å©ãçºæ­¤ï¼å·²æç«éçå©åæ EMPAIA Internationalï¼ä»¥ä½çºæ°¸çºåºç¤æ¶æ§ï¼ç¹¼çºé²è¡æ¨æºåï¼ä¸¦æ¯æ´å»£æ³å¯¦ä½åå¡å° AI è¼å©æ¸ä½ççå­¸çæªä¾ã

##### **Robust Stochastic Graph Generator for Counterfactual Explanations**
2312.11747v2 by Mario Alfonso Prado-Romero, Bardh Prenkaj, Giovanni Stilo

Counterfactual Explanation (CE) techniques have garnered attention as a means
to provide insights to the users engaging with AI systems. While extensively
researched in domains such as medical imaging and autonomous vehicles, Graph
Counterfactual Explanation (GCE) methods have been comparatively
under-explored. GCEs generate a new graph similar to the original one, with a
different outcome grounded on the underlying predictive model. Among these GCE
techniques, those rooted in generative mechanisms have received relatively
limited investigation despite demonstrating impressive accomplishments in other
domains, such as artistic styles and natural language modelling. The preference
for generative explainers stems from their capacity to generate counterfactual
instances during inference, leveraging autonomously acquired perturbations of
the input graph. Motivated by the rationales above, our study introduces
RSGG-CE, a novel Robust Stochastic Graph Generator for Counterfactual
Explanations able to produce counterfactual examples from the learned latent
space considering a partially ordered generation sequence. Furthermore, we
undertake quantitative and qualitative analyses to compare RSGG-CE's
performance against SoA generative explainers, highlighting its increased
ability to engendering plausible counterfactual candidates.

æè¦ï¼åäºå¯¦è§£é (CE) æè¡å·²å¼èµ·éæ³¨ï¼ä½çºä¸ç¨®çºè AI ç³»çµ±äºåçä½¿ç¨èæä¾è¦è§£çæ¹æ³ãéç¶å¨é«å­¸å½±ååèªåé§é§æ±½è»ç­é åå»£æ³ç ç©¶ï¼åå½¢åäºå¯¦è§£é (GCE) æ¹æ³ç¸å°è¼å°è¢«æ¢ç´¢ãGCE æç¢çä¸åé¡ä¼¼æ¼åå§åå½¢çæ°åå½¢ï¼ä¸¦æ ¹æåºç¤é æ¸¬æ¨¡åç¢çä¸åççµæãå¨éäº GCE æè¡ä¸­ï¼åç®¡å¨å¶ä»é åï¼ä¾å¦èè¡é¢¨æ ¼åèªç¶èªè¨å»ºæ¨¡ï¼ä¸­å±ç¾åºä»¤äººå°è±¡æ·±å»çæå°±ï¼ä½æ¤åºæ¼çææ©å¶çæè¡ç²å¾çéæ³¨ç¸å°æéãå°çæå¼è§£éå¨çåå¥½æºæ¼å®åå¨æ¨çæéç¢çåäºå¯¦å¯¦ä¾çè½åï¼å©ç¨è¼¸å¥åå½¢çèªä¸»ç²åæ¾åãåºæ¼ä¸è¿°çç±ï¼æåçç ç©¶å¼å¥äº RSGG-CEï¼ä¸ç¨®ç¨æ¼åäºå¯¦è§£éçæ°åç©©å¥é¨æ©åå½¢çæå¨ï¼è½å¤ å¾å­¸ç¿å°çæ½å¨ç©ºéä¸­ç¢çåäºå¯¦ç¯ä¾ï¼èæ®é¨åæåºççæåºåãæ­¤å¤ï¼æåé²è¡å®éåå®æ§åæï¼ä»¥æ¯è¼ RSGG-CE çæè½è SoA çæå¼è§£éå¨ï¼å¼·èª¿å¶å¢å¼·äºç¢çåçè§£éåé¸çè½åã

##### **Evaluating the Utility of Model Explanations for Model Development**
2312.06032v1 by Shawn Im, Jacob Andreas, Yilun Zhou

One of the motivations for explainable AI is to allow humans to make better
and more informed decisions regarding the use and deployment of AI models. But
careful evaluations are needed to assess whether this expectation has been
fulfilled. Current evaluations mainly focus on algorithmic properties of
explanations, and those that involve human subjects often employ subjective
questions to test human's perception of explanation usefulness, without being
grounded in objective metrics and measurements. In this work, we evaluate
whether explanations can improve human decision-making in practical scenarios
of machine learning model development. We conduct a mixed-methods user study
involving image data to evaluate saliency maps generated by SmoothGrad,
GradCAM, and an oracle explanation on two tasks: model selection and
counterfactual simulation. To our surprise, we did not find evidence of
significant improvement on these tasks when users were provided with any of the
saliency maps, even the synthetic oracle explanation designed to be simple to
understand and highly indicative of the answer. Nonetheless, explanations did
help users more accurately describe the models. These findings suggest caution
regarding the usefulness and potential for misunderstanding in saliency-based
explanations.

æè¦ï¼å¯è§£é AI çåæ©ä¹ä¸æ¯è®äººåå¨ä½¿ç¨åé¨ç½² AI æ¨¡åæååºæ´å¥½ãæ´ææºçæ±ºç­ãä½éè¦ä»ç´°è©ä¼°ä»¥è©ä¼°æ¯å¦å·²éå°æ­¤é æãç®åçè©ä¼°ä¸»è¦éä¸­å¨è§£éçæ¼ç®æ³ç¹æ§ï¼èæ¶åäººé¡åè©¦èçè©ä¼°éå¸¸æ¡ç¨ä¸»è§åé¡ä¾æ¸¬è©¦äººé¡å°è§£éæç¨æ§ççæ³ï¼èæ²æåºæ¼å®¢è§ææ¨åæ¸¬éãå¨éé å·¥ä½ä¸­ï¼æåè©ä¼°è§£éæ¯å¦å¯ä»¥å¨æ©å¨å­¸ç¿æ¨¡åéç¼çå¯¦éå ´æ¯ä¸­æ¹åäººé¡æ±ºç­å¶å®ãæåé²è¡äºä¸é æ¶åå½±åè³æçæ··åæ¹æ³ä½¿ç¨èç ç©¶ï¼ä»¥è©ä¼° SmoothGradãGradCAM åé è¨è§£éå¨å©åä»»åä¸­ç¢ççé¡¯èæ§åï¼æ¨¡åé¸æååäºå¯¦æ¨¡æ¬ãä»¤äººé©è¨çæ¯ï¼æåæ²æç¼ç¾ä»»ä½é¡¯èæ§åï¼å³ä½¿æ¯è¨­è¨çºææ¼çè§£ä¸é«åº¦æç¤ºç­æ¡çåæé è¨è§£éï¼è½è®ä½¿ç¨èå¨éäºä»»åä¸é¡¯èæ¹åçè­æãåç®¡å¦æ­¤ï¼è§£éç¢ºå¯¦æå©æ¼ä½¿ç¨èæ´æºç¢ºå°æè¿°æ¨¡åãéäºç¼ç¾æç¤ºæåè¦å°åºæ¼é¡¯èæ§çè§£éä¸­å¯è½å­å¨èª¤è§£çæç¨æ§ä¿æè¬¹æã

##### **Building Trustworthy NeuroSymbolic AI Systems: Consistency, Reliability, Explainability, and Safety**
2312.06798v1 by Manas Gaur, Amit Sheth

Explainability and Safety engender Trust. These require a model to exhibit
consistency and reliability. To achieve these, it is necessary to use and
analyze data and knowledge with statistical and symbolic AI methods relevant to
the AI application - neither alone will do. Consequently, we argue and seek to
demonstrate that the NeuroSymbolic AI approach is better suited for making AI a
trusted AI system. We present the CREST framework that shows how Consistency,
Reliability, user-level Explainability, and Safety are built on NeuroSymbolic
methods that use data and knowledge to support requirements for critical
applications such as health and well-being. This article focuses on Large
Language Models (LLMs) as the chosen AI system within the CREST framework. LLMs
have garnered substantial attention from researchers due to their versatility
in handling a broad array of natural language processing (NLP) scenarios. For
example, ChatGPT and Google's MedPaLM have emerged as highly promising
platforms for providing information in general and health-related queries,
respectively. Nevertheless, these models remain black boxes despite
incorporating human feedback and instruction-guided tuning. For instance,
ChatGPT can generate unsafe responses despite instituting safety guardrails.
CREST presents a plausible approach harnessing procedural and graph-based
knowledge within a NeuroSymbolic framework to shed light on the challenges
associated with LLMs.

æè¦ï¼å¯è§£éæ§åå®å¨æ§å»ºç«ä¿¡ä»»ãéäºéè¦ä¸åæ¨¡åä¾å±ç¤ºä¸è´æ§åå¯é æ§ãçºäºå¯¦ç¾éäºï¼æå¿è¦ä½¿ç¨ååææ¸æåç¥è­ï¼ä¸¦ä½¿ç¨è AI æç¨ç¸éççµ±è¨åç¬¦è AI æ¹æ³ - å®ç¨ä½¿ç¨ä»»ä½ä¸ç¨®æ¹æ³é½ä¸æå¥æãå æ­¤ï¼æåä¸»å¼µä¸¦è©¦åè­æ NeuroSymbolic AI æ¹æ³æ´é©åæ¼ä½¿ AI æçºåä¿¡ä»»ç AI ç³»çµ±ãæåæåºäº CREST æ¡æ¶ï¼å±ç¤ºäºä¸è´æ§ãå¯é æ§ãä½¿ç¨èå±¤ç´çå¯è§£éæ§åå®å¨æ§æ¯å¦ä½å»ºç«å¨ NeuroSymbolic æ¹æ³ä¸çï¼è©²æ¹æ³ä½¿ç¨æ¸æåç¥è­ä¾æ¯æééµæç¨ï¼ä¾å¦å¥åº·åç¦ç¥ï¼çè¦æ±ãæ¬æéé»éæ³¨å¤§åèªè¨æ¨¡å (LLM)ï¼å çºå®æ¯ CREST æ¡æ¶ä¸­é¸æç AI ç³»çµ±ãLLM å å¶å¨èçå»£æ³çèªç¶èªè¨èç (NLP) å ´æ¯æ¹é¢çå¤åè½æ§èååç ç©¶äººå¡çéæ³¨ãä¾å¦ï¼ChatGPT å Google ç MedPaLM å·²æçºæä¾ä¸è¬åå¥åº·ç¸éæ¥è©¢ä¿¡æ¯çæ¥µæå¸æçå¹³å°ãåç®¡å¦æ­¤ï¼éäºæ¨¡åä»ç¶æ¯é»çå­ï¼åç®¡ç´å¥äºäººé¡åé¥åæä»¤å¼å°çèª¿æ´ãä¾å¦ï¼åç®¡å¶å®äºå®å¨é²è­·æªæ½ï¼ChatGPT ä»å¯è½ç¢çä¸å®å¨çåæãCREST æåºäºä¸ç¨®åççæ¹æ³ï¼å¨ NeuroSymbolic æ¡æ¶ä¸­å©ç¨ç¨åºååºæ¼åè¡¨çç¥è­ï¼ä»¥é¡æè LLM ç¸éçææ°ã

##### **Class-Discriminative Attention Maps for Vision Transformers**
2312.02364v3 by Lennart Brocki, Jakub Binda, Neo Christopher Chung

Importance estimators are explainability methods that quantify feature
importance for deep neural networks (DNN). In vision transformers (ViT), the
self-attention mechanism naturally leads to attention maps, which are sometimes
interpreted as importance scores that indicate which input features ViT models
are focusing on. However, attention maps do not account for signals from
downstream tasks. To generate explanations that are sensitive to downstream
tasks, we have developed class-discriminative attention maps (CDAM), a
gradient-based extension that estimates feature importance with respect to a
known class or a latent concept. CDAM scales attention scores by how relevant
the corresponding tokens are for the predictions of a classifier head. In
addition to targeting the supervised classifier, CDAM can explain an arbitrary
concept shared by selected samples by measuring similarity in the latent space
of ViT. Additionally, we introduce Smooth CDAM and Integrated CDAM, which
average a series of CDAMs with slightly altered tokens. Our quantitative
benchmarks include correctness, compactness, and class sensitivity, in
comparison to 7 other importance estimators. Vanilla, Smooth, and Integrated
CDAM excel across all three benchmarks. In particular, our results suggest that
existing importance estimators may not provide sufficient class-sensitivity. We
demonstrate the utility of CDAM in medical images by training and explaining
malignancy and biomarker prediction models based on lung Computed Tomography
(CT) scans. Overall, CDAM is shown to be highly class-discriminative and
semantically relevant, while providing compact explanations.

æè¦ï¼<paragraph>éè¦æ§ä¼°è¨å¨æ¯ä¸ç¨®å¯è§£éæ§æ¹æ³ï¼ç¨æ¼éåæ·±åº¦ç¥ç¶ç¶²è·¯ (DNN) çç¹å¾µéè¦æ§ãå¨è¦è¦ºTransformer (ViT) ä¸­ï¼èªææ³¨ææ©å¶èªç¶æå°è´æ³¨æååï¼æææå°å¶è§£éçºéè¦æ§åæ¸ï¼è¡¨ç¤º ViT æ¨¡åéæ³¨åªäºè¼¸å¥ç¹å¾µãç¶èï¼æ³¨æååä¸¦æªèæ®ä¾èªä¸æ¸¸ä»»åçä¿¡èãçºäºç¢çå°ä¸æ¸¸ä»»åææçè§£éï¼æåéç¼äºé¡å¥ååæ³¨æåå (CDAM)ï¼éæ¯ä¸ç¨®åºæ¼æ¢¯åº¦çæ´åï¼ç¨æ¼ä¼°è¨ç¸å°æ¼å·²ç¥é¡å¥ææ½å¨æ¦å¿µçç¹å¾µéè¦æ§ãCDAM æ ¹æå°æçç¬¦èèåé¡å¨é ­çé æ¸¬ç¸éç¨åº¦ï¼èª¿æ´æ³¨æååæ¸ãé¤äºéå°ç£ç£åé¡å¨å¤ï¼CDAM éå¯ä»¥ééæ¸¬é ViT çæ½å¨ç©ºéä¸­çç¸ä¼¼æ§ä¾è§£éé¸å®æ¨£æ¬å±æçä»»ææ¦å¿µãæ­¤å¤ï¼æåå¼å¥äºå¹³æ» CDAM åç©å CDAMï¼å®åå°ä¸ç³»åå·æç¥å¾®æ¹è®çç¬¦èç CDAM é²è¡å¹³åãæåçéååºæºåæ¬æ­£ç¢ºæ§ãç·æ¹æ§åé¡å¥æææ§ï¼èå¶ä» 7 åéè¦æ§ä¼°è¨å¨ç¸æ¯ãé¦èãå¹³æ»åç©å CDAM å¨ææä¸ååºæºä¸­è¡¨ç¾åºè²ãç¹å¥æ¯ï¼æåççµæè¡¨æç¾æçéè¦æ§ä¼°è¨å¨å¯è½ç¡æ³æä¾è¶³å¤ çé¡å¥æææ§ãæåééåºæ¼èºé¨é»è¦æ·å±¤ææ (CT) ææè¨ç·´åè§£éæ¡æ§è«ç¤åçç©æ¨è¨é æ¸¬æ¨¡åï¼è­æäº CDAM å¨é«å­¸å½±åä¸­çæç¨ãç¸½çä¾èªªï¼CDAM è¢«è­æå·æé«åº¦é¡å¥ååæ§åèªç¾©ç¸éæ§ï¼åææä¾ç°¡æ½çè§£éã</paragraph>

##### **Deployment of a Robust and Explainable Mortality Prediction Model: The COVID-19 Pandemic and Beyond**
2311.17133v1 by Jacob R. Epifano, Stephen Glass, Ravi P. Ramachandran, Sharad Patel, Aaron J. Masino, Ghulam Rasool

This study investigated the performance, explainability, and robustness of
deployed artificial intelligence (AI) models in predicting mortality during the
COVID-19 pandemic and beyond. The first study of its kind, we found that
Bayesian Neural Networks (BNNs) and intelligent training techniques allowed our
models to maintain performance amidst significant data shifts. Our results
emphasize the importance of developing robust AI models capable of matching or
surpassing clinician predictions, even under challenging conditions. Our
exploration of model explainability revealed that stochastic models generate
more diverse and personalized explanations thereby highlighting the need for AI
models that provide detailed and individualized insights in real-world clinical
settings. Furthermore, we underscored the importance of quantifying uncertainty
in AI models which enables clinicians to make better-informed decisions based
on reliable predictions. Our study advocates for prioritizing implementation
science in AI research for healthcare and ensuring that AI solutions are
practical, beneficial, and sustainable in real-world clinical environments. By
addressing unique challenges and complexities in healthcare settings,
researchers can develop AI models that effectively improve clinical practice
and patient outcomes.

æè¦ï¼æ¬ç ç©¶è°æ¥äºå¨ COVID-19 ç«ææé´åä»¥åé¢æµæ­»äº¡çæ¶ï¼å·²é¨ç½²äººå·¥æºè½ (AI) æ¨¡åçæ§è½ãå¯è§£éæ§åç¨³å¥æ§ãä½ä¸ºåç±»ç ç©¶ä¸­çé¦ä¾ï¼æä»¬åç°è´å¶æ¯ç¥ç»ç½ç» (BNN) åæºè½è®­ç»ææ¯è®©æä»¬çæ¨¡åå¨æ°æ®åçéå¤§ååæ¶ä»è½ä¿ææ§è½ãæä»¬çç»æå¼ºè°äºå¼åç¨³å¥ç AI æ¨¡åçéè¦æ§ï¼å³ä½¿å¨å·ææææ§çæ¡ä»¶ä¸ï¼è¿äºæ¨¡åä¹è½å¹éæè¶è¶ä¸´åºå»ççé¢æµãæä»¬å¯¹æ¨¡åå¯è§£éæ§çæ¢ç´¢è¡¨æï¼éæºæ¨¡åä¼äº§çæ´å¤æ ·åä¸ä¸ªæ§åçè§£éï¼ä»èçªåºäºå¨ç°å®ä¸ççä¸´åºç¯å¢ä¸­æä¾è¯¦ç»ä¸ä¸ªæ§åè§è§£ç AI æ¨¡åçå¿è¦æ§ãæ­¤å¤ï¼æä»¬å¼ºè°äºéå AI æ¨¡åä¸­ä¸ç¡®å®æ§çéè¦æ§ï¼è¿ä½¿ä¸´åºå»çè½å¤æ ¹æ®å¯é çé¢æµååºæ´ææºçå³ç­ãæä»¬çç ç©¶æå¡å¨å»çä¿å¥ç AI ç ç©¶ä¸­ä¼åèèå®æ½ç§å­¦ï¼å¹¶ç¡®ä¿ AI è§£å³æ¹æ¡å¨ç°å®ä¸ççä¸´åºç¯å¢ä¸­å®ç¨ãæçä¸å¯æç»­ãéè¿è§£å³å»çä¿å¥ç¯å¢ä¸­çç¬ç¹ææåå¤ææ§ï¼ç ç©¶äººåå¯ä»¥å¼ååºæææ¹åä¸´åºå®è·µåæ£èé¢åç AI æ¨¡åã

##### **Variational Autoencoders for Feature Exploration and Malignancy Prediction of Lung Lesions**
2311.15719v1 by Benjamin Keel, Aaron Quyn, David Jayne, Samuel D. Relton

Lung cancer is responsible for 21% of cancer deaths in the UK and five-year
survival rates are heavily influenced by the stage the cancer was identified
at. Recent studies have demonstrated the capability of AI methods for accurate
and early diagnosis of lung cancer from routine scans. However, this evidence
has not translated into clinical practice with one barrier being a lack of
interpretable models. This study investigates the application Variational
Autoencoders (VAEs), a type of generative AI model, to lung cancer lesions.
Proposed models were trained on lesions extracted from 3D CT scans in the
LIDC-IDRI public dataset. Latent vector representations of 2D slices produced
by the VAEs were explored through clustering to justify their quality and used
in an MLP classifier model for lung cancer diagnosis, the best model achieved
state-of-the-art metrics of AUC 0.98 and 93.1% accuracy. Cluster analysis shows
the VAE latent space separates the dataset of malignant and benign lesions
based on meaningful feature components including tumour size, shape, patient
and malignancy class. We also include a comparative analysis of the standard
Gaussian VAE (GVAE) and the more recent Dirichlet VAE (DirVAE), which replaces
the prior with a Dirichlet distribution to encourage a more explainable latent
space with disentangled feature representation. Finally, we demonstrate the
potential for latent space traversals corresponding to clinically meaningful
feature changes.

æè¦ï¼èºçå è±åççæ­»äº¡äººæ¸ç 21%ï¼äºå¹´å­æ´»çå¾å¤§ç¨åº¦åæ±ºæ¼ççè¢«ç¼ç¾çéæ®µãæè¿çç ç©¶å·²è­æäººå·¥æºè½æ¹æ³å·æå¾ä¾è¡ææä¸­æºç¢ºåæ©è¨ºæ·èºççè½åãç¶èï¼æ­¤è­æå°æªè½åçºè¨åºå¯¦åï¼å¶ä¸­ä¸åéç¤æ¯ç¼ºä¹å¯è§£éçæ¨¡åãæ¬ç ç©¶æ¢è¨äºæç¨è®åèªåç·¨ç¢¼å¨ (VAE)ï¼ä¸ç¨®çæå¼äººå·¥æºè½æ¨¡åï¼æ¼èºççç¶ãå°æåºçæ¨¡åè¨ç·´æ¼å¾ LIDC-IDRI å¬å±æ¸æéä¸­æåç 3D é»è¦æ·å±¤ææçç¶ãééèé¡æ¢ç´¢äº VAE çæç 2D åççæ½å¨åéè¡¨ç¤ºï¼ä»¥è­æå¶åè³ªï¼ä¸¦ç¨æ¼èºçè¨ºæ·ç MLP åé¡å¨æ¨¡åï¼æä½³æ¨¡åéå°äº AUC 0.98 å 93.1% æºç¢ºåº¦çæåé²ææ¨ãèé¡åæé¡¯ç¤ºï¼VAE æ½å¨ç©ºéæ ¹æææç¾©çç¹å¾µçµæï¼åæ¬è«ç¤å¤§å°ãå½¢çãæ£èåæ¡æ§é¡å¥ï¼å°æ¡æ§åè¯æ§çç¶çæ¸æéåéãæåéåæ¬æ¨æºé«æ¯ VAE (GVAE) åæ´æ°ççå©åé· VAE (DirVAE) çæ¯è¼åæï¼å¾èç¨çå©åé·åä½åä»£åé©ï¼ä»¥ä¿é²å·æè§£éç¹å¾µè¡¨ç¤ºçæ´å·å¯è§£éæ§çæ½å¨ç©ºéãæå¾ï¼æåå±ç¤ºäºèè¨åºææç¾©çç¹å¾µè®åç¸æçæ½å¨ç©ºéæ©«è¶çæ½åã

##### **MRxaI: Black-Box Explainability for Image Classifiers in a Medical Setting**
2311.14471v1 by Nathan Blake, Hana Chockler, David A. Kelly, Santiago Calderon Pena, Akchunya Chanchal

Existing tools for explaining the output of image classifiers can be divided
into white-box, which rely on access to the model internals, and black-box,
agnostic to the model. As the usage of AI in the medical domain grows, so too
does the usage of explainability tools. Existing work on medical image
explanations focuses on white-box tools, such as gradcam. However, there are
clear advantages to switching to a black-box tool, including the ability to use
it with any classifier and the wide selection of black-box tools available. On
standard images, black-box tools are as precise as white-box. In this paper we
compare the performance of several black-box methods against gradcam on a brain
cancer MRI dataset. We demonstrate that most black-box tools are not suitable
for explaining medical image classifications and present a detailed analysis of
the reasons for their shortcomings. We also show that one black-box tool, a
causal explainability-based rex, performs as well as \gradcam.

æè¦ï¼ç¾æçåååé¡å¨è¼¸åºè§£éå·¥å·å¯åçºä¾è³´æ¼æ¨¡åå§é¨å­åæ¬éçç½çï¼ä»¥åèæ¨¡åç¡éçé»çãé¨è AI å¨é«çé åçä½¿ç¨å¢å ï¼å¯è§£éæ§å·¥å·çä½¿ç¨ä¹é¨ä¹å¢å ãç¾æé«å­¸å½±åè§£éçå·¥ä½éé»å¨æ¼ç½çå·¥å·ï¼ä¾å¦ gradcamãç¶èï¼åæå°é»çå·¥å·ææé¡¯çåªé»ï¼åæ¬è½å¤ èä»»ä½åé¡å¨ä¸èµ·ä½¿ç¨ï¼ä»¥åå»£æ³çé»çå·¥å·å¯ä¾é¸æãå¨æ¨æºå½±åä¸ï¼é»çå·¥å·èç½çä¸æ¨£ç²¾ç¢ºãå¨æ¬æä¸­ï¼æåæ¯è¼äºå¤ç¨®é»çæ¹æ³å¨è¦ç MRI è³æéä¸è gradcam çæè½ãæåè­æå¤§å¤æ¸é»çå·¥å·ä¸é©åè§£éé«å­¸å½±ååé¡ï¼ä¸¦è©³ç´°åæå¶ç¼ºé»çåå ãæåéè¡¨æä¸ç¨®é»çå·¥å·ï¼åºæ¼å æå¯è§£éæ§ç rexï¼è¡¨ç¾è \gradcam ä¸æ¨£å¥½ã

##### **Moderating Model Marketplaces: Platform Governance Puzzles for AI Intermediaries**
2311.12573v3 by Robert Gorwa, Michael Veale

The AI development community is increasingly making use of hosting
intermediaries such as Hugging Face provide easy access to user-uploaded models
and training data. These model marketplaces lower technical deployment barriers
for hundreds of thousands of users, yet can be used in numerous potentially
harmful and illegal ways. In this article, we explain ways in which AI systems,
which can both `contain' content and be open-ended tools, present one of the
trickiest platform governance challenges seen to date. We provide case studies
of several incidents across three illustrative platforms -- Hugging Face,
GitHub and Civitai -- to examine how model marketplaces moderate models.
Building on this analysis, we outline important (and yet nevertheless limited)
practices that industry has been developing to respond to moderation demands:
licensing, access and use restrictions, automated content moderation, and open
policy development. While the policy challenge at hand is a considerable one,
we conclude with some ideas as to how platforms could better mobilize resources
to act as a careful, fair, and proportionate regulatory access point.

æè¦ï¼AI éç¼ç¤¾ç¾¤æ¥çå©ç¨ Hugging Face ç­è¨ç®¡ä¸­ä»æ©æ§æä¾ç¨æ¶ä¸å³çæ¨¡ååè¨ç·´è³æçç°¡æå­åæ¬éãéäºæ¨¡åå¸ééä½äºæ¸åè¬åç¨æ¶çæè¡é¨ç½²éç¤ï¼ä½å¯è½æè¢«ç¨æ¼è¨±å¤æ½å¨æå®³åéæ³çæ¹å¼ãå¨æ¬æä¸­ï¼æåèªªæ AI ç³»çµ±æ¢å¯ä»¥ãåå«ãå§å®¹ï¼åå¯ä»¥ä½çºéæ¾å¼å·¥å·ï¼éæåºäºè¿ä»çºæ­¢ææ£æçå¹³å°æ²»çææ°ä¹ä¸ãæåæä¾ Hugging FaceãGitHub å Civitai ç­ä¸åèªªææ§å¹³å°ä¸æ¸èµ·äºä»¶çæ¡ä¾ç ç©¶ï¼ä»¥æª¢è¦æ¨¡åå¸éå¦ä½å¯©æ ¸æ¨¡åãæ ¹ææ­¤åæï¼æåæ¦è¿°ç¢æ¥­çºåæå¯©æ ¸éæ±èéç¼çéè¦ï¼ä½ä»æéï¼å¯¦åï¼ææ¬ãå­ååä½¿ç¨éå¶ãèªååå§å®¹å¯©æ ¸åéæ¾æ¿ç­å¶å®ãéç¶ç¶åæ¿ç­ææ°ç¸ç¶å¯è§ï¼æåæå¾æåºä¸äºæ§æ³ï¼èªªæå¹³å°å¦ä½è½æ´å¥½å°åå¡è³æºï¼ä½çºè¬¹æãå¬å¹³ä¸é©åº¦çæ³è¦å­åé»ã

##### **Ovarian Cancer Data Analysis using Deep Learning: A Systematic Review from the Perspectives of Key Features of Data Analysis and AI Assurance**
2311.11932v1 by Muta Tah Hira, Mohammad A. Razzaque, Mosharraf Sarker

Background and objectives: By extracting this information, Machine or Deep
Learning (ML/DL)-based autonomous data analysis tools can assist clinicians and
cancer researchers in discovering patterns and relationships from complex data
sets. Many DL-based analyses on ovarian cancer (OC) data have recently been
published. These analyses are highly diverse in various aspects of cancer
(e.g., subdomain(s) and cancer type they address) and data analysis features.
However, a comprehensive understanding of these analyses in terms of these
features and AI assurance (AIA) is currently lacking. This systematic review
aims to fill this gap by examining the existing literature and identifying
important aspects of OC data analysis using DL, explicitly focusing on the key
features and AI assurance perspectives. Methods: The PRISMA framework was used
to conduct comprehensive searches in three journal databases. Only studies
published between 2015 and 2023 in peer-reviewed journals were included in the
analysis. Results: In the review, a total of 96 DL-driven analyses were
examined. The findings reveal several important insights regarding DL-driven
ovarian cancer data analysis: - Most studies 71% (68 out of 96) focused on
detection and diagnosis, while no study addressed the prediction and prevention
of OC. - The analyses were predominantly based on samples from a non-diverse
population (75% (72/96 studies)), limited to a geographic location or country.
- Only a small proportion of studies (only 33% (32/96)) performed integrated
analyses, most of which used homogeneous data (clinical or omics). - Notably, a
mere 8.3% (8/96) of the studies validated their models using external and
diverse data sets, highlighting the need for enhanced model validation, and -
The inclusion of AIA in cancer data analysis is in a very early stage; only
2.1% (2/96) explicitly addressed AIA through explainability.

æè¦ï¼<paragraph>èæ¯åç®æ¨ï¼ééæåéäºè³è¨ï¼æ©å¨ææ·±åº¦å­¸ç¿ (ML/DL) åºæ¼èªä¸»æ¸æåæå·¥å·å¯ä»¥åå©è¨åºé«çåççç ç©¶äººå¡å¾è¤éçæ¸æéä¸­ç¼ç¾æ¨¡å¼åéä¿ãæè¿å·²ç¼è¡¨è¨±å¤åºæ¼ DL çåµå·¢ç (OC) æ¸æåæãéäºåæå¨çççååæ¹é¢ï¼ä¾å¦ï¼å®åæ¶åçå­é ååççé¡åï¼åæ¸æåæåè½æ¹é¢é«åº¦å¤æ¨£åãç¶èï¼ç®åç¼ºä¹å°éäºåæå¨éäºç¹å¾µå AI ä¿è­ (AIA) æ¹é¢çå¨é¢çè§£ãéç¯ç³»çµ±æ§åé¡§æ¨å¨ééæª¢è¦ç¾ææç»ä¸¦æç¢ºéæ³¨ééµç¹å¾µå AI ä¿è­è§é»ï¼ä¾å¡«è£éåç©ºç½ãæ¹æ³ï¼ä½¿ç¨ PRISMA æ¶æ§å¨ä¸åæåè³æåº«ä¸­é²è¡å¨é¢æå°ãåæååæ¬ 2015 å¹´è³ 2023 å¹´éç¼è¡¨æ¼åè¡è©å¯©æåçç ç©¶ãçµæï¼å¨åé¡§ä¸­ï¼ç¸½å±æª¢è¦äº 96 é ç± DL é©åçåæãç ç©¶çµææ­ç¤ºäºå¹¾åéæ¼ç± DL é©åçåµå·¢çæ¸æåæçéè¦è¦è§£ï¼- å¤§å¤æ¸ç ç©¶ 71%ï¼96 é ä¸­æ 68 é ï¼å°æ³¨æ¼æª¢æ¸¬åè¨ºæ·ï¼èæ²æç ç©¶æ¢è¨ OC çé æ¸¬åé é²ã- éäºåæä¸»è¦åºæ¼ä¾èªéå¤åæç¾¤çæ¨£æ¬ï¼75%ï¼96 é ç ç©¶ä¸­ç 72 é ï¼ï¼ï¼åéæ¼æåå°çä½ç½®æåå®¶ã- åªæå°é¨åç ç©¶ï¼å 33%ï¼96 é ç ç©¶ä¸­ç 32 é ï¼å·è¡æ´ååæï¼å¶ä¸­å¤§å¤æ¸ä½¿ç¨åè³ªæ¸æï¼è¨åºæçµå­¸ï¼ã- å¼å¾æ³¨æçæ¯ï¼åªæ 8.3%ï¼96 é ç ç©¶ä¸­ç 8 é ï¼ä½¿ç¨å¤é¨åå¤åæ¸æéé©è­äºå¶æ¨¡åï¼å¼·èª¿äºå å¼·æ¨¡åé©è­çå¿è¦æ§ï¼ä»¥å- å° AIA ç´å¥ççæ¸æåæä»èæ¼éå¸¸æ©æçéæ®µï¼åªæ 2.1%ï¼96 é ç ç©¶ä¸­ç 2 é ï¼ééå¯è§£éæ§æç¢ºæ¢è¨äº AIAã</paragraph>

##### **Representing visual classification as a linear combination of words**
2311.10933v1 by Shobhit Agarwal, Yevgeniy R. Semenov, William Lotter

Explainability is a longstanding challenge in deep learning, especially in
high-stakes domains like healthcare. Common explainability methods highlight
image regions that drive an AI model's decision. Humans, however, heavily rely
on language to convey explanations of not only "where" but "what".
Additionally, most explainability approaches focus on explaining individual AI
predictions, rather than describing the features used by an AI model in
general. The latter would be especially useful for model and dataset auditing,
and potentially even knowledge generation as AI is increasingly being used in
novel tasks. Here, we present an explainability strategy that uses a
vision-language model to identify language-based descriptors of a visual
classification task. By leveraging a pre-trained joint embedding space between
images and text, our approach estimates a new classification task as a linear
combination of words, resulting in a weight for each word that indicates its
alignment with the vision-based classifier. We assess our approach using two
medical imaging classification tasks, where we find that the resulting
descriptors largely align with clinical knowledge despite a lack of
domain-specific language training. However, our approach also identifies the
potential for 'shortcut connections' in the public datasets used. Towards a
functional measure of explainability, we perform a pilot reader study where we
find that the AI-identified words can enable non-expert humans to perform a
specialized medical task at a non-trivial level. Altogether, our results
emphasize the potential of using multimodal foundational models to deliver
intuitive, language-based explanations of visual tasks.

æè¦ï¼<paragraph>è§£éæ§æ¯æ·±åº¦å­¸ç¿ä¸­é·æçææ°ï¼ç¹å¥æ¯å¨é«çä¿å¥ç­é«é¢¨éªé åãå¸¸è¦çè§£éæ§æ¹æ³æå¼·èª¿é©å AI æ¨¡åæ±ºç­çå½±åååãç¶èï¼äººé¡å¾å¤§ç¨åº¦ä¾è³´èªè¨ä¾å³éä¸åæ¯ãå¨åªè£¡ãï¼éæãæ¯ä»éº¼ãçè§£éãæ­¤å¤ï¼å¤§å¤æ¸è§£éæ§æ¹æ³é½å°æ³¨æ¼è§£éåå¥ AI é æ¸¬ï¼èä¸æ¯æè¿° AI æ¨¡åä¸è¬ä½¿ç¨çç¹å¾µãå¾èå°æ¼æ¨¡ååè³æéç¨½æ ¸ç¹å¥æç¨ï¼çè³å¯è½å¨ AI æä¾æç¨æ¼æ°ç©ä»»åæç¢çç¥è­ãå¨æ­¤ï¼æåæåºä¸åä½¿ç¨è¦è¦ºèªè¨æ¨¡åä¾è¾¨è­è¦è¦ºåé¡ä»»åçèªè¨æè¿°ç¬¦çè§£éæ§ç­ç¥ãééå©ç¨å½±ååæå­ä¹éé åè¨ç·´çè¯ååµå¥ç©ºéï¼æåçåæ³å°æ°çåé¡ä»»åä¼°è¨çºä¸åç·æ§æå­çµåï¼å°è´æ¯åæå­é½ææ¬éï¼è¡¨ç¤ºå®èåºæ¼è¦è¦ºçåé¡å¨å°é½ãæåä½¿ç¨å©åé«å­¸å½±ååé¡ä»»åä¾è©ä¼°æåçåæ³ï¼æåç¼ç¾ç¢ççæè¿°ç¬¦å¨å¾å¤§ç¨åº¦ä¸èè¨åºç¥è­ä¸è´ï¼åç®¡ç¼ºä¹ç¹å®é åçèªè¨è¨ç·´ãç¶èï¼æåçåæ³ä¹ç¼ç¾äºæç¨å¬éè³æéä¸­çãæ·å¾é£ç·ãçå¯è½æ§ãçºäºéå°è§£éæ§çåè½æ§è¡¡éï¼æåé²è¡äºä¸é è©¦é©è®èç ç©¶ï¼ç¼ç¾ AI è­å¥çæå­è½è®éå°å®¶äººé¡å¨éå¹³å¡çå±¤ç´å·è¡å°æ¥­çé«çä»»åãç¸½ä¹ï¼æåççµæå¼·èª¿äºä½¿ç¨å¤æ¨¡å¼åºç¤æ¨¡åä¾æä¾ç´è§çãåºæ¼èªè¨çè¦è¦ºä»»åè§£éçæ½åã</paragraph>


### Knowledge Graphs
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-12-11**|**From communities to interpretable network and word embedding: an unified approach**|Thibault Prouteau et.al.|[2412.08187v1](http://arxiv.org/abs/2412.08187v1)|null|
|**2024-12-11**|**Can Graph Neural Networks Learn Language with Extremely Weak Text Supervision?**|Zihao Li et.al.|[2412.08174v1](http://arxiv.org/abs/2412.08174v1)|null|
|**2024-12-11**|**Repository-Level Graph Representation Learning for Enhanced Security Patch Detection**|Xin-Cheng Wen et.al.|[2412.08068v1](http://arxiv.org/abs/2412.08068v1)|null|
|**2024-12-11**|**Bootstrapping Heterogeneous Graph Representation Learning via Large Language Models: A Generalized Approach**|Hang Gao et.al.|[2412.08038v1](http://arxiv.org/abs/2412.08038v1)|null|
|**2024-12-10**|**Adapting to Non-Stationary Environments: Multi-Armed Bandit Enhanced Retrieval-Augmented Generation on Knowledge Graphs**|Xiaqiang Tang et.al.|[2412.07618v1](http://arxiv.org/abs/2412.07618v1)|[link](https://github.com/futureeeeee/dynamic-rag)|
|**2024-12-10**|**Knowledge Graph Guided Evaluation of Abstention Techniques**|Kinshuk Vasisht et.al.|[2412.07430v1](http://arxiv.org/abs/2412.07430v1)|null|
|**2024-12-10**|**RAG-based Question Answering over Heterogeneous Data and Text**|Philipp Christmann et.al.|[2412.07420v1](http://arxiv.org/abs/2412.07420v1)|null|
|**2024-12-10**|**Generating Knowledge Graphs from Large Language Models: A Comparative Study of GPT-4, LLaMA 2, and BERT**|Ahan Bhatt et.al.|[2412.07412v1](http://arxiv.org/abs/2412.07412v1)|null|
|**2024-12-10**|**My Words Imply Your Opinion: Reader Agent-Based Propagation Enhancement for Personalized Implicit Emotion Analysis**|Jian Liao et.al.|[2412.07367v1](http://arxiv.org/abs/2412.07367v1)|null|
|**2024-12-09**|**ProVision: Programmatically Scaling Vision-centric Instruction Data for Multimodal Language Models**|Jieyu Zhang et.al.|[2412.07012v2](http://arxiv.org/abs/2412.07012v2)|[link](https://github.com/jieyuz2/provision)|
|**2024-12-09**|**A Self-guided Multimodal Approach to Enhancing Graph Representation Learning for Alzheimer's Diseases**|Zhepeng Wang et.al.|[2412.06212v1](http://arxiv.org/abs/2412.06212v1)|null|
|**2024-12-08**|**Automated Extraction and Creation of FBS Design Reasoning Knowledge Graphs from Structured Data in Product Catalogues Lacking Contextual Information**|Vijayalaxmi Sahadevan et.al.|[2412.05868v1](http://arxiv.org/abs/2412.05868v1)|null|
|**2024-12-08**|**A Collaborative Multi-Agent Approach to Retrieval-Augmented Generation Across Diverse Data**|Aniruddha Salve et.al.|[2412.05838v1](http://arxiv.org/abs/2412.05838v1)|null|
|**2024-12-08**|**Large Language Models Merging for Enhancing the Link Stealing Attack on Graph Neural Networks**|Faqian Guan et.al.|[2412.05830v1](http://arxiv.org/abs/2412.05830v1)|null|
|**2024-12-08**|**GL-Fusion: Rethinking the Combination of Graph Neural Network and Large Language model**|Haotong Yang et.al.|[2412.06849v1](http://arxiv.org/abs/2412.06849v1)|null|
|**2024-12-08**|**M$^{3}$-20M: A Large-Scale Multi-Modal Molecule Dataset for AI-driven Drug Design and Discovery**|Siyuan Guo et.al.|[2412.06847v1](http://arxiv.org/abs/2412.06847v1)|[link](https://github.com/bz99bz/m-3)|
|**2024-12-07**|**HMGIE: Hierarchical and Multi-Grained Inconsistency Evaluation for Vision-Language Data Cleansing**|Zihao Zhu et.al.|[2412.05685v1](http://arxiv.org/abs/2412.05685v1)|null|
|**2024-12-07**|**KG-Retriever: Efficient Knowledge Indexing for Retrieval-Augmented Large Language Models**|Weijie Chen et.al.|[2412.05547v1](http://arxiv.org/abs/2412.05547v1)|null|
|**2024-12-06**|**Knowledge Graphs are all you need: Leveraging KGs in Physics Question Answering**|Krishnasai Addala et.al.|[2412.05453v1](http://arxiv.org/abs/2412.05453v1)|null|
|**2024-12-06**|**A Graph-Based Approach for Conversational AI-Driven Personal Memory Capture and Retrieval in a Real-world Application**|Savini Kashmira et.al.|[2412.05447v1](http://arxiv.org/abs/2412.05447v1)|null|
|**2024-12-06**|**KaLM: Knowledge-aligned Autoregressive Language Modeling via Dual-view Knowledge Graph Contrastive Learning**|Peng Yu et.al.|[2412.04948v1](http://arxiv.org/abs/2412.04948v1)|null|
|**2024-12-06**|**HyperGraphOS: A Meta Operating System for Science and Engineering**|Antonello Ceravola et.al.|[2412.04923v1](http://arxiv.org/abs/2412.04923v1)|null|
|**2024-12-06**|**Transformers Struggle to Learn to Search**|Abulhair Saparov et.al.|[2412.04703v1](http://arxiv.org/abs/2412.04703v1)|null|
|**2024-12-06**|**LLM-Align: Utilizing Large Language Models for Entity Alignment in Knowledge Graphs**|Xuan Chen et.al.|[2412.04690v1](http://arxiv.org/abs/2412.04690v1)|null|
|**2024-12-05**|**Retrieval-Augmented Machine Translation with Unstructured Knowledge**|Jiaan Wang et.al.|[2412.04342v1](http://arxiv.org/abs/2412.04342v1)|[link](https://github.com/krystalan/RAGtrans)|
|**2024-12-05**|**GRAF: Graph Retrieval Augmented by Facts for Legal Question Answering**|Cristian-George CrÄciun et.al.|[2412.04119v1](http://arxiv.org/abs/2412.04119v1)|null|
|**2024-12-05**|**MIND: Effective Incorrect Assignment Detection through a Multi-Modal Structure-Enhanced Language Model**|Yunhe Pang et.al.|[2412.03930v1](http://arxiv.org/abs/2412.03930v1)|[link](https://github.com/thudm/whoiswho)|
|**2024-12-05**|**How Good is ChatGPT in Giving Adaptive Guidance Using Knowledge Graphs in E-Learning Environments?**|Patrick Ocheja et.al.|[2412.03856v1](http://arxiv.org/abs/2412.03856v1)|null|
|**2024-12-05**|**Synergizing LLMs and Knowledge Graphs: A Novel Approach to Software Repository-Related Question Answering**|Samuel Abedu et.al.|[2412.03815v1](http://arxiv.org/abs/2412.03815v1)|null|
|**2024-12-05**|**Agent AI with LangGraph: A Modular Framework for Enhancing Machine Translation Using Large Language Models**|Jialin Wang et.al.|[2412.03801v1](http://arxiv.org/abs/2412.03801v1)|null|
|**2024-12-04**|**Language Model Meets Prototypes: Towards Interpretable Text Classification Models through Prototypical Networks**|Ximing Wen et.al.|[2412.03761v1](http://arxiv.org/abs/2412.03761v1)|null|
|**2024-12-04**|**How to Correctly do Semantic Backpropagation on Language-based Agentic Systems**|Wenyi Wang et.al.|[2412.03624v1](http://arxiv.org/abs/2412.03624v1)|[link](https://github.com/hishamalyahya/semantic_backprop)|
|**2024-12-04**|**Enhancing Supply Chain Visibility with Generative AI: An Exploratory Case Study on Relationship Prediction in Knowledge Graphs**|Ge Zheng et.al.|[2412.03390v1](http://arxiv.org/abs/2412.03390v1)|null|
|**2024-12-04**|**CBEval: A framework for evaluating and interpreting cognitive biases in LLMs**|Ammar Shaikh et.al.|[2412.03605v1](http://arxiv.org/abs/2412.03605v1)|null|
|**2024-12-03**|**Hybrid-SQuAD: Hybrid Scholarly Question Answering Dataset**|Tilahun Abedissa Taffa et.al.|[2412.02788v2](http://arxiv.org/abs/2412.02788v2)|[link](https://github.com/semantic-systems/hybrid-squad)|
|**2024-12-03**|**Characterizing Information Shared by Participants to Coding Challenges: The Case of Advent of Code**|Francesco Cauteruccio et.al.|[2412.02290v1](http://arxiv.org/abs/2412.02290v1)|null|
|**2024-12-02**|**A Neurosymbolic Fast and Slow Architecture for Graph Coloring**|Vedant Khandelwal et.al.|[2412.01752v1](http://arxiv.org/abs/2412.01752v1)|null|
|**2024-12-02**|**Intelligent Spark Agents: A Modular LangGraph Framework for Scalable, Visualized, and Enhanced Big Data Machine Learning Workflows**|Jialin Wang et.al.|[2412.01490v4](http://arxiv.org/abs/2412.01490v4)|null|
|**2024-12-01**|**SelfPrompt: Autonomously Evaluating LLM Robustness via Domain-Constrained Knowledge Guidelines and Refined Adversarial Prompts**|Aihua Pei et.al.|[2412.00765v1](http://arxiv.org/abs/2412.00765v1)|null|
|**2024-11-30**|**Leveraging LLM for Automated Ontology Extraction and Knowledge Graph Generation**|Mohammad Sadeq Abolhasani et.al.|[2412.00608v3](http://arxiv.org/abs/2412.00608v3)|null|
|**2024-11-30**|**Opus: A Large Work Model for Complex Workflow Generation**|ThÃ©o Fagnoni et.al.|[2412.00573v2](http://arxiv.org/abs/2412.00573v2)|null|
|**2024-11-30**|**Node Importance Estimation Leveraging LLMs for Semantic Augmentation in Knowledge Graphs**|Xinyu Lin et.al.|[2412.00478v1](http://arxiv.org/abs/2412.00478v1)|[link](https://github.com/xinyulin-fz/lenie)|
|**2024-11-29**|**An AI-Driven Data Mesh Architecture Enhancing Decision-Making in Infrastructure Construction and Public Procurement**|Saurabh Mishra et.al.|[2412.00224v1](http://arxiv.org/abs/2412.00224v1)|null|
|**2024-11-29**|**PerLA: Perceptive 3D Language Assistant**|Guofeng Mei et.al.|[2411.19774v1](http://arxiv.org/abs/2411.19774v1)|null|
|**2024-11-29**|**Knowledge Management for Automobile Failure Analysis Using Graph RAG**|Yuta Ojima et.al.|[2411.19539v1](http://arxiv.org/abs/2411.19539v1)|null|
|**2024-11-28**|**Way to Specialist: Closing Loop Between Specialized LLM and Evolving Domain Knowledge Graph**|Yutong Zhang et.al.|[2411.19064v1](http://arxiv.org/abs/2411.19064v1)|null|
|**2024-11-28**|**EzSQL: An SQL intermediate representation for improving SQL-to-text Generation**|Meher Bhardwaj et.al.|[2411.18923v1](http://arxiv.org/abs/2411.18923v1)|null|
|**2024-11-27**|**MLLM-Search: A Zero-Shot Approach to Finding People using Multimodal Large Language Models**|Angus Fung et.al.|[2412.00103v1](http://arxiv.org/abs/2412.00103v1)|null|
|**2024-11-27**|**Human Evaluation of Procedural Knowledge Graph Extraction from Text with Large Language Models**|Valentina Anita Carriero et.al.|[2412.03589v1](http://arxiv.org/abs/2412.03589v1)|null|
|**2024-11-27**|**Regularized Multi-LLMs Collaboration for Enhanced Score-based Causal Discovery**|Xiaoxuan Li et.al.|[2411.17989v1](http://arxiv.org/abs/2411.17989v1)|null|
|**2024-11-26**|**ShowUI: One Vision-Language-Action Model for GUI Visual Agent**|Kevin Qinghong Lin et.al.|[2411.17465v1](http://arxiv.org/abs/2411.17465v1)|[link](https://github.com/showlab/showui)|
|**2024-11-26**|**Can LLMs be Good Graph Judger for Knowledge Graph Construction?**|Haoyu Huang et.al.|[2411.17388v1](http://arxiv.org/abs/2411.17388v1)|[link](https://github.com/hhy-huang/graphjudger)|
|**2024-11-26**|**Interleaved Scene Graph for Interleaved Text-and-Image Generation Assessment**|Dongping Chen et.al.|[2411.17188v1](http://arxiv.org/abs/2411.17188v1)|null|
|**2024-11-25**|**AtomR: Atomic Operator-Empowered Large Language Models for Heterogeneous Knowledge Reasoning**|Amy Xin et.al.|[2411.16495v2](http://arxiv.org/abs/2411.16495v2)|[link](https://github.com/THU-KEG/AtomR)|
|**2024-11-25**|**Learning by Analogy: Enhancing Few-Shot Prompting for Math Word Problem Solving with Computational Graph-Based Retrieval**|Xiaocong Yang et.al.|[2411.16454v1](http://arxiv.org/abs/2411.16454v1)|null|
|**2024-11-25**|**Adapter-based Approaches to Knowledge-enhanced Language Models -- A Survey**|Alexander Fichtl et.al.|[2411.16403v1](http://arxiv.org/abs/2411.16403v1)|null|
|**2024-11-24**|**Decoding Urban Industrial Complexity: Enhancing Knowledge-Driven Insights via IndustryScopeGPT**|Siqi Wang et.al.|[2411.15758v1](http://arxiv.org/abs/2411.15758v1)|[link](https://github.com/tongji-kgllm/industryscope)|
|**2024-11-22**|**One to rule them all: natural language to bind communication, perception and action**|Simone Colombani et.al.|[2411.15033v1](http://arxiv.org/abs/2411.15033v1)|null|
|**2024-11-22**|**Time is on my sight: scene graph filtering for dynamic environment perception in an LLM-driven robot**|Simone Colombani et.al.|[2411.15027v1](http://arxiv.org/abs/2411.15027v1)|null|
|**2024-11-22**|**GOT4Rec: Graph of Thoughts for Sequential Recommendation**|Zewen Long et.al.|[2411.14922v1](http://arxiv.org/abs/2411.14922v1)|null|
|**2024-11-22**|**VisGraphVar: A Benchmark Generator for Assessing Variability in Graph Analysis Using Large Vision-Language Models**|Camilo ChacÃ³n Sartori et.al.|[2411.14832v1](http://arxiv.org/abs/2411.14832v1)|null|
|**2024-11-22**|**MolReFlect: Towards In-Context Fine-grained Alignments between Molecules and Texts**|Jiatong Li et.al.|[2411.14721v1](http://arxiv.org/abs/2411.14721v1)|null|
|**2024-11-21**|**G-RAG: Knowledge Expansion in Material Science**|Radeen Mostafa et.al.|[2411.14592v2](http://arxiv.org/abs/2411.14592v2)|[link](https://github.com/RadeenXALNW/G-RAG_1.0)|
|**2024-11-21**|**Knowledge Graphs, Large Language Models, and Hallucinations: An NLP Perspective**|Ernests Lavrinovics et.al.|[2411.14258v1](http://arxiv.org/abs/2411.14258v1)|null|
|**2024-11-21**|**Logic Augmented Generation**|Aldo Gangemi et.al.|[2411.14012v1](http://arxiv.org/abs/2411.14012v1)|null|
|**2024-11-21**|**FastRAG: Retrieval Augmented Generation for Semi-structured Data**|Amar Abane et.al.|[2411.13773v1](http://arxiv.org/abs/2411.13773v1)|null|
|**2024-11-20**|**Predictive Insights into LGBTQ+ Minority Stress: A Transductive Exploration of Social Media Discourse**|S. Chapagain et.al.|[2411.13534v1](http://arxiv.org/abs/2411.13534v1)|[link](https://github.com/chapagaisa/transductive)|
|**2024-11-20**|**KAAE: Numerical Reasoning for Knowledge Graphs via Knowledge-aware Attributes Learning**|Ming Yin et.al.|[2411.12950v2](http://arxiv.org/abs/2411.12950v2)|null|
|**2024-11-19**|**Neurosymbolic Graph Enrichment for Grounded World Models**|Stefano De Giorgis et.al.|[2411.12671v1](http://arxiv.org/abs/2411.12671v1)|null|
|**2024-11-19**|**Instant Policy: In-Context Imitation Learning via Graph Diffusion**|Vitalis Vosylius et.al.|[2411.12633v1](http://arxiv.org/abs/2411.12633v1)|null|
|**2024-11-19**|**Bias-Free Sentiment Analysis through Semantic Blinding and Graph Neural Networks**|Hubert Plisiecki et.al.|[2411.12493v2](http://arxiv.org/abs/2411.12493v2)|null|
|**2024-11-19**|**Neon: News Entity-Interaction Extraction for Enhanced Question Answering**|Sneha Singhania et.al.|[2411.12449v2](http://arxiv.org/abs/2411.12449v2)|null|
|**2024-11-19**|**GRL-Prompt: Towards Knowledge Graph based Prompt Optimization via Reinforcement Learning**|Yuze Liu et.al.|[2411.14479v1](http://arxiv.org/abs/2411.14479v1)|null|
|**2024-11-19**|**Just KIDDIN: Knowledge Infusion and Distillation for Detection of INdecent Memes**|Rahul Garg et.al.|[2411.12174v1](http://arxiv.org/abs/2411.12174v1)|null|
|**2024-11-18**|**Regret-Free Reinforcement Learning for LTL Specifications**|Rupak Majumdar et.al.|[2411.12019v1](http://arxiv.org/abs/2411.12019v1)|null|
|**2024-11-18**|**Semantic-Geometric-Physical-Driven Robot Manipulation Skill Transfer via Skill Library and Tactile Representation**|Mingchao Qi et.al.|[2411.11714v1](http://arxiv.org/abs/2411.11714v1)|[link](https://github.com/mingchaoqi/skill_transfer)|
|**2024-11-18**|**Addressing Hallucinations in Language Models with Knowledge Graph Embeddings as an Additional Modality**|Viktoriia Chekalina et.al.|[2411.11531v1](http://arxiv.org/abs/2411.11531v1)|null|
|**2024-11-17**|**RPN 2: On Interdependence Function Learning Towards Unifying and Advancing CNN, RNN, GNN, and Transformer**|Jiawei Zhang et.al.|[2411.11162v1](http://arxiv.org/abs/2411.11162v1)|null|
|**2024-11-16**|**LLaSA: Large Language and Structured Data Assistant**|Yao Xu et.al.|[2411.14460v1](http://arxiv.org/abs/2411.14460v1)|null|
|**2024-11-16**|**Unveiling User Preferences: A Knowledge Graph and LLM-Driven Approach for Conversational Recommendation**|Zhangchi Qiu et.al.|[2411.14459v1](http://arxiv.org/abs/2411.14459v1)|null|
|**2024-11-16**|**A Novel Approach to Eliminating Hallucinations in Large Language Model-Assisted Causal Discovery**|Grace Sng et.al.|[2411.12759v1](http://arxiv.org/abs/2411.12759v1)|null|
|**2024-11-15**|**VeriGraph: Scene Graphs for Execution Verifiable Robot Planning**|Daniel Ekpo et.al.|[2411.10446v2](http://arxiv.org/abs/2411.10446v2)|null|
|**2024-11-15**|**A Survey of Event Causality Identification: Principles, Taxonomy, Challenges, and Assessment**|Qing Cheng et.al.|[2411.10371v2](http://arxiv.org/abs/2411.10371v2)|null|
|**2024-11-15**|**Prompting and Fine-tuning Large Language Models for Automated Code Review Comment Generation**|Md. Asif Haider et.al.|[2411.10129v1](http://arxiv.org/abs/2411.10129v1)|null|
|**2024-11-15**|**HistoLens: An LLM-Powered Framework for Multi-Layered Analysis of Historical Texts -- A Case Application of Yantie Lun**|Yifan Zeng et.al.|[2411.09978v1](http://arxiv.org/abs/2411.09978v1)|null|
|**2024-11-14**|**Accelerating Knowledge Graph and Ontology Engineering with Large Language Models**|Cogan Shimizu et.al.|[2411.09601v1](http://arxiv.org/abs/2411.09601v1)|null|
|**2024-11-14**|**Automating Reformulation of Essence Specifications via Graph Rewriting**|Ian Miguel et.al.|[2411.09576v1](http://arxiv.org/abs/2411.09576v1)|null|
|**2024-11-13**|**Towards Evaluating Large Language Models for Graph Query Generation**|Siraj Munir et.al.|[2411.08449v2](http://arxiv.org/abs/2411.08449v2)|null|
|**2024-11-13**|**Knowledge Bases in Support of Large Language Models for Processing Web News**|Yihe Zhang et.al.|[2411.08278v2](http://arxiv.org/abs/2411.08278v2)|null|
|**2024-11-12**|**Retrieval, Reasoning, Re-ranking: A Context-Enriched Framework for Knowledge Graph Completion**|Muzhi Li et.al.|[2411.08165v1](http://arxiv.org/abs/2411.08165v1)|null|
|**2024-11-12**|**Language Models as Causal Effect Generators**|Lucius E. J. Bynum et.al.|[2411.08019v1](http://arxiv.org/abs/2411.08019v1)|[link](https://github.com/lbynum/sequence-driven-scms)|
|**2024-11-12**|**From General to Specific: Utilizing General Hallucination to Benchmark Specific Role-Playing Agents**|Chuyi Kong et.al.|[2411.07965v2](http://arxiv.org/abs/2411.07965v2)|null|
|**2024-11-12**|**Chain Association-based Attacking and Shielding Natural Language Processing Systems**|Jiacheng Huang et.al.|[2411.07843v1](http://arxiv.org/abs/2411.07843v1)|null|
|**2024-11-11**|**Gradual Fine-Tuning with Graph Routing for Multi-Source Unsupervised Domain Adaptation**|Yao Ma et.al.|[2411.07185v1](http://arxiv.org/abs/2411.07185v1)|null|
|**2024-11-11**|**A Domain-Agnostic Neurosymbolic Approach for Big Social Data Analysis: Evaluating Mental Health Sentiment on Social Media during COVID-19**|Vedant Khandelwal et.al.|[2411.07163v1](http://arxiv.org/abs/2411.07163v1)|null|
|**2024-11-11**|**A Multi-Agent Approach for REST API Testing with Semantic Graphs and LLM-Driven Inputs**|Myeongsoo Kim et.al.|[2411.07098v1](http://arxiv.org/abs/2411.07098v1)|null|
|**2024-11-11**|**Bridge: A Unified Framework to Knowledge Graph Completion via Language Models and Knowledge Representation**|Qiao Qiao et.al.|[2411.06660v1](http://arxiv.org/abs/2411.06660v1)|null|
|**2024-11-10**|**CausalStock: Deep End-to-end Causal Discovery for News-driven Stock Movement Prediction**|Shuqi Li et.al.|[2411.06391v1](http://arxiv.org/abs/2411.06391v1)|null|
|**2024-11-09**|**Analyzing the Evolution of Graphs and Texts**|Xingzhi Guo et.al.|[2411.06295v1](http://arxiv.org/abs/2411.06295v1)|null|
|**2024-11-09**|**An Empirical Analysis on Spatial Reasoning Capabilities of Large Multimodal Models**|Fatemeh Shiri et.al.|[2411.06048v1](http://arxiv.org/abs/2411.06048v1)|[link](https://github.com/fatemehshiri/spatial-mm)|

#### Abstracts
##### **From communities to interpretable network and word embedding: an unified approach**
2412.08187v1 by Thibault Prouteau, Nicolas DuguÃ©, Simon Guillot

Modelling information from complex systems such as humans social interaction
or words co-occurrences in our languages can help to understand how these
systems are organized and function. Such systems can be modelled by networks,
and network theory provides a useful set of methods to analyze them. Among
these methods, graph embedding is a powerful tool to summarize the interactions
and topology of a network in a vectorized feature space. When used in input of
machine learning algorithms, embedding vectors help with common graph problems
such as link prediction, graph matching, etc. Word embedding has the goal of
representing the sense of words, extracting it from large text corpora. Despite
differences in the structure of information in input of embedding algorithms,
many graph embedding approaches are adapted and inspired from methods in NLP.
Limits of these methods are observed in both domains. Most of these methods
require long and resource greedy training. Another downside to most methods is
that they are black-box, from which understanding how the information is
structured is rather complex. Interpretability of a model allows understanding
how the vector space is structured without the need for external information,
and thus can be audited more easily. With both these limitations in mind, we
propose a novel framework to efficiently embed network vertices in an
interpretable vector space. Our Lower Dimension Bipartite Framework (LDBGF)
leverages the bipartite projection of a network using cliques to reduce
dimensionality. Along with LDBGF, we introduce two implementations of this
framework that rely on communities instead of cliques: SINr-NR and SINr-MF. We
show that SINr-MF can perform well on classical graphs and SINr-NR can produce
high-quality graph and word embeddings that are interpretable and stable across
runs.

æè¦ï¼<paragraph>ééæ¨¡æ¬äººé¡ç¤¾äº¤äºåæèªè¨ä¸­è©å½å±ç¾ç­è¤éç³»çµ±ä¸­çè³è¨ï¼æå©æ¼äºè§£éäºç³»çµ±ççµç¹åéä½æ¹å¼ãéäºç³»çµ±å¯ä»¥ç¨ç¶²è·¯ä¾å»ºæ¨¡ï¼èç¶²è·¯çè«æä¾äºæç¨çæ¹æ³éä¾åæå®åãå¨éäºæ¹æ³ä¸­ï¼åå½¢åµå¥æ¯ä¸ç¨®å¼·å¤§çå·¥å·ï¼å¯ç¨æ¼å¨åéåç¹å¾µç©ºéä¸­ç¸½çµç¶²è·¯çäº¤äºåææ²ãç¶ç¨æ¼æ©å¨å­¸ç¿æ¼ç®æ³çè¼¸å¥æï¼åµå¥åéæå©æ¼å¸¸è¦çåå½¢åé¡ï¼ä¾å¦é£çµé æ¸¬ãåå½¢éå°ç­ãè©åµå¥çç®æ¨æ¯è¡¨ç¤ºè©å½çæç¾©ï¼å¾å¤§åæå­èªæåº«ä¸­èåå®ãåç®¡åµå¥æ¼ç®æ³è¼¸å¥è³è¨ççµæ§ä¸åï¼ä½è¨±å¤åå½¢åµå¥æ¹æ³é½æ¯æ ¹æèªç¶èªè¨èçä¸­çæ¹æ³æ¹ç·¨ååç¼çãå¨å©åé åä¸­é½è§å¯å°éäºæ¹æ³çéå¶ãå¤§å¤æ¸éäºæ¹æ³éè¦æ¼«é·ä¸èè²»è³æºçè¨ç·´ãå¤§å¤æ¸æ¹æ³çå¦ä¸åç¼ºé»æ¯å®åæ¯é»çå­ï¼å¾ä¸­çè§£è³è¨å¦ä½è¢«çµæ§åç¸ç¶è¤éãæ¨¡åçå¯è§£éæ§åè¨±å¨ä¸éè¦å¤é¨è³è¨çææ³ä¸äºè§£åéç©ºéæ¯å¦ä½è¢«çµæ§åçï¼å æ­¤å¯ä»¥æ´å®¹æå°é²è¡ç¨½æ ¸ãç¢è¨éå©åéå¶ï¼æåæåºäºä¸åæ°ç©çæ¡æ¶ï¼ä»¥ææçæ¹å¼å°ç¶²è·¯é é»åµå¥å¯è§£éçåéç©ºéä¸­ãæåçä½ç¶­äºé¨åæ¡æ¶ (LDBGF) å©ç¨ç¶²è·¯çäºé¨åæå½±ä½¿ç¨æ´¾ç³»ä¾éä½ç¶­åº¦ãé¤äº LDBGF ä¹å¤ï¼æåéä»ç´¹äºå©åä¾è³´ç¤¾ç¾¤èéæ´¾ç³»çæ­¤æ¡æ¶å¯¦ä½ï¼SINr-NR å SINr-MFãæåå±ç¤ºäº SINr-MF å¨ç¶å¸åå½¢ä¸å¯ä»¥å·è¡è¯å¥½ï¼è SINr-NR å¯ä»¥ç¢çé«åè³ªçåå½¢åè©åµå¥ï¼éäºåµå¥å¨åæ¬¡å·è¡ä¸­é½æ¯å¯è§£éä¸ç©©å®çã</paragraph>

##### **Can Graph Neural Networks Learn Language with Extremely Weak Text Supervision?**
2412.08174v1 by Zihao Li, Lecheng Zheng, Bowen Jin, Dongqi Fu, Baoyu Jing, Yikun Ban, Jingrui He, Jiawei Han

While great success has been achieved in building vision models with
Contrastive Language-Image Pre-training (CLIP) over Internet-scale image-text
pairs, building transferable Graph Neural Networks (GNNs) with CLIP pipeline is
challenging because of three fundamental issues: the scarcity of labeled data
and text supervision, different levels of downstream tasks, and the conceptual
gaps between domains. In this work, to address these issues, we leverage
multi-modal prompt learning to effectively adapt pre-trained GNN to downstream
tasks and data, given only a few semantically labeled samples, each with
extremely weak text supervision. Our new paradigm embeds the graphs directly in
the same space as the Large Language Models (LLMs) by learning both graph
prompts and text prompts simultaneously. To accomplish this, we improve
state-of-the-art graph prompt method, and then propose the first graph-language
multi-modal prompt learning approach for exploiting the knowledge in
pre-trained models. Notably, due to the insufficient supervision for
fine-tuning, in our paradigm, the pre-trained GNN and the LLM are kept frozen,
so the learnable parameters are much fewer than fine-tuning any pre-trained
model. Through extensive experiments on real-world datasets, we demonstrate the
superior performance of our paradigm in few-shot, multi-task-level, and
cross-domain settings. Moreover, we build the first CLIP-style zero-shot
classification prototype that can generalize GNNs to unseen classes with
extremely weak text supervision.

æè¦ï¼<paragraph>åç®¡å©ç¨ç¶²éç¶²è·¯è¦æ¨¡çååæå­éå°ï¼å¨å»ºç«å·æå°æ¯èªè¨å½±åé è¨ç·´ (CLIP) çè¦è¦ºæ¨¡åæ¹é¢å·²åå¾å·¨å¤§çæåï¼ä½ç±æ¼ä¸ååºæ¬åé¡ï¼ä½¿ç¨ CLIP ç®¡ç·å»ºç«å¯è½ç§»çåç¥ç¶ç¶²è·¯ (GNN) å·æææ°æ§ï¼æ¨è¨è³æåæå­ç£ç£çç¨ç¼ºæ§ãä¸åå±¤ç´çä¸æ¸¸ä»»åï¼ä»¥åé åä¹éçæ¦å¿µå·®è·ãçºäºè§£æ±ºéäºåé¡ï¼æåå¨éåå·¥ä½ä¸­å©ç¨å¤æ¨¡å¼æç¤ºå­¸ç¿ï¼å¨åçµ¦äºå°æ¸èªç¾©æ¨è¨ç¯ä¾ï¼æ¯åç¯ä¾é½å·ææ¥µå¼±çæå­ç£ç£ï¼çææ³ä¸ï¼ææå°èª¿æ´é è¨ç·´ç GNN ä»¥é©æä¸æ¸¸ä»»ååè³æãæåçç¯ä¾ééåæå­¸ç¿åæç¤ºåæå­æç¤ºï¼å°åå½¢ç´æ¥åµå¥èå¤§åèªè¨æ¨¡å (LLM) ç¸åçç©ºéä¸­ãçºäºéæéåç®æ¨ï¼æåæ¹é²äºæåé²çåæç¤ºæ¹æ³ï¼ç¶å¾æåºç¬¬ä¸ååèªè¨å¤æ¨¡å¼æç¤ºå­¸ç¿æ¹æ³ï¼ä»¥å©ç¨é è¨ç·´æ¨¡åä¸­çç¥è­ãå¼å¾æ³¨æçæ¯ï¼ç±æ¼å¾®èª¿çç£ç£ä¸è¶³ï¼å¨æåçç¯ä¾ä¸­ï¼é è¨ç·´ç GNN å LLM ä¿æåçµï¼å æ­¤å¯å­¸ç¿çåæ¸é å°æ¼å¾®èª¿ä»»ä½é è¨ç·´æ¨¡åãééå¨çå¯¦ä¸çè³æéä¸é²è¡å»£æ³çå¯¦é©ï¼æåå±ç¤ºäºæåçç¯ä¾å¨å°éãå¤ä»»åå±¤ç´åè·¨é åè¨­å®ä¸­çåªç°æè½ãæ­¤å¤ï¼æåå»ºç«äºç¬¬ä¸å CLIP é¢¨æ ¼çé¶æ¬¡åé¡ååï¼å®å¯ä»¥å° GNN æ¨å»£å°å·ææ¥µå¼±æå­ç£ç£çæªè¦é¡å¥ã</paragraph>

##### **Repository-Level Graph Representation Learning for Enhanced Security Patch Detection**
2412.08068v1 by Xin-Cheng Wen, Zirui Lin, Cuiyun Gao, Hongyu Zhang, Yong Wang, Qing Liao

Software vendors often silently release security patches without providing
sufficient advisories (e.g., Common Vulnerabilities and Exposures) or delayed
updates via resources (e.g., National Vulnerability Database). Therefore, it
has become crucial to detect these security patches to ensure secure software
maintenance. However, existing methods face the following challenges: (1) They
primarily focus on the information within the patches themselves, overlooking
the complex dependencies in the repository. (2) Security patches typically
involve multiple functions and files, increasing the difficulty in well
learning the representations. To alleviate the above challenges, this paper
proposes a Repository-level Security Patch Detection framework named RepoSPD,
which comprises three key components: 1) a repository-level graph construction,
RepoCPG, which represents software patches by merging pre-patch and post-patch
source code at the repository level; 2) a structure-aware patch representation,
which fuses the graph and sequence branch and aims at comprehending the
relationship among multiple code changes; 3) progressive learning, which
facilitates the model in balancing semantic and structural information. To
evaluate RepoSPD, we employ two widely-used datasets in security patch
detection: SPI-DB and PatchDB. We further extend these datasets to the
repository level, incorporating a total of 20,238 and 28,781 versions of
repository in C/C++ programming languages, respectively, denoted as SPI-DB* and
PatchDB*. We compare RepoSPD with six existing security patch detection methods
and five static tools. Our experimental results demonstrate that RepoSPD
outperforms the state-of-the-art baseline, with improvements of 11.90%, and
3.10% in terms of accuracy on the two datasets, respectively.

æè¦ï¼<paragraph>è»é«ä¾æåéå¸¸æå¨æ²ææä¾è¶³å¤ çè«®è©¢ï¼ä¾å¦å¸¸è¦æ¼æ´åæéªï¼æå»¶é²ééè³æºï¼ä¾å¦åå®¶æ¼æ´è³æåº«ï¼æ´æ°çææ³ä¸ï¼ç¡è²å°ç¼å¸å®å¨æ§ä¿®è£ç¨å¼ãå æ­¤ï¼åµæ¸¬éäºå®å¨æ§ä¿®è£ç¨å¼ä»¥ç¢ºä¿è»é«ç¶­è­·å®å¨è³ééè¦ãç¶èï¼ç¾ææ¹æ³é¢è¨ä»¥ä¸ææ°ï¼(1) å®åä¸»è¦éæ³¨ä¿®è£ç¨å¼æ¬èº«çè³è¨ï¼å¿½ç¥äºå²å­åº«ä¸­è¤éçç¸ä¾æ§ã(2) å®å¨æ§ä¿®è£ç¨å¼éå¸¸æ¶åå¤åå½å¼åæªæ¡ï¼å¢å äºè¯å¥½å­¸ç¿è¡¨ç¤ºå½¢å¼çé£åº¦ãçºäºç·©è§£ä¸è¿°ææ°ï¼æ¬ææåºäºä¸ååçº RepoSPD çå²å­åº«å±¤ç´å®å¨æ§ä¿®è£ç¨å¼åµæ¸¬æ¶æ§ï¼å®åå«ä¸åééµåä»¶ï¼1) å²å­åº«å±¤ç´åå½¢å»ºæ§ï¼RepoCPGï¼å®ééåä½µå²å­åº«å±¤ç´çåä¿®è£ç¨å¼åå¾ä¿®è£ç¨å¼åå§ç¢¼ä¾è¡¨ç¤ºè»é«ä¿®è£ç¨å¼ï¼2) çµæ§æç¥ä¿®è£ç¨å¼è¡¨ç¤ºå½¢å¼ï¼å®èåäºåå½¢ååºååæ¯ï¼æ¨å¨çè§£å¤åç¨å¼ç¢¼è®æ´ä¹éçéä¿ï¼3) æ¼¸é²å¼å­¸ç¿ï¼å®æå©æ¼æ¨¡åå¹³è¡¡èªæåçµæ§è³è¨ãçºäºè©ä¼° RepoSPDï¼æåå¨å®å¨æ§ä¿®è£ç¨å¼åµæ¸¬ä¸­æ¡ç¨äºå©åå»£æ³ä½¿ç¨çè³æéï¼SPI-DB å PatchDBãæåé²ä¸æ­¥å°éäºè³æéæ´åå¥ä»¶å°å²å­åº«å±¤ç´ï¼åå¥ç´å¥äº C/C++ ç¨å¼èªè¨ä¸­ç¸½è¨ 20,238 å 28,781 åçæ¬çå²å­åº«ï¼è¡¨ç¤ºçº SPI-DB* å PatchDB*ãæåå° RepoSPD èå­ç¨®ç¾æçå®å¨æ§ä¿®è£ç¨å¼åµæ¸¬æ¹æ³åäºç¨®éæå·¥å·é²è¡æ¯è¼ãæåçå¯¦é©çµæè¡¨æï¼RepoSPD åªæ¼æåé²çåºæºï¼å¨å©åè³æéä¸çæºç¢ºæ§åå¥æé«äº 11.90% å 3.10%ã</paragraph>

##### **Bootstrapping Heterogeneous Graph Representation Learning via Large Language Models: A Generalized Approach**
2412.08038v1 by Hang Gao, Chenhao Zhang, Fengge Wu, Junsuo Zhao, Changwen Zheng, Huaping Liu

Graph representation learning methods are highly effective in handling
complex non-Euclidean data by capturing intricate relationships and features
within graph structures. However, traditional methods face challenges when
dealing with heterogeneous graphs that contain various types of nodes and edges
due to the diverse sources and complex nature of the data. Existing
Heterogeneous Graph Neural Networks (HGNNs) have shown promising results but
require prior knowledge of node and edge types and unified node feature
formats, which limits their applicability. Recent advancements in graph
representation learning using Large Language Models (LLMs) offer new solutions
by integrating LLMs' data processing capabilities, enabling the alignment of
various graph representations. Nevertheless, these methods often overlook
heterogeneous graph data and require extensive preprocessing. To address these
limitations, we propose a novel method that leverages the strengths of both LLM
and GNN, allowing for the processing of graph data with any format and type of
nodes and edges without the need for type information or special preprocessing.
Our method employs LLM to automatically summarize and classify different data
formats and types, aligns node features, and uses a specialized GNN for
targeted learning, thus obtaining effective graph representations for
downstream tasks. Theoretical analysis and experimental validation have
demonstrated the effectiveness of our method.

æè¦ï¼åè¡¨è¡¨ç¤ºå­¸ç¿æ¹æ³å¨èçè¤éçéæ­å¹¾éå¾æ¸ææ¹é¢éå¸¸ææï¼æ¹æ³æ¯ææåå½¢çµæ§ä¸­çè¤ééä¿åç¹å¾µãç¶èï¼ç±æ¼æ¸æä¾æºå¤æ¨£ä¸æ§è³ªè¤éï¼å³çµ±æ¹æ³å¨èçåå«åç¨®é¡åç¯é»åéçç°è³ªåå½¢æé¢è¨ææ°ãç¾æçç°è³ªåå½¢ç¥ç¶ç¶²è·¯ (HGNN) å·²å±ç¾åºæå¸æçææï¼ä½éè¦äºåäºè§£ç¯é»åéçé¡åï¼ä»¥åçµ±ä¸çç¯é»ç¹å¾µæ ¼å¼ï¼ééå¶äºå¶é©ç¨æ§ãæè¿ä½¿ç¨å¤§åèªè¨æ¨¡å (LLM) çåå½¢è¡¨ç¤ºå­¸ç¿çé²å±æä¾äºæ°çè§£æ±ºæ¹æ¡ï¼æ¹æ³æ¯æ´å LLM çæ¸æèçåè½ï¼ä½¿åç¨®åå½¢è¡¨ç¤ºå¾ä»¥å°é½ãåç®¡å¦æ­¤ï¼éäºæ¹æ³éå¸¸æå¿½ç¥ç°è³ªåå½¢æ¸æï¼ä¸¦ä¸éè¦å»£æ³çé èçãçºäºè§£æ±ºéäºéå¶ï¼æåæåºäºä¸ç¨®æ°æ¹æ³ï¼å®å©ç¨äº LLM å GNN çåªé»ï¼åè¨±èçä»»ä½æ ¼å¼åé¡åçç¯é»åéçåå½¢æ¸æï¼èä¸éè¦é¡åä¿¡æ¯æç¹æ®é èçãæåçæ¨¡åæ¡ç¨ LLM èªåç¸½çµååé¡ä¸åçæ¸ææ ¼å¼åé¡åï¼å°é½ç¯é»ç¹å¾µï¼ä¸¦ä½¿ç¨å°éç GNN é²è¡ç®æ¨å­¸ç¿ï¼å¾èçºä¸æ¸¸ä»»åç²åææçåå½¢è¡¨ç¤ºãçè«åæåå¯¦é©é©è­å·²è­æäºæåæ¹æ³çæææ§ã

##### **Adapting to Non-Stationary Environments: Multi-Armed Bandit Enhanced Retrieval-Augmented Generation on Knowledge Graphs**
2412.07618v1 by Xiaqiang Tang, Jian Li, Nan Du, Sihong Xie

Despite the superior performance of Large language models on many NLP tasks,
they still face significant limitations in memorizing extensive world
knowledge. Recent studies have demonstrated that leveraging the
Retrieval-Augmented Generation (RAG) framework, combined with Knowledge Graphs
that encapsulate extensive factual data in a structured format, robustly
enhances the reasoning capabilities of LLMs. However, deploying such systems in
real-world scenarios presents challenges: the continuous evolution of
non-stationary environments may lead to performance degradation and user
satisfaction requires a careful balance of performance and responsiveness. To
address these challenges, we introduce a Multi-objective Multi-Armed Bandit
enhanced RAG framework, supported by multiple retrieval methods with diverse
capabilities under rich and evolving retrieval contexts in practice. Within
this framework, each retrieval method is treated as a distinct ``arm''. The
system utilizes real-time user feedback to adapt to dynamic environments, by
selecting the appropriate retrieval method based on input queries and the
historical multi-objective performance of each arm. Extensive experiments
conducted on two benchmark KGQA datasets demonstrate that our method
significantly outperforms baseline methods in non-stationary settings while
achieving state-of-the-art performance in stationary environments. Code and
data are available at https://github.com/FUTUREEEEEE/Dynamic-RAG.git

æè¦ï¼åç®¡å¤§åèªè¨æ¨¡åå¨è¨±å¤ NLP ä»»åä¸è¡¨ç¾åªç°ï¼
å®åå¨è¨æ¶å»£æ³çä¸çç¥è­æ¹é¢ä»é¢è¨éå¤§éå¶ãæè¿çç ç©¶è¡¨æï¼
å©ç¨æª¢ç´¢å¢å¼·çæ (RAG) æ¡æ¶ï¼çµåä»¥çµæ§åæ ¼å¼å°è£å»£æ³äºå¯¦è³æçç¥è­åè­ï¼
è½ç©©å¥å°å¢å¼· LLM çæ¨çè½åãç¶èï¼å¨ç¾å¯¦ä¸çå ´æ¯ä¸­é¨ç½²æ­¤é¡ç³»çµ±æç¢çææ°ï¼
éå¹³ç©©ç°å¢çæçºæ¼è®å¯è½å°è´æè½ä¸éï¼èä½¿ç¨èçæ»¿æåº¦éè¦å¨æè½ååææ§ä¹éåå¾ä»ç´°çå¹³è¡¡ã
çºäºæå°éäºææ°ï¼æåå¼å¥äºå¤ç®æ¨å¤èèèæ©å¢å¼·ç RAG æ¡æ¶ï¼
ä¸¦å¨å¯¦åä¸­æ¡ç¨å·åå¤åè½åçåç¨®æª¢ç´¢æ¹æ³ï¼ä»¥æå°è±å¯ä¸ä¸æ·æ¼è®çæª¢ç´¢æå¢ã
å¨æ­¤æ¡æ¶ä¸­ï¼æ¯åæª¢ç´¢æ¹æ³é½è¢«è¦çºä¸åä¸åçãæèãã
è©²ç³»çµ±å©ç¨å³æä½¿ç¨èåé¥ä¾é©æåæç°å¢ï¼
æ ¹æè¼¸å¥æ¥è©¢åæ¯åæèçæ­·å²å¤ç®æ¨æè½ä¾é¸æé©ç¶çæª¢ç´¢æ¹æ³ã
å¨å©ååºæº KGQA è³æéä¸é²è¡çå»£æ³å¯¦é©è¡¨æï¼
æåçæ¨¡åå¨éå¹³ç©©è¨­å®ä¸­é¡¯èåªæ¼åºç·æ¨¡åï¼åæå¨å¹³ç©©ç°å¢ä¸­éå°æåé²çæè½ã
ç¨å¼ç¢¼åè³æå¯æ¼ https://github.com/FUTUREEEEEE/Dynamic-RAG.git åå¾

##### **Knowledge Graph Guided Evaluation of Abstention Techniques**
2412.07430v1 by Kinshuk Vasisht, Navreet Kaur, Danish Pruthi

To deploy language models safely, it is crucial that they abstain from
responding to inappropriate requests. Several prior studies test the safety
promises of models based on their effectiveness in blocking malicious requests.
In this work, we focus on evaluating the underlying techniques that cause
models to abstain. We create SELECT, a benchmark derived from a set of benign
concepts (e.g., "rivers") from a knowledge graph. The nature of SELECT enables
us to isolate the effects of abstention techniques from other safety training
procedures, as well as evaluate their generalization and specificity. Using
SELECT, we benchmark different abstention techniques over six open-weight and
closed-source models. We find that the examined techniques indeed cause models
to abstain with over $80\%$ abstention rates. However, these techniques are not
as effective for descendants of the target concepts, with refusal rates
declining by $19\%$. We also characterize the generalization-vs-specificity
trade-offs for different techniques. Overall, no single technique is invariably
better than the others. Our findings call for a careful evaluation of different
aspects of abstention, and hopefully inform practitioners of various trade-offs
involved.

æè¦ï¼çºäºå®å¨å°é¨ç½²èªè¨æ¨¡åï¼è³ééè¦çæ¯ï¼å®åå¿é é¿ååæä¸é©ç¶çè«æ±ãååææ¸é ç ç©¶æ¸¬è©¦æ¨¡åçå®å¨æ§ï¼ä¾æå®åå°éæ¡æè«æ±çæææ§çºåºç¤ãå¨éé å·¥ä½ä¸­ï¼æåå°æ³¨æ¼è©ä¼°å°è´æ¨¡åé¿ååæçåºå±¤æè¡ãæåå»ºç«äº SELECTï¼ä¸åå¾ç¥è­åè­ä¸­ä¸çµè¯æ§æ¦å¿µï¼ä¾å¦ãæ²³æµãï¼è¡ççåºæºãSELECT çæ§è³ªä½¿æåè½å¤ å°é¿ååææè¡çå½±é¿èå¶ä»å®å¨è¨ç·´ç¨åºéé¢ï¼ä¸¦è©ä¼°å®åçæ¦æ¬æ§åç¹ç°æ§ãä½¿ç¨ SELECTï¼æåå°å­åéæ¾æ¬éåå°éåå§ç¢¼æ¨¡åé²è¡äºä¸åé¿ååææè¡çåºæºæ¸¬è©¦ãæåç¼ç¾ï¼ææª¢æ¥çæè¡ç¢ºå¯¦å°è´æ¨¡åé¿ååæï¼é¿ååæçè¶é 80%ãç¶èï¼éäºæè¡å°æ¼ç®æ¨æ¦å¿µçå¾ä»£ä¸¦ä¸é£éº¼ææï¼æçµçä¸éäº 19%ãæåéæè¿°äºä¸åæè¡çæ¦æ¬æ§èç¹ç°æ§æ¬è¡¡ãç¸½é«èè¨ï¼æ²æä»»ä½å®ä¸æè¡å§çµåªæ¼å¶ä»æè¡ãæåçç¼ç¾è¦æ±ä»ç´°è©ä¼°é¿ååæçä¸åé¢åï¼ä¸¦å¸æè®å¾æ¥­äººå¡äºè§£ææ¶åçåç¨®æ¬è¡¡ã

##### **RAG-based Question Answering over Heterogeneous Data and Text**
2412.07420v1 by Philipp Christmann, Gerhard Weikum

This article presents the QUASAR system for question answering over
unstructured text, structured tables, and knowledge graphs, with unified
treatment of all sources. The system adopts a RAG-based architecture, with a
pipeline of evidence retrieval followed by answer generation, with the latter
powered by a moderate-sized language model. Additionally and uniquely, QUASAR
has components for question understanding, to derive crisper input for evidence
retrieval, and for re-ranking and filtering the retrieved evidence before
feeding the most informative pieces into the answer generation. Experiments
with three different benchmarks demonstrate the high answering quality of our
approach, being on par with or better than large GPT models, while keeping the
computational cost and energy consumption orders of magnitude lower.

æè¦ï¼æ¬æä»ç´¹ QUASAR ç³»çµ±ï¼ç¨æ¼åç­éçµæ§åæå­ãçµæ§åè¡¨æ ¼åç¥è­åè¡¨ä¸­çåé¡ï¼ä¸¦çµ±ä¸èçææä¾æºãè©²ç³»çµ±æ¡ç¨åºæ¼ RAG çæ¶æ§ï¼ç®¡éåæ¬è­ææª¢ç´¢å¾æ¥ç­æ¡çæï¼å¾èç±ä¸­ç­è¦æ¨¡çèªè¨æ¨¡åæä¾æ¯æ´ãæ­¤å¤ï¼QUASAR ç¨ç¹å°åå«åé¡çè§£åä»¶ï¼ä»¥è¡çæ´æ¸æ°çè¼¸å¥é²è¡è­ææª¢ç´¢ï¼ä»¥åå¨å°ææè³è¨ççæ®µè¼¸å¥ç­æ¡çæä¹åéæ°æåºåéæ¿¾æª¢ç´¢å°çè­æãä½¿ç¨ä¸åä¸åçåºæºé²è¡çå¯¦é©è­æäºæåæ¹æ³çé«åç­åè³ªï¼èå¤§å GPT æ¨¡åç¸ç¶ææ´å¥½ï¼åæå°éç®ææ¬åè½æºæ¶èéä½äºå¹¾åæ¸éç´ã

##### **Generating Knowledge Graphs from Large Language Models: A Comparative Study of GPT-4, LLaMA 2, and BERT**
2412.07412v1 by Ahan Bhatt, Nandan Vaghela, Kush Dudhia

Knowledge Graphs (KGs) are essential for the functionality of GraphRAGs, a
form of Retrieval-Augmented Generative Systems (RAGs) that excel in tasks
requiring structured reasoning and semantic understanding. However, creating
KGs for GraphRAGs remains a significant challenge due to accuracy and
scalability limitations of traditional methods. This paper introduces a novel
approach leveraging large language models (LLMs) like GPT-4, LLaMA 2 (13B), and
BERT to generate KGs directly from unstructured data, bypassing traditional
pipelines. Using metrics such as Precision, Recall, F1-Score, Graph Edit
Distance, and Semantic Similarity, we evaluate the models' ability to generate
high-quality KGs. Results demonstrate that GPT-4 achieves superior semantic
fidelity and structural accuracy, LLaMA 2 excels in lightweight,
domain-specific graphs, and BERT provides insights into challenges in
entity-relationship modeling. This study underscores the potential of LLMs to
streamline KG creation and enhance GraphRAG accessibility for real-world
applications, while setting a foundation for future advancements.

æè¦ï¼ç¥è­åè­ (KG) å°æ¼ GraphRAG çåè½è³ééè¦ï¼GraphRAG æ¯ä¸ç¨®æª¢ç´¢å¢å¼·å¼çæç³»çµ± (RAG)ï¼å¨éè¦çµæ§åæ¨çåèªç¾©çè§£çä»»åä¸­è¡¨ç¾åºè²ãç¶èï¼ç±æ¼å³çµ±æ¹æ³çæºç¢ºæ§åå¯æ´åæ§éå¶ï¼çº GraphRAG å»ºç« KG ä»ç¶æ¯ä¸é éå¤§ææ°ãæ¬æä»ç´¹äºä¸ç¨®åµæ°æ¹æ³ï¼å©ç¨å¤§åèªè¨æ¨¡å (LLM)ï¼ä¾å¦ GPT-4ãLLaMA 2 (13B) å BERTï¼ç´æ¥å¾éçµæ§åæ¸æçæ KGï¼ç¹éå³çµ±ç®¡éãæåä½¿ç¨æºç¢ºåº¦ãå¬åçãF1 åæ¸ãåå½¢ç·¨è¼¯è·é¢åèªç¾©ç¸ä¼¼æ§ç­ææ¨ï¼è©ä¼°æ¨¡åçæé«åè³ª KG çè½åãçµæè¡¨æï¼GPT-4 éå°äºåè¶çèªç¾©ä¿çåº¦åçµæ§æºç¢ºæ§ï¼LLaMA 2 å¨è¼éç´ãç¹å®é åçåå½¢ä¸­è¡¨ç¾åºè²ï¼è BERT åæä¾äºå°å¯¦é«éä¿å»ºæ¨¡ææ°çè¦è§£ãéé ç ç©¶å¼·èª¿äº LLM ç°¡å KG å»ºç«åå¢å¼· GraphRAG å¨ç¾å¯¦ä¸çæç¨ä¸­å¯åæ§çæ½åï¼åæçºæªä¾çé²å±å¥ å®äºåºç¤ã

##### **My Words Imply Your Opinion: Reader Agent-Based Propagation Enhancement for Personalized Implicit Emotion Analysis**
2412.07367v1 by Jian Liao, Yu Feng, Xiaoyu Wang, Suge Wang, Jianxing Zheng, Deyu Li

In implicit emotion analysis (IEA), the subtlety of emotional expressions
makes it particularly sensitive to user-specific characteristics. Existing
studies often inject personalization into the analysis by focusing on the
authorial dimension of the emotional text. However, these methods overlook the
potential influence of the intended reader on the reaction of implicit
emotions. In this paper, we refine the IEA task to Personalized Implicit
Emotion Analysis (PIEA) and introduce the RAPPIE model, a novel framework
designed to address the issue of missing user information within this task. In
particular, 1) we create reader agents based on the Large Language Model to
simulate reader reactions, to address challenges of the spiral of silence and
data incompleteness encountered when acquiring reader feedback information. 2)
We establish a reader propagation role system and develop a role-aware emotion
propagation multi-view graph learning model, which effectively deals with the
sparsity of reader information by utilizing the distribution of propagation
roles. 3) We annotate two Chinese PIEA datasets with detailed user metadata,
thereby addressing the limitation of prior datasets that primarily focus on
textual content annotation. Extensive experiments on these datasets indicate
that the RAPPIE model outperforms current state-of-the-art baselines,
highlighting the significance and efficacy of incorporating reader feedback
into the PIEA process.

æè¦ï¼å¨éå¼ææåæ (IEA) ä¸­ï¼ææè¡¨è¾¾çå¾®å¦æ§ä½¿å¶å¯¹ç¹å®äºç¨æ·çç¹å¾ç¹å«ææãç°æçç ç©¶éå¸¸éè¿å³æ³¨ææææ¬çä½èç»´åº¦æ¥å°ä¸ªæ§åæ³¨å¥å°åæä¸­ãç¶èï¼è¿äºæ¹æ³å¿½ç¥äºé¢æè¯»èå¯¹éå¼ææååºçæ½å¨å½±åãå¨æ¬æä¸­ï¼æä»¬å° IEA ä»»å¡ç»åä¸ºä¸ªæ§åéå¼ææåæ (PIEA)ï¼å¹¶å¼å¥ RAPPIE æ¨¡åï¼è¿æ¯ä¸ä¸ªæ°é¢çæ¡æ¶ï¼æ¨å¨è§£å³æ­¤ä»»å¡ä¸­ç¼ºå°ç¨æ·ä¿¡æ¯çé®é¢ãç¹å«æ¯ï¼1) æä»¬åºäºå¤§åè¯­è¨æ¨¡ååå»ºè¯»èä»£çæ¥æ¨¡æè¯»èååºï¼ä»¥è§£å³å¨è·åè¯»èåé¦ä¿¡æ¯æ¶éå°çæ²é»èºæåæ°æ®ä¸å®æ´æ§çææã2) æä»¬å»ºç«äºä¸ä¸ªè¯»èä¼ æ­è§è²ç³»ç»ï¼å¹¶å¼åäºä¸ä¸ªè§è²æç¥æç»ªä¼ æ­å¤è§å¾å¾å­¦ä¹ æ¨¡åï¼è¯¥æ¨¡åéè¿å©ç¨ä¼ æ­è§è²çåå¸ææå°å¤çè¯»èä¿¡æ¯çç¨çæ§ã3) æä»¬ä½¿ç¨è¯¦ç»çç¨æ·åæ°æ®æ³¨éäºä¸¤ä¸ªä¸­æ PIEA æ°æ®éï¼ä»èè§£å³äºååä¸»è¦ä¸æ³¨äºææ¬åå®¹æ³¨éçæ°æ®éçå±éæ§ãå¨è¿äºæ°æ®éä¸è¿è¡çå¹¿æ³å®éªè¡¨æï¼RAPPIE æ¨¡åä¼äºå½åæåè¿çåºçº¿ï¼çªåºäºå°è¯»èåé¦çº³å¥ PIEA è¿ç¨çéè¦æ§åæææ§ã

##### **ProVision: Programmatically Scaling Vision-centric Instruction Data for Multimodal Language Models**
2412.07012v2 by Jieyu Zhang, Le Xue, Linxin Song, Jun Wang, Weikai Huang, Manli Shu, An Yan, Zixian Ma, Juan Carlos Niebles, silvio savarese, Caiming Xiong, Zeyuan Chen, Ranjay Krishna, Ran Xu

With the rise of multimodal applications, instruction data has become
critical for training multimodal language models capable of understanding
complex image-based queries. Existing practices rely on powerful but costly
large language models (LLMs) or multimodal language models (MLMs) to produce
instruction data. These are often prone to hallucinations, licensing issues and
the generation process is often hard to scale and interpret. In this work, we
present a programmatic approach that employs scene graphs as symbolic
representations of images and human-written programs to systematically
synthesize vision-centric instruction data. Our approach ensures the
interpretability and controllability of the data generation process and scales
efficiently while maintaining factual accuracy. By implementing a suite of 24
single-image, 14 multi-image instruction generators, and a scene graph
generation pipeline, we build a scalable, cost-effective system: ProVision
which produces diverse question-answer pairs concerning objects, attributes,
relations, depth, etc., for any given image. Applied to Visual Genome and
DataComp datasets, we generate over 10 million instruction data points,
ProVision-10M, and leverage them in both pretraining and instruction tuning
stages of MLMs. When adopted in the instruction tuning stage, our single-image
instruction data yields up to a 7% improvement on the 2D split and 8% on the 3D
split of CVBench, along with a 3% increase in performance on QBench2,
RealWorldQA, and MMMU. Our multi-image instruction data leads to an 8%
improvement on Mantis-Eval. Incorporation of our data in both pre-training and
fine-tuning stages of xGen-MM-4B leads to an averaged improvement of 1.6%
across 11 benchmarks.

æè¦ï¼<paragraph>é¨èå¤æ¨¡ææç¨ç¨å¼èèµ·ï¼æä»¤è³æå·²æçºè¨ç·´å¤æ¨¡æèªè¨æ¨¡åçééµï¼è©²æ¨¡åè½å¤ çè§£åºæ¼è¤éå½±åçæ¥è©¢ãç¾æåæ³ä¾è³´æ¼å¼·å¤§ä½æè²´çå¤§åèªè¨æ¨¡å (LLM) æå¤æ¨¡æèªè¨æ¨¡å (MLM) ä¾ç¢çæä»¤è³æãéäºæ¹æ³ç¶å¸¸å®¹æåºç¾å¹»è¦ºãææ¬åé¡ï¼ä¸çæéç¨éå¸¸é£ä»¥æ´ååè©®éãå¨éé å·¥ä½ä¸­ï¼æåæåºäºä¸ç¨®ç¨å¼åæ¹æ³ï¼ä½¿ç¨å ´æ¯åå½¢ä½çºå½±åçç¬¦èè¡¨ç¤ºï¼ä¸¦ä½¿ç¨äººæ°å¯«çç¨å¼ç³»çµ±æ§å°åæä»¥è¦è¦ºçºä¸­å¿çæä»¤è³æãæåçåæ³ç¢ºä¿äºè³æçæéç¨çå¯è©®éæ§åå¯æ§æ§ï¼ä¸¦å¨ç¶­æäºå¯¦æºç¢ºæ§çåæææå°æ´åãééå¯¦ä½ä¸çµ 24 åå®ä¸å½±åã14 åå¤éå½±åæä»¤ç¢çå¨ï¼ä»¥åä¸åå ´æ¯åå½¢ç¢çç®¡ç·ï¼æåå»ºç«äºä¸åå¯æ´åãå·æææ¬æççç³»çµ±ï¼ProVisionï¼å®éå°ä»»ä½çµ¦å®çå½±åç¢çéæ¼ç©ä»¶ãå±¬æ§ãéä¿ãæ·±åº¦ç­çåç¨®åç­éå°ãæç¨æ¼ Visual Genome å DataComp è³æéï¼æåç¢çäºè¶é 1000 è¬åæä»¤è³æé»ï¼ProVision-10Mï¼ä¸¦å¨ MLM çé è¨ç·´åæä»¤å¾®èª¿éæ®µä¸­å ä»¥å©ç¨ãç¶å¨æä»¤å¾®èª¿éæ®µæ¡ç¨æï¼æåçå®ä¸å½±åæä»¤è³æå¨ CVBench ç 2D åå²ä¸­æåäº 7%ï¼å¨ 3D åå²ä¸­æåäº 8%ï¼å¨ QBench2ãRealWorldQA å MMMU ä¸çæè½ä¹æåäº 3%ãæåçå¤éå½±åæä»¤è³æå¨ Mantis-Eval ä¸æåäº 8%ãå¨ xGen-MM-4B çé è¨ç·´åå¾®èª¿éæ®µä¸­ç´å¥æåçè³æï¼å¨ 11 ååºæºæ¸¬è©¦ä¸­å¹³åæåäº 1.6%ã</paragraph>

##### **A Self-guided Multimodal Approach to Enhancing Graph Representation Learning for Alzheimer's Diseases**
2412.06212v1 by Zhepeng Wang, Runxue Bao, Yawen Wu, Guodong Liu, Lei Yang, Liang Zhan, Feng Zheng, Weiwen Jiang, Yanfu Zhang

Graph neural networks (GNNs) are powerful machine learning models designed to
handle irregularly structured data. However, their generic design often proves
inadequate for analyzing brain connectomes in Alzheimer's Disease (AD),
highlighting the need to incorporate domain knowledge for optimal performance.
Infusing AD-related knowledge into GNNs is a complicated task. Existing methods
typically rely on collaboration between computer scientists and domain experts,
which can be both time-intensive and resource-demanding. To address these
limitations, this paper presents a novel self-guided, knowledge-infused
multimodal GNN that autonomously incorporates domain knowledge into the model
development process. Our approach conceptualizes domain knowledge as natural
language and introduces a specialized multimodal GNN capable of leveraging this
uncurated knowledge to guide the learning process of the GNN, such that it can
improve the model performance and strengthen the interpretability of the
predictions. To evaluate our framework, we curated a comprehensive dataset of
recent peer-reviewed papers on AD and integrated it with multiple real-world AD
datasets. Experimental results demonstrate the ability of our method to extract
relevant domain knowledge, provide graph-based explanations for AD diagnosis,
and improve the overall performance of the GNN. This approach provides a more
scalable and efficient alternative to inject domain knowledge for AD compared
with the manual design from the domain expert, advancing both prediction
accuracy and interpretability in AD diagnosis.

æè¦ï¼åå½¢ç¥ç¶ç¶²è·¯ (GNN) æ¯ä¸æ¬¾å¼·å¤§çæ©å¨å­¸ç¿æ¨¡åï¼å°éç¨æ¼èççµæ§ä¸è¦åçè³æãç¶èï¼å®åçéç¨è¨­è¨éå¸¸ç¡æ³åååæé¿è²æµ·é»ç (AD) ä¸­çè¦é£æ¥é«ï¼çªé¡¯äºå å¥é åç¥è­ä»¥åªåæè½çéæ±ãå° AD ç¸éç¥è­èå¥ GNN æ¯ä¸é è¤éçä»»åãç¾ææ¹æ³éå¸¸ä»°è³´é»è¦ç§å­¸å®¶åé åå°å®¶ä¹éçåä½ï¼éå¯è½æèè²»å¤§éæéåè³æºãçºäºè§£æ±ºéäºéå¶ï¼æ¬ææåºäºä¸ç¨®æ°ç©çèªå°å¼ãç¥è­æ³¨å¥å¤æ¨¡å¼ GNNï¼å®è½èªä¸»å°å°é åç¥è­ç´å¥æ¨¡åéç¼éç¨ä¸­ãæåçåæ³å°é åç¥è­æ¦å¿µåçºèªç¶èªè¨ï¼ä¸¦å¼å¥ä¸åå°éçå¤æ¨¡å¼ GNNï¼å®è½å©ç¨éç¨®æªç¶æ´ççç¥è­ä¾æå° GNN çå­¸ç¿éç¨ï¼ä»¥ä¾¿å®è½æ¹åæ¨¡åæè½ä¸¦å å¼·é æ¸¬çå¯è§£éæ§ãçºäºè©ä¼°æåçæ¶æ§ï¼æåæ´çäºä¸ä»½éæ¼ AD çè¿æåè¡è©å¯©è«æçå¨é¢è³æéï¼ä¸¦å°å¶èå¤åçå¯¦ä¸çç AD è³æéæ´åãå¯¦é©çµæè­æäºæåçæ¹æ³è½å¤ èåç¸éçé åç¥è­ãæä¾ AD è¨ºæ·çåå½¢åèªªæï¼ä¸¦æ¹å GNN çæ´é«æè½ãèé åå°å®¶çæåè¨­è¨ç¸æ¯ï¼éç¨®æ¹æ³æä¾äºä¸åæ´å·å¯æ´åæ§åæçæ§çæ¿ä»£æ¹æ¡ï¼ç¨æ¼æ³¨å¥ AD çé åç¥è­ï¼é²èæå AD è¨ºæ·ä¸­çé æ¸¬æºç¢ºæ§åå¯è§£éæ§ã

##### **Automated Extraction and Creation of FBS Design Reasoning Knowledge Graphs from Structured Data in Product Catalogues Lacking Contextual Information**
2412.05868v1 by Vijayalaxmi Sahadevan, Sushil Mario, Yash Jaiswal, Divyanshu Bajpai, Vishal Singh, Hiralal Aggarwal, Suhas Suresh, Manjunath Maigur

Ontology-based knowledge graphs (KG) are desirable for effective knowledge
management and reuse in various decision making scenarios, including design.
Creating and populating extensive KG based on specific ontological models can
be highly labour and time-intensive unless automated processes are developed
for knowledge extraction and graph creation. Most research and development on
automated extraction and creation of KG is based on extensive unstructured data
sets that provide contextual information. However, some of the most useful
information about the products and services of a company has traditionally been
recorded as structured data. Such structured data sets rarely follow a standard
ontology, do not capture explicit mapping of relationships between the
entities, and provide no contextual information. Therefore, this research
reports a method and digital workflow developed to address this gap. The
developed method and workflow employ rule-based techniques to extract and
create a Function Behaviour-Structure (FBS) ontology-based KG from legacy
structured data, especially specification sheets and product catalogues. The
solution approach consists of two main components: a process for deriving
context and context-based classification rules for FBS ontology concepts and a
workflow for populating and retrieving the FBS ontology-based KG. KG and
Natural Language Processing (NLP) are used to automate knowledge extraction,
representation, and retrieval. The workflow's effectiveness is demonstrated via
pilot implementation in an industrial context. Insights gained from the pilot
study are reported regarding the challenges and opportunities, including
discussing the FBS ontology and concepts.

æè¦ï¼<paragraph>åºæ¼æ¬ä½è«çç¥è­åè­ (KG) å°æ¼å¨åç¨®æ±ºç­å¶å®æå¢ï¼åæ¬è¨­è¨ï¼ä¸­ææç®¡çåéç¨ç¥è­æ¯çæ³çãå»ºç«ä¸¦å¡«å¥åºæ¼ç¹å®æ¬é«æ¨¡åçå»£æ³ KG å¯è½éå¸¸èè²»äººååæéï¼é¤ééç¼åºç¨æ¼ç¥è­èåååè­å»ºç«çèªååæµç¨ãå¤§å¤æ¸éæ¼ KG èªååèååå»ºç«çç ç©¶åéç¼é½åºæ¼æä¾èçµ¡è³è¨çå»£æ³éçµæ§åè³æéãç¶èï¼éæ¼å¬å¸ç¢ååæåçä¸äºææç¨çè³è¨å³çµ±ä¸é½æ¯ä»¥çµæ§åè³æè¨éçãæ­¤é¡çµæ§åè³æéå¾å°éµå¾ªæ¨æºæ¬é«è«ï¼ä¸ææ·åå¯¦é«ä¹ééä¿çæç¢ºå°æï¼ä¹ä¸ææä¾èçµ¡è³è¨ãå æ­¤ï¼æ¬ç ç©¶å ±åäºä¸ç¨®æ¹æ³åæ¸ä½å·¥ä½æµç¨ï¼ç¨æ¼è§£æ±ºæ­¤å·®è·ãéç¼çæ¹æ³åå·¥ä½æµç¨æ¡ç¨åºæ¼è¦åçæè¡ï¼å¾å³çµ±çµæ§åè³æï¼ç¹å¥æ¯è¦æ ¼è¡¨åç¢åç®éï¼ä¸­èåä¸¦å»ºç«åè½è¡çºçµæ§ (FBS) æ¬é«è«åºç¤ç KGãè§£æ±ºæ¹æ¡æ¹æ³åå«å©åä¸»è¦çµæé¨åï¼ä¸åç¨æ¼æ¨å° FBS æ¬é«è«æ¦å¿µçèçµ¡ååºæ¼èçµ¡çåé¡è¦åçæµç¨ï¼ä»¥åä¸åç¨æ¼å¡«å¥åæª¢ç´¢ FBS æ¬é«è«åºç¤ç KG çå·¥ä½æµç¨ãKG åèªç¶èªè¨èç (NLP) ç¨æ¼èªååç¥è­èåãè¡¨ç¤ºåæª¢ç´¢ãå·¥ä½æµç¨çæææ§ééå¨å·¥æ¥­èçµ¡ä¸­çè©¦é»å¯¦ä½å¾å°è­æãå ±åäºå¾è©¦é»ç ç©¶ä¸­ç²å¾çè¦è§£ï¼åæ¬è¨è« FBS æ¬é«è«åæ¦å¿µå¨å§çææ°åæ©æã</paragraph>

##### **A Collaborative Multi-Agent Approach to Retrieval-Augmented Generation Across Diverse Data**
2412.05838v1 by Aniruddha Salve, Saba Attar, Mahesh Deshmukh, Sayali Shivpuje, Arnab Mitra Utsab

Retrieval-Augmented Generation (RAG) enhances Large Language Models (LLMs) by
incorporating external, domain-specific data into the generative process. While
LLMs are highly capable, they often rely on static, pre-trained datasets,
limiting their ability to integrate dynamic or private data. Traditional RAG
systems typically use a single-agent architecture to handle query generation,
data retrieval, and response synthesis. However, this approach becomes
inefficient when dealing with diverse data sources, such as relational
databases, document stores, and graph databases, often leading to performance
bottlenecks and reduced accuracy. This paper proposes a multi-agent RAG system
to address these limitations. Specialized agents, each optimized for a specific
data source, handle query generation for relational, NoSQL, and document-based
systems. These agents collaborate within a modular framework, with query
execution delegated to an environment designed for compatibility across various
database types. This distributed approach enhances query efficiency, reduces
token overhead, and improves response accuracy by ensuring that each agent
focuses on its specialized task. The proposed system is scalable and adaptable,
making it ideal for generative AI workflows that require integration with
diverse, dynamic, or private data sources. By leveraging specialized agents and
a modular execution environment, the system provides an efficient and robust
solution for handling complex, heterogeneous data environments in generative AI
applications.

æè¦ï¼æª¢ç´¢å¢å¼·çæ (RAG) ééå°å¤é¨é åç¹å®è³æç´å¥çææµç¨ï¼å¢å¼·å¤§åèªè¨æ¨¡å (LLM)ãéç¶ LLM å·æé«åº¦è½åï¼ä½å®åéå¸¸ä¾è³´æ¼éæçé è¨ç·´è³æéï¼éå¶äºå®åæ´ååææç§äººè³æçè½åãå³çµ±ç RAG ç³»çµ±éå¸¸ä½¿ç¨å®ä¸ä»£çæ¶æ§ä¾èçæ¥è©¢çæãè³ææª¢ç´¢ååæåæãç¶èï¼ç¶èçå¤æ¨£åçè³æä¾æºæï¼éç¨®æ¹æ³æè®å¾æ²ææçï¼ä¾å¦éä¿è³æåº«ãæä»¶å²å­ååå½¢è³æåº«ï¼éå¸¸æå°è´æè½ç¶é ¸åéä½æºç¢ºæ§ãæ¬ææåºä¸åå¤ä»£ç RAG ç³»çµ±ä¾è§£æ±ºéäºéå¶ãéå°ç¹å®è³æä¾æºæä½³åçå°éä»£çï¼è² è²¬éä¿ãNoSQL ååºæ¼æä»¶ç³»çµ±çæ¥è©¢çæãéäºä»£çå¨ä¸åæ¨¡çµåæ¶æ§å§åä½ï¼æ¥è©¢å·è¡å§æ´¾çµ¦ä¸åç°å¢ï¼è©²ç°å¢è¨­è¨çºèåç¨®è³æåº«é¡åç¸å®¹ãéç¨®åæ£å¼æ¹æ³å¢å¼·äºæ¥è©¢æçï¼æ¸å°äºæ¨è¨éé·ï¼ä¸¦ééç¢ºä¿æ¯åä»£çå°æ³¨æ¼å¶å°éä»»åï¼ä¾æ¹ååææºç¢ºæ§ãææåºçç³»çµ±å·æå¯æ´åæ§åé©ææ§ï¼ä½¿å¶æçºéè¦èå¤æ¨£åãåææç§äººè³æä¾æºæ´åççæå¼ AI å·¥ä½æµç¨ççæ³é¸æãééå©ç¨å°éä»£çåæ¨¡çµåå·è¡ç°å¢ï¼è©²ç³»çµ±çºèççæå¼ AI æç¨ç¨å¼ä¸­è¤éãç°è³ªçè³æç°å¢ï¼æä¾äºä¸åææä¸ç©©å¥çè§£æ±ºæ¹æ¡ã

##### **Large Language Models Merging for Enhancing the Link Stealing Attack on Graph Neural Networks**
2412.05830v1 by Faqian Guan, Tianqing Zhu, Wenhan Chang, Wei Ren, Wanlei Zhou

Graph Neural Networks (GNNs), specifically designed to process the graph
data, have achieved remarkable success in various applications. Link stealing
attacks on graph data pose a significant privacy threat, as attackers aim to
extract sensitive relationships between nodes (entities), potentially leading
to academic misconduct, fraudulent transactions, or other malicious activities.
Previous studies have primarily focused on single datasets and did not explore
cross-dataset attacks, let alone attacks that leverage the combined knowledge
of multiple attackers. However, we find that an attacker can combine the data
knowledge of multiple attackers to create a more effective attack model, which
can be referred to cross-dataset attacks. Moreover, if knowledge can be
extracted with the help of Large Language Models (LLMs), the attack capability
will be more significant. In this paper, we propose a novel link stealing
attack method that takes advantage of cross-dataset and Large Language Models
(LLMs). The LLM is applied to process datasets with different data structures
in cross-dataset attacks. Each attacker fine-tunes the LLM on their specific
dataset to generate a tailored attack model. We then introduce a novel model
merging method to integrate the parameters of these attacker-specific models
effectively. The result is a merged attack model with superior generalization
capabilities, enabling effective attacks not only on the attackers' datasets
but also on previously unseen (out-of-domain) datasets. We conducted extensive
experiments in four datasets to demonstrate the effectiveness of our method.
Additional experiments with three different GNN and LLM architectures further
illustrate the generality of our approach.

æè¦ï¼åç¥ç¶ç¶²è·¯ (GNN) å°éç¨æ¼èçåå½¢è³æï¼å¨åç¨®æç¨ä¸­é½åå¾äºé¡¯èçæåãé£çµç«åæ»æå°åå½¢è³ææ§æéå¤§çé±ç§å¨èï¼å çºæ»æèæ¨å¨æåç¯é»ï¼å¯¦é«ï¼ä¹éçææéä¿ï¼å¯è½å°è´å­¸è¡ä¸ç¶è¡çºãæ¬ºè©äº¤ææå¶ä»æ¡ææ´»åãååçç ç©¶ä¸»è¦éä¸­æ¼å®ä¸è³æéï¼ä¸¦ä¸æ²ææ¢è¨è·¨è³æéæ»æï¼æ´ä¸ç¨èªªå©ç¨å¤åæ»æèçç¶åç¥è­çæ»æãç¶èï¼æåç¼ç¾æ»æèå¯ä»¥çµåå¤åæ»æèçè³æç¥è­ä¾å»ºç«æ´ææçæ»ææ¨¡åï¼éå¯ä»¥ç¨±çºè·¨è³æéæ»æãæ­¤å¤ï¼å¦æå¯ä»¥å¨å¤§åèªè¨æ¨¡å (LLM) çå¹«å©ä¸æåç¥è­ï¼åæ»æè½åå°ææ´é¡¯èãå¨æ¬æä¸­ï¼æåæåºäºä¸ç¨®æ°ç©çé£çµç«åæ»ææ¹æ³ï¼è©²æ¹æ³å©ç¨è·¨è³æéåå¤§åèªè¨æ¨¡å (LLM)ãLLM ç¨æ¼å¨è·¨è³æéæ»æä¸­èçå·æä¸åè³æçµæ§çè³æéãæ¯åæ»æèéå°å¶ç¹å®è³æéå¾®èª¿ LLM ä»¥ç¢çéèº«æé çæ»ææ¨¡åãç¶å¾ï¼æåå¼å¥ä¸ç¨®æ°ç©çæ¨¡ååä½µæ¹æ³ï¼ä»¥æææ´åéäºç¹å®æ¼æ»æèçæ¨¡åçåæ¸ãçµææ¯ä¸ååä½µçæ»ææ¨¡åï¼å·æåªç°çæ³åè½åï¼ä¸åå¯ä»¥å¨æ»æèçè³æéä¸é²è¡æææ»æï¼éå¯ä»¥å¨ä»¥åæªè¦çï¼åå¤ï¼è³æéä¸é²è¡æææ»æãæåå¨ååè³æéä¸­é²è¡äºå»£æ³çå¯¦é©ï¼ä»¥è­ææåæ¹æ³çæææ§ãä½¿ç¨ä¸ç¨®ä¸åç GNN å LLM æ¶æ§é²è¡çé¡å¤å¯¦é©é²ä¸æ­¥èªªæäºæåæ¹æ³çæ®éæ§ã

##### **GL-Fusion: Rethinking the Combination of Graph Neural Network and Large Language model**
2412.06849v1 by Haotong Yang, Xiyuan Wang, Qian Tao, Shuxian Hu, Zhouchen Lin, Muhan Zhang

Recent research on integrating Large Language Models (LLMs) with Graph Neural
Networks (GNNs) typically follows two approaches: LLM-centered models, which
convert graph data into tokens for LLM processing, and GNN-centered models,
which use LLMs to encode text features into node and edge representations for
GNN input. LLM-centered models often struggle to capture graph structures
effectively, while GNN-centered models compress variable-length textual data
into fixed-size vectors, limiting their ability to understand complex
semantics. Additionally, GNN-centered approaches require converting tasks into
a uniform, manually-designed format, restricting them to classification tasks
and preventing language output. To address these limitations, we introduce a
new architecture that deeply integrates GNN with LLM, featuring three key
innovations: (1) Structure-Aware Transformers, which incorporate GNN's
message-passing capabilities directly into LLM's transformer layers, allowing
simultaneous processing of textual and structural information and generating
outputs from both GNN and LLM; (2) Graph-Text Cross-Attention, which processes
full, uncompressed text from graph nodes and edges, ensuring complete semantic
integration; and (3) GNN-LLM Twin Predictor, enabling LLM's flexible
autoregressive generation alongside GNN's scalable one-pass prediction.
GL-Fusion achieves outstand performance on various tasks. Notably, it achieves
state-of-the-art performance on OGBN-Arxiv and OGBG-Code2.

æè¦ï¼<paragraph>å°å¤§åèªè¨æ¨¡å (LLM) èåç¥ç¶ç¶²è·¯ (GNN) æ´åçææ°ç ç©¶éå¸¸éµå¾ªå©ç¨®æ¹æ³ï¼ä»¥ LLM çºä¸­å¿çæ¨¡åï¼å°åå½¢è³æè½æçº LLM èççç¬¦èï¼ä»¥åä»¥ GNN çºä¸­å¿çæ¨¡åï¼ä½¿ç¨ LLM å°æå­ç¹å¾µç·¨ç¢¼æç¯é»åéç·£è¡¨ç¤ºï¼ä½çº GNN è¼¸å¥ãä»¥ LLM çºä¸­å¿çæ¨¡åéå¸¸é£ä»¥æææ·ååå½¢çµæ§ï¼èä»¥ GNN çºä¸­å¿çæ¨¡åæå°è®é·æå­è³æå£ç¸®æåºå®å¤§å°çåéï¼éå¶å®åçè§£è¤éèªæçè½åãæ­¤å¤ï¼ä»¥ GNN çºä¸­å¿çæ¨¡åéè¦å°ä»»åè½ææçµ±ä¸çæåè¨­è¨æ ¼å¼ï¼éå¶å®ååªè½é²è¡åé¡ä»»åï¼ä¸ç¡æ³ç¢çèªè¨è¼¸åºãçºäºè§£æ±ºéäºéå¶ï¼æåå¼å¥ä¸ç¨®æ°çæ¶æ§ï¼å° GNN è LLM æ·±åº¦æ´åï¼å·åä¸å¤§ééµåµæ°ï¼(1) çµæ§æç¥Transformerï¼å° GNN çè¨æ¯å³éåè½ç´æ¥æ´åå° LLM çTransformerå±¤ä¸­ï¼åè¨±åæèçæå­åçµæ§è³è¨ï¼ä¸¦å¾ GNN å LLM ç¢çè¼¸åºï¼(2) åå½¢æå­äº¤åæ³¨æåï¼èçä¾èªåå½¢ç¯é»åéç·£çå®æ´æªå£ç¸®æå­ï¼ç¢ºä¿å®æ´çèªç¾©æ´åï¼(3) GNN-LLM ééé æ¸¬å¨ï¼åç¨ LLM çå½æ§èªè¿´æ­¸ç¢çï¼ä»¥å GNN çå¯æ´åå®æ¬¡é æ¸¬ãGL-Fusion å¨åç¨®ä»»åä¸­éæååºçæè½ãå¼å¾æ³¨æçæ¯ï¼å®å¨ OGBN-Arxiv å OGBG-Code2 ä¸éå°äºæåé²çæè½ã</paragraph>

##### **M$^{3}$-20M: A Large-Scale Multi-Modal Molecule Dataset for AI-driven Drug Design and Discovery**
2412.06847v1 by Siyuan Guo, Lexuan Wang, Chang Jin, Jinxian Wang, Han Peng, Huayang Shi, Wengen Li, Jihong Guan, Shuigeng Zhou

This paper introduces M$^{3}$-20M, a large-scale Multi-Modal Molecular
dataset that contains over 20 million molecules. Designed to support AI-driven
drug design and discovery, M$^{3}$-20M is 71 times more in the number of
molecules than the largest existing dataset, providing an unprecedented scale
that can highly benefit training or fine-tuning large (language) models with
superior performance for drug design and discovery. This dataset integrates
one-dimensional SMILES, two-dimensional molecular graphs, three-dimensional
molecular structures, physicochemical properties, and textual descriptions
collected through web crawling and generated by using GPT-3.5, offering a
comprehensive view of each molecule. To demonstrate the power of M$^{3}$-20M in
drug design and discovery, we conduct extensive experiments on two key tasks:
molecule generation and molecular property prediction, using large language
models including GLM4, GPT-3.5, and GPT-4. Our experimental results show that
M$^{3}$-20M can significantly boost model performance in both tasks.
Specifically, it enables the models to generate more diverse and valid
molecular structures and achieve higher property prediction accuracy than the
existing single-modal datasets, which validates the value and potential of
M$^{3}$-20M in supporting AI-driven drug design and discovery. The dataset is
available at \url{https://github.com/bz99bz/M-3}.

æè¦ï¼éç¯è«æä»ç´¹äº M$^{3}$-20Mï¼ä¸ååå«è¶é 2000 è¬ååå­çå¤§åå¤æ¨¡æåå­è³æéãM$^{3}$-20M æ¨å¨æ¯æ´ AI é©åçè¥ç©è¨­è¨åç¼ç¾ï¼å¶åå­æ¸éæ¯ç¾ææå¤§è³æéç 71 åï¼æä¾äºåææªæçè¦æ¨¡ï¼å¯ä»¥æ¥µå¤§å°åçæ¼è¨ç·´æå¾®èª¿å¤§åï¼èªè¨ï¼æ¨¡åï¼ä»¥å¨è¥ç©è¨­è¨åç¼ç¾æ¹é¢ç²å¾åè¶çæè½ãæ­¤è³æéæ´åäºééç¶²è·¯ç¬åæ¶éåä½¿ç¨ GPT-3.5 çæçå®ç¶­ SMILESãäºç¶­åå­åãä¸ç¶­åå­çµæ§ãç©çåå­¸æ§è³ªåæå­æè¿°ï¼æä¾äºæ¯ååå­çå¨é¢æª¢è¦ãçºäºå±ç¤º M$^{3}$-20M å¨è¥ç©è¨­è¨åç¼ç¾ä¸­çå¼·å¤§åè½ï¼æåå°å©åééµä»»åé²è¡äºå»£æ³çå¯¦é©ï¼åå­çæååå­æ§è³ªé æ¸¬ï¼ä½¿ç¨åæ¬ GLM4ãGPT-3.5 å GPT-4 å¨å§çå¤§åèªè¨æ¨¡åãæåçå¯¦é©çµæè¡¨æï¼M$^{3}$-20M å¯ä»¥é¡¯èæåæ¨¡åå¨å©åä»»åä¸­çæè½ãå·é«ä¾èªªï¼å®ä½¿æ¨¡åè½å¤ ç¢çæ´å¤æ¨£ååææçåå­çµæ§ï¼ä¸¦æ¯ç¾æçå®æ¨¡æè³æéç²å¾æ´é«çæ§è³ªé æ¸¬æºç¢ºåº¦ï¼éé©è­äº M$^{3}$-20M å¨æ¯æ´ AI é©åçè¥ç©è¨­è¨åç¼ç¾ä¸­çå¹å¼åæ½åãè³æéå¯å¨ \url{https://github.com/bz99bz/M-3} åå¾ã

##### **HMGIE: Hierarchical and Multi-Grained Inconsistency Evaluation for Vision-Language Data Cleansing**
2412.05685v1 by Zihao Zhu, Hongbao Zhang, Guanzong Wu, Siwei Lyu, Baoyuan Wu

Visual-textual inconsistency (VTI) evaluation plays a crucial role in
cleansing vision-language data. Its main challenges stem from the high variety
of image captioning datasets, where differences in content can create a range
of inconsistencies (\eg, inconsistencies in scene, entities, entity attributes,
entity numbers, entity interactions). Moreover, variations in caption length
can introduce inconsistencies at different levels of granularity as well. To
tackle these challenges, we design an adaptive evaluation framework, called
Hierarchical and Multi-Grained Inconsistency Evaluation (HMGIE), which can
provide multi-grained evaluations covering both accuracy and completeness for
various image-caption pairs. Specifically, the HMGIE framework is implemented
by three consecutive modules. Firstly, the semantic graph generation module
converts the image caption to a semantic graph for building a structural
representation of all involved semantic items. Then, the hierarchical
inconsistency evaluation module provides a progressive evaluation procedure
with a dynamic question-answer generation and evaluation strategy guided by the
semantic graph, producing a hierarchical inconsistency evaluation graph (HIEG).
Finally, the quantitative evaluation module calculates the accuracy and
completeness scores based on the HIEG, followed by a natural language
explanation about the detection results. Moreover, to verify the efficacy and
flexibility of the proposed framework on handling different image captioning
datasets, we construct MVTID, an image-caption dataset with diverse types and
granularities of inconsistencies. Extensive experiments on MVTID and other
benchmark datasets demonstrate the superior performance of the proposed HMGIE
to current state-of-the-art methods.

æè¦ï¼è¦è¦ºææ¬ä¸ä¸è´æ§ (VTI) è©ä¼°å¨æ¸çè¦è¦ºèªè¨è³æä¸­æ®æ¼èè³ééè¦çè§è²ãå¶ä¸»è¦ææ°æºèªæ¼ååæ¨é¡è³æéçç¨®é¡ç¹å¤ï¼å¶ä¸­å§å®¹çå·®ç°å¯è½æé æåç¨®ä¸ä¸è´æ§ï¼ä¾å¦å ´æ¯ãå¯¦é«ãå¯¦é«å±¬æ§ãå¯¦é«æ¸éãå¯¦é«äºåçä¸ä¸è´æ§ï¼ãæ­¤å¤ï¼æ¨é¡é·åº¦çè®åä¹æå¨ä¸åç²åº¦å±¤ç´å¼ç¼ä¸ä¸è´æ§ãçºäºæå°éäºææ°ï¼æåè¨­è¨äºä¸åèªé©æè©ä¼°æ¶æ§ï¼ç¨±çºéå±¤å¼å¤ç²åº¦ä¸ä¸è´æ§è©ä¼° (HMGIE)ï¼å®å¯ä»¥æä¾å¤ç²åº¦è©ä¼°ï¼æ¶µèåç¨®ååæ¨é¡å°çæºç¢ºæ§åå®æ´æ§ãå·é«ä¾èªªï¼HMGIE æ¶æ§æ¯ç±ä¸åé£çºæ¨¡çµå¯¦ä½çãé¦åï¼èªæåå½¢ç¢çæ¨¡çµå°ååæ¨é¡è½æçºèªæåå½¢ï¼ä»¥å»ºç«ææç¸éèªæé ç®ççµæ§åè¡¨ç¤ºãç¶å¾ï¼éå±¤å¼ä¸ä¸è´æ§è©ä¼°æ¨¡çµæä¾æ¼¸é²å¼è©ä¼°ç¨åºï¼ä¸¦æ¡ç¨ç±èªæåå½¢å¼å°çåæåé¡è§£ç­ç¢çåè©ä¼°ç­ç¥ï¼ç¢çéå±¤å¼ä¸ä¸è´æ§è©ä¼°åå½¢ (HIEG)ãæå¾ï¼éåè©ä¼°æ¨¡çµæ ¹æ HIEG è¨ç®æºç¢ºæ§åå®æ´æ§åæ¸ï¼æ¥èå°åµæ¸¬çµæé²è¡èªç¶èªè¨èªªæãæ­¤å¤ï¼çºäºé©è­ææåºçæ¶æ§å¨èçä¸åååæ¨é¡è³æéä¸çæè½åéæ´»æ§ï¼æåå»ºæ§äº MVTIDï¼ä¸åå·æä¸åé¡ååä¸ä¸è´æ§ç²åº¦çååæ¨é¡è³æéãå¨ MVTID åå¶ä»åºæºè³æéä¸çå¤§éå¯¦é©è­æäºææåºç HMGIE åªæ¼ç¶åæåé²çæ¹æ³ã

##### **KG-Retriever: Efficient Knowledge Indexing for Retrieval-Augmented Large Language Models**
2412.05547v1 by Weijie Chen, Ting Bai, Jinbo Su, Jian Luan, Wei Liu, Chuan Shi

Large language models with retrieval-augmented generation encounter a pivotal
challenge in intricate retrieval tasks, e.g., multi-hop question answering,
which requires the model to navigate across multiple documents and generate
comprehensive responses based on fragmented information. To tackle this
challenge, we introduce a novel Knowledge Graph-based RAG framework with a
hierarchical knowledge retriever, termed KG-Retriever. The retrieval indexing
in KG-Retriever is constructed on a hierarchical index graph that consists of a
knowledge graph layer and a collaborative document layer. The associative
nature of graph structures is fully utilized to strengthen intra-document and
inter-document connectivity, thereby fundamentally alleviating the information
fragmentation problem and meanwhile improving the retrieval efficiency in
cross-document retrieval of LLMs. With the coarse-grained collaborative
information from neighboring documents and concise information from the
knowledge graph, KG-Retriever achieves marked improvements on five public QA
datasets, showing the effectiveness and efficiency of our proposed RAG
framework.

æè¦ï¼å¤§åè¯­è¨æ¨¡åä½¿ç¨æ£ç´¢å¢å¼ºçæå¨å¤æçæ£ç´¢ä»»å¡ä¸­ä¼éå°å³é®ææï¼ä¾å¦å¤è·³é®é¢è§£ç­ï¼è¿è¦æ±æ¨¡åè·¨å¤ä¸ªææ¡£å¯¼èªå¹¶æ ¹æ®çæ®µä¿¡æ¯çæç»¼åååºãä¸ºäºåºå¯¹è¿ä¸ææï¼æä»¬å¼å¥äºä¸ä¸ªåºäºç¥è¯å¾è°±çæ°å RAG æ¡æ¶ï¼è¯¥æ¡æ¶å·æåå±ç¥è¯æ£ç´¢å¨ï¼ç§°ä¸º KG-RetrieverãKG-Retriever ä¸­çæ£ç´¢ç´¢å¼æå»ºå¨åå±ç´¢å¼å¾ä¸ï¼è¯¥å¾ç±ç¥è¯å¾è°±å±ååä½ææ¡£å±ç»æãå¾ç»æçå³èæ§è´¨è¢«ååå©ç¨ä»¥å å¼ºææ¡£ååææ¡£é´è¿æ¥æ§ï¼ä»èä»æ ¹æ¬ä¸ç¼è§£ä¿¡æ¯ç¢çåé®é¢ï¼åæ¶æé« LLM è·¨ææ¡£æ£ç´¢ä¸­çæ£ç´¢æçãéè¿æ¥èªç¸é»ææ¡£çç²ç²åº¦åä½ä¿¡æ¯åæ¥èªç¥è¯å¾è°±çç®æ´ä¿¡æ¯ï¼KG-Retriever å¨äºä¸ªå¬å±é®ç­æ°æ®éä¸åå¾äºæ¾çæ¹è¿ï¼æ¾ç¤ºäºæä»¬æåºç RAG æ¡æ¶çæææ§åæçã

##### **Knowledge Graphs are all you need: Leveraging KGs in Physics Question Answering**
2412.05453v1 by Krishnasai Addala, Kabir Dev Paul Baghel, Dhruv Jain, Chhavi Kirtani, Avinash Anand, Rajiv Ratn Shah

This study explores the effectiveness of using knowledge graphs generated by
large language models to decompose high school-level physics questions into
sub-questions. We introduce a pipeline aimed at enhancing model response
quality for Question Answering tasks. By employing LLMs to construct knowledge
graphs that capture the internal logic of the questions, these graphs then
guide the generation of subquestions. We hypothesize that this method yields
sub-questions that are more logically consistent with the original questions
compared to traditional decomposition techniques. Our results show that
sub-questions derived from knowledge graphs exhibit significantly improved
fidelity to the original question's logic. This approach not only enhances the
learning experience by providing clearer and more contextually appropriate
sub-questions but also highlights the potential of LLMs to transform
educational methodologies. The findings indicate a promising direction for
applying AI to improve the quality and effectiveness of educational content.

æè¦ï¼æ¬ç ç©¶æ¢è¨ä½¿ç¨å¤§åèªè¨æ¨¡åç¢ççç¥è­åè­å°é«ä¸­ç©çé¡ç®åè§£æå­åé¡çæææ§ãæåå¼é²ä¸åæ¨å¨å¢å¼·æ¨¡ååæåè³ªçç®¡éï¼ç¨æ¼åç­ä»»åãééä½¿ç¨å¤§åèªè¨æ¨¡åå»ºç«ç¥è­åè­ä»¥ææåé¡çå§é¨éè¼¯ï¼éäºåè­æ¥èå¼å°å­åé¡çç¢çãæååè¨­èå³çµ±åè§£æè¡ç¸æ¯ï¼æ­¤æ¹æ³ç¢ççå­åé¡èåå§åé¡å¨éè¼¯ä¸æ´ä¸è´ãæåççµæé¡¯ç¤ºï¼å¾ç¥è­åè­è¡ççå­åé¡å±ç¾åºé¡¯èæ¹åçä¿çåº¦ï¼ç¬¦ååå§åé¡çéè¼¯ãæ­¤æ¹æ³ä¸åééæä¾æ´æ¸æ°ä¸æ´ç¬¦åèçµ¡çå­åé¡ä¾å¢å¼·å­¸ç¿é«é©ï¼ä¹çªé¡¯å¤§åèªè¨æ¨¡åè½åæè²æ¹æ³çæ½åãéäºç¼ç¾æåºäºä¸åæåéçæ¹åï¼å¯å°äººå·¥æºæ§æç¨æ¼æåæè²å§å®¹çåè³ªèæææ§ã

##### **A Graph-Based Approach for Conversational AI-Driven Personal Memory Capture and Retrieval in a Real-world Application**
2412.05447v1 by Savini Kashmira, Jayanaka L. Dantanarayana, Joshua Brodsky, Ashish Mahendra, Yiping Kang, Krisztian Flautner, Lingjia Tang, Jason Mars

TOBU is a novel mobile application that captures and retrieves `personal
memories' (pictures/videos together with stories and context around those
moments) in a user-engaging AI-guided conversational approach. Our initial
prototype showed that existing retrieval techniques such as retrieval-augmented
generation (RAG) systems fall short due to their limitations in understanding
memory relationships, causing low recall, hallucination, and unsatisfactory
user experience. We design TOBUGraph, a novel graph-based retrieval approach.
During capturing, TOBUGraph leverages large language models (LLMs) to
automatically create a dynamic knowledge graph of memories, establishing
context and relationships of those memories. During retrieval, TOBUGraph
combines LLMs with the memory graph to achieve comprehensive recall through
graph traversal. Our evaluation using real user data demonstrates that
TOBUGraph outperforms multiple RAG implementations in both precision and
recall, significantly improving user experience through improved retrieval
accuracy and reduced hallucination.

æè¦ï¼TOBU æ¯ä¸æ¬¾æ°é¢çç§»å¨åºç¨ç¨åºï¼å®ä»¥ç¨æ·åä¸å¼ AI å¼å¯¼å¯¹è¯æ¹å¼ææåæ£ç´¢âä¸ªäººè®°å¿âï¼å¾ç/è§é¢ä»¥åè¿äºæ¶å»å¨å´çæäºåèæ¯ï¼ãæä»¬çåå§ååè¡¨æï¼ç°æçæ£ç´¢ææ¯ï¼ä¾å¦æ£ç´¢å¢å¼ºçæ (RAG) ç³»ç»ï¼ç±äºå®ä»¬å¨çè§£è®°å¿å³ç³»æ¹é¢çå±éæ§èè¡¨ç°ä¸ä½³ï¼ä»èå¯¼è´å¬åçä½ãåºç°å¹»è§åç¨æ·ä½éªä¸ä½³ãæä»¬è®¾è®¡äº TOBUGraphï¼ä¸ç§æ°é¢çåºäºå¾çæ£ç´¢æ¹æ³ãå¨æè·æé´ï¼TOBUGraph å©ç¨å¤§åè¯­è¨æ¨¡å (LLM) èªå¨åå»ºå¨æç¥è¯å¾è°±ï¼å»ºç«è¿äºè®°å¿çèæ¯åå³ç³»ãå¨æ£ç´¢æé´ï¼TOBUGraph å° LLM ä¸è®°å¿å¾è°±ç»åèµ·æ¥ï¼éè¿å¾éåå®ç°å¨é¢å¬åãæä»¬ä½¿ç¨çå®ç¨æ·æ°æ®è¿è¡çè¯ä¼°è¡¨æï¼TOBUGraph å¨ç²¾ç¡®åº¦åå¬åçæ¹é¢é½ä¼äºå¤ä¸ª RAG å®ç°ï¼éè¿æé«æ£ç´¢åç¡®åº¦ååå°å¹»è§ï¼æ¾èæ¹åäºç¨æ·ä½éªã

##### **KaLM: Knowledge-aligned Autoregressive Language Modeling via Dual-view Knowledge Graph Contrastive Learning**
2412.04948v1 by Peng Yu, Cheng Deng, Beiya Dai, Xinbing Wang, Ying Wen

Autoregressive large language models (LLMs) pre-trained by next token
prediction are inherently proficient in generative tasks. However, their
performance on knowledge-driven tasks such as factual knowledge querying
remains unsatisfactory. Knowledge graphs (KGs), as high-quality structured
knowledge bases, can provide reliable knowledge for LLMs, potentially
compensating for their knowledge deficiencies. Aligning LLMs with explicit,
structured knowledge from KGs has been a challenge; previous attempts either
failed to effectively align knowledge representations or compromised the
generative capabilities of LLMs, leading to less-than-optimal outcomes. This
paper proposes \textbf{KaLM}, a \textit{Knowledge-aligned Language Modeling}
approach, which fine-tunes autoregressive LLMs to align with KG knowledge via
the joint objective of explicit knowledge alignment and implicit knowledge
alignment. The explicit knowledge alignment objective aims to directly optimize
the knowledge representation of LLMs through dual-view knowledge graph
contrastive learning. The implicit knowledge alignment objective focuses on
incorporating textual patterns of knowledge into LLMs through triple completion
language modeling. Notably, our method achieves a significant performance boost
in evaluations of knowledge-driven tasks, specifically embedding-based
knowledge graph completion and generation-based knowledge graph question
answering.

æè¦ï¼<paragraph>èªååæ­¸å¤§åèªè¨æ¨¡å (LLM) ç¶ç±ä¸ä¸åç¬¦èé æ¸¬é åè¨ç·´ï¼æ¬è³ªä¸æé·çæå¼ä»»åãç¶èï¼å®åå¨ç¥è­é©åä»»åï¼ä¾å¦äºå¯¦ç¥è­æ¥è©¢ï¼ä¸çè¡¨ç¾ä»ä¸ç¡äººæãç¥è­åè­ (KG) ä½çºé«åè³ªççµæ§åç¥è­åº«ï¼å¯ä»¥çº LLM æä¾å¯é çç¥è­ï¼æ½å¨å°å½è£å¶ç¥è­ä¸è¶³ãå° LLM èä¾èª KG çæç¢ºçµæ§åç¥è­å°é½ä¸ç´æ¯ä¸é ææ°ï¼ååçåè©¦è¦ä¹ç¡æ³ææå°é½ç¥è­è¡¨ç¤ºï¼è¦ä¹æå®³ LLM ççæè½åï¼å°è´çµæä¸ç¡çæ³ãæ¬ææåºäºä¸å**KaLM**ï¼ä¸ç¨®**ç¥è­å°é½èªè¨å»ºæ¨¡**æ¹æ³ï¼å®å¾®èª¿èªååæ­¸ LLM ä»¥ééæç¢ºç¥è­å°é½åé±å¼ç¥è­å°é½çè¯åç®æ¨è KG ç¥è­å°é½ãæç¢ºç¥è­å°é½ç®æ¨æ¨å¨éééè¦åç¥è­åè­å°æ¯å­¸ç¿ç´æ¥æä½³å LLM çç¥è­è¡¨ç¤ºãé±å¼ç¥è­å°é½ç®æ¨å°æ³¨æ¼ééä¸åçµå®æèªè¨å»ºæ¨¡å°ç¥è­çæå­æ¨¡å¼ç´å¥ LLMãå¼å¾æ³¨æçæ¯ï¼æåçæ¨¡åå¨ç¥è­é©åä»»åçè©ä¼°ä¸­ç²å¾é¡¯èçæè½æåï¼ç¹å¥æ¯åºæ¼åµå¥çç¥è­åè­å®æååºæ¼çæçç¥è­åè­åé¡è§£ç­ã</paragraph>

##### **HyperGraphOS: A Meta Operating System for Science and Engineering**
2412.04923v1 by Antonello Ceravola, Frank Joublin, Ahmed R. Sadik, Bram Bolder, Juha-Pekka Tolvanen

This paper presents HyperGraphOS, an innovative Operating System designed for
the scientific and engineering domains. It combines model based engineering,
graph modeling, data containers, and computational tools, offering users a
dynamic workspace for creating and managing complex models represented as
customizable graphs. Using a web based architecture, HyperGraphOS requires only
a modern browser to organize knowledge, documents, and content into
interconnected models. Domain Specific Languages drive workspace navigation,
code generation, AI integration, and process organization.The platform models
function as both visual drawings and data structures, enabling dynamic
modifications and inspection, both interactively and programmatically.
HyperGraphOS was evaluated across various domains, including virtual avatars,
robotic task planning using Large Language Models, and meta modeling for
feature based code development. Results show significant improvements in
flexibility, data management, computation, and document handling.

æè¦ï¼æ¬ææåº HyperGraphOSï¼éæ¯ä¸ååµæ°çä½æ¥­ç³»çµ±ï¼å°çºç§å­¸åå·¥ç¨é åè¨­è¨ãå®çµåäºåºæ¼æ¨¡åçå·¥ç¨ãåå½¢å»ºæ¨¡ãè³æå®¹å¨åè¨ç®å·¥å·ï¼çºä½¿ç¨èæä¾ä¸ååæå·¥ä½ç©ºéï¼ç¨æ¼å»ºç«åç®¡çè¡¨ç¤ºçºå¯èªè¨åå½¢çè¤éæ¨¡åãHyperGraphOS ä½¿ç¨åºæ¼ Web çæ¶æ§ï¼åªéè¦ä¸åç¾ä»£çè¦½å¨å³å¯å°ç¥è­ãæä»¶åå§å®¹çµç¹æäºé£æ¨¡åãç¹å®é åèªè¨é©åå·¥ä½ç©ºéå°è¦½ãç¨å¼ç¢¼ç¢çãAI æ´ååæµç¨çµç¹ãå¹³å°æ¨¡ååæä½çºè¦è¦ºç¹ªååè³æçµæ§ï¼æ¯æ´åæä¿®æ¹åæª¢æ¥ï¼ç¡è«æ¯äºåå¼éæ¯ä»¥ç¨å¼æ¹å¼é²è¡ãHyperGraphOS å·²å¨åç¨®é åä¸­é²è¡è©ä¼°ï¼åæ¬èæ¬åèº«ãä½¿ç¨å¤§åèªè¨æ¨¡åçæ©å¨äººä»»åè¦åï¼ä»¥åç¨æ¼åºæ¼ç¹å¾µçç¨å¼ç¢¼éç¼çåå»ºæ¨¡ãçµæé¡¯ç¤ºåºéæ´»æ§ãè³æç®¡çãéç®åæä»¶èçæ¹é¢çé¡¯èæ¹é²ã

##### **Transformers Struggle to Learn to Search**
2412.04703v1 by Abulhair Saparov, Srushti Pawar, Shreyas Pimpalgaonkar, Nitish Joshi, Richard Yuanzhe Pang, Vishakh Padmakumar, Seyed Mehran Kazemi, Najoung Kim, He He

Search is an ability foundational in many important tasks, and recent studies
have shown that large language models (LLMs) struggle to perform search
robustly. It is unknown whether this inability is due to a lack of data,
insufficient model parameters, or fundamental limitations of the transformer
architecture. In this work, we use the foundational graph connectivity problem
as a testbed to generate effectively limitless high-coverage data to train
small transformers and test whether they can learn to perform search. We find
that, when given the right training distribution, the transformer is able to
learn to search.
  We analyze the algorithm that the transformer has learned through a novel
mechanistic interpretability technique that enables us to extract the
computation graph from the trained model. We find that for each vertex in the
input graph, transformers compute the set of vertices reachable from that
vertex. Each layer then progressively expands these sets, allowing the model to
search over a number of vertices exponential in the number of layers.
  However, we find that as the input graph size increases, the transformer has
greater difficulty in learning the task. This difficulty is not resolved even
as the number of parameters is increased, suggesting that increasing model
scale will not lead to robust search abilities. We also find that performing
search in-context (i.e., chain-of-thought) does not resolve this inability to
learn to search on larger graphs.

æè¦ï¼æå°æ¯è¨±å¤éè¦ä»»åä¸­çä¸é åºç¤è½åï¼æè¿çç ç©¶è¡¨æï¼å¤§åèªè¨æ¨¡å (LLM) é£ä»¥ç©©å¥å°å·è¡æå°ãç®åå°ä¸æ¸æ¥éç¨®ç¡è½æ¯æºæ¼è³æä¸è¶³ãæ¨¡ååæ¸ä¸è¶³ï¼éæ¯ Transformer æ¶æ§çåºæ¬éå¶ãå¨éé å·¥ä½ä¸­ï¼æåä½¿ç¨åºç¤åå½¢é£éæ§åé¡ä½çºæ¸¬è©¦å¹³å°ï¼çæææç¡éçé«è¦èçè³æï¼ä»¥è¨ç·´å°å Transformer ä¸¦æ¸¬è©¦å®åæ¯å¦è½å­¸æå·è¡æå°ãæåç¼ç¾ï¼ç¶çµ¦äºæ­£ç¢ºçè¨ç·´åä½æï¼Transformer è½å¤ å­¸ææå°ã
æåééä¸ç¨®æ°ç©çæ©å¶å¯è§£éæ§æè¡åæ Transformer å­¸å°çæ¼ç®æ³ï¼éè®æåè½å¤ å¾è¨ç·´å¥½çæ¨¡åä¸­æåéç®åå½¢ãæåç¼ç¾ï¼å°æ¼è¼¸å¥åå½¢ä¸­çæ¯åé é»ï¼Transformer æè¨ç®å¾è©²é é»å¯å°éçé é»éåãç¶å¾ï¼æ¯ä¸å±¤é½æéæ­¥æ´åéäºéåï¼è®æ¨¡åè½å¤ å¨èå±¤æ¸åææ¸éä¿çé é»æ¸ç®ä¸é²è¡æå°ã
ç¶èï¼æåç¼ç¾ï¼é¨èè¼¸å¥åå½¢å¤§å°çå¢å ï¼Transformer å¨å­¸ç¿ä»»åææéå°æ´å¤§çå°é£ãå³ä½¿å¢å åæ¸æ¸éï¼éç¨®å°é£ä¹ä¸æå¾å°è§£æ±ºï¼éè¡¨æå¢å æ¨¡åè¦æ¨¡ä¸æå¸¶ä¾ç©©å¥çæå°è½åãæåéç¼ç¾ï¼å¨ä¸ä¸æä¸­å·è¡æå°ï¼å³æèéï¼ç¡æ³è§£æ±ºéç¨®ç¡æ³å­¸ç¿å¨è¼å¤§åå½¢ä¸æå°çåé¡ã

##### **LLM-Align: Utilizing Large Language Models for Entity Alignment in Knowledge Graphs**
2412.04690v1 by Xuan Chen, Tong Lu, Zhichun Wang

Entity Alignment (EA) seeks to identify and match corresponding entities
across different Knowledge Graphs (KGs), playing a crucial role in knowledge
fusion and integration. Embedding-based entity alignment (EA) has recently
gained considerable attention, resulting in the emergence of many innovative
approaches. Initially, these approaches concentrated on learning entity
embeddings based on the structural features of knowledge graphs (KGs) as
defined by relation triples. Subsequent methods have integrated entities' names
and attributes as supplementary information to improve the embeddings used for
EA. However, existing methods lack a deep semantic understanding of entity
attributes and relations. In this paper, we propose a Large Language Model
(LLM) based Entity Alignment method, LLM-Align, which explores the
instruction-following and zero-shot capabilities of Large Language Models to
infer alignments of entities. LLM-Align uses heuristic methods to select
important attributes and relations of entities, and then feeds the selected
triples of entities to an LLM to infer the alignment results. To guarantee the
quality of alignment results, we design a multi-round voting mechanism to
mitigate the hallucination and positional bias issues that occur with LLMs.
Experiments on three EA datasets, demonstrating that our approach achieves
state-of-the-art performance compared to existing EA methods.

æè¦ï¼å¯¦é«å°é½ (EA) æ¨å¨è­å¥åå¹éä¸åç¥è­åè­ (KG) ä¸­å°æçå¯¦é«ï¼å¨ç¥è­èååæ´åä¸­æ®æ¼èè³ééè¦çè§è²ãåºæ¼åµå¥çå¯¦é«å°é½ (EA) è¿ä¾ååéæ³¨ï¼é²èå¬çåºè¨±å¤åµæ°çæ¹æ³ãæåï¼éäºæ¹æ³å°æ³¨æ¼æ ¹æç¥è­åè­ (KG) ççµæ§ç¹å¾µä¾å­¸ç¿å¯¦é«åµå¥ï¼éäºç¹å¾µç±éä¿ä¸åçµå®ç¾©ãå¾çºæ¹æ³å°å¯¦é«åç¨±åå±¬æ§æ´åçºè£åè³è¨ï¼ä»¥æ¹åç¨æ¼ EA çåµå¥ãç¶èï¼ç¾ææ¹æ³ç¼ºä¹å°å¯¦é«å±¬æ§åéä¿çæ·±å¥èªç¾©çè§£ãå¨æ¬æä¸­ï¼æåæåºäºä¸ç¨®åºæ¼å¤§åèªè¨æ¨¡å (LLM) çå¯¦é«å°é½æ¹æ³ LLM-Alignï¼è©²æ¹æ³æ¢ç´¢äºå¤§åèªè¨æ¨¡åçéµå¾ªæä»¤åé¶æ¬¡å­¸ç¿è½åï¼ä»¥æ¨è«å¯¦é«å°é½ãLLM-Align ä½¿ç¨åç¼å¼æ¹æ³ä¾é¸æå¯¦é«çéè¦å±¬æ§åéä¿ï¼ç¶å¾å°å¯¦é«çé¸å®ä¸åçµé¥å¥ LLM ä»¥æ¨è«å°é½çµæãçºäºä¿è­å°é½çµæçåè³ªï¼æåè¨­è¨äºä¸åå¤è¼ªæç¥¨æ©å¶ï¼ä»¥æ¸è¼ LLM ä¸­åºç¾çå¹»è¦ºåä½ç½®åå·®åé¡ãå¨ä¸å EA è³æéä¸çå¯¦é©è¡¨æï¼èç¾æç EA æ¹æ³ç¸æ¯ï¼æåçåæ³éå°äºæåé²çæè½ã

##### **Retrieval-Augmented Machine Translation with Unstructured Knowledge**
2412.04342v1 by Jiaan Wang, Fandong Meng, Yingxue Zhang, Jie Zhou

Retrieval-augmented generation (RAG) introduces additional information to
enhance large language models (LLMs). In machine translation (MT), previous
work typically retrieves in-context examples from paired MT corpora, or
domain-specific knowledge from knowledge graphs, to enhance models' MT ability.
However, a large amount of world knowledge is organized in unstructured
documents, and might not be fully paired across different languages. In this
paper, we study retrieval-augmented MT using unstructured documents.
Specifically, we build RAGtrans, the first benchmark to train and evaluate
LLMs' retrieval-augmented MT ability. RAGtrans contains 79K MT samples
collected via GPT-4o and human translators. Besides, documents from different
languages are also provided to supply the knowledge to these samples. Based on
RAGtrans, we further propose a multi-task training method to teach LLMs how to
use information from multilingual documents during their translation. The
method uses existing multilingual corpora to create auxiliary training
objectives without additional labeling requirements. Extensive experiments show
that the method improves LLMs by 1.58-3.09 BLEU and 1.00-2.03 COMET scores.

æè¦ï¼æª¢ç´¢å¢å¼·ç¢ç (RAG) æå¼å¥é¡å¤è³è¨ï¼ä»¥å¢å¼·å¤§åèªè¨æ¨¡å (LLM)ãå¨æ©å¨ç¿»è­¯ (MT) ä¸­ï¼ååçä½æ¥­éå¸¸æå¾éå°ç MT èªæåº«ä¸­æª¢ç´¢æå¢ç¯ä¾ï¼æå¾ç¥è­åè¡¨ä¸­æª¢ç´¢ç¹å®é åçç¥è­ï¼ä»¥å¢å¼·æ¨¡åç MT è½åãç¶èï¼å¤§éçä¸çç¥è­é½æ¯ä»¥éçµæ§åæä»¶çµç¹ï¼èä¸å¯è½ç¡æ³å®å¨éå°å°ä¸åçèªè¨ä¸­ãå¨æ¬æä¸­ï¼æåç ç©¶ä½¿ç¨éçµæ§åæä»¶é²è¡æª¢ç´¢å¢å¼· MTãå·é«ä¾èªªï¼æåå»ºç«äº RAGtransï¼éæ¯ç¬¬ä¸åç¨æ¼è¨ç·´åè©ä¼° LLM çæª¢ç´¢å¢å¼· MT è½åçåºæºãRAGtrans åå«éé GPT-4o åäººå·¥ç¿»è­¯äººå¡æ¶éç 79K å MT ç¯ä¾ãæ­¤å¤ï¼ä¹æä¾äºä¸åèªè¨çæä»¶ï¼ä»¥æä¾éäºç¯ä¾çç¥è­ãæ ¹æ RAGtransï¼æåé²ä¸æ­¥æåºäºä¸åå¤ä»»åè¨ç·´æ¹æ³ï¼ä»¥æå° LLM å¦ä½å¨ç¿»è­¯éç¨ä¸­ä½¿ç¨å¤èªè¨æä»¶çè³è¨ãè©²æ¹æ³ä½¿ç¨ç¾æçå¤èªè¨èªæåº«å»ºç«è¼å©è¨ç·´ç®æ¨ï¼èç¡éé¡å¤çæ¨è¨éæ±ãå»£æ³çå¯¦é©é¡¯ç¤ºï¼è©²æ¹æ³å° LLM ç BLEU åæ¸æé«äº 1.58-3.09ï¼COMET åæ¸æé«äº 1.00-2.03ã

##### **GRAF: Graph Retrieval Augmented by Facts for Legal Question Answering**
2412.04119v1 by Cristian-George CrÄciun, RÄzvan-Alexandru SmÄdu, Dumitru-Clementin Cercel, Mihaela-Claudia Cercel

Pre-trained Language Models (PLMs) have shown remarkable performances in
recent years, setting a new paradigm for NLP research and industry. The legal
domain has received some attention from the NLP community partly due to its
textual nature. Some tasks from this domain are represented by
question-answering (QA) tasks. This work explores the legal domain
Multiple-Choice QA (MCQA) for a low-resource language. The contribution of this
work is multi-fold. We first introduce JuRO, the first openly available
Romanian legal MCQA dataset, comprising three different examinations and a
number of 10,836 total questions. Along with this dataset, we introduce CROL,
an organized corpus of laws that has a total of 93 distinct documents with
their modifications from 763 time spans, that we leveraged in this work for
Information Retrieval (IR) techniques. Moreover, we are the first to propose
Law-RoG, a Knowledge Graph (KG) for the Romanian language, and this KG is
derived from the aforementioned corpus. Lastly, we propose a novel approach for
MCQA, Graph Retrieval Augmented by Facts (GRAF), which achieves competitive
results with generally accepted SOTA methods and even exceeds them in most
settings.

æè¦ï¼<paragraph>é è¨ç·´èªè¨æ¨¡å (PLM) å¨è¿å¹´ä¾å±ç¾åºåè¶çæè½ï¼çºèªç¶èªè¨èççç ç©¶åç¢æ¥­æ¨¹ç«äºæ°çå¸ç¯ãæ³å¾é åå çºå¶ææ¬æ§è³ªèåå°èªç¶èªè¨èçç¤¾ç¾¤çé¨åéæ³¨ãæ­¤é åä¸­çä¸äºä»»åç±åç­ (QA) ä»»åè¡¨ç¤ºãéé å·¥ä½æ¢ç´¢äºä½è³æºèªè¨çæ³å¾é åå¤éé¸æåç­ (MCQA)ãéé å·¥ä½çè²¢ç»æ¯å¤æ¹é¢çãæåé¦åä»ç´¹ JuROï¼éæ¯ç¬¬ä¸åå¬éçç¾é¦¬å°¼äºæ³å¾ MCQA è³æéï¼åå«ä¸æ¬¡ä¸åçèè©¦åç¸½å± 10,836 ååé¡ãé¤äºéåè³æéä¹å¤ï¼æåéä»ç´¹äº CROLï¼éæ¯ä¸åæçµç¹çæ³å¾èªæåº«ï¼ç¸½å±æ 93 åä¸åçæä»¶ï¼åå«äºä¾èª 763 åæéåéçä¿®æ¹ï¼æåå¨éåå·¥ä½ä¸­å©ç¨å®ä¾é²è¡è³è¨æª¢ç´¢ (IR) æè¡ãæ­¤å¤ï¼æåæ¯ç¬¬ä¸åæåº Law-RoG çäººï¼éæ¯ä¸åç¾é¦¬å°¼äºèªçç¥è­åè­ (KG)ï¼èéå KG æ¯å¾ä¸è¿°èªæåº«è¡ççãæå¾ï¼æåæåºäºä¸åæ°çå¤éé¸æåç­æ¹æ³ï¼ç±äºå¯¦å¢å¼·çåå½¢æª¢ç´¢ (GRAF)ï¼å®å¨ä¸è¬å¬èªç SOTA æ¹æ³ä¸­ç²å¾äºæç«¶ç­åççµæï¼çè³å¨å¤§å¤æ¸è¨­å®ä¸­é½è¶è¶äºå®åã</paragraph>

##### **MIND: Effective Incorrect Assignment Detection through a Multi-Modal Structure-Enhanced Language Model**
2412.03930v1 by Yunhe Pang, Bo Chen, Fanjin Zhang, Yanghui Rao, Jie Tang

The rapid growth of academic publications has exacerbated the issue of author
name ambiguity in online digital libraries. Despite advances in name
disambiguation algorithms, cumulative errors continue to undermine the
reliability of academic systems. It is estimated that over 10% paper-author
assignments are rectified when constructing the million-scale WhoIsWho
benchmark. Existing endeavors to detect incorrect assignments are either
semantic-based or graph-based approaches, which fall short of making full use
of the rich text attributes of papers and implicit structural features defined
via the co-occurrence of paper attributes. To this end, this paper introduces a
structure-enhanced language model that combines key structural features from
graph-based methods with fine-grained semantic features from rich paper
attributes to detect incorrect assignments. The proposed model is trained with
a highly effective multi-modal multi-turn instruction tuning framework, which
incorporates task-guided instruction tuning, text-attribute modality, and
structural modality. Experimental results demonstrate that our model
outperforms previous approaches, achieving top performance on the leaderboard
of KDD Cup 2024. Our code has been publicly available.

æè¦ï¼å­¸è¡åºçåçå¿«éæé·ï¼å åäºç·ä¸æ¸ä½åæ¸é¤¨ä¸­ä½èå§åæ­§ç¾©çåé¡ãåç®¡å§åæ¶æ­§æ¼ç®æ³æé²å±ï¼ç´¯ç©çé¯èª¤ä»æçºç ´å£å­¸è¡ç³»çµ±çå¯é æ§ãæä¼°è¨ï¼å¨å»ºæ§ç¾è¬è¦æ¨¡ç WhoIsWho åºæºæï¼è¶é 10% çè«æä½èææ´¾è¢«ä¿®æ­£ãç¾æçåµæ¸¬ä¸æ­£ç¢ºææ´¾çåªåï¼ä¸æ¯åºæ¼èªæçï¼å°±æ¯åºæ¼åçï¼ç¡æ³ååå©ç¨è«æè±å¯çæå­å±¬æ§åééè«æå±¬æ§å±ç¾å®ç¾©çé±å«çµæ§ç¹å¾µãçºæ­¤ï¼æ¬æä»ç´¹äºä¸åçµæ§å¢å¼·èªè¨æ¨¡åï¼å°åºæ¼åçæ¹æ³ä¸­çééµçµæ§ç¹å¾µèè±å¯è«æå±¬æ§ä¸­çç´°ç²åº¦èªç¾©ç¹å¾µç¸çµåï¼ä»¥åµæ¸¬ä¸æ­£ç¢ºçææ´¾ãææåºçæ¨¡åä½¿ç¨ä¸åé«æçå¤æ¨¡æå¤è¼ªæä»¤å¾®èª¿æ¶æ§é²è¡è¨ç·´ï¼å¶ä¸­åå«ä»»åå°åçæä»¤å¾®èª¿ãæå­å±¬æ§æ¨¡æåçµæ§æ¨¡æãå¯¦é©çµæè­æï¼æåçæ¨¡ååªæ¼ååçæ¨¡åï¼å¨ KDD Cup 2024 çæè¡æ¦ä¸åå¾æä½³æè½ãæåçç¨å¼ç¢¼å·²å¬éã

##### **How Good is ChatGPT in Giving Adaptive Guidance Using Knowledge Graphs in E-Learning Environments?**
2412.03856v1 by Patrick Ocheja, Brendan Flanagan, Yiling Dai, Hiroaki Ogata

E-learning environments are increasingly harnessing large language models
(LLMs) like GPT-3.5 and GPT-4 for tailored educational support. This study
introduces an approach that integrates dynamic knowledge graphs with LLMs to
offer nuanced student assistance. By evaluating past and ongoing student
interactions, the system identifies and appends the most salient learning
context to prompts directed at the LLM. Central to this method is the knowledge
graph's role in assessing a student's comprehension of topic prerequisites.
Depending on the categorized understanding (good, average, or poor), the LLM
adjusts its guidance, offering advanced assistance, foundational reviews, or
in-depth prerequisite explanations, respectively. Preliminary findings suggest
students could benefit from this tiered support, achieving enhanced
comprehension and improved task outcomes. However, several issues related to
potential errors arising from LLMs were identified, which can potentially
mislead students. This highlights the need for human intervention to mitigate
these risks. This research aims to advance AI-driven personalized learning
while acknowledging the limitations and potential pitfalls, thus guiding future
research in technology and data-driven education.

æè¦ï¼é»å­å­¸ç¿ç°å¢æ­£æ¥çå©ç¨å¤§åèªè¨æ¨¡å (LLM)ï¼ä¾å¦ GPT-3.5 å GPT-4ï¼æä¾éèº«æé çæè²æ¯æ´ãæ¬ç ç©¶æåºäºä¸ç¨®æ¹æ³ï¼å°åæç¥è­åè LLM æ´åï¼æä¾ç´°ç·»å¥å¾®çå­¸çåå©ãç³»çµ±æè©ä¼°éå»åæ­£å¨é²è¡çå­¸çäºåï¼æ¾åºä¸¦éå æé¡¯èçå­¸ç¿èçµ¡ï¼ä»¥æç¤º LLMãæ­¤æ¹æ³çæ ¸å¿å¨æ¼ç¥è­åå¨è©ä¼°å­¸çå°ä¸»é¡ååç¥è­ççè§£ç¨åº¦æ¹é¢ææ®æ¼çè§è²ãLLM ææ ¹æåé¡å¾ççè§£ç¨åº¦ï¼è¯å¥½ãæ®éæå·®ï¼èª¿æ´å¶æå°ï¼åå¥æä¾é²éåå©ãåºç¤åé¡§ææ·±å¥çååç¥è­èªªæãåæ­¥ç¼ç¾è¡¨æï¼å­¸çå¯ä»¥åçæ¼éç¨®åå±¤æ¯æ´ï¼éå°å¢å¼·ççè§£ååæ¹åçä»»åææãç¶èï¼å·²æ¾åºè LLM ç¢ççæ½å¨é¯èª¤ç¸éçå¹¾ååé¡ï¼éäºé¯èª¤å¯è½æèª¤å°å­¸çãéçªé¡¯äºäººé¡ä»å¥ä»¥éä½éäºé¢¨éªçå¿è¦æ§ãæ¬ç ç©¶æ¨å¨æ¨é² AI é©åçåäººåå­¸ç¿ï¼åææ¿èªéå¶åæ½å¨çé·é±ï¼å¾èæå°æªä¾å¨æè¡åè³æé©åæè²æ¹é¢çç ç©¶ã

##### **Synergizing LLMs and Knowledge Graphs: A Novel Approach to Software Repository-Related Question Answering**
2412.03815v1 by Samuel Abedu, SayedHassan Khatoonabadi, Emad Shihab

Software repositories contain valuable information for gaining insights into
their development process. However, extracting insights from these repository
data is time-consuming and requires technical expertise. While software
engineering chatbots have been developed to facilitate natural language
interactions with repositories, they struggle with understanding natural
language and accurately retrieving relevant data. This study aims to improve
the accuracy of LLM-based chatbots in answering repository-related questions by
augmenting them with knowledge graphs. We achieve this in a two-step approach;
(1) constructing a knowledge graph from the repository data and (2) synergizing
the knowledge graph with LLM to allow for the natural language questions and
answers. We curated a set of 20 questions with different complexities and
evaluated our approach on five popular open-source projects. Our approach
achieved an accuracy of 65%. We further investigated the limitations and
identified six key issues, with the majority relating to the reasoning
capability of the LLM. We experimented with a few-shot chain-of-thought
prompting to determine if it could enhance our approach. This technique
improved the overall accuracy to 84%. Our findings demonstrate the synergy
between LLMs and knowledge graphs as a viable solution for making repository
data accessible to both technical and non-technical stakeholders.

æè¦ï¼è»é«å²å­åº«åå«æå¹å¼çè³è¨ï¼å¯æ·±å¥äºè§£å¶éç¼æµç¨ãç¶èï¼å¾éäºå²å­åº«è³æä¸­æ·åè¦è§£æ¢èæåéè¦æè¡å°æ¥­ç¥è­ãåç®¡å·²éç¼åºè»é«å·¥ç¨èå¤©æ©å¨äººä¾ä¿é²èå²å­åº«çèªç¶èªè¨äºåï¼ä½å®åå¨çè§£èªç¶èªè¨åæºç¢ºæ·åç¸éè³ææ¹é¢ä»æå°é£ãæ¬ç ç©¶æ¨å¨ééç¥è­åè­æ´å LLM åºç¤èå¤©æ©å¨äººï¼ä»¥æé«å¶åç­å²å­åº«ç¸éåé¡çæºç¢ºæ§ãæåæ¡ç¨å©æ­¥é©æ¹æ³ä¾éææ­¤ç®æ¨ï¼(1) å¾å²å­åº«è³æå»ºæ§ç¥è­åè­ï¼ä»¥å (2) å°ç¥è­åè­è LLM çµåï¼ä»¥åè¨±èªç¶èªè¨åé¡åç­æ¡ãæåç­åäºä¸çµ 20 åå·æä¸åè¤éåº¦çåé¡ï¼ä¸¦éå°äºåç±éçéæºå°æ¡è©ä¼°æåçåæ³ãæåçåæ³éå°äº 65% çæºç¢ºåº¦ãæåé²ä¸æ­¥æ¢è¨äºéå¶ï¼ä¸¦æ¾åºå­åééµåé¡ï¼å¶ä¸­å¤§é¨åè LLM çæ¨çè½åæéãæåå¯¦é©äºå°æ¬¡æ¸çæèéæç¤ºï¼ä»¥ç¢ºå®å®æ¯å¦å¯ä»¥å¢å¼·æåçåæ³ãæ­¤æè¡å°æ´é«æºç¢ºåº¦æé«å° 84%ãæåçç ç©¶çµæè­æäº LLM åç¥è­åè­ä¹éçååææï¼ä½çºè®æè¡åéæè¡å©å®³éä¿äººè½å¤ å­åå²å­åº«è³æçå¯è¡è§£æ±ºæ¹æ¡ã

##### **Agent AI with LangGraph: A Modular Framework for Enhancing Machine Translation Using Large Language Models**
2412.03801v1 by Jialin Wang, Zhihua Duan

This paper explores the transformative role of Agent AI and LangGraph in
advancing the automation and effectiveness of machine translation (MT). Agents
are modular components designed to perform specific tasks, such as translating
between particular languages, with specializations like TranslateEnAgent,
TranslateFrenchAgent, and TranslateJpAgent for English, French, and Japanese
translations, respectively. These agents leverage the powerful semantic
capabilities of large language models (LLMs), such as GPT-4o, to ensure
accurate, contextually relevant translations while maintaining modularity,
scalability, and context retention.
  LangGraph, a graph-based framework built on LangChain, simplifies the
creation and management of these agents and their workflows. It supports
dynamic state management, enabling agents to maintain dialogue context and
automates complex workflows by linking agents and facilitating their
collaboration. With flexibility, open-source community support, and seamless
integration with LLMs, LangGraph empowers agents to deliver high-quality
translations.
  Together, Agent AI and LangGraph create a cohesive system where LangGraph
orchestrates agent interactions, ensuring that user inputs are analyzed,
routed, and processed efficiently. Experimental results demonstrate the
potential of this system to enhance multilingual translation accuracy and
scalability. By highlighting modular design and automated workflows, this paper
sets the stage for further innovations in intelligent machine translation
services.

æè¦ï¼æ¬ææ¢è¨äº Agent AI å LangGraph å¨æ¨åæ©å¨ç¿»è­¯ (MT) çèªåååæçæ¹é¢çè®é©æ§ä½ç¨ãAgent æ¯æ¨¡çµååä»¶ï¼æ¨å¨å·è¡ç¹å®ä»»åï¼ä¾å¦å¨ç¹å®èªè¨ä¹éç¿»è­¯ï¼ä¸¦å·æå°éé åï¼ä¾å¦ TranslateEnAgentãTranslateFrenchAgent å TranslateJpAgent åå¥ç¨æ¼è±æãæ³æåæ¥æçç¿»è­¯ãéäº Agent éç¨å¤§åèªè¨æ¨¡å (LLM) çå¼·å¤§èªç¾©åè½ï¼ä¾å¦ GPT-4oï¼ä»¥ç¢ºä¿æºç¢ºãèä¸ä¸æç¸éçç¿»è­¯ï¼åæä¿ææ¨¡çµåãå¯æ´åæ§åä¸ä¸æä¿çã
LangGraph æ¯å»ºæ§æ¼ LangChain ä¸çåå½¢åæ¡æ¶ï¼ç°¡åäºéäº Agent åå¶å·¥ä½æµç¨çå»ºç«åç®¡çãå®æ¯æ´åæçæç®¡çï¼è® Agent è½å¤ ç¶­è­·å°è©±å§å®¹ï¼ä¸¦ééé£çµ Agent åä¿é²å¶åä½ï¼èªååè¤éçå·¥ä½æµç¨ãLangGraph å·æéæ´»æ§ãéæ¾åå§ç¢¼ç¤¾ç¾¤æ¯æ´åè LLM ç¡ç¸«æ´åç­åªé»ï¼è® Agent è½å¤ æä¾é«åè³ªçç¿»è­¯ã
Agent AI å LangGraph å±åå»ºç«äºä¸åç·å¯çç³»çµ±ï¼å¶ä¸­ LangGraph ç·¨æ Agent äºåï¼ç¢ºä¿ä½¿ç¨èè¼¸å¥è¢«ææå°åæãè·¯ç±åèçãå¯¦é©çµæè­æäºéåç³»çµ±å¨æåå¤èªè¨ç¿»è­¯æºç¢ºæ§åå¯æ´åæ§æ¹é¢çæ½åãééå¼·èª¿æ¨¡çµåè¨­è¨åèªååå·¥ä½æµç¨ï¼æ¬æçºæºæ§åæ©å¨ç¿»è­¯æåçé²ä¸æ­¥åµæ°å¥ å®äºåºç¤ã

##### **Language Model Meets Prototypes: Towards Interpretable Text Classification Models through Prototypical Networks**
2412.03761v1 by Ximing Wen

Pretrained transformer-based Language Models (LMs) are well-known for their
ability to achieve significant improvement on NLP tasks, but their black-box
nature, which leads to a lack of interpretability, has been a major concern. My
dissertation focuses on developing intrinsically interpretable models when
using LMs as encoders while maintaining their superior performance via
prototypical networks. I initiated my research by investigating enhancements in
performance for interpretable models of sarcasm detection. My proposed approach
focuses on capturing sentiment incongruity to enhance accuracy while offering
instance-based explanations for the classification decisions. Later, I
developed a novel white-box multi-head graph attention-based prototype network
designed to explain the decisions of text classification models without
sacrificing the accuracy of the original black-box LMs. In addition, I am
working on extending the attention-based prototype network with contrastive
learning to redesign an interpretable graph neural network, aiming to enhance
both the interpretability and performance of the model in document
classification.

æè¦ï¼é åè¨ç·´å¥½çåºæ¼ Transformer çèªè¨æ¨¡å (LM) ä»¥å¶å¨ NLP ä»»åä¸­åå¾é¡¯èé²æ­¥çè½åèèåï¼ä½å®åçé»çæ§è³ªå°è´ç¼ºä¹å¯è§£éæ§ï¼ä¸ç´æ¯ä¸åä¸»è¦åé¡ãæçè«æéé»å¨æ¼å¨ä½¿ç¨ LM ä½çºç·¨ç¢¼å¨æéç¼å§å¨å¯è§£éçæ¨¡åï¼åæééååç¶²è·¯ç¶­æå¶åªç°çæè½ãæééç ç©¶è«·åºåµæ¸¬çå¯è§£éæ¨¡åçæè½æåä¾ååæçç ç©¶ãææåºçæ¹æ³å°æ³¨æ¼æææç·ä¸ä¸è´æ§ï¼ä»¥æé«æºç¢ºåº¦ï¼åæçºåé¡æ±ºç­æä¾åºæ¼å¯¦ä¾çè§£éãå¾ä¾ï¼æéç¼äºä¸åæ°ç©çç½çå¤é ­åå½¢æ³¨æåååç¶²è·¯ï¼æ¨å¨è§£éæå­åé¡æ¨¡åçæ±ºç­ï¼èä¸æç§ç²åå§é»ç LM çæºç¢ºåº¦ãæ­¤å¤ï¼ææ­£å¨åªåå°åºæ¼æ³¨æåçååç¶²è·¯èå°æ¯å­¸ç¿æ´å±ï¼ä»¥éæ°è¨­è¨ä¸åå¯è§£éçåå½¢ç¥ç¶ç¶²è·¯ï¼æ¨å¨å¢å¼·æ¨¡åå¨æä»¶åé¡ä¸­çå¯è§£éæ§åæè½ã

##### **How to Correctly do Semantic Backpropagation on Language-based Agentic Systems**
2412.03624v1 by Wenyi Wang, Hisham A. Alyahya, Dylan R. Ashley, Oleg Serikov, Dmitrii Khizbullin, Francesco Faccio, JÃ¼rgen Schmidhuber

Language-based agentic systems have shown great promise in recent years,
transitioning from solving small-scale research problems to being deployed in
challenging real-world tasks. However, optimizing these systems often requires
substantial manual labor. Recent studies have demonstrated that these systems
can be represented as computational graphs, enabling automatic optimization.
Despite these advancements, most current efforts in Graph-based Agentic System
Optimization (GASO) fail to properly assign feedback to the system's components
given feedback on the system's output. To address this challenge, we formalize
the concept of semantic backpropagation with semantic gradients -- a
generalization that aligns several key optimization techniques, including
reverse-mode automatic differentiation and the more recent TextGrad by
exploiting the relationship among nodes with a common successor. This serves as
a method for computing directional information about how changes to each
component of an agentic system might improve the system's output. To use these
gradients, we propose a method called semantic gradient descent which enables
us to solve GASO effectively. Our results on both BIG-Bench Hard and GSM8K show
that our approach outperforms existing state-of-the-art methods for solving
GASO problems. A detailed ablation study on the LIAR dataset demonstrates the
parsimonious nature of our method. A full copy of our implementation is
publicly available at https://github.com/HishamAlyahya/semantic_backprop

æè¦ï¼<paragraph>è¿å¹´ä¾ï¼åºæ¼èªè¨çä»£çç³»çµ±å±ç¾äºæ¥µå¤§çåæ¯ï¼
å¾è§£æ±ºå°è¦æ¨¡çç ç©¶åé¡ï¼è½è®çºé¨ç½²å¨
å·æææ°æ§ççå¯¦ä¸çä»»åä¸­ãç¶èï¼æä½³åéäºç³»çµ±éå¸¸éè¦
å¤§éçäººå·¥ååãæè¿çç ç©¶è¡¨æï¼éäºç³»çµ±
å¯ä»¥è¡¨ç¤ºçºè¨ç®åï¼å¯¦ç¾èªåæä½³åã
åç®¡æéäºé²å±ï¼ä½ç®åå¤§å¤æ¸åºæ¼åå½¢çä»£çç³»çµ±
æä½³å (GASO) çåªåï¼é½ç¡æ³é©ç¶å°å°åé¥åéçµ¦ç³»çµ±ççµæé¨å
çµ¦äºç³»çµ±è¼¸åºçåé¥ãçºäºæå°éä¸ææ°ï¼æåæ­£å¼åäº
èªç¾©ååå³æ­çæ¦å¿µï¼ä¸¦å¸¶æèªç¾©æ¢¯åº¦ââä¸ç¨®
æ¦æ¬ï¼å®çµåäºå¹¾ç¨®ééµçæä½³åæè¡ï¼åæ¬
ååæ¨¡å¼èªåå¾®ååæè¿ç TextGradï¼å©ç¨å·æå±åå¾ç¹¼èçç¯é»ä¹éçéä¿ãéå¯ä»¥ç¨ä½
ä¸ç¨®è¨ç®æ¹åè³è¨çæ¹æ³ï¼èªªæå¦ä½æ¹è®ä»£çç³»çµ±çæ¯å
çµæé¨åå¯è½ææ¹åç³»çµ±çè¼¸åºãçºäºä½¿ç¨éäº
æ¢¯åº¦ï¼æåæåºäºä¸ç¨®ç¨±çºèªç¾©æ¢¯åº¦ä¸éçæ¹æ³ï¼ä½¿æåè½å¤ 
ææå°è§£æ±º GASOãæåå¨ BIG-Bench Hard å GSM8K ä¸ççµæè¡¨æ
æåçåæ³åªæ¼è§£æ±º
GASO åé¡çç¾ææåé²æ¹æ³ãå¨ LIAR è³æéä¸é²è¡çè©³ç´°æ¶èç ç©¶è­æäº
æåæ¹æ³çç°¡ç´æ§ãæåçå¯¦ä½çå®æ´å¯æ¬å¬éæ¼ https://github.com/HishamAlyahya/semantic_backprop</paragraph>

##### **Enhancing Supply Chain Visibility with Generative AI: An Exploratory Case Study on Relationship Prediction in Knowledge Graphs**
2412.03390v1 by Ge Zheng, Alexandra Brintrup

A key stumbling block in effective supply chain risk management for companies
and policymakers is a lack of visibility on interdependent supply network
relationships. Relationship prediction, also called link prediction is an
emergent area of supply chain surveillance research that aims to increase the
visibility of supply chains using data-driven techniques. Existing methods have
been successful for predicting relationships but struggle to extract the
context in which these relationships are embedded - such as the products being
supplied or locations they are supplied from. Lack of context prevents
practitioners from distinguishing transactional relations from established
supply chain relations, hindering accurate estimations of risk. In this work,
we develop a new Generative Artificial Intelligence (Gen AI) enhanced machine
learning framework that leverages pre-trained language models as embedding
models combined with machine learning models to predict supply chain
relationships within knowledge graphs. By integrating Generative AI techniques,
our approach captures the nuanced semantic relationships between entities,
thereby improving supply chain visibility and facilitating more precise risk
management. Using data from a real case study, we show that GenAI-enhanced link
prediction surpasses all benchmarks, and demonstrate how GenAI models can be
explored and effectively used in supply chain risk management.

æè¦ï¼ä¾æéé¢¨éªç®¡çä¸­çä¸åééµéç¤å¨æ¼ä¼æ¥­åæ¿ç­å¶å®èç¼ºä¹å°ç¸äºä¾å­ä¾æç¶²è·¯éä¿çè½è¦åº¦ãéä¿é æ¸¬ï¼ä¹ç¨±çºé£çµé æ¸¬ï¼æ¯ä¾æéç£æ§ç ç©¶ä¸­ä¸åæ°èé åï¼æ¨å¨ä½¿ç¨è³æé©åæè¡æé«ä¾æéçè½è¦åº¦ãç¾ææ¹æ³å·²æåé æ¸¬éä¿ï¼ä½é£ä»¥æåéäºéä¿æåµå¥çèæ¯ï¼ä¾å¦æä¾æçç¢åæä¾æå°é»ãç¼ºä¹èæ¯æå¦¨ç¤å¾æ¥­èååäº¤æéä¿åæ¢å®çä¾æééä¿ï¼é²èé»ç¤é¢¨éªçæºç¢ºè©ä¼°ãå¨éé å·¥ä½ä¸­ï¼æåéç¼äºä¸åæ°ççæå¼äººå·¥æºæ§ (Gen AI) å¢å¼·æ©å¨å­¸ç¿æ¶æ§ï¼å®å©ç¨é åè¨ç·´çèªè¨æ¨¡åä½çºåµå¥æ¨¡åï¼ä¸¦çµåæ©å¨å­¸ç¿æ¨¡åä¾é æ¸¬ç¥è­åè­ä¸­çä¾æééä¿ãééæ´åçæå¼ AI æè¡ï¼æåçåæ³ææå°å¯¦é«ä¹éç´°å¾®çèªç¾©éä¿ï¼å¾èæé«ä¾æéè½è¦åº¦ä¸¦ä¿é²æ´ç²¾ç¢ºçé¢¨éªç®¡çãä½¿ç¨ä¾èªçå¯¦æ¡ä¾ç ç©¶çè³æï¼æåè­æ GenAI å¢å¼·é£çµé æ¸¬åªæ¼ææåºæºï¼ä¸¦å±ç¤ºå¦ä½æ¢ç´¢åææå°å¨ä¾æéé¢¨éªç®¡çä¸­ä½¿ç¨ GenAI æ¨¡åã

##### **CBEval: A framework for evaluating and interpreting cognitive biases in LLMs**
2412.03605v1 by Ammar Shaikh, Raj Abhijit Dandekar, Sreedath Panat, Rajat Dandekar

Rapid advancements in Large Language models (LLMs) has significantly enhanced
their reasoning capabilities. Despite improved performance on benchmarks, LLMs
exhibit notable gaps in their cognitive processes. Additionally, as reflections
of human-generated data, these models have the potential to inherit cognitive
biases, raising concerns about their reasoning and decision making
capabilities. In this paper we present a framework to interpret, understand and
provide insights into a host of cognitive biases in LLMs. Conducting our
research on frontier language models we're able to elucidate reasoning
limitations and biases, and provide reasoning behind these biases by
constructing influence graphs that identify phrases and words most responsible
for biases manifested in LLMs. We further investigate biases such as round
number bias and cognitive bias barrier revealed when noting framing effect in
language models.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) çå¿«éé²æ­¥é¡¯èå¢å¼·äºå®åçæ¨çè½åãåç®¡å¨åºæºæ¸¬è©¦ä¸­çè¡¨ç¾æææåï¼ä½ LLM å¨å¶èªç¥éç¨ä¸­ä»å­å¨é¡¯èçå·®è·ãæ­¤å¤ï¼ä½çºäººé¡çææ¸æçåæ ï¼éäºæ¨¡åæå¯è½ç¹¼æ¿èªç¥åå·®ï¼å¼ç¼äººåå°å¶æ¨çåæ±ºç­è½åçææãå¨æ¬æä¸­ï¼æåæåºäºä¸åæ¡æ¶ä¾è§£éãçè§£åæ´å¯ LLM ä¸­çä¸ç³»åèªç¥åå·®ãééå°åæ²¿èªè¨æ¨¡åé²è¡ç ç©¶ï¼æåè½å¤ é¡ææ¨çéå¶ååå·®ï¼ä¸¦ééæ§å»ºå½±é¿åä¾æä¾éäºåå·®èå¾çæ¨çï¼éäºå½±é¿åè­å¥åºå° LLM ä¸­è¡¨ç¾åºçåå·®è² ææå¤§è²¬ä»»çç­èªåè©å½ãæåé²ä¸æ­¥ç ç©¶äºå¨èªè¨æ¨¡åä¸­è¨»ææ¡æ¶ææææ­ç¤ºçåå·®ï¼ä¾å¦åæ¨äºå¥åå·®åèªç¥åå·®éç¤ã

##### **Hybrid-SQuAD: Hybrid Scholarly Question Answering Dataset**
2412.02788v2 by Tilahun Abedissa Taffa, Debayan Banerjee, Yaregal Assabie, Ricardo Usbeck

Existing Scholarly Question Answering (QA) methods typically target
homogeneous data sources, relying solely on either text or Knowledge Graphs
(KGs). However, scholarly information often spans heterogeneous sources,
necessitating the development of QA systems that integrate information from
multiple heterogeneous data sources. To address this challenge, we introduce
Hybrid-SQuAD (Hybrid Scholarly Question Answering Dataset), a novel large-scale
QA dataset designed to facilitate answering questions incorporating both text
and KG facts. The dataset consists of 10.5K question-answer pairs generated by
a large language model, leveraging the KGs DBLP and SemOpenAlex alongside
corresponding text from Wikipedia. In addition, we propose a RAG-based baseline
hybrid QA model, achieving an exact match score of 69.65 on the Hybrid-SQuAD
test set.

æè¦ï¼ç¾æçå­¸è¡åé¡è§£ç­ (QA) æ¹æ³éå¸¸éå°åè³ªè³æä¾æºï¼åä¾è³´ææ¬æç¥è­åè­ (KG)ãç¶èï¼å­¸è¡è³è¨éå¸¸æ©«è·¨ç°è³ªä¾æºï¼å æ­¤æå¿è¦éç¼æ´åä¾èªå¤åç°è³ªè³æä¾æºè³è¨ç QA ç³»çµ±ãçºäºæå°æ­¤ææ°ï¼æåå¼å¥äº Hybrid-SQuADï¼æ··åå­¸è¡åé¡è§£ç­è³æéï¼ï¼éæ¯ä¸åæ°ç©çå¤§è¦æ¨¡ QA è³æéï¼æ¨å¨ä¿é²åç­åå«ææ¬å KG äºå¯¦çåé¡ãè©²è³æéåå« 10.5K ååé¡ç­æ¡å°ï¼ç±å¤§åèªè¨æ¨¡åçæï¼å©ç¨ KGs DBLP å SemOpenAlex ä»¥åä¾èªç¶­åºç¾ç§çå°æææ¬ãæ­¤å¤ï¼æåæåºäºåºæ¼ RAG çåºç·æ··å QA æ¨¡åï¼å¨ Hybrid-SQuAD æ¸¬è©¦éä¸­å¯¦ç¾äº 69.65 çå®å¨å¹éåæ¸ã

##### **Characterizing Information Shared by Participants to Coding Challenges: The Case of Advent of Code**
2412.02290v1 by Francesco Cauteruccio, Enrico Corradini, Luca Virgili

Advent of Code (AoC from now on) is a popular coding challenge requiring to
solve programming puzzles for a variety of skill sets and levels. AoC follows
the advent calendar, therefore it is an annual challenge that lasts for 25
days. AoC participants usually post their solutions on social networks and
discuss them online. These challenges are interesting to study since they could
highlight the adoption of new tools, the evolution of the developer community,
or the technological requirements of well-known companies. For these reasons,
we first create a dataset of the 2019-2021 AoC editions containing the
discussion threads made on the subreddit {\tt /r/adventofcode}. Then, we
propose a model based on stream graphs to best study this context, where we
represent its most important actors through time: participants, comments, and
programming languages. Thanks to our model, we investigate user participation,
adoption of new programming languages during a challenge and between two of
them, and resiliency of programming languages based on a Stack Overflow survey.
We find that the top-used programming languages are almost the same in the
three years, pointing out their importance. Moreover, participants tend to keep
the same programming language for the whole challenge, while the ones attending
two AoCs usually change it in the next one. Finally, we observe interesting
results about the programming languages that are ``Popular'' or ``Loved''
according to the Stack Overflow survey. Firstly, these are the ones adopted for
the longest time in an AoC edition, thanks to which users have a high chance of
reaching the end of the challenge. Secondly, they are the most chosen when a
participant decides to change programming language during the same challenge.

æè¦ï¼éè¨ç¯å¯ç¢¼ï¼ä»¥ä¸ç°¡ç¨± AoCï¼æ¯ä¸é æµè¡çç·¨ç¢¼ææ°ï¼éè¦è§£æ±ºåç¨®æè½çµåç­ç´çç¨å¼è¨­è¨è¬é¡ãAoC éµå¾ªéè¨æï¼å æ­¤æ¯ä¸é çºæ 25 å¤©çå¹´åº¦ææ°ãAoC åèèéå¸¸å¨ç¤¾ç¾¤ç¶²è·¯ä¸ç¼å¸ä»åçè§£æ±ºæ¹æ¡ï¼ä¸¦å¨ç¶²è·¯ä¸è¨è«å®åãéäºææ°å¾æè¶£ï¼å çºå®åå¯ä»¥çªé¡¯æ°å·¥å·çæ¡ç¨ãéç¼äººå¡ç¤¾ç¾¤çæ¼é²ï¼æç¥åå¬å¸çæè¡éæ±ãåºæ¼éäºåå ï¼æåé¦åå»ºç«ä¸ååå«å¨ subreddit {\tt /r/adventofcode} ä¸é²è¡è¨è«ä¸²ç 2019-2021 å¹´ AoC çæ¬è³æéãç¶å¾ï¼æåæåºä¸ååºæ¼ä¸²æµåçæ¨¡åä¾æä½³ç ç©¶æ­¤èæ¯ï¼å¶ä¸­æåé¨èæéåç¾å¶æéè¦çåèèï¼åèèãçè¨åç¨å¼èªè¨ãééæåçæ¨¡åï¼æåèª¿æ¥ä½¿ç¨èåèåº¦ãå¨ææ°æéåå©èä¹éæ¡ç¨æ°ç¨å¼èªè¨çææ³ï¼ä»¥åæ ¹æ Stack Overflow èª¿æ¥å°ç¨å¼èªè¨çå¾©ååãæåç¼ç¾ä¸å¹´ä¾æå¸¸ç¨çç¨å¼èªè¨å¹¾ä¹ç¸åï¼æåºäºå®åçéè¦æ§ãæ­¤å¤ï¼åèèå¾åæ¼å¨æ´åææ°ä¸­ä½¿ç¨ç¸åçç¨å¼èªè¨ï¼èåå å©å AoC çåèèéå¸¸æå¨ä¸ä¸å ´æ¯è³½ä¸­æ´æç¨å¼èªè¨ãæå¾ï¼æåè§å¯å°éæ¼æ ¹æ Stack Overflow èª¿æ¥è¢«æ­¸é¡çºãç±éãæãåæãçç¨å¼èªè¨çä¸äºæè¶£çµæãé¦åï¼éäºç¨å¼èªè¨æ¯ AoC çæ¬ä¸­æ¡ç¨æä¹çç¨å¼èªè¨ï¼å æ­¤ä½¿ç¨èæå¾é«çæ©æå®æææ°ãå¶æ¬¡ï¼ç¶åèèæ±ºå®å¨åä¸åææ°ä¸­æ´æ¹ç¨å¼èªè¨æï¼å®åæ¯æå¸¸è¢«é¸ç¨çç¨å¼èªè¨ã

##### **A Neurosymbolic Fast and Slow Architecture for Graph Coloring**
2412.01752v1 by Vedant Khandelwal, Vishal Pallagani, Biplav Srivastava, Francesca Rossi

Constraint Satisfaction Problems (CSPs) present significant challenges to
artificial intelligence due to their intricate constraints and the necessity
for precise solutions. Existing symbolic solvers are often slow, and prior
research has shown that Large Language Models (LLMs) alone struggle with CSPs
because of their complexity. To bridge this gap, we build upon the existing
SOFAI architecture (or SOFAI-v1), which adapts Daniel Kahneman's ''Thinking,
Fast and Slow'' cognitive model to AI. Our enhanced architecture, SOFAI-v2,
integrates refined metacognitive governance mechanisms to improve adaptability
across complex domains, specifically tailored for solving CSPs like graph
coloring. SOFAI-v2 combines a fast System 1 (S1) based on LLMs with a
deliberative System 2 (S2) governed by a metacognition module. S1's initial
solutions, often limited by non-adherence to constraints, are enhanced through
metacognitive governance, which provides targeted feedback and examples to
adapt S1 to CSP requirements. If S1 fails to solve the problem, metacognition
strategically invokes S2, ensuring accurate and reliable solutions. With
empirical results, we show that SOFAI-v2 for graph coloring problems achieves a
16.98% increased success rate and is 32.42% faster than symbolic solvers.

æè¦ï¼ç´ææ»¿è¶³åé¡ (CSP) å çºå¶è¤éçç´æåå°ç²¾ç¢ºè§£çå¿è¦æ§ï¼å°äººå·¥æºæ§æåºäºéå¤§çææ°ãç¾æçç¬¦èæ±è§£å¨éå¸¸å¾æ¢ï¼èååçç ç©¶è¡¨æï¼å¤§åèªè¨æ¨¡å (LLM) å çºå¶è¤éæ§èç¡æ³å®ç¨èç CSPãçºäºå½è£éåå·®è·ï¼æåå»ºç«å¨ç¾æç SOFAI æ¶æ§ï¼æ SOFAI-v1ï¼ä¹ä¸ï¼å®å° Daniel Kahneman çãå¿«ææ¢æ³ãèªç¥æ¨¡åèª¿æ´çº AIãæåå¢å¼·çæ¶æ§ SOFAI-v2 æ´åäºç²¾ç·»çåèªç¥æ²»çæ©å¶ï¼ä»¥æé«è·¨è¤éé åçé©ææ§ï¼ç¹å¥æ¯éå°è§£æ±ºåå½¢èè²ç­ CSP èéèº«æé ãSOFAI-v2 çµåäºåºæ¼ LLM çå¿«éç³»çµ± 1 (S1) åç±åèªç¥æ¨¡çµç®¡æ§çå¯©æç³»çµ± 2 (S2)ãS1 çåå§è§£æ³éå¸¸åå°ä¸éµå®ç´æçéå¶ï¼ééåèªç¥æ²»çå¾ä»¥å¢å¼·ï¼æä¾æéå°æ§çåé¥åç¯ä¾ï¼ä»¥é©æ S1 ç CSP éæ±ãå¦æ S1 ç¡æ³è§£æ±ºåé¡ï¼åèªç¥æç­ç¥æ§å°å¼å« S2ï¼ç¢ºä¿æºç¢ºä¸å¯é çè§£æ³ãééç¶é©çµæï¼æåå±ç¤ºäºç¨æ¼åå½¢èè²åé¡ç SOFAI-v2 éå°äºæåçæé« 16.98%ï¼ä¸¦ä¸æ¯ç¬¦èæ±è§£å¨å¿« 32.42%ã

##### **Intelligent Spark Agents: A Modular LangGraph Framework for Scalable, Visualized, and Enhanced Big Data Machine Learning Workflows**
2412.01490v4 by Jialin Wang, Zhihua Duan

This paper presents a Spark-based modular LangGraph framework, designed to
enhance machine learning workflows through scalability, visualization, and
intelligent process optimization. At its core, the framework introduces Agent
AI, a pivotal innovation that leverages Spark's distributed computing
capabilities and integrates with LangGraph for workflow orchestration.
  Agent AI facilitates the automation of data preprocessing, feature
engineering, and model evaluation while dynamically interacting with data
through Spark SQL and DataFrame agents. Through LangGraph's graph-structured
workflows, the agents execute complex tasks, adapt to new inputs, and provide
real-time feedback, ensuring seamless decision-making and execution in
distributed environments. This system simplifies machine learning processes by
allowing users to visually design workflows, which are then converted into
Spark-compatible code for high-performance execution.
  The framework also incorporates large language models through the LangChain
ecosystem, enhancing interaction with unstructured data and enabling advanced
data analysis. Experimental evaluations demonstrate significant improvements in
process efficiency and scalability, as well as accurate data-driven
decision-making in diverse application scenarios.
  This paper emphasizes the integration of Spark with intelligent agents and
graph-based workflows to redefine the development and execution of machine
learning tasks in big data environments, paving the way for scalable and
user-friendly AI solutions.

æè¦ï¼<paragraph>æ¬ææåºäºä¸ååºæ¼ Spark çæ¨¡çµå LangGraph æ¡æ¶ï¼æ¨å¨ééå¯æ´åæ§ãå¯è¦ååæºæ§æµç¨æä½³åä¾æåæ©å¨å­¸ç¿å·¥ä½æµç¨ãå¨æ ¸å¿é¨åï¼æ­¤æ¡æ¶å¼å¥äº Agent AIï¼éé ééµåµæ°å©ç¨äº Spark çåæ£å¼éç®è½åï¼ä¸¦è LangGraph æ´åä»¥é²è¡å·¥ä½æµç¨ç·¨æã
  Agent AI ä¿é²äºè³æåèçãç¹å¾µå·¥ç¨åæ¨¡åè©ä¼°çèªååï¼åæéé Spark SQL å DataFrame ä»£çèè³æåæäºåãéé LangGraph çåå½¢çµæ§å·¥ä½æµç¨ï¼éäºä»£çå·è¡è¤éçä»»åãé©ææ°çè¼¸å¥ï¼ä¸¦æä¾å³æåé¥ï¼ç¢ºä¿å¨åæ£å¼ç°å¢ä¸­é²è¡ç¡ç¸«æ±ºç­å¶å®åå·è¡ãæ­¤ç³»çµ±ééåè¨±ä½¿ç¨èè¦è¦ºåè¨­è¨å·¥ä½æµç¨ï¼å¶å¾è½æçºç¸å®¹æ¼ Spark çç¨å¼ç¢¼ä»¥é²è¡é«æ§è½å·è¡ï¼ä¾ç°¡åæ©å¨å­¸ç¿æµç¨ã
  æ­¤æ¡æ¶ä¹éé LangChain çæç³»æ´åäºå¤§åèªè¨æ¨¡åï¼å¢å¼·äºèéçµæ§åè³æçäºåï¼ä¸¦åç¨äºé²éè³æåæãå¯¦é©è©ä¼°é¡¯ç¤ºï¼æµç¨æçåå¯æ´åæ§æé¡¯èæ¹åï¼èä¸å¨ä¸åçæç¨æå¢ä¸­é²è¡äºç²¾ç¢ºçè³æé©åæ±ºç­å¶å®ã
  æ¬æå¼·èª¿äº Spark èæºæ§ä»£çååºæ¼åå½¢çå·¥ä½æµç¨çæ´åï¼ä»¥éæ°å®ç¾©å¤§è³æç°å¢ä¸­æ©å¨å­¸ç¿ä»»åçéç¼åå·è¡ï¼çºå¯æ´åä¸ä½¿ç¨èååç AI è§£å³æ¹æ¡éªè·¯ã</paragraph>

##### **SelfPrompt: Autonomously Evaluating LLM Robustness via Domain-Constrained Knowledge Guidelines and Refined Adversarial Prompts**
2412.00765v1 by Aihua Pei, Zehua Yang, Shunan Zhu, Ruoxi Cheng, Ju Jia

Traditional methods for evaluating the robustness of large language models
(LLMs) often rely on standardized benchmarks, which can escalate costs and
limit evaluations across varied domains. This paper introduces a novel
framework designed to autonomously evaluate the robustness of LLMs by
incorporating refined adversarial prompts and domain-constrained knowledge
guidelines in the form of knowledge graphs. Our method systematically generates
descriptive sentences from domain-constrained knowledge graph triplets to
formulate adversarial prompts, enhancing the relevance and challenge of the
evaluation. These prompts, generated by the LLM itself and tailored to evaluate
its own robustness, undergo a rigorous filtering and refinement process,
ensuring that only those with high textual fluency and semantic fidelity are
used. This self-evaluation mechanism allows the LLM to evaluate its robustness
without the need for external benchmarks. We assess the effectiveness of our
framework through extensive testing on both proprietary models like ChatGPT and
open-source models such as Llama-3.1, Phi-3, and Mistral. Results confirm that
our approach not only reduces dependency on conventional data but also provides
a targeted and efficient means of evaluating LLM robustness in constrained
domains.

æè¦ï¼å³çµ±ç¨æ¼è©ä¼°å¤§åèªè¨æ¨¡å (LLM) ç©©å¥æ§çæ¹æ³éå¸¸ä¾è³´æ¨æºååºæºï¼éå¯è½æå¢å ææ¬ä¸¦éå¶è·¨ä¸åé åçè©ä¼°ãæ¬æä»ç´¹äºä¸åæ°ç©çæ¡æ¶ï¼æ¨å¨ééå¨ç¥è­åè­çå½¢å¼ä¸­ç´å¥ç²¾ç·»çå°ææç¤ºåé åç´æç¥è­æºåï¼ä¾èªä¸»è©ä¼° LLM çç©©å¥æ§ãæåçåæ³æ¯ç³»çµ±æ§å°å¾é åç´æç¥è­åè­ä¸åçµä¸­ç¢çæè¿°æ§å¥å­ï¼ä»¥å¶å®å°ææç¤ºï¼å¢å¼·è©ä¼°çç¸éæ§åææ°æ§ãéäºæç¤ºæ¯ç± LLM æ¬èº«ç¢çï¼ä¸¦éå°è©ä¼°å¶èªèº«çç©©å¥æ§èéèº«æé ï¼å®åæç¶æ­·å´æ ¼çéæ¿¾åç²¾çéç¨ï¼ç¢ºä¿åªæé£äºå·æé«åº¦ææ¬æµæ¢æ§åèªç¾©ä¿çæ§çæç¤ºææè¢«ä½¿ç¨ãéç¨®èªæè©ä¼°æ©å¶åè¨± LLM å¨ä¸éè¦å¤é¨åºæºçææ³ä¸è©ä¼°å¶ç©©å¥æ§ãæåééå°å°ææ¨¡åï¼ä¾å¦ ChatGPTï¼åéæºæ¨¡åï¼ä¾å¦ Llama-3.1ãPhi-3 å Mistralï¼é²è¡å»£æ³æ¸¬è©¦ï¼è©ä¼°æåæ¡æ¶çæææ§ãçµæè­å¯¦ï¼æåçåæ³ä¸åæ¸å°äºå°å³çµ±è³æçä¾è³´æ§ï¼éæä¾äºä¸ç¨®æéå°æ§åææçæ¹æ³ï¼å¯ä»¥å¨åéé åä¸­è©ä¼° LLM çç©©å¥æ§ã

##### **Leveraging LLM for Automated Ontology Extraction and Knowledge Graph Generation**
2412.00608v3 by Mohammad Sadeq Abolhasani, Rong Pan

Extracting relevant and structured knowledge from large, complex technical
documents within the Reliability and Maintainability (RAM) domain is
labor-intensive and prone to errors. Our work addresses this challenge by
presenting OntoKGen, a genuine pipeline for ontology extraction and Knowledge
Graph (KG) generation. OntoKGen leverages Large Language Models (LLMs) through
an interactive user interface guided by our adaptive iterative Chain of Thought
(CoT) algorithm to ensure that the ontology extraction process and, thus, KG
generation align with user-specific requirements. Although KG generation
follows a clear, structured path based on the confirmed ontology, there is no
universally correct ontology as it is inherently based on the user's
preferences. OntoKGen recommends an ontology grounded in best practices,
minimizing user effort and providing valuable insights that may have been
overlooked, all while giving the user complete control over the final ontology.
Having generated the KG based on the confirmed ontology, OntoKGen enables
seamless integration into schemeless, non-relational databases like Neo4j. This
integration allows for flexible storage and retrieval of knowledge from
diverse, unstructured sources, facilitating advanced querying, analysis, and
decision-making. Moreover, the generated KG serves as a robust foundation for
future integration into Retrieval Augmented Generation (RAG) systems, offering
enhanced capabilities for developing domain-specific intelligent applications.

æè¦ï¼å¾å¯é æ§åå¯ç¶­è­·æ§ (RAM) é åä¸­é¾å¤§ä¸è¤éçæè¡æä»¶ä¸­èåç¸éä¸çµæ§åçç¥è­ï¼æ¯ä¸é ååå¯éä¸å®¹æåºé¯çå·¥ä½ãæåçç ç©¶ééæåº OntoKGen ä¾è§£æ±ºéåææ°ï¼éæ¯ä¸åçæ­£çæ¬ä½èååç¥è­åè­ (KG) ç¢ççç®¡éãOntoKGen ééå¤§åèªè¨æ¨¡å (LLM) ä»¥åç±æåèªé©æçè¿­ä»£æèé (CoT) æ¼ç®æ³å¼å°çäºåå¼ä½¿ç¨èä»é¢ï¼ä¾ç¢ºä¿æ¬ä½èåçæµç¨ä»¥åç¥è­åè­çç¢çç¬¦åä½¿ç¨èç¹å®çéæ±ãéç¶ç¥è­åè­çç¢çæéµå¾ªä¸åæç¢ºä¸çµæ§åçè·¯å¾ï¼æ ¹æå·²ç¢ºèªçæ¬ä½ï¼ä½ä¸¦æ²æä¸åæ®éæ­£ç¢ºçæ¬ä½ï¼å çºå®æ¬è³ªä¸æ¯åºæ¼ä½¿ç¨èçåå¥½ãOntoKGen ææ¨è¦ä¸ååºæ¼æä½³å¯¦åçæ¬ä½ï¼å°ä½¿ç¨èçå·¥ä½ééå°æä½ï¼ä¸¦æä¾å¯è½è¢«å¿½ç¥çå¯¶è²´è¦è§£ï¼åæè®ä½¿ç¨èå®å¨æ§å¶æçµçæ¬ä½ãå¨æ ¹æå·²ç¢ºèªçæ¬ä½ç¢çç¥è­åè­å¾ï¼OntoKGen è½å¤ ç¡ç¸«æ´åå°å Neo4j éæ¨£çç¡æ¨¡å¼ãééä¿å¼è³æåº«ä¸­ãéç¨®æ´ååè¨±å¾å¤æ¨£ä¸éçµæ§åçä¾æºä¸­éæ´»å°å²å­åæ·åç¥è­ï¼ä¿é²é²éçæ¥è©¢ãåæåæ±ºç­å¶å®ãæ­¤å¤ï¼ç¢ççç¥è­åè­å¯ä½çºæªä¾æ´åå°æª¢ç´¢æ´å¢çæ (RAG) ç³»çµ±ä¸­çç©©åºåºç¤ï¼æä¾éç¼ç¹å®é åæºæ§åæç¨ç¨å¼çé²éåè½ã

##### **Opus: A Large Work Model for Complex Workflow Generation**
2412.00573v2 by ThÃ©o Fagnoni, Bellinda Mesbah, Mahsun Altin, Phillip Kingston

This paper introduces Opus, a novel framework for generating and optimizing
Workflows tailored to complex Business Process Outsourcing (BPO) use cases,
focusing on cost reduction and quality enhancement while adhering to
established industry processes and operational constraints. Our approach
generates executable Workflows from Intention, defined as the alignment of
Client Input, Client Output, and Process Context. These Workflows are
represented as Directed Acyclic Graphs (DAGs), with nodes as Tasks consisting
of sequences of executable Instructions, including tools and human expert
reviews. We adopt a two-phase methodology: Workflow Generation and Workflow
Optimization. In the Generation phase, Workflows are generated using a Large
Work Model (LWM) informed by a Work Knowledge Graph (WKG) that encodes
domain-specific procedural and operational knowledge. In the Optimization
phase, Workflows are transformed into Workflow Graphs (WFGs), where optimal
Workflows are determined through path optimization. Our experiments demonstrate
that state-of-the-art Large Language Models (LLMs) face challenges in reliably
retrieving detailed process data as well as generating industry-compliant
workflows. The key contributions of this paper include integrating a Work
Knowledge Graph (WKG) into a Large Work Model (LWM) to enable the generation of
context-aware, semantically aligned, structured and auditable Workflows. It
further introduces a two-phase approach that combines Workflow Generation from
Intention with graph-based Workflow Optimization. Finally, we present Opus
Alpha 1 Large and Opus Alpha 1 Small that outperform state-of-the-art LLMs by
38% and 29% respectively in Workflow Generation for a Medical Coding use case.

æè¦ï¼éç¯è«æä»ç´¹äº Opusï¼ä¸åç¨æ¼ç¢çåæä½³åå·¥ä½æµç¨çæ°ç©æ¶æ§ï¼å°çºè¤éçæ¥­åæµç¨å¤å (BPO) ä½¿ç¨æ¡ä¾éèº«æé ï¼éé»å¨æ¼éä½ææ¬åæååè³ªï¼åæéµå®æ¢å®çç¢æ¥­æµç¨åçééå¶ãæåçåæ³æ ¹ææåç¢çå¯å·è¡çå·¥ä½æµç¨ï¼æåå®ç¾©çºå®¢æ¶è¼¸å¥ãå®¢æ¶è¼¸åºåæµç¨èæ¯çå°é½ãéäºå·¥ä½æµç¨è¡¨ç¤ºçºæåç¡ç°å (DAG)ï¼ç¯é»çºåå«å¯å·è¡æä»¤åºåçä»»åï¼åæ¬å·¥å·åäººé¡å°å®¶çå¯©æ¥ãæåæ¡ç¨å©éæ®µæ¹æ³ï¼å·¥ä½æµç¨ç¢çåå·¥ä½æµç¨æä½³åãå¨ç¢çéæ®µï¼å·¥ä½æµç¨ä½¿ç¨å¤§åå·¥ä½æ¨¡å (LWM) ç¢çï¼è©²æ¨¡åç±ç·¨ç¢¼ç¹å®é åç¨åºåéä½ç¥è­çå·¥ä½ç¥è­å (WKG) æä¾è³è¨ãå¨æä½³åéæ®µï¼å·¥ä½æµç¨è½æçºå·¥ä½æµç¨å (WFG)ï¼å¶ä¸­ééè·¯å¾æä½³åä¾ç¢ºå®æä½³å·¥ä½æµç¨ãæåçå¯¦é©è¡¨æï¼æåé²çå¤§åèªè¨æ¨¡å (LLM) å¨å¯é å°æ·åè©³ç´°çæµç¨è³æä»¥åç¢çç¬¦åç¢æ¥­è¦ç¯çå·¥ä½æµç¨æ¹é¢é¢è¨ææ°ãéç¯è«æçä¸»è¦è²¢ç»åæ¬å°å·¥ä½ç¥è­å (WKG) æ´åå°å¤§åå·¥ä½æ¨¡å (LWM) ä¸­ï¼ä»¥ç¢çå·åæå¢æç¥ãèªç¾©å°é½ãçµæ§ååå¯ç¨½æ ¸çå·¥ä½æµç¨ãå®é²ä¸æ­¥ä»ç´¹äºä¸ç¨®å©éæ®µæ¹æ³ï¼å°åºæ¼æåçå·¥ä½æµç¨ç¢çèåºæ¼åå½¢çå·¥ä½æµç¨æä½³åç¸çµåãæå¾ï¼æåå±ç¤ºäº Opus Alpha 1 Large å Opus Alpha 1 Smallï¼å®åå¨é«çç·¨ç¢¼ä½¿ç¨æ¡ä¾ä¸­åå¥æ¯æåé²ç LLM å¨å·¥ä½æµç¨ç¢çæ¹é¢é«åº 38% å 29%ã

##### **Node Importance Estimation Leveraging LLMs for Semantic Augmentation in Knowledge Graphs**
2412.00478v1 by Xinyu Lin, Tianyu Zhang, Chengbin Hou, Jinbao Wang, Jianye Xue, Hairong Lv

Node Importance Estimation (NIE) is a task that quantifies the importance of
node in a graph. Recent research has investigated to exploit various
information from Knowledge Graphs (KGs) to estimate node importance scores.
However, the semantic information in KGs could be insufficient, missing, and
inaccurate, which would limit the performance of existing NIE models. To
address these issues, we leverage Large Language Models (LLMs) for semantic
augmentation thanks to the LLMs' extra knowledge and ability of integrating
knowledge from both LLMs and KGs. To this end, we propose the LLMs Empowered
Node Importance Estimation (LENIE) method to enhance the semantic information
in KGs for better supporting NIE tasks. To our best knowledge, this is the
first work incorporating LLMs into NIE. Specifically, LENIE employs a novel
clustering-based triplet sampling strategy to extract diverse knowledge of a
node sampled from the given KG. After that, LENIE adopts the node-specific
adaptive prompts to integrate the sampled triplets and the original node
descriptions, which are then fed into LLMs for generating richer and more
precise augmented node descriptions. These augmented descriptions finally
initialize node embeddings for boosting the downstream NIE model performance.
Extensive experiments demonstrate LENIE's effectiveness in addressing semantic
deficiencies in KGs, enabling more informative semantic augmentation and
enhancing existing NIE models to achieve the state-of-the-art performance. The
source code of LENIE is freely available at
\url{https://github.com/XinyuLin-FZ/LENIE}.

æè¦ï¼ç¯é»éè¦æ§ä¼°è¨ (NIE) æ¯ä¸é éååä¸­ç¯é»éè¦æ§çä»»åãæè¿çç ç©¶å·²èª¿æ¥å©ç¨ç¥è­åè­ (KG) ä¸­çåç¨®è³è¨ä¾ä¼°è¨ç¯é»éè¦æ§åæ¸ãç¶èï¼KG ä¸­çèªç¾©è³è¨å¯è½ä¸è¶³ãéºå¤±ä¸ä¸æºç¢ºï¼éå°éå¶ç¾æ NIE æ¨¡åçæè½ãçºäºè§£æ±ºéäºåé¡ï¼æåå©ç¨å¤§åèªè¨æ¨¡å (LLM) é²è¡èªç¾©å¢å¼·ï¼éè¦æ­¸åæ¼ LLM çé¡å¤ç¥è­åæ´å LLM å KG ä¸­ç¥è­çè½åãçºæ­¤ï¼æåæåº LLM å¼·åç¯é»éè¦æ§ä¼°è¨ (LENIE) æ¹æ³ï¼ä»¥å¢å¼· KG ä¸­çèªç¾©è³è¨ï¼ä»¥ä¾¿æ´å¥½å°æ¯æ´ NIE ä»»åãææåæç¥ï¼éæ¯å° LLM ç´å¥ NIE çç¬¬ä¸é å·¥ä½ãå·é«ä¾èªªï¼LENIE æ¡ç¨æ°ç©çåºæ¼ç¾¤éçä¸åçµåæ¨£ç­ç¥ï¼ä»¥èåå¾çµ¦å® KG åæ¨£çç¯é»çå¤åç¥è­ãå¨é£ä¹å¾ï¼LENIE æ¡ç¨ç¹å®æ¼ç¯é»çèªé©ææç¤ºï¼ä»¥æ´ååæ¨£çä¸åçµååå§ç¯é»æè¿°ï¼ç¶å¾å°å®åè¼¸å¥ LLM ä»¥ç¢çæ´è±å¯ä¸æ´ç²¾ç¢ºçå¢å¼·ç¯é»æè¿°ãéäºå¢å¼·çæè¿°æçµåå§åç¯é»åµå¥ï¼ä»¥æåä¸æ¸¸ NIE æ¨¡åæè½ãå»£æ³çå¯¦é©è­æäº LENIE å¨è§£æ±º KG ä¸­çèªç¾©ç¼ºé·æ¹é¢çæææ§ï¼å¯¦ç¾æ´å¤è³è¨æ§çèªç¾©å¢å¼·ï¼ä¸¦å¢å¼·ç¾æç NIE æ¨¡åä»¥éææåé²çæè½ãLENIE çåå§ç¨å¼ç¢¼å¯æ¼\url{https://github.com/XinyuLin-FZ/LENIE} åè²»åå¾ã

##### **An AI-Driven Data Mesh Architecture Enhancing Decision-Making in Infrastructure Construction and Public Procurement**
2412.00224v1 by Saurabh Mishra, Mahendra Shinde, Aniket Yadav, Bilal Ayyub, Anand Rao

Infrastructure construction, often dubbed an "industry of industries," is
closely linked with government spending and public procurement, offering
significant opportunities for improved efficiency and productivity through
better transparency and information access. By leveraging these opportunities,
we can achieve notable gains in productivity, cost savings, and broader
economic benefits. Our approach introduces an integrated software ecosystem
utilizing Data Mesh and Service Mesh architectures. This system includes the
largest training dataset for infrastructure and procurement, encompassing over
100 billion tokens, scientific publications, activities, and risk data, all
structured by a systematic AI framework. Supported by a Knowledge Graph linked
to domain-specific multi-agent tasks and Q&A capabilities, our platform
standardizes and ingests diverse data sources, transforming them into
structured knowledge. Leveraging large language models (LLMs) and automation,
our system revolutionizes data structuring and knowledge creation, aiding
decision-making in early-stage project planning, detailed research, market
trend analysis, and qualitative assessments. Its web-scalable architecture
delivers domain-curated information, enabling AI agents to facilitate reasoning
and manage uncertainties, while preparing for future expansions with
specialized agents targeting particular challenges. This integration of AI with
domain expertise not only boosts efficiency and decision-making in construction
and infrastructure but also establishes a framework for enhancing government
efficiency and accelerating the transition of traditional industries to digital
workflows. This work is poised to significantly influence AI-driven initiatives
in this sector and guide best practices in AI Operations.

æè¦ï¼åºç¤å»ºè¨­å»ºè¨­ï¼å¸¸è¢«ç¨±çºãç¢æ¥­ä¸­çç¢æ¥­ãï¼èæ¿åºæ¯åºåå¬å±æ¡è³¼æ¯æ¯ç¸éï¼ééæåéæåº¦åè³è¨åå¾ï¼è½å¤§å¹æåæçåçç¢åãééåç¨éäºæ©æï¼æåè½å¨çç¢åãææ¬ç¯çåæ´å»£æ³çç¶æ¿æçä¸ç²å¾é¡¯èçæ¶çãæåçåæ³å¼é²ä¸åæ´åå¼è»é«çæç³»ï¼å©ç¨è³æç¶²æ ¼åæåç¶²æ ¼æ¶æ§ãéåç³»çµ±åå«åºç¤å»ºè¨­åæ¡è³¼æå¤§çè¨ç·´è³æéï¼æ¶µèè¶é 1000 ååç¬¦èãç§å­¸åºçåãæ´»ååé¢¨éªè³æï¼ææè³æé½ä»¥ç³»çµ±åç AI æ¶æ§é²è¡çµæ§åãæåçå¹³å°ç±é£çµå°ç¹å®é åçå¤éä»£çäººä»»åååç­åè½çç¥è­åè­æä¾æ¯æ´ï¼æ¨æºåä¸¦å¯å¥ä¸åçè³æä¾æºï¼å°å¶è½æçºçµæ§åçç¥è­ãæåçç³»çµ±å©ç¨å¤§èªè¨æ¨¡å (LLM) åèªååï¼å¾¹åºæ¹é©è³æçµæ§ååç¥è­å»ºç«ï¼åå©å¨æ©æéæ®µçå°æ¡è¦åãè©³ç´°ç ç©¶ãå¸å ´è¶¨å¢åæåå®æ§è©ä¼°ä¸­é²è¡æ±ºç­å¶å®ãå¶å¯æ´åè³ç¶²è·¯è¦æ¨¡çæ¶æ§æä¾é åç­å±çè³è¨ï¼è® AI ä»£çäººè½å¤ ä¿é²æ¨çåç®¡çä¸ç¢ºå®æ§ï¼åææºåå¥½ä»¥å°éä»£çäººå æç¹å®ææ°ï¼é²è¡æªä¾çæ´åãéç¨®å° AI èé åå°æ¥­ç¥è­æ´åçæ¹å¼ï¼ä¸åæåå»ºè¨­ååºç¤å»ºè¨­çæçåæ±ºç­å¶å®ï¼ä¹å»ºç«äºä¸åæ¶æ§ï¼ä»¥æåæ¿åºæçä¸¦å éå³çµ±ç¢æ¥­è½åè³æ¸ä½å·¥ä½æµç¨ãéé å·¥ä½æºåå°éåé¨éç AI é©åè¨ç«ç¢çéå¤§å½±é¿ï¼ä¸¦å¼å° AI ä½æ¥­çæä½³å¯¦åã

##### **PerLA: Perceptive 3D Language Assistant**
2411.19774v1 by Guofeng Mei, Wei Lin, Luigi Riz, Yujiao Wu, Fabio Poiesi, Yiming Wang

Enabling Large Language Models (LLMs) to understand the 3D physical world is
an emerging yet challenging research direction. Current strategies for
processing point clouds typically downsample the scene or divide it into
smaller parts for separate analysis. However, both approaches risk losing key
local details or global contextual information. In this paper, we introduce
PerLA, a 3D language assistant designed to be more perceptive to both details
and context, making visual representations more informative for the LLM. PerLA
captures high-resolution (local) details in parallel from different point cloud
areas and integrates them with (global) context obtained from a
lower-resolution whole point cloud. We present a novel algorithm that preserves
point cloud locality through the Hilbert curve and effectively aggregates
local-to-global information via cross-attention and a graph neural network.
Lastly, we introduce a novel loss for local representation consensus to promote
training stability. PerLA outperforms state-of-the-art 3D language assistants,
with gains of up to +1.34 CiDEr on ScanQA for question answering, and +4.22 on
ScanRefer and +3.88 on Nr3D for dense
captioning.\url{https://gfmei.github.io/PerLA/}

æè¦ï¼è®å¤§åèªè¨æ¨¡å (LLM) çè§£ 3D ç©çä¸çæ¯ä¸åæ°èä½å·æææ°æ§çç ç©¶æ¹åãç¶åèçé»é²çç­ç¥éå¸¸æå°å ´æ¯é²è¡éæ¡æ¨£æå°å¶åçºæ´å°çé¨åä»¥é²è¡å®ç¨åæãç¶èï¼éå©ç¨®æ¹æ³é½æå¯è½éºå¤±ééµçå±é¨ç´°ç¯æå¨å±èæ¯è³è¨ãå¨æ¬æä¸­ï¼æåä»ç´¹äº PerLAï¼éæ¯ä¸å 3D èªè¨å©çï¼æ¨å¨æ´æé³å°æç¥ç´°ç¯åèæ¯ï¼è®è¦è¦ºè¡¨ç¾å° LLM æ´æè³è¨æ§ãPerLA å¾ä¸åçé»é²ååä¸¦è¡æ·åé«è§£æåº¦ï¼å±é¨ï¼ç´°ç¯ï¼ä¸¦å°å¶èå¾ä½è§£æåº¦å¨é»é²ä¸­ç²å¾çï¼å¨å±ï¼èæ¯æ´åå¨ä¸èµ·ãæåæåºäºä¸ç¨®æ°æ¼ç®æ³ï¼ééå¸ç¾ä¼¯ç¹æ²ç·ä¿çé»é²å±é¨æ§ï¼ä¸¦ééäº¤åæ³¨æåååå½¢ç¥ç¶ç¶²è·¯ææå°å¯ç¸½å±é¨å°å¨å±è³è¨ãæå¾ï¼æåå¼å¥äºä¸åæ°çæå¤±å½æ¸ï¼ç¨æ¼å±é¨è¡¨ç¤ºå±è­ï¼ä»¥ä¿é²è¨ç·´ç©©å®æ§ãPerLA åªæ¼æåé²ç 3D èªè¨å©çï¼å¨ ScanQA ä¸åç­ç²å¾é«é +1.34 CiDEr çå¢çï¼å¨ ScanRefer ä¸ç²å¾ +4.22ï¼å¨ Nr3D ä¸ç²å¾ +3.88 çå¯éæ¨é¡ã\url{https://gfmei.github.io/PerLA/}

##### **Knowledge Management for Automobile Failure Analysis Using Graph RAG**
2411.19539v1 by Yuta Ojima, Hiroki Sakaji, Tadashi Nakamura, Hiroaki Sakata, Kazuya Seki, Yuu Teshigawara, Masami Yamashita, Kazuhiro Aoyama

This paper presents a knowledge management system for automobile failure
analysis using retrieval-augmented generation (RAG) with large language models
(LLMs) and knowledge graphs (KGs). In the automotive industry, there is a
growing demand for knowledge transfer of failure analysis from experienced
engineers to young engineers. However, failure events are phenomena that occur
in a chain reaction, making them difficult for beginners to analyze them. While
knowledge graphs, which can describe semantic relationships and structure
information is effective in representing failure events, due to their
capability of representing the relationships between components, there is much
information in KGs, so it is challenging for young engineers to extract and
understand sub-graphs from the KG. On the other hand, there is increasing
interest in the use of Graph RAG, a type of RAG that combines LLMs and KGs for
knowledge management. However, when using the current Graph RAG framework with
an existing knowledge graph for automobile failures, several issues arise
because it is difficult to generate executable queries for a knowledge graph
database which is not constructed by LLMs. To address this, we focused on
optimizing the Graph RAG pipeline for existing knowledge graphs. Using an
original Q&A dataset, the ROUGE F1 score of the sentences generated by the
proposed method showed an average improvement of 157.6% compared to the current
method. This highlights the effectiveness of the proposed method for automobile
failure analysis.

æè¦ï¼æ¬ææåºäºä¸åä½¿ç¨æª¢ç´¢å¢å¼·çæï¼RAGï¼åå¤§åèªè¨æ¨¡åï¼LLMï¼åç¥è­åè­ï¼KGï¼çæ±½è»æéåæç¥è­ç®¡çç³»çµ±ãå¨æ±½è»ç¢æ¥­ä¸­ï¼æè¶ä¾è¶å¤çéæ±ï¼å°æéåæç¥è­å¾ç¶é©è±å¯çå·¥ç¨å¸«å³æçµ¦å¹´è¼çå·¥ç¨å¸«ãç¶èï¼æéäºä»¶æ¯ä¸ç¨®é£éåæä¸­ç¼ççç¾è±¡ï¼éä½¿å¾åå­¸èé£ä»¥åæå®åãåç®¡ç¥è­åè­å¯ä»¥æè¿°èªç¾©éä¿åçµæ§åè³è¨ï¼ä¸¦ææå°è¡¨ç¤ºæéäºä»¶ï¼ç±æ¼å®åæè¡¨ç¤ºåä»¶ä¹ééä¿çè½åï¼KG ä¸­æè¨±å¤è³è¨ï¼å æ­¤å¹´è¼çå·¥ç¨å¸«å¾é£å¾ KG ä¸­æååçè§£å­åãå¦ä¸æ¹é¢ï¼äººåè¶ä¾è¶æèè¶£ä½¿ç¨ Graph RAGï¼éæ¯ä¸ç¨®çµå LLM å KG é²è¡ç¥è­ç®¡çç RAGãç¶èï¼ç¶å°ç®åç Graph RAG æ¡æ¶èç¾æçæ±½è»æéç¥è­åè­ä¸èµ·ä½¿ç¨æï¼æåºç¾å¹¾ååé¡ï¼å çºé£ä»¥çæéå°é LLM æ§å»ºçç¥è­åè­è³æåº«çå¯å·è¡æ¥è©¢ãçºäºè§£æ±ºéååé¡ï¼æåå°æ³¨æ¼éå°ç¾æç¥è­åè­æä½³å Graph RAG ç®¡éãä½¿ç¨åå§åç­è³æéï¼ææåºæ¹æ³çæçå¥å­ç ROUGE F1 åæ¸èç®åæ¹æ³ç¸æ¯ï¼å¹³åæåäº 157.6%ãéçªé¡¯äºææåºæ¹æ³å°æ¼æ±½è»æéåæçæææ§ã

##### **Way to Specialist: Closing Loop Between Specialized LLM and Evolving Domain Knowledge Graph**
2411.19064v1 by Yutong Zhang, Lixing Chen, Shenghong Li, Nan Cao, Yang Shi, Jiaxin Ding, Zhe Qu, Pan Zhou, Yang Bai

Large language models (LLMs) have demonstrated exceptional performance across
a wide variety of domains. Nonetheless, generalist LLMs continue to fall short
in reasoning tasks necessitating specialized knowledge. Prior investigations
into specialized LLMs focused on domain-specific training, which entails
substantial efforts in domain data acquisition and model parameter fine-tuning.
To address these challenges, this paper proposes the Way-to-Specialist (WTS)
framework, which synergizes retrieval-augmented generation with knowledge
graphs (KGs) to enhance the specialized capability of LLMs in the absence of
specialized training. In distinction to existing paradigms that merely utilize
external knowledge from general KGs or static domain KGs to prompt LLM for
enhanced domain-specific reasoning, WTS proposes an innovative
"LLM$\circlearrowright$KG" paradigm, which achieves bidirectional enhancement
between specialized LLM and domain knowledge graph (DKG). The proposed paradigm
encompasses two closely coupled components: the DKG-Augmented LLM and the
LLM-Assisted DKG Evolution. The former retrieves question-relevant domain
knowledge from DKG and uses it to prompt LLM to enhance the reasoning
capability for domain-specific tasks; the latter leverages LLM to generate new
domain knowledge from processed tasks and use it to evolve DKG. WTS closes the
loop between DKG-Augmented LLM and LLM-Assisted DKG Evolution, enabling
continuous improvement in the domain specialization as it progressively answers
and learns from domain-specific questions. We validate the performance of WTS
on 6 datasets spanning 5 domains. The experimental results show that WTS
surpasses the previous SOTA in 4 specialized domains and achieves a maximum
performance improvement of 11.3%.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å·²å¨ååé åå±ç¾åºåªç°çè¡¨ç¾ãç¶èï¼éæ LLM å¨éè¦å°æ¥­ç¥è­çæ¨çä»»åä¸­ä»è¡¨ç¾ä¸ä½³ãååå°å°æ¥­ LLM çç ç©¶éä¸­å¨ç¹å®é åè¨ç·´ï¼ééè¦å¤§éé åè³æåå¾åæ¨¡ååæ¸å¾®èª¿ãçºäºæå°éäºææ°ï¼æ¬ææåº Way-to-Specialist (WTS) æ¶æ§ï¼å®å°æª¢ç´¢å¢å¼·çæèç¥è­åè­ (KG) çµåèµ·ä¾ï¼ä»¥æå LLM å¨æ²æå°æ¥­è¨ç·´ææ³ä¸çå°æ¥­è½åãèåå©ç¨ä¾èªä¸è¬ KG æéæé å KG çå¤é¨ç¥è­æç¤º LLM ä»¥å¢å¼·ç¹å®é åæ¨ççæ¢æç¯ä¾ä¸åï¼WTS æåºä¸ååµæ°çãLLM$\circlearrowright$KGãç¯ä¾ï¼å®å¨å°æ¥­ LLM åé åç¥è­åè­ (DKG) ä¹éå¯¦ç¾éåå¢å¼·ãææåºçç¯ä¾åå«å©åç·å¯çµåççµæé¨åï¼DKG å¢å¼· LLM å LLM è¼å© DKG æ¼åãåèå¾ DKG ä¸­æª¢ç´¢èåé¡ç¸éçé åç¥è­ï¼ä¸¦ä½¿ç¨å®æç¤º LLM ä»¥å¢å¼·ç¹å®é åä»»åçæ¨çè½åï¼å¾èå©ç¨ LLM å¾èçéçä»»åä¸­ç¢çæ°çé åç¥è­ï¼ä¸¦ä½¿ç¨å®ä¾æ¼å DKGãWTS éåäº DKG å¢å¼· LLM å LLM è¼å© DKG æ¼åä¹éçè¿´è·¯ï¼é¨èå®éæ¼¸åç­åå­¸ç¿ç¹å®é ååé¡ï¼è½å¤ æçºæ¹åé åå°æ¥­åãæåå¨æ©«è·¨ 5 åé åç 6 åè³æéä¸é©è­ WTS çæè½ãå¯¦é©çµæé¡¯ç¤ºï¼WTS å¨ 4 åå°æ¥­é åä¸­è¶è¶ååç SOTAï¼ä¸¦éå° 11.3% çæå¤§æè½æåã

##### **EzSQL: An SQL intermediate representation for improving SQL-to-text Generation**
2411.18923v1 by Meher Bhardwaj, Hrishikesh Ethari, Dennis Singh Moirangthem

The SQL-to-text generation task traditionally uses template base, Seq2Seq,
tree-to-sequence, and graph-to-sequence models. Recent models take advantage of
pre-trained generative language models for this task in the Seq2Seq framework.
However, treating SQL as a sequence of inputs to the pre-trained models is not
optimal. In this work, we put forward a new SQL intermediate representation
called EzSQL to align SQL with the natural language text sequence. EzSQL
simplifies the SQL queries and brings them closer to natural language text by
modifying operators and keywords, which can usually be described in natural
language. EzSQL also removes the need for set operators. Our proposed
SQL-to-text generation model uses EzSQL as the input to a pre-trained
generative language model for generating the text descriptions. We demonstrate
that our model is an effective state-of-the-art method to generate text
narrations from SQL queries on the WikiSQL and Spider datasets. We also show
that by generating pretraining data using our SQL-to-text generation model, we
can enhance the performance of Text-to-SQL parsers.

æè¦ï¼SQL è½æå­çæä»»åå³çµ±ä¸ä½¿ç¨ç¯æ¬åºç¤ãSeq2Seqãæ¨¹å°åºåååå°åºåæ¨¡åãæè¿çæ¨¡åå©ç¨é è¨ç·´çæå¼èªè¨æ¨¡åä¾å·è¡ Seq2Seq æ¶æ§ä¸­çæ­¤é ä»»åãç¶èï¼å° SQL è¦çºé è¨ç·´æ¨¡åè¼¸å¥åºåä¸¦éæä½³è§£ãå¨æ­¤é å·¥ä½ä¸­ï¼æåæåºä¸ååçº EzSQL çæ°å¼ SQL ä¸­éè¡¨ç¤ºï¼ä»¥å° SQL èèªç¶èªè¨æå­åºåå°é½ãEzSQL ç°¡å SQL æ¥è©¢ï¼ä¸¦ééä¿®æ¹éç®å­èééµå­ï¼éå¸¸å¯ä»¥ç¨èªç¶èªè¨æè¿°ï¼ï¼è®å®åæ´æ¥è¿èªç¶èªè¨æå­ãEzSQL ä¹æ¶é¤äºå°éåéç®å­çéæ±ãæåæåºç SQL è½æå­çææ¨¡åä½¿ç¨ EzSQL ä½çºè¼¸å¥ï¼è¼¸å¥é è¨ç·´çæå¼èªè¨æ¨¡åä»¥ç¢çæå­æè¿°ãæåç¤ºç¯æåçæ¨¡åæ¯ä¸ç¨®ææçææ°æ¹æ³ï¼å¯ä»¥ç¨æ¼å¾ WikiSQL è Spider è³æéä¸­ç SQL æ¥è©¢ç¢çæå­æè¿°ãæåä¹å±ç¤ºééä½¿ç¨æåç SQL è½æå­çææ¨¡åç¢çé è¨ç·´è³æï¼æåå¯ä»¥æåæå­è½ SQL è§£æå¨çæè½ã

##### **MLLM-Search: A Zero-Shot Approach to Finding People using Multimodal Large Language Models**
2412.00103v1 by Angus Fung, Aaron Hao Tan, Haitong Wang, Beno Benhabib, Goldie Nejat

Robotic search of people in human-centered environments, including healthcare
settings, is challenging as autonomous robots need to locate people without
complete or any prior knowledge of their schedules, plans or locations.
Furthermore, robots need to be able to adapt to real-time events that can
influence a person's plan in an environment. In this paper, we present
MLLM-Search, a novel zero-shot person search architecture that leverages
multimodal large language models (MLLM) to address the mobile robot problem of
searching for a person under event-driven scenarios with varying user
schedules. Our approach introduces a novel visual prompting method to provide
robots with spatial understanding of the environment by generating a spatially
grounded waypoint map, representing navigable waypoints by a topological graph
and regions by semantic labels. This is incorporated into a MLLM with a region
planner that selects the next search region based on the semantic relevance to
the search scenario, and a waypoint planner which generates a search path by
considering the semantically relevant objects and the local spatial context
through our unique spatial chain-of-thought prompting approach. Extensive 3D
photorealistic experiments were conducted to validate the performance of
MLLM-Search in searching for a person with a changing schedule in different
environments. An ablation study was also conducted to validate the main design
choices of MLLM-Search. Furthermore, a comparison study with state-of-the art
search methods demonstrated that MLLM-Search outperforms existing methods with
respect to search efficiency. Real-world experiments with a mobile robot in a
multi-room floor of a building showed that MLLM-Search was able to generalize
to finding a person in a new unseen environment.

æè¦ï¼æ©å¨äººå¨ä»¥äººçºä¸­å¿çç°å¢ä¸­æå°äººï¼åæ¬é«çä¿å¥ç°å¢ï¼éæ¯ä¸åææ°ï¼å çºèªä¸»æ©å¨äººéè¦å¨å®å¨ææ²æäºåç¥éä»åçæéè¡¨ãè¨ç«æä½ç½®çææ³ä¸æ¾å°äººãæ­¤å¤ï¼æ©å¨äººéè¦è½å¤ é©æå¯è½å½±é¿ç°å¢ä¸­æäººè¨ç«çå³æäºä»¶ãå¨æ¬æä¸­ï¼æåæåº MLLM-Searchï¼ä¸ç¨®æ°ç©çé¶æ¬¡äººæå°æ¶æ§ï¼å®å©ç¨å¤æ¨¡æå¤§åèªè¨æ¨¡å (MLLM) ä¾è§£æ±ºå¨äºä»¶é©åå ´æ¯ä¸­æå°å·æä¸åä½¿ç¨èæéè¡¨çæäººçè¡åæ©å¨äººåé¡ãæåçåæ³å¼å¥äºä¸ç¨®æ°ç©çè¦è¦ºæç¤ºæ¹æ³ï¼ééçæä¸åç©ºéæ¥å°çèªé»åï¼ä»¥ææ²åè¡¨ç¤ºå¯å°èªèªé»ï¼ä¸¦ééèªç¾©æ¨ç±¤è¡¨ç¤ºååï¼çºæ©å¨äººæä¾ç°å¢çç©ºéçè§£ãéè¢«æ´åå°ä¸åå·æååè¦åå¨ç MLLM ä¸­ï¼è©²ååè¦åå¨æ ¹æèæå°å ´æ¯çèªç¾©ç¸éæ§é¸æä¸ä¸åæå°ååï¼ä»¥åä¸åèªé»è¦åå¨ï¼è©²è¦åå¨ééèæ®èªç¾©ç¸éç©ä»¶åå±é¨ç©ºéèæ¯ééæåç¨ç¹çç©ºéæç¶­æç¤ºæ¹æ³çææå°è·¯å¾ãé²è¡äºå»£æ³ç 3D çå¯¦æå¯¦é©ï¼ä»¥é©è­ MLLM-Search å¨ä¸åç°å¢ä¸­æå°å·æè®æ´æéè¡¨çäººçæè½ãéé²è¡äºä¸é æ¶èç ç©¶ï¼ä»¥é©è­ MLLM-Search çä¸»è¦è¨­è¨é¸æãæ­¤å¤ï¼èæåé²çæå°æ¹æ³çæ¯è¼ç ç©¶è¡¨æï¼MLLM-Search å¨æå°æçæ¹é¢åªæ¼ç¾ææ¹æ³ãå¨å»ºç¯ç©å¤æ¿éæ¨å±¤ä¸­ä½¿ç¨è¡åæ©å¨äººé²è¡ççå¯¦ä¸çå¯¦é©è¡¨æï¼MLLM-Search è½å¤ æ¦æ¬å°å¨ä¸åæ°çæªè¦ç°å¢ä¸­æ¾å°æäººã

##### **Human Evaluation of Procedural Knowledge Graph Extraction from Text with Large Language Models**
2412.03589v1 by Valentina Anita Carriero, Antonia Azzini, Ilaria Baroni, Mario Scrocca, Irene Celino

Procedural Knowledge is the know-how expressed in the form of sequences of
steps needed to perform some tasks. Procedures are usually described by means
of natural language texts, such as recipes or maintenance manuals, possibly
spread across different documents and systems, and their interpretation and
subsequent execution is often left to the reader. Representing such procedures
in a Knowledge Graph (KG) can be the basis to build digital tools to support
those users who need to apply or execute them. In this paper, we leverage Large
Language Model (LLM) capabilities and propose a prompt engineering approach to
extract steps, actions, objects, equipment and temporal information from a
textual procedure, in order to populate a Procedural KG according to a
pre-defined ontology. We evaluate the KG extraction results by means of a user
study, in order to qualitatively and quantitatively assess the perceived
quality and usefulness of the LLM-extracted procedural knowledge. We show that
LLMs can produce outputs of acceptable quality and we assess the subjective
perception of AI by human evaluators.

æè¦ï¼ç¨åºæ§ç¥è­æ¯ä»¥å·è¡æäºä»»åæéçæ­¥é©åºåå½¢å¼è¡¨éçæè¡ç¥è­ãç¨åºéå¸¸ç±èªç¶èªè¨ææ¬æè¿°ï¼ä¾å¦é£è­æç¶­è­·æåï¼å¯è½åæ£å¨ä¸åçæä»¶åç³»çµ±ä¸­ï¼å¶è§£éåå¾çºå·è¡éå¸¸ççµ¦è®èãå¨ç¥è­åè­ (KG) ä¸­è¡¨ç¤ºæ­¤é¡ç¨åºå¯ä»¥æçºæ§å»ºæ¸ä½å·¥å·çåºç¤ï¼ä»¥æ¯æ´éè¦æç¨æå·è¡éäºç¨åºçä½¿ç¨èãå¨æ¬æä¸­ï¼æåå©ç¨å¤§åèªè¨æ¨¡å (LLM) åè½ä¸¦æåºæç¤ºå·¥ç¨æ¹æ³ï¼å¾æå­ç¨åºä¸­æåæ­¥é©ãåä½ãç©ä»¶ãè¨­ååæéè³è¨ï¼ä»¥ä¾¿æ ¹æé å®ç¾©çæ¬ä½å¡«åç¨åº KGãæåééä½¿ç¨èç ç©¶è©ä¼° KG æåçµæï¼ä»¥å®æ§åå®éè©ä¼° LLM æåçç¨åºç¥è­çæç¥åè³ªåå¯¦ç¨æ§ãæåè¡¨æ LLM å¯ä»¥ç¢çå¯æ¥ååè³ªçè¼¸åºï¼ä¸¦ä¸æåè©ä¼°äºäººé¡è©ä¼°èå° AI çä¸»è§æç¥ã

##### **Regularized Multi-LLMs Collaboration for Enhanced Score-based Causal Discovery**
2411.17989v1 by Xiaoxuan Li, Yao Liu, Ruoyu Wang, Lina Yao

As the significance of understanding the cause-and-effect relationships among
variables increases in the development of modern systems and algorithms,
learning causality from observational data has become a preferred and efficient
approach over conducting randomized control trials. However, purely
observational data could be insufficient to reconstruct the true causal graph.
Consequently, many researchers tried to utilise some form of prior knowledge to
improve causal discovery process. In this context, the impressive capabilities
of large language models (LLMs) have emerged as a promising alternative to the
costly acquisition of prior expert knowledge. In this work, we further explore
the potential of using LLMs to enhance causal discovery approaches,
particularly focusing on score-based methods, and we propose a general
framework to utilise the capacity of not only one but multiple LLMs to augment
the discovery process.

æè¦ï¼é¨èçè§£ç¾ä»£ç³»çµ±åæ¼ç®æ³ä¸­è®æ¸ä¹éçå æéä¿çéè¦æ§æ¥çå¢å ï¼å¾è§æ¸¬è³æä¸­å­¸ç¿å æéä¿å·²æçºä¸ç¨®æ¯é²è¡é¨æ©å°ç§è©¦é©æ´åéçä¸æ´ææççæ¹æ³ãç¶èï¼ç´ç²¹çè§æ¸¬è³æå¯è½ä¸è¶³ä»¥éå»ºçæ­£çå æåãå æ­¤ï¼è¨±å¤ç ç©¶äººå¡åè©¦å©ç¨æç¨®å½¢å¼çåé©ç¥è­ä¾æ¹åå æç¼ç¾éç¨ãå¨æ­¤èæ¯ä¸ï¼å¤§åèªè¨æ¨¡å (LLM) çå¼·å¤§åè½å·²æçºæè²´çåé©å°å®¶ç¥è­ç²åçæ¿ä»£æ¹æ¡ãå¨éé å·¥ä½ä¸­ï¼æåé²ä¸æ­¥æ¢è¨äºä½¿ç¨ LLM ä¾å¢å¼·å æç¼ç¾æ¹æ³çå¯è½æ§ï¼ç¹å¥éæ³¨åºæ¼è©åçæ¨¡åï¼ä¸¦ä¸æåæåºäºä¸åéç¨æ¡æ¶ï¼ä¸åå¯ä»¥å©ç¨ä¸å LLMï¼éå¯ä»¥å©ç¨å¤å LLM ä¾æ´åç¼ç¾éç¨ã

##### **ShowUI: One Vision-Language-Action Model for GUI Visual Agent**
2411.17465v1 by Kevin Qinghong Lin, Linjie Li, Difei Gao, Zhengyuan Yang, Shiwei Wu, Zechen Bai, Weixian Lei, Lijuan Wang, Mike Zheng Shou

Building Graphical User Interface (GUI) assistants holds significant promise
for enhancing human workflow productivity. While most agents are
language-based, relying on closed-source API with text-rich meta-information
(e.g., HTML or accessibility tree), they show limitations in perceiving UI
visuals as humans do, highlighting the need for GUI visual agents. In this
work, we develop a vision-language-action model in digital world, namely
ShowUI, which features the following innovations: (i) UI-Guided Visual Token
Selection to reduce computational costs by formulating screenshots as an UI
connected graph, adaptively identifying their redundant relationship and serve
as the criteria for token selection during self-attention blocks; (ii)
Interleaved Vision-Language-Action Streaming that flexibly unifies diverse
needs within GUI tasks, enabling effective management of visual-action history
in navigation or pairing multi-turn query-action sequences per screenshot to
enhance training efficiency; (iii) Small-scale High-quality GUI
Instruction-following Datasets by careful data curation and employing a
resampling strategy to address significant data type imbalances. With above
components, ShowUI, a lightweight 2B model using 256K data, achieves a strong
75.1% accuracy in zero-shot screenshot grounding. Its UI-guided token selection
further reduces 33% of redundant visual tokens during training and speeds up
the performance by 1.4x. Navigation experiments across web Mind2Web, mobile
AITW, and online MiniWob environments further underscore the effectiveness and
potential of our model in advancing GUI visual agents. The models are available
at https://github.com/showlab/ShowUI.

æè¦ï¼<paragraph>å»ºæ§åå½¢ä½¿ç¨èä»é¢ (GUI) å©çæ¥µæææåäººé¡å·¥ä½æµç¨ççç¢åãéç¶å¤§å¤æ¸ä»£çé½æ¯åºæ¼èªè¨ï¼ä»°è³´å·æè±å¯æå­åè³è¨å°éåå§ç¢¼ APIï¼ä¾å¦ HTML æç¡éç¤æ¨¹ï¼ï¼ä½å®åå¨æç¥ä½¿ç¨èä»é¢è¦è¦ºæææ¹é¢é¡¯ç¤ºåºéå¶ï¼éå¸é¡¯äºå° GUI è¦è¦ºä»£ççéæ±ãå¨éé å·¥ä½ä¸­ï¼æåå¨æ¸ä½ä¸çä¸­éç¼äºä¸åè¦è¦ºèªè¨åä½æ¨¡åï¼å³ ShowUIï¼å¶å·æä»¥ä¸åµæ°åè½ï¼(i) UI å¼å°è¦è¦ºä»£å¹£é¸æï¼ééå°è¢å¹æªåè¡¨è¿°çº UI é£æ¥åï¼èªé©æå°è­å¥å¶åé¤éä¿ï¼ä¸¦ä½çºèªæ³¨æååå¡ä¸­ä»£å¹£é¸æçæºåï¼ä»¥éä½éç®ææ¬ï¼(ii) äº¤é¯è¦è¦ºèªè¨åä½ä¸²æµï¼éæ´»å°çµ±ä¸ GUI ä»»åä¸­çåç¨®éæ±ï¼å¨å°è¦½ä¸­ææç®¡çè¦è¦ºåä½æ­·ç¨ï¼æéå°æ¯åè¢å¹æªåçå¤è¼ªæ¥è©¢åä½åºåï¼ä»¥æåè¨ç·´æçï¼(iii) å°è¦æ¨¡é«åè³ª GUI æä»¤éµå¾ªè³æéï¼ééä»ç´°çè³ææ´çåæ¡ç¨åæ½æ¨£ç­ç¥ï¼ä¾è§£æ±ºé¡¯èçè³æé¡åä¸å¹³è¡¡ãShowUI æ¯ä¸åä½¿ç¨ 256K è³æçè¼éç´ 2B æ¨¡åï¼å·åä¸è¿°çµæé¨åï¼å¨é¶æ¬¡æ¹è¢å¹æªåæ¥å°ä¸­éå°å¼·åç 75.1% ç²¾ç¢ºåº¦ãå¶ UI å¼å°ä»£å¹£é¸æé²ä¸æ­¥æ¸å°äºè¨ç·´æé 33% çåé¤è¦è¦ºä»£å¹£ï¼ä¸¦å°æè½æåäº 1.4 åãè·¨ç¶²è·¯ Mind2Webãè¡å AITW åç·ä¸ MiniWob ç°å¢çå°è¦½å¯¦é©é²ä¸æ­¥å¼·èª¿äºæåçæ¨¡åå¨æ¨é² GUI è¦è¦ºä»£çæ¹é¢çæææ§åæ½åãéäºæ¨¡åå¯å¨ https://github.com/showlab/ShowUI åå¾ã</paragraph>

##### **Can LLMs be Good Graph Judger for Knowledge Graph Construction?**
2411.17388v1 by Haoyu Huang, Chong Chen, Conghui He, Yang Li, Jiawei Jiang, Wentao Zhang

In real-world scenarios, most of the data obtained from information retrieval
(IR) system is unstructured. Converting natural language sentences into
structured Knowledge Graphs (KGs) remains a critical challenge. The quality of
constructed KGs may also impact the performance of some KG-dependent domains
like GraphRAG systems and recommendation systems. Recently, Large Language
Models (LLMs) have demonstrated impressive capabilities in addressing a wide
range of natural language processing tasks. However, there are still challenges
when utilizing LLMs to address the task of generating structured KGs. And we
have identified three limitations with respect to existing KG construction
methods. (1)There is a large amount of information and excessive noise in
real-world documents, which could result in extracting messy information.
(2)Native LLMs struggle to effectively extract accuracy knowledge from some
domain-specific documents. (3)Hallucinations phenomenon cannot be overlooked
when utilizing LLMs directly as an unsupervised method for constructing KGs.
  In this paper, we propose GraphJudger, a knowledge graph construction
framework to address the aforementioned challenges. We introduce three
innovative modules in our method, which are entity-centric iterative text
denoising, knowledge aware instruction tuning and graph judgement,
respectively. We seek to utilize the capacity of LLMs to function as a graph
judger, a capability superior to their role only as a predictor for KG
construction problems. Experiments conducted on two general text-graph pair
datasets and one domain-specific text-graph pair dataset show superior
performances compared to baseline methods. The code of our proposed method is
available at https://github.com/hhy-huang/GraphJudger.

æè¦ï¼<paragraph>å¨ç¾å¯¦ä¸ççå ´æ¯ä¸­ï¼å¾è³è¨æª¢ç´¢ (IR) ç³»çµ±åå¾çå¤§é¨åè³æé½æ¯éçµæ§åçãå°èªç¶èªè¨å¥å­è½æçºçµæ§åçç¥è­åè­ (KG) ä»ç¶æ¯ä¸é éå¤§çææ°ãå·²å»ºæ§ç KG åè³ªä¹å¯è½å½±é¿æäºä¾è³´ KG çé åï¼ä¾å¦ GraphRAG ç³»çµ±åæ¨è¦ç³»çµ±çæè½ãæè¿ï¼å¤§åèªè¨æ¨¡å (LLM) å·²å±ç¾åºä»¤äººå°è±¡æ·±å»çè½åï¼è½èçå»£æ³çèªç¶èªè¨èçä»»åãç¶èï¼ç¶å©ç¨ LLM ä¾èçç¢ççµæ§å KG çä»»åæï¼ä»ç¶å­å¨ææ°ãæåå·²éå°ç¾æç KG å»ºæ§æ¹æ³æ¾åºä¸åéå¶ã(1) å¨ç¾å¯¦ä¸ççæä»¶ä¸­æå¤§éçè³è¨åéå¤çéè¨ï¼éå¯è½æå°è´èåéäºçè³è¨ã(2) åç LLM é£ä»¥å¾æäºç¹å®é åçæä»¶ä¸­ææèåç²¾ç¢ºçç¥è­ã(3) å¨å° LLM ç´æ¥ç¨ä½å»ºæ§ KG çéç£ç£å¼æ¹æ³æï¼ç¡æ³å¿½ç¥å¹»è¦ºç¾è±¡ãå¨æ¬æä¸­ï¼æåæåº GraphJudgerï¼éæ¯ä¸åç¥è­åè­å»ºæ§æ¶æ§ï¼ç¨æ¼è§£æ±ºä¸è¿°ææ°ãæåå¨æ¹æ³ä¸­å¼å¥äºä¸ååµæ°çæ¨¡çµï¼åå¥æ¯å¯¦é«çºä¸­å¿çåè¦æå­å»éè¨ãç¥è­æç¥æä»¤å¾®èª¿ååå½¢å¤æ·ãæåå°æ±å©ç¨ LLM çè½åï¼ä½¿å¶ç¼æ®åå½¢å¤æ·èçåè½ï¼éé è½ååªæ¼å¶åä½çº KG å»ºæ§åé¡é æ¸¬èçè§è²ãå¨å©åä¸è¬æå­åå½¢éå°è³æéåä¸åç¹å®é åæå­åå½¢éå°è³æéä¸é²è¡çå¯¦é©é¡¯ç¤ºï¼èåºç·æ¹æ³ç¸æ¯ï¼å¶æè½åªç°ãæåæåºçæ¹æ³çç¨å¼ç¢¼å¯æ¼ https://github.com/hhy-huang/GraphJudger åå¾ã</paragraph>

##### **Interleaved Scene Graph for Interleaved Text-and-Image Generation Assessment**
2411.17188v1 by Dongping Chen, Ruoxi Chen, Shu Pu, Zhaoyi Liu, Yanru Wu, Caixi Chen, Benlin Liu, Yue Huang, Yao Wan, Pan Zhou, Ranjay Krishna

Many real-world user queries (e.g. "How do to make egg fried rice?") could
benefit from systems capable of generating responses with both textual steps
with accompanying images, similar to a cookbook. Models designed to generate
interleaved text and images face challenges in ensuring consistency within and
across these modalities. To address these challenges, we present ISG, a
comprehensive evaluation framework for interleaved text-and-image generation.
ISG leverages a scene graph structure to capture relationships between text and
image blocks, evaluating responses on four levels of granularity: holistic,
structural, block-level, and image-specific. This multi-tiered evaluation
allows for a nuanced assessment of consistency, coherence, and accuracy, and
provides interpretable question-answer feedback. In conjunction with ISG, we
introduce a benchmark, ISG-Bench, encompassing 1,150 samples across 8
categories and 21 subcategories. This benchmark dataset includes complex
language-vision dependencies and golden answers to evaluate models effectively
on vision-centric tasks such as style transfer, a challenging area for current
models. Using ISG-Bench, we demonstrate that recent unified vision-language
models perform poorly on generating interleaved content. While compositional
approaches that combine separate language and image models show a 111%
improvement over unified models at the holistic level, their performance
remains suboptimal at both block and image levels. To facilitate future work,
we develop ISG-Agent, a baseline agent employing a "plan-execute-refine"
pipeline to invoke tools, achieving a 122% performance improvement.

æè¦ï¼è¨±å¤çå¯¦ä¸ççä½¿ç¨èæ¥è©¢ï¼ä¾å¦ãå¦ä½è£½ä½èçé£¯ï¼ãï¼å¯ä»¥åçæ¼è½å¤ ç¢çåå«æå­æ­¥é©åéå¸¶åççåæçç³»çµ±ï¼é¡ä¼¼æ¼é£è­ãå°éç¨æ¼ç¢çäº¤é¯ææ¬ååççæ¨¡åé¢è¨ç¢ºä¿éäºæ¹å¼å§é¨åä¹éçä¸è´æ§çææ°ãçºäºæå°éäºææ°ï¼æåæåºäº ISGï¼ä¸åç¨æ¼äº¤é¯ææ¬ååçç¢ççç¶åè©ä¼°æ¶æ§ãISG å©ç¨å ´æ¯åçµæ§ä¾ææææ¬ååçåå¡ä¹éçéä¿ï¼å¨ååå±¤ç´çç²åº¦ä¸è©ä¼°åæï¼æ´é«ãçµæ§ãåå¡å±¤ç´ååçç¹å®ãéç¨®å¤å±¤è©ä¼°åè¨±å°ä¸è´æ§ãé£è²«æ§åæºç¢ºæ§é²è¡ç´°ç·»çè©ä¼°ï¼ä¸¦æä¾å¯è§£éçåé¡è§£ç­åé¥ãçµå ISGï¼æåå¼å¥äºåºæº ISG-Benchï¼æ¶µè 8 åé¡å¥å 21 åå­é¡å¥ä¸­ç 1,150 åç¯ä¾ãéååºæºè³æéåå«è¤éçèªè¨è¦è¦ºä¾è³´éä¿åé»éç­æ¡ï¼ä»¥ææè©ä¼°æ¨¡åå¨ä»¥è¦è¦ºçºä¸­å¿çä»»åï¼ä¾å¦é¢¨æ ¼è½ç§»ï¼ä¸çè¡¨ç¾ï¼éæ¯ç¶åæ¨¡åé¢è¨çææ°é åãä½¿ç¨ ISG-Benchï¼æåè­æäºæè¿ççµ±ä¸è¦è¦ºèªè¨æ¨¡åå¨ç¢çäº¤é¯å§å®¹ä¸çè¡¨ç¾ä¸ä½³ãéç¶çµåå®ç¨èªè¨ååçæ¨¡åççµåæ¹æ³å¨æ´é«å±¤ç´ä¸æ¯çµ±ä¸æ¨¡åæåäº 111%ï¼ä½å®åå¨åå¡ååçå±¤ç´ä¸çè¡¨ç¾ä»ç¶ä¸ä½³ãçºäºä¿é²å¾çºå·¥ä½ï¼æåéç¼äº ISG-Agentï¼ä¸åæ¡ç¨ãè¨ç«å·è¡ä¿®æ­£ãç®¡ç·çåºæºä»£çï¼ç¨æ¼å¼å«å·¥å·ï¼å¯¦ç¾äº 122% çæè½æåã

##### **AtomR: Atomic Operator-Empowered Large Language Models for Heterogeneous Knowledge Reasoning**
2411.16495v2 by Amy Xin, Jinxin Liu, Zijun Yao, Zhicheng Lee, Shulin Cao, Lei Hou, Juanzi Li

Recent advancements in large language models (LLMs) have led to significant
improvements in various natural language processing tasks, but it is still
challenging for LLMs to perform knowledge-intensive complex question answering
due to LLMs' inefficacy in reasoning planning and the hallucination problem. A
typical solution is to employ retrieval-augmented generation (RAG) coupled with
chain-of-thought (CoT) reasoning, which decomposes complex questions into
chain-like sub-questions and applies iterative RAG at each sub-question.
However, prior works exhibit sub-optimal reasoning planning and overlook
dynamic knowledge retrieval from heterogeneous sources. In this paper, we
propose AtomR, a novel heterogeneous knowledge reasoning framework that
conducts multi-source reasoning at the atomic level. Drawing inspiration from
the graph modeling of knowledge, AtomR leverages large language models (LLMs)
to decompose complex questions into combinations of three atomic knowledge
operators, significantly enhancing the reasoning process at both the planning
and execution stages. We also introduce BlendQA, a novel evaluation benchmark
tailored to assess complex heterogeneous knowledge reasoning. Experiments show
that AtomR significantly outperforms state-of-the-art baselines across three
single-source and two multi-source reasoning benchmarks, with notable
performance gains of 9.4% on 2WikiMultihop and 9.5% on BlendQA.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) çææ°é²å±å·²å¤§å¹æååç¨®èªç¶èªè¨èçä»»åçè¡¨ç¾ï¼ä½ LLM ä»é£ä»¥å·è¡ç¥è­å¯éåè¤éåé¡è§£ç­ï¼åå å¨æ¼ LLM å¨æ¨çè¦ååå¹»è¦ºåé¡æ¹é¢æçä¸å½°ãå¸åçè§£æ±ºæ¹æ¡æ¯æ¡ç¨æª¢ç´¢å¢å¼·çæ (RAG) æ­éæç¶­é (CoT) æ¨çï¼å°è¤éåé¡åè§£æéçå­åé¡ï¼ä¸¦å¨æ¯åå­åé¡å¥ç¨åè¦ RAGãç¶èï¼ååçç ç©¶å±ç¾åºæ¬¡ä½³æ¨çè¦åï¼ä¸¦å¿½ç¥å¾ç°è³ªä¾æºé²è¡åæç¥è­æª¢ç´¢ãå¨æ¬æä¸­ï¼æåæåº AtomRï¼ä¸åæ°ç©çç°è³ªç¥è­æ¨çæ¶æ§ï¼å¨åå­å±¤ç´é²è¡å¤ä¾æºæ¨çãAtomR å¾ç¥è­çåå½¢å»ºæ¨¡ä¸­æ±²åéæï¼å©ç¨å¤§åèªè¨æ¨¡å (LLM) å°è¤éåé¡åè§£æä¸ç¨®åå­ç¥è­éç®å­ççµåï¼å¤§å¹æåè¦ååå·è¡éæ®µçæ¨çç¨åºãæåä¹å¼é² BlendQAï¼ä¸åæ°ç©çè©éåºæºï¼å°éç¨æ¼è©ä¼°è¤éç°è³ªç¥è­æ¨çãå¯¦é©é¡¯ç¤ºï¼AtomR å¨ä¸åå®ä¸ä¾æºåå©åå¤ä¾æºæ¨çåºæºä¸­ï¼è¡¨ç¾é¡¯èåªæ¼ç¾ææè¡åºç·ï¼å¨ 2WikiMultihop ä¸ç²å¾ 9.4% çé¡¯èæè½æåï¼å¨ BlendQA ä¸ç²å¾ 9.5% çæåã

##### **Learning by Analogy: Enhancing Few-Shot Prompting for Math Word Problem Solving with Computational Graph-Based Retrieval**
2411.16454v1 by Xiaocong Yang, Jiacheng Lin, Ziqi Wang, Chengxiang Zhai

Large language models (LLMs) are known to struggle with complicated reasoning
tasks such as math word problems (MWPs). In this paper, we present how analogy
from similarly structured questions can improve LLMs' problem-solving
capabilities for MWPs. Specifically, we rely on the retrieval of problems with
similar computational graphs to the given question to serve as exemplars in the
prompt, providing the correct reasoning path for the generation model to refer
to. Empirical results across six math word problem datasets demonstrate the
effectiveness of our proposed method, which achieves a significant improvement
of up to 6.7 percent on average in absolute value, compared to baseline
methods. These results highlight our method's potential in addressing the
reasoning challenges in current LLMs.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å·²ç¥å¨è¤éæ¨çä»»åï¼ä¾å¦æ¸å­¸æå­é¡ (MWP)ï¼ä¸­æéå°å°é£ãå¨æ¬æä¸­ï¼æåå±ç¤ºäºä¾èªçµæ§ç¸ä¼¼çåé¡çé¡æ¯å¦ä½è½æ¹å LLM å° MWP çåé¡è§£æ±ºè½åãå·é«ä¾èªªï¼æåä¾è³´æ¼æ·åèçµ¦å®åé¡å·æé¡ä¼¼éç®åå½¢çåé¡ï¼ä½çºæç¤ºä¸­çç¯ä¾ï¼çºçææ¨¡åæä¾æ­£ç¢ºçæ¨çè·¯å¾ä»¥ä¾åèãå­åæ¸å­¸æå­é¡æ¸æéçå¯¦è­çµæè­æäºæåæåºçæ¹æ³çæææ§ï¼èåºç·æ¹æ³ç¸æ¯ï¼å¹³åçµå°å¼æé«äº 6.7 åç¾åé»ãéäºçµæçªåºäºæåçæ¹æ³å¨è§£æ±ºç¶å LLM ä¸­çæ¨çææ°æ¹é¢çæ½åã

##### **Adapter-based Approaches to Knowledge-enhanced Language Models -- A Survey**
2411.16403v1 by Alexander Fichtl, Juraj Vladika, Georg Groh

Knowledge-enhanced language models (KELMs) have emerged as promising tools to
bridge the gap between large-scale language models and domain-specific
knowledge. KELMs can achieve higher factual accuracy and mitigate
hallucinations by leveraging knowledge graphs (KGs). They are frequently
combined with adapter modules to reduce the computational load and risk of
catastrophic forgetting. In this paper, we conduct a systematic literature
review (SLR) on adapter-based approaches to KELMs. We provide a structured
overview of existing methodologies in the field through quantitative and
qualitative analysis and explore the strengths and potential shortcomings of
individual approaches. We show that general knowledge and domain-specific
approaches have been frequently explored along with various adapter
architectures and downstream tasks. We particularly focused on the popular
biomedical domain, where we provided an insightful performance comparison of
existing KELMs. We outline the main trends and propose promising future
directions.

æè¦ï¼ç¥è­å¢å¼·èªè¨æ¨¡åï¼KELMï¼å·²æçºå½åå¤§è¦æ¨¡èªè¨æ¨¡åèç¹å®é åç¥è­å·®è·çæåéçå·¥å·ãKELM å¯ä»¥ééå©ç¨ç¥è­åè­ï¼KGï¼ä¾æé«äºå¯¦æºç¢ºæ§ä¸¦æ¸å°å¹»è¦ºãå®åç¶å¸¸èé©éå¨æ¨¡çµçµåä½¿ç¨ï¼ä»¥éä½éç®è² è¼åç½é£æ§éºå¿çé¢¨éªãå¨æ¬æä¸­ï¼æåå°åºæ¼é©éå¨ç KELM æ¹æ³é²è¡ç³»çµ±æ§çæç»åé¡§ï¼SLRï¼ãæåééå®éåå®æ§åææä¾è©²é åæ¢ææ¹æ³è«ççµæ§åæ¦è§ï¼ä¸¦æ¢è¨åå¥æ¹æ³çåªé»åæ½å¨ç¼ºé»ãæåè¡¨æï¼ä¸è¬ç¥è­åç¹å®é åçæ¹æ³å·²èåç¨®é©éå¨æ¶æ§åä¸æ¸¸ä»»åä¸èµ·è¢«é »ç¹æ¢ç´¢ãæåç¹å¥éæ³¨ç±éççç©é«å­¸é åï¼å¨è©²é åä¸­ï¼æåæä¾äºç¾æ KELM çæè¦å°æè½æ¯è¼ãæåæ¦è¿°äºä¸»è¦è¶¨å¢ï¼ä¸¦æåºäºæåéçæªä¾æ¹åã

##### **Decoding Urban Industrial Complexity: Enhancing Knowledge-Driven Insights via IndustryScopeGPT**
2411.15758v1 by Siqi Wang, Chao Liang, Yunfan Gao, Yang Liu, Jing Li, Haofen Wang

Industrial parks are critical to urban economic growth. Yet, their
development often encounters challenges stemming from imbalances between
industrial requirements and urban services, underscoring the need for strategic
planning and operations. This paper introduces IndustryScopeKG, a pioneering
large-scale multi-modal, multi-level industrial park knowledge graph, which
integrates diverse urban data including street views, corporate,
socio-economic, and geospatial information, capturing the complex relationships
and semantics within industrial parks. Alongside this, we present the
IndustryScopeGPT framework, which leverages Large Language Models (LLMs) with
Monte Carlo Tree Search to enhance tool-augmented reasoning and decision-making
in Industrial Park Planning and Operation (IPPO). Our work significantly
improves site recommendation and functional planning, demonstrating the
potential of combining LLMs with structured datasets to advance industrial park
management. This approach sets a new benchmark for intelligent IPPO research
and lays a robust foundation for advancing urban industrial development. The
dataset and related code are available at
https://github.com/Tongji-KGLLM/IndustryScope.

æè¦ï¼å·¥æ¥­ååå°æ¼é½å¸ç¶æ¿æé·è³ééè¦ãç¶èï¼å¶ç¼å±ç¶å¸¸æéå°å·¥æ¥­éæ±èé½å¸æåä¹éä¸å¹³è¡¡æç¢ççææ°ï¼éå¸é¡¯äºç­ç¥æ§è¦åèçéçéæ±ãæ¬æä»ç´¹äº IndustryScopeKGï¼ä¸ååé©æ§çãå¤§è¦æ¨¡ãå¤æ¨¡å¼ãå¤å±¤ç´çå·¥æ¥­ååç¥è­åè­ï¼å®æ´åäºåå«è¡æ¯ãå¬å¸ãç¤¾æç¶æ¿åå°çç©ºéè³è¨å¨å§çåç¨®é½å¸è³æï¼ææå·¥æ¥­ååå§è¤éçéä¿åèªæãé¤æ­¤ä¹å¤ï¼æåæåºäº IndustryScopeGPT æ¶æ§ï¼å®å©ç¨å¤§åèªè¨æ¨¡å (LLM) èèå°å¡ç¾æ¨¹çæå°ï¼ä»¥å¢å¼·å·¥å·è¼å©æ¨çåå¨å·¥æ¥­ååè¦ååçé (IPPO) ä¸­çæ±ºç­å¶å®ãæåçç ç©¶å¤§å¹æ¹åäºå ´å°æ¨è¦ååè½è¦åï¼å±ç¤ºäºçµå LLM åçµæ§åè³æéä»¥æ¨é²å·¥æ¥­ååç®¡ççæ½åãéåæ¹æ³çºæºæ§ IPPO ç ç©¶è¨­å®äºæ°çåºæºï¼ä¸¦çºæ¨é²é½å¸ç¢æ¥­ç¼å±å¥ å®äºç©©åºçåºç¤ãè³æéåç¸éç¨å¼ç¢¼å¯å¨ https://github.com/Tongji-KGLLM/IndustryScope åå¾ã

##### **One to rule them all: natural language to bind communication, perception and action**
2411.15033v1 by Simone Colombani, Dimitri Ognibene, Giuseppe Boccignone

In recent years, research in the area of human-robot interaction has focused
on developing robots capable of understanding complex human instructions and
performing tasks in dynamic and diverse environments. These systems have a wide
range of applications, from personal assistance to industrial robotics,
emphasizing the importance of robots interacting flexibly, naturally and safely
with humans. This paper presents an advanced architecture for robotic action
planning that integrates communication, perception, and planning with Large
Language Models (LLMs). Our system is designed to translate commands expressed
in natural language into executable robot actions, incorporating environmental
information and dynamically updating plans based on real-time feedback. The
Planner Module is the core of the system where LLMs embedded in a modified
ReAct framework are employed to interpret and carry out user commands. By
leveraging their extensive pre-trained knowledge, LLMs can effectively process
user requests without the need to introduce new knowledge on the changing
environment. The modified ReAct framework further enhances the execution space
by providing real-time environmental perception and the outcomes of physical
actions. By combining robust and dynamic semantic map representations as graphs
with control components and failure explanations, this architecture enhances a
robot adaptability, task execution, and seamless collaboration with human users
in shared and dynamic environments. Through the integration of continuous
feedback loops with the environment the system can dynamically adjusts the plan
to accommodate unexpected changes, optimizing the robot ability to perform
tasks. Using a dataset of previous experience is possible to provide detailed
feedback about the failure. Updating the LLMs context of the next iteration
with suggestion on how to overcame the issue.

æè¦ï¼è¿å¹´æ¥ï¼äººæºäº¤äºé¢åçç ç©¶éç¹
å¨äºå¼åè½å¤çè§£å¤æäººç±»æä»¤å¹¶å¨å¨æåå¤æ ·åç¯å¢ä¸­æ§è¡ä»»å¡çæºå¨äººãè¿äºç³»ç»å·æå¹¿æ³çåºç¨ï¼ä»ä¸ªäººå©çå°å·¥ä¸æºå¨äººï¼å¼ºè°äºæºå¨äººä¸äººç±»çµæ´»ãèªç¶åå®å¨äº¤äºçéè¦æ§ãæ¬ææåºäºä¸ç§åè¿çæºå¨äººå¨ä½è§åæ¶æï¼è¯¥æ¶æéæäºéä¿¡ãæç¥åè§åä¸å¤§åè¯­è¨æ¨¡å (LLM)ãæä»¬çç³»ç»æ¨å¨å°ä»¥èªç¶è¯­è¨è¡¨è¾¾çå½ä»¤ç¿»è¯æå¯æ§è¡çæºå¨äººå¨ä½ï¼å¹¶ç»åç¯å¢ä¿¡æ¯å¹¶æ ¹æ®å®æ¶åé¦å¨ææ´æ°è®¡åãè§åå¨æ¨¡åæ¯ç³»ç»çæ ¸å¿ï¼å¶ä¸­åµå¥å¨ä¿®æ¹åç ReAct æ¡æ¶ä¸­ç LLM ç¨äºè§£éåæ§è¡ç¨æ·å½ä»¤ãéè¿å©ç¨å¶å¹¿æ³çé¢è®­ç»ç¥è¯ï¼LLM å¯ä»¥ææå¤çç¨æ·è¯·æ±ï¼èæ éå¼å¥æå³ä¸æ­ååçç¯å¢çæ°ç¥è¯ãä¿®æ¹åç ReAct æ¡æ¶éè¿æä¾å®æ¶ç¯å¢æç¥åç©çå¨ä½çç»æè¿ä¸æ­¥å¢å¼ºäºæ§è¡ç©ºé´ãéè¿å°é²æ£ä¸å¨æè¯­ä¹å°å¾è¡¨ç¤ºä¸æ§å¶ç»ä»¶åæéè§£éç¸ç»åï¼è¯¥æ¶æå¢å¼ºäºæºå¨äººçéåºæ§ãä»»å¡æ§è¡ä»¥åä¸äººç±»ç¨æ·å¨å±äº«åå¨æç¯å¢ä¸­çæ ç¼åä½ãéè¿å°è¿ç»­åé¦åè·¯ä¸ç¯å¢ç¸ç»åï¼ç³»ç»å¯ä»¥å¨æè°æ´è®¡åä»¥éåºæå¤ååï¼ä»èä¼åæºå¨äººæ§è¡ä»»å¡çè½åãå©ç¨ååçç»éªæ°æ®éï¼å¯ä»¥æä¾æå³æéçè¯¦ç»åé¦ãä½¿ç¨æå³å¦ä½åæé®é¢çå»ºè®®æ´æ°ä¸ä¸ä¸ªè¿­ä»£ç LLM ä¸ä¸æã

##### **Time is on my sight: scene graph filtering for dynamic environment perception in an LLM-driven robot**
2411.15027v1 by Simone Colombani, Luca Brini, Dimitri Ognibene, Giuseppe Boccignone

Robots are increasingly being used in dynamic environments like workplaces,
hospitals, and homes. As a result, interactions with robots must be simple and
intuitive, with robots perception adapting efficiently to human-induced
changes. This paper presents a robot control architecture that addresses key
challenges in human-robot interaction, with a particular focus on the dynamic
creation and continuous update of the robot state representation. The
architecture uses Large Language Models to integrate diverse information
sources, including natural language commands, robotic skills representation,
real-time dynamic semantic mapping of the perceived scene. This enables
flexible and adaptive robotic behavior in complex, dynamic environments.
Traditional robotic systems often rely on static, pre-programmed instructions
and settings, limiting their adaptability to dynamic environments and real-time
collaboration. In contrast, this architecture uses LLMs to interpret complex,
high-level instructions and generate actionable plans that enhance human-robot
collaboration. At its core, the system Perception Module generates and
continuously updates a semantic scene graph using RGB-D sensor data, providing
a detailed and structured representation of the environment. A particle filter
is employed to ensure accurate object localization in dynamic, real-world
settings. The Planner Module leverages this up-to-date semantic map to break
down high-level tasks into sub-tasks and link them to robotic skills such as
navigation, object manipulation (e.g., PICK and PLACE), and movement (e.g.,
GOTO). By combining real-time perception, state tracking, and LLM-driven
communication and task planning, the architecture enhances adaptability, task
efficiency, and human-robot collaboration in dynamic environments.

æè¦ï¼<paragraph>æ©å¨äººæ­£è¶ä¾è¶å»£æ³å°æç¨æ¼å·¥ä½å ´æãé«é¢åå®¶åº­ç­åæç°å¢ä¸­ãå æ­¤ï¼èæ©å¨äººçäºåå¿é ç°¡å®ç´è§ï¼æ©å¨äººçæç¥è½åå¿é ææé©æäººé¡å¼ç¼çè®åãæ¬ææåºäºä¸ç¨®æ©å¨äººæ§å¶æ¶æ§ï¼ç¨æ¼è§£æ±ºäººæ©äºåä¸­çééµææ°ï¼ç¹å¥éæ³¨æ©å¨äººçæè¡¨ç¤ºçåæå»ºç«åæçºæ´æ°ãè©²æ¶æ§ä½¿ç¨å¤§åèªè¨æ¨¡åæ´åå¤ç¨®è³è¨ä¾æºï¼åæ¬èªç¶èªè¨å½ä»¤ãæ©å¨äººæè½è¡¨ç¤ºãæç¥å ´æ¯çå³æåæèªç¾©å°æãéä½¿å¾æ©å¨äººå¨è¤éçåæç°å¢ä¸­è½å¤ éæ´»é©æãå³çµ±çæ©å¨äººç³»çµ±éå¸¸ä¾è³´æ¼éæçãé åç·¨ç¨çæä»¤åè¨­å®ï¼ééå¶äºå®åå°åæç°å¢åå³æåä½çé©æè½åãç¸æ¯ä¹ä¸ï¼æ­¤æ¶æ§ä½¿ç¨ LLM ä¾è©®éè¤éçé«å±¤ç´æä»¤ï¼ä¸¦å¶å®å¯è¡çè¨ç«ï¼ä»¥å¢å¼·äººæ©åä½ãå¨ç³»çµ±çæ ¸å¿ï¼æç¥æ¨¡çµä½¿ç¨ RGB-D ææ¸¬å¨è³æç¢çä¸¦æçºæ´æ°èªç¾©å ´æ¯åï¼æä¾ç°å¢çè©³ç´°ä¸çµæ§åçè¡¨ç¤ºãæ¡ç¨ç²å­æ¿¾æ³¢å¨ä»¥ç¢ºä¿å¨åæççå¯¦ä¸çè¨­å®ä¸­æºç¢ºå®ä½ç©ä»¶ãè¦åæ¨¡çµå©ç¨éåææ°çèªç¾©å°åï¼å°é«å±¤ç´ä»»ååè§£çºå­ä»»åï¼ä¸¦å°å®åé£çµå°æ©å¨äººæè½ï¼ä¾å¦å°èªãç©ä»¶æä½ï¼ä¾å¦ï¼åæ¾ï¼åç§»åï¼ä¾å¦ï¼åå¾ï¼ãééçµåå³ææç¥ãçæè¿½è¹¤å LLM é©åçæºéåä»»åè¦åï¼æ­¤æ¶æ§å¢å¼·äºåæç°å¢ä¸­çé©æè½åãä»»åæçåäººæ©åä½ã</paragraph>

##### **GOT4Rec: Graph of Thoughts for Sequential Recommendation**
2411.14922v1 by Zewen Long, Liang Wang, Shu Wu, Qiang Liu, Liang Wang

With the advancement of large language models (LLMs), researchers have
explored various methods to optimally leverage their comprehension and
generation capabilities in sequential recommendation scenarios. However,
several challenges persist in this endeavor. Firstly, most existing approaches
rely on the input-output prompting paradigm, which can result in irrelevant or
inaccurate responses. Secondly, while there have been attempts to enhance LLMs
using prompting strategies such as chain-of-thought (CoT), these efforts have
not fully harnessed the reasoning abilities of LLMs or effectively captured the
multifaceted information contained within user sequences. To address these
limitations, we propose GOT4Rec, a sequential recommendation method that
utilizes the graph of thoughts (GoT) prompting strategy. Specifically, we
identify and utilize three key types of information within user history
sequences: short-term interests, long-term interests and collaborative
information from other users. Our approach enables LLMs to independently reason
and generate recommendations based on these distinct types of information,
subsequently aggregating the results within the GoT framework to derive the
final recommended items. This method allows LLMs, with enhanced reasoning
capabilities, to more effectively consider the diverse information within user
sequences, resulting in more accurate recommendations and more comprehensive
explanations. Extensive experiments on real-world datasets demonstrate the
effectiveness of GOT4Rec, indicating that it outperforms existing
state-of-the-art baselines. Our code is available at
https://anonymous.4open.science/r/GOT4Rec-ED99.

æè¦ï¼é¨èå¤§åèªè¨æ¨¡å (LLM) çé²æ­¥ï¼ç ç©¶äººå¡å·²æ¢ç´¢åç¨®æ¹æ³ï¼ä»¥æä½³æ¹å¼å©ç¨å¶çè§£åçæè½åå¨é åºæ¨è¦å ´æ¯ä¸­ãç¶èï¼å¨éååªåä¸­ä»å­å¨ä¸äºææ°ãé¦åï¼å¤§å¤æ¸ç¾ææ¹æ³ä¾è³´æ¼è¼¸å¥è¼¸åºæç¤ºç¯ä¾ï¼éå¯è½æå°è´ä¸ç¸éæä¸æºç¢ºçåæãå¶æ¬¡ï¼éç¶æäººåè©¦ä½¿ç¨æç¤ºç­ç¥ï¼ä¾å¦ææ³é (CoT)ï¼ä¾å¢å¼· LLMï¼ä½éäºåªåä¸¦æªååå©ç¨ LLM çæ¨çè½åææææ·åä½¿ç¨èåºåä¸­åå«çå¤æ¹é¢è³è¨ãçºäºè§£æ±ºéäºéå¶ï¼æåæåº GOT4Recï¼éæ¯ä¸ç¨®é åºæ¨è¦æ¹æ³ï¼å©ç¨äºææ³å (GoT) æç¤ºç­ç¥ãå·é«ä¾èªªï¼æåå¨ä½¿ç¨èæ­·å²åºåä¸­è­å¥ä¸¦å©ç¨ä¸ç¨®é¡åçééµè³è¨ï¼ç­æèè¶£ãé·æèè¶£åä¾èªå¶ä»ä½¿ç¨èçåä½è³è¨ãæåçæ¹æ³ä½¿ LLM è½å¤ æ ¹æéäºä¸åé¡åçè³è¨ç¨ç«æ¨çä¸¦ç¢çå»ºè­°ï¼ç¶å¾å¨ GoT æ¡æ¶å§å¯ç¸½çµæä»¥æ¨å°åºæçµæ¨è¦çé ç®ãéç¨®æ¹æ³åè¨± LLM å¨å¢å¼·æ¨çè½åçåæï¼æ´ææå°èæ®ä½¿ç¨èåºåä¸­çä¸åè³è¨ï¼å¾èç¢çæ´æºç¢ºçå»ºè­°åæ´å¨é¢çèªªæãå¨çå¯¦ä¸çè³æéä¸çå¤§éå¯¦é©è­æäº GOT4Rec çæææ§ï¼è¡¨æå®åªæ¼ç¾æçæåé²åºæºãæåçç¨å¼ç¢¼å¯å¨ https://anonymous.4open.science/r/GOT4Rec-ED99 åå¾ã

##### **VisGraphVar: A Benchmark Generator for Assessing Variability in Graph Analysis Using Large Vision-Language Models**
2411.14832v1 by Camilo ChacÃ³n Sartori, Christian Blum, Filippo Bistaffa

The fast advancement of Large Vision-Language Models (LVLMs) has shown
immense potential. These models are increasingly capable of tackling abstract
visual tasks. Geometric structures, particularly graphs with their inherent
flexibility and complexity, serve as an excellent benchmark for evaluating
these models' predictive capabilities. While human observers can readily
identify subtle visual details and perform accurate analyses, our investigation
reveals that state-of-the-art LVLMs exhibit consistent limitations in specific
visual graph scenarios, especially when confronted with stylistic variations.
In response to these challenges, we introduce VisGraphVar (Visual Graph
Variability), a customizable benchmark generator able to produce graph images
for seven distinct task categories (detection, classification, segmentation,
pattern recognition, link prediction, reasoning, matching), designed to
systematically evaluate the strengths and limitations of individual LVLMs. We
use VisGraphVar to produce 990 graph images and evaluate six LVLMs, employing
two distinct prompting strategies, namely zero-shot and chain-of-thought. The
findings demonstrate that variations in visual attributes of images (e.g., node
labeling and layout) and the deliberate inclusion of visual imperfections, such
as overlapping nodes, significantly affect model performance. This research
emphasizes the importance of a comprehensive evaluation across graph-related
tasks, extending beyond reasoning alone. VisGraphVar offers valuable insights
to guide the development of more reliable and robust systems capable of
performing advanced visual graph analysis.

æè¦ï¼å¤§åè¦è¦ºèªè¨æ¨¡å (LVLMs) çå¿«éé²æ­¥å·²å±ç¾åºå·¨å¤§çæ½åãéäºæ¨¡åè¶ä¾è¶æè½åèçæ½è±¡çè¦è¦ºä»»åãå¹¾ä½çµæ§ï¼ç¹å¥æ¯å·æå§å¨éæ´»æ§èè¤éæ§çåå½¢ï¼å¯ç¨ä½è©ä¼°éäºæ¨¡åé æ¸¬è½åççµä½³åºæºãäººé¡è§å¯èå¯ä»¥è¼æè¾¨è­å¾®å¦çè¦è¦ºç´°ç¯ä¸¦å·è¡æºç¢ºçåæï¼ä½æåçèª¿æ¥é¡¯ç¤ºï¼æåé²ç LVLMs å¨ç¹å®çè¦è¦ºåå½¢å ´æ¯ä¸­è¡¨ç¾åºæçºçéå¶ï¼ç¹å¥æ¯å¨é¢å°é¢¨æ ¼è®åæãçºäºæå°éäºææ°ï¼æåå¼å¥äº VisGraphVarï¼è¦è¦ºåå½¢è®ç°ï¼ï¼éæ¯ä¸åå¯èªè¨çåºæºç¢çå¨ï¼è½å¤ ç¢çä¸åä¸åä»»åé¡å¥çåå½¢å½±åï¼åµæ¸¬ãåé¡ãåå²ãæ¨¡å¼è¾¨è­ãé£çµé æ¸¬ãæ¨çãéå°ï¼ï¼æ¨å¨ç³»çµ±æ§å°è©ä¼°åå¥ LVLMs çåªé»åéå¶ãæåä½¿ç¨ VisGraphVar ç¢ç 990 ååå½¢å½±åä¸¦è©ä¼°å­å LVLMsï¼æ¡ç¨å©ç¨®ä¸åçæç¤ºç­ç¥ï¼å³é¶æ¬¡å­¸ç¿åæç¶­éãç ç©¶çµæè¡¨æï¼å½±åè¦è¦ºå±¬æ§çè®åï¼ä¾å¦ç¯é»æ¨ç±¤åçé¢ï¼ä»¥åè¦è¦ºççµçææå å¥ï¼ä¾å¦éçç¯é»ï¼æé¡¯èå½±é¿æ¨¡åæè½ãéé ç ç©¶å¼·èª¿äºè·¨åå½¢ç¸éä»»åé²è¡å¨é¢è©ä¼°çéè¦æ§ï¼èä¸åéæ¼æ¨çãVisGraphVar æä¾äºå¯¶è²´çè¦è§£ï¼ä»¥æå°æ´å¯é ä¸å¼·å¤§çç³»çµ±çéç¼ï¼éäºç³»çµ±è½å¤ å·è¡é²éçè¦è¦ºåå½¢åæã

##### **MolReFlect: Towards In-Context Fine-grained Alignments between Molecules and Texts**
2411.14721v1 by Jiatong Li, Yunqing Liu, Wei Liu, Jingdi Le, Di Zhang, Wenqi Fan, Dongzhan Zhou, Yuqiang Li, Qing Li

Molecule discovery is a pivotal research field, impacting everything from the
medicines we take to the materials we use. Recently, Large Language Models
(LLMs) have been widely adopted in molecule understanding and generation, yet
the alignments between molecules and their corresponding captions remain a
significant challenge. Previous endeavours often treat the molecule as a
general SMILES string or molecular graph, neglecting the fine-grained
alignments between the molecular sub-structures and the descriptive textual
phrases, which are crucial for accurate and explainable predictions. In this
case, we introduce MolReFlect, a novel teacher-student framework designed to
contextually perform the molecule-caption alignments in a fine-grained way. Our
approach initially leverages a larger teacher LLM to label the detailed
alignments by directly extracting critical phrases from molecule captions or
SMILES strings and implying them to corresponding sub-structures or
characteristics. To refine these alignments, we propose In-Context Selective
Reflection, which retrieves previous extraction results as context examples for
teacher LLM to reflect and lets a smaller student LLM select from in-context
reflection and previous extraction results. Finally, we enhance the learning
process of the student LLM through Chain-of-Thought In-Context Molecule Tuning,
integrating the fine-grained alignments and the reasoning processes within the
Chain-of-Thought format. Our experimental results demonstrate that MolReFlect
enables LLMs like Mistral-7B to significantly outperform the previous
baselines, achieving SOTA performance on the ChEBI-20 dataset. This advancement
not only enhances the generative capabilities of LLMs in the molecule-caption
translation task, but also contributes to a more explainable framework.

æè¦ï¼åå­ç¼ç¾æ¯ä¸åééµçç ç©¶é åï¼å¾æåæç¨çè¥ç©å°æåä½¿ç¨çææï¼å½±é¿èä¸åãæè¿ï¼å¤§åèªè¨æ¨¡å (LLM) å·²å»£æ³æç¨æ¼åå­çè§£åçæä¸­ï¼ä½åå­åå¶å°ææ¨é¡ä¹éçå°é½ä»ç¶æ¯ä¸é éå¤§ææ°ãååçåªåéå¸¸å°åå­è¦çºä¸è¬ç SMILES å­ç¬¦ä¸²æåå­åï¼å¿½ç¥äºåå­å­çµæ§åæè¿°æ§ææ¬ç­èªä¹éçç´°ç²åº¦å°é½ï¼éå°æ¼æºç¢ºä¸å¯è§£éçé æ¸¬è³ééè¦ãå¨éç¨®ææ³ä¸ï¼æåå¼å¥äº MolReFlectï¼éæ¯ä¸åæ°ç©çå¸«çæ¡æ¶ï¼æ¨å¨ä»¥ç´°ç²åº¦çæ¹å¼å°åå­æ¨é¡å°é½é²è¡ä¸ä¸æå·è¡ãæåçåæ³æåå©ç¨ä¸åæ´å¤§çæå¸« LLM ä¾æ¨è¨è©³ç´°å°é½ï¼æ¹æ³æ¯ç´æ¥å¾åå­æ¨é¡æ SMILES å­ç¬¦ä¸²ä¸­æåééµç­èªï¼ä¸¦å°å®åæç¤ºçºå°æçå­çµæ§æç¹å¾µãçºäºåªåéäºå°é½ï¼æåæåºäºä¸ä¸æé¸ææ§åå°ï¼å®å°ä»¥åçæåçµæä½çºä¸ä¸æç¯ä¾ï¼ä¾æå¸« LLM é²è¡åå°ï¼ä¸¦è®ä¸åè¼å°çå­¸ç LLM å¾ä¸ä¸æåå°åä»¥åçæåçµæä¸­é²è¡é¸æãæå¾ï¼æåééææ³éä¸ä¸æåå­èª¿æ´å¢å¼·äºå­¸ç LLM çå­¸ç¿éç¨ï¼å°ç´°ç²åº¦å°é½åæ¨çéç¨æ´åå°ææ³éæ ¼å¼ä¸­ãæåçå¯¦é©çµæè¡¨æï¼MolReFlect ä½¿å Mistral-7B éæ¨£ç LLM è½å¤ é¡¯èåªæ¼ååçåºæºï¼å¨ ChEBI-20 æ¸æéä¸å¯¦ç¾äº SOTA æ§è½ãéä¸é²æ­¥ä¸åå¢å¼·äº LLM å¨åå­æ¨é¡ç¿»è­¯ä»»åä¸­ççæè½åï¼èä¸éæå©æ¼å»ºç«ä¸åæ´å·å¯è§£éæ§çæ¡æ¶ã

##### **G-RAG: Knowledge Expansion in Material Science**
2411.14592v2 by Radeen Mostafa, Mirza Nihal Baig, Mashaekh Tausif Ehsan, Jakir Hasan

In the field of Material Science, effective information retrieval systems are
essential for facilitating research. Traditional Retrieval-Augmented Generation
(RAG) approaches in Large Language Models (LLMs) often encounter challenges
such as outdated information, hallucinations, limited interpretability due to
context constraints, and inaccurate retrieval. To address these issues, Graph
RAG integrates graph databases to enhance the retrieval process. Our proposed
method processes Material Science documents by extracting key entities
(referred to as MatIDs) from sentences, which are then utilized to query
external Wikipedia knowledge bases (KBs) for additional relevant information.
We implement an agent-based parsing technique to achieve a more detailed
representation of the documents. Our improved version of Graph RAG called G-RAG
further leverages a graph database to capture relationships between these
entities, improving both retrieval accuracy and contextual understanding. This
enhanced approach demonstrates significant improvements in performance for
domains that require precise information retrieval, such as Material Science.

æè¦ï¼å¨ææç§å­¸é åï¼ææçè³è¨æª¢ç´¢ç³»çµ±å°æ¼ä¿é²ç ç©¶è³ééè¦ãå¤§åèªè¨æ¨¡å (LLM) ä¸­çå³çµ±æª¢ç´¢å¢å¼·çæ (RAG) æ¹æ³éå¸¸æéå°ææ°ï¼ä¾å¦éæçè³è¨ãå¹»è¦ºãç±æ¼ä¸ä¸æéå¶èå°è´çå¯è§£éæ§æéï¼ä»¥åæª¢ç´¢ä¸æºç¢ºãçºäºè§£æ±ºéäºåé¡ï¼Graph RAG æ´åäºåå½¢è³æåº«ä»¥å¢å¼·æª¢ç´¢éç¨ãæåæåºçæ¹æ³ééå¾å¥å­ä¸­èåééµå¯¦é« (ç¨±çº MatID) ä¾èçææç§å­¸æä»¶ï¼ç¶å¾å©ç¨éäºå¯¦é«æ¥è©¢å¤é¨çç¶­åºç¾ç§ç¥è­åº« (KB) ä»¥åå¾å¶ä»ç¸éè³è¨ãæåå¯¦ä½äºä¸ç¨®åºæ¼ä»£ççè§£ææè¡ï¼ä»¥éææ´è©³ç´°çæä»¶è¡¨ç¤ºãæåæ¹è¯çæ¬ç Graph RAGï¼ç¨±çº G-RAGï¼é²ä¸æ­¥å©ç¨åå½¢è³æåº«ä¾æ·åéäºå¯¦é«ä¹éçéä¿ï¼é²èæ¹åæª¢ç´¢æºç¢ºåº¦åèçµ¡çè§£ãéç¨®å¢å¼·çæ¹æ³å¨éè¦ç²¾ç¢ºè³è¨æª¢ç´¢çé åï¼ä¾å¦ææç§å­¸ï¼ä¸­ï¼å±ç¾äºé¡¯èçæè½æåã

##### **Knowledge Graphs, Large Language Models, and Hallucinations: An NLP Perspective**
2411.14258v1 by Ernests Lavrinovics, Russa Biswas, Johannes Bjerva, Katja Hose

Large Language Models (LLMs) have revolutionized Natural Language Processing
(NLP) based applications including automated text generation, question
answering, chatbots, and others. However, they face a significant challenge:
hallucinations, where models produce plausible-sounding but factually incorrect
responses. This undermines trust and limits the applicability of LLMs in
different domains. Knowledge Graphs (KGs), on the other hand, provide a
structured collection of interconnected facts represented as entities (nodes)
and their relationships (edges). In recent research, KGs have been leveraged to
provide context that can fill gaps in an LLM understanding of certain topics
offering a promising approach to mitigate hallucinations in LLMs, enhancing
their reliability and accuracy while benefiting from their wide applicability.
Nonetheless, it is still a very active area of research with various unresolved
open problems. In this paper, we discuss these open challenges covering
state-of-the-art datasets and benchmarks as well as methods for knowledge
integration and evaluating hallucinations. In our discussion, we consider the
current use of KGs in LLM systems and identify future directions within each of
these challenges.

æè¦ï¼å¤§åèªè¨æ¨¡åï¼LLMï¼å¾¹åºæ¹è®äºåºæ¼èªç¶èªè¨èçï¼NLPï¼çæç¨ï¼åæ¬èªåæå­çæãåé¡è§£ç­ãèå¤©æ©å¨äººç­ãç¶èï¼å®åé¢è¨èä¸åéå¤§çææ°ï¼å¹»è¦ºï¼æ¨¡åç¢çè½èµ·ä¾åçä½äºå¯¦ä¸ä¸æ­£ç¢ºçåæãéæç ´å£ä¿¡ä»»ï¼ä¸¦éå¶ LLM å¨ä¸åé åçé©ç¨æ§ãå¦ä¸æ¹é¢ï¼ç¥è­åè­ï¼KGï¼æä¾äºä»¥å¯¦é«ï¼ç¯é»ï¼åå¶éä¿ï¼éç·£ï¼è¡¨ç¤ºçç¸äºé£æ¥äºå¯¦ççµæ§åéåãå¨æè¿çç ç©¶ä¸­ï¼KG å·²è¢«ç¨æ¼æä¾ä¸ä¸æï¼å¯ä»¥å¡«è£ LLM å°æäºä¸»é¡çè§£çç©ºç½ï¼æä¾äºä¸ç¨®æå¸æçæ¹æ³ä¾æ¸è¼ LLM ä¸­çå¹»è¦ºï¼æé«å®åçå¯é æ§åæºç¢ºæ§ï¼åæåçæ¼å®åçå»£æ³é©ç¨æ§ãåç®¡å¦æ­¤ï¼éä»ç¶æ¯ä¸åéå¸¸æ´»èºçç ç©¶é åï¼æåç¨®æªè§£æ±ºçéæ¾åé¡ãå¨æ¬æä¸­ï¼æåè¨è«äºéäºéæ¾ææ°ï¼æ¶µèäºæåé²çæ¸æéååºæºï¼ä»¥åç¥è­æ´ååè©ä¼°å¹»è¦ºçæ¹æ³ãå¨æåçè¨è«ä¸­ï¼æåèæ®äº LLM ç³»çµ±ä¸­ KG çç¶åä½¿ç¨ï¼ä¸¦ç¢ºå®äºéäºææ°ä¸­çæ¯ä¸åæªä¾çæ¹åã

##### **Logic Augmented Generation**
2411.14012v1 by Aldo Gangemi, Andrea Giovanni Nuzzolese

Semantic Knowledge Graphs (SKG) face challenges with scalability,
flexibility, contextual understanding, and handling unstructured or ambiguous
information. However, they offer formal and structured knowledge enabling
highly interpretable and reliable results by means of reasoning and querying.
Large Language Models (LLMs) overcome those limitations making them suitable in
open-ended tasks and unstructured environments. Nevertheless, LLMs are neither
interpretable nor reliable. To solve the dichotomy between LLMs and SKGs we
envision Logic Augmented Generation (LAG) that combines the benefits of the two
worlds. LAG uses LLMs as Reactive Continuous Knowledge Graphs that can generate
potentially infinite relations and tacit knowledge on-demand. SKGs are key for
injecting a discrete heuristic dimension with clear logical and factual
boundaries. We exemplify LAG in two tasks of collective intelligence, i.e.,
medical diagnostics and climate projections. Understanding the properties and
limitations of LAG, which are still mostly unknown, is of utmost importance for
enabling a variety of tasks involving tacit knowledge in order to provide
interpretable and effective results.

æè¦ï¼èªæç¥è­åï¼SKGï¼å¨å¯æ´åæ§ãéæ´»æ§ãæå¢çè§£ä»¥åèçéçµæ§åæå«ç³è³è¨æ¹é¢é¢è¨ææ°ãç¶èï¼å®åæä¾æ­£å¼ä¸çµæ§åçç¥è­ï¼è½ééæ¨çåæ¥è©¢æä¾é«åº¦å¯è§£éä¸å¯é ççµæãå¤§åèªè¨æ¨¡åï¼LLMï¼åæäºéäºéå¶ï¼ä½¿å¶é©ç¨æ¼éæ¾å¼ä»»ååéçµæ§åç°å¢ãåç®¡å¦æ­¤ï¼LLM æ¢ä¸å¯è§£éä¹ä¸å¯é ãçºäºè§£æ±º LLM å SKG ä¹éçäºåæ³ï¼æåè¨­æ³äºéè¼¯å¢å¼·çæï¼LAGï¼ï¼å®çµåäºå©åä¸ççåªé»ãLAG ä½¿ç¨ LLM ä½çºåæå¼é£çºç¥è­åï¼å®å¯ä»¥æéç¢çæ½å¨çç¡ééä¿åé»æç¥è­ãSKG æ¯æ³¨å¥é¢æ£åç¼å¼ç¶­åº¦ï¼å·ææç¢ºéè¼¯åäºå¯¦éçï¼çééµãæåå¨éé«æºæ§çå©åä»»åä¸­èä¾èªªæ LAGï¼å³é«çè¨ºæ·åæ°£åé æ¸¬ãçè§£ LAG çç¹æ§åéå¶ï¼ç®åä»ç¶å¤§å¤æ¸æªç¥ï¼å°æ¼åç¨æ¶åé»æç¥è­çåç¨®ä»»åä»¥æä¾å¯è§£éä¸ææççµæè³ééè¦ã

##### **FastRAG: Retrieval Augmented Generation for Semi-structured Data**
2411.13773v1 by Amar Abane, Anis Bekri, Abdella Battou

Efficiently processing and interpreting network data is critical for the
operation of increasingly complex networks. Recent advances in Large Language
Models (LLM) and Retrieval-Augmented Generation (RAG) techniques have improved
data processing in network management. However, existing RAG methods like
VectorRAG and GraphRAG struggle with the complexity and implicit nature of
semi-structured technical data, leading to inefficiencies in time, cost, and
retrieval. This paper introduces FastRAG, a novel RAG approach designed for
semi-structured data. FastRAG employs schema learning and script learning to
extract and structure data without needing to submit entire data sources to an
LLM. It integrates text search with knowledge graph (KG) querying to improve
accuracy in retrieving context-rich information. Evaluation results demonstrate
that FastRAG provides accurate question answering, while improving up to 90% in
time and 85% in cost compared to GraphRAG.

æè¦ï¼ææçå°èçåè§£è®ç¶²è·¯è³æå°æ¼æ¥çè¤éçç¶²è·¯æä½è³ééè¦ãå¤§åèªè¨æ¨¡å (LLM) åæª¢ç´¢å¢å¼·ç¢ç (RAG) æè¡çææ°é²å±å·²ç¶æ¹åäºç¶²è·¯ç®¡çä¸­çè³æèçãç¶èï¼ç¾æç RAG æ¹æ³ï¼ä¾å¦ VectorRAG å GraphRAGï¼é£ä»¥æä»åçµæ§åæè¡è³æçè¤éæ§åé±å«æ§è³ªï¼å°è´æéãææ¬åæª¢ç´¢æçä¸å½°ãæ¬æä»ç´¹ FastRAGï¼ä¸ç¨®å°çºåçµæ§åè³æè¨­è¨çæ°ç© RAG æ¹æ³ãFastRAG ä½¿ç¨æ¶æ§å­¸ç¿åè³æ¬å­¸ç¿ä¾èååå»ºæ§è³æï¼èç¡éå°æ´åè³æä¾æºæäº¤çµ¦ LLMãå®å°æå­æå°èç¥è­åè­ (KG) æ¥è©¢æ´åï¼ä»¥æé«æª¢ç´¢å§å®¹è±å¯è³è¨çæºç¢ºæ§ãè©ä¼°çµæè­æï¼FastRAG æä¾äºæºç¢ºçåç­ï¼åæè GraphRAG ç¸æ¯ï¼æéæ¹åäº 90%ï¼ææ¬æ¹åäº 85%ã

##### **Predictive Insights into LGBTQ+ Minority Stress: A Transductive Exploration of Social Media Discourse**
2411.13534v1 by S. Chapagain, Y. Zhao, T. K. Rohleen, S. M. Hamdi, S. F. Boubrahimi, R. E. Flinn, E. M. Lund, D. Klooster, J. R. Scheer, C. J. Cascalheira

Individuals who identify as sexual and gender minorities, including lesbian,
gay, bisexual, transgender, queer, and others (LGBTQ+) are more likely to
experience poorer health than their heterosexual and cisgender counterparts.
One primary source that drives these health disparities is minority stress
(i.e., chronic and social stressors unique to LGBTQ+ communities' experiences
adapting to the dominant culture). This stress is frequently expressed in
LGBTQ+ users' posts on social media platforms. However, these expressions are
not just straightforward manifestations of minority stress. They involve
linguistic complexity (e.g., idiom or lexical diversity), rendering them
challenging for many traditional natural language processing methods to detect.
In this work, we designed a hybrid model using Graph Neural Networks (GNN) and
Bidirectional Encoder Representations from Transformers (BERT), a pre-trained
deep language model to improve the classification performance of minority
stress detection. We experimented with our model on a benchmark social media
dataset for minority stress detection (LGBTQ+ MiSSoM+). The dataset is
comprised of 5,789 human-annotated Reddit posts from LGBTQ+ subreddits. Our
approach enables the extraction of hidden linguistic nuances through
pretraining on a vast amount of raw data, while also engaging in transductive
learning to jointly develop representations for both labeled training data and
unlabeled test data. The RoBERTa-GCN model achieved an accuracy of 0.86 and an
F1 score of 0.86, surpassing the performance of other baseline models in
predicting LGBTQ+ minority stress. Improved prediction of minority stress
expressions on social media could lead to digital health interventions to
improve the wellbeing of LGBTQ+ people-a community with high rates of
stress-sensitive health problems.

æè¦ï¼<paragraph>èªåèªå·±æ¯æ§èæ§å¥å°æ¸æç¾¤çäººï¼åæ¬å¥³åæ§æãç·åæ§æãéæ§æãè·¨æ§å¥ãé·ååå¶ä» LGBTQ+ æç¾¤ï¼æ¯ç°æ§æåé æ§å¥èæ´å®¹ææè¼å·®çå¥åº·çæ³ãé æéäºå¥åº·å·®ç°çä¸»è¦ä¾æºä¹ä¸æ¯å°æ¸æç¾¤å£åï¼å³ LGBTQ+ ç¤¾ç¾¤å¨é©æä¸»æµæåæç¨æçæ¢æ§èç¤¾æå£åï¼ãéç¨®å£åç¶å¸¸å¨ LGBTQ+ ä½¿ç¨èæ¼ç¤¾ç¾¤åªé«å¹³å°ä¸çè²¼æä¸­è¡¨éåºä¾ãç¶èï¼éäºè¡¨éä¸¦ä¸ååæ¯å°æ¸æç¾¤å£åçç´æ¥è¡¨ç¾ãå®ååå«äºèªè¨è¤éæ§ï¼ä¾å¦æ£ç¨èªæè©å½å¤æ¨£æ§ï¼ï¼è®è¨±å¤å³çµ±çèªç¶èªè¨èçæ¹æ³é£ä»¥è¾¨è­ãå¨éé ç ç©¶ä¸­ï¼æåè¨­è¨äºä¸åæ··åæ¨¡åï¼ä½¿ç¨åç¥ç¶ç¶²è·¯ (GNN) åä¾èª Transformer çéåç·¨ç¢¼å¨è¡¨å¾µ (BERT)ï¼éæ¯ä¸åç¶éé åè¨ç·´çæ·±åº¦èªè¨æ¨¡åï¼ä»¥æåå°æ¸æç¾¤å£åè¾¨è­çåé¡æè½ãæåå¨ä¸åç¨æ¼å°æ¸æç¾¤å£åè¾¨è­çåºæºç¤¾ç¾¤åªé«è³æé (LGBTQ+ MiSSoM+) ä¸å°æåçæ¨¡åé²è¡å¯¦é©ãè©²è³æéåå«äº 5,789 ç¯ç±äººé¡è¨»è§£ç Reddit è²¼æï¼ä¾èªæ¼ LGBTQ+ ç subredditãæåçåæ³è½å¤ ééå¨å¤§éçåå§è³æä¸é²è¡é è¨ç·´ä¾èåé±èçèªè¨å·®ç°ï¼åæä¹åèè½å°å¼å­¸ç¿ï¼ä»¥å±åéç¼æ¨ç±¤è¨ç·´è³æåæªæ¨ç±¤æ¸¬è©¦è³æçè¡¨å¾µãRoBERTa-GCN æ¨¡åéå°äº 0.86 çæºç¢ºçå 0.86 ç F1 åæ¸ï¼å¨é æ¸¬ LGBTQ+ å°æ¸æç¾¤å£åæ¹é¢è¶è¶äºå¶ä»åºç·æ¨¡åçæè½ãå¨ç¤¾ç¾¤åªé«ä¸å°å°æ¸æç¾¤å£åè¡¨éçé æ¸¬æ¹åï¼å¯ä»¥å°è´æ¸ä½å¥åº·ä»å¥æªæ½ï¼ä»¥æ¹å LGBTQ+ æç¾¤çç¦ç¥ï¼èéåæç¾¤æå¾é«çå£åæææ§å¥åº·åé¡ç¼ççã</paragraph>

##### **KAAE: Numerical Reasoning for Knowledge Graphs via Knowledge-aware Attributes Learning**
2411.12950v2 by Ming Yin, Qiang Zhou, Zongsheng Cao, Mei Li

Numerical reasoning is pivotal in various artificial intelligence
applications, such as natural language processing and recommender systems,
where it involves using entities, relations, and attribute values (e.g.,
weight, length) to infer new factual relations (e.g., the Nile is longer than
the Amazon). However, existing approaches encounter two critical challenges in
modeling: (1) semantic relevance-the challenge of insufficiently capturing the
necessary contextual interactions among entities, relations, and numerical
attributes, often resulting in suboptimal inference; and (2) semantic
ambiguity-the difficulty in accurately distinguishing ordinal relationships
during numerical reasoning, which compromises the generation of high-quality
samples and limits the effectiveness of contrastive learning. To address these
challenges, we propose the novel Knowledge-Aware Attributes Embedding model
(KAAE) for knowledge graph embeddings in numerical reasoning. Specifically, to
overcome the challenge of semantic relevance, we introduce a
Mixture-of-Experts-Knowledge-Aware (MoEKA) Encoder, designed to integrate the
semantics of entities, relations, and numerical attributes into a joint
semantic space. To tackle semantic ambiguity, we implement a new ordinal
knowledge contrastive learning (OKCL) strategy that generates high-quality
ordinal samples from the original data with the aid of ordinal relations,
capturing fine-grained semantic nuances essential for accurate numerical
reasoning. Experiments on three public benchmark datasets demonstrate the
superior performance of KAAE across various attribute value distributions.

æè¦ï¼æ¸å¼æ¨çå¨åç¨®äººå·¥æºæ§æç¨ä¸­è³ééè¦ï¼ä¾å¦èªç¶èªè¨èçåæ¨è¦ç³»çµ±ï¼å¶ä¸­æ¶åä½¿ç¨å¯¦é«ãéä¿åå±¬æ§å¼ï¼ä¾å¦ï¼ééãé·åº¦ï¼ä¾æ¨è«æ°çäºå¯¦éä¿ï¼ä¾å¦ï¼å°¼ç¾æ²³æ¯äºé¦¬éæ²³é·ï¼ãç¶èï¼ç¾ææ¹æ³å¨å»ºæ¨¡ä¸­éå°å©åééµææ°ï¼ï¼1ï¼èªç¾©ç¸éæ§ - ç¡æ³ååææå¯¦é«ãéä¿åæ¸å¼å±¬æ§ä¹éå¿è¦çä¸ä¸æäº¤äºçææ°ï¼éå¸¸å°è´æ¬¡åªæ¨çï¼ä»¥åï¼2ï¼èªç¾©æ­§ç¾© - å¨æ¸å¼æ¨çæéæºç¢ºåååºæ¸éä¿çé£åº¦ï¼éææå®³é«åè³ªæ¨£æ¬çç¢çä¸¦éå¶å°æ¯å­¸ç¿çæææ§ãçºäºæå°éäºææ°ï¼æåæåºäºç¨æ¼æ¸å¼æ¨ççç¥è­åè­åµå¥çæ°åç¥è­æç¥å±¬æ§åµå¥æ¨¡å (KAAE)ãå·é«ä¾èªªï¼çºäºåæèªç¾©ç¸éæ§çææ°ï¼æåå¼å¥äºä¸åæ··åå°å®¶ç¥è­æç¥ (MoEKA) ç·¨ç¢¼å¨ï¼æ¨å¨å°å¯¦é«ãéä¿åæ¸å¼å±¬æ§çèªç¾©æ´åå°ä¸åè¯åèªç¾©ç©ºéä¸­ãçºäºæå°èªç¾©æ­§ç¾©ï¼æåå¯¦æ½äºä¸ç¨®æ°çåºæ¸ç¥è­å°æ¯å­¸ç¿ (OKCL) ç­ç¥ï¼è©²ç­ç¥å©ç¨åºæ¸éä¿å¾åå§æ¸æä¸­çæé«åè³ªåºæ¸æ¨£æ¬ï¼ææå°æºç¢ºæ¸å¼æ¨çè³ééè¦çç´°ç·»èªç¾©å·®ç°ãå¨ä¸åå¬éåºæºæ¸æéä¸çå¯¦é©è­æäº KAAE å¨åç¨®å±¬æ§å¼åä½ä¸­çåªç°æ§è½ã

##### **Neurosymbolic Graph Enrichment for Grounded World Models**
2411.12671v1 by Stefano De Giorgis, Aldo Gangemi, Alessandro Russo

The development of artificial intelligence systems capable of understanding
and reasoning about complex real-world scenarios is a significant challenge. In
this work we present a novel approach to enhance and exploit LLM reactive
capability to address complex problems and interpret deeply contextual
real-world meaning. We introduce a method and a tool for creating a multimodal,
knowledge-augmented formal representation of meaning that combines the
strengths of large language models with structured semantic representations.
Our method begins with an image input, utilizing state-of-the-art large
language models to generate a natural language description. This description is
then transformed into an Abstract Meaning Representation (AMR) graph, which is
formalized and enriched with logical design patterns, and layered semantics
derived from linguistic and factual knowledge bases. The resulting graph is
then fed back into the LLM to be extended with implicit knowledge activated by
complex heuristic learning, including semantic implicatures, moral values,
embodied cognition, and metaphorical representations. By bridging the gap
between unstructured language models and formal semantic structures, our method
opens new avenues for tackling intricate problems in natural language
understanding and reasoning.

æè¦ï¼äººå·¥æºè½ç³»çµ±çç¼å±è½å¤ çè§£ä¸¦æ¨çè¤éççå¯¦ä¸çå ´æ¯æ¯ä¸åéå¤§çææ°ãå¨éé å·¥ä½ä¸­ï¼æåæåºäºä¸ç¨®æ°ç©çæ¹æ³ä¾å¢å¼·åå©ç¨ LLM åæè½åï¼ä»¥è§£æ±ºè¤éçåé¡ä¸¦è§£éæ·±å±¤çèªå¢çå¯¦ä¸çæç¾©ãæåä»ç´¹äºä¸ç¨®æ¹æ³åå·¥å·ï¼ç¨æ¼å»ºç«å¤æ¨¡æãç¥è­å¢å¼·çæç¾©å½¢å¼åè¡¨ç¤ºï¼çµåäºå¤§åèªè¨æ¨¡åèçµæ§åèªç¾©è¡¨ç¤ºçåªé»ãæåçæ¨¡åå¾å½±åè¼¸å¥éå§ï¼å©ç¨æåé²çå¤§åèªè¨æ¨¡åä¾ç¢çèªç¶èªè¨æè¿°ãç¶å¾å°æ­¤æè¿°è½æçºæ½è±¡æç¾©è¡¨ç¤º (AMR) åå½¢ï¼ä¸¦ä½¿ç¨éè¼¯è¨­è¨æ¨¡å¼é²è¡å½¢å¼ååè±å¯ï¼ä»¥åå¾èªè¨åäºå¯¦ç¥è­åº«ä¸­è¡ççåå±¤èªç¾©ãç¶å¾å°çµæåå½¢åé¥å° LLMï¼ä»¥æ´å LLM ä¸­ç±è¤éçåç¼å¼å­¸ç¿æåç¨çå§é±ç¥è­ï¼åæ¬èªç¾©èæ¶µãéå¾·å¹å¼ãå·èº«èªç¥åé±å»è¡¨ç¤ºãæåçæ¨¡åééå½åéçµæ§åèªè¨æ¨¡åèå½¢å¼èªç¾©çµæ§ä¹éçå·®è·ï¼çºè§£æ±ºèªç¶èªè¨çè§£åæ¨çä¸­çè¤éåé¡éé¢äºæ°çéå¾ã

##### **Instant Policy: In-Context Imitation Learning via Graph Diffusion**
2411.12633v1 by Vitalis Vosylius, Edward Johns

Following the impressive capabilities of in-context learning with large
transformers, In-Context Imitation Learning (ICIL) is a promising opportunity
for robotics. We introduce Instant Policy, which learns new tasks instantly
(without further training) from just one or two demonstrations, achieving ICIL
through two key components. First, we introduce inductive biases through a
graph representation and model ICIL as a graph generation problem with a
learned diffusion process, enabling structured reasoning over demonstrations,
observations, and actions. Second, we show that such a model can be trained
using pseudo-demonstrations - arbitrary trajectories generated in simulation -
as a virtually infinite pool of training data. Simulated and real experiments
show that Instant Policy enables rapid learning of various everyday robot
tasks. We also show how it can serve as a foundation for cross-embodiment and
zero-shot transfer to language-defined tasks. Code and videos are available at
https://www.robot-learning.uk/instant-policy.

æè¦ï¼ç¹¼å¤§åTransformerå¨æå¢å­¸ç¿ä¸­è¡¨ç¾åºä»¤äººå°è±¡æ·±å»çè½åå¾ï¼æå¢æ¨¡ä»¿å­¸ç¿ (ICIL) æçºäºæ©å¨äººé åä¸­ä¸åæåéçæ©æãæåå¼å¥äºå³æç­ç¥ï¼å®åå¾ä¸æå©æ¬¡ç¤ºç¯ä¸­ç«å³å­¸ç¿æ°ä»»åï¼ç¡éé²ä¸æ­¥è¨ç·´ï¼ï¼ä¸¦ééå©åééµçµæé¨åå¯¦ç¾ ICILãé¦åï¼æåééåå½¢è¡¨ç¤ºåæ¨¡å ICIL å¼å¥æ­¸ç´åå·®ï¼ä¸¦å°å¶ä½çºå·æå­¸ç¿æ´æ£éç¨çåå½¢çæåé¡ï¼å¾èè½å¤ å°ç¤ºç¯ãè§å¯ååä½é²è¡çµæ§åæ¨çãå¶æ¬¡ï¼æåå±ç¤ºäºéç¨®æ¨¡åå¯ä»¥ä½¿ç¨å½ç¤ºç¯é²è¡è¨ç·´ï¼èå½ç¤ºç¯æ¯æ¨¡æ¬ä¸­ç¢ççä»»æè»è·¡ï¼å¯ç¨ä½å¹¾ä¹ç¡éçè¨ç·´æ¸ææ± ãæ¨¡æ¬åçå¯¦å¯¦é©è¡¨æï¼å³æç­ç¥è½å¤ å¿«éå­¸ç¿åç¨®æ¥å¸¸æ©å¨äººä»»åãæåéå±ç¤ºäºå®å¦ä½ä½çºè·¨å·èº«åé¶æ¬¡å³è¼¸å°èªè¨å®ç¾©ä»»åçåºç¤ãä»£ç¢¼åå½±çå¯å¨ https://www.robot-learning.uk/instant-policy åå¾ã

##### **Bias-Free Sentiment Analysis through Semantic Blinding and Graph Neural Networks**
2411.12493v2 by Hubert Plisiecki

This paper introduces the Semantic Propagation Graph Neural Network (SProp
GNN), a machine learning sentiment analysis (SA) architecture that relies
exclusively on syntactic structures and word-level emotional cues to predict
emotions in text. By semantically blinding the model to information about
specific words, it is robust to biases such as political or gender bias that
have been plaguing previous machine learning-based SA systems. The SProp GNN
shows performance superior to lexicon-based alternatives such as VADER and
EmoAtlas on two different prediction tasks, and across two languages.
Additionally, it approaches the accuracy of transformer-based models while
significantly reducing bias in emotion prediction tasks. By offering improved
explainability and reducing bias, the SProp GNN bridges the methodological gap
between interpretable lexicon approaches and powerful, yet often opaque, deep
learning models, offering a robust tool for fair and effective emotion analysis
in understanding human behavior through text.

æè¦ï¼æ¬æä»ç´¹äºèªç¾©å³æ­åç¥ç¶ç¶²è·¯ (SProp GNN)ï¼éæ¯ä¸ç¨®æ©å¨å­¸ç¿æç·åæ (SA) æ¶æ§ï¼å°éä¾è³´å¥æ³çµæ§åè©å½å±¤ç´çæç·ç·ç´¢ä¾é æ¸¬æå­ä¸­çæç·ãééå¨èªç¾©ä¸è®æ¨¡åå°ç¹å®å­è©çè³è¨è¦èä¸è¦ï¼å®è½æææ¶é¤æ¿æ²»ææ§å¥åè¦ç­åèª¤ï¼éäºåèª¤ä¸ç´å°æ¾èååçæ©å¨å­¸ç¿å¼ SA ç³»çµ±ãSProp GNN å¨å©é ä¸åçé æ¸¬ä»»ååå©ç¨®èªè¨ä¸çè¡¨ç¾é½åªæ¼åºæ¼è©å½åº«çæ¿ä»£æ¹æ¡ï¼ä¾å¦ VADER å EmoAtlasãæ­¤å¤ï¼å®å¨å¤§å¹æ¸å°æç·é æ¸¬ä»»åä¸­çåèª¤åæï¼ä¹æ¥è¿äºåºæ¼è½æå¨çæ¨¡åçæºç¢ºåº¦ãééæä¾æ´å¥½çå¯è§£éæ§ä¸¦æ¸å°åèª¤ï¼SProp GNN æ­èµ·äºå¯è©®éè©å½æ¹æ³èå¼·å¤§ä½ç¶å¸¸ä¸éæçæ·±åº¦å­¸ç¿æ¨¡åä¹éçæ¹æ³è«é´»æºï¼æä¾äºä¸åå¼·å¥çå·¥å·ï¼å¯ä»¥ééæå­çè§£äººé¡è¡çºï¼é²è¡å¬å¹³ä¸ææçåæã

##### **Neon: News Entity-Interaction Extraction for Enhanced Question Answering**
2411.12449v2 by Sneha Singhania, Silviu Cucerzan, Allen Herring, Sujay Kumar Jauhar

Capturing fresh information in near real-time and using it to augment
existing large language models (LLMs) is essential to generate up-to-date,
grounded, and reliable output. This problem becomes particularly challenging
when LLMs are used for informational tasks in rapidly evolving fields, such as
Web search related to recent or unfolding events involving entities, where
generating temporally relevant responses requires access to up-to-the-hour news
sources. However, the information modeled by the parametric memory of LLMs is
often outdated, and Web results from prototypical retrieval systems may fail to
capture the latest relevant information and struggle to handle conflicting
reports in evolving news. To address this challenge, we present the NEON
framework, designed to extract emerging entity interactions -- such as events
or activities -- as described in news articles. NEON constructs an
entity-centric timestamped knowledge graph that captures such interactions,
thereby facilitating enhanced QA capabilities related to news events. Our
framework innovates by integrating open Information Extraction (openIE) style
tuples into LLMs to enable in-context retrieval-augmented generation. This
integration demonstrates substantial improvements in QA performance when
tackling temporal, entity-centric search queries. Through NEON, LLMs can
deliver more accurate, reliable, and up-to-date responses.

æè¦ï¼ææè¿ä¹å¯¦æçææ°è³è¨ï¼ä¸¦å©ç¨å®ä¾æ´åç¾æçå¤§åèªè¨æ¨¡å (LLM)ï¼å°æ¼ç¢çå³æãææ ¹æä¸å¯é çè¼¸åºè³ééè¦ãç¶ LLM è¢«ç¨æ¼å¿«éæ¼åçé åä¸­çè¨æ¯ä»»åæï¼éååé¡æè®å¾ç¹å¥å·æææ°æ§ï¼ä¾å¦èæ¶åå¯¦é«çè¿æææ­£å¨ç¼ççäºä»¶ç¸éçç¶²è·¯æå°ï¼å¨éç¨®ææ³ä¸ï¼ç¢çæéç¸éçåæéè¦åå¾ææ°çæ°èä¾æºãç¶èï¼LLM çåæ¸è¨æ¶é«å»ºæ¨¡çè³è¨ç¶å¸¸éæï¼èååæª¢ç´¢ç³»çµ±çç¶²è·¯çµæå¯è½ç¡æ³ææææ°çç¸éè³è¨ï¼ä¸¦ä¸é£ä»¥èçæ¼åä¸­çæ°èä¸­çç¸äºçç¾çå ±å°ãçºäºæå°éåææ°ï¼æåæåºäº NEON æ¡æ¶ï¼æ¨å¨èåæ°èå¯¦é«äºåï¼ä¾å¦äºä»¶ææ´»åï¼ï¼å¦æ°èæç« ä¸­ææè¿°çãNEON å»ºæ§äºä¸åä»¥å¯¦é«çºä¸­å¿çå¸¶æéæ³è¨çç¥è­åè­ï¼ç¨ä¾æææ­¤é¡äºåï¼å¾èä¿é²èæ°èäºä»¶ç¸éçå¢å¼·å¼åç­è½åãæåçæ¡æ¶ééå°éæ¾è³è¨èå (openIE) é¢¨æ ¼åçµæ´åå° LLM ä¸­ï¼ä»¥åç¨æå¢å§æª¢ç´¢å¢å¼·å¼ç¢çï¼é²èåµæ°ãç¶èçæéãä»¥å¯¦é«çºä¸­å¿çæå°æ¥è©¢æï¼éç¨®æ´åé¡¯ç¤ºåºåç­æè½çé¡¯èæåãéé NEONï¼LLM å¯ä»¥æä¾æ´æºç¢ºãå¯é ä¸ææ°çåæã

##### **GRL-Prompt: Towards Knowledge Graph based Prompt Optimization via Reinforcement Learning**
2411.14479v1 by Yuze Liu, Tingjie Liu, Tiehua Zhang, Youhua Xia, Jinze Wang, Zhishu Shen, Jiong Jin, Fei Richard Yu

Large language models (LLMs) have demonstrated impressive success in a wide
range of natural language processing (NLP) tasks due to their extensive general
knowledge of the world. Recent works discovered that the performance of LLMs is
heavily dependent on the input prompt. However, prompt engineering is usually
done manually in a trial-and-error fashion, which can be labor-intensive and
challenging in order to find the optimal prompts. To address these problems and
unleash the utmost potential of LLMs, we propose a novel LLMs-agnostic
framework for prompt optimization, namely GRL-Prompt, which aims to
automatically construct optimal prompts via reinforcement learning (RL) in an
end-to-end manner. To provide structured action/state representation for
optimizing prompts, we construct a knowledge graph (KG) that better encodes the
correlation between the user query and candidate in-context examples.
Furthermore, a policy network is formulated to generate the optimal action by
selecting a set of in-context examples in a rewardable order to construct the
prompt. Additionally, the embedding-based reward shaping is utilized to
stabilize the RL training process. The experimental results show that
GRL-Prompt outperforms recent state-of-the-art methods, achieving an average
increase of 0.10 in ROUGE-1, 0.07 in ROUGE-2, 0.07 in ROUGE-L, and 0.05 in
BLEU.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å¨å»£æ³çèªç¶èªè¨èç (NLP) ä»»åä¸­å±ç¾åºä»¤äººå°è±¡æ·±å»çæåï¼éæ­¸åæ¼å®åå°ä¸ççå»£æ³ä¸è¬ç¥è­ãæè¿çç ç©¶ç¼ç¾ï¼LLM çæè½é«åº¦ä¾è³´æ¼è¼¸å¥æç¤ºãç¶èï¼æç¤ºå·¥ç¨éå¸¸ä»¥è©¦é¯çæ¹å¼æåå®æï¼éå¨å°æ¾æä½³æç¤ºæå¯è½æèè²»å¤§éäººåä¸å·æææ°æ§ãçºäºè§£æ±ºéäºåé¡ä¸¦ç¼æ® LLM çæå¤§æ½åï¼æåæåºäºä¸åæ°ç LLM ä¸å¯ç¥æ¡æ¶ï¼ç¨æ¼æç¤ºæä½³åï¼å³ GRL-Promptï¼å¶æ¨å¨ééå¼·åå­¸ç¿ (RL) ä»¥ç«¯å°ç«¯çæ¹å¼èªåå»ºæ§æä½³æç¤ºãçºäºæä¾çµæ§åçåä½/çæè¡¨ç¤ºä»¥æä½³åæç¤ºï¼æåå»ºæ§äºä¸åç¥è­åè­ (KG)ï¼å®è½æ´å¥½å°ç·¨ç¢¼ä½¿ç¨èæ¥è©¢èåé¸æå¢ç¯ä¾ä¹éçéè¯æ§ãæ­¤å¤ï¼æåå¶å®äºä¸åç­ç¥ç¶²è·¯ï¼ééä»¥å¯çåµçé åºé¸æä¸çµæå¢ç¯ä¾ä¾å»ºæ§æç¤ºï¼ä»¥ç¢çæä½³åä½ãæ­¤å¤ï¼æåå©ç¨åºæ¼åµå¥ççåµå¡é ä¾ç©©å® RL è¨ç·´éç¨ãå¯¦é©çµæé¡¯ç¤ºï¼GRL-Prompt åªæ¼æè¿çææ°æ¹æ³ï¼å¨ ROUGE-1 ä¸­å¹³åå¢å  0.10ï¼å¨ ROUGE-2 ä¸­å¢å  0.07ï¼å¨ ROUGE-L ä¸­å¢å  0.07ï¼å¨ BLEU ä¸­å¢å  0.05ã

##### **Just KIDDIN: Knowledge Infusion and Distillation for Detection of INdecent Memes**
2411.12174v1 by Rahul Garg, Trilok Padhi, Hemang Jain, Ugur Kursuncu, Ponnurangam Kumaraguru

Toxicity identification in online multimodal environments remains a
challenging task due to the complexity of contextual connections across
modalities (e.g., textual and visual). In this paper, we propose a novel
framework that integrates Knowledge Distillation (KD) from Large Visual
Language Models (LVLMs) and knowledge infusion to enhance the performance of
toxicity detection in hateful memes. Our approach extracts sub-knowledge graphs
from ConceptNet, a large-scale commonsense Knowledge Graph (KG) to be infused
within a compact VLM framework. The relational context between toxic phrases in
captions and memes, as well as visual concepts in memes enhance the model's
reasoning capabilities. Experimental results from our study on two hate speech
benchmark datasets demonstrate superior performance over the state-of-the-art
baselines across AU-ROC, F1, and Recall with improvements of 1.1%, 7%, and 35%,
respectively. Given the contextual complexity of the toxicity detection task,
our approach showcases the significance of learning from both explicit (i.e.
KG) as well as implicit (i.e. LVLMs) contextual cues incorporated through a
hybrid neurosymbolic approach. This is crucial for real-world applications
where accurate and scalable recognition of toxic content is critical for
creating safer online environments.

æè¦ï¼ç¶²è·¯å¤æ¨¡æç°å¢ä¸­çæ¯æ§è¾¨è­ï¼ç±æ¼æ¨¡æéï¼ä¾å¦æå­åè¦è¦ºï¼çèçµ¡éè¯è¤éï¼å æ­¤ä»æ¯ä¸é å·æææ°æ§çä»»åãå¨æ¬æä¸­ï¼æåæåºä¸åæ°ç©çæ¶æ§ï¼æ´åä¾èªå¤§åè¦è¦ºèªè¨æ¨¡å (LVLMs) çç¥è­è¸é¤¾ (KD) åç¥è­æ³¨å¥ï¼ä»¥å¢å¼·ä»æ¨è¿·å ä¸­æ¯æ§åµæ¸¬çæè½ãæåçåæ³å¾ ConceptNetï¼ä¸åå¤§åå¸¸è­ç¥è­åè­ (KG)ï¼ä¸­èåå­ç¥è­åï¼ä¸¦æ³¨å¥å°ä¸åç·æ¹ç VLM æ¶æ§ä¸­ãæ¨é¡åè¿·å ä¸­å·ææ¯æ§çè©å½ä¹éçéä¿èçµ¡ï¼ä»¥åè¿·å ä¸­çè¦è¦ºæ¦å¿µï¼å¢å¼·äºæ¨¡åçæ¨çè½åãæåå¨å©åä»æ¨è¨è«åºæºè³æéä¸é²è¡çç ç©¶çå¯¦é©çµæï¼è­æäºå¨ AU-ROCãF1 åå¬åçæ¹é¢ï¼æåçåæ³åªæ¼æåé²çåºæºï¼åå¥æåäº 1.1%ã7% å 35%ãéæ¼æ¯æ§åµæ¸¬ä»»åçèçµ¡è¤éæ§ï¼æåçåæ³å±ç¤ºäºå¾æç¢ºï¼ä¾å¦ KGï¼åé±å«ï¼ä¾å¦ LVLMsï¼èçµ¡ç·ç´¢ä¸­å­¸ç¿ï¼ä¸¦ééæ··åç¥ç¶ç¬¦èæ¹æ³æ´åèµ·ä¾çéè¦æ§ãéå°æ¼çå¯¦ä¸ççæç¨è³ééè¦ï¼å¨éäºæç¨ä¸­ï¼æºç¢ºä¸å¯æ´åçæ¯æ§å§å®¹è¾¨è­å°æ¼åµé æ´å®å¨çç¶²è·¯ç°å¢è³ééè¦ã

##### **Regret-Free Reinforcement Learning for LTL Specifications**
2411.12019v1 by Rupak Majumdar, Mahmoud Salamati, Sadegh Soudjani

Reinforcement learning (RL) is a promising method to learn optimal control
policies for systems with unknown dynamics. In particular, synthesizing
controllers for safety-critical systems based on high-level specifications,
such as those expressed in temporal languages like linear temporal logic (LTL),
presents a significant challenge in control systems research. Current RL-based
methods designed for LTL tasks typically offer only asymptotic guarantees,
which provide no insight into the transient performance during the learning
phase. While running an RL algorithm, it is crucial to assess how close we are
to achieving optimal behavior if we stop learning.
  In this paper, we present the first regret-free online algorithm for learning
a controller that addresses the general class of LTL specifications over Markov
decision processes (MDPs) with a finite set of states and actions. We begin by
proposing a regret-free learning algorithm to solve infinite-horizon
reach-avoid problems. For general LTL specifications, we show that the
synthesis problem can be reduced to a reach-avoid problem when the graph
structure is known. Additionally, we provide an algorithm for learning the
graph structure, assuming knowledge of a minimum transition probability, which
operates independently of the main regret-free algorithm.

æè¦ï¼å¼·åå­¸ç¿ (RL) æ¯ä¸ç¨®æå¸æçæ¹æ³ï¼å¯ä»¥å­¸ç¿æªç¥åæç³»çµ±çæä½³æ§å¶ç­ç¥ãç¹å¥æ¯ï¼åºæ¼é«éè¦ç¯ï¼ä¾å¦ç¨ç·æ§æåºéè¼¯ (LTL) ç­æåºèªè¨è¡¨éçè¦ç¯ï¼çºå®å¨ééµç³»çµ±åææ§å¶å¨ï¼éå¨æ§å¶ç³»çµ±ç ç©¶ä¸­æ¯ä¸åéå¤§ææ°ãç®åçåºæ¼ RL ç LTL ä»»åæ¹æ³éå¸¸åæä¾æ¼¸è¿ä¿è­ï¼éå¨å­¸ç¿éæ®µæ²ææä¾æ«ææè½çè¦è§£ãå¨å·è¡ RL æ¼ç®æ³æï¼å¦ææååæ­¢å­¸ç¿ï¼è©ä¼°æåè·é¢éææä½³è¡çºæå¤è¿è³ééè¦ãå¨æ¬æä¸­ï¼æåæåºäºç¬¬ä¸åç¡éºæ¾ç·ä¸æ¼ç®æ³ï¼ç¨æ¼å­¸ç¿ä¸åæ§å¶å¨ï¼è©²æ§å¶å¨è§£æ±ºäºé¦¬å¯å¤«æ±ºç­éç¨ (MDP) ä¸çä¸è¬é¡å¥ LTL è¦ç¯ï¼å¶ä¸­åå«æéççæååä½éåãæåé¦åæåºä¸åç¡éºæ¾å­¸ç¿æ¼ç®æ³ä¾è§£æ±ºç¡éæåå°éé¿ååé¡ãå°æ¼ä¸è¬ LTL è¦ç¯ï¼æåè¡¨æç¶åå½¢çµæ§å·²ç¥æï¼åæåé¡å¯ä»¥ç°¡åçºå°éé¿ååé¡ãæ­¤å¤ï¼æåæä¾äºä¸åæ¼ç®æ³ä¾å­¸ç¿åå½¢çµæ§ï¼åè¨­ç¥éæå°è½ç§»æ©çï¼å®ç¨ç«æ¼ä¸»è¦çç¡éºæ¾æ¼ç®æ³éä½ã

##### **Semantic-Geometric-Physical-Driven Robot Manipulation Skill Transfer via Skill Library and Tactile Representation**
2411.11714v1 by Mingchao Qi, Yuanjin Li, Xing Liu, Zhengxiong Liu, Panfeng Huang

Deploying robots in open-world environments involves complex tasks
characterized by long sequences and rich interactions, necessitating efficient
transfer of robotic skills across diverse and complex scenarios. To address
this challenge, we propose a skill library framework based on knowledge graphs,
which endows robots with high-level skill awareness and spatial semantic
understanding. The framework hierarchically organizes operational knowledge by
constructing a "task graph" and a "scene graph" to represent task and scene
semantic information, respectively. We introduce a "state graph" to facilitate
interaction between high-level task planning and low-level scene information.
Furthermore, we propose a hierarchical transfer framework for operational
skills. At the task level, the framework integrates contextual learning and
chain-of-thought prompting within a four-stage prompt paradigm, leveraging
large language models' (LLMs) reasoning and generalization capabilities to
achieve task-level subtask sequence transfer. At the motion level, an adaptive
trajectory transfer method is developed using the A* algorithm and the skill
library, enabling motion-level adaptive trajectory transfer. At the physical
level, we introduce an adaptive contour extraction and posture perception
method based on tactile perception. This method dynamically obtains
high-precision contour and posture information from visual-tactile texture data
and adjusts transferred skills, such as contact positions and postures, to
ensure effectiveness in new environments. Experimental results validate the
effectiveness of the proposed methods. Project
website:https://github.com/MingchaoQi/skill_transfer

æè¦ï¼<paragraph>å¨å¼æ¾ä¸çç¯å¢ä¸­é¨ç½²æºå¨äººæ¶åå¤æçä»»å¡ï¼å¶ç¹ç¹æ¯åºåé¿ãäº¤äºä¸°å¯ï¼éè¦å¨ä¸åä¸å¤æçåºæ¯ä¸­é«æå°è½¬ç§»æºå¨äººæè½ãä¸ºäºåºå¯¹è¿ä¸ææï¼æä»¬æåºä¸ä¸ªåºäºç¥è¯å¾è°±çæè½åºæ¡æ¶ï¼å®èµäºæºå¨äººé«çº§æè½æè¯åç©ºé´è¯­ä¹çè§£ãè¯¥æ¡æ¶éè¿æå»ºâä»»å¡å¾âåâåºæ¯å¾âæ¥åå±ç»ç»æä½ç¥è¯ï¼åå«è¡¨ç¤ºä»»å¡ååºæ¯è¯­ä¹ä¿¡æ¯ãæä»¬å¼å¥ä¸ä¸ªâç¶æå¾âæ¥ä¿è¿é«çº§ä»»å¡è§ååä½çº§åºæ¯ä¿¡æ¯ä¹é´çäº¤äºãæ­¤å¤ï¼æä»¬æåºäºä¸ä¸ªæä½æè½çåå±è½¬ç§»æ¡æ¶ãå¨ä»»å¡å±é¢ï¼è¯¥æ¡æ¶å¨ä¸ä¸ªåé¶æ®µæç¤ºèå¼ä¸­éæäºä¸ä¸æå­¦ä¹ åææ³é¾æç¤ºï¼å©ç¨å¤§è¯­è¨æ¨¡å (LLM) çæ¨çåæ³åè½åæ¥å®ç°ä»»å¡çº§å­ä»»å¡åºåè½¬ç§»ãå¨è¿å¨å±é¢ï¼ä½¿ç¨ A* ç®æ³åæè½åºå¼åäºä¸ç§èªéåºè½¨è¿¹è½¬ç§»æ¹æ³ï¼å®ç°è¿å¨çº§èªéåºè½¨è¿¹è½¬ç§»ãå¨ç©çå±é¢ï¼æä»¬å¼å¥äºä¸ç§åºäºè§¦è§æç¥çèªéåºè½®å»æååå§¿ææç¥æ¹æ³ãè¯¥æ¹æ³ä»è§è§è§¦è§çº¹çæ°æ®ä¸­å¨æè·åé«ç²¾åº¦çè½®å»åå§¿æä¿¡æ¯ï¼å¹¶è°æ´è½¬ç§»çæè½ï¼ä¾å¦æ¥è§¦ä½ç½®åå§¿æï¼ä»¥ç¡®ä¿å¨æ°çç¯å¢ä¸­ææãå®éªç»æéªè¯äºææåºæ¹æ³çæææ§ãé¡¹ç®ç½ç«ï¼https://github.com/MingchaoQi/skill_transfer</paragraph>

##### **Addressing Hallucinations in Language Models with Knowledge Graph Embeddings as an Additional Modality**
2411.11531v1 by Viktoriia Chekalina, Anton Razzigaev, Elizaveta Goncharova, Andrey Kuznetsov

In this paper we present an approach to reduce hallucinations in Large
Language Models (LLMs) by incorporating Knowledge Graphs (KGs) as an additional
modality. Our method involves transforming input text into a set of KG
embeddings and using an adapter to integrate these embeddings into the language
model space, without relying on external retrieval processes.
  To facilitate this, we created WikiEntities, a dataset containing over 3
million Wikipedia texts annotated with entities from Wikidata and their
corresponding embeddings from PyTorch-BigGraph. This dataset serves as a
valuable resource for training Entity Linking models and adapting the described
method to various LLMs using specialized adapters.
  Our method does not require fine-tuning of the language models themselves;
instead, we only train the adapter. This ensures that the model's performance
on other tasks is not affected. We trained an adapter for the Mistral 7B, LLaMA
2-7B (chat), and LLaMA 3-8B (instruct) models using this dataset and
demonstrated that our approach improves performance on the HaluEval, True-False
benchmarks and FEVER dataset. The results indicate that incorporating KGs as a
new modality can effectively reduce hallucinations and improve the factual
accuracy of language models, all without the need for external retrieval.

æè¦ï¼<paragraph>å¨æ¬æä¸­ï¼æåæåºäºä¸ç¨®æ¹æ³ï¼ééå°ç¥è­åè­ (KG) ä½çºéå æ¹å¼ç´å¥å¤§åèªè¨æ¨¡å (LLM)ï¼ä»¥æ¸å°å¹»è¦ºãæåçåæ³åæ¬å°è¼¸å¥æå­è½ææä¸çµ KG åµå¥ï¼ä¸¦ä½¿ç¨é©éå¨å°éäºåµå¥æ´åå°èªè¨æ¨¡åç©ºéï¼èç¡éä¾è³´å¤é¨æª¢ç´¢ç¨åºã
çºäºä¿é²éä¸é»ï¼æåå»ºç«äº WikiEntitiesï¼éæ¯ä¸ååå«è¶é 300 è¬åç¶­åºç¾ç§æå­çè³æéï¼å¶ä¸­éæä¾èª Wikidata çå¯¦é«è¨»è§£ï¼ä»¥åå®åä¾èª PyTorch-BigGraph çå°æåµå¥ãæ­¤è³æéä½çºè¨ç·´å¯¦é«é£çµæ¨¡ååä½¿ç¨å°éé©éå¨å°æè¿°æ¹æ³èª¿æ´å°åç¨® LLM çå¯¶è²´è³æºã
æåçåæ³ä¸éè¦å¾®èª¿èªè¨æ¨¡åæ¬èº«ï¼ç¸åï¼æååªè¨ç·´é©éå¨ãéç¢ºä¿äºæ¨¡åå¨å¶ä»ä»»åä¸çæè½ä¸åå½±é¿ãæåä½¿ç¨æ­¤è³æéè¨ç·´äº Mistral 7BãLLaMA 2-7B (èå¤©) å LLaMA 3-8B (æä»¤) æ¨¡åçé©éå¨ï¼ä¸¦è­æäºæåçåæ³æ¹åäº HaluEvalãçååºæºå FEVER è³æéçæè½ãçµæè¡¨æï¼å° KG ä½çºä¸ç¨®æ°æ¹å¼ç´å¥å¯ä»¥æææ¸å°å¹»è¦ºï¼ä¸¦æé«èªè¨æ¨¡åçäºå¯¦æºç¢ºæ§ï¼èç¡éå¤é¨æª¢ç´¢ã</paragraph>

##### **RPN 2: On Interdependence Function Learning Towards Unifying and Advancing CNN, RNN, GNN, and Transformer**
2411.11162v1 by Jiawei Zhang

This paper builds upon our previous work on the Reconciled Polynomial Network
(RPN). The original RPN model was designed under the assumption of input data
independence, presuming the independence among both individual instances within
data batches and attributes in each data instance. However, this assumption
often proves invalid for function learning tasks involving complex,
interdependent data such as language, images, time series, and graphs. Ignoring
such data interdependence may inevitably lead to significant performance
degradation.
  To overcome these limitations, we introduce the new Reconciled Polynomial
Network (version 2), namely RPN 2, in this paper. By incorporating data and
structural interdependence functions, RPN 2 explicitly models data
interdependence via new component functions in its architecture.
  This enhancement not only significantly improves RPN 2's learning performance
but also substantially expands its unifying potential, enabling it to encompass
a broader range of contemporary dominant backbone models within its canonical
representation. These backbones include, but are not limited to, convolutional
neural networks (CNNs), recurrent neural networks (RNNs), graph neural networks
(GNNs), and Transformers. Our analysis reveals that the fundamental
distinctions among these backbone models primarily stem from their diverse
approaches to defining the interdependence functions. Furthermore, this unified
representation opens up new opportunities for designing innovative
architectures with the potential to surpass the performance of these dominant
backbones.

æè¦ï¼æ¬æå»ºç«å¨æä»¬ååå³äºåè°å¤é¡¹å¼ç½ç» (RPN) çå·¥ä½ä¹ä¸ãæåç RPN æ¨¡åæ¯å¨è¾å¥æ°æ®ç¬ç«æ§çåè®¾ä¸è®¾è®¡çï¼åå®æ°æ®æ¹æ¬¡ä¸­åä¸ªå®ä¾ä¹é´çç¬ç«æ§ä»¥åæ¯ä¸ªæ°æ®å®ä¾ä¸­çå±æ§ä¹é´çç¬ç«æ§ãç¶èï¼å¯¹äºæ¶åå¤æç¸äºä¾èµæ°æ®ï¼ä¾å¦è¯­è¨ãå¾åãæ¶é´åºååå¾å½¢ï¼çåè½å­¦ä¹ ä»»å¡ï¼è¿ç§åè®¾éå¸¸è¢«è¯ææ¯æ æçãå¿½ç¥æ­¤ç±»æ°æ®ç¸äºä¾èµæ§ä¸å¯é¿åå°ä¼å¯¼è´æ§è½æ¾çä¸éã
ä¸ºäºåæè¿äºéå¶ï¼æä»¬å¨æ¬æä¸­å¼å¥äºæ°çåè°å¤é¡¹å¼ç½ç»ï¼çæ¬ 2ï¼ï¼å³ RPN 2ãéè¿ç»åæ°æ®åç»æç¸äºä¾èµå½æ°ï¼RPN 2 éè¿å¶æ¶æä¸­çæ°ç»ä»¶å½æ°æç¡®å°å¯¹æ°æ®ç¸äºä¾èµæ§è¿è¡å»ºæ¨¡ã
è¿ç§å¢å¼ºä¸ä»æ¾çæé«äº RPN 2 çå­¦ä¹ æ§è½ï¼èä¸è¿å¤§å¹æ©å±äºå¶ç»ä¸æ½åï¼ä½¿å¶è½å¤å¨å¶è§èè¡¨ç¤ºä¸­åå«æ´å¹¿æ³çå½ä»£ä¸»å¹²æ¨¡åãè¿äºä¸»å¹²åæ¬ä½ä¸éäºå·ç§¯ç¥ç»ç½ç» (CNN)ãå¾ªç¯ç¥ç»ç½ç» (RNN)ãå¾ç¥ç»ç½ç» (GNN) å Transformerãæä»¬çåæè¡¨æï¼è¿äºä¸»å¹²æ¨¡åä¹é´çæ ¹æ¬åºå«ä¸»è¦æºäºå®ä»¬å®ä¹ç¸äºä¾èµå½æ°çä¸åæ¹æ³ãæ­¤å¤ï¼è¿ç§ç»ä¸è¡¨ç¤ºä¸ºè®¾è®¡åæ°æ¶æå¼è¾äºæ°çæºä¼ï¼è¿äºæ¶ææå¯è½è¶è¶è¿äºä¸»å¹²çæ§è½ã

##### **LLaSA: Large Language and Structured Data Assistant**
2411.14460v1 by Yao Xu, Shizhu He, Zeng Xiangrong, Jiabei Chen, Guang Liu, Bingning Wang, Jun Zhao, Kang Liu

Structured data, such as tables, graphs, and databases, play a critical role
in plentiful NLP tasks such as question answering and dialogue system.
Recently, inspired by Vision-Language Models, Graph Neutral Networks (GNNs)
have been introduced as an additional modality into the input of Large Language
Models (LLMs) to improve their performance on Structured Knowledge Grounding
(SKG) tasks. However, those GNN-enhanced LLMs have the following limitations:
(1) They employ diverse GNNs to model varying types of structured data,
rendering them unable to uniformly process various forms of structured data.
(2) The pretraining of GNNs is coupled with specific LLMs, which prevents GNNs
from fully aligning with the textual space and limits their adaptability to
other LLMs. To address these issues, we propose \textbf{L}arge
\textbf{L}anguage and \textbf{S}tructured Data \textbf{A}ssistant (LLaSA), a
general framework for enhancing LLMs' ability to handle structured data.
Specifically, we represent various types of structured data in a unified
hypergraph format, and use self-supervised learning to pretrain a hypergraph
encoder, and a G-Former compressing encoded hypergraph representations with
cross-attention. The compressed hypergraph representations are appended to the
serialized inputs during training and inference stages of LLMs. Experimental
results on multiple SKG tasks show that our pretrained hypergraph encoder can
adapt to various LLMs and enhance their ability to process different types of
structured data. Besides, LLaSA, with LoRA fine-tuning, outperforms previous
SOTA method using full parameters tuning.

æè¦ï¼<paragraph>çµæ§åè³æï¼ä¾å¦è¡¨æ ¼ãåè¡¨åè³æåº«ï¼å¨è±å¯ç NLP ä»»åä¸­æ®æ¼èè³ééè¦çè§è²ï¼ä¾å¦åç­åå°è©±ç³»çµ±ã
æè¿ï¼åå°è¦è¦ºèªè¨æ¨¡åçåç¼ï¼åå½¢ä¸­ç«ç¶²è·¯ (GNN) å·²è¢«å¼å¥å¤§åèªè¨æ¨¡å (LLM) çè¼¸å¥ä¸­ä½çºä¸ç¨®é¡å¤çæ¨¡å¼ï¼ä»¥æåå¶å¨çµæ§åç¥è­åºç¤ (SKG) ä»»åä¸çè¡¨ç¾ãç¶èï¼éäº GNN å¢å¼·ç LLM å·æä»¥ä¸éå¶ï¼
(1) å®åä½¿ç¨ä¸åç GNN ä¾å»ºæ¨¡åç¨®çµæ§åè³æé¡åï¼å°è´å®åç¡æ³çµ±ä¸èçåç¨®å½¢å¼ççµæ§åè³æã
(2) GNN çé è¨ç·´èç¹å®ç LLM çµåå¨ä¸èµ·ï¼éæé»æ­¢ GNN èææ¬ç©ºéå®å¨å°é½ï¼ä¸¦éå¶å¶é©æå¶ä» LLMãçºäºè§£æ±ºéäºåé¡ï¼æåæåºäº**L**arge **L**anguage and **S**tructured Data **A**ssistant (LLaSA)ï¼ä¸åç¨æ¼å¢å¼· LLM èççµæ§åè³æè½åçéç¨æ¡æ¶ã
å·é«ä¾èªªï¼æåä»¥çµ±ä¸çè¶åæ ¼å¼è¡¨ç¤ºåç¨®çµæ§åè³æé¡åï¼ä¸¦ä½¿ç¨èªæç£ç£å­¸ç¿ä¾é è¨ç·´è¶åç·¨ç¢¼å¨ï¼ä»¥åä½¿ç¨è·¨æ³¨æåå£ç¸®ç·¨ç¢¼è¶åè¡¨ç¤ºç G-Formerãå£ç¸®çè¶åè¡¨ç¤ºæéå å° LLM çè¨ç·´åæ¨è«éæ®µçåºååè¼¸å¥ä¸­ãå¤å SKG ä»»åçå¯¦é©çµæè¡¨æï¼æåé è¨ç·´çè¶åç·¨ç¢¼å¨å¯ä»¥é©æåç¨® LLMï¼ä¸¦å¢å¼·å¶èçä¸åé¡åçµæ§åè³æçè½åãæ­¤å¤ï¼LLaSA ä½¿ç¨ LoRA å¾®èª¿ï¼åªæ¼ä½¿ç¨å¨åæ¸å¾®èª¿çåå SOTA æ¹æ³ã</paragraph>

##### **Unveiling User Preferences: A Knowledge Graph and LLM-Driven Approach for Conversational Recommendation**
2411.14459v1 by Zhangchi Qiu, Linhao Luo, Shirui Pan, Alan Wee-Chung Liew

Conversational Recommender Systems (CRSs) aim to provide personalized
recommendations through dynamically capturing user preferences in interactive
conversations. Conventional CRSs often extract user preferences as hidden
representations, which are criticized for their lack of interpretability. This
diminishes the transparency and trustworthiness of the recommendation process.
Recent works have explored combining the impressive capabilities of Large
Language Models (LLMs) with the domain-specific knowledge of Knowledge Graphs
(KGs) to generate human-understandable recommendation explanations. Despite
these efforts, the integration of LLMs and KGs for CRSs remains challenging due
to the modality gap between unstructured dialogues and structured KGs.
Moreover, LLMs pre-trained on large-scale corpora may not be well-suited for
analyzing user preferences, which require domain-specific knowledge. In this
paper, we propose COMPASS, a plug-and-play framework that synergizes LLMs and
KGs to unveil user preferences, enhancing the performance and explainability of
existing CRSs. To address integration challenges, COMPASS employs a two-stage
training approach: first, it bridges the gap between the structured KG and
natural language through an innovative graph entity captioning pre-training
mechanism. This enables the LLM to transform KG entities into concise natural
language descriptions, allowing them to comprehend domain-specific knowledge.
Following, COMPASS optimizes user preference modeling via knowledge-aware
instruction fine-tuning, where the LLM learns to reason and summarize user
preferences from both dialogue histories and KG-augmented context. This enables
COMPASS to perform knowledge-aware reasoning and generate comprehensive and
interpretable user preferences that can seamlessly integrate with existing CRS
models for improving recommendation performance and explainability.

æè¦ï¼å°è©±å¼æ¨è¦ç³»çµ± (CRS) æ¨å¨ééåæææäºåå°è©±ä¸­çä½¿ç¨èåå¥½ï¼æä¾åäººåæ¨è¦ãå³çµ±ç CRS éå¸¸æå°ä½¿ç¨èåå¥½æ·åçºé±èå¼è¡¨å¾µï¼èå¶ç¼ºé»å¨æ¼ç¼ºä¹å¯è§£éæ§ï¼ééä½äºæ¨è¦ç¨å¼çéæåº¦åå¯ä¿¡åº¦ãæè¿çç ç©¶æ¢è¨å°å¤§åèªè¨æ¨¡å (LLM) çå¼·å¤§åè½èç¥è­åè­ (KG) çç¹å®é åç¥è­çµåï¼ä»¥ç¢çäººé¡å¯ä»¥çè§£çæ¨è¦èªªæãåç®¡æéäºåªåï¼ç±æ¼éçµæ§åå°è©±åçµæ§å KG ä¹éçæ¨¡å¼å·®ç°ï¼LLM å KG å¨ CRS ä¸­çæ´åä»ç¶å·æææ°æ§ãæ­¤å¤ï¼éå°å¤§åèªæåº«é åè¨ç·´ç LLM å¯è½ä¸é©ååæä½¿ç¨èåå¥½ï¼å çºééè¦ç¹å®é åçç¥è­ãå¨æ¬æä¸­ï¼æåæåº COMPASSï¼éæ¯ä¸åå³æå³ç¨çæ¶æ§ï¼å®ååéç¨ LLM å KG ä¾æ­ç¤ºä½¿ç¨èåå¥½ï¼å¢å¼·ç¾æ CRS çæè½åå¯è§£éæ§ãçºäºæå°æ´åææ°ï¼COMPASS æ¡ç¨äºå©éæ®µçè¨ç·´æ¹æ³ï¼é¦åï¼å®ééåµæ°çåå½¢å¯¦é«æ¨é¡é è¨ç·´æ©å¶ï¼å½åçµæ§å KG åèªç¶èªè¨ä¹éçå·®è·ãéè® LLM è½å¤ å° KG å¯¦é«è½æçºç°¡æ½çèªç¶èªè¨æè¿°ï¼è®å®åè½å¤ çè§£ç¹å®é åçç¥è­ãæ¥ä¸ä¾ï¼COMPASS ééç¥è­æç¥æä»¤å¾®èª¿ä¾æä½³åä½¿ç¨èåå¥½å»ºæ¨¡ï¼å¶ä¸­ LLM å­¸ç¿å¾å°è©±è¨éå KG æ´åçå§å®¹ä¸­æ¨è«åç¸½çµä½¿ç¨èåå¥½ãéè® COMPASS è½å¤ å·è¡ç¥è­æç¥æ¨çï¼ä¸¦ç¢çå¨é¢ä¸å¯è§£éçä½¿ç¨èåå¥½ï¼éäºåå¥½å¯ä»¥ç¡ç¸«æ´åå°ç¾æç CRS æ¨¡åä¸­ï¼ä»¥æ¹åæ¨è¦æè½åå¯è§£éæ§ã

##### **A Novel Approach to Eliminating Hallucinations in Large Language Model-Assisted Causal Discovery**
2411.12759v1 by Grace Sng, Yanming Zhang, Klaus Mueller

The increasing use of large language models (LLMs) in causal discovery as a
substitute for human domain experts highlights the need for optimal model
selection. This paper presents the first hallucination survey of popular LLMs
for causal discovery. We show that hallucinations exist when using LLMs in
causal discovery so the choice of LLM is important. We propose using Retrieval
Augmented Generation (RAG) to reduce hallucinations when quality data is
available. Additionally, we introduce a novel method employing multiple LLMs
with an arbiter in a debate to audit edges in causal graphs, achieving a
comparable reduction in hallucinations to RAG.

æè¦ï¼é¨èå¤§åèªè¨æ¨¡å (LLM) å¨å æç¼ç¾ä¸­ä½çºäººé¡é åå°å®¶çæ¿ä»£åä½¿ç¨æ¥çå¢å ï¼éå¸é¡¯äºæä½³æ¨¡åé¸æçéæ±ãæ¬ææåºäºç¬¬ä¸ä»½æµè¡ LLM çå¹»è¦ºèª¿æ¥ä»¥é²è¡å æç¼ç¾ãæåè¡¨æå¨å æç¼ç¾ä¸­ä½¿ç¨ LLM æå­å¨å¹»è¦ºï¼å æ­¤ LLM çé¸æå¾éè¦ãæåå»ºè­°ä½¿ç¨æª¢ç´¢å¼·åçæ (RAG) ä¾æ¸å°å¨æåè³ªè³ææç¢ççå¹»è¦ºãæ­¤å¤ï¼æåå¼å¥äºä¸ç¨®æ°çæ¹æ³ï¼å¨è¾¯è«ä¸­ä½¿ç¨å¤å LLM åä»²è£èä¾å¯©æ ¸å æåä¸­çéç·£ï¼è RAG ç¸æ¯ï¼å¹»è¦ºæ¸å°äºè¨±å¤ã

##### **VeriGraph: Scene Graphs for Execution Verifiable Robot Planning**
2411.10446v2 by Daniel Ekpo, Mara Levy, Saksham Suri, Chuong Huynh, Abhinav Shrivastava

Recent advancements in vision-language models (VLMs) offer potential for
robot task planning, but challenges remain due to VLMs' tendency to generate
incorrect action sequences. To address these limitations, we propose VeriGraph,
a novel framework that integrates VLMs for robotic planning while verifying
action feasibility. VeriGraph employs scene graphs as an intermediate
representation, capturing key objects and spatial relationships to improve plan
verification and refinement. The system generates a scene graph from input
images and uses it to iteratively check and correct action sequences generated
by an LLM-based task planner, ensuring constraints are respected and actions
are executable. Our approach significantly enhances task completion rates
across diverse manipulation scenarios, outperforming baseline methods by 58%
for language-based tasks and 30% for image-based tasks.

æè¦ï¼è¦è¦ºèªè¨æ¨¡å (VLM) çææ°é²å±çºæ©å¨äººä»»åè¦åæä¾äºæ½åï¼ä½ç±æ¼ VLM å¾åæ¼çæä¸æ­£ç¢ºçåä½åºåï¼å æ­¤ä»å­å¨ææ°ãçºäºè§£æ±ºéäºéå¶ï¼æåæåºäº VeriGraphï¼éæ¯ä¸åæ°ç©çæ¶æ§ï¼å®æ´åäº VLM ä»¥é²è¡æ©å¨äººè¦åï¼åæé©è­åä½çå¯è¡æ§ãVeriGraph ä½¿ç¨å ´æ¯åä½çºä¸­éè¡¨ç¤ºï¼æ·åééµç©ä»¶åç©ºééä¿ä»¥æ¹åè¨ç«é©è­åç²¾çãç³»çµ±å¾è¼¸å¥å½±åä¸­çæå ´æ¯åï¼ä¸¦ä½¿ç¨å®ä¾åè¦æª¢æ¥åä¿®æ­£ç±åºæ¼ LLM çä»»åè¦åå¨ç¢ççåä½åºåï¼ç¢ºä¿éµå®ç´æä¸åä½å¯å·è¡ãæåçåæ³å¤§å¹æé«äºå¨åç¨®æä½å ´æ¯ä¸­çä»»åå®æçï¼å¨åºæ¼èªè¨çä»»åä¸­åªæ¼åºç·æ¹æ³ 58%ï¼å¨åºæ¼å½±åçä»»åä¸­åªæ¼ 30%ã

##### **A Survey of Event Causality Identification: Principles, Taxonomy, Challenges, and Assessment**
2411.10371v2 by Qing Cheng, Zefan Zeng, Xingchen Hu, Yuehang Si, Zhong Liu

Event Causality Identification (ECI) has become a crucial task in Natural
Language Processing (NLP), aimed at automatically extracting causalities from
textual data. In this survey, we systematically address the foundational
principles, technical frameworks, and challenges of ECI, offering a
comprehensive taxonomy to categorize and clarify current research
methodologies, as well as a quantitative assessment of existing models. We
first establish a conceptual framework for ECI, outlining key definitions,
problem formulations, and evaluation standards. Our taxonomy classifies ECI
methods according to the two primary tasks of sentence-level (SECI) and
document-level (DECI) event causality identification. For SECI, we examine
feature pattern-based matching, deep semantic encoding, causal knowledge
pre-training and prompt-based fine-tuning, and external knowledge enhancement
methods. For DECI, we highlight approaches focused on event graph reasoning and
prompt-based techniques to address the complexity of cross-sentence causal
inference. Additionally, we analyze the strengths, limitations, and open
challenges of each approach. We further conduct an extensive quantitative
evaluation of various ECI methods on two benchmark datasets. Finally, we
explore future research directions, highlighting promising pathways to overcome
current limitations and broaden ECI applications.

æè¦ï¼äºä»¶å æéä¿è­å¥ (ECI) å·²æçºèªç¶èªè¨èç (NLP) ä¸­ä¸é è³ééè¦çä»»åï¼æ¨å¨å¾ææ¬è³æä¸­èªåèåå æéä¿ãå¨æ­¤èª¿æ¥ä¸­ï¼æåç³»çµ±æ§å°æ¢è¨ ECI çåºç¤åçãæè¡æ¶æ§åææ°ï¼æä¾ä¸åå¨é¢çåé¡æ³ä¾åé¡åéæ¸ç¶åçç ç©¶æ¹æ³ï¼ä»¥åå°ç¾ææ¨¡åçéåè©ä¼°ãæåé¦åçº ECI å»ºç«ä¸åæ¦å¿µæ¡æ¶ï¼æ¦è¿°ééµå®ç¾©ãåé¡è¡¨è¿°åè©ä¼°æ¨æºãæåçåé¡æ³æ ¹æå¥å­å±¤ç´ (SECI) åæä»¶å±¤ç´ (DECI) äºä»¶å æéä¿è­å¥éå©åä¸»è¦ä»»åï¼å° ECI æ¹æ³é²è¡åé¡ãå°æ¼ SECIï¼æåæª¢è¦åºæ¼ç¹å¾µæ¨¡å¼çæ¯å°ãæ·±åº¦èªæç·¨ç¢¼ãå æç¥è­é è¨ç·´ååºæ¼æç¤ºçå¾®èª¿ï¼ä»¥åå¤é¨ç¥è­å¢å¼·æ¹æ³ãå°æ¼ DECIï¼æåå¼·èª¿ä»¥äºä»¶åæ¨è«ååºæ¼æç¤ºçæè¡çºéé»çæ¹æ³ï¼ä»¥è§£æ±ºè·¨å¥å­å ææ¨è«çè¤éæ§ãæ­¤å¤ï¼æååææ¯ç¨®æ¹æ³çåªé»ãéå¶åéæ¾æ§ææ°ãæåé²ä¸æ­¥å°åç¨® ECI æ¹æ³å¨å©ååºæºè³æéä¸é²è¡å»£æ³çéåè©ä¼°ãæå¾ï¼æåæ¢è¨æªä¾çç ç©¶æ¹åï¼å¼·èª¿æå¸æåæç¶åéå¶åæ´å± ECI æç¨ç¨å¼çéå¾ã

##### **Prompting and Fine-tuning Large Language Models for Automated Code Review Comment Generation**
2411.10129v1 by Md. Asif Haider, Ayesha Binte Mostofa, Sk. Sabit Bin Mosaddek, Anindya Iqbal, Toufique Ahmed

Generating accurate code review comments remains a significant challenge due
to the inherently diverse and non-unique nature of the task output. Large
language models pretrained on both programming and natural language data tend
to perform well in code-oriented tasks. However, large-scale pretraining is not
always feasible due to its environmental impact and project-specific
generalizability issues. In this work, first we fine-tune open-source Large
language models (LLM) in parameter-efficient, quantized low-rank (QLoRA)
fashion on consumer-grade hardware to improve review comment generation. Recent
studies demonstrate the efficacy of augmenting semantic metadata information
into prompts to boost performance in other code-related tasks. To explore this
in code review activities, we also prompt proprietary, closed-source LLMs
augmenting the input code patch with function call graphs and code summaries.
Both of our strategies improve the review comment generation performance, with
function call graph augmented few-shot prompting on the GPT-3.5 model
surpassing the pretrained baseline by around 90% BLEU-4 score on the
CodeReviewer dataset. Moreover, few-shot prompted Gemini-1.0 Pro, QLoRA
fine-tuned Code Llama and Llama 3.1 models achieve competitive results (ranging
from 25% to 83% performance improvement) on this task. An additional human
evaluation study further validates our experimental findings, reflecting
real-world developers' perceptions of LLM-generated code review comments based
on relevant qualitative metrics.

æè¦ï¼<paragraph>ç¢çæºç¢ºçç¨å¼ç¢¼å¯©æ¥è©è«ä»ç¶æ¯ä¸åéå¤§ææ°ï¼å çºä»»åè¼¸åºçæ¬è³ªä¸æ¯å¤æ¨£ä¸éç¨ç¹çãå¨ç¨å¼è¨­è¨åèªç¶èªè¨è³æä¸é²è¡é è¨ç·´çå¤§åèªè¨æ¨¡åå¾å¾å¨ä»¥ç¨å¼ç¢¼çºå°åçä»»åä¸­è¡¨ç¾è¯å¥½ãç¶èï¼ç±æ¼å¶å°ç°å¢çå½±é¿åå°æ¡ç¹å®çä¸è¬ååé¡ï¼å¤§è¦æ¨¡é è¨ç·´ä¸¦éç¸½æ¯å¯è¡çãå¨éé å·¥ä½ä¸­ï¼æåé¦åå¨åæ¸ææãéåçä½ç§© (QLoRA) æ¹å¼ä¸­å¾®èª¿éæºå¤§åèªè¨æ¨¡å (LLM)ï¼å¨æ¶è²»ç´ç¡¬é«ä¸æ¹åå¯©æ¥è©è«çç¢çãæè¿çç ç©¶è­æäºå¨æç¤ºä¸­å¢å èªç¾©åè³æè³è¨ä»¥æåå¶ä»èç¨å¼ç¢¼ç¸éä»»åä¸­æè½çåæãçºäºå¨ç¨å¼ç¢¼å¯©æ¥æ´»åä¸­æ¢ç´¢éä¸é»ï¼æåä¹æç¤ºå°æçãéæº LLMï¼ä½¿ç¨å½æ¸å¼å«ååç¨å¼ç¢¼æè¦ä¾å¢å è¼¸å¥ç¨å¼ç¢¼ä¿®è£ç¨å¼ãæåçå©ç¨®ç­ç¥é½æ¹åäºå¯©æ¥è©è«ç¢ççæè½ï¼å¨ GPT-3.5 æ¨¡åä¸ä½¿ç¨å½æ¸å¼å«åå¢å çå°éæç¤ºï¼å¨ CodeReviewer è³æéä¸è¶è¶äºé è¨ç·´åºæºï¼BLEU-4 åæ¸æé«äºç´ 90%ãæ­¤å¤ï¼å°éæç¤ºç Gemini-1.0 ProãQLoRA å¾®èª¿ç Code Llama å Llama 3.1 æ¨¡åå¨æ­¤ä»»åä¸éå°äºæç«¶ç­åççµæï¼æè½æåç¯åçº 25% è³ 83%ï¼ãé¡å¤çä½¿ç¨èè©ä¼°ç ç©¶é²ä¸æ­¥é©è­äºæåçå¯¦é©çµæï¼åæ äºå¯¦ééç¼äººå¡å° LLM ç¢ççç¨å¼ç¢¼å¯©æ¥è©è«ççæ³ï¼éäºçæ³åºæ¼ç¸éçå®æ§ææ¨ã</paragraph>

##### **HistoLens: An LLM-Powered Framework for Multi-Layered Analysis of Historical Texts -- A Case Application of Yantie Lun**
2411.09978v1 by Yifan Zeng

This paper proposes HistoLens, a multi-layered analysis framework for
historical texts based on Large Language Models (LLMs). Using the important
Western Han dynasty text "Yantie Lun" as a case study, we demonstrate the
framework's potential applications in historical research and education.
HistoLens integrates NLP technology (especially LLMs), including named entity
recognition, knowledge graph construction, and geographic information
visualization. The paper showcases how HistoLens explores Western Han culture
in "Yantie Lun" through multi-dimensional, visual, and quantitative methods,
focusing particularly on the influence of Confucian and Legalist thoughts on
political, economic, military, and ethnic. We also demonstrate how HistoLens
constructs a machine teaching scenario using LLMs for explainable analysis,
based on a dataset of Confucian and Legalist ideas extracted with LLM
assistance. This approach offers novel and diverse perspectives for studying
historical texts like "Yantie Lun" and provides new auxiliary tools for history
education. The framework aims to equip historians and learners with
LLM-assisted tools to facilitate in-depth, multi-layered analysis of historical
texts and foster innovation in historical education.

æè¦ï¼æ¬ææåº HistoLensï¼ä¸ååºæ¼å¤§åèªè¨æ¨¡å (LLM) çå¤å±¤åææ¶æ§ï¼ç¨æ¼æ­·å²ææ¬ãä½¿ç¨éè¦çè¥¿æ¼¢çæææ¬ãé¹½éµè«ãä½çºåæ¡ç ç©¶ï¼æåå±ç¤ºäºè©²æ¶æ§å¨æ­·å²ç ç©¶åæè²ä¸­çæ½å¨æç¨ãHistoLens æ´åäº NLP æè¡ï¼å°¤å¶æ¯ LLMï¼ï¼åæ¬å½åå¯¦é«è­å¥ãç¥è­åè­å»ºæ§åå°çè³è¨è¦è¦ºåãæ¬æå±ç¤ºäº HistoLens å¦ä½ééå¤ç¶­åº¦ãè¦è¦ºååéåæ¹æ³æ¢ç´¢ãé¹½éµè«ãä¸­çè¥¿æ¼¢æåï¼ç¹å¥éæ³¨åå®¶åæ³å®¶ææ³å°æ¿æ²»ãç¶æ¿ãè»äºåç¨®æçå½±é¿ãæåéå±ç¤ºäº HistoLens å¦ä½å»ºæ§ä¸åä½¿ç¨ LLM çæ©å¨æå­¸å ´æ¯ï¼ä»¥é²è¡å¯è§£éåæï¼éæ¯åºæ¼ LLM åå©æåçåå®¶åæ³å®¶ææ³è³æéãéç¨®æ¹æ³çºç ç©¶ãé¹½éµè«ãç­æ­·å²ææ¬æä¾äºæ°ç©ä¸å¤æ¨£åçè§é»ï¼ä¸¦çºæ­·å²æè²æä¾äºæ°çè¼å©å·¥å·ãè©²æ¶æ§æ¨å¨çºæ­·å²å­¸å®¶åå­¸ç¿èæä¾ LLM åå©çå·¥å·ï¼ä»¥å©æ¼æ·±å¥ãå¤å±¤æ¬¡å°åææ­·å²ææ¬ï¼ä¸¦ä¿é²æ­·å²æè²çåµæ°ã

##### **Accelerating Knowledge Graph and Ontology Engineering with Large Language Models**
2411.09601v1 by Cogan Shimizu, Pascal Hitzler

Large Language Models bear the promise of significant acceleration of key
Knowledge Graph and Ontology Engineering tasks, including ontology modeling,
extension, modification, population, alignment, as well as entity
disambiguation. We lay out LLM-based Knowledge Graph and Ontology Engineering
as a new and coming area of research, and argue that modular approaches to
ontologies will be of central importance.

æè¦ï¼å¤§åèªè¨æ¨¡åæ¿è«¾å¤§å¹å éééµç¥è­åè­åæ¬ä½å·¥ç¨ä»»åï¼åæ¬æ¬ä½å»ºæ¨¡ãæ´åãä¿®æ¹ãå¡«åãæ¯å°ä»¥åå¯¦é«æ¶æ­§ãæåå° LLM çºåºç¤çç¥è­åè­åæ¬ä½å·¥ç¨è¦åçºä¸åæ°èçç ç©¶é åï¼ä¸¦ä¸»å¼µæ¨¡çµåæ¬ä½æ¹æ³å°è³ééè¦ã

##### **Automating Reformulation of Essence Specifications via Graph Rewriting**
2411.09576v1 by Ian Miguel, AndrÃ¡s Z. Salamon, Christopher Stone

Formulating an effective constraint model of a parameterised problem class is
crucial to the efficiency with which instances of the class can subsequently be
solved. It is difficult to know beforehand which of a set of candidate models
will perform best in practice. This paper presents a system that employs graph
rewriting to reformulate an input model for improved performance automatically.
By situating our work in the Essence abstract constraint specification
language, we can use the structure in its high level variable types to trigger
rewrites directly. We implement our system via rewrite rules expressed in the
Graph Programs 2 language, applied to the abstract syntax tree of an input
specification. We show how to automatically translate the solution of the
reformulated problem into a solution of the original problem for verification
and presentation. We demonstrate the efficacy of our system with a detailed
case study.

æè¦ï¼å¶å®ä¸ååæ¸ååé¡é¡å¥çææç´ææ¨¡åå°æ¼é¨å¾æ±è§£è©²é¡å¥çå¯¦ä¾çæçè³ééè¦ãäºåå¾é£ç¥éä¸çµåé¸æ¨¡åä¸­åªä¸åå¨å¯¦åä¸è¡¨ç¾æä½³ãæ¬ææåºä¸åç³»çµ±ï¼æ¡ç¨åå½¢éå¯«ä¾èªåéæ°å¶å®è¼¸å¥æ¨¡åä»¥æ¹åæè½ãééå°æåçå·¥ä½ç½®æ¼ Essence æ½è±¡ç´æè¦ç¯èªè¨ä¸­ï¼æåå¯ä»¥ä½¿ç¨å¶é«å±¤ç´è®æ¸é¡åä¸­ççµæ§ä¾ç´æ¥è§¸ç¼éå¯«ãæåééä»¥ Graph Programs 2 èªè¨è¡¨ç¤ºçéå¯«è¦åä¾å¯¦ä½æåçç³»çµ±ï¼æç¨æ¼è¼¸å¥è¦ç¯çæ½è±¡èªæ³æ¨¹ãæåå±ç¤ºå¦ä½èªåå°éæ°å¶å®åé¡çè§£æ³è½æçºåå§åé¡çè§£æ³ï¼ä»¥é²è¡é©è­ååç¾ãæåééè©³ç´°çåæ¡ç ç©¶ä¾å±ç¤ºæåç³»çµ±çæè½ã

##### **Towards Evaluating Large Language Models for Graph Query Generation**
2411.08449v2 by Siraj Munir, Alessandro Aldini

Large Language Models (LLMs) are revolutionizing the landscape of Generative
Artificial Intelligence (GenAI), with innovative LLM-backed solutions emerging
rapidly. However, when applied to database technologies, specifically query
generation for graph databases and Knowledge Graphs (KGs), LLMs still face
significant challenges. While research on LLM-driven query generation for
Structured Query Language (SQL) exists, similar systems for graph databases
remain underdeveloped. This paper presents a comparative study addressing the
challenge of generating Cypher queries a powerful language for interacting with
graph databases using open-access LLMs. We rigorously evaluate several LLM
agents (OpenAI ChatGPT 4o, Claude Sonnet 3.5, Google Gemini Pro 1.5, and a
locally deployed Llama 3.1 8B) using a designed few-shot learning prompt and
Retrieval Augmented Generation (RAG) backed by Chain-of-Thoughts (CoT)
reasoning. Our empirical analysis of query generation accuracy reveals that
Claude Sonnet 3.5 outperforms its counterparts in this specific domain.
Further, we highlight promising future research directions to address the
identified limitations and advance LLM-driven query generation for graph
databases.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) æ­£å¨é©æ°çæå¼äººå·¥æºæ§ (GenAI) çé åï¼åµæ°ç LLM æ¯æè§£æ±ºæ¹æ¡è¿éæ¹§ç¾ãç¶èï¼ç¶æç¨æ¼è³æåº«æè¡ï¼ç¹å¥æ¯åå½¢è³æåº«åç¥è­åè­ (KG) çæ¥è©¢ç¢çæï¼LLM ä»ç¶é¢è¨éå¤§ææ°ãéç¶å­å¨éå°çµæ§åæ¥è©¢èªè¨ (SQL) ç LLM é©åæ¥è©¢ç¢ççç ç©¶ï¼ä½åå½¢è³æåº«çé¡ä¼¼ç³»çµ±ä»æªååç¼å±ãæ¬ææåºäºä¸é æ¯è¼ç ç©¶ï¼ä»¥è§£æ±ºä½¿ç¨éæ¾å¼ LLM ç¢ç Cypher æ¥è©¢çææ°ï¼Cypher æ¥è©¢æ¯ä¸ç¨®ç¨æ¼èåå½¢è³æåº«äºåçå¼·å¤§èªè¨ãæåä½¿ç¨è¨­è¨çå°éå­¸ç¿æç¤ºåç±ææ³é (CoT) æ¨çæ¯æçæª¢ç´¢æ´åçæ (RAG) å´æ ¼è©ä¼°äºå¤å LLM ä»£çï¼OpenAI ChatGPT 4oãClaude Sonnet 3.5ãGoogle Gemini Pro 1.5 åæ¬å°é¨ç½²ç Llama 3.1 8Bï¼ãæåå°æ¥è©¢ç¢çæºç¢ºæ§çå¯¦è­åæè¡¨æï¼Claude Sonnet 3.5 å¨éåç¹å®é ååªæ¼å¶åé¡ç¢åãæ­¤å¤ï¼æåéé»ä»ç´¹äºæå¸æçæªä¾ç ç©¶æ¹åï¼ä»¥è§£æ±ºå·²è­å¥çéå¶ä¸¦æ¨é² LLM é©åçåå½¢è³æåº«æ¥è©¢ç¢çã

##### **Knowledge Bases in Support of Large Language Models for Processing Web News**
2411.08278v2 by Yihe Zhang, Nabin Pakka, Nian-Feng Tzeng

Large Language Models (LLMs) have received considerable interest in wide
applications lately. During pre-training via massive datasets, such a model
implicitly memorizes the factual knowledge of trained datasets in its hidden
parameters. However, knowledge held implicitly in parameters often makes its
use by downstream applications ineffective due to the lack of common-sense
reasoning. In this article, we introduce a general framework that permits to
build knowledge bases with an aid of LLMs, tailored for processing Web news.
The framework applies a rule-based News Information Extractor (NewsIE) to news
items for extracting their relational tuples, referred to as knowledge bases,
which are then graph-convoluted with the implicit knowledge facts of news items
obtained by LLMs, for their classification. It involves two lightweight
components: 1) NewsIE: for extracting the structural information of every news
item, in the form of relational tuples; 2) BERTGraph: for graph convoluting the
implicit knowledge facts with relational tuples extracted by NewsIE. We have
evaluated our framework under different news-related datasets for news category
classification, with promising experimental results.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) è¿ä¾å¨å»£æ³çæç¨ä¸­ååéæ³¨ãå¨ééå¤§éè³æéé²è¡é è¨ç·´æéï¼æ­¤é¡æ¨¡åæé±å«å°å°è¨ç·´è³æéçäºå¯¦ç¥è­è¨æ¶å¨å¶é±èåæ¸ä¸­ãç¶èï¼é±å«å¨åæ¸ä¸­çç¥è­éå¸¸æå çºç¼ºä¹å¸¸è­æ¨çèå°è´ä¸æ¸¸æç¨ç¡æ³ææä½¿ç¨ãå¨æ¬æä¸­ï¼æåä»ç´¹äºä¸åéç¨æ¶æ§ï¼åè¨±å¨ LLM çåå©ä¸å»ºç«ç¥è­åº«ï¼å°éç¨æ¼èçç¶²è·¯æ°èãæ­¤æ¶æ§å°åºæ¼è¦åçæ°èè³è¨èåå¨ (NewsIE) å¥ç¨å°æ°èé ç®ï¼ä»¥èåå¶éä¿åçµï¼ç¨±çºç¥è­åº«ï¼ï¼ç¶å¾å°å¶è LLM åå¾çæ°èé ç®çé±å«ç¥è­äºå¯¦é²è¡åå½¢å·ç©ï¼ä»¥é²è¡åé¡ãå®åå«å©åè¼éç´åä»¶ï¼1) NewsIEï¼ç¨æ¼èåæ¯åæ°èé ç®ççµæ§åè³è¨ï¼ä»¥éä¿åçµçå½¢å¼åç¾ï¼2) BERTGraphï¼ç¨æ¼å° NewsIE èåçéä¿åçµèé±å«ç¥è­äºå¯¦é²è¡åå½¢å·ç©ãæåå·²å¨ä¸åçèæ°èç¸éçè³æéä¸è©ä¼°æåçæ¶æ§ï¼ç¨æ¼æ°èé¡å¥åé¡ï¼ä¸¦ç²å¾æå¸æçå¯¦é©çµæã

##### **Retrieval, Reasoning, Re-ranking: A Context-Enriched Framework for Knowledge Graph Completion**
2411.08165v1 by Muzhi Li, Cehao Yang, Chengjin Xu, Xuhui Jiang, Yiyan Qi, Jian Guo, Ho-fung Leung, Irwin King

The Knowledge Graph Completion~(KGC) task aims to infer the missing entity
from an incomplete triple. Existing embedding-based methods rely solely on
triples in the KG, which is vulnerable to specious relation patterns and
long-tail entities. On the other hand, text-based methods struggle with the
semantic gap between KG triples and natural language. Apart from triples,
entity contexts (e.g., labels, descriptions, aliases) also play a significant
role in augmenting KGs. To address these limitations, we propose KGR3, a
context-enriched framework for KGC. KGR3 is composed of three modules. Firstly,
the Retrieval module gathers supporting triples from the KG, collects plausible
candidate answers from a base embedding model, and retrieves context for each
related entity. Then, the Reasoning module employs a large language model to
generate potential answers for each query triple. Finally, the Re-ranking
module combines candidate answers from the two modules mentioned above, and
fine-tunes an LLM to provide the best answer. Extensive experiments on widely
used datasets demonstrate that KGR3 consistently improves various KGC methods.
Specifically, the best variant of KGR3 achieves absolute Hits@1 improvements of
12.3% and 5.6% on the FB15k237 and WN18RR datasets.

æè¦ï¼ç¥è­åè­å®æåè½ (KGC) çä»»åæ¨å¨å¾ä¸å®æ´ç 3 åçµä¸­æ¨æ·åºéºå¤±çå¯¦é«ãç¾æçåµå¥å¼æ¹æ³åä¾è³´æ¼ KG ä¸­ç 3 åçµï¼éå®¹æåå°èåéä¿æ¨¡å¼åé·å°¾å¯¦é«çå½±é¿ãå¦ä¸æ¹é¢ï¼åºæ¼ææ¬çæ¹æ³é£ä»¥èç KG 3 åçµåèªç¶èªè¨ä¹éçèªç¾©å·®è·ãé¤äº 3 åçµä¹å¤ï¼å¯¦é«ä¸ä¸æï¼ä¾å¦æ¨ç±¤ãæè¿°ãå¥åï¼å¨æ´å KG ä¸­ä¹æ®æ¼èéè¦çè§è²ãçºäºè§£æ±ºéäºéå¶ï¼æåæåºäº KGR3ï¼ä¸åç¨æ¼ KGC çä¸ä¸æè±å¯æ¶æ§ãKGR3 ç±ä¸åæ¨¡çµçµæãé¦åï¼æª¢ç´¢æ¨¡çµå¾ KG ä¸­æ¶éæ¯æ´ 3 åçµï¼å¾åºç¤åµå¥æ¨¡åä¸­æ¶éå¯è½çåé¸ç­æ¡ï¼ä¸¦çºæ¯åç¸éå¯¦é«æª¢ç´¢ä¸ä¸æãæ¥èï¼æ¨çæ¨¡çµæ¡ç¨å¤§åèªè¨æ¨¡åçºæ¯åæ¥è©¢ 3 åçµçææ½å¨ç­æ¡ãæå¾ï¼éæ°æåæ¨¡çµå°ä¸è¿°å©åæ¨¡çµçåé¸ç­æ¡çµåèµ·ä¾ï¼ä¸¦å¾®èª¿ LLM ä»¥æä¾æä½³ç­æ¡ãå¨å»£æ³ä½¿ç¨çè³æéä¸é²è¡çå»£æ³å¯¦é©è­æï¼KGR3 æçºæ¹é²åç¨® KGC æ¹æ³ãå·é«ä¾èªªï¼KGR3 çæä½³è®é«å¨ FB15k237 å WN18RR è³æéä¸åå¥å¯¦ç¾äº 12.3% å 5.6% ççµå° Hits@1 æ¹é²ã

##### **Language Models as Causal Effect Generators**
2411.08019v1 by Lucius E. J. Bynum, Kyunghyun Cho

We present a framework for large language model (LLM) based data generation
with controllable causal structure. In particular, we define a procedure for
turning any language model and any directed acyclic graph (DAG) into a
sequence-driven structural causal model (SD-SCM). Broadly speaking, an SD-SCM
is a causal model with user-defined structure and LLM-defined structural
equations. We characterize how an SD-SCM allows sampling from observational,
interventional, and counterfactual distributions according to the desired
causal structure. We then leverage this procedure to propose a new type of
benchmark for causal inference methods, generating individual-level
counterfactual data without needing to manually specify functional
relationships between variables. We create an example benchmark consisting of
thousands of datasets, and test a suite of popular estimation methods on these
datasets for average, conditional average, and individual treatment effect
estimation, both with and without hidden confounding. Apart from generating
data, the same procedure also allows us to test for the presence of a causal
effect that might be encoded in an LLM. This procedure can underpin auditing
LLMs for misinformation, discrimination, or otherwise undesirable behavior. We
believe SD-SCMs can serve as a useful tool in any application that would
benefit from sequential data with controllable causal structure.

æè¦ï¼<paragraph>æåæåºäºä¸ååºæ¼å¤§åèªè¨æ¨¡å (LLM) çè³æçææ¶æ§ï¼å·æå¯æ§å¶çå æçµæ§ãå·é«ä¾èªªï¼æåå®ç¾©äºä¸åç¨åºï¼å°ä»»ä½èªè¨æ¨¡ååä»»ä½æåç¡ç°å (DAG) è½ææä¸ååºåé©åççµæ§å ææ¨¡å (SD-SCM)ãå»£ç¾©ä¾èªªï¼SD-SCM æ¯ä¸åå ææ¨¡åï¼å·æä½¿ç¨èå®ç¾©ççµæ§å LLM å®ç¾©ççµæ§æ¹ç¨å¼ãæåæè¿°äº SD-SCM å¦ä½æ ¹ææéçå æçµæ§ï¼åè¨±å¾è§æ¸¬ãä»å¥ååäºå¯¦åä½ä¸­é²è¡æ½æ¨£ãç¶å¾ï¼æåå©ç¨éåç¨åºæåºäºä¸ç¨®é¡åçå ææ¨è«æ¹æ³åºæºï¼çæåé«å±¤ç´çåäºå¯¦è³æï¼èç¡éæåæå®è®æ¸ä¹éçåè½éä¿ãæåå»ºç«äºä¸åç¯ä¾åºæºï¼åå«æ¸ååè³æéï¼ä¸¦å¨éäºè³æéä¸æ¸¬è©¦äºä¸ç³»åæµè¡çä¼°è¨æ¹æ³ï¼ç¨æ¼å¹³åå¼ãæ¢ä»¶å¹³åå¼ååå¥èçææä¼°è¨ï¼ç¡è«æ¯æææ²æé±èæ··æ·ãé¤äºçæè³æä¹å¤ï¼ç¸åçç¨åºä¹åè¨±æåæ¸¬è©¦ LLM ä¸­å¯è½ç·¨ç¢¼çå æææçå­å¨ãæ­¤ç¨åºå¯ä»¥æ¯æå¯©æ ¸ LLM çé¯èª¤è³è¨ãæ­§è¦æå¶ä»ä¸è¯è¡çºãæåç¸ä¿¡ SD-SCM å¯ä»¥ä½çºä»»ä½æç¨ç¨å¼çæç¨å·¥å·ï¼éäºæç¨ç¨å¼å¯ä»¥å¾å·æå¯æ§å¶å æçµæ§çåºåè³æä¸­åçã</paragraph>

##### **From General to Specific: Utilizing General Hallucination to Benchmark Specific Role-Playing Agents**
2411.07965v2 by Chuyi Kong, Ziyang Luo, Hongzhan Lin, Zhiyuan Fan, Yaxin Fan, Yuxi Sun, Jing Ma

The advanced role-playing capabilities of Large Language Models (LLMs) have
paved the way for developing Role-Playing Agents (RPAs). However, existing
benchmarks in this domain, such as HPD and SocialBench face limitations like
poor generalizability, implicit and inaccurate judgments, and the risk of model
forgetting. To address the above issues, we propose an automatic, scalable, and
generalizable paradigm. Specifically, we construct a benchmark, SHARP, by
extracting relations from a general knowledge graph and leveraging the inherent
hallucination properties of RPAs to simulate interactions across roles. We
employ ChatGPT for stance detection and define relationship hallucination along
with three related metrics based on stance transfer. Extensive experiments
validate the effectiveness and stability of our paradigm. Our findings further
explore the factors influencing these metrics and discuss the trade-off between
blind loyalty to relationships and adherence to facts in RPAs.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) çé²éè§è²æ®æ¼è½åå·²çºè§è²æ®æ¼ä»£ç (RPA) çéç¼éªå¹³éè·¯ãç¶èï¼æ­¤é åç¾æçåºæºï¼ä¾å¦ HPD å SocialBenchï¼é¢è¨èæ¦æ¬æ§å·®ãå¤æ·é±å«ä¸ä¸æºç¢ºï¼ä»¥åæ¨¡åéºå¿çé¢¨éªç­éå¶ãçºäºè§£æ±ºä¸è¿°åé¡ï¼æåæåºäºä¸åèªååãå¯æ´åä¸å¯æ¦æ¬çç¯ä¾ãå·é«ä¾èªªï¼æåééå¾ä¸è¬ç¥è­åè­ä¸­æåéä¿ï¼ä¸¦å©ç¨ RPA åºæçå¹»è¦ºç¹æ§ä¾æ¨¡æ¬è·¨è§è²äºåï¼æ§å»ºäºä¸ååºæº SHARPãæåæ¡ç¨ ChatGPT é²è¡ç«å ´æª¢æ¸¬ï¼ä¸¦å®ç¾©éä¿å¹»è¦ºä»¥ååºæ¼ç«å ´è½ç§»çä¸åç¸éææ¨ãå»£æ³çå¯¦é©é©è­äºæåç¯ä¾çæææ§åç©©å®æ§ãæåçç¼ç¾é²ä¸æ­¥æ¢è¨äºå½±é¿éäºææ¨çå ç´ ï¼ä¸¦è¨è«äº RPA ä¸­å°éä¿çç²ç®å¿ èª åº¦èå°äºå¯¦çå æä¹éçæ¬è¡¡ã

##### **Chain Association-based Attacking and Shielding Natural Language Processing Systems**
2411.07843v1 by Jiacheng Huang, Long Chen

Association as a gift enables people do not have to mention something in
completely straightforward words and allows others to understand what they
intend to refer to. In this paper, we propose a chain association-based
adversarial attack against natural language processing systems, utilizing the
comprehension gap between humans and machines. We first generate a chain
association graph for Chinese characters based on the association paradigm for
building search space of potential adversarial examples. Then, we introduce an
discrete particle swarm optimization algorithm to search for the optimal
adversarial examples. We conduct comprehensive experiments and show that
advanced natural language processing models and applications, including large
language models, are vulnerable to our attack, while humans appear good at
understanding the perturbed text. We also explore two methods, including
adversarial training and associative graph-based recovery, to shield systems
from chain association-based attack. Since a few examples that use some
derogatory terms, this paper contains materials that may be offensive or
upsetting to some people.

æè¦ï¼è¯æ³ä½çºä¸ç¨®ç¦®ç©ï¼ä½¿äººåä¸å¿ç¨å®å¨ç´ç½çè©±èªæåæäºï¼ä¸¦è®å¶ä»äººæç½ä»åæ³æçæ¯ä»éº¼ãå¨æ¬æä¸­ï¼æåæåºäºä¸ç¨®åºæ¼éå¼è¯æ³çå°ææ§æ»æï¼ç¨æ¼èªç¶èªè¨èçç³»çµ±ï¼å©ç¨äºäººé¡èæ©å¨ä¹éççè§£å·®è·ãæåé¦ååºæ¼è¯æ³ç¯ä¾çºæ¼¢å­çæä¸åéå¼è¯æ³åï¼ç¨æ¼æ§å»ºæ½å¨å°ææ§ç¯ä¾çæç´¢ç©ºéãç¶å¾ï¼æåå¼å¥ä¸åé¢æ£ç²å­ç¾¤åªåæ¼ç®æ³ä¾æç´¢æä½³çå°ææ§ç¯ä¾ãæåé²è¡äºå¨é¢çå¯¦é©ï¼ä¸¦è¡¨æåé²çèªç¶èªè¨èçæ¨¡ååæç¨ç¨å¼ï¼åæ¬å¤§åèªè¨æ¨¡åï¼é½å®¹æåå°æåçæ»æï¼èäººé¡ä¼¼ä¹å¾æé·çè§£æ¾åå¾çæå­ãæåéæ¢ç´¢äºå©ç¨®æ¹æ³ï¼åæ¬å°ææ§è¨ç·´ååºæ¼è¯æ³åçæ¢å¾©ï¼ä»¥ä¿è­·ç³»çµ±åååºæ¼éå¼è¯æ³çæ»æãç±æ¼ä¸äºç¯ä¾ä½¿ç¨äºæäºè²¶ç¾©è©ï¼å æ­¤æ¬æåå«å¯è½åç¯æä»¤æäºäººæå°ä¸å®çææã

##### **Gradual Fine-Tuning with Graph Routing for Multi-Source Unsupervised Domain Adaptation**
2411.07185v1 by Yao Ma, Samuel Louvan, Zhunxuan Wang

Multi-source unsupervised domain adaptation aims to leverage labeled data
from multiple source domains for training a machine learning model to
generalize well on a target domain without labels. Source domain selection
plays a crucial role in determining the model's performance. It relies on the
similarities amongst source and target domains. Nonetheless, existing work for
source domain selection often involves heavyweight computational procedures,
especially when dealing with numerous source domains and the need to identify
the best ones from them. In this paper, we introduce a framework for gradual
fine tuning (GFT) of machine learning models on multiple source domains. We
represent multiple source domains as an undirected weighted graph. We then give
a new generalization error bound for GFT along any path within the graph, which
is used to determine the optimal path corresponding to the optimal training
order. With this formulation, we introduce three lightweight graph-routing
strategies which tend to minimize the error bound. Our best strategy improves
$2.3\%$ of accuracy over the state-of-the-art on Natural Language Inference
(NLI) task and achieves competitive performance on Sentiment Analysis (SA)
task, especially a $3.9\%$ improvement on a more diverse subset of data we use
for SA.

æè¦ï¼å¤æºæ çç£åèªéåºæ¨å¨å©ç¨æ¥èªå¤ä¸ªæºåçæ è®°æ°æ®ï¼è®­ç»æºå¨å­¦ä¹ æ¨¡åï¼ä»¥ä¾¿å¨æ²¡ææ ç­¾çç®æ åä¸å¾å¥½å°æ³åãæºåéæ©å¨ç¡®å®æ¨¡åæ§è½æ¹é¢èµ·çè³å³éè¦çä½ç¨ãå®ä¾èµäºæºååç®æ åä¹é´çç¸ä¼¼æ§ãå°½ç®¡å¦æ­¤ï¼ç°æçæºåéæ©å·¥ä½éå¸¸æ¶åééçº§è®¡ç®ç¨åºï¼å°¤å¶æ¯å¨å¤çä¼å¤æºåä»¥åéè¦ä»ä¸­è¯å«æä½³æºåæ¶ãå¨æ¬æä¸­ï¼æä»¬ä»ç»äºä¸ä¸ªå¨å¤ä¸ªæºåä¸å¯¹æºå¨å­¦ä¹ æ¨¡åè¿è¡éæ­¥å¾®è° (GFT) çæ¡æ¶ãæä»¬å°å¤ä¸ªæºåè¡¨ç¤ºä¸ºæ åå æå¾ãç¶åï¼æä»¬ä¸ºå¾ä¸­æ²¿ä»»ä½è·¯å¾ç GFT ç»åºäºä¸ä¸ªæ°çæ³åè¯¯å·®çï¼ç¨äºç¡®å®å¯¹åºäºæä½³è®­ç»é¡ºåºçæä½³è·¯å¾ãéè¿è¿ç§è¡¨è¿°ï¼æä»¬ä»ç»äºä¸ç§è½»éçº§çå¾è·¯ç±ç­ç¥ï¼è¿äºç­ç¥å¾åäºæå°åè¯¯å·®çãæä»¬æå¥½çç­ç¥å¨èªç¶è¯­è¨æ¨ç (NLI) ä»»å¡ä¸æ¯æåè¿çææ¯æé«äº 2.3% çåç¡®çï¼å¹¶å¨ææåæ (SA) ä»»å¡ä¸åå¾äºæç«äºåçæ§è½ï¼ç¹å«æ¯å¨æä»¬ç¨äº SA çæ´å¤æ ·åçæ°æ®å­éä¸æé«äº 3.9%ã

##### **A Domain-Agnostic Neurosymbolic Approach for Big Social Data Analysis: Evaluating Mental Health Sentiment on Social Media during COVID-19**
2411.07163v1 by Vedant Khandelwal, Manas Gaur, Ugur Kursuncu, Valerie Shalin, Amit Sheth

Monitoring public sentiment via social media is potentially helpful during
health crises such as the COVID-19 pandemic. However, traditional
frequency-based, data-driven neural network-based approaches can miss newly
relevant content due to the evolving nature of language in a dynamically
evolving environment. Human-curated symbolic knowledge sources, such as
lexicons for standard language and slang terms, can potentially elevate social
media signals in evolving language. We introduce a neurosymbolic method that
integrates neural networks with symbolic knowledge sources, enhancing the
detection and interpretation of mental health-related tweets relevant to
COVID-19. Our method was evaluated using a corpus of large datasets
(approximately 12 billion tweets, 2.5 million subreddit data, and 700k news
articles) and multiple knowledge graphs. This method dynamically adapts to
evolving language, outperforming purely data-driven models with an F1 score
exceeding 92\%. This approach also showed faster adaptation to new data and
lower computational demands than fine-tuning pre-trained large language models
(LLMs). This study demonstrates the benefit of neurosymbolic methods in
interpreting text in a dynamic environment for tasks such as health
surveillance.

æè¦ï¼ééç¤¾ç¾¤åªé«ç£æ§å¬ç¾æç·å¨ COVID-19 ç­å¥åº·å±æ©æéå¯è½å¾æå¹«å©ãç¶èï¼å³çµ±çåºæ¼é »çãè³æé©åçç¥ç¶ç¶²è·¯æ¹æ³å¯è½æé¯éæ°ç¸éçå§å®¹ï¼å çºèªè¨å¨åææ¼åçç°å¢ä¸­ææçºæ¼åãç±äººé¡ç­åçè±¡å¾µæ§ç¥è­ä¾æºï¼ä¾å¦æ¨æºèªè¨åä¿èªè¡èªçè©å½ï¼å¯è½ææåç¤¾ç¾¤åªé«å¨æ¼åèªè¨ä¸­çè¨èãæåå¼å¥ä¸ç¨®å°ç¥ç¶ç¶²è·¯èè±¡å¾µæ§ç¥è­ä¾æºæ´åçç¥ç¶ç¬¦èæ¹æ³ï¼å¢å¼·è COVID-19 ç¸éçå¿çå¥åº·ç¸éæ¨æçåµæ¸¬åè©®éãæåçåæ³ä½¿ç¨å¤§åè³æéèªæåº«ï¼ç´ 120 ååæ¨æã250 è¬å subreddit è³æå 70 è¬åæ°èæç« ï¼åå¤åç¥è­åè­é²è¡è©ä¼°ãéç¨®æ¹æ³åæé©ææ¼åçèªè¨ï¼åªæ¼ç´è³æé©åæ¨¡åï¼F1 åæ¸è¶é 92%ãéç¨®æ¹æ³ä¹é¡¯ç¤ºåºæ¯å¾®èª¿é è¨ç·´å¤§åèªè¨æ¨¡å (LLM) æ´å¿«é©ææ°è³æåæ´ä½çéç®éæ±ãæ¬ç ç©¶è­æäºç¥ç¶ç¬¦èæ¹æ³å¨åæç°å¢ä¸­è©®éæå­çåªé»ï¼é©ç¨æ¼å¥åº·ç£æ§ç­ä»»åã

##### **A Multi-Agent Approach for REST API Testing with Semantic Graphs and LLM-Driven Inputs**
2411.07098v1 by Myeongsoo Kim, Tyler Stennett, Saurabh Sinha, Alessandro Orso

As modern web services increasingly rely on REST APIs, their thorough testing
has become crucial. Furthermore, the advent of REST API specifications such as
the OpenAPI Specification has led to the emergence of many black-box REST API
testing tools. However, these tools often focus on individual test elements in
isolation (e.g., APIs, parameters, values), resulting in lower coverage and
less effectiveness in detecting faults (i.e., 500 response codes). To address
these limitations, we present AutoRestTest, the first black-box framework to
adopt a dependency-embedded multi-agent approach for REST API testing,
integrating Multi-Agent Reinforcement Learning (MARL) with a Semantic Property
Dependency Graph (SPDG) and Large Language Models (LLMs). Our approach treats
REST API testing as a separable problem, where four agents -- API, dependency,
parameter, and value -- collaborate to optimize API exploration. LLMs handle
domain-specific value restrictions, the SPDG model simplifies the search space
for dependencies using a similarity score between API operations, and MARL
dynamically optimizes the agents' behavior. Evaluated on 12 real-world REST
services, AutoRestTest outperforms the four leading black-box REST API testing
tools, including those assisted by RESTGPT (which augments realistic test
inputs using LLMs), in terms of code coverage, operation coverage, and fault
detection. Notably, AutoRestTest is the only tool able to identify an internal
server error in Spotify. Our ablation study underscores the significant
contributions of the agent learning, SPDG, and LLM components.

æè¦ï¼<paragraph>é¨èç¾ä»£ç¶²è·¯æåæ¥çä¾è³´ REST APIï¼å¶å¾¹åºçæ¸¬è©¦è®å¾è³ééè¦ãæ­¤å¤ï¼REST API è¦ç¯ï¼ä¾å¦ OpenAPI è¦ç¯ï¼çåºç¾ï¼å°è´è¨±å¤é»ç REST API æ¸¬è©¦å·¥å·çåºç¾ãç¶èï¼éäºå·¥å·éå¸¸å°æ³¨æ¼å®ç¨çæ¸¬è©¦åç´ ï¼ä¾å¦ APIãåæ¸ãå¼ï¼ï¼å°è´è¦èçè¼ä½ï¼ä¸å¨åµæ¸¬é¯èª¤ï¼å³ 500 åæç¢¼ï¼æ¹é¢æçè¼ä½ãçºäºè§£æ±ºéäºéå¶ï¼æåæåº AutoRestTestï¼éæ¯ç¬¬ä¸åæ¡ç¨ä¾è³´åµå¥å¼å¤ä»£çæ¹æ³é²è¡ REST API æ¸¬è©¦çé»çæ¡æ¶ï¼å°å¤ä»£çå¼·åå­¸ç¿ (MARL) èèªç¾©å±¬æ§ä¾è³´å (SPDG) åå¤§åèªè¨æ¨¡å (LLM) æ´åå¨ä¸èµ·ãæåçåæ³å° REST API æ¸¬è©¦è¦çºä¸åå¯åé¢çåé¡ï¼å¶ä¸­ååä»£çï¼APIãä¾è³´éä¿ãåæ¸åå¼ï¼åååä½ä»¥æä½³å API æ¢ç´¢ãLLM èçç¹å®é åçå¼éå¶ï¼SPDG æ¨¡åä½¿ç¨ API æä½ä¹éçç¸ä¼¼æ§åæ¸ç°¡åä¾è³´éä¿çæå°ç©ºéï¼è MARL ååææä½³åä»£ççè¡çºãå¨ 12 é çå¯¦ä¸çç REST æåä¸é²è¡è©ä¼°ï¼AutoRestTest å¨ç¨å¼ç¢¼è¦èçãæä½è¦èçåé¯èª¤åµæ¸¬æ¹é¢ï¼åªæ¼åç¨®é åçé»ç REST API æ¸¬è©¦å·¥å·ï¼åæ¬é£äºç± RESTGPTï¼ä½¿ç¨ LLM å¢å é¼ççæ¸¬è©¦è¼¸å¥ï¼è¼å©çå·¥å·ãå¼å¾æ³¨æçæ¯ï¼AutoRestTest æ¯å¯ä¸è½å¤ è­å¥ Spotify ä¸­å§é¨ä¼ºæå¨é¯èª¤çå·¥å·ãæåçæ¶èç ç©¶å¼·èª¿äºä»£çå­¸ç¿ãSPDG å LLM çµä»¶çéå¤§è²¢ç»ã</paragraph>

##### **Bridge: A Unified Framework to Knowledge Graph Completion via Language Models and Knowledge Representation**
2411.06660v1 by Qiao Qiao, Yuepei Li, Qing Wang, Kang Zhou, Qi Li

Knowledge graph completion (KGC) is a task of inferring missing triples based
on existing Knowledge Graphs (KGs). Both structural and semantic information
are vital for successful KGC. However, existing methods only use either the
structural knowledge from the KG embeddings or the semantic information from
pre-trained language models (PLMs), leading to suboptimal model performance.
Moreover, since PLMs are not trained on KGs, directly using PLMs to encode
triples may be inappropriate. To overcome these limitations, we propose a novel
framework called Bridge, which jointly encodes structural and semantic
information of KGs. Specifically, we strategically encode entities and
relations separately by PLMs to better utilize the semantic knowledge of PLMs
and enable structured representation learning via a structural learning
principle. Furthermore, to bridge the gap between KGs and PLMs, we employ a
self-supervised representation learning method called BYOL to fine-tune PLMs
with two different views of a triple. Unlike BYOL, which uses augmentation
methods to create two semantically similar views of the same image, potentially
altering the semantic information. We strategically separate the triple into
two parts to create different views, thus avoiding semantic alteration.
Experiments demonstrate that Bridge outperforms the SOTA models on three
benchmark datasets.

æè¦ï¼ç¥è­åè­è£å¨ (KGC) æ¯ä¸é æ ¹æç¾æç¥è­åè­ (KG) æ¨è«éºå¤±ä¸åçµçä»»åãçµæ§åèªç¾©è³è¨å°æ¼æåç KGC è³ééè¦ãç¶èï¼ç¾ææ¹æ³åä½¿ç¨ä¾èª KG åµå¥ççµæ§ç¥è­æä¾èªé è¨ç·´èªè¨æ¨¡å (PLM) çèªç¾©è³è¨ï¼å°è´æ¨¡åæè½ä¸ä½³ãæ­¤å¤ï¼ç±æ¼ PLM æ²æå¨ KG ä¸è¨ç·´ï¼å æ­¤ç´æ¥ä½¿ç¨ PLM ç·¨ç¢¼ä¸åçµå¯è½ä¸¦ä¸é©ç¶ãçºäºåæéäºéå¶ï¼æåæåºä¸ååçº Bridge çæ°æ¶æ§ï¼è©²æ¶æ§è¯åç·¨ç¢¼ KG ççµæ§åèªç¾©è³è¨ãå·é«ä¾èªªï¼æåéé PLM åå¥å°å¯¦é«åéä¿é²è¡ç­ç¥æ§ç·¨ç¢¼ï¼ä»¥æ´å¥½å°å©ç¨ PLM çèªç¾©ç¥è­ï¼ä¸¦ééçµæ§å­¸ç¿åååç¨çµæ§åè¡¨ç¤ºå­¸ç¿ãæ­¤å¤ï¼çºäºå½å KG å PLM ä¹éçå·®è·ï¼æåæ¡ç¨ä¸ç¨®ç¨±çº BYOL çèªç£ç£è¡¨ç¤ºå­¸ç¿æ¹æ³ï¼ä»¥ä¸åçµçå©åä¸åè¦åå¾®èª¿ PLMãè BYOL ä¸åï¼BYOL ä½¿ç¨æ´åæ¹æ³ä¾å»ºç«å©åèªç¾©ä¸ç¸ä¼¼çç¸åå½±åè¦åï¼å¯è½ææ¹è®èªç¾©è³è¨ãæåç­ç¥æ§å°å°ä¸åçµåçºå©é¨åä»¥å»ºç«ä¸åçè¦åï¼å¾èé¿åèªç¾©æ¹è®ãå¯¦é©è­æ Bridge å¨ä¸ååºæºè³æéä¸åªæ¼ SOTA æ¨¡åã

##### **CausalStock: Deep End-to-end Causal Discovery for News-driven Stock Movement Prediction**
2411.06391v1 by Shuqi Li, Yuebo Sun, Yuxin Lin, Xin Gao, Shuo Shang, Rui Yan

There are two issues in news-driven multi-stock movement prediction tasks
that are not well solved in the existing works. On the one hand, "relation
discovery" is a pivotal part when leveraging the price information of other
stocks to achieve accurate stock movement prediction. Given that stock
relations are often unidirectional, such as the "supplier-consumer"
relationship, causal relations are more appropriate to capture the impact
between stocks. On the other hand, there is substantial noise existing in the
news data leading to extracting effective information with difficulty. With
these two issues in mind, we propose a novel framework called CausalStock for
news-driven multi-stock movement prediction, which discovers the temporal
causal relations between stocks. We design a lag-dependent temporal causal
discovery mechanism to model the temporal causal graph distribution. Then a
Functional Causal Model is employed to encapsulate the discovered causal
relations and predict the stock movements. Additionally, we propose a Denoised
News Encoder by taking advantage of the excellent text evaluation ability of
large language models (LLMs) to extract useful information from massive news
data. The experiment results show that CausalStock outperforms the strong
baselines for both news-driven multi-stock movement prediction and multi-stock
movement prediction tasks on six real-world datasets collected from the US,
China, Japan, and UK markets. Moreover, getting benefit from the causal
relations, CausalStock could offer a clear prediction mechanism with good
explainability.

æè¦ï¼<paragraph>å¨æ°èé©åçå¤è¡ç¥¨ç§»åé æ¸¬ä»»åä¸­ï¼ç¾æç ç©¶å°æªå¦¥åè§£æ±ºå©ååé¡ãä¸æ¹é¢ï¼å¨å©ç¨å¶ä»è¡ç¥¨çå¹æ ¼è³è¨ä¾å¯¦ç¾æºç¢ºçè¡ç¥¨ç§»åé æ¸¬æï¼ãéä¿ç¼ç¾ãæ¯ä¸åééµé¨åãç±æ¼è¡ç¥¨éä¿éå¸¸æ¯å®åçï¼ä¾å¦ãä¾æå-æ¶è²»èãéä¿ï¼å æ­¤å æéä¿æ´é©åææè¡ç¥¨ä¹éçå½±é¿ãå¦ä¸æ¹é¢ï¼æ°èè³æä¸­å­å¨å¤§ééè¨ï¼å°è´é£ä»¥æåææè³è¨ãèæ®å°éå©ååé¡ï¼æåæåºäºä¸ååçº CausalStock çæ°æ¡æ¶ï¼ç¨æ¼æ°èé©åçå¤è¡ç¥¨ç§»åé æ¸¬ï¼è©²æ¡æ¶ç¼ç¾äºè¡ç¥¨ä¹éçæåºå æéä¿ãæåè¨­è¨äºä¸åå»¶é²ä¾è³´çæåºå æç¼ç¾æ©å¶ï¼ä»¥å»ºæ¨¡æåºå æååå¸ãç¶å¾æ¡ç¨åè½å ææ¨¡åä¾å°è£ç¼ç¾çå æéä¿ä¸¦é æ¸¬è¡ç¥¨èµ°å¢ãæ­¤å¤ï¼æåæåºäºä¸åå»åªæ°èç·¨ç¢¼å¨ï¼å©ç¨å¤§åèªè¨æ¨¡å (LLM) åºè²çææ¬è©ä¼°è½åå¾å¤§éæ°èè³æä¸­æåæç¨è³è¨ãå¯¦é©çµæè¡¨æï¼CausalStock å¨å¾ç¾åãä¸­åãæ¥æ¬åè±åå¸å ´æ¶éçå­åçå¯¦ä¸çè³æéä¸ï¼å¨æ°èé©åçå¤è¡ç¥¨ç§»åé æ¸¬åå¤è¡ç¥¨ç§»åé æ¸¬ä»»åä¸­é½åªæ¼å¼·å¤§çåºç·ãæ­¤å¤ï¼CausalStock åçæ¼å æéä¿ï¼å¯ä»¥æä¾å·æè¯å¥½å¯è§£éæ§çæ¸æ°é æ¸¬æ©å¶ã</paragraph>

##### **Analyzing the Evolution of Graphs and Texts**
2411.06295v1 by Xingzhi Guo

With the recent advance of representation learning algorithms on graphs
(e.g., DeepWalk/GraphSage) and natural languages (e.g., Word2Vec/BERT) , the
state-of-the art models can even achieve human-level performance over many
downstream tasks, particularly for the task of node and sentence
classification. However, most algorithms focus on large-scale models for static
graphs and text corpus without considering the inherent dynamic characteristics
or discovering the reasons behind the changes. This dissertation aims to
efficiently model the dynamics in graphs (such as social networks and citation
graphs) and understand the changes in texts (specifically news titles and
personal biographies). To achieve this goal, we utilize the renowned
Personalized PageRank algorithm to create effective dynamic network embeddings
for evolving graphs. Our proposed approaches significantly improve the running
time and accuracy for both detecting network abnormal intruders and discovering
entity meaning shifts over large-scale dynamic graphs. For text changes, we
analyze the post-publication changes in news titles to understand the intents
behind the edits and discuss the potential impact of titles changes from
information integrity perspective. Moreover, we investigate self-presented
occupational identities in Twitter users' biographies over five years,
investigating job prestige and demographics effects in how people disclose
jobs, quantifying over-represented jobs and their transitions over time.

æè¦ï¼é¨èåå½¢è¡¨ç¤ºå­¸ç¿æ¼ç®æ³çææ°é²å±ï¼ä¾å¦ DeepWalk/GraphSageï¼åèªç¶èªè¨ï¼ä¾å¦ Word2Vec/BERTï¼ï¼æåé²çæ¨¡åçè³å¯ä»¥å¨è¨±å¤ä¸æ¸¸ä»»åä¸­éå°äººé¡ç­ç´çæè½ï¼ç¹å¥æ¯å°æ¼ç¯é»åå¥å­åé¡çä»»åãç¶èï¼å¤§å¤æ¸æ¼ç®æ³é½å°æ³¨æ¼éæåå½¢åå¤§è¦æ¨¡æå­èªæåº«çæ¨¡åï¼èæ²æèæ®åºæçåæç¹æ§ææ¾åºè®åçåå ãæ¬è«ææ¨å¨ææå°çºåå½¢ï¼ä¾å¦ç¤¾ç¾¤ç¶²è·¯åå¼æåå½¢ï¼å»ºæ¨¡åæï¼ä¸¦äºè§£æå­çè®åï¼ç¹å¥æ¯æ°èæ¨é¡ååäººå³è¨ï¼ãçºäºéæéåç®æ¨ï¼æåå©ç¨èåç Personalized PageRank æ¼ç®æ³çºä¸æ·è®åçåå½¢å»ºç«ææçåæç¶²è·¯åµå¥ãæåæåºçæ¹æ³é¡¯èæ¹åäºåµæ¸¬ç¶²è·¯ç°å¸¸å¥ä¾µèåæ¾åºå¤§è¦æ¨¡åæåå½¢ä¸­å¯¦é«å«ç¾©è½ç§»çå·è¡æéåæºç¢ºåº¦ãå°æ¼æå­è®åçé¨åï¼æååæäºæ°èæ¨é¡å¨åºçå¾çè®åï¼ä»¥äºè§£ç·¨è¼¯èå¾çæåï¼ä¸¦è¨è«æ¨é¡è®æ´å°è³è¨å®æ´æ§çæ½å¨å½±é¿ãæ­¤å¤ï¼æåèª¿æ¥äº Twitter ä½¿ç¨èå¨å³è¨ä¸­åç¾çè·æ¥­èº«åé·éäºå¹´ï¼æ¢è¨äºå·¥ä½è²æåäººå£çµ±è¨è³æå°äººåæ­é²å·¥ä½çå½±é¿ï¼ä¸¦éåäºéåº¦ä»£è¡¨çå·¥ä½åå¶é¨èæéæ¨ç§»çè½è®ã

##### **An Empirical Analysis on Spatial Reasoning Capabilities of Large Multimodal Models**
2411.06048v1 by Fatemeh Shiri, Xiao-Yu Guo, Mona Golestan Far, Xin Yu, Gholamreza Haffari, Yuan-Fang Li

Large Multimodal Models (LMMs) have achieved strong performance across a
range of vision and language tasks. However, their spatial reasoning
capabilities are under-investigated. In this paper, we construct a novel VQA
dataset, Spatial-MM, to comprehensively study LMMs' spatial understanding and
reasoning capabilities. Our analyses on object-relationship and multi-hop
reasoning reveal several important findings. Firstly, bounding boxes and scene
graphs, even synthetic ones, can significantly enhance LMMs' spatial reasoning.
Secondly, LMMs struggle more with questions posed from the human perspective
than the camera perspective about the image. Thirdly, chain of thought (CoT)
prompting does not improve model performance on complex multi-hop questions
involving spatial relations. % Moreover, spatial reasoning steps are much less
accurate than non-spatial ones across MLLMs. Lastly, our perturbation analysis
on GQA-spatial reveals that LMMs are much stronger at basic object detection
than complex spatial reasoning. We believe our benchmark dataset and in-depth
analyses can spark further research on LMMs spatial reasoning. Spatial-MM
benchmark is available at: https://github.com/FatemehShiri/Spatial-MM

æè¦ï¼å¤§åå¤æ¨¡ææ¨¡å (LMM) å·²å¨åç¨®è¦è¦ºåèªè¨ä»»åä¸­åå¾å¼·åçè¡¨ç¾ãç¶èï¼å®åçç©ºéæ¨çè½åå°æªå¾å°ååç ç©¶ãå¨æ¬æä¸­ï¼æåæ§å»ºäºä¸åæ°ç©ç VQA è³æé Spatial-MMï¼ä»¥å¨é¢ç ç©¶ LMM çç©ºéçè§£åæ¨çè½åãæåå°ç©ä»¶éä¿åå¤è·³æ¨ççåææ­ç¤ºäºå¹¾åéè¦çç¼ç¾ãé¦åï¼éçæ¡åå ´æ¯åï¼å³ä½¿æ¯åæçï¼ä¹å¯ä»¥é¡¯èå¢å¼· LMM çç©ºéæ¨çè½åãå¶æ¬¡ï¼LMM å¨åç­å¾äººé¡è¦è§æåºçåé¡ææ¯å¾ç¸æ©è¦è§æåºçåé¡æéå°æ´å¤å°é£ãç¬¬ä¸ï¼æèé (CoT) æç¤ºä¸¦æªæ¹åæ¨¡åå¨æ¶åç©ºééä¿çè¤éå¤è·³åé¡ä¸çæè½ã% æ­¤å¤ï¼å¨ MLLM ä¸­ï¼ç©ºéæ¨çæ­¥é©çæºç¢ºåº¦é ä½æ¼éç©ºéæ­¥é©ãæå¾ï¼æåå° GQA-spatial çæ¾ååæè¡¨æï¼LMM å¨åºæ¬ç©ä»¶åµæ¸¬æ¹é¢çè½åé å¼·æ¼è¤éçç©ºéæ¨çãæåç¸ä¿¡æåçåºæºè³æéåæ·±å¥åæå¯ä»¥æ¿ç¼å° LMM ç©ºéæ¨ççé²ä¸æ­¥ç ç©¶ãSpatial-MM åºæºå¯å¨ä»¥ä¸ç¶²ååå¾ï¼https://github.com/FatemehShiri/Spatial-MM


### Medical
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-12-11**|**IRL for Restless Multi-Armed Bandits with Applications in Maternal and Child Health**|Gauri Jain et.al.|[2412.08463v1](http://arxiv.org/abs/2412.08463v1)|[link](https://github.com/gjain234/whirl)|
|**2024-12-11**|**SmolTulu: Higher Learning Rate to Batch Size Ratios Can Lead to Better Reasoning in SLMs**|Sultan Alrashed et.al.|[2412.08347v1](http://arxiv.org/abs/2412.08347v1)|null|
|**2024-12-11**|**Hierarchical Classification for Automated Image Annotation of Coral Reef Benthic Structures**|CÃ©lia Blondin et.al.|[2412.08228v1](http://arxiv.org/abs/2412.08228v1)|null|
|**2024-12-11**|**How to select slices for annotation to train best-performing deep learning segmentation models for cross-sectional medical images?**|Yixin Zhang et.al.|[2412.08081v1](http://arxiv.org/abs/2412.08081v1)|null|
|**2024-12-11**|**Can a MISL Fly? Analysis and Ingredients for Mutual Information Skill Learning**|Chongyi Zheng et.al.|[2412.08021v1](http://arxiv.org/abs/2412.08021v1)|null|
|**2024-12-10**|**From Lived Experience to Insight: Unpacking the Psychological Risks of Using AI Conversational Agents**|Mohit Chandra et.al.|[2412.07951v1](http://arxiv.org/abs/2412.07951v1)|null|
|**2024-12-10**|**How Should We Represent History in Interpretable Models of Clinical Policies?**|Anton Matsson et.al.|[2412.07895v1](http://arxiv.org/abs/2412.07895v1)|null|
|**2024-12-10**|**Towards Foundation-model-based Multiagent System to Accelerate AI for Social Impact**|Yunfan Zhao et.al.|[2412.07880v1](http://arxiv.org/abs/2412.07880v1)|null|
|**2024-12-10**|**Comparative Analysis of Deep Learning Approaches for Harmful Brain Activity Detection Using EEG**|Shivraj Singh Bhatti et.al.|[2412.07878v1](http://arxiv.org/abs/2412.07878v1)|null|
|**2024-12-10**|**Adapting to Non-Stationary Environments: Multi-Armed Bandit Enhanced Retrieval-Augmented Generation on Knowledge Graphs**|Xiaqiang Tang et.al.|[2412.07618v1](http://arxiv.org/abs/2412.07618v1)|[link](https://github.com/futureeeeee/dynamic-rag)|
|**2024-12-10**|**Scaling Sequential Recommendation Models with Transformers**|Pablo Zivic et.al.|[2412.07585v1](http://arxiv.org/abs/2412.07585v1)|[link](https://github.com/mercadolibre/srt)|
|**2024-12-10**|**Knowledge Graph Guided Evaluation of Abstention Techniques**|Kinshuk Vasisht et.al.|[2412.07430v1](http://arxiv.org/abs/2412.07430v1)|null|
|**2024-12-10**|**A Review of Challenges in Speech-based Conversational AI for Elderly Care**|Willemijn Klaassen et.al.|[2412.07388v1](http://arxiv.org/abs/2412.07388v1)|null|
|**2024-12-10**|**Enhanced MRI Representation via Cross-series Masking**|Churan Wang et.al.|[2412.07387v1](http://arxiv.org/abs/2412.07387v1)|null|
|**2024-12-10**|**On Evaluating the Durability of Safeguards for Open-Weight LLMs**|Xiangyu Qi et.al.|[2412.07097v1](http://arxiv.org/abs/2412.07097v1)|null|
|**2024-12-09**|**Toward AI-Driven Digital Organism: Multiscale Foundation Models for Predicting, Simulating and Programming Biology at All Levels**|Le Song et.al.|[2412.06993v1](http://arxiv.org/abs/2412.06993v1)|[link](https://github.com/genbio-ai/aido)|
|**2024-12-09**|**Diagnosis and Severity Assessment of Ulcerative Colitis using Self Supervised Learning**|Venkat Margapuri et.al.|[2412.07806v1](http://arxiv.org/abs/2412.07806v1)|null|
|**2024-12-09**|**Toward Non-Invasive Diagnosis of Bankart Lesions with Deep Learning**|Sahil Sethi et.al.|[2412.06717v1](http://arxiv.org/abs/2412.06717v1)|null|
|**2024-12-09**|**Parkinson's Disease Diagnosis Through Deep Learning: A Novel LSTM-Based Approach for Freezing of Gait Detection**|Aqib Nazir Mir et.al.|[2412.06709v1](http://arxiv.org/abs/2412.06709v1)|null|
|**2024-12-09**|**Fundus Image-based Visual Acuity Assessment with PAC-Guarantees**|Sooyong Jang et.al.|[2412.06624v1](http://arxiv.org/abs/2412.06624v1)|null|
|**2024-12-09**|**Real-Time Performance Optimization of Travel Reservation Systems Using AI and Microservices**|Biman Barua et.al.|[2412.06874v1](http://arxiv.org/abs/2412.06874v1)|null|
|**2024-12-09**|**Advancing Music Therapy: Integrating Eastern Five-Element Music Theory and Western Techniques with AI in the Novel Five-Element Harmony System**|Yubo Zhou et.al.|[2412.06600v1](http://arxiv.org/abs/2412.06600v1)|null|
|**2024-12-09**|**HES-UNet: A U-Net for Hepatic Echinococcosis Lesion Segmentation**|Jiayan Chen et.al.|[2412.06530v1](http://arxiv.org/abs/2412.06530v1)|null|
|**2024-12-09**|**Simulating Human-like Daily Activities with Desire-driven Autonomy**|Yiding Wang et.al.|[2412.06435v1](http://arxiv.org/abs/2412.06435v1)|null|
|**2024-12-09**|**CAD-Unet: A Capsule Network-Enhanced Unet Architecture for Accurate Segmentation of COVID-19 Lung Infections from CT Images**|Yijie Dang et.al.|[2412.06314v1](http://arxiv.org/abs/2412.06314v1)|null|
|**2024-12-09**|**A Lightweight U-like Network Utilizing Neural Memory Ordinary Differential Equations for Slimming the Decoder**|Quansong He et.al.|[2412.06262v1](http://arxiv.org/abs/2412.06262v1)|[link](https://github.com/nayutayuki/lightweight-nmode-decoders-for-u-like-networks)|
|**2024-12-09**|**MSCrackMamba: Leveraging Vision Mamba for Crack Detection in Fused Multispectral Imagery**|Qinfeng Zhu et.al.|[2412.06211v1](http://arxiv.org/abs/2412.06211v1)|null|
|**2024-12-09**|**Balancing Efficiency and Effectiveness: An LLM-Infused Approach for Optimized CTR Prediction**|Guoxiao Zhang et.al.|[2412.06860v1](http://arxiv.org/abs/2412.06860v1)|null|
|**2024-12-09**|**MMedPO: Aligning Medical Vision-Language Models with Clinical-Aware Multimodal Preference Optimization**|Kangyu Zhu et.al.|[2412.06141v1](http://arxiv.org/abs/2412.06141v1)|[link](https://github.com/aiming-lab/mmedpo)|
|**2024-12-08**|**Imputation Matters: A Deeper Look into an Overlooked Step in Longitudinal Health and Behavior Sensing Research**|Akshat Choube et.al.|[2412.06018v1](http://arxiv.org/abs/2412.06018v1)|null|
|**2024-12-08**|**MG-3D: Multi-Grained Knowledge-Enhanced 3D Medical Vision-Language Pre-training**|Xuefeng Ni et.al.|[2412.05876v1](http://arxiv.org/abs/2412.05876v1)|[link](https://github.com/xuefeng-ni/mg-3d)|
|**2024-12-08**|**Evolving Algebraic Multigrid Methods Using Grammar-Guided Genetic Programming**|Dinesh Parthasarathy et.al.|[2412.05852v1](http://arxiv.org/abs/2412.05852v1)|null|
|**2024-12-07**|**Biological Brain Age Estimation using Sex-Aware Adversarial Variational Autoencoder with Multimodal Neuroimages**|Abd Ur Rehman et.al.|[2412.05632v1](http://arxiv.org/abs/2412.05632v1)|null|
|**2024-12-07**|**UNet++ and LSTM combined approach for Breast Ultrasound Image Segmentation**|Saba Hesaraki et.al.|[2412.05585v1](http://arxiv.org/abs/2412.05585v1)|null|
|**2024-12-07**|**Electrocardiogram (ECG) Based Cardiac Arrhythmia Detection and Classification using Machine Learning Algorithms**|Atit Pokharel et.al.|[2412.05583v2](http://arxiv.org/abs/2412.05583v2)|null|
|**2024-12-07**|**Comprehensive Evaluation of Multimodal AI Models in Medical Imaging Diagnosis: From Data Augmentation to Preference-Based Comparison**|Cailian Ruan et.al.|[2412.05536v1](http://arxiv.org/abs/2412.05536v1)|null|
|**2024-12-06**|**Enhancing LLMs for Impression Generation in Radiology Reports through a Multi-Agent System**|Fang Zeng et.al.|[2412.06828v1](http://arxiv.org/abs/2412.06828v1)|null|
|**2024-12-06**|**Enhancing FKG.in: automating Indian food composition analysis**|Saransh Kumar Gupta et.al.|[2412.05248v2](http://arxiv.org/abs/2412.05248v2)|null|
|**2024-12-06**|**Are Frontier Large Language Models Suitable for Q&A in Science Centres?**|Jacob Watson et.al.|[2412.05200v1](http://arxiv.org/abs/2412.05200v1)|null|
|**2024-12-06**|**SurgBox: Agent-Driven Operating Room Sandbox with Surgery Copilot**|Jinlin Wu et.al.|[2412.05187v1](http://arxiv.org/abs/2412.05187v1)|[link](https://github.com/franciszchen/surgbox)|
|**2024-12-06**|**Project Report: Requirements for a Social Robot as an Information Provider in the Public Sector**|Thomas Sievers et.al.|[2412.05013v1](http://arxiv.org/abs/2412.05013v1)|null|
|**2024-12-06**|**Backdooring Outlier Detection Methods: A Novel Attack Approach**|ZeinabSadat Taghavi et.al.|[2412.05010v1](http://arxiv.org/abs/2412.05010v1)|null|
|**2024-12-06**|**Bed-Attached Vibration Sensor System: A Machine Learning Approach for Fall Detection in Nursing Homes**|Thomas Bartz-Beielstein et.al.|[2412.04950v1](http://arxiv.org/abs/2412.04950v1)|null|
|**2024-12-06**|**Estimating the treatment effect over time under general interference through deep learner integrated TMLE**|Suhan Guo et.al.|[2412.04799v1](http://arxiv.org/abs/2412.04799v1)|null|
|**2024-12-06**|**Multi-class heart disease Detection, Classification, and Prediction using Machine Learning Models**|Mahfuzul Haque et.al.|[2412.04792v1](http://arxiv.org/abs/2412.04792v1)|null|
|**2024-12-06**|**DAWN-SI: Data-Aware and Noise-Informed Stochastic Interpolation for Solving Inverse Problems**|Shadab Ahamed et.al.|[2412.04766v1](http://arxiv.org/abs/2412.04766v1)|null|
|**2024-12-06**|**PCTreeS: 3D Point Cloud Tree Species Classification Using Airborne LiDAR Images**|Hongjin Lin et.al.|[2412.04714v1](http://arxiv.org/abs/2412.04714v1)|null|
|**2024-12-05**|**Semantic Consistency-Based Uncertainty Quantification for Factuality in Radiology Report Generation**|Chenyu Wang et.al.|[2412.04606v1](http://arxiv.org/abs/2412.04606v1)|null|
|**2024-12-05**|**CLINICSUM: Utilizing Language Models for Generating Clinical Summaries from Patient-Doctor Conversations**|Subash Neupane et.al.|[2412.04254v1](http://arxiv.org/abs/2412.04254v1)|null|
|**2024-12-05**|**Automated Medical Report Generation for ECG Data: Bridging Medical Text and Signal Processing with Deep Learning**|Amnon Bleich et.al.|[2412.04067v1](http://arxiv.org/abs/2412.04067v1)|null|
|**2024-12-05**|**FedMetaMed: Federated Meta-Learning for Personalized Medication in Distributed Healthcare Systems**|Jiechao Gao et.al.|[2412.03851v1](http://arxiv.org/abs/2412.03851v1)|null|
|**2024-12-05**|**ELEMENT: Episodic and Lifelong Exploration via Maximum Entropy**|Hongming Li et.al.|[2412.03800v1](http://arxiv.org/abs/2412.03800v1)|null|
|**2024-12-05**|**Automated Multi-Label Annotation for Mental Health Illnesses Using Large Language Models**|Abdelrahaman A. Hassan et.al.|[2412.03796v1](http://arxiv.org/abs/2412.03796v1)|null|
|**2024-12-05**|**Speech Recognition-based Feature Extraction for Enhanced Automatic Severity Classification in Dysarthric Speech**|Yerin Choi et.al.|[2412.03784v1](http://arxiv.org/abs/2412.03784v1)|null|
|**2024-12-04**|**Exploring the Role of AI-Powered Chatbots for Teens and Young Adults with ASD or Social Anxiety**|Dilan Mian et.al.|[2412.03740v1](http://arxiv.org/abs/2412.03740v1)|null|
|**2024-12-04**|**MRGen: Diffusion-based Controllable Data Engine for MRI Segmentation towards Unannotated Modalities**|Haoning Wu et.al.|[2412.04106v1](http://arxiv.org/abs/2412.04106v1)|null|
|**2024-12-04**|**Intuitive Axial Augmentation Using Polar-Sine-Based Piecewise Distortion for Medical Slice-Wise Segmentation**|Yiqin Zhang et.al.|[2412.03352v1](http://arxiv.org/abs/2412.03352v1)|[link](https://github.com/mgamz/psbpd)|
|**2024-12-04**|**Detecting abnormal heart sound using mobile phones and on-device IConNet**|Linh Vu et.al.|[2412.03267v1](http://arxiv.org/abs/2412.03267v1)|null|
|**2024-12-04**|**MRNet: Multifaceted Resilient Networks for Medical Image-to-Image Translation**|Hyojeong Lee et.al.|[2412.03039v1](http://arxiv.org/abs/2412.03039v1)|null|
|**2024-12-04**|**Higher Order Transformers: Efficient Attention Mechanism for Tensor Structured Data**|Soroush Omranpour et.al.|[2412.02919v1](http://arxiv.org/abs/2412.02919v1)|null|
|**2024-12-03**|**A Novel Compact LLM Framework for Local, High-Privacy EHR Data Applications**|Yixiang Qu et.al.|[2412.02868v1](http://arxiv.org/abs/2412.02868v1)|null|
|**2024-12-03**|**Block MedCare: Advancing healthcare through blockchain integration with AI and IoT**|Oliver Simonoski et.al.|[2412.02851v1](http://arxiv.org/abs/2412.02851v1)|null|
|**2024-12-03**|**CNNSum: Exploring Long-Context Summarization with Large Language Models in Chinese Novels**|Lingxiao Wei et.al.|[2412.02819v3](http://arxiv.org/abs/2412.02819v3)|null|
|**2024-12-03**|**Optimization of Transformer heart disease prediction model based on particle swarm optimization algorithm**|Jingyuan Yi et.al.|[2412.02801v2](http://arxiv.org/abs/2412.02801v2)|null|
|**2024-12-03**|**Medical Multimodal Foundation Models in Clinical Diagnosis and Treatment: Applications, Challenges, and Future Directions**|Kai Sun et.al.|[2412.02621v1](http://arxiv.org/abs/2412.02621v1)|null|
|**2024-12-03**|**U-Net in Medical Image Segmentation: A Review of Its Applications Across Modalities**|Fnu Neha et.al.|[2412.02242v1](http://arxiv.org/abs/2412.02242v1)|null|
|**2024-12-03**|**Recovering implicit physics model under real-world constraints**|Ayan Banerjee et.al.|[2412.02215v1](http://arxiv.org/abs/2412.02215v1)|null|
|**2024-12-03**|**Comparative Performance of Machine Learning Algorithms for Early Genetic Disorder and Subclass Classification**|Abu Bakar Siddik et.al.|[2412.02189v1](http://arxiv.org/abs/2412.02189v1)|null|
|**2024-12-03**|**Anatomically-Grounded Fact Checking of Automated Chest X-ray Reports**|R. Mahmood et.al.|[2412.02177v1](http://arxiv.org/abs/2412.02177v1)|null|
|**2024-12-03**|**Keeping Experts in the Loop: Expert-Guided Optimization for Clinical Data Classification using Large Language Models**|Nader Karayanni et.al.|[2412.02173v1](http://arxiv.org/abs/2412.02173v1)|null|
|**2024-12-03**|**Construction and optimization of health behavior prediction model for the elderly in smart elderly care**|Qian Guo et.al.|[2412.02062v1](http://arxiv.org/abs/2412.02062v1)|null|
|**2024-12-02**|**INSIGHT: Explainable Weakly-Supervised Medical Image Analysis**|Wenbo Zhang et.al.|[2412.02012v2](http://arxiv.org/abs/2412.02012v2)|null|
|**2024-12-02**|**The use of large language models to enhance cancer clinical trial educational materials**|Mingye Gao et.al.|[2412.01955v2](http://arxiv.org/abs/2412.01955v2)|null|
|**2024-12-02**|**Recurrent Neural Network on PICTURE Model**|Weihan Xu et.al.|[2412.01933v1](http://arxiv.org/abs/2412.01933v1)|null|
|**2024-12-02**|**ECG-SleepNet: Deep Learning-Based Comprehensive Sleep Stage Classification Using ECG Signals**|Poorya Aghaomidi et.al.|[2412.01929v1](http://arxiv.org/abs/2412.01929v1)|null|
|**2024-12-02**|**Deep Guess acceleration for explainable image reconstruction in sparse-view CT**|Elena Loli Piccolomini et.al.|[2412.01703v1](http://arxiv.org/abs/2412.01703v1)|[link](https://github.com/devangelista2/DeepGuess)|
|**2024-12-02**|**Digital Epidemiology: Leveraging Social Media for Insight into Epilepsy and Mental Health**|Liza Dahiya et.al.|[2412.01692v1](http://arxiv.org/abs/2412.01692v1)|null|
|**2024-12-02**|**Medchain: Bridging the Gap Between LLM Agents and Clinical Practice through Interactive Sequential Benchmarking**|Jie Liu et.al.|[2412.01605v1](http://arxiv.org/abs/2412.01605v1)|null|
|**2024-12-02**|**NCDD: Nearest Centroid Distance Deficit for Out-Of-Distribution Detection in Gastrointestinal Vision**|Sandesh Pokhrel et.al.|[2412.01590v1](http://arxiv.org/abs/2412.01590v1)|[link](https://github.com/bhattarailab/ncdd)|
|**2024-12-02**|**MambaU-Lite: A Lightweight Model based on Mamba and Integrated Channel-Spatial Attention for Skin Lesion Segmentation**|Thi-Nhu-Quynh Nguyen et.al.|[2412.01405v1](http://arxiv.org/abs/2412.01405v1)|[link](https://github.com/nqnguyen812/mambau-lite)|
|**2024-12-02**|**Su-RoBERTa: A Semi-supervised Approach to Predicting Suicide Risk through Social Media using Base Language Models**|Chayan Tank et.al.|[2412.01353v1](http://arxiv.org/abs/2412.01353v1)|null|
|**2024-12-02**|**Multimodal Medical Disease Classification with LLaMA II**|Christian Gapp et.al.|[2412.01306v1](http://arxiv.org/abs/2412.01306v1)|null|
|**2024-12-02**|**Best Practices for Large Language Models in Radiology**|Christian Bluethgen et.al.|[2412.01233v1](http://arxiv.org/abs/2412.01233v1)|null|
|**2024-12-02**|**Object Tracking in a $360^o$ View: A Novel Perspective on Bridging the Gap to Biomedical Advancements**|Mojtaba S. Fazli et.al.|[2412.01119v1](http://arxiv.org/abs/2412.01119v1)|null|
|**2024-12-02**|**Evaluating Automated Radiology Report Quality through Fine-Grained Phrasal Grounding of Clinical Findings**|Razi Mahmood et.al.|[2412.01031v2](http://arxiv.org/abs/2412.01031v2)|null|
|**2024-12-01**|**Generative Language Models Potential for Requirement Engineering Applications: Insights into Current Strengths and Limitations**|Summra Saleem et.al.|[2412.00959v1](http://arxiv.org/abs/2412.00959v1)|null|
|**2024-12-01**|**TSUBF-Net: Trans-Spatial UNet-like Network with Bi-direction Fusion for Segmentation of Adenoid Hypertrophy in CT**|Rulin Zhou et.al.|[2412.00787v1](http://arxiv.org/abs/2412.00787v1)|null|
|**2024-12-01**|**Automating Feedback Analysis in Surgical Training: Detection, Categorization, and Assessment**|Firdavs Nasriddinov et.al.|[2412.00760v1](http://arxiv.org/abs/2412.00760v1)|[link](https://github.com/firdavsn/SurgicalFeedbackAI)|
|**2024-11-30**|**Fairness at Every Intersection: Uncovering and Mitigating Intersectional Biases in Multimodal Clinical Predictions**|Resmi Ramachandranpillai et.al.|[2412.00606v1](http://arxiv.org/abs/2412.00606v1)|null|
|**2024-11-30**|**Opus: A Large Work Model for Complex Workflow Generation**|ThÃ©o Fagnoni et.al.|[2412.00573v2](http://arxiv.org/abs/2412.00573v2)|null|
|**2024-11-30**|**Polish Medical Exams: A new dataset for cross-lingual medical knowledge transfer assessment**|Åukasz Grzybowski et.al.|[2412.00559v1](http://arxiv.org/abs/2412.00559v1)|null|
|**2024-11-30**|**Unveiling Performance Challenges of Large Language Models in Low-Resource Healthcare: A Demographic Fairness Perspective**|Yue Zhou et.al.|[2412.00554v2](http://arxiv.org/abs/2412.00554v2)|null|
|**2024-11-30**|**2-Factor Retrieval for Improved Human-AI Decision Making in Radiology**|Jim Solomon et.al.|[2412.00372v1](http://arxiv.org/abs/2412.00372v1)|null|
|**2024-11-30**|**One Model for One Graph: A New Perspective for Pretraining with Cross-domain Graphs**|Jingzhe Liu et.al.|[2412.00315v1](http://arxiv.org/abs/2412.00315v1)|null|
|**2024-11-30**|**BOTS: Batch Bayesian Optimization of Extended Thompson Sampling for Severely Episode-Limited RL Settings**|Karine Karine et.al.|[2412.00308v1](http://arxiv.org/abs/2412.00308v1)|null|
|**2024-11-29**|**Fine Tuning Large Language Models to Deliver CBT for Depression**|Talha Tahir et.al.|[2412.00251v1](http://arxiv.org/abs/2412.00251v1)|[link](https://github.com/ttahir-git/FineTuning_LLMs_for_CBT_for_Depression)|
|**2024-11-29**|**Integrating Social Determinants of Health into Knowledge Graphs: Evaluating Prediction Bias and Fairness in Healthcare**|Tianqi Shang et.al.|[2412.00245v1](http://arxiv.org/abs/2412.00245v1)|[link](https://github.com/hwq0726/sdoh-kg)|
|**2024-11-29**|**Dynamic EEG-fMRI mapping: Revealing the relationship between brain connectivity and cognitive state**|Guiran Liu et.al.|[2411.19922v1](http://arxiv.org/abs/2411.19922v1)|null|
|**2024-11-29**|**Graph Neural Networks for Heart Failure Prediction on an EHR-Based Patient Similarity Graph**|Heloisa Oss Boll et.al.|[2411.19742v1](http://arxiv.org/abs/2411.19742v1)|[link](https://github.com/hossboll/patient-gnn)|
|**2024-11-29**|**Multimodal Whole Slide Foundation Model for Pathology**|Tong Ding et.al.|[2411.19666v1](http://arxiv.org/abs/2411.19666v1)|[link](https://github.com/mahmoodlab/titan)|

#### Abstracts
##### **IRL for Restless Multi-Armed Bandits with Applications in Maternal and Child Health**
2412.08463v1 by Gauri Jain, Pradeep Varakantham, Haifeng Xu, Aparna Taneja, Prashant Doshi, Milind Tambe

Public health practitioners often have the goal of monitoring patients and
maximizing patients' time spent in "favorable" or healthy states while being
constrained to using limited resources. Restless multi-armed bandits (RMAB) are
an effective model to solve this problem as they are helpful to allocate
limited resources among many agents under resource constraints, where patients
behave differently depending on whether they are intervened on or not. However,
RMABs assume the reward function is known. This is unrealistic in many public
health settings because patients face unique challenges and it is impossible
for a human to know who is most deserving of any intervention at such a large
scale. To address this shortcoming, this paper is the first to present the use
of inverse reinforcement learning (IRL) to learn desired rewards for RMABs, and
we demonstrate improved outcomes in a maternal and child health telehealth
program. First we allow public health experts to specify their goals at an
aggregate or population level and propose an algorithm to design expert
trajectories at scale based on those goals. Second, our algorithm WHIRL uses
gradient updates to optimize the objective, allowing for efficient and accurate
learning of RMAB rewards. Third, we compare with existing baselines and
outperform those in terms of run-time and accuracy. Finally, we evaluate and
show the usefulness of WHIRL on thousands on beneficiaries from a real-world
maternal and child health setting in India. We publicly release our code here:
https://github.com/Gjain234/WHIRL.

æè¦ï¼<paragraph>å¬å±è¡çå¾æ¥­äººå¡éå¸¸æç£æ§æ£èåæå¤§åæ£èèæ¼ãæå©ãæå¥åº·çæçæéçç®æ¨ï¼åæåå°æéè³æºçéå¶ãä¸å®åçå¤èå¼·ç (RMAB) æ¯è§£æ±ºæ­¤åé¡çæææ¨¡åï¼å çºå®åæå©æ¼å¨è³æºéå¶ä¸ï¼å¨è¨±å¤ä»£çä¹éåéæéçè³æºï¼å¶ä¸­æ£èçè¡çºåæ±ºæ¼æ¯å¦å°å¶é²è¡å¹²é ãç¶èï¼RMAB åè¨­å·²ç¥åå ±å½æ¸ãéå¨è¨±å¤å¬å±è¡çç°å¢ä¸­æ¯ä¸åå¯¦éçï¼å çºæ£èé¢è¨ç¨ç¹çææ°ï¼èä¸å°æ¼å¦æ­¤å¤§è¦æ¨¡çå¹²é ï¼äººé¡ä¸å¯è½ç¥éèª°æéè¦å¹²é ãçºäºè§£æ±ºéåç¼ºé»ï¼æ¬æé¦æ¬¡æåºä½¿ç¨éåå¼·åå­¸ç¿ (IRL) ä¾å­¸ç¿ RMAB çææåå ±ï¼ä¸¦ä¸æåå¨æ¯å¬°å¥åº·é è·é«çè¨ç«ä¸­å±ç¤ºäºæ¹åççµæãé¦åï¼æååè¨±å¬å±è¡çå°å®¶å¨ç¸½é«æäººå£å±¤ç´æå®ä»åçç®æ¨ï¼ä¸¦æåºä¸åæ¼ç®æ³ä¾æ ¹æéäºç®æ¨å¤§è¦æ¨¡è¨­è¨å°å®¶è»è·¡ãå¶æ¬¡ï¼æåçæ¼ç®æ³ WHIRL ä½¿ç¨æ¢¯åº¦æ´æ°ä¾æä½³åç®æ¨ï¼åè¨±ææä¸æºç¢ºå°å­¸ç¿ RMAB åå ±ãç¬¬ä¸ï¼æåèç¾æçåºæºé²è¡æ¯è¼ï¼ä¸¦å¨å·è¡æéåæºç¢ºæ§æ¹é¢åªæ¼éäºåºæºãæå¾ï¼æåè©ä¼°ä¸¦å±ç¤ºäº WHIRL å¨å°åº¦å¯¦éæ¯å¬°å¥åº·ç°å¢ä¸­å°æ¸åååçèçæç¨æ§ãæåå¨æ­¤å¬éç¼å¸æåçç¨å¼ç¢¼ï¼https://github.com/Gjain234/WHIRLã</paragraph>

##### **SmolTulu: Higher Learning Rate to Batch Size Ratios Can Lead to Better Reasoning in SLMs**
2412.08347v1 by Sultan Alrashed

We present SmolTulu-1.7b-Instruct, referenced in this report as
SmolTulu-DPO-1130, an instruction-tuned language model that adapts AllenAI's
Tulu 3 post-training pipeline to enhance Huggingface's SmolLM2-1.7B base model.
Through comprehensive empirical analysis using a 135M parameter model, we
demonstrate that the relationship between learning rate and batch size
significantly impacts model performance in a task-dependent manner. Our
findings reveal a clear split: reasoning tasks like ARC and GSM8K benefit from
higher learning rate to batch size ratios, while pattern recognition tasks such
as HellaSwag and IFEval show optimal performance with lower ratios. These
insights informed the development of SmolTulu, which achieves state-of-the-art
performance among sub-2B parameter models on instruction following, scoring
67.7% on IFEval ($\Delta$11%), and mathematical reasoning with 51.6% on GSM8K
($\Delta$3.4%), with an alternate version achieving scoring 57.1% on ARC
($\Delta5.4%$). We release our model, training recipes, and ablation studies to
facilitate further research in efficient model alignment, demonstrating that
careful adaptation of optimization dynamics can help bridge the capability gap
between small and large language models.

æè¦ï¼æåæåº SmolTulu-1.7b-Instructï¼æ¬å ±åä¸­ç¨±çº SmolTulu-DPO-1130ï¼éæ¯ä¸ç¨®æä»¤èª¿æ´èªè¨æ¨¡åï¼æ¡ç¨ AllenAI ç Tulu 3 å¾è¨ç·´ç®¡éä¾å¢å¼· Huggingface ç SmolLM2-1.7B åºç¤æ¨¡åãééä½¿ç¨ 135M åæ¸æ¨¡åçå¨é¢ç¶é©åæï¼æåè­æå­¸ç¿çèæ¹æ¬¡å¤§å°ä¹éçéä¿æä»¥ä»»åç¸éçæ¹å¼é¡¯èå½±é¿æ¨¡åæè½ãæåçç¼ç¾æ­ç¤ºäºä¸åæç¢ºçåæ­§ï¼å ARC å GSM8K ç­æ¨çä»»ååçæ¼è¼é«çå­¸ç¿çå°æ¹æ¬¡å¤§å°çæ¯çï¼èå HellaSwag å IFEval ç­æ¨¡å¼è¾¨è­ä»»ååé¡¯ç¤ºåºè¼ä½æ¯ççæä½³æè½ãéäºè¦è§£çº SmolTulu çéç¼æä¾äºè³è¨ï¼å¨å°æ¼ 2B åæ¸æ¨¡åä¸­ï¼å¨æä»¤éµå¾ªæ¹é¢åå¾äºæåé²çè¡¨ç¾ï¼å¨ IFEval ä¸å¾å 67.7%ï¼Î11%ï¼ï¼å¨ GSM8K ä¸çæ¸å­¸æ¨çå¾åçº 51.6%ï¼Î3.4%ï¼ï¼èå¦ä¸åçæ¬å¨ ARC ä¸å¾å 57.1%ï¼Î5.4%ï¼ãæåç¼å¸æåçæ¨¡åãè¨ç·´ç¯ä¾åæ¶èç ç©¶ï¼ä»¥ä¿é²é«ææ¨¡åå°é½çé²ä¸æ­¥ç ç©¶ï¼è­æä»ç´°èª¿æ´æä½³ååæå¯ä»¥å¹«å©ç¸®å°å°ååå¤§åèªè¨æ¨¡åä¹éçè½åå·®è·ã

##### **Hierarchical Classification for Automated Image Annotation of Coral Reef Benthic Structures**
2412.08228v1 by CÃ©lia Blondin, Joris GuÃ©rin, Kelly Inagaki, Guilherme Longo, Laure Berti-Ãquille

Automated benthic image annotation is crucial to efficiently monitor and
protect coral reefs against climate change. Current machine learning approaches
fail to capture the hierarchical nature of benthic organisms covering reef
substrata, i.e., coral taxonomic levels and health condition. To address this
limitation, we propose to annotate benthic images using hierarchical
classification. Experiments on a custom dataset from a Northeast Brazilian
coral reef show that our approach outperforms flat classifiers, improving both
F1 and hierarchical F1 scores by approximately 2\% across varying amounts of
training data. In addition, this hierarchical method aligns more closely with
ecological objectives.

æè¦ï¼èªåååºæ£²å½±åè¨»è§£å°æ¼ææç£æ¸¬åä¿è­·ççç¤ååæ°£åè®é·å½±é¿è³ééè¦ãç®åçæ©å¨å­¸ç¿æ¹æ³ç¡æ³ææè¦èç¤ç³åºè³ªçåºæ£²çç©çéå±¤æ§è³ªï¼ä¾å¦ççåé¡ç­ç´åå¥åº·çæ³ãçºäºè§£æ±ºæ­¤éå¶ï¼æåå»ºè­°ä½¿ç¨éå±¤åé¡è¨»è§£åºæ£²å½±åãå°ä¾èªå·´è¥¿æ±åé¨ççç¤çèªè¨è³æéé²è¡çå¯¦é©é¡¯ç¤ºï¼æåçåæ³åªæ¼å¹³é¢åé¡å¨ï¼å¨ä¸åæ¸éçè¨ç·´è³æä¸­å° F1 åéå±¤ F1 åæ¸é½æé«äºå¤§ç´ 2%ãæ­¤å¤ï¼éç¨®éå±¤å¼æ¹æ³èçæç®æ¨æ´çºä¸è´ã

##### **How to select slices for annotation to train best-performing deep learning segmentation models for cross-sectional medical images?**
2412.08081v1 by Yixin Zhang, Kevin Kramer, Maciej A. Mazurowski

Automated segmentation of medical images highly depends on the availability
of accurate manual image annotations. Such annotations are very time-consuming
and costly to generate, and often require specialized expertise, particularly
for cross-sectional images which contain many slices for each patient. It is
crucial to ensure the best use of annotation resources. In this paper, we
systematically answer the question of how to select slices of cross-sectional
medical images in order to maximize performance of the resulting deep learning
segmentation models. We conducted experiments on 4 medical imaging segmentation
tasks with varying annotation budgets, numbers of annotated cases, numbers of
annotated slices per volume, slice selection techniques, and mask
interpolations. We found that:
  1) It is almost always preferable to annotate fewer slices per volume and
more volumes given an annotation budget. 2) Selecting slices for annotation by
unsupervised active learning (UAL) is not superior to selecting slices randomly
or at fixed intervals, provided that each volume is allocated the same number
of annotated slices. 3) Interpolating masks between annotated slices rarely
enhances model performance, with exceptions of some specific configuration for
3D models.

æè¦ï¼é«å­¸å½±åçèªåååå²é«åº¦ä¾è³´æ¼æºç¢ºçæåå½±åæ¨è¨»ãæ­¤é¡æ¨è¨»éå¸¸èæä¸çæææ¬é«æï¼ä¸éå¸¸éè¦å°æ¥­ç¥è­ï¼ç¹å¥æ¯å°æ¼æ¯åæ£èåå«è¨±å¤åççæ©«æ·é¢å½±åãç¢ºä¿æä½³å©ç¨æ¨è¨»è³æºè³ééè¦ãå¨æ¬æä¸­ï¼æåç³»çµ±æ§å°åç­äºå¦ä½é¸ææ©«æ·é¢é«å­¸å½±ååçä»¥æå¤§åæ·±åº¦å­¸ç¿åå²æ¨¡åæè½çåé¡ãæåéå° 4 é é«å­¸å½±ååå²ä»»åé²è¡äºå¯¦é©ï¼éäºä»»åå·æä¸åçæ¨è¨»é ç®ãæ¨è¨»æ¡ä¾æ¸ãæ¯åé«ç©çæ¨è¨»åçæ¸ãåçé¸ææè¡åé®ç½©å§æãæåç¼ç¾ï¼
1) å¨çµ¦å®æ¨è¨»é ç®çææ³ä¸ï¼å¹¾ä¹ç¸½æ¯åªåæ¨è¨»æ¯åé«ç©è¼å°åçåæ´å¤é«ç©ã2) éééç£ç£ä¸»åå­¸ç¿ (UAL) é¸æåçé²è¡æ¨è¨»ä¸¦ä¸åªæ¼é¨æ©æåºå®ééé¸æåçï¼åææ¯æ¯åé«ç©åéçæ¨è¨»åçæ¸ç¸åã3) å¨æ¨è¨»åçä¹éå§æé®ç½©å¾å°è½æåæ¨¡åæè½ï¼ä½æäº 3D æ¨¡åçç¹å®çµæé¤å¤ã

##### **Can a MISL Fly? Analysis and Ingredients for Mutual Information Skill Learning**
2412.08021v1 by Chongyi Zheng, Jens Tuyls, Joanne Peng, Benjamin Eysenbach

Self-supervised learning has the potential of lifting several of the key
challenges in reinforcement learning today, such as exploration, representation
learning, and reward design. Recent work (METRA) has effectively argued that
moving away from mutual information and instead optimizing a certain
Wasserstein distance is important for good performance. In this paper, we argue
that the benefits seen in that paper can largely be explained within the
existing framework of mutual information skill learning (MISL). Our analysis
suggests a new MISL method (contrastive successor features) that retains the
excellent performance of METRA with fewer moving parts, and highlights
connections between skill learning, contrastive representation learning, and
successor features. Finally, through careful ablation studies, we provide
further insight into some of the key ingredients for both our method and METRA.

æè¦ï¼èªæç£ç£å­¸ç¿ææ½åè§£æ±ºç¶ä»å¼·åå­¸ç¿ä¸­çå¹¾åééµææ°ï¼ä¾å¦æ¢ç´¢ãè¡¨å¾µå­¸ç¿åçåµè¨­è¨ãæè¿çç ç©¶ï¼METRAï¼ææå°è«è­äºé é¢äºä¿¡æ¯ä¸¦æ¹çºåªåæå Wasserstein è·é¢å°æ¼è¯å¥½çæ§è½å¾éè¦ãå¨æ¬æä¸­ï¼æåè«è­è©²è«æä¸­çå°çåªé»å¯ä»¥å¨äºä¿¡æ¯æè½å­¸ç¿ï¼MISLï¼çç¾ææ¡æ¶å§å¾å°å¾å¤§ç¨åº¦çè§£éãæåçåææåºäºä¸ç¨®æ°ç MISL æ¹æ³ï¼å°æ¯å¾ç¹¼ç¹å¾µï¼ï¼å®ä¿çäº METRA çåºè²æ§è½ï¼åææ¸å°äºæ´»åé¨ä»¶ï¼ä¸¦çªåºäºæè½å­¸ç¿ãå°æ¯è¡¨å¾µå­¸ç¿åå¾ç¹¼ç¹å¾µä¹éçè¯ç¹«ãæå¾ï¼ééä»ç´°çæ¶èç ç©¶ï¼æåé²ä¸æ­¥æ·±å¥äºè§£äºæåçæ¹æ³å METRA çä¸äºééµè¦ç´ ã

##### **From Lived Experience to Insight: Unpacking the Psychological Risks of Using AI Conversational Agents**
2412.07951v1 by Mohit Chandra, Suchismita Naik, Denae Ford, Ebele Okoli, Munmun De Choudhury, Mahsa Ershadi, Gonzalo Ramos, Javier Hernandez, Ananya Bhattacharjee, Shahed Warreth, Jina Suh

Recent gain in popularity of AI conversational agents has led to their
increased use for improving productivity and supporting well-being. While
previous research has aimed to understand the risks associated with
interactions with AI conversational agents, these studies often fall short in
capturing the lived experiences. Additionally, psychological risks have often
been presented as a sub-category within broader AI-related risks in past
taxonomy works, leading to under-representation of the impact of psychological
risks of AI use. To address these challenges, our work presents a novel risk
taxonomy focusing on psychological risks of using AI gathered through lived
experience of individuals. We employed a mixed-method approach, involving a
comprehensive survey with 283 individuals with lived mental health experience
and workshops involving lived experience experts to develop a psychological
risk taxonomy. Our taxonomy features 19 AI behaviors, 21 negative psychological
impacts, and 15 contexts related to individuals. Additionally, we propose a
novel multi-path vignette based framework for understanding the complex
interplay between AI behaviors, psychological impacts, and individual user
contexts. Finally, based on the feedback obtained from the workshop sessions,
we present design recommendations for developing safer and more robust AI
agents. Our work offers an in-depth understanding of the psychological risks
associated with AI conversational agents and provides actionable
recommendations for policymakers, researchers, and developers.

æè¦ï¼æè¿ AI å°è©±ä»£ççæ®åæé«äºå¶å¨æåçç¢ååæ¯æ´ç¦ç¥æ¹é¢çä½¿ç¨çãéç¶ååçç ç©¶æ¨å¨äºè§£è AI å°è©±ä»£çäºåç¸éçé¢¨éªï¼ä½éäºç ç©¶éå¸¸ç¡æ³ææå°å¯¦éç¶é©ãæ­¤å¤ï¼å¨éå»çåé¡å·¥ä½ä¸­ï¼å¿çé¢¨éªéå¸¸è¢«åç¾çºæ´å»£æ³ç AI ç¸éé¢¨éªä¸­çå­é¡å¥ï¼å°è´ AI ä½¿ç¨çå¿çé¢¨éªå½±é¿åè¢«ä½ä¼°ãçºäºæå°éäºææ°ï¼æåçç ç©¶æåºäºä¸ç¨®æ°ç©çé¢¨éªåé¡æ³ï¼éé»éæ³¨ééåäººå¯¦éç¶é©æ¶éå°ç AI ä½¿ç¨å¿çé¢¨éªãæåæ¡ç¨äºæ··åæ¹æ³ï¼åæ¬å° 283 ä½æå¯¦éå¿çå¥åº·ç¶é©çåäººé²è¡å¨é¢èª¿æ¥ï¼ä»¥åèå¯¦éç¶é©å°å®¶åä½çç è¨æï¼ä»¥å¶å®å¿çé¢¨éªåé¡æ³ãæåçåé¡æ³åå« 19 ç¨® AI è¡çºã21 ç¨®è² é¢å¿çå½±é¿å 15 ç¨®èåäººç¸éçèæ¯ãæ­¤å¤ï¼æåæåºäºä¸ç¨®æ°ç©çå¤è·¯å¾å°æååºæ¼æ¡æ¶ï¼ç¨æ¼çè§£ AI è¡çºãå¿çå½±é¿ååå¥ä½¿ç¨èèæ¯ä¹éçè¤éäº¤äºä½ç¨ãæå¾ï¼æ ¹æå¾ç è¨æä¸­ç²å¾çåé¥ï¼æåæåºäºè¨­è¨å»ºè­°ï¼ç¨æ¼éç¼æ´å®å¨ãæ´å¼·å¤§ç AI ä»£çãæåçç ç©¶æä¾äºå°è AI å°è©±ä»£çç¸éçå¿çé¢¨éªçæ·±å¥çè§£ï¼ä¸¦çºæ¿ç­å¶å®èãç ç©¶äººå¡åéç¼äººå¡æä¾äºå¯è¡çå»ºè­°ã

##### **How Should We Represent History in Interpretable Models of Clinical Policies?**
2412.07895v1 by Anton Matsson, Lena Stempfle, Yaochen Rao, Zachary R. Margolin, Heather J. Litman, Fredrik D. Johansson

Modeling policies for sequential clinical decision-making based on
observational data is useful for describing treatment practices, standardizing
frequent patterns in treatment, and evaluating alternative policies. For each
task, it is essential that the policy model is interpretable. Learning accurate
models requires effectively capturing the state of a patient, either through
sequence representation learning or carefully crafted summaries of their
medical history. While recent work has favored the former, it remains a
question as to how histories should best be represented for interpretable
policy modeling. Focused on model fit, we systematically compare diverse
approaches to summarizing patient history for interpretable modeling of
clinical policies across four sequential decision-making tasks. We illustrate
differences in the policies learned using various representations by breaking
down evaluations by patient subgroups, critical states, and stages of
treatment, highlighting challenges specific to common use cases. We find that
interpretable sequence models using learned representations perform on par with
black-box models across all tasks. Interpretable models using hand-crafted
representations perform substantially worse when ignoring history entirely, but
are made competitive by incorporating only a few aggregated and recent elements
of patient history. The added benefits of using a richer representation are
pronounced for subgroups and in specific use cases. This underscores the
importance of evaluating policy models in the context of their intended use.

æè¦ï¼åºæ¼è§å¯è³æå°åºè²«è¨åºæ±ºç­å¶å®å»ºæ¨¡æ¿ç­ï¼æå©æ¼æè¿°æ²»çå¯¦åãæ¨æºåæ²»çä¸­çå¸¸è¦æ¨¡å¼ï¼ä»¥åè©ä¼°æ¿ä»£æ¿ç­ãå°æ¼æ¯é ä»»åï¼æ¿ç­æ¨¡åçå¯è§£éæ§è³ééè¦ãå­¸ç¿ç²¾ç¢ºçæ¨¡åéè¦æææ·åæ£èççæï¼ç¡è«æ¯ééåºåè¡¨å¾µå­¸ç¿æç²¾å¿è£½ä½ççå²æè¦ãéç¶è¿æç ç©¶åå¥½åèï¼ä½å¦ä½ä»¥æä½³æ¹å¼è¡¨å¾µçå²ä»¥é²è¡å¯è§£éçæ¿ç­å»ºæ¨¡ï¼ä»æ¯ä¸ååé¡ãæåå°æ³¨æ¼æ¨¡åæ¬ååº¦ï¼ç³»çµ±æ§å°æ¯è¼åç¨®æè¦æ£èçå²çæ¹æ³ï¼ä»¥éå°åé åºè²«æ±ºç­å¶å®ä»»åé²è¡å¯è§£éçè¨åºæ¿ç­å»ºæ¨¡ãæåééææ£èå­ç¾¤ãå±æ¥çæåæ²»çéæ®µç´°åè©ä¼°ï¼ä¾èªªæä½¿ç¨åç¨®è¡¨å¾µæå­¸ç¿å°çæ¿ç­ä¹éçå·®ç°ï¼ä¸¦å¼·èª¿ç¹å®æ¼å¸¸è¦ä½¿ç¨æ¡ä¾çææ°ãæåç¼ç¾ï¼ä½¿ç¨å­¸ç¿è¡¨å¾µçå¯è§£éåºåæ¨¡åå¨ææä»»åä¸­è¡¨ç¾èé»ç®±æ¨¡åä¸ç¸ä¸ä¸ãä½¿ç¨æå·¥è£½ä½è¡¨å¾µçå¯è§£éæ¨¡åå¨å®å¨å¿½ç¥çå²æè¡¨ç¾æé¡¯è¼å·®ï¼ä½ééåç´å¥å°æ¸æ£èçå²çå½æ´åè¿æåç´ ï¼ä¾¿è½ä½¿å¶å·æç«¶ç­åãä½¿ç¨æ´è±å¯è¡¨å¾µçé¡å¤å¥½èå¨å­ç¾¤åç¹å®ä½¿ç¨æ¡ä¾ä¸­é¡¯èãéå¼·èª¿äºå¨é æç¨éçèçµ¡ä¸­è©ä¼°æ¿ç­æ¨¡åçéè¦æ§ã

##### **Towards Foundation-model-based Multiagent System to Accelerate AI for Social Impact**
2412.07880v1 by Yunfan Zhao, Niclas Boehmer, Aparna Taneja, Milind Tambe

AI for social impact (AI4SI) offers significant potential for addressing
complex societal challenges in areas such as public health, agriculture,
education, conservation, and public safety. However, existing AI4SI research is
often labor-intensive and resource-demanding, limiting its accessibility and
scalability; the standard approach is to design a (base-level) system tailored
to a specific AI4SI problem. We propose the development of a novel meta-level
multi-agent system designed to accelerate the development of such base-level
systems, thereby reducing the computational cost and the burden on social
impact domain experts and AI researchers. Leveraging advancements in foundation
models and large language models, our proposed approach focuses on resource
allocation problems providing help across the full AI4SI pipeline from problem
formulation over solution design to impact evaluation. We highlight the ethical
considerations and challenges inherent in deploying such systems and emphasize
the importance of a human-in-the-loop approach to ensure the responsible and
effective application of AI systems.

æè¦ï¼ç¤¾æå½±é¿åäººå·¥æºæ§ï¼AI4SIï¼å¨è§£æ±ºå¬å±è¡çãè¾²æ¥­ãæè²ãä¿è²åå¬å±å®å¨ç­é åçè¤éç¤¾æææ°æ¹é¢å·æé¡¯èçæ½åãç¶èï¼ç¾æç AI4SI ç ç©¶éå¸¸éè¦å¤§éäººååè³æºï¼éå¶äºå¶å¯åæ§åå¯æ´å±æ§ï¼æ¨æºæ¹æ³æ¯è¨­è¨ä¸åéå°ç¹å® AI4SI åé¡éèº«æé çï¼åºç¤å±¤ç´ï¼ç³»çµ±ãæåå»ºè­°éç¼ä¸åæ°ç©çåå±¤ç´å¤ä»£çç³»çµ±ï¼æ¨å¨å éæ­¤é¡åºç¤å±¤ç´ç³»çµ±çéç¼ï¼å¾èéä½è¨ç®ææ¬åç¤¾æå½±é¿åé åå°å®¶è AI ç ç©¶äººå¡çè² æãå©ç¨åºç¤æ¨¡ååå¤§åèªè¨æ¨¡åçé²å±ï¼æåæåºçæ¹æ³å°æ³¨æ¼è³æºåéåé¡ï¼å¨å¾åé¡è¡¨è¿°å°è§£æ±ºæ¹æ¡è¨­è¨åå°å½±é¿è©ä¼°çå®æ´ AI4SI ç®¡éä¸­æä¾å¹«å©ãæåå¼·èª¿é¨ç½²æ­¤é¡ç³»çµ±æåºæçéå¾·èéåææ°ï¼ä¸¦å¼·èª¿äººæ©åä½æ¹æ³å°æ¼ç¢ºä¿ AI ç³»çµ±è² è²¬ä»»ä¸ææå°æç¨è³ééè¦ã

##### **Comparative Analysis of Deep Learning Approaches for Harmful Brain Activity Detection Using EEG**
2412.07878v1 by Shivraj Singh Bhatti, Aryan Yadav, Mitali Monga, Neeraj Kumar

The classification of harmful brain activities, such as seizures and periodic
discharges, play a vital role in neurocritical care, enabling timely diagnosis
and intervention. Electroencephalography (EEG) provides a non-invasive method
for monitoring brain activity, but the manual interpretation of EEG signals are
time-consuming and rely heavily on expert judgment. This study presents a
comparative analysis of deep learning architectures, including Convolutional
Neural Networks (CNNs), Vision Transformers (ViTs), and EEGNet, applied to the
classification of harmful brain activities using both raw EEG data and
time-frequency representations generated through Continuous Wavelet Transform
(CWT). We evaluate the performance of these models use multimodal data
representations, including high-resolution spectrograms and waveform data, and
introduce a multi-stage training strategy to improve model robustness. Our
results show that training strategies, data preprocessing, and augmentation
techniques are as critical to model success as architecture choice, with
multi-stage TinyViT and EfficientNet demonstrating superior performance. The
findings underscore the importance of robust training regimes in achieving
accurate and efficient EEG classification, providing valuable insights for
deploying AI models in clinical practice.

æè¦ï¼æå®³è¦é¨æ´»åçåé¡ï¼ä¾å¦ç²çç¼ä½åé±ææ§æ¾é»ï¼å¨ç¥ç¶éçç§è­·ä¸­æ®æ¼èè³ééè¦çè§è²ï¼è½åæè¨ºæ·åä»å¥ãè¦é»å (EEG) æä¾äºä¸ç¨®éä¾µå¥å¼çæ¹æ³ä¾ç£æ¸¬è¦é¨æ´»åï¼ä½ EEG è¨èçæåå¤è®èæä¸é«åº¦ä¾è³´å°å®¶çå¤æ·ãæ¬ç ç©¶éå°æ·±åº¦å­¸ç¿æ¶æ§é²è¡æ¯è¼åæï¼åæ¬å·ç©ç¥ç¶ç¶²è·¯ (CNN)ãè¦è¦ºTransformer (ViT) å EEGNetï¼éç¨æ¼æå®³è¦é¨æ´»åçåé¡ï¼åæä½¿ç¨åå§ EEG è³æåééé£çºå°æ³¢è½æ (CWT) çæçæé »è¡¨ç¤ºãæåè©ä¼°éäºæ¨¡åä½¿ç¨å¤æ¨¡å¼è³æè¡¨ç¤ºçæè½ï¼åæ¬é«è§£æåº¦é »è­ååæ³¢å½¢è³æï¼ä¸¦å¼å¥å¤éæ®µè¨ç·´ç­ç¥ä¾æ¹åæ¨¡åçç©©å¥æ§ãæåççµæé¡¯ç¤ºï¼è¨ç·´ç­ç¥ãè³æåèçåæ´åæè¡å°æ¼æ¨¡åçæåèæ¶æ§é¸æä¸æ¨£éè¦ï¼å¶ä¸­å¤éæ®µ TinyViT å EfficientNet è¡¨ç¾åºåªç°çæè½ãéäºç¼ç¾å¼·èª¿äºç©©å¥è¨ç·´æ©å¶å°æ¼éææºç¢ºä¸ææçç EEG åé¡çéè¦æ§ï¼çºå¨è¨åºå¯¦åä¸­é¨ç½² AI æ¨¡åæä¾äºå¯¶è²´çè¦è§£ã

##### **Adapting to Non-Stationary Environments: Multi-Armed Bandit Enhanced Retrieval-Augmented Generation on Knowledge Graphs**
2412.07618v1 by Xiaqiang Tang, Jian Li, Nan Du, Sihong Xie

Despite the superior performance of Large language models on many NLP tasks,
they still face significant limitations in memorizing extensive world
knowledge. Recent studies have demonstrated that leveraging the
Retrieval-Augmented Generation (RAG) framework, combined with Knowledge Graphs
that encapsulate extensive factual data in a structured format, robustly
enhances the reasoning capabilities of LLMs. However, deploying such systems in
real-world scenarios presents challenges: the continuous evolution of
non-stationary environments may lead to performance degradation and user
satisfaction requires a careful balance of performance and responsiveness. To
address these challenges, we introduce a Multi-objective Multi-Armed Bandit
enhanced RAG framework, supported by multiple retrieval methods with diverse
capabilities under rich and evolving retrieval contexts in practice. Within
this framework, each retrieval method is treated as a distinct ``arm''. The
system utilizes real-time user feedback to adapt to dynamic environments, by
selecting the appropriate retrieval method based on input queries and the
historical multi-objective performance of each arm. Extensive experiments
conducted on two benchmark KGQA datasets demonstrate that our method
significantly outperforms baseline methods in non-stationary settings while
achieving state-of-the-art performance in stationary environments. Code and
data are available at https://github.com/FUTUREEEEEE/Dynamic-RAG.git

æè¦ï¼åç®¡å¤§åèªè¨æ¨¡åå¨è¨±å¤ NLP ä»»åä¸è¡¨ç¾åªç°ï¼
å®åå¨è¨æ¶å»£æ³çä¸çç¥è­æ¹é¢ä»é¢è¨éå¤§éå¶ãæè¿çç ç©¶è¡¨æï¼
å©ç¨æª¢ç´¢å¢å¼·çæ (RAG) æ¡æ¶ï¼çµåä»¥çµæ§åæ ¼å¼å°è£å»£æ³äºå¯¦è³æçç¥è­åè­ï¼
è½ç©©å¥å°å¢å¼· LLM çæ¨çè½åãç¶èï¼å¨ç¾å¯¦ä¸çå ´æ¯ä¸­é¨ç½²æ­¤é¡ç³»çµ±æç¢çææ°ï¼
éå¹³ç©©ç°å¢çæçºæ¼è®å¯è½å°è´æè½ä¸éï¼èä½¿ç¨èçæ»¿æåº¦éè¦å¨æè½ååææ§ä¹éåå¾ä»ç´°çå¹³è¡¡ã
çºäºæå°éäºææ°ï¼æåå¼å¥äºå¤ç®æ¨å¤èèèæ©å¢å¼·ç RAG æ¡æ¶ï¼
ä¸¦å¨å¯¦åä¸­æ¡ç¨å·åå¤åè½åçåç¨®æª¢ç´¢æ¹æ³ï¼ä»¥æå°è±å¯ä¸ä¸æ·æ¼è®çæª¢ç´¢æå¢ã
å¨æ­¤æ¡æ¶ä¸­ï¼æ¯åæª¢ç´¢æ¹æ³é½è¢«è¦çºä¸åä¸åçãæèãã
è©²ç³»çµ±å©ç¨å³æä½¿ç¨èåé¥ä¾é©æåæç°å¢ï¼
æ ¹æè¼¸å¥æ¥è©¢åæ¯åæèçæ­·å²å¤ç®æ¨æè½ä¾é¸æé©ç¶çæª¢ç´¢æ¹æ³ã
å¨å©ååºæº KGQA è³æéä¸é²è¡çå»£æ³å¯¦é©è¡¨æï¼
æåçæ¨¡åå¨éå¹³ç©©è¨­å®ä¸­é¡¯èåªæ¼åºç·æ¨¡åï¼åæå¨å¹³ç©©ç°å¢ä¸­éå°æåé²çæè½ã
ç¨å¼ç¢¼åè³æå¯æ¼ https://github.com/FUTUREEEEEE/Dynamic-RAG.git åå¾

##### **Scaling Sequential Recommendation Models with Transformers**
2412.07585v1 by Pablo Zivic, Hernan Vazquez, Jorge Sanchez

Modeling user preferences has been mainly addressed by looking at users'
interaction history with the different elements available in the system.
Tailoring content to individual preferences based on historical data is the
main goal of sequential recommendation.
  The nature of the problem, as well as the good performance observed across
various domains, has motivated the use of the transformer architecture, which
has proven effective in leveraging increasingly larger amounts of training data
when accompanied by an increase in the number of model parameters. This scaling
behavior has brought a great deal of attention, as it provides valuable
guidance in the design and training of even larger models.
  Taking inspiration from the scaling laws observed in training large language
models, we explore similar principles for sequential recommendation.
  We use the full Amazon Product Data dataset, which has only been partially
explored in other studies, and reveal scaling behaviors similar to those found
in language models. Compute-optimal training is possible but requires a careful
analysis of the compute-performance trade-offs specific to the application.
  We also show that performance scaling translates to downstream tasks by
fine-tuning larger pre-trained models on smaller task-specific domains. Our
approach and findings provide a strategic roadmap for model training and
deployment in real high-dimensional preference spaces, facilitating better
training and inference efficiency.
  We hope this paper bridges the gap between the potential of transformers and
the intrinsic complexities of high-dimensional sequential recommendation in
real-world recommender systems.
  Code and models can be found at https://github.com/mercadolibre/srt

æè¦ï¼<paragraph>å»ºæ¨¡ä½¿ç¨èåå¥½ä¸»è¦ééè§å¯ä½¿ç¨èèç³»çµ±ä¸­ä¸ååç´ çäºåè¨éã
æ ¹ææ­·å²è³æèª¿æ´åäººåå¥½çå§å®¹æ¯é£çºæ¨è¦çä¸»è¦ç®æ¨ã
åé¡çæ¬è³ªï¼ä»¥åå¨ååé åè§å¯å°çè¯å¥½æè½ï¼æ¿åµäºTransformeræ¶æ§çä½¿ç¨ï¼å¨å¢å æ¨¡ååæ¸æ¸éæï¼å·²è­æè½ææå©ç¨è¶ä¾è¶å¤è¨ç·´è³æãéç¨®è¦æ¨¡è¡çºå¼èµ·äºæ¥µå¤§çéæ³¨ï¼å çºå®å¨è¨­è¨åè¨ç·´æ´å¤§æ¨¡åææä¾äºæå¹å¼çæå°ã
å¾è¨ç·´å¤§åèªè¨æ¨¡åä¸­è§å¯å°çè¦æ¨¡æ³åä¸­æ±²åéæï¼æåæ¢è¨äºé£çºæ¨è¦çé¡ä¼¼ååã
æåä½¿ç¨äºå®æ´ç Amazon ç¢åè³æéï¼å¶ä»ç ç©¶åé¨åæ¢è¨éï¼ä¸¦æ­ç¤ºäºèå¨èªè¨æ¨¡åä¸­ç¼ç¾çé¡ä¼¼çè¦æ¨¡è¡çºãè¨ç®æä½³è¨ç·´æ¯å¯è½çï¼ä½éè¦ä»ç´°åæç¹å®æ¼æç¨ç¨å¼çè¨ç®æè½æè¡·ã
æåéå±ç¤ºäºæè½è¦æ¨¡è½åçºä¸æ¸¸ä»»åï¼ééå°è¼å°çç¹å®ä»»åé åå¾®èª¿è¼å¤§çé è¨ç·´æ¨¡åãæåçåæ³åç¼ç¾çºæ¨¡åè¨ç·´åå¨å¯¦éé«ç¶­åº¦åå¥½ç©ºéä¸­é¨ç½²æä¾äºç­ç¥æ§è·¯ç·åï¼ä¿é²æ´å¥½çè¨ç·´åæ¨çæçã
æåå¸æéç¯è«æè½å½åTransformeræ½åèå¯¦éæ¨è¦ç³»çµ±ä¸­é«ç¶­åº¦é£çºæ¨è¦çå§å¨è¤éæ§ä¹éçå·®è·ã
ç¨å¼ç¢¼åæ¨¡åå¯ä»¥å¨ https://github.com/mercadolibre/srt æ¾å°</paragraph>

##### **Knowledge Graph Guided Evaluation of Abstention Techniques**
2412.07430v1 by Kinshuk Vasisht, Navreet Kaur, Danish Pruthi

To deploy language models safely, it is crucial that they abstain from
responding to inappropriate requests. Several prior studies test the safety
promises of models based on their effectiveness in blocking malicious requests.
In this work, we focus on evaluating the underlying techniques that cause
models to abstain. We create SELECT, a benchmark derived from a set of benign
concepts (e.g., "rivers") from a knowledge graph. The nature of SELECT enables
us to isolate the effects of abstention techniques from other safety training
procedures, as well as evaluate their generalization and specificity. Using
SELECT, we benchmark different abstention techniques over six open-weight and
closed-source models. We find that the examined techniques indeed cause models
to abstain with over $80\%$ abstention rates. However, these techniques are not
as effective for descendants of the target concepts, with refusal rates
declining by $19\%$. We also characterize the generalization-vs-specificity
trade-offs for different techniques. Overall, no single technique is invariably
better than the others. Our findings call for a careful evaluation of different
aspects of abstention, and hopefully inform practitioners of various trade-offs
involved.

æè¦ï¼çºäºå®å¨å°é¨ç½²èªè¨æ¨¡åï¼è³ééè¦çæ¯ï¼å®åå¿é é¿ååæä¸é©ç¶çè«æ±ãååææ¸é ç ç©¶æ¸¬è©¦æ¨¡åçå®å¨æ§ï¼ä¾æå®åå°éæ¡æè«æ±çæææ§çºåºç¤ãå¨éé å·¥ä½ä¸­ï¼æåå°æ³¨æ¼è©ä¼°å°è´æ¨¡åé¿ååæçåºå±¤æè¡ãæåå»ºç«äº SELECTï¼ä¸åå¾ç¥è­åè­ä¸­ä¸çµè¯æ§æ¦å¿µï¼ä¾å¦ãæ²³æµãï¼è¡ççåºæºãSELECT çæ§è³ªä½¿æåè½å¤ å°é¿ååææè¡çå½±é¿èå¶ä»å®å¨è¨ç·´ç¨åºéé¢ï¼ä¸¦è©ä¼°å®åçæ¦æ¬æ§åç¹ç°æ§ãä½¿ç¨ SELECTï¼æåå°å­åéæ¾æ¬éåå°éåå§ç¢¼æ¨¡åé²è¡äºä¸åé¿ååææè¡çåºæºæ¸¬è©¦ãæåç¼ç¾ï¼ææª¢æ¥çæè¡ç¢ºå¯¦å°è´æ¨¡åé¿ååæï¼é¿ååæçè¶é 80%ãç¶èï¼éäºæè¡å°æ¼ç®æ¨æ¦å¿µçå¾ä»£ä¸¦ä¸é£éº¼ææï¼æçµçä¸éäº 19%ãæåéæè¿°äºä¸åæè¡çæ¦æ¬æ§èç¹ç°æ§æ¬è¡¡ãç¸½é«èè¨ï¼æ²æä»»ä½å®ä¸æè¡å§çµåªæ¼å¶ä»æè¡ãæåçç¼ç¾è¦æ±ä»ç´°è©ä¼°é¿ååæçä¸åé¢åï¼ä¸¦å¸æè®å¾æ¥­äººå¡äºè§£ææ¶åçåç¨®æ¬è¡¡ã

##### **A Review of Challenges in Speech-based Conversational AI for Elderly Care**
2412.07388v1 by Willemijn Klaassen, Bram van Dijk, Marco Spruit

Artificially intelligent systems optimized for speech conversation are
appearing at a fast pace. Such models are interesting from a healthcare
perspective, as these voice-controlled assistants may support the elderly and
enable remote health monitoring. The bottleneck for efficacy, however, is how
well these devices work in practice and how the elderly experience them, but
research on this topic is scant. We review elderly use of voice-controlled AI
and highlight various user- and technology-centered issues, that need to be
considered before effective speech-controlled AI for elderly care can be
realized.

æè¦ï¼ä»¥èªé³å°è©±çºæä½³åçäººå·¥æºæ§ç³»çµ±æ­£å¿«éåºç¾ãæ­¤é¡æ¨¡åå¨é«çä¿å¥æ¹é¢å¾æè¶£ï¼å çºéäºè²æ§å©çå¯ä»¥æ¯æ´é·èä¸¦è½é²è¡é è·å¥åº·ç£æ§ãç¶èï¼æè½çç¶é ¸å¨æ¼éäºè£ç½®å¨å¯¦ééä½ä¸çè¡¨ç¾å¦ä½ï¼ä»¥åé·èå¦ä½é«é©å®åï¼ä½éæ¹é¢çç ç©¶å»å¾ç¨å°ãæååé¡§äºé·èä½¿ç¨è²æ§äººå·¥æºæ§ççæ³ï¼ä¸¦éé»èªªæåç¨®ä»¥ä½¿ç¨èåæè¡çºä¸­å¿çè­°é¡ï¼å¨è½å¯¦ç¾ææçè²æ§äººå·¥æºæ§ä»¥é²è¡é·èç§è­·ä¹åï¼éäºè­°é¡é½éè¦å ä»¥èéã

##### **Enhanced MRI Representation via Cross-series Masking**
2412.07387v1 by Churan Wang, Fei Gao, Lijun Yan, Siwen Wang, Yizhou Yu, Yizhou Wang

Magnetic resonance imaging (MRI) is indispensable for diagnosing and planning
treatment in various medical conditions due to its ability to produce
multi-series images that reveal different tissue characteristics. However,
integrating these diverse series to form a coherent analysis presents
significant challenges, such as differing spatial resolutions and contrast
patterns meanwhile requiring extensive annotated data, which is scarce in
clinical practice. Due to these issues, we introduce a novel Cross-Series
Masking (CSM) Strategy for effectively learning MRI representation in a
self-supervised manner. Specifically, CSM commences by randomly sampling a
subset of regions and series, which are then strategically masked. In the
training process, the cross-series representation is learned by utilizing the
unmasked data to reconstruct the masked portions. This process not only
integrates information across different series but also facilitates the ability
to model both intra-series and inter-series correlations and complementarities.
With the learned representation, the downstream tasks like segmentation and
classification are also enhanced. Taking brain tissue segmentation, breast
tumor benign/malignant classification, and prostate cancer diagnosis as
examples, our method achieves state-of-the-art performance on both public and
in-house datasets.

æè¦ï¼ç£æ¯é å½± (MRI) å°æ¼è¨ºæ·åè¦ååç¨®é«ççæ³çæ²»çè³ééè¦ï¼å çºå®è½å¤ ç¢çæ­ç¤ºä¸åçµç¹ç¹å¾µçå¤ç³»åå½±åãç¶èï¼æ´åéäºä¸åçç³»åä»¥å½¢æé£è²«çåææå¸¶ä¾éå¤§çææ°ï¼ä¾å¦ä¸åçç©ºéè§£æåº¦åå°æ¯æ¨¡å¼ï¼åæéè¦å¤§éçè¨»è§£è³æï¼ä½å¨è¨åºå¯¦åä¸­å»å¾ç¨å°ãç±æ¼éäºåé¡ï¼æåå¼å¥äºä¸ç¨®æ°ç©çè·¨ç³»åé®ç½© (CSM) ç­ç¥ï¼ä»¥ä¾¿ä»¥èªæç£ç£çæ¹å¼ææå°å­¸ç¿ MRI è¡¨å¾µãå·é«ä¾èªªï¼CSM å¾é¨æ©æ½æ¨£åååç³»åçå­ééå§ï¼ç¶å¾å°å¶é²è¡ç­ç¥æ§é®ç½©ãå¨è¨ç·´éç¨ä¸­ï¼è·¨ç³»åè¡¨å¾µæ¯ééå©ç¨æªé®ç½©çè³æä¾éå»ºé®ç½©é¨åèå­¸ç¿çãéåéç¨ä¸åæ´åäºä¸åç³»åçè³è¨ï¼éä¿é²äºå°ç³»åå§åç³»åééè¯æ§åäºè£æ§çå»ºæ¨¡è½åãééå­¸ç¿å°çè¡¨å¾µï¼ä¸æ¸¸ä»»åï¼ä¾å¦åå²ååé¡ï¼ä¹æå¾å°å¢å¼·ãä»¥è¦çµç¹åå²ãä¹³æ¿è«ç¤è¯æ§/æ¡æ§åé¡åååèºçè¨ºæ·çºä¾ï¼æåçæ¨¡åå¨å¬éè³æéåå§é¨è³æéä¸é½éå°äºæåé²çæè½ã

##### **On Evaluating the Durability of Safeguards for Open-Weight LLMs**
2412.07097v1 by Xiangyu Qi, Boyi Wei, Nicholas Carlini, Yangsibo Huang, Tinghao Xie, Luxi He, Matthew Jagielski, Milad Nasr, Prateek Mittal, Peter Henderson

Stakeholders -- from model developers to policymakers -- seek to minimize the
dual-use risks of large language models (LLMs). An open challenge to this goal
is whether technical safeguards can impede the misuse of LLMs, even when models
are customizable via fine-tuning or when model weights are fully open. In
response, several recent studies have proposed methods to produce durable LLM
safeguards for open-weight LLMs that can withstand adversarial modifications of
the model's weights via fine-tuning. This holds the promise of raising
adversaries' costs even under strong threat models where adversaries can
directly fine-tune model weights. However, in this paper, we urge for more
careful characterization of the limits of these approaches. Through several
case studies, we demonstrate that even evaluating these defenses is exceedingly
difficult and can easily mislead audiences into thinking that safeguards are
more durable than they really are. We draw lessons from the evaluation pitfalls
that we identify and suggest future research carefully cabin claims to more
constrained, well-defined, and rigorously examined threat models, which can
provide more useful and candid assessments to stakeholders.

æè¦ï¼å©å®³éä¿äººï¼å¾æ¨¡åéç¼äººå¡å°æ¿ç­å¶å®èï¼å°æ±å°å¤§åèªè¨æ¨¡å (LLM) çééä½¿ç¨é¢¨éªéè³æä½ãå°æ­¤ç®æ¨çå¬éææ°å¨æ¼ï¼æè¡ä¿éæªæ½æ¯å¦è½é»æ­¢ LLM çæ¿«ç¨ï¼å³ä½¿æ¨¡åå¯ééå¾®èª¿é²è¡èªè¨ï¼ææ¨¡åæ¬éå®å¨éæ¾æäº¦ç¶ãçºäºè§£æ±ºæ­¤åé¡ï¼æè¿æå¹¾é ç ç©¶æåºæ¹æ³ï¼ä»¥ç¢çé©ç¨æ¼éæ¾æ¬é LLM çèç¨ LLM ä¿éæªæ½ï¼éäºä¿éæªæ½è½æ¿åééå¾®èª¿å°æ¨¡åæ¬éé²è¡çå°ææ§ä¿®æ¹ãéæææé«å°æçææ¬ï¼å³ä½¿å¨å°æå¯ä»¥ç´æ¥å¾®èª¿æ¨¡åæ¬éçå¼·å¨èæ¨¡åä¸äº¦ç¶ãç¶èï¼å¨æ¬æä¸­ï¼æåæ¦ä¿æ´ä»ç´°å°æè¿°éäºæ¹æ³çéå¶ãééå¤é æ¡ä¾ç ç©¶ï¼æåè­æå³ä½¿è©ä¼°éäºé²ç¦¦æªæ½ä¹æ¥µå¶å°é£ï¼ä¸¦ä¸å¾å®¹æèª¤å°åç¾ï¼è®ä»åèªçºä¿éæªæ½æ¯å¯¦éä¸æ´èç¨ãæåå¾æåè¾¨è­åºçè©ä¼°é·é±ä¸­æ±²åæè¨ï¼ä¸¦å»ºè­°æªä¾çç ç©¶è¬¹æå°å°ä¸»å¼µéå¶å¨æ´åéãå®ç¾©æç¢ºä¸ç¶éå´æ ¼å¯©æ¥çå¨èæ¨¡åä¸­ï¼éå¯ä»¥çºå©å®³éä¿äººæä¾æ´æç¨ä¸å¦ççè©ä¼°ã

##### **Toward AI-Driven Digital Organism: Multiscale Foundation Models for Predicting, Simulating and Programming Biology at All Levels**
2412.06993v1 by Le Song, Eran Segal, Eric Xing

We present an approach of using AI to model and simulate biology and life.
Why is it important? Because at the core of medicine, pharmacy, public health,
longevity, agriculture and food security, environmental protection, and clean
energy, it is biology at work. Biology in the physical world is too complex to
manipulate and always expensive and risky to tamper with. In this perspective,
we layout an engineering viable approach to address this challenge by
constructing an AI-Driven Digital Organism (AIDO), a system of integrated
multiscale foundation models, in a modular, connectable, and holistic fashion
to reflect biological scales, connectedness, and complexities. An AIDO opens up
a safe, affordable and high-throughput alternative platform for predicting,
simulating and programming biology at all levels from molecules to cells to
individuals. We envision that an AIDO is poised to trigger a new wave of
better-guided wet-lab experimentation and better-informed first-principle
reasoning, which can eventually help us better decode and improve life.

æè¦ï¼æåæåºäºä¸ç¨®ä½¿ç¨ AI ä¾å»ºæ¨¡åæ¨¡æ¬çç©å­¸åçå½çæ¹æ³ã
çºä»éº¼éå¾éè¦ï¼å çºå¨é«å­¸ãè¥å­¸ãå¬å±è¡çã
é·å£½ãè¾²æ¥­åé£åå®å¨ãç°å¢ä¿è­·åæ¸æ½
è½æºçæ ¸å¿ï¼é½æ¯çç©å­¸å¨éä½ãç©çä¸çä¸­ççç©å­¸å¤ªéè¤éï¼
é£ä»¥æä½ï¼èä¸ç¸½æ¯æè²´ä¸æé¢¨éªãå¾éåè§åº¦ä¾çï¼
æåå¶å®äºä¸ç¨®å¯è¡çå·¥ç¨æ¹æ³ä¾è§£æ±ºéåææ°ï¼æ¹æ³æ¯
æ§å»ºä¸å AI é©åçæ¸ä½çç©é« (AIDO)ï¼ä¸åæ´åç
å¤å°ºåº¦åºç¤æ¨¡åç³»çµ±ï¼ä»¥æ¨¡çµåãå¯é£æ¥åæ´é«çæ¹å¼
ä¾åæ çç©å°ºåº¦ãé£éæ§åè¤éæ§ãAIDO éåäºä¸åå®å¨ã
è² æå¾èµ·ä¸é«ééçæ¿ä»£å¹³å°ï¼ç¨æ¼é æ¸¬ã
æ¨¡æ¬åç·¨ç¨å¾åå­å°ç´°èå°åé«çææå±¤ç´ççç©å­¸ãæåé è¨ AIDO å°å¼ç¼ä¸æ³¢
ç±æ´ä½³æå°çæ¿å¼å¯¦é©åæ´å®åçç¬¬ä¸åç
æ¨ççæ°æµªæ½®ï¼æçµå¯ä»¥å¹«å©æåæ´å¥½å°è§£ç¢¼åæ¹åçå½ã

##### **Diagnosis and Severity Assessment of Ulcerative Colitis using Self Supervised Learning**
2412.07806v1 by Venkat Margapuri

Ulcerative Colitis (UC) is an incurable inflammatory bowel disease that leads
to ulcers along the large intestine and rectum. The increase in the prevalence
of UC coupled with gastrointestinal physician shortages stresses the healthcare
system and limits the care UC patients receive. A colonoscopy is performed to
diagnose UC and assess its severity based on the Mayo Endoscopic Score (MES).
The MES ranges between zero and three, wherein zero indicates no inflammation
and three indicates that the inflammation is markedly high. Artificial
Intelligence (AI)-based neural network models, such as convolutional neural
networks (CNNs) are capable of analyzing colonoscopies to diagnose and
determine the severity of UC by modeling colonoscopy analysis as a multi-class
classification problem. Prior research for AI-based UC diagnosis relies on
supervised learning approaches that require large annotated datasets to train
the CNNs. However, creating such datasets necessitates that domain experts
invest a significant amount of time, rendering the process expensive and
challenging. To address the challenge, this research employs self-supervised
learning (SSL) frameworks that can efficiently train on unannotated datasets to
analyze colonoscopies and, aid in diagnosing UC and its severity. A comparative
analysis with supervised learning models shows that SSL frameworks, such as
SwAV and SparK outperform supervised learning models on the LIMUC dataset, the
largest publicly available annotated dataset of colonoscopy images for UC.

æè¦ï¼æ½°çæ§çµè¸ç (UC) æ¯ä¸ç¨®ç¡æ³æ²»ççç¼çæ§è¸éç¾çï¼æå°è´å¤§è¸åç´è¸æ½°çãUC çæ£ççå¢å ï¼å ä¸è¸èç§é«å¸«ç­ç¼ºï¼å°é«çä¿å¥ç³»çµ±é æå£åï¼ä¸¦éå¶ UC æ£èæ¥åçç§è­·ãé²è¡å¤§è¸é¡æª¢æ¥ä»¥è¨ºæ· UC ä¸¦æ ¹æ Mayo å§è¦é¡è©å (MES) è©ä¼°å¶å´éç¨åº¦ãMES çç¯åå¨ 0 å° 3 ä¹éï¼å¶ä¸­ 0 è¡¨ç¤ºæ²æç¼çï¼è 3 è¡¨ç¤ºç¼çç¨åº¦é¡¯èãåºæ¼äººå·¥æºæ§ (AI) çç¥ç¶ç¶²è·¯æ¨¡åï¼ä¾å¦å·ç©ç¥ç¶ç¶²è·¯ (CNN)ï¼è½å¤ åæå¤§è¸é¡æª¢æ¥ä»¥è¨ºæ·åç¢ºå® UC çå´éç¨åº¦ï¼æ¹æ³æ¯å°å¤§è¸é¡æª¢æ¥åæå»ºæ¨¡çºå¤é¡å¥åé¡åé¡ãååéå°åºæ¼ AI ç UC è¨ºæ·çç ç©¶ä¾è³´æ¼ç£ç£å¼å­¸ç¿æ¹æ³ï¼éè¦å¤§éæ¨è¨»çè³æéä¾è¨ç·´ CNNãç¶èï¼å»ºç«æ­¤é¡è³æééè¦é åå°å®¶æå¥å¤§éæéï¼ä½¿éåéç¨æ¢æè²´åå·æææ°æ§ãçºäºæå°éåææ°ï¼æ¬ç ç©¶æ¡ç¨èªæç£ç£å­¸ç¿ (SSL) æ¡æ¶ï¼å¯ä»¥å¨æªæ¨è¨»çè³æéä¸é²è¡ææççè¨ç·´ï¼ä»¥åæå¤§è¸é¡æª¢æ¥ä¸¦åå©è¨ºæ· UC åå¶å´éç¨åº¦ãèç£ç£å¼å­¸ç¿æ¨¡åçæ¯è¼åæé¡¯ç¤ºï¼SSL æ¡æ¶ï¼ä¾å¦ SwAV å SparKï¼å¨ LIMUC è³æéï¼æå¤§çå¬é UC å¤§è¸é¡æª¢æ¥å½±åæ¨è¨»è³æéï¼ä¸åªæ¼ç£ç£å¼å­¸ç¿æ¨¡åã

##### **Toward Non-Invasive Diagnosis of Bankart Lesions with Deep Learning**
2412.06717v1 by Sahil Sethi, Sai Reddy, Mansi Sakarvadia, Jordan Serotte, Darlington Nwaudo, Nicholas Maassen, Lewis Shi

Bankart lesions, or anterior-inferior glenoid labral tears, are
diagnostically challenging on standard MRIs due to their subtle imaging
features-often necessitating invasive MRI arthrograms (MRAs). This study
develops deep learning (DL) models to detect Bankart lesions on both standard
MRIs and MRAs, aiming to improve diagnostic accuracy and reduce reliance on
MRAs. We curated a dataset of 586 shoulder MRIs (335 standard, 251 MRAs) from
558 patients who underwent arthroscopy. Ground truth labels were derived from
intraoperative findings, the gold standard for Bankart lesion diagnosis.
Separate DL models for MRAs and standard MRIs were trained using the Swin
Transformer architecture, pre-trained on a public knee MRI dataset. Predictions
from sagittal, axial, and coronal views were ensembled to optimize performance.
The models were evaluated on a 20% hold-out test set (117 MRIs: 46 MRAs, 71
standard MRIs). Bankart lesions were identified in 31.9% of MRAs and 8.6% of
standard MRIs. The models achieved AUCs of 0.87 (86% accuracy, 83% sensitivity,
86% specificity) and 0.90 (85% accuracy, 82% sensitivity, 86% specificity) on
standard MRIs and MRAs, respectively. These results match or surpass
radiologist performance on our dataset and reported literature metrics.
Notably, our model's performance on non-invasive standard MRIs matched or
surpassed the radiologists interpreting MRAs. This study demonstrates the
feasibility of using DL to address the diagnostic challenges posed by subtle
pathologies like Bankart lesions. Our models demonstrate potential to improve
diagnostic confidence, reduce reliance on invasive imaging, and enhance
accessibility to care.

æè¦ï¼Bankart çç¶ï¼æåä¸çåæè£ï¼ç±æ¼å¶å½±åç¹å¾µå¾®å¦ï¼å¨æ¨æºæ ¸ç£å±æ¯æåä¸­è¨ºæ·å·æææ°æ§ï¼éå¸¸éè¦ä¾µå¥æ§æ ¸ç£å±æ¯è¡ç®¡é å½± (MRA)ãæ¬ç ç©¶éç¼æ·±åº¦å­¸ç¿ (DL) æ¨¡åï¼ç¨æ¼å¨æ¨æºæ ¸ç£å±æ¯æååæ ¸ç£å±æ¯è¡ç®¡é å½±ä¸­æª¢æ¸¬ Bankart çç¶ï¼æ¨å¨æé«è¨ºæ·æºç¢ºæ§ä¸¦æ¸å°å°æ ¸ç£å±æ¯è¡ç®¡é å½±çä¾è³´ãæåå¾ 558 åæ¥åéç¯é¡æª¢æ¥çæ£èä¸­ç­åäºä¸çµ 586 ä¾è©é¨æ ¸ç£å±æ¯æå (335 ä¾æ¨æºï¼251 ä¾æ ¸ç£å±æ¯è¡ç®¡é å½±) çæ¸æéãåºæ¬äºå¯¦æ¨ç±¤ä¾èªè¡ä¸­ç¼ç¾ï¼éæ¯ Bankart çç¶è¨ºæ·çé»éæ¨æºãä½¿ç¨ Swin Transformer æ¶æ§è¨ç·´äºæ ¸ç£å±æ¯è¡ç®¡é å½±åæ¨æºæ ¸ç£å±æ¯æåçå®ç¨æ·±åº¦å­¸ç¿æ¨¡åï¼ä¸¦å¨å¬éçèé¨æ ¸ç£å±æ¯æåæ¸æéä¸é²è¡é è¨ç·´ãç¢çé¢ãè»¸é¢åå çé¢çé æ¸¬çµæè¢«çµåèµ·ä¾ä»¥åªåæ§è½ãéäºæ¨¡åå¨ 20% çä¿çæ¸¬è©¦éï¼117 ä¾æ ¸ç£å±æ¯æåï¼46 ä¾æ ¸ç£å±æ¯è¡ç®¡é å½±ï¼71 ä¾æ¨æºæ ¸ç£å±æ¯æåï¼ä¸é²è¡äºè©ä¼°ãå¨ 31.9% çæ ¸ç£å±æ¯è¡ç®¡é å½±å 8.6% çæ¨æºæ ¸ç£å±æ¯æåä¸­ç¼ç¾äº Bankart çç¶ãéäºæ¨¡åå¨æ¨æºæ ¸ç£å±æ¯æååæ ¸ç£å±æ¯è¡ç®¡é å½±ä¸­ç AUC åå¥éå° 0.87ï¼86% æºç¢ºåº¦ï¼83% éæåº¦ï¼86% ç¹ç°åº¦ï¼å 0.90ï¼85% æºç¢ºåº¦ï¼82% éæåº¦ï¼86% ç¹ç°åº¦ï¼ãéäºçµæèæ¾å°ç§é«çå°æåæ¸æéçè¡¨ç¾ç¸å¹éæè¶éï¼ä¸¦è¶éäºå ±åçæç»ææ¨ãå¼å¾æ³¨æçæ¯ï¼æåçæ¨¡åå¨éä¾µå¥æ§æ¨æºæ ¸ç£å±æ¯æåä¸­çè¡¨ç¾èæ¾å°ç§é«çå°æ ¸ç£å±æ¯è¡ç®¡é å½±çè§£éç¸å¹éæè¶éãæ¬ç ç©¶è­æäºä½¿ç¨æ·±åº¦å­¸ç¿ä¾è§£æ±º Bankart çç¶ç­å¾®å¦ççè¨ºæ·ææ°çå¯è¡æ§ãæåçæ¨¡åå±ç¤ºäºæé«è¨ºæ·ä¿¡å¿ãæ¸å°å°ä¾µå¥æ§å½±åæª¢æ¥çä¾è³´ä»¥åå¢å¼·ç²å¾ç§è­·çæ©æçæ½åã

##### **Parkinson's Disease Diagnosis Through Deep Learning: A Novel LSTM-Based Approach for Freezing of Gait Detection**
2412.06709v1 by Aqib Nazir Mir, Iqra Nissar, Mumtaz Ahmed, Sarfaraz Masood, Danish Raza Rizvi

Deep learning holds tremendous potential in healthcare for uncovering hidden
patterns within extensive clinical datasets, aiding in the diagnosis of various
diseases. Parkinson's disease (PD) is a neurodegenerative condition
characterized by the deterioration of brain function. In the initial stages of
PD, automatic diagnosis poses a challenge due to the similarity in behavior
between individuals with PD and those who are healthy. Our objective is to
propose an effective model that can aid in the early detection of Parkinson's
disease. We employed the VGRF gait signal dataset sourced from Physionet for
distinguishing between healthy individuals and those diagnosed with Parkinson's
disease. This paper introduces a novel deep learning architecture based on the
LSTM network for automatically detecting freezing of gait episodes in
Parkinson's disease patients. In contrast to conventional machine learning
algorithms, this method eliminates manual feature engineering and proficiently
captures prolonged temporal dependencies in gait patterns, thereby improving
the diagnosis of Parkinson's disease. The LSTM network resolves the issue of
vanishing gradients by employing memory blocks in place of self-connected
hidden units, allowing for optimal information assimilation. To prevent
overfitting, dropout and L2 regularization techniques have been employed.
Additionally, the stochastic gradient-based optimizer Adam is used for the
optimization process. The results indicate that our proposed approach surpasses
current state-of-the-art models in FOG episode detection, achieving an accuracy
of 97.71%, sensitivity of 99%, precision of 98%, and specificity of 96%. This
demonstrates its potential as a superior classification method for Parkinson's
disease detection.

æè¦ï¼æ·±åº¦å­¸ç¿å¨é«çä¿å¥é åææå·¨å¤§çæ½åï¼å¯ç¨æ¼ç¼æå»£æ³è¨åºè³æéä¸­çé±èæ¨¡å¼ï¼åå©è¨ºæ·åç¨®ç¾çãå¸éæ£®æ°ç (PD) æ¯ä¸ç¨®ç¥ç¶éåæ§ç¾çï¼å¶ç¹å¾µæ¯å¤§è¦åè½æ¡åãå¨ PD çåæéæ®µï¼ç±æ¼ PD æ£èèå¥åº·èçè¡çºç¸ä¼¼ï¼å æ­¤èªåè¨ºæ·å·æææ°æ§ãæåçç®æ¨æ¯æåºä¸åææçæ¨¡åï¼å¯ä»¥å¹«å©æ©ææª¢æ¸¬å¸éæ£®æ°çãæåæ¡ç¨äºä¾èª Physionet ç VGRF æ­¥æä¿¡èè³æéï¼ç¨æ¼ååå¥åº·åé«åè¢«è¨ºæ·åºæ£æå¸éæ£®æ°ççåé«ãæ¬æä»ç´¹äºä¸ç¨®åºæ¼ LSTM ç¶²è·¯çæ·±åº¦å­¸ç¿æ°æ¶æ§ï¼ç¨æ¼èªåæª¢æ¸¬å¸éæ£®æ°çæ£èçæ­¥æåçµç¼ä½ãèå³çµ±æ©å¨å­¸ç¿æ¼ç®æ³ç¸æ¯ï¼æ­¤æ¹æ³æ¶é¤äºæåç¹å¾µå·¥ç¨ï¼ä¸¦çç·´å°æææ­¥ææ¨¡å¼ä¸­çé·æéä¾è³´æ§ï¼å¾èæ¹é²äºå¸éæ£®æ°ççè¨ºæ·ãLSTM ç¶²è·¯ééä½¿ç¨è¨æ¶åå¡ä»£æ¿èªé£æ¥é±èå®åä¾è§£æ±ºæ¢¯åº¦æ¶å¤±åé¡ï¼å¾èå¯¦ç¾æä½³è³è¨ååãçºäºé²æ­¢éåº¦æ¬åï¼å·²æ¡ç¨ä¸­æ·å L2 æ­£ååæè¡ãæ­¤å¤ï¼é¨æ©æ¢¯åº¦åªåå¨ Adam ç¨æ¼åªåéç¨ãçµæè¡¨æï¼æåæåºçæ¹æ³å¨ FOG ç¼ä½æª¢æ¸¬æ¹é¢è¶è¶äºç¶åæåé²çæ¨¡åï¼éå°äº 97.71% çæºç¢ºçã99% çéæåº¦ã98% çç²¾ç¢ºåº¦å 96% çç¹ç°æ§ãéè­æäºå¶ä½çºå¸éæ£®æ°çæª¢æ¸¬çåªè¶åé¡æ¹æ³çæ½åã

##### **Fundus Image-based Visual Acuity Assessment with PAC-Guarantees**
2412.06624v1 by Sooyong Jang, Kuk Jin Jang, Hyonyoung Choi, Yong-Seop Han, Seongjin Lee, Jin-hyun Kim, Insup Lee

Timely detection and treatment are essential for maintaining eye health.
Visual acuity (VA), which measures the clarity of vision at a distance, is a
crucial metric for managing eye health. Machine learning (ML) techniques have
been introduced to assist in VA measurement, potentially alleviating
clinicians' workloads. However, the inherent uncertainties in ML models make
relying solely on them for VA prediction less than ideal. The VA prediction
task involves multiple sources of uncertainty, requiring more robust
approaches. A promising method is to build prediction sets or intervals rather
than point estimates, offering coverage guarantees through techniques like
conformal prediction and Probably Approximately Correct (PAC) prediction sets.
Despite the potential, to date, these approaches have not been applied to the
VA prediction task.To address this, we propose a method for deriving prediction
intervals for estimating visual acuity from fundus images with a PAC guarantee.
Our experimental results demonstrate that the PAC guarantees are upheld, with
performance comparable to or better than that of two prior works that do not
provide such guarantees.

æè¦ï¼åæå°åµæ¸¬åæ²»çå°æ¼ç¶­æç¼çå¥åº·è³ééè¦ã
è¦åï¼VAï¼ï¼ç¨æ¼æ¸¬éé è·é¢è¦è¦ºçæ¸æ°åº¦ï¼æ¯ç¶­æç¼çå¥åº·çééµææ¨ãæ©å¨å­¸ç¿ï¼MLï¼æè¡å·²è¢«å¼å¥ä»¥åå© VA æ¸¬éï¼æ½å¨å°æ¸è¼è¨åºé«å¸«çå·¥ä½è² æãç¶èï¼ML æ¨¡åä¸­åºæçä¸ç¢ºå®æ§ä½¿å¾åä¾è³´å®åé²è¡ VA é æ¸¬ä¸¦éçæ³ãVA é æ¸¬ä»»åæ¶åå¤ç¨®ä¸ç¢ºå®æ§ä¾æºï¼éè¦æ´å¼·å¤§çæ¹æ³ãä¸ç¨®æåéçæ¹æ³æ¯å»ºç«é æ¸¬éåæåéï¼èä¸æ¯é»ä¼°è¨ï¼ééåå±å½¢é æ¸¬åå¤§æ¦æ­£ç¢ºï¼PACï¼é æ¸¬éåéæ¨£çæè¡æä¾è¦èçä¿è­ãåç®¡ææ½åï¼ä½è¿ä»çºæ­¢ï¼éäºæ¹æ³å°æªæç¨æ¼ VA é æ¸¬ä»»åãçºäºè§£æ±ºéååé¡ï¼æåæåºäºä¸ç¨®å¾ç¼åºååä¼°è¨è¦åçé æ¸¬åéçæ¹æ³ï¼ä¸¦æä¾ PAC ä¿è­ãæåçå¯¦é©çµæè¡¨æï¼PAC ä¿è­å¾å°ç¶­æï¼å¶æ§è½èä¸æä¾æ­¤é¡ä¿è­çå©é ååå·¥ä½çæ§è½ç¸ç¶ææ´å¥½ã

##### **Real-Time Performance Optimization of Travel Reservation Systems Using AI and Microservices**
2412.06874v1 by Biman Barua, M. Shamim Kaiser

The rapid growth of the travel industry has increased the need for real-time
optimization in reservation systems that could take care of huge data and
transaction volumes. This study proposes a hybrid framework that ut folds an
Artificial Intelligence and a Microservices approach for the performance
optimization of the system. The AI algorithms forecast demand patterns,
optimize the allocation of resources, and enhance decision-making driven by
Microservices architecture, hence decentralizing system components for
scalability, fault tolerance, and reduced downtime. The model provided focuses
on major problems associated with the travel reservation systems such as
latency of systems, load balancing and data consistency. It endows the systems
with predictive models based on AI improved ability to forecast user demands.
Microservices would also take care of different scales during uneven traffic
patterns. Hence, both aspects ensure better handling of peak loads and spikes
while minimizing delays and ensuring high service quality. A comparison was
made between traditional reservation models, which are monolithic and the new
model of AI-Microservices. Comparatively, the analysis results state that there
is a drastic improvement in processing times where the system uptime and
resource utilization proved the capability of AI and the microservices in
transforming the travel industry in terms of reservation. This research work
focused on AI and Microservices towards real-time optimization, providing
critical insight into how to move forward with practical recommendations for
upgrading travel reservation systems with this technology.

æè¦ï¼æéç¢æ¥­å¿«éæé·ï¼æåäºé è¨ç³»çµ±ä¸­å³ææä½³åçéæ±ï¼éåç³»çµ±å¯ä»¥èçé¾å¤§çè³æåäº¤æéãæ¬ç ç©¶æåºä¸åæ··åæ¶æ§ï¼å®çµåäººå·¥æºæ§åå¾®æåæ¹æ³ä¾æä½³åç³»çµ±æè½ãäººå·¥æºæ§æ¼ç®æ³é æ¸¬éæ±æ¨¡å¼ï¼æä½³åè³æºéç½®ï¼ä¸¦å å¼·ç±å¾®æåæ¶æ§é©åçæ±ºç­å¶å®ï¼å æ­¤åæ£ç³»çµ±åä»¶ä»¥å©æ¼æ´åæ§ãå®¹é¯è½ååæ¸å°åæ©æéãææä¾çæ¨¡åå°æ³¨æ¼èæéé è¨ç³»çµ±ç¸éçä¸»è¦åé¡ï¼ä¾å¦ç³»çµ±å»¶é²ãè² è¼å¹³è¡¡åè³æä¸è´æ§ãå®è³¦äºç³»çµ±é æ¸¬æ¨¡åï¼åºæ¼äººå·¥æºæ§æåé æ¸¬ä½¿ç¨èéæ±çè½åãå¾®æåä¹æå¨æµéæ¨¡å¼ä¸åæèçä¸åçè¦æ¨¡ãå æ­¤ï¼éå©åé¢åç¢ºä¿è½æ´å¥½å°èçå°å³°è² è¼åæµéæ¿å¢ï¼åæå°å»¶é²éå°æä½ä¸¦ç¢ºä¿é«æååè³ªãæ¯è¼å³çµ±çé è¨æ¨¡åï¼å®é«å¼ï¼åæ°ç AI-å¾®æåæ¨¡åãæ¯è¼ä¹ä¸ï¼åæçµææåºèçæéæé¡¯èæ¹åï¼å¶ä¸­ç³»çµ±æ­£å¸¸éè¡æéåè³æºä½¿ç¨çè­æäºäººå·¥æºæ§åå¾®æåå¨é è¨æ¹é¢è½åæéç¢æ¥­çè½åãéé ç ç©¶å·¥ä½å°æ³¨æ¼äººå·¥æºæ§åå¾®æåï¼ä»¥å¯¦ç¾å³ææä½³åï¼æä¾ééµè¦è§£ï¼èªªæå¦ä½ééå¯¦ç¨å»ºè­°ï¼ä½¿ç¨éé æè¡åç´æéé è¨ç³»çµ±ã

##### **Advancing Music Therapy: Integrating Eastern Five-Element Music Theory and Western Techniques with AI in the Novel Five-Element Harmony System**
2412.06600v1 by Yubo Zhou, Weizhen Bian, Kaitai Zhang, Xiaohan Gu

In traditional medical practices, music therapy has proven effective in
treating various psychological and physiological ailments. Particularly in
Eastern traditions, the Five Elements Music Therapy (FEMT), rooted in
traditional Chinese medicine, possesses profound cultural significance and
unique therapeutic philosophies. With the rapid advancement of Information
Technology and Artificial Intelligence, applying these modern technologies to
FEMT could enhance the personalization and cultural relevance of the therapy
and potentially improve therapeutic outcomes. In this article, we developed a
music therapy system for the first time by applying the theory of the five
elements in music therapy to practice. This innovative approach integrates
advanced Information Technology and Artificial Intelligence with Five-Element
Music Therapy (FEMT) to enhance personalized music therapy practices. As
traditional music therapy predominantly follows Western methodologies, the
unique aspects of Eastern practices, specifically the Five-Element theory from
traditional Chinese medicine, should be considered. This system aims to bridge
this gap by utilizing computational technologies to provide a more
personalized, culturally relevant, and therapeutically effective music therapy
experience.

æè¦ï¼å¨å³çµ±çé«çå¯¦åä¸­ï¼é³æ¨æ²»çå·²è¢«è­å¯¦è½æææ²»çåç¨®å¿çåççç¾çãç¹å¥å¨æ±æ¹å³çµ±ä¸­ï¼æ ¹æºæ¼ä¸­é«çäºè¡é³æ¨çæ³ï¼FEMTï¼å·ææ·±é çæåæç¾©åç¨ç¹çæ²»çå²å­¸ãé¨èè³è¨ç§æåäººå·¥æºæ§çå¿«éé²å±ï¼å°éäºç¾ä»£ç§ææç¨æ¼ FEMT è½å¢å¼·æ²»ççåäººååæåç¸éæ§ï¼ä¸¦å¯è½æ¹åæ²»çææãå¨æ¬æä¸­ï¼æåé¦æ¬¡ééå°é³æ¨æ²»çä¸­çäºè¡çè«æç¨æ¼å¯¦åï¼éç¼åºä¸åé³æ¨æ²»çç³»çµ±ãéç¨®åµæ°çæ¹æ³å°åé²çè³è¨ç§æåäººå·¥æºæ§èäºè¡é³æ¨çæ³ï¼FEMTï¼æ´åï¼ä»¥å¢å¼·åäººåçé³æ¨æ²»çå¯¦åãç±æ¼å³çµ±çé³æ¨æ²»çä¸»è¦éµå¾ªè¥¿æ¹çåæ³ï¼å æ­¤æèæ®æ±æ¹å¯¦åçç¨ç¹é¢åï¼ç¹å¥æ¯ä¸­é«çäºè¡çè«ãæ­¤ç³»çµ±æ¨å¨ééå©ç¨éç®ç§æä¾å½åæ­¤å·®è·ï¼æä¾æ´åäººåãæåç¸éä¸æ²»çæææ´å¥½çé³æ¨æ²»çé«é©ã

##### **HES-UNet: A U-Net for Hepatic Echinococcosis Lesion Segmentation**
2412.06530v1 by Jiayan Chen, Kai Li, Zhanjin Wang, Zhan Wang, Jianqiang Huang

Hepatic echinococcosis (HE) is a prevalent disease in economically
underdeveloped pastoral areas, where adequate medical resources are usually
lacking. Existing methods often ignore multi-scale feature fusion or focus only
on feature fusion between adjacent levels, which may lead to insufficient
feature fusion. To address these issues, we propose HES-UNet, an efficient and
accurate model for HE lesion segmentation. This model combines convolutional
layers and attention modules to capture local and global features. During
downsampling, the multi-directional downsampling block (MDB) is employed to
integrate high-frequency and low-frequency features, effectively extracting
image details. The multi-scale aggregation block (MAB) aggregates multi-scale
feature information. In contrast, the multi-scale upsampling Block (MUB) learns
highly abstract features and supplies this information to the skip connection
module to fuse multi-scale features. Due to the distinct regional
characteristics of HE, there is currently no publicly available high-quality
dataset for training our model. We collected CT slice data from 268 patients at
a certain hospital to train and evaluate the model. The experimental results
show that HES-UNet achieves state-of-the-art performance on our dataset,
achieving an overall Dice Similarity Coefficient (DSC) of 89.21%, which is
1.09% higher than that of TransUNet. The project page is available at
https://chenjiayan-qhu.github.io/HES-UNet-page.

æè¦ï¼èåè²çï¼HEï¼å¨ç¶æ¿è½å¾ççç§å°åçè¡ï¼é£è£¡éå¸¸ç¼ºä¹è¶³å¤ çé«çè³æºãç¾ææ¹æ³éå¸¸å¿½ç¥å¤å°ºåº¦ç¹å¾µèåï¼æåéæ³¨ç¸é°å±¤ä¹éçç¹å¾µèåï¼éå¯è½å°è´ç¹å¾µèåä¸è¶³ãçºäºè§£æ±ºéäºåé¡ï¼æåæåºäº HES-UNetï¼éæ¯ä¸ç¨®ç¨æ¼ HE çç¶åå²çé«æä¸æºç¢ºçæ¨¡åãæ­¤æ¨¡åçµåäºå·ç©å±¤åæ³¨æåæ¨¡çµï¼ä»¥æ·åå±é¨åå¨å±ç¹å¾µãå¨éæ¡æ¨£éç¨ä¸­ï¼æ¡ç¨å¤åéæ¡æ¨£åå¡ (MDB) ä¾æ´åé«é »åä½é »ç¹å¾µï¼æææåå½±åç´°ç¯ãå¤å°ºåº¦èååå¡ (MAB) èåå¤å°ºåº¦ç¹å¾µè³è¨ãç¸åï¼å¤å°ºåº¦ä¸æ¡æ¨£åå¡ (MUB) æå­¸ç¿é«åº¦æ½è±¡çç¹å¾µï¼ä¸¦å°æ­¤è³è¨æä¾çµ¦è·³èºé£æ¥æ¨¡çµï¼ä»¥èåå¤å°ºåº¦ç¹å¾µãç±æ¼ HE çååç¹å¾µä¸åï¼ç®åæ²æå¬éå¯ç¨çé«åè³ªè³æéå¯ä¾è¨ç·´æåçæ¨¡åãæåå¾æå®¶é«é¢æ¶éäº 268 ä½æ£èç CT åçè³æï¼ä»¥è¨ç·´åè©ä¼°æ¨¡åãå¯¦é©çµæè¡¨æï¼HES-UNet å¨æåçè³æéä¸éå°äºæåé²çæè½ï¼æ´é« Dice ç¸ä¼¼æ§ä¿æ¸ (DSC) éå° 89.21%ï¼æ¯ TransUNet é« 1.09%ãå°æ¡é é¢å¯æ¼ https://chenjiayan-qhu.github.io/HES-UNet-page åå¾ã

##### **Simulating Human-like Daily Activities with Desire-driven Autonomy**
2412.06435v1 by Yiding Wang, Yuxuan Chen, Fangwei Zhong, Long Ma, Yizhou Wang

Existing task-oriented AI agents often depend on explicit instructions or
external rewards, limiting their ability to be driven by intrinsic motivations
like humans. In this paper, we present a desire-driven autonomy framework to
guide a Large Language Model-based (LLM-based) agent to simulate human-like
daily activities. In contrast to previous agents, our Desire-driven Autonomous
Agent (D2A) operates on the principle of intrinsic desire, allowing it to
propose and select tasks that fulfill its motivational framework autonomously.
Inspired by the Theory of Needs, the motivational framework incorporates an
understanding of human-like desires, such as the need for social interaction,
personal fulfillment, and self-care. Utilizing a desire-driven task generation
mechanism, the agent evaluates its current state and takes a sequence of
activities aligned with its intrinsic motivations. Through simulations, we
demonstrate that our Desire-driven Autonomous Agent (D2A) generates coherent,
contextually relevant daily activities while exhibiting variability and
adaptability similar to human behavior. A comparative analysis with other
LLM-based frameworks demonstrates that our approach significantly enhances the
rationality of the simulated activities.

æè¦ï¼ç¾æçä»»åå°å AI ä»£çéå¸¸ä¾è³´æç¢ºçæç¤ºæå¤é¨çåµï¼ééå¶äºå®ååäººé¡ä¸æ¨£ç±å§å¨åæ©é©åçè½åãå¨æ¬æä¸­ï¼æåæåºäºä¸åæ¾æé©åçèªä¸»æ¡æ¶ï¼ä»¥æå°åºæ¼å¤§åèªè¨æ¨¡å (LLM) çä»£çæ¨¡æ¬é¡äººçæ¥å¸¸æ´»åãèä¹åçä»£çä¸åï¼æåçæ¾æé©åèªä¸»ä»£ç (D2A) éµå¾ªå§å¨æ¾æçååï¼åè¨±å®èªä¸»æåºåé¸æç¬¦åå¶åæ©æ¡æ¶çä»»åãåéæ±çè«çåç¼ï¼åæ©æ¡æ¶åå«å°é¡äººæ¾æççè§£ï¼ä¾å¦ç¤¾æäºåãåäººæ»¿è¶³åèªæä¿å¥çéè¦ãå©ç¨æ¾æé©åä»»åçææ©å¶ï¼ä»£çè©ä¼°å¶ç¶åçæä¸¦æ¡åä¸ç³»åèå¶å§å¨åæ©ä¸è´çæ´»åãééæ¨¡æ¬ï¼æåè­æäºæåçæ¾æé©åèªä¸»ä»£ç (D2A) ç¢çäºé£è²«ãèä¸ä¸æç¸éçæ¥å¸¸æ´»åï¼åæè¡¨ç¾åºèäººé¡è¡çºç¸ä¼¼çå¯è®æ§åé©ææ§ãèå¶ä»åºæ¼ LLM çæ¡æ¶é²è¡æ¯è¼åæè¡¨æï¼æåçåæ³é¡¯èæé«äºæ¨¡æ¬æ´»åçåçæ§ã

##### **CAD-Unet: A Capsule Network-Enhanced Unet Architecture for Accurate Segmentation of COVID-19 Lung Infections from CT Images**
2412.06314v1 by Yijie Dang, Weijun Ma, Xiaohu Luo

Since the outbreak of the COVID-19 pandemic in 2019, medical imaging has
emerged as a primary modality for diagnosing COVID-19 pneumonia. In clinical
settings, the segmentation of lung infections from computed tomography images
enables rapid and accurate quantification and diagnosis of COVID-19.
Segmentation of COVID-19 infections in the lungs poses a formidable challenge,
primarily due to the indistinct boundaries and limited contrast presented by
ground glass opacity manifestations. Moreover, the confounding similarity
between infiltrates, lung tissues, and lung walls further complicates this
segmentation task. To address these challenges, this paper introduces a novel
deep network architecture, called CAD-Unet, for segmenting COVID-19 lung
infections. In this architecture, capsule networks are incorporated into the
existing Unet framework. Capsule networks represent a novel network
architecture that differs from traditional convolutional neural networks. They
utilize vectors for information transfer among capsules, facilitating the
extraction of intricate lesion spatial information. Additionally, we design a
capsule encoder path and establish a coupling path between the unet encoder and
the capsule encoder. This design maximizes the complementary advantages of both
network structures while achieving efficient information fusion. \noindent
Finally, extensive experiments are conducted on four publicly available
datasets, encompassing binary segmentation tasks and multi-class segmentation
tasks. The experimental results demonstrate the superior segmentation
performance of the proposed model. The code has been released at:
https://github.com/AmanoTooko-jie/CAD-Unet.

æè¦ï¼èª 2019 å¹´ COVID-19 å¤§æµè¡çåä»¥æ¥ï¼å»å­¦å½±åå·²æä¸ºè¯æ­ COVID-19 èºççä¸»è¦æ¹å¼ãå¨ä¸´åºç¯å¢ä¸­ï¼ä»è®¡ç®æºæ­å±æ«æå¾åä¸­åå²èºé¨ææï¼å¯ä»¥å¿«éãåç¡®å°éååè¯æ­ COVID-19ãåå²èºé¨ä¸­ç COVID-19 æææ¯ä¸ä¸ªè°å·¨çææï¼è¿ä¸»è¦æ¯ç±äºæ¯ç»çæ ·åç°åºçè¾¹çä¸æ¸æ°ä¸å¯¹æ¯åº¦æéãæ­¤å¤ï¼æµ¸æ¶¦ãèºç»ç»åèºå£ä¹é´çæ··æ·ç¸ä¼¼æ§è¿ä¸æ­¥å¤æåäºè¿é¡¹åå²ä»»å¡ãä¸ºäºåºå¯¹è¿äºææï¼æ¬æä»ç»äºä¸ç§æ°é¢çæ·±åº¦ç½ç»æ¶æï¼ç§°ä¸º CAD-Unetï¼ç¨äºåå² COVID-19 èºé¨ææãå¨æ­¤æ¶æä¸­ï¼è¶åç½ç»è¢«çº³å¥ç°æç Unet æ¡æ¶ä¸­ãè¶åç½ç»ä»£è¡¨äºä¸ç§æ°é¢çç½ç»æ¶æï¼å®ä¸åäºä¼ ç»çå·ç§¯ç¥ç»ç½ç»ãå®ä»¬å©ç¨åéå¨è¶åä¹é´è¿è¡ä¿¡æ¯ä¼ è¾ï¼ä¿è¿äºå¤æçåç©ºé´ä¿¡æ¯çæåãæ­¤å¤ï¼æä»¬è®¾è®¡äºä¸ä¸ªè¶åç¼ç å¨è·¯å¾ï¼å¹¶å¨ unet ç¼ç å¨åè¶åç¼ç å¨ä¹é´å»ºç«äºä¸ä¸ªè¦åè·¯å¾ãè¿ç§è®¾è®¡æå¤§éåº¦å°åæ¥äºä¸¤ç§ç½ç»ç»æçäºè¡¥ä¼å¿ï¼åæ¶å®ç°äºé«æçä¿¡æ¯èåã\noindent
æåï¼å¨åä¸ªå¬å¼å¯ç¨çæ°æ®éä¸è¿è¡äºå¹¿æ³çå®éªï¼åæ¬äºè¿å¶åå²ä»»å¡åå¤ç±»åå²ä»»å¡ãå®éªç»æè¯æäºææåºæ¨¡åçåè¶åå²æ§è½ãè¯¥ä»£ç å·²åå¸å¨ï¼
https://github.com/AmanoTooko-jie/CAD-Unetã

##### **A Lightweight U-like Network Utilizing Neural Memory Ordinary Differential Equations for Slimming the Decoder**
2412.06262v1 by Quansong He, Xiaojun Yao, Jun Wu, Zhang Yi, Tao He

In recent years, advanced U-like networks have demonstrated remarkable
performance in medical image segmentation tasks. However, their drawbacks,
including excessive parameters, high computational complexity, and slow
inference speed, pose challenges for practical implementation in scenarios with
limited computational resources. Existing lightweight U-like networks have
alleviated some of these problems, but they often have pre-designed structures
and consist of inseparable modules, limiting their application scenarios. In
this paper, we propose three plug-and-play decoders by employing different
discretization methods of the neural memory Ordinary Differential Equations
(nmODEs). These decoders integrate features at various levels of abstraction by
processing information from skip connections and performing numerical
operations on upward path. Through experiments on the PH2, ISIC2017, and
ISIC2018 datasets, we embed these decoders into different U-like networks,
demonstrating their effectiveness in significantly reducing the number of
parameters and FLOPs while maintaining performance. In summary, the proposed
discretized nmODEs decoders are capable of reducing the number of parameters by
about 20% ~ 50% and FLOPs by up to 74%, while possessing the potential to adapt
to all U-like networks. Our code is available at
https://github.com/nayutayuki/Lightweight-nmODE-Decoders-For-U-like-networks.

æè¦ï¼è¿å¹´ä¾ï¼åé²ç U åç¶²è·¯å¨é«å­¸å½±ååå²ä»»åä¸­å±ç¾åºåè¶çè¡¨ç¾ãç¶èï¼å®åçç¼ºé»åæ¬éå¤çåæ¸ãé«éç®è¤éåº¦åç·©æ¢çæ¨è«éåº¦ï¼å°å¨éç®è³æºæéçææ³ä¸å¯¦éå·è¡æ§æææ°ãç¾æçè¼éç´ U åç¶²è·¯å·²ç¶æ¸è¼äºéäºåé¡ï¼ä½å®åéå¸¸æé åè¨­è¨ççµæ§ï¼ä¸¦åå«ä¸å¯åé¢çæ¨¡çµï¼éå¶äºå®åçæç¨å ´æ¯ãå¨æ¬æä¸­ï¼æåééæ¡ç¨ç¥ç¶è¨æ¶å¸¸å¾®åæ¹ç¨å¼ (nmODE) çä¸åé¢æ£åæ¹æ³ï¼æåºäºä¸åå³æå³ç¨çè§£ç¢¼å¨ãéäºè§£ç¢¼å¨ééèçä¾èªè·³èºé£æ¥çè³è¨ï¼ä¸¦å¨åä¸è·¯å¾ä¸å·è¡æ¸å¼éç®ï¼æ´åäºä¸åæ½è±¡å±¤ç´çç¹å¾µãééå¨ PH2ãISIC2017 å ISIC2018 è³æéä¸çå¯¦é©ï¼æåå°éäºè§£ç¢¼å¨åµå¥å°ä¸åç U åç¶²è·¯ä¸­ï¼è­æå®åå¨é¡¯èæ¸å°åæ¸å FLOP çåæï¼éè½ç¶­ææè½ãç¸½ä¹ï¼ææåºçé¢æ£ nmODE è§£ç¢¼å¨è½å¤ å°åæ¸æ¸éæ¸å°ç´ 20% ~ 50%ï¼FLOP æå¤æ¸å° 74%ï¼åæå·åé©æææ U åç¶²è·¯çæ½åãæåçç¨å¼ç¢¼å¯ä»¥å¨ https://github.com/nayutayuki/Lightweight-nmODE-Decoders-For-U-like-networks åå¾ã

##### **MSCrackMamba: Leveraging Vision Mamba for Crack Detection in Fused Multispectral Imagery**
2412.06211v1 by Qinfeng Zhu, Yuan Fang, Lei Fan

Crack detection is a critical task in structural health monitoring, aimed at
assessing the structural integrity of bridges, buildings, and roads to prevent
potential failures. Vision-based crack detection has become the mainstream
approach due to its ease of implementation and effectiveness. Fusing infrared
(IR) channels with red, green and blue (RGB) channels can enhance feature
representation and thus improve crack detection. However, IR and RGB channels
often differ in resolution. To align them, higher-resolution RGB images
typically need to be downsampled to match the IR image resolution, which leads
to the loss of fine details. Moreover, crack detection performance is
restricted by the limited receptive fields and high computational complexity of
traditional image segmentation networks. Inspired by the recently proposed
Mamba neural architecture, this study introduces a two-stage paradigm called
MSCrackMamba, which leverages Vision Mamba along with a super-resolution
network to address these challenges. Specifically, to align IR and RGB
channels, we first apply super-resolution to IR channels to match the
resolution of RGB channels for data fusion. Vision Mamba is then adopted as the
backbone network, while UperNet is employed as the decoder for crack detection.
Our approach is validated on the large-scale Crack Detection dataset Crack900,
demonstrating an improvement of 3.55% in mIoU compared to the best-performing
baseline methods.

æè¦ï¼è£ç¸«åµæ¸¬å¨çµæ§å¥åº·ç£æ¸¬ä¸­æ¯ä¸é éè¦çä»»åï¼æ¨å¨è©ä¼°æ©æ¨ãå»ºç¯ç©åéè·¯ççµæ§å®æ´æ§ï¼ä»¥é²æ­¢æ½å¨çæéãåºæ¼è¦è¦ºçè£ç¸«åµæ¸¬ç±æ¼å¶ææ¼å¯¦ä½åæææ§ï¼å·²æçºä¸»æµæ¹æ³ãå°ç´å¤ç· (IR) ééèç´è²ãç¶ è²åèè² (RGB) ééèåå¯ä»¥å¢å¼·ç¹å¾µè¡¨ç¤ºï¼é²èæ¹åè£ç¸«åµæ¸¬ãç¶èï¼IR å RGB éééå¸¸è§£æåº¦ä¸åãçºäºå°é½å®åï¼éå¸¸éè¦å°è¼é«è§£æåº¦ç RGB å½±åé²è¡éæ¡æ¨£ä»¥å¹é IR å½±åè§£æåº¦ï¼éæå°è´ç²¾ç´°ç´°ç¯çéºå¤±ãæ­¤å¤ï¼è£ç¸«åµæ¸¬æè½åå°å³çµ±å½±ååå²ç¶²è·¯æéçæåéåé«éç®è¤éåº¦çéå¶ãåè¿ææåºç Mamba ç¥ç¶æ¶æ§åç¼ï¼æ¬ç ç©¶å¼å¥äºä¸åç¨±çº MSCrackMamba çå©éæ®µç¯ä¾ï¼å®å©ç¨ Vision Mamba åè¶è§£æåº¦ç¶²è·¯ä¾æå°éäºææ°ãå·é«ä¾èªªï¼çºäºå°é½ IR å RGB ééï¼æåé¦åå° IR ééæç¨è¶è§£æåº¦ï¼ä»¥å¹é RGB ééçè§£æåº¦ï¼ä»¥é²è¡è³æèåãç¶å¾æ¡ç¨ Vision Mamba ä½çºéª¨å¹¹ç¶²è·¯ï¼åææ¡ç¨ UperNet ä½çºè£ç¸«åµæ¸¬çè§£ç¢¼å¨ãæåçåæ³å·²å¨å¤§åè£ç¸«åµæ¸¬è³æé Crack900 ä¸­å¾å°é©è­ï¼èæè½æä½³çåºæºæ¹æ³ç¸æ¯ï¼mIoU æåäº 3.55%ã

##### **Balancing Efficiency and Effectiveness: An LLM-Infused Approach for Optimized CTR Prediction**
2412.06860v1 by Guoxiao Zhang, Yi Wei, Yadong Zhang, Huajian Feng, Qiang Liu

Click-Through Rate (CTR) prediction is essential in online advertising, where
semantic information plays a pivotal role in shaping user decisions and
enhancing CTR effectiveness. Capturing and modeling deep semantic information,
such as a user's preference for "H\"aagen-Dazs' HEAVEN strawberry light ice
cream" due to its health-conscious and premium attributes, is challenging.
Traditional semantic modeling often overlooks these intricate details at the
user and item levels. To bridge this gap, we introduce a novel approach that
models deep semantic information end-to-end, leveraging the comprehensive world
knowledge capabilities of Large Language Models (LLMs). Our proposed
LLM-infused CTR prediction framework(Multi-level Deep Semantic Information
Infused CTR model via Distillation, MSD) is designed to uncover deep semantic
insights by utilizing LLMs to extract and distill critical information into a
smaller, more efficient model, enabling seamless end-to-end training and
inference. Importantly, our framework is carefully designed to balance
efficiency and effectiveness, ensuring that the model not only achieves high
performance but also operates with optimal resource utilization. Online A/B
tests conducted on the Meituan sponsored-search system demonstrate that our
method significantly outperforms baseline models in terms of Cost Per Mile
(CPM) and CTR, validating its effectiveness, scalability, and balanced approach
in real-world applications.

æè¦ï¼é»æç (CTR) é æ¸¬å¨ç·ä¸å»£åä¸­è³ééè¦ï¼å¶ä¸­èªæè³è¨å¨å¡é ä½¿ç¨èæ±ºç­åæå CTR æçæ¹é¢æ®æ¼èééµè§è²ãæ·ååå»ºæ¨¡æ·±å¥çèªæè³è¨ï¼ä¾å¦ä½¿ç¨èåå¥½ãH\"aagen-Dazs' HEAVEN èèè¼çå°æ·æ·ãï¼å çºå®å·ææ³¨éå¥åº·åé«ç´çå±¬æ§ï¼æ¯ä¸é ææ°ãå³çµ±çèªæå»ºæ¨¡éå¸¸æå¿½ç¥ä½¿ç¨èåé ç®å±¤ç´çéäºè¤éç´°ç¯ãçºäºå½è£æ­¤å·®è·ï¼æåæåºäºä¸ç¨®åµæ°çæ¹æ³ï¼è©²æ¹æ³å¯ä»¥ç«¯å°ç«¯å°å»ºæ¨¡æ·±å¥èªæè³è¨ï¼ä¸¦å©ç¨å¤§åèªè¨æ¨¡å (LLM) çå¨é¢ä¸çç¥è­è½åãæåæåºç LLM æ³¨å¥ CTR é æ¸¬æ¶æ§ï¼ééç¥è­èåçå¤å±¤ç´æ·±å¥èªæè³è¨æ³¨å¥ CTR æ¨¡åï¼MSDï¼æ¨å¨ééå©ç¨ LLM èååæçééµè³è¨å°ä¸åæ´å°ãæ´ææççæ¨¡åä¸­ï¼ä¾ç¼ææ·±å¥çèªææ´å¯ï¼å¯¦ç¾ç¡ç¸«ç«¯å°ç«¯è¨ç·´åæ¨è«ãéè¦çæ¯ï¼æåçæ¶æ§ç¶éä»ç´°è¨­è¨ï¼ä»¥å¹³è¡¡æçåæè½ï¼ç¢ºä¿æ¨¡åä¸åè½éæé«æ§è½ï¼éè½ä»¥æä½³è³æºå©ç¨çéä½ãå¨ç¾åè´å©æå°ç³»çµ±ä¸é²è¡çç·ä¸ A/B æ¸¬è©¦è­æï¼æåçæ¨¡åå¨æ¯åæ¬¡ææ¬ (CPM) å CTR æ¹é¢é¡¯èåªæ¼åºç·æ¨¡åï¼é©è­äºå¶å¨å¯¦éæç¨ä¸­çæææ§ãå¯æ´åæ§åå¹³è¡¡æ¹æ³ã

##### **MMedPO: Aligning Medical Vision-Language Models with Clinical-Aware Multimodal Preference Optimization**
2412.06141v1 by Kangyu Zhu, Peng Xia, Yun Li, Hongtu Zhu, Sheng Wang, Huaxiu Yao

The advancement of Large Vision-Language Models (LVLMs) has propelled their
application in the medical field. However, Medical LVLMs (Med-LVLMs) encounter
factuality challenges due to modality misalignment, where the models prioritize
textual knowledge over visual input, leading to hallucinations that contradict
information in medical images. Previous attempts to enhance modality alignment
in Med-LVLMs through preference optimization have inadequately mitigated
clinical relevance in preference data, making these samples easily
distinguishable and reducing alignment effectiveness. To address this
challenge, we propose MMedPO, a novel multimodal medical preference
optimization approach that considers the clinical relevance of preference
samples to enhance Med-LVLM alignment. MMedPO curates multimodal preference
data by introducing two types of dispreference: (1) plausible hallucinations
injected through target Med-LVLMs or GPT-4o to produce medically inaccurate
responses, and (2) lesion region neglect achieved through local lesion-noising,
disrupting visual understanding of critical areas. We then calculate clinical
relevance for each sample based on scores from multiple Med-LLMs and visual
tools, and integrate these scores into the preference optimization process as
weights, enabling effective alignment. Our experiments demonstrate that MMedPO
significantly enhances factual accuracy in Med-LVLMs, achieving substantial
improvements over existing preference optimization methods by averaging 14.2%
and 51.7% across the Med-VQA and report generation tasks. Our code are
available in https://github.com/aiming-lab/MMedPO.

æè¦ï¼å¤§åè¦è¦ºèªè¨æ¨¡å (LVLMs) çé²æ­¥æ¨åäºå®åå¨é«çé åçæç¨ãç¶èï¼é«å­¸ LVLMs (Med-LVLMs) ç±æ¼æ¨¡æé¯ä½èéå°äºå¯¦ææ°ï¼å¶ä¸­æ¨¡ååªåèæ®æå­ç¥è­èéè¦è¦ºè¼¸å¥ï¼å°è´å¹»è¦ºèé«å­¸å½±åä¸­çè³è¨ç¸çç¾ãåååè©¦ééåå¥½æä½³åä¾å¢å¼· Med-LVLMs ä¸­çæ¨¡æå°é½ï¼å¨åå¥½è³æä¸­ä¸è¶³ä»¥æ¸è¼è¨åºç¸éæ§ï¼ä½¿å¾éäºç¯ä¾å®¹æååï¼ä¸¦éä½å°é½ææãçºäºæå°éé ææ°ï¼æåæåº MMedPOï¼ä¸ç¨®æ°çå¤æ¨¡æé«å­¸åå¥½æä½³åæ¹æ³ï¼å®èæ®åå¥½ç¯ä¾çè¨åºç¸éæ§ï¼ä»¥å¢å¼· Med-LVLM å°é½ãMMedPO ééå¼å¥å©ç¨®é¡åçååå¥½ä¾ç®¡çå¤æ¨¡æåå¥½è³æï¼(1) åççå¹»è¦ºééç®æ¨ Med-LVLMs æ GPT-4o æ³¨å¥ï¼ä»¥ç¢çé«å­¸ä¸ä¸æºç¢ºçåæï¼ä»¥å (2) ééå±é¨çç¶éè¨å¯¦ç¾çç¶ååå¿½ç¥ï¼ç ´å£å°ééµååçè¦è¦ºçè§£ãç¶å¾ï¼æåæ ¹æä¾èªå¤å Med-LLMs åè¦è¦ºå·¥å·çåæ¸è¨ç®æ¯åç¯ä¾çè¨åºç¸éæ§ï¼ä¸¦å°éäºåæ¸ä½çºæ¬éæ´åå°åå¥½æä½³åéç¨ä¸­ï¼ä»¥å¯¦ç¾ææå°é½ãæåçå¯¦é©è­æï¼MMedPO æé¡¯å¢å¼·äº Med-LVLMs ä¸­çäºå¯¦æºç¢ºæ§ï¼å¨ Med-VQA åå ±åçæä»»åä¸­ï¼å¹³ååå¥æ¯ç¾æçåå¥½æä½³åæ¹æ³æé«äº 14.2% å 51.7%ãæåçç¨å¼ç¢¼å¯ä»¥å¨ https://github.com/aiming-lab/MMedPO ä¸­åå¾ã

##### **Imputation Matters: A Deeper Look into an Overlooked Step in Longitudinal Health and Behavior Sensing Research**
2412.06018v1 by Akshat Choube, Rahul Majethia, Sohini Bhattacharya, Vedant Das Swain, Jiachen Li, Varun Mishra

Longitudinal passive sensing studies for health and behavior outcomes often
have missing and incomplete data. Handling missing data effectively is thus a
critical data processing and modeling step. Our formative interviews with
researchers working in longitudinal health and behavior passive sensing
revealed a recurring theme: most researchers consider imputation a low-priority
step in their analysis and inference pipeline, opting to use simple and
off-the-shelf imputation strategies without comprehensively evaluating its
impact on study outcomes. Through this paper, we call attention to the
importance of imputation. Using publicly available passive sensing datasets for
depression, we show that prioritizing imputation can significantly impact the
study outcomes -- with our proposed imputation strategies resulting in up to
31% improvement in AUROC to predict depression over the original imputation
strategy. We conclude by discussing the challenges and opportunities with
effective imputation in longitudinal sensing studies.

æè¦ï¼ç¸±åè¢«åææ¸¬ç ç©¶å°æ¼å¥åº·åè¡çºçµæå¸¸å¸¸æç¼ºå¤±åä¸å®æ´çè³æãææèçç¼ºå¤±è³æå æ­¤æ¯è³æèçåå»ºæ¨¡çéè¦æ­¥é©ãæåèå¾äºç¸±åå¥åº·åè¡çºè¢«åææ¸¬çç ç©¶äººå¡é²è¡çå½¢ææ§è¨ªè«æ­é²äºä¸ååè¦åºç¾çä¸»é¡ï¼å¤§å¤æ¸ç ç©¶äººå¡èªçºå§ææ¯å¶åæåæ¨è«æµç¨ä¸­åªåé åºè¼ä½çä¸åæ­¥é©ï¼é¸æä½¿ç¨ç°¡å®ä¸ç¾æçå§æç­ç¥ï¼èæ²æå¨é¢è©ä¼°å¶å°ç ç©¶çµæçå½±é¿ãéééç¯è«æï¼æåå¼ç±²éè¦å§æãä½¿ç¨å¬éçè¢«åææ¸¬è³æéé²è¡æé¬±çç ç©¶ï¼æåè­æåªåèæ®å§ææå°ç ç©¶çµæç¢çéå¤§å½±é¿ââæåæåºçå§æç­ç¥ä½¿ AUROC é æ¸¬æé¬±ççè½åæ¯åå§å§æç­ç¥æé«äº 31%ãæå¾ï¼æåè¨è«äºå¨ç¸±åææ¸¬ç ç©¶ä¸­ææå§æçææ°åæ©æã

##### **MG-3D: Multi-Grained Knowledge-Enhanced 3D Medical Vision-Language Pre-training**
2412.05876v1 by Xuefeng Ni, Linshan Wu, Jiaxin Zhuang, Qiong Wang, Mingxiang Wu, Varut Vardhanabhuti, Lihai Zhang, Hanyu Gao, Hao Chen

3D medical image analysis is pivotal in numerous clinical applications.
However, the scarcity of labeled data and limited generalization capabilities
hinder the advancement of AI-empowered models. Radiology reports are easily
accessible and can serve as weakly-supervised signals. However, large-scale
vision-language pre-training (VLP) remains underexplored in 3D medical image
analysis. Specifically, the insufficient investigation into multi-grained
radiology semantics and their correlations across patients leads to
underutilization of large-scale volume-report data.
  Considering intra-patient cross-modal semantic consistency and inter-patient
semantic correlations, we propose a multi-task VLP method, MG-3D, pre-trained
on large-scale data (47.1K), addressing the challenges by the following two
aspects: 1) Establishing the correspondence between volume semantics and
multi-grained medical knowledge of each patient with cross-modal global
alignment and complementary modality-guided local reconstruction, ensuring
intra-patient features of different modalities cohesively represent the same
semantic content; 2) Correlating inter-patient visual semantics based on
fine-grained report correlations across patients, and keeping sensitivity to
global individual differences via contrastive learning, enhancing the
discriminative feature representation. Furthermore, we delve into the scaling
law to explore potential performance improvements. Comprehensive evaluations
across nine uni- and cross-modal clinical tasks are carried out to assess model
efficacy. Extensive experiments on both internal and external datasets
demonstrate the superior transferability, scalability, and generalization of
MG-3D, showcasing its potential in advancing feature representation for 3D
medical image analysis. Code will be available:
https://github.com/Xuefeng-Ni/MG-3D.

æè¦ï¼<paragraph>3D é«å­¸å½±ååæå¨ç¾å¤è¨åºæç¨ä¸­è³ééè¦ã
ç¶èï¼æ¨è¨è³æçç¨ç¼ºåæéçæ¦åè½å
é»ç¤äº AI è³¦è½æ¨¡åçé²æ­¥ãæ¾å°å ±åå®¹æç²å¾ï¼å¯ä»¥ç¨ä½å¼±ç£ç£ä¿¡èãç¶èï¼å¤§è¦æ¨¡
è¦è¦ºèªè¨é è¨ç·´ (VLP) å¨ 3D é«å­¸å½±å
åæä¸­ä»æªå¾å°ååæ¢ç´¢ãå·é«ä¾èªªï¼å°å¤ç²åº¦
æ¾å°èªç¾©åå¶å¨æ£èä¹éçç¸éæ§ç ç©¶ä¸è¶³ï¼å°è´å¤§è¦æ¨¡é«ç©å ±åæ¸æå©ç¨ä¸è¶³ã
èæ®å°æ£èå§é¨è·¨æ¨¡æèªç¾©ä¸è´æ§åæ£èé
èªç¾©ç¸éæ§ï¼æåæåºäºä¸ç¨®å¤ä»»å VLP æ¹æ³ MG-3Dï¼é è¨ç·´
å¨å¤§åæ¸æ (47.1K) ä¸ï¼ééä»¥ä¸å©åæ¹é¢è§£æ±ºææ°ï¼1) å»ºç«é«ç©èªç¾©å
æ¯åæ£èçå¤ç²åº¦é«å­¸ç¥è­ä¹éçå°æéä¿ï¼ééè·¨æ¨¡æå¨å±
å°é½åäºè£æ¨¡æå¼å°çå±é¨éå»ºï¼ç¢ºä¿ä¸åæ¨¡æçæ£èå§é¨ç¹å¾µä¸è´å°è¡¨ç¤ºç¸åç
èªç¾©å§å®¹ï¼2) åºæ¼æ£èä¹éçç´°ç²åº¦å ±åç¸éæ§å°æ£èéçè¦è¦ºèªç¾©é²è¡éè¯ï¼ä¸¦ééå°æ¯å­¸ç¿ä¿æå°
å¨å±åé«å·®ç°çæææ§ï¼å¢å¼·å¤å¥ç¹å¾µè¡¨ç¤ºãæ­¤å¤ï¼æåæ·±å¥ç ç©¶äºæ´å±
å®å¾ä»¥æ¢ç´¢æ½å¨çæ§è½æ¹é²ãè·¨è¶ä¹é å®æ¨¡æåè·¨æ¨¡æè¨åºä»»åçç¶åè©ä¼°æ¯é²è¡çï¼ä»¥è©ä¼°æ¨¡å
æè½ãå¨å§é¨åå¤é¨æ¸æéä¸çå»£æ³å¯¦é©
è­æäº MG-3D çåè¶å¯å³éæ§ãå¯æ´å±æ§åæ³åæ§ï¼å±ç¤ºäºå¶å¨æ¨é² 3D
é«å­¸å½±ååæç¹å¾µè¡¨ç¤ºæ¹é¢çæ½åãä»£ç¢¼å°æä¾ï¼
https://github.com/Xuefeng-Ni/MG-3Dã</paragraph>

##### **Evolving Algebraic Multigrid Methods Using Grammar-Guided Genetic Programming**
2412.05852v1 by Dinesh Parthasarathy, Wayne Bradford Mitchell, Harald KÃ¶stler

Multigrid methods despite being known to be asymptotically optimal
algorithms, depend on the careful selection of their individual components for
efficiency. Also, they are mostly restricted to standard cycle types like V-,
F-, and W-cycles. We use grammar rules to generate arbitrary-shaped cycles,
wherein the smoothers and their relaxation weights are chosen independently at
each step within the cycle. We call this a flexible multigrid cycle. These
flexible cycles are used in Algebraic Multigrid (AMG) methods with the help of
grammar rules and optimized using genetic programming. The flexible AMG methods
are implemented in the software library of hypre, and the programs are
optimized separately for two cases: a standalone AMG solver for a 3D
anisotropic problem and an AMG preconditioner with conjugate gradient for a
multiphysics code. We observe that the optimized flexible cycles provide higher
efficiency and better performance than the standard cycle types.

æè¦ï¼å¤éç¶²æ ¼æ³åç®¡å·²ç¥çºæ¼¸è¿æä½³æ¼ç®æ³ï¼ä½å¶æçåæ±ºæ¼å¶åå¥çµæçä»ç´°é¸æãæ­¤å¤ï¼å®åå¤§å¤ä¾·éæ¼æ¨æºå¾ªç°é¡åï¼ä¾å¦ VãF å W å¾ªç°ãæåä½¿ç¨èªæ³è¦åä¾ç¢çä»»æå½¢ççå¾ªç°ï¼å¶ä¸­å¹³æ»å¨åå¶é¬å¼æ¬éå¨å¾ªç°ä¸­çæ¯åæ­¥é©ä¸­ç¨ç«é¸æãæåç¨±ä¹çºå½æ§å¤éç¶²æ ¼å¾ªç°ãéäºå½æ§å¾ªç°å¨ä»£æ¸å¤éç¶²æ ¼ (AMG) æ¹æ³ä¸­ä½¿ç¨ï¼ä¸¦å¨èªæ³è¦åçå¹«å©ä¸ä½¿ç¨éºå³ç¨å¼è¨­è¨é²è¡æä½³åãå½æ§ AMG æ¹æ³å¨ hypre çè»é«ç¨å¼åº«ä¸­å¯¦ä½ï¼ä¸ç¨å¼éå°å©ç¨®ææ³åå¥æä½³åï¼3D ç°åæ§åé¡çç¨ç« AMG æ±è§£å¨ï¼ä»¥åå¤ç©çå ´ç¨å¼ç¢¼çå±è»æ¢¯åº¦ AMG é èçå¨ãæåè§å¯å°æä½³åçå½æ§å¾ªç°æä¾æ¯æ¨æºå¾ªç°é¡åæ´é«çæçåæ´å¥½çæè½ã

##### **Biological Brain Age Estimation using Sex-Aware Adversarial Variational Autoencoder with Multimodal Neuroimages**
2412.05632v1 by Abd Ur Rehman, Azka Rehman, Muhammad Usman, Abdullah Shahid, Sung-Min Gho, Aleum Lee, Tariq M. Khan, Imran Razzak

Brain aging involves structural and functional changes and therefore serves
as a key biomarker for brain health. Combining structural magnetic resonance
imaging (sMRI) and functional magnetic resonance imaging (fMRI) has the
potential to improve brain age estimation by leveraging complementary data.
However, fMRI data, being noisier than sMRI, complicates multimodal fusion.
Traditional fusion methods often introduce more noise than useful information,
which can reduce accuracy compared to using sMRI alone. In this paper, we
propose a novel multimodal framework for biological brain age estimation,
utilizing a sex-aware adversarial variational autoencoder (SA-AVAE). Our
framework integrates adversarial and variational learning to effectively
disentangle the latent features from both modalities. Specifically, we
decompose the latent space into modality-specific codes and shared codes to
represent complementary and common information across modalities, respectively.
To enhance the disentanglement, we introduce cross-reconstruction and
shared-distinct distance ratio loss as regularization terms. Importantly, we
incorporate sex information into the learned latent code, enabling the model to
capture sex-specific aging patterns for brain age estimation via an integrated
regressor module. We evaluate our model using the publicly available OpenBHB
dataset, a comprehensive multi-site dataset for brain age estimation. The
results from ablation studies and comparisons with state-of-the-art methods
demonstrate that our framework outperforms existing approaches and shows
significant robustness across various age groups, highlighting its potential
for real-time clinical applications in the early detection of neurodegenerative
diseases.

æè¦ï¼å¤§è¦èåæ¶åçµæ§ååè½çæ¹è®ï¼å æ­¤å¯ä½çºå¤§è¦å¥åº·çééµçç©æ¨è¨ãçµåçµæ§æ§ç£æ¯é å½± (sMRI) ååè½æ§ç£æ¯é å½± (fMRI) æå¯è½ééå©ç¨äºè£æ¸æä¾æ¹åå¤§è¦å¹´é½¡ä¼°è¨ãç¶èï¼fMRI è³ææ¯ sMRI éè¨æ´å¤ï¼éä½¿å¾å¤æ¨¡æèåè®å¾è¤éãå³çµ±èåæ¹æ³éå¸¸æå¼å¥æ¯æç¨è³è¨æ´å¤éè¨ï¼éå¯è½æéä½èå®ç¨ä½¿ç¨ sMRI ç¸æ¯çæºç¢ºæ§ãå¨æ¬æä¸­ï¼æåæåºä¸åç¨æ¼çç©å¤§è¦å¹´é½¡ä¼°è¨çæ°å¤æ¨¡ææ¡æ¶ï¼å©ç¨ä¸åææ§å¥æè­çå°æè®ç°èªåç·¨ç¢¼å¨ (SA-AVAE)ãæåçæ¡æ¶æ´åäºå°æåè®ç°å­¸ç¿ï¼ä»¥ææå°è§£éä¾èªå©ç¨®æ¨¡æçæ½å¨ç¹å¾µãå·é«èè¨ï¼æåå°æ½å¨ç©ºéåè§£çºç¹å®æ¼æ¨¡æçä»£ç¢¼åå±äº«ä»£ç¢¼ï¼åå¥è¡¨ç¤ºè·¨æ¨¡æçäºè£åå±åè³è¨ãçºäºå¢å¼·è§£éï¼æåå¼å¥äºäº¤åéå»ºåå±äº«ä¸åè·é¢æ¯çæå¤±ä½çºæ­£ååé ãéè¦çæ¯ï¼æåå°æ§å¥è³è¨ç´å¥å­¸ç¿å°çæ½å¨ä»£ç¢¼ä¸­ï¼ä½¿æ¨¡åè½å¤ ééæ´ååæ­¸æ¨¡çµï¼ææç¹å®æ¼æ§å¥çèåæ¨¡å¼ï¼ä»¥é²è¡å¤§è¦å¹´é½¡ä¼°è¨ãæåä½¿ç¨å¬éå¯ç¨ç OpenBHB è³æéè©ä¼°æåçæ¨¡åï¼éæ¯ä¸åç¨æ¼å¤§è¦å¹´é½¡ä¼°è¨çç¶åå¤å ´åè³æéãæ¶èç ç©¶åèæåé²æ¹æ³çæ¯è¼çµæè¡¨æï¼æåçæ¡æ¶åªæ¼ç¾ææ¹æ³ï¼ä¸¦å¨ååå¹´é½¡çµä¸­é¡¯ç¤ºåºé¡¯èçç©©å¥æ§ï¼çªé¡¯äºå¶å¨ç¥ç¶éåæ§ç¾çæ©ææª¢æ¸¬ä¸­çå³æè¨åºæç¨æ½åã

##### **UNet++ and LSTM combined approach for Breast Ultrasound Image Segmentation**
2412.05585v1 by Saba Hesaraki, Morteza Akbari, Ramin Mousa

Breast cancer stands as a prevalent cause of fatality among females on a
global scale, with prompt detection playing a pivotal role in diminishing
mortality rates. The utilization of ultrasound scans in the BUSI dataset for
medical imagery pertaining to breast cancer has exhibited commendable
segmentation outcomes through the application of UNet and UNet++ networks.
Nevertheless, a notable drawback of these models resides in their inattention
towards the temporal aspects embedded within the images. This research
endeavors to enrich the UNet++ architecture by integrating LSTM layers and
self-attention mechanisms to exploit temporal characteristics for segmentation
purposes. Furthermore, the incorporation of a Multiscale Feature Extraction
Module aims to grasp varied scale features within the UNet++. Through the
amalgamation of our proposed methodology with data augmentation on the BUSI
with GT dataset, an accuracy rate of 98.88%, specificity of 99.53%, precision
of 95.34%, sensitivity of 91.20%, F1-score of 93.74, and Dice coefficient of
92.74% are achieved. These findings demonstrate competitiveness with
cutting-edge techniques outlined in existing literature.

æè¦ï¼ä¹³çæ¯å¨çå¥³æ§æ­»äº¡çä¸»è¦åå ï¼åæ©ç¼ç¾å°æ¼éä½æ­»äº¡çæ®æ¼ééµè§è²ãå¨ BUSI è³æéä¸­ä½¿ç¨è¶é³æ³¢ææé²è¡ä¹³çç¸éçé«å­¸å½±åï¼ééæç¨ UNet å UNet++ ç¶²è·¯å·²å±ç¾åºä»¤äººæ»¿æçåå²çµæãç¶èï¼éäºæ¨¡åä¸åé¡¯èçç¼ºé»å¨æ¼å®åå¿½ç¥äºå½±åä¸­åå«çæéé¢åãæ¬ç ç©¶è´åæ¼ééæ´å LSTM å±¤åèªææ³¨ææ©å¶ä¾è±å¯ UNet++ æ¶æ§ï¼ä»¥å©ç¨æéç¹å¾µé²è¡åå²ãæ­¤å¤ï¼æ´åå¤å°ºåº¦ç¹å¾µèåæ¨¡çµæ¨å¨ææ¡ UNet++ ä¸­åç¨®å°ºåº¦çç¹å¾µãééå°æåæåºçæ¹æ³è BUSI with GT è³æéä¸çè³ææ´åçµåï¼éå°äº 98.88% çæºç¢ºçã99.53% çç¹ç°æ§ã95.34% çç²¾ç¢ºåº¦ã91.20% çææåº¦ã93.74 ç F1 åæ¸ï¼ä»¥å 92.74% ç Dice ä¿æ¸ãéäºç¼ç¾è­æäºèç¾ææç»ä¸­æ¦è¿°çå°ç«¯æè¡å·æç«¶ç­åã

##### **Electrocardiogram (ECG) Based Cardiac Arrhythmia Detection and Classification using Machine Learning Algorithms**
2412.05583v2 by Atit Pokharel, Shashank Dahal, Pratik Sapkota, Bhupendra Bimal Chhetri

The rapid advancements in Artificial Intelligence, specifically Machine
Learning (ML) and Deep Learning (DL), have opened new prospects in medical
sciences for improved diagnosis, prognosis, and treatment of severe health
conditions. This paper focuses on the development of an ML model with high
predictive accuracy to classify arrhythmic electrocardiogram (ECG) signals. The
ECG signals datasets utilized in this study were sourced from the PhysioNet and
MIT-BIH databases. The research commenced with binary classification, where an
optimized Bidirectional Long Short-Term Memory (Bi-LSTM) model yielded
excellent results in differentiating normal and atrial fibrillation signals. A
pivotal aspect of this research was a survey among medical professionals, which
not only validated the practicality of AI-based ECG classifiers but also
identified areas for improvement, including accuracy and the inclusion of more
arrhythmia types. These insights drove the development of an advanced
Convolutional Neural Network (CNN) system capable of classifying five different
types of ECG signals with better accuracy and precision. The CNN model's robust
performance was ensured through rigorous stratified 5-fold cross validation. A
web portal was also developed to demonstrate real-world utility, offering
access to the trained model for real-time classification. This study highlights
the potential applications of such models in remote health monitoring,
predictive healthcare, assistive diagnostic tools, and simulated environments
for educational training and interdisciplinary collaboration between data
scientists and medical personnel.

æè¦ï¼äººå·¥æºæ§çå¿«éé²å±ï¼ç¹å¥æ¯æ©å¨å­¸ç¿ï¼MLï¼åæ·±åº¦å­¸ç¿ï¼DLï¼ï¼çºé«å­¸ç§å­¸éé¢äºæ°çåæ¯ï¼ä»¥æ¹åå´éå¥åº·çæ³çè¨ºæ·ãé å¾åæ²»çãæ¬æéé»å¨æ¼éç¼å·æé«é æ¸¬ç²¾åº¦ç ML æ¨¡åï¼ç¨æ¼åé¡å¿å¾ä¸æ´å¿é»å (ECG) ä¿¡èãæ¬ç ç©¶ä¸­ä½¿ç¨ç ECG ä¿¡èè³æéä¾èª PhysioNet å MIT-BIH è³æåº«ãç ç©¶å¾äºååé¡éå§ï¼å¶ä¸­ç¶éæä½³åçéåé·ç­æè¨æ¶ (Bi-LSTM) æ¨¡åå¨ååæ­£å¸¸åå¿æ¿é¡«åä¿¡èæ¹é¢ç¢çäºæ¥µä½³ççµæãæ¬ç ç©¶çä¸åééµæ¹é¢æ¯éå°é«è­·å°æ¥­äººå¡é²è¡çèª¿æ¥ï¼éä¸åé©è­äºåºæ¼ AI ç ECG åé¡å¨çå¯¦ç¨æ§ï¼éæ¾åºæ¹é²é åï¼åæ¬æºç¢ºæ§åç´å¥æ´å¤å¿å¾ä¸æ´é¡åãéäºè¦è§£æ¨åäºåé²å·ç©ç¥ç¶ç¶²è·¯ (CNN) ç³»çµ±çéç¼ï¼è©²ç³»çµ±è½å¤ ä»¥æ´é«çæºç¢ºåº¦åç²¾ç¢ºåº¦å°äºç¨®é¡åç ECG ä¿¡èé²è¡åé¡ãééå´æ ¼çåå±¤ 5 åäº¤åé©è­ï¼ç¢ºä¿äº CNN æ¨¡åçå¼·å¥æè½ãééç¼äºä¸åç¶²è·¯å¥å£ç¶²ç«ä¾å±ç¤ºçå¯¦ä¸ççæç¨ï¼æä¾å­åå·²è¨ç·´æ¨¡åä»¥é²è¡å³æåé¡ãæ¬ç ç©¶å¼·èª¿äºæ­¤é¡æ¨¡åå¨é è·å¥åº·ç£æ¸¬ãé æ¸¬æ§é«çä¿å¥ãè¼å©è¨ºæ·å·¥å·ä»¥åç¨æ¼æè²è¨ç·´åè³æç§å­¸å®¶èé«è­·äººå¡ä¹éè·¨é ååä½çæ¨¡æ¬ç°å¢ä¸­çæ½å¨æç¨ã

##### **Comprehensive Evaluation of Multimodal AI Models in Medical Imaging Diagnosis: From Data Augmentation to Preference-Based Comparison**
2412.05536v1 by Cailian Ruan, Chengyue Huang, Yahe Yang

This study introduces an evaluation framework for multimodal models in
medical imaging diagnostics. We developed a pipeline incorporating data
preprocessing, model inference, and preference-based evaluation, expanding an
initial set of 500 clinical cases to 3,000 through controlled augmentation. Our
method combined medical images with clinical observations to generate
assessments, using Claude 3.5 Sonnet for independent evaluation against
physician-authored diagnoses. The results indicated varying performance across
models, with Llama 3.2-90B outperforming human diagnoses in 85.27% of cases. In
contrast, specialized vision models like BLIP2 and Llava showed preferences in
41.36% and 46.77% of cases, respectively. This framework highlights the
potential of large multimodal models to outperform human diagnostics in certain
tasks.

æè¦ï¼æ¬ç ç©¶å¼å¥äºä¸åç¨æ¼é«çå½±åè¨ºæ·ä¸­å¤æ¨¡ææ¨¡åçè©ä¼°æ¡æ¶ãæåéç¼äºä¸åçµåäºè³æåèçãæ¨¡åæ¨è«ååºæ¼åå¥½çè©ä¼°çç®¡éï¼ééåæ§æ´åå°æåç 500 åè¨åºæ¡ä¾æ´åå° 3,000 åãæåçåæ³çµåäºé«å­¸å½±ååè¨åºè§å¯ï¼ä»¥ç¢çè©ä¼°ï¼ä½¿ç¨ Claude 3.5 Sonnet å°æé«å¸«æ°å¯«çè¨ºæ·é²è¡ç¨ç«è©ä¼°ãçµæé¡¯ç¤ºä¸åæ¨¡åçè¡¨ç¾ä¸åï¼å¶ä¸­ Llama 3.2-90B å¨ 85.27% çæ¡ä¾ä¸­åªæ¼äººé¡è¨ºæ·ãç¸æ¯ä¹ä¸ï¼å°éçè¦è¦ºæ¨¡åï¼ä¾å¦ BLIP2 å Llavaï¼åå¥å¨ 41.36% å 46.77% çæ¡ä¾ä¸­é¡¯ç¤ºåºåå¥½ãæ­¤æ¡æ¶çªé¡¯äºå¤§åå¤æ¨¡ææ¨¡åå¨æäºä»»åä¸­åªæ¼äººé¡è¨ºæ·çæ½åã

##### **Enhancing LLMs for Impression Generation in Radiology Reports through a Multi-Agent System**
2412.06828v1 by Fang Zeng, Zhiliang Lyu, Quanzheng Li, Xiang Li

This study introduces "RadCouncil," a multi-agent Large Language Model (LLM)
framework designed to enhance the generation of impressions in radiology
reports from the finding section. RadCouncil comprises three specialized
agents: 1) a "Retrieval" Agent that identifies and retrieves similar reports
from a vector database, 2) a "Radiologist" Agent that generates impressions
based on the finding section of the given report plus the exemplar reports
retrieved by the Retrieval Agent, and 3) a "Reviewer" Agent that evaluates the
generated impressions and provides feedback. The performance of RadCouncil was
evaluated using both quantitative metrics (BLEU, ROUGE, BERTScore) and
qualitative criteria assessed by GPT-4, using chest X-ray as a case study.
Experiment results show improvements in RadCouncil over the single-agent
approach across multiple dimensions, including diagnostic accuracy, stylistic
concordance, and clarity. This study highlights the potential of utilizing
multiple interacting LLM agents, each with a dedicated task, to enhance
performance in specialized medical tasks and the development of more robust and
adaptable healthcare AI solutions.

æè¦ï¼æ¬ç ç©¶å¼å¥äºãRadCouncilãï¼ä¸åå¤éä»£çå¤§åèªè¨æ¨¡å (LLM)
æ¡æ¶ï¼æ¨å¨å¢å¼·æ¾å°ç§å ±åä¸­å°è±¡çç¢çï¼ç¹å¥æ¯ç¼ç¾é¨åãRadCouncil åå«ä¸åå°éçä»£çï¼1) ä¸åãæª¢ç´¢ãä»£çï¼ç¨æ¼è­å¥ä¸¦å¾åéè³æåº«ä¸­æª¢ç´¢é¡ä¼¼çå ±åï¼2) ä¸åãæ¾å°ç§é«å¸«ãä»£çï¼ç¨æ¼æ ¹æçµ¦å®å ±åçç¼ç¾é¨åå ä¸æª¢ç´¢ä»£çæª¢ç´¢å°çç¯ä¾å ±åï¼ç¢çå°è±¡ï¼ä»¥å 3) ä¸åãå¯©æ¥èãä»£çï¼ç¨æ¼è©ä¼°ç¢ççå°è±¡ä¸¦æä¾åé¥ãRadCouncil çæè½ä½¿ç¨éåææ¨ (BLEUãROUGEãBERTScore) é²è¡è©ä¼°ï¼ä¸¦ä½¿ç¨è¸é¨ X åä½çºæ¡ä¾ç ç©¶ï¼ç± GPT-4 è©ä¼°è³ªåæ¨æºãå¯¦é©çµæé¡¯ç¤ºï¼RadCouncil å¨å¤åé¢åé½ææ¹é²ï¼åæ¬è¨ºæ·æºç¢ºæ§ãé¢¨æ ¼ä¸è´æ§ï¼ä»¥åæ¸æ°åº¦ï¼åªæ¼å®ä¸ä»£çæ¹æ³ãæ¬ç ç©¶å¼·èª¿äºå©ç¨å¤åäºåå¼ LLM ä»£ççæ½åï¼æ¯åä»£çé½æå°éçä»»åï¼ä»¥å¢å¼·å¨å°æ¥­é«çä»»åä¸­çæè½ï¼ä¸¦éç¼æ´å¼·å¥ä¸é©ææ§æ´å¼·çé«çä¿å¥ AI è§£æ±ºæ¹æ¡ã

##### **Enhancing FKG.in: automating Indian food composition analysis**
2412.05248v2 by Saransh Kumar Gupta, Lipika Dey, Partha Pratim Das, Geeta Trilok-Kumar, Ramesh Jain

This paper presents a novel approach to compute food composition data for
Indian recipes using a knowledge graph for Indian food (FKG.in) and LLMs. The
primary focus is to provide a broad overview of an automated food composition
analysis workflow and describe its core functionalities: nutrition data
aggregation, food composition analysis, and LLM-augmented information
resolution. This workflow aims to complement FKG.in and iteratively supplement
food composition data from verified knowledge bases. Additionally, this paper
highlights the challenges of representing Indian food and accessing food
composition data digitally. It also reviews three key sources of food
composition data: the Indian Food Composition Tables, the Indian Nutrient
Databank, and the Nutritionix API. Furthermore, it briefly outlines how users
can interact with the workflow to obtain diet-based health recommendations and
detailed food composition information for numerous recipes. We then explore the
complex challenges of analyzing Indian recipe information across dimensions
such as structure, multilingualism, and uncertainty as well as present our
ongoing work on LLM-based solutions to address these issues. The methods
proposed in this workshop paper for AI-driven knowledge curation and
information resolution are application-agnostic, generalizable, and replicable
for any domain.

æè¦ï¼æ¬ææåºäºä¸ååµæ°çæ¹æ³ï¼ä½¿ç¨å°åº¦é£åç¥è­åè­ (FKG.in) å LLM ä¾è¨ç®å°åº¦é£è­çé£åæåæ¸æãä¸»è¦éé»æ¯æä¾èªååé£åæååæå·¥ä½æµç¨çå»£æ³æ¦è¿°ï¼ä¸¦æè¿°å¶æ ¸å¿åè½ï¼çé¤æ¸æå½ç¸½ãé£åæååæå LLM å¢å¼·çä¿¡æ¯è§£æãæ­¤å·¥ä½æµç¨æ¨å¨è£å FKG.inï¼ä¸¦åè¦è£åä¾èªé©è­ç¥è­åº«çé£åæåæ¸æãæ­¤å¤ï¼æ¬æéé»ä»ç´¹äºè¡¨ç¤ºå°åº¦é£ååä»¥æ¸ä½æ¹å¼å­åé£åæåæ¸æçææ°ãå®éåé¡§äºé£åæåæ¸æçä¸åééµä¾æºï¼å°åº¦é£åæåè¡¨ãå°åº¦çé¤è³æåº«å Nutritionix APIãæ­¤å¤ï¼å®ç°¡è¦æ¦è¿°äºä½¿ç¨èå¦ä½èå·¥ä½æµç¨äºåä»¥ç²å¾åºæ¼é£²é£çå¥åº·å»ºè­°åå¤§éé£è­çè©³ç´°é£åæåè³è¨ãç¶å¾ï¼æåæ¢è¨äºåæå°åº¦é£è­è³è¨å¨çµæ§ãå¤èªè¨åä¸ç¢ºå®æ§ç­æ¹é¢çè¤éææ°ï¼ä¸¦å±ç¤ºæåå¨åºæ¼ LLM çè§£æ±ºæ¹æ¡ä¸é²è¡çæçºå·¥ä½ï¼ä»¥è§£æ±ºéäºåé¡ãæ¬æç è¨æè«æä¸­æåºç AI é©åç¥è­ç­å±åè³è¨è§£ææ¹æ³èæç¨ç¨å¼ç¡éï¼å¯æ¦æ¬ä¸å¯è¤è£½å°ä»»ä½é åã

##### **Are Frontier Large Language Models Suitable for Q&A in Science Centres?**
2412.05200v1 by Jacob Watson, FabrÃ­cio GÃ³es, Marco Volpe, Talles Medeiros

This paper investigates the suitability of frontier Large Language Models
(LLMs) for Q&A interactions in science centres, with the aim of boosting
visitor engagement while maintaining factual accuracy. Using a dataset of
questions collected from the National Space Centre in Leicester (UK), we
evaluated responses generated by three leading models: OpenAI's GPT-4, Claude
3.5 Sonnet, and Google Gemini 1.5. Each model was prompted for both standard
and creative responses tailored to an 8-year-old audience, and these responses
were assessed by space science experts based on accuracy, engagement, clarity,
novelty, and deviation from expected answers. The results revealed a trade-off
between creativity and accuracy, with Claude outperforming GPT and Gemini in
both maintaining clarity and engaging young audiences, even when asked to
generate more creative responses. Nonetheless, experts observed that higher
novelty was generally associated with reduced factual reliability across all
models. This study highlights the potential of LLMs in educational settings,
emphasizing the need for careful prompt engineering to balance engagement with
scientific rigor.

æè¦ï¼éç¯è«ææ¢è¨åæ²¿å¤§åèªè¨æ¨¡å (LLM) å¨ç§å­¸ä¸­å¿åç­äºåä¸­çé©ç¨æ§ï¼ç®çæ¯å¨ç¶­æäºå¯¦æºç¢ºæ§çåææåè¨ªå®¢åèåº¦ãæåä½¿ç¨å¾è±åèæ¯ç¹åå®¶å¤ªç©ºä¸­å¿æ¶éçæåè³æéï¼è©ä¼°äºä¸åé åæ¨¡åçæçåæï¼OpenAI ç GPT-4ãClaude 3.5 Sonnet å Google Gemini 1.5ãæ¯åæ¨¡åé½è¢«æç¤ºéå° 8 æ­²çåç¾éèº«æé æ¨æºåæåµæçåæï¼èéäºåæåç±å¤ªç©ºç§å­¸å°å®¶æ ¹ææºç¢ºæ§ãåèåº¦ãæ¸æ°åº¦ãæ°ç©æ§åèé æç­æ¡çåå·®é²è¡è©ä¼°ãçµæé¡¯ç¤ºåµé åèæºç¢ºæ§ä¹éå­å¨æ¬è¡¡ï¼Claude å¨ç¶­ææ¸æ°åº¦åå¸å¼å¹´è¼åç¾æ¹é¢åªæ¼ GPT å Geminiï¼å³ä½¿è¢«è¦æ±ç¢çæ´å¤æåµæçåæãåç®¡å¦æ­¤ï¼å°å®¶åè§å¯å°ï¼æææ¨¡åä¸­è¼é«çæ°ç©æ§éå¸¸èè¼ä½çå¯¦éå¯é æ§ç¸éãéé ç ç©¶å¼·èª¿äº LLM å¨æè²ç°å¢ä¸­çæ½åï¼ä¸¦å¼·èª¿éè¦ä»ç´°æç¤ºå·¥ç¨ä»¥å¹³è¡¡åèåº¦åç§å­¸å´è¬¹æ§ã

##### **SurgBox: Agent-Driven Operating Room Sandbox with Surgery Copilot**
2412.05187v1 by Jinlin Wu, Xusheng Liang, Xuexue Bai, Zhen Chen

Surgical interventions, particularly in neurology, represent complex and
high-stakes scenarios that impose substantial cognitive burdens on surgical
teams. Although deliberate education and practice can enhance cognitive
capabilities, surgical training opportunities remain limited due to patient
safety concerns. To address these cognitive challenges in surgical training and
operation, we propose SurgBox, an agent-driven sandbox framework to
systematically enhance the cognitive capabilities of surgeons in immersive
surgical simulations. Specifically, our SurgBox leverages large language models
(LLMs) with tailored Retrieval-Augmented Generation (RAG) to authentically
replicate various surgical roles, enabling realistic training environments for
deliberate practice. In particular, we devise Surgery Copilot, an AI-driven
assistant to actively coordinate the surgical information stream and support
clinical decision-making, thereby diminishing the cognitive workload of
surgical teams during surgery. By incorporating a novel Long-Short Memory
mechanism, our Surgery Copilot can effectively balance immediate procedural
assistance with comprehensive surgical knowledge. Extensive experiments using
real neurosurgical procedure records validate our SurgBox framework in both
enhancing surgical cognitive capabilities and supporting clinical
decision-making. By providing an integrated solution for training and
operational support to address cognitive challenges, our SurgBox framework
advances surgical education and practice, potentially transforming surgical
outcomes and healthcare quality. The code is available at
https://github.com/franciszchen/SurgBox.

æè¦ï¼å¤ç§æè¡ï¼ç¹å¥æ¯å¨ç¥ç¶å¤ç§ï¼ä»£è¡¨äºè¤éä¸é«é¢¨éªçå ´æ¯ï¼å°å¤ç§åéæ½å äºå·¨å¤§çèªç¥è² æãåç®¡ç¶éæ·±æçæ®çæè²åå¯¦è¸å¯ä»¥å¢å¼·èªç¥è½åï¼ä½ç±æ¼æ£èå®å¨åé¡ï¼å¤ç§å¹è¨æ©æä»ç¶æéãçºäºæå°å¤ç§å¹è¨åæè¡ä¸­çéäºèªç¥ææ°ï¼æåæåºäº SurgBoxï¼ä¸åç±ä»£çé©åçæ²çæ¡æ¶ï¼ç¨æ¼ç³»çµ±å°å¢å¼·å¤ç§é«çå¨æ²æµ¸å¼å¤ç§æ¨¡æ¬ä¸­çèªç¥è½åãå·é«ä¾èªªï¼æåç SurgBox å©ç¨å¤§åèªè¨æ¨¡å (LLM) åéèº«å®å¶çæª¢ç´¢å¢å¼·çæ (RAG) ä¾çå¯¦å°è¤è£½åç¨®å¤ç§è§è²ï¼çºæ·±æçæ®çå¯¦è¸æä¾é¼ççå¹è¨ç°å¢ãç¹å¥æ¯ï¼æåè¨­è¨äºæè¡å¯é§é§ï¼ä¸åç± AI é©åçå©æï¼ç¨æ¼ä¸»ååèª¿å¤ç§ä¿¡æ¯æµä¸¦æ¯æè¨åºæ±ºç­å¶å®ï¼å¾èæ¸å°å¤ç§åéå¨æè¡æéçèªç¥è² æãééçµåä¸ç¨®æ°ç©çé·ç­æè¨æ¶æ©å¶ï¼æåç Surgery Copilot å¯ä»¥ææå°å¹³è¡¡å³æç¨åºåå©åå¨é¢çå¤ç§ç¥è­ãä½¿ç¨çå¯¦çç¥ç¶å¤ç§æè¡è¨éé²è¡çå»£æ³å¯¦é©é©è­äºæåç SurgBox æ¡æ¶ï¼æ¢è½å¢å¼·å¤ç§èªç¥è½åï¼åè½æ¯æè¨åºæ±ºç­å¶å®ãééæä¾ä¸åç¶åçå¹è¨åéçæ¯æè§£æ±ºæ¹æ¡ä¾æå°èªç¥ææ°ï¼æåç SurgBox æ¡æ¶æ¨åäºå¤ç§æè²åå¯¦è¸ï¼æå¯è½æ¹è®å¤ç§çµæåé«çä¿å¥è³ªéãä»£ç¢¼å¯å¨ https://github.com/franciszchen/SurgBox ç²å¾ã

##### **Project Report: Requirements for a Social Robot as an Information Provider in the Public Sector**
2412.05013v1 by Thomas Sievers, Nele Russwinkel

Is it possible to integrate a humanoid social robot into the work processes
or customer care in an official environment, e.g. in municipal offices? If so,
what could such an application scenario look like and what skills would the
robot need to have when interacting with human customers? What are requirements
for this kind of interactions? We have devised an application scenario for such
a case, determined the necessary or desirable capabilities of the robot,
developed a corresponding robot application and carried out initial tests and
evaluations in a project together with the Kiel City Council. One of the most
important insights gained in the project was that a humanoid robot with natural
language processing capabilities based on large language models as well as
human-like gestures and posture changes (animations) proved to be much more
preferred by users compared to standard browser-based solutions on tablets for
an information system in the City Council. Furthermore, we propose a connection
of the ACT-R cognitive architecture with the robot, where an ACT-R model is
used in interaction with the robot application to cognitively process and
enhance a dialogue between human and robot.

æè¦ï¼æ¯å¦å¯è½å°é¡äººç¤¾ææ©å¨äººæ´åå°å·¥ä½æµç¨æå®æ¹ç°å¢ä¸­çå®¢æ¶æåä¸­ï¼ä¾å¦å¸æ¿è¾¦å¬å®¤ï¼å¦ææ¯éæ¨£ï¼éæ¨£çæç¨å ´æ¯å¯è½ææ¯ä»éº¼æ¨£å­ï¼èæ©å¨äººå¨èäººé¡å®¢æ¶äºåæéè¦å·ååªäºæè½ï¼éç¨®äºåæåªäºè¦æ±ï¼æåçºéç¨®ææ³è¨­è¨äºä¸åæç¨å ´æ¯ï¼ç¢ºå®äºæ©å¨äººå¿è¦æçæ³çè½åï¼éç¼äºä¸åå°æçæ©å¨äººæç¨ç¨å¼ï¼ä¸¦èåºç¾å¸è­°æå±åå¨ä¸åå°æ¡ä¸­é²è¡äºåæ­¥æ¸¬è©¦åè©ä¼°ãè©²å°æ¡ç²å¾çæéè¦è¦è§£ä¹ä¸æ¯ï¼èå¹³æ¿é»è¦ä¸ç¨æ¼å¸è­°æè³è¨ç³»çµ±çæ¨æºçè¦½å¨è§£æ±ºæ¹æ¡ç¸æ¯ï¼å·æäººå·¥èªè¨èçè½åï¼åºæ¼å¤§åèªè¨æ¨¡åï¼ä»¥åé¡äººçæå¢åå§¿å¢è®åï¼åç«ï¼çé¡äººæ©å¨äººè¢«ä½¿ç¨èæ´çºéçãæ­¤å¤ï¼æåå»ºè­°å° ACT-R èªç¥æ¶æ§èæ©å¨äººé£æ¥èµ·ä¾ï¼å¶ä¸­ ACT-R æ¨¡åç¨æ¼èæ©å¨äººæç¨ç¨å¼äºåï¼ä»¥èªç¥èçåå¢å¼·äººèæ©å¨äººä¹éçå°è©±ã

##### **Backdooring Outlier Detection Methods: A Novel Attack Approach**
2412.05010v1 by ZeinabSadat Taghavi, Hossein Mirzaei

There have been several efforts in backdoor attacks, but these have primarily
focused on the closed-set performance of classifiers (i.e., classification).
This has left a gap in addressing the threat to classifiers' open-set
performance, referred to as outlier detection in the literature. Reliable
outlier detection is crucial for deploying classifiers in critical real-world
applications such as autonomous driving and medical image analysis. First, we
show that existing backdoor attacks fall short in affecting the open-set
performance of classifiers, as they have been specifically designed to confuse
intra-closed-set decision boundaries. In contrast, an effective backdoor attack
for outlier detection needs to confuse the decision boundary between the closed
and open sets. Motivated by this, in this study, we propose BATOD, a novel
Backdoor Attack targeting the Outlier Detection task. Specifically, we design
two categories of triggers to shift inlier samples to outliers and vice versa.
We evaluate BATOD using various real-world datasets and demonstrate its
superior ability to degrade the open-set performance of classifiers compared to
previous attacks, both before and after applying defenses.

æè¦ï¼å°æ¼å¾éæ»æå·²ç¶æå¹¾é åªåï¼ä½éäºä¸»è¦éä¸­å¨åé¡å¨çééæè½ï¼å³åé¡ï¼ä¸ãéä½¿å¾å¨èçåé¡å¨éæ¾éæè½çå¨èä¸åºç¾äºä¸åç¼ºå£ï¼å¨æç»ä¸­ç¨±çºç°å¸¸å¼åµæ¸¬ãå¯é çç°å¸¸å¼åµæ¸¬å°æ¼å¨ééµççå¯¦ä¸çæç¨ä¸­é¨ç½²åé¡å¨è³ééè¦ï¼ä¾å¦èªåé§é§åé«å­¸å½±ååæãé¦åï¼æåå±ç¤ºç¾æçå¾éæ»æå¨å½±é¿åé¡å¨çéæ¾éæè½æ¹é¢ä¸è¶³ï¼å çºå®åè¢«ç¹å¥è¨­è¨ç¨ä¾æ··æ·ééå§æ±ºç­éçãç¸æ¯ä¹ä¸ï¼ææçç°å¸¸å¼åµæ¸¬å¾éæ»æéè¦æ··æ·ééåéæ¾éä¹éçæ±ºç­éçãæéæ¼æ­¤ï¼å¨æ¬ç ç©¶ä¸­ï¼æåæåº BATODï¼ä¸ç¨®éå°ç°å¸¸å¼åµæ¸¬ä»»åçæ°åå¾éæ»æãå·é«ä¾èªªï¼æåè¨­è¨äºå©ç¨®é¡åçè§¸ç¼å¨ï¼å°å§é»æ¨£æ¬è½ç§»å°ç°å¸¸å¼ï¼åä¹äº¦ç¶ãæåä½¿ç¨åç¨®çå¯¦ä¸çè³æéè©ä¼° BATODï¼ä¸¦å±ç¤ºäºå®å¨éä½åé¡å¨çéæ¾éæè½æ¹é¢çåªç°è½åï¼èä¹åå¨æç¨é²ç¦¦æªæ½ä¹ååä¹å¾çæ»æç¸æ¯ã

##### **Bed-Attached Vibration Sensor System: A Machine Learning Approach for Fall Detection in Nursing Homes**
2412.04950v1 by Thomas Bartz-Beielstein, Axel Wellendorf, Noah PÃ¼tz, Jens Brandt, Alexander Hinterleitner, Richard Schulz, Richard Scholz, Olaf Mersmann, Robin Knabe

The increasing shortage of nursing staff and the acute risk of falls in
nursing homes pose significant challenges for the healthcare system. This study
presents the development of an automated fall detection system integrated into
care beds, aimed at enhancing patient safety without compromising privacy
through wearables or video monitoring. Mechanical vibrations transmitted
through the bed frame are processed using a short-time Fourier transform,
enabling robust classification of distinct human fall patterns with a
convolutional neural network. Challenges pertaining to the quantity and
diversity of the data are addressed, proposing the generation of additional
data with a specific emphasis on enhancing variation. While the model shows
promising results in distinguishing fall events from noise using lab data,
further testing in real-world environments is recommended for validation and
improvement. Despite limited available data, the proposed system shows the
potential for an accurate and rapid response to falls, mitigating health
implications, and addressing the needs of an aging population. This case study
was performed as part of the ZIM Project. Further research on sensors enhanced
by artificial intelligence will be continued in the ShapeFuture Project.

æè¦ï¼è­·çäººå¡æ¥çç­ç¼ºï¼ä¸è­·çä¹å®¶ç¼çè·åçé¢¨éªæ¥µé«ï¼å°é«çä¿å¥ç³»çµ±æ§æéå¤§ææ°ãæ¬ç ç©¶æåºå°èªååè·ååµæ¸¬ç³»çµ±æ´åè³è­·çåºï¼æ¨å¨æåçæ£å®å¨ï¼åæééç©¿æ´å¼è£ç½®æè¦è¨ç£æ§ä¾ä¿è­·é±ç§ãééåºæ¶å³éçæ©æ¢°æ¯åæä½¿ç¨ç­æè·åç«èè½æé²è¡èçï¼ä¸¦è½å©ç¨å·ç©ç¥ç¶ç¶²è·¯å°ä¸åäººé¡è·åæ¨¡å¼é²è¡ç©©å¥åé¡ãéå°è³ææ¸éåå¤æ¨£æ§çææ°ï¼æåºç¢çé¡å¤è³æçå»ºè­°ï¼ç¹å¥èéæ¼å¢å è®åæ§ãéç¶æ­¤æ¨¡åå¨ä½¿ç¨å¯¦é©å®¤è³æååè·åäºä»¶åéè¨æé¡¯ç¤ºåºæå¸æççµæï¼ä½å»ºè­°å¨çå¯¦ç°å¢ä¸­é²ä¸æ­¥æ¸¬è©¦ä»¥é²è¡é©è­åæ¹é²ãåç®¡å¯ç¨è³ææéï¼ä½ææåºçç³»çµ±é¡¯ç¤ºåºå°è·åäºä»¶ååºæºç¢ºä¸å¿«éçåæçæ½åï¼æ¸è¼å¥åº·å½±é¿ï¼ä¸¦æ»¿è¶³èé½¡åäººå£çéæ±ãæ­¤æ¡ä¾ç ç©¶æ¯ä½çº ZIM å°æ¡çä¸é¨åé²è¡çãShapeFuture å°æ¡å°æçºé²è¡äººå·¥æºæ§å¢å¼·ææ¸¬å¨çé²ä¸æ­¥ç ç©¶ã

##### **Estimating the treatment effect over time under general interference through deep learner integrated TMLE**
2412.04799v1 by Suhan Guo, Furao Shen, Ni Li

Understanding the effects of quarantine policies in populations with
underlying social networks is crucial for public health, yet most causal
inference methods fail here due to their assumption of independent individuals.
We introduce DeepNetTMLE, a deep-learning-enhanced Targeted Maximum Likelihood
Estimation (TMLE) method designed to estimate time-sensitive treatment effects
in observational data. DeepNetTMLE mitigates bias from time-varying confounders
under general interference by incorporating a temporal module and domain
adversarial training to build intervention-invariant representations. This
process removes associations between current treatments and historical
variables, while the targeting step maintains the bias-variance trade-off,
enhancing the reliability of counterfactual predictions. Using simulations of a
``Susceptible-Infected-Recovered'' model with varied quarantine coverages, we
show that DeepNetTMLE achieves lower bias and more precise confidence intervals
in counterfactual estimates, enabling optimal quarantine recommendations within
budget constraints, surpassing state-of-the-art methods.

æè¦ï¼äºè§£å·ææ½å¨ç¤¾äº¤ç¶²çµ¡çäººç¾¤ä¸­éé¢æ¿ç­çå½±é¿å°æ¼å¬å±è¡çè³ééè¦ï¼ä½ç±æ¼åè¨­åäººç¨ç«ï¼å¤§å¤æ¸å ææ¨è«æ¹æ³å¨æ­¤èå¤±æãæåå¼å¥äº DeepNetTMLEï¼éæ¯ä¸ç¨®æ·±åº¦å­¸ç¿å¢å¼·çç®æ¨æå¤§ä¼¼ç¶ä¼°è¨ (TMLE) æ¹æ³ï¼æ¨å¨ä¼°è¨è§æ¸¬æ¸æä¸­çæéææèçææãDeepNetTMLE ééæ´åæéæ¨¡çµåé åå°æè¨ç·´ä¾å»ºç«ä»å¥ä¸è®è¡¨ç¤ºï¼å¾èæ¸è¼ä¸è¬å¹²æ¾ä¸æè®æ··éå ç´ çåå·®ãæ­¤éç¨æ¶é¤äºç¶åèçèæ­·å²è®æ¸ä¹éçéè¯ï¼èç®æ¨è¨­å®æ­¥é©åç¶­æåå·®è®ç°æ¬è¡¡ï¼å¢å¼·åäºå¯¦é æ¸¬çå¯é æ§ãä½¿ç¨å·æä¸åéé¢è¦èççãææè-ææè-åº·å¾©èãæ¨¡åçæ¨¡æ¬ï¼æåè¡¨æ DeepNetTMLE å¨åäºå¯¦ä¼°è¨ä¸­å¯¦ç¾äºè¼ä½çåå·®åæ´ç²¾ç¢ºçä¿¡å¿åéï¼å¾èå¨é ç®éå¶å§å¯¦ç¾äºæä½³éé¢å»ºè­°ï¼è¶è¶äºæåé²çæ¹æ³ã

##### **Multi-class heart disease Detection, Classification, and Prediction using Machine Learning Models**
2412.04792v1 by Mahfuzul Haque, Abu Saleh Musa Miah, Debashish Gupta, Md. Maruf Al Hossain Prince, Tanzina Alam, Nusrat Sharmin, Mohammed Sowket Ali, Jungpil Shin

Heart disease is a leading cause of premature death worldwide, particularly
among middle-aged and older adults, with men experiencing a higher prevalence.
According to the World Health Organization (WHO), non-communicable diseases,
including heart disease, account for 25\% (17.9 million) of global deaths, with
over 43,204 annual fatalities in Bangladesh. However, the development of heart
disease detection (HDD) systems tailored to the Bangladeshi population remains
underexplored due to the lack of benchmark datasets and reliance on manual or
limited-data approaches. This study addresses these challenges by introducing
new, ethically sourced HDD dataset, BIG-Dataset and CD dataset which
incorporates comprehensive data on symptoms, examination techniques, and risk
factors. Using advanced machine learning techniques, including Logistic
Regression and Random Forest, we achieved a remarkable testing accuracy of up
to 96.6\% with Random Forest. The proposed AI-driven system integrates these
models and datasets to provide real-time, accurate diagnostics and personalized
healthcare recommendations. By leveraging structured datasets and
state-of-the-art machine learning algorithms, this research offers an
innovative solution for scalable and effective heart disease detection, with
the potential to reduce mortality rates and improve clinical outcomes.

æè¦ï¼<paragraph>å¿èçæ¯å¨çéæ©æ­»äº¡çä¸»å ï¼ç¹å¥æ¯å¨ä¸­å¹´åèå¹´äººä¸­ï¼ç·æ§ç¼ççè¼é«ãæ ¹æä¸çè¡ççµç¹ (WHO) çæ¸æï¼åæ¬å¿èçå¨å§çéå³ææ§ç¾çå å¨çæ­»äº¡äººæ¸ç 25%ï¼1790 è¬ï¼ï¼å­å æåæ¯å¹´æè¶é 43,204 äººæ­»æ¼å¿èçãç¶èï¼ç±æ¼ç¼ºä¹åºæºæ¸æéåä¾è³´æåææ¸ææéçæ¹æ³ï¼éå°å­å æåäººå£éèº«æé çå¿èçæª¢æ¸¬ (HDD) ç³»çµ±çéç¼ä»æªå¾å°ååæ¢ç´¢ãæ¬ç ç©¶ééå¼å¥æ°çãç¬¦åéå¾·æ¨æºç HDD æ¸æéãBIG æ¸æéå CD æ¸æéä¾æå°éäºææ°ï¼å¶ä¸­åå«æéççãæª¢æ¥æè¡åé¢¨éªå ç´ çå¨é¢æ¸æãä½¿ç¨åé²çæ©å¨å­¸ç¿æè¡ï¼åæ¬éè¼¯è¿´æ­¸åé¨æ©æ£®æï¼æåä½¿ç¨é¨æ©æ£®æå¯¦ç¾äºé«é 96.6% çé¡¯èæ¸¬è©¦æºç¢ºåº¦ãææåºç AI é©åç³»çµ±æ´åäºéäºæ¨¡ååæ¸æéï¼ä»¥æä¾å¯¦æçæºç¢ºè¨ºæ·ååæ§åçé«çä¿å¥å»ºè­°ãééå©ç¨çµæ§åæ¸æéåæåé²çæ©å¨å­¸ç¿ç®æ³ï¼æ¬ç ç©¶çºå¯æ´å±ä¸ææçå¿èçæª¢æ¸¬æä¾äºä¸ååµæ°çè§£æ±ºæ¹æ¡ï¼å·æéä½æ­»äº¡çåæ¹åè¨åºçµæçæ½åã</paragraph>

##### **DAWN-SI: Data-Aware and Noise-Informed Stochastic Interpolation for Solving Inverse Problems**
2412.04766v1 by Shadab Ahamed, Eldad Haber

Inverse problems, which involve estimating parameters from incomplete or
noisy observations, arise in various fields such as medical imaging,
geophysics, and signal processing. These problems are often ill-posed,
requiring regularization techniques to stabilize the solution. In this work, we
employ $\textit{Stochastic Interpolation}$ (SI), a generative framework that
integrates both deterministic and stochastic processes to map a simple
reference distribution, such as a Gaussian, to the target distribution. Our
method $\textbf{DAWN-SI}$: $\textbf{D}$ata-$\textbf{AW}$are and
$\textbf{N}$oise-informed $\textbf{S}$tochastic $\textbf{I}$nterpolation
incorporates data and noise embedding, allowing the model to access
representations about the measured data explicitly and also account for noise
in the observations, making it particularly robust in scenarios where data is
noisy or incomplete. By learning a time-dependent velocity field, SI not only
provides accurate solutions but also enables uncertainty quantification by
generating multiple plausible outcomes. Unlike pre-trained diffusion models,
which may struggle in highly ill-posed settings, our approach is trained
specifically for each inverse problem and adapts to varying noise levels. We
validate the effectiveness and robustness of our method through extensive
numerical experiments on tasks such as image deblurring and tomography.

æè¦ï¼ååé¡æ¶åå¾ä¸å®æ´ææéè¨çè§æ¸¬ä¸­ä¼°è¨åæ¸ï¼åºç¾å¨åç¨®é åï¼ä¾å¦é«å­¸å½±åãå°çç©çåè¨èèçãéäºåé¡éå¸¸æ¯ä¸é©å®çï¼éè¦æ­£ååæè¡ä¾ç©©å®è§£ãå¨éé å·¥ä½ä¸­ï¼æåæ¡ç¨é¨æ©æå¼ (SI)ï¼ä¸ç¨®çæå¼æ¶æ§ï¼æ´åç¢ºå®æ§åé¨æ©éç¨ï¼å°ç°¡å®çåèåä½ï¼ä¾å¦é«æ¯åä½ï¼å°æå°ç®æ¨åä½ãæåç DAWS-SI æ¹æ³ï¼è³ææç¥åéè¨ç¥æçé¨æ©æå¼ï¼çµåè³æåéè¨åµå¥ï¼è®æ¨¡åè½å¤ æç¢ºå­åéæ¼æ¸¬éè³æçè¡¨ç¤ºï¼ä¸¦èéè§æ¸¬ä¸­çéè¨ï¼ä½¿å¶å¨è³ææéè¨æä¸å®æ´çææ³ä¸ç¹å¥ç©©å¥ãééå­¸ç¿èæéç¸éçéåº¦å ´ï¼SI ä¸åæä¾ç²¾ç¢ºçè§£ï¼éè½ééç¢çå¤ååçççµæä¾éåä¸ç¢ºå®æ§ãèé åè¨ç·´çæ´æ£æ¨¡åä¸åï¼å¾èå¨é«åº¦ä¸é©å®çè¨­å®ä¸­å¯è½æéå°å°é£ï¼æåçåæ³æ¯éå°æ¯åååé¡é²è¡è¨ç·´ï¼ä¸¦é©æä¸åçéè¨ç­ç´ãæåééå»£æ³çæ¸å¼å¯¦é©é©è­äºæåæ¹æ³çæææ§åç©©å¥æ§ï¼éäºä»»ååæ¬å½±åå»æ¨¡ç³åæ·å±¤ææã

##### **PCTreeS: 3D Point Cloud Tree Species Classification Using Airborne LiDAR Images**
2412.04714v1 by Hongjin Lin, Matthew Nazari, Derek Zheng

Reliable large-scale data on the state of forests is crucial for monitoring
ecosystem health, carbon stock, and the impact of climate change. Current
knowledge of tree species distribution relies heavily on manual data collection
in the field, which often takes years to complete, resulting in limited
datasets that cover only a small subset of the world's forests. Recent works
show that state-of-the-art deep learning models using Light Detection and
Ranging (LiDAR) images enable accurate and scalable classification of tree
species in various ecosystems. While LiDAR images contain rich 3D information,
most previous works flatten the 3D images into 2D projections to use
Convolutional Neural Networks (CNNs). This paper offers three significant
contributions: (1) we apply the deep learning framework for tree classification
in tropical savannas; (2) we use Airborne LiDAR images, which have a lower
resolution but greater scalability than Terrestrial LiDAR images used in most
previous works; (3) we introduce the approach of directly feeding 3D point
cloud images into a vision transformer model (PCTreeS). Our results show that
the PCTreeS approach outperforms current CNN baselines with 2D projections in
AUC (0.81), overall accuracy (0.72), and training time (~45 mins). This paper
also motivates further LiDAR image collection and validation for accurate
large-scale automatic classification of tree species.

æè¦ï¼å¯é çå¤§è¦æ¨¡æ£®æçæè³æå°æ¼ç£æ¸¬çæç³»çµ±å¥åº·ãç¢³å²éåæ°£åè®é·çå½±é¿è³ééè¦ãç®åå°æ¨¹ç¨®åå¸çäºè§£æ¥µåº¦ä¾è³´æ¼å¯¦å°æåæ¶éè³æï¼ééå¸¸éè¦è±è²»æ¸å¹´æè½å®æï¼å°è´åªè½æ¶µèå¨çå°æ¸æ£®æçæéè³æéãæè¿çç ç©¶é¡¯ç¤ºï¼ä½¿ç¨åæ¢æ¸¬åæ¸¬è· (LiDAR) å½±åçææ°æ·±åº¦å­¸ç¿æ¨¡åï¼å¯ä»¥å¨åç¨®çæç³»çµ±ä¸­å°æ¨¹ç¨®é²è¡æºç¢ºä¸å¯æ´åçåé¡ãåç®¡ LiDAR å½±ååå«è±å¯ç 3D è³è¨ï¼ä½å¤§å¤æ¸ååçç ç©¶æå° 3D å½±åå£ç¸®æ 2D æå½±ï¼ä»¥ä½¿ç¨å·ç©ç¥ç¶ç¶²è·¯ (CNN)ãæ¬ææä¾äºä¸é éè¦çè²¢ç»ï¼(1) æåå°æ·±åº¦å­¸ç¿æ¶æ§æç¨æ¼ç±å¸¶ç¨æ¨¹èåçæ¨¹ç¨®åé¡ï¼(2) æåä½¿ç¨æ©è¼ LiDAR å½±åï¼å¶è§£æåº¦è¼ä½ï¼ä½å¯æ´åæ§æ¯å¤§å¤æ¸ååç ç©¶ä¸­ä½¿ç¨çå°é¢ LiDAR å½±åæ´é«ï¼(3) æåå¼å¥äºç´æ¥å° 3D é»é²å½±åè¼¸å¥å°è¦è¦ºTransformeræ¨¡å (PCTreeS) çæ¹æ³ãæåççµæé¡¯ç¤ºï¼PCTreeS æ¹æ³å¨ AUC (0.81)ãæ´é«æºç¢ºåº¦ (0.72) åè¨ç·´æé (~45 åé) æ¹é¢åªæ¼ç¶åä½¿ç¨ 2D æå½±ç CNN åºæºãæ¬æä¹æ¿åµé²ä¸æ­¥æ¶éåé©è­ LiDAR å½±åï¼ä»¥é²è¡æºç¢ºçå¤§è¦æ¨¡æ¨¹ç¨®èªååé¡ã

##### **Semantic Consistency-Based Uncertainty Quantification for Factuality in Radiology Report Generation**
2412.04606v1 by Chenyu Wang, Weichao Zhou, Shantanu Ghosh, Kayhan Batmanghelich, Wenchao Li

Radiology report generation (RRG) has shown great potential in assisting
radiologists by automating the labor-intensive task of report writing. While
recent advancements have improved the quality and coherence of generated
reports, ensuring their factual correctness remains a critical challenge.
Although generative medical Vision Large Language Models (VLLMs) have been
proposed to address this issue, these models are prone to hallucinations and
can produce inaccurate diagnostic information. To address these concerns, we
introduce a novel Semantic Consistency-Based Uncertainty Quantification
framework that provides both report-level and sentence-level uncertainties.
Unlike existing approaches, our method does not require modifications to the
underlying model or access to its inner state, such as output token logits,
thus serving as a plug-and-play module that can be seamlessly integrated with
state-of-the-art models. Extensive experiments demonstrate the efficacy of our
method in detecting hallucinations and enhancing the factual accuracy of
automatically generated radiology reports. By abstaining from high-uncertainty
reports, our approach improves factuality scores by $10$%, achieved by
rejecting $20$% of reports using the Radialog model on the MIMIC-CXR dataset.
Furthermore, sentence-level uncertainty flags the lowest-precision sentence in
each report with an $82.9$% success rate.

æè¦ï¼æ¾å°ç§æ¥åçæ (RRG) å·²æ¾ç¤ºåºæå¤§çæ½åï¼å¯éè¿èªå¨æ§è¡æ¥åç¼åçå³å¨å¯éåä»»å¡æ¥åå©æ¾å°ç§å»çãè½ç¶æè¿çè¿æ­¥æé«äºçææ¥åçè´¨éåè¿è´¯æ§ï¼ä½ç¡®ä¿å¶äºå®æ­£ç¡®æ§ä»ç¶æ¯ä¸é¡¹éå¤§ææãå°½ç®¡å·²æåºçææ§å»å­¦è§è§å¤§è¯­è¨æ¨¡å (VLLM) æ¥è§£å³æ­¤é®é¢ï¼ä½è¿äºæ¨¡åå®¹æåºç°å¹»è§å¹¶å¯è½äº§çä¸åç¡®çè¯æ­ä¿¡æ¯ãä¸ºäºè§£å³è¿äºé®é¢ï¼æä»¬å¼å¥äºä¸ä¸ªæ°é¢çåºäºè¯­ä¹ä¸è´æ§çä¸ç¡®å®æ§éåæ¡æ¶ï¼è¯¥æ¡æ¶æä¾æ¥åçº§åå¥å­çº§çä¸ç¡®å®æ§ãä¸ç°ææ¹æ³ä¸åï¼æä»¬çæ¹æ³ä¸éè¦ä¿®æ¹åºå±æ¨¡åæè®¿é®å¶åé¨ç¶æï¼ä¾å¦è¾åºæ è®° logitï¼ï¼å æ­¤å¯ç¨ä½å³æå³ç¨æ¨¡åï¼å¯ä»¥ä¸æåè¿çæ¨¡åæ ç¼éæãå¹¿æ³çå®éªè¡¨æäºæä»¬çæ¹æ³å¨æ£æµå¹»è§åæé«èªå¨çæçæ¾å°ç§æ¥åçäºå®åç¡®æ§æ¹é¢çåæãéè¿é¿åé«åº¦ä¸ç¡®å®çæ¥åï¼æä»¬çæ¹æ³å°çå®æ§å¾åæé«äº 10%ï¼è¿æ¯éè¿ä½¿ç¨ MIMIC-CXR æ°æ®éä¸ç Radialog æ¨¡åæç» 20% çæ¥åå®ç°çãæ­¤å¤ï¼å¥å­çº§ä¸ç¡®å®æ§æ è®°äºæ¯ä»½æ¥åä¸­ç²¾åº¦æä½çå¥å­ï¼æåçä¸º 82.9%ã

##### **CLINICSUM: Utilizing Language Models for Generating Clinical Summaries from Patient-Doctor Conversations**
2412.04254v1 by Subash Neupane, Himanshu Tripathi, Shaswata Mitra, Sean Bozorgzad, Sudip Mittal, Shahram Rahimi, Amin Amirlatifi

This paper presents ClinicSum, a novel framework designed to automatically
generate clinical summaries from patient-doctor conversations. It utilizes a
two-module architecture: a retrieval-based filtering module that extracts
Subjective, Objective, Assessment, and Plan (SOAP) information from
conversation transcripts, and an inference module powered by fine-tuned
Pre-trained Language Models (PLMs), which leverage the extracted SOAP data to
generate abstracted clinical summaries. To fine-tune the PLM, we created a
training dataset of consisting 1,473 conversations-summaries pair by
consolidating two publicly available datasets, FigShare and MTS-Dialog, with
ground truth summaries validated by Subject Matter Experts (SMEs). ClinicSum's
effectiveness is evaluated through both automatic metrics (e.g., ROUGE,
BERTScore) and expert human assessments. Results show that ClinicSum
outperforms state-of-the-art PLMs, demonstrating superior precision, recall,
and F-1 scores in automatic evaluations and receiving high preference from SMEs
in human assessment, making it a robust solution for automated clinical
summarization.

æè¦ï¼æ¬æä»ç´¹ ClinicSumï¼éæ¯ä¸åæ°ç©çæ¶æ§ï¼æ¨å¨èªåå¾çæ£èé«å¸«çå°è©±ä¸­ç¢çè¨åºæè¦ãå®å©ç¨ä¸åéæ¨¡çµæ¶æ§ï¼ä¸ååºæ¼æª¢ç´¢çéæ¿¾æ¨¡çµï¼å¾å°è©±è½éä¸­èåä¸»è§ãå®¢è§ãè©ä¼°åè¨ç« (SOAP) è³è¨ï¼ä»¥åä¸åç±å¾®èª¿éä¹é åè¨ç·´èªè¨æ¨¡å (PLM) æä¾ååçæ¨è«æ¨¡çµï¼å®å©ç¨èåç SOAP è³æç¢çæè¦çè¨åºæè¦ãçºäºå¾®èª¿ PLMï¼æåå»ºç«äºä¸åè¨ç·´è³æéï¼å¶ä¸­åå« 1,473 çµå°è©±æè¦ï¼ééåä½µå©åå¬éå¯ç¨çè³æé FigShare å MTS-Dialogï¼ä»¥åç±ä¸»é¡å°å®¶ (SME) é©è­ççå¯¦æè¦ãClinicSum çæè½ééèªåè©éææ¨ (ä¾å¦ ROUGEãBERTScore) åå°å®¶äººé¡è©ä¼°é²è¡è©éãçµæé¡¯ç¤º ClinicSum åéç¾ææåé²ç PLMï¼å¨èªåè©éä¸­å±ç¾åºåªç°çç²¾ç¢ºåº¦ãå¬åçå F-1 åæ¸ï¼ä¸¦å¨äººé¡è©ä¼°ä¸­ç²å¾ SME çé«åº¦åå¥½ï¼ä½¿å¶æçºèªåè¨åºæè¦çå¼·å¥è§£æ±ºæ¹æ¡ã

##### **Automated Medical Report Generation for ECG Data: Bridging Medical Text and Signal Processing with Deep Learning**
2412.04067v1 by Amnon Bleich, Antje Linnemann, Bjoern H. Diem, Tim OF Conrad

Recent advances in deep learning and natural language generation have
significantly improved image captioning, enabling automated, human-like
descriptions for visual content. In this work, we apply these captioning
techniques to generate clinician-like interpretations of ECG data. This study
leverages existing ECG datasets accompanied by free-text reports authored by
healthcare professionals (HCPs) as training data. These reports, while often
inconsistent, provide a valuable foundation for automated learning. We
introduce an encoder-decoder-based method that uses these reports to train
models to generate detailed descriptions of ECG episodes. This represents a
significant advancement in ECG analysis automation, with potential applications
in zero-shot classification and automated clinical decision support.
  The model is tested on various datasets, including both 1- and 12-lead ECGs.
It significantly outperforms the state-of-the-art reference model by Qiu et
al., achieving a METEOR score of 55.53% compared to 24.51% achieved by the
reference model. Furthermore, several key design choices are discussed,
providing a comprehensive overview of current challenges and innovations in
this domain.
  The source codes for this research are publicly available in our Git
repository https://git.zib.de/ableich/ecg-comment-generation-public

æè¦ï¼æ·±åº¦å­¸ç¿åèªç¶èªè¨çææè¡çææ°é²å±é¡¯èæ¹åäºå½±åæ¨é¡ï¼è½çºè¦è¦ºå§å®¹æä¾èªååçäººé¡èªè¨æè¿°ãå¨éé å·¥ä½ä¸­ï¼æåå°éäºæ¨é¡æè¡æç¨æ¼ç¢çé¡ä¼¼è¨åºé«å¸«å°å¿é»åè³æçè©®éãéé ç ç©¶å©ç¨æ¢æçå¿é»åè³æéï¼ä¸¦éä¸ç±é«çä¿å¥å°æ¥­äººå¡ (HCP) æ°å¯«çèªç±æå­å ±åä½çºè¨ç·´è³æãéäºå ±åéç¶å¸¸å¸¸ä¸ä¸è´ï¼ä½çºèªååå­¸ç¿æä¾äºæå¹å¼çåºç¤ãæåå¼å¥äºä¸åç·¨ç¢¼å¨-è§£ç¢¼å¨æ¹æ³ï¼ä½¿ç¨éäºå ±åä¾è¨ç·´æ¨¡åï¼ä»¥ç¢çå¿é»åäºä»¶çè©³ç´°æè¿°ãéä»£è¡¨å¿é»ååæèªååçéå¤§é²å±ï¼å¨é¶æ¬¡å­¸ç¿åé¡åèªååè¨åºæ±ºç­æ¯æ´ä¸­å·ææ½å¨æç¨ãæ­¤æ¨¡åå¨åç¨®è³æéä¸é²è¡æ¸¬è©¦ï¼åæ¬ 1 å°ç¨å 12 å°ç¨å¿é»åãå®æé¡¯åªæ¼é±ç­äººçç¾ææä½³åèæ¨¡åï¼èåèæ¨¡åéæç 24.51% ç¸æ¯ï¼éå°äº 55.53% ç METEOR åæ¸ãæ­¤å¤ï¼è¨è«äºå¹¾åééµçè¨­è¨é¸æï¼æä¾äºå°éåé åä¸­ç¶åææ°ååµæ°çå¨é¢æ¦è¿°ãæ­¤ç ç©¶çåå§ç¨å¼ç¢¼å¨æåç Git å²å­åº« https://git.zib.de/ableich/ecg-comment-generation-public ä¸­å¬éã

##### **FedMetaMed: Federated Meta-Learning for Personalized Medication in Distributed Healthcare Systems**
2412.03851v1 by Jiechao Gao, Yuangang Li

Personalized medication aims to tailor healthcare to individual patient
characteristics. However, the heterogeneity of patient data across healthcare
systems presents significant challenges to achieving accurate and effective
personalized treatments. Ethical concerns further complicate the aggregation of
large volumes of data from diverse institutions. Federated Learning (FL) offers
a promising decentralized solution by enabling collaborative model training
through the exchange of client models rather than raw data, thus preserving
privacy. However, existing FL methods often suffer from retrogression during
server aggregation, leading to a decline in model performance in real-world
medical FL settings. To address data variability in distributed healthcare
systems, we introduce Federated Meta-Learning for Personalized Medication
(FedMetaMed), which combines federated learning and meta-learning to create
models that adapt to diverse patient data across healthcare systems. The
FedMetaMed framework aims to produce superior personalized models for
individual clients by addressing these limitations. Specifically, we introduce
Cumulative Fourier Aggregation (CFA) at the server to improve stability and
effectiveness in global knowledge aggregation. CFA achieves this by gradually
integrating client models from low to high frequencies. At the client level, we
implement a Collaborative Transfer Optimization (CTO) strategy with a
three-step process - Retrieve, Reciprocate, and Refine - to enhance the
personalized local model through seamless global knowledge transfer.
Experiments on real-world medical imaging datasets demonstrate that FedMetaMed
outperforms state-of-the-art FL methods, showing superior generalization even
on out-of-distribution cohorts.

æè¦ï¼åäººåé«çæ¨å¨éå°åå¥æ£èç¹å¾µèª¿æ´é«çä¿å¥ãç¶èï¼é«çç³»çµ±ä¸­æ£èè³æçç°è³ªæ§å°éææºç¢ºä¸ææçåäººåæ²»çå¸¶ä¾éå¤§ææ°ãå«çåé¡é²ä¸æ­¥ä½¿ä¾èªä¸åæ©æ§çå¤§éè³æçå½ç¸½è¤éåãè¯é¦å­¸ç¿ (FL) æä¾äºä¸ç¨®æåæ¯çåæ£å¼è§£æ±ºæ¹æ¡ï¼ééäº¤æå®¢æ¶æ¨¡åèéåå§è³æä¾å¯¦ç¾åä½æ¨¡åè¨ç·´ï¼å¾èä¿è­·é±ç§ãç¶èï¼ç¾æç FL æ¹æ³å¨ä¼ºæå¨å½ç¸½æéç¶å¸¸é­åéåï¼å°è´å¯¦éé«ç FL è¨­å®ä¸­çæ¨¡åæè½ä¸éãçºäºè§£æ±ºåæ£å¼é«çç³»çµ±ä¸­çè³æè®ç°æ§ï¼æåå¼å¥äºåäººåè¥ç©è¯é¦åå­¸ç¿ (FedMetaMed)ï¼å®çµåäºè¯é¦å­¸ç¿ååå­¸ç¿ä¾å»ºç«æ¨¡åï¼ä»¥é©æé«çç³»çµ±ä¸­ä¸åçæ£èè³æãFedMetaMed æ¡æ¶æ¨å¨ééè§£æ±ºéäºéå¶ï¼çºåå¥å®¢æ¶ç¢çåªè¶çåäººåæ¨¡åãå·é«ä¾èªªï¼æåå¨ä¼ºæå¨ç«¯å¼å¥äºç´¯ç©åç«èå½ç¸½ (CFA)ï¼ä»¥æ¹åå¨çç¥è­å½ç¸½çç©©å®æ§åæææ§ãCFA éééæ­¥æ´åå¾ä½é »çå°é«é »ççå®¢æ¶æ¨¡åä¾å¯¦ç¾éä¸é»ãå¨å®¢æ¶ç«¯å±¤ç´ï¼æåå¯¦æ½äºä¸ç¨®åä½å³è¼¸æä½³å (CTO) ç­ç¥ï¼æ¡ç¨ä¸æ­¥é©æµç¨ - æ·åãåé¥åç²¾ç - ééç¡ç¸«çå¨çç¥è­å³è¼¸ä¾å¢å¼·åäººåæ¬å°æ¨¡åãå¨å¯¦éé«çå½±åè³æéä¸çå¯¦é©è¡¨æï¼FedMetaMed åªæ¼æåé²ç FL æ¹æ³ï¼å³ä½¿å¨éåä½ç¾¤çµä¸­ä¹å±ç¾åºåªè¶çæ³åæ§ã

##### **ELEMENT: Episodic and Lifelong Exploration via Maximum Entropy**
2412.03800v1 by Hongming Li, Shujian Yu, Bin Liu, Jose C. Principe

This paper proposes \emph{Episodic and Lifelong Exploration via Maximum
ENTropy} (ELEMENT), a novel, multiscale, intrinsically motivated reinforcement
learning (RL) framework that is able to explore environments without using any
extrinsic reward and transfer effectively the learned skills to downstream
tasks. We advance the state of the art in three ways. First, we propose a
multiscale entropy optimization to take care of the fact that previous maximum
state entropy, for lifelong exploration with millions of state observations,
suffers from vanishing rewards and becomes very expensive computationally
across iterations. Therefore, we add an episodic maximum entropy over each
episode to speedup the search further. Second, we propose a novel intrinsic
reward for episodic entropy maximization named \emph{average episodic state
entropy} which provides the optimal solution for a theoretical upper bound of
the episodic state entropy objective. Third, to speed the lifelong entropy
maximization, we propose a $k$ nearest neighbors ($k$NN) graph to organize the
estimation of the entropy and updating processes that reduces the computation
substantially. Our ELEMENT significantly outperforms state-of-the-art intrinsic
rewards in both episodic and lifelong setups. Moreover, it can be exploited in
task-agnostic pre-training, collecting data for offline reinforcement learning,
etc.

æè¦ï¼æ¬ææåºäºä¸ç§æ°é¢çå¤å°ºåº¦ãåå¨å¨æºå¼ºåå­¦ä¹  (RL) æ¡æ¶ï¼åä¸ºâéè¿æå¤§çµè¿è¡ææ¯åç»èº«æ¢ç´¢â(ELEMENT)ï¼è¯¥æ¡æ¶è½å¤å¨ä¸ä½¿ç¨ä»»ä½å¤å¨å¥å±çæåµä¸æ¢ç´¢ç¯å¢ï¼å¹¶ææå°å°æå­¦æè½è½¬ç§»å°ä¸æ¸¸ä»»å¡ä¸­ãæä»¬å¨ä¸ä¸ªæ¹é¢æåäºææ¯æ°´å¹³ãé¦åï¼æä»¬æåºäºå¤å°ºåº¦çµä¼åï¼ä»¥è§£å³ä»¥ä¸äºå®ï¼ååçæå¤§ç¶æçµå¨è¿è¡æ°ç¾ä¸æ¬¡ç¶æè§å¯çç»èº«æ¢ç´¢æ¶ï¼ä¼é­åå¥å±æ¶å¤±çå½±åï¼å¹¶ä¸å¨æ¯æ¬¡è¿­ä»£ä¸­é½ä¼åå¾éå¸¸æè´µãå æ­¤ï¼æä»¬å¨æ¯ä¸ªææ¯ä¸­æ·»å äºä¸ä¸ªææ¯æå¤§çµï¼ä»¥è¿ä¸æ­¥å å¿«æç´¢éåº¦ãå¶æ¬¡ï¼æä»¬æåºäºä¸ç§æ°çåå¨å¥å±ï¼ç¨äºææ¯çµæå¤§åï¼åä¸ºâå¹³åææ¯ç¶æçµâï¼å®ä¸ºææ¯ç¶æçµç®æ ççè®ºä¸éæä¾äºæä¼è§£ãç¬¬ä¸ï¼ä¸ºäºå å¿«ç»èº«çµæå¤§åï¼æä»¬æåºäºä¸ä¸ª $k$ è¿é» ($k$NN) å¾ï¼ç¨äºç»ç»çµçä¼°è®¡åæ´æ°è¿ç¨ï¼ä»èå¤§å¹åå°äºè®¡ç®ãæä»¬ç ELEMENT å¨ææ¯åç»èº«è®¾ç½®ä¸­é½ææ¾ä¼äºæåè¿çåå¨å¥å±ãæ­¤å¤ï¼å®è¿å¯ä»¥ç¨äºä¸ä»»å¡æ å³çé¢è®­ç»ãæ¶éç¦»çº¿å¼ºåå­¦ä¹ æ°æ®ç­ã

##### **Automated Multi-Label Annotation for Mental Health Illnesses Using Large Language Models**
2412.03796v1 by Abdelrahaman A. Hassan, Radwa J. Hanafy, Mohammed E. Fouda

The growing prevalence and complexity of mental health disorders present
significant challenges for accurate diagnosis and treatment, particularly in
understanding the interplay between co-occurring conditions. Mental health
disorders, such as depression and Anxiety, often co-occur, yet current datasets
derived from social media posts typically focus on single-disorder labels,
limiting their utility in comprehensive diagnostic analyses. This paper
addresses this critical gap by proposing a novel methodology for cleaning,
sampling, labeling, and combining data to create versatile multi-label
datasets. Our approach introduces a synthetic labeling technique to transform
single-label datasets into multi-label annotations, capturing the complexity of
overlapping mental health conditions. To achieve this, two single-label
datasets are first merged into a foundational multi-label dataset, enabling
realistic analyses of co-occurring diagnoses. We then design and evaluate
various prompting strategies for large language models (LLMs), ranging from
single-label predictions to unrestricted prompts capable of detecting any
present disorders. After rigorously assessing multiple LLMs and prompt
configurations, the optimal combinations are identified and applied to label
six additional single-disorder datasets from RMHD. The result is SPAADE-DR, a
robust, multi-label dataset encompassing diverse mental health conditions. This
research demonstrates the transformative potential of LLM-driven synthetic
labeling in advancing mental health diagnostics from social media data, paving
the way for more nuanced, data-driven insights into mental health care.

æè¦ï¼é¨èå¿çå¥åº·éç¤ççè¡çåè¤éæ§æ¥çå¢å ï¼å°æ¼æºç¢ºè¨ºæ·åæ²»çæåºäºå´å³»çææ°ï¼ç¹å¥æ¯å¨äºè§£å±å­ç¾çä¹éçç¸äºä½ç¨æãå¿çå¥åº·éç¤ï¼ä¾å¦æé¬±çåç¦æ®çï¼ç¶å¸¸å±å­ï¼ä½ç®åå¾ç¤¾ç¾¤åªé«è²¼æä¸­è¡ççè³æééå¸¸åªéæ³¨å®ä¸éç¤æ¨ç±¤ï¼éå¶äºå®åå¨å¨é¢è¨ºæ·åæä¸­çæç¨ãæ¬æééæåºä¸ååµæ°çæ¹æ³ä¾æ¸çãæ½æ¨£ãæ¨ç±¤åçµåè³æï¼ä»¥å»ºç«å¤åè½çå¤æ¨ç±¤è³æéï¼ä¾è§£æ±ºéåééµçå·®è·ãæåçåæ³å¼é²äºä¸ç¨®åææ¨ç±¤æè¡ï¼å°å®æ¨ç±¤è³æéè½æçºå¤æ¨ç±¤è¨»è§£ï¼ææéçå¿çå¥åº·çæ³çè¤éæ§ãçºäºéæéåç®æ¨ï¼é¦åå°å©åå®æ¨ç±¤è³æéåä½µæä¸ååºç¤å¤æ¨ç±¤è³æéï¼ä»¥é²è¡å±å­è¨ºæ·çå¯¦éåæãç¶å¾ï¼æåè¨­è¨ä¸¦è©ä¼°å¤§åèªè¨æ¨¡å (LLM) çåç¨®æç¤ºç­ç¥ï¼å¾å®æ¨ç±¤é æ¸¬å°è½å¤ åµæ¸¬ä»»ä½ç¾æéç¤çç¡éå¶æç¤ºãå¨å´æ ¼è©ä¼°å¤å LLM åæç¤ºéç½®å¾ï¼æ¾åºæä½³çµåä¸¦æç¨æ¼æ¨ç±¤ä¾èª RMHD çå­åå¶ä»å®ä¸éç¤è³æéãçµææ¯ SPAADE-DRï¼ä¸ååå«åç¨®å¿çå¥åº·çæ³çå¼·å¥å¤æ¨ç±¤è³æéãéé ç ç©¶å±ç¤ºäº LLM é©åçåææ¨ç±¤å¨æ¨é²å¾ç¤¾ç¾¤åªé«è³æé²è¡å¿çå¥åº·è¨ºæ·çè½åæ½åï¼çºæ´ç´°ç·»ãè³æé©åçå¿çä¿å¥è¦è§£éªè·¯ã

##### **Speech Recognition-based Feature Extraction for Enhanced Automatic Severity Classification in Dysarthric Speech**
2412.03784v1 by Yerin Choi, Jeehyun Lee, Myoung-Wan Koo

Due to the subjective nature of current clinical evaluation, the need for
automatic severity evaluation in dysarthric speech has emerged. DNN models
outperform ML models but lack user-friendly explainability. ML models offer
explainable results at a feature level, but their performance is comparatively
lower. Current ML models extract various features from raw waveforms to predict
severity. However, existing methods do not encompass all dysarthric features
used in clinical evaluation. To address this gap, we propose a feature
extraction method that minimizes information loss. We introduce an ASR
transcription as a novel feature extraction source. We finetune the ASR model
for dysarthric speech, then use this model to transcribe dysarthric speech and
extract word segment boundary information. It enables capturing finer
pronunciation and broader prosodic features. These features demonstrated an
improved severity prediction performance to existing features: balanced
accuracy of 83.72%.

æè¦ï¼ç±æ¼ç¶åè¨åºè©ä¼°çä¸»è§æ§ï¼å æ­¤åºç¾äºå°æ§é³éç¤è¨èªä¸­èªåå´éç¨åº¦è©ä¼°çéæ±ãDNN æ¨¡ååªæ¼ ML æ¨¡åï¼ä½ç¼ºä¹ä½¿ç¨èååçå¯è§£éæ§ãML æ¨¡åå¨ç¹å¾µå±¤ç´æä¾å¯è§£éççµæï¼ä½å¶æè½ç¸å°è¼ä½ãç¶åç ML æ¨¡åå¾åå§æ³¢å½¢ä¸­æ·ååç¨®ç¹å¾µä»¥é æ¸¬å´éç¨åº¦ãç¶èï¼ç¾ææ¹æ³ä¸¦æªæ¶µèè¨åºè©ä¼°ä¸­ä½¿ç¨çæææ§é³éç¤ç¹å¾µãçºäºè§£æ±ºéåå·®è·ï¼æåæåºäºä¸ç¨®å¯å°è³è¨æå¤±éè³æä½çç¹å¾µæ·åæ¹æ³ãæåå¼å¥äº ASR è½éä½çºä¸ç¨®æ°ç©çç¹å¾µæ·åä¾æºãæåçºæ§é³éç¤è¨èªå¾®èª¿ ASR æ¨¡åï¼ç¶å¾ä½¿ç¨æ­¤æ¨¡åè½éæ§é³éç¤è¨èªä¸¦æ·åå­ååæ®µéçè³è¨ãå®å¯ä»¥æ·åæ´ç²¾ç´°çç¼é³åæ´å»£æ³çé»å¾ç¹å¾µãéäºç¹å¾µé¡¯ç¤ºåºæ¯ç¾æç¹å¾µæ´å¥½çå´éç¨åº¦é æ¸¬æè½ï¼å¹³è¡¡æºç¢ºåº¦çº 83.72%ã

##### **Exploring the Role of AI-Powered Chatbots for Teens and Young Adults with ASD or Social Anxiety**
2412.03740v1 by Dilan Mian

The world can be a complex and difficult place to navigate. People with
High-Functioning Autistic Spectrum Disorder as well as general social
ineptitude often face navigation challenges that individuals of other
demographics simply do not themselves. This can become even more pronounced
with people of that specific group when they are in their teenage years and
early adulthood (that being the usual age range of college students). When they
are at such a vulnerable age, they can be far more susceptible to the struggles
of becoming comfortable and content with social interactions as well as having
strong relationships (outside their immediate family). Concerning this, the
rapid emergence of artificial intelligence chatbots has led to many of them
being used to benefit people of different ages and demographics with easy
accessibility. With this, if there is anything that people with
High-Functioning ASD and social ineptitude want when it comes to guidance
towards self-improvement, surely easy accessibility would be one. What are the
potential benefits and limitations of using a Mindstudio AI-powered chatbot to
provide mental health support for teens and young adults with the
aforementioned conditions? What could be done with a tool like this to help
those individuals navigate ethical dilemmas within different social
environments to reduce existing social tensions? This paper addresses these
queries and offers insights to inform future discussions on the subject.

æè¦ï¼ä¸çå¯è½æ¯ä¸åè¤éä¸é£ä»¥æä»çå°æ¹ãé«åè½èªéçè­ç³»éç¤ä»¥åä¸è¬ç¤¾äº¤ç¡è½çäººï¼ç¶å¸¸æé¢å°å¶ä»äººå£çµ±è¨è³æä¸­çäººæ ¹æ¬ä¸æéå°çæå°ææ°ãç¶ä»åèæ¼éå°å¹´ææåæå¹´åæï¼éå¸¸æ¯å¤§å­¸ççå¹´é½¡ç¯åï¼æï¼éç¨®ææ³å¯è½æè®å¾æ´å æé¡¯ãç¶ä»åèæ¼å¦æ­¤èå¼±çå¹´é½¡æï¼ä»åæ´å®¹æåå°ç¤¾äº¤äºåæå°èªå¨åæ»¿è¶³çææï¼ä»¥åææç¢åºéä¿ï¼å¨ä»åçç´ç³»è¦ªå±¬ä¹å¤ï¼çå½±é¿ãéæ¼éä¸é»ï¼äººå·¥æºæ§èå¤©æ©å¨äººçå¿«éåºç¾ï¼å°è´è¨±å¤äººè¢«ç¨æ¼é ç¦ä¸åå¹´é½¡åäººå£çµ±è¨è³æçäººï¼ä¸¦å·æææ¼å­åæ§ãæäºéåï¼å¦ææ£æé«åè½èªéçåç¤¾äº¤ç¡è½çäººå¨èªææåçæå°æ¹é¢æä»»ä½æ³è¦çæ±è¥¿ï¼é£éº¼ææ¼å­åè¯å®ææ¯ä¸åãä½¿ç¨ç± Mindstudio AI æä¾æè¡æ¯æ´çèå¤©æ©å¨äººï¼çºæ£æä¸è¿°ææ³çéå°å¹´åå¹´è¼äººæä¾å¿çå¥åº·æ¯æ´ï¼æåªäºæ½å¨çå¥½èåéå¶ï¼å¯ä»¥ä½¿ç¨éæ¨£çå·¥å·ä¾å¹«å©é£äºäººæå°ä¸åç¤¾æç°å¢ä¸­çéå¾·å°å¢ï¼ä»¥æ¸å°ç¾æçç¤¾æç·å¼µå±å¢ï¼å¯ä»¥åäºä»éº¼ï¼æ¬ææ¢è¨éäºåé¡ï¼ä¸¦æä¾è¦è§£ï¼çºæªä¾éæ¼æ­¤ä¸»é¡çè¨è«æä¾è³è¨ã

##### **MRGen: Diffusion-based Controllable Data Engine for MRI Segmentation towards Unannotated Modalities**
2412.04106v1 by Haoning Wu, Ziheng Zhao, Ya Zhang, Weidi Xie, Yanfeng Wang

Medical image segmentation has recently demonstrated impressive progress with
deep neural networks, yet the heterogeneous modalities and scarcity of mask
annotations limit the development of segmentation models on unannotated
modalities. This paper investigates a new paradigm for leveraging generative
models in medical applications: controllably synthesizing data for unannotated
modalities, without requiring registered data pairs. Specifically, we make the
following contributions in this paper: (i) we collect and curate a large-scale
radiology image-text dataset, MedGen-1M, comprising modality labels,
attributes, region, and organ information, along with a subset of organ mask
annotations, to support research in controllable medical image generation; (ii)
we propose a diffusion-based data engine, termed MRGen, which enables
generation conditioned on text prompts and masks, synthesizing MR images for
diverse modalities lacking mask annotations, to train segmentation models on
unannotated modalities; (iii) we conduct extensive experiments across various
modalities, illustrating that our data engine can effectively synthesize
training samples and extend MRI segmentation towards unannotated modalities.

æè¦ï¼é«å­¸å½±ååå²æè¿å·²ééæ·±åº¦ç¥ç¶ç¶²è·¯å±ç¾é©äººçé²å±ï¼ä½ç°è³ªæ¨¡æåæ¨ç±¤ç¨å°éå¶äºå¨æªæ¨è¨»æ¨¡æä¸éç¼åå²æ¨¡åãæ¬ææ¢è¨äºä¸åæ°å¸ç¯ï¼ä»¥å©ç¨çææ¨¡åå¨é«å­¸æç¨ä¸­ï¼å¯æ§å°åææªæ¨è¨»æ¨¡æçè³æï¼èç¡éè¨»åè³æå°ãå·é«ä¾èªªï¼æåå¨æ¬æä¸­ååºä»¥ä¸è²¢ç»ï¼(i) æåæ¶éä¸¦ç­åäºä¸åå¤§è¦æ¨¡çæ¾å°å½±åæå­è³æé MedGen-1Mï¼åå«æ¨¡ææ¨ç±¤ãå±¬æ§ãåååå¨å®è³è¨ï¼ä»¥åä¸é¨åå¨å®æ¨ç±¤ï¼ä»¥æ¯æ´å¯æ§é«å­¸å½±åçæçç¸éç ç©¶ï¼(ii) æåæåºäºä¸ååºæ¼æ´æ£çè³æå¼æï¼ç¨±çº MRGenï¼å®è½å¤ æ ¹ææå­æç¤ºåæ¨ç±¤çææ¢ä»¶ï¼åæç¼ºä¹æ¨ç±¤è¨»è§£çä¸åæ¨¡æç MR å½±åï¼ä»¥è¨ç·´æªæ¨è¨»æ¨¡æçåå²æ¨¡åï¼(iii) æåå¨åç¨®æ¨¡æä¸­é²è¡äºå»£æ³çå¯¦é©ï¼èªªææåçè³æå¼æå¯ä»¥ææå°åæè¨ç·´æ¨£æ¬ï¼ä¸¦å° MRI åå²å»¶ä¼¸è³æªæ¨è¨»çæ¨¡æã

##### **Intuitive Axial Augmentation Using Polar-Sine-Based Piecewise Distortion for Medical Slice-Wise Segmentation**
2412.03352v1 by Yiqin Zhang, Qingkui Chen, Chen Huang, Zhengjie Zhang, Meiling Chen, Zhibing Fu

Most data-driven models for medical image analysis rely on universal
augmentations to improve performance. Experimental evidence has confirmed their
effectiveness, but the unclear mechanism underlying them poses a barrier to the
widespread acceptance and trust in such methods within the medical community.
We revisit and acknowledge the unique characteristics of medical images apart
from traditional digital images, and consequently, proposed a medical-specific
augmentation algorithm that is more elastic and aligns well with radiology scan
procedure. The method performs piecewise affine with sinusoidal distorted ray
according to radius on polar coordinates, thus simulating uncertain postures of
human lying flat on the scanning table. Our method could generate human
visceral distribution without affecting the fundamental relative position on
axial plane. Two non-adaptive algorithms, namely Meta-based Scan Table Removal
and Similarity-Guided Parameter Search, are introduced to bolster robustness of
our augmentation method. Experiments show our method improves accuracy across
multiple famous segmentation frameworks without requiring more data samples.
Our preview code is available in: https://github.com/MGAMZ/PSBPD.

æè¦ï¼å¤§å¤æ¸ç¨æ¼é«å­¸å½±ååæçè³æé©åæ¨¡åä»°è³´éç¨æ´ååè½ä¾æåæè½ãå¯¦é©è­æå·²è­å¯¦å¶æææ§ï¼ä½å¶èå¾ä¸æç¢ºçæ©å¶å°é«å­¸çå»£æ³æ¥ååä¿¡ä»»æ­¤é¡æ¹æ³æ§æé»ç¤ãæåéæ°æª¢è¦ä¸¦æ¿èªé«å­¸å½±åèå³çµ±æ¸ä½å½±åçç¨ç¹ç¹æ§ï¼å æ­¤æåºæ´å·å½æ§ä¸èæ¾å°ç·ææç¨åºå¯åéåçé«å­¸ç¹å®æ´åæ¼ç®æ³ãè©²æ¹æ³æ ¹ææ¥µåº§æ¨ä¸çåå¾å·è¡æ­£å¼¦æ­æ²å°ç·çéæ®µä»¿å°ï¼å¾èæ¨¡æ¬äººå¹³èººå¨ææå°ä¸æçä¸ç¢ºå®å§¿å¢ãæåçæ¹æ³å¯ä»¥å¨ä¸å½±é¿è»¸åå¹³é¢ä¸åºæ¬ç¸å°ä½ç½®çææ³ä¸çæäººé«å§èåä½ãå¼å¥äºå©ç¨®éèªé©ææ¼ç®æ³ï¼å³åºæ¼ Meta çææå°ç§»é¤åç¸ä¼¼æ§å°å¼åæ¸æå°ï¼ä»¥å å¼·æåæ´åæ¹æ³çç©©å¥æ§ãå¯¦é©è¡¨æï¼æåçæ¼ç®æ³å¨ä¸éè¦æ´å¤è³ææ¨£æ¬çææ³ä¸ï¼å°±è½æåå¤åèååå²æ¶æ§çæºç¢ºæ§ãæåçé è¦½ç¨å¼ç¢¼å¯å¨ https://github.com/MGAMZ/PSBPD ä¸­åå¾ã

##### **Detecting abnormal heart sound using mobile phones and on-device IConNet**
2412.03267v1 by Linh Vu, Thu Tran

Given the global prevalence of cardiovascular diseases, there is a pressing
need for easily accessible early screening methods. Typically, this requires
medical practitioners to investigate heart auscultations for irregular sounds,
followed by echocardiography and electrocardiography tests. To democratize
early diagnosis, we present a user-friendly solution for abnormal heart sound
detection, utilizing mobile phones and a lightweight neural network optimized
for on-device inference. Unlike previous approaches reliant on specialized
stethoscopes, our method directly analyzes audio recordings, facilitated by a
novel architecture known as IConNet. IConNet, an Interpretable Convolutional
Neural Network, harnesses insights from audio signal processing, enhancing
efficiency and providing transparency in neural pattern extraction from raw
waveform signals. This is a significant step towards trustworthy AI in
healthcare, aiding in remote health monitoring efforts.

æè¦ï¼é´äºå¿è¡ç®¡ç¾çå¨å¨ççæ®éæ§ï¼è¿«åéè¦å®¹æè·åçæ©æç­æ¥æ¹æ³ãéå¸¸ï¼è¿éè¦å»çä»ä¸äººåæ£æ¥å¿èå¬è¯æ¯å¦æä¸è§åçå£°é³ï¼ç¶åè¿è¡è¶å£°å¿å¨å¾åå¿çµå¾æ£æ¥ãä¸ºäºä½¿æ©æè¯æ­æ°ä¸»åï¼æä»¬æåºäºä¸ç§ç¨æ·åå¥½çè§£å³æ¹æ¡ï¼ç¨äºæ£æµå¼å¸¸å¿èå£°é³ï¼å©ç¨ç§»å¨çµè¯åä¸ä¸ªè½»éçº§ç¥ç»ç½ç»ï¼è¯¥ç¥ç»ç½ç»éå¯¹è®¾å¤åæ¨çè¿è¡äºä¼åãä¸ä»¥åä¾èµäºä¸ç¨å¬è¯å¨çåæ³ä¸åï¼æä»¬çæ¹æ³ç´æ¥åæé³é¢è®°å½ï¼è¿å¾çäºä¸ç§ç§°ä¸º IConNet çæ°é¢æ¶æãIConNet æ¯ä¸ç§å¯è§£éçå·ç§¯ç¥ç»ç½ç»ï¼å©ç¨é³é¢ä¿¡å·å¤ççè§è§£ï¼æé«æçï¼å¹¶æä¾ä»åå§æ³¢å½¢ä¿¡å·ä¸­æåç¥ç»æ¨¡å¼çéææ§ãè¿æ¯æåå»çä¿å¥ä¸­å¯ä¿¡èµçäººå·¥æºè½è¿åºçéè¦ä¸æ­¥ï¼æå©äºè¿ç¨å¥åº·çæµå·¥ä½ã

##### **MRNet: Multifaceted Resilient Networks for Medical Image-to-Image Translation**
2412.03039v1 by Hyojeong Lee, Youngwan Jo, Inpyo Hong, Sanghyun Park

We propose a Multifaceted Resilient Network(MRNet), a novel architecture
developed for medical image-to-image translation that outperforms
state-of-the-art methods in MRI-to-CT and MRI-to-MRI conversion. MRNet
leverages the Segment Anything Model (SAM) to exploit frequency-based features
to build a powerful method for advanced medical image transformation. The
architecture extracts comprehensive multiscale features from diverse datasets
using a powerful SAM image encoder and performs resolution-aware feature fusion
that consistently integrates U-Net encoder outputs with SAM-derived features.
This fusion optimizes the traditional U-Net skip connection while leveraging
transformer-based contextual analysis. The translation is complemented by an
innovative dual-mask configuration incorporating dynamic attention patterns and
a specialized loss function designed to address regional mapping mismatches,
preserving both the gross anatomy and tissue details. Extensive validation
studies have shown that MRNet outperforms state-of-the-art architectures,
particularly in maintaining anatomical fidelity and minimizing translation
artifacts.

æè¦ï¼æåæåºä¸åå¤æ¹é¢çå½æ§ç¶²è·¯ (MRNet)ï¼éæ¯ä¸ååµæ°çæ¶æ§ï¼
éç¼ç¨æ¼é«å­¸å½±åè½å½±åçç¿»è­¯ï¼å¶åªæ¼ MRI è½ CT å MRI è½ MRI è½æçææ°æ¹æ³ãMRNet
å©ç¨ Segment Anything Model (SAM) ä¾å©ç¨åºæ¼é »ççç¹å¾µï¼ä»¥å»ºç«ä¸ç¨®å¼·å¤§çæ¹æ³ï¼ç¨æ¼åé²çé«å­¸å½±åè½æãæ­¤
æ¶æ§ä½¿ç¨å¼·å¤§ç SAM å½±åç·¨ç¢¼å¨å¾ä¸åçè³æéæåå¨é¢çå¤å°ºåº¦ç¹å¾µï¼ä¸¦å·è¡è§£æåº¦æç¥ç¹å¾µèåï¼æçºå° U-Net ç·¨ç¢¼å¨è¼¸åºè SAM è¡ççç¹å¾µæ´åå¨ä¸èµ·ã
æ­¤èåæä½³åå³çµ±ç U-Net è·³èºé£æ¥ï¼åæå©ç¨åºæ¼Transformerçä¸ä¸æåæãç¿»è­¯ç±ä¸ååµæ°çéé®ç½©éç½®è£åï¼å®çµåäºåææ³¨ææ¨¡å¼åä¸åå°éçæå¤±å½æ¸ï¼æ¨å¨è§£æ±ºååå°æä¸å¹éçåé¡ï¼åæä¿çäºæ´é«è§£åçµæ§åçµç¹ç´°ç¯ãå»£æ³çé©è­ç ç©¶é¡¯ç¤ºï¼MRNet åªæ¼æåé²çæ¶æ§ï¼ç¹å¥æ¯å¨ç¶­æè§£åä¿çåº¦åæå°åè½æå½å½±æ¹é¢ã

##### **Higher Order Transformers: Efficient Attention Mechanism for Tensor Structured Data**
2412.02919v1 by Soroush Omranpour, Guillaume Rabusseau, Reihaneh Rabbany

Transformers are now ubiquitous for sequence modeling tasks, but their
extension to multi-dimensional data remains a challenge due to the quadratic
cost of the attention mechanism. In this paper, we propose Higher-Order
Transformers (HOT), a novel architecture designed to efficiently process data
with more than two axes, i.e. higher-order tensors. To address the
computational challenges associated with high-order tensor attention, we
introduce a novel Kronecker factorized attention mechanism that reduces the
attention cost to quadratic in each axis' dimension, rather than quadratic in
the total size of the input tensor. To further enhance efficiency, HOT
leverages kernelized attention, reducing the complexity to linear. This
strategy maintains the model's expressiveness while enabling scalable attention
computation. We validate the effectiveness of HOT on two high-dimensional
tasks, including multivariate time series forecasting, and 3D medical image
classification. Experimental results demonstrate that HOT achieves competitive
performance while significantly improving computational efficiency, showcasing
its potential for tackling a wide range of complex, multi-dimensional data.

æè¦ï¼è®å½¢éåç¾å¨æ®éç¨æ¼åºåå»ºæ¨¡ä»»åï¼ä½ç±æ¼æ³¨æåæ©å¶çäºæ¬¡æ¹ææ¬ï¼å®åæ´å±å°å¤ç¶­æ¸æä»ç¶æ¯ä¸åææ°ãå¨æ¬æä¸­ï¼æåæåºäºé«éè®å½¢éå (HOT)ï¼éæ¯ä¸ç¨®æ°ç©çæ¶æ§ï¼æ¨å¨ææèçå·æå©åä»¥ä¸è»¸ç·çæ¸æï¼å³é«éå¼µéãçºäºæå°èé«éå¼µéæ³¨æåç¸éçè¨ç®ææ°ï¼æåå¼å¥äºä¸ç¨®æ°ç©çåç¾å§ååè§£æ³¨æåæ©å¶ï¼è©²æ©å¶å°æ³¨æåææ¬éä½å°æ¯åè»¸ç·ç¶­åº¦çäºæ¬¡æ¹ï¼èä¸æ¯è¼¸å¥å¼µéçç¸½å¤§å°çäºæ¬¡æ¹ãçºäºé²ä¸æ­¥æé«æçï¼HOT å©ç¨æ ¸åæ³¨æåï¼å°è¤éåº¦éä½å°ç·æ§ãæ­¤ç­ç¥ä¿æäºæ¨¡åçè¡¨ç¾åï¼åæå¯¦ç¾äºå¯æ´å±çæ³¨æåè¨ç®ãæåå¨å©åé«ç¶­ä»»åä¸é©è­äº HOT çæææ§ï¼åæ¬å¤åæéåºåé æ¸¬å 3D é«å­¸å½±ååé¡ãå¯¦é©çµæè¡¨æï¼HOT å¨é¡¯èæé«è¨ç®æççåæå¯¦ç¾äºç«¶ç­åçæè½ï¼å±ç¤ºäºå¶æå°åç¨®è¤éçå¤ç¶­æ¸æçæ½åã

##### **A Novel Compact LLM Framework for Local, High-Privacy EHR Data Applications**
2412.02868v1 by Yixiang Qu, Yifan Dai, Shilin Yu, Pradham Tanikella, Travis Schrank, Trevor Hackman, Didong Li, Di Wu

Large Language Models (LLMs) have shown impressive capabilities in natural
language processing, yet their use in sensitive domains like healthcare,
particularly with Electronic Health Records (EHR), faces significant challenges
due to privacy concerns and limited computational resources. This paper
presents a compact LLM framework designed for local deployment in settings with
strict privacy requirements and limited access to high-performance GPUs. We
introduce a novel preprocessing technique that uses information extraction
methods, e.g., regular expressions, to filter and emphasize critical
information in clinical notes, enhancing the performance of smaller LLMs on EHR
data. Our framework is evaluated using zero-shot and few-shot learning
paradigms on both private and publicly available (MIMIC-IV) datasets, and we
also compare its performance with fine-tuned LLMs on the MIMIC-IV dataset. The
results demonstrate that our preprocessing approach significantly boosts the
prediction accuracy of smaller LLMs, making them suitable for high-privacy,
resource-constrained applications. This study offers valuable insights into
optimizing LLM performance for sensitive, data-intensive tasks while addressing
computational and privacy limitations.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å¨èªç¶èªè¨èçæ¹é¢å±ç¾åºä»¤äººå°è±¡æ·±å»çè½åï¼ç¶èå®åå¨é«çä¿å¥ç­ææé åçä½¿ç¨ï¼ç¹å¥æ¯é»å­å¥åº·ç´é (EHR)ï¼ç±æ¼é±ç§åé¡åæéçéç®è³æºèé¢è¨éå¤§ææ°ãæ¬ææåºäºä¸åç·æ¹ç LLM æ¡æ¶ï¼æ¨å¨å¨å·æå´æ ¼é±ç§è¦æ±åæéä½¿ç¨é«æ§è½ GPU çç°å¢ä¸­é²è¡æ¬å°é¨ç½²ãæåå¼å¥äºä¸ç¨®æ°ç©çé èçæè¡ï¼å®ä½¿ç¨è³è¨èåæ¹æ³ï¼ä¾å¦æ­£è¦è¡¨ç¤ºæ³ï¼ä¾éæ¿¾åå¼·èª¿è¨åºç­è¨ä¸­çééµè³è¨ï¼å¢å¼·è¼å° LLM å¨ EHR è³æä¸çæè½ãæåçæ¡æ¶ä½¿ç¨é¶æ¬¡å­¸ç¿åå°æ¬¡å­¸ç¿ç¯ä¾å¨ç§äººåå¬éå¯ç¨ç (MIMIC-IV) è³æéä¸é²è¡è©ä¼°ï¼æåä¹æ¯è¼å®å¨ MIMIC-IV è³æéä¸èå¾®èª¿ LLM çæè½ãçµæè¡¨æï¼æåçé èçæ¹æ³é¡¯èæåäºè¼å° LLM çé æ¸¬æºç¢ºåº¦ï¼ä½¿å¶é©ç¨æ¼é«åº¦é±ç§ãè³æºåéçæç¨ç¨å¼ãéé ç ç©¶æä¾äºå¯¶è²´çè¦è§£ï¼ç¨æ¼æä½³å LLM æè½ä»¥æå°ææãè³æå¯éåä»»åï¼åæè§£æ±ºéç®åé±ç§éå¶ã

##### **Block MedCare: Advancing healthcare through blockchain integration with AI and IoT**
2412.02851v1 by Oliver Simonoski, Dijana Capeska Bogatinoska

This research explores the integration of blockchain technology in
healthcare, focusing on enhancing the security and efficiency of Electronic
Health Record (EHR) management. We propose a novel Ethereum-based system that
empowers patients with secure control over their medical data. Our approach
addresses key challenges in healthcare blockchain implementation, including
scalability, privacy, and regulatory compliance. The system incorporates
digital signatures, Role-Based Access Control, and a multi-layered architecture
to ensure secure, controlled access. We developed a decentralized application
(dApp) with user-friendly interfaces for patients, doctors, and administrators,
demonstrating the practical application of our solution. A survey among
healthcare professionals and IT experts revealed strong interest in blockchain
adoption, while also highlighting concerns about integration costs. The study
explores future enhancements, including integration with IoT devices and
AI-driven analytics, contributing to the evolution of secure, efficient, and
interoperable healthcare systems that leverage cutting-edge technologies for
improved patient care.

æè¦ï¼æ¬ç ç©¶æ¢è¨åå¡éæè¡å¨é«çä¿å¥ä¸­çæ´åï¼å°æ³¨æ¼æåé»å­å¥åº·ç´é (EHR) ç®¡ççå®å¨æ§èæçãæåæåºä¸ååµæ°çä»¥å¤ªåç³»çµ±ï¼è³¦äºæ£èå®å¨å°æ§å¶å¶é«çæ¸æçæ¬åãæåçåæ³è§£æ±ºäºé«çä¿å¥åå¡éå¯¦ä½ä¸­çä¸»è¦ææ°ï¼åæ¬å¯æ´åæ§ãé±ç§åæ³è¦éµå¾ªãè©²ç³»çµ±æ´åäºæ¸ä½ç°½ç« ãåºæ¼è§è²çå­åæ§å¶åå¤å±¤æ¶æ§ï¼ä»¥ç¢ºä¿å®å¨ä¸åæ§çå­åãæåéç¼äºä¸åå·æä½¿ç¨èååä»é¢çå»ä¸­å¿åæç¨ç¨å¼ (dApp)ï¼é©ç¨æ¼æ£èãé«çåç®¡çå¡ï¼å±ç¤ºäºæåè§£æ±ºæ¹æ¡çå¯¦éæç¨ãå¨é«çä¿å¥å°æ¥­äººå¡å IT å°å®¶ä¹éé²è¡çä¸é èª¿æ¥é¡¯ç¤ºï¼ä»åå°åå¡éçæ¡ç¨ææ¿åèè¶£ï¼ä½ä¹å¼·èª¿äºå°æ´åææ¬çææãè©²ç ç©¶æ¢è¨äºæªä¾çå¼·åï¼åæ¬è IoT è£ç½®æ´åå AI é©åçåæï¼æå©æ¼å®å¨ãé«æä¸å¯äºæä½çé«çä¿å¥ç³»çµ±çæ¼é²ï¼è©²ç³»çµ±å©ç¨å°ç«¯æè¡æ¹åæ£èç§è­·ã

##### **CNNSum: Exploring Long-Context Summarization with Large Language Models in Chinese Novels**
2412.02819v3 by Lingxiao Wei, He Yan, Xiangju Lu, Junmin Zhu, Jun Wang, Wei Zhang

Large Language Models (LLMs) have been well-researched in many long-context
tasks. However, due to high annotation costs, high-quality long-context summary
datasets for training or evaluation are scarce, limiting further research. In
this work, we introduce CNNSum, a new multi-scale Chinese long-context novel
summarization benchmark, including four subsets, length covering 16k to 128k,
695 samples in total, the annotations are human-driven. We evaluate commercial
and open-source models on CNNSum and conduct a detailed analysis. Based on the
observations, we further conduct fine-tuning exploration with short-context
summary data. In our study: (1) GPT-4o underperformed, due to excessive
subjective commentary. (2) Currently, long-context summarization mainly relies
on memory ability, small LLMs with stable longer context lengths are the most
cost-effective. Using long data concatenated from short-context summaries makes
a significant improvement. (3) Prompt templates may cause a large performance
gap but can be mitigated through fine-tuning. (4) Fine-tuned Chat or
Instruction versions may harm the Base model and further fine-tuning cannot
bridge performance gap. (5) while models with RoPE base scaling exhibit strong
extrapolation potential, their performance may vary significantly when combined
with other interpolation methods and need careful selection. (6) CNNSum
provides more reliable and insightful evaluation results than other benchmarks.
We release CNNSum to advance research in this field
(https://github.com/CxsGhost/CNNSum).

æè¦ï¼<paragraph>å¤§åèªè¨æ¨¡å (LLM) å·²å¨è¨±å¤é·èªå¢ä»»åä¸­ç²å¾æ·±å¥ç ç©¶ãç¶èï¼ç±æ¼æ¨è¨»ææ¬é«ï¼ç¨æ¼è¨ç·´æè©ä¼°çé«åè³ªé·èªå¢æè¦è³æéç¨å°ï¼éå¶äºé²ä¸æ­¥çç ç©¶ãå¨éé å·¥ä½ä¸­ï¼æåå¼å¥äº CNNSumï¼ä¸åæ°çå¤å°ºåº¦ä¸­æé·èªå¢å°èªªæè¦åºæºï¼åæ¬ååå­éï¼é·åº¦æ¶µè 16k å° 128kï¼ç¸½å± 695 åç¯ä¾ï¼æ¨è¨»æ¯ç±äººå·¥é©åçãæåè©ä¼°äº CNNSum ä¸çåæ¥­åéæºæ¨¡åï¼ä¸¦é²è¡äºè©³ç´°çåæãæ ¹æè§å¯çµæï¼æåé²ä¸æ­¥ä½¿ç¨ç­èªå¢æè¦è³æé²è¡å¾®èª¿æ¢ç´¢ãå¨æåçç ç©¶ä¸­ï¼(1) GPT-4o è¡¨ç¾ä¸ä½³ï¼åå æ¯éåº¦çä¸»è§è©è«ã(2) ç®åï¼é·èªå¢æè¦ä¸»è¦ä¾è³´è¨æ¶è½åï¼å·æç©©å®è¼é·èªå¢é·åº¦çå°å LLM æå·ææ¬æçãä½¿ç¨å¾ç­èªå¢æè¦ä¸²æ¥èæçé·è³æé¡¯èæ¹åäºè¡¨ç¾ã(3) æç¤ºç¯æ¬å¯è½æé æå¾å¤§çæè½å·®è·ï¼ä½å¯ä»¥ééå¾®èª¿ä¾æ¸è¼ã(4) å¾®èª¿éçèå¤©ææä»¤çæ¬å¯è½ææå®³åºç¤æ¨¡åï¼èé²ä¸æ­¥çå¾®èª¿ç¡æ³å½åæè½å·®è·ã(5) éç¶å·æ RoPE åºç¤ç¸®æ¾çæ¨¡åå±ç¾åºå¼·å¤§çå¤æ¨æ½åï¼ä½èå¶ä»å§ææ¹æ³çµåæï¼å¶æè½å¯è½æé¡¯èè®åï¼éè¦ä»ç´°é¸æã(6) CNNSum æä¾æ¯å¶ä»åºæºæ´å¯é ä¸æè¦å°çè©ä¼°çµæãæåç¼å¸ CNNSum ä»¥æ¨é²æ­¤é åçç ç©¶ (https://github.com/CxsGhost/CNNSum)ã</paragraph>

##### **Optimization of Transformer heart disease prediction model based on particle swarm optimization algorithm**
2412.02801v2 by Jingyuan Yi, Peiyang Yu, Tianyi Huang, Zeqiu Xu

Aiming at the latest particle swarm optimization algorithm, this paper
proposes an improved Transformer model to improve the accuracy of heart disease
prediction and provide a new algorithm idea. We first use three mainstream
machine learning classification algorithms - decision tree, random forest and
XGBoost, and then output the confusion matrix of these three models. The
results showed that the random forest model had the best performance in
predicting the classification of heart disease, with an accuracy of 92.2%.
Then, we apply the Transformer model based on particle swarm optimization (PSO)
algorithm to the same dataset for classification experiment. The results show
that the classification accuracy of the model is as high as 96.5%, 4.3
percentage points higher than that of random forest, which verifies the
effectiveness of PSO in optimizing Transformer model. From the above research,
we can see that particle swarm optimization significantly improves Transformer
performance in heart disease prediction. Improving the ability to predict heart
disease is a global priority with benefits for all humankind. Accurate
prediction can enhance public health, optimize medical resources, and reduce
healthcare costs, leading to healthier populations and more productive
societies worldwide. This advancement paves the way for more efficient health
management and supports the foundation of a healthier, more resilient global
community.

æè¦ï¼<paragraph>éå°ææ°çç²å­ç¾¤æä½³åæ¼ç®æ³ï¼æ¬ææåºæ¹è¯ç Transformer æ¨¡åï¼ä»¥æåå¿èçé æ¸¬çæºç¢ºåº¦ï¼ä¸¦æä¾æ°çæ¼ç®æ³æç¶­ãæåé¦åä½¿ç¨ä¸ç¨®ä¸»æµæ©å¨å­¸ç¿åé¡æ¼ç®æ³ââæ±ºç­æ¨¹ãé¨æ©æ£®æè XGBoostï¼ä¸¦è¼¸åºéä¸ç¨®æ¨¡åçæ··æ·ç©é£ãçµæé¡¯ç¤ºé¨æ©æ£®ææ¨¡åå¨é æ¸¬å¿èçåé¡ä¸è¡¨ç¾æä½³ï¼æºç¢ºåº¦çº 92.2%ãæ¥èï¼æåå°åºæ¼ç²å­ç¾¤æä½³å (PSO) æ¼ç®æ³ç Transformer æ¨¡åå¥ç¨æ¼ç¸åè³æéé²è¡åé¡å¯¦é©ãçµæé¡¯ç¤ºè©²æ¨¡åçåé¡æºç¢ºåº¦é«é 96.5%ï¼æ¯é¨æ©æ£®æé«åº 4.3 åç¾åé»ï¼é©è­äº PSO å¨æä½³å Transformer æ¨¡åä¸çæææ§ãå¾ä¸è¿°ç ç©¶ä¸­ï¼æåå¯ä»¥çåºç²å­ç¾¤æä½³åé¡¯èæåäº Transformer å¨å¿èçé æ¸¬ä¸çè¡¨ç¾ãæåé æ¸¬å¿èççè½åæ¯ä¸é å¨çæ§çåªåè¦åï¼å°å¨äººé¡é½æçãæºç¢ºçé æ¸¬å¯ä»¥å¢é²å¬å±è¡çãåªåé«çè³æºä¸¦éä½é«çä¿å¥ææ¬ï¼é²èä¿é²å¨çäººå£çå¥åº·åç¤¾æçç¢åãéé é²å±çºæ´ææççå¥åº·ç®¡çéªè·¯ï¼ä¸¦æ¯æå»ºç«ä¸åæ´å¥åº·ãæ´å·éæ§çå¨çç¤¾ç¾¤ã</paragraph>

##### **Medical Multimodal Foundation Models in Clinical Diagnosis and Treatment: Applications, Challenges, and Future Directions**
2412.02621v1 by Kai Sun, Siyan Xue, Fuchun Sun, Haoran Sun, Yu Luo, Ling Wang, Siyuan Wang, Na Guo, Lei Liu, Tian Zhao, Xinzhou Wang, Lei Yang, Shuo Jin, Jun Yan, Jiahong Dong

Recent advancements in deep learning have significantly revolutionized the
field of clinical diagnosis and treatment, offering novel approaches to improve
diagnostic precision and treatment efficacy across diverse clinical domains,
thus driving the pursuit of precision medicine. The growing availability of
multi-organ and multimodal datasets has accelerated the development of
large-scale Medical Multimodal Foundation Models (MMFMs). These models, known
for their strong generalization capabilities and rich representational power,
are increasingly being adapted to address a wide range of clinical tasks, from
early diagnosis to personalized treatment strategies. This review offers a
comprehensive analysis of recent developments in MMFMs, focusing on three key
aspects: datasets, model architectures, and clinical applications. We also
explore the challenges and opportunities in optimizing multimodal
representations and discuss how these advancements are shaping the future of
healthcare by enabling improved patient outcomes and more efficient clinical
workflows.

æè¦ï¼æ·±åº¦å­¸ç¿çææ°é²å±å¤§å¹é©æ°äºè¨åºè¨ºæ·åæ²»çé åï¼æä¾äºæ¹ååç¨®è¨åºé åè¨ºæ·ç²¾æºåº¦åæ²»çææçæ°æ¹æ³ï¼é²èæ¨åç²¾æºé«ççè¿½æ±ãå¤å¨å®åå¤æ¨¡æè³æéçå¯ç¨æ§æ¥çå¢å ï¼å éäºå¤§è¦æ¨¡é«çå¤æ¨¡æåºç¤æ¨¡å (MMFM) çç¼å±ãéäºæ¨¡åä»¥å¶å¼·å¤§çæ¦åè½ååè±å¯çè¡¨å¾µè½åèèåï¼æ­£æ¥çè¢«æ¹ç·¨ä»¥è§£æ±ºå»£æ³çè¨åºä»»åï¼å¾æ©æè¨ºæ·å°åäººåæ²»çç­ç¥ãæ¬ç¯è©è«æä¾äºå° MMFM è¿æç¼å±çå¨é¢åæï¼éé»éæ³¨ä¸åééµé¢åï¼è³æéãæ¨¡åæ¶æ§åè¨åºæç¨ãæåä¹æ¢è¨äºæä½³åå¤æ¨¡æè¡¨å¾µçææ°åæ©æï¼ä¸¦è¨è«éäºé²å±å¦ä½ééæ¹åæ£èé å¾åæ´ææççè¨åºå·¥ä½æµç¨ï¼å½¢å¡é«çä¿å¥çæªä¾ã

##### **U-Net in Medical Image Segmentation: A Review of Its Applications Across Modalities**
2412.02242v1 by Fnu Neha, Deepshikha Bhati, Deepak Kumar Shukla, Sonavi Makarand Dalvi, Nikolaos Mantzou, Safa Shubbar

Medical imaging is essential in healthcare to provide key insights into
patient anatomy and pathology, aiding in diagnosis and treatment. Non-invasive
techniques such as X-ray, Magnetic Resonance Imaging (MRI), Computed Tomography
(CT), and Ultrasound (US), capture detailed images of organs, tissues, and
abnormalities. Effective analysis of these images requires precise segmentation
to delineate regions of interest (ROI), such as organs or lesions. Traditional
segmentation methods, relying on manual feature-extraction, are labor-intensive
and vary across experts. Recent advancements in Artificial Intelligence (AI)
and Deep Learning (DL), particularly convolutional models such as U-Net and its
variants (U-Net++ and U-Net 3+), have transformed medical image segmentation
(MIS) by automating the process and enhancing accuracy. These models enable
efficient, precise pixel-wise classification across various imaging modalities,
overcoming the limitations of manual segmentation. This review explores various
medical imaging techniques, examines the U-Net architectures and their
adaptations, and discusses their application across different modalities. It
also identifies common challenges in MIS and proposes potential solutions.

æè¦ï¼é«çå½±åå¨é«çä¿å¥ä¸­è³ééè¦ï¼å¯æä¾æ£èè§£åçµæ§åççå­¸çéè¦è¦è§£ï¼æå©æ¼è¨ºæ·åæ²»çãX åãç£æ¯é å½± (MRI)ãé»è¦æ·å±¤ææ (CT) åè¶é³æ³¢ (US) ç­éä¾µå¥å¼æè¡ï¼å¯ææå¨å®ãçµç¹åç°å¸¸çè©³ç´°å½±åãææåæéäºå½±åéè¦ç²¾ç¢ºçåå²ï¼ä»¥æç¹ªæèè¶£åå (ROI)ï¼ä¾å¦å¨å®æçç¶ãå³çµ±çåå²æ¹æ³ä¾è³´æ¼æåç¹å¾µèåï¼æ¢è²»æåå å°å®¶èç°ãäººå·¥æºæ§ (AI) åæ·±åº¦å­¸ç¿ (DL) çææ°é²å±ï¼ç¹å¥æ¯ U-Net åå¶è®é« (U-Net++ å U-Net 3+) ç­å·ç©æ¨¡åï¼å·²ééèªååæµç¨åæé«æºç¢ºåº¦ï¼è½è®äºé«çå½±ååå² (MIS)ãéäºæ¨¡åè½è·¨è¶åç¨®å½±åæ¨¡å¼é²è¡ææä¸ç²¾ç¢ºçéåç´ åé¡ï¼åæäºæååå²çéå¶ãæ¬ç¯è©è«æ¢è¨äºåç¨®é«çå½±åæè¡ï¼å¯©æ¥äº U-Net æ¶æ§åå¶æ¹ç·¨ï¼ä¸¦è¨è«äºå®åå¨ä¸åæ¨¡å¼ä¸­çæç¨ãå®ä¹æ¾åºäº MIS ä¸­å¸¸è¦çææ°ï¼ä¸¦æåºäºæ½å¨çè§£æ±ºæ¹æ¡ã

##### **Recovering implicit physics model under real-world constraints**
2412.02215v1 by Ayan Banerjee, Sandeep K. S. Gupta

Recovering a physics-driven model, i.e. a governing set of equations of the
underlying dynamical systems, from the real-world data has been of recent
interest. Most existing methods either operate on simulation data with
unrealistically high sampling rates or require explicit measurements of all
system variables, which is not amenable in real-world deployments. Moreover,
they assume the timestamps of external perturbations to the physical system are
known a priori, without uncertainty, implicitly discounting any sensor
time-synchronization or human reporting errors. In this paper, we propose a
novel liquid time constant neural network (LTC-NN) based architecture to
recover underlying model of physical dynamics from real-world data. The
automatic differentiation property of LTC-NN nodes overcomes problems
associated with low sampling rates, the input dependent time constant in the
forward pass of the hidden layer of LTC-NN nodes creates a massive search space
of implicit physical dynamics, the physics model solver based data
reconstruction loss guides the search for the correct set of implicit dynamics,
and the use of the dropout regularization in the dense layer ensures extraction
of the sparsest model. Further, to account for the perturbation timing error,
we utilize dense layer nodes to search through input shifts that results in the
lowest reconstruction loss. Experiments on four benchmark dynamical systems,
three with simulation data and one with the real-world data show that the
LTC-NN architecture is more accurate in recovering implicit physics model
coefficients than the state-of-the-art sparse model recovery approaches. We
also introduce four additional case studies (total eight) on real-life medical
examples in simulation and with real-world clinical data to show effectiveness
of our approach in recovering underlying model in practice.

æè¦ï¼<paragraph>å¾çå¯¦ä¸çè³æä¸­éåç©çé©åæ¨¡åï¼å³åºç¤åæç³»çµ±çæ§å¶æ¹ç¨å¼çµï¼ä¸ç´æ¯è¿æçç ç©¶éé»ãç¾ææ¹æ³å¤§å¤å¨å·æéç¾å¯¦é«åæ¨£ççæ¨¡æ¬è³æä¸å·è¡ï¼æéè¦ææç³»çµ±è®æ¸çæç¢ºæ¸¬éå¼ï¼éå¨çå¯¦ä¸ççé¨ç½²ä¸­ä¸¦ä¸å¯è¡ãæ­¤å¤ï¼éäºæ¹æ³åè¨­å°ç©çç³»çµ±çå¤é¨æ¾åçæéæ³æ¯åé©å·²ç¥çï¼ä¸æ²æä¸ç¢ºå®æ§ï¼é±å«å°å¿½ç¥äºä»»ä½ææ¸¬å¨æéåæ­¥æäººçºåå ±é¯èª¤ãå¨æ¬æä¸­ï¼æåæåºäºä¸ç¨®åºæ¼æ°ç©æ¶²ææéå¸¸æ¸ç¥ç¶ç¶²è·¯ (LTC-NN) çæ¶æ§ï¼ä»¥å¾çå¯¦ä¸çè³æä¸­éåç©çåæçåºç¤æ¨¡åãLTC-NN ç¯é»çèªåå¾®åç¹æ§åæäºèä½åæ¨£çç¸éçåé¡ï¼LTC-NN ç¯é»é±èå±¤çååå³éä¸­è¼¸å¥ä¾è³´çæéå¸¸æ¸æç¢çä¸åå·¨å¤§çé±å¼ç©çåææå°ç©ºéï¼åºæ¼ç©çæ¨¡åæ±è§£å¨çè³æéå»ºæå¤±å¼å°äºå°æ­£ç¢ºé±å¼åæéçæå°ï¼ä¸¦ä¸å¨ç¨ å¯å±¤ä¸­ä½¿ç¨ä¸­æ·æ­£ååç¢ºä¿äºæç¨çæ¨¡åçæåãæ­¤å¤ï¼çºäºèæ®æ¾åè¨æé¯èª¤ï¼æåå©ç¨ç¨ å¯å±¤ç¯é»ä¾æå°è¼¸å¥ä½ç§»ï¼éå°å°è´æä½çéå»ºæå¤±ãå¨åååºæºåæç³»çµ±ï¼ä¸åä½¿ç¨æ¨¡æ¬è³æï¼ä¸åä½¿ç¨çå¯¦ä¸çè³æï¼ä¸çå¯¦é©è¡¨æï¼LTC-NN æ¶æ§å¨æ¢å¾©é±å¼ç©çæ¨¡åä¿æ¸æ¹é¢æ¯æåé²çç¨çæ¨¡åæ¢å¾©æ¹æ³æ´æºç¢ºãæåéä»ç´¹äºååé¡å¤çæ¡ä¾ç ç©¶ï¼ç¸½å±å«åï¼ï¼éäºç ç©¶æ¶åæ¨¡æ¬ä¸­ççå¯¦é«çç¯ä¾åçå¯¦ä¸ççè¨åºè³æï¼ä»¥å±ç¤ºæåçåæ³å¨å¯¦åä¸­æ¢å¾©åºç¤æ¨¡åçæææ§ã</paragraph>

##### **Comparative Performance of Machine Learning Algorithms for Early Genetic Disorder and Subclass Classification**
2412.02189v1 by Abu Bakar Siddik, Faisal R. Badal, Afroza Islam

A great deal of effort has been devoted to discovering a particular genetic
disorder, but its classification across a broad spectrum of disorder classes
and types remains elusive. Early diagnosis of genetic disorders enables timely
interventions and improves outcomes. This study implements machine learning
models using basic clinical indicators measurable at birth or infancy to enable
diagnosis in preliminary life stages. Supervised learning algorithms were
implemented on a dataset of 22083 instances with 42 features like family
history, newborn metrics, and basic lab tests. Extensive hyperparameter tuning,
feature engineering, and selection were undertaken. Two multi-class classifiers
were developed: one for predicting disorder classes (mitochondrial,
multifactorial, and single-gene) and one for subtypes (9 disorders).
Performance was evaluated using accuracy, precision, recall, and the F1-score.
The CatBoost classifier achieved the highest accuracy of 77% for predicting
genetic disorder classes. For subtypes, SVM attained a maximum accuracy of 80%.
The study demonstrates the feasibility of using basic clinical data in machine
learning models for early categorization and diagnosis across various genetic
disorders. Applying ML with basic clinical indicators can enable timely
interventions once validated on larger datasets. It is necessary to conduct
further studies to improve model performance on this dataset.

æè¦ï¼<paragraph>è¨±å¤ç ç©¶è´åæ¼ç¼ç¾ç¹å®éºå³æ§ç¾çï¼ä½å¶å¨å»£æ³çç¾çé¡åååé¡ä¸­çåé¡ä»ç¶é£ä»¥ææ¸ãéºå³æ§ç¾ççæ©æè¨ºæ·è½åæä»å¥ä¸¦æ¹åçµæãæ¬ç ç©¶å¯¦ä½æ©å¨å­¸ç¿æ¨¡åï¼ä½¿ç¨åºçæå¬°åææå¯æ¸¬éçåºæ¬è¨åºææ¨ï¼ä»¥å¨çå½çæ©æéæ®µé²è¡è¨ºæ·ãç£ç£å¼å­¸ç¿æ¼ç®æ³å¯¦ä½å¨ä¸ååå« 22083 åå¯¦ä¾çè³æéä¸ï¼å¶ä¸­åå« 42 åç¹å¾µï¼ä¾å¦å®¶æå²ãæ°çåææ¨ååºæ¬å¯¦é©å®¤æª¢é©ãé²è¡äºå»£æ³çè¶åæ¸èª¿æ´ãç¹å¾µå·¥ç¨åé¸æãéç¼äºå©åå¤é¡å¥åé¡å¨ï¼ä¸åç¨æ¼é æ¸¬ç¾çé¡åï¼ç²ç·é«ãå¤å ç´ åå®åºå ï¼ï¼å¦ä¸åç¨æ¼é æ¸¬äºåï¼9 ç¨®ç¾çï¼ãä½¿ç¨æºç¢ºåº¦ãç²¾ç¢ºåº¦ãå¬åçå F1 åæ¸è©ä¼°æè½ãCatBoost åé¡å¨å¨é æ¸¬éºå³æ§ç¾çé¡åæ¹é¢éå°äº 77% çæé«æºç¢ºåº¦ãå°æ¼äºåï¼SVM éå°äº 80% çæé«æºç¢ºåº¦ãæ¬ç ç©¶è­æäºå¨æ©å¨å­¸ç¿æ¨¡åä¸­ä½¿ç¨åºæ¬è¨åºè³æé²è¡æ©æåé¡åè¨ºæ·åç¨®éºå³æ§ç¾ççå¯è¡æ§ãå°æ©å¨å­¸ç¿æç¨æ¼åºæ¬è¨åºææ¨ï¼å¯ä»¥å¨è¼å¤§çè³æéä¸é©è­å¾åæé²è¡å¹²é ãæå¿è¦é²è¡é²ä¸æ­¥çç ç©¶ä»¥æ¹åæ­¤è³æéä¸çæ¨¡åæè½ã</paragraph>

##### **Anatomically-Grounded Fact Checking of Automated Chest X-ray Reports**
2412.02177v1 by R. Mahmood, K. C. L. Wong, D. M. Reyes, N. D'Souza, L. Shi, J. Wu, P. Kaviani, M. Kalra, G. Wang, P. Yan, T. Syeda-Mahmood

With the emergence of large-scale vision-language models, realistic radiology
reports may be generated using only medical images as input guided by simple
prompts. However, their practical utility has been limited due to the factual
errors in their description of findings. In this paper, we propose a novel
model for explainable fact-checking that identifies errors in findings and
their locations indicated through the reports. Specifically, we analyze the
types of errors made by automated reporting methods and derive a new synthetic
dataset of images paired with real and fake descriptions of findings and their
locations from a ground truth dataset. A new multi-label cross-modal
contrastive regression network is then trained on this datsaset. We evaluate
the resulting fact-checking model and its utility in correcting reports
generated by several SOTA automated reporting tools on a variety of benchmark
datasets with results pointing to over 40\% improvement in report quality
through such error detection and correction.

æè¦ï¼é¨èå¤§è¦æ¨¡è¦è¦ºèªè¨æ¨¡åçåºç¾ï¼åä½¿ç¨é«çå½±åä½çºè¼¸å¥ï¼ä¸¦ééç°¡å®æç¤ºå¼å°ï¼å³å¯ç¢çé¼ççæ¾å°ç§å ±åãç¶èï¼ç±æ¼å¶å°ç¼ç¾çæè¿°æäºå¯¦ä¸çé¯èª¤ï¼å æ­¤å¶å¯¦éæç¨åå°éå¶ãå¨æ¬æä¸­ï¼æåæåºäºä¸åç¨æ¼å¯è§£éäºå¯¦æ¥æ ¸çæ°æ¨¡åï¼è©²æ¨¡åå¯è­å¥å ±åä¸­ç¼ç¾çé¯èª¤åå¶ä½ç½®ãå·é«ä¾èªªï¼æååæäºèªååå ±åæ¹æ³æç¢ççé¯èª¤é¡åï¼ä¸¦å¾çå¯¦è³æéä¸­è¡çåºä¸åæ°çåæå½±åè³æéï¼å¶ä¸­éå°äºç¼ç¾åå¶ä½ç½®ççå¯¦åèåæè¿°ãç¶å¾å¨éåè³æéä¸è¨ç·´ä¸åæ°çå¤æ¨ç±¤è·¨æ¨¡æå°æ¯åæ­¸ç¶²è·¯ãæåè©ä¼°äºç¢ççäºå¯¦æ¥æ ¸æ¨¡ååå¶å¨æ´æ­£ç±å¤å SOTA èªååå ±åå·¥å·å¨åç¨®åºæºè³æéä¸ç¢ççå ±åä¸­çæç¨ï¼çµæè¡¨æéééç¨®é¯èª¤åµæ¸¬åæ´æ­£ï¼å ±ååè³ªç²å¾äºè¶é 40% çæåã

##### **Keeping Experts in the Loop: Expert-Guided Optimization for Clinical Data Classification using Large Language Models**
2412.02173v1 by Nader Karayanni, Aya Awwad, Chein-Lien Hsiao, Surish P Shanmugam

Since the emergence of Large Language Models (LLMs), the challenge of
effectively leveraging their potential in healthcare has taken center stage. A
critical barrier to using LLMs for extracting insights from unstructured
clinical notes lies in the prompt engineering process. Despite its pivotal role
in determining task performance, a clear framework for prompt optimization
remains absent. Current methods to address this gap take either a manual prompt
refinement approach, where domain experts collaborate with prompt engineers to
create an optimal prompt, which is time-intensive and difficult to scale, or
through employing automatic prompt optimizing approaches, where the value of
the input of domain experts is not fully realized. To address this, we propose
StructEase, a novel framework that bridges the gap between automation and the
input of human expertise in prompt engineering. A core innovation of the
framework is SamplEase, an iterative sampling algorithm that identifies
high-value cases where expert feedback drives significant performance
improvements. This approach minimizes expert intervention, to effectively
enhance classification outcomes. This targeted approach reduces labeling
redundancy, mitigates human error, and enhances classification outcomes. We
evaluated the performance of StructEase using a dataset of de-identified
clinical narratives from the US National Electronic Injury Surveillance System
(NEISS), demonstrating significant gains in classification performance compared
to current methods. Our findings underscore the value of expert integration in
LLM workflows, achieving notable improvements in F1 score while maintaining
minimal expert effort. By combining transparency, flexibility, and scalability,
StructEase sets the foundation for a framework to integrate expert input into
LLM workflows in healthcare and beyond.

æè¦ï¼èªå¤§åèªè¨æ¨¡å (LLM) åºç¾ä»¥ä¾ï¼ææå©ç¨å¶å¨é«çä¿å¥ä¸­çæ½åçææ°å·²æçºéä¸­ä¹éãä½¿ç¨ LLM å¾éçµæ§åè¨åºç­è¨ä¸­æåè¦è§£çä¸åééµéç¤å¨æ¼æç¤ºå·¥ç¨éç¨ãåç®¡å®å¨ç¢ºå®ä»»åç¸¾æä¸­æ®æ¼èèè¶³è¼éçè§è²ï¼ä½ä»ç¼ºä¹æç¢ºçæç¤ºæä½³åæ¡æ¶ãç®åè§£æ±ºæ­¤å·®è·çæ¹æ³æ¡ç¨æåæç¤ºåªåæ¹æ³ï¼å¶ä¸­é åå°å®¶èæç¤ºå·¥ç¨å¸«åä½å»ºç«æä½³æç¤ºï¼ééå¸¸èæä¸é£ä»¥æ´å±ï¼æééæ¡ç¨èªåæç¤ºæä½³åæ¹æ³ï¼å¶ä¸­é åå°å®¶çè¼¸å¥å¹å¼ä¸¦æªååå¯¦ç¾ãçºäºè§£æ±ºéååé¡ï¼æåæåºäº StructEaseï¼éæ¯ä¸åæ°ç©çæ¡æ¶ï¼å®å½åäºèªååèæç¤ºå·¥ç¨ä¸­äººé¡å°æ¥­ç¥è­è¼¸å¥ä¹éçå·®è·ãè©²æ¡æ¶çæ ¸å¿åµæ°æ¯ SamplEaseï¼éæ¯ä¸ç¨®è¿­ä»£å¼æ½æ¨£æ¼ç®æ³ï¼å®è­å¥åºå°å®¶åé¥è½é¡¯èæåç¸¾æçé«å¹å¼æ¡ä¾ãéç¨®æ¹æ³å°å°å®¶ä»å¥éå°æä½ï¼ä»¥æææååé¡çµæãéç¨®æéå°æ§çæ¹æ³æ¸å°äºæ¨ç±¤åé¤ï¼æ¸è¼äºäººçºé¯èª¤ï¼ä¸¦æåäºåé¡çµæãæåä½¿ç¨ä¾èªç¾ååå®¶é»å­å·å®³ç£æ¸¬ç³»çµ± (NEISS) çå»è­å¥åè¨åºæè¿°è³æéè©ä¼°äº StructEase çç¸¾æï¼èç®åçæ¹æ³ç¸æ¯ï¼åé¡ç¸¾ææäºé¡¯èçæåãæåçç ç©¶çµæå¼·èª¿äºå°å®¶æ´åå¨ LLM å·¥ä½æµç¨ä¸­çå¹å¼ï¼å¨ç¶­ææå°å°å®¶å·¥ä½éçåæï¼éå°äº F1 åæ¸çé¡¯èæåãééçµåéæåº¦ãå½æ§åå¯æ´å±æ§ï¼StructEase çºä¸åæ¡æ¶å¥ å®äºåºç¤ï¼å°å°å®¶è¼¸å¥æ´åå°é«çä¿å¥åå¶ä»é åç LLM å·¥ä½æµç¨ä¸­ã

##### **Construction and optimization of health behavior prediction model for the elderly in smart elderly care**
2412.02062v1 by Qian Guo, Peiyuan Chen

With the intensification of global aging, health management of the elderly
has become a focus of social attention. This study designs and implements a
smart elderly care service model to address issues such as data diversity,
health status complexity, long-term dependence and data loss, sudden changes in
behavior, and data privacy in the prediction of health behaviors of the
elderly. The model achieves accurate prediction and dynamic management of
health behaviors of the elderly through modules such as multimodal data fusion,
data loss processing, nonlinear prediction, emergency detection, and privacy
protection. In the experimental design, based on multi-source data sets and
market research results, the model demonstrates excellent performance in health
behavior prediction, emergency detection, and personalized services. The
experimental results show that the model can effectively improve the accuracy
and robustness of health behavior prediction and meet the actual application
needs in the field of smart elderly care. In the future, with the integration
of more data and further optimization of technology, the model will provide
more powerful technical support for smart elderly care services.

æè¦ï¼é¨èå¨çé«é½¡åå åï¼èå¹´äººçå¥åº·ç®¡çå·²æçºç¤¾æéæ³¨çç¦é»ãæ¬ç ç©¶è¨­è¨ä¸¦å¯¦ä½ä¸åæºæ§èäººç§è­·æåæ¨¡åï¼ä»¥è§£æ±ºèäººå¥åº·è¡çºé æ¸¬ä¸­çè³æç°è³ªæ§ãå¥åº·çæè¤éæ§ãé·æä¾è³´æ§èè³ææµå¤±ãè¡çºçªè®ãè³æé±ç§ç­åé¡ãè©²æ¨¡åééå¤æ¨¡æè³æèåãè³ææµå¤±èçãéç·æ§é æ¸¬ãç·æ¥äºä»¶åµæ¸¬ãé±ç§ä¿è­·ç­æ¨¡çµï¼éå°èäººå¥åº·è¡çºçç²¾æºé æ¸¬èåæç®¡çãå¨å¯¦é©è¨­è¨ä¸ï¼åºæ¼å¤ä¾æºè³æéèå¸å ´èª¿æ¥çµæï¼è©²æ¨¡åå¨å¥åº·è¡çºé æ¸¬ãç·æ¥äºä»¶åµæ¸¬ãåäººåæåç­æ¹é¢åå±ç¾åºåªç°çè¡¨ç¾ãå¯¦é©çµæé¡¯ç¤ºï¼è©²æ¨¡åè½æææåå¥åº·è¡çºé æ¸¬çæºç¢ºæ§èé­¯æ£æ§ï¼ä¸¦æ»¿è¶³æºæ§èäººç§è­·é åçå¯¦éæç¨éæ±ãæªä¾é¨èæ´å¤è³æçæ´åèæè¡çé²ä¸æ­¥åªåï¼è©²æ¨¡åå°çºæºæ§èäººç§è­·æåæä¾æ´å¼·å¤§çæè¡æ¯æã

##### **INSIGHT: Explainable Weakly-Supervised Medical Image Analysis**
2412.02012v2 by Wenbo Zhang, Junyu Chen, Christopher Kanan

Due to their large sizes, volumetric scans and whole-slide pathology images
(WSIs) are often processed by extracting embeddings from local regions and then
an aggregator makes predictions from this set. However, current methods require
post-hoc visualization techniques (e.g., Grad-CAM) and often fail to localize
small yet clinically crucial details. To address these limitations, we
introduce INSIGHT, a novel weakly-supervised aggregator that integrates heatmap
generation as an inductive bias. Starting from pre-trained feature maps,
INSIGHT employs a detection module with small convolutional kernels to capture
fine details and a context module with a broader receptive field to suppress
local false positives. The resulting internal heatmap highlights diagnostically
relevant regions. On CT and WSI benchmarks, INSIGHT achieves state-of-the-art
classification results and high weakly-labeled semantic segmentation
performance. Project website and code are available at:
https://zhangdylan83.github.io/ewsmia/

æè¦ï¼ç±æ¼é«ç©é¾å¤§ï¼é«ç©ææåå¨ç»çççåå (WSI) éå¸¸ééå¾å±é¨ååæååµå¥å¼èçï¼ç¶å¾èåå¨å¾æ­¤çµä¸­ååºé æ¸¬ãç¶èï¼ç®åçæ¹æ³éè¦äºå¾å¯è¦åæè¡ï¼ä¾å¦ Grad-CAMï¼ï¼èä¸å¸¸å¸¸ç¡æ³å®ä½å°åä½è¨åºä¸è³ééè¦çç´°ç¯ãçºäºè§£æ±ºéäºéå¶ï¼æåå¼å¥äº INSIGHTï¼éæ¯ä¸ç¨®æ°ç©çå¼±ç£ç£èåå¨ï¼å®å°ç±åçææ´åçºæ­¸ç´åèª¤ãå¾é åè¨ç·´å¥½çç¹å¾µåéå§ï¼INSIGHT ä½¿ç¨å¸¶æå°åå·ç©æ ¸çæª¢æ¸¬æ¨¡çµä¾æ·åç²¾ç´°çç´°ç¯ï¼ä»¥åå¸¶æè¼å»£æ³æåéçä¸ä¸ææ¨¡çµä¾æå¶å±é¨èª¤å ±ãç¢ççå§é¨ç±åçªåºäºè¨ºæ·ç¸éååãå¨ CT å WSI åºæºä¸ï¼INSIGHT éå°äºæåé²çåé¡çµæåé«å¼±æ¨è¨èªç¾©åå²æè½ãå°æ¡ç¶²ç«åç¨å¼ç¢¼å¯æ¼ä¸åç¶²ååå¾ï¼
https://zhangdylan83.github.io/ewsmia/

##### **The use of large language models to enhance cancer clinical trial educational materials**
2412.01955v2 by Mingye Gao, Aman Varshney, Shan Chen, Vikram Goddla, Jack Gallifant, Patrick Doyle, Claire Novack, Maeve Dillon-Martin, Teresia Perkins, Xinrong Correia, Erik Duhaime, Howard Isenstein, Elad Sharon, Lisa Soleymani Lehmann, David Kozono, Brian Anthony, Dmitriy Dligach, Danielle S. Bitterman

Cancer clinical trials often face challenges in recruitment and engagement
due to a lack of participant-facing informational and educational resources.
This study investigated the potential of Large Language Models (LLMs),
specifically GPT4, in generating patient-friendly educational content from
clinical trial informed consent forms. Using data from ClinicalTrials.gov, we
employed zero-shot learning for creating trial summaries and one-shot learning
for developing multiple-choice questions, evaluating their effectiveness
through patient surveys and crowdsourced annotation. Results showed that
GPT4-generated summaries were both readable and comprehensive, and may improve
patients' understanding and interest in clinical trials. The multiple-choice
questions demonstrated high accuracy and agreement with crowdsourced
annotators. For both resource types, hallucinations were identified that
require ongoing human oversight. The findings demonstrate the potential of LLMs
"out-of-the-box" to support the generation of clinical trial education
materials with minimal trial-specific engineering, but implementation with a
human-in-the-loop is still needed to avoid misinformation risks.

æè¦ï¼ççè¨åºè©¦é©ç±æ¼ç¼ºä¹é¢ååèèçè³è¨åæè²è³æºï¼å¸¸å¸¸å¨æåååèæ¹é¢é¢è¨ææ°ãæ¬ç ç©¶æ¢è¨äºå¤§åèªè¨æ¨¡å (LLM)ï¼ç¹å¥æ¯ GPT4ï¼å¾è¨åºè©¦é©ç¥æåææ¸ä¸­ç¢çå°æ£èååçæè²å§å®¹çæ½åãæåä½¿ç¨ä¾èª ClinicalTrials.gov çè³æï¼æ¡ç¨é¶æ¬¡å­¸ç¿ä¾å»ºç«è©¦é©æè¦ï¼ä»¥åä¸æ¬¡å­¸ç¿ä¾éç¼å¤é¸é¡ï¼ä¸¦ééæ£èèª¿æ¥åç¾¤ç¾å¤åè¨»è§£ä¾è©ä¼°å¶æææ§ãçµæé¡¯ç¤ºï¼GPT4 çæçæè¦å·æå¯è®æ§åå¨é¢æ§ï¼ä¸¦ä¸å¯è½æé«æ£èå°è¨åºè©¦é©ççè§£åèè¶£ãå¤é¸é¡å±ç¤ºåºå¾é«çæºç¢ºåº¦ï¼ä¸¦ä¸èç¾¤ç¾å¤åè¨»è§£èéæå±è­ãå°æ¼éå©ç¨®è³æºé¡åï¼æåç¼ç¾äºéè¦æçºçäººå·¥ç£ç£çå¹»è¦ºãéäºç¼ç¾å±ç¤ºäº LLMãéç®±å³ç¨ãçæ½åï¼å¯ä»¥ç¨æå°çè©¦é©ç¹å®å·¥ç¨ä¾æ¯æ´è¨åºè©¦é©æè²ææçç¢çï¼ä½ä»éè¦æ¡ç¨æäººå¨è¿´è·¯ä¸­çå¯¦ä½ä¾é¿åé¯èª¤è³è¨çé¢¨éªã

##### **Recurrent Neural Network on PICTURE Model**
2412.01933v1 by Weihan Xu

Intensive Care Units (ICUs) provide critical care and life support for most
severely ill and injured patients in the hospital. With the need for ICUs
growing rapidly and unprecedentedly, especially during COVID-19, accurately
identifying the most critical patients helps hospitals to allocate resources
more efficiently and save more lives. The Predicting Intensive Care Transfers
and Other Unforeseen Events (PICTURE) model predicts patient deterioration by
separating those at high risk for imminent intensive care unit transfer,
respiratory failure, or death from those at lower risk. This study aims to
implement a deep learning model to benchmark the performance from the XGBoost
model, an existing model which has competitive results on prediction.

æè¦ï¼å è­·çæ¿ (ICU) æä¾éçç§è­·åçå½æ¯æï¼çµ¦äºé«é¢ä¸­çææå´éååå·æå´éçæ£èãç±æ¼å°å è­·çæ¿çéæ±å¿«éä¸ç©ºåå°å¢é·ï¼ç¹å¥æ¯å¨ COVID-19 æéï¼æºç¢ºæ¾åºçææå±æ¥çæ£èæå©æ¼é«é¢æ´ææå°åéè³æºä¸¦æ½ææ´å¤çå½ãé æ¸¬å è­·çæ¿è½è¨ºåå¶ä»ç¡æ³é è¦äºä»¶ (PICTURE) æ¨¡åééå°é¢è¨è¿«å¨çç«çå è­·çæ¿è½è¨ºãå¼å¸è¡°ç«­ææ­»äº¡çé«é¢¨éªæ£èèé¢¨éªè¼ä½çæ£èååéä¾ï¼é æ¸¬æ£èæ¡åãæ¬ç ç©¶æ¨å¨å¯¦ä½æ·±åº¦å­¸ç¿æ¨¡åï¼ä»¥åºæºå XGBoost æ¨¡åçæè½ï¼å¾èæ¯ä¸ç¨®å¨é æ¸¬æ¹é¢å·æç«¶ç­åçç¾ææ¨¡åã

##### **ECG-SleepNet: Deep Learning-Based Comprehensive Sleep Stage Classification Using ECG Signals**
2412.01929v1 by Poorya Aghaomidi, Ge Wang

Accurate sleep stage classification is essential for understanding sleep
disorders and improving overall health. This study proposes a novel three-stage
approach for sleep stage classification using ECG signals, offering a more
accessible alternative to traditional methods that often rely on complex
modalities like EEG. In Stages 1 and 2, we initialize the weights of two
networks, which are then integrated in Stage 3 for comprehensive
classification. In the first phase, we estimate key features using Feature
Imitating Networks (FINs) to achieve higher accuracy and faster convergence.
The second phase focuses on identifying the N1 sleep stage through the
time-frequency representation of ECG signals. Finally, the third phase
integrates models from the previous stages and employs a Kolmogorov-Arnold
Network (KAN) to classify five distinct sleep stages. Additionally, data
augmentation techniques, particularly SMOTE, are used in enhancing
classification capabilities for underrepresented stages like N1. Our results
demonstrate significant improvements in the classification performance, with an
overall accuracy of 80.79% an overall kappa of 0.73. The model achieves
specific accuracies of 86.70% for Wake, 60.36% for N1, 83.89% for N2, 84.85%
for N3, and 87.16% for REM. This study emphasizes the importance of weight
initialization and data augmentation in optimizing sleep stage classification
with ECG signals.

æè¦ï¼ç²¾æºçç¡ç åæåé¡å°æ¼äºè§£ç¡ç éç¤åæ¹åæ´é«å¥åº·è³ééè¦ãæ¬ç ç©¶æåºä¸åæ°çä¸éæ®µæ¹æ³ï¼ä½¿ç¨ ECG è¨èé²è¡ç¡ç åæåé¡ï¼æä¾äºä¸åæ´ææ¼åå¾çæ¿ä»£æ¹æ¡ï¼å³çµ±æ¹æ³éå¸¸ä¾è³´æ¼ EEG ç­è¤éçæ¨¡å¼ãå¨ç¬¬ 1 åç¬¬ 2 éæ®µï¼æååå§åå©åç¶²è·¯çæ¬éï¼ç¶å¾å¨ç¬¬ 3 éæ®µæ´åå®åä»¥é²è¡å¨é¢çåé¡ãå¨ç¬¬ä¸éæ®µï¼æåä½¿ç¨ç¹å¾µæ¨¡ä»¿ç¶²è·¯ (FIN) ä¼°è¨ééµç¹å¾µï¼ä»¥å¯¦ç¾æ´é«çæºç¢ºåº¦åæ´å¿«çæ¶æãç¬¬äºéæ®µå°æ³¨æ¼éé ECG è¨èçæé »è¡¨ç¤ºä¾è­å¥ N1 ç¡ç éæ®µãæå¾ï¼ç¬¬ä¸éæ®µæ´ååä¸éæ®µçæ¨¡åï¼ä¸¦æ¡ç¨ Kolmogorov-Arnold ç¶²è·¯ (KAN) ä¾åé¡äºåä¸åçç¡ç éæ®µãæ­¤å¤ï¼è³ææ´åæè¡ï¼ç¹å¥æ¯ SMOTEï¼ç¨æ¼å¢å¼·å° N1 ç­ä»£è¡¨æ§ä¸è¶³éæ®µçåé¡è½åãæåççµæè­æäºåé¡æè½æé¡¯èçæ¹åï¼æ´é«æºç¢ºåº¦çº 80.79%ï¼æ´é« kappa çº 0.73ãè©²æ¨¡åå°æ¸éãN1ãN2ãN3 å REM çç¹å®æºç¢ºåº¦åå¥çº 86.70%ã60.36%ã83.89%ã84.85% å 87.16%ãæ¬ç ç©¶å¼·èª¿äºæ¬éåå§ååè³ææ´åå¨ä½¿ç¨ ECG è¨èæä½³åç¡ç åæåé¡ä¸­çéè¦æ§ã

##### **Deep Guess acceleration for explainable image reconstruction in sparse-view CT**
2412.01703v1 by Elena Loli Piccolomini, Davide Evangelista, Elena Morotti

Sparse-view Computed Tomography (CT) is an emerging protocol designed to
reduce X-ray dose radiation in medical imaging. Traditional Filtered Back
Projection algorithm reconstructions suffer from severe artifacts due to sparse
data. In contrast, Model-Based Iterative Reconstruction (MBIR) algorithms,
though better at mitigating noise through regularization, are too
computationally costly for clinical use. This paper introduces a novel
technique, denoted as the Deep Guess acceleration scheme, using a trained
neural network both to quicken the regularized MBIR and to enhance the
reconstruction accuracy. We integrate state-of-the-art deep learning tools to
initialize a clever starting guess for a proximal algorithm solving a
non-convex model and thus computing an interpretable solution image in a few
iterations. Experimental results on real CT images demonstrate the Deep Guess
effectiveness in (very) sparse tomographic protocols, where it overcomes its
mere variational counterpart and many data-driven approaches at the state of
the art. We also consider a ground truth-free implementation and test the
robustness of the proposed framework to noise.

æè¦ï¼ç¨çè¦åé»è¦æ·å±¤ææ (CT) æ¯ä¸ç¨®æ°èçåå®ï¼æ¨å¨æ¸å°é«çå½±åä¸­ç X å°ç·åéè¼»å°ãå³çµ±çæ¿¾æ³¢ååæå½±æ¼ç®æ³éå»ºå ç¨çè³æèå°è´å´éçå½å½±ãç¸æ¯ä¹ä¸ï¼åºæ¼æ¨¡åçè¿­ä»£éå»º (MBIR) æ¼ç®æ³ï¼éç¶ééæ­£ååå¨æ¸è¼éè¨æ¹é¢è¡¨ç¾å¾æ´å¥½ï¼ä½å°æ¼è¨åºä½¿ç¨èè¨ï¼å¶è¨ç®ææ¬éé«ãæ¬æä»ç´¹äºä¸ç¨®åµæ°çæè¡ï¼ç¨±çº Deep Guess å éæ¹æ¡ï¼å®ä½¿ç¨è¨ç·´éçé¡ç¥ç¶ç¶²è·¯ä¾å éæ­£ååç MBIR ä¸¦å¢å¼·éå»ºæºç¢ºåº¦ãæåæ´åäºæåé²çæ·±åº¦å­¸ç¿å·¥å·ï¼çºæ±è§£éå¸æ¨¡åçè¿ç«¯æ¼ç®æ³åå§åä¸åè°æçèµ·å§çæ¸¬ï¼å¾èåå¨å¹¾æ¬¡è¿­ä»£ä¸­è¨ç®åºå¯è§£éçè§£å½±åãå¨çå¯¦ CT å½±åä¸çå¯¦é©çµæè­æäº Deep Guess å¨ï¼éå¸¸ï¼ç¨çæ·å±¤æå½±åå®ä¸­çæææ§ï¼å¨è©²åå®ä¸­ï¼å®åæäºå¶å®ç´çè®åå°æç©åè¨±å¤æåé²çè³æé©åæ¹æ³ãæåéèæ®äºç¡çå¯¦ä¾æçå¯¦ä½ï¼ä¸¦æ¸¬è©¦äºææåºçæ¶æ§å°éè¨çç©©å¥æ§ã

##### **Digital Epidemiology: Leveraging Social Media for Insight into Epilepsy and Mental Health**
2412.01692v1 by Liza Dahiya, Rachit Bagga

Social media platforms, particularly Reddit's r/Epilepsy community, offer a
unique perspective into the experiences of individuals with epilepsy (PWE) and
their caregivers. This study analyzes 57k posts and 533k comments to explore
key themes across demographics such as age, gender, and relationships. Our
findings highlight significant discussions on epilepsy-related challenges,
including depression (with 39.75\% of posts indicating severe symptoms),
driving restrictions, workplace concerns, and pregnancy-related issues in women
with epilepsy. We introduce a novel engagement metric, F(P), which incorporates
post length, sentiment scores, and readability to quantify community
interaction. This analysis underscores the importance of integrated care
addressing both neurological and mental health challenges faced by PWE. The
insights from this study inform strategies for targeted support and awareness
interventions.

æè¦ï¼ç¤¾ç¾¤åªé«å¹³å°ï¼ç¹å¥æ¯ Reddit ç r/Epilepsy ç¤¾ç¾¤ï¼æä¾äºç²çæ£è (PWE) åå¶ç§é¡§èçç¶é©ç¨ç¹è§é»ãéé ç ç©¶åæäº 57k åè²¼æå 533k åçè¨ï¼æ¢è¨ä¸åäººå£çµ±è¨è³æï¼ä¾å¦å¹´é½¡ãæ§å¥åéä¿ï¼ä¸­çä¸»è¦ä¸»é¡ãæåçç¼ç¾å¼·èª¿äºéæ¼ç²çç¸éææ°çéè¦è¨è«ï¼åæ¬æé¬±çï¼39.75% çè²¼æè¡¨ç¤ºæå´éççï¼ãé§é§éå¶ãè·å ´åé¡åç²çå¥³æ§çæ·å­ç¸éåé¡ãæåå¼é²äºä¸é åµæ°çåèåº¦ææ¨ F(P)ï¼å®çµåäºè²¼æé·åº¦ãæç·åæ¸åå¯è®æ§ï¼ä»¥éåç¤¾ç¾¤äºåãéé åæå¼·èª¿äºæ´åæ§ç§è­·çéè¦æ§ï¼å®è½åæè§£æ±º PWE é¢è¨çç¥ç¶åå¿çå¥åº·ææ°ãéé ç ç©¶çè¦è§£æä¾äºéå°æ§æ¯æåæè­ä»å¥ç­ç¥ã

##### **Medchain: Bridging the Gap Between LLM Agents and Clinical Practice through Interactive Sequential Benchmarking**
2412.01605v1 by Jie Liu, Wenxuan Wang, Zizhan Ma, Guolin Huang, Yihang SU, Kao-Jung Chang, Wenting Chen, Haoliang Li, Linlin Shen, Michael Lyu

Clinical decision making (CDM) is a complex, dynamic process crucial to
healthcare delivery, yet it remains a significant challenge for artificial
intelligence systems. While Large Language Model (LLM)-based agents have been
tested on general medical knowledge using licensing exams and knowledge
question-answering tasks, their performance in the CDM in real-world scenarios
is limited due to the lack of comprehensive testing datasets that mirror actual
medical practice. To address this gap, we present MedChain, a dataset of 12,163
clinical cases that covers five key stages of clinical workflow. MedChain
distinguishes itself from existing benchmarks with three key features of
real-world clinical practice: personalization, interactivity, and
sequentiality. Further, to tackle real-world CDM challenges, we also propose
MedChain-Agent, an AI system that integrates a feedback mechanism and a
MCase-RAG module to learn from previous cases and adapt its responses.
MedChain-Agent demonstrates remarkable adaptability in gathering information
dynamically and handling sequential clinical tasks, significantly outperforming
existing approaches. The relevant dataset and code will be released upon
acceptance of this paper.

æè¦ï¼è¨åºæ±ºç­å¶å® (CDM) æ¯ä¸åè¤éãåæçéç¨ï¼å°æ¼é«çä¿å¥çæä¾è³ééè¦ï¼ç¶èå°æ¼äººå·¥æºæ§ç³»çµ±ä¾èªªï¼å®ä»ç¶æ¯ä¸é éå¤§çææ°ãéç¶å¤§åèªè¨æ¨¡å (LLM) åºç¤ä»£çå·²ä½¿ç¨å·ç§èè©¦åç¥è­åç­ä»»åå°ä¸è¬é«çç¥è­é²è¡äºæ¸¬è©¦ï¼ä½å®åå¨å¯¦éå ´æ¯ä¸­ç CDM ä¸­çè¡¨ç¾åå°ç¼ºä¹åæ å¯¦éé«çå¯¦åçç¶åæ¸¬è©¦è³æéçéå¶ãçºäºè§£æ±ºéåå·®è·ï¼æåæåºäº MedChainï¼éæ¯ä¸ååå« 12,163 åè¨åºæ¡ä¾çè³æéï¼æ¶µèäºè¨åºå·¥ä½æµç¨çäºåééµéæ®µãMedChain ä»¥ç¾å¯¦ä¸çè¨åºå¯¦åçä¸åééµç¹å¾µåå¥æ¼ç¾æçåºæºï¼åäººåãäºåæ§åé åºæ§ãæ­¤å¤ï¼çºäºæå°ç¾å¯¦ä¸çç CDM ææ°ï¼æåéæåºäº MedChain-Agentï¼éæ¯ä¸åæ´åäºåé¥æ©å¶å MCase-RAG æ¨¡çµçäººå·¥æºæ§ç³»çµ±ï¼ç¨æ¼å¾ååçæ¡ä¾ä¸­å­¸ç¿ä¸¦èª¿æ´å¶åæãMedChain-Agent å¨åææ¶éè³è¨åèçé åºæ§è¨åºä»»åæ¹é¢å±ç¾äºé¡¯èçé©ææ§ï¼é¡¯èåªæ¼ç¾ææ¹æ³ãç¸éçè³æéåç¨å¼ç¢¼å°å¨æ¬æè¢«æ¥åå¾ç¼å¸ã

##### **NCDD: Nearest Centroid Distance Deficit for Out-Of-Distribution Detection in Gastrointestinal Vision**
2412.01590v1 by Sandesh Pokhrel, Sanjay Bhandari, Sharib Ali, Tryphon Lambrou, Anh Nguyen, Yash Raj Shrestha, Angus Watson, Danail Stoyanov, Prashnna Gyawali, Binod Bhattarai

The integration of deep learning tools in gastrointestinal vision holds the
potential for significant advancements in diagnosis, treatment, and overall
patient care. A major challenge, however, is these tools' tendency to make
overconfident predictions, even when encountering unseen or newly emerging
disease patterns, undermining their reliability.
  We address this critical issue of reliability by framing it as an
out-of-distribution (OOD) detection problem, where previously unseen and
emerging diseases are identified as OOD examples. However, gastrointestinal
images pose a unique challenge due to the overlapping feature representations
between in- Distribution (ID) and OOD examples. Existing approaches often
overlook this characteristic, as they are primarily developed for natural image
datasets, where feature distinctions are more apparent. Despite the overlap, we
hypothesize that the features of an in-distribution example will cluster closer
to the centroids of their ground truth class, resulting in a shorter distance
to the nearest centroid. In contrast, OOD examples maintain an equal distance
from all class centroids. Based on this observation, we propose a novel
nearest-centroid distance deficit (NCCD) score in the feature space for
gastrointestinal OOD detection.
  Evaluations across multiple deep learning architectures and two publicly
available benchmarks, Kvasir2 and Gastrovision, demonstrate the effectiveness
of our approach compared to several state-of-the-art methods. The code and
implementation details are publicly available at:
https://github.com/bhattarailab/NCDD

æè¦ï¼æ·±åº¦å­¸ç¿å·¥å·æ´åå¨èè¸éè¦è¦ºä¸­ï¼å¨è¨ºæ·ãæ²»çåæ´é«çäººç§è­·æ¹é¢å·æé¡¯èé²å±çæ½åãç¶èï¼ä¸åéå¤§çææ°æ¯ï¼éäºå·¥å·å¾åæ¼ååºéåº¦èªä¿¡çé æ¸¬ï¼å³ä½¿å¨éå°æªè¦ææ°åºç¾çç¾çæ¨¡å¼æï¼ä¹æç ´å£å¶å¯é æ§ã
æåå°æ­¤å¯é æ§çééµåé¡ï¼æ¶æ§çºä¸åç°å¸¸åä½ (OOD) åµæ¸¬åé¡ï¼å¶ä¸­ä»¥åæªè¦åæ°åºç¾çç¾çè¢«è¦çº OOD ç¯ä¾ãç¶èï¼ç±æ¼åä½å§ (ID) å OOD ç¯ä¾ä¹éçéçç¹å¾µè¡¨ç¤ºï¼èè¸éå½±åæ§æäºä¸é ç¨ç¹çææ°ãç¾æçæ¹æ³éå¸¸å¿½ç¥æ­¤ç¹æ§ï¼å çºå®åä¸»è¦æ¯çºèªç¶å½±åè³æéèéç¼ï¼å¶ä¸­ç¹å¾µåå¥è¼çºæé¡¯ãåç®¡æéçï¼æååè¨­åä½å§ç¯ä¾çç¹å¾µæèéå¨å¶çå¯¦é¡å¥çè³ªå¿éè¿ï¼å°è´å°æè¿è³ªå¿çè·é¢è¼ç­ãç¸åå°ï¼OOD ç¯ä¾èææé¡å¥è³ªå¿çè·é¢ç¸ç­ãåºæ¼æ­¤è§å¯ï¼æåå¨ç¹å¾µç©ºéä¸­æåºäºä¸åç¨æ¼èè¸é OOD åµæ¸¬çæ°ç©æè¿è³ªå¿è·é¢å·® (NCCD) åæ¸ã
å¨å¤åæ·±åº¦å­¸ç¿æ¶æ§åå©åå¬éåºæº Kvasir2 å Gastrovision ä¸­çè©ä¼°ï¼è­æäºæåçæ¹æ³èå¹¾ç¨®æåé²çæ¹æ³ç¸æ¯çæææ§ãç¨å¼ç¢¼åå¯¦ä½ç´°ç¯å¬éæ¼ï¼
https://github.com/bhattarailab/NCDD

##### **MambaU-Lite: A Lightweight Model based on Mamba and Integrated Channel-Spatial Attention for Skin Lesion Segmentation**
2412.01405v1 by Thi-Nhu-Quynh Nguyen, Quang-Huy Ho, Duy-Thai Nguyen, Hoang-Minh-Quang Le, Van-Truong Pham, Thi-Thao Tran

Early detection of skin abnormalities plays a crucial role in diagnosing and
treating skin cancer. Segmentation of affected skin regions using AI-powered
devices is relatively common and supports the diagnostic process. However,
achieving high performance remains a significant challenge due to the need for
high-resolution images and the often unclear boundaries of individual lesions.
At the same time, medical devices require segmentation models to have a small
memory foot-print and low computational cost. Based on these requirements, we
introduce a novel lightweight model called MambaU-Lite, which combines the
strengths of Mamba and CNN architectures, featuring just over 400K parameters
and a computational cost of more than 1G flops. To enhance both global context
and local feature extraction, we propose the P-Mamba block, a novel component
that incorporates VSS blocks along-side multiple pooling layers, enabling the
model to effectively learn multiscale features and enhance segmentation
performance. We evaluate the model's performance on two skin datasets, ISIC2018
and PH2, yielding promising results. Our source code will be made publicly
available at: https://github.com/nqnguyen812/MambaU-Lite.

æè¦ï¼æ©æç®èç°å¸¸åµæ¸¬å¨è¨ºæ·åæ²»çç®èçä¸­æ®æ¼èè³ééè¦çè§è²ãä½¿ç¨ AI é©åçè£ç½®åå²åå½±é¿çç®èååç¸å°å¸¸è¦ï¼ä¸¦æ¯æ´è¨ºæ·æµç¨ãç¶èï¼ç±æ¼éè¦é«è§£æåº¦å½±åååå¥çç¶éå¸¸ä¸æç¢ºçéçï¼è¦éæé«æ§è½ä»æ¯ä¸é éå¤§çææ°ãåæï¼é«çè£ç½®è¦æ±åå²æ¨¡åå·æå°çè¨æ¶é«ä½ç¨ç©ºéåä½éç®ææ¬ãåºæ¼éäºéæ±ï¼æåå¼é²äºä¸ç¨®åçº MambaU-Lite çæ°åè¼éç´æ¨¡åï¼å®çµåäº Mamba å CNN æ¶æ§çåªé»ï¼ç¹é»æ¯åªæè¶é 400K ååæ¸åè¶é 1G flops çéç®ææ¬ãçºäºå¢å¼·å¨å±èæ¯åå±é¨ç¹å¾µèåï¼æåæåºäº P-Mamba å¡ï¼éæ¯ä¸åæ°ççµæé¨åï¼å®çµåäº VSS å¡åå¤åæ± åå±¤ï¼ä½¿æ¨¡åè½å¤ ææå°å­¸ç¿å¤å°ºåº¦ç¹å¾µä¸¦å¢å¼·åå²æ§è½ãæåå¨å©åç®èè³æé ISIC2018 å PH2 ä¸è©ä¼°äºæ¨¡åçæ§è½ï¼ç¢çäºæå¸æççµæãæåçåå§ç¨å¼ç¢¼å°å¬éæ¼ï¼https://github.com/nqnguyen812/MambaU-Liteã

##### **Su-RoBERTa: A Semi-supervised Approach to Predicting Suicide Risk through Social Media using Base Language Models**
2412.01353v1 by Chayan Tank, Shaina Mehta, Sarthak Pol, Vinayak Katoch, Avinash Anand, Raj Jaiswal, Rajiv Ratn Shah

In recent times, more and more people are posting about their mental states
across various social media platforms. Leveraging this data, AI-based systems
can be developed that help in assessing the mental health of individuals, such
as suicide risk. This paper is a study done on suicidal risk assessments using
Reddit data leveraging Base language models to identify patterns from social
media posts. We have demonstrated that using smaller language models, i.e.,
less than 500M parameters, can also be effective in contrast to LLMs with
greater than 500M parameters. We propose Su-RoBERTa, a fine-tuned RoBERTa on
suicide risk prediction task that utilized both the labeled and unlabeled
Reddit data and tackled class imbalance by data augmentation using GPT-2 model.
Our Su-RoBERTa model attained a 69.84% weighted F1 score during the Final
evaluation. This paper demonstrates the effectiveness of Base language models
for the analysis of the risk factors related to mental health with an efficient
computation pipeline

æè¦ï¼è¿ä¾ï¼æä¾æå¤äººæ¼åç¨®ç¤¾ç¾¤åªé«å¹³å°ç¼å¸å¶å¿ççæãå©ç¨æ­¤è³æï¼å¯ä»¥éç¼åºåºæ¼ AI çç³»çµ±ï¼ç¨æ¼è©ä¼°åäººçå¿çå¥åº·ï¼ä¾å¦èªæ®ºé¢¨éªãæ¬ææ¯ä¸é éå°èªæ®ºé¢¨éªè©ä¼°çç ç©¶ï¼å©ç¨ Reddit è³æï¼ä¸¦å©ç¨åºç¤èªè¨æ¨¡åä¾è­å¥ç¤¾ç¾¤åªé«è²¼æçæ¨¡å¼ãæåå·²ç¶è­æï¼ä½¿ç¨è¼å°çèªè¨æ¨¡åï¼å³å°æ¼ 5 åååæ¸ï¼ä¹å¯ä»¥ææï¼éèåæ¸å¤§æ¼ 5 ååç LLM ç¸æ¯ãæåæåº Su-RoBERTaï¼ä¸åéå°èªæ®ºé¢¨éªé æ¸¬ä»»åé²è¡å¾®èª¿ç RoBERTaï¼å®å©ç¨æ¨è¨åæªæ¨è¨ç Reddit è³æï¼ä¸¦ééä½¿ç¨ GPT-2 æ¨¡åé²è¡è³ææ´åä¾è§£æ±ºé¡å¥ä¸å¹³è¡¡çåé¡ãæåç Su-RoBERTa æ¨¡åå¨æçµè©ä¼°æéç²å¾äº 69.84% çå æ¬ F1 åæ¸ãæ¬æè­æäºåºç¤èªè¨æ¨¡åå¨åæèå¿çå¥åº·ç¸éçé¢¨éªå å­æ¹é¢çæææ§ï¼ä¸¦å·åé«æçéç®ç®¡é

##### **Multimodal Medical Disease Classification with LLaMA II**
2412.01306v1 by Christian Gapp, Elias Tappeiner, Martin Welk, Rainer Schubert

Medical patient data is always multimodal. Images, text, age, gender,
histopathological data are only few examples for different modalities in this
context. Processing and integrating this multimodal data with deep learning
based methods is of utmost interest due to its huge potential for medical
procedure such as diagnosis and patient treatment planning. In this work we
retrain a multimodal transformer-based model for disease classification. To
this end we use the text-image pair dataset from OpenI consisting of 2D chest
X-rays associated with clinical reports. Our focus is on fusion methods for
merging text and vision information extracted from medical datasets. Different
architecture structures with a LLaMA II backbone model are tested. Early fusion
of modality specific features creates better results with the best model
reaching 97.10% mean AUC than late fusion from a deeper level of the
architecture (best model: 96.67% mean AUC). Both outperform former
classification models tested on the same multimodal dataset. The newly
introduced multimodal architecture can be applied to other multimodal datasets
with little effort and can be easily adapted for further research, especially,
but not limited to, the field of medical AI.

æè¦ï¼é«ççæ£è³æç¸½æ¯å¤æ¨¡æçãå½±åãæå­ãå¹´é½¡ãæ§å¥ãçµç¹ççå­¸è³æåªæ¯æ­¤èçµ¡ä¸ä¸åæ¨¡æçå¹¾åä¾å­ãèçåæ´åéäºå¤æ¨¡æè³æï¼ä¸¦ä½¿ç¨æ·±åº¦å­¸ç¿æ¹æ³ï¼ç±æ¼å¶å¨é«çç¨åºï¼ä¾å¦è¨ºæ·åçæ£æ²»çè¨ç«ï¼çé¾å¤§æ½åï¼å æ­¤è³ééè¦ãå¨éé å·¥ä½ä¸­ï¼æåéæ°è¨ç·´ä¸åå¤æ¨¡æTransformeråºç¤æ¨¡åï¼ç¨æ¼ç¾çåé¡ãçºæ­¤ï¼æåä½¿ç¨ä¾èª OpenI çæå­å½±åéå°è³æéï¼å¶ä¸­åå«èè¨åºå ±åç¸éç 2D è¸é¨ X åãæåçéé»å¨æ¼èåæ¹æ³ï¼ç¨æ¼åä½µå¾é«çè³æéæåçæå­åå½±åè³è¨ãæ¸¬è©¦äºå·æ LLaMA II ä¸»å¹¹æ¨¡åçä¸åæ¶æ§çµæ§ãç¹å®æ¼æ¨¡æç¹å¾µçæ©æèåæç¢çæ´å¥½ççµæï¼æä½³æ¨¡åéå° 97.10% çå¹³å AUCï¼é«æ¼å¾æ¶æ§æ´æ·±å±¤æ¬¡é²è¡çå¾æèåï¼æä½³æ¨¡åï¼96.67% çå¹³å AUCï¼ãå©èé½åªæ¼å¨ç¸åå¤æ¨¡æè³æéä¸æ¸¬è©¦çååé¡æ¨¡åãæ°æ¨åºçå¤æ¨¡ææ¶æ§å¯ä»¥æ¯«ä¸è²»åå°æç¨æ¼å¶ä»å¤æ¨¡æè³æéï¼ä¸¦ä¸å¯ä»¥è¼é¬æ¹ç·¨ä»¥é²è¡é²ä¸æ­¥çç ç©¶ï¼ç¹å¥æ¯ï¼ä½ä¸éæ¼ï¼é«ç AI é åã

##### **Best Practices for Large Language Models in Radiology**
2412.01233v1 by Christian Bluethgen, Dave Van Veen, Cyril Zakka, Katherine Link, Aaron Fanous, Roxana Daneshjou, Thomas Frauenfelder, Curtis Langlotz, Sergios Gatidis, Akshay Chaudhari

At the heart of radiological practice is the challenge of integrating complex
imaging data with clinical information to produce actionable insights. Nuanced
application of language is key for various activities, including managing
requests, describing and interpreting imaging findings in the context of
clinical data, and concisely documenting and communicating the outcomes. The
emergence of large language models (LLMs) offers an opportunity to improve the
management and interpretation of the vast data in radiology. Despite being
primarily general-purpose, these advanced computational models demonstrate
impressive capabilities in specialized language-related tasks, even without
specific training. Unlocking the potential of LLMs for radiology requires basic
understanding of their foundations and a strategic approach to navigate their
idiosyncrasies. This review, drawing from practical radiology and machine
learning expertise and recent literature, provides readers insight into the
potential of LLMs in radiology. It examines best practices that have so far
stood the test of time in the rapidly evolving landscape of LLMs. This includes
practical advice for optimizing LLM characteristics for radiology practices
along with limitations, effective prompting, and fine-tuning strategies.

æè¦ï¼æ¾å°å­¸å¯¦åçæ ¸å¿ææ°ï¼å¨æ¼æ´åè¤éçå½±åè³æèè¨åºè³è¨ï¼ä»¥ç¢çå¯è¡çè¦è§£ãèªè¨çç´°ç·»éç¨æ¯åç¨®æ´»åçééµï¼åæ¬ç®¡çè«æ±ãæè¿°åè§£è®å½±åçµæçè¨åºè³æï¼ä»¥åç°¡æ½å°è¨éåå³éçµæãå¤§åèªè¨æ¨¡å (LLM) çåºç¾ï¼æä¾äºä¸åæ©æä¾æ¹åæ¾å°å­¸ä¸­å¤§éè³æçç®¡çåè§£è®ãåç®¡ä¸»è¦æ¯ä¸è¬ç¨éï¼éäºåé²çè¨ç®æ¨¡åå¨å°æ¥­çèªè¨ç¸éä»»åä¸­å±ç¾åºä»¤äººå°è±¡æ·±å»çè½åï¼å³ä½¿æ²æç¹å®çè¨ç·´ãè¦è§£é LLM å¨æ¾å°å­¸ä¸­çæ½åï¼éè¦åºæ¬äºè§£å¶åºç¤ï¼ä»¥åæå°å¶ç¨ç¹ä¹èçç­ç¥æ§æ¹æ³ãéç¯è©è«å¾å¯¦åæ¾å°å­¸åæ©å¨å­¸ç¿å°æ¥­ç¥è­ä»¥åè¿ææç»ä¸­æ±²åï¼çºè®èæä¾ LLM å¨æ¾å°å­¸ä¸­çæ½åçè¦è§£ãå®æª¢è¦äºè¿ä»çºæ­¢å¨ LLM å¿«éæ¼è®çé åä¸­ç¶å¾èµ·æéèé©çæä½³å¯¦åãéåæ¬éå°æ¾å°å­¸å¯¦åæä½³å LLM ç¹æ§çå¯¦åå»ºè­°ï¼ä»¥åéå¶ãææçæç¤ºåå¾®èª¿ç­ç¥ã

##### **Object Tracking in a $360^o$ View: A Novel Perspective on Bridging the Gap to Biomedical Advancements**
2412.01119v1 by Mojtaba S. Fazli, Shannon Quinn

Object tracking is a fundamental tool in modern innovation, with applications
in defense systems, autonomous vehicles, and biomedical research. It enables
precise identification, monitoring, and spatiotemporal analysis of objects
across sequential frames, providing insights into dynamic behaviors. In cell
biology, object tracking is vital for uncovering cellular mechanisms, such as
migration, interactions, and responses to drugs or pathogens. These insights
drive breakthroughs in understanding disease progression and therapeutic
interventions.
  Over time, object tracking methods have evolved from traditional
feature-based approaches to advanced machine learning and deep learning
frameworks. While classical methods are reliable in controlled settings, they
struggle in complex environments with occlusions, variable lighting, and high
object density. Deep learning models address these challenges by delivering
greater accuracy, adaptability, and robustness.
  This review categorizes object tracking techniques into traditional,
statistical, feature-based, and machine learning paradigms, with a focus on
biomedical applications. These methods are essential for tracking cells and
subcellular structures, advancing our understanding of health and disease. Key
performance metrics, including accuracy, efficiency, and adaptability, are
discussed. The paper explores limitations of current methods and highlights
emerging trends to guide the development of next-generation tracking systems
for biomedical research and broader scientific domains.

æè¦ï¼ç©ä»¶è¿½è¹¤æ¯ç¾ä»£åµæ°ä¸­çä¸é åºæ¬å·¥å·ï¼æç¨æ¼åé²ç³»çµ±ãèªåé§é§è»è¼åçç©é«å­¸ç ç©¶ä¸­ãå®è½ç²¾æºå°è¾¨è­ãç£æ§åæç©ºåæé£çºç«é¢ä¸­çç©ä»¶ï¼æä¾åæè¡çºçè¦è§£ãå¨ç´°èçç©å­¸ä¸­ï¼ç©ä»¶è¿½è¹¤å°æ¼æ­é²ç´°èæ©å¶è³ééè¦ï¼ä¾å¦é·ç§»ãäº¤äºä½ç¨åå°è¥ç©æçåé«çåæãéäºè¦è§£æ¨åäºå°ç¾çé²ç¨åæ²»çå¹²é ççè§£ççªç ´ã
é¨èæéçæ¨ç§»ï¼ç©ä»¶è¿½è¹¤æ¹æ³å·²å¾å³çµ±çåºæ¼ç¹å¾µçæ¹æ³æ¼è®çºåé²çæ©å¨å­¸ç¿åæ·±åº¦å­¸ç¿æ¶æ§ãéç¶å³çµ±æ¹æ³å¨åæ§ç°å¢ä¸­æ¯å¯é çï¼ä½å®åå¨æé®æãåç·è®ååç©ä»¶å¯åº¦é«çè¤éç°å¢ä¸­æéå°å°é£ãæ·±åº¦å­¸ç¿æ¨¡åééæä¾æ´é«çæºç¢ºæ§ãé©ææ§åé­¯æ£æ§ä¾æå°éäºææ°ã
æ¬ç¶è¿°å°ç©ä»¶è¿½è¹¤æè¡åçºå³çµ±ãçµ±è¨ãåºæ¼ç¹å¾µåæ©å¨å­¸ç¿ç¯ä¾ï¼éé»éæ³¨çç©é«å­¸æç¨ãéäºæ¹æ³å°æ¼è¿½è¹¤ç´°èåäºç´°èçµæ§è³ééè¦ï¼ä¿é²äºæåå°å¥åº·åç¾çççè§£ãè¨è«äºééµçæè½ææ¨ï¼åæ¬æºç¢ºæ§ãæçåé©ææ§ãæ¬ææ¢è¨äºç¶åæ¹æ³çå±éæ§ï¼ä¸¦éé»ä»ç´¹äºæ°èè¶¨å¢ï¼ä»¥æå°ä¸ä¸ä»£çç©é«å­¸ç ç©¶åæ´å»£æ³çç§å­¸é åè¿½è¹¤ç³»çµ±çéç¼ã

##### **Evaluating Automated Radiology Report Quality through Fine-Grained Phrasal Grounding of Clinical Findings**
2412.01031v2 by Razi Mahmood, Pingkun Yan, Diego Machado Reyes, Ge Wang, Mannudeep K. Kalra, Parisa Kaviani, Joy T. Wu, Tanveer Syeda-Mahmood

Several evaluation metrics have been developed recently to automatically
assess the quality of generative AI reports for chest radiographs based only on
textual information using lexical, semantic, or clinical named entity
recognition methods. In this paper, we develop a new method of report quality
evaluation by first extracting fine-grained finding patterns capturing the
location, laterality, and severity of a large number of clinical findings. We
then performed phrasal grounding to localize their associated anatomical
regions on chest radiograph images. The textual and visual measures are then
combined to rate the quality of the generated reports. We present results that
compare this evaluation metric with other textual metrics on a gold standard
dataset derived from the MIMIC collection and show its robustness and
sensitivity to factual errors.

æè¦ï¼æè¿å·²å¼ååºå ç§è¯ä¼°ææ ï¼ä»åºäºä½¿ç¨è¯æ³ãè¯­ä¹æä¸´åºå½åå®ä½è¯å«æ¹æ³çææ¬ä¿¡æ¯ï¼èªå¨è¯ä¼°è¸é¨ X åçççæå¼ AI æ¥åçè´¨éãå¨æ¬æä¸­ï¼æä»¬å¼åäºä¸ç§æ°çæ¥åè´¨éè¯ä¼°æ¹æ³ï¼é¦åæåç»ç²åº¦çåç°æ¨¡å¼ï¼ææå¤§éä¸´åºåç°çä½ç½®ãå·¦å³æ§åä¸¥éæ§ãç¶åï¼æä»¬æ§è¡ç­è¯­æ¥å°ä»¥å®ä½å¶å¨è¸é¨ X åçå¾åä¸çç¸å³è§£ååºåãç¶åå°ææ¬åè§è§æµéç¸ç»åï¼å¯¹çææ¥åçè´¨éè¿è¡è¯åãæä»¬å±ç¤ºäºå°æ­¤è¯ä¼°ææ ä¸å¶ä»ææ¬ææ å¨æºèª MIMIC éåçéæ åæ°æ®éä¸è¿è¡æ¯è¾çç»æï¼å¹¶å±ç¤ºäºå¶å¯¹äºå®éè¯¯çé²æ£æ§åæææ§ã

##### **Generative Language Models Potential for Requirement Engineering Applications: Insights into Current Strengths and Limitations**
2412.00959v1 by Summra Saleem, Muhammad Nabeel Asim, Ludger Van Elst, Andreas Dengel

Traditional language models have been extensively evaluated for software
engineering domain, however the potential of ChatGPT and Gemini have not been
fully explored. To fulfill this gap, the paper in hand presents a comprehensive
case study to investigate the potential of both language models for development
of diverse types of requirement engineering applications. It deeply explores
impact of varying levels of expert knowledge prompts on the prediction
accuracies of both language models. Across 4 different public benchmark
datasets of requirement engineering tasks, it compares performance of both
language models with existing task specific machine/deep learning predictors
and traditional language models. Specifically, the paper utilizes 4 benchmark
datasets; Pure (7,445 samples, requirements extraction),PROMISE (622 samples,
requirements classification), REQuestA (300 question answer (QA) pairs) and
Aerospace datasets (6347 words, requirements NER tagging). Our experiments
reveal that, in comparison to ChatGPT, Gemini requires more careful prompt
engineering to provide accurate predictions. Moreover, across requirement
extraction benchmark dataset the state-of-the-art F1-score is 0.86 while
ChatGPT and Gemini achieved 0.76 and 0.77,respectively. The State-of-the-art
F1-score on requirements classification dataset is 0.96 and both language
models 0.78. In name entity recognition (NER) task the state-of-the-art
F1-score is 0.92 and ChatGPT managed to produce 0.36, and Gemini 0.25.
Similarly, across question answering dataset the state-of-the-art F1-score is
0.90 and ChatGPT and Gemini managed to produce 0.91 and 0.88 respectively. Our
experiments show that Gemini requires more precise prompt engineering than
ChatGPT. Except for question-answering, both models under-perform compared to
current state-of-the-art predictors across other tasks.

æè¦ï¼å³çµ±èªè¨æ¨¡åå·²å»£æ³è©ä¼°è»é«å·¥ç¨é åï¼ä½ ChatGPT å Gemini çæ½åå°æªè¢«å®å¨æ¢ç´¢ãçºäºå¡«è£éåå·®è·ï¼æ¬ææåºäºå¨é¢çæ¡ä¾ç ç©¶ï¼ä»¥æ¢è¨éå©ç¨®èªè¨æ¨¡åå¨éç¼åç¨®éæ±å·¥ç¨æç¨ç¨å¼æ¹é¢çæ½åãå®æ·±å¥æ¢è¨äºä¸åå±¤ç´å°å®¶ç¥è­æç¤ºå°éå©ç¨®èªè¨æ¨¡åé æ¸¬ç²¾åº¦çå½±é¿ãå¨ 4 åä¸åçéæ±å·¥ç¨ä»»åå¬å±åºæºè³æéï¼å®æ¯è¼äºéå©ç¨®èªè¨æ¨¡åèç¾æä»»åç¹å®æ©å¨/æ·±åº¦å­¸ç¿é æ¸¬å¨åå³çµ±èªè¨æ¨¡åçæè½ãå·é«ä¾èªªï¼æ¬æå©ç¨ 4 ååºæºè³æéï¼Pureï¼7,445 åæ¨£æ¬ï¼éæ±èåï¼ãPROMISEï¼622 åæ¨£æ¬ï¼éæ±åé¡ï¼ãREQuestAï¼300 ååç­ (QA) å°ï¼åèªå¤ªè³æéï¼6347 åå­ï¼éæ± NER æ¨è¨ï¼ãæåçå¯¦é©é¡¯ç¤ºï¼è ChatGPT ç¸æ¯ï¼Gemini éè¦æ´ä»ç´°çæç¤ºå·¥ç¨æè½æä¾æºç¢ºçé æ¸¬ãæ­¤å¤ï¼å¨éæ±èååºæºè³æéï¼æåé²ç F1 åæ¸çº 0.86ï¼è ChatGPT å Gemini åå¥éå° 0.76 å 0.77ãéæ±åé¡è³æéçæåé² F1 åæ¸çº 0.96ï¼èéå©ç¨®èªè¨æ¨¡åé½çº 0.78ãå¨å½åå¯¦é«è­å¥ (NER) ä»»åä¸­ï¼æåé²ç F1 åæ¸çº 0.92ï¼è ChatGPT ç¢ç 0.36ï¼Gemini ç¢ç 0.25ãé¡ä¼¼å°ï¼å¨åç­è³æéï¼æåé²ç F1 åæ¸çº 0.90ï¼è ChatGPT å Gemini åå¥ç¢ç 0.91 å 0.88ãæåçå¯¦é©è¡¨æï¼Gemini éè¦æ¯ ChatGPT æ´ç²¾ç¢ºçæç¤ºå·¥ç¨ãé¤äºåç­ä¹å¤ï¼éå©åæ¨¡åå¨å¶ä»ä»»åçè¡¨ç¾é½ä½æ¼ç®åçææ°é æ¸¬å¨ã

##### **TSUBF-Net: Trans-Spatial UNet-like Network with Bi-direction Fusion for Segmentation of Adenoid Hypertrophy in CT**
2412.00787v1 by Rulin Zhou, Yingjie Feng, Guankun Wang, Xiaopin Zhong, Zongze Wu, Qiang Wu, Xi Zhang

Adenoid hypertrophy stands as a common cause of obstructive sleep
apnea-hypopnea syndrome in children. It is characterized by snoring, nasal
congestion, and growth disorders. Computed Tomography (CT) emerges as a pivotal
medical imaging modality, utilizing X-rays and advanced computational
techniques to generate detailed cross-sectional images. Within the realm of
pediatric airway assessments, CT imaging provides an insightful perspective on
the shape and volume of enlarged adenoids. Despite the advances of deep
learning methods for medical imaging analysis, there remains an emptiness in
the segmentation of adenoid hypertrophy in CT scans. To address this research
gap, we introduce TSUBF-Nett (Trans-Spatial UNet-like Network based on
Bi-direction Fusion), a 3D medical image segmentation framework. TSUBF-Net is
engineered to effectively discern intricate 3D spatial interlayer features in
CT scans and enhance the extraction of boundary-blurring features. Notably, we
propose two innovative modules within the U-shaped network architecture:the
Trans-Spatial Perception module (TSP) and the Bi-directional Sampling
Collaborated Fusion module (BSCF).These two modules are in charge of operating
during the sampling process and strategically fusing down-sampled and
up-sampled features, respectively. Furthermore, we introduce the Sobel loss
term, which optimizes the smoothness of the segmentation results and enhances
model accuracy. Extensive 3D segmentation experiments are conducted on several
datasets. TSUBF-Net is superior to the state-of-the-art methods with the lowest
HD95: 7.03, IoU:85.63, and DSC: 92.26 on our own AHSD dataset. The results in
the other two public datasets also demonstrate that our methods can robustly
and effectively address the challenges of 3D segmentation in CT scans.

æè¦ï¼èºæ¨£é«è¥å¤§æ¯åç«¥é»å¡æ§ç¡ç å¼å¸ä¸­æ­¢ä½éæ°£ç¶åå¾µçå¸¸è¦åå ãå¶ç¹å¾µçºæé¼¾ãé¼»å¡åçé·éç¤ãé»è¦æ·å±¤ææ (CT) æ¯ä¸ç¨®éè¦çé«å­¸å½±åæ¨¡å¼ï¼å©ç¨ X å°ç·ååé²çè¨ç®æè¡çæè©³ç´°çæ©«æ·é¢å½±åãå¨å°åæ°£éè©ä¼°é åï¼CT å½±åæä¾äºèºæ¨£é«è¥å¤§çå½¢çåé«ç©çæ·±å»è¦è§£ãåç®¡æ·±åº¦å­¸ç¿æ¹æ³å¨é«å­¸å½±ååææ¹é¢åå¾äºé²å±ï¼ä½ CT ææä¸­èºæ¨£é«è¥å¤§çåå²ä»å­å¨ç©ºç¼ºãçºäºè§£æ±ºéåç ç©¶å·®è·ï¼æåå¼å¥äº TSUBF-Nettï¼åºæ¼éåèåç Trans-Spatial UNet é¡ç¶²è·¯ï¼ï¼éæ¯ä¸å 3D é«å­¸å½±ååå²æ¡æ¶ãTSUBF-Net è¢«è¨­è¨çºææè­å¥ CT ææä¸­è¤éç 3D ç©ºéäºå±¤ç¹å¾µï¼ä¸¦å¢å¼·éçæ¨¡ç³ç¹å¾µçæåãå¼å¾æ³¨æçæ¯ï¼æåå¨ U å½¢ç¶²è·¯æ¶æ§ä¸­æåºäºå©ååµæ°çæ¨¡çµï¼Trans-Spatial æç¥æ¨¡çµ (TSP) åéåæ¡æ¨£åä½èåæ¨¡çµ (BSCF)ãéå©åæ¨¡çµè² è²¬å¨æ¡æ¨£éç¨ä¸­éä½ï¼ä¸¦åå¥ç­ç¥æ§å°èåä¸æ¡æ¨£åä¸æ¡æ¨£ç¹å¾µãæ­¤å¤ï¼æåå¼å¥äº Sobel æå¤±é ï¼å®åªåäºåå²çµæçå¹³æ»åº¦ä¸¦å¢å¼·äºæ¨¡åçæºç¢ºæ§ãå¨å¤åè³æéä¸é²è¡äºå»£æ³ç 3D åå²å¯¦é©ãTSUBF-Net åªæ¼æåé²çæ¹æ³ï¼å¨æåèªå·±ç AHSD è³æéä¸å·ææä½ç HD95ï¼7.03ãIoUï¼85.63 å DSCï¼92.26ãå¶ä»å©åå¬å±è³æéä¸­ççµæä¹è¡¨æï¼æåçæ¨¡åå¯ä»¥ç©©å¥ææå°è§£æ±º CT ææä¸­ 3D åå²çææ°ã

##### **Automating Feedback Analysis in Surgical Training: Detection, Categorization, and Assessment**
2412.00760v1 by Firdavs Nasriddinov, Rafal Kocielnik, Arushi Gupta, Cherine Yang, Elyssa Wong, Anima Anandkumar, Andrew Hung

This work introduces the first framework for reconstructing surgical dialogue
from unstructured real-world recordings, which is crucial for characterizing
teaching tasks. In surgical training, the formative verbal feedback that
trainers provide to trainees during live surgeries is crucial for ensuring
safety, correcting behavior immediately, and facilitating long-term skill
acquisition. However, analyzing and quantifying this feedback is challenging
due to its unstructured and specialized nature. Automated systems are essential
to manage these complexities at scale, allowing for the creation of structured
datasets that enhance feedback analysis and improve surgical education. Our
framework integrates voice activity detection, speaker diarization, and
automated speech recaognition, with a novel enhancement that 1) removes
hallucinations (non-existent utterances generated during speech recognition
fueled by noise in the operating room) and 2) separates speech from trainers
and trainees using few-shot voice samples. These aspects are vital for
reconstructing accurate surgical dialogues and understanding the roles of
operating room participants. Using data from 33 real-world surgeries, we
demonstrated the system's capability to reconstruct surgical teaching dialogues
and detect feedback instances effectively (F1 score of 0.79+/-0.07). Moreover,
our hallucination removal step improves feedback detection performance by ~14%.
Evaluation on downstream clinically relevant tasks of predicting Behavioral
Adjustment of trainees and classifying Technical feedback, showed performances
comparable to manual annotations with F1 scores of 0.82+/0.03 and 0.81+/0.03
respectively. These results highlight the effectiveness of our framework in
supporting clinically relevant tasks and improving over manual methods.

æè¦ï¼<paragraph>éé å·¥ä½ä»ç´¹äºç¬¬ä¸åç¨æ¼éå»ºæè¡å°è©±çæ¶æ§ï¼è©²æ¶æ§ä¾èªéçµæ§åççå¯¦ä¸çéé³ï¼éå°æ¼æè¿°æå­¸ä»»åè³ééè¦ãå¨å¤ç§å¹è¨ä¸­ï¼å¹è¨èå¨ç¾å ´æè¡æéååè¨èæä¾çå½¢ææ§è¨èªåé¥å°æ¼ç¢ºä¿å®å¨ãç«å³ç³¾æ­£è¡çºåä¿é²é·ææè½ç¿å¾è³ééè¦ãç¶èï¼ç±æ¼å¶éçµæ§ååå°æ¥­æ§è³ªï¼å°æ­¤åé¥é²è¡åæåéåå·æææ°æ§ãèªååç³»çµ±å°æ¼å¤§è¦æ¨¡ç®¡çéäºè¤éæ§è³ééè¦ï¼åè¨±åµå»ºçµæ§åçè³æéï¼ä»¥å¢å¼·åé¥åæä¸¦æ¹åå¤ç§æè²ãæåçæ¶æ§æ´åäºèªé³æ´»ååµæ¸¬ãèªªè©±èæ¥è¨åèªåèªé³è­å¥ï¼ä¸¦å·æä¸åæ°ç©çå¢å¼·åè½ï¼è©²åè½ 1) æ¶é¤äºå¹»è¦ºï¼å¨æè¡å®¤çåªé³å¼ç¼èªé³è­å¥æéç¢ççä¸å­å¨çèªå¥ï¼å 2) ä½¿ç¨å°æ¸èªé³æ¨£æ¬å°å¹è¨èååè¨èçèªé³åéãéäºæ¹é¢å°æ¼éå»ºæºç¢ºçæè¡å°è©±åçè§£æè¡å®¤åèèçè§è²è³ééè¦ãä½¿ç¨ä¾èª 33 æ¬¡çå¯¦æè¡çè³æï¼æåå±ç¤ºäºè©²ç³»çµ±éå»ºæè¡æå­¸å°è©±åæææª¢æ¸¬åé¥å¯¦ä¾çè½åï¼F1 åæ¸çº 0.79+/-0.07ï¼ãæ­¤å¤ï¼æåçå¹»è¦ºæ¶é¤æ­¥é©å°åé¥æª¢æ¸¬æè½æåäºç´ 14%ãå¨é æ¸¬åè¨èçè¡çºèª¿æ´ååé¡æè¡åé¥çä¸æ¸¸è¨åºç¸éä»»åçè©ä¼°ä¸­ï¼é¡¯ç¤ºåºè F1 åæ¸åå¥çº 0.82+/0.03 å 0.81+/0.03 çæåæ¨è¨»ç¸ç¶çæè½ãéäºçµæçªé¡¯äºæåçæ¶æ§å¨æ¯æ´è¨åºç¸éä»»ååæ¹é²æåæ¹æ³æ¹é¢çæææ§ã</paragraph>

##### **Fairness at Every Intersection: Uncovering and Mitigating Intersectional Biases in Multimodal Clinical Predictions**
2412.00606v1 by Resmi Ramachandranpillai, Kishore Sampath, Ayaazuddin Mohammad, Malihe Alikhani

Biases in automated clinical decision-making using Electronic Healthcare
Records (EHR) impose significant disparities in patient care and treatment
outcomes. Conventional approaches have primarily focused on bias mitigation
strategies stemming from single attributes, overlooking intersectional
subgroups -- groups formed across various demographic intersections (such as
race, gender, ethnicity, etc.). Rendering single-attribute mitigation
strategies to intersectional subgroups becomes statistically irrelevant due to
the varying distribution and bias patterns across these subgroups. The
multimodal nature of EHR -- data from various sources such as combinations of
text, time series, tabular, events, and images -- adds another layer of
complexity as the influence on minority groups may fluctuate across modalities.
In this paper, we take the initial steps to uncover potential intersectional
biases in predictions by sourcing extensive multimodal datasets, MIMIC-Eye1 and
MIMIC-IV ED, and propose mitigation at the intersectional subgroup level. We
perform and benchmark downstream tasks and bias evaluation on the datasets by
learning a unified text representation from multimodal sources, harnessing the
enormous capabilities of the pre-trained clinical Language Models (LM),
MedBERT, Clinical BERT, and Clinical BioBERT. Our findings indicate that the
proposed sub-group-specific bias mitigation is robust across different
datasets, subgroups, and embeddings, demonstrating effectiveness in addressing
intersectional biases in multimodal settings.

æè¦ï¼é»å­çæ­· (EHR) ä¸­èªååè¨åºæ±ºç­çåå·®æå°æ£èç§è­·åæ²»ççµæé æé¡¯èçå·®ç°ãå³çµ±æ¹æ³ä¸»è¦å°æ³¨æ¼å®ä¸å±¬æ§çåå·®ç·©è§£ç­ç¥ï¼å¿½ç¥äºäº¤åç¾¤é«ââå¨åç¨®äººå£çµ±è¨äº¤åé»ï¼ä¾å¦ç¨®æãæ§å¥ãç¨®æç­ï¼å½¢æçç¾¤é«ãç±æ¼éäºå­ç¾¤çåå¸ååå·®æ¨¡å¼ä¸åï¼å°å®ä¸å±¬æ§ç·©è§£ç­ç¥æç¨æ¼äº¤åå­ç¾¤å¨çµ±è¨ä¸è®å¾ç¡éç·è¦ãEHR çå¤æ¨¡ææ§è³ªââä¾èªåç¨®ä¾æºçæ¸æï¼ä¾å¦ææ¬ãæéåºåãè¡¨æ ¼ãäºä»¶åååççµåââå¢å äºå¦ä¸å±¤è¤éæ§ï¼å çºå°å°æ¸ç¾¤é«çå½±é¿å¯è½æå¨ä¸åæ¨¡å¼ä¹éæ³¢åãå¨æ¬æä¸­ï¼æåæ¡åäºåæ­¥æ­¥é©ï¼ééæ¡éå»£æ³çå¤æ¨¡ææ¸æé MIMIC-Eye1 å MIMIC-IV ED ä¾æ­ç¤ºé æ¸¬ä¸­çæ½å¨äº¤ååå·®ï¼ä¸¦æåºå¨äº¤åå­ç¾¤ç´å¥é²è¡ç·©è§£ãæåééå¾å¤æ¨¡æä¾æºå­¸ç¿çµ±ä¸çææ¬è¡¨ç¤ºï¼å©ç¨é è¨ç·´çè¨åºèªè¨æ¨¡å (LM)ãMedBERTãClinical BERT å Clinical BioBERT çå¼·å¤§åè½ï¼å°æ¸æéå·è¡ä¸¦åºæºä¸æ¸¸ä»»åååå·®è©ä¼°ãæåçç ç©¶çµæè¡¨æï¼ææåºçå­ç¾¤ç¹å®åå·®ç·©è§£å¨ä¸åçæ¸æéãå­ç¾¤ååµå¥ä¸­é½æ¯ç©©å¥çï¼è­æäºå¨å¤æ¨¡æè¨­ç½®ä¸­è§£æ±ºäº¤ååå·®çæææ§ã

##### **Opus: A Large Work Model for Complex Workflow Generation**
2412.00573v2 by ThÃ©o Fagnoni, Bellinda Mesbah, Mahsun Altin, Phillip Kingston

This paper introduces Opus, a novel framework for generating and optimizing
Workflows tailored to complex Business Process Outsourcing (BPO) use cases,
focusing on cost reduction and quality enhancement while adhering to
established industry processes and operational constraints. Our approach
generates executable Workflows from Intention, defined as the alignment of
Client Input, Client Output, and Process Context. These Workflows are
represented as Directed Acyclic Graphs (DAGs), with nodes as Tasks consisting
of sequences of executable Instructions, including tools and human expert
reviews. We adopt a two-phase methodology: Workflow Generation and Workflow
Optimization. In the Generation phase, Workflows are generated using a Large
Work Model (LWM) informed by a Work Knowledge Graph (WKG) that encodes
domain-specific procedural and operational knowledge. In the Optimization
phase, Workflows are transformed into Workflow Graphs (WFGs), where optimal
Workflows are determined through path optimization. Our experiments demonstrate
that state-of-the-art Large Language Models (LLMs) face challenges in reliably
retrieving detailed process data as well as generating industry-compliant
workflows. The key contributions of this paper include integrating a Work
Knowledge Graph (WKG) into a Large Work Model (LWM) to enable the generation of
context-aware, semantically aligned, structured and auditable Workflows. It
further introduces a two-phase approach that combines Workflow Generation from
Intention with graph-based Workflow Optimization. Finally, we present Opus
Alpha 1 Large and Opus Alpha 1 Small that outperform state-of-the-art LLMs by
38% and 29% respectively in Workflow Generation for a Medical Coding use case.

æè¦ï¼éç¯è«æä»ç´¹äº Opusï¼ä¸åç¨æ¼ç¢çåæä½³åå·¥ä½æµç¨çæ°ç©æ¶æ§ï¼å°çºè¤éçæ¥­åæµç¨å¤å (BPO) ä½¿ç¨æ¡ä¾éèº«æé ï¼éé»å¨æ¼éä½ææ¬åæååè³ªï¼åæéµå®æ¢å®çç¢æ¥­æµç¨åçééå¶ãæåçåæ³æ ¹ææåç¢çå¯å·è¡çå·¥ä½æµç¨ï¼æåå®ç¾©çºå®¢æ¶è¼¸å¥ãå®¢æ¶è¼¸åºåæµç¨èæ¯çå°é½ãéäºå·¥ä½æµç¨è¡¨ç¤ºçºæåç¡ç°å (DAG)ï¼ç¯é»çºåå«å¯å·è¡æä»¤åºåçä»»åï¼åæ¬å·¥å·åäººé¡å°å®¶çå¯©æ¥ãæåæ¡ç¨å©éæ®µæ¹æ³ï¼å·¥ä½æµç¨ç¢çåå·¥ä½æµç¨æä½³åãå¨ç¢çéæ®µï¼å·¥ä½æµç¨ä½¿ç¨å¤§åå·¥ä½æ¨¡å (LWM) ç¢çï¼è©²æ¨¡åç±ç·¨ç¢¼ç¹å®é åç¨åºåéä½ç¥è­çå·¥ä½ç¥è­å (WKG) æä¾è³è¨ãå¨æä½³åéæ®µï¼å·¥ä½æµç¨è½æçºå·¥ä½æµç¨å (WFG)ï¼å¶ä¸­ééè·¯å¾æä½³åä¾ç¢ºå®æä½³å·¥ä½æµç¨ãæåçå¯¦é©è¡¨æï¼æåé²çå¤§åèªè¨æ¨¡å (LLM) å¨å¯é å°æ·åè©³ç´°çæµç¨è³æä»¥åç¢çç¬¦åç¢æ¥­è¦ç¯çå·¥ä½æµç¨æ¹é¢é¢è¨ææ°ãéç¯è«æçä¸»è¦è²¢ç»åæ¬å°å·¥ä½ç¥è­å (WKG) æ´åå°å¤§åå·¥ä½æ¨¡å (LWM) ä¸­ï¼ä»¥ç¢çå·åæå¢æç¥ãèªç¾©å°é½ãçµæ§ååå¯ç¨½æ ¸çå·¥ä½æµç¨ãå®é²ä¸æ­¥ä»ç´¹äºä¸ç¨®å©éæ®µæ¹æ³ï¼å°åºæ¼æåçå·¥ä½æµç¨ç¢çèåºæ¼åå½¢çå·¥ä½æµç¨æä½³åç¸çµåãæå¾ï¼æåå±ç¤ºäº Opus Alpha 1 Large å Opus Alpha 1 Smallï¼å®åå¨é«çç·¨ç¢¼ä½¿ç¨æ¡ä¾ä¸­åå¥æ¯æåé²ç LLM å¨å·¥ä½æµç¨ç¢çæ¹é¢é«åº 38% å 29%ã

##### **Polish Medical Exams: A new dataset for cross-lingual medical knowledge transfer assessment**
2412.00559v1 by Åukasz Grzybowski, Jakub Pokrywka, MichaÅ CiesiÃ³Åka, Jeremi I. Kaczmarek, Marek Kubis

Large Language Models (LLMs) have demonstrated significant potential in
handling specialized tasks, including medical problem-solving. However, most
studies predominantly focus on English-language contexts. This study introduces
a novel benchmark dataset based on Polish medical licensing and specialization
exams (LEK, LDEK, PES) taken by medical doctor candidates and practicing
doctors pursuing specialization. The dataset was web-scraped from publicly
available resources provided by the Medical Examination Center and the Chief
Medical Chamber. It comprises over 24,000 exam questions, including a subset of
parallel Polish-English corpora, where the English portion was professionally
translated by the examination center for foreign candidates. By creating a
structured benchmark from these existing exam questions, we systematically
evaluate state-of-the-art LLMs, including general-purpose, domain-specific, and
Polish-specific models, and compare their performance against human medical
students. Our analysis reveals that while models like GPT-4o achieve near-human
performance, significant challenges persist in cross-lingual translation and
domain-specific understanding. These findings underscore disparities in model
performance across languages and medical specialties, highlighting the
limitations and ethical considerations of deploying LLMs in clinical practice.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å·²å±ç¾åºå¨èçå°æ¥­ä»»åï¼åæ¬é«çåé¡è§£æ±ºï¼æ¹é¢å·æçé¡¯èæ½åãç¶èï¼å¤§å¤æ¸ç ç©¶ä¸»è¦éæ³¨æ¼è±èªèªå¢ãæ¬ç ç©¶å¼å¥äºåºæ¼æ³¢è­é«å­¸è¨±å¯åå°ç§èè©¦ (LEKãLDEKãPES) çæ°åºæºè³æéï¼ç±é«å­¸åå£«åé¸äººåå¾äºå°ç§çå·æ¥­é«çåå ãè©²è³æéå¾é«å­¸èè©¦ä¸­å¿åé¦å¸­é«å­¸é¨éæä¾çå¬éè³æºä¸­é²è¡ç¶²è·¯æåãå®åå«è¶é 24,000 åèè©¦é¡ç®ï¼åæ¬æ³¢è­èª-è±èªèªæåº«çå­éï¼å¶ä¸­è±èªé¨åç±èè©¦ä¸­å¿çºå¤ç±èçå°æ¥­ç¿»è­¯ãééæ ¹æéäºç¾æèè©¦é¡ç®å»ºç«çµæ§ååºæºï¼æåç³»çµ±æ§å°è©ä¼°äºæåé²ç LLMï¼åæ¬éç¨ãç¹å®é ååç¹å®æ¼æ³¢è­çæ¨¡åï¼ä¸¦å°å¶æ§è½èäººé¡é«å­¸çé²è¡æ¯è¼ãæåçåæè¡¨æï¼åç®¡ GPT-4o ç­æ¨¡åéå°äºæ¥è¿äººé¡çæ§è½ï¼ä½è·¨èªè¨ç¿»è­¯åç¹å®é åçè§£ä¸­ä»ç¶å­å¨éå¤§ææ°ãéäºç¼ç¾å¼·èª¿äºè·¨èªè¨åé«å­¸å°æ¥­çæ¨¡åæ§è½å·®ç°ï¼çªé¡¯äºå¨è¨åºå¯¦è¸ä¸­é¨ç½² LLM çå±éæ§åå«çèéã

##### **Unveiling Performance Challenges of Large Language Models in Low-Resource Healthcare: A Demographic Fairness Perspective**
2412.00554v2 by Yue Zhou, Barbara Di Eugenio, Lu Cheng

This paper studies the performance of large language models (LLMs),
particularly regarding demographic fairness, in solving real-world healthcare
tasks. We evaluate state-of-the-art LLMs with three prevalent learning
frameworks across six diverse healthcare tasks and find significant challenges
in applying LLMs to real-world healthcare tasks and persistent fairness issues
across demographic groups. We also find that explicitly providing demographic
information yields mixed results, while LLM's ability to infer such details
raises concerns about biased health predictions. Utilizing LLMs as autonomous
agents with access to up-to-date guidelines does not guarantee performance
improvement. We believe these findings reveal the critical limitations of LLMs
in healthcare fairness and the urgent need for specialized research in this
area.

æè¦ï¼æ¬æç ç©¶å¤§åèªè¨æ¨¡å (LLM) çæè½ï¼ç¹å¥æ¯å¨è§£æ±ºçå¯¦ä¸ççé«çä¿å¥ä»»åæçäººå£çµ±è¨å¬å¹³æ§æ¹é¢ãæåä½¿ç¨ä¸ç¨®æµè¡çå­¸ç¿æ¶æ§ï¼å¨å­é ä¸åçé«çä¿å¥ä»»åä¸­è©ä¼°æåé²ç LLMï¼ä¸¦ç¼ç¾å° LLM æç¨æ¼çå¯¦ä¸ççé«çä¿å¥ä»»åææéå¤§ææ°ï¼ä»¥åä¸åäººå£çµ±è¨ç¾¤é«ä¹éæçºå­å¨å¬å¹³æ§åé¡ãæåéç¼ç¾ï¼æç¢ºæä¾äººå£çµ±è¨è³è¨æç¢çå¥½å£ååççµæï¼è LLM æ¨æ·æ­¤é¡ç´°ç¯çè½åå¼ç¼äºå°æåå·®çå¥åº·é æ¸¬çææãå©ç¨ LLM ä½çºå·æå­åææ°æåçèªä¸»ä»£çä¸¦ä¸ä¿è­æè½ææåãæåç¸ä¿¡éäºç¼ç¾æ­ç¤ºäº LLM å¨é«çä¿å¥å¬å¹³æ§æ¹é¢çéå¤§éå¶ï¼ä»¥åå°æ­¤é åé²è¡å°éç ç©¶çè¿«åéè¦ã

##### **2-Factor Retrieval for Improved Human-AI Decision Making in Radiology**
2412.00372v1 by Jim Solomon, Laleh Jalilian, Alexander Vilesov, Meryl Mathew, Tristan Grogan, Arash Bedayat, Achuta Kadambi

Human-machine teaming in medical AI requires us to understand to what degree
a trained clinician should weigh AI predictions. While previous work has shown
the potential of AI assistance at improving clinical predictions, existing
clinical decision support systems either provide no explainability of their
predictions or use techniques like saliency and Shapley values, which do not
allow for physician-based verification. To address this gap, this study
compares previously used explainable AI techniques with a newly proposed
technique termed '2-factor retrieval (2FR)', which is a combination of
interface design and search retrieval that returns similarly labeled data
without processing this data. This results in a 2-factor security blanket
where: (a) correct images need to be retrieved by the AI; and (b) humans should
associate the retrieved images with the current pathology under test. We find
that when tested on chest X-ray diagnoses, 2FR leads to increases in clinician
accuracy, with particular improvements when clinicians are radiologists and
have low confidence in their decision. Our results highlight the importance of
understanding how different modes of human-AI decision making may impact
clinician accuracy in clinical decision support systems.

æè¦ï¼äººæ©åä½å¨é«ç AI ä¸­ï¼éè¦æåçè§£åéè¨ç·´çè¨åºé«çå¨å¤å¤§ç¨åº¦ä¸æéè¦ AI é æ¸¬ãéç¶ååçç ç©¶é¡¯ç¤º AI è¼å©å¨æ¹åè¨åºé æ¸¬æ¹é¢çæ½åï¼ä½ç¾æçè¨åºæ±ºç­æ¯æ´ç³»çµ±ï¼è¦ä¸å°±æ²ææä¾é æ¸¬çå¯è§£éæ§ï¼è¦ä¸å°±æ¯ä½¿ç¨åé¡¯èæ§å Shapley å¼ä¹é¡çæè¡ï¼éäºæè¡ä¸åè¨±åºæ¼é«ççé©è­ãçºäºè§£æ±ºéåå·®è·ï¼æ¬ç ç©¶å°ååä½¿ç¨çå¯è§£é AI æè¡èä¸ç¨®æ°æåºçç¨±çºã2 å å­æª¢ç´¢ (2FR)ãçæè¡é²è¡æ¯è¼ï¼å¾èæ¯ä¸ç¨®ä»é¢è¨­è¨åæå°æª¢ç´¢ççµåï¼å®æå³åæ¨ç±¤ç¸ä¼¼çè³æï¼èä¸æèçéäºè³æãéæç¢çä¸å 2 å å­å®å¨æ©å¶ï¼å¶ä¸­ï¼(a) æ­£ç¢ºçå½±åéè¦ç± AI æª¢ç´¢ï¼(b) äººé¡æå°æª¢ç´¢çå½±åèæ­£å¨æ¸¬è©¦ä¸­çççè¯æ³èµ·ä¾ãæåç¼ç¾ï¼ç¶å¨è¸é¨ X åè¨ºæ·ä¸é²è¡æ¸¬è©¦æï¼2FR ææé«è¨åºé«ççæºç¢ºåº¦ï¼ç¹å¥æ¯å¨è¨åºé«çæ¯æ¾å°ç§é«çä¸å°å¶æ±ºç­ä¿¡å¿ä¸è¶³æï¼ææé¡¯èçæ¹åãæåççµæå¼·èª¿äºçè§£äººæ©æ±ºç­çä¸åæ¨¡å¼å¦ä½å½±é¿è¨åºé«çå¨è¨åºæ±ºç­æ¯æ´ç³»çµ±ä¸­çæºç¢ºæ§çéè¦æ§ã

##### **One Model for One Graph: A New Perspective for Pretraining with Cross-domain Graphs**
2412.00315v1 by Jingzhe Liu, Haitao Mao, Zhikai Chen, Wenqi Fan, Mingxuan Ju, Tong Zhao, Neil Shah, Jiliang Tang

Graph Neural Networks (GNNs) have emerged as a powerful tool to capture
intricate network patterns, achieving success across different domains.
However, existing GNNs require careful domain-specific architecture designs and
training from scratch on each dataset, leading to an expertise-intensive
process with difficulty in generalizing across graphs from different domains.
Therefore, it can be hard for practitioners to infer which GNN model can
generalize well to graphs from their domains. To address this challenge, we
propose a novel cross-domain pretraining framework, "one model for one graph,"
which overcomes the limitations of previous approaches that failed to use a
single GNN to capture diverse graph patterns across domains with significant
gaps. Specifically, we pretrain a bank of expert models, with each one
corresponding to a specific dataset. When inferring to a new graph, gating
functions choose a subset of experts to effectively integrate prior model
knowledge while avoiding negative transfer. Extensive experiments consistently
demonstrate the superiority of our proposed method on both link prediction and
node classification tasks.

æè¦ï¼åå½¢ç¥ç¶ç¶²è·¯ (GNN) å·²æçºææè¤éç¶²è·¯æ¨¡å¼çå¼·å¤§å·¥å·ï¼å¨ä¸åé åçåå¾æåã
ç¶èï¼ç¾æç GNN éè¦ä»ç´°çç¹å®æ¼é åçæ¶æ§è¨­è¨ï¼ä¸¦éå°æ¯åè³æéå¾é ­éå§è¨ç·´ï¼å°è´å°æ¥­ç¥è­å¯éçéç¨ï¼é£ä»¥æ¦æ¬ä¾èªä¸åé åçåå½¢ã
å æ­¤ï¼å¾æ¥­èå¾é£æ¨æ·åªå GNN æ¨¡åå¯ä»¥å¾å¥½å°æ¦æ¬å°å¶é åçåå½¢ãçºäºæå°éä¸ææ°ï¼æåæåºäºä¸åæ°ç©çè·¨é åé è¨ç·´æ¡æ¶ï¼ãä¸åæ¨¡åå°æä¸ååå½¢ãï¼å®åæäºååæ¹æ³çéå¶ï¼éäºéå¶ç¡æ³ä½¿ç¨å®å GNN ä¾ææè·¨è¶å·æé¡¯èå·®è·çé åçä¸ååå½¢æ¨¡å¼ãå·é«ä¾èªªï¼æåé è¨ç·´äºä¸çµå°å®¶æ¨¡åï¼æ¯ä¸åé½å°æä¸åç¹å®è³æéãå¨æ¨è«å°ä¸åæ°åå½¢æï¼éæ§å½æ¸æé¸æä¸åå°å®¶å­éï¼ä»¥æææ´åååçæ¨¡åç¥è­ï¼åæé¿åè² é¢å³éãå»£æ³çå¯¦é©æçºè­æäºæåæåºçæ¹æ³å¨é£çµé æ¸¬åç¯é»åé¡ä»»åä¸çåªè¶æ§ã

##### **BOTS: Batch Bayesian Optimization of Extended Thompson Sampling for Severely Episode-Limited RL Settings**
2412.00308v1 by Karine Karine, Susan A. Murphy, Benjamin M. Marlin

In settings where the application of reinforcement learning (RL) requires
running real-world trials, including the optimization of adaptive health
interventions, the number of episodes available for learning can be severely
limited due to cost or time constraints. In this setting, the bias-variance
trade-off of contextual bandit methods can be significantly better than that of
more complex full RL methods. However, Thompson sampling bandits are limited to
selecting actions based on distributions of immediate rewards. In this paper,
we extend the linear Thompson sampling bandit to select actions based on a
state-action utility function consisting of the Thompson sampler's estimate of
the expected immediate reward combined with an action bias term. We use batch
Bayesian optimization over episodes to learn the action bias terms with the
goal of maximizing the expected return of the extended Thompson sampler. The
proposed approach is able to learn optimal policies for a strictly broader
class of Markov decision processes (MDPs) than standard Thompson sampling.
Using an adaptive intervention simulation environment that captures key aspects
of behavioral dynamics, we show that the proposed method can significantly
out-perform standard Thompson sampling in terms of total return, while
requiring significantly fewer episodes than standard value function and policy
gradient methods.

æè¦ï¼å¨éè¦ä½¿ç¨å¼·åå­¸ç¿ (RL) é²è¡å¯¦éä¸çè©¦é©ï¼åæ¬æä½³åé©ææ§å¥åº·å¹²é æªæ½çè¨­å®ä¸­ï¼å¯ç¨æ¼å­¸ç¿çååæ¸å¯è½æå çºææ¬ææééå¶èåå°å´ééå¶ãå¨æ­¤è¨­å®ä¸­ï¼æå¢å¼·çæ¹æ³çåå·®è®ç°åæ¨æé¡¯èåªæ¼æ´è¤éçå®æ´ RL æ¹æ³ãä¸éï¼æ¹¯æ®æ£®æ½æ¨£å¼·çåªè½æ ¹æç«å³çåµçåéä¾é¸æè¡åãå¨æ¬æä¸­ï¼æåå»¶ä¼¸ç·æ§æ¹¯æ®æ£®æ½æ¨£å¼·çï¼ä»¥æ ¹æçæè¡åæç¨å½æ¸é¸æè¡åï¼è©²å½æ¸åå«æ¹¯æ®æ£®æ¡æ¨£å¨å°é æç«å³çåµçä¼°è¨å¼ï¼ä»¥ååä½åå·®é ãæåä½¿ç¨æ¹æ¬¡è²æ°æä½³åå¨ååä¸­å­¸ç¿åä½åå·®é ï¼ç®æ¨æ¯æå¤§åå»¶ä¼¸æ¹¯æ®æ£®æ¡æ¨£å¨çé æåå ±ãæåºçæ¹æ³è½å¤ çºæ¯æ¨æºæ¹¯æ®æ£®æ½æ¨£æ´å»£æ³çé¦¬å¯å¤«æ±ºç­ç¨åº (MDP) é¡å¥å­¸ç¿æä½³ç­ç¥ãä½¿ç¨ææè¡çºåæééµå±¤é¢çé©ææ§å¹²é æ¨¡æ¬ç°å¢ï¼æåè­æææåºçæ¹æ³å¨ç¸½åå ±æ¹é¢å¯ä»¥é¡¯èåªæ¼æ¨æºæ¹¯æ®æ£®æ½æ¨£ï¼åææéååæ¸é å°æ¼æ¨æºå¹å¼å½æ¸åç­ç¥æ¢¯åº¦æ¹æ³ã

##### **Fine Tuning Large Language Models to Deliver CBT for Depression**
2412.00251v1 by Talha Tahir

Cognitive Behavioral Therapy (CBT) is a well-established, evidence-based
treatment for Major Depressive Disorder. Unfortunately, there exist significant
barriers to individuals accessing CBT, including cost, scarcity of therapists
and stigma. This study explores the feasibility of fine-tuning small open
weight large language models (LLMs) to deliver CBT for depression. Using 58
sets of synthetic CBT transcripts generated by the Nous Research fine-tune of
Llama 3.1 405b, we fine-tuned three models: Mistral 7b v0.3, Qwen 2.5 7b, and
Llama 3.1 8b. CBT fidelity was evaluated through a modified Cognitive Therapy
Rating Scale (CTRS). All fine-tuned models were compared against each other, as
well as their instruct-tuned variants. Simulated patient transcripts were
generated for the purpose of evaluating model performance, with the instruct
and CBT-tuned models acting as the therapist and DeepSeek-V2.5 acting as the
patient. These simulated transcripts were evaluated on a modified CTRS by
Gemini 1.5 Pro-002. Our findings demonstrated that the CBT-tuned models
significantly outperformed their instruct-tuned counterparts, with an average
improvement of 11.33 points (p < 0.001) on total CTRS score. Llama 3.1 8b had
the strongest performance (mean CTRS score 67.86 +/- 7.24), followed by Qwen
2.5 7b (64.28 +/- 9.55) and Mistral 7b v0.3 (64.17 +/- 9.79), with these
differences between models being statistically significant. The CBT-tuned
models were competent in implementing core CBT techniques and providing
empathetic responses, however, there were limitations observed in agenda
adherence, exploration depth and long-context coherence. This study establishes
that CBT specific fine-tuning can effectively encode therapeutic competencies
in small LLMs, though significant technical and ethical considerations must be
resolved prior to clinical deployment.

æè¦ï¼<paragraph>èªç¥è¡çºçæ³ (CBT) æ¯ä¸ç¨®æ²»çéåº¦æé¬±ççå®åä¸æå¯¦è­åºç¤ççæ³ãä¸å¹¸çæ¯ï¼åäººæ¥å CBT ä»å­å¨éå¤§éç¤ï¼åæ¬è²»ç¨ãæ²»çå¸«ç¨ç¼ºåæ±ååãæ¬ç ç©¶æ¢è¨å¾®èª¿å°åéæ¾å¼æ¬éå¤§åèªè¨æ¨¡å (LLM) ä»¥æä¾ CBT æ²»çæé¬±ççå¯è¡æ§ãä½¿ç¨ Nous Research å¾®èª¿ Llama 3.1 405b æç¢çç 58 çµåæ CBT è¬æ¬ï¼æåå¾®èª¿äºä¸åæ¨¡åï¼Mistral 7b v0.3ãQwen 2.5 7b å Llama 3.1 8bãCBT ä¿çåº¦ééä¿®æ­£å¾çèªç¥æ²»çè©åéè¡¨ (CTRS) é²è¡è©ä¼°ãææå¾®èª¿æ¨¡åå½¼æ­¤æ¯è¼ï¼ä»¥åå®åçæä»¤å¾®èª¿è®é«ãæ¨¡æ¬æ£èè¬æ¬æ¯çºäºè©ä¼°æ¨¡åæè½èç¢ççï¼æä»¤å CBT å¾®èª¿æ¨¡åæ®æ¼æ²»çå¸«ï¼è DeepSeek-V2.5 æ®æ¼æ£èãéäºæ¨¡æ¬è¬æ¬ç± Gemini 1.5 Pro-002 ä½¿ç¨ä¿®æ­£å¾ç CTRS é²è¡è©ä¼°ãæåçç ç©¶çµæé¡¯ç¤ºï¼CBT å¾®èª¿æ¨¡åé¡¯èåªæ¼å¶æä»¤å¾®èª¿æ¨¡åï¼CTRS ç¸½åå¹³åæå 11.33 å (p < 0.001)ãLlama 3.1 8b æè½æå¼· (CTRS å¹³ååæ¸ 67.86 +/- 7.24)ï¼å¶æ¬¡æ¯ Qwen 2.5 7b (64.28 +/- 9.55) å Mistral 7b v0.3 (64.17 +/- 9.79)ï¼éäºæ¨¡åä¹éçå·®ç°å·æçµ±è¨é¡¯èæ§ãCBT å¾®èª¿æ¨¡åå¨å¯¦æ½æ ¸å¿ CBT æè¡åæä¾åçåææ¹é¢è¡¨ç¾å¾å¾å¥½ï¼ç¶èå¨è­°ç¨éµå¾ªãæ¢ç´¢æ·±åº¦åé·èçµ¡é£è²«æ§æ¹é¢ä»æè§å¯å°çéå¶ãæ¬ç ç©¶è­å¯¦ï¼ç¹å®æ¼ CBT çå¾®èª¿å¯ä»¥ææå°å°æ²»çè½åç·¨ç¢¼å°å°å LLM ä¸­ï¼åç®¡å¨è¨åºé¨ç½²ä¹åå¿é è§£æ±ºéå¤§çæè¡åå«çèéã</paragraph>

##### **Integrating Social Determinants of Health into Knowledge Graphs: Evaluating Prediction Bias and Fairness in Healthcare**
2412.00245v1 by Tianqi Shang, Weiqing He, Tianlong Chen, Ying Ding, Huanmei Wu, Kaixiong Zhou, Li Shen

Social determinants of health (SDoH) play a crucial role in patient health
outcomes, yet their integration into biomedical knowledge graphs remains
underexplored. This study addresses this gap by constructing an SDoH-enriched
knowledge graph using the MIMIC-III dataset and PrimeKG. We introduce a novel
fairness formulation for graph embeddings, focusing on invariance with respect
to sensitive SDoH information. Via employing a heterogeneous-GCN model for
drug-disease link prediction, we detect biases related to various SDoH factors.
To mitigate these biases, we propose a post-processing method that
strategically reweights edges connected to SDoHs, balancing their influence on
graph representations. This approach represents one of the first comprehensive
investigations into fairness issues within biomedical knowledge graphs
incorporating SDoH. Our work not only highlights the importance of considering
SDoH in medical informatics but also provides a concrete method for reducing
SDoH-related biases in link prediction tasks, paving the way for more equitable
healthcare recommendations. Our code is available at
\url{https://github.com/hwq0726/SDoH-KG}.

æè¦ï¼ç¤¾æå¥åº·æ±ºå®å ç´ ï¼SDoHï¼å¨æ£èå¥åº·çµæä¸­æ®æ¼èè³ééè¦çè§è²ï¼ä½å®åæ´åå°çç©é«å­¸ç¥è­åè­ä¸­çé¨åä»æå¾æ¢è¨ãæ¬ç ç©¶ééä½¿ç¨ MIMIC-III è³æéå PrimeKG å»ºæ§ä¸å SDoH è±å¯çç¥è­åè­ä¾è§£æ±ºéåå·®è·ãæåéå°åå½¢åµå¥å¼å¥ä¸åæ°çå¬å¹³æ§å¬å¼ï¼å°æ³¨æ¼å°ææç SDoH è³è¨ä¿æä¸è®æ§ãééæ¡ç¨ç°è³ª GCN æ¨¡åé²è¡è¥ç©ç¾çé£çµé æ¸¬ï¼æååµæ¸¬å°èåç¨® SDoH å å­ç¸éçåå·®ãçºäºæ¸è¼éäºåå·®ï¼æåæåºä¸åå¾èçæ¹æ³ï¼è©²æ¹æ³ç­ç¥æ§å°éæ°å æ¬é£æ¥å° SDoH çéç·£ï¼å¹³è¡¡å®åå°åè¡¨è¡¨ç¤ºçå½±é¿ãæ­¤æ¹æ³ä»£è¡¨äºå° SDoH ç´å¥çç©é«å­¸ç¥è­åè­ä¸­å¬å¹³æ§åé¡çç¬¬ä¸åå¨é¢èª¿æ¥ä¹ä¸ãæåçç ç©¶ä¸åå¼·èª¿äºå¨é«å­¸è³è¨å­¸ä¸­èé SDoH çéè¦æ§ï¼ä¹æä¾äºä¸åå·é«çæ¹æ³ä¾æ¸å°é£çµé æ¸¬ä»»åä¸­è SDoH ç¸éçåå·®ï¼çºæ´å¬å¹³çé«çä¿å¥å»ºè­°éªè·¯ãæåçç¨å¼ç¢¼å¯å¨ \url{https://github.com/hwq0726/SDoH-KG} åå¾ã

##### **Dynamic EEG-fMRI mapping: Revealing the relationship between brain connectivity and cognitive state**
2411.19922v1 by Guiran Liu, Binrong Zhu

This study investigated the dynamic connectivity patterns between EEG and
fMRI modalities, contributing to our understanding of brain network
interactions. By employing a comprehensive approach that integrated static and
dynamic analyses of EEG-fMRI data, we were able to uncover distinct
connectivity states and characterize their temporal fluctuations. The results
revealed modular organization within the intrinsic connectivity networks (ICNs)
of the brain, highlighting the significant roles of sensory systems and the
default mode network. The use of a sliding window technique allowed us to
assess how functional connectivity varies over time, further elucidating the
transient nature of brain connectivity. Additionally, our findings align with
previous literature, reinforcing the notion that cognitive states can be
effectively identified through short-duration data, specifically within the
30-60 second timeframe. The established relationships between connectivity
strength and cognitive processes, particularly during different visual states,
underscore the relevance of our approach for future research into brain
dynamics. Overall, this study not only enhances our understanding of the
interplay between EEG and fMRI signals but also paves the way for further
exploration into the neural correlates of cognitive functions and their
implications in clinical settings. Future research should focus on refining
these methodologies and exploring their applications in various cognitive and
clinical contexts.

æè¦ï¼æ¬ç ç©¶èª¿æ¥äºè¦é»åååè½æ§ç£æ¯é å½±ä¹éçåæé£æ¥æ¨¡å¼ï¼æå©æ¼æåäºè§£è¦ç¶²è·¯äºåãééæ¡ç¨æ´åéæååæè¦é»ååè½æ§ç£æ¯é å½±è³æåæçç¶åæ¹æ³ï¼æåå¾ä»¥æ­ç¤ºä¸åçé£æ¥çæä¸¦æè¿°å¶æéæ³¢åãçµæé¡¯ç¤ºè¦é¨å§å¨é£æ¥ç¶²è·¯ (ICN) ä¸­çæ¨¡çµåçµç¹ï¼çªé¡¯äºæå®ç³»çµ±åé è¨­æ¨¡å¼ç¶²è·¯çéè¦è§è²ãæ»åè¦çªæè¡çä½¿ç¨è®æåå¾ä»¥è©ä¼°åè½æ§é£æ¥å¦ä½é¨æéè®åï¼é²ä¸æ­¥é¡æè¦é¨é£æ¥çæ«ææ§ãæ­¤å¤ï¼æåçç ç©¶çµæèååçæç»ä¸è´ï¼å¼·åäºééç­æè³æï¼ç¹å¥æ¯å¨ 30-60 ç§çæéç¯åå§ï¼å¯ä»¥ææè­å¥èªç¥çæçæ¦å¿µãé£æ¥å¼·åº¦åèªç¥éç¨ä¹éå»ºç«çéä¿ï¼ç¹å¥æ¯å¨ä¸åçè¦è¦ºçæä¸ï¼å¼·èª¿äºæåçéå¾èæªä¾è¦é¨åæç ç©¶ç¸éæ§ãæ´é«èè¨ï¼æ¬ç ç©¶ä¸åå¢å¼·äºæåå°è¦é»åååè½æ§ç£æ¯é å½±è¨èä¹éäº¤äºä½ç¨ççè§£ï¼ä¹çºé²ä¸æ­¥æ¢ç´¢èªç¥åè½çç¥ç¶ç¸éæ§åå¶å¨è¨åºç°å¢ä¸­çæç¾©éªè·¯ãæªä¾çç ç©¶æå°æ³¨æ¼åªåéäºæ¹æ³ä¸¦æ¢è¨å¶å¨åç¨®èªç¥åè¨åºèæ¯ä¸­çæç¨ã

##### **Graph Neural Networks for Heart Failure Prediction on an EHR-Based Patient Similarity Graph**
2411.19742v1 by Heloisa Oss Boll, Ali Amirahmadi, Amira Soliman, Stefan Byttner, Mariana Recamonde-Mendoza

Objective: In modern healthcare, accurately predicting diseases is a crucial
matter. This study introduces a novel approach using graph neural networks
(GNNs) and a Graph Transformer (GT) to predict the incidence of heart failure
(HF) on a patient similarity graph at the next hospital visit. Materials and
Methods: We used electronic health records (EHR) from the MIMIC-III dataset and
applied the K-Nearest Neighbors (KNN) algorithm to create a patient similarity
graph using embeddings from diagnoses, procedures, and medications. Three
models - GraphSAGE, Graph Attention Network (GAT), and Graph Transformer (GT) -
were implemented to predict HF incidence. Model performance was evaluated using
F1 score, AUROC, and AUPRC metrics, and results were compared against baseline
algorithms. An interpretability analysis was performed to understand the
model's decision-making process. Results: The GT model demonstrated the best
performance (F1 score: 0.5361, AUROC: 0.7925, AUPRC: 0.5168). Although the
Random Forest (RF) baseline achieved a similar AUPRC value, the GT model
offered enhanced interpretability due to the use of patient relationships in
the graph structure. A joint analysis of attention weights, graph connectivity,
and clinical features provided insight into model predictions across different
classification groups. Discussion and Conclusion: Graph-based approaches such
as GNNs provide an effective framework for predicting HF. By leveraging a
patient similarity graph, GNNs can capture complex relationships in EHR data,
potentially improving prediction accuracy and clinical interpretability.

æè¦ï¼<paragraph>ç®æ¨ï¼å¨ç¾ä»£é«çä¿å¥ä¸­ï¼æºç¢ºé æ¸¬ç¾çæ¯ä¸é è³ééè¦çåé¡ãæ¬ç ç©¶ä»ç´¹äºä¸ç¨®ä½¿ç¨åç¥ç¶ç¶²çµ¡ (GNN) ååå½¢è½æå¨ (GT) çæ°æ¹æ³ï¼ç¨æ¼é æ¸¬ä¸æ¬¡é«é¢å°±è¨ºææ£èç¸ä¼¼åè¡¨ä¸çå¿èè¡°ç«­ (HF) ç¼ççãææåæ¹æ³ï¼æåä½¿ç¨äº MIMIC-III è³æéä¸­çé»å­å¥åº·è¨é (EHR)ï¼ä¸¦æç¨ K-æè¿é° (KNN) æ¼ç®æ³ï¼ä½¿ç¨ä¾èªè¨ºæ·ãç¨åºåè¥ç©çåµå¥ä¾å»ºç«æ£èç¸ä¼¼åè¡¨ãå¯¦ä½äºä¸åæ¨¡å - GraphSAGEãåå½¢æ³¨æåç¶²è·¯ (GAT) ååå½¢è½æå¨ (GT) - ä¾é æ¸¬ HF ç¼ççãä½¿ç¨ F1 åæ¸ãAUROC å AUPRC ææ¨è©ä¼°æ¨¡åæè½ï¼ä¸¦å°çµæèåºæºæ¼ç®æ³é²è¡æ¯è¼ãå·è¡äºè§£éæ§åæä»¥äºè§£æ¨¡åçæ±ºç­éç¨ãçµæï¼GT æ¨¡åè¡¨ç¾åºæä½³æè½ (F1 åæ¸ï¼0.5361ï¼AUROCï¼0.7925ï¼AUPRCï¼0.5168)ãåç®¡é¨æ©æ£®æ (RF) åºæºéå°äºé¡ä¼¼ç AUPRC å¼ï¼ä½ç±æ¼å¨åå½¢çµæ§ä¸­ä½¿ç¨äºæ£èéä¿ï¼å æ­¤ GT æ¨¡åæä¾äºå¢å¼·çè§£éæ§ãå°æ³¨æåæ¬éãåå½¢é£éæ§åè¨åºç¹å¾µçè¯ååææä¾äºå°ä¸ååé¡ç¾¤çµä¸­æ¨¡åé æ¸¬çè¦è§£ãè¨è«åçµè«ï¼åºæ¼åå½¢çæ¹æ³ï¼ä¾å¦ GNNï¼æä¾äºé æ¸¬ HF çæææ¡æ¶ãééå©ç¨æ£èç¸ä¼¼åå½¢ï¼GNN å¯ä»¥æ·å EHR è³æä¸­çè¤ééä¿ï¼é²èå¯è½æé«é æ¸¬æºç¢ºåº¦åè¨åºè§£éæ§ã</paragraph>

##### **Multimodal Whole Slide Foundation Model for Pathology**
2411.19666v1 by Tong Ding, Sophia J. Wagner, Andrew H. Song, Richard J. Chen, Ming Y. Lu, Andrew Zhang, Anurag J. Vaidya, Guillaume Jaume, Muhammad Shaban, Ahrong Kim, Drew F. K. Williamson, Bowen Chen, Cristina Almagro-Perez, Paul Doucet, Sharifa Sahai, Chengkuan Chen, Daisuke Komura, Akihiro Kawabe, Shumpei Ishikawa, Georg Gerber, Tingying Peng, Long Phi Le, Faisal Mahmood

The field of computational pathology has been transformed with recent
advances in foundation models that encode histopathology region-of-interests
(ROIs) into versatile and transferable feature representations via
self-supervised learning (SSL). However, translating these advancements to
address complex clinical challenges at the patient and slide level remains
constrained by limited clinical data in disease-specific cohorts, especially
for rare clinical conditions. We propose TITAN, a multimodal whole slide
foundation model pretrained using 335,645 WSIs via visual self-supervised
learning and vision-language alignment with corresponding pathology reports and
423,122 synthetic captions generated from a multimodal generative AI copilot
for pathology. Without any finetuning or requiring clinical labels, TITAN can
extract general-purpose slide representations and generate pathology reports
that generalize to resource-limited clinical scenarios such as rare disease
retrieval and cancer prognosis. We evaluate TITAN on diverse clinical tasks and
find that TITAN outperforms both ROI and slide foundation models across machine
learning settings such as linear probing, few-shot and zero-shot
classification, rare cancer retrieval and cross-modal retrieval, and pathology
report generation.

æè¦ï¼è¨ç®ççå­¸é åå·²å åºç¤æ¨¡åçææ°é²å±èè½åï¼éäºæ¨¡åééèªç£ç£å­¸ç¿ (SSL) å°çµç¹ççå­¸æèè¶£åå (ROI) ç·¨ç¢¼æå¤åè½ä¸å¯è½ç§»çç¹å¾µè¡¨ç¤ºãç¶èï¼è¦è§£æ±ºæ£èååçå±¤é¢çè¤éè¨åºææ°ï¼å°éäºé²å±è½åçºè§£æ±ºæ¹æ¡ä»åéæ¼ç¹å®ç¾çç¾¤é«ä¸­æéçè¨åºè³æï¼å°¤å¶æ¯ç½è¦çè¨åºææ³ãæåæåº TITANï¼éæ¯ä¸åå¤æ¨¡æå¨åçåºç¤æ¨¡åï¼ä½¿ç¨ 335,645 å WSI ééè¦è¦ºèªç£ç£å­¸ç¿åèå°æççå ±åçè¦è¦ºèªè¨å°é½ï¼ä»¥åç±å¤æ¨¡æçæå¼ AI è¼å©å¡çºççå­¸çæç 423,122 ååææ¨é¡é²è¡é è¨ç·´ãå¨æ²æä»»ä½å¾®èª¿æéè¦è¨åºæ¨ç±¤çææ³ä¸ï¼TITAN å¯ä»¥æåéç¨åçè¡¨ç¤ºï¼ä¸¦çæççå ±åï¼ä»¥æ¦æ¬å°è³æºæéçè¨åºå ´æ¯ï¼ä¾å¦ç½è¦ç¾çæª¢ç´¢åççé å¾ãæåå¨ä¸åçè¨åºä»»åä¸è©ä¼° TITANï¼ç¼ç¾ TITAN å¨æ©å¨å­¸ç¿è¨­å®ä¸­åªæ¼ ROI ååçåºç¤æ¨¡åï¼ä¾å¦ç·æ§æ¢æ¥ãå°æ¬¡å­¸ç¿åé¶æ¬¡å­¸ç¿åé¡ãç½è¦ççæª¢ç´¢åè·¨æ¨¡ææª¢ç´¢ï¼ä»¥åççå ±åçæã


### LLM
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-12-11**|**GPD-1: Generative Pre-training for Driving**|Zixun Xie et.al.|[2412.08643v1](http://arxiv.org/abs/2412.08643v1)|[link](https://github.com/wzzheng/gpd)|
|**2024-12-11**|**Fast Prompt Alignment for Text-to-Image Generation**|Khalil Mrini et.al.|[2412.08639v1](http://arxiv.org/abs/2412.08639v1)|[link](https://github.com/tiktok/fast_prompt_alignment)|
|**2024-12-11**|**DMin: Scalable Training Data Influence Estimation for Diffusion Models**|Huawei Lin et.al.|[2412.08637v1](http://arxiv.org/abs/2412.08637v1)|null|
|**2024-12-11**|**Multimodal Latent Language Modeling with Next-Token Diffusion**|Yutao Sun et.al.|[2412.08635v1](http://arxiv.org/abs/2412.08635v1)|null|
|**2024-12-11**|**Synthetic Vision: Training Vision-Language Models to Understand Physics**|Vahid Balazadeh et.al.|[2412.08619v1](http://arxiv.org/abs/2412.08619v1)|null|
|**2024-12-11**|**Image Retrieval Methods in the Dissimilarity Space**|Madhu Kiran et.al.|[2412.08618v1](http://arxiv.org/abs/2412.08618v1)|null|
|**2024-12-11**|**Exploiting the Index Gradients for Optimization-Based Jailbreaking on Large Language Models**|Jiahui Li et.al.|[2412.08615v1](http://arxiv.org/abs/2412.08615v1)|null|
|**2024-12-11**|**Competition and Diversity in Generative AI**|Manish Raghavan et.al.|[2412.08610v1](http://arxiv.org/abs/2412.08610v1)|null|
|**2024-12-11**|**AdvWave: Stealthy Adversarial Jailbreak Attack against Large Audio-Language Models**|Mintong Kang et.al.|[2412.08608v1](http://arxiv.org/abs/2412.08608v1)|null|
|**2024-12-11**|**Preference Discerning with LLM-Enhanced Generative Retrieval**|Fabian Paischer et.al.|[2412.08604v1](http://arxiv.org/abs/2412.08604v1)|null|
|**2024-12-11**|**Der Effizienz- und Intelligenzbegriff in der Lexikographie und kuenstlichen Intelligenz: kann ChatGPT die lexikographische Textsorte nachbilden?**|Ivan Arias-Arias et.al.|[2412.08599v1](http://arxiv.org/abs/2412.08599v1)|null|
|**2024-12-11**|**RoomTour3D: Geometry-Aware Video-Instruction Tuning for Embodied Navigation**|Mingfei Han et.al.|[2412.08591v1](http://arxiv.org/abs/2412.08591v1)|null|
|**2024-12-11**|**Advancing Single- and Multi-task Text Classification through Large Language Model Fine-tuning**|Hang Zhao et.al.|[2412.08587v1](http://arxiv.org/abs/2412.08587v1)|null|
|**2024-12-11**|**TURBOATTENTION: Efficient Attention Approximation For High Throughputs LLMs**|Hao Kang et.al.|[2412.08585v1](http://arxiv.org/abs/2412.08585v1)|null|
|**2024-12-11**|**Machine Learning Information Retrieval and Summarisation to Support Systematic Review on Outcomes Based Contracting**|Iman Munire Bilal et.al.|[2412.08578v1](http://arxiv.org/abs/2412.08578v1)|null|
|**2024-12-11**|**GenPlan: Generative sequence models as adaptive planners**|Akash Karthikeyan et.al.|[2412.08565v1](http://arxiv.org/abs/2412.08565v1)|null|
|**2024-12-11**|**Can We Generate Visual Programs Without Prompting LLMs?**|Michal Shlapentokh-Rothman et.al.|[2412.08564v1](http://arxiv.org/abs/2412.08564v1)|null|
|**2024-12-11**|**Bilevel Joint Unsupervised and Supervised Training for Automatic Speech Recognition**|Xiaodong Cui et.al.|[2412.08548v1](http://arxiv.org/abs/2412.08548v1)|null|
|**2024-12-11**|**MaestroMotif: Skill Design from Artificial Intelligence Feedback**|Martin Klissarov et.al.|[2412.08542v1](http://arxiv.org/abs/2412.08542v1)|null|
|**2024-12-11**|**TECO: Improving Multimodal Intent Recognition with Text Enhancement through Commonsense Knowledge Extraction**|Quynh-Mai Thi Nguyen et.al.|[2412.08529v1](http://arxiv.org/abs/2412.08529v1)|null|
|**2024-12-11**|**Continual Learning for Encoder-only Language Models via a Discrete Key-Value Bottleneck**|Andor Diera et.al.|[2412.08528v1](http://arxiv.org/abs/2412.08528v1)|null|
|**2024-12-11**|**EMS: Adaptive Evict-then-Merge Strategy for Head-wise KV Cache Compression Based on Global-Local Importance**|Yingxin Li et.al.|[2412.08521v1](http://arxiv.org/abs/2412.08521v1)|null|
|**2024-12-11**|**GR-NLP-TOOLKIT: An Open-Source NLP Toolkit for Modern Greek**|Lefteris Loukas et.al.|[2412.08520v1](http://arxiv.org/abs/2412.08520v1)|[link](https://github.com/nlpaueb/gr-nlp-toolkit)|
|**2024-12-11**|**Bridging Relevance and Reasoning: Rationale Distillation in Retrieval-Augmented Generation**|Pengyue Jia et.al.|[2412.08519v1](http://arxiv.org/abs/2412.08519v1)|null|
|**2024-12-11**|**Enhancing Interpretability Through Loss-Defined Classification Objective in Structured Latent Spaces**|Daniel Geissler et.al.|[2412.08515v1](http://arxiv.org/abs/2412.08515v1)|null|
|**2024-12-11**|**REPEAT: Improving Uncertainty Estimation in Representation Learning Explainability**|Kristoffer K. WickstrÃ¸m et.al.|[2412.08513v1](http://arxiv.org/abs/2412.08513v1)|[link](https://github.com/wickstrom/repeat)|
|**2024-12-11**|**Comparative Opinion Mining in Product Reviews: Multi-perspective Prompt-based Learning**|Hai-Yen Thi Nguyen et.al.|[2412.08508v1](http://arxiv.org/abs/2412.08508v1)|null|
|**2024-12-11**|**SuperCode: Sustainability PER AI-driven CO-DEsign**|P. Chris Broekema et.al.|[2412.08490v1](http://arxiv.org/abs/2412.08490v1)|null|
|**2024-12-11**|**Multi-perspective Alignment for Increasing Naturalness in Neural Machine Translation**|Huiyuan Lai et.al.|[2412.08473v1](http://arxiv.org/abs/2412.08473v1)|null|
|**2024-12-11**|**Bootstrapping Language-Guided Navigation Learning with Self-Refining Data Flywheel**|Zun Wang et.al.|[2412.08467v1](http://arxiv.org/abs/2412.08467v1)|null|
|**2024-12-11**|**IRL for Restless Multi-Armed Bandits with Applications in Maternal and Child Health**|Gauri Jain et.al.|[2412.08463v1](http://arxiv.org/abs/2412.08463v1)|[link](https://github.com/gjain234/whirl)|
|**2024-12-11**|**Federated Learning for Traffic Flow Prediction with Synthetic Data Augmentation**|Fermin Orozco et.al.|[2412.08460v1](http://arxiv.org/abs/2412.08460v1)|null|
|**2024-12-11**|**Efficient Rectification of Neuro-Symbolic Reasoning Inconsistencies by Abductive Reflection**|Wen-Chao Hu et.al.|[2412.08457v1](http://arxiv.org/abs/2412.08457v1)|null|
|**2024-12-11**|**TapeAgents: a Holistic Framework for Agent Development and Optimization**|Dzmitry Bahdanau et.al.|[2412.08445v1](http://arxiv.org/abs/2412.08445v1)|null|
|**2024-12-11**|**Proactive Model Adaptation Against Concept Drift for Online Time Series Forecasting**|Lifan Zhao et.al.|[2412.08435v1](http://arxiv.org/abs/2412.08435v1)|null|
|**2024-12-11**|**Mitigating Out-of-Entity Errors in Named Entity Recognition: A Sentence-Level Strategy**|Guochao Jiang et.al.|[2412.08434v1](http://arxiv.org/abs/2412.08434v1)|null|
|**2024-12-11**|**Assessing Personalized AI Mentoring with Large Language Models in the Computing Field**|Xiao Luo et.al.|[2412.08430v1](http://arxiv.org/abs/2412.08430v1)|null|
|**2024-12-11**|**SwarmGPT-Primitive: A Language-Driven Choreographer for Drone Swarms Using Safe Motion Primitive Composition**|Vedant Vyas et.al.|[2412.08428v1](http://arxiv.org/abs/2412.08428v1)|null|
|**2024-12-11**|**Detecting Conversational Mental Manipulation with Intent-Aware Prompting**|Jiayuan Ma et.al.|[2412.08414v1](http://arxiv.org/abs/2412.08414v1)|[link](https://github.com/anton-jiayuan-ma/manip-iap)|
|**2024-12-11**|**Learning to Reason via Self-Iterative Process Feedback for Small Language Models**|Kaiyuan Chen et.al.|[2412.08393v1](http://arxiv.org/abs/2412.08393v1)|null|
|**2024-12-11**|**The Roles of English in Evaluating Multilingual Language Models**|Wessel Poelman et.al.|[2412.08392v1](http://arxiv.org/abs/2412.08392v1)|null|
|**2024-12-11**|**SweetieChat: A Strategy-Enhanced Role-playing Framework for Diverse Scenarios Handling Emotional Support Agent**|Jing Ye et.al.|[2412.08389v1](http://arxiv.org/abs/2412.08389v1)|null|
|**2024-12-11**|**NyayaAnumana & INLegalLlama: The Largest Indian Legal Judgment Prediction Dataset and Specialized Language Model for Enhanced Decision Analysis**|Shubham Kumar Nigam et.al.|[2412.08385v1](http://arxiv.org/abs/2412.08385v1)|null|
|**2024-12-11**|**HyViLM: Enhancing Fine-Grained Recognition with a Hybrid Encoder for Vision-Language Models**|Shiding Zhu et.al.|[2412.08378v1](http://arxiv.org/abs/2412.08378v1)|null|
|**2024-12-11**|**SmolTulu: Higher Learning Rate to Batch Size Ratios Can Lead to Better Reasoning in SLMs**|Sultan Alrashed et.al.|[2412.08347v1](http://arxiv.org/abs/2412.08347v1)|null|
|**2024-12-11**|**BEIR-NL: Zero-shot Information Retrieval Benchmark for the Dutch Language**|Nikolay Banar et.al.|[2412.08329v1](http://arxiv.org/abs/2412.08329v1)|null|
|**2024-12-11**|**Large Language Models Still Face Challenges in Multi-Hop Reasoning with External Knowledge**|Haotong Zhang et.al.|[2412.08317v1](http://arxiv.org/abs/2412.08317v1)|null|
|**2024-12-11**|**Rumor Detection on Social Media with Temporal Propagation Structure Optimization**|Xingyu Peng et.al.|[2412.08316v1](http://arxiv.org/abs/2412.08316v1)|null|
|**2024-12-11**|**Self-Refining Diffusion Samplers: Enabling Parallelization via Parareal Iterations**|Nikil Roashan Selvam et.al.|[2412.08292v1](http://arxiv.org/abs/2412.08292v1)|null|
|**2024-12-11**|**Code LLMs: A Taxonomy-based Survey**|Nishat Raihan et.al.|[2412.08291v1](http://arxiv.org/abs/2412.08291v1)|null|
|**2024-12-11**|**Adaptive Prompting for Continual Relation Extraction: A Within-Task Variance Perspective**|Minh Le et.al.|[2412.08285v1](http://arxiv.org/abs/2412.08285v1)|null|
|**2024-12-11**|**A Preliminary Analysis of Automatic Word and Syllable Prominence Detection in Non-Native Speech With Text-to-Speech Prosody Embeddings**|Anindita Mondal et.al.|[2412.08283v1](http://arxiv.org/abs/2412.08283v1)|null|
|**2024-12-11**|**Y-NQ: English-YorÃ¹bÃ¡ Evaluation dataset for Open-Book Reading Comprehension and Text Generation**|Marta R. Costa-jussÃ  et.al.|[2412.08279v1](http://arxiv.org/abs/2412.08279v1)|null|
|**2024-12-11**|**2M-BELEBELE: Highly Multilingual Speech and American Sign Language Comprehension Dataset**|Marta R. Costa-jussÃ  et.al.|[2412.08274v1](http://arxiv.org/abs/2412.08274v1)|null|
|**2024-12-11**|**Position-aware Guided Point Cloud Completion with CLIP Model**|Feng Zhou et.al.|[2412.08271v1](http://arxiv.org/abs/2412.08271v1)|null|
|**2024-12-11**|**LCFO: Long Context and Long Form Output Dataset and Benchmarking**|Marta R. Costa-jussÃ  et.al.|[2412.08268v1](http://arxiv.org/abs/2412.08268v1)|null|
|**2024-12-11**|**Discrete Subgraph Sampling for Interpretable Graph based Visual Question Answering**|Pascal Tilli et.al.|[2412.08263v1](http://arxiv.org/abs/2412.08263v1)|null|
|**2024-12-11**|**FLIP: Flow-Centric Generative Planning for General-Purpose Manipulation Tasks**|Chongkai Gao et.al.|[2412.08261v1](http://arxiv.org/abs/2412.08261v1)|null|
|**2024-12-11**|**Large Language Models for Scholarly Ontology Generation: An Extensive Analysis in the Engineering Field**|Tanay Aggarwal et.al.|[2412.08258v1](http://arxiv.org/abs/2412.08258v1)|null|
|**2024-12-11**|**Accurate Medical Named Entity Recognition Through Specialized NLP Models**|Jiacheng Hu et.al.|[2412.08255v1](http://arxiv.org/abs/2412.08255v1)|null|
|**2024-12-11**|**TouchTTS: An Embarrassingly Simple TTS Framework that Everyone Can Touch**|Xingchen Song et.al.|[2412.08237v1](http://arxiv.org/abs/2412.08237v1)|null|
|**2024-12-11**|**Generate Any Scene: Evaluating and Improving Text-to-Vision Generation with Scene Graph Programming**|Ziqi Gao et.al.|[2412.08221v1](http://arxiv.org/abs/2412.08221v1)|null|
|**2024-12-11**|**DocSum: Domain-Adaptive Pre-training for Document Abstractive Summarization**|Phan Phuong Mai Chau et.al.|[2412.08196v1](http://arxiv.org/abs/2412.08196v1)|null|
|**2024-12-11**|**Semantic Scene Completion Based 3D Traversability Estimation for Off-Road Terrains**|Zitong Chen et.al.|[2412.08195v1](http://arxiv.org/abs/2412.08195v1)|null|
|**2024-12-11**|**From communities to interpretable network and word embedding: an unified approach**|Thibault Prouteau et.al.|[2412.08187v1](http://arxiv.org/abs/2412.08187v1)|null|
|**2024-12-11**|**Auto-Generating Earnings Report Analysis via a Financial-Augmented LLM**|Van-Duc Le et.al.|[2412.08179v1](http://arxiv.org/abs/2412.08179v1)|null|
|**2024-12-11**|**Can Graph Neural Networks Learn Language with Extremely Weak Text Supervision?**|Zihao Li et.al.|[2412.08174v1](http://arxiv.org/abs/2412.08174v1)|null|
|**2024-12-11**|**Illusory VQA: Benchmarking and Enhancing Multimodal Models on Visual Illusions**|Mohammadmostafa Rostamkhani et.al.|[2412.08169v1](http://arxiv.org/abs/2412.08169v1)|[link](https://github.com/IllusoryVQA/IllusoryVQA)|
|**2024-12-11**|**NLPineers@ NLU of Devanagari Script Languages 2025: Hate Speech Detection using Ensembling of BERT-based models**|Anmol Guragain et.al.|[2412.08163v1](http://arxiv.org/abs/2412.08163v1)|[link](https://github.com/Anmol2059/NLPineers_Chipsal)|
|**2024-12-11**|**How Vision-Language Tasks Benefit from Large Pre-trained Models: A Survey**|Yayun Qi et.al.|[2412.08158v1](http://arxiv.org/abs/2412.08158v1)|null|
|**2024-12-11**|**Antelope: Potent and Concealed Jailbreak Attack Strategy**|Xin Zhao et.al.|[2412.08156v1](http://arxiv.org/abs/2412.08156v1)|null|
|**2024-12-11**|**A Review of Intelligent Device Fault Diagnosis Technologies Based on Machine Vision**|Guiran Liu et.al.|[2412.08148v1](http://arxiv.org/abs/2412.08148v1)|null|
|**2024-12-11**|**How to Weight Multitask Finetuning? Fast Previews via Bayesian Model-Merging**|Hugo MonzÃ³n Maldonado et.al.|[2412.08147v1](http://arxiv.org/abs/2412.08147v1)|null|
|**2024-12-11**|**A Survey on Private Transformer Inference**|Yang Li et.al.|[2412.08145v1](http://arxiv.org/abs/2412.08145v1)|null|
|**2024-12-11**|**AGMixup: Adaptive Graph Mixup for Semi-supervised Node Classification**|Weigang Lu et.al.|[2412.08144v1](http://arxiv.org/abs/2412.08144v1)|null|
|**2024-12-11**|**Wasserstein Distance Rivals Kullback-Leibler Divergence for Knowledge Distillation**|Jiaming Lv et.al.|[2412.08139v1](http://arxiv.org/abs/2412.08139v1)|null|
|**2024-12-11**|**Learn How to Query from Unlabeled Data Streams in Federated Learning**|Yuchang Sun et.al.|[2412.08138v1](http://arxiv.org/abs/2412.08138v1)|null|
|**2024-12-11**|**DiffRaman: A Conditional Latent Denoising Diffusion Probabilistic Model for Bacterial Raman Spectroscopy Identification Under Limited Data Conditions**|Haiming Yao et.al.|[2412.08131v1](http://arxiv.org/abs/2412.08131v1)|null|
|**2024-12-11**|**Evil twins are not that evil: Qualitative insights into machine-generated prompts**|NathanaÃ«l Carraz Rakotonirina et.al.|[2412.08127v1](http://arxiv.org/abs/2412.08127v1)|null|
|**2024-12-11**|**Progressive Multi-granular Alignments for Grounded Reasoning in Large Vision-Language Models**|Quang-Hung Le et.al.|[2412.08125v1](http://arxiv.org/abs/2412.08125v1)|null|
|**2024-12-11**|**LatentSpeech: Latent Diffusion for Text-To-Speech Generation**|Haowei Lou et.al.|[2412.08117v1](http://arxiv.org/abs/2412.08117v1)|null|
|**2024-12-11**|**Aligner-Guided Training Paradigm: Advancing Text-to-Speech Models with Aligner Guided Duration**|Haowei Lou et.al.|[2412.08112v1](http://arxiv.org/abs/2412.08112v1)|null|
|**2024-12-11**|**Seeing Syntax: Uncovering Syntactic Learning Limitations in Vision-Language Models**|Sri Harsha Dumpala et.al.|[2412.08111v1](http://arxiv.org/abs/2412.08111v1)|null|
|**2024-12-11**|**Barking Up The Syntactic Tree: Enhancing VLM Training with Syntactic Losses**|Jiayun Luo et.al.|[2412.08110v1](http://arxiv.org/abs/2412.08110v1)|null|
|**2024-12-11**|**Unseen Horizons: Unveiling the Real Capability of LLM Code Generation Beyond the Familiar**|Yuanliang Zhang et.al.|[2412.08109v1](http://arxiv.org/abs/2412.08109v1)|null|
|**2024-12-11**|**Doubly-Universal Adversarial Perturbations: Deceiving Vision-Language Models Across Both Images and Text with a Single Perturbation**|Hee-Seon Kim et.al.|[2412.08108v1](http://arxiv.org/abs/2412.08108v1)|null|
|**2024-12-11**|**Adversarial Vulnerabilities in Large Language Models for Time Series Forecasting**|Fuqiang Liu et.al.|[2412.08099v1](http://arxiv.org/abs/2412.08099v1)|null|
|**2024-12-11**|**What You See Is Not Always What You Get: An Empirical Study of Code Comprehension by Large Language Models**|Bangshuo Zhu et.al.|[2412.08098v1](http://arxiv.org/abs/2412.08098v1)|null|
|**2024-12-11**|**Multilingual LLMs Inherently Reward In-Language Time-Sensitive Semantic Alignment for Low-Resource Languages**|Ashutosh Bajpai et.al.|[2412.08090v1](http://arxiv.org/abs/2412.08090v1)|null|
|**2024-12-11**|**How to select slices for annotation to train best-performing deep learning segmentation models for cross-sectional medical images?**|Yixin Zhang et.al.|[2412.08081v1](http://arxiv.org/abs/2412.08081v1)|null|
|**2024-12-11**|**Using Large Language Models for Parametric Shape Optimization**|Xinxin Zhang et.al.|[2412.08072v1](http://arxiv.org/abs/2412.08072v1)|null|
|**2024-12-11**|**DialogAgent: An Auto-engagement Agent for Code Question Answering Data Production**|Xiaoyun Liang et.al.|[2412.08069v1](http://arxiv.org/abs/2412.08069v1)|null|
|**2024-12-11**|**Repository-Level Graph Representation Learning for Enhanced Security Patch Detection**|Xin-Cheng Wen et.al.|[2412.08068v1](http://arxiv.org/abs/2412.08068v1)|null|
|**2024-12-11**|**ContextModule: Improving Code Completion via Repository-level Contextual Information**|Zhanming Guan et.al.|[2412.08063v1](http://arxiv.org/abs/2412.08063v1)|null|
|**2024-12-11**|**Go-Oracle: Automated Test Oracle for Go Concurrency Bugs**|Foivos Tsimpourlas et.al.|[2412.08061v1](http://arxiv.org/abs/2412.08061v1)|null|
|**2024-12-11**|**Federated In-Context LLM Agent Learning**|Panlong Wu et.al.|[2412.08054v1](http://arxiv.org/abs/2412.08054v1)|null|
|**2024-12-11**|**DynamicPAE: Generating Scene-Aware Physical Adversarial Examples in Real-Time**|Jin Hu et.al.|[2412.08053v1](http://arxiv.org/abs/2412.08053v1)|null|
|**2024-12-11**|**M2SE: A Multistage Multitask Instruction Tuning Strategy for Unified Sentiment and Emotion Analysis**|Ao Li et.al.|[2412.08049v1](http://arxiv.org/abs/2412.08049v1)|null|
|**2024-12-11**|**Bootstrapping Heterogeneous Graph Representation Learning via Large Language Models: A Generalized Approach**|Hang Gao et.al.|[2412.08038v1](http://arxiv.org/abs/2412.08038v1)|null|
|**2024-12-11**|**TinyThinker: Distilling Reasoning through Coarse-to-Fine Knowledge Internalization with Self-Reflection**|Shengmin Piao et.al.|[2412.08024v1](http://arxiv.org/abs/2412.08024v1)|null|

#### Abstracts
##### **GPD-1: Generative Pre-training for Driving**
2412.08643v1 by Zixun Xie, Sicheng Zuo, Wenzhao Zheng, Yunpeng Zhang, Dalong Du, Jie Zhou, Jiwen Lu, Shanghang Zhang

Modeling the evolutions of driving scenarios is important for the evaluation
and decision-making of autonomous driving systems. Most existing methods focus
on one aspect of scene evolution such as map generation, motion prediction, and
trajectory planning. In this paper, we propose a unified Generative
Pre-training for Driving (GPD-1) model to accomplish all these tasks altogether
without additional fine-tuning. We represent each scene with ego, agent, and
map tokens and formulate autonomous driving as a unified token generation
problem. We adopt the autoregressive transformer architecture and use a
scene-level attention mask to enable intra-scene bi-directional interactions.
For the ego and agent tokens, we propose a hierarchical positional tokenizer to
effectively encode both 2D positions and headings. For the map tokens, we train
a map vector-quantized autoencoder to efficiently compress ego-centric semantic
maps into discrete tokens. We pre-train our GPD-1 on the large-scale nuPlan
dataset and conduct extensive experiments to evaluate its effectiveness. With
different prompts, our GPD-1 successfully generalizes to various tasks without
finetuning, including scene generation, traffic simulation, closed-loop
simulation, map prediction, and motion planning. Code:
https://github.com/wzzheng/GPD.

æè¦ï¼æ¨¡æ¬é§é§å ´æ¯çæ¼é²å°æ¼è©ä¼°åæ±ºç­èªåé§é§ç³»çµ±éå¸¸éè¦ãç¾æçæ¹æ³å¤§å¤å°æ³¨æ¼å ´æ¯æ¼é²çä¸åé¢åï¼ä¾å¦å°åçæãéåé æ¸¬åè»è·¡è¦åãå¨æ¬æä¸­ï¼æåæåºäºä¸åçµ±ä¸ççæå¼é§é§é è¨ç·´ (GPD-1) æ¨¡åï¼å¯ä»¥åæå®æææéäºä»»åï¼èç¡éé¡å¤çå¾®èª¿ãæåä½¿ç¨èªæãä»£çåå°åç¬¦èè¡¨ç¤ºæ¯åå ´æ¯ï¼ä¸¦å°èªåé§é§è¡¨è¿°çºä¸åçµ±ä¸çç¬¦èçæåé¡ãæåæ¡ç¨èªè¿´æ­¸Transformeræ¶æ§ï¼ä¸¦ä½¿ç¨å ´æ¯ç´å¥çæ³¨æåé®ç½©ä¾åç¨å ´æ¯å§éåäº¤äºãå°æ¼èªæåä»£çç¬¦èï¼æåæåºäºä¸ååå±¤ä½ç½®æ¨è¨å¨ï¼ä»¥ææç·¨ç¢¼ 2D ä½ç½®åæ¨é¡ãå°æ¼å°åç¬¦èï¼æåè¨ç·´äºä¸åå°ååééåçèªåç·¨ç¢¼å¨ï¼ä»¥ææå°å°ä»¥èªæçºä¸­å¿çèªç¾©å°åå£ç¸®æé¢æ£ç¬¦èãæåå¨å¤§å nuPlan è³æéä¸é è¨ç·´æåç GPD-1ï¼ä¸¦é²è¡å»£æ³çå¯¦é©ä¾è©ä¼°å¶æææ§ãééä¸åçæç¤ºï¼æåç GPD-1 æåå°æ¨å»£å°åç¨®ä»»åï¼èç¡éå¾®èª¿ï¼åæ¬å ´æ¯çæãäº¤éæ¨¡æ¬ãéç°æ¨¡æ¬ãå°åé æ¸¬åéåè¦åãç¨å¼ç¢¼ï¼
https://github.com/wzzheng/GPDã

##### **Fast Prompt Alignment for Text-to-Image Generation**
2412.08639v1 by Khalil Mrini, Hanlin Lu, Linjie Yang, Weilin Huang, Heng Wang

Text-to-image generation has advanced rapidly, yet aligning complex textual
prompts with generated visuals remains challenging, especially with intricate
object relationships and fine-grained details. This paper introduces Fast
Prompt Alignment (FPA), a prompt optimization framework that leverages a
one-pass approach, enhancing text-to-image alignment efficiency without the
iterative overhead typical of current methods like OPT2I. FPA uses large
language models (LLMs) for single-iteration prompt paraphrasing, followed by
fine-tuning or in-context learning with optimized prompts to enable real-time
inference, reducing computational demands while preserving alignment fidelity.
Extensive evaluations on the COCO Captions and PartiPrompts datasets
demonstrate that FPA achieves competitive text-image alignment scores at a
fraction of the processing time, as validated through both automated metrics
(TIFA, VQA) and human evaluation. A human study with expert annotators further
reveals a strong correlation between human alignment judgments and automated
scores, underscoring the robustness of FPA's improvements. The proposed method
showcases a scalable, efficient alternative to iterative prompt optimization,
enabling broader applicability in real-time, high-demand settings. The codebase
is provided to facilitate further research:
https://github.com/tiktok/fast_prompt_alignment

æè¦ï¼ææ¬å°ååçææè¡å·²å¿«éé²æ­¥ï¼ä½å°è¤éçæå­æç¤ºèçæçè¦è¦ºææå°é½ä»ç¶å·æææ°æ§ï¼ç¹å¥æ¯å¨è¤éçç©ä»¶éä¿åç´°å¾®çç´°ç¯æ¹é¢ãæ¬æä»ç´¹äºå¿«éæç¤ºå°é½ (FPA)ï¼éæ¯ä¸åæç¤ºæä½³åæ¡æ¶ï¼å®å©ç¨ä¸ç«å¼æ¹æ³ä¾æåæå­å°ååå°é½æçï¼èç¡éå OPT2I ç­ç¾è¡æ¹æ³å¸¸è¦çéè¤éé·ãFPA ä½¿ç¨å¤§åèªè¨æ¨¡å (LLM) é²è¡å®æ¬¡è¿­ä»£æç¤ºæ¹å¯«ï¼ç¶å¾ä½¿ç¨æä½³åæç¤ºé²è¡å¾®èª¿ææå¢å­¸ç¿ï¼ä»¥å¯¦ç¾å³ææ¨è«ï¼å¾èéä½éç®éæ±ï¼åæä¿æå°é½ä¿çåº¦ãå¨ COCO Captions å PartiPrompts è³æéä¸çå»£æ³è©ä¼°è¡¨æï¼FPA å¨èçæéçä¸å°é¨åå§å¯¦ç¾äºå·æç«¶ç­åçæå­ååå°é½åæ¸ï¼éééèªååææ¨ (TIFAãVQA) åäººå·¥è©ä¼°å¾å°é©è­ãèå°å®¶è¨»è§£å¡é²è¡çäººé¡ç ç©¶é²ä¸æ­¥æ­ç¤ºäºäººé¡å°é½å¤æ·èèªåååæ¸ä¹éçå¼·ç¸éæ§ï¼éçªé¡¯äº FPA æ¹é²çç©©å¥æ§ãææåºçæ¹æ³å±ç¤ºäºä¸ç¨®å¯æ´åãé«æçè¿­ä»£æç¤ºæä½³åæ¿ä»£æ¹æ¡ï¼å¯å¨å¯¦æãé«éæ±çè¨­å®ä¸­å¯¦ç¾æ´å»£æ³çæç¨æ§ãæä¾ç¨å¼ç¢¼åº«ä»¥å©æ¼é²ä¸æ­¥ç ç©¶ï¼
https://github.com/tiktok/fast_prompt_alignment

##### **DMin: Scalable Training Data Influence Estimation for Diffusion Models**
2412.08637v1 by Huawei Lin, Yingjie Lao, Weijie Zhao

Identifying the training data samples that most influence a generated image
is a critical task in understanding diffusion models, yet existing influence
estimation methods are constrained to small-scale or LoRA-tuned models due to
computational limitations. As diffusion models scale up, these methods become
impractical. To address this challenge, we propose DMin (Diffusion Model
influence), a scalable framework for estimating the influence of each training
data sample on a given generated image. By leveraging efficient gradient
compression and retrieval techniques, DMin reduces storage requirements from
339.39 TB to only 726 MB and retrieves the top-k most influential training
samples in under 1 second, all while maintaining performance. Our empirical
results demonstrate DMin is both effective in identifying influential training
samples and efficient in terms of computational and storage requirements.

æè¦ï¼æ¾åºå°çæå½±åå½±é¿æå¤§çè¨ç·´è³æç¯ä¾ï¼æ¯äºè§£æ´æ£æ¨¡åçéè¦ä»»åï¼ä½ç¾æçå½±é¿è©ä¼°æ¹æ³ç±æ¼éç®éå¶ï¼åéæ¼å°è¦æ¨¡æ LoRA èª¿æ´éçæ¨¡åãé¨èæ´æ£æ¨¡åè¦æ¨¡æ´å¤§ï¼éäºæ¹æ³è®å¾ä¸åå¯¦éãçºäºæå°éåææ°ï¼æåæåºäº DMinï¼æ´æ£æ¨¡åå½±é¿ï¼ï¼ä¸åå¯æ´åçæ¶æ§ï¼ç¨æ¼è©ä¼°æ¯åè¨ç·´è³æç¯ä¾å°çµ¦å®çæå½±åçå½±é¿ãééå©ç¨é«æçæ¢¯åº¦å£ç¸®åæª¢ç´¢æè¡ï¼DMin å°å²å­éæ±å¾ 339.39 TB æ¸å°å°å 726 MBï¼ä¸¦å¨ä¸å° 1 ç§çæéå§æª¢ç´¢åºå½±é¿åæå¤§çå k åè¨ç·´ç¯ä¾ï¼åæéè½ç¶­ææè½ãæåçå¯¦è­çµæè­æï¼DMin å¨æ¾åºæå½±é¿åçè¨ç·´ç¯ä¾æ¹é¢æ¢ææçï¼å¨éç®åå²å­éæ±æ¹é¢ä¹ååææçã

##### **Multimodal Latent Language Modeling with Next-Token Diffusion**
2412.08635v1 by Yutao Sun, Hangbo Bao, Wenhui Wang, Zhiliang Peng, Li Dong, Shaohan Huang, Jianyong Wang, Furu Wei

Multimodal generative models require a unified approach to handle both
discrete data (e.g., text and code) and continuous data (e.g., image, audio,
video). In this work, we propose Latent Language Modeling (LatentLM), which
seamlessly integrates continuous and discrete data using causal Transformers.
Specifically, we employ a variational autoencoder (VAE) to represent continuous
data as latent vectors and introduce next-token diffusion for autoregressive
generation of these vectors. Additionally, we develop $\sigma$-VAE to address
the challenges of variance collapse, which is crucial for autoregressive
modeling. Extensive experiments demonstrate the effectiveness of LatentLM
across various modalities. In image generation, LatentLM surpasses Diffusion
Transformers in both performance and scalability. When integrated into
multimodal large language models, LatentLM provides a general-purpose interface
that unifies multimodal generation and understanding. Experimental results show
that LatentLM achieves favorable performance compared to Transfusion and vector
quantized models in the setting of scaling up training tokens. In
text-to-speech synthesis, LatentLM outperforms the state-of-the-art VALL-E 2
model in speaker similarity and robustness, while requiring 10x fewer decoding
steps. The results establish LatentLM as a highly effective and scalable
approach to advance large multimodal models.

æè¦ï¼å¤æ¨¡æçææ¨¡åéè¦ä¸ç§ç»ä¸çæ¹æ³æ¥å¤çç¦»æ£æ°æ®ï¼ä¾å¦ææ¬åä»£ç ï¼åè¿ç»­æ°æ®ï¼ä¾å¦å¾åãé³é¢ãè§é¢ï¼ãå¨è¿é¡¹å·¥ä½ä¸­ï¼æä»¬æåºäºæ½å¨è¯­è¨æ¨¡åï¼LatentLMï¼ï¼å®ä½¿ç¨å æ Transformer æ ç¼å°éæäºè¿ç»­æ°æ®åç¦»æ£æ°æ®ãå·ä½æ¥è¯´ï¼æä»¬éç¨ååèªå¨ç¼ç å¨ (VAE) å°è¿ç»­æ°æ®è¡¨ç¤ºä¸ºæ½å¨åéï¼å¹¶å¼å¥ä¸ä¸ä¸ªæ è®°æ©æ£æ¥èªå¨åå½çæè¿äºåéãæ­¤å¤ï¼æä»¬å¼åäº Ï-VAE æ¥è§£å³æ¹å·®åç¼©çææï¼è¿å¯¹èªåå½å»ºæ¨¡è³å³éè¦ãå¹¿æ³çå®éªè¡¨æ LatentLM å¨åç§æ¨¡æä¸­é½å¾ææãå¨å¾åçæä¸­ï¼LatentLM å¨æ§è½åå¯æ©å±æ§æ¹é¢é½è¶è¶äºæ©æ£ Transformerãå½éæå°å¤æ¨¡æå¤§è¯­è¨æ¨¡åä¸­æ¶ï¼LatentLM æä¾äºä¸ä¸ªéç¨æ¥å£ï¼å®ç»ä¸äºå¤æ¨¡æçæåçè§£ãå®éªç»æè¡¨æï¼å¨æ©å±è®­ç»æ è®°çè®¾ç½®ä¸­ï¼ä¸ Transfusion åç¢ééåæ¨¡åç¸æ¯ï¼LatentLM å®ç°äºè¯å¥½çæ§è½ãå¨ææ¬å°è¯­é³åæä¸­ï¼LatentLM å¨è¯´è¯èç¸ä¼¼æ§åé²æ£æ§æ¹é¢ä¼äºæåè¿ç VALL-E 2 æ¨¡åï¼åæ¶éè¦çè§£ç æ­¥éª¤åå°äº 10 åãç»æè¡¨æ LatentLM æ¯ä¸ç§éå¸¸ææä¸å¯æ©å±çæ¹æ³ï¼å¯ä»¥æ¨è¿å¤§åå¤æ¨¡ææ¨¡åã

##### **Synthetic Vision: Training Vision-Language Models to Understand Physics**
2412.08619v1 by Vahid Balazadeh, Mohammadmehdi Ataei, Hyunmin Cheong, Amir Hosein Khasahmadi, Rahul G. Krishnan

Physical reasoning, which involves the interpretation, understanding, and
prediction of object behavior in dynamic environments, remains a significant
challenge for current Vision-Language Models (VLMs). In this work, we propose
two methods to enhance VLMs' physical reasoning capabilities using simulated
data. First, we fine-tune a pre-trained VLM using question-answer (QA) pairs
generated from simulations relevant to physical reasoning tasks. Second, we
introduce Physics Context Builders (PCBs), specialized VLMs fine-tuned to
create scene descriptions enriched with physical properties and processes.
During physical reasoning tasks, these PCBs can be leveraged as context to
assist a Large Language Model (LLM) to improve its performance. We evaluate
both of our approaches using multiple benchmarks, including a new stability
detection QA dataset called Falling Tower, which includes both simulated and
real-world scenes, and CLEVRER. We demonstrate that a small QA fine-tuned VLM
can significantly outperform larger state-of-the-art foundational models. We
also show that integrating PCBs boosts the performance of foundational LLMs on
physical reasoning tasks. Using the real-world scenes from the Falling Tower
dataset, we also validate the robustness of both approaches in Sim2Real
transfer. Our results highlight the utility that simulated data can have in the
creation of learning systems capable of advanced physical reasoning.

æè¦ï¼ç©çæ¨çæ¶åå°åæç°å¢ä¸­ç©é«è¡çºçè§£è®ãçè§£åé æ¸¬ï¼ä»ç¶æ¯ç¶åè¦è¦ºèªè¨æ¨¡å (VLM) çéå¤§ææ°ãå¨éé å·¥ä½ä¸­ï¼æåæåºå©ç¨®æ¹æ³ï¼ä½¿ç¨æ¨¡æ¬æ¸æå¢å¼· VLM çç©çæ¨çè½åãé¦åï¼æåä½¿ç¨èç©çæ¨çä»»åç¸éçæ¨¡æ¬ç¢ççåç­ (QA) å°ï¼å¾®èª¿é åè¨ç·´ç VLMãå¶æ¬¡ï¼æåå¼å¥äºç©çæå¢å»ºæ§å¨ (PCB)ï¼éæ¯ç¶éå¾®èª¿çå°æ¥­ VLMï¼ç¨æ¼å»ºç«è±å¯äºç©çå±¬æ§åéç¨çæå¢æè¿°ãå¨ç©çæ¨çä»»åæéï¼éäº PCB å¯ä»¥ä½çºæå¢ï¼åå©å¤§åèªè¨æ¨¡å (LLM) æ¹åå¶æè½ãæåä½¿ç¨å¤ååºæºå°æåçå©ç¨®æ¹æ³é²è¡è©ä¼°ï¼åæ¬ä¸åç¨±çº Falling Tower çæ°ç©©å®æ§åµæ¸¬ QA è³æéï¼å¶ä¸­åå«æ¨¡æ¬åçå¯¦ä¸ççå ´æ¯ï¼ä»¥å CLEVRERãæåè­æäºä¸åç¶é QA å¾®èª¿çå°å VLM å¯ä»¥é¡¯èåªæ¼æ´å¤§çæåé²åºç¤æ¨¡åãæåéè¡¨æï¼æ´å PCB å¯ä»¥æååºç¤ LLM å¨ç©çæ¨çä»»åä¸çæè½ãä½¿ç¨ Falling Tower è³æéä¸­ççå¯¦ä¸çå ´æ¯ï¼æåéé©è­äºå©ç¨®æ¹æ³å¨ Sim2Real è½ç§»ä¸­çç©©å¥æ§ãæåççµæçªé¡¯äºæ¨¡æ¬æ¸æå¨å»ºç«å·åé²éç©çæ¨çè½åçå­¸ç¿ç³»çµ±ä¸­å¯è½å·æçæç¨ã

##### **Image Retrieval Methods in the Dissimilarity Space**
2412.08618v1 by Madhu Kiran, Kartikey Vishnu, Rafael M. O. Cruz, Eric Granger

Image retrieval methods rely on metric learning to train backbone feature
extraction models that can extract discriminant queries and reference (gallery)
feature representations for similarity matching. Although state-of-the-art
accuracy has improved considerably with the advent of deep learning (DL) models
trained on large datasets, image retrieval remains challenging in many
real-world video analytics and surveillance applications, e.g., person
re-identification. Using the Euclidean space for matching limits the
performance in real-world applications due to the curse of dimensionality,
overfitting, and sensitivity to noisy data.
  We argue that the feature dissimilarity space is more suitable for similarity
matching, and propose a dichotomy transformation to project query and reference
embeddings into a single embedding in the dissimilarity space.
  We also advocate for end-to-end training of a backbone and binary
classification models for pair-wise matching. As opposed to comparing the
distance between queries and reference embeddings, we show the benefits of
classifying the single dissimilarity space embedding (as similar or
dissimilar), especially when trained end-to-end. We propose a method to train
the max-margin classifier together with the backbone feature extractor by
applying constraints to the L2 norm of the classifier weights along with the
hinge loss.
  Our extensive experiments on challenging image retrieval datasets and using
diverse feature extraction backbones highlight the benefits of similarity
matching in the dissimilarity space. In particular, when jointly training the
feature extraction backbone and regularised classifier for matching, the
dissimilarity space provides a higher level of accuracy.

æè¦ï¼å½±åæ·åæ¹æ³ä»°è³´åº¦éå­¸ç¿ä¾è¨ç·´ä¸»å¹¹ç¹å¾µæåæ¨¡åï¼æ­¤æ¨¡åå¯ä»¥æåè¾¨å¥å¼æ¥è©¢ååèï¼ååº«ï¼ç¹å¾µè¡¨ç¤ºï¼ä»¥é²è¡ç¸ä¼¼åº¦æ¯å°ãéç¶æåé²çæºç¢ºåº¦å·²é¨èå¨å¤§åè³æéä¸è¨ç·´çæ·±åº¦å­¸ç¿ï¼DLï¼æ¨¡åçåºç¾èå¤§å¹æåï¼ä½å¨è¨±å¤çå¯¦ä¸çå½±çåæåç£æ§æç¨ç¨å¼ä¸­ï¼å½±åæ·åä»å·æææ°æ§ï¼ä¾å¦äººå¡åè¾¨è­ãç±æ¼ç¶­åº¦ç½é£ãéåº¦æ¬ååå°éè¨è³æçæææ§ï¼ä½¿ç¨æ­å¹¾éå¾ç©ºéé²è¡æ¯å°æéå¶çå¯¦ä¸çæç¨ç¨å¼çæè½ã
æåä¸»å¼µç¹å¾µç¸ç°æ§ç©ºéæ´é©åç¸ä¼¼åº¦æ¯å°ï¼ä¸¦æåºäºåæ³è½æï¼å°æ¥è©¢ååèåµå¥æå½±å°ç¸ç°æ§ç©ºéä¸­çå®ä¸åµå¥ã
æåä¹æå¡å°ä¸»å¹¹åäºååé¡æ¨¡åé²è¡ç«¯å°ç«¯è¨ç·´ï¼ä»¥é²è¡æå°æ¯å°ãèæ¯è¼æ¥è©¢ååèåµå¥ä¹éçè·é¢ç¸åï¼æåå±ç¤ºäºå°å®ä¸ç¸ç°æ§ç©ºéåµå¥ï¼é¡ä¼¼æç¸ç°ï¼é²è¡åé¡çå¥½èï¼ç¹å¥æ¯å¨ç«¯å°ç«¯è¨ç·´æãæåæåºäºä¸ç¨®æ¹æ³ï¼ééå°åé¡å¨æ¬éç L2 ç¯æ¸å¥ç¨ç´æï¼ä»¥åé¸éæå¤±ï¼ä¾è¨ç·´æå¤§ééåé¡å¨åä¸»å¹¹ç¹å¾µèåå¨ã
æåå¨å·æææ°æ§çå½±åæ·åè³æéä¸é²è¡çå»£æ³å¯¦é©ï¼ä¸¦ä½¿ç¨ä¸åçç¹å¾µèåä¸»å¹¹ï¼çªé¡¯äºå¨ç¸ç°æ§ç©ºéä¸­é²è¡ç¸ä¼¼åº¦æ¯å°çå¥½èãç¹å¥æ¯å¨è¯åè¨ç·´ç¹å¾µèåä¸»å¹¹åæ­£è¦ååé¡å¨ä»¥é²è¡æ¯å°æï¼ç¸ç°æ§ç©ºéæä¾äºæ´é«çæºç¢ºåº¦ã

##### **Exploiting the Index Gradients for Optimization-Based Jailbreaking on Large Language Models**
2412.08615v1 by Jiahui Li, Yongchang Hao, Haoyu Xu, Xing Wang, Yu Hong

Despite the advancements in training Large Language Models (LLMs) with
alignment techniques to enhance the safety of generated content, these models
remain susceptible to jailbreak, an adversarial attack method that exposes
security vulnerabilities in LLMs. Notably, the Greedy Coordinate Gradient (GCG)
method has demonstrated the ability to automatically generate adversarial
suffixes that jailbreak state-of-the-art LLMs. However, the optimization
process involved in GCG is highly time-consuming, rendering the jailbreaking
pipeline inefficient. In this paper, we investigate the process of GCG and
identify an issue of Indirect Effect, the key bottleneck of the GCG
optimization. To this end, we propose the Model Attack Gradient Index GCG
(MAGIC), that addresses the Indirect Effect by exploiting the gradient
information of the suffix tokens, thereby accelerating the procedure by having
less computation and fewer iterations. Our experiments on AdvBench show that
MAGIC achieves up to a 1.5x speedup, while maintaining Attack Success Rates
(ASR) on par or even higher than other baselines. Our MAGIC achieved an ASR of
74% on the Llama-2 and an ASR of 54% when conducting transfer attacks on
GPT-3.5. Code is available at https://github.com/jiah-li/magic.

æè¦ï¼åç®¡å¨ä½¿ç¨èª¿æ´æè¡è¨ç·´å¤§åèªè¨æ¨¡å (LLM) ä»¥å¢å¼·æç¢çå§å®¹çå®å¨æ§çéç¨ä¸­åå¾é²å±ï¼ä½éäºæ¨¡åä»å®¹æåå°è¶çæ»æï¼éæ¯ä¸ç¨®ææ´é² LLM ä¸­å®å¨æ¼æ´çå°ææ»ææ¹æ³ãå¼å¾æ³¨æçæ¯ï¼è²ªå©ªåæ¨æ¢¯åº¦ (GCG) æ¹æ³å·²è­ææè½åèªåç¢çå°æå¾ç¶´ï¼ä»¥è¶çæåé²ç LLMãç¶èï¼GCG ä¸­æ¶åçæä½³åéç¨éå¸¸èæï¼å°è´è¶çç®¡éæçä½ä¸ãå¨æ¬æä¸­ï¼æåç ç©¶äº GCG çéç¨ï¼ä¸¦æ¾åºéæ¥ææçåé¡ï¼éæ¯ GCG æä½³åçééµç¶é ¸ãçºæ­¤ï¼æåæåºäºæ¨¡åæ»ææ¢¯åº¦ææ¨ GCG (MAGIC)ï¼å®ééå©ç¨å¾ç¶´æ¨è¨çæ¢¯åº¦è³è¨ä¾è§£æ±ºéæ¥ææï¼å¾èééæ¸å°éç®ååè¦éç®ä¾å éç¨åºãæåå¨ AdvBench ä¸çå¯¦é©é¡¯ç¤ºï¼MAGIC å¯å°éåº¦æåè³ 1.5 åï¼åæç¶­ææ»ææåç (ASR) èå¶ä»åºç·ç¸ç¶ï¼çè³æ´é«ãæåç MAGIC å¨ Llama-2 ä¸éå°äº 74% ç ASRï¼å¨å° GPT-3.5 é²è¡è½ç§»æ»ææéå°äº 54% ç ASRãç¨å¼ç¢¼å¯æ¼ https://github.com/jiah-li/magic åå¾ã

##### **Competition and Diversity in Generative AI**
2412.08610v1 by Manish Raghavan

Recent evidence suggests that the use of generative artificial intelligence
reduces the diversity of content produced. In this work, we develop a
game-theoretic model to explore the downstream consequences of content
homogeneity when producers use generative AI to compete with one another. At
equilibrium, players indeed produce content that is less diverse than optimal.
However, stronger competition mitigates homogeneity and induces more diverse
production. Perhaps more surprisingly, we show that a generative AI model that
performs well in isolation (i.e., according to a benchmark) may fail to do so
when faced with competition, and vice versa. We validate our results
empirically by using language models to play Scattergories, a word game in
which players are rewarded for producing answers that are both correct and
unique. We discuss how the interplay between competition and homogeneity has
implications for the development, evaluation, and use of generative AI.

æè¦ï¼æè¿çè­æè¡¨æï¼ä½¿ç¨çæå¼äººå·¥æºæ§ææ¸å°ç¢åºå§å®¹çå¤æ¨£æ§ãå¨éé å·¥ä½ä¸­ï¼æåéç¼äºä¸ååå¼è«æ¨¡åä¾æ¢è¨ç¶çç¢èä½¿ç¨çæå¼äººå·¥æºæ§å½¼æ­¤ç«¶ç­æï¼å§å®¹åè³ªæ§çä¸æ¸¸å¾æãå¨åè¡¡çæä¸ï¼åèèç¢ºå¯¦æçç¢åºå¤æ¨£æ§ä½æ¼æä½³çæçå§å®¹ãç¶èï¼æ´å¼·ççç«¶ç­ææ¸è¼åè³ªæ§ä¸¦èªå°æ´å¤æ¨£åççç¢ãæè¨±æ´ä»¤äººé©è¨çæ¯ï¼æåè¡¨æä¸åå¨å­¤ç«çæä¸è¡¨ç¾è¯å¥½ççæå¼äººå·¥æºæ§æ¨¡åï¼å³æ ¹æåºæºï¼ï¼å¨é¢å°ç«¶ç­æå¯è½ç¡æ³è¡¨ç¾è¯å¥½ï¼åä¹äº¦ç¶ãæåä½¿ç¨èªè¨æ¨¡åç©çè¬éæ² Scattergories ä¾é©è­æåççµæï¼éæ¯ä¸åå®å­éæ²ï¼ç©å®¶å ç¢çæ­£ç¢ºä¸ç¨ç¹çç­æ¡èç²å¾çåµãæåè¨è«ç«¶ç­ååè³ªæ§ä¹éçäº¤äºä½ç¨å¦ä½å°çæå¼äººå·¥æºæ§çéç¼ãè©ä¼°åä½¿ç¨ç¢çå½±é¿ã

##### **AdvWave: Stealthy Adversarial Jailbreak Attack against Large Audio-Language Models**
2412.08608v1 by Mintong Kang, Chejian Xu, Bo Li

Recent advancements in large audio-language models (LALMs) have enabled
speech-based user interactions, significantly enhancing user experience and
accelerating the deployment of LALMs in real-world applications. However,
ensuring the safety of LALMs is crucial to prevent risky outputs that may raise
societal concerns or violate AI regulations. Despite the importance of this
issue, research on jailbreaking LALMs remains limited due to their recent
emergence and the additional technical challenges they present compared to
attacks on DNN-based audio models. Specifically, the audio encoders in LALMs,
which involve discretization operations, often lead to gradient shattering,
hindering the effectiveness of attacks relying on gradient-based optimizations.
The behavioral variability of LALMs further complicates the identification of
effective (adversarial) optimization targets. Moreover, enforcing stealthiness
constraints on adversarial audio waveforms introduces a reduced, non-convex
feasible solution space, further intensifying the challenges of the
optimization process. To overcome these challenges, we develop AdvWave, the
first jailbreak framework against LALMs. We propose a dual-phase optimization
method that addresses gradient shattering, enabling effective end-to-end
gradient-based optimization. Additionally, we develop an adaptive adversarial
target search algorithm that dynamically adjusts the adversarial optimization
target based on the response patterns of LALMs for specific queries. To ensure
that adversarial audio remains perceptually natural to human listeners, we
design a classifier-guided optimization approach that generates adversarial
noise resembling common urban sounds. Extensive evaluations on multiple
advanced LALMs demonstrate that AdvWave outperforms baseline methods, achieving
a 40% higher average jailbreak attack success rate.

æè¦ï¼<paragraph>å¤§åèªé³èªè¨æ¨¡å (LALM) æè¿çé²å±å·²ç¶å¯¦ç¾äºåºæ¼èªé³çä½¿ç¨èäºåï¼å¤§å¹æåä½¿ç¨èé«é©ï¼ä¸¦å é LALM å¨å¯¦éæç¨ä¸­çé¨ç½²ãä¸éï¼ç¢ºä¿ LALM çå®å¨æ§è³ééè¦ï¼ä»¥é²æ­¢ç¢çæé¢¨éªçè¼¸åºï¼éäºè¼¸åºå¯è½æå¼ç¼ç¤¾æåé¡æéå AI æ³è¦ãåç®¡éååé¡å¾éè¦ï¼ä½ç±æ¼ LALM æè¿æåºç¾ï¼èä¸èéå°åºæ¼æ·±åº¦ç¥ç¶ç¶²è·¯ (DNN) çé³è¨æ¨¡åçæ»æç¸æ¯ï¼LALM å·æé¡å¤çæè¡ææ°ï¼å æ­¤å° LALM é²è¡è¶ççç ç©¶ä»ç¶æéãå·é«ä¾èªªï¼LALM ä¸­çé³è¨ç·¨ç¢¼å¨æ¶åé¢æ£åéç®ï¼ééå¸¸æå°è´æ¢¯åº¦ç ´ç¢ï¼é²èå¦¨ç¤ä¾è³´æ¼åºæ¼æ¢¯åº¦çæä½³åçæ»æçæææ§ãLALM çè¡çºè®ç°æ§é²ä¸æ­¥è¤éåäºææï¼å°ææ§ï¼æä½³åç®æ¨çè­å¥ãæ­¤å¤ï¼å°å°ææ§é³è¨æ³¢å½¢æ½å é±è½æ§ç´ææå¼å¥ä¸åç¸®å°çéå¸å¯è¡è§£ç©ºéï¼é²ä¸æ­¥å åäºæä½³åéç¨çææ°ãçºäºåæéäºææ°ï¼æåéç¼äº AdvWaveï¼éæ¯éå° LALM çç¬¬ä¸åè¶çæ¶æ§ãæåæåºäºä¸ç¨®ééæ®µæä½³åæ¹æ³ï¼å®å¯ä»¥è§£æ±ºæ¢¯åº¦ç ´ç¢åé¡ï¼å¾èå¯¦ç¾ææçç«¯å°ç«¯åºæ¼æ¢¯åº¦çæä½³åãæ­¤å¤ï¼æåéç¼äºä¸åé©ææ§å°æç®æ¨æå°æ¼ç®æ³ï¼å®å¯ä»¥æ ¹æ LALM å°ç¹å®æ¥è©¢çåææ¨¡å¼åæèª¿æ´å°ææ§æä½³åç®æ¨ãçºäºç¢ºä¿å°ææ§é³è¨å°äººé¡è½ç¾ä¾èªªå¨æç¥ä¸ä»ç¶èªç¶ï¼æåè¨­è¨äºä¸ç¨®åé¡å¨å¼å°çæä½³åæ¹æ³ï¼å®æç¢çé¡ä¼¼æ¼å¸¸è¦åå¸è²é³çå°ææ§éè¨ãå¨å¤åé²é LALM ä¸çå»£æ³è©ä¼°è­æï¼AdvWave åªæ¼åºæºæ¹æ³ï¼éå°äºé«åº 40% çå¹³åè¶çæ»ææåçã</paragraph>

##### **Preference Discerning with LLM-Enhanced Generative Retrieval**
2412.08604v1 by Fabian Paischer, Liu Yang, Linfeng Liu, Shuai Shao, Kaveh Hassani, Jiacheng Li, Ricky Chen, Zhang Gabriel Li, Xialo Gao, Wei Shao, Xue Feng, Nima Noorshams, Sem Park, Bo Long, Hamid Eghbalzadeh

Sequential recommendation systems aim to provide personalized recommendations
for users based on their interaction history. To achieve this, they often
incorporate auxiliary information, such as textual descriptions of items and
auxiliary tasks, like predicting user preferences and intent. Despite numerous
efforts to enhance these models, they still suffer from limited
personalization. To address this issue, we propose a new paradigm, which we
term preference discerning. In preference dscerning, we explicitly condition a
generative sequential recommendation system on user preferences within its
context. To this end, we generate user preferences using Large Language Models
(LLMs) based on user reviews and item-specific data. To evaluate preference
discerning capabilities of sequential recommendation systems, we introduce a
novel benchmark that provides a holistic evaluation across various scenarios,
including preference steering and sentiment following. We assess current
state-of-the-art methods using our benchmark and show that they struggle to
accurately discern user preferences. Therefore, we propose a new method named
Mender ($\textbf{M}$ultimodal Prefer$\textbf{en}$ce
$\textbf{d}$iscern$\textbf{er}$), which improves upon existing methods and
achieves state-of-the-art performance on our benchmark. Our results show that
Mender can be effectively guided by human preferences even though they have not
been observed during training, paving the way toward more personalized
sequential recommendation systems. We will open-source the code and benchmarks
upon publication.

æè¦ï¼åºåæ¨è¦ç³»çµ±æ¨å¨æ ¹æä½¿ç¨èçäºåè¨éæä¾åäººåæ¨è¦ãçºæ­¤ï¼å®åéå¸¸æç´å¥è¼å©è³è¨ï¼ä¾å¦é ç®çæå­æè¿°åè¼å©ä»»åï¼ä¾å¦é æ¸¬ä½¿ç¨èåå¥½åæåãåç®¡çºå¢å¼·éäºæ¨¡åä»åºäºè¨±å¤åªåï¼ä½å®åä»åå°åäººåæéçå½±é¿ãçºäºè§£æ±ºéååé¡ï¼æåæåºäºä¸åæ°çç¯ä¾ï¼æåç¨±ä¹çºåå¥½è¾¨è­ãå¨åå¥½è¾¨è­ä¸­ï¼æåæç¢ºå°å°çæå¼åºåæ¨è¦ç³»çµ±ç½®æ¼å¶å§å®¹ä¸­çä½¿ç¨èåå¥½ä¹ä¸ãçºæ­¤ï¼æåæ ¹æä½¿ç¨èè©è«åç¹å®æ¼å°æ¡çè³æï¼ä½¿ç¨å¤§åèªè¨æ¨¡å (LLM) ä¾ç¢çä½¿ç¨èåå¥½ãçºäºè©ä¼°åºåæ¨è¦ç³»çµ±çåå¥½è¾¨è­è½åï¼æåå¼å¥äºä¸åæ°çåºæºï¼å®æä¾äºè·¨ä¸åå ´æ¯çæ´é«è©ä¼°ï¼åæ¬åå¥½å°ååæç·è¿½è¹¤ãæåä½¿ç¨æåçåºæºè©ä¼°äºç¶åæåé²çæ¹æ³ï¼ä¸¦è¡¨æå®åé£ä»¥æºç¢ºè¾¨è­ä½¿ç¨èåå¥½ãå æ­¤ï¼æåæåºäºä¸ç¨®åçº Menderï¼**M**ultimodal Prefer**en**ce **d**iscern**er**ï¼çæ°æ¹æ³ï¼å®æ¹é²äºç¾ææ¹æ³ï¼ä¸¦å¨æåçåºæºä¸éå°äºæåé²çæè½ãæåççµæè¡¨æï¼å³ä½¿å¨è¨ç·´æéæªè§å¯å°äººé¡åå¥½ï¼Mender ä¹å¯ä»¥ææå°åå°äººé¡åå¥½çæå°ï¼çºæ´åäººåçåºåæ¨è¦ç³»çµ±éªå¹³äºéè·¯ãæåå°å¨ç¼è¡¨å¾éæ¾åå§ç¢¼ååºæºã

##### **Der Effizienz- und Intelligenzbegriff in der Lexikographie und kuenstlichen Intelligenz: kann ChatGPT die lexikographische Textsorte nachbilden?**
2412.08599v1 by Ivan Arias-Arias, Maria Jose Dominguez Vazquez, Carlos Valcarcel Riveiro

By means of pilot experiments for the language pair German and Galician, this
paper examines the concept of efficiency and intelligence in lexicography and
artificial intelligence, AI. The aim of the experiments is to gain empirically
and statistically based insights into the lexicographical text type,dictionary
article, in the responses of ChatGPT 3.5, as well as into the lexicographical
data on which this chatbot was trained. Both quantitative and qualitative
methods are used for this purpose. The analysis is based on the evaluation of
the outputs of several sessions with the same prompt in ChatGPT 3.5. On the one
hand, the algorithmic performance of intelligent systems is evaluated in
comparison with data from lexicographical works. On the other hand, the ChatGPT
data supplied is analysed using specific text passages of the aforementioned
lexicographical text type. The results of this study not only help to evaluate
the efficiency of this chatbot regarding the creation of dictionary articles,
but also to delve deeper into the concept of intelligence, the thought
processes and the actions to be carried out in both disciplines.

æè¦ï¼ééå¾·èªåå å©è¥¿äºèªå°èªè¨çè©¦é©ï¼æ¬ææ¢è¨äºè©å½å­¸åäººå·¥æºæ§ï¼AIï¼ä¸­çæçåæºæ§æ¦å¿µãå¯¦é©çç®çæ¯éé ChatGPT 3.5 çåæï¼ä»¥åè¨ç·´éåèå¤©æ©å¨äººçè©å½å­¸è³æï¼ä¾ç²å¾è©å½ææ¬é¡åï¼å­å¸æ¢ç®ï¼çç¶é©åçµ±è¨è¦è§£ãçºæ­¤ï¼æåä½¿ç¨å®éåå®æ§æ¹æ³ãåææ¯æ ¹æå° ChatGPT 3.5 ä¸­ä½¿ç¨ç¸åæç¤ºçå¹¾åæè©±çè¼¸åºé²è¡è©ä¼°ãä¸æ¹é¢ï¼æåè©ä¼°äºæºæ§ç³»çµ±çæ¼ç®æ³æè½ï¼ä¸¦èè©å½å­¸èä½çè³æé²è¡æ¯è¼ãå¦ä¸æ¹é¢ï¼æåä½¿ç¨ä¸è¿°è©å½å­¸ææ¬é¡åçç¹å®æå­æ®µè½ä¾åææä¾ç ChatGPT è³æãéé ç ç©¶ççµæä¸åæå©æ¼è©ä¼°éåèå¤©æ©å¨äººå¨å»ºç«å­å¸æ¢ç®æ¹é¢çæçï¼éè½æ´æ·±å¥å°æ¢è¨æºæ§ãæèéç¨ä»¥åå¨å©åé åä¸­å·è¡çè¡åã

##### **RoomTour3D: Geometry-Aware Video-Instruction Tuning for Embodied Navigation**
2412.08591v1 by Mingfei Han, Liang Ma, Kamila Zhumakhanova, Ekaterina Radionova, Jingyi Zhang, Xiaojun Chang, Xiaodan Liang, Ivan Laptev

Vision-and-Language Navigation (VLN) suffers from the limited diversity and
scale of training data, primarily constrained by the manual curation of
existing simulators. To address this, we introduce RoomTour3D, a
video-instruction dataset derived from web-based room tour videos that capture
real-world indoor spaces and human walking demonstrations. Unlike existing VLN
datasets, RoomTour3D leverages the scale and diversity of online videos to
generate open-ended human walking trajectories and open-world navigable
instructions. To compensate for the lack of navigation data in online videos,
we perform 3D reconstruction and obtain 3D trajectories of walking paths
augmented with additional information on the room types, object locations and
3D shape of surrounding scenes. Our dataset includes $\sim$100K open-ended
description-enriched trajectories with $\sim$200K instructions, and 17K
action-enriched trajectories from 1847 room tour environments. We demonstrate
experimentally that RoomTour3D enables significant improvements across multiple
VLN tasks including CVDN, SOON, R2R, and REVERIE. Moreover, RoomTour3D
facilitates the development of trainable zero-shot VLN agents, showcasing the
potential and challenges of advancing towards open-world navigation.

æè¦ï¼è¦è¦ºèªè¨å°èª (VLN) åå°è¨ç·´è³æçå¤æ¨£æ§åè¦æ¨¡éå¶ï¼éä¸»è¦æ¯åå°ç¾ææ¨¡æ¬å¨æåç­åçç´æãçºäºè§£æ±ºéååé¡ï¼æåå¼å¥äº RoomTour3Dï¼ä¸åå¾ç¶²è·¯ä¸çæ¿éå°è¦½å½±çä¸­è¡ççå½±çæä»¤è³æéï¼è©²è³æéæ·åäºçå¯¦ä¸ççå®¤å§ç©ºéåäººé¡è¡èµ°ç¤ºç¯ãèç¾æç VLN è³æéä¸åï¼RoomTour3D å©ç¨ç·ä¸å½±ççè¦æ¨¡åå¤æ¨£æ§ä¾ç¢çéæ¾å¼çè¡èµ°è»è·¡åéæ¾ä¸ççå°èªæä»¤ãçºäºå½è£ç·ä¸å½±çä¸­å°èªè³æçä¸è¶³ï¼æåå·è¡ 3D éå»ºï¼ä¸¦åå¾è¡èµ°è·¯å¾ç 3D è»è·¡ï¼ä¸¦å ä¸æ¿éé¡åãç©ä»¶ä½ç½®åå¨åå ´æ¯ç 3D å½¢çç­é¡å¤è³è¨ãæåçè³æéåå«å¤§ç´ 10 è¬åéæ¾å¼æè¿°è±å¯çè»è·¡ï¼å¶ä¸­æå¤§ç´ 20 è¬åæä»¤ï¼ä»¥åä¾èª 1847 åæ¿éå°è¦½ç°å¢ç 1 è¬ 7 åååä½è±å¯çè»è·¡ãæåééå¯¦é©è­æï¼RoomTour3D è½å¨å¤å VLN ä»»åä¸­å¸¶ä¾é¡¯èçæ¹åï¼åæ¬ CVDNãSOONãR2R å REVERIEãæ­¤å¤ï¼RoomTour3D ä¿é²äºå¯è¨ç·´çé¶æ¬¡å­¸ç¿ VLN ä»£ççéç¼ï¼å±ç¤ºäºéåéæ¾ä¸çå°èªçæ½ååææ°ã

##### **Advancing Single- and Multi-task Text Classification through Large Language Model Fine-tuning**
2412.08587v1 by Hang Zhao, Qile P. Chen, Yijing Barry Zhang, Gang Yang

Both encoder-only models (e.g., BERT, RoBERTa) and large language models
(LLMs, e.g., Llama3) have been widely used for text classification tasks.
However, there is a lack of systematic studies comparing the performance of
encoder-based models and LLMs in text classification, particularly when
fine-tuning is involved. This study employed a diverse range of models and
methods, varying in size and architecture, and including both fine-tuned and
pre-trained approaches. We first assessed the performances of these LLMs on the
20 Newsgroups (20NG) and MASSIVE datasets, comparing them to encoder-only
RoBERTa models. Additionally, we explored the multi-task capabilities of both
model types by combining multiple classification tasks, including intent
detection and slot-filling, into a single model using data from both datasets.
Our results indicate that fully fine-tuned Llama3-70B models outperform
RoBERTa-large and other decoder LLMs across various classification tasks and
datasets. Moreover, the consolidated multi-task fine-tuned LLMs matched the
performance of dual-model setups in both tasks across both datasets. Overall,
our study provides a comprehensive benchmark of encoder-only and LLM models on
text classification tasks and demonstrates a method to combine two or more
fully fine-tuned decoder LLMs for reduced latency and equivalent performance.

æè¦ï¼<paragraph>åç·¨ç¢¼å¨æ¨¡åï¼ä¾å¦ BERTãRoBERTaï¼åå¤§èªè¨æ¨¡åï¼LLMï¼ä¾å¦ Llama3ï¼å·²è¢«å»£æ³ç¨æ¼ææ¬åé¡ä»»åã
ç¶èï¼ç¼ºä¹æ¯è¼ç·¨ç¢¼å¨æ¨¡åå LLM å¨ææ¬åé¡ä¸­çæè½çç³»çµ±æ§ç ç©¶ï¼ç¹å¥æ¯å¨æ¶åå¾®èª¿æãæ¬ç ç©¶æ¡ç¨äºåç¨®ä¸åçæ¨¡ååæ¹æ³ï¼å¨å¤§å°åæ¶æ§ä¸ææä¸åï¼ä¸¦ä¸åæ¬å¾®èª¿åé è¨ç·´æ¹æ³ãæåé¦åè©ä¼°äºéäº LLM å¨ 20 åæ°èçµ (20NG) å MASSIVE è³æéä¸çæè½ï¼ä¸¦å°å¶èåç·¨ç¢¼å¨ RoBERTa æ¨¡åé²è¡æ¯è¼ãæ­¤å¤ï¼æåééå°å¤ååé¡ä»»åï¼åæ¬æååµæ¸¬åæ§½ä½å¡«è£ï¼çµåå°ä¸åæ¨¡åä¸­ï¼ä½¿ç¨ä¾èªå©åè³æéçè³æï¼æ¢ç´¢äºå©ç¨®æ¨¡åé¡åçå¤ä»»ååè½ãæåççµæè¡¨æï¼ç¶éå®å¨å¾®èª¿ç Llama3-70B æ¨¡åå¨åç¨®åé¡ä»»ååè³æéä¸åªæ¼ RoBERTa-large åå¶ä»è§£ç¢¼å¨ LLMãæ­¤å¤ï¼åä½µçå¤ä»»åå¾®èª¿ LLM å¨å©åä»»åä¸­é½èéæ¨¡åè¨­å®çæè½ç¸å¹éãç¸½é«èè¨ï¼æåçç ç©¶æä¾äºç·¨ç¢¼å¨å LLM æ¨¡åå¨ææ¬åé¡ä»»åä¸çå¨é¢åºæºï¼ä¸¦å±ç¤ºäºä¸ç¨®çµåå©åææ´å¤å®å¨å¾®èª¿çè§£ç¢¼å¨ LLM ä»¥éä½å»¶é²åç­ææè½çæ¹æ³ã</paragraph>

##### **TURBOATTENTION: Efficient Attention Approximation For High Throughputs LLMs**
2412.08585v1 by Hao Kang, Srikant Bharadwaj, James Hensman, Tushar Krishna, Victor Ruhle, Saravan Rajmohan

Large language model (LLM) inference demands significant amount of
computation and memory, especially in the key attention mechanism. While
techniques, such as quantization and acceleration algorithms, like
FlashAttention, have improved efficiency of the overall inference, they address
different aspects of the problem: quantization focuses on weight-activation
operations, while FlashAttention improves execution but requires high-precision
formats. Recent Key-value (KV) cache quantization reduces memory bandwidth but
still needs floating-point dequantization for attention operation.
  We present TurboAttention, a comprehensive approach to enable quantized
execution of attention that simultaneously addresses both memory and
computational efficiency. Our solution introduces two key innovations: FlashQ,
a headwise attention quantization technique that enables both compression of KV
cache and quantized execution of activation-activation multiplication, and
Sparsity-based Softmax Approximation (SAS), which eliminates the need for
dequantization to FP32 during exponentiation operation in attention.
Experimental results demonstrate that TurboAttention achieves 1.2-1.8x speedup
in attention, reduces the KV cache size by over 4.4x, and enables up to 2.37x
maximum throughput over the FP16 baseline while outperforming state-of-the-art
quantization and compression techniques across various datasets and models.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) æ¨è«éè¦å¤§éçéç®åè¨æ¶é«ï¼ç¹å¥æ¯å¨ééµçæ³¨æåæ©å¶ä¸­ãéç¶éååå éæ¼ç®æ³ç­æè¡ï¼ä¾å¦ FlashAttentionï¼å·²æ¹åæ´é«æ¨è«æçï¼ä½å®åè§£æ±ºäºåé¡çä¸åé¢åï¼éåå°æ³¨æ¼æ¬éååæä½ï¼è FlashAttention åæ¹åå·è¡ï¼ä½éè¦é«ç²¾åº¦æ ¼å¼ãæè¿ç Key-value (KV) å¿«åéåæ¸å°äºè¨æ¶é«é »å¯¬ï¼ä½ä»éè¦æµ®é»å»éåä»¥é²è¡æ³¨æåæä½ã
æåæåº TurboAttentionï¼éæ¯ä¸ç¨®å¨é¢çæ¹æ³ï¼ç¨æ¼åç¨æ³¨æåçéåå·è¡ï¼åæèçè¨æ¶é«åéç®æçãæåçè§£æ±ºæ¹æ¡å¼å¥äºå©é ééµåµæ°ï¼FlashQï¼ä¸ç¨®é ­é¨æ³¨æåéåæè¡ï¼å¯åæå£ç¸® KV å¿«åååç¨ååä¹æ³çéåå·è¡ï¼ä»¥ååºæ¼ç¨çæ§ç Softmax è¿ä¼¼ (SAS)ï¼å®æ¶é¤äºå¨æ³¨æåä¸­ææ¸éç®æéå° FP32 å»éåçéæ±ã
å¯¦é©çµæè¡¨æï¼TurboAttention å¨æ³¨æåæ¹é¢å¯¦ç¾äº 1.2-1.8 åçå éï¼å° KV å¿«åå¤§å°æ¸å°äº 4.4 åä»¥ä¸ï¼ä¸¦å¨åç¨®è³æéåæ¨¡åä¸åªæ¼æåé²çéååå£ç¸®æè¡ï¼åæåç¨äºæ¯ FP16 åºç·é«é 2.37 åçæå¤§ååéã

##### **Machine Learning Information Retrieval and Summarisation to Support Systematic Review on Outcomes Based Contracting**
2412.08578v1 by Iman Munire Bilal, Zheng Fang, Miguel Arana-Catania, Felix-Anselm van Lier, Juliana Outes Velarde, Harry Bregazzi, Eleanor Carter, Mara Airoldi, Rob Procter

As academic literature proliferates, traditional review methods are
increasingly challenged by the sheer volume and diversity of available
research. This article presents a study that aims to address these challenges
by enhancing the efficiency and scope of systematic reviews in the social
sciences through advanced machine learning (ML) and natural language processing
(NLP) tools. In particular, we focus on automating stages within the systematic
reviewing process that are time-intensive and repetitive for human annotators
and which lend themselves to immediate scalability through tools such as
information retrieval and summarisation guided by expert advice. The article
concludes with a summary of lessons learnt regarding the integrated approach
towards systematic reviews and future directions for improvement, including
explainability.

æè¦ï¼é¨èå­¸è¡æç»çæ¿å¢ï¼å³çµ±çå¯©æ¥æ¹æ³è¶ä¾è¶åå°å¯ç¨ç ç©¶çé¾å¤§æ¸éåå¤æ¨£æ§çææ°ãæ¬ææåºäºä¸é ç ç©¶ï¼æ¨å¨ééåé²çæ©å¨å­¸ç¿ (ML) åèªç¶èªè¨èç (NLP) å·¥å·ä¾æé«ç¤¾æç§å­¸ä¸­ç³»çµ±æ§å¯©æ¥çæçåç¯åï¼ä»¥æå°éäºææ°ãç¹å¥æ¯ï¼æåå°æ³¨æ¼èªååç³»çµ±æ§å¯©æ¥éç¨ä¸­èæä¸å°äººé¡è¨»éèä¾èªªéè¤çéæ®µï¼éäºéæ®µæ¬èº«å°±å¯ä»¥ééä¿¡æ¯æª¢ç´¢åå°å®¶å»ºè­°æå°çæè¦ç­å·¥å·ç«å³å¯¦ç¾å¯æ´å±æ§ãæ¬ææå¾ç¸½çµäºéæ¼ç³»çµ±æ§å¯©æ¥çç¶åæ¹æ³åæ¹é²çæªä¾æ¹åï¼åæ¬å¯è§£éæ§ï¼çç¶é©æè¨ã

##### **GenPlan: Generative sequence models as adaptive planners**
2412.08565v1 by Akash Karthikeyan, Yash Vardhan Pant

Offline reinforcement learning has shown tremendous success in behavioral
planning by learning from previously collected demonstrations. However,
decision-making in multitask missions still presents significant challenges.
For instance, a mission might require an agent to explore an unknown
environment, discover goals, and navigate to them, even if it involves
interacting with obstacles along the way. Such behavioral planning problems are
difficult to solve due to: a) agents failing to adapt beyond the single task
learned through their reward function, and b) the inability to generalize to
new environments not covered in the training demonstrations, e.g., environments
where all doors were unlocked in the demonstrations. Consequently,
state-of-the-art decision making methods are limited to missions where the
required tasks are well-represented in the training demonstrations and can be
solved within a short (temporal) planning horizon. To address this, we propose
GenPlan: a stochastic and adaptive planner that leverages discrete-flow models
for generative sequence modeling, enabling sample-efficient exploration and
exploitation. This framework relies on an iterative denoising procedure to
generate a sequence of goals and actions. This approach captures multi-modal
action distributions and facilitates goal and task discovery, thereby enhancing
generalization to out-of-distribution tasks and environments, i.e., missions
not part of the training data. We demonstrate the effectiveness of our method
through multiple simulation environments. Notably, GenPlan outperforms the
state-of-the-art methods by over 10% on adaptive planning tasks, where the
agent adapts to multi-task missions while leveraging demonstrations on
single-goal-reaching tasks.

æè¦ï¼<paragraph>é¢ç·å¼·åå­¸ç¿å·²å¨è¡çºè¦åæ¹é¢å±ç¾åºå·¨å¤§çæåï¼æ¹æ³æ¯å¾ååæ¶éçç¤ºç¯ä¸­å­¸ç¿ãç¶èï¼å¤ä»»åä»»åä¸­çæ±ºç­å¶å®ä»å¸¶ä¾éå¤§ææ°ãä¾å¦ï¼ä»»åå¯è½éè¦ä»£çæ¢ç´¢æªç¥ç°å¢ãç¼ç¾ç®æ¨ä¸¦å°èªè³ç®æ¨ï¼å³ä½¿éæ¶åèæ²¿ééç¤ç©äºåãæ­¤é¡è¡çºè¦ååé¡é£ä»¥è§£æ±ºï¼åå æï¼a) ä»£çç¡æ³é©æè¶åºå¶çåµå½æ¸æå­¸å°çå®ä¸ä»»åï¼ä»¥å b) ç¡æ³æ¦æ¬å°è¨ç·´ç¤ºç¯ä¸­æªæ¶µèçæ°ç°å¢ï¼ä¾å¦ï¼å¨ç¤ºç¯ä¸­ææéé½å·²è§£éçç°å¢ãå æ­¤ï¼æåé²çæ±ºç­å¶å®æ¹æ³åéæ¼è¨ç·´ç¤ºç¯ä¸­åååç¾æéä»»åä¸å¯ä»¥å¨ç­ï¼æéï¼è¦åç¯åå§è§£æ±ºçä»»åãçºäºè§£æ±ºæ­¤åé¡ï¼æåæåº GenPlanï¼ä¸åé¨æ©ä¸èªé©æè¦åå¨ï¼å®å©ç¨é¢æ£æµæ¨¡åé²è¡çæåºåå»ºæ¨¡ï¼å¾èå¯¦ç¾æ¨£æ¬æææ¢ç´¢åå©ç¨ãæ­¤æ¡æ¶ä¾è³´æ¼åè¦çå»åªç¨åºï¼ä»¥ç¢çç®æ¨ååä½åºåãæ­¤æ¹æ³æ·åå¤æ¨¡æåä½åä½ï¼ä¸¦ä¿é²ç®æ¨åä»»åç¼ç¾ï¼å¾èå¢å¼·å°åå¸å¤ä»»ååç°å¢çæ¦æ¬ï¼å³ï¼ä¸å±¬æ¼è¨ç·´æ¸æçä»»åãæåééå¤åæ¨¡æ¬ç°å¢å±ç¤ºäºæåæ¹æ³çæææ§ãå¼å¾æ³¨æçæ¯ï¼å¨èªé©æè¦åä»»åä¸ï¼GenPlan çè¡¨ç¾åªæ¼æåé²çæ¹æ³è¶é 10%ï¼å¶ä¸­ä»£çé©æå¤ä»»åä»»åï¼åæå©ç¨å®ä¸ç®æ¨å°éä»»åçç¤ºç¯ã</paragraph>

##### **Can We Generate Visual Programs Without Prompting LLMs?**
2412.08564v1 by Michal Shlapentokh-Rothman, Yu-Xiong Wang, Derek Hoiem

Visual programming prompts LLMs (large language mod-els) to generate
executable code for visual tasks like visual question answering (VQA).
Prompt-based methods are difficult to improve while also being unreliable and
costly in both time and money. Our goal is to develop an efficient visual
programming system without 1) using prompt-based LLMs at inference time and 2)
a large set of program and answer annotations. We develop a synthetic data
augmentation approach and alternative program generation method based on
decoupling programs into higher-level skills called templates and the
corresponding arguments. Our results show that with data augmentation,
prompt-free smaller LLMs ($\approx$ 1B parameters) are competitive with
state-of-the art models with the added benefit of much faster inference

æè¦ï¼è¦è¦ºç¨å¼è¨­è¨æç¤º LLMï¼å¤§åèªè¨æ¨¡åï¼çºè¦è¦ºä»»åï¼ä¾å¦è¦è¦ºåç­ (VQA)ï¼ç¢çå¯å·è¡çç¨å¼ç¢¼ã
æç¤ºå¼æ¹æ³é£ä»¥æ¹é²ï¼èä¸å¨æéåéé¢ä¸æ¢ä¸å¯é åæè²´ãæåçç®æ¨æ¯éç¼ä¸åé«æçè¦è¦ºç¨å¼è¨­è¨ç³»çµ±ï¼ä¸ 1) å¨æ¨çæéä½¿ç¨æç¤ºå¼ LLMï¼ä»¥å 2) å¤§éçç¨å¼åç­æ¡è¨»è§£ãæåéç¼äºä¸ç¨®åºæ¼å°ç¨å¼è§£è¦æç¨±çºç¯æ¬çé«éæè½ï¼ä»¥åå°æåæ¸çåæè³ææ´åæ¹æ³åæ¿ä»£ç¨å¼ç¢çæ¹æ³ãæåççµæé¡¯ç¤ºï¼ä½¿ç¨è³ææ´åï¼ç¡æç¤ºå¼è¼å°ç LLMï¼$\approx$ 1B åæ¸ï¼èæåé²çæ¨¡åå·æç«¶ç­åï¼èä¸å·ææ¨çéåº¦æ´å¿«çéå åªé»

##### **Bilevel Joint Unsupervised and Supervised Training for Automatic Speech Recognition**
2412.08548v1 by Xiaodong Cui, A F M Saif, Songtao Lu, Lisha Chen, Tianyi Chen, Brian Kingsbury, George Saon

In this paper, we propose a bilevel joint unsupervised and supervised
training (BL-JUST) framework for automatic speech recognition. Compared to the
conventional pre-training and fine-tuning strategy which is a disconnected
two-stage process, BL-JUST tries to optimize an acoustic model such that it
simultaneously minimizes both the unsupervised and supervised loss functions.
Because BL-JUST seeks matched local optima of both loss functions, acoustic
representations learned by the acoustic model strike a good balance between
being generic and task-specific. We solve the BL-JUST problem using
penalty-based bilevel gradient descent and evaluate the trained deep neural
network acoustic models on various datasets with a variety of architectures and
loss functions. We show that BL-JUST can outperform the widely-used
pre-training and fine-tuning strategy and some other popular semi-supervised
techniques.

æè¦ï¼å¨æ¬æä¸­ï¼æåæåºäºä¸åéå±¤è¯åç¡ç£ç£åç£ç£è¨ç·´ (BL-JUST) æ¡æ¶ï¼ç¨æ¼èªåèªé³è¾¨è­ãèå³çµ±çé è¨ç·´åå¾®èª¿ç­ç¥ï¼ä¸åä¸é£çºçå©éæ®µéç¨ï¼ç¸æ¯ï¼BL-JUST åè©¦åªåä¸åè²å­¸æ¨¡åï¼ä½¿å®åææå°åç¡ç£ç£åç£ç£æå¤±å½æ¸ãç±æ¼ BL-JUST å°æ±å©åæå¤±å½æ¸çå¹éå±é¨æåªå¼ï¼å æ­¤è²å­¸æ¨¡åå­¸ç¿å°çè²å­¸è¡¨ç¤ºå¨éç¨æ§åç¹å®æ¼ä»»åä¹éåå¾äºè¯å¥½çå¹³è¡¡ãæåä½¿ç¨åºæ¼æ²ç½°çéå±¤æ¢¯åº¦ä¸éä¾è§£æ±º BL-JUST åé¡ï¼ä¸¦å¨å·æåç¨®æ¶æ§åæå¤±å½æ¸çä¸åè³æéä¸è©ä¼°è¨ç·´å¥½çæ·±åº¦ç¥ç¶ç¶²è·¯è²å­¸æ¨¡åãæåè¡¨æï¼BL-JUST å¯ä»¥åªæ¼å»£æ³ä½¿ç¨çé è¨ç·´åå¾®èª¿ç­ç¥ä»¥åå¶ä»ä¸äºæµè¡çåç£ç£æè¡ã

##### **MaestroMotif: Skill Design from Artificial Intelligence Feedback**
2412.08542v1 by Martin Klissarov, Mikael Henaff, Roberta Raileanu, Shagun Sodhani, Pascal Vincent, Amy Zhang, Pierre-Luc Bacon, Doina Precup, Marlos C. Machado, Pierluca D'Oro

Describing skills in natural language has the potential to provide an
accessible way to inject human knowledge about decision-making into an AI
system. We present MaestroMotif, a method for AI-assisted skill design, which
yields high-performing and adaptable agents. MaestroMotif leverages the
capabilities of Large Language Models (LLMs) to effectively create and reuse
skills. It first uses an LLM's feedback to automatically design rewards
corresponding to each skill, starting from their natural language description.
Then, it employs an LLM's code generation abilities, together with
reinforcement learning, for training the skills and combining them to implement
complex behaviors specified in language. We evaluate MaestroMotif using a suite
of complex tasks in the NetHack Learning Environment (NLE), demonstrating that
it surpasses existing approaches in both performance and usability.

æè¦ï¼ç¨èªç¶èªè¨æè¿°æè½ææ½åæä¾ä¸ç¨®å¯å­åçæ¹å¼ï¼å°äººé¡éæ¼æ±ºç­çç¥è­æ³¨å¥ AI ç³»çµ±ãæåæåº MaestroMotifï¼ä¸ç¨®ç± AI è¼å©çæè½è¨­è¨æ¹æ³ï¼å®ç¢çé«æ§è½ä¸é©ææ§å¼·çä»£çãMaestroMotif å©ç¨å¤§åèªè¨æ¨¡å (LLM) çåè½ï¼ææå°å»ºç«åéè¤ä½¿ç¨æè½ãå®é¦åä½¿ç¨ LLM çåé¥ï¼æ ¹æå¶èªç¶èªè¨æè¿°ï¼èªåè¨­è¨èæ¯åæè½å°æççåµãç¶å¾ï¼å®æ¡ç¨ LLM çç¨å¼ç¢¼ç¢çè½åï¼ä¸¦çµåå¼·åå­¸ç¿ï¼è¨ç·´æè½ä¸¦å°å®åçµåèµ·ä¾ï¼ä»¥å¯¦ä½èªè¨ä¸­æå®çè¤éè¡çºãæåä½¿ç¨ NetHack å­¸ç¿ç°å¢ (NLE) ä¸­çä¸çµè¤éä»»åè©ä¼° MaestroMotifï¼è­æå®å¨æè½åå¯ç¨æ§æ¹é¢é½è¶è¶äºç¾ææ¹æ³ã

##### **TECO: Improving Multimodal Intent Recognition with Text Enhancement through Commonsense Knowledge Extraction**
2412.08529v1 by Quynh-Mai Thi Nguyen, Lan-Nhi Thi Nguyen, Cam-Van Thi Nguyen

The objective of multimodal intent recognition (MIR) is to leverage various
modalities-such as text, video, and audio-to detect user intentions, which is
crucial for understanding human language and context in dialogue systems.
Despite advances in this field, two main challenges persist: (1) effectively
extracting and utilizing semantic information from robust textual features; (2)
aligning and fusing non-verbal modalities with verbal ones effectively. This
paper proposes a Text Enhancement with CommOnsense Knowledge Extractor (TECO)
to address these challenges. We begin by extracting relations from both
generated and retrieved knowledge to enrich the contextual information in the
text modality. Subsequently, we align and integrate visual and acoustic
representations with these enhanced text features to form a cohesive multimodal
representation. Our experimental results show substantial improvements over
existing baseline methods.

æè¦ï¼å¤æ¨¡ææåè­å¥ (MIR) çç®æ¨æ¯å©ç¨åç¨®æ¨¡å¼ï¼ä¾å¦æå­ãå½±çåé³è¨ï¼ä¾åµæ¸¬ä½¿ç¨èçæåï¼éå°æ¼çè§£å°è©±ç³»çµ±ä¸­çäººé¡èªè¨åèçµ¡è³ééè¦ãåç®¡éåé åæé²å±ï¼ä½ä»æå©åä¸»è¦ææ°ï¼(1) ææå°å¾å¼·å¤§çæå­ç¹å¾µä¸­æååå©ç¨èªç¾©è³è¨ï¼(2) ææå°å°é½åèåéèªè¨æ¨¡å¼èèªè¨æ¨¡å¼ãæ¬ææåºäºä¸ç¨®å·åå¸¸è­ç¥è­èåå¨çæå­å¼·å (TECO) ä¾æå°éäºææ°ãæåé¦åå¾å·²ç¢çåå·²æ·åçç¥è­ä¸­æåéä¿ï¼ä»¥è±å¯æå­æ¨¡å¼ä¸­çèçµ¡è³è¨ãæ¥èï¼æåå°è¦è¦ºåè½è¦ºè¡¨ç¤ºèéäºå¢å¼·çæå­ç¹å¾µå°é½ä¸¦æ´åï¼ä»¥å½¢æä¸åæåèåçå¤æ¨¡æè¡¨ç¤ºãæåçå¯¦é©çµæé¡¯ç¤ºï¼èç¾æçåºæºæ¹æ³ç¸æ¯ï¼æé¡¯èçé²æ­¥ã

##### **Continual Learning for Encoder-only Language Models via a Discrete Key-Value Bottleneck**
2412.08528v1 by Andor Diera, Lukas Galke, Fabian Karl, Ansgar Scherp

Continual learning remains challenging across various natural language
understanding tasks. When models are updated with new training data, they risk
catastrophic forgetting of prior knowledge. In the present work, we introduce a
discrete key-value bottleneck for encoder-only language models, allowing for
efficient continual learning by requiring only localized updates. Inspired by
the success of a discrete key-value bottleneck in vision, we address new and
NLP-specific challenges. We experiment with different bottleneck architectures
to find the most suitable variants regarding language, and present a generic
discrete key initialization technique for NLP that is task independent. We
evaluate the discrete key-value bottleneck in four continual learning NLP
scenarios and demonstrate that it alleviates catastrophic forgetting. We
showcase that it offers competitive performance to other popular continual
learning methods, with lower computational costs.

æè¦ï¼æçºå­¸ç¿å¨åç¨®èªç¶èªè¨çè§£ä»»åä¸­ä»ç¶å·æææ°æ§ãç¶æ¨¡åä½¿ç¨æ°çè¨ç·´è³ææ´æ°æï¼å®åæç½é£æ§éºå¿ååç¥è­çé¢¨éªãå¨ç®åçå·¥ä½ä¸­ï¼æåçºåç·¨ç¢¼å¨èªè¨æ¨¡åå¼å¥äºé¢æ£éµå¼ç¶é ¸ï¼åéè¦å±é¨æ´æ°ï¼å³å¯å¯¦ç¾ææçæçºå­¸ç¿ãåé¢æ£éµå¼ç¶é ¸å¨è¦è¦ºä¸­çæååç¼ï¼æåè§£æ±ºäº NLP ç¹æçæ°ææ°ãæååè©¦ä½¿ç¨ä¸åçç¶é ¸æ¶æ§ï¼ä»¥æ¾å°æé©åèªè¨çè®é«ï¼ä¸¦æåºäºä¸ç¨®é©ç¨æ¼ NLP çéç¨é¢æ£éµåå§åæè¡ï¼è©²æè¡èä»»åç¡éãæåå¨ååæçºå­¸ç¿ NLP å ´æ¯ä¸­è©ä¼°äºé¢æ£éµå¼ç¶é ¸ï¼ä¸¦è­æå®æ¸è¼äºç½é£æ§éºå¿ãæåå±ç¤ºäºå®ä»¥è¼ä½çè¨ç®ææ¬çºå¶ä»æµè¡çæçºå­¸ç¿æ¹æ³æä¾äºç«¶ç­åçæè½ã

##### **EMS: Adaptive Evict-then-Merge Strategy for Head-wise KV Cache Compression Based on Global-Local Importance**
2412.08521v1 by Yingxin Li, Ye Li, Yuan Meng, Xinzhu Ma, Zihan Geng, Shutao Xia, Zhi Wang

As large language models (LLMs) continue to advance, the demand for higher
quality and faster processing of long contexts across various applications is
growing. KV cache is widely adopted as it stores previously generated key and
value tokens, effectively reducing redundant computations during inference.
However, as memory overhead becomes a significant concern, efficient
compression of KV cache has gained increasing attention. Most existing methods
perform compression from two perspectives: identifying important tokens and
designing compression strategies. However, these approaches often produce
biased distributions of important tokens due to the influence of accumulated
attention scores or positional encoding. Furthermore, they overlook the
sparsity and redundancy across different heads, which leads to difficulties in
preserving the most effective information at the head level. To this end, we
propose EMS to overcome these limitations, while achieving better KV cache
compression under extreme compression ratios. Specifically, we introduce a
Global-Local score that combines accumulated attention scores from both global
and local KV tokens to better identify the token importance. For the
compression strategy, we design an adaptive and unified Evict-then-Merge
framework that accounts for the sparsity and redundancy of KV tokens across
different heads. Additionally, we implement the head-wise parallel compression
through a zero-class mechanism to enhance efficiency. Extensive experiments
demonstrate our SOTA performance even under extreme compression ratios. EMS
consistently achieves the lowest perplexity, improves scores by over 1.28
points across four LLMs on LongBench under a 256 cache budget, and preserves
95% retrieval accuracy with a cache budget less than 2% of the context length
in the Needle-in-a-Haystack task.

æè¦ï¼é¨èå¤§åèªè¨æ¨¡å (LLM) æçºé²æ­¥ï¼å°æ¼åç¨®æç¨ç¨å¼ä¸­æ´é·å§å®¹çé«åè³ªåæ´å¿«éèççéæ±ä¹èæ¥ä¿±å¢ãKV å¿«åè¢«å»£æ³æ¡ç¨ï¼å çºå®å²å­ååç¢ççéé°åå¼æ¬æï¼ææå°æ¸å°æ¨çæéçåé¤éç®ãç¶èï¼é¨èè¨æ¶é«éé·æçºä¸åéè¦çåé¡ï¼KV å¿«åçææå£ç¸®ä¹è¶ä¾è¶åå°éè¦ãç¾æçæ¹æ³å¤§å¤å¾å©åè§åº¦é²è¡å£ç¸®ï¼è­å¥éè¦æ¬æåè¨­è¨å£ç¸®ç­ç¥ãç¶èï¼ç±æ¼ç´¯ç©æ³¨æååæ¸æä½ç½®ç·¨ç¢¼çå½±é¿ï¼éäºæ¹æ³éå¸¸æç¢çéè¦æ¬æçåå·®åä½ãæ­¤å¤ï¼å®åå¿½ç¥äºä¸åé ­é¨ä¹éçç¨çæ§ååé¤ï¼éå°è´é£ä»¥å¨é ­é¨å±¤ç´ä¿çæææçè³è¨ãçºæ­¤ï¼æåæåº EMS ä¾åæéäºéå¶ï¼åæå¨æ¥µç«¯çå£ç¸®æ¯ä¸å¯¦ç¾æ´å¥½ç KV å¿«åå£ç¸®ãå·é«ä¾èªªï¼æåå¼å¥äºä¸åçµåä¾èªå¨å±åå±é¨ KV æ¬æçç´¯ç©æ³¨æååæ¸çå¨å±å±é¨åæ¸ï¼ä»¥æ´å¥½å°è­å¥æ¬æçéè¦æ§ãå°æ¼å£ç¸®ç­ç¥ï¼æåè¨­è¨äºä¸åé©ææ§åçµ±ä¸æ§çéåºååä½µæ¶æ§ï¼å®èéäºä¸åé ­é¨ä¸­ KV æ¬æçç¨çæ§ååé¤ãæ­¤å¤ï¼æåééé¶é¡å¥æ©å¶å¯¦ç¾é ­é¨ææºçå¹³è¡å£ç¸®ï¼ä»¥æé«æçãå»£æ³çå¯¦é©è­æäºæåå³ä½¿å¨æ¥µç«¯çå£ç¸®æ¯ä¸ä¹è½éå° SOTA æè½ãå¨ LongBench ä¸çåå LLM ä¸­ï¼EMS å¨ 256 å¿«åé ç®ä¸æçºå¯¦ç¾æä½å°æåº¦ï¼å°åæ¸æé«äº 1.28 åä»¥ä¸ï¼ä¸¦å¨ Needle-in-a-Haystack ä»»åä¸­ä»¥å°æ¼å§å®¹é·åº¦ 2% çå¿«åé ç®ä¿çäº 95% çæª¢ç´¢æºç¢ºåº¦ã

##### **GR-NLP-TOOLKIT: An Open-Source NLP Toolkit for Modern Greek**
2412.08520v1 by Lefteris Loukas, Nikolaos Smyrnioudis, Chrysa Dikonomaki, Spyros Barbakos, Anastasios Toumazatos, John Koutsikakis, Manolis Kyriakakis, Mary Georgiou, Stavros Vassos, John Pavlopoulos, Ion Androutsopoulos

We present GR-NLP-TOOLKIT, an open-source natural language processing (NLP)
toolkit developed specifically for modern Greek. The toolkit provides
state-of-the-art performance in five core NLP tasks, namely part-of-speech
tagging, morphological tagging, dependency parsing, named entity recognition,
and Greeklishto-Greek transliteration. The toolkit is based on pre-trained
Transformers, it is freely available, and can be easily installed in Python
(pip install gr-nlp-toolkit). It is also accessible through a demonstration
platform on HuggingFace, along with a publicly available API for non-commercial
use. We discuss the functionality provided for each task, the underlying
methods, experiments against comparable open-source toolkits, and future
possible enhancements. The toolkit is available at:
https://github.com/nlpaueb/gr-nlp-toolkit

æè¦ï¼æåæåº GR-NLP-TOOLKITï¼éæ¯ä¸åå°éçºç¾ä»£å¸èèªéç¼çéæºèªç¶èªè¨èç (NLP) å·¥å·åãè©²å·¥å·åå¨äºé æ ¸å¿ NLP ä»»åä¸­æä¾æåé²çæè½ï¼å³è©æ§æ¨è¨ãå½¢ææ¨è¨ãä¾å­å¥æ³åæãå½åå¯¦é«è¾¨è­å Greeklish è½æçºå¸èèªè½å¯«ãè©²å·¥å·ååºæ¼é åè¨ç·´ç Transformersï¼å®æ¯åè²»æä¾çï¼ä¸¦ä¸å¯ä»¥è¼é¬å®è£å¨ Python ä¸­ï¼pip å®è£ gr-nlp-toolkitï¼ãå®ä¹å¯ä»¥éé HuggingFace ä¸çç¤ºç¯å¹³å°å­åï¼ä»¥åä¸åå¬éæä¾ç API ä¾éåæ¥­ç¨éä½¿ç¨ãæåè¨è«äºçºæ¯åä»»åæä¾çåè½ãåºç¤æ¹æ³ãéå°å¯æ¯è¼éæºå·¥å·åçå¯¦é©ï¼ä»¥åæªä¾å¯è½çå¢å¼·åè½ãè©²å·¥å·åå¯å¨ä»¥ä¸ç¶²ååå¾ï¼
https://github.com/nlpaueb/gr-nlp-toolkit

##### **Bridging Relevance and Reasoning: Rationale Distillation in Retrieval-Augmented Generation**
2412.08519v1 by Pengyue Jia, Derong Xu, Xiaopeng Li, Zhaocheng Du, Xiangyang Li, Xiangyu Zhao, Yichao Wang, Yuhao Wang, Huifeng Guo, Ruiming Tang

The reranker and generator are two critical components in the
Retrieval-Augmented Generation (i.e., RAG) pipeline, responsible for ranking
relevant documents and generating responses. However, due to differences in
pre-training data and objectives, there is an inevitable gap between the
documents ranked as relevant by the reranker and those required by the
generator to support answering the query. To address this gap, we propose
RADIO, a novel and practical preference alignment framework with RAtionale
DIstillatiOn. Specifically, We first propose a rationale extraction method that
leverages the reasoning capabilities of Large Language Models (LLMs) to extract
the rationales necessary for answering the query. Subsequently, a
rationale-based alignment process is designed to rerank the documents based on
the extracted rationales, and fine-tune the reranker to align the preferences.
We conduct extensive experiments on two tasks across three datasets to
demonstrate the effectiveness of our approach compared to baseline methods. Our
code is released online to ease reproduction.

æè¦ï¼éæ°æåºå¨åçæå¨æ¯æ£ç´¢å¢å¼ºçæï¼å³ RAGï¼ç®¡éä¸­çä¸¤ä¸ªå³é®ç»ä»¶ï¼è´è´£å¯¹ç¸å³ææ¡£è¿è¡æåºå¹¶çæååºãç¶èï¼ç±äºé¢è®­ç»æ°æ®åç®æ çä¸åï¼éæ°æåºå¨æåçç¸å³ææ¡£ä¸çæå¨åç­æ¥è¯¢æéçææ¡£ä¹é´å­å¨ä¸å¯é¿åçå·®è·ãä¸ºäºè§£å³è¿ä¸å·®è·ï¼æä»¬æåºäº RADIOï¼ä¸ä¸ªæ°é¢ä¸å®ç¨çåå¥½å¯¹é½æ¡æ¶ï¼å¸¦æ RAtionale DIstillatiOnãå·ä½æ¥è¯´ï¼æä»¬é¦åæåºäºä¸ç§åºæ¬åçæåæ¹æ³ï¼è¯¥æ¹æ³å©ç¨å¤§åè¯­è¨æ¨¡å (LLM) çæ¨çè½åæ¥æååç­æ¥è¯¢æéçåºæ¬åçãéåï¼è®¾è®¡äºä¸ä¸ªåºäºåºæ¬åççå¯¹é½è¿ç¨ï¼æ ¹æ®æåçåºæ¬åçå¯¹ææ¡£è¿è¡éæ°æåºï¼å¹¶å¾®è°éæ°æåºå¨ä»¥å¯¹é½åå¥½ãæä»¬å¯¹ä¸ä¸ªæ°æ®éä¸­çä¸¤ä¸ªä»»å¡è¿è¡äºå¹¿æ³çå®éªï¼ä»¥è¯ææä»¬æ¹æ³ä¸åºçº¿æ¹æ³ç¸æ¯çæææ§ãæä»¬çä»£ç å·²å¨çº¿åå¸ï¼ä»¥ç®ååç°ã

##### **Enhancing Interpretability Through Loss-Defined Classification Objective in Structured Latent Spaces**
2412.08515v1 by Daniel Geissler, Bo Zhou, Mengxi Liu, Paul Lukowicz

Supervised machine learning often operates on the data-driven paradigm,
wherein internal model parameters are autonomously optimized to converge
predicted outputs with the ground truth, devoid of explicitly programming rules
or a priori assumptions. Although data-driven methods have yielded notable
successes across various benchmark datasets, they inherently treat models as
opaque entities, thereby limiting their interpretability and yielding a lack of
explanatory insights into their decision-making processes. In this work, we
introduce Latent Boost, a novel approach that integrates advanced distance
metric learning into supervised classification tasks, enhancing both
interpretability and training efficiency. Thus during training, the model is
not only optimized for classification metrics of the discrete data points but
also adheres to the rule that the collective representation zones of each class
should be sharply clustered. By leveraging the rich structural insights of
intermediate model layer latent representations, Latent Boost improves
classification interpretability, as demonstrated by higher Silhouette scores,
while accelerating training convergence. These performance and latent
structural benefits are achieved with minimum additional cost, making it
broadly applicable across various datasets without requiring data-specific
adjustments. Furthermore, Latent Boost introduces a new paradigm for aligning
classification performance with improved model transparency to address the
challenges of black-box models.

æè¦ï¼çç£å¼æºå¨å­¦ä¹ éå¸¸éµå¾ªæ°æ®é©±å¨èä¾ï¼å¶ä¸­åé¨æ¨¡ååæ°ä¼èªå¨ä¼åï¼ä»¥ä½¿é¢æµè¾åºä¸å°é¢å®åµç¸ç¬¦ï¼èæ éæç¡®ç¼ç¨è§åæåéªåè®¾ãå°½ç®¡æ°æ®é©±å¨æ¹æ³å¨åç§åºåæ°æ®éä¸åå¾äºæ¾ççæåï¼ä½å®ä»¬æ¬è´¨ä¸å°æ¨¡åè§ä¸ºä¸éæå®ä½ï¼ä»èéå¶äºå¶å¯è§£éæ§ï¼å¹¶ä¸æ æ³å¯¹å¶å³ç­è¿ç¨æä¾è§£éæ§è§è§£ãå¨è¿é¡¹å·¥ä½ä¸­ï¼æä»¬å¼å¥äºæ½å¨æåï¼è¿æ¯ä¸ç§æ°é¢çæ¹æ³ï¼å®å°åè¿çè·ç¦»åº¦éå­¦ä¹ éæå°çç£åç±»ä»»å¡ä¸­ï¼ä»èå¢å¼ºäºå¯è§£éæ§åè®­ç»æçãå æ­¤ï¼å¨è®­ç»æé´ï¼è¯¥æ¨¡åä¸ä»éå¯¹ç¦»æ£æ°æ®ç¹çåç±»ææ è¿è¡äºä¼åï¼è¿éµå®äºæ¯ä¸ªç±»çéä½è¡¨ç¤ºåºååºè¯¥è¢«éå©èç±»çè§åãéè¿å©ç¨ä¸­é´æ¨¡åå±æ½å¨è¡¨ç¤ºçä¸°å¯ç»æè§è§£ï¼æ½å¨æåæ¹åäºåç±»çå¯è§£éæ§ï¼å¦æ´é«çè½®å»å¾åæç¤ºï¼åæ¶å éäºè®­ç»æ¶æãè¿äºæ§è½åæ½å¨ç»æä¼å¿ä»¥æå°çé¢å¤ææ¬å®ç°ï¼ä½¿å¶å¹¿æ³éç¨äºåç§æ°æ®éï¼èæ éè¿è¡ç¹å®äºæ°æ®çè°æ´ãæ­¤å¤ï¼æ½å¨æåå¼å¥äºä¸ç§æ°çèä¾ï¼ç¨äºå°åç±»æ§è½ä¸æ¹è¿çæ¨¡åéææ§ç¸ç»åï¼ä»¥åºå¯¹é»çæ¨¡åçææã

##### **REPEAT: Improving Uncertainty Estimation in Representation Learning Explainability**
2412.08513v1 by Kristoffer K. WickstrÃ¸m, Thea BrÃ¼sch, Michael C. Kampffmeyer, Robert Jenssen

Incorporating uncertainty is crucial to provide trustworthy explanations of
deep learning models. Recent works have demonstrated how uncertainty modeling
can be particularly important in the unsupervised field of representation
learning explainable artificial intelligence (R-XAI). Current R-XAI methods
provide uncertainty by measuring variability in the importance score. However,
they fail to provide meaningful estimates of whether a pixel is certainly
important or not. In this work, we propose a new R-XAI method called REPEAT
that addresses the key question of whether or not a pixel is \textit{certainly}
important. REPEAT leverages the stochasticity of current R-XAI methods to
produce multiple estimates of importance, thus considering each pixel in an
image as a Bernoulli random variable that is either important or unimportant.
From these Bernoulli random variables we can directly estimate the importance
of a pixel and its associated certainty, thus enabling users to determine
certainty in pixel importance. Our extensive evaluation shows that REPEAT gives
certainty estimates that are more intuitive, better at detecting
out-of-distribution data, and more concise.

æè¦ï¼å°ä¸ç¢ºå®æ§ç´å¥èéå°æ¼æä¾æ·±åº¦å­¸ç¿æ¨¡åçå¯é è§£éè³ééè¦ãæè¿çç ç©¶å·²è­æä¸ç¢ºå®æ§å»ºæ¨¡å¨ç¡ç£ç£è¡¨ç¤ºå­¸ç¿è§£éæ§äººå·¥æºæ§ (R-XAI) é åä¸­å¯è½ç¹å¥éè¦ãç®åç R-XAI æ¹æ³ééæ¸¬ééè¦æ§åæ¸ä¸­çè®ç°æ§ä¾æä¾ä¸ç¢ºå®æ§ãä½æ¯ï¼å®åç¡æ³æä¾ææç¾©çä¼°è¨å¼ï¼èªªæåç´ æ¯å¦ç¢ºå¯¦éè¦ãå¨æ­¤ç ç©¶ä¸­ï¼æåæåºäºä¸ç¨®åçº REPEAT çæ° R-XAI æ¹æ³ï¼ç¨æ¼è§£æ±ºåç´ æ¯å¦ãç¢ºå¯¦ãéè¦çééµåé¡ãREPEAT å©ç¨ç¶å R-XAI æ¹æ³çé¨æ©æ§ä¾ç¢çå¤åéè¦æ§ä¼°è¨å¼ï¼å æ­¤å°å½±åä¸­çæ¯ååç´ è¦çºä¸åä¼¯åªå©é¨æ©è®æ¸ï¼å®å¯è½æ¯éè¦çæä¸éè¦çãå¾éäºä¼¯åªå©é¨æ©è®æ¸ä¸­ï¼æåå¯ä»¥ç´æ¥ä¼°è¨åç´ åå¶ç¸éç¢ºå®æ§çéè¦æ§ï¼å¾èä½¿ç¨æ¶è½å¤ ç¢ºå®åç´ éè¦æ§çç¢ºå®æ§ãæåçå»£æ³è©ä¼°é¡¯ç¤ºï¼REPEAT æä¾çç¢ºå®æ§ä¼°è¨æ´ç´è§ãæ´è½åµæ¸¬åå¸å¤è³æï¼èä¸æ´ç°¡æ½ã

##### **Comparative Opinion Mining in Product Reviews: Multi-perspective Prompt-based Learning**
2412.08508v1 by Hai-Yen Thi Nguyen, Cam-Van Thi Nguyen

Comparative reviews are pivotal in understanding consumer preferences and
influencing purchasing decisions. Comparative Quintuple Extraction (COQE) aims
to identify five key components in text: the target entity, compared entities,
compared aspects, opinions on these aspects, and polarity. Extracting precise
comparative information from product reviews is challenging due to nuanced
language and sequential task errors in traditional methods. To mitigate these
problems, we propose MTP-COQE, an end-to-end model designed for COQE.
Leveraging multi-perspective prompt-based learning, MTP-COQE effectively guides
the generative model in comparative opinion mining tasks. Evaluation on the
Camera-COQE (English) and VCOM (Vietnamese) datasets demonstrates MTP-COQE's
efficacy in automating COQE, achieving superior performance with a 1.41% higher
F1 score than the previous baseline models on the English dataset.
Additionally, we designed a strategy to limit the generative model's creativity
to ensure the output meets expectations. We also performed data augmentation to
address data imbalance and to prevent the model from becoming biased towards
dominant samples.

æè¦ï¼æ¯è¼è©è«å°æ¼äºè§£æ¶è²»èåå¥½åå½±é¿è³¼è²·æ±ºå®è³ééè¦ãæ¯è¼äºåèå (COQE) æ¨å¨è­å¥ææ¬ä¸­çäºåééµçµæé¨åï¼ç®æ¨å¯¦é«ãæ¯è¼å¯¦é«ãæ¯è¼é¢åãå°éäºé¢åçæè¦ä»¥åæ¥µæ§ãç±æ¼å³çµ±æ¹æ³ä¸­èªè¨çç´°å¾®å·®å¥åé åºä»»åé¯èª¤ï¼å¾ç¢åè©è«ä¸­æåç²¾ç¢ºçæ¯è¼è³è¨å·æææ°æ§ãçºäºæ¸è¼éäºåé¡ï¼æåæåºäº MTP-COQEï¼éæ¯ä¸åå°çº COQE è¨­è¨çç«¯å°ç«¯æ¨¡åãå©ç¨å¤è¦è§æç¤ºå¼å­¸ç¿ï¼MTP-COQE ææå°æå°çææ¨¡åé²è¡æ¯è¼æè¦ææä»»åãå¨ Camera-COQEï¼è±èªï¼å VCOMï¼è¶åèªï¼è³æéä¸çè©ä¼°è­æäº MTP-COQE å¨èªåå COQE ä¸­çåæï¼å¨è±èªè³æéä¸æ¯ä»¥åçåºæºæ¨¡åå¯¦ç¾äºé«åº 1.41% ç F1 åæ¸çåªç°æè½ãæ­¤å¤ï¼æåè¨­è¨äºä¸ç¨®ç­ç¥ä¾éå¶çææ¨¡åçåµé åï¼ä»¥ç¢ºä¿è¼¸åºç¬¦åé æãæåéå·è¡äºè³ææ´åï¼ä»¥è§£æ±ºè³æä¸å¹³è¡¡åé¡ï¼ä¸¦é²æ­¢æ¨¡åå°ä¸»è¦æ¨£æ¬ç¢çåè¦ã

##### **SuperCode: Sustainability PER AI-driven CO-DEsign**
2412.08490v1 by P. Chris Broekema, Rob V. van Nieuwpoort

Currently, data-intensive scientific applications require vast amounts of
compute resources to deliver world-leading science. The climate emergency has
made it clear that unlimited use of resources (e.g., energy) for scientific
discovery is no longer acceptable. Future computing hardware promises to be
much more energy efficient, but without better optimized software this cannot
reach its full potential. In this vision paper, we propose a generic AI-driven
co-design methodology, using specialized Large Language Models (like ChatGPT),
to effectively generate efficient code for emerging computing hardware. We
describe how we will validate our methodology with two radio astronomy
applications, with sustainability as the key performance indicator. This paper
is a modified version of our accepted SuperCode project proposal. We present it
here in this form to introduce the vision behind this project and to
disseminate the work in the spirit of Open Science and transparency. An
additional aim is to collect feedback, invite potential collaboration partners
and use-cases to join the project.

æè¦ï¼ç®åï¼è³æå¯éçç§å­¸æç¨ç¨å¼éè¦å¤§éçéç®è³æºæè½æä¾é åä¸ççç§å­¸ãæ°£åç·æ¥äºä»¶å·²ç¶è¡¨æï¼ä¸åè½æ¥åçºäºç§å­¸ç¼ç¾èç¡éä½¿ç¨è³æºï¼ä¾å¦è½æºï¼ãæªä¾çéç®ç¡¬é«æ¿è«¾å°ææ´ç¯è½ï¼ä½æ²æç¶éæä½³ååªåçè»é«ï¼ç¡æ³ç¼æ®å¶å¨é¨æ½åãå¨éä»½é¡æ¯æä»¶ä¸­ï¼æåæåºä¸åéç¨ç AI é©åå±åè¨­è¨æ¹æ³ï¼ä½¿ç¨å¤§åèªè¨æ¨¡åï¼ä¾å¦ ChatGPTï¼ï¼ææå°çºæ°èéç®ç¡¬é«ç¢çé«æçç¨å¼ç¢¼ãæåæè¿°äºå¦ä½ä½¿ç¨å©åç¡ç·é»å¤©æå­¸æç¨ç¨å¼é©è­æåçæè¡ï¼å¶ä¸­æ°¸çºæ§çºééµæè½ææ¨ãéä»½æä»¶æ¯æåå·²æ¥åç SuperCode å°æ¡ææ¡çä¿®æ¹çæ¬ãæåå¨æ­¤ä»¥éç¨®å½¢å¼åç¾ï¼ä»¥ä»ç´¹éåå°æ¡èå¾çé¡æ¯ï¼ä¸¦æ¬èéæ¾ç§å­¸åéæçç²¾ç¥å³æ­éé å·¥ä½ãå¦ä¸åç®çæ¯æ¶éåé¥ï¼éè«æ½å¨çåä½å¤¥ä¼´åä½¿ç¨æ¡ä¾å å¥éåå°æ¡ã

##### **Multi-perspective Alignment for Increasing Naturalness in Neural Machine Translation**
2412.08473v1 by Huiyuan Lai, Esther Ploeger, Rik van Noord, Antonio Toral

Neural machine translation (NMT) systems amplify lexical biases present in
their training data, leading to artificially impoverished language in output
translations. These language-level characteristics render automatic
translations different from text originally written in a language and human
translations, which hinders their usefulness in for example creating evaluation
datasets. Attempts to increase naturalness in NMT can fall short in terms of
content preservation, where increased lexical diversity comes at the cost of
translation accuracy. Inspired by the reinforcement learning from human
feedback framework, we introduce a novel method that rewards both naturalness
and content preservation. We experiment with multiple perspectives to produce
more natural translations, aiming at reducing machine and human translationese.
We evaluate our method on English-to-Dutch literary translation, and find that
our best model produces translations that are lexically richer and exhibit more
properties of human-written language, without loss in translation accuracy.

æè¦ï¼ç¥ç¶æ©å¨ç¿»è­¯ (NMT) ç³»çµ±æ´å¤§äºå¶è¨ç·´è³æä¸­å­å¨çè©å½åå·®ï¼å°è´è¼¸åºç¿»è­¯ä¸­çèªè¨äººçºå°è²§ä¹ãéäºèªè¨å±¤é¢çç¹å¾µä½¿èªåç¿»è­¯ä¸åæ¼åæ¬ç¨ä¸ç¨®èªè¨å¯«æçæå­åäººå·¥ç¿»è­¯ï¼éé»ç¤äºå®åå¨ä¾å¦å»ºç«è©ä¼°è³æéæ¹é¢çç¨éãå¢å  NMT ä¸­èªç¶æ§çåè©¦å¯è½æå¨å§å®¹ä¿å­æ¹é¢ææä¸è¶³ï¼å¶ä¸­å¢å è©å½å¤æ¨£æ§æ¯ä»¥ç§ç²ç¿»è­¯æºç¢ºæ§çºä»£å¹çãåå°äººé¡åé¥æ¡æ¶ä¸­çå¼·åå­¸ç¿çåç¼ï¼æåå¼å¥äºä¸ç¨®æ°çæ¹æ³ï¼å®åæçåµèªç¶æ§åå§å®¹ä¿å­ãæååè©¦äºå¤ç¨®è§é»ä¾ç¢çæ´èªç¶çç¿»è­¯ï¼æ¨å¨æ¸å°æ©å¨åäººå·¥ç¿»è­¯èãæåå°è±èªå°è·è­èªæå­¸ç¿»è­¯è©ä¼°äºæåçæ¹æ³ï¼ç¼ç¾æåæå¥½çæ¨¡åç¢ççç¿»è­¯å¨è©å½ä¸æ´è±å¯ï¼ä¸¦è¡¨ç¾åºæ´å¤äººé¡æ¸é¢èªè¨çç¹æ§ï¼èä¸æéä½ç¿»è­¯æºç¢ºæ§ã

##### **Bootstrapping Language-Guided Navigation Learning with Self-Refining Data Flywheel**
2412.08467v1 by Zun Wang, Jialu Li, Yicong Hong, Songze Li, Kunchang Li, Shoubin Yu, Yi Wang, Yu Qiao, Yali Wang, Mohit Bansal, Limin Wang

Creating high-quality data for training robust language-instructed agents is
a long-lasting challenge in embodied AI. In this paper, we introduce a
Self-Refining Data Flywheel (SRDF) that generates high-quality and large-scale
navigational instruction-trajectory pairs by iteratively refining the data pool
through the collaboration between two models, the instruction generator and the
navigator, without any human-in-the-loop annotation. Specifically, SRDF starts
with using a base generator to create an initial data pool for training a base
navigator, followed by applying the trained navigator to filter the data pool.
This leads to higher-fidelity data to train a better generator, which can, in
turn, produce higher-quality data for training the next-round navigator. Such a
flywheel establishes a data self-refining process, yielding a continuously
improved and highly effective dataset for large-scale language-guided
navigation learning. Our experiments demonstrate that after several flywheel
rounds, the navigator elevates the performance boundary from 70% to 78% SPL on
the classic R2R test set, surpassing human performance (76%) for the first
time. Meanwhile, this process results in a superior generator, evidenced by a
SPICE increase from 23.5 to 26.2, better than all previous VLN instruction
generation methods. Finally, we demonstrate the scalability of our method
through increasing environment and instruction diversity, and the
generalization ability of our pre-trained navigator across various downstream
navigation tasks, surpassing state-of-the-art methods by a large margin in all
cases.

æè¦ï¼<paragraph>çºè¨ç·´å¼·å¤§çèªè¨æå°ä»£çå»ºç«é«åè³ªè³ææ¯é«ç¾å¼äººå·¥æºæ§çé·æææ°ãå¨éç¯è«æä¸­ï¼æåä»ç´¹ä¸åèªæç²¾çè³æé£è¼ª (SRDF)ï¼ééå©åæ¨¡åï¼æä»¤ç¢çå¨åå°èªå¡ï¼çåä½ï¼å¨è³æåº«ä¸­åè¦ç²¾çè³æï¼ç¢çé«åè³ªä¸å¤§è¦æ¨¡çå°èªæä»¤è»è·¡éå°ï¼èç¡éä»»ä½äººå·¥è¿´åè¨»è§£ãå·é«ä¾èªªï¼SRDF å¾ä½¿ç¨åºæ¬ç¢çå¨å»ºç«ä¸ååå§è³æåº«ï¼ç¨æ¼è¨ç·´åºæ¬å°èªå¡ï¼æ¥èä½¿ç¨è¨ç·´å¥½çå°èªå¡ä¾éæ¿¾è³æåº«ãéæç¢çæ´é«ä¿çåº¦çè³æï¼ç¨æ¼è¨ç·´æ´å¥½çç¢çå¨ï¼é²èç¢çæ´é«åè³ªçè³æï¼ç¨æ¼è¨ç·´ä¸ä¸è¼ªå°èªå¡ãéæ¨£çé£è¼ªå»ºç«äºä¸åè³æèªæç²¾çæµç¨ï¼ç¢çä¸åæçºæ¹åä¸é«åº¦ææçè³æéï¼ç¨æ¼å¤§è¦æ¨¡èªè¨å¼å°å°èªå­¸ç¿ãæåçå¯¦é©é¡¯ç¤ºï¼ç¶éå¹¾è¼ªé£è¼ªå¾ï¼å°èªå¡å°ç¶å¸ R2R æ¸¬è©¦éä¸çæè½çç·å¾ 70% æåå° 78% SPLï¼é¦æ¬¡è¶è¶äººé¡æè½ (76%)ãåæï¼éåæµç¨ç¢çäºä¸ååªç°çç¢çå¨ï¼SPICE å¾ 23.5 å¢å å° 26.2ï¼åªæ¼ææååç VLN æä»¤ç¢çæ¹æ³ãæå¾ï¼æåééå¢å ç°å¢åæä»¤å¤æ¨£æ§ï¼ä»¥åé è¨ç·´å°èªå¡å¨åç¨®ä¸æ¸¸å°èªä»»åä¸­çæ³åè½åï¼è­æäºæåæ¹æ³çå¯æ´åæ§ï¼å¨ææææ³ä¸é½å¤§å¹è¶è¶ç¾ææè¡ã</paragraph>

##### **IRL for Restless Multi-Armed Bandits with Applications in Maternal and Child Health**
2412.08463v1 by Gauri Jain, Pradeep Varakantham, Haifeng Xu, Aparna Taneja, Prashant Doshi, Milind Tambe

Public health practitioners often have the goal of monitoring patients and
maximizing patients' time spent in "favorable" or healthy states while being
constrained to using limited resources. Restless multi-armed bandits (RMAB) are
an effective model to solve this problem as they are helpful to allocate
limited resources among many agents under resource constraints, where patients
behave differently depending on whether they are intervened on or not. However,
RMABs assume the reward function is known. This is unrealistic in many public
health settings because patients face unique challenges and it is impossible
for a human to know who is most deserving of any intervention at such a large
scale. To address this shortcoming, this paper is the first to present the use
of inverse reinforcement learning (IRL) to learn desired rewards for RMABs, and
we demonstrate improved outcomes in a maternal and child health telehealth
program. First we allow public health experts to specify their goals at an
aggregate or population level and propose an algorithm to design expert
trajectories at scale based on those goals. Second, our algorithm WHIRL uses
gradient updates to optimize the objective, allowing for efficient and accurate
learning of RMAB rewards. Third, we compare with existing baselines and
outperform those in terms of run-time and accuracy. Finally, we evaluate and
show the usefulness of WHIRL on thousands on beneficiaries from a real-world
maternal and child health setting in India. We publicly release our code here:
https://github.com/Gjain234/WHIRL.

æè¦ï¼<paragraph>å¬å±è¡çå¾æ¥­äººå¡éå¸¸æç£æ§æ£èåæå¤§åæ£èèæ¼ãæå©ãæå¥åº·çæçæéçç®æ¨ï¼åæåå°æéè³æºçéå¶ãä¸å®åçå¤èå¼·ç (RMAB) æ¯è§£æ±ºæ­¤åé¡çæææ¨¡åï¼å çºå®åæå©æ¼å¨è³æºéå¶ä¸ï¼å¨è¨±å¤ä»£çä¹éåéæéçè³æºï¼å¶ä¸­æ£èçè¡çºåæ±ºæ¼æ¯å¦å°å¶é²è¡å¹²é ãç¶èï¼RMAB åè¨­å·²ç¥åå ±å½æ¸ãéå¨è¨±å¤å¬å±è¡çç°å¢ä¸­æ¯ä¸åå¯¦éçï¼å çºæ£èé¢è¨ç¨ç¹çææ°ï¼èä¸å°æ¼å¦æ­¤å¤§è¦æ¨¡çå¹²é ï¼äººé¡ä¸å¯è½ç¥éèª°æéè¦å¹²é ãçºäºè§£æ±ºéåç¼ºé»ï¼æ¬æé¦æ¬¡æåºä½¿ç¨éåå¼·åå­¸ç¿ (IRL) ä¾å­¸ç¿ RMAB çææåå ±ï¼ä¸¦ä¸æåå¨æ¯å¬°å¥åº·é è·é«çè¨ç«ä¸­å±ç¤ºäºæ¹åççµæãé¦åï¼æååè¨±å¬å±è¡çå°å®¶å¨ç¸½é«æäººå£å±¤ç´æå®ä»åçç®æ¨ï¼ä¸¦æåºä¸åæ¼ç®æ³ä¾æ ¹æéäºç®æ¨å¤§è¦æ¨¡è¨­è¨å°å®¶è»è·¡ãå¶æ¬¡ï¼æåçæ¼ç®æ³ WHIRL ä½¿ç¨æ¢¯åº¦æ´æ°ä¾æä½³åç®æ¨ï¼åè¨±ææä¸æºç¢ºå°å­¸ç¿ RMAB åå ±ãç¬¬ä¸ï¼æåèç¾æçåºæºé²è¡æ¯è¼ï¼ä¸¦å¨å·è¡æéåæºç¢ºæ§æ¹é¢åªæ¼éäºåºæºãæå¾ï¼æåè©ä¼°ä¸¦å±ç¤ºäº WHIRL å¨å°åº¦å¯¦éæ¯å¬°å¥åº·ç°å¢ä¸­å°æ¸åååçèçæç¨æ§ãæåå¨æ­¤å¬éç¼å¸æåçç¨å¼ç¢¼ï¼https://github.com/Gjain234/WHIRLã</paragraph>

##### **Federated Learning for Traffic Flow Prediction with Synthetic Data Augmentation**
2412.08460v1 by Fermin Orozco, Pedro Porto Buarque de GusmÃ£o, Hongkai Wen, Johan WahlstrÃ¶m, Man Luo

Deep-learning based traffic prediction models require vast amounts of data to
learn embedded spatial and temporal dependencies. The inherent privacy and
commercial sensitivity of such data has encouraged a shift towards
decentralised data-driven methods, such as Federated Learning (FL). Under a
traditional Machine Learning paradigm, traffic flow prediction models can
capture spatial and temporal relationships within centralised data. In reality,
traffic data is likely distributed across separate data silos owned by multiple
stakeholders. In this work, a cross-silo FL setting is motivated to facilitate
stakeholder collaboration for optimal traffic flow prediction applications.
This work introduces an FL framework, referred to as FedTPS, to generate
synthetic data to augment each client's local dataset by training a
diffusion-based trajectory generation model through FL. The proposed framework
is evaluated on a large-scale real world ride-sharing dataset using various FL
methods and Traffic Flow Prediction models, including a novel prediction model
we introduce, which leverages Temporal and Graph Attention mechanisms to learn
the Spatio-Temporal dependencies embedded within regional traffic flow data.
Experimental results show that FedTPS outperforms multiple other FL baselines
with respect to global model performance.

æè¦ï¼æ·±åº¦å­¸ç¿çäº¤éé æ¸¬æ¨¡åéè¦å¤§éçè³æä¾å­¸ç¿å§åµçæç©ºä¾è³´æ§ãéäºè³æåºæçé±ç§æ§ååæ¥­æææ§ä¿ä½¿äººåè½ååæ£å¼è³æé©åæ¹æ³ï¼ä¾å¦è¯åå­¸ç¿ (FL)ãå¨å³çµ±çæ©å¨å­¸ç¿ç¯ä¾ä¸­ï¼äº¤éæµéé æ¸¬æ¨¡åå¯ä»¥å¨éä¸­å¼è³æä¸­æ·åæç©ºéä¿ãå¯¦éä¸ï¼äº¤éè³æå¯è½åæ£å¨ç±å¤åå©å®³éä¿äººææçç¨ç«è³æåå²ä¸­ãå¨éé å·¥ä½ä¸­ï¼è·¨åå² FL è¨­å®çç®çæ¯ä¿é²å©å®³éä¿äººåä½ï¼ä»¥å¯¦ç¾æä½³çäº¤éæµéé æ¸¬æç¨ãéé å·¥ä½å¼å¥äºä¸å FL æ¶æ§ï¼ç¨±çº FedTPSï¼ç¨æ¼çæåæè³æï¼ä»¥éé FL è¨ç·´åºæ¼æ´æ£çè»è·¡çææ¨¡åï¼ä¾æ´åæ¯åå®¢æ¶ç«¯çæ¬å°è³æéãææåºçæ¶æ§å¨ä¸åå¤§è¦æ¨¡ççå¯¦ä¸çå±ä¹è³æéä¸é²è¡è©ä¼°ï¼ä½¿ç¨åç¨® FL æ¹æ³åäº¤éæµéé æ¸¬æ¨¡åï¼åæ¬æåå¼å¥çä¸åæ°ç©é æ¸¬æ¨¡åï¼å®å©ç¨æåºååå½¢æ³¨æåæ©å¶ä¾å­¸ç¿ååäº¤éæµéè³æä¸­å§åµçæç©ºä¾è³´æ§ãå¯¦é©çµæè¡¨æï¼FedTPS å¨å¨çæ¨¡åæè½æ¹é¢åªæ¼å¶ä»å¤å FL åºæºã

##### **Efficient Rectification of Neuro-Symbolic Reasoning Inconsistencies by Abductive Reflection**
2412.08457v1 by Wen-Chao Hu, Wang-Zhou Dai, Yuan Jiang, Zhi-Hua Zhou

Neuro-Symbolic (NeSy) AI could be regarded as an analogy to human
dual-process cognition, modeling the intuitive System 1 with neural networks
and the algorithmic System 2 with symbolic reasoning. However, for complex
learning targets, NeSy systems often generate outputs inconsistent with domain
knowledge and it is challenging to rectify them. Inspired by the human
Cognitive Reflection, which promptly detects errors in our intuitive response
and revises them by invoking the System 2 reasoning, we propose to improve NeSy
systems by introducing Abductive Reflection (ABL-Refl) based on the Abductive
Learning (ABL) framework. ABL-Refl leverages domain knowledge to abduce a
reflection vector during training, which can then flag potential errors in the
neural network outputs and invoke abduction to rectify them and generate
consistent outputs during inference. ABL-Refl is highly efficient in contrast
to previous ABL implementations. Experiments show that ABL-Refl outperforms
state-of-the-art NeSy methods, achieving excellent accuracy with fewer training
resources and enhanced efficiency.

æè¦ï¼ç¥ç¶ç¬¦èï¼NeSyï¼äººå·¥æºæ§å¯ä»¥è¦çºäººé¡éééç¨èªç¥çé¡æ¯ï¼ä»¥ç¥ç¶ç¶²è·¯å»ºæ¨¡ç´è¦ºçç³»çµ± 1ï¼ä¸¦ä»¥ç¬¦èæ¨çå»ºæ¨¡æ¼ç®æ³ç³»çµ± 2ãç¶èï¼å°æ¼è¤éçå­¸ç¿ç®æ¨ï¼NeSy ç³»çµ±ç¶å¸¸ç¢çèé åç¥è­ä¸ä¸è´çè¼¸åºï¼ä¸é£ä»¥ä¿®æ­£ãåäººé¡èªç¥åççåç¼ï¼å®å¯ä»¥è¿éåµæ¸¬æåç´è¦ºåæä¸­çé¯èª¤ï¼ä¸¦ééå¼å«ç³»çµ± 2 æ¨çä¾ä¿®æ­£å®åï¼æåæåºééå¨æ¼ç¹¹å­¸ç¿ï¼ABLï¼æ¶æ§ä¸­å°å¥æ¼ç¹¹åçï¼ABL-Reflï¼ä¾æ¹å NeSy ç³»çµ±ãABL-Refl å¨è¨ç·´æéå©ç¨é åç¥è­æ¼ç¹¹åå°åéï¼ç¶å¾å¯ä»¥æ¨è¨ç¥ç¶ç¶²è·¯è¼¸åºä¸­çæ½å¨é¯èª¤ï¼ä¸¦å¼å«æ¼ç¹¹ä¾ä¿®æ­£å®åï¼ä¸¦å¨æ¨è«æéç¢çä¸è´çè¼¸åºãèååç ABL å¯¦ä½ç¸æ¯ï¼ABL-Refl éå¸¸ææçãå¯¦é©é¡¯ç¤ºï¼ABL-Refl åªæ¼æåé²ç NeSy æ¹æ³ï¼å¨è¨ç·´è³æºè¼å°ä¸æçæ´é«çææ³ä¸ï¼éå°æ¥µä½³çæºç¢ºåº¦ã

##### **TapeAgents: a Holistic Framework for Agent Development and Optimization**
2412.08445v1 by Dzmitry Bahdanau, Nicolas Gontier, Gabriel Huang, Ehsan Kamalloo, Rafael Pardinas, Alex PichÃ©, Torsten Scholak, Oleh Shliazhko, Jordan Prince Tremblay, Karam Ghanem, Soham Parikh, Mitul Tiwari, Quaizar Vohra

We present TapeAgents, an agent framework built around a granular, structured
log tape of the agent session that also plays the role of the session's
resumable state. In TapeAgents we leverage tapes to facilitate all stages of
the LLM Agent development lifecycle. The agent reasons by processing the tape
and the LLM output to produce new thought and action steps and append them to
the tape. The environment then reacts to the agent's actions by likewise
appending observation steps to the tape. By virtue of this tape-centred design,
TapeAgents can provide AI practitioners with holistic end-to-end support. At
the development stage, tapes facilitate session persistence, agent auditing,
and step-by-step debugging. Post-deployment, one can reuse tapes for
evaluation, fine-tuning, and prompt-tuning; crucially, one can adapt tapes from
other agents or use revised historical tapes. In this report, we explain the
TapeAgents design in detail. We demonstrate possible applications of TapeAgents
with several concrete examples of building monolithic agents and multi-agent
teams, of optimizing agent prompts and finetuning the agent's LLM. We present
tooling prototypes and report a case study where we use TapeAgents to finetune
a Llama-3.1-8B form-filling assistant to perform as well as GPT-4o while being
orders of magnitude cheaper. Lastly, our comparative analysis shows that
TapeAgents's advantages over prior frameworks stem from our novel design of the
LLM agent as a resumable, modular state machine with a structured
configuration, that generates granular, structured logs and that can transform
these logs into training text -- a unique combination of features absent in
previous work.

æè¦ï¼<paragraph>æåæåº TapeAgentsï¼ä¸ç¨®åç¹èä»£çäººæè©±çç´°ç·»çµæ§åæ¥èªç£å¸¶å»ºç«çä»£çäººæ¶æ§ï¼è©²æ¶æ§ä¹æ®æ¼èæè©±å¯æ¢å¾©çæçè§è²ãå¨ TapeAgents ä¸­ï¼æåå©ç¨ç£å¸¶ä¿é² LLM ä»£çäººéç¼çå½é±æçææéæ®µãä»£çäººééèçç£å¸¶å LLM è¼¸åºï¼ç¢çæ°çæ³æ³åè¡åæ­¥é©ï¼ä¸¦å°å®åéå å°ç£å¸¶ä¸ï¼å¾èé²è¡æ¨çãç¶å¾ï¼ç°å¢ééåæ¨£å°è§å¯æ­¥é©éå å°ç£å¸¶ä¸ä¾å°ä»£çäººçåä½ååºåæãç±æ¼éç¨®ä»¥ç£å¸¶çºä¸­å¿çè¨­è¨ï¼TapeAgents å¯ä»¥çº AI å¾æ¥­èæä¾æ´é«çç«¯å°ç«¯æ¯æãå¨éç¼éæ®µï¼ç£å¸¶ä¿é²æè©±æä¹æ§ãä»£çäººç¨½æ ¸åéæ­¥é¤é¯ãé¨ç½²å¾ï¼å¯ä»¥éè¤ä½¿ç¨ç£å¸¶é²è¡è©ä¼°ãå¾®èª¿åæç¤ºèª¿æ´ï¼è³ééè¦çæ¯ï¼å¯ä»¥èª¿æ´å¶ä»ä»£çäººçç£å¸¶æä½¿ç¨ä¿®æ¹å¾çæ­·å²ç£å¸¶ãå¨æ­¤å ±åä¸­ï¼æåè©³ç´°èªªæäº TapeAgents çè¨­è¨ãæåééå¹¾åå·é«çæ§å»ºå®é«ä»£çäººåå¤ä»£çäººåéãåªåä»£çäººæç¤ºåå¾®èª¿ä»£çäººç LLM çç¤ºä¾ï¼å±ç¤ºäº TapeAgents çå¯è½çæç¨ãæåå±ç¤ºäºå·¥å·ååï¼ä¸¦å ±åäºä¸åæ¡ä¾ç ç©¶ï¼å¨è©²æ¡ä¾ç ç©¶ä¸­ï¼æåä½¿ç¨ TapeAgents å¾®èª¿äº Llama-3.1-8B è¡¨å®å¡«å¯«å©æï¼ä½¿å¶å¨å·è¡æè GPT-4o ä¸æ¨£å¥½ï¼åæææ¬ä½å¹¾åæ¸éç´ãæå¾ï¼æåçæ¯è¼åæè¡¨æï¼TapeAgents ç¸å°æ¼ååæ¡æ¶çåªå¢æºæ¼æåå° LLM ä»£çäººè¨­è¨æä¸åå¯æ¢å¾©çãæ¨¡çµåççææ©çæ°ç©è¨­è¨ï¼å®å·æçµæ§åçéç½®ï¼å¯ä»¥ç¢çç´°ç·»çãçµæ§åçæ¥èªï¼ä¸¦ä¸å¯ä»¥å°éäºæ¥èªè½æçºè¨ç·´ææ¬ââéæ¯ä¸åä»¥åçå·¥ä½ä¸­æ²æçç¨ç¹åè½çµåã</paragraph>

##### **Proactive Model Adaptation Against Concept Drift for Online Time Series Forecasting**
2412.08435v1 by Lifan Zhao, Yanyan Shen

Time series forecasting always faces the challenge of concept drift, where
data distributions evolve over time, leading to a decline in forecast model
performance. Existing solutions are based on online learning, which continually
organize recent time series observations as new training samples and update
model parameters according to the forecasting feedback on recent data. However,
they overlook a critical issue: obtaining ground-truth future values of each
sample should be delayed until after the forecast horizon. This delay creates a
temporal gap between the training samples and the test sample. Our empirical
analysis reveals that the gap can introduce concept drift, causing forecast
models to adapt to outdated concepts. In this paper, we present
\textsc{Proceed}, a novel proactive model adaptation framework for online time
series forecasting. \textsc{Proceed} first operates by estimating the concept
drift between the recently used training samples and the current test sample.
It then employs an adaptation generator to efficiently translate the estimated
drift into parameter adjustments, proactively adapting the model to the test
sample. To enhance the generalization capability of the framework,
\textsc{Proceed} is trained on synthetic diverse concept drifts. We conduct
extensive experiments on five real-world datasets across various forecast
models. The empirical study demonstrates that our proposed \textsc{Proceed}
brings more performance improvements than the state-of-the-art online learning
methods, significantly facilitating forecast models' resilience against concept
drifts.

æè¦ï¼æéåºåé æ¸¬ç¸½æ¯é¢è¨æ¦å¿µæ¼ç§»çææ°ï¼å¶ä¸­è³æåä½æé¨èæéæ¼è®ï¼å°è´é æ¸¬æ¨¡åæè½ä¸éãç¾æçè§£æ±ºæ¹æ¡åºæ¼ç·ä¸å­¸ç¿ï¼å®ææçºæ´çæè¿çæéåºåè§å¯çµæä½çºæ°çè¨ç·´æ¨£æ¬ï¼ä¸¦æ ¹ææè¿è³æçé æ¸¬åé¥ä¾æ´æ°æ¨¡ååæ¸ãç¶èï¼å®åå¿½ç¥äºä¸åééµåé¡ï¼æ¯åæ¨£æ¬ççå¯¦æªä¾å¼æå»¶é²å°é æ¸¬ç¯åä¹å¾æè½åå¾ãéç¨®å»¶é²æå¨è¨ç·´æ¨£æ¬åæ¸¬è©¦æ¨£æ¬ä¹éç¢çæéå·®è·ãæåçç¶é©åæé¡¯ç¤ºï¼éåå·®è·å¯è½æå¼ç¼æ¦å¿µæ¼ç§»ï¼å°è´é æ¸¬æ¨¡åé©æéæçè§å¿µãå¨æ¬æä¸­ï¼æåæåº \textsc{Proceed}ï¼ä¸åæ°çä¸»åæ¨¡åé©ææ¶æ§ï¼ç¨æ¼ç·ä¸æéåºåé æ¸¬ã\textsc{Proceed} é¦åééä¼°è¨æè¿ä½¿ç¨çè¨ç·´æ¨£æ¬åç¶åæ¸¬è©¦æ¨£æ¬ä¹éçæ¦å¿µæ¼ç§»ä¾éä½ãç¶å¾ï¼å®ä½¿ç¨é©æç¢çå¨ææå°å°ä¼°è¨çæ¼ç§»è½æçºåæ¸èª¿æ´ï¼ä¸»åå°å°æ¨¡åé©æå°æ¸¬è©¦æ¨£æ¬ãçºäºå¢å¼·æ¶æ§çæ³åè½åï¼\textsc{Proceed} å¨åæå¤æ¨£åçæ¦å¿µæ¼ç§»ä¸é²è¡è¨ç·´ãæåå°äºåçå¯¦ä¸ççè³æéé²è¡äºå»£æ³çå¯¦é©ï¼æ¶µèåç¨®é æ¸¬æ¨¡åãå¯¦è­ç ç©¶è¡¨æï¼æåæåºç \textsc{Proceed} æ¯æåé²çç·ä¸å­¸ç¿æ¹æ³å¸¶ä¾æ´å¤æè½æåï¼å¤§å¹æåé æ¸¬æ¨¡åå°ææ¦å¿µæ¼ç§»çéæ§ã

##### **Mitigating Out-of-Entity Errors in Named Entity Recognition: A Sentence-Level Strategy**
2412.08434v1 by Guochao Jiang, Ziqin Luo, Chengwei Hu, Zepeng Ding, Deqing Yang

Many previous models of named entity recognition (NER) suffer from the
problem of Out-of-Entity (OOE), i.e., the tokens in the entity mentions of the
test samples have not appeared in the training samples, which hinders the
achievement of satisfactory performance. To improve OOE-NER performance, in
this paper, we propose a new framework, namely S+NER, which fully leverages
sentence-level information. Our S+NER achieves better OOE-NER performance
mainly due to the following two particular designs. 1) It first exploits the
pre-trained language model's capability of understanding the target entity's
sentence-level context with a template set. 2) Then, it refines the
sentence-level representation based on the positive and negative templates,
through a contrastive learning strategy and template pooling method, to obtain
better NER results. Our extensive experiments on five benchmark datasets have
demonstrated that, our S+NER outperforms some state-of-the-art OOE-NER models.

æè¦ï¼è¨±å¤ååçå½åå¯¦é«è¾¨è­ (NER) æ¨¡åé½é£½åå¯¦é«å¤é¨ (OOE) åé¡æè¦ï¼äº¦å³æ¸¬è©¦æ¨£æ¬ä¸­å¯¦é«æåçè©å½ä¸¦æªåºç¾å¨è¨ç·´æ¨£æ¬ä¸­ï¼éé»ç¤äºä»¤äººæ»¿æçæè½éæãçºäºæ¹å OOE-NER æè½ï¼æåå¨æ¬æä¸­æåºä¸åæ°çæ¶æ§ï¼å³ S+NERï¼å®ååå©ç¨äºå¥å­å±¤ç´çè³è¨ãæåç S+NER è½å¤ éææ´å¥½ç OOE-NER æè½ï¼ä¸»è¦æ­¸åæ¼ä»¥ä¸å©åç¹å¥çè¨­è¨ã1) å®é¦åå©ç¨é åè¨ç·´çèªè¨æ¨¡åï¼ééä¸çµç¯æ¬ä¾çè§£ç®æ¨å¯¦é«çå¥å­å±¤ç´èçµ¡ã2) æ¥èï¼å®ééå°æ¯å¼å­¸ç¿ç­ç¥åç¯æ¬å¯éæ¹æ³ï¼æ ¹ææ­£ååè² åç¯æ¬ä¾æ¹åå¥å­å±¤ç´çè¡¨å¾µï¼ä»¥ç²å¾æ´å¥½ç NER çµæãæåå¨äºååºæºè³æéä¸é²è¡çå»£æ³å¯¦é©å·²è­æï¼æåç S+NER åªæ¼ä¸äºæåé²ç OOE-NER æ¨¡åã

##### **Assessing Personalized AI Mentoring with Large Language Models in the Computing Field**
2412.08430v1 by Xiao Luo, Sean O'Connell, Shamima Mithun

This paper provides an in-depth evaluation of three state-of-the-art Large
Language Models (LLMs) for personalized career mentoring in the computing
field, using three distinct student profiles that consider gender, race, and
professional levels. We evaluated the performance of GPT-4, LLaMA 3, and Palm 2
using a zero-shot learning approach without human intervention. A quantitative
evaluation was conducted through a custom natural language processing analytics
pipeline to highlight the uniqueness of the responses and to identify words
reflecting each student's profile, including race, gender, or professional
level. The analysis of frequently used words in the responses indicates that
GPT-4 offers more personalized mentoring compared to the other two LLMs.
Additionally, a qualitative evaluation was performed to see if human experts
reached similar conclusions. The analysis of survey responses shows that GPT-4
outperformed the other two LLMs in delivering more accurate and useful
mentoring while addressing specific challenges with encouragement languages.
Our work establishes a foundation for developing personalized mentoring tools
based on LLMs, incorporating human mentors in the process to deliver a more
impactful and tailored mentoring experience.

æè¦ï¼æ¬ææä¾å°ä¸åæåé²çå¤§åèªè¨æ¨¡å (LLM) çæ·±å¥è©ä¼°ï¼ç¨æ¼è¨ç®é åä¸­çåäººåè·æ¥­æå°ï¼ä½¿ç¨ä¸åä¸åçå­¸çæªæ¡ï¼å¶ä¸­èæ®äºæ§å¥ãç¨®æåå°æ¥­æ°´å¹³ãæåä½¿ç¨é¶æ¬¡å­¸ç¿æ¹æ³è©ä¼°äº GPT-4ãLLaMA 3 å Palm 2 çæ§è½ï¼èç¡éäººå·¥å¹²é ãééèªå®ç¾©èªç¶èªè¨èçåæç®¡éé²è¡å®éè©ä¼°ï¼ä»¥çªåºåæçç¨ç¹æ§ä¸¦è­å¥åæ æ¯åå­¸çæªæ¡çè©å½ï¼åæ¬ç¨®æãæ§å¥æå°æ¥­æ°´å¹³ãå°åæä¸­å¸¸ç¨è©å½çåæè¡¨æï¼èå¶ä»å©å LLM ç¸æ¯ï¼GPT-4 æä¾äºæ´åæ§åçæå°ãæ­¤å¤ï¼éé²è¡äºå®æ§è©ä¼°ï¼ä»¥äºè§£äººé¡å°å®¶æ¯å¦å¾åºé¡ä¼¼ççµè«ãå°èª¿æ¥åæçåæè¡¨æï¼GPT-4 å¨æä¾æ´æºç¢ºåæç¨çæå°æ¹é¢åªæ¼å¶ä»å©å LLMï¼åæä½¿ç¨é¼åµèªè¨ä¾æå°å·é«ææ°ãæåçç ç©¶çºåºæ¼ LLM éç¼åæ§åæå°å·¥å·å¥ å®äºåºç¤ï¼å¨éç¨ä¸­å å¥äººé¡å°å¸«ï¼ä»¥æä¾æ´æå½±é¿ååæ´éèº«å®å¶çæå°é«é©ã

##### **SwarmGPT-Primitive: A Language-Driven Choreographer for Drone Swarms Using Safe Motion Primitive Composition**
2412.08428v1 by Vedant Vyas, Martin Schuck, Dinushka O. Dahanaggamaarachchi, Siqi Zhou, Angela P. Schoellig

Catalyzed by advancements in hardware and software, drone performances are
increasingly making their mark in the entertainment industry. However,
designing smooth and safe choreographies for drone swarms is complex and often
requires expert domain knowledge. In this work, we introduce
SwarmGPT-Primitive, a language-based choreographer that integrates the
reasoning capabilities of large language models (LLMs) with safe motion
planning to facilitate deployable drone swarm choreographies. The LLM composes
choreographies for a given piece of music by utilizing a library of motion
primitives; the language-based choreographer is augmented with an
optimization-based safety filter, which certifies the choreography for
real-world deployment by making minimal adjustments when feasibility and safety
constraints are violated. The overall SwarmGPT-Primitive framework decouples
choreographic design from safe motion planning, which allows non-expert users
to re-prompt and refine compositions without concerns about compliance with
constraints such as avoiding collisions or downwash effects or satisfying
actuation limits. We demonstrate our approach through simulations and
experiments with swarms of up to 20 drones performing choreographies designed
based on various songs, highlighting the system's ability to generate effective
and synchronized drone choreographies for real-world deployment.

æè¦ï¼å¨ç¡¬é«åè»é«é²æ­¥çå¬åä¸ï¼ç¡äººæ©è¡¨æ¼å¨å¨æ¨ç¢æ¥­ä¸­è¶ä¾è¶åå°éè¦ãç¶èï¼çºç¡äººæ©ç¾¤è¨­è¨æµæ¢ä¸å®å¨çç·¨èå¾è¤éï¼èä¸éå¸¸éè¦å°å®¶çé åç¥è­ãå¨éé å·¥ä½ä¸­ï¼æåä»ç´¹äº SwarmGPT-Primitiveï¼éæ¯ä¸ç¨®åºæ¼èªè¨çç·¨èå¨ï¼å®å°å¤§åèªè¨æ¨¡å (LLM) çæ¨çè½åèå®å¨çåä½è¦åç¸çµåï¼ä»¥ä¿é²å¯é¨ç½²çç¡äººæ©ç¾¤ç·¨èãLLM å©ç¨åä½åºåçåº«çºçµ¦å®çé³æ¨åµä½ç·¨èï¼åºæ¼èªè¨çç·¨èå¨ææ´åä¸ååºæ¼æä½³åçå®å¨éæ¿¾å¨ï¼ééå¨å¯è¡æ§åå®å¨æ§ç´æé­å°ç ´å£æé²è¡æå°çèª¿æ´ï¼ä¾èªè­ç·¨èä»¥é²è¡å¯¦éé¨ç½²ãæ´é«ç SwarmGPT-Primitive æ¡æ¶å°ç·¨èè¨­è¨èå®å¨çåä½è¦ååéï¼éåè¨±éå°å®¶ä½¿ç¨èéæ°æç¤ºåèª¿æ´æ§åï¼èç¡éæå¿æ¯å¦ç¬¦åç´æï¼ä¾å¦é¿åç¢°ææä¸éæ°£æµææï¼ææ»¿è¶³è´åéå¶ãæåééæ¨¡æ¬åå¯¦é©ä¾å±ç¤ºæåçåæ³ï¼å¶ä¸­ææå¤ 20 æ¶ç¡äººæ©è¡¨æ¼åºæ¼åç¨®æ­æ²è¨­è¨çç·¨èï¼çªé¡¯äºç³»çµ±çºå¯¦éé¨ç½²ç¢çææä¸åæ­¥çç¡äººæ©ç·¨èçè½åã

##### **Detecting Conversational Mental Manipulation with Intent-Aware Prompting**
2412.08414v1 by Jiayuan Ma, Hongbin Na, Zimu Wang, Yining Hua, Yue Liu, Wei Wang, Ling Chen

Mental manipulation severely undermines mental wellness by covertly and
negatively distorting decision-making. While there is an increasing interest in
mental health care within the natural language processing community, progress
in tackling manipulation remains limited due to the complexity of detecting
subtle, covert tactics in conversations. In this paper, we propose Intent-Aware
Prompting (IAP), a novel approach for detecting mental manipulations using
large language models (LLMs), providing a deeper understanding of manipulative
tactics by capturing the underlying intents of participants. Experimental
results on the MentalManip dataset demonstrate superior effectiveness of IAP
against other advanced prompting strategies. Notably, our approach
substantially reduces false negatives, helping detect more instances of mental
manipulation with minimal misjudgment of positive cases. The code of this paper
is available at https://github.com/Anton-Jiayuan-MA/Manip-IAP.

æè¦ï¼å¿çæç¸±ééé±è½åè² é¢å°æ­æ²æ±ºç­å¶å®å´éç ´å£å¿çå¥åº·ãåç®¡èªç¶èªè¨èçç¤¾ç¾¤å°å¿çä¿å¥è¶ä¾è¶æèè¶£ï¼ä½ç±æ¼å¨å°è©±ä¸­åµæ¸¬å¾®å¦ãé±è½ç­ç¥çè¤éæ§ï¼å æ­¤å¨æå°æç¸±æ¹é¢çé²å±ä»ç¶æéãå¨æ¬æä¸­ï¼æåæåºæåæç¥æç¤º (IAP)ï¼éæ¯ä¸ç¨®ä½¿ç¨å¤§åèªè¨æ¨¡å (LLM) åµæ¸¬å¿çæç¸±çæ°æ¹æ³ï¼ééææåèèçåºæ¬æåï¼æ´æ·±å¥å°çè§£æç¸±ç­ç¥ãMentalManip è³æéä¸çå¯¦é©çµæè­æäº IAP åªæ¼å¶ä»åé²æç¤ºç­ç¥çåªè¶æææ§ãå¼å¾æ³¨æçæ¯ï¼æåçåæ³å¤§å¹æ¸å°äºåé°æ§ï¼æå©æ¼åµæ¸¬æ´å¤çå¿çæç¸±æ¡ä¾ï¼åæå°é½æ§æ¡ä¾çèª¤å¤éå°æä½ãæ¬æçç¨å¼ç¢¼å¯å¨ https://github.com/Anton-Jiayuan-MA/Manip-IAP åå¾ã

##### **Learning to Reason via Self-Iterative Process Feedback for Small Language Models**
2412.08393v1 by Kaiyuan Chen, Jin Wang, Xuejie Zhang

Small language models (SLMs) are more efficient, cost-effective, and
customizable than large language models (LLMs), though they often underperform
in specific areas like reasoning. Past methods for enhancing SLMs' reasoning,
such as supervised fine-tuning and distillation, often depend on costly
external signals, resulting in SLMs being overly confident with limited
supervision signals, thus limiting their abilities. Therefore, this study
enables SLMs to learn to reason from self-iterative feedback. By combining odds
ratio preference optimization (ORPO), we fine-tune and align SLMs using
positive and negative signals generated by themselves. Additionally, we
introduce process supervision for rewards in preference alignment by
sampling-based inference simulation and process reward models. Compared to
Supervised Fine-Tuning (SFT), our method improves the performance of Gemma-2B
by 12.43 (Acc) on GSM8K and 3.95 (Pass@1) on MBPP. Furthermore, the proposed
method also demonstrated superior out-of-domain generalization capabilities on
MMLU_Math and HumanEval.

æè¦ï¼å°åè¯­è¨æ¨¡å (SLM) æ¯å¤§åè¯­è¨æ¨¡å (LLM) æ´ææçãæ´å·ææ¬æçä¸æ´å·å¯å®å¶æ§ï¼å°½ç®¡å®ä»¬å¨æ¨çç­ç¹å®é¢åéå¸¸è¡¨ç°ä¸ä½³ãè¿å»å¢å¼º SLM æ¨ççæ¹æ³ï¼ä¾å¦çç£å¾®è°åè¸é¦ï¼éå¸¸ä¾èµäºæè´µçå¤é¨ä¿¡å·ï¼å¯¼è´ SLM å¯¹æéççç£ä¿¡å·è¿åº¦èªä¿¡ï¼ä»èéå¶äºå®ä»¬çè½åãå æ­¤ï¼æ¬ç ç©¶ä½¿ SLM è½å¤ä»èªæè¿­ä»£åé¦ä¸­å­¦ä¹ æ¨çãéè¿ç»åæ¯å¼åå¥½ä¼å (ORPO)ï¼æä»¬ä½¿ç¨èªèº«çæçæ­£è´ä¿¡å·å¯¹ SLM è¿è¡å¾®è°åå¯¹é½ãæ­¤å¤ï¼æä»¬éè¿åºäºéæ ·çæ¨çæ¨¡æåè¿ç¨å¥å±æ¨¡åï¼å¼å¥äºå¥å±çè¿ç¨çç£ä»¥è¿è¡åå¥½å¯¹é½ãä¸çç£å¾®è° (SFT) ç¸æ¯ï¼æä»¬çæ¹æ³å¨ GSM8K ä¸å° Gemma-2B çæ§è½æé«äº 12.43ï¼Accï¼ï¼å¨ MBPP ä¸æé«äº 3.95ï¼Pass@1ï¼ãæ­¤å¤ï¼ææåºçæ¹æ³è¿å¨ MMLU_Math å HumanEval ä¸å±ç¤ºäºåºè²çåå¤æ³åè½åã

##### **The Roles of English in Evaluating Multilingual Language Models**
2412.08392v1 by Wessel Poelman, Miryam de Lhoneux

Multilingual natural language processing is getting increased attention, with
numerous models, benchmarks, and methods being released for many languages.
English is often used in multilingual evaluation to prompt language models
(LMs), mainly to overcome the lack of instruction tuning data in other
languages. In this position paper, we lay out two roles of English in
multilingual LM evaluations: as an interface and as a natural language. We
argue that these roles have different goals: task performance versus language
understanding. This discrepancy is highlighted with examples from datasets and
evaluation setups. Numerous works explicitly use English as an interface to
boost task performance. We recommend to move away from this imprecise method
and instead focus on furthering language understanding.

æè¦ï¼å¤èªè¨èªç¶èªè¨èçæ­£åå°è¶ä¾è¶å¤çéæ³¨ï¼è¨±å¤èªè¨é½ç¼å¸äºå¤§éçæ¨¡åãåºæºåæ¹æ³ãè±èªéå¸¸ç¨æ¼å¤èªè¨è©ä¼°ï¼ä»¥æç¤ºèªè¨æ¨¡å (LM)ï¼ä¸»è¦æ¯çºäºåæå¶ä»èªè¨ä¸­ç¼ºä¹æä»¤èª¿æ´æ¸æçåé¡ãå¨æ¬æä¸­ï¼æåé¡è¿°äºè±èªå¨å¤èªè¨ LM è©ä¼°ä¸­çå©åè§è²ï¼ä½çºä»é¢åä½çºèªç¶èªè¨ãæåèªçºéäºè§è²æä¸åçç®æ¨ï¼ä»»åå·è¡èèªè¨çè§£ãéç¨®å·®ç°ééæ¸æéåè©ä¼°è¨­ç½®çç¯ä¾å¾å°å¼·èª¿ãè¨±å¤ä½åæç¢ºä½¿ç¨è±èªä½çºä»é¢ä¾æåä»»åå·è¡ãæåå»ºè­°é é¢éç¨®ä¸ç²¾ç¢ºçæ¹æ³ï¼èæå°æ³¨æ¼é²ä¸æ­¥æåèªè¨çè§£ã

##### **SweetieChat: A Strategy-Enhanced Role-playing Framework for Diverse Scenarios Handling Emotional Support Agent**
2412.08389v1 by Jing Ye, Lu Xiang, Yaping Zhang, Chengqing Zong

Large Language Models (LLMs) have demonstrated promising potential in
providing empathetic support during interactions. However, their responses
often become verbose or overly formulaic, failing to adequately address the
diverse emotional support needs of real-world scenarios. To tackle this
challenge, we propose an innovative strategy-enhanced role-playing framework,
designed to simulate authentic emotional support conversations. Specifically,
our approach unfolds in two steps: (1) Strategy-Enhanced Role-Playing
Interactions, which involve three pivotal roles -- Seeker, Strategy Counselor,
and Supporter -- engaging in diverse scenarios to emulate real-world
interactions and promote a broader range of dialogues; and (2) Emotional
Support Agent Training, achieved through fine-tuning LLMs using our specially
constructed dataset. Within this framework, we develop the \textbf{ServeForEmo}
dataset, comprising an extensive collection of 3.7K+ multi-turn dialogues and
62.8K+ utterances. We further present \textbf{SweetieChat}, an emotional
support agent capable of handling diverse open-domain scenarios. Extensive
experiments and human evaluations confirm the framework's effectiveness in
enhancing emotional support, highlighting its unique ability to provide more
nuanced and tailored assistance.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å¨äºåä¸­æä¾åçå¿æ¯ææ¹é¢å·²å±ç¾åºæå¸æçæ½åãç¶èï¼ä»åçåæå¸¸å¸¸è®å¾åé·æéæ¼å¬å¼åï¼ç¡æ³ååæ»¿è¶³ç¾å¯¦ä¸çå ´æ¯ä¸­å¤æ¨£çæç·æ¯æéæ±ãçºäºæå°éä¸ææ°ï¼æåæåºäºä¸ååµæ°çç­ç¥å¢å¼·è§è²æ®æ¼æ¡æ¶ï¼æ¨å¨æ¨¡æ¬çå¯¦çæç·æ¯æå°è©±ãå·é«ä¾èªªï¼æåçåæ³åçºå©åæ­¥é©ï¼(1) ç­ç¥å¢å¼·çè§è²æ®æ¼äºåï¼å¶ä¸­æ¶åä¸åééµè§è²ââå°æ±èãç­ç¥é¡§ååæ¯æèââåèä¸åçå ´æ¯ï¼æ¨¡æ¬ç¾å¯¦ä¸ççäºåä¸¦ä¿é²æ´å»£æ³çå°è©±ï¼(2) æç·æ¯æä»£çè¨ç·´ï¼ééä½¿ç¨æåå°éæ§å»ºçæ¸æéå° LLM é²è¡å¾®èª¿ä¾å¯¦ç¾ãå¨æ­¤æ¡æ¶å§ï¼æåéç¼äº \textbf{ServeForEmo} æ¸æéï¼å¶ä¸­åå« 3.7K+ å¤è¼ªå°è©±å 62.8K+ è©±èªçå»£æ³éåãæåé²ä¸æ­¥æåºäº \textbf{SweetieChat}ï¼éæ¯ä¸åè½å¤ èçå¤æ¨£éæ¾é åå ´æ¯çæç·æ¯æä»£çãå»£æ³çå¯¦é©åäººé¡è©ä¼°è­å¯¦äºè©²æ¡æ¶å¨å¢å¼·æç·æ¯ææ¹é¢çæææ§ï¼çªåºäºå¶æä¾æ´ç´°ç·»ååæ§ååå©çç¨ç¹è½åã

##### **NyayaAnumana & INLegalLlama: The Largest Indian Legal Judgment Prediction Dataset and Specialized Language Model for Enhanced Decision Analysis**
2412.08385v1 by Shubham Kumar Nigam, Balaramamahanthi Deepak Patnaik, Shivam Mishra, Noel Shallum, Kripabandhu Ghosh, Arnab Bhattacharya

The integration of artificial intelligence (AI) in legal judgment prediction
(LJP) has the potential to transform the legal landscape, particularly in
jurisdictions like India, where a significant backlog of cases burdens the
legal system. This paper introduces NyayaAnumana, the largest and most diverse
corpus of Indian legal cases compiled for LJP, encompassing a total of 7,02,945
preprocessed cases. NyayaAnumana, which combines the words "Nyay" (judgment)
and "Anuman" (prediction or inference) respectively for most major Indian
languages, includes a wide range of cases from the Supreme Court, High Courts,
Tribunal Courts, District Courts, and Daily Orders and, thus, provides
unparalleled diversity and coverage. Our dataset surpasses existing datasets
like PredEx and ILDC, offering a comprehensive foundation for advanced AI
research in the legal domain.
  In addition to the dataset, we present INLegalLlama, a domain-specific
generative large language model (LLM) tailored to the intricacies of the Indian
legal system. It is developed through a two-phase training approach over a base
LLaMa model. First, Indian legal documents are injected using continual
pretraining. Second, task-specific supervised finetuning is done. This method
allows the model to achieve a deeper understanding of legal contexts.
  Our experiments demonstrate that incorporating diverse court data
significantly boosts model accuracy, achieving approximately 90% F1-score in
prediction tasks. INLegalLlama not only improves prediction accuracy but also
offers comprehensible explanations, addressing the need for explainability in
AI-assisted legal decisions.

æè¦ï¼äººå·¥æºæ§ (AI) æ´åæ¼æ³å¾å¤æ±ºé æ¸¬ (LJP) æå¯è½è½åæ³å¾é åï¼ç¹å¥æ¯å¨åå°åº¦éæ¨£æ¡ä»¶ç©å£éå¤§å°æçºæ³å¾ç³»çµ±è² æçå¸æ³ç®¡è½åãæ¬æä»ç´¹ NyayaAnumanaï¼éæ¯ä¸åéå° LJP ç·¨çºçå°åº¦æ³å¾æ¡ä»¶ä¸­è¦æ¨¡æå¤§ä¸æå¤æ¨£åçèªæåº«ï¼ç¸½å±åå« 7,02,945 åç¶éé èççæ¡ä»¶ãNyayaAnumana çµåäºãNyayãï¼å¤æ±ºï¼åãAnumanãï¼é æ¸¬ææ¨è«ï¼éå©åå­ï¼åå¥ç¨æ¼å¤§å¤æ¸ä¸»è¦çå°åº¦èªè¨ï¼åå«äºä¾èªæé«æ³é¢ãé«ç­æ³é¢ãæ³åº­ãå°æ¹æ³é¢åæ¯æ¥å½ä»¤çå»£æ³æ¡ä»¶ï¼å æ­¤æä¾äºç¡èå«æ¯çå¤æ¨£æ§åæ¶µèç¯åãæåçè³æéè¶è¶äºç¾æçè³æéï¼ä¾å¦ PredEx å ILDCï¼çºæ³å¾é åçé«é AI ç ç©¶æä¾äºå¨é¢çåºç¤ã
é¤äºè³æéä¹å¤ï¼æåéå±ç¤ºäº INLegalLlamaï¼éæ¯ä¸åéå°å°åº¦æ³å¾ç³»çµ±çè¤éæ§éèº«æé çç¹å®é åçæå¼å¤§åèªè¨æ¨¡å (LLM)ãå®æ¯ééå¨åºç¤ LLaMa æ¨¡åä¸é²è¡å©éæ®µè¨ç·´æ¹æ³éç¼çãé¦åï¼ä½¿ç¨æçºé è¨ç·´æ³¨å¥å°åº¦æ³å¾æä»¶ãå¶æ¬¡ï¼å·è¡ç¹å®æ¼ä»»åçç£ç£å¾®èª¿ãæ­¤æ¹æ³è®æ¨¡åè½å¤ æ´æ·±å¥å°äºè§£æ³å¾èçµ¡ã
æåçå¯¦é©è­æï¼æ´åå¤æ¨£åçæ³åº­è³ææé¡¯èæåæ¨¡åæºç¢ºåº¦ï¼å¨é æ¸¬ä»»åä¸­éå°ç´ 90% ç F1 åæ¸ãINLegalLlama ä¸åæé«äºé æ¸¬æºç¢ºåº¦ï¼ä¹æä¾äºææ¼çè§£çè§£éï¼æ»¿è¶³äº AI è¼å©æ³å¾æ±ºç­ä¸­å°å¯è§£éæ§çéæ±ã

##### **HyViLM: Enhancing Fine-Grained Recognition with a Hybrid Encoder for Vision-Language Models**
2412.08378v1 by Shiding Zhu, Wenhui Dong, Jun Song, Yanan Guo, Bo Zheng

Recently, there has been growing interest in the capability of multimodal
large language models (MLLMs) to process high-resolution images. A common
approach currently involves dynamically cropping the original high-resolution
image into smaller sub-images, which are then fed into a vision encoder that
was pre-trained on lower-resolution images. However, this cropping approach
often truncates objects and connected areas in the original image, causing
semantic breaks. To address this limitation, we introduce HyViLM, designed to
process images of any resolution while retaining the overall context during
encoding. Specifically, we: (i) Design a new visual encoder called Hybrid
Encoder that not only encodes individual sub-images but also interacts with
detailed global visual features, significantly improving the model's ability to
encode high-resolution images. (ii) Propose an optimal feature fusion strategy
for the dynamic cropping approach, effectively leveraging information from
different layers of the vision encoder. Compared with the state-of-the-art
MLLMs under the same setting, our HyViLM outperforms existing MLLMs in nine out
of ten tasks. Specifically, HyViLM achieves a 9.6% improvement in performance
on the TextVQA task and a 6.9% enhancement on the DocVQA task.

æè¦ï¼<paragraph>æè¿ï¼äººä»¬å¯¹å¤æ¨¡æå¤§åè¯­è¨æ¨¡å (MLLM) å¤çé«åè¾¨çå¾åçè½åè¶æ¥è¶æå´è¶£ãç®åï¼ä¸ç§å¸¸è§çæ¹æ³æ¶åå°åå§é«åè¾¨çå¾åå¨æè£åªæè¾å°çå­å¾åï¼ç¶åå°å¶è¾å¥å°å¨ä½åè¾¨çå¾åä¸é¢è®­ç»çè§è§ç¼ç å¨ä¸­ãç¶èï¼è¿ç§è£åªæ¹æ³éå¸¸ä¼æªæ­åå§å¾åä¸­çå¯¹è±¡åè¿æ¥åºåï¼ä»èå¯¼è´è¯­ä¹ä¸­æ­ãä¸ºäºè§£å³è¿ä¸éå¶ï¼æä»¬å¼å¥äº HyViLMï¼å®æ¨å¨å¤çä»»ä½åè¾¨ççå¾åï¼åæ¶å¨ç¼ç æé´ä¿çæ´ä½ä¸ä¸æãå·ä½æ¥è¯´ï¼æä»¬ï¼(i) è®¾è®¡äºä¸ç§æ°çè§è§ç¼ç å¨ï¼ç§°ä¸ºæ··åç¼ç å¨ï¼å®ä¸ä»å¯ä»¥å¯¹åä¸ªå­å¾åè¿è¡ç¼ç ï¼è¿å¯ä»¥ä¸è¯¦ç»çå¨å±è§è§ç¹å¾è¿è¡äº¤äºï¼ä»èæ¾èæé«æ¨¡åå¯¹é«åè¾¨çå¾åè¿è¡ç¼ç çè½åã(ii) ä¸ºå¨æè£åªæ¹æ³æåºäºä¸ç§æä½³ç¹å¾èåç­ç¥ï¼ææå°å©ç¨äºè§è§ç¼ç å¨ä¸åå±çä¿¡æ¯ãä¸å¨ç¸åè®¾ç½®ä¸çæåè¿ç MLLM ç¸æ¯ï¼æä»¬ç HyViLM å¨ååä¹ä¹çä»»å¡ä¸­ä¼äºç°æç MLLMãå·ä½æ¥è¯´ï¼HyViLM å¨ TextVQA ä»»å¡ä¸çæ§è½æé«äº 9.6%ï¼å¨ DocVQA ä»»å¡ä¸çæ§è½æé«äº 6.9%ã</paragraph>

##### **SmolTulu: Higher Learning Rate to Batch Size Ratios Can Lead to Better Reasoning in SLMs**
2412.08347v1 by Sultan Alrashed

We present SmolTulu-1.7b-Instruct, referenced in this report as
SmolTulu-DPO-1130, an instruction-tuned language model that adapts AllenAI's
Tulu 3 post-training pipeline to enhance Huggingface's SmolLM2-1.7B base model.
Through comprehensive empirical analysis using a 135M parameter model, we
demonstrate that the relationship between learning rate and batch size
significantly impacts model performance in a task-dependent manner. Our
findings reveal a clear split: reasoning tasks like ARC and GSM8K benefit from
higher learning rate to batch size ratios, while pattern recognition tasks such
as HellaSwag and IFEval show optimal performance with lower ratios. These
insights informed the development of SmolTulu, which achieves state-of-the-art
performance among sub-2B parameter models on instruction following, scoring
67.7% on IFEval ($\Delta$11%), and mathematical reasoning with 51.6% on GSM8K
($\Delta$3.4%), with an alternate version achieving scoring 57.1% on ARC
($\Delta5.4%$). We release our model, training recipes, and ablation studies to
facilitate further research in efficient model alignment, demonstrating that
careful adaptation of optimization dynamics can help bridge the capability gap
between small and large language models.

æè¦ï¼æåæåº SmolTulu-1.7b-Instructï¼æ¬å ±åä¸­ç¨±çº SmolTulu-DPO-1130ï¼éæ¯ä¸ç¨®æä»¤èª¿æ´èªè¨æ¨¡åï¼æ¡ç¨ AllenAI ç Tulu 3 å¾è¨ç·´ç®¡éä¾å¢å¼· Huggingface ç SmolLM2-1.7B åºç¤æ¨¡åãééä½¿ç¨ 135M åæ¸æ¨¡åçå¨é¢ç¶é©åæï¼æåè­æå­¸ç¿çèæ¹æ¬¡å¤§å°ä¹éçéä¿æä»¥ä»»åç¸éçæ¹å¼é¡¯èå½±é¿æ¨¡åæè½ãæåçç¼ç¾æ­ç¤ºäºä¸åæç¢ºçåæ­§ï¼å ARC å GSM8K ç­æ¨çä»»ååçæ¼è¼é«çå­¸ç¿çå°æ¹æ¬¡å¤§å°çæ¯çï¼èå HellaSwag å IFEval ç­æ¨¡å¼è¾¨è­ä»»ååé¡¯ç¤ºåºè¼ä½æ¯ççæä½³æè½ãéäºè¦è§£çº SmolTulu çéç¼æä¾äºè³è¨ï¼å¨å°æ¼ 2B åæ¸æ¨¡åä¸­ï¼å¨æä»¤éµå¾ªæ¹é¢åå¾äºæåé²çè¡¨ç¾ï¼å¨ IFEval ä¸å¾å 67.7%ï¼Î11%ï¼ï¼å¨ GSM8K ä¸çæ¸å­¸æ¨çå¾åçº 51.6%ï¼Î3.4%ï¼ï¼èå¦ä¸åçæ¬å¨ ARC ä¸å¾å 57.1%ï¼Î5.4%ï¼ãæåç¼å¸æåçæ¨¡åãè¨ç·´ç¯ä¾åæ¶èç ç©¶ï¼ä»¥ä¿é²é«ææ¨¡åå°é½çé²ä¸æ­¥ç ç©¶ï¼è­æä»ç´°èª¿æ´æä½³ååæå¯ä»¥å¹«å©ç¸®å°å°ååå¤§åèªè¨æ¨¡åä¹éçè½åå·®è·ã

##### **BEIR-NL: Zero-shot Information Retrieval Benchmark for the Dutch Language**
2412.08329v1 by Nikolay Banar, Ehsan Lotfi, Walter Daelemans

Zero-shot evaluation of information retrieval (IR) models is often performed
using BEIR; a large and heterogeneous benchmark composed of multiple datasets,
covering different retrieval tasks across various domains. Although BEIR has
become a standard benchmark for the zero-shot setup, its exclusively English
content reduces its utility for underrepresented languages in IR, including
Dutch. To address this limitation and encourage the development of Dutch IR
models, we introduce BEIR-NL by automatically translating the publicly
accessible BEIR datasets into Dutch. Using BEIR-NL, we evaluated a wide range
of multilingual dense ranking and reranking models, as well as the lexical BM25
method. Our experiments show that BM25 remains a competitive baseline, and is
only outperformed by the larger dense models trained for retrieval. When
combined with reranking models, BM25 achieves performance on par with the best
dense ranking models. In addition, we explored the impact of translation on the
data by back-translating a selection of datasets to English, and observed a
performance drop for both dense and lexical methods, indicating the limitations
of translation for creating benchmarks. BEIR-NL is publicly available on the
Hugging Face hub.

æè¦ï¼è³è¨æª¢ç´¢ (IR) æ¨¡åçé¶æ¬¡è©ä¼°éå¸¸ä½¿ç¨ BEIR å·è¡ï¼éæ¯ä¸åå¤§åä¸ç°è³ªçåºæºï¼ç±å¤åè³æéçµæï¼æ¶µèåç¨®é åçä¸åæª¢ç´¢ä»»åãéç¶ BEIR å·²æçºé¶æ¬¡è¨­å®çæ¨æºåºæºï¼ä½å¶å°å±¬çè±æå§å®¹éä½äºå¶å¨ IR ä¸­ä»£è¡¨æ§ä¸è¶³çèªè¨ï¼åæ¬è·è­èªï¼ä¸­çæç¨ãçºäºè§£æ±ºéåéå¶ä¸¦é¼åµéç¼è·è­èª IR æ¨¡åï¼æåééå°å¬éå¯å­åç BEIR è³æéèªåç¿»è­¯æè·è­èªä¾å¼å¥ BEIR-NLãä½¿ç¨ BEIR-NLï¼æåè©ä¼°äºå»£æ³çå¤èªè¨å¯éæååéæ°æåæ¨¡åï¼ä»¥åè©å½ BM25 æ¹æ³ãæåçå¯¦é©é¡¯ç¤ºï¼BM25 ä»ç¶æ¯ä¸åæç«¶ç­åçåºæºï¼ä¸¦ä¸åæ¬¡æ¼éå°æª¢ç´¢è¨ç·´çè¼å¤§åå¯éæ¨¡åãèéæ°æåæ¨¡åçµåæï¼BM25 çæè½èæä½³å¯éæåæ¨¡åç¸ç¶ãæ­¤å¤ï¼æåééå°é¨åè³æéååç¿»è­¯æè±æä¾æ¢è¨ç¿»è­¯å°è³æçå½±é¿ï¼ä¸¦è§å¯å°å¯éåè©å½æ¹æ³çæè½ä¸éï¼éè¡¨ç¤ºç¿»è­¯å¨å»ºç«åºæºä¸çéå¶ãBEIR-NL å·²å¨ Hugging Face éæ£å°ä¸­å¬éã

##### **Large Language Models Still Face Challenges in Multi-Hop Reasoning with External Knowledge**
2412.08317v1 by Haotong Zhang

We carry out a series of experiments to test large language models' multi-hop
reasoning ability from three aspects: selecting and combining external
knowledge, dealing with non-sequential reasoning tasks and generalising to data
samples with larger numbers of hops. We test the GPT-3.5 model on four
reasoning benchmarks with Chain-of-Thought prompting (and its variations). Our
results reveal that despite the amazing performance achieved by large language
models on various reasoning tasks, models still suffer from severe drawbacks
which shows a large gap with humans.

æè¦ï¼æåé²è¡ä¸ç³»åå¯¦é©ï¼å¾ä¸åæ¹é¢æ¸¬è©¦å¤§åèªè¨æ¨¡åçå¤è·³æ¨çè½åï¼é¸æåçµåå¤é¨ç¥è­ãèçéé åºæ¨çä»»åä»¥åæ¨å»£å°å·ææ´å¤è·³æ¸çæ¸ææ¨£æ¬ãæåå¨ååæ¨çåºæºä¸æ¸¬è©¦ GPT-3.5 æ¨¡åï¼ä¸¦ä½¿ç¨æèéæç¤ºï¼åå¶è®é«ï¼ãæåççµæè¡¨æï¼åç®¡å¤§åèªè¨æ¨¡åå¨åç¨®æ¨çä»»åä¸åå¾äºé©äººçè¡¨ç¾ï¼ä½æ¨¡åä»ç¶å­å¨å´éçç¼ºé»ï¼éè¡¨æèäººé¡å­å¨å¾å¤§çå·®è·ã

##### **Rumor Detection on Social Media with Temporal Propagation Structure Optimization**
2412.08316v1 by Xingyu Peng, Junran Wu, Ruomei Liu, Ke Xu

Traditional methods for detecting rumors on social media primarily focus on
analyzing textual content, often struggling to capture the complexity of online
interactions. Recent research has shifted towards leveraging graph neural
networks to model the hierarchical conversation structure that emerges during
rumor propagation. However, these methods tend to overlook the temporal aspect
of rumor propagation and may disregard potential noise within the propagation
structure. In this paper, we propose a novel approach that incorporates
temporal information by constructing a weighted propagation tree, where the
weight of each edge represents the time interval between connected posts.
Drawing upon the theory of structural entropy, we transform this tree into a
coding tree. This transformation aims to preserve the essential structure of
rumor propagation while reducing noise. Finally, we introduce a recursive
neural network to learn from the coding tree for rumor veracity prediction.
Experimental results on two common datasets demonstrate the superiority of our
approach.

æè¦ï¼å³çµ±çç¤¾ç¾¤åªé«è¬ è¨åµæ¸¬æ¹æ³ä¸»è¦èéæ¼åææå­å§å®¹ï¼éå¸¸é£ä»¥ææç·ä¸äºåçè¤éæ§ãæè¿çç ç©¶å·²è½åå©ç¨åå½¢ç¥ç¶ç¶²è·¯ä¾æ¨¡æ¬è¬ è¨å³æ­æéåºç¾çéå±¤å¼å°è©±çµæ§ãç¶èï¼éäºæ¹æ³å¾åæ¼å¿½ç¥è¬ è¨å³æ­çæéé¢åï¼ä¸¦å¯è½å¿½ç¥å³æ­çµæ§ä¸­çæ½å¨éè¨ãå¨æ¬æä¸­ï¼æåæåºä¸åæ°çæ¹æ³ï¼ééå»ºæ§å æ¬å³æ­æ¨¹ä¾ç´å¥æéè³è¨ï¼å¶ä¸­æ¯æ¢éçæ¬éä»£è¡¨é£æ¥è²¼æä¹éçæéééãæ ¹æçµæ§çµçè«ï¼æåå°éæ£µæ¨¹è½ææç·¨ç¢¼æ¨¹ãæ­¤è½ææ¨å¨ä¿çè¬ è¨å³æ­çåºæ¬çµæ§ï¼åææ¸å°éè¨ãæå¾ï¼æåå¼å¥éè¿´ç¥ç¶ç¶²è·¯ï¼å¾ç·¨ç¢¼æ¨¹ä¸­å­¸ç¿ä»¥é²è¡è¬ è¨çå¯¦æ§é æ¸¬ãå¨å©åå¸¸è¦è³æéä¸çå¯¦é©çµæè­æäºæåæ¹æ³çåªè¶æ§ã

##### **Self-Refining Diffusion Samplers: Enabling Parallelization via Parareal Iterations**
2412.08292v1 by Nikil Roashan Selvam, Amil Merchant, Stefano Ermon

In diffusion models, samples are generated through an iterative refinement
process, requiring hundreds of sequential model evaluations. Several recent
methods have introduced approximations (fewer discretization steps or
distillation) to trade off speed at the cost of sample quality. In contrast, we
introduce Self-Refining Diffusion Samplers (SRDS) that retain sample quality
and can improve latency at the cost of additional parallel compute. We take
inspiration from the Parareal algorithm, a popular numerical method for
parallel-in-time integration of differential equations. In SRDS, a quick but
rough estimate of a sample is first created and then iteratively refined in
parallel through Parareal iterations. SRDS is not only guaranteed to accurately
solve the ODE and converge to the serial solution but also benefits from
parallelization across the diffusion trajectory, enabling batched inference and
pipelining. As we demonstrate for pre-trained diffusion models, the early
convergence of this refinement procedure drastically reduces the number of
steps required to produce a sample, speeding up generation for instance by up
to 1.7x on a 25-step StableDiffusion-v2 benchmark and up to 4.3x on longer
trajectories.

æè¦ï¼å¨æ´æ£æ¨¡åä¸­ï¼æ¨£æ¬æ¯ééåè¦çç²¾çéç¨ç¢ççï¼éè¦é²è¡æ¸ç¾æ¬¡é åºæ¨¡åè©ä¼°ãæè¿æå¹¾ç¨®æ¹æ³å¼å¥äºè¿ä¼¼å¼ï¼è¼å°çé¢æ£åæ­¥é©æè¸é¤¾ï¼ä¾ä»¥æ¨£æ¬åè³ªçºä»£å¹ä¾æåéåº¦ãç¸åå°ï¼æåå¼å¥äºèªæç²¾çæ´æ£åæ¨£å¨ (SRDS)ï¼å®ä¿çäºæ¨£æ¬åè³ªï¼ä¸¦ä¸å¯ä»¥ä»¥é¡å¤çä¸¦è¡éç®çºä»£å¹ä¾æ¹åå»¶é²ãæåå¾ Parareal æ¼ç®æ³ä¸­æ±²åéæï¼éæ¯ä¸ç¨®ç¨æ¼å¾®åæ¹ç¨å¼ä¸¦è¡æéç©åçç±éæ¸å¼æ¹æ³ãå¨ SRDS ä¸­ï¼é¦åå»ºç«ä¸åå¿«éä½ç²ç¥çæ¨£æ¬ä¼°è¨ï¼ç¶å¾éé Parareal è¿­ä»£ä¸¦è¡å°åè¦ç²¾çãSRDS ä¸åä¿è­æºç¢ºå°æ±è§£ ODE ä¸¦æ¶æå°åºåè§£ï¼èä¸éåçæ¼æ´æ£è»è·¡çä¸¦è¡åï¼å¾èå¯¦ç¾æ¹æ¬¡æ¨è«åæµæ°´ç·ãæ­£å¦æåçºé åè¨ç·´çæ´æ£æ¨¡åæå±ç¤ºçé£æ¨£ï¼éç¨®ç²¾çç¨åºçæ©ææ¶æå¤§å¹æ¸å°äºç¢çæ¨£æ¬æéçæ­¥é©æ¸ï¼ä¾å¦ï¼å¨ 25 æ­¥ç StableDiffusion-v2 åºæºä¸å°çæéåº¦æé«äº 1.7 åï¼å¨æ´é·çè»è·¡ä¸å°éåº¦æé«äº 4.3 åã

##### **Code LLMs: A Taxonomy-based Survey**
2412.08291v1 by Nishat Raihan, Christian Newman, Marcos Zampieri

Large language models (LLMs) have demonstrated remarkable capabilities across
various NLP tasks and have recently expanded their impact to coding tasks,
bridging the gap between natural languages (NL) and programming languages (PL).
This taxonomy-based survey provides a comprehensive analysis of LLMs in the
NL-PL domain, investigating how these models are utilized in coding tasks and
examining their methodologies, architectures, and training processes. We
propose a taxonomy-based framework that categorizes relevant concepts,
providing a unified classification system to facilitate a deeper understanding
of this rapidly evolving field. This survey offers insights into the current
state and future directions of LLMs in coding tasks, including their
applications and limitations.

æè¦ï¼å¤§åèªè¨æ¨¡åï¼LLMï¼å·²å¨åç¨® NLP ä»»åä¸­å±ç¾åºéå¡çè½åï¼æè¿æ´æ´å±å¶å½±é¿åè³ç·¨ç¢¼ä»»åï¼ç¸®å°äºèªç¶èªè¨ï¼NLï¼èç¨å¼èªè¨ï¼PLï¼ä¹éçå·®è·ãéé åºæ¼åé¡çèª¿æ¥æä¾äº LLM å¨ NL-PL é åçå¨é¢åæï¼æ¢è¨äºéäºæ¨¡åå¦ä½ç¨æ¼ç·¨ç¢¼ä»»åï¼ä¸¦æª¢è¦å¶æ¹æ³ãæ¶æ§åè¨ç·´æµç¨ãæåæåºäºä¸ååºæ¼åé¡çæ¶æ§ï¼å°ç¸éæ¦å¿µé²è¡åé¡ï¼æä¾äºä¸åçµ±ä¸çåé¡ç³»çµ±ï¼ä»¥ä¿é²å°éåå¿«éæ¼è®çé åææ´æ·±å¥çäºè§£ãéé èª¿æ¥æä¾äºå° LLM å¨ç·¨ç¢¼ä»»åä¸­ç¶åçæåæªä¾æ¹åçè¦è§£ï¼åæ¬å¶æç¨åéå¶ã

##### **Adaptive Prompting for Continual Relation Extraction: A Within-Task Variance Perspective**
2412.08285v1 by Minh Le, Tien Ngoc Luu, An Nguyen The, Thanh-Thien Le, Trang Nguyen, Thanh Tung Nguyen, Linh Ngo Van, Thien Huu Nguyen

To address catastrophic forgetting in Continual Relation Extraction (CRE),
many current approaches rely on memory buffers to rehearse previously learned
knowledge while acquiring new tasks. Recently, prompt-based methods have
emerged as potent alternatives to rehearsal-based strategies, demonstrating
strong empirical performance. However, upon analyzing existing prompt-based
approaches for CRE, we identified several critical limitations, such as
inaccurate prompt selection, inadequate mechanisms for mitigating forgetting in
shared parameters, and suboptimal handling of cross-task and within-task
variances. To overcome these challenges, we draw inspiration from the
relationship between prefix-tuning and mixture of experts, proposing a novel
approach that employs a prompt pool for each task, capturing variations within
each task while enhancing cross-task variances. Furthermore, we incorporate a
generative model to consolidate prior knowledge within shared parameters,
eliminating the need for explicit data storage. Extensive experiments validate
the efficacy of our approach, demonstrating superior performance over
state-of-the-art prompt-based and rehearsal-free methods in continual relation
extraction.

æè¦ï¼çºäºè§£æ±ºæçºéä¿èå (CRE) ä¸­çç½é£æ§éºå¿ï¼è¨±å¤ç¾ææ¹æ³ä¾è³´è¨æ¶é«ç·©è¡åä¾æç·´ååå­¸ç¿çç¥è­ï¼åæç²åæ°ä»»åãæè¿ï¼åºæ¼æç¤ºçæ¹æ³å·²æçºåºæ¼æç·´ç­ç¥çæåæ¿ä»£æ¹æ¡ï¼å±ç¤ºåºå¼·å¤§çç¶é©æè½ãç¶èï¼å¨åæç¾æçåºæ¼æç¤ºç CRE æ¹æ³å¾ï¼æåç¼ç¾äºå¹¾åééµéå¶ï¼ä¾å¦ä¸æºç¢ºçæç¤ºé¸æãæ¸è¼å±äº«åæ¸ä¸­éºå¿çä¸ååæ©å¶ï¼ä»¥åå°è·¨ä»»ååä»»åå§è®ç°çæ¬¡åªèçãçºäºåæéäºææ°ï¼æåå¾åç¶´èª¿æ´åå°å®¶æ··åä¹éçéä¿ä¸­æ±²åéæï¼æåºäºä¸ç¨®æ°æ¹æ³ï¼è©²æ¹æ³çºæ¯åä»»åæ¡ç¨æç¤ºæ± ï¼æææ¯åä»»åå§çè®ç°ï¼åæå¢å¼·è·¨ä»»åè®ç°ãæ­¤å¤ï¼æåçµåäºä¸åçææ¨¡åä¾æ´åå±äº«åæ¸å§çååç¥è­ï¼æ¶é¤äºå°æç¢ºè³æå²å­çéæ±ãå»£æ³çå¯¦é©é©è­äºæåæ¹æ³çæåï¼å±ç¤ºäºå¨æçºéä¿èåä¸­åªæ¼æåé²çåºæ¼æç¤ºåç¡æç·´æ¹æ³çåè¶æè½ã

##### **A Preliminary Analysis of Automatic Word and Syllable Prominence Detection in Non-Native Speech With Text-to-Speech Prosody Embeddings**
2412.08283v1 by Anindita Mondal, Rangavajjala Sankara Bharadwaj, Jhansi Mallela, Anil Kumar Vuppala, Chiranjeevi Yarra

Automatic detection of prominence at the word and syllable-levels is critical
for building computer-assisted language learning systems. It has been shown
that prosody embeddings learned by the current state-of-the-art (SOTA)
text-to-speech (TTS) systems could generate word- and syllable-level prominence
in the synthesized speech as natural as in native speech. To understand the
effectiveness of prosody embeddings from TTS for prominence detection under
nonnative context, a comparative analysis is conducted on the embeddings
extracted from native and non-native speech considering the prominence-related
embeddings: duration, energy, and pitch from a SOTA TTS named FastSpeech2.
These embeddings are extracted under two conditions considering: 1) only text,
2) both speech and text. For the first condition, the embeddings are extracted
directly from the TTS inference mode, whereas for the second condition, we
propose to extract from the TTS under training mode. Experiments are conducted
on native speech corpus: Tatoeba, and non-native speech corpus: ISLE. For
experimentation, word-level prominence locations are manually annotated for
both corpora. The highest relative improvement on word \& syllable-level
prominence detection accuracies with the TTS embeddings are found to be 13.7% &
5.9% and 16.2% & 6.9% compared to those with the heuristic-based features and
self-supervised Wav2Vec-2.0 representations, respectively.

æè¦ï¼èªååµæ¸¬å®å­åé³ç¯å±¤ç´çéé³å°æ¼å»ºæ§é»è¦è¼å©èªè¨å­¸ç¿ç³»çµ±è³ééè¦ãç®åæåé² (SOTA) çæå­è½èªé³ (TTS) ç³»çµ±æå­¸ç¿å°çé»å¾åµå¥ï¼å·²è¢«è­å¯¦å¯ä»¥åæåºèæ¯èªäººå£«èªªè©±ä¸æ¨£èªç¶çå®å­åé³ç¯å±¤ç´éé³ãçºäºäºè§£ TTS é»å¾åµå¥å¨éæ¯èªèçµ¡ä¸­ç¨æ¼éé³åµæ¸¬çæææ§ï¼æåå°å¾æ¯èªåéæ¯èªæ¼èªªä¸­èååºçåµå¥é²è¡æ¯è¼åæï¼èé SOTA TTSï¼ç¨±çº FastSpeech2ï¼ä¸­èéé³ç¸éçåµå¥ï¼æé·ãè½éåé³é«ãéäºåµå¥æ¯å¨å©åæ¢ä»¶ä¸èåçï¼1) åªææå­ï¼2) èªé³åæå­çæãå°æ¼ç¬¬ä¸åæ¢ä»¶ï¼åµå¥æ¯ç´æ¥å¾ TTS æ¨è«æ¨¡å¼ä¸­èåï¼èå°æ¼ç¬¬äºåæ¢ä»¶ï¼æåå»ºè­°å¾è¨ç·´æ¨¡å¼ä¸­ç TTS ä¸­èåãå¯¦é©æ¯å¨æ¯èªèªæåº«ï¼Tatoeba åéæ¯èªèªæåº«ï¼ISLE ä¸é²è¡ãçºäºå¯¦é©ï¼å©åèªæåº«çå®å­å±¤ç´éé³ä½ç½®é½ç¶éæåæ¨è¨»ãç¼ç¾ä½¿ç¨ TTS åµå¥å¨å®å­åé³ç¯å±¤ç´éé³åµæ¸¬æºç¢ºçä¸æé«çç¸å°æ¹åçº 13.7% å 5.9% ä»¥å 16.2% å 6.9%ï¼åå¥èåºæ¼åç¼å¼ç¹å¾µåèªç£ç£ Wav2Vec-2.0 è¡¨å¾µç¸æ¯ã

##### **Y-NQ: English-YorÃ¹bÃ¡ Evaluation dataset for Open-Book Reading Comprehension and Text Generation**
2412.08279v1 by Marta R. Costa-jussÃ , Joy Chen, Ifeoluwanimi Adebara, Joe Chuang, Christophe Ropers, Eduardo SÃ¡nchez

The purpose of this work is to share an English-Yor\`ub\'a evaluation dataset
for open-book reading comprehension and text generation to assess the
performance of models both in a high- and a low- resource language. The dataset
contains 358 questions and answers on 338 English documents and 208 Yor\`ub\'a
documents. The average document length is ~ 10k words for English and 430 words
for Yor\`ub\'a. Experiments show a consistent disparity in performance between
the two languages, with Yor\`ub\'a falling behind English for automatic metrics
even if documents are much shorter for this language. For a small set of
documents with comparable length, performance of Yor\`ub\'a drops by x2.5
times. When analyzing performance by length, we observe that Yor\`ub\'a
decreases performance dramatically for documents that reach 1500 words while
English performance is barely affected at that length. Our dataset opens the
door to showcasing if English LLM reading comprehension capabilities extend to
Yor\`ub\'a, which for the evaluated LLMs is not the case.

æè¦ï¼æ¬ç ç©¶çç®çæ¯åäº«ä¸ä¸ªè±è¯­-çº¦é²å·´è¯­è¯ä¼°æ°æ®éï¼ç¨äºå¼æ¾å¼éè¯»çè§£åææ¬çæï¼ä»¥è¯ä¼°æ¨¡åå¨é«èµæºåä½èµæºè¯­è¨ä¸­çè¡¨ç°ãè¯¥æ°æ®éåå« 358 ä¸ªé®é¢åç­æ¡ï¼æ¶å 338 ç¯è±è¯­ææ¡£å 208 ç¯çº¦é²å·´è¯­ææ¡£ãè±è¯­ææ¡£çå¹³åé¿åº¦çº¦ä¸º 10k ä¸ªåè¯ï¼çº¦é²å·´è¯­ææ¡£çå¹³åé¿åº¦ä¸º 430 ä¸ªåè¯ãå®éªè¡¨æï¼ä¸¤ç§è¯­è¨å¨è¡¨ç°ä¸å­å¨æç»­çå·®å¼ï¼çº¦é²å·´è¯­å¨èªå¨ææ æ¹é¢è½åäºè±è¯­ï¼å³ä½¿è¯¥è¯­è¨çææ¡£è¦ç­å¾å¤ãå¯¹äºä¸ç»é¿åº¦ç¸å½çææ¡£ï¼çº¦é²å·´è¯­çè¡¨ç°ä¸éäº x2.5 åãå¨æé¿åº¦åæè¡¨ç°æ¶ï¼æä»¬è§å¯å°ï¼çº¦é²å·´è¯­å¨ææ¡£è¾¾å° 1500 ä¸ªåè¯æ¶è¡¨ç°æ¥å§ä¸éï¼èè±è¯­å¨è¯¥é¿åº¦ä¸çè¡¨ç°å ä¹æ²¡æåå°å½±åãæä»¬çæ°æ®éå±ç¤ºäºè±è¯­ LLM éè¯»çè§£è½åæ¯å¦æ©å±å°çº¦é²å·´è¯­ï¼å¯¹äºè¯ä¼°è¿ç LLM æ¥è¯´ï¼äºå®å¹¶éå¦æ­¤ã

##### **2M-BELEBELE: Highly Multilingual Speech and American Sign Language Comprehension Dataset**
2412.08274v1 by Marta R. Costa-jussÃ , Bokai Yu, Pierre Andrews, Belen Alastruey, Necati Cihan Camgoz, Joe Chuang, Jean Maillard, Christophe Ropers, Arina Turkantenko, Carleigh Wood

We introduce the first highly multilingual speech and American Sign Language
(ASL) comprehension dataset by extending BELEBELE. Our dataset covers 74 spoken
languages at the intersection of BELEBELE and FLEURS, and one sign language
(ASL). We evaluate 2M-BELEBELE dataset for both 5-shot and zero-shot settings
and across languages, the speech comprehension accuracy is ~ 8% average lower
compared to reading comprehension.

æè¦ï¼æåééæ´å BELEBELE ä»ç´¹ç¬¬ä¸åé«åº¦å¤èªè¨çèªé³åç¾åæèª (ASL) çè§£è³æéãæåçè³æéæ¶µè BELEBELE å FLEURS äº¤éä¸­ç 74 ç¨®å£èªªèªè¨ï¼ä»¥åä¸ç¨®æèª (ASL)ãæåéå° 5-shot å zero-shot è¨­å®ä»¥åè·¨èªè¨è©ä¼° 2M-BELEBELE è³æéï¼èé±è®çè§£ç¸æ¯ï¼èªé³çè§£æºç¢ºåº¦å¹³åä½ç´ 8%ã

##### **Position-aware Guided Point Cloud Completion with CLIP Model**
2412.08271v1 by Feng Zhou, Qi Zhang, Ju Dai, Lei Li, Qing Fan, Junliang Xing

Point cloud completion aims to recover partial geometric and topological
shapes caused by equipment defects or limited viewpoints. Current methods
either solely rely on the 3D coordinates of the point cloud to complete it or
incorporate additional images with well-calibrated intrinsic parameters to
guide the geometric estimation of the missing parts. Although these methods
have achieved excellent performance by directly predicting the location of
complete points, the extracted features lack fine-grained information regarding
the location of the missing area. To address this issue, we propose a rapid and
efficient method to expand an unimodal framework into a multimodal framework.
This approach incorporates a position-aware module designed to enhance the
spatial information of the missing parts through a weighted map learning
mechanism. In addition, we establish a Point-Text-Image triplet corpus PCI-TI
and MVP-TI based on the existing unimodal point cloud completion dataset and
use the pre-trained vision-language model CLIP to provide richer detail
information for 3D shapes, thereby enhancing performance. Extensive
quantitative and qualitative experiments demonstrate that our method
outperforms state-of-the-art point cloud completion methods.

æè¦ï¼é»é²å®æçç®æ¨æ¯å¾©åå è¨­åç¼ºé·æè¦é»åéèé æçå±é¨å¹¾ä½åææ²å½¢çãç®åçæ¹æ³ï¼è¦ä¸åªä¾è³´é»é²ç 3D åº§æ¨ä¾å®æå®ï¼è¦ä¸å°±çµåé¡å¤å·æè¯å¥½æ ¡æ­£å§é¨åæ¸çå½±åï¼ä¾å¼å°éºå¤±é¨åçå¹¾ä½ä¼°è¨ãéç¶éäºæ¹æ³ééç´æ¥é æ¸¬å®æ´é»çä½ç½®ï¼éå°äºçµä½³çè¡¨ç¾ï¼ä½æååºçç¹å¾µç¼ºä¹æééºå¤±ååä½ç½®çç´°å¾®è³è¨ãçºäºè§£æ±ºéååé¡ï¼æåæåºä¸åå¿«éä¸ææççæ¹æ³ï¼å°å®å³°æ¶æ§æ´å±æå¤å³°æ¶æ§ãæ­¤æ¹æ³çµåäºä¸åä½ç½®æç¥æ¨¡çµï¼æ¨å¨ééå æ¬å°åå­¸ç¿æ©å¶ï¼æåéºå¤±é¨åçç©ºéè³è¨ãæ­¤å¤ï¼æåå¨ç¾æçå®å³°é»é²å®æè³æéçåºç¤ä¸ï¼å»ºç«äºä¸åé»-æå­-å½±åä¸éé«èªæåº« PCI-TI å MVP-TIï¼ä¸¦ä½¿ç¨é åè¨ç·´å¥½çè¦è¦ºèªè¨æ¨¡å CLIPï¼ä¾æä¾æ´è±å¯çç´°ç¯è³è¨ï¼ç¨æ¼ 3D å½¢çï¼é²èæåæè½ãå»£æ³çéååå®æ§å¯¦é©è­æï¼æåçæ¹æ³åªæ¼ç¾æçé»é²å®ææ¹æ³ã

##### **LCFO: Long Context and Long Form Output Dataset and Benchmarking**
2412.08268v1 by Marta R. Costa-jussÃ , Pierre Andrews, Mariano Coria Meglioli, Joy Chen, Joe Chuang, David Dale, Christophe Ropers, Alexandre Mourachko, Eduardo SÃ¡nchez, Holger Schwenk, Tuan Tran, Arina Turkatenko, Carleigh Wood

This paper presents the Long Context and Form Output (LCFO) benchmark, a
novel evaluation framework for assessing gradual summarization and summary
expansion capabilities across diverse domains. LCFO consists of long input
documents (5k words average length), each of which comes with three summaries
of different lengths (20%, 10%, and 5% of the input text), as well as
approximately 15 questions and answers (QA) related to the input content.
Notably, LCFO also provides alignments between specific QA pairs and
corresponding summaries in 7 domains. The primary motivation behind providing
summaries of different lengths is to establish a controllable framework for
generating long texts from shorter inputs, i.e. summary expansion. To establish
an evaluation metric framework for summarization and summary expansion, we
provide human evaluation scores for human-generated outputs, as well as results
from various state-of-the-art large language models (LLMs). GPT-4o-mini
achieves best human scores among automatic systems in both summarization and
summary expansion tasks (~ +10% and +20%, respectively). It even surpasses
human output quality in the case of short summaries (~ +7%). Overall automatic
metrics achieve low correlations with human evaluation scores (~ 0.4) but
moderate correlation on specific evaluation aspects such as fluency and
attribution (~ 0.6). The LCFO benchmark offers a standardized platform for
evaluating summarization and summary expansion performance, as well as
corresponding automatic metrics, thereby providing an important evaluation
framework to advance generative AI.

æè¦ï¼<paragraph>éç¯è«ææåºäºé·ææ¬èå½¢å¼è¼¸åºï¼LCFOï¼åºæºï¼ä¸åç¨æ¼è©ä¼°æ¼¸é²å¼æè¦åæè¦æ´åè½åçå¨æ°è©ä¼°æ¶æ§ï¼é©ç¨æ¼åç¨®é åãLCFO åå«é·è¼¸å¥æä»¶ï¼å¹³åé·åº¦ 5k å­ï¼ï¼æ¯åæä»¶é½éæä¸åä¸åé·åº¦çæè¦ï¼è¼¸å¥æå­ç 20%ã10% å 5%ï¼ï¼ä»¥åå¤§ç´ 15 åèè¼¸å¥å§å®¹ç¸éçåé¡åç­æ¡ (QA)ãå¼å¾æ³¨æçæ¯ï¼LCFO éæä¾äºç¹å® QA å°èå°ææè¦å¨ 7 åé åä¹éçæ¯å°ãæä¾ä¸åé·åº¦çæè¦çä¸»è¦åæ©æ¯å»ºç«ä¸åå¯æ§çæ¶æ§ï¼ç¨æ¼å¾è¼ç­çè¼¸å¥ç¢çè¼é·çæå­ï¼å³æè¦æ´åãçºäºå»ºç«æè¦åæè¦æ´åçè©ä¼°ææ¨æ¶æ§ï¼æåæä¾äºäººé¡å°äººé¡ç¢åºé²è¡è©ä¼°çåæ¸ï¼ä»¥åä¾èªåç¨®æåé²çå¤§èªè¨æ¨¡å (LLM) ççµæãGPT-4o-mini å¨æè¦åæè¦æ´åä»»åä¸­åç²å¾äºèªåç³»çµ±ä¸­æä½³çäººé¡è©åï¼åå¥çº ~ +10% å +20%ï¼ãå¨ç­æè¦çææ³ä¸ï¼å®çè³è¶è¶äºäººé¡çè¼¸åºåè³ªï¼~ +7%ï¼ãæ´é«èè¨ï¼èªåææ¨èäººé¡è©åä¹éçç¸éæ§è¼ä½ï¼~ 0.4ï¼ï¼ä½å¨ç¹å®è©ä¼°æ¹é¢ï¼ä¾å¦æµæ¢åº¦åæ­¸å ï¼çç¸éæ§è¼é«ï¼~ 0.6ï¼ãLCFO åºæºæä¾äºä¸åæ¨æºåçå¹³å°ï¼ç¨æ¼è©ä¼°æè¦åæè¦æ´åæè½ï¼ä»¥åå°æçèªåææ¨ï¼å¾èæä¾äºä¸åéè¦çè©ä¼°æ¶æ§ä¾æ¨é²çæå¼ AIã</paragraph>

##### **Discrete Subgraph Sampling for Interpretable Graph based Visual Question Answering**
2412.08263v1 by Pascal Tilli, Ngoc Thang Vu

Explainable artificial intelligence (XAI) aims to make machine learning
models more transparent. While many approaches focus on generating explanations
post-hoc, interpretable approaches, which generate the explanations
intrinsically alongside the predictions, are relatively rare. In this work, we
integrate different discrete subset sampling methods into a graph-based visual
question answering system to compare their effectiveness in generating
interpretable explanatory subgraphs intrinsically. We evaluate the methods on
the GQA dataset and show that the integrated methods effectively mitigate the
performance trade-off between interpretability and answer accuracy, while also
achieving strong co-occurrences between answer and question tokens.
Furthermore, we conduct a human evaluation to assess the interpretability of
the generated subgraphs using a comparative setting with the extended
Bradley-Terry model, showing that the answer and question token co-occurrence
metrics strongly correlate with human preferences. Our source code is publicly
available.

æè¦ï¼å¯è§£éäººå·¥æºæ§ (XAI) æ¨å¨ä½¿æ©å¨å­¸ç¿æ¨¡åæ´éæãåç®¡è¨±å¤æ¹æ³å°æ³¨æ¼äºå¾ç¢çè§£éï¼ä½å¯è§£éçæ¹æ³ï¼å¨é æ¸¬çåæå§å»ºç¢çè§£éï¼ç¸å°è¼å°è¦ãå¨æ­¤å·¥ä½ä¸­ï¼æåå°ä¸åçé¢æ£å­éæ½æ¨£æ¹æ³æ´åå°åºæ¼åå½¢çè¦è¦ºåç­ç³»çµ±ä¸­ï¼ä»¥æ¯è¼å®åå¨å§å»ºç¢çå¯è§£éçè§£éæ§å­åæ¹é¢çæææ§ãæåå¨ GQA è³æéä¸è©ä¼°éäºæ¹æ³ï¼ä¸¦è¡¨ææ´åçæ¹æ³æææ¸è¼äºå¯è§£éæ§èç­æ¡æºç¢ºæ§ä¹éçæè½åæ¨ï¼åæä¹å¯¦ç¾äºç­æ¡ååé¡æ¨è¨ä¹éçå¼·å±ç¾ãæ­¤å¤ï¼æåé²è¡äººé¡è©ä¼°ä»¥è©ä¼°æç¢çå­åçå¯è§£éæ§ï¼ä¸¦ä½¿ç¨æ´å±ç Bradley-Terry æ¨¡åé²è¡æ¯è¼è¨­å®ï¼çµæè¡¨æç­æ¡ååé¡æ¨è¨å±ç¾ææ¨èäººé¡åå¥½å¯åç¸éãæåçåå§ç¢¼å·²å¬éã

##### **FLIP: Flow-Centric Generative Planning for General-Purpose Manipulation Tasks**
2412.08261v1 by Chongkai Gao, Haozhuo Zhang, Zhixuan Xu, Zhehao Cai, Lin Shao

We aim to develop a model-based planning framework for world models that can
be scaled with increasing model and data budgets for general-purpose
manipulation tasks with only language and vision inputs. To this end, we
present FLow-centric generative Planning (FLIP), a model-based planning
algorithm on visual space that features three key modules: 1. a multi-modal
flow generation model as the general-purpose action proposal module; 2. a
flow-conditioned video generation model as the dynamics module; and 3. a
vision-language representation learning model as the value module. Given an
initial image and language instruction as the goal, FLIP can progressively
search for long-horizon flow and video plans that maximize the discounted
return to accomplish the task. FLIP is able to synthesize long-horizon plans
across objects, robots, and tasks with image flows as the general action
representation, and the dense flow information also provides rich guidance for
long-horizon video generation. In addition, the synthesized flow and video
plans can guide the training of low-level control policies for robot execution.
Experiments on diverse benchmarks demonstrate that FLIP can improve both the
success rates and quality of long-horizon video plan synthesis and has the
interactive world model property, opening up wider applications for future
works.

æè¦ï¼æä»¬æ¨å¨ä¸ºä¸çæ¨¡åå¼åä¸ä¸ªåºäºæ¨¡åçè§åæ¡æ¶ï¼è¯¥æ¡æ¶å¯ä»¥éçæ¨¡ååæ°æ®é¢ç®çå¢å èæ©å±ï¼ä»ä½¿ç¨è¯­è¨åè§è§è¾å¥å³å¯å®æéç¨æä½ä»»å¡ãä¸ºæ­¤ï¼æä»¬æåºäºä»¥æµä¸ºä¸­å¿ççæå¼è§å (FLIP)ï¼è¿æ¯ä¸ç§åºäºè§è§ç©ºé´çåºäºæ¨¡åçè§åç®æ³ï¼å·æä¸ä¸ªå³é®æ¨¡åï¼1. å¤æ¨¡ææµçææ¨¡åä½ä¸ºéç¨å¨ä½æè®®æ¨¡åï¼2. æµæ¡ä»¶è§é¢çææ¨¡åä½ä¸ºå¨åå­¦æ¨¡åï¼3. è§è§è¯­è¨è¡¨ç¤ºå­¦ä¹ æ¨¡åä½ä¸ºä»·å¼æ¨¡åãç»å®ä¸ä¸ªåå§å¾ååè¯­è¨æä»¤ä½ä¸ºç®æ ï¼FLIP å¯ä»¥éæ­¥æç´¢é¿è§éæµåè§é¢è®¡åï¼ä»¥æå¤§åææ£åæ¥ä»¥å®æä»»å¡ãFLIP è½å¤è·¨å¯¹è±¡ãæºå¨äººåä»»å¡ç»¼åé¿è§éè®¡åï¼ä»¥å¾åæµä½ä¸ºéç¨å¨ä½è¡¨ç¤ºï¼å¹¶ä¸å¯éæµä¿¡æ¯è¿ä¸ºé¿è§éè§é¢çææä¾äºä¸°å¯çæå¯¼ãæ­¤å¤ï¼åæçæµåè§é¢è®¡åå¯ä»¥æå¯¼ä½çº§æ§å¶ç­ç¥çè®­ç»ä»¥è¿è¡æºå¨äººæ§è¡ãå¨ä¸ååºåä¸çå®éªè¡¨æï¼FLIP å¯ä»¥æé«é¿è§éè§é¢è®¡ååæçæåçåè´¨éï¼å¹¶ä¸å·æäº¤äºå¼ä¸çæ¨¡åå±æ§ï¼ä¸ºæªæ¥çå·¥ä½å¼è¾äºæ´å¹¿æ³çåºç¨ã

##### **Large Language Models for Scholarly Ontology Generation: An Extensive Analysis in the Engineering Field**
2412.08258v1 by Tanay Aggarwal, Angelo Salatino, Francesco Osborne, Enrico Motta

Ontologies of research topics are crucial for structuring scientific
knowledge, enabling scientists to navigate vast amounts of research, and
forming the backbone of intelligent systems such as search engines and
recommendation systems. However, manual creation of these ontologies is
expensive, slow, and often results in outdated and overly general
representations. As a solution, researchers have been investigating ways to
automate or semi-automate the process of generating these ontologies. This
paper offers a comprehensive analysis of the ability of large language models
(LLMs) to identify semantic relationships between different research topics,
which is a critical step in the development of such ontologies. To this end, we
developed a gold standard based on the IEEE Thesaurus to evaluate the task of
identifying four types of relationships between pairs of topics: broader,
narrower, same-as, and other. Our study evaluates the performance of seventeen
LLMs, which differ in scale, accessibility (open vs. proprietary), and model
type (full vs. quantised), while also assessing four zero-shot reasoning
strategies. Several models have achieved outstanding results, including
Mixtral-8x7B, Dolphin-Mistral-7B, and Claude 3 Sonnet, with F1-scores of 0.847,
0.920, and 0.967, respectively. Furthermore, our findings demonstrate that
smaller, quantised models, when optimised through prompt engineering, can
deliver performance comparable to much larger proprietary models, while
requiring significantly fewer computational resources.

æè¦ï¼<paragraph>ç ç©¶ä¸»é¡çæ¬ä½è«å°æ¼çµæ§åç§å­¸ç¥è­è³ééè¦ï¼è®ç§å­¸å®¶è½å¤ çè¦½å¤§éçç ç©¶ï¼ä¸¦å½¢ææå°å¼æåæ¨è¦ç³»çµ±ç­æºæ§ç³»çµ±çéª¨å¹¹ãç¶èï¼æåå»ºç«éäºæ¬ä½è«çææ¬é«æãç·©æ¢ï¼èä¸ç¶å¸¸å°è´éæä¸éæ¼æ¦æ¬çè¡¨ç¤ºãä½çºè§£æ±ºæ¹æ¡ï¼ç ç©¶äººå¡ä¸ç´å¨ç ç©¶èªååæåèªååéäºæ¬ä½è«çæéç¨çæ¹æ³ãæ¬æå¨é¢åæäºå¤§åèªè¨æ¨¡å (LLM) è­å¥ä¸åç ç©¶ä¸»é¡ä¹éèªç¾©éä¿çè½åï¼éæ¯éç¼æ­¤é¡æ¬ä½è«çééµæ­¥é©ãçºæ­¤ï¼æåæ ¹æ IEEE è©å½è¡¨éç¼äºä¸åé»éæ¨æºï¼ç¨æ¼è©ä¼°è­å¥ä¸»é¡å°ä¹éåç¨®é¡åéä¿çä»»åï¼è¼å»£æ³ãè¼ç¹çªãç¸åï¼ä»¥åå¶ä»ãæåçç ç©¶è©ä¼°äºåä¸å LLM çæè½ï¼éäº LLM å¨è¦æ¨¡ãå¯åæ§ï¼éæ¾èå°æï¼åæ¨¡åé¡åï¼å®æ´èéåï¼ä¸ææä¸åï¼åæä¹è©ä¼°äºåç¨®é¶æ¬¡æ¹æ¨çç­ç¥ãå¹¾åæ¨¡ååå¾äºååºçææï¼åæ¬ Mixtral-8x7BãDolphin-Mistral-7B å Claude 3 Sonnetï¼F1 åæ¸åå¥çº 0.847ã0.920 å 0.967ãæ­¤å¤ï¼æåçç ç©¶çµæè¡¨æï¼è¼å°ãéåçæ¨¡åå¨ééæç¤ºå·¥ç¨é²è¡æä½³åæï¼å¯ä»¥æä¾èè¦æ¨¡æ´å¤§çå°ææ¨¡åç¸ç¶çæè½ï¼åæéè¦é¡¯èæ´å°çéç®è³æºã</paragraph>

##### **Accurate Medical Named Entity Recognition Through Specialized NLP Models**
2412.08255v1 by Jiacheng Hu, Runyuan Bao, Yang Lin, Hanchao Zhang, Yanlin Xiang

This study evaluated the effect of BioBERT in medical text processing for the
task of medical named entity recognition. Through comparative experiments with
models such as BERT, ClinicalBERT, SciBERT, and BlueBERT, the results showed
that BioBERT achieved the best performance in both precision and F1 score,
verifying its applicability and superiority in the medical field. BioBERT
enhances its ability to understand professional terms and complex medical texts
through pre-training on biomedical data, providing a powerful tool for medical
information extraction and clinical decision support. The study also explored
the privacy and compliance challenges of BioBERT when processing medical data,
and proposed future research directions for combining other medical-specific
models to improve generalization and robustness. With the development of deep
learning technology, the potential of BioBERT in application fields such as
intelligent medicine, personalized treatment, and disease prediction will be
further expanded. Future research can focus on the real-time and
interpretability of the model to promote its widespread application in the
medical field.

æè¦ï¼æ¬ç ç©¶è©ä¼°äº BioBERT å¨é«çææ¬èçä¸­å°é«çå½åå¯¦é«è­å¥ä»»åçå½±é¿ãééè BERTãClinicalBERTãSciBERT å BlueBERT ç­æ¨¡åçæ¯è¼å¯¦é©ï¼çµæè¡¨æ BioBERT å¨ç²¾ç¢ºåº¦å F1 åæ¸æ¹é¢ååå¾äºæä½³è¡¨ç¾ï¼é©è­äºå¶å¨é«çé åçé©ç¨æ§ååªè¶æ§ãBioBERT ééå°çç©é«å­¸æ¸æçé è¨ç·´ï¼å¢å¼·äºå¶çè§£å°æ¥­è¡èªåè¤éé«çææ¬çè½åï¼çºé«çä¿¡æ¯æååè¨åºæ±ºç­æ¯ææä¾äºå¼·æåçå·¥å·ãè©²ç ç©¶éæ¢è¨äº BioBERT å¨èçé«çæ¸ææé¢è¨çé±ç§ååè¦ææ°ï¼ä¸¦æåºäºçµåå¶ä»ç¹å®æ¼é«ççæ¨¡åä»¥æé«æ³åæ§åé­¯æ£æ§çæªä¾ç ç©¶æ¹åãé¨èæ·±åº¦å­¸ç¿æè¡çç¼å±ï¼BioBERT å¨æºè½é«çãåæ§åæ²»çåç¾çé æ¸¬ç­æç¨é åçæ½åå°é²ä¸æ­¥æ´å¤§ãæªä¾çç ç©¶å¯ä»¥éæ³¨æ¨¡åçå¯¦ææ§åå¯è§£éæ§ï¼ä»¥ä¿é²å¶å¨é«çé åçå»£æ³æç¨ã

##### **TouchTTS: An Embarrassingly Simple TTS Framework that Everyone Can Touch**
2412.08237v1 by Xingchen Song, Mengtao Xing, Changwei Ma, Shengqiang Li, Di Wu, Binbin Zhang, Fuping Pan, Dinghao Zhou, Yuekai Zhang, Shun Lei, Zhendong Peng, Zhiyong Wu

It is well known that LLM-based systems are data-hungry. Recent LLM-based TTS
works typically employ complex data processing pipelines to obtain high-quality
training data. These sophisticated pipelines require excellent models at each
stage (e.g., speech denoising, speech enhancement, speaker diarization, and
punctuation models), which themselves demand high-quality training data and are
rarely open-sourced. Even with state-of-the-art models, issues persist, such as
incomplete background noise removal and misalignment between punctuation and
actual speech pauses. Moreover, the stringent filtering strategies often retain
only 10-30\% of the original data, significantly impeding data scaling efforts.
In this work, we leverage a noise-robust audio tokenizer (S3Tokenizer) to
design a simplified yet effective TTS data processing pipeline that maintains
data quality while substantially reducing data acquisition costs, achieving a
data retention rate of over 50\%. Beyond data scaling challenges, LLM-based TTS
systems also incur higher deployment costs compared to conventional approaches.
Current systems typically use LLMs solely for text-to-token generation, while
requiring separate models (e.g., flow matching models) for token-to-waveform
generation, which cannot be directly executed by LLM inference engines, further
complicating deployment. To address these challenges, we eliminate redundant
modules in both LLM and flow components, replacing the flow model backbone with
an LLM architecture. Building upon this simplified flow backbone, we propose a
unified architecture for both streaming and non-streaming inference,
significantly reducing deployment costs. Finally, we explore the feasibility of
unifying TTS and ASR tasks using the same data for training, thanks to the
simplified pipeline and the S3Tokenizer that reduces the quality requirements
for TTS training data.

æè¦ï¼ç¾æå¨ç¥ï¼åºæ¼ LLM çç³»çµ±éå¸¸èè³æãæè¿åºæ¼ LLM ç TTS ä½åéå¸¸æ¡ç¨è¤éçè³æèçç®¡ç·ï¼ä»¥åå¾é«åè³ªçè¨ç·´è³æãéäºè¤éçç®¡ç·å¨æ¯åéæ®µé½éè¦åªç§çæ¨¡åï¼ä¾å¦èªé³å»éè¨ãèªé³å¢å¼·ãèªªè©±èæ¥è¨ååæ¨é»ç¬¦èæ¨¡åï¼ï¼èéäºæ¨¡åæ¬èº«éè¦é«åè³ªçè¨ç·´è³æï¼èä¸å¾å°éæºãå³ä½¿ä½¿ç¨æåé²çæ¨¡åï¼åé¡ä»ç¶å­å¨ï¼ä¾å¦èæ¯éè¨ç§»é¤ä¸å®å¨ï¼ä»¥åæ¨é»ç¬¦èåå¯¦éèªé³åé ä¹éçå°é½é¯èª¤ãæ­¤å¤ï¼å´æ ¼çéæ¿¾ç­ç¥éå¸¸åªä¿çåå§è³æç 10-30%ï¼éæé¡¯èé»ç¤è³ææ´åå·¥ä½ãå¨éé å·¥ä½ä¸­ï¼æåå©ç¨æéè¨é³è¨åè©å¨ (S3Tokenizer) ä¾è¨­è¨ä¸åç°¡åä½ææç TTS è³æèçç®¡ç·ï¼å¨å¤§å¹éä½è³æåå¾ææ¬çåæï¼ç¶­æè³æåè³ªï¼éæè¶é 50% çè³æä¿ççãé¤äºè³ææ´åçææ°ä¹å¤ï¼èå³çµ±æ¹æ³ç¸æ¯ï¼åºæ¼ LLM ç TTS ç³»çµ±ä¹ç¢çæ´é«çé¨ç½²ææ¬ãç®åçç³»çµ±éå¸¸åªä½¿ç¨ LLM ä¾é²è¡æå­å°ä»£ç¢¼çç¢çï¼åæéè¦ä¸åçæ¨¡åï¼ä¾å¦æµç¨å¹éæ¨¡åï¼ä¾é²è¡ä»£ç¢¼å°æ³¢å½¢çç¢çï¼è LLM æ¨è«å¼æç¡æ³ç´æ¥å·è¡éäºæ¨¡åï¼éé²ä¸æ­¥è¤éåäºé¨ç½²ãçºäºæå°éäºææ°ï¼æåæ¶é¤äº LLM åæµç¨åä»¶ä¸­çéè¤æ¨¡çµï¼ä¸¦ä»¥ LLM æ¶æ§åä»£æµç¨æ¨¡åä¸»å¹¹ãå»ºæ§å¨éåç°¡åçæµç¨ä¸»å¹¹ä¹ä¸ï¼æåæåºäºä¸åçµ±ä¸çæ¶æ§ï¼ç¨æ¼ä¸²æµåéä¸²æµæ¨è«ï¼å¤§å¹éä½é¨ç½²ææ¬ãæå¾ï¼ç±æ¼ç°¡åçç®¡ç·å S3Tokenizer éä½äº TTS è¨ç·´è³æçåè³ªéæ±ï¼æåæ¢è¨äºä½¿ç¨ç¸åçè³æä¾è¨ç·´ TTS å ASR ä»»åçå¯è¡æ§ã

##### **Generate Any Scene: Evaluating and Improving Text-to-Vision Generation with Scene Graph Programming**
2412.08221v1 by Ziqi Gao, Weikai Huang, Jieyu Zhang, Aniruddha Kembhavi, Ranjay Krishna

DALL-E and Sora have gained attention by producing implausible images, such
as "astronauts riding a horse in space." Despite the proliferation of
text-to-vision models that have inundated the internet with synthetic visuals,
from images to 3D assets, current benchmarks predominantly evaluate these
models on real-world scenes paired with captions. We introduce Generate Any
Scene, a framework that systematically enumerates scene graphs representing a
vast array of visual scenes, spanning realistic to imaginative compositions.
Generate Any Scene leverages 'scene graph programming', a method for
dynamically constructing scene graphs of varying complexity from a structured
taxonomy of visual elements. This taxonomy includes numerous objects,
attributes, and relations, enabling the synthesis of an almost infinite variety
of scene graphs. Using these structured representations, Generate Any Scene
translates each scene graph into a caption, enabling scalable evaluation of
text-to-vision models through standard metrics. We conduct extensive
evaluations across multiple text-to-image, text-to-video, and text-to-3D
models, presenting key findings on model performance. We find that DiT-backbone
text-to-image models align more closely with input captions than UNet-backbone
models. Text-to-video models struggle with balancing dynamics and consistency,
while both text-to-video and text-to-3D models show notable gaps in human
preference alignment. We demonstrate the effectiveness of Generate Any Scene by
conducting three practical applications leveraging captions generated by
Generate Any Scene: 1) a self-improving framework where models iteratively
enhance their performance using generated data, 2) a distillation process to
transfer specific strengths from proprietary models to open-source
counterparts, and 3) improvements in content moderation by identifying and
generating challenging synthetic data.

æè¦ï¼DALL-E å Sora å ç¢çä»¤äººé£ä»¥ç½®ä¿¡çå½±åèååéæ³¨ï¼ä¾å¦ãå¤ªç©ºé¨é¦¬çå¤ªç©ºäººããåç®¡æå­è½è¦è¦ºæ¨¡åå¤§éåºç¾ï¼ä¸¦ä»¥åæè¦è¦ºææåæ¥ç¶²è·¯ï¼å¾å½±åå° 3D ç´ æï¼ç®åçåºæºä¸»è¦å¨éææå­èªªæççå¯¦å ´æ¯ä¸­è©ä¼°éäºæ¨¡åãæåæ¨åº Generate Any Sceneï¼ä¸åç³»çµ±æ§åèå ´æ¯åçæ¶æ§ï¼è¡¨ç¤ºåç¨®è¦è¦ºå ´æ¯ï¼æ¶µèå¾å¯«å¯¦å°å¯ææ³ååçæ§åãGenerate Any Scene æ´»ç¨ãå ´æ¯åç¨å¼è¨­è¨ãï¼éæ¯ä¸ç¨®å¾è¦è¦ºåç´ ççµæ§ååé¡æ³ä¸­åæå»ºæ§ä¸åè¤éåº¦å ´æ¯åçæ¹æ³ãæ­¤åé¡æ³åå«è¨±å¤ç©ä»¶ãå±¬æ§åéä¿ï¼è½åæå¹¾ä¹ç¡éå¤è®çå ´æ¯åãGenerate Any Scene ä½¿ç¨éäºçµæ§åè¡¨ç¤ºï¼å°æ¯åå ´æ¯åè½æçºæå­èªªæï¼è½ééæ¨æºææ¨é²è¡æå­è½è¦è¦ºæ¨¡åçå¯æ´åè©ä¼°ãæåéå°å¤åæå­è½å½±åãæå­è½å½±çåæå­è½ 3D æ¨¡åé²è¡å»£æ³è©ä¼°ï¼ä¸¦æåºæ¨¡åæè½çä¸»è¦ç¼ç¾ãæåç¼ç¾ï¼DiT ä¸»å¹¹çæå­è½å½±åæ¨¡åæ¯ UNet ä¸»å¹¹æ¨¡åæ´è²¼è¿è¼¸å¥æå­èªªæãæå­è½å½±çæ¨¡åå¨å¹³è¡¡åæåä¸è´æ§æ¹é¢æå°é£ï¼èæå­è½å½±çåæå­è½ 3D æ¨¡åå¨äººé¡åå¥½å°é½æ¹é¢é½ææé¡¯çå·®è·ãæåééé²è¡ä¸é å¯¦ç¨æç¨ä¾å±ç¤º Generate Any Scene çæææ§ï¼éäºæç¨å©ç¨ Generate Any Scene çæçæå­èªªæï¼1) ä¸åèªææåçæ¶æ§ï¼å¶ä¸­æ¨¡åæä½¿ç¨ç¢ççè³æåè¦æåå¶æè½ï¼2) ä¸åèåç¨åºï¼å°å°ææ¨¡åçç¹å®åªé»è½ç§»å°éæºå°ææ¨¡åï¼ä»¥å 3) ééè­å¥åç¢çå·æææ°æ§çåæè³æä¾æ¹åå§å®¹å¯©æ ¸ã

##### **DocSum: Domain-Adaptive Pre-training for Document Abstractive Summarization**
2412.08196v1 by Phan Phuong Mai Chau, Souhail Bakkali, Antoine Doucet

Abstractive summarization has made significant strides in condensing and
rephrasing large volumes of text into coherent summaries. However, summarizing
administrative documents presents unique challenges due to domain-specific
terminology, OCR-generated errors, and the scarcity of annotated datasets for
model fine-tuning. Existing models often struggle to adapt to the intricate
structure and specialized content of such documents. To address these
limitations, we introduce DocSum, a domain-adaptive abstractive summarization
framework tailored for administrative documents. Leveraging pre-training on
OCR-transcribed text and fine-tuning with an innovative integration of
question-answer pairs, DocSum enhances summary accuracy and relevance. This
approach tackles the complexities inherent in administrative content, ensuring
outputs that align with real-world business needs. To evaluate its
capabilities, we define a novel downstream task setting-Document Abstractive
Summarization-which reflects the practical requirements of business and
organizational settings. Comprehensive experiments demonstrate DocSum's
effectiveness in producing high-quality summaries, showcasing its potential to
improve decision-making and operational workflows across the public and private
sectors.

æè¦ï¼æè¦å¼æè¦å¨å°å¤§éæå­æ¿ç¸®ä¸¦æ¹å¯«çºé£è²«çæè¦æ¹é¢åå¾éå¤§é²å±ãç¶èï¼ç±æ¼ç¹å®é åçè¡èªãOCR çæçé¯èª¤ï¼ä»¥åç¨æ¼æ¨¡åå¾®èª¿çè¨»è§£è³æéçç¨ç¼ºæ§ï¼æè¦ç®¡çæä»¶æå¸¶ä¾ç¨ç¹çææ°ãç¾æçæ¨¡åéå¸¸é£ä»¥é©ææ­¤é¡æä»¶çè¤éçµæ§åå°æ¥­å§å®¹ãçºäºè§£æ±ºéäºéå¶ï¼æåå¼å¥äº DocSumï¼éæ¯ä¸åéå°ç®¡çæä»¶éèº«æé çé åé©æåæè¦å¼æè¦æ¶æ§ãå©ç¨ OCR è½éææ¬çé è¨ç·´ï¼ä¸¦èåé¡ç­æ¡å°çåµæ°æ´åé²è¡å¾®èª¿ï¼DocSum æé«äºæè¦çæºç¢ºæ§åç¸éæ§ãéç¨®æ¹æ³è§£æ±ºäºç®¡çå§å®¹ä¸­åºæçè¤éæ§ï¼ç¢ºä¿è¼¸åºèç¾å¯¦ä¸ççæ¥­åéæ±ä¿æä¸è´ãçºäºè©ä¼°å¶è½åï¼æåå®ç¾©äºä¸åæ°çä¸æ¸¸ä»»åè¨­å®ââæä»¶æè¦å¼æè¦ââå®åæ äºåæ¥­åçµç¹ç°å¢çå¯¦éè¦æ±ãå¨é¢çå¯¦é©è­æäº DocSum å¨ç¢çé«åè³ªæè¦æ¹é¢çæææ§ï¼å±ç¤ºäºå¶å¨å¬å±åç§çé¨éæ¹åæ±ºç­å¶å®åéçå·¥ä½æµç¨çæ½åã

##### **Semantic Scene Completion Based 3D Traversability Estimation for Off-Road Terrains**
2412.08195v1 by Zitong Chen, Chao Sun, Shida Nie, Chen Min, Changjiu Ning, Haoyu Li, Bo Wang

Off-road environments present significant challenges for autonomous ground
vehicles due to the absence of structured roads and the presence of complex
obstacles, such as uneven terrain, vegetation, and occlusions. Traditional
perception algorithms, designed primarily for structured environments, often
fail under these conditions, leading to inaccurate traversability estimations.
In this paper, ORDformer, a novel multimodal method that combines LiDAR point
clouds with monocular images, is proposed to generate dense traversable
occupancy predictions from a forward-facing perspective. By integrating
multimodal data, environmental feature extraction is enhanced, which is crucial
for accurate occupancy estimation in complex terrains. Furthermore, RELLIS-OCC,
a dataset with 3D traversable occupancy annotations, is introduced,
incorporating geometric features such as step height, slope, and unevenness.
Through a comprehensive analysis of vehicle obstacle-crossing conditions and
the incorporation of vehicle body structure constraints, four traversability
cost labels are generated: lethal, medium-cost, low-cost, and free.
Experimental results demonstrate that ORDformer outperforms existing approaches
in 3D traversable area recognition, particularly in off-road environments with
irregular geometries and partial occlusions. Specifically, ORDformer achieves
over a 20\% improvement in scene completion IoU compared to other models. The
proposed framework is scalable and adaptable to various vehicle platforms,
allowing for adjustments to occupancy grid parameters and the integration of
advanced dynamic models for traversability cost estimation.

æè¦ï¼è¶éç°å¢ç±æ¼ç¼ºä¹çµæ§åçéè·¯ï¼ä¸å­å¨ä¸å¹³å¦çå°å½¢ãæ¤è¢«åé®æç©ç­è¤ééç¤ï¼å æ­¤å°èªä¸»å°é¢è»è¼æ§æéå¤§ææ°ãå³çµ±çæç¥æ¼ç®æ³ä¸»è¦è¨­è¨ç¨æ¼çµæ§åçç°å¢ï¼å¨éäºæ¢ä»¶ä¸éå¸¸æå¤±æï¼å°è´ç¡æ³ç²¾ç¢ºä¼°è¨å¯éè¡æ§ãå¨æ¬æä¸­ï¼æåºäºä¸ç¨®åçº ORDformer çæ°å¤æ¨¡å¼æ¹æ³ï¼å®å° LiDAR é»é²èå®ç®å½±åçµåèµ·ä¾ï¼å¾æåçè¦è§ç¢çå¯éçå¯éè¡ä½ç¨é æ¸¬ãééæ´åå¤æ¨¡å¼è³æï¼å¢å¼·äºç°å¢ç¹å¾µèåï¼éå°æ¼å¨è¤éå°å½¢ä¸­ç²¾ç¢ºä¼°è¨ä½ç¨çè³ééè¦ãæ­¤å¤ï¼éå¼å¥äº RELLIS-OCCï¼éæ¯ä¸åå·æ 3D å¯éè¡ä½ç¨æ¨è¨»çè³æéï¼å¶ä¸­åå«éæ¢¯é«åº¦ãå¡åº¦åä¸å¹³æ´åº¦ç­å¹¾ä½ç¹å¾µãééå°è»è¼éç¤ç©ç©¿è¶æ¢ä»¶é²è¡å¨é¢åæï¼ä¸¦çµåè»èº«çµæ§ç´æï¼çæäºååå¯éè¡ææ¬æ¨ç±¤ï¼è´å½ãä¸­ææ¬ãä½ææ¬åèªç±ãå¯¦é©çµæè¡¨æï¼ORDformer å¨ 3D å¯éè¡ååè­å¥æ¹é¢åªæ¼ç¾ææ¹æ³ï¼ç¹å¥æ¯å¨å·æä¸è¦åå¹¾ä½å½¢çåé¨åé®æç©çè¶éç°å¢ä¸­ãå·é«èè¨ï¼èå¶ä»æ¨¡åç¸æ¯ï¼ORDformer å¨å ´æ¯å®æ IoU æ¹é¢æé«äº 20% ä»¥ä¸ãææåºçæ¡æ¶å·æå¯æ´åæ§åå¯é©ææ§ï¼é©ç¨æ¼åç¨®è»è¼å¹³å°ï¼åè¨±èª¿æ´ä½ç¨çç¶²æ ¼åæ¸ï¼ä¸¦æ´ååé²çåææ¨¡åä»¥ä¼°è¨å¯éè¡ææ¬ã

##### **From communities to interpretable network and word embedding: an unified approach**
2412.08187v1 by Thibault Prouteau, Nicolas DuguÃ©, Simon Guillot

Modelling information from complex systems such as humans social interaction
or words co-occurrences in our languages can help to understand how these
systems are organized and function. Such systems can be modelled by networks,
and network theory provides a useful set of methods to analyze them. Among
these methods, graph embedding is a powerful tool to summarize the interactions
and topology of a network in a vectorized feature space. When used in input of
machine learning algorithms, embedding vectors help with common graph problems
such as link prediction, graph matching, etc. Word embedding has the goal of
representing the sense of words, extracting it from large text corpora. Despite
differences in the structure of information in input of embedding algorithms,
many graph embedding approaches are adapted and inspired from methods in NLP.
Limits of these methods are observed in both domains. Most of these methods
require long and resource greedy training. Another downside to most methods is
that they are black-box, from which understanding how the information is
structured is rather complex. Interpretability of a model allows understanding
how the vector space is structured without the need for external information,
and thus can be audited more easily. With both these limitations in mind, we
propose a novel framework to efficiently embed network vertices in an
interpretable vector space. Our Lower Dimension Bipartite Framework (LDBGF)
leverages the bipartite projection of a network using cliques to reduce
dimensionality. Along with LDBGF, we introduce two implementations of this
framework that rely on communities instead of cliques: SINr-NR and SINr-MF. We
show that SINr-MF can perform well on classical graphs and SINr-NR can produce
high-quality graph and word embeddings that are interpretable and stable across
runs.

æè¦ï¼<paragraph>ééæ¨¡æ¬äººé¡ç¤¾äº¤äºåæèªè¨ä¸­è©å½å±ç¾ç­è¤éç³»çµ±ä¸­çè³è¨ï¼æå©æ¼äºè§£éäºç³»çµ±ççµç¹åéä½æ¹å¼ãéäºç³»çµ±å¯ä»¥ç¨ç¶²è·¯ä¾å»ºæ¨¡ï¼èç¶²è·¯çè«æä¾äºæç¨çæ¹æ³éä¾åæå®åãå¨éäºæ¹æ³ä¸­ï¼åå½¢åµå¥æ¯ä¸ç¨®å¼·å¤§çå·¥å·ï¼å¯ç¨æ¼å¨åéåç¹å¾µç©ºéä¸­ç¸½çµç¶²è·¯çäº¤äºåææ²ãç¶ç¨æ¼æ©å¨å­¸ç¿æ¼ç®æ³çè¼¸å¥æï¼åµå¥åéæå©æ¼å¸¸è¦çåå½¢åé¡ï¼ä¾å¦é£çµé æ¸¬ãåå½¢éå°ç­ãè©åµå¥çç®æ¨æ¯è¡¨ç¤ºè©å½çæç¾©ï¼å¾å¤§åæå­èªæåº«ä¸­èåå®ãåç®¡åµå¥æ¼ç®æ³è¼¸å¥è³è¨ççµæ§ä¸åï¼ä½è¨±å¤åå½¢åµå¥æ¹æ³é½æ¯æ ¹æèªç¶èªè¨èçä¸­çæ¹æ³æ¹ç·¨ååç¼çãå¨å©åé åä¸­é½è§å¯å°éäºæ¹æ³çéå¶ãå¤§å¤æ¸éäºæ¹æ³éè¦æ¼«é·ä¸èè²»è³æºçè¨ç·´ãå¤§å¤æ¸æ¹æ³çå¦ä¸åç¼ºé»æ¯å®åæ¯é»çå­ï¼å¾ä¸­çè§£è³è¨å¦ä½è¢«çµæ§åç¸ç¶è¤éãæ¨¡åçå¯è§£éæ§åè¨±å¨ä¸éè¦å¤é¨è³è¨çææ³ä¸äºè§£åéç©ºéæ¯å¦ä½è¢«çµæ§åçï¼å æ­¤å¯ä»¥æ´å®¹æå°é²è¡ç¨½æ ¸ãç¢è¨éå©åéå¶ï¼æåæåºäºä¸åæ°ç©çæ¡æ¶ï¼ä»¥ææçæ¹å¼å°ç¶²è·¯é é»åµå¥å¯è§£éçåéç©ºéä¸­ãæåçä½ç¶­äºé¨åæ¡æ¶ (LDBGF) å©ç¨ç¶²è·¯çäºé¨åæå½±ä½¿ç¨æ´¾ç³»ä¾éä½ç¶­åº¦ãé¤äº LDBGF ä¹å¤ï¼æåéä»ç´¹äºå©åä¾è³´ç¤¾ç¾¤èéæ´¾ç³»çæ­¤æ¡æ¶å¯¦ä½ï¼SINr-NR å SINr-MFãæåå±ç¤ºäº SINr-MF å¨ç¶å¸åå½¢ä¸å¯ä»¥å·è¡è¯å¥½ï¼è SINr-NR å¯ä»¥ç¢çé«åè³ªçåå½¢åè©åµå¥ï¼éäºåµå¥å¨åæ¬¡å·è¡ä¸­é½æ¯å¯è§£éä¸ç©©å®çã</paragraph>

##### **Auto-Generating Earnings Report Analysis via a Financial-Augmented LLM**
2412.08179v1 by Van-Duc Le

Financial analysis heavily relies on the evaluation of earnings reports to
gain insights into company performance. Traditional generation of these reports
requires extensive financial expertise and is time-consuming. With the
impressive progress in Large Language Models (LLMs), a wide variety of
financially focused LLMs has emerged, addressing tasks like sentiment analysis
and entity recognition in the financial domain. This paper presents a novel
challenge: developing an LLM specifically for automating the generation of
earnings reports analysis. Our methodology involves an in-depth analysis of
existing earnings reports followed by a unique approach to fine-tune an LLM for
this purpose. This approach combines retrieval augmentation and the generation
of instruction-based data, specifically tailored for the financial sector, to
enhance the LLM's performance. With extensive financial documents, we construct
financial instruction data, enabling the refined adaptation of our LLM to
financial contexts. Preliminary results indicate that our augmented LLM
outperforms general open-source models and rivals commercial counterparts like
GPT-3.5 in financial applications. Our research paves the way for streamlined
and insightful automation in financial report generation, marking a significant
stride in the field of financial analysis.

æè¦ï¼è²¡ååæé«åº¦ä¾è³´å°æ¶çå ±åçè©ä¼°ï¼ä»¥æ·±å¥äºè§£å¬å¸ç¸¾æãå³çµ±ä¸ï¼ç¢çéäºå ±åéè¦å»£æ³çè²¡åå°æ¥­ç¥è­ï¼èä¸éå¸¸èæãé¨èå¤§åèªè¨æ¨¡å (LLM) çé©äººé²å±ï¼å·²ç¶åºç¾äºåç¨®ä»¥è²¡åçºéé»ç LLMï¼ç¨æ¼è§£æ±ºè²¡åé åçæç·åæåå¯¦é«è­å¥ç­ä»»åãæ¬ææåºäºæ°çææ°ï¼éç¼ä¸å LLMï¼å°éç¨æ¼èªååæ¶çå ±ååæçç¢çãæåçåæ³åæ¬å°ç¾ææ¶çå ±åé²è¡æ·±å¥åæï¼ç¶å¾æ¡ç¨ç¨ç¹çæ¹æ³å¾®èª¿ LLM ä»¥éå°æ­¤ç®çãæ­¤æ¹æ³çµåæª¢ç´¢æ´ååçæåºæ¼æä»¤çè³æï¼å°ééå°éèé¨éé²è¡èª¿æ´ï¼ä»¥å¢å¼· LLM çæè½ãå©ç¨å»£æ³çè²¡åæä»¶ï¼æåå»ºæ§äºè²¡åæä»¤è³æï¼è®æåç LLM è½å¤ ç²¾ç¢ºå°é©æè²¡åèæ¯ãåæ­¥çµæè¡¨æï¼æåæ´åç LLM åªæ¼ä¸è¬éæºæ¨¡åï¼ä¸¦ä¸å¨è²¡åæç¨ä¸­è GPT-3.5 ç­åæ¥­å°æä¸ç¸ä¸ä¸ãæåçç ç©¶çºè²¡åå ±åç¢ççç°¡ååæ·±å¥èªååéªå¹³äºéè·¯ï¼æ¨èªèè²¡ååæé åçéå¤§é²å±ã

##### **Can Graph Neural Networks Learn Language with Extremely Weak Text Supervision?**
2412.08174v1 by Zihao Li, Lecheng Zheng, Bowen Jin, Dongqi Fu, Baoyu Jing, Yikun Ban, Jingrui He, Jiawei Han

While great success has been achieved in building vision models with
Contrastive Language-Image Pre-training (CLIP) over Internet-scale image-text
pairs, building transferable Graph Neural Networks (GNNs) with CLIP pipeline is
challenging because of three fundamental issues: the scarcity of labeled data
and text supervision, different levels of downstream tasks, and the conceptual
gaps between domains. In this work, to address these issues, we leverage
multi-modal prompt learning to effectively adapt pre-trained GNN to downstream
tasks and data, given only a few semantically labeled samples, each with
extremely weak text supervision. Our new paradigm embeds the graphs directly in
the same space as the Large Language Models (LLMs) by learning both graph
prompts and text prompts simultaneously. To accomplish this, we improve
state-of-the-art graph prompt method, and then propose the first graph-language
multi-modal prompt learning approach for exploiting the knowledge in
pre-trained models. Notably, due to the insufficient supervision for
fine-tuning, in our paradigm, the pre-trained GNN and the LLM are kept frozen,
so the learnable parameters are much fewer than fine-tuning any pre-trained
model. Through extensive experiments on real-world datasets, we demonstrate the
superior performance of our paradigm in few-shot, multi-task-level, and
cross-domain settings. Moreover, we build the first CLIP-style zero-shot
classification prototype that can generalize GNNs to unseen classes with
extremely weak text supervision.

æè¦ï¼<paragraph>åç®¡å©ç¨ç¶²éç¶²è·¯è¦æ¨¡çååæå­éå°ï¼å¨å»ºç«å·æå°æ¯èªè¨å½±åé è¨ç·´ (CLIP) çè¦è¦ºæ¨¡åæ¹é¢å·²åå¾å·¨å¤§çæåï¼ä½ç±æ¼ä¸ååºæ¬åé¡ï¼ä½¿ç¨ CLIP ç®¡ç·å»ºç«å¯è½ç§»çåç¥ç¶ç¶²è·¯ (GNN) å·æææ°æ§ï¼æ¨è¨è³æåæå­ç£ç£çç¨ç¼ºæ§ãä¸åå±¤ç´çä¸æ¸¸ä»»åï¼ä»¥åé åä¹éçæ¦å¿µå·®è·ãçºäºè§£æ±ºéäºåé¡ï¼æåå¨éåå·¥ä½ä¸­å©ç¨å¤æ¨¡å¼æç¤ºå­¸ç¿ï¼å¨åçµ¦äºå°æ¸èªç¾©æ¨è¨ç¯ä¾ï¼æ¯åç¯ä¾é½å·ææ¥µå¼±çæå­ç£ç£ï¼çææ³ä¸ï¼ææå°èª¿æ´é è¨ç·´ç GNN ä»¥é©æä¸æ¸¸ä»»ååè³æãæåçç¯ä¾ééåæå­¸ç¿åæç¤ºåæå­æç¤ºï¼å°åå½¢ç´æ¥åµå¥èå¤§åèªè¨æ¨¡å (LLM) ç¸åçç©ºéä¸­ãçºäºéæéåç®æ¨ï¼æåæ¹é²äºæåé²çåæç¤ºæ¹æ³ï¼ç¶å¾æåºç¬¬ä¸ååèªè¨å¤æ¨¡å¼æç¤ºå­¸ç¿æ¹æ³ï¼ä»¥å©ç¨é è¨ç·´æ¨¡åä¸­çç¥è­ãå¼å¾æ³¨æçæ¯ï¼ç±æ¼å¾®èª¿çç£ç£ä¸è¶³ï¼å¨æåçç¯ä¾ä¸­ï¼é è¨ç·´ç GNN å LLM ä¿æåçµï¼å æ­¤å¯å­¸ç¿çåæ¸é å°æ¼å¾®èª¿ä»»ä½é è¨ç·´æ¨¡åãééå¨çå¯¦ä¸çè³æéä¸é²è¡å»£æ³çå¯¦é©ï¼æåå±ç¤ºäºæåçç¯ä¾å¨å°éãå¤ä»»åå±¤ç´åè·¨é åè¨­å®ä¸­çåªç°æè½ãæ­¤å¤ï¼æåå»ºç«äºç¬¬ä¸å CLIP é¢¨æ ¼çé¶æ¬¡åé¡ååï¼å®å¯ä»¥å° GNN æ¨å»£å°å·ææ¥µå¼±æå­ç£ç£çæªè¦é¡å¥ã</paragraph>

##### **Illusory VQA: Benchmarking and Enhancing Multimodal Models on Visual Illusions**
2412.08169v1 by Mohammadmostafa Rostamkhani, Baktash Ansari, Hoorieh Sabzevari, Farzan Rahmani, Sauleh Eetemadi

In recent years, Visual Question Answering (VQA) has made significant
strides, particularly with the advent of multimodal models that integrate
vision and language understanding. However, existing VQA datasets often
overlook the complexities introduced by image illusions, which pose unique
challenges for both human perception and model interpretation. In this study,
we introduce a novel task called Illusory VQA, along with four specialized
datasets: IllusionMNIST, IllusionFashionMNIST, IllusionAnimals, and
IllusionChar. These datasets are designed to evaluate the performance of
state-of-the-art multimodal models in recognizing and interpreting visual
illusions. We assess the zero-shot performance of various models, fine-tune
selected models on our datasets, and propose a simple yet effective solution
for illusion detection using Gaussian and blur low-pass filters. We show that
this method increases the performance of models significantly and in the case
of BLIP-2 on IllusionAnimals without any fine-tuning, it outperforms humans.
Our findings highlight the disparity between human and model perception of
illusions and demonstrate that fine-tuning and specific preprocessing
techniques can significantly enhance model robustness. This work contributes to
the development of more human-like visual understanding in multimodal models
and suggests future directions for adapting filters using learnable parameters.

æè¦ï¼è¿å¹´ä¾ï¼è¦è¦ºåç­ï¼VQAï¼åå¾äºé¡¯èé²å±ï¼ç¹å¥æ¯é¨èæ´åè¦è¦ºåèªè¨çè§£çå¤æ¨¡ææ¨¡åçåºç¾ãç¶èï¼ç¾æç VQA è³æééå¸¸æå¿½ç¥ç±è¦è¦ºé¯è¦ºå¸¶ä¾çè¤éæ§ï¼èéå°äººé¡ç¥è¦ºåæ¨¡åè§£éé½æ§æäºç¨ç¹çææ°ãå¨æ¬ç ç©¶ä¸­ï¼æåå¼å¥äºä¸é ç¨±çº Illusory VQA çæ°ä»»åï¼ä»¥åååå°éçè³æéï¼IllusionMNISTãIllusionFashionMNISTãIllusionAnimals å IllusionCharãéäºè³æéæ¨å¨è©ä¼°æåé²çå¤æ¨¡ææ¨¡åå¨è­å¥åè§£éè¦è¦ºé¯è¦ºæ¹é¢çæè½ãæåè©ä¼°äºåç¨®æ¨¡åçé¶æ¬¡å­¸ç¿æè½ï¼å¾®èª¿äºæåè³æéä¸­çé¸å®æ¨¡åï¼ä¸¦æåºäºä¸åç°¡å®ä½ææçè§£æ±ºæ¹æ¡ï¼ä½¿ç¨é«æ¯åæ¨¡ç³ä½éæ¿¾æ³¢å¨é²è¡é¯è¦ºåµæ¸¬ãæåè¡¨æï¼éç¨®æ¹æ³é¡¯èæåäºæ¨¡åæè½ï¼å¨æ²æä»»ä½å¾®èª¿çææ³ä¸ï¼å°æ¼ IllusionAnimals ä¸ç BLIP-2ï¼å®çè¡¨ç¾åªæ¼äººé¡ãæåçç ç©¶çµæçªåºäºäººé¡åæ¨¡åå°é¯è¦ºæç¥çå·®ç°ï¼ä¸¦è­æå¾®èª¿åç¹å®çé èçæè¡å¯ä»¥é¡¯èå¢å¼·æ¨¡åçç©©å¥æ§ãéé å·¥ä½æå©æ¼å¨å¤æ¨¡ææ¨¡åä¸­éç¼æ´æ¥è¿äººé¡çè¦è¦ºçè§£ï¼ä¸¦æåºäºä½¿ç¨å¯å­¸ç¿åæ¸èª¿æ´æ¿¾æ³¢å¨çæªä¾æ¹åã

##### **NLPineers@ NLU of Devanagari Script Languages 2025: Hate Speech Detection using Ensembling of BERT-based models**
2412.08163v1 by Anmol Guragain, Nadika Poudel, Rajesh Piryani, Bishesh Khanal

This paper explores hate speech detection in Devanagari-scripted languages,
focusing on Hindi and Nepali, for Subtask B of the CHIPSAL@COLING 2025 Shared
Task. Using a range of transformer-based models such as XLM-RoBERTa, MURIL, and
IndicBERT, we examine their effectiveness in navigating the nuanced boundary
between hate speech and free expression. Our best performing model, implemented
as ensemble of multilingual BERT models achieve Recall of 0.7762 (Rank 3/31 in
terms of recall) and F1 score of 0.6914 (Rank 17/31). To address class
imbalance, we used backtranslation for data augmentation, and cosine similarity
to preserve label consistency after augmentation. This work emphasizes the need
for hate speech detection in Devanagari-scripted languages and presents a
foundation for further research.

æè¦ï¼æ¬ææ¢è¨å¤©åæèªè¨ä¸­çä»æ¨è¨è«åµæ¸¬ï¼éé»æ¾å¨å°å°èªåå°¼æ³ç¾èªï¼éå° CHIPSAL@COLING 2025 å±äº«ä»»åçå­ä»»å Bãæåä½¿ç¨åç¨®åºæ¼è½æå¨çæ¨¡åï¼ä¾å¦ XLM-RoBERTaãMURIL å IndicBERTï¼æ¢è¨å®åå¨å°èªä»æ¨è¨è«åè¨è«èªç±ä¹éå¾®å¦çéçæææ§ãæåæè½æä½³çæ¨¡åå¯¦ä½çºå¤èªè¨ BERT æ¨¡åçåå¥ï¼å¨å¬åçæ¹é¢éå° 0.7762ï¼å¬åçæåç¬¬ 3/31ï¼ï¼F1 åæ¸çº 0.6914ï¼æåç¬¬ 17/31ï¼ãçºäºè§£æ±ºé¡å¥ä¸å¹³è¡¡åé¡ï¼æåä½¿ç¨ååç¿»è­¯é²è¡è³ææ´åï¼ä¸¦ä½¿ç¨é¤å¼¦ç¸ä¼¼åº¦å¨æ´åå¾ä¿çæ¨ç±¤ä¸è´æ§ãéé å·¥ä½å¼·èª¿å¤©åæèªè¨ä¸­ä»æ¨è¨è«åµæ¸¬çéæ±ï¼ä¸¦çºé²ä¸æ­¥çç ç©¶å¥ å®åºç¤ã

##### **How Vision-Language Tasks Benefit from Large Pre-trained Models: A Survey**
2412.08158v1 by Yayun Qi, Hongxi Li, Yiqi Song, Xinxiao Wu, Jiebo Luo

The exploration of various vision-language tasks, such as visual captioning,
visual question answering, and visual commonsense reasoning, is an important
area in artificial intelligence and continuously attracts the research
community's attention. Despite the improvements in overall performance, classic
challenges still exist in vision-language tasks and hinder the development of
this area. In recent years, the rise of pre-trained models is driving the
research on vision-language tasks. Thanks to the massive scale of training data
and model parameters, pre-trained models have exhibited excellent performance
in numerous downstream tasks. Inspired by the powerful capabilities of
pre-trained models, new paradigms have emerged to solve the classic challenges.
Such methods have become mainstream in current research with increasing
attention and rapid advances. In this paper, we present a comprehensive
overview of how vision-language tasks benefit from pre-trained models. First,
we review several main challenges in vision-language tasks and discuss the
limitations of previous solutions before the era of pre-training. Next, we
summarize the recent advances in incorporating pre-trained models to address
the challenges in vision-language tasks. Finally, we analyze the potential
risks associated with the inherent limitations of pre-trained models and
discuss possible solutions, attempting to provide future research directions.

æè¦ï¼åç¨®è¦è¦ºèªè¨ä»»åçæ¢ç´¢ï¼ä¾å¦è¦è¦ºå­å¹ãè¦è¦ºåç­åè¦è¦ºå¸¸è­æ¨çï¼æ¯äººå·¥æºæ§ä¸­ä¸åéè¦çé åï¼ä¸¦æçºå¸å¼ç ç©¶ç¤¾ç¾¤çéæ³¨ãåç®¡æ´é«æè½æææåï¼ç¶å¸ææ°ä»å­å¨æ¼è¦è¦ºèªè¨ä»»åä¸­ï¼ä¸¦é»ç¤éåé åçç¼å±ãè¿å¹´ä¾ï¼é è¨ç·´æ¨¡åçèèµ·å¸¶åäºè¦è¦ºèªè¨ä»»åçç ç©¶ãå¾çæ¼è¨ç·´è³æåæ¨¡ååæ¸çå¤§è¦æ¨¡è¦æ¨¡ï¼é è¨ç·´æ¨¡åå¨è¨±å¤ä¸æ¸¸ä»»åä¸­è¡¨ç¾åºè²çæè½ãåå°é è¨ç·´æ¨¡åå¼·å¤§åè½çåç¼ï¼æ°çå¸ç¯å·²ç¶åºç¾ä¾è§£æ±ºç¶å¸ææ°ãéäºæ¹æ³å·²æçºç¶åç ç©¶çä¸»æµï¼ä¸¦åå°è¶ä¾è¶å¤çéæ³¨åå¿«éé²å±ãå¨æ¬æä¸­ï¼æåæåºäºé è¨ç·´æ¨¡åå¦ä½ä½¿è¦è¦ºèªè¨ä»»ååççå¨é¢æ¦è¿°ãé¦åï¼æååé¡§äºè¦è¦ºèªè¨ä»»åä¸­çå¹¾åä¸»è¦ææ°ï¼ä¸¦è¨è«äºé è¨ç·´æä»£ä¹åååè§£æ±ºæ¹æ¡çéå¶ãæ¥ä¸ä¾ï¼æåç¸½çµäºå°é è¨ç·´æ¨¡åç´å¥ä»¥æå°è¦è¦ºèªè¨ä»»åä¸­ææ°çææ°é²å±ãæå¾ï¼æååæäºèé è¨ç·´æ¨¡ååºæéå¶ç¸éçæ½å¨é¢¨éªï¼ä¸¦è¨è«å¯è½çè§£æ±ºæ¹æ¡ï¼è©¦åæä¾æªä¾çç ç©¶æ¹åã

##### **Antelope: Potent and Concealed Jailbreak Attack Strategy**
2412.08156v1 by Xin Zhao, Xiaojun Chen, Haoyu Gao

Due to the remarkable generative potential of diffusion-based models,
numerous researches have investigated jailbreak attacks targeting these
frameworks. A particularly concerning threat within image models is the
generation of Not-Safe-for-Work (NSFW) content. Despite the implementation of
security filters, numerous efforts continue to explore ways to circumvent these
safeguards. Current attack methodologies primarily encompass adversarial prompt
engineering or concept obfuscation, yet they frequently suffer from slow search
efficiency, conspicuous attack characteristics and poor alignment with targets.
To overcome these challenges, we propose Antelope, a more robust and covert
jailbreak attack strategy designed to expose security vulnerabilities inherent
in generative models. Specifically, Antelope leverages the confusion of
sensitive concepts with similar ones, facilitates searches in the semantically
adjacent space of these related concepts and aligns them with the target
imagery, thereby generating sensitive images that are consistent with the
target and capable of evading detection. Besides, we successfully exploit the
transferability of model-based attacks to penetrate online black-box services.
Experimental evaluations demonstrate that Antelope outperforms existing
baselines across multiple defensive mechanisms, underscoring its efficacy and
versatility.

æè¦ï¼ç±æ¼åºæ¼æ´æ£æ¨¡åçé¡¯èçææ½åï¼è¨±å¤ç ç©¶æ¢è¨äºéå°éäºæ¡æ¶çè¶çæ»æãååæ¨¡åä¸­ä¸åç¹å¥ä»¤äººææçå¨èæ¯éå·¥ä½å®å¨ (NSFW) å§å®¹ççæãåç®¡å¯¦æ½äºå®å¨éæ¿¾å¨ï¼ä½ä»æè¨±å¤åªåæçºæ¢ç´¢è¦é¿éäºé²è­·æªæ½çæ¹æ³ãç®åçæ»ææ¹æ³ä¸»è¦åæ¬å°ææç¤ºå·¥ç¨ææ¦å¿µæ··æ·ï¼ä½å®åç¶å¸¸é­åæç´¢æçä½ãæ»æç¹å¾µæé¡¯ä»¥åèç®æ¨å°é½ä¸è¯çåé¡ãçºäºåæéäºææ°ï¼æåæåºäº Antelopeï¼éæ¯ä¸ç¨®æ´å¼·å¤§ä¸é±è½çè¶çæ»æç­ç¥ï¼æ¨å¨æ­é²çææ¨¡åä¸­åºæçå®å¨æ¼æ´ãå·é«ä¾èªªï¼Antelope å©ç¨æææ¦å¿µèç¸ä¼¼æ¦å¿µçæ··æ·ï¼ä¿é²å¨éäºç¸éæ¦å¿µçèªç¾©é°è¿ç©ºéä¸­é²è¡æç´¢ï¼ä¸¦å°å®åèç®æ¨ååå°é½ï¼å¾èçæèç®æ¨ä¸è´ä¸è½å¤ éé¿æª¢æ¸¬çææååãæ­¤å¤ï¼æåæåå©ç¨åºæ¼æ¨¡åçæ»æçå¯å³éæ§ä¾æ»²éå¨ç·é»çå­æåãå¯¦é©è©ä¼°è¡¨æï¼Antelope å¨å¤ç¨®é²ç¦¦æ©å¶ä¸­åªæ¼ç¾æçåºæºï¼çªé¡¯äºå¶æææ§åå¤åè½æ§ã

##### **A Review of Intelligent Device Fault Diagnosis Technologies Based on Machine Vision**
2412.08148v1 by Guiran Liu, Binrong Zhu

This paper provides a comprehensive review of mechanical equipment fault
diagnosis methods, focusing on the advancements brought by Transformer-based
models. It details the structure, working principles, and benefits of
Transformers, particularly their self-attention mechanism and parallel
computation capabilities, which have propelled their widespread application in
natural language processing and computer vision. The discussion highlights key
Transformer model variants, such as Vision Transformers (ViT) and their
extensions, which leverage self-attention to improve accuracy and efficiency in
visual tasks. Furthermore, the paper examines the application of
Transformer-based approaches in intelligent fault diagnosis for mechanical
systems, showcasing their superior ability to extract and recognize patterns
from complex sensor data for precise fault identification. Despite these
advancements, challenges remain, including the reliance on extensive labeled
datasets, significant computational demands, and difficulties in deploying
models on resource-limited devices. To address these limitations, the paper
proposes future research directions, such as developing lightweight Transformer
architectures, integrating multimodal data sources, and enhancing adaptability
to diverse operational conditions. These efforts aim to further expand the
application of Transformer-based methods in mechanical fault diagnosis, making
them more robust, efficient, and suitable for real-world industrial
environments.

æè¦ï¼æ¬æå¨é¢åé¡¾äºæ©æ¢°è¨­åæéè¨ºæ·æ¹æ³ï¼éé»éæ³¨ Transformer æ¨¡åå¸¶ä¾çé²å±ãå®è©³ç´°èªªæäº Transformer ççµæ§ãå·¥ä½åçååªé»ï¼ç¹å¥æ¯å®åçèªææ³¨ææ©å¶åä¸¦è¡è¨ç®è½åï¼éäºè½åæ¨åäºå®åå¨èªç¶èªè¨èçåé»è¦è¦è¦ºä¸­çå»£æ³æç¨ãè¨è«éé»ä»ç´¹äºééµç Transformer æ¨¡åè®é«ï¼ä¾å¦è¦è¦º Transformer (ViT) åå¶æ´åå¥ä»¶ï¼å®åå©ç¨èªææ³¨æä¾æé«è¦è¦ºä»»åçæºç¢ºæ§åæçãæ­¤å¤ï¼æ¬ææ¢è¨äº Transformer æ¹æ³å¨æ©æ¢°ç³»çµ±çæºæ§æéè¨ºæ·ä¸­çæç¨ï¼å±ç¤ºäºå®åå¾è¤éææ¸¬å¨è³æä¸­æååè­å¥æ¨¡å¼ä»¥é²è¡ç²¾ç¢ºæéè­å¥çåªç°è½åãåç®¡æéäºé²å±ï¼ä½ä»å­å¨ææ°ï¼åæ¬ä¾è³´æ¼å»£æ³æ¨è¨çè³æéãå¤§éçè¨ç®éæ±ä»¥åå¨è³æºåéçè£ç½®ä¸é¨ç½²æ¨¡åçå°é£ãçºäºæå°éäºéå¶ï¼æ¬ææåºäºæªä¾çç ç©¶æ¹åï¼ä¾å¦éç¼è¼éç´ Transformer æ¶æ§ãæ´åå¤æ¨¡å¼è³æä¾æºï¼ä¸¦å¢å¼·å°ä¸åæä½æ¢ä»¶çé©ææ§ãéäºåªåæ¨å¨é²ä¸æ­¥æ´å¤§ Transformer æ¹æ³å¨æ©æ¢°æéè¨ºæ·ä¸­çæç¨ï¼ä½¿å¶æ´å¼·å¤§ãæ´ææçï¼ä¸¦æ´é©åæ¼ç¾å¯¦ä¸ççå·¥æ¥­ç°å¢ã

##### **How to Weight Multitask Finetuning? Fast Previews via Bayesian Model-Merging**
2412.08147v1 by Hugo MonzÃ³n Maldonado, Thomas MÃ¶llenhoff, Nico Daheim, Iryna Gurevych, Mohammad Emtiyaz Khan

When finetuning multiple tasks altogether, it is important to carefully weigh
them to get a good performance, but searching for good weights can be difficult
and costly. Here, we propose to aid the search with fast previews to quickly
get a rough idea of different reweighting options. We use model merging to
create previews by simply reusing and averaging parameters of models trained on
each task separately (no retraining required). To improve the quality of
previews, we propose a Bayesian approach to design new merging strategies by
using more flexible posteriors. We validate our findings on vision and
natural-language transformers. Our work shows the benefits of model merging via
Bayes to improve multitask finetuning.

æè¦ï¼å¨å¾®è°å¤ä¸ªä»»å¡æ¶ï¼ä»ç»æè¡¡å®ä»¬ä»¥è·å¾è¯å¥½çæ§è½éå¸¸éè¦ï¼ä½å¯»æ¾åéçæéå¯è½æ¢å°é¾åæè´µãå¨æ­¤ï¼æä»¬å»ºè®®ä½¿ç¨å¿«éé¢è§æ¥è¾å©æç´¢ï¼ä»¥å¿«éå¤§è´äºè§£ä¸åçéæ°å æéé¡¹ãæä»¬ä½¿ç¨æ¨¡ååå¹¶æ¥åå»ºé¢è§ï¼æ¹æ³æ¯ç®åå°éå¤ä½¿ç¨å¹¶å¹³åå¨æ¯ä¸ªä»»å¡ä¸åç¬è®­ç»çæ¨¡åçåæ°ï¼æ ééæ°è®­ç»ï¼ãä¸ºäºæé«é¢è§çè´¨éï¼æä»¬æåºäºä¸ç§è´å¶æ¯æ¹æ³ï¼éè¿ä½¿ç¨æ´çµæ´»çåéªæ¥è®¾è®¡æ°çåå¹¶ç­ç¥ãæä»¬å¨è§è§åèªç¶è¯­è¨è½¬æ¢å¨ä¸éªè¯äºæä»¬çåç°ãæä»¬çå·¥ä½å±ç¤ºäºéè¿è´å¶æ¯æ¨¡ååå¹¶çå¥½å¤ï¼ä»¥æ¹åå¤ä»»å¡å¾®è°ã

##### **A Survey on Private Transformer Inference**
2412.08145v1 by Yang Li, Xinyu Zhou, Yitong Wang, Liangxin Qian, Jun Zhao

Transformer models have revolutionized AI, enabling applications like content
generation and sentiment analysis. However, their use in Machine Learning as a
Service (MLaaS) raises significant privacy concerns, as centralized servers
process sensitive user data. Private Transformer Inference (PTI) addresses
these issues using cryptographic techniques such as Secure Multi-Party
Computation (MPC) and Homomorphic Encryption (HE), enabling secure model
inference without exposing inputs or models. This paper reviews recent
advancements in PTI, analyzing state-of-the-art solutions, their challenges,
and potential improvements. We also propose evaluation guidelines to assess
resource efficiency and privacy guarantees, aiming to bridge the gap between
high-performance inference and data privacy.

æè¦ï¼Transformeræ¨¡åå¾¹åºæ¹è®äº AIï¼è®å§å®¹çæåæç·åæç­æç¨ç¨å¼å¾ä»¥åä¸ãç¶èï¼å®åç¨æ¼æ©å¨å­¸ç¿å³æå (MLaaS) ææå¼ç¼éå¤§çé±ç§åé¡ï¼å çºéä¸­å¼ä¼ºæå¨æèçææçä½¿ç¨èè³æãç§äººTransformeræ¨è« (PTI) ä½¿ç¨å®å¨å¤æ¹éç® (MPC) ååæå å¯ (HE) ç­å¯ç¢¼æè¡ä¾è§£æ±ºéäºåé¡ï¼è®æ¨¡åè½å¤ å¨ä¸å¬éè¼¸å¥ææ¨¡åçææ³ä¸é²è¡å®å¨æ¨è«ãæ¬æåé¡§äº PTI çææ°é²å±ï¼åæäºæåé²çè§£æ±ºæ¹æ¡ãå®åçææ°åæ½å¨çæ¹é²ãæåä¹æåºè©ä¼°æºåä¾è©ä¼°è³æºæçåé±ç§ä¿è­ï¼ç®æ¨æ¯å½åé«æ§è½æ¨è«åè³æé±ç§ä¹éçå·®è·ã

##### **AGMixup: Adaptive Graph Mixup for Semi-supervised Node Classification**
2412.08144v1 by Weigang Lu, Ziyu Guan, Wei Zhao, Yaming Yang, Yibing Zhan, Yiheng Lu, Dapeng Tao

Mixup is a data augmentation technique that enhances model generalization by
interpolating between data points using a mixing ratio $\lambda$ in the image
domain. Recently, the concept of mixup has been adapted to the graph domain
through node-centric interpolations. However, these approaches often fail to
address the complexity of interconnected relationships, potentially damaging
the graph's natural topology and undermining node interactions. Furthermore,
current graph mixup methods employ a one-size-fits-all strategy with a randomly
sampled $\lambda$ for all mixup pairs, ignoring the diverse needs of different
pairs. This paper proposes an Adaptive Graph Mixup (AGMixup) framework for
semi-supervised node classification. AGMixup introduces a subgraph-centric
approach, which treats each subgraph similarly to how images are handled in
Euclidean domains, thus facilitating a more natural integration of mixup into
graph-based learning. We also propose an adaptive mechanism to tune the mixing
ratio $\lambda$ for diverse mixup pairs, guided by the contextual similarity
and uncertainty of the involved subgraphs. Extensive experiments across seven
datasets on semi-supervised node classification benchmarks demonstrate
AGMixup's superiority over state-of-the-art graph mixup methods. Source codes
are available at \url{https://github.com/WeigangLu/AGMixup}.

æè¦ï¼Mixup æ¯ä¸ç¨®è³ææ´åæè¡ï¼ééå¨å½±åé åä¸­ä½¿ç¨æ··åæ¯ä¾ $\lambda$ å¨è³æé»ä¹éé²è¡å§æï¼ä¾æåæ¨¡åçæ³åè½åãæè¿ï¼Mixup çæ¦å¿µå·²ç¶ééä»¥ç¯é»çºä¸­å¿çå§ææ¹å¼ï¼æ¹ç·¨å°åå½¢é åãç¶èï¼éäºæ¹æ³å¸¸å¸¸ç¡æ³èçç¸äºéè¯éä¿çè¤éæ§ï¼å¯è½ææå®³åå½¢çèªç¶ææ²çµæ§ï¼ä¸¦ç ´å£ç¯é»äºåãæ­¤å¤ï¼ç®åçåå½¢ Mixup æ¹æ³æ¡ç¨ä¸é«é©ç¨çç­ç¥ï¼å°ææ Mixup å°ä½¿ç¨é¨æ©åæ¨£ç $\lambda$ï¼å¿½ç¥äºä¸åå°ä¹éä¸åçéæ±ãæ¬ææåºäºä¸åé©æå¼åå½¢ Mixup (AGMixup) æ¶æ§ï¼ç¨æ¼åç£ç£ç¯é»åé¡ãAGMixup æ¡ç¨äºä¸åä»¥å­åçºä¸­å¿çéå¾ï¼å°æ¯åå­åè¦çºé¡ä¼¼æ¼å¨æ­å¹¾éå¾·é åä¸­èçå½±åçæ¹å¼ï¼å¾èä¿é² Mixup æ´èªç¶å°æ´åå°åºæ¼åå½¢çå­¸ç¿ä¸­ãæåéæåºäºä¸åé©ææ©å¶ï¼æ ¹æææ¶åå­åçä¸ä¸æç¸ä¼¼æ§åä¸ç¢ºå®æ§ï¼èª¿æ´ä¸å Mixup å°çæ··åæ¯ä¾ $\lambda$ãå¨ä¸åè³æéä¸çå»£æ³å¯¦é©ï¼å¨åç£ç£ç¯é»åé¡åºæºä¸è­æäº AGMixup åªæ¼æåé²çåå½¢ Mixup æ¹æ³ãåå§ç¢¼å¯å¨ \url{https://github.com/WeigangLu/AGMixup} åå¾ã

##### **Wasserstein Distance Rivals Kullback-Leibler Divergence for Knowledge Distillation**
2412.08139v1 by Jiaming Lv, Haoyuan Yang, Peihua Li

Since pioneering work of Hinton et al., knowledge distillation based on
Kullback-Leibler Divergence (KL-Div) has been predominant, and recently its
variants have achieved compelling performance. However, KL-Div only compares
probabilities of the corresponding category between the teacher and student
while lacking a mechanism for cross-category comparison. Besides, KL-Div is
problematic when applied to intermediate layers, as it cannot handle
non-overlapping distributions and is unaware of geometry of the underlying
manifold. To address these downsides, we propose a methodology of Wasserstein
Distance (WD) based knowledge distillation. Specifically, we propose a logit
distillation method called WKD-L based on discrete WD, which performs
cross-category comparison of probabilities and thus can explicitly leverage
rich interrelations among categories. Moreover, we introduce a feature
distillation method called WKD-F, which uses a parametric method for modeling
feature distributions and adopts continuous WD for transferring knowledge from
intermediate layers. Comprehensive evaluations on image classification and
object detection have shown (1) for logit distillation WKD-L outperforms very
strong KL-Div variants; (2) for feature distillation WKD-F is superior to the
KL-Div counterparts and state-of-the-art competitors. The source code is
available at https://peihuali.org/WKD

æè¦ï¼èª Hinton ç­äººçå¼åæ§å·¥ä½ä»¥æ¥ï¼åºäº Kullback-Leibler æ£åº¦ (KL-Div) çç¥è¯è¸é¦ä¸ç´å ä¸»å¯¼å°ä½ï¼æè¿å¶åä½å·²ç»åå¾äºä»¤äººä¿¡æçæ§è½ãç¶èï¼KL-Div ä»æ¯è¾äºæå¸åå­¦çä¹é´å¯¹åºç±»å«çæ¦çï¼èç¼ºå°è·¨ç±»å«æ¯è¾çæºå¶ãæ­¤å¤ï¼KL-Div å¨åºç¨äºä¸­é´å±æ¶å­å¨é®é¢ï¼å ä¸ºå®æ æ³å¤çééå åå¸ï¼å¹¶ä¸ä¸äºè§£åºå±æµå½¢çå ä½å½¢ç¶ãä¸ºäºè§£å³è¿äºç¼ºç¹ï¼æä»¬æåºäºä¸ç§åºäº Wasserstein è·ç¦» (WD) çç¥è¯è¸é¦æ¹æ³ãå·ä½æ¥è¯´ï¼æä»¬æåºäºä¸ç§ç§°ä¸º WKD-L ç logit è¸é¦æ¹æ³ï¼å®åºäºç¦»æ£ WDï¼å®æ§è¡æ¦ççè·¨ç±»å«æ¯è¾ï¼å æ­¤å¯ä»¥æç¡®å©ç¨ç±»å«ä¹é´çä¸°å¯ç¸äºå³ç³»ãæ­¤å¤ï¼æä»¬å¼å¥äºä¸ç§ç§°ä¸º WKD-F çç¹å¾è¸é¦æ¹æ³ï¼å®ä½¿ç¨åæ°åæ¹æ³å¯¹ç¹å¾åå¸è¿è¡å»ºæ¨¡ï¼å¹¶éç¨è¿ç»­ WD ä»ä¸­é´å±ä¼ è¾ç¥è¯ãå¨å¾ååç±»åå¯¹è±¡æ£æµæ¹é¢çç»¼åè¯ä¼°è¡¨æ (1) å¯¹äº logit è¸é¦ï¼WKD-L ä¼äºéå¸¸å¼ºå¤§ç KL-Div åä½ï¼(2) å¯¹äºç¹å¾è¸é¦ï¼WKD-F ä¼äº KL-Div å¯¹åºé¡¹åæåè¿çç«äºå¯¹æãæºä»£ç å¯å¨ https://peihuali.org/WKD è·å¾

##### **Learn How to Query from Unlabeled Data Streams in Federated Learning**
2412.08138v1 by Yuchang Sun, Xinran Li, Tao Lin, Jun Zhang

Federated learning (FL) enables collaborative learning among decentralized
clients while safeguarding the privacy of their local data. Existing studies on
FL typically assume offline labeled data available at each client when the
training starts. Nevertheless, the training data in practice often arrive at
clients in a streaming fashion without ground-truth labels. Given the expensive
annotation cost, it is critical to identify a subset of informative samples for
labeling on clients. However, selecting samples locally while accommodating the
global training objective presents a challenge unique to FL. In this work, we
tackle this conundrum by framing the data querying process in FL as a
collaborative decentralized decision-making problem and proposing an effective
solution named LeaDQ, which leverages multi-agent reinforcement learning
algorithms. In particular, under the implicit guidance from global information,
LeaDQ effectively learns the local policies for distributed clients and steers
them towards selecting samples that can enhance the global model's accuracy.
Extensive simulations on image and text tasks show that LeaDQ advances the
model performance in various FL scenarios, outperforming the benchmarking
algorithms.

æè¦ï¼è¯é¦å­¸ç¿ (FL) è½å¤ å¨åæ£å¼ç¨æ¶ç«¯ä¹éé²è¡åä½å­¸ç¿ï¼åæä¿è­·å¶æ¬å°è³æçé±ç§ãç¾æéæ¼ FL çç ç©¶éå¸¸åè¨­å¨è¨ç·´éå§ææ¯åç¨æ¶ç«¯é½æé¢ç·æ¨ç±¤è³æå¯ç¨ãç¶èï¼å¯¦éä¸çè¨ç·´è³æéå¸¸ä»¥ä¸²æµæ¹å¼å³éçµ¦ç¨æ¶ç«¯ï¼ä¸æ²æåºæ¬äºå¯¦æ¨ç±¤ãç±æ¼è¨»è§£ææ¬æè²´ï¼å æ­¤å¨ç¨æ¶ç«¯ä¸è­å¥åºå·æè³è¨æ§çæ¨£æ¬å­éé²è¡æ¨ç±¤éå¸¸éè¦ãç¶èï¼å¨å®¹ç´å¨çè¨ç·´ç®æ¨çåæï¼å¨æ¬å°é¸ææ¨£æ¬å° FL ä¾èªªæ¯ä¸åç¨ç¹çææ°ãå¨éé å·¥ä½ä¸­ï¼æåå° FL ä¸­çè³ææ¥è©¢ç¨åºå»ºæ§çºä¸ååä½å¼åæ£å¼æ±ºç­å¶å®åé¡ï¼ä¸¦æåºäºä¸ååçº LeaDQ çææè§£æ±ºæ¹æ¡ï¼å®å©ç¨äºå¤ä¸»é«å¼·åå­¸ç¿æ¼ç®æ³ãç¹å¥æ¯å¨å¨çè³è¨çé±å¼æå°ä¸ï¼LeaDQ ææå°å­¸ç¿äºåæ£å¼ç¨æ¶ç«¯çæ¬å°æ¿ç­ï¼ä¸¦å¼å°å®åé¸æè½å¤ å¢å¼·å¨çæ¨¡åæºç¢ºæ§çæ¨£æ¬ãå¨å½±ååæå­ä»»åä¸çå»£æ³æ¨¡æ¬é¡¯ç¤ºï¼LeaDQ å¨åç¨® FL å ´æ¯ä¸­æåäºæ¨¡åæè½ï¼åªæ¼åºæºæ¼ç®æ³ã

##### **DiffRaman: A Conditional Latent Denoising Diffusion Probabilistic Model for Bacterial Raman Spectroscopy Identification Under Limited Data Conditions**
2412.08131v1 by Haiming Yao, Wei Luo, Ang Gao, Tao Zhou, Xue Wang

Raman spectroscopy has attracted significant attention in various biochemical
detection fields, especially in the rapid identification of pathogenic
bacteria. The integration of this technology with deep learning to facilitate
automated bacterial Raman spectroscopy diagnosis has emerged as a key focus in
recent research. However, the diagnostic performance of existing deep learning
methods largely depends on a sufficient dataset, and in scenarios where there
is a limited availability of Raman spectroscopy data, it is inadequate to fully
optimize the numerous parameters of deep neural networks. To address these
challenges, this paper proposes a data generation method utilizing deep
generative models to expand the data volume and enhance the recognition
accuracy of bacterial Raman spectra. Specifically, we introduce DiffRaman, a
conditional latent denoising diffusion probability model for Raman spectra
generation. Experimental results demonstrate that synthetic bacterial Raman
spectra generated by DiffRaman can effectively emulate real experimental
spectra, thereby enhancing the performance of diagnostic models, especially
under conditions of limited data. Furthermore, compared to existing generative
models, the proposed DiffRaman offers improvements in both generation quality
and computational efficiency. Our DiffRaman approach offers a well-suited
solution for automated bacteria Raman spectroscopy diagnosis in data-scarce
scenarios, offering new insights into alleviating the labor of spectroscopic
measurements and enhancing rare bacteria identification.

æè¦ï¼ææ¼åè­å¨åç¨®çåæª¢æ¸¬é åä¸­ååéæ³¨ï¼ç¹å¥æ¯å¨çåèçå¿«ééå®ä¸­ãå°æ­¤æè¡èæ·±åº¦å­¸ç¿æ´åä»¥ä¿é²èªååç´°èææ¼åè­è¨ºæ·å·²æçºè¿å¹´ç ç©¶çéé»ãç¶èï¼ç¾ææ·±åº¦å­¸ç¿æ¹æ³çè¨ºæ·æ§è½å¨å¾å¤§ç¨åº¦ä¸åæ±ºæ¼åè¶³çæ¸æéï¼èå¨ææ¼åè­æ¸æå¯ç¨æ§æéçææ³ä¸ï¼ç¡æ³åååªåæ·±åº¦ç¥ç¶ç¶²è·¯çç¾å¤åæ¸ãçºäºæå°éäºææ°ï¼æ¬ææåºäºä¸ç¨®å©ç¨æ·±åº¦çææ¨¡åä¾æ´å±æ¸æéä¸¦å¢å¼·ç´°èææ¼åè­è­å¥ç²¾åº¦çæ¸æçææ¹æ³ãå·é«ä¾èªªï¼æåå¼å¥äº DiffRamanï¼éæ¯ä¸ç¨®ç¨æ¼ææ¼åè­çæçæ¢ä»¶æ½å¨å»åªæ´æ£æ¦çæ¨¡åãå¯¦é©çµæè¡¨æï¼ç± DiffRaman çæçåæç´°èææ¼åè­å¯ä»¥ææå°æ¨¡æ¬çå¯¦å¯¦é©åè­ï¼å¾èå¢å¼·è¨ºæ·æ¨¡åçæ§è½ï¼ç¹å¥æ¯å¨æ¸ææéçææ³ä¸ãæ­¤å¤ï¼èç¾æççææ¨¡åç¸æ¯ï¼ææåºç DiffRaman å¨çæè³ªéåè¨ç®æçæ¹é¢é½æææ¹é²ãæåç DiffRaman æ¹æ³çºæ¸æç¨ç¼ºå ´æ¯ä¸­çèªåç´°èææ¼åè­è¨ºæ·æä¾äºä¸åé©ç¨çè§£æ±ºæ¹æ¡ï¼çºæ¸è¼åè­æ¸¬éçåååå¢å¼·ç½è¦ç´°èçéå®æä¾äºæ°çè¦è§£ã

##### **Evil twins are not that evil: Qualitative insights into machine-generated prompts**
2412.08127v1 by NathanaÃ«l Carraz Rakotonirina, Corentin Kervadec, Francesca Franzon, Marco Baroni

It has been widely observed that language models (LMs) respond in predictable
ways to algorithmically generated prompts that are seemingly unintelligible.
This is both a sign that we lack a full understanding of how LMs work, and a
practical challenge, because opaqueness can be exploited for harmful uses of
LMs, such as jailbreaking. We present the first thorough analysis of opaque
machine-generated prompts, or autoprompts, pertaining to 3 LMs of different
sizes and families. We find that machine-generated prompts are characterized by
a last token that is often intelligible and strongly affects the generation. A
small but consistent proportion of the previous tokens are fillers that
probably appear in the prompt as a by-product of the fact that the optimization
process fixes the number of tokens. The remaining tokens tend to have at least
a loose semantic relation with the generation, although they do not engage in
well-formed syntactic relations with it. We find moreover that some of the
ablations we applied to machine-generated prompts can also be applied to
natural language sequences, leading to similar behavior, suggesting that
autoprompts are a direct consequence of the way in which LMs process linguistic
inputs in general.

æè¦ï¼äººåå»£æ³è§å¯å°ï¼èªè¨æ¨¡å (LM) ä»¥å¯é æ¸¬çæ¹å¼åæçä¼¼é£ä»¥çè§£çæ¼ç®æ³ç¢çæç¤ºãéæ¢æ¯æåç¼ºä¹å° LM å·¥ä½æ¹å¼çååçè§£çè·¡è±¡ï¼ä¹æ¯ä¸åå¯¦éææ°ï¼å çºä¸éææ§å¯è½æè¢«å©ç¨æ¼ LM çæå®³ç¨éï¼ä¾å¦è¶çãæåéå° 3 åä¸åå¤§å°åé¡åç LM æåºé¦æ¬¡å°ä¸éææ©å¨ç¢ççæç¤ºæèªåæç¤ºçå¾¹åºåæãæåç¼ç¾æ©å¨ç¢ççæç¤ºçç¹å¾µæ¯æå¾ä¸åéå¸¸å¯ä»¥çè§£ä¸å¼·çå½±é¿çæçæ¨è¨ãåä¸åæ¨è¨ä¸­æä¸å°é¨åä½ä¸è´çæ¯ä¾æ¯å¡«æï¼éäºå¡«æå¯è½åºç¾å¨æç¤ºä¸­ï¼å çºæä½³åéç¨åºå®äºæ¨è¨çæ¸éãå¶é¤æ¨è¨å¾å¾èçæè³å°æé¬æ£çèªç¾©éä¿ï¼åç®¡å®åä¸æèçæå»ºç«è¯å¥½çå¥æ³éä¿ãæ­¤å¤ï¼æåç¼ç¾æç¨æ¼æ©å¨ç¢ççæç¤ºçä¸äºæ¶èä¹å¯ä»¥æç¨æ¼èªç¶èªè¨åºåï¼å°è´é¡ä¼¼çè¡çºï¼éè¡¨æèªåæç¤ºæ¯ LM ä¸è¬èçèªè¨è¼¸å¥çæ¹å¼çç´æ¥çµæã

##### **Progressive Multi-granular Alignments for Grounded Reasoning in Large Vision-Language Models**
2412.08125v1 by Quang-Hung Le, Long Hoang Dang, Ngan Le, Truyen Tran, Thao Minh Le

Existing Large Vision-Language Models (LVLMs) excel at matching concepts
across multi-modal inputs but struggle with compositional concepts and
high-level relationships between entities. This paper introduces Progressive
multi-granular Vision-Language alignments (PromViL), a novel framework to
enhance LVLMs' ability in performing grounded compositional visual reasoning
tasks. Our approach constructs a hierarchical structure of multi-modal
alignments, ranging from simple to complex concepts. By progressively aligning
textual descriptions with corresponding visual regions, our model learns to
leverage contextual information from lower levels to inform higher-level
reasoning. To facilitate this learning process, we introduce a data generation
process that creates a novel dataset derived from Visual Genome, providing a
wide range of nested compositional vision-language pairs. Experimental results
demonstrate that our PromViL framework significantly outperforms baselines on
various visual grounding and compositional question answering tasks.

æè¦ï¼ç¾æçå¤§åè¦è¦ºèªè¨æ¨¡å (LVLMs) æé·æ¯å°è·¨å¤æ¨¡å¼è¼¸å¥çæ¦å¿µï¼ä½å¨çµåæ¦å¿µåå¯¦é«ä¹éçé«å±¤ç´éä¿ä¸å»æå°é£ãæ¬æä»ç´¹æ¼¸é²å¼å¤ç²åº¦è¦è¦ºèªè¨å°é½ (PromViL)ï¼éæ¯ä¸ç¨®æ°ç©çæ¶æ§ï¼ç¨æ¼å¢å¼· LVLMs å¨å·è¡åºç¤çµåè¦è¦ºæ¨çä»»åçè½åãæåçåæ³å»ºæ§äºä¸åå¤æ¨¡å¼å°é½çåå±¤çµæ§ï¼å¾ç°¡å®å°è¤éçæ¦å¿µãééæ¼¸é²å¼å°å°æå­æè¿°èå°æçè¦è¦ºååå°é½ï¼æåçæ¨¡åå­¸ç¿å©ç¨è¼ä½å±¤ç´çèçµ¡è³è¨ï¼ä¾åç¥è¼é«å±¤ç´çæ¨çãçºäºä¿é²éåå­¸ç¿éç¨ï¼æåå¼å¥äºä¸åè³æç¢çç¨åºï¼éåç¨åºæå»ºç«ä¸åæ°ç©çè³æéï¼è¡çèª Visual Genomeï¼æä¾å»£æ³çåµå¥çµåè¦è¦ºèªè¨éå°ãå¯¦é©çµæè­æï¼æåç PromViL æ¶æ§å¨åç¨®è¦è¦ºåºç¤åçµåå¼åç­ä»»åä¸ï¼é½é¡¯èåªæ¼åºæºã

##### **LatentSpeech: Latent Diffusion for Text-To-Speech Generation**
2412.08117v1 by Haowei Lou, Helen Paik, Pari Delir Haghighi, Wen Hu, Lina Yao

Diffusion-based Generative AI gains significant attention for its superior
performance over other generative techniques like Generative Adversarial
Networks and Variational Autoencoders. While it has achieved notable
advancements in fields such as computer vision and natural language processing,
their application in speech generation remains under-explored. Mainstream
Text-to-Speech systems primarily map outputs to Mel-Spectrograms in the
spectral space, leading to high computational loads due to the sparsity of
MelSpecs. To address these limitations, we propose LatentSpeech, a novel TTS
generation approach utilizing latent diffusion models. By using latent
embeddings as the intermediate representation, LatentSpeech reduces the target
dimension to 5% of what is required for MelSpecs, simplifying the processing
for the TTS encoder and vocoder and enabling efficient high-quality speech
generation. This study marks the first integration of latent diffusion models
in TTS, enhancing the accuracy and naturalness of generated speech.
Experimental results on benchmark datasets demonstrate that LatentSpeech
achieves a 25% improvement in Word Error Rate and a 24% improvement in Mel
Cepstral Distortion compared to existing models, with further improvements
rising to 49.5% and 26%, respectively, with additional training data. These
findings highlight the potential of LatentSpeech to advance the
state-of-the-art in TTS technology

æè¦ï¼åºæ¼æ´æ£ççæå¼ AI å å¶åªæ¼å¶ä»çæå¼æè¡ï¼ä¾å¦çæå°æç¶²è·¯åè®ç°èªåç·¨ç¢¼å¨ï¼çåè¶æè½èååéæ³¨ãéç¶å®å¨é»è¦è¦è¦ºåèªç¶èªè¨èçç­é ååå¾é¡¯èé²å±ï¼ä½å¶å¨èªé³çæçæç¨ä»æªå¾å°ååæ¢ç´¢ãä¸»æµçæå­è½èªé³ç³»çµ±ä¸»è¦å°è¼¸åºæ å°å°é »è­ç©ºéä¸­çæ¢ç¾é »è­åï¼ç±æ¼æ¢ç¾é »è­åçç¨çæ§ï¼å°è´é«éç®è² è¼ãçºäºè§£æ±ºéäºéå¶ï¼æåæåºäº LatentSpeechï¼ä¸ç¨®å©ç¨æ½å¨æ´æ£æ¨¡åçæ°å TTS çææ¹æ³ãééä½¿ç¨æ½å¨åµå¥ä½çºä¸­éè¡¨ç¤ºï¼LatentSpeech å°ç®æ¨ç¶­åº¦æ¸å°å°æ¢ç¾é »è­åæéç¶­åº¦ç 5%ï¼ç°¡åäº TTS ç·¨ç¢¼å¨åèªé³ç·¨ç¢¼å¨çèçï¼ä¸¦å¯¦ç¾äºé«æçé«åè³ªèªé³çæãéé ç ç©¶æ¨èªèæ½å¨æ´æ£æ¨¡åé¦æ¬¡æ´åå° TTS ä¸­ï¼å¢å¼·äºçæèªé³çæºç¢ºæ§åèªç¶æ§ãåºæºè³æéä¸çå¯¦é©çµæè¡¨æï¼èç¾ææ¨¡åç¸æ¯ï¼LatentSpeech çå­åé¯èª¤çæé«äº 25%ï¼æ¢ç¾åé »è­å¤±çæé«äº 24%ï¼èé¨èè¨ç·´è³æçå¢å ï¼é²ä¸æ­¥çæ¹ååå¥éå° 49.5% å 26%ãéäºç¼ç¾çªé¡¯äº LatentSpeech æ¨å TTS æè¡é²æ­¥çæ½åã

##### **Aligner-Guided Training Paradigm: Advancing Text-to-Speech Models with Aligner Guided Duration**
2412.08112v1 by Haowei Lou, Helen Paik, Wen Hu, Lina Yao

Recent advancements in text-to-speech (TTS) systems, such as FastSpeech and
StyleSpeech, have significantly improved speech generation quality. However,
these models often rely on duration generated by external tools like the
Montreal Forced Aligner, which can be time-consuming and lack flexibility. The
importance of accurate duration is often underestimated, despite their crucial
role in achieving natural prosody and intelligibility. To address these
limitations, we propose a novel Aligner-Guided Training Paradigm that
prioritizes accurate duration labelling by training an aligner before the TTS
model. This approach reduces dependence on external tools and enhances
alignment accuracy. We further explore the impact of different acoustic
features, including Mel-Spectrograms, MFCCs, and latent features, on TTS model
performance. Our experimental results show that aligner-guided duration
labelling can achieve up to a 16\% improvement in word error rate and
significantly enhance phoneme and tone alignment. These findings highlight the
effectiveness of our approach in optimizing TTS systems for more natural and
intelligible speech generation.

æè¦ï¼è¿æçæå­è½èªé³ (TTS) ç³»çµ±é²å±ï¼ä¾å¦ FastSpeech å StyleSpeechï¼å·²é¡¯èæåèªé³ç¢çåè³ªãç¶èï¼éäºæ¨¡åéå¸¸ä¾è³´ç±å¤é¨å·¥å·ç¢ççæé·ï¼ä¾å¦ Montreal Forced Alignerï¼éå¯è½æèæä¸ç¼ºä¹å½æ§ãåç®¡æºç¢ºæé·å¨éæèªç¶é³å¾åæ¸æ°åº¦æ¹é¢æ®æ¼è³ééè¦çè§è²ï¼å¶éè¦æ§å»å¸¸å¸¸è¢«ä½ä¼°ãçºäºè§£æ±ºéäºéå¶ï¼æåæåºä¸åæ°ç©ç Aligner å¼å°è¨ç·´ç¯ä¾ï¼å¶åªåèéæºç¢ºæé·æ¨ç±¤ï¼ä¸¦å¨ TTS æ¨¡åä¹åè¨ç·´ä¸å Alignerãæ­¤æ¹æ³æ¸å°å°å¤é¨å·¥å·çä¾è³´ï¼ä¸¦æåå°é½æºç¢ºåº¦ãæåé²ä¸æ­¥æ¢è¨ä¸åè²å­¸ç¹å¾µï¼åæ¬æ¢ç¾é »è­åãMFCC åæ½å¨ç¹å¾µï¼å° TTS æ¨¡åæè½çå½±é¿ãæåçå¯¦é©çµæé¡¯ç¤ºï¼Aligner å¼å°æé·æ¨ç±¤å¯ä»¥éææé« 16% çå­åé¯èª¤çæ¹åï¼ä¸¦é¡¯èæåé³ç´ åè²èª¿å°é½ãéäºç¼ç¾çªé¡¯æåçæ¹æ³å¨æä½³å TTS ç³»çµ±ä»¥ç¢çæ´èªç¶ä¸æ¸æ°çèªé³æ¹é¢çææã

##### **Seeing Syntax: Uncovering Syntactic Learning Limitations in Vision-Language Models**
2412.08111v1 by Sri Harsha Dumpala, David Arps, Sageev Oore, Laura Kallmeyer, Hassan Sajjad

Vision-language models (VLMs), serve as foundation models for multi-modal
applications such as image captioning and text-to-image generation. Recent
studies have highlighted limitations in VLM text encoders, particularly in
areas like compositionality and semantic understanding, though the underlying
reasons for these limitations remain unclear. In this work, we aim to address
this gap by analyzing the syntactic information, one of the fundamental
linguistic properties, encoded by the text encoders of VLMs. We perform a
thorough analysis comparing VLMs with different objective functions, parameter
size and training data size, and with uni-modal language models (ULMs) in their
ability to encode syntactic knowledge. Our findings suggest that ULM text
encoders acquire syntactic information more effectively than those in VLMs. The
syntactic information learned by VLM text encoders is shaped primarily by the
pre-training objective, which plays a more crucial role than other factors such
as model architecture, model size, or the volume of pre-training data. Models
exhibit different layer-wise trends where CLIP performance dropped across
layers while for other models, middle layers are rich in encoding syntactic
knowledge.

æè¦ï¼è¦è¦ºèªè¨æ¨¡å (VLM) æ¯å¤æ¨¡ææç¨ç¨å¼çåºç¤æ¨¡åï¼ä¾å¦å½±åæ¨é¡åæå­è½å½±åçæãæè¿çç ç©¶å¼·èª¿äº VLM æå­ç·¨ç¢¼å¨çéå¶ï¼ç¹å¥æ¯å¨çµåæ§åèªç¾©çè§£ç­é åï¼åç®¡éäºéå¶çæ ¹æ¬åå ä»ä¸æ¸æ¥ãå¨éé å·¥ä½ä¸­ï¼æåæ¨å¨ééåæèªæ³è³è¨ï¼èªè¨åºæ¬å±¬æ§ä¹ä¸ï¼ä¾è§£æ±ºéåå·®è·ï¼ç± VLM çæå­ç·¨ç¢¼å¨ç·¨ç¢¼ãæåå·è¡äºä¸é å¾¹åºçåæï¼æ¯è¼å·æä¸åç®æ¨å½æ¸ãåæ¸å¤§å°åè¨ç·´è³æå¤§å°ç VLMï¼ä»¥åå¨å¶ç·¨ç¢¼èªæ³ç¥è­çè½åä¸­å·æå®æ¨¡æèªè¨æ¨¡å (ULM)ãæåçç ç©¶çµæè¡¨æï¼ULM æå­ç·¨ç¢¼å¨æ¯ VLM ä¸­çç·¨ç¢¼å¨æ´ææå°ç²åèªæ³è³è¨ãVLM æå­ç·¨ç¢¼å¨å­¸ç¿å°çèªæ³è³è¨ä¸»è¦ç±é è¨ç·´ç®æ¨å½¢æï¼å®æ¯å¶ä»å ç´ ï¼ä¾å¦æ¨¡åæ¶æ§ãæ¨¡åå¤§å°æé è¨ç·´è³æéï¼æ®æ¼æ´éè¦çè§è²ãæ¨¡åå±ç¾åºä¸åçéå±¤è¶¨å¢ï¼å¶ä¸­ CLIP æ§è½å¨åå±¤ä¸éï¼èå°æ¼å¶ä»æ¨¡åï¼ä¸­éå±¤å¯å«ç·¨ç¢¼èªæ³ç¥è­ã

##### **Barking Up The Syntactic Tree: Enhancing VLM Training with Syntactic Losses**
2412.08110v1 by Jiayun Luo, Mir Rayat Imtiaz Hossain, Boyang Li, Leonid Sigal

Vision-Language Models (VLMs) achieved strong performance on a variety of
tasks (e.g., image-text retrieval, visual question answering). However, most
VLMs rely on coarse-grained image-caption pairs for alignment, relying on data
volume to resolve ambiguities and ground linguistic concepts in images. The
richer semantic and syntactic structure within text is largely overlooked. To
address this, we propose HIerarchically STructured Learning (HIST) that
enhances VLM training without any additional supervision, by hierarchically
decomposing captions into the constituent Subject, Noun Phrases, and Composite
Phrases. Entailment between these constituent components allows us to formulate
additional regularization constraints on the VLM attention maps. Specifically,
we introduce two novel loss functions: (1) Subject Loss, which aligns image
content with the subject of corresponding phrase, acting as an entailment of
standard contrastive/matching losses at the Phrase level; (2) Addition Loss, to
balance attention across multiple objects. HIST is general, and can be applied
to any VLM for which attention between vision and language can be computed; we
illustrate its efficacy on BLIP and ALBEF. HIST outperforms baseline VLMs,
achieving up to +9.8% improvement in visual grounding, +6.3% in multi-object
referring segmentation, +1.1% in image-text retrieval, and +0.2% in visual
question answering, underscoring the value of structuring learning in VLMs.

æè¦ï¼è¦è¦ºèªè¨æ¨¡å (VLM) å¨åç¨®ä»»åä¸ (ä¾å¦ï¼å½±åæå­æª¢ç´¢ãè¦è¦ºåé¡è§£ç­) çæå¼·åçè¡¨ç¾ãç¶èï¼å¤§å¤æ¸ VLM ä¾è³´ç²ç¥çå½±åæ¨é¡éå°ä¾å°é½ï¼ä»°è³´è³æéä¾è§£æ±ºæ­§ç¾©ä¸¦å¨å½±åä¸­å»ºç«èªè¨æ¦å¿µãææ¬ä¸­æ´è±å¯çèªæåèªæ³çµæ§å¨å¾å¤§ç¨åº¦ä¸è¢«å¿½ç¥äºãçºäºè§£æ±ºéååé¡ï¼æåæåºåå±¤çµæ§å­¸ç¿ (HIST)ï¼ééå°æ¨é¡åå±¤åè§£çºæ§æä¸»è©ãåè©çèªåè¤åçèªï¼å¨æ²æä»»ä½é¡å¤ç£ç£çææ³ä¸å¢å¼· VLM è¨ç·´ãéäºæ§ææåä¹éçèæ¶µéä¿è®æåè½å¤ å¶å® VLM æ³¨æååä¸çé¡å¤æ­£ååç´æãå·é«ä¾èªªï¼æåå¼å¥äºå©åæ°ç©çæå¤±å½æ¸ï¼(1) ä¸»è©æå¤±ï¼å°å½±åå§å®¹èå°æçèªçä¸»è©å°é½ï¼ä½çºçèªå±¤ç´æ¨æºå°æ¯/å¹éæå¤±çèæ¶µéä¿ï¼(2) å æ³æå¤±ï¼å¹³è¡¡å¤åç©ä»¶çæ³¨æåãHIST æ¯éç¨çï¼ä¸¦ä¸å¯ä»¥æç¨æ¼ä»»ä½å¯ä»¥è¨ç®è¦è¦ºåèªè¨ä¹éæ³¨æåç VLMï¼æåèªªæäºå®å¨ BLIP å ALBEF ä¸çåæãHIST åªæ¼åºæº VLMï¼å¨è¦è¦ºåºç¤ä¸æåäº +9.8%ï¼å¨å¤ç©ä»¶åèåå²ä¸æåäº +6.3%ï¼å¨å½±åæå­æª¢ç´¢ä¸æåäº +1.1%ï¼å¨è¦è¦ºåé¡è§£ç­ä¸æåäº +0.2%ï¼å¼·èª¿äºå¨ VLM ä¸­å»ºæ§å­¸ç¿çå¹å¼ã

##### **Unseen Horizons: Unveiling the Real Capability of LLM Code Generation Beyond the Familiar**
2412.08109v1 by Yuanliang Zhang, Yifan Xie, Shanshan Li, Ke Liu, Chong Wang, Zhouyang Jia, Xiangbing Huang, Jie Song, Chaopeng Luo, Zhizheng Zheng, Rulin Xu, Yitong Liu, Si Zheng, Xiangke Liao

Recently, large language models (LLMs) have shown strong potential in code
generation tasks. However, there are still gaps before they can be fully
applied in actual software development processes. Accurately assessing the code
generation capabilities of large language models has become an important basis
for evaluating and improving the models. Some existing works have constructed
datasets to evaluate the capabilities of these models. However, the current
evaluation process may encounter the illusion of "Specialist in Familiarity",
primarily due to three gaps: the exposure of target code, case timeliness, and
dependency availability. The fundamental reason for these gaps is that the code
in current datasets may have been extensively exposed and exercised during the
training phase, and due to the continuous training and development of LLM,
their timeliness has been severely compromised. The key to solve the problem is
to, as much as possible, evaluate the LLMs using code that they have not
encountered before. Thus, the fundamental idea in this paper is to draw on the
concept of code obfuscation, changing code at different levels while ensuring
the functionality and output. To this end, we build a code-obfuscation based
benchmark OBFUSEVAL. We first collect 1,354 raw cases from five real-world
projects, including function description and code. Then we use three-level
strategy (symbol, structure and semantic) to obfuscate descriptions, code and
context dependencies. We evaluate four LLMs on OBFU- SEVAL and compared the
effectiveness of different obfuscation strategy. We use official test suites of
these projects to evaluate the generated code. The results show that after
obfuscation, the average decrease ratio of test pass rate can up to 62.5%.

æè¦ï¼<paragraph>æè¿ï¼å¤§åè¯­è¨æ¨¡åï¼LLMï¼å¨ä»£ç çæä»»å¡ä¸­æ¾ç¤ºåºå¼ºå¤§çæ½åãç¶èï¼å¨å®ä»¬è½å®å¨åºç¨äºå®éè½¯ä»¶å¼åæµç¨ä¹åï¼ä»å­å¨å·®è·ãåç¡®è¯ä¼°å¤§åè¯­è¨æ¨¡åçä»£ç çæè½åå·²æä¸ºè¯ä¼°åæ¹è¿æ¨¡åçéè¦åºç¡ãä¸äºç°æå·¥ä½å·²ç»æå»ºäºæ°æ®éæ¥è¯ä¼°è¿äºæ¨¡åçè½åãç¶èï¼å½åçè¯ä¼°è¿ç¨å¯è½ä¼éå°âçè½çå·§âçéè§ï¼è¿ä¸»è¦æ¯ç±äºä¸ä¸ªå·®è·ï¼ç®æ ä»£ç çæ´é²ãæ¡ä¾æ¶ææ§åä¾èµæ§å¯ç¨æ§ãè¿äºå·®è·çæ ¹æ¬åå å¨äºï¼å½åæ°æ®éä¸­çä»£ç å¯è½å¨è®­ç»é¶æ®µå·²ç»å¾å°å¹¿æ³çæ´é²åç»ä¹ ï¼å¹¶ä¸ç±äº LLM çæç»­è®­ç»åå¼åï¼å®ä»¬çæ¶é´æ§åå°äºä¸¥éæå®³ãè§£å³è¯¥é®é¢çå³é®æ¯å°½å¯è½ä½¿ç¨ LLM ä¹åæªéå°è¿çä»£ç æ¥è¯ä¼° LLMãå æ­¤ï¼æ¬æçåºæ¬ææ³æ¯åé´ä»£ç æ··æ·çæ¦å¿µï¼å¨ç¡®ä¿åè½åè¾åºçåæ¶æ¹åä¸åçº§å«çä»£ç ãä¸ºæ­¤ï¼æä»¬æå»ºäºä¸ä¸ªåºäºä»£ç æ··æ·çåºå OBFUSEVALãæä»¬é¦åä»äºä¸ªçå®é¡¹ç®ä¸­æ¶éäº 1,354 ä¸ªåå§æ¡ä¾ï¼åæ¬åè½æè¿°åä»£ç ãç¶åï¼æä»¬ä½¿ç¨ä¸çº§ç­ç¥ï¼ç¬¦å·ãç»æåè¯­ä¹ï¼æ¥æ··æ·æè¿°ãä»£ç åä¸ä¸æä¾èµæ§ãæä»¬å¨ OBFU-SEVAL ä¸è¯ä¼°äºåä¸ª LLMï¼å¹¶æ¯è¾äºä¸åæ··æ·ç­ç¥çæææ§ãæä»¬ä½¿ç¨è¿äºé¡¹ç®çå®æ¹æµè¯å¥ä»¶æ¥è¯ä¼°çæçä»£ç ãç»æè¡¨æï¼æ··æ·åï¼æµè¯éè¿ççå¹³åä¸éçå¯è¾¾ 62.5%ã</paragraph>

##### **Doubly-Universal Adversarial Perturbations: Deceiving Vision-Language Models Across Both Images and Text with a Single Perturbation**
2412.08108v1 by Hee-Seon Kim, Minbeom Kim, Changick Kim

Large Vision-Language Models (VLMs) have demonstrated remarkable performance
across multimodal tasks by integrating vision encoders with large language
models (LLMs). However, these models remain vulnerable to adversarial attacks.
Among such attacks, Universal Adversarial Perturbations (UAPs) are especially
powerful, as a single optimized perturbation can mislead the model across
various input images. In this work, we introduce a novel UAP specifically
designed for VLMs: the Doubly-Universal Adversarial Perturbation (Doubly-UAP),
capable of universally deceiving VLMs across both image and text inputs. To
successfully disrupt the vision encoder's fundamental process, we analyze the
core components of the attention mechanism. After identifying value vectors in
the middle-to-late layers as the most vulnerable, we optimize Doubly-UAP in a
label-free manner with a frozen model. Despite being developed as a black-box
to the LLM, Doubly-UAP achieves high attack success rates on VLMs, consistently
outperforming baseline methods across vision-language tasks. Extensive ablation
studies and analyses further demonstrate the robustness of Doubly-UAP and
provide insights into how it influences internal attention mechanisms.

æè¦ï¼å¤§åè¦è¦ºèªè¨æ¨¡å (VLM) ééæ´åè¦è¦ºç·¨ç¢¼å¨èå¤§åèªè¨æ¨¡å (LLM)ï¼å¨å¤æ¨¡æä»»åä¸­å±ç¾åºåè¶çæè½ãç¶èï¼éäºæ¨¡åä»ç¶å®¹æåå°å°ææ§æ»æãå¨éäºæ»æä¸­ï¼éç¨å°ææ¾å (UAP) ç¹å¥å¼·å¤§ï¼å çºå®ä¸æä½³åçæ¾åå¯ä»¥èª¤å°æ¨¡åè·¨è¶åç¨®è¼¸å¥å½±åãå¨éé å·¥ä½ä¸­ï¼æåå¼å¥ä¸ç¨®å°éçº VLM è¨­è¨çæ°å UAPï¼éééç¨å°ææ¾å (Doubly-UAP)ï¼å®è½å¤ æ®éæ¬ºé¨è·¨è¶å½±ååæå­è¼¸å¥ç VLMãçºäºæåç ´å£è¦è¦ºç·¨ç¢¼å¨çåºæ¬éç¨ï¼æååæäºæ³¨æåæ©å¶çæ ¸å¿çµæé¨åãå¨å°ä¸­éå°å¾é¢çå±¤ä¸­çå¼åéè­å¥çºæèå¼±çå±¤å¾ï¼æåä½¿ç¨åçµæ¨¡åä»¥ç¡æ¨ç±¤çæ¹å¼æä½³å Doubly-UAPãåç®¡æ¯ä½çº LLM çé»çå­éç¼ï¼Doubly-UAP å¨ VLM ä¸å¯¦ç¾äºå¾é«çæ»ææåçï¼å¨è¦è¦ºèªè¨ä»»åä¸­å§çµåªæ¼åºç·æ¹æ³ãå»£æ³çæ¶èç ç©¶ååæé²ä¸æ­¥è­æäº Doubly-UAP çç©©å¥æ§ï¼ä¸¦æä¾äºå®å¦ä½å½±é¿å§é¨æ³¨æåæ©å¶çè¦è§£ã

##### **Adversarial Vulnerabilities in Large Language Models for Time Series Forecasting**
2412.08099v1 by Fuqiang Liu, Sicong Jiang, Luis Miranda-Moreno, Seongjin Choi, Lijun Sun

Large Language Models (LLMs) have recently demonstrated significant potential
in the field of time series forecasting, offering impressive capabilities in
handling complex temporal data. However, their robustness and reliability in
real-world applications remain under-explored, particularly concerning their
susceptibility to adversarial attacks. In this paper, we introduce a targeted
adversarial attack framework for LLM-based time series forecasting. By
employing both gradient-free and black-box optimization methods, we generate
minimal yet highly effective perturbations that significantly degrade the
forecasting accuracy across multiple datasets and LLM architectures. Our
experiments, which include models like TimeGPT and LLM-Time with GPT-3.5,
GPT-4, LLaMa, and Mistral, show that adversarial attacks lead to much more
severe performance degradation than random noise, and demonstrate the broad
effectiveness of our attacks across different LLMs. The results underscore the
critical vulnerabilities of LLMs in time series forecasting, highlighting the
need for robust defense mechanisms to ensure their reliable deployment in
practical applications.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) è¿æå¨æéåºåé æ¸¬é åå±ç¤ºäºé¡¯èçæ½åï¼å¨èçè¤éæéæ¸ææ¹é¢å±ç¾äºä»¤äººå°è±¡æ·±å»çè½åãç¶èï¼å®åå¨å¯¦éæç¨ä¸­çç©©å¥æ§åå¯é æ§ä»æªå¾å°ååæ¢è¨ï¼ç¹å¥æ¯éæ¼å®åå°å°ææ§æ»æçæææ§ãå¨æ¬æä¸­ï¼æåå¼å¥äºä¸åéå° LLM æéåºåé æ¸¬çç®æ¨å°ææ§æ»ææ¡æ¶ãééæ¡ç¨ç¡æ¢¯åº¦åé»çåªåæ¹æ³ï¼æåçæäºæ¥µå°ä½é«æççæ¾åï¼éäºæ¾åæé¡¯èéä½å¤åè³æéå LLM æ¶æ§çé æ¸¬æºç¢ºåº¦ãæåçå¯¦é©åæ¬ TimeGPT å LLM-Time ç­æ¨¡åï¼ä»¥å GPT-3.5ãGPT-4ãLLaMa å Mistralï¼çµæé¡¯ç¤ºå°ææ§æ»æå°è´çæè½ä¸éé æ¯é¨æ©éè¨å´éï¼ä¸¦è­æäºæåçæ»æå¨ä¸å LLM ä¸­çå»£æ³æææ§ãéäºçµæå¼·èª¿äº LLM å¨æéåºåé æ¸¬ä¸­çééµæ¼æ´ï¼çªé¡¯äºå¨å¯¦éæç¨ä¸­ç¢ºä¿å®åå¯é é¨ç½²çå¿è¦æ§ã

##### **What You See Is Not Always What You Get: An Empirical Study of Code Comprehension by Large Language Models**
2412.08098v1 by Bangshuo Zhu, Jiawen Wen, Huaming Chen

Recent studies have demonstrated outstanding capabilities of large language
models (LLMs) in software engineering domain, covering numerous tasks such as
code generation and comprehension. While the benefit of LLMs for coding task is
well noted, it is perceived that LLMs are vulnerable to adversarial attacks. In
this paper, we study the specific LLM vulnerability to imperceptible character
attacks, a type of prompt-injection attack that uses special characters to
befuddle an LLM whilst keeping the attack hidden to human eyes. We devise four
categories of attacks and investigate their effects on the performance outcomes
of tasks relating to code analysis and code comprehension. Two generations of
ChatGPT are included to evaluate the impact of advancements made to
contemporary models. Our experimental design consisted of comparing perturbed
and unperturbed code snippets and evaluating two performance outcomes, which
are model confidence using log probabilities of response, and correctness of
response. We conclude that earlier version of ChatGPT exhibits a strong
negative linear correlation between the amount of perturbation and the
performance outcomes, while the recent ChatGPT presents a strong negative
correlation between the presence of perturbation and performance outcomes, but
no valid correlational relationship between perturbation budget and performance
outcomes. We anticipate this work contributes to an in-depth understanding of
leveraging LLMs for coding tasks. It is suggested future research should delve
into how to create LLMs that can return a correct response even if the prompt
exhibits perturbations.

æè¦ï¼<paragraph>æè¿çç ç©¶å·²è­æå¤§åèªè¨æ¨¡å (LLM) å¨è»é«å·¥ç¨é åå·æååºçè½åï¼æ¶µèäºè¨±å¤ä»»åï¼ä¾å¦ç¨å¼ç¢¼ç¢çåçè§£ãéç¶ LLM å°ç·¨ç¢¼ä»»åçå¥½èå·²å»£çºäººç¥ï¼ä½ LLM è¢«èªçºå®¹æåå°å°ææ§æ»æãå¨æ¬æä¸­ï¼æåç ç©¶äº LLM å°é£ä»¥å¯è¦ºçå­åæ»æçå·é«æ¼æ´ï¼éæ¯ä¸ç¨®æç¤ºæ³¨å¥æ»æï¼å®ä½¿ç¨ç¹æ®å­åä¾æ··æ· LLMï¼åæè®æ»æå°äººç¼é±èãæåè¨­è¨äºåç¨®é¡åçæ»æï¼ä¸¦ç ç©¶å®åå°èç¨å¼ç¢¼åæåç¨å¼ç¢¼çè§£ç¸éä»»åçæè½çµæçå½±é¿ãåå«å©ä»£ ChatGPT ä»¥è©ä¼°å°ç¶ä»£æ¨¡åæåé²å±çå½±é¿ãæåçå¯¦é©è¨­è¨åæ¬æ¯è¼æ¾ååæªæ¾åçç¨å¼ç¢¼çæ®µï¼ä¸¦è©ä¼°å©åæè½çµæï¼åå¥æ¯ä½¿ç¨åæçå°æ¸æ©ççæ¨¡åä¿¡å¿ï¼ä»¥ååæçæ­£ç¢ºæ§ãæåå¾åºççµè«æ¯ï¼è¼æ©çæ¬ç ChatGPT å¨æ¾åéåæè½çµæä¹éè¡¨ç¾åºå¼·ççè² ç·æ§ç¸éæ§ï¼èæè¿ç ChatGPT å¨æ¾åçå­å¨åæè½çµæä¹éè¡¨ç¾åºå¼·ççè² ç¸éæ§ï¼ä½æ¾åé ç®åæè½çµæä¹éæ²æææçç¸ééä¿ãæåé æéé å·¥ä½æå©æ¼æ·±å¥äºè§£å¦ä½å©ç¨ LLM é²è¡ç·¨ç¢¼ä»»åãå»ºè­°æªä¾çç ç©¶ææ·±å¥æ¢è¨å¦ä½å»ºç«å³ä½¿æç¤ºåºç¾æ¾åä¹è½åå³æ­£ç¢ºåæç LLMã</paragraph>

##### **Multilingual LLMs Inherently Reward In-Language Time-Sensitive Semantic Alignment for Low-Resource Languages**
2412.08090v1 by Ashutosh Bajpai, Tanmoy Chakraborty

The unwavering disparity in labeled resources between resource-rich languages
and those considered low-resource remains a significant impediment for Large
Language Models (LLMs). Recent strides in cross-lingual in-context learning
(X-ICL), mainly through semantically aligned examples retrieved from
multilingual pre-trained transformers, have shown promise in mitigating this
issue. However, our investigation reveals that LLMs intrinsically reward
in-language semantically aligned cross-lingual instances over direct
cross-lingual semantic alignments, with a pronounced disparity in handling
time-sensitive queries in the X-ICL setup. Such queries demand sound temporal
reasoning ability from LLMs, yet the advancements have predominantly focused on
English. This study aims to bridge this gap by improving temporal reasoning
capabilities in low-resource languages. To this end, we introduce mTEMPREASON a
temporal reasoning dataset aimed at the varied degrees of low-resource
languages and propose Cross-Lingual Time-Sensitive Semantic Alignment
(CLiTSSA), a novel method to improve temporal reasoning in these contexts. To
facilitate this, we construct an extension of mTEMPREASON comprising pairs of
parallel cross-language temporal queries along with their anticipated
in-language semantic similarity scores. Our empirical evidence underscores the
superior performance of CLiTSSA compared to established baselines across three
languages - Romanian, German, and French, encompassing three temporal tasks and
including a diverse set of four contemporaneous LLMs. This marks a significant
step forward in addressing resource disparity in the context of temporal
reasoning across languages.

æè¦ï¼<paragraph>å¨è³æºè±å¯çèªè¨åè¢«èªçºæ¯ä½è³æºçèªè¨ä¹éæ¨è¨è³æºçå å®å·®ç°ä»ç¶æ¯å¤§åèªè¨æ¨¡å (LLM) çéå¤§éç¤ãæè¿è·¨èªè¨æå¢å­¸ç¿ (X-ICL) çé²å±ï¼ä¸»è¦æ¯ééå¾å¤èªè¨é è¨ç·´è½æå¨ä¸­æ·åçèªç¾©å°é½ç¯ä¾ï¼å·²å±ç¾åºç·©è§£æ­¤åé¡çå¸æãç¶èï¼æåçèª¿æ¥é¡¯ç¤ºï¼LLM æ¬è³ªä¸çåµèªè¨å§èªç¾©å°é½çè·¨èªè¨å¯¦ä¾ï¼èä¸æ¯ç´æ¥çè·¨èªè¨èªç¾©å°é½ï¼å¨èç X-ICL è¨­å®ä¸­çæéæææ¥è©¢ææé¡¯èå·®ç°ãæ­¤é¡æ¥è©¢è¦æ± LLM å·åè¯å¥½çæéæ¨çè½åï¼ä½é²å±ä¸»è¦éä¸­å¨è±èªä¸ãæ¬ç ç©¶æ¨å¨ééæ¹åä½è³æºèªè¨ä¸­çæéæ¨çè½åä¾å½åæ­¤å·®è·ãçºæ­¤ï¼æåå¼å¥äº mTEMPREASONï¼ä¸åéå°ä¸åç¨åº¦ä½è³æºèªè¨çæéæ¨çè³æéï¼ä¸¦æåºäºè·¨èªè¨æéææèªç¾©å°é½ (CLiTSSA)ï¼ä¸ç¨®å¨éäºæå¢ä¸­æ¹åæéæ¨ççæ°æ¹æ³ãçºäºä¿é²éä¸é»ï¼æåå»ºæ§äºä¸å mTEMPREASON å»¶ä¼¸ï¼å¶ä¸­åå«å¹³è¡è·¨èªè¨æéæ¥è©¢å°ä»¥åå®åé æçèªè¨å§èªç¾©ç¸ä¼¼æ§è©åãæåçå¯¦è­è­æå¼·èª¿äº CLiTSSA çæè½åªæ¼ä¸åèªè¨ï¼ç¾é¦¬å°¼äºèªãå¾·èªåæ³èªï¼çæ¢å®åºæºï¼æ¶µèäºä¸åæéä»»åï¼ä¸¦åå«äºååç¶ä»£ LLM çå¤æ¨£åéåãéæ¨èªèå¨è·¨èªè¨æéæ¨çä¸­è§£æ±ºè³æºå·®ç°æ¹é¢éåºäºéè¦ä¸æ­¥ã</paragraph>

##### **How to select slices for annotation to train best-performing deep learning segmentation models for cross-sectional medical images?**
2412.08081v1 by Yixin Zhang, Kevin Kramer, Maciej A. Mazurowski

Automated segmentation of medical images highly depends on the availability
of accurate manual image annotations. Such annotations are very time-consuming
and costly to generate, and often require specialized expertise, particularly
for cross-sectional images which contain many slices for each patient. It is
crucial to ensure the best use of annotation resources. In this paper, we
systematically answer the question of how to select slices of cross-sectional
medical images in order to maximize performance of the resulting deep learning
segmentation models. We conducted experiments on 4 medical imaging segmentation
tasks with varying annotation budgets, numbers of annotated cases, numbers of
annotated slices per volume, slice selection techniques, and mask
interpolations. We found that:
  1) It is almost always preferable to annotate fewer slices per volume and
more volumes given an annotation budget. 2) Selecting slices for annotation by
unsupervised active learning (UAL) is not superior to selecting slices randomly
or at fixed intervals, provided that each volume is allocated the same number
of annotated slices. 3) Interpolating masks between annotated slices rarely
enhances model performance, with exceptions of some specific configuration for
3D models.

æè¦ï¼é«å­¸å½±åçèªåååå²é«åº¦ä¾è³´æ¼æºç¢ºçæåå½±åæ¨è¨»ãæ­¤é¡æ¨è¨»éå¸¸èæä¸çæææ¬é«æï¼ä¸éå¸¸éè¦å°æ¥­ç¥è­ï¼ç¹å¥æ¯å°æ¼æ¯åæ£èåå«è¨±å¤åççæ©«æ·é¢å½±åãç¢ºä¿æä½³å©ç¨æ¨è¨»è³æºè³ééè¦ãå¨æ¬æä¸­ï¼æåç³»çµ±æ§å°åç­äºå¦ä½é¸ææ©«æ·é¢é«å­¸å½±ååçä»¥æå¤§åæ·±åº¦å­¸ç¿åå²æ¨¡åæè½çåé¡ãæåéå° 4 é é«å­¸å½±ååå²ä»»åé²è¡äºå¯¦é©ï¼éäºä»»åå·æä¸åçæ¨è¨»é ç®ãæ¨è¨»æ¡ä¾æ¸ãæ¯åé«ç©çæ¨è¨»åçæ¸ãåçé¸ææè¡åé®ç½©å§æãæåç¼ç¾ï¼
1) å¨çµ¦å®æ¨è¨»é ç®çææ³ä¸ï¼å¹¾ä¹ç¸½æ¯åªåæ¨è¨»æ¯åé«ç©è¼å°åçåæ´å¤é«ç©ã2) éééç£ç£ä¸»åå­¸ç¿ (UAL) é¸æåçé²è¡æ¨è¨»ä¸¦ä¸åªæ¼é¨æ©æåºå®ééé¸æåçï¼åææ¯æ¯åé«ç©åéçæ¨è¨»åçæ¸ç¸åã3) å¨æ¨è¨»åçä¹éå§æé®ç½©å¾å°è½æåæ¨¡åæè½ï¼ä½æäº 3D æ¨¡åçç¹å®çµæé¤å¤ã

##### **Using Large Language Models for Parametric Shape Optimization**
2412.08072v1 by Xinxin Zhang, Zhuoqun Xu, Guangpu Zhu, Chien Ming Jonathan Tay, Yongdong Cui, Boo Cheong Khoo, Lailai Zhu

Recent advanced large language models (LLMs) have showcased their emergent
capability of in-context learning, facilitating intelligent decision-making
through natural language prompts without retraining. This new machine learning
paradigm has shown promise in various fields, including general control and
optimization problems. Inspired by these advancements, we explore the potential
of LLMs for a specific and essential engineering task: parametric shape
optimization (PSO). We develop an optimization framework, LLM-PSO, that
leverages an LLM to determine the optimal shape of parameterized engineering
designs in the spirit of evolutionary strategies. Utilizing the ``Claude 3.5
Sonnet'' LLM, we evaluate LLM-PSO on two benchmark flow optimization problems,
specifically aiming to identify drag-minimizing profiles for 1) a
two-dimensional airfoil in laminar flow, and 2) a three-dimensional
axisymmetric body in Stokes flow. In both cases, LLM-PSO successfully
identifies optimal shapes in agreement with benchmark solutions. Besides, it
generally converges faster than other classical optimization algorithms. Our
preliminary exploration may inspire further investigations into harnessing LLMs
for shape optimization and engineering design more broadly.

æè¦ï¼æè¿çåè¿å¤§åè¯­è¨æ¨¡å (LLM) å±ç¤ºäºå®ä»¬å¨æå¢å­¦ä¹ ä¸­çæ°å´è½åï¼éè¿èªç¶è¯­è¨æç¤ºä¿è¿æºè½å³ç­å¶å®ï¼èæ ééæ°è®­ç»ãè¿ç§æ°çæºå¨å­¦ä¹ èä¾å¨åä¸ªé¢åé½æ¾ç¤ºåºåæ¯ï¼åæ¬éç¨æ§å¶åä¼åé®é¢ãåè¿äºè¿æ­¥çå¯åï¼æä»¬æ¢ç´¢äº LLM å¨ç¹å®ä¸å¿è¦çå·¥ç¨ä»»å¡ä¸­çæ½åï¼åæ°åå½¢ç¶ä¼å (PSO)ãæä»¬å¼åäºä¸ä¸ªä¼åæ¡æ¶ LLM-PSOï¼å®å©ç¨ LLM æ ¹æ®è¿åç­ç¥çç²¾ç¥ç¡®å®åæ°åå·¥ç¨è®¾è®¡çæä½³å½¢ç¶ãå©ç¨ ``Claude 3.5 Sonnet'' LLMï¼æä»¬å¨ä¸¤ä¸ªåºåæµä¼åé®é¢ä¸è¯ä¼° LLM-PSOï¼å·ä½ç®æ æ¯è¯å«é»åæå°çè½®å»ï¼ç¨äº 1) å±æµä¸­çäºç»´æºç¿¼å 2) æ¯æåæ¯æµä¸­çä¸ç»´è½´å¯¹ç§°ä½ãå¨è¿ä¸¤ç§æåµä¸ï¼LLM-PSO é½æåè¯å«åºä¸åºåè§£å³æ¹æ¡ä¸è´çæä½³å½¢ç¶ãæ­¤å¤ï¼å®éå¸¸æ¯å¶ä»ç»å¸ä¼åç®æ³æ¶æå¾æ´å¿«ãæä»¬çåæ­¥æ¢ç´¢å¯è½ä¼æ¿åè¿ä¸æ­¥çç ç©¶ï¼ä»¥å©ç¨ LLM æ´å¹¿æ³å°è¿è¡å½¢ç¶ä¼ååå·¥ç¨è®¾è®¡ã

##### **DialogAgent: An Auto-engagement Agent for Code Question Answering Data Production**
2412.08069v1 by Xiaoyun Liang, Jingyi Ren, Jiayi Qi, Chao Peng, Bo Jiang

Large Language Models (LLMs) have become increasingly integral to enhancing
developer productivity, particularly in code generation, comprehension, and
repair tasks. However, fine-tuning these models with high-quality, real-world
data is challenging due to privacy concerns and the lack of accessible, labeled
datasets. In this paper, we present DialogAgent, an automated tool for
generating synthetic training data that closely mimics real developer
interactions within Integrated Development Environments (IDEs). DialogAgent
enables the production of diverse, high-fidelity query-response pairs by
simulating multi-turn dialogues and contextual behaviors observed in real-world
programming scenarios. The tool significantly reduces the reliance on manual
data generation, increasing efficiency by 4.8 times compared to traditional
methods. Our experiments and online deployment demonstrate substantial
improvements in model performance for code-related question-answering tasks:
the acceptance rate of responses generated by our in-house model is improved by
33%, after training on synthesized data generated by DialogAgent.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å·²æ¥çæçºæåéç¼äººå¡çç¢åçéè¦çµæé¨åï¼ç¹å¥æ¯å¨ç¨å¼ç¢¼çæãçè§£åä¿®å¾©ä»»åä¸­ãç¶èï¼ç±æ¼é±ç§åé¡åå¯å­åæ¨è¨è³æéçç¼ºä¹ï¼ä½¿ç¨é«åè³ªççå¯¦ä¸çè³æå¾®èª¿éäºæ¨¡åå·æææ°æ§ãå¨æ¬æä¸­ï¼æåæåº DialogAgentï¼éæ¯ä¸ç¨®èªååå·¥å·ï¼ç¨æ¼çæåæè¨ç·´è³æï¼è©²è³æå¯ä»¥ç·å¯æ¨¡æ¬æ´åéç¼ç°å¢ (IDE) ä¸­ççå¯¦éç¼äººå¡äºåãDialogAgent ééæ¨¡æ¬çå¯¦ä¸çç¨å¼è¨­è¨å ´æ¯ä¸­è§å¯å°çå¤è¼ªå°è©±åæå¢è¡çºï¼è½å¤ ç¢çå¤æ¨£åãé«ä¿çåº¦çæ¥è©¢åæéå°ãæ­¤å·¥å·å¤§å¹æ¸å°å°æåè³æçæçä¾è³´ï¼èå³çµ±æ¹æ³ç¸æ¯ï¼æçæé« 4.8 åãæåçå¯¦é©åç·ä¸é¨ç½²è­æäºç¨å¼ç¢¼ç¸éåé¡åç­ä»»åçæ¨¡åæè½æå¤§å¹é²æ­¥ï¼å¨ç¶é DialogAgent çæçåæè³æè¨ç·´å¾ï¼æåå§é¨æ¨¡åç¢ççåææ¥åçæé«äº 33%ã

##### **Repository-Level Graph Representation Learning for Enhanced Security Patch Detection**
2412.08068v1 by Xin-Cheng Wen, Zirui Lin, Cuiyun Gao, Hongyu Zhang, Yong Wang, Qing Liao

Software vendors often silently release security patches without providing
sufficient advisories (e.g., Common Vulnerabilities and Exposures) or delayed
updates via resources (e.g., National Vulnerability Database). Therefore, it
has become crucial to detect these security patches to ensure secure software
maintenance. However, existing methods face the following challenges: (1) They
primarily focus on the information within the patches themselves, overlooking
the complex dependencies in the repository. (2) Security patches typically
involve multiple functions and files, increasing the difficulty in well
learning the representations. To alleviate the above challenges, this paper
proposes a Repository-level Security Patch Detection framework named RepoSPD,
which comprises three key components: 1) a repository-level graph construction,
RepoCPG, which represents software patches by merging pre-patch and post-patch
source code at the repository level; 2) a structure-aware patch representation,
which fuses the graph and sequence branch and aims at comprehending the
relationship among multiple code changes; 3) progressive learning, which
facilitates the model in balancing semantic and structural information. To
evaluate RepoSPD, we employ two widely-used datasets in security patch
detection: SPI-DB and PatchDB. We further extend these datasets to the
repository level, incorporating a total of 20,238 and 28,781 versions of
repository in C/C++ programming languages, respectively, denoted as SPI-DB* and
PatchDB*. We compare RepoSPD with six existing security patch detection methods
and five static tools. Our experimental results demonstrate that RepoSPD
outperforms the state-of-the-art baseline, with improvements of 11.90%, and
3.10% in terms of accuracy on the two datasets, respectively.

æè¦ï¼<paragraph>è»é«ä¾æåéå¸¸æå¨æ²ææä¾è¶³å¤ çè«®è©¢ï¼ä¾å¦å¸¸è¦æ¼æ´åæéªï¼æå»¶é²ééè³æºï¼ä¾å¦åå®¶æ¼æ´è³æåº«ï¼æ´æ°çææ³ä¸ï¼ç¡è²å°ç¼å¸å®å¨æ§ä¿®è£ç¨å¼ãå æ­¤ï¼åµæ¸¬éäºå®å¨æ§ä¿®è£ç¨å¼ä»¥ç¢ºä¿è»é«ç¶­è­·å®å¨è³ééè¦ãç¶èï¼ç¾ææ¹æ³é¢è¨ä»¥ä¸ææ°ï¼(1) å®åä¸»è¦éæ³¨ä¿®è£ç¨å¼æ¬èº«çè³è¨ï¼å¿½ç¥äºå²å­åº«ä¸­è¤éçç¸ä¾æ§ã(2) å®å¨æ§ä¿®è£ç¨å¼éå¸¸æ¶åå¤åå½å¼åæªæ¡ï¼å¢å äºè¯å¥½å­¸ç¿è¡¨ç¤ºå½¢å¼çé£åº¦ãçºäºç·©è§£ä¸è¿°ææ°ï¼æ¬ææåºäºä¸ååçº RepoSPD çå²å­åº«å±¤ç´å®å¨æ§ä¿®è£ç¨å¼åµæ¸¬æ¶æ§ï¼å®åå«ä¸åééµåä»¶ï¼1) å²å­åº«å±¤ç´åå½¢å»ºæ§ï¼RepoCPGï¼å®ééåä½µå²å­åº«å±¤ç´çåä¿®è£ç¨å¼åå¾ä¿®è£ç¨å¼åå§ç¢¼ä¾è¡¨ç¤ºè»é«ä¿®è£ç¨å¼ï¼2) çµæ§æç¥ä¿®è£ç¨å¼è¡¨ç¤ºå½¢å¼ï¼å®èåäºåå½¢ååºååæ¯ï¼æ¨å¨çè§£å¤åç¨å¼ç¢¼è®æ´ä¹éçéä¿ï¼3) æ¼¸é²å¼å­¸ç¿ï¼å®æå©æ¼æ¨¡åå¹³è¡¡èªæåçµæ§è³è¨ãçºäºè©ä¼° RepoSPDï¼æåå¨å®å¨æ§ä¿®è£ç¨å¼åµæ¸¬ä¸­æ¡ç¨äºå©åå»£æ³ä½¿ç¨çè³æéï¼SPI-DB å PatchDBãæåé²ä¸æ­¥å°éäºè³æéæ´åå¥ä»¶å°å²å­åº«å±¤ç´ï¼åå¥ç´å¥äº C/C++ ç¨å¼èªè¨ä¸­ç¸½è¨ 20,238 å 28,781 åçæ¬çå²å­åº«ï¼è¡¨ç¤ºçº SPI-DB* å PatchDB*ãæåå° RepoSPD èå­ç¨®ç¾æçå®å¨æ§ä¿®è£ç¨å¼åµæ¸¬æ¹æ³åäºç¨®éæå·¥å·é²è¡æ¯è¼ãæåçå¯¦é©çµæè¡¨æï¼RepoSPD åªæ¼æåé²çåºæºï¼å¨å©åè³æéä¸çæºç¢ºæ§åå¥æé«äº 11.90% å 3.10%ã</paragraph>

##### **ContextModule: Improving Code Completion via Repository-level Contextual Information**
2412.08063v1 by Zhanming Guan, Junlin Liu, Jierui Liu, Chao Peng, Dexin Liu, Ningyuan Sun, Bo Jiang, Wenchao Li, Jie Liu, Hang Zhu

Large Language Models (LLMs) have demonstrated impressive capabilities in
code completion tasks, where they assist developers by predicting and
generating new code in real-time. However, existing LLM-based code completion
systems primarily rely on the immediate context of the file being edited, often
missing valuable repository-level information, user behaviour and edit history
that could improve suggestion accuracy. Additionally, challenges such as
efficiently retrieving relevant code snippets from large repositories,
incorporating user behavior, and balancing accuracy with low-latency
requirements in production environments remain unresolved. In this paper, we
propose ContextModule, a framework designed to enhance LLM-based code
completion by retrieving and integrating three types of contextual information
from the repository: user behavior-based code, similar code snippets, and
critical symbol definitions. By capturing user interactions across files and
leveraging repository-wide static analysis, ContextModule improves the
relevance and precision of generated code. We implement performance
optimizations, such as index caching, to ensure the system meets the latency
constraints of real-world coding environments. Experimental results and
industrial practise demonstrate that ContextModule significantly improves code
completion accuracy and user acceptance rates.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å·²å¨ä»£ç¢¼å®æä»»åä¸­å±ç¾åºä»¤äººå°è±¡æ·±å»çè½åï¼å®åè½åå©éç¼äººå¡å³æé æ¸¬åç¢çæ°ä»£ç¢¼ãç¶èï¼ç¾æç LLM åºæ¼ä»£ç¢¼å®æç³»çµ±ä¸»è¦ä¾è³´æ¼æ­£å¨ç·¨è¼¯æªæ¡çå³æå§å®¹ï¼éå¸¸æéºæ¼æå¹å¼çå²å­åº«å±¤ç´è³è¨ãä½¿ç¨èè¡çºåç·¨è¼¯è¨éï¼èéäºè³è¨å¯ä»¥æåå»ºè­°çæºç¢ºåº¦ãæ­¤å¤ï¼å¨çç¢ç°å¢ä¸­ææçå°å¾å¤§åå²å­åº«æ·åç¸éç¨å¼ç¢¼çæ®µãç´å¥ä½¿ç¨èè¡çºï¼ä»¥åå¹³è¡¡æºç¢ºåº¦èä½å»¶é²éæ±ç­ææ°ä»ç¶æªç²è§£æ±ºãå¨æ¬æä¸­ï¼æåæåº ContextModuleï¼ä¸åæ¨å¨ééå¾å²å­åº«æ·ååæ´åä¸ç¨®é¡åçå§å®¹è³è¨ä¾å¢å¼· LLM åºæ¼ä»£ç¢¼å®æçæ¶æ§ï¼åºæ¼ä½¿ç¨èè¡çºçä»£ç¢¼ãé¡ä¼¼çç¨å¼ç¢¼çæ®µåééµç¬¦èå®ç¾©ãééæ·åè·¨æªæ¡çä½¿ç¨èäºåä¸¦å©ç¨å²å­åº«ç¯åçéæåæï¼ContextModule æåäºæç¢çä»£ç¢¼çç¸éæ§åç²¾ç¢ºåº¦ãæåå¯¦ä½æè½æä½³åï¼ä¾å¦ç´¢å¼å¿«åï¼ä»¥ç¢ºä¿ç³»çµ±ç¬¦åçå¯¦ä¸çç·¨ç¢¼ç°å¢çå»¶é²éå¶ãå¯¦é©çµæåç¢æ¥­å¯¦åè­æï¼ContextModule å¤§å¹æåäºä»£ç¢¼å®æçæºç¢ºåº¦åä½¿ç¨èæ¥åçã

##### **Go-Oracle: Automated Test Oracle for Go Concurrency Bugs**
2412.08061v1 by Foivos Tsimpourlas, Chao Peng, Carlos Rosuero, Ping Yang, Ajitha Rajan

The Go programming language has gained significant traction for developing
software, especially in various infrastructure systems. Nonetheless,
concurrency bugs have become a prevalent issue within Go, presenting a unique
challenge due to the language's dual concurrency mechanisms-communicating
sequential processes and shared memory. Detecting concurrency bugs and
accurately classifying program executions as pass or fail presents an immense
challenge, even for domain experts. We conducted a survey with expert
developers at Bytedance that confirmed this challenge. Our work seeks to
address the test oracle problem for Go programs, to automatically classify test
executions as pass or fail. This problem has not been investigated in the
literature for Go programs owing to its distinctive programming model.
  Our approach involves collecting both passing and failing execution traces
from various subject Go programs. We capture a comprehensive array of execution
events using the native Go execution tracer. Subsequently, we preprocess and
encode these traces before training a transformer-based neural network to
effectively classify the traces as either passing or failing. The evaluation of
our approach encompasses 8 subject programs sourced from the GoBench
repository. These subject programs are routinely used as benchmarks in an
industry setting. Encouragingly, our test oracle, Go-Oracle, demonstrates high
accuracies even when operating with a limited dataset, showcasing the efficacy
and potential of our methodology. Developers at Bytedance strongly agreed that
they would use the Go-Oracle tool over the current practice of manual
inspections to classify tests for Go programs as pass or fail.

æè¦ï¼Go ç¨å¼èªè¨å¨éç¼è»é«æ¹é¢ç²å¾é¡¯èçé²å±ï¼ç¹å¥æ¯å¨åç¨®åºç¤æ¶æ§ç³»çµ±ä¸­ãåç®¡å¦æ­¤ï¼ä¸¦ç¼é¯èª¤å·²æçº Go ä¸­æ®éçåé¡ï¼ç±æ¼èªè¨çééä¸¦ç¼æ©å¶ï¼å³éé åºèçåå±äº«è¨æ¶é«ï¼ï¼éæåºäºç¨ç¹çææ°ãå³ä½¿å°æ¼é åå°å®¶ä¾èªªï¼åµæ¸¬ä¸¦ç¼é¯èª¤åæºç¢ºå°å°ç¨å¼å·è¡åé¡çºééæå¤±æä¹æ§æäºå·¨å¤§çææ°ãæåå¨ ByteDance é²è¡äºä¸é å°å®¶éç¼äººå¡èª¿æ¥ï¼è­å¯¦äºéé ææ°ãæåçç ç©¶æ¨å¨è§£æ±º Go ç¨å¼çæ¸¬è©¦é è¨åé¡ï¼ä»¥èªåå°æ¸¬è©¦å·è¡åé¡çºééæå¤±æãç±æ¼å¶ç¨ç¹çç¨å¼è¨­è¨æ¨¡åï¼éååé¡å°æªå¨ Go ç¨å¼çæç»ä¸­å¾å°æ¢è¨ãæåçåæ³åæ¬å¾åç¨®ä¸»é¡ Go ç¨å¼æ¶éééåå¤±æçå·è¡è¿½è¹¤ãæåä½¿ç¨åç Go å·è¡è¿½è¹¤å¨æ·åå¨é¢çå·è¡äºä»¶é£åãé¨å¾ï¼æåå¨è¨ç·´åºæ¼è½æå¨çé¡ç¥ç¶ç¶²è·¯ä»¥ææå°å°è¿½è¹¤åé¡çºééæå¤±æä¹åï¼å°éäºè¿½è¹¤é²è¡é èçåç·¨ç¢¼ãæåçæ¹æ³è©ä¼°åå«ä¾èª GoBench å²å­åº«ç 8 åä¸»é¡ç¨å¼ãéäºä¸»é¡ç¨å¼éå¸¸ç¨ä½ç¢æ¥­ç°å¢ä¸­çåºæºãä»¤äººé¼èçæ¯ï¼å³ä½¿å¨ä½¿ç¨æéçè³æéæä½æï¼æåçæ¸¬è©¦é è¨ Go-Oracle ä¹è¡¨ç¾åºå¾é«çæºç¢ºæ§ï¼å±ç¤ºäºæåæ¹æ³çæææ§åæ½åãByteDance çéç¼äººå¡å¼·çåæï¼ä»åå°ä½¿ç¨ Go-Oracle å·¥å·ï¼èä¸æ¯ç®åçæ¸¬è©¦æåæª¢æ¥æ¹å¼ï¼å° Go ç¨å¼çæ¸¬è©¦åé¡çºééæå¤±æã

##### **Federated In-Context LLM Agent Learning**
2412.08054v1 by Panlong Wu, Kangshuo Li, Junbao Nan, Fangxin Wang

Large Language Models (LLMs) have revolutionized intelligent services by
enabling logical reasoning, tool use, and interaction with external systems as
agents. The advancement of LLMs is frequently hindered by the scarcity of
high-quality data, much of which is inherently sensitive. Federated learning
(FL) offers a potential solution by facilitating the collaborative training of
distributed LLMs while safeguarding private data. However, FL frameworks face
significant bandwidth and computational demands, along with challenges from
heterogeneous data distributions. The emerging in-context learning capability
of LLMs offers a promising approach by aggregating natural language rather than
bulky model parameters. Yet, this method risks privacy leakage, as it
necessitates the collection and presentation of data samples from various
clients during aggregation. In this paper, we propose a novel
privacy-preserving Federated In-Context LLM Agent Learning (FICAL) algorithm,
which to our best knowledge for the first work unleashes the power of
in-context learning to train diverse LLM agents through FL. In our design,
knowledge compendiums generated by a novel LLM-enhanced Knowledge Compendiums
Generation (KCG) module are transmitted between clients and the server instead
of model parameters in previous FL methods. Apart from that, an incredible
Retrieval Augmented Generation (RAG) based Tool Learning and Utilizing (TLU)
module is designed and we incorporate the aggregated global knowledge
compendium as a teacher to teach LLM agents the usage of tools. We conducted
extensive experiments and the results show that FICAL has competitive
performance compared to other SOTA baselines with a significant communication
cost decrease of $\mathbf{3.33\times10^5}$ times.

æè¦ï¼<paragraph>å¤§åèªè¨æ¨¡å (LLM) ééè®ä»£çäººé²è¡éè¼¯æ¨çãä½¿ç¨å·¥å·ä»¥åèå¤é¨ç³»çµ±äºåï¼é²èé©æ°äºæºæ§æåãLLM çé²å±ç¶å¸¸åå°é«åè³ªè³æç­ç¼ºçé»ç¤ï¼å¶ä¸­è¨±å¤è³ææ¬è³ªä¸æ¯ææçãè¯åå­¸ç¿ (FL) æä¾äºä¸åæ½å¨çè§£æ±ºæ¹æ¡ï¼å®ä¿é²äºåæ£å¼ LLM çåä½è¨ç·´ï¼åæä¿è­·äºç§äººè³æãç¶èï¼FL æ¡æ¶é¢è¨èé¡¯èçé »å¯¬åéç®éæ±ï¼ä»¥åç°è³ªè³æåä½å¸¶ä¾çææ°ãLLM æ°èçèªå¢å­¸ç¿è½åæä¾äºä¸åæåéçæ¹æ³ï¼å®èåèªç¶èªè¨ï¼èä¸æ¯é¾å¤§çæ¨¡ååæ¸ãç¶èï¼æ­¤æ¹æ³æé±ç§å¤æ´©çé¢¨éªï¼å çºå®éè¦å¨èåéç¨ä¸­æ¶éååç¾ä¾èªä¸åå®¢æ¶ç«¯çè³ææ¨£æ¬ãå¨æ¬æä¸­ï¼æåæåºäºä¸ç¨®æ°ç©çé±ç§ä¿è­·è¯åèªå¢ LLM ä»£çå­¸ç¿ (FICAL) æ¼ç®æ³ï¼æ ¹ææåæç¥ï¼éæ¯ç¬¬ä¸åç¼æ®èªå¢å­¸ç¿çåéï¼éé FL è¨ç·´å¤æ¨£åç LLM ä»£çãå¨æåçè¨­è¨ä¸­ï¼ç±æ°ç©ç LLM å¢å¼·çç¥è­å½ç·¨çæ (KCG) æ¨¡çµç¢ççç¥è­å½ç·¨å¨å®¢æ¶ç«¯åä¼ºæå¨ä¹éå³è¼¸ï¼èä¸æ¯åå FL æ¹æ³ä¸­çæ¨¡ååæ¸ãé¤æ­¤ä¹å¤ï¼æåè¨­è¨äºä¸ååºæ¼ä»¤äººé£ä»¥ç½®ä¿¡çæª¢ç´¢å¢å¼·çæ (RAG) çå·¥å·å­¸ç¿åå©ç¨ (TLU) æ¨¡çµï¼ä¸¦å°èåçå¨çç¥è­å½ç·¨ä½çºèå¸«ï¼æå° LLM ä»£çå¦ä½ä½¿ç¨å·¥å·ãæåé²è¡äºå»£æ³çå¯¦é©ï¼çµæé¡¯ç¤º FICAL èå¶ä» SOTA åºæºç¸æ¯å·æç«¶ç­åçæè½ï¼åæå°éè¨ææ¬å¤§å¹éä½ $\mathbf{3.33\times10^5}$ åã</paragraph>

##### **DynamicPAE: Generating Scene-Aware Physical Adversarial Examples in Real-Time**
2412.08053v1 by Jin Hu, Xianglong Liu, Jiakai Wang, Junkai Zhang, Xianqi Yang, Haotong Qin, Yuqing Ma, Ke Xu

Physical adversarial examples (PAEs) are regarded as "whistle-blowers" of
real-world risks in deep-learning applications. However, current PAE generation
studies show limited adaptive attacking ability to diverse and varying scenes.
The key challenges in generating dynamic PAEs are exploring their patterns
under noisy gradient feedback and adapting the attack to agnostic scenario
natures. To address the problems, we present DynamicPAE, the first generative
framework that enables scene-aware real-time physical attacks beyond static
attacks. Specifically, to train the dynamic PAE generator under noisy gradient
feedback, we introduce the residual-driven sample trajectory guidance
technique, which redefines the training task to break the limited feedback
information restriction that leads to the degeneracy problem. Intuitively, it
allows the gradient feedback to be passed to the generator through a low-noise
auxiliary task, thereby guiding the optimization away from degenerate solutions
and facilitating a more comprehensive and stable exploration of feasible PAEs.
To adapt the generator to agnostic scenario natures, we introduce the
context-aligned scene expectation simulation process, consisting of the
conditional-uncertainty-aligned data module and the skewness-aligned objective
re-weighting module. The former enhances robustness in the context of
incomplete observation by employing a conditional probabilistic model for
domain randomization, while the latter facilitates consistent stealth control
across different attack targets by automatically reweighting losses based on
the skewness indicator. Extensive digital and physical evaluations demonstrate
the superior attack performance of DynamicPAE, attaining a 1.95 $\times$ boost
(65.55% average AP drop under attack) on representative object detectors (e.g.,
Yolo-v8) over state-of-the-art static PAE generating methods.

æè¦ï¼<paragraph>ç©çå¯¹ææ§ç¯ä¾ (PAE) è¢«è¦çºæ·±åº¦å­¸ç¿æç¨ä¸­ãå¹å¨èãççå¯¦ä¸çé¢¨éªãç¶èï¼ç®åç PAE çæç ç©¶é¡¯ç¤ºåºæéçé©ææ§æ»æè½åï¼ç¡æ³æå°å¤æ¨£ååè®åçå ´æ¯ãçæåæ PAE çä¸»è¦ææ°æ¯æ¢ç´¢å®åå¨æéè¨çæ¢¯åº¦åé¥ä¸çæ¨¡å¼ï¼ä¸¦é©ææ»æå°ä¸å¯ç¥å ´æ¯çæ§è³ªãçºäºè§£æ±ºéäºåé¡ï¼æåæåºäº DynamicPAEï¼éæ¯ç¬¬ä¸åçæå¼æ¶æ§ï¼å®è½é²è¡å ´æ¯æç¥çå¯¦æç©çæ»æï¼è¶è¶éææ»æãå·é«ä¾èªªï¼çºäºå¨æéè¨çæ¢¯åº¦åé¥ä¸è¨ç·´åæ PAE çæå¨ï¼æåå¼å¥äºæ®å·®é©åçæ¨£æ¬è»è·¡å¼å°æè¡ï¼å®éæ°å®ç¾©äºè¨ç·´ä»»åï¼ä»¥æç ´å°è´éååé¡çæéåé¥è³è¨éå¶ãç´è§å°èªªï¼å®åè¨±æ¢¯åº¦åé¥ééä½éè¨è¼å©ä»»åå³éå°çæå¨ï¼å¾èå¼å°æä½³åé é¢éåè§£ï¼ä¸¦ä¿é²å°å¯è¡ PAE é²è¡æ´å¨é¢åç©©å®çæ¢ç´¢ãçºäºé©æçæå¨å°ä¸å¯ç¥å ´æ¯çæ§è³ªï¼æåå¼å¥äºä¸ä¸æå°é½çå ´æ¯æææ¨¡æ¬éç¨ï¼å®åå«æ¢ä»¶ä¸ç¢ºå®æ§å°é½æ¸ææ¨¡çµåååº¦å°é½ç®æ¨éæ°å æ¬æ¨¡çµãåèééæ¡ç¨æ¢ä»¶æ©çæ¨¡åé²è¡ç¶²åé¨æ©åï¼å¢å¼·äºå¨ä¸å®æ´è§æ¸¬ä¸çç©©å¥æ§ï¼èå¾èééæ ¹æååº¦ææ¨èªåéæ°å æ¬æå¤±ï¼ä¿è¿äºå¨ä¸åæ»å»ç®æ ä¹é´çä¸è´éèº«æ§å¶ãå»£æ³çæ¸ä½åç©çè©ä¼°è­æäº DynamicPAE åªç°çæ»ææ§è½ï¼å¨ä»£è¡¨æ§çç©ä»¶åµæ¸¬å¨ï¼ä¾å¦ï¼Yolo-v8ï¼ä¸ï¼èæåé²çéæ PAE çææ¹æ³ç¸æ¯ï¼æ»æä¸çå¹³å AP ä¸éäº 1.95 åï¼65.55%ï¼ã</paragraph>

##### **M2SE: A Multistage Multitask Instruction Tuning Strategy for Unified Sentiment and Emotion Analysis**
2412.08049v1 by Ao Li, Longwei Xu, Chen Ling, Jinghui Zhang, Pengwei Wang

Sentiment analysis and emotion recognition are crucial for applications such
as human-computer interaction and depression detection. Traditional unimodal
methods often fail to capture the complexity of emotional expressions due to
conflicting signals from different modalities. Current Multimodal Large
Language Models (MLLMs) also face challenges in detecting subtle facial
expressions and addressing a wide range of emotion-related tasks. To tackle
these issues, we propose M2SE, a Multistage Multitask Sentiment and Emotion
Instruction Tuning Strategy for general-purpose MLLMs. It employs a combined
approach to train models on tasks such as multimodal sentiment analysis,
emotion recognition, facial expression recognition, emotion reason inference,
and emotion cause-pair extraction. We also introduce the Emotion Multitask
dataset (EMT), a custom dataset that supports these five tasks. Our model,
Emotion Universe (EmoVerse), is built on a basic MLLM framework without
modifications, yet it achieves substantial improvements across these tasks when
trained with the M2SE strategy. Extensive experiments demonstrate that EmoVerse
outperforms existing methods, achieving state-of-the-art results in sentiment
and emotion tasks. These results highlight the effectiveness of M2SE in
enhancing multimodal emotion perception. The dataset and code are available at
https://github.com/xiaoyaoxinyi/M2SE.

æè¦ï¼æç·åæåæç·è¾¨è­å°æ¼äººæ©äºååæé¬±çåµæ¸¬ç­æç¨è³ééè¦ãå³çµ±çå®æ¨¡ææ¹æ³ç±æ¼ä¸åæ¨¡æçè¨èç¸äºè¡çªï¼å¸¸å¸¸ç¡æ³ææå°æç·è¡¨éçè¤éæ§ãç®åçå¤æ¨¡æå¤§åèªè¨æ¨¡å (MLLM) å¨åµæ¸¬ç´°å¾®é¢é¨è¡¨æåèçå»£æ³çæç·ç¸éä»»åæ¹é¢ä¹é¢è¨ææ°ãçºäºè§£æ±ºéäºåé¡ï¼æåæåºäº M2SEï¼ä¸ç¨®éå°éç¨ MLLM çå¤éæ®µå¤ä»»åæç·åæç·æä»¤èª¿æ´ç­ç¥ãå®æ¡ç¨ä¸ç¨®çµåæ¹æ³ä¾è¨ç·´æ¨¡åï¼å·è¡å¤æ¨¡ææç·åæãæç·è¾¨è­ãé¢é¨è¡¨æè¾¨è­ãæç·åå æ¨è«åæç·æå å°èåç­ä»»åãæåä¹å¼å¥äºæç·å¤ä»»åè³æé (EMT)ï¼éæ¯ä¸åæ¯æ´éäºé ä»»åçå®¢è£½åè³æéãæåçæ¨¡åæç·å®å® (EmoVerse) å»ºç«å¨ä¸ååºæ¬ç MLLM æ¶æ§ä¸ï¼æ²æä¿®æ¹ï¼ä½å¨ä½¿ç¨ M2SE ç­ç¥è¨ç·´å¾ï¼å¨éäºä»»åä¸­é½åå¾äºé¡¯èçé²æ­¥ãå»£æ³çå¯¦é©è­æï¼EmoVerse åªæ¼ç¾ææ¹æ³ï¼å¨æç·åææä»»åä¸­åå¾äºæåé²ççµæãéäºçµæçªé¡¯äº M2SE å¨å¢å¼·å¤æ¨¡ææç·æç¥æ¹é¢çæææ§ãè³æéåç¨å¼ç¢¼å¯å¨ https://github.com/xiaoyaoxinyi/M2SE åå¾ã

##### **Bootstrapping Heterogeneous Graph Representation Learning via Large Language Models: A Generalized Approach**
2412.08038v1 by Hang Gao, Chenhao Zhang, Fengge Wu, Junsuo Zhao, Changwen Zheng, Huaping Liu

Graph representation learning methods are highly effective in handling
complex non-Euclidean data by capturing intricate relationships and features
within graph structures. However, traditional methods face challenges when
dealing with heterogeneous graphs that contain various types of nodes and edges
due to the diverse sources and complex nature of the data. Existing
Heterogeneous Graph Neural Networks (HGNNs) have shown promising results but
require prior knowledge of node and edge types and unified node feature
formats, which limits their applicability. Recent advancements in graph
representation learning using Large Language Models (LLMs) offer new solutions
by integrating LLMs' data processing capabilities, enabling the alignment of
various graph representations. Nevertheless, these methods often overlook
heterogeneous graph data and require extensive preprocessing. To address these
limitations, we propose a novel method that leverages the strengths of both LLM
and GNN, allowing for the processing of graph data with any format and type of
nodes and edges without the need for type information or special preprocessing.
Our method employs LLM to automatically summarize and classify different data
formats and types, aligns node features, and uses a specialized GNN for
targeted learning, thus obtaining effective graph representations for
downstream tasks. Theoretical analysis and experimental validation have
demonstrated the effectiveness of our method.

æè¦ï¼åè¡¨è¡¨ç¤ºå­¸ç¿æ¹æ³å¨èçè¤éçéæ­å¹¾éå¾æ¸ææ¹é¢éå¸¸ææï¼æ¹æ³æ¯ææåå½¢çµæ§ä¸­çè¤ééä¿åç¹å¾µãç¶èï¼ç±æ¼æ¸æä¾æºå¤æ¨£ä¸æ§è³ªè¤éï¼å³çµ±æ¹æ³å¨èçåå«åç¨®é¡åç¯é»åéçç°è³ªåå½¢æé¢è¨ææ°ãç¾æçç°è³ªåå½¢ç¥ç¶ç¶²è·¯ (HGNN) å·²å±ç¾åºæå¸æçææï¼ä½éè¦äºåäºè§£ç¯é»åéçé¡åï¼ä»¥åçµ±ä¸çç¯é»ç¹å¾µæ ¼å¼ï¼ééå¶äºå¶é©ç¨æ§ãæè¿ä½¿ç¨å¤§åèªè¨æ¨¡å (LLM) çåå½¢è¡¨ç¤ºå­¸ç¿çé²å±æä¾äºæ°çè§£æ±ºæ¹æ¡ï¼æ¹æ³æ¯æ´å LLM çæ¸æèçåè½ï¼ä½¿åç¨®åå½¢è¡¨ç¤ºå¾ä»¥å°é½ãåç®¡å¦æ­¤ï¼éäºæ¹æ³éå¸¸æå¿½ç¥ç°è³ªåå½¢æ¸æï¼ä¸¦ä¸éè¦å»£æ³çé èçãçºäºè§£æ±ºéäºéå¶ï¼æåæåºäºä¸ç¨®æ°æ¹æ³ï¼å®å©ç¨äº LLM å GNN çåªé»ï¼åè¨±èçä»»ä½æ ¼å¼åé¡åçç¯é»åéçåå½¢æ¸æï¼èä¸éè¦é¡åä¿¡æ¯æç¹æ®é èçãæåçæ¨¡åæ¡ç¨ LLM èªåç¸½çµååé¡ä¸åçæ¸ææ ¼å¼åé¡åï¼å°é½ç¯é»ç¹å¾µï¼ä¸¦ä½¿ç¨å°éç GNN é²è¡ç®æ¨å­¸ç¿ï¼å¾èçºä¸æ¸¸ä»»åç²åææçåå½¢è¡¨ç¤ºãçè«åæåå¯¦é©é©è­å·²è­æäºæåæ¹æ³çæææ§ã

##### **TinyThinker: Distilling Reasoning through Coarse-to-Fine Knowledge Internalization with Self-Reflection**
2412.08024v1 by Shengmin Piao, Sanghyun Park

Large Language Models exhibit impressive reasoning capabilities across
diverse tasks, motivating efforts to distill these capabilities into smaller
models through generated reasoning data. However, direct training on such
synthesized reasoning data may lead to superficial imitation of reasoning
process, rather than fostering a genuine integration of reasoning capabilities
with underlying knowledge. To address this, we propose TinyThinker, a framework
introducing two novel approaches. First, we introduce a three-stage process
that incrementally guides the student model through the reasoning process,
progressively refining knowledge from coarse to fine granularity. Second, we
develop a two-phase training framework comprising an initial reasoning
acquisition phase followed by a self-reflection phase utilizing self-generated
data. Experiments on commonsense reasoning benchmarks demonstrate that
TinyThinker achieves superior performance compared to baselines. Ablation
studies further validate the effectiveness of each component in our framework.
TinyThinker is extendable to other knowledge-intensive reasoning tasks,
offering an alternative strategy for developing effective reasoning
capabilities in smaller language models. Codes are available at
https://github.com/shengminp/TinyThinker

æè¦ï¼å¤§åèªè¨æ¨¡åå¨åç¨®ä»»åä¸­å±ç¾åºä»¤äººå°è±¡æ·±å»çæ¨çè½åï¼æ¿åµäººåééç¢ççæ¨çè³æå°éäºè½åæçå°è¼å°çæ¨¡åä¸­ãç¶èï¼ç´æ¥è¨ç·´æ­¤é¡åæçæ¨çè³æå¯è½æå°è´æ¨çéç¨çè¡¨é¢æ¨¡ä»¿ï¼èä¸æ¯ä¿é²æ¨çè½åèåºç¤ç¥è­ççæ­£æ´åãçºäºè§£æ±ºéååé¡ï¼æåæåº TinyThinkerï¼ä¸åå¼å¥å©ç¨®æ°æ¹æ³çæ¡æ¶ãé¦åï¼æåå¼å¥ä¸åä¸éæ®µæµç¨ï¼éæ­¥å¼å°å­¸çæ¨¡åå®ææ¨çéç¨ï¼éæ­¥å¾ç²ç¥å°ç²¾ç´°çç²åº¦ä¸­æçç¥è­ãå¶æ¬¡ï¼æåéç¼äºä¸åå©éæ®µè¨ç·´æ¡æ¶ï¼åæ¬ä¸ååå§æ¨çç²åéæ®µï¼ç¶å¾æ¯ä¸åå©ç¨èªçè³æçèªçéæ®µãå¨å¸¸è­æ¨çåºæºä¸çå¯¦é©è¡¨æï¼èåºæºç·ç¸æ¯ï¼TinyThinker éå°äºæ´é«çæ§è½ãæ¶èç ç©¶é²ä¸æ­¥é©è­äºæåæ¡æ¶ä¸­æ¯åçµä»¶çæææ§ãTinyThinker å¯æ´å±å°å¶ä»ç¥è­å¯éåæ¨çä»»åï¼çºå¨è¼å°çèªè¨æ¨¡åä¸­éç¼ææçæ¨çè½åæä¾äºä¸ç¨®æ¿ä»£ç­ç¥ãç¨å¼ç¢¼å¯å¨ https://github.com/shengminp/TinyThinker ç²å¾

