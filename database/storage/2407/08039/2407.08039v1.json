{"2407.08039": {"publish_time": "2024-07-10", "title": "Knowledge Overshadowing Causes Amalgamated Hallucination in Large Language Models", "paper_summary": "Hallucination is often regarded as a major impediment for using large\nlanguage models (LLMs), especially for knowledge-intensive tasks. Even when the\ntraining corpus consists solely of true statements, language models still\ngenerate hallucinations in the form of amalgamations of multiple facts. We coin\nthis phenomenon as ``knowledge overshadowing'': when we query knowledge from a\nlanguage model with multiple conditions, some conditions overshadow others,\nleading to hallucinated outputs. This phenomenon partially stems from training\ndata imbalance, which we verify on both pretrained models and fine-tuned\nmodels, over a wide range of LM model families and sizes.From a theoretical\npoint of view, knowledge overshadowing can be interpreted as\nover-generalization of the dominant conditions (patterns). We show that the\nhallucination rate grows with both the imbalance ratio (between the popular and\nunpopular condition) and the length of dominant condition description,\nconsistent with our derived generalization bound. Finally, we propose to\nutilize overshadowing conditions as a signal to catch hallucination before it\nis produced, along with a training-free self-contrastive decoding method to\nalleviate hallucination during inference. Our proposed approach showcases up to\n82% F1 for hallucination anticipation and 11.2% to 39.4% hallucination control,\nwith different models and datasets.", "paper_summary_zh": "\u5e7b\u89c9\u901a\u5e38\u88ab\u89c6\u4e3a\u4f7f\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b (LLM) \u7684\u4e3b\u8981\u969c\u788d\uff0c\u5c24\u5176\u662f\u5bf9\u4e8e\u77e5\u8bc6\u5bc6\u96c6\u578b\u4efb\u52a1\u3002\u5373\u4f7f\u8bad\u7ec3\u8bed\u6599\u5e93\u4ec5\u5305\u542b\u771f\u5b9e\u9648\u8ff0\uff0c\u8bed\u8a00\u6a21\u578b\u4ecd\u4f1a\u4ee5\u591a\u79cd\u4e8b\u5b9e\u7684\u6df7\u5408\u5f62\u5f0f\u4ea7\u751f\u5e7b\u89c9\u3002\u6211\u4eec\u628a\u8fd9\u79cd\u73b0\u8c61\u79f0\u4e3a\u201c\u77e5\u8bc6\u63a9\u76d6\u201d\uff1a\u5f53\u6211\u4eec\u7528\u591a\u4e2a\u6761\u4ef6\u4ece\u8bed\u8a00\u6a21\u578b\u4e2d\u67e5\u8be2\u77e5\u8bc6\u65f6\uff0c\u4e00\u4e9b\u6761\u4ef6\u4f1a\u63a9\u76d6\u5176\u4ed6\u6761\u4ef6\uff0c\u4ece\u800c\u5bfc\u81f4\u4ea7\u751f\u5e7b\u89c9\u7684\u8f93\u51fa\u3002\u8fd9\u79cd\u73b0\u8c61\u90e8\u5206\u6e90\u4e8e\u8bad\u7ec3\u6570\u636e\u4e0d\u5e73\u8861\uff0c\u6211\u4eec\u5728\u9884\u8bad\u7ec3\u6a21\u578b\u548c\u5fae\u8c03\u6a21\u578b\u4e0a\u4ee5\u53ca\u5728\u5e7f\u6cdb\u7684 LM \u6a21\u578b\u7cfb\u5217\u548c\u89c4\u6a21\u4e0a\u5bf9\u6b64\u8fdb\u884c\u4e86\u9a8c\u8bc1\u3002\u4ece\u7406\u8bba\u89d2\u5ea6\u6765\u770b\uff0c\u77e5\u8bc6\u63a9\u76d6\u53ef\u4ee5\u89e3\u91ca\u4e3a\u5bf9\u4e3b\u8981\u6761\u4ef6\uff08\u6a21\u5f0f\uff09\u7684\u8fc7\u5ea6\u6982\u62ec\u3002\u6211\u4eec\u8868\u660e\uff0c\u5e7b\u89c9\u7387\u968f\u7740\u4e0d\u5e73\u8861\u7387\uff08\u6d41\u884c\u6761\u4ef6\u548c\u4e0d\u53d7\u6b22\u8fce\u6761\u4ef6\u4e4b\u95f4\uff09\u548c\u4e3b\u8981\u6761\u4ef6\u63cf\u8ff0\u7684\u957f\u5ea6\u800c\u589e\u52a0\uff0c\u8fd9\u4e0e\u6211\u4eec\u5f97\u51fa\u7684\u6982\u62ec\u754c\u9650\u4e00\u81f4\u3002\u6700\u540e\uff0c\u6211\u4eec\u5efa\u8bae\u5229\u7528\u63a9\u76d6\u6761\u4ef6\u4f5c\u4e3a\u4e00\u79cd\u4fe1\u53f7\uff0c\u5728\u4ea7\u751f\u5e7b\u89c9\u4e4b\u524d\u6355\u83b7\u5e7b\u89c9\uff0c\u5e76\u4f7f\u7528\u65e0\u8bad\u7ec3\u7684\u81ea\u5bf9\u6bd4\u89e3\u7801\u65b9\u6cd5\u6765\u51cf\u8f7b\u63a8\u7406\u8fc7\u7a0b\u4e2d\u7684\u5e7b\u89c9\u3002\u6211\u4eec\u63d0\u51fa\u7684\u65b9\u6cd5\u5c55\u793a\u4e86\u9ad8\u8fbe 82% \u7684 F1 \u5e7b\u89c9\u9884\u6d4b\u548c 11.2% \u5230 39.4% \u7684\u5e7b\u89c9\u63a7\u5236\uff0c\u5177\u6709\u4e0d\u540c\u7684\u6a21\u578b\u548c\u6570\u636e\u96c6\u3002", "author": "Yuji Zhang et.al.", "authors": "Yuji Zhang, Sha Li, Jiateng Liu, Pengfei Yu, Yi R. Fung, Jing Li, Manling Li, Heng Ji", "id": "2407.08039v1", "paper_url": "http://arxiv.org/abs/2407.08039v1", "repo": "null"}}