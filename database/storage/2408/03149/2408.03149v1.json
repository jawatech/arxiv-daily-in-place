{"2408.03149": {"publish_time": "2024-08-06", "title": "Leveraging Entity Information for Cross-Modality Correlation Learning: The Entity-Guided Multimodal Summarization", "paper_summary": "The rapid increase in multimedia data has spurred advancements in Multimodal\nSummarization with Multimodal Output (MSMO), which aims to produce a multimodal\nsummary that integrates both text and relevant images. The inherent\nheterogeneity of content within multimodal inputs and outputs presents a\nsignificant challenge to the execution of MSMO. Traditional approaches\ntypically adopt a holistic perspective on coarse image-text data or individual\nvisual objects, overlooking the essential connections between objects and the\nentities they represent. To integrate the fine-grained entity knowledge, we\npropose an Entity-Guided Multimodal Summarization model (EGMS). Our model,\nbuilding on BART, utilizes dual multimodal encoders with shared weights to\nprocess text-image and entity-image information concurrently. A gating\nmechanism then combines visual data for enhanced textual summary generation,\nwhile image selection is refined through knowledge distillation from a\npre-trained vision-language model. Extensive experiments on public MSMO dataset\nvalidate the superiority of the EGMS method, which also prove the necessity to\nincorporate entity information into MSMO problem.", "paper_summary_zh": "\u96a8\u8457\u591a\u5a92\u9ad4\u8cc7\u6599\u7684\u5feb\u901f\u589e\u52a0\uff0c\u523a\u6fc0\u4e86\u591a\u6a21\u614b\u8f38\u51fa\u591a\u6a21\u614b\u6458\u8981 (MSMO) \u7684\u9032\u5c55\uff0c\u5176\u76ee\u6a19\u662f\u7522\u751f\u4e00\u500b\u6574\u5408\u6587\u5b57\u548c\u76f8\u95dc\u5f71\u50cf\u7684\u591a\u6a21\u614b\u6458\u8981\u3002\u591a\u6a21\u614b\u8f38\u5165\u548c\u8f38\u51fa\u5167\u5728\u7684\u7570\u8cea\u6027\uff0c\u5c0d MSMO \u7684\u57f7\u884c\u69cb\u6210\u91cd\u5927\u6311\u6230\u3002\u50b3\u7d71\u65b9\u6cd5\u901a\u5e38\u63a1\u7528\u6574\u9ad4\u89c0\u9ede\uff0c\u91dd\u5c0d\u7c97\u7565\u7684\u5f71\u50cf\u6587\u5b57\u8cc7\u6599\u6216\u500b\u5225\u8996\u89ba\u7269\u4ef6\uff0c\u5ffd\u7565\u4e86\u7269\u4ef6\u8207\u5176\u6240\u4ee3\u8868\u5be6\u9ad4\u4e4b\u9593\u7684\u672c\u8cea\u95dc\u806f\u6027\u3002\u70ba\u4e86\u6574\u5408\u7d30\u7c92\u5ea6\u7684\u5be6\u9ad4\u77e5\u8b58\uff0c\u6211\u5011\u63d0\u51fa\u4e00\u500b\u5be6\u9ad4\u5f15\u5c0e\u5f0f\u591a\u6a21\u614b\u6458\u8981\u6a21\u578b (EGMS)\u3002\u6211\u5011\u7684\u6a21\u578b\u5efa\u69cb\u5728 BART \u4e0a\uff0c\u5229\u7528\u5177\u6709\u5171\u4eab\u6b0a\u91cd\u7684\u96d9\u91cd\u591a\u6a21\u614b\u7de8\u78bc\u5668\uff0c\u540c\u6642\u8655\u7406\u6587\u5b57\u5f71\u50cf\u548c\u5be6\u9ad4\u5f71\u50cf\u8cc7\u8a0a\u3002\u4e00\u500b\u9598\u63a7\u6a5f\u5236\u63a5\u8457\u7d50\u5408\u8996\u89ba\u8cc7\u6599\uff0c\u4ee5\u589e\u5f37\u6587\u5b57\u6458\u8981\u7684\u751f\u6210\uff0c\u540c\u6642\u900f\u904e\u9810\u5148\u8a13\u7df4\u7684\u8996\u89ba\u8a9e\u8a00\u6a21\u578b\u7684\u77e5\u8b58\u8403\u53d6\uff0c\u7cbe\u7149\u5f71\u50cf\u9078\u64c7\u3002\u5728\u516c\u958b MSMO \u8cc7\u6599\u96c6\u4e0a\u7684\u5ee3\u6cdb\u5be6\u9a57\u9a57\u8b49\u4e86 EGMS \u65b9\u6cd5\u7684\u512a\u8d8a\u6027\uff0c\u4e5f\u8b49\u660e\u4e86\u5c07\u5be6\u9ad4\u8cc7\u8a0a\u7d0d\u5165 MSMO \u554f\u984c\u7684\u5fc5\u8981\u6027\u3002", "author": "Yanghai Zhang et.al.", "authors": "Yanghai Zhang, Ye Liu, Shiwei Wu, Kai Zhang, Xukai Liu, Qi Liu, Enhong Chen", "id": "2408.03149v1", "paper_url": "http://arxiv.org/abs/2408.03149v1", "repo": "null"}}