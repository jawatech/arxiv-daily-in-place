{"2406.14868": {"publish_time": "2024-06-21", "title": "Direct Multi-Turn Preference Optimization for Language Agents", "paper_summary": "Adapting Large Language Models (LLMs) for agent tasks is critical in\ndeveloping language agents. Direct Preference Optimization (DPO) is a promising\ntechnique for this adaptation with the alleviation of compounding errors,\noffering a means to directly optimize Reinforcement Learning (RL) objectives.\nHowever, applying DPO to multi-turn tasks presents challenges due to the\ninability to cancel the partition function. Overcoming this obstacle involves\nmaking the partition function independent of the current state and addressing\nlength disparities between preferred and dis-preferred trajectories. In this\nlight, we replace the policy constraint with the state-action occupancy measure\nconstraint in the RL objective and add length normalization to the\nBradley-Terry model, yielding a novel loss function named DMPO for multi-turn\nagent tasks with theoretical explanations. Extensive experiments on three\nmulti-turn agent task datasets confirm the effectiveness and superiority of the\nDMPO loss.", "paper_summary_zh": "\u8abf\u6574\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u4ee5\u9069\u61c9\u4ee3\u7406\u4eba\u4efb\u52d9\uff0c\u5c0d\u65bc\u958b\u767c\u8a9e\u8a00\u4ee3\u7406\u4eba\u81f3\u95dc\u91cd\u8981\u3002\u76f4\u63a5\u504f\u597d\u6700\u4f73\u5316 (DPO) \u662f\u4e00\u7a2e\u6709\u524d\u9014\u7684\u6280\u8853\uff0c\u53ef\u900f\u904e\u7de9\u89e3\u8907\u5408\u932f\u8aa4\u4f86\u9032\u884c\u6b64\u8abf\u6574\uff0c\u63d0\u4f9b\u76f4\u63a5\u6700\u4f73\u5316\u5f37\u5316\u5b78\u7fd2 (RL) \u76ee\u6a19\u7684\u65b9\u6cd5\u3002\u7136\u800c\uff0c\u7531\u65bc\u7121\u6cd5\u53d6\u6d88\u5206\u5272\u51fd\u6578\uff0c\u5c07 DPO \u61c9\u7528\u65bc\u591a\u8f2a\u4efb\u52d9\u6703\u7522\u751f\u6311\u6230\u3002\u514b\u670d\u6b64\u969c\u7919\u6d89\u53ca\u8b93\u5206\u5272\u51fd\u6578\u7368\u7acb\u65bc\u7576\u524d\u72c0\u614b\uff0c\u4e26\u89e3\u6c7a\u9996\u9078\u548c\u975e\u9996\u9078\u8ecc\u8de1\u4e4b\u9593\u7684\u9577\u5ea6\u5dee\u7570\u3002\u6709\u9451\u65bc\u6b64\uff0c\u6211\u5011\u5728 RL \u76ee\u6a19\u4e2d\u7528\u72c0\u614b\u52d5\u4f5c\u4f54\u7528\u6e2c\u91cf\u7d04\u675f\u53d6\u4ee3\u653f\u7b56\u7d04\u675f\uff0c\u4e26\u5c07\u9577\u5ea6\u6b63\u898f\u5316\u52a0\u5165 Bradley-Terry \u6a21\u578b\uff0c\u7522\u751f\u4e00\u500b\u540d\u70ba DMPO \u7684\u65b0\u640d\u5931\u51fd\u6578\uff0c\u7528\u65bc\u591a\u8f2a\u4ee3\u7406\u4eba\u4efb\u52d9\uff0c\u4e26\u9644\u6709\u7406\u8ad6\u8aaa\u660e\u3002\u5728\u4e09\u500b\u591a\u8f2a\u4ee3\u7406\u4eba\u4efb\u52d9\u8cc7\u6599\u96c6\u4e0a\u7684\u5ee3\u6cdb\u5be6\u9a57\u8b49\u5be6\u4e86 DMPO \u640d\u5931\u7684\u6709\u6548\u6027\u548c\u512a\u8d8a\u6027\u3002", "author": "Wentao Shi et.al.", "authors": "Wentao Shi, Mengqi Yuan, Junkang Wu, Qifan Wang, Fuli Feng", "id": "2406.14868v1", "paper_url": "http://arxiv.org/abs/2406.14868v1", "repo": "null"}}