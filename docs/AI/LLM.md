
### LLM
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-05-08**|**THRONE: An Object-based Hallucination Benchmark for the Free-form Generations of Large Vision-Language Models**|Prannay Kaul et.al.|[2405.05256v1](http://arxiv.org/abs/2405.05256v1)|null|
|**2024-05-08**|**Open Source Language Models Can Provide Feedback: Evaluating LLMs' Ability to Help Students Using GPT-4-As-A-Judge**|Charles Koutcheme et.al.|[2405.05253v1](http://arxiv.org/abs/2405.05253v1)|[link](https://github.com/koutchemecharles/iticse24)|
|**2024-05-08**|**You Only Cache Once: Decoder-Decoder Architectures for Language Models**|Yutao Sun et.al.|[2405.05254v2](http://arxiv.org/abs/2405.05254v2)|null|
|**2024-05-08**|**Attention-Driven Training-Free Efficiency Enhancement of Diffusion Models**|Hongjie Wang et.al.|[2405.05252v1](http://arxiv.org/abs/2405.05252v1)|null|
|**2024-05-08**|**LLMs with Personalities in Multi-issue Negotiation Games**|Sean Noh et.al.|[2405.05248v2](http://arxiv.org/abs/2405.05248v2)|null|
|**2024-05-08**|**SVDD Challenge 2024: A Singing Voice Deepfake Detection Challenge Evaluation Plan**|You Zhang et.al.|[2405.05244v1](http://arxiv.org/abs/2405.05244v1)|[link](https://github.com/svddchallenge/ctrsvdd2024_baseline)|
|**2024-05-08**|**Conv-Basis: A New Paradigm for Efficient Attention Inference and Gradient Computation in Transformers**|Jiuxiang Gu et.al.|[2405.05219v1](http://arxiv.org/abs/2405.05219v1)|null|
|**2024-05-08**|**CARE-SD: Classifier-based analysis for recognizing and eliminating stigmatizing and doubt marker labels in electronic health records: model development and validation**|Drew Walker et.al.|[2405.05204v1](http://arxiv.org/abs/2405.05204v1)|null|
|**2024-05-08**|**MIDGARD: Self-Consistency Using Minimum Description Length for Structured Commonsense Reasoning**|Inderjeet Nair et.al.|[2405.05189v1](http://arxiv.org/abs/2405.05189v1)|null|
|**2024-05-08**|**Encoder-Decoder Framework for Interactive Free Verses with Generation with Controllable High-Quality Rhyming**|Tommaso Pasini et.al.|[2405.05176v1](http://arxiv.org/abs/2405.05176v1)|null|
|**2024-05-08**|**Air Gap: Protecting Privacy-Conscious Conversational Agents**|Eugene Bagdasaryan et.al.|[2405.05175v1](http://arxiv.org/abs/2405.05175v1)|null|
|**2024-05-08**|**Motion Capture Analysis of Verb and Adjective Types in Austrian Sign Language**|Julia Krebs et.al.|[2405.05161v1](http://arxiv.org/abs/2405.05161v1)|null|
|**2024-05-08**|**The Potential and Implications of Generative AI on HCI Education**|Ahmed Kharrufa et.al.|[2405.05154v1](http://arxiv.org/abs/2405.05154v1)|null|
|**2024-05-08**|**Hybrid Convolutional Neural Networks with Reliability Guarantee**|Hans Dermot Doran et.al.|[2405.05146v2](http://arxiv.org/abs/2405.05146v2)|null|
|**2024-05-08**|**XAMPLER: Learning to Retrieve Cross-Lingual In-Context Examples**|Peiqin Lin et.al.|[2405.05116v1](http://arxiv.org/abs/2405.05116v1)|null|
|**2024-05-08**|**QFMTS: Generating Query-Focused Summaries over Multi-Table Inputs**|Weijia Zhang et.al.|[2405.05109v1](http://arxiv.org/abs/2405.05109v1)|null|
|**2024-05-08**|**Concerns on Bias in Large Language Models when Creating Synthetic Personae**|Helena A. Haxvig et.al.|[2405.05080v1](http://arxiv.org/abs/2405.05080v1)|null|
|**2024-05-08**|**Designing Skill-Compatible AI: Methodologies and Frameworks in Chess**|Karim Hamade et.al.|[2405.05066v1](http://arxiv.org/abs/2405.05066v1)|null|
|**2024-05-08**|**Conversational Topic Recommendation in Counseling and Psychotherapy with Decision Transformer and Large Language Models**|Aylin Gunal et.al.|[2405.05060v1](http://arxiv.org/abs/2405.05060v1)|null|
|**2024-05-08**|**Seeds of Stereotypes: A Large-Scale Textual Analysis of Race and Gender Associations with Diseases in Online Sources**|Lasse Hyldig Hansen et.al.|[2405.05049v1](http://arxiv.org/abs/2405.05049v1)|null|
|**2024-05-08**|**StyleMamba : State Space Model for Efficient Text-driven Image Style Transfer**|Zijia Wang et.al.|[2405.05027v1](http://arxiv.org/abs/2405.05027v1)|null|
|**2024-05-08**|**ADELIE: Aligning Large Language Models on Information Extraction**|Yunjia Qi et.al.|[2405.05008v1](http://arxiv.org/abs/2405.05008v1)|[link](https://github.com/THU-KEG/ADELIE)|
|**2024-05-08**|**Health Index Estimation Through Integration of General Knowledge with Unsupervised Learning**|Kristupas Bajarunas et.al.|[2405.04990v1](http://arxiv.org/abs/2405.04990v1)|[link](https://github.com/kbaja/unsupervisedhi)|
|**2024-05-08**|**Discrepancy-based Diffusion Models for Lesion Detection in Brain MRI**|Keqiang Fan et.al.|[2405.04974v1](http://arxiv.org/abs/2405.04974v1)|null|
|**2024-05-08**|**A review on discriminative self-supervised learning methods**|Nikolaos Giakoumoglou et.al.|[2405.04969v1](http://arxiv.org/abs/2405.04969v1)|null|
|**2024-05-08**|**P-ICL: Point In-Context Learning for Named Entity Recognition with Large Language Models**|Guochao Jiang et.al.|[2405.04960v1](http://arxiv.org/abs/2405.04960v1)|null|
|**2024-05-08**|**Improving Long Text Understanding with Knowledge Distilled from Summarization Model**|Yan Liu et.al.|[2405.04955v1](http://arxiv.org/abs/2405.04955v1)|null|
|**2024-05-08**|**VisionGraph: Leveraging Large Multimodal Models for Graph Theory Problems in Visual Context**|Yunxin Li et.al.|[2405.04950v1](http://arxiv.org/abs/2405.04950v1)|[link](https://github.com/hitsz-tmg/visiongraph)|
|**2024-05-08**|**Imprecise Probabilities Meet Partial Observability: Game Semantics for Robust POMDPs**|Eline M. Bovy et.al.|[2405.04941v1](http://arxiv.org/abs/2405.04941v1)|null|
|**2024-05-08**|**Developing trustworthy AI applications with foundation models**|Michael Mock et.al.|[2405.04937v1](http://arxiv.org/abs/2405.04937v1)|null|
|**2024-05-08**|**Delve into Base-Novel Confusion: Redundancy Exploration for Few-Shot Class-Incremental Learning**|Haichen Zhou et.al.|[2405.04918v1](http://arxiv.org/abs/2405.04918v1)|null|
|**2024-05-08**|**Traj-LLM: A New Exploration for Empowering Trajectory Prediction with Pre-trained Large Language Models**|Zhengxing Lan et.al.|[2405.04909v1](http://arxiv.org/abs/2405.04909v1)|null|
|**2024-05-08**|**Machine Learning-based NLP for Emotion Classification on a Cholera X Dataset**|Paul Jideani et.al.|[2405.04897v1](http://arxiv.org/abs/2405.04897v1)|null|
|**2024-05-08**|**Molecule-Space: Free Lunch in Unified Multimodal Space via Knowledge Fusion**|Zehan Wang et.al.|[2405.04883v1](http://arxiv.org/abs/2405.04883v1)|[link](https://github.com/moleculespace/moleculespace)|
|**2024-05-08**|**The Codecfake Dataset and Countermeasures for the Universally Detection of Deepfake Audio**|Yuankun Xie et.al.|[2405.04880v1](http://arxiv.org/abs/2405.04880v1)|null|
|**2024-05-08**|**SCALA: Split Federated Learning with Concatenated Activations and Logit Adjustments**|Jiarong Yang et.al.|[2405.04875v1](http://arxiv.org/abs/2405.04875v1)|null|
|**2024-05-08**|**Logical Negation Augmenting and Debiasing for Prompt-based Methods**|Yitian Li et.al.|[2405.04872v1](http://arxiv.org/abs/2405.04872v1)|null|
|**2024-05-08**|**Enhancing Geometric Ontology Embeddings for $\mathcal{EL}^{++}$ with Negative Sampling and Deductive Closure Filtering**|Olga Mashkova et.al.|[2405.04868v1](http://arxiv.org/abs/2405.04868v1)|[link](https://github.com/bio-ontology-research-group/geometric_embeddings)|
|**2024-05-08**|**xMTrans: Temporal Attentive Cross-Modality Fusion Transformer for Long-Term Traffic Prediction**|Huy Quang Ung et.al.|[2405.04841v1](http://arxiv.org/abs/2405.04841v1)|null|
|**2024-05-08**|**Fine-tuning Pre-trained Named Entity Recognition Models For Indian Languages**|Sankalp Bahad et.al.|[2405.04829v1](http://arxiv.org/abs/2405.04829v1)|null|
|**2024-05-08**|**ChuXin: 1.6B Technical Report**|Xiaomin Zhuang et.al.|[2405.04828v1](http://arxiv.org/abs/2405.04828v1)|null|
|**2024-05-08**|**Explanation as a Watermark: Towards Harmless and Multi-bit Model Ownership Verification via Watermarking Feature Attribution**|Shuo Shao et.al.|[2405.04825v1](http://arxiv.org/abs/2405.04825v1)|null|
|**2024-05-08**|**APrompt4EM: Augmented Prompt Tuning for Generalized Entity Matching**|Yikuan Xia et.al.|[2405.04820v1](http://arxiv.org/abs/2405.04820v1)|null|
|**2024-05-08**|**DALK: Dynamic Co-Augmentation of LLMs and KG to answer Alzheimer's Disease Questions with Scientific Literature**|Dawei Li et.al.|[2405.04819v1](http://arxiv.org/abs/2405.04819v1)|[link](https://github.com/david-li0406/dalk)|
|**2024-05-08**|**ACORN: Aspect-wise Commonsense Reasoning Explanation Evaluation**|Ana Brassard et.al.|[2405.04818v1](http://arxiv.org/abs/2405.04818v1)|null|
|**2024-05-08**|**A Novel Technique for Query Plan Representation Based on Graph Neural Networks**|Baoming Chang et.al.|[2405.04814v1](http://arxiv.org/abs/2405.04814v1)|null|
|**2024-05-08**|**From LLMs to Actions: Latent Codes as Bridges in Hierarchical Robot Control**|Yide Shentu et.al.|[2405.04798v1](http://arxiv.org/abs/2405.04798v1)|null|
|**2024-05-08**|**Zero-shot LLM-guided Counterfactual Generation for Text**|Amrita Bhattacharjee et.al.|[2405.04793v1](http://arxiv.org/abs/2405.04793v1)|null|
|**2024-05-08**|**CourseGPT-zh: an Educational Large Language Model Based on Knowledge Distillation Incorporating Prompt Optimization**|Zheyan Qu et.al.|[2405.04781v1](http://arxiv.org/abs/2405.04781v1)|null|
|**2024-05-08**|**Empathy Through Multimodality in Conversational Interfaces**|Mahyar Abbasian et.al.|[2405.04777v1](http://arxiv.org/abs/2405.04777v1)|null|
|**2024-05-08**|**Chain of Thoughtlessness: An Analysis of CoT in Planning**|Kaya Stechly et.al.|[2405.04776v1](http://arxiv.org/abs/2405.04776v1)|null|
|**2024-05-08**|**Hypergraph-enhanced Dual Semi-supervised Graph Classification**|Wei Ju et.al.|[2405.04773v1](http://arxiv.org/abs/2405.04773v1)|null|
|**2024-05-08**|**When Foresight Pruning Meets Zeroth-Order Optimization: Efficient Federated Learning for Low-Memory Devices**|Pengyu Zhang et.al.|[2405.04765v1](http://arxiv.org/abs/2405.04765v1)|null|
|**2024-05-08**|**Large Language Models for Cyber Security: A Systematic Literature Review**|HanXiang Xu et.al.|[2405.04760v2](http://arxiv.org/abs/2405.04760v2)|null|
|**2024-05-08**|**BiasKG: Adversarial Knowledge Graphs to Induce Bias in Large Language Models**|Chu Fei Luo et.al.|[2405.04756v1](http://arxiv.org/abs/2405.04756v1)|[link](https://github.com/VectorInstitute/biaskg)|
|**2024-05-08**|**AttacKG+:Boosting Attack Knowledge Graph Construction with Large Language Models**|Yongheng Zhang et.al.|[2405.04753v1](http://arxiv.org/abs/2405.04753v1)|null|
|**2024-05-08**|**S-EQA: Tackling Situational Queries in Embodied Question Answering**|Vishnu Sashank Dorbala et.al.|[2405.04732v1](http://arxiv.org/abs/2405.04732v1)|null|
|**2024-05-08**|**Learning Phonotactics from Linguistic Informants**|Canaan Breiss et.al.|[2405.04726v1](http://arxiv.org/abs/2405.04726v1)|null|
|**2024-05-07**|**Physics-based deep learning reveals rising heating demand heightens air pollution in Norwegian cities**|Cong Cao et.al.|[2405.04716v1](http://arxiv.org/abs/2405.04716v1)|null|
|**2024-05-07**|**Robust Implementation of Retrieval-Augmented Generation on Edge-based Computing-in-Memory Architectures**|Ruiyang Qin et.al.|[2405.04700v1](http://arxiv.org/abs/2405.04700v1)|null|
|**2024-05-07**|**Bridging the Bosphorus: Advancing Turkish Large Language Models through Strategies for Low-Resource Language Adaptation and Benchmarking**|Emre Can Acikgoz et.al.|[2405.04685v1](http://arxiv.org/abs/2405.04685v1)|null|
|**2024-05-07**|**TALC: Time-Aligned Captions for Multi-Scene Text-to-Video Generation**|Hritik Bansal et.al.|[2405.04682v1](http://arxiv.org/abs/2405.04682v1)|null|
|**2024-05-07**|**Understanding the Capabilities and Limitations of Large Language Models for Cultural Commonsense**|Siqi Shen et.al.|[2405.04655v1](http://arxiv.org/abs/2405.04655v1)|[link](https://github.com/MichiganNLP/LLM_cultural_commonsense)|
|**2024-05-07**|**ResNCT: A Deep Learning Model for the Synthesis of Nephrographic Phase Images in CT Urography**|Syed Jamal Safdar Gardezi et.al.|[2405.04629v1](http://arxiv.org/abs/2405.04629v1)|null|
|**2024-05-07**|**AI in Lung Health: Benchmarking Detection and Diagnostic Models Across Multiple CT Scan Datasets**|Fakrul Islam Tushar et.al.|[2405.04605v1](http://arxiv.org/abs/2405.04605v1)|null|
|**2024-05-07**|**Language Modeling Using Tensor Trains**|Zhan Su et.al.|[2405.04590v1](http://arxiv.org/abs/2405.04590v1)|[link](https://github.com/shuishen112/tensortrainlm)|
|**2024-05-07**|**QServe: W4A8KV4 Quantization and System Co-design for Efficient LLM Serving**|Yujun Lin et.al.|[2405.04532v1](http://arxiv.org/abs/2405.04532v1)|[link](https://github.com/mit-han-lab/qserve)|
|**2024-05-07**|**NaturalCodeBench: Examining Coding Performance Mismatch on HumanEval and Natural User Prompts**|Shudan Zhang et.al.|[2405.04520v1](http://arxiv.org/abs/2405.04520v1)|null|
|**2024-05-07**|**xLSTM: Extended Long Short-Term Memory**|Maximilian Beck et.al.|[2405.04517v1](http://arxiv.org/abs/2405.04517v1)|null|
|**2024-05-07**|**A Transformer with Stack Attention**|Jiaoda Li et.al.|[2405.04515v1](http://arxiv.org/abs/2405.04515v1)|[link](https://github.com/rycolab/stack-transformer)|
|**2024-05-07**|**Switchable Decision: Dynamic Neural Generation Networks**|Shujian Zhang et.al.|[2405.04513v1](http://arxiv.org/abs/2405.04513v1)|null|
|**2024-05-07**|**Toward In-Context Teaching: Adapting Examples to Students' Misconceptions**|Alexis Ross et.al.|[2405.04495v1](http://arxiv.org/abs/2405.04495v1)|null|
|**2024-05-07**|**TorchDriveEnv: A Reinforcement Learning Benchmark for Autonomous Driving with Reactive, Realistic, and Diverse Non-Playable Characters**|Jonathan Wilder Lavington et.al.|[2405.04491v1](http://arxiv.org/abs/2405.04491v1)|null|
|**2024-05-07**|**Towards Continual Knowledge Graph Embedding via Incremental Distillation**|Jiajun Liu et.al.|[2405.04453v1](http://arxiv.org/abs/2405.04453v1)|[link](https://github.com/seukgcode/incde)|
|**2024-05-07**|**POV Learning: Individual Alignment of Multimodal Models using Human Perception**|Simon Werner et.al.|[2405.04443v1](http://arxiv.org/abs/2405.04443v1)|null|
|**2024-05-07**|**AugmenTory: A Fast and Flexible Polygon Augmentation Library**|Tanaz Ghahremani et.al.|[2405.04442v1](http://arxiv.org/abs/2405.04442v1)|null|
|**2024-05-07**|**DeepSeek-V2: A Strong, Economical, and Efficient Mixture-of-Experts Language Model**|DeepSeek-AI et.al.|[2405.04434v2](http://arxiv.org/abs/2405.04434v2)|[link](https://github.com/deepseek-ai/deepseek-v2)|
|**2024-05-07**|**The Silicone Ceiling: Auditing GPT's Race and Gender Biases in Hiring**|Lena Armstrong et.al.|[2405.04412v1](http://arxiv.org/abs/2405.04412v1)|null|
|**2024-05-07**|**Vision Mamba: A Comprehensive Survey and Taxonomy**|Xiao Liu et.al.|[2405.04404v1](http://arxiv.org/abs/2405.04404v1)|[link](https://github.com/lx6c78/vision-mamba-a-comprehensive-survey-and-taxonomy)|
|**2024-05-07**|**Learning To See But Forgetting To Follow: Visual Instruction Tuning Makes LLMs More Prone To Jailbreak Attacks**|Georgios Pantazopoulos et.al.|[2405.04403v1](http://arxiv.org/abs/2405.04403v1)|[link](https://github.com/gpantaz/vl_jailbreak)|
|**2024-05-07**|**Pragmatist Intelligence: Where the Principle of Usefulness Can Take ANNs**|Antonio Bikić et.al.|[2405.04386v1](http://arxiv.org/abs/2405.04386v1)|null|
|**2024-05-07**|**Leveraging LSTM and GAN for Modern Malware Detection**|Ishita Gupta et.al.|[2405.04373v1](http://arxiv.org/abs/2405.04373v1)|null|
|**2024-05-07**|**Explainable machine learning for predicting shellfish toxicity in the Adriatic Sea using long-term monitoring data of HABs**|Martin Marzidovšek et.al.|[2405.04372v2](http://arxiv.org/abs/2405.04372v2)|null|
|**2024-05-07**|**Inferring Discussion Topics about Exploitation of Vulnerabilities from Underground Hacking Forums**|Felipe Moreno-Vera et.al.|[2405.04561v1](http://arxiv.org/abs/2405.04561v1)|[link](https://github.com/fmorenovr/nlptoolkit)|
|**2024-05-07**|**Global Scale Self-Supervised Channel Charting with Sensor Fusion**|Omid Esrafilian et.al.|[2405.04357v1](http://arxiv.org/abs/2405.04357v1)|null|
|**2024-05-07**|**Revisiting character-level adversarial attacks**|Elias Abad Rocamora et.al.|[2405.04346v1](http://arxiv.org/abs/2405.04346v1)|[link](https://github.com/lions-epfl/charmer)|
|**2024-05-07**|**Temporal and Heterogeneous Graph Neural Network for Remaining Useful Life Prediction**|Zhihao Wen et.al.|[2405.04336v1](http://arxiv.org/abs/2405.04336v1)|null|
|**2024-05-07**|**A Fourth Wave of Open Data? Exploring the Spectrum of Scenarios for Open Data and Generative AI**|Hannah Chafetz et.al.|[2405.04333v1](http://arxiv.org/abs/2405.04333v1)|null|
|**2024-05-07**|**Deception in Reinforced Autonomous Agents: The Unconventional Rabbit Hat Trick in Legislation**|Atharvan Dogra et.al.|[2405.04325v1](http://arxiv.org/abs/2405.04325v1)|null|
|**2024-05-07**|**Granite Code Models: A Family of Open Foundation Models for Code Intelligence**|Mayank Mishra et.al.|[2405.04324v1](http://arxiv.org/abs/2405.04324v1)|[link](https://github.com/ibm-granite/granite-code-models)|
|**2024-05-07**|**Beyond human subjectivity and error: a novel AI grading system**|Alexandra Gobrecht et.al.|[2405.04323v1](http://arxiv.org/abs/2405.04323v1)|null|
|**2024-05-07**|**Cross-IQA: Unsupervised Learning for Image Quality Assessment**|Zhen Zhang et.al.|[2405.04311v1](http://arxiv.org/abs/2405.04311v1)|null|
|**2024-05-07**|**Improving Offline Reinforcement Learning with Inaccurate Simulators**|Yiwen Hou et.al.|[2405.04307v1](http://arxiv.org/abs/2405.04307v1)|null|
|**2024-05-07**|**A New Dataset and Comparative Study for Aphid Cluster Detection and Segmentation in Sorghum Fields**|Raiyan Rahman et.al.|[2405.04305v1](http://arxiv.org/abs/2405.04305v1)|null|
|**2024-05-07**|**Accelerating Speculative Decoding using Dynamic Speculation Length**|Jonathan Mamou et.al.|[2405.04304v1](http://arxiv.org/abs/2405.04304v1)|null|
|**2024-05-07**|**Behaviour Planning: A Toolkit for Diverse Planning**|Mustafa F Abdelwahed et.al.|[2405.04300v1](http://arxiv.org/abs/2405.04300v1)|null|
|**2024-05-07**|**Enhancing the Efficiency and Accuracy of Underlying Asset Reviews in Structured Finance: The Application of Multi-agent Framework**|Xiangpeng Wan et.al.|[2405.04294v1](http://arxiv.org/abs/2405.04294v1)|[link](https://github.com/elricwan/audit)|
|**2024-05-07**|**Mitigating Clickbait: An Approach to Spoiler Generation Using Multitask Learning**|Sayantan Pal et.al.|[2405.04292v1](http://arxiv.org/abs/2405.04292v1)|null|
|**2024-05-07**|**Who Wrote This? The Key to Zero-Shot LLM-Generated Text Detection Is GECScore**|Junchao Wu et.al.|[2405.04286v1](http://arxiv.org/abs/2405.04286v1)|null|
|**2024-05-07**|**On the Foundations of Earth and Climate Foundation Models**|Xiao Xiang Zhu et.al.|[2405.04285v1](http://arxiv.org/abs/2405.04285v1)|null|

#### Abstracts
##### **THRONE: An Object-based Hallucination Benchmark for the Free-form Generations of Large Vision-Language Models**
2405.05256v1 by Prannay Kaul, Zhizhong Li, Hao Yang, Yonatan Dukler, Ashwin Swaminathan, C. J. Taylor, Stefano Soatto

Mitigating hallucinations in large vision-language models (LVLMs) remains an
open problem. Recent benchmarks do not address hallucinations in open-ended
free-form responses, which we term "Type I hallucinations". Instead, they focus
on hallucinations responding to very specific question formats -- typically a
multiple-choice response regarding a particular object or attribute -- which we
term "Type II hallucinations". Additionally, such benchmarks often require
external API calls to models which are subject to change. In practice, we
observe that a reduction in Type II hallucinations does not lead to a reduction
in Type I hallucinations but rather that the two forms of hallucinations are
often anti-correlated. To address this, we propose THRONE, a novel object-based
automatic framework for quantitatively evaluating Type I hallucinations in LVLM
free-form outputs. We use public language models (LMs) to identify
hallucinations in LVLM responses and compute informative metrics. By evaluating
a large selection of recent LVLMs using public datasets, we show that an
improvement in existing metrics do not lead to a reduction in Type I
hallucinations, and that established benchmarks for measuring Type I
hallucinations are incomplete. Finally, we provide a simple and effective data
augmentation method to reduce Type I and Type II hallucinations as a strong
baseline.

摘要：大型视觉语言模型 (LVLMs) 中的幻觉缓解仍然是一个悬而未决的问题。最近的基准没有解决开放式自由形式响应中的幻觉，我们称之为“I 型幻觉”。相反，它们专注于对非常具体的问题格式做出回应的幻觉——通常是关于特定对象或属性的多项选择响应——我们称之为“II 型幻觉”。此外，此类基准通常需要对模型进行外部 API 调用，而这些模型可能会发生变化。在实践中，我们观察到 II 型幻觉的减少并没有导致 I 型幻觉的减少，而是两种形式的幻觉通常是反相关的。为了解决这个问题，我们提出了 THRONE，这是一个基于对象的新型自动框架，用于对 LVLM 自由形式输出中的 I 型幻觉进行定量评估。我们使用公共语言模型 (LM) 来识别 LVLM 响应中的幻觉并计算信息丰富的指标。通过使用公共数据集评估大量最近的 LVLMs，我们表明现有指标的改进并没有导致 I 型幻觉的减少，并且用于测量 I 型幻觉的既定基准是不完整的。最后，我们提供了一种简单有效的 data augmentation 方法来减少 I 型和 II 型幻觉作为强基线。

##### **Open Source Language Models Can Provide Feedback: Evaluating LLMs' Ability to Help Students Using GPT-4-As-A-Judge**
2405.05253v1 by Charles Koutcheme, Nicola Dainese, Sami Sarsa, Arto Hellas, Juho Leinonen, Paul Denny

Large language models (LLMs) have shown great potential for the automatic
generation of feedback in a wide range of computing contexts. However, concerns
have been voiced around the privacy and ethical implications of sending student
work to proprietary models. This has sparked considerable interest in the use
of open source LLMs in education, but the quality of the feedback that such
open models can produce remains understudied. This is a concern as providing
flawed or misleading generated feedback could be detrimental to student
learning. Inspired by recent work that has utilised very powerful LLMs, such as
GPT-4, to evaluate the outputs produced by less powerful models, we conduct an
automated analysis of the quality of the feedback produced by several open
source models using a dataset from an introductory programming course. First,
we investigate the viability of employing GPT-4 as an automated evaluator by
comparing its evaluations with those of a human expert. We observe that GPT-4
demonstrates a bias toward positively rating feedback while exhibiting moderate
agreement with human raters, showcasing its potential as a feedback evaluator.
Second, we explore the quality of feedback generated by several leading
open-source LLMs by using GPT-4 to evaluate the feedback. We find that some
models offer competitive performance with popular proprietary LLMs, such as
ChatGPT, indicating opportunities for their responsible use in educational
settings.

摘要：大型語言模型 (LLM) 已在各種運算環境中展現出自動產生回饋的強大潛力。然而，對於將學生作業傳送至專有模型的隱私和倫理影響，已引起各界關注。這點燃了人們對在教育中使用開放原始碼 LLM 的濃厚興趣，但此類開放模型能產生的回饋品質仍有待深入探討。這是個令人擔憂的問題，因為提供有缺陷或誤導性的產生式回饋可能會對學生的學習造成負面影響。受到近期採用功能強大的 LLM（例如 GPT-4）來評估功能較弱的模型產出之研究啟發，我們使用來自入門程式設計課程的資料集，對幾個開放原始碼模型產生的回饋品質進行自動化分析。首先，我們透過將 GPT-4 的評估結果與人類專家的評估結果進行比較，來探討採用 GPT-4 作為自動化評估器的可行性。我們觀察到，GPT-4 在評分回饋時表現出正向偏誤，同時與人類評分者展現出適度的共識，顯示其作為回饋評估器的潛力。其次，我們使用 GPT-4 來評估回饋，進一步探討幾個領先的開放原始碼 LLM 所產生回饋的品質。我們發現，某些模型提供的效能可與流行的專有 LLM（例如 ChatGPT）相媲美，這表示它們在教育環境中負責任地使用是有機會的。

##### **You Only Cache Once: Decoder-Decoder Architectures for Language Models**
2405.05254v2 by Yutao Sun, Li Dong, Yi Zhu, Shaohan Huang, Wenhui Wang, Shuming Ma, Quanlu Zhang, Jianyong Wang, Furu Wei

We introduce a decoder-decoder architecture, YOCO, for large language models,
which only caches key-value pairs once. It consists of two components, i.e., a
cross-decoder stacked upon a self-decoder. The self-decoder efficiently encodes
global key-value (KV) caches that are reused by the cross-decoder via
cross-attention. The overall model behaves like a decoder-only Transformer,
although YOCO only caches once. The design substantially reduces GPU memory
demands, yet retains global attention capability. Additionally, the computation
flow enables prefilling to early exit without changing the final output,
thereby significantly speeding up the prefill stage. Experimental results
demonstrate that YOCO achieves favorable performance compared to Transformer in
various settings of scaling up model size and number of training tokens. We
also extend YOCO to 1M context length with near-perfect needle retrieval
accuracy. The profiling results show that YOCO improves inference memory,
prefill latency, and throughput by orders of magnitude across context lengths
and model sizes. Code is available at https://aka.ms/YOCO.

摘要：我們為大型語言模型引入了解碼器-解碼器架構 YOCO，它只快取一次鍵值對。它包含兩個組成部分，即堆疊在自解碼器上的交叉解碼器。自解碼器有效地編碼全局鍵值 (KV) 快取，而交叉解碼器透過交叉注意力重複使用這些快取。整體模型的行為類似於僅解碼器的 Transformer，儘管 YOCO 只快取一次。此設計大幅降低了 GPU 記憶體需求，但仍保留了全局注意力能力。此外，運算流程能夠在不變更最終輸出的情況下進行預先填入以提前退出，從而大幅加快預先填入階段。實驗結果證明，與 Transformer 相比，YOCO 在擴充模型大小和訓練權杖數量的各種設定中都達到了良好的效能。我們也將 YOCO 延伸到 1 百萬文字脈絡長度，並具有接近完美的針頭擷取準確度。分析結果顯示，YOCO 在各種文字脈絡長度和模型大小中，大幅改善了推論記憶體、預先填入延遲和處理量。程式碼可於 https://aka.ms/YOCO 取得。

##### **Attention-Driven Training-Free Efficiency Enhancement of Diffusion Models**
2405.05252v1 by Hongjie Wang, Difan Liu, Yan Kang, Yijun Li, Zhe Lin, Niraj K. Jha, Yuchen Liu

Diffusion Models (DMs) have exhibited superior performance in generating
high-quality and diverse images. However, this exceptional performance comes at
the cost of expensive architectural design, particularly due to the attention
module heavily used in leading models. Existing works mainly adopt a retraining
process to enhance DM efficiency. This is computationally expensive and not
very scalable. To this end, we introduce the Attention-driven Training-free
Efficient Diffusion Model (AT-EDM) framework that leverages attention maps to
perform run-time pruning of redundant tokens, without the need for any
retraining. Specifically, for single-denoising-step pruning, we develop a novel
ranking algorithm, Generalized Weighted Page Rank (G-WPR), to identify
redundant tokens, and a similarity-based recovery method to restore tokens for
the convolution operation. In addition, we propose a Denoising-Steps-Aware
Pruning (DSAP) approach to adjust the pruning budget across different denoising
timesteps for better generation quality. Extensive evaluations show that AT-EDM
performs favorably against prior art in terms of efficiency (e.g., 38.8% FLOPs
saving and up to 1.53x speed-up over Stable Diffusion XL) while maintaining
nearly the same FID and CLIP scores as the full model. Project webpage:
https://atedm.github.io.

摘要：擴散模型 (DM) 在生成高品質且多樣化的圖像方面表現出色的效能。然而，這種卓越的效能是以昂貴的架構設計為代價，特別是因為注意力模組大量用於領先的模型中。現有的作品主要採用再訓練的過程來增強 DM 效率。這在計算上很昂貴，而且擴充性不佳。為此，我們引入了注意力驅動的無訓練高效擴散模型 (AT-EDM) 架構，它利用注意力圖在執行時修剪冗餘的符號，而無需進行任何再訓練。具體來說，對於單一去噪步驟的修剪，我們開發了一種新穎的排名演算法，即廣義加權頁面排名 (G-WPR)，以識別冗餘的符號，並使用基於相似性的復原方法來復原用於卷積運算的符號。此外，我們提出了一種去噪步驟感知修剪 (DSAP) 方法，以調整不同去噪時間步長的修剪預算，以獲得更好的生成品質。廣泛的評估顯示，AT-EDM 在效率方面表現優於先前的技術（例如，節省 38.8% 的 FLOP，並且速度比 Stable Diffusion XL 快 1.53 倍），同時維持與完整模型幾乎相同的 FID 和 CLIP 分數。專案網頁：https://atedm.github.io。

##### **LLMs with Personalities in Multi-issue Negotiation Games**
2405.05248v2 by Sean Noh, Ho-Chun Herbert Chang

Powered by large language models (LLMs), AI agents have become capable of
many human tasks. Using the most canonical definitions of the Big Five
personality, we measure the ability of LLMs to negotiate within a
game-theoretical framework, as well as methodological challenges to measuring
notions of fairness and risk. Simulations (n=1,500) for both single-issue and
multi-issue negotiation reveal increase in domain complexity with asymmetric
issue valuations improve agreement rates but decrease surplus from aggressive
negotiation. Through gradient-boosted regression and Shapley explainers, we
find high openness, conscientiousness, and neuroticism are associated with fair
tendencies; low agreeableness and low openness are associated with rational
tendencies. Low conscientiousness is associated with high toxicity. These
results indicate that LLMs may have built-in guardrails that default to fair
behavior, but can be "jail broken" to exploit agreeable opponents. We also
offer pragmatic insight in how negotiation bots can be designed, and a
framework of assessing negotiation behavior based on game theory and
computational social science.

摘要：透過大型語言模型（LLM）的驅動，AI 代理已經能夠執行許多人類任務。使用大五人格特質中最具代表性的定義，我們測量 LLM 在博弈論架構中協商的能力，以及測量公平性和風險概念的方法論挑戰。針對單一議題和多重議題協商的模擬（n=1,500）顯示，隨著議題估值不對稱，領域複雜性會增加，這會改善協議率，但會減少激進協商的盈餘。透過梯度提升迴歸和 Shapley 解釋器，我們發現開放性、盡責性和神經質傾向與公平傾向有關；低宜人性與低開放性與理性傾向有關。低盡責性與高毒性有關。這些結果表明，LLM 可能內建了預設為公平行為的防護機制，但可以被「越獄」以利用合適的對手。我們也提供了關於協商機器人如何設計的務實見解，以及一個基於博弈論和計算社會科學評估協商行為的架構。

##### **SVDD Challenge 2024: A Singing Voice Deepfake Detection Challenge Evaluation Plan**
2405.05244v1 by You Zhang, Yongyi Zang, Jiatong Shi, Ryuichi Yamamoto, Jionghao Han, Yuxun Tang, Tomoki Toda, Zhiyao Duan

The rapid advancement of AI-generated singing voices, which now closely mimic
natural human singing and align seamlessly with musical scores, has led to
heightened concerns for artists and the music industry. Unlike spoken voice,
singing voice presents unique challenges due to its musical nature and the
presence of strong background music, making singing voice deepfake detection
(SVDD) a specialized field requiring focused attention. To promote SVDD
research, we recently proposed the "SVDD Challenge," the very first research
challenge focusing on SVDD for lab-controlled and in-the-wild bonafide and
deepfake singing voice recordings. The challenge will be held in conjunction
with the 2024 IEEE Spoken Language Technology Workshop (SLT 2024).

摘要：隨著 AI 生成的歌聲快速進步，現在已能緊密模仿自然的人聲演唱，並與樂譜無縫對齊，這讓藝術家和音樂產業高度關注。與說話的聲音不同，歌聲因其音樂性質和強烈的背景音樂而呈現出獨特的挑戰，使得歌聲深度造假偵測 (SVDD) 成為需要專注關注的專業領域。為了推廣 SVDD 研究，我們最近提出了「SVDD 挑戰」，這是第一個專注於實驗室控制和野外真實與深度造假的歌聲錄音的 SVDD 研究挑戰。此挑戰將與 2024 年 IEEE 口語語言技術研討會 (SLT 2024) 同時舉行。

##### **Conv-Basis: A New Paradigm for Efficient Attention Inference and Gradient Computation in Transformers**
2405.05219v1 by Jiuxiang Gu, Yingyu Liang, Heshan Liu, Zhenmei Shi, Zhao Song, Junze Yin

Large Language Models (LLMs) have profoundly changed the world. Their
self-attention mechanism is the key to the success of transformers in LLMs.
However, the quadratic computational cost $O(n^2)$ to the length $n$ input
sequence is the notorious obstacle for further improvement and scalability in
the longer context. In this work, we leverage the convolution-like structure of
attention matrices to develop an efficient approximation method for attention
computation using convolution matrices. We propose a $\mathsf{conv}$ basis
system, "similar" to the rank basis, and show that any lower triangular
(attention) matrix can always be decomposed as a sum of $k$ structured
convolution matrices in this basis system. We then design an algorithm to
quickly decompose the attention matrix into $k$ convolution matrices. Thanks to
Fast Fourier Transforms (FFT), the attention {\it inference} can be computed in
$O(knd \log n)$ time, where $d$ is the hidden dimension. In practice, we have $
d \ll n$, i.e., $d=3,072$ and $n=1,000,000$ for Gemma. Thus, when $kd =
n^{o(1)}$, our algorithm achieve almost linear time, i.e., $n^{1+o(1)}$.
Furthermore, the attention {\it training forward} and {\it backward gradient}
can be computed in $n^{1+o(1)}$ as well. Our approach can avoid explicitly
computing the $n \times n$ attention matrix, which may largely alleviate the
quadratic computational complexity. Furthermore, our algorithm works on any
input matrices. This work provides a new paradigm for accelerating attention
computation in transformers to enable their application to longer contexts.

摘要：大型語言模型 (LLM) 深刻地改變了世界。它們的自我注意機制是 LLM 中Transformer的成功的關鍵。然而，對於長度為 n 的輸入序列，二次計算成本 $O(n^2)$ 是進一步改進和擴展到更長語境中的著名障礙。在這項工作中，我們利用注意矩陣的卷積類似結構，開發了一種使用卷積矩陣對注意力計算進行有效近似的方法。我們提出了一個 $\mathsf{conv}$ 基礎系統，它「類似」於秩基礎，並證明任何下三角（注意力）矩陣都可以始終分解為這個基礎系統中 k 個結構化卷積矩陣的和。然後，我們設計了一種演算法，將注意力矩陣快速分解為 k 個卷積矩陣。得益於快速傅立葉轉換 (FFT)，注意力「推論」可以在 $O(knd \log n)$ 時間內計算，其中 d 是隱藏維度。在實務中，我們有 $d \ll n$，即對於 Gemma，$d=3,072$ 且 $n=1,000,000$。因此，當 $kd = n^{o(1)}$ 時，我們的演算法幾乎達到線性時間，即 $n^{1+o(1)}$。此外，注意力「訓練前向」和「反向梯度」也可以在 $n^{1+o(1)}$ 中計算。我們的做法可以避免明確計算 $n \times n$ 注意力矩陣，這可能會大幅減輕二次計算複雜度。此外，我們的演算法適用於任何輸入矩陣。這項工作為加速Transformer中的注意力計算提供了一個新的典範，以使其能夠應用於更長的語境中。

##### **CARE-SD: Classifier-based analysis for recognizing and eliminating stigmatizing and doubt marker labels in electronic health records: model development and validation**
2405.05204v1 by Drew Walker, Annie Thorne, Sudeshna Das, Jennifer Love, Hannah LF Cooper, Melvin Livingston III, Abeed Sarker

Objective: To detect and classify features of stigmatizing and biased
language in intensive care electronic health records (EHRs) using natural
language processing techniques. Materials and Methods: We first created a
lexicon and regular expression lists from literature-driven stem words for
linguistic features of stigmatizing patient labels, doubt markers, and scare
quotes within EHRs. The lexicon was further extended using Word2Vec and GPT
3.5, and refined through human evaluation. These lexicons were used to search
for matches across 18 million sentences from the de-identified Medical
Information Mart for Intensive Care-III (MIMIC-III) dataset. For each
linguistic bias feature, 1000 sentence matches were sampled, labeled by expert
clinical and public health annotators, and used to supervised learning
classifiers. Results: Lexicon development from expanded literature stem-word
lists resulted in a doubt marker lexicon containing 58 expressions, and a
stigmatizing labels lexicon containing 127 expressions. Classifiers for doubt
markers and stigmatizing labels had the highest performance, with macro
F1-scores of .84 and .79, positive-label recall and precision values ranging
from .71 to .86, and accuracies aligning closely with human annotator agreement
(.87). Discussion: This study demonstrated the feasibility of supervised
classifiers in automatically identifying stigmatizing labels and doubt markers
in medical text, and identified trends in stigmatizing language use in an EHR
setting. Additional labeled data may help improve lower scare quote model
performance. Conclusions: Classifiers developed in this study showed high model
performance and can be applied to identify patterns and target interventions to
reduce stigmatizing labels and doubt markers in healthcare systems.

摘要：<paragraph>目標：使用自然語言處理技術來偵測和分類加護病房電子病歷（EHR）中污名化和偏見語言的特徵。材料和方法：我們首先從文獻驅動的詞幹字建立詞彙和正規表示式清單，以找出污名化患者標籤、懷疑標記和 EHR 中的恐嚇引號的語言特徵。詞彙進一步使用 Word2Vec 和 GPT 3.5 擴充，並透過人工評估進行精煉。這些詞彙用於在去識別的重症監護醫療資訊市場 III（MIMIC-III）資料集的 1,800 萬個句子中搜尋比對。對於每個語言偏見特徵，抽取 1,000 個句子比對，由臨床和公共衛生專家註解員標籤，並用於監督學習分類器。結果：從擴充的文獻詞幹字清單開發詞彙，產生包含 58 個表達式的懷疑標記詞彙，以及包含 127 個表達式的污名化標籤詞彙。懷疑標記和污名化標籤的分類器效能最高，巨觀 F1 分數為 .84 和 .79，正標籤召回率和精確度值介於 .71 到 .86，準確度與人工註解員的一致性非常接近（.87）。討論：這項研究證明了監督分類器在自動識別醫療文本中的污名化標籤和懷疑標記的可行性，並找出在 EHR 設定中使用污名化語言的趨勢。額外的標籤資料可能有助於改善較低的恐嚇引號模型效能。結論：本研究中開發的分類器顯示出很高的模型效能，可用於識別模式和目標介入措施，以減少醫療保健系統中的污名化標籤和懷疑標記。</paragraph>

##### **MIDGARD: Self-Consistency Using Minimum Description Length for Structured Commonsense Reasoning**
2405.05189v1 by Inderjeet Nair, Lu Wang

We study the task of conducting structured reasoning as generating a
reasoning graph from natural language input using large language models (LLMs).
Previous approaches have explored various prompting schemes, yet they suffer
from error propagation due to the autoregressive nature and single-pass-based
decoding, which lack error correction capability. Additionally, relying solely
on a single sample may result in the omission of true nodes and edges. To
counter this, we draw inspiration from self-consistency (SC), which involves
sampling a diverse set of reasoning chains and taking the majority vote as the
final answer. To tackle the substantial challenge of applying SC on generated
graphs, we propose MIDGARD (MInimum Description length Guided Aggregation of
Reasoning in Directed acyclic graph) that leverages Minimum Description Length
(MDL)-based formulation to identify consistent properties among the different
graph samples generated by an LLM. This formulation helps reject properties
that appear in only a few samples, which are likely to be erroneous, while
enabling the inclusion of missing elements without compromising precision. Our
method demonstrates superior performance than comparisons across various
structured reasoning tasks, including argument structure extraction,
explanation graph generation, inferring dependency relations among actions for
everyday tasks, and semantic graph generation from natural texts.

摘要：我們研究將結構化推理的任務作為使用大型語言模型 (LLM) 從自然語言輸入產生推理圖。
先前的做法已探討各種提示方案，但由於自迴歸性質和基於單次傳遞的解碼，它們會遭受錯誤傳播，而這缺乏錯誤修正能力。此外，僅依賴單一範例可能會導致遺漏真實節點和邊緣。為了解決此問題，我們從自一致性 (SC) 中汲取靈感，其中涉及取樣多元推理鏈並將多數決作為最終答案。為了應對在生成圖形上應用 SC 的重大挑戰，我們提出了 MIDGARD (無向非循環圖中推理的最小描述長度引導聚合)，它利用基於最小描述長度 (MDL) 的公式來識別 LLM 生成的不同圖形範例之間的一致屬性。此公式有助於拒絕僅出現在少數範例中且可能錯誤的屬性，同時在不損及精準度的前提下納入遺失元素。我們的模型在各種結構化推理任務中表現出優於比較的效能，包括論證結構提取、解釋圖形生成、推論日常任務中動作之間的依賴關係，以及從自然文本生成語義圖形。

##### **Encoder-Decoder Framework for Interactive Free Verses with Generation with Controllable High-Quality Rhyming**
2405.05176v1 by Tommaso Pasini, Alejo López-Ávila, Husam Quteineh, Gerasimos Lampouras, Jinhua Du, Yubing Wang, Ze Li, Yusen Sun

Composing poetry or lyrics involves several creative factors, but a
challenging aspect of generation is the adherence to a more or less strict
metric and rhyming pattern. To address this challenge specifically, previous
work on the task has mainly focused on reverse language modeling, which brings
the critical selection of each rhyming word to the forefront of each verse. On
the other hand, reversing the word order requires that models be trained from
scratch with this task-specific goal and cannot take advantage of transfer
learning from a Pretrained Language Model (PLM). We propose a novel fine-tuning
approach that prepends the rhyming word at the start of each lyric, which
allows the critical rhyming decision to be made before the model commits to the
content of the lyric (as during reverse language modeling), but maintains
compatibility with the word order of regular PLMs as the lyric itself is still
generated in left-to-right order. We conducted extensive experiments to compare
this fine-tuning against the current state-of-the-art strategies for rhyming,
finding that our approach generates more readable text and better rhyming
capabilities. Furthermore, we furnish a high-quality dataset in English and 12
other languages, analyse the approach's feasibility in a multilingual context,
provide extensive experimental results shedding light on good and bad practices
for lyrics generation, and propose metrics to compare methods in the future.

摘要：創作詩歌或歌詞牽涉到多項創意因素，但生成過程中的一項挑戰性面向在於必須遵守或多或少嚴格的格律和押韻模式。為了特別解決這項挑戰，先前針對這項任務的研究主要著重於反向語言建模，這會讓每個押韻字詞的關鍵選擇成為每節經文的最前要務。另一方面，反轉字詞順序需要模型針對這個特定任務目標從頭訓練，且無法利用預訓練語言模型 (PLM) 的轉移學習。我們提出一個新穎的微調方法，將押韻字詞置於每句歌詞的開頭，這讓關鍵的押韻決定可以在模型承諾歌詞內容之前做出（就像在反向語言建模期間一樣），但維持與一般 PLM 的字詞順序相容，因為歌詞本身仍以由左至右的順序生成。我們進行了廣泛的實驗，將這個微調與目前押韻技術的最新策略進行比較，發現我們的做法能產生更具可讀性的文字和更好的押韻能力。此外，我們提供了英文和其他 12 種語言的高品質資料集，分析了該方法在多語言環境中的可行性，提供了廣泛的實驗結果，闡明了歌詞生成的良好和不良做法，並提出了用於未來比較方法的指標。

##### **Air Gap: Protecting Privacy-Conscious Conversational Agents**
2405.05175v1 by Eugene Bagdasaryan, Ren Yi, Sahra Ghalebikesabi, Peter Kairouz, Marco Gruteser, Sewoong Oh, Borja Balle, Daniel Ramage

The growing use of large language model (LLM)-based conversational agents to
manage sensitive user data raises significant privacy concerns. While these
agents excel at understanding and acting on context, this capability can be
exploited by malicious actors. We introduce a novel threat model where
adversarial third-party apps manipulate the context of interaction to trick
LLM-based agents into revealing private information not relevant to the task at
hand.
  Grounded in the framework of contextual integrity, we introduce AirGapAgent,
a privacy-conscious agent designed to prevent unintended data leakage by
restricting the agent's access to only the data necessary for a specific task.
Extensive experiments using Gemini, GPT, and Mistral models as agents validate
our approach's effectiveness in mitigating this form of context hijacking while
maintaining core agent functionality. For example, we show that a single-query
context hijacking attack on a Gemini Ultra agent reduces its ability to protect
user data from 94% to 45%, while an AirGapAgent achieves 97% protection,
rendering the same attack ineffective.

摘要：隨著基於大型語言模型 (LLM) 的對話式代理程式日益用於管理敏感的使用者資料，這會引發重大的隱私問題。雖然這些代理程式擅長理解和處理脈絡，但惡意行為者可能會利用此功能。我們引入了一個新的威脅模型，其中惡意的第三方應用程式會操縱互動脈絡，誘騙基於 LLM 的代理程式揭露與手邊任務無關的私人資訊。
  基於脈絡完整性的架構，我們引入了 AirGapAgent，這是一個注重隱私的代理程式，旨在透過限制代理程式僅存取特定任務所需的資料來防止意外的資料外洩。使用 Gemini、GPT 和 Mistral 模型作為代理程式的廣泛實驗驗證了我們的方法在減輕這種形式的脈絡劫持時的有效性，同時維持核心代理程式功能。例如，我們展示了對 Gemini Ultra 代理程式的單一查詢脈絡劫持攻擊，會將其保護使用者資料的能力從 94% 降低到 45%，而 AirGapAgent 達到了 97% 的保護，讓相同的攻擊無效。

##### **Motion Capture Analysis of Verb and Adjective Types in Austrian Sign Language**
2405.05161v1 by Julia Krebs, Evie Malaia, Ronnie B. Wilbur, Isabella Fessl, Hans-Peter Wiesinger, Hermann Schwameder, Dietmar Roehm

Across a number of sign languages, temporal and spatial characteristics of
dominant hand articulation are used to express semantic and grammatical
features. In this study of Austrian Sign Language (\"Osterreichische
Geb\"ardensprache, or \"OGS), motion capture data of four Deaf signers is used
to quantitatively characterize the kinematic parameters of sign production in
verbs and adjectives. We investigate (1) the difference in production between
verbs involving a natural endpoint (telic verbs; e.g. arrive) and verbs lacking
an endpoint (atelic verbs; e.g. analyze), and (2) adjective signs in
intensified vs. non-intensified (plain) forms. Motion capture data analysis
using linear-mixed effects models (LME) indicates that both the endpoint
marking in verbs, as well as marking of intensification in adjectives, are
expressed by movement modulation in \"OGS. While the semantic distinction
between verb types (telic/atelic) is marked by higher peak velocity and shorter
duration for telic signs compared to atelic ones, the grammatical distinction
(intensification) in adjectives is expressed by longer duration for intensified
compared to non-intensified adjectives. The observed individual differences of
signers might be interpreted as personal signing style.

摘要：在許多手語中，慣用手關節的時間和空間特性被用來表達語義和語法特徵。在這項關於奧地利手語（「Osterreichische Geb\"ardensprache」或「OGS」）的研究中，四位聾人手語者的動作捕捉資料被用來量化描述動詞和形容詞中手語製作的運動參數。我們探討（1）涉及自然終點的動詞（完成動詞；例如到達）和沒有終點的動詞（非完成動詞；例如分析）之間的製作差異，以及（2）加強與非加強（普通）形式的形容詞手語。使用線性混合效應模型（LME）的動作捕捉資料分析指出，動詞中的終點標記以及形容詞中的強化標記都由「OGS」中的動作調節表達。雖然動詞類型（完成/非完成）之間的語義區別由與非完成手語相比更高的峰值速度和更短的持續時間標記，但形容詞中的語法區別（強化）由與非強化形容詞相比更長的持續時間表達。手語者觀察到的個別差異可能被解釋為個人的手語風格。

##### **The Potential and Implications of Generative AI on HCI Education**
2405.05154v1 by Ahmed Kharrufa, Ian G Johnson

Generative AI (GAI) is impacting teaching and learning directly or indirectly
across a range of subjects and disciplines. As educators, we need to understand
the potential and limitations of AI in HCI education and ensure our graduating
HCI students are aware of the potential and limitations of AI in HCI. In this
paper, we report on the main pedagogical insights gained from the inclusion of
generative AI into a 10 week undergraduate module. We designed the module to
encourage student experimentation with GAI models as part of the design brief
requirement and planned practical sessions and discussions. Our insights are
based on replies to a survey sent out to the students after completing the
module. Our key findings, for HCI educators, report on the use of AI as a
persona for developing project ideas and creating resources for design, and AI
as a mirror for reflecting students' understanding of key concepts and ideas
and highlighting knowledge gaps. We also discuss potential pitfalls that should
be considered and the need to assess students' literacies and assumptions of
GAIs as pedagogical tools. Finally, we put forward the case for educators to
take the opportunities GAI presents as an educational tool and be experimental,
creative, and courageous in their practice. We end with a discussion of our
findings in relation to the TPACK framework in HCI.

摘要：生成式 AI (GAI) 直接或間接影響各個科目和學科的教學和學習。作為教育工作者，我們需要了解 AI 在 HCI 教育中的潛力和限制，並確保我們畢業的 HCI 學生了解 AI 在 HCI 中的潛力和限制。在本文中，我們報告了將生成式 AI 納入 10 週大學模組中獲得的主要教學見解。我們設計模組以鼓勵學生將 GAI 模型的實驗作為設計簡報要求的一部分，並規劃實務課程和討論。我們的見解基於在完成模組後寄給學生的調查回覆。我們對 HCI 教育工作者的主要發現報告了 AI 作為開發專案構想和建立設計資源的角色，以及 AI 作為反映學生對關鍵概念和想法的理解並突顯知識差距的鏡子。我們也討論應考慮的潛在陷阱，以及評量學生對 GAI 作為教學工具的識字能力和假設的必要性。最後，我們提出教育工作者應將 GAI 視為教育工具所帶來的機會，並在實務中保持實驗、創意和勇氣。我們以討論我們的發現與 HCI 中的 TPACK 架構的關係作為結尾。

##### **Hybrid Convolutional Neural Networks with Reliability Guarantee**
2405.05146v2 by Hans Dermot Doran, Suzana Veljanovska

Making AI safe and dependable requires the generation of dependable models
and dependable execution of those models. We propose redundant execution as a
well-known technique that can be used to ensure reliable execution of the AI
model. This generic technique will extend the application scope of
AI-accelerators that do not feature well-documented safety or dependability
properties. Typical redundancy techniques incur at least double or triple the
computational expense of the original. We adopt a co-design approach,
integrating reliable model execution with non-reliable execution, focusing that
additional computational expense only where it is strictly necessary. We
describe the design, implementation and some preliminary results of a hybrid
CNN.

摘要：要確保 AI 安全且可靠，需要產生可靠的模型以及可靠地執行這些模型。我們建議採用冗餘執行，這是一種眾所周知的技術，可用於確保 AI 模型的可靠執行。此通用技術將擴展沒有完善記錄的安全或可靠性屬性的 AI 加速器的應用範圍。典型的冗餘技術會產生至少兩倍或三倍於原始計算成本的計算開銷。我們採用共同設計方法，將可靠模型執行與非可靠執行整合在一起，僅將額外的計算開銷集中在絕對必要的地方。我們描述了混合 CNN 的設計、實作和一些初步結果。

##### **XAMPLER: Learning to Retrieve Cross-Lingual In-Context Examples**
2405.05116v1 by Peiqin Lin, André F. T. Martins, Hinrich Schütze

Recent studies have shown that leveraging off-the-shelf or fine-tuned
retrievers, capable of retrieving high-quality in-context examples,
significantly improves in-context learning of English. However, adapting these
methods to other languages, especially low-resource ones, presents challenges
due to the scarcity of available cross-lingual retrievers and annotated data.
In this paper, we introduce XAMPLER: Cross-Lingual Example Retrieval, a method
tailored to tackle the challenge of cross-lingual in-context learning using
only annotated English data. XAMPLER first trains a retriever with
positive/negative English samples, which are constructed based on the
predictions of the multilingual large language model for in-context learning.
Then, the trained retriever is directly employed to retrieve English examples
as few-shot examples for in-context learning of target languages. Experiments
on the massively multilingual text classification benchmark of SIB200 with 176
languages demonstrate that XAMPLER substantially improves the in-context
learning performance across languages. Our code is available at
https://github.com/cisnlp/XAMPLER.

摘要：最近的研究表明，利用現成的或微調過的檢索器，能夠檢索出高品質的語境範例，可以顯著改善英文的語境學習。然而，將這些方法調整到其他語言，尤其是低資源語言，會因為缺乏可用的跨語言檢索器和註解資料而產生挑戰。在本文中，我們介紹了 XAMPLER：跨語言範例檢索，一種方法專門用於解決跨語言語境學習的挑戰，僅使用註解過的英文資料。XAMPLER 首先使用正/負英文範例訓練檢索器，這些範例是根據多語言大型語言模型的預測，針對語境學習所建構的。然後，直接使用訓練好的檢索器來檢索英文範例，作為目標語言語境學習的少樣本範例。在包含 176 種語言的 SIB200 大規模多語言文字分類基準上進行的實驗證明，XAMPLER 大幅改善了跨語言的語境學習效能。我們的程式碼可在 https://github.com/cisnlp/XAMPLER 取得。

##### **QFMTS: Generating Query-Focused Summaries over Multi-Table Inputs**
2405.05109v1 by Weijia Zhang, Vaishali Pal, Jia-Hong Huang, Evangelos Kanoulas, Maarten de Rijke

Table summarization is a crucial task aimed at condensing information from
tabular data into concise and comprehensible textual summaries. However,
existing approaches often fall short of adequately meeting users' information
and quality requirements and tend to overlook the complexities of real-world
queries. In this paper, we propose a novel method to address these limitations
by introducing query-focused multi-table summarization. Our approach, which
comprises a table serialization module, a summarization controller, and a large
language model (LLM), utilizes textual queries and multiple tables to generate
query-dependent table summaries tailored to users' information needs. To
facilitate research in this area, we present a comprehensive dataset
specifically tailored for this task, consisting of 4909 query-summary pairs,
each associated with multiple tables. Through extensive experiments using our
curated dataset, we demonstrate the effectiveness of our proposed method
compared to baseline approaches. Our findings offer insights into the
challenges of complex table reasoning for precise summarization, contributing
to the advancement of research in query-focused multi-table summarization.

摘要：表格摘要是一項關鍵任務，旨在將來自表格資料的資訊濃縮成簡潔且易於理解的文字摘要。然而，現有的方法通常無法充分滿足使用者的資訊和品質需求，且傾向於忽略真實世界查詢的複雜性。在本文中，我們提出了一種新的方法來解決這些限制，方法是引入以查詢為中心的多分表摘要。我們的做法包含一個表格序列化模組、一個摘要控制器和一個大型語言模型 (LLM)，它利用文字查詢和多個表格來產生依據查詢而定的表格摘要，以滿足使用者的資訊需求。為了促進這方面的研究，我們提出了一個專門針對此任務的全面資料集，其中包含 4909 個查詢摘要對，每個都與多個表格相關聯。透過使用我們整理的資料集進行廣泛的實驗，我們證明了我們提出的方法與基線方法相比的有效性。我們的研究結果提供了對複雜表格推理在精確摘要方面的挑戰的見解，有助於推進以查詢為中心的多分表摘要的研究。

##### **Concerns on Bias in Large Language Models when Creating Synthetic Personae**
2405.05080v1 by Helena A. Haxvig

This position paper explores the benefits, drawbacks, and ethical
considerations of incorporating synthetic personae in HCI research,
particularly focusing on the customization challenges beyond the limitations of
current Large Language Models (LLMs). These perspectives are derived from the
initial results of a sub-study employing vignettes to showcase the existence of
bias within black-box LLMs and explore methods for manipulating them. The study
aims to establish a foundation for understanding the challenges associated with
these models, emphasizing the necessity of thorough testing before utilizing
them to create synthetic personae for HCI research.

摘要：此立場文件探討了在 HCI 研究中納入合成角色的優點、缺點和倫理考量，特別關注當前大型語言模型 (LLM) 的限制之外的客製化挑戰。這些觀點來自於一項子研究的初步結果，該研究採用小故事來說明黑箱 LLM 中存在的偏見，並探討操縱它們的方法。該研究旨在建立一個基礎，以了解與這些模型相關的挑戰，強調在利用它們為 HCI 研究創建合成角色之前徹底測試的必要性。

##### **Designing Skill-Compatible AI: Methodologies and Frameworks in Chess**
2405.05066v1 by Karim Hamade, Reid McIlroy-Young, Siddhartha Sen, Jon Kleinberg, Ashton Anderson

Powerful artificial intelligence systems are often used in settings where
they must interact with agents that are computationally much weaker, for
example when they work alongside humans or operate in complex environments
where some tasks are handled by algorithms, heuristics, or other entities of
varying computational power. For AI agents to successfully interact in these
settings, however, achieving superhuman performance alone is not sufficient;
they also need to account for suboptimal actions or idiosyncratic style from
their less-skilled counterparts. We propose a formal evaluation framework for
assessing the compatibility of near-optimal AI with interaction partners who
may have much lower levels of skill; we use popular collaborative chess
variants as model systems to study and develop AI agents that can successfully
interact with lower-skill entities. Traditional chess engines designed to
output near-optimal moves prove to be inadequate partners when paired with
engines of various lower skill levels in this domain, as they are not designed
to consider the presence of other agents. We contribute three methodologies to
explicitly create skill-compatible AI agents in complex decision-making
settings, and two chess game frameworks designed to foster collaboration
between powerful AI agents and less-skilled partners. On these frameworks, our
agents outperform state-of-the-art chess AI (based on AlphaZero) despite being
weaker in conventional chess, demonstrating that skill-compatibility is a
tangible trait that is qualitatively and measurably distinct from raw
performance. Our evaluations further explore and clarify the mechanisms by
which our agents achieve skill-compatibility.

摘要：強大的 AI 系統經常在必須與運算能力較弱的代理互動的環境中使用，例如當它們與人類並肩工作或在由演算法、啟發法或其他不同運算能力實體處理某些任務的複雜環境中運作時。然而，對於 AI 代理要在這些環境中成功互動，僅僅達到超人類的表現是不夠的；它們還需要考慮技能較差的對應方的次佳行動或獨特風格。我們提出一個正式的評估架構，用於評估近乎最佳 AI 與技能水平可能低得多的互動夥伴的相容性；我們使用流行的合作西洋棋變體作為模型系統來研究和開發能夠與技能較低的實體成功互動的 AI 代理。傳統的西洋棋引擎旨在輸出近乎最佳的移動，證明在與此領域中各種較低技能等級的引擎配對時，它們並非稱職的夥伴，因為它們並非設計用於考量其他代理的存在。我們貢獻了三種方法論，用於在複雜的決策制定環境中明確建立技能相容的 AI 代理，以及兩個旨在促進強大 AI 代理與技能較差的夥伴之間協作的西洋棋遊戲架構。在這些架構上，我們的代理表現優於最先進的西洋棋 AI（基於 AlphaZero），儘管在傳統西洋棋中較弱，這證明了技能相容性是一個具體的特質，在質量和可衡量性上都與原始表現不同。我們的評估進一步探討並釐清了我們的代理實現技能相容性的機制。

##### **Conversational Topic Recommendation in Counseling and Psychotherapy with Decision Transformer and Large Language Models**
2405.05060v1 by Aylin Gunal, Baihan Lin, Djallel Bouneffouf

Given the increasing demand for mental health assistance, artificial
intelligence (AI), particularly large language models (LLMs), may be valuable
for integration into automated clinical support systems. In this work, we
leverage a decision transformer architecture for topic recommendation in
counseling conversations between patients and mental health professionals. The
architecture is utilized for offline reinforcement learning, and we extract
states (dialogue turn embeddings), actions (conversation topics), and rewards
(scores measuring the alignment between patient and therapist) from previous
turns within a conversation to train a decision transformer model. We
demonstrate an improvement over baseline reinforcement learning methods, and
propose a novel system of utilizing our model's output as synthetic labels for
fine-tuning a large language model for the same task. Although our
implementation based on LLaMA-2 7B has mixed results, future work can
undoubtedly build on the design.

摘要：由於對心理健康協助的需求日益增加，人工智慧 (AI)，尤其是大型語言模型 (LLM)，可能對於整合到自動化臨床支援系統中非常有價值。在這項工作中，我們利用決策轉換器架構，針對患者與心理健康專業人員之間諮商對話中的主題推薦。此架構用於離線強化學習，我們從對話中的先前回合中提取狀態（對話回合嵌入）、動作（對話主題）和獎勵（衡量患者與治療師之間一致性的分數），以訓練決策轉換器模型。我們展示了對基準強化學習方法的改進，並提出了一個新穎的系統，利用我們模型的輸出作為合成標籤，以微調大型語言模型以執行相同的任務。儘管我們基於 LLaMA-2 7B 的實作有不同的結果，但未來的研究無疑可以建立在該設計上。

##### **Seeds of Stereotypes: A Large-Scale Textual Analysis of Race and Gender Associations with Diseases in Online Sources**
2405.05049v1 by Lasse Hyldig Hansen, Nikolaj Andersen, Jack Gallifant, Liam G. McCoy, James K Stone, Nura Izath, Marcela Aguirre-Jerez, Danielle S Bitterman, Judy Gichoya, Leo Anthony Celi

Background Advancements in Large Language Models (LLMs) hold transformative
potential in healthcare, however, recent work has raised concern about the
tendency of these models to produce outputs that display racial or gender
biases. Although training data is a likely source of such biases, exploration
of disease and demographic associations in text data at scale has been limited.
  Methods We conducted a large-scale textual analysis using a dataset
comprising diverse web sources, including Arxiv, Wikipedia, and Common Crawl.
The study analyzed the context in which various diseases are discussed
alongside markers of race and gender. Given that LLMs are pre-trained on
similar datasets, this approach allowed us to examine the potential biases that
LLMs may learn and internalize. We compared these findings with actual
demographic disease prevalence as well as GPT-4 outputs in order to evaluate
the extent of bias representation.
  Results Our findings indicate that demographic terms are disproportionately
associated with specific disease concepts in online texts. gender terms are
prominently associated with disease concepts, while racial terms are much less
frequently associated. We find widespread disparities in the associations of
specific racial and gender terms with the 18 diseases analyzed. Most
prominently, we see an overall significant overrepresentation of Black race
mentions in comparison to population proportions.
  Conclusions Our results highlight the need for critical examination and
transparent reporting of biases in LLM pretraining datasets. Our study suggests
the need to develop mitigation strategies to counteract the influence of biased
training data in LLMs, particularly in sensitive domains such as healthcare.

摘要：<paragraph>背景 大型语言模型 (LLM) 的进步在医疗保健领域具有变革性的潜力，然而，最近的研究引起了人们对这些模型产生显示种族或性别偏见的输出的趋势的担忧。虽然训练数据可能是此类偏见的一个可能来源，但对文本数据中疾病和人口统计关联的大规模探索一直受到限制。
方法 我们使用了一个包含各种网络来源（包括 Arxiv、维基百科和 Common Crawl）的数据集进行了大规模文本分析。该研究分析了在讨论各种疾病时种族和性别标记的语境。鉴于 LLM 是在类似的数据集上进行预训练的，这种方法使我们能够检查 LLM 可能学习和内化的潜在偏见。我们将这些发现与实际的人口疾病患病率以及 GPT-4 输出进行了比较，以评估偏见表征的程度。
结果 我们的研究结果表明，人口统计术语与在线文本中的特定疾病概念不成比例地相关。性别术语与疾病概念密切相关，而种族术语的关联频率要低得多。我们发现特定种族和性别术语与所分析的 18 种疾病的关联存在广泛差异。最突出的是，我们看到与人口比例相比，黑人种族的提及总体上明显过高。
结论 我们的研究结果强调了对 LLM 预训练数据集中的偏见进行批判性检查和透明报告的必要性。我们的研究表明需要制定缓解策略来抵消有偏训练数据对 LLM 的影响，特别是在医疗保健等敏感领域。</paragraph>

##### **StyleMamba : State Space Model for Efficient Text-driven Image Style Transfer**
2405.05027v1 by Zijia Wang, Zhi-Song Liu

We present StyleMamba, an efficient image style transfer framework that
translates text prompts into corresponding visual styles while preserving the
content integrity of the original images. Existing text-guided stylization
requires hundreds of training iterations and takes a lot of computing
resources. To speed up the process, we propose a conditional State Space Model
for Efficient Text-driven Image Style Transfer, dubbed StyleMamba, that
sequentially aligns the image features to the target text prompts. To enhance
the local and global style consistency between text and image, we propose
masked and second-order directional losses to optimize the stylization
direction to significantly reduce the training iterations by 5 times and the
inference time by 3 times. Extensive experiments and qualitative evaluation
confirm the robust and superior stylization performance of our methods compared
to the existing baselines.

摘要：我們提出 StyleMamba，一個有效率的影像風格轉移架構，它能將文字提示轉換成對應的視覺風格，同時保留原始影像的內容完整性。現有的文字引導風格化需要數百次的訓練反覆運算，並耗費大量的運算資源。為了加速這個過程，我們提出了一個條件式狀態空間模型，用於有效率的文字驅動影像風格轉移，稱為 StyleMamba，它會將影像特徵依序對齊到目標文字提示。為了加強文字和影像之間的局部和整體風格一致性，我們提出遮罩和二階方向損失，以最佳化風格化方向，大幅減少 5 倍的訓練反覆運算和 3 倍的推論時間。廣泛的實驗和定性評估證實了我們的方法與現有的基準相比，具有強健且優異的風格化表現。

##### **ADELIE: Aligning Large Language Models on Information Extraction**
2405.05008v1 by Yunjia Qi, Hao Peng, Xiaozhi Wang, Bin Xu, Lei Hou, Juanzi Li

Large language models (LLMs) usually fall short on information extraction
(IE) tasks and struggle to follow the complex instructions of IE tasks. This
primarily arises from LLMs not being aligned with humans, as mainstream
alignment datasets typically do not include IE data. In this paper, we
introduce ADELIE (Aligning large language moDELs on Information Extraction), an
aligned LLM that effectively solves various IE tasks, including closed IE, open
IE, and on-demand IE. We first collect and construct a high-quality alignment
corpus IEInstruct for IE. Then we train ADELIE_SFT using instruction tuning on
IEInstruct. We further train ADELIE_SFT with direct preference optimization
(DPO) objective, resulting in ADELIE_DPO. Extensive experiments on various
held-out IE datasets demonstrate that our models (ADELIE_SFT and ADELIE_DPO)
achieve state-of-the-art (SoTA) performance among open-source models. We
further explore the general capabilities of ADELIE, and experimental results
reveal that their general capabilities do not exhibit a noticeable decline. We
will release the code, data, and models to facilitate further research.

摘要：大型語言模型 (LLM) 通常在資訊抽取 (IE) 任務中表現不佳，且難以遵循 IE 任務的複雜指示。這主要是因為 LLM 與人類不一致，因為主流對齊資料集通常不包含 IE 資料。在本文中，我們介紹 ADELIE（對齊大型語言模型以進行資訊抽取），這是一種對齊的 LLM，可有效解決各種 IE 任務，包括封閉式 IE、開放式 IE 和依需求 IE。我們首先收集並建立一個高品質的對齊語料庫 IEInstruct，以進行 IE。然後我們使用 IEInstruct 上的指示微調來訓練 ADELIE_SFT。我們進一步使用直接偏好最佳化 (DPO) 目標來訓練 ADELIE_SFT，產生 ADELIE_DPO。在各種保留 IE 資料集上進行的廣泛實驗表明，我們的模型（ADELIE_SFT 和 ADELIE_DPO）在開源模型中取得了最先進 (SoTA) 的效能。我們進一步探索 ADELIE 的一般能力，實驗結果顯示其一般能力並未出現顯著下降。我們將釋出程式碼、資料和模型，以利進一步研究。

##### **Health Index Estimation Through Integration of General Knowledge with Unsupervised Learning**
2405.04990v1 by Kristupas Bajarunas, Marcia L. Baptista, Kai Goebel, Manuel A. Chao

Accurately estimating a Health Index (HI) from condition monitoring data (CM)
is essential for reliable and interpretable prognostics and health management
(PHM) in complex systems. In most scenarios, complex systems operate under
varying operating conditions and can exhibit different fault modes, making
unsupervised inference of an HI from CM data a significant challenge. Hybrid
models combining prior knowledge about degradation with deep learning models
have been proposed to overcome this challenge. However, previously suggested
hybrid models for HI estimation usually rely heavily on system-specific
information, limiting their transferability to other systems. In this work, we
propose an unsupervised hybrid method for HI estimation that integrates general
knowledge about degradation into the convolutional autoencoder's model
architecture and learning algorithm, enhancing its applicability across various
systems. The effectiveness of the proposed method is demonstrated in two case
studies from different domains: turbofan engines and lithium batteries. The
results show that the proposed method outperforms other competitive
alternatives, including residual-based methods, in terms of HI quality and
their utility for Remaining Useful Life (RUL) predictions. The case studies
also highlight the comparable performance of our proposed method with a
supervised model trained with HI labels.

摘要：從狀態監控資料 (CM) 精確估計健康指數 (HI) 對於複雜系統中的可靠且可解讀的預後和健康管理 (PHM) 至關重要。在大多數情況下，複雜系統在不同的操作條件下運行，並且可能會表現出不同的故障模式，這使得從 CM 資料中進行無監督的 HI 推論成為一項重大挑戰。已經提出結合關於退化的先驗知識與深度學習模型的混合模型來克服這一挑戰。然而，先前建議用於 HI 估計的混合模型通常嚴重依賴系統特定資訊，這限制了它們對其他系統的可傳輸性。在這項工作中，我們提出了一種用於 HI 估計的無監督混合方法，該方法將關於退化的通用知識整合到卷積自動編碼器的模型架構和學習演算法中，增強了其在各種系統中的適用性。所提出的方法的有效性在來自不同領域的兩個案例研究中得到證明：渦扇發動機和鋰電池。結果表明，所提出的方法在 HI 品質和對剩餘使用壽命 (RUL) 預測的效用方面優於其他競爭性替代方案，包括基於殘差的方法。案例研究還強調了我們提出的方法與使用 HI 標籤訓練的監督模型相當的性能。

##### **Discrepancy-based Diffusion Models for Lesion Detection in Brain MRI**
2405.04974v1 by Keqiang Fan, Xiaohao Cai, Mahesan Niranjan

Diffusion probabilistic models (DPMs) have exhibited significant
effectiveness in computer vision tasks, particularly in image generation.
However, their notable performance heavily relies on labelled datasets, which
limits their application in medical images due to the associated high-cost
annotations. Current DPM-related methods for lesion detection in medical
imaging, which can be categorized into two distinct approaches, primarily rely
on image-level annotations. The first approach, based on anomaly detection,
involves learning reference healthy brain representations and identifying
anomalies based on the difference in inference results. In contrast, the second
approach, resembling a segmentation task, employs only the original brain
multi-modalities as prior information for generating pixel-level annotations.
In this paper, our proposed model - discrepancy distribution medical diffusion
(DDMD) - for lesion detection in brain MRI introduces a novel framework by
incorporating distinctive discrepancy features, deviating from the conventional
direct reliance on image-level annotations or the original brain modalities. In
our method, the inconsistency in image-level annotations is translated into
distribution discrepancies among heterogeneous samples while preserving
information within homogeneous samples. This property retains pixel-wise
uncertainty and facilitates an implicit ensemble of segmentation, ultimately
enhancing the overall detection performance. Thorough experiments conducted on
the BRATS2020 benchmark dataset containing multimodal MRI scans for brain
tumour detection demonstrate the great performance of our approach in
comparison to state-of-the-art methods.

摘要：擴散機率模型 (DPM) 在電腦視覺任務中展現出顯著的效能，特別是在影像生成方面。然而，它們顯著的效能高度仰賴標籤資料集，這會因為相關的高成本註解而限制它們在醫學影像中的應用。目前用於醫學影像病灶偵測的 DPM 相關方法可分為兩種不同的方法，主要仰賴影像層級的註解。第一種方法是基於異常偵測，涉及學習參考健康腦部表徵，並根據推論結果的差異來識別異常。相反地，第二種方法類似於分割任務，僅使用原始腦部多模態作為產生畫素層級註解的先驗資訊。在本文中，我們提出的模型——差異分佈醫學擴散 (DDMD)——用於腦部 MRI 中的病灶偵測，它透過納入獨特的差異特徵來引入一個新穎的架構，偏離對影像層級註解或原始腦部模態的傳統直接依賴。在我們的這種方法中，影像層級註解中的不一致性被轉換為異質樣本之間的分布差異，同時保留同質樣本內的資訊。此特性保留了逐畫素的不確定性，並促進分割的隱含集合，最終提升整體偵測效能。在 BRATS2020 基準資料集上進行的徹底實驗包含用於腦腫瘤偵測的多模態 MRI 掃描，證明了我們的方法與最先進的方法相比具有優異的效能。

##### **A review on discriminative self-supervised learning methods**
2405.04969v1 by Nikolaos Giakoumoglou, Tania Stathaki

In the field of computer vision, self-supervised learning has emerged as a
method to extract robust features from unlabeled data, where models derive
labels autonomously from the data itself, without the need for manual
annotation. This paper provides a comprehensive review of discriminative
approaches of self-supervised learning within the domain of computer vision,
examining their evolution and current status. Through an exploration of various
methods including contrastive, self-distillation, knowledge distillation,
feature decorrelation, and clustering techniques, we investigate how these
approaches leverage the abundance of unlabeled data. Finally, we have
comparison of self-supervised learning methods on the standard ImageNet
classification benchmark.

摘要：在電腦視覺領域中，自我監督學習已經成為從未標籤資料中提取穩健特徵的一種方法，其中模型從資料本身自動推導標籤，而無需手動註解。本文全面回顧了電腦視覺領域內自我監督學習的判別方法，探討了它們的演變和現狀。透過探索各種方法，包括對比、自我蒸餾、知識蒸餾、特徵去相關和聚類技術，我們探討了這些方法如何利用豐富的未標籤資料。最後，我們比較了標準 ImageNet 分類基準上的自我監督學習方法。

##### **P-ICL: Point In-Context Learning for Named Entity Recognition with Large Language Models**
2405.04960v1 by Guochao Jiang, Zepeng Ding, Yuchen Shi, Deqing Yang

In recent years, the rise of large language models (LLMs) has made it
possible to directly achieve named entity recognition (NER) without any
demonstration samples or only using a few samples through in-context learning
(ICL). However, standard ICL only helps LLMs understand task instructions,
format and input-label mapping, but neglects the particularity of the NER task
itself. In this paper, we propose a new prompting framework P-ICL to better
achieve NER with LLMs, in which some point entities are leveraged as the
auxiliary information to recognize each entity type. With such significant
information, the LLM can achieve entity classification more precisely. To
obtain optimal point entities for prompting LLMs, we also proposed a point
entity selection method based on K-Means clustering. Our extensive experiments
on some representative NER benchmarks verify the effectiveness of our proposed
strategies in P-ICL and point entity selection.

摘要：近年來，大型語言模型 (LLM) 的興起使得在沒有任何示範範例或僅透過情境學習 (ICL) 使用少數範例的情況下，就能直接達成命名實體辨識 (NER)。然而，標準的 ICL 只協助 LLM 理解任務指示、格式和輸入標籤對應，但忽略了 NER 任務本身的特殊性。在本文中，我們提出一個新的提示架構 P-ICL，以便使用 LLM 更佳地達成 NER，其中一些點實體被用作輔助資訊來辨識每個實體類型。有了這些重要的資訊，LLM 可以更精確地達成實體分類。為了取得用於提示 LLM 的最佳點實體，我們也提出一個基於 K-Means 聚類的點實體選取方法。我們在一些具代表性的 NER 基準上進行的廣泛實驗驗證了我們在 P-ICL 和點實體選取中提出的策略的有效性。

##### **Improving Long Text Understanding with Knowledge Distilled from Summarization Model**
2405.04955v1 by Yan Liu, Yazheng Yang, Xiaokang Chen

Long text understanding is important yet challenging for natural language
processing. A long article or document usually contains many redundant words
that are not pertinent to its gist and sometimes can be regarded as noise. With
recent advances of abstractive summarization, we propose our \emph{Gist
Detector} to leverage the gist detection ability of a summarization model and
integrate the extracted gist into downstream models to enhance their long text
understanding ability. Specifically, Gist Detector first learns the gist
detection knowledge distilled from a summarization model, and then produces
gist-aware representations to augment downstream models. We evaluate our method
on three different tasks: long document classification, distantly supervised
open-domain question answering, and non-parallel text style transfer. The
experimental results show that our method can significantly improve the
performance of baseline models on all tasks.

摘要：長文本理解對自然語言處理來說很重要，但也具有挑戰性。長篇論文或文件通常包含許多與其要旨無關的冗餘字詞，有時可以被視為雜訊。隨著摘要摘要的最新進展，我們提出我們的「要點偵測器」，以利用摘要模型的要點偵測能力，並將提取出的要點整合到下游模型中，以增強其長文本理解能力。具體來說，要點偵測器首先學習從摘要模型中提煉出的要點偵測知識，然後產生要點感知表示，以擴充下游模型。我們對我們的模型進行了三項不同的任務評估：長文分類、遠程監督的開放領域問答和非平行文本風格轉換。實驗結果表明，我們的模型可以在所有任務上顯著提高基線模型的效能。

##### **VisionGraph: Leveraging Large Multimodal Models for Graph Theory Problems in Visual Context**
2405.04950v1 by Yunxin Li, Baotian Hu, Haoyuan Shi, Wei Wang, Longyue Wang, Min Zhang

Large Multimodal Models (LMMs) have achieved impressive success in visual
understanding and reasoning, remarkably improving the performance of
mathematical reasoning in a visual context. Yet, a challenging type of visual
math lies in the multimodal graph theory problem, which demands that LMMs
understand the graphical structures accurately and perform multi-step reasoning
on the visual graph. Additionally, exploring multimodal graph theory problems
will lead to more effective strategies in fields like biology, transportation,
and robotics planning. To step forward in this direction, we are the first to
design a benchmark named VisionGraph, used to explore the capabilities of
advanced LMMs in solving multimodal graph theory problems. It encompasses eight
complex graph problem tasks, from connectivity to shortest path problems.
Subsequently, we present a Description-Program-Reasoning (DPR) chain to enhance
the logical accuracy of reasoning processes through graphical structure
description generation and algorithm-aware multi-step reasoning. Our extensive
study shows that 1) GPT-4V outperforms Gemini Pro in multi-step graph
reasoning; 2) All LMMs exhibit inferior perception accuracy for graphical
structures, whether in zero/few-shot settings or with supervised fine-tuning
(SFT), which further affects problem-solving performance; 3) DPR significantly
improves the multi-step graph reasoning capabilities of LMMs and the GPT-4V
(DPR) agent achieves SOTA performance.

摘要：大型多模态模型 (LMM) 在视觉理解和推理方面取得了令人瞩目的成功，显著提高了视觉环境中数学推理的性能。然而，一种具有挑战性的视觉数学存在于多模态图论问题中，它要求 LMM 准确理解图形结构并在视觉图上执行多步推理。此外，探索多模态图论问题将为生物学、交通运输和机器人规划等领域带来更有效的策略。为了朝这个方向迈进，我们率先设计了一个名为 VisionGraph 的基准，用于探索先进 LMM 在解决多模态图论问题中的能力。它包含八个复杂的图问题任务，从连通性到最短路径问题。随后，我们提出了一个描述-程序-推理 (DPR) 链，通过图形结构描述生成和算法感知的多步推理来增强推理过程的逻辑准确性。我们的广泛研究表明：1) GPT-4V 在多步图推理中优于 Gemini Pro；2) 所有 LMM 在图形结构的感知准确性方面表现较差，无论是在零/少样本设置中还是在有监督微调 (SFT) 的情况下，这进一步影响了问题求解性能；3) DPR 显着提高了 LMM 的多步图推理能力，并且 GPT-4V (DPR) 代理实现了 SOTA 性能。

##### **Imprecise Probabilities Meet Partial Observability: Game Semantics for Robust POMDPs**
2405.04941v1 by Eline M. Bovy, Marnix Suilen, Sebastian Junges, Nils Jansen

Partially observable Markov decision processes (POMDPs) rely on the key
assumption that probability distributions are precisely known. Robust POMDPs
(RPOMDPs) alleviate this concern by defining imprecise probabilities, referred
to as uncertainty sets. While robust MDPs have been studied extensively, work
on RPOMDPs is limited and primarily focuses on algorithmic solution methods. We
expand the theoretical understanding of RPOMDPs by showing that 1) different
assumptions on the uncertainty sets affect optimal policies and values; 2)
RPOMDPs have a partially observable stochastic game (POSG) semantic; and 3) the
same RPOMDP with different assumptions leads to semantically different POSGs
and, thus, different policies and values. These novel semantics for RPOMDPS
give access to results for the widely studied POSG model; concretely, we show
the existence of a Nash equilibrium. Finally, we classify the existing RPOMDP
literature using our semantics, clarifying under which uncertainty assumptions
these existing works operate.

摘要：部分可觀測馬可夫決策過程 (POMDP) 依賴於一個關鍵假設，即機率分佈是精確已知的。強健 POMDP (RPOMDP) 透過定義不精確的機率（稱為不確定性集合）來減輕這個問題。儘管強健 MDP 已被廣泛研究，但對 RPOMDP 的研究卻很有限，且主要集中於演算法解決方法。我們透過顯示以下內容來擴展對 RPOMDP 的理論理解：1) 不確定性集合的不同假設會影響最佳策略和價值；2) RPOMDP 具有部分可觀測隨機遊戲 (POSG) 語義；以及 3) 具有不同假設的相同 RPOMDP 會導致語義上不同的 POSG，因此會產生不同的策略和價值。這些 RPOMDP 的新語義可以取得廣泛研究的 POSG 模型的結果；具體來說，我們證明了納許均衡的存在性。最後，我們使用我們的語義對現有的 RPOMDP 文獻進行分類，釐清這些現有著作是在哪些不確定性假設下運作的。

##### **Developing trustworthy AI applications with foundation models**
2405.04937v1 by Michael Mock, Sebastian Schmidt, Felix Müller, Rebekka Görge, Anna Schmitz, Elena Haedecke, Angelika Voss, Dirk Hecker, Maximillian Poretschkin

The trustworthiness of AI applications has been the subject of recent
research and is also addressed in the EU's recently adopted AI Regulation. The
currently emerging foundation models in the field of text, speech and image
processing offer completely new possibilities for developing AI applications.
This whitepaper shows how the trustworthiness of an AI application developed
with foundation models can be evaluated and ensured. For this purpose, the
application-specific, risk-based approach for testing and ensuring the
trustworthiness of AI applications, as developed in the 'AI Assessment Catalog
- Guideline for Trustworthy Artificial Intelligence' by Fraunhofer IAIS, is
transferred to the context of foundation models. Special consideration is given
to the fact that specific risks of foundation models can have an impact on the
AI application and must also be taken into account when checking
trustworthiness. Chapter 1 of the white paper explains the fundamental
relationship between foundation models and AI applications based on them in
terms of trustworthiness. Chapter 2 provides an introduction to the technical
construction of foundation models and Chapter 3 shows how AI applications can
be developed based on them. Chapter 4 provides an overview of the resulting
risks regarding trustworthiness. Chapter 5 shows which requirements for AI
applications and foundation models are to be expected according to the draft of
the European Union's AI Regulation and Chapter 6 finally shows the system and
procedure for meeting trustworthiness requirements.

摘要：人工智能應用程式的可信賴性一直是近期研究的主題，並在歐盟最近通過的人工智慧法規中有所闡述。目前在文字、語音和影像處理領域中新興的基礎模型為開發人工智能應用程式提供了全新的可能性。本白皮書說明了如何評估和確保使用基礎模型開發的人工智慧應用程式的可信賴性。為此，將 Fraunhofer IAIS 在「AI 評估目錄 - 可信賴人工智慧指南」中開發的特定於應用程式的、基於風險的測試和確保人工智慧應用程式可信賴性的方法轉移到基礎模型的背景中。特別考慮到基礎模型的特定風險可能會對人工智慧應用程式產生影響，在檢查可信賴性時也必須將其納入考量。白皮書的第 1 章說明了基礎模型與基於它們的人工智慧應用程式之間在可信賴性方面的基本關係。第 2 章介紹了基礎模型的技術結構，第 3 章說明了如何基於它們開發人工智慧應用程式。第 4 章提供了關於可信賴性的風險概觀。第 5 章說明了根據歐盟人工智慧法規草案，對人工智慧應用程式和基礎模型的預期要求，最後第 6 章說明了滿足可信賴性要求的系統和程序。

##### **Delve into Base-Novel Confusion: Redundancy Exploration for Few-Shot Class-Incremental Learning**
2405.04918v1 by Haichen Zhou, Yixiong Zou, Ruixuan Li, Yuhua Li, Kui Xiao

Few-shot class-incremental learning (FSCIL) aims to acquire knowledge from
novel classes with limited samples while retaining information about base
classes. Existing methods address catastrophic forgetting and overfitting by
freezing the feature extractor during novel-class learning. However, these
methods usually tend to cause the confusion between base and novel classes,
i.e., classifying novel-class samples into base classes. In this paper, we
delve into this phenomenon to study its cause and solution. We first interpret
the confusion as the collision between the novel-class and the base-class
region in the feature space. Then, we find the collision is caused by the
label-irrelevant redundancies within the base-class feature and pixel space.
Through qualitative and quantitative experiments, we identify this redundancy
as the shortcut in the base-class training, which can be decoupled to alleviate
the collision. Based on this analysis, to alleviate the collision between base
and novel classes, we propose a method for FSCIL named Redundancy Decoupling
and Integration (RDI). RDI first decouples redundancies from base-class space
to shrink the intra-base-class feature space. Then, it integrates the
redundancies as a dummy class to enlarge the inter-base-class feature space.
This process effectively compresses the base-class feature space, creating
buffer space for novel classes and alleviating the model's confusion between
the base and novel classes. Extensive experiments across benchmark datasets,
including CIFAR-100, miniImageNet, and CUB-200-2011 demonstrate that our method
achieves state-of-the-art performance.

摘要：<paragraph>少樣本類別增量學習 (FSCIL) 旨在從具有有限範例的新類別中獲取知識，同時保留有關基礎類別的資訊。現有方法透過在學習新類別時凍結特徵萃取器來解決災難性遺忘和過度擬合。然而，這些方法通常會導致基礎類別和新類別之間的混淆，即，將新類別範例分類到基礎類別中。在本文中，我們深入探討此現象以研究其成因和解決方案。我們首先將混淆解釋為特徵空間中新類別和基礎類別區域之間的碰撞。然後，我們發現碰撞是由基礎類別特徵和像素空間中的與標籤無關的冗餘造成的。透過定性和定量實驗，我們將此冗餘識別為基礎類別訓練中的捷徑，可以將其解耦以減輕碰撞。基於此分析，為了減輕基礎類別和新類別之間的碰撞，我們提出了一種名為冗餘解耦與整合 (RDI) 的 FSCIL 方法。RDI 首先從基礎類別空間中解耦冗餘，以縮小基礎類別內部特徵空間。然後，它將冗餘整合為一個虛擬類別，以擴大基礎類別之間的特徵空間。此程序有效壓縮了基礎類別特徵空間，為新類別創造了緩衝空間，並減輕了模型對基礎類別和新類別之間的混淆。在包括 CIFAR-100、miniImageNet 和 CUB-200-2011 在內的基準資料集上進行的廣泛實驗證明，我們的模型達到了最先進的效能。</paragraph>

##### **Traj-LLM: A New Exploration for Empowering Trajectory Prediction with Pre-trained Large Language Models**
2405.04909v1 by Zhengxing Lan, Hongbo Li, Lingshan Liu, Bo Fan, Yisheng Lv, Yilong Ren, Zhiyong Cui

Predicting the future trajectories of dynamic traffic actors is a cornerstone
task in autonomous driving. Though existing notable efforts have resulted in
impressive performance improvements, a gap persists in scene cognitive and
understanding of the complex traffic semantics. This paper proposes Traj-LLM,
the first to investigate the potential of using Large Language Models (LLMs)
without explicit prompt engineering to generate future motion from agents'
past/observed trajectories and scene semantics. Traj-LLM starts with sparse
context joint coding to dissect the agent and scene features into a form that
LLMs understand. On this basis, we innovatively explore LLMs' powerful
comprehension abilities to capture a spectrum of high-level scene knowledge and
interactive information. Emulating the human-like lane focus cognitive function
and enhancing Traj-LLM's scene comprehension, we introduce lane-aware
probabilistic learning powered by the pioneering Mamba module. Finally, a
multi-modal Laplace decoder is designed to achieve scene-compliant multi-modal
predictions. Extensive experiments manifest that Traj-LLM, fortified by LLMs'
strong prior knowledge and understanding prowess, together with lane-aware
probability learning, outstrips state-of-the-art methods across evaluation
metrics. Moreover, the few-shot analysis further substantiates Traj-LLM's
performance, wherein with just 50% of the dataset, it outperforms the majority
of benchmarks relying on complete data utilization. This study explores
equipping the trajectory prediction task with advanced capabilities inherent in
LLMs, furnishing a more universal and adaptable solution for forecasting agent
motion in a new way.

摘要：預測動態交通參與者的未來軌跡是自動駕駛的一項基石任務。儘管現有的顯著努力已帶來令人印象深刻的效能提升，但場景認知和對複雜交通語意的理解仍存在差距。本文提出了 Traj-LLM，這是第一個探討使用大型語言模型 (LLM) 的潛力，而無需明確提示工程即可從代理人的過去/觀察到的軌跡和場景語義中產生未來的運動。Traj-LLM 從稀疏上下文聯合編碼開始，將代理和場景特徵剖析成 LLM 能理解的形式。在此基礎上，我們創新地探索 LLM 強大的理解能力，以擷取一系列高級場景知識和互動資訊。模擬類似人類的車道焦點認知功能並增強 Traj-LLM 的場景理解，我們引入了由先驅 Mamba 模組驅動的車道感知機率學習。最後，設計了一個多模態拉普拉斯解碼器，以實現符合場景的多模態預測。廣泛的實驗表明，Traj-LLM 透過 LLM 強大的先驗知識和理解能力，再加上車道感知機率學習，在各項評估指標中都超越了最先進的方法。此外，少次學習分析進一步證實了 Traj-LLM 的效能，其中僅使用 50% 的資料集，就優於依賴完整資料利用的大多數基準。本研究探討了為軌跡預測任務配備 LLM 固有的先進能力，為以新方式預測代理運動提供了更通用且適應性更強的解決方案。

##### **Machine Learning-based NLP for Emotion Classification on a Cholera X Dataset**
2405.04897v1 by Paul Jideani, Aurona Gerber

Recent social media posts on the cholera outbreak in Hammanskraal have
highlighted the diverse range of emotions people experienced in response to
such an event. The extent of people's opinions varies greatly depending on
their level of knowledge and information about the disease. The documented
re-search about Cholera lacks investigations into the classification of
emotions. This study aims to examine the emotions expressed in social media
posts about Chol-era. A dataset of 23,000 posts was extracted and
pre-processed. The Python Nat-ural Language Toolkit (NLTK) sentiment analyzer
library was applied to deter-mine the emotional significance of each text.
Additionally, Machine Learning (ML) models were applied for emotion
classification, including Long short-term memory (LSTM), Logistic regression,
Decision trees, and the Bidirectional En-coder Representations from
Transformers (BERT) model. The results of this study demonstrated that LSTM
achieved the highest accuracy of 75%. Emotion classification presents a
promising tool for gaining a deeper understanding of the impact of Cholera on
society. The findings of this study might contribute to the development of
effective interventions in public health strategies.

摘要：最近社群媒體上關於 Hammanskraal 霍亂爆發的貼文突顯了人們對此類事件的反應中所經歷的各種情緒。人們意見的廣泛程度取決於他們對此疾病的知識和資訊的程度。有記錄的霍亂研究缺乏對情緒分類的調查。本研究旨在探討社群媒體貼文中表達的關於霍亂的情緒。從 23,000 篇貼文中萃取並預處理了一個資料集。應用 Python 自然語言工具包 (NLTK) 情緒分析程式庫來決定每段文字的情緒重要性。此外，應用機器學習 (ML) 模型來進行情緒分類，包括長短期記憶 (LSTM)、邏輯迴歸、決策樹，以及轉換器 (BERT) 模型中的雙向編碼器表徵。本研究的結果顯示 LSTM 達到了 75% 的最高準確度。情緒分類提供了一個有用的工具，可以更深入地了解霍亂對社會的影響。本研究的發現可能有助於制定公共衛生策略中的有效干預措施。

##### **Molecule-Space: Free Lunch in Unified Multimodal Space via Knowledge Fusion**
2405.04883v1 by Zehan Wang, Ziang Zhang, Xize Cheng, Rongjie Huang, Luping Liu, Zhenhui Ye, Haifeng Huang, Yang Zhao, Tao Jin, Peng Gao, Zhou Zhao

Unified multi-model representation spaces are the foundation of multimodal
understanding and generation. However, the billions of model parameters and
catastrophic forgetting problems make it challenging to further enhance
pre-trained unified spaces. In this work, we propose Molecule-Space, an idea
that treats multimodal representation spaces as "molecules", and augments
pre-trained unified space by integrating knowledge from extra expert spaces via
"molecules space reactions". Specifically, we introduce two kinds of basic
space reactions: 1) Space Displacement Reaction and 2) Space Combination
Reaction. Based on these defined basic reactions, we design Complex Sequential
& Parallel Reactions to effectively integrate multiple spaces simultaneously.
Benefiting from the modularization concept, we further propose a coarse-to-fine
customized inference strategy to flexibly adjust the enhanced unified space for
different purposes. Experimentally, we fuse the audio-image-text space of
ImageBind with the image-text and audio-text expert spaces. The resulting space
outperforms ImageBind on 5 downstream tasks across 9 datasets. Moreover, via
customized inference, it even surpasses the used image-text and audio-text
expert spaces.

摘要：統一的多模式表示空間是多模式理解和生成的基礎。然而，數十億個模型參數和災難性遺忘問題使得進一步增強預訓練統一空間變得具有挑戰性。在這項工作中，我們提出了 Molecule-Space，這是一個將多模式表示空間視為「分子」的思想，並通過「分子空間反應」整合來自額外專家空間的知識來擴充預訓練統一空間。具體來說，我們引入了兩種基本的空間反應：1）空間置換反應和 2）空間組合反應。根據這些定義的基本反應，我們設計了複雜的順序和並行反應，以有效地同時整合多個空間。受益於模塊化概念，我們進一步提出了粗到細的客製化推論策略，以靈活調整增強的統一空間以適應不同的目的。在實驗中，我們將 ImageBind 的音訊-影像-文字空間與影像-文字和音訊-文字專家空間融合。生成的空間在 9 個資料集上的 5 個下游任務中優於 ImageBind。此外，通過客製化推論，它甚至超越了所使用的影像-文字和音訊-文字專家空間。

##### **The Codecfake Dataset and Countermeasures for the Universally Detection of Deepfake Audio**
2405.04880v1 by Yuankun Xie, Yi Lu, Ruibo Fu, Zhengqi Wen, Zhiyong Wang, Jianhua Tao, Xin Qi, Xiaopeng Wang, Yukun Liu, Haonan Cheng, Long Ye, Yi Sun

With the proliferation of Audio Language Model (ALM) based deepfake audio,
there is an urgent need for effective detection methods. Unlike traditional
deepfake audio generation, which often involves multi-step processes
culminating in vocoder usage, ALM directly utilizes neural codec methods to
decode discrete codes into audio. Moreover, driven by large-scale data, ALMs
exhibit remarkable robustness and versatility, posing a significant challenge
to current audio deepfake detection (ADD) models. To effectively detect
ALM-based deepfake audio, we focus on the mechanism of the ALM-based audio
generation method, the conversion from neural codec to waveform. We initially
construct the Codecfake dataset, an open-source large-scale dataset, including
two languages, millions of audio samples, and various test conditions, tailored
for ALM-based audio detection. Additionally, to achieve universal detection of
deepfake audio and tackle domain ascent bias issue of original SAM, we propose
the CSAM strategy to learn a domain balanced and generalized minima. Experiment
results demonstrate that co-training on Codecfake dataset and vocoded dataset
with CSAM strategy yield the lowest average Equal Error Rate (EER) of 0.616%
across all test conditions compared to baseline models.

摘要：隨著基於音訊語言模型 (ALM) 的深度偽造音訊的激增，急需有效的偵測方法。與傳統的深度偽造音訊生成不同，後者通常涉及多步驟流程，最終使用語音編碼器，而 ALM 直接利用神經編解碼器方法將離散代碼解碼為音訊。此外，在大量資料的驅動下，ALM 展現出顯著的穩健性和多功能性，對目前的音訊深度偽造偵測 (ADD) 模型構成重大挑戰。為了有效偵測基於 ALM 的深度偽造音訊，我們專注於基於 ALM 的音訊生成方法的機制，即從神經編解碼器轉換為波形。我們最初建構 Codecfake 資料集，一個開放原始碼的大規模資料集，包括兩種語言、數百萬個音訊範例和各種測試條件，專門用於基於 ALM 的音訊偵測。此外，為了實現深度偽造音訊的通用偵測並解決原始 SAM 的領域提升偏差問題，我們提出 CSAM 策略來學習領域平衡且廣泛的最小值。實驗結果表明，在 Codecfake 資料集和使用 CSAM 策略進行語音編碼的資料集上進行聯合訓練，在所有測試條件下的平均等錯誤率 (EER) 最低，為 0.616%，優於基準模型。

##### **SCALA: Split Federated Learning with Concatenated Activations and Logit Adjustments**
2405.04875v1 by Jiarong Yang, Yuan Liu

Split Federated Learning (SFL) is a distributed machine learning framework
which strategically divides the learning process between a server and clients
and collaboratively trains a shared model by aggregating local models updated
based on data from distributed clients. However, data heterogeneity and partial
client participation result in label distribution skew, which severely degrades
the learning performance. To address this issue, we propose SFL with
Concatenated Activations and Logit Adjustments (SCALA). Specifically, the
activations from the client-side models are concatenated as the input of the
server-side model so as to centrally adjust label distribution across different
clients, and logit adjustments of loss functions on both server-side and
client-side models are performed to deal with the label distribution variation
across different subsets of participating clients. Theoretical analysis and
experimental results verify the superiority of the proposed SCALA on public
datasets.

摘要：分割联邦學習 (SFL) 是一種分散式機器學習架構，它在伺服器和用戶端之間策略性地分割學習過程，並透過彙總根據分散用戶端資料更新的區域模型來協作訓練共享模型。然而，資料異質性和部分用戶端參與會導致標籤分佈偏差，嚴重降低學習效能。為了解決這個問題，我們提出結合激勵和邏輯調整的 SFL (SCALA)。具體來說，用戶端模型的激勵會串接為伺服器端模型的輸入，以便集中調整不同用戶端的標籤分佈，並在伺服器端和用戶端模型上執行損失函數的邏輯調整，以處理參與用戶端不同子集的標籤分佈變化。理論分析和實驗結果驗證了所提出的 SCALA 在公共資料集上的優越性。

##### **Logical Negation Augmenting and Debiasing for Prompt-based Methods**
2405.04872v1 by Yitian Li, Jidong Tian, Hao He, Yaohui Jin

Prompt-based methods have gained increasing attention on NLP and shown
validity on many downstream tasks. Many works have focused on mining these
methods' potential for knowledge extraction, but few explore their ability to
make logical reasoning. In this work, we focus on the effectiveness of the
prompt-based methods on first-order logical reasoning and find that the
bottleneck lies in logical negation. Based on our analysis, logical negation
tends to result in spurious correlations to negative answers, while
propositions without logical negation correlate to positive answers. To solve
the problem, we propose a simple but effective method, Negation Augmenting and
Negation Debiasing (NAND), which introduces negative propositions to
prompt-based methods without updating parameters. Specifically, these negative
propositions can counteract spurious correlations by providing "not" for all
instances so that models cannot make decisions only by whether expressions
contain a logical negation. Experiments on three datasets show that NAND not
only solves the problem of calibrating logical negation but also significantly
enhances prompt-based methods of logical reasoning without model retraining.

摘要：基於提示的方法在 NLP 上獲得越來越多的關注，並在許多下游任務中展現其有效性。許多研究專注於探討這些方法在知識萃取方面的潛力，但鮮少探討它們進行邏輯推理的能力。在這項研究中，我們專注於基於提示的方法在第一階邏輯推理上的有效性，並發現瓶頸在於邏輯否定。根據我們的分析，邏輯否定傾向於導致與否定答案的虛假相關，而沒有邏輯否定的命題則與肯定答案相關。為了解決這個問題，我們提出一個簡單但有效的方法，否定增強和否定去偏 (NAND)，它在不更新參數的情況下，將否定命題引入基於提示的方法。具體來說，這些否定命題可以透過為所有實例提供「非」，來抵消虛假相關，讓模型無法僅透過表達式是否包含邏輯否定來做出決策。在三個資料集上的實驗顯示，NAND 不僅解決了校準邏輯否定的問題，還顯著增強了基於提示的邏輯推理方法，而無需重新訓練模型。

##### **Enhancing Geometric Ontology Embeddings for $\mathcal{EL}^{++}$ with Negative Sampling and Deductive Closure Filtering**
2405.04868v1 by Olga Mashkova, Fernando Zhapa-Camacho, Robert Hoehndorf

Ontology embeddings map classes, relations, and individuals in ontologies
into $\mathbb{R}^n$, and within $\mathbb{R}^n$ similarity between entities can
be computed or new axioms inferred. For ontologies in the Description Logic
$\mathcal{EL}^{++}$, several embedding methods have been developed that
explicitly generate models of an ontology. However, these methods suffer from
some limitations; they do not distinguish between statements that are
unprovable and provably false, and therefore they may use entailed statements
as negatives. Furthermore, they do not utilize the deductive closure of an
ontology to identify statements that are inferred but not asserted. We
evaluated a set of embedding methods for $\mathcal{EL}^{++}$ ontologies based
on high-dimensional ball representation of concept descriptions, incorporating
several modifications that aim to make use of the ontology deductive closure.
In particular, we designed novel negative losses that account both for the
deductive closure and different types of negatives. We demonstrate that our
embedding methods improve over the baseline ontology embedding in the task of
knowledge base or ontology completion.

摘要：本体嵌入将本体中的类、关系和个体映射到 $\mathbb{R}^n$ 中，并且在 $\mathbb{R}^n$ 中可以计算实体之间的相似性或推断新的公理。对于描述逻辑 $\mathcal{EL}^{++}$ 中的本体，已经开发了几种嵌入方法，这些方法可以明确生成本体模型。但是，这些方法存在一些限制；它们不区分不可证明和可证明为假之间的陈述，因此它们可能将蕴含的陈述用作否定。此外，它们不利用本体的演绎闭包来识别被推断但未断言的陈述。我们基于概念描述的高维球表示评估了一组用于 $\mathcal{EL}^{++}$ 本体嵌入的方法，并结合了旨在利用本体演绎闭包的若干修改。特别是，我们设计了新的负损失，它同时考虑了演绎闭包和不同类型的否定。我们证明了我们的嵌入方法在知识库或本体完成功能的任务中改进了基线本体嵌入。

##### **xMTrans: Temporal Attentive Cross-Modality Fusion Transformer for Long-Term Traffic Prediction**
2405.04841v1 by Huy Quang Ung, Hao Niu, Minh-Son Dao, Shinya Wada, Atsunori Minamikawa

Traffic predictions play a crucial role in intelligent transportation
systems. The rapid development of IoT devices allows us to collect different
kinds of data with high correlations to traffic predictions, fostering the
development of efficient multi-modal traffic prediction models. Until now,
there are few studies focusing on utilizing advantages of multi-modal data for
traffic predictions. In this paper, we introduce a novel temporal attentive
cross-modality transformer model for long-term traffic predictions, namely
xMTrans, with capability of exploring the temporal correlations between the
data of two modalities: one target modality (for prediction, e.g., traffic
congestion) and one support modality (e.g., people flow). We conducted
extensive experiments to evaluate our proposed model on traffic congestion and
taxi demand predictions using real-world datasets. The results showed the
superiority of xMTrans against recent state-of-the-art methods on long-term
traffic predictions. In addition, we also conducted a comprehensive ablation
study to further analyze the effectiveness of each module in xMTrans.

摘要：交通預測在智慧交通系統中扮演至關重要的角色。物聯網設備的快速發展，使我們得以收集各種與交通預測高度相關的資料，促進了有效率的多模式交通預測模型的發展。到目前為止，專注於利用多模式資料優勢進行交通預測的研究很少。在本文中，我們介紹了一種新穎的時序注意力跨模態轉換器模型，用於長期交通預測，即 xMTrans，它能夠探索兩種模式資料之間的時序關聯：一種目標模式（用於預測，例如交通擁堵）和一種支援模式（例如人流）。我們進行了廣泛的實驗，使用真實世界的資料集來評估我們提出的交通擁堵和計程車需求預測模型。結果表明，xMTrans 在長期交通預測方面優於最近的最新方法。此外，我們還進行了一項全面的消融研究，以進一步分析 xMTrans 中每個模組的有效性。

##### **Fine-tuning Pre-trained Named Entity Recognition Models For Indian Languages**
2405.04829v1 by Sankalp Bahad, Pruthwik Mishra, Karunesh Arora, Rakesh Chandra Balabantaray, Dipti Misra Sharma, Parameswari Krishnamurthy

Named Entity Recognition (NER) is a useful component in Natural Language
Processing (NLP) applications. It is used in various tasks such as Machine
Translation, Summarization, Information Retrieval, and Question-Answering
systems. The research on NER is centered around English and some other major
languages, whereas limited attention has been given to Indian languages. We
analyze the challenges and propose techniques that can be tailored for
Multilingual Named Entity Recognition for Indian Languages. We present a human
annotated named entity corpora of 40K sentences for 4 Indian languages from two
of the major Indian language families. Additionally,we present a multilingual
model fine-tuned on our dataset, which achieves an F1 score of 0.80 on our
dataset on average. We achieve comparable performance on completely unseen
benchmark datasets for Indian languages which affirms the usability of our
model.

摘要：命名實體識別 (NER) 是自然語言處理 (NLP) 應用中一個有用的組成部分。它用於各種任務，例如機器翻譯、摘要、資訊檢索和問答系統。NER 的研究主要集中在英語和其他一些主要語言上，而對印度語言的關注則較少。我們分析挑戰並提出可以針對印度語言的多語言命名實體識別量身打造的技術。我們提供了一個由人類標註的命名實體語料庫，其中包含來自兩個主要印度語言家族的 4 種印度語言的 40K 個句子。此外，我們還提供了一個針對我們的資料集進行微調的多語言模型，它在我們的資料集上的平均 F1 分數為 0.80。我們在印度語言的完全未見基準資料集上達到了相當的效能，這肯定了我們模型的可用性。

##### **ChuXin: 1.6B Technical Report**
2405.04828v1 by Xiaomin Zhuang, Yufan Jiang, Qiaozhi He, Zhihua Wu

In this report, we present ChuXin, an entirely open-source language model
with a size of 1.6 billion parameters. Unlike the majority of works that only
open-sourced the model weights and architecture, we have made everything needed
to train a model available, including the training data, the training process,
and the evaluation code. Our goal is to empower and strengthen the open
research community, fostering transparency and enabling a new wave of
innovation in the field of language modeling. Furthermore, we extend the
context length to 1M tokens through lightweight continual pretraining and
demonstrate strong needle-in-a-haystack retrieval performance. The weights for
both models are available at Hugging Face to download and use.

摘要：<paragraph>在此報告中，我們提出 ChuXin，一個完全開源的語言模型，參數量為 16 億。與大多數僅開源模型權重和架構的作品不同，我們讓訓練模型所需的一切都可用，包括訓練資料、訓練流程和評估程式碼。我們的目標是賦能並強化開放的研究社群，促進透明度並在語言建模領域開啟創新的新一波。此外，我們透過輕量級的持續預訓練將內容長度延伸至 1M 個符號，並展示出強大的大海撈針檢索效能。兩個模型的權重都可以在 Hugging Face 下載並使用。</paragraph>

##### **Explanation as a Watermark: Towards Harmless and Multi-bit Model Ownership Verification via Watermarking Feature Attribution**
2405.04825v1 by Shuo Shao, Yiming Li, Hongwei Yao, Yiling He, Zhan Qin, Kui Ren

Ownership verification is currently the most critical and widely adopted
post-hoc method to safeguard model copyright. In general, model owners exploit
it to identify whether a given suspicious third-party model is stolen from them
by examining whether it has particular properties `inherited' from their
released models. Currently, backdoor-based model watermarks are the primary and
cutting-edge methods to implant such properties in the released models.
However, backdoor-based methods have two fatal drawbacks, including harmfulness
and ambiguity. The former indicates that they introduce maliciously
controllable misclassification behaviors ($i.e.$, backdoor) to the watermarked
released models. The latter denotes that malicious users can easily pass the
verification by finding other misclassified samples, leading to ownership
ambiguity.
  In this paper, we argue that both limitations stem from the `zero-bit' nature
of existing watermarking schemes, where they exploit the status ($i.e.$,
misclassified) of predictions for verification. Motivated by this
understanding, we design a new watermarking paradigm, $i.e.$, Explanation as a
Watermark (EaaW), that implants verification behaviors into the explanation of
feature attribution instead of model predictions. Specifically, EaaW embeds a
`multi-bit' watermark into the feature attribution explanation of specific
trigger samples without changing the original prediction. We correspondingly
design the watermark embedding and extraction algorithms inspired by
explainable artificial intelligence. In particular, our approach can be used
for different tasks ($e.g.$, image classification and text generation).
Extensive experiments verify the effectiveness and harmlessness of our EaaW and
its resistance to potential attacks.

摘要：目前，所有權驗證是保護模型著作權最關鍵且廣為採用的事後方法。一般而言，模型所有者利用它來識別特定可疑的第三方模型是否從他們那裡竊取，方法是檢查它是否具有從他們發布的模型「繼承」的特定屬性。目前，基於後門的模型浮水印是植入發布模型中此類屬性的主要且最先進的方法。然而，基於後門的方法有兩個致命的缺點，包括有害性和模糊性。前者表示它們會將惡意可控的錯誤分類行為（即後門）引入帶浮水印的發布模型。後者表示惡意使用者可以輕鬆地透過尋找其他錯誤分類的範例來通過驗證，導致所有權模糊性。
在本文中，我們認為這兩個限制都源於現有浮水印方案的「零位元」性質，它們利用預測的狀態（即錯誤分類）進行驗證。受此理解的啟發，我們設計了一個新的浮水印範例，即解釋作為浮水印 (EaaW)，它將驗證行為植入特徵歸因的解釋中，而不是模型預測中。具體來說，EaaW 將「多位元」浮水印嵌入特定觸發範例的特徵歸因解釋中，而不會改變原始預測。我們相應地設計了受可解釋人工智慧啟發的浮水印嵌入和提取演算法。特別是，我們的做法可應用於不同的任務（例如，影像分類和文字生成）。廣泛的實驗驗證了我們 EaaW 的有效性和無害性，以及它對潛在攻擊的抵抗力。

##### **APrompt4EM: Augmented Prompt Tuning for Generalized Entity Matching**
2405.04820v1 by Yikuan Xia, Jiazun Chen, Xinchi Li, Jun Gao

Generalized Entity Matching (GEM), which aims at judging whether two records
represented in different formats refer to the same real-world entity, is an
essential task in data management. The prompt tuning paradigm for pre-trained
language models (PLMs), including the recent PromptEM model, effectively
addresses the challenges of low-resource GEM in practical applications,
offering a robust solution when labeled data is scarce. However, existing
prompt tuning models for GEM face the challenges of prompt design and
information gap. This paper introduces an augmented prompt tuning framework for
the challenges, which consists of two main improvements. The first is an
augmented contextualized soft token-based prompt tuning method that extracts a
guiding soft token benefit for the PLMs' prompt tuning, and the second is a
cost-effective information augmentation strategy leveraging large language
models (LLMs). Our approach performs well on the low-resource GEM challenges.
Extensive experiments show promising advancements of our basic model without
information augmentation over existing methods based on moderate-size PLMs
(average 5.24%+), and our model with information augmentation achieves
comparable performance compared with fine-tuned LLMs, using less than 14% of
the API fee.

摘要：廣義實體配對 (GEM) 旨在判斷以不同格式表示的兩個記錄是否指涉同一個真實世界實體，是資料管理中的一項基本任務。預訓練語言模型 (PLM) 的提示調整範例，包括最近的 PromptEM 模型，有效地解決了實際應用中低資源 GEM 的挑戰，在標籤資料稀少時提供強健的解決方案。然而，現有的 GEM 提示調整模型面臨提示設計和資訊差距的挑戰。本文針對這些挑戰，提出一個擴充的提示調整架構，包含兩個主要的改進。第一個是擴充的語境化軟標記提示調整方法，用於萃取一個引導性的軟標記優點，以利 PLM 的提示調整；第二個是一個具成本效益的資訊擴充策略，利用大型語言模型 (LLM)。我們的做法在低資源 GEM 挑戰中表現良好。廣泛的實驗顯示，我們的基本模型在沒有資訊擴充的情況下，相較於基於中等規模 PLM 的現有方法，有顯著的進步（平均 5.24%+），而我們的模型在有資訊擴充的情況下，使用不到 14% 的 API 費用，達到了與微調 LLM 相當的效能。

##### **DALK: Dynamic Co-Augmentation of LLMs and KG to answer Alzheimer's Disease Questions with Scientific Literature**
2405.04819v1 by Dawei Li, Shu Yang, Zhen Tan, Jae Young Baik, Sunkwon Yun, Joseph Lee, Aaron Chacko, Bojian Hou, Duy Duong-Tran, Ying Ding, Huan Liu, Li Shen, Tianlong Chen

Recent advancements in large language models (LLMs) have achieved promising
performances across various applications. Nonetheless, the ongoing challenge of
integrating long-tail knowledge continues to impede the seamless adoption of
LLMs in specialized domains. In this work, we introduce DALK, a.k.a. Dynamic
Co-Augmentation of LLMs and KG, to address this limitation and demonstrate its
ability on studying Alzheimer's Disease (AD), a specialized sub-field in
biomedicine and a global health priority. With a synergized framework of LLM
and KG mutually enhancing each other, we first leverage LLM to construct an
evolving AD-specific knowledge graph (KG) sourced from AD-related scientific
literature, and then we utilize a coarse-to-fine sampling method with a novel
self-aware knowledge retrieval approach to select appropriate knowledge from
the KG to augment LLM inference capabilities. The experimental results,
conducted on our constructed AD question answering (ADQA) benchmark, underscore
the efficacy of DALK. Additionally, we perform a series of detailed analyses
that can offer valuable insights and guidelines for the emerging topic of
mutually enhancing KG and LLM. We will release the code and data at
https://github.com/David-Li0406/DALK.

摘要：大型語言模型 (LLM) 近期的進展在各種應用中取得了可觀的表現。儘管如此，整合長尾知識的持續挑戰仍然阻礙了 LLM 在專業領域的無縫採用。在這項工作中，我們引入了 DALK，又名 LLM 和 KG 的動態協同擴充，以解決這個限制，並展示其在研究阿茲海默症 (AD) 的能力，這是一個生物醫學中的專業子領域，也是全球健康的優先事項。透過 LLM 和 KG 互相增強的協同架構，我們首先利用 LLM 從與 AD 相關的科學文獻中建構一個不斷演進的 AD 專屬知識圖譜 (KG)，然後我們利用粗到細的抽樣方法，並採用新穎的自知知識擷取方法，從 KG 中選擇適當的知識來擴充 LLM 推論能力。在我們建構的 AD 問題解答 (ADQA) 基準上進行的實驗結果突顯了 DALK 的功效。此外，我們執行了一系列詳細的分析，可以為 KG 和 LLM 相互增強的新興主題提供有價值的見解和指導方針。我們將在 https://github.com/David-Li0406/DALK 釋出程式碼和資料。

##### **ACORN: Aspect-wise Commonsense Reasoning Explanation Evaluation**
2405.04818v1 by Ana Brassard, Benjamin Heinzerling, Keito Kudo, Keisuke Sakaguchi, Kentaro Inui

Evaluating free-text explanations is a multifaceted, subjective, and
labor-intensive task. Large language models (LLMs) present an appealing
alternative due to their potential for consistency, scalability, and
cost-efficiency. In this work, we present ACORN, a new dataset of 3,500
free-text explanations and aspect-wise quality ratings, and use it to gain
insights into how LLMs evaluate explanations. We observed that replacing one of
the human ratings sometimes maintained, but more often lowered the
inter-annotator agreement across different settings and quality aspects,
suggesting that their judgments are not always consistent with human raters. We
further quantified this difference by comparing the correlation between
LLM-generated ratings with majority-voted human ratings across different
quality aspects. With the best system, Spearman's rank correlation ranged
between 0.53 to 0.95, averaging 0.72 across aspects, indicating moderately high
but imperfect alignment. Finally, we considered the alternative of using an LLM
as an additional rater when human raters are scarce, and measured the
correlation between majority-voted labels with a limited human pool and LLMs as
an additional rater, compared to the original gold labels. While GPT-4 improved
the outcome when there were only two human raters, in all other observed cases,
LLMs were neutral to detrimental when there were three or more human raters. We
publicly release the dataset to support future improvements in LLM-in-the-loop
evaluation here: https://github.com/a-brassard/ACORN.

摘要：評估自由文字的說明是一項多面向、主觀且需要大量人工的工作。大型語言模型 (LLM) 由於其潛在的一致性、可擴充性和成本效益，提供了一個有吸引力的替代方案。在這項工作中，我們提出了 ACORN，一個包含 3,500 個自由文字說明和面向方面的品質評分的新資料集，並使用它來深入了解 LLM 如何評估說明。我們觀察到，有時會替換其中一個人類評分，但在不同的設定和品質方面，更常降低評分者之間的協議，這表示他們的判斷並不總是與人類評分者一致。我們進一步通過比較 LLM 生成的評分與不同品質方面的大多數投票人類評分之間的相關性，量化了這種差異。使用最佳系統，Spearman 等級相關性介於 0.53 到 0.95 之間，在不同方面平均為 0.72，表示適度高但並不完美的對齊。最後，我們考慮了在人類評分者稀少時使用 LLM 作為額外評分者的替代方案，並測量了大多數投票標籤與有限的人類池和 LLM 作為額外評分者的相關性，並與原始黃金標籤進行比較。儘管 GPT-4 在只有兩個人類評分者時改善了結果，但在所有其他觀察案例中，當有三個或更多人類評分者時，LLM 對結果沒有幫助甚至有害。我們公開發布資料集以支援 LLM 在迴圈評估中的未來改進：https://github.com/a-brassard/ACORN。

##### **A Novel Technique for Query Plan Representation Based on Graph Neural Networks**
2405.04814v1 by Baoming Chang, Amin Kamali, Verena Kantere

Learning representations for query plans play a pivotal role in machine
learning-based query optimizers of database management systems. To this end,
particular model architectures are proposed in the literature to convert the
tree-structured query plans into representations with formats learnable by
downstream machine learning models. However, existing research rarely compares
and analyzes the query plan representation capabilities of these tree models
and their direct impact on the performance of the overall optimizer. To address
this problem, we perform a comparative study to explore the effect of using
different state-of-the-art tree models on the optimizer's cost estimation and
plan selection performance in relatively complex workloads. Additionally, we
explore the possibility of using graph neural networks (GNN) in the query plan
representation task. We propose a novel tree model combining directed GNN with
Gated Recurrent Units (GRU) and demonstrate experimentally that the new tree
model provides significant improvements to cost estimation tasks and relatively
excellent plan selection performance compared to the state-of-the-art tree
models.

摘要：學習查詢計畫的表徵在資料庫管理系統的機器學習查詢最佳化器中扮演關鍵角色。為此，文獻中提出了特定的模型架構，將樹狀結構的查詢計畫轉換成下游機器學習模型可學習的格式表徵。然而，現有的研究很少比較和分析這些樹狀模型的查詢計畫表徵能力，以及它們對整體最佳化器效能的直接影響。為了解決這個問題，我們執行了一項比較研究，探討使用不同的最新樹狀模型對最佳化器的成本估計和計畫選擇效能的影響，特別是在相對複雜的工作負載中。此外，我們探討了在查詢計畫表徵任務中使用圖神經網路 (GNN) 的可能性。我們提出了一種結合有向 GNN 和門控遞迴單元 (GRU) 的新樹狀模型，並透過實驗證明，與現有的樹狀模型相比，新的樹狀模型在成本估計任務中提供了顯著的改進，並且在計畫選擇效能方面相對優異。

##### **From LLMs to Actions: Latent Codes as Bridges in Hierarchical Robot Control**
2405.04798v1 by Yide Shentu, Philipp Wu, Aravind Rajeswaran, Pieter Abbeel

Hierarchical control for robotics has long been plagued by the need to have a
well defined interface layer to communicate between high-level task planners
and low-level policies. With the advent of LLMs, language has been emerging as
a prospective interface layer. However, this has several limitations. Not all
tasks can be decomposed into steps that are easily expressible in natural
language (e.g. performing a dance routine). Further, it makes end-to-end
finetuning on embodied data challenging due to domain shift and catastrophic
forgetting. We introduce our method -- Learnable Latent Codes as Bridges (LCB)
-- as an alternate architecture to overcome these limitations. \method~uses a
learnable latent code to act as a bridge between LLMs and low-level policies.
This enables LLMs to flexibly communicate goals in the task plan without being
entirely constrained by language limitations. Additionally, it enables
end-to-end finetuning without destroying the embedding space of word tokens
learned during pre-training. Through experiments on Language Table and Calvin,
two common language based benchmarks for embodied agents, we find that
\method~outperforms baselines (including those w/ GPT-4V) that leverage pure
language as the interface layer on tasks that require reasoning and multi-step
behaviors.

摘要：階層式機器人控制長期以來一直受到需要有明確介面層來溝通高階任務規劃者和低階政策的困擾。隨著 LLM 的出現，語言已成為潛在的介面層。然而，這有幾個限制。並非所有任務都能分解成容易用自然語言表達的步驟（例如執行舞蹈動作）。此外，由於領域轉移和災難性遺忘，這使得針對具體資料進行端到端微調具有挑戰性。我們介紹了我們的模型——可學習潛在碼作為橋樑 (LCB)——作為一種克服這些限制的替代架構。\method~使用可學習潛在碼作為 LLM 和低階政策之間的橋樑。這使 LLM 能夠靈活地傳達任務計畫中的目標，而不會完全受到語言限制的約束。此外，它可以在不破壞預訓練期間學習到的文字符號嵌入空間的情況下進行端到端微調。透過對語言表格和凱文進行實驗，這兩個是具體代理的常見語言基準，我們發現\method~優於基準（包括那些使用 GPT-4V 的基準），這些基準在需要推理和多步驟行為的任務上利用純語言作為介面層。

##### **Zero-shot LLM-guided Counterfactual Generation for Text**
2405.04793v1 by Amrita Bhattacharjee, Raha Moraffah, Joshua Garland, Huan Liu

Counterfactual examples are frequently used for model development and
evaluation in many natural language processing (NLP) tasks. Although methods
for automated counterfactual generation have been explored, such methods depend
on models such as pre-trained language models that are then fine-tuned on
auxiliary, often task-specific datasets. Collecting and annotating such
datasets for counterfactual generation is labor intensive and therefore,
infeasible in practice. Therefore, in this work, we focus on a novel problem
setting: \textit{zero-shot counterfactual generation}. To this end, we propose
a structured way to utilize large language models (LLMs) as general purpose
counterfactual example generators. We hypothesize that the
instruction-following and textual understanding capabilities of recent LLMs can
be effectively leveraged for generating high quality counterfactuals in a
zero-shot manner, without requiring any training or fine-tuning. Through
comprehensive experiments on various downstream tasks in natural language
processing (NLP), we demonstrate the efficacy of LLMs as zero-shot
counterfactual generators in evaluating and explaining black-box NLP models.

摘要：反事實範例經常應用於自然語言處理 (NLP) 任務中的模型開發和評估。儘管已探索用於自動化反事實產生之方法，但此類方法仰賴於模型，例如預先訓練的語言模型，然後在輔助性資料集（通常為特定於任務的資料集）上進行微調。收集和標註此類資料集以進行反事實產生需要大量人力，因此在實務上不可行。因此，在這項工作中，我們專注於一個新穎的問題設定：\textit{零次學習反事實產生}。為此，我們提出一個結構化的方式，利用大型語言模型 (LLM) 作為通用反事實範例產生器。我們假設，最近的 LLM 的指令遵循和文本理解能力可以有效地用於產生高品質的反事實，以零次學習的方式進行，無需任何訓練或微調。透過在自然語言處理 (NLP) 中各種下游任務進行全面的實驗，我們證明了 LLM 作為零次學習反事實產生器在評估和解釋黑盒 NLP 模型中的效能。

##### **CourseGPT-zh: an Educational Large Language Model Based on Knowledge Distillation Incorporating Prompt Optimization**
2405.04781v1 by Zheyan Qu, Lu Yin, Zitong Yu, Wenbo Wang, Xing zhang

Large language models (LLMs) have demonstrated astonishing capabilities in
natural language processing (NLP) tasks, sparking interest in their application
to professional domains with higher specialized requirements. However,
restricted access to closed-source LLMs via APIs and the difficulty in
collecting massive high-quality datasets pose obstacles to the development of
large language models in education fields of various courses. Given these
challenges, we propose CourseGPT-zh, a course-oriented education LLM that
supports customization and low-cost deployment. To address the
comprehensiveness and diversity requirements of course-specific corpora, we
design a high-quality question-answering corpus distillation framework
incorporating prompt optimization, which effectively mines textbook knowledge
and enhances its diversity. Moreover, considering the alignment of LLM
responses with user needs, a novel method for discrete prompt optimization
based on LLM-as-Judge is introduced. During optimization, this framework
leverages the LLM's ability to reflect on and exploit error feedback and
patterns, allowing for prompts that meet user needs and preferences while
saving response length. Lastly, we obtain CourseGPT-zh based on the open-source
LLM using parameter-efficient fine-tuning. Experimental results show that our
discrete prompt optimization framework effectively improves the response
quality of ChatGPT, and CourseGPT-zh exhibits strong professional capabilities
in specialized knowledge question-answering, significantly outperforming
comparable open-source models.

摘要：大型語言模型 (LLM) 在自然語言處理 (NLP) 任務中展現出驚人的能力，激發了將其應用於專業領域，以滿足更高專業化需求的興趣。然而，透過 API 限制存取封閉原始碼的 LLM，以及難以收集大量高品質資料集，對各種課程的教育領域中大型語言模型的開發構成障礙。鑑於這些挑戰，我們提出 CourseGPT-zh，一個以課程為導向的教育 LLM，支援客製化和低成本部署。為了滿足課程特定語料庫的全面性和多樣性需求，我們設計了一個高品質問答語料庫萃取架構，結合提示最佳化，有效挖掘教科書知識並提升其多樣性。此外，考量到 LLM 回應與使用者需求的一致性，引入了基於 LLM-as-Judge 的離散提示最佳化新方法。在最佳化過程中，此架構利用 LLM 反思和利用錯誤回饋和模式的能力，允許提示滿足使用者需求和偏好，同時節省回應長度。最後，我們使用參數有效微調，根據開源 LLM 獲得 CourseGPT-zh。實驗結果顯示，我們的離散提示最佳化架構有效提升 ChatGPT 的回應品質，而 CourseGPT-zh 在專業知識問答中展現強大的專業能力，顯著優於同類開源模型。

##### **Empathy Through Multimodality in Conversational Interfaces**
2405.04777v1 by Mahyar Abbasian, Iman Azimi, Mohammad Feli, Amir M. Rahmani, Ramesh Jain

Agents represent one of the most emerging applications of Large Language
Models (LLMs) and Generative AI, with their effectiveness hinging on multimodal
capabilities to navigate complex user environments. Conversational Health
Agents (CHAs), a prime example of this, are redefining healthcare by offering
nuanced support that transcends textual analysis to incorporate emotional
intelligence. This paper introduces an LLM-based CHA engineered for rich,
multimodal dialogue-especially in the realm of mental health support. It
adeptly interprets and responds to users' emotional states by analyzing
multimodal cues, thus delivering contextually aware and empathetically resonant
verbal responses. Our implementation leverages the versatile openCHA framework,
and our comprehensive evaluation involves neutral prompts expressed in diverse
emotional tones: sadness, anger, and joy. We evaluate the consistency and
repeatability of the planning capability of the proposed CHA. Furthermore,
human evaluators critique the CHA's empathic delivery, with findings revealing
a striking concordance between the CHA's outputs and evaluators' assessments.
These results affirm the indispensable role of vocal (soon multimodal) emotion
recognition in strengthening the empathetic connection built by CHAs, cementing
their place at the forefront of interactive, compassionate digital health
solutions.

摘要：代理是大型語言模型 (LLM) 和生成式 AI 最新的應用之一，其有效性取決於在複雜用戶環境中導航的多模態能力。對話式健康代理 (CHA) 就是一個很好的例子，它透過提供超越文字分析以納入情緒智慧的細微支持，重新定義了醫療保健。本文介紹了一個基於 LLM 的 CHA，它專為豐富的多模態對話而設計，特別是在心理健康支持領域。它透過分析多模態線索來靈活地詮釋和回應使用者的情緒狀態，從而提供具有情境意識和同理共鳴的言語回應。我們的實作利用了通用的 openCHA 框架，而我們的全面評估涉及以不同的情緒語氣表達的中立提示：悲傷、憤怒和喜悅。我們評估了所提出的 CHA 計畫能力的一致性和可重複性。此外，人類評估員會批判 CHA 的同理心傳遞，結果顯示 CHA 的輸出與評估員的評估之間有驚人的一致性。這些結果肯定了語音（很快會是多模態）情緒識別在強化 CHA 建立的同理心連結中不可或缺的作用，鞏固了它們在互動式、富有同情心的數位健康解決方案中的領先地位。

##### **Chain of Thoughtlessness: An Analysis of CoT in Planning**
2405.04776v1 by Kaya Stechly, Karthik Valmeekam, Subbarao Kambhampati

Large language model (LLM) performance on reasoning problems typically does
not generalize out of distribution. Previous work has claimed that this can be
mitigated by modifying prompts to include examples with chains of
thought--demonstrations of solution procedures--with the intuition that it is
possible to in-context teach an LLM an algorithm for solving the problem. This
paper presents a case study of chain of thought on problems from Blocksworld, a
classical planning domain, and examine the performance of two state-of-the-art
LLMs across two axes: generality of examples given in prompt, and complexity of
problems queried with each prompt. While our problems are very simple, we only
find meaningful performance improvements from chain of thought prompts when
those prompts are exceedingly specific to their problem class, and that those
improvements quickly deteriorate as the size n of the query-specified stack
grows past the size of stacks shown in the examples. Our results hint that,
contrary to previous claims in the literature, CoT's performance improvements
do not stem from the model learning general algorithmic procedures via
demonstrations and depend on carefully engineering highly problem specific
prompts. This spotlights drawbacks of chain of thought, especially because of
the sharp tradeoff between possible performance gains and the amount of human
labor necessary to generate examples with correct reasoning traces.

摘要：大型語言模型 (LLM) 在推理問題上的表現通常不會推廣到分布之外。先前的研究聲稱，這可以用修改提示來緩解，其中包括帶有思考鏈的範例——解決程序的示範——直覺上認為可以針對特定問題在上下文中教授 LLM 一種演算法。本文針對區塊世界問題的思考鏈進行個案研究，區塊世界是一個經典的規劃領域，並在兩個軸線上檢驗兩個最先進的 LLM 的表現：提示中提供的範例的一般性，以及使用每個提示查詢的問題的複雜性。雖然我們的問題非常簡單，但我們只在思考鏈提示極其特定於其問題類別時，才發現有意義的效能提升，而且隨著查詢指定的堆疊大小 n 超過範例中顯示的堆疊大小，這些提升會迅速惡化。我們的結果暗示，與文獻中先前的說法相反，思考鏈的效能提升並非源於模型透過示範學習一般演算法程序，而是取決於仔細設計高度特定於問題的提示。這突顯了思考鏈的缺點，特別是因為在可能的效能提升與產生具有正確推理追蹤的範例所需的人力之間存在顯著的權衡。

##### **Hypergraph-enhanced Dual Semi-supervised Graph Classification**
2405.04773v1 by Wei Ju, Zhengyang Mao, Siyu Yi, Yifang Qin, Yiyang Gu, Zhiping Xiao, Yifan Wang, Xiao Luo, Ming Zhang

In this paper, we study semi-supervised graph classification, which aims at
accurately predicting the categories of graphs in scenarios with limited
labeled graphs and abundant unlabeled graphs. Despite the promising capability
of graph neural networks (GNNs), they typically require a large number of
costly labeled graphs, while a wealth of unlabeled graphs fail to be
effectively utilized. Moreover, GNNs are inherently limited to encoding local
neighborhood information using message-passing mechanisms, thus lacking the
ability to model higher-order dependencies among nodes. To tackle these
challenges, we propose a Hypergraph-Enhanced DuAL framework named HEAL for
semi-supervised graph classification, which captures graph semantics from the
perspective of the hypergraph and the line graph, respectively. Specifically,
to better explore the higher-order relationships among nodes, we design a
hypergraph structure learning to adaptively learn complex node dependencies
beyond pairwise relations. Meanwhile, based on the learned hypergraph, we
introduce a line graph to capture the interaction between hyperedges, thereby
better mining the underlying semantic structures. Finally, we develop a
relational consistency learning to facilitate knowledge transfer between the
two branches and provide better mutual guidance. Extensive experiments on
real-world graph datasets verify the effectiveness of the proposed method
against existing state-of-the-art methods.

摘要：<paragraph>在本文中，我們探討半監督圖形分類，旨在準確預測圖形類別，並在標籤圖形有限但未標籤圖形豐富的情況下進行。儘管圖形神經網路 (GNN) 具有令人滿意的能力，但它們通常需要大量的昂貴標籤圖形，而大量未標籤圖形無法得到有效利用。此外，GNN 本質上僅限於使用訊息傳遞機制編碼局部鄰域資訊，因此缺乏對節點之間高階依賴關係進行建模的能力。為了應對這些挑戰，我們提出了一個名為 HEAL 的超圖形增強對偶框架，用於半監督圖形分類，它分別從超圖形和線圖的角度捕獲圖形語義。具體來說，為了更好地探索節點之間的高階關係，我們設計了一個超圖形結構學習，以自適應地學習超越成對關係的複雜節點依賴關係。同時，基於學習到的超圖形，我們引入了一個線圖來捕獲超邊之間的交互作用，從而更好地挖掘底層語義結構。最後，我們開發了一種關係一致性學習，以促進兩個分支之間的知識傳遞並提供更好的相互指導。在真實世界圖形資料集上的大量實驗驗證了所提出的方法對現有最先進方法的有效性。</paragraph>

##### **When Foresight Pruning Meets Zeroth-Order Optimization: Efficient Federated Learning for Low-Memory Devices**
2405.04765v1 by Pengyu Zhang, Yingjie Liu, Yingbo Zhou, Xiao Du, Xian Wei, Ting Wang, Mingsong Chen

Although Federated Learning (FL) enables collaborative learning in Artificial
Intelligence of Things (AIoT) design, it fails to work on low-memory AIoT
devices due to its heavy memory usage. To address this problem, various
federated pruning methods are proposed to reduce memory usage during inference.
However, few of them can substantially mitigate the memory burdens during
pruning and training. As an alternative, zeroth-order or backpropagation-free
(BP-Free) methods can partially alleviate the memory consumption, but they
suffer from scaling up and large computation overheads, since the gradient
estimation error and floating point operations (FLOPs) increase as the
dimensionality of the model parameters grows. In this paper, we propose a
federated foresight pruning method based on Neural Tangent Kernel (NTK), which
can seamlessly integrate with federated BP-Free training frameworks. We present
an approximation to the computation of federated NTK by using the local NTK
matrices. Moreover, we demonstrate that the data-free property of our method
can substantially reduce the approximation error in extreme data heterogeneity
scenarios. Since our approach improves the performance of the vanilla BP-Free
method with fewer FLOPs and truly alleviates memory pressure during training
and inference, it makes FL more friendly to low-memory devices. Comprehensive
experimental results obtained from simulation- and real test-bed-based
platforms show that our federated foresight-pruning method not only preserves
the ability of the dense model with a memory reduction up to 9x but also boosts
the performance of the vanilla BP-Free method with dramatically fewer FLOPs.

摘要：雖然聯合學習 (FL) 能讓人工智慧物聯網 (AIoT) 設計中的協作學習成為可能，但由於其龐大的記憶體使用量，它無法在低記憶體的 AIoT 裝置上運作。為了解決這個問題，提出了各種聯合剪枝方法，以便在推論期間減少記憶體使用量。然而，其中只有少數能實質上減輕剪枝和訓練期間的記憶體負擔。作為一種替代方案，零階或反向傳播 (BP-Free) 方法可以部分減輕記憶體消耗，但它們會導致擴展和大量的運算開銷，因為隨著模型參數維度的增加，梯度估計誤差和浮點運算 (FLOP) 會增加。在本文中，我們提出了一個基於神經切線核 (NTK) 的聯合預見性剪枝方法，它可以無縫整合到聯合 BP-Free 訓練架構中。我們提出了一個使用局部 NTK 矩陣來計算聯合 NTK 的近似值。此外，我們證明了我們方法的無資料特性可以在極端資料異質性場景中大幅減少近似誤差。由於我們的方法以較少的 FLOP 改善了香草 BP-Free 方法的效能，並真正減輕了訓練和推論期間的記憶體壓力，它讓 FL 更適用於低記憶體裝置。從模擬和基於真實測試平台取得的綜合實驗結果顯示，我們的聯合預見性剪枝方法不僅保留了密集模型的能力，記憶體減少了 9 倍，而且還以大幅減少的 FLOP 提升了香草 BP-Free 方法的效能。

##### **Large Language Models for Cyber Security: A Systematic Literature Review**
2405.04760v2 by HanXiang Xu, ShenAo Wang, NingKe Li, KaiLong Wang, YanJie Zhao, Kai Chen, Ting Yu, Yang Liu, HaoYu Wang

The rapid advancement of Large Language Models (LLMs) has opened up new
opportunities for leveraging artificial intelligence in various domains,
including cybersecurity. As the volume and sophistication of cyber threats
continue to grow, there is an increasing need for intelligent systems that can
automatically detect vulnerabilities, analyze malware, and respond to attacks.
In this survey, we conduct a comprehensive review of the literature on the
application of LLMs in cybersecurity (LLM4Security). By comprehensively
collecting over 30K relevant papers and systematically analyzing 127 papers
from top security and software engineering venues, we aim to provide a holistic
view of how LLMs are being used to solve diverse problems across the
cybersecurity domain. Through our analysis, we identify several key findings.
First, we observe that LLMs are being applied to a wide range of cybersecurity
tasks, including vulnerability detection, malware analysis, network intrusion
detection, and phishing detection. Second, we find that the datasets used for
training and evaluating LLMs in these tasks are often limited in size and
diversity, highlighting the need for more comprehensive and representative
datasets. Third, we identify several promising techniques for adapting LLMs to
specific cybersecurity domains, such as fine-tuning, transfer learning, and
domain-specific pre-training. Finally, we discuss the main challenges and
opportunities for future research in LLM4Security, including the need for more
interpretable and explainable models, the importance of addressing data privacy
and security concerns, and the potential for leveraging LLMs for proactive
defense and threat hunting. Overall, our survey provides a comprehensive
overview of the current state-of-the-art in LLM4Security and identifies several
promising directions for future research.

摘要：大型語言模型（LLM）快速發展，為在各種領域利用人工智慧開闢了新機會，包括網路安全。隨著網路威脅的數量和複雜性持續增加，對於能夠自動偵測弱點、分析惡意軟體和回應攻擊的智慧系統需求也日益增加。在這項調查中，我們對 LLM 在網路安全中的應用（LLM4Security）相關文獻進行全面回顧。透過全面蒐集超過 30K 篇相關論文，並系統性地分析來自頂尖安全和軟體工程場所的 127 篇論文，我們旨在提供 LLM 如何用於解決網路安全領域中各種問題的全面觀點。透過我們的分析，我們找出幾個關鍵發現。首先，我們觀察到 LLM 被應用於廣泛的網路安全任務，包括弱點偵測、惡意軟體分析、網路入侵偵測和網路釣魚偵測。其次，我們發現用於訓練和評估這些任務中 LLM 的資料集通常在規模和多樣性上受到限制，這突顯了對於更全面且具代表性的資料集的需求。第三，我們找出幾個將 LLM 適應到特定網路安全領域的有前景技術，例如微調、遷移學習和特定領域的預訓練。最後，我們討論 LLM4Security 未來研究的主要挑戰和機會，包括對於更具可解釋性和可說明性的模型的需求、解決資料隱私和安全問題的重要性，以及利用 LLM 進行主動防禦和威脅追蹤的潛力。總體而言，我們的調查提供了 LLM4Security 目前最先進技術的全面概觀，並找出幾個有前景的未來研究方向。

##### **BiasKG: Adversarial Knowledge Graphs to Induce Bias in Large Language Models**
2405.04756v1 by Chu Fei Luo, Ahmad Ghawanmeh, Xiaodan Zhu, Faiza Khan Khattak

Modern large language models (LLMs) have a significant amount of world
knowledge, which enables strong performance in commonsense reasoning and
knowledge-intensive tasks when harnessed properly. The language model can also
learn social biases, which has a significant potential for societal harm. There
have been many mitigation strategies proposed for LLM safety, but it is unclear
how effective they are for eliminating social biases. In this work, we propose
a new methodology for attacking language models with knowledge graph augmented
generation. We refactor natural language stereotypes into a knowledge graph,
and use adversarial attacking strategies to induce biased responses from
several open- and closed-source language models. We find our method increases
bias in all models, even those trained with safety guardrails. This
demonstrates the need for further research in AI safety, and further work in
this new adversarial space.

摘要：現代的大型語言模型（LLM）擁有大量的世界知識，在適當利用時，這使它們在常識推理和知識密集型任務中表現出色。語言模型還可以學習社會偏見，這對社會危害具有重大潛力。已經提出了許多針對 LLM 安全性的緩解策略，但目前尚不清楚它們在消除社會偏見方面的有效性。在這項工作中，我們提出了一種新的方法，使用知識圖譜增強生成來攻擊語言模型。我們將自然語言刻板印象重構為知識圖譜，並使用對抗性攻擊策略來誘導來自幾個開源和閉源語言模型的偏差回應。我們發現我們的模型增加了所有模型中的偏差，即使是那些使用安全防護措施進行訓練的模型。這表明需要進一步研究人工智能安全，並在這個新的對抗空間中進一步開展工作。

##### **AttacKG+:Boosting Attack Knowledge Graph Construction with Large Language Models**
2405.04753v1 by Yongheng Zhang, Tingwen Du, Yunshan Ma, Xiang Wang, Yi Xie, Guozheng Yang, Yuliang Lu, Ee-Chien Chang

Attack knowledge graph construction seeks to convert textual cyber threat
intelligence (CTI) reports into structured representations, portraying the
evolutionary traces of cyber attacks. Even though previous research has
proposed various methods to construct attack knowledge graphs, they generally
suffer from limited generalization capability to diverse knowledge types as
well as requirement of expertise in model design and tuning. Addressing these
limitations, we seek to utilize Large Language Models (LLMs), which have
achieved enormous success in a broad range of tasks given exceptional
capabilities in both language understanding and zero-shot task fulfillment.
Thus, we propose a fully automatic LLM-based framework to construct attack
knowledge graphs named: AttacKG+. Our framework consists of four consecutive
modules: rewriter, parser, identifier, and summarizer, each of which is
implemented by instruction prompting and in-context learning empowered by LLMs.
Furthermore, we upgrade the existing attack knowledge schema and propose a
comprehensive version. We represent a cyber attack as a temporally unfolding
event, each temporal step of which encapsulates three layers of representation,
including behavior graph, MITRE TTP labels, and state summary. Extensive
evaluation demonstrates that: 1) our formulation seamlessly satisfies the
information needs in threat event analysis, 2) our construction framework is
effective in faithfully and accurately extracting the information defined by
AttacKG+, and 3) our attack graph directly benefits downstream security
practices such as attack reconstruction. All the code and datasets will be
released upon acceptance.

摘要：攻擊知識圖譜建構旨在將文字形式的網路威脅情報 (CTI) 報告轉換成結構化表示，描繪網路攻擊的演化軌跡。儘管先前的研究已提出各種建構攻擊知識圖譜的方法，但它們普遍存在對不同知識類型的概化能力有限，以及對模型設計和調整專業知識的需求等問題。為了解決這些限制，我們尋求利用大型語言模型 (LLM)，它在廣泛的任務中取得了巨大的成功，在語言理解和零次學習任務完成方面都具備出色的能力。因此，我們提出一個完全自動化的基於 LLM 的框架來建構攻擊知識圖譜，名為：AttacKG+。我們的框架包含四個連續的模組：改寫器、解析器、識別器和摘要器，每個模組都是透過指令提示和 LLM 賦能的脈絡學習來實現。此外，我們升級了現有的攻擊知識架構，並提出了一個全面的版本。我們將網路攻擊表示為一個時間展開的事件，每個時間步驟都包含三層表示，包括行為圖、MITRE TTP 標籤和狀態摘要。廣泛的評估表明：1) 我們的表述無縫地滿足了威脅事件分析中的資訊需求，2) 我們的建構框架有效地忠實且準確地提取 AttacKG+ 定義的資訊，以及 3) 我們的攻擊圖直接有利於下游安全實務，例如攻擊重建。所有程式碼和資料集將在被接受後發布。

##### **S-EQA: Tackling Situational Queries in Embodied Question Answering**
2405.04732v1 by Vishnu Sashank Dorbala, Prasoon Goyal, Robinson Piramuthu, Michael Johnston, Dinesh Manocha, Reza Ghanadhan

We present and tackle the problem of Embodied Question Answering (EQA) with
Situational Queries (S-EQA) in a household environment. Unlike prior EQA work
tackling simple queries that directly reference target objects and quantifiable
properties pertaining them, EQA with situational queries (such as "Is the
bathroom clean and dry?") is more challenging, as the agent needs to figure out
not just what the target objects pertaining to the query are, but also requires
a consensus on their states to be answerable. Towards this objective, we first
introduce a novel Prompt-Generate-Evaluate (PGE) scheme that wraps around an
LLM's output to create a dataset of unique situational queries, corresponding
consensus object information, and predicted answers. PGE maintains uniqueness
among the generated queries, using multiple forms of semantic similarity. We
validate the generated dataset via a large scale user-study conducted on
M-Turk, and introduce it as S-EQA, the first dataset tackling EQA with
situational queries. Our user study establishes the authenticity of S-EQA with
a high 97.26% of the generated queries being deemed answerable, given the
consensus object data. Conversely, we observe a low correlation of 46.2% on the
LLM-predicted answers to human-evaluated ones; indicating the LLM's poor
capability in directly answering situational queries, while establishing
S-EQA's usability in providing a human-validated consensus for an indirect
solution. We evaluate S-EQA via Visual Question Answering (VQA) on VirtualHome,
which unlike other simulators, contains several objects with modifiable states
that also visually appear different upon modification -- enabling us to set a
quantitative benchmark for S-EQA. To the best of our knowledge, this is the
first work to introduce EQA with situational queries, and also the first to use
a generative approach for query creation.

摘要：<paragraph>我們提出並解決了在家庭環境中使用情境查詢（S-EQA）的具身問題回答（EQA）問題。與先前處理直接引用目標對象和與之相關的可量化屬性的簡單查詢的 EQA 工作不同，使用情境查詢（例如「浴室是否乾淨乾燥？」）的 EQA 更具挑戰性，因為代理必須找出不只是與查詢相關的目標對象，還需要就其狀態達成共識才能回答。為了達成此目標，我們首先介紹一個新穎的提示生成評估（PGE）架構，它包覆 LLM 的輸出以建立一個包含獨特情境查詢、對應共識對象資訊和預測答案的資料集。PGE 使用多種形式的語義相似性，在生成的查詢中維持獨特性。我們透過在 M-Turk 上進行的大規模使用者研究驗證所生成的資料集，並將其作為 S-EQA 介紹，這是第一個處理使用情境查詢的 EQA 的資料集。我們的使用者研究建立了 S-EQA 的真實性，在給定共識對象資料的情況下，97.26% 的生成查詢被認為是可以回答的。相反地，我們觀察到 LLM 預測答案與人類評估答案之間的相關性很低，只有 46.2%；這表示 LLM 直接回答情境查詢的能力很差，同時建立了 S-EQA 在提供間接解決方案的人類驗證共識方面的可用性。我們透過在 VirtualHome 上的視覺問答（VQA）評估 S-EQA，與其他模擬器不同，它包含了幾個狀態可修改的對象，這些對象在修改後在視覺上也會出現不同的變化，使我們能夠為 S-EQA 設定一個量化基準。據我們所知，這是第一個介紹使用情境查詢的 EQA 的研究，也是第一個使用生成式方法進行查詢建立的研究。</paragraph>

##### **Learning Phonotactics from Linguistic Informants**
2405.04726v1 by Canaan Breiss, Alexis Ross, Amani Maina-Kilaas, Roger Levy, Jacob Andreas

We propose an interactive approach to language learning that utilizes
linguistic acceptability judgments from an informant (a competent language
user) to learn a grammar. Given a grammar formalism and a framework for
synthesizing data, our model iteratively selects or synthesizes a data-point
according to one of a range of information-theoretic policies, asks the
informant for a binary judgment, and updates its own parameters in preparation
for the next query. We demonstrate the effectiveness of our model in the domain
of phonotactics, the rules governing what kinds of sound-sequences are
acceptable in a language, and carry out two experiments, one with
typologically-natural linguistic data and another with a range of
procedurally-generated languages. We find that the information-theoretic
policies that our model uses to select items to query the informant achieve
sample efficiency comparable to, and sometimes greater than, fully supervised
approaches.

摘要：我們提出一個互動式語言學習方法，利用線民（一位有能力的語言使用者）的語言可接受性判斷來學習文法。給定一個文法形式主義和一個用於合成資料的架構，我們的模型會根據一系列資訊理論政策反覆選擇或合成一個資料點，詢問線民一個二元判斷，並更新自己的參數以準備下一個查詢。我們在音位論領域展示了我們模型的有效性，音位論是管理語言中哪些音序序列可被接受的規則，並進行了兩個實驗，一個使用類型學上自然語言資料，另一個使用一系列程序生成的語言。我們發現我們的模型用於選擇項目以查詢線民的資訊理論政策達到了與完全監督方法相當，有時甚至更高的取樣效率。

##### **Physics-based deep learning reveals rising heating demand heightens air pollution in Norwegian cities**
2405.04716v1 by Cong Cao, Ramit Debnath, R. Michael Alvarez

Policymakers frequently analyze air quality and climate change in isolation,
disregarding their interactions. This study explores the influence of specific
climate factors on air quality by contrasting a regression model with K-Means
Clustering, Hierarchical Clustering, and Random Forest techniques. We employ
Physics-based Deep Learning (PBDL) and Long Short-Term Memory (LSTM) to examine
the air pollution predictions. Our analysis utilizes ten years (2009-2018) of
daily traffic, weather, and air pollution data from three major cities in
Norway. Findings from feature selection reveal a correlation between rising
heating degree days and heightened air pollution levels, suggesting increased
heating activities in Norway are a contributing factor to worsening air
quality. PBDL demonstrates superior accuracy in air pollution predictions
compared to LSTM. This paper contributes to the growing literature on PBDL
methods for more accurate air pollution predictions using environmental
variables, aiding policymakers in formulating effective data-driven climate
policies.

摘要：政策制定者經常獨立分析空氣品質和氣候變遷，忽視它們之間的交互作用。本研究透過對比回歸模型與 K 平均值分群、階層式分群和隨機森林技術，探討特定氣候因子對空氣品質的影響。我們採用基於物理學深度學習 (PBDL) 和長短期記憶 (LSTM) 來檢驗空氣污染預測。我們的分析利用挪威三個主要城市的十年 (2009-2018) 每日常見交通、天氣和空氣污染資料。特徵選擇的發現顯示，暖氣度日上升與空氣污染程度升高之間存在相關性，這表示挪威的暖氣活動增加是空氣品質惡化的促成因素。與 LSTM 相比，PBDL 在空氣污染預測中展現出更高的準確度。本文有助於發展有關使用環境變數進行更準確空氣污染預測的 PBDL 方法的文獻，協助政策制定者制定有效的資料驅動氣候政策。

##### **Robust Implementation of Retrieval-Augmented Generation on Edge-based Computing-in-Memory Architectures**
2405.04700v1 by Ruiyang Qin, Zheyu Yan, Dewen Zeng, Zhenge Jia, Dancheng Liu, Jianbo Liu, Zhi Zheng, Ningyuan Cao, Kai Ni, Jinjun Xiong, Yiyu Shi

Large Language Models (LLMs) deployed on edge devices learn through
fine-tuning and updating a certain portion of their parameters. Although such
learning methods can be optimized to reduce resource utilization, the overall
required resources remain a heavy burden on edge devices. Instead,
Retrieval-Augmented Generation (RAG), a resource-efficient LLM learning method,
can improve the quality of the LLM-generated content without updating model
parameters. However, the RAG-based LLM may involve repetitive searches on the
profile data in every user-LLM interaction. This search can lead to significant
latency along with the accumulation of user data. Conventional efforts to
decrease latency result in restricting the size of saved user data, thus
reducing the scalability of RAG as user data continuously grows. It remains an
open question: how to free RAG from the constraints of latency and scalability
on edge devices? In this paper, we propose a novel framework to accelerate RAG
via Computing-in-Memory (CiM) architectures. It accelerates matrix
multiplications by performing in-situ computation inside the memory while
avoiding the expensive data transfer between the computing unit and memory. Our
framework, Robust CiM-backed RAG (RoCR), utilizing a novel contrastive
learning-based training method and noise-aware training, can enable RAG to
efficiently search profile data with CiM. To the best of our knowledge, this is
the first work utilizing CiM to accelerate RAG.

摘要：大型語言模型 (LLM) 部署在邊緣設備上，透過微調和更新特定參數來學習。儘管這種學習方法可以最佳化以減少資源利用，但整體所需的資源對邊緣設備而言仍然是很重的負擔。取而代之的是，檢索增強式生成 (RAG) 是一種資源效率高的 LLM 學習方法，可以在不更新模型參數的情況下提升 LLM 生成的內容品質。然而，基於 RAG 的 LLM 可能涉及在每次使用者-LLM 互動中重複搜尋個人資料。這種搜尋會導致顯著的延遲，以及使用者資料的累積。降低延遲的傳統方法會限制儲存的使用者資料大小，因此會降低 RAG 的可擴充性，因為使用者資料會持續增加。如何讓 RAG 擺脫邊緣設備上延遲和可擴充性的限制？這仍然是一個開放的問題。在本文中，我們提出一個新的架構，透過記憶體運算 (CiM) 架構來加速 RAG。它透過在記憶體內執行原地運算來加速矩陣乘法，同時避免在運算單元和記憶體之間進行昂貴的資料傳輸。我們的架構，強健的 CiM 支援 RAG (RoCR)，利用一種新的對比學習訓練方法和感知雜訊的訓練，可以讓 RAG 使用 CiM 有效搜尋個人資料。據我們所知，這是第一個利用 CiM 來加速 RAG 的作品。

##### **Bridging the Bosphorus: Advancing Turkish Large Language Models through Strategies for Low-Resource Language Adaptation and Benchmarking**
2405.04685v1 by Emre Can Acikgoz, Mete Erdogan, Deniz Yuret

Large Language Models (LLMs) are becoming crucial across various fields,
emphasizing the urgency for high-quality models in underrepresented languages.
This study explores the unique challenges faced by low-resource languages, such
as data scarcity, model selection, evaluation, and computational limitations,
with a special focus on Turkish. We conduct an in-depth analysis to evaluate
the impact of training strategies, model choices, and data availability on the
performance of LLMs designed for underrepresented languages. Our approach
includes two methodologies: (i) adapting existing LLMs originally pretrained in
English to understand Turkish, and (ii) developing a model from the ground up
using Turkish pretraining data, both supplemented with supervised fine-tuning
on a novel Turkish instruction-tuning dataset aimed at enhancing reasoning
capabilities. The relative performance of these methods is evaluated through
the creation of a new leaderboard for Turkish LLMs, featuring benchmarks that
assess different reasoning and knowledge skills. Furthermore, we conducted
experiments on data and model scaling, both during pretraining and fine-tuning,
simultaneously emphasizing the capacity for knowledge transfer across languages
and addressing the challenges of catastrophic forgetting encountered during
fine-tuning on a different language. Our goal is to offer a detailed guide for
advancing the LLM framework in low-resource linguistic contexts, thereby making
natural language processing (NLP) benefits more globally accessible.

摘要：大型語言模型 (LLM) 在各個領域正變得至關重要，強調了對低代表性語言中高品質模型的迫切需求。本研究探討低資源語言所面臨的獨特挑戰，例如資料稀少、模型選擇、評估和計算限制，特別關注土耳其語。我們進行深入分析，評估訓練策略、模型選擇和資料可用性對專為低代表性語言設計的 LLM 效能的影響。我們的做法包括兩種方法：(i) 調整原先以英語預訓練的現有 LLM 以理解土耳其語，以及 (ii) 使用土耳其語預訓練資料從頭開始開發模型，這兩種方法都補充了在新的土耳其語指令調整資料集上進行的監督微調，旨在增強推理能力。這些方法的相對效能是透過建立一個新的土耳其語 LLM 排行榜來評估，其中包括評估不同推理和知識技能的基準。此外，我們對資料和模型擴充進行了實驗，包括在預訓練和微調期間，同時強調跨語言知識轉移的能力，並解決在不同語言上進行微調時遇到的災難性遺忘挑戰。我們的目標是提供一份詳細指南，以在低資源語言環境中推進 LLM 架構，從而讓自然語言處理 (NLP) 的好處更具全球可及性。

##### **TALC: Time-Aligned Captions for Multi-Scene Text-to-Video Generation**
2405.04682v1 by Hritik Bansal, Yonatan Bitton, Michal Yarom, Idan Szpektor, Aditya Grover, Kai-Wei Chang

Recent advances in diffusion-based generative modeling have led to the
development of text-to-video (T2V) models that can generate high-quality videos
conditioned on a text prompt. Most of these T2V models often produce
single-scene video clips that depict an entity performing a particular action
(e.g., `a red panda climbing a tree'). However, it is pertinent to generate
multi-scene videos since they are ubiquitous in the real-world (e.g., `a red
panda climbing a tree' followed by `the red panda sleeps on the top of the
tree'). To generate multi-scene videos from the pretrained T2V model, we
introduce Time-Aligned Captions (TALC) framework. Specifically, we enhance the
text-conditioning mechanism in the T2V architecture to recognize the temporal
alignment between the video scenes and scene descriptions. For instance, we
condition the visual features of the earlier and later scenes of the generated
video with the representations of the first scene description (e.g., `a red
panda climbing a tree') and second scene description (e.g., `the red panda
sleeps on the top of the tree'), respectively. As a result, we show that the
T2V model can generate multi-scene videos that adhere to the multi-scene text
descriptions and be visually consistent (e.g., entity and background). Further,
we finetune the pretrained T2V model with multi-scene video-text data using the
TALC framework. We show that the TALC-finetuned model outperforms the baseline
methods by 15.5 points in the overall score, which averages visual consistency
and text adherence using human evaluation. The project website is
https://talc-mst2v.github.io/.

摘要：<paragraph>最近在基于扩散的生成式建模方面的进展已导致开发出文本到视频 (T2V) 模型，该模型可根据文本提示生成高质量视频。这些 T2V 模型中的大多数通常会生成描绘实体执行特定动作的单场景视频片段（例如，“一只红熊猫爬树”）。然而，生成多场景视频是相关的，因为它们在现实世界中无处不在（例如，“一只红熊猫爬树”，然后“红熊猫睡在树顶”）。为了从预训练的 T2V 模型生成多场景视频，我们引入了时间对齐字幕 (TALC) 框架。具体来说，我们增强了 T2V 架构中的文本调节机制，以识别视频场景和场景描述之间的时态对齐。例如，我们使用第一个场景描述（例如，“一只红熊猫爬树”）和第二个场景描述（例如，“红熊猫睡在树顶”）的表示，分别调节生成视频的早期和后期场景的可视化特征。因此，我们表明 T2V 模型可以生成符合多场景文本描述且在视觉上保持一致（例如，实体和背景）的多场景视频。此外，我们使用 TALC 框架使用多场景视频文本数据对预训练的 T2V 模型进行微调。我们表明，TALC 微调模型在总体得分上比基线方法高出 15.5 分，该得分使用人类评估对视觉一致性和文本依从性进行平均。项目网站是 https://talc-mst2v.github.io/。</paragraph>

##### **Understanding the Capabilities and Limitations of Large Language Models for Cultural Commonsense**
2405.04655v1 by Siqi Shen, Lajanugen Logeswaran, Moontae Lee, Honglak Lee, Soujanya Poria, Rada Mihalcea

Large language models (LLMs) have demonstrated substantial commonsense
understanding through numerous benchmark evaluations. However, their
understanding of cultural commonsense remains largely unexamined. In this
paper, we conduct a comprehensive examination of the capabilities and
limitations of several state-of-the-art LLMs in the context of cultural
commonsense tasks. Using several general and cultural commonsense benchmarks,
we find that (1) LLMs have a significant discrepancy in performance when tested
on culture-specific commonsense knowledge for different cultures; (2) LLMs'
general commonsense capability is affected by cultural context; and (3) The
language used to query the LLMs can impact their performance on
cultural-related tasks. Our study points to the inherent bias in the cultural
understanding of LLMs and provides insights that can help develop culturally
aware language models.

摘要：大型語言模型 (LLM) 已通過大量的基準評估證明了其顯著的常識理解能力。然而，它們對文化常識的理解在很大程度上仍未得到檢驗。在本文中，我們對幾個最先進的 LLM 在文化常識任務中的能力和局限性進行了全面檢驗。使用幾個一般和文化常識基準，我們發現 (1) 當針對不同文化的特定文化常識知識進行測試時，LLM 的性能存在顯著差異；(2) LLM 的一般常識能力受文化背景的影響；以及 (3) 用於查詢 LLM 的語言會影響其在與文化相關任務上的性能。我們的研究指出了 LLM 在文化理解中的固有偏差，並提供了可以幫助開發具有文化意識的語言模型的見解。

##### **ResNCT: A Deep Learning Model for the Synthesis of Nephrographic Phase Images in CT Urography**
2405.04629v1 by Syed Jamal Safdar Gardezi, Lucas Aronson, Peter Wawrzyn, Hongkun Yu, E. Jason Abel, Daniel D. Shapiro, Meghan G. Lubner, Joshua Warner, Giuseppe Toia, Lu Mao, Pallavi Tiwari, Andrew L. Wentland

Purpose: To develop and evaluate a transformer-based deep learning model for
the synthesis of nephrographic phase images in CT urography (CTU) examinations
from the unenhanced and urographic phases.
  Materials and Methods: This retrospective study was approved by the local
Institutional Review Board. A dataset of 119 patients (mean $\pm$ SD age, 65
$\pm$ 12 years; 75/44 males/females) with three-phase CT urography studies was
curated for deep learning model development. The three phases for each patient
were aligned with an affine registration algorithm. A custom model, coined
Residual transformer model for Nephrographic phase CT image synthesis (ResNCT),
was developed and implemented with paired inputs of non-contrast and urographic
sets of images trained to produce the nephrographic phase images, that were
compared with the corresponding ground truth nephrographic phase images. The
synthesized images were evaluated with multiple performance metrics, including
peak signal to noise ratio (PSNR), structural similarity index (SSIM),
normalized cross correlation coefficient (NCC), mean absolute error (MAE), and
root mean squared error (RMSE).
  Results: The ResNCT model successfully generated synthetic nephrographic
images from non-contrast and urographic image inputs. With respect to ground
truth nephrographic phase images, the images synthesized by the model achieved
high PSNR (27.8 $\pm$ 2.7 dB), SSIM (0.88 $\pm$ 0.05), and NCC (0.98 $\pm$
0.02), and low MAE (0.02 $\pm$ 0.005) and RMSE (0.042 $\pm$ 0.016).
  Conclusion: The ResNCT model synthesized nephrographic phase CT images with
high similarity to ground truth images. The ResNCT model provides a means of
eliminating the acquisition of the nephrographic phase with a resultant 33%
reduction in radiation dose for CTU examinations.

摘要：<paragraph>目的：開發並評估基於 Transformer 的深度學習模型，用於從未增強和尿路造影期中合成 CT 尿路造影 (CTU) 檢查的腎造影期影像。
材料和方法：這項回顧性研究已獲得當地機構審查委員會核准。整理了一個包含 119 位患者（平均年齡 $\pm$ 標準差，65 $\pm$ 12 歲；75/44 位男性/女性）的三期 CT 尿路造影研究資料集，以進行深度學習模型開發。每位患者的三個期別使用仿射配準演算法對齊。開發並實作了一個自訂模型，稱為腎造影期 CT 影像合成的殘差 Transformer 模型 (ResNCT)，並使用非對比和尿路造影影像組的配對輸入進行訓練，以產生腎造影期影像，並與對應的真實腎造影期影像進行比較。使用多項效能指標評估合成的影像，包括峰值信號雜訊比 (PSNR)、結構相似性指標 (SSIM)、歸一化互相關係係數 (NCC)、平均絕對誤差 (MAE) 和均方根誤差 (RMSE)。
結果：ResNCT 模型成功地從非對比和尿路造影影像輸入中生成了合成腎造影影像。相對於真實腎造影期影像，模型合成的影像達到了較高的 PSNR (27.8 $\pm$ 2.7 dB)、SSIM (0.88 $\pm$ 0.05) 和 NCC (0.98 $\pm$ 0.02)，以及較低的 MAE (0.02 $\pm$ 0.005) 和 RMSE (0.042 $\pm$ 0.016)。
結論：ResNCT 模型合成了與真實影像高度相似的腎造影期 CT 影像。ResNCT 模型提供了一種消除腎造影期擷取的方法，從而使 CTU 檢查的輻射劑量減少了 33%。</paragraph>

##### **AI in Lung Health: Benchmarking Detection and Diagnostic Models Across Multiple CT Scan Datasets**
2405.04605v1 by Fakrul Islam Tushar, Avivah Wang, Lavsen Dahal, Michael R. Harowicz, Kyle J. Lafata, Tina D. Tailor, Joseph Y. Lo

BACKGROUND: Lung cancer's high mortality rate can be mitigated by early
detection, which is increasingly reliant on artificial intelligence (AI) for
diagnostic imaging. However, the performance of AI models is contingent upon
the datasets used for their training and validation. METHODS: This study
developed and validated the DLCSD-mD and LUNA16-mD models utilizing the Duke
Lung Cancer Screening Dataset (DLCSD), encompassing over 2,000 CT scans with
more than 3,000 annotations. These models were rigorously evaluated against the
internal DLCSD and external LUNA16 and NLST datasets, aiming to establish a
benchmark for imaging-based performance. The assessment focused on creating a
standardized evaluation framework to facilitate consistent comparison with
widely utilized datasets, ensuring a comprehensive validation of the model's
efficacy. Diagnostic accuracy was assessed using free-response receiver
operating characteristic (FROC) and area under the curve (AUC) analyses.
RESULTS: On the internal DLCSD set, the DLCSD-mD model achieved an AUC of 0.93
(95% CI:0.91-0.94), demonstrating high accuracy. Its performance was sustained
on the external datasets, with AUCs of 0.97 (95% CI: 0.96-0.98) on LUNA16 and
0.75 (95% CI: 0.73-0.76) on NLST. Similarly, the LUNA16-mD model recorded an
AUC of 0.96 (95% CI: 0.95-0.97) on its native dataset and showed transferable
diagnostic performance with AUCs of 0.91 (95% CI: 0.89-0.93) on DLCSD and 0.71
(95% CI: 0.70-0.72) on NLST. CONCLUSION: The DLCSD-mD model exhibits reliable
performance across different datasets, establishing the DLCSD as a robust
benchmark for lung cancer detection and diagnosis. Through the provision of our
models and code to the public domain, we aim to accelerate the development of
AI-based diagnostic tools and encourage reproducibility and collaborative
advancements within the medical machine-learning (ML) field.

摘要：<paragraph>背景：肺癌的高死亡率可以通过早期检测来降低，而早期检测越来越依赖于用于诊断成像的人工智能 (AI)。然而，AI 模型的性能取决于用于训练和验证的数据集。方法：本研究利用杜克肺癌筛查数据集 (DLCSD) 开发并验证了 DLCSD-mD 和 LUNA16-mD 模型，该数据集包含 2,000 多个 CT 扫描和 3,000 多个注释。这些模型针对内部 DLCSD 和外部 LUNA16 和 NLST 数据集进行了严格评估，旨在为基于成像的性能建立基准。评估重点在于创建标准化评估框架，以促进与广泛使用的数据集进行一致的比较，确保对模型功效进行全面验证。诊断准确性使用自由响应接收器操作特性 (FROC) 和曲线下面积 (AUC) 分析进行评估。结果：在内部 DLCSD 数据集上，DLCSD-mD 模型的 AUC 为 0.93 (95% CI：0.91-0.94)，显示出很高的准确性。在外部数据集上，其性能保持稳定，在 LUNA16 上的 AUC 为 0.97 (95% CI：0.96-0.98)，在 NLST 上的 AUC 为 0.75 (95% CI：0.73-0.76)。类似地，LUNA16-mD 模型在其本机数据集上的 AUC 为 0.96 (95% CI：0.95-0.97)，并且在 DLCSD 上的 AUC 为 0.91 (95% CI：0.89-0.93)，在 NLST 上的 AUC 为 0.71 (95% CI：0.70-0.72)，显示出可转移的诊断性能。结论：DLCSD-mD 模型在不同数据集上表现出可靠的性能，将 DLCSD 确立为肺癌检测和诊断的稳健基准。通过向公共领域提供我们的模型和代码，我们旨在加速基于 AI 的诊断工具的开发，并鼓励医学机器学习 (ML) 领域的再现性和协作进步。</paragraph>

##### **Language Modeling Using Tensor Trains**
2405.04590v1 by Zhan Su, Yuqin Zhou, Fengran Mo, Jakob Grue Simonsen

We propose a novel tensor network language model based on the simplest tensor
network (i.e., tensor trains), called `Tensor Train Language Model' (TTLM).
TTLM represents sentences in an exponential space constructed by the tensor
product of words, but computing the probabilities of sentences in a
low-dimensional fashion. We demonstrate that the architectures of Second-order
RNNs, Recurrent Arithmetic Circuits (RACs), and Multiplicative Integration RNNs
are, essentially, special cases of TTLM. Experimental evaluations on real
language modeling tasks show that the proposed variants of TTLM (i.e.,
TTLM-Large and TTLM-Tiny) outperform the vanilla Recurrent Neural Networks
(RNNs) with low-scale of hidden units. (The code is available at
https://github.com/shuishen112/tensortrainlm.)

摘要：我們提出一個基於最簡單張量網路（即張量列車）的新型張量網路語言模型，稱為「張量列車語言模型」（TTLM）。
TTLM 在由詞彙張量積構建的指數空間中表示句子，但以低維方式計算句子的機率。我們證明了二階遞迴神經網路、遞迴算術電路（RAC）和乘法積分遞迴神經網路的架構基本上是 TTLM 的特例。在真實語言建模任務上的實驗評估顯示，TTLM 的提議變體（即 TTLM-Large 和 TTLM-Tiny）優於具有低規模隱藏單元的香草遞迴神經網路（RNN）。（程式碼可在 https://github.com/shuishen112/tensortrainlm 取得。）

##### **QServe: W4A8KV4 Quantization and System Co-design for Efficient LLM Serving**
2405.04532v1 by Yujun Lin, Haotian Tang, Shang Yang, Zhekai Zhang, Guangxuan Xiao, Chuang Gan, Song Han

Quantization can accelerate large language model (LLM) inference. Going
beyond INT8 quantization, the research community is actively exploring even
lower precision, such as INT4. Nonetheless, state-of-the-art INT4 quantization
techniques only accelerate low-batch, edge LLM inference, failing to deliver
performance gains in large-batch, cloud-based LLM serving. We uncover a
critical issue: existing INT4 quantization methods suffer from significant
runtime overhead (20-90%) when dequantizing either weights or partial sums on
GPUs. To address this challenge, we introduce QoQ, a W4A8KV4 quantization
algorithm with 4-bit weight, 8-bit activation, and 4-bit KV cache. QoQ stands
for quattuor-octo-quattuor, which represents 4-8-4 in Latin. QoQ is implemented
by the QServe inference library that achieves measured speedup. The key insight
driving QServe is that the efficiency of LLM serving on GPUs is critically
influenced by operations on low-throughput CUDA cores. Building upon this
insight, in QoQ algorithm, we introduce progressive quantization that can allow
low dequantization overhead in W4A8 GEMM. Additionally, we develop
SmoothAttention to effectively mitigate the accuracy degradation incurred by
4-bit KV quantization. In the QServe system, we perform compute-aware weight
reordering and take advantage of register-level parallelism to reduce
dequantization latency. We also make fused attention memory-bound, harnessing
the performance gain brought by KV4 quantization. As a result, QServe improves
the maximum achievable serving throughput of Llama-3-8B by 1.2x on A100, 1.4x
on L40S; and Qwen1.5-72B by 2.4x on A100, 3.5x on L40S, compared to
TensorRT-LLM. Remarkably, QServe on L40S GPU can achieve even higher throughput
than TensorRT-LLM on A100. Thus, QServe effectively reduces the dollar cost of
LLM serving by 3x. Code is available at https://github.com/mit-han-lab/qserve.

摘要：量化可以加速大型语言模型 (LLM) 推论。超越 INT8 量化，研究界正在积极探索更低精度，例如 INT4。尽管如此，最先进的 INT4 量化技术仅加速小批量边缘 LLM 推论，无法在大批量基于云的 LLM 服务中提供性能提升。我们发现了一个关键问题：现有的 INT4 量化方法在 GPU 上对权重或部分和进行去量化时会产生大量的运行时开销 (20-90%)。为了应对这一挑战，我们引入了 QoQ，一种具有 4 位权重、8 位激活和 4 位 KV 缓存的 W4A8KV4 量化算法。QoQ 代表 quattuor-octo-quattuor，在拉丁语中表示 4-8-4。QoQ 由 QServe 推论库实现，该库实现了已测量的加速。推动 QServe 的关键见解是，GPU 上的 LLM 服务的效率受到低吞吐量 CUDA 核心上的操作的严重影响。基于此见解，在 QoQ 算法中，我们引入了渐进式量化，可以在 W4A8 GEMM 中允许较低的去量化开销。此外，我们开发了 SmoothAttention 以有效减轻 4 位 KV 量化带来的精度下降。在 QServe 系统中，我们执行计算感知权重重新排序并利用寄存器级并行性来减少去量化延迟。我们还使融合注意内存受限，利用 KV4 量化带来的性能提升。结果，QServe 将 Llama-3-8B 的最大可实现服务吞吐量提高了 1.2 倍（A100 上），1.4 倍（L40S 上）；与 TensorRT-LLM 相比，Qwen1.5-72B 在 A100 上提高了 2.4 倍，在 L40S 上提高了 3.5 倍。值得注意的是，L40S GPU 上的 QServe 甚至可以实现比 A100 上的 TensorRT-LLM 更高的吞吐量。因此，QServe 有效地将 LLM 服务的美元成本降低了 3 倍。代码可在 https://github.com/mit-han-lab/qserve 获得。

##### **NaturalCodeBench: Examining Coding Performance Mismatch on HumanEval and Natural User Prompts**
2405.04520v1 by Shudan Zhang, Hanlin Zhao, Xiao Liu, Qinkai Zheng, Zehan Qi, Xiaotao Gu, Xiaohan Zhang, Yuxiao Dong, Jie Tang

Large language models (LLMs) have manifested strong ability to generate codes
for productive activities. However, current benchmarks for code synthesis, such
as HumanEval, MBPP, and DS-1000, are predominantly oriented towards
introductory tasks on algorithm and data science, insufficiently satisfying
challenging requirements prevalent in real-world coding. To fill this gap, we
propose NaturalCodeBench (NCB), a challenging code benchmark designed to mirror
the complexity and variety of scenarios in real coding tasks. NCB comprises 402
high-quality problems in Python and Java, meticulously selected from natural
user queries from online coding services, covering 6 different domains. Noting
the extraordinary difficulty in creating testing cases for real-world queries,
we also introduce a semi-automated pipeline to enhance the efficiency of test
case construction. Comparing with manual solutions, it achieves an efficiency
increase of more than 4 times. Our systematic experiments on 39 LLMs find that
performance gaps on NCB between models with close HumanEval scores could still
be significant, indicating a lack of focus on practical code synthesis
scenarios or over-specified optimization on HumanEval. On the other hand, even
the best-performing GPT-4 is still far from satisfying on NCB. The evaluation
toolkit and development set are available at
https://github.com/THUDM/NaturalCodeBench.

摘要：大型語言模型 (LLM) 已展現出產生代碼以進行生產活動的強大能力。然而，目前的程式碼合成基準，例如 HumanEval、MBPP 和 DS-1000，主要針對演算法和資料科學的入門任務，無法充分滿足現實世界編碼中普遍存在的挑戰性需求。為了填補這個空白，我們提出 NaturalCodeBench (NCB)，一個具有挑戰性的程式碼基準，旨在反映真實編碼任務中各種場景的複雜性和多樣性。NCB 包含 402 個高品質的 Python 和 Java 問題，從線上編碼服務的自然使用者查詢中仔細挑選，涵蓋 6 個不同的領域。注意到為現實世界的查詢建立測試案例的難度極高，我們還引入了一個半自動化管道來提高測試案例建構的效率。與手動解決方案相比，它的效率提升了 4 倍以上。我們對 39 個 LLM 進行的系統性實驗發現，在 HumanEval 得分接近的模型之間，NCB 上的效能差距仍然可能很大，這表示缺乏對實際程式碼合成場景的關注或對 HumanEval 的過度特定最佳化。另一方面，即使效能最佳的 GPT-4 在 NCB 上仍遠未令人滿意。評估工具包和開發組可以在 https://github.com/THUDM/NaturalCodeBench 取得。

##### **xLSTM: Extended Long Short-Term Memory**
2405.04517v1 by Maximilian Beck, Korbinian Pöppel, Markus Spanring, Andreas Auer, Oleksandra Prudnikova, Michael Kopp, Günter Klambauer, Johannes Brandstetter, Sepp Hochreiter

In the 1990s, the constant error carousel and gating were introduced as the
central ideas of the Long Short-Term Memory (LSTM). Since then, LSTMs have
stood the test of time and contributed to numerous deep learning success
stories, in particular they constituted the first Large Language Models (LLMs).
However, the advent of the Transformer technology with parallelizable
self-attention at its core marked the dawn of a new era, outpacing LSTMs at
scale. We now raise a simple question: How far do we get in language modeling
when scaling LSTMs to billions of parameters, leveraging the latest techniques
from modern LLMs, but mitigating known limitations of LSTMs? Firstly, we
introduce exponential gating with appropriate normalization and stabilization
techniques. Secondly, we modify the LSTM memory structure, obtaining: (i) sLSTM
with a scalar memory, a scalar update, and new memory mixing, (ii) mLSTM that
is fully parallelizable with a matrix memory and a covariance update rule.
Integrating these LSTM extensions into residual block backbones yields xLSTM
blocks that are then residually stacked into xLSTM architectures. Exponential
gating and modified memory structures boost xLSTM capabilities to perform
favorably when compared to state-of-the-art Transformers and State Space
Models, both in performance and scaling.

摘要：在 1990 年代，恆定錯誤迴旋木馬和閘控被引入為長期短期記憶 (LSTM) 的核心概念。從那時起，LSTM 經受住了時間的考驗，並為許多深度學習的成功案例做出了貢獻，特別是它們構成了第一批大型語言模型 (LLM)。然而，以可並行化自注意力為核心的 Transformer 技術的出現標誌著一個新時代的到來，其規模超過了 LSTM。我們現在提出一個簡單的問題：當我們將 LSTM 擴展到數十億個參數、利用現代 LLM 的最新技術，但減輕 LSTM 的已知限制時，我們在語言建模中能走多遠？首先，我們引入具有適當正規化和穩定技術的指數閘控。其次，我們修改 LSTM 記憶結構，獲得：(i) 帶有標量記憶體、標量更新和新記憶體混合的 sLSTM，(ii) mLSTM，它使用矩陣記憶體和協方差更新規則完全可並行化。將這些 LSTM 擴充整合到殘差塊主幹中會產生 xLSTM 塊，然後將它們殘差堆疊到 xLSTM 架構中。與最先進的 Transformer 和狀態空間模型相比，指數閘控和修改的記憶體結構提升了 xLSTM 的能力，在效能和擴充性方面表現出色。

##### **A Transformer with Stack Attention**
2405.04515v1 by Jiaoda Li, Jennifer C. White, Mrinmaya Sachan, Ryan Cotterell

Natural languages are believed to be (mildly) context-sensitive. Despite
underpinning remarkably capable large language models, transformers are unable
to model many context-free language tasks. In an attempt to address this
limitation in the modeling power of transformer-based language models, we
propose augmenting them with a differentiable, stack-based attention mechanism.
Our stack-based attention mechanism can be incorporated into any
transformer-based language model and adds a level of interpretability to the
model. We show that the addition of our stack-based attention mechanism enables
the transformer to model some, but not all, deterministic context-free
languages.

摘要：自然語言被認為是（輕微地）上下文相關的。儘管支撐著非常有能力的大型語言模型，但Transformer無法模擬許多無上下文語言任務。為了解決Transformer語言模型建模能力中的這個限制，我們建議使用可微分堆疊式注意力機制對它們進行擴充。我們的堆疊式注意力機制可以整合到任何基於Transformer的語言模型中，並為模型增加一層可解釋性。我們展示了加入我們的堆疊式注意力機制使Transformer能夠模擬一些，但不是全部，確定性的無上下文語言。

##### **Switchable Decision: Dynamic Neural Generation Networks**
2405.04513v1 by Shujian Zhang, Korawat Tanwisuth, Chengyue Gong, Pengcheng He, Mingyuan Zhou

Auto-regressive generation models achieve competitive performance across many
different NLP tasks such as summarization, question answering, and
classifications. However, they are also known for being slow in inference,
which makes them challenging to deploy in real-time applications. We propose a
switchable decision to accelerate inference by dynamically assigning
computation resources for each data instance. Automatically making decisions on
where to skip and how to balance quality and computation cost with constrained
optimization, our dynamic neural generation networks enforce the efficient
inference path and determine the optimized trade-off. Experiments across
question answering, summarization, and classification benchmarks show that our
method benefits from less computation cost during inference while keeping the
same accuracy. Extensive experiments and ablation studies demonstrate that our
method can be general, effective, and beneficial for many NLP tasks.

摘要：自動回歸生成模型在許多不同的 NLP 任務中實現了競爭效能，例如摘要、問答和分類。然而，它們也以推理緩慢而聞名，這使得它們難以部署在即時應用程式中。我們提出了一個可切換的決策，透過動態分配每個資料實例的運算資源來加速推理。我們的動態神經生成網路自動做出決策，決定在哪裡跳過以及如何平衡品質和運算成本與受限最佳化，強制執行有效的推理路徑並確定最佳化的權衡。在問答、摘要和分類基準上的實驗顯示，我們的模型在推理期間受益於較低的運算成本，同時保持相同的準確度。廣泛的實驗和消融研究表明，我們的模型可以適用於許多 NLP 任務，並對其有效且有益。

##### **Toward In-Context Teaching: Adapting Examples to Students' Misconceptions**
2405.04495v1 by Alexis Ross, Jacob Andreas

When a teacher provides examples for a student to study, these examples must
be informative, enabling a student to progress from their current state toward
a target concept or skill. Good teachers must therefore simultaneously infer
what students already know and adapt their teaching to students' changing state
of knowledge. There is increasing interest in using computational models,
particularly large language models, as pedagogical tools. As students, language
models in particular have shown a remarkable ability to adapt to new tasks
given small numbers of examples. But how effectively can these models adapt as
teachers to students of different types? To study this question, we introduce a
suite of models and evaluation methods we call AdapT. AdapT has two components:
(1) a collection of simulated Bayesian student models that can be used for
evaluation of automated teaching methods; (2) a platform for evaluation with
human students, to characterize the real-world effectiveness of these methods.
We additionally introduce (3) AToM, a new probabilistic model for adaptive
teaching that jointly infers students' past beliefs and optimizes for the
correctness of future beliefs. In evaluations of simulated students across
three learning domains (fraction arithmetic, English morphology, function
learning), AToM systematically outperforms LLM-based and standard Bayesian
teaching models. In human experiments, both AToM and LLMs outperform
non-adaptive random example selection. Our results highlight both the
difficulty of the adaptive teaching task and the potential of learned adaptive
models for solving it.

摘要：當老師提供範例供學生學習時，這些範例必須提供資訊，讓學生能從目前的狀態進步到目標概念或技能。因此，好老師必須同時推論出學生已經知道什麼，並根據學生知識的變化調整教學。使用計算模型（尤其是大型語言模型）作為教學工具的興趣與日俱增。特別是作為學生的語言模型，已經展現出驚人的能力，可以在給予少量範例的情況下適應新任務。但這些模型作為老師，能多有效地適應不同類型的學生？為了研究這個問題，我們提出了一套模型和評量方法，我們稱之為 AdapT。AdapT 有兩個組成部分：(1) 一組模擬 Bayesian 學生模型，可用於評量自動化教學方法；(2) 一個與真人學生一起評量的平台，用於描述這些方法的實際世界效能。我們另外提出 (3) AToM，一個新的機率模型，用於適應性教學，它會同時推論學生的過去信念，並針對未來信念的正確性進行最佳化。在三個學習領域（分數算術、英文形態學、函數學習）的模擬學生評量中，AToM 系統性地優於基於 LLM 和標準 Bayesian 的教學模型。在人體實驗中，AToM 和 LLM 都優於非適應性隨機範例選擇。我們的結果突顯了適應性教學任務的難度，以及學習適應性模型在解決此任務上的潛力。

##### **TorchDriveEnv: A Reinforcement Learning Benchmark for Autonomous Driving with Reactive, Realistic, and Diverse Non-Playable Characters**
2405.04491v1 by Jonathan Wilder Lavington, Ke Zhang, Vasileios Lioutas, Matthew Niedoba, Yunpeng Liu, Dylan Green, Saeid Naderiparizi, Xiaoxuan Liang, Setareh Dabiri, Adam Ścibior, Berend Zwartsenberg, Frank Wood

The training, testing, and deployment, of autonomous vehicles requires
realistic and efficient simulators. Moreover, because of the high variability
between different problems presented in different autonomous systems, these
simulators need to be easy to use, and easy to modify. To address these
problems we introduce TorchDriveSim and its benchmark extension TorchDriveEnv.
TorchDriveEnv is a lightweight reinforcement learning benchmark programmed
entirely in Python, which can be modified to test a number of different factors
in learned vehicle behavior, including the effect of varying kinematic models,
agent types, and traffic control patterns. Most importantly unlike many replay
based simulation approaches, TorchDriveEnv is fully integrated with a state of
the art behavioral simulation API. This allows users to train and evaluate
driving models alongside data driven Non-Playable Characters (NPC) whose
initializations and driving behavior are reactive, realistic, and diverse. We
illustrate the efficiency and simplicity of TorchDriveEnv by evaluating common
reinforcement learning baselines in both training and validation environments.
Our experiments show that TorchDriveEnv is easy to use, but difficult to solve.

摘要：自動駕駛車輛的訓練、測試和部署需要逼真且高效的模擬器。此外，由於不同自動系統中出現的不同問題之間存在高度可變性，因此這些模擬器需要易於使用且易於修改。為了解決這些問題，我們引入了 TorchDriveSim 及其基準延伸 TorchDriveEnv。TorchDriveEnv 是一個輕量級強化學習基準，完全使用 Python 編寫，可以修改以測試學習車輛行為中的許多不同因素，包括不同運動模型、代理類型和交通控制模式的影響。最重要的是，與許多基於重播的模擬方法不同，TorchDriveEnv 與最先進的行為模擬 API 完全整合。這使用戶能夠訓練和評估駕駛模型，同時使用數據驅動的非玩家角色 (NPC)，其初始化和駕駛行為具有反應性、真實性和多樣性。我們通過在訓練和驗證環境中評估常見的強化學習基準，來說明 TorchDriveEnv 的效率和簡潔性。我們的實驗表明，TorchDriveEnv 易於使用，但難以解決。

##### **Towards Continual Knowledge Graph Embedding via Incremental Distillation**
2405.04453v1 by Jiajun Liu, Wenjun Ke, Peng Wang, Ziyu Shang, Jinhua Gao, Guozheng Li, Ke Ji, Yanhe Liu

Traditional knowledge graph embedding (KGE) methods typically require
preserving the entire knowledge graph (KG) with significant training costs when
new knowledge emerges. To address this issue, the continual knowledge graph
embedding (CKGE) task has been proposed to train the KGE model by learning
emerging knowledge efficiently while simultaneously preserving decent old
knowledge. However, the explicit graph structure in KGs, which is critical for
the above goal, has been heavily ignored by existing CKGE methods. On the one
hand, existing methods usually learn new triples in a random order, destroying
the inner structure of new KGs. On the other hand, old triples are preserved
with equal priority, failing to alleviate catastrophic forgetting effectively.
In this paper, we propose a competitive method for CKGE based on incremental
distillation (IncDE), which considers the full use of the explicit graph
structure in KGs. First, to optimize the learning order, we introduce a
hierarchical strategy, ranking new triples for layer-by-layer learning. By
employing the inter- and intra-hierarchical orders together, new triples are
grouped into layers based on the graph structure features. Secondly, to
preserve the old knowledge effectively, we devise a novel incremental
distillation mechanism, which facilitates the seamless transfer of entity
representations from the previous layer to the next one, promoting old
knowledge preservation. Finally, we adopt a two-stage training paradigm to
avoid the over-corruption of old knowledge influenced by under-trained new
knowledge. Experimental results demonstrate the superiority of IncDE over
state-of-the-art baselines. Notably, the incremental distillation mechanism
contributes to improvements of 0.2%-6.5% in the mean reciprocal rank (MRR)
score.

摘要：<paragraph>傳統知識圖表嵌入 (KGE) 方法通常需要在出現新知識時保留整個知識圖表 (KG)，這會產生大量的訓練成本。為了解決這個問題，已經提出持續知識圖表嵌入 (CKGE) 任務，透過有效率地學習新興知識並同時保留良好的舊知識，來訓練 KGE 模型。然而，現有的 CKGE 方法嚴重忽略了 KG 中對上述目標至關重要的明確圖表結構。一方面，現有方法通常以隨機順序學習新的三元組，破壞了新 KG 的內部結構。另一方面，舊的三元組以同等的優先順序被保留，無法有效減輕災難性遺忘。在本文中，我們提出了一個基於增量蒸餾 (IncDE) 的 CKGE 競爭方法，它考慮了 KG 中明確圖表結構的充分利用。首先，為了優化學習順序，我們引入了一種分層策略，對新的三元組進行分層學習的排序。透過同時使用層間和層內順序，新的三元組會根據圖表結構特徵分組到不同的層中。其次，為了有效保留舊知識，我們設計了一種新的增量蒸餾機制，它促進了實體表示從前一層到下一層的無縫傳遞，促進了舊知識的保留。最後，我們採用兩階段訓練範例，以避免受訓練不足的新知識影響而導致舊知識過度損壞。實驗結果證明了 IncDE 優於最先進的基準。值得注意的是，增量蒸餾機制有助於平均倒數排名 (MRR) 分數提高 0.2%-6.5%。</paragraph>

##### **POV Learning: Individual Alignment of Multimodal Models using Human Perception**
2405.04443v1 by Simon Werner, Katharina Christ, Laura Bernardy, Marion G. Müller, Achim Rettinger

Aligning machine learning systems with human expectations is mostly attempted
by training with manually vetted human behavioral samples, typically explicit
feedback. This is done on a population level since the context that is
capturing the subjective Point-Of-View (POV) of a concrete person in a specific
situational context is not retained in the data. However, we argue that
alignment on an individual level can boost the subjective predictive
performance for the individual user interacting with the system considerably.
Since perception differs for each person, the same situation is observed
differently. Consequently, the basis for decision making and the subsequent
reasoning processes and observable reactions differ. We hypothesize that
individual perception patterns can be used for improving the alignment on an
individual level. We test this, by integrating perception information into
machine learning systems and measuring their predictive performance
wrt.~individual subjective assessments. For our empirical study, we collect a
novel data set of multimodal stimuli and corresponding eye tracking sequences
for the novel task of Perception-Guided Crossmodal Entailment and tackle it
with our Perception-Guided Multimodal Transformer. Our findings suggest that
exploiting individual perception signals for the machine learning of subjective
human assessments provides a valuable cue for individual alignment. It does not
only improve the overall predictive performance from the point-of-view of the
individual user but might also contribute to steering AI systems towards every
person's individual expectations and values.

摘要：機器學習系統與人類預期的對齊，大多數是透過手動審查人類行為範例進行訓練，通常是明確的回饋。這是在人口層級進行的，因為在資料中並未保留捕捉具體個人在特定情境脈絡中的主觀觀點 (POV) 的脈絡。然而，我們主張在個人層級上的對齊可以大幅提升與系統互動的個別使用者主觀預測效能。由於每個人的感知不同，因此觀察到相同的情況時會有不同的看法。因此，決策制定的基礎和後續的推理程序和可觀察到的反應也會有所不同。我們假設可以利用個別的感知模式來改善個人層級上的對齊。我們透過將感知資訊整合到機器學習系統中並衡量其相對於個別主觀評估的預測效能，來測試這一點。對於我們的實證研究，我們收集了一組新穎的多模態刺激和對應的眼睛追蹤序列資料，用於感知導向的跨模態蘊涵的新穎任務，並使用我們的感知導向多模態轉換器來處理它。我們的研究結果表明，利用個別感知訊號進行主觀人類評估的機器學習，可提供有價值的個人對齊線索。它不僅可以從個別使用者的觀點改善整體預測效能，還可能有助於引導 AI 系統朝向每個人的個別期望和價值觀。

##### **AugmenTory: A Fast and Flexible Polygon Augmentation Library**
2405.04442v1 by Tanaz Ghahremani, Mohammad Hoseyni, Mohammad Javad Ahmadi, Pouria Mehrabi, Amirhossein Nikoofard

Data augmentation is a key technique for addressing the challenge of limited
datasets, which have become a major component in the training procedures of
image processing. Techniques such as geometric transformations and color space
adjustments have been thoroughly tested for their ability to artificially
expand training datasets and generate semi-realistic data for training
purposes. Data augmentation is the most important key to addressing the
challenge of limited datasets, which have become a major component of image
processing training procedures. Data augmentation techniques, such as geometric
transformations and color space adjustments, are thoroughly tested for their
ability to artificially expand training datasets and generate semi-realistic
data for training purposes. Polygons play a crucial role in instance
segmentation and have seen a surge in use across advanced models, such as
YOLOv8. Despite their growing popularity, the lack of specialized libraries
hampers the polygon-augmentation process. This paper introduces a novel
solution to this challenge, embodied in the newly developed AugmenTory library.
Notably, AugmenTory offers reduced computational demands in both time and space
compared to existing methods. Additionally, the library includes a
postprocessing thresholding feature. The AugmenTory package is publicly
available on GitHub, where interested users can access the source code:
https://github.com/Smartory/AugmenTory

摘要：資料擴充是解決有限資料集挑戰的一項關鍵技術，這已成為影像處理訓練程序中的主要組成部分。幾何轉換和色彩空間調整等技術已徹底測試其人工擴充訓練資料集和產生半擬真資料以進行訓練目的的能力。資料擴充是解決有限資料集挑戰最重要的關鍵，這已成為影像處理訓練程序的主要組成部分。資料擴充技術，例如幾何轉換和色彩空間調整，已徹底測試其人工擴充訓練資料集和產生半擬真資料以進行訓練目的的能力。多邊形在實例分割中扮演至關重要的角色，並已在 YOLOv8 等進階模型中廣泛使用。儘管它們越來越受歡迎，但缺乏專門的函式庫會阻礙多邊形擴充程序。本文介紹了解決此挑戰的一項創新方案，體現在新開發的 AugmenTory 函式庫中。值得注意的是，與現有方法相比，AugmenTory 在時間和空間上都降低了運算需求。此外，該函式庫還包含後處理閾值功能。AugmenTory 套件已在 GitHub 上公開，有興趣的使用者可以在其中存取原始程式碼：
https://github.com/Smartory/AugmenTory

##### **DeepSeek-V2: A Strong, Economical, and Efficient Mixture-of-Experts Language Model**
2405.04434v2 by DeepSeek-AI

We present DeepSeek-V2, a strong Mixture-of-Experts (MoE) language model
characterized by economical training and efficient inference. It comprises 236B
total parameters, of which 21B are activated for each token, and supports a
context length of 128K tokens. DeepSeek-V2 adopts innovative architectures
including Multi-head Latent Attention (MLA) and DeepSeekMoE. MLA guarantees
efficient inference through significantly compressing the Key-Value (KV) cache
into a latent vector, while DeepSeekMoE enables training strong models at an
economical cost through sparse computation. Compared with DeepSeek 67B,
DeepSeek-V2 achieves significantly stronger performance, and meanwhile saves
42.5% of training costs, reduces the KV cache by 93.3%, and boosts the maximum
generation throughput to 5.76 times. We pretrain DeepSeek-V2 on a high-quality
and multi-source corpus consisting of 8.1T tokens, and further perform
Supervised Fine-Tuning (SFT) and Reinforcement Learning (RL) to fully unlock
its potential. Evaluation results show that, even with only 21B activated
parameters, DeepSeek-V2 and its chat versions still achieve top-tier
performance among open-source models.

摘要：我們提出 DeepSeek-V2，一種強大的 Mixture-of-Experts (MoE) 語言模型，特點是經濟訓練和高效推理。它包含 236B 個總參數，其中 21B 個會對每個符號啟用，並支援 128K 個符號的內容長度。DeepSeek-V2 採用創新的架構，包括多頭潛在注意力 (MLA) 和 DeepSeekMoE。MLA 透過大幅壓縮 Key-Value (KV) 快取到潛在向量中，保證高效推理，而 DeepSeekMoE 透過稀疏運算，以經濟成本訓練強大的模型。與 DeepSeek 67B 相比，DeepSeek-V2 達到顯著更強的效能，同時節省 42.5% 的訓練成本，將 KV 快取減少 93.3%，並將最大生成處理量提升至 5.76 倍。我們在包含 8.1T 個符號的高品質多來源語料庫上預訓練 DeepSeek-V2，並進一步執行監督微調 (SFT) 和強化學習 (RL) 以完全發揮其潛力。評估結果顯示，即使只有 21B 個已啟用的參數，DeepSeek-V2 及其聊天版本仍能在開源模型中達到頂級效能。

##### **The Silicone Ceiling: Auditing GPT's Race and Gender Biases in Hiring**
2405.04412v1 by Lena Armstrong, Abbey Liu, Stephen MacNeil, Danaë Metaxa

Large language models (LLMs) are increasingly being introduced in workplace
settings, with the goals of improving efficiency and fairness. However,
concerns have arisen regarding these models' potential to reflect or exacerbate
social biases and stereotypes. This study explores the potential impact of LLMs
on hiring practices. To do so, we conduct an algorithm audit of race and gender
biases in one commonly-used LLM, OpenAI's GPT-3.5, taking inspiration from the
history of traditional offline resume audits. We conduct two studies using
names with varied race and gender connotations: resume assessment (Study 1) and
resume generation (Study 2). In Study 1, we ask GPT to score resumes with 32
different names (4 names for each combination of the 2 gender and 4 racial
groups) and two anonymous options across 10 occupations and 3 evaluation tasks
(overall rating, willingness to interview, and hireability). We find that the
model reflects some biases based on stereotypes. In Study 2, we prompt GPT to
create resumes (10 for each name) for fictitious job candidates. When
generating resumes, GPT reveals underlying biases; women's resumes had
occupations with less experience, while Asian and Hispanic resumes had
immigrant markers, such as non-native English and non-U.S. education and work
experiences. Our findings contribute to a growing body of literature on LLM
biases, in particular when used in workplace contexts.

摘要：大型語言模型 (LLM) 愈來愈多地被導入工作場所，目標是提升效率和公平性。然而，對於這些模型反映或加劇社會偏見和刻板印象的潛力，已引起關注。本研究探討 LLM 對招聘實務的潛在影響。為此，我們對一個常用的 LLM，OpenAI 的 GPT-3.5，進行種族和性別偏見的演算法稽核，並從傳統的離線履歷稽核歷史中汲取靈感。我們使用具有不同種族和性別內涵的名字進行兩項研究：履歷評估（研究 1）和履歷產生（研究 2）。在研究 1 中，我們要求 GPT 為具有 32 個不同名字（2 個性別和 4 個種族群組的每個組合 4 個名字）和 10 個職業和 3 個評估任務（整體評分、願意面試和可聘用性）的履歷評分。我們發現該模型反映了一些基於刻板印象的偏見。在研究 2 中，我們提示 GPT 為虛構的求職者建立履歷（每個名字 10 個）。在產生履歷時，GPT 揭示了潛在的偏見；女性的履歷具有經驗較少的職業，而亞裔和西班牙裔的履歷則有移民標記，例如非母語英語和非美國教育和工作經驗。我們的研究結果有助於建立關於 LLM 偏見的文獻，特別是在工作場所環境中使用時。

##### **Vision Mamba: A Comprehensive Survey and Taxonomy**
2405.04404v1 by Xiao Liu, Chenxu Zhang, Lei Zhang

State Space Model (SSM) is a mathematical model used to describe and analyze
the behavior of dynamic systems. This model has witnessed numerous applications
in several fields, including control theory, signal processing, economics and
machine learning. In the field of deep learning, state space models are used to
process sequence data, such as time series analysis, natural language
processing (NLP) and video understanding. By mapping sequence data to state
space, long-term dependencies in the data can be better captured. In
particular, modern SSMs have shown strong representational capabilities in NLP,
especially in long sequence modeling, while maintaining linear time complexity.
Notably, based on the latest state-space models, Mamba merges time-varying
parameters into SSMs and formulates a hardware-aware algorithm for efficient
training and inference. Given its impressive efficiency and strong long-range
dependency modeling capability, Mamba is expected to become a new AI
architecture that may outperform Transformer. Recently, a number of works have
attempted to study the potential of Mamba in various fields, such as general
vision, multi-modal, medical image analysis and remote sensing image analysis,
by extending Mamba from natural language domain to visual domain. To fully
understand Mamba in the visual domain, we conduct a comprehensive survey and
present a taxonomy study. This survey focuses on Mamba's application to a
variety of visual tasks and data types, and discusses its predecessors, recent
advances and far-reaching impact on a wide range of domains. Since Mamba is now
on an upward trend, please actively notice us if you have new findings, and new
progress on Mamba will be included in this survey in a timely manner and
updated on the Mamba project at
https://github.com/lx6c78/Vision-Mamba-A-Comprehensive-Survey-and-Taxonomy.

摘要：狀態空間模型 (SSM) 是一種數學模型，用於描述和分析動態系統的行為。此模型已在多個領域見證了許多應用，包括控制理論、訊號處理、經濟學和機器學習。在深度學習領域，狀態空間模型用於處理序列資料，例如時間序列分析、自然語言處理 (NLP) 和影片理解。透過將序列資料對應到狀態空間，可以更好地擷取資料中的長期依賴關係。特別是，現代 SSM 已在 NLP 中展現出強大的表示能力，特別是在長序列建模中，同時維持線性時間複雜度。值得注意的是，基於最新的狀態空間模型，Mamba 將時變參數合併到 SSM 中，並制定了一種硬體感知演算法，以進行有效率的訓練和推論。鑑於其令人印象深刻的效率和強大的長程依賴關係建模能力，預計 Mamba 將成為一種新的 AI 架構，其效能可能超越 Transformer。最近，許多研究嘗試探討 Mamba 在各種領域的潛力，例如一般視覺、多模式、醫學影像分析和遙測影像分析，方法是將 Mamba 從自然語言網域延伸到視覺網域。為了充分理解視覺網域中的 Mamba，我們進行了一項全面的調查，並提出了一項分類研究。這項調查重點在於 Mamba 在各種視覺任務和資料類型中的應用，並討論其前身、最新進展和對廣泛領域的深遠影響。由於 Mamba 目前正處於上升趨勢，如果您有新的發現，請積極通知我們，而 Mamba 的新進展將適時納入這項調查，並在 Mamba 專案中更新於 https://github.com/lx6c78/Vision-Mamba-A-Comprehensive-Survey-and-Taxonomy。

##### **Learning To See But Forgetting To Follow: Visual Instruction Tuning Makes LLMs More Prone To Jailbreak Attacks**
2405.04403v1 by Georgios Pantazopoulos, Amit Parekh, Malvina Nikandrou, Alessandro Suglia

Augmenting Large Language Models (LLMs) with image-understanding capabilities
has resulted in a boom of high-performing Vision-Language models (VLMs). While
studying the alignment of LLMs to human values has received widespread
attention, the safety of VLMs has not received the same attention. In this
paper, we explore the impact of jailbreaking on three state-of-the-art VLMs,
each using a distinct modeling approach. By comparing each VLM to their
respective LLM backbone, we find that each VLM is more susceptible to
jailbreaking. We consider this as an undesirable outcome from visual
instruction-tuning, which imposes a forgetting effect on an LLM's safety
guardrails. Therefore, we provide recommendations for future work based on
evaluation strategies that aim to highlight the weaknesses of a VLM, as well as
take safety measures into account during visual instruction tuning.

摘要：擴增大型語言模型 (LLM) 的影像理解能力，已導致高性能視覺語言模型 (VLM) 的蓬勃發展。儘管研究 LLM 與人類價值觀的一致性已受到廣泛關注，但 VLM 的安全性尚未獲得同等的關注。在本文中，我們探討了越獄對三個最先進的 VLM 的影響，每個 VLM 都使用不同的建模方法。透過將每個 VLM 與其各自的 LLM 主幹進行比較，我們發現每個 VLM 都更容易受到越獄的影響。我們將此視為視覺指令調整的一個不良結果，這對 LLM 的安全防護措施施加了遺忘效應。因此，我們根據評估策略提供未來工作的建議，這些策略旨在突顯 VLM 的弱點，並在視覺指令調整期間考量安全措施。

##### **Pragmatist Intelligence: Where the Principle of Usefulness Can Take ANNs**
2405.04386v1 by Antonio Bikić, Sayan Mukherjee

Artificial neural networks (ANNs) perform extraordinarily on numerous tasks
including classification or prediction, e.g., speech processing and image
classification. These new functions are based on a computational model that is
enabled to select freely all necessary internal model parameters as long as it
eventually delivers the functionality it is supposed to exhibit. Here, we
review the connection between the model parameter selection in machine learning
(ML) algorithms running on ANNs and the epistemological theory of neopragmatism
focusing on the theory's utility and anti-representationalist aspects. To
understand the consequences of the model parameter selection of an ANN, we
suggest using neopragmatist theories whose implications are well studied.
Incidentally, neopragmatism's notion of optimization is also based on utility
considerations. This means that applying this approach elegantly reveals the
inherent connections between optimization in ML, using a numerical method
during the learning phase, and optimization in the ethical theory of
consequentialism, where it occurs as a maxim of action. We suggest that these
connections originate from the way relevance is calculated in ML systems. This
could ultimately reveal a tendency for specific actions in ML systems.

摘要：人工神經網路 (ANN) 在許多任務上表現得非常好，包括分類或預測，例如語音處理和影像分類。這些新功能基於一個計算模型，只要它最終提供它應該展示的功能，就能自由選擇所有必要的內部模型參數。在這裡，我們回顧機器學習 (ML) 演算法中模型參數選擇與人工神經網路執行的運作，以及新實用主義的認識論，重點在於該理論的效用和反表象方面。為了了解人工神經網路模型參數選擇的後果，我們建議使用新實用主義理論，其含義已得到充分的研究。順便一提，新實用主義的最佳化概念也基於效用考量。這表示應用這種方法優雅地揭示了機器學習中最佳化的內在關聯，在學習階段使用數值方法，以及後果主義的倫理理論中的最佳化，在其中它作為行動格言出現。我們建議這些關聯源自機器學習系統中計算相關性的方式。這最終可能會揭示機器學習系統中特定動作的趨勢。

##### **Leveraging LSTM and GAN for Modern Malware Detection**
2405.04373v1 by Ishita Gupta, Sneha Kumari, Priya Jha, Mohona Ghosh

The malware booming is a cyberspace equal to the effect of climate change to
ecosystems in terms of danger. In the case of significant investments in
cybersecurity technologies and staff training, the global community has become
locked up in the eternal war with cyber security threats. The multi-form and
changing faces of malware are continuously pushing the boundaries of the
cybersecurity practitioners employ various approaches like detection and
mitigate in coping with this issue. Some old mannerisms like signature-based
detection and behavioral analysis are slow to adapt to the speedy evolution of
malware types. Consequently, this paper proposes the utilization of the Deep
Learning Model, LSTM networks, and GANs to amplify malware detection accuracy
and speed. A fast-growing, state-of-the-art technology that leverages raw
bytestream-based data and deep learning architectures, the AI technology
provides better accuracy and performance than the traditional methods.
Integration of LSTM and GAN model is the technique that is used for the
synthetic generation of data, leading to the expansion of the training
datasets, and as a result, the detection accuracy is improved. The paper uses
the VirusShare dataset which has more than one million unique samples of the
malware as the training and evaluation set for the presented models. Through
thorough data preparation including tokenization, augmentation, as well as
model training, the LSTM and GAN models convey the better performance in the
tasks compared to straight classifiers. The research outcomes come out with 98%
accuracy that shows the efficiency of deep learning plays a decisive role in
proactive cybersecurity defense. Aside from that, the paper studies the output
of ensemble learning and model fusion methods as a way to reduce biases and
lift model complexity.

摘要：惡意軟體的蓬勃發展對網路空間的影響，等同於氣候變遷對生態系統的危害。在對網路安全技術和員工訓練進行大量投資的情況下，全球社群已陷入與網路安全威脅的永恆戰爭中。惡意軟體的多樣化形式和不斷變化的面貌，持續挑戰網路安全從業人員的界限，他們採用各種方法來應對此問題，例如偵測和緩解。一些舊有的方式，例如基於特徵碼的偵測和行為分析，適應惡意軟體類型快速演變的速度較慢。因此，本文提出利用深度學習模型、LSTM 網路和 GAN 來提升惡意軟體偵測的準確度和速度。人工智慧技術是一種快速發展的尖端技術，它利用基於原始位元組串流的資料和深度學習架構，提供比傳統方法更好的準確度和效能。LSTM 和 GAN 模型的整合是一種用於資料合成產生的技術，可擴充訓練資料集，進而提升偵測準確度。本文使用 VirusShare 資料集，其中包含一百萬個以上的獨特惡意軟體樣本，作為所提出模型的訓練和評估集。透過包含代幣化、擴充和模型訓練在內的徹底資料準備，LSTM 和 GAN 模型在任務中的表現優於直接分類器。研究結果達到了 98% 的準確度，顯示深度學習的效率在主動網路安全防禦中扮演決定性的角色。除此之外，本文探討整體學習和模型融合方法的輸出，作為減少偏差和提升模型複雜度的方法。

##### **Explainable machine learning for predicting shellfish toxicity in the Adriatic Sea using long-term monitoring data of HABs**
2405.04372v2 by Martin Marzidovšek, Janja Francé, Vid Podpečan, Stanka Vadnjal, Jožica Dolenc, Patricija Mozetič

In this study, explainable machine learning techniques are applied to predict
the toxicity of mussels in the Gulf of Trieste (Adriatic Sea) caused by harmful
algal blooms. By analysing a newly created 28-year dataset containing records
of toxic phytoplankton in mussel farming areas and toxin concentrations in
mussels (Mytilus galloprovincialis), we train and evaluate the performance of
ML models to accurately predict diarrhetic shellfish poisoning (DSP) events.
The random forest model provided the best prediction of positive toxicity
results based on the F1 score. Explainability methods such as permutation
importance and SHAP identified key species (Dinophysis fortii and D. caudata)
and environmental factors (salinity, river discharge and precipitation) as the
best predictors of DSP outbreaks. These findings are important for improving
early warning systems and supporting sustainable aquaculture practices.

摘要：本研究採用可解釋機器學習技術，用以預測有害藻華導致的里雅斯特灣（亞得里亞海）貽貝毒性。透過分析一個新建立的 28 年資料集，其中包含貽貝養殖區有毒浮游植物的紀錄，以及貽貝（Mytilus galloprovincialis）中的毒素濃度，我們訓練並評估機器學習模型的效能，以準確預測腹瀉性貝類中毒 (DSP) 事件。隨機森林模型根據 F1 分數提供了最佳的正向毒性結果預測。可解釋性方法，例如排列重要性和 SHAP，則找出關鍵物種（Dinophysis fortii 和 D. caudata）和環境因素（鹽度、河流流量和降水），作為 DSP 爆發的最佳預測指標。這些發現對於改善預警系統和支援永續水產養殖實務至關重要。

##### **Inferring Discussion Topics about Exploitation of Vulnerabilities from Underground Hacking Forums**
2405.04561v1 by Felipe Moreno-Vera

The increasing sophistication of cyber threats necessitates proactive
measures to identify vulnerabilities and potential exploits. Underground
hacking forums serve as breeding grounds for the exchange of hacking techniques
and discussions related to exploitation. In this research, we propose an
innovative approach using topic modeling to analyze and uncover key themes in
vulnerabilities discussed within these forums. The objective of our study is to
develop a machine learning-based model that can automatically detect and
classify vulnerability-related discussions in underground hacking forums. By
monitoring and analyzing the content of these forums, we aim to identify
emerging vulnerabilities, exploit techniques, and potential threat actors. To
achieve this, we collect a large-scale dataset consisting of posts and threads
from multiple underground forums. We preprocess and clean the data to ensure
accuracy and reliability. Leveraging topic modeling techniques, specifically
Latent Dirichlet Allocation (LDA), we uncover latent topics and their
associated keywords within the dataset. This enables us to identify recurring
themes and prevalent discussions related to vulnerabilities, exploits, and
potential targets.

摘要：由於網路威脅日益複雜，因此需要採取主動措施來識別漏洞和潛在的攻擊手法。地下駭客論壇是交換駭客技術和討論與攻擊相關議題的溫床。在這項研究中，我們提出一個創新的方法，利用主題建模來分析和找出這些論壇中討論的漏洞中的關鍵主題。我們研究的目標是開發一個基於機器學習的模型，可以自動偵測和分類地下駭客論壇中與漏洞相關的討論。透過監控和分析這些論壇的內容，我們希望能找出新興的漏洞、攻擊手法和潛在的威脅者。為了達成這個目標，我們收集了一個由多個地下論壇的貼文和串組成的龐大資料集。我們預先處理並清理資料，以確保其準確性和可靠性。利用主題建模技術，特別是隱含狄利克雷配置（LDA），我們找出資料集中的潛在主題及其相關的關鍵字。這讓我們能夠找出與漏洞、攻擊手法和潛在目標相關的重複主題和盛行的討論。

##### **Global Scale Self-Supervised Channel Charting with Sensor Fusion**
2405.04357v1 by Omid Esrafilian, Mohsen Ahadi, Florian Kaltenberger, David Gesbert

The sensing and positioning capabilities foreseen in 6G have great potential
for technology advancements in various domains, such as future smart cities and
industrial use cases. Channel charting has emerged as a promising technology in
recent years for radio frequency-based sensing and localization. However, the
accuracy of these techniques is yet far behind the numbers envisioned in 6G. To
reduce this gap, in this paper, we propose a novel channel charting technique
capitalizing on the time of arrival measurements from surrounding Transmission
Reception Points (TRPs) along with their locations and leveraging sensor fusion
in channel charting by incorporating laser scanner data during the training
phase of our algorithm. The proposed algorithm remains self-supervised during
training and test phases, requiring no geometrical models or user position
ground truth. Simulation results validate the achievement of a sub-meter level
localization accuracy using our algorithm 90% of the time, outperforming the
state-of-the-art channel charting techniques and the traditional
triangulation-based approaches.

摘要：6G 中預見的感測和定位能力對於各種領域的技術進展具有極大的潛力，例如未來智慧城市和工業用例。頻道繪製近年來已成為一種很有前景的技術，用於基於無線電頻率的感測和定位。然而，這些技術的準確性遠遠落後於 6G 中預期的數字。為了縮小這個差距，在本文中，我們提出了一種新穎的頻道繪製技術，利用來自周圍傳輸接收點 (TRP) 的到達時間測量值以及它們的位置，並在演算法訓練階段透過納入雷射掃描儀資料來利用頻道繪製中的感測器融合。所提出的演算法在訓練和測試階段仍然是自我監督的，不需要幾何模型或使用者位置真實值。模擬結果驗證了使用我們的演算法在 90% 的時間內達成次公尺等級的定位準確度，優於最先進的頻道繪製技術和傳統的基於三角測量的途徑。

##### **Revisiting character-level adversarial attacks**
2405.04346v1 by Elias Abad Rocamora, Yongtao Wu, Fanghui Liu, Grigorios G. Chrysos, Volkan Cevher

Adversarial attacks in Natural Language Processing apply perturbations in the
character or token levels. Token-level attacks, gaining prominence for their
use of gradient-based methods, are susceptible to altering sentence semantics,
leading to invalid adversarial examples. While character-level attacks easily
maintain semantics, they have received less attention as they cannot easily
adopt popular gradient-based methods, and are thought to be easy to defend.
Challenging these beliefs, we introduce Charmer, an efficient query-based
adversarial attack capable of achieving high attack success rate (ASR) while
generating highly similar adversarial examples. Our method successfully targets
both small (BERT) and large (Llama 2) models. Specifically, on BERT with SST-2,
Charmer improves the ASR in 4.84% points and the USE similarity in 8% points
with respect to the previous art. Our implementation is available in
https://github.com/LIONS-EPFL/Charmer.

摘要：自然語言處理中的對抗性攻擊在字元或標記層級套用擾動。標記層級攻擊因使用基於梯度的技術而聲名大噪，容易改變句子語義，導致無效的對抗性範例。雖然字元層級攻擊容易維持語義，但由於它們無法輕易採用熱門的基於梯度的技術，而且被認為容易防禦，因此較不受重視。為了挑戰這些觀念，我們引入了 Charmer，一種有效率的基於查詢的對抗性攻擊，能夠在產生高度相似的對抗性範例的同時，達成高攻擊成功率 (ASR)。我們的技術成功地針對小型 (BERT) 和大型 (Llama 2) 模型。具體來說，在使用 SST-2 的 BERT 上，Charmer 將 ASR 提高了 4.84%，將 USE 相似性提高了 8%，優於先前的技術。我們的實作可在 https://github.com/LIONS-EPFL/Charmer 中取得。

##### **Temporal and Heterogeneous Graph Neural Network for Remaining Useful Life Prediction**
2405.04336v1 by Zhihao Wen, Yuan Fang, Pengcheng Wei, Fayao Liu, Zhenghua Chen, Min Wu

Predicting Remaining Useful Life (RUL) plays a crucial role in the
prognostics and health management of industrial systems that involve a variety
of interrelated sensors. Given a constant stream of time series sensory data
from such systems, deep learning models have risen to prominence at identifying
complex, nonlinear temporal dependencies in these data. In addition to the
temporal dependencies of individual sensors, spatial dependencies emerge as
important correlations among these sensors, which can be naturally modelled by
a temporal graph that describes time-varying spatial relationships. However,
the majority of existing studies have relied on capturing discrete snapshots of
this temporal graph, a coarse-grained approach that leads to loss of temporal
information. Moreover, given the variety of heterogeneous sensors, it becomes
vital that such inherent heterogeneity is leveraged for RUL prediction in
temporal sensor graphs. To capture the nuances of the temporal and spatial
relationships and heterogeneous characteristics in an interconnected graph of
sensors, we introduce a novel model named Temporal and Heterogeneous Graph
Neural Networks (THGNN). Specifically, THGNN aggregates historical data from
neighboring nodes to accurately capture the temporal dynamics and spatial
correlations within the stream of sensor data in a fine-grained manner.
Moreover, the model leverages Feature-wise Linear Modulation (FiLM) to address
the diversity of sensor types, significantly improving the model's capacity to
learn the heterogeneity in the data sources. Finally, we have validated the
effectiveness of our approach through comprehensive experiments. Our empirical
findings demonstrate significant advancements on the N-CMAPSS dataset,
achieving improvements of up to 19.2% and 31.6% in terms of two different
evaluation metrics over state-of-the-art methods.

摘要：<paragraph>預測剩餘使用壽命 (RUL) 在涉及各種相互關聯感測器的工業系統的預測和健康管理中扮演著至關重要的角色。在給定來自此類系統的連續時間序列感測資料後，深度學習模型在識別這些資料中的複雜非線性時間依賴性方面已變得突出。除了個別感測器的時間依賴性外，空間依賴性會以這些感測器之間的重要關聯形式出現，而時間圖表可以自然地對其建模，該圖表描述了隨時間變化的空間關係。然而，現有研究大多依賴於擷取此時間圖表的離散快照，這是一種粗略的方法，會導致時間資訊的遺失。此外，考量到各種異質感測器，在時間感測器圖表中對 RUL 進行預測時，利用此類固有異質性變得至關重要。為了擷取互連感測器圖表中時間和空間關係以及異質特性的細微差別，我們引進了一個名為時間異質圖形神經網路 (THGNN) 的新穎模型。具體來說，THGNN 從鄰近節點匯聚歷史資料，以精細的方式準確擷取感測器資料串流中的時間動態和空間關聯。此外，該模型利用特徵線性調變 (FiLM) 來解決感測器類型的多樣性，顯著提升模型學習資料來源中異質性的能力。最後，我們透過全面的實驗驗證了我們方法的有效性。我們的經驗發現證明了在 N-CMAPSS 資料集上取得顯著進展，在兩個不同的評估指標方面，與最先進的方法相比，分別取得高達 19.2% 和 31.6% 的進步。</paragraph>

##### **A Fourth Wave of Open Data? Exploring the Spectrum of Scenarios for Open Data and Generative AI**
2405.04333v1 by Hannah Chafetz, Sampriti Saxena, Stefaan G. Verhulst

Since late 2022, generative AI has taken the world by storm, with widespread
use of tools including ChatGPT, Gemini, and Claude. Generative AI and large
language model (LLM) applications are transforming how individuals find and
access data and knowledge. However, the intricate relationship between open
data and generative AI, and the vast potential it holds for driving innovation
in this field remain underexplored areas. This white paper seeks to unpack the
relationship between open data and generative AI and explore possible
components of a new Fourth Wave of Open Data: Is open data becoming AI ready?
Is open data moving towards a data commons approach? Is generative AI making
open data more conversational? Will generative AI improve open data quality and
provenance? Towards this end, we provide a new Spectrum of Scenarios framework.
This framework outlines a range of scenarios in which open data and generative
AI could intersect and what is required from a data quality and provenance
perspective to make open data ready for those specific scenarios. These
scenarios include: pertaining, adaptation, inference and insight generation,
data augmentation, and open-ended exploration. Through this process, we found
that in order for data holders to embrace generative AI to improve open data
access and develop greater insights from open data, they first must make
progress around five key areas: enhance transparency and documentation, uphold
quality and integrity, promote interoperability and standards, improve
accessibility and useability, and address ethical considerations.

摘要：自 2022 年底以來，生成式 AI 已席捲全球，ChatGPT、Gemini 和 Claude 等工具廣泛使用。生成式 AI 和大型語言模型 (LLM) 應用程式正在改變個人尋找和存取資料與知識的方式。然而，開放資料和生成式 AI 之間的複雜關係，以及它在推動此領域創新的巨大潛力，仍然是尚未充分探索的領域。本白皮書旨在解開開放資料和生成式 AI 之間的關係，並探討開放資料第四波的可能組成部分：開放資料是否準備好迎接 AI？開放資料是否朝向資料共用方法邁進？生成式 AI 是否讓開放資料更具對話性？生成式 AI 是否會改善開放資料的品質和來源？為此，我們提供了一個新的情境光譜架構。此架構概述了一系列開放資料和生成式 AI 可能相交的情境，以及從資料品質和來源的角度來看，讓開放資料為這些特定情境做好準備所需的條件。這些情境包括：關聯、改編、推論和見解產生、資料擴充和開放式探索。透過此流程，我們發現資料持有者若要採用生成式 AI 來改善開放資料存取並從開放資料中發展出更深入的見解，他們必須先在五個關鍵領域取得進展：加強透明度和文件化、維護品質和完整性、促進互操作性和標準化、改善可存取性和可用性，以及解決倫理考量。

##### **Deception in Reinforced Autonomous Agents: The Unconventional Rabbit Hat Trick in Legislation**
2405.04325v1 by Atharvan Dogra, Ameet Deshpande, John Nay, Tanmay Rajpurohit, Ashwin Kalyan, Balaraman Ravindran

Recent developments in large language models (LLMs), while offering a
powerful foundation for developing natural language agents, raise safety
concerns about them and the autonomous agents built upon them. Deception is one
potential capability of AI agents of particular concern, which we refer to as
an act or statement that misleads, hides the truth, or promotes a belief that
is not true in its entirety or in part. We move away from the conventional
understanding of deception through straight-out lying, making objective selfish
decisions, or giving false information, as seen in previous AI safety research.
We target a specific category of deception achieved through obfuscation and
equivocation. We broadly explain the two types of deception by analogizing them
with the rabbit-out-of-hat magic trick, where (i) the rabbit either comes out
of a hidden trap door or (ii) (our focus) the audience is completely distracted
to see the magician bring out the rabbit right in front of them using sleight
of hand or misdirection. Our novel testbed framework displays intrinsic
deception capabilities of LLM agents in a goal-driven environment when directed
to be deceptive in their natural language generations in a two-agent
adversarial dialogue system built upon the legislative task of "lobbying" for a
bill. Along the lines of a goal-driven environment, we show developing
deceptive capacity through a reinforcement learning setup, building it around
the theories of language philosophy and cognitive psychology. We find that the
lobbyist agent increases its deceptive capabilities by ~ 40% (relative) through
subsequent reinforcement trials of adversarial interactions, and our deception
detection mechanism shows a detection capability of up to 92%. Our results
highlight potential issues in agent-human interaction, with agents potentially
manipulating humans towards its programmed end-goal.

摘要：大型語言模型 (LLM) 的最新進展，雖然為開發自然語言代理提供了強大的基礎，但對它們以及建立在它們之上的自主代理提出了安全方面的擔憂。欺騙是人工智能代理特別關注的潛在能力之一，我們將其稱為誤導、隱瞞真相或宣傳部分或全部不真實信念的行為或陳述。我們遠離通過直接撒謊、做出客觀自私的決定或提供虛假信息來理解欺騙的傳統觀念，正如在先前的 AI 安全研究中所見。我們針對通過混淆和模稜兩可實現的特定類別的欺騙行為。我們通過將它們比作魔術師從帽子中變出兔子的戲法來廣泛解釋這兩種欺騙行為，其中 (i) 兔子要麼從隱藏的活門中出來，或者 (ii) (我們的重點) 觀眾完全被分散注意力，看到魔術師使用障眼法或誤導手法在他們面前變出兔子。我們新穎的測試框架在目標驅動環境中展示了 LLM 代理的內在欺騙能力，當指示它們在建立在「遊說」法案的立法任務之上的雙代理對抗對話系統中以自然語言生成方式進行欺騙時。沿著目標驅動環境的思路，我們展示了通過強化學習設置來發展欺騙能力，並圍繞語言哲學和認知心理學的理論來構建它。我們發現，遊說代理通過後續的對抗互動強化試驗，將其欺騙能力提高了約 40%（相對值），而我們的欺騙檢測機制顯示出高達 92% 的檢測能力。我們的結果突出了代理人與人之間互動中的潛在問題，代理人可能會操縱人類朝著其規劃的最終目標前進。

##### **Granite Code Models: A Family of Open Foundation Models for Code Intelligence**
2405.04324v1 by Mayank Mishra, Matt Stallone, Gaoyuan Zhang, Yikang Shen, Aditya Prasad, Adriana Meza Soria, Michele Merler, Parameswaran Selvam, Saptha Surendran, Shivdeep Singh, Manish Sethi, Xuan-Hong Dang, Pengyuan Li, Kun-Lung Wu, Syed Zawad, Andrew Coleman, Matthew White, Mark Lewis, Raju Pavuluri, Yan Koyfman, Boris Lublinsky, Maximilien de Bayser, Ibrahim Abdelaziz, Kinjal Basu, Mayank Agarwal, Yi Zhou, Chris Johnson, Aanchal Goyal, Hima Patel, Yousaf Shah, Petros Zerfos, Heiko Ludwig, Asim Munawar, Maxwell Crouse, Pavan Kapanipathi, Shweta Salaria, Bob Calio, Sophia Wen, Seetharami Seelam, Brian Belgodere, Carlos Fonseca, Amith Singhee, Nirmit Desai, David D. Cox, Ruchir Puri, Rameswar Panda

Large Language Models (LLMs) trained on code are revolutionizing the software
development process. Increasingly, code LLMs are being integrated into software
development environments to improve the productivity of human programmers, and
LLM-based agents are beginning to show promise for handling complex tasks
autonomously. Realizing the full potential of code LLMs requires a wide range
of capabilities, including code generation, fixing bugs, explaining and
documenting code, maintaining repositories, and more. In this work, we
introduce the Granite series of decoder-only code models for code generative
tasks, trained with code written in 116 programming languages. The Granite Code
models family consists of models ranging in size from 3 to 34 billion
parameters, suitable for applications ranging from complex application
modernization tasks to on-device memory-constrained use cases. Evaluation on a
comprehensive set of tasks demonstrates that Granite Code models consistently
reaches state-of-the-art performance among available open-source code LLMs. The
Granite Code model family was optimized for enterprise software development
workflows and performs well across a range of coding tasks (e.g. code
generation, fixing and explanation), making it a versatile all around code
model. We release all our Granite Code models under an Apache 2.0 license for
both research and commercial use.

摘要：大型語言模型 (LLM) 接受過程式碼訓練，正在革新軟體開發流程。程式碼 LLM 愈來愈多地整合到軟體開發環境中，以提升人類程式設計師的生產力，而基於 LLM 的代理程式也開始展現出自主處理複雜任務的希望。要實現程式碼 LLM 的全部潛力，需要廣泛的功能，包括產生程式碼、修正錯誤、說明和記錄程式碼、維護儲存庫等等。在這項工作中，我們引入了 Granite 系列的僅解碼器程式碼模型，用於程式碼產生任務，並使用 116 種程式語言編寫的程式碼進行訓練。Granite Code 模型系列包含大小從 30 億到 340 億個參數不等的模型，適用於從複雜的應用程式現代化任務到裝置記憶體受限使用案例的各種應用程式。對一組全面的任務進行評估，證明 Granite Code 模型在現有的開源程式碼 LLM 中始終達到最先進的效能。Granite Code 模型系列經過最佳化，適用於企業軟體開發工作流程，並且在各種編碼任務（例如產生程式碼、修正和說明）中表現良好，使其成為一款功能強大的全方位程式碼模型。我們根據 Apache 2.0 授權釋出所有 Granite Code 模型，供研究和商業用途。

##### **Beyond human subjectivity and error: a novel AI grading system**
2405.04323v1 by Alexandra Gobrecht, Felix Tuma, Moritz Möller, Thomas Zöller, Mark Zakhvatkin, Alexandra Wuttig, Holger Sommerfeldt, Sven Schütt

The grading of open-ended questions is a high-effort, high-impact task in
education. Automating this task promises a significant reduction in workload
for education professionals, as well as more consistent grading outcomes for
students, by circumventing human subjectivity and error. While recent
breakthroughs in AI technology might facilitate such automation, this has not
been demonstrated at scale. It this paper, we introduce a novel automatic short
answer grading (ASAG) system. The system is based on a fine-tuned open-source
transformer model which we trained on large set of exam data from university
courses across a large range of disciplines. We evaluated the trained model's
performance against held-out test data in a first experiment and found high
accuracy levels across a broad spectrum of unseen questions, even in unseen
courses. We further compared the performance of our model with that of
certified human domain experts in a second experiment: we first assembled
another test dataset from real historical exams - the historic grades contained
in that data were awarded to students in a regulated, legally binding
examination process; we therefore considered them as ground truth for our
experiment. We then asked certified human domain experts and our model to grade
the historic student answers again without disclosing the historic grades.
Finally, we compared the hence obtained grades with the historic grades (our
ground truth). We found that for the courses examined, the model deviated less
from the official historic grades than the human re-graders - the model's
median absolute error was 44 % smaller than the human re-graders', implying
that the model is more consistent than humans in grading. These results suggest
that leveraging AI enhanced grading can reduce human subjectivity, improve
consistency and thus ultimately increase fairness.

摘要：開放式問題的評分是教育中高投入、高影響力的任務。自動化這項任務承諾大幅減少教育專業人員的工作量，並透過規避人為的主觀和錯誤，為學生提供更一致的評分結果。雖然 AI 技術的最新突破可能有助於這種自動化，但這尚未大規模示範。在本文中，我們介紹了一種新穎的自動簡答評分 (ASAG) 系統。該系統基於一個經過微調的開源轉換器模型，我們在來自各個學科的大學課程的大量考試數據上對其進行了訓練。我們在第一次實驗中評估了訓練模型對保留測試數據的效能，並發現即使在未見過的課程中，在廣泛的未見過問題中也具有很高的準確度。在第二次實驗中，我們進一步比較了我們模型的效能與經過認證的人類領域專家的效能：我們首先從真實的歷史考試中收集了另一個測試數據集 - 該數據中包含的歷史成績是在受監管的、具有法律約束力的考試過程中授予學生的；因此，我們將其視為我們實驗的真實情況。然後，我們要求經過認證的人類領域專家和我們的模型在不透露歷史成績的情況下再次評分歷史學生的答案。最後，我們將因此獲得的成績與歷史成績（我們的真實情況）進行比較。我們發現，對於所檢查的課程，該模型比人類重新評分者偏離官方歷史成績的程度更小 - 該模型的中值絕對誤差比人類重新評分者小 44%，這意味著該模型在評分方面比人類更一致。這些結果表明，利用 AI 增強評分可以減少人為的主觀性，提高一致性，從而最終提高公平性。

##### **Cross-IQA: Unsupervised Learning for Image Quality Assessment**
2405.04311v1 by Zhen Zhang

Automatic perception of image quality is a challenging problem that impacts
billions of Internet and social media users daily. To advance research in this
field, we propose a no-reference image quality assessment (NR-IQA) method
termed Cross-IQA based on vision transformer(ViT) model. The proposed Cross-IQA
method can learn image quality features from unlabeled image data. We construct
the pretext task of synthesized image reconstruction to unsupervised extract
the image quality information based ViT block. The pretrained encoder of
Cross-IQA is used to fine-tune a linear regression model for score prediction.
Experimental results show that Cross-IQA can achieve state-of-the-art
performance in assessing the low-frequency degradation information (e.g., color
change, blurring, etc.) of images compared with the classical full-reference
IQA and NR-IQA under the same datasets.

摘要：影像品質的自動感知是一項具有挑戰性的問題，它每天都會影響數十億的網際網路和社群媒體使用者。為了推進此領域的研究，我們提出了一種基於視覺轉換器 (ViT) 模型的無參考影像品質評估 (NR-IQA) 方法，稱為 Cross-IQA。所提出的 Cross-IQA 方法可以從未標籤的影像資料中學習影像品質特徵。我們建構了合成影像重建的預設任務，以非監督的方式根據 ViT 區塊萃取影像品質資訊。Cross-IQA 的預訓練編碼器用於微調線性回歸模型以進行分數預測。實驗結果顯示，與在相同資料集下的傳統全參考 IQA 和 NR-IQA 相比，Cross-IQA 可以達成評估影像低頻劣化資訊（例如，色彩變化、模糊等）的最新技術效能。

##### **Improving Offline Reinforcement Learning with Inaccurate Simulators**
2405.04307v1 by Yiwen Hou, Haoyuan Sun, Jinming Ma, Feng Wu

Offline reinforcement learning (RL) provides a promising approach to avoid
costly online interaction with the real environment. However, the performance
of offline RL highly depends on the quality of the datasets, which may cause
extrapolation error in the learning process. In many robotic applications, an
inaccurate simulator is often available. However, the data directly collected
from the inaccurate simulator cannot be directly used in offline RL due to the
well-known exploration-exploitation dilemma and the dynamic gap between
inaccurate simulation and the real environment. To address these issues, we
propose a novel approach to combine the offline dataset and the inaccurate
simulation data in a better manner. Specifically, we pre-train a generative
adversarial network (GAN) model to fit the state distribution of the offline
dataset. Given this, we collect data from the inaccurate simulator starting
from the distribution provided by the generator and reweight the simulated data
using the discriminator. Our experimental results in the D4RL benchmark and a
real-world manipulation task confirm that our method can benefit more from both
inaccurate simulator and limited offline datasets to achieve better performance
than the state-of-the-art methods.

摘要：離線強化學習 (RL) 提供一種有前途的方法來避免與真實環境進行代價高昂的線上互動。然而，離線 RL 的效能高度依賴於資料集的品質，這可能會在學習過程中導致外推誤差。在許多機器人應用中，通常可以使用不準確的模擬器。然而，由於眾所周知的探索開發兩難困境和不準確的模擬與真實環境之間的動態差距，無法直接在離線 RL 中使用從不準確的模擬器直接收集的資料。為了解決這些問題，我們提出了一種新方法，以更好的方式結合離線資料集和不準確的模擬資料。具體來說，我們預先訓練一個生成對抗網路 (GAN) 模型來擬合離線資料集的狀態分佈。有鑑於此，我們從產生器提供的分佈開始，從不準確的模擬器收集資料，並使用辨別器重新加權模擬資料。我們在 D4RL 基準和真實世界操作任務中的實驗結果證實，與最先進的方法相比，我們的模型可以從不準確的模擬器和有限的離線資料集中受益更多，以實現更好的效能。

##### **A New Dataset and Comparative Study for Aphid Cluster Detection and Segmentation in Sorghum Fields**
2405.04305v1 by Raiyan Rahman, Christopher Indris, Goetz Bramesfeld, Tianxiao Zhang, Kaidong Li, Xiangyu Chen, Ivan Grijalva, Brian McCornack, Daniel Flippo, Ajay Sharda, Guanghui Wang

Aphid infestations are one of the primary causes of extensive damage to wheat
and sorghum fields and are one of the most common vectors for plant viruses,
resulting in significant agricultural yield losses. To address this problem,
farmers often employ the inefficient use of harmful chemical pesticides that
have negative health and environmental impacts. As a result, a large amount of
pesticide is wasted on areas without significant pest infestation. This brings
to attention the urgent need for an intelligent autonomous system that can
locate and spray sufficiently large infestations selectively within the complex
crop canopies. We have developed a large multi-scale dataset for aphid cluster
detection and segmentation, collected from actual sorghum fields and
meticulously annotated to include clusters of aphids. Our dataset comprises a
total of 54,742 image patches, showcasing a variety of viewpoints, diverse
lighting conditions, and multiple scales, highlighting its effectiveness for
real-world applications. In this study, we trained and evaluated four real-time
semantic segmentation models and three object detection models specifically for
aphid cluster segmentation and detection. Considering the balance between
accuracy and efficiency, Fast-SCNN delivered the most effective segmentation
results, achieving 80.46% mean precision, 81.21% mean recall, and 91.66 frames
per second (FPS). For object detection, RT-DETR exhibited the best overall
performance with a 61.63% mean average precision (mAP), 92.6% mean recall, and
72.55 on an NVIDIA V100 GPU. Our experiments further indicate that aphid
cluster segmentation is more suitable for assessing aphid infestations than
using detection models.

摘要：蚜蟲侵擾是小麥和高粱田廣泛受損的主要原因之一，也是植物病毒最常見的媒介，導致農業產量大幅損失。為了解決這個問題，農民通常採用低效率且有害的化學殺蟲劑，對健康和環境造成負面影響。因此，大量殺蟲劑浪費在沒有嚴重蟲害侵擾的地區。這引起了人們對一個智慧型自主系統的迫切需求，該系統可以在複雜的作物冠層中選擇性地定位和噴灑足夠大的蟲害。我們開發了一個大型多尺度資料集，用於蚜蟲叢集檢測和分割，從實際的高粱田收集，並經過細緻標註以包含蚜蟲叢集。我們的資料集總共包含 54,742 個影像貼片，展示了各種視角、不同的光照條件和多個尺度，突顯了其在實際應用中的有效性。在本研究中，我們訓練並評估了四個即時語義分割模型和三個物件偵測模型，專門用於蚜蟲叢集分割和偵測。在準確度和效率之間取得平衡，Fast-SCNN 提供了最有效的分割結果，平均準確率達 80.46%，平均召回率達 81.21%，每秒幀數 (FPS) 達 91.66。在物件偵測方面，RT-DETR 表現出最佳的整體效能，在 NVIDIA V100 GPU 上的平均準確率 (mAP) 為 61.63%，平均召回率為 92.6%，為 72.55。我們的實驗進一步表明，與使用偵測模型相比，蚜蟲叢集分割更適合評估蚜蟲侵擾。

##### **Accelerating Speculative Decoding using Dynamic Speculation Length**
2405.04304v1 by Jonathan Mamou, Oren Pereg, Daniel Korat, Moshe Berchansky, Nadav Timor, Moshe Wasserblat, Roy Schwartz

Speculative decoding is a promising method for reducing the inference latency
of large language models. The effectiveness of the method depends on the
speculation length (SL) - the number of tokens generated by the draft model at
each iteration. The vast majority of speculative decoding approaches use the
same SL for all iterations. In this work, we show that this practice is
suboptimal. We introduce DISCO, a DynamIc SpeCulation length Optimization
method that uses a classifier to dynamically adjust the SL at each iteration,
while provably preserving the decoding quality. Experiments with four
benchmarks demonstrate average speedup gains of 10.3% relative to our best
baselines.

摘要：推測解碼是一種有望降低大型語言模型推論延遲的方法。此方法的有效性取決於推測長度 (SL)，也就是草稿模型在每個反覆運算中產生的符號數量。絕大多數的推測解碼方法對所有反覆運算使用相同的 SL。在這項工作中，我們證明這種做法次於最佳。我們推出 DISCO，一種動態推測長度最佳化方法，它使用分類器在每次反覆運算中動態調整 SL，同時可證明保留解碼品質。使用四個基準進行的實驗顯示，相較於我們最佳的基準，平均加速增益為 10.3%。

##### **Behaviour Planning: A Toolkit for Diverse Planning**
2405.04300v1 by Mustafa F Abdelwahed, Joan Espasa, Alice Toniolo, Ian P. Gent

Diverse planning is the problem of generating plans with distinct
characteristics. This is valuable for many real-world scenarios, including
applications related to plan recognition and business process automation. In
this work, we introduce \emph{Behaviour Planning}, a diverse planning toolkit
that can characterise and generate diverse plans based on modular diversity
models. We present a qualitative framework for describing diversity models, a
planning approach for generating plans aligned with any given diversity model,
and provide a practical implementation of an SMT-based behaviour planner. We
showcase how the qualitative approach offered by Behaviour Planning allows it
to overcome various challenges faced by previous approaches. Finally, the
experimental evaluation shows the effectiveness of Behaviour Planning in
generating diverse plans compared to state-of-the-art approaches.

摘要：多樣化規劃是產生具有不同特性的計劃的問題。這對於許多真實世界的場景很有價值，包括與計劃識別和業務流程自動化相關的應用。在這項工作中，我們介紹了「行為規劃」，這是一個多樣化的規劃工具包，可以根據模組化多樣性模型來表徵和產生多樣化的計劃。我們提出了描述多樣性模型的定性框架，一種用於產生與任何給定多樣性模型一致的計劃的規劃方法，並提供了基於 SMT 的行為規劃器的實際實現。我們展示了行為規劃所提供的定性方法如何讓它克服先前方法所面臨的各種挑戰。最後，實驗評估顯示了行為規劃在產生多樣化計劃方面與最先進的方法相比的有效性。

##### **Enhancing the Efficiency and Accuracy of Underlying Asset Reviews in Structured Finance: The Application of Multi-agent Framework**
2405.04294v1 by Xiangpeng Wan, Haicheng Deng, Kai Zou, Shiqi Xu

Structured finance, which involves restructuring diverse assets into
securities like MBS, ABS, and CDOs, enhances capital market efficiency but
presents significant due diligence challenges. This study explores the
integration of artificial intelligence (AI) with traditional asset review
processes to improve efficiency and accuracy in structured finance. Using both
open-sourced and close-sourced large language models (LLMs), we demonstrate
that AI can automate the verification of information between loan applications
and bank statements effectively. While close-sourced models such as GPT-4 show
superior performance, open-sourced models like LLAMA3 offer a cost-effective
alternative. Dual-agent systems further increase accuracy, though this comes
with higher operational costs. This research highlights AI's potential to
minimize manual errors and streamline due diligence, suggesting a broader
application of AI in financial document analysis and risk management.

摘要：結構性融資涉及將不同資產重組為證券，例如 MBS、ABS 和 CDO，它提高了資本市場效率，但也帶來了重大的盡職調查挑戰。本研究探討了將人工智慧 (AI) 與傳統資產審查流程整合，以提高結構性融資的效率和準確性。我們使用開源和閉源大型語言模型 (LLM)，證明 AI 能夠有效自動化貸款申請和銀行對帳單之間的資訊驗證。雖然 GPT-4 等閉源模型表現優異，但 LLAMA3 等開源模型提供了具有成本效益的替代方案。雙代理系統進一步提高了準確性，儘管這會帶來更高的營運成本。本研究強調了 AI 在最大限度減少人為錯誤和簡化盡職調查方面的潛力，並表明 AI 在財務文件分析和風險管理中具有更廣泛的應用。

##### **Mitigating Clickbait: An Approach to Spoiler Generation Using Multitask Learning**
2405.04292v1 by Sayantan Pal, Souvik Das, Rohini K. Srihari

This study introduces 'clickbait spoiling', a novel technique designed to
detect, categorize, and generate spoilers as succinct text responses,
countering the curiosity induced by clickbait content. By leveraging a
multi-task learning framework, our model's generalization capabilities are
significantly enhanced, effectively addressing the pervasive issue of
clickbait. The crux of our research lies in generating appropriate spoilers, be
it a phrase, an extended passage, or multiple, depending on the spoiler type
required. Our methodology integrates two crucial techniques: a refined spoiler
categorization method and a modified version of the Question Answering (QA)
mechanism, incorporated within a multi-task learning paradigm for optimized
spoiler extraction from context. Notably, we have included fine-tuning methods
for models capable of handling longer sequences to accommodate the generation
of extended spoilers. This research highlights the potential of sophisticated
text processing techniques in tackling the omnipresent issue of clickbait,
promising an enhanced user experience in the digital realm.

摘要：本研究介紹「誘餌破壞」，一種新技術，旨在偵測、分類和產生簡潔文字回應的破壞內容，對抗誘餌內容引發的好奇心。透過利用多任務學習架構，我們模型的概化能力獲得顯著提升，有效解決誘餌的普遍問題。我們研究的重點在於產生適當的破壞內容，無論是片語、延伸段落或多重內容，視所需的破壞類型而定。我們的技術整合兩項重要的技術：精緻的破壞分類方法和問答 (QA) 機制的修改版本，在多任務學習範例中納入，以從脈絡中最佳化擷取破壞內容。值得注意的是，我們已納入微調方法，以供模型處理較長的序列，以容納延伸破壞內容的產生。本研究強調進階文字處理技術在解決無所不在的誘餌問題上的潛力，並承諾在數位領域中提升使用者體驗。

##### **Who Wrote This? The Key to Zero-Shot LLM-Generated Text Detection Is GECScore**
2405.04286v1 by Junchao Wu, Runzhe Zhan, Derek F. Wong, Shu Yang, Xuebo Liu, Lidia S. Chao, Min Zhang

The efficacy of an large language model (LLM) generated text detector depends
substantially on the availability of sizable training data. White-box zero-shot
detectors, which require no such data, are nonetheless limited by the
accessibility of the source model of the LLM-generated text. In this paper, we
propose an simple but effective black-box zero-shot detection approach,
predicated on the observation that human-written texts typically contain more
grammatical errors than LLM-generated texts. This approach entails computing
the Grammar Error Correction Score (GECScore) for the given text to distinguish
between human-written and LLM-generated text. Extensive experimental results
show that our method outperforms current state-of-the-art (SOTA) zero-shot and
supervised methods, achieving an average AUROC of 98.7% and showing strong
robustness against paraphrase and adversarial perturbation attacks.

摘要：大型語言模型 (LLM) 生成的文字偵測器的效能，在很大程度上取決於可取得大量訓練資料。白盒零次學習偵測器不需要此類資料，但仍受到 LLM 生成的文字原始模型的可取得性限制。在本文中，我們提出一個簡單但有效的黑盒零次學習偵測方法，其預設人類撰寫的文字通常包含比 LLM 生成的文字更多的語法錯誤。此方法需要計算給定文字的語法錯誤修正分數 (GECScore)，以區分人類撰寫的文字和 LLM 生成的文字。廣泛的實驗結果顯示，我們的模型優於目前最先進 (SOTA) 的零次學習和監督式方法，平均 AUROC 達到 98.7%，並在面對同義詞替換和對抗性擾動攻擊時展現出強大的穩健性。

##### **On the Foundations of Earth and Climate Foundation Models**
2405.04285v1 by Xiao Xiang Zhu, Zhitong Xiong, Yi Wang, Adam J. Stewart, Konrad Heidler, Yuanyuan Wang, Zhenghang Yuan, Thomas Dujardin, Qingsong Xu, Yilei Shi

Foundation models have enormous potential in advancing Earth and climate
sciences, however, current approaches may not be optimal as they focus on a few
basic features of a desirable Earth and climate foundation model. Crafting the
ideal Earth foundation model, we define eleven features which would allow such
a foundation model to be beneficial for any geoscientific downstream
application in an environmental- and human-centric manner.We further shed light
on the way forward to achieve the ideal model and to evaluate Earth foundation
models. What comes after foundation models? Energy efficient adaptation,
adversarial defenses, and interpretability are among the emerging directions.

摘要：基礎模型在推進地球和氣候科學方面具有巨大的潛力，然而，當前的途徑可能並非最佳，因為它們專注於理想地球和氣候基礎模型的幾個基本特徵。在制定理想的地球基礎模型時，我們定義了 11 個特徵，這些特徵將允許此類基礎模型以以環境和人類為中心的方式，對任何地球科學下游應用產生有益影響。我們進一步闡明了實現理想模型和評估地球基礎模型的途徑。基礎模型之後是什麼？節能適應、對抗性防禦和可解釋性是新興的方向。

