{"2412.17601": {"publish_time": "2024-12-23", "title": "AFANet: Adaptive Frequency-Aware Network for Weakly-Supervised Few-Shot Semantic Segmentation", "paper_summary": "Few-shot learning aims to recognize novel concepts by leveraging prior\nknowledge learned from a few samples. However, for visually intensive tasks\nsuch as few-shot semantic segmentation, pixel-level annotations are\ntime-consuming and costly. Therefore, in this paper, we utilize the more\nchallenging image-level annotations and propose an adaptive frequency-aware\nnetwork (AFANet) for weakly-supervised few-shot semantic segmentation (WFSS).\nSpecifically, we first propose a cross-granularity frequency-aware module (CFM)\nthat decouples RGB images into high-frequency and low-frequency distributions\nand further optimizes semantic structural information by realigning them.\nUnlike most existing WFSS methods using the textual information from the\nmulti-modal language-vision model, e.g., CLIP, in an offline learning manner,\nwe further propose a CLIP-guided spatial-adapter module (CSM), which performs\nspatial domain adaptive transformation on textual information through online\nlearning, thus providing enriched cross-modal semantic information for CFM.\nExtensive experiments on the Pascal-5\\textsuperscript{i} and\nCOCO-20\\textsuperscript{i} datasets demonstrate that AFANet has achieved\nstate-of-the-art performance. The code is available at\nhttps://github.com/jarch-ma/AFANet.", "paper_summary_zh": "\u5c0f\u6837\u672c\u5b66\u4e60\u65e8\u5728\u901a\u8fc7\u5229\u7528\u4ece\u5c11\u6570\u6837\u672c\u4e2d\u5b66\u5230\u7684\u5148\u9a8c\u77e5\u8bc6\u6765\u8bc6\u522b\u65b0\u6982\u5ff5\u3002\u7136\u800c\uff0c\u5bf9\u4e8e\u89c6\u89c9\u5bc6\u96c6\u578b\u4efb\u52a1\uff08\u5982\u5c0f\u6837\u672c\u8bed\u4e49\u5206\u5272\uff09\uff0c\u50cf\u7d20\u7ea7\u6ce8\u91ca\u65e2\u8017\u65f6\u53c8\u6602\u8d35\u3002\u56e0\u6b64\uff0c\u5728\u672c\u6587\u4e2d\uff0c\u6211\u4eec\u5229\u7528\u66f4\u5177\u6311\u6218\u6027\u7684\u56fe\u50cf\u7ea7\u6ce8\u91ca\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u5f31\u76d1\u7763\u5c0f\u6837\u672c\u8bed\u4e49\u5206\u5272\uff08WFSS\uff09\u7684\u81ea\u9002\u5e94\u9891\u7387\u611f\u77e5\u7f51\u7edc\uff08AFANet\uff09\u3002\u5177\u4f53\u6765\u8bf4\uff0c\u6211\u4eec\u9996\u5148\u63d0\u51fa\u4e86\u4e00\u79cd\u8de8\u7c92\u5ea6\u9891\u7387\u611f\u77e5\u6a21\u5757\uff08CFM\uff09\uff0c\u5c06 RGB \u56fe\u50cf\u89e3\u8026\u4e3a\u9ad8\u9891\u548c\u4f4e\u9891\u5206\u5e03\uff0c\u5e76\u901a\u8fc7\u91cd\u65b0\u5bf9\u9f50\u8fdb\u4e00\u6b65\u4f18\u5316\u8bed\u4e49\u7ed3\u6784\u4fe1\u606f\u3002\u4e0e\u5927\u591a\u6570\u73b0\u6709\u7684 WFSS \u65b9\u6cd5\u4e0d\u540c\uff0c\u540e\u8005\u4ee5\u79bb\u7ebf\u5b66\u4e60\u7684\u65b9\u5f0f\u4f7f\u7528\u6765\u81ea\u591a\u6a21\u6001\u8bed\u8a00\u89c6\u89c9\u6a21\u578b\uff08\u4f8b\u5982 CLIP\uff09\u7684\u6587\u672c\u4fe1\u606f\uff0c\u6211\u4eec\u8fdb\u4e00\u6b65\u63d0\u51fa\u4e86\u4e00\u79cd CLIP \u6307\u5bfc\u7684\u7a7a\u95f4\u9002\u914d\u5668\u6a21\u5757\uff08CSM\uff09\uff0c\u8be5\u6a21\u5757\u901a\u8fc7\u5728\u7ebf\u5b66\u4e60\u5bf9\u6587\u672c\u4fe1\u606f\u6267\u884c\u7a7a\u95f4\u57df\u81ea\u9002\u5e94\u53d8\u6362\uff0c\u4ece\u800c\u4e3a CFM \u63d0\u4f9b\u4e30\u5bcc\u7684\u8de8\u6a21\u6001\u8bed\u4e49\u4fe1\u606f\u3002\u5728 Pascal-5i \u548c COCO-20i \u6570\u636e\u96c6\u4e0a\u7684\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\uff0cAFANet \u5df2\u8fbe\u5230\u6700\u5148\u8fdb\u7684\u6027\u80fd\u3002\u4ee3\u7801\u53ef\u5728 https://github.com/jarch-ma/AFANet \u83b7\u5f97\u3002", "author": "Jiaqi Ma et.al.", "authors": "Jiaqi Ma, Guo-Sen Xie, Fang Zhao, Zechao Li", "id": "2412.17601v1", "paper_url": "http://arxiv.org/abs/2412.17601v1", "repo": "https://github.com/jarch-ma/AFANet"}}