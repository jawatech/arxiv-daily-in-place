{"2410.13857": {"publish_time": "2024-10-17", "title": "How Numerical Precision Affects Mathematical Reasoning Capabilities of LLMs", "paper_summary": "Despite the remarkable success of Transformer-based Large Language Models\n(LLMs) across various domains, understanding and enhancing their mathematical\ncapabilities remains a significant challenge. In this paper, we conduct a\nrigorous theoretical analysis of LLMs' mathematical abilities, with a specific\nfocus on their arithmetic performances. We identify numerical precision as a\nkey factor that influences their effectiveness in mathematical tasks. Our\nresults show that Transformers operating with low numerical precision fail to\naddress arithmetic tasks, such as iterated addition and integer multiplication,\nunless the model size grows super-polynomially with respect to the input\nlength. In contrast, Transformers with standard numerical precision can\nefficiently handle these tasks with significantly smaller model sizes. We\nfurther support our theoretical findings through empirical experiments that\nexplore the impact of varying numerical precision on arithmetic tasks,\nproviding valuable insights for improving the mathematical reasoning\ncapabilities of LLMs.", "paper_summary_zh": "\u5118\u7ba1 Transformer \u70ba\u57fa\u790e\u7684\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u5728\u5404\u500b\u9818\u57df\u90fd\u7372\u5f97\u986f\u8457\u7684\u6210\u529f\uff0c\u4f46\u4e86\u89e3\u548c\u63d0\u5347\u5b83\u5011\u7684\u6578\u5b78\u80fd\u529b\u4ecd\u7136\u662f\u4e00\u9805\u91cd\u5927\u6311\u6230\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u5c0d LLM \u7684\u6578\u5b78\u80fd\u529b\u9032\u884c\u56b4\u8b39\u7684\u7406\u8ad6\u5206\u6790\uff0c\u7279\u5225\u95dc\u6ce8\u5b83\u5011\u7684\u7b97\u8853\u8868\u73fe\u3002\u6211\u5011\u5c07\u6578\u503c\u7cbe\u5ea6\u78ba\u5b9a\u70ba\u5f71\u97ff\u5176\u5728\u6578\u5b78\u4efb\u52d9\u4e2d\u6709\u6548\u6027\u7684\u95dc\u9375\u56e0\u7d20\u3002\u6211\u5011\u7684\u7d50\u679c\u986f\u793a\uff0c\u4f7f\u7528\u4f4e\u6578\u503c\u7cbe\u5ea6\u7684 Transformer \u7121\u6cd5\u89e3\u6c7a\u7b97\u8853\u4efb\u52d9\uff0c\u4f8b\u5982\u53cd\u8986\u52a0\u6cd5\u548c\u6574\u6578\u4e58\u6cd5\uff0c\u9664\u975e\u6a21\u578b\u5927\u5c0f\u76f8\u5c0d\u65bc\u8f38\u5165\u9577\u5ea6\u5448\u8d85\u591a\u9805\u5f0f\u589e\u9577\u3002\u76f8\u53cd\u5730\uff0c\u5177\u6709\u6a19\u6e96\u6578\u503c\u7cbe\u5ea6\u7684 Transformer \u53ef\u4ee5\u4f7f\u7528\u986f\u8457\u66f4\u5c0f\u7684\u6a21\u578b\u5927\u5c0f\u6709\u6548\u8655\u7406\u9019\u4e9b\u4efb\u52d9\u3002\u6211\u5011\u9032\u4e00\u6b65\u900f\u904e\u5be6\u8b49\u5be6\u9a57\u652f\u6301\u6211\u5011\u7684\u7406\u8ad6\u767c\u73fe\uff0c\u63a2\u8a0e\u4e0d\u540c\u6578\u503c\u7cbe\u5ea6\u5c0d\u7b97\u8853\u4efb\u52d9\u7684\u5f71\u97ff\uff0c\u70ba\u63d0\u5347 LLM \u7684\u6578\u5b78\u63a8\u7406\u80fd\u529b\u63d0\u4f9b\u6709\u50f9\u503c\u7684\u898b\u89e3\u3002", "author": "Guhao Feng et.al.", "authors": "Guhao Feng, Kai Yang, Yuntian Gu, Xinyue Ai, Shengjie Luo, Jiacheng Sun, Di He, Zhenguo Li, Liwei Wang", "id": "2410.13857v1", "paper_url": "http://arxiv.org/abs/2410.13857v1", "repo": "null"}}