{"2302.03033": {"publish_time": "2023-01-18", "title": "Exemplars and Counterexemplars Explanations for Image Classifiers, Targeting Skin Lesion Labeling", "paper_summary": "Explainable AI consists in developing mechanisms allowing for an interaction\nbetween decision systems and humans by making the decisions of the formers\nunderstandable. This is particularly important in sensitive contexts like in\nthe medical domain. We propose a use case study, for skin lesion diagnosis,\nillustrating how it is possible to provide the practitioner with explanations\non the decisions of a state of the art deep neural network classifier trained\nto characterize skin lesions from examples. Our framework consists of a trained\nclassifier onto which an explanation module operates. The latter is able to\noffer the practitioner exemplars and counterexemplars for the classification\ndiagnosis thus allowing the physician to interact with the automatic diagnosis\nsystem. The exemplars are generated via an adversarial autoencoder. We\nillustrate the behavior of the system on representative examples.", "paper_summary_zh": "", "author": "Carlo Metta et.al.", "authors": "Carlo Metta,Riccardo Guidotti,Yuan Yin,Patrick Gallinari,Salvatore Rinzivillo", "id": "2302.03033v1", "paper_url": "http://arxiv.org/abs/2302.03033v1", "repo": "null"}}