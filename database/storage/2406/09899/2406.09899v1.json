{"2406.09899": {"publish_time": "2024-06-14", "title": "Learning Solution-Aware Transformers for Efficiently Solving Quadratic Assignment Problem", "paper_summary": "Recently various optimization problems, such as Mixed Integer Linear\nProgramming Problems (MILPs), have undergone comprehensive investigation,\nleveraging the capabilities of machine learning. This work focuses on\nlearning-based solutions for efficiently solving the Quadratic Assignment\nProblem (QAPs), which stands as a formidable challenge in combinatorial\noptimization. While many instances of simpler problems admit fully\npolynomial-time approximate solution (FPTAS), QAP is shown to be strongly\nNP-hard. Even finding a FPTAS for QAP is difficult, in the sense that the\nexistence of a FPTAS implies $P = NP$. Current research on QAPs suffer from\nlimited scale and computational inefficiency. To attack the aforementioned\nissues, we here propose the first solution of its kind for QAP in the\nlearn-to-improve category. This work encodes facility and location nodes\nseparately, instead of forming computationally intensive association graphs\nprevalent in current approaches. This design choice enables scalability to\nlarger problem sizes. Furthermore, a \\textbf{S}olution \\textbf{AW}are\n\\textbf{T}ransformer (SAWT) architecture integrates the incumbent solution\nmatrix with the attention score to effectively capture higher-order information\nof the QAPs. Our model's effectiveness is validated through extensive\nexperiments on self-generated QAP instances of varying sizes and the QAPLIB\nbenchmark.", "paper_summary_zh": "\u6700\u8fd1\u5404\u7a2e\u6700\u4f73\u5316\u554f\u984c\uff0c\u4f8b\u5982\u6df7\u5408\u6574\u6578\u7dda\u6027\u898f\u5283\u554f\u984c (MILP)\uff0c\u5df2\u7d93\u7d93\u904e\u5168\u9762\u7684\u7814\u7a76\uff0c\u5229\u7528\u6a5f\u5668\u5b78\u7fd2\u7684\u80fd\u529b\u3002\u9019\u9805\u5de5\u4f5c\u5c08\u6ce8\u65bc\u57fa\u65bc\u5b78\u7fd2\u7684\u89e3\u6c7a\u65b9\u6848\uff0c\u4ee5\u6709\u6548\u89e3\u6c7a\u4e8c\u6b21\u6307\u6d3e\u554f\u984c (QAP)\uff0c\u9019\u5728\u7d44\u5408\u6700\u4f73\u5316\u4e2d\u662f\u4e00\u500b\u8271\u9245\u7684\u6311\u6230\u3002\u5118\u7ba1\u8a31\u591a\u8f03\u7c21\u55ae\u554f\u984c\u7684\u5be6\u4f8b\u627f\u8a8d\u5b8c\u5168\u591a\u9805\u5f0f\u6642\u9593\u8fd1\u4f3c\u89e3 (FPTAS)\uff0c\u4f46 QAP \u5df2\u88ab\u8b49\u660e\u662f\u5f37 NP-hard\u3002\u5373\u4f7f\u627e\u5230 QAP \u7684 FPTAS \u4e5f\u5f88\u56f0\u96e3\uff0c\u56e0\u70ba FPTAS \u7684\u5b58\u5728\u610f\u5473\u8457 $P = NP$\u3002\u76ee\u524d\u5c0d QAP \u7684\u7814\u7a76\u53d7\u5230\u898f\u6a21\u6709\u9650\u548c\u8a08\u7b97\u6548\u7387\u4f4e\u4e0b\u7684\u56f0\u64fe\u3002\u70ba\u4e86\u89e3\u6c7a\u4e0a\u8ff0\u554f\u984c\uff0c\u6211\u5011\u5728\u6b64\u63d0\u51fa QAP \u5728\u5b78\u7fd2\u6539\u9032\u985e\u5225\u4e2d\u7684\u7b2c\u4e00\u500b\u6b64\u985e\u89e3\u6c7a\u65b9\u6848\u3002\u9019\u9805\u5de5\u4f5c\u5206\u5225\u7de8\u78bc\u8a2d\u65bd\u548c\u4f4d\u7f6e\u7bc0\u9ede\uff0c\u800c\u4e0d\u662f\u5f62\u6210\u7576\u524d\u65b9\u6cd5\u4e2d\u666e\u904d\u5b58\u5728\u7684\u8a08\u7b97\u5bc6\u96c6\u578b\u95dc\u806f\u5716\u3002\u9019\u7a2e\u8a2d\u8a08\u9078\u64c7\u4f7f\u53ef\u64f4\u5c55\u6027\u9054\u5230\u66f4\u5927\u7684\u554f\u984c\u898f\u6a21\u3002\u6b64\u5916\uff0c\\textbf{S}olution \\textbf{AW}are \\textbf{T}ransformer (SAWT) \u67b6\u69cb\u5c07\u73fe\u6709\u89e3\u77e9\u9663\u8207\u6ce8\u610f\u529b\u5206\u6578\u6574\u5408\u5728\u4e00\u8d77\uff0c\u4ee5\u6709\u6548\u6355\u6349 QAP \u7684\u9ad8\u968e\u8cc7\u8a0a\u3002\u6211\u5011\u7684\u6a21\u578b\u7684\u6709\u6548\u6027\u901a\u904e\u5728\u5404\u7a2e\u5927\u5c0f\u7684\u81ea\u6211\u751f\u6210 QAP \u5be6\u4f8b\u548c QAPLIB \u57fa\u6e96\u4e0a\u9032\u884c\u5ee3\u6cdb\u7684\u5be6\u9a57\u5f97\u5230\u9a57\u8b49\u3002", "author": "Zhentao Tan et.al.", "authors": "Zhentao Tan, Yadong Mu", "id": "2406.09899v1", "paper_url": "http://arxiv.org/abs/2406.09899v1", "repo": "https://github.com/pkutan/sawt"}}