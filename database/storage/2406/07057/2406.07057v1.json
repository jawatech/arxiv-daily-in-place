{"2406.07057": {"publish_time": "2024-06-11", "title": "Benchmarking Trustworthiness of Multimodal Large Language Models: A Comprehensive Study", "paper_summary": "Despite the superior capabilities of Multimodal Large Language Models (MLLMs)\nacross diverse tasks, they still face significant trustworthiness challenges.\nYet, current literature on the assessment of trustworthy MLLMs remains limited,\nlacking a holistic evaluation to offer thorough insights into future\nimprovements. In this work, we establish MultiTrust, the first comprehensive\nand unified benchmark on the trustworthiness of MLLMs across five primary\naspects: truthfulness, safety, robustness, fairness, and privacy. Our benchmark\nemploys a rigorous evaluation strategy that addresses both multimodal risks and\ncross-modal impacts, encompassing 32 diverse tasks with self-curated datasets.\nExtensive experiments with 21 modern MLLMs reveal some previously unexplored\ntrustworthiness issues and risks, highlighting the complexities introduced by\nthe multimodality and underscoring the necessity for advanced methodologies to\nenhance their reliability. For instance, typical proprietary models still\nstruggle with the perception of visually confusing images and are vulnerable to\nmultimodal jailbreaking and adversarial attacks; MLLMs are more inclined to\ndisclose privacy in text and reveal ideological and cultural biases even when\npaired with irrelevant images in inference, indicating that the multimodality\namplifies the internal risks from base LLMs. Additionally, we release a\nscalable toolbox for standardized trustworthiness research, aiming to\nfacilitate future advancements in this important field. Code and resources are\npublicly available at: https://multi-trust.github.io/.", "paper_summary_zh": "\u5118\u7ba1\u591a\u6a21\u614b\u5927\u578b\u8a9e\u8a00\u6a21\u578b (MMLM) \u5728\u5404\u7a2e\u4efb\u52d9\u4e2d\u5177\u5099\u512a\u7570\u7684\u80fd\u529b\uff0c\u4f46\u5b83\u5011\u4ecd\u9762\u81e8\u91cd\u5927\u7684\u53ef\u4fe1\u5ea6\u6311\u6230\u3002\u7136\u800c\uff0c\u76ee\u524d\u95dc\u65bc\u53ef\u4fe1 MMLM \u8a55\u4f30\u7684\u6587\u737b\u4ecd\u7136\u6709\u9650\uff0c\u7f3a\u4e4f\u5168\u9762\u7684\u8a55\u4f30\u4f86\u63d0\u4f9b\u5c0d\u672a\u4f86\u6539\u9032\u7684\u6df1\u5165\u898b\u89e3\u3002\u5728\u9019\u9805\u5de5\u4f5c\u4e2d\uff0c\u6211\u5011\u5efa\u7acb\u4e86 MultiTrust\uff0c\u9019\u662f\u7b2c\u4e00\u500b\u91dd\u5c0d MMLM \u53ef\u4fe1\u5ea6\u7684\u5168\u9762\u4e14\u7d71\u4e00\u7684\u57fa\u6e96\uff0c\u6db5\u84cb\u4e94\u500b\u4e3b\u8981\u65b9\u9762\uff1a\u771f\u5be6\u6027\u3001\u5b89\u5168\u6027\u3001\u5065\u58ef\u6027\u3001\u516c\u5e73\u6027\u548c\u96b1\u79c1\u3002\u6211\u5011\u7684\u57fa\u6e96\u63a1\u7528\u56b4\u683c\u7684\u8a55\u4f30\u7b56\u7565\uff0c\u89e3\u6c7a\u4e86\u591a\u6a21\u614b\u98a8\u96aa\u548c\u8de8\u6a21\u614b\u5f71\u97ff\uff0c\u5305\u542b 32 \u9805\u4f7f\u7528\u81ea\u8a02\u8cc7\u6599\u96c6\u7684\u591a\u5143\u4efb\u52d9\u3002\u4f7f\u7528 21 \u500b\u73fe\u4ee3 MLLM \u9032\u884c\u7684\u5ee3\u6cdb\u5be6\u9a57\u63ed\u793a\u4e86\u4e00\u4e9b\u5148\u524d\u672a\u63a2\u7d22\u7684\u53ef\u4fe1\u5ea6\u554f\u984c\u548c\u98a8\u96aa\uff0c\u7a81\u986f\u4e86\u591a\u6a21\u614b\u6027\u5e36\u4f86\u7684\u8907\u96dc\u6027\uff0c\u4e26\u5f37\u8abf\u4e86\u63a1\u7528\u5148\u9032\u65b9\u6cd5\u4ee5\u589e\u5f37\u5176\u53ef\u9760\u6027\u7684\u5fc5\u8981\u6027\u3002\u4f8b\u5982\uff0c\u5178\u578b\u7684\u5c08\u6709\u6a21\u578b\u4ecd\u7136\u96e3\u4ee5\u8fa8\u8b58\u8996\u89ba\u4e0a\u4ee4\u4eba\u56f0\u60d1\u7684\u5f71\u50cf\uff0c\u4e26\u4e14\u5bb9\u6613\u53d7\u5230\u591a\u6a21\u614b\u8d8a\u7344\u548c\u5c0d\u6297\u6027\u653b\u64ca\uff1bMMLM \u66f4\u50be\u5411\u65bc\u5728\u6587\u5b57\u4e2d\u63ed\u9732\u96b1\u79c1\uff0c\u4e26\u5728\u63a8\u8ad6\u4e2d\u8207\u7121\u95dc\u7684\u5f71\u50cf\u914d\u5c0d\u6642\u63ed\u9732\u610f\u8b58\u5f62\u614b\u548c\u6587\u5316\u504f\u898b\uff0c\u9019\u8868\u793a\u591a\u6a21\u614b\u6027\u653e\u5927\u4e86\u57fa\u790e LLM \u7684\u5167\u90e8\u98a8\u96aa\u3002\u6b64\u5916\uff0c\u6211\u5011\u767c\u5e03\u4e86\u4e00\u500b\u53ef\u64f4\u5145\u7684\u5de5\u5177\u7bb1\uff0c\u7528\u65bc\u6a19\u6e96\u5316\u7684\u53ef\u4fe1\u5ea6\u7814\u7a76\uff0c\u65e8\u5728\u4fc3\u9032\u9019\u500b\u91cd\u8981\u9818\u57df\u7684\u672a\u4f86\u9032\u5c55\u3002\u7a0b\u5f0f\u78bc\u548c\u8cc7\u6e90\u516c\u958b\u65bc\uff1ahttps://multi-trust.github.io/\u3002", "author": "Yichi Zhang et.al.", "authors": "Yichi Zhang, Yao Huang, Yitong Sun, Chang Liu, Zhe Zhao, Zhengwei Fang, Yifan Wang, Huanran Chen, Xiao Yang, Xingxing Wei, Hang Su, Yinpeng Dong, Jun Zhu", "id": "2406.07057v1", "paper_url": "http://arxiv.org/abs/2406.07057v1", "repo": "null"}}