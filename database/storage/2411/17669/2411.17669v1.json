{"2411.17669": {"publish_time": "2024-11-26", "title": "Linguistic Laws Meet Protein Sequences: A Comparative Analysis of Subword Tokenization Methods", "paper_summary": "Tokenization is a crucial step in processing protein sequences for machine\nlearning models, as proteins are complex sequences of amino acids that require\nmeaningful segmentation to capture their functional and structural properties.\nHowever, existing subword tokenization methods, developed primarily for human\nlanguage, may be inadequate for protein sequences, which have unique patterns\nand constraints. This study evaluates three prominent tokenization approaches,\nByte-Pair Encoding (BPE), WordPiece, and SentencePiece, across varying\nvocabulary sizes (400-6400), analyzing their effectiveness in protein sequence\nrepresentation, domain boundary preservation, and adherence to established\nlinguistic laws. Our comprehensive analysis reveals distinct behavioral\npatterns among these tokenizers, with vocabulary size significantly influencing\ntheir performance. BPE demonstrates better contextual specialization and\nmarginally better domain boundary preservation at smaller vocabularies, while\nSentencePiece achieves better encoding efficiency, leading to lower fertility\nscores. WordPiece offers a balanced compromise between these characteristics.\nHowever, all tokenizers show limitations in maintaining protein domain\nintegrity, particularly as vocabulary size increases. Analysis of linguistic\nlaw adherence shows partial compliance with Zipf's and Brevity laws but notable\ndeviations from Menzerath's law, suggesting that protein sequences may follow\ndistinct organizational principles from natural languages. These findings\nhighlight the limitations of applying traditional NLP tokenization methods to\nprotein sequences and emphasize the need for developing specialized\ntokenization strategies that better account for the unique characteristics of\nproteins.", "paper_summary_zh": "<paragraph>\u5728\u8655\u7406\u86cb\u767d\u8cea\u5e8f\u5217\u4ee5\u4f9b\u6a5f\u5668\u5b78\u7fd2\u6a21\u578b\u4f7f\u7528\u6642\uff0c\u5206\u8a5e\u662f\u4e00\u500b\u81f3\u95dc\u91cd\u8981\u7684\u6b65\u9a5f\uff0c\u56e0\u70ba\u86cb\u767d\u8cea\u662f\u8907\u96dc\u7684\u80fa\u57fa\u9178\u5e8f\u5217\uff0c\u9700\u8981\u6709\u610f\u7fa9\u7684\u5206\u6bb5\u624d\u80fd\u6355\u6349\u5176\u529f\u80fd\u548c\u7d50\u69cb\u7279\u6027\u3002\n\u7136\u800c\uff0c\u73fe\u6709\u7684\u5b50\u8a5e\u5206\u8a5e\u65b9\u6cd5\u4e3b\u8981\u70ba\u4eba\u985e\u8a9e\u8a00\u800c\u958b\u767c\uff0c\u53ef\u80fd\u4e0d\u9069\u5408\u86cb\u767d\u8cea\u5e8f\u5217\uff0c\u56e0\u70ba\u86cb\u767d\u8cea\u5e8f\u5217\u6709\u7368\u7279\u7684\u6a21\u5f0f\u548c\u7d04\u675f\u3002\u672c\u7814\u7a76\u8a55\u4f30\u4e86\u4e09\u7a2e\u4e3b\u8981\u7684\u6a19\u8a18\u5316\u65b9\u6cd5\uff0c\u5373\u4f4d\u5143\u7d44\u5c0d\u7de8\u78bc (BPE)\u3001WordPiece \u548c SentencePiece\uff0c\u5728\u4e0d\u540c\u7684\u8a5e\u5f59\u5927\u5c0f (400-6400) \u4e2d\uff0c\u5206\u6790\u5b83\u5011\u5728\u86cb\u767d\u8cea\u5e8f\u5217\u8868\u793a\u3001\u7db2\u57df\u908a\u754c\u4fdd\u7559\u548c\u5c0d\u5df2\u5efa\u7acb\u8a9e\u8a00\u5b9a\u5f8b\u7684\u9075\u5b88\u65b9\u9762\u7684\u6709\u6548\u6027\u3002\u6211\u5011\u5168\u9762\u7684\u5206\u6790\u63ed\u793a\u4e86\u9019\u4e9b\u6a19\u8a18\u5668\u4e4b\u9593\u4e0d\u540c\u7684\u884c\u70ba\u6a21\u5f0f\uff0c\u8a5e\u5f59\u5927\u5c0f\u986f\u8457\u5f71\u97ff\u5176\u6027\u80fd\u3002BPE \u5728\u8f03\u5c0f\u7684\u8a5e\u5f59\u4e2d\u8868\u73fe\u51fa\u66f4\u597d\u7684\u4e0a\u4e0b\u6587\u5c08\u696d\u5316\u548c\u7565\u5fae\u66f4\u597d\u7684\u7db2\u57df\u908a\u754c\u4fdd\u7559\uff0c\u800c SentencePiece \u5247\u5be6\u73fe\u4e86\u66f4\u597d\u7684\u7de8\u78bc\u6548\u7387\uff0c\u5c0e\u81f4\u8f03\u4f4e\u7684\u751f\u80b2\u7387\u5206\u6578\u3002WordPiece \u5728\u9019\u4e9b\u7279\u5fb5\u4e4b\u9593\u63d0\u4f9b\u4e86\u5e73\u8861\u7684\u6298\u8877\u3002\n\u7136\u800c\uff0c\u6240\u6709\u6a19\u8a18\u5668\u5728\u7dad\u8b77\u86cb\u767d\u8cea\u7db2\u57df\u5b8c\u6574\u6027\u65b9\u9762\u90fd\u8868\u73fe\u51fa\u5c40\u9650\u6027\uff0c\u7279\u5225\u662f\u96a8\u8457\u8a5e\u5f59\u5927\u5c0f\u7684\u589e\u52a0\u3002\u5c0d\u8a9e\u8a00\u5b9a\u5f8b\u9075\u5b88\u60c5\u6cc1\u7684\u5206\u6790\u986f\u793a\u90e8\u5206\u7b26\u5408\u9f4a\u592b\u5b9a\u5f8b\u548c\u7c21\u6f54\u5b9a\u5f8b\uff0c\u4f46\u660e\u986f\u504f\u96e2\u9580\u6fa4\u62c9\u7279\u5b9a\u5f8b\uff0c\u9019\u8868\u660e\u86cb\u767d\u8cea\u5e8f\u5217\u53ef\u80fd\u9075\u5faa\u8207\u81ea\u7136\u8a9e\u8a00\u4e0d\u540c\u7684\u7d44\u7e54\u539f\u5247\u3002\u9019\u4e9b\u767c\u73fe\u5f37\u8abf\u4e86\u5c07\u50b3\u7d71 NLP \u6a19\u8a18\u5316\u65b9\u6cd5\u61c9\u7528\u65bc\u86cb\u767d\u8cea\u5e8f\u5217\u7684\u5c40\u9650\u6027\uff0c\u4e26\u5f37\u8abf\u4e86\u958b\u767c\u5c08\u9580\u7684\u6a19\u8a18\u5316\u7b56\u7565\u7684\u5fc5\u8981\u6027\uff0c\u9019\u4e9b\u7b56\u7565\u53ef\u4ee5\u66f4\u597d\u5730\u8aaa\u660e\u86cb\u767d\u8cea\u7684\u7368\u7279\u7279\u5fb5\u3002</paragraph>", "author": "Burak Suyunu et.al.", "authors": "Burak Suyunu, Enes Taylan, Arzucan \u00d6zg\u00fcr", "id": "2411.17669v1", "paper_url": "http://arxiv.org/abs/2411.17669v1", "repo": "https://github.com/boun-tabi-lifelu/linguistics-meet-proteins"}}