{"2501.08528": {"publish_time": "2025-01-15", "title": "Dynamic Portfolio Optimization via Augmented DDPG with Quantum Price Levels-Based Trading Strategy", "paper_summary": "With the development of deep learning, Dynamic Portfolio Optimization (DPO)\nproblem has received a lot of attention in recent years, not only in the field\nof finance but also in the field of deep learning. Some advanced research in\nrecent years has proposed the application of Deep Reinforcement Learning (DRL)\nto the DPO problem, which demonstrated to be more advantageous than supervised\nlearning in solving the DPO problem. However, there are still certain unsolved\nissues: 1) DRL algorithms usually have the problems of slow learning speed and\nhigh sample complexity, which is especially problematic when dealing with\ncomplex financial data. 2) researchers use DRL simply for the purpose of\nobtaining high returns, but pay little attention to the problem of risk control\nand trading strategy, which will affect the stability of model returns. In\norder to address these issues, in this study we revamped the intrinsic\nstructure of the model based on the Deep Deterministic Policy Gradient (DDPG)\nand proposed the Augmented DDPG model. Besides, we also proposed an innovative\nrisk control strategy based on Quantum Price Levels (QPLs) derived from Quantum\nFinance Theory (QFT). Our experimental results revealed that our model has\nbetter profitability as well as risk control ability with less sample\ncomplexity in the DPO problem compared to the baseline models.", "paper_summary_zh": "<paragraph>\u96a8\u8457\u6df1\u5ea6\u5b78\u7fd2\u7684\u767c\u5c55\uff0c\u52d5\u614b\u6295\u8cc7\u7d44\u5408\u6700\u4f73\u5316\uff08DPO\uff09\u554f\u984c\u8fd1\u5e74\u4f86\u53d7\u5230\u5ee3\u6cdb\u95dc\u6ce8\uff0c\u4e0d\u50c5\u5728\u91d1\u878d\u9818\u57df\uff0c\u4e5f\u5728\u6df1\u5ea6\u5b78\u7fd2\u9818\u57df\u3002\u8fd1\u5e74\u4f86\u4e00\u4e9b\u9032\u968e\u7684\u7814\u7a76\u63d0\u51fa\u5c07\u6df1\u5ea6\u5f37\u5316\u5b78\u7fd2\uff08DRL\uff09\u61c9\u7528\u65bc DPO \u554f\u984c\uff0c\u8b49\u660e\u6bd4\u76e3\u7763\u5f0f\u5b78\u7fd2\u5728\u89e3\u6c7a DPO \u554f\u984c\u4e0a\u66f4\u6709\u512a\u52e2\u3002\u7136\u800c\uff0c\u4ecd\u5b58\u5728\u4e00\u4e9b\u672a\u89e3\u6c7a\u7684\u554f\u984c\uff1a1\uff09DRL \u6f14\u7b97\u6cd5\u901a\u5e38\u6709\u5b78\u7fd2\u901f\u5ea6\u6162\u3001\u6a23\u672c\u8907\u96dc\u5ea6\u9ad8\u7684\u554f\u984c\uff0c\u7279\u5225\u662f\u5728\u8655\u7406\u8907\u96dc\u7684\u91d1\u878d\u8cc7\u6599\u6642\u6703\u51fa\u73fe\u554f\u984c\u30022\uff09\u7814\u7a76\u4eba\u54e1\u4f7f\u7528 DRL \u50c5\u50c5\u662f\u70ba\u4e86\u7372\u5f97\u9ad8\u5831\u916c\uff0c\u4f46\u8f03\u5c11\u95dc\u6ce8\u98a8\u96aa\u63a7\u7ba1\u548c\u4ea4\u6613\u7b56\u7565\u7684\u554f\u984c\uff0c\u9019\u5c07\u5f71\u97ff\u6a21\u578b\u5831\u916c\u7684\u7a69\u5b9a\u6027\u3002\u70ba\u4e86\u89e3\u6c7a\u9019\u4e9b\u554f\u984c\uff0c\u672c\u7814\u7a76\u4ee5\u6df1\u5ea6\u78ba\u5b9a\u6027\u7b56\u7565\u68af\u5ea6\uff08DDPG\uff09\u70ba\u57fa\u790e\uff0c\u6539\u9020\u4e86\u6a21\u578b\u7684\u5167\u5728\u7d50\u69cb\uff0c\u4e26\u63d0\u51fa\u4e86\u64f4\u589e DDPG \u6a21\u578b\u3002\u6b64\u5916\uff0c\u6211\u5011\u9084\u63d0\u51fa\u4e86\u4e00\u7a2e\u5275\u65b0\u7684\u98a8\u96aa\u63a7\u7ba1\u7b56\u7565\uff0c\u8a72\u7b56\u7565\u57fa\u65bc\u91cf\u5b50\u91d1\u878d\u7406\u8ad6\uff08QFT\uff09\u884d\u751f\u7684\u91cf\u5b50\u50f9\u683c\u6c34\u6e96\uff08QPL\uff09\u3002\u6211\u5011\u7684\u5be6\u9a57\u7d50\u679c\u986f\u793a\uff0c\u8207\u57fa\u7dda\u6a21\u578b\u76f8\u6bd4\uff0c\u6211\u5011\u7684\u6a21\u578b\u5728 DPO \u554f\u984c\u4e0a\u5177\u6709\u66f4\u597d\u7684\u7372\u5229\u80fd\u529b\u548c\u98a8\u96aa\u63a7\u7ba1\u80fd\u529b\uff0c\u4e14\u6a23\u672c\u8907\u96dc\u5ea6\u8f03\u4f4e\u3002</paragraph>", "author": "Runsheng Lin et.al.", "authors": "Runsheng Lin, Zihan Xing, Mingze Ma, Raymond S. T. Lee", "id": "2501.08528v1", "paper_url": "http://arxiv.org/abs/2501.08528v1", "repo": "null"}}