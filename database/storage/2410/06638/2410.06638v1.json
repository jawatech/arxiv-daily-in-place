{"2410.06638": {"publish_time": "2024-10-09", "title": "Subtle Errors Matter: Preference Learning via Error-injected Self-editing", "paper_summary": "Large Language Models (LLMs) have exhibited strong mathematical reasoning and\ncomputational prowess, tackling tasks ranging from basic arithmetic to advanced\ncompetition-level problems. However, frequently occurring subtle errors, such\nas miscalculations or incorrect substitutions, limit the models' full\nmathematical potential. Existing studies to improve mathematical ability\ntypically involve distilling reasoning skills from stronger LLMs or applying\npreference learning to step-wise response pairs. Although these methods\nleverage samples of varying granularity to mitigate reasoning errors, they\noverlook the frequently occurring subtle errors. A major reason is that sampled\npreference pairs involve differences unrelated to the errors, which may\ndistract the model from focusing on subtle errors. In this work, we propose a\nnovel preference learning framework called eRror-Injected Self-Editing (RISE),\nwhich injects predefined subtle errors into partial tokens of correct solutions\nto construct hard pairs for error mitigation. In detail, RISE uses the model\nitself to edit a small number of tokens in the solution, injecting designed\nsubtle errors. Then, pairs composed of self-edited solutions and their\ncorresponding correct ones, along with pairs of correct and incorrect solutions\nobtained through sampling, are used together for subtle error-aware DPO\ntraining. Compared with other preference learning methods, RISE further refines\nthe training objective to focus on predefined errors and their tokens, without\nrequiring fine-grained sampling or preference annotation. Extensive experiments\nvalidate the effectiveness of RISE, with preference learning on\nQwen2-7B-Instruct yielding notable improvements of 3.0% on GSM8K and 7.9% on\nMATH.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u5c55\u73fe\u5f37\u5927\u7684\u6578\u5b78\u63a8\u7406\u80fd\u529b\u548c\u8a08\u7b97\u5be6\u529b\uff0c\u80fd\u8655\u7406\u5f9e\u57fa\u672c\u7b97\u8853\u5230\u9032\u968e\u7af6\u8cfd\u7b49\u7d1a\u554f\u984c\u7684\u5404\u7a2e\u4efb\u52d9\u3002\u7136\u800c\uff0c\u7d93\u5e38\u767c\u751f\u7684\u7d30\u5fae\u932f\u8aa4\uff0c\u4f8b\u5982\u8a08\u7b97\u932f\u8aa4\u6216\u4e0d\u6b63\u78ba\u7684\u66ff\u63db\uff0c\u9650\u5236\u4e86\u6a21\u578b\u7684\u5b8c\u6574\u6578\u5b78\u6f5b\u529b\u3002\u73fe\u6709\u7684\u7814\u7a76\u7528\u65bc\u63d0\u5347\u6578\u5b78\u80fd\u529b\u901a\u5e38\u6d89\u53ca\u5f9e\u66f4\u5f37\u5927\u7684 LLM \u4e2d\u8403\u53d6\u63a8\u7406\u6280\u80fd\uff0c\u6216\u5c07\u504f\u597d\u5b78\u7fd2\u61c9\u7528\u65bc\u9010\u6b65\u56de\u61c9\u914d\u5c0d\u3002\u5118\u7ba1\u9019\u4e9b\u65b9\u6cd5\u5229\u7528\u4e0d\u540c\u7c92\u5ea6\u7684\u7bc4\u672c\u4f86\u6e1b\u8f15\u63a8\u7406\u932f\u8aa4\uff0c\u4f46\u5b83\u5011\u5ffd\u7565\u4e86\u7d93\u5e38\u767c\u751f\u7684\u7d30\u5fae\u932f\u8aa4\u3002\u4e3b\u8981\u539f\u56e0\u662f\u53d6\u6a23\u7684\u504f\u597d\u914d\u5c0d\u6d89\u53ca\u8207\u932f\u8aa4\u7121\u95dc\u7684\u5dee\u7570\uff0c\u9019\u53ef\u80fd\u6703\u5206\u6563\u6a21\u578b\u5c0d\u7d30\u5fae\u932f\u8aa4\u7684\u95dc\u6ce8\u3002\u5728\u9019\u9805\u5de5\u4f5c\u4e2d\uff0c\u6211\u5011\u63d0\u51fa\u4e00\u500b\u540d\u70ba eRror-Injected Self-Editing (RISE) \u7684\u65b0\u504f\u597d\u5b78\u7fd2\u67b6\u69cb\uff0c\u5b83\u5c07\u9810\u5b9a\u7fa9\u7684\u7d30\u5fae\u932f\u8aa4\u6ce8\u5165\u6b63\u78ba\u89e3\u7b54\u7684\u90e8\u5206\u4ee3\u5e63\u4e2d\uff0c\u4ee5\u5efa\u69cb\u96e3\u914d\u5c0d\u4f86\u6e1b\u8f15\u932f\u8aa4\u3002\u8a73\u7d30\u4f86\u8aaa\uff0cRISE \u4f7f\u7528\u6a21\u578b\u672c\u8eab\u7de8\u8f2f\u89e3\u7b54\u4e2d\u5c11\u6578\u7684\u4ee3\u5e63\uff0c\u6ce8\u5165\u8a2d\u8a08\u7684\u7d30\u5fae\u932f\u8aa4\u3002\u7136\u5f8c\uff0c\u7531\u81ea\u6211\u7de8\u8f2f\u7684\u89e3\u7b54\u53ca\u5176\u5c0d\u61c9\u7684\u6b63\u78ba\u89e3\u7b54\u6240\u7d44\u6210\u7684\u914d\u5c0d\uff0c\u9023\u540c\u900f\u904e\u53d6\u6a23\u7372\u5f97\u7684\u6b63\u78ba\u548c\u4e0d\u6b63\u78ba\u89e3\u7b54\u7684\u914d\u5c0d\uff0c\u4e00\u8d77\u7528\u65bc\u5177\u5099\u7d30\u5fae\u932f\u8aa4\u611f\u77e5\u7684 DPO \u8a13\u7df4\u3002\u8207\u5176\u4ed6\u504f\u597d\u5b78\u7fd2\u65b9\u6cd5\u76f8\u6bd4\uff0cRISE \u9032\u4e00\u6b65\u6539\u5584\u8a13\u7df4\u76ee\u6a19\uff0c\u5c08\u6ce8\u65bc\u9810\u5b9a\u7fa9\u7684\u932f\u8aa4\u53ca\u5176\u4ee3\u5e63\uff0c\u800c\u4e0d\u9700\u8981\u7d30\u7c92\u5ea6\u7684\u53d6\u6a23\u6216\u504f\u597d\u8a3b\u89e3\u3002\u5ee3\u6cdb\u7684\u5be6\u9a57\u9a57\u8b49\u4e86 RISE \u7684\u6709\u6548\u6027\uff0c\u5728 Qwen2-7B-Instruct \u4e0a\u7684\u504f\u597d\u5b78\u7fd2\u7522\u751f\u986f\u8457\u7684\u9032\u6b65\uff0c\u5728 GSM8K \u4e0a\u63d0\u5347\u4e86 3.0%\uff0c\u5728 MATH \u4e0a\u63d0\u5347\u4e86 7.9%\u3002", "author": "Kaishuai Xu et.al.", "authors": "Kaishuai Xu, Tiezheng Yu, Wenjun Hou, Yi Cheng, Chak Tou Leong, Liangyou Li, Xin Jiang, Lifeng Shang, Qun Liu, Wenjie Li", "id": "2410.06638v1", "paper_url": "http://arxiv.org/abs/2410.06638v1", "repo": "null"}}