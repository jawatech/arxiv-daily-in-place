{"2408.08147": {"publish_time": "2024-08-15", "title": "P/D-Serve: Serving Disaggregated Large Language Model at Scale", "paper_summary": "Serving disaggregated large language models (LLMs) over tens of thousands of\nxPU devices (GPUs or NPUs) with reliable performance faces multiple challenges.\n1) Ignoring the diversity (various prefixes and tidal requests), treating all\nthe prompts in a mixed pool is inadequate. To facilitate the similarity per\nscenario and minimize the inner mismatch on P/D (prefill and decoding)\nprocessing, fine-grained organization is required, dynamically adjusting P/D\nratios for better performance. 2) Due to inaccurate estimation on workload\n(queue status or maintained connections), the global scheduler easily incurs\nunnecessary timeouts in prefill. 3) Block-fixed device-to-device (D2D) KVCache\ntransfer over cluster-level RDMA (remote direct memory access) fails to achieve\ndesired D2D utilization as expected. To overcome previous problems, this paper\nproposes an end-to-end system P/D-Serve, complying with the paradigm of MLOps\n(machine learning operations), which models end-to-end (E2E) P/D performance\nand enables: 1) fine-grained P/D organization, mapping the service with RoCE\n(RDMA over converged ethernet) as needed, to facilitate similar processing and\ndynamic adjustments on P/D ratios; 2) on-demand forwarding upon rejections for\nidle prefill, decoupling the scheduler from regular inaccurate reports and\nlocal queues, to avoid timeouts in prefill; and 3) efficient KVCache transfer\nvia optimized D2D access. P/D-Serve is implemented upon Ascend and MindSpore,\nhas been deployed over tens of thousands of NPUs for more than eight months in\ncommercial use, and further achieves 60\\%, 42\\% and 46\\% improvements on E2E\nthroughput, time-to-first-token (TTFT) SLO (service level objective) and D2D\ntransfer time. As the E2E system with optimizations, P/D-Serve achieves 6.7x\nincrease on throughput, compared with aggregated LLMs.", "paper_summary_zh": "<paragraph>\u5728\u6578\u842c\u500b xPU \u88dd\u7f6e\uff08GPU \u6216 NPU\uff09\u4e0a\u63d0\u4f9b\u5177\u5099\u53ef\u9760\u6548\u80fd\u7684\u5206\u6563\u5f0f\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM)\uff0c\u6703\u9762\u81e8\u591a\u9805\u6311\u6230\u30021) \u5ffd\u7565\u591a\u6a23\u6027\uff08\u5404\u7a2e\u524d\u7db4\u548c\u6f6e\u6c50\u8981\u6c42\uff09\uff0c\u5c07\u6240\u6709\u63d0\u793a\u8996\u70ba\u6df7\u5408\u6c60\u662f\u4e0d\u5920\u7684\u3002\u70ba\u4e86\u4fc3\u9032\u6bcf\u500b\u5834\u666f\u7684\u76f8\u4f3c\u6027\u4e26\u6700\u5c0f\u5316 P/D\uff08\u9810\u586b\u548c\u89e3\u78bc\uff09\u8655\u7406\u4e2d\u7684\u5167\u90e8\u4e0d\u5339\u914d\uff0c\u9700\u8981\u7d30\u7dfb\u7684\u7d44\u7e54\uff0c\u52d5\u614b\u8abf\u6574 P/D \u6bd4\u4f8b\u4ee5\u7372\u5f97\u66f4\u597d\u7684\u6548\u80fd\u30022) \u7531\u65bc\u5c0d\u5de5\u4f5c\u8ca0\u8f09\uff08\u4f47\u5217\u72c0\u614b\u6216\u7dad\u8b77\u9023\u7dda\uff09\u7684\u4f30\u8a08\u4e0d\u6e96\u78ba\uff0c\u56e0\u6b64\u5168\u57df\u6392\u7a0b\u5668\u5f88\u5bb9\u6613\u5728\u9810\u586b\u6642\u9020\u6210\u4e0d\u5fc5\u8981\u7684\u903e\u6642\u30023) \u5340\u584a\u56fa\u5b9a\u7684\u88dd\u7f6e\u5c0d\u88dd\u7f6e (D2D) KVCache \u50b3\u8f38\u900f\u904e\u53e2\u96c6\u5c64\u7d1a\u7684 RDMA\uff08\u9060\u7aef\u76f4\u63a5\u8a18\u61b6\u9ad4\u5b58\u53d6\uff09\u7121\u6cd5\u9054\u5230\u9810\u671f\u7684\u7406\u60f3 D2D \u4f7f\u7528\u7387\u3002\u70ba\u4e86\u514b\u670d\u4ee5\u524d\u7684\u554f\u984c\uff0c\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u500b\u7aef\u5c0d\u7aef\u7cfb\u7d71 P/D-Serve\uff0c\u7b26\u5408 MLOps\uff08\u6a5f\u5668\u5b78\u7fd2\u4f5c\u696d\uff09\u7684\u7bc4\u4f8b\uff0c\u5b83\u5efa\u69cb\u4e86\u7aef\u5c0d\u7aef (E2E) P/D \u6548\u80fd\uff0c\u4e26\u555f\u7528\uff1a1) \u7d30\u7dfb\u7684 P/D \u7d44\u7e54\uff0c\u6839\u64da\u9700\u8981\u5c07\u670d\u52d9\u5c0d\u61c9\u5230 RoCE\uff08\u805a\u5408\u4e59\u592a\u7db2\u8def\u4e0a\u7684 RDMA\uff09\uff0c\u4ee5\u4fc3\u9032\u985e\u4f3c\u7684\u8655\u7406\u548c P/D \u6bd4\u4f8b\u7684\u52d5\u614b\u8abf\u6574\uff1b2) \u5728\u62d2\u7d55\u9592\u7f6e\u9810\u586b\u6642\u9032\u884c\u4f9d\u9700\u6c42\u8f49\u767c\uff0c\u5c07\u6392\u7a0b\u5668\u5f9e\u5b9a\u671f\u4e0d\u6e96\u78ba\u7684\u5831\u544a\u548c\u672c\u6a5f\u4f47\u5217\u4e2d\u5206\u96e2\u51fa\u4f86\uff0c\u4ee5\u907f\u514d\u9810\u586b\u903e\u6642\uff1b3) \u900f\u904e\u6700\u4f73\u5316\u7684 D2D \u5b58\u53d6\u9032\u884c\u6709\u6548\u7684 KVCache \u50b3\u8f38\u3002P/D-Serve \u662f\u5728 Ascend \u548c MindSpore \u4e0a\u5be6\u4f5c\u7684\uff0c\u5df2\u5728\u6578\u842c\u500b NPU \u4e0a\u90e8\u7f72\u8d85\u904e\u516b\u500b\u6708\uff0c\u5728\u5546\u696d\u7528\u9014\u4e0a\u9032\u4e00\u6b65\u5be6\u73fe\u4e86 E2E \u541e\u5410\u91cf\u3001\u9996\u6b21\u4ee3\u5e63\u6642\u9593 (TTFT) SLO\uff08\u670d\u52d9\u7b49\u7d1a\u76ee\u6a19\uff09\u548c D2D \u50b3\u8f38\u6642\u9593\u5206\u5225\u63d0\u5347\u4e86 60%\u300142% \u548c 46%\u3002\u4f5c\u70ba\u5177\u5099\u6700\u4f73\u5316\u7684 E2E \u7cfb\u7d71\uff0cP/D-Serve \u5728\u541e\u5410\u91cf\u4e0a\u5be6\u73fe\u4e86 6.7 \u500d\u7684\u63d0\u5347\uff0c\u8207\u805a\u96c6\u5f0f LLM \u76f8\u6bd4\u3002</paragraph>", "author": "Yibo Jin et.al.", "authors": "Yibo Jin, Tao Wang, Huimin Lin, Mingyang Song, Peiyang Li, Yipeng Ma, Yicheng Shan, Zhengfan Yuan, Cailong Li, Yajing Sun, Tiandeng Wu, Xing Chu, Ruizhi Huan, Li Ma, Xiao You, Wenting Zhou, Yunpeng Ye, Wen Liu, Xiangkun Xu, Yongsheng Zhang, Tiantian Dong, Jiawei Zhu, Zhe Wang, Xijian Ju, Jianxun Song, Haoliang Cheng, Xiaojing Li, Jiandong Ding, Hefei Guo, Zhengyong Zhang", "id": "2408.08147v1", "paper_url": "http://arxiv.org/abs/2408.08147v1", "repo": "null"}}