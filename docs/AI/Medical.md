
### Medical
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-10-10**|**ONCOPILOT: A Promptable CT Foundation Model For Solid Tumor Evaluation**|Léo Machado et.al.|[2410.07908v2](http://arxiv.org/abs/2410.07908v2)|null|
|**2024-10-10**|**Offline Inverse Constrained Reinforcement Learning for Safe-Critical Decision Making in Healthcare**|Nan Fang et.al.|[2410.07525v1](http://arxiv.org/abs/2410.07525v1)|null|
|**2024-10-09**|**Unlocking Real-Time Fluorescence Lifetime Imaging: Multi-Pixel Parallelism for FPGA-Accelerated Processing**|Ismail Erbas et.al.|[2410.07364v1](http://arxiv.org/abs/2410.07364v1)|null|
|**2024-10-09**|**Taking a turn for the better: Conversation redirection throughout the course of mental-health therapy**|Vivian Nguyen et.al.|[2410.07147v1](http://arxiv.org/abs/2410.07147v1)|null|
|**2024-10-09**|**Mental Disorders Detection in the Era of Large Language Models**|Gleb Kuzmin et.al.|[2410.07129v1](http://arxiv.org/abs/2410.07129v1)|null|
|**2024-10-09**|**MentalArena: Self-play Training of Language Models for Diagnosis and Treatment of Mental Health Disorders**|Cheng Li et.al.|[2410.06845v1](http://arxiv.org/abs/2410.06845v1)|[link](https://github.com/scarelette/mentalarena)|
|**2024-10-09**|**An Improved Approach for Cardiac MRI Segmentation based on 3D UNet Combined with Papillary Muscle Exclusion**|Narjes Benameur et.al.|[2410.06818v1](http://arxiv.org/abs/2410.06818v1)|null|
|**2024-10-09**|**Deep Learning for Surgical Instrument Recognition and Segmentation in Robotic-Assisted Surgeries: A Systematic Review**|Fatimaelzahraa Ali Ahmed et.al.|[2410.07269v1](http://arxiv.org/abs/2410.07269v1)|null|
|**2024-10-08**|**Multimodal Representation Learning using Adaptive Graph Construction**|Weichen Huang et.al.|[2410.06395v1](http://arxiv.org/abs/2410.06395v1)|null|
|**2024-10-08**|**Skin Cancer Machine Learning Model Tone Bias**|James Pope et.al.|[2410.06385v1](http://arxiv.org/abs/2410.06385v1)|null|
|**2024-10-08**|**HumVI: A Multilingual Dataset for Detecting Violent Incidents Impacting Humanitarian Aid**|Hemank Lamba et.al.|[2410.06370v1](http://arxiv.org/abs/2410.06370v1)|[link](https://github.com/dataminr-ai/humvi-dataset)|
|**2024-10-08**|**A Comparative Study of Hybrid Models in Health Misinformation Text Classification**|Mkululi Sikosana et.al.|[2410.06311v1](http://arxiv.org/abs/2410.06311v1)|null|
|**2024-10-08**|**KnowledgeSG: Privacy-Preserving Synthetic Text Generation with Knowledge Distillation from Server**|Wenhao Wang et.al.|[2410.05725v2](http://arxiv.org/abs/2410.05725v2)|[link](https://github.com/wwh0411/knowledgesg)|
|**2024-10-08**|**Copiloting Diagnosis of Autism in Real Clinical Scenarios via LLMs**|Yi Jiang et.al.|[2410.05684v2](http://arxiv.org/abs/2410.05684v2)|null|
|**2024-10-08**|**NegMerge: Consensual Weight Negation for Strong Machine Unlearning**|Hyoseo Kim et.al.|[2410.05583v1](http://arxiv.org/abs/2410.05583v1)|[link](https://github.com/naver-ai/negmerge)|
|**2024-10-07**|**AI-Driven Early Mental Health Screening with Limited Data: Analyzing Selfies of Pregnant Women**|Gustavo A. Basílio et.al.|[2410.05450v1](http://arxiv.org/abs/2410.05450v1)|null|
|**2024-10-07**|**Improving Predictor Reliability with Selective Recalibration**|Thomas P. Zollo et.al.|[2410.05407v1](http://arxiv.org/abs/2410.05407v1)|null|
|**2024-10-07**|**CasiMedicos-Arg: A Medical Question Answering Dataset Annotated with Explanatory Argumentative Structures**|Ekaterina Sviridova et.al.|[2410.05235v2](http://arxiv.org/abs/2410.05235v2)|null|
|**2024-10-07**|**RespLLM: Unifying Audio and Text with Multimodal LLMs for Generalized Respiratory Health Prediction**|Yuwei Zhang et.al.|[2410.05361v1](http://arxiv.org/abs/2410.05361v1)|null|
|**2024-10-07**|**Synthetic Generation of Dermatoscopic Images with GAN and Closed-Form Factorization**|Rohan Reddy Mekala et.al.|[2410.05114v1](http://arxiv.org/abs/2410.05114v1)|null|
|**2024-10-07**|**Named Clinical Entity Recognition Benchmark**|Wadood M Abdul et.al.|[2410.05046v1](http://arxiv.org/abs/2410.05046v1)|[link](https://github.com/wadoodabdul/clinical_ner_benchmark)|
|**2024-10-07**|**Learning Interpretable Hierarchical Dynamical Systems Models from Time Series Data**|Manuel Brenner et.al.|[2410.04814v1](http://arxiv.org/abs/2410.04814v1)|null|
|**2024-10-07**|**$\textbf{Only-IF}$:Revealing the Decisive Effect of Instruction Diversity on Generalization**|Dylan Zhang et.al.|[2410.04717v1](http://arxiv.org/abs/2410.04717v1)|null|
|**2024-10-07**|**Rule-based Data Selection for Large Language Models**|Xiaomin Li et.al.|[2410.04715v1](http://arxiv.org/abs/2410.04715v1)|null|
|**2024-10-07**|**Knowledge Graph Based Agent for Complex, Knowledge-Intensive QA in Medicine**|Xiaorui Su et.al.|[2410.04660v1](http://arxiv.org/abs/2410.04660v1)|null|
|**2024-10-06**|**Multi-Tiered Self-Contrastive Learning for Medical Microwave Radiometry (MWR) Breast Cancer Detection**|Christoforos Galazis et.al.|[2410.04636v1](http://arxiv.org/abs/2410.04636v1)|[link](https://github.com/cgalaz01/self_contrastive_mwr)|
|**2024-10-06**|**Semi-Markovian Planning to Coordinate Aerial and Maritime Medical Evacuation Platforms**|Mahdi Al-Husseini et.al.|[2410.04523v1](http://arxiv.org/abs/2410.04523v1)|null|
|**2024-10-06**|**RespDiff: An End-to-End Multi-scale RNN Diffusion Model for Respiratory Waveform Estimation from PPG Signals**|Yuyang Miao et.al.|[2410.04366v1](http://arxiv.org/abs/2410.04366v1)|null|
|**2024-10-05**|**Applying Quantum Autoencoders for Time Series Anomaly Detection**|Robin Frehner et.al.|[2410.04154v2](http://arxiv.org/abs/2410.04154v2)|null|
|**2024-10-05**|**DAMMI:Daily Activities in a Psychologically Annotated Multi-Modal IoT dataset**|Mohsen Falah Rad et.al.|[2410.04152v1](http://arxiv.org/abs/2410.04152v1)|null|
|**2024-10-05**|**From Hospital to Portables: A Universal ECG Foundation Model Built on 10+ Million Diverse Recordings**|Jun Li et.al.|[2410.04133v1](http://arxiv.org/abs/2410.04133v1)|null|
|**2024-10-05**|**Taming the Tail: Leveraging Asymmetric Loss and Pade Approximation to Overcome Medical Image Long-Tailed Class Imbalance**|Pankhi Kashyap et.al.|[2410.04084v1](http://arxiv.org/abs/2410.04084v1)|null|
|**2024-10-04**|**Still Not Quite There! Evaluating Large Language Models for Comorbid Mental Health Diagnosis**|Amey Hengle et.al.|[2410.03908v1](http://arxiv.org/abs/2410.03908v1)|null|
|**2024-10-04**|**Not All Diffusion Model Activations Have Been Evaluated as Discriminative Features**|Benyuan Meng et.al.|[2410.03558v2](http://arxiv.org/abs/2410.03558v2)|[link](https://github.com/darkbblue/generic-diffusion-feature)|
|**2024-10-04**|**Towards Real-time Intrahepatic Vessel Identification in Intraoperative Ultrasound-Guided Liver Surgery**|Karl-Philippe Beaudet et.al.|[2410.03420v2](http://arxiv.org/abs/2410.03420v2)|null|
|**2024-10-04**|**Make Interval Bound Propagation great again**|Patryk Krukowski et.al.|[2410.03373v1](http://arxiv.org/abs/2410.03373v1)|[link](https://github.com/gmum/make-interval-bound-propagation-great-again)|
|**2024-10-04**|**An Enhanced Harmonic Densely Connected Hybrid Transformer Network Architecture for Chronic Wound Segmentation Utilising Multi-Colour Space Tensor Merging**|Bill Cassidy et.al.|[2410.03359v1](http://arxiv.org/abs/2410.03359v1)|null|
|**2024-10-04**|**Comparative Analysis and Ensemble Enhancement of Leading CNN Architectures for Breast Cancer Classification**|Gary Murphy et.al.|[2410.03333v1](http://arxiv.org/abs/2410.03333v1)|null|
|**2024-10-04**|**Manikin-Recorded Cardiopulmonary Sounds Dataset Using Digital Stethoscope**|Yasaman Torabi et.al.|[2410.03280v1](http://arxiv.org/abs/2410.03280v1)|[link](https://github.com/torabiy/hls-cmds)|
|**2024-10-04**|**Looking into Concept Explanation Methods for Diabetic Retinopathy Classification**|Andrea M. Storås et.al.|[2410.03188v1](http://arxiv.org/abs/2410.03188v1)|[link](https://github.com/andreastoraas/conceptexplanations_dr_grading)|
|**2024-10-04**|**Remaining Useful Life Prediction: A Study on Multidimensional Industrial Signal Processing and Efficient Transfer Learning Based on Large Language Models**|Yan Chen et.al.|[2410.03134v1](http://arxiv.org/abs/2410.03134v1)|null|
|**2024-10-04**|**Image First or Text First? Optimising the Sequencing of Modalities in Large Language Model Prompting and Reasoning Tasks**|Grant Wardle et.al.|[2410.03062v1](http://arxiv.org/abs/2410.03062v1)|null|
|**2024-10-03**|**Is Your Paper Being Reviewed by an LLM? Investigating AI Text Detectability in Peer Review**|Sungduk Yu et.al.|[2410.03019v1](http://arxiv.org/abs/2410.03019v1)|null|
|**2024-10-03**|**DailyDilemmas: Revealing Value Preferences of LLMs with Quandaries of Daily Life**|Yu Ying Chiu et.al.|[2410.02683v1](http://arxiv.org/abs/2410.02683v1)|null|
|**2024-10-03**|**Plots Unlock Time-Series Understanding in Multimodal Models**|Mayank Daswani et.al.|[2410.02637v1](http://arxiv.org/abs/2410.02637v1)|null|
|**2024-10-03**|**IC3M: In-Car Multimodal Multi-object Monitoring for Abnormal Status of Both Driver and Passengers**|Zihan Fang et.al.|[2410.02592v3](http://arxiv.org/abs/2410.02592v3)|null|
|**2024-10-03**|**Deep Regression 2D-3D Ultrasound Registration for Liver Motion Correction in Focal Tumor Thermal Ablation**|Shuwei Xing et.al.|[2410.02579v1](http://arxiv.org/abs/2410.02579v1)|[link](https://github.com/xingorno/deepregs2v)|
|**2024-10-03**|**ColaCare: Enhancing Electronic Health Record Modeling through Large Language Model-Driven Multi-Agent Collaboration**|Zixiang Wang et.al.|[2410.02551v1](http://arxiv.org/abs/2410.02551v1)|null|
|**2024-10-03**|**SAFLEX: Self-Adaptive Augmentation via Feature Label Extrapolation**|Mucong Ding et.al.|[2410.02512v1](http://arxiv.org/abs/2410.02512v1)|null|
|**2024-10-03**|**Clinnova Federated Learning Proof of Concept: Key Takeaways from a Cross-border Collaboration**|Julia Alekseenko et.al.|[2410.02443v1](http://arxiv.org/abs/2410.02443v1)|null|
|**2024-10-03**|**A Comprehensive Survey of Mamba Architectures for Medical Image Analysis: Classification, Segmentation, Restoration and Beyond**|Shubhi Bansal et.al.|[2410.02362v1](http://arxiv.org/abs/2410.02362v1)|[link](https://github.com/madhavaprasath23/awesome-mamba-papers-on-medical-domain)|
|**2024-10-03**|**CTARR: A fast and robust method for identifying anatomical regions on CT images via atlas registration**|Thomas Buddenkotte et.al.|[2410.02316v1](http://arxiv.org/abs/2410.02316v1)|[link](https://github.com/thomasbudd/ctarr)|
|**2024-10-02**|**Multi-Omic and Quantum Machine Learning Integration for Lung Subtypes Classification**|Mandeep Kaur Saggi et.al.|[2410.02085v1](http://arxiv.org/abs/2410.02085v1)|null|
|**2024-10-02**|**Zodiac: A Cardiologist-Level LLM Framework for Multi-Agent Diagnostics**|Yuan Zhou et.al.|[2410.02026v1](http://arxiv.org/abs/2410.02026v1)|null|
|**2024-10-02**|**UlcerGPT: A Multimodal Approach Leveraging Large Language and Vision Models for Diabetic Foot Ulcer Image Transcription**|Reza Basiri et.al.|[2410.01989v1](http://arxiv.org/abs/2410.01989v1)|null|
|**2024-10-02**|**A Two-Stage Proactive Dialogue Generator for Efficient Clinical Information Collection Using Large Language Model**|Xueshen Li et.al.|[2410.03770v1](http://arxiv.org/abs/2410.03770v1)|null|
|**2024-10-02**|**DeFine: Enhancing LLM Decision-Making with Factor Profiles and Analogical Reasoning**|Yebowen Hu et.al.|[2410.01772v1](http://arxiv.org/abs/2410.01772v1)|null|
|**2024-10-02**|**Towards a vision foundation model for comprehensive assessment of Cardiac MRI**|Athira J Jacob et.al.|[2410.01665v2](http://arxiv.org/abs/2410.01665v2)|null|
|**2024-10-02**|**Imaging foundation model for universal enhancement of non-ideal measurement CT**|Yuxin Liu et.al.|[2410.01591v1](http://arxiv.org/abs/2410.01591v1)|[link](https://github.com/yutinghe-list/tamp)|
|**2024-10-02**|**OpenMathInstruct-2: Accelerating AI for Math with Massive Open-Source Instruction Data**|Shubham Toshniwal et.al.|[2410.01560v2](http://arxiv.org/abs/2410.01560v2)|[link](https://github.com/kipok/nemo-skills)|
|**2024-10-02**|**MedQA-CS: Benchmarking Large Language Models Clinical Skills Using an AI-SCE Framework**|Zonghai Yao et.al.|[2410.01553v1](http://arxiv.org/abs/2410.01553v1)|[link](https://github.com/bio-nlp/medqa-cs)|
|**2024-10-02**|**On the Convergence of FedProx with Extrapolation and Inexact Prox**|Hanmin Li et.al.|[2410.01410v1](http://arxiv.org/abs/2410.01410v1)|null|
|**2024-10-02**|**See Me and Believe Me: Causality and Intersectionality in Testimonial Injustice in Healthcare**|Kenya S. Andrews et.al.|[2410.01227v1](http://arxiv.org/abs/2410.01227v1)|null|
|**2024-10-01**|**Explainable Diagnosis Prediction through Neuro-Symbolic Integration**|Qiuhao Lu et.al.|[2410.01855v1](http://arxiv.org/abs/2410.01855v1)|null|
|**2024-10-01**|**Heterogeneous sound classification with the Broad Sound Taxonomy and Dataset**|Panagiota Anastasopoulou et.al.|[2410.00980v1](http://arxiv.org/abs/2410.00980v1)|[link](https://github.com/allholy/bsd10k)|
|**2024-10-01**|**The Gradient of Health Data Privacy**|Baihan Lin et.al.|[2410.00897v1](http://arxiv.org/abs/2410.00897v1)|null|
|**2024-10-01**|**GAMMA-PD: Graph-based Analysis of Multi-Modal Motor Impairment Assessments in Parkinson's Disease**|Favour Nerrise et.al.|[2410.00944v1](http://arxiv.org/abs/2410.00944v1)|null|
|**2024-10-01**|**Contrastive Abstraction for Reinforcement Learning**|Vihang Patil et.al.|[2410.00704v1](http://arxiv.org/abs/2410.00704v1)|null|
|**2024-10-01**|**Arges: Spatio-Temporal Transformer for Ulcerative Colitis Severity Assessment in Endoscopy Videos**|Krishna Chaitanya et.al.|[2410.00536v1](http://arxiv.org/abs/2410.00536v1)|null|
|**2024-10-01**|**Bayes-CATSI: A variational Bayesian deep learning framework for medical time series data imputation**|Omkar Kulkarni et.al.|[2410.01847v2](http://arxiv.org/abs/2410.01847v2)|[link](https://github.com/pingala-institute/Bayes-medicaldataimputation)|
|**2024-10-01**|**ReXplain: Translating Radiology into Patient-Friendly Video Reports**|Luyang Luo et.al.|[2410.00441v1](http://arxiv.org/abs/2410.00441v1)|null|
|**2024-10-01**|**Towards Democratization of Subspeciality Medical Expertise**|Jack W. O'Sullivan et.al.|[2410.03741v1](http://arxiv.org/abs/2410.03741v1)|null|
|**2024-10-01**|**CXPMRG-Bench: Pre-training and Benchmarking for X-ray Medical Report Generation on CheXpert Plus Dataset**|Xiao Wang et.al.|[2410.00379v1](http://arxiv.org/abs/2410.00379v1)|[link](https://github.com/event-ahu/medical_image_analysis)|
|**2024-10-01**|**Easydiagnos: a framework for accurate feature selection for automatic diagnosis in smart healthcare**|Prasenjit Maji et.al.|[2410.00366v1](http://arxiv.org/abs/2410.00366v1)|null|
|**2024-09-30**|**The age of spiritual machines: Language quietus induces synthetic altered states of consciousness in artificial intelligence**|Jeremy I Skipper et.al.|[2410.00257v1](http://arxiv.org/abs/2410.00257v1)|null|
|**2024-09-30**|**CliMB: An AI-enabled Partner for Clinical Predictive Modeling**|Evgeny Saveliev et.al.|[2410.03736v1](http://arxiv.org/abs/2410.03736v1)|null|
|**2024-09-30**|**Adapting LLMs for the Medical Domain in Portuguese: A Study on Fine-Tuning and Model Evaluation**|Pedro Henrique Paiola et.al.|[2410.00163v1](http://arxiv.org/abs/2410.00163v1)|null|
|**2024-09-30**|**The Perfect Blend: Redefining RLHF with Mixture of Judges**|Tengyu Xu et.al.|[2409.20370v1](http://arxiv.org/abs/2409.20370v1)|null|
|**2024-09-30**|**Forecasting Disease Progression with Parallel Hyperplanes in Longitudinal Retinal OCT**|Arunava Chakravarty et.al.|[2409.20195v2](http://arxiv.org/abs/2409.20195v2)|[link](https://github.com/arunava555/Forecast_parallel_hyperplanes)|
|**2024-09-30**|**Classification of Radiological Text in Small and Imbalanced Datasets in a Non-English Language**|Vincent Beliveau et.al.|[2409.20147v1](http://arxiv.org/abs/2409.20147v1)|[link](https://github.com/vbeliveau/radiology-text-classification)|
|**2024-09-30**|**Positive-Sum Fairness: Leveraging Demographic Attributes to Achieve Fair AI Outcomes Without Sacrificing Group Gains**|Samia Belhadj et.al.|[2409.19940v1](http://arxiv.org/abs/2409.19940v1)|null|
|**2024-09-29**|**InfantCryNet: A Data-driven Framework for Intelligent Analysis of Infant Cries**|Mengze Hong et.al.|[2409.19689v1](http://arxiv.org/abs/2409.19689v1)|null|
|**2024-09-29**|**See Detail Say Clear: Towards Brain CT Report Generation via Pathological Clue-driven Representation Learning**|Chengxin Zheng et.al.|[2409.19676v2](http://arxiv.org/abs/2409.19676v2)|[link](https://github.com/chauncey-jheng/pcrl-mrg)|
|**2024-09-29**|**Assessment and manipulation of latent constructs in pre-trained language models using psychometric scales**|Maor Reuben et.al.|[2409.19655v1](http://arxiv.org/abs/2409.19655v1)|[link](https://github.com/cnai-lab/qlatent)|
|**2024-09-29**|**A Survey on Graph Neural Networks for Remaining Useful Life Prediction: Methodologies, Evaluation and Future Trends**|Yucheng Wang et.al.|[2409.19629v1](http://arxiv.org/abs/2409.19629v1)|[link](https://github.com/Frank-Wang-oss/GNN_RUL_Benchmarking)|
|**2024-09-29**|**MCDDPM: Multichannel Conditional Denoising Diffusion Model for Unsupervised Anomaly Detection in Brain MRI**|Vivek Kumar Trivedi et.al.|[2409.19623v1](http://arxiv.org/abs/2409.19623v1)|[link](https://github.com/vivekkumartri/mcddpm)|
|**2024-09-29**|**Understanding Clinical Decision-Making in Traditional East Asian Medicine through Dimensionality Reduction: An Empirical Investigation**|Hyojin Bae et.al.|[2409.19531v1](http://arxiv.org/abs/2409.19531v1)|null|
|**2024-09-29**|**MedHalu: Hallucinations in Responses to Healthcare Queries by Large Language Models**|Vibhor Agarwal et.al.|[2409.19492v1](http://arxiv.org/abs/2409.19492v1)|null|
|**2024-09-28**|**INSIGHTBUDDY-AI: Medication Extraction and Entity Linking using Large Language Models and Ensemble Learning**|Pablo Romero et.al.|[2409.19467v1](http://arxiv.org/abs/2409.19467v1)|null|
|**2024-09-28**|**Mind the Gap: Promoting Missing Modality Brain Tumor Segmentation with Alignment**|Tianyi Liu et.al.|[2409.19366v1](http://arxiv.org/abs/2409.19366v1)|null|
|**2024-09-28**|**3D-CT-GPT: Generating 3D Radiology Reports through Integration of Large Vision-Language Models**|Hao Chen et.al.|[2409.19330v1](http://arxiv.org/abs/2409.19330v1)|null|
|**2024-09-28**|**Epidemiology-Aware Neural ODE with Continuous Disease Transmission Graph**|Guancheng Wan et.al.|[2410.00049v1](http://arxiv.org/abs/2410.00049v1)|[link](https://github.com/emory-melody/epilearn)|
|**2024-09-27**|**A GEN AI Framework for Medical Note Generation**|Hui Yi Leong et.al.|[2410.01841v1](http://arxiv.org/abs/2410.01841v1)|null|
|**2024-09-27**|**Secure Multiparty Generative AI**|Manil Shrestha et.al.|[2409.19120v1](http://arxiv.org/abs/2409.19120v1)|null|
|**2024-09-27**|**Differential privacy for protecting patient data in speech disorder detection using deep learning**|Soroosh Tayebi Arasteh et.al.|[2409.19078v1](http://arxiv.org/abs/2409.19078v1)|null|
|**2024-09-27**|**AIPatient: Simulating Patients with EHRs and LLM Powered Agentic Workflow**|Huizi Yu et.al.|[2409.18924v2](http://arxiv.org/abs/2409.18924v2)|null|
|**2024-09-27**|**Suicide Phenotyping from Clinical Notes in Safety-Net Psychiatric Hospital Using Multi-Label Classification with Pre-Trained Language Models**|Zehan Li et.al.|[2409.18878v2](http://arxiv.org/abs/2409.18878v2)|null|
|**2024-09-27**|**Early diagnosis of Alzheimer's disease from MRI images with deep learning model**|Sajjad Aghasi Javid et.al.|[2409.18814v1](http://arxiv.org/abs/2409.18814v1)|null|
|**2024-09-27**|**State-of-the-Art Periorbital Distance Prediction and Disease Classification Using Periorbital Features**|George R. Nahass et.al.|[2409.18769v3](http://arxiv.org/abs/2409.18769v3)|null|
|**2024-09-27**|**Multi-modal Medical Image Fusion For Non-Small Cell Lung Cancer Classification**|Salma Hassan et.al.|[2409.18715v1](http://arxiv.org/abs/2409.18715v1)|null|

#### Abstracts
##### **ONCOPILOT: A Promptable CT Foundation Model For Solid Tumor Evaluation**
2410.07908v2 by Léo Machado, Hélène Philippe, Élodie Ferreres, Julien Khlaut, Julie Dupuis, Korentin Le Floch, Denis Habip Gatenyo, Pascal Roux, Jules Grégory, Maxime Ronot, Corentin Dancette, Daniel Tordjman, Pierre Manceron, Paul Hérent

Carcinogenesis is a proteiform phenomenon, with tumors emerging in various
locations and displaying complex, diverse shapes. At the crucial intersection
of research and clinical practice, it demands precise and flexible assessment.
However, current biomarkers, such as RECIST 1.1's long and short axis
measurements, fall short of capturing this complexity, offering an approximate
estimate of tumor burden and a simplistic representation of a more intricate
process. Additionally, existing supervised AI models face challenges in
addressing the variability in tumor presentations, limiting their clinical
utility. These limitations arise from the scarcity of annotations and the
models' focus on narrowly defined tasks.
  To address these challenges, we developed ONCOPILOT, an interactive
radiological foundation model trained on approximately 7,500 CT scans covering
the whole body, from both normal anatomy and a wide range of oncological cases.
ONCOPILOT performs 3D tumor segmentation using visual prompts like point-click
and bounding boxes, outperforming state-of-the-art models (e.g., nnUnet) and
achieving radiologist-level accuracy in RECIST 1.1 measurements. The key
advantage of this foundation model is its ability to surpass state-of-the-art
performance while keeping the radiologist in the loop, a capability that
previous models could not achieve. When radiologists interactively refine the
segmentations, accuracy improves further. ONCOPILOT also accelerates
measurement processes and reduces inter-reader variability, facilitating
volumetric analysis and unlocking new biomarkers for deeper insights.
  This AI assistant is expected to enhance the precision of RECIST 1.1
measurements, unlock the potential of volumetric biomarkers, and improve
patient stratification and clinical care, while seamlessly integrating into the
radiological workflow.

摘要：<paragraph>致癌作用是一種變形現象，腫瘤出現在不同位置，並呈現出複雜、多樣的形狀。在研究和臨床實務的重要交會點，它需要精確且靈活的評估。然而，目前的生物標記，例如 RECIST 1.1 的長軸和短軸測量，未能捕捉到這種複雜性，僅提供腫瘤負擔的近似估計值，以及對更複雜過程的簡化表示。此外，現有的監督式 AI 模型在處理腫瘤表現的變異性時面臨挑戰，限制了它們的臨床效用。這些限制來自於標註的稀少性，以及模型專注於狹義定義的任務。
為了應對這些挑戰，我們開發了 ONCOPILOT，這是一個互動式放射學基礎模型，訓練於大約 7,500 個涵蓋全身的 CT 掃描，包括正常解剖結構和各種腫瘤病例。ONCOPILOT 使用視覺提示（例如點選和邊界框）執行 3D 腫瘤分割，優於最先進的模型（例如 nnUnet），並在 RECIST 1.1 測量中達到放射科醫師等級的準確度。這個基礎模型的主要優點是它能夠超越最先進的效能，同時讓放射科醫師參與其中，這是以前的模型無法達到的能力。當放射科醫師互動式地調整分割時，準確度會進一步提高。ONCOPILOT 也加速了測量過程並減少了讀者間的變異性，促進了體積分析，並解鎖了新的生物標記，以獲得更深入的見解。
預計這個 AI 助理將提高 RECIST 1.1 測量的準確度，釋放體積生物標記的潛力，並改善患者分層和臨床照護，同時無縫整合到放射學工作流程中。</paragraph>

##### **Offline Inverse Constrained Reinforcement Learning for Safe-Critical Decision Making in Healthcare**
2410.07525v1 by Nan Fang, Guiliang Liu, Wei Gong

Reinforcement Learning (RL) applied in healthcare can lead to unsafe medical
decisions and treatment, such as excessive dosages or abrupt changes, often due
to agents overlooking common-sense constraints. Consequently, Constrained
Reinforcement Learning (CRL) is a natural choice for safe decisions. However,
specifying the exact cost function is inherently difficult in healthcare.
Recent Inverse Constrained Reinforcement Learning (ICRL) is a promising
approach that infers constraints from expert demonstrations. ICRL algorithms
model Markovian decisions in an interactive environment. These settings do not
align with the practical requirement of a decision-making system in healthcare,
where decisions rely on historical treatment recorded in an offline dataset. To
tackle these issues, we propose the Constraint Transformer (CT). Specifically,
1) we utilize a causal attention mechanism to incorporate historical decisions
and observations into the constraint modeling, while employing a Non-Markovian
layer for weighted constraints to capture critical states. 2) A generative
world model is used to perform exploratory data augmentation, enabling offline
RL methods to simulate unsafe decision sequences. In multiple medical
scenarios, empirical results demonstrate that CT can capture unsafe states and
achieve strategies that approximate lower mortality rates, reducing the
occurrence probability of unsafe behaviors.

摘要：強化學習 (RL) 應用於醫療保健可能會導致不安全的醫療決策和治療，例如過量劑量或突然變化，這通常是因為代理忽略了常識約束。因此，約束強化學習 (CRL) 是安全決策的自然選擇。然而，在醫療保健中明確指定確切的成本函數本質上是困難的。最近的逆約束強化學習 (ICRL) 是一種有前途的方法，它從專家示範中推斷出約束。ICRL 演算法在互動環境中對馬可夫決策進行建模。這些設定與醫療保健中決策系統的實際需求不符，在醫療保健中，決策依賴於離線資料集中記錄的歷史治療。為了解決這些問題，我們提出了約束轉換器 (CT)。具體來說，1) 我們利用因果注意機制將歷史決策和觀察納入約束建模，同時採用非馬可夫層來對加權約束進行建模，以捕捉關鍵狀態。2) 生成式世界模型用於執行探索性資料擴充，使離線 RL 方法能夠模擬不安全的決策序列。在多種醫療場景中，實證結果表明，CT 能夠捕捉不安全的狀態，並制定出近似於較低死亡率的策略，從而降低不安全行為發生的機率。

##### **Unlocking Real-Time Fluorescence Lifetime Imaging: Multi-Pixel Parallelism for FPGA-Accelerated Processing**
2410.07364v1 by Ismail Erbas, Aporva Amarnath, Vikas Pandey, Karthik Swaminathan, Naigang Wang, Xavier Intes

Fluorescence lifetime imaging (FLI) is a widely used technique in the
biomedical field for measuring the decay times of fluorescent molecules,
providing insights into metabolic states, protein interactions, and
ligand-receptor bindings. However, its broader application in fast biological
processes, such as dynamic activity monitoring, and clinical use, such as in
guided surgery, is limited by long data acquisition times and computationally
demanding data processing. While deep learning has reduced post-processing
times, time-resolved data acquisition remains a bottleneck for real-time
applications. To address this, we propose a method to achieve real-time FLI
using an FPGA-based hardware accelerator. Specifically, we implemented a
GRU-based sequence-to-sequence (Seq2Seq) model on an FPGA board compatible with
time-resolved cameras. The GRU model balances accurate processing with the
resource constraints of FPGAs, which have limited DSP units and BRAM. The
limited memory and computational resources on the FPGA require efficient
scheduling of operations and memory allocation to deploy deep learning models
for low-latency applications. We address these challenges by using STOMP, a
queue-based discrete-event simulator that automates and optimizes task
scheduling and memory management on hardware. By integrating a GRU-based
Seq2Seq model and its compressed version, called Seq2SeqLite, generated through
knowledge distillation, we were able to process multiple pixels in parallel,
reducing latency compared to sequential processing. We explore various levels
of parallelism to achieve an optimal balance between performance and resource
utilization. Our results indicate that the proposed techniques achieved a 17.7x
and 52.0x speedup over manual scheduling for the Seq2Seq model and the
Seq2SeqLite model, respectively.

摘要：螢光生命週期影像 (FLI) 是生物醫學領域中廣泛使用的技術，用於測量螢光分子的衰變時間，提供代謝狀態、蛋白質交互作用和配體受體結合的見解。然而，其在快速生物過程（例如動態活動監測）和臨床用途（例如引導式手術）中的廣泛應用受到長時間資料擷取和計算需求高的資料處理的限制。儘管深度學習減少了後處理時間，但時間解析資料擷取仍然是即時應用程式的瓶頸。為了解決這個問題，我們提出了一種使用基於 FPGA 的硬體加速器來實現即時 FLI 的方法。具體來說，我們在與時間解析相機相容的 FPGA 板上實作了基於 GRU 的序列對序列 (Seq2Seq) 模型。GRU 模型平衡了準確的處理與 FPGA 的資源限制，FPGA 的 DSP 單元和 BRAM 有限。FPGA 上有限的記憶體和計算資源需要有效地排程作業和記憶體配置，才能部署深度學習模型以進行低延遲應用程式。我們透過使用 STOMP 來解決這些挑戰，這是一個基於佇列的離散事件模擬器，可自動化和最佳化硬體上的任務排程和記憶體管理。透過整合基於 GRU 的 Seq2Seq 模型及其壓縮版本 Seq2SeqLite（透過知識萃取產生），我們能夠平行處理多個像素，與順序處理相比，可減少延遲。我們探索了各種平行層級，以在效能和資源利用率之間取得最佳平衡。我們的結果表明，與 Seq2Seq 模型和 Seq2SeqLite 模型的手動排程相比，所提出的技術分別達到了 17.7 倍和 52.0 倍的加速。

##### **Taking a turn for the better: Conversation redirection throughout the course of mental-health therapy**
2410.07147v1 by Vivian Nguyen, Sang Min Jung, Lillian Lee, Thomas D. Hull, Cristian Danescu-Niculescu-Mizil

Mental-health therapy involves a complex conversation flow in which patients
and therapists continuously negotiate what should be talked about next. For
example, therapists might try to shift the conversation's direction to keep the
therapeutic process on track and avoid stagnation, or patients might push the
discussion towards issues they want to focus on.
  How do such patient and therapist redirections relate to the development and
quality of their relationship? To answer this question, we introduce a
probabilistic measure of the extent to which a certain utterance immediately
redirects the flow of the conversation, accounting for both the intention and
the actual realization of such a change. We apply this new measure to
characterize the development of patient-therapist relationships over multiple
sessions in a very large, widely-used online therapy platform. Our analysis
reveals that (1) patient control of the conversation's direction generally
increases relative to that of the therapist as their relationship progresses;
and (2) patients who have less control in the first few sessions are
significantly more likely to eventually express dissatisfaction with their
therapist and terminate the relationship.

摘要：心理健康治療涉及複雜的對話流程，其中患者和治療師持續協商接下來應討論什麼。例如，治療師可能會嘗試改變對話方向，以使治療過程保持在正軌並避免停滯，或者患者可能會將討論引向他們想關注的問題。
患者和治療師的這種重新定向與他們關係的發展和品質有何關係？為了回答這個問題，我們引入了一個機率測量，用於衡量某個話語在多大程度上立即重新定向對話流程，同時考量此類變化的意圖和實際實現。我們將此新測量應用於描述患者-治療師關係在一個非常龐大、廣泛使用的線上治療平台上，在多個療程中的發展。我們的分析顯示，(1) 隨著患者與治療師關係的進展，患者對對話方向的控制通常會相對於治療師而增加；(2) 在最初幾次療程中控制較少的患者，最終顯著更有可能對其治療師表達不滿並終止關係。

##### **Mental Disorders Detection in the Era of Large Language Models**
2410.07129v1 by Gleb Kuzmin, Petr Strepetov, Maksim Stankevich, Ivan Smirnov, Artem Shelmanov

This paper compares the effectiveness of traditional machine learning
methods, encoder-based models, and large language models (LLMs) on the task of
detecting depression and anxiety. Five datasets were considered, each differing
in format and the method used to define the target pathology class. We tested
AutoML models based on linguistic features, several variations of encoder-based
Transformers such as BERT, and state-of-the-art LLMs as pathology
classification models. The results demonstrated that LLMs outperform
traditional methods, particularly on noisy and small datasets where training
examples vary significantly in text length and genre. However, psycholinguistic
features and encoder-based models can achieve performance comparable to
language models when trained on texts from individuals with clinically
confirmed depression, highlighting their potential effectiveness in targeted
clinical applications.

摘要：本文比較了傳統機器學習方法、編碼器模型和大型語言模型 (LLM) 在憂鬱和焦慮症偵測任務上的有效性。考慮了五個資料集，每個資料集在格式和用於定義目標病理類別的方法上都不同。我們測試了基於語言特徵的 AutoML 模型、多種編碼器模型（如 BERT）的變體，以及最新的 LLM 作為病理分類模型。結果表明，LLM 優於傳統方法，特別是在訓練範例在文字長度和類型上差異很大的嘈雜且小的資料集上。然而，當使用經臨床證實患有憂鬱症的個人的文字進行訓練時，心理語言學特徵和編碼器模型可以達到與語言模型相當的性能，突顯了它們在目標臨床應用中的潛在有效性。

##### **MentalArena: Self-play Training of Language Models for Diagnosis and Treatment of Mental Health Disorders**
2410.06845v1 by Cheng Li, May Fung, Qingyun Wang, Chi Han, Manling Li, Jindong Wang, Heng Ji

Mental health disorders are one of the most serious diseases in the world.
Most people with such a disease lack access to adequate care, which highlights
the importance of training models for the diagnosis and treatment of mental
health disorders. However, in the mental health domain, privacy concerns limit
the accessibility of personalized treatment data, making it challenging to
build powerful models. In this paper, we introduce MentalArena, a self-play
framework to train language models by generating domain-specific personalized
data, where we obtain a better model capable of making a personalized diagnosis
and treatment (as a therapist) and providing information (as a patient). To
accurately model human-like mental health patients, we devise Symptom Encoder,
which simulates a real patient from both cognition and behavior perspectives.
To address intent bias during patient-therapist interactions, we propose
Symptom Decoder to compare diagnosed symptoms with encoded symptoms, and
dynamically manage the dialogue between patient and therapist according to the
identified deviations. We evaluated MentalArena against 6 benchmarks, including
biomedicalQA and mental health tasks, compared to 6 advanced models. Our
models, fine-tuned on both GPT-3.5 and Llama-3-8b, significantly outperform
their counterparts, including GPT-4o. We hope that our work can inspire future
research on personalized care. Code is available in
https://github.com/Scarelette/MentalArena/tree/main

摘要：心理健康障礙是世界上最嚴重的疾病之一。
大多數患有這種疾病的人無法獲得適當的照護，這凸顯了訓練模型以診斷和治療心理健康障礙的重要性。然而，在心理健康領域，隱私問題限制了個人化治療資料的可及性，這使得建立強大的模型變得具有挑戰性。在本文中，我們介紹了 MentalArena，一個自玩框架，通過生成特定領域的個人化資料來訓練語言模型，在其中我們獲得了一個更好的模型，能夠進行個人化診斷和治療（作為治療師）並提供資訊（作為患者）。為了準確模擬類似人類的心理健康患者，我們設計了症狀編碼器，它從認知和行為的角度模擬一個真實的患者。為了解決患者與治療師互動期間的意圖偏差，我們提出了症狀解碼器，將診斷出的症狀與編碼症狀進行比較，並根據識別出的偏差動態管理患者與治療師之間的對話。我們針對 6 個基準對 MentalArena 進行了評估，包括生物醫學問答和心理健康任務，並與 6 個先進模型進行了比較。我們的模型在 GPT-3.5 和 Llama-3-8b 上都進行了微調，顯著優於其對應模型，包括 GPT-4o。我們希望我們的研究能激勵未來對個人化照護的研究。程式碼可在 https://github.com/Scarelette/MentalArena/tree/main 中獲得

##### **An Improved Approach for Cardiac MRI Segmentation based on 3D UNet Combined with Papillary Muscle Exclusion**
2410.06818v1 by Narjes Benameur, Ramzi Mahmoudi, Mohamed Deriche, Amira fayouka, Imene Masmoudi, Nessrine Zoghlami

Left ventricular ejection fraction (LVEF) is the most important clinical
parameter of cardiovascular function. The accuracy in estimating this parameter
is highly dependent upon the precise segmentation of the left ventricle (LV)
structure at the end diastole and systole phases. Therefore, it is crucial to
develop robust algorithms for the precise segmentation of the heart structure
during different phases. Methodology: In this work, an improved 3D UNet model
is introduced to segment the myocardium and LV, while excluding papillary
muscles, as per the recommendation of the Society for Cardiovascular Magnetic
Resonance. For the practical testing of the proposed framework, a total of
8,400 cardiac MRI images were collected and analysed from the military hospital
in Tunis (HMPIT), as well as the popular ACDC public dataset. As performance
metrics, we used the Dice coefficient and the F1 score for validation/testing
of the LV and the myocardium segmentation. Results: The data was split into
70%, 10%, and 20% for training, validation, and testing, respectively. It is
worth noting that the proposed segmentation model was tested across three axis
views: basal, medio basal and apical at two different cardiac phases: end
diastole and end systole instances. The experimental results showed a Dice
index of 0.965 and 0.945, and an F1 score of 0.801 and 0.799, at the end
diastolic and systolic phases, respectively. Additionally, clinical evaluation
outcomes revealed a significant difference in the LVEF and other clinical
parameters when the papillary muscles were included or excluded.

摘要：左心室射血分數 (LVEF) 是心血管功能最重要的臨床參數。估計此參數的準確性高度依賴於左心室 (LV) 結構在舒張末期和收縮期的精確分割。因此，開發用於精確分割不同時期心臟結構的強健演算法至關重要。方法：在此工作中，引進了一個改良的 3D UNet 模型來分割心肌和左心室，同時根據心血管磁共振學會的建議排除乳頭肌。為了對提出的架構進行實際測試，從突尼斯的軍事醫院 (HMPIT) 和流行的 ACDC 公共資料集收集並分析了總共 8,400 張心臟 MRI 影像。作為效能指標，我們使用 Dice 係數和 F1 分數來驗證/測試左心室和心肌分割。結果：資料被分成 70%、10% 和 20% 分別用於訓練、驗證和測試。值得注意的是，所提出的分割模型在三個軸向視圖中進行了測試：基底、中基底和心尖，在兩個不同的心臟時期：舒張末期和收縮末期。實驗結果顯示，在舒張末期和收縮期，Dice 指數分別為 0.965 和 0.945，F1 分數分別為 0.801 和 0.799。此外，臨床評估結果顯示，當乳頭肌被納入或排除時，LVEF 和其他臨床參數存在顯著差異。

##### **Deep Learning for Surgical Instrument Recognition and Segmentation in Robotic-Assisted Surgeries: A Systematic Review**
2410.07269v1 by Fatimaelzahraa Ali Ahmed, Mahmoud Yousef, Mariam Ali Ahmed, Hasan Omar Ali, Anns Mahboob, Hazrat Ali, Zubair Shah, Omar Aboumarzouk, Abdulla Al Ansari, Shidin Balakrishnan

Applying deep learning (DL) for annotating surgical instruments in
robot-assisted minimally invasive surgeries (MIS) represents a significant
advancement in surgical technology. This systematic review examines 48 studies
that and advanced DL methods and architectures. These sophisticated DL models
have shown notable improvements in the precision and efficiency of detecting
and segmenting surgical tools. The enhanced capabilities of these models
support various clinical applications, including real-time intraoperative
guidance, comprehensive postoperative evaluations, and objective assessments of
surgical skills. By accurately identifying and segmenting surgical instruments
in video data, DL models provide detailed feedback to surgeons, thereby
improving surgical outcomes and reducing complication risks. Furthermore, the
application of DL in surgical education is transformative. The review
underscores the significant impact of DL on improving the accuracy of skill
assessments and the overall quality of surgical training programs. However,
implementing DL in surgical tool detection and segmentation faces challenges,
such as the need for large, accurately annotated datasets to train these models
effectively. The manual annotation process is labor-intensive and
time-consuming, posing a significant bottleneck. Future research should focus
on automating the detection and segmentation process and enhancing the
robustness of DL models against environmental variations. Expanding the
application of DL models across various surgical specialties will be essential
to fully realize this technology's potential. Integrating DL with other
emerging technologies, such as augmented reality (AR), also offers promising
opportunities to further enhance the precision and efficacy of surgical
procedures.

摘要：應用深度學習 (DL) 來註解機器人輔助微創手術 (MIS) 中的外科器械代表了外科技術的重大進步。這項系統性回顧審查了 48 項研究，這些研究採用先進的 DL 方法和架構。這些複雜的 DL 模型在偵測和分割外科手術工具的精準度和效率方面已展現出顯著的進步。這些模型增強的功能支援各種臨床應用，包括即時術中引導、全面的術後評估和外科技術的客觀評估。透過在影片資料中精確識別和分割外科器械，DL 模型能提供詳細的回饋給外科醫生，進而改善手術結果並降低併發症風險。此外，DL 在外科教育中的應用具有變革性。這項回顧強調了 DL 在改善技能評估準確度和整體外科訓練計畫品質方面的重大影響。然而，在外科工具偵測和分割中實施 DL 面臨挑戰，例如需要大量準確註解的資料集才能有效訓練這些模型。手動註解過程耗時且費力，構成了一項重大的瓶頸。未來的研究應專注於自動化偵測和分割流程，並增強 DL 模型對環境變化的魯棒性。擴展 DL 模型在各種外科專科的應用對於充分實現這項技術的潛力至關重要。將 DL 與其他新興技術（例如擴增實境 (AR)）整合也提供了有望進一步增強外科手術精準度和效率的機會。

##### **Multimodal Representation Learning using Adaptive Graph Construction**
2410.06395v1 by Weichen Huang

Multimodal contrastive learning train neural networks by levergaing data from
heterogeneous sources such as images and text. Yet, many current multimodal
learning architectures cannot generalize to an arbitrary number of modalities
and need to be hand-constructed. We propose AutoBIND, a novel contrastive
learning framework that can learn representations from an arbitrary number of
modalites through graph optimization. We evaluate AutoBIND on Alzhiemer's
disease detection because it has real-world medical applicability and it
contains a broad range of data modalities. We show that AutoBIND outperforms
previous methods on this task, highlighting the generalizablility of the
approach.

摘要：多模態對比學習透過利用來自異質來源（例如圖像和文字）的資料來訓練神經網路。然而，許多目前的多模態學習架構無法推廣到任意數量的模態，並且需要手動建構。我們提出了 AutoBIND，一個新穎的對比學習架構，它可以透過圖形最佳化從任意數量的模態中學習表徵。我們在阿茲海默症的偵測上評估 AutoBIND，因為它具有實際的醫療應用性，而且它包含廣泛的資料模態。我們展示 AutoBIND 在這項任務上優於先前的各種方法，突顯了此方法的泛化能力。

##### **Skin Cancer Machine Learning Model Tone Bias**
2410.06385v1 by James Pope, Md Hassanuzzaman, Mingmar Sherpa, Omar Emara, Ayush Joshi, Nirmala Adhikari

Background: Many open-source skin cancer image datasets are the result of
clinical trials conducted in countries with lighter skin tones. Due to this
tone imbalance, machine learning models derived from these datasets can perform
well at detecting skin cancer for lighter skin tones. Any tone bias in these
models could introduce fairness concerns and reduce public trust in the
artificial intelligence health field.
  Methods: We examine a subset of images from the International Skin Imaging
Collaboration (ISIC) archive that provide tone information. The subset has a
significant tone imbalance. These imbalances could explain a model's tone bias.
To address this, we train models using the imbalanced dataset and a balanced
dataset to compare against. The datasets are used to train a deep convolutional
neural network model to classify the images as malignant or benign. We then
evaluate the models' disparate impact, based on selection rate, relative to
dark or light skin tone.
  Results: Using the imbalanced dataset, we found that the model is
significantly better at detecting malignant images in lighter tone resulting in
a disparate impact of 0.577. Using the balanced dataset, we found that the
model is also significantly better at detecting malignant images in lighter
versus darker tones with a disparate impact of 0.684. Using the imbalanced or
balanced dataset to train the model still results in a disparate impact well
below the standard threshold of 0.80 which suggests the model is biased with
respect to skin tone.
  Conclusion: The results show that typical skin cancer machine learning models
can be tone biased. These results provide evidence that diagnosis or tone
imbalance is not the cause of the bias. Other techniques will be necessary to
identify and address the bias in these models, an area of future investigation.

摘要：<paragraph>背景：許多開放原始碼皮膚癌圖像資料集是根據在膚色較淺的國家進行的臨床試驗的結果。由於這種色調不平衡，從這些資料集派生的機器學習模型在檢測膚色較淺的皮膚癌方面表現良好。這些模型中的任何色調偏差都可能引發公平性的問題，並降低公眾對人工智慧健康領域的信任。
方法：我們檢查了國際皮膚影像合作組織 (ISIC) 檔案庫中提供色調資訊的圖像子集。該子集具有顯著的色調不平衡。這些不平衡可能解釋了模型的色調偏差。為了解決這個問題，我們使用不平衡的資料集和平衡的資料集訓練模型，以便進行比較。這些資料集用於訓練深度卷積神經網路模型，將影像分類為惡性或良性。然後，我們根據選擇率評估模型的不同影響，相對於深色或淺色膚色。
結果：使用不平衡的資料集，我們發現該模型在檢測淺色色調中的惡性影像方面顯著優於在深色色調中檢測惡性影像，導致 0.577 的不同影響。使用平衡的資料集，我們發現該模型在檢測淺色色調中的惡性影像方面也顯著優於深色色調，不同影響為 0.684。使用不平衡或平衡的資料集訓練模型仍然會導致不同影響，遠低於 0.80 的標準閾值，這表明模型在膚色方面有偏差。
結論：結果表明，典型的皮膚癌機器學習模型可能會產生色調偏差。這些結果提供了證據表明，診斷或色調不平衡並非造成偏差的原因。需要其他技術來識別和解決這些模型中的偏差，這是未來研究的一個領域。</paragraph>

##### **HumVI: A Multilingual Dataset for Detecting Violent Incidents Impacting Humanitarian Aid**
2410.06370v1 by Hemank Lamba, Anton Abilov, Ke Zhang, Elizabeth M. Olson, Henry k. Dambanemuya, João c. Bárcia, David S. Batista, Christina Wille, Aoife Cahill, Joel Tetreault, Alex Jaimes

Humanitarian organizations can enhance their effectiveness by analyzing data
to discover trends, gather aggregated insights, manage their security risks,
support decision-making, and inform advocacy and funding proposals. However,
data about violent incidents with direct impact and relevance for humanitarian
aid operations is not readily available. An automatic data collection and
NLP-backed classification framework aligned with humanitarian perspectives can
help bridge this gap. In this paper, we present HumVI - a dataset comprising
news articles in three languages (English, French, Arabic) containing instances
of different types of violent incidents categorized by the humanitarian sector
they impact, e.g., aid security, education, food security, health, and
protection. Reliable labels were obtained for the dataset by partnering with a
data-backed humanitarian organization, Insecurity Insight. We provide multiple
benchmarks for the dataset, employing various deep learning architectures and
techniques, including data augmentation and mask loss, to address different
task-related challenges, e.g., domain expansion. The dataset is publicly
available at https://github.com/dataminr-ai/humvi-dataset.

摘要：人道主義組織可以透過分析資料來提升其效能，以發現趨勢、收集彙總的見解、管理其安全風險、支援決策制定，並提供倡議和資金提案的資訊。然而，關於暴力事件的資料，其直接影響和與人道主義援助行動相關性，並不容易取得。一個自動資料收集和 NLP 支援的分類架構，與人道主義觀點一致，有助於彌合此差距。在本文中，我們提出 HumVI - 一個包含三種語言（英語、法語、阿拉伯語）新聞文章的資料集，其中包含人道主義部門分類的不同類型暴力事件的案例，例如援助安全、教育、糧食安全、健康和保護。透過與資料支援的人道主義組織 Insecurity Insight 合作，取得資料集的可靠標籤。我們為資料集提供多個基準，採用各種深度學習架構和技術，包括資料擴充和遮罩損失，以解決不同的任務相關挑戰，例如領域擴充。資料集公開於 https://github.com/dataminr-ai/humvi-dataset。

##### **A Comparative Study of Hybrid Models in Health Misinformation Text Classification**
2410.06311v1 by Mkululi Sikosana, Oluwaseun Ajao, Sean Maudsley-Barton

This study evaluates the effectiveness of machine learning (ML) and deep
learning (DL) models in detecting COVID-19-related misinformation on online
social networks (OSNs), aiming to develop more effective tools for countering
the spread of health misinformation during the pan-demic. The study trained and
tested various ML classifiers (Naive Bayes, SVM, Random Forest, etc.), DL
models (CNN, LSTM, hybrid CNN+LSTM), and pretrained language models
(DistilBERT, RoBERTa) on the "COVID19-FNIR DATASET". These models were
evaluated for accuracy, F1 score, recall, precision, and ROC, and used
preprocessing techniques like stemming and lemmatization. The results showed
SVM performed well, achieving a 94.41% F1-score. DL models with Word2Vec
embeddings exceeded 98% in all performance metrics (accuracy, F1 score, recall,
precision & ROC). The CNN+LSTM hybrid models also exceeded 98% across
performance metrics, outperforming pretrained models like DistilBERT and
RoBERTa. Our study concludes that DL and hybrid DL models are more effective
than conventional ML algorithms for detecting COVID-19 misinformation on OSNs.
The findings highlight the importance of advanced neural network approaches and
large-scale pretraining in misinformation detection. Future research should
optimize these models for various misinformation types and adapt to changing
OSNs, aiding in combating health misinformation.

摘要：這項研究評估機器學習 (ML) 和深度學習 (DL) 模型在偵測線上社群網路 (OSN) 上與 COVID-19 相關的錯誤訊息的有效性，目標是開發更有效的工具來對抗大流行期間健康錯誤訊息的散布。這項研究訓練並測試了各種 ML 分類器（樸素貝氏、SVM、隨機森林等）、DL 模型（CNN、LSTM、混合 CNN+LSTM）和預訓練語言模型（DistilBERT、RoBERTa）在「COVID19-FNIR 資料集」上。這些模型經過評估，標準為準確度、F1 分數、召回率、精確度和 ROC，並使用了詞幹化和詞形還原等前處理技術。結果顯示 SVM 表現良好，達到 94.41% 的 F1 分數。使用 Word2Vec 嵌入的 DL 模型在所有效能指標（準確度、F1 分數、召回率、精確度和 ROC）中都超過 98%。CNN+LSTM 混合模型在所有效能指標中也超過 98%，優於 DistilBERT 和 RoBERTa 等預訓練模型。我們的研究結論是，DL 和混合 DL 模型比傳統 ML 演算法更能有效偵測 OSN 上的 COVID-19 錯誤訊息。這些發現突顯了進階神經網路方法和錯誤訊息偵測中大規模預訓練的重要性。未來的研究應針對各種錯誤訊息類型最佳化這些模型，並適應不斷變化的 OSN，協助打擊健康錯誤訊息。

##### **KnowledgeSG: Privacy-Preserving Synthetic Text Generation with Knowledge Distillation from Server**
2410.05725v2 by Wenhao Wang, Xiaoyu Liang, Rui Ye, Jingyi Chai, Siheng Chen, Yanfeng Wang

The success of large language models (LLMs) facilitate many parties to
fine-tune LLMs on their own private data. However, this practice raises privacy
concerns due to the memorization of LLMs. Existing solutions, such as utilizing
synthetic data for substitution, struggle to simultaneously improve performance
and preserve privacy. They either rely on a local model for generation,
resulting in a performance decline, or take advantage of APIs, directly
exposing the data to API servers. To address this issue, we propose
KnowledgeSG, a novel client-server framework which enhances synthetic data
quality and improves model performance while ensuring privacy. We achieve this
by learning local knowledge from the private data with differential privacy
(DP) and distilling professional knowledge from the server. Additionally,
inspired by federated learning, we transmit models rather than data between the
client and server to prevent privacy leakage. Extensive experiments in medical
and financial domains demonstrate the effectiveness of KnowledgeSG. Our code is
now publicly available at https://github.com/wwh0411/KnowledgeSG.

摘要：大型語言模型 (LLM) 的成功讓許多人可以微調 LLM 以符合他們的私人資料。然而，由於 LLM 的記憶功能，此做法引發了隱私問題。現有的解決方案，例如使用合成資料進行替換，難以同時改善效能並維護隱私。它們依賴於區域模型進行產生，導致效能下降，或利用 API，直接將資料公開給 API 伺服器。為了解決此問題，我們提出 KnowledgeSG，一種新穎的客戶端伺服器架構，它能提升合成資料品質並改善模型效能，同時確保隱私。我們透過使用差分隱私 (DP) 從私人資料中學習區域知識，並從伺服器中萃取專業知識來達成此目標。此外，受到聯邦學習的啟發，我們傳輸模型而非資料在客戶端和伺服器之間，以防止隱私外洩。在醫療和金融領域的廣泛實驗證明了 KnowledgeSG 的有效性。我們的程式碼現在公開於 https://github.com/wwh0411/KnowledgeSG。

##### **Copiloting Diagnosis of Autism in Real Clinical Scenarios via LLMs**
2410.05684v2 by Yi Jiang, Qingyang Shen, Shuzhong Lai, Shunyu Qi, Qian Zheng, Lin Yao, Yueming Wang, Gang Pan

Autism spectrum disorder(ASD) is a pervasive developmental disorder that
significantly impacts the daily functioning and social participation of
individuals. Despite the abundance of research focused on supporting the
clinical diagnosis of ASD, there is still a lack of systematic and
comprehensive exploration in the field of methods based on Large Language
Models (LLMs), particularly regarding the real-world clinical diagnostic
scenarios based on Autism Diagnostic Observation Schedule, Second Edition
(ADOS-2). Therefore, we have proposed a framework called ADOS-Copilot, which
strikes a balance between scoring and explanation and explored the factors that
influence the performance of LLMs in this task. The experimental results
indicate that our proposed framework is competitive with the diagnostic results
of clinicians, with a minimum MAE of 0.4643, binary classification F1-score of
81.79\%, and ternary classification F1-score of 78.37\%. Furthermore, we have
systematically elucidated the strengths and limitations of current LLMs in this
task from the perspectives of ADOS-2, LLMs' capabilities, language, and model
scale aiming to inspire and guide the future application of LLMs in a broader
fields of mental health disorders. We hope for more research to be transferred
into real clinical practice, opening a window of kindness to the world for
eccentric children.

摘要：自閉症譜系障礙 (ASD) 是一種廣泛的發展障礙，會顯著影響個體的日常生活功能和社交參與。儘管有大量的研究專注於支持 ASD 的臨床診斷，但在基於大型語言模型 (LLM) 的方法領域中，仍然缺乏系統且全面的探索，特別是關於基於自閉症診斷觀察量表第二版的真實世界臨床診斷情境 (ADOS-2)。因此，我們提出了一個名為 ADOS-Copilot 的框架，它在評分和解釋之間取得平衡，並探討了影響 LLM 在此任務中表現的因素。實驗結果表明，我們提出的框架與臨床醫生的診斷結果具有競爭力，MAE 最小為 0.4643，二元分類 F1 分數為 81.79%，三元分類 F1 分數為 78.37%。此外，我們從 ADOS-2、LLM 的能力、語言和模型規模的角度系統地闡明了當前 LLM 在此任務中的優勢和局限性，旨在激勵和指導 LLM 在更廣泛的精神疾病領域中的未來應用。我們希望更多的研究能轉化為真正的臨床實踐，為古怪的孩子們打開一扇通往世界的善意之窗。

##### **NegMerge: Consensual Weight Negation for Strong Machine Unlearning**
2410.05583v1 by Hyoseo Kim, Dongyoon Han, Junsuk Choe

Machine unlearning aims to selectively remove specific knowledge from a
model. Current methods, such as task arithmetic, rely on fine-tuning models on
the forget set, generating a task vector, and subtracting it from the original
model. However, we argue the effectiveness of this approach is highly sensitive
to hyperparameter selection, necessitating careful validation to identify the
best model among many fine-tuned candidates. In this paper, we propose a novel
method that leverages all given fine-tuned models rather than selecting a
single one. By constructing task vectors from models trained with varied
hyperparameters and merging only the components of the task vectors with
consistent signs, we perform unlearning by negating the merged task vector from
the original model. Given that existing methods also utilize multiple
fine-tuned models, our approach delivers more effective unlearning without
incurring additional computational costs. We demonstrate the effectiveness of
our method on both vision-language models and standard image classification
models, showing improved unlearning performance with minimal degradation on the
retain set, outperforming state-of-the-art techniques.

摘要：機器去學習旨在選擇性地從模型中移除特定知識。目前的方法，例如任務算術，依賴於在遺忘集上微調模型，生成任務向量，並從原始模型中減去它。然而，我們認為這種方法的有效性對超參數選擇高度敏感，需要仔細驗證以在許多微調候選者中找出最佳模型。在本文中，我們提出了一種新方法，該方法利用所有給定的微調模型，而不是選擇一個。通過使用具有不同超參數訓練的模型構建任務向量，並僅合併具有相同符號的任務向量的組成部分，我們通過從原始模型中否定合併的任務向量來執行去學習。鑑於現有方法也利用多個微調模型，我們的做法在不產生額外計算成本的情況下提供了更有效的去學習。我們在視覺語言模型和標準圖像分類模型上展示了我們方法的有效性，顯示出改進的去學習性能，同時對保留集的下降幅度最小，優於最先進的技術。

##### **AI-Driven Early Mental Health Screening with Limited Data: Analyzing Selfies of Pregnant Women**
2410.05450v1 by Gustavo A. Basílio, Thiago B. Pereira, Alessandro L. Koerich, Ludmila Dias, Maria das Graças da S. Teixeira, Rafael T. Sousa, Wilian H. Hisatugu, Amanda S. Mota, Anilton S. Garcia, Marco Aurélio K. Galletta, Hermano Tavares, Thiago M. Paixão

Major Depressive Disorder and anxiety disorders affect millions globally,
contributing significantly to the burden of mental health issues. Early
screening is crucial for effective intervention, as timely identification of
mental health issues can significantly improve treatment outcomes. Artificial
intelligence (AI) can be valuable for improving the screening of mental
disorders, enabling early intervention and better treatment outcomes. AI-driven
screening can leverage the analysis of multiple data sources, including facial
features in digital images. However, existing methods often rely on controlled
environments or specialized equipment, limiting their broad applicability. This
study explores the potential of AI models for ubiquitous depression-anxiety
screening given face-centric selfies. The investigation focuses on high-risk
pregnant patients, a population that is particularly vulnerable to mental
health issues. To cope with limited training data resulting from our clinical
setup, pre-trained models were utilized in two different approaches:
fine-tuning convolutional neural networks (CNNs) originally designed for facial
expression recognition and employing vision-language models (VLMs) for
zero-shot analysis of facial expressions. Experimental results indicate that
the proposed VLM-based method significantly outperforms CNNs, achieving an
accuracy of 77.6% and an F1-score of 56.0%. Although there is significant room
for improvement, the results suggest that VLMs can be a promising approach for
mental health screening, especially in scenarios with limited data.

摘要：重度憂鬱症和焦慮症影響全球數百萬人，
對心理健康問題的負擔有顯著的影響。早期
篩檢對於有效干預至關重要，因為及時識別
心理健康問題可以顯著改善治療結果。人工
智慧 (AI) 可以為改善心理疾病的篩檢提供有價值的幫助，
實現早期干預和更好的治療結果。AI 驅動的
篩檢可以利用多個數據來源的分析，包括數位影像中的臉部
特徵。然而，現有方法通常依賴受控
環境或專業設備，限制了它們的廣泛適用性。本
研究探討 AI 模型在無所不在的憂鬱症焦慮症
篩檢中，以臉部為中心的自拍的潛力。調查重點關注高風險
孕婦，這是一個特別容易受到心理健康問題影響的人群。為了應對因我們的臨床
設置而產生的有限訓練資料，預先訓練的模型被用於兩種不同的方法：
微調原本設計用於臉部表情辨識的卷積神經網路 (CNN)，並採用視覺語言模型 (VLM) 進行
零次學習的臉部表情分析。實驗結果表明
提出的基於 VLM 的方法顯著優於 CNN，達到 77.6% 的準確率和 56.0% 的 F1 分數。儘管有顯著的改進空間，
結果表明 VLM 可以成為心理健康篩檢的一種有前途的方法，特別是在資料有限的情況下。

##### **Improving Predictor Reliability with Selective Recalibration**
2410.05407v1 by Thomas P. Zollo, Zhun Deng, Jake C. Snell, Toniann Pitassi, Richard Zemel

A reliable deep learning system should be able to accurately express its
confidence with respect to its predictions, a quality known as calibration. One
of the most effective ways to produce reliable confidence estimates with a
pre-trained model is by applying a post-hoc recalibration method. Popular
recalibration methods like temperature scaling are typically fit on a small
amount of data and work in the model's output space, as opposed to the more
expressive feature embedding space, and thus usually have only one or a handful
of parameters. However, the target distribution to which they are applied is
often complex and difficult to fit well with such a function. To this end we
propose \textit{selective recalibration}, where a selection model learns to
reject some user-chosen proportion of the data in order to allow the
recalibrator to focus on regions of the input space that can be well-captured
by such a model. We provide theoretical analysis to motivate our algorithm, and
test our method through comprehensive experiments on difficult medical imaging
and zero-shot classification tasks. Our results show that selective
recalibration consistently leads to significantly lower calibration error than
a wide range of selection and recalibration baselines.

摘要：一個可靠的深度學習系統應該能夠準確地表達其對預測的信心，這項品質稱為校準。使用預先訓練的模型產生可靠的信心估計值最有效的方法之一是應用事後重新校準方法。熱門的重新校準方法（例如溫度縮放）通常適用於少量資料，並在模型的輸出空間中運作，而不是更具表現力的特徵嵌入空間，因此通常只有一個或少數幾個參數。然而，它們所應用的目標分佈通常很複雜，且難以用此類函數做良好的擬合。為此，我們提出「選擇性重新校準」，其中選擇模型會學習拒絕使用者選擇的某些資料比例，以允許重新校準器專注於輸入空間中能被此類模型良好捕捉到的區域。我們提供理論分析來激勵我們的演算法，並透過在困難的醫學影像和零次分類任務中進行全面的實驗來測試我們的模型。我們的結果顯示，選擇性重新校準持續導致校準誤差顯著低於各種選擇和重新校準基線。

##### **CasiMedicos-Arg: A Medical Question Answering Dataset Annotated with Explanatory Argumentative Structures**
2410.05235v2 by Ekaterina Sviridova, Anar Yeginbergen, Ainara Estarrona, Elena Cabrio, Serena Villata, Rodrigo Agerri

Explaining Artificial Intelligence (AI) decisions is a major challenge
nowadays in AI, in particular when applied to sensitive scenarios like medicine
and law. However, the need to explain the rationale behind decisions is a main
issue also for human-based deliberation as it is important to justify
\textit{why} a certain decision has been taken. Resident medical doctors for
instance are required not only to provide a (possibly correct) diagnosis, but
also to explain how they reached a certain conclusion. Developing new tools to
aid residents to train their explanation skills is therefore a central
objective of AI in education. In this paper, we follow this direction, and we
present, to the best of our knowledge, the first multilingual dataset for
Medical Question Answering where correct and incorrect diagnoses for a clinical
case are enriched with a natural language explanation written by doctors. These
explanations have been manually annotated with argument components (i.e.,
premise, claim) and argument relations (i.e., attack, support), resulting in
the Multilingual CasiMedicos-Arg dataset which consists of 558 clinical cases
in four languages (English, Spanish, French, Italian) with explanations, where
we annotated 5021 claims, 2313 premises, 2431 support relations, and 1106
attack relations. We conclude by showing how competitive baselines perform over
this challenging dataset for the argument mining task.

摘要：解釋人工智慧 (AI) 的決策是現在 AI 的一項重大挑戰，特別是應用於像醫學和法律等敏感情境時。然而，解釋決策背後理由的需求也是基於人類的考量的一個主要問題，因為有必要證明為什麼做出某個決策。例如，住院醫師不僅需要提供（可能是正確的）診斷，還需要解釋他們如何達成某個結論。因此，開發新的工具來幫助住院醫師訓練他們的解釋技巧是教育中 AI 的一項核心目標。在本文中，我們遵循這個方向，並且根據我們的了解，提出第一個多語言醫學問答資料集，其中臨床病例的正確和不正確診斷都附有由醫生撰寫的自然語言解釋。這些解釋已使用論證組成（即前提、主張）和論證關係（即攻擊、支持）進行手動註解，產生多語言 CasiMedicos-Arg 資料集，其中包含 558 個具有解釋的四種語言（英語、西班牙語、法語、義大利語）的臨床病例，我們註解了 5021 個主張、2313 個前提、2431 個支持關係和 1106 個攻擊關係。我們最後展示了競爭基準如何針對論證探勘任務執行此具挑戰性的資料集。

##### **RespLLM: Unifying Audio and Text with Multimodal LLMs for Generalized Respiratory Health Prediction**
2410.05361v1 by Yuwei Zhang, Tong Xia, Aaqib Saeed, Cecilia Mascolo

The high incidence and mortality rates associated with respiratory diseases
underscores the importance of early screening. Machine learning models can
automate clinical consultations and auscultation, offering vital support in
this area. However, the data involved, spanning demographics, medical history,
symptoms, and respiratory audio, are heterogeneous and complex. Existing
approaches are insufficient and lack generalizability, as they typically rely
on limited training data, basic fusion techniques, and task-specific models. In
this paper, we propose RespLLM, a novel multimodal large language model (LLM)
framework that unifies text and audio representations for respiratory health
prediction. RespLLM leverages the extensive prior knowledge of pretrained LLMs
and enables effective audio-text fusion through cross-modal attentions.
Instruction tuning is employed to integrate diverse data from multiple sources,
ensuring generalizability and versatility of the model. Experiments on five
real-world datasets demonstrate that RespLLM outperforms leading baselines by
an average of 4.6% on trained tasks, 7.9% on unseen datasets, and facilitates
zero-shot predictions for new tasks. Our work lays the foundation for
multimodal models that can perceive, listen to, and understand heterogeneous
data, paving the way for scalable respiratory health diagnosis.

摘要：高發生率和死亡率的呼吸道疾病突顯了早期篩檢的重要性。機器學習模型可以自動化臨床諮詢和聽診，在此領域提供重要的支援。然而，所涉及的資料涵蓋人口統計、病史、症狀和呼吸音訊，既異質又複雜。現有的方法不足且缺乏概括性，因為它們通常依賴於有限的訓練資料、基本的融合技術和特定於任務的模型。在本文中，我們提出 RespLLM，這是一個新穎的多模態大型語言模型 (LLM) 框架，它統一了文本和音訊表示，以進行呼吸道健康預測。RespLLM 利用預訓練 LLM 的廣泛先驗知識，並透過跨模態注意力實現有效的音訊文本融合。指示調整用於整合來自多個來源的不同資料，確保模型的概括性和多功能性。在五個真實世界資料集上的實驗表明，RespLLM 在訓練任務上比領先的基準高出平均 4.6%，在未見資料集上高出 7.9%，並促進新任務的零次學習預測。我們的研究為多模態模型奠定了基礎，這些模型可以感知、聆聽和理解異質資料，為可擴充的呼吸道健康診斷鋪平道路。

##### **Synthetic Generation of Dermatoscopic Images with GAN and Closed-Form Factorization**
2410.05114v1 by Rohan Reddy Mekala, Frederik Pahde, Simon Baur, Sneha Chandrashekar, Madeline Diep, Markus Wenzel, Eric L. Wisotzky, Galip Ümit Yolcu, Sebastian Lapuschkin, Jackie Ma, Peter Eisert, Mikael Lindvall, Adam Porter, Wojciech Samek

In the realm of dermatological diagnoses, where the analysis of dermatoscopic
and microscopic skin lesion images is pivotal for the accurate and early
detection of various medical conditions, the costs associated with creating
diverse and high-quality annotated datasets have hampered the accuracy and
generalizability of machine learning models. We propose an innovative
unsupervised augmentation solution that harnesses Generative Adversarial
Network (GAN) based models and associated techniques over their latent space to
generate controlled semiautomatically-discovered semantic variations in
dermatoscopic images. We created synthetic images to incorporate the semantic
variations and augmented the training data with these images. With this
approach, we were able to increase the performance of machine learning models
and set a new benchmark amongst non-ensemble based models in skin lesion
classification on the HAM10000 dataset; and used the observed analytics and
generated models for detailed studies on model explainability, affirming the
effectiveness of our solution.

摘要：在皮膚科診斷領域，皮膚鏡檢查和顯微鏡皮膚病變影像的分析對於準確且早期偵測各種醫療狀況至關重要，但建立多樣化且高品質的標記資料集相關成本已阻礙機器學習模型的準確性和普遍性。我們提出創新的非監督式擴充解決方案，利用生成對抗網路 (GAN) 基礎模型及其在潛在空間上的相關技術，以在皮膚鏡影像中產生受控的半自動發現語義變化。我們建立合成影像以納入語義變化，並使用這些影像擴充訓練資料。透過此方法，我們得以提升機器學習模型的效能，並在 HAM10000 資料集的皮膚病變分類中設定非整體式模型的新基準；並使用觀察到的分析和建立的模型進行模型可解釋性的詳細研究，確認我們解決方案的有效性。

##### **Named Clinical Entity Recognition Benchmark**
2410.05046v1 by Wadood M Abdul, Marco AF Pimentel, Muhammad Umar Salman, Tathagata Raha, Clément Christophe, Praveen K Kanithi, Nasir Hayat, Ronnie Rajan, Shadab Khan

This technical report introduces a Named Clinical Entity Recognition
Benchmark for evaluating language models in healthcare, addressing the crucial
natural language processing (NLP) task of extracting structured information
from clinical narratives to support applications like automated coding,
clinical trial cohort identification, and clinical decision support.
  The leaderboard provides a standardized platform for assessing diverse
language models, including encoder and decoder architectures, on their ability
to identify and classify clinical entities across multiple medical domains. A
curated collection of openly available clinical datasets is utilized,
encompassing entities such as diseases, symptoms, medications, procedures, and
laboratory measurements. Importantly, these entities are standardized according
to the Observational Medical Outcomes Partnership (OMOP) Common Data Model,
ensuring consistency and interoperability across different healthcare systems
and datasets, and a comprehensive evaluation of model performance. Performance
of models is primarily assessed using the F1-score, and it is complemented by
various assessment modes to provide comprehensive insights into model
performance. The report also includes a brief analysis of models evaluated to
date, highlighting observed trends and limitations.
  By establishing this benchmarking framework, the leaderboard aims to promote
transparency, facilitate comparative analyses, and drive innovation in clinical
entity recognition tasks, addressing the need for robust evaluation methods in
healthcare NLP.

摘要：這份技術報告介紹了一個命名臨床實體辨識基準，用於評估醫療保健中的語言模型，解決從臨床敘述中萃取結構化資訊的關鍵自然語言處理 (NLP) 任務，以支援自動編碼、臨床試驗群組識別和臨床決策支援等應用程式。
排行榜提供一個標準化平台，用於評估各種語言模型，包括編碼器和解碼器架構，以及它們跨多個醫療領域識別和分類臨床實體的能力。利用精心整理的公開臨床資料集，涵蓋疾病、症狀、藥物、程序和實驗室測量等實體。重要的是，這些實體根據觀察性醫療結果合作夥伴關係 (OMOP) 常見資料模型標準化，確保不同醫療保健系統和資料集之間的一致性和互通性，以及模型效能的全面評估。模型效能主要使用 F1 分數評估，並輔以各種評估模式，提供對模型效能的全面見解。報告還包括對迄今評估模型的簡要分析，重點說明觀察到的趨勢和限制。
透過建立此基準架構，排行榜旨在促進透明度、促進比較分析，並推動臨床實體辨識任務的創新，滿足醫療保健 NLP 中對健全評估方法的需求。

##### **Learning Interpretable Hierarchical Dynamical Systems Models from Time Series Data**
2410.04814v1 by Manuel Brenner, Elias Weber, Georgia Koppe, Daniel Durstewitz

In science, we are often interested in obtaining a generative model of the
underlying system dynamics from observed time series. While powerful methods
for dynamical systems reconstruction (DSR) exist when data come from a single
domain, how to best integrate data from multiple dynamical regimes and leverage
it for generalization is still an open question. This becomes particularly
important when individual time series are short, and group-level information
may help to fill in for gaps in single-domain data. At the same time, averaging
is not an option in DSR, as it will wipe out crucial dynamical properties
(e.g., limit cycles in one domain vs. chaos in another). Hence, a framework is
needed that enables to efficiently harvest group-level (multi-domain)
information while retaining all single-domain dynamical characteristics. Here
we provide such a hierarchical approach and showcase it on popular DSR
benchmarks, as well as on neuroscientific and medical time series. In addition
to faithful reconstruction of all individual dynamical regimes, our
unsupervised methodology discovers common low-dimensional feature spaces in
which datasets with similar dynamics cluster. The features spanning these
spaces were further dynamically highly interpretable, surprisingly in often
linear relation to control parameters that govern the dynamics of the
underlying system. Finally, we illustrate transfer learning and generalization
to new parameter regimes.

摘要：在科學中，我們常常有興趣從觀察到的時間序列中獲得基礎系統動態的生成模型。雖然當資料來自單一領域時，強大的動態系統重建 (DSR) 方法已經存在，但如何最佳整合來自多個動態機制的資料並利用它進行概括仍然是一個開放的問題。當個別時間序列很短時，這一點尤其重要，而且群組層級的資訊可能有助於填補單一領域資料中的空白。同時，平均化並非 DSR 中的選項，因為它會消除關鍵的動態特性（例如，一個領域中的極限週期相對於另一個領域中的混亂）。因此，需要一個框架，能夠有效收集群組層級（多領域）資訊，同時保留所有單一領域動態特性。在這裡，我們提供這種階層式方法，並在流行的 DSR 基準以及神經科學和醫學時間序列中展示它。除了忠實重建所有個別動態機制之外，我們的非監督方法還發現了常見的低維特徵空間，其中具有相似動態的資料集會成群。跨越這些空間的特徵在動態上進一步具有高度可解釋性，令人驚訝的是，它們通常與控制基礎系統動態的控制參數呈線性關係。最後，我們說明了遷移式學習和對新參數機制的概括。

##### **$\textbf{Only-IF}$:Revealing the Decisive Effect of Instruction Diversity on Generalization**
2410.04717v1 by Dylan Zhang, Justin Wang, Francois Charton

Understanding and accurately following instructions is critical for large
language models (LLMs) to be effective across diverse tasks. In this work, we
rigorously examine the key factors that enable models to generalize to unseen
instructions, providing insights to guide the collection of data for
instruction-tuning. Through controlled experiments, inspired by the
Turing-complete Markov algorithm, we demonstrate that such generalization
$\textbf{only emerges}$ when training data is diversified enough across
semantic domains. Our findings also reveal that merely diversifying within
limited domains fails to ensure robust generalization. In contrast,
cross-domain data diversification, even under constrained data budgets,
significantly enhances a model's adaptability. We further extend our analysis
to real-world scenarios, including fine-tuning of
$\textit{$\textbf{specialist}$}$ and $\textit{$\textbf{generalist}$}$ models.
In both cases, we demonstrate that 1) better performance can be achieved by
increasing the diversity of an established dataset while keeping the data size
constant, and 2) when scaling up the data, diversifying the semantics of
instructions is more effective than simply increasing the quantity of similar
data. Our research provides important insights for dataset collation,
particularly when optimizing model performance by expanding training data for
both specialist and generalist scenarios. We show that careful consideration of
data diversification is key: training specialist models with data extending
beyond their core domain leads to significant performance improvements, while
generalist models benefit from diverse data mixtures that enhance their overall
instruction-following capabilities across a wide range of applications. Our
results highlight the critical role of strategic diversification and offer
clear guidelines for improving data quality.

摘要：<paragraph>對於大型語言模型 (LLM) 來說，理解並準確遵循指示對於在各種任務中發揮作用至關重要。在這項工作中，我們嚴格審查了使模型能夠概括到未見指示的關鍵因素，並提供見解以指導指示調整數據的收集。通過受圖靈完備馬可夫演算法啟發的受控實驗，我們證明了這種概括僅當訓練數據在語義領域中足夠多樣化時才會出現。我們的發現還表明，僅在有限的領域內進行多樣化不足以確保穩健的概括。相比之下，即使在受限的數據預算下，跨領域數據多樣化也會顯著增強模型的適應性。我們進一步將我們的分析擴展到現實世界場景，包括微調專家和通才模型。在這兩種情況下，我們證明了 1) 可以在保持數據大小不變的同時通過增加既定數據集的多樣性來實現更好的性能，以及 2) 在擴展數據時，多樣化指令的語義比簡單地增加相似數據的數量更有效。我們的研究為數據集整理提供了重要的見解，特別是在通過擴展專家和通才場景的訓練數據來優化模型性能時。我們表明，仔細考慮數據多樣化是關鍵：使用超出其核心領域的數據訓練專家模型會導致性能顯著提升，而通才模型受益於多樣化的數據混合，這些混合增強了它們在廣泛應用中的整體指令遵循能力。我們的結果突出了策略多樣化的關鍵作用，並為提高數據質量提供了明確的指導方針。</paragraph>

##### **Rule-based Data Selection for Large Language Models**
2410.04715v1 by Xiaomin Li, Mingye Gao, Zhiwei Zhang, Chang Yue, Hong Hu

The quality of training data significantly impacts the performance of large
language models (LLMs). There are increasing studies using LLMs to rate and
select data based on several human-crafted metrics (rules). However, these
conventional rule-based approaches often depend too heavily on human
heuristics, lack effective metrics for assessing rules, and exhibit limited
adaptability to new tasks. In our study, we introduce an innovative rule-based
framework that utilizes the orthogonality of score vectors associated with
rules as a novel metric for rule evaluations. Our approach includes an
automated pipeline that first uses LLMs to generate a diverse set of rules,
encompassing various rating dimensions to evaluate data quality. Then it rates
a batch of data based on these rules and uses the determinantal point process
(DPP) from random matrix theory to select the most orthogonal score vectors,
thereby identifying a set of independent rules. These rules are subsequently
used to evaluate all data, selecting samples with the highest average scores
for downstream tasks such as LLM training. We verify the effectiveness of our
method through two experimental setups: 1) comparisons with ground truth
ratings and 2) benchmarking LLMs trained with the chosen data. Our
comprehensive experiments cover a range of scenarios, including general
pre-training and domain-specific fine-tuning in areas such as IMDB, Medical,
Math, and Code. The outcomes demonstrate that our DPP-based rule rating method
consistently outperforms other approaches, including rule-free rating, uniform
sampling, importance resampling, and QuRating, in terms of both rating
precision and model performance.

摘要：訓練資料的品質會顯著影響大型語言模型 (LLM) 的效能。有愈來愈多研究使用 LLM 來評分並根據多項人為建立的指標 (規則) 選擇資料。然而，這些傳統的基於規則的方法通常過度依賴人類的啟發法，缺乏評估規則的有效指標，且在適應新任務方面展現出有限的靈活性。在我們的研究中，我們引進一個創新的基於規則的架構，它利用與規則相關聯的分數向量的正交性作為規則評估的新指標。我們的做法包括一個自動化流程，該流程首先使用 LLM 產生一組多樣化的規則，涵蓋各種評分面向以評估資料品質。接著，它根據這些規則評分一批資料，並使用隨機矩陣理論中的行列式點過程 (DPP) 來選出最正交的分數向量，從而找出獨立規則的集合。這些規則隨後用於評估所有資料，針對下游任務（例如 LLM 訓練）選出平均分數最高的樣本。我們透過兩個實驗設定驗證我們方法的有效性：1) 與真實評分進行比較，以及 2) 對使用所選資料訓練的 LLM 進行基準測試。我們全面的實驗涵蓋一系列情境，包括在 IMDB、醫學、數學和程式碼等領域的一般預訓練和特定領域的微調。結果顯示，我們的基於 DPP 的規則評分方法在評分精準度和模型效能方面始終優於其他方法，包括無規則評分、均勻抽樣、重要性再抽樣和 QuRating。

##### **Knowledge Graph Based Agent for Complex, Knowledge-Intensive QA in Medicine**
2410.04660v1 by Xiaorui Su, Yibo Wang, Shanghua Gao, Xiaolong Liu, Valentina Giunchiglia, Djork-Arné Clevert, Marinka Zitnik

Biomedical knowledge is uniquely complex and structured, requiring distinct
reasoning strategies compared to other scientific disciplines like physics or
chemistry. Biomedical scientists do not rely on a single approach to reasoning;
instead, they use various strategies, including rule-based, prototype-based,
and case-based reasoning. This diversity calls for flexible approaches that
accommodate multiple reasoning strategies while leveraging in-domain knowledge.
We introduce KGARevion, a knowledge graph (KG) based agent designed to address
the complexity of knowledge-intensive medical queries. Upon receiving a query,
KGARevion generates relevant triplets by using the knowledge base of the LLM.
These triplets are then verified against a grounded KG to filter out erroneous
information and ensure that only accurate, relevant data contribute to the
final answer. Unlike RAG-based models, this multi-step process ensures
robustness in reasoning while adapting to different models of medical
reasoning. Evaluations on four gold-standard medical QA datasets show that
KGARevion improves accuracy by over 5.2%, outperforming 15 models in handling
complex medical questions. To test its capabilities, we curated three new
medical QA datasets with varying levels of semantic complexity, where KGARevion
achieved a 10.4% improvement in accuracy.

摘要：生物医学知識獨特地複雜且結構化，需要與其他科學領域（如物理或化學）不同的推理策略。生物醫學科學家不依賴單一的推理方法；相反，他們使用各種策略，包括基於規則、基於原型和基於案例的推理。這種多樣性需要靈活的方法，同時利用領域知識來適應多種推理策略。我們介紹了 KGARevion，這是一個基於知識圖譜 (KG) 的代理，旨在解決知識密集型醫療查詢的複雜性。在收到查詢後，KGARevion 使用 LLM 的知識庫生成相關的三元組。然後將這些三元組與基礎 KG 進行驗證，以過濾掉錯誤信息並確保只有準確、相關的數據有助於最終答案。與基於 RAG 的模型不同，這種多步驟過程確保了推理的穩健性，同時適應不同的醫療推理模型。對四個黃金標準醫療 QA 數據集的評估表明，KGARevion 將準確率提高了 5.2%，在處理複雜的醫療問題方面優於 15 個模型。為了測試其能力，我們策劃了三個新的醫療 QA 數據集，具有不同的語義複雜性，其中 KGARevion 在準確率上提高了 10.4%。

##### **Multi-Tiered Self-Contrastive Learning for Medical Microwave Radiometry (MWR) Breast Cancer Detection**
2410.04636v1 by Christoforos Galazis, Huiyi Wu, Igor Goryanin

The pursuit of enhanced breast cancer detection and monitoring techniques is
a paramount healthcare objective, driving the need for innovative imaging
technologies and diagnostic approaches. This study introduces a novel
multi-tiered self-contrastive model tailored for the application of microwave
radiometry (MWR) breast cancer detection. Our approach encompasses three
distinct models: Local-MWR (L-MWR), Regional-MWR (R-MWR), and Global-MWR
(G-MWR), each engineered to analyze varying sub-regional comparisons within the
breasts. These models are cohesively integrated through the Joint-MWR (J-MWR)
network, which leverages the self-contrastive data generated at each analytical
level to enhance detection capabilities. Employing a dataset comprising 4,932
cases of female patients, our research showcases the effectiveness of our
proposed models. Notably, the J-MWR model distinguishes itself by achieving a
Matthews correlation coefficient of 0.74 $\pm$ 0.018, surpassing existing MWR
neural networks and contrastive methods. These results highlight the
significant potential of self-contrastive learning techniques in improving both
the diagnostic accuracy and generalizability of MWR-based breast cancer
detection processes. Such advancements hold considerable promise for further
investigative and clinical endeavors. The source code is available at:
https://github.com/cgalaz01/self_contrastive_mwr

摘要：追求增強乳癌檢測和監測技術是一項至關重要的醫療保健目標，推動了創新影像技術和診斷方法的需求。本研究介紹了一種新穎的多層自對比模型，專門用於微波輻射測量 (MWR) 乳癌檢測。我們的做法包含三個不同的模型：局部 MWR (L-MWR)、區域 MWR (R-MWR) 和全局 MWR (G-MWR)，每個模型都設計用於分析乳房內不同的次區域比較。這些模型通過聯合 MWR (J-MWR) 網路緊密整合，利用在每個分析層級產生的自對比資料來增強檢測能力。我們的研究採用包含 4,932 例女性患者的資料集，展示了我們提出的模型的有效性。值得注意的是，J-MWR 模型以達到 0.74 ± 0.018 的馬修斯相關係數而區別於其他模型，超越了現有的 MWR 神經網路和對比方法。這些結果突顯了自對比學習技術在改善基於 MWR 的乳癌檢測程序的診斷準確性和概括性方面具有顯著的潛力。這些進展為進一步的調查和臨床工作提供了相當大的希望。原始碼可在以下網址取得：https://github.com/cgalaz01/self_contrastive_mwr

##### **Semi-Markovian Planning to Coordinate Aerial and Maritime Medical Evacuation Platforms**
2410.04523v1 by Mahdi Al-Husseini, Kyle H. Wray, Mykel J. Kochenderfer

The transfer of patients between two aircraft using an underway watercraft
increases medical evacuation reach and flexibility in maritime environments.
The selection of any one of multiple underway watercraft for patient exchange
is complicated by participating aircraft utilization history and a
participating watercraft position and velocity. The selection problem is
modeled as a semi-Markov decision process with an action space including both
fixed land and moving watercraft exchange points. Monte Carlo tree search with
root parallelization is used to select optimal exchange points and determine
aircraft dispatch times. Model parameters are varied in simulation to identify
representative scenarios where watercraft exchange points reduce incident
response times. We find that an optimal policy with watercraft exchange points
outperforms an optimal policy without watercraft exchange points and a greedy
policy by 35% and 40%, respectively. In partnership with the United States
Army, we deploy for the first time the watercraft exchange point by executing a
mock patient transfer with a manikin between two HH-60M medical evacuation
helicopters and an underway Army Logistic Support Vessel south of the Hawaiian
island of Oahu. Both helicopters were dispatched in accordance with our
optimized decision strategy.

摘要：使用航行中的水上交通工具在两架飞机之间转运患者，可增加海上环境中的医疗后送范围和灵活性。
由于参与飞机的使用历史以及参与水上交通工具的位置和速度，选择多个航行中的水上交通工具中的任何一个进行患者交换变得复杂。选择问题被建模为半马尔可夫决策过程，其动作空间包括固定陆地和移动水上交通工具交换点。使用根并行化的蒙特卡罗树搜索来选择最佳交换点并确定飞机调度时间。在仿真中改变模型参数，以识别水上交通工具交换点减少事件响应时间的代表性场景。我们发现，具有水上交通工具交换点的最优策略比没有水上交通工具交换点的最优策略和贪婪策略分别高出 35% 和 40%。与美国陆军合作，我们首次通过在两架 HH-60M 医疗后送直升机和夏威夷欧胡岛南部航行中的陆军后勤支援船之间执行模拟患者转运，部署了水上交通工具交换点。两架直升机均按照我们优化的决策策略进行调度。

##### **RespDiff: An End-to-End Multi-scale RNN Diffusion Model for Respiratory Waveform Estimation from PPG Signals**
2410.04366v1 by Yuyang Miao, Zehua Chen, Chang Li, Danilo Mandic

Respiratory rate (RR) is a critical health indicator often monitored under
inconvenient scenarios, limiting its practicality for continuous monitoring.
Photoplethysmography (PPG) sensors, increasingly integrated into wearable
devices, offer a chance to continuously estimate RR in a portable manner. In
this paper, we propose RespDiff, an end-to-end multi-scale RNN diffusion model
for respiratory waveform estimation from PPG signals. RespDiff does not require
hand-crafted features or the exclusion of low-quality signal segments, making
it suitable for real-world scenarios. The model employs multi-scale encoders,
to extract features at different resolutions, and a bidirectional RNN to
process PPG signals and extract respiratory waveform. Additionally, a spectral
loss term is introduced to optimize the model further. Experiments conducted on
the BIDMC dataset demonstrate that RespDiff outperforms notable previous works,
achieving a mean absolute error (MAE) of 1.18 bpm for RR estimation while
others range from 1.66 to 2.15 bpm, showing its potential for robust and
accurate respiratory monitoring in real-world applications.

摘要：呼吸速率 (RR) 是一項重要的健康指標，通常在不方便的情況下進行監測，這限制了其在持續監測中的實用性。光電容積描記法 (PPG) 感測器日益整合到可穿戴裝置中，提供了一種以可攜式方式持續估計 RR 的機會。在本文中，我們提出了 RespDiff，這是一個端到端的多分辨率 RNN 擴散模型，用於從 PPG 訊號中估計呼吸波形。RespDiff 不需要人工特徵或排除低品質訊號片段，使其適用於實際場景。該模型採用多分辨率編碼器，以不同解析度提取特徵，並採用雙向 RNN 來處理 PPG 訊號和提取呼吸波形。此外，還引入了頻譜損失項以進一步最佳化模型。在 BIDMC 資料集上進行的實驗表明，RespDiff 優於之前的顯著研究，在 RR 估計中實現了 1.18 bpm 的平均絕對誤差 (MAE)，而其他誤差範圍從 1.66 到 2.15 bpm，顯示了其在實際應用中進行穩健且準確的呼吸監測的潛力。

##### **Applying Quantum Autoencoders for Time Series Anomaly Detection**
2410.04154v2 by Robin Frehner, Kurt Stockinger

Anomaly detection is an important problem with applications in various
domains such as fraud detection, pattern recognition or medical diagnosis.
Several algorithms have been introduced using classical computing approaches.
However, using quantum computing for solving anomaly detection problems in time
series data is a widely unexplored research field.
  This paper explores the application of quantum autoencoders to time series
anomaly detection. We investigate two primary techniques for classifying
anomalies: (1) Analyzing the reconstruction error generated by the quantum
autoencoder and (2) latent representation analysis. Our simulated experimental
results, conducted across various ansaetze, demonstrate that quantum
autoencoders consistently outperform classical deep learning-based autoencoders
across multiple datasets. Specifically, quantum autoencoders achieve superior
anomaly detection performance while utilizing 60-230 times fewer parameters and
requiring five times fewer training iterations. In addition, we implement our
quantum encoder on real quantum hardware. Our experimental results demonstrate
that quantum autoencoders achieve anomaly detection performance on par with
their simulated counterparts.

摘要：異常偵測是一個重要的問題，在各個領域都有應用，例如詐欺偵測、模式辨識或醫療診斷。
已經有使用傳統運算方法提出的多種演算法。
然而，使用量子運算來解決時間序列資料中的異常偵測問題是一個廣泛未開發的研究領域。
本文探討量子自動編碼器在時間序列異常偵測的應用。我們研究了兩種分類異常的主要技術：(1) 分析量子自動編碼器產生的重建誤差，以及 (2) 潛在表示分析。我們在各種 ansaetze 下進行模擬實驗，結果表明，量子自動編碼器在多個資料集上始終優於基於經典深度學習的自動編碼器。具體來說，量子自動編碼器在使用少 60-230 倍的參數和需要少五倍的訓練反覆運算的情況下，實現了卓越的異常偵測效能。此外，我們在真實量子硬體上實現了我們的量子編碼器。我們的實驗結果表明，量子自動編碼器實現了與其模擬對應物相當的異常偵測效能。

##### **DAMMI:Daily Activities in a Psychologically Annotated Multi-Modal IoT dataset**
2410.04152v1 by Mohsen Falah Rad, Kamrad Khoshhal Roudposhti, Mohammad Hassan Khoobkar, Mohsen Shirali, Zahra Ahmadi, Carlos Fernandez-Llatas

The growth in the elderly population and the shift in the age pyramid have
increased the demand for healthcare and well-being services. To address this
concern, alongside the rising cost of medical care, the concept of ageing at
home has emerged, driven by recent advances in medical and technological
solutions. Experts in computer science, communication technology, and
healthcare have collaborated to develop affordable health solutions by
employing sensors in living environments, wearable devices, and smartphones, in
association with advanced data mining and intelligent systems with learning
capabilities, to monitor, analyze, and predict the health status of elderly
individuals. However, implementing intelligent healthcare systems and
developing analytical techniques requires testing and evaluating algorithms on
real-world data. Despite the need, there is a shortage of publicly available
datasets that meet these requirements. To address this gap, we present the
DAMMI dataset in this work, designed to support researchers in the field. The
dataset includes daily activity data of an elderly individual collected via
home-installed sensors, smartphone data, and a wristband over 146 days. It also
contains daily psychological reports provided by a team of psychologists.
Furthermore, the data collection spans significant events such as the COVID-19
pandemic, New Year's holidays, and the religious month of Ramadan, offering
additional opportunities for analysis. In this paper, we outline detailed
information about the data collection system, the types of data recorded, and
pre-processed event logs. This dataset is intended to assist professionals in
IoT and data mining in evaluating and implementing their research ideas.

摘要：隨著老年人口的增長和年齡金字塔的轉變，對醫療保健和福祉服務的需求也隨之增加。為了解決這個問題，加上醫療保健成本的上升，在家中老化的概念應運而生，這得益於醫療和技術解決方案的最新進展。電腦科學、通訊技術和醫療保健方面的專家合作開發了經濟實惠的健康解決方案，方法是在生活環境中使用感測器、穿戴式裝置和智慧型手機，並結合先進的資料探勘和具備學習能力的智慧系統，來監控、分析和預測老年人的健康狀況。然而，實施智慧型醫療保健系統和開發分析技術需要在真實世界資料上測試和評估演算法。儘管有這個需求，但符合這些要求的公開可用資料集卻很缺乏。為了解決這個差距，我們在這項工作中提出了 DAMMI 資料集，旨在支援該領域的研究人員。該資料集包括透過安裝在家的感測器、智慧型手機資料和一個手環在 146 天內收集到的老年人日常活動資料。它還包含由心理學家團隊提供的每日心理報告。此外，資料收集涵蓋了重要的事件，例如 COVID-19 大流行、新年假期和齋戒月，為分析提供了額外的機會。在本文中，我們概述了有關資料收集系統、記錄的資料類型和預處理事件記錄的詳細資訊。此資料集旨在協助物聯網和資料探勘方面的專業人員評估和實施其研究構想。

##### **From Hospital to Portables: A Universal ECG Foundation Model Built on 10+ Million Diverse Recordings**
2410.04133v1 by Jun Li, Aaron Aguirre, Junior Moura, Che Liu, Lanhai Zhong, Chenxi Sun, Gari Clifford, Brandon Westover, Shenda Hong

Artificial Intelligence (AI) has shown great promise in electrocardiogram
(ECG) analysis and cardiovascular disease detection. However, developing a
general AI-ECG model has been challenging due to inter-individual variability
and the diversity of ECG diagnoses, limiting existing models to specific
diagnostic tasks and datasets. Moreover, current AI-ECG models struggle to
achieve comparable performance between single-lead and 12-lead ECGs, limiting
the application of AI-ECG to portable and wearable ECG devices. To address
these limitations, we introduce an ECG Foundation Model (ECGFounder), a
general-purpose model that leverages real-world ECG annotations from cardiology
experts to broaden the diagnostic capabilities of ECG analysis. ECGFounder is
trained on over 10 million ECGs with 150 label categories from the
Harvard-Emory ECG Database, enabling comprehensive cardiovascular disease
diagnosis through ECG analysis. The model is designed to be both effective
out-of-the-box and fine-tunable for downstream tasks, maximizing usability.
More importantly, we extend its application to single-lead ECGs, enabling
complex condition diagnoses and supporting various downstream tasks in mobile
and remote monitoring scenarios. Experimental results demonstrate that
ECGFounder achieves expert-level performance on internal validation sets for
both 12-lead and single-lead ECGs, while also exhibiting strong classification
performance and generalization across various diagnoses on external validation
sets. When fine-tuned, ECGFounder outperforms baseline models in demographics
detection, clinical event detection, and cross-modality cardiac rhythm
diagnosis. The trained model and data will be publicly released upon
publication through the bdsp.io. Our code is available at
https://github.com/bdsp-core/ECGFounder.

摘要：人工智慧（AI）在心電圖（ECG）分析和心血管疾病檢測方面已展現極佳的前景。然而，由於個體間變異性和 ECG 診斷的多樣性，開發通用 AI-ECG 模型一直是一項挑戰，這限制了現有模型只能用於特定的診斷任務和資料集。此外，目前的 AI-ECG 模型難以在單導程和 12 導程 ECG 之間取得相當的效能，這限制了 AI-ECG 應用於可攜式和可穿戴 ECG 裝置。為了克服這些限制，我們引進了一種 ECG 基礎模型（ECGFounder），這是一種通用模型，它利用來自心臟病專家的真實世界 ECG 標註，以擴展 ECG 分析的診斷能力。ECGFounder 經由哈佛-艾默里 ECG 資料庫中超過 1 千萬個 ECG 和 150 個標籤類別進行訓練，能透過 ECG 分析進行全面的心血管疾病診斷。該模型被設計為開箱即用且可微調以進行下游任務，以最大化可用性。更重要的是，我們將其應用延伸至單導程 ECG，能進行複雜狀況診斷，並支援行動和遠端監控情境中的各種下游任務。實驗結果顯示，ECGFounder 在 12 導程和單導程 ECG 的內部驗證集中達到了專家級的效能，同時在外部驗證集中對各種診斷也展現出強大的分類效能和泛化能力。經過微調後，ECGFounder 在人口統計資料檢測、臨床事件檢測和跨模態心律診斷方面優於基準模型。訓練好的模型和資料將在出版後透過 bdsp.io 公開發布。我們的程式碼可在 https://github.com/bdsp-core/ECGFounder 取得。

##### **Taming the Tail: Leveraging Asymmetric Loss and Pade Approximation to Overcome Medical Image Long-Tailed Class Imbalance**
2410.04084v1 by Pankhi Kashyap, Pavni Tandon, Sunny Gupta, Abhishek Tiwari, Ritwik Kulkarni, Kshitij Sharad Jadhav

Long-tailed problems in healthcare emerge from data imbalance due to
variability in the prevalence and representation of different medical
conditions, warranting the requirement of precise and dependable classification
methods. Traditional loss functions such as cross-entropy and binary
cross-entropy are often inadequate due to their inability to address the
imbalances between the classes with high representation and the classes with
low representation found in medical image datasets. We introduce a novel
polynomial loss function based on Pade approximation, designed specifically to
overcome the challenges associated with long-tailed classification. This
approach incorporates asymmetric sampling techniques to better classify
under-represented classes. We conducted extensive evaluations on three publicly
available medical datasets and a proprietary medical dataset. Our
implementation of the proposed loss function is open-sourced in the public
repository:https://github.com/ipankhi/ALPA.

摘要：醫療保健中的長尾問題源於數據不平衡，這是由於不同醫療狀況的流行率和表現存在變異性，這保證了對精確且可靠的分類方法的需求。傳統損失函數（例如交叉熵和二元交叉熵）通常不足，因為它們無法解決醫療影像資料集中表示率高的類別與表示率低的類別之間的不平衡。我們引入了一種基於 Pade 近似的多項式損失函數，專門設計用於克服與長尾分類相關的挑戰。此方法結合了非對稱抽樣技術，以更好地對代表性不足的類別進行分類。我們對三個公開的醫療資料集和一個專有醫療資料集進行了廣泛的評估。我們對提議損失函數的實作已在公共儲存庫中開源：https://github.com/ipankhi/ALPA。

##### **Still Not Quite There! Evaluating Large Language Models for Comorbid Mental Health Diagnosis**
2410.03908v1 by Amey Hengle, Atharva Kulkarni, Shantanu Patankar, Madhumitha Chandrasekaran, Sneha D'Silva, Jemima Jacob, Rashmi Gupta

In this study, we introduce ANGST, a novel, first-of-its kind benchmark for
depression-anxiety comorbidity classification from social media posts. Unlike
contemporary datasets that often oversimplify the intricate interplay between
different mental health disorders by treating them as isolated conditions,
ANGST enables multi-label classification, allowing each post to be
simultaneously identified as indicating depression and/or anxiety. Comprising
2876 meticulously annotated posts by expert psychologists and an additional
7667 silver-labeled posts, ANGST posits a more representative sample of online
mental health discourse. Moreover, we benchmark ANGST using various
state-of-the-art language models, ranging from Mental-BERT to GPT-4. Our
results provide significant insights into the capabilities and limitations of
these models in complex diagnostic scenarios. While GPT-4 generally outperforms
other models, none achieve an F1 score exceeding 72% in multi-class comorbid
classification, underscoring the ongoing challenges in applying language models
to mental health diagnostics.

摘要：在這項研究中，我們介紹 ANGST，這是一個新穎的、同類首創的基準，用於從社群媒體貼文中分類憂鬱症和焦慮症共病。與當代的資料集不同，當代的資料集通常會過度簡化不同心理健康障礙之間的複雜交互作用，將它們視為孤立的狀況，而 ANGST 能夠進行多標籤分類，讓每則貼文都能同時被辨識為表示憂鬱症和/或焦慮症。ANGST 包含了 2876 則由專家心理學家仔細註解的貼文，以及另外 7667 則標記為銀級的貼文，它提出了更具代表性的線上心理健康論述範例。此外，我們使用從 Mental-BERT 到 GPT-4 等各種最先進的語言模型對 ANGST 進行基準測試。我們的結果提供了重要的見解，說明了這些模型在複雜的診斷情境中的能力和限制。雖然 GPT-4 通常優於其他模型，但沒有任何模型在多類共病分類中達到超過 72% 的 F1 分數，這凸顯了將語言模型應用於心理健康診斷的持續挑戰。

##### **Not All Diffusion Model Activations Have Been Evaluated as Discriminative Features**
2410.03558v2 by Benyuan Meng, Qianqian Xu, Zitai Wang, Xiaochun Cao, Qingming Huang

Diffusion models are initially designed for image generation. Recent research
shows that the internal signals within their backbones, named activations, can
also serve as dense features for various discriminative tasks such as semantic
segmentation. Given numerous activations, selecting a small yet effective
subset poses a fundamental problem. To this end, the early study of this field
performs a large-scale quantitative comparison of the discriminative ability of
the activations. However, we find that many potential activations have not been
evaluated, such as the queries and keys used to compute attention scores.
Moreover, recent advancements in diffusion architectures bring many new
activations, such as those within embedded ViT modules. Both combined,
activation selection remains unresolved but overlooked. To tackle this issue,
this paper takes a further step with a much broader range of activations
evaluated. Considering the significant increase in activations, a full-scale
quantitative comparison is no longer operational. Instead, we seek to
understand the properties of these activations, such that the activations that
are clearly inferior can be filtered out in advance via simple qualitative
evaluation. After careful analysis, we discover three properties universal
among diffusion models, enabling this study to go beyond specific models. On
top of this, we present effective feature selection solutions for several
popular diffusion models. Finally, the experiments across multiple
discriminative tasks validate the superiority of our method over the SOTA
competitors. Our code is available at
https://github.com/Darkbblue/generic-diffusion-feature.

摘要：擴散模型最初是為影像生成而設計。最近的研究顯示，其主幹中的內部訊號（稱為激活）也可以作為各種判別任務（例如語意分割）的稠密特徵。在給定大量激活的情況下，選擇一個小但有效的子集是一個基本問題。為此，此領域的早期研究對激活的判別能力進行了大規模的定量比較。然而，我們發現許多潛在的激活尚未經過評估，例如用於計算注意力分數的查詢和鍵。此外，擴散架構的最新進展帶來了許多新的激活，例如嵌入式 ViT 模組中的那些。兩者結合，激活選擇仍然未解決，但被忽視了。為了解決這個問題，本文採用更廣泛的激活評估範圍，進一步邁出了一步。考慮到激活的顯著增加，全面定量比較不再可行。相反，我們尋求了解這些激活的特性，以便可以透過簡單的定性評估事先篩選出明顯較差的激活。經過仔細分析，我們發現擴散模型中普遍存在三個特性，使本研究能夠超越特定模型。除此之外，我們針對幾種流行的擴散模型提出了有效的特徵選擇解決方案。最後，跨多個判別任務的實驗驗證了我們的方法優於 SOTA 競爭對手。我們的程式碼可在 https://github.com/Darkbblue/generic-diffusion-feature 取得。

##### **Towards Real-time Intrahepatic Vessel Identification in Intraoperative Ultrasound-Guided Liver Surgery**
2410.03420v2 by Karl-Philippe Beaudet, Alexandros Karargyris, Sidaty El Hadramy, Stéphane Cotin, Jean-Paul Mazellier, Nicolas Padoy, Juan Verde

While laparoscopic liver resection is less prone to complications and
maintains patient outcomes compared to traditional open surgery, its complexity
hinders widespread adoption due to challenges in representing the liver's
internal structure. Laparoscopic intraoperative ultrasound offers efficient,
cost-effective and radiation-free guidance. Our objective is to aid physicians
in identifying internal liver structures using laparoscopic intraoperative
ultrasound. We propose a patient-specific approach using preoperative 3D
ultrasound liver volume to train a deep learning model for real-time
identification of portal tree and branch structures. Our personalized AI model,
validated on ex vivo swine livers, achieved superior precision (0.95) and
recall (0.93) compared to surgeons, laying groundwork for precise vessel
identification in ultrasound-based liver resection. Its adaptability and
potential clinical impact promise to advance surgical interventions and improve
patient care.

摘要：腹腔鏡肝切除術與傳統開放式手術相比，較不易產生併發症，且能維持患者的治療結果，但其複雜性阻礙了廣泛採用，原因在於難以呈現肝臟的內部結構。腹腔鏡術中超音波提供有效、經濟且無輻射的導引。我們的目標是協助醫師使用腹腔鏡術中超音波來辨識肝臟的內部結構。我們提出一個使用術前 3D 超音波肝臟體積來訓練深度學習模型，以即時辨識門脈樹和分支結構的患者特定方法。我們的個人化人工智慧模型在離體豬肝臟上驗證，與外科醫師相比，達到了更高的精確度 (0.95) 和召回率 (0.93)，為基於超音波的肝臟切除術中精確血管辨識奠定了基礎。其適應性和潛在的臨床影響有望推進外科手術，並改善患者照護。

##### **Make Interval Bound Propagation great again**
2410.03373v1 by Patryk Krukowski, Daniel Wilczak, Jacek Tabor, Anna Bielawska, Przemysław Spurek

In various scenarios motivated by real life, such as medical data analysis,
autonomous driving, and adversarial training, we are interested in robust deep
networks. A network is robust when a relatively small perturbation of the input
cannot lead to drastic changes in output (like change of class, etc.). This
falls under the broader scope field of Neural Network Certification (NNC). Two
crucial problems in NNC are of profound interest to the scientific community:
how to calculate the robustness of a given pre-trained network and how to
construct robust networks. The common approach to constructing robust networks
is Interval Bound Propagation (IBP). This paper demonstrates that IBP is
sub-optimal in the first case due to its susceptibility to the wrapping effect.
Even for linear activation, IBP gives strongly sub-optimal bounds.
Consequently, one should use strategies immune to the wrapping effect to obtain
bounds close to optimal ones. We adapt two classical approaches dedicated to
strict computations -- Dubleton Arithmetic and Affine Arithmetic -- to mitigate
the wrapping effect in neural networks. These techniques yield precise results
for networks with linear activation functions, thus resisting the wrapping
effect. As a result, we achieve bounds significantly closer to the optimal
level than IBPs.

摘要：在各種受現實生活激勵的場景中，例如醫學數據分析、自動駕駛和對抗性訓練，我們對強健的深度網路感興趣。當輸入的微小擾動不會導致輸出發生劇烈變化（例如類別改變等）時，網路就是強健的。這屬於神經網路認證 (NNC) 的廣泛範疇。NNC 中的兩個關鍵問題引起了科學界的濃厚興趣：如何計算給定預訓練網路的強健性，以及如何構建強健網路。構建強健網路的常見方法是區間邊界傳播 (IBP)。本文證明，由於 IBP 容易受到包覆效應的影響，因此在第一種情況下它是次優的。即使對於線性激活，IBP 也會給出強烈的次優邊界。因此，應使用對包覆效應免疫的策略來獲得接近最優邊界的邊界。我們調整了專門用於嚴格計算的兩種經典方法——雙元運算和仿射運算——以減輕神經網路中的包覆效應。這些技術對具有線性激活函數的網路產生精確的結果，從而抵抗包覆效應。因此，我們實現的邊界顯著接近於 IBP 的最優級別。

##### **An Enhanced Harmonic Densely Connected Hybrid Transformer Network Architecture for Chronic Wound Segmentation Utilising Multi-Colour Space Tensor Merging**
2410.03359v1 by Bill Cassidy, Christian Mcbride, Connah Kendrick, Neil D. Reeves, Joseph M. Pappachan, Cornelius J. Fernandez, Elias Chacko, Raphael Brüngel, Christoph M. Friedrich, Metib Alotaibi, Abdullah Abdulaziz AlWabel, Mohammad Alderwish, Kuan-Ying Lai, Moi Hoon Yap

Chronic wounds and associated complications present ever growing burdens for
clinics and hospitals world wide. Venous, arterial, diabetic, and pressure
wounds are becoming increasingly common globally. These conditions can result
in highly debilitating repercussions for those affected, with limb amputations
and increased mortality risk resulting from infection becoming more common. New
methods to assist clinicians in chronic wound care are therefore vital to
maintain high quality care standards. This paper presents an improved HarDNet
segmentation architecture which integrates a contrast-eliminating component in
the initial layers of the network to enhance feature learning. We also utilise
a multi-colour space tensor merging process and adjust the harmonic shape of
the convolution blocks to facilitate these additional features. We train our
proposed model using wound images from light-skinned patients and test the
model on two test sets (one set with ground truth, and one without) comprising
only darker-skinned cases. Subjective ratings are obtained from clinical wound
experts with intraclass correlation coefficient used to determine inter-rater
reliability. For the dark-skin tone test set with ground truth, we demonstrate
improvements in terms of Dice similarity coefficient (+0.1221) and intersection
over union (+0.1274). Qualitative analysis showed high expert ratings, with
improvements of >3% demonstrated when comparing the baseline model with the
proposed model. This paper presents the first study to focus on darker-skin
tones for chronic wound segmentation using models trained only on wound images
exhibiting lighter skin. Diabetes is highly prevalent in countries where
patients have darker skin tones, highlighting the need for a greater focus on
such cases. Additionally, we conduct the largest qualitative study to date for
chronic wound segmentation.

摘要：<paragraph>慢性傷口及其併發症對全球診所和醫院而言，帶來日益沉重的負擔。靜脈性、動脈性、糖尿病性和壓瘡在全球愈來愈普遍。這些疾病會對患者造成高度衰弱的影響，截肢和因感染而導致的死亡風險也日益普遍。因此，新的方法協助臨床醫生進行慢性傷口照護至關重要，以維持高品質的照護標準。本文提出一個改良的 HarDNet 分割架構，將對比消除元件整合到網路的初始層，以增強特徵學習。我們也利用多色彩空間張量合併程序，並調整卷積區塊的諧波形狀，以利於這些額外特徵。我們使用淺膚色患者的傷口影像訓練我們提出的模型，並在兩個測試組（一個組有基本事實，一個組沒有）上測試模型，這些組僅包含較深膚色的病例。從臨床傷口專家取得主觀評分，並使用類內相關係數來確定評分者間信賴度。對於有基本事實的深膚色測試組，我們展示了骰子相似係數 (+0.1221) 和聯集比交集 (+0.1274) 的改進。定性分析顯示專家評分很高，與基準模型相比，提出的模型顯示出 >3% 的改進。本文提出第一個研究，專注於使用僅在表現出較淺膚色的傷口影像上訓練的模型，進行深膚色慢性傷口分割。糖尿病在患者膚色較深的國家非常普遍，強調需要更多關注此類病例。此外，我們進行了迄今為止最大的慢性傷口分割定性研究。</paragraph>

##### **Comparative Analysis and Ensemble Enhancement of Leading CNN Architectures for Breast Cancer Classification**
2410.03333v1 by Gary Murphy, Raghubir Singh

This study introduces a novel and accurate approach to breast cancer
classification using histopathology images. It systematically compares leading
Convolutional Neural Network (CNN) models across varying image datasets,
identifies their optimal hyperparameters, and ranks them based on
classification efficacy. To maximize classification accuracy for each model we
explore, the effects of data augmentation, alternative fully-connected layers,
model training hyperparameter settings, and, the advantages of retraining
models versus using pre-trained weights. Our methodology includes several
original concepts, including serializing generated datasets to ensure
consistent data conditions across training runs and significantly reducing
training duration. Combined with automated curation of results, this enabled
the exploration of over 2,000 training permutations -- such a comprehensive
comparison is as yet unprecedented. Our findings establish the settings
required to achieve exceptional classification accuracy for standalone CNN
models and rank them by model efficacy. Based on these results, we propose
ensemble architectures that stack three high-performing standalone CNN models
together with diverse classifiers, resulting in improved classification
accuracy. The ability to systematically run so many model permutations to get
the best outcomes gives rise to very high quality results, including 99.75% for
BreakHis x40 and BreakHis x200 and 95.18% for the Bach datasets when split into
train, validation and test datasets. The Bach Online blind challenge, yielded
89% using this approach. Whilst this study is based on breast cancer
histopathology image datasets, the methodology is equally applicable to other
medical image datasets.

摘要：本研究引入了一種新穎且準確的方法，使用組織病理學影像來對乳癌進行分類。它系統性地比較了在不同影像資料集中的領先卷積神經網路 (CNN) 模型，找出它們最佳的超參數，並根據分類效能對它們進行排名。為了最大化我們探索的每個模型的分類準確度，我們探討了資料擴充、替代全連接層、模型訓練超參數設定，以及重新訓練模型與使用預訓練權重的優點。我們的做法包含了幾個原始概念，包括序列化產生的資料集，以確保在訓練過程中資料條件一致，並大幅縮短訓練時間。結合自動化結果整理，這使得我們能夠探索超過 2,000 個訓練排列組合——如此全面的比較在目前為止是前所未有的。我們的發現建立了達成傑出分類準確度所需的設定，並根據模型效能對獨立的 CNN 模型進行排名。根據這些結果，我們提出了將三個高性能獨立 CNN 模型與不同的分類器堆疊在一起的整體架構，進而提升了分類準確度。系統性地執行這麼多模型排列組合以獲得最佳結果的能力，產生了非常高品質的結果，包括將 BreakHis x40 和 BreakHis x200 分割成訓練、驗證和測試資料集時，準確度達到 99.75%，而 Bach 資料集的準確度達到 95.18%。使用這種方法，Bach Online 盲測的準確度達到 89%。雖然本研究是基於乳癌組織病理學影像資料集，但此方法同樣適用於其他醫學影像資料集。

##### **Manikin-Recorded Cardiopulmonary Sounds Dataset Using Digital Stethoscope**
2410.03280v1 by Yasaman Torabi, Shahram Shirani, James P. Reilly

Heart and lung sounds are crucial for healthcare monitoring. Recent
improvements in stethoscope technology have made it possible to capture patient
sounds with enhanced precision. In this dataset, we used a digital stethoscope
to capture both heart and lung sounds, including individual and mixed
recordings. To our knowledge, this is the first dataset to offer both separate
and mixed cardiorespiratory sounds. The recordings were collected from a
clinical manikin, a patient simulator designed to replicate human physiological
conditions, generating clean heart and lung sounds at different body locations.
This dataset includes both normal sounds and various abnormalities (i.e.,
murmur, atrial fibrillation, tachycardia, atrioventricular block, third and
fourth heart sound, wheezing, crackles, rhonchi, pleural rub, and gurgling
sounds). The dataset includes audio recordings of chest examinations performed
at different anatomical locations, as determined by specialist nurses. Each
recording has been enhanced using frequency filters to highlight specific sound
types. This dataset is useful for applications in artificial intelligence, such
as automated cardiopulmonary disease detection, sound classification,
unsupervised separation techniques, and deep learning algorithms related to
audio signal processing.

摘要：心臟與肺部聲音對於醫療保健監測至關重要。最近在聽診器技術方面的進步，使得以更高的精準度擷取患者聲音成為可能。在這個資料集中，我們使用數位聽診器擷取心臟與肺部聲音，包括個別和混合的錄音。據我們所知，這是第一個提供個別和混合的心肺聲音的資料集。這些錄音是從臨床假人收集的，臨床假人是一種模擬人體生理狀況的患者模擬器，可在不同身體部位產生乾淨的心臟和肺部聲音。這個資料集包含正常聲音和各種異常（例如，雜音、心房顫動、心動過速、房室傳導阻滯、第三和第四心音、喘鳴、爆裂音、囉音、胸膜摩擦音和咕嚕聲）。這個資料集包含在不同解剖位置進行胸部檢查的音訊錄音，由專科護理師確定。每個錄音都使用頻率濾波器進行加強，以突顯特定的聲音類型。這個資料集對於人工智慧的應用很有用，例如自動心肺疾病偵測、聲音分類、無監督分離技術和與音訊訊號處理相關的深度學習演算法。

##### **Looking into Concept Explanation Methods for Diabetic Retinopathy Classification**
2410.03188v1 by Andrea M. Storås, Josefine V. Sundgaard

Diabetic retinopathy is a common complication of diabetes, and monitoring the
progression of retinal abnormalities using fundus imaging is crucial. Because
the images must be interpreted by a medical expert, it is infeasible to screen
all individuals with diabetes for diabetic retinopathy. Deep learning has shown
impressive results for automatic analysis and grading of fundus images. One
drawback is, however, the lack of interpretability, which hampers the
implementation of such systems in the clinic. Explainable artificial
intelligence methods can be applied to explain the deep neural networks.
Explanations based on concepts have shown to be intuitive for humans to
understand, but have not yet been explored in detail for diabetic retinopathy
grading. This work investigates and compares two concept-based explanation
techniques for explaining deep neural networks developed for automatic
diagnosis of diabetic retinopathy: Quantitative Testing with Concept Activation
Vectors and Concept Bottleneck Models. We found that both methods have
strengths and weaknesses, and choice of method should take the available data
and the end user's preferences into account.

摘要：糖尿病視網膜病變是糖尿病的常見併發症，使用眼底成像監控視網膜異常的進展至關重要。由於影像必須由醫療專家解釋，因此不可能篩選出所有患有糖尿病視網膜病變的糖尿病患者。深度學習已在眼底影像的自動分析和分級方面展現出令人印象深刻的成果。然而，其中一個缺點是缺乏可解釋性，這阻礙了此類系統在臨床上的實施。可解釋的人工智慧方法可應用於解釋深度神經網路。基於概念的解釋已被證明對人類來說直觀易懂，但尚未詳細探討糖尿病視網膜病變分級。這項工作探討並比較了兩種基於概念的解釋技術，用於解釋為糖尿病視網膜病變自動診斷而開發的深度神經網路：使用概念激活向量進行的定量測試和概念瓶頸模型。我們發現這兩種方法各有優缺點，方法的選擇應考慮可用的資料和最終使用者的偏好。

##### **Remaining Useful Life Prediction: A Study on Multidimensional Industrial Signal Processing and Efficient Transfer Learning Based on Large Language Models**
2410.03134v1 by Yan Chen, Cheng Liu

Remaining useful life (RUL) prediction is crucial for maintaining modern
industrial systems, where equipment reliability and operational safety are
paramount. Traditional methods, based on small-scale deep learning or
physical/statistical models, often struggle with complex, multidimensional
sensor data and varying operating conditions, limiting their generalization
capabilities. To address these challenges, this paper introduces an innovative
regression framework utilizing large language models (LLMs) for RUL prediction.
By leveraging the modeling power of LLMs pre-trained on corpus data, the
proposed model can effectively capture complex temporal dependencies and
improve prediction accuracy. Extensive experiments on the Turbofan engine's RUL
prediction task show that the proposed model surpasses state-of-the-art (SOTA)
methods on the challenging FD002 and FD004 subsets and achieves near-SOTA
results on the other subsets. Notably, different from previous research, our
framework uses the same sliding window length and all sensor signals for all
subsets, demonstrating strong consistency and generalization. Moreover,
transfer learning experiments reveal that with minimal target domain data for
fine-tuning, the model outperforms SOTA methods trained on full target domain
data. This research highlights the significant potential of LLMs in industrial
signal processing and RUL prediction, offering a forward-looking solution for
health management in future intelligent industrial systems.

摘要：剩餘使用壽命 (RUL) 預測對於維護現代工業系統至關重要，在這些系統中，設備可靠性和操作安全至上。傳統方法基於小規模深度學習或物理/統計模型，通常難以處理複雜、多維度的感測器資料和不同的操作條件，限制了它們的泛化能力。為了應對這些挑戰，本文介紹了一個創新的回歸架構，利用大型語言模型 (LLM) 來進行 RUL 預測。通過利用在語料資料上預先訓練的 LLM 的建模能力，所提出的模型可以有效地捕捉複雜的時間依賴性並提高預測準確度。在渦輪風扇引擎的 RUL 預測任務上進行的廣泛實驗表明，所提出的模型在具有挑戰性的 FD002 和 FD004 子集中超越了最先進 (SOTA) 的方法，並在其他子集中達到了接近 SOTA 的結果。值得注意的是，與先前的研究不同，我們的框架對所有子集都使用相同的滑動窗口長度和所有感測器訊號，展示了強大的相容性和泛化能力。此外，轉移學習實驗表明，透過對微調進行最少的目標網域資料，該模型的表現優於在完整目標網域資料上訓練的 SOTA 方法。這項研究突顯了 LLM 在工業訊號處理和 RUL 預測中的巨大潛力，為未來智慧工業系統中的健康管理提供了前瞻性的解決方案。

##### **Image First or Text First? Optimising the Sequencing of Modalities in Large Language Model Prompting and Reasoning Tasks**
2410.03062v1 by Grant Wardle, Teo Susnjak

This paper examines how the sequencing of images and text within multi-modal
prompts influences the reasoning performance of large language models (LLMs).
We performed empirical evaluations using three commercial LLMs. Our results
demonstrate that the order in which modalities are presented can significantly
affect performance, particularly in tasks of varying complexity. For simpler
tasks involving a single image, modality sequencing had a clear impact on
accuracy. However, in more complex tasks involving multiple images and
intricate reasoning steps, the effect of sequencing diminished, likely due to
the increased cognitive demands of the task. Our findings also highlight the
importance of question/prompt structure. In nested and multi-step reasoning
tasks, modality sequencing played a key role in shaping model performance.
While LLMs excelled in the initial stages of reasoning, they struggled to
re-incorporate earlier information, underscoring the challenges of multi-hop
reasoning within transformer architectures. This suggests that aligning the
sequence of modalities with the logical flow of reasoning steps is more
critical than modality order alone. These insights offer valuable implications
for improving multi-modal prompt design, with broader applications across
fields such as education, medical imaging, and cross-modal learning.

摘要：本文探討在多模態提示中影像和文字的順序如何影響大型語言模型 (LLM) 的推理表現。我們使用三個商用 LLM 進行實證評估。我們的結果表明，模態呈現的順序會顯著影響表現，特別是在不同複雜度任務中。對於涉及單一影像的較簡單任務，模態順序對準確度有明顯影響。然而，在涉及多個影像和複雜推理步驟的較複雜任務中，順序的影響減弱，這可能是由於任務的認知需求增加。我們的發現也突顯了問題/提示結構的重要性。在嵌套和多步驟推理任務中，模態順序在塑造模型表現中扮演關鍵角色。雖然 LLM 在推理的初始階段表現出色，但它們難以重新整合早期的資訊，這凸顯了Transformer架構中多跳推理的挑戰。這表明將模態順序與推理步驟的邏輯流程對齊比單獨的模態順序更為重要。這些見解為改善多模態提示設計提供了寶貴的啟示，並在教育、醫學影像和跨模態學習等領域有更廣泛的應用。

##### **Is Your Paper Being Reviewed by an LLM? Investigating AI Text Detectability in Peer Review**
2410.03019v1 by Sungduk Yu, Man Luo, Avinash Madasu, Vasudev Lal, Phillip Howard

Peer review is a critical process for ensuring the integrity of published
scientific research. Confidence in this process is predicated on the assumption
that experts in the relevant domain give careful consideration to the merits of
manuscripts which are submitted for publication. With the recent rapid
advancements in the linguistic capabilities of large language models (LLMs), a
new potential risk to the peer review process is that negligent reviewers will
rely on LLMs to perform the often time consuming process of reviewing a paper.
In this study, we investigate the ability of existing AI text detection
algorithms to distinguish between peer reviews written by humans and different
state-of-the-art LLMs. Our analysis shows that existing approaches fail to
identify many GPT-4o written reviews without also producing a high number of
false positive classifications. To address this deficiency, we propose a new
detection approach which surpasses existing methods in the identification of
GPT-4o written peer reviews at low levels of false positive classifications.
Our work reveals the difficulty of accurately identifying AI-generated text at
the individual review level, highlighting the urgent need for new tools and
methods to detect this type of unethical application of generative AI.

摘要：同儕審查是確保已發表的科學研究的完整性的關鍵過程。對此過程的信心建立在一個假設之上，即相關領域的專家會仔細考慮提交出版的稿件的優點。隨著大型語言模型 (LLM) 的語言能力最近的快速進展，對同儕審查過程的一個新的潛在風險是，疏忽的審查員會依賴 LLM 來執行審查論文這個常常很耗時的過程。在本研究中，我們調查了現有 AI 文字偵測演算法區分由人類撰寫的同儕審查和不同的最先進 LLM 的能力。我們的分析顯示，現有的方法無法識別許多 GPT-4o 寫的評論，同時也不會產生大量的假陽性分類。為了解決這個缺陷，我們提出了一種新的偵測方法，它在低水平的假陽性分類中超越了現有的方法，識別 GPT-4o 寫的同儕審查。我們的研究揭示了在個別審查層級準確識別 AI 生成的文字的難度，強調了迫切需要新的工具和方法來偵測這種不道德的生成式 AI 應用。

##### **DailyDilemmas: Revealing Value Preferences of LLMs with Quandaries of Daily Life**
2410.02683v1 by Yu Ying Chiu, Liwei Jiang, Yejin Choi

As we increasingly seek guidance from LLMs for decision-making in daily life,
many of these decisions are not clear-cut and depend significantly on the
personal values and ethical standards of the users. We present DailyDilemmas, a
dataset of 1,360 moral dilemmas encountered in everyday life. Each dilemma
includes two possible actions and with each action, the affected parties and
human values invoked. Based on these dilemmas, we consolidated a set of human
values across everyday topics e.g., interpersonal relationships, workplace, and
environmental issues. We evaluated LLMs on these dilemmas to determine what
action they will take and the values represented by these actions. Then, we
analyzed these values through the lens of five popular theories inspired by
sociology, psychology and philosophy. These theories are: World Value Survey,
Moral Foundation Theory, Maslow's Hierarchy of Needs, Aristotle's Virtues, and
Plutchik Wheel of Emotion. We find that LLMs are most aligned with the
self-expression over survival values in terms of World Value Survey, care over
loyalty in Moral Foundation Theory. Interestingly, we find large preferences
differences in models for some core values such as truthfulness e.g.,
Mixtral-8x7B model tends to neglect it by 9.7% while GPT-4-turbo model tends to
select it by 9.4%. We also study the recent guidance released by OpenAI
(ModelSpec), and Anthropic (Constitutional AI) to understand how their released
principles reflect their actual value prioritization when facing nuanced moral
reasoning in daily-life settings. We find that end users cannot effectively
steer such prioritization using system prompts.

摘要：<paragraph>隨著我們在日常生活中越來越依賴 LLM 來進行決策，
其中許多決策並非明確，而且在很大程度上取決於
使用者的個人價值觀和道德標準。我們提出了日常困境，一個
在日常生活中遇到的 1,360 個道德困境的數據集。每個困境
包含兩個可能的行動，並針對每個行動，受到影響的各方和
引發的人類價值觀。根據這些困境，我們彙整了一組人類
價值觀，涵蓋日常主題，例如人際關係、職場和
環境問題。我們針對這些困境評估 LLM，以確定它們將採取什麼
行動以及這些行動所代表的價值觀。接著，我們
透過社會學、心理學和哲學啟發的五種流行理論來分析這些價值觀。這些理論為：世界價值觀調查、
道德基礎理論、馬斯洛需求層次理論、亞里斯多德美德，以及
普拉契克情緒之輪。我們發現 LLM 在世界價值觀調查中與
生存價值觀相比，更傾向於自我表達；在道德基礎理論中，更傾向於關懷而非忠誠。有趣的是，我們發現對於某些核心價值觀，例如誠實，不同模型之間存在很大的偏好差異，例如，
Mixtral-8x7B 模型傾向於忽略它 9.7%，而 GPT-4-turbo 模型傾向於選擇它 9.4%。我們還研究了 OpenAI
(ModelSpec) 和 Anthropic (Constitutional AI) 最近發布的指導方針，以了解他們發布的原則如何在面對日常生活中微妙的道德推理時反映他們的實際價值優先順序。我們發現，最終使用者無法有效地
使用系統提示來引導此類優先順序。</paragraph>

##### **Plots Unlock Time-Series Understanding in Multimodal Models**
2410.02637v1 by Mayank Daswani, Mathias M. J. Bellaiche, Marc Wilson, Desislav Ivanov, Mikhail Papkov, Eva Schnider, Jing Tang, Kay Lamerigts, Gabriela Botea, Michael A. Sanchez, Yojan Patel, Shruthi Prabhakara, Shravya Shetty, Umesh Telang

While multimodal foundation models can now natively work with data beyond
text, they remain underutilized in analyzing the considerable amounts of
multi-dimensional time-series data in fields like healthcare, finance, and
social sciences, representing a missed opportunity for richer, data-driven
insights. This paper proposes a simple but effective method that leverages the
existing vision encoders of these models to "see" time-series data via plots,
avoiding the need for additional, potentially costly, model training. Our
empirical evaluations show that this approach outperforms providing the raw
time-series data as text, with the additional benefit that visual time-series
representations demonstrate up to a 90% reduction in model API costs. We
validate our hypothesis through synthetic data tasks of increasing complexity,
progressing from simple functional form identification on clean data, to
extracting trends from noisy scatter plots. To demonstrate generalizability
from synthetic tasks with clear reasoning steps to more complex, real-world
scenarios, we apply our approach to consumer health tasks - specifically fall
detection, activity recognition, and readiness assessment - which involve
heterogeneous, noisy data and multi-step reasoning. The overall success in plot
performance over text performance (up to an 120% performance increase on
zero-shot synthetic tasks, and up to 150% performance increase on real-world
tasks), across both GPT and Gemini model families, highlights our approach's
potential for making the best use of the native capabilities of foundation
models.

摘要：儘管多模態基礎模型現在可以原生處理文字以外的資料，但它們在分析醫療保健、金融和社會科學等領域中大量多維時間序列資料時仍未被充分利用，這代表錯失了獲得更豐富資料驅動見解的機會。本文提出了一種簡單但有效的方法，利用這些模型現有的視覺編碼器透過圖表「查看」時間序列資料，避免需要額外且可能昂貴的模型訓練。我們的經驗評估顯示，這種方法優於提供原始時間序列資料作為文字，額外的好處是視覺時間序列表示可以減少高達 90% 的模型 API 成本。我們透過日益複雜的合成資料任務驗證我們的假設，從乾淨資料上的簡單函數形式識別，到從雜訊散佈圖中萃取趨勢。為了證明從具有明確推理步驟的合成任務到更複雜的真實世界場景的概括性，我們將我們的做法應用於消費者健康任務，特別是跌倒偵測、活動識別和準備評估，這些任務涉及異質、雜訊資料和多步驟推理。在 GPT 和 Gemini 模型系列中，圖表表現優於文字表現的整體成功（在零次學習合成任務中表現提升高達 120%，在真實世界任務中表現提升高達 150%），突顯了我們的方法在最佳利用基礎模型原生功能方面的潛力。

##### **IC3M: In-Car Multimodal Multi-object Monitoring for Abnormal Status of Both Driver and Passengers**
2410.02592v3 by Zihan Fang, Zheng Lin, Senkang Hu, Hangcheng Cao, Yiqin Deng, Xianhao Chen, Yuguang Fang

Recently, in-car monitoring has emerged as a promising technology for
detecting early-stage abnormal status of the driver and providing timely alerts
to prevent traffic accidents. Although training models with multimodal data
enhances the reliability of abnormal status detection, the scarcity of labeled
data and the imbalance of class distribution impede the extraction of critical
abnormal state features, significantly deteriorating training performance.
Furthermore, missing modalities due to environment and hardware limitations
further exacerbate the challenge of abnormal status identification. More
importantly, monitoring abnormal health conditions of passengers, particularly
in elderly care, is of paramount importance but remains underexplored. To
address these challenges, we introduce our IC3M, an efficient
camera-rotation-based multimodal framework for monitoring both driver and
passengers in a car. Our IC3M comprises two key modules: an adaptive threshold
pseudo-labeling strategy and a missing modality reconstruction. The former
customizes pseudo-labeling thresholds for different classes based on the class
distribution, generating class-balanced pseudo labels to guide model training
effectively, while the latter leverages crossmodality relationships learned
from limited labels to accurately recover missing modalities by distribution
transferring from available modalities. Extensive experimental results
demonstrate that IC3M outperforms state-of-the-art benchmarks in accuracy,
precision, and recall while exhibiting superior robustness under limited
labeled data and severe missing modality.

摘要：<paragraph>最近，車載監控已成為一種有前途的技術，用於檢測駕駛員的早期異常狀態，並提供及時警報以防止交通事故。儘管使用多模態數據訓練模型增強了異常狀態檢測的可靠性，但標記數據的稀缺性和類別分佈的不平衡阻礙了關鍵異常狀態特徵的提取，顯著降低了訓練性能。此外，由於環境和硬體限制而導致的模態缺失進一步加劇了異常狀態識別的挑戰。更重要的是，監控乘客的異常健康狀況，特別是在老年護理中，至關重要，但仍未得到充分探索。為了應對這些挑戰，我們引入了我們的 IC3M，這是一個基於相機旋轉的高效多模態框架，用於監控汽車中的駕駛員和乘客。我們的 IC3M 包含兩個關鍵模組：自適應閾值偽標籤策略和缺失模態重建。前者根據類別分佈為不同的類別自訂偽標籤閾值，生成類別平衡的偽標籤以有效地指導模型訓練，而後者則利用從有限標籤中學習到的跨模態關係，通過從可用模態進行分佈轉移來準確恢復缺失的模態。廣泛的實驗結果表明，IC3M 在準確性、精確度和召回率方面優於最先進的基準，同時在標記數據有限和嚴重缺失模態的情況下表現出卓越的魯棒性。</paragraph>

##### **Deep Regression 2D-3D Ultrasound Registration for Liver Motion Correction in Focal Tumor Thermal Ablation**
2410.02579v1 by Shuwei Xing, Derek W. Cool, David Tessier, Elvis C. S. Chen, Terry M. Peters, Aaron Fenster

Liver tumor ablation procedures require accurate placement of the needle
applicator at the tumor centroid. The lower-cost and real-time nature of
ultrasound (US) has advantages over computed tomography (CT) for applicator
guidance, however, in some patients, liver tumors may be occult on US and tumor
mimics can make lesion identification challenging. Image registration
techniques can aid in interpreting anatomical details and identifying tumors,
but their clinical application has been hindered by the tradeoff between
alignment accuracy and runtime performance, particularly when compensating for
liver motion due to patient breathing or movement. Therefore, we propose a
2D-3D US registration approach to enable intra-procedural alignment that
mitigates errors caused by liver motion. Specifically, our approach can
correlate imbalanced 2D and 3D US image features and use continuous 6D rotation
representations to enhance the model's training stability. The dataset was
divided into 2388, 196 and 193 image pairs for training, validation and
testing, respectively. Our approach achieved a mean Euclidean distance error of
2.28 mm $\pm$ 1.81 mm and a mean geodesic angular error of 2.99$^{\circ}$ $\pm$
1.95$^{\circ}$, with a runtime of 0.22 seconds per 2D-3D US image pair. These
results demonstrate that our approach can achieve accurate alignment and
clinically acceptable runtime, indicating potential for clinical translation.

摘要：肝臟腫瘤消融手術需要將針頭施用器精準置於腫瘤中心點。超音波 (US) 成本較低且為即時影像，相較於電腦斷層掃描 (CT)，在施用器導引方面有優勢，然而，對於某些患者，肝臟腫瘤在超音波影像上可能不明顯，而腫瘤模擬會讓病灶辨識更具挑戰性。影像配準技術有助於解讀解剖細節和辨識腫瘤，但由於平衡校準準確度和執行效能，其臨床應用受到阻礙，特別是在補償因患者呼吸或移動而產生的肝臟運動時。因此，我們提出 2D-3D 超音波配準方法，以進行術中校準，減輕因肝臟運動而產生的誤差。具體來說，我們的做法可以關聯失衡的 2D 和 3D 超音波影像特徵，並使用連續的 6D 旋轉表示來增強模型的訓練穩定度。資料集分為 2388、196 和 193 影像對，分別用於訓練、驗證和測試。我們的做法達成平均歐氏距離誤差 2.28 mm $\pm$ 1.81 mm，以及平均測地角誤差 2.99$^{\circ}$ $\pm$ 1.95$^{\circ}$，執行時間為每 2D-3D 超音波影像對 0.22 秒。這些結果證明我們的做法可以達成精準校準和臨床上可接受的執行時間，顯示出臨床轉譯的潛力。

##### **ColaCare: Enhancing Electronic Health Record Modeling through Large Language Model-Driven Multi-Agent Collaboration**
2410.02551v1 by Zixiang Wang, Yinghao Zhu, Huiya Zhao, Xiaochen Zheng, Tianlong Wang, Wen Tang, Yasha Wang, Chengwei Pan, Ewen M. Harrison, Junyi Gao, Liantao Ma

We introduce ColaCare, a framework that enhances Electronic Health Record
(EHR) modeling through multi-agent collaboration driven by Large Language
Models (LLMs). Our approach seamlessly integrates domain-specific expert models
with LLMs to bridge the gap between structured EHR data and text-based
reasoning. Inspired by clinical consultations, ColaCare employs two types of
agents: DoctorAgent and MetaAgent, which collaboratively analyze patient data.
Expert models process and generate predictions from numerical EHR data, while
LLM agents produce reasoning references and decision-making reports within the
collaborative consultation framework. We additionally incorporate the Merck
Manual of Diagnosis and Therapy (MSD) medical guideline within a
retrieval-augmented generation (RAG) module for authoritative evidence support.
Extensive experiments conducted on four distinct EHR datasets demonstrate
ColaCare's superior performance in mortality prediction tasks, underscoring its
potential to revolutionize clinical decision support systems and advance
personalized precision medicine. The code, complete prompt templates, more case
studies, etc. are publicly available at the anonymous link:
https://colacare.netlify.app.

摘要：我們推出 ColaCare，一個透過大型語言模型 (LLM) 驅動的多重代理協作，來增強電子健康紀錄 (EHR) 建模的框架。我們的做法將領域特定專家模型與 LLM 無縫整合，以彌合結構化 EHR 資料與基於文字的推理之間的差距。ColaCare 受到臨床諮詢的啟發，採用了兩種代理：DoctorAgent 和 MetaAgent，它們協作分析患者資料。專家模型處理並從數值 EHR 資料產生預測，而 LLM 代理則在協作諮詢框架內產生推理參考和決策報告。我們另外在一個檢索增強生成 (RAG) 模組中納入了默克診斷與治療手冊 (MSD) 醫療指南，以獲得權威證據支持。在四個不同的 EHR 資料集上進行的廣泛實驗證明了 ColaCare 在死亡率預測任務中的優異效能，強調了其革新臨床決策支援系統和推進個人化精準醫療的潛力。程式碼、完整的提示範本、更多案例研究等，都可以在匿名連結中公開取得：https://colacare.netlify.app。

##### **SAFLEX: Self-Adaptive Augmentation via Feature Label Extrapolation**
2410.02512v1 by Mucong Ding, Bang An, Yuancheng Xu, Anirudh Satheesh, Furong Huang

Data augmentation, a cornerstone technique in deep learning, is crucial in
enhancing model performance, especially with scarce labeled data. While
traditional techniques are effective, their reliance on hand-crafted methods
limits their applicability across diverse data types and tasks. Although modern
learnable augmentation methods offer increased adaptability, they are
computationally expensive and challenging to incorporate within prevalent
augmentation workflows. In this work, we present a novel, efficient method for
data augmentation, effectively bridging the gap between existing augmentation
strategies and emerging datasets and learning tasks. We introduce SAFLEX
(Self-Adaptive Augmentation via Feature Label EXtrapolation), which learns the
sample weights and soft labels of augmented samples provided by any given
upstream augmentation pipeline, using a specifically designed efficient bilevel
optimization algorithm. Remarkably, SAFLEX effectively reduces the noise and
label errors of the upstream augmentation pipeline with a marginal
computational cost. As a versatile module, SAFLEX excels across diverse
datasets, including natural and medical images and tabular data, showcasing its
prowess in few-shot learning and out-of-distribution generalization. SAFLEX
seamlessly integrates with common augmentation strategies like RandAug, CutMix,
and those from large pre-trained generative models like stable diffusion and is
also compatible with frameworks such as CLIP's fine-tuning. Our findings
highlight the potential to adapt existing augmentation pipelines for new data
types and tasks, signaling a move towards more adaptable and resilient training
frameworks.

摘要：資料擴充是深度學習的基石技術，在提升模型效能方面至關重要，特別是在標籤資料稀少的情況下。雖然傳統技術很有效，但它們依賴於手工製作的方法，限制了它們在不同資料類型和任務中的適用性。儘管現代可學習的擴充方法提供了更高的適應性，但它們在計算上很昂貴，並且難以整合到普遍的擴充工作流程中。在這項工作中，我們提出了一種新穎、有效率的資料擴充方法，有效地彌合了現有擴充策略與新興資料集和學習任務之間的差距。我們引入了 SAFLEX（透過特徵標籤外推進行自適應擴充），它使用專門設計的有效雙層次最佳化演算法，學習由任何給定的上游擴充管道提供的擴充樣本的樣本權重和軟標籤。值得注意的是，SAFLEX 有效地降低了上游擴充管道的雜訊和標籤錯誤，且計算成本很低。作為一個多功能模組，SAFLEX 在各種資料集中表現出色，包括自然和醫學影像以及表格資料，展示了它在少樣本學習和分布外概括中的優異能力。SAFLEX 與常見的擴充策略（如 RandAug、CutMix，以及來自大型預訓練生成模型（如穩定擴散）的擴充策略）無縫整合，並且也相容於 CLIP 的微調等框架。我們的研究結果突顯了調整現有擴充管道以適應新資料類型和任務的潛力，標誌著朝向更具適應性和韌性的訓練框架邁進。

##### **Clinnova Federated Learning Proof of Concept: Key Takeaways from a Cross-border Collaboration**
2410.02443v1 by Julia Alekseenko, Bram Stieltjes, Michael Bach, Melanie Boerries, Oliver Opitz, Alexandros Karargyris, Nicolas Padoy

Clinnova, a collaborative initiative involving France, Germany, Switzerland,
and Luxembourg, is dedicated to unlocking the power of precision medicine
through data federation, standardization, and interoperability. This European
Greater Region initiative seeks to create an interoperable European standard
using artificial intelligence (AI) and data science to enhance healthcare
outcomes and efficiency. Key components include multidisciplinary research
centers, a federated biobanking strategy, a digital health innovation platform,
and a federated AI strategy. It targets inflammatory bowel disease, rheumatoid
diseases, and multiple sclerosis (MS), emphasizing data quality to develop AI
algorithms for personalized treatment and translational research.
  The IHU Strasbourg (Institute of Minimal-invasive Surgery) has the lead in
this initiative to develop the federated learning (FL) proof of concept (POC)
that will serve as a foundation for advancing AI in healthcare. At its core,
Clinnova-MS aims to enhance MS patient care by using FL to develop more
accurate models that detect disease progression, guide interventions, and
validate digital biomarkers across multiple sites. This technical report
presents insights and key takeaways from the first cross-border federated POC
on MS segmentation of MRI images within the Clinnova framework. While our work
marks a significant milestone in advancing MS segmentation through cross-border
collaboration, it also underscores the importance of addressing technical,
logistical, and ethical considerations to realize the full potential of FL in
healthcare settings.

摘要：Clinnova 是一項由法國、德國、瑞士和盧森堡合作發起的計畫，致力於透過資料聯合、標準化和互通性來釋放精準醫療的力量。這個歐洲大區計畫旨在使用人工智慧 (AI) 和資料科學建立一個可互通的歐洲標準，以提升醫療保健成果和效率。主要組成部分包括跨領域研究中心、聯合生物銀行策略、數位健康創新平台和聯合 AI 策略。它針對發炎性腸道疾病、類風濕性疾病和多發性硬化症 (MS) 進行研究，強調資料品質以開發 AI 演算法，用於個人化治療和轉譯研究。
史特拉斯堡 IHU（微創手術研究所）在這個計畫中領先開發聯合學習 (FL) 概念驗證 (POC)，這將作為在醫療保健中推進 AI 的基礎。Clinnova-MS 的核心目標是透過使用 FL 來提升 MS 患者照護，以開發更精確的模型來偵測疾病進程、引導介入措施，並驗證多個地點的數位生物標記。這份技術報告提供了 Clinnova 架構內 MS 磁振造影影像分割首次跨境聯合 POC 的見解和主要結論。雖然我們的成果在透過跨境合作推進 MS 分割方面是一個重要的里程碑，但也強調了在醫療保健環境中實現 FL 的全部潛力時，解決技術、後勤和倫理考量的必要性。

##### **A Comprehensive Survey of Mamba Architectures for Medical Image Analysis: Classification, Segmentation, Restoration and Beyond**
2410.02362v1 by Shubhi Bansal, Sreeharish A, Madhava Prasath J, Manikandan S, Sreekanth Madisetty, Mohammad Zia Ur Rehman, Chandravardhan Singh Raghaw, Gaurav Duggal, Nagendra Kumar

Mamba, a special case of the State Space Model, is gaining popularity as an
alternative to template-based deep learning approaches in medical image
analysis. While transformers are powerful architectures, they have drawbacks,
including quadratic computational complexity and an inability to address
long-range dependencies efficiently. This limitation affects the analysis of
large and complex datasets in medical imaging, where there are many spatial and
temporal relationships. In contrast, Mamba offers benefits that make it
well-suited for medical image analysis. It has linear time complexity, which is
a significant improvement over transformers. Mamba processes longer sequences
without attention mechanisms, enabling faster inference and requiring less
memory. Mamba also demonstrates strong performance in merging multimodal data,
improving diagnosis accuracy and patient outcomes. The organization of this
paper allows readers to appreciate the capabilities of Mamba in medical imaging
step by step. We begin by defining core concepts of SSMs and models, including
S4, S5, and S6, followed by an exploration of Mamba architectures such as pure
Mamba, U-Net variants, and hybrid models with convolutional neural networks,
transformers, and Graph Neural Networks. We also cover Mamba optimizations,
techniques and adaptations, scanning, datasets, applications, experimental
results, and conclude with its challenges and future directions in medical
imaging. This review aims to demonstrate the transformative potential of Mamba
in overcoming existing barriers within medical imaging while paving the way for
innovative advancements in the field. A comprehensive list of Mamba
architectures applied in the medical field, reviewed in this work, is available
at Github.

摘要：Mamba 是一種特殊類型的狀態空間模型，逐漸受到重視，成為醫學影像分析中基於範本的深度學習方法的替代方案。儘管Transformer是強大的架構，但它們有缺點，包括二次計算複雜度，以及無法有效處理長距離依賴性。這種限制會影響醫學影像中大型複雜資料集的分析，其中有許多空間和時間關係。相比之下，Mamba 提供的優點使其非常適合醫學影像分析。它具有線性時間複雜度，這是一個比Transformer顯著的改進。Mamba 在沒有注意機制的情況下處理更長的序列，從而實現更快的推理並需要更少的記憶體。Mamba 在合併多模態數據方面也表現出強大的效能，提高了診斷準確性和患者預後。本文的組織方式讓讀者可以逐步了解 Mamba 在醫學影像中的功能。我們從定義 SSM 和模型的核心概念開始，包括 S4、S5 和 S6，然後探討 Mamba 架構，例如純 Mamba、U-Net 變體，以及帶有卷積神經網路、Transformer和圖神經網路的混合模型。我們還涵蓋了 Mamba 最佳化、技術和改編、掃描、資料集、應用、實驗結果，並以其在醫學影像中的挑戰和未來方向作為結論。本篇評論旨在展示 Mamba 在克服醫學影像中現有障礙方面的轉型潛力，同時為該領域的創新進步鋪平道路。在這項工作中回顧的應用於醫學領域的 Mamba 架構的綜合清單可在 Github 上取得。

##### **CTARR: A fast and robust method for identifying anatomical regions on CT images via atlas registration**
2410.02316v1 by Thomas Buddenkotte, Roland Opfer, Julia Krüger, Alessa Hering, Mireia Crispin-Ortuzar

Medical image analysis tasks often focus on regions or structures located in
a particular location within the patient's body. Often large parts of the image
may not be of interest for the image analysis task. When using deep-learning
based approaches, this causes an unnecessary increases the computational burden
during inference and raises the chance of errors. In this paper, we introduce
CTARR, a novel generic method for CT Anatomical Region Recognition. The method
serves as a pre-processing step for any deep learning-based CT image analysis
pipeline by automatically identifying the pre-defined anatomical region that is
relevant for the follow-up task and removing the rest. It can be used in (i)
image segmentation to prevent false positives in anatomically implausible
regions and speeding up the inference, (ii) image classification to produce
image crops that are consistent in their anatomical context, and (iii) image
registration by serving as a fast pre-registration step. Our proposed method is
based on atlas registration and provides a fast and robust way to crop any
anatomical region encoded as one or multiple bounding box(es) from any
unlabeled CT scan of the brain, chest, abdomen and/or pelvis. We demonstrate
the utility and robustness of the proposed method in the context of medical
image segmentation by evaluating it on six datasets of public segmentation
challenges. The foreground voxels in the regions of interest are preserved in
the vast majority of cases and tasks (97.45-100%) while taking only fractions
of a seconds to compute (0.1-0.21s) on a deep learning workstation and greatly
reducing the segmentation runtime (2.0-12.7x). Our code is available at
https://github.com/ThomasBudd/ctarr.

摘要：<paragraph>医学影像分析任务通常专注于患者体内特定位置的区域或结构。通常，影像的大部分可能与影像分析任务无关。在使用基于深度学习的方法时，这会导致在推理过程中不必要地增加计算负担并增加出错的可能性。在本文中，我们介绍了 CTARR，一种用于 CT 解剖区域识别的通用新方法。该方法作为任何基于深度学习的 CT 影像分析管道的预处理步骤，通过自动识别与后续任务相关的预定义解剖区域并移除其余部分。它可用于 (i) 影像分割，以防止在解剖上不可能的区域中出现假阳性并加快推理，(ii) 影像分类，以产生在解剖背景下一致的影像裁剪，以及 (iii) 影像配准，作为快速预配准步骤。我们提出的方法基于图谱配准，并提供了一种快速且稳健的方式，可以从大脑、胸部、腹部和/或骨盆的任何未标记 CT 扫描中裁剪编码为一个或多个边界框的任何解剖区域。我们通过在六个公共分割挑战数据集上对其进行评估，证明了所提出方法在医学影像分割方面的实用性和稳健性。在绝大多数情况下和任务中（97.45-100%），感兴趣区域中的前景体素得以保留，同时仅需在深度学习工作站上花费几分之一秒（0.1-0.21 秒）进行计算，并且极大地缩短了分割运行时间（2.0-12.7 倍）。我们的代码可在 https://github.com/ThomasBudd/ctarr 上获取。</paragraph>

##### **Multi-Omic and Quantum Machine Learning Integration for Lung Subtypes Classification**
2410.02085v1 by Mandeep Kaur Saggi, Amandeep Singh Bhatia, Mensah Isaiah, Humaira Gowher, Sabre Kais

Quantum Machine Learning (QML) is a red-hot field that brings novel
discoveries and exciting opportunities to resolve, speed up, or refine the
analysis of a wide range of computational problems. In the realm of biomedical
research and personalized medicine, the significance of multi-omics integration
lies in its ability to provide a thorough and holistic comprehension of complex
biological systems. This technology links fundamental research to clinical
practice. The insights gained from integrated omics data can be translated into
clinical tools for diagnosis, prognosis, and treatment planning. The fusion of
quantum computing and machine learning holds promise for unraveling complex
patterns within multi-omics datasets, providing unprecedented insights into the
molecular landscape of lung cancer. Due to the heterogeneity, complexity, and
high dimensionality of multi-omic cancer data, characterized by the vast number
of features (such as gene expression, micro-RNA, and DNA methylation) relative
to the limited number of lung cancer patient samples, our prime motivation for
this paper is the integration of multi-omic data, unique feature selection, and
diagnostic classification of lung subtypes: lung squamous cell carcinoma
(LUSC-I) and lung adenocarcinoma (LUAD-II) using quantum machine learning. We
developed a method for finding the best differentiating features between LUAD
and LUSC datasets, which has the potential for biomarker discovery.

摘要：量子機器學習 (QML) 是個熱門領域，它帶來新穎的發現和令人興奮的機會，用於解決、加速或改進對各種計算問題的分析。在生物醫學研究和個人化醫療領域，多組學整合的重要性在於它能夠提供對複雜生物系統全面且整體的理解。這項技術將基礎研究與臨床實務連結起來。從整合組學資料中獲得的見解可以轉化為診斷、預後和治療計畫的臨床工具。量子運算和機器學習的融合有望解開多組學資料集中的複雜模式，提供前所未有的見解，深入了解肺癌的分子層面。由於多組學癌症資料的異質性、複雜性和高維度，其特徵（例如基因表現、微型 RNA 和 DNA 甲基化）的數量相對於肺癌患者樣本的數量而言非常龐大，因此我們撰寫這篇論文的主要動機是整合多組學資料、獨特的特徵選擇，以及使用量子機器學習對肺癌亞型進行診斷分類：肺鱗狀細胞癌 (LUSC-I) 和肺腺癌 (LUAD-II)。我們開發了一種方法來找出 LUAD 和 LUSC 資料集之間最佳的區分特徵，這有潛力用於生物標記的發現。

##### **Zodiac: A Cardiologist-Level LLM Framework for Multi-Agent Diagnostics**
2410.02026v1 by Yuan Zhou, Peng Zhang, Mengya Song, Alice Zheng, Yiwen Lu, Zhiheng Liu, Yong Chen, Zhaohan Xi

Large language models (LLMs) have demonstrated remarkable progress in
healthcare. However, a significant gap remains regarding LLMs' professionalism
in domain-specific clinical practices, limiting their application in real-world
diagnostics. In this work, we introduce ZODIAC, an LLM-powered framework with
cardiologist-level professionalism designed to engage LLMs in cardiological
diagnostics. ZODIAC assists cardiologists by extracting clinically relevant
characteristics from patient data, detecting significant arrhythmias, and
generating preliminary reports for the review and refinement by cardiologists.
To achieve cardiologist-level professionalism, ZODIAC is built on a multi-agent
collaboration framework, enabling the processing of patient data across
multiple modalities. Each LLM agent is fine-tuned using real-world patient data
adjudicated by cardiologists, reinforcing the model's professionalism. ZODIAC
undergoes rigorous clinical validation with independent cardiologists,
evaluated across eight metrics that measure clinical effectiveness and address
security concerns. Results show that ZODIAC outperforms industry-leading
models, including OpenAI's GPT-4o, Meta's Llama-3.1-405B, and Google's
Gemini-pro, as well as medical-specialist LLMs like Microsoft's BioGPT. ZODIAC
demonstrates the transformative potential of specialized LLMs in healthcare by
delivering domain-specific solutions that meet the stringent demands of medical
practice. Notably, ZODIAC has been successfully integrated into
electrocardiography (ECG) devices, exemplifying the growing trend of embedding
LLMs into Software-as-Medical-Device (SaMD).

摘要：大型語言模型 (LLM) 已在醫療保健領域展現出顯著的進展。然而，LLM 在特定領域的臨床實務中專業性方面仍存在顯著差距，這限制了它們在真實世界診斷中的應用。在這項工作中，我們引入了 ZODIAC，一個由 LLM 驅動的架構，具備心臟病專科醫師等級的專業素養，旨在讓 LLM 參與心臟病診斷。ZODIAC 透過從患者資料中提取臨床相關特徵、偵測顯著心律不整，以及產生初步報告供心臟病專科醫師檢閱和修改，來協助心臟病專科醫師。為了達到心臟病專科醫師等級的專業素養，ZODIAC 建立在多代理協作架構上，讓不同方式的患者資料能夠處理。每個 LLM 代理使用由心臟病專科醫師裁定的真實世界患者資料進行微調，強化模型的專業素養。ZODIAC 進行嚴格的臨床驗證，由獨立的心臟病專科醫師進行評估，評量八項衡量臨床有效性並解決安全問題的指標。結果顯示，ZODIAC 的表現優於業界領先的模型，包括 OpenAI 的 GPT-4o、Meta 的 Llama-3.1-405B，以及 Google 的 Gemini-pro，以及像 Microsoft 的 BioGPT 等醫療專家 LLM。ZODIAC 透過提供符合醫療實務嚴格要求的特定領域解決方案，證明了專業 LLM 在醫療保健領域的變革潛力。值得注意的是，ZODIAC 已成功整合到心電圖 (ECG) 設備中，這體現了將 LLM 嵌入軟體即醫療設備 (SaMD) 的趨勢。

##### **UlcerGPT: A Multimodal Approach Leveraging Large Language and Vision Models for Diabetic Foot Ulcer Image Transcription**
2410.01989v1 by Reza Basiri, Ali Abedi, Chau Nguyen, Milos R. Popovic, Shehroz S. Khan

Diabetic foot ulcers (DFUs) are a leading cause of hospitalizations and lower
limb amputations, placing a substantial burden on patients and healthcare
systems. Early detection and accurate classification of DFUs are critical for
preventing serious complications, yet many patients experience delays in
receiving care due to limited access to specialized services. Telehealth has
emerged as a promising solution, improving access to care and reducing the need
for in-person visits. The integration of artificial intelligence and pattern
recognition into telemedicine has further enhanced DFU management by enabling
automatic detection, classification, and monitoring from images. Despite
advancements in artificial intelligence-driven approaches for DFU image
analysis, the application of large language models for DFU image transcription
has not yet been explored. To address this gap, we introduce UlcerGPT, a novel
multimodal approach leveraging large language and vision models for DFU image
transcription. This framework combines advanced vision and language models,
such as Large Language and Vision Assistant and Chat Generative Pre-trained
Transformer, to transcribe DFU images by jointly detecting, classifying, and
localizing regions of interest. Through detailed experiments on a public
dataset, evaluated by expert clinicians, UlcerGPT demonstrates promising
results in the accuracy and efficiency of DFU transcription, offering potential
support for clinicians in delivering timely care via telemedicine.

摘要：糖尿病足潰瘍 (DFU) 是導致住院和下肢截肢的主要原因，對患者和醫療保健系統造成沉重負擔。早期發現和準確分類 DFU 對於預防嚴重併發症至關重要，但許多患者因無法獲得專業服務而延誤就醫。遠距醫療已成為一個有前途的解決方案，改善了就醫管道並減少親自就診的需求。將人工智慧和模式識別整合到遠距醫療進一步增強了 DFU 管理，能從影像中自動偵測、分類和監控。儘管在人工智慧驅動的 DFU 影像分析方法方面有進展，但尚未探索將大型語言模型應用於 DFU 影像轉錄。為了解決這個差距，我們引入了 UlcerGPT，這是一種新穎的多模態方法，利用大型語言和視覺模型進行 DFU 影像轉錄。此架構結合了先進的視覺和語言模型，例如大型語言和視覺助理以及聊天生成式預訓練轉換器，透過共同偵測、分類和定位感興趣區域來轉錄 DFU 影像。透過在公開資料集上進行詳細實驗，並由專家臨床醫師評估，UlcerGPT 在 DFU 轉錄的準確性和效率方面展現了有前景的結果，為臨床醫師透過遠距醫療提供及時照護提供了潛在支援。

##### **A Two-Stage Proactive Dialogue Generator for Efficient Clinical Information Collection Using Large Language Model**
2410.03770v1 by Xueshen Li, Xinlong Hou, Nirupama Ravi, Ziyi Huang, Yu Gan

Efficient patient-doctor interaction is among the key factors for a
successful disease diagnosis. During the conversation, the doctor could query
complementary diagnostic information, such as the patient's symptoms, previous
surgery, and other related information that goes beyond medical evidence data
(test results) to enhance disease diagnosis. However, this procedure is usually
time-consuming and less-efficient, which can be potentially optimized through
computer-assisted systems. As such, we propose a diagnostic dialogue system to
automate the patient information collection procedure. By exploiting medical
history and conversation logic, our conversation agents, particularly the
doctor agent, can pose multi-round clinical queries to effectively collect the
most relevant disease diagnostic information. Moreover, benefiting from our
two-stage recommendation structure, carefully designed ranking criteria, and
interactive patient agent, our model is able to overcome the under-exploration
and non-flexible challenges in dialogue generation. Our experimental results on
a real-world medical conversation dataset show that our model can generate
clinical queries that mimic the conversation style of real doctors, with
efficient fluency, professionalism, and safety, while effectively collecting
relevant disease diagnostic information.

摘要：<paragraph>有效率的病患與醫生互動是疾病診斷成功的關鍵要素之一。在對話中，醫生可以查詢補充性的診斷資訊，例如病患的症狀、先前的外科手術，以及其他相關的資訊，這些資訊超出了醫療證據資料（檢驗結果）的範圍，可以增強疾病診斷。然而，此程序通常耗時且效率較低，可以透過電腦輔助系統進行潛在的最佳化。因此，我們提出一個診斷對話系統來自動化病患資訊收集程序。透過利用病史和對話邏輯，我們的對話代理，特別是醫生代理，可以提出多輪的臨床查詢，以有效收集最相關的疾病診斷資訊。此外，得益於我們的兩階段建議結構、精心設計的排名準則和互動式病患代理，我們的模型能夠克服對話產生中的探索不足和不靈活的挑戰。我們在真實世界的醫療對話資料集上的實驗結果顯示，我們的模型可以產生模擬真實醫生對話風格的臨床查詢，具有流暢、專業和安全的效率，同時有效收集相關的疾病診斷資訊。</paragraph>

##### **DeFine: Enhancing LLM Decision-Making with Factor Profiles and Analogical Reasoning**
2410.01772v1 by Yebowen Hu, Xiaoyang Wang, Wenlin Yao, Yiming Lu, Daoan Zhang, Hassan Foroosh, Dong Yu, Fei Liu

LLMs are ideal for decision-making due to their ability to reason over long
contexts and identify critical factors. However, challenges arise when
processing transcripts of spoken speech describing complex scenarios. These
transcripts often contain ungrammatical or incomplete sentences, repetitions,
hedging, and vagueness. For example, during a company's earnings call, an
executive might project a positive revenue outlook to reassure investors,
despite significant uncertainty regarding future earnings. It is crucial for
LLMs to incorporate this uncertainty systematically when making decisions. In
this paper, we introduce DeFine, a new framework that constructs probabilistic
factor profiles from complex scenarios. DeFine then integrates these profiles
with analogical reasoning, leveraging insights from similar past experiences to
guide LLMs in making critical decisions in novel situations. Our framework
separates the tasks of quantifying uncertainty in complex scenarios and
incorporating it into LLM decision-making. This approach is particularly useful
in fields such as medical consultations, negotiations, and political debates,
where making decisions under uncertainty is vital.

摘要：LLM 非常適合用於決策制定，因為它們能夠對長篇脈絡進行推理並找出關鍵因素。然而，在處理描述複雜場景的口語轉錄時會產生挑戰。這些轉錄通常包含不符合文法或不完整的句子、重複、迴避和模糊。例如，在公司的收益電話會議中，一位主管可能會預測正面的收益前景以安撫投資人，儘管對未來的收益有很大的不確定性。對於 LLM 來說，在做決策時系統性地納入這種不確定性至關重要。在本文中，我們介紹了 DeFine，一個從複雜場景構建機率因子輪廓的新架構。然後，DeFine 將這些輪廓與類比推理整合，利用過去類似經驗中的見解來引導 LLM 在新情況中做出關鍵決策。我們的架構將量化複雜場景中的不確定性以及將其納入 LLM 決策制定的任務分開。這種方法在醫療諮詢、談判和政治辯論等領域特別有用，在這些領域中，在不確定性下做出決策至關重要。

##### **Towards a vision foundation model for comprehensive assessment of Cardiac MRI**
2410.01665v2 by Athira J Jacob, Indraneel Borgohain, Teodora Chitiboi, Puneet Sharma, Dorin Comaniciu, Daniel Rueckert

Cardiac magnetic resonance imaging (CMR), considered the gold standard for
noninvasive cardiac assessment, is a diverse and complex modality requiring a
wide variety of image processing tasks for comprehensive assessment of cardiac
morphology and function. Advances in deep learning have enabled the development
of state-of-the-art (SoTA) models for these tasks. However, model training is
challenging due to data and label scarcity, especially in the less common
imaging sequences. Moreover, each model is often trained for a specific task,
with no connection between related tasks. In this work, we introduce a vision
foundation model trained for CMR assessment, that is trained in a
self-supervised fashion on 36 million CMR images. We then finetune the model in
supervised way for 9 clinical tasks typical to a CMR workflow, across
classification, segmentation, landmark localization, and pathology detection.
We demonstrate improved accuracy and robustness across all tasks, over a range
of available labeled dataset sizes. We also demonstrate improved few-shot
learning with fewer labeled samples, a common challenge in medical image
analyses. We achieve an out-of-box performance comparable to SoTA for most
clinical tasks. The proposed method thus presents a resource-efficient, unified
framework for CMR assessment, with the potential to accelerate the development
of deep learning-based solutions for image analysis tasks, even with few
annotated data available.

摘要：心臟磁振造影 (CMR) 被視為非侵入性心臟評估的金標準，是一種多元且複雜的模式，需要廣泛的影像處理任務才能全面評估心臟形態和功能。深度學習的進步使得開發這些任務的最新技術 (SoTA) 模型成為可能。然而，模型訓練由於資料和標籤的稀少性而具有挑戰性，尤其是在較不常見的影像序列中。此外，每個模型通常針對特定任務進行訓練，與相關任務之間沒有關聯性。在這項工作中，我們引入了一個針對 CMR 評估訓練的視覺基礎模型，該模型以自監督的方式在 3600 萬張 CMR 影像上進行訓練。然後，我們以監督方式對模型進行微調，以執行 CMR 工作流程中典型的 9 項臨床任務，包括分類、分割、地標定位和病理檢測。我們證明了在各種可用標籤資料集大小中，所有任務的準確性和穩健性都有所提高。我們還展示了在標籤樣本較少的情況下改進的 few-shot 學習，這是醫學影像分析中常見的挑戰。我們實現了與大多數臨床任務的 SoTA 相當的開箱即用效能。因此，所提出的方法提供了一個資源高效的統一框架，用於 CMR 評估，並有可能加速基於深度學習的影像分析任務的解決方案開發，即使只有少量的註解資料可用。

##### **Imaging foundation model for universal enhancement of non-ideal measurement CT**
2410.01591v1 by Yuxin Liu, Rongjun Ge, Yuting He, Zhan Wu, Chenyu You, Shuo Li, Yang Chen

Non-ideal measurement computed tomography (NICT), which sacrifices optimal
imaging standards for new advantages in CT imaging, is expanding the clinical
application scope of CT images. However, with the reduction of imaging
standards, the image quality has also been reduced, extremely limiting the
clinical acceptability. Although numerous studies have demonstrated the
feasibility of deep learning for the NICT enhancement in specific scenarios,
their high data cost and limited generalizability have become large obstacles.
The recent research on the foundation model has brought new opportunities for
building a universal NICT enhancement model - bridging the image quality
degradation with minimal data cost. However, owing to the challenges in the
collection of large pre-training datasets and the compatibility of data
variation, no success has been reported. In this paper, we propose a
multi-scale integrated Transformer AMPlifier (TAMP), the first imaging
foundation model for universal NICT enhancement. It has been pre-trained on a
large-scale physical-driven simulation dataset with 3.6 million NICT-ICT image
pairs, and is able to directly generalize to the NICT enhancement tasks with
various non-ideal settings and body regions. Via the adaptation with few data,
it can further achieve professional performance in real-world specific
scenarios. Our extensive experiments have demonstrated that the proposed TAMP
has significant potential for promoting the exploration and application of NICT
and serving a wider range of medical scenarios.

摘要：非理想測量電腦斷層掃描 (NICT) 犧牲了最佳影像標準以換取電腦斷層掃描影像的新優勢，正在擴展電腦斷層影像的臨床應用範圍。然而，隨著影像標準的降低，影像品質也隨之降低，極大地限制了臨床可接受性。儘管許多研究已證明深度學習在特定場景中可行，但其高資料成本和有限的概括性已成為重大的障礙。最近對基礎模型的研究為建立通用 NICT 增強模型帶來了新的機會，以最小的資料成本彌合影像品質下降的問題。然而，由於收集大型預訓練資料集和資料變異的相容性方面的挑戰，尚未報告成功。在本文中，我們提出了一個多尺度整合Transformer放大器 (TAMP)，這是第一個用於通用 NICT 增強的影像基礎模型。它已在一個包含 360 萬個 NICT-ICT 影像對的大型物理驅動模擬資料集上進行預訓練，並且能夠直接概括到具有各種非理想設定和身體區域的 NICT 增強任務。透過少數資料的適應，它可以在現實世界的特定場景中進一步實現專業效能。我們的廣泛實驗表明，所提出的 TAMP 具有促進 NICT 的探索和應用並服務於更廣泛的醫療場景的巨大潛力。

##### **OpenMathInstruct-2: Accelerating AI for Math with Massive Open-Source Instruction Data**
2410.01560v2 by Shubham Toshniwal, Wei Du, Ivan Moshkov, Branislav Kisacanin, Alexan Ayrapetyan, Igor Gitman

Mathematical reasoning continues to be a critical challenge in large language
model (LLM) development with significant interest. However, most of the
cutting-edge progress in mathematical reasoning with LLMs has become
\emph{closed-source} due to lack of access to training data. This lack of data
access limits researchers from understanding the impact of different choices
for synthesizing and utilizing the data. With the goal of creating a
high-quality finetuning (SFT) dataset for math reasoning, we conduct careful
ablation experiments on data synthesis using the recently released
\texttt{Llama3.1} family of models. Our experiments show that: (a) solution
format matters, with excessively verbose solutions proving detrimental to SFT
performance, (b) data generated by a strong teacher outperforms equally-sized
data generated by a weak student model, (c) SFT is robust to low-quality
solutions, allowing for imprecise data filtering, and (d) question diversity is
crucial for achieving data scaling gains. Based on these insights, we create
the OpenMathInstruct-2 dataset, which consists of 14M question-solution pairs
($\approx$ 600K unique questions), making it nearly eight times larger than the
previous largest open-source math reasoning dataset. Finetuning the
\texttt{Llama-3.1-8B-Base} using OpenMathInstruct-2 outperforms
\texttt{Llama3.1-8B-Instruct} on MATH by an absolute 15.9\% (51.9\%
$\rightarrow$ 67.8\%). Finally, to accelerate the open-source efforts, we
release the code, the finetuned models, and the OpenMathInstruct-2 dataset
under a commercially permissive license.

摘要：<paragraph>數學推理在大型語言模型 (LLM) 的發展中持續成為一項關鍵挑戰，並引起極大的興趣。然而，由於缺乏訓練資料的存取，大多數 LLM 在數學推理方面的尖端進展已成為「封閉原始碼」。這種資料存取的缺乏限制了研究人員了解不同選擇對綜合和利用資料的影響。為了建立一個用於數學推理的高品質微調 (SFT) 資料集，我們使用最近發布的 \texttt{Llama3.1} 模型系列對資料合成進行了仔細的消融實驗。我們的實驗表明：(a) 解答格式很重要，過於冗長的解答會對 SFT 效能造成損害，(b) 由強老師產生的資料優於由弱學生模型產生的相同大小資料，(c) SFT 對低品質解答具有魯棒性，允許進行不精確的資料過濾，以及 (d) 問題的多樣性對於實現資料擴充增益至關重要。根據這些見解，我們建立了 OpenMathInstruct-2 資料集，其中包含 1400 萬個問題解答對（約 60 萬個獨特問題），使其規模幾乎是之前最大的開源數學推理資料集的八倍。使用 OpenMathInstruct-2 微調 \texttt{Llama-3.1-8B-Base} 在 MATH 上的表現優於 \texttt{Llama3.1-8B-Instruct}，絕對優勢 15.9%（51.9% → 67.8%）。最後，為了加速開源工作，我們在商業許可下發布了程式碼、微調模型和 OpenMathInstruct-2 資料集。</paragraph>

##### **MedQA-CS: Benchmarking Large Language Models Clinical Skills Using an AI-SCE Framework**
2410.01553v1 by Zonghai Yao, Zihao Zhang, Chaolong Tang, Xingyu Bian, Youxia Zhao, Zhichao Yang, Junda Wang, Huixue Zhou, Won Seok Jang, Feiyun Ouyang, Hong Yu

Artificial intelligence (AI) and large language models (LLMs) in healthcare
require advanced clinical skills (CS), yet current benchmarks fail to evaluate
these comprehensively. We introduce MedQA-CS, an AI-SCE framework inspired by
medical education's Objective Structured Clinical Examinations (OSCEs), to
address this gap. MedQA-CS evaluates LLMs through two instruction-following
tasks, LLM-as-medical-student and LLM-as-CS-examiner, designed to reflect real
clinical scenarios. Our contributions include developing MedQA-CS, a
comprehensive evaluation framework with publicly available data and expert
annotations, and providing the quantitative and qualitative assessment of LLMs
as reliable judges in CS evaluation. Our experiments show that MedQA-CS is a
more challenging benchmark for evaluating clinical skills than traditional
multiple-choice QA benchmarks (e.g., MedQA). Combined with existing benchmarks,
MedQA-CS enables a more comprehensive evaluation of LLMs' clinical capabilities
for both open- and closed-source LLMs.

摘要：人工智慧 (AI) 和大型語言模型 (LLM) 在醫療保健中
需要進階的臨床技能 (CS)，但目前的基準無法全面評估
這些技能。我們引入了 MedQA-CS，一個受
醫學教育的客觀結構化臨床考試 (OSCE) 啟發的 AI-SCE 架構，以
解決這個差距。MedQA-CS 透過兩個指令遵循任務來評估 LLM，LLM
扮演醫學生和 LLM 扮演 CS 考官，旨在反映真實
的臨床場景。我們的貢獻包括開發 MedQA-CS，一個
包含公開可用資料和專家註解的綜合評估架構，並提供 LLM
作為 CS 評估中可靠評分者的量化和質性評估。我們的實驗顯示，MedQA-CS 是
一個比傳統多選題 QA 基準（例如 MedQA）更具挑戰性的臨床技能評估基準。結合現有基準，
MedQA-CS 能夠更全面地評估 LLM 的臨床能力，適用於開放原始碼和閉源 LLM。

##### **On the Convergence of FedProx with Extrapolation and Inexact Prox**
2410.01410v1 by Hanmin Li, Peter Richtárik

Enhancing the FedProx federated learning algorithm (Li et al., 2020) with
server-side extrapolation, Li et al. (2024a) recently introduced the FedExProx
method. Their theoretical analysis, however, relies on the assumption that each
client computes a certain proximal operator exactly, which is impractical since
this is virtually never possible to do in real settings. In this paper, we
investigate the behavior of FedExProx without this exactness assumption in the
smooth and globally strongly convex setting. We establish a general convergence
result, showing that inexactness leads to convergence to a neighborhood of the
solution. Additionally, we demonstrate that, with careful control, the adverse
effects of this inexactness can be mitigated. By linking inexactness to biased
compression (Beznosikov et al., 2023), we refine our analysis, highlighting
robustness of extrapolation to inexact proximal updates. We also examine the
local iteration complexity required by each client to achieved the required
level of inexactness using various local optimizers. Our theoretical insights
are validated through comprehensive numerical experiments.

摘要：透過伺服器端外推增強 FedProx 聯邦學習演算法（Li 等人，2020），Li 等人（2024a）最近引入了 FedExProx 方法。然而，他們的理論分析依賴於每個客戶端都精確計算出某個近端算子的假設，這在實際環境中幾乎不可能做到，因此不切實際。在本文中，我們研究了在平滑且全局強凸設定中，沒有此精確度假設的 FedExProx 行為。我們建立了一個通用的收斂結果，表明不精確度會導致收斂到解的鄰域。此外，我們證明透過仔細控制，可以減輕這種不精確度的負面影響。透過將不精確度連結到有偏壓縮（Beznosikov 等人，2023），我們改進了分析，強調外推對不精確近端更新的穩健性。我們還研究了每個客戶端達到的不精確度所需的地方反覆運算複雜度，並使用各種地方最佳化器。我們的理論見解已透過全面的數值實驗驗證。

##### **See Me and Believe Me: Causality and Intersectionality in Testimonial Injustice in Healthcare**
2410.01227v1 by Kenya S. Andrews, Mesrob I. Ohannessian, Elena Zheleva

In medical settings, it is critical that all who are in need of care are
correctly heard and understood. When this is not the case due to prejudices a
listener has, the speaker is experiencing \emph{testimonial injustice}, which,
building upon recent work, we quantify by the presence of several categories of
unjust vocabulary in medical notes. In this paper, we use FCI, a causal
discovery method, to study the degree to which certain demographic features
could lead to marginalization (e.g., age, gender, and race) by way of
contributing to testimonial injustice. To achieve this, we review physicians'
notes for each patient, where we identify occurrences of unjust vocabulary,
along with the demographic features present, and use causal discovery to build
a Structural Causal Model (SCM) relating those demographic features to
testimonial injustice. We analyze and discuss the resulting SCMs to show the
interaction of these factors and how they influence the experience of
injustice. Despite the potential presence of some confounding variables, we
observe how one contributing feature can make a person more prone to
experiencing another contributor of testimonial injustice. There is no single
root of injustice and thus intersectionality cannot be ignored. These results
call for considering more than singular or equalized attributes of who a person
is when analyzing and improving their experiences of bias and injustice. This
work is thus a first foray at using causal discovery to understand the nuanced
experiences of patients in medical settings, and its insights could be used to
guide design principles throughout healthcare, to build trust and promote
better patient care.

摘要：在醫療場景中，所有需要照護的人都能被正確地聆聽和理解至關重要。當這因為聽者的偏見而無法發生時，說話者便會經歷「見證不正義」，而我們根據近期的研究，透過醫療紀錄中出現的不公正詞彙類別來量化見證不正義。在本文中，我們使用因果發現方法 FCI 來研究某些人口特徵可能透過促成見證不正義，進而導致邊緣化（例如年齡、性別和種族）的程度。為達成此目的，我們檢視每位病患的醫師紀錄，找出不公正詞彙出現的時機以及存在的人口特徵，並使用因果發現建立結構因果模型 (SCM)，將這些人口特徵與見證不正義關聯起來。我們分析並討論產生的 SCM，以顯示這些因素的交互作用，以及它們如何影響不正義的體驗。儘管存在一些潛在的混淆變因，我們觀察到一個促成因素如何讓一個人更容易經歷另一個見證不正義的促成因素。不正義沒有單一根源，因此無法忽視交叉性。這些結果呼籲在分析和改善人們的偏見和不正義體驗時，考量的不只是個人的單一或平等屬性。因此，這項研究是使用因果發現來了解醫療場景中病患細微體驗的首次嘗試，而其見解可用於引導整個醫療保健的設計原則，建立信任並促進更好的病患照護。

##### **Explainable Diagnosis Prediction through Neuro-Symbolic Integration**
2410.01855v1 by Qiuhao Lu, Rui Li, Elham Sagheb, Andrew Wen, Jinlian Wang, Liwei Wang, Jungwei W. Fan, Hongfang Liu

Diagnosis prediction is a critical task in healthcare, where timely and
accurate identification of medical conditions can significantly impact patient
outcomes. Traditional machine learning and deep learning models have achieved
notable success in this domain but often lack interpretability which is a
crucial requirement in clinical settings. In this study, we explore the use of
neuro-symbolic methods, specifically Logical Neural Networks (LNNs), to develop
explainable models for diagnosis prediction. Essentially, we design and
implement LNN-based models that integrate domain-specific knowledge through
logical rules with learnable thresholds. Our models, particularly
$M_{\text{multi-pathway}}$ and $M_{\text{comprehensive}}$, demonstrate superior
performance over traditional models such as Logistic Regression, SVM, and
Random Forest, achieving higher accuracy (up to 80.52\%) and AUROC scores (up
to 0.8457) in the case study of diabetes prediction. The learned weights and
thresholds within the LNN models provide direct insights into feature
contributions, enhancing interpretability without compromising predictive
power. These findings highlight the potential of neuro-symbolic approaches in
bridging the gap between accuracy and explainability in healthcare AI
applications. By offering transparent and adaptable diagnostic models, our work
contributes to the advancement of precision medicine and supports the
development of equitable healthcare solutions. Future research will focus on
extending these methods to larger and more diverse datasets to further validate
their applicability across different medical conditions and populations.

摘要：診斷預測是醫療保健中的一項關鍵任務，及時且準確地識別醫療狀況會對患者的結果產生重大影響。傳統機器學習和深度學習模型已在此領域取得顯著成功，但通常缺乏可解釋性，這是臨床環境中的關鍵要求。在本研究中，我們探討了神經符號方法，特別是邏輯神經網路 (LNN)，以開發可解釋的診斷預測模型。基本上，我們設計並實作了基於 LNN 的模型，該模型透過邏輯規則和可學習的閾值整合領域特定的知識。我們的模型，特別是 $M_{\text{multi-pathway}}$ 和 $M_{\text{comprehensive}}$，表現出優於傳統模型（如邏輯迴歸、SVM 和隨機森林）的卓越效能，在糖尿病預測的案例研究中，達到了更高的準確度（高達 80.52%）和 AUROC 分數（高達 0.8457）。LNN 模型中學習的權重和閾值提供了對特徵貢獻的直接見解，增強了可解釋性，同時不損害預測能力。這些發現突顯了神經符號方法在彌合醫療保健 AI 應用中準確性和可解釋性差距方面的潛力。透過提供透明且適應性強的診斷模型，我們的研究有助於精準醫療的進步，並支援公平醫療保健解決方案的開發。未來的研究將專注於將這些方法擴展到更大且更多樣化的資料集，以進一步驗證其在不同醫療狀況和人群中的適用性。

##### **Heterogeneous sound classification with the Broad Sound Taxonomy and Dataset**
2410.00980v1 by Panagiota Anastasopoulou, Jessica Torrey, Xavier Serra, Frederic Font

Automatic sound classification has a wide range of applications in machine
listening, enabling context-aware sound processing and understanding. This
paper explores methodologies for automatically classifying heterogeneous sounds
characterized by high intra-class variability. Our study evaluates the
classification task using the Broad Sound Taxonomy, a two-level taxonomy
comprising 28 classes designed to cover a heterogeneous range of sounds with
semantic distinctions tailored for practical user applications. We construct a
dataset through manual annotation to ensure accuracy, diverse representation
within each class and relevance in real-world scenarios. We compare a variety
of both traditional and modern machine learning approaches to establish a
baseline for the task of heterogeneous sound classification. We investigate the
role of input features, specifically examining how acoustically derived sound
representations compare to embeddings extracted with pre-trained deep neural
networks that capture both acoustic and semantic information about sounds.
Experimental results illustrate that audio embeddings encoding acoustic and
semantic information achieve higher accuracy in the classification task. After
careful analysis of classification errors, we identify some underlying reasons
for failure and propose actions to mitigate them. The paper highlights the need
for deeper exploration of all stages of classification, understanding the data
and adopting methodologies capable of effectively handling data complexity and
generalizing in real-world sound environments.

摘要：自動聲音分類在機器聆聽中具有廣泛的應用，可實現情境感知的聲音處理和理解。本文探討了自動分類異質聲音的方法，其特點是類內變異性高。我們的研究使用廣泛聲音分類法評估分類任務，廣泛聲音分類法是一種兩級分類法，包含 28 個類別，旨在涵蓋範圍廣泛的異質聲音，並針對實際使用者應用量身打造語義區別。我們通過手動註解構建一個數據集，以確保準確性、每個類別中的多樣性表示和在現實世界場景中的相關性。我們比較了各種傳統和現代機器學習方法，以建立異質聲音分類任務的基線。我們研究了輸入特徵的作用，特別考察了從聲學派生的聲音表示如何與使用預訓練深度神經網路提取的嵌入進行比較，這些網路可以擷取聲音的聲學和語義資訊。實驗結果表明，編碼聲學和語義資訊的音訊嵌入在分類任務中實現了更高的準確性。在仔細分析分類錯誤後，我們找出了一些失敗的根本原因，並提出了一些減輕這些原因的措施。本文強調需要對分類的所有階段進行更深入的探討，了解數據並採用能夠有效處理數據複雜性並在現實世界聲音環境中進行概括的方法。

##### **The Gradient of Health Data Privacy**
2410.00897v1 by Baihan Lin

In the era of digital health and artificial intelligence, the management of
patient data privacy has become increasingly complex, with significant
implications for global health equity and patient trust. This paper introduces
a novel "privacy gradient" approach to health data governance, offering a more
nuanced and adaptive framework than traditional binary privacy models. Our
multidimensional concept considers factors such as data sensitivity,
stakeholder relationships, purpose of use, and temporal aspects, allowing for
context-sensitive privacy protections. Through policy analyses, ethical
considerations, and case studies spanning adolescent health, integrated care,
and genomic research, we demonstrate how this approach can address critical
privacy challenges in diverse healthcare settings worldwide. The privacy
gradient model has the potential to enhance patient engagement, improve care
coordination, and accelerate medical research while safeguarding individual
privacy rights. We provide policy recommendations for implementing this
approach, considering its impact on healthcare systems, research
infrastructures, and global health initiatives. This work aims to inform
policymakers, healthcare leaders, and digital health innovators, contributing
to a more equitable, trustworthy, and effective global health data ecosystem in
the digital age.

摘要：在數位健康與人工智慧的時代，病患資料隱私的管理變得越來越複雜，對全球的健康公平與病患信任有重大的影響。本文介紹了一個新的「隱私梯度」方法來管理健康資料，提供比傳統二元隱私模型更細緻且更具適應性的架構。我們的多面向概念考量了資料敏感度、利害關係人的關係、使用目的和時間面向等因素，允許針對脈絡敏感的隱私保護。透過政策分析、倫理考量，以及涵蓋青少年健康、整合照護和基因組研究的案例研究，我們展示了此方法如何解決全球不同醫療保健環境中的關鍵隱私挑戰。隱私梯度模型有潛力提升病患參與、改善照護協調，以及加速醫學研究，同時保障個體的隱私權。我們提供實施此方法的政策建議，考量其對醫療保健系統、研究基礎設施和全球健康計畫的影響。這項工作旨在提供資訊給政策制定者、醫療保健領導者和數位健康創新者，在數位時代中促成更公平、更值得信賴且更有效的全球健康資料生態系統。

##### **GAMMA-PD: Graph-based Analysis of Multi-Modal Motor Impairment Assessments in Parkinson's Disease**
2410.00944v1 by Favour Nerrise, Alice Louise Heiman, Ehsan Adeli

The rapid advancement of medical technology has led to an exponential
increase in multi-modal medical data, including imaging, genomics, and
electronic health records (EHRs). Graph neural networks (GNNs) have been widely
used to represent this data due to their prominent performance in capturing
pairwise relationships. However, the heterogeneity and complexity of
multi-modal medical data still pose significant challenges for standard GNNs,
which struggle with learning higher-order, non-pairwise relationships. This
paper proposes GAMMA-PD (Graph-based Analysis of Multi-modal Motor Impairment
Assessments in Parkinson's Disease), a novel heterogeneous hypergraph fusion
framework for multi-modal clinical data analysis. GAMMA-PD integrates imaging
and non-imaging data into a "hypernetwork" (patient population graph) by
preserving higher-order information and similarity between patient profiles and
symptom subtypes. We also design a feature-based attention-weighted mechanism
to interpret feature-level contributions towards downstream decision tasks. We
evaluate our approach with clinical data from the Parkinson's Progression
Markers Initiative (PPMI) and a private dataset. We demonstrate gains in
predicting motor impairment symptoms in Parkinson's disease. Our end-to-end
framework also learns associations between subsets of patient characteristics
to generate clinically relevant explanations for disease and symptom profiles.
The source code is available at https://github.com/favour-nerrise/GAMMA-PD.

摘要：醫療技術的快速進步導致多模式醫療資料呈指數成長，包括影像、基因組學和電子健康紀錄 (EHR)。圖形神經網路 (GNN) 因其在捕捉成對關係上的出色表現而被廣泛用於表示這些資料。然而，多模式醫療資料的異質性和複雜性對標準 GNN 來說仍然構成重大挑戰，而 GNN 難以學習高階、非成對關係。本文提出 GAMMA-PD（基於圖形分析帕金森氏症多模式運動障礙評估），一個用於多模式臨床資料分析的新型異質超圖融合架構。GAMMA-PD 透過保留高階資訊和患者特徵與症狀子類型之間的相似性，將影像和非影像資料整合到「超網路」（患者族群圖）中。我們還設計了一個基於特徵的注意力加權機制，以解釋特徵層級的貢獻對下游決策任務的影響。我們使用帕金森氏症進展標記計畫 (PPMI) 的臨床資料和一個私人資料集來評估我們的做法。我們展示了在預測帕金森氏症運動障礙症狀方面的進展。我們的端對端架構也學習患者特徵子集之間的關聯，以產生對疾病和症狀特徵具有臨床意義的解釋。原始碼可在 https://github.com/favour-nerrise/GAMMA-PD 取得。

##### **Contrastive Abstraction for Reinforcement Learning**
2410.00704v1 by Vihang Patil, Markus Hofmarcher, Elisabeth Rumetshofer, Sepp Hochreiter

Learning agents with reinforcement learning is difficult when dealing with
long trajectories that involve a large number of states. To address these
learning problems effectively, the number of states can be reduced by abstract
representations that cluster states. In principle, deep reinforcement learning
can find abstract states, but end-to-end learning is unstable. We propose
contrastive abstraction learning to find abstract states, where we assume that
successive states in a trajectory belong to the same abstract state. Such
abstract states may be basic locations, achieved subgoals, inventory, or health
conditions. Contrastive abstraction learning first constructs clusters of state
representations by contrastive learning and then applies modern Hopfield
networks to determine the abstract states. The first phase of contrastive
abstraction learning is self-supervised learning, where contrastive learning
forces states with sequential proximity to have similar representations. The
second phase uses modern Hopfield networks to map similar state representations
to the same fixed point, i.e.\ to an abstract state. The level of abstraction
can be adjusted by determining the number of fixed points of the modern
Hopfield network. Furthermore, \textit{contrastive abstraction learning} does
not require rewards and facilitates efficient reinforcement learning for a wide
range of downstream tasks. Our experiments demonstrate the effectiveness of
contrastive abstraction learning for reinforcement learning.

摘要：使用強化學習的學習代理在處理包含大量狀態的長軌跡時很困難。為了有效解決這些學習問題，可以透過將狀態分群的抽象表示來減少狀態數量。原則上，深度強化學習可以找到抽象狀態，但端到端學習是不穩定的。我們提出對比抽象學習來尋找抽象狀態，我們假設軌跡中的連續狀態屬於同一個抽象狀態。這樣的抽象狀態可能是基本位置、已達成的子目標、庫存或健康狀況。對比抽象學習首先透過對比學習建構狀態表示的群集，然後應用現代 Hopfield 網路來確定抽象狀態。對比抽象學習的第一階段是自我監督學習，其中對比學習會強制具有順序接近性的狀態具有相似的表示。第二階段使用現代 Hopfield 網路將相似的狀態表示對應到同一個定點，即抽象狀態。抽象層級可以透過確定現代 Hopfield 網路的定點數量來調整。此外，對比抽象學習不需要獎勵，並促進各種下游任務的有效強化學習。我們的實驗證明了對比抽象學習對於強化學習的有效性。

##### **Arges: Spatio-Temporal Transformer for Ulcerative Colitis Severity Assessment in Endoscopy Videos**
2410.00536v1 by Krishna Chaitanya, Pablo F. Damasceno, Shreyas Fadnavis, Pooya Mobadersany, Chaitanya Parmar, Emily Scherer, Natalia Zemlianskaia, Lindsey Surace, Louis R. Ghanem, Oana Gabriela Cula, Tommaso Mansi, Kristopher Standish

Accurate assessment of disease severity from endoscopy videos in ulcerative
colitis (UC) is crucial for evaluating drug efficacy in clinical trials.
Severity is often measured by the Mayo Endoscopic Subscore (MES) and Ulcerative
Colitis Endoscopic Index of Severity (UCEIS) score. However, expert MES/UCEIS
annotation is time-consuming and susceptible to inter-rater variability,
factors addressable by automation. Automation attempts with frame-level labels
face challenges in fully-supervised solutions due to the prevalence of
video-level labels in clinical trials. CNN-based weakly-supervised models (WSL)
with end-to-end (e2e) training lack generalization to new disease scores and
ignore spatio-temporal information crucial for accurate scoring. To address
these limitations, we propose "Arges", a deep learning framework that utilizes
a transformer with positional encoding to incorporate spatio-temporal
information from frame features to estimate disease severity scores in
endoscopy video. Extracted features are derived from a foundation model
(ArgesFM), pre-trained on a large diverse dataset from multiple clinical trials
(61M frames, 3927 videos). We evaluate four UC disease severity scores,
including MES and three UCEIS component scores. Test set evaluation indicates
significant improvements, with F1 scores increasing by 4.1% for MES and 18.8%,
6.6%, 3.8% for the three UCEIS component scores compared to state-of-the-art
methods. Prospective validation on previously unseen clinical trial data
further demonstrates the model's successful generalization.

摘要：<paragraph>在潰瘍性結腸炎 (UC) 中，準確評估內視鏡視頻中的疾病嚴重程度對於評估臨床試驗中的藥物療效至關重要。嚴重程度通常通過 Mayo 內視鏡亞分數 (MES) 和潰瘍性結腸炎內視鏡嚴重程度指數 (UCEIS) 分數來衡量。然而，專家 MES/UCEIS 注釋既費時又容易受到評分者間變異性的影響，而自動化可以解決這些因素。由於臨床試驗中視頻級別標籤的普遍存在，使用幀級標籤的自動化嘗試在完全監督的解決方案中面臨挑戰。具有端到端 (e2e) 訓練的基於 CNN 的弱監督模型 (WSL) 缺乏對新疾病評分的泛化，並且忽視了對準確評分至關重要的時空信息。為了解決這些限制，我們提出了「Arges」，這是一個深度學習框架，它利用具有位置編碼的Transformer將時空信息從幀特徵中提取出來，以估計內視鏡視頻中的疾病嚴重程度評分。提取的特徵來自基礎模型 (ArgesFM)，該模型在來自多個臨床試驗的大型多樣化數據集（6100 萬幀，3927 個視頻）上進行了預訓練。我們評估了四個 UC 疾病嚴重程度評分，包括 MES 和三個 UCEIS 組成部分評分。測試集評估表明有顯著改善，與最先進的方法相比，MES 的 F1 分數提高了 4.1%，三個 UCEIS 組成部分評分的 F1 分數分別提高了 18.8%、6.6% 和 3.8%。在以前未見的臨床試驗數據上的前瞻性驗證進一步證明了該模型成功的泛化。</paragraph>

##### **Bayes-CATSI: A variational Bayesian deep learning framework for medical time series data imputation**
2410.01847v2 by Omkar Kulkarni, Rohitash Chandra

Medical time series datasets feature missing values that need data imputation
methods, however, conventional machine learning models fall short due to a lack
of uncertainty quantification in predictions. Among these models, the CATSI
(Context-Aware Time Series Imputation) stands out for its effectiveness by
incorporating a context vector into the imputation process, capturing the
global dependencies of each patient. In this paper, we propose a Bayesian
Context-Aware Time Series Imputation (Bayes-CATSI) framework which leverages
uncertainty quantification offered by variational inference. We consider the
time series derived from electroencephalography (EEG), electrooculography
(EOG), electromyography (EMG), electrocardiology (EKG). Variational Inference
assumes the shape of the posterior distribution and through minimization of the
Kullback-Leibler(KL) divergence it finds variational densities that are closest
to the true posterior distribution. Thus , we integrate the variational
Bayesian deep learning layers into the CATSI model. Our results show that
Bayes-CATSI not only provides uncertainty quantification but also achieves
superior imputation performance compared to the CATSI model. Specifically, an
instance of Bayes-CATSI outperforms CATSI by 9.57 %. We provide an open-source
code implementation for applying Bayes-CATSI to other medical data imputation
problems.

摘要：醫療時間序列資料集特徵有遺失值，需要資料估計方法，然而，傳統的機器學習模型由於缺乏預測中的不確定量化而不足。在這些模型中，CATSI（情境感知時間序列估計）因其將情境向量納入估計過程中而脫穎而出，捕捉每個病人的整體依賴性。在本文中，我們提出一個貝氏情境感知時間序列估計（Bayes-CATSI）架構，它利用變異推論提供的未確定量化。我們考慮來自腦電圖（EEG）、眼動圖（EOG）、肌電圖（EMG）、心電圖（EKG）的時間序列。變異推論假設後驗分配的形狀，並通過最小化 Kullback-Leibler（KL）散度，它找出最接近真實後驗分配的變異密度。因此，我們將變異貝氏深度學習層整合到 CATSI 模型中。我們的結果表明，Bayes-CATSI 不僅提供不確定性量化，而且與 CATSI 模型相比，還實現了卓越的估計性能。具體來說，Bayes-CATSI 的一個實例比 CATSI 高出 9.57%。我們提供一個開源程式碼實作，將 Bayes-CATSI 應用於其他醫療資料估計問題。

##### **ReXplain: Translating Radiology into Patient-Friendly Video Reports**
2410.00441v1 by Luyang Luo, Jenanan Vairavamurthy, Xiaoman Zhang, Abhinav Kumar, Ramon R. Ter-Oganesyan, Stuart T. Schroff, Dan Shilo, Rydhwana Hossain, Mike Moritz, Pranav Rajpurkar

Radiology reports often remain incomprehensible to patients, undermining
patient-centered care. We present ReXplain (Radiology eXplanation), an
innovative AI-driven system that generates patient-friendly video reports for
radiology findings. ReXplain uniquely integrates a large language model for
text simplification, an image segmentation model for anatomical region
identification, and an avatar generation tool, producing comprehensive
explanations with plain language, highlighted imagery, and 3D organ renderings.
Our proof-of-concept study with five board-certified radiologists indicates
that ReXplain could accurately deliver radiological information and effectively
simulate one-on-one consultations. This work demonstrates a new paradigm in
AI-assisted medical communication, potentially improving patient engagement and
satisfaction in radiology care, and opens new avenues for research in
multimodal medical communication.

摘要：放射科報告通常令患者難以理解，破壞了以患者為中心的照護。我們提出 ReXplain（放射科解釋），一個創新的 AI 驅動系統，它會為放射科檢查結果產生對患者友善的影片報告。ReXplain 獨特地整合了一個用於文字簡化的語言模型、一個用於解剖區域識別的影像分割模型，以及一個頭像產生工具，產生了包含淺顯易懂的語言、重點影像和 3D 器官渲染的全面解釋。我們與五位通過認證的放射科醫師進行的驗證概念研究指出，ReXplain 能夠準確地傳達放射科資訊，並有效地模擬一對一的諮詢。這項工作展示了 AI 輔助醫療溝通的新典範，它有潛力改善患者參與度和放射科照護的滿意度，並為多模式醫療溝通的研究開啟了新途徑。

##### **Towards Democratization of Subspeciality Medical Expertise**
2410.03741v1 by Jack W. O'Sullivan, Anil Palepu, Khaled Saab, Wei-Hung Weng, Yong Cheng, Emily Chu, Yaanik Desai, Aly Elezaby, Daniel Seung Kim, Roy Lan, Wilson Tang, Natalie Tapaskar, Victoria Parikh, Sneha S. Jain, Kavita Kulkarni, Philip Mansfield, Dale Webster, Juraj Gottweis, Joelle Barral, Mike Schaekermann, Ryutaro Tanno, S. Sara Mahdavi, Vivek Natarajan, Alan Karthikesalingam, Euan Ashley, Tao Tu

The scarcity of subspecialist medical expertise, particularly in rare,
complex and life-threatening diseases, poses a significant challenge for
healthcare delivery. This issue is particularly acute in cardiology where
timely, accurate management determines outcomes. We explored the potential of
AMIE (Articulate Medical Intelligence Explorer), a large language model
(LLM)-based experimental AI system optimized for diagnostic dialogue, to
potentially augment and support clinical decision-making in this challenging
context. We curated a real-world dataset of 204 complex cases from a
subspecialist cardiology practice, including results for electrocardiograms,
echocardiograms, cardiac MRI, genetic tests, and cardiopulmonary stress tests.
We developed a ten-domain evaluation rubric used by subspecialists to evaluate
the quality of diagnosis and clinical management plans produced by general
cardiologists or AMIE, the latter enhanced with web-search and self-critique
capabilities. AMIE was rated superior to general cardiologists for 5 of the 10
domains (with preference ranging from 9% to 20%), and equivalent for the rest.
Access to AMIE's response improved cardiologists' overall response quality in
63.7% of cases while lowering quality in just 3.4%. Cardiologists' responses
with access to AMIE were superior to cardiologist responses without access to
AMIE for all 10 domains. Qualitative examinations suggest AMIE and general
cardiologist could complement each other, with AMIE thorough and sensitive,
while general cardiologist concise and specific. Overall, our results suggest
that specialized medical LLMs have the potential to augment general
cardiologists' capabilities by bridging gaps in subspecialty expertise, though
further research and validation are essential for wide clinical utility.

摘要：<paragraph>在罕见、复杂且危及生命的疾病中，特别是缺乏次专科医学专业知识，这对医疗保健的提供构成了重大挑战。此问题在心脏病学中尤为严重，因为及时的准确管理决定了结果。我们探索了 AMIE（Articulate Medical Intelligence Explorer）的潜力，它是一种基于大语言模型 (LLM) 的实验性人工智能系统，针对诊断对话进行了优化，可以增强和支持在这种具有挑战性的情况下进行临床决策。我们从次专科心脏病实践中整理了一个包含 204 个复杂病例的真实世界数据集，包括心电图、超声心动图、心脏核磁共振、基因检测和心肺压力测试的结果。我们制定了一个由次专科医生使用的十个领域评估标准，用于评估普通心脏病专家或 AMIE 产生的诊断和临床管理计划的质量，后者通过网络搜索和自我批评能力得到了增强。在 10 个领域中，AMIE 被评为优于普通心脏病专家（偏好范围为 9% 至 20%），其余领域则相当。在 63.7% 的病例中，获得 AMIE 的回应改善了心脏病专家的整体回应质量，而在 3.4% 的病例中降低了质量。获得 AMIE 的心脏病专家的回应优于没有获得 AMIE 的心脏病专家的回应，适用于所有 10 个领域。定性检查表明，AMIE 和普通心脏病专家可以互为补充，AMIE 全面而敏感，而普通心脏病专家则简洁而具体。总体而言，我们的研究结果表明，专业的医学 LLM 有可能通过弥合次专科专业知识的差距来增强普通心脏病专家的能力，尽管进一步的研究和验证对于广泛的临床应用至关重要。</paragraph>

##### **CXPMRG-Bench: Pre-training and Benchmarking for X-ray Medical Report Generation on CheXpert Plus Dataset**
2410.00379v1 by Xiao Wang, Fuling Wang, Yuehang Li, Qingchuan Ma, Shiao Wang, Bo Jiang, Chuanfu Li, Jin Tang

X-ray image-based medical report generation (MRG) is a pivotal area in
artificial intelligence which can significantly reduce diagnostic burdens and
patient wait times. Despite significant progress, we believe that the task has
reached a bottleneck due to the limited benchmark datasets and the existing
large models' insufficient capability enhancements in this specialized domain.
Specifically, the recently released CheXpert Plus dataset lacks comparative
evaluation algorithms and their results, providing only the dataset itself.
This situation makes the training, evaluation, and comparison of subsequent
algorithms challenging. Thus, we conduct a comprehensive benchmarking of
existing mainstream X-ray report generation models and large language models
(LLMs), on the CheXpert Plus dataset. We believe that the proposed benchmark
can provide a solid comparative basis for subsequent algorithms and serve as a
guide for researchers to quickly grasp the state-of-the-art models in this
field. More importantly, we propose a large model for the X-ray image report
generation using a multi-stage pre-training strategy, including self-supervised
autoregressive generation and Xray-report contrastive learning, and supervised
fine-tuning. Extensive experimental results indicate that the autoregressive
pre-training based on Mamba effectively encodes X-ray images, and the
image-text contrastive pre-training further aligns the feature spaces,
achieving better experimental results. Source code can be found on
\url{https://github.com/Event-AHU/Medical_Image_Analysis}.

摘要：基於 X 光影像的醫療報告生成 (MRG) 是人工智慧中的一個關鍵領域，它可以大幅減少診斷負擔和病患的等待時間。儘管有顯著的進展，我們認為這項任務已經達到瓶頸，原因是基準資料集有限，而且現有的大型模型在這項專業領域中能力增強不足。具體而言，最近發布的 CheXpert Plus 資料集缺乏比較評估演算法及其結果，只提供資料集本身。這種情況使得後續演算法的訓練、評估和比較具有挑戰性。因此，我們對現有的主流 X 光報告生成模型和大型語言模型 (LLM) 進行了全面的基準測試，資料集為 CheXpert Plus。我們相信，所提出的基準測試可以為後續演算法提供穩固的比較基礎，並作為研究人員快速掌握此領域最先進模型的指南。更重要的是，我們提出一個使用多階段預訓練策略的大型模型，用於 X 光影像報告生成，包括自監督自迴歸生成和 X 光報告對比學習，以及監督微調。廣泛的實驗結果表明，基於 Mamba 的自迴歸預訓練有效地編碼了 X 光影像，而影像文字對比預訓練進一步對齊了特徵空間，達到了更好的實驗結果。原始碼可以在 \url{https://github.com/Event-AHU/Medical_Image_Analysis} 找到。

##### **Easydiagnos: a framework for accurate feature selection for automatic diagnosis in smart healthcare**
2410.00366v1 by Prasenjit Maji, Amit Kumar Mondal, Hemanta Kumar Mondal, Saraju P. Mohanty

The rapid advancements in artificial intelligence (AI) have revolutionized
smart healthcare, driving innovations in wearable technologies, continuous
monitoring devices, and intelligent diagnostic systems. However, security,
explainability, robustness, and performance optimization challenges remain
critical barriers to widespread adoption in clinical environments. This
research presents an innovative algorithmic method using the Adaptive Feature
Evaluator (AFE) algorithm to improve feature selection in healthcare datasets
and overcome problems. AFE integrating Genetic Algorithms (GA), Explainable
Artificial Intelligence (XAI), and Permutation Combination Techniques (PCT),
the algorithm optimizes Clinical Decision Support Systems (CDSS), thereby
enhancing predictive accuracy and interpretability. The proposed method is
validated across three diverse healthcare datasets using six distinct machine
learning algorithms, demonstrating its robustness and superiority over
conventional feature selection techniques. The results underscore the
transformative potential of AFE in smart healthcare, enabling personalized and
transparent patient care. Notably, the AFE algorithm, when combined with a
Multi-layer Perceptron (MLP), achieved an accuracy of up to 98.5%, highlighting
its capability to improve clinical decision-making processes in real-world
healthcare applications.

摘要：人工智慧 (AI) 的快速進展徹底改變了智慧醫療保健，推動了可穿戴技術、持續監控裝置和智慧診斷系統的創新。然而，安全性、可解釋性、穩健性和效能最佳化挑戰仍然是臨床環境中廣泛採用的關鍵障礙。本研究提出一個創新的演算法方法，使用自適應特徵評估器 (AFE) 演算法來改善醫療保健資料集中的特徵選取並克服問題。AFE 整合了遺傳演算法 (GA)、可解釋人工智慧 (XAI) 和排列組合技術 (PCT)，該演算法最佳化了臨床決策支援系統 (CDSS)，從而提高了預測準確性和可解釋性。所提出的方法使用六種不同的機器學習演算法驗證了三個不同的醫療保健資料集，證明了其穩健性和優於傳統特徵選取技術。結果強調了 AFE 在智慧醫療保健中的轉變潛力，實現了個人化和透明的患者照護。值得注意的是，AFE 演算法與多層感知器 (MLP) 結合使用時，準確度高達 98.5%，突顯了其改善實際醫療保健應用中臨床決策制定流程的能力。

##### **The age of spiritual machines: Language quietus induces synthetic altered states of consciousness in artificial intelligence**
2410.00257v1 by Jeremy I Skipper, Joanna Kuc, Greg Cooper, Christopher Timmermann

How is language related to consciousness? Language functions to categorise
perceptual experiences (e.g., labelling interoceptive states as 'happy') and
higher-level constructs (e.g., using 'I' to represent the narrative self).
Psychedelic use and meditation might be described as altered states that impair
or intentionally modify the capacity for linguistic categorisation. For
example, psychedelic phenomenology is often characterised by 'oceanic
boundlessness' or 'unity' and 'ego dissolution', which might be expected of a
system unburdened by entrenched language categories. If language breakdown
plays a role in producing such altered behaviour, multimodal artificial
intelligence might align more with these phenomenological descriptions when
attention is shifted away from language. We tested this hypothesis by comparing
the semantic embedding spaces from simulated altered states after manipulating
attentional weights in CLIP and FLAVA models to embedding spaces from altered
states questionnaires before manipulation. Compared to random text and various
other altered states including anxiety, models were more aligned with
disembodied, ego-less, spiritual, and unitive states, as well as minimal
phenomenal experiences, with decreased attention to language and vision.
Reduced attention to language was associated with distinct linguistic patterns
and blurred embeddings within and, especially, across semantic categories
(e.g., 'giraffes' become more like 'bananas'). These results lend support to
the role of language categorisation in the phenomenology of altered states of
consciousness, like those experienced with high doses of psychedelics or
concentration meditation, states that often lead to improved mental health and
wellbeing.

摘要：語言如何與意識相關？語言功能用於分類感知經驗（例如，將內感受狀態標記為「快樂」）和更高層次的建構（例如，使用「我」來代表敘事自我）。迷幻藥的使用和冥想可以被描述為改變狀態，會損害或故意修改語言分類的能力。例如，迷幻現象學通常以「海洋般的無界」或「統一」和「自我解體」為特徵，這可能是沒有根深蒂固的語言類別的系統所預期的。如果語言崩潰在產生這種改變的行為中發揮作用，那麼當注意力從語言轉移時，多模態人工智能可能更符合這些現象學描述。我們通過比較在 CLIP 和 FLAVA 模型中操縱注意力權重後模擬的改變狀態的語義嵌入空間與操縱前的改變狀態問卷的嵌入空間來測試這個假設。與隨機文本和包括焦慮在內的各種其他改變狀態相比，這些模型更符合無肉身、無自我、精神和統一狀態，以及最小的現象體驗，並且對語言和視覺的注意力降低。對語言的注意力降低與不同的語言模式和模糊的嵌入相關，特別是在語義類別中（例如，「長頸鹿」變得更像「香蕉」）。這些結果支持了語言分類在改變意識狀態的現象學中的作用，例如服用高劑量迷幻藥或專注冥想所經歷的狀態，這些狀態通常會導致心理健康和幸福感的改善。

##### **CliMB: An AI-enabled Partner for Clinical Predictive Modeling**
2410.03736v1 by Evgeny Saveliev, Tim Schubert, Thomas Pouplin, Vasilis Kosmoliaptsis, Mihaela van der Schaar

Despite its significant promise and continuous technical advances, real-world
applications of artificial intelligence (AI) remain limited. We attribute this
to the "domain expert-AI-conundrum": while domain experts, such as clinician
scientists, should be able to build predictive models such as risk scores, they
face substantial barriers in accessing state-of-the-art (SOTA) tools. While
automated machine learning (AutoML) has been proposed as a partner in clinical
predictive modeling, many additional requirements need to be fulfilled to make
machine learning accessible for clinician scientists.
  To address this gap, we introduce CliMB, a no-code AI-enabled partner
designed to empower clinician scientists to create predictive models using
natural language. CliMB guides clinician scientists through the entire medical
data science pipeline, thus empowering them to create predictive models from
real-world data in just one conversation. CliMB also creates structured reports
and interpretable visuals. In evaluations involving clinician scientists and
systematic comparisons against a baseline GPT-4, CliMB consistently
demonstrated superior performance in key areas such as planning, error
prevention, code execution, and model performance. Moreover, in blinded
assessments involving 45 clinicians from diverse specialties and career stages,
more than 80% preferred CliMB over GPT-4. Overall, by providing a no-code
interface with clear guidance and access to SOTA methods in the fields of
data-centric AI, AutoML, and interpretable ML, CliMB empowers clinician
scientists to build robust predictive models.

摘要：儘管人工智能 (AI) 承諾重大且技術持續進步，但實際世界中的人工智慧應用仍有限。我們將此歸因於「領域專家-AI-難題」：儘管領域專家（例如臨床科學家）應能建立預測模型（例如風險評分），但他們在取得最先進 (SOTA) 工具時面臨重大障礙。儘管已提出自動機器學習 (AutoML) 作為臨床預測模型的合作夥伴，但仍需要滿足許多額外需求，才能讓臨床科學家使用機器學習。
為了解決此差距，我們引入了 CliMB，這是一個免編碼、AI 驅動的合作夥伴，旨在讓臨床科學家能夠使用自然語言建立預測模型。CliMB 引導臨床科學家完成整個醫學數據科學流程，從而讓他們能夠在一次對話中從真實世界資料建立預測模型。CliMB 也會建立結構化報告和可解釋的視覺化。在涉及臨床科學家和系統性比較基準 GPT-4 的評估中，CliMB 在規劃、錯誤預防、程式碼執行和模型效能等關鍵領域持續展現出卓越的效能。此外，在涉及來自不同專科和職業階段的 45 位臨床醫生的盲測評估中，超過 80% 的人偏好 CliMB 勝過 GPT-4。整體而言，透過提供免編碼介面、明確指南，並取得資料為中心 AI、AutoML 和可解釋 ML 領域的 SOTA 方法，CliMB 能讓臨床科學家建立穩健的預測模型。

##### **Adapting LLMs for the Medical Domain in Portuguese: A Study on Fine-Tuning and Model Evaluation**
2410.00163v1 by Pedro Henrique Paiola, Gabriel Lino Garcia, João Renato Ribeiro Manesco, Mateus Roder, Douglas Rodrigues, João Paulo Papa

This study evaluates the performance of large language models (LLMs) as
medical agents in Portuguese, aiming to develop a reliable and relevant virtual
assistant for healthcare professionals. The HealthCareMagic-100k-en and MedQuAD
datasets, translated from English using GPT-3.5, were used to fine-tune the
ChatBode-7B model using the PEFT-QLoRA method. The InternLM2 model, with
initial training on medical data, presented the best overall performance, with
high precision and adequacy in metrics such as accuracy, completeness and
safety. However, DrBode models, derived from ChatBode, exhibited a phenomenon
of catastrophic forgetting of acquired medical knowledge. Despite this, these
models performed frequently or even better in aspects such as grammaticality
and coherence. A significant challenge was low inter-rater agreement,
highlighting the need for more robust assessment protocols. This work paves the
way for future research, such as evaluating multilingual models specific to the
medical field, improving the quality of training data, and developing more
consistent evaluation methodologies for the medical field.

摘要：本研究評估大型語言模型 (LLM) 在葡萄牙語中作為醫療代理的表現，旨在為醫療專業人員開發一個可靠且相關的虛擬助理。HealthCareMagic-100k-en 和 MedQuAD 資料集，使用 GPT-3.5 從英語翻譯，用於使用 PEFT-QLoRA 方法微調 ChatBode-7B 模型。InternLM2 模型，在醫療資料上進行初始訓練，表現出最好的整體表現，在準確性、完整性和安全性等指標上具有很高的精度和充分性。然而，源自 ChatBode 的 DrBode 模型表現出對獲得的醫療知識災難性遺忘的現象。儘管如此，這些模型在語法性和連貫性等方面表現得很好甚至更好。一個重大的挑戰是評分者之間的協議低，這凸顯了對更強大的評估協議的需求。這項工作為未來的研究鋪平了道路，例如評估特定於醫療領域的多語言模型、提高訓練資料的品質，以及為醫療領域開發更一致的評估方法。

##### **The Perfect Blend: Redefining RLHF with Mixture of Judges**
2409.20370v1 by Tengyu Xu, Eryk Helenowski, Karthik Abinav Sankararaman, Di Jin, Kaiyan Peng, Eric Han, Shaoliang Nie, Chen Zhu, Hejia Zhang, Wenxuan Zhou, Zhouhao Zeng, Yun He, Karishma Mandyam, Arya Talabzadeh, Madian Khabsa, Gabriel Cohen, Yuandong Tian, Hao Ma, Sinong Wang, Han Fang

Reinforcement learning from human feedback (RLHF) has become the leading
approach for fine-tuning large language models (LLM). However, RLHF has
limitations in multi-task learning (MTL) due to challenges of reward hacking
and extreme multi-objective optimization (i.e., trade-off of multiple and/or
sometimes conflicting objectives). Applying RLHF for MTL currently requires
careful tuning of the weights for reward model and data combinations. This is
often done via human intuition and does not generalize. In this work, we
introduce a novel post-training paradigm which we called Constrained Generative
Policy Optimization (CGPO). The core of CGPO is Mixture of Judges (MoJ) with
cost-efficient constrained policy optimization with stratification, which can
identify the perfect blend in RLHF in a principled manner. It shows strong
empirical results with theoretical guarantees, does not require extensive
hyper-parameter tuning, and is plug-and-play in common post-training pipelines.
Together, this can detect and mitigate reward hacking behaviors while reaching
a pareto-optimal point across an extremely large number of objectives.
  Our empirical evaluations demonstrate that CGPO significantly outperforms
standard RLHF algorithms like PPO and DPO across various tasks including
general chat, STEM questions, instruction following, and coding. Specifically,
CGPO shows improvements of 7.4% in AlpacaEval-2 (general chat), 12.5% in
Arena-Hard (STEM & reasoning), and consistent gains in other domains like math
and coding. Notably, PPO, while commonly used, is prone to severe reward
hacking in popular coding benchmarks, which CGPO successfully addresses. This
breakthrough in RLHF not only tackles reward hacking and extreme
multi-objective optimization challenges but also advances the state-of-the-art
in aligning general-purpose LLMs for diverse applications.

摘要：人類回饋強化學習 (RLHF) 已成為微調大型語言模型 (LLM) 的領先方法。然而，RLHF 在多任務學習 (MTL) 中受到獎勵破解和極端多目標最佳化（例如，多重和/或有時相互衝突的目標之間的取捨）的挑戰而有所限制。目前，將 RLHF 應用於 MTL 需要仔細調整獎勵模型和資料組合的權重。這通常是透過人類直覺來完成，而且無法概括。在這項工作中，我們引入了一種新穎的訓練後範例，我們稱之為受約束生成策略最佳化 (CGPO)。CGPO 的核心是法官混合 (MoJ)，透過分層進行具有成本效益的受約束策略最佳化，它可以以原則性的方式找出 RLHF 中的完美融合。它在理論保證下展現強大的實證結果，不需要廣泛的超參數調整，並且可以即插即用於常見的訓練後管道。總之，它可以在極大量的目標中偵測和減輕獎勵破解行為，同時達到帕雷托最優點。我們的實證評估證明，CGPO 在各種任務中顯著優於標準 RLHF 演算法，例如一般聊天、STEM 問題、指令遵循和編碼。具體來說，CGPO 在 AlpacaEval-2（一般聊天）中提升了 7.4%，在 Arena-Hard（STEM 和推理）中提升了 12.5%，並且在數學和編碼等其他領域中持續獲得收益。值得注意的是，PPO 雖然普遍使用，但在流行的編碼基準中容易受到嚴重的獎勵破解，而 CGPO 成功地解決了這個問題。RLHF 的這項突破不僅解決了獎勵破解和極端多目標最佳化的挑戰，而且還推動了將通用 LLM 與各種應用程式相結合的最新技術。

##### **Forecasting Disease Progression with Parallel Hyperplanes in Longitudinal Retinal OCT**
2409.20195v2 by Arunava Chakravarty, Taha Emre, Dmitrii Lachinov, Antoine Rivail, Hendrik Scholl, Lars Fritsche, Sobha Sivaprasad, Daniel Rueckert, Andrew Lotery, Ursula Schmidt-Erfurth, Hrvoje Bogunović

Predicting future disease progression risk from medical images is challenging
due to patient heterogeneity, and subtle or unknown imaging biomarkers.
Moreover, deep learning (DL) methods for survival analysis are susceptible to
image domain shifts across scanners. We tackle these issues in the task of
predicting late dry Age-related Macular Degeneration (dAMD) onset from retinal
OCT scans. We propose a novel DL method for survival prediction to jointly
predict from the current scan a risk score, inversely related to
time-to-conversion, and the probability of conversion within a time interval
$t$. It uses a family of parallel hyperplanes generated by parameterizing the
bias term as a function of $t$. In addition, we develop unsupervised losses
based on intra-subject image pairs to ensure that risk scores increase over
time and that future conversion predictions are consistent with AMD stage
prediction using actual scans of future visits. Such losses enable
data-efficient fine-tuning of the trained model on new unlabeled datasets
acquired with a different scanner. Extensive evaluation on two large datasets
acquired with different scanners resulted in a mean AUROCs of 0.82 for
Dataset-1 and 0.83 for Dataset-2, across prediction intervals of 6,12 and 24
months.

摘要：预测未来疾病进展风险从医学影像中具有挑战性
由于病人异质性，和细微或未知的影像生物标记。
此外，深度学习（DL）方法用于存活分析容易受到
跨扫描仪的影像领域转移。我们在预测晚期干性年龄相关性黄斑部病变（dAMD）发作的任务中解决这些问题，从视网膜
OCT 扫描。我们提出一种新的 DL 方法用于存活预测，从当前扫描中联合
预测一个风险评分，与转换时间成反比，以及在时间间隔内转换的可能性
$t$。它使用一组平行的超平面，通过将偏差项参数化为 $t$ 的函数来生成。此外，我们开发无监督损失
基于受试者内影像对，以确保风险评分随着
时间增加，并且未来的转换预测与 AMD 阶段
预测使用未来访问的实际扫描是一致的。此类损失允许
在使用不同扫描仪获取的新未标记数据集上对训练模型进行数据高效微调。对两个大型数据集的广泛评估
使用不同的扫描仪获得的，平均 AUROC 为 0.82，对于数据集 1 和 0.83，对于数据集 2，跨预测间隔 6,12 和 24
个月。

##### **Classification of Radiological Text in Small and Imbalanced Datasets in a Non-English Language**
2409.20147v1 by Vincent Beliveau, Helene Kaas, Martin Prener, Claes N. Ladefoged, Desmond Elliott, Gitte M. Knudsen, Lars H. Pinborg, Melanie Ganz

Natural language processing (NLP) in the medical domain can underperform in
real-world applications involving small datasets in a non-English language with
few labeled samples and imbalanced classes. There is yet no consensus on how to
approach this problem. We evaluated a set of NLP models including BERT-like
transformers, few-shot learning with sentence transformers (SetFit), and
prompted large language models (LLM), using three datasets of radiology reports
on magnetic resonance images of epilepsy patients in Danish, a low-resource
language. Our results indicate that BERT-like models pretrained in the target
domain of radiology reports currently offer the optimal performances for this
scenario. Notably, the SetFit and LLM models underperformed compared to
BERT-like models, with LLM performing the worst. Importantly, none of the
models investigated was sufficiently accurate to allow for text classification
without any supervision. However, they show potential for data filtering, which
could reduce the amount of manual labeling required.

摘要：自然語言處理 (NLP) 在醫療領域中，在涉及非英語語言中小型資料集、標記樣本少和類別不平衡的實際應用中表現不佳。對於如何解決這個問題，目前尚未達成共識。我們使用三組丹麥語癲癇患者磁共振影像的放射報告資料集，評估了一組 NLP 模型，包括類 BERT 轉換器、使用句子轉換器 (SetFit) 的少樣本學習，以及提示的大型語言模型 (LLM)。我們的結果表明，目前在放射報告目標領域中預訓練的類 BERT 模型為此情境提供最佳效能。值得注意的是，與類 BERT 模型相比，SetFit 和 LLM 模型表現不佳，而 LLM 表現最差。重要的是，所研究的模型中沒有一個足夠準確，可以在沒有任何監督的情況下進行文字分類。然而，它們顯示出資料過濾的潛力，這可以減少所需的手動標記量。

##### **Positive-Sum Fairness: Leveraging Demographic Attributes to Achieve Fair AI Outcomes Without Sacrificing Group Gains**
2409.19940v1 by Samia Belhadj, Sanguk Park, Ambika Seth, Hesham Dar, Thijs Kooi

Fairness in medical AI is increasingly recognized as a crucial aspect of
healthcare delivery. While most of the prior work done on fairness emphasizes
the importance of equal performance, we argue that decreases in fairness can be
either harmful or non-harmful, depending on the type of change and how
sensitive attributes are used. To this end, we introduce the notion of
positive-sum fairness, which states that an increase in performance that
results in a larger group disparity is acceptable as long as it does not come
at the cost of individual subgroup performance. This allows sensitive
attributes correlated with the disease to be used to increase performance
without compromising on fairness.
  We illustrate this idea by comparing four CNN models that make different use
of the race attribute in the training phase. The results show that removing all
demographic encodings from the images helps close the gap in performance
between the different subgroups, whereas leveraging the race attribute as a
model's input increases the overall performance while widening the disparities
between subgroups. These larger gaps are then put in perspective of the
collective benefit through our notion of positive-sum fairness to distinguish
harmful from non harmful disparities.

摘要：醫療 AI 中的公平性日益被視為醫療保健提供中至關重要的一環。雖然大多數先前關於公平性的研究都強調同等表現的重要性，我們認為公平性的下降可能是有害的或無害的，具體取決於變化的類型和敏感屬性的使用方式。為此，我們引入了正和公平性的概念，它指出，只要不以犧牲個別子群體表現為代價，那麼導致群體差異更大的表現提升是可以接受的。這允許將與疾病相關的敏感屬性用於提高表現，而不會損害公平性。
我們通過比較四個在訓練階段對種族屬性使用不同的 CNN 模型來說明這個想法。結果顯示，從圖像中移除所有人口編碼有助於縮小不同子群體之間的表現差距，而將種族屬性用作模型的輸入會提高整體表現，同時擴大子群體之間的差異。然後，通過我們正和公平性的概念將這些更大的差距置於整體效益的角度，以區分有害和無害的差異。

##### **InfantCryNet: A Data-driven Framework for Intelligent Analysis of Infant Cries**
2409.19689v1 by Mengze Hong, Chen Jason Zhang, Lingxiao Yang, Yuanfeng Song, Di Jiang

Understanding the meaning of infant cries is a significant challenge for
young parents in caring for their newborns. The presence of background noise
and the lack of labeled data present practical challenges in developing systems
that can detect crying and analyze its underlying reasons. In this paper, we
present a novel data-driven framework, "InfantCryNet," for accomplishing these
tasks. To address the issue of data scarcity, we employ pre-trained audio
models to incorporate prior knowledge into our model. We propose the use of
statistical pooling and multi-head attention pooling techniques to extract
features more effectively. Additionally, knowledge distillation and model
quantization are applied to enhance model efficiency and reduce the model size,
better supporting industrial deployment in mobile devices. Experiments on
real-life datasets demonstrate the superior performance of the proposed
framework, outperforming state-of-the-art baselines by 4.4% in classification
accuracy. The model compression effectively reduces the model size by 7%
without compromising performance and by up to 28% with only an 8% decrease in
accuracy, offering practical insights for model selection and system design.

摘要：了解嬰兒哭聲的含義對於年輕父母照顧新生兒來說是一項重大挑戰。背景噪音的存在和標籤資料的缺乏在開發可以偵測哭聲並分析其背後原因的系統時提出了實際挑戰。在本文中，我們提出了一個新穎的資料驅動框架「InfantCryNet」來完成這些任務。為了解決資料稀缺的問題，我們採用預先訓練的音訊模型，將先驗知識納入我們的模型中。我們提出使用統計池化和多頭注意力池化技術來更有效地提取特徵。此外，知識蒸餾和模型量化被應用於增強模型效率並縮小模型大小，更好地支援行動裝置中的產業部署。對真實資料集的實驗證明了所提出的框架的優異效能，在分類準確度上比最先進的基準高出 4.4%。模型壓縮有效地將模型大小減少了 7%，而不會損害效能，並在準確度僅下降 8% 的情況下將模型大小減少了 28%，為模型選擇和系統設計提供了實用的見解。

##### **See Detail Say Clear: Towards Brain CT Report Generation via Pathological Clue-driven Representation Learning**
2409.19676v2 by Chengxin Zheng, Junzhong Ji, Yanzhao Shi, Xiaodan Zhang, Liangqiong Qu

Brain CT report generation is significant to aid physicians in diagnosing
cranial diseases. Recent studies concentrate on handling the consistency
between visual and textual pathological features to improve the coherence of
report. However, there exist some challenges: 1) Redundant visual representing:
Massive irrelevant areas in 3D scans distract models from representing salient
visual contexts. 2) Shifted semantic representing: Limited medical corpus
causes difficulties for models to transfer the learned textual representations
to generative layers. This study introduces a Pathological Clue-driven
Representation Learning (PCRL) model to build cross-modal representations based
on pathological clues and naturally adapt them for accurate report generation.
Specifically, we construct pathological clues from perspectives of segmented
regions, pathological entities, and report themes, to fully grasp visual
pathological patterns and learn cross-modal feature representations. To adapt
the representations for the text generation task, we bridge the gap between
representation learning and report generation by using a unified large language
model (LLM) with task-tailored instructions. These crafted instructions enable
the LLM to be flexibly fine-tuned across tasks and smoothly transfer the
semantic representation for report generation. Experiments demonstrate that our
method outperforms previous methods and achieves SoTA performance. Our code is
available at "https://github.com/Chauncey-Jheng/PCRL-MRG".

摘要：腦部電腦斷層掃描報告生成有助於醫生診斷顱骨疾病。最近的研究專注於處理視覺和文字病理特徵之間的一致性，以提高報告的一致性。然而，存在一些挑戰：1) 多餘的視覺表示：3D 掃描中的大量無關區域會分散模型對顯著視覺背景的表示。2) 轉移的語義表示：有限的醫學語料庫導致模型難以將學習到的文字表示轉移到生成層。本研究引入了病理線索驅動表示學習 (PCRL) 模型，基於病理線索構建跨模態表示，並自然地調整它們以進行準確的報告生成。具體來說，我們從分割區域、病理實體和報告主題的角度構建病理線索，以充分掌握視覺病理模式並學習跨模態特徵表示。為了調整表示以適應文本生成任務，我們通過使用具有任務定制指令的統一大型語言模型 (LLM) 來彌合表示學習和報告生成之間的差距。這些精心製作的指令使 LLM 能夠靈活地跨任務進行微調，並順利地將語義表示轉移到報告生成中。實驗表明，我們的模型優於先前的模型，並達到了最先進的性能。我們的程式碼可在「https://github.com/Chauncey-Jheng/PCRL-MRG」取得。

##### **Assessment and manipulation of latent constructs in pre-trained language models using psychometric scales**
2409.19655v1 by Maor Reuben, Ortal Slobodin, Aviad Elyshar, Idan-Chaim Cohen, Orna Braun-Lewensohn, Odeya Cohen, Rami Puzis

Human-like personality traits have recently been discovered in large language
models, raising the hypothesis that their (known and as yet undiscovered)
biases conform with human latent psychological constructs. While large
conversational models may be tricked into answering psychometric
questionnaires, the latent psychological constructs of thousands of simpler
transformers, trained for other tasks, cannot be assessed because appropriate
psychometric methods are currently lacking. Here, we show how standard
psychological questionnaires can be reformulated into natural language
inference prompts, and we provide a code library to support the psychometric
assessment of arbitrary models. We demonstrate, using a sample of 88 publicly
available models, the existence of human-like mental health-related constructs
(including anxiety, depression, and Sense of Coherence) which conform with
standard theories in human psychology and show similar correlations and
mitigation strategies. The ability to interpret and rectify the performance of
language models by using psychological tools can boost the development of more
explainable, controllable, and trustworthy models.

摘要：大型語言模型最近發現了類人的人格特質，提出了一個假設，即它們（已知和尚未發現的）偏見符合人類潛在的心理結構。雖然大型對話模型可能會被誘騙回答心理測驗問卷，但數千個經過訓練以執行其他任務的較簡單轉換器的潛在心理結構無法評估，因為目前缺乏適當的心理測量方法。在這裡，我們展示了如何將標準心理問卷重新表述為自然語言推理提示，並提供一個代碼庫來支持任意模型的心理測量評估。我們使用 88 個公開可用的模型的樣本，證明了類人心理健康相關結構（包括焦慮、抑鬱和一致感）的存在，這些結構符合人類心理學的標準理論，並顯示出類似的相關性和緩解策略。使用心理工具解釋和糾正語言模型的性能的能力可以促進更具可解釋性、可控性和可信度的模型的開發。

##### **A Survey on Graph Neural Networks for Remaining Useful Life Prediction: Methodologies, Evaluation and Future Trends**
2409.19629v1 by Yucheng Wang, Min Wu, Xiaoli Li, Lihua Xie, Zhenghua Chen

Remaining Useful Life (RUL) prediction is a critical aspect of Prognostics
and Health Management (PHM), aimed at predicting the future state of a system
to enable timely maintenance and prevent unexpected failures. While existing
deep learning methods have shown promise, they often struggle to fully leverage
the spatial information inherent in complex systems, limiting their
effectiveness in RUL prediction. To address this challenge, recent research has
explored the use of Graph Neural Networks (GNNs) to model spatial information
for more accurate RUL prediction. This paper presents a comprehensive review of
GNN techniques applied to RUL prediction, summarizing existing methods and
offering guidance for future research. We first propose a novel taxonomy based
on the stages of adapting GNNs to RUL prediction, systematically categorizing
approaches into four key stages: graph construction, graph modeling, graph
information processing, and graph readout. By organizing the field in this way,
we highlight the unique challenges and considerations at each stage of the GNN
pipeline. Additionally, we conduct a thorough evaluation of various
state-of-the-art (SOTA) GNN methods, ensuring consistent experimental settings
for fair comparisons. This rigorous analysis yields valuable insights into the
strengths and weaknesses of different approaches, serving as an experimental
guide for researchers and practitioners working in this area. Finally, we
identify and discuss several promising research directions that could further
advance the field, emphasizing the potential for GNNs to revolutionize RUL
prediction and enhance the effectiveness of PHM strategies. The benchmarking
codes are available in GitHub:
https://github.com/Frank-Wang-oss/GNN\_RUL\_Benchmarking.

摘要：剩餘使用壽命 (RUL) 預測是預測與健康管理 (PHM) 的一個關鍵面向，旨在預測系統的未來狀態，以利於適時維護並預防意外故障。雖然現有的深度學習方法已展現前景，但它們往往難以充分利用複雜系統中固有的空間資訊，限制了它們在 RUL 預測中的效能。為了解決此挑戰，最近的研究已探討使用圖神經網路 (GNN) 來建模空間資訊，以進行更準確的 RUL 預測。本文提供了應用於 RUL 預測的 GNN 技術的全面回顧，總結了現有方法，並為未來的研究提供指導。我們首先根據適應 GNN 至 RUL 預測的階段提出一個新穎的分類法，系統性地將方法分類為四個關鍵階段：圖形建構、圖形建模、圖形資訊處理和圖形讀取。透過這種方式組織領域，我們強調了 GNN 管線中每個階段的獨特挑戰和考量。此外，我們對各種最先進 (SOTA) GNN 方法進行了徹底的評估，確保了一致的實驗設定以進行公平的比較。這種嚴謹的分析對不同方法的優缺點產生了寶貴的見解，作為在這個領域工作的研究人員和實務者的實驗指南。最後，我們找出並討論了幾個有前景的研究方向，這些方向可以進一步推進此領域，強調 GNN 具有革新 RUL 預測和提升 PHM 策略效能的潛力。基準代碼可在 GitHub 中取得：https://github.com/Frank-Wang-oss/GNN\_RUL\_Benchmarking。

##### **MCDDPM: Multichannel Conditional Denoising Diffusion Model for Unsupervised Anomaly Detection in Brain MRI**
2409.19623v1 by Vivek Kumar Trivedi, Bheeshm Sharma, P. Balamurugan

Detecting anomalies in brain MRI scans using supervised deep learning methods
presents challenges due to anatomical diversity and labor-intensive requirement
of pixel-level annotations. Generative models like Denoising Diffusion
Probabilistic Model (DDPM) and their variants like pDDPM, mDDPM, cDDPM have
recently emerged to be powerful alternatives to perform unsupervised anomaly
detection in brain MRI scans. These methods leverage frame-level labels of
healthy brains to generate healthy tissues in brain MRI scans. During
inference, when an anomalous (or unhealthy) scan image is presented as an
input, these models generate a healthy scan image corresponding to the input
anomalous scan, and the difference map between the generated healthy scan image
and the original anomalous scan image provide the necessary pixel level
identification of abnormal tissues. The generated healthy images from the DDPM,
pDDPM and mDDPM models however suffer from fidelity issues and contain
artifacts that do not have medical significance. While cDDPM achieves slightly
better fidelity and artifact suppression, it requires huge memory footprint and
is computationally expensive than the other DDPM based models. In this work, we
propose an improved version of DDPM called Multichannel Conditional Denoising
Diffusion Probabilistic Model (MCDDPM) for unsupervised anomaly detection in
brain MRI scans. Our proposed model achieves high fidelity by making use of
additional information from the healthy images during the training process,
enriching the representation power of DDPM models, with a computational cost
and memory requirements on par with DDPM, pDDPM and mDDPM models. Experimental
results on multiple datasets (e.g. BraTS20, BraTS21) demonstrate promising
performance of the proposed method. The code is available at
https://github.com/vivekkumartri/MCDDPM.

摘要：使用监督式深度学习方法检测脑部 MRI 扫描中的异常现象会面临解剖学多样性以及像素级注释的劳动密集型需求的挑战。去噪扩散概率模型 (DDPM) 及其变体如 pDDPM、mDDPM、cDDPM 等生成模型最近浮出水面，成为在脑部 MRI 扫描中执行无监督异常检测的强大替代方案。这些方法利用健康脑部的帧级标签在脑部 MRI 扫描中生成健康组织。在推理过程中，当异常（或不健康）扫描图像作为输入呈现时，这些模型会生成与输入异常扫描对应的健康扫描图像，而生成的健康扫描图像与原始异常扫描图像之间的差异图提供了异常组织的必要像素级识别。然而，DDPM、pDDPM 和 mDDPM 模型生成的健康图像存在保真度问题，并且包含没有医学意义的伪像。虽然 cDDPM 实现了稍微更好的保真度和伪像抑制，但它需要巨大的内存占用，并且比其他基于 DDPM 的模型在计算上更昂贵。在这项工作中，我们提出了一个称为多通道条件去噪扩散概率模型 (MCDDPM) 的 DDPM 改进版本，用于在脑部 MRI 扫描中进行无监督异常检测。我们提出的模型通过在训练过程中利用健康图像中的附加信息来实现高保真度，从而丰富了 DDPM 模型的表示能力，并且计算成本和内存需求与 DDPM、pDDPM 和 mDDPM 模型相当。在多个数据集（例如 BraTS20、BraTS21）上的实验结果证明了所提出方法的良好性能。代码可在 https://github.com/vivekkumartri/MCDDPM 获得。

##### **Understanding Clinical Decision-Making in Traditional East Asian Medicine through Dimensionality Reduction: An Empirical Investigation**
2409.19531v1 by Hyojin Bae, Bongsu Kang, Chang-Eop Kim

This study examines the clinical decision-making processes in Traditional
East Asian Medicine (TEAM) by reinterpreting pattern identification (PI)
through the lens of dimensionality reduction. Focusing on the Eight Principle
Pattern Identification (EPPI) system and utilizing empirical data from the
Shang-Han-Lun, we explore the necessity and significance of prioritizing the
Exterior-Interior pattern in diagnosis and treatment selection. We test three
hypotheses: whether the Ext-Int pattern contains the most information about
patient symptoms, represents the most abstract and generalizable symptom
information, and facilitates the selection of appropriate herbal prescriptions.
Employing quantitative measures such as the abstraction index,
cross-conditional generalization performance, and decision tree regression, our
results demonstrate that the Exterior-Interior pattern represents the most
abstract and generalizable symptom information, contributing to the efficient
mapping between symptom and herbal prescription spaces. This research provides
an objective framework for understanding the cognitive processes underlying
TEAM, bridging traditional medical practices with modern computational
approaches. The findings offer insights into the development of AI-driven
diagnostic tools in TEAM and conventional medicine, with the potential to
advance clinical practice, education, and research.

摘要：本研究透過降維透視重新詮釋證候辨識（PI），探討傳統東亞醫學（TEAM）的臨床決策制定過程。我們專注於八綱證候辨識（EPPI）系統，並利用傷寒論的經驗資料，探討在診斷和治療選擇中優先考慮表裡證的必要性和重要性。我們檢驗了三個假設：表裡證是否包含最多關於患者症狀的資訊、是否代表最抽象且可概括的症狀資訊，以及是否能促進適當草藥處方的選擇。我們的結果採用了抽象指數、交叉條件概化效能和決策樹回歸等量化測量，證明表裡證代表最抽象且可概括的症狀資訊，有助於症狀與草藥處方空間之間的有效對應。本研究為理解 TEAM 背後的認知過程提供了客觀架構，結合傳統醫學實務與現代運算方法。研究結果提供了見解，有助於開發 TEAM 和傳統醫學中由 AI 驅動的診斷工具，並有潛力促進臨床實務、教育和研究。

##### **MedHalu: Hallucinations in Responses to Healthcare Queries by Large Language Models**
2409.19492v1 by Vibhor Agarwal, Yiqiao Jin, Mohit Chandra, Munmun De Choudhury, Srijan Kumar, Nishanth Sastry

The remarkable capabilities of large language models (LLMs) in language
understanding and generation have not rendered them immune to hallucinations.
LLMs can still generate plausible-sounding but factually incorrect or
fabricated information. As LLM-empowered chatbots become popular, laypeople may
frequently ask health-related queries and risk falling victim to these LLM
hallucinations, resulting in various societal and healthcare implications. In
this work, we conduct a pioneering study of hallucinations in LLM-generated
responses to real-world healthcare queries from patients. We propose MedHalu, a
carefully crafted first-of-its-kind medical hallucination dataset with a
diverse range of health-related topics and the corresponding hallucinated
responses from LLMs with labeled hallucination types and hallucinated text
spans. We also introduce MedHaluDetect framework to evaluate capabilities of
various LLMs in detecting hallucinations. We also employ three groups of
evaluators -- medical experts, LLMs, and laypeople -- to study who are more
vulnerable to these medical hallucinations. We find that LLMs are much worse
than the experts. They also perform no better than laypeople and even worse in
few cases in detecting hallucinations. To fill this gap, we propose
expert-in-the-loop approach to improve hallucination detection through LLMs by
infusing expert reasoning. We observe significant performance gains for all the
LLMs with an average macro-F1 improvement of 6.3 percentage points for GPT-4.

摘要：大型語言模型 (LLM) 在語言理解和生成方面的卓越能力並未讓它們免於出現幻覺。LLM 仍然可以生成聽起來合理但事實上不正確或捏造的信息。隨著由 LLM 驅動的聊天機器人變得流行，外行人可能會頻繁詢問與健康相關的問題，並冒著成為這些 LLM 幻覺受害者的風險，從而產生各種社會和醫療保健影響。在這項工作中，我們對患者現實世界的醫療保健查詢中由 LLM 生成的回應中的幻覺進行了開創性的研究。我們提出了 MedHalu，這是一個精心製作的同類首創的醫學幻覺數據集，其中包含各種與健康相關的主題以及來自 LLM 的對應幻覺回應，並標記了幻覺類型和幻覺文本跨度。我們還引入了 MedHaluDetect 框架來評估各種 LLM 在檢測幻覺方面的能力。我們還聘請了三組評估人員——醫學專家、LLM 和外行人——來研究誰更容易受到這些醫療幻覺的影響。我們發現 LLM 遠不如專家。在檢測幻覺方面，它們的表現也不比外行人好，甚至在某些情況下表現得更糟。為了填補這一空白，我們提出了專家循環方法，通過注入專家推理來改進 LLM 的幻覺檢測。我們觀察到所有 LLM 的性能都有顯著提升，GPT-4 的平均宏觀 F1 提升了 6.3 個百分點。

##### **INSIGHTBUDDY-AI: Medication Extraction and Entity Linking using Large Language Models and Ensemble Learning**
2409.19467v1 by Pablo Romero, Lifeng Han, Goran Nenadic

Medication Extraction and Mining play an important role in healthcare NLP
research due to its practical applications in hospital settings, such as their
mapping into standard clinical knowledge bases (SNOMED-CT, BNF, etc.). In this
work, we investigate state-of-the-art LLMs in text mining tasks on medications
and their related attributes such as dosage, route, strength, and adverse
effects. In addition, we explore different ensemble learning methods
(\textsc{Stack-Ensemble} and \textsc{Voting-Ensemble}) to augment the model
performances from individual LLMs. Our ensemble learning result demonstrated
better performances than individually fine-tuned base models BERT, RoBERTa,
RoBERTa-L, BioBERT, BioClinicalBERT, BioMedRoBERTa, ClinicalBERT, and
PubMedBERT across general and specific domains. Finally, we build up an entity
linking function to map extracted medical terminologies into the SNOMED-CT
codes and the British National Formulary (BNF) codes, which are further mapped
to the Dictionary of Medicines and Devices (dm+d), and ICD. Our model's toolkit
and desktop applications are publicly available at
\url{https://github.com/HECTA-UoM/ensemble-NER}.

摘要：藥物萃取和探勘在醫療保健自然語言處理研究中扮演重要的角色，因為它在醫院環境中有實際應用，例如將它們對應到標準臨床知識庫（SNOMED-CT、BNF 等）。在這項工作中，我們探討了最先進的 LLM 在藥物及其相關屬性（例如劑量、途徑、強度和不良反應）的文字探勘任務。此外，我們探索了不同的整合學習方法（\textsc{Stack-Ensemble} 和 \textsc{Voting-Ensemble}）以增強個別 LLM 的模型效能。我們的整合學習結果證明了比個別微調基礎模型 BERT、RoBERTa、RoBERTa-L、BioBERT、BioClinicalBERT、BioMedRoBERTa、ClinicalBERT 和 PubMedBERT 在一般和特定領域中表現得更好。最後，我們建立了一個實體連結函數，將萃取的醫學術語對應到 SNOMED-CT 代碼和英國國家處方集 (BNF) 代碼，進一步對應到藥品和器材字典 (dm+d) 和 ICD。我們的模型工具組和桌面應用程式公開於\url{https://github.com/HECTA-UoM/ensemble-NER}。

##### **Mind the Gap: Promoting Missing Modality Brain Tumor Segmentation with Alignment**
2409.19366v1 by Tianyi Liu, Zhaorui Tan, Haochuan Jiang, Xi Yang, Kaizhu Huang

Brain tumor segmentation is often based on multiple magnetic resonance
imaging (MRI). However, in clinical practice, certain modalities of MRI may be
missing, which presents an even more difficult scenario. To cope with this
challenge, knowledge distillation has emerged as one promising strategy.
However, recent efforts typically overlook the modality gaps and thus fail to
learn invariant feature representations across different modalities. Such
drawback consequently leads to limited performance for both teachers and
students. To ameliorate these problems, in this paper, we propose a novel
paradigm that aligns latent features of involved modalities to a well-defined
distribution anchor. As a major contribution, we prove that our novel training
paradigm ensures a tight evidence lower bound, thus theoretically certifying
its effectiveness. Extensive experiments on different backbones validate that
the proposed paradigm can enable invariant feature representations and produce
a teacher with narrowed modality gaps. This further offers superior guidance
for missing modality students, achieving an average improvement of 1.75 on dice
score.

摘要：腦腫瘤分割通常基於多種磁共振影像 (MRI)。然而，在臨床實務中，某些 MRI 的方式可能缺失，這會構成更困難的情境。為了應對此一挑戰，知識蒸餾已成為一項有前途的策略。然而，最近的努力通常忽略方式的差距，因此無法學習跨不同方式的不變特徵表示。這樣的缺點導致教師和學生兩者的表現有限。為了改善這些問題，我們在本文中提出一個新的範例，將相關方式的潛在特徵與明確定義的分布錨點對齊。作為一項重大貢獻，我們證明我們新的訓練範例確保嚴謹的證據下界，從而理論上證明其有效性。在不同骨幹上的廣泛實驗驗證了所提出的範例能夠啟用不變特徵表示，並產生方式差距縮小的教師。這進一步為遺失方式的學生提供優異的指導，在骰子分數上平均提升 1.75。

##### **3D-CT-GPT: Generating 3D Radiology Reports through Integration of Large Vision-Language Models**
2409.19330v1 by Hao Chen, Wei Zhao, Yingli Li, Tianyang Zhong, Yisong Wang, Youlan Shang, Lei Guo, Junwei Han, Tianming Liu, Jun Liu, Tuo Zhang

Medical image analysis is crucial in modern radiological diagnostics,
especially given the exponential growth in medical imaging data. The demand for
automated report generation systems has become increasingly urgent. While prior
research has mainly focused on using machine learning and multimodal language
models for 2D medical images, the generation of reports for 3D medical images
has been less explored due to data scarcity and computational complexities.
This paper introduces 3D-CT-GPT, a Visual Question Answering (VQA)-based
medical visual language model specifically designed for generating radiology
reports from 3D CT scans, particularly chest CTs. Extensive experiments on both
public and private datasets demonstrate that 3D-CT-GPT significantly
outperforms existing methods in terms of report accuracy and quality. Although
current methods are few, including the partially open-source CT2Rep and the
open-source M3D, we ensured fair comparison through appropriate data conversion
and evaluation methodologies. Experimental results indicate that 3D-CT-GPT
enhances diagnostic accuracy and report coherence, establishing itself as a
robust solution for clinical radiology report generation. Future work will
focus on expanding the dataset and further optimizing the model to enhance its
performance and applicability.

摘要：醫療影像分析在現代放射診斷中至關重要，特別是考慮到醫學影像資料的指數成長。對自動化報告產生系統的需求已變得越來越迫切。雖然先前的研究主要集中於使用機器學習和多模態語言模型進行 2D 醫療影像，但由於資料稀少和計算複雜度，3D 醫療影像的報告產生較少被探討。本文介紹 3D-CT-GPT，一種專門設計用於從 3D CT 掃描（特別是胸部 CT）產生放射科報告的基於視覺問答 (VQA) 的醫學視覺語言模型。在公共和私人資料集上的廣泛實驗表明，3D-CT-GPT 在報告準確性和品質方面顯著優於現有方法。雖然目前的方法很少，包括部分開源的 CT2Rep 和開源的 M3D，但我們透過適當的資料轉換和評估方法確保了公平的比較。實驗結果表明，3D-CT-GPT 增強了診斷準確性和報告一致性，確立了其作為臨床放射科報告產生的強大解決方案。未來的研究將專注於擴充資料集和進一步最佳化模型，以增強其效能和適用性。

##### **Epidemiology-Aware Neural ODE with Continuous Disease Transmission Graph**
2410.00049v1 by Guancheng Wan, Zewen Liu, Max S. Y. Lau, B. Aditya Prakash, Wei Jin

Effective epidemic forecasting is critical for public health strategies and
efficient medical resource allocation, especially in the face of rapidly
spreading infectious diseases. However, existing deep-learning methods often
overlook the dynamic nature of epidemics and fail to account for the specific
mechanisms of disease transmission. In response to these challenges, we
introduce an innovative end-to-end framework called Epidemiology-Aware Neural
ODE with Continuous Disease Transmission Graph (EARTH) in this paper. To learn
continuous and regional disease transmission patterns, we first propose EANO,
which seamlessly integrates the neural ODE approach with the epidemic
mechanism, considering the complex spatial spread process during epidemic
evolution. Additionally, we introduce GLTG to model global infection trends and
leverage these signals to guide local transmission dynamically. To accommodate
both the global coherence of epidemic trends and the local nuances of epidemic
transmission patterns, we build a cross-attention approach to fuse the most
meaningful information for forecasting. Through the smooth synergy of both
components, EARTH offers a more robust and flexible approach to understanding
and predicting the spread of infectious diseases. Extensive experiments show
EARTH superior performance in forecasting real-world epidemics compared to
state-of-the-art methods. The code will be available at
https://github.com/Emory-Melody/EpiLearn.

摘要：<paragraph>有效的疫情预测对于公共卫生策略和高效的医疗资源分配至关重要，尤其是在快速传播的传染病面前。然而，现有的深度学习方法常常忽视疫情的动态特性，并且无法解释疾病传播的具体机制。为了应对这些挑战，我们在本文中介绍了一个创新的端到端框架，称为具有连续疾病传播图的流行病感知神经 ODE（EARTH）。为了学习连续的区域性疾病传播模式，我们首先提出了 EANO，它将神经 ODE 方法与流行病机制无缝集成，考虑了流行病演变过程中的复杂空间传播过程。此外，我们引入了 GLTG 来建模全球感染趋势，并利用这些信号动态地指导局部传播。为了适应流行病趋势的全局一致性和流行病传播模式的局部细微差别，我们构建了一种交叉注意方法来融合最有意义的预测信息。通过这两个组件的平稳协同作用，EARTH 为理解和预测传染病的传播提供了一种更稳健、更灵活的方法。大量的实验表明，与最先进的方法相比，EARTH 在预测现实世界的流行病方面具有卓越的性能。代码将在 https://github.com/Emory-Melody/EpiLearn 上提供。</paragraph>

##### **A GEN AI Framework for Medical Note Generation**
2410.01841v1 by Hui Yi Leong, Yi Fan Gao, Shuai Ji, Bora Kalaycioglu, Uktu Pamuksuz

The increasing administrative burden of medical documentation, particularly
through Electronic Health Records (EHR), significantly reduces the time
available for direct patient care and contributes to physician burnout. To
address this issue, we propose MediNotes, an advanced generative AI framework
designed to automate the creation of SOAP (Subjective, Objective, Assessment,
Plan) notes from medical conversations. MediNotes integrates Large Language
Models (LLMs), Retrieval-Augmented Generation (RAG), and Automatic Speech
Recognition (ASR) to capture and process both text and voice inputs in real
time or from recorded audio, generating structured and contextually accurate
medical notes. The framework also incorporates advanced techniques like
Quantized Low-Rank Adaptation (QLoRA) and Parameter-Efficient Fine-Tuning
(PEFT) for efficient model fine-tuning in resource-constrained environments.
Additionally, MediNotes offers a query-based retrieval system, allowing
healthcare providers and patients to access relevant medical information
quickly and accurately. Evaluations using the ACI-BENCH dataset demonstrate
that MediNotes significantly improves the accuracy, efficiency, and usability
of automated medical documentation, offering a robust solution to reduce the
administrative burden on healthcare professionals while improving the quality
of clinical workflows.

摘要：隨著電子病歷 (EHR) 的出現，醫療文件管理的行政負擔日益加重，這顯著減少了直接患者照護的時間，並導致醫師倦怠。為了解決這個問題，我們提出 MediNotes，一個先進的生成式 AI 框架，旨在自動化 SOAP（主觀、客觀、評估、計畫）筆記的建立，這些筆記來自於醫療對話。MediNotes 整合了大型語言模型 (LLM)、檢索增強生成 (RAG) 和自動語音辨識 (ASR)，以即時或從錄製的音訊中擷取和處理文字和語音輸入，產生結構化且在脈絡上準確的醫療筆記。這個框架也結合了先進的技術，例如量化低秩適應 (QLoRA) 和參數有效微調 (PEFT)，以在資源受限的環境中進行有效率的模型微調。此外，MediNotes 提供一個基於查詢的檢索系統，讓醫療保健提供者和患者可以快速且準確地存取相關的醫療資訊。使用 ACI-BENCH 資料集的評估顯示，MediNotes 大幅提升了自動化醫療文件管理的準確性、效率和可用性，提供了一個強健的解決方案，以減輕醫療保健專業人員的行政負擔，同時改善臨床工作流程的品質。

##### **Secure Multiparty Generative AI**
2409.19120v1 by Manil Shrestha, Yashodha Ravichandran, Edward Kim

As usage of generative AI tools skyrockets, the amount of sensitive
information being exposed to these models and centralized model providers is
alarming. For example, confidential source code from Samsung suffered a data
leak as the text prompt to ChatGPT encountered data leakage. An increasing
number of companies are restricting the use of LLMs (Apple, Verizon, JPMorgan
Chase, etc.) due to data leakage or confidentiality issues. Also, an increasing
number of centralized generative model providers are restricting, filtering,
aligning, or censoring what can be used. Midjourney and RunwayML, two of the
major image generation platforms, restrict the prompts to their system via
prompt filtering. Certain political figures are restricted from image
generation, as well as words associated with women's health care, rights, and
abortion.
  In our research, we present a secure and private methodology for generative
artificial intelligence that does not expose sensitive data or models to
third-party AI providers. Our work modifies the key building block of modern
generative AI algorithms, e.g. the transformer, and introduces confidential and
verifiable multiparty computations in a decentralized network to maintain the
1) privacy of the user input and obfuscation to the output of the model, and 2)
introduce privacy to the model itself. Additionally, the sharding process
reduces the computational burden on any one node, enabling the distribution of
resources of large generative AI processes across multiple, smaller nodes. We
show that as long as there exists one honest node in the decentralized
computation, security is maintained. We also show that the inference process
will still succeed if only a majority of the nodes in the computation are
successful. Thus, our method offers both secure and verifiable computation in a
decentralized network.

摘要：<paragraph>隨著生成式 AI 工具的使用量激增，暴露給這些模型和集中式模型提供者的敏感資訊數量令人擔憂。例如，來自三星的機密原始碼發生資料外洩，因為 ChatGPT 的文字提示遇到了資料外洩。由於資料外洩或機密性問題，越來越多的公司正在限制使用 LLM（Apple、Verizon、JPMorgan Chase 等）。此外，越來越多的集中式生成模型提供者正在限制、過濾、調整或審查可以使用什麼。Midjourney 和 RunwayML 是兩個主要的影像生成平台，它們透過提示過濾限制系統的提示。某些政治人物被禁止生成影像，以及與婦女保健、權利和墮胎相關的字詞。
在我們的研究中，我們提出了一種安全且私密的生成式人工智慧方法，不會將敏感資料或模型暴露給第三方 AI 提供者。我們的研究修改了現代生成式 AI 演算法的主要建構區塊，例如Transformer，並在分散式網路中引入了機密且可驗證的多方運算，以維護 1) 使用者輸入的隱私和模型輸出的混淆，以及 2) 為模型本身引入隱私。此外，分片處理會降低任何一個節點的運算負擔，讓大型生成式 AI 處理的資源可以分布在多個較小的節點上。我們表明，只要在分散式運算中存在一個誠實的節點，就能維持安全性。我們也表明，如果運算中只有多數節點成功，推理程序仍然會成功。因此，我們的模型在分散式網路中提供了安全且可驗證的運算。</paragraph>

##### **Differential privacy for protecting patient data in speech disorder detection using deep learning**
2409.19078v1 by Soroosh Tayebi Arasteh, Mahshad Lotfinia, Paula Andrea Perez-Toro, Tomas Arias-Vergara, Juan Rafael Orozco-Arroyave, Maria Schuster, Andreas Maier, Seung Hee Yang

Speech pathology has impacts on communication abilities and quality of life.
While deep learning-based models have shown potential in diagnosing these
disorders, the use of sensitive data raises critical privacy concerns. Although
differential privacy (DP) has been explored in the medical imaging domain, its
application in pathological speech analysis remains largely unexplored despite
the equally critical privacy concerns. This study is the first to investigate
DP's impact on pathological speech data, focusing on the trade-offs between
privacy, diagnostic accuracy, and fairness. Using a large, real-world dataset
of 200 hours of recordings from 2,839 German-speaking participants, we observed
a maximum accuracy reduction of 3.85% when training with DP with a privacy
budget, denoted by {\epsilon}, of 7.51. To generalize our findings, we
validated our approach on a smaller dataset of Spanish-speaking Parkinson's
disease patients, demonstrating that careful pretraining on large-scale
task-specific datasets can maintain or even improve model accuracy under DP
constraints. We also conducted a comprehensive fairness analysis, revealing
that reasonable privacy levels (2<{\epsilon}<10) do not introduce significant
gender bias, though age-related disparities may require further attention. Our
results suggest that DP can effectively balance privacy and utility in speech
disorder detection, but also highlight the unique challenges in the speech
domain, particularly regarding the privacy-fairness trade-off. This provides a
foundation for future work to refine DP methodologies and address fairness
across diverse patient groups in real-world deployments.

摘要：<paragraph>言語病理學對溝通能力和生活品質有影響。
儘管基於深度學習的模型在診斷這些疾病方面已展現潛力，但敏感資料的使用引發了嚴重的隱私問題。儘管差分隱私 (DP) 已在醫學影像領域中得到探討，但其在病理語言分析中的應用仍未得到充分探討，儘管其隱私問題同樣嚴重。本研究首次探討了 DP 對病理語言資料的影響，重點關注隱私、診斷準確性和公平性之間的權衡。我們使用了一個大型的真實世界資料集，其中包含來自 2,839 名德語參與者的 200 小時錄音，我們觀察到在使用 DP 進行訓練時，隱私預算（以 {\epsilon} 表示）為 7.51 時，準確度最高降低了 3.85%。為了推廣我們的發現，我們在一個規模較小的西班牙語帕金森病患者資料集上驗證了我們的做法，證明了在大規模特定任務資料集上進行仔細的預訓練可以在 DP 約束下維持甚至提高模型準確度。我們還進行了全面的公平性分析，結果顯示合理的隱私等級（2<{\epsilon}<10）不會引入顯著的性別偏見，儘管與年齡相關的差異可能需要進一步關注。我們的結果表明，DP 可以有效地在語言障礙檢測中平衡隱私和效用，但也突出了語言領域中獨特的挑戰，特別是關於隱私公平性的權衡。這為未來的研究提供了基礎，以完善 DP 方法並在實際部署中解決不同患者群體中的公平性問題。</paragraph>

##### **AIPatient: Simulating Patients with EHRs and LLM Powered Agentic Workflow**
2409.18924v2 by Huizi Yu, Jiayan Zhou, Lingyao Li, Shan Chen, Jack Gallifant, Anye Shi, Xiang Li, Wenyue Hua, Mingyu Jin, Guang Chen, Yang Zhou, Zhao Li, Trisha Gupte, Ming-Li Chen, Zahra Azizi, Yongfeng Zhang, Themistocles L. Assimes, Xin Ma, Danielle S. Bitterman, Lin Lu, Lizhou Fan

Simulated patient systems play a crucial role in modern medical education and
research, providing safe, integrative learning environments and enabling
clinical decision-making simulations. Large Language Models (LLM) could advance
simulated patient systems by replicating medical conditions and patient-doctor
interactions with high fidelity and low cost. However, ensuring the
effectiveness and trustworthiness of these systems remains a challenge, as they
require a large, diverse, and precise patient knowledgebase, along with a
robust and stable knowledge diffusion to users. Here, we developed AIPatient,
an advanced simulated patient system with AIPatient Knowledge Graph (AIPatient
KG) as the input and the Reasoning Retrieval-Augmented Generation (Reasoning
RAG) agentic workflow as the generation backbone. AIPatient KG samples data
from Electronic Health Records (EHRs) in the Medical Information Mart for
Intensive Care (MIMIC)-III database, producing a clinically diverse and
relevant cohort of 1,495 patients with high knowledgebase validity (F1 0.89).
Reasoning RAG leverages six LLM powered agents spanning tasks including
retrieval, KG query generation, abstraction, checker, rewrite, and
summarization. This agentic framework reaches an overall accuracy of 94.15% in
EHR-based medical Question Answering (QA), outperforming benchmarks that use
either no agent or only partial agent integration. Our system also presents
high readability (median Flesch Reading Ease 77.23; median Flesch Kincaid Grade
5.6), robustness (ANOVA F-value 0.6126, p>0.1), and stability (ANOVA F-value
0.782, p>0.1). The promising performance of the AIPatient system highlights its
potential to support a wide range of applications, including medical education,
model evaluation, and system integration.

摘要：模擬病人系統在現代醫學教育和研究中扮演著至關重要的角色，提供安全、整合的學習環境，並能進行臨床決策模擬。大型語言模型 (LLM) 能透過高保真度和低成本複製醫療狀況和醫病互動，進而提升模擬病人系統。然而，確保這些系統的有效性和可信度仍然是一項挑戰，因為它們需要一個龐大、多元且精確的病人知識庫，以及穩健且穩定的知識傳播給使用者。在此，我們開發了 AIPatient，一個進階的模擬病人系統，以 AIPatient 知識圖譜 (AIPatient KG) 作為輸入，並以推理檢索增強生成 (Reasoning RAG) 代理工作流程作為生成主幹。AIPatient KG 從重症監護醫學資訊中心 (MIMIC)-III 資料庫中的電子健康紀錄 (EHR) 中抽取資料，產生一個臨床多樣且相關的 1,495 名病患群組，具有很高的知識庫效度 (F1 0.89)。推理 RAG 槓桿了六個 LLM 驅動的代理，跨越檢索、KG 查詢產生、抽象、檢查器、重寫和摘要等任務。這個代理框架在基於 EHR 的醫療問答 (QA) 中達到了 94.15% 的整體準確度，優於不使用代理或僅部分代理整合的基準。我們的系統還具有很高的可讀性 (Flesch 閱讀簡便性中位數 77.23；Flesch Kincaid 等級中位數 5.6)、穩健性 (ANOVA F 值 0.6126，p>0.1) 和穩定性 (ANOVA F 值 0.782，p>0.1)。AIPatient 系統的出色表現突顯了它在支援各種應用程式的潛力，包括醫學教育、模型評估和系統整合。

##### **Suicide Phenotyping from Clinical Notes in Safety-Net Psychiatric Hospital Using Multi-Label Classification with Pre-Trained Language Models**
2409.18878v2 by Zehan Li, Yan Hu, Scott Lane, Salih Selek, Lokesh Shahani, Rodrigo Machado-Vieira, Jair Soares, Hua Xu, Hongfang Liu, Ming Huang

Accurate identification and categorization of suicidal events can yield
better suicide precautions, reducing operational burden, and improving care
quality in high-acuity psychiatric settings. Pre-trained language models offer
promise for identifying suicidality from unstructured clinical narratives. We
evaluated the performance of four BERT-based models using two fine-tuning
strategies (multiple single-label and single multi-label) for detecting
coexisting suicidal events from 500 annotated psychiatric evaluation notes. The
notes were labeled for suicidal ideation (SI), suicide attempts (SA), exposure
to suicide (ES), and non-suicidal self-injury (NSSI). RoBERTa outperformed
other models using multiple single-label classification strategy (acc=0.86,
F1=0.78). MentalBERT (acc=0.83, F1=0.74) also exceeded BioClinicalBERT
(acc=0.82, F1=0.72) which outperformed BERT (acc=0.80, F1=0.70). RoBERTa
fine-tuned with single multi-label classification further improved the model
performance (acc=0.88, F1=0.81). The findings highlight that the model
optimization, pretraining with domain-relevant data, and the single multi-label
classification strategy enhance the model performance of suicide phenotyping.
Keywords: EHR-based Phenotyping; Natural Language Processing; Secondary Use of
EHR Data; Suicide Classification; BERT-based Model; Psychiatry; Mental Health

摘要：<paragraph>準確辨識和分類自殺事件，可以產生更好的自殺預防措施，降低運作負擔，並提升高敏精神科環境中的照護品質。預先訓練的語言模型有望從非結構化的臨床敘述中辨識出自殺傾向。我們評估了四個 BERT 模型的效能，使用兩種微調策略（多重單標籤和單一多標籤）來偵測 500 個註解的精神科評估記錄中並存的自殺事件。這些記錄標記為自殺意念（SI）、自殺企圖（SA）、接觸自殺（ES）和非自殺自傷（NSSI）。RoBERTa 使用多重單標籤分類策略表現優於其他模型（acc=0.86，F1=0.78）。MentalBERT（acc=0.83，F1=0.74）也超過 BioClinicalBERT（acc=0.82，F1=0.72），而 BioClinicalBERT 則優於 BERT（acc=0.80，F1=0.70）。使用單一多標籤分類微調的 RoBERTa 進一步提升了模型效能（acc=0.88，F1=0.81）。研究結果強調，模型最佳化、使用與領域相關資料進行預訓練，以及單一多標籤分類策略，可以提升自殺表型分析的模型效能。關鍵字：基於電子病歷的表型分析；自然語言處理；電子病歷資料的二次使用；自殺分類；基於 BERT 的模型；精神科；心理健康</paragraph>

##### **Early diagnosis of Alzheimer's disease from MRI images with deep learning model**
2409.18814v1 by Sajjad Aghasi Javid, Mahmood Mohassel Feghhi

It is acknowledged that the most common cause of dementia worldwide is
Alzheimer's disease (AD). This condition progresses in severity from mild to
severe and interferes with people's everyday routines. Early diagnosis plays a
critical role in patient care and clinical trials. Convolutional neural
networks (CNN) are used to create a framework for identifying specific disease
features from MRI scans Classification of dementia involves approaches such as
medical history review, neuropsychological tests, and magnetic resonance
imaging (MRI). However, the image dataset obtained from Kaggle faces a
significant issue of class imbalance, which requires equal distribution of
samples from each class to address. In this article, to address this imbalance,
the Synthetic Minority Oversampling Technique (SMOTE) is utilized. Furthermore,
a pre-trained convolutional neural network has been applied to the DEMNET
dementia network to extract key features from AD images. The proposed model
achieved an impressive accuracy of 98.67%.

摘要：全球公認最常見的失智症成因是
阿茲海默症（AD）。這種疾病的嚴重程度從輕度到重度，並會干擾人們的日常作息。早期診斷在患者照護和臨床試驗中扮演至關重要的角色。卷積神經網路（CNN）用於建立一個架構，以從 MRI 掃描中辨識特定的疾病特徵。失智症的分類涉及病歷回顧、神經心理測驗和磁振造影（MRI）等方法。然而，從 Kaggle 取得的影像資料集面臨類別不平衡的重大問題，這需要每個類別的樣本數量相等才能解決。在本文中，為了解決這種不平衡，使用了合成少數過採樣技術（SMOTE）。此外，已將預先訓練好的卷積神經網路應用於 DEMNET 失智症網路，以從 AD 影像中萃取關鍵特徵。所提出的模型達到了令人印象深刻的 98.67% 準確率。

##### **State-of-the-Art Periorbital Distance Prediction and Disease Classification Using Periorbital Features**
2409.18769v3 by George R. Nahass, Ghasem Yazdanpanah, Madison Cheung, Alex Palacios, Jeffery Peterson, Kevin Heinze, Sasha Hubschman, Chad A. Purnell, Pete Setabutr, Ann Q. Tran, Darvin Yi

Periorbital distances and features around the eyes and lids hold valuable
information for disease quantification and monitoring of surgical and medical
intervention. These distances are commonly measured manually, a process that is
both subjective and highly time-consuming. Here, we set out to developed three
deep-learning methods for segmentation and periorbital distance prediction, and
also evaluate the utility of periorbital distances for disease classification.
The MAE of our deep learning predicted distances was less than or very close to
the error observed between trained human annotators. We compared our models to
the current state-of-the-art (SOTA) method for periorbital distance prediction
and found that our methods outperformed SOTA on all of our datasets on all but
one periorbital measurement. We also show that robust segmentation can be
achieved on diseased eyes using models trained on open-source, healthy eyes,
and that periorbital distances have can be used as high-quality features in
downstream classification models. Leveraging segmentation networks as
intermediary steps in classification has broad implications for increasing the
generalizability of classification models in ophthalmic plastic and
craniofacial surgery by avoiding the out-of-distribution problem observed in
traditional convolutional neural networks.

摘要：眼周及眼瞼周圍的眶周距離和特徵對於疾病量化及手術和醫療介入的監測具有寶貴的資訊。這些距離通常透過手動測量，這是一個主觀且非常耗時的過程。在此，我們著手開發三種深度學習方法，用於分割和眶周距離預測，並評估眶周距離在疾病分類中的效用。我們的深度學習預測距離的 MAE 低於或非常接近訓練過的人類註解者之間觀察到的誤差。我們將我們的模型與眶周距離預測的現有技術 (SOTA) 方法進行比較，發現我們的模型在所有資料集中的所有眶周測量中都優於 SOTA，只有一個例外。我們還表明，使用在開放原始碼健康眼睛上訓練的模型，可以在患病的眼睛上實現穩健的分割，並且眶周距離可用作下游分類模型中的高品質特徵。利用分割網路作為分類中的中間步驟，對於透過避免傳統卷積神經網路中觀察到的分佈外問題，來增加眼科整形和顱顏面手術中分類模型的泛化性，具有廣泛的影響。

##### **Multi-modal Medical Image Fusion For Non-Small Cell Lung Cancer Classification**
2409.18715v1 by Salma Hassan, Hamad Al Hammadi, Ibrahim Mohammed, Muhammad Haris Khan

The early detection and nuanced subtype classification of non-small cell lung
cancer (NSCLC), a predominant cause of cancer mortality worldwide, is a
critical and complex issue. In this paper, we introduce an innovative
integration of multi-modal data, synthesizing fused medical imaging (CT and PET
scans) with clinical health records and genomic data. This unique fusion
methodology leverages advanced machine learning models, notably MedClip and
BEiT, for sophisticated image feature extraction, setting a new standard in
computational oncology. Our research surpasses existing approaches, as
evidenced by a substantial enhancement in NSCLC detection and classification
precision. The results showcase notable improvements across key performance
metrics, including accuracy, precision, recall, and F1-score. Specifically, our
leading multi-modal classifier model records an impressive accuracy of 94.04%.
We believe that our approach has the potential to transform NSCLC diagnostics,
facilitating earlier detection and more effective treatment planning and,
ultimately, leading to superior patient outcomes in lung cancer care.

摘要：早期檢測和細緻的非小細胞肺癌 (NSCLC) 亞型分類，是全球癌症死亡率的主要原因，是一個關鍵且複雜的問題。在本文中，我們介紹了一個創新的多模式數據整合，將融合的醫學影像 (CT 和 PET 掃描) 與臨床健康記錄和基因組數據合成。這種獨特的融合方法利用了先進的機器學習模型，特別是 MedClip 和 BEiT，進行複雜的影像特徵提取，為計算腫瘤學設定了新的標準。我們的研究超越了現有方法，這從 NSCLC 檢測和分類精度的顯著提高中得到證明。結果展示了在關鍵效能指標（包括準確度、精確度、召回率和 F1 分數）上的顯著改進。具體來說，我們領先的多模式分類器模型記錄了令人印象深刻的 94.04% 準確度。我們相信我們的做法有潛力轉變 NSCLC 診斷，促進早期檢測和更有效的治療計畫，並最終改善肺癌照護中的患者預後。

