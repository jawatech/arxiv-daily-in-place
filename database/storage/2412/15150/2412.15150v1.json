{"2412.15150": {"publish_time": "2024-12-19", "title": "Leveraging Color Channel Independence for Improved Unsupervised Object Detection", "paper_summary": "Object-centric architectures can learn to extract distinct object\nrepresentations from visual scenes, enabling downstream applications on the\nobject level. Similarly to autoencoder-based image models, object-centric\napproaches have been trained on the unsupervised reconstruction loss of images\nencoded by RGB color spaces. In our work, we challenge the common assumption\nthat RGB images are the optimal color space for unsupervised learning in\ncomputer vision. We discuss conceptually and empirically that other color\nspaces, such as HSV, bear essential characteristics for object-centric\nrepresentation learning, like robustness to lighting conditions. We further\nshow that models improve when requiring them to predict additional color\nchannels. Specifically, we propose to transform the predicted targets to the\nRGB-S space, which extends RGB with HSV's saturation component and leads to\nmarkedly better reconstruction and disentanglement for five common evaluation\ndatasets. The use of composite color spaces can be implemented with basically\nno computational overhead, is agnostic of the models' architecture, and is\nuniversally applicable across a wide range of visual computing tasks and\ntraining types. The findings of our approach encourage additional\ninvestigations in computer vision tasks beyond object-centric learning.", "paper_summary_zh": "\u7269\u4ef6\u4e2d\u5fc3\u67b6\u6784\u53ef\u4ee5\u5b66\u4e60\u4ece\u89c6\u89c9\u573a\u666f\u4e2d\u8403\u53d6\u51fa\u4e0d\u540c\u7684\u7269\u4ef6\u8868\u5f81\uff0c\u8ba9\u4e0b\u6e38\u5e94\u7528\u80fd\u591f\u5728\u7269\u4ef6\u5c42\u7ea7\u4e0a\u8fd0\u884c\u3002\u7c7b\u4f3c\u4e8e\u57fa\u4e8e\u81ea\u52a8\u7f16\u7801\u5668\u7684\u56fe\u50cf\u6a21\u578b\uff0c\u7269\u4ef6\u4e2d\u5fc3\u65b9\u6cd5\u5df2\u7ecf\u8fc7\u8bad\u7ec3\uff0c\u53ef\u4ee5\u65e0\u76d1\u7763\u5730\u91cd\u5efa\u7531 RGB \u8272\u5f69\u7a7a\u95f4\u7f16\u7801\u7684\u56fe\u50cf\u7684\u635f\u5931\u3002\u5728\u6211\u4eec\u7684\u5de5\u4f5c\u4e2d\uff0c\u6211\u4eec\u6311\u6218\u4e86 RGB \u56fe\u50cf\u662f\u8ba1\u7b97\u673a\u89c6\u89c9\u4e2d\u65e0\u76d1\u7763\u5b66\u4e60\u7684\u6700\u4f73\u8272\u5f69\u7a7a\u95f4\u7684\u666e\u904d\u5047\u8bbe\u3002\u6211\u4eec\u4ece\u6982\u5ff5\u4e0a\u548c\u7ecf\u9a8c\u4e0a\u8ba8\u8bba\u4e86\u5176\u4ed6\u8272\u5f69\u7a7a\u95f4\uff08\u4f8b\u5982 HSV\uff09\u5177\u6709\u7269\u4ef6\u4e2d\u5fc3\u8868\u5f81\u5b66\u4e60\u7684\u57fa\u672c\u7279\u6027\uff0c\u4f8b\u5982\u5bf9\u5149\u7167\u6761\u4ef6\u7684\u9c81\u68d2\u6027\u3002\u6211\u4eec\u8fdb\u4e00\u6b65\u8868\u660e\uff0c\u5f53\u8981\u6c42\u6a21\u578b\u9884\u6d4b\u989d\u5916\u7684\u8272\u5f69\u901a\u9053\u65f6\uff0c\u6a21\u578b\u4f1a\u5f97\u5230\u6539\u5584\u3002\u5177\u4f53\u6765\u8bf4\uff0c\u6211\u4eec\u5efa\u8bae\u5c06\u9884\u6d4b\u76ee\u6807\u8f6c\u6362\u4e3a RGB-S \u7a7a\u95f4\uff0c\u8be5\u7a7a\u95f4\u4f7f\u7528 HSV \u7684\u9971\u548c\u5ea6\u5206\u91cf\u6269\u5c55\u4e86 RGB\uff0c\u5e76\u5bfc\u81f4\u4e94\u4e2a\u5e38\u89c1\u8bc4\u4f30\u6570\u636e\u96c6\u7684\u91cd\u5efa\u548c\u89e3\u7f20\u660e\u663e\u66f4\u597d\u3002\u590d\u5408\u8272\u5f69\u7a7a\u95f4\u7684\u4f7f\u7528\u57fa\u672c\u4e0a\u53ef\u4ee5\u4e0d\u589e\u52a0\u8ba1\u7b97\u5f00\u9500\u6765\u5b9e\u73b0\uff0c\u4e0e\u6a21\u578b\u7684\u67b6\u6784\u65e0\u5173\uff0c\u5e76\u4e14\u666e\u904d\u9002\u7528\u4e8e\u5e7f\u6cdb\u7684\u89c6\u89c9\u8ba1\u7b97\u4efb\u52a1\u548c\u8bad\u7ec3\u7c7b\u578b\u3002\u6211\u4eec\u65b9\u6cd5\u7684\u53d1\u73b0\u9f13\u52b1\u5728\u8d85\u8d8a\u7269\u4ef6\u4e2d\u5fc3\u5b66\u4e60\u7684\u8ba1\u7b97\u673a\u89c6\u89c9\u4efb\u52a1\u4e2d\u8fdb\u884c\u989d\u5916\u7684\u8c03\u67e5\u3002", "author": "Bastian J\u00e4ckl et.al.", "authors": "Bastian J\u00e4ckl, Yannick Metz, Udo Schlegel, Daniel A. Keim, Maximilian T. Fischer", "id": "2412.15150v1", "paper_url": "http://arxiv.org/abs/2412.15150v1", "repo": "null"}}