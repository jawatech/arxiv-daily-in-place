{"2409.18653": {"publish_time": "2024-09-27", "title": "When SAM2 Meets Video Camouflaged Object Segmentation: A Comprehensive Evaluation and Adaptation", "paper_summary": "This study investigates the application and performance of the Segment\nAnything Model 2 (SAM2) in the challenging task of video camouflaged object\nsegmentation (VCOS). VCOS involves detecting objects that blend seamlessly in\nthe surroundings for videos, due to similar colors and textures, poor light\nconditions, etc. Compared to the objects in normal scenes, camouflaged objects\nare much more difficult to detect. SAM2, a video foundation model, has shown\npotential in various tasks. But its effectiveness in dynamic camouflaged\nscenarios remains under-explored. This study presents a comprehensive study on\nSAM2's ability in VCOS. First, we assess SAM2's performance on camouflaged\nvideo datasets using different models and prompts (click, box, and mask).\nSecond, we explore the integration of SAM2 with existing multimodal large\nlanguage models (MLLMs) and VCOS methods. Third, we specifically adapt SAM2 by\nfine-tuning it on the video camouflaged dataset. Our comprehensive experiments\ndemonstrate that SAM2 has excellent zero-shot ability of detecting camouflaged\nobjects in videos. We also show that this ability could be further improved by\nspecifically adjusting SAM2's parameters for VCOS. The code will be available\nat https://github.com/zhoustan/SAM2-VCOS", "paper_summary_zh": "\u672c\u7814\u7a76\u63a2\u8a0e Segment Anything Model 2 (SAM2) \u5728\u5f71\u7247\u507d\u88dd\u7269\u4ef6\u5206\u5272 (VCOS) \u7684\u8271\u96e3\u4efb\u52d9\u4e2d\u7684\u61c9\u7528\u8207\u6548\u80fd\u3002VCOS \u6d89\u53ca\u5075\u6e2c\u5728\u5f71\u7247\u4e2d\u8207\u5468\u906d\u74b0\u5883\u7121\u7e2b\u878d\u5408\u7684\u7269\u4ef6\uff0c\u539f\u56e0\u5728\u65bc\u76f8\u4f3c\u7684\u8272\u5f69\u8207\u7d0b\u7406\u3001\u4e0d\u826f\u7684\u5149\u7dda\u689d\u4ef6\u7b49\u3002\u8207\u4e00\u822c\u5834\u666f\u4e2d\u7684\u7269\u4ef6\u76f8\u6bd4\uff0c\u507d\u88dd\u7269\u4ef6\u66f4\u96e3\u4ee5\u5075\u6e2c\u3002SAM2 \u662f\u4e00\u500b\u5f71\u7247\u57fa\u790e\u6a21\u578b\uff0c\u5df2\u5728\u5404\u7a2e\u4efb\u52d9\u4e2d\u5c55\u73fe\u6f5b\u529b\u3002\u4f46\u5b83\u5728\u52d5\u614b\u507d\u88dd\u5834\u666f\u4e2d\u7684\u6548\u80fd\u4ecd\u672a\u53d7\u5230\u5145\u5206\u63a2\u8a0e\u3002\u672c\u7814\u7a76\u5c0d SAM2 \u5728 VCOS \u4e2d\u7684\u80fd\u529b\u9032\u884c\u5168\u9762\u7814\u7a76\u3002\u9996\u5148\uff0c\u6211\u5011\u4f7f\u7528\u4e0d\u540c\u7684\u6a21\u578b\u548c\u63d0\u793a (\u9ede\u9078\u3001\u65b9\u6846\u548c\u906e\u7f69) \u8a55\u4f30 SAM2 \u5728\u507d\u88dd\u5f71\u7247\u8cc7\u6599\u96c6\u4e0a\u7684\u6548\u80fd\u3002\u5176\u6b21\uff0c\u6211\u5011\u63a2\u8a0e SAM2 \u8207\u73fe\u6709\u7684\u591a\u6a21\u614b\u5927\u578b\u8a9e\u8a00\u6a21\u578b (MLLM) \u548c VCOS \u65b9\u6cd5\u7684\u6574\u5408\u3002\u7b2c\u4e09\uff0c\u6211\u5011\u900f\u904e\u5728\u5f71\u7247\u507d\u88dd\u8cc7\u6599\u96c6\u4e0a\u5fae\u8abf SAM2\uff0c\u7279\u5225\u8abf\u6574\u5b83\u3002\u6211\u5011\u7684\u5168\u9762\u5be6\u9a57\u8b49\u660e SAM2 \u5177\u6709\u6975\u4f73\u7684\u96f6\u6b21\u5b78\u7fd2\u80fd\u529b\uff0c\u53ef\u4ee5\u5075\u6e2c\u5f71\u7247\u4e2d\u7684\u507d\u88dd\u7269\u4ef6\u3002\u6211\u5011\u4e5f\u986f\u793a\uff0c\u900f\u904e\u7279\u5225\u8abf\u6574 SAM2 \u7684\u53c3\u6578\u4ee5\u7b26\u5408 VCOS\uff0c\u53ef\u4ee5\u9032\u4e00\u6b65\u63d0\u5347\u6b64\u80fd\u529b\u3002\u7a0b\u5f0f\u78bc\u5c07\u5728 https://github.com/zhoustan/SAM2-VCOS \u4e2d\u63d0\u4f9b", "author": "Yuli Zhou et.al.", "authors": "Yuli Zhou, Guolei Sun, Yawei Li, Luca Benini, Ender Konukoglu", "id": "2409.18653v1", "paper_url": "http://arxiv.org/abs/2409.18653v1", "repo": "https://github.com/zhoustan/sam2-vcos"}}