{"2501.07408": {"publish_time": "2025-01-13", "title": "Initial Findings on Sensor based Open Vocabulary Activity Recognition via Text Embedding Inversion", "paper_summary": "Conventional human activity recognition (HAR) relies on classifiers trained\nto predict discrete activity classes, inherently limiting recognition to\nactivities explicitly present in the training set. Such classifiers would\ninvariably fail, putting zero likelihood, when encountering unseen activities.\nWe propose Open Vocabulary HAR (OV-HAR), a framework that overcomes this\nlimitation by first converting each activity into natural language and breaking\nit into a sequence of elementary motions. This descriptive text is then encoded\ninto a fixed-size embedding. The model is trained to regress this embedding,\nwhich is subsequently decoded back into natural language using a pre-trained\nembedding inversion model. Unlike other works that rely on auto-regressive\nlarge language models (LLMs) at their core, OV-HAR achieves open vocabulary\nrecognition without the computational overhead of such models. The generated\ntext can be transformed into a single activity class using LLM prompt\nengineering. We have evaluated our approach on different modalities, including\nvision (pose), IMU, and pressure sensors, demonstrating robust generalization\nacross unseen activities and modalities, offering a fundamentally different\nparadigm from contemporary classifiers.", "paper_summary_zh": "\u50b3\u7d71\u7684\u4eba\u985e\u6d3b\u52d5\u8b58\u5225 (HAR) \u4f9d\u8cf4\u65bc\u8a13\u7df4\u597d\u7684\u5206\u985e\u5668\u4f86\u9810\u6e2c\u96e2\u6563\u7684\u6d3b\u52d5\u985e\u5225\uff0c\u672c\u8cea\u4e0a\u5c07\u8b58\u5225\u9650\u5236\u5728\u8a13\u7df4\u96c6\u4e2d\u660e\u78ba\u5448\u73fe\u7684\u6d3b\u52d5\u3002\u6b64\u985e\u5206\u985e\u5668\u5728\u9047\u5230\u672a\u898b\u904e\u7684\u6d3b\u52d5\u6642\uff0c\u6703\u4e00\u5f8b\u5931\u6557\uff0c\u4e26\u7d66\u51fa\u96f6\u6a5f\u7387\u3002\u6211\u5011\u63d0\u51fa\u958b\u653e\u8a5e\u5f59 HAR (OV-HAR)\uff0c\u4e00\u500b\u900f\u904e\u5148\u5c07\u6bcf\u500b\u6d3b\u52d5\u8f49\u63db\u70ba\u81ea\u7136\u8a9e\u8a00\u4e26\u5c07\u5176\u5206\u89e3\u6210\u4e00\u7cfb\u5217\u57fa\u672c\u52d5\u4f5c\u4f86\u514b\u670d\u6b64\u9650\u5236\u7684\u67b6\u69cb\u3002\u63a5\u8457\u5c07\u6b64\u63cf\u8ff0\u6587\u5b57\u7de8\u78bc\u6210\u56fa\u5b9a\u5927\u5c0f\u7684\u5167\u5d4c\u3002\u6b64\u6a21\u578b\u7d93\u904e\u8a13\u7df4\u4ee5\u56de\u6b78\u6b64\u5167\u5d4c\uff0c\u96a8\u5f8c\u518d\u4f7f\u7528\u9810\u5148\u8a13\u7df4\u597d\u7684\u5167\u5d4c\u53cd\u8f49\u6a21\u578b\u5c07\u5176\u89e3\u78bc\u56de\u81ea\u7136\u8a9e\u8a00\u3002\u8207\u5176\u4ed6\u4f9d\u8cf4\u65bc\u6838\u5fc3\u81ea\u8ff4\u6b78\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u7684\u4f5c\u54c1\u4e0d\u540c\uff0cOV-HAR \u5728\u6c92\u6709\u6b64\u985e\u6a21\u578b\u7684\u904b\u7b97\u8ca0\u64d4\u4e0b\uff0c\u5c31\u80fd\u9054\u6210\u958b\u653e\u8a5e\u5f59\u8b58\u5225\u3002\u7522\u751f\u7684\u6587\u5b57\u53ef\u4ee5\u4f7f\u7528 LLM \u63d0\u793a\u5de5\u7a0b\u8f49\u63db\u6210\u55ae\u4e00\u6d3b\u52d5\u985e\u5225\u3002\u6211\u5011\u5df2\u5728\u4e0d\u540c\u7684\u6a21\u5f0f\u4e0a\u8a55\u4f30\u6211\u5011\u7684\u505a\u6cd5\uff0c\u5305\u62ec\u8996\u89ba (\u59ff\u52e2)\u3001IMU \u548c\u58d3\u529b\u611f\u6e2c\u5668\uff0c\u5c55\u793a\u4e86\u5728\u672a\u898b\u904e\u7684\u6d3b\u52d5\u548c\u6a21\u5f0f\u4e2d\u7a69\u5065\u7684\u6cdb\u5316\uff0c\u63d0\u4f9b\u4e86\u4e00\u500b\u8207\u7576\u4ee3\u5206\u985e\u5668\u622a\u7136\u4e0d\u540c\u7684\u7bc4\u4f8b\u3002", "author": "Lala Shakti Swarup Ray et.al.", "authors": "Lala Shakti Swarup Ray, Bo Zhou, Sungho Suh, Paul Lukowicz", "id": "2501.07408v1", "paper_url": "http://arxiv.org/abs/2501.07408v1", "repo": "null"}}