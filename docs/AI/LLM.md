
### LLM
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-07-26**|**SOAP-RL: Sequential Option Advantage Propagation for Reinforcement Learning in POMDP Environments**|Shu Ishida et.al.|[2407.18913v1](http://arxiv.org/abs/2407.18913v1)|null|
|**2024-07-26**|**Wolf: Captioning Everything with a World Summarization Framework**|Boyi Li et.al.|[2407.18908v1](http://arxiv.org/abs/2407.18908v1)|null|
|**2024-07-26**|**AppWorld: A Controllable World of Apps and People for Benchmarking Interactive Coding Agents**|Harsh Trivedi et.al.|[2407.18901v1](http://arxiv.org/abs/2407.18901v1)|[link](https://github.com/stonybrooknlp/appworld)|
|**2024-07-26**|**Learn from the Learnt: Source-Free Active Domain Adaptation via Contrastive Sampling and Visual Persistence**|Mengyao Lyu et.al.|[2407.18899v1](http://arxiv.org/abs/2407.18899v1)|null|
|**2024-07-26**|**Embedding And Clustering Your Data Can Improve Contrastive Pretraining**|Luke Merrick et.al.|[2407.18887v1](http://arxiv.org/abs/2407.18887v1)|null|
|**2024-07-26**|**Generative Adversarial Networks for Imputing Sparse Learning Performance**|Liang Zhang et.al.|[2407.18875v1](http://arxiv.org/abs/2407.18875v1)|null|
|**2024-07-26**|**Unifying Visual and Semantic Feature Spaces with Diffusion Models for Enhanced Cross-Modal Alignment**|Yuze Zheng et.al.|[2407.18854v1](http://arxiv.org/abs/2407.18854v1)|null|
|**2024-07-26**|**Enhancing material property prediction with ensemble deep graph convolutional networks**|Chowdhury Mohammad Abid Rahman et.al.|[2407.18847v1](http://arxiv.org/abs/2407.18847v1)|null|
|**2024-07-26**|**Human-artificial intelligence teaming for scientific information extraction from data-driven additive manufacturing research using large language models**|Mutahar Safdar et.al.|[2407.18827v1](http://arxiv.org/abs/2407.18827v1)|null|
|**2024-07-26**|**Learning Chaotic Systems and Long-Term Predictions with Neural Jump ODEs**|Florian Krach et.al.|[2407.18808v1](http://arxiv.org/abs/2407.18808v1)|null|
|**2024-07-26**|**The power of Prompts: Evaluating and Mitigating Gender Bias in MT with LLMs**|Aleix Sant et.al.|[2407.18786v1](http://arxiv.org/abs/2407.18786v1)|null|
|**2024-07-26**|**Understanding XAI Through the Philosopher's Lens: A Historical Perspective**|Martina Mattioli et.al.|[2407.18782v1](http://arxiv.org/abs/2407.18782v1)|null|
|**2024-07-26**|**TAGIFY: LLM-powered Tagging Interface for Improved Data Findability on OGD portals**|Kevin Kliimask et.al.|[2407.18764v1](http://arxiv.org/abs/2407.18764v1)|null|
|**2024-07-26**|**Score matching through the roof: linear, nonlinear, and latent variables causal discovery**|Francesco Montagna et.al.|[2407.18755v1](http://arxiv.org/abs/2407.18755v1)|null|
|**2024-07-26**|**Knowledge Graph Structure as Prompt: Improving Small Language Models Capabilities for Knowledge-based Causal Discovery**|Yuni Susanti et.al.|[2407.18752v1](http://arxiv.org/abs/2407.18752v1)|[link](https://github.com/littleflow3r/kg-structure-as-prompt)|
|**2024-07-26**|**Multi-Robot System Architecture design in SysML and BPMN**|Ahmed R. Sadik et.al.|[2407.18749v1](http://arxiv.org/abs/2407.18749v1)|null|
|**2024-07-26**|**Towards Effective and Efficient Continual Pre-training of Large Language Models**|Jie Chen et.al.|[2407.18743v1](http://arxiv.org/abs/2407.18743v1)|null|
|**2024-07-26**|**Towards Generalized Offensive Language Identification**|Alphaeus Dmonte et.al.|[2407.18738v1](http://arxiv.org/abs/2407.18738v1)|null|
|**2024-07-26**|**Neurosymbolic AI for Enhancing Instructability in Generative AI**|Amit Sheth et.al.|[2407.18722v1](http://arxiv.org/abs/2407.18722v1)|null|
|**2024-07-26**|**ChatSchema: A pipeline of extracting structured information with Large Multimodal Models based on schema**|Fei Wang et.al.|[2407.18716v1](http://arxiv.org/abs/2407.18716v1)|null|
|**2024-07-26**|**Cluster-norm for Unsupervised Probing of Knowledge**|Walter Laurito et.al.|[2407.18712v1](http://arxiv.org/abs/2407.18712v1)|null|
|**2024-07-26**|**Adaptive Contrastive Search: Uncertainty-Guided Decoding for Open-Ended Text Generation**|Esteban Garces Arias et.al.|[2407.18698v1](http://arxiv.org/abs/2407.18698v1)|null|
|**2024-07-26**|**Graph Neural Networks for Virtual Sensing in Complex Systems: Addressing Heterogeneous Temporal Dynamics**|Mengjie Zhao et.al.|[2407.18691v1](http://arxiv.org/abs/2407.18691v1)|null|
|**2024-07-26**|**Collaborative Evolving Strategy for Automatic Data-Centric Development**|Xu Yang et.al.|[2407.18690v1](http://arxiv.org/abs/2407.18690v1)|null|
|**2024-07-26**|**The BIAS Detection Framework: Bias Detection in Word Embeddings and Language Models for European Languages**|Alexandre Puttick et.al.|[2407.18689v1](http://arxiv.org/abs/2407.18689v1)|null|
|**2024-07-26**|**Every Part Matters: Integrity Verification of Scientific Figures Based on Multimodal Large Language Models**|Xiang Shi et.al.|[2407.18626v1](http://arxiv.org/abs/2407.18626v1)|null|
|**2024-07-26**|**Topology Optimization of Random Memristors for Input-Aware Dynamic SNN**|Bo Wang et.al.|[2407.18625v1](http://arxiv.org/abs/2407.18625v1)|null|
|**2024-07-26**|**Using GPT-4 to guide causal machine learning**|Anthony C. Constantinou et.al.|[2407.18607v1](http://arxiv.org/abs/2407.18607v1)|null|
|**2024-07-26**|**Climbing the Complexity Ladder with Expressive Attention**|Claudius Gros et.al.|[2407.18601v1](http://arxiv.org/abs/2407.18601v1)|null|
|**2024-07-26**|**Reinforcement Learning for Sustainable Energy: A Survey**|Koen Ponse et.al.|[2407.18597v1](http://arxiv.org/abs/2407.18597v1)|null|
|**2024-07-26**|**Dynamic Language Group-Based MoE: Enhancing Efficiency and Flexibility for Code-Switching Speech Recognition**|Hukai Huang et.al.|[2407.18581v1](http://arxiv.org/abs/2407.18581v1)|null|
|**2024-07-26**|**Speech Bandwidth Expansion Via High Fidelity Generative Adversarial Networks**|Mahmoud Salhab et.al.|[2407.18571v1](http://arxiv.org/abs/2407.18571v1)|null|
|**2024-07-26**|**PP-TIL: Personalized Planning for Autonomous Driving with Instance-based Transfer Imitation Learning**|Fangze Lin et.al.|[2407.18569v1](http://arxiv.org/abs/2407.18569v1)|null|
|**2024-07-26**|**Learning Robust Named Entity Recognizers From Noisy Data With Retrieval Augmentation**|Chaoyi Ai et.al.|[2407.18562v1](http://arxiv.org/abs/2407.18562v1)|null|
|**2024-07-26**|**Look Globally and Reason: Two-stage Path Reasoning over Sparse Knowledge Graphs**|Saiping Guan et.al.|[2407.18556v1](http://arxiv.org/abs/2407.18556v1)|null|
|**2024-07-26**|**How To Segment in 3D Using 2D Models: Automated 3D Segmentation of Prostate Cancer Metastatic Lesions on PET Volumes Using Multi-Angle Maximum Intensity Projections and Diffusion Models**|Amirhosein Toosi et.al.|[2407.18555v1](http://arxiv.org/abs/2407.18555v1)|null|
|**2024-07-26**|**Multimodal Emotion Recognition using Audio-Video Transformer Fusion with Cross Attention**|Joe Dhanith P R et.al.|[2407.18552v1](http://arxiv.org/abs/2407.18552v1)|null|
|**2024-07-26**|**ReALFRED: An Embodied Instruction Following Benchmark in Photo-Realistic Environments**|Taewoong Kim et.al.|[2407.18550v1](http://arxiv.org/abs/2407.18550v1)|[link](https://github.com/snumprlab/realfred)|
|**2024-07-26**|**Towards Improving NAM-to-Speech Synthesis Intelligibility using Self-Supervised Speech Models**|Neil Shah et.al.|[2407.18541v1](http://arxiv.org/abs/2407.18541v1)|null|
|**2024-07-26**|**A Universal Prompting Strategy for Extracting Process Model Information from Natural Language Text using Large Language Models**|Julian Neuberger et.al.|[2407.18540v1](http://arxiv.org/abs/2407.18540v1)|[link](https://github.com/julianneuberger/llm-process-generation)|
|**2024-07-26**|**Towards a Multidimensional Evaluation Framework for Empathetic Conversational Systems**|Aravind Sesagiri Raamkumar et.al.|[2407.18538v1](http://arxiv.org/abs/2407.18538v1)|null|
|**2024-07-26**|**Outer Approximation and Super-modular Cuts for Constrained Assortment Optimization under Mixed-Logit Model**|Hoang Giang Pham et.al.|[2407.18532v1](http://arxiv.org/abs/2407.18532v1)|null|
|**2024-07-26**|**Is larger always better? Evaluating and prompting large language models for non-generative medical tasks**|Yinghao Zhu et.al.|[2407.18525v1](http://arxiv.org/abs/2407.18525v1)|[link](https://github.com/yhzhu99/ehr-llm-benchmark)|
|**2024-07-26**|**She Works, He Works: A Curious Exploration of Gender Bias in AI-Generated Imagery**|Amalia Foka et.al.|[2407.18524v1](http://arxiv.org/abs/2407.18524v1)|null|
|**2024-07-26**|**Patched MOA: optimizing inference for diverse software development tasks**|Asankhaya Sharma et.al.|[2407.18521v1](http://arxiv.org/abs/2407.18521v1)|null|
|**2024-07-26**|**SLIM: Style-Linguistics Mismatch Model for Generalized Audio Deepfake Detection**|Yi Zhu et.al.|[2407.18517v1](http://arxiv.org/abs/2407.18517v1)|null|
|**2024-07-26**|**The formation of perceptual space in early phonetic acquisition: a cross-linguistic modeling approach**|Frank Lihui Tan et.al.|[2407.18501v1](http://arxiv.org/abs/2407.18501v1)|null|
|**2024-07-26**|**Non-Overlapping Placement of Macro Cells based on Reinforcement Learning in Chip Design**|Tao Yu et.al.|[2407.18499v1](http://arxiv.org/abs/2407.18499v1)|null|
|**2024-07-26**|**A Reliable Common-Sense Reasoning Socialbot Built Using LLMs and Goal-Directed ASP**|Yankai Zeng et.al.|[2407.18498v1](http://arxiv.org/abs/2407.18498v1)|null|
|**2024-07-26**|**Towards More Accurate Prediction of Human Empathy and Emotion in Text and Multi-turn Conversations by Combining Advanced NLP, Transformers-based Networks, and Linguistic Methodologies**|Manisha Singh et.al.|[2407.18496v1](http://arxiv.org/abs/2407.18496v1)|null|
|**2024-07-26**|**A Role-specific Guided Large Language Model for Ophthalmic Consultation Based on Stylistic Differentiation**|Laiyi Fu et.al.|[2407.18483v2](http://arxiv.org/abs/2407.18483v2)|[link](https://github.com/sperfu/eyedoc)|
|**2024-07-26**|**Multi-turn Response Selection with Commonsense-enhanced Language Models**|Yuandong Wang et.al.|[2407.18479v1](http://arxiv.org/abs/2407.18479v1)|null|
|**2024-07-26**|**Constructing the CORD-19 Vaccine Dataset**|Manisha Singh et.al.|[2407.18471v1](http://arxiv.org/abs/2407.18471v1)|null|
|**2024-07-26**|**Diffusion-Driven Semantic Communication for Generative Models with Bandwidth Constraints**|Lei Guo et.al.|[2407.18468v1](http://arxiv.org/abs/2407.18468v1)|null|
|**2024-07-26**|**Enhancing Dysarthric Speech Recognition for Unseen Speakers via Prototype-Based Adaptation**|Shiyao Wang et.al.|[2407.18461v1](http://arxiv.org/abs/2407.18461v1)|[link](https://github.com/nku-hlt/pb-dsr)|
|**2024-07-26**|**Fairness Definitions in Language Models Explained**|Thang Viet Doan et.al.|[2407.18454v1](http://arxiv.org/abs/2407.18454v1)|[link](https://github.com/lavinwong/fairness-in-large-language-models)|
|**2024-07-26**|**Capturing the security expert knowledge in feature selection for web application attack detection**|Amanda Riverol et.al.|[2407.18445v1](http://arxiv.org/abs/2407.18445v1)|null|
|**2024-07-26**|**Guidance-Based Prompt Data Augmentation in Specialized Domains for Named Entity Recognition**|Hyeonseok Kang et.al.|[2407.18442v1](http://arxiv.org/abs/2407.18442v1)|null|
|**2024-07-26**|**Mixed Non-linear Quantization for Vision Transformers**|Gihwan Kim et.al.|[2407.18437v1](http://arxiv.org/abs/2407.18437v1)|null|
|**2024-07-25**|**Weighted Risk Invariance: Domain Generalization under Invariant Feature Shift**|Gina Wong et.al.|[2407.18428v1](http://arxiv.org/abs/2407.18428v1)|[link](https://github.com/ginawong/weighted_risk_invariance)|
|**2024-07-25**|**HDL-GPT: High-Quality HDL is All You Need**|Bhuvnesh Kumar et.al.|[2407.18423v1](http://arxiv.org/abs/2407.18423v1)|null|
|**2024-07-25**|**Self-Directed Synthetic Dialogues and Revisions Technical Report**|Nathan Lambert et.al.|[2407.18421v1](http://arxiv.org/abs/2407.18421v1)|null|
|**2024-07-25**|**The Art of Refusal: A Survey of Abstention in Large Language Models**|Bingbing Wen et.al.|[2407.18418v1](http://arxiv.org/abs/2407.18418v1)|null|
|**2024-07-25**|**PersonaGym: Evaluating Persona Agents and LLMs**|Vinay Samuel et.al.|[2407.18416v2](http://arxiv.org/abs/2407.18416v2)|null|
|**2024-07-25**|**Adversarial Robust Decision Transformer: Enhancing Robustness of RvS via Minimax Returns-to-go**|Xiaohang Tang et.al.|[2407.18414v1](http://arxiv.org/abs/2407.18414v1)|null|
|**2024-07-25**|**Simulation of Neural Responses to Classical Music Using Organoid Intelligence Methods**|Daniel Szelogowski et.al.|[2407.18413v1](http://arxiv.org/abs/2407.18413v1)|[link](https://github.com/danielathome19/Pianoid-EEG-NN)|
|**2024-07-25**|**SCALE: Self-regulated Clustered federAted LEarning in a Homogeneous Environment**|Sai Puppala et.al.|[2407.18387v1](http://arxiv.org/abs/2407.18387v1)|null|
|**2024-07-25**|**Exploring Bengali Religious Dialect Biases in Large Language Models with Evaluation Perspectives**|Azmine Toushik Wasi et.al.|[2407.18376v1](http://arxiv.org/abs/2407.18376v1)|null|
|**2024-07-25**|**Trust or Escalate: LLM Judges with Provable Guarantees for Human Agreement**|Jaehun Jung et.al.|[2407.18370v1](http://arxiv.org/abs/2407.18370v1)|null|
|**2024-07-25**|**Robust Claim Verification Through Fact Detection**|Nazanin Jafari et.al.|[2407.18367v1](http://arxiv.org/abs/2407.18367v1)|null|
|**2024-07-25**|**FADAS: Towards Federated Adaptive Asynchronous Optimization**|Yujia Wang et.al.|[2407.18365v1](http://arxiv.org/abs/2407.18365v1)|[link](https://github.com/yujiaw98/fadas)|
|**2024-07-25**|**Generative AI like ChatGPT in Blockchain Federated Learning: use cases, opportunities and future**|Sai Puppala et.al.|[2407.18358v1](http://arxiv.org/abs/2407.18358v1)|null|
|**2024-07-25**|**Introducing δ-XAI: a novel sensitivity-based method for local AI explanations**|Alessandro De Carlo et.al.|[2407.18343v1](http://arxiv.org/abs/2407.18343v1)|null|
|**2024-07-25**|**Combining Cognitive and Generative AI for Self-explanation in Interactive AI Agents**|Shalini Sushri et.al.|[2407.18335v1](http://arxiv.org/abs/2407.18335v1)|null|
|**2024-07-25**|**Affectively Framework: Towards Human-like Affect-Based Agents**|Matthew Barthet et.al.|[2407.18316v1](http://arxiv.org/abs/2407.18316v1)|null|
|**2024-07-25**|**Revolutionizing Undergraduate Learning: CourseGPT and Its Generative AI Advancements**|Ahmad M. Nazar et.al.|[2407.18310v1](http://arxiv.org/abs/2407.18310v1)|null|
|**2024-07-25**|**Self-Training with Direct Preference Optimization Improves Chain-of-Thought Reasoning**|Tianduo Wang et.al.|[2407.18248v1](http://arxiv.org/abs/2407.18248v1)|[link](https://github.com/tianduowang/dpo-st)|
|**2024-07-25**|**LoRA-Pro: Are Low-Rank Adapters Properly Optimized?**|Zhengbo Wang et.al.|[2407.18242v1](http://arxiv.org/abs/2407.18242v1)|[link](https://github.com/mrflogs/LoRA-Pro)|
|**2024-07-25**|**Recursive Introspection: Teaching Language Model Agents How to Self-Improve**|Yuxiao Qu et.al.|[2407.18219v2](http://arxiv.org/abs/2407.18219v2)|null|
|**2024-07-25**|**Exploring Scaling Trends in LLM Robustness**|Nikolaus Howe et.al.|[2407.18213v2](http://arxiv.org/abs/2407.18213v2)|null|
|**2024-07-25**|**Differentiable Quantum Architecture Search in Asynchronous Quantum Reinforcement Learning**|Samuel Yen-Chi Chen et.al.|[2407.18202v1](http://arxiv.org/abs/2407.18202v1)|null|
|**2024-07-25**|**Gene Regulatory Network Inference from Pre-trained Single-Cell Transcriptomics Transformer with Joint Graph Learning**|Sindhura Kommu et.al.|[2407.18181v1](http://arxiv.org/abs/2407.18181v1)|null|
|**2024-07-25**|**Quasar-ViT: Hardware-Oriented Quantization-Aware Architecture Search for Vision Transformers**|Zhengang Li et.al.|[2407.18175v1](http://arxiv.org/abs/2407.18175v1)|null|
|**2024-07-25**|**The FIGNEWS Shared Task on News Media Narratives**|Wajdi Zaghouani et.al.|[2407.18147v1](http://arxiv.org/abs/2407.18147v1)|null|
|**2024-07-25**|**Taxonomy-Aware Continual Semantic Segmentation in Hyperbolic Spaces for Open-World Perception**|Julia Hindel et.al.|[2407.18145v1](http://arxiv.org/abs/2407.18145v1)|null|
|**2024-07-25**|**Dallah: A Dialect-Aware Multimodal Large Language Model for Arabic**|Fakhraddin Alwajih et.al.|[2407.18129v2](http://arxiv.org/abs/2407.18129v2)|null|
|**2024-07-25**|**Self-supervised pre-training with diffusion model for few-shot landmark detection in x-ray images**|Roberto Di Via et.al.|[2407.18125v1](http://arxiv.org/abs/2407.18125v1)|null|
|**2024-07-25**|**Tracking linguistic information in transformer-based sentence embeddings through targeted sparsification**|Vivi Nastase et.al.|[2407.18119v1](http://arxiv.org/abs/2407.18119v1)|[link](https://github.com/clcl-geneva/blm-snfdisentangling)|
|**2024-07-25**|**Multi-Resolution Histopathology Patch Graphs for Ovarian Cancer Subtyping**|Jack Breen et.al.|[2407.18105v1](http://arxiv.org/abs/2407.18105v1)|[link](https://github.com/scjjb/MultiscalePathGraph)|
|**2024-07-25**|**Privacy Threats and Countermeasures in Federated Learning for Internet of Things: A Systematic Review**|Adel ElZemity et.al.|[2407.18096v1](http://arxiv.org/abs/2407.18096v1)|null|
|**2024-07-25**|**PEFT-U: Parameter-Efficient Fine-Tuning for User Personalization**|Christopher Clarke et.al.|[2407.18078v1](http://arxiv.org/abs/2407.18078v1)|[link](https://github.com/ChrisIsKing/Parameter-Efficient-Personalization)|
|**2024-07-25**|**Difficulty Estimation and Simplification of French Text Using LLMs**|Henri Jamet et.al.|[2407.18061v1](http://arxiv.org/abs/2407.18061v1)|null|
|**2024-07-25**|**Peak-Controlled Logits Poisoning Attack in Federated Distillation**|Yuhan Tang et.al.|[2407.18039v1](http://arxiv.org/abs/2407.18039v1)|null|
|**2024-07-25**|**RestoreAgent: Autonomous Image Restoration Agent via Multimodal Large Language Models**|Haoyu Chen et.al.|[2407.18035v1](http://arxiv.org/abs/2407.18035v1)|null|
|**2024-07-25**|**AttentionHand: Text-driven Controllable Hand Image Generation for 3D Hand Reconstruction in the Wild**|Junho Park et.al.|[2407.18034v1](http://arxiv.org/abs/2407.18034v1)|null|
|**2024-07-25**|**Learning mental states estimation through self-observation: a developmental synergy between intentions and beliefs representations in a deep-learning model of Theory of Mind**|Francesca Bianco et.al.|[2407.18022v1](http://arxiv.org/abs/2407.18022v1)|null|
|**2024-07-25**|**Quadratic Advantage with Quantum Randomized Smoothing Applied to Time-Series Analysis**|Nicola Franco et.al.|[2407.18021v1](http://arxiv.org/abs/2407.18021v1)|null|
|**2024-07-25**|**GermanPartiesQA: Benchmarking Commercial Large Language Models for Political Bias and Sycophancy**|Jan Batzner et.al.|[2407.18008v1](http://arxiv.org/abs/2407.18008v1)|null|
|**2024-07-25**|**Keep the Cost Down: A Review on Methods to Optimize LLM' s KV-Cache Consumption**|Luohe Shi et.al.|[2407.18003v2](http://arxiv.org/abs/2407.18003v2)|null|
|**2024-07-25**|**On the Effect of Purely Synthetic Training Data for Different Automatic Speech Recognition Architectures**|Nick Rossenbach et.al.|[2407.17997v1](http://arxiv.org/abs/2407.17997v1)|null|

#### Abstracts
##### **SOAP-RL: Sequential Option Advantage Propagation for Reinforcement Learning in POMDP Environments**
2407.18913v1 by Shu Ishida, João F. Henriques

This work compares ways of extending Reinforcement Learning algorithms to
Partially Observed Markov Decision Processes (POMDPs) with options. One view of
options is as temporally extended action, which can be realized as a memory
that allows the agent to retain historical information beyond the policy's
context window. While option assignment could be handled using heuristics and
hand-crafted objectives, learning temporally consistent options and associated
sub-policies without explicit supervision is a challenge. Two algorithms, PPOEM
and SOAP, are proposed and studied in depth to address this problem. PPOEM
applies the forward-backward algorithm (for Hidden Markov Models) to optimize
the expected returns for an option-augmented policy. However, this learning
approach is unstable during on-policy rollouts. It is also unsuited for
learning causal policies without the knowledge of future trajectories, since
option assignments are optimized for offline sequences where the entire episode
is available. As an alternative approach, SOAP evaluates the policy gradient
for an optimal option assignment. It extends the concept of the generalized
advantage estimation (GAE) to propagate option advantages through time, which
is an analytical equivalent to performing temporal back-propagation of option
policy gradients. This option policy is only conditional on the history of the
agent, not future actions. Evaluated against competing baselines, SOAP
exhibited the most robust performance, correctly discovering options for POMDP
corridor environments, as well as on standard benchmarks including Atari and
MuJoCo, outperforming PPOEM, as well as LSTM and Option-Critic baselines. The
open-sourced code is available at https://github.com/shuishida/SoapRL.

摘要：<paragraph>這項工作比較了擴展強 reinforcement learning 演算法到具有選項的 Partially Observed Markov Decision Processes (POMDPs) 的方式。
選項的一種觀點是作為時間延伸的動作，可以實現為一個記憶體，允許代理保留超出政策上下文視窗的歷史資訊。
雖然選項分配可以使用啟發法和手工目標來處理，但學習時間一致的選項和相關的子政策而沒有明確的監督是一個挑戰。
提出了兩種演算法，PPOEM 和 SOAP，並深入研究以解決這個問題。
PPOEM 適用正向後向演算法（對於 Hidden Markov 模型）來最佳化選項增強政策的預期回報。
然而，這種學習方法在基於政策的執行期間是不穩定的。
它也不適合在不知道未來軌跡的情況下學習因果政策，因為選項分配是針對離線序列進行最佳化的，其中整個情節是可用的。
作為一種替代方法，SOAP 評估最佳選項分配的政策梯度。
它擴展了廣義優勢估計 (GAE) 的概念，以隨著時間傳播選項優勢，這與執行選項政策梯度的時間反向傳播的分析等價。
這個選項政策僅取決於代理的歷史，而不是未來的動作。
與競爭基準進行評估，SOAP 表現出最穩健的效能，正確地發現了 POMDP 走廊環境的選項，以及在包括 Atari 和 MuJoCo 在內的標準基準上，優於 PPOEM，以及 LSTM 和 Option-Critic 基準。
開放原始碼可以在 https://github.com/shuishida/SoapRL 取得。</paragraph>

##### **Wolf: Captioning Everything with a World Summarization Framework**
2407.18908v1 by Boyi Li, Ligeng Zhu, Ran Tian, Shuhan Tan, Yuxiao Chen, Yao Lu, Yin Cui, Sushant Veer, Max Ehrlich, Jonah Philion, Xinshuo Weng, Fuzhao Xue, Andrew Tao, Ming-Yu Liu, Sanja Fidler, Boris Ivanovic, Trevor Darrell, Jitendra Malik, Song Han, Marco Pavone

We propose Wolf, a WOrLd summarization Framework for accurate video
captioning. Wolf is an automated captioning framework that adopts a
mixture-of-experts approach, leveraging complementary strengths of Vision
Language Models (VLMs). By utilizing both image and video models, our framework
captures different levels of information and summarizes them efficiently. Our
approach can be applied to enhance video understanding, auto-labeling, and
captioning. To evaluate caption quality, we introduce CapScore, an LLM-based
metric to assess the similarity and quality of generated captions compared to
the ground truth captions. We further build four human-annotated datasets in
three domains: autonomous driving, general scenes, and robotics, to facilitate
comprehensive comparisons. We show that Wolf achieves superior captioning
performance compared to state-of-the-art approaches from the research community
(VILA1.5, CogAgent) and commercial solutions (Gemini-Pro-1.5, GPT-4V). For
instance, in comparison with GPT-4V, Wolf improves CapScore both quality-wise
by 55.6% and similarity-wise by 77.4% on challenging driving videos. Finally,
we establish a benchmark for video captioning and introduce a leaderboard,
aiming to accelerate advancements in video understanding, captioning, and data
alignment. Leaderboard: https://wolfv0.github.io/leaderboard.html.

摘要：<paragraph>我們提出 Wolf，一個用於準確影片字幕的 WOrLd 摘要架構。Wolf 是一個自動化的字幕架構，採用專家混合方法，利用視覺語言模型 (VLM) 的互補優勢。透過同時使用影像和影片模型，我們的架構擷取不同層級的資訊，並有效地將它們摘要出來。我們的做法可以應用於提升影片理解、自動標籤和字幕。為了評估字幕品質，我們引進 CapScore，一個基於 LLM 的指標，用於評估產生的字幕與真實字幕的相似度和品質。我們進一步在三個領域建立了四個由人標註的資料集：自動駕駛、一般場景和機器人技術，以利進行全面的比較。我們展示 Wolf 達到比研究社群的最新方法（VILA1.5、CogAgent）和商業解決方案（Gemini-Pro-1.5、GPT-4V）更優異的字幕表現。例如，與 GPT-4V 相比，Wolf 在具有挑戰性的駕駛影片中，CapScore 的品質提升了 55.6%，相似度提升了 77.4%。最後，我們為影片字幕建立了一個基準，並引進一個排行榜，旨在加速影片理解、字幕和資料比對的進展。排行榜：https://wolfv0.github.io/leaderboard.html。</paragraph>

##### **AppWorld: A Controllable World of Apps and People for Benchmarking Interactive Coding Agents**
2407.18901v1 by Harsh Trivedi, Tushar Khot, Mareike Hartmann, Ruskin Manku, Vinty Dong, Edward Li, Shashank Gupta, Ashish Sabharwal, Niranjan Balasubramanian

Autonomous agents that address day-to-day digital tasks (e.g., ordering
groceries for a household), must not only operate multiple apps (e.g., notes,
messaging, shopping app) via APIs, but also generate rich code with complex
control flow in an iterative manner based on their interaction with the
environment. However, existing benchmarks for tool use are inadequate, as they
only cover tasks that require a simple sequence of API calls.
  To remedy this gap, we built $\textbf{AppWorld Engine}$, a high-quality
execution environment (60K lines of code) of 9 day-to-day apps operable via 457
APIs and populated with realistic digital activities simulating the lives of
~100 fictitious users. We then created $\textbf{AppWorld Benchmark}$ (40K lines
of code), a suite of 750 natural, diverse, and challenging autonomous agent
tasks requiring rich and interactive code generation. It supports robust
programmatic evaluation with state-based unit tests, allowing for different
ways of completing a task while also checking for unexpected changes, i.e.,
collateral damage. The state-of-the-art LLM, GPT-4o, solves only ~49% of our
'normal' tasks and ~30% of 'challenge' tasks, while other models solve at least
16% fewer. This highlights the benchmark's difficulty and AppWorld's potential
to push the frontiers of interactive coding agents. The project website is
available at https://appworld.dev/.

摘要：<paragraph>處理日常數位任務（例如：為家庭訂購食品雜貨）的自主代理，不僅必須透過 API 操作多個應用程式（例如：記事本、訊息、購物應用程式），還必須根據與環境的互動，以迭代方式產生具有複雜控制流程的豐富程式碼。然而，現有的工具使用基準並不充分，因為它們僅涵蓋需要一系列簡單 API 呼叫的任務。
  為了彌補這個差距，我們建構了 $\textbf{AppWorld Engine}$，一個高品質的執行環境（60K 行程式碼），其中包含 9 個可透過 457 個 API 操作的日常應用程式，並填充了模擬大約 100 個虛構使用者生活的真實數位活動。接著，我們建立了 $\textbf{AppWorld Benchmark}$（40K 行程式碼），一個包含 750 個自然、多元且具有挑戰性的自主代理任務套件，需要豐富且互動的程式碼產生。它支援穩健的程式化評估，並使用基於狀態的單元測試，允許以不同的方式完成任務，同時檢查意外的變更，例如附帶損害。最先進的 LLM，GPT-4o，僅解決了大約 49% 的「一般」任務和大約 30% 的「挑戰」任務，而其他模型的解決率至少低了 16%。這突顯了基準的難度，以及 AppWorld 推動互動式編碼代理邊界的潛力。專案網站可於 https://appworld.dev/ 獲得。</paragraph>

##### **Learn from the Learnt: Source-Free Active Domain Adaptation via Contrastive Sampling and Visual Persistence**
2407.18899v1 by Mengyao Lyu, Tianxiang Hao, Xinhao Xu, Hui Chen, Zijia Lin, Jungong Han, Guiguang Ding

Domain Adaptation (DA) facilitates knowledge transfer from a source domain to
a related target domain. This paper investigates a practical DA paradigm,
namely Source data-Free Active Domain Adaptation (SFADA), where source data
becomes inaccessible during adaptation, and a minimum amount of annotation
budget is available in the target domain. Without referencing the source data,
new challenges emerge in identifying the most informative target samples for
labeling, establishing cross-domain alignment during adaptation, and ensuring
continuous performance improvements through the iterative query-and-adaptation
process. In response, we present learn from the learnt (LFTL), a novel paradigm
for SFADA to leverage the learnt knowledge from the source pretrained model and
actively iterated models without extra overhead. We propose Contrastive Active
Sampling to learn from the hypotheses of the preceding model, thereby querying
target samples that are both informative to the current model and persistently
challenging throughout active learning. During adaptation, we learn from
features of actively selected anchors obtained from previous intermediate
models, so that the Visual Persistence-guided Adaptation can facilitate feature
distribution alignment and active sample exploitation. Extensive experiments on
three widely-used benchmarks show that our LFTL achieves state-of-the-art
performance, superior computational efficiency and continuous improvements as
the annotation budget increases. Our code is available at
https://github.com/lyumengyao/lftl.

摘要：領域適應 (DA) 促進了從源領域到相關目標領域的知識轉移。本文探討了一個實用的 DA 典範，即無源數據主動領域適應 (SFADA)，其中源數據在適應期間變得不可訪問，並且在目標領域中可用的註解預算非常少。在不參考源數據的情況下，在識別用於標籤的最具信息性的目標樣本、在適應期間建立跨領域對齊以及通過迭代查詢和適應過程確保持續的性能改進方面出現了新的挑戰。作為回應，我們提出了從所學中學習 (LFTL)，這是一種新的 SFADA 典範，用於利用從源預訓練模型中學習到的知識，並在沒有額外開銷的情況下主動迭代模型。我們提出對比主動採樣，以從前一個模型的假設中學習，從而查詢對當前模型既有信息又有助於在主動學習過程中持續挑戰的目標樣本。在適應過程中，我們從從先前中間模型獲得的積極選擇錨點的特徵中學習，以便視覺持久性引導適應可以促進特徵分佈對齊和主動樣本利用。在三個廣泛使用的基準上進行的廣泛實驗表明，我們的 LFTL 達到了最先進的性能、卓越的計算效率和隨著註解預算的增加而持續改進。我們的代碼可在 https://github.com/lyumengyao/lftl 上獲得。

##### **Embedding And Clustering Your Data Can Improve Contrastive Pretraining**
2407.18887v1 by Luke Merrick

Recent studies of large-scale contrastive pretraining in the text embedding
domain show that using single-source minibatches, rather than mixed-source
minibatches, can substantially improve overall model accuracy. In this work, we
explore extending training data stratification beyond source granularity by
leveraging a pretrained text embedding model and the classic k-means clustering
algorithm to further split training data apart by the semantic clusters within
each source. Experimentally, we observe a notable increase in NDCG@10 when
pretraining a BERT-based text embedding model on query-passage pairs from the
MSMARCO passage retrieval dataset. Additionally, we conceptually connect our
clustering approach to both the Topic Aware Sampling (TAS) aspect of the TAS-B
methodology and the nearest-neighbor-based hard-negative mining aspect of the
ANCE methodology and discuss how this unified view motivates future lines of
research on the organization of contrastive pretraining data.

摘要：最近在文本嵌入領域中進行的大規模對比預訓練研究表明，使用單一來源的小批次，而不是混合來源的小批次，可以大幅提升整體模型準確度。在這項工作中，我們探討了透過利用預訓練文本嵌入模型和經典的 k 均值聚類演算法，將訓練資料分層擴展到來源粒度之外，進一步根據每個來源內的語義群集將訓練資料分開。在實驗中，我們觀察到在 MSMARCO 段落檢索資料集中的查詢-段落對上預訓練基於 BERT 的文本嵌入模型時，NDCG@10 有顯著提升。此外，我們在概念上將我們的聚類方法與 TAS-B 方法論的 Topic Aware Sampling (TAS) 面向和 ANCE 方法論的基於最近鄰的困難負例挖掘面向連結起來，並討論這種統一觀點如何激勵未來在對比預訓練資料組織的研究方向。

##### **Generative Adversarial Networks for Imputing Sparse Learning Performance**
2407.18875v1 by Liang Zhang, Mohammed Yeasin, Jionghao Lin, Felix Havugimana, Xiangen Hu

Learning performance data, such as correct or incorrect responses to
questions in Intelligent Tutoring Systems (ITSs) is crucial for tracking and
assessing the learners' progress and mastery of knowledge. However, the issue
of data sparsity, characterized by unexplored questions and missing attempts,
hampers accurate assessment and the provision of tailored, personalized
instruction within ITSs. This paper proposes using the Generative Adversarial
Imputation Networks (GAIN) framework to impute sparse learning performance
data, reconstructed into a three-dimensional (3D) tensor representation across
the dimensions of learners, questions and attempts. Our customized GAIN-based
method computational process imputes sparse data in a 3D tensor space,
significantly enhanced by convolutional neural networks for its input and
output layers. This adaptation also includes the use of a least squares loss
function for optimization and aligns the shapes of the input and output with
the dimensions of the questions-attempts matrices along the learners'
dimension. Through extensive experiments on six datasets from various ITSs,
including AutoTutor, ASSISTments and MATHia, we demonstrate that the GAIN
approach generally outperforms existing methods such as tensor factorization
and other generative adversarial network (GAN) based approaches in terms of
imputation accuracy. This finding enhances comprehensive learning data modeling
and analytics in AI-based education.

摘要：學習表現資料，例如智慧型教學系統 (ITS) 中問題的正確或錯誤回應，對於追蹤和評量學生的進度和知識掌握至關重要。然而，資料稀疏的問題，其特徵是未探索的問題和遺漏的嘗試，阻礙了準確的評量和在 ITS 中提供客製化、個人化的教學。本文提出使用生成對抗式填補網路 (GAIN) 架構來填補稀疏的學習表現資料，並將其重建為跨越學生、問題和嘗試維度的三維 (3D) 張量表示。我們客製化的 GAIN 為基礎的方法運算處理在 3D 張量空間中填補稀疏資料，其輸入和輸出層由卷積神經網路大幅強化。此調整也包含使用最小平方損失函數進行最佳化，並將輸入和輸出的形狀與學生的維度沿著問題嘗試矩陣的維度對齊。透過對來自各種 ITS 的六個資料集進行廣泛的實驗，包括 AutoTutor、ASSISTments 和 MATHia，我們證明 GAIN 方法在填補準確性方面通常優於現有方法，例如張量分解和其他基於生成對抗網路 (GAN) 的方法。此發現增強了基於 AI 的教育中的綜合學習資料建模和分析。

##### **Unifying Visual and Semantic Feature Spaces with Diffusion Models for Enhanced Cross-Modal Alignment**
2407.18854v1 by Yuze Zheng, Zixuan Li, Xiangxian Li, Jinxing Liu, Yuqing Wang, Xiangxu Meng, Lei Meng

Image classification models often demonstrate unstable performance in
real-world applications due to variations in image information, driven by
differing visual perspectives of subject objects and lighting discrepancies. To
mitigate these challenges, existing studies commonly incorporate additional
modal information matching the visual data to regularize the model's learning
process, enabling the extraction of high-quality visual features from complex
image regions. Specifically, in the realm of multimodal learning, cross-modal
alignment is recognized as an effective strategy, harmonizing different modal
information by learning a domain-consistent latent feature space for visual and
semantic features. However, this approach may face limitations due to the
heterogeneity between multimodal information, such as differences in feature
distribution and structure. To address this issue, we introduce a Multimodal
Alignment and Reconstruction Network (MARNet), designed to enhance the model's
resistance to visual noise. Importantly, MARNet includes a cross-modal
diffusion reconstruction module for smoothly and stably blending information
across different domains. Experiments conducted on two benchmark datasets,
Vireo-Food172 and Ingredient-101, demonstrate that MARNet effectively improves
the quality of image information extracted by the model. It is a plug-and-play
framework that can be rapidly integrated into various image classification
frameworks, boosting model performance.

摘要：影像分類模型在真實世界的應用中，常因影像資訊的變化而表現不穩定，這些變化是由於受試物體不同的視覺觀點和光線差異所致。為了減輕這些挑戰，現有的研究通常會納入額外的模態資訊，將視覺資料與常規化模型的學習過程相匹配，從複雜的影像區域中提取高品質的視覺特徵。具體來說，在多模態學習的領域中，跨模態對齊被視為一種有效的策略，透過學習視覺和語義特徵的領域一致潛在特徵空間，調和不同的模態資訊。然而，此方法可能會因多模態資訊之間的異質性而面臨限制，例如特徵分佈和結構的差異。為了解決這個問題，我們引進了一個多模態對齊和重建網路 (MARNet)，旨在增強模型對視覺雜訊的抵抗力。重要的是，MARNet 包含一個跨模態擴散重建模組，用於平順且穩定地混合不同領域的資訊。在兩個基準資料集 Vireo-Food172 和 Ingredient-101 上進行的實驗證明，MARNet 有效地改善了模型提取的影像資訊品質。它是一個即插即用的架構，可以快速整合到各種影像分類架構中，提升模型效能。

##### **Enhancing material property prediction with ensemble deep graph convolutional networks**
2407.18847v1 by Chowdhury Mohammad Abid Rahman, Ghadendra Bhandari, Nasser M Nasrabadi, Aldo H. Romero, Prashnna K. Gyawali

Machine learning (ML) models have emerged as powerful tools for accelerating
materials discovery and design by enabling accurate predictions of properties
from compositional and structural data. These capabilities are vital for
developing advanced technologies across fields such as energy, electronics, and
biomedicine, potentially reducing the time and resources needed for new
material exploration and promoting rapid innovation cycles. Recent efforts have
focused on employing advanced ML algorithms, including deep learning - based
graph neural network, for property prediction. Additionally, ensemble models
have proven to enhance the generalizability and robustness of ML and DL.
However, the use of such ensemble strategies in deep graph networks for
material property prediction remains underexplored. Our research provides an
in-depth evaluation of ensemble strategies in deep learning - based graph
neural network, specifically targeting material property prediction tasks. By
testing the Crystal Graph Convolutional Neural Network (CGCNN) and its
multitask version, MT-CGCNN, we demonstrated that ensemble techniques,
especially prediction averaging, substantially improve precision beyond
traditional metrics for key properties like formation energy per atom ($\Delta
E^{f}$), band gap ($E_{g}$) and density ($\rho$) in 33,990 stable inorganic
materials. These findings support the broader application of ensemble methods
to enhance predictive accuracy in the field.

摘要：機器學習 (ML) 模型已成為強大的工具，可透過啟用準確預測組成和結構資料中的屬性，來加速材料發現和設計。這些功能對於開發能源、電子和生物醫學等領域的先進技術至關重要，有可能減少新材料探索所需的時間和資源，並促進快速的創新週期。最近的努力集中於採用先進的 ML 演算法，包括基於深度學習的圖神經網路，進行屬性預測。此外，合奏模型已被證明可以增強 ML 和 DL 的概括性和穩健性。然而，在深度圖網路中使用此類合奏策略來進行材料屬性預測仍未得到充分探索。我們的研究對基於深度學習的圖神經網路中的合奏策略進行了深入評估，特別針對材料屬性預測任務。透過測試 Crystal Graph Convolutional Neural Network (CGCNN) 及其多任務版本 MT-CGCNN，我們證明了合奏技術，特別是預測平均值，大幅提升了傳統指標的精準度，例如 33,990 種穩定無機材料中的每個原子形成能 ($\Delta E^{f}$)、能隙 ($E_{g}$) 和密度 ($\rho$)。這些發現支持更廣泛地應用合奏方法，以提高該領域的預測準確度。

##### **Human-artificial intelligence teaming for scientific information extraction from data-driven additive manufacturing research using large language models**
2407.18827v1 by Mutahar Safdar, Jiarui Xie, Andrei Mircea, Yaoyao Fiona Zhao

Data-driven research in Additive Manufacturing (AM) has gained significant
success in recent years. This has led to a plethora of scientific literature to
emerge. The knowledge in these works consists of AM and Artificial Intelligence
(AI) contexts that have not been mined and formalized in an integrated way. It
requires substantial effort and time to extract scientific information from
these works. AM domain experts have contributed over two dozen review papers to
summarize these works. However, information specific to AM and AI contexts
still requires manual effort to extract. The recent success of foundation
models such as BERT (Bidirectional Encoder Representations for Transformers) or
GPT (Generative Pre-trained Transformers) on textual data has opened the
possibility of expediting scientific information extraction. We propose a
framework that enables collaboration between AM and AI experts to continuously
extract scientific information from data-driven AM literature. A demonstration
tool is implemented based on the proposed framework and a case study is
conducted to extract information relevant to the datasets, modeling, sensing,
and AM system categories. We show the ability of LLMs (Large Language Models)
to expedite the extraction of relevant information from data-driven AM
literature. In the future, the framework can be used to extract information
from the broader design and manufacturing literature in the engineering
discipline.

摘要：近年來，增材製造 (AM) 中的數據驅動研究已取得顯著成功。這導致了大量科學文獻的出現。這些著作中的知識包含 AM 和人工智慧 (AI) 的背景，這些背景尚未以整合的方式進行挖掘和形式化。從這些著作中提取科學信息需要大量的精力和時間。AM 領域專家已撰寫了 20 多篇評論文章來總結這些著作。然而，特定於 AM 和 AI 背景的信息仍需要人工提取。基礎模型（例如 BERT（Transformer的雙向編碼器表示）或 GPT（生成式預訓練Transformer））在文本數據上的最新成功為加速科學信息提取打開了可能性。我們提出了一个框架，使 AM 和 AI 專家能夠持續從數據驅動的 AM 文獻中提取科學信息。根據所提出的框架實現了一個示範工具，並進行了一個案例研究，以提取與數據集、建模、感測和 AM 系統類別相關的信息。我們展示了 LLM（大型語言模型）從數據驅動的 AM 文獻中快速提取相關信息的能力。未來，該框架可用于從工程學科中更廣泛的設計和製造文獻中提取信息。

##### **Learning Chaotic Systems and Long-Term Predictions with Neural Jump ODEs**
2407.18808v1 by Florian Krach, Josef Teichmann

The Path-dependent Neural Jump ODE (PD-NJ-ODE) is a model for online
prediction of generic (possibly non-Markovian) stochastic processes with
irregular (in time) and potentially incomplete (with respect to coordinates)
observations. It is a model for which convergence to the $L^2$-optimal
predictor, which is given by the conditional expectation, is established
theoretically. Thereby, the training of the model is solely based on a dataset
of realizations of the underlying stochastic process, without the need of
knowledge of the law of the process. In the case where the underlying process
is deterministic, the conditional expectation coincides with the process
itself. Therefore, this framework can equivalently be used to learn the
dynamics of ODE or PDE systems solely from realizations of the dynamical system
with different initial conditions. We showcase the potential of our method by
applying it to the chaotic system of a double pendulum. When training the
standard PD-NJ-ODE method, we see that the prediction starts to diverge from
the true path after about half of the evaluation time. In this work we enhance
the model with two novel ideas, which independently of each other improve the
performance of our modelling setup. The resulting dynamics match the true
dynamics of the chaotic system very closely. The same enhancements can be used
to provably enable the PD-NJ-ODE to learn long-term predictions for general
stochastic datasets, where the standard model fails. This is verified in
several experiments.

摘要：基於路徑的神經跳躍 ODE（PD-NJ-ODE）是一個模型，用於線上預測通用的（可能是非馬可夫鏈的）隨機過程，具有不規則（在時間上）和潛在不完整（相對於坐標）的觀測。這是一個模型，其收斂到 $L^2$ 最佳預測器，由條件期望給出，在理論上已建立。因此，模型的訓練僅基於基礎隨機過程實現的資料集，無需了解過程的規律。在基礎過程是確定性的情況下，條件期望與過程本身一致。因此，這個框架可以等效地用於僅從具有不同初始條件的動力系統實現中學習 ODE 或 PDE 系統的動力學。我們通過將我們的模型應用於雙擺的混沌系統來展示我們方法的潛力。在訓練標準 PD-NJ-ODE 方法時，我們看到預測在評估時間過了一半後開始偏離真實路徑。在這項工作中，我們使用兩個新穎的想法來增強模型，它們獨立於彼此提高了我們建模設定的性能。產生的動力學與混沌系統的真實動力學非常吻合。相同的增強可以用於證明使 PD-NJ-ODE 能學習一般隨機資料集的長期預測，而標準模型會失敗。這在幾個實驗中得到驗證。

##### **The power of Prompts: Evaluating and Mitigating Gender Bias in MT with LLMs**
2407.18786v1 by Aleix Sant, Carlos Escolano, Audrey Mash, Francesca De Luca Fornaciari, Maite Melero

This paper studies gender bias in machine translation through the lens of
Large Language Models (LLMs). Four widely-used test sets are employed to
benchmark various base LLMs, comparing their translation quality and gender
bias against state-of-the-art Neural Machine Translation (NMT) models for
English to Catalan (En $\rightarrow$ Ca) and English to Spanish (En
$\rightarrow$ Es) translation directions. Our findings reveal pervasive gender
bias across all models, with base LLMs exhibiting a higher degree of bias
compared to NMT models. To combat this bias, we explore prompting engineering
techniques applied to an instruction-tuned LLM. We identify a prompt structure
that significantly reduces gender bias by up to 12% on the WinoMT evaluation
dataset compared to more straightforward prompts. These results significantly
reduce the gender bias accuracy gap between LLMs and traditional NMT systems.

摘要：這篇論文透過大型語言模型 (LLM) 的角度研究機器翻譯中的性別偏見。採用四個廣泛使用的測試集來評量各種基礎 LLM，比較它們在英譯加泰隆語 (En $\rightarrow$ Ca) 和英譯西班牙語 (En $\rightarrow$ Es) 翻譯方向上的翻譯品質和性別偏見，並與最先進的神經機器翻譯 (NMT) 模型進行對比。我們的研究結果揭露所有模型中普遍存在性別偏見，與 NMT 模型相比，基礎 LLM 表現出更高的偏見程度。為了消除這種偏見，我們探索了應用於指令微調 LLM 的提示工程技術。我們確定了一個提示結構，與更直接的提示相比，在 WinoMT 評估資料集上將性別偏見顯著降低了 12%。這些結果顯著縮小了 LLM 與傳統 NMT 系統之間的性別偏見準確性差距。

##### **Understanding XAI Through the Philosopher's Lens: A Historical Perspective**
2407.18782v1 by Martina Mattioli, Antonio Emanuele Cinà, Marcello Pelillo

Despite explainable AI (XAI) has recently become a hot topic and several
different approaches have been developed, there is still a widespread belief
that it lacks a convincing unifying foundation. On the other hand, over the
past centuries, the very concept of explanation has been the subject of
extensive philosophical analysis in an attempt to address the fundamental
question of "why" in the context of scientific law. However, this discussion
has rarely been connected with XAI. This paper tries to fill in this gap and
aims to explore the concept of explanation in AI through an epistemological
lens. By comparing the historical development of both the philosophy of science
and AI, an intriguing picture emerges. Specifically, we show that a gradual
progression has independently occurred in both domains from logical-deductive
to statistical models of explanation, thereby experiencing in both cases a
paradigm shift from deterministic to nondeterministic and probabilistic
causality. Interestingly, we also notice that similar concepts have
independently emerged in both realms such as, for example, the relation between
explanation and understanding and the importance of pragmatic factors. Our
study aims to be the first step towards understanding the philosophical
underpinnings of the notion of explanation in AI, and we hope that our findings
will shed some fresh light on the elusive nature of XAI.

摘要：儘管可解釋 AI (XAI) 最近已成為熱門話題且已開發出幾種不同的方法，但仍普遍認為它缺乏令人信服的統一基礎。另一方面，在過去幾個世紀中，解釋的概念一直是廣泛哲學分析的主題，目的是在科學定律的背景下探討「為什麼」這個基本問題。然而，這種討論很少與 XAI 有關。本文試圖填補這一空白，並旨在透過認識論的觀點探討 AI 中的解釋概念。透過比較科學哲學和 AI 的歷史發展，一幅有趣的圖像浮現出來。具體來說，我們表明在邏輯演繹到統計解釋模型的兩個領域中，逐漸進展是獨立發生的，從而在兩者中都經歷了從確定性到非確定性和機率因果關係的典範轉移。有趣的是，我們還注意到類似的概念在兩個領域中都獨立出現，例如解釋與理解之間的關係以及實用因素的重要性。我們的研究旨在成為了解 AI 中解釋概念的哲學基礎的第一步，我們希望我們的發現將為 XAI 的難以捉摸的本質帶來一些新的見解。

##### **TAGIFY: LLM-powered Tagging Interface for Improved Data Findability on OGD portals**
2407.18764v1 by Kevin Kliimask, Anastasija Nikiforova

Efforts directed towards promoting Open Government Data (OGD) have gained
significant traction across various governmental tiers since the mid-2000s. As
more datasets are published on OGD portals, finding specific data becomes
harder, leading to information overload. Complete and accurate documentation of
datasets, including association of proper tags with datasets is key to
improving dataset findability and accessibility. Analysis conducted on the
Estonian Open Data Portal, revealed that 11% datasets have no associated tags,
while 26% had only one tag assigned to them, which underscores challenges in
data findability and accessibility within the portal, which, according to the
recent Open Data Maturity Report, is considered trend-setter. The aim of this
study is to propose an automated solution to tagging datasets to improve data
findability on OGD portals. This paper presents Tagify - a prototype of tagging
interface that employs large language models (LLM) such as GPT-3.5-turbo and
GPT-4 to automate dataset tagging, generating tags for datasets in English and
Estonian, thereby augmenting metadata preparation by data publishers and
improving data findability on OGD portals by data users. The developed solution
was evaluated by users and their feedback was collected to define an agenda for
future prototype improvements.

摘要：自 2000 年代中期以來，促進開放政府資料 (OGD) 的努力已在各級政府間獲得顯著進展。隨著 OGD 入口網站上發布更多資料集，尋找特定資料變得更加困難，導致資訊過載。完整且準確的資料集文件，包括將適當標籤與資料集關聯起來，是改善資料集可查找性和可存取性的關鍵。對愛沙尼亞開放資料入口網站進行的分析顯示，11% 的資料集沒有關聯標籤，而 26% 的資料集只有一個標籤，這突顯了入口網站內資料可查找性和可存取性的挑戰，根據最近的開放資料成熟度報告，該網站被認為是趨勢引領者。本研究的目的是提出一個自動化解決方案來標記資料集，以改善 OGD 入口網站上的資料可查找性。本文介紹了 Tagify - 一個標記介面的原型，它採用大型語言模型 (LLM)，例如 GPT-3.5-turbo 和 GPT-4 來自動化資料集標記，為英文和愛沙尼亞文的資料集產生標籤，從而擴充資料發布者的元資料準備工作，並改善資料使用者在 OGD 入口網站上的資料可查找性。已開發的解決方案由使用者評估，並收集他們的回饋，以定義未來原型改進的議程。

##### **Score matching through the roof: linear, nonlinear, and latent variables causal discovery**
2407.18755v1 by Francesco Montagna, Philipp M. Faller, Patrick Bloebaum, Elke Kirschbaum, Francesco Locatello

Causal discovery from observational data holds great promise, but existing
methods rely on strong assumptions about the underlying causal structure, often
requiring full observability of all relevant variables. We tackle these
challenges by leveraging the score function $\nabla \log p(X)$ of observed
variables for causal discovery and propose the following contributions. First,
we generalize the existing results of identifiability with the score to
additive noise models with minimal requirements on the causal mechanisms.
Second, we establish conditions for inferring causal relations from the score
even in the presence of hidden variables; this result is two-faced: we
demonstrate the score's potential as an alternative to conditional independence
tests to infer the equivalence class of causal graphs with hidden variables,
and we provide the necessary conditions for identifying direct causes in latent
variable models. Building on these insights, we propose a flexible algorithm
for causal discovery across linear, nonlinear, and latent variable models,
which we empirically validate.

摘要：從觀測資料中進行因果發現具有很大的前景，但現有方法依賴於對底層因果結構的強假設，通常需要所有相關變數的完全可觀察性。我們透過利用觀測變數的得分函數 $\nabla \log p(X)$ 來應對這些挑戰，並提出以下貢獻。首先，我們將現有的可識別性結果推廣到具有對因果機制要求最小的加性雜訊模型中的得分。其次，我們建立了即使在存在隱藏變數的情況下，從得分中推斷因果關係的條件；這個結果是兩面的：我們證明了得分作為條件獨立性檢定的替代方法的潛力，以推斷具有隱藏變數的因果圖的等價類，並且我們提供了識別潛在變數模型中直接原因的必要條件。基於這些見解，我們提出了一個靈活的演算法，用於跨線性、非線性和潛在變數模型進行因果發現，我們對此進行了實證驗證。

##### **Knowledge Graph Structure as Prompt: Improving Small Language Models Capabilities for Knowledge-based Causal Discovery**
2407.18752v1 by Yuni Susanti, Michael Färber

Causal discovery aims to estimate causal structures among variables based on
observational data. Large Language Models (LLMs) offer a fresh perspective to
tackle the causal discovery problem by reasoning on the metadata associated
with variables rather than their actual data values, an approach referred to as
knowledge-based causal discovery. In this paper, we investigate the
capabilities of Small Language Models (SLMs, defined as LLMs with fewer than 1
billion parameters) with prompt-based learning for knowledge-based causal
discovery. Specifically, we present KG Structure as Prompt, a novel approach
for integrating structural information from a knowledge graph, such as common
neighbor nodes and metapaths, into prompt-based learning to enhance the
capabilities of SLMs. Experimental results on three types of biomedical and
open-domain datasets under few-shot settings demonstrate the effectiveness of
our approach, surpassing most baselines and even conventional fine-tuning
approaches trained on full datasets. Our findings further highlight the strong
capabilities of SLMs: in combination with knowledge graphs and prompt-based
learning, SLMs demonstrate the potential to surpass LLMs with larger number of
parameters. Our code and datasets are available on GitHub.

摘要：因果發現旨在根據觀測資料估計變數之間的因果結構。大型語言模型 (LLM) 提供了一個新觀點，透過推理與變數相關的元資料，而非其實際資料值，來解決因果發現問題，這種方法稱為基於知識的因果發現。在本文中，我們探討小型語言模型 (SLM，定義為參數少於 10 億的 LLM) 的能力，並使用基於提示的學習進行基於知識的因果發現。具體來說，我們提出 KG 結構作為提示，這是一種新穎的方法，可以將來自知識圖表的結構化資訊（例如，共同鄰居節點和元路徑）整合到基於提示的學習中，以增強 SLM 的能力。在少次嘗試的設定下，針對三種類型的生物醫學和開放領域資料集的實驗結果證明了我們方法的有效性，超越了大多數基線，甚至超越了針對完整資料集訓練的傳統微調方法。我們的發現進一步突顯了 SLM 的強大功能：SLM 結合知識圖表和基於提示的學習，證明了超越參數數量較多的 LLM 的潛力。我們的程式碼和資料集可在 GitHub 上取得。

##### **Multi-Robot System Architecture design in SysML and BPMN**
2407.18749v1 by Ahmed R. Sadik, Christian Goerick

Multi-Robot System (MRS) is a complex system that contains many different
software and hardware components. This main problem addressed in this article
is the MRS design complexity. The proposed solution provides a modular modeling
and simulation technique that is based on formal system engineering method,
therefore the MRS design complexity is decomposed and reduced. Modeling the MRS
has been achieved via two formal Architecture Description Languages (ADLs),
which are Systems Modeling Language (SysML) and Business Process Model and
Notation (BPMN), to design the system blueprints. By using those abstract
design ADLs, the implementation of the project becomes technology agnostic.
This allows to transfer the design concept from on programming language to
another. During the simulation phase, a multi-agent environment is used to
simulate the MRS blueprints. The simulation has been implemented in Java Agent
Development (JADE) middleware. Therefore, its results can be used to analysis
and verify the proposed MRS model in form of performance evaluation matrix.

摘要：多機器人系統 (MRS) 是一個複雜的系統，包含許多不同的軟體和硬體元件。本文探討的主要問題是 MRS 設計的複雜性。所提出的解決方案提供一種模組化建模和模擬技術，該技術基於正式的系統工程方法，因此 MRS 設計的複雜性被分解和降低。MRS 的建模已透過兩種正式的架構描述語言 (ADL) 來實現，分別是系統建模語言 (SysML) 和商業流程模型與標記法 (BPMN)，以設計系統藍圖。透過使用這些抽象設計 ADL，專案的實作變得與技術無關。這允許將設計概念從一種程式語言轉移到另一種程式語言。在模擬階段，會使用多代理環境來模擬 MRS 藍圖。模擬已在 Java Agent Development (JADE) 中介軟體中實作。因此，其結果可用於以效能評估矩陣的形式分析和驗證所提出的 MRS 模型。

##### **Towards Effective and Efficient Continual Pre-training of Large Language Models**
2407.18743v1 by Jie Chen, Zhipeng Chen, Jiapeng Wang, Kun Zhou, Yutao Zhu, Jinhao Jiang, Yingqian Min, Wayne Xin Zhao, Zhicheng Dou, Jiaxin Mao, Yankai Lin, Ruihua Song, Jun Xu, Xu Chen, Rui Yan, Zhewei Wei, Di Hu, Wenbing Huang, Ji-Rong Wen

Continual pre-training (CPT) has been an important approach for adapting
language models to specific domains or tasks. To make the CPT approach more
traceable, this paper presents a technical report for continually pre-training
Llama-3 (8B), which significantly enhances the Chinese language ability and
scientific reasoning ability of the backbone model. To enhance the new
abilities while retaining the original abilities, we design specific data
mixture and curriculum strategies by utilizing existing datasets and
synthesizing high-quality datasets. Specifically, we synthesize
multidisciplinary scientific question and answer (QA) pairs based on related
web pages, and subsequently incorporate these synthetic data to improve the
scientific reasoning ability of Llama-3. We refer to the model after CPT as
Llama-3-SynE (Synthetic data Enhanced Llama-3). We also present the tuning
experiments with a relatively small model -- TinyLlama, and employ the derived
findings to train the backbone model. Extensive experiments on a number of
evaluation benchmarks show that our approach can largely improve the
performance of the backbone models, including both the general abilities (+8.81
on C-Eval and +6.31 on CMMLU) and the scientific reasoning abilities (+12.00 on
MATH and +4.13 on SciEval), without hurting the original capacities. Our model,
data, and codes are available at https://github.com/RUC-GSAI/Llama-3-SynE.

摘要：持續預訓練 (CPT) 一直是將語言模型調整到特定領域或任務的重要方法。為了讓 CPT 方法更具可追溯性，本文針對 Llama-3 (8B) 的持續預訓練提出技術報告，大幅提升了主幹模型的中文能力和科學推理能力。為了在保留原本能力的同時提升新能力，我們利用既有資料集並合成高品質資料集，設計出特定的資料混合和課程策略。具體來說，我們根據相關網頁合成跨學科科學問答 (QA) 配對，並進一步納入這些合成資料，以提升 Llama-3 的科學推理能力。我們將 CPT 後的模型稱為 Llama-3-SynE (合成資料增強 Llama-3)。我們也提出一個使用相對較小模型 TinyLlama 的微調實驗，並運用得出的發現來訓練主幹模型。在多個評量基準上的廣泛實驗顯示，我們的做法大幅提升了主幹模型的效能，包括一般能力（在 C-Eval 上提升 +8.81，在 CMMLU 上提升 +6.31）和科學推理能力（在 MATH 上提升 +12.00，在 SciEval 上提升 +4.13），且不損及原本的能力。我們的模型、資料和程式碼可在 https://github.com/RUC-GSAI/Llama-3-SynE 取得。

##### **Towards Generalized Offensive Language Identification**
2407.18738v1 by Alphaeus Dmonte, Tejas Arya, Tharindu Ranasinghe, Marcos Zampieri

The prevalence of offensive content on the internet, encompassing hate speech
and cyberbullying, is a pervasive issue worldwide. Consequently, it has
garnered significant attention from the machine learning (ML) and natural
language processing (NLP) communities. As a result, numerous systems have been
developed to automatically identify potentially harmful content and mitigate
its impact. These systems can follow two approaches; (1) Use publicly available
models and application endpoints, including prompting large language models
(LLMs) (2) Annotate datasets and train ML models on them. However, both
approaches lack an understanding of how generalizable they are. Furthermore,
the applicability of these systems is often questioned in off-domain and
practical environments. This paper empirically evaluates the generalizability
of offensive language detection models and datasets across a novel generalized
benchmark. We answer three research questions on generalizability. Our findings
will be useful in creating robust real-world offensive language detection
systems.

摘要：網路上的攻擊性內容盛行，包括仇恨言論和網路霸凌，這是全球普遍的問題。因此，它引起了機器學習 (ML) 和自然語言處理 (NLP) 社群的極大關注。結果，已經開發出許多系統來自動識別潛在有害內容並減輕其影響。這些系統可以遵循兩種方法：(1) 使用公開的模型和應用程式端點，包括提示大型語言模型 (LLM)；(2) 對資料集進行註解並在它們上訓練 ML 模型。然而，這兩種方法都不了解它們的概括性。此外，這些系統的適用性常常在非領域和實際環境中受到質疑。本文根據新的概括基準實證評估攻擊性語言偵測模型和資料集的概括性。我們回答了三個關於概括性的研究問題。我們的發現將有助於建立強大的真實世界攻擊性語言偵測系統。

##### **Neurosymbolic AI for Enhancing Instructability in Generative AI**
2407.18722v1 by Amit Sheth, Vishal Pallagani, Kaushik Roy

Generative AI, especially via Large Language Models (LLMs), has transformed
content creation across text, images, and music, showcasing capabilities in
following instructions through prompting, largely facilitated by instruction
tuning. Instruction tuning is a supervised fine-tuning method where LLMs are
trained on datasets formatted with specific tasks and corresponding
instructions. This method systematically enhances the model's ability to
comprehend and execute the provided directives. Despite these advancements,
LLMs still face challenges in consistently interpreting complex, multi-step
instructions and generalizing them to novel tasks, which are essential for
broader applicability in real-world scenarios. This article explores why
neurosymbolic AI offers a better path to enhance the instructability of LLMs.
We explore the use a symbolic task planner to decompose high-level instructions
into structured tasks, a neural semantic parser to ground these tasks into
executable actions, and a neuro-symbolic executor to implement these actions
while dynamically maintaining an explicit representation of state. We also seek
to show that neurosymbolic approach enhances the reliability and
context-awareness of task execution, enabling LLMs to dynamically interpret and
respond to a wider range of instructional contexts with greater precision and
flexibility.

摘要：生成式 AI，特别是通过大型语言模型 (LLM)，已将内容创作转化为文本、图像和音乐，展示了通过提示遵循指令的能力，在很大程度上由指令微调促成。指令微调是一种监督微调方法，其中 LLM 在具有特定任务格式和相应指令的数据集上进行训练。此方法系统地增强了模型理解和执行所提供指令的能力。尽管有这些进步，LLM 在一致地解释复杂的多步骤指令和将其概括为新任务方面仍然面临挑战，这对于在现实世界场景中更广泛的适用性至关重要。本文探讨了神经符号 AI 为什么为增强 LLM 的可指导性提供了更好的途径。我们探索使用符号任务规划器将高级指令分解为结构化任务，使用神经语义解析器将这些任务基础化为可执行动作，以及使用神经符号执行器在动态维护状态的显式表示的同时实施这些动作。我们还试图表明神经符号方法增强了任务执行的可靠性和上下文感知，使 LLM 能够以更高的精度和灵活性动态解释和响应更广泛的指令性上下文。

##### **ChatSchema: A pipeline of extracting structured information with Large Multimodal Models based on schema**
2407.18716v1 by Fei Wang, Yuewen Zheng, Qin Li, Jingyi Wu, Pengfei Li, Luxia Zhang

Objective: This study introduces ChatSchema, an effective method for
extracting and structuring information from unstructured data in medical paper
reports using a combination of Large Multimodal Models (LMMs) and Optical
Character Recognition (OCR) based on the schema. By integrating predefined
schema, we intend to enable LMMs to directly extract and standardize
information according to the schema specifications, facilitating further data
entry. Method: Our approach involves a two-stage process, including
classification and extraction for categorizing report scenarios and structuring
information. We established and annotated a dataset to verify the effectiveness
of ChatSchema, and evaluated key extraction using precision, recall, F1-score,
and accuracy metrics. Based on key extraction, we further assessed value
extraction. We conducted ablation studies on two LMMs to illustrate the
improvement of structured information extraction with different input modals
and methods. Result: We analyzed 100 medical reports from Peking University
First Hospital and established a ground truth dataset with 2,945 key-value
pairs. We evaluated ChatSchema using GPT-4o and Gemini 1.5 Pro and found a
higher overall performance of GPT-4o. The results are as follows: For the
result of key extraction, key-precision was 98.6%, key-recall was 98.5%,
key-F1-score was 98.6%. For the result of value extraction based on correct key
extraction, the overall accuracy was 97.2%, precision was 95.8%, recall was
95.8%, and F1-score was 95.8%. An ablation study demonstrated that ChatSchema
achieved significantly higher overall accuracy and overall F1-score of
key-value extraction, compared to the Baseline, with increases of 26.9% overall
accuracy and 27.4% overall F1-score, respectively.

摘要：<paragraph>目標：本研究介紹 ChatSchema，這是一種有效的方法，可使用大型多模態模型 (LMM) 和基於架構的光學字元辨識 (OCR) 的組合，從醫學論文報告中的非結構化資料中萃取和建構資訊。透過整合預先定義的架構，我們打算讓 LMM 能夠根據架構規格直接萃取和標準化資訊，進而簡化後續的資料輸入。方法：我們的做法包含一個兩階段的程序，包括分類和萃取，用於分類報告場景和建構資訊。我們建立並註解了一個資料集，以驗證 ChatSchema 的有效性，並使用精確度、召回率、F1 分數和準確度指標評估關鍵萃取。根據關鍵萃取，我們進一步評估值萃取。我們對兩個 LMM 進行消融研究，以說明使用不同的輸入模態和方法改善結構化資訊萃取。結果：我們分析了來自北京大學第一醫院的 100 份醫療報告，並建立了一個包含 2,945 個鍵值對的地面實況資料集。我們使用 GPT-4o 和 Gemini 1.5 Pro 評估 ChatSchema，發現 GPT-4o 的整體表現較高。結果如下：對於關鍵萃取的結果，關鍵精確度為 98.6%，關鍵召回率為 98.5%，關鍵 F1 分數為 98.6%。對於基於正確關鍵萃取的值萃取結果，整體準確度為 97.2%，精確度為 95.8%，召回率為 95.8%，F1 分數為 95.8%。消融研究表明，與基線相比，ChatSchema 在鍵值萃取方面實現了顯著更高的整體準確度和整體 F1 分數，整體準確度提高了 26.9%，整體 F1 分數提高了 27.4%。</paragraph>

##### **Cluster-norm for Unsupervised Probing of Knowledge**
2407.18712v1 by Walter Laurito, Sharan Maiya, Grégoire Dhimoïla, Owen, Yeung, Kaarel Hänni

The deployment of language models brings challenges in generating reliable
information, especially when these models are fine-tuned using human
preferences. To extract encoded knowledge without (potentially) biased human
labels, unsupervised probing techniques like Contrast-Consistent Search (CCS)
have been developed (Burns et al., 2022). However, salient but unrelated
features in a given dataset can mislead these probes (Farquhar et al., 2023).
Addressing this, we propose a cluster normalization method to minimize the
impact of such features by clustering and normalizing activations of contrast
pairs before applying unsupervised probing techniques. While this approach does
not address the issue of differentiating between knowledge in general and
simulated knowledge - a major issue in the literature of latent knowledge
elicitation (Christiano et al., 2021) - it significantly improves the ability
of unsupervised probes to identify the intended knowledge amidst distractions.

摘要：語言模型的部署帶來了產生可靠資訊的挑戰，特別是在使用人類偏好微調這些模型時。為了在沒有（潛在）偏見的人類標籤的情況下提取編碼知識，已經開發了對比一致性搜尋 (CCS) 等無監督探測技術 (Burns et al., 2022)。然而，給定資料集中的顯著但無關的特性可能會誤導這些探測 (Farquhar et al., 2023)。針對此問題，我們提出了一種群集正規化方法，藉由在套用無監督探測技術之前群集並正規化對比對的活化，將此類特性的影響降至最低。雖然這種方法並未解決區分一般知識和模擬知識的問題，這是潛在知識引發問題中的主要問題 (Christiano et al., 2021)，但它顯著提高了無監督探測在干擾中識別預期知識的能力。

##### **Adaptive Contrastive Search: Uncertainty-Guided Decoding for Open-Ended Text Generation**
2407.18698v1 by Esteban Garces Arias, Julian Rodemann, Meimingwei Li, Christian Heumann, Matthias Aßenmacher

Decoding from the output distributions of large language models to produce
high-quality text is a complex challenge in language modeling. Various
approaches, such as beam search, sampling with temperature, $k-$sampling,
nucleus $p-$sampling, typical decoding, contrastive decoding, and contrastive
search, have been proposed to address this problem, aiming to improve
coherence, diversity, as well as resemblance to human-generated text. In this
study, we introduce adaptive contrastive search, a novel decoding strategy
extending contrastive search by incorporating an adaptive degeneration penalty,
guided by the estimated uncertainty of the model at each generation step. This
strategy is designed to enhance both the creativity and diversity of the
language modeling process while at the same time producing coherent and
high-quality generated text output. Our findings indicate performance
enhancement in both aspects, across different model architectures and datasets,
underscoring the effectiveness of our method in text generation tasks. Our code
base, datasets, and models are publicly available.

摘要：從大型語言模型的輸出分佈解碼以產生高品質的文字，在語言模型中是一個複雜的挑戰。各種方法，例如波束搜尋、溫度抽樣、$k$ 抽樣、核 $p$ 抽樣、典型解碼、對比解碼和對比搜尋，已被提出以解決這個問題，目標是改善連貫性、多樣性，以及與人類產生的文字的相似性。在這項研究中，我們引入了自適應對比搜尋，一種新的解碼策略，透過結合自適應退化懲罰來擴充對比搜尋，並在每個產生步驟中由模型的估計不確定性來引導。此策略旨在同時提升語言模型處理的創造力和多樣性，同時產生連貫且高品質的產生文字輸出。我們的發現指出在不同的模型架構和資料集中的效能提升，強調了我們的方法在文字產生任務中的有效性。我們的程式碼庫、資料集和模型已公開提供。

##### **Graph Neural Networks for Virtual Sensing in Complex Systems: Addressing Heterogeneous Temporal Dynamics**
2407.18691v1 by Mengjie Zhao, Cees Taal, Stephan Baggerohr, Olga Fink

Real-time condition monitoring is crucial for the reliable and efficient
operation of complex systems. However, relying solely on physical sensors can
be limited due to their cost, placement constraints, or inability to directly
measure certain critical parameters. Virtual sensing addresses these
limitations by leveraging readily available sensor data and system knowledge to
estimate inaccessible parameters or infer system states. The increasing
complexity of industrial systems necessitates deployments of sensors with
diverse modalities to provide a comprehensive understanding of system states.
These sensors capture data at varying frequencies to monitor both rapid and
slowly varying system dynamics, as well as local and global state evolutions of
the systems. This leads to heterogeneous temporal dynamics, which, particularly
under varying operational end environmental conditions, pose a significant
challenge for accurate virtual sensing. To address this, we propose a
Heterogeneous Temporal Graph Neural Network (HTGNN) framework. HTGNN explicitly
models signals from diverse sensors and integrates operating conditions into
the model architecture. We evaluate HTGNN using two newly released datasets: a
bearing dataset with diverse load conditions for bearing load prediction and a
year-long simulated dataset for predicting bridge live loads. Our results
demonstrate that HTGNN significantly outperforms established baseline methods
in both tasks, particularly under highly varying operating conditions. These
results highlight HTGNN's potential as a robust and accurate virtual sensing
approach for complex systems, paving the way for improved monitoring,
predictive maintenance, and enhanced system performance.

摘要：對於複雜系統的可靠且有效率的操作，即時狀態監控至關重要。然而，僅依賴於物理感測器可能會受到成本、配置限制或無法直接測量某些關鍵參數的限制。虛擬感測透過運用現成的感測器資料和系統知識來估計無法取得的參數或推論系統狀態，來解決這些限制。工業系統越來越複雜，需要配置具有不同模態的感測器，以全面了解系統狀態。這些感測器以不同的頻率擷取資料，以監控快速和緩慢變化的系統動態，以及系統的局部和整體狀態演變。這會導致異質的時間動態，特別是在不同的運作和環境條件下，會對精確的虛擬感測造成重大挑戰。為了解決這個問題，我們提出異質時間圖形神經網路 (HTGNN) 架構。HTGNN 明確地模擬來自不同感測器的訊號，並將作業條件整合到模型架構中。我們使用兩個新發布的資料集評估 HTGNN：一個具有不同負載條件的軸承資料集，用於軸承負載預測，以及一個用於預測橋樑活載荷的長達一年的模擬資料集。我們的結果證明，在兩種任務中，HTGNN 都明顯優於既定的基準方法，特別是在高度變化的操作條件下。這些結果突顯了 HTGNN 作為複雜系統穩健且精確的虛擬感測方法的潛力，為改善監控、預測性維護和增強系統效能鋪路。

##### **Collaborative Evolving Strategy for Automatic Data-Centric Development**
2407.18690v1 by Xu Yang, Haotian Chen, Wenjun Feng, Haoxue Wang, Zeqi Ye, Xinjie Shen, Xiao Yang, Shizhao Sun, Weiqing Liu, Jiang Bian

Artificial Intelligence (AI) significantly influences many fields, largely
thanks to the vast amounts of high-quality data for machine learning models.
The emphasis is now on a data-centric AI strategy, prioritizing data
development over model design progress. Automating this process is crucial. In
this paper, we serve as the first work to introduce the automatic data-centric
development (AD^2) task and outline its core challenges, which require
domain-experts-like task scheduling and implementation capability, largely
unexplored by previous work.
  By leveraging the strong complex problem-solving capabilities of large
language models (LLMs), we propose an LLM-based autonomous agent, equipped with
a strategy named Collaborative Knowledge-STudying-Enhanced Evolution by
Retrieval (Co-STEER), to simultaneously address all the challenges.
Specifically, our proposed Co-STEER agent enriches its domain knowledge through
our proposed evolving strategy and develops both its scheduling and
implementation skills by accumulating and retrieving domain-specific practical
experience. With an improved schedule, the capability for implementation
accelerates. Simultaneously, as implementation feedback becomes more thorough,
the scheduling accuracy increases. These two capabilities evolve together
through practical feedback, enabling a collaborative evolution process.
  Extensive experimental results demonstrate that our Co-STEER agent breaks new
ground in AD^2 research, possesses strong evolvable schedule and implementation
ability, and demonstrates the significant effectiveness of its components. Our
Co-STEER paves the way for AD^2 advancements.

摘要：<paragraph>人工智慧 (AI) 在許多領域中產生了重大的影響，這在很大程度上要歸功於機器學習模型的大量高品質資料。現在的重點在於以資料為中心的 AI 策略，將資料開發優先於模型設計進度。自動化這個流程至關重要。在本文中，我們作為第一個介紹自動以資料為中心開發 (AD^2) 任務並概述其核心挑戰的工作，這些挑戰需要像領域專家一樣的任務排程和實作能力，而這在先前的研究中大多未被探討。
  透過利用大型語言模型 (LLM) 強大的複雜問題解決能力，我們提出一個基於 LLM 的自主代理，配備一個名為透過檢索進行協作知識研究增強演化 (Co-STEER) 的策略，以同時解決所有挑戰。
具體來說，我們提出的 Co-STEER 代理透過我們提出的演化策略豐富其領域知識，並透過累積和檢索特定領域的實務經驗來培養其排程和實作技能。透過改善的排程，實作能力加速。同時，隨著實作回饋變得更全面，排程準確度也會提高。這兩種能力透過實務回饋共同演化，促成協作演化流程。
  廣泛的實驗結果證明，我們的 Co-STEER 代理在 AD^2 研究中開創了新局，具備強大的可演化排程和實作能力，並證明了其組成部分的顯著有效性。我們的 Co-STEER 為 AD^2 的進步鋪平了道路。</paragraph>

##### **The BIAS Detection Framework: Bias Detection in Word Embeddings and Language Models for European Languages**
2407.18689v1 by Alexandre Puttick, Leander Rankwiler, Catherine Ikae, Mascha Kurpicz-Briki

The project BIAS: Mitigating Diversity Biases of AI in the Labor Market is a
four-year project funded by the European commission and supported by the Swiss
State Secretariat for Education, Research and Innovation (SERI). As part of the
project, novel bias detection methods to identify societal bias in language
models and word embeddings in European languages are developed, with particular
attention to linguistic and geographic particularities. This technical report
describes the overall architecture and components of the BIAS Detection
Framework. The code described in this technical report is available and will be
updated and expanded continuously with upcoming results from the BIAS project.
The details about the datasets for the different languages are described in
corresponding papers at scientific venues.

摘要：BIAS 專案：減輕勞動市場中 AI 的多元化偏見，是一個為期四年的專案，由歐洲委員會資助，並獲得瑞士教育、研究和創新國家秘書處 (SERI) 的支援。作為該專案的一部分，開發了新的偏見偵測方法，以識別歐洲語言中的語言模型和字詞嵌入中的社會偏見，特別注意語言和地理的特殊性。此技術報告描述了 BIAS 偵測架構的整體架構和組成部分。本技術報告中描述的程式碼已公開，並將持續更新和擴充，以納入 BIAS 專案的最新成果。不同語言的資料集詳細資訊已在科學場域的對應論文中說明。

##### **Every Part Matters: Integrity Verification of Scientific Figures Based on Multimodal Large Language Models**
2407.18626v1 by Xiang Shi, Jiawei Liu, Yinpeng Liu, Qikai Cheng, Wei Lu

This paper tackles a key issue in the interpretation of scientific figures:
the fine-grained alignment of text and figures. It advances beyond prior
research that primarily dealt with straightforward, data-driven visualizations
such as bar and pie charts and only offered a basic understanding of diagrams
through captioning and classification. We introduce a novel task, Figure
Integrity Verification, designed to evaluate the precision of technologies in
aligning textual knowledge with visual elements in scientific figures. To
support this, we develop a semi-automated method for constructing a large-scale
dataset, Figure-seg, specifically designed for this task. Additionally, we
propose an innovative framework, Every Part Matters (EPM), which leverages
Multimodal Large Language Models (MLLMs) to not only incrementally improve the
alignment and verification of text-figure integrity but also enhance integrity
through analogical reasoning. Our comprehensive experiments show that these
innovations substantially improve upon existing methods, allowing for more
precise and thorough analysis of complex scientific figures. This progress not
only enhances our understanding of multimodal technologies but also stimulates
further research and practical applications across fields requiring the
accurate interpretation of complex visual data.

摘要：這篇論文探討科學圖表解讀中的關鍵問題：文字和圖表的細粒度對齊。它超越了先前的研究，這些研究主要處理直接的、資料驅動的可視化，例如長條圖和圓餅圖，並且僅通過標題和分類提供了對圖表的基礎理解。我們引入了一項新任務，稱為圖表完整性驗證，旨在評估技術在將文字知識與科學圖表中的視覺元素對齊時的準確度。為了支持這一點，我們開發了一種半自動化的方法來構建一個專門為此任務設計的大規模資料集 Figure-seg。此外，我們提出了一個創新的框架，Every Part Matters (EPM)，它利用多模態大型語言模型 (MLLM) 不僅逐步改進文字圖表完整性的對齊和驗證，而且還通過類比推理增強完整性。我們的全面實驗表明，這些創新在現有方法的基礎上有了顯著的改進，允許對複雜的科學圖表進行更精確和徹底的分析。這項進展不僅增強了我們對多模態技術的理解，而且還激勵了跨領域的進一步研究和實際應用，這些領域需要準確解讀複雜的視覺資料。

##### **Topology Optimization of Random Memristors for Input-Aware Dynamic SNN**
2407.18625v1 by Bo Wang, Shaocong Wang, Ning Lin, Yi Li, Yifei Yu, Yue Zhang, Jichang Yang, Xiaoshan Wu, Yangu He, Songqi Wang, Rui Chen, Guoqi Li, Xiaojuan Qi, Zhongrui Wang, Dashan Shang

There is unprecedented development in machine learning, exemplified by recent
large language models and world simulators, which are artificial neural
networks running on digital computers. However, they still cannot parallel
human brains in terms of energy efficiency and the streamlined adaptability to
inputs of different difficulties, due to differences in signal representation,
optimization, run-time reconfigurability, and hardware architecture. To address
these fundamental challenges, we introduce pruning optimization for input-aware
dynamic memristive spiking neural network (PRIME). Signal representation-wise,
PRIME employs leaky integrate-and-fire neurons to emulate the brain's inherent
spiking mechanism. Drawing inspiration from the brain's structural plasticity,
PRIME optimizes the topology of a random memristive spiking neural network
without expensive memristor conductance fine-tuning. For runtime
reconfigurability, inspired by the brain's dynamic adjustment of computational
depth, PRIME employs an input-aware dynamic early stop policy to minimize
latency during inference, thereby boosting energy efficiency without
compromising performance. Architecture-wise, PRIME leverages memristive
in-memory computing, mirroring the brain and mitigating the von Neumann
bottleneck. We validated our system using a 40 nm 256 Kb memristor-based
in-memory computing macro on neuromorphic image classification and image
inpainting. Our results demonstrate the classification accuracy and Inception
Score are comparable to the software baseline, while achieving maximal
62.50-fold improvements in energy efficiency, and maximal 77.0% computational
load savings. The system also exhibits robustness against stochastic synaptic
noise of analogue memristors. Our software-hardware co-designed model paves the
way to future brain-inspired neuromorphic computing with brain-like energy
efficiency and adaptivity.

摘要：機器學習有空前的發展，最近的大語言模型和世界模擬器就是例證，它們是運作於數位電腦上的人工神經網路。然而，由於訊號表徵、最佳化、執行時間可重新組態性與硬體架構的差異，它們在能源效率和對不同難度輸入的簡化適應性方面，仍然無法與人腦並駕齊驅。為了應對這些基本挑戰，我們為輸入感知動態記憶電阻尖峰神經網路 (PRIME) 引進修剪最佳化。在訊號表徵方面，PRIME 採用漏電積分和發射神經元，模擬大腦固有的尖峰機制。PRIME 從大腦的結構可塑性中汲取靈感，最佳化隨機記憶電阻尖峰神經網路的拓撲，而無需昂貴的記憶電阻電導精細調整。對於執行時間可重新組態性，PRIME 受到大腦動態調整計算深度啟發，採用輸入感知動態早期停止策略，以在推論期間將延遲降至最低，從而提升能源效率，同時不損害效能。在架構方面，PRIME 充分利用記憶電阻內部記憶體運算，反映大腦並減輕馮紐曼瓶頸。我們使用 40 nm 256 Kb 基於記憶電阻的內部記憶體運算巨集，在神經形態影像分類和影像修復上驗證我們的系統。我們的結果顯示，分類準確度和 Inception 分數與軟體基準相當，同時在能源效率方面達到最大的 62.50 倍提升，並在計算負載方面節省最多 77.0%。該系統還展現出對類比記憶電阻的隨機突觸雜訊的穩健性。我們軟體硬體共同設計的模型，為未來具備大腦般能源效率和適應性的、受大腦啟發的神經形態運算鋪路。

##### **Using GPT-4 to guide causal machine learning**
2407.18607v1 by Anthony C. Constantinou, Neville K. Kitson, Alessio Zanga

Since its introduction to the public, ChatGPT has had an unprecedented
impact. While some experts praised AI advancements and highlighted their
potential risks, others have been critical about the accuracy and usefulness of
Large Language Models (LLMs). In this paper, we are interested in the ability
of LLMs to identify causal relationships. We focus on the well-established
GPT-4 (Turbo) and evaluate its performance under the most restrictive
conditions, by isolating its ability to infer causal relationships based solely
on the variable labels without being given any context, demonstrating the
minimum level of effectiveness one can expect when it is provided with
label-only information. We show that questionnaire participants judge the GPT-4
graphs as the most accurate in the evaluated categories, closely followed by
knowledge graphs constructed by domain experts, with causal Machine Learning
(ML) far behind. We use these results to highlight the important limitation of
causal ML, which often produces causal graphs that violate common sense,
affecting trust in them. However, we show that pairing GPT-4 with causal ML
overcomes this limitation, resulting in graphical structures learnt from real
data that align more closely with those identified by domain experts, compared
to structures learnt by causal ML alone. Overall, our findings suggest that
despite GPT-4 not being explicitly designed to reason causally, it can still be
a valuable tool for causal representation, as it improves the causal discovery
process of causal ML algorithms that are designed to do just that.

摘要：自 ChatGPT 向公众发布以来，它产生了前所未有的影响。虽然一些专家赞扬了 AI 的进步并强调了其潜在风险，但其他人一直批评大型语言模型 (LLM) 的准确性和有用性。在本文中，我们对 LLM 识别因果关系的能力感兴趣。我们专注于成熟的 GPT-4（Turbo），并在最严格的条件下评估其性能，通过孤立其仅根据变量标签推断因果关系的能力，而不提供任何上下文，展示了当仅提供标签信息时人们可以预期的最低有效性水平。我们表明，问卷参与者认为 GPT-4 图形在评估类别中是最准确的，紧随其后的是由领域专家构建的知识图谱，因果机器学习 (ML) 远远落后。我们使用这些结果来强调因果 ML 的重要局限性，它经常产生违背常识的因果图，影响人们对它们的信任。然而，我们表明将 GPT-4 与因果 ML 配对可以克服这一限制，从而产生从真实数据中学到的图形结构，与领域专家识别的结构相比，更紧密地与之对齐，而不是仅由因果 ML 学到的结构。总体而言，我们的研究结果表明，尽管 GPT-4 并未明确设计为因果推理，但它仍然可以成为因果表示的宝贵工具，因为它改进了旨在执行此操作的因果 ML 算法的因果发现过程。

##### **Climbing the Complexity Ladder with Expressive Attention**
2407.18601v1 by Claudius Gros

Attention involves comparing query and key vectors in terms of a scalar
product, $\mathbf{Q}^T\mathbf{K}$, together with a subsequent softmax
normalization. Classicaly, parallel/orthogonal/antiparallel queries and keys
lead to large/intermediate/small attention weights. Here we study expressive
attention (EA), which is based on $(\mathbf{Q}^T\mathbf{K})^2$, the squared dot
product. In this case attention is enhanced when query and key are either
parallel or antiparallel, and suppressed for orthogonal configurations. For a
series of autoregressive prediction tasks, we find that EA performs at least as
well as the standard mechanism, dot-product attention (DPA). Increasing task
complexity, EA is observed to outperform DPA with increasing margins, which
also holds for multi-task settings. For a given model size, EA manages to
achieve 100\% performance for a range of complexity levels not accessible to
DPA.

摘要：注意力涉及以标量积 $\mathbf{Q}^T\mathbf{K}$ 比较查询和键向量，以及随后的 softmax 归一化。经典地，平行的/正交的/反平行的查询和键导致大的/中等的/小的注意力权重。在这里，我们研究基于 $(\mathbf{Q}^T\mathbf{K})^2$ 的平方点积的表达式注意力 (EA)。在这种情况下，当查询和键平行或反平行时，注意力会增强，而当正交配置时，注意力会被抑制。对于一系列自回归预测任务，我们发现 EA 的表现至少与标准机制点积注意力 (DPA) 一样好。随着任务复杂性的增加，观察到 EA 以越来越大的优势优于 DPA，这也适用于多任务设置。对于给定的模型大小，EA 设法针对 DPA 无法达到的复杂度级别范围实现 100% 的性能。

##### **Reinforcement Learning for Sustainable Energy: A Survey**
2407.18597v1 by Koen Ponse, Felix Kleuker, Márton Fejér, Álvaro Serra-Gómez, Aske Plaat, Thomas Moerland

The transition to sustainable energy is a key challenge of our time,
requiring modifications in the entire pipeline of energy production, storage,
transmission, and consumption. At every stage, new sequential decision-making
challenges emerge, ranging from the operation of wind farms to the management
of electrical grids or the scheduling of electric vehicle charging stations.
All such problems are well suited for reinforcement learning, the branch of
machine learning that learns behavior from data. Therefore, numerous studies
have explored the use of reinforcement learning for sustainable energy. This
paper surveys this literature with the intention of bridging both the
underlying research communities: energy and machine learning. After a brief
introduction of both fields, we systematically list relevant sustainability
challenges, how they can be modeled as a reinforcement learning problem, and
what solution approaches currently exist in the literature. Afterwards, we zoom
out and identify overarching reinforcement learning themes that appear
throughout sustainability, such as multi-agent, offline, and safe reinforcement
learning. Lastly, we also cover standardization of environments, which will be
crucial for connecting both research fields, and highlight potential directions
for future work. In summary, this survey provides an extensive overview of
reinforcement learning methods for sustainable energy, which may play a vital
role in the energy transition.

摘要：<paragraph>轉向永續能源是我們時代的一項關鍵挑戰，
需要修改能源生產、儲存、傳輸和消耗的整個管線。在每個階段，都會出現新的順序決策挑戰，從風力發電場的運作到電網管理或電動車充電站的排程。
所有這些問題都非常適合強化學習，這是機器學習的一個分支，從資料中學習行為。因此，許多研究已經探討了將強化學習應用於永續能源。這篇論文調查了這份文獻，目的是橋接能源和機器學習這兩個基礎研究社群。在簡要介紹這兩個領域後，我們系統性地列出相關永續性挑戰、它們如何建模為強化學習問題，以及目前文獻中存在哪些解決方案。之後，我們縮小範圍並找出貫穿永續性的整體強化學習主題，例如多重代理、離線和安全的強化學習。最後，我們也涵蓋環境標準化，這對於連結兩個研究領域至關重要，並重點說明未來工作的潛在方向。總之，這項調查提供了強化學習方法在永續能源方面的廣泛概述，這可能在能源轉型中扮演至關重要的角色。</paragraph>

##### **Dynamic Language Group-Based MoE: Enhancing Efficiency and Flexibility for Code-Switching Speech Recognition**
2407.18581v1 by Hukai Huang, Shenghui Lu, Yahui Shan, He Qu, Wenhao Guan, Qingyang Hong, Lin Li

The Mixture of Experts (MoE) approach is ideally suited for tackling
multilingual and code-switching (CS) challenges due to its multi-expert
architecture. This work introduces the DLG-MoE, which is optimized for
bilingual and CS scenarios. Our novel Dynamic Language Group-based MoE layer
features a language router with shared weights for explicit language modeling,
while independent unsupervised routers within the language group handle
attributes beyond language. This structure not only enhances expert extension
capabilities but also supports dynamic top-k training, allowing for flexible
inference across various top-k values and improving overall performance. The
model requires no pre-training and supports streaming recognition, achieving
state-of-the-art (SOTA) results with unmatched flexibility compared to other
methods. The Code will be released.

摘要：專家混合 (MoE) 方法由於其多專家架構，非常適合解決多語言和語碼轉換 (CS) 的挑戰。這項工作引入了 DLG-MoE，它針對雙語和 CS 場景進行了最佳化。我們創新的基於動態語言群組的 MoE 層具有語言路由器，具有用於明確語言建模的共享權重，而語言群組內的獨立非監督路由器處理語言之外的屬性。此結構不僅增強了專家擴充功能，還支援動態 top-k 訓練，允許跨各種 top-k 值進行靈活推論並改善整體效能。該模型不需要預訓練並支援串流辨識，與其他方法相比，它實現了最先進 (SOTA) 的結果，並具有無與倫比的靈活性。程式碼將會釋出。

##### **Speech Bandwidth Expansion Via High Fidelity Generative Adversarial Networks**
2407.18571v1 by Mahmoud Salhab, Haidar Harmanani

Speech bandwidth expansion is crucial for expanding the frequency range of
low-bandwidth speech signals, thereby improving audio quality, clarity and
perceptibility in digital applications. Its applications span telephony,
compression, text-to-speech synthesis, and speech recognition. This paper
presents a novel approach using a high-fidelity generative adversarial network,
unlike cascaded systems, our system is trained end-to-end on paired narrowband
and wideband speech signals. Our method integrates various bandwidth upsampling
ratios into a single unified model specifically designed for speech bandwidth
expansion applications. Our approach exhibits robust performance across various
bandwidth expansion factors, including those not encountered during training,
demonstrating zero-shot capability. To the best of our knowledge, this is the
first work to showcase this capability. The experimental results demonstrate
that our method outperforms previous end-to-end approaches, as well as
interpolation and traditional techniques, showcasing its effectiveness in
practical speech enhancement applications.

摘要：語音頻寬擴展對於擴展低頻寬語音訊號的頻率範圍至關重要，從而提高數位應用中的音訊品質、清晰度和可感知度。其應用涵蓋電話、壓縮、文字轉語音合成和語音辨識。本文提出了一種使用高保真生成對抗網路的新方法，與串聯系統不同，我們的系統在配對的窄頻和寬頻語音訊號上進行端對端訓練。我們的模型將各種頻寬上採樣比率整合到一個單一的統一模型中，專門設計用於語音頻寬擴展應用。我們的模型在各種頻寬擴展因子中展現出強健的效能，包括在訓練期間未遇到的因子，證明了零次學習能力。據我們所知，這是第一個展示此能力的研究。實驗結果證明，我們的模型優於先前的端對端方法，以及插值和傳統技術，證明了其在實用的語音增強應用中的有效性。

##### **PP-TIL: Personalized Planning for Autonomous Driving with Instance-based Transfer Imitation Learning**
2407.18569v1 by Fangze Lin, Ying He, Fei Yu

Personalized motion planning holds significant importance within urban
automated driving, catering to the unique requirements of individual users.
Nevertheless, prior endeavors have frequently encountered difficulties in
simultaneously addressing two crucial aspects: personalized planning within
intricate urban settings and enhancing planning performance through data
utilization. The challenge arises from the expensive and limited nature of user
data, coupled with the scene state space tending towards infinity. These
factors contribute to overfitting and poor generalization problems during model
training. Henceforth, we propose an instance-based transfer imitation learning
approach. This method facilitates knowledge transfer from extensive expert
domain data to the user domain, presenting a fundamental resolution to these
issues. We initially train a pre-trained model using large-scale expert data.
Subsequently, during the fine-tuning phase, we feed the batch data, which
comprises expert and user data. Employing the inverse reinforcement learning
technique, we extract the style feature distribution from user demonstrations,
constructing the regularization term for the approximation of user style. In
our experiments, we conducted extensive evaluations of the proposed method.
Compared to the baseline methods, our approach mitigates the overfitting issue
caused by sparse user data. Furthermore, we discovered that integrating the
driving model with a differentiable nonlinear optimizer as a safety protection
layer for end-to-end personalized fine-tuning results in superior planning
performance.

摘要：個人化路徑規劃在城市自動駕駛中具有重要意義，滿足個別使用者的獨特需求。然而，先前的努力經常遇到困難，無法同時解決兩個關鍵方面：複雜城市環境中的個人化規劃，以及透過資料利用來提升規劃效能。挑戰來自於使用者資料昂貴且有限的性質，再加上場景狀態空間趨近於無限大。這些因素導致過度擬合和模型訓練期間的概化問題不佳。因此，我們提出一個基於實例的轉移模擬學習方法。此方法促進從廣泛的專家領域資料到使用者領域的知識轉移，為這些問題提供一個基本的解決方案。我們最初使用大規模的專家資料訓練一個預訓練模型。隨後，在微調階段，我們提供包含專家和使用者資料的批次資料。運用逆向強化學習技術，我們從使用者示範中提取樣式特徵分佈，建構使用者樣式近似的正則化項。在我們的實驗中，我們對所提出的方法進行了廣泛的評估。與基準方法相比，我們的做法減輕了稀疏使用者資料所造成的過度擬合問題。此外，我們發現將駕駛模型與可微非線性最佳化器整合為端到端個人化微調的安全防護層，可帶來優異的規劃效能。

##### **Learning Robust Named Entity Recognizers From Noisy Data With Retrieval Augmentation**
2407.18562v1 by Chaoyi Ai, Yong Jiang, Shen Huang, Pengjun Xie, Kewei Tu

Named entity recognition (NER) models often struggle with noisy inputs, such
as those with spelling mistakes or errors generated by Optical Character
Recognition processes, and learning a robust NER model is challenging. Existing
robust NER models utilize both noisy text and its corresponding gold text for
training, which is infeasible in many real-world applications in which gold
text is not available. In this paper, we consider a more realistic setting in
which only noisy text and its NER labels are available. We propose to retrieve
relevant text of the noisy text from a knowledge corpus and use it to enhance
the representation of the original noisy input. We design three retrieval
methods: sparse retrieval based on lexicon similarity, dense retrieval based on
semantic similarity, and self-retrieval based on task-specific text. After
retrieving relevant text, we concatenate the retrieved text with the original
noisy text and encode them with a transformer network, utilizing self-attention
to enhance the contextual token representations of the noisy text using the
retrieved text. We further employ a multi-view training framework that improves
robust NER without retrieving text during inference. Experiments show that our
retrieval-augmented model achieves significant improvements in various noisy
NER settings.

摘要：命名實體辨識 (NER) 模型通常難以處理有雜訊的輸入，例如拼寫錯誤或光學字元辨識程序產生的錯誤，而學習穩健的 NER 模型具有挑戰性。現有的穩健 NER 模型同時利用有雜訊的文字及其對應的黃金文字進行訓練，這在許多現實世界的應用中是不可行的，因為黃金文字不可用。在本文中，我們考慮一個更實際的設定，其中只有有雜訊的文字及其 NER 標籤可用。我們提議從知識語料庫中擷取有雜訊文字的相关文字，並使用它來增強原始有雜訊輸入的表示。我們設計了三種擷取方法：基於詞彙相似性的稀疏擷取、基於語義相似性的稠密擷取，以及基於特定任務文字的自擷取。在擷取相關文字後，我們將擷取的文字與原始有雜訊文字串接，並使用Transformer網路對它們進行編碼，利用自我注意來使用擷取的文字增強有雜訊文字的語境標記表示。我們進一步採用多視角訓練架構，它在推理過程中不擷取文字就能改善穩健的 NER。實驗表明，我們的擷取增強模型在各種有雜訊的 NER 設定中取得顯著的改進。

##### **Look Globally and Reason: Two-stage Path Reasoning over Sparse Knowledge Graphs**
2407.18556v1 by Saiping Guan, Jiyao Wei, Xiaolong Jin, Jiafeng Guo, Xueqi Cheng

Sparse Knowledge Graphs (KGs), frequently encountered in real-world
applications, contain fewer facts in the form of (head entity, relation, tail
entity) compared to more populated KGs. The sparse KG completion task, which
reasons answers for given queries in the form of (head entity, relation, ?) for
sparse KGs, is particularly challenging due to the necessity of reasoning
missing facts based on limited facts. Path-based models, known for excellent
explainability, are often employed for this task. However, existing path-based
models typically rely on external models to fill in missing facts and
subsequently perform path reasoning. This approach introduces unexplainable
factors or necessitates meticulous rule design. In light of this, this paper
proposes an alternative approach by looking inward instead of seeking external
assistance. We introduce a two-stage path reasoning model called LoGRe (Look
Globally and Reason) over sparse KGs. LoGRe constructs a relation-path
reasoning schema by globally analyzing the training data to alleviate the
sparseness problem. Based on this schema, LoGRe then aggregates paths to reason
out answers. Experimental results on five benchmark sparse KG datasets
demonstrate the effectiveness of the proposed LoGRe model.

摘要：稀疏知識圖譜 (KG) 在現實世界的應用中經常遇到，與較多填充的 KG 相比，它包含較少以 (頭實體、關係、尾實體) 形式表示的事實。稀疏 KG 完成任務，它會根據以 (頭實體、關係、?) 形式給定的查詢推理出答案，由於必須根據有限的事實推理出缺失的事實，因此特別具有挑戰性。基於路徑的模型以其出色的可解釋性而聞名，通常用於此任務。然而，現有的基於路徑的模型通常依賴外部模型來填補缺失的事實，然後執行路徑推理。這種方法引入了無法解釋的因素，或需要細緻的規則設計。有鑑於此，本文提出了一種替代方法，即向內看而不是尋求外部協助。我們介紹了一個名為 LoGRe (全局觀察並推理) 的兩階段路徑推理模型，用於稀疏 KG。LoGRe 通過全局分析訓練資料來建構關係路徑推理架構，以減輕稀疏性問題。根據此架構，LoGRe 接著聚合路徑來推理出答案。在五個基準稀疏 KG 資料集上的實驗結果證明了所提出的 LoGRe 模型的有效性。

##### **How To Segment in 3D Using 2D Models: Automated 3D Segmentation of Prostate Cancer Metastatic Lesions on PET Volumes Using Multi-Angle Maximum Intensity Projections and Diffusion Models**
2407.18555v1 by Amirhosein Toosi, Sara Harsini, François Bénard, Carlos Uribe, Arman Rahmim

Prostate specific membrane antigen (PSMA) positron emission
tomography/computed tomography (PET/CT) imaging provides a tremendously
exciting frontier in visualization of prostate cancer (PCa) metastatic lesions.
However, accurate segmentation of metastatic lesions is challenging due to low
signal-to-noise ratios and variable sizes, shapes, and locations of the
lesions. This study proposes a novel approach for automated segmentation of
metastatic lesions in PSMA PET/CT 3D volumetric images using 2D denoising
diffusion probabilistic models (DDPMs). Instead of 2D trans-axial slices or 3D
volumes, the proposed approach segments the lesions on generated multi-angle
maximum intensity projections (MA-MIPs) of the PSMA PET images, then obtains
the final 3D segmentation masks from 3D ordered subset expectation maximization
(OSEM) reconstruction of 2D MA-MIPs segmentations. Our proposed method achieved
superior performance compared to state-of-the-art 3D segmentation approaches in
terms of accuracy and robustness in detecting and segmenting small metastatic
PCa lesions. The proposed method has significant potential as a tool for
quantitative analysis of metastatic burden in PCa patients.

摘要：前列腺特异性膜抗原 (PSMA) 正电子发射断层扫描/计算机断层扫描 (PET/CT) 影像在可视化前列腺癌 (PCa) 转移灶方面提供了极具吸引力的前沿。
然而，由于信噪比低以及病灶大小、形状和位置的变化，准确分割转移灶具有挑战性。
本研究提出了一种新颖的方法，用于使用 2D 去噪扩散概率模型 (DDPM) 自动分割 PSMA PET/CT 3D 体积图像中的转移灶。
所提出的方法不是对 2D 横轴切片或 3D 体积进行分割，而是对 PSMA PET 图像生成的多分辨率最大强度投影 (MA-MIP) 进行分割，然后从 2D MA-MIP 分割的 3D 有序子集期望最大化 (OSEM) 重建中获取最终 3D 分割掩模。
与最先进的 3D 分割方法相比，我们提出的方法在检测和分割小型转移性 PCa 病灶方面实现了更高的准确性和鲁棒性。
所提出的方法作为一种工具具有显著的潜力，用于对 PCa 患者的转移负荷进行定量分析。

##### **Multimodal Emotion Recognition using Audio-Video Transformer Fusion with Cross Attention**
2407.18552v1 by Joe Dhanith P R, Shravan Venkatraman, Vigya Sharma, Santhosh Malarvannan

Understanding emotions is a fundamental aspect of human communication.
Integrating audio and video signals offers a more comprehensive understanding
of emotional states compared to traditional methods that rely on a single data
source, such as speech or facial expressions. Despite its potential, multimodal
emotion recognition faces significant challenges, particularly in
synchronization, feature extraction, and fusion of diverse data sources. To
address these issues, this paper introduces a novel transformer-based model
named Audio-Video Transformer Fusion with Cross Attention (AVT-CA). The AVT-CA
model employs a transformer fusion approach to effectively capture and
synchronize interlinked features from both audio and video inputs, thereby
resolving synchronization problems. Additionally, the Cross Attention mechanism
within AVT-CA selectively extracts and emphasizes critical features while
discarding irrelevant ones from both modalities, addressing feature extraction
and fusion challenges. Extensive experimental analysis conducted on the
CMU-MOSEI, RAVDESS and CREMA-D datasets demonstrates the efficacy of the
proposed model. The results underscore the importance of AVT-CA in developing
precise and reliable multimodal emotion recognition systems for practical
applications.

摘要：理解情緒是人類溝通的基本面向。
相較於依賴單一資料來源（例如語音或面部表情）的傳統方法，整合音訊和視訊訊號能提供對情緒狀態更全面的理解。儘管具有潛力，多模態情緒辨識仍面臨重大挑戰，特別是在同步化、特徵萃取和不同資料來源的融合方面。為了解決這些問題，本文介紹了一個名為音訊視訊轉換器融合帶交叉注意力的新穎轉換器模型（AVT-CA）。AVT-CA 模型採用轉換器融合方法，以有效擷取和同步來自音訊和視訊輸入的相互連結特徵，從而解決同步化問題。此外，AVT-CA 內部的交叉注意力機制會選擇性地萃取和強調關鍵特徵，同時捨棄來自兩種模態的不相關特徵，解決了特徵萃取和融合的挑戰。在 CMU-MOSEI、RAVDESS 和 CREMA-D 資料集上進行的廣泛實驗分析證明了所提出模型的效能。結果強調了 AVT-CA 在開發精確且可靠的多模態情緒辨識系統以供實際應用中的重要性。

##### **ReALFRED: An Embodied Instruction Following Benchmark in Photo-Realistic Environments**
2407.18550v1 by Taewoong Kim, Cheolhong Min, Byeonghwi Kim, Jinyeon Kim, Wonje Jeung, Jonghyun Choi

Simulated virtual environments have been widely used to learn robotic agents
that perform daily household tasks. These environments encourage research
progress by far, but often provide limited object interactability, visual
appearance different from real-world environments, or relatively smaller
environment sizes. This prevents the learned models in the virtual scenes from
being readily deployable. To bridge the gap between these learning environments
and deploying (i.e., real) environments, we propose the ReALFRED benchmark that
employs real-world scenes, objects, and room layouts to learn agents to
complete household tasks by understanding free-form language instructions and
interacting with objects in large, multi-room and 3D-captured scenes.
Specifically, we extend the ALFRED benchmark with updates for larger
environmental spaces with smaller visual domain gaps. With ReALFRED, we analyze
previously crafted methods for the ALFRED benchmark and observe that they
consistently yield lower performance in all metrics, encouraging the community
to develop methods in more realistic environments. Our code and data are
publicly available.

摘要：模擬虛擬環境已被廣泛用於學習執行日常家務任務的機器人代理。這些環境極大地促進了研究進度，但通常提供有限的物件互動性、與真實世界環境不同的視覺外觀，或相對較小的環境大小。這會讓虛擬場景中學習的模型無法輕易地部署。為了彌補這些學習環境與部署（即真實）環境之間的差距，我們提出了 ReALFRED 基準，它採用真實世界的場景、物件和房間佈局來學習代理，藉由理解自由形式的語言指令並與大型、多房間和 3D 擷取場景中的物件互動，來完成家務任務。具體來說，我們擴充了 ALFRED 基準，以更新較大環境空間的較小視覺域差距。透過 ReALFRED，我們分析了先前為 ALFRED 基準製作的方法，並觀察到它們在所有指標中持續產生較低的效能，鼓勵社群在更逼真的環境中開發方法。我們的程式碼和資料已公開。

##### **Towards Improving NAM-to-Speech Synthesis Intelligibility using Self-Supervised Speech Models**
2407.18541v1 by Neil Shah, Shirish Karande, Vineet Gandhi

We propose a novel approach to significantly improve the intelligibility in
the Non-Audible Murmur (NAM)-to-speech conversion task, leveraging
self-supervision and sequence-to-sequence (Seq2Seq) learning techniques. Unlike
conventional methods that explicitly record ground-truth speech, our
methodology relies on self-supervision and speech-to-speech synthesis to
simulate ground-truth speech. Despite utilizing simulated speech, our method
surpasses the current state-of-the-art (SOTA) by 29.08% improvement in the
Mel-Cepstral Distortion (MCD) metric. Additionally, we present error rates and
demonstrate our model's proficiency to synthesize speech in novel voices of
interest. Moreover, we present a methodology for augmenting the existing CSTR
NAM TIMIT Plus corpus, setting a benchmark with a Word Error Rate (WER) of
42.57% to gauge the intelligibility of the synthesized speech. Speech samples
can be found at https://nam2speech.github.io/NAM2Speech/

摘要：我們提出了一種新穎的方法，可以顯著提高非可聽雜音 (NAM) 轉換為語音任務中的可懂度，利用自我監督和序列到序列 (Seq2Seq) 學習技術。與明確記錄真實語音的傳統方法不同，我們的技術依賴於自我監督和語音到語音合成來模擬真實語音。儘管使用模擬語音，我們的技術在 Mel-Cepstral Distortion (MCD) 指標中超越了現有的最先進 (SOTA) 技術，改進了 29.08%。此外，我們提供了錯誤率，並展示了我們的模型在合成新穎的目標語音方面的熟練度。此外，我們提出了一種擴充現有 CSTR NAM TIMIT Plus 語料庫的方法，並設定了詞語錯誤率 (WER) 為 42.57% 的基準，以評估合成語音的可懂度。可以在 https://nam2speech.github.io/NAM2Speech/ 找到語音範例

##### **A Universal Prompting Strategy for Extracting Process Model Information from Natural Language Text using Large Language Models**
2407.18540v1 by Julian Neuberger, Lars Ackermann, Han van der Aa, Stefan Jablonski

Over the past decade, extensive research efforts have been dedicated to the
extraction of information from textual process descriptions. Despite the
remarkable progress witnessed in natural language processing (NLP), information
extraction within the Business Process Management domain remains predominantly
reliant on rule-based systems and machine learning methodologies. Data scarcity
has so far prevented the successful application of deep learning techniques.
However, the rapid progress in generative large language models (LLMs) makes it
possible to solve many NLP tasks with very high quality without the need for
extensive data. Therefore, we systematically investigate the potential of LLMs
for extracting information from textual process descriptions, targeting the
detection of process elements such as activities and actors, and relations
between them. Using a heuristic algorithm, we demonstrate the suitability of
the extracted information for process model generation. Based on a novel
prompting strategy, we show that LLMs are able to outperform state-of-the-art
machine learning approaches with absolute performance improvements of up to 8\%
$F_1$ score across three different datasets. We evaluate our prompting strategy
on eight different LLMs, showing it is universally applicable, while also
analyzing the impact of certain prompt parts on extraction quality. The number
of example texts, the specificity of definitions, and the rigour of format
instructions are identified as key for improving the accuracy of extracted
information. Our code, prompts, and data are publicly available.

摘要：<paragraph>在過去十年中，廣泛的研究工作致力於從文本流程描述中提取資訊。儘管自然語言處理 (NLP) 取得了顯著進展，但商業流程管理領域內的資訊提取仍然主要依賴於基於規則的系統和機器學習方法。迄今為止，資料稀少阻礙了深度學習技術的成功應用。然而，生成式大型語言模型 (LLM) 的快速進展使得在無需大量資料的情況下，以極高的品質解決許多 NLP 任務成為可能。因此，我們系統性地探討了 LLM 從文本流程描述中提取資訊的潛力，目標是偵測流程元素，例如活動和參與者，以及它們之間的關係。使用啟發式演算法，我們證明了提取資訊適用於流程模型生成。基於創新的提示策略，我們展示了 LLM 能夠優於最先進的機器學習方法，在三個不同的資料集上，$F_1$ 分數的絕對效能提升高達 8%。我們在八個不同的 LLM 上評估我們的提示策略，顯示它具有普遍適用的性，同時也分析了特定提示部分對提取品質的影響。範例文字數量、定義的具體性以及格式說明的嚴謹性被認為是提高提取資訊準確性的關鍵。我們的程式碼、提示和資料皆公開提供。</paragraph>

##### **Towards a Multidimensional Evaluation Framework for Empathetic Conversational Systems**
2407.18538v1 by Aravind Sesagiri Raamkumar, Siyuan Brandon Loh

Empathetic Conversational Systems (ECS) are built to respond empathetically
to the user's emotions and sentiments, regardless of the application domain.
Current ECS studies evaluation approaches are restricted to offline evaluation
experiments primarily for gold standard comparison & benchmarking, and user
evaluation studies for collecting human ratings on specific constructs. These
methods are inadequate in measuring the actual quality of empathy in
conversations. In this paper, we propose a multidimensional empathy evaluation
framework with three new methods for measuring empathy at (i) structural level
using three empathy-related dimensions, (ii) behavioral level using empathy
behavioral types, and (iii) overall level using an empathy lexicon, thereby
fortifying the evaluation process. Experiments were conducted with the
state-of-the-art ECS models and large language models (LLMs) to show the
framework's usefulness.

摘要：同理心對話系統（ECS）旨在對使用者的情緒和感受做出同理心的回應，不論應用領域為何。目前的 ECS 研究評估方法僅限於離線評估實驗，主要是用於黃金標準比較和基準測試，以及使用者評估研究，以收集特定建構的人類評分。這些方法無法充分衡量對話中的同理心實際品質。在本文中，我們提出一個多面向的同理心評估架構，包含三種新的方法，用於衡量同理心，包括（一）使用三個同理心相關面向的結構層級、（二）使用同理心行為類型的行為層級，以及（三）使用同理心詞彙的整體層級，從而強化評估流程。我們使用最先進的 ECS 模型和大型語言模型（LLM）進行實驗，以顯示此架構的實用性。

##### **Outer Approximation and Super-modular Cuts for Constrained Assortment Optimization under Mixed-Logit Model**
2407.18532v1 by Hoang Giang Pham, Tien Mai

In this paper, we study the assortment optimization problem under the
mixed-logit customer choice model. While assortment optimization has been a
major topic in revenue management for decades, the mixed-logit model is
considered one of the most general and flexible approaches for modeling and
predicting customer purchasing behavior. Existing exact methods have primarily
relied on mixed-integer linear programming (MILP) or second-order cone (CONIC)
reformulations, which allow for exact problem solving using off-the-shelf
solvers. However, these approaches often suffer from weak continuous
relaxations and are slow when solving large instances. Our work addresses the
problem by focusing on components of the objective function that can be proven
to be monotonically super-modular and convex. This allows us to derive valid
cuts to outer-approximate the nonlinear objective functions. We then
demonstrate that these valid cuts can be incorporated into Cutting Plane or
Branch-and-Cut methods to solve the problem exactly. Extensive experiments show
that our approaches consistently outperform previous methods in terms of both
solution quality and computation time.

摘要：在本文中，我们研究了混合 logit 客户选择模型下的分类优化问题。虽然分类优化几十年来一直是收益管理中的一个主要课题，但混合 logit 模型被认为是建模和预测客户购买行为的最通用和灵活的方法之一。现有的精确方法主要依赖于混合整数线性规划 (MILP) 或二阶锥 (CONIC) 重构，这允许使用现成的求解器进行精确的问题求解。然而，这些方法通常会因连续松弛而变得脆弱，并且在求解大型实例时速度很慢。我们的工作通过关注目标函数的组成部分来解决这个问题，该组成部分可以被证明是单调超模态和凸的。这使我们能够导出有效的割集来外近似非线性目标函数。然后我们证明了这些有效割集可以合并到切割平面或分支切割方法中，以精确求解问题。大量的实验表明，我们的方法在求解质量和计算时间方面始终优于以前的方法。

##### **Is larger always better? Evaluating and prompting large language models for non-generative medical tasks**
2407.18525v1 by Yinghao Zhu, Junyi Gao, Zixiang Wang, Weibin Liao, Xiaochen Zheng, Lifang Liang, Yasha Wang, Chengwei Pan, Ewen M. Harrison, Liantao Ma

The use of Large Language Models (LLMs) in medicine is growing, but their
ability to handle both structured Electronic Health Record (EHR) data and
unstructured clinical notes is not well-studied. This study benchmarks various
models, including GPT-based LLMs, BERT-based models, and traditional clinical
predictive models, for non-generative medical tasks utilizing renowned
datasets. We assessed 14 language models (9 GPT-based and 5 BERT-based) and 7
traditional predictive models using the MIMIC dataset (ICU patient records) and
the TJH dataset (early COVID-19 EHR data), focusing on tasks such as mortality
and readmission prediction, disease hierarchy reconstruction, and biomedical
sentence matching, comparing both zero-shot and finetuned performance. Results
indicated that LLMs exhibited robust zero-shot predictive capabilities on
structured EHR data when using well-designed prompting strategies, frequently
surpassing traditional models. However, for unstructured medical texts, LLMs
did not outperform finetuned BERT models, which excelled in both supervised and
unsupervised tasks. Consequently, while LLMs are effective for zero-shot
learning on structured data, finetuned BERT models are more suitable for
unstructured texts, underscoring the importance of selecting models based on
specific task requirements and data characteristics to optimize the application
of NLP technology in healthcare.

摘要：大型語言模型 (LLM) 在醫學中的應用日益廣泛，但它們同時處理結構化電子病歷 (EHR) 資料和非結構化臨床註記的能力尚未得到充分研究。本研究針對各種模型進行基準測試，包括基於 GPT 的 LLM、基於 BERT 的模型，以及傳統的臨床預測模型，用於利用著名資料集的非生成性醫療任務。我們使用 MIMIC 資料集（ICU 病人記錄）和 TJH 資料集（早期 COVID-19 EHR 資料）評估了 14 個語言模型（9 個基於 GPT，5 個基於 BERT）和 7 個傳統預測模型，重點關注死亡率和再入院預測、疾病層級重建和生物醫學句子配對等任務，並比較了零次學習和微調後的效能。結果表明，LLM 在使用設計良好的提示策略時，對結構化 EHR 資料展現出強大的零次學習預測能力，經常超越傳統模型。然而，對於非結構化的醫療文本，LLM 的表現不如微調後的 BERT 模型，後者在監督式和非監督式任務中都表現出色。因此，儘管 LLM 對於結構化資料的零次學習很有用，但微調後的 BERT 模型更適合非結構化文本，這強調了根據特定任務需求和資料特性選擇模型以優化醫療保健中 NLP 技術應用之重要性。

##### **She Works, He Works: A Curious Exploration of Gender Bias in AI-Generated Imagery**
2407.18524v1 by Amalia Foka

This paper examines gender bias in AI-generated imagery of construction
workers, highlighting discrepancies in the portrayal of male and female
figures. Grounded in Griselda Pollock's theories on visual culture and gender,
the analysis reveals that AI models tend to sexualize female figures while
portraying male figures as more authoritative and competent. These findings
underscore AI's potential to mirror and perpetuate societal biases, emphasizing
the need for critical engagement with AI-generated content. The project
contributes to discussions on the ethical implications of AI in creative
practices and its broader impact on cultural perceptions of gender.

摘要：這篇論文探討了 AI 生成的建築工人圖像中的性別偏見，重點說明男性和女性人物描繪上的差異。分析根據 Griselda Pollock 的視覺文化和性別理論為基礎，揭示 AI 模型傾向於將女性人物性化，同時將男性人物描繪得更具權威和能力。這些發現強調了 AI 可能反映和延續社會偏見，突顯了批判性地參與 AI 生成的內容的重要性。該專案有助於討論 AI 在創意實務中的倫理意涵，以及其對性別文化認知的更廣泛影響。

##### **Patched MOA: optimizing inference for diverse software development tasks**
2407.18521v1 by Asankhaya Sharma

This paper introduces Patched MOA (Mixture of Agents), an inference
optimization technique that significantly enhances the performance of large
language models (LLMs) across diverse software development tasks. We evaluate
three inference optimization algorithms - Best of N, Mixture of Agents, and
Monte Carlo Tree Search and demonstrate that Patched MOA can boost the
performance of smaller models to surpass that of larger, more expensive models.
Notably, our approach improves the gpt-4o-mini model's performance on the
Arena-Hard-Auto benchmark by 15.52%, outperforming gpt-4-turbo at a fraction of
the cost. We also apply Patched MOA to various software development workflows,
showing consistent improvements in task completion rates. Our method is
model-agnostic, transparent to end-users, and can be easily integrated into
existing LLM pipelines. This work contributes to the growing field of LLM
optimization, offering a cost-effective solution for enhancing model
performance without the need for fine-tuning or larger models.

摘要：這篇論文介紹了修補後的 MOA（代理混合），一種推論最佳化技術，它可以大幅提升大型語言模型 (LLM) 在各種軟體開發任務中的效能。我們評估了三種推論最佳化演算法，分別是 N 中最佳、代理混合，以及蒙地卡羅樹狀搜尋，並展示修補後的 MOA 可以提升較小型模型的效能，超越較大型、較昂貴的模型。值得注意的是，我們的做法在 Arena-Hard-Auto 基準測試中將 gpt-4o-mini 模型的效能提升了 15.52%，以不到 gpt-4-turbo 成本的一小部分就超越了 gpt-4-turbo。我們也將修補後的 MOA 應用於各種軟體開發工作流程，顯示在任務完成率方面有顯著的提升。我們的方法與模型無關，對最終使用者來說是透明的，而且可以輕鬆整合到現有的 LLM 管線中。這項工作有助於 LLM 最佳化領域的發展，提供一種具成本效益的解決方案，可以在不需要微調或使用較大型模型的情況下提升模型效能。

##### **SLIM: Style-Linguistics Mismatch Model for Generalized Audio Deepfake Detection**
2407.18517v1 by Yi Zhu, Surya Koppisetti, Trang Tran, Gaurav Bharaj

Audio deepfake detection (ADD) is crucial to combat the misuse of speech
synthesized from generative AI models. Existing ADD models suffer from
generalization issues, with a large performance discrepancy between in-domain
and out-of-domain data. Moreover, the black-box nature of existing models
limits their use in real-world scenarios, where explanations are required for
model decisions. To alleviate these issues, we introduce a new ADD model that
explicitly uses the StyleLInguistics Mismatch (SLIM) in fake speech to separate
them from real speech. SLIM first employs self-supervised pretraining on only
real samples to learn the style-linguistics dependency in the real class. The
learned features are then used in complement with standard pretrained acoustic
features (e.g., Wav2vec) to learn a classifier on the real and fake classes.
When the feature encoders are frozen, SLIM outperforms benchmark methods on
out-of-domain datasets while achieving competitive results on in-domain data.
The features learned by SLIM allow us to quantify the (mis)match between style
and linguistic content in a sample, hence facilitating an explanation of the
model decision.

摘要：音訊深度偽造偵測 (ADD) 對於打擊濫用由生成式 AI 模型合成的語音至關重要。現有的 ADD 模型有泛化問題，在網域內和網域外資料之間的效能差異很大。此外，現有模型的黑箱性質限制了它們在現實世界中的應用，因為在現實世界中需要對模型決策進行解釋。為了緩解這些問題，我們引入了一個新的 ADD 模型，它明確地利用了偽造語音中的風格語言不匹配 (SLIM) 來將其與真實語音分開。SLIM 首先僅在真實樣本上採用自我監督預訓練，以學習真實類別中的風格語言依賴性。然後將學習到的特徵與標準預訓練聲學特徵（例如 Wav2vec）一起使用，以學習真實和偽造類別的分類器。當特徵編碼器被凍結時，SLIM 在網域外資料集上優於基準方法，同時在網域內資料上取得了競爭力的結果。SLIM 學習到的特徵讓我們能夠量化樣本中風格和語言內容之間的（不）匹配，從而有助於解釋模型決策。

##### **The formation of perceptual space in early phonetic acquisition: a cross-linguistic modeling approach**
2407.18501v1 by Frank Lihui Tan, Youngah Do

This study investigates how learners organize perceptual space in early
phonetic acquisition by advancing previous studies in two key aspects. Firstly,
it examines the shape of the learned hidden representation as well as its
ability to categorize phonetic categories. Secondly, it explores the impact of
training models on context-free acoustic information, without involving
contextual cues, on phonetic acquisition, closely mimicking the early language
learning stage. Using a cross-linguistic modeling approach, autoencoder models
are trained on English and Mandarin and evaluated in both native and non-native
conditions, following experimental conditions used in infant language
perception studies. The results demonstrate that unsupervised bottom-up
training on context-free acoustic information leads to comparable learned
representations of perceptual space between native and non-native conditions
for both English and Mandarin, resembling the early stage of universal
listening in infants. These findings provide insights into the organization of
perceptual space during early phonetic acquisition and contribute to our
understanding of the formation and representation of phonetic categories.

摘要：本研究探討學習者如何在早期語音習得中組織知覺空間，並從兩個關鍵方面推進先前的研究。首先，它探討學習到的隱藏表徵的形狀及其對語音類別進行分類的能力。其次，它探討了在語音習得中，在不涉及上下文線索的情況下，訓練模型對無上下文聲學資訊的影響，這與早期的語言學習階段非常相似。使用跨語言建模方法，對英語和普通話訓練自動編碼器模型，並在母語和非母語條件下進行評估，遵循嬰兒語言知覺研究中使用的實驗條件。結果表明，在無上下文聲學資訊上進行無監督的自下而上訓練，會導致英語和普通話的母語和非母語條件之間的知覺空間學習表徵具有可比性，類似於嬰兒的普遍聆聽的早期階段。這些發現提供了對早期語音習得過程中知覺空間組織的見解，並有助於我們理解語音類別的形成和表徵。

##### **Non-Overlapping Placement of Macro Cells based on Reinforcement Learning in Chip Design**
2407.18499v1 by Tao Yu, Peng Gao, Fei Wang, Ru-Yue Yuan

Due to the increasing complexity of chip design, existing placement methods
still have many shortcomings in dealing with macro cells coverage and
optimization efficiency. Aiming at the problems of layout overlap, inferior
performance, and low optimization efficiency in existing chip design methods,
this paper proposes an end-to-end placement method, SRLPlacer, based on
reinforcement learning. First, the placement problem is transformed into a
Markov decision process by establishing the coupling relationship graph model
between macro cells to learn the strategy for optimizing layouts. Secondly, the
whole placement process is optimized after integrating the standard cell
layout. By assessing on the public benchmark ISPD2005, the proposed SRLPlacer
can effectively solve the overlap problem between macro cells while considering
routing congestion and shortening the total wire length to ensure routability.

摘要：由於晶片設計複雜度日益提升，現有的佈局方法在處理巨量儲存格覆蓋率與最佳化效率上仍有許多不足。針對現有晶片設計方法中佈局重疊、效能不佳、最佳化效率低等問題，本文提出一個基於強化學習的端到端佈局方法 SRLPlacer。首先將佈局問題轉換為馬可夫決策過程，建立巨量儲存格間的耦合關係圖模型，學習最佳化佈局的策略。其次，將標準單元佈局整合後，對整體佈局流程進行最佳化。在公開基準 ISPD2005 上評估，提出的 SRLPlacer 能有效解決巨量儲存格間的重疊問題，同時考量走線壅塞，並縮短總走線長度，以確保可走線性。

##### **A Reliable Common-Sense Reasoning Socialbot Built Using LLMs and Goal-Directed ASP**
2407.18498v1 by Yankai Zeng, Abhiramon Rajashekharan, Kinjal Basu, Huaduo Wang, Joaquín Arias, Gopal Gupta

The development of large language models (LLMs), such as GPT, has enabled the
construction of several socialbots, like ChatGPT, that are receiving a lot of
attention for their ability to simulate a human conversation. However, the
conversation is not guided by a goal and is hard to control. In addition,
because LLMs rely more on pattern recognition than deductive reasoning, they
can give confusing answers and have difficulty integrating multiple topics into
a cohesive response. These limitations often lead the LLM to deviate from the
main topic to keep the conversation interesting. We propose AutoCompanion, a
socialbot that uses an LLM model to translate natural language into predicates
(and vice versa) and employs commonsense reasoning based on Answer Set
Programming (ASP) to hold a social conversation with a human. In particular, we
rely on s(CASP), a goal-directed implementation of ASP as the backend. This
paper presents the framework design and how an LLM is used to parse user
messages and generate a response from the s(CASP) engine output. To validate
our proposal, we describe (real) conversations in which the chatbot's goal is
to keep the user entertained by talking about movies and books, and s(CASP)
ensures (i) correctness of answers, (ii) coherence (and precision) during the
conversation, which it dynamically regulates to achieve its specific purpose,
and (iii) no deviation from the main topic.

摘要：大型語言模型 (LLM) 如 GPT 的發展，促成了多款社交機器人的建構，例如 ChatGPT，它們因模擬人類對話的能力而備受關注。然而，對話並非由目標引導，且難以控制。此外，由於 LLM 更依賴於模式辨識而非演繹推理，因此它們可能會給出令人困惑的答案，並難以將多個主題整合到一個有凝聚力的回應中。這些限制通常會導致 LLM 偏離主旨，以保持對話的趣味性。我們提出 AutoCompanion，一種使用 LLM 模型將自然語言轉換為謂詞（反之亦然）的社交機器人，並採用基於答案集程式設計 (ASP) 的常識推理，與人類進行社交對話。特別是，我們依賴於 s(CASP)，一種目標導向的 ASP 實作，作為後端。本文介紹了框架設計，以及如何使用 LLM 來解析使用者訊息，並從 s(CASP) 引擎輸出產生回應。為了驗證我們的提案，我們描述了聊天機器人的目標是透過談論電影和書籍讓使用者保持娛樂的（真實）對話，而 s(CASP) 確保 (i) 答案的正確性，(ii) 對話期間的一致性（和精確性），它會動態調整對話以達成其特定目的，以及 (iii) 不偏離主旨。

##### **Towards More Accurate Prediction of Human Empathy and Emotion in Text and Multi-turn Conversations by Combining Advanced NLP, Transformers-based Networks, and Linguistic Methodologies**
2407.18496v1 by Manisha Singh, Divy Sharma, Alonso Ma, Nora Goldfine

Based on the WASSA 2022 Shared Task on Empathy Detection and Emotion
Classification, we predict the level of empathic concern and personal distress
displayed in essays. For the first stage of this project we implemented a
Feed-Forward Neural Network using sentence-level embeddings as features. We
experimented with four different embedding models for generating the inputs to
the neural network. The subsequent stage builds upon the previous work and we
have implemented three types of revisions. The first revision focuses on the
enhancements to the model architecture and the training approach. The second
revision focuses on handling class imbalance using stratified data sampling.
The third revision focuses on leveraging lexical resources, where we apply four
different resources to enrich the features associated with the dataset. During
the final stage of this project, we have created the final end-to-end system
for the primary task using an ensemble of models to revise primary task
performance. Additionally, as part of the final stage, these approaches have
been adapted to the WASSA 2023 Shared Task on Empathy Emotion and Personality
Detection in Interactions, in which the empathic concern, emotion polarity, and
emotion intensity in dyadic text conversations are predicted.

摘要：根據 WASSA 2022 年同理心檢測和情緒分類的共享任務，我們預測論文中顯示的同理關懷和個人痛苦程度。在這個專案的第一階段，我們使用句子層級的詞嵌入作為特徵，實作了前饋神經網路。我們實驗了四種不同的詞嵌入模型，以產生輸入到神經網路。後續階段建立在前一項工作之上，我們實作了三種類型的修正。第一個修正著重於模型架構和訓練方法的增強。第二個修正著重於使用分層資料抽樣來處理類別不平衡。第三個修正著重於利用詞彙資源，我們運用四種不同的資源來豐富與資料集相關的特徵。在這個專案的最後階段，我們使用模型的整體來建立主要任務的最終端對端系統，以修正主要任務的效能。此外，作為最後階段的一部分，這些方法已被調整到 WASSA 2023 年同理心情緒和互動中的人格檢測的共享任務，其中預測了二元文字對話中的同理關懷、情緒極性和情緒強度。

##### **A Role-specific Guided Large Language Model for Ophthalmic Consultation Based on Stylistic Differentiation**
2407.18483v2 by Laiyi Fu, Binbin Fan, Hongkai Du, Yanxiang Feng, Chunhua Li, Huping Song

Ophthalmology consultations are crucial for diagnosing, treating, and
preventing eye diseases. However, the growing demand for consultations exceeds
the availability of ophthalmologists. By leveraging large pre-trained language
models, we can design effective dialogues for specific scenarios, aiding in
consultations. Traditional fine-tuning strategies for question-answering tasks
are impractical due to increasing model size and often ignoring patient-doctor
role function during consultations. In this paper, we propose EyeDoctor, an
ophthalmic medical questioning large language model that enhances accuracy
through doctor-patient role perception guided and an augmented knowledge base
with external disease information. Experimental results show EyeDoctor achieves
higher question-answering precision in ophthalmology consultations. Notably,
EyeDoctor demonstrated a 7.25% improvement in Rouge-1 scores and a 10.16%
improvement in F1 scores on multi-round datasets compared to second best model
ChatGPT, highlighting the importance of doctor-patient role differentiation and
dynamic knowledge base expansion for intelligent medical consultations. EyeDoc
also serves as a free available web based service and souce code is available
at https://github.com/sperfu/EyeDoc.

摘要：眼科諮詢對於診斷、治療和預防眼疾至關重要。然而，對諮詢服務的需求不斷增長，卻超過了眼科醫生的可提供數量。透過利用大型預先訓練的語言模型，我們可以為特定場景設計出有效的對話，協助諮詢服務。傳統的微調策略對於問答任務來說並不切實際，因為模型的規模越來越大，而且在諮詢過程中通常會忽略患者和醫生的角色功能。在本文中，我們提出了 EyeDoctor，這是一個眼科醫療問答大型語言模型，它透過醫生和患者角色認知引導和一個具備外部疾病資訊的擴增知識庫來提高準確性。實驗結果顯示，EyeDoctor 在眼科諮詢中達到了更高的問答準確度。值得注意的是，與第二好的模型 ChatGPT 相比，EyeDoctor 在多輪數據集上 Rouge-1 分數提高了 7.25%，F1 分數提高了 10.16%，這凸顯了醫生和患者角色區分以及動態知識庫擴展對於智慧醫療諮詢的重要性。EyeDoc 也作為一個免費的網路服務，其原始碼可於 https://github.com/sperfu/EyeDoc 取得。

##### **Multi-turn Response Selection with Commonsense-enhanced Language Models**
2407.18479v1 by Yuandong Wang, Xuhui Ren, Tong Chen, Yuxiao Dong, Nguyen Quoc Viet Hung, Jie Tang

As a branch of advanced artificial intelligence, dialogue systems are
prospering. Multi-turn response selection is a general research problem in
dialogue systems. With the assistance of background information and pre-trained
language models, the performance of state-of-the-art methods on this problem
gains impressive improvement. However, existing studies neglect the importance
of external commonsense knowledge. Hence, we design a Siamese network where a
pre-trained Language model merges with a Graph neural network (SinLG). SinLG
takes advantage of Pre-trained Language Models (PLMs) to catch the word
correlations in the context and response candidates and utilizes a Graph Neural
Network (GNN) to reason helpful common sense from an external knowledge graph.
The GNN aims to assist the PLM in fine-tuning, and arousing its related
memories to attain better performance. Specifically, we first extract related
concepts as nodes from an external knowledge graph to construct a subgraph with
the context response pair as a super node for each sample. Next, we learn two
representations for the context response pair via both the PLM and GNN. A
similarity loss between the two representations is utilized to transfer the
commonsense knowledge from the GNN to the PLM. Then only the PLM is used to
infer online so that efficiency can be guaranteed. Finally, we conduct
extensive experiments on two variants of the PERSONA-CHAT dataset, which proves
that our solution can not only improve the performance of the PLM but also
achieve an efficient inference.

摘要：作為高級人工智慧的一個分支，對話系統正蓬勃發展。多輪回應用戶回應選擇是對話系統中一個通用的研究問題。在背景資訊和預先訓練的語言模型的協助下，最先進的方法在此問題上的表現獲致令人印象深刻的進步。然而，現有的研究忽略了外部常識知識的重要性。因此，我們設計了一個暹羅網路，其中一個預先訓練的語言模型與一個圖神經網路（SinLG）合併。SinLG 利用預先訓練的語言模型（PLM）來捕捉語境和回應候選中的詞彙關聯，並利用圖神經網路（GNN）從外部知識圖譜推理有用的常識。GNN 旨在協助 PLM 進行微調，並喚醒其相關記憶以獲得更好的表現。具體來說，我們首先從外部知識圖譜中提取相關概念作為節點，以構建一個子圖，其中語境回應對作為每個範例的超級節點。接下來，我們透過 PLM 和 GNN 為語境回應對學習兩個表示。兩個表示之間的相似性損失用於將常識知識從 GNN 轉移到 PLM。然後僅使用 PLM 來進行線上推論，以便保證效率。最後，我們對 PERSONA-CHAT 資料集的兩個變體進行了廣泛的實驗，這證明我們的解決方案不僅可以提高 PLM 的效能，還能實現高效的推論。

##### **Constructing the CORD-19 Vaccine Dataset**
2407.18471v1 by Manisha Singh, Divy Sharma, Alonso Ma, Bridget Tyree, Margaret Mitchell

We introduce new dataset 'CORD-19-Vaccination' to cater to scientists
specifically looking into COVID-19 vaccine-related research. This dataset is
extracted from CORD-19 dataset [Wang et al., 2020] and augmented with new
columns for language detail, author demography, keywords, and topic per paper.
Facebook's fastText model is used to identify languages [Joulin et al., 2016].
To establish author demography (author affiliation, lab/institution location,
and lab/institution country columns) we processed the JSON file for each paper
and then further enhanced using Google's search API to determine country
values. 'Yake' was used to extract keywords from the title, abstract, and body
of each paper and the LDA (Latent Dirichlet Allocation) algorithm was used to
add topic information [Campos et al., 2020, 2018a,b]. To evaluate the dataset,
we demonstrate a question-answering task like the one used in the CORD-19
Kaggle challenge [Goldbloom et al., 2022]. For further evaluation, sequential
sentence classification was performed on each paper's abstract using the model
from Dernoncourt et al. [2016]. We partially hand annotated the training
dataset and used a pre-trained BERT-PubMed layer. 'CORD- 19-Vaccination'
contains 30k research papers and can be immensely valuable for NLP research
such as text mining, information extraction, and question answering, specific
to the domain of COVID-19 vaccine research.

摘要：<paragraph>我們推出新的資料集「CORD-19-Vaccination」，以滿足專門研究與 COVID-19 疫苗相關研究的科學家。此資料集摘錄自 CORD-19 資料集 [Wang et al., 2020]，並新增了語言詳細資料、作者人口統計、關鍵字和每篇論文的主題等新欄位。Facebook 的 fastText 模型用於辨識語言 [Joulin et al., 2016]。為了建立作者人口統計（作者隸屬、實驗室/機構所在地和實驗室/機構國家欄位），我們處理了每篇論文的 JSON 檔案，然後進一步使用 Google 的搜尋 API 來判斷國家/地區值。我們使用「Yake」從每篇論文的標題、摘要和本文中萃取關鍵字，並使用 LDA（潛在狄利克雷配置）演算法來新增主題資訊 [Campos et al., 2020, 2018a,b]。為了評量資料集，我們示範了一個問答任務，類似於 CORD-19 Kaggle 挑戰中使用的任務 [Goldbloom et al., 2022]。為了進一步評量，我們使用 Dernoncourt et al. [2016] 的模型對每篇論文的摘要執行順序句分類。我們部分手動標記訓練資料集，並使用預先訓練好的 BERT-PubMed 層。「CORD-19-Vaccination」包含 30k 篇研究論文，對於 NLP 研究（例如文字探勘、資訊萃取和問答），特別是針對 COVID-19 疫苗研究領域，將極具價值。</paragraph>

##### **Diffusion-Driven Semantic Communication for Generative Models with Bandwidth Constraints**
2407.18468v1 by Lei Guo, Wei Chen, Yuxuan Sun, Bo Ai, Nikolaos Pappas, Tony Quek

Diffusion models have been extensively utilized in AI-generated content
(AIGC) in recent years, thanks to the superior generation capabilities.
Combining with semantic communications, diffusion models are used for tasks
such as denoising, data reconstruction, and content generation. However,
existing diffusion-based generative models do not consider the stringent
bandwidth limitation, which limits its application in wireless communication.
This paper introduces a diffusion-driven semantic communication framework with
advanced VAE-based compression for bandwidth-constrained generative model. Our
designed architecture utilizes the diffusion model, where the signal
transmission process through the wireless channel acts as the forward process
in diffusion. To reduce bandwidth requirements, we incorporate a downsampling
module and a paired upsampling module based on a variational auto-encoder with
reparameterization at the receiver to ensure that the recovered features
conform to the Gaussian distribution. Furthermore, we derive the loss function
for our proposed system and evaluate its performance through comprehensive
experiments. Our experimental results demonstrate significant improvements in
pixel-level metrics such as peak signal to noise ratio (PSNR) and semantic
metrics like learned perceptual image patch similarity (LPIPS). These
enhancements are more profound regarding the compression rates and SNR compared
to deep joint source-channel coding (DJSCC).

摘要：近年来，得益于其出色的生成能力，扩散模型已广泛应用于人工智能生成内容 (AIGC) 中。结合语义通信，扩散模型可用于去噪、数据重建和内容生成等任务。然而，现有的基于扩散的生成模型并没有考虑严格的带宽限制，这限制了其在无线通信中的应用。本文介绍了一个基于扩散的语义通信框架，该框架具有先进的基于 VAE 的压缩功能，适用于带宽受限的生成模型。我们设计的架构利用了扩散模型，其中通过无线信道进行的信号传输过程充当了扩散中的前向过程。为了减少带宽需求，我们在接收端结合了一个基于变分自动编码器和重新参数化的下采样模块和一个配对的上采样模块，以确保恢复的特征符合高斯分布。此外，我们推导了所提出系统的损失函数，并通过综合实验评估了其性能。我们的实验结果表明，在峰值信噪比 (PSNR) 等像素级指标和学习感知图像块相似性 (LPIPS) 等语义指标方面有显著提高。与深度联合源信道编码 (DJSCC) 相比，这些增强在压缩率和 SNR 方面更为明显。

##### **Enhancing Dysarthric Speech Recognition for Unseen Speakers via Prototype-Based Adaptation**
2407.18461v1 by Shiyao Wang, Shiwan Zhao, Jiaming Zhou, Aobo Kong, Yong Qin

Dysarthric speech recognition (DSR) presents a formidable challenge due to
inherent inter-speaker variability, leading to severe performance degradation
when applying DSR models to new dysarthric speakers. Traditional speaker
adaptation methodologies typically involve fine-tuning models for each speaker,
but this strategy is cost-prohibitive and inconvenient for disabled users,
requiring substantial data collection. To address this issue, we introduce a
prototype-based approach that markedly improves DSR performance for unseen
dysarthric speakers without additional fine-tuning. Our method employs a
feature extractor trained with HuBERT to produce per-word prototypes that
encapsulate the characteristics of previously unseen speakers. These prototypes
serve as the basis for classification. Additionally, we incorporate supervised
contrastive learning to refine feature extraction. By enhancing representation
quality, we further improve DSR performance, enabling effective personalized
DSR. We release our code at https://github.com/NKU-HLT/PB-DSR.

摘要：構音障礙語音識別 (DSR) 因與生俱來的說話者間差異而面臨嚴峻挑戰，導致將 DSR 模型應用於新的構音障礙說話者時，效能嚴重下降。傳統的說話者適應方法通常涉及微調每個說話者的模型，但對於殘疾使用者來說，這種策略既昂貴又不方便，需要大量的資料收集。為了解決這個問題，我們引入一種基於原型的做法，它顯著改善了 DSR 對未見過構音障礙說話者的表現，而無需額外的微調。我們的做法採用經由 HuBERT 訓練的特徵萃取器，以產生每個單詞的原型，這些原型包含先前未見過說話者的特徵。這些原型作為分類的基礎。此外，我們納入監督對比學習以改善特徵萃取。透過提升表徵品質，我們進一步改善 DSR 的表現，實現有效的個人化 DSR。我們在 https://github.com/NKU-HLT/PB-DSR/ 發布我們的程式碼。

##### **Fairness Definitions in Language Models Explained**
2407.18454v1 by Thang Viet Doan, Zhibo Chu, Zichong Wang, Wenbin Zhang

Language Models (LMs) have demonstrated exceptional performance across
various Natural Language Processing (NLP) tasks. Despite these advancements,
LMs can inherit and amplify societal biases related to sensitive attributes
such as gender and race, limiting their adoption in real-world applications.
Therefore, fairness has been extensively explored in LMs, leading to the
proposal of various fairness notions. However, the lack of clear agreement on
which fairness definition to apply in specific contexts (\textit{e.g.,}
medium-sized LMs versus large-sized LMs) and the complexity of understanding
the distinctions between these definitions can create confusion and impede
further progress. To this end, this paper proposes a systematic survey that
clarifies the definitions of fairness as they apply to LMs. Specifically, we
begin with a brief introduction to LMs and fairness in LMs, followed by a
comprehensive, up-to-date overview of existing fairness notions in LMs and the
introduction of a novel taxonomy that categorizes these concepts based on their
foundational principles and operational distinctions. We further illustrate
each definition through experiments, showcasing their practical implications
and outcomes. Finally, we discuss current research challenges and open
questions, aiming to foster innovative ideas and advance the field. The
implementation and additional resources are publicly available at
https://github.com/LavinWong/Fairness-in-Large-Language-Models/tree/main/definitions.

摘要：<paragraph>語言模型 (LM) 在各種自然語言處理 (NLP) 任務中展現出傑出的表現。儘管有這些進展，LM 仍可能繼承並放大與敏感屬性（例如性別和種族）相關的社會偏見，這限制了它們在真實世界應用中的採用。因此，公平性已在 LM 中廣泛探討，並提出各種公平性概念。然而，對於在特定背景下套用哪種公平性定義缺乏明確共識（例如中型 LM 與大型 LM），以及理解這些定義之間差異的複雜性可能會造成混淆並阻礙進一步的進展。為此，本文提出了一項系統性的調查，以釐清公平性的定義，因為它們適用於 LM。具體來說，我們從 LM 和 LM 中的公平性簡介開始，接著對 LM 中現有的公平性概念進行全面、最新的概述，並介紹一種新的分類法，根據它們的基本原則和運作區別對這些概念進行分類。我們進一步通過實驗說明每個定義，展示它們的實際含義和結果。最後，我們討論當前的研究挑戰和開放性問題，旨在培養創新思想並推動該領域的進步。實作和額外資源已公開於 https://github.com/LavinWong/Fairness-in-Large-Language-Models/tree/main/definitions。</paragraph>

##### **Capturing the security expert knowledge in feature selection for web application attack detection**
2407.18445v1 by Amanda Riverol, Gustavo Betarte, Rodrigo Martínez, Álvaro Pardo

This article puts forward the use of mutual information values to replicate
the expertise of security professionals in selecting features for detecting web
attacks. The goal is to enhance the effectiveness of web application firewalls
(WAFs). Web applications are frequently vulnerable to various security threats,
making WAFs essential for their protection. WAFs analyze HTTP traffic using
rule-based approaches to identify known attack patterns and to detect and block
potential malicious requests. However, a major challenge is the occurrence of
false positives, which can lead to blocking legitimate traffic and impact the
normal functioning of the application. The problem is addressed as an approach
that combines supervised learning for feature selection with a semi-supervised
learning scenario for training a One-Class SVM model. The experimental findings
show that the model trained with features selected by the proposed algorithm
outperformed the expert-based selection approach in terms of performance.
Additionally, the results obtained by the traditional rule-based WAF
ModSecurity, configured with a vanilla set of OWASP CRS rules, were also
improved.

摘要：本文提出了使用互信息值来复制安全专业人员在选择用于检测网络攻击的功能时的专业知识。目标是提高 Web 应用程序防火墙 (WAF) 的有效性。Web 应用程序经常容易受到各种安全威胁的攻击，这使得 WAF 对于保护它们至关重要。WAF 使用基于规则的方法分析 HTTP 流量，以识别已知的攻击模式并检测和阻止潜在的恶意请求。然而，一个主要挑战是误报的发生，这可能导致阻止合法流量并影响应用程序的正常运行。该问题被解决为一种方法，该方法将用于特征选择的有监督学习与用于训练单类 SVM 模型的半监督学习场景相结合。实验结果表明，使用所提出的算法选择的特征训练的模型在性能方面优于基于专家的选择方法。此外，还改进了使用一组香草 OWASP CRS 规则配置的传统基于规则的 WAF ModSecurity 获得的结果。

##### **Guidance-Based Prompt Data Augmentation in Specialized Domains for Named Entity Recognition**
2407.18442v1 by Hyeonseok Kang, Hyein Seo, Jeesu Jung, Sangkeun Jung, Du-Seong Chang, Riwoo Chung

While the abundance of rich and vast datasets across numerous fields has
facilitated the advancement of natural language processing, sectors in need of
specialized data types continue to struggle with the challenge of finding
quality data. Our study introduces a novel guidance data augmentation technique
utilizing abstracted context and sentence structures to produce varied
sentences while maintaining context-entity relationships, addressing data
scarcity challenges. By fostering a closer relationship between context,
sentence structure, and role of entities, our method enhances data
augmentation's effectiveness. Consequently, by showcasing diversification in
both entity-related vocabulary and overall sentence structure, and
simultaneously improving the training performance of named entity recognition
task.

摘要：儘管豐富且龐大的資料集在許多領域中十分充足，促进了自然語言處理的進步，但需要特定資料類型的產業仍持續面臨尋找優質資料的挑戰。我們的研究引入了一種新穎的引導資料擴充技術，利用抽象的脈絡和句子結構，在維持脈絡實體關係的同時產生多變的句子，解決資料短缺的挑戰。透過促進脈絡、句子結構和實體角色之間更緊密的關係，我們的技術增強了資料擴充的有效性。因此，透過展示實體相關詞彙和整體句子結構的多樣性，同時改善命名實體辨識任務的訓練表現。

##### **Mixed Non-linear Quantization for Vision Transformers**
2407.18437v1 by Gihwan Kim, Jemin Lee, Sihyeong Park, Yongin Kwon, Hyungshin Kim

The majority of quantization methods have been proposed to reduce the model
size of Vision Transformers, yet most of them have overlooked the quantization
of non-linear operations. Only a few works have addressed quantization for
non-linear operations, but they applied a single quantization method across all
non-linear operations. We believe that this can be further improved by
employing a different quantization method for each non-linear operation.
Therefore, to assign the most error-minimizing quantization method from the
known methods to each non-linear layer, we propose a mixed non-linear
quantization that considers layer-wise quantization sensitivity measured by
SQNR difference metric. The results show that our method outperforms I-BERT,
FQ-ViT, and I-ViT in both 8-bit and 6-bit settings for ViT, DeiT, and Swin
models by an average of 0.6%p and 19.6%p, respectively. Our method outperforms
I-BERT and I-ViT by 0.6%p and 20.8%p, respectively, when training time is
limited. We plan to release our code at
https://gitlab.com/ones-ai/mixed-non-linear-quantization.

摘要：目前已提出的量化方法大多数都是为了减小视觉转换器的模型大小，但其中大多数都忽略了非线性运算的量化。只有少数工作解决了非线性运算的量化问题，但它们对所有非线性运算都应用了单一的量化方法。我们相信通过为每个非线性运算采用不同的量化方法，可以进一步改进这一点。因此，为了将已知方法中最能减少误差的量化方法分配给每个非线性层，我们提出了混合非线性量化，该量化考虑了由 SQNR 差分度量衡量的逐层量化灵敏度。结果表明，我们的方法在 ViT、DeiT 和 Swin 模型的 8 位和 6 位设置中分别比 I-BERT、FQ-ViT 和 I-ViT 的性能高出 0.6%p 和 19.6%p。当训练时间有限时，我们的方法比 I-BERT 和 I-ViT 的性能分别高出 0.6%p 和 20.8%p。我们计划在 https://gitlab.com/ones-ai/mixed-non-linear-quantization 上发布我们的代码。

##### **Weighted Risk Invariance: Domain Generalization under Invariant Feature Shift**
2407.18428v1 by Gina Wong, Joshua Gleason, Rama Chellappa, Yoav Wald, Anqi Liu

Learning models whose predictions are invariant under multiple environments
is a promising approach for out-of-distribution generalization. Such models are
trained to extract features $X_{\text{inv}}$ where the conditional distribution
$Y \mid X_{\text{inv}}$ of the label given the extracted features does not
change across environments. Invariant models are also supposed to generalize to
shifts in the marginal distribution $p(X_{\text{inv}})$ of the extracted
features $X_{\text{inv}}$, a type of shift we call an $\textit{invariant
covariate shift}$. However, we show that proposed methods for learning
invariant models underperform under invariant covariate shift, either failing
to learn invariant models$\unicode{x2014}$even for data generated from simple
and well-studied linear-Gaussian models$\unicode{x2014}$or having poor
finite-sample performance. To alleviate these problems, we propose
$\textit{weighted risk invariance}$ (WRI). Our framework is based on imposing
invariance of the loss across environments subject to appropriate reweightings
of the training examples. We show that WRI provably learns invariant models,
i.e. discards spurious correlations, in linear-Gaussian settings. We propose a
practical algorithm to implement WRI by learning the density
$p(X_{\text{inv}})$ and the model parameters simultaneously, and we demonstrate
empirically that WRI outperforms previous invariant learning methods under
invariant covariate shift.

摘要：學習預測在多重環境下不變的模型，是針對非分佈推廣的一種有前途的方法。此類模型經過訓練，可萃取出特徵 $X_{\text{inv}}$，其中給定萃取特徵的條件分佈 $Y \mid X_{\text{inv}}$ 在不同環境中不會改變。不變模型也假設能推廣到萃取特徵 $X_{\text{inv}}$ 的邊際分佈 $p(X_{\text{inv}})$ 的轉移，我們將此類型的轉移稱為「不變協變數轉移」。然而，我們顯示出針對不變協變數轉移學習不變模型的提議方法表現不佳，不是無法學習不變模型（即使對於由簡單且經過充分研究的線性高斯模型產生的資料），就是具有不佳的有限樣本效能。為了緩解這些問題，我們提出「加權風險不變性」(WRI)。我們的架構基於在適當重新加權訓練範例的環境中，強加損失的不變性。我們顯示出 WRI 可證明學習不變模型，亦即捨棄線性高斯設定中的虛假關聯性。我們提出一個實用的演算法來實作 WRI，方法是同時學習密度 $p(X_{\text{inv}})$ 與模型參數，且我們實證顯示 WRI 在不變協變數轉移下優於先前的非變學習方法。

##### **HDL-GPT: High-Quality HDL is All You Need**
2407.18423v1 by Bhuvnesh Kumar, Saurav Nanda, Ganapathy Parthasarathy, Pawan Patil, Austin Tsai, Parivesh Choudhary

This paper presents Hardware Description Language Generative Pre-trained
Transformers (HDL-GPT), a novel approach that leverages the vast repository of
open-source High Definition Language (HDL) codes to train superior quality
large code models. The core premise of this paper is the hypothesis that
high-quality HDL is all you need to create models with exceptional performance
and broad zero-shot generalization abilities. The paper elucidates the methods
employed for the curation and augmentation of large corpora from open-source
HDL code, transforming highly variable quality data into high-quality data
through careful prompting and context maintenance. We demonstrate that the
careful selection, filtering, and augmentation of data across HDLs can yield
powerful models that surpass current state-of-the-art models. We also explore
the impact of different fine-tuning methods on the quality of results. We
describe experimental results across a range of fine-tuned SOTA LLMs,
substantiating our claims. We demonstrate improvements of 50% to 200% over SOTA
HDL models on current benchmarks in tasks ranging from HDL circuit
explanations, code generation, formal and simulation testbench creation,
triaging bugs, and fixing them. HDL-GPT opens new avenues for the development
of advanced model training techniques for circuit design tasks.

摘要：本文提出硬體描述語言生成式預訓練轉換器 (HDL-GPT)，這是一種新方法，利用大量開源高定義語言 (HDL) 程式碼來訓練優質的大型程式碼模型。本文的核心前提是高品質的 HDL 是建立具有卓越效能和廣泛零次學習概化能力模型的唯一要素。本文闡明了從開源 HDL 程式碼策展和擴充大型語料庫所使用的方法，透過仔細提示和脈絡維護，將品質高度變異的資料轉換成高品質資料。我們證明了仔細選擇、篩選和擴充 HDL 中的資料可以產生強大的模型，超越現有的最先進模型。我們也探討了不同微調方法對結果品質的影響。我們描述了針對一系列微調過的 SOTA LLM 的實驗結果，以證實我們的說法。我們證明了在從 HDL 電路說明、程式碼產生、正式和模擬測試平台建立、分類錯誤到修正錯誤等任務的現有基準中，HDL-GPT 比 SOTA HDL 模型進步了 50% 至 200%。HDL-GPT 為電路設計任務的進階模型訓練技術開發開啟了新途徑。

##### **Self-Directed Synthetic Dialogues and Revisions Technical Report**
2407.18421v1 by Nathan Lambert, Hailey Schoelkopf, Aaron Gokaslan, Luca Soldaini, Valentina Pyatkin, Louis Castricato

Synthetic data has become an important tool in the fine-tuning of language
models to follow instructions and solve complex problems. Nevertheless, the
majority of open data to date is often lacking multi-turn data and collected on
closed models, limiting progress on advancing open fine-tuning methods. We
introduce Self Directed Synthetic Dialogues (SDSD), an experimental dataset
consisting of guided conversations of language models talking to themselves.
The dataset consists of multi-turn conversations generated with DBRX, Llama 2
70B, and Mistral Large, all instructed to follow a conversation plan generated
prior to the conversation. We also explore including principles from
Constitutional AI and other related works to create synthetic preference data
via revisions to the final conversation turn. We hope this work encourages
further exploration in multi-turn data and the use of open models for expanding
the impact of synthetic data.

摘要：合成資料已成為微調語言模型以遵循指示和解決複雜問題的重要工具。儘管如此，迄今為止的大部分開放資料通常缺乏多輪資料，且是在封閉模型上收集的，這限制了開放式微調方法的進展。我們介紹了自導式合成對話 (SDSD)，這是一個實驗性資料集，包含語言模型與自己對話的引導式對話。該資料集包含使用 DBRX、Llama 2 70B 和 Mistral Large 生成的多輪對話，所有對話均遵循在對話之前生成的對話計畫。我們還探討了將憲法 AI 和其他相關工作的原則納入其中，以透過修改最終對話回合來建立合成偏好資料。我們希望這項工作能鼓勵進一步探索多輪資料，以及使用開放模型來擴大合成資料的影響力。

##### **The Art of Refusal: A Survey of Abstention in Large Language Models**
2407.18418v1 by Bingbing Wen, Jihan Yao, Shangbin Feng, Chenjun Xu, Yulia Tsvetkov, Bill Howe, Lucy Lu Wang

Abstention, the refusal of large language models (LLMs) to provide an answer,
is increasingly recognized for its potential to mitigate hallucinations and
enhance safety in building LLM systems. In this survey, we introduce a
framework to examine abstention behavior from three perspectives: the query,
the model, and human values. We review the literature on abstention methods
(categorized based on the development stages of LLMs), benchmarks, and
evaluation metrics, and discuss the merits and limitations of prior work. We
further identify and motivate areas for future research, such as encouraging
the study of abstention as a meta-capability across tasks and customizing
abstention abilities based on context. In doing so, we aim to broaden the scope
and impact of abstention methodologies in AI systems.

摘要：棄權，大型語言模型 (LLM) 拒絕提供答案，
它的潛力日益受到重視，因為它可以減輕幻覺並
增強 LLM 系統的安全性。在這次調查中，我們介紹了一個
架構，從三個角度檢視棄權行為：查詢、
模型和人類價值觀。我們回顧了關於棄權方法的文獻
（根據 LLM 的開發階段分類）、基準和
評估指標，並討論先前工作的優點和限制。我們
進一步找出並激勵未來的研究領域，例如鼓勵
研究棄權作為跨任務的元能力，以及根據內容自訂
棄權能力。在這樣做的過程中，我們旨在擴大棄權方法在 AI 系統中的範圍
和影響。

##### **PersonaGym: Evaluating Persona Agents and LLMs**
2407.18416v2 by Vinay Samuel, Henry Peng Zou, Yue Zhou, Shreyas Chaudhari, Ashwin Kalyan, Tanmay Rajpurohit, Ameet Deshpande, Karthik Narasimhan, Vishvak Murahari

Persona agents, which are LLM agents that act according to an assigned
persona, have demonstrated impressive contextual response capabilities across
various applications. These persona agents offer significant enhancements
across diverse sectors, such as education, healthcare, and entertainment, where
model developers can align agent responses to different user requirements
thereby broadening the scope of agent applications. However, evaluating persona
agent performance is incredibly challenging due to the complexity of assessing
persona adherence in free-form interactions across various environments that
are relevant to each persona agent. We introduce PersonaGym, the first dynamic
evaluation framework for assessing persona agents, and PersonaScore, the first
automated human-aligned metric grounded in decision theory for comprehensive
large-scale evaluation of persona agents. Our evaluation of 6 open and
closed-source LLMs, using a benchmark encompassing 200 personas and 10,000
questions, reveals significant opportunities for advancement in persona agent
capabilities across state-of-the-art models. For example, Claude 3.5 Sonnet
only has a 2.97% relative improvement in PersonaScore than GPT 3.5 despite
being a much more advanced model. Importantly, we find that increased model
size and complexity do not necessarily imply enhanced persona agent
capabilities thereby highlighting the pressing need for algorithmic and
architectural invention towards faithful and performant persona agents.

摘要：擬人代理，是依據指定擬人而行動的 LLM 代理，已在各種應用中展現出令人印象深刻的脈絡回應能力。這些擬人代理在教育、醫療保健和娛樂等不同領域提供顯著的增強功能，模型開發人員可以在其中將代理回應與不同的使用者需求對齊，從而擴大代理應用範圍。然而，由於在與每個擬人代理相關的各種環境中評估擬人代理的複雜性，評估擬人代理效能是一項極具挑戰性的任務。我們引入了 PersonaGym，這是第一個用於評估擬人代理的動態評估架構，以及 PersonaScore，這是第一個基於決策理論的自動化人類對齊指標，用於對擬人代理進行全面的大規模評估。我們使用包含 200 個擬人角色和 10,000 個問題的基準，對 6 個開放和閉源的 LLM 進行評估，結果顯示擬人代理能力在最先進的模型中具有顯著的進步機會。例如，儘管 Claude 3.5 Sonnet 是一個更先進的模型，但其 PersonaScore 相對於 GPT 3.5 僅有 2.97% 的相對提升。重要的是，我們發現模型大小和複雜性的增加並不一定意味著擬人代理能力的提升，從而突顯了對演算法和架構發明以實現忠實且高效能的擬人代理的迫切需求。

##### **Adversarial Robust Decision Transformer: Enhancing Robustness of RvS via Minimax Returns-to-go**
2407.18414v1 by Xiaohang Tang, Afonso Marques, Parameswaran Kamalaruban, Ilija Bogunovic

Decision Transformer (DT), as one of the representative Reinforcement
Learning via Supervised Learning (RvS) methods, has achieved strong performance
in offline learning tasks by leveraging the powerful Transformer architecture
for sequential decision-making. However, in adversarial environments, these
methods can be non-robust, since the return is dependent on the strategies of
both the decision-maker and adversary. Training a probabilistic model
conditioned on observed return to predict action can fail to generalize, as the
trajectories that achieve a return in the dataset might have done so due to a
weak and suboptimal behavior adversary. To address this, we propose a
worst-case-aware RvS algorithm, the Adversarial Robust Decision Transformer
(ARDT), which learns and conditions the policy on in-sample minimax
returns-to-go. ARDT aligns the target return with the worst-case return learned
through minimax expectile regression, thereby enhancing robustness against
powerful test-time adversaries. In experiments conducted on sequential games
with full data coverage, ARDT can generate a maximin (Nash Equilibrium)
strategy, the solution with the largest adversarial robustness. In large-scale
sequential games and continuous adversarial RL environments with partial data
coverage, ARDT demonstrates significantly superior robustness to powerful
test-time adversaries and attains higher worst-case returns compared to
contemporary DT methods.

摘要：決策Transformer (DT) 作為代表性的強化學習透過監督學習 (RvS) 方法之一，透過利用強大的Transformer架構進行順序決策，在離線學習任務中取得強勁的表現。然而，在對抗環境中，這些方法可能非穩健，因為回報取決於決策者和對手的策略。訓練一個以觀察回報為條件的機率模型來預測動作可能會無法概化，因為在資料集中達到回報的軌跡可能是由於對手表現不佳且次優。為了解決這個問題，我們提出一個最壞情況感知的 RvS 演算法，對抗穩健決策Transformer (ARDT)，它學習並以樣本內最小最大值回報為條件來制定策略。ARDT 將目標回報與透過最小最大值期望回歸學習到的最壞情況回報對齊，從而增強對強大測試時間對手的穩健性。在具有完整資料覆蓋範圍的順序遊戲中進行的實驗中，ARDT 可以產生一個最大最小值 (納許均衡) 策略，這是具有最大對抗穩健性的解。在具有部分資料覆蓋範圍的大規模順序遊戲和連續對抗 RL 環境中，ARDT 展現出對強大測試時間對手的顯著優越穩健性，並與當代 DT 方法相比獲得更高的最壞情況回報。

##### **Simulation of Neural Responses to Classical Music Using Organoid Intelligence Methods**
2407.18413v1 by Daniel Szelogowski

Music is a complex auditory stimulus capable of eliciting significant changes
in brain activity, influencing cognitive processes such as memory, attention,
and emotional regulation. However, the underlying mechanisms of music-induced
cognitive processes remain largely unknown. Organoid intelligence and deep
learning models show promise for simulating and analyzing these neural
responses to classical music, an area significantly unexplored in computational
neuroscience. Hence, we present the PyOrganoid library, an innovative tool that
facilitates the simulation of organoid learning models, integrating
sophisticated machine learning techniques with biologically inspired organoid
simulations. Our study features the development of the Pianoid model, a "deep
organoid learning" model that utilizes a Bidirectional LSTM network to predict
EEG responses based on audio features from classical music recordings. This
model demonstrates the feasibility of using computational methods to replicate
complex neural processes, providing valuable insights into music perception and
cognition. Likewise, our findings emphasize the utility of synthetic models in
neuroscience research and highlight the PyOrganoid library's potential as a
versatile tool for advancing studies in neuroscience and artificial
intelligence.

摘要：音樂是一種複雜的聽覺刺激，能夠引發腦部活動的重大變化，影響記憶力、注意力和情緒調節等認知過程。然而，音樂誘發認知過程的底層機制仍然很大程度上未知。類器官智能和深度學習模型顯示出模擬和分析這些對古典音樂的神經反應的前景，這是計算神經科學中一個顯著未被探索的領域。因此，我們提出了 PyOrganoid 庫，這是一個創新的工具，它促進了類器官學習模型的模擬，將精密的機器學習技術與受生物啟發的類器官模擬整合在一起。我們的研究特點是開發了 Pianoid 模型，一個「深度類器官學習」模型，它利用雙向 LSTM 網路根據古典音樂錄音的音訊特徵來預測腦電圖反應。這個模型證明了使用計算方法複製複雜神經過程的可行性，為音樂感知和認知提供了有價值的見解。同樣地，我們的研究結果強調了合成模型在神經科學研究中的效用，並突出了 PyOrganoid 庫作為推進神經科學和人工智慧研究的多功能工具的潛力。

##### **SCALE: Self-regulated Clustered federAted LEarning in a Homogeneous Environment**
2407.18387v1 by Sai Puppala, Ismail Hossain, Md Jahangir Alam, Sajedul Talukder, Zahidur Talukder, Syed Bahauddin

Federated Learning (FL) has emerged as a transformative approach for enabling
distributed machine learning while preserving user privacy, yet it faces
challenges like communication inefficiencies and reliance on centralized
infrastructures, leading to increased latency and costs. This paper presents a
novel FL methodology that overcomes these limitations by eliminating the
dependency on edge servers, employing a server-assisted Proximity Evaluation
for dynamic cluster formation based on data similarity, performance indices,
and geographical proximity. Our integrated approach enhances operational
efficiency and scalability through a Hybrid Decentralized Aggregation Protocol,
which merges local model training with peer-to-peer weight exchange and a
centralized final aggregation managed by a dynamically elected driver node,
significantly curtailing global communication overhead. Additionally, the
methodology includes Decentralized Driver Selection, Check-pointing to reduce
network traffic, and a Health Status Verification Mechanism for system
robustness. Validated using the breast cancer dataset, our architecture not
only demonstrates a nearly tenfold reduction in communication overhead but also
shows remarkable improvements in reducing training latency and energy
consumption while maintaining high learning performance, offering a scalable,
efficient, and privacy-preserving solution for the future of federated learning
ecosystems.

摘要：聯邦學習 (FL) 已成為一種變革性方法，用於在保護使用者隱私的同時啟用分散式機器學習，但它面臨著諸如通訊效率低和依賴於集中式基礎設施等挑戰，導致延遲和成本增加。本文提出了一種新穎的 FL 方法，通過消除對邊緣伺服器的依賴，採用伺服器輔助的接近度評估來根據資料相似性、效能指標和地理接近度進行動態叢集形成，從而克服了這些限制。我們的整合方法透過混合式分散式聚合協定來增強運作效率和可擴充性，該協定將本地模型訓練與點對點權重交換以及由動態選出的驅動程式節點管理的集中式最終聚合合併在一起，大幅減少了整體通訊開銷。此外，該方法包括分散式驅動程式選擇、檢查點以減少網路流量，以及用於系統穩健性的健康狀態驗證機制。我們的架構使用乳癌資料集進行驗證，不僅證明通訊開銷減少了近十倍，而且還顯示出在降低訓練延遲和能源消耗的同時，學習效能仍保持很高的顯著改進，為聯邦學習生態系統的未來提供了一個可擴充性、高效且保護隱私的解決方案。

##### **Exploring Bengali Religious Dialect Biases in Large Language Models with Evaluation Perspectives**
2407.18376v1 by Azmine Toushik Wasi, Raima Islam, Mst Rafia Islam, Taki Hasan Rafi, Dong-Kyu Chae

While Large Language Models (LLM) have created a massive technological impact
in the past decade, allowing for human-enabled applications, they can produce
output that contains stereotypes and biases, especially when using low-resource
languages. This can be of great ethical concern when dealing with sensitive
topics such as religion. As a means toward making LLMS more fair, we explore
bias from a religious perspective in Bengali, focusing specifically on two main
religious dialects: Hindu and Muslim-majority dialects. Here, we perform
different experiments and audit showing the comparative analysis of different
sentences using three commonly used LLMs: ChatGPT, Gemini, and Microsoft
Copilot, pertaining to the Hindu and Muslim dialects of specific words and
showcasing which ones catch the social biases and which do not. Furthermore, we
analyze our findings and relate them to potential reasons and evaluation
perspectives, considering their global impact with over 300 million speakers
worldwide. With this work, we hope to establish the rigor for creating more
fairness in LLMs, as these are widely used as creative writing agents.

摘要：儘管大型語言模型 (LLM) 在過去十年間創造了龐大的技術影響，允許人類啟用應用程式，但它們可以產生包含刻板印象和偏見的輸出，特別是在使用低資源語言時。在處理宗教等敏感議題時，這可能會引起重大的道德疑慮。作為讓 LLM 更加公平的方法，我們從宗教觀點探討孟加拉語中的偏見，特別專注於兩種主要的宗教方言：印度教和穆斯林佔多數的方言。在這裡，我們執行不同的實驗和稽核，顯示使用三個常用 LLM：ChatGPT、Gemini 和 Microsoft Copilot，針對特定字詞的印度教和穆斯林方言進行比較分析，並展示哪些會捕捉到社會偏見，哪些不會。此外，我們分析我們的發現，並將它們與潛在原因和評估觀點聯繫起來，考慮到它們在全球的影響，全球有超過 3 億的使用者。透過這項工作，我們希望建立嚴謹性，以在 LLM 中創造更多公平性，因為它們被廣泛用作創意寫作代理。

##### **Trust or Escalate: LLM Judges with Provable Guarantees for Human Agreement**
2407.18370v1 by Jaehun Jung, Faeze Brahman, Yejin Choi

We present a principled approach to provide LLM-based evaluation with a
rigorous guarantee of human agreement. We first propose that a reliable
evaluation method should not uncritically rely on model preferences for
pairwise evaluation, but rather assess the confidence of judge models and
selectively decide when to trust its judgement. We then show that under this
selective evaluation framework, human agreement can be provably guaranteed --
such that the model evaluation aligns with that of humans to a user-specified
agreement level. As part of our framework, we also introduce Simulated
Annotators, a novel confidence estimation method that significantly improves
judge calibration and thus enables high coverage of evaluated instances.
Finally, we propose Cascaded Selective Evaluation, where we use cheaper models
as initial judges and escalate to stronger models only when necessary -- again,
while still providing a provable guarantee of human agreement. Experimental
results show that Cascaded Selective Evaluation guarantees strong alignment
with humans, far beyond what LLM judges could achieve without selective
evaluation. For example, on a subset of Chatbot Arena where GPT-4 almost never
achieves 80% human agreement, our method, even while employing substantially
cost-effective models such as Mistral-7B, guarantees over 80% human agreement
with almost 80% test coverage.

摘要：<paragraph>我們提出了一個基於原則的方法，以提供具有嚴格人類共識保證的 LLM 評估。我們首先提出，一個可靠的評估方法不應不加批判地依賴模型偏好進行成對評估，而應評估評審模型的信心，並有選擇性地決定何時相信其判斷。然後我們表明，在這種選擇性評估框架下，人類共識可以被證明是有保證的——這樣，模型評估與人類的一致程度達到使用者指定的共識水準。作為我們框架的一部分，我們還引入了模擬註解員，這是一種新穎的信心估計方法，它顯著改善了評審校準，從而實現了評估實例的高覆蓋率。最後，我們提出了串聯選擇性評估，在其中我們使用較便宜的模型作為初始評審，並僅在必要時升級到更強大的模型——同樣，同時仍然提供人類共識的可證明保證。實驗結果表明，串聯選擇性評估保證了與人類的強一致性，遠遠超出了 LLM 評審在沒有選擇性評估的情況下所能達到的水準。例如，在 GPT-4 幾乎從未達到 80% 人類共識的 Chatbot Arena 的一個子集中，我們的模型即使採用了諸如 Mistral-7B 等具有顯著成本效益的模型，也能保證超過 80% 的人類共識，測試覆蓋率接近 80%。</paragraph>

##### **Robust Claim Verification Through Fact Detection**
2407.18367v1 by Nazanin Jafari, James Allan

Claim verification can be a challenging task. In this paper, we present a
method to enhance the robustness and reasoning capabilities of automated claim
verification through the extraction of short facts from evidence. Our novel
approach, FactDetect, leverages Large Language Models (LLMs) to generate
concise factual statements from evidence and label these facts based on their
semantic relevance to the claim and evidence. The generated facts are then
combined with the claim and evidence. To train a lightweight supervised model,
we incorporate a fact-detection task into the claim verification process as a
multitasking approach to improve both performance and explainability. We also
show that augmenting FactDetect in the claim verification prompt enhances
performance in zero-shot claim verification using LLMs. Our method demonstrates
competitive results in the supervised claim verification model by 15% on the F1
score when evaluated for challenging scientific claim verification datasets. We
also demonstrate that FactDetect can be augmented with claim and evidence for
zero-shot prompting (AugFactDetect) in LLMs for verdict prediction. We show
that AugFactDetect outperforms the baseline with statistical significance on
three challenging scientific claim verification datasets with an average of
17.3% performance gain compared to the best performing baselines.

摘要：聲明驗證可能是一項具有挑戰性的任務。在本文中，我們提出了一種透過從證據中萃取簡短事實來增強自動化聲明驗證的穩健性和推理能力的方法。我們創新的方法 FactDetect 利用大型語言模型 (LLM) 從證據中產生簡潔的事實陳述，並根據這些事實與聲明和證據的語義相關性標記這些事實。然後將產生的事實與聲明和證據結合。為了訓練一個輕量化的監督模型，我們將事實偵測任務融入聲明驗證過程中，作為一種多任務方法來提升效能和可解釋性。我們也顯示在聲明驗證提示中擴充 FactDetect 可透過 LLM 增強零次學習聲明驗證的效能。我們的這項方法在有監督的聲明驗證模型中展現出競爭力的結果，在針對具有挑戰性的科學聲明驗證資料集進行評估時，F1 分數提升了 15%。我們也展示 FactDetect 可以擴充聲明和證據，以在 LLM 中進行零次學習提示（AugFactDetect），用於判決預測。我們顯示 AugFactDetect 在三個具有挑戰性的科學聲明驗證資料集上以統計顯著性優於基準，與效能表現最佳的基準相比，平均效能提升 17.3%。

##### **FADAS: Towards Federated Adaptive Asynchronous Optimization**
2407.18365v1 by Yujia Wang, Shiqiang Wang, Songtao Lu, Jinghui Chen

Federated learning (FL) has emerged as a widely adopted training paradigm for
privacy-preserving machine learning. While the SGD-based FL algorithms have
demonstrated considerable success in the past, there is a growing trend towards
adopting adaptive federated optimization methods, particularly for training
large-scale models. However, the conventional synchronous aggregation design
poses a significant challenge to the practical deployment of those adaptive
federated optimization methods, particularly in the presence of straggler
clients. To fill this research gap, this paper introduces federated adaptive
asynchronous optimization, named FADAS, a novel method that incorporates
asynchronous updates into adaptive federated optimization with provable
guarantees. To further enhance the efficiency and resilience of our proposed
method in scenarios with significant asynchronous delays, we also extend FADAS
with a delay-adaptive learning adjustment strategy. We rigorously establish the
convergence rate of the proposed algorithms and empirical results demonstrate
the superior performance of FADAS over other asynchronous FL baselines.

摘要：聯合學習 (FL) 已成為廣泛採用的訓練範例，用於保護隱私的機器學習。儘管基於 SGD 的 FL 演算法過去已證明相當成功，但目前有愈來愈多人傾向採用適應性聯合最佳化方法，特別是針對訓練大型模型。然而，傳統的同步聚合設計對那些適應性聯合最佳化方法的實際部署構成重大挑戰，特別是在存在落後用戶端的情況下。為了填補這項研究空白，本文介紹聯合適應性非同步最佳化，稱為 FADAS，這是一種新穎的方法，將非同步更新納入適應性聯合最佳化，並提供可驗證的保證。為了進一步提升我們所提出的方法在存在大量非同步延遲情況下的效率和復原力，我們也以延遲適應型學習調整策略延伸 FADAS。我們嚴謹地建立所提出的演算法的收斂率，而經驗結果證明 FADAS 優於其他非同步 FL 基準的卓越效能。

##### **Generative AI like ChatGPT in Blockchain Federated Learning: use cases, opportunities and future**
2407.18358v1 by Sai Puppala, Ismail Hossain, Md Jahangir Alam, Sajedul Talukder, Jannatul Ferdaus, Mahedi Hasan, Sameera Pisupati, Shanmukh Mathukumilli

Federated learning has become a significant approach for training machine
learning models using decentralized data without necessitating the sharing of
this data. Recently, the incorporation of generative artificial intelligence
(AI) methods has provided new possibilities for improving privacy, augmenting
data, and customizing models. This research explores potential integrations of
generative AI in federated learning, revealing various opportunities to enhance
privacy, data efficiency, and model performance. It particularly emphasizes the
importance of generative models like generative adversarial networks (GANs) and
variational autoencoders (VAEs) in creating synthetic data that replicates the
distribution of real data. Generating synthetic data helps federated learning
address challenges related to limited data availability and supports robust
model development. Additionally, we examine various applications of generative
AI in federated learning that enable more personalized solutions.

摘要：聯邦學習已成為一種重要的訓練機器學習模型的方法，它使用分散式數據，而無需分享這些數據。最近，生成式人工智慧 (AI) 方法的納入為改善隱私、擴充數據和客製化模型提供了新的可能性。本研究探討了生成式 AI 在聯邦學習中的潛在整合，揭示了各種增強隱私、數據效率和模型效能的機會。它特別強調了生成式對抗網路 (GAN) 和變異自動編碼器 (VAE) 等生成式模型在建立複製真實數據分布的合成數據中的重要性。生成合成數據有助於聯邦學習解決與數據可用性有限相關的挑戰，並支援穩健的模型開發。此外，我們探討了生成式 AI 在聯邦學習中的各種應用，這些應用能實現更個人化的解決方案。

##### **Introducing δ-XAI: a novel sensitivity-based method for local AI explanations**
2407.18343v1 by Alessandro De Carlo, Enea Parimbelli, Nicola Melillo, Giovanna Nicora

Explainable Artificial Intelligence (XAI) is central to the debate on
integrating Artificial Intelligence (AI) and Machine Learning (ML) algorithms
into clinical practice. High-performing AI/ML models, such as ensemble learners
and deep neural networks, often lack interpretability, hampering clinicians'
trust in their predictions. To address this, XAI techniques are being developed
to describe AI/ML predictions in human-understandable terms. One promising
direction is the adaptation of sensitivity analysis (SA) and global sensitivity
analysis (GSA), which inherently rank model inputs by their impact on
predictions. Here, we introduce a novel delta-XAI method that provides local
explanations of ML model predictions by extending the delta index, a GSA
metric. The delta-XAI index assesses the impact of each feature's value on the
predicted output for individual instances in both regression and classification
problems. We formalize the delta-XAI index and provide code for its
implementation. The delta-XAI method was evaluated on simulated scenarios using
linear regression models, with Shapley values serving as a benchmark. Results
showed that the delta-XAI index is generally consistent with Shapley values,
with notable discrepancies in models with highly impactful or extreme feature
values. The delta-XAI index demonstrated higher sensitivity in detecting
dominant features and handling extreme feature values. Qualitatively, the
delta-XAI provides intuitive explanations by leveraging probability density
functions, making feature rankings clearer and more explainable for
practitioners. Overall, the delta-XAI method appears promising for robustly
obtaining local explanations of ML model predictions. Further investigations in
real-world clinical settings will be conducted to evaluate its impact on
AI-assisted clinical workflows.

摘要：可解釋人工智慧 (XAI) 是整合人工智慧 (AI) 和機器學習 (ML) 演算法進入臨床實務的辯論核心。高性能的 AI/ML 模型，例如整合學習器和深度神經網路，通常缺乏可解釋性，阻礙臨床醫師對其預測的信任。為了解決此問題，XAI 技術正在開發中，用人類可理解的術語描述 AI/ML 預測。一個有希望的方向是採用敏感度分析 (SA) 和全局敏感度分析 (GSA)，它們本質上按模型輸入對預測的影響對其進行排序。在此，我們介紹了一種新的 delta-XAI 方法，它通過擴展 GSA 指標 delta 指數，提供了 ML 模型預測的局部解釋。delta-XAI 指數評估了每個特徵值對迴歸和分類問題中個別實例的預測輸出之影響。我們將 delta-XAI 指數形式化並提供其實作程式碼。delta-XAI 方法使用線性迴歸模型在模擬場景中進行評估，其中 Shapley 值作為基準。結果表明，delta-XAI 指數通常與 Shapley 值一致，在具有高度影響力或極端特徵值的模型中存在顯著差異。delta-XAI 指數在檢測主要特徵和處理極端特徵值方面表現出更高的敏感性。定性地說，delta-XAI 透過利用機率密度函數提供直觀的解釋，使特徵排名更清晰、更易於從業人員理解。總體而言，delta-XAI 方法對於穩健地獲得 ML 模型預測的局部解釋似乎很有希望。將在真實世界的臨床環境中進行進一步調查，以評估其對 AI 輔助臨床工作流程的影響。

##### **Combining Cognitive and Generative AI for Self-explanation in Interactive AI Agents**
2407.18335v1 by Shalini Sushri, Rahul Dass, Rhea Basappa, Hong Lu, Ashok Goel

The Virtual Experimental Research Assistant (VERA) is an inquiry-based
learning environment that empowers a learner to build conceptual models of
complex ecological systems and experiment with agent-based simulations of the
models. This study investigates the convergence of cognitive AI and generative
AI for self-explanation in interactive AI agents such as VERA. From a cognitive
AI viewpoint, we endow VERA with a functional model of its own design,
knowledge, and reasoning represented in the Task--Method--Knowledge (TMK)
language. From the perspective of generative AI, we use ChatGPT, LangChain, and
Chain-of-Thought to answer user questions based on the VERA TMK model. Thus, we
combine cognitive and generative AI to generate explanations about how VERA
works and produces its answers. The preliminary evaluation of the generation of
explanations in VERA on a bank of 66 questions derived from earlier work
appears promising.

摘要：虛擬實驗研究助理 (VERA) 是一種基於探究的學習環境，它能讓學習者建立複雜生態系統的概念模型，並對模型的基於代理的模擬進行實驗。本研究探討了認知 AI 和生成式 AI 在 VERA 等互動式 AI 代理中的自我解釋的匯聚。從認知 AI 的觀點來看，我們賦予 VERA 一個以任務-方法-知識 (TMK) 語言表示的其自身設計、知識和推理的功能模型。從生成式 AI 的角度來看，我們使用 ChatGPT、LangChain 和思想鏈根據 VERA TMK 模型來回答使用者的問題。因此，我們結合認知 AI 和生成式 AI 來產生關於 VERA 如何運作並產生答案的解釋。VERA 在一組源自早期工作的 66 個問題中產生解釋的初步評估看來很有希望。

##### **Affectively Framework: Towards Human-like Affect-Based Agents**
2407.18316v1 by Matthew Barthet, Roberto Gallotta, Ahmed Khalifa, Antonios Liapis, Georgios N. Yannakakis

Game environments offer a unique opportunity for training virtual agents due
to their interactive nature, which provides diverse play traces and affect
labels. Despite their potential, no reinforcement learning framework
incorporates human affect models as part of their observation space or reward
mechanism. To address this, we present the \emph{Affectively Framework}, a set
of Open-AI Gym environments that integrate affect as part of the observation
space. This paper introduces the framework and its three game environments and
provides baseline experiments to validate its effectiveness and potential.

摘要：遊戲環境提供訓練虛擬代理人的獨特機會，因為它們的互動式性質提供了多樣的遊戲軌跡和影響標籤。儘管它們具有潛力，但沒有任何強化學習框架將人類影響模型納入其觀察空間或獎勵機制的一部分。為了解決這個問題，我們提出了「Affectively Framework」，這是一組 Open-AI Gym 環境，將影響作為觀察空間的一部分進行整合。本文介紹了這個框架及其三個遊戲環境，並提供了基準實驗來驗證其有效性和潛力。

##### **Revolutionizing Undergraduate Learning: CourseGPT and Its Generative AI Advancements**
2407.18310v1 by Ahmad M. Nazar, Mohamed Y. Selim, Ashraf Gaffar, Shakil Ahmed

Integrating Generative AI (GenAI) into educational contexts presents a
transformative potential for enhancing learning experiences. This paper
introduces CourseGPT, a generative AI tool designed to support instructors and
enhance the educational experiences of undergraduate students. Built on
open-source Large Language Models (LLMs) from Mistral AI, CourseGPT offers
continuous instructor support and regular updates to course materials,
enriching the learning environment. By utilizing course-specific content, such
as slide decks and supplementary readings and references, CourseGPT provides
precise, dynamically generated responses to student inquiries. Unlike generic
AI models, CourseGPT allows instructors to manage and control the responses,
thus extending the course scope without overwhelming details. The paper
demonstrates the application of CourseGPT using the CPR E 431 - Basics of
Information System Security course as a pilot. This course, with its large
enrollments and diverse curriculum, serves as an ideal testbed for CourseGPT.
The tool aims to enhance the learning experience, accelerate feedback
processes, and streamline administrative tasks. The study evaluates CourseGPT's
impact on student outcomes, focusing on correctness scores, context recall, and
faithfulness of responses. Results indicate that the Mixtral-8x7b model, with a
higher parameter count, outperforms smaller models, achieving an 88.0%
correctness score and a 66.6% faithfulness score. Additionally, feedback from
former students and teaching assistants on CourseGPT's accuracy, helpfulness,
and overall performance was collected. The outcomes revealed that a significant
majority found CourseGPT to be highly accurate and beneficial in addressing
their queries, with many praising its ability to provide timely and relevant
information.

摘要：<paragraph>將生成式 AI (GenAI) 整合到教育環境中，具備提升學習體驗的轉型潛力。本文介紹 CourseGPT，這是一款生成式 AI 工具，旨在支援教師並提升大學生的教育體驗。CourseGPT 建構於 Mistral AI 的開源大型語言模型 (LLM) 上，提供持續的教師支援和定期更新的課程教材，豐富學習環境。透過利用課程特定內容，例如投影片、補充讀物和參考資料，CourseGPT 能針對學生的詢問提供精確且動態產生的回應。與一般 AI 模型不同，CourseGPT 允許教師管理和控制回應，從而擴展課程範圍，而不會有過多細節。本文示範使用 CPR E 431 - 資訊系統安全基礎課程作為試點，來應用 CourseGPT。本課程註冊人數眾多，課程內容多元，是 CourseGPT 的理想測試平台。此工具旨在提升學習體驗、加速回饋流程，並簡化行政任務。本研究評估 CourseGPT 對學生成果的影響，重點在於正確性分數、內容回憶和回應的真實性。結果顯示，參數計數較高的 Mixtral-8x7b 模型優於較小的模型，正確性分數達到 88.0%，真實性分數達到 66.6%。此外，還收集了前學生和助教對 CourseGPT 的準確性、有益性和整體表現的回饋。結果顯示，絕大多數人發現 CourseGPT 在回答他們的疑問時非常準確且有益，許多人讚揚它能提供及時且相關的資訊。</paragraph>

##### **Self-Training with Direct Preference Optimization Improves Chain-of-Thought Reasoning**
2407.18248v1 by Tianduo Wang, Shichen Li, Wei Lu

Effective training of language models (LMs) for mathematical reasoning tasks
demands high-quality supervised fine-tuning data. Besides obtaining annotations
from human experts, a common alternative is sampling from larger and more
powerful LMs. However, this knowledge distillation approach can be costly and
unstable, particularly when relying on closed-source, proprietary LMs like
GPT-4, whose behaviors are often unpredictable. In this work, we demonstrate
that the reasoning abilities of small-scale LMs can be enhanced through
self-training, a process where models learn from their own outputs. We also
show that the conventional self-training can be further augmented by a
preference learning algorithm called Direct Preference Optimization (DPO). By
integrating DPO into self-training, we leverage preference data to guide LMs
towards more accurate and diverse chain-of-thought reasoning. We evaluate our
method across various mathematical reasoning tasks using different base models.
Our experiments show that this approach not only improves LMs' reasoning
performance but also offers a more cost-effective and scalable solution
compared to relying on large proprietary LMs.

摘要：要有效訓練數學推理任務的語言模型 (LM)，需要高品質的監督微調資料。除了從人類專家取得註解之外，一個常見的替代方案是從更大、更強大的 LM 中取樣。然而，這種知識蒸餾方法代價高昂且不穩定，特別是當依賴於封閉原始碼的專有 LM（例如 GPT-4）時，其行為通常難以預測。在這項工作中，我們證明了小規模 LM 的推理能力可以透過自訓練來增強，這是一個模型從自己的輸出中學習的過程。我們也展示了傳統的自訓練可以進一步透過一種稱為直接偏好最佳化 (DPO) 的偏好學習演算法來擴充。透過將 DPO 整合到自訓練中，我們利用偏好資料引導 LM 朝向更準確、更多樣化的思考鏈推理。我們使用不同的基礎模型，在各種數學推理任務中評估我們的模型。我們的實驗顯示，這種方法不僅改善了 LM 的推理效能，而且與依賴大型專有 LM 相比，還提供了一個更具成本效益且可擴充的解決方案。

##### **LoRA-Pro: Are Low-Rank Adapters Properly Optimized?**
2407.18242v1 by Zhengbo Wang, Jian Liang

Low-Rank Adaptation, also known as LoRA, has emerged as a prominent method
for parameter-efficient fine-tuning foundation models by re-parameterizing the
original matrix into the product of two low-rank matrices. Despite its
efficiency, LoRA often yields inferior performance compared to full
fine-tuning. In this paper, we propose LoRA-Pro to bridge this performance gap.
Firstly, we delve into the optimization processes in LoRA and full fine-tuning.
We reveal that while LoRA employs low-rank approximation, it neglects to
approximate the optimization process of full fine-tuning. To address this, we
introduce a novel concept called the "equivalent gradient." This virtual
gradient makes the optimization process on the re-parameterized matrix
equivalent to LoRA, which can be used to quantify the differences between LoRA
and full fine-tuning. The equivalent gradient is derived from the gradients of
matrices $A$ and $B$. To narrow the performance gap, our approach minimizes the
differences between the equivalent gradient and the gradient obtained from full
fine-tuning during the optimization process. By solving this objective, we
derive optimal closed-form solutions for updating matrices $A$ and $B$. Our
method constrains the optimization process, shrinking the performance gap
between LoRA and full fine-tuning. Extensive experiments on natural language
processing tasks validate the effectiveness of our method.

摘要：低秩適應（LoRA）已成為一種重要的方法，可透過將原始矩陣重新參數化為兩個低秩矩陣的乘積，對參數有效率的微調基礎模型。儘管 LoRA 具有效率，但與完整微調相比，其效能通常較差。在本文中，我們提出 LoRA-Pro 來彌合此效能差距。首先，我們深入探討 LoRA 和完整微調中的最佳化程序。我們揭示，儘管 LoRA 採用低秩近似，但它忽略了完整微調的最佳化程序。為了解決這個問題，我們引入了一個名為「等效梯度」的新概念。這個虛擬梯度使重新參數化矩陣上的最佳化程序等同於 LoRA，可用来量化 LoRA 和完整微調之間的差異。等效梯度來自矩陣 A 和 B 的梯度。為了縮小效能差距，我們的做法是在最佳化程序中最小化等效梯度和從完整微調中獲得的梯度之間的差異。透過解決這個目標，我們推導出更新矩陣 A 和 B 的最佳閉式解。我們的做法約束了最佳化程序，縮小了 LoRA 和完整微調之間的效能差距。自然語言處理任務上的大量實驗驗證了我們方法的有效性。

##### **Recursive Introspection: Teaching Language Model Agents How to Self-Improve**
2407.18219v2 by Yuxiao Qu, Tianjun Zhang, Naman Garg, Aviral Kumar

A central piece in enabling intelligent agentic behavior in foundation models
is to make them capable of introspecting upon their behavior, reasoning, and
correcting their mistakes as more computation or interaction is available. Even
the strongest proprietary large language models (LLMs) do not quite exhibit the
ability of continually improving their responses sequentially, even in
scenarios where they are explicitly told that they are making a mistake. In
this paper, we develop RISE: Recursive IntroSpEction, an approach for
fine-tuning LLMs to introduce this capability, despite prior work hypothesizing
that this capability may not be possible to attain. Our approach prescribes an
iterative fine-tuning procedure, which attempts to teach the model how to alter
its response after having executed previously unsuccessful attempts to solve a
hard test-time problem, with optionally additional environment feedback. RISE
poses fine-tuning for a single-turn prompt as solving a multi-turn Markov
decision process (MDP), where the initial state is the prompt. Inspired by
principles in online imitation learning and reinforcement learning, we propose
strategies for multi-turn data collection and training so as to imbue an LLM
with the capability to recursively detect and correct its previous mistakes in
subsequent iterations. Our experiments show that RISE enables Llama2, Llama3,
and Mistral models to improve themselves with more turns on math reasoning
tasks, outperforming several single-turn strategies given an equal amount of
inference-time computation. We also find that RISE scales well, often attaining
larger benefits with more capable models. Our analysis shows that RISE makes
meaningful improvements to responses to arrive at the correct solution for
challenging prompts, without disrupting one-turn abilities as a result of
expressing more complex distributions.

摘要：<paragraph>在基礎模型中啟用智能代理行為的核心部分是讓它們能夠內省自己的行為、推理，並在有更多運算或互動可用時糾正它們的錯誤。即使是最強大的專有大型語言模型 (LLM) 也不太會表現出連續改進其回應的能力，即使在明確告訴它們它們犯了錯誤的情況下也是如此。在本文中，我們開發了 RISE：遞迴內省，一種微調 LLM 以引入此功能的方法，儘管先前的工作假設可能無法獲得此功能。我們的做法規定了一個反覆微調程序，該程序試圖教導模型如何在執行先前不成功的嘗試以解決困難的測試時間問題後更改其響應，並可選擇額外提供環境回饋。RISE 將單輪提示的微調設定為解決多輪馬可夫決策過程 (MDP)，其中初始狀態是提示。受在線模仿學習和強化學習原理的啟發，我們提出了多輪數據收集和訓練策略，以便賦予 LLM 在後續迭代中遞歸檢測和糾正其先前錯誤的能力。我們的實驗表明，RISE 使 Llama2、Llama3 和 Mistral 模型能夠在數學推理任務中通過更多輪次來改進自身，在給定相同推理時間計算的情況下，優於多種單輪策略。我們還發現 RISE 具有良好的擴展性，通常通過更強大的模型獲得更大的好處。我們的分析表明，RISE 對響應進行了有意義的改進，以獲得對具有挑戰性提示的正確解決方案，而不會因為表達更複雜的分布而破壞單輪能力。</paragraph>

##### **Exploring Scaling Trends in LLM Robustness**
2407.18213v2 by Nikolaus Howe, Michał Zajac, Ian McKenzie, Oskar Hollinsworth, Tom Tseng, Pierre-Luc Bacon, Adam Gleave

Language model capabilities predictably improve from scaling a model's size
and training data. Motivated by this, increasingly large language models have
been trained, yielding an array of impressive capabilities. Yet these models
are vulnerable to adversarial prompts, such as "jailbreaks" that hijack models
to perform undesired behaviors, posing a significant risk of misuse. Prior work
indicates that computer vision models become more robust with model and data
scaling, raising the question: does language model robustness also improve with
scale? We study this question empirically, finding that larger models respond
substantially better to adversarial training, but there is little to no benefit
from model scale in the absence of explicit defenses.

摘要：語言模型的能力可預測地從擴展模型大小和訓練資料中獲得改善。受此啟發，已經訓練出越來越大的語言模型，產生了一系列令人印象深刻的能力。然而，這些模型容易受到對抗性提示的影響，例如劫持模型以執行不需要的行為的「越獄」，對誤用構成重大風險。先前的研究表明，電腦視覺模型隨著模型和資料的擴展而變得更強大，這引發了一個問題：語言模型的穩健性是否也隨著規模而提高？我們以經驗研究這個問題，發現較大的模型對對抗性訓練的反應顯著更好，但在沒有明確防禦措施的情況下，模型規模幾乎沒有好處。

##### **Differentiable Quantum Architecture Search in Asynchronous Quantum Reinforcement Learning**
2407.18202v1 by Samuel Yen-Chi Chen

The emergence of quantum reinforcement learning (QRL) is propelled by
advancements in quantum computing (QC) and machine learning (ML), particularly
through quantum neural networks (QNN) built on variational quantum circuits
(VQC). These advancements have proven successful in addressing sequential
decision-making tasks. However, constructing effective QRL models demands
significant expertise due to challenges in designing quantum circuit
architectures, including data encoding and parameterized circuits, which
profoundly influence model performance. In this paper, we propose addressing
this challenge with differentiable quantum architecture search (DiffQAS),
enabling trainable circuit parameters and structure weights using
gradient-based optimization. Furthermore, we enhance training efficiency
through asynchronous reinforcement learning (RL) methods facilitating parallel
training. Through numerical simulations, we demonstrate that our proposed
DiffQAS-QRL approach achieves performance comparable to manually-crafted
circuit architectures across considered environments, showcasing stability
across diverse scenarios. This methodology offers a pathway for designing QRL
models without extensive quantum knowledge, ensuring robust performance and
fostering broader application of QRL.

摘要：量子強化學習 (QRL) 的出現是由量子運算 (QC) 和機器學習 (ML) 的進步推動，特別是建立在變分量子電路 (VQC) 上的量子神經網路 (QNN)。這些進步已被證明在解決序貫決策任務方面是成功的。然而，構建有效的 QRL 模型需要大量的專業知識，因為在設計量子電路架構時會遇到挑戰，包括數據編碼和參數化電路，這會深刻影響模型性能。在本文中，我們提出使用可微分量子架構搜尋 (DiffQAS) 來解決這個挑戰，使用基於梯度的最佳化來啟用可訓練的電路參數和結構權重。此外，我們透過非同步強化學習 (RL) 方法來增強訓練效率，促進並行訓練。透過數值模擬，我們證明我們提出的 DiffQAS-QRL 方法達到了與人工製作的電路架構相當的性能，在各種環境中展現了穩定性。這種方法提供了一個在沒有廣泛量子知識的情況下設計 QRL 模型的途徑，確保了穩健的性能，並促進了 QRL 的更廣泛應用。

##### **Gene Regulatory Network Inference from Pre-trained Single-Cell Transcriptomics Transformer with Joint Graph Learning**
2407.18181v1 by Sindhura Kommu, Yizhi Wang, Yue Wang, Xuan Wang

Inferring gene regulatory networks (GRNs) from single-cell RNA sequencing
(scRNA-seq) data is a complex challenge that requires capturing the intricate
relationships between genes and their regulatory interactions. In this study,
we tackle this challenge by leveraging the single-cell BERT-based pre-trained
transformer model (scBERT), trained on extensive unlabeled scRNA-seq data, to
augment structured biological knowledge from existing GRNs. We introduce a
novel joint graph learning approach that combines the rich contextual
representations learned by pre-trained single-cell language models with the
structured knowledge encoded in GRNs using graph neural networks (GNNs). By
integrating these two modalities, our approach effectively reasons over boththe
gene expression level constraints provided by the scRNA-seq data and the
structured biological knowledge inherent in GRNs. We evaluate our method on
human cell benchmark datasets from the BEELINE study with cell type-specific
ground truth networks. The results demonstrate superior performance over
current state-of-the-art baselines, offering a deeper understanding of cellular
regulatory mechanisms.

摘要：從單細胞 RNA 定序 (scRNA-seq) 資料推論基因調控網路 (GRN) 是一項複雜的挑戰，需要掌握基因與其調控交互作用之間的複雜關係。在此研究中，我們透過利用在廣泛的未標記 scRNA-seq 資料上訓練的單細胞 BERT 基於預訓練轉換器模型 (scBERT)，來克服此挑戰，以擴充現有 GRN 中的結構化生物知識。我們引入一種新穎的聯合圖形學習方法，它結合了預訓練單細胞語言模型所學習到的豐富脈絡表徵，以及使用圖形神經網路 (GNN) 對 GRN 中編碼的結構化知識。透過整合這兩種方式，我們的做法有效地對 scRNA-seq 資料提供的基因表現層級約束和 GRN 中固有的結構化生物知識進行推理。我們使用 BEELINE 研究中的人類細胞基準資料集，以及細胞類型特定的基本事實網路，來評估我們的方法。結果證明其效能優於目前最先進的基準，提供了對細胞調控機制的更深入理解。

##### **Quasar-ViT: Hardware-Oriented Quantization-Aware Architecture Search for Vision Transformers**
2407.18175v1 by Zhengang Li, Alec Lu, Yanyue Xie, Zhenglun Kong, Mengshu Sun, Hao Tang, Zhong Jia Xue, Peiyan Dong, Caiwen Ding, Yanzhi Wang, Xue Lin, Zhenman Fang

Vision transformers (ViTs) have demonstrated their superior accuracy for
computer vision tasks compared to convolutional neural networks (CNNs).
However, ViT models are often computation-intensive for efficient deployment on
resource-limited edge devices. This work proposes Quasar-ViT, a
hardware-oriented quantization-aware architecture search framework for ViTs, to
design efficient ViT models for hardware implementation while preserving the
accuracy. First, Quasar-ViT trains a supernet using our row-wise flexible
mixed-precision quantization scheme, mixed-precision weight entanglement, and
supernet layer scaling techniques. Then, it applies an efficient
hardware-oriented search algorithm, integrated with hardware latency and
resource modeling, to determine a series of optimal subnets from supernet under
different inference latency targets. Finally, we propose a series of
model-adaptive designs on the FPGA platform to support the architecture search
and mitigate the gap between the theoretical computation reduction and the
practical inference speedup. Our searched models achieve 101.5, 159.6, and
251.6 frames-per-second (FPS) inference speed on the AMD/Xilinx ZCU102 FPGA
with 80.4%, 78.6%, and 74.9% top-1 accuracy, respectively, for the ImageNet
dataset, consistently outperforming prior works.

摘要：<paragraph>與卷積神經網路（CNN）相比，視覺轉換器（ViT）已證明其在電腦視覺任務上的優異準確度。然而，ViT 模型通常在計算上很密集，無法在資源有限的邊緣裝置上有效率地部署。這項工作提出了 Quasar-ViT，一個面向硬體的量化感知架構搜尋框架，用於 ViT，以設計高效的 ViT 模型進行硬體實作，同時保持準確度。首先，Quasar-ViT 使用我們列式彈性混合精度量化方案、混合精度權重糾纏和超網路層縮放技術來訓練超網路。然後，它應用一個有效率的面向硬體的搜尋演算法，整合硬體延遲和資源建模，以在不同的推論延遲目標下從超網路中確定一系列最佳子網路。最後，我們在 FPGA 平臺上提出了一系列模型自適應設計，以支援架構搜尋並縮小理論運算減少和實際推論加速之間的差距。我們搜尋的模型在 AMD/Xilinx ZCU102 FPGA 上分別以 80.4%、78.6% 和 74.9% 的 top-1 準確度，達到 101.5、159.6 和 251.6 幀每秒 (FPS) 的推論速度，用於 ImageNet 資料集，始終優於先前的研究。</paragraph>

##### **The FIGNEWS Shared Task on News Media Narratives**
2407.18147v1 by Wajdi Zaghouani, Mustafa Jarrar, Nizar Habash, Houda Bouamor, Imed Zitouni, Mona Diab, Samhaa R. El-Beltagy, Muhammed AbuOdeh

We present an overview of the FIGNEWS shared task, organized as part of the
ArabicNLP 2024 conference co-located with ACL 2024. The shared task addresses
bias and propaganda annotation in multilingual news posts. We focus on the
early days of the Israel War on Gaza as a case study. The task aims to foster
collaboration in developing annotation guidelines for subjective tasks by
creating frameworks for analyzing diverse narratives highlighting potential
bias and propaganda. In a spirit of fostering and encouraging diversity, we
address the problem from a multilingual perspective, namely within five
languages: English, French, Arabic, Hebrew, and Hindi. A total of 17 teams
participated in two annotation subtasks: bias (16 teams) and propaganda (6
teams). The teams competed in four evaluation tracks: guidelines development,
annotation quality, annotation quantity, and consistency. Collectively, the
teams produced 129,800 data points. Key findings and implications for the field
are discussed.

摘要：<paragraph>我們概述了 FIGNEWS 共享任務，該任務作為 ArabicNLP 2024 會議的一部分，與 ACL 2024 共同舉辦。共享任務處理多語言新聞文章中的偏見和宣傳標註。我們專注於以色列對加薩戰爭的早期作為案例研究。該任務旨在通過建立分析不同敘述的框架來促進開發主觀任務的標註指南，重點是潛在的偏見和宣傳。本著培養和鼓勵多樣性的精神，我們從多語言的角度來解決這個問題，即在五種語言中：英語、法語、阿拉伯語、希伯來語和印地語。共有 17 個團隊參與了兩個標註子任務：偏見（16 個團隊）和宣傳（6 個團隊）。這些團隊參加了四個評估軌道：指南制定、標註品質、標註數量和一致性。總的來說，這些團隊產生了 129,800 個數據點。討論了該領域的關鍵發現和影響。</paragraph>

##### **Taxonomy-Aware Continual Semantic Segmentation in Hyperbolic Spaces for Open-World Perception**
2407.18145v1 by Julia Hindel, Daniele Cattaneo, Abhinav Valada

Semantic segmentation models are typically trained on a fixed set of classes,
limiting their applicability in open-world scenarios. Class-incremental
semantic segmentation aims to update models with emerging new classes while
preventing catastrophic forgetting of previously learned ones. However,
existing methods impose strict rigidity on old classes, reducing their
effectiveness in learning new incremental classes. In this work, we propose
Taxonomy-Oriented Poincar\'e-regularized Incremental-Class Segmentation
(TOPICS) that learns feature embeddings in hyperbolic space following explicit
taxonomy-tree structures. This supervision provides plasticity for old classes,
updating ancestors based on new classes while integrating new classes at
fitting positions. Additionally, we maintain implicit class relational
constraints on the geometric basis of the Poincar\'e ball. This ensures that
the latent space can continuously adapt to new constraints while maintaining a
robust structure to combat catastrophic forgetting. We also establish eight
realistic incremental learning protocols for autonomous driving scenarios,
where novel classes can originate from known classes or the background.
Extensive evaluations of TOPICS on the Cityscapes and Mapillary Vistas 2.0
benchmarks demonstrate that it achieves state-of-the-art performance. We make
the code and trained models publicly available at
http://topics.cs.uni-freiburg.de.

摘要：語意分割模型通常在固定的類別集合上訓練，
限制了它們在開放世界場景中的適用性。類別遞增
語意分割旨在使用新出現的類別更新模型，同時
防止災難性地遺忘先前學習的類別。然而，
現有方法對舊類別施加嚴格的剛性，降低了它們
學習新遞增類別的有效性。在這項工作中，我們提出
面向分類學的龐加萊正則化遞增類別分割 (TOPICS)，它在雙曲空間中學習特徵嵌入，遵循明確的
分類樹結構。這種監督為舊類別提供可塑性，
在適當的位置整合新類別的同時，基於新類別更新祖先。此外，我們在龐加萊球的幾何基礎上維持隱式類別關係約束。這確保了
潛在空間可以持續適應新約束，同時維持穩固的結構以對抗災難性遺忘。我們還為自動駕駛場景建立了八個
現實的遞增學習協定，其中新類別可以源自已知類別或背景。
在 Cityscapes 和 Mapillary Vistas 2.0 上對 TOPICS 的廣泛評估
基準證明它達到了最先進的效能。我們將
程式碼和訓練好的模型公開於
http://topics.cs.uni-freiburg.de。

##### **Dallah: A Dialect-Aware Multimodal Large Language Model for Arabic**
2407.18129v2 by Fakhraddin Alwajih, Gagan Bhatia, Muhammad Abdul-Mageed

Recent advancements have significantly enhanced the capabilities of
Multimodal Large Language Models (MLLMs) in generating and understanding
image-to-text content. Despite these successes, progress is predominantly
limited to English due to the scarcity of high quality multimodal resources in
other languages. This limitation impedes the development of competitive models
in languages such as Arabic. To alleviate this situation, we introduce an
efficient Arabic multimodal assistant, dubbed Dallah, that utilizes an advanced
language model based on LLaMA-2 to facilitate multimodal interactions. Dallah
demonstrates state-of-the-art performance in Arabic MLLMs. Through fine-tuning
six Arabic dialects, Dallah showcases its capability to handle complex
dialectal interactions incorporating both textual and visual elements. The
model excels in two benchmark tests: one evaluating its performance on Modern
Standard Arabic (MSA) and another specifically designed to assess dialectal
responses. Beyond its robust performance in multimodal interaction tasks,
Dallah has the potential to pave the way for further development of
dialect-aware Arabic MLLMs.

摘要：最近的進展顯著增強了多模態大型語言模型 (MLLM) 在產生和理解圖像到文字內容方面的能力。儘管取得了這些成功，但由於其他語言中缺乏高品質的多模態資源，進展主要僅限於英語。這種限制阻礙了在阿拉伯語等語言中開發競爭模型。為了緩解這種情況，我們引入了一個高效的阿拉伯語多模態助理，名為 Dallah，它利用基於 LLaMA-2 的先進語言模型來促進多模態互動。Dallah 在阿拉伯語 MLLM 中展示了最先進的性能。通過微調六種阿拉伯語方言，Dallah 展示了其處理複雜方言互動的能力，包括文本和視覺元素。該模型在兩個基準測試中表現出色：一個評估其在現代標準阿拉伯語 (MSA) 上的性能，另一個專門設計用於評估方言回應。除了在多模態互動任務中表現出色外，Dallah 還有可能為進一步開發具有方言意識的阿拉伯語 MLLM 鋪平道路。

##### **Self-supervised pre-training with diffusion model for few-shot landmark detection in x-ray images**
2407.18125v1 by Roberto Di Via, Francesca Odone, Vito Paolo Pastore

In the last few years, deep neural networks have been extensively applied in
the medical domain for different tasks, ranging from image classification and
segmentation to landmark detection. However, the application of these
technologies in the medical domain is often hindered by data scarcity, both in
terms of available annotations and images. This study introduces a new
self-supervised pre-training protocol based on diffusion models for landmark
detection in x-ray images. Our results show that the proposed self-supervised
framework can provide accurate landmark detection with a minimal number of
available annotated training images (up to 50), outperforming ImageNet
supervised pre-training and state-of-the-art self-supervised pre-trainings for
three popular x-ray benchmark datasets. To our knowledge, this is the first
exploration of diffusion models for self-supervised learning in landmark
detection, which may offer a valuable pre-training approach in few-shot
regimes, for mitigating data scarcity.

摘要：在過去幾年中，深度神經網路已廣泛應用於醫療領域的不同任務，從影像分類和分割到地標偵測。然而，這些技術在醫療領域的應用常常受到資料稀少的阻礙，無論是在可用的註解或影像方面。本研究介紹了一個新的自監督預訓練協定，它是基於擴散模型，用於 X 光影像中的地標偵測。我們的結果顯示，所提出的自監督架構可以在最少數量的可用註解訓練影像（最多 50 個）下提供準確的地標偵測，優於 ImageNet 監督式預訓練以及三個熱門 X 光基準資料集的最新自監督式預訓練。據我們所知，這是首次探討擴散模型用於地標偵測中的自監督式學習，它可能在小樣本訓練模式中提供有價值的預訓練方法，以減輕資料稀少的問題。

##### **Tracking linguistic information in transformer-based sentence embeddings through targeted sparsification**
2407.18119v1 by Vivi Nastase, Paola Merlo

Analyses of transformer-based models have shown that they encode a variety of
linguistic information from their textual input. While these analyses have shed
a light on the relation between linguistic information on one side, and
internal architecture and parameters on the other, a question remains
unanswered: how is this linguistic information reflected in sentence
embeddings? Using datasets consisting of sentences with known structure, we
test to what degree information about chunks (in particular noun, verb or
prepositional phrases), such as grammatical number, or semantic role, can be
localized in sentence embeddings. Our results show that such information is not
distributed over the entire sentence embedding, but rather it is encoded in
specific regions. Understanding how the information from an input text is
compressed into sentence embeddings helps understand current transformer models
and help build future explainable neural models.

摘要：基於Transformer的模型分析顯示，它們會對文本輸入編碼各種語言資訊。儘管這些分析已闡明一方面語言資訊與另一方面內部架構和參數之間的關係，但仍有一個問題未獲得解答：這種語言資訊是如何反映在句子嵌入中？我們使用包含已知結構句子的資料集，測試有關區塊（特別是名詞、動詞或介系詞短語）的資訊，例如文法數或語意角色，可以在何種程度上定位在句子嵌入中。我們的結果顯示，此類資訊並未分佈在整個句子嵌入中，而是編碼在特定區域中。了解輸入文字的資訊如何壓縮到句子嵌入中，有助於了解目前的Transformer模型，並有助於建構未來可解釋的神經模型。

##### **Multi-Resolution Histopathology Patch Graphs for Ovarian Cancer Subtyping**
2407.18105v1 by Jack Breen, Katie Allen, Kieran Zucker, Nicolas M. Orsi, Nishant Ravikumar

Computer vision models are increasingly capable of classifying ovarian
epithelial cancer subtypes, but they differ from pathologists by processing
small tissue patches at a single resolution. Multi-resolution graph models
leverage the spatial relationships of patches at multiple magnifications,
learning the context for each patch. In this study, we conduct the most
thorough validation of a graph model for ovarian cancer subtyping to date.
Seven models were tuned and trained using five-fold cross-validation on a set
of 1864 whole slide images (WSIs) from 434 patients treated at Leeds Teaching
Hospitals NHS Trust. The cross-validation models were ensembled and evaluated
using a balanced hold-out test set of 100 WSIs from 30 patients, and an
external validation set of 80 WSIs from 80 patients in the Transcanadian Study.
The best-performing model, a graph model using 10x+20x magnification data, gave
balanced accuracies of 73%, 88%, and 99% in cross-validation, hold-out testing,
and external validation, respectively. However, this only exceeded the
performance of attention-based multiple instance learning in external
validation, with a 93% balanced accuracy. Graph models benefitted greatly from
using the UNI foundation model rather than an ImageNet-pretrained ResNet50 for
feature extraction, with this having a much greater effect on performance than
changing the subsequent classification approach. The accuracy of the combined
foundation model and multi-resolution graph network offers a step towards the
clinical applicability of these models, with a new highest-reported performance
for this task, though further validations are still required to ensure the
robustness and usability of the models.

摘要：電腦視覺模型越來越能夠分類卵巢上皮癌的亞型，但它們與病理學家不同，它們以單一解析度處理小組織貼片。多解析度圖形模型利用多個放大倍率下貼片的空間關係，學習每個貼片的背景。在這項研究中，我們對圖形模型進行了迄今為止最徹底的卵巢癌亞型驗證。使用 434 名在利茲教學醫院 NHS 信託基金接受治療的患者的 1864 張全幻燈片影像 (WSI) 進行五倍交叉驗證，調整並訓練了七個模型。將交叉驗證模型集成並使用來自 30 名患者的 100 張 WSI 的平衡留出測試集和來自 Transcanadian 研究中 80 名患者的 80 張 WSI 的外部驗證集進行評估。表現最佳的模型，一個使用 10 倍+20 倍放大倍率資料的圖形模型，在交叉驗證、留出測試和外部驗證中分別給出 73%、88% 和 99% 的平衡準確度。然而，這僅超過了外部驗證中基於注意力的多實例學習的表現，平衡準確度為 93%。圖形模型從使用 UNI 基礎模型而不是 ImageNet 預訓練的 ResNet50 進行特徵提取中受益匪淺，與改變後續分類方法相比，這對效能有更大的影響。結合基礎模型和多解析度圖形網路的準確度為這些模型的臨床應用邁出了一步，對於這項任務來說，這是新的最高報告表現，儘管仍需要進一步的驗證來確保模型的穩健性和可用性。

##### **Privacy Threats and Countermeasures in Federated Learning for Internet of Things: A Systematic Review**
2407.18096v1 by Adel ElZemity, Budi Arief

Federated Learning (FL) in the Internet of Things (IoT) environments can
enhance machine learning by utilising decentralised data, but at the same time,
it might introduce significant privacy and security concerns due to the
constrained nature of IoT devices. This represents a research challenge that we
aim to address in this paper. We systematically analysed recent literature to
identify privacy threats in FL within IoT environments, and evaluate the
defensive measures that can be employed to mitigate these threats. Using a
Systematic Literature Review (SLR) approach, we searched five publication
databases (Scopus, IEEE Xplore, Wiley, ACM, and Science Direct), collating
relevant papers published between 2017 and April 2024, a period which spans
from the introduction of FL until now. Guided by the PRISMA protocol, we
selected 49 papers to focus our systematic review on. We analysed these papers,
paying special attention to the privacy threats and defensive measures --
specifically within the context of IoT -- using inclusion and exclusion
criteria tailored to highlight recent advances and critical insights. We
identified various privacy threats, including inference attacks, poisoning
attacks, and eavesdropping, along with defensive measures such as Differential
Privacy and Secure Multi-Party Computation. These defences were evaluated for
their effectiveness in protecting privacy without compromising the functional
integrity of FL in IoT settings. Our review underscores the necessity for
robust and efficient privacy-preserving strategies tailored for IoT
environments. Notably, there is a need for strategies against replay, evasion,
and model stealing attacks. Exploring lightweight defensive measures and
emerging technologies such as blockchain may help improve the privacy of FL in
IoT, leading to the creation of FL models that can operate under variable
network conditions.

摘要：<paragraph>聯邦學習 (FL) 在物聯網 (IoT) 環境中可以利用分散式數據增強機器學習，但同時，由於 IoT 設備的受限性質，它可能會帶來重大的隱私和安全問題。這是一個研究挑戰，我們希望在本文中解決這個問題。我們系統地分析了最近的文獻，以識別 IoT 環境中 FL 中的隱私威脅，並評估可採取的防禦措施來減輕這些威脅。使用系統文獻回顧 (SLR) 方法，我們搜索了五個出版物資料庫（Scopus、IEEE Xplore、Wiley、ACM 和 Science Direct），整理了 2017 年至 2024 年 4 月之間發表的相關論文，這段時間涵蓋了 FL 的引入至今。在 PRISMA 協議的指導下，我們選擇了 49 篇論文作為系統回顧的重點。我們分析了這些論文，特別關注隱私威脅和防禦措施——特別是在 IoT 的背景下——使用量身定制的包含和排除標準來強調最近的進展和批判性見解。我們發現了各種隱私威脅，包括推理攻擊、中毒攻擊和竊聽，以及防禦措施，例如差分隱私和安全多方計算。這些防禦措施的有效性在於保護隱私，同時不損害 IoT 設置中 FL 的功能完整性。我們的回顧強調了針對 IoT 環境量身定制的強大且有效的隱私保護策略的必要性。值得注意的是，需要針對重播、規避和模型竊取攻擊制定策略。探索輕量級防禦措施和區塊鏈等新興技術可能有助於提高 IoT 中 FL 的隱私性，從而創建可在變量網路條件下運作的 FL 模型。</paragraph>

##### **PEFT-U: Parameter-Efficient Fine-Tuning for User Personalization**
2407.18078v1 by Christopher Clarke, Yuzhao Heng, Lingjia Tang, Jason Mars

The recent emergence of Large Language Models (LLMs) has heralded a new era
of human-AI interaction. These sophisticated models, exemplified by Chat-GPT
and its successors, have exhibited remarkable capabilities in language
understanding. However, as these LLMs have undergone exponential growth, a
crucial dimension that remains understudied is the personalization of these
models. Large foundation models such as GPT-3 etc. focus on creating a
universal model that serves a broad range of tasks and users. This approach
emphasizes the model's generalization capabilities, treating users as a
collective rather than as distinct individuals. While practical for many common
applications, this one-size-fits-all approach often fails to address the rich
tapestry of human diversity and individual needs. To explore this issue we
introduce the PEFT-U Benchmark: a new dataset for building and evaluating NLP
models for user personalization. \datasetname{} consists of a series of
user-centered tasks containing diverse and individualized expressions where the
preferences of users can potentially differ for the same input. Using PEFT-U,
we explore the challenge of efficiently personalizing LLMs to accommodate
user-specific preferences in the context of diverse user-centered tasks.

摘要：大型語言模型 (LLM) 近期興起，預示著人機互動的新紀元。這些精密的模型，以 Chat-GPT 及其後繼者為例，在語言理解方面展現了非凡的能力。然而，隨著這些 LLM 經歷指數級增長，一個仍未得到充分研究的重要面向是這些模型的個人化。大型基礎模型，例如 GPT-3 等，專注於建立一個通用的模型，服務於廣泛的任務和使用者。此方法強調模型的概化能力，將使用者視為一個集體，而非獨立的個體。雖然對許多常見應用來說很實用，但這種一體適用的方法通常無法滿足人類多元性和個別需求的豐富性。為了探討此問題，我們引入了 PEFT-U 基準：一個用於建立和評估使用者個人化 NLP 模型的新資料集。\datasetname{} 包含一系列以使用者為中心的任務，其中包含多樣化且個性化的表達，使用者的偏好可能因相同的輸入而有所不同。使用 PEFT-U，我們探討了在多元化以使用者為中心的任務中，有效個人化 LLM 以適應使用者特定偏好的挑戰。

##### **Difficulty Estimation and Simplification of French Text Using LLMs**
2407.18061v1 by Henri Jamet, Yash Raj Shrestha, Michalis Vlachos

We leverage generative large language models for language learning
applications, focusing on estimating the difficulty of foreign language texts
and simplifying them to lower difficulty levels. We frame both tasks as
prediction problems and develop a difficulty classification model using labeled
examples, transfer learning, and large language models, demonstrating superior
accuracy compared to previous approaches. For simplification, we evaluate the
trade-off between simplification quality and meaning preservation, comparing
zero-shot and fine-tuned performances of large language models. We show that
meaningful text simplifications can be obtained with limited fine-tuning. Our
experiments are conducted on French texts, but our methods are
language-agnostic and directly applicable to other foreign languages.

摘要：我們利用生成式大型語言模型進行語言學習應用，重點在於估計外語文本的難度並將其簡化為較低的難度等級。我們將這兩個任務都設定為預測問題，並使用標記範例、轉移學習和大語言模型開發難度分類模型，與先前的做法相比，證明了其優越的準確性。對於簡化，我們評估了簡化品質與意義保留之間的取捨，比較大型語言模型的零次學習和微調效能。我們表明，透過有限的微調，可以獲得有意義的文本簡化。我們的實驗是在法語文本上進行的，但我們的語言方法與語言無關，並且可直接應用於其他外語。

##### **Peak-Controlled Logits Poisoning Attack in Federated Distillation**
2407.18039v1 by Yuhan Tang, Aoxu Zhang, Zhiyuan Wu, Bo Gao, Tian Wen, Yuwei Wang, Sheng Sun

Federated Distillation (FD) offers an innovative approach to distributed
machine learning, leveraging knowledge distillation for efficient and flexible
cross-device knowledge transfer without necessitating the upload of extensive
model parameters to a central server. While FD has gained popularity, its
vulnerability to poisoning attacks remains underexplored. To address this gap,
we previously introduced FDLA (Federated Distillation Logits Attack), a method
that manipulates logits communication to mislead and degrade the performance of
client models. However, the impact of FDLA on participants with different
identities and the effects of malicious modifications at various stages of
knowledge transfer remain unexplored. To this end, we present PCFDLA
(Peak-Controlled Federated Distillation Logits Attack), an advanced and more
stealthy logits poisoning attack method for FD. PCFDLA enhances the
effectiveness of FDLA by carefully controlling the peak values of logits to
create highly misleading yet inconspicuous modifications. Furthermore, we
introduce a novel metric for better evaluating attack efficacy, demonstrating
that PCFDLA maintains stealth while being significantly more disruptive to
victim models compared to its predecessors. Experimental results across various
datasets confirm the superior impact of PCFDLA on model accuracy, solidifying
its potential threat in federated distillation systems.

摘要：联邦蒸馏 (FD) 提供了一种分布式机器学习的创新方法，它利用知识蒸馏来实现高效且灵活的跨设备知识转移，而无需将大量的模型参数上传到中央服务器。虽然 FD 已获得普及，但其对中毒攻击的脆弱性仍未得到充分探索。为了解决这一差距，我们之前引入了 FDLA（联邦蒸馏 Logits 攻击），这是一种通过操纵 Logits 通信来误导并降低客户端模型性能的方法。但是，FDLA 对具有不同身份的参与者的影响以及在知识转移的不同阶段进行恶意修改的影响仍未得到探索。为此，我们提出了 PCFDLA（峰值控制联邦蒸馏 Logits 攻击），这是一种针对 FD 的高级且更隐蔽的 Logits 中毒攻击方法。PCFDLA 通过仔细控制 Logits 的峰值来增强 FDLA 的有效性，以创建极具误导性但又不引人注目的修改。此外，我们引入了一个新指标来更好地评估攻击效果，证明 PCFDLA 在保持隐蔽性的同时，与之前的攻击方法相比，对受害者模型的破坏性更大。跨各种数据集的实验结果证实了 PCFDLA 对模型精度的卓越影响，巩固了其在联邦蒸馏系统中的潜在威胁。

##### **RestoreAgent: Autonomous Image Restoration Agent via Multimodal Large Language Models**
2407.18035v1 by Haoyu Chen, Wenbo Li, Jinjin Gu, Jingjing Ren, Sixiang Chen, Tian Ye, Renjing Pei, Kaiwen Zhou, Fenglong Song, Lei Zhu

Natural images captured by mobile devices often suffer from multiple types of
degradation, such as noise, blur, and low light. Traditional image restoration
methods require manual selection of specific tasks, algorithms, and execution
sequences, which is time-consuming and may yield suboptimal results. All-in-one
models, though capable of handling multiple tasks, typically support only a
limited range and often produce overly smooth, low-fidelity outcomes due to
their broad data distribution fitting. To address these challenges, we first
define a new pipeline for restoring images with multiple degradations, and then
introduce RestoreAgent, an intelligent image restoration system leveraging
multimodal large language models. RestoreAgent autonomously assesses the type
and extent of degradation in input images and performs restoration through (1)
determining the appropriate restoration tasks, (2) optimizing the task
sequence, (3) selecting the most suitable models, and (4) executing the
restoration. Experimental results demonstrate the superior performance of
RestoreAgent in handling complex degradation, surpassing human experts.
Furthermore, the system modular design facilitates the fast integration of new
tasks and models, enhancing its flexibility and scalability for various
applications.

摘要：行動裝置拍攝的自然影像通常會受到多種類型的劣化，例如雜訊、模糊和低光源。傳統的影像修復方法需要手動選擇特定任務、演算法和執行順序，這既耗時又可能產生次佳的結果。雖然一體成型的模型能夠處理多項任務，但通常只支援有限的範圍，而且由於其廣泛的資料分佈擬合，通常會產生過於平滑、低保真的結果。為了應對這些挑戰，我們首先定義了一個新的管道來修復具有多重劣化現象的影像，然後介紹 RestoreAgent，一個利用多模態大型語言模型的智慧影像修復系統。RestoreAgent 自主評估輸入影像的劣化類型和程度，並透過 (1) 確定適當的修復任務、(2) 最佳化任務順序、(3) 選擇最合適的模型，以及 (4) 執行修復來執行修復。實驗結果證明 RestoreAgent 在處理複雜劣化方面的優異效能，超越了人類專家。此外，系統模組化設計有助於快速整合新的任務和模型，增強其靈活性，並擴充其在各種應用程式中的可擴充性。

##### **AttentionHand: Text-driven Controllable Hand Image Generation for 3D Hand Reconstruction in the Wild**
2407.18034v1 by Junho Park, Kyeongbo Kong, Suk-Ju Kang

Recently, there has been a significant amount of research conducted on 3D
hand reconstruction to use various forms of human-computer interaction.
However, 3D hand reconstruction in the wild is challenging due to extreme lack
of in-the-wild 3D hand datasets. Especially, when hands are in complex pose
such as interacting hands, the problems like appearance similarity, self-handed
occclusion and depth ambiguity make it more difficult. To overcome these
issues, we propose AttentionHand, a novel method for text-driven controllable
hand image generation. Since AttentionHand can generate various and numerous
in-the-wild hand images well-aligned with 3D hand label, we can acquire a new
3D hand dataset, and can relieve the domain gap between indoor and outdoor
scenes. Our method needs easy-to-use four modalities (i.e, an RGB image, a hand
mesh image from 3D label, a bounding box, and a text prompt). These modalities
are embedded into the latent space by the encoding phase. Then, through the
text attention stage, hand-related tokens from the given text prompt are
attended to highlight hand-related regions of the latent embedding. After the
highlighted embedding is fed to the visual attention stage, hand-related
regions in the embedding are attended by conditioning global and local hand
mesh images with the diffusion-based pipeline. In the decoding phase, the final
feature is decoded to new hand images, which are well-aligned with the given
hand mesh image and text prompt. As a result, AttentionHand achieved
state-of-the-art among text-to-hand image generation models, and the
performance of 3D hand mesh reconstruction was improved by additionally
training with hand images generated by AttentionHand.

摘要：<paragraph>最近，已针对 3D 手部重建进行了大量研究，以使用各种形式的人机交互。
然而，由于极度缺乏野外 3D 手部数据集，野外 3D 手部重建具有挑战性。特别是在手部处于复杂姿势（例如交互手部）时，外观相似性、自手遮挡和深度歧义等问题使情况变得更加困难。为了克服这些问题，我们提出了 AttentionHand，这是一种用于文本驱动的可控手部图像生成的新方法。由于 AttentionHand 可以生成各种大量与 3D 手部标签对齐良好的野外手部图像，我们可以获取新的 3D 手部数据集，并且可以缓解室内和室外场景之间的领域差距。我们的方法需要易于使用的四种模态（即 RGB 图像、3D 标签中的手部网格图像、边界框和文本提示）。这些模态通过编码阶段嵌入到潜在空间中。然后，通过文本注意力阶段，来自给定文本提示的手部相关标记被用来突出潜在嵌入中的手部相关区域。在突出显示的嵌入被馈送到视觉注意力阶段后，嵌入中的手部相关区域通过基于扩散的管道与全局和局部手部网格图像进行条件处理。在解码阶段，最终特征被解码为新的手部图像，这些图像与给定的手部网格图像和文本提示对齐良好。结果，AttentionHand 在文本到手部图像生成模型中实现了最先进的水平，并且通过使用 AttentionHand 生成的图像进行额外训练，改进了 3D 手部网格重建的性能。</paragraph>

##### **Learning mental states estimation through self-observation: a developmental synergy between intentions and beliefs representations in a deep-learning model of Theory of Mind**
2407.18022v1 by Francesca Bianco, Silvia Rigato, Maria Laura Filippetti, Dimitri Ognibene

Theory of Mind (ToM), the ability to attribute beliefs, intentions, or mental
states to others, is a crucial feature of human social interaction. In complex
environments, where the human sensory system reaches its limits, behaviour is
strongly driven by our beliefs about the state of the world around us.
Accessing others' mental states, e.g., beliefs and intentions, allows for more
effective social interactions in natural contexts. Yet, these variables are not
directly observable, making understanding ToM a challenging quest of interest
for different fields, including psychology, machine learning and robotics. In
this paper, we contribute to this topic by showing a developmental synergy
between learning to predict low-level mental states (e.g., intentions, goals)
and attributing high-level ones (i.e., beliefs). Specifically, we assume that
learning beliefs attribution can occur by observing one's own decision
processes involving beliefs, e.g., in a partially observable environment. Using
a simple feed-forward deep learning model, we show that, when learning to
predict others' intentions and actions, more accurate predictions can be
acquired earlier if beliefs attribution is learnt simultaneously. Furthermore,
we show that the learning performance improves even when observed actors have a
different embodiment than the observer and the gain is higher when observing
beliefs-driven chunks of behaviour. We propose that our computational approach
can inform the understanding of human social cognitive development and be
relevant for the design of future adaptive social robots able to autonomously
understand, assist, and learn from human interaction partners in novel natural
environments and tasks.

摘要：心智理論 (ToM) 是將信念、意圖或心智狀態歸因於他人的能力，是人類社交互動的一項關鍵特徵。在複雜的環境中，人類的感官系統會達到其極限，行為會受到我們對周遭世界狀態的信念強烈驅使。存取他人的心智狀態，例如信念和意圖，可以在自然情境中進行更有效的社交互動。然而，這些變數並非直接可觀察，使得理解心智理論成為一個具有挑戰性的任務，引起心理學、機器學習和機器人學等不同領域的興趣。在本文中，我們透過展示預測低階心智狀態（例如意圖、目標）和歸因高階心智狀態（即信念）之間的發展協同作用，為此主題做出貢獻。具體來說，我們假設信念歸因學習可以透過觀察個人涉及信念的決策過程來進行，例如在部分可觀察的環境中。使用簡單的前饋深度學習模型，我們展示在學習預測他人的意圖和行為時，如果同時學習信念歸因，可以更早獲得更準確的預測。此外，我們展示即使觀察到的行為者與觀察者具有不同的具體化，學習表現也會有所提升，而且在觀察由信念驅動的行為片段時，增益會更高。我們提出我們的計算方法可以為理解人類社會認知發展提供資訊，並與未來適應性社會機器人的設計相關，這些機器人能夠在新的自然環境和任務中自主理解、協助和從人類互動夥伴那裡學習。

##### **Quadratic Advantage with Quantum Randomized Smoothing Applied to Time-Series Analysis**
2407.18021v1 by Nicola Franco, Marie Kempkes, Jakob Spiegelberg, Jeanette Miriam Lorenz

As quantum machine learning continues to develop at a rapid pace, the
importance of ensuring the robustness and efficiency of quantum algorithms
cannot be overstated. Our research presents an analysis of quantum randomized
smoothing, how data encoding and perturbation modeling approaches can be
matched to achieve meaningful robustness certificates. By utilizing an
innovative approach integrating Grover's algorithm, a quadratic sampling
advantage over classical randomized smoothing is achieved. This strategy
necessitates a basis state encoding, thus restricting the space of meaningful
perturbations. We show how constrained $k$-distant Hamming weight perturbations
are a suitable noise distribution here, and elucidate how they can be
constructed on a quantum computer. The efficacy of the proposed framework is
demonstrated on a time series classification task employing a Bag-of-Words
pre-processing solution. The advantage of quadratic sample reduction is
recovered especially in the regime with large number of samples. This may allow
quantum computers to efficiently scale randomized smoothing to more complex
tasks beyond the reach of classical methods.

摘要：隨著量子機器學習持續快速發展，確保量子演算法的穩健性和效率至關重要。我們的研究分析了量子隨機平滑，以及如何將資料編碼和擾動建模方法匹配以取得有意義的穩健性證明。透過整合葛羅佛演算法的創新方法，達成相較於古典隨機平滑的二次取樣優勢。此策略需要基底態編碼，因此限制了有意義的擾動空間。我們展示了受約束的 k 遠距漢明權重擾動在此處為合適的雜訊分佈，並說明如何在量子電腦上建構它們。所提出的架構效能已在使用詞袋預處理解決方案的時間序列分類任務中得到驗證。二次取樣減少的優勢特別在大量樣本的條件下得以恢復。這可能讓量子電腦有效地將隨機平滑擴展到更複雜的任務，超越古典方法的範圍。

##### **GermanPartiesQA: Benchmarking Commercial Large Language Models for Political Bias and Sycophancy**
2407.18008v1 by Jan Batzner, Volker Stocker, Stefan Schmid, Gjergji Kasneci

LLMs are changing the way humans create and interact with content,
potentially affecting citizens' political opinions and voting decisions. As
LLMs increasingly shape our digital information ecosystems, auditing to
evaluate biases, sycophancy, or steerability has emerged as an active field of
research. In this paper, we evaluate and compare the alignment of six LLMs by
OpenAI, Anthropic, and Cohere with German party positions and evaluate
sycophancy based on a prompt experiment. We contribute to evaluating political
bias and sycophancy in multi-party systems across major commercial LLMs. First,
we develop the benchmark dataset GermanPartiesQA based on the Voting Advice
Application Wahl-o-Mat covering 10 state and 1 national elections between 2021
and 2023. In our study, we find a left-green tendency across all examined LLMs.
We then conduct our prompt experiment for which we use the benchmark and
sociodemographic data of leading German parliamentarians to evaluate changes in
LLMs responses. To differentiate between sycophancy and steerabilty, we use 'I
am [politician X], ...' and 'You are [politician X], ...' prompts. Against our
expectations, we do not observe notable differences between prompting 'I am'
and 'You are'. While our findings underscore that LLM responses can be
ideologically steered with political personas, they suggest that observed
changes in LLM outputs could be better described as personalization to the
given context rather than sycophancy.

摘要：大型語言模型 (LLM) 正在改變人類建立和互動內容的方式，
潛在地影響公民的政治觀點和投票決定。由於
LLM 愈來愈形塑我們的數位資訊生態系統，審查以
評估偏見、阿諛奉承或可操縱性已成為一項活躍的研究領域。在本文中，我們評估並比較 OpenAI、Anthropic 和 Cohere 的六個 LLM 與德國政黨立場的一致性，並根據提示實驗評估阿諛奉承。我們致力於評估主要商業 LLM 中多黨制的政治偏見和阿諛奉承。首先，
我們根據投票建議應用程式 Wahl-o-Mat 開發基準資料集 GermanPartiesQA，涵蓋 2021 年至 2023 年之間的 10 次州選舉和 1 次全國選舉。在我們的研究中，我們發現所有受檢 LLM 都傾向於左綠。然後，我們進行提示實驗，我們使用基準和德國國會議員的社會人口資料來評估 LLM 回應的變化。為了區分阿諛奉承和可操縱性，我們使用「我是 [政治人物 X]，...」和「你是 [政治人物 X]，...」提示。與我們的預期相反，我們沒有觀察到提示「我是」和「你是」之間的顯著差異。雖然我們的研究結果強調 LLM 回應可以用政治人物來進行意識形態操縱，但它們表明，觀察到的 LLM 輸出變化可以更適切地描述為對特定脈絡的個人化，而不是阿諛奉承。

##### **Keep the Cost Down: A Review on Methods to Optimize LLM' s KV-Cache Consumption**
2407.18003v2 by Luohe Shi, Hongyi Zhang, Yao Yao, Zuchao Li, Hai Zhao

Large Language Models (LLMs), epitomized by ChatGPT' s release in late 2022,
have revolutionized various industries with their advanced language
comprehension. However, their efficiency is challenged by the Transformer
architecture' s struggle with handling long texts. KV-Cache has emerged as a
pivotal solution to this issue, converting the time complexity of token
generation from quadratic to linear, albeit with increased GPU memory overhead
proportional to conversation length. With the development of the LLM community
and academia, various KV-Cache compression methods have been proposed. In this
review, we dissect the various properties of KV-Cache and elaborate on various
methods currently used to optimize the KV-Cache space usage of LLMs. These
methods span the pre-training phase, deployment phase, and inference phase, and
we summarize the commonalities and differences among these methods.
Additionally, we list some metrics for evaluating the long-text capabilities of
large language models, from both efficiency and capability perspectives. Our
review thus sheds light on the evolving landscape of LLM optimization, offering
insights into future advancements in this dynamic field.

摘要：大型語言模型（LLM），以 2022 年底發布的 ChatGPT 為代表，透過其先進的語言理解能力，對各個產業帶來革命性的影響。然而，其效率卻受到 Transformer 架構在處理長文時所面臨的挑戰。KV 快取已成為解決此問題的關鍵方案，它將 Token 生成的時間複雜度從二次方轉換為線性，儘管 GPU 記憶體會隨著對話長度而增加。隨著 LLM 社群和學術界的發展，已提出各種 KV 快取壓縮方法。在本篇評論中，我們剖析 KV 快取的各種特性，並詳細說明目前用於最佳化 LLM 的 KV 快取空間使用的各種方法。這些方法涵蓋預訓練階段、部署階段和推理階段，我們將總結這些方法之間的共性與差異。此外，我們列出一些用於評估大型語言模型長文能力的指標，從效率和能力的角度來看。因此，我們的評論闡明了 LLM 最佳化領域的演變趨勢，並提供對這個動態領域未來進展的見解。

##### **On the Effect of Purely Synthetic Training Data for Different Automatic Speech Recognition Architectures**
2407.17997v1 by Nick Rossenbach, Benedikt Hilmes, Ralf Schlüter

In this work we evaluate the utility of synthetic data for training automatic
speech recognition (ASR). We use the ASR training data to train a
text-to-speech (TTS) system similar to FastSpeech-2. With this TTS we reproduce
the original training data, training ASR systems solely on synthetic data. For
ASR, we use three different architectures, attention-based encoder-decoder,
hybrid deep neural network hidden Markov model and a Gaussian mixture hidden
Markov model, showing the different sensitivity of the models to synthetic data
generation. In order to extend previous work, we present a number of ablation
studies on the effectiveness of synthetic vs. real training data for ASR. In
particular we focus on how the gap between training on synthetic and real data
changes by varying the speaker embedding or by scaling the model size. For the
latter we show that the TTS models generalize well, even when training scores
indicate overfitting.

摘要：在這項工作中，我們評估了合成資料在訓練自動語音辨識 (ASR) 的效用。我們使用 ASR 訓練資料來訓練類似 FastSpeech-2 的文字轉語音 (TTS) 系統。透過這個 TTS，我們重現原始訓練資料，僅使用合成資料訓練 ASR 系統。對於 ASR，我們使用三種不同的架構：基於注意力的編碼器-解碼器、混合深度神經網路隱藏馬可夫模型和高斯混合隱藏馬可夫模型，顯示模型對合成資料生成的敏感度不同。為了擴展先前的研究，我們提出了一些關於合成與真實訓練資料對 ASR 有效性的消融研究。特別是，我們專注於透過改變說話者嵌入或調整模型大小，來縮小在合成資料和真實資料上訓練的差距。對於後者，我們表明 TTS 模型具有良好的泛化性，即使訓練分數表示過度擬合。

