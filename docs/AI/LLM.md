
### LLM
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-08-02**|**Prompt Recursive Search: A Living Framework with Adaptive Growth in LLM Auto-Prompting**|Xiangyu Zhao et.al.|[2408.01423v1](http://arxiv.org/abs/2408.01423v1)|null|
|**2024-08-02**|**Mission Impossible: A Statistical Perspective on Jailbreaking LLMs**|Jingtong Su et.al.|[2408.01420v1](http://arxiv.org/abs/2408.01420v1)|null|
|**2024-08-02**|**DebateQA: Evaluating Question Answering on Debatable Knowledge**|Rongwu Xu et.al.|[2408.01419v1](http://arxiv.org/abs/2408.01419v1)|null|
|**2024-08-02**|**Talk Less, Interact Better: Evaluating In-context Conversational Adaptation in Multimodal LLMs**|Yilun Hua et.al.|[2408.01417v1](http://arxiv.org/abs/2408.01417v1)|null|
|**2024-08-02**|**Conditional LoRA Parameter Generation**|Xiaolong Jin et.al.|[2408.01415v1](http://arxiv.org/abs/2408.01415v1)|null|
|**2024-08-02**|**Pre-trained Language Models Improve the Few-shot Prompt Ability of Decision Transformer**|Yu Yang et.al.|[2408.01402v1](http://arxiv.org/abs/2408.01402v1)|null|
|**2024-08-02**|**Improving Multilingual Neural Machine Translation by Utilizing Semantic and Linguistic Features**|Mengyu Bu et.al.|[2408.01394v1](http://arxiv.org/abs/2408.01394v1)|null|
|**2024-08-02**|**Coalitions of Large Language Models Increase the Robustness of AI Agents**|Prattyush Mangal et.al.|[2408.01380v1](http://arxiv.org/abs/2408.01380v1)|null|
|**2024-08-02**|**Toward Automatic Relevance Judgment using Vision--Language Models for Image--Text Retrieval Evaluation**|Jheng-Hong Yang et.al.|[2408.01363v1](http://arxiv.org/abs/2408.01363v1)|null|
|**2024-08-02**|**PC$^2$: Pseudo-Classification Based Pseudo-Captioning for Noisy Correspondence Learning in Cross-Modal Retrieval**|Yue Duan et.al.|[2408.01349v1](http://arxiv.org/abs/2408.01349v1)|null|
|**2024-08-02**|**Prompt Refinement or Fine-tuning? Best Practices for using LLMs in Computational Social Science Tasks**|Anders Giovanni Møller et.al.|[2408.01346v1](http://arxiv.org/abs/2408.01346v1)|null|
|**2024-08-02**|**StitchFusion: Weaving Any Visual Modalities to Enhance Multimodal Semantic Segmentation**|Bingyu Li et.al.|[2408.01343v1](http://arxiv.org/abs/2408.01343v1)|null|
|**2024-08-02**|**MuChoMusic: Evaluating Music Understanding in Multimodal Audio-Language Models**|Benno Weck et.al.|[2408.01337v1](http://arxiv.org/abs/2408.01337v1)|null|
|**2024-08-02**|**A Backbone for Long-Horizon Robot Task Understanding**|Xiaoshuai Chen et.al.|[2408.01334v1](http://arxiv.org/abs/2408.01334v1)|null|
|**2024-08-02**|**FANNO: Augmenting High-Quality Instruction Data with Open-Sourced LLMs Only**|He Zhu et.al.|[2408.01323v1](http://arxiv.org/abs/2408.01323v1)|null|
|**2024-08-02**|**A Robotics-Inspired Scanpath Model Reveals the Importance of Uncertainty and Semantic Object Cues for Gaze Guidance in Dynamic Scenes**|Vito Mengers et.al.|[2408.01322v1](http://arxiv.org/abs/2408.01322v1)|null|
|**2024-08-02**|**A Comprehensive Review of Multimodal Large Language Models: Performance and Challenges Across Different Tasks**|Jiaqi Wang et.al.|[2408.01319v1](http://arxiv.org/abs/2408.01319v1)|null|
|**2024-08-02**|**Synergistic pathways of modulation enable robust task packing within neural dynamics**|Giacomo Vedovati et.al.|[2408.01316v1](http://arxiv.org/abs/2408.01316v1)|null|
|**2024-08-02**|**Reconsidering Token Embeddings with the Definitions for Pre-trained Language Models**|Ying Zhang et.al.|[2408.01308v1](http://arxiv.org/abs/2408.01308v1)|null|
|**2024-08-02**|**Deep Learning based Visually Rich Document Content Understanding: A Survey**|Yihao Ding et.al.|[2408.01287v1](http://arxiv.org/abs/2408.01287v1)|null|
|**2024-08-02**|**The Mismeasure of Man and Models: Evaluating Allocational Harms in Large Language Models**|Hannah Chen et.al.|[2408.01285v1](http://arxiv.org/abs/2408.01285v1)|null|
|**2024-08-02**|**RAGEval: Scenario Specific RAG Evaluation Dataset Generation Framework**|Kunlun Zhu et.al.|[2408.01262v1](http://arxiv.org/abs/2408.01262v1)|null|
|**2024-08-02**|**TrIM: Triangular Input Movement Systolic Array for Convolutional Neural Networks -- Part I: Dataflow and Analytical Modelling**|Cristian Sestito et.al.|[2408.01254v1](http://arxiv.org/abs/2408.01254v1)|null|
|**2024-08-02**|**Metareasoning in uncertain environments: a meta-BAMDP framework**|Prakhar Godara et.al.|[2408.01253v1](http://arxiv.org/abs/2408.01253v1)|null|
|**2024-08-02**|**Rubric-based Learner Modelling via Noisy Gates Bayesian Networks for Computational Thinking Skills Assessment**|Giorgia Adorni et.al.|[2408.01221v1](http://arxiv.org/abs/2408.01221v1)|null|
|**2024-08-02**|**High-Throughput Phenotyping of Clinical Text Using Large Language Models**|Daniel B. Hier et.al.|[2408.01214v1](http://arxiv.org/abs/2408.01214v1)|null|
|**2024-08-02**|**Multi-Objective Deep Reinforcement Learning for Optimisation in Autonomous Systems**|Juan C. Rosero et.al.|[2408.01188v1](http://arxiv.org/abs/2408.01188v1)|null|
|**2024-08-02**|**Misinforming LLMs: vulnerabilities, challenges and opportunities**|Bo Zhou et.al.|[2408.01168v1](http://arxiv.org/abs/2408.01168v1)|null|
|**2024-08-02**|**TCR-GPT: Integrating Autoregressive Model and Reinforcement Learning for T-Cell Receptor Repertoires Generation**|Yicheng Lin et.al.|[2408.01156v1](http://arxiv.org/abs/2408.01156v1)|null|
|**2024-08-02**|**DERA: Dense Entity Retrieval for Entity Alignment in Knowledge Graphs**|Zhichun Wang et.al.|[2408.01154v1](http://arxiv.org/abs/2408.01154v1)|null|
|**2024-08-02**|**Interpreting Global Perturbation Robustness of Image Models using Axiomatic Spectral Importance Decomposition**|Róisín Luo et.al.|[2408.01139v1](http://arxiv.org/abs/2408.01139v1)|null|
|**2024-08-02**|**A Survey of Mamba**|Haohao Qu et.al.|[2408.01129v1](http://arxiv.org/abs/2408.01129v1)|null|
|**2024-08-02**|**CFBench: A Comprehensive Constraints-Following Benchmark for LLMs**|Tao Zhang et.al.|[2408.01122v1](http://arxiv.org/abs/2408.01122v1)|null|
|**2024-08-02**|**Task Prompt Vectors: Effective Initialization through Multi-Task Soft-Prompt Transfer**|Robert Belanec et.al.|[2408.01119v1](http://arxiv.org/abs/2408.01119v1)|null|
|**2024-08-02**|**IAI Group at CheckThat! 2024: Transformer Models and Data Augmentation for Checkworthy Claim Detection**|Peter Røysland Aarnes et.al.|[2408.01118v1](http://arxiv.org/abs/2408.01118v1)|null|
|**2024-08-02**|**BioRAG: A RAG-LLM Framework for Biological Question Reasoning**|Chengrui Wang et.al.|[2408.01107v1](http://arxiv.org/abs/2408.01107v1)|null|
|**2024-08-02**|**Contribution-based Low-Rank Adaptation with Pre-training Model for Real Image Restoration**|Donwon Park et.al.|[2408.01099v1](http://arxiv.org/abs/2408.01099v1)|null|
|**2024-08-02**|**Six Dragons Fly Again: Reviving 15th-Century Korean Court Music with Transformers and Novel Encoding**|Danbinaerin Han et.al.|[2408.01096v1](http://arxiv.org/abs/2408.01096v1)|null|
|**2024-08-02**|**Dissecting Dissonance: Benchmarking Large Multimodal Models Against Self-Contradictory Instructions**|Jin Gao et.al.|[2408.01091v1](http://arxiv.org/abs/2408.01091v1)|null|
|**2024-08-02**|**General-purpose Dataflow Model with Neuromorphic Primitives**|Weihao Zhang et.al.|[2408.01090v1](http://arxiv.org/abs/2408.01090v1)|null|
|**2024-08-02**|**Bridging Information Gaps in Dialogues With Grounded Exchanges Using Knowledge Graphs**|Phillip Schneider et.al.|[2408.01088v1](http://arxiv.org/abs/2408.01088v1)|null|
|**2024-08-02**|**Adaptive Contrastive Decoding in Retrieval-Augmented Generation for Handling Noisy Contexts**|Youna Kim et.al.|[2408.01084v1](http://arxiv.org/abs/2408.01084v1)|null|
|**2024-08-02**|**The EAP-AIAS: Adapting the AI Assessment Scale for English for Academic Purposes**|Jasper Roe et.al.|[2408.01075v1](http://arxiv.org/abs/2408.01075v1)|null|
|**2024-08-02**|**Leveraging Large Language Models for Mobile App Review Feature Extraction**|Quim Motger et.al.|[2408.01063v1](http://arxiv.org/abs/2408.01063v1)|null|
|**2024-08-02**|**LLM as Runtime Error Handler: A Promising Pathway to Adaptive Self-Healing of Software Systems**|Zhensu Sun et.al.|[2408.01055v1](http://arxiv.org/abs/2408.01055v1)|null|
|**2024-08-02**|**The Impact of Hyperparameters on Large Language Model Inference Performance: An Evaluation of vLLM and HuggingFace Pipelines**|Matias Martinez et.al.|[2408.01050v1](http://arxiv.org/abs/2408.01050v1)|null|
|**2024-08-02**|**QUDSELECT: Selective Decoding for Questions Under Discussion Parsing**|Ashima Suvarna et.al.|[2408.01046v1](http://arxiv.org/abs/2408.01046v1)|null|
|**2024-08-02**|**UNER: A Unified Prediction Head for Named Entity Recognition in Visually-rich Documents**|Yi Tu et.al.|[2408.01038v1](http://arxiv.org/abs/2408.01038v1)|null|
|**2024-08-02**|**Semantic Skill Grounding for Embodied Instruction-Following in Cross-Domain Environments**|Sangwoo Shin et.al.|[2408.01024v1](http://arxiv.org/abs/2408.01024v1)|null|
|**2024-08-02**|**GNN-MolKAN: Harnessing the Power of KAN to Advance Molecular Representation Learning with GNNs**|Ruifeng Li et.al.|[2408.01018v1](http://arxiv.org/abs/2408.01018v1)|null|
|**2024-08-02**|**IBB Traffic Graph Data: Benchmarking and Road Traffic Prediction Model**|Eren Olug et.al.|[2408.01016v1](http://arxiv.org/abs/2408.01016v1)|null|
|**2024-08-02**|**Tensor Train Low-rank Approximation (TT-LoRA): Democratizing AI with Accelerated LLMs**|Afia Anjum et.al.|[2408.01008v1](http://arxiv.org/abs/2408.01008v1)|null|
|**2024-08-02**|**Enhancing Financial Market Predictions: Causality-Driven Feature Selection**|Wenhao Liang et.al.|[2408.01005v1](http://arxiv.org/abs/2408.01005v1)|null|
|**2024-08-02**|**Piculet: Specialized Models-Guided Hallucination Decrease for MultiModal Large Language Models**|Kohou Wang et.al.|[2408.01003v1](http://arxiv.org/abs/2408.01003v1)|null|
|**2024-08-02**|**FBSDiff: Plug-and-Play Frequency Band Substitution of Diffusion Features for Highly Controllable Text-Driven Image Translation**|Xiang Gao et.al.|[2408.00998v1](http://arxiv.org/abs/2408.00998v1)|null|
|**2024-08-02**|**A Safe Exploration Strategy for Model-free Task Adaptation in Safety-constrained Grid Environments**|Erfan Entezami et.al.|[2408.00997v1](http://arxiv.org/abs/2408.00997v1)|null|
|**2024-08-02**|**IncidentNet: Traffic Incident Detection, Localization and Severity Estimation with Sparse Sensing**|Sai Shashank Peddiraju et.al.|[2408.00996v1](http://arxiv.org/abs/2408.00996v1)|null|
|**2024-08-02**|**ArchCode: Incorporating Software Requirements in Code Generation with Large Language Models**|Hojae Han et.al.|[2408.00994v1](http://arxiv.org/abs/2408.00994v1)|null|
|**2024-08-02**|**Fairness in Large Language Models in Three Hour**|Thang Doan Viet et.al.|[2408.00992v1](http://arxiv.org/abs/2408.00992v1)|null|
|**2024-08-02**|**On the Resilience of Multi-Agent Systems with Malicious Agents**|Jen-tse Huang et.al.|[2408.00989v1](http://arxiv.org/abs/2408.00989v1)|null|
|**2024-08-02**|**A SAT-based approach to rigorous verification of Bayesian networks**|Ignacy Stępka et.al.|[2408.00986v1](http://arxiv.org/abs/2408.00986v1)|null|
|**2024-08-02**|**Cross-domain Named Entity Recognition via Graph Matching**|Junhao Zheng et.al.|[2408.00981v1](http://arxiv.org/abs/2408.00981v1)|null|
|**2024-08-02**|**Automatic Extraction of Relationships among Motivations, Emotions and Actions from Natural Language Texts**|Fei Yang et.al.|[2408.00966v1](http://arxiv.org/abs/2408.00966v1)|null|
|**2024-08-02**|**PERSOMA: PERsonalized SOft ProMpt Adapter Architecture for Personalized Language Prompting**|Liam Hebert et.al.|[2408.00960v1](http://arxiv.org/abs/2408.00960v1)|null|
|**2024-08-01**|**Leveraging Large Language Models (LLMs) for Traffic Management at Urban Intersections: The Case of Mixed Traffic Scenarios**|Sari Masri et.al.|[2408.00948v1](http://arxiv.org/abs/2408.00948v1)|null|
|**2024-08-01**|**CIResDiff: A Clinically-Informed Residual Diffusion Model for Predicting Idiopathic Pulmonary Fibrosis Progression**|Caiwen Jiang et.al.|[2408.00938v1](http://arxiv.org/abs/2408.00938v1)|null|
|**2024-08-01**|**Towards Zero-Shot Annotation of the Built Environment with Vision-Language Models (Vision Paper)**|Bin Han et.al.|[2408.00932v1](http://arxiv.org/abs/2408.00932v1)|null|
|**2024-08-01**|**Enabling High Data Throughput Reinforcement Learning on GPUs: A Domain Agnostic Framework for Data-Driven Scientific Research**|Tian Lan et.al.|[2408.00930v1](http://arxiv.org/abs/2408.00930v1)|null|
|**2024-08-01**|**WHITE PAPER: A Brief Exploration of Data Exfiltration using GCG Suffixes**|Victor Valbuena et.al.|[2408.00925v1](http://arxiv.org/abs/2408.00925v1)|null|
|**2024-08-01**|**Reclaiming Residual Knowledge: A Novel Paradigm to Low-Bit Quantization**|Róisín Luo et.al.|[2408.00923v1](http://arxiv.org/abs/2408.00923v1)|null|
|**2024-08-01**|**Automatic Pull Request Description Generation Using LLMs: A T5 Model Approach**|Md Nazmus Sakib et.al.|[2408.00921v1](http://arxiv.org/abs/2408.00921v1)|null|
|**2024-08-01**|**Granting GPT-4 License and Opportunity: Enhancing Accuracy and Confidence Estimation for Few-Shot Event Detection**|Steven Fincke et.al.|[2408.00914v1](http://arxiv.org/abs/2408.00914v1)|null|
|**2024-08-01**|**Parkinson's Disease Detection from Resting State EEG using Multi-Head Graph Structure Learning with Gradient Weighted Graph Attention Explanations**|Christopher Neves et.al.|[2408.00906v1](http://arxiv.org/abs/2408.00906v1)|null|
|**2024-08-01**|**Expressive MIDI-format Piano Performance Generation**|Jingwei Liu et.al.|[2408.00900v1](http://arxiv.org/abs/2408.00900v1)|null|
|**2024-08-01**|**Hybrid Querying Over Relational Databases and Large Language Models**|Fuheng Zhao et.al.|[2408.00884v1](http://arxiv.org/abs/2408.00884v1)|null|
|**2024-08-01**|**On the Relationship Between Monotone and Squared Probabilistic Circuits**|Benjie Wang et.al.|[2408.00876v1](http://arxiv.org/abs/2408.00876v1)|null|
|**2024-08-01**|**UniMoT: Unified Molecule-Text Language Model with Discrete Token Representation**|Juzheng Zhang et.al.|[2408.00863v1](http://arxiv.org/abs/2408.00863v1)|null|
|**2024-08-01**|**UlRe-NeRF: 3D Ultrasound Imaging through Neural Rendering with Ultrasound Reflection Direction Parameterization**|Ziwen Guo et.al.|[2408.00860v1](http://arxiv.org/abs/2408.00860v1)|null|
|**2024-08-01**|**LICM: Effective and Efficient Long Interest Chain Modeling for News Recommendation**|Zhen Yang et.al.|[2408.00859v1](http://arxiv.org/abs/2408.00859v1)|null|
|**2024-08-01**|**Calibrating Bayesian Generative Machine Learning for Bayesiamplification**|Sebastian Bieringer et.al.|[2408.00838v1](http://arxiv.org/abs/2408.00838v1)|null|
|**2024-08-01**|**MM-Vet v2: A Challenging Benchmark to Evaluate Large Multimodal Models for Integrated Capabilities**|Weihao Yu et.al.|[2408.00765v1](http://arxiv.org/abs/2408.00765v1)|null|
|**2024-08-01**|**AgentGen: Enhancing Planning Abilities for Large Language Model based Agent via Environment and Task Generation**|Mengkang Hu et.al.|[2408.00764v1](http://arxiv.org/abs/2408.00764v1)|null|
|**2024-08-01**|**Tamper-Resistant Safeguards for Open-Weight LLMs**|Rishub Tamirisa et.al.|[2408.00761v1](http://arxiv.org/abs/2408.00761v1)|null|
|**2024-08-01**|**Smoothed Energy Guidance: Guiding Diffusion Models with Reduced Energy Curvature of Attention**|Susung Hong et.al.|[2408.00760v1](http://arxiv.org/abs/2408.00760v1)|null|
|**2024-08-01**|**Segment anything model 2: an application to 2D and 3D medical images**|Haoyu Dong et.al.|[2408.00756v1](http://arxiv.org/abs/2408.00756v1)|null|
|**2024-08-01**|**DynamoLLM: Designing LLM Inference Clusters for Performance and Energy Efficiency**|Jovan Stojkovic et.al.|[2408.00741v1](http://arxiv.org/abs/2408.00741v1)|null|
|**2024-08-01**|**CERT-ED: Certifiably Robust Text Classification for Edit Distance**|Zhuoqun Huang et.al.|[2408.00728v1](http://arxiv.org/abs/2408.00728v1)|null|
|**2024-08-01**|**Improving Retrieval-Augmented Generation in Medicine with Iterative Follow-up Questions**|Guangzhi Xiong et.al.|[2408.00727v1](http://arxiv.org/abs/2408.00727v1)|null|
|**2024-08-01**|**Y Social: an LLM-powered Social Media Digital Twin**|Giulio Rossetti et.al.|[2408.00818v1](http://arxiv.org/abs/2408.00818v1)|null|
|**2024-08-01**|**An Empirical Analysis of Compute-Optimal Inference for Problem-Solving with Language Models**|Yangzhen Wu et.al.|[2408.00724v1](http://arxiv.org/abs/2408.00724v1)|null|
|**2024-08-01**|**Pathway to Secure and Trustworthy 6G for LLMs: Attacks, Defense, and Opportunities**|Sunder Ali Khowaja et.al.|[2408.00722v1](http://arxiv.org/abs/2408.00722v1)|null|
|**2024-08-01**|**SAM 2: Segment Anything in Images and Videos**|Nikhila Ravi et.al.|[2408.00714v1](http://arxiv.org/abs/2408.00714v1)|null|
|**2024-08-01**|**Investigating Brain Connectivity and Regional Statistics from EEG for early stage Parkinson's Classification**|Amarpal Sahota et.al.|[2408.00711v1](http://arxiv.org/abs/2408.00711v1)|null|
|**2024-08-01**|**Point-supervised Brain Tumor Segmentation with Box-prompted MedSAM**|Xiaofeng Liu et.al.|[2408.00706v1](http://arxiv.org/abs/2408.00706v1)|null|
|**2024-08-01**|**Future of Artificial Intelligence in Agile Software Development**|Mariyam Mahboob et.al.|[2408.00703v1](http://arxiv.org/abs/2408.00703v1)|null|
|**2024-08-01**|**Improving Text Embeddings for Smaller Language Models Using Contrastive Fine-tuning**|Trapoom Ukarapol et.al.|[2408.00690v2](http://arxiv.org/abs/2408.00690v2)|null|
|**2024-08-01**|**Can Developers Prompt? A Controlled Experiment for Code Documentation Generation**|Hans-Alexander Kruse et.al.|[2408.00686v1](http://arxiv.org/abs/2408.00686v1)|null|
|**2024-08-01**|**Assessing the Variety of a Concept Space Using an Unbiased Estimate of Rao's Quadratic Index**|Anubhab Majumder et.al.|[2408.00684v1](http://arxiv.org/abs/2408.00684v1)|null|
|**2024-08-01**|**Learning in Multi-Objective Public Goods Games with Non-Linear Utilities**|Nicole Orzan et.al.|[2408.00682v1](http://arxiv.org/abs/2408.00682v1)|null|
|**2024-08-01**|**Leveraging Entailment Judgements in Cross-Lingual Summarisation**|Huajian Zhang et.al.|[2408.00675v1](http://arxiv.org/abs/2408.00675v1)|null|

#### Abstracts
##### **Prompt Recursive Search: A Living Framework with Adaptive Growth in LLM Auto-Prompting**
2408.01423v1 by Xiangyu Zhao, Chengqian Ma

Large Language Models (LLMs) exhibit remarkable proficiency in addressing a
diverse array of tasks within the Natural Language Processing (NLP) domain,
with various prompt design strategies significantly augmenting their
capabilities. However, these prompts, while beneficial, each possess inherent
limitations. The primary prompt design methodologies are twofold: The first,
exemplified by the Chain of Thought (CoT), involves manually crafting prompts
specific to individual datasets, hence termed Expert-Designed Prompts (EDPs).
Once these prompts are established, they are unalterable, and their
effectiveness is capped by the expertise of the human designers. When applied
to LLMs, the static nature of EDPs results in a uniform approach to both simple
and complex problems within the same dataset, leading to the inefficient use of
tokens for straightforward issues. The second method involves prompts
autonomously generated by the LLM, known as LLM-Derived Prompts (LDPs), which
provide tailored solutions to specific problems, mitigating the limitations of
EDPs. However, LDPs may encounter a decline in performance when tackling
complex problems due to the potential for error accumulation during the
solution planning process. To address these challenges, we have conceived a
novel Prompt Recursive Search (PRS) framework that leverages the LLM to
generate solutions specific to the problem, thereby conserving tokens. The
framework incorporates an assessment of problem complexity and an adjustable
structure, ensuring a reduction in the likelihood of errors. We have
substantiated the efficacy of PRS framework through extensive experiments using
LLMs with different numbers of parameters across a spectrum of datasets in
various domains. Compared to the CoT method, the PRS method has increased the
accuracy on the BBH dataset by 8% using Llama3-7B model, achieving a 22%
improvement.

摘要：大型語言模型 (LLM) 在處理自然語言處理 (NLP) 領域中的各種任務時展現出卓越的能力，而各種提示設計策略顯著地增強了它們的功能。然而，這些提示雖然有益，但各有其固有的限制。主要的提示設計方法有兩種：第一種，以思想鏈 (CoT) 為例，涉及手動製作特定於個別資料集的提示，因此稱為專家設計提示 (EDP)。一旦建立這些提示，它們將不可更改，並且它們的有效性受到人類設計師專業知識的限制。當應用於 LLM 時，EDP 的靜態特性導致對同一資料集中的簡單和複雜問題採用統一的方法，從而導致對直接問題的令牌使用效率低下。第二種方法涉及由 LLM 自主生成的提示，稱為 LLM 派生提示 (LDP)，它為具體問題提供了量身定制的解決方案，從而減輕了 EDP 的限制。然而，LDP 在解決複雜問題時可能會遇到效能下降，因為在解決方案規劃過程中可能會累積錯誤。為了應對這些挑戰，我們構思了一個新穎的提示遞迴搜尋 (PRS) 框架，它利用 LLM 為特定問題生成解決方案，從而節省令牌。該框架包含對問題複雜性的評估和可調整的結構，確保降低錯誤發生的可能性。我們通過使用具有不同參數數量且涵蓋各種領域資料集的 LLM 進行廣泛實驗，證實了 PRS 框架的功效。與 CoT 方法相比，PRS 方法使用 Llama3-7B 模型將 BBH 資料集上的準確度提高了 8%，達到了 22% 的改進。

##### **Mission Impossible: A Statistical Perspective on Jailbreaking LLMs**
2408.01420v1 by Jingtong Su, Julia Kempe, Karen Ullrich

Large language models (LLMs) are trained on a deluge of text data with
limited quality control. As a result, LLMs can exhibit unintended or even
harmful behaviours, such as leaking information, fake news or hate speech.
Countermeasures, commonly referred to as preference alignment, include
fine-tuning the pretrained LLMs with carefully crafted text examples of desired
behaviour. Even then, empirical evidence shows preference aligned LLMs can be
enticed to harmful behaviour. This so called jailbreaking of LLMs is typically
achieved by adversarially modifying the input prompt to the LLM. Our paper
provides theoretical insights into the phenomenon of preference alignment and
jailbreaking from a statistical perspective. Under our framework, we first show
that pretrained LLMs will mimic harmful behaviour if present in the training
corpus. Under that same framework, we then introduce a statistical notion of
alignment, and lower-bound the jailbreaking probability, showing that it is
unpreventable under reasonable assumptions. Based on our insights, we propose
an alteration to the currently prevalent alignment strategy RLHF. Specifically,
we introduce a simple modification to the RLHF objective, we call E-RLHF, that
aims to increase the likelihood of safe responses. E-RLHF brings no additional
training cost, and is compatible with other methods. Empirically, we
demonstrate that E-RLHF outperforms RLHF on all alignment problems put forward
by the AdvBench and HarmBench project without sacrificing model performance as
measured by the MT-Bench project.

摘要：大型語言模型 (LLM) 在大量的文本資料上進行訓練，品質控管有限。因此，LLM 可能會表現出意外甚至有害的行為，例如洩露資訊、假新聞或仇恨言論。對策通常稱為偏好對齊，包括使用精心製作的所需行為範例微調預訓練的 LLM。即使如此，實證證據顯示，偏好對齊的 LLM 仍可能受到引誘而產生有害行為。這種所謂的 LLM 越獄通常是透過對 LLM 的輸入提示進行對抗性修改來實現。我們的論文從統計角度提供了對偏好對齊和越獄現象的理論見解。在我們的架構下，我們首先展示了如果訓練語料庫中存在有害行為，預訓練的 LLM 將會模仿這種行為。在同一個架構下，我們接著引入了一個對齊的統計概念，並對越獄機率進行下限約束，顯示在合理的假設下，越獄是無法預防的。根據我們的見解，我們提出了對目前普遍採用的對齊策略 RLHF 的修改。具體來說，我們對 RLHF 目標進行了一個簡單的修改，我們稱之為 E-RLHF，其目的是提高安全回應的可能性。E-RLHF 沒有帶來額外的訓練成本，並且與其他方法相容。根據經驗，我們證明 E-RLHF 在 AdvBench 和 HarmBench 專案提出的所有對齊問題上都優於 RLHF，同時不會犧牲由 MT-Bench 專案測量的模型效能。

##### **DebateQA: Evaluating Question Answering on Debatable Knowledge**
2408.01419v1 by Rongwu Xu, Xuan Qi, Zehan Qi, Wei Xu, Zhijiang Guo

The rise of large language models (LLMs) has enabled us to seek answers to
inherently debatable questions on LLM chatbots, necessitating a reliable way to
evaluate their ability. However, traditional QA benchmarks assume fixed answers
are inadequate for this purpose. To address this, we introduce DebateQA, a
dataset of 2,941 debatable questions, each accompanied by multiple
human-annotated partial answers that capture a variety of perspectives. We
develop two metrics: Perspective Diversity, which evaluates the
comprehensiveness of perspectives, and Dispute Awareness, which assesses if the
LLM acknowledges the question's debatable nature. Experiments demonstrate that
both metrics align with human preferences and are stable across different
underlying models. Using DebateQA with two metrics, we assess 12 popular LLMs
and retrieval-augmented generation methods. Our findings reveal that while LLMs
generally excel at recognizing debatable issues, their ability to provide
comprehensive answers encompassing diverse perspectives varies considerably.

摘要：大型語言模型 (LLM) 的興起讓我們得以在 LLM 聊天機器人上尋找本質上具有爭議性的問題的答案，這需要一種可靠的方法來評估它們的能力。然而，傳統的問答基準假設固定答案不足以達到此目的。為了解決這個問題，我們引入了 DebateQA，這是一個包含 2,941 個有爭議性的問題的資料集，每個問題都附有多個由人類註解的部分答案，這些答案涵蓋了各種觀點。我們開發了兩個指標：觀點多樣性，用於評估觀點的全面性，以及爭議意識，用於評估 LLM 是否承認問題的爭議性質。實驗表明，這兩個指標都與人類偏好一致，並且在不同的基礎模型中保持穩定。使用具有兩個指標的 DebateQA，我們評估了 12 個流行的 LLM 和檢索增強生成方法。我們的研究結果表明，雖然 LLM 通常擅長識別有爭議的問題，但它們提供包含不同觀點的全面答案的能力差異很大。

##### **Talk Less, Interact Better: Evaluating In-context Conversational Adaptation in Multimodal LLMs**
2408.01417v1 by Yilun Hua, Yoav Artzi

Humans spontaneously use increasingly efficient language as interactions
progress, by adapting and forming ad-hoc conventions. This phenomenon has been
studied extensively using reference games, showing properties of human language
that go beyond relaying intents. It remains unexplored whether multimodal large
language models (MLLMs) similarly increase communication efficiency during
interactions, and what mechanisms they may adopt for this purpose. We introduce
ICCA, an automated framework to evaluate such conversational adaptation as an
in-context behavior in MLLMs. We evaluate several state-of-the-art MLLMs, and
observe that while they may understand the increasingly efficient language of
their interlocutor, they do not spontaneously make their own language more
efficient over time. This latter ability can only be elicited in some models
(e.g., GPT-4) with heavy-handed prompting. This shows that this property of
linguistic interaction does not arise from current training regimes, even
though it is a common hallmark of human language. ICCA is available at
https://github.com/lil-lab/ICCA.

摘要：人類在互動過程中會自發地使用越來越有效率的語言，透過適應和形成臨時慣例。這個現象已經透過參考遊戲廣泛地研究過，顯示出人類語言的特性超越了傳遞意圖。多模態大型語言模型 (MLLM) 是否也會在互動過程中提升溝通效率，以及它們可能採用什麼機制來達成此目的，這部分仍未被探討過。我們引入了 ICCA，一個自動化架構，用來評估這種對話適應，作為 MLLM 的情境行為。我們評估了幾個最先進的 MLLM，並觀察到，儘管它們可能理解對話者的語言越來越有效率，但它們並不會自發地讓自己的語言隨著時間變得更有效率。後者的能力只能在某些模型（例如 GPT-4）中透過強烈的提示引發。這顯示出語言互動的這個特性並非來自目前的訓練機制，儘管它是人類語言的共同特徵。ICCA 可在 https://github.com/lil-lab/ICCA 取得。

##### **Conditional LoRA Parameter Generation**
2408.01415v1 by Xiaolong Jin, Kai Wang, Dongwen Tang, Wangbo Zhao, Yukun Zhou, Junshu Tang, Yang You

Generative models have achieved remarkable success in image, video, and text
domains. Inspired by this, researchers have explored utilizing generative
models to generate neural network parameters. However, these efforts have been
limited by the parameter size and the practicality of generating
high-performance parameters. In this paper, we propose COND P-DIFF, a novel
approach that demonstrates the feasibility of controllable high-performance
parameter generation, particularly for LoRA (Low-Rank Adaptation) weights,
during the fine-tuning process. Specifically, we employ an autoencoder to
extract efficient latent representations for parameters. We then train a
conditional latent diffusion model to synthesize high-performing model
parameters from random noise based on specific task conditions. Experimental
results in both computer vision and natural language processing domains
consistently demonstrate that COND P-DIFF can generate high-performance
parameters conditioned on the given task. Moreover, we observe that the
parameter distribution generated by COND P-DIFF exhibits differences compared
to the distribution obtained through normal optimization methods, indicating a
certain level of generalization capability. Our work paves the way for further
exploration of condition-driven parameter generation, offering a promising
direction for task-specific adaptation of neural networks.

摘要：生成式模型在影像、影片和文字領域已取得顯著的成功。受此啟發，研究人員已探討利用生成式模型來產生神經網路參數。然而，這些努力受到參數大小和產生高性能參數的實用性的限制。在本文中，我們提出 COND P-DIFF，這是一種新穎的方法，展示了可控高性能參數產生的可行性，特別是在微調過程中針對 LoRA（低秩適應）權重。具體來說，我們採用自動編碼器來提取參數的有效潛在表示。然後，我們訓練一個條件潛在擴散模型，根據特定任務條件從隨機雜訊中合成高性能模型參數。電腦視覺和自然語言處理領域的實驗結果一致地證明，COND P-DIFF 可以產生針對給定任務進行條件化的效能參數。此外，我們觀察到，與透過一般最佳化方法獲得的分布相比，COND P-DIFF 生成的參數分布呈現出差異，表示具有一定程度的概化能力。我們的研究為條件驅動參數生成的進一步探索鋪平了道路，為神經網路的任務特定適應提供了有希望的方向。

##### **Pre-trained Language Models Improve the Few-shot Prompt Ability of Decision Transformer**
2408.01402v1 by Yu Yang, Pan Xu

Decision Transformer (DT) has emerged as a promising class of algorithms in
offline reinforcement learning (RL) tasks, leveraging pre-collected datasets
and Transformer's capability to model long sequences. Recent works have
demonstrated that using parts of trajectories from training tasks as prompts in
DT enhances its performance on unseen tasks, giving rise to Prompt-DT methods.
However, collecting data from specific environments can be both costly and
unsafe in many scenarios, leading to suboptimal performance and limited
few-shot prompt abilities due to the data-hungry nature of Transformer-based
models. Additionally, the limited datasets used in pre-training make it
challenging for Prompt-DT type of methods to distinguish between various RL
tasks through prompts alone. To address these challenges, we introduce the
Language model-initialized Prompt Decision Transformer (LPDT), which leverages
pre-trained language models for meta-RL tasks and fine-tunes the model using
Low-rank Adaptation (LoRA). We further incorporate prompt regularization to
effectively differentiate between tasks based on prompt feature
representations. Our approach integrates pre-trained language model and RL
tasks seamlessly. Extensive empirical studies demonstrate that initializing
with a pre-trained language model significantly enhances the performance of
Prompt-DT on unseen tasks compared to baseline methods.

摘要：決策Transformer (DT) 已成為離線強化學習 (RL) 任務中一種有前途的演算法類別，它利用預先收集的資料集和Transformer對長序列建模的能力。最近的研究表明，將訓練任務中部分軌跡用作 DT 中的提示，可以提升其在未見任務中的表現，由此產生了提示 DT 方法。然而，在許多場景中，從特定環境收集資料既昂貴又不安全，這導致了次優的表現和有限的少次提示能力，因為基於Transformer的模型具有資料密集的特性。此外，預訓練中使用的有限資料集使得提示 DT 類型的模型僅透過提示就難以區分各種 RL 任務。為了應對這些挑戰，我們引入了基於語言模型的提示決策Transformer (LPDT)，它利用預先訓練的語言模型進行元 RL 任務，並使用低秩適應 (LoRA) 微調模型。我們進一步整合提示正規化，以根據提示特徵表示有效區分任務。我們的做法無縫整合了預先訓練的語言模型和 RL 任務。廣泛的實證研究表明，與基線方法相比，使用預先訓練的語言模型進行初始化顯著提升了提示 DT 在未見任務中的表現。

##### **Improving Multilingual Neural Machine Translation by Utilizing Semantic and Linguistic Features**
2408.01394v1 by Mengyu Bu, Shuhao Gu, Yang Feng

The many-to-many multilingual neural machine translation can be regarded as
the process of integrating semantic features from the source sentences and
linguistic features from the target sentences. To enhance zero-shot
translation, models need to share knowledge across languages, which can be
achieved through auxiliary tasks for learning a universal representation or
cross-lingual mapping. To this end, we propose to exploit both semantic and
linguistic features between multiple languages to enhance multilingual
translation. On the encoder side, we introduce a disentangling learning task
that aligns encoder representations by disentangling semantic and linguistic
features, thus facilitating knowledge transfer while preserving complete
information. On the decoder side, we leverage a linguistic encoder to integrate
low-level linguistic features to assist in the target language generation.
Experimental results on multilingual datasets demonstrate significant
improvement in zero-shot translation compared to the baseline system, while
maintaining performance in supervised translation. Further analysis validates
the effectiveness of our method in leveraging both semantic and linguistic
features. The code is available at https://github.com/ictnlp/SemLing-MNMT.

摘要：多對多多語言神經機器翻譯可視為整合來源句子的語意特徵和目標句子的語言特徵的過程。為了增強零次學習翻譯，模型需要跨語言共享知識，這可透過輔助任務來學習通用表示或跨語言對應來達成。為此，我們提議利用多種語言之間的語意和語言特徵來增強多語言翻譯。在編碼器方面，我們引入了一個解開學習任務，透過解開語意和語言特徵來對齊編碼器表示，從而促進知識傳遞，同時保留完整資訊。在解碼器方面，我們利用語言編碼器整合低階語言特徵，以協助目標語言產生。多語言資料集上的實驗結果顯示，與基準系統相比，零次學習翻譯有顯著改善，同時在監督式翻譯中維持效能。進一步的分析驗證了我們的方法在利用語意和語言特徵方面的有效性。程式碼可於 https://github.com/ictnlp/SemLing-MNMT 取得。

##### **Coalitions of Large Language Models Increase the Robustness of AI Agents**
2408.01380v1 by Prattyush Mangal, Carol Mak, Theo Kanakis, Timothy Donovan, Dave Braines, Edward Pyzer-Knapp

The emergence of Large Language Models (LLMs) have fundamentally altered the
way we interact with digital systems and have led to the pursuit of LLM powered
AI agents to assist in daily workflows. LLMs, whilst powerful and capable of
demonstrating some emergent properties, are not logical reasoners and often
struggle to perform well at all sub-tasks carried out by an AI agent to plan
and execute a workflow. While existing studies tackle this lack of proficiency
by generalised pretraining at a huge scale or by specialised fine-tuning for
tool use, we assess if a system comprising of a coalition of pretrained LLMs,
each exhibiting specialised performance at individual sub-tasks, can match the
performance of single model agents. The coalition of models approach showcases
its potential for building robustness and reducing the operational costs of
these AI agents by leveraging traits exhibited by specific models. Our findings
demonstrate that fine-tuning can be mitigated by considering a coalition of
pretrained models and believe that this approach can be applied to other
non-agentic systems which utilise LLMs.

摘要：大型語言模型 (LLM) 的出現從根本上改變了我們與數位系統互動的方式，並導致追求由 LLM 驅動的 AI 代理，以協助日常工作流程。LLM 雖然功能強大，並且能夠展示一些新興屬性，但並非邏輯推理者，而且通常難以執行 AI 代理在規劃和執行工作流程時執行的所有子任務。雖然現有研究透過大規模的廣泛預訓練或針對工具使用進行專門微調來解決這種缺乏熟練度，但我們評估由預訓練 LLM 聯盟組成的系統，每個系統在個別子任務中表現出專門的效能，是否能與單一模型代理的效能相匹配。模型聯盟方法展示了其透過利用特定模型所表現出的特質來建構穩健性和降低這些 AI 代理的營運成本的潛力。我們的研究結果表明，透過考慮預訓練模型聯盟，可以減輕微調，並相信這種方法可以應用於其他使用 LLM 的非代理系統。

##### **Toward Automatic Relevance Judgment using Vision--Language Models for Image--Text Retrieval Evaluation**
2408.01363v1 by Jheng-Hong Yang, Jimmy Lin

Vision--Language Models (VLMs) have demonstrated success across diverse
applications, yet their potential to assist in relevance judgments remains
uncertain. This paper assesses the relevance estimation capabilities of VLMs,
including CLIP, LLaVA, and GPT-4V, within a large-scale \textit{ad hoc}
retrieval task tailored for multimedia content creation in a zero-shot fashion.
Preliminary experiments reveal the following: (1) Both LLaVA and GPT-4V,
encompassing open-source and closed-source visual-instruction-tuned Large
Language Models (LLMs), achieve notable Kendall's $\tau \sim 0.4$ when compared
to human relevance judgments, surpassing the CLIPScore metric. (2) While
CLIPScore is strongly preferred, LLMs are less biased towards CLIP-based
retrieval systems. (3) GPT-4V's score distribution aligns more closely with
human judgments than other models, achieving a Cohen's $\kappa$ value of around
0.08, which outperforms CLIPScore at approximately -0.096. These findings
underscore the potential of LLM-powered VLMs in enhancing relevance judgments.

摘要：視覺語言模型 (VLM) 已在各種應用中展現成功，但它們在協助相關性判斷方面的潛力仍不確定。本文評估了 VLM 的相關性估計能力，包括 CLIP、LLaVA 和 GPT-4V，在專為零次學習模式的多媒體內容創作量身打造的大規模「臨時」檢索任務中。初步實驗揭示了以下內容：(1) 包含開源和閉源視覺指令調整大型語言模型 (LLM) 的 LLaVA 和 GPT-4V，與人類相關性判斷相比，達到了顯著的 Kendall's $\tau \sim 0.4$，超越了 CLIPScore 指標。(2) 雖然強烈偏好 CLIPScore，但 LLM 對基於 CLIP 的檢索系統的偏見較小。(3) GPT-4V 的分數分佈與人類判斷更為一致，達到約 0.08 的 Cohen's $\kappa$ 值，優於 CLIPScore 的約 -0.096。這些發現強調了 LLM 驅動的 VLM 在增強相關性判斷方面的潛力。

##### **PC$^2$: Pseudo-Classification Based Pseudo-Captioning for Noisy Correspondence Learning in Cross-Modal Retrieval**
2408.01349v1 by Yue Duan, Zhangxuan Gu, Zhenzhe Ying, Lei Qi, Changhua Meng, Yinghuan Shi

In the realm of cross-modal retrieval, seamlessly integrating diverse
modalities within multimedia remains a formidable challenge, especially given
the complexities introduced by noisy correspondence learning (NCL). Such noise
often stems from mismatched data pairs, which is a significant obstacle
distinct from traditional noisy labels. This paper introduces
Pseudo-Classification based Pseudo-Captioning (PC$^2$) framework to address
this challenge. PC$^2$ offers a threefold strategy: firstly, it establishes an
auxiliary "pseudo-classification" task that interprets captions as categorical
labels, steering the model to learn image-text semantic similarity through a
non-contrastive mechanism. Secondly, unlike prevailing margin-based techniques,
capitalizing on PC$^2$'s pseudo-classification capability, we generate
pseudo-captions to provide more informative and tangible supervision for each
mismatched pair. Thirdly, the oscillation of pseudo-classification is borrowed
to assistant the correction of correspondence. In addition to technical
contributions, we develop a realistic NCL dataset called Noise of Web (NoW),
which could be a new powerful NCL benchmark where noise exists naturally.
Empirical evaluations of PC$^2$ showcase marked improvements over existing
state-of-the-art robust cross-modal retrieval techniques on both simulated and
realistic datasets with various NCL settings. The contributed dataset and
source code are released at https://github.com/alipay/PC2-NoiseofWeb.

摘要：在跨模態檢索領域中，在多媒體中無縫整合不同的模態仍然是一項艱鉅的挑戰，特別是考慮到噪聲對應學習 (NCL) 所帶來的複雜性。這種噪聲通常源自不匹配的資料對，這是與傳統的噪聲標籤截然不同的重大障礙。本文介紹了基於偽分類的偽標題 (PC$^2$) 框架來解決這個挑戰。PC$^2$ 提供了一個三管齊下的策略：首先，它建立一個輔助的「偽分類」任務，將標題解釋為分類標籤，引導模型通過非對比機制學習圖像文字語義相似性。其次，與流行的基於邊緣的技術不同，利用 PC$^2$ 的偽分類能力，我們生成偽標題，為每個不匹配的對提供更具資訊性和具體的監督。第三，借用偽分類的振盪來協助對應的校正。除了技術貢獻之外，我們還開發了一個名為 Web 噪聲 (NoW) 的現實 NCL 資料集，這可能是一個新的強大 NCL 基準，其中噪聲自然存在。PC$^2$ 的經驗評估展示了在模擬和現實資料集上，在各種 NCL 設定下，對現有最先進的強健跨模態檢索技術的顯著改進。貢獻的資料集和原始碼發布於 https://github.com/alipay/PC2-NoiseofWeb。

##### **Prompt Refinement or Fine-tuning? Best Practices for using LLMs in Computational Social Science Tasks**
2408.01346v1 by Anders Giovanni Møller, Luca Maria Aiello

Large Language Models are expressive tools that enable complex tasks of text
understanding within Computational Social Science. Their versatility, while
beneficial, poses a barrier for establishing standardized best practices within
the field. To bring clarity on the values of different strategies, we present
an overview of the performance of modern LLM-based classification methods on a
benchmark of 23 social knowledge tasks. Our results point to three best
practices: select models with larger vocabulary and pre-training corpora; avoid
simple zero-shot in favor of AI-enhanced prompting; fine-tune on task-specific
data, and consider more complex forms instruction-tuning on multiple datasets
only when only training data is more abundant.

摘要：大型語言模型是一種表現力強大的工具，可以在計算社會科學中執行複雜的文本理解任務。它們的多功能性雖然有益，但對建立該領域的標準化最佳實務構成了障礙。為了釐清不同策略的價值，我們針對 23 項社會知識任務的基準，概述了基於現代 LLM 的分類方法的效能。我們的結果指出了三項最佳實務：選擇具有較大詞彙量和預訓練語料庫的模型；避免使用簡單的零次學習，而改用 AI 增強提示；針對特定任務的資料進行微調，並且僅在訓練資料更豐富時，才考慮對多個資料集進行更複雜形式的指令調整。

##### **StitchFusion: Weaving Any Visual Modalities to Enhance Multimodal Semantic Segmentation**
2408.01343v1 by Bingyu Li, Da Zhang, Zhiyuan Zhao, Junyu Gao, Xuelong Li

Multimodal semantic segmentation shows significant potential for enhancing
segmentation accuracy in complex scenes. However, current methods often
incorporate specialized feature fusion modules tailored to specific modalities,
thereby restricting input flexibility and increasing the number of training
parameters. To address these challenges, we propose StitchFusion, a
straightforward yet effective modal fusion framework that integrates
large-scale pre-trained models directly as encoders and feature fusers. This
approach facilitates comprehensive multi-modal and multi-scale feature fusion,
accommodating any visual modal inputs. Specifically, Our framework achieves
modal integration during encoding by sharing multi-modal visual information. To
enhance information exchange across modalities, we introduce a
multi-directional adapter module (MultiAdapter) to enable cross-modal
information transfer during encoding. By leveraging MultiAdapter to propagate
multi-scale information across pre-trained encoders during the encoding
process, StitchFusion achieves multi-modal visual information integration
during encoding. Extensive comparative experiments demonstrate that our model
achieves state-of-the-art performance on four multi-modal segmentation datasets
with minimal additional parameters. Furthermore, the experimental integration
of MultiAdapter with existing Feature Fusion Modules (FFMs) highlights their
complementary nature. Our code is available at StitchFusion_repo.

摘要：多模態語意分割在增強複雜場景中的分割準確度方面展現出顯著的潛力。然而，當前方法通常會納入針對特定模態量身打造的專業特徵融合模組，從而限制輸入彈性並增加訓練參數數量。為了解決這些挑戰，我們提出 StitchFusion，一個直接將大規模預訓練模型作為編碼器和特徵融合器的簡單卻有效的模態融合架構。這種方法促進了全面的多模態和多尺度特徵融合，容納任何視覺模態輸入。具體來說，我們的架構透過共享多模態視覺資訊，在編碼過程中實現模態整合。為了增強跨模態的資訊交換，我們引入了一個多向適配器模組 (MultiAdapter)，以便在編碼過程中實現跨模態資訊傳輸。透過利用 MultiAdapter 在編碼過程中跨預訓練編碼器傳播多尺度資訊，StitchFusion 在編碼過程中實現了多模態視覺資訊整合。廣泛的比較實驗證明，我們的模型在四個多模態分割資料集上實現了最先進的效能，且額外參數最少。此外，MultiAdapter 與現有特徵融合模組 (FFM) 的實驗整合突顯了它們的互補性質。我們的程式碼可在 StitchFusion_repo 取得。

##### **MuChoMusic: Evaluating Music Understanding in Multimodal Audio-Language Models**
2408.01337v1 by Benno Weck, Ilaria Manco, Emmanouil Benetos, Elio Quinton, George Fazekas, Dmitry Bogdanov

Multimodal models that jointly process audio and language hold great promise
in audio understanding and are increasingly being adopted in the music domain.
By allowing users to query via text and obtain information about a given audio
input, these models have the potential to enable a variety of music
understanding tasks via language-based interfaces. However, their evaluation
poses considerable challenges, and it remains unclear how to effectively assess
their ability to correctly interpret music-related inputs with current methods.
Motivated by this, we introduce MuChoMusic, a benchmark for evaluating music
understanding in multimodal language models focused on audio. MuChoMusic
comprises 1,187 multiple-choice questions, all validated by human annotators,
on 644 music tracks sourced from two publicly available music datasets, and
covering a wide variety of genres. Questions in the benchmark are crafted to
assess knowledge and reasoning abilities across several dimensions that cover
fundamental musical concepts and their relation to cultural and functional
contexts. Through the holistic analysis afforded by the benchmark, we evaluate
five open-source models and identify several pitfalls, including an
over-reliance on the language modality, pointing to a need for better
multimodal integration. Data and code are open-sourced.

摘要：<paragraph>多模態模型同時處理音訊和語言，在音訊理解方面極具前景，並且在音樂領域中越來越廣泛地被採用。
透過允許使用者透過文字查詢並取得關於特定音訊輸入的資訊，這些模型有潛力透過基於語言的介面啟用各種音樂理解任務。然而，它們的評估會帶來相當大的挑戰，而且目前仍不清楚如何有效評估它們正確詮釋與音樂相關輸入的能力。
因此，我們引入了 MuChoMusic，一個專注於音訊的多模態語言模型中評估音樂理解的基準。MuChoMusic 包含 1,187 個多重選擇題，全部由人類註解者驗證，涵蓋來自兩個公開音樂資料集的 644 首音樂曲目，並涵蓋了各種類型。基準中的問題旨在評估跨越幾個維度的知識和推理能力，這些維度涵蓋了基本的音樂概念及其與文化和功能背景的關係。透過基準提供的整體分析，我們評估了五個開源模型，並找出幾個缺陷，包括過度依賴語言模態，指出需要更好的多模態整合。資料和程式碼都是開源的。</paragraph>

##### **A Backbone for Long-Horizon Robot Task Understanding**
2408.01334v1 by Xiaoshuai Chen, Wei Chen, Dongmyoung Lee, Yukun Ge, Nicolas Rojas, Petar Kormushev

End-to-end robot learning, particularly for long-horizon tasks, often results
in unpredictable outcomes and poor generalization. To address these challenges,
we propose a novel Therblig-based Backbone Framework (TBBF) to enhance robot
task understanding and transferability. This framework uses therbligs (basic
action elements) as the backbone to decompose high-level robot tasks into
elemental robot configurations, which are then integrated with current
foundation models to improve task understanding. The approach consists of two
stages: offline training and online testing. During the offline training stage,
we developed the Meta-RGate SynerFusion (MGSF) network for accurate therblig
segmentation across various tasks. In the online testing stage, after a
one-shot demonstration of a new task is collected, our MGSF network extracts
high-level knowledge, which is then encoded into the image using Action
Registration (ActionREG). Additionally, the Large Language Model
(LLM)-Alignment Policy for Visual Correction (LAP-VC) is employed to ensure
precise action execution, facilitating trajectory transfer in novel robot
scenarios. Experimental results validate these methods, achieving 94.37% recall
in therblig segmentation and success rates of 94.4% and 80% in real-world
online robot testing for simple and complex scenarios, respectively.
Supplementary material is available at:
https://sites.google.com/view/therbligsbasedbackbone/home

摘要：端對端機器人學習，特別是針對長期任務，通常會導致難以預測的結果和不佳的泛化性。為了應對這些挑戰，我們提出了一個新穎的 Therblig 構建骨幹架構 (TBBF) 來增強機器人任務理解和可轉移性。這個架構使用 Therblig（基本動作元素）作為骨幹將高階機器人任務分解為元素機器人組態，然後將它們與當前的基礎模型整合以改善任務理解。此方法包含兩個階段：離線訓練和線上測試。在離線訓練階段，我們開發了 Meta-RGate SynerFusion (MGSF) 網路，用於跨各種任務進行準確的 Therblig 分割。在線上測試階段，在收集新任務的一次性展示後，我們的 MGSF 網路會萃取高階知識，然後使用動作註冊 (ActionREG) 將其編碼到影像中。此外，大型語言模型 (LLM)-視覺修正對齊策略 (LAP-VC) 用於確保精確的動作執行，促進新穎機器人場景中的軌跡轉移。實驗結果驗證了這些方法，在 Therblig 分割中達到 94.37% 的召回率，以及在簡單和複雜場景中分別為 94.4% 和 80% 的實際線上機器人測試成功率。補充資料可在以下網址取得：https://sites.google.com/view/therbligsbasedbackbone/home

##### **FANNO: Augmenting High-Quality Instruction Data with Open-Sourced LLMs Only**
2408.01323v1 by He Zhu, Junyou Su, Tianle Lun, Yicheng Tao, Wenjia Zhang, Zipei Fan, Guanhua Chen

Instruction fine-tuning stands as a crucial advancement in leveraging large
language models (LLMs) for enhanced task performance. However, the annotation
of instruction datasets has traditionally been expensive and laborious, often
relying on manual annotations or costly API calls of proprietary LLMs. To
address these challenges, we introduce FANNO, a fully autonomous, open-sourced
framework that revolutionizes the annotation process without the need for
pre-existing annotated data. Utilizing a Mistral-7b-instruct model, FANNO
efficiently produces diverse and high-quality datasets through a structured
process involving document pre-screening, instruction generation, and response
generation. Experiments on Open LLM Leaderboard and AlpacaEval benchmark show
that the FANNO can generate high-quality data with diversity and complexity for
free, comparable to human-annotated or cleaned datasets like
Alpaca-GPT4-Cleaned.

摘要：指令微調作為利用大型語言模型（LLM）以增強任務效能的關鍵進展。然而，指令資料集的註解傳統上既昂貴又費力，通常依賴於手動註解或專有 LLM 的昂貴 API 呼叫。為了應對這些挑戰，我們引入了 FANNO，一個完全自主、開源的架構，它徹底改變了註解過程，無需預先註解的資料。FANNO 利用 Mistral-7b-instruct 模型，透過涉及文件預篩選、指令產生和回應產生的結構化流程，有效地產生多樣化且高品質的資料集。在 Open LLM Leaderboard 和 AlpacaEval 基準上的實驗表明，FANNO 可以免費產生高品質、多樣化且複雜的資料，媲美人工註解或清理過的資料集，例如 Alpaca-GPT4-Cleaned。

##### **A Robotics-Inspired Scanpath Model Reveals the Importance of Uncertainty and Semantic Object Cues for Gaze Guidance in Dynamic Scenes**
2408.01322v1 by Vito Mengers, Nicolas Roth, Oliver Brock, Klaus Obermayer, Martin Rolfs

How we perceive objects around us depends on what we actively attend to, yet
our eye movements depend on the perceived objects. Still, object segmentation
and gaze behavior are typically treated as two independent processes. Drawing
on an information processing pattern from robotics, we present a mechanistic
model that simulates these processes for dynamic real-world scenes. Our
image-computable model uses the current scene segmentation for object-based
saccadic decision-making while using the foveated object to refine its scene
segmentation recursively. To model this refinement, we use a Bayesian filter,
which also provides an uncertainty estimate for the segmentation that we use to
guide active scene exploration. We demonstrate that this model closely
resembles observers' free viewing behavior, measured by scanpath statistics,
including foveation duration and saccade amplitude distributions used for
parameter fitting and higher-level statistics not used for fitting. These
include how object detections, inspections, and returns are balanced and a
delay of returning saccades without an explicit implementation of such temporal
inhibition of return. Extensive simulations and ablation studies show that
uncertainty promotes balanced exploration and that semantic object cues are
crucial to form the perceptual units used in object-based attention. Moreover,
we show how our model's modular design allows for extensions, such as
incorporating saccadic momentum or pre-saccadic attention, to further align its
output with human scanpaths.

摘要：我們如何感知周遭的物體取決於我們積極注意的事物，但我們的眼睛移動取決於感知的物體。儘管如此，物體分割和凝視行為通常被視為兩個獨立的過程。借鑒機器人的資訊處理模式，我們提出了一個機制模型，模擬動態真實世界場景的這些過程。我們的影像可計算模型使用當前的場景分割進行基於物體的注視點決策，同時使用注視的物體遞迴地優化其場景分割。為了模擬這種優化，我們使用貝氏濾波器，它還提供了分割的不確定性估計，我們使用此估計來引導主動場景探索。我們證明，此模型與觀察者的自由視覺行為非常相似，透過掃描路徑統計資料測量，包括注視點持續時間和用於參數擬合的跳躍幅度分佈，以及未用於擬合的高階統計資料。這些包括如何平衡物體偵測、檢查和返回，以及在沒有明確實施此類時間性回返抑制的情況下返回跳躍的延遲。廣泛的模擬和消融研究表明，不確定性促進了平衡的探索，而且語義物體線索對於形成基於物體注意力的感知單元至關重要。此外，我們展示了我們的模型的模組化設計如何允許擴充，例如納入跳躍動量或跳躍前注意力，以進一步將其輸出與人類掃描路徑對齊。

##### **A Comprehensive Review of Multimodal Large Language Models: Performance and Challenges Across Different Tasks**
2408.01319v1 by Jiaqi Wang, Hanqi Jiang, Yiheng Liu, Chong Ma, Xu Zhang, Yi Pan, Mengyuan Liu, Peiran Gu, Sichen Xia, Wenjun Li, Yutong Zhang, Zihao Wu, Zhengliang Liu, Tianyang Zhong, Bao Ge, Tuo Zhang, Ning Qiang, Xintao Hu, Xi Jiang, Xin Zhang, Wei Zhang, Dinggang Shen, Tianming Liu, Shu Zhang

In an era defined by the explosive growth of data and rapid technological
advancements, Multimodal Large Language Models (MLLMs) stand at the forefront
of artificial intelligence (AI) systems. Designed to seamlessly integrate
diverse data types-including text, images, videos, audio, and physiological
sequences-MLLMs address the complexities of real-world applications far beyond
the capabilities of single-modality systems. In this paper, we systematically
sort out the applications of MLLM in multimodal tasks such as natural language,
vision, and audio. We also provide a comparative analysis of the focus of
different MLLMs in the tasks, and provide insights into the shortcomings of
current MLLMs, and suggest potential directions for future research. Through
these discussions, this paper hopes to provide valuable insights for the
further development and application of MLLM.

摘要：在數據爆炸性增長和快速技術進步所定義的時代中，多模態大型語言模型 (MLLM) 成為人工智慧 (AI) 系統的先驅。MLLM 旨在無縫整合各種資料類型，包括文字、影像、影片、音訊和生理序列，解決了遠遠超出單一模式系統功能的真實世界應用複雜性。在本文中，我們系統性地整理出 MLLM 在自然語言、視覺和音訊等多模態任務中的應用。我們也提供了不同 MLLM 在任務中的關注焦點的比較分析，並深入探討了當前 MLLM 的缺點，並建議未來研究的潛在方向。透過這些討論，本文希望能為 MLLM 的進一步發展和應用提供有價值的見解。

##### **Synergistic pathways of modulation enable robust task packing within neural dynamics**
2408.01316v1 by Giacomo Vedovati, ShiNung Ching

Understanding how brain networks learn and manage multiple tasks
simultaneously is of interest in both neuroscience and artificial intelligence.
In this regard, a recent research thread in theoretical neuroscience has
focused on how recurrent neural network models and their internal dynamics
enact multi-task learning. To manage different tasks requires a mechanism to
convey information about task identity or context into the model, which from a
biological perspective may involve mechanisms of neuromodulation. In this
study, we use recurrent network models to probe the distinctions between two
forms of contextual modulation of neural dynamics, at the level of neuronal
excitability and at the level of synaptic strength. We characterize these
mechanisms in terms of their functional outcomes, focusing on their robustness
to context ambiguity and, relatedly, their efficiency with respect to packing
multiple tasks into finite size networks. We also demonstrate distinction
between these mechanisms at the level of the neuronal dynamics they induce.
Together, these characterizations indicate complementarity and synergy in how
these mechanisms act, potentially over multiple time-scales, toward enhancing
robustness of multi-task learning.

摘要：理解腦部網路如何學習並同時管理多重任務，在神經科學與人工智慧中都受到重視。
在這方面，理論神經科學中近期的一個研究主題，專注於遞迴神經網路模型及其內部動態如何制定多任務學習。管理不同任務需要一種機制，將任務身分或脈絡的資訊傳遞到模型中，這從生物觀點來看，可能涉及神經調節機制。在這項研究中，我們使用遞迴網路模型，探討神經動態的兩種脈絡調變形式之間的區別，在神經元興奮性層級和突觸強度層級。我們根據其功能結果來描述這些機制，專注於其對脈絡模糊性的穩健性，以及相關地，其在將多重任務打包到有限大小網路方面的效率。我們也展示了這些機制在它們引發的神經元動態層級上的區別。這些描述共同指出這些機制的作用方式中的互補性和協同作用，可能跨越多個時間尺度，以增強多任務學習的穩健性。

##### **Reconsidering Token Embeddings with the Definitions for Pre-trained Language Models**
2408.01308v1 by Ying Zhang, Dongyuan Li, Manabu Okumura

Learning token embeddings based on token co-occurrence statistics has proven
effective for both pre-training and fine-tuning in natural language processing.
However, recent studies have pointed out the distribution of learned embeddings
degenerates into anisotropy, and even pre-trained language models (PLMs) suffer
from a loss of semantics-related information in embeddings for low-frequency
tokens. This study first analyzes fine-tuning dynamics of a PLM, BART-large,
and demonstrates its robustness against degeneration. On the basis of this
finding, we propose DefinitionEMB, a method that utilizes definitions to
construct isotropically distributed and semantics-related token embeddings for
PLMs while maintaining original robustness during fine-tuning. Our experiments
demonstrate the effectiveness of leveraging definitions from Wiktionary to
construct such embeddings for RoBERTa-base and BART-large. Furthermore, the
constructed embeddings for low-frequency tokens improve the performance of
these models across various GLUE and four text summarization datasets.

摘要：學習基於標記共現統計的標記嵌入已證明對於自然語言處理中的預訓練和微調都很有效。
然而，最近的研究指出，學習到的嵌入分佈會退化為各向異性，甚至預訓練語言模型 (PLM) 也會因為低頻率標記的嵌入而喪失語義相關資訊。本研究首先分析了 PLM BART-large 的微調動態，並展示其對退化的穩健性。根據此發現，我們提出了 DefinitionEMB，這是一種利用定義來建構各向同性分佈且語義相關的 PLM 標記嵌入的方法，同時在微調期間維持原始穩健性。我們的實驗證明了利用維基詞典中的定義來建構 RoBERTa-base 和 BART-large 的此類嵌入的有效性。此外，為低頻率標記建構的嵌入改善了這些模型在各種 GLUE 和四個文本摘要資料集中的效能。

##### **Deep Learning based Visually Rich Document Content Understanding: A Survey**
2408.01287v1 by Yihao Ding, Jean Lee, Soyeon Caren Han

Visually Rich Documents (VRDs) are essential in academia, finance, medical
fields, and marketing due to their multimodal information content. Traditional
methods for extracting information from VRDs depend on expert knowledge and
manual labor, making them costly and inefficient. The advent of deep learning
has revolutionized this process, introducing models that leverage multimodal
information vision, text, and layout along with pretraining tasks to develop
comprehensive document representations. These models have achieved
state-of-the-art performance across various downstream tasks, significantly
enhancing the efficiency and accuracy of information extraction from VRDs. In
response to the growing demands and rapid developments in Visually Rich
Document Understanding (VRDU), this paper provides a comprehensive review of
deep learning-based VRDU frameworks. We systematically survey and analyze
existing methods and benchmark datasets, categorizing them based on adopted
strategies and downstream tasks. Furthermore, we compare different techniques
used in VRDU models, focusing on feature representation and fusion, model
architecture, and pretraining methods, while highlighting their strengths,
limitations, and appropriate scenarios. Finally, we identify emerging trends
and challenges in VRDU, offering insights into future research directions and
practical applications. This survey aims to provide a thorough understanding of
VRDU advancements, benefiting both academic and industrial sectors.

摘要：視覺豐富文件 (VRD) 由於其多模態資訊內容，在學術界、金融業、醫療領域和行銷領域中至關重要。從 VRD 中提取資訊的傳統方法依賴於專家知識和手動勞動，這使得它們既昂貴又低效。深度學習的出現徹底改變了這個過程，引入了利用多模態資訊視覺、文字和佈局以及預訓練任務來開發綜合文件表示的模型。這些模型在各種下游任務中都取得了最先進的效能，顯著提高了從 VRD 中提取資訊的效率和準確性。為了應對視覺豐富文件理解 (VRDU) 中不斷增長的需求和快速發展，本文對基於深度學習的 VRDU 框架進行了全面回顧。我們系統地調查和分析現有方法和基準資料集，並根據採用的策略和下游任務對它們進行分類。此外，我們比較了 VRDU 模型中使用的不同技術，重點關注特徵表示和融合、模型架構和預訓練方法，同時強調它們的優勢、限制和適當的場景。最後，我們確定了 VRDU 中的新興趨勢和挑戰，對未來的研究方向和實際應用提供了見解。本調查旨在提供對 VRDU 進展的透徹理解，使學術界和產業界受益。

##### **The Mismeasure of Man and Models: Evaluating Allocational Harms in Large Language Models**
2408.01285v1 by Hannah Chen, Yangfeng Ji, David Evans

Large language models (LLMs) are now being considered and even deployed for
applications that support high-stakes decision-making, such as recruitment and
clinical decisions. While several methods have been proposed for measuring
bias, there remains a gap between predictions, which are what the proposed
methods consider, and how they are used to make decisions. In this work, we
introduce Rank-Allocational-Based Bias Index (RABBI), a model-agnostic bias
measure that assesses potential allocational harms arising from biases in LLM
predictions. We compare RABBI and current bias metrics on two allocation
decision tasks. We evaluate their predictive validity across ten LLMs and
utility for model selection. Our results reveal that commonly-used bias metrics
based on average performance gap and distribution distance fail to reliably
capture group disparities in allocation outcomes, whereas RABBI exhibits a
strong correlation with allocation disparities. Our work highlights the need to
account for how models are used in contexts with limited resource constraints.

摘要：大型語言模型 (LLM) 現正被考慮，甚至部署在支援高風險決策的應用程式中，例如招聘和臨床決策。雖然已提出幾種衡量偏差的方法，但預測（這是所提出方法考慮的內容）與它們如何用於決策之間仍存在差距。在這項工作中，我們引入了基於排名分配的偏差指標 (RABBI)，這是一個與模型無關的偏差衡量標準，用於評估由 LLM 預測中的偏差所產生的潛在分配危害。我們在兩個分配決策任務中比較了 RABBI 和當前的偏差指標。我們評估了它們在十個 LLM 中的預測效度和模型選擇的效用。我們的結果顯示，基於平均效能差距和分佈距離的常用偏差指標無法可靠地捕捉分配結果中的群體差異，而 RABBI 則與分配差異呈現強相關。我們的研究強調了在資源限制的背景下，需要考量模型的使用方式。

##### **RAGEval: Scenario Specific RAG Evaluation Dataset Generation Framework**
2408.01262v1 by Kunlun Zhu, Yifan Luo, Dingling Xu, Ruobing Wang, Shi Yu, Shuo Wang, Yukun Yan, Zhenghao Liu, Xu Han, Zhiyuan Liu, Maosong Sun

Retrieval-Augmented Generation (RAG) systems have demonstrated their
advantages in alleviating the hallucination of Large Language Models (LLMs).
Existing RAG benchmarks mainly focus on evaluating whether LLMs can correctly
answer the general knowledge. However, they are unable to evaluate the
effectiveness of the RAG system in dealing with the data from different
vertical domains. This paper introduces RAGEval, a framework for automatically
generating evaluation datasets to evaluate the knowledge usage ability of
different LLMs in different scenarios. Specifically, RAGEval summarizes a
schema from seed documents, applies the configurations to generate diverse
documents, and constructs question-answering pairs according to both articles
and configurations. We propose three novel metrics, Completeness,
Hallucination, and Irrelevance, to carefully evaluate the responses generated
by LLMs. By benchmarking RAG models in vertical domains, RAGEval has the
ability to better evaluate the knowledge usage ability of LLMs, which avoids
the confusion regarding the source of knowledge in answering question in
existing QA datasets--whether it comes from parameterized memory or retrieval.

摘要：检索增强生成 (RAG) 系统已证明其在减轻大型语言模型 (LLM) 的幻觉方面的优势。现有的 RAG 基准主要集中在评估 LLM 是否可以正确回答常识。然而，它们无法评估 RAG 系统在处理来自不同垂直领域的的数据时的有效性。本文介绍了 RAGEval，这是一个用于自动生成评估数据集以评估不同 LLM 在不同场景中的知识使用能力的框架。具体来说，RAGEval 从种子文档中总结出一个模式，应用配置来生成不同的文档，并根据文章和配置构建问答对。我们提出了三个新颖的指标：完整性、幻觉和不相关性，以仔细评估 LLM 生成的响应。通过对垂直领域的 RAG 模型进行基准测试，RAGEval 能够更好地评估 LLM 的知识使用能力，从而避免了在现有问答数据集中的回答问题时的知识来源的困惑——它是否来自参数化记忆或检索。

##### **TrIM: Triangular Input Movement Systolic Array for Convolutional Neural Networks -- Part I: Dataflow and Analytical Modelling**
2408.01254v1 by Cristian Sestito, Shady Agwa, Themis Prodromakis

In order to follow the ever-growing computational complexity and data
intensity of state-of-the-art AI models, new computing paradigms are being
proposed. These paradigms aim at achieving high energy efficiency, by
mitigating the Von Neumann bottleneck that relates to the energy cost of moving
data between the processing cores and the memory. Convolutional Neural Networks
(CNNs) are particularly susceptible to this bottleneck, given the massive data
they have to manage. Systolic Arrays (SAs) are promising architectures to
mitigate the data transmission cost, thanks to high data utilization carried
out by an array of Processing Elements (PEs). These PEs continuously exchange
and process data locally based on specific dataflows (like weight stationary
and row stationary), in turn reducing the number of memory accesses to the main
memory. The hardware specialization of SAs can meet different workloads,
ranging from matrix multiplications to multi-dimensional convolutions. In this
paper, we propose TrIM: a novel dataflow for SAs based on a Triangular Input
Movement and compatible with CNN computing. When compared to state-of-the-art
SA dataflows, like weight stationary and row stationary, the high data
utilization offered by TrIM guarantees ~10x less memory access. Furthermore,
considering that PEs continuously overlap multiplications and accumulations,
TrIM achieves high throughput (up to 81.8% higher than row stationary), other
than requiring a limited number of registers (up to 15.6x fewer registers than
row stationary).

摘要：<paragraph>為了跟上最先進的人工智慧模型不斷增長的計算複雜度和資料密集度，新的運算範例應運而生。這些範例旨在透過減輕馮紐曼瓶頸來實現高能效，馮紐曼瓶頸與在處理核心和記憶體之間移動資料的能源成本有關。卷積神經網路 (CNN) 特別容易受到此瓶頸的影響，因為它們必須管理大量資料。收縮陣列 (SA) 是一種很有前景的架構，可以減輕資料傳輸成本，這要歸功於由處理元件 (PE) 陣列執行的資料高利用率。這些 PE 會根據特定資料流（例如權重固定和列固定）持續在本地交換和處理資料，進而減少對主記憶體的記憶體存取次數。SA 的硬體專門化可以滿足不同的工作負載，從矩陣乘法到多維卷積。在本文中，我們提出 TrIM：一種基於三角形輸入移動，且與 CNN 運算相容的 SA 新型資料流。與最先進的 SA 資料流（例如權重固定和列固定）相比，TrIM 提供的高資料利用率可保證記憶體存取次數減少約 10 倍。此外，考量到 PE 會持續重疊乘法和累加，TrIM 可實現高通量（比列固定高出 81.8%），而且所需的暫存器數量較少（比列固定少 15.6 倍）。</paragraph>

##### **Metareasoning in uncertain environments: a meta-BAMDP framework**
2408.01253v1 by Prakhar Godara, Tilman Diego Aléman, Angela J. Yu

In decision-making scenarios, \textit{reasoning} can be viewed as an
algorithm $P$ that makes a choice of an action $a^* \in \mathcal{A}$, aiming to
optimize some outcome such as maximizing the value function of a Markov
decision process (MDP). However, executing $P$ itself may bear some costs
(time, energy, limited capacity, etc.) and needs to be considered alongside
explicit utility obtained by making the choice in the underlying decision
problem. Such costs need to be taken into account in order to accurately model
human behavior, as well as optimizing AI planning, as all physical systems are
bound to face resource constraints. Finding the right $P$ can itself be framed
as an optimization problem over the space of reasoning processes $P$, generally
referred to as \textit{metareasoning}. Conventionally, human metareasoning
models assume that the agent knows the transition and reward distributions of
the underlying MDP. This paper generalizes such models by proposing a meta
Bayes-Adaptive MDP (meta-BAMDP) framework to handle metareasoning in
environments with unknown reward/transition distributions, which encompasses a
far larger and more realistic set of planning problems that humans and AI
systems face. As a first step, we apply the framework to two-armed Bernoulli
bandit (TABB) tasks, which have often been used to study human decision making.
Owing to the meta problem's complexity, our solutions are necessarily
approximate, but nevertheless robust within a range of assumptions that are
arguably realistic for human decision-making scenarios. These results offer a
normative framework for understanding human exploration under cognitive
constraints. This integration of Bayesian adaptive strategies with
metareasoning enriches both the theoretical landscape of decision-making
research and practical applications in designing AI systems that plan under
uncertainty and resource constraints.

摘要：<paragraph>在決策制定情境中，\textit{推理}可以視為一種演算法 $P$，它會選擇一個動作 $a^* \in \mathcal{A}$，目標是最佳化某個結果，例如最大化馬可夫決策過程 (MDP) 的價值函數。然而，執行 $P$ 本身可能會產生一些成本（時間、能量、有限容量等），並且需要與在基本決策問題中做出選擇所獲得的明確效用一併考慮。為了精確模擬人類行為以及最佳化 AI 規劃，需要將此類成本納入考量，因為所有物理系統都一定會面臨資源限制。找出適當的 $P$ 本身可以視為推理過程 $P$ 空間上的最佳化問題，通常稱為\textit{後設推理}。傳統上，人類後設推理模型假設代理知道基本 MDP 的轉換和報酬分配。本文透過提出後設貝氏自適應 MDP (meta-BAMDP) 架構，將此類模型概括化，以處理未知報酬/轉換分配環境中的後設推理，其中包含人類和 AI 系統面臨的更廣泛且更實際的規劃問題集。第一步，我們將架構應用於兩臂伯努利強盜 (TABB) 任務，這項任務經常被用於研究人類決策制定。由於後設問題的複雜性，我們的解決方案必然是近似的，但仍然在對人類決策制定情境來說相當實際的一系列假設中穩健。這些結果為理解人類在認知限制下的探索提供了一個規範架構。將貝氏自適應策略與後設推理整合，豐富了決策制定研究的理論範疇，以及在設計在不確定性和資源限制下規劃的 AI 系統時的實際應用。</paragraph>

##### **Rubric-based Learner Modelling via Noisy Gates Bayesian Networks for Computational Thinking Skills Assessment**
2408.01221v1 by Giorgia Adorni, Francesca Mangili, Alberto Piatti, Claudio Bonesana, Alessandro Antonucci

In modern and personalised education, there is a growing interest in
developing learners' competencies and accurately assessing them. In a previous
work, we proposed a procedure for deriving a learner model for automatic skill
assessment from a task-specific competence rubric, thus simplifying the
implementation of automated assessment tools. The previous approach, however,
suffered two main limitations: (i) the ordering between competencies defined by
the assessment rubric was only indirectly modelled; (ii) supplementary skills,
not under assessment but necessary for accomplishing the task, were not
included in the model. In this work, we address issue (i) by introducing dummy
observed nodes, strictly enforcing the skills ordering without changing the
network's structure. In contrast, for point (ii), we design a network with two
layers of gates, one performing disjunctive operations by noisy-OR gates and
the other conjunctive operations through logical ANDs. Such changes improve the
model outcomes' coherence and the modelling tool's flexibility without
compromising the model's compact parametrisation, interpretability and simple
experts' elicitation. We used this approach to develop a learner model for
Computational Thinking (CT) skills assessment. The CT-cube skills assessment
framework and the Cross Array Task (CAT) are used to exemplify it and
demonstrate its feasibility.

摘要：在現代化且個人化的教育中，對於培養學習者的能力並準確地評量他們的能力，有越來越高的興趣。在先前的研究中，我們提出了一個程序，用來從特定任務的能力評量標準中，推導出一個學習者模型，用於自動化技能評估，進而簡化自動化評量工具的實作。然而，先前的作法有兩個主要的限制：(i) 由評量標準所定義的能力之間的順序，僅以間接的方式建模；(ii) 額外的技能，雖然沒有在評量中，但對於完成任務而言是必要的，並沒有包含在模型中。在這項研究中，我們透過引入虛擬的觀察節點，來解決問題 (i)，嚴格地強制執行技能的順序，而不會改變網路的結構。相反地，對於重點 (ii)，我們設計了一個具有兩層閘門的網路，一層透過 noisy-OR 閘門執行析取運算，另一層透過邏輯 AND 執行合取運算。這些變更改善了模型結果的一致性，以及建模工具的彈性，而不會影響模型的緊湊參數化、可解釋性，以及簡單的專家引導。我們使用這種方法，來開發一個用於計算思維 (CT) 技能評估的學習者模型。CT 立方技能評估架構和交叉陣列任務 (CAT) 用於舉例說明，並展示其可行性。

##### **High-Throughput Phenotyping of Clinical Text Using Large Language Models**
2408.01214v1 by Daniel B. Hier, S. Ilyas Munzir, Anne Stahlfeld, Tayo Obafemi-Ajayi, Michael D. Carrithers

High-throughput phenotyping automates the mapping of patient signs to
standardized ontology concepts and is essential for precision medicine. This
study evaluates the automation of phenotyping of clinical summaries from the
Online Mendelian Inheritance in Man (OMIM) database using large language
models. Due to their rich phenotype data, these summaries can be surrogates for
physician notes. We conduct a performance comparison of GPT-4 and
GPT-3.5-Turbo. Our results indicate that GPT-4 surpasses GPT-3.5-Turbo in
identifying, categorizing, and normalizing signs, achieving concordance with
manual annotators comparable to inter-rater agreement. Despite some limitations
in sign normalization, the extensive pre-training of GPT-4 results in high
performance and generalizability across several phenotyping tasks while
obviating the need for manually annotated training data. Large language models
are expected to be the dominant method for automating high-throughput
phenotyping of clinical text.

摘要：高通量表型自動化將患者症狀對應到標準化本体概念，對於精準醫療至關重要。本研究評估使用大型語言模型自動化來自人類孟德爾遺傳線上（OMIM）資料庫的臨床摘要表型。由於其豐富的表型資料，這些摘要可以作為醫師備忘錄的替代品。我們對 GPT-4 和 GPT-3.5-Turbo 進行效能比較。我們的結果顯示，GPT-4 在識別、分類和標準化症狀方面優於 GPT-3.5-Turbo，與手動註解者的符合度可媲美評分者間的一致性。儘管在症狀標準化方面有一些限制，但 GPT-4 的廣泛預訓練在多項表型任務中仍能帶來高效能和概括性，同時無需手動註解的訓練資料。大型語言模型預計將成為自動化臨床文字高通量表型的主要方法。

##### **Multi-Objective Deep Reinforcement Learning for Optimisation in Autonomous Systems**
2408.01188v1 by Juan C. Rosero, Ivana Dusparic, Nicolás Cardozo

Reinforcement Learning (RL) is used extensively in Autonomous Systems (AS) as
it enables learning at runtime without the need for a model of the environment
or predefined actions. However, most applications of RL in AS, such as those
based on Q-learning, can only optimize one objective, making it necessary in
multi-objective systems to combine multiple objectives in a single objective
function with predefined weights. A number of Multi-Objective Reinforcement
Learning (MORL) techniques exist but they have mostly been applied in RL
benchmarks rather than real-world AS systems. In this work, we use a MORL
technique called Deep W-Learning (DWN) and apply it to the Emergent Web Servers
exemplar, a self-adaptive server, to find the optimal configuration for runtime
performance optimization. We compare DWN to two single-objective optimization
implementations: {\epsilon}-greedy algorithm and Deep Q-Networks. Our initial
evaluation shows that DWN optimizes multiple objectives simultaneously with
similar results than DQN and {\epsilon}-greedy approaches, having a better
performance for some metrics, and avoids issues associated with combining
multiple objectives into a single utility function.

摘要：強化學習（RL）廣泛用於自主系統（AS），因為它可以在執行時進行學習，而不需要環境模型或預定義動作。然而，RL 在 AS 中的大多數應用，例如基於 Q 學習的應用，只能最佳化一個目標，這使得在多目標系統中必須將多個目標組合成一個具有預定義權重的單一目標函數。許多多目標強化學習（MORL）技術已經存在，但它們大多應用於 RL 基準測試，而不是真實世界的 AS 系統。在這項工作中，我們使用一種稱為深度 W 學習（DWN）的 MORL 技術，並將其應用於新興 Web 伺服器範例（一種自適應伺服器），以找到最佳配置以進行執行時效能最佳化。我們將 DWN 與兩個單目標最佳化實作進行比較：{\epsilon}-greedy 演算法和深度 Q 網路。我們的初步評估顯示，DWN 同時最佳化多個目標，其結果與 DQN 和 {\epsilon}-greedy 方法相似，在某些指標上具有更好的效能，並避免了將多個目標組合成單一效用函數相關的問題。

##### **Misinforming LLMs: vulnerabilities, challenges and opportunities**
2408.01168v1 by Bo Zhou, Daniel Geißler, Paul Lukowicz

Large Language Models (LLMs) have made significant advances in natural
language processing, but their underlying mechanisms are often misunderstood.
Despite exhibiting coherent answers and apparent reasoning behaviors, LLMs rely
on statistical patterns in word embeddings rather than true cognitive
processes. This leads to vulnerabilities such as "hallucination" and
misinformation. The paper argues that current LLM architectures are inherently
untrustworthy due to their reliance on correlations of sequential patterns of
word embedding vectors. However, ongoing research into combining generative
transformer-based models with fact bases and logic programming languages may
lead to the development of trustworthy LLMs capable of generating statements
based on given truth and explaining their self-reasoning process.

摘要：大型語言模型 (LLM) 在自然語言處理方面取得了重大進展，但其底層機制往往被人誤解。儘管表現出連貫的答案和明顯的推理行為，但 LLM 依賴於詞嵌入中的統計模式，而不是真正的認知過程。這導致了諸如「幻覺」和錯誤訊息等漏洞。本文認為，當前 LLM 架構本質上是不可信的，因為它們依賴於詞嵌入向量的序列模式相關性。然而，正在進行的研究將生成式Transformer模型與事實基礎和邏輯程式語言相結合，可能會導致開發出可信賴的 LLM，這些 LLM 能夠根據既定事實產生陳述並解釋其自身推理過程。

##### **TCR-GPT: Integrating Autoregressive Model and Reinforcement Learning for T-Cell Receptor Repertoires Generation**
2408.01156v1 by Yicheng Lin, Dandan Zhang, Yun Liu

T-cell receptors (TCRs) play a crucial role in the immune system by
recognizing and binding to specific antigens presented by infected or cancerous
cells. Understanding the sequence patterns of TCRs is essential for developing
targeted immune therapies and designing effective vaccines. Language models,
such as auto-regressive transformers, offer a powerful solution to this problem
by learning the probability distributions of TCR repertoires, enabling the
generation of new TCR sequences that inherit the underlying patterns of the
repertoire. We introduce TCR-GPT, a probabilistic model built on a decoder-only
transformer architecture, designed to uncover and replicate sequence patterns
in TCR repertoires. TCR-GPT demonstrates an accuracy of 0.953 in inferring
sequence probability distributions measured by Pearson correlation coefficient.
Furthermore, by leveraging Reinforcement Learning(RL), we adapted the
distribution of TCR sequences to generate TCRs capable of recognizing specific
peptides, offering significant potential for advancing targeted immune
therapies and vaccine development. With the efficacy of RL, fine-tuned
pretrained TCR-GPT models demonstrated the ability to produce TCR repertoires
likely to bind specific peptides, illustrating RL's efficiency in enhancing the
model's adaptability to the probability distributions of biologically relevant
TCR sequences.

摘要：T 細胞受體 (TCR) 在免疫系統中扮演著至關重要的角色，
透過辨識並結合受感染或癌細胞呈現出的特定抗原。了解 TCR 的序列模式對於開發標靶免疫療法和設計有效疫苗至關重要。語言模型，
例如自迴歸轉換器，提供了一個強大的解決方案來解決這個問題，
透過學習 TCR 庫的機率分佈，能夠產生繼承庫中潛在模式的新 TCR 序列。我們引進 TCR-GPT，一個建立在僅解碼器轉換器架構上的機率模型，旨在揭示和複製 TCR 庫中的序列模式。TCR-GPT 在推論序列機率分佈時展現出 0.953 的準確度，透過皮爾森相關係數測量。此外，透過利用強化學習 (RL)，我們調整了 TCR 序列的分配，以產生能夠辨識特定胜肽的 TCR，為標靶免疫療法和疫苗開發的進步提供了顯著的潛力。透過 RL 的功效，微調後的預訓練 TCR-GPT 模型展現出產生可能結合特定胜肽的 TCR 庫的能力，說明了 RL 在增強模型對生物相關 TCR 序列機率分佈的適應性方面的效率。

##### **DERA: Dense Entity Retrieval for Entity Alignment in Knowledge Graphs**
2408.01154v1 by Zhichun Wang, Xuan Chen

Entity Alignment (EA) aims to match equivalent entities in different
Knowledge Graphs (KGs), which is essential for knowledge fusion and
integration. Recently, embedding-based EA has attracted significant attention
and many approaches have been proposed. Early approaches primarily focus on
learning entity embeddings from the structural features of KGs, defined by
relation triples. Later methods incorporated entities' names and attributes as
auxiliary information to enhance embeddings for EA. However, these approaches
often used different techniques to encode structural and attribute information,
limiting their interaction and mutual enhancement. In this work, we propose a
dense entity retrieval framework for EA, leveraging language models to
uniformly encode various features of entities and facilitate nearest entity
search across KGs. Alignment candidates are first generated through entity
retrieval, which are subsequently reranked to determine the final alignments.
We conduct comprehensive experiments on both cross-lingual and monolingual EA
datasets, demonstrating that our approach achieves state-of-the-art performance
compared to existing EA methods.

摘要：實體對齊 (EA) 旨在比對不同知識圖譜 (KG) 中的等效實體，這對於知識融合和整合非常重要。最近，基於嵌入的 EA 已引起相當大的關注，並且已提出許多方法。早期的方法主要專注於從 KG 的結構特徵中學習實體嵌入，這些特徵由關係三元組定義。後續的方法將實體的名稱和屬性作為輔助資訊，以增強 EA 的嵌入。然而，這些方法通常使用不同的技術來編碼結構和屬性資訊，限制了它們的互動和相互增強。在這項工作中，我們提出了一個密集實體擷取架構，用於 EA，利用語言模型來統一編碼實體的各種特徵，並促進跨 KG 的最近實體搜尋。對齊候選者首先透過實體擷取產生，然後重新排序以確定最終對齊。我們對跨語言和單語言 EA 資料集進行了全面的實驗，證明與現有的 EA 方法相比，我們的做法達到了最先進的效能。

##### **Interpreting Global Perturbation Robustness of Image Models using Axiomatic Spectral Importance Decomposition**
2408.01139v1 by Róisín Luo, James McDermott, Colm O'Riordan

Perturbation robustness evaluates the vulnerabilities of models, arising from
a variety of perturbations, such as data corruptions and adversarial attacks.
Understanding the mechanisms of perturbation robustness is critical for global
interpretability. We present a model-agnostic, global mechanistic
interpretability method to interpret the perturbation robustness of image
models. This research is motivated by two key aspects. First, previous global
interpretability works, in tandem with robustness benchmarks, e.g. mean
corruption error (mCE), are not designed to directly interpret the mechanisms
of perturbation robustness within image models. Second, we notice that the
spectral signal-to-noise ratios (SNR) of perturbed natural images exponentially
decay over the frequency. This power-law-like decay implies that: Low-frequency
signals are generally more robust than high-frequency signals -- yet high
classification accuracy can not be achieved by low-frequency signals alone. By
applying Shapley value theory, our method axiomatically quantifies the
predictive powers of robust features and non-robust features within an
information theory framework. Our method, dubbed as \textbf{I-ASIDE}
(\textbf{I}mage \textbf{A}xiomatic \textbf{S}pectral \textbf{I}mportance
\textbf{D}ecomposition \textbf{E}xplanation), provides a unique insight into
model robustness mechanisms. We conduct extensive experiments over a variety of
vision models pre-trained on ImageNet to show that \textbf{I-ASIDE} can not
only \textbf{measure} the perturbation robustness but also \textbf{provide
interpretations} of its mechanisms.

摘要：擾動魯棒性評估模型的漏洞，這些漏洞來自於各種擾動，例如資料損毀和對抗性攻擊。了解擾動魯棒性的機制對於全球可解釋性至關重要。我們提出一個與模型無關的、全球機制可解釋性方法來解釋影像模型的擾動魯棒性。這項研究是基於兩個關鍵面向。首先，先前的全球可解釋性工作與魯棒性基準（例如平均損壞誤差 (mCE)）結合使用，並非設計用於直接解釋影像模型中的擾動魯棒性機制。其次，我們注意到擾動自然影像的頻譜訊號雜訊比 (SNR) 會隨著頻率呈指數衰減。這種冪律衰減表示：低頻訊號通常比高頻訊號更穩健，但僅靠低頻訊號無法達到高分類準確度。透過應用 Shapley 值理論，我們的模型在資訊理論架構中公理化量化穩健特徵和非穩健特徵的預測能力。我們的模型稱為 \textbf{I-ASIDE}（\textbf{I}mage \textbf{A}xiomatic \textbf{S}pectral \textbf{I}mportance \textbf{D}ecomposition \textbf{E}xplanation），它提供了模型魯棒性機制的獨特見解。我們對各種在 ImageNet 上預先訓練的視覺模型進行廣泛的實驗，以證明 \textbf{I-ASIDE} 不僅可以\textbf{測量}擾動魯棒性，還可以\textbf{提供其機制的解釋}。

##### **A Survey of Mamba**
2408.01129v1 by Haohao Qu, Liangbo Ning, Rui An, Wenqi Fan, Tyler Derr, Xin Xu, Qing Li

Deep learning, as a vital technique, has sparked a notable revolution in
artificial intelligence. As the most representative architecture, Transformers
have empowered numerous advanced models, especially the large language models
that comprise billions of parameters, becoming a cornerstone in deep learning.
Despite the impressive achievements, Transformers still face inherent
limitations, particularly the time-consuming inference resulting from the
quadratic computation complexity of attention calculation. Recently, a novel
architecture named Mamba, drawing inspiration from classical state space
models, has emerged as a promising alternative for building foundation models,
delivering comparable modeling abilities to Transformers while preserving
near-linear scalability concerning sequence length. This has sparked an
increasing number of studies actively exploring Mamba's potential to achieve
impressive performance across diverse domains. Given such rapid evolution,
there is a critical need for a systematic review that consolidates existing
Mamba-empowered models, offering a comprehensive understanding of this emerging
model architecture. In this survey, we therefore conduct an in-depth
investigation of recent Mamba-associated studies, covering from three main
aspects: the advancements of Mamba-based models, the techniques of adapting
Mamba to diverse data, and the applications where Mamba can excel.
Specifically, we first recall the foundational knowledge of various
representative deep learning models and the details of Mamba as preliminaries.
Then, to showcase the significance of Mamba, we comprehensively review the
related studies focusing on Mamba models' architecture design, data
adaptability, and applications. Finally, we present an discussion of current
limitations and explore various promising research directions to provide deeper
insights for future investigations.

摘要：深度學習作為一項重要技術，在人工智慧領域引發了一場顯著的革命。作為最具代表性的架構，Transformer 已賦能多種進階模型，特別是包含數十億個參數的大型語言模型，成為深度學習的基石。儘管取得了令人印象深刻的成就，Transformer 仍然面臨固有的限制，特別是注意力計算的二次運算複雜度所導致的耗時推論。最近，一種名為 Mamba 的新架構，從經典狀態空間模型中汲取靈感，已成為構建基礎模型的有前途的替代方案，在保持與序列長度相關的近線性可擴充性的同時，提供了與 Transformer 相當的建模能力。這激發了越來越多的研究積極探索 Mamba 在不同領域實現令人印象深刻的效能的潛力。鑑於這種快速的演變，迫切需要進行系統性的回顧，以整合現有的 Mamba 賦能模型，對這種新興模型架構提供全面的理解。因此，在本次調查中，我們對最近與 Mamba 相關的研究進行了深入調查，涵蓋了三個主要方面：基於 Mamba 的模型的進展、將 Mamba 適應於不同資料的技術，以及 Mamba 可以發揮優勢的應用。具體來說，我們首先回顧了各種具有代表性的深度學習模型的基本知識和 Mamba 的詳細資訊作為預備知識。然後，為了展示 Mamba 的重要性，我們全面回顧了專注於 Mamba 模型的架構設計、資料適應性和應用相關的研究。最後，我們提出了對當前限制的討論，並探討了各種有前途的研究方向，以期為未來的調查提供更深入的見解。

##### **CFBench: A Comprehensive Constraints-Following Benchmark for LLMs**
2408.01122v1 by Tao Zhang, Yanjun Shen, Wenjing Luo, Yan Zhang, Hao Liang, Tao Zhang, Fan Yang, Mingan Lin, Yujing Qiao, Weipeng Chen, Bin Cui, Wentao Zhang, Zenan Zhou

The adeptness of Large Language Models (LLMs) in comprehending and following
natural language instructions is critical for their deployment in sophisticated
real-world applications. Existing evaluations mainly focus on fragmented
constraints or narrow scenarios, but they overlook the comprehensiveness and
authenticity of constraints from the user's perspective. To bridge this gap, we
propose CFBench, a large-scale Comprehensive Constraints Following Benchmark
for LLMs, featuring 1,000 curated samples that cover more than 200 real-life
scenarios and over 50 NLP tasks. CFBench meticulously compiles constraints from
real-world instructions and constructs an innovative systematic framework for
constraint types, which includes 10 primary categories and over 25
subcategories, and ensures each constraint is seamlessly integrated within the
instructions. To make certain that the evaluation of LLM outputs aligns with
user perceptions, we propose an advanced methodology that integrates
multi-dimensional assessment criteria with requirement prioritization, covering
various perspectives of constraints, instructions, and requirement fulfillment.
Evaluating current leading LLMs on CFBench reveals substantial room for
improvement in constraints following, and we further investigate influencing
factors and enhancement strategies. The data and code are publicly available at
https://github.com/PKU-Baichuan-MLSystemLab/CFBench

摘要：大型語言模型 (LLM) 在理解和遵循自然語言指令方面的熟練度對於它們在複雜的現實世界應用中部署至關重要。現有的評估主要集中在分散的約束或狹窄的場景中，但它們忽視了約束的全面性和從使用者角度出發的真實性。為了彌合這一差距，我們提出了 CFBench，一個針對 LLM 的大規模綜合約束遵循基準，其中包含 1,000 個策劃範例，涵蓋 200 多個真實生活場景和 50 多個 NLP 任務。CFBench 精心編制了來自真實世界指令的約束，並構建了一個創新的約束類型系統化框架，其中包含 10 個主要類別和 25 個子類別，並確保每個約束都無縫整合在指令中。為了確保對 LLM 輸出的評估與使用者認知保持一致，我們提出了一種先進的方法，將多維評估標準與需求優先順序相結合，涵蓋約束、指令和需求滿足的各種觀點。在 CFBench 上評估當前領先的 LLM 揭示了約束遵循方面有很大的改進空間，我們進一步研究了影響因素和增強策略。數據和程式碼可在 https://github.com/PKU-Baichuan-MLSystemLab/CFBench 公開取得

##### **Task Prompt Vectors: Effective Initialization through Multi-Task Soft-Prompt Transfer**
2408.01119v1 by Robert Belanec, Simon Ostermann, Ivan Srba, Maria Bielikova

Prompt tuning is a modular and efficient solution for training large language
models (LLMs). One of its main advantages is task modularity, making it
suitable for multi-task problems. However, current soft-prompt-based methods
often sacrifice multi-task modularity, requiring the training process to be
fully or partially repeated for each newly added task. While recent work on
task vectors applied arithmetic operations on full model weights to achieve the
desired multi-task performance, a similar approach for soft-prompts is still
missing. To this end, we introduce Task Prompt Vectors, created by element-wise
difference between weights of tuned soft-prompts and their random
initialization. Experimental results on 12 NLU datasets show that task prompt
vectors can be used in low-resource settings to effectively initialize prompt
tuning on similar tasks. In addition, we show that task prompt vectors are
independent of the random initialization of prompt tuning. This allows prompt
arithmetics with the pre-trained vectors from different tasks. In this way, by
arithmetic addition of task prompt vectors from multiple tasks, we are able to
outperform a state-of-the-art baseline in some cases.

摘要：提示調整是一種訓練大型語言模型 (LLM) 的模組化且有效率的解決方案。它的主要優勢之一是任務模組化，使其適用於多任務問題。然而，目前的軟提示方法通常會犧牲多任務模組化，需要針對每個新增加的任務完全或部分重複訓練過程。雖然最近關於任務向量的研究對完整的模型權重應用算術運算以達成所需的任務效能，但軟提示的類似方法仍然付之闕如。為此，我們引入了任務提示向量，它是透過調整過的軟提示權重與其隨機初始化之間的元素差異所建立的。在 12 個 NLU 資料集上的實驗結果顯示，任務提示向量可用於低資源設定中，以有效初始化類似任務的提示調整。此外，我們顯示任務提示向量與提示調整的隨機初始化無關。這允許使用來自不同任務的預先訓練向量進行提示運算。藉由這種方式，透過多個任務的任務提示向量的算術加法，我們有能力在某些情況下優於最先進的基準。

##### **IAI Group at CheckThat! 2024: Transformer Models and Data Augmentation for Checkworthy Claim Detection**
2408.01118v1 by Peter Røysland Aarnes, Vinay Setty, Petra Galuščáková

This paper describes IAI group's participation for automated check-worthiness
estimation for claims, within the framework of the 2024 CheckThat! Lab "Task 1:
Check-Worthiness Estimation". The task involves the automated detection of
check-worthy claims in English, Dutch, and Arabic political debates and Twitter
data. We utilized various pre-trained generative decoder and encoder
transformer models, employing methods such as few-shot chain-of-thought
reasoning, fine-tuning, data augmentation, and transfer learning from one
language to another. Despite variable success in terms of performance, our
models achieved notable placements on the organizer's leaderboard: ninth-best
in English, third-best in Dutch, and the top placement in Arabic, utilizing
multilingual datasets for enhancing the generalizability of check-worthiness
detection. Despite a significant drop in performance on the unlabeled test
dataset compared to the development test dataset, our findings contribute to
the ongoing efforts in claim detection research, highlighting the challenges
and potential of language-specific adaptations in claim verification systems.

摘要：本文描述了 IAI 小組參與 2024 年 CheckThat！實驗室「任務 1：檢核價值評估」中自動化聲明檢核價值評估的過程。此任務涉及自動偵測英文、荷蘭文和阿拉伯文政治辯論和 Twitter 資料中的檢核價值聲明。我們利用了各種預先訓練的生成式解碼器和編碼器Transformer模型，並採用了少樣本思維鏈推理、微調、資料擴充和從一種語言到另一種語言的遷移學習等方法。儘管在效能方面有不同的成功，但我們的模型在組織者的排行榜上取得了顯著的排名：英文第九名、荷蘭文第三名，並利用多語言資料集來增強檢核價值偵測的概括性，在阿拉伯文方面排名第一。儘管在未標記測試資料集上的效能與開發測試資料集相比大幅下降，但我們的研究結果有助於聲明偵測研究的持續努力，並突顯了聲明驗證系統中特定語言適應的挑戰和潛力。

##### **BioRAG: A RAG-LLM Framework for Biological Question Reasoning**
2408.01107v1 by Chengrui Wang, Qingqing Long, Xiao Meng, Xunxin Cai, Chengjun Wu, Zhen Meng, Xuezhi Wang, Yuanchun Zhou

The question-answering system for Life science research, which is
characterized by the rapid pace of discovery, evolving insights, and complex
interactions among knowledge entities, presents unique challenges in
maintaining a comprehensive knowledge warehouse and accurate information
retrieval. To address these issues, we introduce BioRAG, a novel
Retrieval-Augmented Generation (RAG) with the Large Language Models (LLMs)
framework. Our approach starts with parsing, indexing, and segmenting an
extensive collection of 22 million scientific papers as the basic knowledge,
followed by training a specialized embedding model tailored to this domain.
Additionally, we enhance the vector retrieval process by incorporating a
domain-specific knowledge hierarchy, which aids in modeling the intricate
interrelationships among each query and context. For queries requiring the most
current information, BioRAG deconstructs the question and employs an iterative
retrieval process incorporated with the search engine for step-by-step
reasoning. Rigorous experiments have demonstrated that our model outperforms
fine-tuned LLM, LLM with search engines, and other scientific RAG frameworks
across multiple life science question-answering tasks.

摘要：生命科學研究的問答系統，其特點是發現的快速步伐、洞察力的演變，以及知識實體之間的複雜互動，在維護全面的知識倉庫和準確的信息檢索方面提出了獨特的挑戰。為了解決這些問題，我們引入了 BioRAG，一種新穎的檢索增強生成 (RAG)，採用大語言模型 (LLM) 框架。我們的做法從解析、索引和分割 2200 萬篇科學論文的廣泛集合作為基本知識開始，然後訓練一個專門針對該領域的嵌入模型。此外，我們通過整合特定於領域的知識層級來增強向量檢索過程，這有助於對每個查詢和上下文之間的複雜相互關係進行建模。對於需要最新信息的查詢，BioRAG 會解構問題並採用迭代檢索過程，結合搜索引擎進行逐步推理。嚴格的實驗表明，我們的模型在多個生命科學問答任務中優於微調的 LLM、帶有搜索引擎的 LLM 和其他科學 RAG 框架。

##### **Contribution-based Low-Rank Adaptation with Pre-training Model for Real Image Restoration**
2408.01099v1 by Donwon Park, Hayeon Kim, Se Young Chun

Recently, pre-trained model and efficient parameter tuning have achieved
remarkable success in natural language processing and high-level computer
vision with the aid of masked modeling and prompt tuning. In low-level computer
vision, however, there have been limited investigations on pre-trained models
and even efficient fine-tuning strategy has not yet been explored despite its
importance and benefit in various real-world tasks such as alleviating memory
inflation issue when integrating new tasks on AI edge devices. Here, we propose
a novel efficient parameter tuning approach dubbed contribution-based low-rank
adaptation (CoLoRA) for multiple image restorations along with effective
pre-training method with random order degradations (PROD). Unlike prior arts
that tune all network parameters, our CoLoRA effectively fine-tunes small
amount of parameters by leveraging LoRA (low-rank adaptation) for each new
vision task with our contribution-based method to adaptively determine layer by
layer capacity for that task to yield comparable performance to full tuning.
Furthermore, our PROD strategy allows to extend the capability of pre-trained
models with improved performance as well as robustness to bridge synthetic
pre-training and real-world fine-tuning. Our CoLoRA with PROD has demonstrated
its superior performance in various image restoration tasks across diverse
degradation types on both synthetic and real-world datasets for known and novel
tasks.

摘要：近期，预先训练模型和高效参数调整在自然语言处理和高级计算机视觉中取得了显著的成功，这得益于掩蔽建模和提示调整。然而，在低级计算机视觉中，对预先训练模型的研究有限，即使在各种实际任务中（例如，在 AI 边缘设备上集成新任务时缓解内存膨胀问题）中它很重要且有益，但尚未探索高效的微调策略。在此，我们提出了一种新颖的高效参数调整方法，称为基于贡献的低秩适应 (CoLoRA)，用于多种图像修复以及具有随机顺序退化的有效预训练方法 (PROD)。与调整所有网络参数的先前技术不同，我们的 CoLoRA 通过利用 LoRA（低秩适应）为每项新的视觉任务有效地微调少量参数，并使用我们基于贡献的方法自适应地确定任务的逐层容量，以产生与完全调整相当的性能。此外，我们的 PROD 策略允许扩展预训练模型的能力，同时提高性能和鲁棒性，以弥合理论预训练和实际微调之间的差距。我们的 CoLoRA 与 PROD 已证明了其在各种图像修复任务中的卓越性能，这些任务跨越了合成和实际数据集中的已知和新颖任务的各种退化类型。

##### **Six Dragons Fly Again: Reviving 15th-Century Korean Court Music with Transformers and Novel Encoding**
2408.01096v1 by Danbinaerin Han, Mark Gotham, Dongmin Kim, Hannah Park, Sihun Lee, Dasaem Jeong

We introduce a project that revives a piece of 15th-century Korean court
music, Chihwapyeong and Chwipunghyeong, composed upon the poem Songs of the
Dragon Flying to Heaven. One of the earliest examples of Jeongganbo, a Korean
musical notation system, the remaining version only consists of a rudimentary
melody. Our research team, commissioned by the National Gugak (Korean
Traditional Music) Center, aimed to transform this old melody into a
performable arrangement for a six-part ensemble. Using Jeongganbo data acquired
through bespoke optical music recognition, we trained a BERT-like masked
language model and an encoder-decoder transformer model. We also propose an
encoding scheme that strictly follows the structure of Jeongganbo and denotes
note durations as positions. The resulting machine-transformed version of
Chihwapyeong and Chwipunghyeong were evaluated by experts and performed by the
Court Music Orchestra of National Gugak Center. Our work demonstrates that
generative models can successfully be applied to traditional music with limited
training data if combined with careful design.

摘要：我們介紹了一個復原 15 世紀韓國宮廷音樂的專案，即《飛龍歌》的《雉和拍》和《吹風詠》。這是韓國音樂記譜法「正干譜」最早的範例之一，現存版本僅包含基本的旋律。我們的研究團隊受國家國樂中心委託，旨在將這首古老的旋律轉化為六人合奏的表演編排。我們使用透過客製化光學音樂辨識取得的正干譜資料，訓練了一個類似 BERT 的遮蔽語言模型和一個編碼器-解碼器轉換器模型。我們還提出了一種編碼方案，它嚴格遵循正干譜的結構，並將音符時值標示為位置。由機器轉換後的《雉和拍》和《吹風詠》由專家評估，並由國家國樂中心的宮廷音樂樂團演奏。我們的研究證明，如果將生成模型與謹慎的設計結合，即使訓練資料有限，也能成功應用於傳統音樂。

##### **Dissecting Dissonance: Benchmarking Large Multimodal Models Against Self-Contradictory Instructions**
2408.01091v1 by Jin Gao, Lei Gan, Yuankai Li, Yixin Ye, Dequan Wang

Large multimodal models (LMMs) excel in adhering to human instructions.
However, self-contradictory instructions may arise due to the increasing trend
of multimodal interaction and context length, which is challenging for language
beginners and vulnerable populations. We introduce the Self-Contradictory
Instructions benchmark to evaluate the capability of LMMs in recognizing
conflicting commands. It comprises 20,000 conflicts, evenly distributed between
language and vision paradigms. It is constructed by a novel automatic dataset
creation framework, which expedites the process and enables us to encompass a
wide range of instruction forms. Our comprehensive evaluation reveals current
LMMs consistently struggle to identify multimodal instruction discordance due
to a lack of self-awareness. Hence, we propose the Cognitive Awakening
Prompting to inject cognition from external, largely enhancing dissonance
detection. The dataset and code are here: https://selfcontradiction.github.io/.

摘要：大型多模态模型 (LMM) 擅长遵循人类指令。
然而，由于多模态交互和上下文长度的趋势不断增长，可能会出现自相矛盾的指令，这对语言初学者和弱势群体来说具有挑战性。我们引入了自相矛盾指令基准来评估 LMM 在识别冲突命令方面的能力。它包含 20,000 个冲突，均匀分布在语言和视觉范式之间。它是由一个新颖的自动数据集创建框架构建的，该框架加快了进程，使我们能够涵盖广泛的指令形式。我们的综合评估显示，由于缺乏自我意识，当前的 LMM 一直难以识别多模态指令不一致。因此，我们提出了认知唤醒提示，以注入来自外部的认知，极大地增强了不和谐检测。数据集和代码在这里：https://selfcontradiction.github.io/。

##### **General-purpose Dataflow Model with Neuromorphic Primitives**
2408.01090v1 by Weihao Zhang, Yu Du, Hongyi Li, Songchen Ma, Rong Zhao

Neuromorphic computing exhibits great potential to provide high-performance
benefits in various applications beyond neural networks. However, a
general-purpose program execution model that aligns with the features of
neuromorphic computing is required to bridge the gap between program
versatility and neuromorphic hardware efficiency. The dataflow model offers a
potential solution, but it faces high graph complexity and incompatibility with
neuromorphic hardware when dealing with control flow programs, which decreases
the programmability and performance. Here, we present a dataflow model tailored
for neuromorphic hardware, called neuromorphic dataflow, which provides a
compact, concise, and neuromorphic-compatible program representation for
control logic. The neuromorphic dataflow introduces "when" and "where"
primitives, which restructure the view of control. The neuromorphic dataflow
embeds these primitives in the dataflow schema with the plasticity inherited
from the spiking algorithms. Our method enables the deployment of
general-purpose programs on neuromorphic hardware with both programmability and
plasticity, while fully utilizing the hardware's potential.

摘要：神經形態運算在神經網路以外的各種應用中展現出極大的潛力，可提供高性能優勢。然而，需要一個與神經形態運算特徵相符的通用程式執行模型來彌合程式多功能性和神經形態硬體效率之間的差距。資料流程模型提供了一個可能的解決方案，但它在處理控制流程程式時面臨圖形複雜度高和與神經形態硬體不相容的問題，這降低了可程式性和效能。在此，我們提出了一個針對神經形態硬體量身打造的資料流程模型，稱為神經形態資料流程，它為控制邏輯提供了一個緊湊、簡潔且與神經形態相容的程式表示。神經形態資料流程引入了「何時」和「何處」的原語，它們重構了控制的觀點。神經形態資料流程將這些原語嵌入資料流程架構中，並具有從尖峰演算法繼承而來的可塑性。我們的技術可以在神經形態硬體上部署通用程式，同時具備可程式性和可塑性，同時充分利用硬體的潛力。

##### **Bridging Information Gaps in Dialogues With Grounded Exchanges Using Knowledge Graphs**
2408.01088v1 by Phillip Schneider, Nektarios Machner, Kristiina Jokinen, Florian Matthes

Knowledge models are fundamental to dialogue systems for enabling
conversational interactions, which require handling domain-specific knowledge.
Ensuring effective communication in information-providing conversations entails
aligning user understanding with the knowledge available to the system.
However, dialogue systems often face challenges arising from semantic
inconsistencies in how information is expressed in natural language compared to
how it is represented within the system's internal knowledge. To address this
problem, we study the potential of large language models for conversational
grounding, a mechanism to bridge information gaps by establishing shared
knowledge between dialogue participants. Our approach involves annotating human
conversations across five knowledge domains to create a new dialogue corpus
called BridgeKG. Through a series of experiments on this dataset, we
empirically evaluate the capabilities of large language models in classifying
grounding acts and identifying grounded information items within a knowledge
graph structure. Our findings offer insights into how these models use
in-context learning for conversational grounding tasks and common prediction
errors, which we illustrate with examples from challenging dialogues. We
discuss how the models handle knowledge graphs as a semantic layer between
unstructured dialogue utterances and structured information items.

摘要：知識模型是對話系統的基本要素，用於啟用對話互動，這需要處理特定領域的知識。確保在提供資訊的對話中進行有效的溝通，需要將使用者的理解與系統可用的知識結合起來。然而，對話系統經常面臨語意不一致的挑戰，在自然語言中表達資訊的方式與在系統內部知識中表示資訊的方式不同。為了解決這個問題，我們研究大型語言模型在對話基礎中的潛力，這是一種透過在對話參與者之間建立共享知識來彌合資訊差距的機制。我們的做法包括註解五個知識領域中的人類對話，以建立一個新的對話語料庫，稱為 BridgeKG。透過對此資料集進行一系列實驗，我們實證評估大型語言模型在分類基礎行為和識別知識圖結構中的基礎資訊項目的能力。我們的發現提供了關於這些模型如何使用情境學習來進行對話基礎任務和常見預測錯誤的見解，我們用具有挑戰性的對話範例來說明。我們討論模型如何將知識圖形視為非結構化對話語句和結構化資訊項目之間的語意層。

##### **Adaptive Contrastive Decoding in Retrieval-Augmented Generation for Handling Noisy Contexts**
2408.01084v1 by Youna Kim, Hyuhng Joon Kim, Cheonbok Park, Choonghyun Park, Hyunsoo Cho, Junyeob Kim, Kang Min Yoo, Sang-goo Lee, Taeuk Kim

When using large language models (LLMs) in knowledge-intensive tasks, such as
open-domain question answering, external context can bridge a gap between
external knowledge and LLM's parametric knowledge. Recent research has been
developed to amplify contextual knowledge over the parametric knowledge of LLM
with contrastive decoding approaches. While these approaches could yield
truthful responses when relevant context is provided, they are prone to
vulnerabilities when faced with noisy contexts. We extend the scope of previous
studies to encompass noisy contexts and propose adaptive contrastive decoding
(ACD) to leverage contextual influence effectively. ACD demonstrates
improvements in open-domain question answering tasks compared to baselines,
especially in robustness by remaining undistracted by noisy contexts in
retrieval-augmented generation.

摘要：在知識密集型任務中使用大型語言模型 (LLM) 時，例如開放領域問題解答，外部背景可以彌合外部知識與 LLM 參數知識之間的差距。最近的研究已開發為通過對比解碼方法來放大 LLM 的參數知識上的背景知識。雖然這些方法可以在提供相關背景時產生真實的回應，但它們在面對嘈雜的背景時容易出現漏洞。我們擴展了先前研究的範圍以涵蓋嘈雜的背景，並提出自適應對比解碼 (ACD) 以有效利用背景影響。與基準相比，ACD 在開放領域問題解答任務中展示了改進，特別是在通過在檢索增強生成中不受嘈雜背景影響而保持魯棒性方面。

##### **The EAP-AIAS: Adapting the AI Assessment Scale for English for Academic Purposes**
2408.01075v1 by Jasper Roe, Mike Perkins, Yulia Tregubova

The rapid advancement of Generative Artificial Intelligence (GenAI) presents
both opportunities and challenges for English for Academic Purposes (EAP)
instruction. This paper proposes an adaptation of the AI Assessment Scale
(AIAS) specifically tailored for EAP contexts, termed the EAP-AIAS.
  This framework aims to provide a structured approach for integrating GenAI
tools into EAP assessment practices while maintaining academic integrity and
supporting language development. The EAP-AIAS consists of five levels, ranging
from "No AI" to "Full AI", each delineating appropriate GenAI usage in EAP
tasks. We discuss the rationale behind this adaptation, considering the unique
needs of language learners and the dual focus of EAP on language proficiency
and academic acculturation.
  This paper explores potential applications of the EAP-AIAS across various EAP
assessment types, including writing tasks, presentations, and research
projects. By offering a flexible framework, the EAP-AIAS seeks to empower EAP
practitioners seeking to deal with the complexities of GenAI integration in
education and prepare students for an AI-enhanced academic and professional
future. This adaptation represents a step towards addressing the pressing need
for ethical and pedagogically sound AI integration in language education.

摘要：生成式人工智能 (GenAI) 的快速進展為學術英語 (EAP) 教學帶來了機遇和挑戰。本文提出了一種專門針對 EAP 環境調整的 AI 評量量表 (AIAS)，稱為 EAP-AIAS。此架構旨在提供一種結構化的方法，將 GenAI 工具整合到 EAP 評量實務中，同時維護學術誠信並支援語言發展。EAP-AIAS 包含五個等級，範圍從「無 AI」到「全 AI」，每個等級都描述了在 EAP 任務中適當的 GenAI 使用方式。我們討論了這種調整背後的原理，考慮到語言學習者的獨特需求以及 EAP 對語言能力和學術適應的雙重關注。本文探討了 EAP-AIAS 在各種 EAP 評量類型中的潛在應用，包括寫作任務、簡報和研究專題。透過提供一個彈性的架構，EAP-AIAS 旨在賦能 EAP 從業人員，以應對教育中整合 GenAI 的複雜性，並讓學生為 AI 增強的學術和專業未來做好準備。這種調整代表著邁向滿足語言教育中道德且教學上健全的 AI 整合迫切需求的一步。

##### **Leveraging Large Language Models for Mobile App Review Feature Extraction**
2408.01063v1 by Quim Motger, Alessio Miaschi, Felice Dell'Orletta, Xavier Franch, Jordi Marco

Mobile app review analysis presents unique challenges due to the low quality,
subjective bias, and noisy content of user-generated documents. Extracting
features from these reviews is essential for tasks such as feature
prioritization and sentiment analysis, but it remains a challenging task.
Meanwhile, encoder-only models based on the Transformer architecture have shown
promising results for classification and information extraction tasks for
multiple software engineering processes. This study explores the hypothesis
that encoder-only large language models can enhance feature extraction from
mobile app reviews. By leveraging crowdsourced annotations from an industrial
context, we redefine feature extraction as a supervised token classification
task. Our approach includes extending the pre-training of these models with a
large corpus of user reviews to improve contextual understanding and employing
instance selection techniques to optimize model fine-tuning. Empirical
evaluations demonstrate that this method improves the precision and recall of
extracted features and enhances performance efficiency. Key contributions
include a novel approach to feature extraction, annotated datasets, extended
pre-trained models, and an instance selection mechanism for cost-effective
fine-tuning. This research provides practical methods and empirical evidence in
applying large language models to natural language processing tasks within
mobile app reviews, offering improved performance in feature extraction.

摘要：行動應用程式評論分析由於使用者產生的文件品質低落、主觀偏見和內容雜亂等因素而面臨獨特的挑戰。從這些評論中萃取特徵對於功能優先順序和情緒分析等任務至關重要，但這仍然是一項具有挑戰性的任務。與此同時，基於 Transformer 架構的僅編碼器模型已為多項軟體工程程序的分類和資訊萃取任務展現出令人振奮的成果。本研究探討了僅編碼器大型語言模型能夠提升從行動應用程式評論中萃取特徵的假設。透過利用來自產業背景的群眾外包註解，我們將特徵萃取重新定義為受監督的權杖分類任務。我們的做法包括使用大量使用者評論來擴充這些模型的預先訓練，以改善脈絡理解，並採用實例選擇技術來最佳化模型微調。實證評估顯示，此方法改善了萃取特徵的準確度和召回率，並提升了效能。主要貢獻包括一種用於特徵萃取的新穎方法、註解資料集、擴充的預先訓練模型，以及一種用於經濟高效微調的實例選擇機制。本研究提供了實務方法和實證證據，說明如何將大型語言模型應用於行動應用程式評論中的自然語言處理任務，並在特徵萃取方面提供更好的效能。

##### **LLM as Runtime Error Handler: A Promising Pathway to Adaptive Self-Healing of Software Systems**
2408.01055v1 by Zhensu Sun, Haotian Zhu, Bowen Xu, Xiaoning Du, Li Li, David Lo

Unanticipated runtime errors, lacking predefined handlers, can abruptly
terminate execution and lead to severe consequences, such as data loss or
system crashes. Despite extensive efforts to identify potential errors during
the development phase, such unanticipated errors remain a challenge to to be
entirely eliminated, making the runtime mitigation measurements still
indispensable to minimize their impact. Automated self-healing techniques, such
as reusing existing handlers, have been investigated to reduce the loss coming
through with the execution termination. However, the usability of existing
methods is retained by their predefined heuristic rules and they fail to handle
diverse runtime errors adaptively. Recently, the advent of Large Language
Models (LLMs) has opened new avenues for addressing this problem. Inspired by
their remarkable capabilities in understanding and generating code, we propose
to deal with the runtime errors in a real-time manner using LLMs.
  Specifically, we propose Healer, the first LLM-assisted self-healing
framework for handling runtime errors. When an unhandled runtime error occurs,
Healer will be activated to generate a piece of error-handling code with the
help of its internal LLM and the code will be executed inside the runtime
environment owned by the framework to obtain a rectified program state from
which the program should continue its execution. Our exploratory study
evaluates the performance of Healer using four different code benchmarks and
three state-of-the-art LLMs, GPT-3.5, GPT-4, and CodeQwen-7B. Results show
that, without the need for any fine-tuning, GPT-4 can successfully help
programs recover from 72.8% of runtime errors, highlighting the potential of
LLMs in handling runtime errors.

摘要：<paragraph>未預期的執行時間錯誤缺乏預先定義的處理常式，可能會突然終止執行並導致嚴重後果，例如資料遺失或系統崩潰。儘管在開發階段已盡力找出潛在錯誤，但此類未預期的錯誤仍難以完全消除，因此執行時間緩解措施對於將其影響降至最低仍然不可或缺。已研究自動自我復原技術，例如重複使用現有處理常式，以減少執行終止造成的損失。然而，現有方法的可用性受其預先定義的啟發式規則所限，且無法靈活處理不同的執行時間錯誤。最近，大型語言模型 (LLM) 的出現為解決此問題開闢了新途徑。受到 LLM 在理解和產生程式碼方面的卓越能力所啟發，我們提議使用 LLM 即時處理執行時間錯誤。
具體來說，我們提出 Healer，這是第一個由 LLM 輔助的自我復原架構，用於處理執行時間錯誤。當發生未處理的執行時間錯誤時，Healer 將會被啟動，並在內部 LLM 的協助下產生一段錯誤處理程式碼，且該程式碼將在架構擁有的執行時間環境中執行，以取得已修正的程式狀態，而程式應從該狀態繼續執行。我們的探索性研究使用四個不同的程式碼基準和三個最先進的 LLM（GPT-3.5、GPT-4 和 CodeQwen-7B）來評估 Healer 的效能。結果顯示，無需任何微調，GPT-4 便能成功協助程式從 72.8% 的執行時間錯誤中復原，突顯了 LLM 在處理執行時間錯誤方面的潛力。</paragraph>

##### **The Impact of Hyperparameters on Large Language Model Inference Performance: An Evaluation of vLLM and HuggingFace Pipelines**
2408.01050v1 by Matias Martinez

The recent surge of open-source large language models (LLMs) enables
developers to create AI-based solutions while maintaining control over aspects
such as privacy and compliance, thereby providing governance and ownership of
the model deployment process. To utilize these LLMs, inference engines are
needed. These engines load the model's weights onto available resources, such
as GPUs, and process queries to generate responses. The speed of inference, or
performance, of the LLM, is critical for real-time applications, as it computes
millions or billions of floating point operations per inference. Recently,
advanced inference engines such as vLLM have emerged, incorporating novel
mechanisms such as efficient memory management to achieve state-of-the-art
performance. In this paper, we analyze the performance, particularly the
throughput (tokens generated per unit of time), of 20 LLMs using two inference
libraries: vLLM and HuggingFace's pipelines. We investigate how various
hyperparameters, which developers must configure, influence inference
performance. Our results reveal that throughput landscapes are irregular, with
distinct peaks, highlighting the importance of hyperparameter optimization to
achieve maximum performance. We also show that applying hyperparameter
optimization when upgrading or downgrading the GPU model used for inference can
improve throughput from HuggingFace pipelines by an average of 9.16% and 13.7%,
respectively.

摘要：<paragraph>最近開放原始碼的大型語言模型 (LLM) 的激增，讓開發人員能夠在維護隱私和合規等方面保持控制的情況下建立基於 AI 的解決方案，從而提供模型部署流程的治理和所有權。為了使用這些 LLM，需要推理引擎。這些引擎將模型的權重載入到可用資源（例如 GPU）上，並處理查詢以產生回應。LLM 的推理速度或效能對於即時應用程式至關重要，因為它每進行一次推理就會計算數百萬或數十億個浮點運算。最近，出現了 vLLM 等先進的推理引擎，它結合了高效記憶體管理等新機制來實現最先進的效能。在本文中，我們分析了效能，特別是使用兩個推理庫（vLLM 和 HuggingFace 的管道）的 20 個 LLM 的吞吐量（每單位時間產生的代幣）。我們探討了開發人員必須配置的各種超參數如何影響推理效能。我們的結果顯示，吞吐量狀況是不規則的，有明顯的高峰，這突顯了超參數最佳化對於達成最大效能的重要性。我們還展示了在升級或降級用於推理的 GPU 模型時應用超參數最佳化可以分別將 HuggingFace 管道的吞吐量平均提升 9.16% 和 13.7%。</paragraph>

##### **QUDSELECT: Selective Decoding for Questions Under Discussion Parsing**
2408.01046v1 by Ashima Suvarna, Xiao Liu, Tanmay Parekh, Kai-Wei Chang, Nanyun Peng

Question Under Discussion (QUD) is a discourse framework that uses implicit
questions to reveal discourse relationships between sentences. In QUD parsing,
each sentence is viewed as an answer to a question triggered by an anchor
sentence in prior context. The resulting QUD structure is required to conform
to several theoretical criteria like answer compatibility (how well the
question is answered), making QUD parsing a challenging task. Previous works
construct QUD parsers in a pipelined manner (i.e. detect the trigger sentence
in context and then generate the question). However, these parsers lack a
holistic view of the task and can hardly satisfy all the criteria. In this
work, we introduce QUDSELECT, a joint-training framework that selectively
decodes the QUD dependency structures considering the QUD criteria. Using
instruction-tuning, we train models to simultaneously predict the anchor
sentence and generate the associated question. To explicitly incorporate the
criteria, we adopt a selective decoding strategy of sampling multiple QUD
candidates during inference, followed by selecting the best one with criteria
scorers. Our method outperforms the state-of-the-art baseline models by 9% in
human evaluation and 4% in automatic evaluation, demonstrating the
effectiveness of our framework.

摘要：討論中的問題 (QUD) 是一種話語架構，它使用隱含問題來揭示句子之間的話語關係。在 QUD 解析中，每個句子都被視為一個由先前語境中的錨定句子觸發的問題的答案。產生的 QUD 結構必須符合幾個理論標準，例如答案相容性（問題回答得有多好），這使得 QUD 解析成為一項具有挑戰性的任務。先前的研究以流水線的方式構建 QUD 解析器（即在語境中檢測觸發句子，然後生成問題）。然而，這些解析器缺乏對任務的整體看法，很難滿足所有標準。在這項工作中，我們介紹了 QUDSELECT，這是一個聯合訓練框架，它有選擇地解碼 QUD 依賴結構，並考慮了 QUD 標準。使用指令微調，我們訓練模型同時預測錨定句子並生成相關問題。為了明確地納入標準，我們採用了一種選擇性解碼策略，在推理期間對多個 QUD 候選進行抽樣，然後根據標準評分器選擇最佳候選。我們的模型在人工評估中比最先進的基準模型高出 9%，在自動評估中高出 4%，證明了我們框架的有效性。

##### **UNER: A Unified Prediction Head for Named Entity Recognition in Visually-rich Documents**
2408.01038v1 by Yi Tu, Chong Zhang, Ya Guo, Huan Chen, Jinyang Tang, Huijia Zhu, Qi Zhang

The recognition of named entities in visually-rich documents (VrD-NER) plays
a critical role in various real-world scenarios and applications. However, the
research in VrD-NER faces three major challenges: complex document layouts,
incorrect reading orders, and unsuitable task formulations. To address these
challenges, we propose a query-aware entity extraction head, namely UNER, to
collaborate with existing multi-modal document transformers to develop more
robust VrD-NER models. The UNER head considers the VrD-NER task as a
combination of sequence labeling and reading order prediction, effectively
addressing the issues of discontinuous entities in documents. Experimental
evaluations on diverse datasets demonstrate the effectiveness of UNER in
improving entity extraction performance. Moreover, the UNER head enables a
supervised pre-training stage on various VrD-NER datasets to enhance the
document transformer backbones and exhibits substantial knowledge transfer from
the pre-training stage to the fine-tuning stage. By incorporating universal
layout understanding, a pre-trained UNER-based model demonstrates significant
advantages in few-shot and cross-linguistic scenarios and exhibits zero-shot
entity extraction abilities.

摘要：在視覺豐富文件（VrD-NER）中識別命名實體對於各種真實世界的場景和應用扮演著至關重要的角色。然而，VrD-NER 的研究面臨三大挑戰：複雜的文件佈局、錯誤的閱讀順序，以及不適當的任務表述。為了應對這些挑戰，我們提出了一個查詢感知實體提取頭，即 UNER，與現有的多模態文件轉換器協作，以開發更強大的 VrD-NER 模型。UNER 頭部將 VrD-NER 任務視為序列標籤和閱讀順序預測的組合，有效地解決了文件中不連續實體的問題。在不同數據集上的實驗評估證明了 UNER 在提高實體提取性能方面的有效性。此外，UNER 頭部在各種 VrD-NER 數據集上啟用了一個監督預訓練階段，以增強文件轉換器主幹，並展示了從預訓練階段到微調階段的大量知識轉移。通過整合通用的佈局理解，一個預訓練的基於 UNER 的模型在少鏡頭和跨語言場景中展示了顯著的優勢，並展示了零鏡頭實體提取能力。

##### **Semantic Skill Grounding for Embodied Instruction-Following in Cross-Domain Environments**
2408.01024v1 by Sangwoo Shin, Seunghyun Kim, Youngsoo Jang, Moontae Lee, Honguk Woo

In embodied instruction-following (EIF), the integration of pretrained
language models (LMs) as task planners emerges as a significant branch, where
tasks are planned at the skill level by prompting LMs with pretrained skills
and user instructions. However, grounding these pretrained skills in different
domains remains challenging due to their intricate entanglement with the
domain-specific knowledge. To address this challenge, we present a semantic
skill grounding (SemGro) framework that leverages the hierarchical nature of
semantic skills. SemGro recognizes the broad spectrum of these skills, ranging
from short-horizon low-semantic skills that are universally applicable across
domains to long-horizon rich-semantic skills that are highly specialized and
tailored for particular domains. The framework employs an iterative skill
decomposition approach, starting from the higher levels of semantic skill
hierarchy and then moving downwards, so as to ground each planned skill to an
executable level within the target domain. To do so, we use the reasoning
capabilities of LMs for composing and decomposing semantic skills, as well as
their multi-modal extension for assessing the skill feasibility in the target
domain. Our experiments in the VirtualHome benchmark show the efficacy of
SemGro in 300 cross-domain EIF scenarios.

摘要：在體現指令遵循 (EIF) 中，預訓練語言模型 (LM) 作為任務規劃者的整合成為一個重要的分支，其中任務在技能層級上被規劃，通過提示 LM 預訓練技能和使用者指令。然而，由於預訓練技能與特定領域知識的複雜糾纏，將這些預訓練技能基礎化在不同的領域中仍然具有挑戰性。為了應對這一挑戰，我們提出了一個語義技能基礎化 (SemGro) 框架，該框架利用了語義技能的層次結構。SemGro 認識到這些技能的廣泛範圍，從普遍適用於跨領域的短視界低語義技能到高度專業化且針對特定領域量身定制的長視界豐富語義技能。該框架採用了一種迭代技能分解方法，從語義技能層次的較高層級開始，然後向下移動，以便將每個計劃技能基礎化到目標領域中的可執行層級。為此，我們使用 LM 的推理能力來組合和分解語義技能，以及它們的多模式擴充功能來評估目標領域中的技能可行性。我們在 VirtualHome 基準測試中的實驗顯示了 SemGro 在 300 個跨領域 EIF 場景中的功效。

##### **GNN-MolKAN: Harnessing the Power of KAN to Advance Molecular Representation Learning with GNNs**
2408.01018v1 by Ruifeng Li

Effective molecular representation learning is crucial for molecular property
prediction and drug design. However, existing approaches struggle with
limitations in insufficient annotations and suboptimal architecture design. For
instance, Graph Neural Networks (GNNs) suffer from over-squashing, causing the
loss of important structural details in molecules, thus impairing molecular
representations. In this work, we propose a new class of GNNs, GNN-MolKAN and
its augmented variant, GNN-MolKAN+, that integrate the Kolmogorov-Arnold
Networks (KAN) architecture from AI + Science into GNNs to address these
challenges. Additionally, we introduce Adaptive FastKAN (AdFastKAN), an
advanced KAN that offers increased stability and speed, further enhancing the
performance of standard GNNs. Notably, our approach holds three key benefits:
1) Superior Performance: GNN-MolKAN and GNN-MolKAN+ demonstrate superior
prediction ability, robust generalization to unseen scaffolds, and versatile
transferability across different GNN architectures. 2) Efficiency: These models
require less computational time and fewer parameters while matching or
surpassing the state-of-the-art (SOTA) self-supervised methods. 3) Few-shot
Learning Ability: GNN-MolKAN demonstrates great potential in few-shot learning
scenarios, achieving an average improvement of 6.97% across few-shot
benchmarks. Overall, we validate our architecture on 6 classification datasets,
6 regression datasets, and 4 few-shot learning datasets, consistently achieving
highly competitive results across all of them.

摘要：有效的分子表示學習對於分子屬性預測和藥物設計至關重要。然而，現有方法在註解不足和次優架構設計方面存在局限性。例如，圖神經網路 (GNN) 會產生過度壓縮，導致分子中重要的結構細節遺失，進而損害分子表示。在這項工作中，我們提出一個新的 GNN 類別，GNN-MolKAN 及其擴增變體 GNN-MolKAN+，將來自 AI + Science 的 Kolmogorov-Arnold 網路 (KAN) 架構整合到 GNN 中，以解決這些挑戰。此外，我們引入了自適應快速 KAN (AdFastKAN)，這是一種先進的 KAN，提供了更高的穩定性和速度，進一步增強了標準 GNN 的效能。值得注意的是，我們的做法有三大好處：1) 優異的效能：GNN-MolKAN 和 GNN-MolKAN+ 展現出優異的預測能力、對未見支架的強健泛化能力，以及在不同 GNN 架構之間的多功能可傳遞性。2) 效率：這些模型所需的運算時間較短，且參數較少，同時匹配或超越了最先進 (SOTA) 的自監督方法。3) 少樣本學習能力：GNN-MolKAN 在少樣本學習情境中展現出極大的潛力，在少樣本基準中平均提升了 6.97%。總體而言，我們在 6 個分類資料集、6 個回歸資料集和 4 個少樣本學習資料集上驗證了我們的架構，在所有這些資料集上持續取得極具競爭力的結果。

##### **IBB Traffic Graph Data: Benchmarking and Road Traffic Prediction Model**
2408.01016v1 by Eren Olug, Kiymet Kaya, Resul Tugay, Sule Gunduz Oguducu

Road traffic congestion prediction is a crucial component of intelligent
transportation systems, since it enables proactive traffic management, enhances
suburban experience, reduces environmental impact, and improves overall safety
and efficiency. Although there are several public datasets, especially for
metropolitan areas, these datasets may not be applicable to practical scenarios
due to insufficiency in the scale of data (i.e. number of sensors and road
links) and several external factors like different characteristics of the
target area such as urban, highways and the data collection location. To
address this, this paper introduces a novel IBB Traffic graph dataset as an
alternative benchmark dataset to mitigate these limitations and enrich the
literature with new geographical characteristics. IBB Traffic graph dataset
covers the sensor data collected at 2451 distinct locations. Moreover, we
propose a novel Road Traffic Prediction Model that strengthens temporal links
through feature engineering, node embedding with GLEE to represent
inter-related relationships within the traffic network, and traffic prediction
with ExtraTrees. The results indicate that the proposed model consistently
outperforms the baseline models, demonstrating an average accuracy improvement
of 4%.

摘要：道路交通拥塞预测是智能交通系统的重要组成部分，因为它能够实现主动交通管理、增强郊区体验、减少环境影响，并提高整体安全性和效率。尽管有几个公共数据集，特别是对于大都市地区，但由于数据规模（即传感器和道路链路数量）不足以及不同目标区域（如城市、高速公路和数据收集位置）等几个外部因素，这些数据集可能不适用于实际场景。为了解决这个问题，本文介绍了一个新颖的 IBB 交通图数据集，作为替代基准数据集，以减轻这些限制并用新的地理特征丰富文献。IBB 交通图数据集涵盖了在 2451 个不同位置收集的传感器数据。此外，我们提出了一个新颖的道路交通预测模型，该模型通过特征工程、使用 GLEE 的节点嵌入来表示交通网络中的相互关系，以及使用 ExtraTrees 进行交通预测来加强时间联系。结果表明，所提出的模型始终优于基线模型，平均准确度提高了 4%。

##### **Tensor Train Low-rank Approximation (TT-LoRA): Democratizing AI with Accelerated LLMs**
2408.01008v1 by Afia Anjum, Maksim E. Eren, Ismael Boureima, Boian Alexandrov, Manish Bhattarai

In recent years, Large Language Models (LLMs) have demonstrated remarkable
capabilities across a wide range of natural language processing (NLP) tasks,
such as question-answering, sentiment analysis, text summarization, and machine
translation. However, the ever-growing complexity of LLMs demands immense
computational resources, hindering the broader research and application of
these models. To address this, various parameter-efficient fine-tuning
strategies, such as Low-Rank Approximation (LoRA) and Adapters, have been
developed. Despite their potential, these methods often face limitations in
compressibility. Specifically, LoRA struggles to scale effectively with the
increasing number of trainable parameters in modern large scale LLMs.
Additionally, Low-Rank Economic Tensor-Train Adaptation (LoRETTA), which
utilizes tensor train decomposition, has not yet achieved the level of
compression necessary for fine-tuning very large scale models with limited
resources. This paper introduces Tensor Train Low-Rank Approximation (TT-LoRA),
a novel parameter-efficient fine-tuning (PEFT) approach that extends LoRETTA
with optimized tensor train (TT) decomposition integration. By eliminating
Adapters and traditional LoRA-based structures, TT-LoRA achieves greater model
compression without compromising downstream task performance, along with
reduced inference latency and computational overhead. We conduct an exhaustive
parameter search to establish benchmarks that highlight the trade-off between
model compression and performance. Our results demonstrate significant
compression of LLMs while maintaining comparable performance to larger models,
facilitating their deployment on resource-constraint platforms.

摘要：近年來，大型語言模型（LLM）在廣泛的自然語言處理（NLP）任務中展現了卓越的能力，例如問答、情緒分析、文字摘要和機器翻譯。然而，LLM 不斷增長的複雜性需要龐大的運算資源，阻礙了這些模型更廣泛的研究和應用。為了解決這個問題，已經開發了各種參數高效的微調策略，例如低秩近似（LoRA）和適配器。儘管有潛力，這些方法在可壓縮性方面常常面臨限制。具體來說，LoRA 難以隨著現代大規模 LLM 中可訓練參數的數量增加而有效擴展。此外，利用張量訓練分解的低秩經濟張量訓練適應（LoRETTA）尚未達到使用有限資源微調超大規模模型所需的壓縮級別。本文介紹了張量訓練低秩近似（TT-LoRA），這是一種新的參數高效微調（PEFT）方法，它通過優化的張量訓練（TT）分解整合擴展了 LoRETTA。通過消除適配器和傳統的基於 LoRA 的結構，TT-LoRA 在不影響下游任務性能的情況下實現了更大的模型壓縮，同時降低了推理延遲和運算開銷。我們進行了詳盡的參數搜索，以建立基準，突顯模型壓縮和性能之間的權衡。我們的結果表明，LLM 的壓縮顯著，同時保持與較大模型相當的性能，促進它們在資源約束平台上的部署。

##### **Enhancing Financial Market Predictions: Causality-Driven Feature Selection**
2408.01005v1 by Wenhao Liang, Zhengyang Li, Weitong Chen

This paper introduces the FinSen dataset that revolutionizes financial market
analysis by integrating economic and financial news articles from 197 countries
with stock market data. The dataset's extensive coverage spans 15 years from
2007 to 2023 with temporal information, offering a rich, global perspective
with 160,000 records on financial market news. Our study leverages causally
validated sentiment scores and LSTM models to enhance market forecast accuracy
and reliability. Utilizing the FinSen dataset, we introduce an innovative Focal
Calibration Loss, reducing Expected Calibration Error (ECE) to 3.34 percent
with the DAN 3 model. This not only improves prediction accuracy but also
aligns probabilistic forecasts closely with real outcomes, crucial for the
financial sector where predicted probability is paramount. Our approach
demonstrates the effectiveness of combining sentiment analysis with precise
calibration techniques for trustworthy financial forecasting where the cost of
misinterpretation can be high. Finsen Data can be found at [this github
URL](https://github.com/EagleAdelaide/FinSen_Dataset.git).

摘要：本文介绍了 FinSen 数据集，该数据集通过整合来自 197 个国家的经济和金融新闻文章以及股票市场数据，彻底改变了金融市场分析。该数据集的广泛覆盖范围跨越了 2007 年至 2023 年的 15 年时间信息，提供了丰富的全球视角，包含 160,000 条金融市场新闻记录。我们的研究利用因果验证的情感评分和 LSTM 模型来提高市场预测的准确性和可靠性。利用 FinSen 数据集，我们引入了一种创新的焦点校准损失，将 DAN 3 模型的预期校准误差 (ECE) 降低至 3.34%。这不仅提高了预测准确性，还使概率预测与实际结果紧密一致，这对预测概率至关重要的金融领域至关重要。我们的方法证明了将情感分析与精确校准技术相结合对于可信的财务预测的有效性，而财务预测中误解的成本可能很高。Finsen 数据可以在 [此 github URL](https://github.com/EagleAdelaide/FinSen_Dataset.git) 中找到。

##### **Piculet: Specialized Models-Guided Hallucination Decrease for MultiModal Large Language Models**
2408.01003v1 by Kohou Wang, Xiang Liu, Zhaoxiang Liu, Kai Wang, Shiguo Lian

Multimodal Large Language Models (MLLMs) have made significant progress in
bridging the gap between visual and language modalities. However,
hallucinations in MLLMs, where the generated text does not align with image
content, continue to be a major challenge. Existing methods for addressing
hallucinations often rely on instruction-tuning, which requires retraining the
model with specific data, which increases the cost of utilizing MLLMs further.
In this paper, we introduce a novel training-free method, named Piculet, for
enhancing the input representation of MLLMs. Piculet leverages multiple
specialized models to extract descriptions of visual information from the input
image and combine these descriptions with the original image and query as input
to the MLLM. We evaluate our method both quantitively and qualitatively, and
the results demonstrate that Piculet greatly decreases hallucinations of MLLMs.
Our method can be easily extended to different MLLMs while being universal.

摘要：多模態大型語言模型 (MLLM) 在彌合視覺與語言模式之間的差距方面取得了顯著進展。然而，MLLM 中的幻覺，即生成的文字與影像內容不符，仍然是一項重大挑戰。現有解決幻覺的方法通常依賴於指令微調，這需要使用特定資料重新訓練模型，這進一步增加了使用 MLLM 的成本。在本文中，我們介紹了一種新的免訓練方法，稱為 Piculet，用於增強 MLLM 的輸入表示。Piculet 利用多個專業模型從輸入影像中提取視覺資訊的描述，並將這些描述與原始影像和查詢結合作為輸入提供給 MLLM。我們對方法進行了量化和質化評估，結果表明 Piculet 大大減少了 MLLM 的幻覺。我們的這種方法可以輕鬆地擴展到不同的 MLLM，同時具有通用性。

##### **FBSDiff: Plug-and-Play Frequency Band Substitution of Diffusion Features for Highly Controllable Text-Driven Image Translation**
2408.00998v1 by Xiang Gao, Jiaying Liu

Large-scale text-to-image diffusion models have been a revolutionary
milestone in the evolution of generative AI and multimodal technology, allowing
extraordinary image generation based on natural-language text prompts. However,
the issue of lacking controllability of such models restricts their practical
applicability for real-life content creation, for which attention has been
focused on leveraging a reference image to control text-to-image synthesis. Due
to the close correlation between the reference image and the generated image,
this problem can also be regarded as the task of manipulating (or editing) the
reference image as per the text, namely text-driven image-to-image translation.
This paper contributes a novel, concise, and efficient approach that adapts the
pre-trained large-scale text-to-image (T2I) diffusion model to the
image-to-image (I2I) paradigm in a plug-and-play manner, realizing high-quality
and versatile text-driven I2I translation without any model training, model
fine-tuning, or online optimization process. To guide T2I generation with a
reference image, we propose to model diverse guiding factors with
correspondingly different frequency bands of diffusion features in the DCT
spectral space, and accordingly devise a novel frequency band substitution
layer that dynamically substitutes a certain DCT frequency band of the
diffusion features with the corresponding counterpart of the reference image
along the reverse sampling process. We demonstrate that our method flexibly
enables highly controllable text-driven I2I translation both in the guiding
factor and guiding intensity of the reference image, simply by tuning the type
and bandwidth of the substituted frequency band, respectively. Extensive
qualitative and quantitative experiments verify the superiority of our approach
over related methods in I2I translation visual quality, versatility, and
controllability.

摘要：<paragraph>大型文本到图像扩散模型是生成式人工智能和多模态技术演进中的一项革命性里程碑，它允许基于自然语言文本提示生成非凡的图像。然而，此类模型缺乏可控性的问题限制了它们在现实生活中的内容创作中的实际适用性，而对此，人们将注意力集中在利用参考图像来控制文本到图像合成上。由于参考图像和生成图像之间的密切相关性，这个问题也可以看作是根据文本操纵（或编辑）参考图像的任务，即文本驱动的图像到图像转换。本文贡献了一种新颖、简洁且高效的方法，该方法以即插即用的方式将预训练的大型文本到图像 (T2I) 扩散模型调整到图像到图像 (I2I) 范式，从而实现高质量且通用的文本驱动的 I2I 转换，而无需任何模型训练、模型微调或在线优化过程。为了用参考图像指导 T2I 生成，我们提出用 DCT 谱空间中扩散特征的对应不同频带对不同的引导因子进行建模，并相应地设计了一个新颖的频带替换层，该层在反向采样过程中用参考图像的对应部分动态替换扩散特征的某个 DCT 频带。我们证明了我们的方法可以通过分别调整替换频带的类型和带宽，灵活地实现对参考图像的引导因子和引导强度的可高度控制的文本驱动的 I2I 转换。广泛的定性和定量实验验证了我们的方法在 I2I 转换视觉质量、多功能性和可控性方面优于相关方法。</paragraph>

##### **A Safe Exploration Strategy for Model-free Task Adaptation in Safety-constrained Grid Environments**
2408.00997v1 by Erfan Entezami, Mahsa Sahebdel, Dhawal Gupta

Training a model-free reinforcement learning agent requires allowing the
agent to sufficiently explore the environment to search for an optimal policy.
In safety-constrained environments, utilizing unsupervised exploration or a
non-optimal policy may lead the agent to undesirable states, resulting in
outcomes that are potentially costly or hazardous for both the agent and the
environment. In this paper, we introduce a new exploration framework for
navigating the grid environments that enables model-free agents to interact
with the environment while adhering to safety constraints. Our framework
includes a pre-training phase, during which the agent learns to identify
potentially unsafe states based on both observable features and specified
safety constraints in the environment. Subsequently, a binary classification
model is trained to predict those unsafe states in new environments that
exhibit similar dynamics. This trained classifier empowers model-free agents to
determine situations in which employing random exploration or a suboptimal
policy may pose safety risks, in which case our framework prompts the agent to
follow a predefined safe policy to mitigate the potential for hazardous
consequences. We evaluated our framework on three randomly generated grid
environments and demonstrated how model-free agents can safely adapt to new
tasks and learn optimal policies for new environments. Our results indicate
that by defining an appropriate safe policy and utilizing a well-trained model
to detect unsafe states, our framework enables a model-free agent to adapt to
new tasks and environments with significantly fewer safety violations.

摘要：訓練無模型強化學習代理人需要允許代理人充分探索環境以搜尋最佳策略。在安全受限的環境中，利用非監督式探索或非最佳策略可能會導致代理人進入不良狀態，造成對代理人和環境都有潛在代價或危險的後果。在本文中，我們介紹了一個新的探索架構，用於導航網格環境，讓無模型代理人能夠與環境互動，同時遵守安全限制。我們的架構包含一個預訓練階段，在該階段中，代理人會學習根據可觀察特徵和環境中指定的安全性限制來識別潛在不安全的狀態。隨後，訓練一個二進位分類模型來預測在具有類似動態的新環境中的那些不安全狀態。這個訓練好的分類器讓無模型代理人能夠判斷在哪些情況下採用隨機探索或次最佳策略可能會構成安全風險，在這種情況下，我們的架構會提示代理人遵循預定義的安全策略來減輕潛在的危險後果。我們在三個隨機生成的網格環境中評估了我們的架構，並展示了無模型代理人如何安全地適應新任務並學習新環境的最佳策略。我們的結果表明，通過定義適當的安全策略並利用訓練良好的模型來偵測不安全狀態，我們的架構讓無模型代理人能夠適應新任務和環境，而且大幅減少安全違規。

##### **IncidentNet: Traffic Incident Detection, Localization and Severity Estimation with Sparse Sensing**
2408.00996v1 by Sai Shashank Peddiraju, Kaustubh Harapanahalli, Edward Andert, Aviral Shrivastava

Prior art in traffic incident detection relies on high sensor coverage and is
primarily based on decision-tree and random forest models that have limited
representation capacity and, as a result, cannot detect incidents with high
accuracy. This paper presents IncidentNet - a novel approach for classifying,
localizing, and estimating the severity of traffic incidents using deep
learning models trained on data captured from sparsely placed sensors in urban
environments. Our model works on microscopic traffic data that can be collected
using cameras installed at traffic intersections. Due to the unavailability of
datasets that provide microscopic traffic details and traffic incident details
simultaneously, we also present a methodology to generate a synthetic
microscopic traffic dataset that matches given macroscopic traffic data.
IncidentNet achieves a traffic incident detection rate of 98%, with false alarm
rates of less than 7% in 197 seconds on average in urban environments with
cameras on less than 20% of the traffic intersections.

摘要：先前的交通事故检测技术仰赖高传感器覆盖率，主要基于决策树和随机森林模型，其表示能力有限，因此无法以高准确度检测事故。本文提出 IncidentNet，一种使用深度学习模型对城市环境中稀疏放置的传感器所撷取的数据进行训练，以对交通事故进行分类、定位和估计严重程度的新颖方法。我们的模型处理可使用安装在交通路口摄像机所收集的微观交通数据。由于没有同时提供微观交通详细信息和交通事故详细信息的数据集，我们也提出一种方法来生成与给定的宏观交通数据相符的合成微观交通数据集。IncidentNet 在交通路口摄像机覆盖率不到 20% 的城市环境中，以平均 197 秒的时间，实现了 98% 的交通事故检测率，误报率低于 7%。

##### **ArchCode: Incorporating Software Requirements in Code Generation with Large Language Models**
2408.00994v1 by Hojae Han, Jaejin Kim, Jaeseok Yoo, Youngwon Lee, Seung-won Hwang

This paper aims to extend the code generation capability of large language
models (LLMs) to automatically manage comprehensive software requirements from
given textual descriptions. Such requirements include both functional (i.e.
achieving expected behavior for inputs) and non-functional (e.g., time/space
performance, robustness, maintainability) requirements. However, textual
descriptions can either express requirements verbosely or may even omit some of
them. We introduce ARCHCODE, a novel framework that leverages in-context
learning to organize requirements observed in descriptions and to extrapolate
unexpressed requirements from them. ARCHCODE generates requirements from given
descriptions, conditioning them to produce code snippets and test cases. Each
test case is tailored to one of the requirements, allowing for the ranking of
code snippets based on the compliance of their execution results with the
requirements. Public benchmarks show that ARCHCODE enhances to satisfy
functional requirements, significantly improving Pass@k scores. Furthermore, we
introduce HumanEval-NFR, the first evaluation of LLMs' non-functional
requirements in code generation, demonstrating ARCHCODE's superiority over
baseline methods. The implementation of ARCHCODE and the HumanEval-NFR
benchmark are both publicly accessible.

摘要：本文旨在擴展大型語言模型 (LLM) 的程式碼生成能力，以自動管理從給定的文字描述中得出的全面軟體需求。此類需求包括功能性（即達成輸入的預期行為）和非功能性（例如時間/空間效能、穩健性、可維護性）需求。然而，文字描述可能會冗長地表達需求，甚至可能省略其中一些需求。我們引進 ARCHCODE，一個創新的架構，它利用情境學習來組織在描述中觀察到的需求，並從中推斷未表達的需求。ARCHCODE 從給定的描述中產生需求，調整它們以產生程式碼片段和測試案例。每個測試案例都針對其中一個需求量身打造，允許根據程式碼片段執行結果是否符合需求來對程式碼片段進行排名。公開基準測試顯示，ARCHCODE 增強了滿足功能性需求的能力，大幅提升了 Pass@k 分數。此外，我們引進 HumanEval-NFR，這是第一個評估 LLM 在程式碼生成中的非功能性需求，證明了 ARCHCODE 優於基準方法。ARCHCODE 的實作和 HumanEval-NFR 基準測試都公開提供。

##### **Fairness in Large Language Models in Three Hour**
2408.00992v1 by Thang Doan Viet, Zichong Wang, Minh Nhat Nguyen, Wenbin Zhang

Large Language Models (LLMs) have demonstrated remarkable success across
various domains but often lack fairness considerations, potentially leading to
discriminatory outcomes against marginalized populations. Unlike fairness in
traditional machine learning, fairness in LLMs involves unique backgrounds,
taxonomies, and fulfillment techniques. This tutorial provides a systematic
overview of recent advances in the literature concerning fair LLMs, beginning
with real-world case studies to introduce LLMs, followed by an analysis of bias
causes therein. The concept of fairness in LLMs is then explored, summarizing
the strategies for evaluating bias and the algorithms designed to promote
fairness. Additionally, resources for assessing bias in LLMs, including
toolkits and datasets, are compiled, and current research challenges and open
questions in the field are discussed. The repository is available at
\url{https://github.com/LavinWong/Fairness-in-Large-Language-Models}.

摘要：大型語言模型 (LLM) 已在各種領域展現出顯著的成功，但往往缺乏公平性的考量，可能導致對弱勢群體產生歧視性的結果。與傳統機器學習中的公平性不同，LLM 中的公平性涉及獨特的背景、分類法和實踐技巧。本教學課程系統性地概述了關於公平 LLM 的文獻中的最新進展，從實際案例研究開始介紹 LLM，然後分析其中的偏差原因。接著探討 LLM 中公平性的概念，總結評估偏差的策略和促進公平性的演算法。此外，編制了評估 LLM 中偏差的資源，包括工具包和資料集，並討論了該領域目前的研究挑戰和開放性問題。資源庫可在\url{https://github.com/LavinWong/Fairness-in-Large-Language-Models}取得。

##### **On the Resilience of Multi-Agent Systems with Malicious Agents**
2408.00989v1 by Jen-tse Huang, Jiaxu Zhou, Tailin Jin, Xuhui Zhou, Zixi Chen, Wenxuan Wang, Youliang Yuan, Maarten Sap, Michael R. Lyu

Multi-agent systems, powered by large language models, have shown great
abilities across various tasks due to the collaboration of expert agents, each
focusing on a specific domain. However, when agents are deployed separately,
there is a risk that malicious users may introduce malicious agents who
generate incorrect or irrelevant results that are too stealthy to be identified
by other non-specialized agents. Therefore, this paper investigates two
essential questions: (1) What is the resilience of various multi-agent system
structures (e.g., A$\rightarrow$B$\rightarrow$C,
A$\leftrightarrow$B$\leftrightarrow$C) under malicious agents, on different
downstream tasks? (2) How can we increase system resilience to defend against
malicious agents? To simulate malicious agents, we devise two methods,
AutoTransform and AutoInject, to transform any agent into a malicious one while
preserving its functional integrity. We run comprehensive experiments on four
downstream multi-agent systems tasks, namely code generation, math problems,
translation, and text evaluation. Results suggest that the "hierarchical"
multi-agent structure, i.e., A$\rightarrow$(B$\leftrightarrow$C), exhibits
superior resilience with the lowest performance drop of $23.6\%$, compared to
$46.4\%$ and $49.8\%$ of other two structures. Additionally, we show the
promise of improving multi-agent system resilience by demonstrating that two
defense methods, introducing an additional agent to review and correct messages
or mechanisms for each agent to challenge others' outputs, can enhance system
resilience. Our code and data are available at
https://github.com/CUHK-ARISE/MAS-Resilience.

摘要：<paragraph>多代理系統由大型語言模型驅動，由於專家代理的協作，每個代理專注於特定領域，因此在各種任務中展現出極佳的能力。然而，當代理分別部署時，存在惡意使用者可能引入惡意代理的風險，這些代理會產生不正確或不相關的結果，而這些結果隱蔽到無法被其他非專業代理識別。因此，本文探討兩個基本問題：(1) 在不同的下游任務中，各種多代理系統結構（例如，A→B→C，A↔B↔C）對惡意代理的韌性為何？(2) 我們如何提高系統韌性以抵禦惡意代理？為了模擬惡意代理，我們設計了兩種方法，AutoTransform 和 AutoInject，將任何代理轉換為惡意代理，同時保留其功能完整性。我們對四種下游多代理系統任務執行全面實驗，即程式碼生成、數學問題、翻譯和文字評估。結果表明，「階層式」多代理結構，即 A→(B↔C)，表現出優異的韌性，效能下降最低為 23.6%，而其他兩個結構的效能下降分別為 46.4% 和 49.8%。此外，我們展示了提高多代理系統韌性的前景，證明了兩種防禦方法，即引入額外的代理來檢閱和更正訊息，或讓每個代理挑戰其他代理輸出的機制，可以增強系統韌性。我們的程式碼和資料可在 https://github.com/CUHK-ARISE/MAS-Resilience 取得。</paragraph>

##### **A SAT-based approach to rigorous verification of Bayesian networks**
2408.00986v1 by Ignacy Stępka, Nicholas Gisolfi, Artur Dubrawski

Recent advancements in machine learning have accelerated its widespread
adoption across various real-world applications. However, in safety-critical
domains, the deployment of machine learning models is riddled with challenges
due to their complexity, lack of interpretability, and absence of formal
guarantees regarding their behavior. In this paper, we introduce a verification
framework tailored for Bayesian networks, designed to address these drawbacks.
Our framework comprises two key components: (1) a two-step compilation and
encoding scheme that translates Bayesian networks into Boolean logic literals,
and (2) formal verification queries that leverage these literals to verify
various properties encoded as constraints. Specifically, we introduce two
verification queries: if-then rules (ITR) and feature monotonicity (FMO). We
benchmark the efficiency of our verification scheme and demonstrate its
practical utility in real-world scenarios.

摘要：機器學習的最新進展加速了其在各種實際應用中的廣泛採用。然而，在安全關鍵領域中，機器學習模型的部署充滿挑戰，因為它們的複雜性、缺乏可解釋性，以及缺乏關於它們行為的正式保證。在本文中，我們介紹了一個專門針對貝氏網路的驗證框架，旨在解決這些缺點。我們的框架包含兩個關鍵組成部分：(1) 將貝氏網路轉換為布林邏輯文字的兩步編譯和編碼方案，以及 (2) 利用這些文字驗證編碼為約束的各種屬性的正式驗證查詢。具體來說，我們介紹了兩個驗證查詢：如果-那麼規則 (ITR) 和特徵單調性 (FMO)。我們對驗證方案的效率進行基準測試，並展示了其在實際場景中的實際效用。

##### **Cross-domain Named Entity Recognition via Graph Matching**
2408.00981v1 by Junhao Zheng, Haibin Chen, Qianli Ma

Cross-domain NER is a practical yet challenging problem since the data
scarcity in the real-world scenario. A common practice is first to learn a NER
model in a rich-resource general domain and then adapt the model to specific
domains. Due to the mismatch problem between entity types across domains, the
wide knowledge in the general domain can not effectively transfer to the target
domain NER model. To this end, we model the label relationship as a probability
distribution and construct label graphs in both source and target label spaces.
To enhance the contextual representation with label structures, we fuse the
label graph into the word embedding output by BERT. By representing label
relationships as graphs, we formulate cross-domain NER as a graph matching
problem. Furthermore, the proposed method has good applicability with
pre-training methods and is potentially capable of other cross-domain
prediction tasks. Empirical results on four datasets show that our method
outperforms a series of transfer learning, multi-task learning, and few-shot
learning methods.

摘要：跨域命名實體辨識是一個實用但具有挑戰性的問題，因為在現實世界的場景中資料稀少。常見的做法是首先在豐富資源的通用領域中學習命名實體辨識模型，然後將模型調整到特定領域。由於跨領域的實體類型之間的不匹配問題，通用領域中的廣泛知識無法有效地轉移到目標領域的命名實體辨識模型。為此，我們將標籤關係建模為機率分佈，並在來源和目標標籤空間中建構標籤圖。為了使用標籤結構增強上下文表示，我們將標籤圖融合到 BERT 的字詞嵌入輸出中。透過將標籤關係表示為圖形，我們將跨域命名實體辨識制定為圖形配對問題。此外，所提出的方法對於預訓練方法具有良好的適用性，並且潛在地能夠執行其他跨域預測任務。在四個資料集上的經驗結果顯示，我們的模型優於一系列的遷移學習、多任務學習和少量學習方法。

##### **Automatic Extraction of Relationships among Motivations, Emotions and Actions from Natural Language Texts**
2408.00966v1 by Fei Yang

We propose a new graph-based framework to reveal relationships among
motivations, emotions and actions explicitly given natural language texts. A
directed acyclic graph is designed to describe human's nature. Nurture beliefs
are incorporated to connect outside events and the human's nature graph. No
annotation resources are required due to the power of large language models.
Amazon Fine Foods Reviews dataset is used as corpus and food-related
motivations are focused. Totally 92,990 relationship graphs are generated, of
which 63% make logical sense. We make further analysis to investigate error
types for optimization direction in future research.

摘要：我們提出一個新的基於圖形的架構，用於揭示在自然語言文本中明確給出的動機、情緒和動作之間的關係。有向無環圖被設計用於描述人類的本性。培養信念被納入其中，用於連接外部事件和人類的本性圖。由於大型語言模型的強大功能，不需要註解資源。亞馬遜美食評論數據集被用作語料庫，並且重點關注與食物相關的動機。總共生成了 92,990 個關係圖，其中 63% 具有邏輯意義。我們進一步分析以調查錯誤類型，以便為未來的研究提供優化方向。

##### **PERSOMA: PERsonalized SOft ProMpt Adapter Architecture for Personalized Language Prompting**
2408.00960v1 by Liam Hebert, Krishna Sayana, Ambarish Jash, Alexandros Karatzoglou, Sukhdeep Sodhi, Sumanth Doddapaneni, Yanli Cai, Dima Kuzmin

Understanding the nuances of a user's extensive interaction history is key to
building accurate and personalized natural language systems that can adapt to
evolving user preferences. To address this, we introduce PERSOMA, Personalized
Soft Prompt Adapter architecture. Unlike previous personalized prompting
methods for large language models, PERSOMA offers a novel approach to
efficiently capture user history. It achieves this by resampling and
compressing interactions as free form text into expressive soft prompt
embeddings, building upon recent research utilizing embedding representations
as input for LLMs. We rigorously validate our approach by evaluating various
adapter architectures, first-stage sampling strategies, parameter-efficient
tuning techniques like LoRA, and other personalization methods. Our results
demonstrate PERSOMA's superior ability to handle large and complex user
histories compared to existing embedding-based and text-prompt-based
techniques.

摘要：了解使用者廣泛互動歷程的細微差別，是建構精準且個人化的自然語言系統的關鍵，此系統能適應不斷變化的使用者偏好。為了解決這個問題，我們引進 PERSOMA，個人化的軟提示適配器架構。與大型語言模型先前的個人化提示方法不同，PERSOMA 提供一種新穎的方法來有效擷取使用者歷程。它透過重新取樣和壓縮互動，將其作為自由形式文字壓縮成表達式的軟提示嵌入，建構在最近利用嵌入式表徵作為 LLM 輸入的研究之上。我們透過評估各種適配器架構、第一階段取樣策略、參數有效率的調整技術（例如 LoRA）和其他個人化方法，嚴格驗證我們的做法。我們的結果證明，與現有的基於嵌入和基於文字提示的技術相比，PERSOMA 處理大型且複雜的使用者歷程的能力更為出色。

##### **Leveraging Large Language Models (LLMs) for Traffic Management at Urban Intersections: The Case of Mixed Traffic Scenarios**
2408.00948v1 by Sari Masri, Huthaifa I. Ashqar, Mohammed Elhenawy

Urban traffic management faces significant challenges due to the dynamic
environments, and traditional algorithms fail to quickly adapt to this
environment in real-time and predict possible conflicts. This study explores
the ability of a Large Language Model (LLM), specifically, GPT-4o-mini to
improve traffic management at urban intersections. We recruited GPT-4o-mini to
analyze, predict position, detect and resolve the conflicts at an intersection
in real-time for various basic scenarios. The key findings of this study to
investigate whether LLMs can logically reason and understand the scenarios to
enhance the traffic efficiency and safety by providing real-time analysis. The
study highlights the potential of LLMs in urban traffic management creating
more intelligent and more adaptive systems. Results showed the GPT-4o-mini was
effectively able to detect and resolve conflicts in heavy traffic, congestion,
and mixed-speed conditions. The complex scenario of multiple intersections with
obstacles and pedestrians saw successful conflict management as well. Results
show that the integration of LLMs promises to improve the effectiveness of
traffic control for safer and more efficient urban intersection management.

摘要：由於動態環境，城市交通管理面臨重大挑戰，傳統演算法無法在即時環境中快速適應並預測可能的衝突。本研究探討大型語言模型 (LLM)，特別是 GPT-4o-mini，在改善城市路口交通管理的能力。我們招募 GPT-4o-mini 來分析、預測位置、偵測和解決各種基本情境中路口的衝突。本研究的主要發現是調查 LLM 是否能透過提供即時分析來邏輯推理和了解情境，以提升交通效率和安全性。本研究強調了 LLM 在城市交通管理中創造更智慧、更具適應性的系統的潛力。結果顯示 GPT-4o-mini 能有效偵測並解決交通壅塞、擁擠和混合速度狀況下的衝突。具有障礙物和行人的多個路口的複雜情境也成功管理了衝突。結果顯示，整合 LLM 有望改善交通控制的有效性，以實現更安全、更有效率的城市路口管理。

##### **CIResDiff: A Clinically-Informed Residual Diffusion Model for Predicting Idiopathic Pulmonary Fibrosis Progression**
2408.00938v1 by Caiwen Jiang, Xiaodan Xing, Zaixin Ou, Mianxin Liu, Walsh Simon, Guang Yang, Dinggang Shen

The progression of Idiopathic Pulmonary Fibrosis (IPF) significantly
correlates with higher patient mortality rates. Early detection of IPF
progression is critical for initiating timely treatment, which can effectively
slow down the advancement of the disease. However, the current clinical
criteria define disease progression requiring two CT scans with a one-year
interval, presenting a dilemma: a disease progression is identified only after
the disease has already progressed. To this end, in this paper, we develop a
novel diffusion model to accurately predict the progression of IPF by
generating patient's follow-up CT scan from the initial CT scan. Specifically,
from the clinical prior knowledge, we tailor improvements to the traditional
diffusion model and propose a Clinically-Informed Residual Diffusion model,
called CIResDiff. The key innovations of CIResDiff include 1) performing the
target region pre-registration to align the lung regions of two CT scans at
different time points for reducing the generation difficulty, 2) adopting the
residual diffusion instead of traditional diffusion to enable the model focus
more on differences (i.e., lesions) between the two CT scans rather than the
largely identical anatomical content, and 3) designing the clinically-informed
process based on CLIP technology to integrate lung function information which
is highly relevant to diagnosis into the reverse process for assisting
generation. Extensive experiments on clinical data demonstrate that our
approach can outperform state-of-the-art methods and effectively predict the
progression of IPF.

摘要：特發性肺纖維化 (IPF) 的進程與較高的患者死亡率顯著相關。早期發現 IPF 進程對於及時開始治療至關重要，這可以有效減緩疾病的進展。然而，當前的臨床標準定義疾病進程需要兩次 CT 掃描，間隔一年，這提出了兩難：只有在疾病已經進展後才能識別出疾病進程。為此，在本文中，我們開發了一種新穎的擴散模型，通過從初始 CT 掃描生成患者的後續 CT 掃描，準確預測 IPF 的進程。具體來說，從臨床先驗知識中，我們調整了傳統擴散模型，並提出了稱為 CIResDiff 的臨床信息殘差擴散模型。CIResDiff 的關鍵創新包括 1) 執行目標區域預註冊，以對齊不同時間點的兩次 CT 掃描的肺部區域，以降低生成難度，2) 採用殘差擴散而不是傳統擴散，以使模型更多地關注兩次 CT 掃描之間的差異（即病灶）而不是在很大程度上相同的解剖內容，以及 3) 設計基於 CLIP 技術的臨床信息流程，以將與診斷高度相關的肺功能信息整合到反向過程中以協助生成。臨床數據的大量實驗表明，我們的做法可以優於最先進的方法，並有效預測 IPF 的進程。

##### **Towards Zero-Shot Annotation of the Built Environment with Vision-Language Models (Vision Paper)**
2408.00932v1 by Bin Han, Yiwei Yang, Anat Caspi, Bill Howe

Equitable urban transportation applications require high-fidelity digital
representations of the built environment: not just streets and sidewalks, but
bike lanes, marked and unmarked crossings, curb ramps and cuts, obstructions,
traffic signals, signage, street markings, potholes, and more. Direct
inspections and manual annotations are prohibitively expensive at scale.
Conventional machine learning methods require substantial annotated training
data for adequate performance. In this paper, we consider vision language
models as a mechanism for annotating diverse urban features from satellite
images, reducing the dependence on human annotation to produce large training
sets. While these models have achieved impressive results in describing common
objects in images captured from a human perspective, their training sets are
less likely to include strong signals for esoteric features in the built
environment, and their performance in these settings is therefore unclear. We
demonstrate proof-of-concept combining a state-of-the-art vision language model
and variants of a prompting strategy that asks the model to consider segmented
elements independently of the original image. Experiments on two urban features
-- stop lines and raised tables -- show that while direct zero-shot prompting
correctly annotates nearly zero images, the pre-segmentation strategies can
annotate images with near 40% intersection-over-union accuracy. We describe how
these results inform a new research agenda in automatic annotation of the built
environment to improve equity, accessibility, and safety at broad scale and in
diverse environments.

摘要：公平的城市交通應用程式需要高保真的數位化建成環境表示：不僅僅是街道和人行道，還有自行車道、標示和未標示的路口、路緣坡道和切口、障礙物、交通號誌、標誌、街道標線、坑洞等等。直接檢查和手動註解在規模上成本過於高昂。傳統的機器學習方法需要大量的註解訓練資料才能有足夠的效能。在本文中，我們將視覺語言模型視為一種從衛星影像中註解各種城市特徵的機制，減少對人工註解的依賴以產生大量的訓練集。儘管這些模型在描述從人類視角拍攝的影像中常見物體方面取得了令人印象深刻的成果，但其訓練集不太可能包含建成環境中深奧特徵的強訊號，因此它們在這些設定中的效能尚不清楚。我們展示了概念驗證，結合了最先進的視覺語言模型和提示策略的變體，要求模型獨立於原始影像考慮分割元素。在兩個城市特徵（停止線和高架桌面）上的實驗表明，雖然直接的零次提示正確註解了接近於零的影像，但預分割策略可以註解接近 40% 的交集聯集準確度的影像。我們描述了這些結果如何告知建成環境自動註解的新研究議程，以在廣泛規模和多樣化的環境中改善公平性、可及性和安全性。

##### **Enabling High Data Throughput Reinforcement Learning on GPUs: A Domain Agnostic Framework for Data-Driven Scientific Research**
2408.00930v1 by Tian Lan, Huan Wang, Caiming Xiong, Silvio Savarese

We introduce WarpSci, a domain agnostic framework designed to overcome
crucial system bottlenecks encountered in the application of reinforcement
learning to intricate environments with vast datasets featuring
high-dimensional observation or action spaces. Notably, our framework
eliminates the need for data transfer between the CPU and GPU, enabling the
concurrent execution of thousands of simulations on a single or multiple GPUs.
This high data throughput architecture proves particularly advantageous for
data-driven scientific research, where intricate environment models are
commonly essential.

摘要：我們推出 WarpSci，一個領域不可知論的架構，旨在克服在將強化學習應用於具有龐大資料集的複雜環境時遇到的關鍵系統瓶頸，這些資料集具有高維度觀察或動作空間。值得注意的是，我們的架構消除了 CPU 和 GPU 之間的資料傳輸需求，可以在單個或多個 GPU 上並行執行數千次模擬。這種高資料傳輸量架構被證明對資料驅動的科學研究特別有利，其中複雜的環境模型通常是必不可少的。

##### **WHITE PAPER: A Brief Exploration of Data Exfiltration using GCG Suffixes**
2408.00925v1 by Victor Valbuena

The cross-prompt injection attack (XPIA) is an effective technique that can
be used for data exfiltration, and that has seen increasing use. In this
attack, the attacker injects a malicious instruction into third party data
which an LLM is likely to consume when assisting a user, who is the victim.
XPIA is often used as a means for data exfiltration, and the estimated cost of
the average data breach for a business is nearly $4.5 million, which includes
breaches such as compromised enterprise credentials. With the rise of
gradient-based attacks such as the GCG suffix attack, the odds of an XPIA
occurring which uses a GCG suffix are worryingly high. As part of my work in
Microsoft's AI Red Team, I demonstrated a viable attack model using a GCG
suffix paired with an injection in a simulated XPIA scenario. The results
indicate that the presence of a GCG suffix can increase the odds of successful
data exfiltration by nearly 20%, with some caveats.

摘要：跨提示注入攻击 (XPIA) 是一种有效技术，可用于数据泄露，并且使用量不断增加。在这次攻击中，攻击者向第三方数据中注入恶意指令，而 LLM 在协助受害者用户时可能会使用该指令。XPIA 通常用作数据泄露的手段，而企业数据泄露的平均成本估计接近 450 万美元，其中包括泄露的企业凭证。随着基于梯度的攻击（如 GCG 后缀攻击）的兴起，发生使用 GCG 后缀的 XPIA 的几率令人担忧地高。作为我在 Microsoft AI 红队的部分工作，我展示了一个可行的攻击模型，该模型使用 GCG 后缀与模拟 XPIA 场景中的注入配对。结果表明，GCG 后缀的存在可以将成功数据泄露的几率提高近 20%，但有一些警告。

##### **Reclaiming Residual Knowledge: A Novel Paradigm to Low-Bit Quantization**
2408.00923v1 by Róisín Luo, Alexandru Drimbarean, James McDermott, Colm O'Riordan

This paper explores a novel paradigm in low-bit (i.e. 4-bits or lower)
quantization, differing from existing state-of-the-art methods, by framing
optimal quantization as an architecture search problem within convolutional
neural networks (ConvNets). Our framework, dubbed \textbf{CoRa} (Optimal
Quantization Residual \textbf{Co}nvolutional Operator Low-\textbf{Ra}nk
Adaptation), is motivated by two key aspects. Firstly, quantization residual
knowledge, i.e. the lost information between floating-point weights and
quantized weights, has long been neglected by the research community.
Reclaiming the critical residual knowledge, with an infinitesimal extra
parameter cost, can reverse performance degradation without training. Secondly,
state-of-the-art quantization frameworks search for optimal quantized weights
to address the performance degradation. Yet, the vast search spaces in weight
optimization pose a challenge for the efficient optimization in large models.
For example, state-of-the-art BRECQ necessitates $2 \times 10^4$ iterations to
quantize models. Fundamentally differing from existing methods, \textbf{CoRa}
searches for the optimal architectures of low-rank adapters, reclaiming
critical quantization residual knowledge, within the search spaces smaller
compared to the weight spaces, by many orders of magnitude. The low-rank
adapters approximate the quantization residual weights, discarded in previous
methods. We evaluate our approach over multiple pre-trained ConvNets on
ImageNet. \textbf{CoRa} achieves comparable performance against both
state-of-the-art quantization-aware training and post-training quantization
baselines, in $4$-bit and $3$-bit quantization, by using less than $250$
iterations on a small calibration set with $1600$ images. Thus, \textbf{CoRa}
establishes a new state-of-the-art in terms of the optimization efficiency in
low-bit quantization.

摘要：<paragraph>本文探討低位元（即 4 位元或更低）量化中的一種新模式，它不同於現有的最先進方法，而是將最佳量化設定為卷積神經網路（ConvNets）中的架構搜尋問題。我們的框架稱為 \textbf{CoRa}（最佳量化殘差\textbf{Co}nvolutional 算子低\textbf{Ra}nk 適應），其動機來自兩個關鍵方面。首先，量化殘差知識，即浮點權重和量化權重之間的遺失資訊，長期以來一直被研究社群所忽視。以極小的額外參數成本回收重要的殘差知識，可以在不進行訓練的情況下扭轉效能下降。其次，最先進的量化框架會搜尋最佳量化權重來解決效能下降問題。然而，權重最佳化中的龐大搜尋空間對大型模型中的有效最佳化構成挑戰。例如，最先進的 BRECQ 需要 $2 \times 10^4$ 次反覆運算才能量化模型。與現有方法有根本上的不同，\textbf{CoRa} 會搜尋低秩適配器的最佳架構，回收重要的量化殘差知識，在與權重空間相比小很多個數量級的搜尋空間中。低秩適配器近似於量化殘差權重，這在先前的模型中會被捨棄。我們針對 ImageNet 上的數個預先訓練的 ConvNets 評估我們的做法。\textbf{CoRa} 在 4 位元和 3 位元量化中，使用小於 $250$ 次反覆運算，在一個包含 $1600$ 張影像的小校正集合上，達到與最先進的量化感知訓練和訓練後量化基準相當的效能。因此，\textbf{CoRa} 在低位元量化的最佳化效率方面樹立了新的最先進標準。</paragraph>

##### **Automatic Pull Request Description Generation Using LLMs: A T5 Model Approach**
2408.00921v1 by Md Nazmus Sakib, Md Athikul Islam, Md Mashrur Arifin

Developers create pull request (PR) descriptions to provide an overview of
their changes and explain the motivations behind them. These descriptions help
reviewers and fellow developers quickly understand the updates. Despite their
importance, some developers omit these descriptions. To tackle this problem, we
propose an automated method for generating PR descriptions based on commit
messages and source code comments. This method frames the task as a text
summarization problem, for which we utilized the T5 text-to-text transfer
model. We fine-tuned a pre-trained T5 model using a dataset containing 33,466
PRs. The model's effectiveness was assessed using ROUGE metrics, which are
recognized for their strong alignment with human evaluations. Our findings
reveal that the T5 model significantly outperforms LexRank, which served as our
baseline for comparison.

摘要：開發人員建立拉取請求 (PR) 說明，提供變更的概觀並說明背後的動機。這些說明有助於審查者和開發人員夥伴快速了解更新。儘管它們很重要，但有些開發人員會省略這些說明。為了解決這個問題，我們提出一個自動化方法，根據提交訊息和原始碼註解產生 PR 說明。此方法將任務設定為一個文字摘要問題，我們為此利用了 T5 文字到文字轉移模型。我們使用包含 33,466 個 PR 的資料集微調預訓練的 T5 模型。模型的有效性是使用 ROUGE 指標進行評估的，這些指標因與人類評估的高度一致性而受到認可。我們的研究結果顯示，T5 模型顯著優於 LexRank，而 LexRank 是我們用於比較的基準。

##### **Granting GPT-4 License and Opportunity: Enhancing Accuracy and Confidence Estimation for Few-Shot Event Detection**
2408.00914v1 by Steven Fincke, Adrien Bibal, Elizabeth Boschee

Large Language Models (LLMs) such as GPT-4 have shown enough promise in the
few-shot learning context to suggest use in the generation of "silver" data and
refinement of new ontologies through iterative application and review. Such
workflows become more effective with reliable confidence estimation.
Unfortunately, confidence estimation is a documented weakness of models such as
GPT-4, and established methods to compensate require significant additional
complexity and computation. The present effort explores methods for effective
confidence estimation with GPT-4 with few-shot learning for event detection in
the BETTER ontology as a vehicle. The key innovation is expanding the prompt
and task presented to GPT-4 to provide License to speculate when unsure and
Opportunity to quantify and explain its uncertainty (L&O). This approach
improves accuracy and provides usable confidence measures (0.759 AUC) with no
additional machinery.

摘要：大型語言模型（LLM），例如 GPT-4，在小樣本學習情境中已展現足夠的潛力，建議用於產生「銀」數據，並透過反覆應用和檢視來改進新的本體論。此類工作流程會隨著可靠的信心估計而變得更有效。遺憾的是，信心估計是 GPT-4 等模型的已記錄弱點，而補償已建立方法需要大量額外的複雜性和運算。目前的努力探索了使用 GPT-4 進行有效信心估計的方法，以事件偵測為載具，在 BETTER 本體論中進行小樣本學習。關鍵創新是擴展提示和任務，提供給 GPT-4，以便在不確定時獲得推測許可，並有機會量化和解釋其不確定性（L&O）。此方法可提升準確度，並提供可用的信心測量（0.759 AUC），而無需額外機制。

##### **Parkinson's Disease Detection from Resting State EEG using Multi-Head Graph Structure Learning with Gradient Weighted Graph Attention Explanations**
2408.00906v1 by Christopher Neves, Yong Zeng, Yiming Xiao

Parkinson's disease (PD) is a debilitating neurodegenerative disease that has
severe impacts on an individual's quality of life. Compared with structural and
functional MRI-based biomarkers for the disease, electroencephalography (EEG)
can provide more accessible alternatives for clinical insights. While deep
learning (DL) techniques have provided excellent outcomes, many techniques fail
to model spatial information and dynamic brain connectivity, and face
challenges in robust feature learning, limited data sizes, and poor
explainability. To address these issues, we proposed a novel graph neural
network (GNN) technique for explainable PD detection using resting state EEG.
Specifically, we employ structured global convolutions with contrastive
learning to better model complex features with limited data, a novel multi-head
graph structure learner to capture the non-Euclidean structure of EEG data, and
a head-wise gradient-weighted graph attention explainer to offer neural
connectivity insights. We developed and evaluated our method using the UC San
Diego Parkinson's disease EEG dataset, and achieved 69.40% detection accuracy
in subject-wise leave-one-out cross-validation while generating intuitive
explanations for the learnt graph topology.

摘要：帕金森氏症（PD）是一种衰弱性神经退行性疾病，对个人的生活质量有严重影响。与用于该疾病的结构性和功能性 MRI 生物标记物相比，脑电图 (EEG) 可以提供更易于获取的临床见解替代方案。虽然深度学习 (DL) 技术提供了卓越的结果，但许多技术未能对空间信息和动态大脑连接进行建模，并且在稳健特征学习、有限的数据大小和较差的可解释性方面面临挑战。为了解决这些问题，我们提出了一种新颖的图神经网络 (GNN) 技术，用于使用静息状态脑电图进行可解释的 PD 检测。具体而言，我们采用具有对比学习的结构化全局卷积来更好地对具有有限数据的复杂特征进行建模，采用新颖的多头图结构学习器来捕获脑电图数据的非欧几里得结构，以及采用头权重梯度图注意解释器来提供神经连接见解。我们使用加州大学圣地亚哥分校帕金森氏症脑电图数据集开发并评估了我们的方法，并在按受试者留一法交叉验证中实现了 69.40% 的检测准确率，同时为学习到的图拓扑生成直观的解释。

##### **Expressive MIDI-format Piano Performance Generation**
2408.00900v1 by Jingwei Liu

This work presents a generative neural network that's able to generate
expressive piano performance in MIDI format. The musical expressivity is
reflected by vivid micro-timing, rich polyphonic texture, varied dynamics, and
the sustain pedal effects. This model is innovative from many aspects of data
processing to neural network design. We claim that this symbolic music
generation model overcame the common critics of symbolic music and is able to
generate expressive music flows as good as, if not better than generations with
raw audio. One drawback is that, due to the limited time for submission, the
model is not fine-tuned and sufficiently trained, thus the generation may sound
incoherent and random at certain points. Despite that, this model shows its
powerful generative ability to generate expressive piano pieces.

摘要：本研究提出了一種生成式神經網路，能夠生成 MIDI 格式的富有表現力的鋼琴演奏。這種音樂表現力反映在生動的微時序、豐富的複音織體、多變的動態以及延音踏板效果中。此模型從資料處理到神經網路設計的許多方面都具有創新性。我們聲稱，這種符號音樂生成模型克服了符號音樂的常見批評，並且能夠生成表現力豐富的音樂流，與使用原始音訊生成的音樂一樣好，甚至更好。一個缺點是，由於提交時間有限，該模型沒有經過微調和充分訓練，因此生成在某些點可能聽起來不連貫且隨機。儘管如此，此模型展示了其生成富有表現力的鋼琴曲目的強大生成能力。

##### **Hybrid Querying Over Relational Databases and Large Language Models**
2408.00884v1 by Fuheng Zhao, Divyakant Agrawal, Amr El Abbadi

Database queries traditionally operate under the closed-world assumption,
providing no answers to questions that require information beyond the data
stored in the database. Hybrid querying using SQL offers an alternative by
integrating relational databases with large language models (LLMs) to answer
beyond-database questions. In this paper, we present the first cross-domain
benchmark, SWAN, containing 120 beyond-database questions over four real-world
databases. To leverage state-of-the-art language models in addressing these
complex questions in SWAN, we present, HQDL, a preliminary solution for hybrid
querying, and also discuss potential future directions. Our evaluation
demonstrates that HQDL using GPT-4 Turbo with few-shot prompts, achieves 40.0\%
in execution accuracy and 48.2\% in data factuality. These results highlights
both the potential and challenges for hybrid querying. We believe that our work
will inspire further research in creating more efficient and accurate data
systems that seamlessly integrate relational databases and large language
models to address beyond-database questions.

摘要：傳統上，資料庫查詢是在封閉世界的假設下運作，對於需要資料庫中儲存資料以外的資訊的問題不提供答案。使用 SQL 的混合查詢提供了一種替代方案，透過整合關聯式資料庫和大型語言模型 (LLM) 來回答資料庫以外的問題。在本文中，我們提出了第一個跨領域基準 SWAN，其中包含 120 個針對四個真實世界資料庫的資料庫以外的問題。為了在 SWAN 中利用最先進的語言模型來解決這些複雜問題，我們提出了 HQDL，一種混合查詢的初步解決方案，並討論了潛在的未來方向。我們的評估表明，使用 GPT-4 Turbo 搭配少次提示的 HQDL，在執行準確度上達到 40.0%，在資料真實性上達到 48.2%。這些結果突顯了混合查詢的潛力與挑戰。我們相信，我們的研究將激勵進一步的研究，以建立更有效率、更準確的資料系統，無縫整合關聯式資料庫和大型語言模型，以回答資料庫以外的問題。

##### **On the Relationship Between Monotone and Squared Probabilistic Circuits**
2408.00876v1 by Benjie Wang, Guy Van den Broeck

Probabilistic circuits are a unifying representation of functions as
computation graphs of weighted sums and products. Their primary application is
in probabilistic modeling, where circuits with non-negative weights (monotone
circuits) can be used to represent and learn density/mass functions, with
tractable marginal inference. Recently, it was proposed to instead represent
densities as the square of the circuit function (squared circuits); this allows
the use of negative weights while retaining tractability, and can be
exponentially more compact than monotone circuits. Unfortunately, we show the
reverse also holds, meaning that monotone circuits and squared circuits are
incomparable in general. This raises the question of whether we can reconcile,
and indeed improve upon the two modeling approaches. We answer in the positive
by proposing InceptionPCs, a novel type of circuit that naturally encompasses
both monotone circuits and squared circuits as special cases, and employs
complex parameters. Empirically, we validate that InceptionPCs can outperform
both monotone and squared circuits on image datasets.

摘要：機率電路是函數的統一表示形式，作為加權總和和乘積的計算圖表。它們的主要應用在機率建模，其中具有非負權重（單調電路）的電路可用於表示和學習密度/質量函數，並具有可處理的邊際推論。最近，有人提出改用電路函數的平方來表示密度（平方電路）；這允許使用負權重，同時保持可處理性，並且可以比單調電路更緊湊。遺憾的是，我們表明反之亦然，也就是說，單調電路和平方電路通常無法相提並論。這引發了一個問題，我們是否可以調和，並確實改進這兩種建模方法。我們以提出 InceptionPC 來回答這個問題，InceptionPC 是一種新型電路，自然包含單調電路和平方電路作為特例，並採用複雜的參數。根據經驗，我們驗證 InceptionPC 在影像資料集上可以優於單調電路和平方電路。

##### **UniMoT: Unified Molecule-Text Language Model with Discrete Token Representation**
2408.00863v1 by Juzheng Zhang, Yatao Bian, Yongqiang Chen, Quanming Yao

The remarkable success of Large Language Models (LLMs) across diverse tasks
has driven the research community to extend their capabilities to molecular
applications. However, most molecular LLMs employ adapter-based architectures
that do not treat molecule and text modalities equally and lack a supervision
signal for the molecule modality. To address these issues, we introduce UniMoT,
a Unified Molecule-Text LLM adopting a tokenizer-based architecture that
expands the vocabulary of LLM with molecule tokens. Specifically, we introduce
a Vector Quantization-driven tokenizer that incorporates a Q-Former to bridge
the modality gap between molecule and text. This tokenizer transforms molecules
into sequences of molecule tokens with causal dependency, encapsulating
high-level molecular and textual information. Equipped with this tokenizer,
UniMoT can unify molecule and text modalities under a shared token
representation and an autoregressive training paradigm, enabling it to
interpret molecules as a foreign language and generate them as text. Following
a four-stage training scheme, UniMoT emerges as a multi-modal generalist
capable of performing both molecule-to-text and text-to-molecule tasks.
Extensive experiments demonstrate that UniMoT achieves state-of-the-art
performance across a wide range of molecule comprehension and generation tasks.

摘要：大型語言模型 (LLM) 在各種任務中取得顯著成功，驅使研究社群將其功能擴展到分子應用。然而，大多數分子 LLM 使用基於適配器的架構，並不平等對待分子和文字模式，且缺乏分子模式的監督訊號。為了解決這些問題，我們引入了 UniMoT，一種統一的分子文字 LLM，採用基於標記化的架構，將分子標記擴展到 LLM 的詞彙中。具體來說，我們引入了由向量量化驅動的標記化器，其中包含一個 Q-Former，用於彌合分子和文字之間的模式差距。這個標記化器將分子轉換成具有因果依賴關係的分子標記序列，封裝了高階分子和文字資訊。有了這個標記化器，UniMoT 可以統一分子和文字模式，在共享標記表示和自迴歸訓練範例下，使其能夠將分子解釋為外語並將其生成為文字。遵循四階段訓練計畫，UniMoT 成為一個多模式通才，能夠執行分子到文字和文字到分子任務。廣泛的實驗證明，UniMoT 在各種分子理解和生成任務中都達到了最先進的效能。

##### **UlRe-NeRF: 3D Ultrasound Imaging through Neural Rendering with Ultrasound Reflection Direction Parameterization**
2408.00860v1 by Ziwen Guo, Zi Fang, Zhuang Fu

Three-dimensional ultrasound imaging is a critical technology widely used in
medical diagnostics. However, traditional 3D ultrasound imaging methods have
limitations such as fixed resolution, low storage efficiency, and insufficient
contextual connectivity, leading to poor performance in handling complex
artifacts and reflection characteristics. Recently, techniques based on NeRF
(Neural Radiance Fields) have made significant progress in view synthesis and
3D reconstruction, but there remains a research gap in high-quality ultrasound
imaging. To address these issues, we propose a new model, UlRe-NeRF, which
combines implicit neural networks and explicit ultrasound volume rendering into
an ultrasound neural rendering architecture. This model incorporates reflection
direction parameterization and harmonic encoding, using a directional MLP
module to generate view-dependent high-frequency reflection intensity
estimates, and a spatial MLP module to produce the medium's physical property
parameters. These parameters are used in the volume rendering process to
accurately reproduce the propagation and reflection behavior of ultrasound
waves in the medium. Experimental results demonstrate that the UlRe-NeRF model
significantly enhances the realism and accuracy of high-fidelity ultrasound
image reconstruction, especially in handling complex medium structures.

摘要：三維超音波影像技術是一項廣泛用於醫療診斷的重要技術。然而，傳統的 3D 超音波影像方法有解析度固定、儲存效率低、上下文關聯性不足等限制，導致在處理複雜的偽影和反射特性時效能不佳。最近，基於 NeRF（神經輻照場）的技術在視圖合成和 3D 重建方面取得了重大進展，但在高品質超音波影像方面仍存在研究空白。為了解決這些問題，我們提出了一個新的模型 UlRe-NeRF，它將隱式神經網路和顯式超音波體積渲染結合到一個超音波神經渲染架構中。此模型結合了反射方向參數化和諧波編碼，使用方向性 MLP 模組來產生視圖依賴的高頻反射強度估計，並使用空間 MLP 模組來產生介質的物理屬性參數。這些參數用於體積渲染過程中，以準確重現超音波在介質中的傳播和反射行為。實驗結果表明，UlRe-NeRF 模型顯著增強了高保真超音波影像重建的真實性和準確性，特別是在處理複雜介質結構時。

##### **LICM: Effective and Efficient Long Interest Chain Modeling for News Recommendation**
2408.00859v1 by Zhen Yang, Wenhui Wang, Tao Qi, Peng Zhang, Tianyun Zhang, Ru Zhang, Jianyi Liu, Yongfeng Huang

Accurately recommending personalized candidate news articles to users has
always been the core challenge of news recommendation system. News
recommendations often require modeling of user interests to match candidate
news. Recent efforts have primarily focused on extract local subgraph
information, the lack of a comprehensive global news graph extraction has
hindered the ability to utilize global news information collaboratively among
similar users. To overcome these limitations, we propose an effective and
efficient Long Interest Chain Modeling for News Recommendation(LICM), which
combines neighbor interest with long-chain interest distilled from a global
news click graph based on the collaborative of similar users to enhance news
recommendation. For a global news graph based on the click history of all
users, long chain interest generated from it can better utilize the
high-dimensional information within it, enhancing the effectiveness of
collaborative recommendations. We therefore design a comprehensive selection
mechanism and interest encoder to obtain long-chain interest from the global
graph. Finally, we use a gated network to integrate long-chain information with
neighbor information to achieve the final user representation. Experiment
results on real-world datasets validate the effectiveness and efficiency of our
model to improve the performance of news recommendation.

摘要：準確推薦個人化候選新聞文章給使用者一直都是新聞推薦系統的核心挑戰。新聞推薦通常需要對使用者興趣進行建模，以匹配候選新聞。最近的研究工作主要集中在提取局部子圖資訊上，缺乏全面的全局新聞圖表提取阻礙了在相似使用者之間協作利用全局新聞資訊的能力。為了克服這些限制，我們提出了一種有效且高效的新聞推薦長興趣鏈建模（LICM），它結合了鄰近興趣與從基於相似使用者協作的全局新聞點擊圖表中提取的長鏈興趣，以增強新聞推薦。對於一個基於所有使用者點擊記錄的全局新聞圖表，從中產生的長鏈興趣可以更好地利用其中的高維資訊，增強協作推薦的有效性。因此，我們設計了一個全面的選擇機制和興趣編碼器，從全局圖表中獲取長鏈興趣。最後，我們使用一個門控網路將長鏈資訊與鄰近資訊整合，以獲得最終的使用者表徵。在真實世界資料集上的實驗結果驗證了我們模型的有效性和效率，以改善新聞推薦的效能。

##### **Calibrating Bayesian Generative Machine Learning for Bayesiamplification**
2408.00838v1 by Sebastian Bieringer, Sascha Diefenbacher, Gregor Kasieczka, Mathias Trabs

Recently, combinations of generative and Bayesian machine learning have been
introduced in particle physics for both fast detector simulation and inference
tasks. These neural networks aim to quantify the uncertainty on the generated
distribution originating from limited training statistics. The interpretation
of a distribution-wide uncertainty however remains ill-defined. We show a clear
scheme for quantifying the calibration of Bayesian generative machine learning
models. For a Continuous Normalizing Flow applied to a low-dimensional toy
example, we evaluate the calibration of Bayesian uncertainties from either a
mean-field Gaussian weight posterior, or Monte Carlo sampling network weights,
to gauge their behaviour on unsteady distribution edges. Well calibrated
uncertainties can then be used to roughly estimate the number of uncorrelated
truth samples that are equivalent to the generated sample and clearly indicate
data amplification for smooth features of the distribution.

摘要：<paragraph>最近，生成和貝氏機器學習的組合已引入粒子物理學，用於快速偵測器模擬和推理任務。這些神經網路旨在量化生成分布的不確定性，該不確定性源自有限的訓練統計資料。然而，對分布範圍不確定性的解釋仍然定義不清。我們展示了一個清晰的方案，用於量化貝氏生成機器學習模型的校準。對於應用於低維玩具範例的連續正規化流，我們評估了貝氏不確定性的校準，無論是來自平均場高斯權重後驗或蒙地卡羅採樣網路權重，以評估它們在不穩定分布邊緣的行為。校準良好的不確定性可用於粗略估計與生成樣本等效的非相關真實樣本的數量，並清楚地指示分布平滑特徵的資料擴增。</paragraph>

##### **MM-Vet v2: A Challenging Benchmark to Evaluate Large Multimodal Models for Integrated Capabilities**
2408.00765v1 by Weihao Yu, Zhengyuan Yang, Linfeng Ren, Linjie Li, Jianfeng Wang, Kevin Lin, Chung-Ching Lin, Zicheng Liu, Lijuan Wang, Xinchao Wang

MM-Vet, with open-ended vision-language questions targeting at evaluating
integrated capabilities, has become one of the most popular benchmarks for
large multimodal model evaluation. MM-Vet assesses six core vision-language
(VL) capabilities: recognition, knowledge, spatial awareness, language
generation, OCR, and math. However, its question format is restricted to single
image-text pairs, lacking the interleaved image and text sequences prevalent in
real-world scenarios. To address this limitation, we introduce MM-Vet v2, which
includes a new VL capability called "image-text sequence understanding",
evaluating models' ability to process VL sequences. Furthermore, we maintain
the high quality of evaluation samples while further expanding the evaluation
set size. Using MM-Vet v2 to benchmark large multimodal models, we found that
Claude 3.5 Sonnet is the best model with a score of 71.8, slightly
outperforming GPT-4o which scored 71.0. Among open-weight models,
InternVL2-Llama3-76B leads with a score of 68.4.

摘要：MM-Vet 透過針對評估整合能力而設計的開放式視覺語言問題，已成為大型多模態模型評估最受歡迎的基準之一。MM-Vet 評估六項核心視覺語言 (VL) 能力：辨識、知識、空間意識、語言生成、OCR 和數學。然而，其問題格式僅限於單一影像文字對，缺乏真實世界場景中普遍存在的交錯影像和文字序列。為了解決此限制，我們引入了 MM-Vet v2，其中包含稱為「影像文字序列理解」的新 VL 能力，用於評估模型處理 VL 序列的能力。此外，我們在進一步擴充評估集大小的同時，維持評估範例的高品質。我們使用 MM-Vet v2 對大型多模態模型進行基準測試，發現 Claude 3.5 Sonnet 是最佳模型，得分為 71.8，略優於 GPT-4o 的 71.0 分。在開放權重模型中，InternVL2-Llama3-76B 以 68.4 分領先。

##### **AgentGen: Enhancing Planning Abilities for Large Language Model based Agent via Environment and Task Generation**
2408.00764v1 by Mengkang Hu, Pu Zhao, Can Xu, Qingfeng Sun, Jianguang Lou, Qingwei Lin, Ping Luo, Saravan Rajmohan, Dongmei Zhang

Large Language Model (LLM) based agents have garnered significant attention
and are becoming increasingly popular. Furthermore, planning ability is a
crucial component of an LLM-based agent, involving interaction with the
environment and executing actions to complete a planning task, which generally
entails achieving a desired goal from an initial state. This paper investigates
enhancing the planning abilities of LLMs through instruction tuning, referred
to as agent training. Recent studies have demonstrated that utilizing
expert-level trajectory for instruction-tuning LLMs effectively enhances their
planning capabilities. However, existing work primarily focuses on synthesizing
trajectories from manually designed planning tasks and environments. The
labor-intensive nature of creating these environments and tasks impedes the
generation of sufficiently varied and extensive trajectories. To address this
limitation, this paper explores the automated synthesis of diverse environments
and a gradual range of planning tasks, from easy to difficult. We introduce a
framework, AgentGen, that leverages LLMs first to generate environments and
subsequently generate planning tasks conditioned on these environments.
Specifically, to improve environmental diversity, we propose using an
inspiration corpus composed of various domain-specific text segments as the
context for synthesizing environments. Moreover, to increase the difficulty
diversity of generated planning tasks, we propose a bidirectional evolution
method, Bi-Evol, that evolves planning tasks from easier and harder directions
to synthesize a task set with a smoother difficulty curve. The evaluation
results derived from AgentBoard show that AgentGen greatly improves LLMs'
planning ability, e.g., the AgentGen instruction-tuned Llama-3 8B surpasses
GPT-3.5 in overall performance. Moreover, in certain tasks, it even outperforms
GPT-4.

摘要：大型語言模型 (LLM) 基於代理已引起廣泛關注，並正變得越來越流行。此外，規劃能力是 LLM 基於代理的重要組成部分，涉及與環境互動並執行動作以完成規劃任務，這通常需要從初始狀態實現預期目標。本文探討了通過指令調整來增強 LLM 的規劃能力，稱為代理訓練。最近的研究表明，利用專家級軌跡進行指令調整 LLM 有效地增強了其規劃能力。然而，現有工作主要集中於從人工設計的規劃任務和環境中合成軌跡。創建這些環境和任務的勞動密集性阻礙了產生足夠多樣化和廣泛的軌跡。為了解決這個限制，本文探討了多樣化環境和從容易到困難的逐步規劃任務的自動合成。我們引入了一個框架 AgentGen，它利用 LLM 首先生成環境，然後根據這些環境生成規劃任務。具體來說，為了提高環境的多樣性，我們建議使用由各種特定領域文本片段組成的靈感語料庫作為合成環境的背景。此外，為了增加生成規劃任務的難度多樣性，我們提出了一種雙向演化方法 Bi-Evol，它從更容易和更困難的方向演化規劃任務，以合成一個具有更平滑難度曲線的任務集。從 AgentBoard 衍生的評估結果表明，AgentGen 大大提高了 LLM 的規劃能力，例如，AgentGen 指令調整的 Llama-3 8B 在整體性能上超過了 GPT-3.5。此外，在某些任務中，它甚至優於 GPT-4。

##### **Tamper-Resistant Safeguards for Open-Weight LLMs**
2408.00761v1 by Rishub Tamirisa, Bhrugu Bharathi, Long Phan, Andy Zhou, Alice Gatti, Tarun Suresh, Maxwell Lin, Justin Wang, Rowan Wang, Ron Arel, Andy Zou, Dawn Song, Bo Li, Dan Hendrycks, Mantas Mazeika

Rapid advances in the capabilities of large language models (LLMs) have
raised widespread concerns regarding their potential for malicious use.
Open-weight LLMs present unique challenges, as existing safeguards lack
robustness to tampering attacks that modify model weights. For example, recent
works have demonstrated that refusal and unlearning safeguards can be trivially
removed with a few steps of fine-tuning. These vulnerabilities necessitate new
approaches for enabling the safe release of open-weight LLMs. We develop a
method, called TAR, for building tamper-resistant safeguards into open-weight
LLMs such that adversaries cannot remove the safeguards even after thousands of
steps of fine-tuning. In extensive evaluations and red teaming analyses, we
find that our method greatly improves tamper-resistance while preserving benign
capabilities. Our results demonstrate that tamper-resistance is a tractable
problem, opening up a promising new avenue to improve the safety and security
of open-weight LLMs.

摘要：大型語言模型 (LLM) 的功能快速進步，引發了人們對其潛在惡意使用感到普遍擔憂。開放權重的 LLM 提出獨特挑戰，因為現有保障措施缺乏對修改模型權重的竄改攻擊的健全性。例如，最近的研究表明，拒絕和遺忘保障措施可以用微調的幾個步驟輕鬆移除。這些漏洞需要新的方法來實現開放權重 LLM 的安全發布。我們開發了一種稱為 TAR 的方法，用於將防篡改保障措施建置到開放權重 LLM 中，這樣即使經過數千次微調步驟，對手也無法移除保障措施。在廣泛的評估和紅隊分析中，我們發現我們的這種方法大幅提高了防篡改能力，同時保留了良性功能。我們的結果表明，防篡改是一個易於解決的問題，為改善開放權重 LLM 的安全性和安全性開闢了一條新的途徑。

##### **Smoothed Energy Guidance: Guiding Diffusion Models with Reduced Energy Curvature of Attention**
2408.00760v1 by Susung Hong

Conditional diffusion models have shown remarkable success in visual content
generation, producing high-quality samples across various domains, largely due
to classifier-free guidance (CFG). Recent attempts to extend guidance to
unconditional models have relied on heuristic techniques, resulting in
suboptimal generation quality and unintended effects. In this work, we propose
Smoothed Energy Guidance (SEG), a novel training- and condition-free approach
that leverages the energy-based perspective of the self-attention mechanism to
enhance image generation. By defining the energy of self-attention, we
introduce a method to reduce the curvature of the energy landscape of attention
and use the output as the unconditional prediction. Practically, we control the
curvature of the energy landscape by adjusting the Gaussian kernel parameter
while keeping the guidance scale parameter fixed. Additionally, we present a
query blurring method that is equivalent to blurring the entire attention
weights without incurring quadratic complexity in the number of tokens. In our
experiments, SEG achieves a Pareto improvement in both quality and the
reduction of side effects. The code is available at
\url{https://github.com/SusungHong/SEG-SDXL}.

摘要：條件擴散模型在視覺內容生成方面展現出顯著的成功，在各種領域產生高品質的範例，這在很大程度上歸功於無分類器引導 (CFG)。最近嘗試將引導擴展到無條件模型依賴於啟發式技術，導致次優的生成品質和意外的影響。在這項工作中，我們提出平滑能量引導 (SEG)，一種新穎的訓練和條件無關的方法，它利用自注意力機制的基於能量的觀點來增強影像生成。透過定義自注意力的能量，我們引入一種方法來減少注意力的能量景觀的曲率，並使用輸出作為無條件預測。實際上，我們透過調整高斯核參數來控制能量景觀的曲率，同時保持引導規模參數固定。此外，我們提出一個查詢模糊方法，這等同於模糊整個注意力權重，而不會產生二次複雜度，令牌數量也不受影響。在我們的實驗中，SEG 在品質和副作用的減少方面都達到了帕累托改善。程式碼可在 \url{https://github.com/SusungHong/SEG-SDXL} 取得。

##### **Segment anything model 2: an application to 2D and 3D medical images**
2408.00756v1 by Haoyu Dong, Hanxue Gu, Yaqian Chen, Jichen Yang, Maciej A. Mazurowski

Segment Anything Model (SAM) has gained significant attention because of its
ability to segment a variety of objects in images given a prompt. The recently
developed SAM 2 has extended this ability to video inputs. This opens an
opportunity to apply SAM to 3D images, one of the fundamental tasks in the
medical imaging field. In this paper, we provide an extensive evaluation of SAM
2's ability to segment both 2D and 3D medical images. We collect 18 medical
imaging datasets, including common 3D modalities such as computed tomography
(CT), magnetic resonance imaging (MRI), and positron emission tomography (PET)
as well as 2D modalities such as X-ray and ultrasound. We consider two
evaluation pipelines of SAM 2: (1) multi-frame 3D segmentation, where prompts
are provided to one or multiple slice(s) selected from the volume, and (2)
single-frame 2D segmentation, where prompts are provided to each slice. The
former is only applicable to 3D modalities, while the latter applies to both 2D
and 3D modalities. We learn that SAM 2 exhibits similar performance as SAM
under single-frame 2D segmentation, and has variable performance under
multi-frame 3D segmentation depending on the choices of slices to annotate, the
direction of the propagation, the predictions utilized during the propagation,
etc.

摘要：分段任何模型 (SAM) 因其在給定提示的情況下分段圖像中各種物體的能力而備受關注。最近開發的 SAM 2 已將此能力擴展到影片輸入。這開啟了一個將 SAM 應用於 3D 影像的機會，這是醫學影像領域的基礎任務之一。在本文中，我們對 SAM 2 分段 2D 和 3D 醫學影像的能力進行了廣泛評估。我們收集了 18 個醫學影像資料集，包括常見的 3D 方式，例如電腦斷層掃描 (CT)、磁振造影 (MRI) 和正子發射斷層掃描 (PET)，以及 2D 方式，例如 X 光和超音波。我們考慮了 SAM 2 的兩個評估管道：(1) 多幀 3D 分段，其中提示提供給從體積中選取的一個或多個切片，以及 (2) 單幀 2D 分段，其中提示提供給每個切片。前者僅適用於 3D 方式，而後者適用於 2D 和 3D 方式。我們了解到，在單幀 2D 分段下，SAM 2 表現出與 SAM 相似的效能，而在多幀 3D 分段下則表現出不同的效能，具體取決於標記切片的選擇、傳播方向、傳播期間使用的預測等。

##### **DynamoLLM: Designing LLM Inference Clusters for Performance and Energy Efficiency**
2408.00741v1 by Jovan Stojkovic, Chaojie Zhang, Íñigo Goiri, Josep Torrellas, Esha Choukse

The rapid evolution and widespread adoption of generative large language
models (LLMs) have made them a pivotal workload in various applications. Today,
LLM inference clusters receive a large number of queries with strict Service
Level Objectives (SLOs). To achieve the desired performance, these models
execute on power-hungry GPUs causing the inference clusters to consume large
amount of energy and, consequently, result in excessive carbon emissions.
Fortunately, we find that there is a great opportunity to exploit the
heterogeneity in inference compute properties and fluctuations in inference
workloads, to significantly improve energy-efficiency. However, such a diverse
and dynamic environment creates a large search-space where different system
configurations (e.g., number of instances, model parallelism, and GPU
frequency) translate into different energy-performance trade-offs. To address
these challenges, we propose DynamoLLM, the first energy-management framework
for LLM inference environments. DynamoLLM automatically and dynamically
reconfigures the inference cluster to optimize for energy and cost of LLM
serving under the service's performance SLOs. We show that at a service-level,
DynamoLLM conserves 53% energy and 38% operational carbon emissions, and
reduces 61% cost to the customer, while meeting the latency SLOs.

摘要：生成式大型语言模型 (LLM) 的快速发展和广泛采用，使其成为各种应用程序中的关键工作负载。如今，LLM 推理集群会收到大量具有严格服务级别目标 (SLO) 的查询。为了实现所需的性能，这些模型在耗电的 GPU 上执行，导致推理集群消耗大量的能量，从而导致过度的碳排放。幸运的是，我们发现有很大的机会利用推理计算特性和推理工作负载的波动中的异质性，以显著提高能效。然而，如此多样化和动态的环境创造了一个巨大的搜索空间，其中不同的系统配置（例如，实例数量、模型并行性和 GPU 频率）转化为不同的能效权衡。为了应对这些挑战，我们提出了 DynamoLLM，这是 LLM 推理环境的第一个能源管理框架。DynamoLLM 会自动动态地重新配置推理集群，以优化 LLM 服务的能源和成本，同时满足服务的性能 SLO。我们表明，在服务级别，DynamoLLM 节省了 53% 的能源和 38% 的运营碳排放，并为客户节省了 61% 的成本，同时满足了延迟 SLO。

##### **CERT-ED: Certifiably Robust Text Classification for Edit Distance**
2408.00728v1 by Zhuoqun Huang, Neil G Marchant, Olga Ohrimenko, Benjamin I. P. Rubinstein

With the growing integration of AI in daily life, ensuring the robustness of
systems to inference-time attacks is crucial. Among the approaches for
certifying robustness to such adversarial examples, randomized smoothing has
emerged as highly promising due to its nature as a wrapper around arbitrary
black-box models. Previous work on randomized smoothing in natural language
processing has primarily focused on specific subsets of edit distance
operations, such as synonym substitution or word insertion, without exploring
the certification of all edit operations. In this paper, we adapt Randomized
Deletion (Huang et al., 2023) and propose, CERTified Edit Distance defense
(CERT-ED) for natural language classification. Through comprehensive
experiments, we demonstrate that CERT-ED outperforms the existing Hamming
distance method RanMASK (Zeng et al., 2023) in 4 out of 5 datasets in terms of
both accuracy and the cardinality of the certificate. By covering various
threat models, including 5 direct and 5 transfer attacks, our method improves
empirical robustness in 38 out of 50 settings.

摘要：隨著 AI 在日常生活中整合度不斷提高，確保系統在推理時間攻擊中的穩健性至關重要。在用於驗證對此類對抗範例的穩健性的方法中，隨機平滑因其作為任意黑盒模型的包裝器的特性而備受矚目。先前針對自然語言處理中隨機平滑的研究主要集中在編輯距離操作的特定子集上，例如同義詞替換或詞彙插入，而沒有探索所有編輯操作的驗證。在本文中，我們調整了隨機刪除（Huang et al., 2023）並提出了自然語言分類的 CERTified 編輯距離防禦（CERT-ED）。透過全面的實驗，我們證明 CERT-ED 在準確性和證書基數方面，在 5 個資料集中有 4 個資料集優於現有的漢明距離方法 RanMASK（Zeng et al., 2023）。透過涵蓋各種威脅模型，包括 5 次直接攻擊和 5 次傳輸攻擊，我們的模型在 50 個設定中有 38 個設定改進了經驗穩健性。

##### **Improving Retrieval-Augmented Generation in Medicine with Iterative Follow-up Questions**
2408.00727v1 by Guangzhi Xiong, Qiao Jin, Xiao Wang, Minjia Zhang, Zhiyong Lu, Aidong Zhang

The emergent abilities of large language models (LLMs) have demonstrated
great potential in solving medical questions. They can possess considerable
medical knowledge, but may still hallucinate and are inflexible in the
knowledge updates. While Retrieval-Augmented Generation (RAG) has been proposed
to enhance the medical question-answering capabilities of LLMs with external
knowledge bases, it may still fail in complex cases where multiple rounds of
information-seeking are required. To address such an issue, we propose
iterative RAG for medicine (i-MedRAG), where LLMs can iteratively ask follow-up
queries based on previous information-seeking attempts. In each iteration of
i-MedRAG, the follow-up queries will be answered by a vanilla RAG system and
they will be further used to guide the query generation in the next iteration.
Our experiments show the improved performance of various LLMs brought by
i-MedRAG compared with vanilla RAG on complex questions from clinical vignettes
in the United States Medical Licensing Examination (USMLE), as well as various
knowledge tests in the Massive Multitask Language Understanding (MMLU) dataset.
Notably, our zero-shot i-MedRAG outperforms all existing prompt engineering and
fine-tuning methods on GPT-3.5, achieving an accuracy of 69.68\% on the MedQA
dataset. In addition, we characterize the scaling properties of i-MedRAG with
different iterations of follow-up queries and different numbers of queries per
iteration. Our case studies show that i-MedRAG can flexibly ask follow-up
queries to form reasoning chains, providing an in-depth analysis of medical
questions. To the best of our knowledge, this is the first-of-its-kind study on
incorporating follow-up queries into medical RAG.

摘要：大型語言模型（LLM）的新興能力已證明在解決醫療問題方面具有巨大潛力。它們可能擁有大量的醫療知識，但仍可能產生幻覺，並且在知識更新方面缺乏靈活性。雖然已提出檢索增強生成（RAG）以利用外部知識庫增強 LLM 的醫療問題解答能力，但在需要多輪信息檢索的複雜情況下，它仍可能失敗。為了解決這個問題，我們提出了用於醫療的迭代 RAG（i-MedRAG），其中 LLM 可以根據先前的信息檢索嘗試反覆詢問後續查詢。在 i-MedRAG 的每次迭代中，後續查詢將由基本的 RAG 系統回答，並且它們將進一步用於指導下一次迭代中的查詢生成。我們的實驗表明，與美國醫學執照考試（USMLE）中臨床小插圖中的複雜問題以及 Massive Multitask Language Understanding（MMLU）數據集中各種知識測試中的基本 RAG 相比，i-MedRAG 帶來的各種 LLM 的改進性能。值得注意的是，我們的零次學習 i-MedRAG 在 GPT-3.5 上優於所有現有的提示工程和微調方法，在 MedQA 數據集上達到了 69.68% 的準確率。此外，我們描述了 i-MedRAG 的擴展屬性，包括不同的後續查詢迭代和每個迭代的不同查詢數量。我們的案例研究表明，i-MedRAG 可以靈活地詢問後續查詢以形成推理鏈，從而對醫療問題進行深入分析。據我們所知，這是第一個將後續查詢納入醫療 RAG 的同類研究。

##### **Y Social: an LLM-powered Social Media Digital Twin**
2408.00818v1 by Giulio Rossetti, Massimo Stella, Rémy Cazabet, Katherine Abramski, Erica Cau, Salvatore Citraro, Andrea Failla, Riccardo Improta, Virginia Morini, Valentina Pansanella

In this paper we introduce Y, a new-generation digital twin designed to
replicate an online social media platform. Digital twins are virtual replicas
of physical systems that allow for advanced analyses and experimentation. In
the case of social media, a digital twin such as Y provides a powerful tool for
researchers to simulate and understand complex online interactions. {\tt Y}
leverages state-of-the-art Large Language Models (LLMs) to replicate
sophisticated agent behaviors, enabling accurate simulations of user
interactions, content dissemination, and network dynamics. By integrating these
aspects, Y offers valuable insights into user engagement, information spread,
and the impact of platform policies. Moreover, the integration of LLMs allows Y
to generate nuanced textual content and predict user responses, facilitating
the study of emergent phenomena in online environments.
  To better characterize the proposed digital twin, in this paper we describe
the rationale behind its implementation, provide examples of the analyses that
can be performed on the data it enables to be generated, and discuss its
relevance for multidisciplinary research.

摘要：<paragraph>在本文中，我們介紹了 Y，一種新一代的數位雙胞胎，旨在複製線上社群媒體平台。數位雙胞胎是實體系統的虛擬複製品，允許進行進階分析和實驗。在社群媒體的情況下，像 Y 這樣的數位雙胞胎為研究人員提供了強大的工具，可以模擬和了解複雜的線上互動。{\tt Y} 採用最先進的大語言模型 (LLM) 來複製複雜的代理人行為，實現使用者互動、內容傳播和網路動態的精確模擬。透過整合這些面向，Y 提供了關於使用者參與度、資訊傳播和平台政策影響的寶貴見解。此外，整合 LLM 讓 Y 能夠產生細緻入微的文字內容並預測使用者的回應，促進對線上環境中新興現象的研究。為了更好地描述所提出的數位雙胞胎，在本文中，我們說明了其實作背後的原理，提供了可以在其所啟用的資料上執行的分析範例，並探討其對跨領域研究的相關性。</paragraph>

##### **An Empirical Analysis of Compute-Optimal Inference for Problem-Solving with Language Models**
2408.00724v1 by Yangzhen Wu, Zhiqing Sun, Shanda Li, Sean Welleck, Yiming Yang

The optimal training configurations of large language models (LLMs) with
respect to model sizes and compute budgets have been extensively studied. But
how to optimally configure LLMs during inference has not been explored in
sufficient depth. We study compute-optimal inference: designing models and
inference strategies that optimally trade off additional inference-time compute
for improved performance. As a first step towards understanding and designing
compute-optimal inference methods, we assessed the effectiveness and
computational efficiency of multiple inference strategies such as Greedy
Search, Majority Voting, Best-of-N, Weighted Voting, and their variants on two
different Tree Search algorithms, involving different model sizes and
computational budgets. We found that a smaller language model with a novel tree
search algorithm typically achieves a Pareto-optimal trade-off. These results
highlight the potential benefits of deploying smaller models equipped with more
sophisticated decoding algorithms in budget-constrained scenarios, e.g., on
end-devices, to enhance problem-solving accuracy. For instance, we show that
the Llemma-7B model can achieve competitive accuracy to a Llemma-34B model on
MATH500 while using $2\times$ less FLOPs. Our findings could potentially apply
to any generation task with a well-defined measure of success.

摘要：對於大型語言模型 (LLM) 的最佳訓練組態，無論是模型大小或運算預算，都已廣泛研究過。但如何最佳組態 LLM 在推論期間尚未深入探討。我們研究計算最佳推論：設計模型和推論策略，最佳折衷額外的推論時間計算以提升效能。作為了解和設計計算最佳推論方法的第一步，我們評估多種推論策略的效能和計算效率，例如貪婪搜尋、多數決、N 中最佳、加權投票，以及它們在兩種不同樹狀搜尋演算法上的變體，涉及不同模型大小和計算預算。我們發現，具備新穎樹狀搜尋演算法的較小語言模型通常能達成帕雷托最佳折衷。這些結果突顯在預算受限的情況下，部署配備更精緻解碼演算法的小型模型的潛在好處，例如在終端裝置上，以提升問題解決的準確度。例如，我們顯示 Llemma-7B 模型在 MATH500 上能達成與 Llemma-34B 模型競爭的準確度，同時使用少 $2\times$ 的 FLOP。我們的發現潛在可應用於任何具有明確成功衡量標準的產生任務。

##### **Pathway to Secure and Trustworthy 6G for LLMs: Attacks, Defense, and Opportunities**
2408.00722v1 by Sunder Ali Khowaja, Parus Khuwaja, Kapal Dev, Hussam Al Hamadi, Engin Zeydan

Recently, large language models (LLMs) have been gaining a lot of interest
due to their adaptability and extensibility in emerging applications, including
communication networks. It is anticipated that 6G mobile edge computing
networks will be able to support LLMs as a service, as they provide ultra
reliable low-latency communications and closed loop massive connectivity.
However, LLMs are vulnerable to data and model privacy issues that affect the
trustworthiness of LLMs to be deployed for user-based services. In this paper,
we explore the security vulnerabilities associated with fine-tuning LLMs in 6G
networks, in particular the membership inference attack. We define the
characteristics of an attack network that can perform a membership inference
attack if the attacker has access to the fine-tuned model for the downstream
task. We show that the membership inference attacks are effective for any
downstream task, which can lead to a personal data breach when using LLM as a
service. The experimental results show that the attack success rate of maximum
92% can be achieved on named entity recognition task. Based on the experimental
analysis, we discuss possible defense mechanisms and present possible research
directions to make the LLMs more trustworthy in the context of 6G networks.

摘要：<paragraph>最近，大型语言模型 (LLM) 因其在包括通信网络在内的新兴应用中的适应性和可扩展性而备受关注。预计 6G 移动边缘计算网络将能够支持 LLM 作为一项服务，因为它们提供了超可靠的低延迟通信和闭环大规模连接。然而，LLM 容易受到数据和模型隐私问题的影响，这些问题会影响 LLM 被部署用于基于用户的服务的可信度。在本文中，我们探讨了在 6G 网络中微调 LLM 相关的安全漏洞，特别是成员推断攻击。我们定义了攻击网络的特征，如果攻击者可以访问下游任务的微调模型，则该攻击网络可以执行成员推断攻击。我们表明，成员推断攻击对任何下游任务都是有效的，这在使用 LLM 作为服务时可能导致个人数据泄露。实验结果表明，在命名实体识别任务上可以实现最高 92% 的攻击成功率。基于实验分析，我们讨论了可能的防御机制，并提出了可能的的研究方向，以使 LLM 在 6G 网络的背景下更值得信赖。</paragraph>

##### **SAM 2: Segment Anything in Images and Videos**
2408.00714v1 by Nikhila Ravi, Valentin Gabeur, Yuan-Ting Hu, Ronghang Hu, Chaitanya Ryali, Tengyu Ma, Haitham Khedr, Roman Rädle, Chloe Rolland, Laura Gustafson, Eric Mintun, Junting Pan, Kalyan Vasudev Alwala, Nicolas Carion, Chao-Yuan Wu, Ross Girshick, Piotr Dollár, Christoph Feichtenhofer

We present Segment Anything Model 2 (SAM 2), a foundation model towards
solving promptable visual segmentation in images and videos. We build a data
engine, which improves model and data via user interaction, to collect the
largest video segmentation dataset to date. Our model is a simple transformer
architecture with streaming memory for real-time video processing. SAM 2
trained on our data provides strong performance across a wide range of tasks.
In video segmentation, we observe better accuracy, using 3x fewer interactions
than prior approaches. In image segmentation, our model is more accurate and 6x
faster than the Segment Anything Model (SAM). We believe that our data, model,
and insights will serve as a significant milestone for video segmentation and
related perception tasks. We are releasing a version of our model, the dataset
and an interactive demo.

摘要：我們提出「區段任何東西模型 2」(SAM 2)，這是一個基礎模型，用於解決影像和影片中的可提示視覺區段。我們建構了一個資料引擎，透過使用者互動來改善模型和資料，以收集迄今為止最大的影片區段資料集。我們的模型是一種簡單的轉換器架構，具有串流記憶體，可進行即時影片處理。在我們的資料上訓練的 SAM 2 在廣泛的任務中提供了強大的效能。在影片區段中，我們觀察到更高的準確度，與先前的做法相比，互動次數減少了 3 倍。在影像區段中，我們的模型比「區段任何東西模型」(SAM) 更準確，速度快了 6 倍。我們相信我們的資料、模型和見解將成為影片區段和相關感知任務的重要里程碑。我們正在釋出我們模型的一個版本、資料集和一個互動示範。

##### **Investigating Brain Connectivity and Regional Statistics from EEG for early stage Parkinson's Classification**
2408.00711v1 by Amarpal Sahota, Amber Roguski, Matthew W Jones, Zahraa S. Abdallah, Raul Santos-Rodriguez

We evaluate the effectiveness of combining brain connectivity metrics with
signal statistics for early stage Parkinson's Disease (PD) classification using
electroencephalogram data (EEG). The data is from 5 arousal states - wakeful
and four sleep stages (N1, N2, N3 and REM). Our pipeline uses an Ada Boost
model for classification on a challenging early stage PD classification task
with with only 30 participants (11 PD , 19 Healthy Control). Evaluating 9 brain
connectivity metrics we find the best connectivity metric to be different for
each arousal state with Phase Lag Index achieving the highest individual
classification accuracy of 86\% on N1 data. Further to this our pipeline using
regional signal statistics achieves an accuracy of 78\%, using brain
connectivity only achieves an accuracy of 86\% whereas combining the two
achieves a best accuracy of 91\%. This best performance is achieved on N1 data
using Phase Lag Index (PLI) combined with statistics derived from the frequency
characteristics of the EEG signal. This model also achieves a recall of 80 \%
and precision of 96\%. Furthermore we find that on data from each arousal
state, combining PLI with regional signal statistics improves classification
accuracy versus using signal statistics or brain connectivity alone. Thus we
conclude that combining brain connectivity statistics with regional EEG
statistics is optimal for classifier performance on early stage Parkinson's.
Additionally, we find outperformance of N1 EEG for classification of
Parkinson's and expect this could be due to disrupted N1 sleep in PD. This
should be explored in future work.

摘要：<paragraph>我們評估將腦連接性指標與訊號統計資料結合起來對早期帕金森氏症 (PD) 分類的有效性，使用腦電圖資料 (EEG)。資料來自 5 種喚醒狀態 - 清醒和四個睡眠階段 (N1、N2、N3 和 REM)。我們的管道使用 Ada Boost 模型對具有挑戰性的早期 PD 分類任務進行分類，僅有 30 位參與者 (11 位 PD，19 位健康對照組)。評估 9 種腦連接性指標，我們發現最佳連接性指標因每種喚醒狀態而異，相位滯後指標在 N1 資料上達到最高的個別分類準確度 86%。此外，我們的管道使用區域訊號統計資料達到 78% 的準確度，僅使用腦連接性達到 86% 的準確度，而將兩者結合起來達到最佳 91% 的準確度。此最佳效能是在 N1 資料上使用相位滯後指標 (PLI) 結合從 EEG 訊號的頻率特性衍生的統計資料時所達成。此模型也達到 80% 的召回率和 96% 的精確度。此外，我們發現，在來自每種喚醒狀態的資料上，將 PLI 與區域訊號統計資料結合起來，可提升分類準確度，優於僅使用訊號統計資料或腦連接性。因此，我們得出結論，將腦連接性統計資料與區域 EEG 統計資料結合起來，對於早期帕金森氏症的分類器效能而言是最佳的。此外，我們發現 N1 EEG 在帕金森氏症的分類上有優異表現，並預期這可能是由於 PD 中 N1 睡眠中斷所致。這應在未來的研究中加以探討。</paragraph>

##### **Point-supervised Brain Tumor Segmentation with Box-prompted MedSAM**
2408.00706v1 by Xiaofeng Liu, Jonghye Woo, Chao Ma, Jinsong Ouyang, Georges El Fakhri

Delineating lesions and anatomical structure is important for image-guided
interventions. Point-supervised medical image segmentation (PSS) has great
potential to alleviate costly expert delineation labeling. However, due to the
lack of precise size and boundary guidance, the effectiveness of PSS often
falls short of expectations. Although recent vision foundational models, such
as the medical segment anything model (MedSAM), have made significant
advancements in bounding-box-prompted segmentation, it is not straightforward
to utilize point annotation, and is prone to semantic ambiguity. In this
preliminary study, we introduce an iterative framework to facilitate
semantic-aware point-supervised MedSAM. Specifically, the semantic box-prompt
generator (SBPG) module has the capacity to convert the point input into
potential pseudo bounding box suggestions, which are explicitly refined by the
prototype-based semantic similarity. This is then succeeded by a prompt-guided
spatial refinement (PGSR) module that harnesses the exceptional
generalizability of MedSAM to infer the segmentation mask, which also updates
the box proposal seed in SBPG. Performance can be progressively improved with
adequate iterations. We conducted an evaluation on BraTS2018 for the
segmentation of whole brain tumors and demonstrated its superior performance
compared to traditional PSS methods and on par with box-supervised methods.

摘要：描繪病灶和解剖結構對於影像導引介入非常重要。點監督醫學影像分割（PSS）具有減輕昂貴的專家描繪標籤的巨大潛力。然而，由於缺乏精確的大小和邊界引導，PSS 的有效性通常低於預期。儘管最近的視覺基礎模型，例如醫學分割任何模型（MedSAM），在邊界框提示分割方面取得了重大進展，但利用點註釋並不容易，而且容易產生語義歧義。在這項初步研究中，我們引入了一個迭代框架來促進語義感知點監督 MedSAM。具體來說，語義框提示生成器（SBPG）模組能夠將點輸入轉換為潛在的偽邊界框建議，這些建議由基於原型的語義相似性明確細化。然後，由提示引導的空間細化（PGSR）模組繼承，它利用 MedSAM 的出色可概化性來推斷分割蒙版，這也會更新 SBPG 中的框建議種子。通過充分的迭代可以逐步提高性能。我們對 BraTS2018 進行了全腦腫瘤分割評估，並證明其性能優於傳統的 PSS 方法，並且與框監督方法相當。

##### **Future of Artificial Intelligence in Agile Software Development**
2408.00703v1 by Mariyam Mahboob, Mohammed Rayyan Uddin Ahmed, Zoiba Zia, Mariam Shakeel Ali, Ayman Khaleel Ahmed

The advent of Artificial intelligence has promising advantages that can be
utilized to transform the landscape of software project development. The
Software process framework consists of activities that constantly require
routine human interaction, leading to the possibility of errors and
uncertainties. AI can assist software development managers, software testers,
and other team members by leveraging LLMs, GenAI models, and AI agents to
perform routine tasks, risk analysis and prediction, strategy recommendations,
and support decision making. AI has the potential to increase efficiency and
reduce the risks encountered by the project management team while increasing
the project success rates. Additionally, it can also break down complex notions
and development processes for stakeholders to make informed decisions. In this
paper, we propose an approach in which AI tools and technologies can be
utilized to bestow maximum assistance for agile software projects, which have
become increasingly favored in the industry in recent years.

摘要：人工智慧的出現具有可帶來優勢，可望用於轉換軟體專案開發的樣貌。軟體流程架構包含持續需要常規人類互動的活動，導致可能產生錯誤和不確定性。人工智慧能協助軟體開發經理、軟體測試人員和其他團隊成員，透過利用大型語言模型 (LLM)、生成式人工智慧模型和人工智慧代理程式來執行常規工作、風險分析和預測、策略建議和支援決策制定。人工智慧有潛力提升效率和降低專案管理團隊遭遇的風險，同時提升專案成功率。此外，人工智慧還能為利害關係人分解複雜的概念和開發流程，以做出明智的決策。在本文中，我們提出一個方法，其中人工智慧工具和技術可望用於賦予敏捷軟體專案最大的協助，這些專案近年來在產業中越來越受到青睞。

##### **Improving Text Embeddings for Smaller Language Models Using Contrastive Fine-tuning**
2408.00690v2 by Trapoom Ukarapol, Zhicheng Lee, Amy Xin

While Large Language Models show remarkable performance in natural language
understanding, their resource-intensive nature makes them less accessible. In
contrast, smaller language models such as MiniCPM offer more sustainable
scalability, but often underperform without specialized optimization. In this
paper, we explore the enhancement of smaller language models through the
improvement of their text embeddings. We select three language models, MiniCPM,
Phi-2, and Gemma, to conduct contrastive fine-tuning on the NLI dataset. Our
results demonstrate that this fine-tuning method enhances the quality of text
embeddings for all three models across various benchmarks, with MiniCPM showing
the most significant improvements of an average 56.33% performance gain. The
contrastive fine-tuning code is publicly available at
https://github.com/trapoom555/Language-Model-STS-CFT.

摘要：儘管大型語言模型在自然語言理解方面表現出色，但其資源密集的特性使其不易取得。相反地，較小的語言模型（例如 MiniCPM）提供了更永續的可擴充性，但通常在沒有專業最佳化的情況下表現不佳。在本文中，我們探討透過改善其文字嵌入來增強較小的語言模型。我們選擇了三個語言模型（MiniCPM、Phi-2 和 Gemma）在 NLI 資料集上進行對比微調。我們的結果證明，這種微調方法提升了所有三個模型在各種基準上的文字嵌入品質，其中 MiniCPM 顯示最顯著的進步，平均效能提升了 56.33%。對比微調程式碼已公開於 https://github.com/trapoom555/Language-Model-STS-CFT。

##### **Can Developers Prompt? A Controlled Experiment for Code Documentation Generation**
2408.00686v1 by Hans-Alexander Kruse, Tim Puhlfürß, Walid Maalej

Large language models (LLMs) bear great potential for automating tedious
development tasks such as creating and maintaining code documentation. However,
it is unclear to what extent developers can effectively prompt LLMs to create
concise and useful documentation. We report on a controlled experiment with 20
professionals and 30 computer science students tasked with code documentation
generation for two Python functions. The experimental group freely entered
ad-hoc prompts in a ChatGPT-like extension of Visual Studio Code, while the
control group executed a predefined few-shot prompt. Our results reveal that
professionals and students were unaware of or unable to apply prompt
engineering techniques. Especially students perceived the documentation
produced from ad-hoc prompts as significantly less readable, less concise, and
less helpful than documentation from prepared prompts. Some professionals
produced higher quality documentation by just including the keyword Docstring
in their ad-hoc prompts. While students desired more support in formulating
prompts, professionals appreciated the flexibility of ad-hoc prompting.
Participants in both groups rarely assessed the output as perfect. Instead,
they understood the tools as support to iteratively refine the documentation.
Further research is needed to understand which prompting skills and preferences
developers have and which support they need for certain tasks.

摘要：大型語言模型 (LLM) 具有自動化繁瑣開發任務（例如建立和維護程式碼文件）的巨大潛力。然而，目前尚不清楚開發人員在多大程度上可以有效地提示 LLM 建立簡潔且有用的文件。我們報告了一項受控實驗，有 20 位專業人員和 30 位電腦科學系學生負責為兩個 Python 函數建立程式碼文件。實驗組在類似 ChatGPT 的 Visual Studio Code 擴充功能中自由輸入臨時提示，而對照組則執行預先定義的少量提示。我們的結果顯示，專業人員和學生不知道或無法應用提示工程技術。特別是學生認為根據臨時提示產生的文件顯著低於根據準備好的提示產生的文件，可讀性、簡潔性和有幫助性都較低。一些專業人員僅在臨時提示中加入 Docstring 關鍵字，就產生了更高品質的文件。雖然學生希望在制定提示時獲得更多支援，但專業人員則欣賞臨時提示的靈活性。這兩組的參與者很少將輸出評估為完美。相反地，他們將這些工具視為反覆修改文件的支援。需要進一步研究以了解開發人員具備哪些提示技能和偏好，以及他們在某些任務中需要哪些支援。

##### **Assessing the Variety of a Concept Space Using an Unbiased Estimate of Rao's Quadratic Index**
2408.00684v1 by Anubhab Majumder, Ujjwal Pal, Amaresh Chakrabarti

Past research relates design creativity to 'divergent thinking,' i.e., how
well the concept space is explored during the early phase of design.
Researchers have argued that generating several concepts would increase the
chances of producing better design solutions. 'Variety' is one of the
parameters by which one can quantify the breadth of a concept space explored by
the designers. It is useful to assess variety at the conceptual design stage
because, at this stage, designers have the freedom to explore different
solution principles so as to satisfy a design problem with substantially novel
concepts. This article elaborates on and critically examines the existing
variety metrics from the engineering design literature, discussing their
limitations. A new distance-based variety metric is proposed, along with a
prescriptive framework to support the assessment process. This framework uses
the SAPPhIRE model of causality as a knowledge representation scheme to measure
the real-valued distance between two design concepts. The proposed framework is
implemented in a software tool called 'VariAnT.' Furthermore, the tool's
application is demonstrated through an illustrative example.

摘要：過去的研究將設計創意與「發散性思考」聯繫起來，亦即在設計的早期階段，概念空間探索得有多好。研究人員主張，產生多個概念將增加產生更好設計解決方案的機會。「多樣性」是其中一個參數，設計人員可以用來量化他們探索的概念空間廣度。在概念設計階段評估多樣性很有用，因為在這個階段，設計人員有自由探索不同的解決方案原則，以滿足實質上具有新穎概念的設計問題。本文詳細說明並批判性地審查工程設計文獻中現有的多樣性指標，並討論它們的限制。提出了一種新的基於距離的多樣性指標，以及一個規範性框架來支持評估過程。這個框架使用 SAPPhIRE 因果關係模型作為知識表示方案，來測量兩個設計概念之間的實值距離。所提出的框架在稱為「VariAnT」的軟體工具中實作。此外，透過一個說明性範例展示了該工具的應用。

##### **Learning in Multi-Objective Public Goods Games with Non-Linear Utilities**
2408.00682v1 by Nicole Orzan, Erman Acar, Davide Grossi, Patrick Mannion, Roxana Rădulescu

Addressing the question of how to achieve optimal decision-making under risk
and uncertainty is crucial for enhancing the capabilities of artificial agents
that collaborate with or support humans. In this work, we address this question
in the context of Public Goods Games. We study learning in a novel
multi-objective version of the Public Goods Game where agents have different
risk preferences, by means of multi-objective reinforcement learning. We
introduce a parametric non-linear utility function to model risk preferences at
the level of individual agents, over the collective and individual reward
components of the game. We study the interplay between such preference
modelling and environmental uncertainty on the incentive alignment level in the
game. We demonstrate how different combinations of individual preferences and
environmental uncertainties sustain the emergence of cooperative patterns in
non-cooperative environments (i.e., where competitive strategies are dominant),
while others sustain competitive patterns in cooperative environments (i.e.,
where cooperative strategies are dominant).

摘要：探討如何在風險和不確定性下達成最佳決策，對於提升與人類合作或支援人類的人工智慧代理能力至關重要。在這項研究中，我們在公共財博弈的背景下探討這個問題。我們透過多目標強化學習，研究在公共財博弈的新穎多目標版本中學習。我們引入一個參數非線性效用函數，以在個人代理層級對風險偏好進行建模，涵蓋博弈的集體和個人獎勵組成部分。我們研究此類偏好建模與環境不確定性在博弈中激勵對齊層級之間的交互作用。我們展示了個人偏好和環境不確定性的不同組合如何在非合作環境中維持合作模式的出現（即競爭策略佔主導地位），而其他組合如何在合作環境中維持競爭模式（即合作策略佔主導地位）。

##### **Leveraging Entailment Judgements in Cross-Lingual Summarisation**
2408.00675v1 by Huajian Zhang, Laura Perez-Beltrachini

Synthetically created Cross-Lingual Summarisation (CLS) datasets are prone to
include document-summary pairs where the reference summary is unfaithful to the
corresponding document as it contains content not supported by the document
(i.e., hallucinated content). This low data quality misleads model learning and
obscures evaluation results. Automatic ways to assess hallucinations and
improve training have been proposed for monolingual summarisation,
predominantly in English. For CLS, we propose to use off-the-shelf
cross-lingual Natural Language Inference (X-NLI) to evaluate faithfulness of
reference and model generated summaries. Then, we study training approaches
that are aware of faithfulness issues in the training data and propose an
approach that uses unlikelihood loss to teach a model about unfaithful summary
sequences. Our results show that it is possible to train CLS models that yield
more faithful summaries while maintaining comparable or better informativess.

摘要：合成建立的跨語言摘要 (CLS) 資料集容易包含文件摘要對，其中參考摘要對應文件不忠實，因為它包含文件不支援的內容（即幻覺內容）。這種低資料品質會誤導模型學習，並掩蓋評估結果。已經提出用於單語言摘要的自動方法來評估幻覺並改善訓練，主要用於英文。對於 CLS，我們建議使用現成的跨語言自然語言推論 (X-NLI) 來評估參考和模型產生的摘要的忠實度。然後，我們研究了訓練方法，這些方法了解訓練資料中的忠實度問題，並提出了一種使用不似然損失來教導模型有關不忠實摘要序列的方法。我們的結果表明，訓練 CLS 模型是可能的，這些模型會產生更忠實的摘要，同時保持可比性或更好的資訊性。

