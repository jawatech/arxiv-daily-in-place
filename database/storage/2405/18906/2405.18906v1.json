{"2405.18906": {"publish_time": "2024-05-29", "title": "Language Generation with Strictly Proper Scoring Rules", "paper_summary": "Language generation based on maximum likelihood estimation (MLE) has become\nthe fundamental approach for text generation. Maximum likelihood estimation is\ntypically performed by minimizing the log-likelihood loss, also known as the\nlogarithmic score in statistical decision theory. The logarithmic score is\nstrictly proper in the sense that it encourages honest forecasts, where the\nexpected score is maximized only when the model reports true probabilities.\nAlthough many strictly proper scoring rules exist, the logarithmic score is the\nonly local scoring rule among them that depends exclusively on the probability\nof the observed sample, making it capable of handling the exponentially large\nsample space of natural text. In this work, we propose a straightforward\nstrategy for adapting scoring rules to language generation, allowing for\nlanguage modeling with any non-local scoring rules. Leveraging this strategy,\nwe train language generation models using two classic strictly proper scoring\nrules, the Brier score and the Spherical score, as alternatives to the\nlogarithmic score. Experimental results indicate that simply substituting the\nloss function, without adjusting other hyperparameters, can yield substantial\nimprovements in model's generation capabilities. Moreover, these improvements\ncan scale up to large language models (LLMs) such as LLaMA-7B and LLaMA-13B.\nSource code: \\url{https://github.com/shaochenze/ScoringRulesLM}.", "paper_summary_zh": "\u57fa\u65bc\u6700\u5927\u4f3c\u7136\u4f30\u8a08 (MLE) \u7684\u8a9e\u8a00\u751f\u6210\u5df2\u6210\u70ba\u6587\u672c\u751f\u6210\u7684\u57fa\u790e\u65b9\u6cd5\u3002\u6700\u5927\u4f3c\u7136\u4f30\u8a08\u901a\u5e38\u900f\u904e\u6700\u5c0f\u5316\u5c0d\u6578\u4f3c\u7136\u640d\u5931\u4f86\u57f7\u884c\uff0c\u9019\u5728\u7d71\u8a08\u6c7a\u7b56\u7406\u8ad6\u4e2d\u4e5f\u7a31\u70ba\u5c0d\u6578\u5f97\u5206\u3002\u5c0d\u6578\u5f97\u5206\u5728\u56b4\u683c\u610f\u7fa9\u4e0a\u662f\u9069\u7576\u7684\uff0c\u56e0\u70ba\u5b83\u9f13\u52f5\u8aa0\u5be6\u7684\u9810\u6e2c\uff0c\u5176\u4e2d\u9810\u671f\u5f97\u5206\u50c5\u5728\u6a21\u578b\u5831\u544a\u771f\u5be6\u6a5f\u7387\u6642\u6700\u5927\u5316\u3002\u5118\u7ba1\u5b58\u5728\u8a31\u591a\u56b4\u683c\u9069\u7576\u7684\u8a55\u5206\u898f\u5247\uff0c\u4f46\u5c0d\u6578\u5f97\u5206\u662f\u5176\u4e2d\u552f\u4e00\u50c5\u4f9d\u8cf4\u65bc\u89c0\u5bdf\u6a23\u672c\u6a5f\u7387\u7684\u5c40\u90e8\u8a55\u5206\u898f\u5247\uff0c\u4f7f\u5176\u80fd\u5920\u8655\u7406\u81ea\u7136\u6587\u672c\u7684\u6307\u6578\u7d1a\u5927\u578b\u6a23\u672c\u7a7a\u9593\u3002\u5728\u9019\u9805\u5de5\u4f5c\u4e2d\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u4e00\u500b\u5c07\u8a55\u5206\u898f\u5247\u9069\u61c9\u8a9e\u8a00\u751f\u6210\u7684\u76f4\u63a5\u7b56\u7565\uff0c\u5141\u8a31\u4f7f\u7528\u4efb\u4f55\u975e\u5c40\u90e8\u8a55\u5206\u898f\u5247\u9032\u884c\u8a9e\u8a00\u5efa\u6a21\u3002\u5229\u7528\u6b64\u7b56\u7565\uff0c\u6211\u5011\u4f7f\u7528\u5169\u500b\u7d93\u5178\u7684\u56b4\u683c\u9069\u7576\u8a55\u5206\u898f\u5247\uff08Brier \u5f97\u5206\u548c\u7403\u9762\u5f97\u5206\uff09\u8a13\u7df4\u8a9e\u8a00\u751f\u6210\u6a21\u578b\uff0c\u4f5c\u70ba\u5c0d\u6578\u5f97\u5206\u7684\u66ff\u4ee3\u65b9\u6848\u3002\u5be6\u9a57\u7d50\u679c\u8868\u660e\uff0c\u50c5\u66ff\u63db\u640d\u5931\u51fd\u6578\uff0c\u800c\u4e0d\u8abf\u6574\u5176\u4ed6\u8d85\u53c3\u6578\uff0c\u5c31\u80fd\u986f\u8457\u63d0\u5347\u6a21\u578b\u7684\u751f\u6210\u80fd\u529b\u3002\u6b64\u5916\uff0c\u9019\u4e9b\u6539\u9032\u53ef\u4ee5\u64f4\u5c55\u5230\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM)\uff0c\u4f8b\u5982 LLaMA-7B \u548c LLaMA-13B\u3002\u539f\u59cb\u78bc\uff1a\\url{https://github.com/shaochenze/ScoringRulesLM}\u3002", "author": "Chenze Shao et.al.", "authors": "Chenze Shao, Fandong Meng, Yijin Liu, Jie Zhou", "id": "2405.18906v1", "paper_url": "http://arxiv.org/abs/2405.18906v1", "repo": "https://github.com/shaochenze/scoringruleslm"}}