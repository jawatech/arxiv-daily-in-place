{"2408.02302": {"publish_time": "2024-08-05", "title": "SNFinLLM: Systematic and Nuanced Financial Domain Adaptation of Chinese Large Language Models", "paper_summary": "Large language models (LLMs) have become powerful tools for advancing natural\nlanguage processing applications in the financial industry. However, existing\nfinancial LLMs often face challenges such as hallucinations or superficial\nparameter training, resulting in suboptimal performance, particularly in\nfinancial computing and machine reading comprehension (MRC). To address these\nissues, we propose a novel large language model specifically designed for the\nChinese financial domain, named SNFinLLM. SNFinLLM excels in domain-specific\ntasks such as answering questions, summarizing financial research reports,\nanalyzing sentiment, and executing financial calculations. We then perform the\nsupervised fine-tuning (SFT) to enhance the model's proficiency across various\nfinancial domains. Specifically, we gather extensive financial data and create\na high-quality instruction dataset composed of news articles, professional\npapers, and research reports of finance domain. Utilizing both domain-specific\nand general datasets, we proceed with continuous pre-training on an established\nopen-source base model, resulting in SNFinLLM-base. Following this, we engage\nin supervised fine-tuning (SFT) to bolster the model's capability across\nmultiple financial tasks. Crucially, we employ a straightforward Direct\nPreference Optimization (DPO) method to better align the model with human\npreferences. Extensive experiments conducted on finance benchmarks and our\nevaluation dataset demonstrate that SNFinLLM markedly outperforms other\nstate-of-the-art financial language models. For more details, check out our\ndemo video here: https://www.youtube.com/watch?v=GYT-65HZwus.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u5df2\u6210\u70ba\u63a8\u52d5\u91d1\u878d\u696d\u81ea\u7136\u8a9e\u8a00\u8655\u7406\u61c9\u7528\u7a0b\u5f0f\u7684\u5f37\u5927\u5de5\u5177\u3002\u7136\u800c\uff0c\u73fe\u6709\u7684\u91d1\u878d LLM \u7d93\u5e38\u9762\u81e8\u5e7b\u89ba\u6216\u8868\u9762\u53c3\u6578\u8a13\u7df4\u7b49\u6311\u6230\uff0c\u5c0e\u81f4\u6b21\u4f73\u6548\u80fd\uff0c\u7279\u5225\u662f\u5728\u91d1\u878d\u904b\u7b97\u548c\u6a5f\u5668\u95b1\u8b80\u7406\u89e3 (MRC) \u4e2d\u3002\u70ba\u4e86\u89e3\u6c7a\u9019\u4e9b\u554f\u984c\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u4e00\u500b\u5c08\u9580\u70ba\u4e2d\u6587\u91d1\u878d\u9818\u57df\u8a2d\u8a08\u7684\u65b0\u578b\u5927\u578b\u8a9e\u8a00\u6a21\u578b\uff0c\u7a31\u70ba SNFinLLM\u3002SNFinLLM \u5728\u7279\u5b9a\u9818\u57df\u7684\u4efb\u52d9\u4e2d\u8868\u73fe\u51fa\u8272\uff0c\u4f8b\u5982\u56de\u7b54\u554f\u984c\u3001\u7e3d\u7d50\u8ca1\u52d9\u7814\u7a76\u5831\u544a\u3001\u5206\u6790\u60c5\u7dd2\u548c\u57f7\u884c\u8ca1\u52d9\u8a08\u7b97\u3002\u7136\u5f8c\uff0c\u6211\u5011\u57f7\u884c\u76e3\u7763\u5fae\u8abf (SFT) \u4ee5\u589e\u5f37\u6a21\u578b\u5728\u5404\u7a2e\u91d1\u878d\u9818\u57df\u7684\u719f\u7df4\u5ea6\u3002\u5177\u9ad4\u4f86\u8aaa\uff0c\u6211\u5011\u6536\u96c6\u5ee3\u6cdb\u7684\u8ca1\u52d9\u6578\u64da\uff0c\u4e26\u5efa\u7acb\u4e00\u500b\u7531\u65b0\u805e\u6587\u7ae0\u3001\u5c08\u696d\u8ad6\u6587\u548c\u91d1\u878d\u9818\u57df\u7814\u7a76\u5831\u544a\u7d44\u6210\u7684\u9ad8\u54c1\u8cea\u6307\u4ee4\u6578\u64da\u96c6\u3002\u5229\u7528\u7279\u5b9a\u9818\u57df\u548c\u4e00\u822c\u6578\u64da\u96c6\uff0c\u6211\u5011\u7e7c\u7e8c\u5728\u5df2\u5efa\u7acb\u7684\u958b\u6e90\u57fa\u790e\u6a21\u578b\u4e0a\u9032\u884c\u6301\u7e8c\u9810\u8a13\u7df4\uff0c\u7522\u751f SNFinLLM-base\u3002\u5728\u6b64\u4e4b\u5f8c\uff0c\u6211\u5011\u9032\u884c\u76e3\u7763\u5fae\u8abf (SFT) \u4ee5\u52a0\u5f37\u6a21\u578b\u5728\u591a\u9805\u8ca1\u52d9\u4efb\u52d9\u4e2d\u7684\u80fd\u529b\u3002\u81f3\u95dc\u91cd\u8981\u7684\u662f\uff0c\u6211\u5011\u63a1\u7528\u76f4\u63a5\u504f\u597d\u6700\u4f73\u5316 (DPO) \u65b9\u6cd5\uff0c\u4ee5\u66f4\u597d\u5730\u5c07\u6a21\u578b\u8207\u4eba\u985e\u504f\u597d\u4fdd\u6301\u4e00\u81f4\u3002\u5728\u91d1\u878d\u57fa\u6e96\u548c\u6211\u5011\u7684\u8a55\u4f30\u6578\u64da\u96c6\u4e0a\u9032\u884c\u7684\u5ee3\u6cdb\u5be6\u9a57\u8868\u660e\uff0cSNFinLLM \u660e\u986f\u512a\u65bc\u5176\u4ed6\u6700\u5148\u9032\u7684\u91d1\u878d\u8a9e\u8a00\u6a21\u578b\u3002\u6709\u95dc\u66f4\u591a\u8a73\u7d30\u8cc7\u8a0a\uff0c\u8acb\u5728\u6b64\u8655\u67e5\u770b\u6211\u5011\u7684\u793a\u7bc4\u5f71\u7247\uff1ahttps://www.youtube.com/watch?v=GYT-65HZwus\u3002", "author": "Shujuan Zhao et.al.", "authors": "Shujuan Zhao, Lingfeng Qiao, Kangyang Luo, Qian-Wen Zhang, Junru Lu, Di Yin", "id": "2408.02302v1", "paper_url": "http://arxiv.org/abs/2408.02302v1", "repo": "null"}}