
### LLM
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2025-01-14**|**PokerBench: Training Large Language Models to become Professional Poker Players**|Richard Zhuang et.al.|[2501.08328v1](http://arxiv.org/abs/2501.08328v1)|[link](https://github.com/pokerllm/pokerbench)|
|**2025-01-14**|**ADAM-1: AI and Bioinformatics for Alzheimer's Detection and Microbiome-Clinical Data Integrations**|Ziyuan Huang et.al.|[2501.08324v1](http://arxiv.org/abs/2501.08324v1)|null|
|**2025-01-14**|**Exploring Robustness of Multilingual LLMs on Real-World Noisy Data**|Amirhossein Aliakbarzadeh et.al.|[2501.08322v1](http://arxiv.org/abs/2501.08322v1)|[link](https://github.com/caisa-lab/llms-real-world-noise-robustness)|
|**2025-01-14**|**Enhancing Automated Interpretability with Output-Centric Feature Descriptions**|Yoav Gur-Arieh et.al.|[2501.08319v1](http://arxiv.org/abs/2501.08319v1)|[link](https://github.com/yoavgur/feature-descriptions)|
|**2025-01-14**|**Diffusion Adversarial Post-Training for One-Step Video Generation**|Shanchuan Lin et.al.|[2501.08316v1](http://arxiv.org/abs/2501.08316v1)|null|
|**2025-01-14**|**MiniMax-01: Scaling Foundation Models with Lightning Attention**|MiniMax et.al.|[2501.08313v1](http://arxiv.org/abs/2501.08313v1)|null|
|**2025-01-14**|**Everybody Likes to Sleep: A Computer-Assisted Comparison of Object Naming Data from 30 Languages**|Alžběta Kučerová et.al.|[2501.08312v1](http://arxiv.org/abs/2501.08312v1)|[link](https://github.com/calc-project/object-naming-data)|
|**2025-01-14**|**Polynomial Threshold Functions of Bounded Tree-Width: Some Explainability and Complexity Aspects**|Karine Chubarian et.al.|[2501.08297v1](http://arxiv.org/abs/2501.08297v1)|null|
|**2025-01-14**|**HALoGEN: Fantastic LLM Hallucinations and Where to Find Them**|Abhilasha Ravichander et.al.|[2501.08292v1](http://arxiv.org/abs/2501.08292v1)|null|
|**2025-01-14**|**AfriHate: A Multilingual Collection of Hate Speech and Abusive Language Datasets for African Languages**|Shamsuddeen Hassan Muhammad et.al.|[2501.08284v1](http://arxiv.org/abs/2501.08284v1)|null|
|**2025-01-14**|**Exploring Robustness of LLMs to Sociodemographically-Conditioned Paraphrasing**|Pulkit Arora et.al.|[2501.08276v1](http://arxiv.org/abs/2501.08276v1)|null|
|**2025-01-14**|**Comparative Analysis of Efficient Adapter-Based Fine-Tuning of State-of-the-Art Transformer Models**|Saad Mashkoor Siddiqui et.al.|[2501.08271v1](http://arxiv.org/abs/2501.08271v1)|null|
|**2025-01-14**|**AI Driven Water Segmentation with deep learning models for Enhanced Flood Monitoring**|Sanjida Afrin Mou et.al.|[2501.08266v1](http://arxiv.org/abs/2501.08266v1)|[link](https://github.com/SanjidaAfrin25/flood-detection-using-deepLab-unet-resnet)|
|**2025-01-14**|**Eliciting In-context Retrieval and Reasoning for Long-context Large Language Models**|Yifu Qiu et.al.|[2501.08248v1](http://arxiv.org/abs/2501.08248v1)|null|
|**2025-01-14**|**A Feature-Level Ensemble Model for COVID-19 Identification in CXR Images using Choquet Integral and Differential Evolution Optimization**|Amir Reza Takhsha et.al.|[2501.08241v1](http://arxiv.org/abs/2501.08241v1)|null|
|**2025-01-14**|**Dynamic Pricing in High-Speed Railways Using Multi-Agent Reinforcement Learning**|Enrique Adrian Villarrubia-Martin et.al.|[2501.08234v1](http://arxiv.org/abs/2501.08234v1)|null|
|**2025-01-14**|**ASTRID -- An Automated and Scalable TRIaD for the Evaluation of RAG-based Clinical Question Answering Systems**|Mohita Chowdhury et.al.|[2501.08208v1](http://arxiv.org/abs/2501.08208v1)|null|
|**2025-01-14**|**Modeling Feature Maps for Quantum Machine Learning**|Navneet Singh et.al.|[2501.08205v1](http://arxiv.org/abs/2501.08205v1)|null|
|**2025-01-14**|**ArithmAttack: Evaluating Robustness of LLMs to Noisy Context in Math Problem Solving**|Zain Ul Abedin et.al.|[2501.08203v1](http://arxiv.org/abs/2501.08203v1)|null|
|**2025-01-14**|**CWEval: Outcome-driven Evaluation on Functionality and Security of LLM Code Generation**|Jinjun Peng et.al.|[2501.08200v1](http://arxiv.org/abs/2501.08200v1)|null|
|**2025-01-14**|**EmoNeXt: an Adapted ConvNeXt for Facial Emotion Recognition**|Yassine El Boudouri et.al.|[2501.08199v1](http://arxiv.org/abs/2501.08199v1)|[link](https://github.com/yelboudouri/EmoNeXt)|
|**2025-01-14**|**OpenCSG Chinese Corpus: A Series of High-quality Chinese Datasets for LLM Training**|Yijiong Yu et.al.|[2501.08197v1](http://arxiv.org/abs/2501.08197v1)|[link](https://github.com/yuyijiong/fineweb-edu-chinese)|
|**2025-01-14**|**PRESERVE: Prefetching Model Weights and KV-Cache in Distributed LLM Serving**|Ahmet Caner Yüzügüler et.al.|[2501.08192v1](http://arxiv.org/abs/2501.08192v1)|null|
|**2025-01-14**|**A Critical Synthesis of Uncertainty Quantification and Foundation Models in Monocular Depth Estimation**|Steven Landgraf et.al.|[2501.08188v1](http://arxiv.org/abs/2501.08188v1)|null|
|**2025-01-14**|**A Multi-Modal AI Copilot for Single-Cell Analysis with Instruction Following**|Yin Fang et.al.|[2501.08187v1](http://arxiv.org/abs/2501.08187v1)|null|
|**2025-01-14**|**Assessing AI Adoption and Digitalization in SMEs: A Framework for Implementation**|Serena Proietti et.al.|[2501.08184v1](http://arxiv.org/abs/2501.08184v1)|null|
|**2025-01-14**|**CG-MER: A Card Game-based Multimodal dataset for Emotion Recognition**|Nessrine Farhat et.al.|[2501.08182v1](http://arxiv.org/abs/2501.08182v1)|null|
|**2025-01-14**|**Revolutionizing Communication with Deep Learning and XAI for Enhanced Arabic Sign Language Recognition**|Mazen Balat et.al.|[2501.08169v1](http://arxiv.org/abs/2501.08169v1)|null|
|**2025-01-14**|**LeapVAD: A Leap in Autonomous Driving via Cognitive Perception and Dual-Process Thinking**|Yukai Ma et.al.|[2501.08168v1](http://arxiv.org/abs/2501.08168v1)|null|
|**2025-01-14**|**Potential and Perils of Large Language Models as Judges of Unstructured Textual Data**|Rewina Bedemariam et.al.|[2501.08167v1](http://arxiv.org/abs/2501.08167v1)|null|
|**2025-01-14**|**I Can Find You in Seconds! Leveraging Large Language Models for Code Authorship Attribution**|Soohyeon Choi et.al.|[2501.08165v1](http://arxiv.org/abs/2501.08165v1)|null|
|**2025-01-14**|**FairTTTS: A Tree Test Time Simulation Method for Fairness-Aware Classification**|Nurit Cohen-Inger et.al.|[2501.08155v1](http://arxiv.org/abs/2501.08155v1)|null|
|**2025-01-14**|**Multiple-Input Variational Auto-Encoder for Anomaly Detection in Heterogeneous Data**|Phai Vu Dinh et.al.|[2501.08149v1](http://arxiv.org/abs/2501.08149v1)|null|
|**2025-01-14**|**Refusal Behavior in Large Language Models: A Nonlinear Perspective**|Fabian Hildebrandt et.al.|[2501.08145v1](http://arxiv.org/abs/2501.08145v1)|null|
|**2025-01-14**|**An Empirical Wall-Pressure Spectrum Model for Aeroacoustic Predictions Based on Symbolic Regression**|Laura Botero Bolívar et.al.|[2501.08134v1](http://arxiv.org/abs/2501.08134v1)|null|
|**2025-01-14**|**In-situ graph reasoning and knowledge expansion using Graph-PReFLexOR**|Markus J. Buehler et.al.|[2501.08120v1](http://arxiv.org/abs/2501.08120v1)|null|
|**2025-01-14**|**Data-driven inventory management for new products: A warm-start and adjusted Dyna-$Q$ approach**|Xinyu Qu et.al.|[2501.08109v1](http://arxiv.org/abs/2501.08109v1)|null|
|**2025-01-14**|**Consistency of Responses and Continuations Generated by Large Language Models on Social Media**|Wenlu Fan et.al.|[2501.08102v1](http://arxiv.org/abs/2501.08102v1)|null|
|**2025-01-14**|**Hierarchical Autoscaling for Large Language Model Serving with Chiron**|Archit Patke et.al.|[2501.08090v1](http://arxiv.org/abs/2501.08090v1)|null|
|**2025-01-14**|**NOMTO: Neural Operator-based symbolic Model approximaTion and discOvery**|Sergei Garmaev et.al.|[2501.08086v1](http://arxiv.org/abs/2501.08086v1)|null|
|**2025-01-14**|**Dynamic Multimodal Sentiment Analysis: Leveraging Cross-Modal Attention for Enabled Classification**|Hui Lee et.al.|[2501.08085v1](http://arxiv.org/abs/2501.08085v1)|null|
|**2025-01-14**|**Artificial Liver Classifier: A New Alternative to Conventional Machine Learning Models**|Mahmood A. Jumaah et.al.|[2501.08074v1](http://arxiv.org/abs/2501.08074v1)|null|
|**2025-01-14**|**A Roadmap to Guide the Integration of LLMs in Hierarchical Planning**|Israel Puerta-Merino et.al.|[2501.08068v1](http://arxiv.org/abs/2501.08068v1)|null|
|**2025-01-14**|**Optimizing Speech Multi-View Feature Fusion through Conditional Computation**|Weiqiao Shan et.al.|[2501.08057v1](http://arxiv.org/abs/2501.08057v1)|null|
|**2025-01-14**|**Exploring Narrative Clustering in Large Language Models: A Layerwise Analysis of BERT**|Awritrojit Banerjee et.al.|[2501.08053v1](http://arxiv.org/abs/2501.08053v1)|null|
|**2025-01-14**|**Exploring visual language models as a powerful tool in the diagnosis of Ewing Sarcoma**|Alvaro Pastor-Naranjo et.al.|[2501.08042v1](http://arxiv.org/abs/2501.08042v1)|null|
|**2025-01-14**|**READ: Reinforcement-based Adversarial Learning for Text Classification with Limited Labeled Data**|Rohit Sharma et.al.|[2501.08035v1](http://arxiv.org/abs/2501.08035v1)|null|
|**2025-01-14**|**Cooperative Patrol Routing: Optimizing Urban Crime Surveillance through Multi-Agent Reinforcement Learning**|Juan Palma-Borda et.al.|[2501.08020v1](http://arxiv.org/abs/2501.08020v1)|null|
|**2025-01-14**|**An AI-driven framework for rapid and localized optimizations of urban open spaces**|Pegah Eshraghi et.al.|[2501.08019v1](http://arxiv.org/abs/2501.08019v1)|null|
|**2025-01-14**|**TriAdaptLoRA: Brain-Inspired Triangular Adaptive Low-Rank Adaptation for Parameter-Efficient Fine-Tuning**|Yao Liang et.al.|[2501.08008v1](http://arxiv.org/abs/2501.08008v1)|null|
|**2025-01-14**|**DisCoPatch: Batch Statistics Are All You Need For OOD Detection, But Only If You Can Trust Them**|Francisco Caetano et.al.|[2501.08005v1](http://arxiv.org/abs/2501.08005v1)|null|
|**2025-01-14**|**Maximizing Uncertainty for Federated learning via Bayesian Optimisation-based Model Poisoning**|Marios Aristodemou et.al.|[2501.08002v1](http://arxiv.org/abs/2501.08002v1)|null|
|**2025-01-14**|**GDiffRetro: Retrosynthesis Prediction with Dual Graph Enhanced Molecular Representation and Diffusion Generation**|Shengyin Sun et.al.|[2501.08001v1](http://arxiv.org/abs/2501.08001v1)|[link](https://github.com/sunshy-1/gdiffretro)|
|**2025-01-14**|**LLM-Ehnanced Holonic Architecture for Ad-Hoc Scalable SoS**|Muhammad Ashfaq et.al.|[2501.07992v1](http://arxiv.org/abs/2501.07992v1)|null|
|**2025-01-14**|**Training Hybrid Neural Networks with Multimode Optical Nonlinearities Using Digital Twins**|Ilker Oguz et.al.|[2501.07991v1](http://arxiv.org/abs/2501.07991v1)|null|
|**2025-01-14**|**Facial Dynamics in Video: Instruction Tuning for Improved Facial Expression Perception and Contextual Awareness**|Jiaxing Zhao et.al.|[2501.07978v1](http://arxiv.org/abs/2501.07978v1)|null|
|**2025-01-14**|**Comprehensive Metapath-based Heterogeneous Graph Transformer for Gene-Disease Association Prediction**|Wentao Cui et.al.|[2501.07970v1](http://arxiv.org/abs/2501.07970v1)|null|
|**2025-01-14**|**Self-Instruct Few-Shot Jailbreaking: Decompose the Attack into Pattern and Behavior Learning**|Jiaqi Hua et.al.|[2501.07959v1](http://arxiv.org/abs/2501.07959v1)|[link](https://github.com/iphosi/self-instruct-fsj)|
|**2025-01-14**|**AI Guide Dog: Egocentric Path Prediction on Smartphone**|Aishwarya Jadhav et.al.|[2501.07957v1](http://arxiv.org/abs/2501.07957v1)|null|
|**2025-01-14**|**Early prediction of the transferability of bovine embryos from videomicroscopy**|Yasmine Hachani et.al.|[2501.07945v1](http://arxiv.org/abs/2501.07945v1)|null|
|**2025-01-14**|**Advice for Diabetes Self-Management by ChatGPT Models: Challenges and Recommendations**|Waqar Hussain et.al.|[2501.07931v1](http://arxiv.org/abs/2501.07931v1)|null|
|**2025-01-14**|**An Adaptive Orthogonal Convolution Scheme for Efficient and Flexible CNN Architectures**|Thibaut Boissin et.al.|[2501.07930v1](http://arxiv.org/abs/2501.07930v1)|[link](https://github.com/thib-s/orthogonium)|
|**2025-01-14**|**Gandalf the Red: Adaptive Security for LLMs**|Niklas Pfister et.al.|[2501.07927v1](http://arxiv.org/abs/2501.07927v1)|null|
|**2025-01-14**|**Exploring Aviation Incident Narratives Using Topic Modeling and Clustering Techniques**|Aziida Nanyonga et.al.|[2501.07924v1](http://arxiv.org/abs/2501.07924v1)|null|
|**2025-01-14**|**Aviation Safety Enhancement via NLP & Deep Learning: Classifying Flight Phases in ATSB Safety Reports**|Aziida Nanyonga et.al.|[2501.07923v1](http://arxiv.org/abs/2501.07923v1)|null|
|**2025-01-14**|**Large Language Model Interface for Home Energy Management Systems**|François Michelon et.al.|[2501.07919v1](http://arxiv.org/abs/2501.07919v1)|null|
|**2025-01-14**|**Deep Learning and Natural Language Processing in the Field of Construction**|Rémy Kessler et.al.|[2501.07911v1](http://arxiv.org/abs/2501.07911v1)|null|
|**2025-01-14**|**Logarithmic Memory Networks (LMNs): Efficient Long-Range Sequence Modeling for Resource-Constrained Environments**|Mohamed A. Taha et.al.|[2501.07905v1](http://arxiv.org/abs/2501.07905v1)|[link](https://github.com/ahmedboin/logarithmicmemory)|
|**2025-01-14**|**Leveraging Metamemory Mechanisms for Enhanced Data-Free Code Generation in LLMs**|Shuai Wang et.al.|[2501.07892v1](http://arxiv.org/abs/2501.07892v1)|null|
|**2025-01-14**|**GRAPHMOE: Amplifying Cognitive Depth of Mixture-of-Experts Network via Introducing Self-Rethinking Mechanism**|Chen Tang et.al.|[2501.07890v1](http://arxiv.org/abs/2501.07890v1)|null|
|**2025-01-14**|**Tarsier2: Advancing Large Vision-Language Models from Detailed Video Description to Comprehensive Video Understanding**|Liping Yuan et.al.|[2501.07888v1](http://arxiv.org/abs/2501.07888v1)|null|
|**2025-01-14**|**Iterative Label Refinement Matters More than Preference Optimization under Weak Supervision**|Yaowen Ye et.al.|[2501.07886v1](http://arxiv.org/abs/2501.07886v1)|[link](https://github.com/helloelwin/iterative-label-refinement)|
|**2025-01-14**|**Continual Learning with Embedding Layer Surgery and Task-wise Beam Search using Whisper**|Chin Yuen Kwok et.al.|[2501.07875v1](http://arxiv.org/abs/2501.07875v1)|null|
|**2025-01-14**|**ReARTeR: Retrieval-Augmented Reasoning with Trustworthy Process Rewarding**|Zhongxiang Sun et.al.|[2501.07861v1](http://arxiv.org/abs/2501.07861v1)|null|
|**2025-01-14**|**Hierarchical Repository-Level Code Summarization for Business Applications Using Local LLMs**|Nilesh Dhulshette et.al.|[2501.07857v1](http://arxiv.org/abs/2501.07857v1)|null|
|**2025-01-14**|**State-of-the-Art Transformer Models for Image Super-Resolution: Techniques, Challenges, and Applications**|Debasish Dutta et.al.|[2501.07855v1](http://arxiv.org/abs/2501.07855v1)|null|
|**2025-01-14**|**Optimizing Language Models for Grammatical Acceptability: A Comparative Study of Fine-Tuning Techniques**|Shobhit Ratan et.al.|[2501.07853v1](http://arxiv.org/abs/2501.07853v1)|null|
|**2025-01-14**|**Unveiling Provider Bias in Large Language Models for Code Generation**|Xiaoyu Zhang et.al.|[2501.07849v1](http://arxiv.org/abs/2501.07849v1)|null|
|**2025-01-14**|**Reasoning with Graphs: Structuring Implicit Knowledge to Enhance LLMs Reasoning**|Haoyu Han et.al.|[2501.07845v1](http://arxiv.org/abs/2501.07845v1)|null|
|**2025-01-14**|**A Driver Advisory System Based on Large Language Model for High-speed Train**|Y. C. Luo et.al.|[2501.07837v1](http://arxiv.org/abs/2501.07837v1)|null|
|**2025-01-14**|**Flow: A Modular Approach to Automated Agentic Workflow Generation**|Boye Niu et.al.|[2501.07834v1](http://arxiv.org/abs/2501.07834v1)|null|
|**2025-01-14**|**Real-time Verification and Refinement of Language Model Text Generation**|Joonho Ko et.al.|[2501.07824v1](http://arxiv.org/abs/2501.07824v1)|null|
|**2025-01-14**|**A Multi-Encoder Frozen-Decoder Approach for Fine-Tuning Large Language Models**|Kaustubh D. Dhole et.al.|[2501.07818v1](http://arxiv.org/abs/2501.07818v1)|null|
|**2025-01-14**|**Agent-Centric Projection of Prompting Techniques and Implications for Synthetic Training Data for Large Language Models**|Dhruv Dhamani et.al.|[2501.07815v1](http://arxiv.org/abs/2501.07815v1)|null|
|**2025-01-14**|**STTS-EAD: Improving Spatio-Temporal Learning Based Time Series Prediction via**|Yuanyuan Liang et.al.|[2501.07814v1](http://arxiv.org/abs/2501.07814v1)|null|
|**2025-01-14**|**Talk to Right Specialists: Routing and Planning in Multi-agent System for Question Answering**|Feijie Wu et.al.|[2501.07813v1](http://arxiv.org/abs/2501.07813v1)|null|
|**2025-01-14**|**Conformal mapping Coordinates Physics-Informed Neural Networks (CoCo-PINNs): learning neural networks for designing neutral inclusions**|Daehee Cho et.al.|[2501.07809v1](http://arxiv.org/abs/2501.07809v1)|null|
|**2025-01-14**|**A Low-cost and Ultra-lightweight Binary Neural Network for Traffic Signal Recognition**|Mingke Xiao et.al.|[2501.07808v1](http://arxiv.org/abs/2501.07808v1)|null|
|**2025-01-14**|**Visual Language Models as Operator Agents in the Space Domain**|Alejandro Carrasco et.al.|[2501.07802v1](http://arxiv.org/abs/2501.07802v1)|null|
|**2025-01-14**|**A Comparative Analysis of DNN-based White-Box Explainable AI Methods in Network Security**|Osvaldo Arreche et.al.|[2501.07801v1](http://arxiv.org/abs/2501.07801v1)|null|
|**2025-01-14**|**BioPose: Biomechanically-accurate 3D Pose Estimation from Monocular Videos**|Farnoosh Koleini et.al.|[2501.07800v1](http://arxiv.org/abs/2501.07800v1)|null|
|**2025-01-14**|**Parameter-Inverted Image Pyramid Networks for Visual Perception and Multimodal Understanding**|Zhaokai Wang et.al.|[2501.07783v1](http://arxiv.org/abs/2501.07783v1)|[link](https://github.com/opengvlab/piip)|
|**2025-01-14**|**Transforming Indoor Localization: Advanced Transformer Architecture for NLOS Dominated Wireless Environments with Distributed Sensors**|Saad Masrur et.al.|[2501.07774v1](http://arxiv.org/abs/2501.07774v1)|null|
|**2025-01-14**|**Large Language Models for Knowledge Graph Embedding Techniques, Methods, and Challenges: A Survey**|Bingchen Liu et.al.|[2501.07766v1](http://arxiv.org/abs/2501.07766v1)|null|
|**2025-01-14**|**Deep Learning for Disease Outbreak Prediction: A Robust Early Warning Signal for Transcritical Bifurcations**|Reza Miry et.al.|[2501.07764v1](http://arxiv.org/abs/2501.07764v1)|null|
|**2025-01-14**|**On the Statistical Capacity of Deep Generative Models**|Edric Tam et.al.|[2501.07763v1](http://arxiv.org/abs/2501.07763v1)|[link](https://github.com/edrictam/generative_capacity)|
|**2025-01-14**|**Impatient Bandits: Optimizing for the Long-Term Without Delay**|Kelly W. Zhang et.al.|[2501.07761v1](http://arxiv.org/abs/2501.07761v1)|null|
|**2025-01-13**|**Performance Optimization of Ratings-Based Reinforcement Learning**|Evelyn Rose et.al.|[2501.07755v1](http://arxiv.org/abs/2501.07755v1)|null|
|**2025-01-13**|**Rethinking AI Cultural Evaluation**|Michal Bravansky et.al.|[2501.07751v1](http://arxiv.org/abs/2501.07751v1)|null|
|**2025-01-13**|**Advancing Student Writing Through Automated Syntax Feedback**|Kamyar Zeinalipour et.al.|[2501.07740v1](http://arxiv.org/abs/2501.07740v1)|null|

#### Abstracts
##### **PokerBench: Training Large Language Models to become Professional Poker Players**
2501.08328v1 by Richard Zhuang, Akshat Gupta, Richard Yang, Aniket Rahane, Zhengyu Li, Gopala Anumanchipalli

We introduce PokerBench - a benchmark for evaluating the poker-playing
abilities of large language models (LLMs). As LLMs excel in traditional NLP
tasks, their application to complex, strategic games like poker poses a new
challenge. Poker, an incomplete information game, demands a multitude of skills
such as mathematics, reasoning, planning, strategy, and a deep understanding of
game theory and human psychology. This makes Poker the ideal next frontier for
large language models. PokerBench consists of a comprehensive compilation of
11,000 most important scenarios, split between pre-flop and post-flop play,
developed in collaboration with trained poker players. We evaluate prominent
models including GPT-4, ChatGPT 3.5, and various Llama and Gemma series models,
finding that all state-of-the-art LLMs underperform in playing optimal poker.
However, after fine-tuning, these models show marked improvements. We validate
PokerBench by having models with different scores compete with each other,
demonstrating that higher scores on PokerBench lead to higher win rates in
actual poker games. Through gameplay between our fine-tuned model and GPT-4, we
also identify limitations of simple supervised fine-tuning for learning optimal
playing strategy, suggesting the need for more advanced methodologies for
effectively training language models to excel in games. PokerBench thus
presents a unique benchmark for a quick and reliable evaluation of the
poker-playing ability of LLMs as well as a comprehensive benchmark to study the
progress of LLMs in complex game-playing scenarios. The dataset and code will
be made available at: \url{https://github.com/pokerllm/pokerbench}.

摘要：<paragraph>我們推出 PokerBench - 一個用於評估大型語言模型 (LLM) 的撲克遊戲能力的基準。由於 LLM 在傳統 NLP 任務中表現出色，因此將其應用於撲克等複雜的策略遊戲構成了一項新的挑戰。撲克是一種不完全資訊遊戲，需要大量的技能，例如數學、推理、規劃、策略，以及對博弈論和人類心理學的深入理解。這使得撲克成為大型語言模型的理想下一個前沿。PokerBench 包含 11,000 個最重要的場景的綜合彙編，分為翻牌前和翻牌後遊戲，並與訓練有素的撲克玩家合作開發。我們評估了包括 GPT-4、ChatGPT 3.5 以及各種 Llama 和 Gemma 系列模型在內的知名模型，發現所有最先進的 LLM 在玩最佳撲克時表現不佳。然而，在微調後，這些模型顯示出顯著的改進。我們通過讓具有不同分數的模型相互競爭來驗證 PokerBench，證明 PokerBench 上較高的分數會導致實際撲克遊戲中較高的獲勝率。通過我們微調的模型和 GPT-4 之間的遊戲，我們還發現了簡單的監督微調在學習最佳遊戲策略方面的局限性，這表明需要更先進的方法來有效地訓練語言模型在遊戲中表現出色。因此，PokerBench 為快速可靠地評估 LLM 的撲克遊戲能力提供了一個獨特的基準，並提供了一個全面的基準來研究 LLM 在複雜遊戲場景中的進展。數據集和代碼將在以下位置提供：\url{https://github.com/pokerllm/pokerbench}。</paragraph>

##### **ADAM-1: AI and Bioinformatics for Alzheimer's Detection and Microbiome-Clinical Data Integrations**
2501.08324v1 by Ziyuan Huang, Vishaldeep Kaur Sekhon, Ouyang Guo, Mark Newman, Roozbeh Sadeghian, Maria L. Vaida, Cynthia Jo, Doyle Ward, Vanni Bucci, John P. Haran

The Alzheimer's Disease Analysis Model Generation 1 (ADAM) is a multi-agent
large language model (LLM) framework designed to integrate and analyze
multi-modal data, including microbiome profiles, clinical datasets, and
external knowledge bases, to enhance the understanding and detection of
Alzheimer's disease (AD). By leveraging retrieval-augmented generation (RAG)
techniques along with its multi-agent architecture, ADAM-1 synthesizes insights
from diverse data sources and contextualizes findings using literature-driven
evidence. Comparative evaluation against XGBoost revealed similar mean F1
scores but significantly reduced variance for ADAM-1, highlighting its
robustness and consistency, particularly in small laboratory datasets. While
currently tailored for binary classification tasks, future iterations aim to
incorporate additional data modalities, such as neuroimaging and biomarkers, to
broaden the scalability and applicability for Alzheimer's research and
diagnostics.

摘要：阿茲海默症分析模型生成 1 (ADAM) 是一個多代理大型語言模型 (LLM) 架構，旨在整合和分析多模式數據，包括微生物組特徵、臨床數據集和外部知識庫，以增進對阿茲海默症 (AD) 的理解和偵測。透過利用擷取增強生成 (RAG) 技術以及其多代理架構，ADAM-1 從不同的數據來源中綜合見解，並使用文獻驅動的證據對發現進行情境化。與 XGBoost 的比較評估顯示類似的平均 F1 分數，但 ADAM-1 的變異顯著降低，突顯其穩健性和一致性，特別是在小型實驗室數據集中。雖然目前針對二元分類任務進行調整，但未來的迭代旨在納入其他數據模式，例如神經影像和生物標記，以擴大阿茲海默症研究和診斷的可擴充性和適用性。

##### **Exploring Robustness of Multilingual LLMs on Real-World Noisy Data**
2501.08322v1 by Amirhossein Aliakbarzadeh, Lucie Flek, Akbar Karimi

Large Language Models (LLMs) are trained on Web data that might contain
spelling errors made by humans. But do they become robust to similar real-world
noise? In this paper, we investigate the effect of real-world spelling mistakes
on the performance of 9 language models, with parameters ranging from 0.2B to
13B, in 3 different NLP tasks, namely Natural Language Inference (NLI), Name
Entity Recognition (NER), and Intent Classification (IC). We perform our
experiments on 6 different languages and build a dictionary of real-world noise
for them using the Wikipedia edit history. We show that the performance gap of
the studied models on the clean and noisy test data averaged across all the
datasets and languages ranges from 2.3 to 4.3 absolute percentage points. In
addition, mT5 models, in general, show more robustness compared to BLOOM,
Falcon, and BERT-like models. In particular, mT5 (13B), was the most robust on
average overall, across the 3 tasks, and in 4 of the 6 languages.

摘要：大型語言模型 (LLM) 是根據網路資料訓練而成的，這些資料可能包含人類拼寫錯誤。但它們是否能對類似的真實世界雜訊產生穩健性？在本文中，我們探討真實世界拼寫錯誤對 9 個語言模型效能的影響，這些模型的參數範圍從 0.2B 到 13B，涵蓋 3 個不同的自然語言處理 (NLP) 任務，即自然語言推論 (NLI)、命名實體辨識 (NER) 和意圖分類 (IC)。我們在 6 種不同的語言上執行實驗，並使用維基百科編輯記錄為這些語言建立真實世界雜訊字典。我們顯示出這些研究模型在乾淨和雜訊測試資料上的效能差距，平均在所有資料集和語言的範圍從 2.3 到 4.3 個絕對百分比點。此外，與 BLOOM、Falcon 和 BERT 類似模型相比，mT5 模型通常表現出更高的穩健性。特別是，mT5 (13B) 在 3 個任務和 6 種語言中的 4 種語言中，整體上最穩健。

##### **Enhancing Automated Interpretability with Output-Centric Feature Descriptions**
2501.08319v1 by Yoav Gur-Arieh, Roy Mayan, Chen Agassy, Atticus Geiger, Mor Geva

Automated interpretability pipelines generate natural language descriptions
for the concepts represented by features in large language models (LLMs), such
as plants or the first word in a sentence. These descriptions are derived using
inputs that activate the feature, which may be a dimension or a direction in
the model's representation space. However, identifying activating inputs is
costly, and the mechanistic role of a feature in model behavior is determined
both by how inputs cause a feature to activate and by how feature activation
affects outputs. Using steering evaluations, we reveal that current pipelines
provide descriptions that fail to capture the causal effect of the feature on
outputs. To fix this, we propose efficient, output-centric methods for
automatically generating feature descriptions. These methods use the tokens
weighted higher after feature stimulation or the highest weight tokens after
applying the vocabulary "unembedding" head directly to the feature. Our
output-centric descriptions better capture the causal effect of a feature on
model outputs than input-centric descriptions, but combining the two leads to
the best performance on both input and output evaluations. Lastly, we show that
output-centric descriptions can be used to find inputs that activate features
previously thought to be "dead".

摘要：自動可解釋性管道會為大型語言模型 (LLM) 中特徵所代表的概念產生自然語言說明，例如植物或句子中的第一個字。這些說明是使用會啟動特徵的輸入所衍生，而這些輸入可能是模型表示空間中的維度或方向。然而，找出啟動輸入的成本很高，且特徵在模型行為中所扮演的機械角色是由輸入如何導致特徵啟動，以及特徵啟動如何影響輸出所決定。使用引導評估，我們揭露目前的管道所提供的說明無法捕捉特徵對輸出的因果關係。為了修正這個問題，我們提出用於自動產生特徵說明的有效且以輸出為中心的各種方法。這些方法會使用在特徵刺激後權重較高的代碼，或在將詞彙「解嵌入」標頭直接套用至特徵後權重最高的代碼。我們以輸出為中心的說明比以輸入為中心的說明更能捕捉特徵對模型輸出的因果關係，但結合這兩種說明可在輸入和輸出評估中獲得最佳效能。最後，我們證明以輸出為中心的說明可用於找出會啟動以前被認為是「無效」的特徵的輸入。

##### **Diffusion Adversarial Post-Training for One-Step Video Generation**
2501.08316v1 by Shanchuan Lin, Xin Xia, Yuxi Ren, Ceyuan Yang, Xuefeng Xiao, Lu Jiang

The diffusion models are widely used for image and video generation, but
their iterative generation process is slow and expansive. While existing
distillation approaches have demonstrated the potential for one-step generation
in the image domain, they still suffer from significant quality degradation. In
this work, we propose Adversarial Post-Training (APT) against real data
following diffusion pre-training for one-step video generation. To improve the
training stability and quality, we introduce several improvements to the model
architecture and training procedures, along with an approximated R1
regularization objective. Empirically, our experiments show that our
adversarial post-trained model, Seaweed-APT, can generate 2-second, 1280x720,
24fps videos in real time using a single forward evaluation step. Additionally,
our model is capable of generating 1024px images in a single step, achieving
quality comparable to state-of-the-art methods.

摘要：擴散模型廣泛用於影像和影片生成，但其反覆生成過程緩慢且耗費資源。雖然現有的蒸餾方法已展示出在影像領域進行單步生成的可能性，但它們仍會造成品質大幅下降。在這項工作中，我們針對真實資料提出對抗式後訓練 (APT)，並在擴散預訓練後進行單步影片生成。為了改善訓練穩定性和品質，我們對模型架構和訓練程序進行多項改良，並採用近似 R1 正則化目標。根據經驗，我們的實驗顯示，我們的對抗式後訓練模型 Seaweed-APT 能夠使用單一前向評估步驟，即時生成 2 秒、1280x720、24fps 的影片。此外，我們的模型能夠在單一步驟中生成 1024px 的影像，並達到與現有方法相當的品質。

##### **MiniMax-01: Scaling Foundation Models with Lightning Attention**
2501.08313v1 by MiniMax, Aonian Li, Bangwei Gong, Bo Yang, Boji Shan, Chang Liu, Cheng Zhu, Chunhao Zhang, Congchao Guo, Da Chen, Dong Li, Enwei Jiao, Gengxin Li, Guojun Zhang, Haohai Sun, Houze Dong, Jiadai Zhu, Jiaqi Zhuang, Jiayuan Song, Jin Zhu, Jingtao Han, Jingyang Li, Junbin Xie, Junhao Xu, Junjie Yan, Kaishun Zhang, Kecheng Xiao, Kexi Kang, Le Han, Leyang Wang, Lianfei Yu, Liheng Feng, Lin Zheng, Linbo Chai, Long Xing, Meizhi Ju, Mingyuan Chi, Mozhi Zhang, Peikai Huang, Pengcheng Niu, Pengfei Li, Pengyu Zhao, Qi Yang, Qidi Xu, Qiexiang Wang, Qin Wang, Qiuhui Li, Ruitao Leng, Shengmin Shi, Shuqi Yu, Sichen Li, Songquan Zhu, Tao Huang, Tianrun Liang, Weigao Sun, Weixuan Sun, Weiyu Cheng, Wenkai Li, Xiangjun Song, Xiao Su, Xiaodong Han, Xinjie Zhang, Xinzhu Hou, Xu Min, Xun Zou, Xuyang Shen, Yan Gong, Yingjie Zhu, Yipeng Zhou, Yiran Zhong, Yongyi Hu, Yuanxiang Fan, Yue Yu, Yufeng Yang, Yuhao Li, Yunan Huang, Yunji Li, Yunpeng Huang, Yunzhi Xu, Yuxin Mao, Zehan Li, Zekang Li, Zewei Tao, Zewen Ying, Zhaoyang Cong, Zhen Qin, Zhenhua Fan, Zhihang Yu, Zhuo Jiang, Zijia Wu

We introduce MiniMax-01 series, including MiniMax-Text-01 and MiniMax-VL-01,
which are comparable to top-tier models while offering superior capabilities in
processing longer contexts. The core lies in lightning attention and its
efficient scaling. To maximize computational capacity, we integrate it with
Mixture of Experts (MoE), creating a model with 32 experts and 456 billion
total parameters, of which 45.9 billion are activated for each token. We
develop an optimized parallel strategy and highly efficient
computation-communication overlap techniques for MoE and lightning attention.
This approach enables us to conduct efficient training and inference on models
with hundreds of billions of parameters across contexts spanning millions of
tokens. The context window of MiniMax-Text-01 can reach up to 1 million tokens
during training and extrapolate to 4 million tokens during inference at an
affordable cost. Our vision-language model, MiniMax-VL-01 is built through
continued training with 512 billion vision-language tokens. Experiments on both
standard and in-house benchmarks show that our models match the performance of
state-of-the-art models like GPT-4o and Claude-3.5-Sonnet while offering 20-32
times longer context window. We publicly release MiniMax-01 at
https://github.com/MiniMax-AI.

摘要：<paragraph>我們推出 MiniMax-01 系列，包括 MiniMax-Text-01 和 MiniMax-VL-01，
它們與頂級模型相當，同時在處理較長語境方面提供卓越的功能。核心在於閃電注意力及其高效縮放。為了最大化計算能力，我們將其與專家混合 (MoE) 整合，建立一個擁有 32 個專家和 4560 億個總參數的模型，其中 459 億個參數被啟用於每個代幣。我們為 MoE 和閃電注意力開發了一個優化的並行策略和高效的計算通訊重疊技術。這種方法使我們能夠對擁有數百億個參數的模型進行高效的訓練和推理，而這些參數跨越數百萬個代幣的語境。MiniMax-Text-01 的語境窗口在訓練期間可以達到 100 萬個代幣，並在推理期間以合理成本推斷到 400 萬個代幣。我們的視覺語言模型 MiniMax-VL-01 是透過持續訓練 5120 億個視覺語言代幣建立的。在標準基準和內部基準上的實驗表明，我們的模型與 GPT-4o 和 Claude-3.5-Sonnet 等最先進模型的性能相匹配，同時提供 20-32 倍更長的語境窗口。我們在 https://github.com/MiniMax-AI 上公開發布 MiniMax-01。</paragraph>

##### **Everybody Likes to Sleep: A Computer-Assisted Comparison of Object Naming Data from 30 Languages**
2501.08312v1 by Alžběta Kučerová, Johann-Mattis List

Object naming - the act of identifying an object with a word or a phrase - is
a fundamental skill in interpersonal communication, relevant to many
disciplines, such as psycholinguistics, cognitive linguistics, or language and
vision research. Object naming datasets, which consist of concept lists with
picture pairings, are used to gain insights into how humans access and select
names for objects in their surroundings and to study the cognitive processes
involved in converting visual stimuli into semantic concepts. Unfortunately,
object naming datasets often lack transparency and have a highly idiosyncratic
structure. Our study tries to make current object naming data transparent and
comparable by using a multilingual, computer-assisted approach that links
individual items of object naming lists to unified concepts. Our current sample
links 17 object naming datasets that cover 30 languages from 10 different
language families. We illustrate how the comparative dataset can be explored by
searching for concepts that recur across the majority of datasets and comparing
the conceptual spaces of covered object naming datasets with classical basic
vocabulary lists from historical linguistics and linguistic typology. Our
findings can serve as a basis for enhancing cross-linguistic object naming
research and as a guideline for future studies dealing with object naming
tasks.

摘要：<paragraph>對象命名——用一個詞或一個短語識別一個對象的行為——是一項人際溝通的基本技能，與許多領域相關，例如心理語言學、認知語言學或語言和視覺研究。對象命名數據集包含帶有圖片配對的概念清單，用於深入了解人類如何訪問和選擇周圍對象的名稱，以及研究將視覺刺激轉換為語義概念所涉及的認知過程。不幸的是，對象命名數據集通常缺乏透明度，並且具有高度的獨特性結構。我們的研究試圖通過使用多語言、計算機輔助的方法將對象命名清單的單個項目鏈接到統一的概念，從而使當前對象命名數據透明且具有可比性。我們目前的樣本鏈接了 17 個對象命名數據集，這些數據集涵蓋了來自 10 個不同語言家族的 30 種語言。我們說明瞭如何通過搜索跨大多數數據集重複出現的概念以及將涵蓋的對象命名數據集的概念空間與歷史語言學和語言類型學中的經典基本詞彙表進行比較來探索比較數據集。我們的研究結果可以作為增強跨語言對象命名研究的基礎，並作為處理對象命名任務的未來研究的指導方針。</paragraph>

##### **Polynomial Threshold Functions of Bounded Tree-Width: Some Explainability and Complexity Aspects**
2501.08297v1 by Karine Chubarian, Johnny Joyce, Gyorgy Turan

The tree-width of a multivariate polynomial is the tree-width of the
hypergraph with hyperedges corresponding to its terms. Multivariate polynomials
of bounded tree-width have been studied by Makowsky and Meer as a new sparsity
condition that allows for polynomial solvability of problems which are
intractable in general. We consider a variation on this theme for Boolean
variables. A representation of a Boolean function as the sign of a polynomial
is called a polynomial threshold representation. We discuss Boolean functions
representable as polynomial threshold functions of bounded tree-width and
present two applications to Bayesian network classifiers, a probabilistic
graphical model. Both applications are in Explainable Artificial Intelligence
(XAI), the research area dealing with the black-box nature of many recent
machine learning models. We also give a separation result between the
representational power of positive and general polynomial threshold functions.

摘要：多變量多項式的樹寬度是與其項對應的超圖的樹寬度。Makowsky 和 Meer 研究了有界樹寬度的多變量多項式，作為一種新的稀疏性條件，允許對一般難以解決的問題進行多項式求解。我們考慮了布林變數的這個主題變體。布林函數的表示形式為多項式的符號，稱為多項式閾值表示。我們討論了可表示為有界樹寬度的多項式閾值函數的布林函數，並介紹了貝氏網路分類器（一種機率圖形模型）的兩個應用。這兩個應用都在可解釋人工智慧（XAI）中，這是一個研究許多近期機器學習模型的黑箱性質的研究領域。我們還給出了正多項式閾值函數和一般多項式閾值函數的表示能力之間的分離結果。

##### **HALoGEN: Fantastic LLM Hallucinations and Where to Find Them**
2501.08292v1 by Abhilasha Ravichander, Shrusti Ghela, David Wadden, Yejin Choi

Despite their impressive ability to generate high-quality and fluent text,
generative large language models (LLMs) also produce hallucinations: statements
that are misaligned with established world knowledge or provided input context.
However, measuring hallucination can be challenging, as having humans verify
model generations on-the-fly is both expensive and time-consuming. In this
work, we release HALoGEN, a comprehensive hallucination benchmark consisting
of: (1) 10,923 prompts for generative models spanning nine domains including
programming, scientific attribution, and summarization, and (2) automatic
high-precision verifiers for each use case that decompose LLM generations into
atomic units, and verify each unit against a high-quality knowledge source. We
use this framework to evaluate ~150,000 generations from 14 language models,
finding that even the best-performing models are riddled with hallucinations
(sometimes up to 86% of generated atomic facts depending on the domain). We
further define a novel error classification for LLM hallucinations based on
whether they likely stem from incorrect recollection of training data (Type A
errors), or incorrect knowledge in training data (Type B errors), or are
fabrication (Type C errors). We hope our framework provides a foundation to
enable the principled study of why generative models hallucinate, and advances
the development of trustworthy large language models.

摘要：儘管生成式大型語言模型 (LLM) 擁有生成高品質且流利文字的驚人能力，
但它們也會產生幻覺：與既定的世界知識或提供的輸入背景不符的陳述。
然而，測量幻覺可能具有挑戰性，因為讓人類即時驗證模型生成既昂貴又耗時。在
這項工作中，我們發布了 HALoGEN，一個全面的幻覺基準，包含：
(1) 10,923 個提示，供生成模型涵蓋九個領域，包括
程式設計、科學歸因和摘要，以及 (2) 針對每個使用案例的自動
高精度驗證器，將 LLM 生成分解為原子單位，並根據高品質知識來源驗證每個單位。我們
使用這個框架從 14 個語言模型評估了約 150,000 個生成，
發現即使是效能最好的模型也充斥著幻覺
（有時高達 86% 的生成原子事實，視領域而定）。我們
進一步定義了 LLM 幻覺的新錯誤分類，基於它們可能源自訓練資料的錯誤回憶（A 型
錯誤）、訓練資料中的錯誤知識（B 型錯誤），或捏造（C 型錯誤）。我們希望我們的框架提供一個基礎，
以讓原則性的研究能夠了解生成模型產生幻覺的原因，並促進可信賴大型語言模型的開發。

##### **AfriHate: A Multilingual Collection of Hate Speech and Abusive Language Datasets for African Languages**
2501.08284v1 by Shamsuddeen Hassan Muhammad, Idris Abdulmumin, Abinew Ali Ayele, David Ifeoluwa Adelani, Ibrahim Said Ahmad, Saminu Mohammad Aliyu, Nelson Odhiambo Onyango, Lilian D. A. Wanzare, Samuel Rutunda, Lukman Jibril Aliyu, Esubalew Alemneh, Oumaima Hourrane, Hagos Tesfahun Gebremichael, Elyas Abdi Ismail, Meriem Beloucif, Ebrahim Chekol Jibril, Andiswa Bukula, Rooweither Mabuya, Salomey Osei, Abigail Oppong, Tadesse Destaw Belay, Tadesse Kebede Guge, Tesfa Tegegne Asfaw, Chiamaka Ijeoma Chukwuneke, Paul Röttger, Seid Muhie Yimam, Nedjma Ousidhoum

Hate speech and abusive language are global phenomena that need
socio-cultural background knowledge to be understood, identified, and
moderated. However, in many regions of the Global South, there have been
several documented occurrences of (1) absence of moderation and (2) censorship
due to the reliance on keyword spotting out of context. Further, high-profile
individuals have frequently been at the center of the moderation process, while
large and targeted hate speech campaigns against minorities have been
overlooked. These limitations are mainly due to the lack of high-quality data
in the local languages and the failure to include local communities in the
collection, annotation, and moderation processes. To address this issue, we
present AfriHate: a multilingual collection of hate speech and abusive language
datasets in 15 African languages. Each instance in AfriHate is annotated by
native speakers familiar with the local culture. We report the challenges
related to the construction of the datasets and present various classification
baseline results with and without using LLMs. The datasets, individual
annotations, and hate speech and offensive language lexicons are available on
https://github.com/AfriHate/AfriHate

摘要：仇恨言論和辱罵性語言是全球現象，需要社會文化背景知識才能理解、識別和管理。然而，在全球南方的許多地區，已經有幾起記錄在案的事件（1）缺乏管理和（2）審查，這是由於依賴於上下文之外的關鍵字偵測。此外，高知名度人士經常處於管理流程的中心，而針對少數群體的大規模且有針對性的仇恨言論運動卻被忽視了。這些限制主要是由於缺乏當地語言的高品質資料，以及未能讓當地社群參與收集、註解和管理流程。為了解決這個問題，我們提出了 AfriHate：一個包含 15 種非洲語言的仇恨言論和辱罵性語言資料集的多語言集合。AfriHate 中的每個實例都由熟悉當地文化的母語人士註解。我們報告了與資料集建構相關的挑戰，並展示了使用和不使用 LLM 的各種分類基準結果。資料集、個別註解以及仇恨言論和攻擊性語言詞彙表可在 https://github.com/AfriHate/AfriHate 上取得。

##### **Exploring Robustness of LLMs to Sociodemographically-Conditioned Paraphrasing**
2501.08276v1 by Pulkit Arora, Akbar Karimi, Lucie Flek

Large Language Models (LLMs) have shown impressive performance in various NLP
tasks. However, there are concerns about their reliability in different domains
of linguistic variations. Many works have proposed robustness evaluation
measures for local adversarial attacks, but we need globally robust models
unbiased to different language styles. We take a broader approach to explore a
wider range of variations across sociodemographic dimensions to perform
structured reliability tests on the reasoning capacity of language models. We
extend the SocialIQA dataset to create diverse paraphrased sets conditioned on
sociodemographic styles. The assessment aims to provide a deeper understanding
of LLMs in (a) their capability of generating demographic paraphrases with
engineered prompts and (b) their reasoning capabilities in real-world, complex
language scenarios. We also explore measures such as perplexity,
explainability, and ATOMIC performance of paraphrases for fine-grained
reliability analysis of LLMs on these sets. We find that demographic-specific
paraphrasing significantly impacts the performance of language models,
indicating that the subtleties of language variations remain a significant
challenge. The code and dataset will be made available for reproducibility and
future research.

摘要：大型語言模型 (LLM) 在各種自然語言處理 (NLP) 任務中展現了令人印象深刻的效能。然而，對於它們在不同語言變異領域的可靠性仍有疑慮。許多研究已針對局部對抗攻擊提出穩健性評估措施，但我們需要對不同語言風格沒有偏見的全球穩健模型。我們採取更廣泛的方法，探索社會人口特徵維度中更廣泛的變異，對語言模型的推理能力進行結構化的可靠性測試。我們擴充 SocialIQA 資料集，以建立以社會人口特徵風格為條件的不同同義詞組。評估旨在提供對 LLM 的更深入理解，包括：(a) 它們使用設計提示產生人口同義詞的能力，以及 (b) 它們在現實世界中複雜語言情境中的推理能力。我們還探索困惑度、可解釋性和同義詞的 ATOMIC 效能等指標，以對 LLM 在這些集合上的可靠性進行細緻的分析。我們發現，特定人口的同義詞改寫會顯著影響語言模型的效能，這表示語言變異的細微差別仍然是一項重大的挑戰。程式碼和資料集將提供出來，以利於再現性和後續研究。

##### **Comparative Analysis of Efficient Adapter-Based Fine-Tuning of State-of-the-Art Transformer Models**
2501.08271v1 by Saad Mashkoor Siddiqui, Mohammad Ali Sheikh, Muhammad Aleem, Kajol R Singh

In this work, we investigate the efficacy of various adapter architectures on
supervised binary classification tasks from the SuperGLUE benchmark as well as
a supervised multi-class news category classification task from Kaggle.
Specifically, we compare classification performance and time complexity of
three transformer models, namely DistilBERT, ELECTRA, and BART, using
conventional fine-tuning as well as nine state-of-the-art (SoTA) adapter
architectures. Our analysis reveals performance differences across adapter
architectures, highlighting their ability to achieve comparable or better
performance relative to fine-tuning at a fraction of the training time. Similar
results are observed on the new classification task, further supporting our
findings and demonstrating adapters as efficient and flexible alternatives to
fine-tuning. This study provides valuable insights and guidelines for selecting
and implementing adapters in diverse natural language processing (NLP)
applications.

摘要：在本文中，我們探討各種適配器架構在 SuperGLUE 基準中的監督式二元分類任務以及來自 Kaggle 的監督式多類新聞分類任務中的功效。具體來說，我們比較了 DistilBERT、ELECTRA 和 BART 這三種Transformer模型的分類效能和時間複雜度，使用傳統微調以及九種最先進 (SoTA) 適配器架構。我們的分析揭示了適配器架構之間的效能差異，突出了它們以低於訓練時間的一小部分達到與微調相當或更好的效能的能力。在新的分類任務中觀察到了類似的結果，進一步支持我們的發現，並展示適配器作為微調的有效且靈活的替代方案。本研究為在各種自然語言處理 (NLP) 應用中選擇和實作適配器提供了有價值的見解和指南。

##### **AI Driven Water Segmentation with deep learning models for Enhanced Flood Monitoring**
2501.08266v1 by Sanjida Afrin Mou, Tasfia Noor Chowdhury, Adib Ibn Mannan, Sadia Nourin Mim, Lubana Tarannum, Tasrin Noman, Jamal Uddin Ahamed

Flooding is a major natural hazard causing significant fatalities and
economic losses annually, with increasing frequency due to climate change.
Rapid and accurate flood detection and monitoring are crucial for mitigating
these impacts. This study compares the performance of three deep learning
models UNet, ResNet, and DeepLabv3 for pixelwise water segmentation to aid in
flood detection, utilizing images from drones, in field observations, and
social media. This study involves creating a new dataset that augments
wellknown benchmark datasets with flood-specific images, enhancing the
robustness of the models. The UNet, ResNet, and DeepLab v3 architectures are
tested to determine their effectiveness in various environmental conditions and
geographical locations, and the strengths and limitations of each model are
also discussed here, providing insights into their applicability in different
scenarios by predicting image segmentation masks. This fully automated approach
allows these models to isolate flooded areas in images, significantly reducing
processing time compared to traditional semi-automated methods. The outcome of
this study is to predict segmented masks for each image effected by a flood
disaster and the validation accuracy of these models. This methodology
facilitates timely and continuous flood monitoring, providing vital data for
emergency response teams to reduce loss of life and economic damages. It offers
a significant reduction in the time required to generate flood maps, cutting
down the manual processing time. Additionally, we present avenues for future
research, including the integration of multimodal data sources and the
development of robust deep learning architectures tailored specifically for
flood detection tasks. Overall, our work contributes to the advancement of
flood management strategies through innovative use of deep learning
technologies.

摘要：<paragraph>洪水是一種重大的自然災害，每年造成大量人員傷亡和經濟損失，而且由於氣候變遷，洪水發生的頻率越來越高。快速而準確的洪水偵測和監控對於減輕這些影響至關重要。本研究比較了三種深度學習模型 UNet、ResNet 和 DeepLabv3 在像素級水體分割中的表現，以協助洪水偵測，利用無人機、現場觀測和社群媒體中的影像。本研究涉及建立一個新的資料集，將眾所周知的基準資料集與特定洪水的影像擴充，以增強模型的穩健性。測試 UNet、ResNet 和 DeepLab v3 架構，以確定它們在各種環境條件和地理位置中的有效性，並且在此探討每個模型的優點和限制，提供在不同場景中預測影像分割遮罩的應用見解。這種全自動化方法讓這些模型能夠在影像中隔離淹水區域，與傳統的半自動化方法相比，大幅減少處理時間。本研究的成果是預測受洪災影響的每張影像的分割遮罩，以及這些模型的驗證準確度。這種方法促進及時且持續的洪水監控，提供緊急應變小組的重要資料，以減少人員傷亡和經濟損失。它大幅縮短了生成洪水地圖所需的時間，減少了手動處理時間。此外，我們提出了未來研究的途徑，包括整合多模式資料來源，以及開發專門針對洪水偵測任務的穩健深度學習架構。總體而言，我們的研究透過創新使用深度學習技術，為洪水管理策略的進步做出貢獻。</paragraph>

##### **Eliciting In-context Retrieval and Reasoning for Long-context Large Language Models**
2501.08248v1 by Yifu Qiu, Varun Embar, Yizhe Zhang, Navdeep Jaitly, Shay B. Cohen, Benjamin Han

Recent advancements in long-context language models (LCLMs) promise to
transform Retrieval-Augmented Generation (RAG) by simplifying pipelines. With
their expanded context windows, LCLMs can process entire knowledge bases and
perform retrieval and reasoning directly -- a capability we define as
In-Context Retrieval and Reasoning (ICR^2). However, existing benchmarks like
LOFT often overestimate LCLM performance by providing overly simplified
contexts. To address this, we introduce ICR^2, a benchmark that evaluates LCLMs
in more realistic scenarios by including confounding passages retrieved with
strong retrievers. We then propose three methods to enhance LCLM performance:
(1) retrieve-then-generate fine-tuning, (2) retrieval-attention-probing, which
uses attention heads to filter and de-noise long contexts during decoding, and
(3) joint retrieval head training alongside the generation head. Our evaluation
of five well-known LCLMs on LOFT and ICR^2 demonstrates significant gains with
our best approach applied to Mistral-7B: +17 and +15 points by Exact Match on
LOFT, and +13 and +2 points on ICR^2, compared to vanilla RAG and supervised
fine-tuning, respectively. It even outperforms GPT-4-Turbo on most tasks
despite being a much smaller model.

摘要：長文本語言模型 (LCLM) 的最新進展有望透過簡化管線來轉換檢索增強產生 (RAG)。LCLM 透過其擴充的內容視窗，可以處理整個知識庫，並直接執行檢索和推理，我們將此功能定義為情境內檢索和推理 (ICR^2)。不過，現有的基準（例如 LOFT）經常透過提供過度簡化的內容來高估 LCLM 的效能。為了解決這個問題，我們推出 ICR^2，這是一個透過納入使用強大檢索器檢索到的混淆段落，在更實際的場景中評估 LCLM 的基準。接著，我們提出三種方法來提升 LCLM 的效能：(1) 先檢索後產生的微調、(2) 檢索注意力探測，它使用注意力標頭在解碼期間過濾和去除雜訊，以及 (3) 在產生標頭旁進行聯合檢索標頭訓練。我們在 LOFT 和 ICR^2 上對五個知名的 LCLM 進行評估，證明我們的最佳方法應用於 Mistral-7B 時有顯著進步：與原始 RAG 和監督微調相比，在 LOFT 上的完全比對增加了 17 和 15 點，在 ICR^2 上增加了 13 和 2 點。即使它是一個小得多的模型，但在大多數任務上仍優於 GPT-4-Turbo。

##### **A Feature-Level Ensemble Model for COVID-19 Identification in CXR Images using Choquet Integral and Differential Evolution Optimization**
2501.08241v1 by Amir Reza Takhsha, Maryam Rastgarpour, Mozhgan Naderi

The COVID-19 pandemic has profoundly impacted billions globally. It
challenges public health and healthcare systems due to its rapid spread and
severe respiratory effects. An effective strategy to mitigate the COVID-19
pandemic involves integrating testing to identify infected individuals. While
RT-PCR is considered the gold standard for diagnosing COVID-19, it has some
limitations such as the risk of false negatives. To address this problem, this
paper introduces a novel Deep Learning Diagnosis System that integrates
pre-trained Deep Convolutional Neural Networks (DCNNs) within an ensemble
learning framework to achieve precise identification of COVID-19 cases from
Chest X-ray (CXR) images. We combine feature vectors from the final hidden
layers of pre-trained DCNNs using the Choquet integral to capture interactions
between different DCNNs that a linear approach cannot. We employed
Sugeno-$\lambda$ measure theory to derive fuzzy measures for subsets of
networks to enable aggregation. We utilized Differential Evolution to estimate
fuzzy densities. We developed a TensorFlow-based layer for Choquet operation to
facilitate efficient aggregation, due to the intricacies involved in
aggregating feature vectors. Experimental results on the COVIDx dataset show
that our ensemble model achieved 98\% accuracy in three-class classification
and 99.50\% in binary classification, outperforming its components-DenseNet-201
(97\% for three-class, 98.75\% for binary), Inception-v3 (96.25\% for
three-class, 98.50\% for binary), and Xception (94.50\% for three-class, 98\%
for binary)-and surpassing many previous methods.

摘要：新冠肺炎疫情已对全球数十亿人产生深远影响。由于其传播迅速且呼吸道症状严重，它对公共卫生和医疗保健系统构成挑战。减轻新冠肺炎疫情的有效策略包括整合检测以识别受感染者。虽然 RT-PCR 被认为是诊断新冠肺炎的黄金标准，但它也有一些限制，例如假阴性的风险。为了解决这个问题，本文介绍了一种新颖的深度学习诊断系统，该系统将预训练的深度卷积神经网络 (DCNN) 集成到集成学习框架中，以从胸部 X 射线 (CXR) 图像中精确识别新冠肺炎病例。我们使用 Choquet 积分结合来自预训练 DCNN 的最后一个隐藏层的特征向量，以捕获线性方法无法实现的不同 DCNN 之间的交互。我们采用 Sugeno-$\lambda$ 测度理论来导出网络子集的模糊测度以实现聚合。我们利用差分进化来估计模糊密度。由于聚合特征向量的复杂性，我们开发了一个基于 TensorFlow 的 Choquet 操作层以促进高效聚合。COVIDx 数据集上的实验结果表明，我们的集成模型在三类分类中达到 98% 的准确率，在二元分类中达到 99.50%，优于其组件 DenseNet-201（三类为 97%，二元为 98.75%）、Inception-v3（三类为 96.25%，二元为 98.50%）和 Xception（三类为 94.50%，二元为 98%），并超越了许多以前的方法。

##### **Dynamic Pricing in High-Speed Railways Using Multi-Agent Reinforcement Learning**
2501.08234v1 by Enrique Adrian Villarrubia-Martin, Luis Rodriguez-Benitez, David Muñoz-Valero, Giovanni Montana, Luis Jimenez-Linares

This paper addresses a critical challenge in the high-speed passenger railway
industry: designing effective dynamic pricing strategies in the context of
competing and cooperating operators. To address this, a multi-agent
reinforcement learning (MARL) framework based on a non-zero-sum Markov game is
proposed, incorporating random utility models to capture passenger decision
making. Unlike prior studies in areas such as energy, airlines, and mobile
networks, dynamic pricing for railway systems using deep reinforcement learning
has received limited attention. A key contribution of this paper is a
parametrisable and versatile reinforcement learning simulator designed to model
a variety of railway network configurations and demand patterns while enabling
realistic, microscopic modelling of user behaviour, called RailPricing-RL. This
environment supports the proposed MARL framework, which models heterogeneous
agents competing to maximise individual profits while fostering cooperative
behaviour to synchronise connecting services. Experimental results validate the
framework, demonstrating how user preferences affect MARL performance and how
pricing policies influence passenger choices, utility, and overall system
dynamics. This study provides a foundation for advancing dynamic pricing
strategies in railway systems, aligning profitability with system-wide
efficiency, and supporting future research on optimising pricing policies.

摘要：本文探討高速鐵路產業中的關鍵挑戰：在競爭與合作的營運商背景下，設計有效的動態定價策略。為了解決此問題，提出一個基於非零和馬可夫博弈的多重代理強化學習 (MARL) 架構，並納入隨機效用模型來捕捉乘客決策。與能源、航空公司和行動網路等領域先前的研究不同，使用深度強化學習的鐵路系統動態定價受到的關注有限。本文的一項重要貢獻是可參數化且用途廣泛的強化學習模擬器，旨在模擬各種鐵路網路組態和需求模式，同時支援使用者行為的實際微觀建模，稱為 RailPricing-RL。此環境支援所提出的 MARL 架構，該架構模擬異質代理競爭以最大化個別利潤，同時促進合作行為以同步連接服務。實驗結果驗證了此架構，展示使用者偏好如何影響 MARL 性能，以及定價政策如何影響乘客選擇、效用和整體系統動態。本研究提供了推進鐵路系統動態定價策略的基礎，將獲利能力與系統範圍的效率結合起來，並支援未來優化定價政策的研究。

##### **ASTRID -- An Automated and Scalable TRIaD for the Evaluation of RAG-based Clinical Question Answering Systems**
2501.08208v1 by Mohita Chowdhury, Yajie Vera He, Aisling Higham, Ernest Lim

Large Language Models (LLMs) have shown impressive potential in clinical
question answering (QA), with Retrieval Augmented Generation (RAG) emerging as
a leading approach for ensuring the factual accuracy of model responses.
However, current automated RAG metrics perform poorly in clinical and
conversational use cases. Using clinical human evaluations of responses is
expensive, unscalable, and not conducive to the continuous iterative
development of RAG systems. To address these challenges, we introduce ASTRID -
an Automated and Scalable TRIaD for evaluating clinical QA systems leveraging
RAG - consisting of three metrics: Context Relevance (CR), Refusal Accuracy
(RA), and Conversational Faithfulness (CF). Our novel evaluation metric, CF, is
designed to better capture the faithfulness of a model's response to the
knowledge base without penalising conversational elements. To validate our
triad, we curate a dataset of over 200 real-world patient questions posed to an
LLM-based QA agent during surgical follow-up for cataract surgery - the highest
volume operation in the world - augmented with clinician-selected questions for
emergency, clinical, and non-clinical out-of-domain scenarios. We demonstrate
that CF can predict human ratings of faithfulness better than existing
definitions for conversational use cases. Furthermore, we show that evaluation
using our triad consisting of CF, RA, and CR exhibits alignment with clinician
assessment for inappropriate, harmful, or unhelpful responses. Finally, using
nine different LLMs, we demonstrate that the three metrics can closely agree
with human evaluations, highlighting the potential of these metrics for use in
LLM-driven automated evaluation pipelines. We also publish the prompts and
datasets for these experiments, providing valuable resources for further
research and development.

摘要：大型語言模型 (LLM) 在臨床問答 (QA) 中展現了令人印象深刻的潛力，其中檢索增強生成 (RAG) 成為確保模型回應事實準確性的領先方法。然而，目前的自動化 RAG 指標在臨床和對話式用例中表現不佳。使用臨床人類對回應的評估既昂貴又不具可擴充性，也不利於 RAG 系統的持續迭代開發。為了應對這些挑戰，我們引入了 ASTRID - 一種用於評估利用 RAG 的臨床 QA 系統的自動化且可擴充的 TRIaD - 包含三個指標：脈絡相關性 (CR)、拒絕準確性 (RA) 和對話忠實度 (CF)。我們新穎的評估指標 CF 旨在更好地捕捉模型對知識庫的回應的忠實度，同時不懲罰對話元素。為了驗證我們的三元組，我們策劃了一個數據集，其中包含在白內障手術術後隨訪期間向 LLM 基於 QA 的代理提出的 200 多個真實世界的患者問題 - 世界上手術量最大的手術 - 並增加了臨床醫生選擇的問題，用於緊急、臨床和非臨床領域外情境。我們證明，與對話式用例現有定義相比，CF 可以更好地預測人類對忠實度的評分。此外，我們表明使用由 CF、RA 和 CR 組成的三元組進行評估與臨床醫生對不適當、有害或無益的回應的評估保持一致。最後，使用九種不同的 LLM，我們證明這三個指標可以與人類評估緊密一致，突顯了這些指標在 LLM 驅動的自動化評估管道中使用的潛力。我們還公佈了這些實驗的提示和數據集，為進一步的研究和開發提供了寶貴的資源。

##### **Modeling Feature Maps for Quantum Machine Learning**
2501.08205v1 by Navneet Singh, Shiva Raj Pokhrel

Quantum Machine Learning (QML) offers significant potential for complex tasks
like genome sequence classification, but quantum noise on Noisy
Intermediate-Scale Quantum (NISQ) devices poses practical challenges. This
study systematically evaluates how various quantum noise models including
dephasing, amplitude damping, depolarizing, thermal noise, bit-flip, and
phase-flip affect key QML algorithms (QSVC, Peg-QSVC, QNN, VQC) and feature
mapping techniques (ZFeatureMap, ZZFeatureMap, and PauliFeatureMap). Results
indicate that QSVC is notably robust under noise, whereas Peg-QSVC and QNN are
more sensitive, particularly to depolarizing and amplitude-damping noise. The
PauliFeatureMap is especially vulnerable, highlighting difficulties in
maintaining accurate classification under noisy conditions. These findings
underscore the critical importance of feature map selection and noise
mitigation strategies in optimizing QML for genomic classification, with
promising implications for personalized medicine.

摘要：量子機器學習 (QML) 為基因組序列分類等複雜任務提供了巨大的潛力，但有噪聲中階量子 (NISQ) 裝置上的量子噪聲會帶來實際挑戰。本研究系統性地評估了各種量子噪聲模型，包括去相位、振幅阻尼、去極化、熱噪聲、位元翻轉和相位翻轉，如何影響主要的 QML 演算法 (QSVC、Peg-QSVC、QNN、VQC) 和特徵對應技術 (ZFeatureMap、ZZFeatureMap 和 PauliFeatureMap)。結果表明，QSVC 在噪聲下顯著強健，而 Peg-QSVC 和 QNN 則較敏感，特別是對於去極化和振幅阻尼噪聲。PauliFeatureMap 特別容易受到影響，突顯了在有噪聲條件下維持準確分類的難度。這些發現強調了特徵對應選擇和噪聲緩解策略在最佳化 QML 以進行基因組分類中的重要性，對個人化醫療有令人振奮的影響。

##### **ArithmAttack: Evaluating Robustness of LLMs to Noisy Context in Math Problem Solving**
2501.08203v1 by Zain Ul Abedin, Shahzeb Qamar, Lucie Flek, Akbar Karimi

While Large Language Models (LLMs) have shown impressive capabilities in math
problem-solving tasks, their robustness to noisy inputs is not well-studied. In
this work, we propose ArithmAttack to examine how robust the LLMs are when they
encounter noisy prompts that contain extra noise in the form of punctuation
marks. While being easy to implement, ArithmAttack does not cause any
information loss since words are not added or deleted from the context. We
evaluate the robustness of seven LLMs, including LLama3, Mistral, and
Mathstral, on noisy GSM8K and MultiArith datasets. Our experiments suggest that
all the studied models show vulnerability to such noise, with more noise
leading to poorer performances.

摘要：儘管大型語言模型 (LLM) 在數學問題解決任務中展現出令人印象深刻的能力，它們對於有雜訊輸入的健壯性尚未得到充分研究。在這項工作中，我們提出 ArithmAttack 來檢驗 LLM 在遇到包含額外雜訊（以標點符號形式）的雜訊提示時具有多麼健壯。ArithmAttack 容易實作，而且不會造成任何資訊遺失，因為不會從內容中新增或刪除字詞。我們評估了七個 LLM 的健壯性，包括 LLama3、Mistral 和 Mathstral，在有雜訊的 GSM8K 和 MultiArith 資料集上。我們的實驗表明，所有研究的模型都顯示出對這種雜訊的脆弱性，雜訊越多，效能越差。

##### **CWEval: Outcome-driven Evaluation on Functionality and Security of LLM Code Generation**
2501.08200v1 by Jinjun Peng, Leyi Cui, Kele Huang, Junfeng Yang, Baishakhi Ray

Large Language Models (LLMs) have significantly aided developers by
generating or assisting in code writing, enhancing productivity across various
tasks. While identifying incorrect code is often straightforward, detecting
vulnerabilities in functionally correct code is more challenging, especially
for developers with limited security knowledge, which poses considerable
security risks of using LLM-generated code and underscores the need for robust
evaluation benchmarks that assess both functional correctness and security.
Current benchmarks like CyberSecEval and SecurityEval attempt to solve it but
are hindered by unclear and impractical specifications, failing to assess both
functionality and security accurately. To tackle these deficiencies, we
introduce CWEval, a novel outcome-driven evaluation framework designed to
enhance the evaluation of secure code generation by LLMs. This framework not
only assesses code functionality but also its security simultaneously with
high-quality task specifications and outcome-driven test oracles which provides
high accuracy. Coupled with CWEval-bench, a multilingual, security-critical
coding benchmark, CWEval provides a rigorous empirical security evaluation on
LLM-generated code, overcoming previous benchmarks' shortcomings. Through our
evaluations, CWEval reveals a notable portion of functional but insecure code
produced by LLMs, and shows a serious inaccuracy of previous evaluations,
ultimately contributing significantly to the field of secure code generation.
We open-source our artifact at: https://github.com/Co1lin/CWEval .

摘要：大型語言模型 (LLM) 已透過產生或協助撰寫程式碼，大幅協助開發人員，提升各種任務的生產力。雖然識別錯誤的程式碼通常很簡單，但偵測功能正確程式碼中的漏洞更具挑戰性，特別是對於安全知識有限的開發人員而言，這對使用 LLM 生成的程式碼構成相當大的安全風險，並強調需要健全的評估基準，以評估功能正確性和安全性。CyberSecEval 和 SecurityEval 等目前的基準試圖解決這個問題，但受到不明確且不切實際的規格阻礙，無法準確評估功能和安全性。為了解決這些缺點，我們引入了 CWEval，一個新穎的成果導向評估架構，旨在加強對 LLM 安全程式碼生成的評估。這個架構不僅評估程式碼功能，還同時評估其安全性，並具備高品質的任務規格和成果導向測試預言，可提供高準確度。結合多語言、安全關鍵編碼基準 CWEval-bench，CWEval 對 LLM 生成的程式碼提供嚴謹的經驗安全評估，克服了先前基準的缺點。透過我們的評估，CWEval 揭露了 LLM 產生的一大部分功能性但又不安全的程式碼，並顯示先前評估的嚴重不準確性，最終對安全程式碼生成的領域做出重大貢獻。我們在 https://github.com/Co1lin/CWEval 開放原始碼工件。

##### **EmoNeXt: an Adapted ConvNeXt for Facial Emotion Recognition**
2501.08199v1 by Yassine El Boudouri, Amine Bohi

Facial expressions play a crucial role in human communication serving as a
powerful and impactful means to express a wide range of emotions. With
advancements in artificial intelligence and computer vision, deep neural
networks have emerged as effective tools for facial emotion recognition. In
this paper, we propose EmoNeXt, a novel deep learning framework for facial
expression recognition based on an adapted ConvNeXt architecture network. We
integrate a Spatial Transformer Network (STN) to focus on feature-rich regions
of the face and Squeeze-and-Excitation blocks to capture channel-wise
dependencies. Moreover, we introduce a self-attention regularization term,
encouraging the model to generate compact feature vectors. We demonstrate the
superiority of our model over existing state-of-the-art deep learning models on
the FER2013 dataset regarding emotion classification accuracy.

摘要：面部表情在人类沟通中扮演着至关重要的角色，作为表达广泛情绪的一种有力且有影响力的方式。随着人工智能和计算机视觉的进步，深度神经网络已成为面部表情识别中有效的工具。在本文中，我们提出了 EmoNeXt，一种基于自适应 ConvNeXt 架构网络的面部表情识别深度学习框架。我们集成了空间变换网络 (STN) 来关注面部中富含特征的区域和 Squeeze-and-Excitation 块来捕获通道依赖性。此外，我们引入了一个自注意力正则化项，鼓励模型生成紧凑的特征向量。我们在 FER2013 数据集上展示了我们的模型在情绪分类准确性方面优于现有最先进的深度学习模型。

##### **OpenCSG Chinese Corpus: A Series of High-quality Chinese Datasets for LLM Training**
2501.08197v1 by Yijiong Yu, Ziyun Dai, Zekun Wang, Wei Wang, Ran Chen, Ji Pei

Large language models (LLMs) have demonstrated remarkable capabilities, but
their success heavily relies on the quality of pretraining corpora. For Chinese
LLMs, the scarcity of high-quality Chinese datasets presents a significant
challenge, often limiting their performance. To address this issue, we propose
the OpenCSG Chinese Corpus, a series of high-quality datasets specifically
designed for LLM pretraining, post-training, and fine-tuning. This corpus
includes Fineweb-edu-chinese, Fineweb-edu-chinese-v2, Cosmopedia-chinese, and
Smoltalk-chinese, each with distinct characteristics: Fineweb-edu datasets
focus on filtered, high-quality content derived from diverse Chinese web
sources; Cosmopedia-chinese provides synthetic, textbook-style data for
knowledge-intensive training; and Smoltalk-chinese emphasizes stylistic and
diverse chat-format data. The OpenCSG Chinese Corpus is characterized by its
high-quality text, diverse coverage across domains, and scalable, reproducible
data curation processes. Additionally, we conducted extensive experimental
analyses, including evaluations on smaller parameter models, which demonstrated
significant performance improvements in tasks such as C-Eval, showcasing the
effectiveness of the corpus for training Chinese LLMs.

摘要：大型語言模型 (LLM) 已展示出非凡的能力，但其成功很大程度上依賴於預訓練語料庫的品質。對於中文 LLM，高品質中文資料集的稀缺性是一個重大挑戰，通常會限制其效能。為了解決這個問題，我們提出 OpenCSG 中文語料庫，這是一系列專門設計用於 LLM 預訓練、後訓練和微調的高品質資料集。此語料庫包含 Fineweb-edu-chinese、Fineweb-edu-chinese-v2、Cosmopedia-chinese 和 Smoltalk-chinese，每個資料集都有不同的特點：Fineweb-edu 資料集專注於從各種中文網路來源衍生的經過篩選的高品質內容；Cosmopedia-chinese 提供用於知識密集訓練的合成教科書式資料；而 Smoltalk-chinese 則強調風格化和多樣化的聊天格式資料。OpenCSG 中文語料庫的特點是其高品質文字、跨領域的多樣化涵蓋範圍，以及可擴充且可重製的資料策展流程。此外，我們進行了廣泛的實驗分析，包括對較小參數模型的評估，這證明了在任務（例如 C-Eval）中效能有顯著提升，展示了該語料庫在訓練中文 LLM 方面的有效性。

##### **PRESERVE: Prefetching Model Weights and KV-Cache in Distributed LLM Serving**
2501.08192v1 by Ahmet Caner Yüzügüler, Jiawei Zhuang, Lukas Cavigelli

Large language models (LLMs) are widely used across various applications, but
their substantial computational requirements pose significant challenges,
particularly in terms of HBM bandwidth bottlenecks and inter-device
communication overhead. In this paper, we present PRESERVE, a novel prefetching
framework designed to optimize LLM inference by overlapping memory reads for
model weights and KV-cache with collective communication operations. Through
extensive experiments conducted on commercial AI accelerators, we demonstrate
up to 1.6x end-to-end speedup on state-of-the-art, open-source LLMs.
Additionally, we perform a design space exploration that identifies the optimal
hardware configuration for the proposed method, showing a further 1.25x
improvement in performance per cost by selecting the optimal L2 cache size. Our
results show that PRESERVE has the potential to mitigate the memory bottlenecks
and communication overheads, offering a solution to improve the performance and
scalability of the LLM inference systems.

摘要：大型語言模型 (LLM) 廣泛用於各種應用程式中，但其龐大的運算需求帶來嚴峻的挑戰，特別是在 HBM 頻寬瓶頸和裝置間通訊負擔方面。在本文中，我們提出 PRESERVE，一個創新的預先擷取架構，旨在透過重疊模型權重的記憶體讀取和 KV 快取與集體通訊操作，來最佳化 LLM 推論。透過在商用 AI 加速器上進行廣泛的實驗，我們展示了最先進的開源 LLM 可達 1.6 倍的端到端加速。此外，我們執行設計空間探索，找出建議方法的最佳硬體配置，顯示透過選擇最佳 L2 快取大小，效能每成本可進一步提升 1.25 倍。我們的結果顯示 PRESERVE 有可能緩解記憶體瓶頸和通訊負擔，提供一個解決方案來提升 LLM 推論系統的效能和可擴充性。

##### **A Critical Synthesis of Uncertainty Quantification and Foundation Models in Monocular Depth Estimation**
2501.08188v1 by Steven Landgraf, Rongjun Qin, Markus Ulrich

While recent foundation models have enabled significant breakthroughs in
monocular depth estimation, a clear path towards safe and reliable deployment
in the real-world remains elusive. Metric depth estimation, which involves
predicting absolute distances, poses particular challenges, as even the most
advanced foundation models remain prone to critical errors. Since quantifying
the uncertainty has emerged as a promising endeavor to address these
limitations and enable trustworthy deployment, we fuse five different
uncertainty quantification methods with the current state-of-the-art
DepthAnythingV2 foundation model. To cover a wide range of metric depth
domains, we evaluate their performance on four diverse datasets. Our findings
identify fine-tuning with the Gaussian Negative Log-Likelihood Loss (GNLL) as a
particularly promising approach, offering reliable uncertainty estimates while
maintaining predictive performance and computational efficiency on par with the
baseline, encompassing both training and inference time. By fusing uncertainty
quantification and foundation models within the context of monocular depth
estimation, this paper lays a critical foundation for future research aimed at
improving not only model performance but also its explainability. Extending
this critical synthesis of uncertainty quantification and foundation models
into other crucial tasks, such as semantic segmentation and pose estimation,
presents exciting opportunities for safer and more reliable machine vision
systems.

摘要：儘管近期基礎模型在單眼深度估計方面取得重大突破，但通往現實世界中安全且可靠部署的明確路徑仍難以捉摸。度量深度估計涉及預測絕對距離，這會造成特定的挑戰，因為即使是最先進的基礎模型仍容易出現重大錯誤。由於量化不確定性已成為了解決這些限制和實現可信賴部署的潛力方法，我們將五種不同的不確定性量化方法與當前最先進的 DepthAnythingV2 基礎模型融合在一起。為了涵蓋廣泛的度量深度領域，我們在四個不同的資料集上評估其效能。我們的研究結果發現，使用高斯負對數似然損失 (GNLL) 進行微調是一種特別有前途的方法，它在維持預測效能和運算效率與基準相當時，提供可靠的不確定性估計，涵蓋訓練和推論時間。透過在單眼深度估計的背景下融合不確定性量化和基礎模型，本文為未來的研究奠定了重要的基礎，旨在不僅提升模型效能，也提升其可解釋性。將不確定性量化和基礎模型的這種重要綜合延伸到其他關鍵任務中，例如語意分割和姿勢估計，為更安全、更可靠的機器視覺系統提供了令人興奮的機會。

##### **A Multi-Modal AI Copilot for Single-Cell Analysis with Instruction Following**
2501.08187v1 by Yin Fang, Xinle Deng, Kangwei Liu, Ningyu Zhang, Jingyang Qian, Penghui Yang, Xiaohui Fan, Huajun Chen

Large language models excel at interpreting complex natural language
instructions, enabling them to perform a wide range of tasks. In the life
sciences, single-cell RNA sequencing (scRNA-seq) data serves as the "language
of cellular biology", capturing intricate gene expression patterns at the
single-cell level. However, interacting with this "language" through
conventional tools is often inefficient and unintuitive, posing challenges for
researchers. To address these limitations, we present InstructCell, a
multi-modal AI copilot that leverages natural language as a medium for more
direct and flexible single-cell analysis. We construct a comprehensive
multi-modal instruction dataset that pairs text-based instructions with
scRNA-seq profiles from diverse tissues and species. Building on this, we
develop a multi-modal cell language architecture capable of simultaneously
interpreting and processing both modalities. InstructCell empowers researchers
to accomplish critical tasks-such as cell type annotation, conditional
pseudo-cell generation, and drug sensitivity prediction-using straightforward
natural language commands. Extensive evaluations demonstrate that InstructCell
consistently meets or exceeds the performance of existing single-cell
foundation models, while adapting to diverse experimental conditions. More
importantly, InstructCell provides an accessible and intuitive tool for
exploring complex single-cell data, lowering technical barriers and enabling
deeper biological insights.

摘要：大型語言模型擅長解讀複雜的自然語言指令，讓它們能夠執行廣泛的任務。在生命科學中，單細胞 RNA 定序 (scRNA-seq) 資料作為「細胞生物學的語言」，捕捉單細胞層級複雜的基因表現模式。然而，透過傳統工具與這「語言」互動通常沒有效率且不直觀，對研究人員來說構成挑戰。為了解決這些限制，我們提出 InstructCell，一種多模態 AI 副駕駛，利用自然語言作為媒介進行更直接且彈性的單細胞分析。我們建構一個全面的多模態指令資料集，將文字指令與來自不同組織和物種的 scRNA-seq 特徵檔配對。在此基礎上，我們開發出一個多模態細胞語言架構，能夠同時解讀和處理這兩種模態。InstructCell 賦能研究人員使用直接的自然語言指令完成關鍵任務，例如細胞類型註解、條件偽細胞產生和藥物敏感性預測。廣泛的評估顯示，InstructCell 持續達到或超越現有單細胞基礎模型的效能，同時適應不同的實驗條件。更重要的是，InstructCell 提供一個易於使用且直觀的工具來探索複雜的單細胞資料，降低技術障礙並獲得更深入的生物見解。

##### **Assessing AI Adoption and Digitalization in SMEs: A Framework for Implementation**
2501.08184v1 by Serena Proietti, Roberto Magnani

The primary objective of this research is to examine the current state of
digitalization and the integration of artificial intelligence (AI) within small
and medium-sized enterprises (SMEs) in Italy. There is a significant gap
between SMEs and large corporations in their use of AI, with SMEs facing
numerous barriers to adoption. This study identifies critical drivers and
obstacles to achieving intelligent transformation, proposing a framework model
to address key challenges and provide actionable guidelines

摘要：本研究的主要目的是檢視義大利中小企業 (SME) 中數位化的現況與人工智慧 (AI) 的整合。中小企業與大型企業在使用 AI 上有顯著的差距，中小企業在採用 AI 時面臨許多障礙。本研究找出實現智慧轉型的關鍵驅動力和障礙，並提出一個架構模型來解決主要挑戰並提供可行的指引

##### **CG-MER: A Card Game-based Multimodal dataset for Emotion Recognition**
2501.08182v1 by Nessrine Farhat, Amine Bohi, Leila Ben Letaifa, Rim Slama

The field of affective computing has seen significant advancements in
exploring the relationship between emotions and emerging technologies. This
paper presents a novel and valuable contribution to this field with the
introduction of a comprehensive French multimodal dataset designed specifically
for emotion recognition. The dataset encompasses three primary modalities:
facial expressions, speech, and gestures, providing a holistic perspective on
emotions. Moreover, the dataset has the potential to incorporate additional
modalities, such as Natural Language Processing (NLP) to expand the scope of
emotion recognition research. The dataset was curated through engaging
participants in card game sessions, where they were prompted to express a range
of emotions while responding to diverse questions. The study included 10
sessions with 20 participants (9 females and 11 males). The dataset serves as a
valuable resource for furthering research in emotion recognition and provides
an avenue for exploring the intricate connections between human emotions and
digital technologies.

摘要：情感計算領域在探索情緒與新興科技之間的關係方面已取得顯著進展。這篇論文透過引入專門為情緒辨識而設計的全面法語多模態資料集，對此領域提出新穎且有價值的貢獻。資料集包含三個主要的模態：表情、語音和手勢，提供對情緒的整體觀點。此外，資料集有潛力納入其他模態，例如自然語言處理 (NLP)，以擴展情緒辨識研究的範圍。此資料集是透過讓參與者參與紙牌遊戲，並在回答各種問題的同時提示他們表達一系列情緒來策劃的。這項研究包括 10 場會議，有 20 位參與者（9 位女性和 11 位男性）。此資料集是促進情緒辨識研究的寶貴資源，並提供探索人類情緒與數位科技之間複雜關聯的途徑。

##### **Revolutionizing Communication with Deep Learning and XAI for Enhanced Arabic Sign Language Recognition**
2501.08169v1 by Mazen Balat, Rewaa Awaad, Ahmed B. Zaky, Salah A. Aly

This study introduces an integrated approach to recognizing Arabic Sign
Language (ArSL) using state-of-the-art deep learning models such as
MobileNetV3, ResNet50, and EfficientNet-B2. These models are further enhanced
by explainable AI (XAI) techniques to boost interpretability. The ArSL2018 and
RGB Arabic Alphabets Sign Language (AASL) datasets are employed, with
EfficientNet-B2 achieving peak accuracies of 99.48\% and 98.99\%, respectively.
Key innovations include sophisticated data augmentation methods to mitigate
class imbalance, implementation of stratified 5-fold cross-validation for
better generalization, and the use of Grad-CAM for clear model decision
transparency. The proposed system not only sets new benchmarks in recognition
accuracy but also emphasizes interpretability, making it suitable for
applications in healthcare, education, and inclusive communication
technologies.

摘要：本研究引入一種整合式方法，使用最先進的深度學習模型，例如 MobileNetV3、ResNet50 和 EfficientNet-B2，來辨識阿拉伯手語 (ArSL)。這些模型進一步透過可解釋 AI (XAI) 技術進行強化，以提升可詮釋性。本研究採用 ArSL2018 和 RGB 阿拉伯字母手語 (AASL) 資料集，其中 EfficientNet-B2 分別達到 99.48% 和 98.99% 的最高準確度。主要的創新包括：精密的資料擴充方法，以減輕類別不平衡；實作分層 5 倍交叉驗證，以獲得更好的泛化性；以及使用 Grad-CAM 以獲得清晰的模型決策透明度。所提出的系統不僅在辨識準確度上樹立新的基準，也強調可詮釋性，使其適用於醫療保健、教育和包容性通訊技術中的應用。

##### **LeapVAD: A Leap in Autonomous Driving via Cognitive Perception and Dual-Process Thinking**
2501.08168v1 by Yukai Ma, Tiantian Wei, Naiting Zhong, Jianbiao Mei, Tao Hu, Licheng Wen, Xuemeng Yang, Botian Shi, Yong Liu

While autonomous driving technology has made remarkable strides, data-driven
approaches still struggle with complex scenarios due to their limited reasoning
capabilities. Meanwhile, knowledge-driven autonomous driving systems have
evolved considerably with the popularization of visual language models. In this
paper, we propose LeapVAD, a novel method based on cognitive perception and
dual-process thinking. Our approach implements a human-attentional mechanism to
identify and focus on critical traffic elements that influence driving
decisions. By characterizing these objects through comprehensive attributes -
including appearance, motion patterns, and associated risks - LeapVAD achieves
more effective environmental representation and streamlines the decision-making
process. Furthermore, LeapVAD incorporates an innovative dual-process
decision-making module miming the human-driving learning process. The system
consists of an Analytic Process (System-II) that accumulates driving experience
through logical reasoning and a Heuristic Process (System-I) that refines this
knowledge via fine-tuning and few-shot learning. LeapVAD also includes
reflective mechanisms and a growing memory bank, enabling it to learn from past
mistakes and continuously improve its performance in a closed-loop environment.
To enhance efficiency, we develop a scene encoder network that generates
compact scene representations for rapid retrieval of relevant driving
experiences. Extensive evaluations conducted on two leading autonomous driving
simulators, CARLA and DriveArena, demonstrate that LeapVAD achieves superior
performance compared to camera-only approaches despite limited training data.
Comprehensive ablation studies further emphasize its effectiveness in
continuous learning and domain adaptation. Project page:
https://pjlab-adg.github.io/LeapVAD/.

摘要：<paragraph>儘管自動駕駛技術已取得顯著進展，但資料驅動方法仍因其推理能力有限而難以應對複雜場景。與此同時，隨著視覺語言模型的普及，知識驅動的自動駕駛系統已大幅演進。在本文中，我們提出 LeapVAD，一種基於認知感知和雙重過程思考的新方法。我們的做法實作了一種人類注意力機制，以識別並專注於影響駕駛決策的關鍵交通元素。透過全面屬性（包括外觀、運動模式和相關風險）來描述這些物件，LeapVAD 可達成更有效的環境表徵，並簡化決策制定過程。此外，LeapVAD 結合了一個創新的雙重過程決策制定模組，模仿人類駕駛學習過程。系統包含一個分析過程（系統 II），透過邏輯推理累積駕駛經驗，以及一個啟發式過程（系統 I），透過微調和少量學習來精進此知識。LeapVAD 也包含反思機制和一個不斷成長的記憶庫，使其能夠從過去的錯誤中學習，並在閉環環境中持續改善其效能。為了提高效率，我們開發了一個場景編碼器網路，可產生精簡的場景表徵，以快速擷取相關的駕駛經驗。在兩個領先的自動駕駛模擬器 CARLA 和 DriveArena 上進行的廣泛評估證明，儘管訓練資料有限，LeapVAD 仍能達成優於僅使用相機的方法的卓越效能。全面的消融研究進一步強調其在持續學習和領域適應中的有效性。專案頁面：
https://pjlab-adg.github.io/LeapVAD/。</paragraph>

##### **Potential and Perils of Large Language Models as Judges of Unstructured Textual Data**
2501.08167v1 by Rewina Bedemariam, Natalie Perez, Sreyoshi Bhaduri, Satya Kapoor, Alex Gil, Elizabeth Conjar, Ikkei Itoku, David Theil, Aman Chadha, Naumaan Nayyar

Rapid advancements in large language models have unlocked remarkable
capabilities when it comes to processing and summarizing unstructured text
data. This has implications for the analysis of rich, open-ended datasets, such
as survey responses, where LLMs hold the promise of efficiently distilling key
themes and sentiments. However, as organizations increasingly turn to these
powerful AI systems to make sense of textual feedback, a critical question
arises, can we trust LLMs to accurately represent the perspectives contained
within these text based datasets? While LLMs excel at generating human-like
summaries, there is a risk that their outputs may inadvertently diverge from
the true substance of the original responses. Discrepancies between the
LLM-generated outputs and the actual themes present in the data could lead to
flawed decision-making, with far-reaching consequences for organizations. This
research investigates the effectiveness of LLMs as judge models to evaluate the
thematic alignment of summaries generated by other LLMs. We utilized an
Anthropic Claude model to generate thematic summaries from open-ended survey
responses, with Amazon's Titan Express, Nova Pro, and Meta's Llama serving as
LLM judges. The LLM-as-judge approach was compared to human evaluations using
Cohen's kappa, Spearman's rho, and Krippendorff's alpha, validating a scalable
alternative to traditional human centric evaluation methods. Our findings
reveal that while LLMs as judges offer a scalable solution comparable to human
raters, humans may still excel at detecting subtle, context-specific nuances.
This research contributes to the growing body of knowledge on AI assisted text
analysis. We discuss limitations and provide recommendations for future
research, emphasizing the need for careful consideration when generalizing LLM
judge models across various contexts and use cases.

摘要：大型語言模型的快速進展解鎖了在處理和總結非結構化文本數據方面的非凡能力。這對豐富的開放式數據集的分析有影響，例如調查回應，其中 LLM 承諾有效地提煉關鍵主題和情緒。然而，隨著組織越來越多地求助於這些強大的 AI 系統來理解文本反饋，一個關鍵問題出現了，我們能相信 LLM 能準確地代表這些基於文本的數據集所包含的觀點嗎？雖然 LLM 在生成類似人類的摘要方面表現出色，但存在其輸出可能無意間偏離原始回應的真正實質的風險。LLM 生成的輸出與數據中存在的實際主題之間的差異可能導致有缺陷的決策制定，對組織產生深遠的影響。本研究調查了 LLM 作為評估模型的有效性，以評估其他 LLM 生成的摘要的主題一致性。我們利用 Anthropic Claude 模型從開放式調查回應中生成主題摘要，亞馬遜的 Titan Express、Nova Pro 和 Meta 的 Llama 作為 LLM 評審。使用 Cohen's kappa、Spearman's rho 和 Krippendorff's alpha 將 LLM 作為評審的方法與人類評估進行了比較，驗證了傳統以人為中心的評估方法的可擴展替代方案。我們的研究結果表明，雖然 LLM 作為評審提供了一個與人類評分員相當的可擴展解決方案，但人類仍然可能擅長檢測微妙的、特定於上下文的細微差別。本研究有助於增加有關 AI 輔助文本分析的知識體系。我們討論了局限性並提供了對未來研究的建議，強調在各種背景和用例中概括 LLM 評審模型時需要仔細考慮。

##### **I Can Find You in Seconds! Leveraging Large Language Models for Code Authorship Attribution**
2501.08165v1 by Soohyeon Choi, Yong Kiam Tan, Mark Huasong Meng, Mohamed Ragab, Soumik Mondal, David Mohaisen, Khin Mi Mi Aung

Source code authorship attribution is important in software forensics,
plagiarism detection, and protecting software patch integrity. Existing
techniques often rely on supervised machine learning, which struggles with
generalization across different programming languages and coding styles due to
the need for large labeled datasets. Inspired by recent advances in natural
language authorship analysis using large language models (LLMs), which have
shown exceptional performance without task-specific tuning, this paper explores
the use of LLMs for source code authorship attribution.
  We present a comprehensive study demonstrating that state-of-the-art LLMs can
successfully attribute source code authorship across different languages. LLMs
can determine whether two code snippets are written by the same author with
zero-shot prompting, achieving a Matthews Correlation Coefficient (MCC) of
0.78, and can attribute code authorship from a small set of reference code
snippets via few-shot learning, achieving MCC of 0.77. Additionally, LLMs show
some adversarial robustness against misattribution attacks.
  Despite these capabilities, we found that naive prompting of LLMs does not
scale well with a large number of authors due to input token limitations. To
address this, we propose a tournament-style approach for large-scale
attribution. Evaluating this approach on datasets of C++ (500 authors, 26,355
samples) and Java (686 authors, 55,267 samples) code from GitHub, we achieve
classification accuracy of up to 65% for C++ and 68.7% for Java using only one
reference per author. These results open new possibilities for applying LLMs to
code authorship attribution in cybersecurity and software engineering.

摘要：<paragraph>原始碼作者歸屬在軟體鑑識、抄襲偵測和保護軟體修補程式完整性方面非常重要。現有技術通常依賴於監督式機器學習，由於需要大量標籤資料集，因此在不同的程式語言和編碼風格中難以概化。受到最近使用大型語言模型 (LLM) 進行自然語言作者分析的進展啟發，這些模型在沒有特定任務調整的情況下表現出色的，本文探討使用 LLM 進行原始碼作者歸屬。
我們提出了一項全面的研究，證明最先進的 LLM 可以跨不同語言成功歸屬原始碼作者。LLM 可以透過零次提示來判斷兩個程式碼片段是否由同一位作者撰寫，達到 0.78 的馬修斯相關係數 (MCC)，並且可以透過少量參考程式碼片段透過少量學習來歸屬程式碼作者，達到 0.77 的 MCC。此外，LLM 對錯誤歸屬攻擊表現出一些對抗彈性。
儘管有這些功能，我們發現由於輸入權杖限制，LLM 的天真提示無法很好地擴展到大量作者。為了解決這個問題，我們提出了一種錦標賽式方法進行大規模歸屬。在 GitHub 上的 C++（500 位作者，26,355 個範例）和 Java（686 位作者，55,267 個範例）程式碼的資料集上評估此方法，我們僅使用每位作者一個參考，就達到高達 65% 的 C++ 分類準確度和 68.7% 的 Java 分類準確度。這些結果為將 LLM 應用於網路安全和軟體工程中的程式碼作者歸屬開啟了新的可能性。</paragraph>

##### **FairTTTS: A Tree Test Time Simulation Method for Fairness-Aware Classification**
2501.08155v1 by Nurit Cohen-Inger, Lior Rokach, Bracha Shapira, Seffi Cohen

Algorithmic decision-making has become deeply ingrained in many domains, yet
biases in machine learning models can still produce discriminatory outcomes,
often harming unprivileged groups. Achieving fair classification is inherently
challenging, requiring a careful balance between predictive performance and
ethical considerations. We present FairTTTS, a novel post-processing bias
mitigation method inspired by the Tree Test Time Simulation (TTTS) method.
Originally developed to enhance accuracy and robustness against adversarial
inputs through probabilistic decision-path adjustments, TTTS serves as the
foundation for FairTTTS. By building on this accuracy-enhancing technique,
FairTTTS mitigates bias and improves predictive performance. FairTTTS uses a
distance-based heuristic to adjust decisions at protected attribute nodes,
ensuring fairness for unprivileged samples. This fairness-oriented adjustment
occurs as a post-processing step, allowing FairTTTS to be applied to
pre-trained models, diverse datasets, and various fairness metrics without
retraining. Extensive evaluation on seven benchmark datasets shows that
FairTTTS outperforms traditional methods in fairness improvement, achieving a
20.96% average increase over the baseline compared to 18.78% for related work,
and further enhances accuracy by 0.55%. In contrast, competing methods
typically reduce accuracy by 0.42%. These results confirm that FairTTTS
effectively promotes more equitable decision-making while simultaneously
improving predictive performance.

摘要：演算法決策制定已深植於許多領域中，然而機器學習模型中的偏見仍可能產生歧視性的結果，通常會傷害未受保障的群體。達成公平分類本質上具有挑戰性，需要在預測效能與道德考量之間取得仔細的平衡。我們提出 FairTTTS，這是一種新穎的後處理偏誤緩解方法，其靈感來自樹測試時間模擬 (TTTS) 方法。TTTS 最初是為了透過機率決策路徑調整來增強針對對抗輸入的準確度和穩健性而開發，並作為 FairTTTS 的基礎。透過建立在這種增強準確度的技術之上，FairTTTS 可以減輕偏誤並改善預測效能。FairTTTS 使用基於距離的啟發法來調整受保護屬性節點的決策，確保未受保障樣本的公平性。這種以公平性為導向的調整會在後處理步驟中發生，允許 FairTTTS 套用至預先訓練的模型、多樣化的資料集和各種公平性指標，而無需重新訓練。在七個基準資料集上的廣泛評估顯示，FairTTTS 在公平性改善方面優於傳統方法，與相關工作的 18.78% 相比，平均提升了 20.96%，並進一步將準確度提升了 0.55%。相反地，競爭方法通常會將準確度降低 0.42%。這些結果證實，FairTTTS 有效地促進了更公平的決策制定，同時也改善了預測效能。

##### **Multiple-Input Variational Auto-Encoder for Anomaly Detection in Heterogeneous Data**
2501.08149v1 by Phai Vu Dinh, Diep N. Nguyen, Dinh Thai Hoang, Quang Uy Nguyen, Eryk Dutkiewicz

Anomaly detection (AD) plays a pivotal role in AI applications, e.g., in
classification, and intrusion/threat detection in cybersecurity. However, most
existing methods face challenges of heterogeneity amongst feature subsets posed
by non-independent and identically distributed (non-IID) data. We propose a
novel neural network model called Multiple-Input Auto-Encoder for AD (MIAEAD)
to address this. MIAEAD assigns an anomaly score to each feature subset of a
data sample to indicate its likelihood of being an anomaly. This is done by
using the reconstruction error of its sub-encoder as the anomaly score. All
sub-encoders are then simultaneously trained using unsupervised learning to
determine the anomaly scores of feature subsets. The final AUC of MIAEAD is
calculated for each sub-dataset, and the maximum AUC obtained among the
sub-datasets is selected. To leverage the modelling of the distribution of
normal data to identify anomalies of the generative models, we develop a novel
neural network architecture/model called Multiple-Input Variational
Auto-Encoder (MIVAE). MIVAE can process feature subsets through its
sub-encoders before learning distribution of normal data in the latent space.
This allows MIVAE to identify anomalies that deviate from the learned
distribution. We theoretically prove that the difference in the average anomaly
score between normal samples and anomalies obtained by the proposed MIVAE is
greater than that of the Variational Auto-Encoder (VAEAD), resulting in a
higher AUC for MIVAE. Extensive experiments on eight real-world anomaly
datasets demonstrate the superior performance of MIAEAD and MIVAE over
conventional methods and the state-of-the-art unsupervised models, by up to 6%
in terms of AUC score. Alternatively, MIAEAD and MIVAE have a high AUC when
applied to feature subsets with low heterogeneity based on the coefficient of
variation (CV) score.

摘要：異常偵測 (AD) 在 AI 應用中扮演著關鍵角色，例如在分類、以及網路安全中的入侵/威脅偵測。然而，現有的方法大多面臨由非獨立同分佈 (non-IID) 資料所造成的特徵子集間的異質性挑戰。我們提出一個名為多輸入自動編碼器異常偵測 (MIAEAD) 的新穎神經網路模型來解決這個問題。MIAEAD 會為資料樣本的每個特徵子集分配一個異常分數，以表示其成為異常值的可能性。這是透過使用其子編碼器的重建誤差作為異常分數來完成的。然後所有子編碼器會同時使用非監督式學習進行訓練，以確定特徵子集的異常分數。MIAEAD 的最終 AUC 會針對每個子資料集計算，並選取在子資料集中獲得的最大 AUC。為了利用生成模型的常態資料分佈建模來識別異常值，我們開發了一個名為多輸入變異自動編碼器 (MIVAE) 的新穎神經網路架構/模型。MIVAE 可以透過其子編碼器處理特徵子集，然後在潛在空間中學習常態資料的分佈。這允許 MIVAE 識別出與所學習分佈不同的異常值。我們在理論上證明，MIVAE 所獲得的常態樣本與異常值之間的平均異常分數差異大於變異自動編碼器 (VAEAD)，導致 MIVAE 具有更高的 AUC。在八個真實世界的異常資料集上進行的廣泛實驗證明了 MIAEAD 和 MIVAE 優於傳統方法和最先進的非監督式模型，AUC 分數提高了 6%。或者，MIAEAD 和 MIVAE 在應用於根據變異係數 (CV) 分數具有低異質性的特徵子集時，具有很高的 AUC。

##### **Refusal Behavior in Large Language Models: A Nonlinear Perspective**
2501.08145v1 by Fabian Hildebrandt, Andreas Maier, Patrick Krauss, Achim Schilling

Refusal behavior in large language models (LLMs) enables them to decline
responding to harmful, unethical, or inappropriate prompts, ensuring alignment
with ethical standards. This paper investigates refusal behavior across six
LLMs from three architectural families. We challenge the assumption of refusal
as a linear phenomenon by employing dimensionality reduction techniques,
including PCA, t-SNE, and UMAP. Our results reveal that refusal mechanisms
exhibit nonlinear, multidimensional characteristics that vary by model
architecture and layer. These findings highlight the need for nonlinear
interpretability to improve alignment research and inform safer AI deployment
strategies.

摘要：大型語言模型 (LLM) 中的拒絕行為使它們能夠拒絕回應有害、不道德或不適當的提示，確保與道德標準保持一致。本文調查了來自三個架構家族的六個 LLM 的拒絕行為。我們通過採用降維技術（包括 PCA、t-SNE 和 UMAP）來挑戰拒絕作為線性現象的假設。我們的結果表明，拒絕機制表現出非線性、多維特徵，這些特徵因模型架構和層而異。這些發現強調了非線性可解釋性的必要性，以改進對齊研究並為更安全的 AI 部署策略提供信息。

##### **An Empirical Wall-Pressure Spectrum Model for Aeroacoustic Predictions Based on Symbolic Regression**
2501.08134v1 by Laura Botero Bolívar, David Huergo, Fernanda L. dos Santos, Cornelis H. Venner, Leandro D. de Santana, Esteban Ferrer

Fast-turn around methods to predict airfoil trailing-edge noise are crucial
for incorporating noise limitations into design optimization loops of several
applications. Among these aeroacoustic predictive models, Amiet's theory offers
the best balance between accuracy and simplicity. The accuracy of the model
relies heavily on precise wall-pressure spectrum predictions, which are often
based on single-equation formulations with adjustable parameters. These
parameters are calibrated for particular airfoils and flow conditions and
consequently tend to fail when applied outside their calibration range. This
paper introduces a new wall-pressure spectrum empirical model designed to
enhance the robustness and accuracy of current state-of-the-art predictions
while widening the range of applicability of the model to different airfoils
and flow conditions. The model is developed using AI-based symbolic regression
via a genetic-algorithm-based approach, and applied to a dataset of
wall-pressure fluctuations measured on NACA 0008 and NACA 63018 airfoils at
multiple angles of attack and inflow velocities, covering turbulent boundary
layers with both adverse and favorable pressure gradients. Validation against
experimental data (outside the training dataset) demonstrates the robustness of
the model compared to well-accepted semi-empirical models. Finally, the model
is integrated with Amiet's theory to predict the aeroacoustic noise of a
full-scale wind turbine, showing good agreement with experimental measurements.

摘要：預測翼型後緣噪音的快速週轉方法對於將噪音限制納入多種應用的設計最佳化迴圈至關重要。在這些空氣動力聲學預測模型中，Amiet 的理論在準確性和簡便性之間取得了最佳平衡。模型的準確性在很大程度上依賴於精確的壁壓譜預測，而這些預測通常基於具有可調整參數的單一方程式公式。這些參數經過校準以適應特定的翼型和流動條件，因此當應用於校準範圍之外時往往會失效。本文介紹了一個新的壁壓譜經驗模型，旨在增強當前最先進預測的穩健性和準確性，同時擴大模型對不同翼型和流動條件的適用範圍。該模型是通過基於遺傳演算法的方法使用基於 AI 的符號回歸開發的，並應用於在 NACA 0008 和 NACA 63018 翼型上測量的壁壓波動數據集，涵蓋具有不利和有利壓力梯度的湍流邊界層。與公認的半經驗模型相比，針對實驗數據（訓練數據集之外）的驗證證明了該模型的穩健性。最後，該模型與 Amiet 的理論相結合，以預測全尺寸風力渦輪機的空氣動力聲學噪音，顯示出與實驗測量結果的一致性。

##### **In-situ graph reasoning and knowledge expansion using Graph-PReFLexOR**
2501.08120v1 by Markus J. Buehler

The pursuit of automated scientific discovery has fueled progress from
symbolic logic to modern AI, forging new frontiers in reasoning and pattern
recognition. Transformers function as potential systems, where every possible
relationship remains latent potentiality until tasks impose constraints, akin
to measurement. Yet, refining their sampling requires more than probabilistic
selection: solutions must conform to specific structures or rules, ensuring
consistency and the invocation of general principles. We present
Graph-PReFLexOR (Graph-based Preference-based Recursive Language Modeling for
Exploratory Optimization of Reasoning), a framework that combines graph
reasoning with symbolic abstraction to dynamically expand domain knowledge.
Inspired by reinforcement learning, Graph-PReFLexOR defines reasoning as a
structured mapping, where tasks yield knowledge graphs, abstract patterns, and
ultimately, final answers. Inspired by category theory, it encodes concepts as
nodes and their relationships as edges, supporting hierarchical inference and
adaptive learning through isomorphic representations. Demonstrations include
hypothesis generation, materials design, and creative reasoning, such as
discovering relationships between mythological concepts like 'thin places' with
materials science. We propose a 'knowledge garden growth' strategy that
integrates insights across domains, promoting interdisciplinary connections.
Results with a 3-billion-parameter Graph-PReFLexOR model show superior
reasoning depth and adaptability, underscoring the potential for transparent,
multidisciplinary AI-driven discovery. It lays the groundwork for general
autonomous reasoning solutions.

摘要：<paragraph>追求自動化科學發現已經推動了從符號邏輯到現代 AI 的進展，在推理和模式識別中開闢了新的領域。Transformer 作為潛在系統運作，其中每種可能的關係都保持潛在潛力，直到任務施加約束，類似於測量。然而，優化其採樣需要的不只是機率選擇：解決方案必須符合特定結構或規則，以確保一致性並呼應一般原則。我們提出了 Graph-PReFLexOR（基於圖形的基於偏好的遞迴語言建模，用於推理的探索性優化），一個將圖形推理與符號抽象相結合以動態擴展領域知識的框架。受強化學習的啟發，Graph-PReFLexOR 將推理定義為結構化對應，任務產生知識圖形、抽象模式以及最終答案。受範疇論的啟發，它將概念編碼為節點，將它們的關係編碼為邊緣，通過同構表示支持階層式推論和自適應學習。示範包括假設生成、材料設計和創造性推理，例如發現神話概念（如「薄弱點」）與材料科學之間的關係。我們提出了一種「知識花園成長」策略，它整合了跨領域的見解，促進了跨學科的聯繫。使用 30 億參數 Graph-PReFLexOR 模型的結果顯示出優異的推理深度和適應性，強調了透明、多學科 AI 驅動發現的潛力。它為通用的自主推理解決方案奠定了基礎。</paragraph>

##### **Data-driven inventory management for new products: A warm-start and adjusted Dyna-$Q$ approach**
2501.08109v1 by Xinyu Qu, Longxiao Liu, Wenjie Huang

In this paper, we propose a novel reinforcement learning algorithm for
inventory management of newly launched products with no or limited historical
demand information. The algorithm follows the classic Dyna-$Q$ structure,
balancing the model-based and model-free approaches, while accelerating the
training process of Dyna-$Q$ and mitigating the model discrepancy generated by
the model-based feedback. Warm-start information from the demand data of
existing similar products can be incorporated into the algorithm to further
stabilize the early-stage training and reduce the variance of the estimated
optimal policy. Our approach is validated through a case study of bakery
inventory management with real data. The adjusted Dyna-$Q$ shows up to a 23.7\%
reduction in average daily cost compared with $Q$-learning, and up to a 77.5\%
reduction in training time within the same horizon compared with classic
Dyna-$Q$. By incorporating the warm-start information, it can be found that the
adjusted Dyna-$Q$ has the lowest total cost, lowest variance in total cost, and
relatively low shortage percentages among all the algorithms under a 30-day
testing.

摘要：<paragraph>在本文中，我们提出了一种新颖的强化学习演算法，用于在没有或只有有限的历史需求资讯的情况下管理新推出的产品的库存。此演算法遵循经典的 Dyna-$Q$ 结构，平衡基于模型和无模型的方法，同时加速 Dyna-$Q$ 的训练程序，并减轻基于模型的回馈产生的模型差异。可以将现有类似产品的需求资料的热启动资讯纳入演算法，以进一步稳定早期阶段的训练，并减少估计最佳政策的差异。我们的方法已透过实际资料的麵包店库存管理案例研究得到验证。调整后的 Dyna-$Q$ 显示出与 $Q$-learning 相比，平均每日成本降低了 23.7%，与经典 Dyna-$Q$ 相比，在相同范围内训练时间减少了 77.5%。透过纳入热启动资讯，可以发现调整后的 Dyna-$Q$ 在所有演算法中具有最低的总成本、最低的总成本差异，以及在 30 天测试中的相对较低的短缺百分比。</paragraph>

##### **Consistency of Responses and Continuations Generated by Large Language Models on Social Media**
2501.08102v1 by Wenlu Fan, Yuqi Zhu, Chenyang Wang, Bin Wang, Wentao Xu

Large Language Models (LLMs) demonstrate remarkable capabilities in text
generation, yet their emotional consistency and semantic coherence in social
media contexts remain insufficiently understood. This study investigates how
LLMs handle emotional content and maintain semantic relationships through
continuation and response tasks using two open-source models: Gemma and Llama.
By analyzing climate change discussions from Twitter and Reddit, we examine
emotional transitions, intensity patterns, and semantic similarity between
human-authored and LLM-generated content. Our findings reveal that while both
models maintain high semantic coherence, they exhibit distinct emotional
patterns: Gemma shows a tendency toward negative emotion amplification,
particularly anger, while maintaining certain positive emotions like optimism.
Llama demonstrates superior emotional preservation across a broader spectrum of
affects. Both models systematically generate responses with attenuated
emotional intensity compared to human-authored content and show a bias toward
positive emotions in response tasks. Additionally, both models maintain strong
semantic similarity with original texts, though performance varies between
continuation and response tasks. These findings provide insights into LLMs'
emotional and semantic processing capabilities, with implications for their
deployment in social media contexts and human-AI interaction design.

摘要：大型語言模型 (LLM) 在文本生成方面展現出卓越的能力，但在社交媒體情境中的情緒一致性和語義連貫性仍有待進一步了解。本研究探討 LLM 如何透過使用兩個開源模型：Gemma 和 Llama，在延續和回應任務中處理情緒內容並維持語義關係。透過分析來自 Twitter 和 Reddit 的氣候變遷討論，我們檢視了人類撰寫和 LLM 生成的內容之間的情緒轉換、強度模式和語義相似性。我們的研究結果顯示，儘管這兩個模型都維持了高度的語義連貫性，但它們表現出截然不同的情緒模式：Gemma 傾向於放大負面情緒，尤其是憤怒，同時維持某些積極情緒，例如樂觀。Llama 則展現出在更廣泛的情緒範圍內維持情緒的優越性。這兩個模型都系統性地產生與人類撰寫內容相比，情緒強度較弱的回應，並在回應任務中表現出偏好正向情緒。此外，這兩個模型都與原始文字維持強烈的語義相似性，儘管在延續和回應任務之間的表現有所不同。這些研究結果提供了對 LLM 情緒和語義處理能力的見解，並對其在社交媒體情境中的部署和人機互動設計產生影響。

##### **Hierarchical Autoscaling for Large Language Model Serving with Chiron**
2501.08090v1 by Archit Patke, Dhemath Reddy, Saurabh Jha, Chandra Narayanaswami, Zbigniew Kalbarczyk, Ravishankar Iyer

Large language model (LLM) serving is becoming an increasingly important
workload for cloud providers. Based on performance SLO requirements, LLM
inference requests can be divided into (a) interactive requests that have tight
SLOs in the order of seconds, and (b) batch requests that have relaxed SLO in
the order of minutes to hours. These SLOs can degrade based on the arrival
rates, multiplexing, and configuration parameters, thus necessitating the use
of resource autoscaling on serving instances and their batch sizes. However,
previous autoscalers for LLM serving do not consider request SLOs leading to
unnecessary scaling and resource under-utilization. To address these
limitations, we introduce Chiron, an autoscaler that uses the idea of
hierarchical backpressure estimated using queue size, utilization, and SLOs.
Our experiments show that Chiron achieves up to 90% higher SLO attainment and
improves GPU efficiency by up to 70% compared to existing solutions.

摘要：大型語言模型 (LLM) 服務正成為雲端供應商日益重要的工作負載。LLM 推論要求可基於效能 SLO 需求分為：(a) 交互式要求，其 SLO 嚴格，約為數秒，以及 (b) 批次要求，其 SLO 較為寬鬆，約為數分鐘至數小時。這些 SLO 可能會根據到達率、多工處理和組態參數而降低，因此需要在提供執行個體及其批次大小上使用資源自動擴充。然而，先前的 LLM 服務自動擴充器並未考量要求 SLO，導致不必要的擴充和資源使用不足。為了解決這些限制，我們引進 Chiron，這是一個自動擴充器，使用佇列大小、使用率和 SLO 估計的階層式反壓概念。我們的實驗顯示，與現有解決方案相比，Chiron 可達成高達 90% 的 SLO 達成率，並將 GPU 效率提升高達 70%。

##### **NOMTO: Neural Operator-based symbolic Model approximaTion and discOvery**
2501.08086v1 by Sergei Garmaev, Siddhartha Mishra, Olga Fink

While many physical and engineering processes are most effectively described
by non-linear symbolic models, existing non-linear symbolic regression (SR)
methods are restricted to a limited set of continuous algebraic functions,
thereby limiting their applicability to discover higher order non-linear
differential relations. In this work, we introduce the Neural Operator-based
symbolic Model approximaTion and discOvery (NOMTO) method, a novel approach to
symbolic model discovery that leverages Neural Operators to encompass a broad
range of symbolic operations. We demonstrate that NOMTO can successfully
identify symbolic expressions containing elementary functions with
singularities, special functions, and derivatives. Additionally, our
experiments demonstrate that NOMTO can accurately rediscover second-order
non-linear partial differential equations. By broadening the set of symbolic
operations available for discovery, NOMTO significantly advances the
capabilities of existing SR methods. It provides a powerful and flexible tool
for model discovery, capable of capturing complex relations in a variety of
physical systems.

摘要：雖然許多物理和工程程序最有效地透過非線性符號模型描述，現有的非線性符號回歸 (SR) 方法僅限於一組連續代數函數，因此限制了它們在發現高階非線性微分關係中的適用性。在這項工作中，我們引入了基於神經算子的符號模型近似和發現 (NOMTO) 方法，一種符號模型發現的新方法，它利用神經算子涵蓋廣泛的符號運算。我們證明 NOMTO 可以成功識別包含具有奇異性、特殊函數和導數的基本函數的符號表達式。此外，我們的實驗證明 NOMTO 可以準確地重新發現二階非線性偏微分方程式。透過擴展可供發現的符號運算組，NOMTO 大大提升了現有 SR 方法的功能。它提供了一個強大且靈活的模型發現工具，能夠捕捉各種物理系統中的複雜關係。

##### **Dynamic Multimodal Sentiment Analysis: Leveraging Cross-Modal Attention for Enabled Classification**
2501.08085v1 by Hui Lee, Singh Suniljit, Yong Siang Ong

This paper explores the development of a multimodal sentiment analysis model
that integrates text, audio, and visual data to enhance sentiment
classification. The goal is to improve emotion detection by capturing the
complex interactions between these modalities, thereby enabling more accurate
and nuanced sentiment interpretation. The study evaluates three feature fusion
strategies -- late stage fusion, early stage fusion, and multi-headed attention
-- within a transformer-based architecture. Experiments were conducted using
the CMU-MOSEI dataset, which includes synchronized text, audio, and visual
inputs labeled with sentiment scores. Results show that early stage fusion
significantly outperforms late stage fusion, achieving an accuracy of 71.87\%,
while the multi-headed attention approach offers marginal improvement, reaching
72.39\%. The findings suggest that integrating modalities early in the process
enhances sentiment classification, while attention mechanisms may have limited
impact within the current framework. Future work will focus on refining feature
fusion techniques, incorporating temporal data, and exploring dynamic feature
weighting to further improve model performance.

摘要：本文探討了一個多模態情緒分析模型的開發，該模型整合了文字、音訊和視覺資料，以增強情緒分類。目標是透過捕捉這些模態之間的複雜互動，來提升情緒偵測，進而實現更準確且細緻的情緒詮釋。本研究評估了三個特徵融合策略：後期融合、早期融合和多頭注意力，這些策略都在基於 Transformer 的架構中。實驗使用 CMU-MOSEI 資料集進行，其中包含同步的文字、音訊和視覺輸入，並標記了情緒分數。結果顯示，早期融合顯著優於後期融合，達到 71.87% 的準確度，而多頭注意力方法提供了邊際改善，達到 72.39%。研究結果表明，在過程中早期整合模態可以增強情緒分類，而注意力機制在當前框架中可能影響有限。未來的研究將專注於改進特徵融合技術、整合時間資料，並探討動態特徵加權，以進一步提升模型效能。

##### **Artificial Liver Classifier: A New Alternative to Conventional Machine Learning Models**
2501.08074v1 by Mahmood A. Jumaah, Yossra H. Ali, Tarik A. Rashid

Supervised machine learning classifiers often encounter challenges related to
performance, accuracy, and overfitting. This paper introduces the Artificial
Liver Classifier (ALC), a novel supervised learning classifier inspired by the
human liver's detoxification function. The ALC is characterized by its
simplicity, speed, hyperparameters-free, ability to reduce overfitting, and
effectiveness in addressing multi-classification problems through
straightforward mathematical operations. To optimize the ALC's parameters, an
improved FOX optimization algorithm (IFOX) is employed as the training method.
The proposed ALC was evaluated on five benchmark machine learning datasets:
Iris Flower, Breast Cancer Wisconsin, Wine, Voice Gender, and MNIST. The
results demonstrated competitive performance, with the ALC achieving 100%
accuracy on the Iris dataset, surpassing logistic regression, multilayer
perceptron, and support vector machine. Similarly, on the Breast Cancer
dataset, it achieved 99.12% accuracy, outperforming XGBoost and logistic
regression. Across all datasets, the ALC consistently exhibited lower
overfitting gaps and loss compared to conventional classifiers. These findings
highlight the potential of leveraging biological process simulations to develop
efficient machine learning models and open new avenues for innovation in the
field.

摘要：监督式机器学习分类器经常遇到与性能、准确度和过度拟合相关的挑战。本文介绍了人工肝分类器 (ALC)，这是一种新颖的监督式学习分类器，灵感来自人类肝脏的解毒功能。ALC 的特点是简单、快速、无超参数、能够减少过度拟合，并且通过简单的数学运算有效地解决多分类问题。为了优化 ALC 的参数，采用改进的 FOX 优化算法 (IFOX) 作为训练方法。在五个基准机器学习数据集上评估了所提出的 ALC：鸢尾花、威斯康星乳腺癌、葡萄酒、语音性别和 MNIST。结果显示了具有竞争力的性能，ALC 在鸢尾花数据集上实现了 100% 的准确度，超过了逻辑回归、多层感知器和支持向量机。同样，在乳腺癌数据集上，它实现了 99.12% 的准确度，优于 XGBoost 和逻辑回归。在所有数据集上，ALC 与传统分类器相比，始终表现出较低的过度拟合差距和损失。这些发现突出了利用生物过程模拟来开发高效机器学习模型的潜力，并为该领域的创新开辟了新的途径。

##### **A Roadmap to Guide the Integration of LLMs in Hierarchical Planning**
2501.08068v1 by Israel Puerta-Merino, Carlos Núñez-Molina, Pablo Mesejo, Juan Fernández-Olivares

Recent advances in Large Language Models (LLMs) are fostering their
integration into several reasoning-related fields, including Automated Planning
(AP). However, their integration into Hierarchical Planning (HP), a subfield of
AP that leverages hierarchical knowledge to enhance planning performance,
remains largely unexplored. In this preliminary work, we propose a roadmap to
address this gap and harness the potential of LLMs for HP. To this end, we
present a taxonomy of integration methods, exploring how LLMs can be utilized
within the HP life cycle. Additionally, we provide a benchmark with a
standardized dataset for evaluating the performance of future LLM-based HP
approaches, and present initial results for a state-of-the-art HP planner and
LLM planner. As expected, the latter exhibits limited performance (3\% correct
plans, and none with a correct hierarchical decomposition) but serves as a
valuable baseline for future approaches.

摘要：大型語言模型 (LLM) 的最新進展促進了它們與多個推理相關領域的整合，包括自動規劃 (AP)。然而，它們與階層規劃 (HP) 的整合，一個利用階層知識來增強規劃效能的 AP 子領域，在很大程度上仍未被探索。在這個初步工作中，我們提出了一個路線圖來解決這個差距，並利用 LLM 在 HP 中的潛力。為此，我們提出了一種整合方法分類法，探討如何在 HP 生命周期中利用 LLM。此外，我們提供了一個具有標準化資料集的基準，用於評估基於 LLM 的 HP 方法的未來效能，並提出了一個最先進的 HP 規劃器和 LLM 規劃器的初步結果。正如預期的那樣，後者表現出有限的效能（3% 正確的計畫，沒有任何正確的階層分解），但作為未來方法的一個有價值的基準。

##### **Optimizing Speech Multi-View Feature Fusion through Conditional Computation**
2501.08057v1 by Weiqiao Shan, Yuhao Zhang, Yuchen Han, Bei Li, Xiaofeng Zhao, Yuang Li, Min Zhang, Hao Yang, Tong Xiao, Jingbo Zhu

Recent advancements have highlighted the efficacy of self-supervised learning
(SSL) features in various speech-related tasks, providing lightweight and
versatile multi-view speech representations. However, our study reveals that
while SSL features expedite model convergence, they conflict with traditional
spectral features like FBanks in terms of update directions. In response, we
propose a novel generalized feature fusion framework grounded in conditional
computation, featuring a gradient-sensitive gating network and a multi-stage
dropout strategy. This framework mitigates feature conflicts and bolsters model
robustness to multi-view input features. By integrating SSL and spectral
features, our approach accelerates convergence and maintains performance on par
with spectral models across multiple speech translation tasks on the MUSTC
dataset.

摘要：最近的進展強調了自監督學習 (SSL) 特徵在各種語音相關任務中的效能，提供了輕量且多面向的語音表徵。然而，我們的研究顯示，儘管 SSL 特徵加速了模型收斂，但它們在更新方向上與 FBanks 等傳統頻譜特徵產生衝突。為了解決這個問題，我們提出了一個新的廣義特徵融合架構，其基礎在於條件運算，並採用了梯度敏感閘控網路和多階段中斷策略。這個架構減輕了特徵衝突，並增強了模型對多面向輸入特徵的穩健性。透過整合 SSL 和頻譜特徵，我們的做法加速了收斂，並在 MUSTC 資料集上的多項語音翻譯任務中，維持與頻譜模型同等的效能。

##### **Exploring Narrative Clustering in Large Language Models: A Layerwise Analysis of BERT**
2501.08053v1 by Awritrojit Banerjee, Achim Schilling, Patrick Krauss

This study investigates the internal mechanisms of BERT, a transformer-based
large language model, with a focus on its ability to cluster narrative content
and authorial style across its layers. Using a dataset of narratives developed
via GPT-4, featuring diverse semantic content and stylistic variations, we
analyze BERT's layerwise activations to uncover patterns of localized neural
processing. Through dimensionality reduction techniques such as Principal
Component Analysis (PCA) and Multidimensional Scaling (MDS), we reveal that
BERT exhibits strong clustering based on narrative content in its later layers,
with progressively compact and distinct clusters. While strong stylistic
clustering might occur when narratives are rephrased into different text types
(e.g., fables, sci-fi, kids' stories), minimal clustering is observed for
authorial style specific to individual writers. These findings highlight BERT's
prioritization of semantic content over stylistic features, offering insights
into its representational capabilities and processing hierarchy. This study
contributes to understanding how transformer models like BERT encode linguistic
information, paving the way for future interdisciplinary research in artificial
intelligence and cognitive neuroscience.

摘要：本研究探討了 BERT 的內部機制，這是一個基於轉換器的大型語言模型，重點在於它在各層中對敘事內容和作者風格進行聚類的能力。我們使用透過 GPT-4 開發的敘事資料集，其中包含多樣化的語義內容和風格變化，分析 BERT 的逐層激活，以揭示局部神經處理模式。透過主成分分析 (PCA) 和多維度縮放 (MDS) 等降維技術，我們發現 BERT 在後層中根據敘事內容表現出強烈的聚類，具有漸進緊湊且不同的聚類。雖然當敘事被改寫成不同的文本類型（例如寓言、科幻小說、兒童故事）時，可能會發生強烈的風格聚類，但對於特定於個別作家的作者風格，觀察到的聚類最少。這些發現突顯了 BERT 優先考慮語義內容而非風格特徵，提供了對其表徵能力和處理層級的見解。本研究有助於了解 BERT 等轉換器模型如何編碼語言資訊，為未來在人工智慧和認知神經科學中的跨領域研究鋪路。

##### **Exploring visual language models as a powerful tool in the diagnosis of Ewing Sarcoma**
2501.08042v1 by Alvaro Pastor-Naranjo, Pablo Meseguer, Rocío del Amor, Jose Antonio Lopez-Guerrero, Samuel Navarro, Katia Scotlandi, Antonio Llombart-Bosch, Isidro Machado, Valery Naranjo

Ewing's sarcoma (ES), characterized by a high density of small round blue
cells without structural organization, presents a significant health concern,
particularly among adolescents aged 10 to 19. Artificial intelligence-based
systems for automated analysis of histopathological images are promising to
contribute to an accurate diagnosis of ES. In this context, this study explores
the feature extraction ability of different pre-training strategies for
distinguishing ES from other soft tissue or bone sarcomas with similar
morphology in digitized tissue microarrays for the first time, as far as we
know. Vision-language supervision (VLS) is compared to fully-supervised
ImageNet pre-training within a multiple instance learning paradigm. Our
findings indicate a substantial improvement in diagnostic accuracy with the
adaption of VLS using an in-domain dataset. Notably, these models not only
enhance the accuracy of predicted classes but also drastically reduce the
number of trainable parameters and computational costs.

摘要：尤因氏肉瘤 (ES) 的特征是高密度的无结构组织的小圆形蓝色细胞，对健康构成重大威胁，尤其是在 10 至 19 岁的青少年中。基于人工智能的组织病理学图像自动分析系统有望有助于 ES 的准确诊断。在此背景下，本研究首次探讨了不同预训练策略的特征提取能力，以区分 ES 与数字化组织微阵列中形态相似的其他软组织或骨肉瘤，据我们所知。视觉语言监督 (VLS) 与多实例学习范式中的完全监督 ImageNet 预训练进行了比较。我们的研究结果表明，使用域内数据集调整 VLS 可大幅提高诊断准确性。值得注意的是，这些模型不仅提高了预测类别的准确性，还大幅减少了可训练参数和计算成本。

##### **READ: Reinforcement-based Adversarial Learning for Text Classification with Limited Labeled Data**
2501.08035v1 by Rohit Sharma, Shanu Kumar, Avinash Kumar

Pre-trained transformer models such as BERT have shown massive gains across
many text classification tasks. However, these models usually need enormous
labeled data to achieve impressive performances. Obtaining labeled data is
often expensive and time-consuming, whereas collecting unlabeled data using
some heuristics is relatively much cheaper for any task. Therefore, this paper
proposes a method that encapsulates reinforcement learning-based text
generation and semi-supervised adversarial learning approaches in a novel way
to improve the model's performance. Our method READ, Reinforcement-based
Adversarial learning, utilizes an unlabeled dataset to generate diverse
synthetic text through reinforcement learning, improving the model's
generalization capability using adversarial learning. Our experimental results
show that READ outperforms the existing state-of-art methods on multiple
datasets.

摘要：預訓練過的Transformer模型，例如 BERT，已在許多文字分類任務中展現出巨大的進步。然而，這些模型通常需要大量的標籤資料才能達到令人印象深刻的效能。取得標籤資料通常昂貴且耗時，而使用一些啟發法收集未標籤資料對於任何任務來說相對便宜得多。因此，本文提出了一種方法，以新穎的方式將基於強化學習的文字生成和半監督對抗學習方法封裝起來，以提升模型的效能。我們的 READ 方法（基於強化對抗學習）利用未標籤的資料集透過強化學習產生多樣化的合成文字，並使用對抗學習提升模型的泛化能力。我們的實驗結果顯示，READ 在多個資料集上優於現有的最先進方法。

##### **Cooperative Patrol Routing: Optimizing Urban Crime Surveillance through Multi-Agent Reinforcement Learning**
2501.08020v1 by Juan Palma-Borda, Eduardo Guzmán, María-Victoria Belmonte

The effective design of patrol strategies is a difficult and complex problem,
especially in medium and large areas. The objective is to plan, in a
coordinated manner, the optimal routes for a set of patrols in a given area, in
order to achieve maximum coverage of the area, while also trying to minimize
the number of patrols. In this paper, we propose a multi-agent reinforcement
learning (MARL) model, based on a decentralized partially observable Markov
decision process, to plan unpredictable patrol routes within an urban
environment represented as an undirected graph. The model attempts to maximize
a target function that characterizes the environment within a given time frame.
Our model has been tested to optimize police patrol routes in three
medium-sized districts of the city of Malaga. The aim was to maximize
surveillance coverage of the most crime-prone areas, based on actual crime data
in the city. To address this problem, several MARL algorithms have been
studied, and among these the Value Decomposition Proximal Policy Optimization
(VDPPO) algorithm exhibited the best performance. We also introduce a novel
metric, the coverage index, for the evaluation of the coverage performance of
the routes generated by our model. This metric is inspired by the predictive
accuracy index (PAI), which is commonly used in criminology to detect hotspots.
Using this metric, we have evaluated the model under various scenarios in which
the number of agents (or patrols), their starting positions, and the level of
information they can observe in the environment have been modified. Results
show that the coordinated routes generated by our model achieve a coverage of
more than $90\%$ of the $3\%$ of graph nodes with the highest crime incidence,
and $65\%$ for $20\%$ of these nodes; $3\%$ and $20\%$ represent the coverage
standards for police resource allocation.

摘要：巡邏策略的有效設計是一個困難且複雜的問題，特別是在中大型區域。目標是以協調的方式規劃特定區域內一組巡邏的最佳路線，以實現區域的最大覆蓋率，同時也試圖將巡邏次數減至最少。在本文中，我們提出了一個基於分散部分可觀察馬可夫決策過程的多主體強化學習 (MARL) 模型，以規劃在表示為無向圖的城市環境中不可預測的巡邏路線。該模型嘗試最大化表徵給定時間範圍內環境的目標函數。我們的模型已經過測試，以優化西班牙馬拉加市三個中等規模區域的警察巡邏路線。目標是根據該市的實際犯罪數據，最大化對犯罪多發區域的監控覆蓋率。為了解決這個問題，已經研究了多個 MARL 演算法，其中 Value Decomposition Proximal Policy Optimization (VDPPO) 演算法表現最佳。我們還引入了一個新的指標，即覆蓋率指數，用於評估我們模型生成的路線的覆蓋率表現。此指標的靈感來自預測準確度指數 (PAI)，它通常用於犯罪學中偵測熱點。使用此指標，我們在各種場景下評估了模型，其中修改了主體（或巡邏）的數量、他們的起始位置以及他們可以在環境中觀察到的資訊層級。結果顯示，我們的模型生成的協調路線達到了對犯罪發生率最高的 $3\%$ 圖節點的 $90\%$ 以上的覆蓋率，而對於 $20\%$ 的這些節點則達到了 $65\%$；$3\%$ 和 $20\%$ 代表了警察資源配置的覆蓋率標準。

##### **An AI-driven framework for rapid and localized optimizations of urban open spaces**
2501.08019v1 by Pegah Eshraghi, Arman Nikkhah Dehnavi, Maedeh Mirdamadi, Riccardo Talami, Zahra-Sadat Zomorodian

As urbanization accelerates, open spaces are increasingly recognized for
their role in enhancing sustainability and well-being, yet they remain
underexplored compared to built spaces. This study introduces an AI-driven
framework that integrates machine learning models (MLMs) and explainable AI
techniques to optimize Sky View Factor (SVF) and visibility, key spatial
metrics influencing thermal comfort and perceived safety in urban spaces.
Unlike global optimization methods, which are computationally intensive and
impractical for localized adjustments, this framework supports incremental
design improvements with lower computational costs and greater flexibility. The
framework employs SHapley Adaptive Explanations (SHAP) to analyze feature
importance and Counterfactual Explanations (CFXs) to propose minimal design
changes. Simulations tested five MLMs, identifying XGBoost as the most
accurate, with building width, park area, and heights of surrounding buildings
as critical for SVF, and distances from southern buildings as key for
visibility. Compared to Genetic Algorithms, which required approximately 15/30
minutes across 3/4 generations to converge, the tested CFX approach achieved
optimized results in 1 minute with a 5% RMSE error, demonstrating significantly
faster performance and suitability for scalable retrofitting strategies. This
interpretable and computationally efficient framework advances urban
performance optimization, providing data-driven insights and practical
retrofitting solutions for enhancing usability and environmental quality across
diverse urban contexts.

摘要：隨著都市化加速，開放空間在提升永續性和福祉方面的作用日益受到重視，但與已建成的空間相比，它們仍未得到充分的探索。本研究引入了一個以 AI 為驅動的架構，它整合了機器學習模型 (MLM) 和可解釋的 AI 技術，以最佳化天空視角因子 (SVF) 和能見度，這些是影響城市空間熱舒適度和感知安全性的關鍵空間指標。與計算密集且不切實際用於局部調整的全局最佳化方法不同，此架構支援以較低的計算成本和更大的靈活性進行增量式設計改進。此架構採用 SHapley 自適應解釋 (SHAP) 來分析特徵重要性，並採用反事實解釋 (CFX) 來提出最小的設計變更。模擬測試了五個 MLM，將 XGBoost 識別為最準確的，其中建築物寬度、公園面積和周圍建築物的高度對於 SVF 至關重要，而與南部建築物的距離對於能見度至關重要。與遺傳演算法相比，遺傳演算法需要大約 15/30 分鐘才能在 3/4 代中收斂，而測試的 CFX 方法在 1 分鐘內以 5% 的 RMSE 誤差實現了最佳化結果，這證明了其顯著更快的效能和適用於可擴充的改造策略。這個可解釋且計算效率高的架構推動了城市效能最佳化，它提供了資料驅動的見解和實用的改造解決方案，以提升不同城市環境中的可用性和環境品質。

##### **TriAdaptLoRA: Brain-Inspired Triangular Adaptive Low-Rank Adaptation for Parameter-Efficient Fine-Tuning**
2501.08008v1 by Yao Liang, Yuwei Wang, Yi Zeng

The fine-tuning of Large Language Models (LLMs) is pivotal for achieving
optimal performance across diverse downstream tasks. However, while full
fine-tuning delivers superior results, it entails significant computational and
resource costs. Parameter-Efficient Fine-Tuning (PEFT) methods, such as LoRA,
address these challenges by reducing the number of trainable parameters, but
they often struggle with rank adjustment efficiency and task-specific
adaptability. We propose Triangular Adaptive Low-Rank Adaptation
(TriAdaptLoRA), a novel PEFT framework inspired by neuroscience principles,
which dynamically optimizes the allocation of trainable parameters.
TriAdaptLoRA introduces three key innovations: 1) a triangular split of
transformation matrices into lower and upper triangular components to maximize
parameter utilization, 2) a parameter importance metric based on normalized
Frobenius norms for efficient adaptation, and 3) an adaptive rank-growth
strategy governed by dynamic thresholds, allowing flexible parameter allocation
across training steps. Experiments conducted on a variety of natural language
understanding and generation tasks demonstrate that TriAdaptLoRA consistently
outperforms existing PEFT methods. It achieves superior performance, enhanced
stability, and reduced computational overhead, particularly under linear
threshold-driven rank growth. These results highlight its efficacy as a
scalable and resource-efficient solution for fine-tuning LLMs.

摘要：大型語言模型 (LLM) 的微調對於在各種下游任務中實現最佳效能至關重要。然而，儘管完全微調可提供優異的結果，但它需要大量的運算和資源成本。參數高效微調 (PEFT) 方法（例如 LoRA）透過減少可訓練參數的數量來解決這些挑戰，但它們通常難以應付秩調整效率和特定任務的適應性。我們提出三角自適應低秩適應 (TriAdaptLoRA)，這是一個受神經科學原理啟發的新穎 PEFT 架構，它動態最佳化可訓練參數的配置。TriAdaptLoRA 引入了三項關鍵創新：1) 將轉換矩陣三角形分割為下三角形和上三角形組成，以最大化參數利用率，2) 一個基於正規化弗羅貝尼烏斯範數的參數重要性度量，以利於高效適應，以及 3) 一個由動態閾值控制的自適應秩增長策略，允許在訓練步驟中靈活配置參數。在各種自然語言理解和生成任務中進行的實驗表明，TriAdaptLoRA 持續優於現有的 PEFT 方法。它在線性閾值驅動的秩增長下，特別是實現了優異的效能、增強的穩定性和減少的運算負擔。這些結果突顯了它作為可擴充且資源高效的 LLM 微調解決方案的效力。

##### **DisCoPatch: Batch Statistics Are All You Need For OOD Detection, But Only If You Can Trust Them**
2501.08005v1 by Francisco Caetano, Christiaan Viviers, Luis A. Zavala-Mondragón, Peter H. N. de With, Fons van der Sommen

Out-of-distribution (OOD) detection holds significant importance across many
applications. While semantic and domain-shift OOD problems are well-studied,
this work focuses on covariate shifts - subtle variations in the data
distribution that can degrade machine learning performance. We hypothesize that
detecting these subtle shifts can improve our understanding of in-distribution
boundaries, ultimately improving OOD detection. In adversarial discriminators
trained with Batch Normalization (BN), real and adversarial samples form
distinct domains with unique batch statistics - a property we exploit for OOD
detection. We introduce DisCoPatch, an unsupervised Adversarial Variational
Autoencoder (VAE) framework that harnesses this mechanism. During inference,
batches consist of patches from the same image, ensuring a consistent data
distribution that allows the model to rely on batch statistics. DisCoPatch uses
the VAE's suboptimal outputs (generated and reconstructed) as negative samples
to train the discriminator, thereby improving its ability to delineate the
boundary between in-distribution samples and covariate shifts. By tightening
this boundary, DisCoPatch achieves state-of-the-art results in public OOD
detection benchmarks. The proposed model not only excels in detecting covariate
shifts, achieving 95.5% AUROC on ImageNet-1K(-C) but also outperforms all prior
methods on public Near-OOD (95.0%) benchmarks. With a compact model size of
25MB, it achieves high OOD detection performance at notably lower latency than
existing methods, making it an efficient and practical solution for real-world
OOD detection applications. The code will be made publicly available

摘要：<paragraph>非分布 (OOD) 偵測在許多應用中都非常重要。雖然語意和領域轉移 OOD 問題已廣受探討，但本研究專注於協變數轉移，這是資料分佈中的細微變化，會降低機器學習效能。我們假設偵測這些細微轉移可以改善我們對分佈內邊界的理解，進而改善 OOD 偵測。在使用批次正規化 (BN) 訓練的對抗判別器中，真實樣本和對抗樣本會形成具有獨特批次統計資料的不同領域，我們利用這個特性進行 OOD 偵測。我們提出 DisCoPatch，一個利用此機制的無監督對抗變異自動編碼器 (VAE) 架構。在推理期間，批次包含來自同一影像的區塊，確保一致的資料分佈，讓模型可以依賴批次統計資料。DisCoPatch 使用 VAE 的次佳輸出 (生成和重建) 作為負樣本來訓練判別器，從而提高其描繪分佈內樣本和協變數轉移之間邊界的能力。透過收緊這個邊界，DisCoPatch 在公開 OOD 偵測基準測試中獲得最先進的結果。所提出的模型不僅在偵測協變數轉移方面表現出色，在 ImageNet-1K(-C) 上達到 95.5% 的 AUROC，而且在公開 Near-OOD (95.0%) 基準測試中也優於所有先前方法。模型大小僅 25MB，以顯著低於現有方法的延遲時間實現高 OOD 偵測效能，使其成為現實世界 OOD 偵測應用程式中一種高效且實用的解決方案。程式碼將公開提供</paragraph>

##### **Maximizing Uncertainty for Federated learning via Bayesian Optimisation-based Model Poisoning**
2501.08002v1 by Marios Aristodemou, Xiaolan Liu, Yuan Wang, Konstantinos G. Kyriakopoulos, Sangarapillai Lambotharan, Qingsong Wei

As we transition from Narrow Artificial Intelligence towards Artificial Super
Intelligence, users are increasingly concerned about their privacy and the
trustworthiness of machine learning (ML) technology. A common denominator for
the metrics of trustworthiness is the quantification of uncertainty inherent in
DL algorithms, and specifically in the model parameters, input data, and model
predictions. One of the common approaches to address privacy-related issues in
DL is to adopt distributed learning such as federated learning (FL), where
private raw data is not shared among users. Despite the privacy-preserving
mechanisms in FL, it still faces challenges in trustworthiness. Specifically,
the malicious users, during training, can systematically create malicious model
parameters to compromise the models predictive and generative capabilities,
resulting in high uncertainty about their reliability. To demonstrate malicious
behaviour, we propose a novel model poisoning attack method named Delphi which
aims to maximise the uncertainty of the global model output. We achieve this by
taking advantage of the relationship between the uncertainty and the model
parameters of the first hidden layer of the local model. Delphi employs two
types of optimisation , Bayesian Optimisation and Least Squares Trust Region,
to search for the optimal poisoned model parameters, named as Delphi-BO and
Delphi-LSTR. We quantify the uncertainty using the KL Divergence to minimise
the distance of the predictive probability distribution towards an uncertain
distribution of model output. Furthermore, we establish a mathematical proof
for the attack effectiveness demonstrated in FL. Numerical results demonstrate
that Delphi-BO induces a higher amount of uncertainty than Delphi-LSTR
highlighting vulnerability of FL systems to model poisoning attacks.

摘要：随着我们从狭义人工智能过渡到人工智能超级智能，用户越来越关注他们的隐私和机器学习 (ML) 技术的可靠性。可信度指标的一个共同点是对深度学习算法中固有的不确定性的量化，特别是在模型参数、输入数据和模型预测中。解决深度学习中与隐私相关问题的一种常见方法是采用分布式学习，例如联邦学习 (FL)，其中私人原始数据不会在用户之间共享。尽管 FL 中有保护隐私的机制，但它在可信度方面仍然面临挑战。具体来说，恶意用户在训练期间可以系统地创建恶意模型参数来损害模型的预测和生成能力，从而导致对其可靠性的高度不确定性。为了证明恶意行为，我们提出了一种名为 Delphi 的新型模型中毒攻击方法，旨在最大化全局模型输出的不确定性。我们通过利用局部模型第一隐藏层的模型参数与不确定性之间的关系来实现这一点。Delphi 采用两种类型的优化，贝叶斯优化和最小二乘信任域，来搜索最优中毒模型参数，称为 Delphi-BO 和 Delphi-LSTR。我们使用 KL 散度量化不确定性，以最小化预测概率分布与模型输出的不确定分布之间的距离。此外，我们为在 FL 中展示的攻击有效性建立了数学证明。数值结果表明，Delphi-BO 引起的不确定性高于 Delphi-LSTR，突出了 FL 系统对模型中毒攻击的脆弱性。

##### **GDiffRetro: Retrosynthesis Prediction with Dual Graph Enhanced Molecular Representation and Diffusion Generation**
2501.08001v1 by Shengyin Sun, Wenhao Yu, Yuxiang Ren, Weitao Du, Liwei Liu, Xuecang Zhang, Ying Hu, Chen Ma

Retrosynthesis prediction focuses on identifying reactants capable of
synthesizing a target product. Typically, the retrosynthesis prediction
involves two phases: Reaction Center Identification and Reactant Generation.
However, we argue that most existing methods suffer from two limitations in the
two phases: (i) Existing models do not adequately capture the ``face''
information in molecular graphs for the reaction center identification. (ii)
Current approaches for the reactant generation predominantly use sequence
generation in a 2D space, which lacks versatility in generating reasonable
distributions for completed reactive groups and overlooks molecules' inherent
3D properties. To overcome the above limitations, we propose GDiffRetro. For
the reaction center identification, GDiffRetro uniquely integrates the original
graph with its corresponding dual graph to represent molecular structures,
which helps guide the model to focus more on the faces in the graph. For the
reactant generation, GDiffRetro employs a conditional diffusion model in 3D to
further transform the obtained synthon into a complete reactant. Our
experimental findings reveal that GDiffRetro outperforms state-of-the-art
semi-template models across various evaluative metrics.

摘要：逆合成预测专注于识别能够合成目标产物的反应物。通常，逆合成预测涉及两个阶段：反应中心识别和反应物生成。然而，我们认为大多数现有方法在两个阶段都存在两个局限性：(i) 现有模型不能充分捕捉反应中心识别的分子图中的“面”信息。(ii) 当前反应物生成方法主要在二维空间中使用序列生成，这缺乏生成合理完成反应基团分布的多功能性，并且忽略了分子的固有 3D 属性。为了克服上述限制，我们提出了 GDiffRetro。对于反应中心识别，GDiffRetro 将原始图与其对应的对偶图唯一地集成在一起以表示分子结构，这有助于引导模型更多地关注图中的面。对于反应物生成，GDiffRetro 在 3D 中采用条件扩散模型，将获得的合成子进一步转化为完整的反应物。我们的实验结果表明，GDiffRetro 在各种评估指标上优于最先进的半模板模型。

##### **LLM-Ehnanced Holonic Architecture for Ad-Hoc Scalable SoS**
2501.07992v1 by Muhammad Ashfaq, Ahmed R. Sadik, Tommi Mikkonen, Muhammad Waseem, Niko Mäkitalo

As modern system of systems (SoS) become increasingly adaptive and human
centred, traditional architectures often struggle to support interoperability,
reconfigurability, and effective human system interaction. This paper addresses
these challenges by advancing the state of the art holonic architecture for
SoS, offering two main contributions to support these adaptive needs. First, we
propose a layered architecture for holons, which includes reasoning,
communication, and capabilities layers. This design facilitates seamless
interoperability among heterogeneous constituent systems by improving data
exchange and integration. Second, inspired by principles of intelligent
manufacturing, we introduce specialised holons namely, supervisor, planner,
task, and resource holons aimed at enhancing the adaptability and
reconfigurability of SoS. These specialised holons utilise large language
models within their reasoning layers to support decision making and ensure real
time adaptability. We demonstrate our approach through a 3D mobility case study
focused on smart city transportation, showcasing its potential for managing
complex, multimodal SoS environments. Additionally, we propose evaluation
methods to assess the architecture efficiency and scalability,laying the
groundwork for future empirical validations through simulations and real world
implementations.

摘要：隨著現代系統系統（SoS）變得越來越具有適應性和以人為中心，傳統架構往往難以支援互操作性、可重新配置性以及有效的人機系統互動。本文透過推進 SoS 的最先進整體架構來解決這些挑戰，並提供兩個主要貢獻來支援這些適應性需求。首先，我們提出了一個用於整體的階層式架構，其中包括推理、通訊和功能層。此設計透過改善資料交換和整合，促進異質構成系統之間的無縫互操作性。其次，受到智慧製造原理的啟發，我們引入了專業整體，即監督者、規劃者、任務和資源整體，旨在增強 SoS 的適應性和可重新配置性。這些專業整體在其推理層中利用大型語言模型來支援決策制定並確保實時適應性。我們透過一個專注於智慧城市運輸的 3D 行動個案研究來展示我們的做法，展示其管理複雜、多模式 SoS 環境的潛力。此外，我們提出了評估方法來評估架構效率和可擴充性，為透過模擬和實際世界實作進行未來的實證驗證奠定基礎。

##### **Training Hybrid Neural Networks with Multimode Optical Nonlinearities Using Digital Twins**
2501.07991v1 by Ilker Oguz, Louis J. E. Suter, Jih-Liang Hsieh, Mustafa Yildirim, Niyazi Ulas Dinc, Christophe Moser, Demetri Psaltis

The ability to train ever-larger neural networks brings artificial
intelligence to the forefront of scientific and technical discoveries. However,
their exponentially increasing size creates a proportionally greater demand for
energy and computational hardware. Incorporating complex physical events in
networks as fixed, efficient computation modules can address this demand by
decreasing the complexity of trainable layers. Here, we utilize ultrashort
pulse propagation in multimode fibers, which perform large-scale nonlinear
transformations, for this purpose. Training the hybrid architecture is achieved
through a neural model that differentiably approximates the optical system. The
training algorithm updates the neural simulator and backpropagates the error
signal over this proxy to optimize layers preceding the optical one. Our
experimental results achieve state-of-the-art image classification accuracies
and simulation fidelity. Moreover, the framework demonstrates exceptional
resilience to experimental drifts. By integrating low-energy physical systems
into neural networks, this approach enables scalable, energy-efficient AI
models with significantly reduced computational demands.

摘要：隨著訓練越來越大型的神經網路的能力，人工智慧躍升至科學和技術發現的最前線。然而，其指數級增長的規模對能源和運算硬體的需求也成正比增加。透過將複雜的物理事件納入網路中，作為固定且有效率的運算模組，可以透過減少可訓練層的複雜度來滿足這項需求。在此，我們利用多模纖維中的超短脈衝傳播，執行大規模非線性轉換，以達到此目的。透過可微分近似光學系統的神經模型，可以訓練混合架構。訓練演算法會更新神經模擬器，並透過此代理程式反向傳播錯誤訊號，以最佳化光學層之前的所有層。我們的實驗結果達到了最先進的影像分類準確度和模擬保真度。此外，此架構展現出對實驗漂移的非凡韌性。透過將低能量物理系統整合到神經網路中，此方法能建構可擴充、節能的 AI 模型，並大幅減少運算需求。

##### **Facial Dynamics in Video: Instruction Tuning for Improved Facial Expression Perception and Contextual Awareness**
2501.07978v1 by Jiaxing Zhao, Boyuan Sun, Xiang Chen, Xihan Wei

Facial expression captioning has found widespread application across various
domains. Recently, the emergence of video Multimodal Large Language Models
(MLLMs) has shown promise in general video understanding tasks. However,
describing facial expressions within videos poses two major challenges for
these models: (1) the lack of adequate datasets and benchmarks, and (2) the
limited visual token capacity of video MLLMs. To address these issues, this
paper introduces a new instruction-following dataset tailored for dynamic
facial expression caption. The dataset comprises 5,033 high-quality video clips
annotated manually, containing over 700,000 tokens. Its purpose is to improve
the capability of video MLLMs to discern subtle facial nuances. Furthermore, we
propose FaceTrack-MM, which leverages a limited number of tokens to encode the
main character's face. This model demonstrates superior performance in tracking
faces and focusing on the facial expressions of the main characters, even in
intricate multi-person scenarios. Additionally, we introduce a novel evaluation
metric combining event extraction, relation classification, and the longest
common subsequence (LCS) algorithm to assess the content consistency and
temporal sequence consistency of generated text. Moreover, we present
FEC-Bench, a benchmark designed to assess the performance of existing video
MLLMs in this specific task. All data and source code will be made publicly
available.

摘要：人臉表情標題在各種領域中已廣泛應用。最近，視頻多模態大型語言模型 (MLLM) 的出現已在一般的視頻理解任務中展現出前景。然而，在視頻中描述人臉表情對這些模型提出了兩大挑戰：(1) 缺乏足夠的數據集和基準，以及 (2) 視頻 MLLM 的視覺令牌容量有限。為了解決這些問題，本文介紹了一個新的指令遵循數據集，專門針對動態人臉表情標題。該數據集包含 5,033 個手動註釋的高品質視頻剪輯，包含超過 700,000 個令牌。其目的是提高視頻 MLLM 辨別細微面部細微差別的能力。此外，我們提出了 FaceTrack-MM，它利用有限數量的令牌對主角色的臉部進行編碼。此模型在追蹤臉部和關注主要角色的面部表情方面表現出優異的性能，即使在複雜的多人場景中也是如此。此外，我們引入了一種新的評估指標，結合事件提取、關係分類和最長公共子序列 (LCS) 演算法，以評估生成文本的內容一致性和時間順序一致性。此外，我們還提出了 FEC-Bench，這是一個基準，旨在評估現有視頻 MLLM 在此特定任務中的性能。所有數據和源代碼都將公開提供。

##### **Comprehensive Metapath-based Heterogeneous Graph Transformer for Gene-Disease Association Prediction**
2501.07970v1 by Wentao Cui, Shoubo Li, Chen Fang, Qingqing Long, Chengrui Wang, Xuezhi Wang, Yuanchun Zhou

Discovering gene-disease associations is crucial for understanding disease
mechanisms, yet identifying these associations remains challenging due to the
time and cost of biological experiments. Computational methods are increasingly
vital for efficient and scalable gene-disease association prediction.
Graph-based learning models, which leverage node features and network
relationships, are commonly employed for biomolecular predictions. However,
existing methods often struggle to effectively integrate node features,
heterogeneous structures, and semantic information. To address these
challenges, we propose COmprehensive MEtapath-based heterogeneous graph
Transformer(COMET) for predicting gene-disease associations. COMET integrates
diverse datasets to construct comprehensive heterogeneous networks,
initializing node features with BioGPT. We define seven Metapaths and utilize a
transformer framework to aggregate Metapath instances, capturing global
contexts and long-distance dependencies. Through intra- and inter-metapath
aggregation using attention mechanisms, COMET fuses latent vectors from
multiple Metapaths to enhance GDA prediction accuracy. Our method demonstrates
superior robustness compared to state-of-the-art approaches. Ablation studies
and visualizations validate COMET's effectiveness, providing valuable insights
for advancing human health research.

摘要：發現基因疾病關聯對於理解疾病機制至關重要，但由於生物實驗的時間和成本，識別這些關聯仍然具有挑戰性。計算方法對於高效且可擴充的基因疾病關聯預測越來越重要。基於圖的學習模型利用節點特徵和網路關係，通常用於生物分子預測。然而，現有方法通常難以有效整合節點特徵、異質結構和語義資訊。為了應對這些挑戰，我們提出了基於綜合元路徑的異質圖轉換器 (COMET)，用於預測基因疾病關聯。COMET 整合了不同的資料集來構建全面的異質網路，使用 BioGPT 初始化節點特徵。我們定義了七個元路徑，並利用轉換器框架來聚合元路徑實例，擷取全局上下文和長距離依賴關係。通過使用注意機制進行元路徑內部和元路徑間聚合，COMET 融合了來自多個元路徑的潛在向量，以增強 GDA 預測準確性。與最先進的方法相比，我們的模型展示了卓越的穩健性。消融研究和視覺化驗證了 COMET 的有效性，為推進人類健康研究提供了有價值的見解。

##### **Self-Instruct Few-Shot Jailbreaking: Decompose the Attack into Pattern and Behavior Learning**
2501.07959v1 by Jiaqi Hua, Wanxu Wei

Recently, several works have been conducted on jailbreaking Large Language
Models (LLMs) with few-shot malicious demos. In particular, Zheng et al. (2024)
focuses on improving the efficiency of Few-Shot Jailbreaking (FSJ) by injecting
special tokens into the demos and employing demo-level random search.
Nevertheless, this method lacks generality since it specifies the
instruction-response structure. Moreover, the reason why inserting special
tokens takes effect in inducing harmful behaviors is only empirically
discussed. In this paper, we take a deeper insight into the mechanism of
special token injection and propose Self-Instruct Few-Shot Jailbreaking
(Self-Instruct-FSJ) facilitated with the demo-level greedy search. This
framework decomposes the FSJ attack into pattern and behavior learning to
exploit the model's vulnerabilities in a more generalized and efficient way. We
conduct elaborate experiments to evaluate our method on common open-source
models and compare it with baseline algorithms. Our code is available at
https://github.com/iphosi/Self-Instruct-FSJ.

摘要：<paragraph>最近，已经对使用少次恶意演示越狱大型语言模型 (LLM) 进行了多项研究。特别是，Zheng 等人 (2024) 专注于通过向演示中注入特殊标记并采用演示级随机搜索来提高少次越狱 (FSJ) 的效率。然而，这种方法缺乏通用性，因为它指定了指令响应结构。此外，为什么插入特殊标记会对诱发有害行为产生效果的原因仅凭经验进行了讨论。在本文中，我们深入了解了特殊标记注入的机制，并提出了在演示级贪婪搜索的帮助下进行自指令少次越狱 (Self-Instruct-FSJ)。此框架将 FSJ 攻击分解为模式和行为学习，以更通用、更有效的方式利用模型的漏洞。我们进行了精心设计的实验，以评估我们在常见开源模型上的方法，并将其与基线算法进行比较。我们的代码可在 https://github.com/iphosi/Self-Instruct-FSJ 获得。</paragraph>

##### **AI Guide Dog: Egocentric Path Prediction on Smartphone**
2501.07957v1 by Aishwarya Jadhav, Jeffery Cao, Abhishree Shetty, Urvashi Priyam Kumar, Aditi Sharma, Ben Sukboontip, Jayant Sravan Tamarapalli, Jingyi Zhang, Anirudh Koul

This paper introduces AI Guide Dog (AIGD), a lightweight egocentric
navigation assistance system for visually impaired individuals, designed for
real-time deployment on smartphones. AIGD addresses key challenges in blind
navigation by employing a vision-only, multi-label classification approach to
predict directional commands, ensuring safe traversal across diverse
environments. We propose a novel technique to enable goal-based outdoor
navigation by integrating GPS signals and high-level directions, while also
addressing uncertain multi-path predictions for destination-free indoor
navigation. Our generalized model is the first navigation assistance system to
handle both goal-oriented and exploratory navigation scenarios across indoor
and outdoor settings, establishing a new state-of-the-art in blind navigation.
We present methods, datasets, evaluations, and deployment insights to encourage
further innovations in assistive navigation systems.

摘要：本篇論文介紹 AI 導盲犬 (AIGD)，這是一種輕量級的第一人稱導航輔助系統，專門為視障人士設計，可在智慧型手機上即時部署。AIGD 透過採用僅視覺的多標籤分類方法來預測方向指令，解決盲人導航中的關鍵挑戰，確保在不同的環境中安全穿越。我們提出了一種新技術，透過整合 GPS 訊號和高階方向，實現以目標為基礎的戶外導航，同時也解決了目的地不明確的室內導航中的多路徑預測不確定性。我們的廣義模型是第一個導航輔助系統，可以在室內和室外環境中處理以目標為導向和探索性的導航場景，在盲人導航領域建立了新的技術水準。我們提出方法、資料集、評估和部署見解，以鼓勵輔助導航系統進一步創新。

##### **Early prediction of the transferability of bovine embryos from videomicroscopy**
2501.07945v1 by Yasmine Hachani, Patrick Bouthemy, Elisa Fromont, Sylvie Ruffini, Ludivine Laffont, Alline de Paula Reis

Videomicroscopy is a promising tool combined with machine learning for
studying the early development of in vitro fertilized bovine embryos and
assessing its transferability as soon as possible. We aim to predict the embryo
transferability within four days at most, taking 2D time-lapse microscopy
videos as input. We formulate this problem as a supervised binary
classification problem for the classes transferable and not transferable. The
challenges are three-fold: 1) poorly discriminating appearance and motion, 2)
class ambiguity, 3) small amount of annotated data. We propose a 3D
convolutional neural network involving three pathways, which makes it
multi-scale in time and able to handle appearance and motion in different ways.
For training, we retain the focal loss. Our model, named SFR, compares
favorably to other methods. Experiments demonstrate its effectiveness and
accuracy for our challenging biological task.

摘要：顯微錄影與機器學習結合，是一種很有前景的工具，可用於研究體外受精牛胚胎的早期發育，並盡快評估其可移植性。我們旨在最多在四天內預測胚胎可移植性，並將 2D 時間差顯微鏡錄影視訊作為輸入。我們將此問題表述為可移植和不可移植類別的監督式二元分類問題。挑戰有三方面：1) 難以區分的樣貌和動作，2) 類別模糊性，3) 標註資料量少。我們提出一個涉及三條路徑的 3D 捲積神經網路，這讓它在時間上具有多重尺度，並能夠以不同的方式處理外觀和動作。在訓練時，我們保留焦點損失。我們名為 SFR 的模型，與其他方法相比之下表現良好。實驗證明了它對我們具有挑戰性的生物任務的有效性和準確性。

##### **Advice for Diabetes Self-Management by ChatGPT Models: Challenges and Recommendations**
2501.07931v1 by Waqar Hussain, John Grundy

Given their ability for advanced reasoning, extensive contextual
understanding, and robust question-answering abilities, large language models
have become prominent in healthcare management research. Despite adeptly
handling a broad spectrum of healthcare inquiries, these models face
significant challenges in delivering accurate and practical advice for chronic
conditions such as diabetes. We evaluate the responses of ChatGPT versions 3.5
and 4 to diabetes patient queries, assessing their depth of medical knowledge
and their capacity to deliver personalized, context-specific advice for
diabetes self-management. Our findings reveal discrepancies in accuracy and
embedded biases, emphasizing the models' limitations in providing tailored
advice unless activated by sophisticated prompting techniques. Additionally, we
observe that both models often provide advice without seeking necessary
clarification, a practice that can result in potentially dangerous advice. This
underscores the limited practical effectiveness of these models without human
oversight in clinical settings. To address these issues, we propose a
commonsense evaluation layer for prompt evaluation and incorporating
disease-specific external memory using an advanced Retrieval Augmented
Generation technique. This approach aims to improve information quality and
reduce misinformation risks, contributing to more reliable AI applications in
healthcare settings. Our findings seek to influence the future direction of AI
in healthcare, enhancing both the scope and quality of its integration.

摘要：由於大型語言模型具有先進推理能力、廣泛的背景理解能力和強大的問題回答能力，因此在醫療保健管理研究中變得突出。儘管這些模型能熟練地處理廣泛的醫療保健查詢，但在提供慢性疾病（例如糖尿病）的準確且實用的建議方面，這些模型面臨著重大的挑戰。我們評估了 ChatGPT 版本 3.5 和 4 對糖尿病患者查詢的回應，評估了他們的醫學知識深度以及提供針對糖尿病自我管理的個性化、特定於背景的建議的能力。我們的研究結果揭示了準確性和內嵌偏差的差異，強調了這些模型在未經複雜提示技術啟用時提供定制建議的局限性。此外，我們觀察到這兩個模型通常在不尋求必要的澄清的情況下提供建議，這種做法可能會導致潛在的危險建議。這凸顯了這些模型在沒有臨床環境中的人工監督的情況下實用有效性有限。為了解決這些問題，我們提出了一個常識評估層，用於提示評估和使用先進的檢索增強生成技術整合特定疾病的外部記憶體。這種方法旨在提高資訊品質並降低錯誤資訊風險，有助於在醫療保健環境中建立更可靠的人工智慧應用程式。我們的研究結果旨在影響人工智慧在醫療保健中的未來方向，同時提升其整合的範圍和品質。

##### **An Adaptive Orthogonal Convolution Scheme for Efficient and Flexible CNN Architectures**
2501.07930v1 by Thibaut Boissin, Franck Mamalet, Thomas Fel, Agustin Martin Picard, Thomas Massena, Mathieu Serrurier

Orthogonal convolutional layers are the workhorse of multiple areas in
machine learning, such as adversarial robustness, normalizing flows, GANs, and
Lipschitzconstrained models. Their ability to preserve norms and ensure stable
gradient propagation makes them valuable for a large range of problems. Despite
their promise, the deployment of orthogonal convolution in large-scale
applications is a significant challenge due to computational overhead and
limited support for modern features like strides, dilations, group
convolutions, and transposed convolutions.In this paper, we introduce AOC
(Adaptative Orthogonal Convolution), a scalable method for constructing
orthogonal convolutions, effectively overcoming these limitations. This
advancement unlocks the construction of architectures that were previously
considered impractical. We demonstrate through our experiments that our method
produces expressive models that become increasingly efficient as they scale. To
foster further advancement, we provide an open-source library implementing this
method, available at https://github.com/thib-s/orthogonium.

摘要：正交卷积层是机器学习中多个领域的引擎，例如对抗鲁棒性、正则化流、GAN 和 Lipschitz 约束模型。它们能够保留范数并确保稳定的梯度传播，使其对于广泛的问题很有价值。尽管有这些优势，但由于计算开销大以及对步幅、扩张、组卷积和转置卷积等现代特性的支持有限，正交卷积在大规模应用中的部署面临着严峻的挑战。在本文中，我们介绍了 AOC（自适应正交卷积），这是一种可扩展的正交卷积构建方法，有效地克服了这些限制。这一进步解锁了以前被认为不切实际的架构的构建。我们通过实验表明，我们的方法产生的表达模型随着规模的扩大而变得越来越高效。为了促进进一步的发展，我们提供了一个实现此方法的开源库，网址为 https://github.com/thib-s/orthogonium。

##### **Gandalf the Red: Adaptive Security for LLMs**
2501.07927v1 by Niklas Pfister, Václav Volhejn, Manuel Knott, Santiago Arias, Julia Bazińska, Mykhailo Bichurin, Alan Commike, Janet Darling, Peter Dienes, Matthew Fiedler, David Haber, Matthias Kraft, Marco Lancini, Max Mathys, Damián Pascual-Ortiz, Jakub Podolak, Adrià Romero-López, Kyriacos Shiarlis, Andreas Signer, Zsolt Terek, Athanasios Theocharis, Daniel Timbrell, Samuel Trautwein, Samuel Watts, Natalie Wu, Mateo Rojas-Carulla

Current evaluations of defenses against prompt attacks in large language
model (LLM) applications often overlook two critical factors: the dynamic
nature of adversarial behavior and the usability penalties imposed on
legitimate users by restrictive defenses. We propose D-SEC (Dynamic Security
Utility Threat Model), which explicitly separates attackers from legitimate
users, models multi-step interactions, and rigorously expresses the
security-utility in an optimizable form. We further address the shortcomings in
existing evaluations by introducing Gandalf, a crowd-sourced, gamified
red-teaming platform designed to generate realistic, adaptive attack datasets.
Using Gandalf, we collect and release a dataset of 279k prompt attacks.
Complemented by benign user data, our analysis reveals the interplay between
security and utility, showing that defenses integrated in the LLM (e.g., system
prompts) can degrade usability even without blocking requests. We demonstrate
that restricted application domains, defense-in-depth, and adaptive defenses
are effective strategies for building secure and useful LLM applications. Code
is available at
\href{https://github.com/lakeraai/dsec-gandalf}{\texttt{https://github.com/lakeraai/dsec-gandalf}}.

摘要：現今針對大型語言模型 (LLM) 應用程式中提示攻擊的防禦評估，往往忽略兩個關鍵因素：對抗行為的動態性質，以及限制性防禦機制對合法使用者的可用性懲罰。我們提出 D-SEC（動態安全效用威脅模型），它明確區分攻擊者和合法使用者，模擬多步驟互動，並嚴謹地以可最佳化的形式表達安全效用。我們進一步透過導入甘道夫來解決現有評估的缺點，甘道夫是一個群眾外包、遊戲化的紅隊平台，旨在產生逼真且適應性強的攻擊資料集。透過甘道夫，我們收集並發布了包含 279k 個提示攻擊的資料集。我們的分析透過良性使用者資料的補充，揭示了安全性和可用性之間的交互作用，顯示整合在 LLM 中的防禦機制（例如系統提示）即使沒有封鎖請求，也可能降低可用性。我們證明了受限應用程式網域、深度防禦和適應性防禦是建構安全且有用的 LLM 應用程式的有效策略。程式碼可於
\href{https://github.com/lakeraai/dsec-gandalf}{\texttt{https://github.com/lakeraai/dsec-gandalf}} 取得。

##### **Exploring Aviation Incident Narratives Using Topic Modeling and Clustering Techniques**
2501.07924v1 by Aziida Nanyonga, Hassan Wasswa, Ugur Turhan, Keith Joiner, Graham Wild

Aviation safety is a global concern, requiring detailed investigations into
incidents to understand contributing factors comprehensively. This study uses
the National Transportation Safety Board (NTSB) dataset. It applies advanced
natural language processing (NLP) techniques, including Latent Dirichlet
Allocation (LDA), Non-Negative Matrix Factorization (NMF), Latent Semantic
Analysis (LSA), Probabilistic Latent Semantic Analysis (pLSA), and K-means
clustering. The main objectives are identifying latent themes, exploring
semantic relationships, assessing probabilistic connections, and cluster
incidents based on shared characteristics. This research contributes to
aviation safety by providing insights into incident narratives and
demonstrating the versatility of NLP and topic modelling techniques in
extracting valuable information from complex datasets. The results, including
topics identified from various techniques, provide an understanding of
recurring themes. Comparative analysis reveals that LDA performed best with a
coherence value of 0.597, pLSA of 0.583, LSA of 0.542, and NMF of 0.437.
K-means clustering further reveals commonalities and unique insights into
incident narratives. In conclusion, this study uncovers latent patterns and
thematic structures within incident narratives, offering a comparative analysis
of multiple-topic modelling techniques. Future research avenues include
exploring temporal patterns, incorporating additional datasets, and developing
predictive models for early identification of safety issues. This research lays
the groundwork for enhancing the understanding and improvement of aviation
safety by utilising the wealth of information embedded in incident narratives.

摘要：航空安全是一項全球關注的事項，需要對事故進行詳細調查，以全面了解促成因素。本研究使用國家運輸安全委員會 (NTSB) 的數據集。它應用先進的自然語言處理 (NLP) 技術，包括隱含狄利克雷分配 (LDA)、非負矩陣分解 (NMF)、隱含語義分析 (LSA)、概率隱含語義分析 (pLSA) 和 K 均值聚類。主要目標是識別潛在主題、探索語義關係、評估概率聯繫，並根據共享特徵對事件進行聚類。本研究通過提供對事故敘述的見解，並展示 NLP 和主題建模技術在從複雜數據集中提取有價值信息的用途廣泛性，為航空安全做出貢獻。結果，包括從各種技術中識別的主題，提供了對重複主題的理解。比較分析表明，LDA 的表現最佳，相干度值為 0.597，pLSA 為 0.583，LSA 為 0.542，NMF 為 0.437。K 均值聚類進一步揭示了事件敘述中的共性和獨特見解。總之，本研究揭示了事件敘述中的潛在模式和主題結構，提供了對多主題建模技術的比較分析。未來的研究途徑包括探索時間模式、納入其他數據集，以及開發用於早期識別安全問題的預測模型。本研究為利用事故敘述中包含的大量信息來增強對航空安全的理解和改進奠定了基礎。

##### **Aviation Safety Enhancement via NLP & Deep Learning: Classifying Flight Phases in ATSB Safety Reports**
2501.07923v1 by Aziida Nanyonga, Hassan Wasswa, Graham Wild

Aviation safety is paramount, demanding precise analysis of safety
occurrences during different flight phases. This study employs Natural Language
Processing (NLP) and Deep Learning models, including LSTM, CNN, Bidirectional
LSTM (BLSTM), and simple Recurrent Neural Networks (sRNN), to classify flight
phases in safety reports from the Australian Transport Safety Bureau (ATSB).
The models exhibited high accuracy, precision, recall, and F1 scores, with LSTM
achieving the highest performance of 87%, 88%, 87%, and 88%, respectively. This
performance highlights their effectiveness in automating safety occurrence
analysis. The integration of NLP and Deep Learning technologies promises
transformative enhancements in aviation safety analysis, enabling targeted
safety measures and streamlined report handling.

摘要：航空安全至上，需要對不同飛行階段的安全事件進行精確分析。本研究採用自然語言處理 (NLP) 和深度學習模型，包括 LSTM、CNN、雙向 LSTM (BLSTM) 和簡單遞迴神經網路 (sRNN)，對澳洲運輸安全局 (ATSB) 的安全報告中的飛行階段進行分類。這些模型展現出高準確度、精確度、召回率和 F1 分數，其中 LSTM 達到最高效能，分別為 87%、88%、87% 和 88%。此效能突顯出它們在自動化安全事件分析方面的效能。NLP 和深度學習技術的整合，有望為航空安全分析帶來變革性的強化，進而實現有針對性的安全措施和簡化報告處理。

##### **Large Language Model Interface for Home Energy Management Systems**
2501.07919v1 by François Michelon, Yihong Zhou, Thomas Morstyn

Home Energy Management Systems (HEMSs) help households tailor their
electricity usage based on power system signals such as energy prices. This
technology helps to reduce energy bills and offers greater demand-side
flexibility that supports the power system stability. However, residents who
lack a technical background may find it difficult to use HEMSs effectively,
because HEMSs require well-formatted parameterization that reflects the
characteristics of the energy resources, houses, and users' needs. Recently,
Large-Language Models (LLMs) have demonstrated an outstanding ability in
language understanding. Motivated by this, we propose an LLM-based interface
that interacts with users to understand and parameterize their
``badly-formatted answers'', and then outputs well-formatted parameters to
implement an HEMS. We further use Reason and Act method (ReAct) and few-shot
prompting to enhance the LLM performance. Evaluating the interface performance
requires multiple user--LLM interactions. To avoid the efforts in finding
volunteer users and reduce the evaluation time, we additionally propose a
method that uses another LLM to simulate users with varying expertise, ranging
from knowledgeable to non-technical. By comprehensive evaluation, the proposed
LLM-based HEMS interface achieves an average parameter retrieval accuracy of
88\%, outperforming benchmark models without ReAct and/or few-shot prompting.

摘要：家庭能源管理系統 (HEMS) 協助家庭根據能源價格等電力系統訊號調整其用電量。此技術有助於減少電費，並提供更大的需求側彈性，以支援電力系統穩定性。然而，缺乏技術背景的住戶可能難以有效使用 HEMS，因為 HEMS 需要格式良好的參數化，以反映能源資源、房屋和使用者需求的特徵。最近，大型語言模型 (LLM) 已展現出在語言理解方面的傑出能力。受此啟發，我們提出了一個基於 LLM 的介面，與使用者互動以了解並參數化其「格式不佳的答案」，然後輸出格式良好的參數來實作 HEMS。我們進一步使用推理和行為方法 (ReAct) 和少次提示來增強 LLM 效能。評估介面效能需要多次使用者與 LLM 互動。為避免尋找志願使用者的努力並減少評估時間，我們另外提出一個使用另一個 LLM 來模擬具有不同專業知識的使用者的方法，範圍從知識豐富到非技術人員。透過全面的評估，所提出的基於 LLM 的 HEMS 介面達到了 88% 的平均參數檢索準確度，優於沒有 ReAct 和/或少次提示的基準模型。

##### **Deep Learning and Natural Language Processing in the Field of Construction**
2501.07911v1 by Rémy Kessler, Nicolas Béchet

This article presents a complete process to extract hypernym relationships in
the field of construction using two main steps: terminology extraction and
detection of hypernyms from these terms. We first describe the corpus analysis
method to extract terminology from a collection of technical specifications in
the field of construction. Using statistics and word n-grams analysis, we
extract the domain's terminology and then perform pruning steps with linguistic
patterns and internet queries to improve the quality of the final terminology.
Second, we present a machine-learning approach based on various words embedding
models and combinations to deal with the detection of hypernyms from the
extracted terminology. Extracted terminology is evaluated using a manual
evaluation carried out by 6 experts in the domain, and the hypernym
identification method is evaluated with different datasets. The global approach
provides relevant and promising results.

摘要：本文提出了一個完整的流程，使用兩個主要步驟在建築領域中提取上位詞關係：術語提取和從這些術語中偵測上位詞。我們首先描述語料庫分析方法，以從建築領域的技術規範集合中提取術語。使用統計和字元 n-grams 分析，我們提取領域的術語，然後使用語言模式和網路查詢執行修剪步驟，以提高最終術語的品質。其次，我們提出一個基於各種字詞嵌入模型和組合的機器學習方法，以處理從提取的術語中偵測上位詞。提取的術語使用由領域中的 6 位專家執行的，手動評估進行評估，並且上位詞識別方法使用不同的資料集進行評估。整體方法提供了相關且有希望的結果。

##### **Logarithmic Memory Networks (LMNs): Efficient Long-Range Sequence Modeling for Resource-Constrained Environments**
2501.07905v1 by Mohamed A. Taha

Long-range sequence modeling is a crucial aspect of natural language
processing and time series analysis. However, traditional models like Recurrent
Neural Networks (RNNs) and Transformers suffer from computational and memory
inefficiencies, especially when dealing with long sequences. This paper
introduces Logarithmic Memory Networks (LMNs), a novel architecture that
leverages a hierarchical logarithmic tree structure to efficiently store and
retrieve past information. LMNs dynamically summarize historical context,
significantly reducing the memory footprint and computational complexity of
attention mechanisms from O(n2) to O(log(n)). The model employs a
single-vector, targeted attention mechanism to access stored information, and
the memory block construction worker (summarizer) layer operates in two modes:
a parallel execution mode during training for efficient processing of
hierarchical tree structures and a sequential execution mode during inference,
which acts as a memory management system. It also implicitly encodes positional
information, eliminating the need for explicit positional encodings. These
features make LMNs a robust and scalable solution for processing long-range
sequences in resource-constrained environments, offering practical improvements
in efficiency and scalability. The code is publicly available under the MIT
License on GitHub: https://github.com/AhmedBoin/LogarithmicMemory.

摘要：長程序列建模是自然語言處理和時間序列分析中至關重要的一面。然而，傳統模型，例如循環神經網路 (RNN) 和 Transformer，在計算和記憶方面效率低落，特別是在處理長序列時。本文介紹了對數記憶網路 (LMN)，這是一種新穎的架構，它利用分層對數樹結構有效地儲存和擷取過去的資訊。LMN 動態地總結歷史脈絡，大幅降低了記憶體佔用空間和注意力機制的計算複雜度，從 O(n2) 降至 O(log(n))。該模型採用單一向量、有針對性的注意力機制來存取儲存的資訊，而記憶體區塊建構器 (摘要器) 層在兩種模式下運作：訓練期間的並行執行模式，用於有效處理分層樹狀結構，以及推論期間的順序執行模式，作為記憶體管理系統。它也隱含地編碼位置資訊，消除了對明確位置編碼的需求。這些特點使 LMN 成為在資源受限環境中處理長程序列的強大且可擴充的解決方案，在效率和可擴充性方面提供了實際的改進。程式碼在 GitHub 上以 MIT 授權公開：https://github.com/AhmedBoin/LogarithmicMemory。

##### **Leveraging Metamemory Mechanisms for Enhanced Data-Free Code Generation in LLMs**
2501.07892v1 by Shuai Wang, Liang Ding, Yibing Zhan, Yong Luo, Zheng He, Dapeng Tao

Automated code generation using large language models (LLMs) has gained
attention due to its efficiency and adaptability. However, real-world coding
tasks or benchmarks like HumanEval and StudentEval often lack dedicated
training datasets, challenging existing few-shot prompting approaches that rely
on reference examples. Inspired by human metamemory-a cognitive process
involving recall and evaluation-we present a novel framework (namely M^2WF) for
improving LLMs' one-time code generation. This approach enables LLMs to
autonomously generate, evaluate, and utilize synthetic examples to enhance
reliability and performance. Unlike prior methods, it minimizes dependency on
curated data and adapts flexibly to various coding scenarios. Our experiments
demonstrate significant improvements in coding benchmarks, offering a scalable
and robust solution for data-free environments. The code and framework will be
publicly available on GitHub and HuggingFace.

摘要：使用大型語言模型 (LLM) 的自動化程式碼生成因其效率和適應性而備受關注。然而，像 HumanEval 和 StudentEval 這樣的真實世界編碼任務或基準通常缺乏專用的訓練資料集，這對依賴參考範例的現有少次提示方法構成了挑戰。受人類元記憶的啟發，這是一種涉及回憶和評估的認知過程，我們提出了一個新的框架 (即 M^2WF) 來改善 LLM 的一次性程式碼生成。這種方法使 LLM 能夠自主生成、評估和利用合成範例來增強可靠性和效能。與之前的做法不同，它最大限度地減少了對策劃資料的依賴性，並靈活地適應各種編碼場景。我們的實驗證明了編碼基準的顯著改進，為無資料環境提供了一個可擴充且穩健的解決方案。程式碼和框架將在 GitHub 和 HuggingFace 上公開。

##### **GRAPHMOE: Amplifying Cognitive Depth of Mixture-of-Experts Network via Introducing Self-Rethinking Mechanism**
2501.07890v1 by Chen Tang, Bo Lv, Zifan Zheng, Bohao Yang, Kun Zhao, Ning Liao, Xiaoxing Wang, Feiyu Xiong, Zhiyu Li, Nayu Liu, Jingchi Jiang

Traditional Mixture-of-Experts (MoE) networks benefit from utilizing multiple
smaller expert models as opposed to a single large network. However, these
experts typically operate independently, leaving a question open about whether
interconnecting these models could enhance the performance of MoE networks. In
response, we introduce GRAPHMOE, a novel method aimed at augmenting the
cognitive depth of language models via a self-rethinking mechanism constructed
on Pseudo GraphMoE networks. GRAPHMOE employs a recurrent routing strategy to
simulate iterative thinking steps, thereby facilitating the flow of information
among expert nodes. We implement the GRAPHMOE architecture using Low-Rank
Adaptation techniques (LoRA) and conduct extensive experiments on various
benchmark datasets. The experimental results reveal that GRAPHMOE outperforms
other LoRA based models, achieving state-of-the-art (SOTA) performance.
Additionally, this study explores a novel recurrent routing strategy that may
inspire further advancements in enhancing the reasoning capabilities of
language models.

摘要：傳統的混合專家 (MoE) 網路受益於使用多個較小的專家模型，而不是單一的大型網路。然而，這些專家通常獨立運作，留下一個問題，即互連這些模型是否可以增強 MoE 網路的效能。為了解決這個問題，我們引入了 GRAPHMOE，這是一種新穎的方法，旨在透過建構在偽圖形 MoE 網路上的自我反思機制來擴增語言模型的認知深度。GRAPHMOE 使用遞迴路由策略來模擬反覆的思考步驟，從而促進專家節點之間的資訊流動。我們使用低秩適應技術 (LoRA) 來實作 GRAPHMOE 架構，並在各種基準資料集上進行廣泛的實驗。實驗結果顯示 GRAPHMOE 優於其他基於 LoRA 的模型，達到了最先進 (SOTA) 的效能。此外，本研究探討了一種新穎的遞迴路由策略，這可能會激勵進一步提升語言模型推理能力的進展。

##### **Tarsier2: Advancing Large Vision-Language Models from Detailed Video Description to Comprehensive Video Understanding**
2501.07888v1 by Liping Yuan, Jiawei Wang, Haomiao Sun, Yuchen Zhang, Yuan Lin

We introduce Tarsier2, a state-of-the-art large vision-language model (LVLM)
designed for generating detailed and accurate video descriptions, while also
exhibiting superior general video understanding capabilities. Tarsier2 achieves
significant advancements through three key upgrades: (1) Scaling pre-training
data from 11M to 40M video-text pairs, enriching both volume and diversity; (2)
Performing fine-grained temporal alignment during supervised fine-tuning; (3)
Using model-based sampling to automatically construct preference data and
applying DPO training for optimization. Extensive experiments show that
Tarsier2-7B consistently outperforms leading proprietary models, including
GPT-4o and Gemini 1.5 Pro, in detailed video description tasks. On the DREAM-1K
benchmark, Tarsier2-7B improves F1 by 2.8\% over GPT-4o and 5.8\% over
Gemini-1.5-Pro. In human side-by-side evaluations, Tarsier2-7B shows a +8.6\%
performance advantage over GPT-4o and +24.9\% over Gemini-1.5-Pro. Tarsier2-7B
also sets new state-of-the-art results across 15 public benchmarks, spanning
tasks such as video question-answering, video grounding, hallucination test,
and embodied question-answering, demonstrating its versatility as a robust
generalist vision-language model.

摘要：<paragraph>我們介紹 Tarsier2，這是一種最先進的大型視覺語言模型 (LVLM)，
專為產生詳細且準確的影片說明而設計，同時還展現出卓越的整體影片理解能力。Tarsier2 透過三項關鍵升級實現顯著進步：(1) 將預訓練
資料從 11M 擴充至 40M 的影片文字配對，豐富數量和多樣性；(2)
在監督微調期間執行細緻的時間對齊；(3)
使用基於模型的抽樣自動建構偏好資料，並應用 DPO 訓練進行最佳化。廣泛的實驗顯示，
Tarsier2-7B 在詳細的影片說明任務中始終優於領先的專有模型，包括
GPT-4o 和 Gemini 1.5 Pro。在 DREAM-1K
基準測試中，Tarsier2-7B 將 F1 提升了 2.8%，優於 GPT-4o，並將
Gemini-1.5-Pro 提升了 5.8%。在人類並排評估中，Tarsier2-7B 顯示出比
GPT-4o 高出 +8.6%，比 Gemini-1.5-Pro 高出 +24.9% 的效能優勢。Tarsier2-7B
也創下 15 個公開基準測試的最新技術成果，涵蓋影片問答、影片接地、幻覺測試，
以及具體問題解答等任務，證明其作為強大通才視覺語言模型的多功能性。</paragraph>

##### **Iterative Label Refinement Matters More than Preference Optimization under Weak Supervision**
2501.07886v1 by Yaowen Ye, Cassidy Laidlaw, Jacob Steinhardt

Language model (LM) post-training relies on two stages of human supervision:
task demonstrations for supervised finetuning (SFT), followed by preference
comparisons for reinforcement learning from human feedback (RLHF). As LMs
become more capable, the tasks they are given become harder to supervise. Will
post-training remain effective under unreliable supervision? To test this, we
simulate unreliable demonstrations and comparison feedback using small LMs and
time-constrained humans. We find that in the presence of unreliable
supervision, SFT still retains some effectiveness, but DPO (a common RLHF
algorithm) fails to improve the model beyond SFT. To address this, we propose
iterative label refinement (ILR) as an alternative to RLHF. ILR improves the
SFT data by using comparison feedback to decide whether human demonstrations
should be replaced by model-generated alternatives, then retrains the model via
SFT on the updated data. SFT+ILR outperforms SFT+DPO on several tasks with
unreliable supervision (math, coding, and safe instruction-following). Our
findings suggest that as LMs are used for complex tasks where human supervision
is unreliable, RLHF may no longer be the best use of human comparison feedback;
instead, it is better to direct feedback towards improving the training data
rather than continually training the model. Our code and data are available at
https://github.com/helloelwin/iterative-label-refinement.

摘要：語言模型 (LM) 後續訓練依賴於人類監督的兩個階段：監督微調 (SFT) 的任務示範，接著是人類回饋 (RLHF) 的強化學習偏好比較。隨著 LM 變得更強大，給予它們的任務也變得更難以監督。後續訓練在不可靠的監督下仍會有效嗎？為測試這一點，我們使用小型 LM 和時間受限的人類模擬不可靠的示範和比較回饋。我們發現，在不可靠的監督下，SFT 仍然保留一些效能，但 DPO（一種常見的 RLHF 演算法）無法將模型提升至超越 SFT。為了解決這個問題，我們提出反覆標籤修正 (ILR) 作為 RLHF 的替代方案。ILR 使用比較回饋來決定是否應將人類示範替換為模型產生的替代方案，藉此改善 SFT 資料，然後透過 SFT 在更新的資料上重新訓練模型。SFT+ILR 在多項具有不可靠監督的任務（數學、編碼和安全指令遵循）上優於 SFT+DPO。我們的發現表明，隨著 LM 被用於人類監督不可靠的複雜任務，RLHF 可能不再是人類比較回饋的最佳用途；相反地，最好將回饋導向改善訓練資料，而不是持續訓練模型。我們的程式碼和資料可在 https://github.com/helloelwin/iterative-label-refinement 取得。

##### **Continual Learning with Embedding Layer Surgery and Task-wise Beam Search using Whisper**
2501.07875v1 by Chin Yuen Kwok, Jia Qi Yip, Eng Siong Chng

Current Multilingual ASR models only support a fraction of the world's
languages. Continual Learning (CL) aims to tackle this problem by adding new
languages to pre-trained models while avoiding the loss of performance on
existing languages, also known as Catastrophic Forgetting (CF). However,
existing CL methods overlook the adaptation of the token embedding lookup table
at the decoder, despite its significant contribution to CF. We propose
Embedding Layer Surgery where separate copies of the token embeddings are
created for each new languages, and one of the copies is selected to replace
the old languages embeddings when transcribing the corresponding new language.
Unfortunately, this approach means LID errors also cause incorrect ASR
embedding selection. Our Task-wise Beam Search allows self-correction for such
mistakes. By adapting Whisper to 10 hours of data for each of 10 unseen
languages from Common Voice, results show that our method reduces the Average
WER (AWER) of pre-trained languages from 14.2% to 11.9% compared with
Experience Replay, without compromising the AWER of the unseen languages.

摘要：目前的多語言 ASR 模型僅支援世界語言的一小部分。持續學習 (CL) 旨在透過將新的語言新增至預先訓練的模型來解決此問題，同時避免既有語言的效能損失，也就是所謂的災難性遺忘 (CF)。然而，現有的 CL 方法忽略了解碼器中權杖嵌入查詢表的適應，儘管它對 CF 有顯著貢獻。我們提出嵌入層手術，其中為每種新語言建立權杖嵌入的獨立副本，並選取其中一個副本取代轉錄對應新語言時的舊語言嵌入。不幸的是，此方法表示 LID 錯誤也會導致不正確的 ASR 嵌入選取。我們的任務明智波束搜尋允許針對此類錯誤進行自我修正。透過將 Whisper 適應至來自 Common Voice 的 10 種未見語言的 10 小時資料，結果顯示，與經驗重播相比，我們的方法將預先訓練語言的平均 WER (AWER) 從 14.2% 降低至 11.9%，同時不影響未見語言的 AWER。

##### **ReARTeR: Retrieval-Augmented Reasoning with Trustworthy Process Rewarding**
2501.07861v1 by Zhongxiang Sun, Qipeng Wang, Weijie Yu, Xiaoxue Zang, Kai Zheng, Jun Xu, Xiao Zhang, Song Yang, Han Li

Retrieval-Augmented Generation (RAG) systems for Large Language Models (LLMs)
hold promise in knowledge-intensive tasks but face limitations in complex
multi-step reasoning. While recent methods have integrated RAG with
chain-of-thought reasoning or test-time search using Process Reward Models
(PRMs), these approaches encounter challenges such as a lack of explanations,
bias in PRM training data, early-step bias in PRM scores, and insufficient
post-training optimization of reasoning potential. To address these issues, we
propose Retrieval-Augmented Reasoning through Trustworthy Process Rewarding
(ReARTeR), a framework that enhances RAG systems' reasoning capabilities
through post-training and test-time scaling. At test time, ReARTeR introduces
Trustworthy Process Rewarding via a Process Reward Model for accurate scalar
scoring and a Process Explanation Model (PEM) for generating natural language
explanations, enabling step refinement. During post-training, it utilizes Monte
Carlo Tree Search guided by Trustworthy Process Rewarding to collect
high-quality step-level preference data, optimized through Iterative Preference
Optimization. ReARTeR addresses three core challenges: (1) misalignment between
PRM and PEM, tackled through off-policy preference learning; (2) bias in PRM
training data, mitigated by balanced annotation methods and stronger
annotations for challenging examples; and (3) early-step bias in PRM, resolved
through a temporal-difference-based look-ahead search strategy. Experimental
results on multi-step reasoning benchmarks demonstrate significant
improvements, underscoring ReARTeR's potential to advance the reasoning
capabilities of RAG systems.

摘要：<paragraph>針對大型語言模型 (LLM) 的檢索增強產生 (RAG) 系統在知識密集型任務中大有可為，但在複雜的多步驟推理中卻面臨限制。雖然最近的方法已將 RAG 與思考鏈推理或使用流程獎勵模型 (PRM) 的測試時間搜尋整合在一起，但這些方法會遇到諸如缺乏解釋、PRM 訓練資料中的偏差、PRM 分數中的早期步驟偏差，以及推理潛力的訓練後最佳化不足等挑戰。為了解決這些問題，我們提出透過可信賴流程獎勵的檢索增強推理 (ReARTeR)，這是一個透過訓練後和測試時間縮放來增強 RAG 系統推理能力的架構。在測試時間，ReARTeR 透過流程獎勵模型引入可信賴流程獎勵，以進行準確的標量評分，並透過流程解釋模型 (PEM) 產生自然語言解釋，進而能夠進行步驟精煉。在訓練後期間，它利用由可信賴流程獎勵引導的蒙地卡羅樹狀搜尋來收集高品質的步驟層級偏好資料，並透過反覆偏好最佳化進行最佳化。ReARTeR 解決了三個核心挑戰：(1) PRM 和 PEM 之間的錯位，透過非策略偏好學習來解決；(2) PRM 訓練資料中的偏差，透過平衡註解方法和針對具有挑戰性範例的更強註解來減輕；(3) PRM 中的早期步驟偏差，透過基於時間差的超前搜尋策略來解決。多步驟推理基準上的實驗結果證明了顯著的改進，突顯了 ReARTeR 在提升 RAG 系統推理能力方面的潛力。</paragraph>

##### **Hierarchical Repository-Level Code Summarization for Business Applications Using Local LLMs**
2501.07857v1 by Nilesh Dhulshette, Sapan Shah, Vinay Kulkarni

In large-scale software development, understanding the functionality and
intent behind complex codebases is critical for effective development and
maintenance. While code summarization has been widely studied, existing methods
primarily focus on smaller code units, such as functions, and struggle with
larger code artifacts like files and packages. Additionally, current
summarization models tend to emphasize low-level implementation details, often
overlooking the domain and business context that are crucial for real-world
applications. This paper proposes a two-step hierarchical approach for
repository-level code summarization, tailored to business applications. First,
smaller code units such as functions and variables are identified using syntax
analysis and summarized with local LLMs. These summaries are then aggregated to
generate higher-level file and package summaries. To ensure the summaries are
grounded in business context, we design custom prompts that capture the
intended purpose of code artifacts based on the domain and problem context of
the business application. We evaluate our approach on a business support system
(BSS) for the telecommunications domain, showing that syntax analysis-based
hierarchical summarization improves coverage, while business-context grounding
enhances the relevance of the generated summaries.

摘要：在大規模軟體開發中，了解複雜程式碼庫背後的運作功能和意圖對於有效開發和維護至關重要。雖然程式碼摘要已被廣泛研究，但現有方法主要集中於較小的程式碼單元，例如函式，並且難以處理更大的程式碼人工製品，例如檔案和套件。此外，目前的摘要模型傾向於強調低層級的實作細節，通常忽略了對於真實世界應用程式至關重要的網域和商業脈絡。本文提出了一個針對商業應用程式量身打造的兩步驟階層式方法，用於儲存庫層級程式碼摘要。首先，使用語法分析識別較小的程式碼單元，例如函式和變數，並使用區域 LLM 進行摘要。然後將這些摘要彙總以產生更高級別的檔案和套件摘要。為確保摘要建立在商業脈絡中，我們設計了自訂提示，根據商業應用的網域和問題脈絡擷取程式碼人工製品的預期目的。我們在電信網域的商業支援系統 (BSS) 上評估了我們的做法，結果顯示基於語法分析的階層式摘要改進了涵蓋範圍，而商業脈絡基礎則增強了所產生摘要的相關性。

##### **State-of-the-Art Transformer Models for Image Super-Resolution: Techniques, Challenges, and Applications**
2501.07855v1 by Debasish Dutta, Deepjyoti Chetia, Neeharika Sonowal, Sanjib Kr Kalita

Image Super-Resolution (SR) aims to recover a high-resolution image from its
low-resolution counterpart, which has been affected by a specific degradation
process. This is achieved by enhancing detail and visual quality. Recent
advancements in transformer-based methods have remolded image super-resolution
by enabling high-quality reconstructions surpassing previous deep-learning
approaches like CNN and GAN-based. This effectively addresses the limitations
of previous methods, such as limited receptive fields, poor global context
capture, and challenges in high-frequency detail recovery. Additionally, the
paper reviews recent trends and advancements in transformer-based SR models,
exploring various innovative techniques and architectures that combine
transformers with traditional networks to balance global and local contexts.
These neoteric methods are critically analyzed, revealing promising yet
unexplored gaps and potential directions for future research. Several
visualizations of models and techniques are included to foster a holistic
understanding of recent trends. This work seeks to offer a structured roadmap
for researchers at the forefront of deep learning, specifically exploring the
impact of transformers on super-resolution techniques.

摘要：影像超解析度 (SR) 旨在從低解析度的影像中復原高解析度的影像，而低解析度的影像會受到特定劣化過程的影響。這種復原是透過增強細節與視覺品質來達成。最近在基於 Transformer 的方法上的進展，透過實現優於先前深度學習方法（例如基於 CNN 和 GAN 的方法）的高品質重建，來改造影像超解析度。這有效地解決了先前方法的限制，例如有限的感受野、不佳的整體脈絡擷取，以及高頻細節復原的挑戰。此外，這篇論文回顧了基於 Transformer 的 SR 模型的近期趨勢與進展，探討各種創新的技術與架構，這些技術與架構結合 Transformer 與傳統網路，以平衡整體與局部脈絡。這些新穎的方法經過嚴格分析，揭露了有前途但尚未探索的差距，以及未來研究的潛在方向。包含了模型與技術的若干視覺化，以促進對近期趨勢的全面了解。這項工作旨在為深層學習領域的前沿研究人員提供一個架構化的藍圖，特別探討 Transformer 對超解析度技術的影響。

##### **Optimizing Language Models for Grammatical Acceptability: A Comparative Study of Fine-Tuning Techniques**
2501.07853v1 by Shobhit Ratan, Farley Knight, Ghada Jerfel, Sze Chung Ho

This study explores the fine-tuning (FT) of the Open Pre-trained Transformer
(OPT-125M) for grammatical acceptability tasks using the CoLA dataset. By
comparing Vanilla-Fine-Tuning (VFT), Pattern-Based-Fine-Tuning (PBFT), and
Parameter-Efficient Fine-Tuning techniques (PEFT) like Low-Rank Adaptation
(LoRA), we demonstrate significant improvements in computational efficiency
while maintaining high accuracy. Our experiments reveal that while VFT achieves
the highest accuracy (81.2%), LoRA enhancing FT by reducing memory usage and
iteration time by more than 50%, and increases accuracy in PBFT case. Context
Distillation (CD), though computationally efficient, underperformed with
accuracy around 31%. Our findings contribute to democratizing access to large
language models (LLM) by reducing computational barriers.

摘要：本研究探討了使用 CoLA 資料集針對語法可接受性任務對開放式預訓練Transformer (OPT-125M) 進行微調 (FT)。透過比較香草微調 (VFT)、基於模式的微調 (PBFT) 和參數有效微調技術 (PEFT)（例如低秩適應 (LoRA)），我們證明了在維持高準確度的同時，顯著提高了運算效率。我們的實驗顯示，儘管 VFT 達到了最高的準確度 (81.2%)，但 LoRA 透過減少記憶體使用量和迭代時間超過 50% 來增強 FT，並提高了 PBFT 案例的準確度。脈絡蒸餾 (CD) 雖然運算效率高，但準確度僅約 31%，表現不佳。我們的研究結果有助於透過降低運算障礙，讓更多人使用大型語言模型 (LLM)。

##### **Unveiling Provider Bias in Large Language Models for Code Generation**
2501.07849v1 by Xiaoyu Zhang, Juan Zhai, Shiqing Ma, Qingshuang Bao, Weipeng Jiang, Chao Shen, Yang Liu

Large Language Models (LLMs) have emerged as the new recommendation engines,
outperforming traditional methods in both capability and scope, particularly in
code generation applications. Our research reveals a novel provider bias in
LLMs, namely without explicit input prompts, these models show systematic
preferences for services from specific providers in their recommendations
(e.g., favoring Google Cloud over Microsoft Azure). This bias holds significant
implications for market dynamics and societal equilibrium, potentially
promoting digital monopolies. It may also deceive users and violate their
expectations, leading to various consequences. This paper presents the first
comprehensive empirical study of provider bias in LLM code generation. We
develop a systematic methodology encompassing an automated pipeline for dataset
generation, incorporating 6 distinct coding task categories and 30 real-world
application scenarios. Our analysis encompasses over 600,000 LLM-generated
responses across seven state-of-the-art models, utilizing approximately 500
million tokens (equivalent to \$5,000+ in computational costs). The study
evaluates both the generated code snippets and their embedded service provider
selections to quantify provider bias. Additionally, we conduct a comparative
analysis of seven debiasing prompting techniques to assess their efficacy in
mitigating these biases. Our findings demonstrate that LLMs exhibit significant
provider preferences, predominantly favoring services from Google and Amazon,
and can autonomously modify input code to incorporate their preferred providers
without users' requests. Notably, we observe discrepancies between providers
recommended in conversational contexts versus those implemented in generated
code. The complete dataset and analysis results are available in our
repository.

摘要：大型語言模型 (LLM) 已成為新的推薦引擎，在能力和範圍上都優於傳統方法，特別是在程式碼產生應用中。我們的研究揭露了 LLM 中一種新的供應商偏見，即在沒有明確輸入提示的情況下，這些模型在其推薦中系統性地偏好特定供應商的服務（例如，偏好 Google Cloud 而非 Microsoft Azure）。這種偏見對市場動態和社會平衡具有重大影響，可能會促進數位壟斷。它也可能欺騙使用者並違反他們的期望，導致各種後果。本文提出了第一個關於 LLM 程式碼產生中供應商偏見的全面實證研究。我們開發了一種系統化的方法，包括一個用於產生資料集的自動化流程，其中包含 6 個不同的編碼任務類別和 30 個真實世界的應用場景。我們的分析涵蓋了七個最先進模型產生的超過 600,000 個 LLM 回應，使用了大約 5 億個代幣（相當於 5,000 美元以上的運算成本）。該研究評估了產生的程式碼片段及其嵌入的服務供應商選擇，以量化供應商偏見。此外，我們對七種去偏提示技術進行了比較分析，以評估它們在減輕這些偏見方面的效力。我們的研究結果表明，LLM 表現出顯著的供應商偏好，主要偏好 Google 和 Amazon 的服務，並且可以在沒有使用者要求的情況下自主修改輸入程式碼以納入其首選供應商。值得注意的是，我們觀察到在對話情境中推薦的供應商與在產生的程式碼中實現的供應商之間存在差異。完整的資料集和分析結果可在我們的儲存庫中找到。

##### **Reasoning with Graphs: Structuring Implicit Knowledge to Enhance LLMs Reasoning**
2501.07845v1 by Haoyu Han, Yaochen Xie, Hui Liu, Xianfeng Tang, Sreyashi Nag, William Headden, Hui Liu, Yang Li, Chen Luo, Shuiwang Ji, Qi He, Jiliang Tang

Large language models (LLMs) have demonstrated remarkable success across a
wide range of tasks; however, they still encounter challenges in reasoning
tasks that require understanding and inferring relationships between distinct
pieces of information within text sequences. This challenge is particularly
pronounced in tasks involving multi-step processes, such as logical reasoning
and multi-hop question answering, where understanding implicit relationships
between entities and leveraging multi-hop connections in the given context are
crucial. Graphs, as fundamental data structures, explicitly represent pairwise
relationships between entities, thereby offering the potential to enhance LLMs'
reasoning capabilities. External graphs have proven effective in supporting
LLMs across multiple tasks. However, in many reasoning tasks, no pre-existing
graph structure is provided. Can we structure implicit knowledge derived from
context into graphs to assist LLMs in reasoning? In this paper, we propose
Reasoning with Graphs (RwG) by first constructing explicit graphs from the
context and then leveraging these graphs to enhance LLM reasoning performance
on reasoning tasks. Extensive experiments demonstrate the effectiveness of the
proposed method in improving both logical reasoning and multi-hop question
answering tasks.

摘要：大型語言模型 (LLM) 已在各種任務中展現出顯著的成功；然而，它們在推理任務中仍會遇到挑戰，這些任務需要理解和推論文字序列中不同資訊片段之間的關係。這個挑戰在涉及多步驟程序的任務中特別明顯，例如邏輯推理和多跳問題解答，其中理解實體之間的隱含關係並利用給定脈絡中的多跳連接至關重要。圖形作為基本的資料結構，明確表示實體之間成對的關係，從而提供增強 LLM 推理能力的潛力。外部圖形已被證明可以有效支援 LLM 執行多項任務。然而，在許多推理任務中，並沒有提供預先存在的圖形結構。我們能將從脈絡中衍生的隱含知識結構成圖形，以協助 LLM 進行推理嗎？在本文中，我們提出使用圖形進行推理 (RwG)，方法是首先從脈絡中建構明確的圖形，然後利用這些圖形來增強 LLM 在推理任務中的推理效能。廣泛的實驗證明了所提出的方法在改進邏輯推理和多跳問題解答任務方面的有效性。

##### **A Driver Advisory System Based on Large Language Model for High-speed Train**
2501.07837v1 by Y. C. Luo, J. Xun, W. Wang, R. Z. Zhang, Z. C. Zhao

With the rapid development of China high-speed railway, drivers face
increasingly significant technical challenges during operations, such as fault
handling. Currently, drivers depend on the onboard mechanic when facing
technical issues, for instance, traction loss or sensor faults. This dependency
can hinder effective operation, even lead to accidents, while waiting for
faults to be addressed. To enhance the accuracy and explainability of actions
during fault handling, an Intelligent Driver Advisory System (IDAS) framework
based on a large language model (LLM) named IDAS-LLM, is introduced. Initially,
domain-fine-tuning of the LLM is performed using a constructed railway
knowledge question-and-answer dataset to improve answer accuracy in
railway-related questions. Subsequently, integration of the Retrieval-augmented
Generation (RAG) architecture is pursued for system design to enhance the
explainability of generated responses. Comparative experiments are conducted
using the constructed railway driving knowledge assessment dataset. Results
indicate that domain-fine-tuned LLMs show an improvement in answer accuracy by
an average of 10%, outperforming some current mainstream LLMs. Additionally,
the inclusion of the RAG framework increases the average recall rate of
question-and-answer sessions by about 4%. Finally, the fault handling
capability of IDAS-LLM is demonstrated through simulations of real operational
scenarios, proving that the proposed framework has practical application
prospects.

摘要：隨著中國高速鐵路的快速發展，司機在營運過程中面臨越來越嚴峻的技術挑戰，例如故障處理。目前，司機在面對技術問題時依賴車載機械師，例如牽引力損失或感測器故障。這種依賴性可能會阻礙有效操作，甚至導致事故，同時等待解決故障。為了提高故障處理期間動作的準確性和可解釋性，引入了基於大型語言模型 (LLM) 名為 IDAS-LLM 的智能駕駛員諮詢系統 (IDAS) 框架。最初，LLM 的領域微調是使用構建的鐵路知識問答數據集進行的，以提高鐵路相關問題的回答準確性。隨後，尋求將檢索增強生成 (RAG) 架構整合到系統設計中，以增強生成回應的可解釋性。使用構建的鐵路駕駛知識評估數據集進行比較實驗。結果表明，領域微調的 LLM 將回答準確性平均提高了 10%，優於當前一些主流的 LLM。此外，RAG 框架的納入將問答會話的平均召回率提高了約 4%。最後，通過模擬實際操作場景證明了 IDAS-LLM 的故障處理能力，證明了所提出的框架具有實際應用前景。

##### **Flow: A Modular Approach to Automated Agentic Workflow Generation**
2501.07834v1 by Boye Niu, Yiliao Song, Kai Lian, Yifan Shen, Yu Yao, Kun Zhang, Tongliang Liu

Multi-agent frameworks powered by large language models (LLMs) have
demonstrated great success in automated planning and task execution. However,
the effective adjustment of Agentic workflows during execution has not been
well-studied. A effective workflow adjustment is crucial, as in many real-world
scenarios, the initial plan must adjust to unforeseen challenges and changing
conditions in real-time to ensure the efficient execution of complex tasks. In
this paper, we define workflows as an activity-on-vertex (AOV) graphs. We
continuously refine the workflow by dynamically adjusting task allocations
based on historical performance and previous AOV with LLM agents. To further
enhance system performance, we emphasize modularity in workflow design based on
measuring parallelism and dependence complexity. Our proposed multi-agent
framework achieved efficient sub-task concurrent execution, goal achievement,
and error tolerance. Empirical results across different practical tasks
demonstrate dramatic improvements in the efficiency of multi-agent frameworks
through dynamic workflow updating and modularization.

摘要：大型語言模型（LLM）驅動的多代理架構已在自動化規劃和任務執行中展現出巨大的成功。然而，在執行期間有效調整代理工作流程尚未得到充分研究。有效的工作流程調整至關重要，因為在許多實際場景中，初始計畫必須即時調整以應對無法預見的挑戰和不斷變化的條件，以確保複雜任務的有效執行。在本文中，我們將工作流程定義為頂點上的活動（AOV）圖形。我們根據歷史績效和先前的 AOV 與 LLM 代理，透過動態調整任務分配，持續優化工作流程。為了進一步提升系統效能，我們強調基於測量並行性和依賴複雜性的工作流程設計中的模組化。我們提出的多代理架構達到了有效子任務並行執行、目標達成和容錯。跨不同實際任務的實證結果證明，透過動態工作流程更新和模組化，多代理架構的效率有了顯著的提升。

##### **Real-time Verification and Refinement of Language Model Text Generation**
2501.07824v1 by Joonho Ko, Jinheon Baek, Sung Ju Hwang

Large language models (LLMs) have shown remarkable performance across a wide
range of natural language tasks. However, a critical challenge remains in that
they sometimes generate factually incorrect answers. To address this, while
many previous work has focused on identifying errors in their generation and
further refining them, they are slow in deployment since they are designed to
verify the response from LLMs only after their entire generation (from the
first to last tokens) is done. Further, we observe that once LLMs generate
incorrect tokens early on, there is a higher likelihood that subsequent tokens
will also be factually incorrect. To this end, in this work, we propose
Streaming-VR (Streaming Verification and Refinement), a novel approach designed
to enhance the efficiency of verification and refinement of LLM outputs.
Specifically, the proposed Streaming-VR enables on-the-fly verification and
correction of tokens as they are being generated, similar to a streaming
process, ensuring that each subset of tokens is checked and refined in
real-time by another LLM as the LLM constructs its response. Through
comprehensive evaluations on multiple datasets, we demonstrate that our
approach not only enhances the factual accuracy of LLMs, but also offers a more
efficient solution compared to prior refinement methods.

摘要：大型語言模型 (LLM) 在廣泛的自然語言任務中展現出卓越的表現。然而，一個關鍵的挑戰在於它們有時會產生事實上不正確的答案。為了解決這個問題，雖然許多先前的工作專注於識別它們產生的錯誤並進一步修正，但由於它們被設計為僅在它們的整個產生（從第一個到最後一個符號）完成後才驗證 LLM 的回應，因此它們的部署速度很慢。此外，我們觀察到，一旦 LLM 在早期產生不正確的符號，後續符號也更有可能在事實上不正確。為此，在這項工作中，我們提出了串流 VR（串流驗證和修正），這是一種新穎的方法，旨在提高 LLM 輸出的驗證和修正效率。具體來說，所提出的串流 VR 能夠在符號被產生的同時對其進行即時驗證和修正，類似於串流處理，確保符號的每個子集在 LLM 建構其回應時由另一個 LLM 即時檢查和修正。透過對多個資料集進行全面的評估，我們證明了我們的方法不僅增強了 LLM 的事實準確性，而且與先前的修正方法相比，還提供了一個更有效的解決方案。

##### **A Multi-Encoder Frozen-Decoder Approach for Fine-Tuning Large Language Models**
2501.07818v1 by Kaustubh D. Dhole

Among parameter-efficient fine-tuning methods, freezing has emerged as a
popular strategy for speeding up training, reducing catastrophic forgetting,
and improving downstream performance. We investigate the impact of freezing the
decoder in a multi-task setup comprising diverse natural language tasks, aiming
to reduce deployment overhead and enhance portability to novel tasks. Our
experiments, conducted by fine-tuning both individual and multi-task setups on
the AlexaTM model, reveal that freezing decoders is highly effective for tasks
with natural language outputs and mitigates catastrophic forgetting in
multilingual tasks. However, we find that pairing frozen decoders with a larger
model can effectively maintain or even enhance performance in structured and QA
tasks, making it a viable strategy for a broader range of task types.

摘要：在參數高效微調方法中，凍結已成為一種流行的策略，用於加速訓練、減少災難性遺忘，並改善下游效能。我們研究了在包含多種自然語言任務的多任務設定中凍結解碼器的影響，旨在減少部署開銷並增強對新任務的可移植性。我們的實驗通過在 AlexaTM 模型上微調個別和多任務設定進行，結果表明凍結解碼器對於具有自然語言輸出的任務非常有效，並減輕了多語言任務中的災難性遺忘。然而，我們發現將凍結的解碼器與較大的模型配對可以有效地維持甚至增強結構化和問答任務中的效能，這使其成為更廣泛任務類型的可行策略。

##### **Agent-Centric Projection of Prompting Techniques and Implications for Synthetic Training Data for Large Language Models**
2501.07815v1 by Dhruv Dhamani, Mary Lou Maher

Recent advances in prompting techniques and multi-agent systems for Large
Language Models (LLMs) have produced increasingly complex approaches. However,
we lack a framework for characterizing and comparing prompting techniques or
understanding their relationship to multi-agent LLM systems. This position
paper introduces and explains the concepts of linear contexts (a single,
continuous sequence of interactions) and non-linear contexts (branching or
multi-path) in LLM systems. These concepts enable the development of an
agent-centric projection of prompting techniques, a framework that can reveal
deep connections between prompting strategies and multi-agent systems. We
propose three conjectures based on this framework: (1) results from non-linear
prompting techniques can predict outcomes in equivalent multi-agent systems,
(2) multi-agent system architectures can be replicated through single-LLM
prompting techniques that simulate equivalent interaction patterns, and (3)
these equivalences suggest novel approaches for generating synthetic training
data. We argue that this perspective enables systematic cross-pollination of
research findings between prompting and multi-agent domains, while providing
new directions for improving both the design and training of future LLM
systems.

摘要：最近在大型語言模型 (LLM) 的提示技術和多主體系統方面的進展產生了越來越複雜的方法。然而，我們缺乏一個架構來表徵和比較提示技術，或了解它們與多主體 LLM 系統的關係。本文介紹並解釋了 LLM 系統中線性脈絡（單一、連續的互動序列）和非線性脈絡（分支或多路徑）的概念。這些概念能夠開發出以主體為中心的提示技術投影，一個可以揭示提示策略和多主體系統之間深層聯繫的架構。我們基於這個架構提出三個猜想：(1) 非線性提示技術的結果可以預測等效多主體系統中的結果，(2) 多主體系統架構可以透過模擬等效互動模式的單一 LLM 提示技術來複製，以及 (3) 這些等效性建議了產生合成訓練資料的新方法。我們認為，這個觀點能夠讓提示和多主體領域之間的研究發現進行系統性的交互授粉，同時為改進未來 LLM 系統的設計和訓練提供新的方向。

##### **STTS-EAD: Improving Spatio-Temporal Learning Based Time Series Prediction via**
2501.07814v1 by Yuanyuan Liang, Tianhao Zhang, Tingyu Xie

Handling anomalies is a critical preprocessing step in multivariate time
series prediction. However, existing approaches that separate anomaly
preprocessing from model training for multivariate time series prediction
encounter significant limitations. Specifically, these methods fail to utilize
auxiliary information crucial for identifying latent anomalies associated with
spatiotemporal factors during the preprocessing stage. Instead, they rely
solely on data distribution for anomaly detection, which can result in the
incorrect processing of numerous samples that could otherwise contribute
positively to model training. To address this, we propose STTS-EAD, an
end-to-end method that seamlessly integrates anomaly detection into the
training process of multivariate time series forecasting and aims to improve
Spatio-Temporal learning based Time Series prediction via Embedded Anomaly
Detection. Our proposed STTS-EAD leverages spatio-temporal information for
forecasting and anomaly detection, with the two parts alternately executed and
optimized for each other. To the best of our knowledge, STTS-EAD is the first
to integrate anomaly detection and forecasting tasks in the training phase for
improving the accuracy of multivariate time series forecasting. Extensive
experiments on a public stock dataset and two real-world sales datasets from a
renowned coffee chain enterprise show that our proposed method can effectively
process detected anomalies in the training stage to improve forecasting
performance in the inference stage and significantly outperform baselines.

摘要：處理異常值是多元時間序列預測中一個重要的前處理步驟。然而，現有將異常值前處理與多元時間序列預測模型訓練分開的方法會遇到顯著的限制。具體來說，這些方法無法利用在預處理階段識別與時空因素相關的潛在異常值至關重要的輔助信息。相反，它們僅依賴於異常值檢測的數據分佈，這可能導致對許多本可以對模型訓練做出積極貢獻的樣本進行不正確的處理。為了解決這個問題，我們提出了 STTS-EAD，這是一種將異常值檢測無縫集成到多元時間序列預測訓練過程中的端到端方法，旨在通過嵌入異常值檢測來改進基於時空學習的時間序列預測。我們提出的 STTS-EAD 利用時空信息進行預測和異常值檢測，這兩個部分交替執行並相互優化。據我們所知，STTS-EAD 是第一個在訓練階段集成異常值檢測和預測任務以提高多元時間序列預測精度的模型。在一個公開股票數據集和來自一家著名咖啡連鎖企業的兩個真實世界銷售數據集上進行的廣泛實驗表明，我們提出的方法可以在訓練階段有效處理檢測到的異常值，以提高推理階段的預測性能，並顯著優於基線。

##### **Talk to Right Specialists: Routing and Planning in Multi-agent System for Question Answering**
2501.07813v1 by Feijie Wu, Zitao Li, Fei Wei, Yaliang Li, Bolin Ding, Jing Gao

Leveraging large language models (LLMs), an agent can utilize
retrieval-augmented generation (RAG) techniques to integrate external knowledge
and increase the reliability of its responses. Current RAG-based agents
integrate single, domain-specific knowledge sources, limiting their ability and
leading to hallucinated or inaccurate responses when addressing cross-domain
queries. Integrating multiple knowledge bases into a unified RAG-based agent
raises significant challenges, including increased retrieval overhead and data
sovereignty when sensitive data is involved. In this work, we propose RopMura,
a novel multi-agent system that addresses these limitations by incorporating
highly efficient routing and planning mechanisms. RopMura features two key
components: a router that intelligently selects the most relevant agents based
on knowledge boundaries and a planner that decomposes complex multi-hop queries
into manageable steps, allowing for coordinating cross-domain responses.
Experimental results demonstrate that RopMura effectively handles both
single-hop and multi-hop queries, with the routing mechanism enabling precise
answers for single-hop queries and the combined routing and planning mechanisms
achieving accurate, multi-step resolutions for complex queries.

摘要：利用大型语言模型 (LLM)，代理可以利用检索增强生成 (RAG) 技术整合外部知识并提高其响应的可靠性。当前基于 RAG 的代理整合了单一且特定于领域的知识源，这限制了它们的能力，并且在处理跨领域查询时会导致出现幻觉或不准确的响应。将多个知识库整合到基于 RAG 的统一代理中会带来重大挑战，包括在涉及敏感数据时增加检索开销和数据主权。在这项工作中，我们提出了 RopMura，这是一种新颖的多代理系统，它通过结合高效的路由和规划机制来解决这些限制。RopMura 具有两个关键组件：一个基于知识边界智能选择最相关代理的路由器，以及一个将复杂的多跳查询分解为可管理步骤的规划器，从而允许协调跨域响应。实验结果表明，RopMura 有效地处理了单跳和多跳查询，其中路由机制能够为单跳查询提供精确的答案，而路由和规划机制相结合则为复杂查询实现了准确的多步骤解析。

##### **Conformal mapping Coordinates Physics-Informed Neural Networks (CoCo-PINNs): learning neural networks for designing neutral inclusions**
2501.07809v1 by Daehee Cho, Hyeonmin Yun, Jaeyong Lee, Mikyoung Lim

We focus on designing and solving the neutral inclusion problem via neural
networks. The neutral inclusion problem has a long history in the theory of
composite materials, and it is exceedingly challenging to identify the precise
condition that precipitates a general-shaped inclusion into a neutral
inclusion. Physics-informed neural networks (PINNs) have recently become a
highly successful approach to addressing both forward and inverse problems
associated with partial differential equations. We found that traditional PINNs
perform inadequately when applied to the inverse problem of designing neutral
inclusions with arbitrary shapes. In this study, we introduce a novel approach,
Conformal mapping Coordinates Physics-Informed Neural Networks (CoCo-PINNs),
which integrates complex analysis techniques into PINNs. This method exhibits
strong performance in solving forward-inverse problems to construct neutral
inclusions of arbitrary shapes in two dimensions, where the imperfect interface
condition on the inclusion's boundary is modeled by training neural networks.
Notably, we mathematically prove that training with a single linear field is
sufficient to achieve neutrality for untrained linear fields in arbitrary
directions, given a minor assumption. We demonstrate that CoCo-PINNs offer
enhanced performances in terms of credibility, consistency, and stability.

摘要：<paragraph>我們專注於透過神經網路設計並解決中性包涵問題。中性包涵問題在複合材料理論中具有悠久的歷史，而要找出能使一般形狀包涵轉變為中性包涵的精確條件是一項極具挑戰性的任務。受物理啟發的神經網路 (PINN) 近來已成為解決與偏微分方程式相關的正向和反向問題時非常成功的方法。我們發現，傳統 PINN 在應用於設計任意形狀中性包涵的反向問題時表現不佳。在本研究中，我們引入了一種新方法，共形映射座標受物理啟發的神經網路 (CoCo-PINN)，它將複分析技術整合到 PINN 中。此方法在解決正向反向問題以建構二維任意形狀的中性包涵時展現出強大的效能，其中包涵邊界的非完美介面條件是透過訓練神經網路來建模的。值得注意的是，我們在數學上證明，在一個微小的假設下，使用單一線性場進行訓練就足以在任意方向實現未受過訓練的線性場的中性。我們證明了 CoCo-PINN 在可信度、一致性和穩定性方面提供了增強的效能。</paragraph>

##### **A Low-cost and Ultra-lightweight Binary Neural Network for Traffic Signal Recognition**
2501.07808v1 by Mingke Xiao, Yue Su, Liang Yu, Guanglong Qu, Yutong Jia, Yukuan Chang, Xu Zhang

The deployment of neural networks in vehicle platforms and wearable
Artificial Intelligence-of-Things (AIOT) scenarios has become a research area
that has attracted much attention. With the continuous evolution of deep
learning technology, many image classification models are committed to
improving recognition accuracy, but this is often accompanied by problems such
as large model resource usage, complex structure, and high power consumption,
which makes it challenging to deploy on resource-constrained platforms. Herein,
we propose an ultra-lightweight binary neural network (BNN) model designed for
hardware deployment, and conduct image classification research based on the
German Traffic Sign Recognition Benchmark (GTSRB) dataset. In addition, we also
verify it on the Chinese Traffic Sign (CTS) and Belgian Traffic Sign (BTS)
datasets. The proposed model shows excellent recognition performance with an
accuracy of up to 97.64%, making it one of the best performing BNN models in
the GTSRB dataset. Compared with the full-precision model, the accuracy loss is
controlled within 1%, and the parameter storage overhead of the model is only
10% of that of the full-precision model. More importantly, our network model
only relies on logical operations and low-bit width fixed-point addition and
subtraction operations during the inference phase, which greatly simplifies the
design complexity of the processing element (PE). Our research shows the great
potential of BNN in the hardware deployment of computer vision models,
especially in the field of computer vision tasks related to autonomous driving.

摘要：<paragraph>神經網路在車輛平台和可穿戴人工智慧物聯網（AIOT）場景中的部署已成為備受關注的研究領域。隨著深度學習技術的持續演進，許多影像分類模型致力於提升辨識準確度，但這也常伴隨著模型資源使用量大、結構複雜、耗能高等問題，使得在資源受限的平台上部署時面臨挑戰。本文提出一個專為硬體部署而設計的超輕量級二元神經網路（BNN）模型，並基於德國交通標誌辨識基準（GTSRB）資料集進行影像分類研究。此外，我們也驗證於中國交通標誌（CTS）和比利時交通標誌（BTS）資料集。所提出的模型展現優異的辨識效能，在 GTSRB 資料集上最高可達 97.64% 的準確度，使其成為效能最佳的 BNN 模型之一。與全精度模型相比，準確度損失控制在 1% 以內，且模型的參數儲存開銷僅為全精度模型的 10%。更重要的是，我們的網路模型在推理階段僅依賴邏輯運算和低位元寬度定點加法和減法運算，大幅簡化處理元件（PE）的設計複雜度。我們的研究顯示 BNN 在電腦視覺模型的硬體部署上具有極大的潛力，特別是在與自動駕駛相關的電腦視覺任務領域。</paragraph>

##### **Visual Language Models as Operator Agents in the Space Domain**
2501.07802v1 by Alejandro Carrasco, Marco Nedungadi, Enrico M. Zucchelli, Amit Jain, Victor Rodriguez-Fernandez, Richard Linares

This paper explores the application of Vision-Language Models (VLMs) as
operator agents in the space domain, focusing on both software and hardware
operational paradigms. Building on advances in Large Language Models (LLMs) and
their multimodal extensions, we investigate how VLMs can enhance autonomous
control and decision-making in space missions. In the software context, we
employ VLMs within the Kerbal Space Program Differential Games (KSPDG)
simulation environment, enabling the agent to interpret visual screenshots of
the graphical user interface to perform complex orbital maneuvers. In the
hardware context, we integrate VLMs with robotic systems equipped with cameras
to inspect and diagnose physical space objects, such as satellites. Our results
demonstrate that VLMs can effectively process visual and textual data to
generate contextually appropriate actions, competing with traditional methods
and non-multimodal LLMs in simulation tasks, and showing promise in real-world
applications.

摘要：本文探討了視覺語言模型 (VLM) 在太空領域作為操作員代理的應用，重點關注軟體和硬體操作範例。在大型語言模型 (LLM) 和其多模態擴充的進展基礎上，我們探討了 VLM 如何增強太空任務中的自主控制和決策制定。在軟體情境中，我們在 Kerbal 太空計畫微分遊戲 (KSPDG) 模擬環境中採用 VLM，使代理能夠解譯圖形使用者介面的視覺截圖，以執行複雜的軌道機動。在硬體情境中，我們將 VLM 與配備相機的機器人系統整合，以檢查和診斷物理太空物體，例如衛星。我們的結果證明，VLM 能有效處理視覺和文字資料，以產生符合情境的適當動作，在模擬任務中與傳統方法和非多模態 LLM 競爭，並在真實世界應用中展現前景。

##### **A Comparative Analysis of DNN-based White-Box Explainable AI Methods in Network Security**
2501.07801v1 by Osvaldo Arreche, Mustafa Abdallah

New research focuses on creating artificial intelligence (AI) solutions for
network intrusion detection systems (NIDS), drawing its inspiration from the
ever-growing number of intrusions on networked systems, increasing its
complexity and intelligibility. Hence, the use of explainable AI (XAI)
techniques in real-world intrusion detection systems comes from the requirement
to comprehend and elucidate black-box AI models to security analysts. In an
effort to meet such requirements, this paper focuses on applying and evaluating
White-Box XAI techniques (particularly LRP, IG, and DeepLift) for NIDS via an
end-to-end framework for neural network models, using three widely used network
intrusion datasets (NSL-KDD, CICIDS-2017, and RoEduNet-SIMARGL2021), assessing
its global and local scopes, and examining six distinct assessment measures
(descriptive accuracy, sparsity, stability, robustness, efficiency, and
completeness). We also compare the performance of white-box XAI methods with
black-box XAI methods. The results show that using White-box XAI techniques
scores high in robustness and completeness, which are crucial metrics for IDS.
Moreover, the source codes for the programs developed for our XAI evaluation
framework are available to be improved and used by the research community.

摘要：新研究著重於為網路入侵偵測系統 (NIDS) 創造人工智慧 (AI) 解決方案，從網路系統上不斷增加的入侵中汲取靈感，提升其複雜性和可理解性。因此，在真實世界的入侵偵測系統中使用可解釋 AI (XAI) 技術，來自於安全分析師理解並闡明黑箱 AI 模型的要求。為了滿足此類要求，本文專注於透過神經網路模型的端對端架構，針對 NIDS 應用和評估白盒 XAI 技術（尤其是 LRP、IG 和 DeepLift），使用三個廣泛使用的網路入侵資料集 (NSL-KDD、CICIDS-2017 和 RoEduNet-SIMARGL2021)，評估其全球和區域範圍，並檢視六項不同的評估措施（描述準確度、稀疏性、穩定性、穩健性、效率和完整性）。我們也比較白盒 XAI 方法與黑盒 XAI 方法的效能。結果顯示使用白盒 XAI 技術在穩健性和完整性方面得分很高，而這兩個指標對於 IDS 至關重要。此外，為我們的 XAI 評估架構所開發程式的原始碼可供研究社群改進和使用。

##### **BioPose: Biomechanically-accurate 3D Pose Estimation from Monocular Videos**
2501.07800v1 by Farnoosh Koleini, Muhammad Usama Saleem, Pu Wang, Hongfei Xue, Ahmed Helmy, Abbey Fenwick

Recent advancements in 3D human pose estimation from single-camera images and
videos have relied on parametric models, like SMPL. However, these models
oversimplify anatomical structures, limiting their accuracy in capturing true
joint locations and movements, which reduces their applicability in
biomechanics, healthcare, and robotics. Biomechanically accurate pose
estimation, on the other hand, typically requires costly marker-based motion
capture systems and optimization techniques in specialized labs. To bridge this
gap, we propose BioPose, a novel learning-based framework for predicting
biomechanically accurate 3D human pose directly from monocular videos. BioPose
includes three key components: a Multi-Query Human Mesh Recovery model
(MQ-HMR), a Neural Inverse Kinematics (NeurIK) model, and a 2D-informed pose
refinement technique. MQ-HMR leverages a multi-query deformable transformer to
extract multi-scale fine-grained image features, enabling precise human mesh
recovery. NeurIK treats the mesh vertices as virtual markers, applying a
spatial-temporal network to regress biomechanically accurate 3D poses under
anatomical constraints. To further improve 3D pose estimations, a 2D-informed
refinement step optimizes the query tokens during inference by aligning the 3D
structure with 2D pose observations. Experiments on benchmark datasets
demonstrate that BioPose significantly outperforms state-of-the-art methods.
Project website:
\url{https://m-usamasaleem.github.io/publication/BioPose/BioPose.html}.

摘要：<paragraph>最近在單一相機影像和影片中進行 3D 人體姿勢估計的進展，仰賴於參數模型，例如 SMPL。然而，這些模型過度簡化解剖結構，限制其在捕捉真實關節位置和動作時的準確性，這降低了它們在生物力學、醫療保健和機器人技術中的適用性。另一方面，在生物力學上準確的姿勢估計通常需要昂貴的基於標記的動作捕捉系統和在專門實驗室中進行最佳化技術。為了彌補這個差距，我們提出了 BioPose，一個用於從單眼影片中直接預測生物力學上準確的 3D 人體姿勢的新型基於學習的框架。BioPose 包含三個關鍵組成部分：多重查詢人體網格復原模型 (MQ-HMR)、神經反向運動學 (NeurIK) 模型和 2D 資訊姿勢精緻化技術。MQ-HMR 採用多重查詢可變形轉換器來提取多尺度細粒度影像特徵，實現精確的人體網格復原。NeurIK 將網格頂點視為虛擬標記，應用時空網路在解剖約束下回歸生物力學上準確的 3D 姿勢。為了進一步改善 3D 姿勢估計，2D 資訊精緻化步驟會在推論期間最佳化查詢代碼，藉由將 3D 結構與 2D 姿勢觀察結果對齊。基準資料集上的實驗證明，BioPose 明顯優於最先進的方法。專案網站：\url{https://m-usamasaleem.github.io/publication/BioPose/BioPose.html}。</paragraph>

##### **Parameter-Inverted Image Pyramid Networks for Visual Perception and Multimodal Understanding**
2501.07783v1 by Zhaokai Wang, Xizhou Zhu, Xue Yang, Gen Luo, Hao Li, Changyao Tian, Wenhan Dou, Junqi Ge, Lewei Lu, Yu Qiao, Jifeng Dai

Image pyramids are widely adopted in top-performing methods to obtain
multi-scale features for precise visual perception and understanding. However,
current image pyramids use the same large-scale model to process multiple
resolutions of images, leading to significant computational cost. To address
this challenge, we propose a novel network architecture, called
Parameter-Inverted Image Pyramid Networks (PIIP). Specifically, PIIP uses
pretrained models (ViTs or CNNs) as branches to process multi-scale images,
where images of higher resolutions are processed by smaller network branches to
balance computational cost and performance. To integrate information from
different spatial scales, we further propose a novel cross-branch feature
interaction mechanism. To validate PIIP, we apply it to various perception
models and a representative multimodal large language model called LLaVA, and
conduct extensive experiments on various tasks such as object detection,
segmentation, image classification and multimodal understanding. PIIP achieves
superior performance compared to single-branch and existing multi-resolution
approaches with lower computational cost. When applied to InternViT-6B, a
large-scale vision foundation model, PIIP can improve its performance by 1%-2%
on detection and segmentation with only 40%-60% of the original computation,
finally achieving 60.0 box AP on MS COCO and 59.7 mIoU on ADE20K. For
multimodal understanding, our PIIP-LLaVA achieves 73.0% accuracy on TextVQA and
74.5% on MMBench with only 2.8M training data. Our code is released at
https://github.com/OpenGVLab/PIIP.

摘要：图像金字塔被广泛应用于高性能方法中，以获取多尺度特征，用于精确的视觉感知和理解。然而，当前的图像金字塔使用相同的大规模模型来处理图像的多个分辨率，导致了巨大的计算成本。为了应对这一挑战，我们提出了一种新颖的网络架构，称为参数反转图像金字塔网络 (PIIP)。具体来说，PIIP 使用预训练模型（ViT 或 CNN）作为分支来处理多尺度图像，其中较高分辨率的图像由较小的网络分支处理，以平衡计算成本和性能。为了整合来自不同空间尺度的信息，我们进一步提出了一种新颖的跨分支特征交互机制。为了验证 PIIP，我们将其应用于各种感知模型和一个名为 LLaVA 的代表性多模态大语言模型，并在对象检测、分割、图像分类和多模态理解等各种任务上进行了广泛的实验。与单分支和现有的多分辨率方法相比，PIIP 以较低的计算成本实现了卓越的性能。当应用于大规模视觉基础模型 InternViT-6B 时，PIIP 可以将其在检测和分割上的性能提高 1%-2%，而原始计算量仅为 40%-60%，最终在 MS COCO 上实现了 60.0 框 AP，在 ADE20K 上实现了 59.7 mIoU。对于多模态理解，我们的 PIIP-LLaVA 在 TextVQA 上实现了 73.0% 的准确率，在 MMBench 上实现了 74.5%，而训练数据仅为 2.8M。我们的代码已在 https://github.com/OpenGVLab/PIIP 中发布。

##### **Transforming Indoor Localization: Advanced Transformer Architecture for NLOS Dominated Wireless Environments with Distributed Sensors**
2501.07774v1 by Saad Masrur, Jung-Fu, Cheng, Atieh R. Khamesi, Ismail Guvenc

Indoor localization in challenging non-line-of-sight (NLOS) environments
often leads to mediocre accuracy with traditional approaches. Deep learning
(DL) has been applied to tackle these challenges; however, many DL approaches
overlook computational complexity, especially for floating-point operations
(FLOPs), making them unsuitable for resource-limited devices. Transformer-based
models have achieved remarkable success in natural language processing (NLP)
and computer vision (CV) tasks, motivating their use in wireless applications.
However, their use in indoor localization remains nascent, and directly
applying Transformers for indoor localization can be both computationally
intensive and exhibit limitations in accuracy. To address these challenges, in
this work, we introduce a novel tokenization approach, referred to as Sensor
Snapshot Tokenization (SST), which preserves variable-specific representations
of power delay profile (PDP) and enhances attention mechanisms by effectively
capturing multi-variate correlation. Complementing this, we propose a
lightweight Swish-Gated Linear Unit-based Transformer (L-SwiGLU Transformer)
model, designed to reduce computational complexity without compromising
localization accuracy. Together, these contributions mitigate the computational
burden and dependency on large datasets, making Transformer models more
efficient and suitable for resource-constrained scenarios. The proposed
tokenization method enables the Vanilla Transformer to achieve a 90th
percentile positioning error of 0.388 m in a highly NLOS indoor factory,
surpassing conventional tokenization methods. The L-SwiGLU ViT further reduces
the error to 0.355 m, achieving an 8.51% improvement. Additionally, the
proposed model outperforms a 14.1 times larger model with a 46.13% improvement,
underscoring its computational efficiency.

摘要：在具有挑戰性的非視線（NLOS）環境中進行室內定位，通常會導致傳統方法的準確度平庸。深度學習（DL）已被應用於應對這些挑戰；然而，許多 DL 方法忽視了計算複雜度，特別是對於浮點運算（FLOP），這使得它們不適合資源受限的設備。基於 Transformer 的模型在自然語言處理（NLP）和計算機視覺（CV）任務中取得了顯著的成功，激勵了它們在無線應用中的使用。然而，它們在室內定位中的使用仍然處於萌芽階段，並且直接應用 Transformer 進行室內定位既會計算密集，又會表現出準確性方面的限制。為了應對這些挑戰，在這項工作中，我們引入了一種新穎的標記化方法，稱為傳感器快照標記化（SST），它保留了功率延遲輪廓（PDP）的特定於變量的表示，並通過有效地捕獲多變量相關性來增強注意力機制。與此相輔相成的是，我們提出了一個輕量級的 Swish-Gated 線性單元 Transformer（L-SwiGLU Transformer）模型，旨在降低計算複雜度，同時不損害定位精度。這些貢獻共同減輕了計算負擔和對大型數據集的依賴性，使 Transformer 模型更有效率，更適合資源受限的場景。所提出的標記化方法使 Vanilla Transformer 能夠在高度 NLOS 室內工廠中實現 0.388 m 的第 90 個百分位定位誤差，超過了傳統的標記化方法。L-SwiGLU ViT 進一步將誤差降低到 0.355 m，實現了 8.51% 的改進。此外，所提出的模型優於一個大 14.1 倍的模型，改進了 46.13%，突顯了它的計算效率。

##### **Large Language Models for Knowledge Graph Embedding Techniques, Methods, and Challenges: A Survey**
2501.07766v1 by Bingchen Liu, Xin Li

Large Language Models (LLMs) have attracted a lot of attention in various
fields due to their superior performance, aiming to train hundreds of millions
or more parameters on large amounts of text data to understand and generate
natural language. As the superior performance of LLMs becomes apparent, they
are increasingly being applied to knowledge graph embedding (KGE) related tasks
to improve the processing results. As a deep learning model in the field of
Natural Language Processing (NLP), it learns a large amount of textual data to
predict the next word or generate content related to a given text. However,
LLMs have recently been invoked to varying degrees in different types of KGE
related scenarios such as multi-modal KGE and open KGE according to their task
characteristics. In this paper, we investigate a wide range of approaches for
performing LLMs-related tasks in different types of KGE scenarios. To better
compare the various approaches, we summarize each KGE scenario in a
classification. In addition to the categorization methods, we provide a tabular
overview of the methods and their source code links for a more direct
comparison. In the article we also discuss the applications in which the
methods are mainly used and suggest several forward-looking directions for the
development of this new research area.

摘要：大型語言模型 (LLM) 由於其優異的性能，在各個領域中引起了許多關注，目標是訓練數億或更多參數，以理解和產生大量文本資料中的自然語言。隨著 LLM 優異性能的顯現，它們正越來越廣泛地應用於知識圖譜嵌入 (KGE) 相關任務，以改善處理結果。作為自然語言處理 (NLP) 領域中的深度學習模型，它學習大量的文本資料，以預測下一個單字或產生與給定文本相關的內容。然而，根據任務特性，LLM 最近已在不同類型的 KGE 相關場景（例如多模態 KGE 和開放式 KGE）中以不同程度被採用。在本文中，我們探討了在不同類型的 KGE 場景中執行與 LLM 相關任務的各種方法。為了更好地比較各種方法，我們在分類中總結了每個 KGE 場景。除了分類方法之外，我們還提供了方法及其原始碼連結的表格概觀，以便進行更直接的比較。在本文中，我們還討論了這些方法主要用於哪些應用，並建議了幾個這個新研究領域發展的前瞻性方向。

##### **Deep Learning for Disease Outbreak Prediction: A Robust Early Warning Signal for Transcritical Bifurcations**
2501.07764v1 by Reza Miry, Amit K. Chakraborty, Russell Greiner, Mark A. Lewis, Hao Wang, Tianyu Guan, Pouria Ramazi

Early Warning Signals (EWSs) are vital for implementing preventive measures
before a disease turns into a pandemic. While new diseases exhibit unique
behaviors, they often share fundamental characteristics from a dynamical
systems perspective. Moreover, measurements during disease outbreaks are often
corrupted by different noise sources, posing challenges for Time Series
Classification (TSC) tasks. In this study, we address the problem of having a
robust EWS for disease outbreak prediction using a best-performing deep
learning model in the domain of TSC. We employed two simulated datasets to
train the model: one representing generated dynamical systems with randomly
selected polynomial terms to model new disease behaviors, and another
simulating noise-induced disease dynamics to account for noisy measurements.
The model's performance was analyzed using both simulated data from different
disease models and real-world data, including influenza and COVID-19. Results
demonstrate that the proposed model outperforms previous models, effectively
providing EWSs of impending outbreaks across various scenarios. This study
bridges advancements in deep learning with the ability to provide robust early
warning signals in noisy environments, making it highly applicable to
real-world crises involving emerging disease outbreaks.

摘要：早期预警信号 (EWS) 对于在疾病演变成大流行之前实施预防措施至关重要。虽然新疾病表现出独特的行为，但从动态系统角度来看，它们通常具有共同的基本特征。此外，在疾病爆发期间的测量值经常受到不同噪声源的干扰，这对时间序列分类 (TSC) 任务构成了挑战。在这项研究中，我们解决了使用 TSC 领域中表现最佳的深度学习模型来预测疾病爆发以获得稳健 EWS 的问题。我们采用了两个模拟数据集来训练模型：一个表示使用随机选择的多项式项生成动态系统来模拟新疾病行为，另一个模拟噪声引起的疾病动态来解释有噪声的测量值。该模型的性能使用来自不同疾病模型的模拟数据和现实世界数据（包括流感和 COVID-19）进行分析。结果表明，所提出的模型优于以前的模型，有效地提供了各种情况下即将爆发的 EWS。本研究将深度学习的进步与在有噪声环境中提供稳健的早期预警信号的能力联系起来，使其高度适用于涉及新发疾病爆发的现实世界危机。

##### **On the Statistical Capacity of Deep Generative Models**
2501.07763v1 by Edric Tam, David B. Dunson

Deep generative models are routinely used in generating samples from complex,
high-dimensional distributions. Despite their apparent successes, their
statistical properties are not well understood. A common assumption is that
with enough training data and sufficiently large neural networks, deep
generative model samples will have arbitrarily small errors in sampling from
any continuous target distribution. We set up a unifying framework that debunks
this belief. We demonstrate that broad classes of deep generative models,
including variational autoencoders and generative adversarial networks, are not
universal generators. Under the predominant case of Gaussian latent variables,
these models can only generate concentrated samples that exhibit light tails.
Using tools from concentration of measure and convex geometry, we give
analogous results for more general log-concave and strongly log-concave latent
variable distributions. We extend our results to diffusion models via a
reduction argument. We use the Gromov--Levy inequality to give similar
guarantees when the latent variables lie on manifolds with positive Ricci
curvature. These results shed light on the limited capacity of common deep
generative models to handle heavy tails. We illustrate the empirical relevance
of our work with simulations and financial data.

摘要：深度生成模型通常用于生成来自复杂、高维分布的样本。尽管它们取得了明显的成功，但它们的统计特性尚未得到很好的理解。一个普遍的假设是，有了足够多的训练数据和足够大的神经网络，深度生成模型样本在从任何连续目标分布中进行采样时都会有任意小的误差。我们建立了一个统一的框架来揭穿这一信念。我们证明了包括变分自动编码器和生成对抗网络在内的广泛类别的深度生成模型不是通用生成器。在高斯潜在变量占主导的情况下，这些模型只能生成表现出轻尾的集中样本。利用测度集中和凸几何学的工具，我们给出了更一般的对数凹和强对数凹潜在变量分布的类似结果。我们通过约简论证将我们的结果扩展到扩散模型。我们使用 Gromov-Levy 不等式，当潜在变量位于具有正 Ricci 曲率流形上时，给出了类似的保证。这些结果揭示了常见的深度生成模型处理重尾的有限能力。我们用模拟和金融数据来说明我们工作的经验相关性。

##### **Impatient Bandits: Optimizing for the Long-Term Without Delay**
2501.07761v1 by Kelly W. Zhang, Thomas Baldwin-McDonald, Kamil Ciosek, Lucas Maystre, Daniel Russo

Increasingly, recommender systems are tasked with improving users' long-term
satisfaction. In this context, we study a content exploration task, which we
formalize as a bandit problem with delayed rewards. There is an apparent
trade-off in choosing the learning signal: waiting for the full reward to
become available might take several weeks, slowing the rate of learning,
whereas using short-term proxy rewards reflects the actual long-term goal only
imperfectly. First, we develop a predictive model of delayed rewards that
incorporates all information obtained to date. Rewards as well as shorter-term
surrogate outcomes are combined through a Bayesian filter to obtain a
probabilistic belief. Second, we devise a bandit algorithm that quickly learns
to identify content aligned with long-term success using this new predictive
model. We prove a regret bound for our algorithm that depends on the
\textit{Value of Progressive Feedback}, an information theoretic metric that
captures the quality of short-term leading indicators that are observed prior
to the long-term reward. We apply our approach to a podcast recommendation
problem, where we seek to recommend shows that users engage with repeatedly
over two months. We empirically validate that our approach significantly
outperforms methods that optimize for short-term proxies or rely solely on
delayed rewards, as demonstrated by an A/B test in a recommendation system that
serves hundreds of millions of users.

摘要：推薦系統日益肩負起提升使用者長期滿意度的任務。在此脈絡下，我們研究內容探索任務，我們將其形式化為具有延遲獎勵的多重選擇問題。在選擇學習訊號時，存在明顯的權衡：等待完整的獎勵可能需要數週時間，會減緩學習速度，而使用短期代理獎勵僅不完美地反映實際長期目標。首先，我們開發一個延遲獎勵預測模型，其中包含迄今為止獲得的所有資訊。獎勵以及較短期的替代結果透過貝氏濾波器結合，以獲得機率信念。其次，我們設計一種多重選擇演算法，使用這個新的預測模型，快速學會識別與長期成功相符的內容。我們證明了演算法的後悔邊界取決於「漸進式回饋價值」，這是一個資訊理論指標，它擷取在長期獎勵之前觀察到的短期領先指標的品質。我們將我們的做法應用於播客推薦問題，我們尋求推薦使用者在兩個月內重複參與的節目。我們透過在推薦系統中進行 A/B 測試，證明我們的做法顯著優於針對短期代理進行最佳化或僅依賴延遲獎勵的方法，而該推薦系統服務數億名使用者。

##### **Performance Optimization of Ratings-Based Reinforcement Learning**
2501.07755v1 by Evelyn Rose, Devin White, Mingkang Wu, Vernon Lawhern, Nicholas R. Waytowich, Yongcan Cao

This paper explores multiple optimization methods to improve the performance
of rating-based reinforcement learning (RbRL). RbRL, a method based on the idea
of human ratings, has been developed to infer reward functions in reward-free
environments for the subsequent policy learning via standard reinforcement
learning, which requires the availability of reward functions. Specifically,
RbRL minimizes the cross entropy loss that quantifies the differences between
human ratings and estimated ratings derived from the inferred reward. Hence, a
low loss means a high degree of consistency between human ratings and estimated
ratings. Despite its simple form, RbRL has various hyperparameters and can be
sensitive to various factors. Therefore, it is critical to provide
comprehensive experiments to understand the impact of various hyperparameters
on the performance of RbRL. This paper is a work in progress, providing users
some general guidelines on how to select hyperparameters in RbRL.

摘要：本文探討多種最佳化方法，以提升基於評分強化學習 (RbRL) 的效能。RbRL 是一種基於人類評分概念的方法，用於推論無獎勵環境中的獎勵函數，以便透過標準強化學習進行後續的政策學習，而後者需要獎勵函數。具體而言，RbRL 最小化交叉熵損失，而交叉熵損失量化了人類評分與從推論獎勵中衍生的預估評分之間的差異。因此，損失低表示人類評分與預估評分之間的一致性高。儘管形式簡單，但 RbRL 具有各種超參數，且可能對各種因素敏感。因此，提供全面的實驗以了解各種超參數對 RbRL 效能的影響至關重要。本文是一項正在進行中的工作，為使用者提供一些有關如何在 RbRL 中選擇超參數的一般準則。

##### **Rethinking AI Cultural Evaluation**
2501.07751v1 by Michal Bravansky, Filip Trhlik, Fazl Barez

As AI systems become more integrated into society, evaluating their capacity
to align with diverse cultural values is crucial for their responsible
deployment. Current evaluation methods predominantly rely on multiple-choice
question (MCQ) datasets. In this study, we demonstrate that MCQs are
insufficient for capturing the complexity of cultural values expressed in
open-ended scenarios. Our findings highlight significant discrepancies between
MCQ-based assessments and the values conveyed in unconstrained interactions.
Based on these findings, we recommend moving beyond MCQs to adopt more
open-ended, context-specific assessments that better reflect how AI models
engage with cultural values in realistic settings.

摘要：隨著 AI 系統越來越融入社會，評估其與多元文化價值觀一致的能力對於其負責任的部署至關重要。目前的評估方法主要依賴於多選題 (MCQ) 資料集。在本研究中，我們證明 MCQ 不足以捕捉在開放式情境中表達的文化價值觀的複雜性。我們的研究結果突出了基於 MCQ 的評估與在無約束互動中傳達的價值觀之間的顯著差異。根據這些發現，我們建議超越 MCQ，採用更多開放式、特定於情境的評估，以更好地反映 AI 模型如何在現實環境中與文化價值觀互動。

##### **Advancing Student Writing Through Automated Syntax Feedback**
2501.07740v1 by Kamyar Zeinalipour, Mehak Mehak, Fatemeh Parsamotamed, Marco Maggini, Marco Gori

This study underscores the pivotal role of syntax feedback in augmenting the
syntactic proficiency of students. Recognizing the challenges faced by learners
in mastering syntactic nuances, we introduce a specialized dataset named
Essay-Syntax-Instruct designed to enhance the understanding and application of
English syntax among these students. Leveraging the capabilities of Large
Language Models (LLMs) such as GPT3.5-Turbo, Llama-2-7b-chat-hf,
Llama-2-13b-chat-hf, and Mistral-7B-Instruct-v0.2, this work embarks on a
comprehensive fine-tuning process tailored to the syntax improvement task.
Through meticulous evaluation, we demonstrate that the fine-tuned LLMs exhibit
a marked improvement in addressing syntax-related challenges, thereby serving
as a potent tool for students to identify and rectify their syntactic errors.
The findings not only highlight the effectiveness of the proposed dataset in
elevating the performance of LLMs for syntax enhancement but also illuminate a
promising path for utilizing advanced language models to support language
acquisition efforts. This research contributes to the broader field of language
learning technology by showcasing the potential of LLMs in facilitating the
linguistic development of Students.

摘要：本研究強調語法回饋在提升學生語法能力的關鍵作用。我們認識到學習者在掌握語法細微差別時面臨的挑戰，因此我們引入了名為 Essay-Syntax-Instruct 的專門數據集，旨在增強這些學生對英語語法的理解和應用。利用大型語言模型 (LLM) 的能力，例如 GPT3.5-Turbo、Llama-2-7b-chat-hf、Llama-2-13b-chat-hf 和 Mistral-7B-Instruct-v0.2，這項工作著手進行針對語法改進任務量身定制的全面微調過程。透過細緻的評估，我們證明微調後的 LLM 在解決與語法相關的挑戰方面表現出顯著的進步，從而作為學生識別和糾正其語法錯誤的有力工具。這些發現不僅突顯了所提出的數據集在提升 LLM 語法增強效能方面的有效性，也為利用先進的語言模型來支持語言習得工作照亮了一條有希望的道路。本研究透過展示 LLM 在促進學生語言發展方面的潛力，為語言學習技術的廣泛領域做出了貢獻。

