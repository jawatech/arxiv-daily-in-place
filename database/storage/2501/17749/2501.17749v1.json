{"2501.17749": {"publish_time": "2025-01-29", "title": "Early External Safety Testing of OpenAI's o3-mini: Insights from the Pre-Deployment Evaluation", "paper_summary": "Large Language Models (LLMs) have become an integral part of our daily lives.\nHowever, they impose certain risks, including those that can harm individuals'\nprivacy, perpetuate biases and spread misinformation. These risks highlight the\nneed for robust safety mechanisms, ethical guidelines, and thorough testing to\nensure their responsible deployment. Safety of LLMs is a key property that\nneeds to be thoroughly tested prior the model to be deployed and accessible to\nthe general users. This paper reports the external safety testing experience\nconducted by researchers from Mondragon University and University of Seville on\nOpenAI's new o3-mini LLM as part of OpenAI's early access for safety testing\nprogram. In particular, we apply our tool, ASTRAL, to automatically and\nsystematically generate up to date unsafe test inputs (i.e., prompts) that\nhelps us test and assess different safety categories of LLMs. We automatically\ngenerate and execute a total of 10,080 unsafe test input on a early o3-mini\nbeta version. After manually verifying the test cases classified as unsafe by\nASTRAL, we identify a total of 87 actual instances of unsafe LLM behavior. We\nhighlight key insights and findings uncovered during the pre-deployment\nexternal testing phase of OpenAI's latest LLM.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u5df2\u6210\u70ba\u6211\u5011\u65e5\u5e38\u751f\u6d3b\u4e0d\u53ef\u6216\u7f3a\u7684\u4e00\u90e8\u5206\u3002\n\u7136\u800c\uff0c\u5b83\u5011\u6703\u5e36\u4f86\u67d0\u4e9b\u98a8\u96aa\uff0c\u5305\u62ec\u53ef\u80fd\u640d\u5bb3\u500b\u4eba\u96b1\u79c1\u3001\u5ef6\u7e8c\u504f\u898b\u548c\u6563\u5e03\u932f\u8aa4\u8a0a\u606f\u7684\u98a8\u96aa\u3002\u9019\u4e9b\u98a8\u96aa\u7a81\u986f\u51fa\u9700\u8981\u7a69\u5065\u7684\u5b89\u5168\u6a5f\u5236\u3001\u9053\u5fb7\u6e96\u5247\u548c\u5fb9\u5e95\u7684\u6e2c\u8a66\uff0c\u4ee5\u78ba\u4fdd\u5176\u8ca0\u8cac\u4efb\u7684\u90e8\u7f72\u3002LLM \u7684\u5b89\u5168\u6027\u662f\u4e00\u500b\u95dc\u9375\u7279\u6027\uff0c\u9700\u8981\u5728\u6a21\u578b\u90e8\u7f72\u4e26\u4f9b\u4e00\u822c\u4f7f\u7528\u8005\u5b58\u53d6\u4e4b\u524d\u9032\u884c\u5fb9\u5e95\u7684\u6e2c\u8a66\u3002\u672c\u6587\u5831\u544a\u4e86 Mondragon \u5927\u5b78\u548c\u585e\u7dad\u4e9e\u5927\u5b78\u7684\u7814\u7a76\u4eba\u54e1\u5728 OpenAI \u7684\u65e9\u671f\u5b58\u53d6\u5b89\u5168\u6e2c\u8a66\u8a08\u756b\u4e2d\uff0c\u91dd\u5c0d OpenAI \u7684\u65b0 o3-mini LLM \u9032\u884c\u7684\u5916\u90e8\u5b89\u5168\u6e2c\u8a66\u7d93\u9a57\u3002\u7279\u5225\u662f\uff0c\u6211\u5011\u904b\u7528\u6211\u5011\u7684\u5de5\u5177 ASTRAL \u81ea\u52d5\u4e14\u7cfb\u7d71\u6027\u5730\u7522\u751f\u6700\u65b0\u7684\u4e0d\u5b89\u5168\u6e2c\u8a66\u8f38\u5165\uff08\u5373\u63d0\u793a\uff09\uff0c\u9019\u6709\u52a9\u65bc\u6211\u5011\u6e2c\u8a66\u548c\u8a55\u4f30 LLM \u7684\u4e0d\u540c\u5b89\u5168\u985e\u5225\u3002\u6211\u5011\u81ea\u52d5\u7522\u751f\u4e26\u57f7\u884c\u7e3d\u5171 10,080 \u500b\u4e0d\u5b89\u5168\u6e2c\u8a66\u8f38\u5165\uff0c\u91dd\u5c0d\u65e9\u671f o3-mini \u6e2c\u8a66\u7248\u3002\u5728\u624b\u52d5\u9a57\u8b49 ASTRAL \u5206\u985e\u70ba\u4e0d\u5b89\u5168\u7684\u6e2c\u8a66\u6848\u4f8b\u5f8c\uff0c\u6211\u5011\u7e3d\u5171\u627e\u51fa 87 \u500b LLM \u4e0d\u5b89\u5168\u884c\u70ba\u7684\u5be6\u969b\u7bc4\u4f8b\u3002\u6211\u5011\u91cd\u9ede\u8aaa\u660e\u5728 OpenAI \u6700\u65b0 LLM \u7684\u90e8\u7f72\u524d\u5916\u90e8\u6e2c\u8a66\u968e\u6bb5\u4e2d\u767c\u73fe\u7684\u4e3b\u8981\u898b\u89e3\u548c\u767c\u73fe\u3002", "author": "Aitor Arrieta et.al.", "authors": "Aitor Arrieta, Miriam Ugarte, Pablo Valle, Jos\u00e9 Antonio Parejo, Sergio Segura", "id": "2501.17749v1", "paper_url": "http://arxiv.org/abs/2501.17749v1", "repo": "null"}}