{"2502.08092": {"publish_time": "2025-02-12", "title": "GCoT: Chain-of-Thought Prompt Learning for Graphs", "paper_summary": "Chain-of-thought (CoT) prompting has achieved remarkable success in natural\nlanguage processing (NLP). However, its vast potential remains largely\nunexplored for graphs. This raises an interesting question: How can we design\nCoT prompting for graphs to guide graph models to learn step by step? On one\nhand, unlike natural languages, graphs are non-linear and characterized by\ncomplex topological structures. On the other hand, many graphs lack textual\ndata, making it difficult to formulate language-based CoT prompting. In this\nwork, we propose the first CoT prompt learning framework for text-free graphs,\nGCoT. Specifically, we decompose the adaptation process for each downstream\ntask into a series of inference steps, with each step consisting of\nprompt-based inference, ``thought'' generation, and thought-conditioned prompt\nlearning. While the steps mimic CoT prompting in NLP, the exact mechanism\ndiffers significantly. Specifically, at each step, an input graph, along with a\nprompt, is first fed into a pre-trained graph encoder for prompt-based\ninference. We then aggregate the hidden layers of the encoder to construct a\n``thought'', which captures the working state of each node in the current step.\nConditioned on this thought, we learn a prompt specific to each node based on\nthe current state. These prompts are fed into the next inference step,\nrepeating the cycle. To evaluate and analyze the effectiveness of GCoT, we\nconduct comprehensive experiments on eight public datasets, which demonstrate\nthe advantage of our approach.", "paper_summary_zh": "<paragraph>\u93c8\u5f0f\u601d\u8003 (CoT) \u63d0\u793a\u5728\u81ea\u7136\u8a9e\u8a00\u8655\u7406 (NLP) \u4e2d\u53d6\u5f97\u4e86\u986f\u8457\u7684\u6210\u529f\u3002\u7136\u800c\uff0c\u5176\u9f90\u5927\u7684\u6f5b\u529b\u5728\u5716\u5f62\u65b9\u9762\u4ecd\u672a\u5f97\u5230\u5145\u5206\u63a2\u7d22\u3002\u9019\u63d0\u51fa\u4e86\u4e00\u500b\u6709\u8da3\u7684\u554f\u984c\uff1a\u6211\u5011\u5982\u4f55\u8a2d\u8a08\u5716\u5f62\u7684 CoT \u63d0\u793a\u4f86\u6307\u5c0e\u5716\u5f62\u6a21\u578b\u9010\u6b65\u5b78\u7fd2\uff1f\u4e00\u65b9\u9762\uff0c\u8207\u81ea\u7136\u8a9e\u8a00\u4e0d\u540c\uff0c\u5716\u5f62\u662f\u975e\u7dda\u6027\u7684\uff0c\u4e26\u4e14\u5177\u6709\u8907\u96dc\u7684\u62d3\u64b2\u7d50\u69cb\u3002\u53e6\u4e00\u65b9\u9762\uff0c\u8a31\u591a\u5716\u5f62\u7f3a\u4e4f\u6587\u672c\u6578\u64da\uff0c\u9019\u4f7f\u5f97\u96e3\u4ee5\u5236\u5b9a\u57fa\u65bc\u8a9e\u8a00\u7684 CoT \u63d0\u793a\u3002\u5728\u9019\u9805\u5de5\u4f5c\u4e2d\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u7b2c\u4e00\u500b\u9069\u7528\u65bc\u7121\u6587\u672c\u5716\u5f62\u7684 CoT \u63d0\u793a\u5b78\u7fd2\u6846\u67b6 GCoT\u3002\u5177\u9ad4\u4f86\u8aaa\uff0c\u6211\u5011\u5c07\u6bcf\u500b\u4e0b\u6e38\u4efb\u52d9\u7684\u9069\u61c9\u904e\u7a0b\u5206\u89e3\u70ba\u4e00\u7cfb\u5217\u63a8\u7406\u6b65\u9a5f\uff0c\u6bcf\u500b\u6b65\u9a5f\u90fd\u5305\u542b\u57fa\u65bc\u63d0\u793a\u7684\u63a8\u7406\u3001\u300c\u601d\u60f3\u300d\u751f\u6210\u4ee5\u53ca\u57fa\u65bc\u601d\u60f3\u7684\u63d0\u793a\u5b78\u7fd2\u3002\u96d6\u7136\u9019\u4e9b\u6b65\u9a5f\u6a21\u64ec\u4e86 NLP \u4e2d\u7684 CoT \u63d0\u793a\uff0c\u4f46\u5177\u9ad4\u6a5f\u5236\u537b\u6709\u5f88\u5927\u4e0d\u540c\u3002\u5177\u9ad4\u4f86\u8aaa\uff0c\u5728\u6bcf\u4e00\u6b65\u4e2d\uff0c\u4e00\u500b\u8f38\u5165\u5716\u5f62\u9023\u540c\u4e00\u500b\u63d0\u793a\u9996\u5148\u88ab\u8f38\u5165\u5230\u4e00\u500b\u9810\u8a13\u7df4\u7684\u5716\u5f62\u7de8\u78bc\u5668\u4e2d\u9032\u884c\u57fa\u65bc\u63d0\u793a\u7684\u63a8\u7406\u3002\u7136\u5f8c\uff0c\u6211\u5011\u805a\u5408\u7de8\u78bc\u5668\u7684\u96b1\u85cf\u5c64\u4ee5\u69cb\u5efa\u4e00\u500b\u300c\u601d\u60f3\u300d\uff0c\u5b83\u6355\u7372\u4e86\u7576\u524d\u6b65\u9a5f\u4e2d\u6bcf\u500b\u7bc0\u9ede\u7684\u5de5\u4f5c\u72c0\u614b\u3002\u57fa\u65bc\u9019\u500b\u601d\u60f3\uff0c\u6211\u5011\u6839\u64da\u7576\u524d\u72c0\u614b\u5b78\u7fd2\u4e00\u500b\u7279\u5b9a\u65bc\u6bcf\u500b\u7bc0\u9ede\u7684\u63d0\u793a\u3002\u9019\u4e9b\u63d0\u793a\u88ab\u8f38\u5165\u5230\u4e0b\u4e00\u500b\u63a8\u7406\u6b65\u9a5f\u4e2d\uff0c\u91cd\u8907\u9019\u500b\u5faa\u74b0\u3002\u70ba\u4e86\u8a55\u4f30\u548c\u5206\u6790 GCoT \u7684\u6709\u6548\u6027\uff0c\u6211\u5011\u5c0d\u516b\u500b\u516c\u5171\u6578\u64da\u96c6\u9032\u884c\u4e86\u5168\u9762\u7684\u5be6\u9a57\uff0c\u9019\u8b49\u660e\u4e86\u6211\u5011\u65b9\u6cd5\u7684\u512a\u52e2\u3002</paragraph>", "author": "Xingtong Yu et.al.", "authors": "Xingtong Yu, Chang Zhou, Zhongwei Kuai, Xinming Zhang, Yuan Fang", "id": "2502.08092v1", "paper_url": "http://arxiv.org/abs/2502.08092v1", "repo": "null"}}