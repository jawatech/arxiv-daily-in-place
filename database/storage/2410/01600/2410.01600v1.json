{"2410.01600": {"publish_time": "2024-10-02", "title": "ENTP: Encoder-only Next Token Prediction", "paper_summary": "Next-token prediction models have predominantly relied on decoder-only\nTransformers with causal attention, driven by the common belief that causal\nattention is essential to prevent \"cheating\" by masking future tokens. We\nchallenge this widely accepted notion and argue that this design choice is\nabout efficiency rather than necessity. While decoder-only Transformers are\nstill a good choice for practical reasons, they are not the only viable option.\nIn this work, we introduce Encoder-only Next Token Prediction (ENTP). We\nexplore the differences between ENTP and decoder-only Transformers in\nexpressive power and complexity, highlighting potential advantages of ENTP. We\nintroduce the Triplet-Counting task and show, both theoretically and\nexperimentally, that while ENTP can perform this task easily, a decoder-only\nTransformer cannot. Finally, we empirically demonstrate ENTP's superior\nperformance across various realistic tasks, such as length generalization and\nin-context learning.", "paper_summary_zh": "\u4e0b\u4e00\u500b\u4ee3\u5e63\u9810\u6e2c\u6a21\u578b\u4e3b\u8981\u4f9d\u8cf4\u65bc\u5177\u6709\u56e0\u679c\u6ce8\u610f\u529b\u7684\u50c5\u89e3\u78bc\u5668 Transformer\uff0c\u9019\u6e90\u65bc\u4e00\u500b\u666e\u904d\u7684\u89c0\u5ff5\uff0c\u5373\u56e0\u679c\u6ce8\u610f\u529b\u5c0d\u65bc\u9632\u6b62\u901a\u904e\u906e\u853d\u672a\u4f86\u4ee3\u5e63\u4f86\u300c\u4f5c\u5f0a\u300d\u81f3\u95dc\u91cd\u8981\u3002\u6211\u5011\u6311\u6230\u9019\u500b\u5ee3\u6cdb\u63a5\u53d7\u7684\u6982\u5ff5\uff0c\u4e26\u8a8d\u70ba\u9019\u7a2e\u8a2d\u8a08\u9078\u64c7\u662f\u51fa\u65bc\u6548\u7387\u800c\u4e0d\u662f\u5fc5\u8981\u6027\u3002\u5118\u7ba1\u50c5\u89e3\u78bc\u5668 Transformer \u4ecd\u7136\u662f\u51fa\u65bc\u5be6\u969b\u539f\u56e0\u7684\u826f\u597d\u9078\u64c7\uff0c\u4f46\u5b83\u5011\u4e26\u975e\u552f\u4e00\u53ef\u884c\u7684\u9078\u9805\u3002\u5728\u9019\u9805\u5de5\u4f5c\u4e2d\uff0c\u6211\u5011\u5f15\u5165\u4e86\u50c5\u7de8\u78bc\u5668\u4e0b\u4e00\u500b\u4ee3\u5e63\u9810\u6e2c (ENTP)\u3002\u6211\u5011\u63a2\u8a0e\u4e86 ENTP \u548c\u50c5\u89e3\u78bc\u5668 Transformer \u5728\u8868\u73fe\u529b\u8207\u8907\u96dc\u6027\u65b9\u9762\u7684\u5dee\u7570\uff0c\u5f37\u8abf\u4e86 ENTP \u7684\u6f5b\u5728\u512a\u52e2\u3002\u6211\u5011\u5f15\u5165\u4e86\u4e09\u5143\u7d44\u8a08\u7b97\u4efb\u52d9\uff0c\u4e26\u5728\u7406\u8ad6\u4e0a\u548c\u5be6\u9a57\u4e0a\u8b49\u660e\uff0c\u5118\u7ba1 ENTP \u53ef\u4ee5\u8f15\u9b06\u57f7\u884c\u6b64\u4efb\u52d9\uff0c\u4f46\u50c5\u89e3\u78bc\u5668 Transformer \u537b\u7121\u6cd5\u57f7\u884c\u3002\u6700\u5f8c\uff0c\u6211\u5011\u901a\u904e\u7d93\u9a57\u8b49\u660e\u4e86 ENTP \u5728\u5404\u7a2e\u73fe\u5be6\u4efb\u52d9\u4e2d\u7684\u5353\u8d8a\u8868\u73fe\uff0c\u4f8b\u5982\u9577\u5ea6\u6cdb\u5316\u548c\u60c5\u5883\u5b78\u7fd2\u3002", "author": "Ethan Ewer et.al.", "authors": "Ethan Ewer, Daewon Chae, Thomas Zeng, Jinkyu Kim, Kangwook Lee", "id": "2410.01600v1", "paper_url": "http://arxiv.org/abs/2410.01600v1", "repo": "null"}}