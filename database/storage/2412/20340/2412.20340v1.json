{"2412.20340": {"publish_time": "2024-12-29", "title": "Distilling Desired Comments for Enhanced Code Review with Large Language Models", "paper_summary": "There has been a growing interest in using Large Language Models (LLMs) for\ncode review thanks to their proven proficiency in code comprehension. The\nprimary objective of most review scenarios is to generate desired review\ncomments (DRCs) that explicitly identify issues to trigger code fixes. However,\nexisting LLM-based solutions are not so effective in generating DRCs for\nvarious reasons such as hallucination. To enhance their code review ability,\nthey need to be fine-tuned with a customized dataset that is ideally full of\nDRCs. Nevertheless, such a dataset is not yet available, while manual\nannotation of DRCs is too laborious to be practical. In this paper, we propose\na dataset distillation method, Desiview, which can automatically construct a\ndistilled dataset by identifying DRCs from a code review dataset. Experiments\non the CodeReviewer dataset comprising more than 150K review entries show that\nDesiview achieves an impressive performance of 88.93%, 80.37%, 86.67%, and\n84.44% in terms of Precision, Recall, Accuracy, and F1, respectively,\nsurpassing state-of-the-art methods. To validate the effect of such a distilled\ndataset on enhancing LLMs' code review ability, we first fine-tune the latest\nLLaMA series (i.e., LLaMA 3 and LLaMA 3.1) to build model Desiview4FT. We then\nenhance the model training effect through KTO alignment by feeding those review\ncomments identified as non-DRCs to the LLMs, resulting in model Desiview4FA.\nVerification results indicate that Desiview4FA slightly outperforms\nDesiview4FT, while both models have significantly improved against the base\nmodels in terms of generating DRCs. Human evaluation confirms that both models\nidentify issues more accurately and tend to generate review comments that\nbetter describe the issues contained in the code than the base LLMs do.", "paper_summary_zh": "<paragraph>\u7531\u65bc\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u5728\u7a0b\u5f0f\u78bc\u7406\u89e3\u65b9\u9762\u5df2\u8b49\u660e\u5176\u80fd\u529b\uff0c\u56e0\u6b64\u4f7f\u7528 LLM \u9032\u884c\u7a0b\u5f0f\u78bc\u6aa2\u95b1\u7684\u8208\u8da3\u65e5\u76ca\u589e\u52a0\u3002\u5927\u591a\u6578\u6aa2\u95b1\u60c5\u5883\u7684\u521d\u968e\u76ee\u6a19\u662f\u7522\u751f\u660e\u78ba\u6307\u51fa\u554f\u984c\u4ee5\u89f8\u767c\u7a0b\u5f0f\u78bc\u4fee\u6b63\u7684\u9810\u671f\u6aa2\u95b1\u8a55\u8ad6 (DRC)\u3002\u7136\u800c\uff0c\u73fe\u6709\u7684\u57fa\u65bc LLM \u7684\u89e3\u6c7a\u65b9\u6848\u7531\u65bc\u5e7b\u89ba\u7b49\u5404\u7a2e\u539f\u56e0\uff0c\u5728\u7522\u751f DRC \u65b9\u9762\u4e26\u975e\u5982\u6b64\u6709\u6548\u3002\u70ba\u4e86\u589e\u5f37\u5176\u7a0b\u5f0f\u78bc\u6aa2\u95b1\u80fd\u529b\uff0c\u9700\u8981\u4f7f\u7528\u7406\u60f3\u60c5\u6cc1\u4e0b\u5145\u6eff DRC \u7684\u81ea\u8a02\u8cc7\u6599\u96c6\u5c0d\u5176\u9032\u884c\u5fae\u8abf\u3002\u5118\u7ba1\u5982\u6b64\uff0c\u6b64\u985e\u8cc7\u6599\u96c6\u5c1a\u672a\u63a8\u51fa\uff0c\u800c DRC \u7684\u624b\u52d5\u8a3b\u89e3\u53c8\u592a\u904e\u8cbb\u529b\uff0c\u4e0d\u5207\u5be6\u969b\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u4e00\u7a2e\u8cc7\u6599\u96c6\u8403\u53d6\u65b9\u6cd5 Desiview\uff0c\u5b83\u53ef\u4ee5\u900f\u904e\u5f9e\u7a0b\u5f0f\u78bc\u6aa2\u95b1\u8cc7\u6599\u96c6\u4e2d\u8b58\u5225 DRC \u4f86\u81ea\u52d5\u5efa\u69cb\u8403\u53d6\u7684\u8cc7\u6599\u96c6\u3002\u5728\u5305\u542b\u8d85\u904e 15 \u842c\u500b\u6aa2\u95b1\u689d\u76ee\u7684 CodeReviewer \u8cc7\u6599\u96c6\u4e0a\u9032\u884c\u7684\u5be6\u9a57\u8868\u660e\uff0cDesiview \u5728\u6e96\u78ba\u5ea6\u3001\u53ec\u56de\u7387\u3001\u6e96\u78ba\u6027\u548c F1 \u65b9\u9762\u5206\u5225\u9054\u5230\u4e86\u4ee4\u4eba\u5370\u8c61\u6df1\u523b\u7684 88.93%\u300180.37%\u300186.67% \u548c 84.44%\uff0c\u8d85\u8d8a\u4e86\u6700\u5148\u9032\u7684\u65b9\u6cd5\u3002\u70ba\u4e86\u9a57\u8b49\u6b64\u985e\u8403\u53d6\u8cc7\u6599\u96c6\u5c0d\u589e\u5f37 LLM \u7a0b\u5f0f\u78bc\u6aa2\u95b1\u80fd\u529b\u7684\u5f71\u97ff\uff0c\u6211\u5011\u9996\u5148\u5fae\u8abf\u4e86\u6700\u65b0\u7684 LLaMA \u7cfb\u5217\uff08\u5373 LLaMA 3 \u548c LLaMA 3.1\uff09\u4f86\u5efa\u69cb\u6a21\u578b Desiview4FT\u3002\u7136\u5f8c\uff0c\u6211\u5011\u900f\u904e KTO \u5c0d\u9f4a\u4f86\u589e\u5f37\u6a21\u578b\u8a13\u7df4\u6548\u679c\uff0c\u65b9\u6cd5\u662f\u5c07\u90a3\u4e9b\u88ab\u8b58\u5225\u70ba\u975e DRC \u7684\u6aa2\u95b1\u8a55\u8ad6\u63d0\u4f9b\u7d66 LLM\uff0c\u5f9e\u800c\u7522\u751f\u6a21\u578b Desiview4FA\u3002\u9a57\u8b49\u7d50\u679c\u8868\u660e\uff0cDesiview4FA \u7565\u52dd\u65bc Desiview4FT\uff0c\u800c\u9019\u5169\u500b\u6a21\u578b\u5728\u7522\u751f DRC \u65b9\u9762\u90fd\u986f\u8457\u512a\u65bc\u57fa\u790e\u6a21\u578b\u3002\u4eba\u5de5\u8a55\u4f30\u8b49\u5be6\uff0c\u9019\u5169\u500b\u6a21\u578b\u90fd\u80fd\u66f4\u6e96\u78ba\u5730\u8b58\u5225\u554f\u984c\uff0c\u4e26\u4e14\u50be\u5411\u65bc\u7522\u751f\u6bd4\u57fa\u790e LLM \u66f4\u80fd\u63cf\u8ff0\u7a0b\u5f0f\u78bc\u4e2d\u6240\u542b\u554f\u984c\u7684\u6aa2\u95b1\u8a55\u8ad6\u3002</paragraph>", "author": "Yongda Yu et.al.", "authors": "Yongda Yu, Lei Zhang, Guoping Rong, Haifeng Shen, Jiahao Zhang, Haoxiang Yan, Guohao Shi, Dong Shao, Ruiqi Pan, Yuan Li, Qiushi Wang, Zhao Tian", "id": "2412.20340v1", "paper_url": "http://arxiv.org/abs/2412.20340v1", "repo": "null"}}