{"2406.06048": {"publish_time": "2024-06-10", "title": "Robust Latent Representation Tuning for Image-text Classification", "paper_summary": "Large models have demonstrated exceptional generalization capabilities in\ncomputer vision and natural language processing. Recent efforts have focused on\nenhancing these models with multimodal processing abilities. However,\naddressing the challenges posed by scenarios where one modality is absent\nremains a significant hurdle. In response to this issue, we propose a robust\nlatent representation tuning method for large models. Specifically, our\napproach introduces a modality latent translation module to maximize the\ncorrelation between modalities. Following this, a newly designed fusion module\nis employed to facilitate information interaction between the modalities. In\nthis framework, not only are common semantics refined during training, but the\nmethod also yields robust representations in the absence of one modality.\nImportantly, our method maintains the frozen state of the image and text\nfoundation models to preserve their abilities acquired through large-scale\npretraining. We conduct experiments on several public datasets, and the results\nunderscore the effectiveness of our proposed method.", "paper_summary_zh": "\u5927\u578b\u6a21\u578b\u5728\u96fb\u8166\u8996\u89ba\u548c\u81ea\u7136\u8a9e\u8a00\u8655\u7406\u4e2d\u5c55\u73fe\u4e86\u5353\u8d8a\u7684\u6cdb\u5316\u80fd\u529b\u3002\u6700\u8fd1\u7684\u52aa\u529b\u96c6\u4e2d\u5728\u589e\u5f37\u9019\u4e9b\u6a21\u578b\u7684\u591a\u6a21\u614b\u8655\u7406\u80fd\u529b\u4e0a\u3002\u7136\u800c\uff0c\u5728\u4e00\u500b\u6a21\u614b\u7f3a\u5931\u7684\u60c5\u6cc1\u4e0b\uff0c\u89e3\u6c7a\u6240\u5e36\u4f86\u7684\u6311\u6230\u4ecd\u7136\u662f\u4e00\u500b\u91cd\u5927\u7684\u96e3\u984c\u3002\u70ba\u4e86\u61c9\u5c0d\u9019\u500b\u554f\u984c\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u4e00\u7a2e\u91dd\u5c0d\u5927\u578b\u6a21\u578b\u7684\u7a69\u5065\u6f5b\u5728\u8868\u5fb5\u8abf\u6574\u65b9\u6cd5\u3002\u5177\u9ad4\u4f86\u8aaa\uff0c\u6211\u5011\u7684\u505a\u6cd5\u5f15\u5165\u4e86\u6a21\u614b\u6f5b\u5728\u7ffb\u8b6f\u6a21\u7d44\uff0c\u4ee5\u6700\u5927\u5316\u6a21\u614b\u4e4b\u9593\u7684\u95dc\u806f\u6027\u3002\u5728\u6b64\u4e4b\u5f8c\uff0c\u63a1\u7528\u4e00\u500b\u65b0\u8a2d\u8a08\u7684\u878d\u5408\u6a21\u7d44\uff0c\u4ee5\u4fc3\u9032\u6a21\u614b\u4e4b\u9593\u7684\u8cc7\u8a0a\u4e92\u52d5\u3002\u5728\u9019\u500b\u67b6\u69cb\u4e2d\uff0c\u4e0d\u50c5\u5728\u8a13\u7df4\u671f\u9593\u7cbe\u7149\u4e86\u5171\u7528\u8a9e\u7fa9\uff0c\u800c\u4e14\u8a72\u65b9\u6cd5\u9084\u5728\u4e00\u500b\u6a21\u614b\u7f3a\u5931\u7684\u60c5\u6cc1\u4e0b\u7522\u751f\u4e86\u7a69\u5065\u7684\u8868\u5fb5\u3002\u91cd\u8981\u7684\u662f\uff0c\u6211\u5011\u7684\u505a\u6cd5\u7dad\u6301\u4e86\u5f71\u50cf\u548c\u6587\u5b57\u57fa\u790e\u6a21\u578b\u7684\u51cd\u7d50\u72c0\u614b\uff0c\u4ee5\u4fdd\u7559\u5b83\u5011\u900f\u904e\u5927\u898f\u6a21\u9810\u8a13\u7df4\u6240\u7372\u5f97\u7684\u80fd\u529b\u3002\u6211\u5011\u5728\u5e7e\u500b\u516c\u958b\u8cc7\u6599\u96c6\u4e0a\u9032\u884c\u4e86\u5be6\u9a57\uff0c\u7d50\u679c\u7a81\u986f\u4e86\u6211\u5011\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "author": "Hao Sun et.al.", "authors": "Hao Sun, Yu Song", "id": "2406.06048v1", "paper_url": "http://arxiv.org/abs/2406.06048v1", "repo": "null"}}