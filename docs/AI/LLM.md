
### LLM
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2025-01-24**|**Mitigating GenAI-powered Evidence Pollution for Out-of-Context Multimodal Misinformation Detection**|Zehong Yan et.al.|[2501.14728v1](http://arxiv.org/abs/2501.14728v1)|null|
|**2025-01-24**|**Do LLMs Provide Consistent Answers to Health-Related Questions across Languages?**|Ipek Baris Schlicht et.al.|[2501.14719v1](http://arxiv.org/abs/2501.14719v1)|null|
|**2025-01-24**|**Towards Better Understanding Table Instruction Tuning: Decoupling the Effects from Data versus Models**|Naihao Deng et.al.|[2501.14717v1](http://arxiv.org/abs/2501.14717v1)|null|
|**2025-01-24**|**FlexiGPT: Pruning and Extending Large Language Models with Low-Rank Weight Sharing**|James Seale Smith et.al.|[2501.14713v1](http://arxiv.org/abs/2501.14713v1)|null|
|**2025-01-24**|**The Karp Dataset**|Mason DiCicco et.al.|[2501.14705v1](http://arxiv.org/abs/2501.14705v1)|null|
|**2025-01-24**|**NLP-based assessment of prescription appropriateness from Italian referrals**|Vittorio Torri et.al.|[2501.14701v1](http://arxiv.org/abs/2501.14701v1)|null|
|**2025-01-24**|**Rethinking Table Instruction Tuning**|Naihao Deng et.al.|[2501.14693v1](http://arxiv.org/abs/2501.14693v1)|null|
|**2025-01-24**|**Approach to Designing CV Systems for Medical Applications: Data, Architecture and AI**|Dmitry Ryabtsev et.al.|[2501.14689v1](http://arxiv.org/abs/2501.14689v1)|null|
|**2025-01-24**|**Decoding Generalization from Memorization in Deep Neural Networks**|Simran Ketha et.al.|[2501.14687v1](http://arxiv.org/abs/2501.14687v1)|null|
|**2025-01-24**|**Rethinking Foundation Models for Medical Image Classification through a Benchmark Study on MedMNIST**|Fuping Wu et.al.|[2501.14685v1](http://arxiv.org/abs/2501.14685v1)|null|
|**2025-01-24**|**Surface Vision Mamba: Leveraging Bidirectional State Space Model for Efficient Spherical Manifold Representation**|Rongzhao He et.al.|[2501.14679v1](http://arxiv.org/abs/2501.14679v1)|null|
|**2025-01-24**|**A Predictive Approach for Enhancing Accuracy in Remote Robotic Surgery Using Informer Model**|Muhammad Hanif Lashari et.al.|[2501.14678v1](http://arxiv.org/abs/2501.14678v1)|null|
|**2025-01-24**|**State Space Models for Extractive Summarization in Low Resource Scenarios**|Nisrine Ait Khayi et.al.|[2501.14673v1](http://arxiv.org/abs/2501.14673v1)|null|
|**2025-01-24**|**MedAgentBench: Dataset for Benchmarking LLMs as Agents in Medical Applications**|Yixing Jiang et.al.|[2501.14654v1](http://arxiv.org/abs/2501.14654v1)|[link](https://github.com/stanfordmlgroup/medagentbench)|
|**2025-01-24**|**Federated Domain Generalization with Data-free On-server Gradient Matching**|Trong-Binh Nguyen et.al.|[2501.14653v1](http://arxiv.org/abs/2501.14653v1)|null|
|**2025-01-24**|**Investigating the (De)Composition Capabilities of Large Language Models in Natural-to-Formal Language Conversion**|Ziyao Xu et.al.|[2501.14649v1](http://arxiv.org/abs/2501.14649v1)|[link](https://github.com/xzy-xzy/dedc)|
|**2025-01-24**|**Whisper D-SGD: Correlated Noise Across Agents for Differentially Private Decentralized Learning**|Angelo Rodio et.al.|[2501.14644v1](http://arxiv.org/abs/2501.14644v1)|[link](https://github.com/arodio/whisperdsgd)|
|**2025-01-24**|**Recommending Actionable Strategies: A Semantic Approach to Integrating Analytical Frameworks with Decision Heuristics**|Renato Ghisellini et.al.|[2501.14634v1](http://arxiv.org/abs/2501.14634v1)|null|
|**2025-01-24**|**Extracting Problem Structure with LLMs for Optimized SAT Local Search**|André Schilder et.al.|[2501.14630v1](http://arxiv.org/abs/2501.14630v1)|null|
|**2025-01-24**|**ACT-JEPA: Joint-Embedding Predictive Architecture Improves Policy Representation Learning**|Aleksandar Vujinovic et.al.|[2501.14622v1](http://arxiv.org/abs/2501.14622v1)|null|
|**2025-01-24**|**Funzac at CoMeDi Shared Task: Modeling Annotator Disagreement from Word-In-Context Perspectives**|Olufunke O. Sarumi et.al.|[2501.14617v1](http://arxiv.org/abs/2501.14617v1)|[link](https://github.com/funzac/comedi)|
|**2025-01-24**|**Leveraging Spatial Cues from Cochlear Implant Microphones to Efficiently Enhance Speech Separation in Real-World Listening Scenes**|Feyisayo Olalere et.al.|[2501.14610v1](http://arxiv.org/abs/2501.14610v1)|null|
|**2025-01-24**|**Age and Power Minimization via Meta-Deep Reinforcement Learning in UAV Networks**|Sankani Sarathchandra et.al.|[2501.14603v1](http://arxiv.org/abs/2501.14603v1)|null|
|**2025-01-24**|**ZETA: Leveraging Z-order Curves for Efficient Top-k Attention**|Qiuhao Zeng et.al.|[2501.14577v1](http://arxiv.org/abs/2501.14577v1)|null|
|**2025-01-24**|**Leveraging ChatGPT's Multimodal Vision Capabilities to Rank Satellite Images by Poverty Level: Advancing Tools for Social Science Research**|Hamid Sarmadi et.al.|[2501.14546v1](http://arxiv.org/abs/2501.14546v1)|null|
|**2025-01-24**|**Distributed Conformal Prediction via Message Passing**|Haifeng Wen et.al.|[2501.14544v1](http://arxiv.org/abs/2501.14544v1)|null|
|**2025-01-24**|**VERUS-LM: a Versatile Framework for Combining LLMs with Symbolic Reasoning**|Benjamin Callewaert et.al.|[2501.14540v1](http://arxiv.org/abs/2501.14540v1)|null|
|**2025-01-24**|**Idiom Detection in Sorani Kurdish Texts**|Skala Kamaran Omer et.al.|[2501.14528v1](http://arxiv.org/abs/2501.14528v1)|null|
|**2025-01-24**|**WanJuanSiLu: A High-Quality Open-Source Webtext Dataset for Low-Resource Languages**|Jia Yu et.al.|[2501.14506v1](http://arxiv.org/abs/2501.14506v1)|null|
|**2025-01-24**|**Evaluating and Improving Graph to Text Generation with Large Language Models**|Jie He et.al.|[2501.14497v1](http://arxiv.org/abs/2501.14497v1)|[link](https://github.com/probe2/kg_text)|
|**2025-01-24**|**Analyzing the Effect of Linguistic Similarity on Cross-Lingual Transfer: Tasks and Experimental Setups Matter**|Verena Blaschke et.al.|[2501.14491v1](http://arxiv.org/abs/2501.14491v1)|null|
|**2025-01-24**|**RealCritic: Towards Effectiveness-Driven Evaluation of Language Model Critiques**|Zhengyang Tang et.al.|[2501.14492v1](http://arxiv.org/abs/2501.14492v1)|[link](https://github.com/tangzhy/realcritic)|
|**2025-01-24**|**The Pseudo-Dimension of Contracts**|Paul Duetting et.al.|[2501.14474v1](http://arxiv.org/abs/2501.14474v1)|null|
|**2025-01-24**|**Pesti-Gen: Unleashing a Generative Molecule Approach for Toxicity Aware Pesticide Design**|Taehan Kim et.al.|[2501.14469v1](http://arxiv.org/abs/2501.14469v1)|null|
|**2025-01-24**|**Interpretability Analysis of Domain Adapted Dense Retrievers**|Goksenin Yuksel et.al.|[2501.14459v1](http://arxiv.org/abs/2501.14459v1)|null|
|**2025-01-24**|**Understanding and Mitigating Gender Bias in LLMs via Interpretable Neuron Editing**|Zeping Yu et.al.|[2501.14457v1](http://arxiv.org/abs/2501.14457v1)|null|
|**2025-01-24**|**Learning more with the same effort: how randomization improves the robustness of a robotic deep reinforcement learning agent**|Lucía Güitta-López et.al.|[2501.14443v1](http://arxiv.org/abs/2501.14443v1)|null|
|**2025-01-24**|**Domaino1s: Guiding LLM Reasoning for Explainable Answers in High-Stakes Domains**|Xu Chu et.al.|[2501.14431v1](http://arxiv.org/abs/2501.14431v1)|null|
|**2025-01-24**|**Adaptive Rank Allocation for Federated Parameter-Efficient Fine-Tuning of Language Models**|Fei Wu et.al.|[2501.14406v1](http://arxiv.org/abs/2501.14406v1)|null|
|**2025-01-24**|**SKIL: Semantic Keypoint Imitation Learning for Generalizable Data-efficient Manipulation**|Shengjie Wang et.al.|[2501.14400v1](http://arxiv.org/abs/2501.14400v1)|null|
|**2025-01-24**|**Handling Heterophily in Recommender Systems with Wavelet Hypergraph Diffusion**|Darnbi Sakong et.al.|[2501.14399v1](http://arxiv.org/abs/2501.14399v1)|null|
|**2025-01-24**|**ECTIL: Label-efficient Computational Tumour Infiltrating Lymphocyte (TIL) assessment in breast cancer: Multicentre validation in 2,340 patients with breast cancer**|Yoni Schirris et.al.|[2501.14379v1](http://arxiv.org/abs/2501.14379v1)|null|
|**2025-01-24**|**DRESSing Up LLM: Efficient Stylized Question-Answering via Style Subspace Editing**|Xinyu Ma et.al.|[2501.14371v1](http://arxiv.org/abs/2501.14371v1)|[link](https://github.com/arthurleom/dress-llm)|
|**2025-01-24**|**In System Alignments we Trust! Explainable Alignments via Projections**|Dominique Sommers et.al.|[2501.14360v1](http://arxiv.org/abs/2501.14360v1)|null|
|**2025-01-24**|**HorNets: Learning from Discrete and Continuous Signals with Routing Neural Networks**|Boshko koloski et.al.|[2501.14346v1](http://arxiv.org/abs/2501.14346v1)|[link](https://github.com/bkolosk1/hornets)|
|**2025-01-24**|**Chain-of-Retrieval Augmented Generation**|Liang Wang et.al.|[2501.14342v1](http://arxiv.org/abs/2501.14342v1)|null|
|**2025-01-24**|**Exploring the sustainable scaling of AI dilemma: A projective study of corporations' AI environmental impacts**|Clément Desroches et.al.|[2501.14334v1](http://arxiv.org/abs/2501.14334v1)|null|
|**2025-01-24**|**Clear Minds Think Alike: What Makes LLM Fine-tuning Robust? A Study of Token Perplexity**|Chao-Chung Wu et.al.|[2501.14315v1](http://arxiv.org/abs/2501.14315v1)|null|
|**2025-01-24**|**Permutation-based multi-objective evolutionary feature selection for high-dimensional data**|Raquel Espinosa et.al.|[2501.14310v1](http://arxiv.org/abs/2501.14310v1)|null|
|**2025-01-24**|**Learning Primitive Relations for Compositional Zero-Shot Learning**|Insu Lee et.al.|[2501.14308v1](http://arxiv.org/abs/2501.14308v1)|null|
|**2025-01-24**|**A Zero-Shot LLM Framework for Automatic Assignment Grading in Higher Education**|Calvin Yeung et.al.|[2501.14305v1](http://arxiv.org/abs/2501.14305v1)|[link](https://github.com/calvinyeungck/automated_assignment_grading)|
|**2025-01-24**|**MASTER: A Multi-Agent System with LLM Specialized MCTS**|Bingzheng Gan et.al.|[2501.14304v1](http://arxiv.org/abs/2501.14304v1)|null|
|**2025-01-24**|**Fast Think-on-Graph: Wider, Deeper and Faster Reasoning of Large Language Model on Knowledge Graph**|Xujian Liang et.al.|[2501.14300v1](http://arxiv.org/abs/2501.14300v1)|[link](https://github.com/dosonleung/fasttog)|
|**2025-01-24**|**Examining Alignment of Large Language Models through Representative Heuristics: The Case of Political Stereotypes**|Sullam Jeoung et.al.|[2501.14294v1](http://arxiv.org/abs/2501.14294v1)|null|
|**2025-01-24**|**A Comprehensive Framework for Semantic Similarity Detection Using Transformer Architectures and Enhanced Ensemble Techniques**|Lifu Gao et.al.|[2501.14288v1](http://arxiv.org/abs/2501.14288v1)|null|
|**2025-01-24**|**Global Semantic-Guided Sub-image Feature Weight Allocation in High-Resolution Large Vision-Language Models**|Yuxuan Liang et.al.|[2501.14276v1](http://arxiv.org/abs/2501.14276v1)|null|
|**2025-01-24**|**Leveraging Online Olympiad-Level Math Problems for LLMs Training and Contamination-Resistant Evaluation**|Sadegh Mahdavi et.al.|[2501.14275v1](http://arxiv.org/abs/2501.14275v1)|[link](https://github.com/dsl-lab/aops)|
|**2025-01-24**|**Hierarchical Time-Aware Mixture of Experts for Multi-Modal Sequential Recommendation**|Shengzhe Zhang et.al.|[2501.14269v1](http://arxiv.org/abs/2501.14269v1)|[link](https://github.com/SStarCCat/HM4SR)|
|**2025-01-24**|**Pre-train and Fine-tune: Recommenders as Large Models**|Zhenhao Jiang et.al.|[2501.14268v1](http://arxiv.org/abs/2501.14268v1)|null|
|**2025-01-24**|**Siren: A Learning-Based Multi-Turn Attack Framework for Simulating Real-World Human Jailbreak Behaviors**|Yi Zhao et.al.|[2501.14250v1](http://arxiv.org/abs/2501.14250v1)|[link](https://github.com/yiyiyizhao/siren)|
|**2025-01-24**|**Humanity's Last Exam**|Long Phan et.al.|[2501.14249v1](http://arxiv.org/abs/2501.14249v1)|null|
|**2025-01-24**|**Detection and Classification of Acute Lymphoblastic Leukemia Utilizing Deep Transfer Learning**|Md. Abu Ahnaf Mollick et.al.|[2501.14228v1](http://arxiv.org/abs/2501.14228v1)|null|
|**2025-01-24**|**Multi-agent KTO: Reinforcing Strategic Interactions of Large Language Model in Language Game**|Rong Ye et.al.|[2501.14225v1](http://arxiv.org/abs/2501.14225v1)|null|
|**2025-01-24**|**Top Ten Challenges Towards Agentic Neural Graph Databases**|Jiaxin Bai et.al.|[2501.14224v1](http://arxiv.org/abs/2501.14224v1)|null|
|**2025-01-24**|**TFG-Flow: Training-free Guidance in Multimodal Generative Flow**|Haowei Lin et.al.|[2501.14216v1](http://arxiv.org/abs/2501.14216v1)|null|
|**2025-01-24**|**PuzzleGPT: Emulating Human Puzzle-Solving Ability for Time and Location Prediction**|Hammad Ayyubi et.al.|[2501.14210v1](http://arxiv.org/abs/2501.14210v1)|null|
|**2025-01-24**|**Dynamic Token Reduction during Generation for Vision Language Models**|Xiaoyu Liang et.al.|[2501.14204v1](http://arxiv.org/abs/2501.14204v1)|null|
|**2025-01-24**|**Coordinating Ride-Pooling with Public Transit using Reward-Guided Conservative Q-Learning: An Offline Training and Online Fine-Tuning Reinforcement Learning Framework**|Yulong Hu et.al.|[2501.14199v1](http://arxiv.org/abs/2501.14199v1)|null|
|**2025-01-24**|**Distributed Multi-Agent Coordination Using Multi-Modal Foundation Models**|Saaduddin Mahmud et.al.|[2501.14189v1](http://arxiv.org/abs/2501.14189v1)|null|
|**2025-01-24**|**Dreamweaver: Learning Compositional World Representations from Pixels**|Junyeob Baek et.al.|[2501.14174v1](http://arxiv.org/abs/2501.14174v1)|null|
|**2025-01-24**|**UltraLightSqueezeNet: A Deep Learning Architecture for Malaria Classification with up to 54x fewer trainable parameters for resource constrained devices**|Suresh Babu Nettur et.al.|[2501.14172v1](http://arxiv.org/abs/2501.14172v1)|null|
|**2025-01-24**|**Enhancing Multimodal Entity Linking with Jaccard Distance-based Conditional Contrastive Learning and Contextual Visual Augmentation**|Cong-Duy Nguyen et.al.|[2501.14166v1](http://arxiv.org/abs/2501.14166v1)|null|
|**2025-01-24**|**LoCoML: A Framework for Real-World ML Inference Pipelines**|Kritin Maddireddy et.al.|[2501.14165v1](http://arxiv.org/abs/2501.14165v1)|null|
|**2025-01-24**|**Test-Time Code-Switching for Cross-lingual Aspect Sentiment Triplet Extraction**|Dongming Sheng et.al.|[2501.14144v1](http://arxiv.org/abs/2501.14144v1)|null|
|**2025-01-23**|**Reinforcement Learning Platform for Adversarial Black-box Attacks with Custom Distortion Filters**|Soumyendu Sarkar et.al.|[2501.14122v1](http://arxiv.org/abs/2501.14122v1)|null|
|**2025-01-23**|**On the Transfer of Knowledge in Quantum Algorithms**|Esther Villar-Rodriguez et.al.|[2501.14120v1](http://arxiv.org/abs/2501.14120v1)|null|
|**2025-01-23**|**Autonomous Structural Memory Manipulation for Large Language Models Using Hierarchical Embedding Augmentation**|Derek Yotheringhay et.al.|[2501.14119v1](http://arxiv.org/abs/2501.14119v1)|null|
|**2025-01-23**|**LeCoPCR: Legal Concept-guided Prior Case Retrieval for European Court of Human Rights cases**|T. Y. S. S. Santosh et.al.|[2501.14114v1](http://arxiv.org/abs/2501.14114v1)|null|
|**2025-01-23**|**RELexED: Retrieval-Enhanced Legal Summarization with Exemplar Diversity**|T. Y. S. S. Santosh et.al.|[2501.14113v1](http://arxiv.org/abs/2501.14113v1)|null|
|**2025-01-23**|**CoPERLex: Content Planning with Event-based Representations for Legal Case Summarization**|T. Y. S. S. Santosh et.al.|[2501.14112v1](http://arxiv.org/abs/2501.14112v1)|null|
|**2025-01-23**|**MedSlice: Fine-Tuned Large Language Models for Secure Clinical Note Sectioning**|Joshua Davis et.al.|[2501.14105v1](http://arxiv.org/abs/2501.14105v1)|[link](https://github.com/lindvalllab/medslice)|
|**2025-01-23**|**Communicating Activations Between Language Model Agents**|Vignav Ramesh et.al.|[2501.14082v1](http://arxiv.org/abs/2501.14082v1)|null|
|**2025-01-23**|**Enhancing Biomedical Relation Extraction with Directionality**|Po-Ting Lai et.al.|[2501.14079v1](http://arxiv.org/abs/2501.14079v1)|[link](https://github.com/ncbi-nlp/bioredirect)|
|**2025-01-23**|**LLMs are Vulnerable to Malicious Prompts Disguised as Scientific Language**|Yubin Ge et.al.|[2501.14073v1](http://arxiv.org/abs/2501.14073v1)|null|
|**2025-01-23**|**Revisiting CLIP: Efficient Alignment of 3D MRI and Tabular Data using Domain-Specific Foundation Models**|Jakob Krogh Petersen et.al.|[2501.14051v1](http://arxiv.org/abs/2501.14051v1)|[link](https://github.com/jakekrogh/3d-clip-for-brain-mri)|
|**2025-01-23**|**GraphRAG under Fire**|Jiacheng Liang et.al.|[2501.14050v1](http://arxiv.org/abs/2501.14050v1)|null|
|**2025-01-23**|**SIDDA: SInkhorn Dynamic Domain Adaptation for Image Classification with Equivariant Neural Networks**|Sneh Pandya et.al.|[2501.14048v1](http://arxiv.org/abs/2501.14048v1)|[link](https://github.com/deepskies/gcnn_da)|
|**2025-01-23**|**Leveraging Large Language Models to Analyze Emotional and Contextual Drivers of Teen Substance Use in Online Discussions**|Jianfeng Zhu et.al.|[2501.14037v1](http://arxiv.org/abs/2501.14037v1)|null|
|**2025-01-23**|**Human-Alignment Influences the Utility of AI-assisted Decision Making**|Nina L. Corvelo Benz et.al.|[2501.14035v1](http://arxiv.org/abs/2501.14035v1)|[link](https://github.com/networks-learning/human-alignment-study)|
|**2025-01-23**|**CRPO: Confidence-Reward Driven Preference Optimization for Machine Translation**|Guofeng Cui et.al.|[2501.13927v1](http://arxiv.org/abs/2501.13927v1)|null|
|**2025-01-23**|**Can We Generate Images with CoT? Let's Verify and Reinforce Image Generation Step by Step**|Ziyu Guo et.al.|[2501.13926v1](http://arxiv.org/abs/2501.13926v1)|[link](https://github.com/ziyuguo99/image-generation-cot)|
|**2025-01-23**|**Towards Robust Multimodal Open-set Test-time Adaptation via Adaptive Entropy-aware Optimization**|Hao Dong et.al.|[2501.13924v1](http://arxiv.org/abs/2501.13924v1)|[link](https://github.com/donghao51/aeo)|
|**2025-01-23**|**The Breeze 2 Herd of Models: Traditional Chinese LLMs Based on Llama with Vision-Aware and Function-Calling Capabilities**|Chan-Jan Hsu et.al.|[2501.13921v1](http://arxiv.org/abs/2501.13921v1)|null|
|**2025-01-23**|**IMAGINE-E: Image Generation Intelligence Evaluation of State-of-the-art Text-to-Image Models**|Jiayi Lei et.al.|[2501.13920v1](http://arxiv.org/abs/2501.13920v1)|null|
|**2025-01-23**|**Temporal Preference Optimization for Long-Form Video Understanding**|Rui Li et.al.|[2501.13919v1](http://arxiv.org/abs/2501.13919v1)|null|
|**2025-01-23**|**Improving Video Generation with Human Feedback**|Jie Liu et.al.|[2501.13918v1](http://arxiv.org/abs/2501.13918v1)|null|
|**2025-01-23**|**Analysis of Indic Language Capabilities in LLMs**|Aatman Vaidya et.al.|[2501.13912v1](http://arxiv.org/abs/2501.13912v1)|null|
|**2025-01-23**|**Transfer Learning of Surrogate Models via Domain Affine Transformation Across Synthetic and Real-World Benchmarks**|Shuaiqun Pan et.al.|[2501.14012v1](http://arxiv.org/abs/2501.14012v1)|null|
|**2025-01-23**|**QuanTaxo: A Quantum Approach to Self-Supervised Taxonomy Expansion**|Sahil Mishra et.al.|[2501.14011v1](http://arxiv.org/abs/2501.14011v1)|[link](https://github.com/sahilmishra0012/quantaxo)|
|**2025-01-23**|**PointOBB-v3: Expanding Performance Boundaries of Single Point-Supervised Oriented Object Detection**|Peiyuan Zhang et.al.|[2501.13898v1](http://arxiv.org/abs/2501.13898v1)|[link](https://github.com/zpywhu/pointobb-v3)|

#### Abstracts
##### **Mitigating GenAI-powered Evidence Pollution for Out-of-Context Multimodal Misinformation Detection**
2501.14728v1 by Zehong Yan, Peng Qi, Wynne Hsu, Mong Li Lee

While large generative artificial intelligence (GenAI) models have achieved
significant success, they also raise growing concerns about online information
security due to their potential misuse for generating deceptive content.
Out-of-context (OOC) multimodal misinformation detection, which often retrieves
Web evidence to identify the repurposing of images in false contexts, faces the
issue of reasoning over GenAI-polluted evidence to derive accurate predictions.
Existing works simulate GenAI-powered pollution at the claim level with
stylistic rewriting to conceal linguistic cues, and ignore evidence-level
pollution for such information-seeking applications. In this work, we
investigate how polluted evidence affects the performance of existing OOC
detectors, revealing a performance degradation of more than 9 percentage
points. We propose two strategies, cross-modal evidence reranking and
cross-modal claim-evidence reasoning, to address the challenges posed by
polluted evidence. Extensive experiments on two benchmark datasets show that
these strategies can effectively enhance the robustness of existing
out-of-context detectors amidst polluted evidence.

摘要：儘管大型生成式人工智能 (GenAI) 模型已取得顯著的成功，但由於它們可能被誤用來產生具有欺騙性的內容，因此也引發了人們對線上資訊安全的擔憂。
語境外 (OOC) 多模態錯誤資訊偵測通常會擷取網路證據來識別錯誤語境中影像的再利用，它面臨著必須對受到 GenAI 汙染的證據進行推理才能得出準確預測的問題。
現有作品會以風格化改寫的方式在宣稱層級模擬由 GenAI 驅動的汙染，以隱藏語言線索，並忽略此類資訊搜尋應用程式的證據層級汙染。在這項工作中，我們探討受到汙染的證據如何影響現有 OOC 偵測器的效能，揭露了超過 9 個百分點的效能下降。我們提出了兩種策略，交叉模態證據重新排序和交叉模態宣稱-證據推理，來解決受到汙染的證據所帶來的挑戰。在兩個基準資料集上進行的廣泛實驗顯示，這些策略可以在受到汙染的證據中有效提升現有語境外偵測器的穩健性。

##### **Do LLMs Provide Consistent Answers to Health-Related Questions across Languages?**
2501.14719v1 by Ipek Baris Schlicht, Zhixue Zhao, Burcu Sayin, Lucie Flek, Paolo Rosso

Equitable access to reliable health information is vital for public health,
but the quality of online health resources varies by language, raising concerns
about inconsistencies in Large Language Models (LLMs) for healthcare. In this
study, we examine the consistency of responses provided by LLMs to
health-related questions across English, German, Turkish, and Chinese. We
largely expand the HealthFC dataset by categorizing health-related questions by
disease type and broadening its multilingual scope with Turkish and Chinese
translations. We reveal significant inconsistencies in responses that could
spread healthcare misinformation. Our main contributions are 1) a multilingual
health-related inquiry dataset with meta-information on disease categories, and
2) a novel prompt-based evaluation workflow that enables sub-dimensional
comparisons between two languages through parsing. Our findings highlight key
challenges in deploying LLM-based tools in multilingual contexts and emphasize
the need for improved cross-lingual alignment to ensure accurate and equitable
healthcare information.

摘要：可靠的健康資訊的公平取得對公共衛生至關重要，
但網路健康資源的品質因語言而異，這引發了對大型語言模型 (LLM) 在醫療保健方面的不一致性的擔憂。在這項研究中，我們探討了 LLM 對英語、德語、土耳其語和中文的健康相關問題所提供回應的一致性。我們透過依疾病類型分類健康相關問題，並透過土耳其語和中文翻譯擴展其多語言範圍，大幅擴展了 HealthFC 資料集。我們揭露了回應中存在顯著的不一致性，這可能會散布醫療保健錯誤資訊。我們的貢獻主要有 1) 一個包含疾病類別元資訊的多語言健康相關查詢資料集，以及 2) 一個新穎的提示式評估工作流程，它能透過解析在兩種語言之間進行次維度比較。我們的研究結果突顯了在多語言環境中部署基於 LLM 的工具的主要挑戰，並強調需要改善跨語言對齊以確保準確且公平的醫療保健資訊。

##### **Towards Better Understanding Table Instruction Tuning: Decoupling the Effects from Data versus Models**
2501.14717v1 by Naihao Deng, Sheng Zhang, Henghui Zhu, Shuaichen Chang, Jiani Zhang, Alexander Hanbo Li, Chung-Wei Hang, Hideo Kobayashi, Yiqun Hu, Patrick Ng

Recent advances in natural language processing have leveraged instruction
tuning to enhance Large Language Models (LLMs) for table-related tasks.
However, previous works train different base models with different training
data, lacking an apples-to-apples comparison across the result table LLMs. To
address this, we fine-tune base models from the Mistral, OLMo, and Phi families
on existing public training datasets. Our replication achieves performance on
par with or surpassing existing table LLMs, establishing new state-of-the-art
performance on Hitab, a table question-answering dataset. More importantly,
through systematic out-of-domain evaluation, we decouple the contributions of
training data and the base model, providing insight into their individual
impacts. In addition, we assess the effects of table-specific instruction
tuning on general-purpose benchmarks, revealing trade-offs between
specialization and generalization.

摘要：自然語言處理的最新進展利用指令調整來增強大型語言模型 (LLM) 以執行與表格相關的任務。然而，先前的研究使用不同的訓練資料訓練不同的基礎模型，缺乏對結果表格 LLM 的蘋果對蘋果比較。為了解決這個問題，我們微調了 Mistral、OLMo 和 Phi 家族中的基礎模型，使用現有的公開訓練資料集。我們的複製在與現有表格 LLM 相當或超越的效能上取得成就，在表格問答資料集 Hitab 上建立了新的最先進效能。更重要的是，透過系統性的領域外評估，我們解耦了訓練資料和基礎模型的貢獻，提供了對其個別影響的見解。此外，我們評估了特定表格指令調整對一般用途基準的影響，揭示了專業化和概括化之間的權衡。

##### **FlexiGPT: Pruning and Extending Large Language Models with Low-Rank Weight Sharing**
2501.14713v1 by James Seale Smith, Chi-Heng Lin, Shikhar Tuli, Haris Jeelani, Shangqian Gao, Yilin Shen, Hongxia Jin, Yen-Chang Hsu

The rapid proliferation of large language models (LLMs) in natural language
processing (NLP) has created a critical need for techniques that enable
efficient deployment on memory-constrained devices without compromising
performance. We present a method to prune LLMs that selectively prunes model
blocks based on an importance score and replaces them with a low-parameter
replacement strategy. Specifically, we propose a principled metric to replace
each pruned block using a weight-sharing mechanism that leverages unpruned
counterparts from the model and block-specific low-rank adapters. Furthermore,
we facilitate the learning of these replacement blocks with output feature
normalization and an adapter initialization scheme built on low-rank SVD
reconstructions. Empirical evaluations demonstrate substantial performance
gains over existing methods, achieving state-of-the-art performance on 5/6
benchmarks for a compression rate of 30% and 6/6 benchmarks for a compression
rate of 40%. We also demonstrate that our approach can extend smaller models,
boosting performance on 6/6 benchmarks using only ~0.3% tokens of extended
training with minimal additional parameter costs.

摘要：大型語言模型（LLM）在自然語言處理（NLP）中的快速擴散，已創造出對技術的關鍵需求，這些技術可以在不影響效能的情況下，在受記憶體限制的裝置上進行有效率的部署。我們提出了一種修剪 LLM 的方法，該方法根據重要性分數選擇性地修剪模型區塊，並用低參數替換策略取代它們。具體來說，我們提出一個有原則的指標，使用權重共享機制替換每個修剪區塊，該機制利用模型中未修剪的對應部分和特定區塊的低階適配器。此外，我們使用輸出特徵正規化和建立在低階 SVD 重建上的適配器初始化方案，促進這些替換區塊的學習。經驗評估顯示，與現有方法相比，效能大幅提升，在壓縮率為 30% 的情況下，在 5/6 個基準測試中達到最先進的效能，在壓縮率為 40% 的情況下，在 6/6 個基準測試中達到最先進的效能。我們還證明，我們的做法可以擴充較小的模型，僅使用約 0.3% 的延伸訓練權標，就能在 6/6 個基準測試中提升效能，而額外的參數成本極小。

##### **The Karp Dataset**
2501.14705v1 by Mason DiCicco, Eamon Worden, Conner Olsen, Nikhil Gangaram, Daniel Reichman, Neil Heffernan

Understanding the mathematical reasoning capabilities of Large Language
Models (LLMs) is a central topic in the study of artificial intelligence. This
new domain necessitates the creation of datasets of reasoning tasks for both
training and benchmarking the performance of LLMs. To this end, we introduce
the Karp dataset: The first dataset composed of detailed proofs of
NP-completeness reductions. The reductions vary in difficulty, ranging from
simple exercises of undergraduate courses to more challenging reductions from
academic papers. We compare the performance of state-of-the-art models on this
task and demonstrate the effect of fine-tuning with the Karp dataset on
reasoning capacity.

摘要：理解大型語言模型 (LLM) 的數學推理能力是人工智慧研究中的核心主題。這個新領域需要建立推理任務的資料集，以訓練和評量 LLM 的效能。為此，我們引入了 Karp 資料集：第一個由 NP 完全性簡約的詳細證明組成的資料集。簡約難度不一，從大學部課程的簡單練習到學術論文中更具挑戰性的簡約。我們比較了最先進模型在此任務上的效能，並展示了使用 Karp 資料集進行微調對推理能力的影響。

##### **NLP-based assessment of prescription appropriateness from Italian referrals**
2501.14701v1 by Vittorio Torri, Annamaria Bottelli, Michele Ercolanoni, Olivia Leoni, Francesca Ieva

Objective: This study proposes a Natural Language Processing pipeline to
evaluate prescription appropriateness in Italian referrals, where reasons for
prescriptions are recorded only as free text, complicating automated
comparisons with guidelines. The pipeline aims to derive, for the first time, a
comprehensive summary of the reasons behind these referrals and a
quantification of their appropriateness. While demonstrated in a specific case
study, the approach is designed to generalize to other types of examinations.
  Methods: Leveraging embeddings from a transformer-based model, the proposed
approach clusters referral texts, maps clusters to labels, and aligns these
labels with existing guidelines. We present a case study on a dataset of
496,971 referrals, consisting of all referrals for venous echocolordopplers of
the lower limbs between 2019 and 2021 in the Lombardy Region. A sample of 1,000
referrals was manually annotated to validate the results.
  Results: The pipeline exhibited high performance for referrals' reasons
(Prec=92.43%, Rec=83.28%) and excellent results for referrals' appropriateness
(Prec=93.58%, Rec=91.52%) on the annotated subset. Analysis of the entire
dataset identified clusters matching guideline-defined reasons - both
appropriate and inappropriate - as well as clusters not addressed in the
guidelines. Overall, 34.32% of referrals were marked as appropriate, 34.07%
inappropriate, 14.37% likely inappropriate, and 17.24% could not be mapped to
guidelines.
  Conclusions: The proposed pipeline effectively assessed prescription
appropriateness across a large dataset, serving as a valuable tool for health
authorities. Findings have informed the Lombardy Region's efforts to strengthen
recommendations and reduce the burden of inappropriate referrals.

摘要：<paragraph>目的：本研究提出一個自然語言處理管道，以評估義大利轉介處方的適當性，因為處方原因僅以自由文字記錄，這使得與指南的自動化比較變得複雜。該管道旨在首次得出這些轉介背後原因的全面摘要，並量化其適當性。雖然在具體案例研究中得到證明，但該方法旨在推廣到其他類型的檢查。
方法：利用基於Transformer的模型中的嵌入，所提出的方法對轉介文本進行分群，將分群對應到標籤，並將這些標籤與現有指南對齊。我們對 496,971 個轉介組成的資料集進行案例研究，其中包括 2019 年至 2021 年倫巴底大區所有下肢靜脈超聲多普勒轉介。手動註釋了 1,000 個轉介樣本以驗證結果。
結果：該管道對轉介原因表現出高性能（Prec=92.43%，Rec=83.28%），並且在註釋子集中對轉介適當性表現出極好的結果（Prec=93.58%，Rec=91.52%）。對整個資料集的分析識別出與指南定義的原因相匹配的分群 - 適當和不適當 - 以及指南中未涉及的分群。總體而言，34.32% 的轉介被標記為適當，34.07% 不適當，14.37% 可能不適當，17.24% 無法對應到指南。
結論：所提出的管道有效地評估了大型資料集中的處方適當性，成為衛生主管部門的寶貴工具。研究結果為倫巴底大區加強建議和減少不適當轉介負擔的努力提供了依據。</paragraph>

##### **Rethinking Table Instruction Tuning**
2501.14693v1 by Naihao Deng, Rada Mihalcea

Recent advances in table understanding have focused on instruction-tuning
large language models (LLMs) for table-related tasks. However, existing
research has overlooked the impact of hyperparameter choices and lacks a
comprehensive evaluation of the out-of-domain table understanding ability and
the general capabilities of these table LLMs. In this paper, we evaluate these
abilities in existing table LLMs, and reveal significant declines in both
out-of-domain table understanding and general capabilities compared to their
base models. Through systematic analysis, we show that hyperparameters, such as
learning rate, can significantly influence both table-specific and general
capabilities. Contrary to the existing table instruction-tuning works, we
demonstrate that smaller learning rates and fewer training instances can
enhance table understanding while preserving general capabilities. Based on our
findings, we introduce TAMA, a TAble LLM instruction-tuned from LLaMA 3.1 8B
Instruct, which achieves performance on par with, or surpassing GPT-3.5 and
GPT-4 on table tasks, while maintaining strong out-of-domain generalization and
general capabilities. Our findings highlight the potential for reduced data
annotation costs and more efficient model development through careful
hyperparameter selection.

摘要：最近表理解的進展集中在指令調校大型語言模型 (LLM) 以執行與表格相關的任務。然而，現有的研究忽略了超參數選擇的影響，並且缺乏對領域外表格理解能力和這些表格 LLM 的一般能力的全面評估。在本文中，我們評估了現有表格 LLM 中的這些能力，並揭示了與其基礎模型相比，領域外表格理解和一般能力都有顯著下降。透過系統分析，我們表明超參數（例如學習率）可以顯著影響特定表格和一般能力。與現有表格指令調校工作相反，我們證明較小的學習率和較少的訓練實例可以在保留一般能力的同時增強表格理解。根據我們的發現，我們引入了 TAMA，這是一個從 LLaMA 3.1 8B Instruct 調校的表格 LLM，它在表格任務上實現了與 GPT-3.5 和 GPT-4 相當或超越的效能，同時保持強大的領域外概化和一般能力。我們的發現強調了透過仔細選擇超參數，降低資料標註成本和更有效率的模型開發的可能性。

##### **Approach to Designing CV Systems for Medical Applications: Data, Architecture and AI**
2501.14689v1 by Dmitry Ryabtsev, Boris Vasilyev, Sergey Shershakov

This paper introduces an innovative software system for fundus image analysis
that deliberately diverges from the conventional screening approach, opting not
to predict specific diagnoses. Instead, our methodology mimics the diagnostic
process by thoroughly analyzing both normal and pathological features of fundus
structures, leaving the ultimate decision-making authority in the hands of
healthcare professionals. Our initiative addresses the need for objective
clinical analysis and seeks to automate and enhance the clinical workflow of
fundus image examination. The system, from its overarching architecture to the
modular analysis design powered by artificial intelligence (AI) models, aligns
seamlessly with ophthalmological practices. Our unique approach utilizes a
combination of state-of-the-art deep learning methods and traditional computer
vision algorithms to provide a comprehensive and nuanced analysis of fundus
structures. We present a distinctive methodology for designing medical
applications, using our system as an illustrative example. Comprehensive
verification and validation results demonstrate the efficacy of our approach in
revolutionizing fundus image analysis, with potential applications across
various medical domains.

摘要：本論文介紹了一種創新的軟體系統，用於眼底影像分析，它刻意偏離傳統的篩檢方法，選擇不預測具體的診斷。相反地，我們的分析方法模擬診斷過程，徹底分析眼底結構的正常和病理特徵，將最終的決策權交到醫療保健專業人員手中。我們的計畫旨在滿足客觀臨床分析的需求，並尋求自動化和強化眼底影像檢查的臨床工作流程。該系統從其整體架構到由人工智慧 (AI) 模型驅動的模組化分析設計，都與眼科實務無縫對齊。我們獨特的方法結合了最先進的深度學習方法和傳統的電腦視覺演算法，提供眼底結構的全面且細緻的分析。我們提出了一種獨特的設計醫療應用方法，並以我們的系統作為說明範例。全面的驗證和驗證結果證明了我們的方法在革新眼底影像分析方面的效力，並具有在各種醫療領域的潛在應用。

##### **Decoding Generalization from Memorization in Deep Neural Networks**
2501.14687v1 by Simran Ketha, Venkatakrishnan Ramaswamy

Overparameterized Deep Neural Networks that generalize well have been key to
the dramatic success of Deep Learning in recent years. The reasons for their
remarkable ability to generalize are not well understood yet. It has also been
known that deep networks possess the ability to memorize training data, as
evidenced by perfect or high training accuracies on models trained with
corrupted data that have class labels shuffled to varying degrees.
Concomitantly, such models are known to generalize poorly, i.e. they suffer
from poor test accuracies, due to which it is thought that the act of
memorizing substantially degrades the ability to generalize. It has, however,
been unclear why the poor generalization that accompanies such memorization,
comes about. One possibility is that in the process of training with corrupted
data, the layers of the network irretrievably reorganize their representations
in a manner that makes generalization difficult. The other possibility is that
the network retains significant ability to generalize, but the trained network
somehow chooses to readout in a manner that is detrimental to generalization.
Here, we provide evidence for the latter possibility by demonstrating,
empirically, that such models possess information in their representations for
substantially improved generalization, even in the face of memorization.
Furthermore, such generalization abilities can be easily decoded from the
internals of the trained model, and we build a technique to do so from the
outputs of specific layers of the network. We demonstrate results on multiple
models trained with a number of standard datasets.

摘要：<paragraph>過度參數化的深度神經網路具有良好的泛化性，是近年來深度學習獲得巨大成功的關鍵。它們具有非凡泛化能力的原因尚未得到很好的理解。眾所周知，深度網路具有記憶訓練資料的能力，這一點從在資料標籤隨機洗牌到不同程度的已損毀資料訓練模型中完美的或高訓練準確度就可以證明。與此同時，已知此類模型的泛化性較差，即它們的測試準確度較差，因此人們認為記憶行為會大幅降低泛化能力。然而，一直不清楚伴隨此類記憶而來的泛化性較差的原因。一種可能性是在使用已損毀資料訓練的過程中，網路的各層會不可挽回地以一種難以泛化的方式重新組織它們的表示。另一種可能性是網路保留了顯著的泛化能力，但訓練後的網路在某種程度上選擇以不利於泛化的方式讀出。在這裡，我們通過實證證明後一種可能性，證明此類模型在其表示中具有顯著改善泛化的資訊，即使在記憶的情況下也是如此。此外，此類泛化能力可以輕鬆地從訓練模型的內部解碼，我們建立了一種從網路特定層的輸出中進行解碼的技術。我們展示了使用多個標準資料集訓練的模型的結果。</paragraph>

##### **Rethinking Foundation Models for Medical Image Classification through a Benchmark Study on MedMNIST**
2501.14685v1 by Fuping Wu, Bartlomiej W. Papiez

Foundation models are widely employed in medical image analysis, due to their
high adaptability and generalizability for downstream tasks. With the
increasing number of foundation models being released, model selection has
become an important issue. In this work, we study the capabilities of
foundation models in medical image classification tasks by conducting a
benchmark study on the MedMNIST dataset. Specifically, we adopt various
foundation models ranging from convolutional to Transformer-based models and
implement both end-to-end training and linear probing for all classification
tasks. The results demonstrate the significant potential of these pre-trained
models when transferred for medical image classification. We further conduct
experiments with different image sizes and various sizes of training data. By
analyzing all the results, we provide preliminary, yet useful insights and
conclusions on this topic.

摘要：基礎模型廣泛用於醫學影像分析，因為它們對下游任務具有高度的適應性和概括性。隨著發布的基礎模型數量越來越多，模型選擇已成為一個重要問題。在這項工作中，我們通過對 MedMNIST 資料集進行基準研究來研究基礎模型在醫學影像分類任務中的能力。具體來說，我們採用了從卷積到基於 Transformer 的模型等各種基礎模型，並對所有分類任務實施端到端訓練和線性探測。結果證明了這些預訓練模型在轉移到醫學影像分類時具有顯著的潛力。我們進一步進行了不同影像大小和各種訓練資料大小的實驗。通過分析所有結果，我們對此主題提供了初步但有用的見解和結論。

##### **Surface Vision Mamba: Leveraging Bidirectional State Space Model for Efficient Spherical Manifold Representation**
2501.14679v1 by Rongzhao He, Weihao Zheng

Attention-based methods have demonstrated exceptional performance in
modelling long-range dependencies on spherical cortical surfaces, surpassing
traditional Geometric Deep Learning (GDL) models. However, their extensive
inference time and high memory demands pose challenges for application to large
datasets with limited computing resources. Inspired by the state space model in
computer vision, we introduce the attention-free Vision Mamba (Vim) to
spherical surfaces, presenting a domain-agnostic architecture for analyzing
data on spherical manifolds. Our method achieves surface patching by
representing spherical data as a sequence of triangular patches derived from a
subdivided icosphere. The proposed Surface Vision Mamba (SiM) is evaluated on
multiple neurodevelopmental phenotype regression tasks using cortical surface
metrics from neonatal brains. Experimental results demonstrate that SiM
outperforms both attention- and GDL-based methods, delivering 4.8 times faster
inference and achieving 91.7% lower memory consumption compared to the Surface
Vision Transformer (SiT) under the Ico-4 grid partitioning. Sensitivity
analysis further underscores the potential of SiM to identify subtle cognitive
developmental patterns. The code is available at
https://github.com/Rongzhao-He/surface-vision-mamba.

摘要：<paragraph>基於注意力的方法已證明在球形皮質表面上建模長程依賴性方面表現出色，超越了傳統的幾何深度學習 (GDL) 模型。然而，它們廣泛的推論時間和高記憶體需求對應用於具有有限運算資源的大型資料集構成挑戰。受電腦視覺中的狀態空間模型啟發，我們將無注意力的 Vision Mamba (Vim) 引入球形表面，提出了一個與領域無關的架構，用於分析球形流形上的資料。我們的透過將球形資料表示為從細分等角球體衍生的三角形補丁序列，來實現表面貼片。所提出的 Surface Vision Mamba (SiM) 使用來自新生兒大腦的皮質表面指標，在多個神經發育表型回歸任務上進行評估。實驗結果表明，與基於注意力和 GDL 的方法相比，SiM 表現出色，在 Ico-4 網格分割下提供快 4.8 倍的推論速度，並實現低 91.7% 的記憶體消耗，低於 Surface Vision Transformer (SiT)。敏感性分析進一步強調了 SiM 識別微妙認知發育模式的潛力。程式碼可在 https://github.com/Rongzhao-He/surface-vision-mamba 取得。</paragraph>

##### **A Predictive Approach for Enhancing Accuracy in Remote Robotic Surgery Using Informer Model**
2501.14678v1 by Muhammad Hanif Lashari, Shakil Ahmed, Wafa Batayneh, Ashfaq Khokhar

Precise and real-time estimation of the robotic arm's position on the
patient's side is essential for the success of remote robotic surgery in
Tactile Internet (TI) environments. This paper presents a prediction model
based on the Transformer-based Informer framework for accurate and efficient
position estimation. Additionally, it combines a Four-State Hidden Markov Model
(4-State HMM) to simulate realistic packet loss scenarios. The proposed
approach addresses challenges such as network delays, jitter, and packet loss
to ensure reliable and precise operation in remote surgical applications. The
method integrates the optimization problem into the Informer model by embedding
constraints such as energy efficiency, smoothness, and robustness into its
training process using a differentiable optimization layer. The Informer
framework uses features such as ProbSparse attention, attention distilling, and
a generative-style decoder to focus on position-critical features while
maintaining a low computational complexity of O(L log L). The method is
evaluated using the JIGSAWS dataset, achieving a prediction accuracy of over 90
percent under various network scenarios. A comparison with models such as TCN,
RNN, and LSTM demonstrates the Informer framework's superior performance in
handling position prediction and meeting real-time requirements, making it
suitable for Tactile Internet-enabled robotic surgery.

摘要：機器手臂在病患端的精確即時位置估計，對於觸覺網路 (TI) 環境中的遠距機器人手術成功至關重要。本文提出一個基於 Transformer Informer 架構的預測模型，以進行準確且有效率的位置估計。此外，它結合了一個四態隱藏馬可夫模型 (4-State HMM) 來模擬真實的封包遺失情境。所提出的方法可以解決網路延遲、抖動和封包遺失等挑戰，以確保遠距手術應用中的可靠且精確操作。此方法透過將能量效率、平滑度和穩健性等約束嵌入其訓練過程中，將最佳化問題整合到 Informer 模型中，並使用可微分最佳化層。Informer 架構使用 ProbSparse 注意力、注意力萃取和生成式解碼器等功能，專注於位置關鍵特徵，同時維持 O(L log L) 的低計算複雜度。此方法使用 JIGSAWS 資料集進行評估，在各種網路情境下達成超過 90% 的預測準確度。與 TCN、RNN 和 LSTM 等模型的比較，證明了 Informer 架構在處理位置預測和滿足即時需求方面的優異效能，使其適用於觸覺網路啟用的機器人手術。

##### **State Space Models for Extractive Summarization in Low Resource Scenarios**
2501.14673v1 by Nisrine Ait Khayi

Extractive summarization involves selecting the most relevant sentences from
a text. Recently, researchers have focused on advancing methods to improve
state-of-the-art results in low-resource settings. Motivated by these
advancements, we propose the MPoincareSum method. This method applies the Mamba
state space model to generate the semantics of reviews and sentences, which are
then concatenated. A Poincare compression is used to select the most meaningful
features, followed by the application of a linear layer to predict sentence
relevance based on the corresponding review. Finally, we paraphrase the
relevant sentences to create the final summary. To evaluate the effectiveness
of MPoincareSum, we conducted extensive experiments using the Amazon review
dataset. The performance of the method was assessed using ROUGE scores. The
experimental results demonstrate that MPoincareSum outperforms several existing
approaches in the literature

摘要：萃取式摘要涉及從文本中選取最相關的句子。最近，研究人員專注於進步的方法，以改善低資源設定中的最先進結果。受到這些進展的激勵，我們提出 MPoincareSum 方法。此方法應用 Mamba 狀態空間模型來產生評論和句子的語義，然後將其串接。使用 Poincare 壓縮來選擇最有意義的特徵，然後應用線性層根據對應的評論預測句子相關性。最後，我們對相關句子進行改寫，以建立最終摘要。為了評估 MPoincareSum 的有效性，我們使用 Amazon 評論資料集進行了廣泛的實驗。使用 ROUGE 分數評估方法的效能。實驗結果表明，MPoincareSum 優於文獻中現有的幾種方法

##### **MedAgentBench: Dataset for Benchmarking LLMs as Agents in Medical Applications**
2501.14654v1 by Yixing Jiang, Kameron C. Black, Gloria Geng, Danny Park, Andrew Y. Ng, Jonathan H. Chen

Recent large language models (LLMs) have demonstrated significant
advancements, particularly in their ability to serve as agents thereby
surpassing their traditional role as chatbots. These agents can leverage their
planning and tool utilization capabilities to address tasks specified at a high
level. However, a standardized dataset to benchmark the agent capabilities of
LLMs in medical applications is currently lacking, making the evaluation of
LLMs on complex tasks in interactive healthcare environments challenging. To
address this gap, we introduce MedAgentBench, a broad evaluation suite designed
to assess the agent capabilities of large language models within medical
records contexts. MedAgentBench encompasses 100 patient-specific
clinically-derived tasks from 10 categories written by human physicians,
realistic profiles of 100 patients with over 700,000 data elements, a
FHIR-compliant interactive environment, and an accompanying codebase. The
environment uses the standard APIs and communication infrastructure used in
modern EMR systems, so it can be easily migrated into live EMR systems.
MedAgentBench presents an unsaturated agent-oriented benchmark that current
state-of-the-art LLMs exhibit some ability to succeed at. The best model
(GPT-4o) achieves a success rate of 72%. However, there is still substantial
space for improvement to give the community a next direction to optimize.
Furthermore, there is significant variation in performance across task
categories. MedAgentBench establishes this and is publicly available at
https://github.com/stanfordmlgroup/MedAgentBench , offering a valuable
framework for model developers to track progress and drive continuous
improvements in the agent capabilities of large language models within the
medical domain.

摘要：<paragraph>最近的大型语言模型 (LLM) 已展示出显著的进步，特别是在其作为代理的能力方面，从而超越了其作为聊天机器人的传统角色。这些代理可以利用其规划和工具利用能力来解决在高层指定的任务。然而，目前缺乏用于对医疗应用中 LLM 的代理能力进行基准测试的标准化数据集，这使得在交互式医疗保健环境中对 LLM 在复杂任务上的评估具有挑战性。为了解决这一差距，我们引入了 MedAgentBench，这是一个广泛的评估套件，旨在评估大型语言模型在医疗记录背景下的代理能力。MedAgentBench 包含 100 个由人类医生编写的来自 10 个类别的特定于患者的临床任务、100 个患者的真实个人资料（包含超过 700,000 个数据元素）、一个符合 FHIR 的交互式环境以及一个配套的代码库。该环境使用现代 EMR 系统中使用的标准 API 和通信基础设施，因此可以轻松地迁移到实时 EMR 系统中。MedAgentBench 呈现了一个未饱和的以代理为导向的基准，当前最先进的 LLM 表现出一定程度的成功能力。最好的模型 (GPT-4o) 的成功率达到 72%。然而，仍然有很大的改进空间，可以为社区提供优化方向。此外，不同任务类别之间的性能差异很大。MedAgentBench 建立了这一点，并在 https://github.com/stanfordmlgroup/MedAgentBench 公开提供，为模型开发者提供了一个有价值的框架，用于跟踪进度并推动大型语言模型在医疗领域的代理能力的持续改进。</paragraph>

##### **Federated Domain Generalization with Data-free On-server Gradient Matching**
2501.14653v1 by Trong-Binh Nguyen, Minh-Duong Nguyen, Jinsun Park, Quoc-Viet Pham, Won Joo Hwang

Domain Generalization (DG) aims to learn from multiple known source domains a
model that can generalize well to unknown target domains. One of the key
approaches in DG is training an encoder which generates domain-invariant
representations. However, this approach is not applicable in Federated Domain
Generalization (FDG), where data from various domains are distributed across
different clients. In this paper, we introduce a novel approach, dubbed
Federated Learning via On-server Matching Gradient (FedOMG), which can
\emph{efficiently leverage domain information from distributed domains}.
Specifically, we utilize the local gradients as information about the
distributed models to find an invariant gradient direction across all domains
through gradient inner product maximization. The advantages are two-fold: 1)
FedOMG can aggregate the characteristics of distributed models on the
centralized server without incurring any additional communication cost, and 2)
FedOMG is orthogonal to many existing FL/FDG methods, allowing for additional
performance improvements by being seamlessly integrated with them. Extensive
experimental evaluations on various settings to demonstrate the robustness of
FedOMG compared to other FL/FDG baselines. Our method outperforms recent SOTA
baselines on four FL benchmark datasets (MNIST, EMNIST, CIFAR-10, and
CIFAR-100), and three FDG benchmark datasets (PACS, VLCS, and OfficeHome).

摘要：領域泛化（DG）旨在從多個已知的來源領域學習一個模型，該模型可以很好地泛化到未知的目標領域。DG 中的一個關鍵方法是訓練一個編碼器，它生成與領域不變的表示。然而，這種方法不適用於聯合領域泛化 (FDG)，其中來自不同領域的數據分佈在不同的客戶端上。在本文中，我們介紹了一種新方法，稱為通過伺服器上匹配梯度進行聯合學習 (FedOMG)，它可以\emph{有效地利用來自分佈式領域的領域信息}。具體來說，我們利用局部梯度作為分佈式模型的信息，通過梯度內積最大化來找到所有領域中不變的梯度方向。優點有兩個：1) FedOMG 可以聚合中心化伺服器上分佈式模型的特徵，而不會產生任何額外的通信成本，以及 2) FedOMG 與許多現有的 FL/FDG 方法正交，允許通過與它們無縫集成來進一步提高性能。在各種設置上進行了廣泛的實驗評估，以證明 FedOMG 與其他 FL/FDG 基準相比的魯棒性。我們的模型在四個 FL 基準數據集（MNIST、EMNIST、CIFAR-10 和 CIFAR-100）和三個 FDG 基準數據集（PACS、VLCS 和 OfficeHome）上優於最近的 SOTA 基準。

##### **Investigating the (De)Composition Capabilities of Large Language Models in Natural-to-Formal Language Conversion**
2501.14649v1 by Ziyao Xu, Houfeng Wang

To achieve generalized and robust natural-to-formal language conversion
(N2F), large language models (LLMs) need to have strong capabilities of
decomposition and composition in N2F when faced with an unfamiliar formal
language and be able to cope with compositional gaps and counter-intuitive
symbolic names. To investigate whether LLMs have this set of basic capabilities
in N2F, we propose the DEDC framework. This framework semi-automatically
performs sample and task construction, allowing decoupled evaluation of the set
of decomposition and composition capabilities of LLMs in N2F. Based on this
framework, we evaluate and analyze the most advanced LLMs, and the main
findings include that: (1) the LLMs are deficient in both decomposition and
composition; (2) the LLMs show a wide coverage of error types that can be
attributed to deficiencies in natural language understanding and the learning
and use of symbolic systems; (3) compositional gaps and counter-intuitive
symbolic names both affect the decomposition and composition of the LLMs. Our
work provides a new perspective for investigating the basic capabilities of
decomposition and composition of LLMs in N2F. The detailed analysis of
deficiencies and attributions can help subsequent improvements of LLMs.

摘要：<paragraph>為了達成廣泛且穩健的自然語言轉換為形式語言（N2F），大型語言模型（LLM）需要在面對不熟悉的形式語言時擁有強大的 N2F 分解和組合能力，並能夠應對組合間隔和反直覺的符號名稱。為了探究 LLM 是否具備這組 N2F 基本能力，我們提出了 DEDC 架構。此架構半自動執行範例和任務建構，允許對 LLM 在 N2F 中的分解和組合能力組進行解耦評估。根據此架構，我們評估和分析最先進的 LLM，主要發現包括：(1) LLM 在分解和組合方面均有缺陷；(2) LLM 顯示出廣泛的錯誤類型，可歸因於自然語言理解以及符號系統的學習和使用方面的缺陷；(3) 組合間隔和反直覺的符號名稱都會影響 LLM 的分解和組合。我們的研究為探究 LLM 在 N2F 中的分解和組合基本能力提供了新的觀點。對缺陷和歸因的詳細分析有助於後續改進 LLM。</paragraph>

##### **Whisper D-SGD: Correlated Noise Across Agents for Differentially Private Decentralized Learning**
2501.14644v1 by Angelo Rodio, Zheng Chen, Erik G. Larsson

Decentralized learning enables distributed agents to train a shared machine
learning model through local computation and peer-to-peer communication.
Although each agent retains its dataset locally, the communication of local
models can still expose private information to adversaries. To mitigate these
threats, local differential privacy (LDP) injects independent noise per agent,
but it suffers a larger utility gap than central differential privacy (CDP). We
introduce Whisper D-SGD, a novel covariance-based approach that generates
correlated privacy noise across agents, unifying several state-of-the-art
methods as special cases. By leveraging network topology and mixing weights,
Whisper D-SGD optimizes the noise covariance to achieve network-wide noise
cancellation. Experimental results show that Whisper D-SGD cancels more noise
than existing pairwise-correlation schemes, substantially narrowing the CDP-LDP
gap and improving model performance under the same privacy guarantees.

摘要：分散式學習使分散式代理能夠透過本地運算和點對點通訊訓練共享機器學習模型。儘管每個代理在本地保留其資料集，但本地模型的通訊仍可能向對手揭露私人資訊。為了減輕這些威脅，本地差異隱私 (LDP) 會針對每個代理注入獨立雜訊，但它會造成比中央差異隱私 (CDP) 更大的效用差距。我們引入了 Whisper D-SGD，一種新的基於協方差的方法，它會產生代理之間相關的隱私雜訊，將數種最先進的方法統一為特例。透過利用網路拓撲和混合權重，Whisper D-SGD 會最佳化雜訊協方差，以達成網路範圍的雜訊消除。實驗結果顯示，Whisper D-SGD 消除了比現有的成對相關性方案更多的雜訊，大幅縮小了 CDP-LDP 差距，並在相同的隱私保證下提升了模型效能。

##### **Recommending Actionable Strategies: A Semantic Approach to Integrating Analytical Frameworks with Decision Heuristics**
2501.14634v1 by Renato Ghisellini, Remo Pareschi, Marco Pedroni, Giovanni Battista Raggi

We present a novel approach for recommending actionable strategies by
integrating strategic frameworks with decision heuristics through semantic
analysis. While strategy frameworks provide systematic models for assessment
and planning, and decision heuristics encode experiential knowledge,these
traditions have historically remained separate. Our methodology bridges this
gap using advanced natural language processing (NLP), demonstrated through
integrating frameworks like the 6C model with the Thirty-Six Stratagems. The
approach employs vector space representations and semantic similarity
calculations to map framework parameters to heuristic patterns, supported by a
computational architecture that combines deep semantic processing with
constrained use of Large Language Models. By processing both primary content
and secondary elements (diagrams, matrices) as complementary linguistic
representations, we demonstrate effectiveness through corporate strategy case
studies. The methodology generalizes to various analytical frameworks and
heuristic sets, culminating in a plug-and-play architecture for generating
recommender systems that enable cohesive integration of strategic frameworks
and decision heuristics into actionable guidance.

摘要：我們提出了一種新穎的方法，透過語意分析，將策略架構與決策啟發法整合在一起，來推薦可行的策略。雖然策略架構提供了系統化的評估和規劃模型，而決策啟發法編碼了經驗知識，但這些傳統在歷史上一直是分開的。我們的做法使用先進的自然語言處理 (NLP) 來彌合這個差距，並透過將 6C 模型等架構與三十六計整合在一起來加以證明。該方法採用向量空間表示和語意相似性計算，將架構參數映射到啟發模式，並由結合深度語意處理和約束式使用大型語言模型的計算架構提供支援。透過將主要內容和次要元素（圖表、矩陣）作為互補的語言表示進行處理，我們透過公司策略案例研究證明了其有效性。該方法可以概括到各種分析架構和啟發式集合，最終形成一個即插即用的架構，用於產生推薦系統，使策略架構和決策啟發法能夠緊密整合到可行的指導中。

##### **Extracting Problem Structure with LLMs for Optimized SAT Local Search**
2501.14630v1 by André Schilder, Stefan Szeider

Local search preprocessing makes Conflict-Driven Clause Learning (CDCL)
solvers faster by providing high-quality starting points and modern SAT solvers
have incorporated this technique into their preprocessing steps. However, these
tools rely on basic strategies that miss the structural patterns in problems.
We present a method that applies Large Language Models (LLMs) to analyze
Python-based encoding code. This reveals hidden structural patterns in how
problems convert into SAT. Our method automatically generates specialized local
search algorithms that find these patterns and use them to create strong
initial assignments. This works for any problem instance from the same encoding
type. Our tests show encouraging results, achieving faster solving times
compared to baseline preprocessing systems.

摘要：區域搜尋預處理使衝突驅動子句學習 (CDCL) 解算器能提供高品質的起點，而現代 SAT 解算器已將此技術納入其預處理步驟中，讓解算器能運作得更快。然而，這些工具依賴於基本策略，而錯失了問題中的結構模式。我們提出了一個方法，將大型語言模型 (LLM) 應用於分析基於 Python 的編碼碼。這揭露了問題轉換為 SAT 時隱藏的結構模式。我們的自動產生特殊區域搜尋演算法，找出這些模式並使用它們來建立強而有力的初始指派。這適用於相同編碼類型的任何問題實例。我們的測試顯示令人振奮的結果，與基準預處理系統相比，能達成更快的解算時間。

##### **ACT-JEPA: Joint-Embedding Predictive Architecture Improves Policy Representation Learning**
2501.14622v1 by Aleksandar Vujinovic, Aleksandar Kovacevic

Learning efficient representations for decision-making policies is a
challenge in imitation learning (IL). Current IL methods require expert
demonstrations, which are expensive to collect. Consequently, they often have
underdeveloped world models. Self-supervised learning (SSL) offers an
alternative by allowing models to learn from diverse, unlabeled data, including
failures. However, SSL methods often operate in raw input space, making them
inefficient. In this work, we propose ACT-JEPA, a novel architecture that
integrates IL and SSL to enhance policy representations. We train a policy to
predict (1) action sequences and (2) abstract observation sequences. The first
objective uses action chunking to improve action prediction and reduce
compounding errors. The second objective extends this idea of chunking by
predicting abstract observation sequences. We utilize Joint-Embedding
Predictive Architecture to predict in abstract representation space, allowing
the model to filter out irrelevant details, improve efficiency, and develop a
robust world model. Our experiments show that ACT-JEPA improves the quality of
representations by learning temporal environment dynamics. Additionally, the
model's ability to predict abstract observation sequences results in
representations that effectively generalize to action sequence prediction.
ACT-JEPA performs on par with established baselines across a range of
decision-making tasks.

摘要：在模仿學習（IL）中，學習決策制定策略的有效表示是一項挑戰。當前的 IL 方法需要專家示範，而收集這些示範的成本很高。因此，它們通常有欠發展的世界模型。自我監督學習（SSL）提供了一種替代方案，允許模型從多樣化的、未標記的數據（包括失敗）中學習。然而，SSL 方法通常在原始輸入空間中運作，這使得它們效率低下。在這項工作中，我們提出了 ACT-JEPA，這是一種將 IL 和 SSL 集成在一起以增強策略表示的新架構。我們訓練一個策略來預測（1）動作序列和（2）抽象觀察序列。第一個目標使用動作分塊來改進動作預測並減少累積誤差。第二個目標通過預測抽象觀察序列來擴展這個分塊的想法。我們利用聯合嵌入預測架構在抽象表示空間中進行預測，允許模型過濾掉無關的細節、提高效率並開發一個強健的世界模型。我們的實驗表明，ACT-JEPA 通過學習時間環境動態來提高表示的質量。此外，模型預測抽象觀察序列的能力產生了有效概括到動作序列預測的表示。ACT-JEPA 在一系列決策制定任務中與已建立的基準表現相當。

##### **Funzac at CoMeDi Shared Task: Modeling Annotator Disagreement from Word-In-Context Perspectives**
2501.14617v1 by Olufunke O. Sarumi, Charles Welch, Lucie Flek, Jörg Schlötterer

In this work, we evaluate annotator disagreement in Word-in-Context (WiC)
tasks exploring the relationship between contextual meaning and disagreement as
part of the CoMeDi shared task competition. While prior studies have modeled
disagreement by analyzing annotator attributes with single-sentence inputs,
this shared task incorporates WiC to bridge the gap between sentence-level
semantic representation and annotator judgment variability. We describe three
different methods that we developed for the shared task, including a feature
enrichment approach that combines concatenation, element-wise differences,
products, and cosine similarity, Euclidean and Manhattan distances to extend
contextual embedding representations, a transformation by Adapter blocks to
obtain task-specific representations of contextual embeddings, and classifiers
of varying complexities, including ensembles. The comparison of our methods
demonstrates improved performance for methods that include enriched and
task-specfic features. While the performance of our method falls short in
comparison to the best system in subtask 1 (OGWiC), it is competitive to the
official evaluation results in subtask 2 (DisWiC).

摘要：在這項工作中，我們評估了語境中的單字 (WiC) 任務中的註解者分歧，探索了語境意義和分歧之間的關係，作為 CoMeDi 共享任務競賽的一部分。雖然先前的研究已通過分析單一句子輸入的註解者屬性對分歧進行建模，但此共享任務納入了 WiC，以彌合句子層級語義表示和註解者判斷變異之間的差距。我們描述了我們為共享任務開發的三種不同方法，包括一種特徵豐富化方法，它結合了串聯、元素差異、乘積和餘弦相似性、歐幾里得和曼哈頓距離來擴充語境嵌入表示，通過適配器塊進行轉換以獲得語境嵌入的特定於任務的表示，以及包括集合在內的不同複雜程度的分類器。我們的方法的比較證明了包含豐富和特定於任務的特徵的方法的效能有所提升。雖然我們的方法的效能與子任務 1 (OGWiC) 中的最佳系統相比有所不足，但它與子任務 2 (DisWiC) 中的官方評估結果具有競爭力。

##### **Leveraging Spatial Cues from Cochlear Implant Microphones to Efficiently Enhance Speech Separation in Real-World Listening Scenes**
2501.14610v1 by Feyisayo Olalere, Kiki van der Heijden, Christiaan H. Stronks, Jeroen Briaire, Johan HM Frijns, Marcel van Gerven

Speech separation approaches for single-channel, dry speech mixtures have
significantly improved. However, real-world spatial and reverberant acoustic
environments remain challenging, limiting the effectiveness of these approaches
for assistive hearing devices like cochlear implants (CIs). To address this, we
quantify the impact of real-world acoustic scenes on speech separation and
explore how spatial cues can enhance separation quality efficiently. We analyze
performance based on implicit spatial cues (inherent in the acoustic input and
learned by the model) and explicit spatial cues (manually calculated spatial
features added as auxiliary inputs). Our findings show that spatial cues (both
implicit and explicit) improve separation for mixtures with spatially separated
and nearby talkers. Furthermore, spatial cues enhance separation when spectral
cues are ambiguous, such as when voices are similar. Explicit spatial cues are
particularly beneficial when implicit spatial cues are weak. For instance,
single CI microphone recordings provide weaker implicit spatial cues than
bilateral CIs, but even single CIs benefit from explicit cues. These results
emphasize the importance of training models on real-world data to improve
generalizability in everyday listening scenarios. Additionally, our statistical
analyses offer insights into how data properties influence model performance,
supporting the development of efficient speech separation approaches for CIs
and other assistive devices in real-world settings.

摘要：單通道、乾式語音混合的語音分離方法已顯著改善。然而，真實世界的空間和混響聲學環境仍然具有挑戰性，這限制了這些方法對助聽裝置（例如人工耳蝸 (CI)）的有效性。為了解決這個問題，我們量化了真實世界聲學場景對語音分離的影響，並探討了空間線索如何有效地增強分離品質。我們根據隱含空間線索（聲學輸入中固有的，且由模型學習的）和顯式空間線索（手動計算的空間特徵，作為輔助輸入新增）分析效能。我們的研究結果顯示，空間線索（隱含和顯式）可改善空間分離和附近說話者的混合分離。此外，當頻譜線索模稜兩可時（例如聲音相似時），空間線索會增強分離。當隱含空間線索較弱時，顯式空間線索特別有益。例如，單一 CI 麥克風錄音提供的隱含空間線索比雙邊 CI 弱，但即使單一 CI 也能從顯式線索中受益。這些結果強調了在真實世界資料上訓練模型以改善日常聆聽場景中概括性的重要性。此外，我們的統計分析提供了資料屬性如何影響模型效能的見解，支援在真實世界設定中開發 CI 和其他輔助裝置的有效語音分離方法。

##### **Age and Power Minimization via Meta-Deep Reinforcement Learning in UAV Networks**
2501.14603v1 by Sankani Sarathchandra, Eslam Eldeeb, Mohammad Shehab, Hirley Alves, Konstantin Mikhaylov, Mohamed-Slim Alouini

Age-of-information (AoI) and transmission power are crucial performance
metrics in low energy wireless networks, where information freshness is of
paramount importance. This study examines a power-limited internet of things
(IoT) network supported by a flying unmanned aerial vehicle(UAV) that collects
data. Our aim is to optimize the UAV flight trajectory and scheduling policy to
minimize a varying AoI and transmission power combination. To tackle this
variation, this paper proposes a meta-deep reinforcement learning (RL) approach
that integrates deep Q-networks (DQNs) with model-agnostic meta-learning
(MAML). DQNs determine optimal UAV decisions, while MAML enables scalability
across varying objective functions. Numerical results indicate that the
proposed algorithm converges faster and adapts to new objectives more
effectively than traditional deep RL methods, achieving minimal AoI and
transmission power overall.

摘要：資訊年齡 (AoI) 和傳輸功率是低能耗無線網路中至關重要的效能指標，其中資訊新鮮度至關重要。本研究探討由飛行無人機 (UAV) 支援的電力受限物聯網 (IoT) 網路，該無人機負責收集資料。我們的目標是最佳化無人機飛行軌跡和排程政策，以最小化變動的 AoI 和傳輸功率組合。為了應對這種變動，本文提出了一種元深度強化學習 (RL) 方法，它將深度 Q 網路 (DQN) 與模型不可知的元學習 (MAML) 整合在一起。DQN 決定最佳無人機決策，而 MAML 則支援在不同的目標函數之間進行擴充。數值結果表明，與傳統的深度 RL 方法相比，所提出的演算法收斂得更快，並且更有效地適應新的目標，整體上實現了最小的 AoI 和傳輸功率。

##### **ZETA: Leveraging Z-order Curves for Efficient Top-k Attention**
2501.14577v1 by Qiuhao Zeng, Jerry Huang, Peng Lu, Gezheng Xu, Boxing Chen, Charles Ling, Boyu Wang

Over recent years, the Transformer has become a fundamental building block
for sequence modeling architectures. Yet at its core is the use of
self-attention, whose memory and computational cost grow quadratically with the
sequence length $N$, rendering it prohibitively expensive for long sequences. A
promising approach is top-$k$ attention, which selects only the $k$ most
relevant tokens and achieves performance comparable to vanilla self-attention
while significantly reducing space and computational demands. However, causal
masks require the current query token to only attend to past tokens, preventing
the existing top-$k$ attention method from efficiently searching for the most
relevant tokens in parallel, thereby limiting training efficiency. In this
work, we propose ZETA, leveraging \textbf{Z}-Order Curves for
\textbf{E}fficient \textbf{T}op-$k$ \textbf{A}ttention, to enable parallel
querying of past tokens for entire sequences. % in both space and time
complexity of $\mathcal{O}(N \log N)$. We first theoretically show that the
choice of key and query dimensions involves a trade-off between the curse of
dimensionality and the preservation of relative distances after projection. In
light of this insight, we propose reducing the dimensionality of keys and
queries in contrast to values and further leverage $Z$-order curves to map
low-dimensional keys and queries into \emph{one}-dimensional space, which
permits parallel sorting, thereby largely improving the efficiency for top-$k$
token selection. Experimental results demonstrate that ZETA matches the
performance of standard attention on the synthetic \textsc{Multi-Query
Associative Recall} task and outperforms attention and its variants on
\textsc{Long Range Arena} and \textsc{WikiText-103} language modeling.

摘要：<paragraph>近年来，Transformer 已成为序列建模架构的基本构建模块。然而，其核心是使用自注意力，其内存和计算成本随序列长度 $N$ 二次增长，使得其对于长序列的开销过大。一种有前景的方法是 top-$k$ 注意力，它仅选择 $k$ 个最相关的标记，并实现与香草自注意力相当的性能，同时显著降低空间和计算需求。然而，因果掩码要求当前查询标记仅关注过去标记，从而阻止现有的 top-$k$ 注意力方法并行有效地搜索最相关的标记，从而限制了训练效率。在这项工作中，我们提出了 ZETA，利用 \textbf{Z} 阶曲线实现 \textbf{E}fficient \textbf{T}op-$k$ \textbf{A}ttention，以实现对整个序列中过去标记的并行查询。% 在空间和时间复杂度上均为 $\mathcal{O}(N \log N)$。我们首先从理论上表明，键和查询维度的选择涉及维度灾难和投影后相对距离的保留之间的权衡。根据这一见解，我们提出降低键和查询的维度，与值形成对比，并进一步利用 $Z$ 阶曲线将低维键和查询映射到\emph{一}维空间，这允许并行排序，从而极大地提高了 top-$k$ 标记选择的效率。实验结果表明，ZETA 在合成 \textsc{多查询关联召回} 任务上与标准注意力的性能相匹配，并在 \textsc{长程竞技场} 和 \textsc{WikiText-103} 语言建模上优于注意力及其变体。</paragraph>

##### **Leveraging ChatGPT's Multimodal Vision Capabilities to Rank Satellite Images by Poverty Level: Advancing Tools for Social Science Research**
2501.14546v1 by Hamid Sarmadi, Ola Hall, Thorsteinn Rögnvaldsson, Mattias Ohlsson

This paper investigates the novel application of Large Language Models (LLMs)
with vision capabilities to analyze satellite imagery for village-level poverty
prediction. Although LLMs were originally designed for natural language
understanding, their adaptability to multimodal tasks, including geospatial
analysis, has opened new frontiers in data-driven research. By leveraging
advancements in vision-enabled LLMs, we assess their ability to provide
interpretable, scalable, and reliable insights into human poverty from
satellite images. Using a pairwise comparison approach, we demonstrate that
ChatGPT can rank satellite images based on poverty levels with accuracy
comparable to domain experts. These findings highlight both the promise and the
limitations of LLMs in socioeconomic research, providing a foundation for their
integration into poverty assessment workflows. This study contributes to the
ongoing exploration of unconventional data sources for welfare analysis and
opens pathways for cost-effective, large-scale poverty monitoring.

摘要：本文探討大型語言模型（LLM）的新穎應用，結合視覺能力來分析衛星影像，用於村莊層級的貧窮預測。儘管 LLM 最初是為自然語言理解而設計，但其對多模態任務（包括地理空間分析）的適應性，開啟了資料驅動研究的新領域。透過利用具備視覺功能的 LLM 的進步，我們評估其從衛星影像中提供可解釋、可擴充且可靠的人類貧窮洞察的能力。使用成對比較方法，我們證明 ChatGPT 可以根據貧窮程度對衛星影像進行排名，其準確度與領域專家相當。這些發現突顯了 LLM 在社會經濟研究中的優點和限制，為其整合到貧窮評估工作流程中奠定了基礎。本研究有助於持續探索非傳統資料來源以進行福利分析，並為具成本效益的大規模貧窮監測開啟了途徑。

##### **Distributed Conformal Prediction via Message Passing**
2501.14544v1 by Haifeng Wen, Hong Xing, Osvaldo Simeone

Post-hoc calibration of pre-trained models is critical for ensuring reliable
inference, especially in safety-critical domains such as healthcare. Conformal
Prediction (CP) offers a robust post-hoc calibration framework, providing
distribution-free statistical coverage guarantees for prediction sets by
leveraging held-out datasets. In this work, we address a decentralized setting
where each device has limited calibration data and can communicate only with
its neighbors over an arbitrary graph topology. We propose two
message-passing-based approaches for achieving reliable inference via CP:
quantile-based distributed conformal prediction (Q-DCP) and histogram-based
distributed conformal prediction (H-DCP). Q-DCP employs distributed quantile
regression enhanced with tailored smoothing and regularization terms to
accelerate convergence, while H-DCP uses a consensus-based histogram estimation
approach. Through extensive experiments, we investigate the trade-offs between
hyperparameter tuning requirements, communication overhead, coverage
guarantees, and prediction set sizes across different network topologies.

摘要：預先訓練模型的事後校正對於確保可靠的推論至關重要，尤其是在醫療保健等安全性至上的領域。一致性預測 (CP) 提供了一個強健的事後校正架構，透過利用保留的資料集，為預測集合提供不依賴分配的統計覆蓋率保證。在這項研究中，我們探討了一個分散式設定，其中每個裝置都只有有限的校正資料，而且只能透過任意圖形拓撲與其鄰近裝置進行通訊。我們提出了兩種基於訊息傳遞的方法，透過 CP 達到可靠的推論：基於分位數的分散式一致性預測 (Q-DCP) 和基於直方圖的分散式一致性預測 (H-DCP)。Q-DCP 採用的分散式分位數回歸經過量身打造的平滑和正則化項強化，以加速收斂，而 H-DCP 則使用基於共識的直方圖估計方法。透過廣泛的實驗，我們探討了在不同的網路拓撲中，超參數調整需求、通訊負擔、覆蓋率保證和預測集合大小之間的取捨。

##### **VERUS-LM: a Versatile Framework for Combining LLMs with Symbolic Reasoning**
2501.14540v1 by Benjamin Callewaert, Simon Vandevelde, Joost Vennekens

A recent approach to neurosymbolic reasoning is to explicitly combine the
strengths of large language models (LLMs) and symbolic solvers to tackle
complex reasoning tasks. However, current approaches face significant
limitations, including poor generalizability due to task-specific prompts,
inefficiencies caused by the lack of separation between knowledge and queries,
and restricted inferential capabilities. These shortcomings hinder their
scalability and applicability across diverse domains. In this paper, we
introduce VERUS-LM, a novel framework designed to address these challenges.
VERUS-LM employs a generic prompting mechanism, clearly separates domain
knowledge from queries, and supports a wide range of different logical
reasoning tasks. This framework enhances adaptability, reduces computational
cost, and allows for richer forms of reasoning, such as optimization and
constraint satisfaction. We show that our approach succeeds in diverse
reasoning on a novel dataset, markedly outperforming LLMs. Additionally, our
system achieves competitive results on common reasoning benchmarks when
compared to other state-of-the-art approaches, and significantly surpasses them
on the difficult AR-LSAT dataset. By pushing the boundaries of hybrid
reasoning, VERUS-LM represents a significant step towards more versatile
neurosymbolic AI systems

摘要：最近神经符号推理的一种方法是明确结合大型语言模型 (LLM) 和符号求解器的优势来解决复杂的推理任务。然而，目前的方法面临着重大的局限性，包括由于特定任务提示导致的泛化能力差、由于缺乏知识和查询之间的分离而导致的效率低下以及受限的推理能力。这些缺点阻碍了它们在不同领域的可扩展性和适用性。在本文中，我们介绍了 VERUS-LM，这是一个旨在解决这些挑战的新框架。VERUS-LM 采用通用提示机制，将领域知识与查询明确分开，并支持各种不同的逻辑推理任务。该框架增强了适应性，降低了计算成本，并允许进行更丰富的推理形式，例如优化和约束满足。我们表明，我们的方法在新的数据集上取得了不同的推理成功，明显优于 LLM。此外，与其他最先进的方法相比，我们的系统在常见的推理基准上取得了有竞争力的结果，并且在困难的 AR-LSAT 数据集上明显超越了它们。通过突破混合推理的界限，VERUS-LM 代表了朝着更通用的神经符号 AI 系统迈出的重要一步

##### **Idiom Detection in Sorani Kurdish Texts**
2501.14528v1 by Skala Kamaran Omer, Hossein Hassani

Idiom detection using Natural Language Processing (NLP) is the computerized
process of recognizing figurative expressions within a text that convey
meanings beyond the literal interpretation of the words. While idiom detection
has seen significant progress across various languages, the Kurdish language
faces a considerable research gap in this area despite the importance of idioms
in tasks like machine translation and sentiment analysis. This study addresses
idiom detection in Sorani Kurdish by approaching it as a text classification
task using deep learning techniques. To tackle this, we developed a dataset
containing 10,580 sentences embedding 101 Sorani Kurdish idioms across diverse
contexts. Using this dataset, we developed and evaluated three deep learning
models: KuBERT-based transformer sequence classification, a Recurrent
Convolutional Neural Network (RCNN), and a BiLSTM model with an attention
mechanism. The evaluations revealed that the transformer model, the fine-tuned
BERT, consistently outperformed the others, achieving nearly 99% accuracy while
the RCNN achieved 96.5% and the BiLSTM 80%. These results highlight the
effectiveness of Transformer-based architectures in low-resource languages like
Kurdish. This research provides a dataset, three optimized models, and insights
into idiom detection, laying a foundation for advancing Kurdish NLP.

摘要：慣用語偵測使用自然語言處理 (NLP)，是一種電腦化的程序，用於辨識文字中的比喻表達方式，傳達出超出字面意思的意義。雖然慣用語偵測在各種語言中都有顯著的進展，但庫德語在這個領域卻面臨相當大的研究差距，儘管慣用語在機器翻譯和情緒分析等任務中很重要。本研究透過將慣用語偵測視為一種使用深度學習技術的文字分類任務，來探討索拉尼庫德語中的慣用語偵測。為了解決這個問題，我們開發了一個包含 10,580 個句子的資料集，其中嵌入了 101 個索拉尼庫德語慣用語，涵蓋了各種不同的脈絡。使用這個資料集，我們開發並評估了三個深度學習模型：基於 KuBERT 的 Transformer 序列分類、遞迴卷積神經網路 (RCNN) 和帶有注意力機制的 BiLSTM 模型。評估結果顯示，Transformer 模型、微調後的 BERT，始終優於其他模型，準確率接近 99%，而 RCNN 達到 96.5%，BiLSTM 達到 80%。這些結果突顯了 Transformer-based 架構在低資源語言（如庫德語）中的有效性。本研究提供了一個資料集、三個最佳化模型和對慣用語偵測的見解，為推進庫德語 NLP 奠定了基礎。

##### **WanJuanSiLu: A High-Quality Open-Source Webtext Dataset for Low-Resource Languages**
2501.14506v1 by Jia Yu, Fei Yuan, Rui Min, Jing Yu, Pei Chu, Jiayang Li, Wei Li, Ruijie Zhang, Zhenxiang Li, Zhifei Ren, Dong Zheng, Wenjian Zhang, Yan Teng, Lingyu Meng, ZhenJiang Jin, Jiantao Qiu, ShaSha Wang, Zhongying Tu, Dahua Lin, Yu Wang, Yu Qiao, Yanfeng Wang, Conghui He

This paper introduces the open-source dataset WanJuanSiLu, designed to
provide high-quality training corpora for low-resource languages, thereby
advancing the research and development of multilingual models. To achieve this,
we have developed a systematic data processing framework tailored for
low-resource languages. This framework encompasses key stages such as data
extraction, corpus cleaning, content deduplication, security filtering, quality
evaluation, and theme classification. Through the implementation of this
framework, we have significantly improved both the quality and security of the
dataset, while maintaining its linguistic diversity. As of now, data for all
five languages have been fully open-sourced. The dataset can be accessed at
https://opendatalab.com/applyMultilingualCorpus, and GitHub repository is
available at https://github.com/opendatalab/WanJuan3.0

摘要：本文介紹了開源資料集 WanJuanSiLu，其設計目的是為低資源語言提供高品質的訓練語料庫，進而推動多語言模型的研究與開發。為此，我們開發了一個系統性的資料處理架構，專門針對低資源語言。此架構包含資料萃取、語料庫清理、內容去重、安全性過濾、品質評估和主題分類等主要階段。透過實作此架構，我們大幅提升了資料集的品質和安全性，同時維持其語言的多樣性。目前，所有五種語言的資料都已完全開源。可在 https://opendatalab.com/applyMultilingualCorpus 存取資料集，GitHub 儲存庫可於 https://github.com/opendatalab/WanJuan3.0 取得

##### **Evaluating and Improving Graph to Text Generation with Large Language Models**
2501.14497v1 by Jie He, Yijun Yang, Wanqiu Long, Deyi Xiong, Victor Gutierrez Basulto, Jeff Z. Pan

Large language models (LLMs) have demonstrated immense potential across
various tasks. However, research for exploring and improving the capabilities
of LLMs in interpreting graph structures remains limited. To address this gap,
we conduct a comprehensive evaluation of prompting current open-source LLMs on
graph-to-text generation tasks. Although we explored the optimal prompting
strategies and proposed a novel and effective diversity-difficulty-based
few-shot sample selection method, we found that the improvements from
tuning-free approaches were incremental, as LLMs struggle with planning on
complex graphs, particularly those with a larger number of triplets. To further
improve LLMs in planning with graph sequences and grounding in truth, we
introduce a new graph-to-text dataset, PlanGTG, annotated with two sub-tasks:
reordering and attribution. Through extensive automatic and human evaluations,
we demonstrate significant improvements in the quality of generated text from
both few-shot learning and fine-tuning perspectives using the PlanGTG dataset.
Our study paves the way for new research directions in graph-to-text
generation. PlanGTG datasets can be found in https://github.com/probe2/kg_text.

摘要：大型語言模型（LLM）已在各種任務中展現出巨大的潛力。然而，探索和提升 LLM 在詮釋圖形結構方面的能力的研究仍然有限。為了解決這個差距，我們對提示目前開源的 LLM 執行圖形轉文字生成任務進行全面評估。儘管我們探索了最佳提示策略並提出了一種新穎且有效的基於多樣性難度的少樣本選擇方法，但我們發現無調校方法的改進是漸進的，因為 LLM 難以規劃複雜的圖形，特別是那些具有較多三元組的圖形。為了進一步提升 LLM 在圖形序列規劃和真實依據方面的能力，我們引入了一個新的圖形轉文字資料集 PlanGTG，並註解了兩個子任務：重新排序和歸因。透過廣泛的自動化和人工評估，我們證明了使用 PlanGTG 資料集從少樣本學習和微調角度產生文字的品質有顯著提升。我們的研究為圖形轉文字生成中的新研究方向鋪路。PlanGTG 資料集可以在 https://github.com/probe2/kg_text 中找到。

##### **Analyzing the Effect of Linguistic Similarity on Cross-Lingual Transfer: Tasks and Experimental Setups Matter**
2501.14491v1 by Verena Blaschke, Masha Fedzechkina, Maartje ter Hoeve

Cross-lingual transfer is a popular approach to increase the amount of
training data for NLP tasks in a low-resource context. However, the best
strategy to decide which cross-lingual data to include is unclear. Prior
research often focuses on a small set of languages from a few language families
and/or a single task. It is still an open question how these findings extend to
a wider variety of languages and tasks. In this work, we analyze cross-lingual
transfer for 266 languages from a wide variety of language families. Moreover,
we include three popular NLP tasks: POS tagging, dependency parsing, and topic
classification. Our findings indicate that the effect of linguistic similarity
on transfer performance depends on a range of factors: the NLP task, the (mono-
or multilingual) input representations, and the definition of linguistic
similarity.

摘要：跨語言轉移是一種流行的作法，用於增加低資源環境下 NLP 任務的訓練資料量。然而，要決定納入哪些跨語言資料的最佳策略仍不明確。先前的研究通常專注於少數語言家族中的一小組語言和/或單一任務。這些發現如何擴展到更多元化的語言和任務，這仍是一個開放性的問題。在這項工作中，我們分析了來自各種語言家族的 266 種語言的跨語言轉移。此外，我們納入了三項流行的 NLP 任務：詞性標記、依存句法分析和主題分類。我們的研究結果表明，語言相似性對轉移效能的影響取決於一系列因素：NLP 任務、（單語或多語）輸入表示，以及語言相似性的定義。

##### **RealCritic: Towards Effectiveness-Driven Evaluation of Language Model Critiques**
2501.14492v1 by Zhengyang Tang, Ziniu Li, Zhenyang Xiao, Tian Ding, Ruoyu Sun, Benyou Wang, Dayiheng Liu, Fei Huang, Tianyu Liu, Bowen Yu, Junyang Lin

Critiques are important for enhancing the performance of Large Language
Models (LLMs), enabling both self-improvement and constructive feedback for
others by identifying flaws and suggesting improvements. However, evaluating
the critique capabilities of LLMs presents a significant challenge due to the
open-ended nature of the task. In this work, we introduce a new benchmark
designed to assess the critique capabilities of LLMs. Unlike existing
benchmarks, which typically function in an open-loop fashion, our approach
employs a closed-loop methodology that evaluates the quality of corrections
generated from critiques. Moreover, the benchmark incorporates features such as
self-critique, cross-critique, and iterative critique, which are crucial for
distinguishing the abilities of advanced reasoning models from more classical
ones. We implement this benchmark using eight challenging reasoning tasks. We
have several interesting findings. First, despite demonstrating comparable
performance in direct chain-of-thought generation, classical LLMs significantly
lag behind the advanced reasoning-based model o1-mini across all critique
scenarios. Second, in self-critique and iterative critique settings, classical
LLMs may even underperform relative to their baseline capabilities. We hope
that this benchmark will serve as a valuable resource to guide future
advancements. The code and data are available at
\url{https://github.com/tangzhy/RealCritic}.

摘要：批評對於大型語言模型 (LLM) 的效能提升非常重要，它能透過找出缺點並建議改進方式，達到自我提升和對他人提供建設性回饋的目的。然而，評估 LLM 的批評能力是一項重大挑戰，因為這項任務的本質是開放式的。在這項研究中，我們提出了一個新的基準，用來評估 LLM 的批評能力。與現有的基準（通常以開放迴路的方式運作）不同，我們的做法採用閉迴路方法，用來評估從批評中產生的修正品質。此外，這個基準還包含自評、交叉批評和反覆批評等功能，這些功能對於區分進階推理模型和較傳統模型的能力至關重要。我們使用八項具有挑戰性的推理任務來實作這個基準。我們有幾個有趣的發現。首先，儘管在直接的思維鏈生成中表現出相當的效能，但傳統的 LLM 在所有批評情境中都遠遠落後於基於進階推理的模型 o1-mini。其次，在自評和反覆批評的設定中，傳統的 LLM 甚至可能表現不如其基準能力。我們希望這個基準能成為引導未來進展的寶貴資源。程式碼和資料可在 \url{https://github.com/tangzhy/RealCritic} 取得。

##### **The Pseudo-Dimension of Contracts**
2501.14474v1 by Paul Duetting, Michal Feldman, Tomasz Ponitka, Ermis Soumalias

Algorithmic contract design studies scenarios where a principal incentivizes
an agent to exert effort on her behalf. In this work, we focus on settings
where the agent's type is drawn from an unknown distribution, and formalize an
offline learning framework for learning near-optimal contracts from sample
agent types. A central tool in our analysis is the notion of pseudo-dimension
from statistical learning theory. Beyond its role in establishing upper bounds
on the sample complexity, pseudo-dimension measures the intrinsic complexity of
a class of contracts, offering a new perspective on the tradeoffs between
simplicity and optimality in contract design. Our main results provide
essentially optimal tradeoffs between pseudo-dimension and representation error
(defined as the loss in principal's utility) with respect to linear and bounded
contracts. Using these tradeoffs, we derive sample- and time-efficient learning
algorithms, and demonstrate their near-optimality by providing almost matching
lower bounds on the sample complexity. Conversely, for unbounded contracts, we
prove an impossibility result showing that no learning algorithm exists.
  Finally, we extend our techniques in three important ways. First, we provide
refined pseudo-dimension and sample complexity guarantees for the combinatorial
actions model, revealing a novel connection between the number of critical
values and sample complexity. Second, we extend our results to menus of
contracts, showing that their pseudo-dimension scales linearly with the menu
size. Third, we adapt our algorithms to the online learning setting, where we
show that, a polynomial number of type samples suffice to learn near-optimal
bounded contracts. Combined with prior work, this establishes a formal
separation between expert advice and bandit feedback for this setting.

摘要：<paragraph>演算法合約設計研究場景，其中委託人激勵代理人為其付出努力。在這項工作中，我們專注於代理人的類型從未知分佈中抽出的設定，並形式化一個離線學習架構，以從樣本代理人類型中學習近乎最佳的合約。我們分析中的核心工具是統計學習理論中的偽維度概念。除了在建立樣本複雜度上限中的作用外，偽維度還測量了一類合約的內在複雜度，為合約設計中簡潔性和最佳性之間的權衡提供了新的觀點。我們的成果在偽維度和表示誤差（定義為委託人效用的損失）之間提供了本質上最佳的權衡，相對於線性和有界合約。利用這些權衡，我們推導出樣本和時間效率的學習演算法，並透過提供幾乎匹配樣本複雜度下限來證明它們的近乎最佳性。相反地，對於無界合約，我們證明了一個不可能的結果，表明不存在學習演算法。最後，我們以三種重要方式擴展了我們的技術。首先，我們為組合動作模型提供了精確的偽維度和樣本複雜度保證，揭示了臨界值數量和樣本複雜度之間的新穎關聯。其次，我們將我們的結果擴展到合約選單，表明它們的偽維度與選單大小成線性比例。第三，我們將我們的演算法調整到線上學習設定，在其中我們表明，多項式的類型樣本數量足以學習近乎最佳的有界合約。結合先前的研究，這為此設定的專家建議和多臂老虎機回饋建立了一個正式的分離。</paragraph>

##### **Pesti-Gen: Unleashing a Generative Molecule Approach for Toxicity Aware Pesticide Design**
2501.14469v1 by Taehan Kim, Wonduk Seo

Global climate change has reduced crop resilience and pesticide efficacy,
making reliance on synthetic pesticides inevitable, even though their
widespread use poses significant health and environmental risks. While these
pesticides remain a key tool in pest management, previous machine-learning
applications in pesticide and agriculture have focused on classification or
regression, leaving the fundamental challenge of generating new molecular
structures or designing novel candidates unaddressed. In this paper, we propose
Pesti-Gen, a novel generative model based on variational auto-encoders,
designed to create pesticide candidates with optimized properties for the first
time. Specifically, Pesti-Gen leverages a two-stage learning process: an
initial pre-training phase that captures a generalized chemical structure
representation, followed by a fine-tuning stage that incorporates
toxicity-specific information. The model simultaneously optimizes over multiple
toxicity metrics, such as (1) livestock toxicity and (2) aqua toxicity to
generate environmentally friendly pesticide candidates. Notably, Pesti-Gen
achieves approximately 68\% structural validity in generating new molecular
structures, demonstrating the model's effectiveness in producing optimized and
feasible pesticide candidates, thereby providing a new way for safer and more
sustainable pest management solutions.

摘要：全球氣候變遷降低了作物的復原力與殺蟲劑的效力，
使得仰賴合成殺蟲劑成為無可避免的趨勢，儘管它們的廣泛使用會帶來重大的健康和環境風險。儘管這些殺蟲劑仍然是蟲害管理中的關鍵工具，過去在殺蟲劑和農業方面的機器學習應用都著重於分類或迴歸，而未解決產生新的分子結構或設計新候選藥劑的基本挑戰。在本文中，我們提出 Pesti-Gen，一種基於變異自動編碼器的創新生成模型，旨在首次建立具有最佳化特性的殺蟲劑候選藥劑。具體來說，Pesti-Gen 採用兩階段學習流程：一個擷取廣義化學結構表示的初始預訓練階段，接著是一個納入毒性特定資訊的微調階段。此模型同時針對多種毒性指標進行最佳化，例如 (1) 牲畜毒性和 (2) 水生毒性，以產生對環境友善的殺蟲劑候選藥劑。值得注意的是，Pesti-Gen 在產生新的分子結構方面達到了約 68% 的結構效度，證明了此模型在產生最佳化且可行的殺蟲劑候選藥劑方面的效能，進而為更安全且更永續的蟲害管理解決方案提供了一種新方法。

##### **Interpretability Analysis of Domain Adapted Dense Retrievers**
2501.14459v1 by Goksenin Yuksel, Jaap Kamps

Dense retrievers have demonstrated significant potential for neural
information retrieval; however, they exhibit a lack of robustness to domain
shifts, thereby limiting their efficacy in zero-shot settings across diverse
domains. Previous research has investigated unsupervised domain adaptation
techniques to adapt dense retrievers to target domains. However, these studies
have not focused on explainability analysis to understand how such adaptations
alter the model's behavior. In this paper, we propose utilizing the integrated
gradients framework to develop an interpretability method that provides both
instance-based and ranking-based explanations for dense retrievers. To generate
these explanations, we introduce a novel baseline that reveals both query and
document attributions. This method is used to analyze the effects of domain
adaptation on input attributions for query and document tokens across two
datasets: the financial question answering dataset (FIQA) and the biomedical
information retrieval dataset (TREC-COVID). Our visualizations reveal that
domain-adapted models focus more on in-domain terminology compared to
non-adapted models, exemplified by terms such as "hedge," "gold," "corona," and
"disease." This research addresses how unsupervised domain adaptation
techniques influence the behavior of dense retrievers when adapted to new
domains. Additionally, we demonstrate that integrated gradients are a viable
choice for explaining and analyzing the internal mechanisms of these opaque
neural models.

摘要：密集檢索器已證明在神經資訊檢索方面具有顯著的潛力；然而，它們缺乏對領域轉移的健壯性，從而限制了它們在不同領域的零次學習設置中的效能。先前的研究調查了無監督領域適應技術，以適應密集檢索器以鎖定領域。然而，這些研究並未專注於可解釋性分析，以了解此類適應如何改變模型的行為。在本文中，我們建議利用整合梯度框架來開發一種可解釋性方法，該方法同時為密集檢索器提供基於實例和基於排名的解釋。為了產生這些解釋，我們引入了一個新穎的基準，揭示了查詢和文件歸因。此方法用於分析領域適應對兩個數據集中查詢和文件代碼輸入歸因的影響：財務問題回答數據集 (FIQA) 和生物醫學資訊檢索數據集 (TREC-COVID)。我們的視覺化顯示，與未適應模型相比，領域適應模型更關注於領域內術語，例如「避險」、「黃金」、「冠狀病毒」和「疾病」。這項研究探討了無監督領域適應技術如何影響密集檢索器在適應新領域時的行為。此外，我們證明整合梯度是解釋和分析這些不透明神經模型的內部機制的可行選擇。

##### **Understanding and Mitigating Gender Bias in LLMs via Interpretable Neuron Editing**
2501.14457v1 by Zeping Yu, Sophia Ananiadou

Large language models (LLMs) often exhibit gender bias, posing challenges for
their safe deployment. Existing methods to mitigate bias lack a comprehensive
understanding of its mechanisms or compromise the model's core capabilities. To
address these issues, we propose the CommonWords dataset, to systematically
evaluate gender bias in LLMs. Our analysis reveals pervasive bias across models
and identifies specific neuron circuits, including gender neurons and general
neurons, responsible for this behavior. Notably, editing even a small number of
general neurons can disrupt the model's overall capabilities due to
hierarchical neuron interactions. Based on these insights, we propose an
interpretable neuron editing method that combines logit-based and causal-based
strategies to selectively target biased neurons. Experiments on five LLMs
demonstrate that our method effectively reduces gender bias while preserving
the model's original capabilities, outperforming existing fine-tuning and
editing approaches. Our findings contribute a novel dataset, a detailed
analysis of bias mechanisms, and a practical solution for mitigating gender
bias in LLMs.

摘要：大型語言模型 (LLM) 經常表現出性別偏見，對其安全部署構成挑戰。現有的減輕偏見的方法缺乏對其機制的全面理解，或損害模型的核心能力。為了解決這些問題，我們提出 CommonWords 資料集，以系統性地評估 LLM 中的性別偏見。我們的分析揭示了跨模型的普遍偏見，並識別出特定神經元電路，包括性別神經元和一般神經元，這些神經元對這種行為負責。值得注意的是，由於分層神經元交互作用，即使編輯少數一般神經元也會破壞模型的整體能力。基於這些見解，我們提出了一種可解釋的神經元編輯方法，該方法結合了基於邏輯和基於因果的策略來選擇性地針對有偏見的神經元。對五個 LLM 的實驗表明，我們的模型有效地減少了性別偏見，同時保留了模型的原始能力，優於現有的微調和編輯方法。我們的研究結果提供了一個新的資料集、對偏見機制的詳細分析，以及一種減輕 LLM 中性別偏見的實用解決方案。

##### **Learning more with the same effort: how randomization improves the robustness of a robotic deep reinforcement learning agent**
2501.14443v1 by Lucía Güitta-López, Jaime Boal, Álvaro J. López-López

The industrial application of Deep Reinforcement Learning (DRL) is frequently
slowed down because of the inability to generate the experience required to
train the models. Collecting data often involves considerable time and economic
effort that is unaffordable in most cases. Fortunately, devices like robots can
be trained with synthetic experience thanks to virtual environments. With this
approach, the sample efficiency problems of artificial agents are mitigated,
but another issue arises: the need for efficiently transferring the synthetic
experience into the real world (sim-to-real).
  This paper analyzes the robustness of a state-of-the-art sim-to-real
technique known as progressive neural networks (PNNs) and studies how adding
diversity to the synthetic experience can complement it. To better understand
the drivers that lead to a lack of robustness, the robotic agent is still
tested in a virtual environment to ensure total control on the divergence
between the simulated and real models.
  The results show that a PNN-like agent exhibits a substantial decrease in its
robustness at the beginning of the real training phase. Randomizing certain
variables during simulation-based training significantly mitigates this issue.
On average, the increase in the model's accuracy is around 25% when diversity
is introduced in the training process. This improvement can be translated into
a decrease in the required real experience for the same final robustness
performance. Notwithstanding, adding real experience to agents should still be
beneficial regardless of the quality of the virtual experience fed into the
agent.

摘要：深度強化學習 (DRL) 的產業應用經常因為無法產生訓練模型所需的經驗而進度緩慢。收集資料通常需要大量時間和金錢，在許多情況下負擔不起。幸運的是，機器人等裝置可以透過虛擬環境利用合成經驗進行訓練。這種方法緩解了人工代理的樣本效率問題，但產生了另一個問題：需要有效地將合成經驗轉移到現實世界（模擬到真實）。
本文分析了最先進的模擬到真實技術（稱為漸進式神經網路 (PNN)）的穩健性，並研究如何透過增加合成經驗的多樣性來補充它。為了更深入了解導致缺乏穩健性的驅動因素，機器人代理仍會在虛擬環境中進行測試，以確保對模擬模型和真實模型之間的差異進行完全控制。
結果顯示，類 PNN 代理在真實訓練階段開始時，其穩健性大幅下降。在基於模擬的訓練期間將某些變數隨機化，可顯著緩解此問題。當在訓練過程中引入多樣性時，模型精確度的平均增加幅度約為 25%。此改進可以轉換為在相同的最終穩健性表現下減少所需的真實經驗。儘管如此，無論提供給代理的虛擬經驗品質如何，為代理增加真實經驗仍應是有益的。

##### **Domaino1s: Guiding LLM Reasoning for Explainable Answers in High-Stakes Domains**
2501.14431v1 by Xu Chu, Zhijie Tan, Hanlin Xue, Guanyu Wang, Tong Mo, Weiping Li

Large Language Models (LLMs) are widely applied to downstream domains.
However, current LLMs for high-stakes domain tasks, such as financial
investment and legal QA, typically generate brief answers without reasoning
processes and explanations. This limits users' confidence in making decisions
based on their responses. While original CoT shows promise, it lacks
self-correction mechanisms during reasoning. This work introduces Domain$o1$s,
which enhances LLMs' reasoning capabilities on domain tasks through supervised
fine-tuning and tree search. We construct CoT-stock-2k and CoT-legal-2k
datasets for fine-tuning models that activate domain-specific reasoning steps
based on their judgment. Additionally, we propose Selective Tree Exploration to
spontaneously explore solution spaces and sample optimal reasoning paths to
improve performance. We also introduce PROOF-Score, a new metric for evaluating
domain models' explainability, complementing traditional accuracy metrics with
richer assessment dimensions. Extensive experiments on stock investment
recommendation and legal reasoning QA tasks demonstrate Domaino1s's leading
performance and explainability. Our code is available at
https://anonymous.4open.science/r/Domaino1s-006F/.

摘要：大型語言模型 (LLM) 廣泛應用於下游領域。
然而，目前用於高風險領域任務的 LLM，例如金融投資和法律 QA，通常會產生簡短的答案，而沒有推理過程和解釋。這限制了使用者根據其回應做出決策的信心。儘管原始的 CoT 顯示出前景，但它在推理過程中缺乏自我修正機制。這項工作介紹了 Domain$o1$s，它通過監督微調和樹狀搜尋增強了 LLM 在領域任務上的推理能力。我們構建了 CoT-stock-2k 和 CoT-legal-2k 資料集，用於微調模型，這些模型會根據判斷啟動特定領域的推理步驟。此外，我們提出了選擇性樹狀探索，以自發探索解空間並採樣最佳推理路徑以提高性能。我們還引入了 PROOF-Score，這是一個用於評估領域模型可解釋性的新指標，它使用更豐富的評估維度來補充傳統的準確性指標。在股票投資推薦和法律推理 QA 任務上的廣泛實驗證明了 Domaino1s 的領先性能和可解釋性。我們的程式碼可在 https://anonymous.4open.science/r/Domaino1s-006F/ 取得。

##### **Adaptive Rank Allocation for Federated Parameter-Efficient Fine-Tuning of Language Models**
2501.14406v1 by Fei Wu, Jia Hu, Geyong Min, Shiqiang Wang

Pre-trained Language Models (PLMs) have demonstrated their superiority and
versatility in modern Natural Language Processing (NLP), effectively adapting
to various downstream tasks through further fine-tuning. Federated
Parameter-Efficient Fine-Tuning (FedPEFT) has emerged as a promising solution
to address privacy and efficiency challenges in distributed training for PLMs
on mobile devices. However, our measurements reveal two key limitations of
FedPEFT: heterogeneous data leads to significant performance degradation, and a
fixed parameter configuration results in communication inefficiency. To
overcome these limitations, we propose FedARA, a novel Federated Adaptive Rank
Allocation for parameter-efficient fine-tuning of language models.
Specifically, FedARA employs truncated singular value decomposition (SVD)
adaptation to enhance flexibility and expressiveness, significantly mitigating
the adverse effects of data heterogeneity. Subsequently, it utilizes dynamic
rank allocation to progressively identify critical ranks, effectively improving
communication efficiency. Lastly, it leverages rank-based module pruning to
remove inactive modules, steadily reducing local training time and peak memory
usage in each round. Extensive experiments show that FedARA consistently
outperforms weak baselines by an average of 8.49\% and strong baselines by
6.95\% across various datasets under data heterogeneity while significantly
improving communication efficiency by 2.40\(\times\). Moreover, experiments on
AGX Orin, Orin Nano and Raspberry Pi 5 devices demonstrate substantial
decreases in total training time and energy consumption by up to 48.90\% and
46.95\%, respectively.

摘要：<paragraph>預訓練語言模型 (PLM) 已展現其在現代自然語言處理 (NLP) 中的優越性和多功能性，透過進一步的微調，有效地適應各種下游任務。聯邦參數高效微調 (FedPEFT) 已成為一種有前景的解決方案，用於解決行動裝置上 PLM 分散式訓練的隱私和效率挑戰。然而，我們的測量結果揭示了 FedPEFT 的兩個主要限制：異質資料會導致效能顯著下降，而固定的參數組態會導致通訊效率低下。為了克服這些限制，我們提出 FedARA，一種用於語言模型參數高效微調的新型聯邦自適應秩分配。具體來說，FedARA 採用截斷奇異值分解 (SVD) 適應來增強靈活性與表達力，大幅減輕資料異質性的負面影響。隨後，它利用動態秩分配來逐步識別關鍵秩，有效改善通訊效率。最後，它利用基於秩的模組剪枝來移除非活動模組，在每一輪中穩定的減少區域訓練時間和峰值記憶體使用量。廣泛的實驗顯示，FedARA 在資料異質性下，在各種資料集上，平均優於弱基線 8.49%，優於強基線 6.95%，同時將通訊效率顯著提高了 2.40 倍。此外，在 AGX Orin、Orin Nano 和 Raspberry Pi 5 裝置上進行的實驗證明，總訓練時間和能源消耗分別大幅減少了 48.90% 和 46.95%。</paragraph>

##### **SKIL: Semantic Keypoint Imitation Learning for Generalizable Data-efficient Manipulation**
2501.14400v1 by Shengjie Wang, Jiacheng You, Yihang Hu, Jiongye Li, Yang Gao

Real-world tasks such as garment manipulation and table rearrangement demand
robots to perform generalizable, highly precise, and long-horizon actions.
Although imitation learning has proven to be an effective approach for teaching
robots new skills, large amounts of expert demonstration data are still
indispensible for these complex tasks, resulting in high sample complexity and
costly data collection. To address this, we propose Semantic Keypoint Imitation
Learning (SKIL), a framework which automatically obtain semantic keypoints with
help of vision foundation models, and forms the descriptor of semantic
keypoints that enables effecient imitation learning of complex robotic tasks
with significantly lower sample complexity. In real world experiments, SKIL
doubles the performance of baseline methods in tasks such as picking a cup or
mouse, while demonstrating exceptional robustness to variations in objects,
environmental changes, and distractors. For long-horizon tasks like hanging a
towel on a rack where previous methods fail completely, SKIL achieves a mean
success rate of 70\% with as few as 30 demonstrations. Furthermore, SKIL
naturally supports cross-embodiment learning due to its semantic keypoints
abstraction, our experiments demonstrate that even human videos bring
considerable improvement to the learning performance. All these results
demonstrate the great success of SKIL in achieving data-efficint generalizable
robotic learning. Visualizations and code are available at:
https://skil-robotics.github.io/SKIL-robotics/.

摘要：現實世界的任務，例如服裝操作和桌子重新排列，要求機器人執行可概括、高度精確且長時域的動作。儘管模仿學習已被證明是教導機器人新技能的有效方法，但對於這些複雜任務來說，大量的專家示範數據仍然不可或缺，導致高樣本複雜度和昂貴的數據收集。為了解決這個問題，我們提出了語義關鍵點模仿學習 (SKIL)，一個自動獲取語義關鍵點的框架，借助視覺基礎模型，並形成語義關鍵點的描述符，使複雜機器人任務的有效模仿學習成為可能，且樣本複雜度顯著降低。在真實世界的實驗中，SKIL 在拾取杯子或滑鼠等任務中將基線方法的性能提高了一倍，同時展示了對物體變化、環境變化和干擾因素的非凡魯棒性。對於長時域任務，例如將毛巾掛在架子上，以前的辦法完全失敗，SKIL 以低至 30 次示範實現了 70% 的平均成功率。此外，由於其語義關鍵點抽象，SKIL 自然支援跨具體化學習，我們的實驗表明，即使是人類視頻也能顯著提高學習性能。所有這些結果都證明了 SKIL 在實現資料有效率的可概括機器人學習方面取得了巨大成功。視覺化和程式碼可在以下位置取得：https://skil-robotics.github.io/SKIL-robotics/。

##### **Handling Heterophily in Recommender Systems with Wavelet Hypergraph Diffusion**
2501.14399v1 by Darnbi Sakong, Thanh Tam Nguyen

Recommender systems are pivotal in delivering personalised user experiences
across various domains. However, capturing the heterophily patterns and the
multi-dimensional nature of user-item interactions poses significant
challenges. To address this, we introduce FWHDNN (Fusion-based Wavelet
Hypergraph Diffusion Neural Networks), an innovative framework aimed at
advancing representation learning in hypergraph-based recommendation tasks. The
model incorporates three key components: (1) a cross-difference relation
encoder leveraging heterophily-aware hypergraph diffusion to adapt
message-passing for diverse class labels, (2) a multi-level cluster-wise
encoder employing wavelet transform-based hypergraph neural network layers to
capture multi-scale topological relationships, and (3) an integrated
multi-modal fusion mechanism that combines structural and textual information
through intermediate and late-fusion strategies. Extensive experiments on
real-world datasets demonstrate that FWHDNN surpasses state-of-the-art methods
in accuracy, robustness, and scalability in capturing high-order
interconnections between users and items.

摘要：推薦系統在提供個人化使用者體驗方面至關重要，橫跨各種領域。然而，捕捉異質性模式和使用者與項目互動的多維本質會造成重大的挑戰。為了解決這個問題，我們引進了 FWHDNN（基於融合的波形超圖擴散神經網路），這是一個創新的架構，旨在推動超圖推薦任務中的表徵學習。這個模型包含了三個關鍵組成部分：(1) 跨差異關係編碼器，利用異質性感知超圖擴散來調整訊息傳遞以適應不同的類別標籤，(2) 多層級叢集編碼器，採用基於小波轉換的超圖神經網路層，以捕捉多尺度拓撲關係，以及 (3) 整合多模式融合機制，透過中間融合和後期融合策略，結合結構化和文字資訊。在真實世界資料集上進行的廣泛實驗證明，FWHDNN 在捕捉使用者和項目之間的高階互連方面，超越了最先進的方法，在準確性、穩健性和可擴充性上都有所提升。

##### **ECTIL: Label-efficient Computational Tumour Infiltrating Lymphocyte (TIL) assessment in breast cancer: Multicentre validation in 2,340 patients with breast cancer**
2501.14379v1 by Yoni Schirris, Rosie Voorthuis, Mark Opdam, Marte Liefaard, Gabe S Sonke, Gwen Dackus, Vincent de Jong, Yuwei Wang, Annelot Van Rossum, Tessa G Steenbruggen, Lars C Steggink, Liesbeth G. E. de Vries, Marc van de Vijver, Roberto Salgado, Efstratios Gavves, Paul J van Diest, Sabine C Linn, Jonas Teuwen, Renee Menezes, Marleen Kok, Hugo Horlings

The level of tumour-infiltrating lymphocytes (TILs) is a prognostic factor
for patients with (triple-negative) breast cancer (BC). Computational TIL
assessment (CTA) has the potential to assist pathologists in this
labour-intensive task, but current CTA models rely heavily on many detailed
annotations. We propose and validate a fundamentally simpler deep learning
based CTA that can be trained in only ten minutes on hundredfold fewer
pathologist annotations. We collected whole slide images (WSIs) with TILs
scores and clinical data of 2,340 patients with BC from six cohorts including
three randomised clinical trials. Morphological features were extracted from
whole slide images (WSIs) using a pathology foundation model. Our
label-efficient Computational stromal TIL assessment model (ECTIL) directly
regresses the TILs score from these features. ECTIL trained on only a few
hundred samples (ECTIL-TCGA) showed concordance with the pathologist over five
heterogeneous external cohorts (r=0.54-0.74, AUROC=0.80-0.94). Training on all
slides of five cohorts (ECTIL-combined) improved results on a held-out test set
(r=0.69, AUROC=0.85). Multivariable Cox regression analyses indicated that
every 10% increase of ECTIL scores was associated with improved overall
survival independent of clinicopathological variables (HR 0.86, p<0.01),
similar to the pathologist score (HR 0.87, p<0.001). We demonstrate that ECTIL
is highly concordant with an expert pathologist and obtains a similar hazard
ratio. ECTIL has a fundamentally simpler design than existing methods and can
be trained on orders of magnitude fewer annotations. Such a CTA may be used to
pre-screen patients for, e.g., immunotherapy clinical trial inclusion, or as a
tool to assist clinicians in the diagnostic work-up of patients with BC. Our
model is available under an open source licence
(https://github.com/nki-ai/ectil).

摘要：肿瘤浸润淋巴细胞 (TIL) 的水平是 (三阴性) 乳腺癌 (BC) 患者的预后因素。计算 TIL 评估 (CTA) 有可能协助病理学家完成这项劳动密集型任务，但目前的 CTA 模型严重依赖于许多详细的注释。我们提出并验证了一个基于深度学习的 CTA，它可以在几百倍更少的病理学家注释上仅在十分钟内进行训练。我们从六个队列中收集了 2,340 名 BC 患者的 TILs 评分和临床数据的全玻片图像 (WSI)，其中包括三项随机临床试验。使用病理基础模型从全玻片图像 (WSI) 中提取形态学特征。我们的标签高效计算基质 TIL 评估模型 (ECTIL) 直接从这些特征中回归 TILs 评分。仅在几百个样本上进行训练的 ECTIL（ECTIL-TCGA）显示出与病理学家在五个异质外部队列中的一致性（r=0.54-0.74，AUROC=0.80-0.94）。在五个队列的所有玻片上进行训练（ECTIL-combined）改善了保留测试集上的结果（r=0.69，AUROC=0.85）。多变量 Cox 回归分析表明，ECTIL 评分每增加 10%，与临床病理学变量无关的总体生存率就会提高（HR 0.86，p<0.01），类似于病理学家评分（HR 0.87，p<0.001）。我们证明 ECTIL 与专家病理学家高度一致，并获得了类似的风险比。ECTIL 的设计比现有方法从根本上更简单，并且可以在数量级更少的注释上进行训练。这种 CTA 可用于对患者进行预筛选，例如免疫治疗临床试验纳入，或作为一种工具来帮助临床医生对 BC 患者进行诊断检查。我们的模型可在开放源代码许可下获得 (https://github.com/nki-ai/ectil)。

##### **DRESSing Up LLM: Efficient Stylized Question-Answering via Style Subspace Editing**
2501.14371v1 by Xinyu Ma, Yifeng Xu, Yang Lin, Tianlong Wang, Xu Chu, Xin Gao, Junfeng Zhao, Yasha Wang

We introduce DRESS, a novel approach for generating stylized large language
model (LLM) responses through representation editing. Existing methods like
prompting and fine-tuning are either insufficient for complex style adaptation
or computationally expensive, particularly in tasks like NPC creation or
character role-playing. Our approach leverages the over-parameterized nature of
LLMs to disentangle a style-relevant subspace within the model's representation
space to conduct representation editing, ensuring a minimal impact on the
original semantics. By applying adaptive editing strengths, we dynamically
adjust the steering vectors in the style subspace to maintain both stylistic
fidelity and semantic integrity. We develop two stylized QA benchmark datasets
to validate the effectiveness of DRESS, and the results demonstrate significant
improvements compared to baseline methods such as prompting and ITI. In short,
DRESS is a lightweight, train-free solution for enhancing LLMs with flexible
and effective style control, making it particularly useful for developing
stylized conversational agents. Codes and benchmark datasets are available at
https://github.com/ArthurLeoM/DRESS-LLM.

摘要：我們介紹 DRESS，這是一種透過表徵編輯來產生風格化大型語言模型 (LLM) 回應的新穎方法。提示和微調等現有方法對於複雜的風格適應而言要嘛不足，要嘛計算成本高昂，尤其是在 NPC 建立或角色扮演等任務中。我們的做法利用 LLM 的過度參數化性質，在模型的表徵空間中解開一個與風格相關的子空間，以進行表徵編輯，確保對原始語義的影響最小。透過應用自適應編輯強度，我們動態調整風格子空間中的引導向量，以維持風格保真度和語義完整性。我們開發了兩個風格化的問答基準資料集，以驗證 DRESS 的有效性，結果顯示與提示和 ITI 等基準方法相比有顯著的改進。簡而言之，DRESS 是一種輕量級、免訓練的解決方案，可用於增強 LLM，具備靈活且有效的風格控制，使其特別適用於開發風格化的對話代理。程式碼和基準資料集可在 https://github.com/ArthurLeoM/DRESS-LLM 取得。

##### **In System Alignments we Trust! Explainable Alignments via Projections**
2501.14360v1 by Dominique Sommers, Natalia Sidorova, Boudewijn van Dongen

Alignments are a well-known process mining technique for reconciling system
logs and normative process models. Evidence of certain behaviors in a real
system may only be present in one representation - either a log or a model -
but not in the other. Since for processes in which multiple entities, like
objects and resources, are involved in the activities, their interactions
affect the behavior and are therefore essential to take into account in the
alignments.
  Additionally, both logged and modeled representations of reality may be
imprecise and only partially represent some of these entities, but not all. In
this paper, we introduce the concept of "relaxations" through projections for
alignments to deal with partially correct models and logs. Relaxed alignments
help to distinguish between trustworthy and untrustworthy content of the two
representations (the log and the model) to achieve a better understanding of
the underlying process and expose quality issues.

摘要：對齊是調和系統紀錄和規範流程模型的知名流程探勘技術。在真實系統中特定行為的證據可能只存在於一個表示法（可能是紀錄或模型），而不在另一個表示法中。由於在流程中，多個實體（例如物件和資源）會參與活動，因此它們的互動會影響行為，因此在對齊時必須將它們納入考量。
此外，現實的記錄和模型表示法都可能不精確，而且可能只部分表示這些實體中的一些，而不是全部。在本文中，我們透過投影引入了「放鬆」的概念，以處理部分正確的模型和紀錄的對齊。放鬆對齊有助於區分兩個表示法（紀錄和模型）中值得信賴和不可信賴的內容，以更好地理解基礎流程並揭露品質問題。

##### **HorNets: Learning from Discrete and Continuous Signals with Routing Neural Networks**
2501.14346v1 by Boshko koloski, Nada Lavrač, Blaž Škrlj

Construction of neural network architectures suitable for learning from both
continuous and discrete tabular data is a challenging research endeavor.
Contemporary high-dimensional tabular data sets are often characterized by a
relatively small instance count, requiring data-efficient learning. We propose
HorNets (Horn Networks), a neural network architecture with state-of-the-art
performance on synthetic and real-life data sets from scarce-data tabular
domains. HorNets are based on a clipped polynomial-like activation function,
extended by a custom discrete-continuous routing mechanism that decides which
part of the neural network to optimize based on the input's cardinality. By
explicitly modeling parts of the feature combination space or combining whole
space in a linear attention-like manner, HorNets dynamically decide which mode
of operation is the most suitable for a given piece of data with no explicit
supervision. This architecture is one of the few approaches that reliably
retrieves logical clauses (including noisy XNOR) and achieves state-of-the-art
classification performance on 14 real-life biomedical high-dimensional data
sets. HorNets are made freely available under a permissive license alongside a
synthetic generator of categorical benchmarks.

摘要：構建適合從連續和離散表格資料學習的神經網路架構是一項具有挑戰性的研究工作。
當代高維度表格資料集通常的特徵是實例數量相對較少，需要資料有效學習。我們提出 HorNets（霍恩網路），一種在稀疏資料表格領域的合成和真實資料集上具有最先進效能的神經網路架構。HorNets 基於一個裁剪的多項式類激活函數，並由一個自訂離散連續路由機制擴充，該機制根據輸入的基數來決定要優化神經網路的哪一部分。透過明確建模特徵組合空間的一部分或以線性注意力類的方式組合整個空間，HorNets 動態決定哪種運作模式最適合給定的資料部分，而不需要明確監督。這種架構是少數可靠擷取邏輯子句（包括雜訊 XNOR）的方法之一，並在 14 個真實生物醫學高維度資料集上達成最先進的分類效能。HorNets 在寬鬆許可證下免費提供，並附有一個類別基準的合成產生器。

##### **Chain-of-Retrieval Augmented Generation**
2501.14342v1 by Liang Wang, Haonan Chen, Nan Yang, Xiaolong Huang, Zhicheng Dou, Furu Wei

This paper introduces an approach for training o1-like RAG models that
retrieve and reason over relevant information step by step before generating
the final answer. Conventional RAG methods usually perform a single retrieval
step before the generation process, which limits their effectiveness in
addressing complex queries due to imperfect retrieval results. In contrast, our
proposed method, CoRAG (Chain-of-Retrieval Augmented Generation), allows the
model to dynamically reformulate the query based on the evolving state. To
train CoRAG effectively, we utilize rejection sampling to automatically
generate intermediate retrieval chains, thereby augmenting existing RAG
datasets that only provide the correct final answer. At test time, we propose
various decoding strategies to scale the model's test-time compute by
controlling the length and number of sampled retrieval chains. Experimental
results across multiple benchmarks validate the efficacy of CoRAG, particularly
in multi-hop question answering tasks, where we observe more than 10 points
improvement in EM score compared to strong baselines. On the KILT benchmark,
CoRAG establishes a new state-of-the-art performance across a diverse range of
knowledge-intensive tasks. Furthermore, we offer comprehensive analyses to
understand the scaling behavior of CoRAG, laying the groundwork for future
research aimed at developing factual and grounded foundation models.

摘要：本文介紹一種訓練類似 o1 的 RAG 模型的方法，該模型在產生最終答案之前，會逐步擷取並推理相關資訊。傳統的 RAG 方法通常在產生過程之前執行單一擷取步驟，這會限制它們在處理複雜查詢時的有效性，因為擷取結果不完美。相反，我們提出的方法 CoRAG（擷取增強生成鏈）允許模型根據演化狀態動態重新表述查詢。為了有效訓練 CoRAG，我們利用拒絕抽樣自動產生中間擷取鏈，從而擴充現有的 RAG 資料集，這些資料集只提供正確的最終答案。在測試時，我們提出各種解碼策略，透過控制抽樣擷取鏈的長度和數量來擴充模型的測試時間運算。在多個基準測試中的實驗結果驗證了 CoRAG 的效能，特別是在多跳式問答任務中，我們觀察到 EM 分數比強大的基線改進了 10 分以上。在 KILT 基準測試中，CoRAG 在各種知識密集型任務中建立了新的最先進效能。此外，我們提供全面的分析來了解 CoRAG 的擴充行為，為未來旨在開發事實和基礎基礎模型的研究奠定基礎。

##### **Exploring the sustainable scaling of AI dilemma: A projective study of corporations' AI environmental impacts**
2501.14334v1 by Clément Desroches, Martin Chauvin, Louis Ladan, Caroline Vateau, Simon Gosset, Philippe Cordier

The rapid growth of artificial intelligence (AI), particularly Large Language
Models (LLMs), has raised concerns regarding its global environmental impact
that extends beyond greenhouse gas emissions to include consideration of
hardware fabrication and end-of-life processes. The opacity from major
providers hinders companies' abilities to evaluate their AI-related
environmental impacts and achieve net-zero targets.In this paper, we propose a
methodology to estimate the environmental impact of a company's AI portfolio,
providing actionable insights without necessitating extensive AI and Life-Cycle
Assessment (LCA) expertise. Results confirm that large generative AI models
consume up to 4600x more energy than traditional models. Our modelling
approach, which accounts for increased AI usage, hardware computing efficiency,
and changes in electricity mix in line with IPCC scenarios, forecasts AI
electricity use up to 2030. Under a high adoption scenario, driven by
widespread Generative AI and agents adoption associated to increasingly complex
models and frameworks, AI electricity use is projected to rise by a factor of
24.4.Mitigating the environmental impact of Generative AI by 2030 requires
coordinated efforts across the AI value chain. Isolated measures in hardware
efficiency, model efficiency, or grid improvements alone are insufficient. We
advocate for standardized environmental assessment frameworks, greater
transparency from the all actors of the value chain and the introduction of a
"Return on Environment" metric to align AI development with net-zero goals.

摘要：人工智慧（AI），特別是大型語言模型（LLM）的快速發展，引發了對其全球環境影響的擔憂，其影響範圍不僅限於溫室氣體排放，還包括對硬體製造和報廢流程的考量。主要供應商的不透明性阻礙了公司評估其 AI 相關環境影響並實現淨零目標的能力。在本文中，我們提出了一種方法，用於估計公司 AI 組合的環境影響，提供可行的見解，而無需大量的 AI 和生命週期評估 (LCA) 專業知識。結果證實，大型生成式 AI 模型消耗的能源比傳統模型多達 4600 倍。我們的建模方法考慮了 AI 使用量的增加、硬體運算效率以及與 IPCC 情境一致的電力結構變化，預測了 AI 的電力使用量至 2030 年。在高採用率情境下，受廣泛採用的生成式 AI 和代理人採用所驅動，這些代理人與日益複雜的模型和架構相關，預計 AI 電力使用量將增加 24.4 倍。到 2030 年減輕生成式 AI 的環境影響需要在整個 AI 價值鏈中協調努力。單靠硬體效率、模型效率或電網改善等孤立措施是不夠的。我們提倡標準化的環境評估框架、價值鏈中所有參與者的更大透明度，以及引入「環境投資報酬率」指標，以使 AI 開發與淨零目標保持一致。

##### **Clear Minds Think Alike: What Makes LLM Fine-tuning Robust? A Study of Token Perplexity**
2501.14315v1 by Chao-Chung Wu, Zhi Rui Tam, Chieh-Yen Lin, Hung-yi Lee, Yun-Nung Chen

Maintaining consistent model performance across domains is a fundamental
challenge in machine learning. While recent work has explored using
LLM-generated data for fine-tuning, its impact on cross-domain generalization
remains poorly understood. In this paper, we present a systematic analysis
revealing that fine-tuning with LLM-generated data not only improves target
task performance but also reduces out-of-domain (OOD) degradation compared to
fine-tuning with ground truth data. Through analyzing the data sequence in
tasks of various domains, we demonstrate that this enhanced OOD robustness
stems from a reduced prevalence of high perplexity tokens in LLM-generated
sequences. Following this hypothesis we showed that masking high perplexity
tokens in ground truth training data also achieves similar OOD preservation
comparable to using LLM-generated data. Extensive experiments across diverse
model architectures and scales, including Gemma2-2B, Mistral-7B and Llama3-8B,
corroborate the consistency of our findings. To the best of our knowledge, this
work provides the first mechanistic explanation for the superior OOD robustness
conferred by LLM-generated training data, offering valuable insights for
developing more robust fine-tuning strategies.

摘要：在機器學習中，維持模型在不同領域中的一致效能是一項基本的挑戰。雖然最近的研究探討了使用 LLM 生成的資料進行微調，但它對跨領域泛化的影響仍然知之甚少。在本文中，我們提出一個系統性的分析，揭示使用 LLM 生成的資料進行微調不僅可以改善目標任務的效能，而且與使用真實資料進行微調相比，還能減少領域外 (OOD) 的退化。透過分析不同領域任務中的資料序列，我們證明了這種增強的 OOD 穩健性源於 LLM 生成的序列中高困惑度標記的發生率降低。根據這個假設，我們表明在真實訓練資料中遮蔽高困惑度標記也可以實現與使用 LLM 生成的資料相似的 OOD 保留。在包括 Gemma2-2B、Mistral-7B 和 Llama3-8B 在內的各種模型架構和規模中進行的廣泛實驗，證實了我們發現的一致性。據我們所知，這項工作首次提供了 LLM 生成的訓練資料賦予的優異 OOD 穩健性的機制解釋，為開發更穩健的微調策略提供了寶貴的見解。

##### **Permutation-based multi-objective evolutionary feature selection for high-dimensional data**
2501.14310v1 by Raquel Espinosa, Gracia Sánchez, José Palma, Fernando Jiménez

Feature selection is a critical step in the analysis of high-dimensional
data, where the number of features often vastly exceeds the number of samples.
Effective feature selection not only improves model performance and
interpretability but also reduces computational costs and mitigates the risk of
overfitting. In this context, we propose a novel feature selection method for
high-dimensional data, based on the well-known permutation feature importance
approach, but extending it to evaluate subsets of attributes rather than
individual features. This extension more effectively captures how interactions
among features influence model performance. The proposed method employs a
multi-objective evolutionary algorithm to search for candidate feature subsets,
with the objectives of maximizing the degradation in model performance when the
selected features are shuffled, and minimizing the cardinality of the feature
subset. The effectiveness of our method has been validated on a set of 24
publicly available high-dimensional datasets for classification and regression
tasks, and compared against 9 well-established feature selection methods
designed for high-dimensional problems, including the conventional permutation
feature importance method. The results demonstrate the ability of our approach
in balancing accuracy and computational efficiency, providing a powerful tool
for feature selection in complex, high-dimensional datasets.

摘要：特徵選擇是高維度資料分析中的一個關鍵步驟，其中特徵數目通常遠遠超過樣本數目。有效的特徵選擇不僅可以提升模型效能和可解釋性，還能降低運算成本並減輕過度擬合的風險。在此脈絡中，我們提出一個針對高維度資料的新穎特徵選擇方法，它基於著名的置換特徵重要性方法，但將其擴展為評估屬性子集，而非個別特徵。此擴展更有效地捕捉特徵之間的互動如何影響模型效能。所提出的方法採用多目標演化演算法來搜尋候選特徵子集，目標為最大化模型效能的下降程度（當所選特徵被洗牌時），並最小化特徵子集的基數。我們的方法的有效性已在 24 個公開的高維度資料集上獲得驗證，這些資料集適用於分類和回歸任務，並與 9 種針對高維度問題設計的、完善的特徵選擇方法進行比較，包括傳統的置換特徵重要性方法。結果證明了我們的方法在平衡準確性和運算效率方面的能力，為複雜、高維度資料集中的特徵選擇提供了一個強大的工具。

##### **Learning Primitive Relations for Compositional Zero-Shot Learning**
2501.14308v1 by Insu Lee, Jiseob Kim, Kyuhong Shim, Byonghyo Shim

Compositional Zero-Shot Learning (CZSL) aims to identify unseen state-object
compositions by leveraging knowledge learned from seen compositions. Existing
approaches often independently predict states and objects, overlooking their
relationships. In this paper, we propose a novel framework, learning primitive
relations (LPR), designed to probabilistically capture the relationships
between states and objects. By employing the cross-attention mechanism, LPR
considers the dependencies between states and objects, enabling the model to
infer the likelihood of unseen compositions. Experimental results demonstrate
that LPR outperforms state-of-the-art methods on all three CZSL benchmark
datasets in both closed-world and open-world settings. Through qualitative
analysis, we show that LPR leverages state-object relationships for unseen
composition prediction.

摘要：組合零樣本學習 (CZSL) 旨在透過運用從已見組合中學習到的知識來識別未見的狀態-物件組合。現有方法通常獨立預測狀態和物件，忽略它們之間的關係。在本文中，我們提出一個新穎的架構，學習原始關係 (LPR)，旨在以機率方式捕捉狀態和物件之間的關係。透過採用交叉注意力機制，LPR 考慮狀態和物件之間的依賴關係，使模型能夠推論未見組合的可能性。實驗結果證明，在封閉世界和開放世界設定中，LPR 在所有三個 CZSL 基準資料集上都優於最先進的方法。透過定性分析，我們展示 LPR 利用狀態-物件關係進行未見組合預測。

##### **A Zero-Shot LLM Framework for Automatic Assignment Grading in Higher Education**
2501.14305v1 by Calvin Yeung, Jeff Yu, King Chau Cheung, Tat Wing Wong, Chun Man Chan, Kin Chi Wong, Keisuke Fujii

Automated grading has become an essential tool in education technology due to
its ability to efficiently assess large volumes of student work, provide
consistent and unbiased evaluations, and deliver immediate feedback to enhance
learning. However, current systems face significant limitations, including the
need for large datasets in few-shot learning methods, a lack of personalized
and actionable feedback, and an overemphasis on benchmark performance rather
than student experience. To address these challenges, we propose a Zero-Shot
Large Language Model (LLM)-Based Automated Assignment Grading (AAG) system.
This framework leverages prompt engineering to evaluate both computational and
explanatory student responses without requiring additional training or
fine-tuning. The AAG system delivers tailored feedback that highlights
individual strengths and areas for improvement, thereby enhancing student
learning outcomes. Our study demonstrates the system's effectiveness through
comprehensive evaluations, including survey responses from higher education
students that indicate significant improvements in motivation, understanding,
and preparedness compared to traditional grading methods. The results validate
the AAG system's potential to transform educational assessment by prioritizing
learning experiences and providing scalable, high-quality feedback.

摘要：自動評分已成為教育技術中不可或缺的工具，因為它能有效評量大量的學生作業、提供一致且公正的評量，並提供立即回饋以增進學習。然而，目前的系統面臨嚴重的限制，包括少樣本學習方法中需要大量的資料集、缺乏個人化且可行的回饋，以及過度重視基準表現而非學生體驗。為了應對這些挑戰，我們提出了一個基於零樣本大型語言模型 (LLM) 的自動作業評分 (AAG) 系統。此架構利用提示工程來評量計算和說明性的學生回應，而不需要額外的訓練或微調。AAG 系統提供客製化的回饋，強調個人的優勢和需要改進的地方，從而增進學生的學習成果。我們的研究透過全面的評量來展示系統的有效性，包括來自高等教育學生的問卷調查回應，這些回應顯示與傳統評分方法相比，動機、理解力和準備度都有顯著的進步。結果驗證了 AAG 系統透過優先考慮學習體驗和提供可擴充、高品質的回饋，轉型教育評量的潛力。

##### **MASTER: A Multi-Agent System with LLM Specialized MCTS**
2501.14304v1 by Bingzheng Gan, Yufan Zhao, Tianyi Zhang, Jing Huang, Yusu Li, Shu Xian Teo, Changwang Zhang, Wei Shi

Large Language Models (LLM) are increasingly being explored for
problem-solving tasks. However, their strategic planning capability is often
viewed with skepticism. Recent studies have incorporated the Monte Carlo Tree
Search (MCTS) algorithm to augment the planning capacity of LLM. Despite its
potential, MCTS relies on extensive sampling simulations to approximate the
true reward distribution, leading to two primary issues. Firstly, MCTS is
effective for tasks like the Game of Go, where simulation results can yield
objective rewards (e.g., 1 for a win and 0 for a loss). However, for tasks such
as question answering, the result of a simulation is the answer to the
question, which cannot obtain an objective reward without the ground truth.
Secondly, obtaining statistically significant reward estimations typically
requires a sample size exceeding 30 simulations, resulting in excessive token
usage and time consumption. To address these challenges, we present Multi-Agent
System with Tactical Execution and Reasoning using LLM Specialized MCTS
(MASTER), a novel framework that coordinates agent recruitment and
communication using LLM specialized MCTS. This system autonomously adjusts the
number of agents based on task complexity and ensures focused communication
among them. Comprehensive experiments across various tasks demonstrate the
effectiveness of our proposed framework. It achieves 76% accuracy on HotpotQA
and 80% on WebShop, setting new state-of-the-art performance on these datasets.

摘要：大型語言模型 (LLM) 正越來越常被用於解決問題的任務中。然而，它們的策略規劃能力常常受到質疑。最近的研究已整合蒙地卡羅樹搜尋 (MCTS) 演算法來擴增 LLM 的規劃能力。儘管有其潛力，MCTS 依賴大量的抽樣模擬來近似真實的回饋分佈，導致兩個主要問題。首先，MCTS 適用於圍棋等任務，其中模擬結果可以產生客觀的回饋（例如，贏得比賽為 1，輸掉比賽為 0）。然而，對於問答等任務，模擬的結果是問題的答案，而答案在沒有正解的情況下無法獲得客觀的回饋。其次，要獲得具有統計意義的回饋估計值，通常需要超過 30 次模擬的樣本大小，這會導致過度使用權杖和浪費時間。為了應對這些挑戰，我們提出使用 LLM 專用 MCTS 的多代理系統，具備戰術執行和推理 (MASTER)，這是一個協調代理招募和使用 LLM 專用 MCTS 進行溝通的新架構。這個系統會根據任務的複雜性自動調整代理數量，並確保它們之間的溝通專注。跨各種任務的綜合實驗證明了我們提出的架構的有效性。它在 HotpotQA 上達到了 76% 的準確度，在 WebShop 上達到了 80%，在這些資料集上創下了新的最先進效能。

##### **Fast Think-on-Graph: Wider, Deeper and Faster Reasoning of Large Language Model on Knowledge Graph**
2501.14300v1 by Xujian Liang, Zhaoquan Gu

Graph Retrieval Augmented Generation (GRAG) is a novel paradigm that takes
the naive RAG system a step further by integrating graph information, such as
knowledge graph (KGs), into large-scale language models (LLMs) to mitigate
hallucination. However, existing GRAG still encounter limitations: 1) simple
paradigms usually fail with the complex problems due to the narrow and shallow
correlations capture from KGs 2) methods of strong coupling with KGs tend to be
high computation cost and time consuming if the graph is dense. In this paper,
we propose the Fast Think-on-Graph (FastToG), an innovative paradigm for
enabling LLMs to think ``community by community" within KGs. To do this,
FastToG employs community detection for deeper correlation capture and two
stages community pruning - coarse and fine pruning for faster retrieval.
Furthermore, we also develop two Community-to-Text methods to convert the graph
structure of communities into textual form for better understanding by LLMs.
Experimental results demonstrate the effectiveness of FastToG, showcasing
higher accuracy, faster reasoning, and better explainability compared to the
previous works.

摘要：圖表檢索增強生成 (GRAG) 是一種新穎的範例，它透過將圖表資訊（例如知識圖表 (KG)) 整合到大型語言模型 (LLM) 中，進一步提升了樸素的 RAG 系統以減輕幻覺。然而，現有的 GRAG 仍會遇到限制：1) 簡單的範例通常會因從 KG 中擷取的關聯性狹隘且淺薄而無法解決複雜的問題 2) 如果圖表很密集，與 KG 強耦合的方法往往會導致高運算成本和耗時。在本文中，我們提出了 Fast Think-on-Graph (FastToG)，這是一種創新的範例，可讓 LLM 在 KG 中「逐個社群」進行思考。為此，FastToG 使用社群偵測來擷取更深入的關聯性，並使用兩個階段的社群修剪（粗略修剪和精細修剪）來加快檢索速度。此外，我們還開發了兩種社群到文字的方法，將社群的圖表結構轉換為文字形式，以便 LLM 更容易理解。實驗結果證明了 FastToG 的有效性，與先前的研究相比，展示出更高的準確性、更快的推理速度和更好的可解釋性。

##### **Examining Alignment of Large Language Models through Representative Heuristics: The Case of Political Stereotypes**
2501.14294v1 by Sullam Jeoung, Yubin Ge, Haohan Wang, Jana Diesner

Examining the alignment of large language models (LLMs) has become
increasingly important, particularly when these systems fail to operate as
intended. This study explores the challenge of aligning LLMs with human
intentions and values, with specific focus on their political inclinations.
Previous research has highlighted LLMs' propensity to display political
leanings, and their ability to mimic certain political parties' stances on
various issues. However, the extent and conditions under which LLMs deviate
from empirical positions have not been thoroughly examined. To address this
gap, our study systematically investigates the factors contributing to LLMs'
deviations from empirical positions on political issues, aiming to quantify
these deviations and identify the conditions that cause them.
  Drawing on cognitive science findings related to representativeness
heuristics -- where individuals readily recall the representative attribute of
a target group in a way that leads to exaggerated beliefs -- we scrutinize LLM
responses through this heuristics lens. We conduct experiments to determine how
LLMs exhibit stereotypes by inflating judgments in favor of specific political
parties. Our results indicate that while LLMs can mimic certain political
parties' positions, they often exaggerate these positions more than human
respondents do. Notably, LLMs tend to overemphasize representativeness to a
greater extent than humans. This study highlights the susceptibility of LLMs to
representativeness heuristics, suggeseting potential vulnerabilities to
political stereotypes. We propose prompt-based mitigation strategies that
demonstrate effectiveness in reducing the influence of representativeness in
LLM responses.

摘要：<paragraph>檢視大型語言模型（LLM）的對齊方式變得越來越重要，特別是在這些系統無法按預期運作時。本研究探討了將 LLM 與人類意圖和價值觀對齊的挑戰，特別關注其政治傾向。先前的研究強調了 LLM 顯示政治傾向的傾向，以及它們模擬某些政黨對各種問題的立場的能力。然而，LLM 偏離經驗立場的程度和條件尚未得到徹底檢驗。為了解決這個差距，我們的研究系統地調查了導致 LLM 在政治問題上偏離經驗立場的因素，旨在量化這些偏差並找出導致它們的條件。
根據與代表性啟發法相關的認知科學發現——個人容易以導致誇大信念的方式回憶目標群體的代表性屬性——我們透過此啟發法透鏡仔細審查 LLM 回應。我們進行實驗以確定 LLM 如何通過誇大對特定政黨有利的判斷來表現刻板印象。我們的結果表明，雖然 LLM 可以模擬某些政黨的立場，但它們通常比人類受訪者更誇大這些立場。值得注意的是，LLM 往往比人類更強調代表性。本研究強調了 LLM 對代表性啟發法的敏感性，表明對政治刻板印象的潛在脆弱性。我們提出了基於提示的緩解策略，證明了在減少代表性對 LLM 回應的影響方面有效。</paragraph>

##### **A Comprehensive Framework for Semantic Similarity Detection Using Transformer Architectures and Enhanced Ensemble Techniques**
2501.14288v1 by Lifu Gao, Qi Zhang, Ziwei Liu

Detecting AI-generated text, especially in short-context documents, is
difficult because there is not enough context for accurate classification. This
paper presents a new teacher-student model that uses domain adaptation and data
augmentation to solve these problems. The teacher model, which combines
DeBERTa-v3-large and Mamba-790m, learns semantic knowledge through
domain-specific fine-tuning. The student model handles short-context text more
efficiently. The system uses a Mean Squared Error (MSE) loss function to guide
the student's learning, improving both accuracy and efficiency. Also, data
augmentation methods like spelling correction and error injection make the
model more robust. Experimental results show that this approach works better
than baseline methods, proving its usefulness for real-time AI-generated text
detection and other text classification tasks.

摘要：偵測 AI 生成的文字，特別是在短語境文件中，很困難，因為沒有足夠的語境可以進行精確的分類。這篇論文提出了一個新的師生模型，它使用領域適應和資料擴充來解決這些問題。教師模型結合了 DeBERTa-v3-large 和 Mamba-790m，透過特定領域的微調來學習語義知識。學生模型更有效率地處理短語境文字。系統使用均方誤差 (MSE) 損失函數來引導學生的學習，同時提升準確性和效率。此外，拼寫校正和錯誤注入等資料擴充方法讓模型更強健。實驗結果顯示，此方法比基準方法表現得更好，證明了它在即時 AI 生成的文字偵測和其他文字分類任務中的效用。

##### **Global Semantic-Guided Sub-image Feature Weight Allocation in High-Resolution Large Vision-Language Models**
2501.14276v1 by Yuxuan Liang, Xu Li, Xiaolei Chen, Haotian Chen, Yi Zheng, Chenghang Lai, Bin Li, Xiangyang Xue

As the demand for high-resolution image processing in Large Vision-Language
Models (LVLMs) grows, sub-image partitioning has become a popular approach for
mitigating visual information loss associated with fixed-resolution processing.
However, existing partitioning methods uniformly process sub-images, resulting
in suboptimal image understanding. In this work, we reveal that the sub-images
with higher semantic relevance to the entire image encapsulate richer visual
information for preserving the model's visual understanding ability. Therefore,
we propose the Global Semantic-guided Weight Allocator (GSWA) module, which
dynamically allocates weights to sub-images based on their relative information
density, emulating human visual attention mechanisms. This approach enables the
model to focus on more informative regions, overcoming the limitations of
uniform treatment. We integrate GSWA into the InternVL2-2B framework to create
SleighVL, a lightweight yet high-performing model. Extensive experiments
demonstrate that SleighVL outperforms models with comparable parameters and
remains competitive with larger models. Our work provides a promising direction
for more efficient and contextually aware high-resolution image processing in
LVLMs, advancing multimodal system development.

摘要：随着大型视觉语言模型 (LVLMs) 中对高分辨率图像处理的需求不断增长，子图像分区已成为缓解与固定分辨率处理相关的视觉信息丢失的流行方法。然而，现有的分区方法统一处理子图像，导致子图像理解不佳。在这项工作中，我们揭示了与整个图像具有较高语义相关性的子图像封装了更丰富的视觉信息，以保留模型的视觉理解能力。因此，我们提出了全局语义引导权重分配器 (GSWA) 模块，该模块根据子图像的相对信息密度动态分配权重，模拟人类视觉注意力机制。这种方法使模型能够专注于更多信息丰富的区域，克服了统一处理的局限性。我们将 GSWA 集成到 InternVL2-2B 框架中以创建 SleighVL，这是一种轻量级但高性能的模型。大量实验表明，SleighVL 优于具有可比参数的模型，并且与更大模型保持竞争力。我们的工作为 LVLMs 中更高效且具有上下文感知能力的高分辨率图像处理提供了一个有希望的方向，从而促进了多模态系统开发。

##### **Leveraging Online Olympiad-Level Math Problems for LLMs Training and Contamination-Resistant Evaluation**
2501.14275v1 by Sadegh Mahdavi, Muchen Li, Kaiwen Liu, Christos Thrampoulidis, Leonid Sigal, Renjie Liao

Advances in Large Language Models (LLMs) have sparked interest in their
ability to solve Olympiad-level math problems. However, the training and
evaluation of these models are constrained by the limited size and quality of
available datasets, as creating large-scale data for such advanced problems
requires extensive effort from human experts. In addition, current benchmarks
are prone to contamination, leading to unreliable evaluations. In this paper,
we present an automated pipeline that leverages the rich resources of the Art
of Problem Solving (AoPS) forum, which predominantly features Olympiad-level
problems and community-driven solutions. Using open-source LLMs, we develop a
method to extract question-answer pairs from the forum, resulting in
AoPS-Instruct, a dataset of more than 600,000 high-quality QA pairs. Our
experiments demonstrate that fine-tuning LLMs on AoPS-Instruct improves their
reasoning abilities across various benchmarks. Moreover, we build an automatic
pipeline that introduces LiveAoPSBench, an evolving evaluation set with
timestamps, derived from the latest forum data, providing a
contamination-resistant benchmark for assessing LLM performance. Notably, we
observe a significant decline in LLM performance over time, suggesting their
success on older examples may stem from pre-training exposure rather than true
reasoning ability. Our work presents a scalable approach to creating and
maintaining large-scale, high-quality datasets for advanced math reasoning,
offering valuable insights into the capabilities and limitations of LLMs in
this domain. Our benchmark and code is available at
https://github.com/DSL-Lab/aops

摘要：大型語言模型 (LLM) 的進步激發了人們對其解決奧林匹克數學問題能力的興趣。然而，這些模型的訓練和評估受到可用數據集規模和品質的限制，因為為這類進階問題建立大規模數據需要人類專家的廣泛努力。此外，目前的基準容易受到汙染，導致評估不可靠。在本文中，我們提出了一個自動化管道，利用了問題解決的藝術 (AoPS) 論壇的豐富資源，該論壇主要以奧林匹克程度的問題和社群驅動的解決方案為特色。使用開源 LLM，我們開發了一種從論壇中萃取問答配對的方法，產生了 AoPS-Instruct，一個包含超過 600,000 個高品質 QA 配對的數據集。我們的實驗證明，在 AoPS-Instruct 上微調 LLM 能夠提升其在各種基準上的推理能力。此外，我們建立了一個自動化管道，引入了 LiveAoPSBench，一個從最新論壇數據衍生的、帶有時間戳記的演化評估集，提供了一個抗汙染的基準來評估 LLM 效能。值得注意的是，我們觀察到 LLM 效能隨著時間推移而顯著下降，這表明它們在較舊範例上的成功可能源於預訓練曝光，而不是真正的推理能力。我們的研究提出了一個可擴展的方法來建立和維護用於進階數學推理的大規模、高品質數據集，提供了關於 LLM 在此領域中能力和限制的寶貴見解。我們的基準和程式碼可以在 https://github.com/DSL-Lab/aops 取得

##### **Hierarchical Time-Aware Mixture of Experts for Multi-Modal Sequential Recommendation**
2501.14269v1 by Shengzhe Zhang, Liyi Chen, Dazhong Shen, Chao Wang, Hui Xiong

Multi-modal sequential recommendation (SR) leverages multi-modal data to
learn more comprehensive item features and user preferences than traditional SR
methods, which has become a critical topic in both academia and industry.
Existing methods typically focus on enhancing multi-modal information utility
through adaptive modality fusion to capture the evolving of user preference
from user-item interaction sequences. However, most of them overlook the
interference caused by redundant interest-irrelevant information contained in
rich multi-modal data. Additionally, they primarily rely on implicit temporal
information based solely on chronological ordering, neglecting explicit
temporal signals that could more effectively represent dynamic user interest
over time. To address these limitations, we propose a Hierarchical time-aware
Mixture of experts for multi-modal Sequential Recommendation (HM4SR) with a
two-level Mixture of Experts (MoE) and a multi-task learning strategy.
Specifically, the first MoE, named Interactive MoE, extracts essential user
interest-related information from the multi-modal data of each item. Then, the
second MoE, termed Temporal MoE, captures user dynamic interests by introducing
explicit temporal embeddings from timestamps in modality encoding. To further
address data sparsity, we propose three auxiliary supervision tasks:
sequence-level category prediction (CP) for item feature understanding,
contrastive learning on ID (IDCL) to align sequence context with user
interests, and placeholder contrastive learning (PCL) to integrate temporal
information with modalities for dynamic interest modeling. Extensive
experiments on four public datasets verify the effectiveness of HM4SR compared
to several state-of-the-art approaches.

摘要：多模态顺序推荐（SR）利用多模态数据来学习比传统 SR 方法更全面的项目特征和用户偏好，这已成为学术界和工业界的关键课题。现有方法通常专注于通过自适应模态融合来增强多模态信息效用，以从用户-项目交互序列中捕捉用户偏好的演变。然而，大多数方法忽略了丰富多模态数据中包含的冗余与兴趣无关的信息所造成的干扰。此外，它们主要依赖于仅基于时间顺序的隐式时间信息，而忽略了可以更有效地表示动态用户兴趣的显式时间信号。为了解决这些限制，我们提出了一种具有两级专家混合（MoE）和多任务学习策略的分层时间感知专家混合用于多模态顺序推荐（HM4SR）。具体来说，第一个 MoE，称为交互式 MoE，从每个项目的模态数据中提取基本的与用户兴趣相关的信息。然后，第二个 MoE，称为时间 MoE，通过在模态编码中引入时间戳的显式时间嵌入来捕捉用户动态兴趣。为了进一步解决数据稀疏性，我们提出了三个辅助监督任务：用于项目特征理解的序列级类别预测（CP）、用于将序列上下文与用户兴趣对齐的 ID 对比学习（IDCL），以及用于将时间信息与模态整合以进行动态兴趣建模的占位符对比学习（PCL）。在四个公开数据集上的广泛实验验证了 HM4SR 与几种最先进方法相比的有效性。

##### **Pre-train and Fine-tune: Recommenders as Large Models**
2501.14268v1 by Zhenhao Jiang, Chenghao Chen, Hao Feng, Yu Yang, Jin Liu, Jie Zhang, Jia Jia, Ning Hu

In reality, users have different interests in different periods, regions,
scenes, etc. Such changes in interest are so drastic that they are difficult to
be captured by recommenders. Existing multi-domain learning can alleviate this
problem. However, the structure of the industrial recommendation system is
complex, the amount of data is huge, and the training cost is extremely high,
so it is difficult to modify the structure of the industrial recommender and
re-train it. To fill this gap, we consider recommenders as large pre-trained
models and fine-tune them. We first propose the theory of the information
bottleneck for fine-tuning and present an explanation for the fine-tuning
technique in recommenders. To tailor for recommendation, we design an
information-aware adaptive kernel (IAK) technique to fine-tune the pre-trained
recommender. Specifically, we define fine-tuning as two phases: knowledge
compression and knowledge matching and let the training stage of IAK explicitly
approximate these two phases. Our proposed approach designed from the essence
of fine-tuning is well interpretable. Extensive online and offline experiments
show the superiority of our proposed method. Besides, we also share unique and
important lessons we learned when deploying the method in a large-scale online
platform. We also present the potential issues of fine-tuning techniques in
recommendation systems and the corresponding solutions. The recommender with
IAK technique has been deployed on the homepage of a billion-scale online food
platform for several months and has yielded considerable profits in our
business.

摘要：<paragraph>在現實中，使用者在不同的時段、區域、場景等，會有不同的興趣。而這樣的興趣變化劇烈，難以被推薦系統捕捉到。現有的多領域學習可以緩解這個問題。然而，產業推薦系統的架構複雜、資料量龐大、訓練成本極高，因此難以修改產業推薦系統的架構並重新訓練。為了填補這個缺口，我們將推薦系統視為大型預訓練模型，並對其進行微調。我們首先提出微調的資訊瓶頸理論，並對推薦系統中的微調技術提出解釋。為了客製化推薦，我們設計了一種資訊感知自適應核 (IAK) 技術來微調預訓練的推薦系統。具體來說，我們將微調定義為兩個階段：知識壓縮和知識匹配，並讓 IAK 的訓練階段明確逼近這兩個階段。我們提出的方法從微調的本質設計，具有良好的可解釋性。廣泛的線上和離線實驗顯示了我們提出的方法的優越性。此外，我們還分享了在大型線上平台部署該方法時學到的獨特且重要的經驗。我們也提出了微調技術在推薦系統中的潛在問題和對應的解決方案。結合 IAK 技術的推薦系統已在十億規模的線上美食平台首頁部署數月，並在我們的業務中產生了可觀的利潤。</paragraph>

##### **Siren: A Learning-Based Multi-Turn Attack Framework for Simulating Real-World Human Jailbreak Behaviors**
2501.14250v1 by Yi Zhao, Youzhi Zhang

Large language models (LLMs) are widely used in real-world applications,
raising concerns about their safety and trustworthiness. While red-teaming with
jailbreak prompts exposes the vulnerabilities of LLMs, current efforts focus
primarily on single-turn attacks, overlooking the multi-turn strategies used by
real-world adversaries. Existing multi-turn methods rely on static patterns or
predefined logical chains, failing to account for the dynamic strategies during
attacks. We propose Siren, a learning-based multi-turn attack framework
designed to simulate real-world human jailbreak behaviors. Siren consists of
three stages: (1) training set construction utilizing Turn-Level LLM feedback
(Turn-MF), (2) post-training attackers with supervised fine-tuning (SFT) and
direct preference optimization (DPO), and (3) interactions between the
attacking and target LLMs. Experiments demonstrate that Siren achieves an
attack success rate (ASR) of 90% with LLaMA-3-8B as the attacker against
Gemini-1.5-Pro as the target model, and 70% with Mistral-7B against GPT-4o,
significantly outperforming single-turn baselines. Moreover, Siren with a
7B-scale model achieves performance comparable to a multi-turn baseline that
leverages GPT-4o as the attacker, while requiring fewer turns and employing
decomposition strategies that are better semantically aligned with attack
goals. We hope Siren inspires the development of stronger defenses against
advanced multi-turn jailbreak attacks under realistic scenarios. Code is
available at https://github.com/YiyiyiZhao/siren. Warning: This paper contains
potentially harmful text.

摘要：大型語言模型 (LLM) 廣泛用於實際應用中，引發了人們對其安全性和可信度的擔憂。雖然使用越獄提示進行紅隊測試揭露了 LLM 的漏洞，但目前的努力主要集中在單回合攻擊上，忽視了現實世界中的對手所使用的多回合策略。現有的多回合方法依賴於靜態模式或預定義的邏輯鏈，無法說明攻擊過程中的動態策略。我們提出了 Siren，一個基於學習的多回合攻擊框架，旨在模擬現實世界中人類越獄行為。Siren 包含三個階段：(1) 利用回合級 LLM 反饋 (Turn-MF) 訓練集合建構，(2) 具有監督微調 (SFT) 和直接偏好最佳化 (DPO) 的訓練後攻擊者，以及 (3) 攻擊和目標 LLM 之間的互動。實驗表明，Siren 以 LLaMA-3-8B 作為攻擊者對抗 Gemini-1.5-Pro 作為目標模型時，攻擊成功率 (ASR) 達到 90%，而 Mistral-7B 對抗 GPT-4o 時達到 70%，顯著優於單回合基準。此外，Siren 使用 7B 級別模型達到的性能與使用 GPT-4o 作為攻擊者的多回合基準相當，同時需要的回合更少，並採用了與攻擊目標在語義上更一致的分解策略。我們希望 Siren 能激勵人們在現實場景中開發出針對高級多回合越獄攻擊的更強大的防禦措施。程式碼可在 https://github.com/YiyiyiZhao/siren 取得。警告：本文包含潛在有害的文字。

##### **Humanity's Last Exam**
2501.14249v1 by Long Phan, Alice Gatti, Ziwen Han, Nathaniel Li, Josephina Hu, Hugh Zhang, Sean Shi, Michael Choi, Anish Agrawal, Arnav Chopra, Adam Khoja, Ryan Kim, Jason Hausenloy, Oliver Zhang, Mantas Mazeika, Daron Anderson, Tung Nguyen, Mobeen Mahmood, Fiona Feng, Steven Y. Feng, Haoran Zhao, Michael Yu, Varun Gangal, Chelsea Zou, Zihan Wang, Jessica P. Wang, Pawan Kumar, Oleksandr Pokutnyi, Robert Gerbicz, Serguei Popov, John-Clark Levin, Mstyslav Kazakov, Johannes Schmitt, Geoff Galgon, Alvaro Sanchez, Yongki Lee, Will Yeadon, Scott Sauers, Marc Roth, Chidozie Agu, Søren Riis, Fabian Giska, Saiteja Utpala, Zachary Giboney, Gashaw M. Goshu, Joan of Arc Xavier, Sarah-Jane Crowson, Mohinder Maheshbhai Naiya, Noah Burns, Lennart Finke, Zerui Cheng, Hyunwoo Park, Francesco Fournier-Facio, John Wydallis, Mark Nandor, Ankit Singh, Tim Gehrunger, Jiaqi Cai, Ben McCarty, Darling Duclosel, Jungbae Nam, Jennifer Zampese, Ryan G. Hoerr, Aras Bacho, Gautier Abou Loume, Abdallah Galal, Hangrui Cao, Alexis C Garretson, Damien Sileo, Qiuyu Ren, Doru Cojoc, Pavel Arkhipov, Usman Qazi, Lianghui Li, Sumeet Motwani, Christian Schroeder de Witt, Edwin Taylor, Johannes Veith, Eric Singer, Taylor D. Hartman, Paolo Rissone, Jaehyeok Jin, Jack Wei Lun Shi, Chris G. Willcocks, Joshua Robinson, Aleksandar Mikov, Ameya Prabhu, Longke Tang, Xavier Alapont, Justine Leon Uro, Kevin Zhou, Emily de Oliveira Santos, Andrey Pupasov Maksimov, Edward Vendrow, Kengo Zenitani, Julien Guillod, Yuqi Li, Joshua Vendrow, Vladyslav Kuchkin, Ng Ze-An, Pierre Marion, Denis Efremov, Jayson Lynch, Kaiqu Liang, Andrew Gritsevskiy, Dakotah Martinez, Ben Pageler, Nick Crispino, Dimitri Zvonkine, Natanael Wildner Fraga, Saeed Soori, Ori Press, Henry Tang, Julian Salazar, Sean R. Green, Lina Brüssel, Moon Twayana, Aymeric Dieuleveut, T. Ryan Rogers, Wenjin Zhang, Bikun Li, Jinzhou Yang, Arun Rao, Gabriel Loiseau, Mikhail Kalinin, Marco Lukas, Ciprian Manolescu, Subrata Mishra, Ariel Ghislain Kemogne Kamdoum, Tobias Kreiman, Tad Hogg, Alvin Jin, Carlo Bosio, Gongbo Sun, Brian P Coppola, Tim Tarver, Haline Heidinger, Rafael Sayous, Stefan Ivanov, Joseph M Cavanagh, Jiawei Shen, Joseph Marvin Imperial, Philippe Schwaller, Shaipranesh Senthilkuma, Andres M Bran, Ali Dehghan, Andres Algaba, Brecht Verbeken, David Noever, Ragavendran P V, Lisa Schut, Ilia Sucholutsky, Evgenii Zheltonozhskii, Derek Lim, Richard Stanley, Shankar Sivarajan, Tong Yang, John Maar, Julian Wykowski, Martí Oller, Jennifer Sandlin, Anmol Sahu, Yuzheng Hu, Sara Fish, Nasser Heydari, Archimedes Apronti, Kaivalya Rawal, Tobias Garcia Vilchis, Yuexuan Zu, Martin Lackner, James Koppel, Jeremy Nguyen, Daniil S. Antonenko, Steffi Chern, Bingchen Zhao, Pierrot Arsene, Alan Goldfarb, Sergey Ivanov, Rafał Poświata, Chenguang Wang, Daofeng Li, Donato Crisostomi, Andrea Achilleos, Benjamin Myklebust, Archan Sen, David Perrella, Nurdin Kaparov, Mark H Inlow, Allen Zang, Elliott Thornley, Daniil Orel, Vladislav Poritski, Shalev Ben-David, Zachary Berger, Parker Whitfill, Michael Foster, Daniel Munro, Linh Ho, Dan Bar Hava, Aleksey Kuchkin, Robert Lauff, David Holmes, Frank Sommerhage, Keith Schneider, Zakayo Kazibwe, Nate Stambaugh, Mukhwinder Singh, Ilias Magoulas, Don Clarke, Dae Hyun Kim, Felipe Meneguitti Dias, Veit Elser, Kanu Priya Agarwal, Victor Efren Guadarrama Vilchis, Immo Klose, Christoph Demian, Ujjwala Anantheswaran, Adam Zweiger, Guglielmo Albani, Jeffery Li, Nicolas Daans, Maksim Radionov, Václav Rozhoň, Ziqiao Ma, Christian Stump, Mohammed Berkani, Jacob Platnick, Volodymyr Nevirkovets, Luke Basler, Marco Piccardo, Ferenc Jeanplong, Niv Cohen, Josef Tkadlec, Paul Rosu, Piotr Padlewski, Stanislaw Barzowski, Kyle Montgomery, Aline Menezes, Arkil Patel, Zixuan Wang, Jamie Tucker-Foltz, Jack Stade, Tom Goertzen, Fereshteh Kazemi, Jeremiah Milbauer, John Arnold Ambay, Abhishek Shukla, Yan Carlos Leyva Labrador, Alan Givré, Hew Wolff, Vivien Rossbach, Muhammad Fayez Aziz, Younesse Kaddar, Yanxu Chen, Robin Zhang, Jiayi Pan, Antonio Terpin, Niklas Muennighoff, Hailey Schoelkopf, Eric Zheng, Avishy Carmi, Adam Jones, Jainam Shah, Ethan D. L. Brown, Kelin Zhu, Max Bartolo, Richard Wheeler, Andrew Ho, Shaul Barkan, Jiaqi Wang, Martin Stehberger, Egor Kretov, Kaustubh Sridhar, Zienab EL-Wasif, Anji Zhang, Daniel Pyda, Joanna Tam, David M. Cunningham, Vladimir Goryachev, Demosthenes Patramanis, Michael Krause, Andrew Redenti, Daniel Bugas, David Aldous, Jesyin Lai, Shannon Coleman, Mohsen Bahaloo, Jiangnan Xu, Sangwon Lee, Sandy Zhao, Ning Tang, Michael K. Cohen, Micah Carroll, Orr Paradise, Jan Hendrik Kirchner, Stefan Steinerberger, Maksym Ovchynnikov, Jason O. Matos, Adithya Shenoy, Benedito Alves de Oliveira Junior, Michael Wang, Yuzhou Nie, Paolo Giordano, Philipp Petersen, Anna Sztyber-Betley, Priti Shukla, Jonathan Crozier, Antonella Pinto, Shreyas Verma, Prashant Joshi, Zheng-Xin Yong, Allison Tee, Jérémy Andréoletti, Orion Weller, Raghav Singhal, Gang Zhang, Alexander Ivanov, Seri Khoury, Hamid Mostaghimi, Kunvar Thaman, Qijia Chen, Tran Quoc Khánh, Jacob Loader, Stefano Cavalleri, Hannah Szlyk, Zachary Brown, Jonathan Roberts, William Alley, Kunyang Sun, Ryan Stendall, Max Lamparth, Anka Reuel, Ting Wang, Hanmeng Xu, Sreenivas Goud Raparthi, Pablo Hernández-Cámara, Freddie Martin, Dmitry Malishev, Thomas Preu, Tomek Korbak, Marcus Abramovitch, Dominic Williamson, Ziye Chen, Biró Bálint, M Saiful Bari, Peyman Kassani, Zihao Wang, Behzad Ansarinejad, Laxman Prasad Goswami, Yewen Sun, Hossam Elgnainy, Daniel Tordera, George Balabanian, Earth Anderson, Lynna Kvistad, Alejandro José Moyano, Rajat Maheshwari, Ahmad Sakor, Murat Eron, Isaac C. McAlister, Javier Gimenez, Innocent Enyekwe, Andrew Favre D. O., Shailesh Shah, Xiaoxiang Zhou, Firuz Kamalov, Ronald Clark, Sherwin Abdoli, Tim Santens, Khalida Meer, Harrison K Wang, Kalyan Ramakrishnan, Evan Chen, Alessandro Tomasiello, G. Bruno De Luca, Shi-Zhuo Looi, Vinh-Kha Le, Noam Kolt, Niels Mündler, Avi Semler, Emma Rodman, Jacob Drori, Carl J Fossum, Milind Jagota, Ronak Pradeep, Honglu Fan, Tej Shah, Jonathan Eicher, Michael Chen, Kushal Thaman, William Merrill, Carter Harris, Jason Gross, Ilya Gusev, Asankhaya Sharma, Shashank Agnihotri, Pavel Zhelnov, Siranut Usawasutsakorn, Mohammadreza Mofayezi, Sergei Bogdanov, Alexander Piperski, Marc Carauleanu, David K. Zhang, Dylan Ler, Roman Leventov, Ignat Soroko, Thorben Jansen, Pascal Lauer, Joshua Duersch, Vage Taamazyan, Wiktor Morak, Wenjie Ma, William Held, Tran Đuc Huy, Ruicheng Xian, Armel Randy Zebaze, Mohanad Mohamed, Julian Noah Leser, Michelle X Yuan, Laila Yacar, Johannes Lengler, Hossein Shahrtash, Edson Oliveira, Joseph W. Jackson, Daniel Espinosa Gonzalez, Andy Zou, Muthu Chidambaram, Timothy Manik, Hector Haffenden, Dashiell Stander, Ali Dasouqi, Alexander Shen, Emilien Duc, Bita Golshani, David Stap, Mikalai Uzhou, Alina Borisovna Zhidkovskaya, Lukas Lewark, Mátyás Vincze, Dustin Wehr, Colin Tang, Zaki Hossain, Shaun Phillips, Jiang Muzhen, Fredrik Ekström, Angela Hammon, Oam Patel, Nicolas Remy, Faraz Farhidi, George Medley, Forough Mohammadzadeh, Madellene Peñaflor, Haile Kassahun, Alena Friedrich, Claire Sparrow, Taom Sakal, Omkar Dhamane, Ali Khajegili Mirabadi, Eric Hallman, Mike Battaglia, Mohammad Maghsoudimehrabani, Hieu Hoang, Alon Amit, Dave Hulbert, Roberto Pereira, Simon Weber, Stephen Mensah, Nathan Andre, Anton Peristyy, Chris Harjadi, Himanshu Gupta, Stephen Malina, Samuel Albanie, Will Cai, Mustafa Mehkary, Frank Reidegeld, Anna-Katharina Dick, Cary Friday, Jasdeep Sidhu, Wanyoung Kim, Mariana Costa, Hubeyb Gurdogan, Brian Weber, Harsh Kumar, Tong Jiang, Arunim Agarwal, Chiara Ceconello, Warren S. Vaz, Chao Zhuang, Haon Park, Andrew R. Tawfeek, Daattavya Aggarwal, Michael Kirchhof, Linjie Dai, Evan Kim, Johan Ferret, Yuzhou Wang, Minghao Yan, Krzysztof Burdzy, Lixin Zhang, Antonio Franca, Diana T. Pham, Kang Yong Loh, Joshua Robinson, Shreen Gul, Gunjan Chhablani, Zhehang Du, Adrian Cosma, Colin White, Robin Riblet, Prajvi Saxena, Jacob Votava, Vladimir Vinnikov, Ethan Delaney, Shiv Halasyamani, Syed M. Shahid, Jean-Christophe Mourrat, Lavr Vetoshkin, Renas Bacho, Vincent Ginis, Aleksandr Maksapetyan, Florencia de la Rosa, Xiuyu Li, Guillaume Malod, Leon Lang, Julien Laurendeau, Fatimah Adesanya, Julien Portier, Lawrence Hollom, Victor Souza, Yuchen Anna Zhou, Yiğit Yalın, Gbenga Daniel Obikoya, Luca Arnaboldi, Rai, Filippo Bigi, Kaniuar Bacho, Pierre Clavier, Gabriel Recchia, Mara Popescu, Nikita Shulga, Ngefor Mildred Tanwie, Thomas C. H. Lux, Ben Rank, Colin Ni, Alesia Yakimchyk, Huanxu, Liu, Olle Häggström, Emil Verkama, Himanshu Narayan, Hans Gundlach, Leonor Brito-Santana, Brian Amaro, Vivek Vajipey, Rynaa Grover, Yiyang Fan, Gabriel Poesia Reis e Silva, Linwei Xin, Yosi Kratish, Jakub Łucki, Wen-Ding Li, Justin Xu, Kevin Joseph Scaria, Freddie Vargus, Farzad Habibi, Long, Lian, Emanuele Rodolà, Jules Robins, Vincent Cheng, Declan Grabb, Ida Bosio, Tony Fruhauff, Ido Akov, Eve J. Y. Lo, Hao Qi, Xi Jiang, Ben Segev, Jingxuan Fan, Sarah Martinson, Erik Y. Wang, Kaylie Hausknecht, Michael P. Brenner, Mao Mao, Yibo Jiang, Xinyu Zhang, David Avagian, Eshawn Jessica Scipio, Muhammad Rehan Siddiqi, Alon Ragoler, Justin Tan, Deepakkumar Patil, Rebeka Plecnik, Aaron Kirtland, Roselynn Grace Montecillo, Stephane Durand, Omer Faruk Bodur, Zahra Adoul, Mohamed Zekry, Guillaume Douville, Ali Karakoc, Tania C. B. Santos, Samir Shamseldeen, Loukmane Karim, Anna Liakhovitskaia, Nate Resman, Nicholas Farina, Juan Carlos Gonzalez, Gabe Maayan, Sarah Hoback, Rodrigo De Oliveira Pena, Glen Sherman, Hodjat Mariji, Rasoul Pouriamanesh, Wentao Wu, Gözdenur Demir, Sandra Mendoza, Ismail Alarab, Joshua Cole, Danyelle Ferreira, Bryan Johnson, Hsiaoyun Milliron, Mohammad Safdari, Liangti Dai, Siriphan Arthornthurasuk, Alexey Pronin, Jing Fan, Angel Ramirez-Trinidad, Ashley Cartwright, Daphiny Pottmaier, Omid Taheri, David Outevsky, Stanley Stepanic, Samuel Perry, Luke Askew, Raúl Adrián Huerta Rodríguez, Abdelkader Dendane, Sam Ali, Ricardo Lorena, Krishnamurthy Iyer, Sk Md Salauddin, Murat Islam, Juan Gonzalez, Josh Ducey, Russell Campbell, Maja Somrak, Vasilios Mavroudis, Eric Vergo, Juehang Qin, Benjámin Borbás, Eric Chu, Jack Lindsey, Anil Radhakrishnan, Antoine Jallon, I. M. J. McInnis, Alex Hoover, Sören Möller, Song Bian, John Lai, Tejal Patwardhan, Summer Yue, Alexandr Wang, Dan Hendrycks

Benchmarks are important tools for tracking the rapid advancements in large
language model (LLM) capabilities. However, benchmarks are not keeping pace in
difficulty: LLMs now achieve over 90\% accuracy on popular benchmarks like
MMLU, limiting informed measurement of state-of-the-art LLM capabilities. In
response, we introduce Humanity's Last Exam (HLE), a multi-modal benchmark at
the frontier of human knowledge, designed to be the final closed-ended academic
benchmark of its kind with broad subject coverage. HLE consists of 3,000
questions across dozens of subjects, including mathematics, humanities, and the
natural sciences. HLE is developed globally by subject-matter experts and
consists of multiple-choice and short-answer questions suitable for automated
grading. Each question has a known solution that is unambiguous and easily
verifiable, but cannot be quickly answered via internet retrieval.
State-of-the-art LLMs demonstrate low accuracy and calibration on HLE,
highlighting a significant gap between current LLM capabilities and the expert
human frontier on closed-ended academic questions. To inform research and
policymaking upon a clear understanding of model capabilities, we publicly
release HLE at https://lastexam.ai.

摘要：基準測試是追蹤大型語言模型 (LLM) 能力快速進展的重要工具。然而，基準測試的難度並未跟上腳步：LLM 現在在 MMLU 等熱門基準測試中達到 90% 以上的準確度，限制了對最先進 LLM 能力的有效衡量。為了解決這個問題，我們引入了人類最後考試 (HLE)，這是一個跨領域基準測試，處於人類知識的前沿，旨在成為最後一個封閉式學術基準測試，涵蓋廣泛的主題。HLE 包含 3,000 個問題，涵蓋數十個科目，包括數學、人文學科和自然科學。HLE 由全球的專家共同開發，包含適合自動評分的選擇題和簡答題。每個問題都有已知的解法，明確且易於驗證，但無法透過網路檢索快速回答。最先進的 LLM 在 HLE 上展現出低準確度和校準，突顯了當前 LLM 能力與封閉式學術問題的專家人類前沿之間的顯著差距。為了在清楚了解模型能力的情況下為研究和政策制定提供資訊，我們在 https://lastexam.ai 公開發布 HLE。

##### **Detection and Classification of Acute Lymphoblastic Leukemia Utilizing Deep Transfer Learning**
2501.14228v1 by Md. Abu Ahnaf Mollick, Md. Mahfujur Rahman, D. M. Asadujjaman, Abdullah Tamim, Nosin Anjum Dristi, Md. Takbir Hossen

A mutation in the DNA of a single cell that compromises its function
initiates leukemia,leading to the overproduction of immature white blood cells
that encroach upon the space required for the generation of healthy blood
cells.Leukemia is treatable if identified in its initial stages. However,its
diagnosis is both arduous and time consuming. This study proposes a novel
approach for diagnosing leukemia across four stages Benign,Early,Pre,and Pro
using deep learning techniques.We employed two Convolutional Neural Network
(CNN) models as MobileNetV2 with an altered head and a custom model. The custom
model consists of multiple convolutional layers,each paired with corresponding
max pooling layers.We utilized MobileNetV2 with ImageNet weights,adjusting the
head to integrate the final results.The dataset used is the publicly available
"Acute Lymphoblastic Leukemia (ALL) Image Dataset", and we applied the
Synthetic Minority Oversampling Technique (SMOTE) to augment and balance the
training dataset.The custom model achieved an accuracy of 98.6%, while
MobileNetV2 attained a superior accuracy of 99.69%. The pretrained model showed
promising results,indicating an increased likelihood of real-world application.

摘要：單一細胞 DNA 中會損害其功能的突變會引發白血病，導致未成熟白血球過度增生，侵佔健康血球生成的空間。白血病若在初期階段就能識別，是可以治療的。然而，它的診斷既艱難又耗時。本研究提出了一種使用深度學習技術診斷四個白血病階段（良性、早期、前期和進展期）的新方法。我們使用了兩個卷積神經網路 (CNN) 模型，分別是具有修改頭部的 MobileNetV2 和一個自訂模型。自訂模型包含多個卷積層，每個卷積層都與對應的最大池化層配對。我們利用具有 ImageNet 權重的 MobileNetV2，調整頭部以整合最終結果。所使用的資料集是公開的「急性淋巴性白血病 (ALL) 影像資料集」，我們應用合成少數過採樣技術 (SMOTE) 來擴充和平衡訓練資料集。自訂模型達到了 98.6% 的準確率，而 MobileNetV2 則達到了 99.69% 的優異準確率。預訓練模型顯示出有希望的結果，表示在現實世界中應用的可能性提高。

##### **Multi-agent KTO: Reinforcing Strategic Interactions of Large Language Model in Language Game**
2501.14225v1 by Rong Ye, Yongxin Zhang, Yikai Zhang, Haoyu Kuang, Zhongyu Wei, Peng Sun

Achieving Artificial General Intelligence (AGI) requires AI agents that can
not only make stratigic decisions but also engage in flexible and meaningful
communication. Inspired by Wittgenstein's language game theory in Philosophical
Investigations, we propose that language agents can learn through in-context
interaction rather than traditional multi-stage frameworks that separate
decision-making from language expression. Using Werewolf, a social deduction
game that tests language understanding, strategic interaction, and
adaptability, we develop the Multi-agent Kahneman & Tversky's Optimization
(MaKTO). MaKTO engages diverse models in extensive gameplay to generate
unpaired desirable and unacceptable responses, then employs KTO to refine the
model's decision-making process. In 9-player Werewolf games, MaKTO achieves a
61% average win rate across various models, outperforming GPT-4o and two-stage
RL agents by relative improvements of 23.0% and 10.9%, respectively. Notably,
MaKTO also demonstrates human-like performance, winning 60% against expert
players and showing only 49% detectability in Turing-style blind tests. These
results showcase MaKTO's superior decision-making, strategic adaptation, and
natural language generation in complex social deduction games.

摘要：要实现人工智能通用智能（AGI），需要 AI 代理不仅能做出战略决策，还能进行灵活且有意义的沟通。受维特根斯坦在《哲学研究》中提出的语言游戏理论的启发，我们提出语言代理可以通过情境互动学习，而不是通过将决策与语言表达分开的传统多阶段框架。我们使用狼人游戏（一种测试语言理解、战略互动和适应性的社交推理游戏）开发了多代理卡尼曼和特沃斯基优化（MaKTO）。MaKTO 让不同的模型参与广泛的游戏，以生成不成对的理想和不可接受的响应，然后使用 KTO 优化模型的决策过程。在 9 人狼人游戏中，MaKTO 在各种模型中实现了 61% 的平均获胜率，分别比 GPT-4o 和两阶段 RL 代理的相对改进率高出 23.0% 和 10.9%。值得注意的是，MaKTO 还展示了类人的表现，在对战专家玩家时获胜率为 60%，在图灵风格的盲测中仅显示 49% 的可检测性。这些结果展示了 MaKTO 在复杂的社交推理游戏中出色的决策、战略适应和自然语言生成能力。

##### **Top Ten Challenges Towards Agentic Neural Graph Databases**
2501.14224v1 by Jiaxin Bai, Zihao Wang, Yukun Zhou, Hang Yin, Weizhi Fei, Qi Hu, Zheye Deng, Jiayang Cheng, Tianshi Zheng, Hong Ting Tsang, Yisen Gao, Zhongwei Xie, Yufei Li, Lixin Fan, Binhang Yuan, Wei Wang, Lei Chen, Xiaofang Zhou, Yangqiu Song

Graph databases (GDBs) like Neo4j and TigerGraph excel at handling
interconnected data but lack advanced inference capabilities. Neural Graph
Databases (NGDBs) address this by integrating Graph Neural Networks (GNNs) for
predictive analysis and reasoning over incomplete or noisy data. However, NGDBs
rely on predefined queries and lack autonomy and adaptability. This paper
introduces Agentic Neural Graph Databases (Agentic NGDBs), which extend NGDBs
with three core functionalities: autonomous query construction, neural query
execution, and continuous learning. We identify ten key challenges in realizing
Agentic NGDBs: semantic unit representation, abductive reasoning, scalable
query execution, and integration with foundation models like large language
models (LLMs). By addressing these challenges, Agentic NGDBs can enable
intelligent, self-improving systems for modern data-driven applications, paving
the way for adaptable and autonomous data management solutions.

摘要：圖形資料庫（GDB），例如 Neo4j 和 TigerGraph，擅長處理相互連接的資料，但缺乏進階的推論能力。神經圖形資料庫（NGDB）透過整合圖形神經網路（GNN）來解決這個問題，以進行預測分析和對不完整或有雜訊的資料進行推理。然而，NGDB 依賴於預先定義的查詢，並且缺乏自主性和適應性。本文介紹了代理神經圖形資料庫（Agentic NGDB），它以三項核心功能擴充了 NGDB：自動查詢建構、神經查詢執行和持續學習。我們找出實現 Agentic NGDB 的十大關鍵挑戰：語義單元表示、演繹推理、可擴充查詢執行，以及與基礎模型（例如大型語言模型 (LLM)）整合。透過解決這些挑戰，Agentic NGDB 可以為現代資料驅動應用打造智慧且自我改善的系統，為適應性和自主資料管理解決方案鋪路。

##### **TFG-Flow: Training-free Guidance in Multimodal Generative Flow**
2501.14216v1 by Haowei Lin, Shanda Li, Haotian Ye, Yiming Yang, Stefano Ermon, Yitao Liang, Jianzhu Ma

Given an unconditional generative model and a predictor for a target property
(e.g., a classifier), the goal of training-free guidance is to generate samples
with desirable target properties without additional training. As a highly
efficient technique for steering generative models toward flexible outcomes,
training-free guidance has gained increasing attention in diffusion models.
However, existing methods only handle data in continuous spaces, while many
scientific applications involve both continuous and discrete data (referred to
as multimodality). Another emerging trend is the growing use of the simple and
general flow matching framework in building generative foundation models, where
guided generation remains under-explored. To address this, we introduce
TFG-Flow, a novel training-free guidance method for multimodal generative flow.
TFG-Flow addresses the curse-of-dimensionality while maintaining the property
of unbiased sampling in guiding discrete variables. We validate TFG-Flow on
four molecular design tasks and show that TFG-Flow has great potential in drug
design by generating molecules with desired properties.

摘要：假設我們有一個無條件生成模型和一個目標屬性的預測器（例如分類器），無訓練引導的目標是生成具有理想目標屬性的樣本，而無需額外訓練。作為一種引導生成模型朝向靈活結果的高效技術，無訓練引導在擴散模型中獲得了越來越多的關注。然而，現有方法僅處理連續空間中的數據，而許多科學應用涉及連續和離散數據（稱為多模態）。另一個新興趨勢是越來越多地使用簡單且通用的流匹配框架來構建生成基礎模型，其中引導生成仍未得到充分探索。為了解決這個問題，我們引入了 TFG-Flow，這是一種針對多模態生成流的新型無訓練引導方法。TFG-Flow 在保持無偏採樣的屬性的同時解決了維度災難，從而引導離散變量。我們在四個分子設計任務上驗證了 TFG-Flow，並表明 TFG-Flow 在藥物設計中具有巨大的潛力，因為它可以生成具有所需屬性的分子。

##### **PuzzleGPT: Emulating Human Puzzle-Solving Ability for Time and Location Prediction**
2501.14210v1 by Hammad Ayyubi, Xuande Feng, Junzhang Liu, Xudong Lin, Zhecan Wang, Shih-Fu Chang

The task of predicting time and location from images is challenging and
requires complex human-like puzzle-solving ability over different clues. In
this work, we formalize this ability into core skills and implement them using
different modules in an expert pipeline called PuzzleGPT. PuzzleGPT consists of
a perceiver to identify visual clues, a reasoner to deduce prediction
candidates, a combiner to combinatorially combine information from different
clues, a web retriever to get external knowledge if the task can't be solved
locally, and a noise filter for robustness. This results in a zero-shot,
interpretable, and robust approach that records state-of-the-art performance on
two datasets -- TARA and WikiTilo. PuzzleGPT outperforms large VLMs such as
BLIP-2, InstructBLIP, LLaVA, and even GPT-4V, as well as automatically
generated reasoning pipelines like VisProg, by at least 32% and 38%,
respectively. It even rivals or surpasses finetuned models.

摘要：從影像預測時間和位置的任務具有挑戰性，需要具備人類般的複雜解謎能力，才能從不同的線索中解謎。在此研究中，我們將這種能力形式化為核心技能，並使用專家管道 PuzzleGPT 中的不同模組來實作這些技能。PuzzleGPT 包含一個感知器，用於識別視覺線索；一個推理器，用於推論預測候選項；一個組合器，用於組合來自不同線索的資訊；一個網路檢索器，用於在無法在本地解決任務時取得外部知識；以及一個雜訊濾波器，用於增強穩健性。這產生了一種零次學習、可解釋且穩健的方法，在兩個資料集（TARA 和 WikiTilo）上創下最先進的效能。PuzzleGPT 的表現優於大型 VLM，例如 BLIP-2、InstructBLIP、LLaVA，甚至 GPT-4V，以及自動產生的推理管道（例如 VisProg），分別至少高出 32% 和 38%。它甚至與微調模型相抗衡或超越微調模型。

##### **Dynamic Token Reduction during Generation for Vision Language Models**
2501.14204v1 by Xiaoyu Liang, Chaofeng Guan, Jiaying Lu, Huiyao Chen, Huan Wang, Haoji Hu

Vision-Language Models (VLMs) have achieved notable success in multimodal
tasks but face practical limitations due to the quadratic complexity of decoder
attention mechanisms and autoregressive generation. Existing methods like FASTV
and VTW have achieved notable results in reducing redundant visual tokens, but
these approaches focus on pruning tokens in a single forward pass without
systematically analyzing the redundancy of visual tokens throughout the entire
generation process. In this paper, we introduce a dynamic pruning strategy
tailored for VLMs, namedDynamic Rate (DyRate), which progressively adjusts the
compression rate during generation. Our analysis of the distribution of
attention reveals that the importance of visual tokens decreases throughout the
generation process, inspiring us to adopt a more aggressive compression rate.
By integrating a lightweight predictor based on attention distribution, our
approach enables flexible adjustment of pruning rates based on the attention
distribution. Our experimental results demonstrate that our method not only
reduces computational demands but also maintains the quality of responses.

摘要：視覺語言模型 (VLM) 已在多模態任務中取得顯著成功，但由於解碼器注意力機制和自迴歸生成的二次複雜性而面臨實際限制。FASTV 和 VTW 等現有方法已在減少多餘視覺符號方面取得顯著成果，但這些方法專注於在單次前向傳遞中修剪符號，而沒有系統地分析整個生成過程中視覺符號的冗餘。在本文中，我們引入了一種專為 VLM 設計的動態修剪策略，稱為動態速率 (DyRate)，它會在生成過程中逐步調整壓縮率。我們對注意力分佈的分析表明，視覺符號的重要性會在整個生成過程中降低，這啟發我們採用更激進的壓縮率。通過整合基於注意力分佈的輕量級預測器，我們的技術可以根據注意力分佈靈活調整修剪率。我們的實驗結果表明，我們的技術不僅減少了運算需求，而且還維持了回應的品質。

##### **Coordinating Ride-Pooling with Public Transit using Reward-Guided Conservative Q-Learning: An Offline Training and Online Fine-Tuning Reinforcement Learning Framework**
2501.14199v1 by Yulong Hu, Tingting Dong, Sen Li

This paper introduces a novel reinforcement learning (RL) framework, termed
Reward-Guided Conservative Q-learning (RG-CQL), to enhance coordination between
ride-pooling and public transit within a multimodal transportation network. We
model each ride-pooling vehicle as an agent governed by a Markov Decision
Process (MDP) and propose an offline training and online fine-tuning RL
framework to learn the optimal operational decisions of the multimodal
transportation systems, including rider-vehicle matching, selection of drop-off
locations for passengers, and vehicle routing decisions, with improved data
efficiency. During the offline training phase, we develop a Conservative Double
Deep Q Network (CDDQN) as the action executor and a supervised learning-based
reward estimator, termed the Guider Network, to extract valuable insights into
action-reward relationships from data batches. In the online fine-tuning phase,
the Guider Network serves as an exploration guide, aiding CDDQN in effectively
and conservatively exploring unknown state-action pairs. The efficacy of our
algorithm is demonstrated through a realistic case study using real-world data
from Manhattan. We show that integrating ride-pooling with public transit
outperforms two benchmark cases solo rides coordinated with transit and
ride-pooling without transit coordination by 17% and 22% in the achieved system
rewards, respectively. Furthermore, our innovative offline training and online
fine-tuning framework offers a remarkable 81.3% improvement in data efficiency
compared to traditional online RL methods with adequate exploration budgets,
with a 4.3% increase in total rewards and a 5.6% reduction in overestimation
errors. Experimental results further demonstrate that RG-CQL effectively
addresses the challenges of transitioning from offline to online RL in
large-scale ride-pooling systems integrated with transit.

摘要：<paragraph>本文介紹了一種創新的強化學習 (RL) 架構，稱為獎勵引導保守 Q 學習 (RG-CQL)，以增強多式聯運網路中乘車共乘與大眾運輸之間的協調。我們將每個乘車共乘車輛建模為受馬可夫決策過程 (MDP) 控制的代理，並提出一個離線訓練和線上微調 RL 架構，以學習多式聯運系統的最佳營運決策，包括乘客與車輛配對、乘客下車地點的選擇，以及車輛路線決策，並提高資料效率。在離線訓練階段，我們開發了一個保守雙深度 Q 網路 (CDDQN) 作為動作執行器，以及一個基於監督學習的獎勵估計器，稱為引導網路，從資料批次中提取對動作獎勵關係的寶貴見解。在線上微調階段，引導網路作為探索指南，協助 CDDQN 有效且保守地探索未知的狀態動作對。我們使用來自曼哈頓的真實世界資料，透過一個實際案例研究來證明我們演算法的功效。我們展示了將乘車共乘與大眾運輸整合起來，在達成的系統獎勵方面分別比與運輸協調的單人乘車和沒有運輸協調的乘車共乘高出 17% 和 22%。此外，我們創新的離線訓練和線上微調架構，與具有足夠探索預算的傳統線上 RL 方法相比，在資料效率方面提供了顯著的 81.3% 提升，總獎勵增加了 4.3%，高估誤差減少了 5.6%。實驗結果進一步證明，RG-CQL 有效地應對了從離線到線上 RL 轉換在與運輸整合的大規模乘車共乘系統中的挑戰。</paragraph>

##### **Distributed Multi-Agent Coordination Using Multi-Modal Foundation Models**
2501.14189v1 by Saaduddin Mahmud, Dorian Benhamou Goldfajn, Shlomo Zilberstein

Distributed Constraint Optimization Problems (DCOPs) offer a powerful
framework for multi-agent coordination but often rely on labor-intensive,
manual problem construction. To address this, we introduce VL-DCOPs, a
framework that takes advantage of large multimodal foundation models (LFMs) to
automatically generate constraints from both visual and linguistic
instructions. We then introduce a spectrum of agent archetypes for solving
VL-DCOPs: from a neuro-symbolic agent that delegates some of the algorithmic
decisions to an LFM, to a fully neural agent that depends entirely on an LFM
for coordination. We evaluate these agent archetypes using state-of-the-art
LLMs (large language models) and VLMs (vision language models) on three novel
VL-DCOP tasks and compare their respective advantages and drawbacks. Lastly, we
discuss how this work extends to broader frontier challenges in the DCOP
literature.

摘要：分散式約束最佳化問題 (DCOP) 提供了一個強大的多代理協調架構，但通常依賴於勞力密集的手動問題建構。為了解決這個問題，我們引入了 VL-DCOP，一個利用大型多模態基礎模型 (LFM) 從視覺和語言指令自動產生約束的架構。接著我們引入了用於解決 VL-DCOP 的一組代理原型：從將部分演算法決策委派給 LFM 的神經符號代理，到完全依賴 LFM 進行協調的全神經網路代理。我們使用最先進的 LLM (大型語言模型) 和 VLM (視覺語言模型) 在三個新穎的 VL-DCOP 任務上評估這些代理原型，並比較它們各自的優缺點。最後，我們討論了這項工作如何擴展到 DCOP 文獻中更廣泛的前沿挑戰。

##### **Dreamweaver: Learning Compositional World Representations from Pixels**
2501.14174v1 by Junyeob Baek, Yi-Fu Wu, Gautam Singh, Sungjin Ahn

Humans have an innate ability to decompose their perceptions of the world
into objects and their attributes, such as colors, shapes, and movement
patterns. This cognitive process enables us to imagine novel futures by
recombining familiar concepts. However, replicating this ability in artificial
intelligence systems has proven challenging, particularly when it comes to
modeling videos into compositional concepts and generating unseen, recomposed
futures without relying on auxiliary data, such as text, masks, or bounding
boxes. In this paper, we propose Dreamweaver, a neural architecture designed to
discover hierarchical and compositional representations from raw videos and
generate compositional future simulations. Our approach leverages a novel
Recurrent Block-Slot Unit (RBSU) to decompose videos into their constituent
objects and attributes. In addition, Dreamweaver uses a multi-future-frame
prediction objective to capture disentangled representations for dynamic
concepts more effectively as well as static concepts. In experiments, we
demonstrate our model outperforms current state-of-the-art baselines for world
modeling when evaluated under the DCI framework across multiple datasets.
Furthermore, we show how the modularized concept representations of our model
enable compositional imagination, allowing the generation of novel videos by
recombining attributes from different objects.

摘要：人類具有將他們對世界的感知分解成物件及其屬性（例如顏色、形狀和運動模式）的先天能力。這個認知過程讓我們能夠透過重新組合熟悉的概念來想像新穎的未來。然而，在人工智慧系統中複製這種能力已被證明具有挑戰性，特別是在將影片建模成組合概念並產生未見過的、重新組合的未來時，且不依賴輔助資料，例如文字、遮罩或邊界框。在本文中，我們提出了 Dreamweaver，一種神經架構，旨在從原始影片中發現階層式和組合式表示，並產生組合式未來模擬。我們的做法利用一種新穎的遞迴區塊槽單元 (RBSU) 將影片分解成其組成物件和屬性。此外，Dreamweaver 使用多未來幀預測目標，以更有效地擷取動態概念和靜態概念的解糾纏表示。在實驗中，我們證明了我們的模型在多個資料集上根據 DCI 架構評估時，優於當前世界建模技術的最新基準。此外，我們展示了我們模型的模組化概念表示如何啟用組合式想像力，允許透過重新組合來自不同物件的屬性來產生新穎的影片。

##### **UltraLightSqueezeNet: A Deep Learning Architecture for Malaria Classification with up to 54x fewer trainable parameters for resource constrained devices**
2501.14172v1 by Suresh Babu Nettur, Shanthi Karpurapu, Unnati Nettur, Likhit Sagar Gajja, Sravanthy Myneni, Akhil Dusi, Lalithya Posham

Lightweight deep learning approaches for malaria detection have gained
attention for their potential to enhance diagnostics in resource constrained
environments. For our study, we selected SqueezeNet1.1 as it is one of the most
popular lightweight architectures. SqueezeNet1.1 is a later version of
SqueezeNet1.0 and is 2.4 times more computationally efficient than the original
model. We proposed and implemented three ultra-lightweight architecture
variants to SqueezeNet1.1 architecture, namely Variant 1 (one fire module),
Variant 2 (two fire modules), and Variant 3 (four fire modules), which are even
more compact than SqueezeNetV1.1 (eight fire modules). These models were
implemented to evaluate the best performing variant that achieves superior
computational efficiency without sacrificing accuracy in malaria blood cell
classification. The models were trained and evaluated using the NIH Malaria
dataset. We assessed each model's performance based on metrics including
accuracy, recall, precision, F1-score, and Area Under the Curve (AUC). The
results show that the SqueezeNet1.1 model achieves the highest performance
across all metrics, with a classification accuracy of 97.12%. Variant 3 (four
fire modules) offers a competitive alternative, delivering almost identical
results (accuracy 96.55%) with a 6x reduction in computational overhead
compared to SqueezeNet1.1. Variant 2 and Variant 1 perform slightly lower than
Variant 3, with Variant 2 (two fire modules) reducing computational overhead by
28x, and Variant 1 (one fire module) achieving a 54x reduction in trainable
parameters compared to SqueezeNet1.1. These findings demonstrate that our
SqueezeNet1.1 architecture variants provide a flexible approach to malaria
detection, enabling the selection of a variant that balances resource
constraints and performance.

摘要：輕量級深度學習用於瘧疾檢測的方法因其增強資源受限環境中診斷的潛力而備受關注。在我們的研究中，我們選擇了 SqueezeNet1.1，因為它是最受歡迎的輕量級架構之一。SqueezeNet1.1 是 SqueezeNet1.0 的後續版本，其計算效率比原始模型高出 2.4 倍。我們提出並實作了三個超輕量級架構變體，分別是 SqueezeNet1.1 架構的變體 1（一個 fire 模組）、變體 2（兩個 fire 模組）和變體 3（四個 fire 模組），它們甚至比 SqueezeNetV1.1（八個 fire 模組）更精簡。這些模型的實作目的是評估在不犧牲瘧疾血球分類準確性的情況下，能達成卓越運算效率的最佳效能變體。這些模型使用 NIH 瘧疾資料集進行訓練和評估。我們根據準確度、召回率、精確度、F1 分數和曲線下面積 (AUC) 等指標評估每個模型的效能。結果顯示，SqueezeNet1.1 模型在所有指標上都達到最高效能，分類準確度為 97.12%。變體 3（四個 fire 模組）提供了有競爭力的替代方案，提供了幾乎相同的結果（準確度 96.55%），同時與 SqueezeNet1.1 相比，運算負擔減少了 6 倍。變體 2 和變體 1 的效能略低於變體 3，其中變體 2（兩個 fire 模組）將運算負擔減少了 28 倍，而變體 1（一個 fire 模組）與 SqueezeNet1.1 相比，可訓練參數減少了 54 倍。這些發現證明了我們的 SqueezeNet1.1 架構變體提供了瘧疾檢測的彈性方法，能夠選擇平衡資源限制和效能的變體。

##### **Enhancing Multimodal Entity Linking with Jaccard Distance-based Conditional Contrastive Learning and Contextual Visual Augmentation**
2501.14166v1 by Cong-Duy Nguyen, Xiaobao Wu, Thong Nguyen, Shuai Zhao, Khoi Le, Viet-Anh Nguyen, Feng Yichao, Anh Tuan Luu

Previous research on multimodal entity linking (MEL) has primarily employed
contrastive learning as the primary objective. However, using the rest of the
batch as negative samples without careful consideration, these studies risk
leveraging easy features and potentially overlook essential details that make
entities unique. In this work, we propose JD-CCL (Jaccard Distance-based
Conditional Contrastive Learning), a novel approach designed to enhance the
ability to match multimodal entity linking models. JD-CCL leverages
meta-information to select negative samples with similar attributes, making the
linking task more challenging and robust. Additionally, to address the
limitations caused by the variations within the visual modality among mentions
and entities, we introduce a novel method, CVaCPT (Contextual Visual-aid
Controllable Patch Transform). It enhances visual representations by
incorporating multi-view synthetic images and contextual textual
representations to scale and shift patch representations. Experimental results
on benchmark MEL datasets demonstrate the strong effectiveness of our approach.

摘要：先前針對多模態實體連結 (MEL) 的研究主要採用對比學習作為主要目標。然而，這些研究在未經仔細考量的情況下將批次其餘部分用作負樣本，因此有風險會利用容易辨識的特徵，並可能忽略使實體獨一無二的重要細節。在本文中，我們提出 JD-CCL（Jaccard 距離基礎條件對比學習），這是一種新穎的方法，旨在增強多模態實體連結模型的匹配能力。JD-CCL 利用元資訊來選擇具有類似屬性的負樣本，使連結任務更具挑戰性和穩健性。此外，為了解決在提及和實體之間的視覺模式中變異所造成的限制，我們引入了一種新方法，稱為 CVaCPT（脈絡視覺輔助可控區塊轉換）。它透過結合多視角合成影像和脈絡文字表徵來增強視覺表徵，以縮放和轉移區塊表徵。在基準 MEL 資料集上的實驗結果證明了我們方法的強大效能。

##### **LoCoML: A Framework for Real-World ML Inference Pipelines**
2501.14165v1 by Kritin Maddireddy, Santhosh Kotekal Methukula, Chandrasekar Sridhar, Karthik Vaidhyanathan

The widespread adoption of machine learning (ML) has brought forth diverse
models with varying architectures, and data requirements, introducing new
challenges in integrating these systems into real-world applications.
Traditional solutions often struggle to manage the complexities of connecting
heterogeneous models, especially when dealing with varied technical
specifications. These limitations are amplified in large-scale, collaborative
projects where stakeholders contribute models with different technical
specifications. To address these challenges, we developed LoCoML, a low-code
framework designed to simplify the integration of diverse ML models within the
context of the \textit{Bhashini Project} - a large-scale initiative aimed at
integrating AI-driven language technologies such as automatic speech
recognition, machine translation, text-to-speech, and optical character
recognition to support seamless communication across more than 20 languages.
Initial evaluations show that LoCoML adds only a small amount of computational
load, making it efficient and effective for large-scale ML integration. Our
practical insights show that a low-code approach can be a practical solution
for connecting multiple ML models in a collaborative environment.

摘要：機器學習 (ML) 的廣泛採用帶來了架構和資料需求各不相同的各種模型，在將這些系統整合到實際應用中時引入了新的挑戰。
傳統的解決方案常常難以管理連接異質模型的複雜性，特別是在處理各種技術規格時。這些限制在大型協作專案中會被放大，在這些專案中，利害關係人會貢獻具有不同技術規格的模型。為了應對這些挑戰，我們開發了 LoCoML，這是一個低程式碼框架，旨在簡化在「Bhashini 專案」中整合各種 ML 模型，這是一個大型計畫，旨在整合 AI 驅動的語言技術，例如自動語音辨識、機器翻譯、文字轉語音和光學字元辨識，以支援超過 20 種語言的無縫溝通。
初步評估顯示，LoCoML 只增加了少量運算負載，使其對於大規模 ML 整合來說既有效率又有效。我們的實務見解顯示，低程式碼方法可以成為在協作環境中連接多個 ML 模型的實用解決方案。

##### **Test-Time Code-Switching for Cross-lingual Aspect Sentiment Triplet Extraction**
2501.14144v1 by Dongming Sheng, Kexin Han, Hao Li, Yan Zhang, Yucheng Huang, Jun Lang, Wenqiang Liu

Aspect Sentiment Triplet Extraction (ASTE) is a thriving research area with
impressive outcomes being achieved on high-resource languages. However, the
application of cross-lingual transfer to the ASTE task has been relatively
unexplored, and current code-switching methods still suffer from term boundary
detection issues and out-of-dictionary problems. In this study, we introduce a
novel Test-Time Code-SWitching (TT-CSW) framework, which bridges the gap
between the bilingual training phase and the monolingual test-time prediction.
During training, a generative model is developed based on bilingual
code-switched training data and can produce bilingual ASTE triplets for
bilingual inputs. In the testing stage, we employ an alignment-based
code-switching technique for test-time augmentation. Extensive experiments on
cross-lingual ASTE datasets validate the effectiveness of our proposed method.
We achieve an average improvement of 3.7% in terms of weighted-averaged F1 in
four datasets with different languages. Additionally, we set a benchmark using
ChatGPT and GPT-4, and demonstrate that even smaller generative models
fine-tuned with our proposed TT-CSW framework surpass ChatGPT and GPT-4 by
14.2% and 5.0% respectively.

摘要：面向方面的情感三元組抽取 (ASTE) 是個蓬勃發展的研究領域，在高資源語言中取得令人印象深刻的成果。然而，跨語言轉移應用於 ASTE 任務的研究相對較少，目前的代碼轉換方法仍然存在術語邊界偵測問題和字典外問題。在本研究中，我們引入了一個新穎的測試時代碼轉換 (TT-CSW) 框架，它彌合了雙語訓練階段與單語測試時預測之間的差距。在訓練期間，基於雙語代碼轉換訓練數據開發了一個生成模型，並且可以為雙語輸入產生雙語 ASTE 三元組。在測試階段，我們採用基於對齊的代碼轉換技術進行測試時擴充。跨語言 ASTE 資料集上的大量實驗驗證了我們提出的方法的有效性。我們在四個不同語言的資料集中，在加權平均 F1 方面實現了平均 3.7% 的提升。此外，我們使用 ChatGPT 和 GPT-4 設定了一個基準，並證明即使是較小的生成模型使用我們提出的 TT-CSW 框架進行微調，也分別比 ChatGPT 和 GPT-4 高出 14.2% 和 5.0%。

##### **Reinforcement Learning Platform for Adversarial Black-box Attacks with Custom Distortion Filters**
2501.14122v1 by Soumyendu Sarkar, Ashwin Ramesh Babu, Sajad Mousavi, Vineet Gundecha, Sahand Ghorbanpour, Avisek Naug, Ricardo Luna Gutierrez, Antonio Guillen

We present a Reinforcement Learning Platform for Adversarial Black-box
untargeted and targeted attacks, RLAB, that allows users to select from various
distortion filters to create adversarial examples. The platform uses a
Reinforcement Learning agent to add minimum distortion to input images while
still causing misclassification by the target model. The agent uses a novel
dual-action method to explore the input image at each step to identify
sensitive regions for adding distortions while removing noises that have less
impact on the target model. This dual action leads to faster and more efficient
convergence of the attack. The platform can also be used to measure the
robustness of image classification models against specific distortion types.
Also, retraining the model with adversarial samples significantly improved
robustness when evaluated on benchmark datasets. The proposed platform
outperforms state-of-the-art methods in terms of the average number of queries
required to cause misclassification. This advances trustworthiness with a
positive social impact.

摘要：我們提出一個針對對抗性黑盒無目標和目標攻擊的強化學習平台 RLAB，它允許使用者從各種失真濾鏡中選擇，以建立對抗性範例。該平台使用強化學習代理，在不造成目標模型誤分類的情況下，將輸入影像的失真降至最低。該代理使用一種新穎的雙重動作方法，在每個步驟中探索輸入影像，以找出可加入失真的敏感區域，同時移除對目標模型影響較小的雜訊。這種雙重動作導致攻擊的收斂速度更快、效率更高。該平台還可用来衡量影像分類模型對特定失真類型的穩健性。此外，使用對抗性範例重新訓練模型，在基準資料集上評估時，顯著改善了穩健性。所提出的平台在造成誤分類所需的平均查詢次數方面，優於最先進的方法。這透過正向的社會影響，提升了可信度。

##### **On the Transfer of Knowledge in Quantum Algorithms**
2501.14120v1 by Esther Villar-Rodriguez, Eneko Osaba, Izaskun Oregi, Sebastián V. Romero, Julián Ferreiro-Vélez

The field of quantum computing is generating significant anticipation within
the scientific and industrial communities due to its potential to revolutionize
computing paradigms. Recognizing this potential, this paper explores the
integration of transfer of knowledge techniques, traditionally used in
classical artificial intelligence, into quantum computing. We present a
comprehensive classification of the transfer models, focusing on Transfer
Learning and Transfer Optimization. Additionally, we analyze relevant schemes
in quantum computing that can benefit from knowledge sharing, and we delve into
the potential synergies, supported by theoretical insights and initial
experimental results. Our findings suggest that leveraging the transfer of
knowledge can enhance the efficiency and effectiveness of quantum algorithms,
particularly in the context of hybrid solvers. This approach not only
accelerates the optimization process but also reduces the computational burden
on quantum processors, making it a valuable tool for advancing quantum
computing technologies.

摘要：量子運算領域在科學和產業界中產生了重大的期待，因為它有潛力革新運算模式。為了了解這種潛力，本文探討了將知識傳輸技術（傳統上用於古典人工智慧）整合到量子運算中的方法。我們提出了傳輸模型的全面分類，重點在於遷移學習和遷移最佳化。此外，我們分析了量子運算中可以從知識共享中受益的相关方案，並深入探討了由理論見解和初步實驗結果支持的潛在協同效應。我們的研究結果表明，利用知識傳輸可以提高量子演算法的效率和效能，特別是在混合求解器的背景下。這種方法不僅加速了最佳化流程，還減輕了量子處理器的運算負擔，使其成為推進量子運算技術的寶貴工具。

##### **Autonomous Structural Memory Manipulation for Large Language Models Using Hierarchical Embedding Augmentation**
2501.14119v1 by Derek Yotheringhay, Alistair Kirkland, Humphrey Kirkbride, Josiah Whitesteeple

Transformative innovations in model architectures have introduced
hierarchical embedding augmentation as a means to redefine the representation
of tokens through multi-level semantic structures, offering enhanced
adaptability to complex linguistic inputs. Autonomous structural memory
manipulation further advances this paradigm through dynamic memory reallocation
mechanisms that prioritize critical contextual features while suppressing less
relevant information, enabling scalable and efficient performance across
diverse tasks. Experimental results reveal substantial improvements in
computational efficiency, with marked reductions in processing overhead for
longer input sequences, achieved through memory reorganization strategies that
adapt to evolving contextual requirements. Hierarchical embeddings not only
improved contextual alignment but also facilitated task generalization by
capturing relationships at varying semantic granularities, ensuring coherence
across layers without introducing significant computational redundancies.
Comparative analysis against baseline models demonstrated unique advantages in
accuracy, efficiency, and interpretability, particularly in tasks requiring
complex contextual understanding or domain-specific adaptability. The ability
to dynamically adjust token representations and memory configurations
contributed to the model's robustness under varied and unpredictable input
conditions. Applications benefiting from these advancements include
multi-domain generalization, interactive systems, and scenarios involving
real-time decision-making, where traditional static memory architectures often
face limitations. The proposed methodology combines advanced embedding and
memory management strategies into a cohesive framework that addresses
scalability challenges while preserving task-specific relevance.

摘要：模型架構的轉型創新引入了分層嵌入擴充，作為透過多層語義結構重新定義符號表徵的方法，提供增強的複雜語言輸入適應性。自體結構記憶操作進一步透過動態記憶重新配置機制推進此範例，此機制優先處理關鍵的脈絡特徵，同時抑制較不相關的資訊，讓跨不同任務的效能具備可擴充性和效率。實驗結果顯示在運算效率方面有大幅進步，透過適應不斷變化的脈絡需求的記憶重組策略，大幅減少較長輸入序列的處理負擔。分層嵌入不僅改善脈絡對齊，也透過擷取不同語義粒度的關係來促進任務概化，確保跨層次的一致性，同時不會引入顯著的運算冗餘。與基準模型的比較分析證明了在準確度、效率和可解釋性方面有獨特的優勢，特別是在需要複雜脈絡理解或特定領域適應性的任務中。動態調整符號表徵和記憶組態的能力有助於模型在變化多端且無法預測的輸入條件下展現穩健性。從這些進展中受益的應用包括多領域概化、互動式系統，以及涉及即時決策的場景，在這些場景中，傳統的靜態記憶架構經常會面臨限制。所提出的方法將進階嵌入和記憶管理策略結合到一個緊密的架構中，此架構解決了可擴充性挑戰，同時保留了特定任務相關性。

##### **LeCoPCR: Legal Concept-guided Prior Case Retrieval for European Court of Human Rights cases**
2501.14114v1 by T. Y. S. S. Santosh, Isaac Misael Olguín Nolasco, Matthias Grabmair

Prior case retrieval (PCR) is crucial for legal practitioners to find
relevant precedent cases given the facts of a query case. Existing approaches
often overlook the underlying semantic intent in determining relevance with
respect to the query case. In this work, we propose LeCoPCR, a novel approach
that explicitly generate intents in the form of legal concepts from a given
query case facts and then augments the query with these concepts to enhance
models understanding of semantic intent that dictates relavance. To overcome
the unavailability of annotated legal concepts, we employ a weak supervision
approach to extract key legal concepts from the reasoning section using
Determinantal Point Process (DPP) to balance quality and diversity.
Experimental results on the ECtHR-PCR dataset demonstrate the effectiveness of
leveraging legal concepts and DPP-based key concept extraction.

摘要：先例檢索 (PCR) 對法律從業人員而言至關重要，能根據查詢案例的事實找到相關的判例。現有方法在確定與查詢案例相關性時，經常忽略基礎語意意圖。在這項工作中，我們提出 LeCoPCR，一種創新的方法，能從給定的查詢案例事實中以法律概念的形式明確產生意圖，然後使用這些概念擴充查詢，以增強模型對語意意圖的理解，而語意意圖決定了相關性。為了克服標註法律概念的不可用性，我們採用弱監督方法，使用行列式點過程 (DPP) 從推理部分中萃取關鍵法律概念，以平衡品質和多樣性。在 ECtHR-PCR 資料集上的實驗結果證明了利用法律概念和基於 DPP 的關鍵概念萃取的有效性。

##### **RELexED: Retrieval-Enhanced Legal Summarization with Exemplar Diversity**
2501.14113v1 by T. Y. S. S. Santosh, Chen Jia, Patrick Goroncy, Matthias Grabmair

This paper addresses the task of legal summarization, which involves
distilling complex legal documents into concise, coherent summaries. Current
approaches often struggle with content theme deviation and inconsistent writing
styles due to their reliance solely on source documents. We propose RELexED, a
retrieval-augmented framework that utilizes exemplar summaries along with the
source document to guide the model. RELexED employs a two-stage exemplar
selection strategy, leveraging a determinantal point process to balance the
trade-off between similarity of exemplars to the query and diversity among
exemplars, with scores computed via influence functions. Experimental results
on two legal summarization datasets demonstrate that RELexED significantly
outperforms models that do not utilize exemplars and those that rely solely on
similarity-based exemplar selection.

摘要：本文探討法律摘要任務，這涉及將複雜的法律文件簡化為簡潔、連貫的摘要。目前的做法通常會因過度依賴原始文件而導致內容主題偏離和寫作風格不一致。我們提出 RELexED，一個檢索增強框架，它利用範例摘要和原始文件來指導模型。RELexED 使用兩階段範例選擇策略，利用行列式點過程來平衡範例與查詢的相似性與範例之間的多樣性，並透過影響函數計算分數。在兩個法律摘要資料集上的實驗結果表明，RELexED 明顯優於不使用範例的模型和僅依賴基於相似性的範例選擇的模型。

##### **CoPERLex: Content Planning with Event-based Representations for Legal Case Summarization**
2501.14112v1 by T. Y. S. S. Santosh, Youssef Farag, Matthias Grabmair

Legal professionals often struggle with lengthy judgments and require
efficient summarization for quick comprehension. To address this challenge, we
investigate the need for structured planning in legal case summarization,
particularly through event-centric representations that reflect the narrative
nature of legal case documents. We propose our framework, CoPERLex, which
operates in three stages: first, it performs content selection to identify
crucial information from the judgment; second, the selected content is utilized
to generate intermediate plans through event-centric representations modeled as
Subject-Verb-Object tuples; and finally, it generates coherent summaries based
on both the content and the structured plan. Our experiments on four legal
summarization datasets demonstrate the effectiveness of integrating content
selection and planning components, highlighting the advantages of event-centric
plans over traditional entity-centric approaches in the context of legal
judgements.

摘要：法律專業人士常常為冗長的判決書所苦，需要有效率的摘要以快速理解。為了應對這個挑戰，我們探討法律案例摘要中結構化規劃的必要性，特別是透過以事件為中心的表述，反映法律案例文件的敘事性質。我們提出我們的架構 CoPERLex，它分三個階段運作：首先，它執行內容選擇以識別判決書中的關鍵資訊；其次，選定的內容用於透過建模為「主詞-動詞-受詞」組的以事件為中心的表述來產生中間計畫；最後，它根據內容和結構化計畫產生連貫的摘要。我們對四個法律摘要資料集的實驗證明了整合內容選擇和規劃組件的有效性，突顯了以事件為中心的計畫在法律判決的背景下優於傳統以實體為中心的途徑。

##### **MedSlice: Fine-Tuned Large Language Models for Secure Clinical Note Sectioning**
2501.14105v1 by Joshua Davis, Thomas Sounack, Kate Sciacca, Jessie M Brain, Brigitte N Durieux, Nicole D Agaronnik, Charlotta Lindvall

Extracting sections from clinical notes is crucial for downstream analysis
but is challenging due to variability in formatting and labor-intensive nature
of manual sectioning. While proprietary large language models (LLMs) have shown
promise, privacy concerns limit their accessibility. This study develops a
pipeline for automated note sectioning using open-source LLMs, focusing on
three sections: History of Present Illness, Interval History, and Assessment
and Plan. We fine-tuned three open-source LLMs to extract sections using a
curated dataset of 487 progress notes, comparing results relative to
proprietary models (GPT-4o, GPT-4o mini). Internal and external validity were
assessed via precision, recall and F1 score. Fine-tuned Llama 3.1 8B
outperformed GPT-4o (F1=0.92). On the external validity test set, performance
remained high (F1= 0.85). Fine-tuned open-source LLMs can surpass proprietary
models in clinical note sectioning, offering advantages in cost, performance,
and accessibility.

摘要：從臨床記錄中萃取區塊對於下游分析至關重要，但由於格式變異和手動分區的勞力密集性質，這是一項挑戰。專有大型語言模型 (LLM) 已展現潛力，但隱私問題限制了其可及性。本研究開發了一個使用開放原始碼 LLM 的自動化記錄分區管線，專注於三個區塊：現病史、間隔病史以及評估和計畫。我們微調了三個開放原始碼 LLM 以使用 487 個進度記錄的精選資料集萃取區塊，並將結果與專有模型 (GPT-4o、GPT-4o mini) 進行比較。內部和外部效度透過準確度、召回率和 F1 分數進行評估。微調後的 Llama 3.1 8B 優於 GPT-4o (F1=0.92)。在外部效度測試集中，效能仍然很高 (F1= 0.85)。微調後的開放原始碼 LLM 能在臨床記錄分區中超越專有模型，在成本、效能和可及性方面提供優勢。

##### **Communicating Activations Between Language Model Agents**
2501.14082v1 by Vignav Ramesh, Kenneth Li

Communication between multiple language model (LM) agents has been shown to
scale up the reasoning ability of LMs. While natural language has been the
dominant medium for inter-LM communication, it is not obvious this should be
the standard: not only does natural language communication incur high inference
costs that scale quickly with the number of both agents and messages, but also
the decoding process abstracts away too much rich information that could be
otherwise accessed from the internal activations. In this work, we propose a
simple technique whereby LMs communicate via activations; concretely, we pause
an LM $\textit{B}$'s computation at an intermediate layer, combine its current
activation with another LM $\textit{A}$'s intermediate activation via some
function $\textit{f}$, then pass $\textit{f}$'s output into the next layer of
$\textit{B}$ and continue the forward pass till decoding is complete. This
approach scales up LMs on new tasks with zero additional parameters and data,
and saves a substantial amount of compute over natural language communication.
We test our method with various functional forms $\textit{f}$ on two
experimental setups--multi-player coordination games and reasoning
benchmarks--and find that it achieves up to $27.0\%$ improvement over natural
language communication across datasets with $<$$1/4$ the compute, illustrating
the superiority and robustness of activations as an alternative "language" for
communication between LMs.

摘要：多語系語言模型 (LM) 代理之間的溝通已被證實能提升 LM 的推理能力。儘管自然語言一直是 LM 間溝通的主要媒介，但這並不表示自然語言理應成為標準：自然語言溝通不僅會產生高昂的推理成本，且成本會隨著代理和訊息數量快速增加，而且解碼程序會抽象化太多豐富的資訊，否則這些資訊可從內部啟用存取。在這項研究中，我們提出了一種簡單的技術，讓 LM 能透過啟用進行溝通；具體來說，我們暫停 LM $\textit{B}$ 在中間層的運算，透過函數 $\textit{f}$ 將其目前的啟用與另一個 LM $\textit{A}$ 的中間啟用結合，然後將 $\textit{f}$ 的輸出傳遞到 $\textit{B}$ 的下一層，並繼續進行前向傳遞，直到解碼完成。這種方法能讓 LM 在新的任務中擴充，而無需額外的參數和資料，還能比自然語言溝通節省大量的運算量。我們在兩個實驗設置（多玩家協調遊戲和推理基準）上測試了我們的各種函數形式 $\textit{f}$，發現它在資料集上實現了比自然語言溝通高達 $27.0\%$ 的進步，運算量卻不到 $1/4$，這說明了啟用作為 LM 間溝通的另一種「語言」的優越性和穩健性。

##### **Enhancing Biomedical Relation Extraction with Directionality**
2501.14079v1 by Po-Ting Lai, Chih-Hsuan Wei, Shubo Tian, Robert Leaman, Zhiyong Lu

Biological relation networks contain rich information for understanding the
biological mechanisms behind the relationship of entities such as genes,
proteins, diseases, and chemicals. The vast growth of biomedical literature
poses significant challenges updating the network knowledge. The recent
Biomedical Relation Extraction Dataset (BioRED) provides valuable manual
annotations, facilitating the develop-ment of machine-learning and pre-trained
language model approaches for automatically identifying novel document-level
(inter-sentence context) relationships. Nonetheless, its annotations lack
directionality (subject/object) for the entity roles, essential for studying
complex biological networks. Herein we annotate the entity roles of the
relationships in the BioRED corpus and subsequently propose a novel multi-task
language model with soft-prompt learning to jointly identify the relationship,
novel findings, and entity roles. Our results in-clude an enriched BioRED
corpus with 10,864 directionality annotations. Moreover, our proposed method
outperforms existing large language models such as the state-of-the-art GPT-4
and Llama-3 on two benchmarking tasks. Our source code and dataset are
available at https://github.com/ncbi-nlp/BioREDirect.

摘要：生物關係網路包含豐富的資訊，用於了解基因、蛋白質、疾病和化學物質等實體關係背後的生物機制。生物醫學文獻的快速成長對更新網路知識構成重大挑戰。最近的生物醫學關係萃取資料集 (BioRED) 提供了有價值的手動註解，促進了機器學習和預先訓練語言模型方法的發展，用於自動識別新的文件層級（句子間脈絡）關係。儘管如此，其註解缺乏實體角色的方向性（主詞/受詞），這對於研究複雜的生物網路至關重要。在此，我們註解了 BioRED 語料庫中關係的實體角色，並隨後提出了一個新穎的多任務語言模型，採用軟提示學習來聯合識別關係、新發現和實體角色。我們的結果包括一個豐富的 BioRED 語料庫，其中包含 10,864 個方向性註解。此外，我們提出的方法優於現有的大型語言模型，例如最先進的 GPT-4 和 Llama-3，在兩個基準任務上。我們的原始碼和資料集可在 https://github.com/ncbi-nlp/BioREDirect 取得。

##### **LLMs are Vulnerable to Malicious Prompts Disguised as Scientific Language**
2501.14073v1 by Yubin Ge, Neeraja Kirtane, Hao Peng, Dilek Hakkani-Tür

As large language models (LLMs) have been deployed in various real-world
settings, concerns about the harm they may propagate have grown. Various
jailbreaking techniques have been developed to expose the vulnerabilities of
these models and improve their safety. This work reveals that many
state-of-the-art proprietary and open-source LLMs are vulnerable to malicious
requests hidden behind scientific language. Specifically, our experiments with
GPT4o, GPT4o-mini, GPT-4, LLama3-405B-Instruct, Llama3-70B-Instruct, Cohere,
Gemini models on the StereoSet data demonstrate that, the models' biases and
toxicity substantially increase when prompted with requests that deliberately
misinterpret social science and psychological studies as evidence supporting
the benefits of stereotypical biases. Alarmingly, these models can also be
manipulated to generate fabricated scientific arguments claiming that biases
are beneficial, which can be used by ill-intended actors to systematically
jailbreak even the strongest models like GPT. Our analysis studies various
factors that contribute to the models' vulnerabilities to malicious requests in
academic language. Mentioning author names and venues enhances the
persuasiveness of some models, and the bias scores can increase as dialogues
progress. Our findings call for a more careful investigation on the use of
scientific data in the training of LLMs.

摘要：隨著大型語言模型 (LLM) 在各種真實世界場景中部署，人們對其可能傳播的危害的擔憂也隨之增加。已經開發了各種越獄技術來揭露這些模型的漏洞並提高其安全性。這項工作揭示了許多最先進的專有和開源 LLM 容易受到隱藏在科學語言背後的惡意請求的攻擊。具體來說，我們對 StereoSet 數據上的 GPT4o、GPT4o-mini、GPT-4、LLama3-405B-Instruct、Llama3-70B-Instruct、Cohere、Gemini 模型的實驗表明，當使用故意將社會科學和心理學研究誤解為支持刻板印象偏見好處的證據的請求時，模型的偏見和毒性會大幅增加。令人擔憂的是，這些模型還可以被操縱以產生虛假的科學論據，聲稱偏見是有益的，這可以被心懷不軌的人用來系統性地越獄甚至像 GPT 這樣的最強大的模型。我們的分析研究了導致模型容易受到學術語言中的惡意請求攻擊的各種因素。提及作者姓名和場景會增強某些模型的說服力，並且隨著對話的進行，偏見分數可能會增加。我們的研究結果要求對 LLM 訓練中科學數據的使用進行更仔細的調查。

##### **Revisiting CLIP: Efficient Alignment of 3D MRI and Tabular Data using Domain-Specific Foundation Models**
2501.14051v1 by Jakob Krogh Petersen, Valdemar Licht, Mads Nielsen, Asbjørn Munk

Multi-modal models require aligned, shared embedding spaces. However, common
CLIP-based approaches need large amounts of samples and do not natively support
3D or tabular data, both of which are crucial in the medical domain. To address
these issues, we revisit CLIP-style alignment by training a domain-specific 3D
foundation model as an image encoder and demonstrate that modality alignment is
feasible with only 62 MRI scans. Our approach is enabled by a simple embedding
accumulation strategy required for training in 3D, which scales the amount of
negative pairs across batches in order to stabilize training. We perform a
thorough evaluation of various design choices, including the choice of backbone
and loss functions, and evaluate the proposed methodology on zero-shot
classification and image-retrieval tasks. While zero-shot image-retrieval
remains challenging, zero-shot classification results demonstrate that the
proposed approach can meaningfully align the representations of 3D MRI with
tabular data.

摘要：多模態模型需要對齊的共用嵌入空間。然而，常見的基於 CLIP 的方法需要大量的樣本，並且原生不支援 3D 或表格資料，而這兩者在醫療領域中都至關重要。為了解決這些問題，我們透過訓練一個領域特定的 3D 基礎模型作為影像編碼器，重新檢視 CLIP 風格的對齊，並證明只要 62 個 MRI 掃描即可達成模態對齊。我們的做法得益於一個簡單的嵌入累積策略，這是 3D 訓練所必需的，它會調整批次中的負對數量以穩定訓練。我們對各種設計選擇進行了徹底的評估，包括主幹和損失函數的選擇，並在零樣本分類和影像檢索任務上評估所提出的方法。儘管零樣本影像檢索仍然具有挑戰性，但零樣本分類結果證明，所提出的方法可以有意義地將 3D MRI 的表示與表格資料對齊。

##### **GraphRAG under Fire**
2501.14050v1 by Jiacheng Liang, Yuhui Wang, Changjiang Li, Rongyi Zhu, Tanqiu Jiang, Neil Gong, Ting Wang

GraphRAG advances retrieval-augmented generation (RAG) by structuring
external knowledge as multi-scale knowledge graphs, enabling language models to
integrate both broad context and granular details in their reasoning. While
GraphRAG has demonstrated success across domains, its security implications
remain largely unexplored. To bridge this gap, this work examines GraphRAG's
vulnerability to poisoning attacks, uncovering an intriguing security paradox:
compared to conventional RAG, GraphRAG's graph-based indexing and retrieval
enhance resilience against simple poisoning attacks; meanwhile, the same
features also create new attack surfaces. We present GRAGPoison, a novel attack
that exploits shared relations in the knowledge graph to craft poisoning text
capable of compromising multiple queries simultaneously. GRAGPoison employs
three key strategies: i) relation injection to introduce false knowledge, ii)
relation enhancement to amplify poisoning influence, and iii) narrative
generation to embed malicious content within coherent text. Empirical
evaluation across diverse datasets and models shows that GRAGPoison
substantially outperforms existing attacks in terms of effectiveness (up to 98%
success rate) and scalability (using less than 68% poisoning text). We also
explore potential defensive measures and their limitations, identifying
promising directions for future research.

摘要：GraphRAG 透過將外部知識結構化為多尺度知識圖譜，推動了檢索增強生成 (RAG)，使語言模型能夠在其推理中整合廣泛的背景和細微的細節。儘管 GraphRAG 在各個領域都已展現出成功，但其安全性影響在很大程度上仍未被探索。為了彌補這一差距，本研究探討了 GraphRAG 對投毒攻擊的脆弱性，揭示了一個有趣的安全悖論：與傳統的 RAG 相比，GraphRAG 基於圖表的索引和檢索增強了對簡單投毒攻擊的韌性；同時，相同的特徵也創造了新的攻擊面。我們提出了 GRAGPoison，這是一種新穎的攻擊，它利用知識圖譜中的共享關係來製作中毒文本，能夠同時危害多個查詢。GRAGPoison 採用了三項關鍵策略：i) 關係注入以引入錯誤的知識，ii) 關係增強以擴大投毒影響，以及 iii) 敘事生成以將惡意內容嵌入連貫的文本中。在各種數據集和模型上的經驗評估表明，GRAGPoison 在有效性（成功率高達 98%）和可擴展性（使用不到 68% 的投毒文本）方面都明顯優於現有的攻擊。我們還探討了潛在的防禦措施及其局限性，確定了未來研究的有希望的方向。

##### **SIDDA: SInkhorn Dynamic Domain Adaptation for Image Classification with Equivariant Neural Networks**
2501.14048v1 by Sneh Pandya, Purvik Patel, Brian D. Nord, Mike Walmsley, Aleksandra Ćiprijanović

Modern neural networks (NNs) often do not generalize well in the presence of
a "covariate shift"; that is, in situations where the training and test data
distributions differ, but the conditional distribution of classification labels
remains unchanged. In such cases, NN generalization can be reduced to a problem
of learning more domain-invariant features. Domain adaptation (DA) methods
include a range of techniques aimed at achieving this; however, these methods
have struggled with the need for extensive hyperparameter tuning, which then
incurs significant computational costs. In this work, we introduce SIDDA, an
out-of-the-box DA training algorithm built upon the Sinkhorn divergence, that
can achieve effective domain alignment with minimal hyperparameter tuning and
computational overhead. We demonstrate the efficacy of our method on multiple
simulated and real datasets of varying complexity, including simple shapes,
handwritten digits, and real astronomical observations. SIDDA is compatible
with a variety of NN architectures, and it works particularly well in improving
classification accuracy and model calibration when paired with equivariant
neural networks (ENNs). We find that SIDDA enhances the generalization
capabilities of NNs, achieving up to a $\approx40\%$ improvement in
classification accuracy on unlabeled target data. We also study the efficacy of
DA on ENNs with respect to the varying group orders of the dihedral group
$D_N$, and find that the model performance improves as the degree of
equivariance increases. Finally, we find that SIDDA enhances model calibration
on both source and target data--achieving over an order of magnitude
improvement in the ECE and Brier score. SIDDA's versatility, combined with its
automated approach to domain alignment, has the potential to advance
multi-dataset studies by enabling the development of highly generalizable
models.

摘要：<paragraph>現代神經網路 (NN) 在出現「協變位移」時通常無法很好地概化；也就是說，在訓練和測試資料分佈不同，但分類標籤的條件分佈保持不變的情況下。在這種情況下，NN 概化可以簡化為學習更多領域不變特徵的問題。領域適應 (DA) 方法包括一系列旨在實現此目的的技術；然而，這些方法一直難以滿足廣泛的超參數調整需求，這會產生大量的運算成本。在這項工作中，我們介紹了 SIDDA，一種建立在辛霍恩散度上的開箱即用 DA 訓練演算法，它可以在最小的超參數調整和運算開銷下實現有效的領域對齊。我們在多個不同複雜程度的模擬和真實資料集上展示了我們方法的功效，包括簡單形狀、手寫數字和真實的天文觀測。SIDDA 與各種 NN 架構相容，並且在與等變神經網路 (ENN) 配對時，特別能改善分類準確度和模型校準。我們發現 SIDDA 增強了 NN 的概化能力，在未標記目標資料上的分類準確度提升了約 40%。我們還研究了 DA 對 ENN 的功效，相對於二面體群 $D_N$ 的不同群階，我們發現隨著等變程度的增加，模型效能也會提升。最後，我們發現 SIDDA 增強了來源和目標資料的模型校準，在 ECE 和布賴爾分數上獲得了數量級的改進。SIDDA 的多功能性，加上其自動化的領域對齊方法，有潛力透過促進高度可概化的模型開發，來推動多資料集研究。</paragraph>

##### **Leveraging Large Language Models to Analyze Emotional and Contextual Drivers of Teen Substance Use in Online Discussions**
2501.14037v1 by Jianfeng Zhu, Ruoming Jin, Hailong Jiang, Yulan Wang, Xinyu Zhang, Karin G. Coifman

Adolescence is a critical stage often linked to risky behaviors, including
substance use, with significant developmental and public health implications.
Social media provides a lens into adolescent self-expression, but interpreting
emotional and contextual signals remains complex. This study applies Large
Language Models (LLMs) to analyze adolescents' social media posts, uncovering
emotional patterns (e.g., sadness, guilt, fear, joy) and contextual factors
(e.g., family, peers, school) related to substance use. Heatmap and machine
learning analyses identified key predictors of substance use-related posts.
Negative emotions like sadness and guilt were significantly more frequent in
substance use contexts, with guilt acting as a protective factor, while shame
and peer influence heightened substance use risk. Joy was more common in
non-substance use discussions. Peer influence correlated strongly with sadness,
fear, and disgust, while family and school environments aligned with
non-substance use. Findings underscore the importance of addressing emotional
vulnerabilities and contextual influences, suggesting that collaborative
interventions involving families, schools, and communities can reduce risk
factors and foster healthier adolescent development.

摘要：青春期是與風險行為（包括物質使用）常有關聯的關鍵階段，對發展和公共衛生具有重大影響。
社群媒體提供了一個觀察青少年自我表達的視角，但解讀情緒和脈絡信號仍然很複雜。本研究採用大型語言模型（LLM）來分析青少年的社群媒體貼文，揭露與物質使用相關的情緒模式（例如：悲傷、罪惡感、恐懼、快樂）和脈絡因素（例如：家庭、同儕、學校）。熱點圖和機器學習分析找出物質使用相關貼文的關鍵預測因子。在物質使用脈絡中，悲傷和罪惡感等負面情緒顯著更頻繁，罪惡感具有保護作用，而羞恥感和同儕影響則會增加物質使用風險。在非物質使用討論中，快樂更為常見。同儕影響與悲傷、恐懼和厭惡密切相關，而家庭和學校環境則與非物質使用一致。研究結果強調了處理情緒脆弱性和脈絡影響的重要性，並表明涉及家庭、學校和社區的合作干預可以降低風險因素，並促進更健康的青少年發展。

##### **Human-Alignment Influences the Utility of AI-assisted Decision Making**
2501.14035v1 by Nina L. Corvelo Benz, Manuel Gomez Rodriguez

Whenever an AI model is used to predict a relevant (binary) outcome in
AI-assisted decision making, it is widely agreed that, together with each
prediction, the model should provide an AI confidence value. However, it has
been unclear why decision makers have often difficulties to develop a good
sense on when to trust a prediction using AI confidence values. Very recently,
Corvelo Benz and Gomez Rodriguez have argued that, for rational decision
makers, the utility of AI-assisted decision making is inherently bounded by the
degree of alignment between the AI confidence values and the decision maker's
confidence on their own predictions. In this work, we empirically investigate
to what extent the degree of alignment actually influences the utility of
AI-assisted decision making. To this end, we design and run a large-scale human
subject study (n=703) where participants solve a simple decision making task -
an online card game - assisted by an AI model with a steerable degree of
alignment. Our results show a positive association between the degree of
alignment and the utility of AI-assisted decision making. In addition, our
results also show that post-processing the AI confidence values to achieve
multicalibration with respect to the participants' confidence on their own
predictions increases both the degree of alignment and the utility of
AI-assisted decision making.

摘要：每當 AI 模型用於預測 AI 輔助決策中的相關（二元）結果時，人們普遍同意，除了每個預測外，模型還應提供 AI 信心值。然而，一直不清楚為何決策者經常難以培養在何時使用 AI 信心值來信任預測的良好意識。最近，Corvelo Benz 和 Gomez Rodriguez 提出，對於理性決策者而言，AI 輔助決策的效用本質上受限於 AI 信心值與決策者對自己預測的信心之間的一致性程度。在這項工作中，我們實證研究了一致性程度實際上在多大程度上影響 AI 輔助決策的效用。為此，我們設計並執行了一項大規模的人類受試者研究（n=703），參與者在 AI 模型的協助下解決一個簡單的決策任務——一款線上紙牌遊戲，其中 AI 模型的一致性程度可控。我們的結果顯示一致性程度與 AI 輔助決策的效用之間存在正相關。此外，我們的結果還顯示，對 AI 信心值進行後處理以實現相對於參與者對自己預測的信心的多校準，既能提高一致性程度，又能提高 AI 輔助決策的效用。

##### **CRPO: Confidence-Reward Driven Preference Optimization for Machine Translation**
2501.13927v1 by Guofeng Cui, Pichao Wang, Yang Liu, Zemian Ke, Zhu Liu, Vimal Bhat

Large language models (LLMs) have shown great potential in natural language
processing tasks, but their application to machine translation (MT) remains
challenging due to pretraining on English-centric data and the complexity of
reinforcement learning from human feedback (RLHF). Direct Preference
Optimization (DPO) has emerged as a simpler and more efficient alternative, but
its performance depends heavily on the quality of preference data. To address
this, we propose Confidence-Reward driven Preference Optimization (CRPO), a
novel method that combines reward scores with model confidence to improve data
selection for fine-tuning. CRPO selects challenging sentence pairs where the
model is uncertain or underperforms, leading to more effective learning. While
primarily designed for LLMs, CRPO also generalizes to encoder-decoder models
like NLLB, demonstrating its versatility. Empirical results show that CRPO
outperforms existing methods such as RS-DPO, RSO and MBR score in both
translation accuracy and data efficiency.

摘要：大型語言模型 (LLM) 在自然語言處理任務中展現出極大的潛力，但由於預訓練時以英語為中心資料，以及從人類回饋中進行強化學習的複雜性，其在機器翻譯 (MT) 中的應用仍然具有挑戰性。直接偏好最佳化 (DPO) 已成為一種更簡單且更有效率的替代方案，但其效能高度依賴於偏好資料的品質。為了解決此問題，我們提出以信心獎勵為驅動力的偏好最佳化 (CRPO)，這是一種結合獎勵分數與模型信心的新方法，以改善微調的資料選取。CRPO 選擇模型不確定或表現不佳的具挑戰性句子對，進而帶來更有效的學習。儘管 CRPO 主要設計用於 LLM，但它也適用於編碼器-解碼器模型，例如 NLLB，證明了其多功能性。實證結果顯示，CRPO 在翻譯準確度和資料效率方面均優於現有方法，例如 RS-DPO、RSO 和 MBR 分數。

##### **Can We Generate Images with CoT? Let's Verify and Reinforce Image Generation Step by Step**
2501.13926v1 by Ziyu Guo, Renrui Zhang, Chengzhuo Tong, Zhizheng Zhao, Peng Gao, Hongsheng Li, Pheng-Ann Heng

Chain-of-Thought (CoT) reasoning has been extensively explored in large
models to tackle complex understanding tasks. However, it still remains an open
question whether such strategies can be applied to verifying and reinforcing
image generation scenarios. In this paper, we provide the first comprehensive
investigation of the potential of CoT reasoning to enhance autoregressive image
generation. We focus on three techniques: scaling test-time computation for
verification, aligning model preferences with Direct Preference Optimization
(DPO), and integrating these techniques for complementary effects. Our results
demonstrate that these approaches can be effectively adapted and combined to
significantly improve image generation performance. Furthermore, given the
pivotal role of reward models in our findings, we propose the Potential
Assessment Reward Model (PARM) and PARM++, specialized for autoregressive image
generation. PARM adaptively assesses each generation step through a potential
assessment approach, merging the strengths of existing reward models, and
PARM++ further introduces a reflection mechanism to self-correct the generated
unsatisfactory image. Using our investigated reasoning strategies, we enhance a
baseline model, Show-o, to achieve superior results, with a significant +24%
improvement on the GenEval benchmark, surpassing Stable Diffusion 3 by +15%. We
hope our study provides unique insights and paves a new path for integrating
CoT reasoning with autoregressive image generation. Code and models are
released at https://github.com/ZiyuGuo99/Image-Generation-CoT

摘要：<paragraph>鏈式思考 (CoT) 推理已被廣泛地探索於大型模型中，以解決複雜的理解任務。然而，此類策略是否能應用於驗證和強化影像生成場景，仍是一個開放性的問題。在本文中，我們提供了第一個關於 CoT 推理潛力用於增強自迴歸影像生成的全面調查。我們專注於三種技術：擴展測試時間運算以進行驗證、將模型偏好與直接偏好最佳化 (DPO) 對齊，以及整合這些技術以產生互補效果。我們的結果證明，這些方法可以有效地適應並結合，以顯著改善影像生成效能。此外，鑑於獎勵模型在我們的發現中扮演著關鍵角色，我們提出了潛力評估獎勵模型 (PARM) 和 PARM++，專門用於自迴歸影像生成。PARM 透過潛力評估方法自適應地評估每個生成步驟，合併現有獎勵模型的優點，而 PARM++ 進一步引入反射機制來自我修正生成的令人不滿意的影像。使用我們調查的推理策略，我們增強了一個基準模型 Show-o，以取得優異的結果，在 GenEval 基準上顯著提升 +24%，超越 Stable Diffusion 3 +15%。我們希望我們的研究提供獨特的見解，並為將 CoT 推理與自迴歸影像生成整合開闢一條新途徑。程式碼和模型已於 https://github.com/ZiyuGuo99/Image-Generation-CoT 發布</paragraph>

##### **Towards Robust Multimodal Open-set Test-time Adaptation via Adaptive Entropy-aware Optimization**
2501.13924v1 by Hao Dong, Eleni Chatzi, Olga Fink

Test-time adaptation (TTA) has demonstrated significant potential in
addressing distribution shifts between training and testing data. Open-set
test-time adaptation (OSTTA) aims to adapt a source pre-trained model online to
an unlabeled target domain that contains unknown classes. This task becomes
more challenging when multiple modalities are involved. Existing methods have
primarily focused on unimodal OSTTA, often filtering out low-confidence samples
without addressing the complexities of multimodal data. In this work, we
present Adaptive Entropy-aware Optimization (AEO), a novel framework
specifically designed to tackle Multimodal Open-set Test-time Adaptation
(MM-OSTTA) for the first time. Our analysis shows that the entropy difference
between known and unknown samples in the target domain strongly correlates with
MM-OSTTA performance. To leverage this, we propose two key components:
Unknown-aware Adaptive Entropy Optimization (UAE) and Adaptive Modality
Prediction Discrepancy Optimization (AMP). These components enhance the ability
of model to distinguish unknown class samples during online adaptation by
amplifying the entropy difference between known and unknown samples. To
thoroughly evaluate our proposed methods in the MM-OSTTA setting, we establish
a new benchmark derived from existing datasets. This benchmark includes two
downstream tasks and incorporates five modalities. Extensive experiments across
various domain shift situations demonstrate the efficacy and versatility of the
AEO framework. Additionally, we highlight the strong performance of AEO in
long-term and continual MM-OSTTA settings, both of which are challenging and
highly relevant to real-world applications. Our source code is available at
https://github.com/donghao51/AEO.

摘要：<paragraph>測試時間適應 (TTA) 已展現出在解決訓練資料與測試資料之間的分配轉移上具有顯著潛力。開放集測試時間適應 (OSTTA) 旨在將來源預先訓練的模型線上適應到包含未知類別的未標記目標網域。當涉及多種模式時，這項任務將變得更具挑戰性。現有方法主要關注於單模態 OSTTA，通常會過濾掉低信心樣本，而不會解決多模態資料的複雜性。在這項工作中，我們提出自適應熵感知最佳化 (AEO)，這是一個新穎的架構，專門設計來首次處理多模態開放集測試時間適應 (MM-OSTTA)。我們的分析顯示，目標網域中已知和未知樣本之間的熵差異與 MM-OSTTA 效能密切相關。為了利用這一點，我們提出了兩個關鍵組成部分：未知感知自適應熵最佳化 (UAE) 和自適應模式預測差異最佳化 (AMP)。這些組成部分增強了模型在線上適應期間區分未知類別樣本的能力，方法是擴大已知和未知樣本之間的熵差異。為了在 MM-OSTTA 設定中徹底評估我們提出的方法，我們建立了一個源自現有資料集的新基準。此基準包含兩個下游任務並納入了五種模式。在各種領域轉移情況下的廣泛實驗證明了 AEO 架構的效能和多功能性。此外，我們強調了 AEO 在長期和持續的 MM-OSTTA 設定中的強勁效能，這兩者都具有挑戰性，並且與實際應用高度相關。我們的原始碼可在 https://github.com/donghao51/AEO 取得。</paragraph>

##### **The Breeze 2 Herd of Models: Traditional Chinese LLMs Based on Llama with Vision-Aware and Function-Calling Capabilities**
2501.13921v1 by Chan-Jan Hsu, Chia-Sheng Liu, Meng-Hsi Chen, Muxi Chen, Po-Chun Hsu, Yi-Chang Chen, Da-Shan Shiu

Breeze 2 is a suite of advanced multi-modal language models, available in 3B
and 8B parameter configurations, specifically designed to enhance Traditional
Chinese language representation. Building upon the Llama 3, Breeze 2 continues
pretraining on an extensive corpus to enhance the linguistic and cultural
heritage of Traditional Chinese. It incorporates vision-aware capabilities
through a visual encoder and a bridge module, and supports function-calling via
prompt templates and post-training on function-calling data. The effectiveness
of Breeze 2 is benchmarked across various tasks, including Taiwan general
knowledge, instruction-following, long context, function calling, and vision
understanding. Furthermore, we showcase the capabilities of the its 3B model in
a mobile application. We are publicly releasing all Breeze 2 models under the
Llama 3 Community License.

摘要：Breeze 2 是一套進階的多模態語言模型，提供 3B 和 8B 參數配置，專門設計用於增強繁體中文語言表示。Breeze 2 建立在 Llama 3 的基礎上，持續在廣泛的語料庫上進行預訓練，以增強繁體中文的語言和文化遺產。它透過視覺編碼器和橋接模組整合了視覺感知能力，並透過提示範本和功能呼叫資料的後續訓練支援功能呼叫。Breeze 2 的有效性已針對各種任務進行基準測試，包括台灣一般知識、遵循指示、長篇語境、功能呼叫和視覺理解。此外，我們在行動應用程式中展示其 3B 模型的功能。我們在 Llama 3 社群授權下公開發布所有 Breeze 2 模型。

##### **IMAGINE-E: Image Generation Intelligence Evaluation of State-of-the-art Text-to-Image Models**
2501.13920v1 by Jiayi Lei, Renrui Zhang, Xiangfei Hu, Weifeng Lin, Zhen Li, Wenjian Sun, Ruoyi Du, Le Zhuo, Zhongyu Li, Xinyue Li, Shitian Zhao, Ziyu Guo, Yiting Lu, Peng Gao, Hongsheng Li

With the rapid development of diffusion models, text-to-image(T2I) models
have made significant progress, showcasing impressive abilities in prompt
following and image generation. Recently launched models such as FLUX.1 and
Ideogram2.0, along with others like Dall-E3 and Stable Diffusion 3, have
demonstrated exceptional performance across various complex tasks, raising
questions about whether T2I models are moving towards general-purpose
applicability. Beyond traditional image generation, these models exhibit
capabilities across a range of fields, including controllable generation, image
editing, video, audio, 3D, and motion generation, as well as computer vision
tasks like semantic segmentation and depth estimation. However, current
evaluation frameworks are insufficient to comprehensively assess these models'
performance across expanding domains. To thoroughly evaluate these models, we
developed the IMAGINE-E and tested six prominent models: FLUX.1, Ideogram2.0,
Midjourney, Dall-E3, Stable Diffusion 3, and Jimeng. Our evaluation is divided
into five key domains: structured output generation, realism, and physical
consistency, specific domain generation, challenging scenario generation, and
multi-style creation tasks. This comprehensive assessment highlights each
model's strengths and limitations, particularly the outstanding performance of
FLUX.1 and Ideogram2.0 in structured and specific domain tasks, underscoring
the expanding applications and potential of T2I models as foundational AI
tools. This study provides valuable insights into the current state and future
trajectory of T2I models as they evolve towards general-purpose usability.
Evaluation scripts will be released at https://github.com/jylei16/Imagine-e.

摘要：<paragraph>隨著擴散模型的快速發展，文字轉圖像 (T2I) 模型已取得顯著進展，在提示追蹤和影像生成方面展現令人印象深刻的能力。最近推出的模型，如 FLUX.1 和 Ideogram2.0，以及 Dall-E3 和 Stable Diffusion 3 等其他模型，已在各種複雜任務中展現出色的效能，引發 T2I 模型是否正朝向通用適用性邁進的疑問。除了傳統的影像生成外，這些模型在可控生成、影像編輯、影片、音訊、3D 和動作生成，以及語意分割和深度估計等電腦視覺任務中展現出跨領域的能力。然而，目前的評估架構不足以全面評估這些模型在擴展領域中的效能。為了徹底評估這些模型，我們開發了 IMAGINE-E，並測試了六個傑出的模型：FLUX.1、Ideogram2.0、Midjourney、Dall-E3、Stable Diffusion 3 和 Jimeng。我們的評估分為五個關鍵領域：結構化輸出生成、真實感和物理一致性、特定領域生成、具挑戰性的場景生成和多樣式創作任務。此綜合評估突顯了每個模型的優勢和限制，特別是 FLUX.1 和 Ideogram2.0 在結構化和特定領域任務中的出色效能，強調了 T2I 模型作為基礎 AI 工具的擴展應用和潛力。本研究提供了對 T2I 模型當前狀態和未來軌跡的寶貴見解，因為它們朝向通用可用性演進。評估腳本將在 https://github.com/jylei16/Imagine-e 發布。</paragraph>

##### **Temporal Preference Optimization for Long-Form Video Understanding**
2501.13919v1 by Rui Li, Xiaohan Wang, Yuhui Zhang, Zeyu Wang, Serena Yeung-Levy

Despite significant advancements in video large multimodal models
(video-LMMs), achieving effective temporal grounding in long-form videos
remains a challenge for existing models. To address this limitation, we propose
Temporal Preference Optimization (TPO), a novel post-training framework
designed to enhance the temporal grounding capabilities of video-LMMs through
preference learning. TPO adopts a self-training approach that enables models to
differentiate between well-grounded and less accurate temporal responses by
leveraging curated preference datasets at two granularities: localized temporal
grounding, which focuses on specific video segments, and comprehensive temporal
grounding, which captures extended temporal dependencies across entire video
sequences. By optimizing on these preference datasets, TPO significantly
enhances temporal understanding while reducing reliance on manually annotated
data. Extensive experiments on three long-form video understanding
benchmarks--LongVideoBench, MLVU, and Video-MME--demonstrate the effectiveness
of TPO across two state-of-the-art video-LMMs. Notably, LLaVA-Video-TPO
establishes itself as the leading 7B model on the Video-MME benchmark,
underscoring the potential of TPO as a scalable and efficient solution for
advancing temporal reasoning in long-form video understanding. Project page:
https://ruili33.github.io/tpo_website.

摘要：儘管在視訊大型多模態模型（video-LMMs）中取得顯著進展，但在長篇影片中實現有效的時間基礎仍是現有模型的挑戰。為了解決此限制，我們提出時間偏好最佳化（TPO），這是一個新穎的後訓練架構，旨在透過偏好學習增強 video-LMMs 的時間基礎能力。TPO 採用自訓練方法，使模型能夠透過利用兩個粒度層級的精選偏好資料集來區分基礎良好的時間回應與較不準確的時間回應：局部時間基礎，專注於特定影片片段，以及全面時間基礎，擷取整個影片序列中延伸的時間依賴性。透過最佳化這些偏好資料集，TPO 大幅增強時間理解，同時減少對手動註解資料的依賴。在三個長篇影片理解基準測試（LongVideoBench、MLVU 和 Video-MME）上進行的大量實驗證明了 TPO 在兩個最先進的 video-LMMs 中的有效性。值得注意的是，LLaVA-Video-TPO 在 Video-MME 基準測試中確立了自己作為領先的 7B 模型，突顯了 TPO 作為可擴充且有效解決方案的潛力，可促進長篇影片理解中的時間推理。專案頁面：https://ruili33.github.io/tpo_website。

##### **Improving Video Generation with Human Feedback**
2501.13918v1 by Jie Liu, Gongye Liu, Jiajun Liang, Ziyang Yuan, Xiaokun Liu, Mingwu Zheng, Xiele Wu, Qiulin Wang, Wenyu Qin, Menghan Xia, Xintao Wang, Xiaohong Liu, Fei Yang, Pengfei Wan, Di Zhang, Kun Gai, Yujiu Yang, Wanli Ouyang

Video generation has achieved significant advances through rectified flow
techniques, but issues like unsmooth motion and misalignment between videos and
prompts persist. In this work, we develop a systematic pipeline that harnesses
human feedback to mitigate these problems and refine the video generation
model. Specifically, we begin by constructing a large-scale human preference
dataset focused on modern video generation models, incorporating pairwise
annotations across multi-dimensions. We then introduce VideoReward, a
multi-dimensional video reward model, and examine how annotations and various
design choices impact its rewarding efficacy. From a unified reinforcement
learning perspective aimed at maximizing reward with KL regularization, we
introduce three alignment algorithms for flow-based models by extending those
from diffusion models. These include two training-time strategies: direct
preference optimization for flow (Flow-DPO) and reward weighted regression for
flow (Flow-RWR), and an inference-time technique, Flow-NRG, which applies
reward guidance directly to noisy videos. Experimental results indicate that
VideoReward significantly outperforms existing reward models, and Flow-DPO
demonstrates superior performance compared to both Flow-RWR and standard
supervised fine-tuning methods. Additionally, Flow-NRG lets users assign custom
weights to multiple objectives during inference, meeting personalized video
quality needs. Project page: https://gongyeliu.github.io/videoalign.

摘要：影片生成透過修正流技術已獲得重大進展，但影片與提示之間的不流暢動態和未對齊等問題仍然存在。在本文中，我們開發了一個系統化管道，利用人類回饋來減輕這些問題並改善影片生成模型。具體來說，我們首先建立一個大型人類偏好資料集，專注於現代影片生成模型，並結合跨多維度的成對註解。接著我們介紹 VideoReward，一個多維影片獎勵模型，並探討註解和各種設計選擇如何影響其獎勵效能。從統一的強化學習觀點，旨在最大化具有 KL 正規化的獎勵，我們透過擴充擴散模型的演算法，為基於流的模型引入了三種對齊演算法。這些演算法包括兩個訓練時間策略：流的直接偏好最佳化 (Flow-DPO) 和流的獎勵加權迴歸 (Flow-RWR)，以及一個推論時間技術 Flow-NRG，它將獎勵引導直接應用於有雜訊的影片。實驗結果顯示，VideoReward 明顯優於現有的獎勵模型，而 Flow-DPO 與 Flow-RWR 和標準監督微調方法相比，表現出優異的效能。此外，Flow-NRG 讓使用者在推論期間為多個目標分配自訂權重，滿足個人化的影片品質需求。專案頁面：https://gongyeliu.github.io/videoalign。

##### **Analysis of Indic Language Capabilities in LLMs**
2501.13912v1 by Aatman Vaidya, Tarunima Prabhakar, Denny George, Swair Shah

This report evaluates the performance of text-in text-out Large Language
Models (LLMs) to understand and generate Indic languages. This evaluation is
used to identify and prioritize Indic languages suited for inclusion in safety
benchmarks. We conduct this study by reviewing existing evaluation studies and
datasets; and a set of twenty-eight LLMs that support Indic languages. We
analyze the LLMs on the basis of the training data, license for model and data,
type of access and model developers. We also compare Indic language performance
across evaluation datasets and find that significant performance disparities in
performance across Indic languages. Hindi is the most widely represented
language in models. While model performance roughly correlates with number of
speakers for the top five languages, the assessment after that varies.

摘要：這份報告評估文本輸入文本輸出的大型語言模型 (LLM) 了解和產生印度語言的效能。此評估用於找出並優先處理適合納入安全基準的印度語言。我們透過檢閱現有的評估研究和資料集來進行這項研究；以及支援印度語言的二十八個 LLM。我們根據訓練資料、模型和資料的授權、存取類型和模型開發者來分析 LLM。我們也比較了不同評估資料集的印度語言效能，並發現印度語言的效能有顯著的差異。印地語是模型中最廣泛代表的語言。儘管模型效能大致與前五名語言的使用者人數相關，但此後的評估則有所不同。

##### **Transfer Learning of Surrogate Models via Domain Affine Transformation Across Synthetic and Real-World Benchmarks**
2501.14012v1 by Shuaiqun Pan, Diederick Vermetten, Manuel López-Ibáñez, Thomas Bäck, Hao Wang

Surrogate models are frequently employed as efficient substitutes for the
costly execution of real-world processes. However, constructing a high-quality
surrogate model often demands extensive data acquisition. A solution to this
issue is to transfer pre-trained surrogate models for new tasks, provided that
certain invariances exist between tasks. This study focuses on transferring
non-differentiable surrogate models (e.g., random forest) from a source
function to a target function, where we assume their domains are related by an
unknown affine transformation, using only a limited amount of transfer data
points evaluated on the target. Previous research attempts to tackle this
challenge for differentiable models, e.g., Gaussian process regression, which
minimizes the empirical loss on the transfer data by tuning the affine
transformations. In this paper, we extend the previous work to the random
forest model and assess its effectiveness on a widely-used artificial problem
set - Black-Box Optimization Benchmark (BBOB) testbed, and on four real-world
transfer learning problems. The results highlight the significant practical
advantages of the proposed method, particularly in reducing both the data
requirements and computational costs of training surrogate models for complex
real-world scenarios.

摘要：代理模型經常被用作真實世界過程中昂貴執行的高效替代品。然而，構建一個高品質的代理模型通常需要廣泛的數據採集。這個問題的解決方案是轉移預先訓練好的代理模型以執行新任務，前提是任務之間存在某些不變性。本研究重點在於從源函數轉移不可微分的代理模型（例如，隨機森林）到目標函數，其中我們假設它們的域由未知的仿射轉換相關聯，僅使用在目標上評估的有限數量的轉移數據點。先前的研究嘗試解決可微分模型的這個挑戰，例如，高斯過程回歸，它通過調整仿射轉換來最小化轉移數據的經驗損失。在本文中，我們將先前的研究延伸到隨機森林模型，並評估其在廣泛使用的人工問題集 - 黑盒最佳化基準 (BBOB) 測試平台以及四個真實世界的轉移學習問題上的有效性。結果突出了所提出方法的顯著實用優勢，特別是在減少複雜現實世界場景中訓練代理模型的數據需求和計算成本方面。

##### **QuanTaxo: A Quantum Approach to Self-Supervised Taxonomy Expansion**
2501.14011v1 by Sahil Mishra, Avi Patni, Niladri Chatterjee, Tanmoy Chakraborty

A taxonomy is a hierarchical graph containing knowledge to provide valuable
insights for various web applications. Online retail organizations like
Microsoft and Amazon utilize taxonomies to improve product recommendations and
optimize advertisement by enhancing query interpretation. However, the manual
construction of taxonomies requires significant human effort. As web content
continues to expand at an unprecedented pace, existing taxonomies risk becoming
outdated, struggling to incorporate new and emerging information effectively.
As a consequence, there is a growing need for dynamic taxonomy expansion to
keep them relevant and up-to-date. Existing taxonomy expansion methods often
rely on classical word embeddings to represent entities. However, these
embeddings fall short in capturing hierarchical polysemy, where an entity's
meaning can vary based on its position in the hierarchy and its surrounding
context. To address this challenge, we introduce QuanTaxo, an innovative
quantum-inspired framework for taxonomy expansion. QuanTaxo encodes entity
representations in quantum space, effectively modeling hierarchical polysemy by
leveraging the principles of Hilbert space to capture interference effects
between entities, yielding richer and more nuanced representations.
Comprehensive experiments on four real-world benchmark datasets show that
QuanTaxo significantly outperforms classical embedding models, achieving
substantial improvements of 18.45% in accuracy, 20.5% in Mean Reciprocal Rank,
and 17.87% in Wu & Palmer metrics across eight classical embedding-based
baselines. We further highlight the superiority of QuanTaxo through extensive
ablation and case studies.

摘要：<paragraph>分類法是一個階層圖，包含知識，可為各種網路應用程式提供有價值的見解。微軟和亞馬遜等線上零售組織利用分類法來改善產品推薦，並透過加強查詢詮釋來最佳化廣告。然而，分類法的建置需要大量人力。隨著網路內容持續以空前的速度擴充，現有的分類法有過時的風險，難以有效納入新興資訊。因此，對於動態分類法擴充的需求日益增加，以保持其相關性和時效性。現有的分類法擴充方法通常依賴傳統的詞彙嵌入來表示實體。然而，這些嵌入無法捕捉階層多義性，其中實體的意義會根據其在階層中的位置及其周遭脈絡而有所不同。為了應對這項挑戰，我們引入了 QuanTaxo，一個創新的量子啟發式分類法擴充架構。QuanTaxo 在量子空間中編碼實體表示，透過利用希爾伯特空間的原理來捕捉實體之間的干擾效應，有效地建模階層多義性，產生更豐富且更細緻的表示。在四個真實世界的基準資料集上的全面實驗顯示，QuanTaxo 明顯優於傳統嵌入模型，在準確度方面提升了 18.45%，在平均倒數排名方面提升了 20.5%，在 Wu & Palmer 指標方面提升了 17.87%，超越了八個基於傳統嵌入的基準。我們進一步透過廣泛的消融和個案研究來強調 QuanTaxo 的優越性。</paragraph>

##### **PointOBB-v3: Expanding Performance Boundaries of Single Point-Supervised Oriented Object Detection**
2501.13898v1 by Peiyuan Zhang, Junwei Luo, Xue Yang, Yi Yu, Qingyun Li, Yue Zhou, Xiaosong Jia, Xudong Lu, Jingdong Chen, Xiang Li, Junchi Yan, Yansheng Li

With the growing demand for oriented object detection (OOD), recent studies
on point-supervised OOD have attracted significant interest. In this paper, we
propose PointOBB-v3, a stronger single point-supervised OOD framework. Compared
to existing methods, it generates pseudo rotated boxes without additional
priors and incorporates support for the end-to-end paradigm. PointOBB-v3
functions by integrating three unique image views: the original view, a resized
view, and a rotated/flipped (rot/flp) view. Based on the views, a scale
augmentation module and an angle acquisition module are constructed. In the
first module, a Scale-Sensitive Consistency (SSC) loss and a Scale-Sensitive
Feature Fusion (SSFF) module are introduced to improve the model's ability to
estimate object scale. To achieve precise angle predictions, the second module
employs symmetry-based self-supervised learning. Additionally, we introduce an
end-to-end version that eliminates the pseudo-label generation process by
integrating a detector branch and introduces an Instance-Aware Weighting (IAW)
strategy to focus on high-quality predictions. We conducted extensive
experiments on the DIOR-R, DOTA-v1.0/v1.5/v2.0, FAIR1M, STAR, and RSAR
datasets. Across all these datasets, our method achieves an average improvement
in accuracy of 3.56% in comparison to previous state-of-the-art methods. The
code will be available at https://github.com/ZpyWHU/PointOBB-v3.

摘要：隨著面向目標偵測 (OOD) 需求的增長，最近對點監督 OOD 的研究引起了極大的興趣。在本文中，我們提出了 PointOBB-v3，一個更強大的單點監督 OOD 框架。與現有方法相比，它在沒有額外先驗知識的情況下生成了偽旋轉框，並結合了對端到端範例的支持。PointOBB-v3 的功能是透過整合三個獨特的影像檢視：原始檢視、縮放檢視和旋轉/翻轉 (rot/flp) 檢視。根據這些檢視，構建了一個比例擴充模組和一個角度擷取模組。在第一個模組中，引入了比例敏感一致性 (SSC) 損失和比例敏感特徵融合 (SSFF) 模組，以提高模型估計物件比例的能力。為了實現精確的角度預測，第二個模組採用了基於對稱的自監督學習。此外，我們引入了端到端版本，透過整合偵測器分支並引入實例感知加權 (IAW) 策略來消除偽標籤生成過程，以專注於高品質預測。我們對 DIOR-R、DOTA-v1.0/v1.5/v2.0、FAIR1M、STAR 和 RSAR 資料集進行了廣泛的實驗。在所有這些資料集中，與先前的最先進方法相比，我們的模型在準確度方面平均提升了 3.56%。程式碼將可在 https://github.com/ZpyWHU/PointOBB-v3 取得。

