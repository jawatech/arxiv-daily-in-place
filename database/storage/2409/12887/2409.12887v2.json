{"2409.12887": {"publish_time": "2024-09-19", "title": "Enhancing Unsupervised Sentence Embeddings via Knowledge-Driven Data Augmentation and Gaussian-Decayed Contrastive Learning", "paper_summary": "Recently, using large language models (LLMs) for data augmentation has led to\nconsiderable improvements in unsupervised sentence embedding models. However,\nexisting methods encounter two primary challenges: limited data diversity and\nhigh data noise. Current approaches often neglect fine-grained knowledge, such\nas entities and quantities, leading to insufficient diversity. Additionally,\nunsupervised data frequently lacks discriminative information, and the\ngenerated synthetic samples may introduce noise. In this paper, we propose a\npipeline-based data augmentation method via LLMs and introduce the\nGaussian-decayed gradient-assisted Contrastive Sentence Embedding (GCSE) model\nto enhance unsupervised sentence embeddings. To tackle the issue of low data\ndiversity, our pipeline utilizes knowledge graphs (KGs) to extract entities and\nquantities, enabling LLMs to generate more diverse, knowledge-enriched samples.\nTo address high data noise, the GCSE model uses a Gaussian-decayed function to\nlimit the impact of false hard negative samples, enhancing the model's\ndiscriminative capability. Experimental results show that our approach achieves\nstate-of-the-art performance in semantic textual similarity (STS) tasks, using\nfewer data samples and smaller LLMs, demonstrating its efficiency and\nrobustness across various models.", "paper_summary_zh": "<paragraph>\u6700\u8fd1\uff0c\u4f7f\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b (LLM) \u8fdb\u884c\u6570\u636e\u6269\u5145\u5df2\u5bfc\u81f4\u65e0\u76d1\u7763\u53e5\u5b50\u5d4c\u5165\u6a21\u578b\u5927\u5e45\u6539\u5584\u3002\u7136\u800c\uff0c\u73b0\u6709\u65b9\u6cd5\u4f1a\u9047\u5230\u4e24\u4e2a\u4e3b\u8981\u6311\u6218\uff1a\u6570\u636e\u591a\u6837\u6027\u6709\u9650\u548c\u6570\u636e\u566a\u97f3\u9ad8\u3002\u5f53\u524d\u65b9\u6cd5\u901a\u5e38\u5ffd\u7565\u7ec6\u7c92\u5ea6\u77e5\u8bc6\uff0c\u4f8b\u5982\u5b9e\u4f53\u548c\u6570\u91cf\uff0c\u5bfc\u81f4\u591a\u6837\u6027\u4e0d\u8db3\u3002\u6b64\u5916\uff0c\u65e0\u76d1\u7763\u6570\u636e\u7ecf\u5e38\u7f3a\u4e4f\u5224\u522b\u4fe1\u606f\uff0c\u5e76\u4e14\u751f\u6210\u7684\u5408\u6210\u6837\u672c\u53ef\u80fd\u4f1a\u5f15\u5165\u566a\u97f3\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u7ba1\u9053\u7684\u6570\u636e\u6269\u5145\u65b9\u6cd5\uff0c\u901a\u8fc7 LLM\uff0c\u5e76\u5f15\u5165\u4e86\u9ad8\u65af\u8870\u51cf\u68af\u5ea6\u8f85\u52a9\u5bf9\u6bd4\u53e5\u5b50\u5d4c\u5165 (GCSE) \u6a21\u578b\u6765\u589e\u5f3a\u65e0\u76d1\u7763\u53e5\u5b50\u5d4c\u5165\u3002\u4e3a\u4e86\u89e3\u51b3\u6570\u636e\u591a\u6837\u6027\u4f4e\u7684\u95ee\u9898\uff0c\u6211\u4eec\u7684\u7ba1\u9053\u5229\u7528\u77e5\u8bc6\u56fe\u8c31 (KG) \u6765\u63d0\u53d6\u5b9e\u4f53\u548c\u6570\u91cf\uff0c\u4f7f LLM \u80fd\u591f\u751f\u6210\u66f4\u591a\u6837\u5316\u3001\u77e5\u8bc6\u4e30\u5bcc\u7684\u6837\u672c\u3002\u4e3a\u4e86\u89e3\u51b3\u6570\u636e\u566a\u97f3\u9ad8\u7684\u95ee\u9898\uff0cGCSE \u6a21\u578b\u4f7f\u7528\u9ad8\u65af\u8870\u51cf\u51fd\u6570\u6765\u9650\u5236\u9519\u8bef\u56f0\u96be\u8d1f\u6837\u672c\u7684\u5f71\u54cd\uff0c\u4ece\u800c\u589e\u5f3a\u6a21\u578b\u7684\u5224\u522b\u80fd\u529b\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u6211\u4eec\u7684\u65b9\u6cd5\u5728\u8bed\u4e49\u6587\u672c\u76f8\u4f3c\u6027 (STS) \u4efb\u52a1\u4e2d\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\uff0c\u4f7f\u7528\u8f83\u5c11\u7684\u6570\u636e\u6837\u672c\u548c\u8f83\u5c0f\u7684 LLM\uff0c\u5c55\u793a\u4e86\u5176\u5728\u5404\u79cd\u6a21\u578b\u4e2d\u7684\u6548\u7387\u548c\u9c81\u68d2\u6027\u3002</paragraph>", "author": "Peichao Lai et.al.", "authors": "Peichao Lai, Zhengfeng Zhang, Wentao Zhang, Fangcheng Fu, Bin Cui", "id": "2409.12887v2", "paper_url": "http://arxiv.org/abs/2409.12887v2", "repo": "null"}}