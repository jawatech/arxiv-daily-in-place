{"2409.06328": {"publish_time": "2024-09-10", "title": "Extracting Paragraphs from LLM Token Activations", "paper_summary": "Generative large language models (LLMs) excel in natural language processing\ntasks, yet their inner workings remain underexplored beyond token-level\npredictions. This study investigates the degree to which these models decide\nthe content of a paragraph at its onset, shedding light on their contextual\nunderstanding. By examining the information encoded in single-token\nactivations, specifically the \"\\textbackslash n\\textbackslash n\" double newline\ntoken, we demonstrate that patching these activations can transfer significant\ninformation about the context of the following paragraph, providing further\ninsights into the model's capacity to plan ahead.", "paper_summary_zh": "\u751f\u6210\u5f0f\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u5728\u81ea\u7136\u8a9e\u8a00\u8655\u7406\u4efb\u52d9\u4e2d\u8868\u73fe\u51fa\u8272\uff0c\u4f46\u5b83\u5011\u7684\u5167\u90e8\u904b\u4f5c\u4ecd\u672a\u88ab\u5145\u5206\u63a2\u7d22\uff0c\u50c5\u6b62\u65bc\u7b26\u865f\u5c64\u7d1a\u7684\u9810\u6e2c\u3002\u672c\u7814\u7a76\u63a2\u8a0e\u9019\u4e9b\u6a21\u578b\u5728\u6bb5\u843d\u958b\u982d\u6c7a\u5b9a\u5167\u5bb9\u7684\u7a0b\u5ea6\uff0c\u9032\u800c\u95e1\u660e\u5b83\u5011\u7684\u4e0a\u4e0b\u6587\u7406\u89e3\u80fd\u529b\u3002\u900f\u904e\u6aa2\u8996\u55ae\u4e00\u7b26\u865f\u6fc0\u6d3b\u4e2d\u7de8\u78bc\u7684\u8cc7\u8a0a\uff0c\u7279\u5225\u662f\u300c\\n\\n\u300d\u96d9\u63db\u884c\u7b26\u865f\uff0c\u6211\u5011\u8b49\u660e\u4fee\u88dc\u9019\u4e9b\u6fc0\u6d3b\u53ef\u4ee5\u50b3\u905e\u5f8c\u7e8c\u6bb5\u843d\u4e0a\u4e0b\u6587\u7684\u986f\u8457\u8cc7\u8a0a\uff0c\u9032\u4e00\u6b65\u4e86\u89e3\u6a21\u578b\u7684\u8d85\u524d\u898f\u5283\u80fd\u529b\u3002", "author": "Nicholas Pochinkov et.al.", "authors": "Nicholas Pochinkov, Angelo Benoit, Lovkush Agarwal, Zainab Ali Majid, Lucile Ter-Minassian", "id": "2409.06328v1", "paper_url": "http://arxiv.org/abs/2409.06328v1", "repo": "null"}}