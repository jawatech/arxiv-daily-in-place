{"2412.04784": {"publish_time": "2024-12-06", "title": "NLP-ADBench: NLP Anomaly Detection Benchmark", "paper_summary": "Anomaly detection (AD) is a critical machine learning task with diverse\napplications in web systems, including fraud detection, content moderation, and\nuser behavior analysis. Despite its significance, AD in natural language\nprocessing (NLP) remains underexplored, limiting advancements in detecting\nanomalies in text data such as harmful content, phishing attempts, or spam\nreviews. In this paper, we introduce NLP-ADBench, the most comprehensive\nbenchmark for NLP anomaly detection (NLP-AD), comprising eight curated datasets\nand evaluations of nineteen state-of-the-art algorithms. These include three\nend-to-end methods and sixteen two-step algorithms that apply traditional\nanomaly detection techniques to language embeddings generated by\nbert-base-uncased and OpenAI's text-embedding-3-large models.\n  Our results reveal critical insights and future directions for NLP-AD.\nNotably, no single model excels across all datasets, highlighting the need for\nautomated model selection. Moreover, two-step methods leveraging\ntransformer-based embeddings consistently outperform specialized end-to-end\napproaches, with OpenAI embeddings demonstrating superior performance over BERT\nembeddings. By releasing NLP-ADBench at\nhttps://github.com/USC-FORTIS/NLP-ADBench, we provide a standardized framework\nfor evaluating NLP-AD methods, fostering the development of innovative\napproaches. This work fills a crucial gap in the field and establishes a\nfoundation for advancing NLP anomaly detection, particularly in the context of\nimproving the safety and reliability of web-based systems.", "paper_summary_zh": "\u7570\u5e38\u5075\u6e2c (AD) \u662f\u4e00\u9805\u91cd\u8981\u7684\u6a5f\u5668\u5b78\u7fd2\u4efb\u52d9\uff0c\u5728\u7db2\u8def\u7cfb\u7d71\u4e2d\u5177\u6709\u591a\u6a23\u5316\u7684\u61c9\u7528\uff0c\u5305\u62ec\u8a50\u6b3a\u5075\u6e2c\u3001\u5167\u5bb9\u5be9\u6838\u548c\u4f7f\u7528\u8005\u884c\u70ba\u5206\u6790\u3002\u5118\u7ba1\u7570\u5e38\u5075\u6e2c\u5177\u6709\u91cd\u8981\u6027\uff0c\u4f46\u81ea\u7136\u8a9e\u8a00\u8655\u7406 (NLP) \u4e2d\u7684\u7570\u5e38\u5075\u6e2c\u4ecd\u672a\u88ab\u5145\u5206\u63a2\u7d22\uff0c\u9019\u9650\u5236\u4e86\u5075\u6e2c\u6587\u5b57\u8cc7\u6599\u4e2d\u7570\u5e38\u73fe\u8c61\u7684\u9032\u5c55\uff0c\u4f8b\u5982\u6709\u5bb3\u5167\u5bb9\u3001\u7db2\u8def\u91e3\u9b5a\u5617\u8a66\u6216\u5783\u573e\u8a55\u8ad6\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u4ecb\u7d39\u4e86 NLP-ADBench\uff0c\u9019\u662f NLP \u7570\u5e38\u5075\u6e2c (NLP-AD) \u6700\u5168\u9762\u7684\u57fa\u6e96\uff0c\u5305\u542b\u516b\u500b\u7b56\u5283\u597d\u7684\u8cc7\u6599\u96c6\u548c\u5341\u4e5d\u7a2e\u6700\u5148\u9032\u6f14\u7b97\u6cd5\u7684\u8a55\u4f30\u3002\u9019\u4e9b\u5305\u62ec\u4e09\u7a2e\u7aef\u5c0d\u7aef\u65b9\u6cd5\u548c\u5341\u516d\u7a2e\u5169\u6b65\u9a5f\u6f14\u7b97\u6cd5\uff0c\u5b83\u5011\u5c07\u50b3\u7d71\u7684\u7570\u5e38\u5075\u6e2c\u6280\u8853\u61c9\u7528\u65bc\u7531 bert-base-uncased \u548c OpenAI \u7684 text-embedding-3-large \u6a21\u578b\u7522\u751f\u7684\u8a9e\u8a00\u5d4c\u5165\u3002\u6211\u5011\u7684\u7d50\u679c\u63ed\u793a\u4e86 NLP-AD \u7684\u95dc\u9375\u898b\u89e3\u548c\u672a\u4f86\u65b9\u5411\u3002\u503c\u5f97\u6ce8\u610f\u7684\u662f\uff0c\u6c92\u6709\u55ae\u4e00\u6a21\u578b\u5728\u6240\u6709\u8cc7\u6599\u96c6\u4e0a\u8868\u73fe\u512a\u7570\uff0c\u9019\u7a81\u986f\u4e86\u81ea\u52d5\u5316\u6a21\u578b\u9078\u64c7\u7684\u5fc5\u8981\u6027\u3002\u6b64\u5916\uff0c\u5229\u7528\u57fa\u65bc Transformer \u7684\u5d4c\u5165\u7684\u5169\u6b65\u9a5f\u65b9\u6cd5\u59cb\u7d42\u512a\u65bc\u5c08\u9580\u7684\u7aef\u5c0d\u7aef\u65b9\u6cd5\uff0c\u800c OpenAI \u5d4c\u5165\u8868\u73fe\u51fa\u512a\u65bc BERT \u5d4c\u5165\u7684\u6548\u80fd\u3002\u900f\u904e\u5728 https://github.com/USC-FORTIS/NLP-ADBench \u4e0a\u767c\u5e03 NLP-ADBench\uff0c\u6211\u5011\u63d0\u4f9b\u4e86\u4e00\u500b\u6a19\u6e96\u5316\u7684\u6846\u67b6\u4f86\u8a55\u4f30 NLP-AD \u65b9\u6cd5\uff0c\u4fc3\u9032\u5275\u65b0\u65b9\u6cd5\u7684\u767c\u5c55\u3002\u9019\u9805\u5de5\u4f5c\u586b\u88dc\u4e86\u8a72\u9818\u57df\u7684\u95dc\u9375\u7a7a\u767d\uff0c\u4e26\u5efa\u7acb\u4e86\u63a8\u9032 NLP \u7570\u5e38\u5075\u6e2c\u7684\u57fa\u790e\uff0c\u7279\u5225\u662f\u5728\u6539\u5584\u57fa\u65bc\u7db2\u8def\u7cfb\u7d71\u7684\u5b89\u5168\u6027\u548c\u53ef\u9760\u6027\u7684\u60c5\u6cc1\u4e0b\u3002", "author": "Yuangang Li et.al.", "authors": "Yuangang Li, Jiaqi Li, Zhuo Xiao, Tiankai Yang, Yi Nian, Xiyang Hu, Yue Zhao", "id": "2412.04784v1", "paper_url": "http://arxiv.org/abs/2412.04784v1", "repo": "https://github.com/usc-fortis/nlp-adbench"}}