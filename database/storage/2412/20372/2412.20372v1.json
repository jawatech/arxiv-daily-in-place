{"2412.20372": {"publish_time": "2024-12-29", "title": "LLM2: Let Large Language Models Harness System 2 Reasoning", "paper_summary": "Large language models (LLMs) have exhibited impressive capabilities across a\nmyriad of tasks, yet they occasionally yield undesirable outputs. We posit that\nthese limitations are rooted in the foundational autoregressive architecture of\nLLMs, which inherently lacks mechanisms for differentiating between desirable\nand undesirable results. Drawing inspiration from the dual-process theory of\nhuman cognition, we introduce LLM2, a novel framework that combines an LLM\n(System 1) with a process-based verifier (System 2). Within LLM2, the LLM is\nresponsible for generating plausible candidates, while the verifier provides\ntimely process-based feedback to distinguish desirable and undesirable outputs.\nThe verifier is trained with a pairwise comparison loss on synthetic\nprocess-supervision data generated through our token quality exploration\nstrategy. Empirical results on mathematical reasoning benchmarks substantiate\nthe efficacy of LLM2, exemplified by an accuracy enhancement from 50.3 to 57.8\n(+7.5) for Llama3-1B on GSM8K. Furthermore, when combined with\nself-consistency, LLM2 achieves additional improvements, boosting major@20\naccuracy from 56.2 to 70.2 (+14.0).", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u5728\u5404\u7a2e\u4efb\u52d9\u4e2d\u8868\u73fe\u51fa\u4ee4\u4eba\u5370\u8c61\u6df1\u523b\u7684\u80fd\u529b\uff0c\u4f46\u5b83\u5011\u5076\u723e\u6703\u7522\u751f\u4e0d\u826f\u7684\u8f38\u51fa\u3002\u6211\u5011\u5047\u8a2d\u9019\u4e9b\u9650\u5236\u6839\u690d\u65bc LLM \u7684\u57fa\u790e\u81ea\u56de\u6b78\u67b6\u69cb\uff0c\u5b83\u672c\u8cea\u4e0a\u7f3a\u4e4f\u5340\u5206\u671f\u671b\u7d50\u679c\u548c\u4e0d\u826f\u7d50\u679c\u7684\u6a5f\u5236\u3002\u5f9e\u4eba\u985e\u8a8d\u77e5\u7684\u96d9\u91cd\u904e\u7a0b\u7406\u8ad6\u4e2d\u6c72\u53d6\u9748\u611f\uff0c\u6211\u5011\u5f15\u5165\u4e86 LLM2\uff0c\u9019\u662f\u4e00\u500b\u65b0\u7a4e\u7684\u6846\u67b6\uff0c\u5b83\u5c07 LLM\uff08\u7cfb\u7d71 1\uff09\u8207\u57fa\u65bc\u6d41\u7a0b\u7684\u9a57\u8b49\u5668\uff08\u7cfb\u7d71 2\uff09\u76f8\u7d50\u5408\u3002\u5728 LLM2 \u4e2d\uff0cLLM \u8ca0\u8cac\u7522\u751f\u5408\u7406\u7684\u5019\u9078\u9805\uff0c\u800c\u9a57\u8b49\u5668\u5247\u63d0\u4f9b\u53ca\u6642\u7684\u57fa\u65bc\u6d41\u7a0b\u7684\u56de\u994b\uff0c\u4ee5\u5340\u5206\u671f\u671b\u8f38\u51fa\u548c\u4e0d\u826f\u8f38\u51fa\u3002\u9a57\u8b49\u5668\u4f7f\u7528\u6210\u5c0d\u6bd4\u8f03\u640d\u5931\u5728\u901a\u904e\u6211\u5011\u7684\u4ee3\u5e63\u54c1\u8cea\u63a2\u7d22\u7b56\u7565\u751f\u6210\u7684\u5408\u6210\u6d41\u7a0b\u76e3\u7763\u6578\u64da\u4e0a\u9032\u884c\u8a13\u7df4\u3002\u6578\u5b78\u63a8\u7406\u57fa\u6e96\u4e0a\u7684\u7d93\u9a57\u7d50\u679c\u8b49\u5be6\u4e86 LLM2 \u7684\u6709\u6548\u6027\uff0cLlama3-1B \u5728 GSM8K \u4e0a\u7684\u6e96\u78ba\u7387\u5f9e 50.3 \u63d0\u5347\u5230 57.8\uff08+7.5\uff09\u5c31\u662f\u4e00\u500b\u4f8b\u5b50\u3002\u6b64\u5916\uff0c\u7576\u8207\u81ea\u6d3d\u6027\u76f8\u7d50\u5408\u6642\uff0cLLM2 \u53ef\u4ee5\u5be6\u73fe\u9032\u4e00\u6b65\u7684\u6539\u9032\uff0c\u5c07 major@20 \u6e96\u78ba\u7387\u5f9e 56.2 \u63d0\u5347\u5230 70.2\uff08+14.0\uff09\u3002", "author": "Cheng Yang et.al.", "authors": "Cheng Yang, Chufan Shi, Siheng Li, Bo Shui, Yujiu Yang, Wai Lam", "id": "2412.20372v1", "paper_url": "http://arxiv.org/abs/2412.20372v1", "repo": "null"}}