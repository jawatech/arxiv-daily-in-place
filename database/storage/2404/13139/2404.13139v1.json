{"2404.13139": {"publish_time": "2024-04-19", "title": "Explainable AI for Fair Sepsis Mortality Predictive Model", "paper_summary": "Artificial intelligence supports healthcare professionals with predictive\nmodeling, greatly transforming clinical decision-making. This study addresses\nthe crucial need for fairness and explainability in AI applications within\nhealthcare to ensure equitable outcomes across diverse patient demographics. By\nfocusing on the predictive modeling of sepsis-related mortality, we propose a\nmethod that learns a performance-optimized predictive model and then employs\nthe transfer learning process to produce a model with better fairness. Our\nmethod also introduces a novel permutation-based feature importance algorithm\naiming at elucidating the contribution of each feature in enhancing fairness on\npredictions. Unlike existing explainability methods concentrating on explaining\nfeature contribution to predictive performance, our proposed method uniquely\nbridges the gap in understanding how each feature contributes to fairness. This\nadvancement is pivotal, given sepsis's significant mortality rate and its role\nin one-third of hospital deaths. Our method not only aids in identifying and\nmitigating biases within the predictive model but also fosters trust among\nhealthcare stakeholders by improving the transparency and fairness of model\npredictions, thereby contributing to more equitable and trustworthy healthcare\ndelivery.", "paper_summary_zh": "", "author": "Chia-Hsuan Chang et.al.", "authors": "Chia-Hsuan Chang,Xiaoyang Wang,Christopher C. Yang", "id": "2404.13139v1", "paper_url": "http://arxiv.org/abs/2404.13139v1", "repo": "null"}}