{"2406.11839": {"publish_time": "2024-06-17", "title": "mDPO: Conditional Preference Optimization for Multimodal Large Language Models", "paper_summary": "Direct preference optimization (DPO) has shown to be an effective method for\nlarge language model (LLM) alignment. Recent works have attempted to apply DPO\nto multimodal scenarios but have found it challenging to achieve consistent\nimprovement. Through a comparative experiment, we identify the unconditional\npreference problem in multimodal preference optimization, where the model\noverlooks the image condition. To address this problem, we propose mDPO, a\nmultimodal DPO objective that prevents the over-prioritization of language-only\npreferences by also optimizing image preference. Moreover, we introduce a\nreward anchor that forces the reward to be positive for chosen responses,\nthereby avoiding the decrease in their likelihood -- an intrinsic problem of\nrelative preference optimization. Experiments on two multimodal LLMs of\ndifferent sizes and three widely used benchmarks demonstrate that mDPO\neffectively addresses the unconditional preference problem in multimodal\npreference optimization and significantly improves model performance,\nparticularly in reducing hallucination.", "paper_summary_zh": "\u76f4\u63a5\u504f\u597d\u6700\u4f73\u5316 (DPO) \u5df2\u88ab\u8b49\u660e\u662f\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u5c0d\u9f4a\u7684\u6709\u6548\u65b9\u6cd5\u3002\u6700\u8fd1\u7684\u7814\u7a76\u5df2\u5617\u8a66\u5c07 DPO \u61c9\u7528\u65bc\u591a\u6a21\u614b\u5834\u666f\uff0c\u4f46\u767c\u73fe\u96e3\u4ee5\u9054\u6210\u4e00\u81f4\u7684\u6539\u5584\u3002\u900f\u904e\u6bd4\u8f03\u5be6\u9a57\uff0c\u6211\u5011\u627e\u51fa\u591a\u6a21\u614b\u504f\u597d\u6700\u4f73\u5316\u4e2d\u7684\u7121\u689d\u4ef6\u504f\u597d\u554f\u984c\uff0c\u5176\u4e2d\u6a21\u578b\u5ffd\u7565\u4e86\u5f71\u50cf\u689d\u4ef6\u3002\u70ba\u4e86\u89e3\u6c7a\u6b64\u554f\u984c\uff0c\u6211\u5011\u63d0\u51fa mDPO\uff0c\u4e00\u7a2e\u591a\u6a21\u614b DPO \u76ee\u6a19\uff0c\u900f\u904e\u6700\u4f73\u5316\u5f71\u50cf\u504f\u597d\u4f86\u9632\u6b62\u904e\u5ea6\u512a\u5148\u8003\u616e\u50c5\u8a9e\u8a00\u7684\u504f\u597d\u3002\u6b64\u5916\uff0c\u6211\u5011\u5f15\u5165\u4e86\u734e\u52f5\u9328\u9ede\uff0c\u5f37\u5236\u734e\u52f5\u5c0d\u6240\u9078\u56de\u61c9\u70ba\u6b63\u503c\uff0c\u5f9e\u800c\u907f\u514d\u5176\u53ef\u80fd\u6027\u964d\u4f4e\u2014\u2014\u9019\u662f\u76f8\u5c0d\u504f\u597d\u6700\u4f73\u5316\u7684\u5167\u5728\u554f\u984c\u3002\u5728\u4e0d\u540c\u5927\u5c0f\u7684\u5169\u500b\u591a\u6a21\u614b LLM \u548c\u4e09\u500b\u5ee3\u6cdb\u4f7f\u7528\u7684\u57fa\u6e96\u4e0a\u7684\u5be6\u9a57\u8b49\u660e\uff0cmDPO \u6709\u6548\u5730\u89e3\u6c7a\u4e86\u591a\u6a21\u614b\u504f\u597d\u6700\u4f73\u5316\u4e2d\u7684\u7121\u689d\u4ef6\u504f\u597d\u554f\u984c\uff0c\u4e26\u986f\u8457\u6539\u5584\u4e86\u6a21\u578b\u6548\u80fd\uff0c\u7279\u5225\u662f\u5728\u6e1b\u5c11\u5e7b\u89ba\u65b9\u9762\u3002", "author": "Fei Wang et.al.", "authors": "Fei Wang, Wenxuan Zhou, James Y. Huang, Nan Xu, Sheng Zhang, Hoifung Poon, Muhao Chen", "id": "2406.11839v1", "paper_url": "http://arxiv.org/abs/2406.11839v1", "repo": "null"}}