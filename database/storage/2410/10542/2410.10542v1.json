{"2410.10542": {"publish_time": "2024-10-14", "title": "Rethinking Legal Judgement Prediction in a Realistic Scenario in the Era of Large Language Models", "paper_summary": "This study investigates judgment prediction in a realistic scenario within\nthe context of Indian judgments, utilizing a range of transformer-based models,\nincluding InLegalBERT, BERT, and XLNet, alongside LLMs such as Llama-2 and\nGPT-3.5 Turbo. In this realistic scenario, we simulate how judgments are\npredicted at the point when a case is presented for a decision in court, using\nonly the information available at that time, such as the facts of the case,\nstatutes, precedents, and arguments. This approach mimics real-world\nconditions, where decisions must be made without the benefit of hindsight,\nunlike retrospective analyses often found in previous studies. For transformer\nmodels, we experiment with hierarchical transformers and the summarization of\njudgment facts to optimize input for these models. Our experiments with LLMs\nreveal that GPT-3.5 Turbo excels in realistic scenarios, demonstrating robust\nperformance in judgment prediction. Furthermore, incorporating additional legal\ninformation, such as statutes and precedents, significantly improves the\noutcome of the prediction task. The LLMs also provide explanations for their\npredictions. To evaluate the quality of these predictions and explanations, we\nintroduce two human evaluation metrics: Clarity and Linking. Our findings from\nboth automatic and human evaluations indicate that, despite advancements in\nLLMs, they are yet to achieve expert-level performance in judgment prediction\nand explanation tasks.", "paper_summary_zh": "\u672c\u7814\u7a76\u5728\u5370\u5ea6\u5224\u6c7a\u7684\u80cc\u666f\u4e0b\uff0c\u5229\u7528\u4e00\u7cfb\u5217\u57fa\u65bcTransformer\u7684\u6a21\u578b\uff08\u5305\u62ec InLegalBERT\u3001BERT \u548c XLNet\uff09\u4ee5\u53ca\u8af8\u5982 Llama-2 \u548c GPT-3.5 Turbo \u7b49 LLM\uff0c\u63a2\u8a0e\u4e86\u5728\u73fe\u5be6\u5834\u666f\u4e2d\u7684\u5224\u6c7a\u9810\u6e2c\u3002\u5728\u9019\u500b\u73fe\u5be6\u5834\u666f\u4e2d\uff0c\u6211\u5011\u6a21\u64ec\u4e86\u5728\u6cd5\u5ead\u4e0a\u63d0\u51fa\u5224\u6c7a\u6642\u5982\u4f55\u9810\u6e2c\u5224\u6c7a\uff0c\u50c5\u4f7f\u7528\u7576\u6642\u53ef\u7528\u7684\u8cc7\u8a0a\uff0c\u4f8b\u5982\u6848\u4ef6\u7684\u4e8b\u5be6\u3001\u6cd5\u898f\u3001\u5148\u4f8b\u548c\u8ad6\u9ede\u3002\u9019\u7a2e\u65b9\u6cd5\u6a21\u64ec\u4e86\u771f\u5be6\u4e16\u754c\u7684\u689d\u4ef6\uff0c\u5728\u9019\u4e9b\u689d\u4ef6\u4e0b\u5fc5\u9808\u5728\u6c92\u6709\u4e8b\u5f8c\u898b\u4e4b\u660e\u7684\u5e6b\u52a9\u4e0b\u505a\u51fa\u6c7a\u5b9a\uff0c\u9019\u8207\u5148\u524d\u7814\u7a76\u4e2d\u7d93\u5e38\u767c\u73fe\u7684\u56de\u9867\u6027\u5206\u6790\u4e0d\u540c\u3002\u5c0d\u65bcTransformer\u6a21\u578b\uff0c\u6211\u5011\u5617\u8a66\u4e86\u968e\u5c64\u5f0fTransformer\u548c\u5224\u6c7a\u4e8b\u5be6\u6458\u8981\uff0c\u4ee5\u512a\u5316\u9019\u4e9b\u6a21\u578b\u7684\u8f38\u5165\u3002\u6211\u5011\u5c0d LLM \u7684\u5be6\u9a57\u8868\u660e\uff0cGPT-3.5 Turbo \u5728\u73fe\u5be6\u5834\u666f\u4e2d\u8868\u73fe\u51fa\u8272\uff0c\u5728\u5224\u6c7a\u9810\u6e2c\u4e2d\u8868\u73fe\u51fa\u5f37\u5927\u7684\u6027\u80fd\u3002\u6b64\u5916\uff0c\u7d0d\u5165\u5176\u4ed6\u6cd5\u5f8b\u8cc7\u8a0a\uff08\u4f8b\u5982\u6cd5\u898f\u548c\u5148\u4f8b\uff09\u986f\u8457\u6539\u5584\u4e86\u9810\u6e2c\u4efb\u52d9\u7684\u7d50\u679c\u3002LLM \u4e5f\u70ba\u5176\u9810\u6e2c\u63d0\u4f9b\u4e86\u89e3\u91cb\u3002\u70ba\u4e86\u8a55\u4f30\u9019\u4e9b\u9810\u6e2c\u548c\u89e3\u91cb\u7684\u54c1\u8cea\uff0c\u6211\u5011\u5f15\u5165\u4e86\u5169\u500b\u4eba\u985e\u8a55\u4f30\u6307\u6a19\uff1a\u6e05\u6670\u5ea6\u548c\u9023\u7d50\u6027\u3002\u6211\u5011\u5f9e\u81ea\u52d5\u548c\u4eba\u985e\u8a55\u4f30\u4e2d\u5f97\u51fa\u7684\u7d50\u679c\u8868\u660e\uff0c\u5118\u7ba1 LLM \u6709\u6240\u9032\u6b65\uff0c\u4f46\u5b83\u5011\u5c1a\u672a\u5728\u5224\u6c7a\u9810\u6e2c\u548c\u89e3\u91cb\u4efb\u52d9\u4e2d\u9054\u5230\u5c08\u5bb6\u7d1a\u5225\u7684\u8868\u73fe\u3002", "author": "Shubham Kumar Nigam et.al.", "authors": "Shubham Kumar Nigam, Aniket Deroy, Subhankar Maity, Arnab Bhattacharya", "id": "2410.10542v1", "paper_url": "http://arxiv.org/abs/2410.10542v1", "repo": "null"}}