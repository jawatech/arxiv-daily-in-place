{"2410.22790": {"publish_time": "2024-10-30", "title": "Dual Contrastive Transformer for Hierarchical Preference Modeling in Sequential Recommendation", "paper_summary": "Sequential recommender systems (SRSs) aim to predict the subsequent items\nwhich may interest users via comprehensively modeling users' complex preference\nembedded in the sequence of user-item interactions. However, most of existing\nSRSs often model users' single low-level preference based on item ID\ninformation while ignoring the high-level preference revealed by item attribute\ninformation, such as item category. Furthermore, they often utilize limited\nsequence context information to predict the next item while overlooking richer\ninter-item semantic relations. To this end, in this paper, we proposed a novel\nhierarchical preference modeling framework to substantially model the complex\nlow- and high-level preference dynamics for accurate sequential recommendation.\nSpecifically, in the framework, a novel dual-transformer module and a novel\ndual contrastive learning scheme have been designed to discriminatively learn\nusers' low- and high-level preference and to effectively enhance both low- and\nhigh-level preference learning respectively. In addition, a novel\nsemantics-enhanced context embedding module has been devised to generate more\ninformative context embedding for further improving the recommendation\nperformance. Extensive experiments on six real-world datasets have demonstrated\nboth the superiority of our proposed method over the state-of-the-art ones and\nthe rationality of our design.", "paper_summary_zh": "\u5e8f\u5217\u63a8\u85a6\u7cfb\u7d71 (SRS) \u7684\u76ee\u7684\u662f\u9810\u6e2c\u5f8c\u7e8c\u9805\u76ee\uff0c\u9019\u4e9b\u9805\u76ee\u53ef\u80fd\u900f\u904e\u5168\u9762\u5efa\u6a21\u5d4c\u5165\u5728\u4f7f\u7528\u8005\u8207\u9805\u76ee\u4e92\u52d5\u5e8f\u5217\u4e2d\u7684\u4f7f\u7528\u8005\u7684\u8907\u96dc\u504f\u597d\u4f86\u5f15\u8d77\u4f7f\u7528\u8005\u7684\u8208\u8da3\u3002\u7136\u800c\uff0c\u73fe\u6709\u7684 SRS \u5927\u591a\u5e38\u6839\u64da\u9805\u76ee ID \u8cc7\u8a0a\u4f86\u5efa\u6a21\u4f7f\u7528\u8005\u7684\u55ae\u4e00\u4f4e\u5c64\u7d1a\u504f\u597d\uff0c\u540c\u6642\u5ffd\u7565\u9805\u76ee\u5c6c\u6027\u8cc7\u8a0a\uff08\u4f8b\u5982\u9805\u76ee\u985e\u5225\uff09\u6240\u63ed\u793a\u7684\u9ad8\u5c64\u7d1a\u504f\u597d\u3002\u6b64\u5916\uff0c\u4ed6\u5011\u901a\u5e38\u5229\u7528\u6709\u9650\u7684\u5e8f\u5217\u8108\u7d61\u8cc7\u8a0a\u4f86\u9810\u6e2c\u4e0b\u4e00\u500b\u9805\u76ee\uff0c\u540c\u6642\u5ffd\u7565\u66f4\u8c50\u5bcc\u7684\u9805\u76ee\u9593\u8a9e\u7fa9\u95dc\u4fc2\u3002\u70ba\u6b64\uff0c\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u4e00\u500b\u65b0\u7a4e\u7684\u5206\u5c64\u504f\u597d\u5efa\u6a21\u67b6\u69cb\uff0c\u4ee5\u5be6\u8cea\u6027\u5730\u5efa\u6a21\u8907\u96dc\u7684\u4f4e\u5c64\u7d1a\u548c\u9ad8\u5c64\u7d1a\u504f\u597d\u52d5\u614b\uff0c\u4ee5\u9032\u884c\u6e96\u78ba\u7684\u5e8f\u5217\u63a8\u85a6\u3002\u5177\u9ad4\u4f86\u8aaa\uff0c\u5728\u8a72\u67b6\u69cb\u4e2d\uff0c\u8a2d\u8a08\u4e86\u4e00\u500b\u65b0\u7a4e\u7684\u96d9\u91cdTransformer\u6a21\u7d44\u548c\u4e00\u500b\u65b0\u7a4e\u7684\u96d9\u91cd\u5c0d\u6bd4\u5b78\u7fd2\u65b9\u6848\uff0c\u5206\u5225\u7528\u65bc\u5340\u5225\u6027\u5730\u5b78\u7fd2\u4f7f\u7528\u8005\u7684\u4f4e\u5c64\u7d1a\u548c\u9ad8\u5c64\u7d1a\u504f\u597d\uff0c\u4e26\u6709\u6548\u5730\u589e\u5f37\u4f4e\u5c64\u7d1a\u548c\u9ad8\u5c64\u7d1a\u504f\u597d\u5b78\u7fd2\u3002\u6b64\u5916\uff0c\u9084\u8a2d\u8a08\u4e86\u4e00\u500b\u65b0\u7a4e\u7684\u8a9e\u7fa9\u589e\u5f37\u8108\u7d61\u5d4c\u5165\u6a21\u7d44\uff0c\u4ee5\u7522\u751f\u66f4\u591a\u8cc7\u8a0a\u6027\u7684\u8108\u7d61\u5d4c\u5165\uff0c\u9032\u4e00\u6b65\u6539\u5584\u63a8\u85a6\u6548\u80fd\u3002\u5728\u516d\u500b\u771f\u5be6\u4e16\u754c\u8cc7\u6599\u96c6\u4e0a\u9032\u884c\u7684\u5927\u91cf\u5be6\u9a57\u8b49\u660e\u4e86\u6211\u5011\u63d0\u51fa\u7684\u65b9\u6cd5\u512a\u65bc\u73fe\u6709\u6280\u8853\uff0c\u4ee5\u53ca\u6211\u5011\u8a2d\u8a08\u7684\u5408\u7406\u6027\u3002", "author": "Chengkai Huang et.al.", "authors": "Chengkai Huang, Shoujin Wang, Xianzhi Wang, Lina Yao", "id": "2410.22790v1", "paper_url": "http://arxiv.org/abs/2410.22790v1", "repo": "null"}}