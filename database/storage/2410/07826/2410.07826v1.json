{"2410.07826": {"publish_time": "2024-10-10", "title": "Fine-Tuning Language Models for Ethical Ambiguity: A Comparative Study of Alignment with Human Responses", "paper_summary": "Language models often misinterpret human intentions due to their handling of\nambiguity, a limitation well-recognized in NLP research. While morally clear\nscenarios are more discernible to LLMs, greater difficulty is encountered in\nmorally ambiguous contexts. In this investigation, we explored LLM calibration\nto show that human and LLM judgments are poorly aligned in such scenarios. We\nused two curated datasets from the Scruples project for evaluation: DILEMMAS,\nwhich involves pairs of distinct moral scenarios to assess the model's ability\nto compare and contrast ethical situations, and ANECDOTES, which presents\nindividual narratives to evaluate the model's skill in drawing out details,\ninterpreting, and analyzing distinct moral scenarios. Model answer\nprobabilities were extracted for all possible choices and compared with human\nannotations to benchmark the alignment of three models: Llama-3.1-8b,\nZephyr-7b-beta, and Mistral-7b. Significant improvements were observed after\nfine-tuning, with notable enhancements in both cross-entropy and Dirichlet\nscores, particularly in the latter. Notably, after fine-tuning, the performance\nof Mistral-7B-Instruct-v0.3 was on par with GPT-4o. However, the experimental\nmodels that were examined were all still outperformed by the BERT and RoBERTa\nmodels in terms of cross-entropy scores. Our fine-tuning approach, which\nimproves the model's understanding of text distributions in a text-to-text\nformat, effectively enhances performance and alignment in complex\ndecision-making contexts, underscoring the need for further research to refine\nethical reasoning techniques and capture human judgment nuances.", "paper_summary_zh": "\u8a9e\u8a00\u6a21\u578b\u7d93\u5e38\u6703\u8aa4\u89e3\u4eba\u985e\u7684\u610f\u5716\uff0c\u56e0\u70ba\u5b83\u5011\u8655\u7406\u6b67\u7fa9\u7684\u65b9\u5f0f\uff0c\u9019\u5728 NLP \u7814\u7a76\u4e2d\u662f\u4e00\u500b\u5ee3\u70ba\u4eba\u77e5\u7684\u9650\u5236\u3002\u96d6\u7136\u5c0d\u65bc LLM \u4f86\u8aaa\uff0c\u9053\u5fb7\u660e\u78ba\u7684\u5834\u666f\u66f4\u5bb9\u6613\u8fa8\u8b58\uff0c\u4f46\u5728\u9053\u5fb7\u6a21\u7cca\u7684\u8a9e\u5883\u4e2d\u6703\u9047\u5230\u66f4\u5927\u7684\u56f0\u96e3\u3002\u5728\u6b64\u7814\u7a76\u4e2d\uff0c\u6211\u5011\u63a2\u8a0e\u4e86 LLM \u6821\u6b63\uff0c\u4ee5\u8b49\u660e\u4eba\u985e\u548c LLM \u7684\u5224\u65b7\u5728\u9019\u7a2e\u5834\u666f\u4e2d\u5c0d\u9f4a\u5f97\u4e0d\u597d\u3002\u6211\u5011\u4f7f\u7528\u4e86\u4f86\u81ea Scruples \u5c08\u6848\u7684\u5169\u500b\u6574\u7406\u904e\u7684\u8cc7\u6599\u96c6\u9032\u884c\u8a55\u4f30\uff1aDILEMMAS\uff0c\u5176\u4e2d\u5305\u542b\u5169\u7d44\u4e0d\u540c\u7684\u9053\u5fb7\u5834\u666f\uff0c\u7528\u65bc\u8a55\u4f30\u6a21\u578b\u6bd4\u8f03\u548c\u5c0d\u6bd4\u9053\u5fb7\u60c5\u5883\u7684\u7684\u80fd\u529b\uff0c\u4ee5\u53ca ANECDOTES\uff0c\u5176\u4e2d\u63d0\u4f9b\u4e86\u500b\u5225\u6558\u8ff0\uff0c\u7528\u65bc\u8a55\u4f30\u6a21\u578b\u5728\u63d0\u53d6\u7d30\u7bc0\u3001\u8a6e\u91cb\u548c\u5206\u6790\u4e0d\u540c\u7684\u9053\u5fb7\u5834\u666f\u65b9\u9762\u7684\u6280\u80fd\u3002\u6a21\u578b\u7b54\u6848\u6a5f\u7387\u6703\u88ab\u63d0\u53d6\u51fa\u4f86\uff0c\u4ee5\u4f9b\u6240\u6709\u53ef\u80fd\u7684\u9078\u64c7\u4f7f\u7528\uff0c\u4e26\u8207\u4eba\u985e\u8a3b\u89e3\u9032\u884c\u6bd4\u8f03\uff0c\u4ee5\u57fa\u6e96\u6e2c\u8a66\u4e09\u500b\u6a21\u578b\u7684\u5c0d\u9f4a\u7a0b\u5ea6\uff1aLlama-3.1-8b\u3001Zephyr-7b-beta \u548c Mistral-7b\u3002\u5728\u5fae\u8abf\u5f8c\u89c0\u5bdf\u5230\u986f\u8457\u7684\u9032\u6b65\uff0c\u7279\u5225\u662f\u5728\u5f8c\u8005\u4e2d\uff0c\u4ea4\u53c9\u71b5\u548c Dirichlet \u5206\u6578\u90fd\u6709\u986f\u8457\u7684\u63d0\u5347\u3002\u7279\u5225\u503c\u5f97\u6ce8\u610f\u7684\u662f\uff0c\u5fae\u8abf\u5f8c\uff0cMistral-7B-Instruct-v0.3 \u7684\u6548\u80fd\u8207 GPT-4o \u76f8\u7576\u3002\u7136\u800c\uff0c\u5728\u4ea4\u53c9\u71b5\u5206\u6578\u65b9\u9762\uff0c\u6240\u6aa2\u9a57\u7684\u5be6\u9a57\u6a21\u578b\u4ecd\u5168\u90fd\u88ab BERT \u548c RoBERTa \u6a21\u578b\u8d85\u8d8a\u3002\u6211\u5011\u7684\u5fae\u8abf\u65b9\u6cd5\u6539\u9032\u4e86\u6a21\u578b\u5c0d\u6587\u5b57\u5230\u6587\u5b57\u683c\u5f0f\u4e2d\u6587\u5b57\u5206\u4f48\u7684\u7406\u89e3\uff0c\u6709\u6548\u5730\u63d0\u5347\u4e86\u5728\u8907\u96dc\u6c7a\u7b56\u5236\u5b9a\u8a9e\u5883\u4e2d\u7684\u6548\u80fd\u548c\u5c0d\u9f4a\u7a0b\u5ea6\uff0c\u5f37\u8abf\u4e86\u9032\u4e00\u6b65\u7814\u7a76\u4ee5\u6539\u5584\u9053\u5fb7\u63a8\u7406\u6280\u8853\u548c\u6355\u6349\u4eba\u985e\u5224\u65b7\u7d30\u5fae\u5dee\u522b\u7684\u5fc5\u8981\u6027\u3002", "author": "Pranav Senthilkumar et.al.", "authors": "Pranav Senthilkumar, Visshwa Balasubramanian, Prisha Jain, Aneesa Maity, Jonathan Lu, Kevin Zhu", "id": "2410.07826v1", "paper_url": "http://arxiv.org/abs/2410.07826v1", "repo": "null"}}