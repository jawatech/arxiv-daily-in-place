{"2412.18428": {"publish_time": "2024-12-24", "title": "Explainable Multi-Modal Data Exploration in Natural Language via LLM Agent", "paper_summary": "International enterprises, organizations, or hospitals collect large amounts\nof multi-modal data stored in databases, text documents, images, and videos.\nWhile there has been recent progress in the separate fields of multi-modal data\nexploration as well as in database systems that automatically translate natural\nlanguage questions to database query languages, the research challenge of\nquerying database systems combined with other unstructured modalities such as\nimages in natural language is widely unexplored.\n  In this paper, we propose XMODE - a system that enables explainable,\nmulti-modal data exploration in natural language. Our approach is based on the\nfollowing research contributions: (1) Our system is inspired by a real-world\nuse case that enables users to explore multi-modal information systems. (2)\nXMODE leverages a LLM-based agentic AI framework to decompose a natural\nlanguage question into subtasks such as text-to-SQL generation and image\nanalysis. (3) Experimental results on multi-modal datasets over relational data\nand images demonstrate that our system outperforms state-of-the-art multi-modal\nexploration systems, excelling not only in accuracy but also in various\nperformance metrics such as query latency, API costs, planning efficiency, and\nexplanation quality, thanks to the more effective utilization of the reasoning\ncapabilities of LLMs.", "paper_summary_zh": "\u570b\u969b\u4f01\u696d\u3001\u7d44\u7e54\u6216\u91ab\u9662\u6536\u96c6\u5927\u91cf\u5132\u5b58\u5728\u8cc7\u6599\u5eab\u3001\u6587\u5b57\u6587\u4ef6\u3001\u5716\u7247\u548c\u5f71\u7247\u4e2d\u7684\u591a\u6a21\u614b\u8cc7\u6599\u3002\u96d6\u7136\u591a\u6a21\u614b\u8cc7\u6599\u63a2\u52d8\u7684\u7368\u7acb\u9818\u57df\u4ee5\u53ca\u81ea\u52d5\u5c07\u81ea\u7136\u8a9e\u8a00\u554f\u984c\u8f49\u63db\u6210\u8cc7\u6599\u5eab\u67e5\u8a62\u8a9e\u8a00\u7684\u8cc7\u6599\u5eab\u7cfb\u7d71\u6700\u8fd1\u5df2\u6709\u9032\u5c55\uff0c\u4f46\u7d50\u5408\u5176\u4ed6\u975e\u7d50\u69cb\u5316\u6a21\u614b\uff08\u4f8b\u5982\u5716\u7247\uff09\u4ee5\u81ea\u7136\u8a9e\u8a00\u67e5\u8a62\u8cc7\u6599\u5eab\u7cfb\u7d71\u7684\u7814\u7a76\u6311\u6230\u4ecd\u9bae\u5c11\u63a2\u8a0e\u3002\u5728\u6b64\u7bc7\u8ad6\u6587\u4e2d\uff0c\u6211\u5011\u63d0\u51fa XMODE\uff0c\u4e00\u500b\u80fd\u4f7f\u7528\u81ea\u7136\u8a9e\u8a00\u9032\u884c\u53ef\u89e3\u91cb\u591a\u6a21\u614b\u8cc7\u6599\u63a2\u52d8\u7684\u7cfb\u7d71\u3002\u6211\u5011\u7684\u505a\u6cd5\u57fa\u65bc\u4ee5\u4e0b\u7814\u7a76\u8ca2\u737b\uff1a(1) \u6211\u5011\u7684\u7cfb\u7d71\u9748\u611f\u4f86\u81ea\u4e00\u500b\u80fd\u8b93\u4f7f\u7528\u8005\u63a2\u7d22\u591a\u6a21\u614b\u8cc7\u8a0a\u7cfb\u7d71\u7684\u771f\u5be6\u4e16\u754c\u4f7f\u7528\u6848\u4f8b\u3002(2) XMODE \u5229\u7528\u4e00\u500b\u57fa\u65bc LLM \u7684\u4ee3\u7406 AI \u67b6\u69cb\uff0c\u5c07\u81ea\u7136\u8a9e\u8a00\u554f\u984c\u5206\u89e3\u6210\u6587\u5b57\u8f49 SQL \u7522\u751f\u548c\u5716\u7247\u5206\u6790\u7b49\u5b50\u4efb\u52d9\u3002(3) \u5728\u95dc\u806f\u8cc7\u6599\u548c\u5716\u7247\u7684\u591a\u6a21\u614b\u8cc7\u6599\u96c6\u4e0a\u7684\u5be6\u9a57\u7d50\u679c\u986f\u793a\uff0c\u6211\u5011\u7684\u7cfb\u7d71\u512a\u65bc\u6700\u5148\u9032\u7684\u591a\u6a21\u614b\u63a2\u52d8\u7cfb\u7d71\uff0c\u4e0d\u50c5\u5728\u6e96\u78ba\u5ea6\u4e0a\u8868\u73fe\u51fa\u8272\uff0c\u5728\u5404\u7a2e\u6548\u80fd\u6307\u6a19\uff08\u4f8b\u5982\u67e5\u8a62\u5ef6\u9072\u3001API \u6210\u672c\u3001\u898f\u5283\u6548\u7387\u548c\u8aaa\u660e\u54c1\u8cea\uff09\u4e0a\u4e5f\u8868\u73fe\u51fa\u8272\uff0c\u9019\u8981\u6b78\u529f\u65bc\u66f4\u6709\u6548\u5730\u5229\u7528 LLM \u7684\u63a8\u7406\u80fd\u529b\u3002", "author": "Farhad Nooralahzadeh et.al.", "authors": "Farhad Nooralahzadeh, Yi Zhang, Jonathan Furst, Kurt Stockinger", "id": "2412.18428v1", "paper_url": "http://arxiv.org/abs/2412.18428v1", "repo": "null"}}