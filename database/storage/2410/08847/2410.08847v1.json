{"2410.08847": {"publish_time": "2024-10-11", "title": "Unintentional Unalignment: Likelihood Displacement in Direct Preference Optimization", "paper_summary": "Direct Preference Optimization (DPO) and its variants are increasingly used\nfor aligning language models with human preferences. Although these methods are\ndesigned to teach a model to generate preferred responses more frequently\nrelative to dispreferred responses, prior work has observed that the likelihood\nof preferred responses often decreases during training. The current work sheds\nlight on the causes and implications of this counter-intuitive phenomenon,\nwhich we term likelihood displacement. We demonstrate that likelihood\ndisplacement can be catastrophic, shifting probability mass from preferred\nresponses to responses with an opposite meaning. As a simple example, training\na model to prefer $\\texttt{No}$ over $\\texttt{Never}$ can sharply increase the\nprobability of $\\texttt{Yes}$. Moreover, when aligning the model to refuse\nunsafe prompts, we show that such displacement can unintentionally lead to\nunalignment, by shifting probability mass from preferred refusal responses to\nharmful responses (e.g., reducing the refusal rate of Llama-3-8B-Instruct from\n74.4% to 33.4%). We theoretically characterize that likelihood displacement is\ndriven by preferences that induce similar embeddings, as measured by a centered\nhidden embedding similarity (CHES) score. Empirically, the CHES score enables\nidentifying which training samples contribute most to likelihood displacement\nin a given dataset. Filtering out these samples effectively mitigated\nunintentional unalignment in our experiments. More broadly, our results\nhighlight the importance of curating data with sufficiently distinct\npreferences, for which we believe the CHES score may prove valuable.", "paper_summary_zh": "\u76f4\u63a5\u504f\u597d\u512a\u5316\uff08DPO\uff09\u53ca\u5176\u8b8a\u9ad4\u6b63\u8d8a\u4f86\u8d8a\u5e38\u88ab\u7528\u65bc\u4f7f\u8a9e\u8a00\u6a21\u578b\u8207\u4eba\u985e\u504f\u597d\u4fdd\u6301\u4e00\u81f4\u3002\u5118\u7ba1\u9019\u4e9b\u65b9\u6cd5\u65e8\u5728\u6559\u5c0e\u6a21\u578b\u66f4\u983b\u7e41\u5730\u7522\u751f\u504f\u597d\u7684\u56de\u61c9\uff0c\u76f8\u5c0d\u65bc\u4e0d\u504f\u597d\u7684\u56de\u61c9\uff0c\u4f46\u5148\u524d\u7684\u7814\u7a76\u89c0\u5bdf\u5230\u504f\u597d\u56de\u61c9\u7684\u53ef\u80fd\u6027\u901a\u5e38\u6703\u5728\u8a13\u7df4\u671f\u9593\u4e0b\u964d\u3002\u76ee\u524d\u7684\u7814\u7a76\u95e1\u660e\u4e86\u9019\u7a2e\u53cd\u76f4\u89ba\u73fe\u8c61\u7684\u539f\u56e0\u548c\u5f71\u97ff\uff0c\u6211\u5011\u7a31\u4e4b\u70ba\u53ef\u80fd\u6027\u4f4d\u79fb\u3002\u6211\u5011\u8b49\u660e\u53ef\u80fd\u6027\u4f4d\u79fb\u53ef\u80fd\u662f\u707d\u96e3\u6027\u7684\uff0c\u5b83\u5c07\u6a5f\u7387\u8cea\u91cf\u5f9e\u504f\u597d\u7684\u56de\u61c9\u8f49\u79fb\u5230\u5177\u6709\u76f8\u53cd\u542b\u7fa9\u7684\u56de\u61c9\u3002\u8209\u4e00\u500b\u7c21\u55ae\u7684\u4f8b\u5b50\uff0c\u8a13\u7df4\u4e00\u500b\u6a21\u578b\u504f\u597d $\\texttt{No}$ \u512a\u65bc $\\texttt{Never}$\uff0c\u53ef\u80fd\u6703\u5927\u5e45\u589e\u52a0 $\\texttt{Yes}$ \u7684\u6a5f\u7387\u3002\u6b64\u5916\uff0c\u7576\u5c07\u6a21\u578b\u8abf\u6574\u70ba\u62d2\u7d55\u4e0d\u5b89\u5168\u7684\u63d0\u793a\u6642\uff0c\u6211\u5011\u8868\u660e\u9019\u7a2e\u4f4d\u79fb\u53ef\u80fd\u6703\u7121\u610f\u4e2d\u5c0e\u81f4\u672a\u5c0d\u9f4a\uff0c\u65b9\u6cd5\u662f\u5c07\u6a5f\u7387\u8cea\u91cf\u5f9e\u504f\u597d\u7684\u62d2\u7d55\u56de\u61c9\u8f49\u79fb\u5230\u6709\u5bb3\u7684\u56de\u61c9\uff08\u4f8b\u5982\uff0c\u5c07 Llama-3-8B-Instruct \u7684\u62d2\u7d55\u7387\u5f9e 74.4% \u964d\u4f4e\u5230 33.4%\uff09\u3002\u6211\u5011\u5f9e\u7406\u8ad6\u4e0a\u63cf\u8ff0\u4e86\u53ef\u80fd\u6027\u4f4d\u79fb\u662f\u7531\u8a98\u5c0e\u76f8\u4f3c\u5d4c\u5165\u7684\u504f\u597d\u9a45\u52d5\u7684\uff0c\u9019\u662f\u901a\u904e\u4e2d\u5fc3\u96b1\u85cf\u5d4c\u5165\u76f8\u4f3c\u5ea6 (CHES) \u5206\u6578\u4f86\u8861\u91cf\u7684\u3002\u6839\u64da\u7d93\u9a57\uff0cCHES \u5206\u6578\u80fd\u5920\u8b58\u5225\u54ea\u4e9b\u8a13\u7df4\u6a23\u672c\u5c0d\u7d66\u5b9a\u8cc7\u6599\u96c6\u4e2d\u7684\u53ef\u80fd\u6027\u4f4d\u79fb\u8ca2\u737b\u6700\u5927\u3002\u5728\u6211\u5011\u7684\u5be6\u9a57\u4e2d\uff0c\u904e\u6ffe\u6389\u9019\u4e9b\u6a23\u672c\u6709\u6548\u5730\u6e1b\u8f15\u4e86\u7121\u610f\u7684\u672a\u5c0d\u9f4a\u3002\u66f4\u5ee3\u6cdb\u5730\u8aaa\uff0c\u6211\u5011\u7684\u7d50\u679c\u7a81\u51fa\u4e86\u7b56\u5283\u5177\u6709\u8db3\u5920\u4e0d\u540c\u504f\u597d\u7684\u8cc7\u6599\u7684\u91cd\u8981\u6027\uff0c\u6211\u5011\u76f8\u4fe1 CHES \u5206\u6578\u53ef\u80fd\u88ab\u8b49\u660e\u662f\u6709\u50f9\u503c\u7684\u3002", "author": "Noam Razin et.al.", "authors": "Noam Razin, Sadhika Malladi, Adithya Bhaskar, Danqi Chen, Sanjeev Arora, Boris Hanin", "id": "2410.08847v1", "paper_url": "http://arxiv.org/abs/2410.08847v1", "repo": "null"}}