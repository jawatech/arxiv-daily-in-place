{"2412.18169": {"publish_time": "2024-12-24", "title": "KunServe: Elastic and Efficient Large Language Model Serving with Parameter-centric Memory Management", "paper_summary": "The stateful nature of large language model (LLM) servingcan easily throttle\nprecious GPU memory under load burstor long-generation requests like\nchain-of-thought reasoning,causing latency spikes due to queuing incoming\nrequests. However, state-of-the-art KVCache centric approaches handleload\nspikes by dropping, migrating, or swapping KVCache,which faces an essential\ntradeoff between the performance ofongoing vs. incoming requests and thus still\nseverely violatesSLO.This paper makes a key observation such that model\nparam-eters are independent of the requests and are replicated acrossGPUs, and\nthus proposes a parameter-centric approach byselectively dropping replicated\nparameters to leave preciousmemory for requests. However, LLM requires KVCache\ntobe saved in bound with model parameters and thus droppingparameters can cause\neither huge computation waste or longnetwork delay, affecting all ongoing\nrequests. Based on the ob-servation that attention operators can be decoupled\nfrom otheroperators, this paper further proposes a novel remote\nattentionmechanism through pipeline parallelism so as to serve up-coming\nrequests with the additional memory borrowed fromparameters on remote GPUs.\nThis paper further addresses sev-eral other challenges including lively\nexchanging KVCachewith incomplete parameters, generating an appropriate\nplanthat balances memory requirements with cooperative exe-cution overhead, and\nseamlessly restoring parameters whenthe throttling has gone. Evaluations show\nthatKUNSERVEreduces the tail TTFT of requests under throttling by up to 27.3x\ncompared to the state-of-the-art.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u670d\u52d9\u7684\u72c0\u614b\u6027\u8cea\u5728\u8ca0\u8f09\u7a81\u7136\u589e\u52a0\u6216\u9577\u751f\u6210\u8acb\u6c42\uff08\u4f8b\u5982\u601d\u8003\u93c8\u63a8\u7406\uff09\u7684\u60c5\u6cc1\u4e0b\uff0c\u5bb9\u6613\u9650\u5236\u5bf6\u8cb4\u7684 GPU \u8a18\u61b6\u9ad4\uff0c\u5c0e\u81f4\u6392\u968a\u7684\u50b3\u5165\u8acb\u6c42\u7522\u751f\u5ef6\u9072\u9ad8\u5cf0\u3002\u7136\u800c\uff0c\u6700\u5148\u9032\u7684 KVCache \u4e2d\u5fc3\u5316\u65b9\u6cd5\u900f\u904e\u6368\u68c4\u3001\u9077\u79fb\u6216\u4ea4\u63db KVCache \u4f86\u8655\u7406\u8ca0\u8f09\u9ad8\u5cf0\uff0c\u9019\u5728\u6b63\u5728\u9032\u884c\u7684\u8acb\u6c42\u8207\u50b3\u5165\u8acb\u6c42\u7684\u6548\u80fd\u4e4b\u9593\u9762\u81e8\u8457\u672c\u8cea\u4e0a\u7684\u6b0a\u8861\uff0c\u56e0\u6b64\u4ecd\u7136\u56b4\u91cd\u9055\u53cd SLO\u3002\u672c\u6587\u63d0\u51fa\u4e00\u500b\u95dc\u9375\u89c0\u5bdf\uff0c\u5373\u6a21\u578b\u53c3\u6578\u8207\u8acb\u6c42\u7121\u95dc\uff0c\u4e26\u8de8 GPU \u8907\u88fd\uff0c\u56e0\u6b64\u63d0\u51fa\u4e00\u500b\u4ee5\u53c3\u6578\u70ba\u4e2d\u5fc3\u7684\u7b56\u7565\uff0c\u900f\u904e\u9078\u64c7\u6027\u5730\u6368\u68c4\u8907\u88fd\u7684\u53c3\u6578\uff0c\u70ba\u8acb\u6c42\u7559\u4e0b\u5bf6\u8cb4\u7684\u8a18\u61b6\u9ad4\u3002\u7136\u800c\uff0cLLM \u8981\u6c42 KVCache \u8207\u6a21\u578b\u53c3\u6578\u4e00\u8d77\u5132\u5b58\uff0c\u56e0\u6b64\u6368\u68c4\u53c3\u6578\u53ef\u80fd\u6703\u5c0e\u81f4\u5927\u91cf\u7684\u904b\u7b97\u6d6a\u8cbb\u6216\u9577\u7684\u7db2\u8def\u5ef6\u9072\uff0c\u5f71\u97ff\u6240\u6709\u6b63\u5728\u9032\u884c\u7684\u8acb\u6c42\u3002\u57fa\u65bc\u6ce8\u610f\u529b\u904b\u7b97\u5b50\u53ef\u4ee5\u8207\u5176\u4ed6\u904b\u7b97\u5b50\u5206\u96e2\u7684\u89c0\u5bdf\uff0c\u672c\u6587\u9032\u4e00\u6b65\u900f\u904e\u7ba1\u7dda\u5e73\u884c\u5316\u63d0\u51fa\u4e00\u500b\u65b0\u7a4e\u7684\u9060\u7aef\u6ce8\u610f\u529b\u6a5f\u5236\uff0c\u4ee5\u4fbf\u4f7f\u7528\u5f9e\u9060\u7aef GPU \u4e0a\u53c3\u6578\u501f\u4f86\u7684\u984d\u5916\u8a18\u61b6\u9ad4\u4f86\u670d\u52d9\u5373\u5c07\u5230\u4f86\u7684\u8acb\u6c42\u3002\u672c\u6587\u9032\u4e00\u6b65\u89e3\u6c7a\u4e86\u5176\u4ed6\u5e7e\u500b\u6311\u6230\uff0c\u5305\u62ec\u8207\u4e0d\u5b8c\u6574\u53c3\u6578\u4ea4\u63db KVCache\u3001\u7522\u751f\u4e00\u500b\u5e73\u8861\u8a18\u61b6\u9ad4\u9700\u6c42\u8207\u5408\u4f5c\u57f7\u884c\u8ca0\u64d4\u7684\u9069\u7576\u8a08\u756b\uff0c\u4ee5\u53ca\u5728\u9650\u5236\u89e3\u9664\u6642\u7121\u7e2b\u9084\u539f\u53c3\u6578\u3002\u8a55\u4f30\u986f\u793a\uff0c\u8207\u6700\u5148\u9032\u7684\u6280\u8853\u76f8\u6bd4\uff0cKUNSERVE \u5c07\u5728\u9650\u5236\u4e0b\u7684\u8acb\u6c42\u5c3e\u7aef TTFT \u6e1b\u5c11\u4e86\u591a\u9054 27.3 \u500d\u3002", "author": "Rongxin Cheng et.al.", "authors": "Rongxin Cheng, Yifan Peng, Yuxin Lai, Xingda Wei, Rong Chen, Haibo Chen", "id": "2412.18169v1", "paper_url": "http://arxiv.org/abs/2412.18169v1", "repo": "null"}}