{"2502.03387": {"publish_time": "2025-02-05", "title": "LIMO: Less is More for Reasoning", "paper_summary": "We present a fundamental discovery that challenges our understanding of how\ncomplex reasoning emerges in large language models. While conventional wisdom\nsuggests that sophisticated reasoning tasks demand extensive training data\n(>100,000 examples), we demonstrate that complex mathematical reasoning\nabilities can be effectively elicited with surprisingly few examples. Through\ncomprehensive experiments, our proposed model LIMO demonstrates unprecedented\nperformance in mathematical reasoning. With merely 817 curated training\nsamples, LIMO achieves 57.1% accuracy on AIME and 94.8% on MATH, improving from\nprevious SFT-based models' 6.5% and 59.2% respectively, while only using 1% of\nthe training data required by previous approaches. LIMO demonstrates\nexceptional out-of-distribution generalization, achieving 40.5% absolute\nimprovement across 10 diverse benchmarks, outperforming models trained on 100x\nmore data, challenging the notion that SFT leads to memorization rather than\ngeneralization. Based on these results, we propose the Less-Is-More Reasoning\nHypothesis (LIMO Hypothesis): In foundation models where domain knowledge has\nbeen comprehensively encoded during pre-training, sophisticated reasoning\ncapabilities can emerge through minimal but precisely orchestrated\ndemonstrations of cognitive processes. This hypothesis posits that the\nelicitation threshold for complex reasoning is determined by two key factors:\n(1) the completeness of the model's encoded knowledge foundation during\npre-training, and (2) the effectiveness of post-training examples as \"cognitive\ntemplates\" that show the model how to utilize its knowledge base to solve\ncomplex reasoning tasks. To facilitate reproducibility and future research in\ndata-efficient reasoning, we release LIMO as a comprehensive open-source suite\nat https://github.com/GAIR-NLP/LIMO.", "paper_summary_zh": "<paragraph>\u6211\u5011\u63d0\u51fa\u4e86\u4e00\u9805\u57fa\u672c\u767c\u73fe\uff0c\u6311\u6230\u4e86\u6211\u5011\u5c0d\u5927\u578b\u8a9e\u8a00\u6a21\u578b\u4e2d\u8907\u96dc\u63a8\u7406\u5982\u4f55\u51fa\u73fe\u7684\u7406\u89e3\u3002\u96d6\u7136\u50b3\u7d71\u667a\u6167\u8868\u660e\uff0c\u8907\u96dc\u7684\u63a8\u7406\u4efb\u52d9\u9700\u8981\u5927\u91cf\u7684\u8a13\u7df4\u6578\u64da\uff08>100,000 \u500b\u7bc4\u4f8b\uff09\uff0c\u4f46\u6211\u5011\u8b49\u660e\u4e86\u8907\u96dc\u7684\u6578\u5b78\u63a8\u7406\u80fd\u529b\u53ef\u4ee5\u7528\u9a5a\u4eba\u7684\u5c11\u6578\u7bc4\u4f8b\u6709\u6548\u5730\u5f15\u767c\u3002\u901a\u904e\u5168\u9762\u7684\u5be6\u9a57\uff0c\u6211\u5011\u63d0\u51fa\u7684\u6a21\u578b LIMO \u5728\u6578\u5b78\u63a8\u7406\u4e2d\u5c55\u793a\u4e86\u524d\u6240\u672a\u6709\u7684\u8868\u73fe\u3002LIMO \u50c5\u4f7f\u7528 817 \u500b\u7cbe\u5fc3\u7b56\u5283\u7684\u8a13\u7df4\u6a23\u672c\uff0c\u5728 AIME \u4e0a\u9054\u5230\u4e86 57.1% \u7684\u6e96\u78ba\u5ea6\uff0c\u5728 MATH \u4e0a\u9054\u5230\u4e86 94.8%\uff0c\u5206\u5225\u6bd4\u4ee5\u524d\u7684\u57fa\u65bc SFT \u7684\u6a21\u578b\u63d0\u9ad8\u4e86 6.5% \u548c 59.2%\uff0c\u540c\u6642\u50c5\u4f7f\u7528\u4e86\u4ee5\u524d\u65b9\u6cd5\u6240\u9700\u8a13\u7df4\u6578\u64da\u7684 1%\u3002LIMO \u5c55\u793a\u4e86\u51fa\u8272\u7684\u5206\u5e03\u5916\u6cdb\u5316\u80fd\u529b\uff0c\u5728 10 \u500b\u4e0d\u540c\u7684\u57fa\u6e96\u6e2c\u8a66\u4e2d\u53d6\u5f97\u4e86 40.5% \u7684\u7d55\u5c0d\u6539\u9032\uff0c\u512a\u65bc\u5728 100 \u500d\u66f4\u591a\u6578\u64da\u4e0a\u8a13\u7df4\u7684\u6a21\u578b\uff0c\u6311\u6230\u4e86 SFT \u5c0e\u81f4\u8a18\u61b6\u800c\u4e0d\u662f\u6cdb\u5316\u7684\u89c0\u5ff5\u3002\u57fa\u65bc\u9019\u4e9b\u7d50\u679c\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u5c11\u5373\u662f\u591a\u63a8\u7406\u5047\u8a2d\uff08LIMO \u5047\u8a2d\uff09\uff1a\u5728\u9810\u8a13\u7df4\u904e\u7a0b\u4e2d\u5df2\u5168\u9762\u7de8\u78bc\u9818\u57df\u77e5\u8b58\u7684\u57fa\u790e\u6a21\u578b\u4e2d\uff0c\u8907\u96dc\u7684\u63a8\u7406\u80fd\u529b\u53ef\u4ee5\u901a\u904e\u5c0d\u8a8d\u77e5\u904e\u7a0b\u9032\u884c\u6700\u5c11\u7684\u4f46\u7cbe\u78ba\u5b89\u6392\u7684\u6f14\u793a\u800c\u51fa\u73fe\u3002\u9019\u500b\u5047\u8a2d\u5047\u8a2d\u8907\u96dc\u63a8\u7406\u7684\u5f15\u767c\u95be\u503c\u662f\u7531\u5169\u500b\u95dc\u9375\u56e0\u7d20\u6c7a\u5b9a\u7684\uff1a(1) \u9810\u8a13\u7df4\u671f\u9593\u6a21\u578b\u7de8\u78bc\u77e5\u8b58\u57fa\u790e\u7684\u5b8c\u6574\u6027\uff0c\u4ee5\u53ca (2) \u8a13\u7df4\u5f8c\u7bc4\u4f8b\u4f5c\u70ba\u300c\u8a8d\u77e5\u6a21\u677f\u300d\u7684\u6709\u6548\u6027\uff0c\u5411\u6a21\u578b\u5c55\u793a\u5982\u4f55\u5229\u7528\u5176\u77e5\u8b58\u5eab\u4f86\u89e3\u6c7a\u8907\u96dc\u7684\u63a8\u7406\u4efb\u52d9\u3002\u70ba\u4e86\u4fc3\u9032\u6578\u64da\u6709\u6548\u63a8\u7406\u7684\u53ef\u8907\u88fd\u6027\u548c\u672a\u4f86\u7814\u7a76\uff0c\u6211\u5011\u5728 https://github.com/GAIR-NLP/LIMO \u4e0a\u767c\u5e03 LIMO \u4f5c\u70ba\u4e00\u500b\u5168\u9762\u7684\u958b\u6e90\u5957\u4ef6\u3002</paragraph>", "author": "Yixin Ye et.al.", "authors": "Yixin Ye, Zhen Huang, Yang Xiao, Ethan Chern, Shijie Xia, Pengfei Liu", "id": "2502.03387v1", "paper_url": "http://arxiv.org/abs/2502.03387v1", "repo": "null"}}