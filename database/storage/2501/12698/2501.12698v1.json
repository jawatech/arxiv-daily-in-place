{"2501.12698": {"publish_time": "2025-01-22", "title": "Training Dialogue Systems by AI Feedback for Improving Overall Dialogue Impression", "paper_summary": "To improve user engagement during conversations with dialogue systems, we\nmust improve individual dialogue responses and dialogue impressions such as\nconsistency, personality, and empathy throughout the entire dialogue. While\nsuch dialogue systems have been developing rapidly with the help of large\nlanguage models (LLMs), reinforcement learning from AI feedback (RLAIF) has\nattracted attention to align LLM-based dialogue models for such dialogue\nimpressions. In RLAIF, a reward model based on another LLM is used to create a\ntraining signal for an LLM-based dialogue model using zero-shot/few-shot\nprompting techniques. However, evaluating an entire dialogue only by prompting\nLLMs is challenging. In this study, the supervised fine-tuning (SFT) of LLMs\nprepared reward models corresponding to 12 metrics related to the impression of\nthe entire dialogue for evaluating dialogue responses. We tuned our dialogue\nmodels using the reward model signals as feedback to improve the impression of\nthe system. The results of automatic and human evaluations showed that tuning\nthe dialogue model using our reward model corresponding to dialogue impression\nimproved the evaluation of individual metrics and the naturalness of the\ndialogue response.", "paper_summary_zh": "\u70ba\u4e86\u5728\u5c0d\u8a71\u7cfb\u7d71\u5c0d\u8a71\u671f\u9593\u63d0\u5347\u4f7f\u7528\u8005\u7684\u53c3\u8207\u5ea6\uff0c\u6211\u5011\u5fc5\u9808\u6539\u5584\u500b\u5225\u5c0d\u8a71\u56de\u61c9\u4ee5\u53ca\u5c0d\u8a71\u5370\u8c61\uff0c\u4f8b\u5982\u5728\u6574\u500b\u5c0d\u8a71\u4e2d\u7684\u4e00\u81f4\u6027\u3001\u500b\u6027\u8207\u540c\u7406\u5fc3\u3002\u96d6\u7136\u6b64\u985e\u5c0d\u8a71\u7cfb\u7d71\u5728\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u7684\u5354\u52a9\u4e0b\u5feb\u901f\u767c\u5c55\uff0c\u4f46\u4f86\u81ea AI \u56de\u994b\u7684\u5f37\u5316\u5b78\u7fd2 (RLAIF) \u5df2\u5f15\u8d77\u6ce8\u610f\uff0c\u53ef\u8abf\u6574\u57fa\u65bc LLM \u7684\u5c0d\u8a71\u6a21\u578b\u4ee5\u7372\u5f97\u6b64\u985e\u5c0d\u8a71\u5370\u8c61\u3002\u5728 RLAIF \u4e2d\uff0c\u57fa\u65bc\u53e6\u4e00\u500b LLM \u7684\u734e\u52f5\u6a21\u578b\u7528\u65bc\u4f7f\u7528\u96f6\u6b21/\u5c11\u6b21\u63d0\u793a\u6280\u8853\u70ba\u57fa\u65bc LLM \u7684\u5c0d\u8a71\u6a21\u578b\u5efa\u7acb\u8a13\u7df4\u8a0a\u865f\u3002\u4e0d\u904e\uff0c\u50c5\u900f\u904e\u63d0\u793a LLM \u5c31\u8a55\u4f30\u6574\u500b\u5c0d\u8a71\u5177\u6709\u6311\u6230\u6027\u3002\u5728\u9019\u9805\u7814\u7a76\u4e2d\uff0cLLM \u7684\u76e3\u7763\u5fae\u8abf (SFT) \u6e96\u5099\u4e86\u8207 12 \u9805\u6307\u6a19\u5c0d\u61c9\u7684\u734e\u52f5\u6a21\u578b\uff0c\u9019\u4e9b\u6307\u6a19\u8207\u8a55\u4f30\u5c0d\u8a71\u56de\u61c9\u7684\u5c0d\u8a71\u6574\u9ad4\u5370\u8c61\u6709\u95dc\u3002\u6211\u5011\u4f7f\u7528\u734e\u52f5\u6a21\u578b\u8a0a\u865f\u4f5c\u70ba\u56de\u994b\u5fae\u8abf\u6211\u5011\u7684\u5c0d\u8a71\u6a21\u578b\uff0c\u4ee5\u6539\u5584\u7cfb\u7d71\u7684\u5370\u8c61\u3002\u81ea\u52d5\u548c\u4eba\u5de5\u8a55\u4f30\u7d50\u679c\u986f\u793a\uff0c\u4f7f\u7528\u8207\u5c0d\u8a71\u5370\u8c61\u5c0d\u61c9\u7684\u734e\u52f5\u6a21\u578b\u5fae\u8abf\u5c0d\u8a71\u6a21\u578b\uff0c\u6539\u5584\u4e86\u500b\u5225\u6307\u6a19\u7684\u8a55\u4f30\u4ee5\u53ca\u5c0d\u8a71\u56de\u61c9\u7684\u81ea\u7136\u6027\u3002", "author": "Kai Yoshida et.al.", "authors": "Kai Yoshida, Masahiro Mizukami, Seiya Kawano, Canasai Kruengkrai, Hiroaki Sugiyama, Koichiro Yoshino", "id": "2501.12698v1", "paper_url": "http://arxiv.org/abs/2501.12698v1", "repo": "null"}}