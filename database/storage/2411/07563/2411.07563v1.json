{"2411.07563": {"publish_time": "2024-11-12", "title": "Improving Grapheme-to-Phoneme Conversion through In-Context Knowledge Retrieval with Large Language Models", "paper_summary": "Grapheme-to-phoneme (G2P) conversion is a crucial step in Text-to-Speech\n(TTS) systems, responsible for mapping grapheme to corresponding phonetic\nrepresentations. However, it faces ambiguities problems where the same grapheme\ncan represent multiple phonemes depending on contexts, posing a challenge for\nG2P conversion. Inspired by the remarkable success of Large Language Models\n(LLMs) in handling context-aware scenarios, contextual G2P conversion systems\nwith LLMs' in-context knowledge retrieval (ICKR) capabilities are proposed to\npromote disambiguation capability. The efficacy of incorporating ICKR into G2P\nconversion systems is demonstrated thoroughly on the Librig2p dataset. In\nparticular, the best contextual G2P conversion system using ICKR outperforms\nthe baseline with weighted average phoneme error rate (PER) reductions of 2.0%\nabsolute (28.9% relative). Using GPT-4 in the ICKR system can increase of 3.5%\nabsolute (3.8% relative) on the Librig2p dataset.", "paper_summary_zh": "\u97f3\u7d20\u8f49\u63db (G2P) \u662f\u6587\u5b57\u8f49\u8a9e\u97f3 (TTS) \u7cfb\u7d71\u4e2d\u81f3\u95dc\u91cd\u8981\u7684\u4e00\u6b65\uff0c\u8ca0\u8cac\u5c07\u97f3\u7d20\u5c0d\u61c9\u5230\u76f8\u61c9\u7684\u8a9e\u97f3\u8868\u793a\u3002\u7136\u800c\uff0c\u5b83\u9762\u81e8\u8457\u6b67\u7fa9\u554f\u984c\uff0c\u5373\u76f8\u540c\u7684\u97f3\u7d20\u53ef\u4ee5\u8868\u793a\u591a\u500b\u97f3\u7d20\uff0c\u5177\u9ad4\u53d6\u6c7a\u65bc\u4e0a\u4e0b\u6587\uff0c\u9019\u5c0d G2P \u8f49\u63db\u69cb\u6210\u4e86\u6311\u6230\u3002\u53d7\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u5728\u8655\u7406\u4e0a\u4e0b\u6587\u611f\u77e5\u5834\u666f\u4e2d\u53d6\u5f97\u7684\u986f\u8457\u6210\u529f\u555f\u767c\uff0c\u63d0\u51fa\u5177\u5099 LLM \u7684\u4e0a\u4e0b\u6587\u77e5\u8b58\u6aa2\u7d22 (ICKR) \u529f\u80fd\u7684\u4e0a\u4e0b\u6587 G2P \u8f49\u63db\u7cfb\u7d71\uff0c\u4ee5\u63d0\u5347\u6d88\u6b67\u7fa9\u80fd\u529b\u3002\u5728 Librig2p \u8cc7\u6599\u96c6\u4e0a\u5fb9\u5e95\u8b49\u660e\u4e86\u5c07 ICKR \u7d0d\u5165 G2P \u8f49\u63db\u7cfb\u7d71\u7684\u529f\u6548\u3002\u7279\u5225\u662f\uff0c\u4f7f\u7528 ICKR \u7684\u6700\u4f73\u4e0a\u4e0b\u6587 G2P \u8f49\u63db\u7cfb\u7d71\u512a\u65bc\u57fa\u7dda\uff0c\u52a0\u6b0a\u5e73\u5747\u97f3\u7d20\u932f\u8aa4\u7387 (PER) \u964d\u4f4e\u4e86 2.0%\uff08\u76f8\u5c0d\u964d\u4f4e 28.9%\uff09\u3002\u5728 ICKR \u7cfb\u7d71\u4e2d\u4f7f\u7528 GPT-4 \u53ef\u4ee5\u4f7f Librig2p \u8cc7\u6599\u96c6\u7684\u7d55\u5c0d\u503c\u589e\u52a0 3.5%\uff08\u76f8\u5c0d\u589e\u52a0 3.8%\uff09\u3002", "author": "Dongrui Han et.al.", "authors": "Dongrui Han, Mingyu Cui, Jiawen Kang, Xixin Wu, Xunying Liu, Helen Meng", "id": "2411.07563v1", "paper_url": "http://arxiv.org/abs/2411.07563v1", "repo": "null"}}