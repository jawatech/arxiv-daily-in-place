{"2412.03253": {"publish_time": "2024-12-04", "title": "Alignment at Pre-training! Towards Native Alignment for Arabic LLMs", "paper_summary": "The alignment of large language models (LLMs) is critical for developing\neffective and safe language models. Traditional approaches focus on aligning\nmodels during the instruction tuning or reinforcement learning stages, referred\nto in this paper as `post alignment'. We argue that alignment during the\npre-training phase, which we term `native alignment', warrants investigation.\nNative alignment aims to prevent unaligned content from the beginning, rather\nthan relying on post-hoc processing. This approach leverages extensively\naligned pre-training data to enhance the effectiveness and usability of\npre-trained models. Our study specifically explores the application of native\nalignment in the context of Arabic LLMs. We conduct comprehensive experiments\nand ablation studies to evaluate the impact of native alignment on model\nperformance and alignment stability. Additionally, we release open-source\nArabic LLMs that demonstrate state-of-the-art performance on various\nbenchmarks, providing significant benefits to the Arabic LLM community.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u5c0d\u9f4a\u5c0d\u65bc\u958b\u767c\u6709\u6548\u4e14\u5b89\u5168\u7684\u8a9e\u8a00\u6a21\u578b\u81f3\u95dc\u91cd\u8981\u3002\u50b3\u7d71\u65b9\u6cd5\u8457\u91cd\u65bc\u5728\u6307\u4ee4\u5fae\u8abf\u6216\u5f37\u5316\u5b78\u7fd2\u968e\u6bb5\u5c0d\u9f4a\u6a21\u578b\uff0c\u672c\u6587\u7a31\u4e4b\u70ba\u300c\u5f8c\u5c0d\u9f4a\u300d\u3002\u6211\u5011\u8a8d\u70ba\uff0c\u5728\u9810\u8a13\u7df4\u968e\u6bb5\u9032\u884c\u5c0d\u9f4a\uff08\u6211\u5011\u7a31\u4e4b\u70ba\u300c\u539f\u751f\u5c0d\u9f4a\u300d\uff09\u503c\u5f97\u63a2\u8a0e\u3002\u539f\u751f\u5c0d\u9f4a\u65e8\u5728\u5f9e\u4e00\u958b\u59cb\u5c31\u9632\u6b62\u672a\u5c0d\u9f4a\u7684\u5167\u5bb9\uff0c\u800c\u4e0d\u662f\u4f9d\u8cf4\u4e8b\u5f8c\u8655\u7406\u3002\u9019\u7a2e\u65b9\u6cd5\u5145\u5206\u5229\u7528\u7d93\u904e\u5927\u91cf\u5c0d\u9f4a\u7684\u9810\u8a13\u7df4\u8cc7\u6599\uff0c\u4ee5\u589e\u5f37\u9810\u8a13\u7df4\u6a21\u578b\u7684\u6709\u6548\u6027\u548c\u53ef\u7528\u6027\u3002\u6211\u5011\u7684\u7814\u7a76\u7279\u5225\u63a2\u8a0e\u4e86\u539f\u751f\u5c0d\u9f4a\u5728\u963f\u62c9\u4f2f\u8a9e LLM \u4e2d\u7684\u61c9\u7528\u3002\u6211\u5011\u9032\u884c\u4e86\u5168\u9762\u7684\u5be6\u9a57\u548c\u6d88\u878d\u7814\u7a76\uff0c\u4ee5\u8a55\u4f30\u539f\u751f\u5c0d\u9f4a\u5c0d\u6a21\u578b\u6548\u80fd\u548c\u5c0d\u9f4a\u7a69\u5b9a\u6027\u7684\u5f71\u97ff\u3002\u6b64\u5916\uff0c\u6211\u5011\u767c\u5e03\u4e86\u958b\u653e\u539f\u59cb\u78bc\u7684\u963f\u62c9\u4f2f\u8a9e LLM\uff0c\u9019\u4e9b LLM \u5728\u5404\u7a2e\u57fa\u6e96\u6e2c\u8a66\u4e2d\u8868\u73fe\u51fa\u6700\u5148\u9032\u7684\u6548\u80fd\uff0c\u70ba\u963f\u62c9\u4f2f\u8a9e LLM \u793e\u7fa4\u5e36\u4f86\u986f\u8457\u7684\u597d\u8655\u3002", "author": "Juhao Liang et.al.", "authors": "Juhao Liang, Zhenyang Cai, Jianqing Zhu, Huang Huang, Kewei Zong, Bang An, Mosen Alharthi, Juncai He, Lian Zhang, Haizhou Li, Benyou Wang, Jinchao Xu", "id": "2412.03253v1", "paper_url": "http://arxiv.org/abs/2412.03253v1", "repo": "https://github.com/freedomintelligence/acegpt-v2"}}