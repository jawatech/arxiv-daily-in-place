{"2405.18915": {"publish_time": "2024-05-29", "title": "Towards Faithful Chain-of-Thought: Large Language Models are Bridging Reasoners", "paper_summary": "Large language models (LLMs) suffer from serious unfaithful chain-of-thought\n(CoT) issues. Previous work attempts to measure and explain it but lacks\nin-depth analysis within CoTs and does not consider the interactions among all\nreasoning components jointly. In this paper, we first study the CoT\nfaithfulness issue at the granularity of CoT steps, identify two reasoning\nparadigms: centralized reasoning and distributed reasoning, and find their\nrelationship with faithfulness. Subsequently, we conduct a joint analysis of\nthe causal relevance among the context, CoT, and answer during reasoning. The\nresult proves that, when the LLM predicts answers, it can recall correct\ninformation missing in the CoT from the context, leading to unfaithfulness\nissues. Finally, we propose the inferential bridging method to mitigate this\nissue, in which we use the attribution method to recall information as hints\nfor CoT generation and filter out noisy CoTs based on their semantic\nconsistency and attribution scores. Extensive experiments demonstrate that our\napproach effectively alleviates the unfaithful CoT problem.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u5b58\u5728\u56b4\u91cd\u7684\u63a8\u7406\u93c8 (CoT) \u4e0d\u5fe0\u5be6\u554f\u984c\u3002\u5148\u524d\u7684\u7814\u7a76\u5617\u8a66\u6e2c\u91cf\u548c\u89e3\u91cb\u5b83\uff0c\u4f46\u7f3a\u4e4f\u5c0d CoT \u5167\u90e8\u7684\u6df1\u5165\u5206\u6790\uff0c\u4e26\u4e14\u6c92\u6709\u5171\u540c\u8003\u616e\u6240\u6709\u63a8\u7406\u7d44\u6210\u90e8\u5206\u4e4b\u9593\u7684\u4e92\u52d5\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u9996\u5148\u7814\u7a76 CoT \u6b65\u9a5f\u7c92\u5ea6\u7684 CoT \u5fe0\u5be6\u5ea6\u554f\u984c\uff0c\u8b58\u5225\u51fa\u5169\u7a2e\u63a8\u7406\u7bc4\u4f8b\uff1a\u96c6\u4e2d\u63a8\u7406\u548c\u5206\u6563\u63a8\u7406\uff0c\u4e26\u627e\u51fa\u5b83\u5011\u8207\u5fe0\u5be6\u5ea6\u7684\u95dc\u4fc2\u3002\u96a8\u5f8c\uff0c\u6211\u5011\u5c0d\u63a8\u7406\u904e\u7a0b\u4e2d\u7684\u80cc\u666f\u3001CoT \u548c\u7b54\u6848\u4e4b\u9593\u7684\u56e0\u679c\u95dc\u806f\u9032\u884c\u806f\u5408\u5206\u6790\u3002\u7d50\u679c\u8b49\u660e\uff0c\u7576 LLM \u9810\u6e2c\u7b54\u6848\u6642\uff0c\u5b83\u53ef\u4ee5\u5f9e\u80cc\u666f\u4e2d\u53ec\u56de CoT \u4e2d\u907a\u6f0f\u7684\u6b63\u78ba\u8cc7\u8a0a\uff0c\u5c0e\u81f4\u4e0d\u5fe0\u5be6\u554f\u984c\u3002\u6700\u5f8c\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u63a8\u7406\u6a4b\u63a5\u65b9\u6cd5\u4f86\u6e1b\u8f15\u9019\u500b\u554f\u984c\uff0c\u6211\u5011\u5728\u5176\u4e2d\u4f7f\u7528\u6b78\u56e0\u65b9\u6cd5\u5c07\u8cc7\u8a0a\u4f5c\u70ba CoT \u751f\u6210\u7684\u63d0\u793a\u9032\u884c\u53ec\u56de\uff0c\u4e26\u6839\u64da\u5b83\u5011\u7684\u8a9e\u7fa9\u4e00\u81f4\u6027\u548c\u6b78\u56e0\u5206\u6578\u904e\u6ffe\u6389\u6709\u96dc\u8a0a\u7684 CoT\u3002\u5927\u91cf\u7684\u5be6\u9a57\u8b49\u660e\uff0c\u6211\u5011\u7684\u505a\u6cd5\u6709\u6548\u5730\u7de9\u89e3\u4e86\u4e0d\u5fe0\u5be6\u7684 CoT \u554f\u984c\u3002", "author": "Jiachun Li et.al.", "authors": "Jiachun Li, Pengfei Cao, Yubo Chen, Kang Liu, Jun Zhao", "id": "2405.18915v1", "paper_url": "http://arxiv.org/abs/2405.18915v1", "repo": "null"}}