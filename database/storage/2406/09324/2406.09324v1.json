{"2406.09324": {"publish_time": "2024-06-13", "title": "Bag of Tricks: Benchmarking of Jailbreak Attacks on LLMs", "paper_summary": "Although Large Language Models (LLMs) have demonstrated significant\ncapabilities in executing complex tasks in a zero-shot manner, they are\nsusceptible to jailbreak attacks and can be manipulated to produce harmful\noutputs. Recently, a growing body of research has categorized jailbreak attacks\ninto token-level and prompt-level attacks. However, previous work primarily\noverlooks the diverse key factors of jailbreak attacks, with most studies\nconcentrating on LLM vulnerabilities and lacking exploration of\ndefense-enhanced LLMs. To address these issues, we evaluate the impact of\nvarious attack settings on LLM performance and provide a baseline benchmark for\njailbreak attacks, encouraging the adoption of a standardized evaluation\nframework. Specifically, we evaluate the eight key factors of implementing\njailbreak attacks on LLMs from both target-level and attack-level perspectives.\nWe further conduct seven representative jailbreak attacks on six defense\nmethods across two widely used datasets, encompassing approximately 320\nexperiments with about 50,000 GPU hours on A800-80G. Our experimental results\nhighlight the need for standardized benchmarking to evaluate these attacks on\ndefense-enhanced LLMs. Our code is available at\nhttps://github.com/usail-hkust/Bag_of_Tricks_for_LLM_Jailbreaking.", "paper_summary_zh": "\u5118\u7ba1\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u5df2\u5c55\u73fe\u51fa\u4ee5\u96f6\u6b21\u5b78\u7fd2\u7684\u65b9\u5f0f\u57f7\u884c\u8907\u96dc\u4efb\u52d9\u7684\u986f\u8457\u80fd\u529b\uff0c\u5b83\u5011\u4ecd\u5bb9\u6613\u53d7\u5230\u8d8a\u7344\u653b\u64ca\uff0c\u4e26\u53ef\u80fd\u88ab\u64cd\u7e31\u4ee5\u7522\u751f\u6709\u5bb3\u7684\u8f38\u51fa\u3002\u6700\u8fd1\uff0c\u8d8a\u4f86\u8d8a\u591a\u7684\u7814\u7a76\u5c07\u8d8a\u7344\u653b\u64ca\u5206\u985e\u70ba\u4ee3\u5e63\u7d1a\u5225\u548c\u63d0\u793a\u7d1a\u5225\u653b\u64ca\u3002\u7136\u800c\uff0c\u5148\u524d\u7684\u7814\u7a76\u4e3b\u8981\u5ffd\u7565\u4e86\u8d8a\u7344\u653b\u64ca\u7684\u591a\u7a2e\u95dc\u9375\u56e0\u7d20\uff0c\u5927\u591a\u6578\u7814\u7a76\u90fd\u96c6\u4e2d\u5728 LLM \u6f0f\u6d1e\u4e0a\uff0c\u800c\u7f3a\u4e4f\u5c0d\u9632\u79a6\u589e\u5f37 LLM \u7684\u63a2\u7d22\u3002\u70ba\u4e86\u89e3\u6c7a\u9019\u4e9b\u554f\u984c\uff0c\u6211\u5011\u8a55\u4f30\u4e86\u5404\u7a2e\u653b\u64ca\u8a2d\u7f6e\u5c0d LLM \u6548\u80fd\u7684\u5f71\u97ff\uff0c\u4e26\u70ba\u8d8a\u7344\u653b\u64ca\u63d0\u4f9b\u57fa\u7dda\u57fa\u6e96\uff0c\u9f13\u52f5\u63a1\u7528\u6a19\u6e96\u5316\u7684\u8a55\u4f30\u67b6\u69cb\u3002\u5177\u9ad4\u4f86\u8aaa\uff0c\u6211\u5011\u5f9e\u76ee\u6a19\u5c64\u7d1a\u548c\u653b\u64ca\u5c64\u7d1a\u7684\u89d2\u5ea6\u8a55\u4f30\u4e86\u5728 LLM \u4e0a\u5be6\u65bd\u8d8a\u7344\u653b\u64ca\u7684\u516b\u500b\u95dc\u9375\u56e0\u7d20\u3002\u6211\u5011\u9032\u4e00\u6b65\u5c0d\u5169\u500b\u5ee3\u6cdb\u4f7f\u7528\u7684\u8cc7\u6599\u96c6\u4e0a\u7684\u516d\u7a2e\u9632\u79a6\u65b9\u6cd5\u9032\u884c\u4e86\u4e03\u6b21\u4ee3\u8868\u6027\u7684\u8d8a\u7344\u653b\u64ca\uff0c\u6db5\u84cb\u4e86\u5927\u7d04 320 \u500b\u5be6\u9a57\uff0c\u5728 A800-80G \u4e0a\u5927\u7d04\u6709 50,000 \u500b GPU \u5c0f\u6642\u3002\u6211\u5011\u7684\u5be6\u9a57\u7d50\u679c\u5f37\u8abf\u4e86\u9700\u8981\u6a19\u6e96\u5316\u7684\u57fa\u6e96\u6e2c\u8a66\u4f86\u8a55\u4f30\u9019\u4e9b\u5c0d\u9632\u79a6\u589e\u5f37 LLM \u7684\u653b\u64ca\u3002\u6211\u5011\u7684\u7a0b\u5f0f\u78bc\u53ef\u5728 https://github.com/usail-hkust/Bag_of_Tricks_for_LLM_Jailbreaking \u53d6\u5f97\u3002", "author": "Zhao Xu et.al.", "authors": "Zhao Xu, Fan Liu, Hao Liu", "id": "2406.09324v1", "paper_url": "http://arxiv.org/abs/2406.09324v1", "repo": "https://github.com/usail-hkust/bag_of_tricks_for_llm_jailbreaking"}}