{"2501.19377": {"publish_time": "2025-01-31", "title": "SELMA: A Speech-Enabled Language Model for Virtual Assistant Interactions", "paper_summary": "In this work, we present and evaluate SELMA, a Speech-Enabled Language Model\nfor virtual Assistant interactions that integrates audio and text as inputs to\na Large Language Model (LLM). SELMA is designed to handle three primary and two\nauxiliary tasks related to interactions with virtual assistants simultaneously\nwithin a single end-to-end model. We employ low-rank adaptation modules for\nparameter-efficient training of both the audio encoder and the LLM.\nAdditionally, we implement a feature pooling strategy enabling the system to\nrecognize global patterns and improve accuracy on tasks less reliant on\nindividual sequence elements. Experimental results on Voice Trigger (VT)\ndetection, Device-Directed Speech Detection (DDSD), and Automatic Speech\nRecognition (ASR), demonstrate that our approach both simplifies the typical\ninput processing pipeline of virtual assistants significantly and also improves\nperformance compared to dedicated models for each individual task. SELMA yields\nrelative Equal-Error Rate improvements of 64% on the VT detection task, and 22%\non DDSD, while also achieving word error rates close to the baseline.", "paper_summary_zh": "\u5728\u9019\u9805\u5de5\u4f5c\u4e2d\uff0c\u6211\u5011\u63d0\u51fa\u4e26\u8a55\u4f30\u4e86 SELMA\uff0c\u4e00\u500b\u8a9e\u97f3\u555f\u7528\u8a9e\u8a00\u6a21\u578b\uff0c\u7528\u65bc\u865b\u64ec\u52a9\u7406\u4e92\u52d5\uff0c\u5b83\u5c07\u97f3\u8a0a\u548c\u6587\u5b57\u6574\u5408\u70ba\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u7684\u8f38\u5165\u3002SELMA \u88ab\u8a2d\u8a08\u70ba\u540c\u6642\u8655\u7406\u8207\u865b\u64ec\u52a9\u7406\u4e92\u52d5\u76f8\u95dc\u7684\u4e09\u500b\u4e3b\u8981\u4efb\u52d9\u548c\u5169\u500b\u8f14\u52a9\u4efb\u52d9\uff0c\u6240\u6709\u4efb\u52d9\u90fd\u5728\u55ae\u4e00\u7aef\u5230\u7aef\u6a21\u578b\u4e2d\u9032\u884c\u3002\u6211\u5011\u63a1\u7528\u4f4e\u79e9\u9069\u61c9\u6a21\u7d44\uff0c\u7528\u65bc\u97f3\u8a0a\u7de8\u78bc\u5668\u548c LLM \u7684\u53c3\u6578\u6709\u6548\u7387\u8a13\u7df4\u3002\u6b64\u5916\uff0c\u6211\u5011\u5be6\u4f5c\u4e86\u4e00\u500b\u7279\u5fb5\u6c60\u5316\u7b56\u7565\uff0c\u8b93\u7cfb\u7d71\u80fd\u8fa8\u8b58\u5168\u57df\u6a21\u5f0f\uff0c\u4e26\u63d0\u5347\u5c0d\u4e0d\u592a\u4f9d\u8cf4\u500b\u5225\u5e8f\u5217\u5143\u7d20\u7684\u4efb\u52d9\u7684\u6e96\u78ba\u5ea6\u3002\u8a9e\u97f3\u89f8\u767c (VT) \u5075\u6e2c\u3001\u88dd\u7f6e\u5c0e\u5411\u8a9e\u97f3\u5075\u6e2c (DDSD) \u548c\u81ea\u52d5\u8a9e\u97f3\u8fa8\u8b58 (ASR) \u7684\u5be6\u9a57\u7d50\u679c\u986f\u793a\uff0c\u6211\u5011\u7684\u505a\u6cd5\u5927\u5e45\u7c21\u5316\u4e86\u865b\u64ec\u52a9\u7406\u7684\u5178\u578b\u8f38\u5165\u8655\u7406\u7ba1\u7dda\uff0c\u800c\u4e14\u4e5f\u63d0\u5347\u4e86\u6548\u80fd\uff0c\u512a\u65bc\u91dd\u5c0d\u6bcf\u500b\u500b\u5225\u4efb\u52d9\u7684\u5c08\u7528\u6a21\u578b\u3002SELMA \u5728 VT \u5075\u6e2c\u4efb\u52d9\u4e0a\u7522\u751f\u4e86 64% \u7684\u76f8\u5c0d\u7b49\u932f\u8aa4\u7387\u6539\u9032\uff0c\u5728 DDSD \u4e0a\u7522\u751f\u4e86 22% \u7684\u6539\u9032\uff0c\u540c\u6642\u4e5f\u5728\u5b57\u5143\u932f\u8aa4\u7387\u4e0a\u9054\u5230\u63a5\u8fd1\u57fa\u7dda\u7684\u8868\u73fe\u3002", "author": "Dominik Wagner et.al.", "authors": "Dominik Wagner, Alexander Churchill, Siddharth Sigtia, Erik Marchi", "id": "2501.19377v2", "paper_url": "http://arxiv.org/abs/2501.19377v2", "repo": "null"}}