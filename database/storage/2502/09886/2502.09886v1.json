{"2502.09886": {"publish_time": "2025-02-14", "title": "Video2Policy: Scaling up Manipulation Tasks in Simulation through Internet Videos", "paper_summary": "Simulation offers a promising approach for cheaply scaling training data for\ngeneralist policies. To scalably generate data from diverse and realistic\ntasks, existing algorithms either rely on large language models (LLMs) that may\nhallucinate tasks not interesting for robotics; or digital twins, which require\ncareful real-to-sim alignment and are hard to scale. To address these\nchallenges, we introduce Video2Policy, a novel framework that leverages\ninternet RGB videos to reconstruct tasks based on everyday human behavior. Our\napproach comprises two phases: (1) task generation in simulation from videos;\nand (2) reinforcement learning utilizing in-context LLM-generated reward\nfunctions iteratively. We demonstrate the efficacy of Video2Policy by\nreconstructing over 100 videos from the Something-Something-v2 (SSv2) dataset,\nwhich depicts diverse and complex human behaviors on 9 different tasks. Our\nmethod can successfully train RL policies on such tasks, including complex and\nchallenging tasks such as throwing. Finally, we show that the generated\nsimulation data can be scaled up for training a general policy, and it can be\ntransferred back to the real robot in a Real2Sim2Real way.", "paper_summary_zh": "\u6a21\u64ec\u63d0\u4f9b\u4e86\u4e00\u7a2e\u6709\u524d\u9014\u7684\u65b9\u6cd5\uff0c\u53ef\u4ee5\u7528\u65bc\u64f4\u5c55\u8a13\u7df4\u8cc7\u6599\uff0c\u4ee5\u5236\u5b9a\u901a\u624d\u653f\u7b56\u3002\u70ba\u4e86\u5f9e\u591a\u6a23\u5316\u4e14\u903c\u771f\u7684\u4efb\u52d9\u4e2d\u53ef\u64f4\u5145\u5730\u7522\u751f\u8cc7\u6599\uff0c\u73fe\u6709\u6f14\u7b97\u6cd5\u4ef0\u8cf4\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM)\uff0c\u9019\u4e9b\u6a21\u578b\u53ef\u80fd\u6703\u7522\u751f\u5c0d\u6a5f\u5668\u4eba\u6280\u8853\u4e0d\u611f\u8208\u8da3\u7684\u4efb\u52d9\uff1b\u6216\u8005\u4ef0\u8cf4\u6578\u4f4d\u96d9\u80de\u80ce\uff0c\u9019\u9700\u8981\u4ed4\u7d30\u5730\u5c07\u771f\u5be6\u74b0\u5883\u8207\u6a21\u64ec\u74b0\u5883\u5c0d\u9f4a\uff0c\u800c\u4e14\u5f88\u96e3\u64f4\u5145\u3002\u70ba\u4e86\u61c9\u5c0d\u9019\u4e9b\u6311\u6230\uff0c\u6211\u5011\u5f15\u5165\u4e86 Video2Policy\uff0c\u9019\u662f\u4e00\u500b\u65b0\u7a4e\u7684\u67b6\u69cb\uff0c\u5b83\u5229\u7528\u7db2\u8def\u4e0a\u7684 RGB \u5f71\u7247\uff0c\u6839\u64da\u65e5\u5e38\u4eba\u985e\u884c\u70ba\u4f86\u91cd\u5efa\u4efb\u52d9\u3002\u6211\u5011\u7684\u505a\u6cd5\u5305\u542b\u5169\u500b\u968e\u6bb5\uff1a(1) \u5f9e\u5f71\u7247\u4e2d\u5728\u6a21\u64ec\u74b0\u5883\u4e2d\u7522\u751f\u4efb\u52d9\uff1b\u4ee5\u53ca (2) \u5229\u7528\u5728\u60c5\u5883\u4e2d\u7531 LLM \u7522\u751f\u7684\u734e\u52f5\u51fd\u6578\uff0c\u53cd\u8986\u9032\u884c\u5f37\u5316\u5b78\u7fd2\u3002\u6211\u5011\u900f\u904e\u91cd\u5efa Something-Something-v2 (SSv2) \u8cc7\u6599\u96c6\u4e2d\u7684 100 \u591a\u500b\u5f71\u7247\u4f86\u5c55\u793a Video2Policy \u7684\u6548\u80fd\uff0c\u9019\u4e9b\u5f71\u7247\u63cf\u7e6a\u4e86 9 \u9805\u4e0d\u540c\u4efb\u52d9\u4e2d\u591a\u6a23\u5316\u4e14\u8907\u96dc\u7684\u4eba\u985e\u884c\u70ba\u3002\u6211\u5011\u7684\u505a\u6cd5\u53ef\u4ee5\u5728\u9019\u4e9b\u4efb\u52d9\u4e0a\u6210\u529f\u8a13\u7df4 RL \u653f\u7b56\uff0c\u5305\u62ec\u8907\u96dc\u4e14\u5177\u6311\u6230\u6027\u7684\u4efb\u52d9\uff0c\u4f8b\u5982\u6295\u64f2\u3002\u6700\u5f8c\uff0c\u6211\u5011\u5c55\u793a\u4e86\u7522\u751f\u7684\u6a21\u64ec\u8cc7\u6599\u53ef\u4ee5\u64f4\u5145\u5230\u8a13\u7df4\u4e00\u822c\u653f\u7b56\uff0c\u800c\u4e14\u53ef\u4ee5\u900f\u904e Real2Sim2Real \u7684\u65b9\u5f0f\u8f49\u79fb\u56de\u771f\u5be6\u6a5f\u5668\u4eba\u3002", "author": "Weirui Ye et.al.", "authors": "Weirui Ye, Fangchen Liu, Zheng Ding, Yang Gao, Oleh Rybkin, Pieter Abbeel", "id": "2502.09886v1", "paper_url": "http://arxiv.org/abs/2502.09886v1", "repo": "null"}}