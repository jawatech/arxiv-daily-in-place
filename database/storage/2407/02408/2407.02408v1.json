{"2407.02408": {"publish_time": "2024-07-02", "title": "CEB: Compositional Evaluation Benchmark for Fairness in Large Language Models", "paper_summary": "As Large Language Models (LLMs) are increasingly deployed to handle various\nnatural language processing (NLP) tasks, concerns regarding the potential\nnegative societal impacts of LLM-generated content have also arisen. To\nevaluate the biases exhibited by LLMs, researchers have recently proposed a\nvariety of datasets. However, existing bias evaluation efforts often focus on\nonly a particular type of bias and employ inconsistent evaluation metrics,\nleading to difficulties in comparison across different datasets and LLMs. To\naddress these limitations, we collect a variety of datasets designed for the\nbias evaluation of LLMs, and further propose CEB, a Compositional Evaluation\nBenchmark that covers different types of bias across different social groups\nand tasks. The curation of CEB is based on our newly proposed compositional\ntaxonomy, which characterizes each dataset from three dimensions: bias types,\nsocial groups, and tasks. By combining the three dimensions, we develop a\ncomprehensive evaluation strategy for the bias in LLMs. Our experiments\ndemonstrate that the levels of bias vary across these dimensions, thereby\nproviding guidance for the development of specific bias mitigation methods.", "paper_summary_zh": "\u7531\u65bc\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM)  zunehmend zur Bew\u00e4ltigung verschiedener Aufgaben der Verarbeitung nat\u00fcrlicher Sprache (NLP) eingesetzt werden, sind auch Bedenken hinsichtlich der potenziellen negativen gesellschaftlichen Auswirkungen von LLM-generierten Inhalten aufgekommen. Um die von LLMs aufgewiesenen Verzerrungen zu bewerten, haben Forscher in j\u00fcngster Zeit eine Vielzahl von Datens\u00e4tzen vorgeschlagen. Allerdings konzentrieren sich bestehende Bem\u00fchungen zur Verzerrungsbewertung oft nur auf eine bestimmte Art von Verzerrung und verwenden inkonsistente Bewertungsmetriken, was zu Schwierigkeiten beim Vergleich verschiedener Datens\u00e4tze und LLMs f\u00fchrt. Um diese Einschr\u00e4nkungen zu beheben, sammeln wir eine Vielzahl von Datens\u00e4tzen, die f\u00fcr die Verzerrungsbewertung von LLMs konzipiert wurden, und schlagen au\u00dferdem CEB vor, einen kompositorischen Bewertungsma\u00dfstab, der verschiedene Arten von Verzerrungen in verschiedenen sozialen Gruppen und Aufgaben abdeckt. Die Zusammenstellung von CEB basiert auf unserer neu vorgeschlagenen kompositorischen Taxonomie, die jeden Datensatz anhand von drei Dimensionen charakterisiert: Verzerrungstypen, soziale Gruppen und Aufgaben. Durch die Kombination der drei Dimensionen entwickeln wir eine umfassende Bewertungsstrategie f\u00fcr die Verzerrung in LLMs. Unsere Experimente zeigen, dass die Verzerrungsstufen in diesen Dimensionen variieren und bieten so eine Anleitung f\u00fcr die Entwicklung spezifischer Methoden zur Reduzierung von Verzerrungen.", "author": "Song Wang et.al.", "authors": "Song Wang, Peng Wang, Tong Zhou, Yushun Dong, Zhen Tan, Jundong Li", "id": "2407.02408v1", "paper_url": "http://arxiv.org/abs/2407.02408v1", "repo": "null"}}