{"2407.06540": {"publish_time": "2024-07-09", "title": "General and Task-Oriented Video Segmentation", "paper_summary": "We present GvSeg, a general video segmentation framework for addressing four\ndifferent video segmentation tasks (i.e., instance, semantic, panoptic, and\nexemplar-guided) while maintaining an identical architectural design.\nCurrently, there is a trend towards developing general video segmentation\nsolutions that can be applied across multiple tasks. This streamlines research\nendeavors and simplifies deployment. However, such a highly homogenized\nframework in current design, where each element maintains uniformity, could\noverlook the inherent diversity among different tasks and lead to suboptimal\nperformance. To tackle this, GvSeg: i) provides a holistic disentanglement and\nmodeling for segment targets, thoroughly examining them from the perspective of\nappearance, position, and shape, and on this basis, ii) reformulates the query\ninitialization, matching and sampling strategies in alignment with the\ntask-specific requirement. These architecture-agnostic innovations empower\nGvSeg to effectively address each unique task by accommodating the specific\nproperties that characterize them. Extensive experiments on seven gold-standard\nbenchmark datasets demonstrate that GvSeg surpasses all existing\nspecialized/general solutions by a significant margin on four different video\nsegmentation tasks.", "paper_summary_zh": "\u6211\u5011\u63d0\u51fa GvSeg\uff0c\u4e00\u500b\u901a\u7528\u5f71\u7247\u5206\u5272\u67b6\u69cb\uff0c\u7528\u65bc\u8655\u7406\u56db\u7a2e\u4e0d\u540c\u7684\u5f71\u7247\u5206\u5272\u4efb\u52d9\uff08\u5373\u5be6\u4f8b\u3001\u8a9e\u7fa9\u3001\u5168\u666f\u548c\u7bc4\u4f8b\u5f15\u5c0e\uff09\uff0c\u540c\u6642\u7dad\u6301\u76f8\u540c\u7684\u67b6\u69cb\u8a2d\u8a08\u3002\n\u76ee\u524d\uff0c\u767c\u5c55\u901a\u7528\u5f71\u7247\u5206\u5272\u89e3\u6c7a\u65b9\u6848\u7684\u8da8\u52e2\u6b63\u8208\u8d77\uff0c\u9019\u4e9b\u89e3\u6c7a\u65b9\u6848\u53ef\u61c9\u7528\u65bc\u591a\u9805\u4efb\u52d9\u3002\u9019\u7c21\u5316\u4e86\u7814\u7a76\u5de5\u4f5c\u4e26\u7c21\u5316\u4e86\u90e8\u7f72\u3002\u7136\u800c\uff0c\u5728\u76ee\u524d\u7684\u8a2d\u8a08\u4e2d\uff0c\u9019\u7a2e\u9ad8\u5ea6\u540c\u8cea\u5316\u7684\u67b6\u69cb\uff08\u5176\u4e2d\u6bcf\u500b\u5143\u7d20\u90fd\u4fdd\u6301\u4e00\u81f4\u6027\uff09\u53ef\u80fd\u6703\u5ffd\u7565\u4e0d\u540c\u4efb\u52d9\u4e4b\u9593\u7684\u56fa\u6709\u5dee\u7570\u6027\uff0c\u4e26\u5c0e\u81f4\u6b21\u4f73\u6548\u80fd\u3002\u70ba\u4e86\u89e3\u6c7a\u9019\u500b\u554f\u984c\uff0cGvSeg\uff1ai) \u63d0\u4f9b\u4e86\u4e00\u500b\u6574\u9ad4\u7684\u89e3\u958b\u548c\u5efa\u6a21\uff0c\u7528\u65bc\u5206\u5272\u76ee\u6a19\uff0c\u5f9e\u5916\u89c0\u3001\u4f4d\u7f6e\u548c\u5f62\u72c0\u7684\u89d2\u5ea6\u5fb9\u5e95\u6aa2\u8996\u5b83\u5011\uff0c\u4e26\u5728\u6b64\u57fa\u790e\u4e0a\uff0cii) \u91cd\u65b0\u5236\u5b9a\u67e5\u8a62\u521d\u59cb\u5316\u3001\u5339\u914d\u548c\u53d6\u6a23\u7b56\u7565\uff0c\u4ee5\u7b26\u5408\u7279\u5b9a\u4efb\u52d9\u7684\u8981\u6c42\u3002\u9019\u4e9b\u8207\u67b6\u69cb\u7121\u95dc\u7684\u5275\u65b0\u4f7f GvSeg \u80fd\u5920\u901a\u904e\u9069\u61c9\u5b83\u5011\u7684\u7279\u5fb5\u4f86\u6709\u6548\u5730\u89e3\u6c7a\u6bcf\u500b\u7368\u7279\u7684\u4efb\u52d9\u3002\u5728\u4e03\u500b\u9ec3\u91d1\u6a19\u6e96\u57fa\u6e96\u8cc7\u6599\u96c6\u4e0a\u7684\u5927\u91cf\u5be6\u9a57\u8868\u660e\uff0cGvSeg \u5728\u56db\u7a2e\u4e0d\u540c\u7684\u5f71\u7247\u5206\u5272\u4efb\u52d9\u4e0a\u4ee5\u986f\u8457\u5e45\u5ea6\u8d85\u8d8a\u6240\u6709\u73fe\u6709\u7684\u5c08\u7528/\u901a\u7528\u89e3\u6c7a\u65b9\u6848\u3002", "author": "Mu Chen et.al.", "authors": "Mu Chen, Liulei Li, Wenguan Wang, Ruijie Quan, Yi Yang", "id": "2407.06540v1", "paper_url": "http://arxiv.org/abs/2407.06540v1", "repo": "https://github.com/kagawa588/gvseg"}}