{"2404.16954": {"publish_time": "2024-04-25", "title": "Taming False Positives in Out-of-Distribution Detection with Human Feedback", "paper_summary": "Robustness to out-of-distribution (OOD) samples is crucial for safely\ndeploying machine learning models in the open world. Recent works have focused\non designing scoring functions to quantify OOD uncertainty. Setting appropriate\nthresholds for these scoring functions for OOD detection is challenging as OOD\nsamples are often unavailable up front. Typically, thresholds are set to\nachieve a desired true positive rate (TPR), e.g., $95\\%$ TPR. However, this can\nlead to very high false positive rates (FPR), ranging from 60 to 96\\%, as\nobserved in the Open-OOD benchmark. In safety-critical real-life applications,\ne.g., medical diagnosis, controlling the FPR is essential when dealing with\nvarious OOD samples dynamically. To address these challenges, we propose a\nmathematically grounded OOD detection framework that leverages expert feedback\nto \\emph{safely} update the threshold on the fly. We provide theoretical\nresults showing that it is guaranteed to meet the FPR constraint at all times\nwhile minimizing the use of human feedback. Another key feature of our\nframework is that it can work with any scoring function for OOD uncertainty\nquantification. Empirical evaluation of our system on synthetic and benchmark\nOOD datasets shows that our method can maintain FPR at most $5\\%$ while\nmaximizing TPR.", "paper_summary_zh": "", "author": "Harit Vishwakarma et.al.", "authors": "Harit Vishwakarma,Heguang Lin,Ramya Korlakai Vinayak", "id": "2404.16954v1", "paper_url": "http://arxiv.org/abs/2404.16954v1", "repo": "https://github.com/2454511550lin/tamefalsepositives-ood"}}