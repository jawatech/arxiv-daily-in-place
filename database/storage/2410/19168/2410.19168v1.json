{"2410.19168": {"publish_time": "2024-10-24", "title": "MMAU: A Massive Multi-Task Audio Understanding and Reasoning Benchmark", "paper_summary": "The ability to comprehend audio--which includes speech, non-speech sounds,\nand music--is crucial for AI agents to interact effectively with the world. We\npresent MMAU, a novel benchmark designed to evaluate multimodal audio\nunderstanding models on tasks requiring expert-level knowledge and complex\nreasoning. MMAU comprises 10k carefully curated audio clips paired with\nhuman-annotated natural language questions and answers spanning speech,\nenvironmental sounds, and music. It includes information extraction and\nreasoning questions, requiring models to demonstrate 27 distinct skills across\nunique and challenging tasks. Unlike existing benchmarks, MMAU emphasizes\nadvanced perception and reasoning with domain-specific knowledge, challenging\nmodels to tackle tasks akin to those faced by experts. We assess 18 open-source\nand proprietary (Large) Audio-Language Models, demonstrating the significant\nchallenges posed by MMAU. Notably, even the most advanced Gemini Pro v1.5\nachieves only 52.97% accuracy, and the state-of-the-art open-source Qwen2-Audio\nachieves only 52.50%, highlighting considerable room for improvement. We\nbelieve MMAU will drive the audio and multimodal research community to develop\nmore advanced audio understanding models capable of solving complex audio\ntasks.", "paper_summary_zh": "\u7406\u89e3\u97f3\u8a0a\uff08\u5305\u62ec\u8a9e\u97f3\u3001\u975e\u8a9e\u97f3\u8072\u97f3\u548c\u97f3\u6a02\uff09\u7684\u80fd\u529b\u5c0d\u65bc AI \u4ee3\u7406\u7a0b\u5f0f\u8207\u4e16\u754c\u6709\u6548\u4e92\u52d5\u81f3\u95dc\u91cd\u8981\u3002\u6211\u5011\u63d0\u51fa MMAU\uff0c\u9019\u662f\u4e00\u500b\u65b0\u7a4e\u7684\u57fa\u6e96\uff0c\u65e8\u5728\u8a55\u4f30\u591a\u6a21\u614b\u97f3\u8a0a\u7406\u89e3\u6a21\u578b\u5728\u9700\u8981\u5c08\u5bb6\u7d1a\u77e5\u8b58\u548c\u8907\u96dc\u63a8\u7406\u4efb\u52d9\u4e0a\u7684\u8868\u73fe\u3002MMAU \u5305\u542b 10k \u500b\u7d93\u904e\u4ed4\u7d30\u7b56\u5283\u7684\u97f3\u8a0a\u7247\u6bb5\uff0c\u4e26\u642d\u914d\u4eba\u5de5\u6a19\u8a3b\u7684\u81ea\u7136\u8a9e\u8a00\u554f\u984c\u548c\u7b54\u6848\uff0c\u6db5\u84cb\u8a9e\u97f3\u3001\u74b0\u5883\u97f3\u548c\u97f3\u6a02\u3002\u5b83\u5305\u62ec\u8cc7\u8a0a\u8403\u53d6\u548c\u63a8\u7406\u554f\u984c\uff0c\u8981\u6c42\u6a21\u578b\u5728\u7368\u7279\u4e14\u5177\u6709\u6311\u6230\u6027\u7684\u4efb\u52d9\u4e2d\u5c55\u73fe 27 \u9805\u4e0d\u540c\u7684\u6280\u80fd\u3002\u8207\u73fe\u6709\u7684\u57fa\u6e96\u4e0d\u540c\uff0cMMAU \u5f37\u8abf\u9032\u968e\u611f\u77e5\u548c\u5177\u5099\u7279\u5b9a\u9818\u57df\u77e5\u8b58\u7684\u63a8\u7406\uff0c\u6311\u6230\u6a21\u578b\u8655\u7406\u985e\u4f3c\u5c08\u5bb6\u6240\u9762\u5c0d\u4efb\u52d9\u3002\u6211\u5011\u8a55\u4f30\u4e86 18 \u500b\u958b\u6e90\u548c\u5c08\u6709\uff08\u5927\u578b\uff09\u97f3\u8a0a\u8a9e\u8a00\u6a21\u578b\uff0c\u8b49\u660e\u4e86 MMAU \u69cb\u6210\u7684\u91cd\u5927\u6311\u6230\u3002\u503c\u5f97\u6ce8\u610f\u7684\u662f\uff0c\u5373\u4f7f\u662f\u6700\u5148\u9032\u7684 Gemini Pro v1.5 \u4e5f\u50c5\u9054\u5230 52.97% \u7684\u6e96\u78ba\u5ea6\uff0c\u800c\u6700\u5148\u9032\u7684\u958b\u6e90 Qwen2-Audio \u4e5f\u50c5\u9054\u5230 52.50%\uff0c\u7a81\u986f\u51fa\u6709\u5f88\u5927\u7684\u6539\u9032\u7a7a\u9593\u3002\u6211\u5011\u76f8\u4fe1 MMAU \u5c07\u9a45\u52d5\u97f3\u8a0a\u548c\u591a\u6a21\u614b\u7814\u7a76\u793e\u7fa4\u958b\u767c\u66f4\u5148\u9032\u7684\u97f3\u8a0a\u7406\u89e3\u6a21\u578b\uff0c\u80fd\u5920\u89e3\u6c7a\u8907\u96dc\u7684\u97f3\u8a0a\u4efb\u52d9\u3002", "author": "S Sakshi et.al.", "authors": "S Sakshi, Utkarsh Tyagi, Sonal Kumar, Ashish Seth, Ramaneswaran Selvakumar, Oriol Nieto, Ramani Duraiswami, Sreyan Ghosh, Dinesh Manocha", "id": "2410.19168v1", "paper_url": "http://arxiv.org/abs/2410.19168v1", "repo": "null"}}