{"2501.19069": {"publish_time": "2025-01-31", "title": "Improving vision-language alignment with graph spiking hybrid Networks", "paper_summary": "To bridge the semantic gap between vision and language (VL), it is necessary\nto develop a good alignment strategy, which includes handling semantic\ndiversity, abstract representation of visual information, and generalization\nability of models. Recent works use detector-based bounding boxes or patches\nwith regular partitions to represent visual semantics. While current paradigms\nhave made strides, they are still insufficient for fully capturing the nuanced\ncontextual relations among various objects. This paper proposes a comprehensive\nvisual semantic representation module, necessitating the utilization of\npanoptic segmentation to generate coherent fine-grained semantic features.\nFurthermore, we propose a novel Graph Spiking Hybrid Network (GSHN) that\nintegrates the complementary advantages of Spiking Neural Networks (SNNs) and\nGraph Attention Networks (GATs) to encode visual semantic information.\nIntriguingly, the model not only encodes the discrete and continuous latent\nvariables of instances but also adeptly captures both local and global\ncontextual features, thereby significantly enhancing the richness and diversity\nof semantic representations. Leveraging the spatiotemporal properties inherent\nin SNNs, we employ contrastive learning (CL) to enhance the similarity-based\nrepresentation of embeddings. This strategy alleviates the computational\noverhead of the model and enriches meaningful visual representations by\nconstructing positive and negative sample pairs. We design an innovative\npre-training method, Spiked Text Learning (STL), which uses text features to\nimprove the encoding ability of discrete semantics. Experiments show that the\nproposed GSHN exhibits promising results on multiple VL downstream tasks.", "paper_summary_zh": "<paragraph>\u70ba\u4e86\u5f4c\u5408\u8996\u89ba\u548c\u8a9e\u8a00 (VL) \u4e4b\u9593\u7684\u8a9e\u610f\u5dee\u8ddd\uff0c\u5fc5\u9808\u5236\u5b9a\u826f\u597d\u7684\u5c0d\u9f4a\u7b56\u7565\uff0c\u5176\u4e2d\u5305\u62ec\u8655\u7406\u8a9e\u610f\u591a\u6a23\u6027\u3001\u8996\u89ba\u8cc7\u8a0a\u7684\u62bd\u8c61\u8868\u793a\u4ee5\u53ca\u6a21\u578b\u7684\u6cdb\u5316\u80fd\u529b\u3002\u6700\u8fd1\u7684\u7814\u7a76\u4f7f\u7528\u57fa\u65bc\u5075\u6e2c\u5668\u7684\u908a\u754c\u6846\u6216\u5177\u6709\u898f\u5247\u5206\u5272\u7684\u5340\u584a\u4f86\u8868\u793a\u8996\u89ba\u8a9e\u610f\u3002\u96d6\u7136\u76ee\u524d\u7684\u7bc4\u4f8b\u5df2\u53d6\u5f97\u9032\u5c55\uff0c\u4f46\u5c0d\u65bc\u5b8c\u5168\u6355\u6349\u5404\u7a2e\u7269\u4ef6\u4e4b\u9593\u7684\u7d30\u5fae\u8108\u7d61\u95dc\u4fc2\u4ecd\u4e0d\u8db3\u5920\u3002\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u500b\u5168\u9762\u7684\u8996\u89ba\u8a9e\u610f\u8868\u793a\u6a21\u7d44\uff0c\u9700\u8981\u5229\u7528\u5168\u666f\u5206\u5272\u4f86\u7522\u751f\u9023\u8cab\u7684\u7d30\u7c92\u5ea6\u8a9e\u610f\u7279\u5fb5\u3002\u6b64\u5916\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u4e00\u500b\u65b0\u7a4e\u7684\u5716\u5f62\u8108\u885d\u6df7\u5408\u7db2\u8def (GSHN)\uff0c\u5b83\u6574\u5408\u4e86\u8108\u885d\u795e\u7d93\u7db2\u8def (SNN) \u548c\u5716\u5f62\u6ce8\u610f\u529b\u7db2\u8def (GAT) \u7684\u4e92\u88dc\u512a\u52e2\u4f86\u7de8\u78bc\u8996\u89ba\u8a9e\u610f\u8cc7\u8a0a\u3002\u6709\u8da3\u7684\u662f\uff0c\u8a72\u6a21\u578b\u4e0d\u50c5\u7de8\u78bc\u5be6\u4f8b\u7684\u96e2\u6563\u548c\u9023\u7e8c\u6f5b\u5728\u8b8a\u6578\uff0c\u9084\u80fd\u5de7\u5999\u5730\u6355\u6349\u5c40\u90e8\u548c\u5168\u57df\u8108\u7d61\u7279\u5fb5\uff0c\u5f9e\u800c\u986f\u8457\u589e\u5f37\u8a9e\u610f\u8868\u793a\u7684\u8c50\u5bcc\u6027\u548c\u591a\u6a23\u6027\u3002\u5229\u7528 SNN \u4e2d\u56fa\u6709\u7684\u6642\u7a7a\u7279\u6027\uff0c\u6211\u5011\u63a1\u7528\u5c0d\u6bd4\u5b78\u7fd2 (CL) \u4f86\u589e\u5f37\u5d4c\u5165\u7684\u57fa\u65bc\u76f8\u4f3c\u6027\u7684\u8868\u793a\u3002\u6b64\u7b56\u7565\u6e1b\u8f15\u4e86\u6a21\u578b\u7684\u8a08\u7b97\u8ca0\u64d4\uff0c\u4e26\u900f\u904e\u5efa\u69cb\u6b63\u8ca0\u6a23\u672c\u5c0d\u4f86\u8c50\u5bcc\u6709\u610f\u7fa9\u7684\u8996\u89ba\u8868\u793a\u3002\u6211\u5011\u8a2d\u8a08\u4e86\u4e00\u500b\u5275\u65b0\u7684\u9810\u8a13\u7df4\u65b9\u6cd5\uff0c\u8108\u885d\u6587\u672c\u5b78\u7fd2 (STL)\uff0c\u5b83\u4f7f\u7528\u6587\u672c\u7279\u5fb5\u4f86\u63d0\u9ad8\u96e2\u6563\u8a9e\u610f\u7684\u7de8\u78bc\u80fd\u529b\u3002\u5be6\u9a57\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684 GSHN \u5728\u591a\u500b VL \u4e0b\u6e38\u4efb\u52d9\u4e0a\u5c55\u73fe\u51fa\u6709\u5e0c\u671b\u7684\u7d50\u679c\u3002</paragraph>", "author": "Siyu Zhang et.al.", "authors": "Siyu Zhang, Heming Zheng, Yiming Wu, Yeming Chen", "id": "2501.19069v1", "paper_url": "http://arxiv.org/abs/2501.19069v1", "repo": "null"}}