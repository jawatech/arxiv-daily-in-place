{"2501.07016": {"publish_time": "2025-01-13", "title": "A Multi-Modal Deep Learning Framework for Pan-Cancer Prognosis", "paper_summary": "Prognostic task is of great importance as it closely related to the survival\nanalysis of patients, the optimization of treatment plans and the allocation of\nresources. The existing prognostic models have shown promising results on\nspecific datasets, but there are limitations in two aspects. On the one hand,\nthey merely explore certain types of modal data, such as patient histopathology\nWSI and gene expression analysis. On the other hand, they adopt the\nper-cancer-per-model paradigm, which means the trained models can only predict\nthe prognostic effect of a single type of cancer, resulting in weak\ngeneralization ability. In this paper, a deep-learning based model, named\nUMPSNet, is proposed. Specifically, to comprehensively understand the condition\nof patients, in addition to constructing encoders for histopathology images and\ngenomic expression profiles respectively, UMPSNet further integrates four types\nof important meta data (demographic information, cancer type information,\ntreatment protocols, and diagnosis results) into text templates, and then\nintroduces a text encoder to extract textual features. In addition, the optimal\ntransport OT-based attention mechanism is utilized to align and fuse features\nof different modalities. Furthermore, a guided soft mixture of experts (GMoE)\nmechanism is introduced to effectively address the issue of distribution\ndifferences among multiple cancer datasets. By incorporating the multi-modality\nof patient data and joint training, UMPSNet outperforms all SOTA approaches,\nand moreover, it demonstrates the effectiveness and generalization ability of\nthe proposed learning paradigm of a single model for multiple cancer types. The\ncode of UMPSNet is available at https://github.com/binging512/UMPSNet.", "paper_summary_zh": "\u9810\u5f8c\u4efb\u52d9\u975e\u5e38\u91cd\u8981\uff0c\u56e0\u70ba\u5b83\u8207\u75c5\u60a3\u7684\u5b58\u6d3b\u5206\u6790\u3001\u6cbb\u7642\u8a08\u756b\u7684\u6700\u4f73\u5316\u548c\u8cc7\u6e90\u5206\u914d\u5bc6\u5207\u76f8\u95dc\u3002\u73fe\u6709\u7684\u9810\u5f8c\u6a21\u578b\u5728\u7279\u5b9a\u8cc7\u6599\u96c6\u4e0a\u5df2\u5c55\u73fe\u51fa\u6709\u5e0c\u671b\u7684\u7d50\u679c\uff0c\u4f46\u6709\u5169\u500b\u65b9\u9762\u7684\u9650\u5236\u3002\u4e00\u65b9\u9762\uff0c\u5b83\u5011\u50c5\u63a2\u8a0e\u7279\u5b9a\u985e\u578b\u7684\u6a21\u5f0f\u8cc7\u6599\uff0c\u4f8b\u5982\u75c5\u60a3\u7d44\u7e54\u75c5\u7406\u5b78 WSI \u548c\u57fa\u56e0\u8868\u73fe\u5206\u6790\u3002\u53e6\u4e00\u65b9\u9762\uff0c\u5b83\u5011\u63a1\u7528\u300c\u6bcf\u7a2e\u764c\u75c7\u5c0d\u61c9\u4e00\u500b\u6a21\u578b\u300d\u7684\u6a21\u5f0f\uff0c\u9019\u8868\u793a\u8a13\u7df4\u51fa\u4f86\u7684\u6a21\u578b\u53ea\u80fd\u9810\u6e2c\u55ae\u4e00\u7a2e\u985e\u764c\u75c7\u7684\u9810\u5f8c\u6548\u61c9\uff0c\u5c0e\u81f4\u6982\u5316\u80fd\u529b\u4e0d\u8db3\u3002\u5728\u672c\u6587\u4e2d\uff0c\u63d0\u51fa\u4e86\u4e00\u500b\u540d\u70ba UMPSNet \u7684\u6df1\u5ea6\u5b78\u7fd2\u6a21\u578b\u3002\u5177\u9ad4\u4f86\u8aaa\uff0c\u70ba\u4e86\u5168\u9762\u4e86\u89e3\u75c5\u60a3\u7684\u72c0\u6cc1\uff0c\u9664\u4e86\u5206\u5225\u5efa\u69cb\u7d44\u7e54\u75c5\u7406\u5b78\u5f71\u50cf\u548c\u57fa\u56e0\u9ad4\u8868\u73fe\u7279\u5fb5\u7684\u7de8\u78bc\u5668\u4e4b\u5916\uff0cUMPSNet \u9084\u9032\u4e00\u6b65\u5c07\u56db\u7a2e\u985e\u578b\u7684\u91cd\u8981\u5143\u8cc7\u6599\uff08\u4eba\u53e3\u7d71\u8a08\u8cc7\u8a0a\u3001\u764c\u75c7\u985e\u578b\u8cc7\u8a0a\u3001\u6cbb\u7642\u65b9\u6848\u548c\u8a3a\u65b7\u7d50\u679c\uff09\u6574\u5408\u5230\u6587\u5b57\u7bc4\u672c\u4e2d\uff0c\u7136\u5f8c\u5f15\u5165\u6587\u5b57\u7de8\u78bc\u5668\u4f86\u8403\u53d6\u6587\u5b57\u7279\u5fb5\u3002\u6b64\u5916\uff0c\u5229\u7528\u6700\u4f73\u50b3\u8f38 OT \u70ba\u57fa\u790e\u7684\u6ce8\u610f\u529b\u6a5f\u5236\u4f86\u5c0d\u9f4a\u548c\u878d\u5408\u4e0d\u540c\u6a21\u5f0f\u7684\u7279\u5fb5\u3002\u6b64\u5916\uff0c\u5f15\u5165\u4e86\u5f15\u5c0e\u5f0f\u8edf\u6027\u5c08\u5bb6\u6df7\u5408 (GMoE) \u6a5f\u5236\uff0c\u4ee5\u6709\u6548\u89e3\u6c7a\u591a\u500b\u764c\u75c7\u8cc7\u6599\u96c6\u4e4b\u9593\u7684\u5206\u914d\u5dee\u7570\u554f\u984c\u3002\u900f\u904e\u6574\u5408\u75c5\u60a3\u8cc7\u6599\u7684\u591a\u6a21\u5f0f\u548c\u806f\u5408\u8a13\u7df4\uff0cUMPSNet \u512a\u65bc\u6240\u6709 SOTA \u65b9\u6cd5\uff0c\u800c\u4e14\u8b49\u660e\u4e86\u55ae\u4e00\u6a21\u578b\u5c0d\u591a\u7a2e\u764c\u75c7\u985e\u578b\u7684\u5b78\u7fd2\u7bc4\u4f8b\u7684\u6709\u6548\u6027\u548c\u6982\u5316\u80fd\u529b\u3002UMPSNet \u7684\u7a0b\u5f0f\u78bc\u53ef\u5728 https://github.com/binging512/UMPSNet \u53d6\u5f97\u3002", "author": "Binyu Zhang et.al.", "authors": "Binyu Zhang, Shichao Li, Junpeng Jian, Zhu Meng, Limei Guo, Zhicheng Zhao", "id": "2501.07016v1", "paper_url": "http://arxiv.org/abs/2501.07016v1", "repo": "https://github.com/binging512/umpsnet"}}