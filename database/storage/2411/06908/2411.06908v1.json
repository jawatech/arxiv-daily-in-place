{"2411.06908": {"publish_time": "2024-11-11", "title": "EVQAScore: Efficient Video Question Answering Data Evaluation", "paper_summary": "Video question-answering (QA) is a core task in video understanding.\nEvaluating the quality of video QA and video caption data quality for training\nvideo large language models (VideoLLMs) is an essential challenge. Although\nvarious methods have been proposed for assessing video caption quality, there\nremains a lack of dedicated evaluation methods for Video QA. To address this\ngap, we introduce EVQAScore, a reference-free method that leverages keyword\nextraction to assess both video caption and video QA data quality.\nAdditionally, we incorporate frame sampling and rescaling techniques to enhance\nthe efficiency and robustness of our evaluation, this enables our score to\nevaluate the quality of extremely long videos. Our approach achieves\nstate-of-the-art (SOTA) performance (32.8 for Kendall correlation and 42.3 for\nSpearman correlation, 4.7 and 5.9 higher than the previous method PAC-S++) on\nthe VATEX-EVAL benchmark for video caption evaluation. Furthermore, by using\nEVQAScore for data selection, we achieved SOTA results with only 12.5\\% of the\noriginal data volume, outperforming the previous SOTA method PAC-S and 100\\% of\ndata.", "paper_summary_zh": "\u5f71\u7247\u554f\u7b54 (QA) \u662f\u5f71\u7247\u7406\u89e3\u4e2d\u7684\u4e00\u9805\u6838\u5fc3\u4efb\u52d9\u3002\n\u8a55\u4f30\u5f71\u7247 QA \u548c\u5f71\u7247\u6a19\u984c\u8cc7\u6599\u54c1\u8cea\u4ee5\u8a13\u7df4\u5f71\u7247\u5927\u578b\u8a9e\u8a00\u6a21\u578b (VideoLLM) \u662f\u9805\u91cd\u8981\u7684\u6311\u6230\u3002\u5118\u7ba1\n\u5df2\u7d93\u63d0\u51fa\u5404\u7a2e\u65b9\u6cd5\u4f86\u8a55\u4f30\u5f71\u7247\u6a19\u984c\u54c1\u8cea\uff0c\u4f46\u4ecd\u7136\u7f3a\u4e4f\u91dd\u5c0d\u5f71\u7247 QA \u7684\u5c08\u7528\u8a55\u4f30\u65b9\u6cd5\u3002\u70ba\u4e86\u89e3\u6c7a\u9019\u500b\n\u554f\u984c\uff0c\u6211\u5011\u5f15\u5165\u4e86 EVQAScore\uff0c\u4e00\u7a2e\u7121\u53c3\u8003\u65b9\u6cd5\uff0c\u5b83\u5229\u7528\u95dc\u9375\u5b57\u8403\u53d6\u4f86\u8a55\u4f30\u5f71\u7247\u6a19\u984c\u548c\u5f71\u7247 QA \u8cc7\u6599\u54c1\u8cea\u3002\n\u6b64\u5916\uff0c\u6211\u5011\u7d50\u5408\u4e86\u5f71\u683c\u53d6\u6a23\u548c\u7e2e\u653e\u6280\u8853\u4f86\u63d0\u5347\u6211\u5011\u8a55\u4f30\u7684\u6548\u7387\u548c\u7a69\u5065\u6027\uff0c\u9019\u4f7f\u5f97\u6211\u5011\u7684\u8a55\u5206\u80fd\u5920\n\u8a55\u4f30\u6975\u9577\u5f71\u7247\u7684\u54c1\u8cea\u3002\u6211\u5011\u7684\u505a\u6cd5\u5728\u5f71\u7247\u6a19\u984c\u8a55\u4f30\u7684 VATEX-EVAL \u57fa\u6e96\u4e0a\u9054\u5230\u4e86\u6700\u5148\u9032 (SOTA) \u7684\u6548\u80fd\uff08Kendall \u76f8\u95dc\u6027\u70ba 32.8\uff0cSpearman \u76f8\u95dc\u6027\u70ba 42.3\uff0c\u6bd4\u524d\u4e00\u500b\u65b9\u6cd5 PAC-S++ \u9ad8\u51fa 4.7 \u548c 5.9\uff09\u3002\u6b64\u5916\uff0c\u900f\u904e\u4f7f\u7528 EVQAScore \u9032\u884c\u8cc7\u6599\u9078\u53d6\uff0c\u6211\u5011\u50c5\u4f7f\u7528\u539f\u8cc7\u6599\u91cf 12.5% \u5c31\u9054\u5230\u4e86 SOTA \u7d50\u679c\uff0c\u512a\u65bc\u524d\u4e00\u500b SOTA \u65b9\u6cd5 PAC-S \u548c 100% \u7684\u8cc7\u6599\u3002", "author": "Hao Liang et.al.", "authors": "Hao Liang, Zirong Chen, Wentao Zhang", "id": "2411.06908v1", "paper_url": "http://arxiv.org/abs/2411.06908v1", "repo": "null"}}