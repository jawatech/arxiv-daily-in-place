{"2410.01704": {"publish_time": "2024-10-02", "title": "An Exploration of Self-Supervised Mutual Information Alignment for Multi-Task Settings", "paper_summary": "There is a growing need for pluralistic alignment methods that can steer\nlanguage models towards individual attributes and preferences. One such method,\nSelf-Supervised Alignment with Mutual Information (SAMI), uses conditional\nmutual information to encourage the connection between behavioral preferences\nand model responses. We conduct two experiments exploring SAMI in multi-task\nsettings. First, we compare SAMI to Direct Preference Optimization (DPO) on a\nmulti-task benchmark (MT-Bench), using a stronger model to generate training\ndata for a weaker one across diverse categories (humanities, STEM, extraction,\ncoding, math, reasoning, and roleplay). Our results indicate that one iteration\nof SAMI has a 57% win rate against DPO, with significant variation in\nperformance between task categories. Second, we examine SAMI's impact on\nmathematical accuracy (GSM-8K) relative to supervised fine-tuning (SFT). While\nSAMI increases zero-shot performance by 1.1%, SFT is more effective with a 3.2%\nboost. However, SAMI shows interesting scaling trends. When given 10 attempts,\nSAMI improves accuracy by 3.9%, while SFT achieves a 10.1% increase. Combining\nSAMI with SFT yields an additional improvement of 1.3% in multi-attempt\nsettings, though single-attempt accuracy remains unchanged.", "paper_summary_zh": "<paragraph>\u65e5\u76ca\u589e\u9577\u7684\u9700\u6c42\uff0c\u9700\u8981\u591a\u5143\u5316\u5c0d\u9f4a\u65b9\u6cd5\uff0c\u9019\u4e9b\u65b9\u6cd5\u53ef\u4ee5\u5f15\u5c0e\u8a9e\u8a00\u6a21\u578b\u671d\u5411\u500b\u4eba\u5c6c\u6027\u548c\u504f\u597d\u3002\u5176\u4e2d\u4e00\u7a2e\u65b9\u6cd5\uff0c\u4f7f\u7528\u689d\u4ef6\u4e92\u60e0\u8cc7\u8a0a\u7684\u81ea\u76e3\u7763\u5c0d\u9f4a\uff08SAMI\uff09\uff0c\u4f7f\u7528\u689d\u4ef6\u4e92\u60e0\u8cc7\u8a0a\u4f86\u9f13\u52f5\u884c\u70ba\u504f\u597d\u548c\u6a21\u578b\u56de\u61c9\u4e4b\u9593\u7684\u9023\u63a5\u3002\u6211\u5011\u9032\u884c\u4e86\u5169\u9805\u5be6\u9a57\uff0c\u63a2\u7d22 SAMI \u5728\u591a\u4efb\u52d9\u8a2d\u5b9a\u4e2d\u7684\u61c9\u7528\u3002\u9996\u5148\uff0c\u6211\u5011\u5728\u591a\u4efb\u52d9\u57fa\u6e96\uff08MT-Bench\uff09\u4e0a\u5c07 SAMI \u8207\u76f4\u63a5\u504f\u597d\u6700\u4f73\u5316\uff08DPO\uff09\u9032\u884c\u6bd4\u8f03\uff0c\u4f7f\u7528\u66f4\u5f37\u5927\u7684\u6a21\u578b\u4f86\u70ba\u8f03\u5f31\u7684\u6a21\u578b\u751f\u6210\u8a13\u7df4\u8cc7\u6599\uff0c\u6db5\u84cb\u4e0d\u540c\u985e\u5225\uff08\u4eba\u6587\u3001STEM\u3001\u8403\u53d6\u3001\u7de8\u78bc\u3001\u6578\u5b78\u3001\u63a8\u7406\u548c\u89d2\u8272\u626e\u6f14\uff09\u3002\u6211\u5011\u7684\u7d50\u679c\u8868\u660e\uff0cSAMI \u7684\u4e00\u6b21\u8fed\u4ee3\u5c0d DPO \u7684\u52dd\u7387\u70ba 57%\uff0c\u4efb\u52d9\u985e\u5225\u4e4b\u9593\u7684\u6548\u80fd\u5dee\u7570\u986f\u8457\u3002\u5176\u6b21\uff0c\u6211\u5011\u6aa2\u8996 SAMI \u5c0d\u6578\u5b78\u6e96\u78ba\u5ea6\uff08GSM-8K\uff09\u7684\u5f71\u97ff\uff0c\u76f8\u5c0d\u65bc\u76e3\u7763\u5fae\u8abf\uff08SFT\uff09\u3002\u96d6\u7136 SAMI \u5c07\u96f6\u6b21\u5b78\u7fd2\u6548\u80fd\u63d0\u5347 1.1%\uff0c\u4f46 SFT \u4ee5 3.2% \u7684\u63d0\u5347\u66f4\u70ba\u6709\u6548\u3002\u7136\u800c\uff0cSAMI \u986f\u793a\u51fa\u6709\u8da3\u7684\u64f4\u5145\u8da8\u52e2\u3002\u7576\u7d66\u4e88 10 \u6b21\u5617\u8a66\u6642\uff0cSAMI \u5c07\u6e96\u78ba\u5ea6\u63d0\u5347 3.9%\uff0c\u800c SFT \u9054\u5230 10.1% \u7684\u63d0\u5347\u3002\u5c07 SAMI \u8207 SFT \u7d50\u5408\u4f7f\u7528\uff0c\u5728\u591a\u5617\u8a66\u8a2d\u5b9a\u4e2d\u984d\u5916\u63d0\u5347 1.3%\uff0c\u5118\u7ba1\u55ae\u6b21\u5617\u8a66\u7684\u6e96\u78ba\u5ea6\u4fdd\u6301\u4e0d\u8b8a\u3002</paragraph>", "author": "Soham Govande et.al.", "authors": "Soham Govande", "id": "2410.01704v1", "paper_url": "http://arxiv.org/abs/2410.01704v1", "repo": "null"}}