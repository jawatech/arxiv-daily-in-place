{"2407.12376": {"publish_time": "2024-07-17", "title": "Deep Learning-based Sentiment Analysis of Olympics Tweets", "paper_summary": "Sentiment analysis (SA), is an approach of natural language processing (NLP)\nfor determining a text's emotional tone by analyzing subjective information\nsuch as views, feelings, and attitudes toward specific topics, products,\nservices, events, or experiences. This study attempts to develop an advanced\ndeep learning (DL) model for SA to understand global audience emotions through\ntweets in the context of the Olympic Games. The findings represent global\nattitudes around the Olympics and contribute to advancing the SA models. We\nhave used NLP for tweet pre-processing and sophisticated DL models for arguing\nwith SA, this research enhances the reliability and accuracy of sentiment\nclassification. The study focuses on data selection, preprocessing,\nvisualization, feature extraction, and model building, featuring a baseline\nNa\\\"ive Bayes (NB) model and three advanced DL models: Convolutional Neural\nNetwork (CNN), Bidirectional Long Short-Term Memory (BiLSTM), and Bidirectional\nEncoder Representations from Transformers (BERT). The results of the\nexperiments show that the BERT model can efficiently classify sentiments\nrelated to the Olympics, achieving the highest accuracy of 99.23%.", "paper_summary_zh": "\u60c5\u7dd2\u5206\u6790 (SA) \u662f\u81ea\u7136\u8a9e\u8a00\u8655\u7406 (NLP) \u7684\u4e00\u7a2e\u65b9\u6cd5\uff0c\u900f\u904e\u5206\u6790\u89c0\u9ede\u3001\u611f\u53d7\u548c\u5c0d\u7279\u5b9a\u4e3b\u984c\u3001\u7522\u54c1\u3001\u670d\u52d9\u3001\u4e8b\u4ef6\u6216\u7d93\u9a57\u7684\u614b\u5ea6\u7b49\u4e3b\u89c0\u8cc7\u8a0a\uff0c\u4f86\u5224\u5b9a\u4e00\u6bb5\u6587\u5b57\u7684\u60c5\u7dd2\u57fa\u8abf\u3002\u672c\u7814\u7a76\u5617\u8a66\u958b\u767c\u4e00\u500b\u9032\u968e\u7684\u6df1\u5ea6\u5b78\u7fd2 (DL) \u6a21\u578b\u9032\u884c SA\uff0c\u4ee5\u900f\u904e\u5967\u904b\u6703\u7684\u63a8\u6587\u4f86\u4e86\u89e3\u5168\u7403\u89c0\u773e\u7684\u60c5\u7dd2\u3002\u7814\u7a76\u7d50\u679c\u4ee3\u8868\u4e86\u5168\u7403\u5c0d\u65bc\u5967\u904b\u6703\u7684\u614b\u5ea6\uff0c\u4e26\u6709\u52a9\u65bc\u63a8\u9032 SA \u6a21\u578b\u7684\u767c\u5c55\u3002\u6211\u5011\u4f7f\u7528 NLP \u5c0d\u63a8\u6587\u9032\u884c\u524d\u8655\u7406\uff0c\u4e26\u4f7f\u7528\u9032\u968e\u7684 DL \u6a21\u578b\u9032\u884c SA \u8ad6\u8b49\uff0c\u9019\u9805\u7814\u7a76\u63d0\u5347\u4e86\u60c5\u7dd2\u5206\u985e\u7684\u53ef\u9760\u6027\u548c\u6e96\u78ba\u6027\u3002\u672c\u7814\u7a76\u8457\u91cd\u65bc\u8cc7\u6599\u9078\u53d6\u3001\u524d\u8655\u7406\u3001\u8996\u89ba\u5316\u3001\u7279\u5fb5\u8403\u53d6\u548c\u6a21\u578b\u5efa\u69cb\uff0c\u63a1\u7528\u57fa\u6e96\u7684\u6734\u7d20\u8c9d\u6c0f (NB) \u6a21\u578b\u548c\u4e09\u500b\u9032\u968e\u7684 DL \u6a21\u578b\uff1a\u5377\u7a4d\u795e\u7d93\u7db2\u8def (CNN)\u3001\u96d9\u5411\u9577\u77ed\u671f\u8a18\u61b6 (BiLSTM) \u548c Transformer \u7684\u96d9\u5411\u7de8\u78bc\u5668\u8868\u5fb5 (BERT)\u3002\u5be6\u9a57\u7d50\u679c\u986f\u793a\uff0cBERT \u6a21\u578b\u80fd\u6709\u6548\u5730\u5206\u985e\u8207\u5967\u904b\u6703\u76f8\u95dc\u7684\u60c5\u7dd2\uff0c\u9054\u5230 99.23% \u7684\u6700\u9ad8\u6e96\u78ba\u5ea6\u3002", "author": "Indranil Bandyopadhyay et.al.", "authors": "Indranil Bandyopadhyay, Rahul Karmakar", "id": "2407.12376v1", "paper_url": "http://arxiv.org/abs/2407.12376v1", "repo": "null"}}