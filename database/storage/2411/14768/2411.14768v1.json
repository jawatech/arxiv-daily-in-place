{"2411.14768": {"publish_time": "2024-11-22", "title": "Grid and Road Expressions Are Complementary for Trajectory Representation Learning", "paper_summary": "Trajectory representation learning (TRL) maps trajectories to vectors that\ncan be used for many downstream tasks. Existing TRL methods use either grid\ntrajectories, capturing movement in free space, or road trajectories, capturing\nmovement in a road network, as input. We observe that the two types of\ntrajectories are complementary, providing either region and location\ninformation or providing road structure and movement regularity. Therefore, we\npropose a novel multimodal TRL method, dubbed GREEN, to jointly utilize Grid\nand Road trajectory Expressions for Effective representatioN learning. In\nparticular, we transform raw GPS trajectories into both grid and road\ntrajectories and tailor two encoders to capture their respective information.\nTo align the two encoders such that they complement each other, we adopt a\ncontrastive loss to encourage them to produce similar embeddings for the same\nraw trajectory and design a mask language model (MLM) loss to use grid\ntrajectories to help reconstruct masked road trajectories. To learn the final\ntrajectory representation, a dual-modal interactor is used to fuse the outputs\nof the two encoders via cross-attention. We compare GREEN with 7\nstate-of-the-art TRL methods for 3 downstream tasks, finding that GREEN\nconsistently outperforms all baselines and improves the accuracy of the\nbest-performing baseline by an average of 15.99\\%.", "paper_summary_zh": "\u8ecc\u8de1\u8868\u5fb5\u5b78\u7fd2 (TRL) \u5c07\u8ecc\u8de1\u5c0d\u61c9\u5230\u5411\u91cf\uff0c\u53ef\u4f9b\u8a31\u591a\u4e0b\u6e38\u4efb\u52d9\u4f7f\u7528\u3002\u73fe\u6709\u7684 TRL \u65b9\u6cd5\u4f7f\u7528\u7db2\u683c\u8ecc\u8de1\uff08\u6355\u6349\u81ea\u7531\u7a7a\u9593\u4e2d\u7684\u79fb\u52d5\uff09\u6216\u9053\u8def\u8ecc\u8de1\uff08\u6355\u6349\u9053\u8def\u7db2\u8def\u4e2d\u7684\u79fb\u52d5\uff09\u4f5c\u70ba\u8f38\u5165\u3002\u6211\u5011\u89c0\u5bdf\u5230\u9019\u5169\u7a2e\u8ecc\u8de1\u985e\u578b\u4e92\u88dc\uff0c\u63d0\u4f9b\u5340\u57df\u548c\u4f4d\u7f6e\u8cc7\u8a0a\u6216\u63d0\u4f9b\u9053\u8def\u7d50\u69cb\u548c\u79fb\u52d5\u898f\u5f8b\u3002\u56e0\u6b64\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u4e00\u7a2e\u65b0\u7a4e\u7684\u591a\u6a21\u614b TRL \u65b9\u6cd5\uff0c\u7a31\u70ba GREEN\uff0c\u4ee5\u806f\u5408\u5229\u7528\u7db2\u683c\u548c\u9053\u8def\u8ecc\u8de1\u8868\u9054\u5f0f\u9032\u884c\u6709\u6548\u8868\u5fb5\u5b78\u7fd2\u3002\u5177\u9ad4\u4f86\u8aaa\uff0c\u6211\u5011\u5c07\u539f\u59cb GPS \u8ecc\u8de1\u8f49\u63db\u70ba\u7db2\u683c\u548c\u9053\u8def\u8ecc\u8de1\uff0c\u4e26\u8abf\u6574\u5169\u500b\u7de8\u78bc\u5668\u4ee5\u6355\u6349\u5b83\u5011\u5404\u81ea\u7684\u8cc7\u8a0a\u3002\u70ba\u4e86\u5c0d\u9f4a\u5169\u500b\u7de8\u78bc\u5668\u4ee5\u4f7f\u5176\u4e92\u76f8\u88dc\u5145\uff0c\u6211\u5011\u63a1\u7528\u5c0d\u6bd4\u640d\u5931\u4f86\u9f13\u52f5\u5b83\u5011\u70ba\u76f8\u540c\u7684\u539f\u59cb\u8ecc\u8de1\u7522\u751f\u985e\u4f3c\u7684\u5d4c\u5165\uff0c\u4e26\u8a2d\u8a08\u4e00\u500b\u906e\u7f69\u8a9e\u8a00\u6a21\u578b (MLM) \u640d\u5931\u4f86\u4f7f\u7528\u7db2\u683c\u8ecc\u8de1\u5e6b\u52a9\u91cd\u5efa\u906e\u7f69\u9053\u8def\u8ecc\u8de1\u3002\u70ba\u4e86\u5b78\u7fd2\u6700\u7d42\u8ecc\u8de1\u8868\u5fb5\uff0c\u4f7f\u7528\u96d9\u6a21\u614b\u4ea4\u4e92\u5668\u900f\u904e\u4ea4\u53c9\u6ce8\u610f\u878d\u5408\u5169\u500b\u7de8\u78bc\u5668\u7684\u8f38\u51fa\u3002\u6211\u5011\u5c07 GREEN \u8207 7 \u7a2e\u6700\u5148\u9032\u7684 TRL \u65b9\u6cd5\u9032\u884c\u6bd4\u8f03\uff0c\u7528\u65bc 3 \u500b\u4e0b\u6e38\u4efb\u52d9\uff0c\u767c\u73fe GREEN \u4e00\u81f4\u5730\u512a\u65bc\u6240\u6709\u57fa\u6e96\uff0c\u4e26\u5c07\u6548\u80fd\u6700\u4f73\u7684\u57fa\u6e96\u7684\u6e96\u78ba\u5ea6\u5e73\u5747\u63d0\u9ad8\u4e86 15.99%\u3002", "author": "Silin Zhou et.al.", "authors": "Silin Zhou, Shuo Shang, Lisi Chen, Peng Han, Christian S. Jensen", "id": "2411.14768v1", "paper_url": "http://arxiv.org/abs/2411.14768v1", "repo": "null"}}