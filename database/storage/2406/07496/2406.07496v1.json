{"2406.07496": {"publish_time": "2024-06-11", "title": "TextGrad: Automatic \"Differentiation\" via Text", "paper_summary": "AI is undergoing a paradigm shift, with breakthroughs achieved by systems\norchestrating multiple large language models (LLMs) and other complex\ncomponents. As a result, developing principled and automated optimization\nmethods for compound AI systems is one of the most important new challenges.\nNeural networks faced a similar challenge in its early days until\nbackpropagation and automatic differentiation transformed the field by making\noptimization turn-key. Inspired by this, we introduce TextGrad, a powerful\nframework performing automatic ``differentiation'' via text. TextGrad\nbackpropagates textual feedback provided by LLMs to improve individual\ncomponents of a compound AI system. In our framework, LLMs provide rich,\ngeneral, natural language suggestions to optimize variables in computation\ngraphs, ranging from code snippets to molecular structures. TextGrad follows\nPyTorch's syntax and abstraction and is flexible and easy-to-use. It works\nout-of-the-box for a variety of tasks, where the users only provide the\nobjective function without tuning components or prompts of the framework. We\nshowcase TextGrad's effectiveness and generality across a diverse range of\napplications, from question answering and molecule optimization to radiotherapy\ntreatment planning. Without modifying the framework, TextGrad improves the\nzero-shot accuracy of GPT-4o in Google-Proof Question Answering from $51\\%$ to\n$55\\%$, yields $20\\%$ relative performance gain in optimizing LeetCode-Hard\ncoding problem solutions, improves prompts for reasoning, designs new druglike\nsmall molecules with desirable in silico binding, and designs radiation\noncology treatment plans with high specificity. TextGrad lays a foundation to\naccelerate the development of the next-generation of AI systems.", "paper_summary_zh": "<paragraph>AI \u6b63\u7d93\u6b77\u4e00\u5834\u5178\u7bc4\u8f49\u79fb\uff0c\u7a81\u7834\u4f86\u81ea\u65bc\u7cfb\u7d71\u7de8\u6392\u591a\u500b\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u548c\u5176\u4ed6\u8907\u96dc\u7d44\u6210\u90e8\u5206\u3002\u56e0\u6b64\uff0c\u70ba\u8907\u5408\u5f0f AI \u7cfb\u7d71\u958b\u767c\u539f\u5247\u5316\u4e14\u81ea\u52d5\u5316\u7684\u6700\u4f73\u5316\u65b9\u6cd5\uff0c\u662f\u5176\u4e2d\u4e00\u9805\u6700\u91cd\u8981\u7684\u65b0\u6311\u6230\u3002\u795e\u7d93\u7db2\u8def\u5728\u65e9\u671f\u9762\u81e8\u985e\u4f3c\u7684\u6311\u6230\uff0c\u76f4\u5230\u53cd\u5411\u50b3\u64ad\u548c\u81ea\u52d5\u5fae\u5206\u900f\u904e\u8b93\u6700\u4f73\u5316\u8b8a\u5f97\u5bb9\u6613\uff0c\u9032\u800c\u8f49\u8b8a\u4e86\u9019\u500b\u9818\u57df\u3002\u53d7\u5230\u6b64\u555f\u767c\uff0c\u6211\u5011\u5f15\u5165\u4e86 TextGrad\uff0c\u4e00\u500b\u5f37\u5927\u7684\u6846\u67b6\uff0c\u900f\u904e\u6587\u5b57\u57f7\u884c\u81ea\u52d5\u300c\u5fae\u5206\u300d\u3002TextGrad \u53cd\u5411\u50b3\u64ad LLM \u63d0\u4f9b\u7684\u6587\u5b57\u56de\u994b\uff0c\u4ee5\u6539\u5584\u8907\u5408\u5f0f AI \u7cfb\u7d71\u7684\u500b\u5225\u7d44\u6210\u90e8\u5206\u3002\u5728\u6211\u5011\u7684\u6846\u67b6\u4e2d\uff0cLLM \u63d0\u4f9b\u8c50\u5bcc\u3001\u901a\u7528\u3001\u81ea\u7136\u7684\u8a9e\u8a00\u5efa\u8b70\uff0c\u4f86\u6700\u4f73\u5316\u904b\u7b97\u5716\u4e2d\u7684\u8b8a\u6578\uff0c\u7bc4\u570d\u5f9e\u7a0b\u5f0f\u78bc\u7247\u6bb5\u5230\u5206\u5b50\u7d50\u69cb\u3002TextGrad \u9075\u5faa PyTorch \u7684\u8a9e\u6cd5\u548c\u62bd\u8c61\uff0c\u4e14\u9748\u6d3b\u4e14\u6613\u65bc\u4f7f\u7528\u3002\u5b83\u9069\u7528\u65bc\u5404\u7a2e\u4efb\u52d9\uff0c\u4f7f\u7528\u8005\u53ea\u9700\u63d0\u4f9b\u76ee\u6a19\u51fd\u6578\uff0c\u800c\u7121\u9700\u8abf\u6574\u6846\u67b6\u7684\u7d44\u6210\u90e8\u5206\u6216\u63d0\u793a\u3002\u6211\u5011\u5c55\u793a\u4e86 TextGrad \u5728\u5404\u7a2e\u61c9\u7528\u4e2d\u7684\u6709\u6548\u6027\u548c\u666e\u904d\u6027\uff0c\u5f9e\u554f\u7b54\u548c\u5206\u5b50\u6700\u4f73\u5316\u5230\u653e\u5c04\u6cbb\u7642\u8a08\u756b\u3002\u5728\u4e0d\u4fee\u6539\u6846\u67b6\u7684\u60c5\u6cc1\u4e0b\uff0cTextGrad \u5c07 Google-Proof \u554f\u7b54\u4e2d GPT-4o \u7684\u96f6\u6b21\u5b78\u7fd2\u6e96\u78ba\u5ea6\u5f9e 51% \u63d0\u5347\u81f3 55%\uff0c\u5728\u6700\u4f73\u5316 LeetCode-Hard \u7de8\u78bc\u554f\u984c\u89e3\u7b54\u4e2d\u7522\u751f 20% \u7684\u76f8\u5c0d\u6548\u80fd\u63d0\u5347\uff0c\u6539\u5584\u63a8\u7406\u63d0\u793a\uff0c\u8a2d\u8a08\u5177\u6709\u7406\u60f3\u7684\u77fd\u57fa\u7d50\u5408\u7684\u65b0\u85e5\u7269\u5c0f\u5206\u5b50\uff0c\u4e26\u8a2d\u8a08\u51fa\u5177\u6709\u9ad8\u7279\u7570\u6027\u7684\u653e\u5c04\u816b\u7624\u6cbb\u7642\u8a08\u756b\u3002TextGrad \u70ba\u52a0\u901f\u958b\u767c\u4e0b\u4e00\u4ee3 AI \u7cfb\u7d71\u5960\u5b9a\u4e86\u57fa\u790e\u3002</paragraph>", "author": "Mert Yuksekgonul et.al.", "authors": "Mert Yuksekgonul, Federico Bianchi, Joseph Boen, Sheng Liu, Zhi Huang, Carlos Guestrin, James Zou", "id": "2406.07496v1", "paper_url": "http://arxiv.org/abs/2406.07496v1", "repo": "https://github.com/zou-group/textgrad"}}