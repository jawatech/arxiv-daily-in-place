# arxiv-daily
 Automated deployment @ 2024-09-27 09:05:13 Asia/Taipei
> Welcome to contribute! Add your topics and keywords in [`topic.yml`](https://github.com/jawatech/arxiv-daily-in-place/blob/main/database/topic.yml).
> You can also view historical data through the [storage](https://github.com/jawatech/arxiv-daily-in-place/blob/main/database/storage).

## AI

### LLM
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-09-25**|**Molmo and PixMo: Open Weights and Open Data for State-of-the-Art Multimodal Models**|Matt Deitke et.al.|[2409.17146v1](http://arxiv.org/abs/2409.17146v1)|null|
|**2024-09-25**|**Differential Privacy Regularization: Protecting Training Data Through Loss Function Regularization**|Francisco Aguilera-Martínez et.al.|[2409.17144v1](http://arxiv.org/abs/2409.17144v1)|null|
|**2024-09-25**|**Attention Prompting on Image for Large Vision-Language Models**|Runpeng Yu et.al.|[2409.17143v1](http://arxiv.org/abs/2409.17143v1)|[link](https://github.com/yu-rp/apiprompting)|
|**2024-09-25**|**FineZip : Pushing the Limits of Large Language Models for Practical Lossless Text Compression**|Fazal Mittu et.al.|[2409.17141v1](http://arxiv.org/abs/2409.17141v1)|[link](https://github.com/fazalmittu/finezip)|
|**2024-09-25**|**Turn Every Application into an Agent: Towards Efficient Human-Agent-Computer Interaction with API-First LLM-Based Agents**|Junting Lu et.al.|[2409.17140v1](http://arxiv.org/abs/2409.17140v1)|null|
|**2024-09-25**|**Assessing the Level of Toxicity Against Distinct Groups in Bangla Social Media Comments: A Comprehensive Investigation**|Mukaffi Bin Moin et.al.|[2409.17130v1](http://arxiv.org/abs/2409.17130v1)|null|
|**2024-09-25**|**Blox-Net: Generative Design-for-Robot-Assembly Using VLM Supervision, Physics Simulation, and a Robot with Reset**|Andrew Goldberg et.al.|[2409.17126v1](http://arxiv.org/abs/2409.17126v1)|null|
|**2024-09-25**|**On-orbit Servicing for Spacecraft Collision Avoidance With Autonomous Decision Making**|Susmitha Patnala et.al.|[2409.17125v1](http://arxiv.org/abs/2409.17125v1)|null|
|**2024-09-25**|**Deep Learning and Machine Learning, Advancing Big Data Analytics and Management: Handy Appetizer**|Benji Peng et.al.|[2409.17120v1](http://arxiv.org/abs/2409.17120v1)|null|
|**2024-09-25**|**Programming Every Example: Lifting Pre-training Data Quality like Experts at Scale**|Fan Zhou et.al.|[2409.17115v1](http://arxiv.org/abs/2409.17115v1)|[link](https://github.com/gair-nlp/prox)|
|**2024-09-25**|**Unveiling Ontological Commitment in Multi-Modal Foundation Models**|Mert Keser et.al.|[2409.17109v1](http://arxiv.org/abs/2409.17109v1)|null|
|**2024-09-25**|**Accumulator-Aware Post-Training Quantization**|Ian Colbert et.al.|[2409.17092v1](http://arxiv.org/abs/2409.17092v1)|null|
|**2024-09-25**|**Ctrl-GenAug: Controllable Generative Augmentation for Medical Sequence Classification**|Xinrui Zhou et.al.|[2409.17091v1](http://arxiv.org/abs/2409.17091v1)|null|
|**2024-09-25**|**Can Vision Language Models Learn from Visual Demonstrations of Ambiguous Spatial Reasoning?**|Bowen Zhao et.al.|[2409.17080v1](http://arxiv.org/abs/2409.17080v1)|null|
|**2024-09-25**|**Enhancing Post-Hoc Attributions in Long Document Comprehension via Coarse Grained Answer Decomposition**|Pritika Ramu et.al.|[2409.17073v1](http://arxiv.org/abs/2409.17073v1)|null|
|**2024-09-25**|**The Effect of Perceptual Metrics on Music Representation Learning for Genre Classification**|Tashi Namgyal et.al.|[2409.17069v1](http://arxiv.org/abs/2409.17069v1)|null|
|**2024-09-25**|**VPTQ: Extreme Low-bit Vector Post-Training Quantization for Large Language Models**|Yifei Liu et.al.|[2409.17066v1](http://arxiv.org/abs/2409.17066v1)|[link](https://github.com/microsoft/vptq)|
|**2024-09-25**|**Benchmarking Domain Generalization Algorithms in Computational Pathology**|Neda Zamanitajeddin et.al.|[2409.17063v1](http://arxiv.org/abs/2409.17063v1)|null|
|**2024-09-25**|**DRIM: Learning Disentangled Representations from Incomplete Multimodal Healthcare Data**|Lucas Robinet et.al.|[2409.17055v1](http://arxiv.org/abs/2409.17055v1)|[link](https://github.com/lucas-rbnt/drim)|
|**2024-09-25**|**Using LLM for Real-Time Transcription and Summarization of Doctor-Patient Interactions into ePuskesmas in Indonesia**|Azmul Asmar Irfan et.al.|[2409.17054v1](http://arxiv.org/abs/2409.17054v1)|null|
|**2024-09-25**|**ControlCity: A Multimodal Diffusion Model Based Approach for Accurate Geospatial Data Generation and Urban Morphology Analysis**|Fangshuo Zhou et.al.|[2409.17049v1](http://arxiv.org/abs/2409.17049v1)|[link](https://github.com/fangshuoz/controlcity)|
|**2024-09-25**|**GeoBiked: A Dataset with Geometric Features and Automated Labeling Techniques to Enable Deep Generative Models in Engineering Design**|Phillip Mueller et.al.|[2409.17045v1](http://arxiv.org/abs/2409.17045v1)|null|
|**2024-09-25**|**How to Connect Speech Foundation Models and Large Language Models? What Matters and What Does Not**|Francesco Verdini et.al.|[2409.17044v1](http://arxiv.org/abs/2409.17044v1)|null|
|**2024-09-25**|**Counterfactual Token Generation in Large Language Models**|Ivi Chatzi et.al.|[2409.17027v1](http://arxiv.org/abs/2409.17027v1)|null|
|**2024-09-25**|**AI-Driven Risk-Aware Scheduling for Active Debris Removal Missions**|Antoine Poupon et.al.|[2409.17012v1](http://arxiv.org/abs/2409.17012v1)|null|
|**2024-09-25**|**LLM-CARD: Towards a Description and Landscape of Large Language Models**|Shengwei Tian et.al.|[2409.17011v1](http://arxiv.org/abs/2409.17011v1)|null|
|**2024-09-25**|**Models Can and Should Embrace the Communicative Nature of Human-Generated Math**|Sasha Boguraev et.al.|[2409.17005v1](http://arxiv.org/abs/2409.17005v1)|null|
|**2024-09-25**|**INT-FlashAttention: Enabling Flash Attention for INT8 Quantization**|Shimao Chen et.al.|[2409.16997v2](http://arxiv.org/abs/2409.16997v2)|[link](https://github.com/int-flashattention2024/int-flashattention)|
|**2024-09-25**|**Harnessing Diversity for Important Data Selection in Pretraining Large Language Models**|Chi Zhang et.al.|[2409.16986v1](http://arxiv.org/abs/2409.16986v1)|null|
|**2024-09-25**|**AXCEL: Automated eXplainable Consistency Evaluation using LLMs**|P Aditya Sreekar et.al.|[2409.16984v1](http://arxiv.org/abs/2409.16984v1)|null|
|**2024-09-25**|**Decoding Large-Language Models: A Systematic Overview of Socio-Technical Impacts, Constraints, and Emerging Questions**|Zeyneb N. Kaya et.al.|[2409.16974v1](http://arxiv.org/abs/2409.16974v1)|null|
|**2024-09-25**|**Adaptive Self-Supervised Learning Strategies for Dynamic On-Device LLM Personalization**|Rafael Mendoza et.al.|[2409.16973v1](http://arxiv.org/abs/2409.16973v1)|null|
|**2024-09-25**|**Weighted Cross-entropy for Low-Resource Languages in Multilingual Speech Recognition**|Andrés Piñeiro-Martín et.al.|[2409.16954v1](http://arxiv.org/abs/2409.16954v1)|null|
|**2024-09-25**|**Dynamic Obstacle Avoidance through Uncertainty-Based Adaptive Planning with Diffusion**|Vineet Punyamoorty et.al.|[2409.16950v1](http://arxiv.org/abs/2409.16950v1)|null|
|**2024-09-25**|**Go-SLAM: Grounded Object Segmentation and Localization with Gaussian Splatting SLAM**|Phu Pham et.al.|[2409.16944v1](http://arxiv.org/abs/2409.16944v1)|null|
|**2024-09-25**|**Generative Object Insertion in Gaussian Splatting with a Multi-View Diffusion Model**|Hongliang Zhong et.al.|[2409.16938v1](http://arxiv.org/abs/2409.16938v1)|[link](https://github.com/jiutongbro/multiview_inpaint)|
|**2024-09-25**|**Semi-Supervised Cognitive State Classification from Speech with Multi-View Pseudo-Labeling**|Yuanchao Li et.al.|[2409.16937v1](http://arxiv.org/abs/2409.16937v1)|[link](https://github.com/yc-li20/semi-supervised-training)|
|**2024-09-25**|**Investigating OCR-Sensitive Neurons to Improve Entity Recognition in Historical Documents**|Emanuela Boros et.al.|[2409.16934v2](http://arxiv.org/abs/2409.16934v2)|null|
|**2024-09-25**|**Quantum-Classical Sentiment Analysis**|Mario Bifulco et.al.|[2409.16928v1](http://arxiv.org/abs/2409.16928v1)|null|
|**2024-09-25**|**Cross-lingual Speech Emotion Recognition: Humans vs. Self-Supervised Models**|Zhichen Han et.al.|[2409.16920v1](http://arxiv.org/abs/2409.16920v1)|[link](https://github.com/zhan7721/crosslingual_ser)|
|**2024-09-25**|**Zero-Shot Detection of LLM-Generated Text using Token Cohesiveness**|Shixuan Ma et.al.|[2409.16914v1](http://arxiv.org/abs/2409.16914v1)|[link](https://github.com/shixuan-ma/tocsin)|
|**2024-09-25**|**Tell Me What You Don't Know: Enhancing Refusal Capabilities of Role-Playing Agents via Representation Space Analysis and Editing**|Wenhao Liu et.al.|[2409.16913v1](http://arxiv.org/abs/2409.16913v1)|null|
|**2024-09-25**|**Pruning Multilingual Large Language Models for Multilingual Inference**|Hwichan Kim et.al.|[2409.16911v1](http://arxiv.org/abs/2409.16911v1)|null|
|**2024-09-25**|**Enhancing Temporal Sensitivity and Reasoning for Time-Sensitive Question Answering**|Wanqi Yang et.al.|[2409.16909v1](http://arxiv.org/abs/2409.16909v1)|null|
|**2024-09-25**|**Discriminative Anchor Learning for Efficient Multi-view Clustering**|Yalan Qin et.al.|[2409.16904v1](http://arxiv.org/abs/2409.16904v1)|null|
|**2024-09-25**|**Towards Underwater Camouflaged Object Tracking: An Experimental Evaluation of SAM and SAM 2**|Chunhui Zhang et.al.|[2409.16902v1](http://arxiv.org/abs/2409.16902v1)|[link](https://github.com/983632847/awesome-multimodal-object-tracking)|
|**2024-09-25**|**A Roadmap for Embodied and Social Grounding in LLMs**|Sara Incao et.al.|[2409.16900v1](http://arxiv.org/abs/2409.16900v1)|null|
|**2024-09-25**|**AI-driven View Guidance System in Intra-cardiac Echocardiography Imaging**|Jaeyoung Huh et.al.|[2409.16898v1](http://arxiv.org/abs/2409.16898v1)|null|
|**2024-09-25**|**Shifting from endangerment to rebirth in the Artificial Intelligence Age: An Ensemble Machine Learning Approach for Hawrami Text Classification**|Aram Khaksar et.al.|[2409.16884v1](http://arxiv.org/abs/2409.16884v1)|null|
|**2024-09-25**|**Revisiting Space Mission Planning: A Reinforcement Learning-Guided Approach for Multi-Debris Rendezvous**|Agni Bandyopadhyay et.al.|[2409.16882v1](http://arxiv.org/abs/2409.16882v1)|null|
|**2024-09-25**|**Automating Traffic Model Enhancement with AI Research Agent**|Xusen Guo et.al.|[2409.16876v1](http://arxiv.org/abs/2409.16876v1)|null|
|**2024-09-25**|**Ethical and Scalable Automation: A Governance and Compliance Framework for Business Applications**|Haocheng Lin et.al.|[2409.16872v1](http://arxiv.org/abs/2409.16872v1)|null|
|**2024-09-25**|**Multi-objective Evolution of Heuristic Using Large Language Model**|Shunyu Yao et.al.|[2409.16867v1](http://arxiv.org/abs/2409.16867v1)|null|
|**2024-09-25**|**The Role of Language Models in Modern Healthcare: A Comprehensive Review**|Amna Khalid et.al.|[2409.16860v1](http://arxiv.org/abs/2409.16860v1)|null|
|**2024-09-25**|**Dispute resolution in legal mediation with quantitative argumentation**|Xiao Chi et.al.|[2409.16854v1](http://arxiv.org/abs/2409.16854v1)|null|
|**2024-09-25**|**Exposing Assumptions in AI Benchmarks through Cognitive Modelling**|Jonathan H. Rystrøm et.al.|[2409.16849v1](http://arxiv.org/abs/2409.16849v1)|null|
|**2024-09-25**|**Uncertainty Representations in State-Space Layers for Deep Reinforcement Learning under Partial Observability**|Carlos E. Luis et.al.|[2409.16824v1](http://arxiv.org/abs/2409.16824v1)|null|
|**2024-09-25**|**XAI-guided Insulator Anomaly Detection for Imbalanced Datasets**|Maximilian Andreas Hoefler et.al.|[2409.16821v1](http://arxiv.org/abs/2409.16821v1)|null|
|**2024-09-25**|**CodeInsight: A Curated Dataset of Practical Coding Solutions from Stack Overflow**|Nathanaël Beau et.al.|[2409.16819v1](http://arxiv.org/abs/2409.16819v1)|[link](https://github.com/nathanaelbeau/codeinsight)|
|**2024-09-25**|**PeerArg: Argumentative Peer Review with LLMs**|Purin Sukpanichnant et.al.|[2409.16813v1](http://arxiv.org/abs/2409.16813v1)|null|
|**2024-09-25**|**A Few Hypocrites: Few-Shot Learning and Subtype Definitions for Detecting Hypocrisy Accusations in Online Climate Change Debates**|Paulina Garcia Corral et.al.|[2409.16807v1](http://arxiv.org/abs/2409.16807v1)|null|
|**2024-09-25**|**Large Language Model Predicts Above Normal All India Summer Monsoon Rainfall in 2024**|Ujjawal Sharma et.al.|[2409.16799v1](http://arxiv.org/abs/2409.16799v1)|null|
|**2024-09-25**|**Scalable Ensemble Diversification for OOD Generalization and Detection**|Alexander Rubinstein et.al.|[2409.16797v1](http://arxiv.org/abs/2409.16797v1)|null|
|**2024-09-25**|**Mitigating the Bias of Large Language Model Evaluation**|Hongli Zhou et.al.|[2409.16788v1](http://arxiv.org/abs/2409.16788v1)|null|
|**2024-09-25**|**Enhancing Feature Selection and Interpretability in AI Regression Tasks Through Feature Attribution**|Alexander Hinterleitner et.al.|[2409.16787v1](http://arxiv.org/abs/2409.16787v1)|null|
|**2024-09-25**|**Holistic Automated Red Teaming for Large Language Models through Top-Down Test Case Generation and Multi-turn Interaction**|Jinchuan Zhang et.al.|[2409.16783v1](http://arxiv.org/abs/2409.16783v1)|null|
|**2024-09-25**|**LLaMa-SciQ: An Educational Chatbot for Answering Science MCQ**|Marc-Antoine Allard et.al.|[2409.16779v1](http://arxiv.org/abs/2409.16779v1)|null|
|**2024-09-25**|**Offline and Distributional Reinforcement Learning for Radio Resource Management**|Eslam Eldeeb et.al.|[2409.16764v1](http://arxiv.org/abs/2409.16764v1)|null|
|**2024-09-25**|**E-SQL: Direct Schema Linking via Question Enrichment in Text-to-SQL**|Hasan Alp Caferoğlu et.al.|[2409.16751v1](http://arxiv.org/abs/2409.16751v1)|[link](https://github.com/HasanAlpCaferoglu/E-SQL)|
|**2024-09-25**|**GB-RVFL: Fusion of Randomized Neural Network and Granular Ball Computing**|M. Sajid et.al.|[2409.16735v1](http://arxiv.org/abs/2409.16735v1)|null|
|**2024-09-25**|**RoleBreak: Character Hallucination as a Jailbreak Attack in Role-Playing Systems**|Yihong Tang et.al.|[2409.16727v1](http://arxiv.org/abs/2409.16727v1)|null|
|**2024-09-25**|**PMSS: Pretrained Matrices Skeleton Selection for LLM Fine-tuning**|Qibin Wang et.al.|[2409.16722v1](http://arxiv.org/abs/2409.16722v1)|null|
|**2024-09-25**|**A Multi-Dataset Classification-Based Deep Learning Framework for Electronic Health Records and Predictive Analysis in Healthcare**|Syed Mohd Faisal Malik et.al.|[2409.16721v1](http://arxiv.org/abs/2409.16721v1)|null|
|**2024-09-25**|**Vision-Language Model Fine-Tuning via Simple Parameter-Efficient Modification**|Ming Li et.al.|[2409.16718v1](http://arxiv.org/abs/2409.16718v1)|[link](https://github.com/minglllli/clipfit)|
|**2024-09-25**|**Beyond Turing Test: Can GPT-4 Sway Experts' Decisions?**|Takehiro Takayanagi et.al.|[2409.16710v1](http://arxiv.org/abs/2409.16710v1)|null|
|**2024-09-25**|**Probing Omissions and Distortions in Transformer-based RDF-to-Text Models**|Juliette Faille et.al.|[2409.16707v1](http://arxiv.org/abs/2409.16707v1)|null|
|**2024-09-25**|**Pix2Next: Leveraging Vision Foundation Models for RGB to NIR Image Translation**|Youngwan Jin et.al.|[2409.16706v1](http://arxiv.org/abs/2409.16706v1)|null|
|**2024-09-25**|**A Survey of Low-bit Large Language Models: Basics, Systems, and Algorithms**|Ruihao Gong et.al.|[2409.16694v1](http://arxiv.org/abs/2409.16694v1)|null|
|**2024-09-25**|**CaBRNet, an open-source library for developing and evaluating Case-Based Reasoning Models**|Romain Xu-Darme et.al.|[2409.16693v1](http://arxiv.org/abs/2409.16693v1)|[link](https://github.com/aiser-team/cabrnet)|
|**2024-09-25**|**Layout-Corrector: Alleviating Layout Sticking Phenomenon in Discrete Diffusion Model**|Shoma Iwai et.al.|[2409.16689v1](http://arxiv.org/abs/2409.16689v1)|null|
|**2024-09-25**|**MSI-Agent: Incorporating Multi-Scale Insight into Embodied Agents for Superior Planning and Decision-Making**|Dayuan Fu et.al.|[2409.16686v1](http://arxiv.org/abs/2409.16686v1)|null|
|**2024-09-25**|**Erase then Rectify: A Training-Free Parameter Editing Approach for Cost-Effective Graph Unlearning**|Zhe-Rui Yang et.al.|[2409.16684v1](http://arxiv.org/abs/2409.16684v1)|null|
|**2024-09-25**|**SynTQA: Synergistic Table-based Question Answering via Mixture of Text-to-SQL and E2E TQA**|Siyue Zhang et.al.|[2409.16682v1](http://arxiv.org/abs/2409.16682v1)|null|
|**2024-09-25**|**Emotional Dimension Control in Language Model-Based Text-to-Speech: Spanning a Broad Spectrum of Human Emotions**|Kun Zhou et.al.|[2409.16681v1](http://arxiv.org/abs/2409.16681v1)|null|
|**2024-09-25**|**TSBP: Improving Object Detection in Histology Images via Test-time Self-guided Bounding-box Propagation**|Tingting Yang et.al.|[2409.16678v1](http://arxiv.org/abs/2409.16678v1)|[link](https://github.com/jwhgdeu/tsbp)|
|**2024-09-25**|**SWE2: SubWord Enriched and Significant Word Emphasized Framework for Hate Speech Detection**|Guanyi Mou et.al.|[2409.16673v1](http://arxiv.org/abs/2409.16673v1)|null|
|**2024-09-25**|**GraphLoRA: Structure-Aware Contrastive Low-Rank Adaptation for Cross-Graph Transfer Learning**|Zhe-Rui Yang et.al.|[2409.16670v1](http://arxiv.org/abs/2409.16670v1)|null|
|**2024-09-25**|**Topic-aware Causal Intervention for Counterfactual Detection**|Thong Nguyen et.al.|[2409.16668v1](http://arxiv.org/abs/2409.16668v1)|null|
|**2024-09-25**|**A Character-Centric Creative Story Generation via Imagination**|Kyeongman Park et.al.|[2409.16667v1](http://arxiv.org/abs/2409.16667v1)|null|
|**2024-09-25**|**Pre-trained Language Models Return Distinguishable Probability Distributions to Unfaithfully Hallucinated Texts**|Taehun Cha et.al.|[2409.16658v1](http://arxiv.org/abs/2409.16658v1)|[link](https://github.com/AIML-K/HalluDist)|
|**2024-09-25**|**Speech Recognition Rescoring with Large Speech-Text Foundation Models**|Prashanth Gurunath Shivakumar et.al.|[2409.16654v1](http://arxiv.org/abs/2409.16654v1)|null|
|**2024-09-25**|**Progressive Representation Learning for Real-Time UAV Tracking**|Changhong Fu et.al.|[2409.16652v1](http://arxiv.org/abs/2409.16652v1)|[link](https://github.com/vision4robotics/prl-track)|
|**2024-09-25**|**Domain-Independent Automatic Generation of Descriptive Texts for Time-Series Data**|Kota Dohi et.al.|[2409.16647v1](http://arxiv.org/abs/2409.16647v1)|null|
|**2024-09-25**|**Cross-Lingual and Cross-Cultural Variation in Image Descriptions**|Uri Berger et.al.|[2409.16646v1](http://arxiv.org/abs/2409.16646v1)|null|
|**2024-09-25**|**Task Addition in Multi-Task Learning by Geometrical Alignment**|Soorin Yim et.al.|[2409.16645v1](http://arxiv.org/abs/2409.16645v1)|null|
|**2024-09-25**|**Enabling Auditory Large Language Models for Automatic Speech Quality Evaluation**|Siyin Wang et.al.|[2409.16644v1](http://arxiv.org/abs/2409.16644v1)|null|
|**2024-09-25**|**Training Language Models to Win Debates with Self-Play Improves Judge Accuracy**|Samuel Arnesen et.al.|[2409.16636v1](http://arxiv.org/abs/2409.16636v1)|[link](https://github.com/samuelarnesen/nyu-debate-modeling)|
|**2024-09-25**|**Judgment of Thoughts: Courtroom of the Binary Logical Reasoning in Large Language Models**|Sungjune Park et.al.|[2409.16635v1](http://arxiv.org/abs/2409.16635v1)|null|
|**2024-09-25**|**Stochastic Subsampling With Average Pooling**|Bum Jun Kim et.al.|[2409.16630v1](http://arxiv.org/abs/2409.16630v1)|null|
|**2024-09-25**|**Ascend HiFloat8 Format for Deep Learning**|Yuanyong Luo et.al.|[2409.16626v2](http://arxiv.org/abs/2409.16626v2)|null|

#### Abstracts
##### **Molmo and PixMo: Open Weights and Open Data for State-of-the-Art Multimodal Models**
2409.17146v1 by Matt Deitke, Christopher Clark, Sangho Lee, Rohun Tripathi, Yue Yang, Jae Sung Park, Mohammadreza Salehi, Niklas Muennighoff, Kyle Lo, Luca Soldaini, Jiasen Lu, Taira Anderson, Erin Bransom, Kiana Ehsani, Huong Ngo, YenSung Chen, Ajay Patel, Mark Yatskar, Chris Callison-Burch, Andrew Head, Rose Hendrix, Favyen Bastani, Eli VanderBilt, Nathan Lambert, Yvonne Chou, Arnavi Chheda, Jenna Sparks, Sam Skjonsberg, Michael Schmitz, Aaron Sarnat, Byron Bischoff, Pete Walsh, Chris Newell, Piper Wolters, Tanmay Gupta, Kuo-Hao Zeng, Jon Borchardt, Dirk Groeneveld, Jen Dumas, Crystal Nam, Sophie Lebrecht, Caitlin Wittlif, Carissa Schoenick, Oscar Michel, Ranjay Krishna, Luca Weihs, Noah A. Smith, Hannaneh Hajishirzi, Ross Girshick, Ali Farhadi, Aniruddha Kembhavi

Today's most advanced multimodal models remain proprietary. The strongest
open-weight models rely heavily on synthetic data from proprietary VLMs to
achieve good performance, effectively distilling these closed models into open
ones. As a result, the community is still missing foundational knowledge about
how to build performant VLMs from scratch. We present Molmo, a new family of
VLMs that are state-of-the-art in their class of openness. Our key innovation
is a novel, highly detailed image caption dataset collected entirely from human
annotators using speech-based descriptions. To enable a wide array of user
interactions, we also introduce a diverse dataset mixture for fine-tuning that
includes in-the-wild Q&A and innovative 2D pointing data. The success of our
approach relies on careful choices for the model architecture details, a
well-tuned training pipeline, and, most critically, the quality of our newly
collected datasets, all of which will be released. The best-in-class 72B model
within the Molmo family not only outperforms others in the class of open weight
and data models but also compares favorably against proprietary systems like
GPT-4o, Claude 3.5, and Gemini 1.5 on both academic benchmarks and human
evaluation.
  We will be releasing all of our model weights, captioning and fine-tuning
data, and source code in the near future. Select model weights, inference code,
and demo are available at https://molmo.allenai.org.

摘要：<paragraph>當今最先進的多模式模型仍然是專有的。最強大的開放權重模型極度依賴於來自專有 VLM 的合成資料，才能達到良好的效能，有效地將這些封閉模型提煉成開放模型。因此，社群仍然缺乏如何從頭打造效能良好的 VLM 的基礎知識。我們提出 Molmo，一個新的 VLM 家族，在開放性方面屬於其類別中的最先進技術。我們的關鍵創新是使用語音描述從人類註釋員那裡完全收集而來的一組新穎且極為詳細的影像標題資料集。為了支援各種使用者互動，我們還引進一個多元的資料集混合體進行微調，其中包括實際的問答和創新的 2D 指向資料。我們方法的成功有賴於模型架構細節的仔細選擇、調整良好的訓練管道，以及最關鍵的是我們新收集的資料集的品質，所有這些都將發布。Molmo 家族中最好的 72B 模型不僅優於開放權重和資料模型類別中的其他模型，而且在學術基準和人類評估中，也與 GPT-4o、Claude 3.5 和 Gemini 1.5 等專有系統相比之下毫不遜色。我們將在不久的將來釋出我們所有的模型權重、字幕和微調資料，以及原始程式碼。部分模型權重、推論程式碼和示範可於 https://molmo.allenai.org 取得。</paragraph>

##### **Differential Privacy Regularization: Protecting Training Data Through Loss Function Regularization**
2409.17144v1 by Francisco Aguilera-Martínez, Fernando Berzal

Training machine learning models based on neural networks requires large
datasets, which may contain sensitive information. The models, however, should
not expose private information from these datasets. Differentially private SGD
[DP-SGD] requires the modification of the standard stochastic gradient descent
[SGD] algorithm for training new models. In this short paper, a novel
regularization strategy is proposed to achieve the same goal in a more
efficient manner.

摘要：基於神經網路訓練機器學習模型需要大量資料集，其中可能包含敏感資訊。然而，模型不應公開這些資料集中的私人資訊。差分隱私 SGD [DP-SGD] 需要修改標準隨機梯度下降 [SGD] 演算法才能訓練新模型。在這篇短文中，提出了一種新穎的正規化策略，以更有效率的方式達成相同的目標。

##### **Attention Prompting on Image for Large Vision-Language Models**
2409.17143v1 by Runpeng Yu, Weihao Yu, Xinchao Wang

Compared with Large Language Models (LLMs), Large Vision-Language Models
(LVLMs) can also accept images as input, thus showcasing more interesting
emergent capabilities and demonstrating impressive performance on various
vision-language tasks. Motivated by text prompting in LLMs, visual prompting
has been explored to enhance LVLMs' capabilities of perceiving visual
information. However, previous visual prompting techniques solely process
visual inputs without considering text queries, limiting the models' ability to
follow text instructions to complete tasks. To fill this gap, in this work, we
propose a new prompting technique named Attention Prompting on Image, which
just simply overlays a text-query-guided attention heatmap on the original
input image and effectively enhances LVLM on various tasks. Specifically, we
generate an attention heatmap for the input image dependent on the text query
with an auxiliary model like CLIP. Then the heatmap simply multiplies the pixel
values of the original image to obtain the actual input image for the LVLM.
Extensive experiments on various vison-language benchmarks verify the
effectiveness of our technique. For example, Attention Prompting on Image
improves LLaVA-1.5 by 3.8% and 2.9% on MM-Vet and LLaVA-Wild benchmarks,
respectively.

摘要：與大型語言模型 (LLM) 相比，大型視覺語言模型 (LVLMs) 也可以接受影像作為輸入，因此展示出更有趣的浮現能力，並在各種視覺語言任務上展現出令人印象深刻的效能。受 LLM 中文字提示的啟發，視覺提示已廣泛探索，以增強 LVLMs 感知視覺資訊的能力。然而，先前的視覺提示技術僅處理視覺輸入，而不考慮文字查詢，這限制了模型按照文字指示完成任務的能力。為了填補這個空白，我們在這項工作中提出了一種新的提示技術，稱為影像上的注意力提示，它只是簡單地將文字查詢引導的注意力熱圖疊加在原始輸入影像上，並有效地增強了 LVLM 在各種任務上的能力。具體來說，我們為輸入影像產生一個注意力熱圖，該熱圖取決於文字查詢和 CLIP 等輔助模型。然後，熱圖簡單地將原始影像的像素值相乘，以取得 LVLM 的實際輸入影像。在各種視覺語言基準上的廣泛實驗驗證了我們技術的有效性。例如，影像上的注意力提示分別在 MM-Vet 和 LLaVA-Wild 基準上將 LLaVA-1.5 提升了 3.8% 和 2.9%。

##### **FineZip : Pushing the Limits of Large Language Models for Practical Lossless Text Compression**
2409.17141v1 by Fazal Mittu, Yihuan Bu, Akshat Gupta, Ashok Devireddy, Alp Eren Ozdarendeli, Anant Singh, Gopala Anumanchipalli

While the language modeling objective has been shown to be deeply connected
with compression, it is surprising that modern LLMs are not employed in
practical text compression systems. In this paper, we provide an in-depth
analysis of neural network and transformer-based compression techniques to
answer this question. We compare traditional text compression systems with
neural network and LLM-based text compression methods. Although LLM-based
systems significantly outperform conventional compression methods, they are
highly impractical. Specifically, LLMZip, a recent text compression system
using Llama3-8B requires 9.5 days to compress just 10 MB of text, although with
huge improvements in compression ratios. To overcome this, we present FineZip -
a novel LLM-based text compression system that combines ideas of online
memorization and dynamic context to reduce the compression time immensely.
FineZip can compress the above corpus in approximately 4 hours compared to 9.5
days, a 54 times improvement over LLMZip and comparable performance. FineZip
outperforms traditional algorithmic compression methods with a large margin,
improving compression ratios by approximately 50\%. With this work, we take the
first step towards making lossless text compression with LLMs a reality. While
FineZip presents a significant step in that direction, LLMs are still not a
viable solution for large-scale text compression. We hope our work paves the
way for future research and innovation to solve this problem.

摘要：儘管語言模型目標已被證明與壓縮有密切的關聯，但令人驚訝的是，現代 LLM 並未用於實際的文字壓縮系統中。在本文中，我們提供了神經網路和基於Transformer的壓縮技術的深入分析，以回答這個問題。我們將傳統的文字壓縮系統與基於神經網路和 LLM 的文字壓縮方法進行比較。儘管基於 LLM 的系統明顯優於傳統的壓縮方法，但它們極不切實際。具體來說，LLMZip 是一個最近的文字壓縮系統，使用 Llama3-8B 需要 9.5 天才能壓縮僅 10 MB 的文字，儘管壓縮比有了很大的改進。為了克服這個問題，我們提出了 FineZip - 一個新穎的基於 LLM 的文字壓縮系統，它結合了線上記憶和動態內容的想法，以極大地減少壓縮時間。與 9.5 天相比，FineZip 大約可以在 4 小時內壓縮上述語料庫，比 LLMZip 提高了 54 倍，並且具有相當的效能。FineZip 以很大的差距優於傳統的演算法壓縮方法，將壓縮比提高了大約 50%。透過這項工作，我們邁出了第一步，讓使用 LLM 的無損文字壓縮成為現實。儘管 FineZip 朝著這個方向邁出了重要一步，但 LLM 仍然不是大規模文字壓縮的可行解決方案。我們希望我們的研究為解決這個問題的未來研究和創新鋪平道路。

##### **Turn Every Application into an Agent: Towards Efficient Human-Agent-Computer Interaction with API-First LLM-Based Agents**
2409.17140v1 by Junting Lu, Zhiyang Zhang, Fangkai Yang, Jue Zhang, Lu Wang, Chao Du, Qingwei Lin, Saravan Rajmohan, Dongmei Zhang, Qi Zhang

Multimodal large language models (MLLMs) have enabled LLM-based agents to
directly interact with application user interfaces (UIs), enhancing agents'
performance in complex tasks. However, these agents often suffer from high
latency and low reliability due to the extensive sequential UI interactions. To
address this issue, we propose AXIS, a novel LLM-based agents framework
prioritize actions through application programming interfaces (APIs) over UI
actions. This framework also facilitates the creation and expansion of APIs
through automated exploration of applications. Our experiments on Office Word
demonstrate that AXIS reduces task completion time by 65%-70% and cognitive
workload by 38%-53%, while maintaining accuracy of 97%-98% compare to humans.
Our work contributes to a new human-agent-computer interaction (HACI) framework
and a fresh UI design principle for application providers in the era of LLMs.
It also explores the possibility of turning every applications into agents,
paving the way towards an agent-centric operating system (Agent OS).

摘要：多模态大型语言模型 (MLLM) 已让基于 LLM 的代理直接与应用程序用户界面 (UI) 互动，提升了代理在复杂任务中的表现。然而，这些代理经常因为广泛的顺序 UI 互动而遭受高延迟和低可靠性的问题。为了解决这个问题，我们提出 AXIS，一个新颖的基于 LLM 的代理框架，通过应用程序编程接口 (API) 优先执行动作，而不是 UI 动作。此框架还通过自动探索应用程序来促进创建和扩展 API。我们在 Office Word 上的实验表明，AXIS 将任务完成时间减少了 65%-70%，认知工作量减少了 38%-53%，同时将准确性维持在 97%-98%，可与人类相媲美。我们的工作有助于形成一个人机计算机交互 (HACI) 框架，以及在 LLM 时代为应用程序提供者提供一个新的 UI 设计原则。它还探索了将每个应用程序变成代理的可能性，为以代理为中心的作业系统 (Agent OS) 铺平了道路。

##### **Assessing the Level of Toxicity Against Distinct Groups in Bangla Social Media Comments: A Comprehensive Investigation**
2409.17130v1 by Mukaffi Bin Moin, Pronay Debnath, Usafa Akther Rifa, Rijeet Bin Anis

Social media platforms have a vital role in the modern world, serving as
conduits for communication, the exchange of ideas, and the establishment of
networks. However, the misuse of these platforms through toxic comments, which
can range from offensive remarks to hate speech, is a concerning issue. This
study focuses on identifying toxic comments in the Bengali language targeting
three specific groups: transgender people, indigenous people, and migrant
people, from multiple social media sources. The study delves into the intricate
process of identifying and categorizing toxic language while considering the
varying degrees of toxicity: high, medium, and low. The methodology involves
creating a dataset, manual annotation, and employing pre-trained transformer
models like Bangla-BERT, bangla-bert-base, distil-BERT, and
Bert-base-multilingual-cased for classification. Diverse assessment metrics
such as accuracy, recall, precision, and F1-score are employed to evaluate the
model's effectiveness. The experimental findings reveal that Bangla-BERT
surpasses alternative models, achieving an F1-score of 0.8903. This research
exposes the complexity of toxicity in Bangla social media dialogues, revealing
its differing impacts on diverse demographic groups.

摘要：<paragraph>社群媒體平台在現代社會中扮演著至關重要的角色，作為溝通、思想交流和建立人際網絡的管道。然而，這些平台遭到濫用，出現了從攻擊性言論到仇恨言論等各種形式的惡意留言，這是一個令人擔憂的問題。本研究專注於從多個社群媒體來源中找出針對三個特定群體（跨性別者、原住民和移工）的孟加拉語惡意留言。本研究深入探討了識別和分類惡意語言的複雜過程，同時考慮了不同程度的惡意程度：高、中、低。方法包括建立資料集、手動標註，並運用預先訓練好的轉換器模型，例如 Bangla-BERT、bangla-bert-base、distil-BERT 和 Bert-base-multilingual-cased 進行分類。採用多樣化的評估指標，例如準確度、召回率、精確度和 F1 分數，來評估模型的有效性。實驗結果顯示，Bangla-BERT 優於其他模型，達到 0.8903 的 F1 分數。本研究揭露了孟加拉社群媒體對話中惡意言論的複雜性，顯示出它對不同人口群體產生不同的影響。</paragraph>

##### **Blox-Net: Generative Design-for-Robot-Assembly Using VLM Supervision, Physics Simulation, and a Robot with Reset**
2409.17126v1 by Andrew Goldberg, Kavish Kondap, Tianshuang Qiu, Zehan Ma, Letian Fu, Justin Kerr, Huang Huang, Kaiyuan Chen, Kuan Fang, Ken Goldberg

Generative AI systems have shown impressive capabilities in creating text,
code, and images. Inspired by the rich history of research in industrial
''Design for Assembly'', we introduce a novel problem: Generative
Design-for-Robot-Assembly (GDfRA). The task is to generate an assembly based on
a natural language prompt (e.g., ''giraffe'') and an image of available
physical components, such as 3D-printed blocks. The output is an assembly, a
spatial arrangement of these components, and instructions for a robot to build
this assembly. The output must 1) resemble the requested object and 2) be
reliably assembled by a 6 DoF robot arm with a suction gripper. We then present
Blox-Net, a GDfRA system that combines generative vision language models with
well-established methods in computer vision, simulation, perturbation analysis,
motion planning, and physical robot experimentation to solve a class of GDfRA
problems with minimal human supervision. Blox-Net achieved a Top-1 accuracy of
63.5% in the ''recognizability'' of its designed assemblies (eg, resembling
giraffe as judged by a VLM). These designs, after automated perturbation
redesign, were reliably assembled by a robot, achieving near-perfect success
across 10 consecutive assembly iterations with human intervention only during
reset prior to assembly. Surprisingly, this entire design process from textual
word (''giraffe'') to reliable physical assembly is performed with zero human
intervention.

摘要：生成式 AI 系統在建立文字、程式碼和影像方面展現出令人印象深刻的能力。受到工業「組裝設計」研究豐富歷史的啟發，我們提出了一個新的問題：生成式機器人組裝設計 (GDfRA)。這項任務是根據自然語言提示（例如「長頸鹿」）和可用實體元件（例如 3D 列印積木）的影像來產生組裝。輸出是一個組裝，這些元件的空間配置，以及機器人組裝此組裝的說明。輸出必須 1) 類似於請求的物件，且 2) 能夠由具有吸盤夾具的 6 DoF 機器手臂可靠地組裝。接著我們提出 Blox-Net，這是一個 GDfRA 系統，結合了生成式視覺語言模型與電腦視覺、模擬、擾動分析、動作規劃和實體機器人實驗中已建立良好的方法，以解決一類 GDfRA 問題，且只需最少的人工監督。在組裝設計的「可辨識性」方面，Blox-Net 達到了 63.5% 的 Top-1 精確度（例如，經由 VLM 判斷類似於長頸鹿）。這些設計在自動擾動重新設計後，由機器人可靠地組裝，在 10 次連續組裝反覆運算中達到近乎完美的成功率，只有在組裝前重設時才需要人工介入。令人驚訝的是，從文字詞彙（「長頸鹿」）到可靠的實體組裝，整個設計過程完全沒有人工介入。

##### **On-orbit Servicing for Spacecraft Collision Avoidance With Autonomous Decision Making**
2409.17125v1 by Susmitha Patnala, Adam Abdin

This study develops an AI-based implementation of autonomous On-Orbit
Servicing (OOS) mission to assist with spacecraft collision avoidance maneuvers
(CAMs). We propose an autonomous `servicer' trained with Reinforcement Learning
(RL) to autonomously detect potential collisions between a target satellite and
space debris, rendezvous and dock with endangered satellites, and execute
optimal CAM. The RL model integrates collision risk estimates, satellite
specifications, and debris data to generate an optimal maneuver matrix for OOS
rendezvous and collision prevention. We employ the Cross-Entropy algorithm to
find optimal decision policies efficiently. Initial results demonstrate the
feasibility of autonomous robotic OOS for collision avoidance services,
focusing on one servicer spacecraft to one endangered satellite scenario.
However, merging spacecraft rendezvous and optimal CAM presents significant
complexities. We discuss design challenges and critical parameters for the
successful implementation of the framework presented through a case study.

摘要：本研究開發了一種基於 AI 的自主軌道服務 (OOS) 任務實作，用於協助太空船的防撞操作 (CAM)。我們提出一個使用強化學習 (RL) 訓練的自主「服務器」，用於自主偵測目標衛星與太空碎片之間的潛在碰撞，與瀕危衛星會合並對接，並執行最佳化 CAM。RL 模型整合了碰撞風險估計、衛星規格和碎片資料，以產生一個最佳化操作矩陣，用於 OOS 會合和防撞。我們採用交叉熵演算法來有效找出最佳決策策略。初步結果證明了自主機器人 OOS 防撞服務的可行性，專注於一艘服務器太空船對一艘瀕危衛星的場景。然而，整合太空船會合和最佳化 CAM 會產生顯著的複雜性。我們透過一個案例研究討論了成功實作所提出的架構的設計挑戰和關鍵參數。

##### **Deep Learning and Machine Learning, Advancing Big Data Analytics and Management: Handy Appetizer**
2409.17120v1 by Benji Peng, Xuanhe Pan, Yizhu Wen, Ziqian Bi, Keyu Chen, Ming Li, Ming Liu, Qian Niu, Junyu Liu, Jinlang Wang, Sen Zhang, Jiawei Xu, Pohsun Feng

This book explores the role of Artificial Intelligence (AI), Machine Learning
(ML), and Deep Learning (DL) in driving the progress of big data analytics and
management. The book focuses on simplifying the complex mathematical concepts
behind deep learning, offering intuitive visualizations and practical case
studies to help readers understand how neural networks and technologies like
Convolutional Neural Networks (CNNs) work. It introduces several classic models
and technologies such as Transformers, GPT, ResNet, BERT, and YOLO,
highlighting their applications in fields like natural language processing,
image recognition, and autonomous driving. The book also emphasizes the
importance of pre-trained models and how they can enhance model performance and
accuracy, with instructions on how to apply these models in various real-world
scenarios. Additionally, it provides an overview of key big data management
technologies like SQL and NoSQL databases, as well as distributed computing
frameworks such as Apache Hadoop and Spark, explaining their importance in
managing and processing vast amounts of data. Ultimately, the book underscores
the value of mastering deep learning and big data management skills as critical
tools for the future workforce, making it an essential resource for both
beginners and experienced professionals.

摘要：本書探討人工智慧 (AI)、機器學習 (ML) 和深度學習 (DL) 在推動大數據分析和管理進步中的角色。本書重點在於簡化深度學習背後複雜的數學概念，提供直觀的視覺化和實用的案例研究，以幫助讀者了解神經網路和卷積神經網路 (CNN) 等技術如何運作。它介紹了幾個經典模型和技術，例如 Transformers、GPT、ResNet、BERT 和 YOLO，重點介紹它們在自然語言處理、影像辨識和自動駕駛等領域的應用。本書也強調預訓練模型的重要性，以及它們如何增強模型效能和準確度，並提供如何將這些模型應用於各種實際場景的說明。此外，它概述了關鍵大數據管理技術，例如 SQL 和 NoSQL 資料庫，以及分散式運算架構，例如 Apache Hadoop 和 Spark，說明它們在管理和處理大量資料中的重要性。最後，本書強調精通深度學習和大數據管理技能的價值，因為它們是未來勞動力必備的重要工具，使其成為初學者和經驗豐富的專業人士的必備資源。

##### **Programming Every Example: Lifting Pre-training Data Quality like Experts at Scale**
2409.17115v1 by Fan Zhou, Zengzhi Wang, Qian Liu, Junlong Li, Pengfei Liu

Large language model pre-training has traditionally relied on human experts
to craft heuristics for improving the corpora quality, resulting in numerous
rules developed to date. However, these rules lack the flexibility to address
the unique characteristics of individual example effectively. Meanwhile,
applying tailored rules to every example is impractical for human experts. In
this paper, we demonstrate that even small language models, with as few as 0.3B
parameters, can exhibit substantial data refining capabilities comparable to
those of human experts. We introduce Programming Every Example (ProX), a novel
framework that treats data refinement as a programming task, enabling models to
refine corpora by generating and executing fine-grained operations, such as
string normalization, for each individual example at scale. Experimental
results show that models pre-trained on ProX-curated data outperform either
original data or data filtered by other selection methods by more than 2%
across various downstream benchmarks. Its effectiveness spans various model
sizes and pre-training corpora, including C4, RedPajama-V2, and FineWeb.
Furthermore, ProX exhibits significant potential in domain-specific continual
pre-training: without domain specific design, models trained on OpenWebMath
refined by ProX outperform human-crafted rule-based methods, improving average
accuracy by 7.6% over Mistral-7B, with 14.6% for Llama-2-7B and 20.3% for
CodeLlama-7B, all within 10B tokens to be comparable to models like Llemma-7B
trained on 200B tokens. Further analysis highlights that ProX significantly
saves training FLOPs, offering a promising path for efficient LLM
pre-training.We are open-sourcing ProX with >100B corpus, models, and sharing
all training and implementation details for reproducible research and future
innovation. Code: https://github.com/GAIR-NLP/ProX

摘要：大型語言模型預訓練傳統上依賴人類專家
制定啟發式方法來改善語料庫品質，導致迄今已開發出許多規則。然而，這些規則缺乏靈活性，無法有效解決個別範例的獨特特性。同時，對每個範例應用量身打造的規則對人類專家來說並不實際。在本文中，我們證明即使是只有 0.3B 參數的小語言模型，也可以展現出與人類專家相當的實質性資料精煉能力。我們引入了「為每個範例編程」（ProX），這是一個新穎的架構，將資料精煉視為一項編程任務，使模型能夠透過為每個個別範例產生並執行細微的運算（例如字串正規化）來精煉語料庫。實驗結果顯示，使用 ProX 整理資料後預先訓練的模型，在各種下游基準中都比原始資料或由其他選擇方法篩選的資料高出 2% 以上。其效能涵蓋各種模型大小和預訓練語料庫，包括 C4、RedPajama-V2 和 FineWeb。此外，ProX 在特定領域的持續預訓練中展現出顯著的潛力：在沒有特定領域設計的情況下，使用 ProX 精煉的 OpenWebMath 訓練模型優於人類編寫的基於規則的方法，平均準確度比 Mistral-7B 提高 7.6%，比 Llama-2-7B 提高 14.6%，比 CodeLlama-7B 提高 20.3%，所有都在 10B 個代幣內，與訓練 200B 個代幣的 Llemma-7B 等模型相當。進一步的分析重點指出，ProX 大幅節省了訓練 FLOP，為高效 LLM 預訓練提供了一條有希望的路徑。我們開放原始碼 ProX，其中包含 >100B 語料庫、模型，並分享所有訓練和實作細節，以利於可重製的研究和未來的創新。程式碼：https://github.com/GAIR-NLP/ProX

##### **Unveiling Ontological Commitment in Multi-Modal Foundation Models**
2409.17109v1 by Mert Keser, Gesina Schwalbe, Niki Amini-Naieni, Matthias Rottmann, Alois Knoll

Ontological commitment, i.e., used concepts, relations, and assumptions, are
a corner stone of qualitative reasoning (QR) models. The state-of-the-art for
processing raw inputs, though, are deep neural networks (DNNs), nowadays often
based off from multimodal foundation models. These automatically learn rich
representations of concepts and respective reasoning. Unfortunately, the
learned qualitative knowledge is opaque, preventing easy inspection,
validation, or adaptation against available QR models. So far, it is possible
to associate pre-defined concepts with latent representations of DNNs, but
extractable relations are mostly limited to semantic similarity. As a next step
towards QR for validation and verification of DNNs: Concretely, we propose a
method that extracts the learned superclass hierarchy from a multimodal DNN for
a given set of leaf concepts. Under the hood we (1) obtain leaf concept
embeddings using the DNN's textual input modality; (2) apply hierarchical
clustering to them, using that DNNs encode semantic similarities via vector
distances; and (3) label the such-obtained parent concepts using search in
available ontologies from QR. An initial evaluation study shows that meaningful
ontological class hierarchies can be extracted from state-of-the-art foundation
models. Furthermore, we demonstrate how to validate and verify a DNN's learned
representations against given ontologies. Lastly, we discuss potential future
applications in the context of QR.

摘要：本体論承諾，即使用概念、關係和假設，是定性推理（QR）模型的基石。然而，處理原始輸入的最新技術是深度神經網路（DNN），現在通常基於多模態基礎模型。這些自動學習概念和各自推理的豐富表示。不幸的是，學習到的定性知識是不透明的，阻止了對可用 QR 模型的輕鬆檢查、驗證或適應。到目前為止，可以將預定義的概念與 DNN 的潛在表示關聯起來，但可提取的關係大多限於語義相似性。作為驗證和驗證 DNN 的 QR 的下一步：具體來說，我們提出了一種方法，該方法從多模態 DNN 中提取學習到的超類別層次結構，用於給定的葉子概念集。在幕後，我們（1）使用 DNN 的文本輸入方式獲取葉子概念嵌入；（2）對它們應用階層聚類，使用 DNN 通過向量距離編碼語義相似性；（3）使用 QR 中可用本体中的搜尋標籤此類獲得的父概念。初步評估研究表明，可以從最先進的基礎模型中提取有意義的本体類別層次結構。此外，我們展示了如何根據給定的本体驗證和驗證 DNN 學習的表示。最後，我們討論了 QR 背景下的潛在未來應用。

##### **Accumulator-Aware Post-Training Quantization**
2409.17092v1 by Ian Colbert, Fabian Grob, Giuseppe Franco, Jinjie Zhang, Rayan Saab

Several recent studies have investigated low-precision accumulation,
reporting improvements in throughput, power, and area across various platforms.
However, the accompanying proposals have only considered the quantization-aware
training (QAT) paradigm, in which models are fine-tuned or trained from scratch
with quantization in the loop. As models continue to grow in size, QAT
techniques become increasingly more expensive, which has motivated the recent
surge in post-training quantization (PTQ) research. To the best of our
knowledge, ours marks the first formal study of accumulator-aware quantization
in the PTQ setting. To bridge this gap, we introduce AXE, a practical framework
of accumulator-aware extensions designed to endow overflow avoidance guarantees
to existing layer-wise PTQ algorithms. We theoretically motivate AXE and
demonstrate its flexibility by implementing it on top of two state-of-the-art
PTQ algorithms: GPFQ and OPTQ. We further generalize AXE to support multi-stage
accumulation for the first time, opening the door for full datapath
optimization and scaling to large language models (LLMs). We evaluate AXE
across image classification and language generation models, and observe
significant improvements in the trade-off between accumulator bit width and
model accuracy over baseline methods.

摘要：最近有许多研究调查了低精度累加，报告了在各种平台上吞吐量、功耗和面积的改进。然而，随附的提案只考虑了量化感知训练 (QAT) 范例，其中模型经过微调或从头开始训练，并且在循环中进行量化。随着模型尺寸持续增长，QAT 技术变得越来越昂贵，这促使训练后量化 (PTQ) 研究最近激增。据我们所知，我们的研究标志着在 PTQ 设置中首次正式研究了累加器感知量化。为了弥补这一差距，我们引入了 AXE，这是一个实用的累加器感知扩展框架，旨在为现有的逐层 PTQ 算法提供溢出避免保证。我们在理论上激发了 AXE，并通过在两种最先进的 PTQ 算法 GPFQ 和 OPTQ 的基础上实现它来证明其灵活性。我们进一步将 AXE 概括为首次支持多级累加，为完全数据路径优化和扩展到大语言模型 (LLM) 打开了大门。我们在图像分类和语言生成模型中评估了 AXE，并观察到在累加器位宽和模型准确性之间的权衡方面，相较于基线方法有显著的改进。

##### **Ctrl-GenAug: Controllable Generative Augmentation for Medical Sequence Classification**
2409.17091v1 by Xinrui Zhou, Yuhao Huang, Haoran Dou, Shijing Chen, Ao Chang, Jia Liu, Weiran Long, Jian Zheng, Erjiao Xu, Jie Ren, Ruobing Huang, Jun Cheng, Wufeng Xue, Dong Ni

In the medical field, the limited availability of large-scale datasets and
labor-intensive annotation processes hinder the performance of deep models.
Diffusion-based generative augmentation approaches present a promising solution
to this issue, having been proven effective in advancing downstream medical
recognition tasks. Nevertheless, existing works lack sufficient semantic and
sequential steerability for challenging video/3D sequence generation, and
neglect quality control of noisy synthesized samples, resulting in unreliable
synthetic databases and severely limiting the performance of downstream tasks.
In this work, we present Ctrl-GenAug, a novel and general generative
augmentation framework that enables highly semantic- and sequential-customized
sequence synthesis and suppresses incorrectly synthesized samples, to aid
medical sequence classification. Specifically, we first design a multimodal
conditions-guided sequence generator for controllably synthesizing
diagnosis-promotive samples. A sequential augmentation module is integrated to
enhance the temporal/stereoscopic coherence of generated samples. Then, we
propose a noisy synthetic data filter to suppress unreliable cases at semantic
and sequential levels. Extensive experiments on 3 medical datasets, using 11
networks trained on 3 paradigms, comprehensively analyze the effectiveness and
generality of Ctrl-GenAug, particularly in underrepresented high-risk
populations and out-domain conditions.

摘要：在医学領域中，大規模數據集的可用性有限，且人工標註過程繁瑣，阻礙了深度模型的執行。基於擴散的生成式擴充方法為此問題提供了有前景的解決方案，已被證實能有效推進下游醫療識別任務。儘管如此，現有作品缺乏足夠的語義和序列可控性，難以進行具有挑戰性的視訊/3D 序列生成，且忽略了對有雜訊合成樣本的品質控制，導致合成式資料庫不可靠，並嚴重限制了下游任務的執行。在這項工作中，我們提出了 Ctrl-GenAug，一個新穎且通用的生成式擴充架構，能實現高度語義和序列自訂的序列合成，並抑制錯誤合成的樣本，以協助醫療序列分類。具體來說，我們首先設計了一個多模態條件引導序列生成器，用於可控地合成促進診斷的樣本。整合了一個序列擴充模組，以增強生成樣本的時間/立體一致性。然後，我們提出了一個有雜訊的合成資料濾波器，以抑制語義和序列層級中不可靠的案例。在 3 個醫療數據集上進行的廣泛實驗，使用在 3 個範例中訓練的 11 個網路，全面分析了 Ctrl-GenAug 的有效性和普遍性，特別是在代表性不足的高風險族群和領域外條件中。

##### **Can Vision Language Models Learn from Visual Demonstrations of Ambiguous Spatial Reasoning?**
2409.17080v1 by Bowen Zhao, Leo Parker Dirac, Paulina Varshavskaya

Large vision-language models (VLMs) have become state-of-the-art for many
computer vision tasks, with in-context learning (ICL) as a popular adaptation
strategy for new ones. But can VLMs learn novel concepts purely from visual
demonstrations, or are they limited to adapting to the output format of ICL
examples? We propose a new benchmark we call Spatial Visual Ambiguity Tasks
(SVAT) that challenges state-of-the-art VLMs to learn new visuospatial tasks
in-context. We find that VLMs fail to do this zero-shot, and sometimes continue
to fail after finetuning. However, adding simpler data to the training by
curriculum learning leads to improved ICL performance.

摘要：大型視覺語言模型 (VLM) 已成為許多電腦視覺任務的最新技術，其中情境學習 (ICL) 是一種適用於新任務的熱門改編策略。但 VLM 能否僅從視覺示範中學習新概念，或者它們是否僅限於適應 ICL 範例的輸出格式？我們提出一個新基準，我們稱之為空間視覺模糊任務 (SVAT)，它挑戰最新技術的 VLM 在情境中學習新的視覺空間任務。我們發現 VLM 無法做到這一點，有時在微調後仍會繼續失敗。然而，透過課程學習將更簡單的資料新增到訓練中，可以提升 ICL 的效能。

##### **Enhancing Post-Hoc Attributions in Long Document Comprehension via Coarse Grained Answer Decomposition**
2409.17073v1 by Pritika Ramu, Koustava Goswami, Apoorv Saxena, Balaji Vasan Srinivavsan

Accurately attributing answer text to its source document is crucial for
developing a reliable question-answering system. However, attribution for long
documents remains largely unexplored. Post-hoc attribution systems are designed
to map answer text back to the source document, yet the granularity of this
mapping has not been addressed. Furthermore, a critical question arises: What
precisely should be attributed, with an emphasis on identifying the information
units within an answer that necessitate grounding? In this paper, we propose
and investigate a novel approach to the factual decomposition of generated
answers for attribution, employing template-based in-context learning. To
accomplish this, we utilize the question and integrate negative sampling during
few-shot in-context learning for decomposition. This approach enhances the
semantic understanding of both abstractive and extractive answers. We examine
the impact of answer decomposition by providing a thorough examination of
various attribution approaches, ranging from retrieval-based techniques to
LLM-based attributors.

摘要：準確地將答案文字歸因於其原始文件對於開發可靠的問答系統至關重要。然而，對於長文件的歸因仍然很大程度上未被探索。事後歸因系統旨在將答案文字映射回原始文件，但尚未解決此映射的粒度。此外，一個關鍵問題出現了：應該歸因什麼，重點是識別答案中需要依據的資訊單元？在本文中，我們提出並探討一種新穎的方法來對生成的答案進行事實分解以進行歸因，採用基於模板的上下文學習。為了實現這一點，我們在少次數上下文學習期間利用問題並整合負面抽樣進行分解。這種方法增強了對抽象和抽取答案的語義理解。我們通過提供對各種歸因方法的徹底檢查來檢驗答案分解的影響，範圍從基於檢索的技術到基於 LLM 的歸因器。

##### **The Effect of Perceptual Metrics on Music Representation Learning for Genre Classification**
2409.17069v1 by Tashi Namgyal, Alexander Hepburn, Raul Santos-Rodriguez, Valero Laparra, Jesus Malo

The subjective quality of natural signals can be approximated with objective
perceptual metrics. Designed to approximate the perceptual behaviour of human
observers, perceptual metrics often reflect structures found in natural signals
and neurological pathways. Models trained with perceptual metrics as loss
functions can capture perceptually meaningful features from the structures held
within these metrics. We demonstrate that using features extracted from
autoencoders trained with perceptual losses can improve performance on music
understanding tasks, i.e. genre classification, over using these metrics
directly as distances when learning a classifier. This result suggests improved
generalisation to novel signals when using perceptual metrics as loss functions
for representation learning.

摘要：自然訊號的主觀品質可以用客觀的感知指標來近似。為了近似人類觀察者的感知行為，感知指標通常反映自然訊號和神經路徑中發現的結構。以感知指標作為損失函數訓練的模型可以從這些指標中包含的結構中擷取有感知意義的特徵。我們證明，使用從使用感知損失訓練的自編碼器中提取的特徵可以改善音樂理解任務（例如類型分類）的效能，而不是在學習分類器時直接將這些指標用作距離。此結果表明，在使用感知指標作為表示學習的損失函數時，對新訊號的概化能力會有所提升。

##### **VPTQ: Extreme Low-bit Vector Post-Training Quantization for Large Language Models**
2409.17066v1 by Yifei Liu, Jicheng Wen, Yang Wang, Shengyu Ye, Li Lyna Zhang, Ting Cao, Cheng Li, Mao Yang

Scaling model size significantly challenges the deployment and inference of
Large Language Models (LLMs). Due to the redundancy in LLM weights, recent
research has focused on pushing weight-only quantization to extremely low-bit
(even down to 2 bits). It reduces memory requirements, optimizes storage costs,
and decreases memory bandwidth needs during inference. However, due to
numerical representation limitations, traditional scalar-based weight
quantization struggles to achieve such extreme low-bit. Recent research on
Vector Quantization (VQ) for LLMs has demonstrated the potential for extremely
low-bit model quantization by compressing vectors into indices using lookup
tables.
  In this paper, we introduce Vector Post-Training Quantization (VPTQ) for
extremely low-bit quantization of LLMs. We use Second-Order Optimization to
formulate the LLM VQ problem and guide our quantization algorithm design by
solving the optimization. We further refine the weights using
Channel-Independent Second-Order Optimization for a granular VQ. In addition,
by decomposing the optimization problem, we propose a brief and effective
codebook initialization algorithm. We also extend VPTQ to support residual and
outlier quantization, which enhances model accuracy and further compresses the
model. Our experimental results show that VPTQ reduces model quantization
perplexity by $0.01$-$0.34$ on LLaMA-2, $0.38$-$0.68$ on Mistral-7B,
$4.41$-$7.34$ on LLaMA-3 over SOTA at 2-bit, with an average accuracy
improvement of $0.79$-$1.5\%$ on LLaMA-2, $1\%$ on Mistral-7B, $11$-$22\%$ on
LLaMA-3 on QA tasks on average. We only utilize $10.4$-$18.6\%$ of the
quantization algorithm execution time, resulting in a $1.6$-$1.8\times$
increase in inference throughput compared to SOTA.

摘要：<paragraph>大幅縮放模型大小會對大型語言模型 (LLM) 的部署和推論帶來嚴峻挑戰。由於 LLM 權重中的冗餘，最近的研究已專注於將僅權重量化推至極低位元（甚至低至 2 位元）。這減少了記憶體需求，最佳化儲存成本，並在推論期間降低記憶體頻寬需求。然而，由於數值表示限制，傳統的基於純量權重量化難以達到如此極低的位元。最近針對 LLM 的向量量化 (VQ) 研究已證明了極低位元模型量化的潛力，方法是使用查找表將向量壓縮成索引。
本文中，我們介紹了極低位元 LLM 量化的向量後訓練量化 (VPTQ)。我們使用二階最佳化來制定 LLM VQ 問題，並透過求解最佳化來引導我們的量化演算法設計。我們進一步使用通道無關二階最佳化來改善權重，以進行細緻的 VQ。此外，透過分解最佳化問題，我們提出了一個簡短且有效的碼本初始化演算法。我們也擴充 VPTQ 以支援殘差和離群值量化，這能提升模型準確度並進一步壓縮模型。我們的實驗結果顯示，VPTQ 在 2 位元時，將 LLaMA-2 的模型量化困惑度降低了 $0.01$-$0.34$，Mistral-7B 降低了 $0.38$-$0.68$，LLaMA-3 降低了 $4.41$-$7.34$，優於 SOTA，平均準確度提升了 LLaMA-2 的 $0.79$-$1.5\%$，Mistral-7B 的 $1\%$，LLaMA-3 的 $11$-$22\%$（平均而言）。我們僅利用了量化演算法執行時間的 $10.4$-$18.6\%$，與 SOTA 相比，推論吞吐量增加了 $1.6$-$1.8\times$。</paragraph>

##### **Benchmarking Domain Generalization Algorithms in Computational Pathology**
2409.17063v1 by Neda Zamanitajeddin, Mostafa Jahanifar, Kesi Xu, Fouzia Siraj, Nasir Rajpoot

Deep learning models have shown immense promise in computational pathology
(CPath) tasks, but their performance often suffers when applied to unseen data
due to domain shifts. Addressing this requires domain generalization (DG)
algorithms. However, a systematic evaluation of DG algorithms in the CPath
context is lacking. This study aims to benchmark the effectiveness of 30 DG
algorithms on 3 CPath tasks of varying difficulty through 7,560
cross-validation runs. We evaluate these algorithms using a unified and robust
platform, incorporating modality-specific techniques and recent advances like
pretrained foundation models. Our extensive cross-validation experiments
provide insights into the relative performance of various DG strategies. We
observe that self-supervised learning and stain augmentation consistently
outperform other methods, highlighting the potential of pretrained models and
data augmentation. Furthermore, we introduce a new pan-cancer tumor detection
dataset (HISTOPANTUM) as a benchmark for future research. This study offers
valuable guidance to researchers in selecting appropriate DG approaches for
CPath tasks.

摘要：深度學習模型在計算病理學 (CPath) 任務中展現出巨大的前景，但當應用於未見數據時，其效能通常會因領域轉移而下降。解決此問題需要領域泛化 (DG) 演算法。然而，目前缺乏在 CPath 背景下對 DG 演算法的系統性評估。本研究旨在透過 7,560 次交叉驗證執行，對 30 種 DG 演算法在 3 種不同難度的 CPath 任務上的效能進行基準測試。我們使用一個統一且穩健的平台評估這些演算法，並結合特定於方式的技術和預訓練基礎模型等最新進展。我們廣泛的交叉驗證實驗提供了對各種 DG 策略相對效能的見解。我們觀察到自監督式學習和染色增強始終優於其他方法，突顯了預訓練模型和資料增強的潛力。此外，我們引入了一個新的泛癌腫瘤檢測資料集 (HISTOPANTUM) 作為未來研究的基準。本研究為研究人員在選擇適當的 DG 方法以執行 CPath 任務時提供了寶貴的指導。

##### **DRIM: Learning Disentangled Representations from Incomplete Multimodal Healthcare Data**
2409.17055v1 by Lucas Robinet, Ahmad Berjaoui, Ziad Kheil, Elizabeth Cohen-Jonathan Moyal

Real-life medical data is often multimodal and incomplete, fueling the
growing need for advanced deep learning models capable of integrating them
efficiently. The use of diverse modalities, including histopathology slides,
MRI, and genetic data, offers unprecedented opportunities to improve prognosis
prediction and to unveil new treatment pathways. Contrastive learning, widely
used for deriving representations from paired data in multimodal tasks, assumes
that different views contain the same task-relevant information and leverages
only shared information. This assumption becomes restrictive when handling
medical data since each modality also harbors specific knowledge relevant to
downstream tasks. We introduce DRIM, a new multimodal method for capturing
these shared and unique representations, despite data sparsity. More
specifically, given a set of modalities, we aim to encode a representation for
each one that can be divided into two components: one encapsulating
patient-related information common across modalities and the other,
encapsulating modality-specific details. This is achieved by increasing the
shared information among different patient modalities while minimizing the
overlap between shared and unique components within each modality. Our method
outperforms state-of-the-art algorithms on glioma patients survival prediction
tasks, while being robust to missing modalities. To promote reproducibility,
the code is made publicly available at https://github.com/Lucas-rbnt/DRIM

摘要：真實生活中的醫療數據通常是多模態且不完整的，這使得對能夠有效整合它們的高級深度學習模型的需求不斷增長。使用多種形式，包括組織病理切片、核磁共振和遺傳數據，提供了前所未有的機會來改進預後預測並揭示新的治療途徑。對比學習廣泛用於從多模態任務中的配對數據中推導出表示，它假設不同的觀點包含相同的與任務相關的信息，並且僅利用共享信息。在處理醫療數據時，這一假設變得具有限制性，因為每種形式也包含與下游任務相關的具體知識。我們介紹了 DRIM，這是一種新的多模態方法，用於捕獲這些共享和唯一的表示，儘管數據稀疏。更具體地說，給定一組形式，我們旨在對每個形式編碼一個表示，該表示可以分為兩個組成部分：一個封裝跨形式的患者相關信息，另一個封裝形式特定的細節。這是通過增加不同患者形式之間的共享信息，同時最大程度地減少每個形式中共享和唯一組成部分之間的重疊來實現的。我們的算法在神經膠質瘤患者的生存預測任務中優於最先進的算法，同時對缺失的形式具有魯棒性。為了促進可重複性，代碼已在 https://github.com/Lucas-rbnt/DRIM 上公開。

##### **Using LLM for Real-Time Transcription and Summarization of Doctor-Patient Interactions into ePuskesmas in Indonesia**
2409.17054v1 by Azmul Asmar Irfan, Nur Ahmad Khatim, Mansur M. Arief

One of the key issues contributing to inefficiency in Puskesmas is the
time-consuming nature of doctor-patient interactions. Doctors need to conduct
thorough consultations, which include diagnosing the patient's condition,
providing treatment advice, and transcribing detailed notes into medical
records. In regions with diverse linguistic backgrounds, doctors often have to
ask clarifying questions, further prolonging the process. While diagnosing is
essential, transcription and summarization can often be automated using AI to
improve time efficiency and help doctors enhance care quality and enable early
diagnosis and intervention. This paper proposes a solution using a localized
large language model (LLM) to transcribe, translate, and summarize
doctor-patient conversations. We utilize the Whisper model for transcription
and GPT-3 to summarize them into the ePuskemas medical records format. This
system is implemented as an add-on to an existing web browser extension,
allowing doctors to fill out patient forms while talking. By leveraging this
solution for real-time transcription, translation, and summarization, doctors
can improve the turnaround time for patient care while enhancing the quality of
records, which become more detailed and insightful for future visits. This
innovation addresses challenges like overcrowded facilities and the
administrative burden on healthcare providers in Indonesia. We believe this
solution will help doctors save time, provide better care, and produce more
accurate medical records, representing a significant step toward modernizing
healthcare and ensuring patients receive timely, high-quality care, even in
resource-constrained settings.

摘要：<paragraph>導致 Puskesmas 效率低下的關鍵問題之一是，醫生和病人互動耗時。醫生需要進行徹底的諮詢，包括診斷病人的病情、提供治療建議，以及將詳細的筆記記錄在醫療記錄中。在語言背景多元的地區，醫生經常必須提出澄清問題，進一步延長流程。雖然診斷至關重要，但使用 AI 進行轉錄和摘要通常可以自動化，以提高時間效率，並幫助醫生提高護理品質，並實現早期診斷和干預。本文提出了一個使用本地化大型語言模型 (LLM) 來轉錄、翻譯和摘要醫生與病人對話的解決方案。我們利用 Whisper 模型進行轉錄，並使用 GPT-3 將其摘要成 ePuskemas 醫療記錄格式。此系統實作為現有網路瀏覽器擴充功能的附加元件，讓醫生可以在交談時填寫病患表單。透過利用此解決方案進行即時轉錄、翻譯和摘要，醫生可以改善病患照護的周轉時間，同時提升記錄品質，讓記錄變得更詳細且更有洞見，以利於後續就診。此創新解決了像醫療機構人滿為患和印尼醫療保健提供者的行政負擔等挑戰。我們相信此解決方案將幫助醫生節省時間、提供更好的照護，並產生更準確的醫療記錄，代表著現代化醫療保健並確保病人即使在資源受限的環境中也能獲得及時、高品質的照護的重要一步。</paragraph>

##### **ControlCity: A Multimodal Diffusion Model Based Approach for Accurate Geospatial Data Generation and Urban Morphology Analysis**
2409.17049v1 by Fangshuo Zhou, Huaxia Li, Rui Hu, Sensen Wu, Hailin Feng, Zhenhong Du, Liuchang Xu

Volunteer Geographic Information (VGI), with its rich variety, large volume,
rapid updates, and diverse sources, has become a critical source of geospatial
data. However, VGI data from platforms like OSM exhibit significant quality
heterogeneity across different data types, particularly with urban building
data. To address this, we propose a multi-source geographic data transformation
solution, utilizing accessible and complete VGI data to assist in generating
urban building footprint data. We also employ a multimodal data generation
framework to improve accuracy. First, we introduce a pipeline for constructing
an 'image-text-metadata-building footprint' dataset, primarily based on road
network data and supplemented by other multimodal data. We then present
ControlCity, a geographic data transformation method based on a multimodal
diffusion model. This method first uses a pre-trained text-to-image model to
align text, metadata, and building footprint data. An improved ControlNet
further integrates road network and land-use imagery, producing refined
building footprint data. Experiments across 22 global cities demonstrate that
ControlCity successfully simulates real urban building patterns, achieving
state-of-the-art performance. Specifically, our method achieves an average FID
score of 50.94, reducing error by 71.01% compared to leading methods, and a
MIoU score of 0.36, an improvement of 38.46%. Additionally, our model excels in
tasks like urban morphology transfer, zero-shot city generation, and spatial
data completeness assessment. In the zero-shot city task, our method accurately
predicts and generates similar urban structures, demonstrating strong
generalization. This study confirms the effectiveness of our approach in
generating urban building footprint data and capturing complex city
characteristics.

摘要：<paragraph>志工地理資訊 (VGI) 擁有豐富多樣性、龐大資料量、快速更新和多元來源，已成為地理空間資料的重要來源。然而，來自 OSM 等平台的 VGI 資料在不同資料類型中展現出顯著的品質異質性，特別是與都市建築資料相關。為了解決這個問題，我們提出一個多來源地理資料轉換解決方案，利用可取得且完整的 VGI 資料來協助產生都市建築足跡資料。我們也採用多模態資料產生架構來提升準確度。首先，我們導入一個用於建構「影像-文字-元資料-建築足跡」資料集的管道，主要基於道路網路資料，並由其他多模態資料補充。然後，我們提出 ControlCity，一種基於多模態擴散模型的地理資料轉換方法。此方法首先使用預先訓練好的文字轉影像模型來比對文字、元資料和建築足跡資料。改良後的 ControlNet 進一步整合道路網路和土地使用影像，產生精緻化的建築足跡資料。在 22 個全球城市進行的實驗證明，ControlCity 成功模擬了真實的都市建築模式，達到最先進的效能。具體來說，我們的模型平均 FID 分數為 50.94，與領先方法相比減少了 71.01% 的誤差，而 MIoU 分數為 0.36，提升了 38.46%。此外，我們的模型在都市形態轉換、零次學習城市產生和空間資料完整性評估等任務中表現出色。在零次學習城市任務中，我們的模型準確預測並產生類似的都市結構，展現出強大的泛化能力。這項研究證實了我們在產生都市建築足跡資料和擷取複雜城市特徵方面的成效。</paragraph>

##### **GeoBiked: A Dataset with Geometric Features and Automated Labeling Techniques to Enable Deep Generative Models in Engineering Design**
2409.17045v1 by Phillip Mueller, Sebastian Mueller, Lars Mikelsons

We provide a dataset for enabling Deep Generative Models (DGMs) in
engineering design and propose methods to automate data labeling by utilizing
large-scale foundation models. GeoBiked is curated to contain 4 355 bicycle
images, annotated with structural and technical features and is used to
investigate two automated labeling techniques: The utilization of consolidated
latent features (Hyperfeatures) from image-generation models to detect
geometric correspondences (e.g. the position of the wheel center) in structural
images and the generation of diverse text descriptions for structural images.
GPT-4o, a vision-language-model (VLM), is instructed to analyze images and
produce diverse descriptions aligned with the system-prompt. By representing
technical images as Diffusion-Hyperfeatures, drawing geometric correspondences
between them is possible. The detection accuracy of geometric points in unseen
samples is improved by presenting multiple annotated source images. GPT-4o has
sufficient capabilities to generate accurate descriptions of technical images.
Grounding the generation only on images leads to diverse descriptions but
causes hallucinations, while grounding it on categorical labels restricts the
diversity. Using both as input balances creativity and accuracy. Successfully
using Hyperfeatures for geometric correspondence suggests that this approach
can be used for general point-detection and annotation tasks in technical
images. Labeling such images with text descriptions using VLMs is possible, but
dependent on the models detection capabilities, careful prompt-engineering and
the selection of input information. Applying foundation models in engineering
design is largely unexplored. We aim to bridge this gap with a dataset to
explore training, finetuning and conditioning DGMs in this field and suggesting
approaches to bootstrap foundation models to process technical images.

摘要：<paragraph>我們提供了一個資料集，用於在工程設計中啟用深度生成模型 (DGM)，並提出透過利用大規模基礎模型自動化資料標籤的方法。GeoBiked 經過策展，包含 4,355 張自行車影像，並附有結構和技術特徵註解，且用於調查兩種自動化標籤技術：利用影像生成模型的整合潛在特徵（超特徵）來偵測結構影像中的幾何對應（例如車輪中心的位子），以及為結構影像產生多樣化的文字描述。GPT-4o 是一個視覺語言模型 (VLM)，指示要分析影像並產生與系統提示一致的多樣化描述。透過將技術影像表示為擴散超特徵，就可以繪製它們之間的幾何對應。透過呈現多個帶註解的來源影像，可以改善在未見樣本中幾何點的偵測準確度。GPT-4o 具有足夠的能力來產生技術影像的準確描述。僅根據影像進行基礎會產生多樣化的描述，但會產生幻覺，而根據分類標籤進行基礎則會限制多樣性。將兩者都用作輸入，可以平衡創造力和準確性。成功地將超特徵用於幾何對應，表示這種方法可用於技術影像中的一般點偵測和註解任務。使用 VLM 標籤此類影像的文字描述是可行的，但取決於模型的偵測能力、仔細的提示工程和輸入資訊的選擇。在工程設計中應用基礎模型在很大程度上尚未探索。我們旨在透過一個資料集來填補這個空白，以探索在這個領域訓練、微調和調整 DGM，並建議引導基礎模型處理技術影像的方法。</paragraph>

##### **How to Connect Speech Foundation Models and Large Language Models? What Matters and What Does Not**
2409.17044v1 by Francesco Verdini, Pierfrancesco Melucci, Stefano Perna, Francesco Cariaggi, Marco Gaido, Sara Papi, Szymon Mazurek, Marek Kasztelnik, Luisa Bentivogli, Sébastien Bratières, Paolo Merialdo, Simone Scardapane

The remarkable performance achieved by Large Language Models (LLM) has driven
research efforts to leverage them for a wide range of tasks and input
modalities. In speech-to-text (S2T) tasks, the emerging solution consists of
projecting the output of the encoder of a Speech Foundational Model (SFM) into
the LLM embedding space through an adapter module. However, no work has yet
investigated how much the downstream-task performance depends on each component
(SFM, adapter, LLM) nor whether the best design of the adapter depends on the
chosen SFM and LLM. To fill this gap, we evaluate the combination of 5 adapter
modules, 2 LLMs (Mistral and Llama), and 2 SFMs (Whisper and SeamlessM4T) on
two widespread S2T tasks, namely Automatic Speech Recognition and Speech
Translation. Our results demonstrate that the SFM plays a pivotal role in
downstream performance, while the adapter choice has moderate impact and
depends on the SFM and LLM.

摘要：大型語言模型 (LLM) 的卓越表現推動了研究工作，以利用它們來執行各種任務和輸入方式。在語音轉文字 (S2T) 任務中，新興的解決方案包括將語音基礎模型 (SFM) 編碼器的輸出通過適配器模組投影到 LLM 嵌入空間。然而，目前尚未有研究探討下游任務的表現有多依賴於每個元件 (SFM、適配器、LLM)，或適配器的最佳設計是否取決於所選的 SFM 和 LLM。為了填補此空白，我們在兩個廣泛的 S2T 任務上評估了 5 個適配器模組、2 個 LLM（Mistral 和 Llama）和 2 個 SFM（Whisper 和 SeamlessM4T）的組合，即自動語音辨識和語音翻譯。我們的結果表明，SFM 在下游表現中扮演著關鍵角色，而適配器的選擇具有中等影響，且取決於 SFM 和 LLM。

##### **Counterfactual Token Generation in Large Language Models**
2409.17027v1 by Ivi Chatzi, Nina Corvelo Benz, Eleni Straitouri, Stratis Tsirtsis, Manuel Gomez-Rodriguez

"Sure, I am happy to generate a story for you: Captain Lyra stood at the helm
of her trusty ship, the Maelstrom's Fury, gazing out at the endless sea. [...]
Lyra's eyes welled up with tears as she realized the bitter truth - she had
sacrificed everything for fleeting riches, and lost the love of her crew, her
family, and herself." Although this story, generated by a large language model,
is captivating, one may wonder -- how would the story have unfolded if the
model had chosen "Captain Maeve" as the protagonist instead? We cannot know.
State-of-the-art large language models are stateless -- they maintain no
internal memory or state. Given a prompt, they generate a sequence of tokens as
an output using an autoregressive process. As a consequence, they cannot reason
about counterfactual alternatives to tokens they have generated in the past. In
this work, our goal is to enhance them with this functionality. To this end, we
develop a causal model of token generation that builds upon the Gumbel-Max
structural causal model. Our model allows any large language model to perform
counterfactual token generation at almost no cost in comparison with vanilla
token generation, it is embarrassingly simple to implement, and it does not
require any fine-tuning nor prompt engineering. We implement our model on Llama
3 8B-instruct and conduct both qualitative and quantitative analyses of
counterfactually generated text. We conclude with a demonstrative application
of counterfactual token generation for bias detection, unveiling interesting
insights about the model of the world constructed by large language models.

摘要：「當然，我很樂意為您產生一個故事：萊拉船長站在她忠實的船隻，暴風之怒號的舵柄上，凝視著無盡的大海。[...]萊拉的雙眼噙滿淚水，她意識到了一個痛苦的真相——她為了稍縱即逝的財富犧牲了一切，失去了船員、家人和自己的愛。」儘管這個由大型語言模型產生的故事引人入勝，但人們可能會好奇——如果該模型選擇「梅芙船長」作為主角，故事會如何展開？我們不得而知。最先進的大型語言模型是無狀態的——它們不維護任何內部記憶或狀態。給定一個提示，它們會使用自迴歸過程生成一個序列的標記作為輸出。因此，它們無法對過去生成的標記的反事實替代方案進行推理。在這項工作中，我們的目標是增強它們的這項功能。為此，我們開發了一個因果標記生成模型，該模型建立在 Gumbel-Max 結構因果模型之上。我們的模型允許任何大型語言模型以幾乎沒有成本（與香草標記生成相比）執行反事實標記生成，其實現非常簡單，並且不需要任何微調或提示工程。我們在 Llama 3 8B-instruct 上實現了我們的模型，並對反事實生成的文本進行了定性和定量分析。我們以反事實標記生成的一個示範應用來檢測偏差作為結論，揭示了大型語言模型構建的世界模型的有趣見解。

##### **AI-Driven Risk-Aware Scheduling for Active Debris Removal Missions**
2409.17012v1 by Antoine Poupon, Hugo de Rohan Willner, Pierre Nikitits, Adam Abdin

The proliferation of debris in Low Earth Orbit (LEO) represents a significant
threat to space sustainability and spacecraft safety. Active Debris Removal
(ADR) has emerged as a promising approach to address this issue, utilising
Orbital Transfer Vehicles (OTVs) to facilitate debris deorbiting, thereby
reducing future collision risks. However, ADR missions are substantially
complex, necessitating accurate planning to make the missions economically
viable and technically effective. Moreover, these servicing missions require a
high level of autonomous capability to plan under evolving orbital conditions
and changing mission requirements. In this paper, an autonomous
decision-planning model based on Deep Reinforcement Learning (DRL) is developed
to train an OTV to plan optimal debris removal sequencing. It is shown that
using the proposed framework, the agent can find optimal mission plans and
learn to update the planning autonomously to include risk handling of debris
with high collision risk.

摘要：低地球軌道 (LEO) 中的碎片激增對太空永續性和太空船安全構成重大威脅。主動碎片移除 (ADR) 已成為解決此問題的一種有前景的方法，利用軌道轉移載具 (OTV) 促進碎片脫軌，從而降低未來的碰撞風險。然而，ADR 任務相當複雜，需要準確的規劃才能使任務在經濟上可行且在技術上有效。此外，這些維修任務需要高度的自主能力，以便在不斷變化的軌道條件和變化的任務需求下進行規劃。在本文中，開發了一個基於深度強化學習 (DRL) 的自主決策規劃模型，用於訓練 OTV 規劃最佳的碎片移除順序。結果表明，使用所提出的框架，代理可以找到最佳的任務計畫，並學會自主更新計畫，以納入對高碰撞風險碎片的風險處理。

##### **LLM-CARD: Towards a Description and Landscape of Large Language Models**
2409.17011v1 by Shengwei Tian, Lifeng Han, Erick Mendez Guzman, Goran Nenadic

With the rapid growth of the Natural Language Processing (NLP) field, a vast
variety of Large Language Models (LLMs) continue to emerge for diverse NLP
tasks. As an increasing number of papers are presented, researchers and
developers face the challenge of information overload. Thus, it is particularly
important to develop a system that can automatically extract and organise key
information about LLMs from academic papers (\textbf{LLM model card}). This
work is to develop such a pioneer system by using Named Entity Recognition
(\textbf{NER}) and Relation Extraction (\textbf{RE}) methods that automatically
extract key information about large language models from the papers, helping
researchers to efficiently access information about LLMs. These features
include model \textit{licence}, model \textit{name}, and model
\textit{application}. With these features, we can form a model card for each
paper. \textbf{Data-contribution} wise, 106 academic papers were processed by
defining three dictionaries - LLMs name, licence, and application. 11,051
sentences were extracted through dictionary lookup, and the dataset was
constructed through manual review of the final selection of 129 sentences that
have a link between the name and the licence, and 106 sentences that have a
link between the model name and the application.

摘要：隨著自然語言處理 (NLP) 領域的快速發展，各種大型語言模型 (LLM) 持續湧現，以執行多元的 NLP 任務。隨著發表論文數量日增，研究人員和開發人員面臨資訊過載的挑戰。因此，開發一個系統，能自動從學術論文中擷取和組織有關 LLM 的關鍵資訊（**LLM 模型卡**）特別重要。這項工作是要透過使用命名實體辨識（**NER**）和關係擷取（**RE**）方法，開發出這樣的先驅系統，從論文中自動擷取有關大型語言模型的關鍵資訊，協助研究人員有效存取有關 LLM 的資訊。這些功能包括模型**授權**、模型**名稱**和模型**應用**。有了這些功能，我們可以為每篇論文建立模型卡。**資料貢獻**方面，透過定義三個字典（LLM 名稱、授權和應用），處理了 106 篇學術論文。透過字典查詢擷取了 11,051 個句子，並透過手動檢閱最後選出的 129 個句子（名稱與授權之間有連結）和 106 個句子（模型名稱與應用之間有連結）來建構資料集。

##### **Models Can and Should Embrace the Communicative Nature of Human-Generated Math**
2409.17005v1 by Sasha Boguraev, Ben Lipkin, Leonie Weissweiler, Kyle Mahowald

Math is constructed by people for people: just as natural language corpora
reflect not just propositions but the communicative goals of language users,
the math data that models are trained on reflects not just idealized
mathematical entities but rich communicative intentions. While there are
important advantages to treating math in a purely symbolic manner, we here
hypothesize that there are benefits to treating math as situated linguistic
communication and that language models are well suited for this goal, in ways
that are not fully appreciated. We illustrate these points with two case
studies. First, we ran an experiment in which we found that language models
interpret the equals sign in a humanlike way -- generating systematically
different word problems for the same underlying equation arranged in different
ways. Second, we found that language models prefer proofs to be ordered in
naturalistic ways, even though other orders would be logically equivalent. We
advocate for AI systems that learn from and represent the communicative
intentions latent in human-generated math.

摘要：數學是由人為人建構的：就像自然語言語料庫不僅反映命題，也反映語言使用者的溝通目標，模型訓練的數學資料不僅反映理想化的數學實體，也反映豐富的溝通意圖。雖然以純粹的符號方式處理數學具有重要的優點，但我們在此假設將數學視為情境化的語言溝通是有好處的，並且語言模型非常適合這個目標，這點尚未被充分理解。我們用兩個案例研究來說明這些觀點。首先，我們進行了一個實驗，發現語言模型以類似人類的方式詮釋等號，針對以不同方式排列的相同基礎方程式，系統性地產生不同的文字題。其次，我們發現語言模型偏好以自然主義的方式排列證明，即使其他順序在邏輯上是等價的。我們提倡學習並表示人類產生的數學中潛在的溝通意圖的人工智慧系統。

##### **INT-FlashAttention: Enabling Flash Attention for INT8 Quantization**
2409.16997v2 by Shimao Chen, Zirui Liu, Zhiying Wu, Ce Zheng, Peizhuang Cong, Zihan Jiang, Yuhan Wu, Lei Su, Tong Yang

As the foundation of large language models (LLMs), self-attention module
faces the challenge of quadratic time and memory complexity with respect to
sequence length. FlashAttention accelerates attention computation and reduces
its memory usage by leveraging the GPU memory hierarchy. A promising research
direction is to integrate FlashAttention with quantization methods. This paper
introduces INT-FlashAttention, the first INT8 quantization architecture
compatible with the forward workflow of FlashAttention, which significantly
improves the inference speed of FlashAttention on Ampere GPUs. We implement our
INT-FlashAttention prototype with fully INT8 activations and general
matrix-multiplication (GEMM) kernels, making it the first attention operator
with fully INT8 input. As a general token-level post-training quantization
framework, INT-FlashAttention is also compatible with other data formats like
INT4, etc. Experimental results show INT-FlashAttention achieves 72% faster
inference speed and 82% smaller quantization error compared to standard
FlashAttention with FP16 and FP8 data format.

摘要：作為大型語言模型 (LLM) 的基礎，自注意力模組在序列長度方面面臨二次時間和記憶體複雜度的挑戰。FlashAttention 透過利用 GPU 記憶體階層來加速注意力計算並減少其記憶體使用量。一個有前途的研究方向是將 FlashAttention 與量化方法整合在一起。本文介紹 INT-FlashAttention，這是第一個與 FlashAttention 的前向工作流程相容的 INT8 量化架構，它顯著提升了 FlashAttention 在 Ampere GPU 上的推論速度。我們實作了具有完整 INT8 啟用和一般矩陣乘法 (GEMM) 核心之 INT-FlashAttention 原型，使其成為第一個具有完整 INT8 輸入的注意力運算子。作為一個通用的標記層級後訓練量化架構，INT-FlashAttention 也與其他資料格式相容，例如 INT4 等。實驗結果顯示，與具有 FP16 和 FP8 資料格式的標準 FlashAttention 相比，INT-FlashAttention 的推論速度快了 72%，量化誤差小了 82%。

##### **Harnessing Diversity for Important Data Selection in Pretraining Large Language Models**
2409.16986v1 by Chi Zhang, Huaping Zhong, Kuan Zhang, Chengliang Chai, Rui Wang, Xinlin Zhuang, Tianyi Bai, Jiantao Qiu, Lei Cao, Ye Yuan, Guoren Wang, Conghui He

Data selection is of great significance in pre-training large language
models, given the variation in quality within the large-scale available
training corpora. To achieve this, researchers are currently investigating the
use of data influence to measure the importance of data instances, $i.e.,$ a
high influence score indicates that incorporating this instance to the training
set is likely to enhance the model performance. Consequently, they select the
top-$k$ instances with the highest scores. However, this approach has several
limitations. (1) Computing the influence of all available data is
time-consuming. (2) The selected data instances are not diverse enough, which
may hinder the pre-trained model's ability to generalize effectively to various
downstream tasks. In this paper, we introduce \texttt{Quad}, a data selection
approach that considers both quality and diversity by using data influence to
achieve state-of-the-art pre-training results. In particular, noting that
attention layers capture extensive semantic details, we have adapted the
accelerated $iHVP$ computation methods for attention layers, enhancing our
ability to evaluate the influence of data, $i.e.,$ its quality. For the
diversity, \texttt{Quad} clusters the dataset into similar data instances
within each cluster and diverse instances across different clusters. For each
cluster, if we opt to select data from it, we take some samples to evaluate the
influence to prevent processing all instances. To determine which clusters to
select, we utilize the classic Multi-Armed Bandit method, treating each cluster
as an arm. This approach favors clusters with highly influential instances
(ensuring high quality) or clusters that have been selected less frequently
(ensuring diversity), thereby well balancing between quality and diversity.

摘要：<paragraph>在預訓練大型語言模型時，由於大型可用訓練語料庫中的品質差異，資料選擇非常重要。為了達成此目的，研究人員目前正在研究使用資料影響力來衡量資料實例的重要程度，$i.e.,$ 高影響力分數表示將此實例納入訓練集可能會提升模型效能。因此，他們會選出分數最高的前 $k$ 個實例。然而，此方法有幾個限制。(1) 計算所有可用資料的影響力很耗時。(2) 選出的資料實例不夠多元，這可能會妨礙預訓練模型有效地對各種下游任務進行概化。在本文中，我們介紹了 \texttt{Quad}，這是一種資料選擇方法，透過使用資料影響力來兼顧品質和多元性，以達成最先進的預訓練結果。特別要注意的是，注意力層會擷取廣泛的語義細節，我們已針對注意力層調整加速的 $iHVP$ 計算方法，增強我們評估資料影響力（即其品質）的能力。對於多元性，\texttt{Quad} 將資料集分群為每個群集內部相似的資料實例，以及不同群集之間不同的實例。對於每個群集，如果我們選擇從中選取資料，我們會取得一些樣本來評估影響力，以避免處理所有實例。為了決定要選取哪些群集，我們利用經典的多重機率賭徒法，將每個群集視為一個機率。此方法偏好具有高影響力實例的群集（確保高品質）或較少被選取的群集（確保多元性），從而很好地平衡品質和多元性。</paragraph>

##### **AXCEL: Automated eXplainable Consistency Evaluation using LLMs**
2409.16984v1 by P Aditya Sreekar, Sahil Verma, Suransh Chopra, Sarik Ghazarian, Abhishek Persad, Narayanan Sadagopan

Large Language Models (LLMs) are widely used in both industry and academia
for various tasks, yet evaluating the consistency of generated text responses
continues to be a challenge. Traditional metrics like ROUGE and BLEU show a
weak correlation with human judgment. More sophisticated metrics using Natural
Language Inference (NLI) have shown improved correlations but are complex to
implement, require domain-specific training due to poor cross-domain
generalization, and lack explainability. More recently, prompt-based metrics
using LLMs as evaluators have emerged; while they are easier to implement, they
still lack explainability and depend on task-specific prompts, which limits
their generalizability. This work introduces Automated eXplainable Consistency
Evaluation using LLMs (AXCEL), a prompt-based consistency metric which offers
explanations for the consistency scores by providing detailed reasoning and
pinpointing inconsistent text spans. AXCEL is also a generalizable metric which
can be adopted to multiple tasks without changing the prompt. AXCEL outperforms
both non-prompt and prompt-based state-of-the-art (SOTA) metrics in detecting
inconsistencies across summarization by 8.7%, free text generation by 6.2%, and
data-to-text conversion tasks by 29.4%. We also evaluate the influence of
underlying LLMs on prompt based metric performance and recalibrate the SOTA
prompt-based metrics with the latest LLMs for fair comparison. Further, we show
that AXCEL demonstrates strong performance using open source LLMs.

摘要：大型語言模型 (LLM) 廣泛用於產業和學術界
執行各種任務，然而評估所產生文字回應的一致性
仍然是一項挑戰。傳統指標，例如 ROUGE 和 BLEU，顯示出
與人類判斷的相關性較弱。使用自然語言推論 (NLI) 的更精密的指標顯示出改善的相關性，但實作複雜，由於跨領域概化性差，需要特定領域的訓練，並且缺乏可解釋性。最近，使用 LLM 作為評估器的提示式指標已經出現；雖然它們更容易實作，但它們仍然缺乏可解釋性，並且依賴於特定任務的提示，這限制了它們的概化性。這項工作引入了使用 LLM 的自動化可解釋一致性評估 (AXCEL)，這是一個基於提示的一致性指標，它透過提供詳細的推理和精確定位不一致的文字範圍，為一致性評分提供解釋。AXCEL 也是一個可概化的指標，可以在不更改提示的情況下採用於多項任務。AXCEL 在檢測摘要的不一致性方面優於非提示式和提示式最先進 (SOTA) 指標 8.7%，自由文字產生 6.2%，以及資料到文字轉換任務 29.4%。我們也評估了底層 LLM 對基於提示的指標效能的影響，並使用最新的 LLM 重新校準 SOTA 基於提示的指標以進行公平比較。此外，我們展示了 AXCEL 使用開源 LLM 具有強大的效能。

##### **Decoding Large-Language Models: A Systematic Overview of Socio-Technical Impacts, Constraints, and Emerging Questions**
2409.16974v1 by Zeyneb N. Kaya, Souvick Ghosh

There have been rapid advancements in the capabilities of large language
models (LLMs) in recent years, greatly revolutionizing the field of natural
language processing (NLP) and artificial intelligence (AI) to understand and
interact with human language. Therefore, in this work, we conduct a systematic
investigation of the literature to identify the prominent themes and directions
of LLM developments, impacts, and limitations. Our findings illustrate the
aims, methodologies, limitations, and future directions of LLM research. It
includes responsible development considerations, algorithmic improvements,
ethical challenges, and societal implications of LLM development. Overall, this
paper provides a rigorous and comprehensive overview of current research in LLM
and identifies potential directions for future development. The article
highlights the application areas that could have a positive impact on society
along with the ethical considerations.

摘要：近年來，大型語言模型 (LLM) 的能力突飛猛進，極大地革新了自然語言處理 (NLP) 和人工智慧 (AI) 理解和互動人類語言的領域。因此，在本文中，我們對文獻進行系統性的探討，以找出 LLM 發展、影響和限制的顯著主題和方向。我們的研究結果說明了 LLM 研究的目的、方法、限制和未來方向。它包括負責任的開發考量、演算法的改進、倫理挑戰和 LLM 發展的社會影響。總體而言，本文提供了 LLM 當前研究的嚴謹且全面的概述，並找出未來發展的潛在方向。本文重點介紹了可能對社會產生正面影響的應用領域，以及倫理考量。

##### **Adaptive Self-Supervised Learning Strategies for Dynamic On-Device LLM Personalization**
2409.16973v1 by Rafael Mendoza, Isabella Cruz, Richard Liu, Aarav Deshmukh, David Williams, Jesscia Peng, Rohan Iyer

Large language models (LLMs) have revolutionized how we interact with
technology, but their personalization to individual user preferences remains a
significant challenge, particularly in on-device applications. Traditional
methods often depend heavily on labeled datasets and can be resource-intensive.
To address these issues, we present Adaptive Self-Supervised Learning
Strategies (ASLS), which utilizes self-supervised learning techniques to
personalize LLMs dynamically. The framework comprises a user profiling layer
for collecting interaction data and a neural adaptation layer for real-time
model fine-tuning. This innovative approach enables continuous learning from
user feedback, allowing the model to generate responses that align closely with
user-specific contexts. The adaptive mechanisms of ASLS minimize computational
demands and enhance personalization efficiency. Experimental results across
various user scenarios illustrate the superior performance of ASLS in boosting
user engagement and satisfaction, highlighting its potential to redefine LLMs
as highly responsive and context-aware systems on-device.

摘要：大型語言模型 (LLM) 徹底改變了我們與科技互動的方式，但它們的個人化以適應個別使用者的偏好仍然是一項重大的挑戰，特別是在裝置應用程式中。傳統方法通常高度依賴標籤資料集，且可能耗費大量資源。為了解決這些問題，我們提出自適應自我監督學習策略 (ASLS)，它利用自我監督學習技術來動態地個人化 LLM。該架構包含一個用於收集互動資料的使用者設定檔層，以及一個用於即時模型微調的神經適應層。這種創新的方法能從使用者的回饋中持續學習，讓模型能夠產生與使用者特定脈絡緊密結合的回應。ASLS 的自適應機制可將運算需求降到最低，並提升個人化效率。在各種使用者情境中的實驗結果說明了 ASLS 在提升使用者參與度和滿意度方面的卓越效能，突顯了它在將 LLM 重新定義為高度回應且具備脈絡感知能力的裝置系統方面的潛力。

##### **Weighted Cross-entropy for Low-Resource Languages in Multilingual Speech Recognition**
2409.16954v1 by Andrés Piñeiro-Martín, Carmen García-Mateo, Laura Docío-Fernández, María del Carmen López-Pérez, Georg Rehm

This paper addresses the challenge of integrating low-resource languages into
multilingual automatic speech recognition (ASR) systems. We introduce a novel
application of weighted cross-entropy, typically used for unbalanced datasets,
to facilitate the integration of low-resource languages into pre-trained
multilingual ASR models within the context of continual multilingual learning.
We fine-tune the Whisper multilingual ASR model on five high-resource languages
and one low-resource language, employing language-weighted dynamic
cross-entropy and data augmentation. The results show a remarkable 6.69% word
error rate (WER) reduction for the low-resource language compared to the
fine-tuned model without applying our approach, and a 48.86% WER reduction
compared to the original Whisper model. In addition, our approach yields an
average WER reduction of 3.29% across the six languages, showing no degradation
for the high-resource languages.

摘要：本文探討了將低資源語言整合至多語言自動語音辨識 (ASR) 系統的挑戰。我們引進了加權交叉熵的新應用，通常用於不平衡的資料集，以促進在持續多語言學習的脈絡中，將低資源語言整合至預先訓練的多語言 ASR 模型中。我們微調了 Whisper 多語言 ASR 模型，使用五種高資源語言和一種低資源語言，採用語言加權動態交叉熵和資料擴充。結果顯示，與未套用我們方法的微調模型相比，低資源語言的字元錯誤率 (WER) 降低了 6.69%，與原始 Whisper 模型相比，WER 降低了 48.86%。此外，我們的做法對六種語言的平均 WER 降低了 3.29%，顯示對高資源語言沒有造成影響。

##### **Dynamic Obstacle Avoidance through Uncertainty-Based Adaptive Planning with Diffusion**
2409.16950v1 by Vineet Punyamoorty, Pascal Jutras-Dubé, Ruqi Zhang, Vaneet Aggarwal, Damon Conover, Aniket Bera

By framing reinforcement learning as a sequence modeling problem, recent work
has enabled the use of generative models, such as diffusion models, for
planning. While these models are effective in predicting long-horizon state
trajectories in deterministic environments, they face challenges in dynamic
settings with moving obstacles. Effective collision avoidance demands
continuous monitoring and adaptive decision-making. While replanning at every
timestep could ensure safety, it introduces substantial computational overhead
due to the repetitive prediction of overlapping state sequences -- a process
that is particularly costly with diffusion models, known for their intensive
iterative sampling procedure. We propose an adaptive generative planning
approach that dynamically adjusts replanning frequency based on the uncertainty
of action predictions. Our method minimizes the need for frequent,
computationally expensive, and redundant replanning while maintaining robust
collision avoidance performance. In experiments, we obtain a 13.5% increase in
the mean trajectory length and a 12.7% increase in mean reward over
long-horizon planning, indicating a reduction in collision rates and an
improved ability to navigate the environment safely.

摘要：藉由將強化學習建構為序列建模問題，近期研究已能使用生成模型，例如擴散模型，進行規劃。儘管這些模型有效預測確定性環境中的長時程狀態軌跡，但在具有移動障礙物的動態設定中，它們面臨挑戰。有效的碰撞避免需要持續監控和適應性決策制定。儘管在每個時間步長重新規劃可以確保安全性，但由於重複預測重疊的狀態序列，因此會產生大量的運算負擔，而這種程序對於以其密集迭代採樣程序而聞名的擴散模型來說特別昂貴。我們提出了一種適應性生成規劃方法，該方法根據動作預測的不確定性動態調整重新規劃頻率。我們的模型將頻繁、運算成本高且重複的重新規劃需求降至最低，同時維持穩健的碰撞避免效能。在實驗中，我們在長期規劃中獲得平均軌跡長度增加 13.5% 和平均回報增加 12.7%，表示碰撞率降低，以及在環境中安全導航的能力提升。

##### **Go-SLAM: Grounded Object Segmentation and Localization with Gaussian Splatting SLAM**
2409.16944v1 by Phu Pham, Dipam Patel, Damon Conover, Aniket Bera

We introduce Go-SLAM, a novel framework that utilizes 3D Gaussian Splatting
SLAM to reconstruct dynamic environments while embedding object-level
information within the scene representations. This framework employs advanced
object segmentation techniques, assigning a unique identifier to each Gaussian
splat that corresponds to the object it represents. Consequently, our system
facilitates open-vocabulary querying, allowing users to locate objects using
natural language descriptions. Furthermore, the framework features an optimal
path generation module that calculates efficient navigation paths for robots
toward queried objects, considering obstacles and environmental uncertainties.
Comprehensive evaluations in various scene settings demonstrate the
effectiveness of our approach in delivering high-fidelity scene
reconstructions, precise object segmentation, flexible object querying, and
efficient robot path planning. This work represents an additional step forward
in bridging the gap between 3D scene reconstruction, semantic object
understanding, and real-time environment interactions.

摘要：我們介紹 Go-SLAM，一個利用 3D 高斯潑濺 SLAM 重建動態環境，同時將物件層級資訊嵌入場景表示中的新穎架構。此架構採用進階物件分割技術，為每個高斯潑濺分配一個獨特識別碼，對應於它所代表的物件。因此，我們的系統促進開放式詞彙查詢，讓使用者能使用自然語言描述來定位物件。此外，此架構具備最佳路徑產生模組，可計算機器人前往查詢物件的有效導航路徑，考量障礙物和環境不確定性。在各種場景設定中的全面評估證明了我們方法在提供高保真場景重建、精確物件分割、彈性物件查詢和有效機器人路徑規劃方面的效能。這項工作代表了在 3D 場景重建、語意物件理解和即時環境互動之間搭起橋樑的額外進展。

##### **Generative Object Insertion in Gaussian Splatting with a Multi-View Diffusion Model**
2409.16938v1 by Hongliang Zhong, Can Wang, Jingbo Zhang, Jing Liao

Generating and inserting new objects into 3D content is a compelling approach
for achieving versatile scene recreation. Existing methods, which rely on SDS
optimization or single-view inpainting, often struggle to produce high-quality
results. To address this, we propose a novel method for object insertion in 3D
content represented by Gaussian Splatting. Our approach introduces a multi-view
diffusion model, dubbed MVInpainter, which is built upon a pre-trained stable
video diffusion model to facilitate view-consistent object inpainting. Within
MVInpainter, we incorporate a ControlNet-based conditional injection module to
enable controlled and more predictable multi-view generation. After generating
the multi-view inpainted results, we further propose a mask-aware 3D
reconstruction technique to refine Gaussian Splatting reconstruction from these
sparse inpainted views. By leveraging these fabricate techniques, our approach
yields diverse results, ensures view-consistent and harmonious insertions, and
produces better object quality. Extensive experiments demonstrate that our
approach outperforms existing methods.

摘要：生成和插入新物件到 3D 內容中，是達成多功能場景重現的引人入勝方法。現有方法依賴於 SDS 最佳化或單視點繪製，通常難以產生高品質的結果。為了解決這個問題，我們提出一個創新的方法，用於在由高斯噴繪表示的 3D 內容中插入物件。我們的做法引進一個多視點擴散模型，稱為 MVInpainter，它建構於預先訓練的穩定影片擴散模型之上，以促進視點一致的物件繪製。在 MVInpainter 內，我們整合一個基於 ControlNet 的條件式注入模組，以啟用受控且更可預測的多視點生成。在產生多視點繪製結果後，我們進一步提出一個具備遮罩感知的 3D 重建技術，從這些稀疏繪製視點中，改善高斯噴繪重建。透過利用這些製造技術，我們的做法產生多樣化的結果，確保視點一致且和諧的插入，並產生更好的物件品質。廣泛的實驗證明，我們的做法優於現有方法。

##### **Semi-Supervised Cognitive State Classification from Speech with Multi-View Pseudo-Labeling**
2409.16937v1 by Yuanchao Li, Zixing Zhang, Jing Han, Peter Bell, Catherine Lai

The lack of labeled data is a common challenge in speech classification
tasks, particularly those requiring extensive subjective assessment, such as
cognitive state classification. In this work, we propose a Semi-Supervised
Learning (SSL) framework, introducing a novel multi-view pseudo-labeling method
that leverages both acoustic and linguistic characteristics to select the most
confident data for training the classification model. Acoustically, unlabeled
data are compared to labeled data using the Frechet audio distance, calculated
from embeddings generated by multiple audio encoders. Linguistically, large
language models are prompted to revise automatic speech recognition
transcriptions and predict labels based on our proposed task-specific
knowledge. High-confidence data are identified when pseudo-labels from both
sources align, while mismatches are treated as low-confidence data. A bimodal
classifier is then trained to iteratively label the low-confidence data until a
predefined criterion is met. We evaluate our SSL framework on emotion
recognition and dementia detection tasks. Experimental results demonstrate that
our method achieves competitive performance compared to fully supervised
learning using only 30% of the labeled data and significantly outperforms two
selected baselines.

摘要：標籤資料的缺乏是語音分類任務中常見的挑戰，特別是需要廣泛主觀評估的任務，例如認知狀態分類。在這項工作中，我們提出一個半監督式學習 (SSL) 架構，引進一種新穎的多視角偽標籤方法，該方法利用聲學和語言特徵來選擇最可靠的資料以訓練分類模型。在聲學上，使用由多個音訊編碼器產生的嵌入計算的 Frechet 音訊距離，將未標籤資料與標籤資料進行比較。在語言學上，提示大型語言模型修改自動語音辨識轉錄，並根據我們提出的特定任務知識預測標籤。當來自兩個來源的偽標籤對齊時，會識別出高可靠性資料，而錯配則視為低可靠性資料。然後訓練一個雙峰分類器，以反覆標籤低可靠性資料，直到符合預定義的準則。我們在情緒辨識和失智症檢測任務上評估我們的 SSL 架構。實驗結果表明，與僅使用 30% 標籤資料的全監督式學習相比，我們的方法獲得了具有競爭力的效能，並且明顯優於兩個選定的基準。

##### **Investigating OCR-Sensitive Neurons to Improve Entity Recognition in Historical Documents**
2409.16934v2 by Emanuela Boros, Maud Ehrmann

This paper investigates the presence of OCR-sensitive neurons within the
Transformer architecture and their influence on named entity recognition (NER)
performance on historical documents. By analysing neuron activation patterns in
response to clean and noisy text inputs, we identify and then neutralise
OCR-sensitive neurons to improve model performance. Based on two open access
large language models (Llama2 and Mistral), experiments demonstrate the
existence of OCR-sensitive regions and show improvements in NER performance on
historical newspapers and classical commentaries, highlighting the potential of
targeted neuron modulation to improve models' performance on noisy text.

摘要：本文探討了 Transformer 架構中 OCR 敏感神經元的存在，以及它們對歷史文件中的命名實體辨識 (NER) 效能的影響。透過分析神經元在回應乾淨和有雜訊的文字輸入時的活化模式，我們找出 OCR 敏感神經元，然後將其無效化，以提升模型效能。根據兩個開放取用的大型語言模型 (Llama2 和 Mistral)，實驗證實了 OCR 敏感區域的存在，並顯示了歷史報紙和古典評論中的 NER 效能提升，突顯了目標神經元調變在提升模型對有雜訊文字的效能上的潛力。

##### **Quantum-Classical Sentiment Analysis**
2409.16928v1 by Mario Bifulco, Luca Roversi

In this study, we initially investigate the application of a hybrid
classical-quantum classifier (HCQC) for sentiment analysis, comparing its
performance against the classical CPLEX classifier and the Transformer
architecture. Our findings indicate that while the HCQC underperforms relative
to the Transformer in terms of classification accuracy, but it requires
significantly less time to converge to a reasonably good approximate solution.
This experiment also reveals a critical bottleneck in the HCQC, whose
architecture is partially undisclosed by the D-Wave property. To address this
limitation, we propose a novel algorithm based on the algebraic decomposition
of QUBO models, which enhances the time the quantum processing unit can
allocate to problem-solving tasks.

摘要：在本研究中，我们最初调查了混合经典量子分类器 (HCQC) 在情感分析中的应用，将其性能与经典 CPLEX 分类器和 Transformer 架构进行了比较。我们的研究结果表明，虽然 HCQC 在分类准确性方面不如 Transformer，但它需要花费明显更少的时间来收敛到一个相当好的近似解。此实验还揭示了 HCQC 中的一个关键瓶颈，其架构部分由 D-Wave 属性未公开。为了解决这一限制，我们提出了一种基于 QUBO 模型代数分解的新算法，该算法可以延长量子处理单元分配给问题解决任务的时间。

##### **Cross-lingual Speech Emotion Recognition: Humans vs. Self-Supervised Models**
2409.16920v1 by Zhichen Han, Tianqi Geng, Hui Feng, Jiahong Yuan, Korin Richmond, Yuanchao Li

Utilizing Self-Supervised Learning (SSL) models for Speech Emotion
Recognition (SER) has proven effective, yet limited research has explored
cross-lingual scenarios. This study presents a comparative analysis between
human performance and SSL models, beginning with a layer-wise analysis and an
exploration of parameter-efficient fine-tuning strategies in monolingual,
cross-lingual, and transfer learning contexts. We further compare the SER
ability of models and humans at both utterance- and segment-levels.
Additionally, we investigate the impact of dialect on cross-lingual SER through
human evaluation. Our findings reveal that models, with appropriate knowledge
transfer, can adapt to the target language and achieve performance comparable
to native speakers. We also demonstrate the significant effect of dialect on
SER for individuals without prior linguistic and paralinguistic background.
Moreover, both humans and models exhibit distinct behaviors across different
emotions. These results offer new insights into the cross-lingual SER
capabilities of SSL models, underscoring both their similarities to and
differences from human emotion perception.

摘要：利用自我監督學習 (SSL) 模型進行語音情緒辨識 (SER) 已被證實有效，但對於跨語言情境的探索研究有限。本研究提供人類表現與 SSL 模型之間的比較分析，從逐層分析開始，並探討單語、跨語言和遷移學習情境中的參數有效微調策略。我們進一步比較模型與人類在語句和區段層級的 SER 能力。此外，我們透過人類評估探討方言對跨語言 SER 的影響。我們的發現顯示，具備適當知識轉移的模型可以適應目標語言，並達成與母語人士相當的表現。我們也證實方言對沒有語言學和副語言學背景的個人 SER 有顯著影響。此外，人類和模型在不同情緒中展現出不同的行為。這些結果提供新的見解，了解 SSL 模型的跨語言 SER 能力，強調它們與人類情緒感知的相似性和差異性。

##### **Zero-Shot Detection of LLM-Generated Text using Token Cohesiveness**
2409.16914v1 by Shixuan Ma, Quan Wang

The increasing capability and widespread usage of large language models
(LLMs) highlight the desirability of automatic detection of LLM-generated text.
Zero-shot detectors, due to their training-free nature, have received
considerable attention and notable success. In this paper, we identify a new
feature, token cohesiveness, that is useful for zero-shot detection, and we
demonstrate that LLM-generated text tends to exhibit higher token cohesiveness
than human-written text. Based on this observation, we devise TOCSIN, a generic
dual-channel detection paradigm that uses token cohesiveness as a plug-and-play
module to improve existing zero-shot detectors. To calculate token
cohesiveness, TOCSIN only requires a few rounds of random token deletion and
semantic difference measurement, making it particularly suitable for a
practical black-box setting where the source model used for generation is not
accessible. Extensive experiments with four state-of-the-art base detectors on
various datasets, source models, and evaluation settings demonstrate the
effectiveness and generality of the proposed approach. Code available at:
\url{https://github.com/Shixuan-Ma/TOCSIN}.

摘要：隨著大型語言模型 (LLM) 能力的提升和廣泛使用，自動偵測 LLM 生成的文字的需求也越來越高。零次學習偵測器由於無需訓練，因此備受關注，並取得顯著的成功。在本文中，我們找出了一個新的特徵，即「詞彙凝聚力」，它對於零次學習偵測很有用，並且我們證明了 LLM 生成的文字往往比人類寫的文字展現出更高的詞彙凝聚力。基於這個觀察，我們設計了 TOCSIN，這是一個通用的雙通道偵測範例，它使用詞彙凝聚力作為即插即用的模組，以改善現有的零次學習偵測器。為了計算詞彙凝聚力，TOCSIN 只需要進行幾輪隨機詞彙刪除和語意差異測量，這使得它特別適合在無法取得用於生成的原始模型的實際黑盒設定中使用。在各種資料集、原始模型和評估設定上使用四個最先進的基本偵測器進行的廣泛實驗證明了所提出方法的有效性和普遍性。程式碼可於以下網址取得：\url{https://github.com/Shixuan-Ma/TOCSIN}。

##### **Tell Me What You Don't Know: Enhancing Refusal Capabilities of Role-Playing Agents via Representation Space Analysis and Editing**
2409.16913v1 by Wenhao Liu, Siyu An, Junru Lu, Muling Wu, Tianlong Li, Xiaohua Wang, Xiaoqing Zheng, Di Yin, Xing Sun, Xuanjing Huang

Role-Playing Agents (RPAs) have shown remarkable performance in various
applications, yet they often struggle to recognize and appropriately respond to
hard queries that conflict with their role-play knowledge. To investigate RPAs'
performance when faced with different types of conflicting requests, we develop
an evaluation benchmark that includes contextual knowledge conflicting
requests, parametric knowledge conflicting requests, and non-conflicting
requests to assess RPAs' ability to identify conflicts and refuse to answer
appropriately without over-refusing. Through extensive evaluation, we find that
most RPAs behave significant performance gaps toward different conflict
requests. To elucidate the reasons, we conduct an in-depth representation-level
analysis of RPAs under various conflict scenarios. Our findings reveal the
existence of rejection regions and direct response regions within the model's
forwarding representation, and thus influence the RPA's final response
behavior. Therefore, we introduce a lightweight representation editing approach
that conveniently shifts conflicting requests to the rejection region, thereby
enhancing the model's refusal accuracy. The experimental results validate the
effectiveness of our editing method, improving RPAs' refusal ability of
conflicting requests while maintaining their general role-playing capabilities.

摘要：角色扮演代理（RPA）在各種應用中已展現出卓越的效能，但它們經常難以辨識並適當地回應與其角色扮演知識相衝突的困難查詢。為調查 RPA 在面對不同類型的衝突要求時的效能，我們開發了一個評估基準，其中包括情境知識衝突要求、參數知識衝突要求和非衝突要求，以評估 RPA 辨識衝突並適當地拒絕回答的能力，而不會過度拒絕。透過廣泛的評估，我們發現大多數 RPA 對不同的衝突要求表現出顯著的效能差距。為了闡明原因，我們對 RPA 在各種衝突情境下的表示層級進行深入分析。我們的研究結果揭示了模型轉發表示中拒絕區域和直接回應區域的存在，進而影響 RPA 的最終回應行為。因此，我們引入了一種輕量的表示編輯方法，可便利地將衝突要求轉移到拒絕區域，從而提高模型的拒絕準確度。實驗結果驗證了我們編輯方法的有效性，提升了 RPA 拒絕衝突要求的能力，同時維持其一般角色扮演能力。

##### **Pruning Multilingual Large Language Models for Multilingual Inference**
2409.16911v1 by Hwichan Kim, Jun Suzuki, Tosho Hirasawa, Mamoru Komachi

Multilingual large language models (MLLMs), trained on multilingual balanced
data, demonstrate better zero-shot learning performance in non-English
languages compared to large language models trained on English-dominant data.
However, the disparity in performance between English and non-English languages
remains a challenge yet to be fully addressed. A distinctive characteristic of
MLLMs is their high-quality translation capabilities, indicating an acquired
proficiency in aligning between languages. This study explores how to enhance
the zero-shot performance of MLLMs in non-English languages by leveraging their
alignment capability between English and non-English languages. To achieve
this, we first analyze the behavior of MLLMs when performing translation and
reveal that there are large magnitude features that play a critical role in the
translation process. Inspired by these findings, we retain the weights
associated with operations involving the large magnitude features and prune
other weights to force MLLMs to rely on these features for tasks beyond
translation. We empirically demonstrate that this pruning strategy can enhance
the MLLMs' performance in non-English language.

摘要：多語言大型語言模型 (MLLM) 在多語言平衡資料上訓練，相較於在英語主導資料上訓練的大型語言模型，在非英語語言中展現出更好的零次學習表現。然而，英語與非英語語言之間的表現差異仍是一個尚未完全解決的挑戰。MLLM 的一個顯著特徵是它們的高品質翻譯能力，這表示在語言之間取得一致性的能力。本研究探討如何透過利用 MLLM 在英語和非英語語言之間的一致性能力，來增強 MLLM 在非英語語言中的零次表現。為達成此目標，我們首先分析 MLLM 在執行翻譯時的行為，並揭示出有大量的特徵在翻譯過程中扮演關鍵角色。受到這些發現的啟發，我們保留與涉及大量特徵的操作相關的權重，並剪除其他權重，以強迫 MLLM 在超越翻譯的任務中依賴這些特徵。我們透過實證證明，此剪枝策略可以增強 MLLM 在非英語語言中的表現。

##### **Enhancing Temporal Sensitivity and Reasoning for Time-Sensitive Question Answering**
2409.16909v1 by Wanqi Yang, Yanda Li, Meng Fang, Ling Chen

Time-Sensitive Question Answering (TSQA) demands the effective utilization of
specific temporal contexts, encompassing multiple time-evolving facts, to
address time-sensitive questions. This necessitates not only the parsing of
temporal information within questions but also the identification and
understanding of time-evolving facts to generate accurate answers. However,
current large language models still have limited sensitivity to temporal
information and their inadequate temporal reasoning capabilities.In this paper,
we propose a novel framework that enhances temporal awareness and reasoning
through Temporal Information-Aware Embedding and Granular Contrastive
Reinforcement Learning. Experimental results on four TSQA datasets demonstrate
that our framework significantly outperforms existing LLMs in TSQA tasks,
marking a step forward in bridging the performance gap between machine and
human temporal understanding and reasoning.

摘要：時敏問題解答 (TSQA) 要求有效利用特定時間背景，包含多重時間演化事實，來回答時敏問題。這不僅需要解析問題中的時間資訊，也需要識別和理解時間演化事實，以產生準確的答案。然而，目前的巨量語言模型對於時間資訊的敏感度仍然有限，且其時間推理能力不足。在本文中，我們提出一個創新的框架，透過時間資訊感知嵌入和細粒對比強化學習來增強時間感知和推理。在四個 TSQA 資料集上的實驗結果顯示，我們的框架在 TSQA 任務中顯著優於現有的 LLM，標誌著在機器和人類時間理解與推理之間的效能差距中向前邁進一步。

##### **Discriminative Anchor Learning for Efficient Multi-view Clustering**
2409.16904v1 by Yalan Qin, Nan Pu, Hanzhou Wu, Nicu Sebe

Multi-view clustering aims to study the complementary information across
views and discover the underlying structure. For solving the relatively high
computational cost for the existing approaches, works based on anchor have been
presented recently. Even with acceptable clustering performance, these methods
tend to map the original representation from multiple views into a fixed shared
graph based on the original dataset. However, most studies ignore the
discriminative property of the learned anchors, which ruin the representation
capability of the built model. Moreover, the complementary information among
anchors across views is neglected to be ensured by simply learning the shared
anchor graph without considering the quality of view-specific anchors. In this
paper, we propose discriminative anchor learning for multi-view clustering
(DALMC) for handling the above issues. We learn discriminative view-specific
feature representations according to the original dataset and build anchors
from different views based on these representations, which increase the quality
of the shared anchor graph. The discriminative feature learning and consensus
anchor graph construction are integrated into a unified framework to improve
each other for realizing the refinement. The optimal anchors from multiple
views and the consensus anchor graph are learned with the orthogonal
constraints. We give an iterative algorithm to deal with the formulated
problem. Extensive experiments on different datasets show the effectiveness and
efficiency of our method compared with other methods.

摘要：多視圖聚類旨在研究跨視圖的互補資訊並發現底層結構。為了解決現有方法相對較高的運算成本，最近提出了基於錨點的運算。即使具有可接受的聚類效能，這些方法傾向於根據原始資料集將來自多個視圖的原始表示映射到一個固定的共享圖形中。然而，大多數研究忽視了學習錨點的判別特性，這會破壞構建模型的表示能力。此外，僅通過學習共享錨點圖形而不考慮特定於視圖的錨點的品質，會忽略跨視圖錨點之間的互補資訊。在本文中，我們提出用於多視圖聚類的判別錨點學習 (DALMC) 來處理上述問題。我們根據原始資料集學習判別的特定於視圖的特徵表示，並根據這些表示從不同的視圖構建錨點，這會提高共享錨點圖形的品質。判別特徵學習和共識錨點圖形構建整合到一個統一的架構中，以相互改進以實現精煉。來自多個視圖的最佳錨點和共識錨點圖形在正交約束下學習。我們給出一個反覆運算演算法來處理公式化的問題。在不同資料集上的大量實驗顯示了我們的方法與其他方法相比的有效性和效率。

##### **Towards Underwater Camouflaged Object Tracking: An Experimental Evaluation of SAM and SAM 2**
2409.16902v1 by Chunhui Zhang, Li Liu, Guanjie Huang, Hao Wen, Xi Zhou, Yanfeng Wang

Over the past decade, significant progress has been made in visual object
tracking, largely due to the availability of large-scale training datasets.
However, existing tracking datasets are primarily focused on open-air
scenarios, which greatly limits the development of object tracking in
underwater environments. To address this issue, we take a step forward by
proposing the first large-scale underwater camouflaged object tracking dataset,
namely UW-COT. Based on the proposed dataset, this paper presents an
experimental evaluation of several advanced visual object tracking methods and
the latest advancements in image and video segmentation. Specifically, we
compare the performance of the Segment Anything Model (SAM) and its updated
version, SAM 2, in challenging underwater environments. Our findings highlight
the improvements in SAM 2 over SAM, demonstrating its enhanced capability to
handle the complexities of underwater camouflaged objects. Compared to current
advanced visual object tracking methods, the latest video segmentation
foundation model SAM 2 also exhibits significant advantages, providing valuable
insights into the development of more effective tracking technologies for
underwater scenarios. The dataset will be accessible at
\color{magenta}{https://github.com/983632847/Awesome-Multimodal-Object-Tracking}.

摘要：在過去十年中，視覺物體追蹤取得了重大的進展，這在很大程度上要歸功於大規模訓練資料集的可用性。
然而，現有的追蹤資料集主要集中在露天場景，這極大地限制了水下環境中物體追蹤的發展。為了解決這個問題，我們提出第一個大規模水下偽裝物體追蹤資料集 UW-COT，向前邁出了一步。基於所提出的資料集，本文對幾種先進的視覺物體追蹤方法和影像和影片分割的最新進展進行了實驗評估。具體來說，我們比較了 Segment Anything Model (SAM) 及其更新版本 SAM 2 在具有挑戰性的水下環境中的效能。我們的研究結果突出了 SAM 2 相較於 SAM 的改進，證明了其增強了處理水下偽裝物體複雜性的能力。與目前先進的視覺物體追蹤方法相比，最新的影片分割基礎模型 SAM 2 也展現出顯著的優勢，為開發更有效的追蹤技術提供了寶貴的見解，以應對水下場景。該資料集可以在
\color{magenta}{https://github.com/983632847/Awesome-Multimodal-Object-Tracking} 取得。

##### **A Roadmap for Embodied and Social Grounding in LLMs**
2409.16900v1 by Sara Incao, Carlo Mazzola, Giulia Belgiovine, Alessandra Sciutti

The fusion of Large Language Models (LLMs) and robotic systems has led to a
transformative paradigm in the robotic field, offering unparalleled
capabilities not only in the communication domain but also in skills like
multimodal input handling, high-level reasoning, and plan generation. The
grounding of LLMs knowledge into the empirical world has been considered a
crucial pathway to exploit the efficiency of LLMs in robotics. Nevertheless,
connecting LLMs' representations to the external world with multimodal
approaches or with robots' bodies is not enough to let them understand the
meaning of the language they are manipulating. Taking inspiration from humans,
this work draws attention to three necessary elements for an agent to grasp and
experience the world. The roadmap for LLMs grounding is envisaged in an active
bodily system as the reference point for experiencing the environment, a
temporally structured experience for a coherent, self-related interaction with
the external world, and social skills to acquire a common-grounded shared
experience.

摘要：大型語言模型 (LLM) 和機器人系統的融合，在機器人領域中帶來了轉型的典範，不僅在溝通領域，在多模態輸入處理、高階推理和計畫生成等技能方面，也提供了無與倫比的能力。將 LLM 知識基礎化到經驗世界中，被認為是利用 LLM 在機器人技術中效率的一條關鍵途徑。儘管如此，將 LLM 的表示與外部世界連接起來，透過多模態方法或機器人的身體，還不足以讓它們理解所操作語言的含義。從人類身上汲取靈感，這項工作提請注意，一個代理人掌握和體驗世界所需的三個必要元素。LLM 基礎的路線圖，被設想在一個活躍的身體系統中，作為體驗環境的參考點，一個時間結構化的體驗，用於與外部世界的連貫、自我相關的互動，以及社會技能，以獲得一個共同基礎的共享體驗。

##### **AI-driven View Guidance System in Intra-cardiac Echocardiography Imaging**
2409.16898v1 by Jaeyoung Huh, Paul Klein, Gareth Funka-Lea, Puneet Sharma, Ankur Kapoor, Young-Ho Kim

Intra-cardiac Echocardiography (ICE) is a crucial imaging modality used in
electrophysiology (EP) and structural heart disease (SHD) interventions,
providing real-time, high-resolution views from within the heart. Despite its
advantages, effective manipulation of the ICE catheter requires significant
expertise, which can lead to inconsistent outcomes, particularly among less
experienced operators. To address this challenge, we propose an AI-driven
closed-loop view guidance system with human-in-the-loop feedback, designed to
assist users in navigating ICE imaging without requiring specialized knowledge.
Our method models the relative position and orientation vectors between
arbitrary views and clinically defined ICE views in a spatial coordinate
system, guiding users on how to manipulate the ICE catheter to transition from
the current view to the desired view over time. Operating in a closed-loop
configuration, the system continuously predicts and updates the necessary
catheter manipulations, ensuring seamless integration into existing clinical
workflows. The effectiveness of the proposed system is demonstrated through a
simulation-based evaluation, achieving an 89% success rate with the 6532 test
dataset, highlighting its potential to improve the accuracy and efficiency of
ICE imaging procedures.

摘要：心內超音波檢查 (ICE) 是一種關鍵的影像模式，用於電生理學 (EP) 和結構性心臟疾病 (SHD) 的介入治療，可從心臟內部提供即時、高解析度的影像。儘管有這些優點，但有效操作 ICE 導管需要相當的專業知識，這可能會導致不一致的結果，尤其是在經驗較少的操作員中。為了應對這個挑戰，我們提出一個以 AI 為驅動的閉環視圖引導系統，並結合人機環回饋，旨在協助使用者在不需要專業知識的情況下導航 ICE 影像。我們的模型模擬了任意視圖和臨床定義的 ICE 視圖之間的相對位置和方向向量，在一個空間座標系統中引導使用者如何操作 ICE 導管，以隨著時間從目前的視圖過渡到期望的視圖。在閉環配置中操作時，系統會持續預測和更新必要的導管操作，確保無縫整合到現有的臨床工作流程中。所提出的系統的有效性透過基於模擬的評估得到證明，在 6532 個測試資料集中達到 89% 的成功率，突顯其改善 ICE 影像程序的準確性和效率的潛力。

##### **Shifting from endangerment to rebirth in the Artificial Intelligence Age: An Ensemble Machine Learning Approach for Hawrami Text Classification**
2409.16884v1 by Aram Khaksar, Hossein Hassani

Hawrami, a dialect of Kurdish, is classified as an endangered language as it
suffers from the scarcity of data and the gradual loss of its speakers. Natural
Language Processing projects can be used to partially compensate for data
availability for endangered languages/dialects through a variety of approaches,
such as machine translation, language model building, and corpora development.
Similarly, NLP projects such as text classification are in language
documentation. Several text classification studies have been conducted for
Kurdish, but they were mainly dedicated to two particular dialects: Sorani
(Central Kurdish) and Kurmanji (Northern Kurdish). In this paper, we introduce
various text classification models using a dataset of 6,854 articles in Hawrami
labeled into 15 categories by two native speakers. We use K-nearest Neighbor
(KNN), Linear Support Vector Machine (Linear SVM), Logistic Regression (LR),
and Decision Tree (DT) to evaluate how well those methods perform the
classification task. The results indicate that the Linear SVM achieves a 96% of
accuracy and outperforms the other approaches.

摘要：霍拉米語是一種庫德語方言，由於資料稀少且講者逐漸減少，被歸類為瀕危語言。自然語言處理專案可透過各種方法，例如機器翻譯、語言模型建構和語料庫開發，來部分彌補瀕危語言/方言的資料取得問題。類似地，自然語言處理專案（例如文字分類）在語言文件編寫中也很重要。庫德語已經進行過多項文字分類研究，但主要針對兩種特定方言：索拉尼語（中央庫德語）和庫爾曼吉語（北庫德語）。在本文中，我們使用由兩位母語人士標記為 15 個類別的 6,854 篇霍拉米語文章的資料集，介紹各種文字分類模型。我們使用 K 最近鄰 (KNN)、線性支援向量機 (線性 SVM)、邏輯迴歸 (LR) 和決策樹 (DT) 來評估這些方法執行分類任務的表現如何。結果顯示線性 SVM 達到 96% 的準確度，並且優於其他方法。

##### **Revisiting Space Mission Planning: A Reinforcement Learning-Guided Approach for Multi-Debris Rendezvous**
2409.16882v1 by Agni Bandyopadhyay, Guenther Waxenegger-Wilfing

This research introduces a novel application of a masked Proximal Policy
Optimization (PPO) algorithm from the field of deep reinforcement learning
(RL), for determining the most efficient sequence of space debris visitation,
utilizing the Lambert solver as per Izzo's adaptation for individual
rendezvous. The aim is to optimize the sequence in which all the given debris
should be visited to get the least total time for rendezvous for the entire
mission. A neural network (NN) policy is developed, trained on simulated space
missions with varying debris fields. After training, the neural network
calculates approximately optimal paths using Izzo's adaptation of Lambert
maneuvers. Performance is evaluated against standard heuristics in mission
planning. The reinforcement learning approach demonstrates a significant
improvement in planning efficiency by optimizing the sequence for debris
rendezvous, reducing the total mission time by an average of approximately
{10.96\%} and {13.66\%} compared to the Genetic and Greedy algorithms,
respectively. The model on average identifies the most time-efficient sequence
for debris visitation across various simulated scenarios with the fastest
computational speed. This approach signifies a step forward in enhancing
mission planning strategies for space debris clearance.

摘要：这项研究引入了深度强化学习（RL）领域中一种掩蔽近端策略优化（PPO）算法的新应用，用于确定空间碎片访问的最有效顺序，利用 Lambert 求解器根据 Izzo 对个别会合的改编。目的是优化访问所有给定碎片的顺序，以获得整个任务会合的最小总时间。开发了一个神经网络（NN）策略，在具有不同碎片场的模拟太空任务中进行训练。训练后，神经网络使用 Izzo 对 Lambert 机动的改编计算近似最优路径。在任务规划中针对标准启发式方法评估性能。强化学习方法通过优化碎片会合的顺序，显着提高了规划效率，与遗传和贪婪算法相比，总任务时间平均减少了大约{10.96%}和{13.66%}。该模型平均确定了在各种模拟场景中碎片访问的最省时顺序，并具有最快的计算速度。这种方法标志着增强空间碎片清除任务规划策略向前迈进了一步。

##### **Automating Traffic Model Enhancement with AI Research Agent**
2409.16876v1 by Xusen Guo, Xinxi Yang, Mingxing Peng, Hongliang Lu, Meixin Zhu, Hai Yang

Developing efficient traffic models is essential for optimizing
transportation systems, yet current approaches remain time-intensive and
susceptible to human errors due to their reliance on manual processes.
Traditional workflows involve exhaustive literature reviews, formula
optimization, and iterative testing, leading to inefficiencies in research. In
response, we introduce the Traffic Research Agent (TR-Agent), an AI-driven
system designed to autonomously develop and refine traffic models through an
iterative, closed-loop process. Specifically, we divide the research pipeline
into four key stages: idea generation, theory formulation, theory evaluation,
and iterative optimization; and construct TR-Agent with four corresponding
modules: Idea Generator, Code Generator, Evaluator, and Analyzer. Working in
synergy, these modules retrieve knowledge from external resources, generate
novel ideas, implement and debug models, and finally assess them on the
evaluation datasets. Furthermore, the system continuously refines these models
based on iterative feedback, enhancing research efficiency and model
performance. Experimental results demonstrate that TR-Agent achieves
significant performance improvements across multiple traffic models, including
the Intelligent Driver Model (IDM) for car following, the MOBIL lane-changing
model, and the Lighthill-Whitham-Richards (LWR) traffic flow model.
Additionally, TR-Agent provides detailed explanations for its optimizations,
allowing researchers to verify and build upon its improvements easily. This
flexibility makes the framework a powerful tool for researchers in
transportation and beyond. To further support research and collaboration, we
have open-sourced both the code and data used in our experiments, facilitating
broader access and enabling continued advancements in the field.

摘要：<paragraph>開發有效的交通模型對於最佳化運輸系統至關重要，然而，目前的方法仍然十分耗時，且由於依賴手動流程，容易產生人為錯誤。傳統的工作流程涉及廣泛的文獻回顧、公式最佳化和反覆測試，導致研究效率低下。為了解決此問題，我們引入了交通研究代理（TR-Agent），這是一個由人工智慧驅動的系統，旨在透過反覆、閉環的流程自主開發和完善交通模型。具體來說，我們將研究流程劃分為四個關鍵階段：構想產生、理論制定、理論評估和反覆最佳化；並使用四個相應的模組構建 TR-Agent：構想產生器、程式碼產生器、評估器和分析器。這些模組協同工作，從外部資源中擷取知識、產生新穎的構想、實作和除錯模型，最後在評估資料集上評估它們。此外，系統會根據反覆的回饋持續精進這些模型，提升研究效率和模型效能。實驗結果證明，TR-Agent 在多個交通模型中均獲得顯著的效能提升，包括用於跟車的智慧駕駛模型（IDM）、MOBIL 變換車道模型和 Lighthill-Whitham-Richards（LWR）交通流模型。此外，TR-Agent 為其最佳化提供了詳細的說明，讓研究人員能夠輕鬆驗證和建構其改進成果。這種靈活性使這個架構成為交通運輸及其他領域研究人員強而有力的工具。為了進一步支持研究和合作，我們已開放我們實驗中使用的程式碼和資料，促進更廣泛的存取，並促成該領域的持續進步。</paragraph>

##### **Ethical and Scalable Automation: A Governance and Compliance Framework for Business Applications**
2409.16872v1 by Haocheng Lin

The popularisation of applying AI in businesses poses significant challenges
relating to ethical principles, governance, and legal compliance. Although
businesses have embedded AI into their day-to-day processes, they lack a
unified approach for mitigating its potential risks. This paper introduces a
framework ensuring that AI must be ethical, controllable, viable, and
desirable. Balancing these factors ensures the design of a framework that
addresses its trade-offs, such as balancing performance against explainability.
A successful framework provides practical advice for businesses to meet
regulatory requirements in sectors such as finance and healthcare, where it is
critical to comply with standards like GPDR and the EU AI Act. Different case
studies validate this framework by integrating AI in both academic and
practical environments. For instance, large language models are cost-effective
alternatives for generating synthetic opinions that emulate attitudes to
environmental issues. These case studies demonstrate how having a structured
framework could enhance transparency and maintain performance levels as shown
from the alignment between synthetic and expected distributions. This alignment
is quantified using metrics like Chi-test scores, normalized mutual
information, and Jaccard indexes. Future research should explore the
framework's empirical validation in diverse industrial settings further,
ensuring the model's scalability and adaptability.

摘要：隨著 AI 在企業中的普及，在道德原則、治理和法律合規方面帶來了重大的挑戰。儘管企業已將 AI 嵌入其日常流程，但他們缺乏統一的方法來減輕其潛在風險。本文介紹了一個框架，確保 AI 必須符合道德、可控、可行且合適。平衡這些因素可確保設計一個框架，以解決其權衡取捨，例如平衡效能和可解釋性。一個成功的框架為企業提供了實用的建議，以滿足金融和醫療保健等行業的法規要求，在這些行業中，遵守 GDPR 和歐盟 AI 法案等標準至關重要。不同的案例研究通過在學術和實務環境中整合 AI 來驗證這個框架。例如，大型語言模型是生成模擬對環境問題態度的合成意見的經濟有效替代方案。這些案例研究展示了擁有結構化框架如何增強透明度並維持效能水準，這從合成分佈和預期分佈之間的一致性中可以看出。這種一致性是使用卡方檢定分數、標準化互信息和傑卡德指數等指標量化的。未來的研究應進一步探討該框架在不同產業環境中的實證驗證，確保模型的可擴充性和適應性。

##### **Multi-objective Evolution of Heuristic Using Large Language Model**
2409.16867v1 by Shunyu Yao, Fei Liu, Xi Lin, Zhichao Lu, Zhenkun Wang, Qingfu Zhang

Heuristics are commonly used to tackle diverse search and optimization
problems. Design heuristics usually require tedious manual crafting with domain
knowledge. Recent works have incorporated large language models (LLMs) into
automatic heuristic search leveraging their powerful language and coding
capacity. However, existing research focuses on the optimal performance on the
target problem as the sole objective, neglecting other criteria such as
efficiency and scalability, which are vital in practice. To tackle this
challenge, we propose to model heuristic search as a multi-objective
optimization problem and consider introducing other practical criteria beyond
optimal performance. Due to the complexity of the search space, conventional
multi-objective optimization methods struggle to effectively handle
multi-objective heuristic search. We propose the first LLM-based
multi-objective heuristic search framework, Multi-objective Evolution of
Heuristic (MEoH), which integrates LLMs in a zero-shot manner to generate a
non-dominated set of heuristics to meet multiple design criteria. We design a
new dominance-dissimilarity mechanism for effective population management and
selection, which incorporates both code dissimilarity in the search space and
dominance in the objective space. MEoH is demonstrated in two well-known
combinatorial optimization problems: the online Bin Packing Problem (BPP) and
the Traveling Salesman Problem (TSP). Results indicate that a variety of elite
heuristics are automatically generated in a single run, offering more trade-off
options than existing methods. It successfully achieves competitive or superior
performance while improving efficiency up to 10 times. Moreover, we also
observe that the multi-objective search introduces novel insights into
heuristic design and leads to the discovery of diverse heuristics.

摘要：啟發式法通常用於解決各種搜尋和最佳化問題。設計啟發式法通常需要使用領域知識進行繁瑣的手動製作。最近的研究已將大型語言模型 (LLM) 納入自動啟發式搜尋中，以利用其強大的語言和編碼能力。然而，現有研究只關注目標問題的最佳效能，而忽略了其他標準，例如效率和可擴充性，這在實務上至關重要。為了應對這個挑戰，我們提出將啟發式搜尋建模為多目標最佳化問題，並考慮在最佳效能之外引入其他實用標準。由於搜尋空間的複雜性，傳統的多目標最佳化方法難以有效處理多目標啟發式搜尋。我們提出了第一個基於 LLM 的多目標啟發式搜尋架構，即啟發式多目標演化 (MEoH)，它以零次學習的方式整合 LLM，以產生一組非支配的啟發式法，以滿足多重設計標準。我們設計了一個新的支配相異性機制，用於有效的人口管理和選擇，它結合了搜尋空間中的程式碼相異性和目標空間中的支配性。MEoH 在兩個著名的組合最佳化問題中得到證明：線上二維 bin 分割問題 (BPP) 和旅行推銷員問題 (TSP)。結果表明，在單次執行中自動產生了各種精英啟發式法，提供了比現有方法更多權衡選項。它成功地達到了競爭性或優越的效能，同時將效率提升了 10 倍。此外，我們還觀察到，多目標搜尋為啟發式設計引入了新的見解，並導致了各種啟發式法的發現。

##### **The Role of Language Models in Modern Healthcare: A Comprehensive Review**
2409.16860v1 by Amna Khalid, Ayma Khalid, Umar Khalid

The application of large language models (LLMs) in healthcare has gained
significant attention due to their ability to process complex medical data and
provide insights for clinical decision-making. These models have demonstrated
substantial capabilities in understanding and generating natural language,
which is crucial for medical documentation, diagnostics, and patient
interaction. This review examines the trajectory of language models from their
early stages to the current state-of-the-art LLMs, highlighting their strengths
in healthcare applications and discussing challenges such as data privacy,
bias, and ethical considerations. The potential of LLMs to enhance healthcare
delivery is explored, alongside the necessary steps to ensure their ethical and
effective integration into medical practice.

摘要：大型語言模型 (LLM) 在醫療保健中的應用已獲得顯著關注，因為它們能夠處理複雜的醫療數據並提供臨床決策的見解。這些模型已展示出在理解和產生自然語言方面的實質能力，這對於醫療文件、診斷和患者互動至關重要。本篇評論探討了語言模型從早期階段到當前最先進的 LLM 的軌跡，重點介紹了它們在醫療保健應用中的優勢，並討論了數據隱私、偏見和道德考量等挑戰。探討了 LLM 提升醫療保健服務的潛力，以及確保它們道德且有效整合到醫療實務中的必要步驟。

##### **Dispute resolution in legal mediation with quantitative argumentation**
2409.16854v1 by Xiao Chi

Mediation is often treated as an extension of negotiation, without taking
into account the unique role that norms and facts play in legal mediation.
Additionally, current approaches for updating argument acceptability in
response to changing variables frequently require the introduction of new
arguments or the removal of existing ones, which can be inefficient and
cumbersome in decision-making processes within legal disputes. In this paper,
our contribution is two-fold. First, we introduce a QuAM (Quantitative
Argumentation Mediate) framework, which integrates the parties' knowledge and
the mediator's knowledge, including facts and legal norms, when determining the
acceptability of a mediation goal. Second, we develop a new formalism to model
the relationship between the acceptability of a goal argument and the values
assigned to a variable associated with the argument. We use a real-world legal
mediation as a running example to illustrate our approach.

摘要：調解通常被視為協商的延伸，卻未考量規範和事實於法律調解中所扮演的獨特角色。此外，當前針對回應變數變更而更新論證可接受性的做法，常需要提出新的論證或移除現有的論證，這在法律爭議中的決策過程中可能低效率且繁瑣。在本文中，我們的貢獻有兩個面向。首先，我們提出一個 QuAM（量化論證調解）架構，在決定調解目標的可接受性時，整合當事人的知識和調解人的知識，包含事實和法律規範。其次，我們發展一種新的形式主義來建構目標論證的可接受性與與論證相關的變數所賦予值的關係。我們使用一個真實世界的法律調解作為一個執行範例來說明我們的做法。

##### **Exposing Assumptions in AI Benchmarks through Cognitive Modelling**
2409.16849v1 by Jonathan H. Rystrøm, Kenneth C. Enevoldsen

Cultural AI benchmarks often rely on implicit assumptions about measured
constructs, leading to vague formulations with poor validity and unclear
interrelations. We propose exposing these assumptions using explicit cognitive
models formulated as Structural Equation Models. Using cross-lingual alignment
transfer as an example, we show how this approach can answer key research
questions and identify missing datasets. This framework grounds benchmark
construction theoretically and guides dataset development to improve construct
measurement. By embracing transparency, we move towards more rigorous,
cumulative AI evaluation science, challenging researchers to critically examine
their assessment foundations.

摘要：文化 AI 基準經常依賴於測量結構的隱含假設，導致模糊的表述、效度不佳和不清晰的相互關係。我們建議使用明確的認知模型（以結構方程模型的形式表述）來揭示這些假設。以跨語言對齊轉移為例，我們展示了這種方法如何回答關鍵的研究問題並識別缺失的數據集。此框架在理論上建立了基準構建，並指導數據集開發以改進結構測量。通過擁抱透明度，我們朝著更嚴謹、累積的 AI 評估科學邁進，挑戰研究人員批判性地審查他們的評估基礎。

##### **Uncertainty Representations in State-Space Layers for Deep Reinforcement Learning under Partial Observability**
2409.16824v1 by Carlos E. Luis, Alessandro G. Bottero, Julia Vinogradska, Felix Berkenkamp, Jan Peters

Optimal decision-making under partial observability requires reasoning about
the uncertainty of the environment's hidden state. However, most reinforcement
learning architectures handle partial observability with sequence models that
have no internal mechanism to incorporate uncertainty in their hidden state
representation, such as recurrent neural networks, deterministic state-space
models and transformers. Inspired by advances in probabilistic world models for
reinforcement learning, we propose a standalone Kalman filter layer that
performs closed-form Gaussian inference in linear state-space models and train
it end-to-end within a model-free architecture to maximize returns. Similar to
efficient linear recurrent layers, the Kalman filter layer processes sequential
data using a parallel scan, which scales logarithmically with the sequence
length. By design, Kalman filter layers are a drop-in replacement for other
recurrent layers in standard model-free architectures, but importantly they
include an explicit mechanism for probabilistic filtering of the latent state
representation. Experiments in a wide variety of tasks with partial
observability show that Kalman filter layers excel in problems where
uncertainty reasoning is key for decision-making, outperforming other stateful
models.

摘要：在部分可观测性下进行最优决策需要对环境的隐藏状态的不确定性进行推理。然而，大多数强化学习架构使用序列模型处理部分可观测性，这些模型没有内部机制来合并其隐藏状态表示中的不确定性，例如循环神经网络、确定性状态空间模型和转换器。受强化学习概率世界模型的进步启发，我们提出了一种独立的卡尔曼滤波层，它在线性状态空间模型中执行闭式高斯推理，并在无模型架构中端到端地对其进行训练，以最大化回报。与高效线性循环层类似，卡尔曼滤波层使用并行扫描处理顺序数据，该扫描与序列长度成对数比例。通过设计，卡尔曼滤波层可以替代标准无模型架构中的其他循环层，但重要的是，它们包括用于概率过滤潜在状态表示的显式机制。在具有部分可观测性的各种任务中的实验表明，卡尔曼滤波层在不确定性推理是决策的关键的问题中表现出色，优于其他有状态模型。

##### **XAI-guided Insulator Anomaly Detection for Imbalanced Datasets**
2409.16821v1 by Maximilian Andreas Hoefler, Karsten Mueller, Wojciech Samek

Power grids serve as a vital component in numerous industries, seamlessly
delivering electrical energy to industrial processes and technologies, making
their safe and reliable operation indispensable. However, powerlines can be
hard to inspect due to difficult terrain or harsh climatic conditions.
Therefore, unmanned aerial vehicles are increasingly deployed to inspect
powerlines, resulting in a substantial stream of visual data which requires
swift and accurate processing. Deep learning methods have become widely popular
for this task, proving to be a valuable asset in fault detection. In
particular, the detection of insulator defects is crucial for predicting
powerline failures, since their malfunction can lead to transmission
disruptions. It is therefore of great interest to continuously maintain and
rigorously inspect insulator components. In this work we propose a novel
pipeline to tackle this task. We utilize state-of-the-art object detection to
detect and subsequently classify individual insulator anomalies. Our approach
addresses dataset challenges such as imbalance and motion-blurred images
through a fine-tuning methodology which allows us to alter the classification
focus of the model by increasing the classification accuracy of anomalous
insulators. In addition, we employ explainable-AI tools for precise
localization and explanation of anomalies. This proposed method contributes to
the field of anomaly detection, particularly vision-based industrial inspection
and predictive maintenance. We significantly improve defect detection accuracy
by up to 13%, while also offering a detailed analysis of model
mis-classifications and localization quality, showcasing the potential of our
method on real-world data.

摘要：電力網路在許多產業中扮演著至關重要的角色，無縫地將電力傳輸到工業流程和技術，使其安全且可靠的運作不可或缺。然而，由於地形崎嶇或氣候條件惡劣，電力線路可能難以檢查。因此，無人機正越來越廣泛地用於檢查電力線路，產生大量的視覺資料，需要快速且準確的處理。深度學習方法已廣泛應用於此任務，證明是故障偵測中寶貴的資產。特別是，絕緣體缺陷的偵測對於預測電力線路故障至關重要，因為其故障可能導致傳輸中斷。因此，持續維護和嚴格檢查絕緣體元件非常重要。在這項工作中，我們提出了一個新的管道來解決這個任務。我們利用最先進的物件偵測來偵測並隨後分類個別絕緣體異常。我們的做法透過微調方法來解決資料集的挑戰，例如不平衡和動態模糊影像，這讓我們能夠透過提高異常絕緣體的分類準確度來改變模型的分類重點。此外，我們採用可解釋的 AI 工具來精確定位和解釋異常。此提議的方法有助於異常偵測領域，特別是基於視覺的工業檢查和預測性維護。我們顯著地將缺陷偵測準確度提高了 13%，同時也提供了模型錯誤分類和定位品質的詳細分析，展示了我們的方法在真實世界資料中的潛力。

##### **CodeInsight: A Curated Dataset of Practical Coding Solutions from Stack Overflow**
2409.16819v1 by Nathanaël Beau, Benoît Crabbé

We introduce a novel dataset tailored for code generation, aimed at aiding
developers in common tasks. Our dataset provides examples that include a
clarified intent, code snippets associated, and an average of three related
unit tests. It encompasses a range of libraries such as \texttt{Pandas},
\texttt{Numpy}, and \texttt{Regex}, along with more than 70 standard libraries
in Python code derived from Stack Overflow. Comprising 3,409 crafted examples
by Python experts, our dataset is designed for both model finetuning and
standalone evaluation. To complete unit tests evaluation, we categorize
examples in order to get more fine grained analysis, enhancing the
understanding of models' strengths and weaknesses in specific coding tasks. The
examples have been refined to reduce data contamination, a process confirmed by
the performance of three leading models: Mistral 7B, CodeLLaMa 13B, and
Starcoder 15B. We further investigate data-contamination testing GPT-4
performance on a part of our dataset. The benchmark can be accessed at
\url{https://github.com/NathanaelBeau/CodeInsight}.

摘要：<paragraph>我們引進一個專門為程式碼產生量身打造的新穎資料集，旨在協助開發人員執行常見任務。我們的資料集提供範例，其中包含明確的意圖、關聯的程式碼片段，以及平均三個相關單元測試。它涵蓋各種函式庫，例如 \texttt{Pandas}、\texttt{Numpy} 和 \texttt{Regex}，以及來自 Stack Overflow 中 Python 程式碼的 70 多個標準函式庫。我們的資料集由 Python 專家精心製作 3,409 個範例，專為模型微調和獨立評估而設計。為了完成單元測試評估，我們對範例進行分類以取得更精細的分析，增強對模型在特定編碼任務中優缺點的理解。這些範例經過精煉以減少資料污染，這個過程由三個領先模型的效能所證實：Mistral 7B、CodeLLaMa 13B 和 Starcoder 15B。我們進一步調查資料污染測試 GPT-4 在我們資料集一部分的效能。基準測試可以在 \url{https://github.com/NathanaelBeau/CodeInsight} 取得。</paragraph>

##### **PeerArg: Argumentative Peer Review with LLMs**
2409.16813v1 by Purin Sukpanichnant, Anna Rapberger, Francesca Toni

Peer review is an essential process to determine the quality of papers
submitted to scientific conferences or journals. However, it is subjective and
prone to biases. Several studies have been conducted to apply techniques from
NLP to support peer review, but they are based on black-box techniques and
their outputs are difficult to interpret and trust. In this paper, we propose a
novel pipeline to support and understand the reviewing and decision-making
processes of peer review: the PeerArg system combining LLMs with methods from
knowledge representation. PeerArg takes in input a set of reviews for a paper
and outputs the paper acceptance prediction. We evaluate the performance of the
PeerArg pipeline on three different datasets, in comparison with a novel
end-2-end LLM that uses few-shot learning to predict paper acceptance given
reviews. The results indicate that the end-2-end LLM is capable of predicting
paper acceptance from reviews, but a variant of the PeerArg pipeline
outperforms this LLM.

摘要：同行評審是決定提交給科學會議或期刊的論文品質的必要程序。然而，它具有主觀性，且容易產生偏見。已經進行了多項研究來應用自然語言處理 (NLP) 的技術來支援同行評審，但它們基於黑盒技術，且其產出難以解釋和信任。在本文中，我們提出了一個新穎的管道來支援和理解同行評審的審查和決策流程：PeerArg 系統，它結合了大型語言模型 (LLM) 和知識表示方法。PeerArg 輸入一組論文評論，並輸出論文接受預測。我們在三個不同的資料集上評估 PeerArg 管道的效能，並與一個新穎的端對端 LLM 進行比較，該 LLM 使用少量學習來預測給定評論的論文接受度。結果表明，端對端 LLM 能夠根據評論預測論文接受度，但 PeerArg 管道的變體優於此 LLM。

##### **A Few Hypocrites: Few-Shot Learning and Subtype Definitions for Detecting Hypocrisy Accusations in Online Climate Change Debates**
2409.16807v1 by Paulina Garcia Corral, Avishai Green, Hendrik Meyer, Anke Stoll, Xiaoyue Yan, Myrthe Reuver

The climate crisis is a salient issue in online discussions, and hypocrisy
accusations are a central rhetorical element in these debates. However, for
large-scale text analysis, hypocrisy accusation detection is an understudied
tool, most often defined as a smaller subtask of fallacious argument detection.
In this paper, we define hypocrisy accusation detection as an independent task
in NLP, and identify different relevant subtypes of hypocrisy accusations. Our
Climate Hypocrisy Accusation Corpus (CHAC) consists of 420 Reddit climate
debate comments, expert-annotated into two different types of hypocrisy
accusations: personal versus political hypocrisy. We evaluate few-shot
in-context learning with 6 shots and 3 instruction-tuned Large Language Models
(LLMs) for detecting hypocrisy accusations in this dataset. Results indicate
that the GPT-4o and Llama-3 models in particular show promise in detecting
hypocrisy accusations (F1 reaching 0.68, while previous work shows F1 of 0.44).
However, context matters for a complex semantic concept such as hypocrisy
accusations, and we find models struggle especially at identifying political
hypocrisy accusations compared to personal moral hypocrisy. Our study
contributes new insights in hypocrisy detection and climate change discourse,
and is a stepping stone for large-scale analysis of hypocrisy accusation in
online climate debates.

摘要：氣候危機是網路討論中一個顯著的問題，而偽善指控是這些辯論中一個主要的修辭元素。然而，對於大規模的文字分析，偽善指控偵測是一個研究不足的工具，最常被定義為謬誤論證偵測的一個較小的子任務。在本文中，我們將偽善指控偵測定義為自然語言處理 (NLP) 中一個獨立的任務，並找出偽善指控的不同相關子類型。我們的氣候偽善指控語料庫 (CHAC) 包含 420 則 Reddit 氣候辯論留言，由專家註釋為兩種不同類型的偽善指控：個人偽善與政治偽善。我們評估了在這個資料集偵測偽善指控的六次小樣本情境學習，以及三個經過指令微調的大型語言模型 (LLM)。結果顯示，GPT-4o 和 Llama-3 模型在偵測偽善指控方面特別有前景（F1 達到 0.68，而先前的研究顯示 F1 為 0.44）。然而，對於偽善指控等複雜的語義概念，背景很重要，我們發現與個人道德偽善相比，模型在辨識政治偽善指控時特別吃力。我們的研究為偽善偵測和氣候變遷論述提供了新的見解，並且是大規模分析網路氣候辯論中偽善指控的踏腳石。

##### **Large Language Model Predicts Above Normal All India Summer Monsoon Rainfall in 2024**
2409.16799v1 by Ujjawal Sharma, Madhav Biyani, Akhil Dev Suresh, Debi Prasad Bhuyan, Saroj Kanta Mishra, Tanmoy Chakraborty

Reliable prediction of the All India Summer Monsoon Rainfall (AISMR) is
pivotal for informed policymaking for the country, impacting the lives of
billions of people. However, accurate simulation of AISMR has been a persistent
challenge due to the complex interplay of various muti-scale factors and the
inherent variability of the monsoon system. This research focuses on adapting
and fine-tuning the latest LLM model, PatchTST, to accurately predict AISMR
with a lead time of three months. The fine-tuned PatchTST model, trained with
historical AISMR data, the Ni\~no3.4 index, and categorical Indian Ocean Dipole
values, outperforms several popular neural network models and statistical
models. This fine-tuned LLM model exhibits an exceptionally low RMSE percentage
of 0.07% and a Spearman correlation of 0.976. This is particularly impressive,
since it is nearly 80% more accurate than the best-performing NN models. The
model predicts an above-normal monsoon for the year 2024, with an accumulated
rainfall of 921.6 mm in the month of June-September for the entire country.

摘要：準確預測全印度夏季季風降雨量 (AISMR) 對於國家明智的政策制定至關重要，影響著數十億人的生活。然而，由於各種多尺度因素的複雜相互作用和季風系統的固有變異性，對 AISMR 的準確模擬一直是一個持續的挑戰。本研究專注於調整和微調最新的 LLM 模型 PatchTST，以準確預測提前三個月到來的 AISMR。經過微調的 PatchTST 模型使用歷史 AISMR 資料、Ni\~no3.4 指數和分類的印度洋偶極值進行訓練，其表現優於幾種流行的神經網路模型和統計模型。經過微調的 LLM 模型展現出極低的 RMSE 百分比 0.07% 和 Spearman 相關性 0.976。這特別令人印象深刻，因為它比效能最好的 NN 模型準確了近 80%。該模型預測 2024 年將出現異常季風，全國 6 月至 9 月的累積降雨量為 921.6 毫米。

##### **Scalable Ensemble Diversification for OOD Generalization and Detection**
2409.16797v1 by Alexander Rubinstein, Luca Scimeca, Damien Teney, Seong Joon Oh

Training a diverse ensemble of models has several practical applications such
as providing candidates for model selection with better out-of-distribution
(OOD) generalization, and enabling the detection of OOD samples via Bayesian
principles. An existing approach to diverse ensemble training encourages the
models to disagree on provided OOD samples. However, the approach is
computationally expensive and it requires well-separated ID and OOD examples,
such that it has only been demonstrated in small-scale settings.
  $\textbf{Method.}$ This work presents a method for Scalable Ensemble
Diversification (SED) applicable to large-scale settings (e.g. ImageNet) that
does not require OOD samples. Instead, SED identifies hard training samples on
the fly and encourages the ensemble members to disagree on these. To improve
scaling, we show how to avoid the expensive computations in existing methods of
exhaustive pairwise disagreements across models.
  $\textbf{Results.}$ We evaluate the benefits of diversification with
experiments on ImageNet. First, for OOD generalization, we observe large
benefits from the diversification in multiple settings including output-space
(classical) ensembles and weight-space ensembles (model soups). Second, for OOD
detection, we turn the diversity of ensemble hypotheses into a novel
uncertainty score estimator that surpasses a large number of OOD detection
baselines.
  Code is available here:
https://github.com/AlexanderRubinstein/diverse-universe-public.

摘要：<paragraph>訓練多元模型集合有多項實際應用，例如提供模型選擇候選，以獲得更好的分布外 (OOD) 概化，並能透過貝氏原理來偵測 OOD 樣本。現有多元集合訓練方法鼓勵模型對提供的 OOD 樣本表示不同意。然而，此方法在運算上很昂貴，而且需要有良好分離的 ID 和 OOD 範例，因此僅在小規模設定中得到驗證。
$\textbf{方法}$。本研究提出適用於大型設定（例如 ImageNet）的可擴充集合多樣化 (SED) 方法，不需要 OOD 樣本。相反地，SED 會在執行中找出困難的訓練樣本，並鼓勵集合成員對這些樣本表示不同意。為了改善擴充性，我們展示如何避免現有方法中跨模型的窮舉成對不同意所產生的昂貴運算。
$\textbf{結果}$。我們在 ImageNet 上的實驗中評估了多樣化的優點。首先，對於 OOD 概化，我們觀察到多樣化在多種設定中帶來極大的好處，包括輸出空間（傳統）集合和權重空間集合（模型湯）。其次，對於 OOD 偵測，我們將集合假設的多樣性轉換為一種新穎的不確定性評分估計器，其優於大量的 OOD 偵測基準。
程式碼可在此取得：
https://github.com/AlexanderRubinstein/diverse-universe-public。</paragraph>

##### **Mitigating the Bias of Large Language Model Evaluation**
2409.16788v1 by Hongli Zhou, Hui Huang, Yunfei Long, Bing Xu, Conghui Zhu, Hailong Cao, Muyun Yang, Tiejun Zhao

Recently, there has been a trend of evaluating the Large Language Model (LLM)
quality in the flavor of LLM-as-a-Judge, namely leveraging another LLM to
evaluate the current output quality. However, existing judges are proven to be
biased, namely they would favor answers which present better superficial
quality (such as verbosity, fluency) while ignoring the instruction following
ability. In this work, we propose systematic research about the bias of
LLM-as-a-Judge. Specifically, for closed-source judge models, we apply
calibration to mitigate the significance of superficial quality, both on
probability level and prompt level. For open-source judge models, we propose to
mitigate the bias by contrastive training, with curated negative samples that
deviate from instruction but present better superficial quality. We apply our
methods on the bias evaluation benchmark, and experiment results show our
methods mitigate the bias by a large margin while maintaining a satisfactory
evaluation accuracy.

摘要：最近，評估大型語言模型 (LLM) 品質的趨勢是 LLM-as-a-Judge，也就是利用另一個 LLM 來評估目前的輸出品質。然而，現有的評審已被證明有偏見，也就是說，他們會偏好呈現較佳表面品質（例如冗長、流暢）的答案，而忽略遵循指令的能力。在這項工作中，我們提出關於 LLM-as-a-Judge 偏見的系統性研究。特別是，對於閉源評審模型，我們應用校準來減輕表面品質的重要性，無論是在機率層級或提示層級。對於開源評審模型，我們建議透過對比訓練來減輕偏見，並使用偏離指令但呈現較佳表面品質的負面樣本。我們在偏見評估基準上套用我們的模型，實驗結果顯示我們的模型在維持滿意評估精準度的同時，大幅減輕了偏見。

##### **Enhancing Feature Selection and Interpretability in AI Regression Tasks Through Feature Attribution**
2409.16787v1 by Alexander Hinterleitner, Thomas Bartz-Beielstein, Richard Schulz, Sebastian Spengler, Thomas Winter, Christoph Leitenmeier

Research in Explainable Artificial Intelligence (XAI) is increasing, aiming
to make deep learning models more transparent. Most XAI methods focus on
justifying the decisions made by Artificial Intelligence (AI) systems in
security-relevant applications. However, relatively little attention has been
given to using these methods to improve the performance and robustness of deep
learning algorithms. Additionally, much of the existing XAI work primarily
addresses classification problems. In this study, we investigate the potential
of feature attribution methods to filter out uninformative features in input
data for regression problems, thereby improving the accuracy and stability of
predictions. We introduce a feature selection pipeline that combines Integrated
Gradients with k-means clustering to select an optimal set of variables from
the initial data space. To validate the effectiveness of this approach, we
apply it to a real-world industrial problem - blade vibration analysis in the
development process of turbo machinery.

摘要：可解釋人工智慧 (XAI) 的研究正在增加，目標是讓深度學習模型更具透明度。大多數 XAI 方法專注於為人工智慧 (AI) 系統在與安全相關的應用程式中所做出的決策辯護。然而，對於使用這些方法來改善深度學習演算法的效能和健壯性，卻相對較少關注。此外，現有許多 XAI 工作主要解決分類問題。在本研究中，我們探討特徵歸因方法的潛力，以在回歸問題的輸入資料中篩選出無意義的特徵，從而提升預測的準確性和穩定性。我們引入了一個特徵選取管線，結合了整合梯度和 k 均值聚類，從初始資料空間中選取一組最佳變數。為了驗證此方法的有效性，我們將其應用於現實世界的產業問題，即渦輪機械開發過程中的葉片振動分析。

##### **Holistic Automated Red Teaming for Large Language Models through Top-Down Test Case Generation and Multi-turn Interaction**
2409.16783v1 by Jinchuan Zhang, Yan Zhou, Yaxin Liu, Ziming Li, Songlin Hu

Automated red teaming is an effective method for identifying misaligned
behaviors in large language models (LLMs). Existing approaches, however, often
focus primarily on improving attack success rates while overlooking the need
for comprehensive test case coverage. Additionally, most of these methods are
limited to single-turn red teaming, failing to capture the multi-turn dynamics
of real-world human-machine interactions. To overcome these limitations, we
propose HARM (Holistic Automated Red teaMing), which scales up the diversity of
test cases using a top-down approach based on an extensible, fine-grained risk
taxonomy. Our method also leverages a novel fine-tuning strategy and
reinforcement learning techniques to facilitate multi-turn adversarial probing
in a human-like manner. Experimental results demonstrate that our framework
enables a more systematic understanding of model vulnerabilities and offers
more targeted guidance for the alignment process.

摘要：自動化紅隊是一種有效的方法，用於識別大型語言模型 (LLM) 中的錯誤行為。然而，現有的方法通常主要集中於提高攻擊成功率，而忽視了對全面測試用例覆蓋的需求。此外，這些方法中的大多數僅限於單回合紅隊，無法捕捉到現實世界中人機交互的多回合動態。為了克服這些限制，我們提出了 HARM（整體自動紅隊），它使用基於可擴展、細粒度風險分類的自頂向下方法擴大了測試用例的多樣性。我們的模型還利用了一種新穎的微調策略和強化學習技術，以人類的方式促進多回合對抗探測。實驗結果表明，我們的框架可以更系統地了解模型漏洞，並為對齊過程提供更有針對性的指導。

##### **LLaMa-SciQ: An Educational Chatbot for Answering Science MCQ**
2409.16779v1 by Marc-Antoine Allard, Matin Ansaripour, Maria Yuffa, Paul Teiletche

Large Language Models (LLMs) often struggle with tasks requiring mathematical
reasoning, particularly multiple-choice questions (MCQs). To address this
issue, we developed LLaMa-SciQ, an educational chatbot designed to assist
college students in solving and understanding MCQs in STEM fields. We begin by
fine-tuning and aligning the models to human preferences. After comparing the
performance of Mistral-7B and LLaMa-8B, we selected the latter as the base
model due to its higher evaluation accuracy. To further enhance accuracy, we
implement Retrieval-Augmented Generation (RAG) and apply quantization to
compress the model, reducing inference time and increasing accessibility for
students. For mathematical reasoning, LLaMa-SciQ achieved 74.5% accuracy on the
GSM8k dataset and 30% on the MATH dataset. However, RAG does not improve
performance and even reduces it, likely due to retriever issues or the model's
unfamiliarity with context. Despite this, the quantized model shows only a 5%
loss in performance, demonstrating significant efficiency improvements.

摘要：大型語言模型 (LLM) 通常難以執行需要數學推理的任務，特別是多選題 (MCQ)。為了解決這個問題，我們開發了 LLaMa-SciQ，這是一個教育聊天機器人，旨在協助大學生解決和理解 STEM 領域的 MCQ。我們首先微調模型並將其與人類偏好保持一致。在比較了 Mistral-7B 和 LLaMa-8B 的性能後，我們選擇後者作為基礎模型，因為它的評估準確度較高。為了進一步提高準確度，我們實施了檢索增強生成 (RAG) 並應用量化來壓縮模型，從而減少推理時間並增加學生的可及性。對於數學推理，LLaMa-SciQ 在 GSM8k 數據集上達到 74.5% 的準確度，在 MATH 數據集上達到 30%。但是，RAG 沒有提高性能，甚至降低了性能，這可能是由於檢索器問題或模型不熟悉上下文。儘管如此，量化模型僅顯示出 5% 的性能損失，證明了顯著的效率改進。

##### **Offline and Distributional Reinforcement Learning for Radio Resource Management**
2409.16764v1 by Eslam Eldeeb, Hirley Alves

Reinforcement learning (RL) has proved to have a promising role in future
intelligent wireless networks. Online RL has been adopted for radio resource
management (RRM), taking over traditional schemes. However, due to its reliance
on online interaction with the environment, its role becomes limited in
practical, real-world problems where online interaction is not feasible. In
addition, traditional RL stands short in front of the uncertainties and risks
in real-world stochastic environments. In this manner, we propose an offline
and distributional RL scheme for the RRM problem, enabling offline training
using a static dataset without any interaction with the environment and
considering the sources of uncertainties using the distributions of the return.
Simulation results demonstrate that the proposed scheme outperforms
conventional resource management models. In addition, it is the only scheme
that surpasses online RL and achieves a $16 \%$ gain over online RL.

摘要：強化學習 (RL) 已證明在未來的智慧無線網路中具有前景。線上 RL 已被採用於無線資源管理 (RRM)，接管傳統的架構。然而，由於它依賴與環境的線上互動，因此在實際的真實世界問題中，其角色受到限制，因為線上互動不可行。此外，傳統的 RL 在面對真實世界隨機環境中的不確定性和風險時，仍有不足之處。因此，我們提出了一個針對 RRM 問題的離線和分配式 RL 架構，使用靜態資料集進行離線訓練，而無需與環境互動，並使用回報的分配來考量不確定性的來源。模擬結果證明，所提出的架構優於傳統的資源管理模型。此外，它是唯一超越線上 RL 的架構，並在線上 RL 上獲得 16% 的收益。

##### **E-SQL: Direct Schema Linking via Question Enrichment in Text-to-SQL**
2409.16751v1 by Hasan Alp Caferoğlu, Özgür Ulusoy

Translating Natural Language Queries into Structured Query Language
(Text-to-SQL or NLQ-to-SQL) is a critical task extensively studied by both the
natural language processing and database communities, aimed at providing a
natural language interface to databases (NLIDB) and lowering the barrier for
non-experts. Despite recent advancements made through the use of Large Language
Models (LLMs), significant challenges remain. These include handling complex
database schemas, resolving ambiguity in user queries, and generating SQL
queries with intricate structures that accurately reflect the user's intent. In
this work, we introduce E-SQL, a novel pipeline specifically designed to
address these challenges through direct schema linking and candidate predicate
augmentation. E-SQL enhances the natural language query by incorporating
relevant database items (i.e., tables, columns, and values) and conditions
directly into the question, bridging the gap between the query and the database
structure. The pipeline leverages candidate predicate augmentation to mitigate
erroneous or incomplete predicates in generated SQLs. We further investigate
the impact of schema filtering, a technique widely explored in previous work,
and demonstrate its diminishing returns when applied alongside advanced large
language models. Comprehensive evaluations on the BIRD benchmark illustrate
that E-SQL achieves competitive performance, particularly excelling in complex
queries with a 66.29% execution accuracy on the test set. All code required to
reproduce the reported results is publicly available on our GitHub repository.

摘要：將自然語言查詢轉換為結構化查詢語言（文本轉 SQL 或 NLQ 轉 SQL）是一項重要的任務，自然語言處理和資料庫社群廣泛研究，旨在提供資料庫的自然語言介面（NLIDB），並降低非專家的門檻。儘管透過使用大型語言模型（LLM）取得了最近的進展，但仍有重大挑戰。這些挑戰包括處理複雜的資料庫架構、解決使用者查詢中的歧義，以及產生精細結構的 SQL 查詢，以準確反映使用者的意圖。在這項工作中，我們介紹了 E-SQL，這是一個專門設計用於透過直接架構連結和候選謂詞擴充來解決這些挑戰的新穎管道。E-SQL 透過將相關資料庫項目（即表格、欄位和值）和條件直接納入問題中，來增強自然語言查詢，縮小查詢和資料庫結構之間的差距。該管道利用候選謂詞擴充來減輕產生 SQL 中錯誤或不完整的謂詞。我們進一步探討了架構過濾的影響，這是一種在先前工作中廣泛探討的技術，並證明當與先進的大型語言模型一起應用時，它的報酬遞減。在 BIRD 基準上的全面評估表明，E-SQL 達到了競爭力的效能，特別是在複雜查詢中，在測試集中執行準確度為 66.29%。重現報告結果所需的所有程式碼都公開在我們的 GitHub 儲存庫中。

##### **GB-RVFL: Fusion of Randomized Neural Network and Granular Ball Computing**
2409.16735v1 by M. Sajid, A. Quadir, M. Tanveer

The random vector functional link (RVFL) network is a prominent
classification model with strong generalization ability. However, RVFL treats
all samples uniformly, ignoring whether they are pure or noisy, and its
scalability is limited due to the need for inverting the entire training
matrix. To address these issues, we propose granular ball RVFL (GB-RVFL) model,
which uses granular balls (GBs) as inputs instead of training samples. This
approach enhances scalability by requiring only the inverse of the GB center
matrix and improves robustness against noise and outliers through the coarse
granularity of GBs. Furthermore, RVFL overlooks the dataset's geometric
structure. To address this, we propose graph embedding GB-RVFL (GE-GB-RVFL)
model, which fuses granular computing and graph embedding (GE) to preserve the
topological structure of GBs. The proposed GB-RVFL and GE-GB-RVFL models are
evaluated on KEEL, UCI, NDC and biomedical datasets, demonstrating superior
performance compared to baseline models.

摘要：隨機向量函數連結 (RVFL) 網路是一種傑出的分類模型，具有強大的泛化能力。然而，RVFL 一視同仁地對待所有樣本，忽略它們是純淨的還是有雜訊的，而且由於需要對整個訓練矩陣進行反轉，因此其可擴充性受到限制。為了解決這些問題，我們提出了顆粒球 RVFL (GB-RVFL) 模型，它使用顆粒球 (GB) 作為輸入，而不是訓練樣本。這種方法僅需要反轉 GB 中心矩陣，就能增強可擴充性，並且透過 GB 的粗粒度來改善對雜訊和異常值的魯棒性。此外，RVFL 忽略了資料集的幾何結構。為了解決這個問題，我們提出了圖嵌入 GB-RVFL (GE-GB-RVFL) 模型，它融合了顆粒運算和圖嵌入 (GE)，以保留 GB 的拓撲結構。所提出的 GB-RVFL 和 GE-GB-RVFL 模型在 KEEL、UCI、NDC 和生物醫學資料集上進行評估，與基線模型相比，表現出優異的效能。

##### **RoleBreak: Character Hallucination as a Jailbreak Attack in Role-Playing Systems**
2409.16727v1 by Yihong Tang, Bo Wang, Xu Wang, Dongming Zhao, Jing Liu, Jijun Zhang, Ruifang He, Yuexian Hou

Role-playing systems powered by large language models (LLMs) have become
increasingly influential in emotional communication applications. However,
these systems are susceptible to character hallucinations, where the model
deviates from predefined character roles and generates responses that are
inconsistent with the intended persona. This paper presents the first
systematic analysis of character hallucination from an attack perspective,
introducing the RoleBreak framework. Our framework identifies two core
mechanisms-query sparsity and role-query conflict-as key factors driving
character hallucination. Leveraging these insights, we construct a novel
dataset, RoleBreakEval, to evaluate existing hallucination mitigation
techniques. Our experiments reveal that even enhanced models trained to
minimize hallucination remain vulnerable to attacks. To address these
vulnerabilities, we propose a novel defence strategy, the Narrator Mode, which
generates supplemental context through narration to mitigate role-query
conflicts and improve query generalization. Experimental results demonstrate
that Narrator Mode significantly outperforms traditional refusal-based
strategies by reducing hallucinations, enhancing fidelity to character roles
and queries, and improving overall narrative coherence.

摘要：大型语言模型（LLM）驱动的角色扮演系统在情感沟通应用中变得越来越有影响力。然而，这些系统容易出现角色错觉，即模型偏离预定义的角色，并生成与预期角色不一致的反应。本文从攻击的角度对角色错觉进行了首次系统分析，引入了 RoleBreak 框架。我们的框架将两个核心机制（查询稀疏性和角色查询冲突）确定为推动角色错觉的关键因素。利用这些见解，我们构建了一个新数据集 RoleBreakEval，以评估现有的错觉缓解技术。我们的实验表明，即使经过训练以最大程度减少错觉的增强模型仍然容易受到攻击。为了解决这些漏洞，我们提出了一种新颖的防御策略，即叙述者模式，它通过叙述生成补充语境来缓解角色查询冲突并提高查询泛化能力。实验结果表明，叙述者模式通过减少错觉、增强对角色和查询的保真度以及提高整体叙事连贯性，明显优于传统的基于拒绝的策略。

##### **PMSS: Pretrained Matrices Skeleton Selection for LLM Fine-tuning**
2409.16722v1 by Qibin Wang, Xiaolin Hu, Weikai Xu, Wei Liu, Jian Luan, Bin Wang

Low-rank adaptation (LoRA) and its variants have recently gained much
interest due to their ability to avoid excessive inference costs. However, LoRA
still encounters the following challenges: (1) Limitation of low-rank
assumption; and (2) Its initialization method may be suboptimal. To this end,
we propose PMSS(Pre-trained Matrices Skeleton Selection), which enables
high-rank updates with low costs while leveraging semantic and linguistic
information inherent in pre-trained weight. It achieves this by selecting
skeletons from the pre-trained weight matrix and only learning a small matrix
instead. Experiments demonstrate that PMSS outperforms LoRA and other
fine-tuning methods across tasks with much less trainable parameters. We
demonstrate its effectiveness, especially in handling complex tasks such as
DROP benchmark(+3.4%/+5.9% on LLaMA2-7B/13B) and math
reasoning(+12.89%/+5.61%/+3.11% on LLaMA2-7B, Mistral-7B and Gemma-7B of
GSM8K). The code and model will be released soon.

摘要：低秩適應 (LoRA) 及其變體最近因其避免過度推理成本的能力而備受關注。然而，LoRA 仍面臨以下挑戰：(1) 低秩假設的限制；以及 (2) 其初始化方法可能次優。為此，我們提出 PMSS（預訓練矩陣骨架選擇），它能夠以低成本進行高秩更新，同時利用預訓練權重中固有的語義和語言信息。它通過從預訓練權重矩陣中選擇骨架並只學習一個小矩陣來實現這一點。實驗表明，PMSS 在具有更少可訓練參數的任務中優於 LoRA 和其他微調方法。我們證明了它的有效性，特別是在處理複雜任務方面，例如 DROP 基準（在 LLaMA2-7B/13B 上+3.4%/+5.9%）和數學推理（在 GSM8K 的 LLaMA2-7B、Mistral-7B 和 Gemma-7B 上+12.89%/+5.61%/+3.11%）。代碼和模型將很快發布。

##### **A Multi-Dataset Classification-Based Deep Learning Framework for Electronic Health Records and Predictive Analysis in Healthcare**
2409.16721v1 by Syed Mohd Faisal Malik, Md Tabrez Nafis, Mohd Abdul Ahad, Safdar Tanweer

In contemporary healthcare, to protect patient data, electronic health
records have become invaluable repositories, creating vast opportunities to
leverage deep learning techniques for predictive analysis. Retinal fundus
images, cirrhosis stages, and heart disease diagnostic predictions have shown
promising results through the integration of deep learning techniques for
classifying diverse datasets. This study proposes a novel deep learning
predictive analysis framework for classifying multiple datasets by
pre-processing data from three distinct sources. A hybrid deep learning model
combining Residual Networks and Artificial Neural Networks is proposed to
detect acute and chronic diseases such as heart diseases, cirrhosis, and
retinal conditions, outperforming existing models. Dataset preparation involves
aspects such as categorical data transformation, dimensionality reduction, and
missing data synthesis. Feature extraction is effectively performed using
scaler transformation for categorical datasets and ResNet architecture for
image datasets. The resulting features are integrated into a unified
classification model. Rigorous experimentation and evaluation resulted in high
accuracies of 93%, 99%, and 95% for retinal fundus images, cirrhosis stages,
and heart disease diagnostic predictions, respectively. The efficacy of the
proposed method is demonstrated through a detailed analysis of F1-score,
precision, and recall metrics. This study offers a comprehensive exploration of
methodologies and experiments, providing in-depth knowledge of deep learning
predictive analysis in electronic health records.

摘要：<paragraph>在當代醫療保健中，為了保護患者數據，電子健康記錄已成為無價的儲存庫，創造了利用深度學習技術進行預測分析的廣闊機會。視網膜眼底圖像、肝硬化分期和心臟病診斷預測已透過整合深度學習技術來分類不同的數據集，顯示出有希望的結果。本研究提出一個新的深度學習預測分析架構，透過預處理來自三個不同來源的數據來分類多個數據集。提出了一個結合殘差網路和人工神經網路的混合深度學習模型，用於檢測急性病和慢性病，例如心臟病、肝硬化和視網膜疾病，其效能優於現有的模型。數據集準備涉及範疇資料轉換、降維和遺失資料合成等方面。特徵萃取使用範疇資料集的縮放器轉換和影像資料集的 ResNet 架構來有效執行。產生的特徵被整合到一個統一的分類模型中。嚴謹的實驗和評估導致視網膜眼底圖像、肝硬化分期和心臟病診斷預測的準確度分別高達 93%、99% 和 95%。所提出方法的有效性透過對 F1 分數、精確度和召回率指標的詳細分析來證明。本研究提供了方法論和實驗的全面探討，深入了解電子健康記錄中的深度學習預測分析。</paragraph>

##### **Vision-Language Model Fine-Tuning via Simple Parameter-Efficient Modification**
2409.16718v1 by Ming Li, Jike Zhong, Chenxin Li, Liuzhuozheng Li, Nie Lin, Masashi Sugiyama

Recent advances in fine-tuning Vision-Language Models (VLMs) have witnessed
the success of prompt tuning and adapter tuning, while the classic model
fine-tuning on inherent parameters seems to be overlooked. It is believed that
fine-tuning the parameters of VLMs with few-shot samples corrupts the
pre-trained knowledge since fine-tuning the CLIP model even degrades
performance. In this paper, we revisit this viewpoint, and propose a new
perspective: fine-tuning the specific parameters instead of all will uncover
the power of classic model fine-tuning on VLMs. Through our meticulous study,
we propose ClipFit, a simple yet effective method to fine-tune CLIP without
introducing any overhead of extra parameters. We demonstrate that by only
fine-tuning the specific bias terms and normalization layers, ClipFit can
improve the performance of zero-shot CLIP by 7.27\% average harmonic mean
accuracy. Lastly, to understand how fine-tuning in CLIPFit affects the
pre-trained models, we conducted extensive experimental analyses w.r.t. changes
in internal parameters and representations. We found that low-level text bias
layers and the first layer normalization layer change much more than other
layers. The code is available at \url{https://github.com/minglllli/CLIPFit}.

摘要：最近对视觉语言模型 (VLM) 的微调取得了进展，见证了提示微调和适配器微调的成功，而经典模型对固有参数的微调似乎被忽视了。人们认为，用少量样本微调 VLM 的参数会破坏预训练的知识，因为即使微调 CLIP 模型也会降低性能。在本文中，我们重新审视了这个观点，并提出了一个新的观点：微调特定参数而不是所有参数将揭示经典模型微调在 VLM 上的强大功能。通过我们细致的研究，我们提出了 ClipFit，这是一种简单而有效的方法，可以在不引入任何额外参数开销的情况下对 CLIP 进行微调。我们证明，仅通过微调特定的偏差项和归一化层，ClipFit 可以将零样本 CLIP 的性能提高 7.27% 的平均谐波平均准确率。最后，为了了解 ClipFit 中的微调如何影响预训练模型，我们对内部参数和表示的变化进行了广泛的实验分析。我们发现低级文本偏差层和第一层归一化层比其他层变化更大。代码可在 \url{https://github.com/minglllli/CLIPFit} 获得。

##### **Beyond Turing Test: Can GPT-4 Sway Experts' Decisions?**
2409.16710v1 by Takehiro Takayanagi, Hiroya Takamura, Kiyoshi Izumi, Chung-Chi Chen

In the post-Turing era, evaluating large language models (LLMs) involves
assessing generated text based on readers' reactions rather than merely its
indistinguishability from human-produced content. This paper explores how
LLM-generated text impacts readers' decisions, focusing on both amateur and
expert audiences. Our findings indicate that GPT-4 can generate persuasive
analyses affecting the decisions of both amateurs and professionals.
Furthermore, we evaluate the generated text from the aspects of grammar,
convincingness, logical coherence, and usefulness. The results highlight a high
correlation between real-world evaluation through audience reactions and the
current multi-dimensional evaluators commonly used for generative models.
Overall, this paper shows the potential and risk of using generated text to
sway human decisions and also points out a new direction for evaluating
generated text, i.e., leveraging the reactions and decisions of readers. We
release our dataset to assist future research.

摘要：在後圖靈時代，評估大型語言模型 (LLM) 涉及
根據讀者的反應評估產生的文字，而不是僅僅根據其與人類產生的內容是否難以區分。本文探討
LLM 生成的文字如何影響讀者的決策，同時關注業餘和
專業受眾。我們的研究結果表明，GPT-4 可以產生影響業餘人士和專業人士決策的有說服力的分析。
此外，我們從語法、
說服力、邏輯連貫性和有用性方面評估產生的文字。結果強調了通過受眾反應進行的真實世界評估與
當前通常用於生成模型的多維評估器之間的高度相關性。
總的來說，本文展示了使用生成的文字來影響人類決策的潛力和風險，並指出了評估
生成文本的新方向，即利用讀者的反應和決策。我們發布我們的數據集以協助未來的研究。

##### **Probing Omissions and Distortions in Transformer-based RDF-to-Text Models**
2409.16707v1 by Juliette Faille, Albert Gatt, Claire Gardent

In Natural Language Generation (NLG), important information is sometimes
omitted in the output text. To better understand and analyse how this type of
mistake arises, we focus on RDF-to-Text generation and explore two methods of
probing omissions in the encoder output of BART (Lewis et al, 2020) and of T5
(Raffel et al, 2019): (i) a novel parameter-free probing method based on the
computation of cosine similarity between embeddings of RDF graphs and of RDF
graphs in which we removed some entities and (ii) a parametric probe which
performs binary classification on the encoder embeddings to detect omitted
entities. We also extend our analysis to distorted entities, i.e. entities that
are not fully correctly mentioned in the generated text (e.g. misspelling of
entity, wrong units of measurement). We found that both omitted and distorted
entities can be probed in the encoder's output embeddings. This suggests that
the encoder emits a weaker signal for these entities and therefore is
responsible for some loss of information. This also shows that probing methods
can be used to detect mistakes in the output of NLG models.

摘要：在自然語言生成 (NLG) 中，重要資訊有時會在輸出文字中被省略。為了更了解並分析這類錯誤是如何產生的，我們專注於 RDF 轉文字的生成，並探討兩種探測 BART (Lewis 等人，2020) 和 T5 (Raffel 等人，2019) 的編碼器輸出中遺漏的方法：(i) 一種基於 RDF 圖形嵌入和我們移除一些實體的 RDF 圖形之間的餘弦相似度計算的新型無參數探測方法，以及 (ii) 一種在編碼器嵌入中執行二元分類以偵測遺漏實體的參數化探測。我們也將我們的分析延伸到扭曲的實體，也就是在產生的文字中沒有被完全正確提及的實體 (例如實體拼寫錯誤、測量單位錯誤)。我們發現遺漏和扭曲的實體都可以被探測到在編碼器的輸出嵌入中。這表示編碼器針對這些實體發射較弱的訊號，因此導致一些資訊遺失。這也顯示探測方法可以用於偵測 NLG 模型輸出中的錯誤。

##### **Pix2Next: Leveraging Vision Foundation Models for RGB to NIR Image Translation**
2409.16706v1 by Youngwan Jin, Incheol Park, Hanbin Song, Hyeongjin Ju, Yagiz Nalcakan, Shiho Kim

This paper proposes Pix2Next, a novel image-to-image translation framework
designed to address the challenge of generating high-quality Near-Infrared
(NIR) images from RGB inputs. Our approach leverages a state-of-the-art Vision
Foundation Model (VFM) within an encoder-decoder architecture, incorporating
cross-attention mechanisms to enhance feature integration. This design captures
detailed global representations and preserves essential spectral
characteristics, treating RGB-to-NIR translation as more than a simple domain
transfer problem. A multi-scale PatchGAN discriminator ensures realistic image
generation at various detail levels, while carefully designed loss functions
couple global context understanding with local feature preservation. We
performed experiments on the RANUS dataset to demonstrate Pix2Next's advantages
in quantitative metrics and visual quality, improving the FID score by 34.81%
compared to existing methods. Furthermore, we demonstrate the practical utility
of Pix2Next by showing improved performance on a downstream object detection
task using generated NIR data to augment limited real NIR datasets. The
proposed approach enables the scaling up of NIR datasets without additional
data acquisition or annotation efforts, potentially accelerating advancements
in NIR-based computer vision applications.

摘要：本文提出 Pix2Next，這是一個新穎的影像轉換架構，旨在解決從 RGB 輸入產生高品質近紅外線 (NIR) 影像的挑戰。我們的做法在編碼器解碼器架構中利用最先進的 Vision Foundation Model (VFM)，並結合跨注意力機制來增強特徵整合。這種設計擷取了詳細的全局表示，並保留了必要的頻譜特性，將 RGB 轉 NIR 轉換視為不只是單純的網域轉移問題。多尺度 PatchGAN 辨識器確保在各種細節層級中產生逼真的影像，同時精心設計的損失函數將全局脈絡理解與局部特徵保留結合起來。我們在 RANUS 資料集上進行實驗，以展示 Pix2Next 在定量指標和視覺品質方面的優點，與現有方法相比，將 FID 分數提高了 34.81%。此外，我們展示了 Pix2Next 的實際效用，方法是在下游物件偵測任務中顯示使用產生的 NIR 資料來擴充有限的真實 NIR 資料集，從而提高效能。所提出的方法可以在不額外取得資料或標註的情況下擴充 NIR 資料集，這有可能加速基於 NIR 的電腦視覺應用程式的進展。

##### **A Survey of Low-bit Large Language Models: Basics, Systems, and Algorithms**
2409.16694v1 by Ruihao Gong, Yifu Ding, Zining Wang, Chengtao Lv, Xingyu Zheng, Jinyang Du, Haotong Qin, Jinyang Guo, Michele Magno, Xianglong Liu

Large language models (LLMs) have achieved remarkable advancements in natural
language processing, showcasing exceptional performance across various tasks.
However, the expensive memory and computational requirements present
significant challenges for their practical deployment. Low-bit quantization has
emerged as a critical approach to mitigate these challenges by reducing the
bit-width of model parameters, activations, and gradients, thus decreasing
memory usage and computational demands. This paper presents a comprehensive
survey of low-bit quantization methods tailored for LLMs, covering the
fundamental principles, system implementations, and algorithmic strategies. An
overview of basic concepts and new data formats specific to low-bit LLMs is
first introduced, followed by a review of frameworks and systems that
facilitate low-bit LLMs across various hardware platforms. Then, we categorize
and analyze techniques and toolkits for efficient low-bit training and
inference of LLMs. Finally, we conclude with a discussion of future trends and
potential advancements of low-bit LLMs. Our systematic overview from basic,
system, and algorithm perspectives can offer valuable insights and guidelines
for future works to enhance the efficiency and applicability of LLMs through
low-bit quantization.

摘要：大型語言模型 (LLM) 在自然語言處理方面取得了顯著進展，在各種任務中展現出卓越的表現。然而，昂貴的記憶體和運算需求對其實際部署構成了重大挑戰。低位元量化已成為緩解這些挑戰的一種關鍵方法，透過減少模型參數、激活和梯度的位元寬度，從而降低記憶體使用量和運算需求。本文對針對 LLM 量身打造的低位元量化方法進行了全面的調查，涵蓋了基本原理、系統實作和演算法策略。首先介紹了低位元 LLM 的基本概念和新的資料格式概觀，接著回顧了在各種硬體平台上促進低位元 LLM 的框架和系統。然後，我們分類和分析了用於有效低位元訓練和推論 LLM 的技術和工具包。最後，我們以討論低位元 LLM 的未來趨勢和潛在進展作為結論。我們從基本、系統和演算法的角度進行系統性概述，可以為透過低位元量化提升 LLM 的效率和適用性的後續工作提供有價值的見解和指導方針。

##### **CaBRNet, an open-source library for developing and evaluating Case-Based Reasoning Models**
2409.16693v1 by Romain Xu-Darme, Aymeric Varasse, Alban Grastien, Julien Girard, Zakaria Chihani

In the field of explainable AI, a vibrant effort is dedicated to the design
of self-explainable models, as a more principled alternative to post-hoc
methods that attempt to explain the decisions after a model opaquely makes
them. However, this productive line of research suffers from common downsides:
lack of reproducibility, unfeasible comparison, diverging standards. In this
paper, we propose CaBRNet, an open-source, modular, backward-compatible
framework for Case-Based Reasoning Networks:
https://github.com/aiser-team/cabrnet.

摘要：在可解釋 AI 領域中，一項充滿活力的工作專注於設計可自解釋模型，作為一種更具原則性的替代方案，用於事後方法，試圖在模型不透明地做出決策後解釋這些決策。然而，這條富有成效的研究路線存在一些常見的缺點：缺乏可重複性、不可行的比較、標準不一。在本文中，我們提出 CaBRNet，這是一個開源、模組化、向後相容的框架，用於基於案例的推理網路：
https://github.com/aiser-team/cabrnet。

##### **Layout-Corrector: Alleviating Layout Sticking Phenomenon in Discrete Diffusion Model**
2409.16689v1 by Shoma Iwai, Atsuki Osanai, Shunsuke Kitada, Shinichiro Omachi

Layout generation is a task to synthesize a harmonious layout with elements
characterized by attributes such as category, position, and size. Human
designers experiment with the placement and modification of elements to create
aesthetic layouts, however, we observed that current discrete diffusion models
(DDMs) struggle to correct inharmonious layouts after they have been generated.
In this paper, we first provide novel insights into layout sticking phenomenon
in DDMs and then propose a simple yet effective layout-assessment module
Layout-Corrector, which works in conjunction with existing DDMs to address the
layout sticking problem. We present a learning-based module capable of
identifying inharmonious elements within layouts, considering overall layout
harmony characterized by complex composition. During the generation process,
Layout-Corrector evaluates the correctness of each token in the generated
layout, reinitializing those with low scores to the ungenerated state. The DDM
then uses the high-scored tokens as clues to regenerate the harmonized tokens.
Layout-Corrector, tested on common benchmarks, consistently boosts
layout-generation performance when in conjunction with various state-of-the-art
DDMs. Furthermore, our extensive analysis demonstrates that the
Layout-Corrector (1) successfully identifies erroneous tokens, (2) facilitates
control over the fidelity-diversity trade-off, and (3) significantly mitigates
the performance drop associated with fast sampling.

摘要：版面生成是綜合元素的一項任務，這些元素的特徵在於類別、位置和大小等屬性。人類設計師會嘗試元素的擺放和修改，以建立美觀的版面，然而，我們觀察到目前的離散擴散模型 (DDM) 在生成不協調的版面後，難以進行修正。在本文中，我們首先提供對 DDM 中版面黏著現象的新見解，然後提出一個簡單但有效的版面評估模組 Layout-Corrector，它與現有的 DDM 協同運作，以解決版面黏著問題。我們提出一個基於學習的模組，能夠識別版面中的不協調元素，並考量由複雜組合所特徵化的整體版面和諧性。在生成過程中，Layout-Corrector 評估生成版面中每個標記的正確性，將評分較低的標記重新初始化為未生成狀態。然後，DDM 使用高分標記作為線索，重新生成和諧的標記。Layout-Corrector 在常見的基準測試中經過測試，與各種最先進的 DDM 結合使用時，始終提升版面生成效能。此外，我們廣泛的分析證明，Layout-Corrector (1) 成功識別錯誤標記，(2) 促進對保真度和多樣性權衡的控制，以及 (3) 大幅減輕與快速取樣相關的效能下降。

##### **MSI-Agent: Incorporating Multi-Scale Insight into Embodied Agents for Superior Planning and Decision-Making**
2409.16686v1 by Dayuan Fu, Biqing Qi, Yihuai Gao, Che Jiang, Guanting Dong, Bowen Zhou

Long-term memory is significant for agents, in which insights play a crucial
role. However, the emergence of irrelevant insight and the lack of general
insight can greatly undermine the effectiveness of insight. To solve this
problem, in this paper, we introduce Multi-Scale Insight Agent (MSI-Agent), an
embodied agent designed to improve LLMs' planning and decision-making ability
by summarizing and utilizing insight effectively across different scales. MSI
achieves this through the experience selector, insight generator, and insight
selector. Leveraging a three-part pipeline, MSI can generate task-specific and
high-level insight, store it in a database, and then use relevant insight from
it to aid in decision-making. Our experiments show that MSI outperforms another
insight strategy when planning by GPT3.5. Moreover, We delve into the
strategies for selecting seed experience and insight, aiming to provide LLM
with more useful and relevant insight for better decision-making. Our
observations also indicate that MSI exhibits better robustness when facing
domain-shifting scenarios.

摘要：長期記憶對於智能體來說非常重要，其中見解扮演著關鍵角色。然而，無關見解的出現和一般見解的缺乏會極大地損害見解的有效性。為了解決這個問題，在本文中，我們介紹了多尺度見解智能體 (MSI-Agent)，這是一個具象智能體，旨在透過有效地總結和利用不同尺度的見解來改善 LLM 的規劃和決策能力。MSI 透過經驗選擇器、見解產生器和見解選擇器來實現這一點。MSI 利用一個由三部分組成的管線，可以產生特定於任務和高層級的見解，將其儲存在資料庫中，然後從中使用相關見解來協助決策。我們的實驗顯示，MSI 在 GPT3.5 規劃時優於其他見解策略。此外，我們深入探討了選擇種子經驗和見解的策略，旨在為 LLM 提供更有用且相關的見解，以做出更好的決策。我們的觀察結果還表明，MSI 在面對領域轉換場景時表現出更好的穩健性。

##### **Erase then Rectify: A Training-Free Parameter Editing Approach for Cost-Effective Graph Unlearning**
2409.16684v1 by Zhe-Rui Yang, Jindong Han, Chang-Dong Wang, Hao Liu

Graph unlearning, which aims to eliminate the influence of specific nodes,
edges, or attributes from a trained Graph Neural Network (GNN), is essential in
applications where privacy, bias, or data obsolescence is a concern. However,
existing graph unlearning techniques often necessitate additional training on
the remaining data, leading to significant computational costs, particularly
with large-scale graphs. To address these challenges, we propose a two-stage
training-free approach, Erase then Rectify (ETR), designed for efficient and
scalable graph unlearning while preserving the model utility. Specifically, we
first build a theoretical foundation showing that masking parameters critical
for unlearned samples enables effective unlearning. Building on this insight,
the Erase stage strategically edits model parameters to eliminate the impact of
unlearned samples and their propagated influence on intercorrelated nodes. To
further ensure the GNN's utility, the Rectify stage devises a gradient
approximation method to estimate the model's gradient on the remaining dataset,
which is then used to enhance model performance. Overall, ETR achieves graph
unlearning without additional training or full training data access,
significantly reducing computational overhead and preserving data privacy.
Extensive experiments on seven public datasets demonstrate the consistent
superiority of ETR in model utility, unlearning efficiency, and unlearning
effectiveness, establishing it as a promising solution for real-world graph
unlearning challenges.

摘要：圖表反學習旨在消除特定節點、邊緣或屬性對已訓練圖神經網路 (GNN) 的影響，在隱私、偏見或資料過時為問題的應用中至關重要。然而，現有的圖表反學習技術通常需要對剩餘資料進行額外訓練，導致顯著的運算成本，特別是在大型圖表中。為了應對這些挑戰，我們提出了一個兩階段免訓練方法，即先擦除再修正 (ETR)，旨在實現高效且可擴充的圖表反學習，同時保留模型效用。具體來說，我們首先建立一個理論基礎，表明遮罩對未學習樣本至關重要的參數可以實現有效的反學習。根據這個見解，擦除階段策略性地編輯模型參數，以消除未學習樣本及其對相互關聯節點的傳播影響。為了進一步確保 GNN 的效用，修正階段設計了一種梯度近似方法來估計模型在剩餘資料集上的梯度，然後用於增強模型效能。總體而言，ETR 在沒有額外訓練或完全訓練資料存取的情況下實現了圖表反學習，顯著降低了運算負擔並維護了資料隱私。在七個公開資料集上的廣泛實驗證明了 ETR 在模型效用、反學習效率和反學習有效性方面的一致優越性，使其成為解決現實世界圖表反學習挑戰的有希望的解決方案。

##### **SynTQA: Synergistic Table-based Question Answering via Mixture of Text-to-SQL and E2E TQA**
2409.16682v1 by Siyue Zhang, Anh Tuan Luu, Chen Zhao

Text-to-SQL parsing and end-to-end question answering (E2E TQA) are two main
approaches for Table-based Question Answering task. Despite success on multiple
benchmarks, they have yet to be compared and their synergy remains unexplored.
In this paper, we identify different strengths and weaknesses through
evaluating state-of-the-art models on benchmark datasets: Text-to-SQL
demonstrates superiority in handling questions involving arithmetic operations
and long tables; E2E TQA excels in addressing ambiguous questions, non-standard
table schema, and complex table contents. To combine both strengths, we propose
a Synergistic Table-based Question Answering approach that integrate different
models via answer selection, which is agnostic to any model types. Further
experiments validate that ensembling models by either feature-based or
LLM-based answer selector significantly improves the performance over
individual models.

摘要：文本到 SQL 解析和端到端問題解答 (E2E TQA) 是表格問題解答任務的兩種主要方法。儘管在多個基準測試中取得成功，但它們尚未進行比較，而且它們的協同作用仍未得到探索。在本文中，我們通過評估基準數據集上的最先進模型來識別不同的優勢和劣勢：文本到 SQL 在處理涉及算術運算和長表的查詢方面表現出優越性；E2E TQA 在解決模稜兩可的查詢、非標準表格架構和複雜表格內容方面表現出色。為了結合這兩種優勢，我們提出了一種協同表格問題解答方法，該方法通過與任何模型類型無關的答案選擇整合不同的模型。進一步的實驗驗證了通過基於特徵或基於 LLM 的答案選擇器組合模型顯著優於單個模型的性能。

##### **Emotional Dimension Control in Language Model-Based Text-to-Speech: Spanning a Broad Spectrum of Human Emotions**
2409.16681v1 by Kun Zhou, You Zhang, Shengkui Zhao, Hao Wang, Zexu Pan, Dianwen Ng, Chong Zhang, Chongjia Ni, Yukun Ma, Trung Hieu Nguyen, Jia Qi Yip, Bin Ma

Current emotional text-to-speech (TTS) systems face challenges in mimicking a
broad spectrum of human emotions due to the inherent complexity of emotions and
limitations in emotional speech datasets and models. This paper proposes a TTS
framework that facilitates control over pleasure, arousal, and dominance, and
can synthesize a diversity of emotional styles without requiring any emotional
speech data during TTS training. We train an emotional attribute predictor
using only categorical labels from speech data, aligning with psychological
research and incorporating anchored dimensionality reduction on self-supervised
learning (SSL) features. The TTS framework converts text inputs into phonetic
tokens via an autoregressive language model and uses pseudo-emotional
dimensions to guide the parallel prediction of fine-grained acoustic details.
Experiments conducted on the LibriTTS dataset demonstrate that our framework
can synthesize speech with enhanced naturalness and a variety of emotional
styles by effectively controlling emotional dimensions, even without the
inclusion of any emotional speech during TTS training.

摘要：當前的語音合成（TTS）系統在模擬人類廣泛的情緒時會面臨挑戰，原因在於情緒的複雜性以及情緒化語音資料集和模型的限制。本論文提出了一個 TTS 架構，可以輕鬆控制愉悅、激動和支配，且無需在 TTS 訓練期間使用任何情緒化語音資料就能合成各種情緒風格。我們只使用語音資料中的分類標籤訓練情緒屬性預測器，並與心理學研究相符，並將錨定降維納入自監督學習（SSL）功能。TTS 架構透過自迴歸語言模型將文字輸入轉換為音標符號，並使用偽情緒維度來引導對細緻聲學細節的並行預測。在 LibriTTS 資料集上進行的實驗表明，我們的架構可以合成自然度更高的語音和各種情緒風格，即使在 TTS 訓練期間沒有加入任何情緒化語音也能有效控制情緒維度。

##### **TSBP: Improving Object Detection in Histology Images via Test-time Self-guided Bounding-box Propagation**
2409.16678v1 by Tingting Yang, Liang Xiao, Yizhe Zhang

A global threshold (e.g., 0.5) is often applied to determine which bounding
boxes should be included in the final results for an object detection task. A
higher threshold reduces false positives but may result in missing a
significant portion of true positives. A lower threshold can increase detection
recall but may also result in more false positives. Because of this, using a
preset global threshold (e.g., 0.5) applied to all the bounding box candidates
may lead to suboptimal solutions. In this paper, we propose a Test-time
Self-guided Bounding-box Propagation (TSBP) method, leveraging Earth Mover's
Distance (EMD) to enhance object detection in histology images. TSBP utilizes
bounding boxes with high confidence to influence those with low confidence,
leveraging visual similarities between them. This propagation mechanism enables
bounding boxes to be selected in a controllable, explainable, and robust
manner, which surpasses the effectiveness of using simple thresholds and
uncertainty calibration methods. Importantly, TSBP does not necessitate
additional labeled samples for model training or parameter estimation, unlike
calibration methods. We conduct experiments on gland detection and cell
detection tasks in histology images. The results show that our proposed TSBP
significantly improves detection outcomes when working in conjunction with
state-of-the-art deep learning-based detection networks. Compared to other
methods such as uncertainty calibration, TSBP yields more robust and accurate
object detection predictions while using no additional labeled samples. The
code is available at https://github.com/jwhgdeu/TSBP.

摘要：<paragraph>在目標偵測任務中，通常會套用一個全域閾值（例如 0.5）來決定哪些邊界框應包含在最終結果中。較高的閾值會降低誤報，但可能會導致遺漏大量真陽性。較低的閾值會提高偵測召回率，但也可能導致更多誤報。因此，將預設的全域閾值（例如 0.5）套用至所有邊界框候選項可能會導致次佳解。在本文中，我們提出一個測試時間自導邊界框傳播 (TSBP) 方法，利用 Earth Mover's Distance (EMD) 來增強組織學影像中的目標偵測。TSBP 利用高信心的邊界框來影響低信心的邊界框，並利用它們之間的視覺相似性。這種傳播機制讓邊界框能夠以可控、可解釋且穩健的方式進行選擇，這超越了使用簡單閾值和不確定性校正方法的有效性。重要的是，與校正方法不同，TSBP 不需要額外標記樣本進行模型訓練或參數估計。我們針對組織學影像中的腺體偵測和細胞偵測任務進行實驗。結果顯示，我們提出的 TSBP 在與最先進的基於深度學習的偵測網路結合使用時，顯著改善了偵測結果。與其他方法（例如不確定性校正）相比，TSBP 在不使用任何額外標記樣本的情況下，產生更穩健且準確的目標偵測預測。程式碼可於 https://github.com/jwhgdeu/TSBP 取得。</paragraph>

##### **SWE2: SubWord Enriched and Significant Word Emphasized Framework for Hate Speech Detection**
2409.16673v1 by Guanyi Mou, Pengyi Ye, Kyumin Lee

Hate speech detection on online social networks has become one of the
emerging hot topics in recent years. With the broad spread and fast propagation
speed across online social networks, hate speech makes significant impacts on
society by increasing prejudice and hurting people. Therefore, there are
aroused attention and concern from both industry and academia. In this paper,
we address the hate speech problem and propose a novel hate speech detection
framework called SWE2, which only relies on the content of messages and
automatically identifies hate speech. In particular, our framework exploits
both word-level semantic information and sub-word knowledge. It is intuitively
persuasive and also practically performs well under a situation with/without
character-level adversarial attack. Experimental results show that our proposed
model achieves 0.975 accuracy and 0.953 macro F1, outperforming 7
state-of-the-art baselines under no adversarial attack. Our model robustly and
significantly performed well under extreme adversarial attack (manipulation of
50% messages), achieving 0.967 accuracy and 0.934 macro F1.

摘要：近幾年來，在線上社群網路中，仇恨言論偵測已成為新興熱門議題之一。仇恨言論在線上社群網路中廣泛散佈和快速傳播，透過加劇偏見和傷害他人，對社會造成重大影響。因此，無論是業界或學術界都引起了關注和重視。在本文中，我們探討仇恨言論問題，並提出一個名為 SWE2 的全新仇恨言論偵測架構，它僅依賴訊息內容，並自動辨識仇恨言論。特別是，我們的架構同時利用字詞層級的語意資訊和字詞知識。它直觀且具有說服力，在有/無字元層級對抗攻擊的情況下，實際執行效果也很好。實驗結果顯示，我們提出的模型在沒有對抗攻擊的情況下，達到了 0.975 的準確度和 0.953 的巨集 F1，優於 7 個最先進的基準。我們的模型在極端的對抗攻擊（50% 訊息遭竄改）下表現得相當穩健且出色，達到了 0.967 的準確度和 0.934 的巨集 F1。

##### **GraphLoRA: Structure-Aware Contrastive Low-Rank Adaptation for Cross-Graph Transfer Learning**
2409.16670v1 by Zhe-Rui Yang, Jindong Han, Chang-Dong Wang, Hao Liu

Graph Neural Networks (GNNs) have demonstrated remarkable proficiency in
handling a range of graph analytical tasks across various domains, such as
e-commerce and social networks. Despite their versatility, GNNs face
significant challenges in transferability, limiting their utility in real-world
applications. Existing research in GNN transfer learning overlooks
discrepancies in distribution among various graph datasets, facing challenges
when transferring across different distributions. How to effectively adopt a
well-trained GNN to new graphs with varying feature and structural
distributions remains an under-explored problem. Taking inspiration from the
success of Low-Rank Adaptation (LoRA) in adapting large language models to
various domains, we propose GraphLoRA, an effective and parameter-efficient
method for transferring well-trained GNNs to diverse graph domains.
Specifically, we first propose a Structure-aware Maximum Mean Discrepancy
(SMMD) to align divergent node feature distributions across source and target
graphs. Moreover, we introduce low-rank adaptation by injecting a small
trainable GNN alongside the pre-trained one, effectively bridging structural
distribution gaps while mitigating the catastrophic forgetting. Additionally, a
structure-aware regularization objective is proposed to enhance the
adaptability of the pre-trained GNN to target graph with scarce supervision
labels. Extensive experiments on six real-world datasets demonstrate the
effectiveness of GraphLoRA against eleven baselines by tuning only 20% of
parameters, even across disparate graph domains. The code is available at
https://anonymous.4open.science/r/GraphLoRA.

摘要：圖形神經網路 (GNN) 已展現出在各種領域處理一系列圖形分析任務的卓越能力，例如電子商務和社群網路。儘管 GNN 具有多功能性，但在可轉移性方面仍面臨重大挑戰，限制了它們在現實世界應用中的效用。現有的 GNN 轉移學習研究忽視了各種圖形資料集之間的分布差異，在跨不同分布轉移時面臨挑戰。如何有效地將訓練良好的 GNN 應用於具有不同特徵和結構分布的新圖形，仍然是一個尚未充分探討的問題。從低秩適應 (LoRA) 在將大型語言模型適應到各種領域方面獲得的成功中汲取靈感，我們提出了 GraphLoRA，這是一種有效且參數效率高的方法，可用於將訓練良好的 GNN 轉移到不同的圖形領域。具體來說，我們首先提出一個結構感知最大平均差異 (SMMD) 來調整來源和目標圖形中的不同節點特徵分布。此外，我們通過在預先訓練的 GNN 旁邊注入一個小的可訓練 GNN 來引入低秩適應，從而有效地彌合結構分布差距，同時減輕災難性遺忘。此外，還提出了結構感知正則化目標，以增強預先訓練的 GNN 對具有稀疏監督標籤的目標圖形的適應性。在六個真實世界資料集上的大量實驗證明了 GraphLoRA 的有效性，它僅調整了 20% 的參數，即使在不同的圖形領域中也能夠勝過十一種基準。程式碼可在 https://anonymous.4open.science/r/GraphLoRA 取得。

##### **Topic-aware Causal Intervention for Counterfactual Detection**
2409.16668v1 by Thong Nguyen, Truc-My Nguyen

Counterfactual statements, which describe events that did not or cannot take
place, are beneficial to numerous NLP applications. Hence, we consider the
problem of counterfactual detection (CFD) and seek to enhance the CFD models.
Previous models are reliant on clue phrases to predict counterfactuality, so
they suffer from significant performance drop when clue phrase hints do not
exist during testing. Moreover, these models tend to predict
non-counterfactuals over counterfactuals. To address these issues, we propose
to integrate neural topic model into the CFD model to capture the global
semantics of the input statement. We continue to causally intervene the hidden
representations of the CFD model to balance the effect of the class labels.
Extensive experiments show that our approach outperforms previous
state-of-the-art CFD and bias-resolving methods in both the CFD and other
bias-sensitive tasks.

摘要：反事實陳述描述了未發生或無法發生的事件，對許多 NLP 應用有益。因此，我們考慮反事實檢測 (CFD) 的問題，並尋求增強 CFD 模型。先前的模型依賴於線索短語來預測反事實，因此在測試期間沒有線索短語提示時，它們的效能會大幅下降。此外，這些模型傾向於預測非反事實而不是反事實。為了解決這些問題，我們建議將神經主題模型整合到 CFD 模型中，以擷取輸入陳述的整體語義。我們繼續因果干預 CFD 模型的隱藏表示，以平衡類別標籤的影響。廣泛的實驗表明，我們的做法在 CFD 和其他偏見敏感任務中都優於先前的最先進 CFD 和偏見解決方法。

##### **A Character-Centric Creative Story Generation via Imagination**
2409.16667v1 by Kyeongman Park, Minbeom Kim, Kyomin Jung

Creative story generation with diverse and detailed story elements is a
long-standing goal for large language models. While existing methodologies
generate long and coherent stories, they fall significantly short of human
capabilities in terms of diversity and character detail. To address this, we
introduce a novel story generation framework called CCI (Character-centric
Creative story generation via Imagination). CCI features two innovative modules
for creative story generation: IG (Image-Guided Imagination) and MW
(Multi-Writer model). In the IG module, we utilize DALL-E 3 to create visual
representations of key story elements. The IG generates more novel and concrete
characters, backgrounds, and main plots than text-only methods. The MW module
uses these story elements created by IG to generate multiple description
candidates for the protagonist and select the best one. This method
incorporates vivid and rich character descriptions into the story. We compared
the stories generated by CCI and baseline models through human evaluation and
statistical analysis. The results showed significant improvements in the
creativity. Furthermore, by enabling interactive multi-modal story generation
with users, we have opened up possibilities for human-LLM integration in
cultural development.

摘要：運用多元且詳細的故事元素進行創意故事生成，一直是大型語言模型的長期目標。儘管現有的方法論可產生長篇且連貫的故事，但在多元性和角色細節方面，卻遠遠不及人類的能力。為了解決這個問題，我們提出一個名為 CCI（以角色為中心，透過想像進行創意故事生成）的新穎故事生成架構。CCI 具備兩個用於創意故事生成的創新模組：IG（影像引導想像）和 MW（多作者模型）。在 IG 模組中，我們利用 DALL-E 3 來建立關鍵故事元素的視覺表示。IG 產生的角色、背景和主線劇情，比純文字方法更新穎且具體。MW 模組使用 IG 建立的這些故事元素，為主角產生多個描述候選，並選出最佳者。此方法將生動且豐富的角色描述納入故事中。我們透過人工評估和統計分析，比較了 CCI 和基準模型所產生的故事。結果顯示在創意方面有顯著的進步。此外，透過啟用與使用者互動的多模態故事生成，我們開啟了人類與大型語言模型在文化發展中整合的可能性。

##### **Pre-trained Language Models Return Distinguishable Probability Distributions to Unfaithfully Hallucinated Texts**
2409.16658v1 by Taehun Cha, Donghun Lee

In this work, we show the pre-trained language models return distinguishable
generation probability and uncertainty distribution to unfaithfully
hallucinated texts, regardless of their size and structure. By examining 24
models on 6 data sets, we find out that 88-98% of cases return statistically
significantly distinguishable generation probability and uncertainty
distributions. Using this general phenomenon, we showcase a
hallucination-reducing training algorithm. Our algorithm outperforms other
baselines by achieving higher faithfulness metrics while maintaining sound
general text quality measures.

摘要：在這項工作中，我們展示了預訓練的語言模型，無論其大小和結構如何，都返回可區分的生成機率和不確定性分佈，以不忠實地虛構文本。透過檢視 6 個資料集上的 24 個模型，我們發現 88-98% 的案例回傳具有統計顯著區別的生成機率和不確定性分佈。使用這個一般現象，我們展示了一個減少虛構的訓練演算法。我們的演算法在維持良好的文字品質測量標準的同時，透過達成更高的忠實度指標，勝過其他基準。

##### **Speech Recognition Rescoring with Large Speech-Text Foundation Models**
2409.16654v1 by Prashanth Gurunath Shivakumar, Jari Kolehmainen, Aditya Gourav, Yi Gu, Ankur Gandhe, Ariya Rastrow, Ivan Bulyko

Large language models (LLM) have demonstrated the ability to understand human
language by leveraging large amount of text data. Automatic speech recognition
(ASR) systems are often limited by available transcribed speech data and
benefit from a second pass rescoring using LLM. Recently multi-modal large
language models, particularly speech and text foundational models have
demonstrated strong spoken language understanding. Speech-Text foundational
models leverage large amounts of unlabelled and labelled data both in speech
and text modalities to model human language. In this work, we propose novel
techniques to use multi-modal LLM for ASR rescoring. We also explore
discriminative training to further improve the foundational model rescoring
performance. We demonstrate cross-modal knowledge transfer in speech-text LLM
can benefit rescoring. Our experiments demonstrate up-to 20% relative
improvements over Whisper large ASR and up-to 15% relative improvements over
text-only LLM.

摘要：大型語言模型 (LLM) 已展現出透過大量文字資料理解人類語言的能力。自動語音辨識 (ASR) 系統通常受到可用轉錄語音資料的限制，並受益於使用 LLM 進行二次評分。最近，多模態大型語言模型，特別是語音和文字基礎模型，已展現出強大的口語理解能力。語音文字基礎模型利用大量未標記和標記資料，在語音和文字模式中建構人類語言模型。在這項工作中，我們提出使用多模態 LLM 進行 ASR 評分的新技術。我們也探討判別訓練，以進一步改善基礎模型的評分表現。我們證明語音文字 LLM 中的跨模態知識轉移可以改善評分。我們的實驗證明，相較於 Whisper 大型 ASR，我們的模型有高達 20% 的相對改善；相較於純文字 LLM，我們的模型有高達 15% 的相對改善。

##### **Progressive Representation Learning for Real-Time UAV Tracking**
2409.16652v1 by Changhong Fu, Xiang Lei, Haobo Zuo, Liangliang Yao, Guangze Zheng, Jia Pan

Visual object tracking has significantly promoted autonomous applications for
unmanned aerial vehicles (UAVs). However, learning robust object
representations for UAV tracking is especially challenging in complex dynamic
environments, when confronted with aspect ratio change and occlusion. These
challenges severely alter the original information of the object. To handle the
above issues, this work proposes a novel progressive representation learning
framework for UAV tracking, i.e., PRL-Track. Specifically, PRL-Track is divided
into coarse representation learning and fine representation learning. For
coarse representation learning, two innovative regulators, which rely on
appearance and semantic information, are designed to mitigate appearance
interference and capture semantic information. Furthermore, for fine
representation learning, a new hierarchical modeling generator is developed to
intertwine coarse object representations. Exhaustive experiments demonstrate
that the proposed PRL-Track delivers exceptional performance on three
authoritative UAV tracking benchmarks. Real-world tests indicate that the
proposed PRL-Track realizes superior tracking performance with 42.6 frames per
second on the typical UAV platform equipped with an edge smart camera. The
code, model, and demo videos are available at
\url{https://github.com/vision4robotics/PRL-Track}.

摘要：視覺物件追蹤已大幅提升無人機 (UAV) 的自主應用。然而，在複雜的動態環境中，學習穩健的物件表示以進行無人機追蹤特別具有挑戰性，特別是在面對長寬比變動和遮擋時。這些挑戰會嚴重改變物件的原始資訊。為了處理上述問題，這項研究提出一個新的漸進式表示學習架構以進行無人機追蹤，亦即 PRL-Track。具體來說，PRL-Track 分為粗略表示學習和精細表示學習。對於粗略表示學習，設計了兩個創新的調節器，它們依賴於外觀和語義資訊，以減輕外觀干擾並擷取語義資訊。此外，對於精細表示學習，開發了一個新的階層式建模產生器，以交織粗略物件表示。詳盡的實驗證明，所提出的 PRL-Track 在三個權威的無人機追蹤基準上提供了非凡的效能。真實世界的測試表明，所提出的 PRL-Track 在配備邊緣智慧相機的典型無人機平台上以每秒 42.6 幀的速度實現了優異的追蹤效能。程式碼、模型和示範影片可在 \url{https://github.com/vision4robotics/PRL-Track} 取得。

##### **Domain-Independent Automatic Generation of Descriptive Texts for Time-Series Data**
2409.16647v1 by Kota Dohi, Aoi Ito, Harsh Purohit, Tomoya Nishida, Takashi Endo, Yohei Kawaguchi

Due to scarcity of time-series data annotated with descriptive texts,
training a model to generate descriptive texts for time-series data is
challenging. In this study, we propose a method to systematically generate
domain-independent descriptive texts from time-series data. We identify two
distinct approaches for creating pairs of time-series data and descriptive
texts: the forward approach and the backward approach. By implementing the
novel backward approach, we create the Temporal Automated Captions for
Observations (TACO) dataset. Experimental results demonstrate that a
contrastive learning based model trained using the TACO dataset is capable of
generating descriptive texts for time-series data in novel domains.

摘要：由於標有描述文字的時間序列資料稀少，訓練模型來為時間序列資料產生描述文字是一項挑戰。在本研究中，我們提出了一種從時間序列資料系統性產生與領域無關的描述文字的方法。我們找出兩種不同的方法來建立時間序列資料和描述文字的配對：正向方法和反向方法。透過實作新穎的反向方法，我們建立了觀測時間自動標題 (TACO) 資料集。實驗結果證明，使用 TACO 資料集訓練的對比學習模型能夠為新領域的時間序列資料產生描述文字。

##### **Cross-Lingual and Cross-Cultural Variation in Image Descriptions**
2409.16646v1 by Uri Berger, Edoardo M. Ponti

Do speakers of different languages talk differently about what they see?
Behavioural and cognitive studies report cultural effects on perception;
however, these are mostly limited in scope and hard to replicate. In this work,
we conduct the first large-scale empirical study of cross-lingual variation in
image descriptions. Using a multimodal dataset with 31 languages and images
from diverse locations, we develop a method to accurately identify entities
mentioned in captions and present in the images, then measure how they vary
across languages. Our analysis reveals that pairs of languages that are
geographically or genetically closer tend to mention the same entities more
frequently. We also identify entity categories whose saliency is universally
high (such as animate beings), low (clothing accessories) or displaying high
variance across languages (landscape). In a case study, we measure the
differences in a specific language pair (e.g., Japanese mentions clothing far
more frequently than English). Furthermore, our method corroborates previous
small-scale studies, including 1) Rosch et al. (1976)'s theory of basic-level
categories, demonstrating a preference for entities that are neither too
generic nor too specific, and 2) Miyamoto et al. (2006)'s hypothesis that
environments afford patterns of perception, such as entity counts. Overall, our
work reveals the presence of both universal and culture-specific patterns in
entity mentions.

摘要：不同語言的說話者，對於他們所看到的事物，是否會有不同的談論方式？
行為和認知研究報告了文化對認知的影響；
然而，這些影響大多範圍有限，且難以複製。在本文中，
我們進行了第一個關於跨語言影像描述變化的廣泛實證研究。使用一個包含 31 種語言和來自不同地點的影像的多模態資料集，我們開發了一個方法來準確識別說明文字中提到的實體，並顯示在影像中，然後測量它們在不同語言中的變化。我們的分析顯示，地理或遺傳上較接近的語言對，傾向於更頻繁地提及相同的實體。我們還識別出顯著性普遍較高（例如有生命的生物）、較低（服裝配件）或在不同語言中顯示出高變異性的實體類別（景觀）。在一個案例研究中，我們測量特定語言對的差異（例如，日文比英文更頻繁地提及服裝）。此外，我們的研究方法證實了先前的中小型研究，包括 1) Rosch et al. (1976) 的基本層級類別理論，證明了對既不太過概括也不太過具體的實體的偏好，以及 2) Miyamoto et al. (2006) 的假設，即環境提供了認知模式，例如實體計數。總的來說，我們的研究揭示了實體提及中普遍和特定於文化的模式的存在。

##### **Task Addition in Multi-Task Learning by Geometrical Alignment**
2409.16645v1 by Soorin Yim, Dae-Woong Jeong, Sung Moon Ko, Sumin Lee, Hyunseung Kim, Chanhui Lee, Sehui Han

Training deep learning models on limited data while maintaining
generalization is one of the fundamental challenges in molecular property
prediction. One effective solution is transferring knowledge extracted from
abundant datasets to those with scarce data. Recently, a novel algorithm called
Geometrically Aligned Transfer Encoder (GATE) has been introduced, which uses
soft parameter sharing by aligning the geometrical shapes of task-specific
latent spaces. However, GATE faces limitations in scaling to multiple tasks due
to computational costs. In this study, we propose a task addition approach for
GATE to improve performance on target tasks with limited data while minimizing
computational complexity. It is achieved through supervised multi-task
pre-training on a large dataset, followed by the addition and training of
task-specific modules for each target task. Our experiments demonstrate the
superior performance of the task addition strategy for GATE over conventional
multi-task methods, with comparable computational costs.

摘要：在保持泛化的同時，使用有限數據訓練深度學習模型是分子性質預測中的基本挑戰之一。一個有效的解決方案是將從豐富的數據集中提取的知識轉移到數據稀缺的數據集中。最近，一種名為幾何對齊傳輸編碼器 (GATE) 的新演算法已經被引入，它通過對齊特定於任務的潛在空間的幾何形狀來使用軟參數共享。然而，GATE 由於計算成本，在擴展到多個任務時面臨限制。在本研究中，我們提出了一種任務添加方法，用於 GATE 以提高目標任務在數據有限的情況下的性能，同時最小化計算複雜度。它是通過在大型數據集上進行監督式多任務預訓練，然後為每個目標任務添加和訓練特定於任務的模組來實現的。我們的實驗證明了任務添加策略對 GATE 的優異性能優於傳統的多任務方法，並且具有可比較的計算成本。

##### **Enabling Auditory Large Language Models for Automatic Speech Quality Evaluation**
2409.16644v1 by Siyin Wang, Wenyi Yu, Yudong Yang, Changli Tang, Yixuan Li, Jimin Zhuang, Xianzhao Chen, Xiaohai Tian, Jun Zhang, Guangzhi Sun, Lu Lu, Chao Zhang

Speech quality assessment typically requires evaluating audio from multiple
aspects, such as mean opinion score (MOS) and speaker similarity (SIM) etc.,
which can be challenging to cover using one small model designed for a single
task. In this paper, we propose leveraging recently introduced auditory large
language models (LLMs) for automatic speech quality assessment. By employing
task-specific prompts, auditory LLMs are finetuned to predict MOS, SIM and A/B
testing results, which are commonly used for evaluating text-to-speech systems.
Additionally, the finetuned auditory LLM is able to generate natural language
descriptions assessing aspects like noisiness, distortion, discontinuity, and
overall quality, providing more interpretable outputs. Extensive experiments
have been performed on the NISQA, BVCC, SOMOS and VoxSim speech quality
datasets, using open-source auditory LLMs such as SALMONN, Qwen-Audio, and
Qwen2-Audio. For the natural language descriptions task, a commercial model
Google Gemini 1.5 Pro is also evaluated. The results demonstrate that auditory
LLMs achieve competitive performance compared to state-of-the-art task-specific
small models in predicting MOS and SIM, while also delivering promising results
in A/B testing and natural language descriptions. Our data processing scripts
and finetuned model checkpoints will be released upon acceptance.

摘要：語音品質評估通常需要從多個面向評估音訊，例如平均意見分數 (MOS) 和說話者相似度 (SIM) 等，而使用針對單一任務設計的小型模型來涵蓋這些面向可能會是一項挑戰。在本文中，我們提議利用最近推出的聽覺大型語言模型 (LLM) 來進行自動語音品質評估。透過採用特定於任務的提示，聽覺 LLM 會經過微調，以預測 MOS、SIM 和 A/B 測試結果，這些結果通常用於評估文字轉語音系統。此外，經過微調的聽覺 LLM 能夠產生自然語言描述，評估雜訊、失真、不連續性以及整體品質等面向，提供更易於理解的輸出。我們已經在 NISQA、BVCC、SOMOS 和 VoxSim 語音品質資料集上執行廣泛的實驗，使用 SALMONN、Qwen-Audio 和 Qwen2-Audio 等開源聽覺 LLM。對於自然語言描述任務，我們也評估了商用模型 Google Gemini 1.5 Pro。結果顯示，與針對特定任務的最新小型模型相比，聽覺 LLM 在預測 MOS 和 SIM 時達到了有競爭力的效能，同時在 A/B 測試和自然語言描述中也提供了有希望的結果。我們的資料處理腳本和經過微調的模型檢查點將在獲得接受後釋出。

##### **Training Language Models to Win Debates with Self-Play Improves Judge Accuracy**
2409.16636v1 by Samuel Arnesen, David Rein, Julian Michael

We test the robustness of debate as a method of scalable oversight by
training models to debate with data generated via self-play. In a long-context
reading comprehension task, we find that language model based evaluators answer
questions more accurately when judging models optimized to win debates. By
contrast, we find no such relationship for consultancy models trained to
persuade a judge without an opposing debater present. In quantitative and
qualitative comparisons between our debate models and novel consultancy
baselines, we find evidence that debate training encourages stronger and more
informative arguments, showing promise that it can help provide high-quality
supervision for tasks that are difficult to directly evaluate.

摘要：我們透過訓練模型與透過自我對戰產生資料來辯論，來測試辯論作為可擴充監督方法的穩健性。在長語境閱讀理解任務中，我們發現基於語言模型的評估者在評斷最佳化以贏得辯論的模型時，能更準確地回答問題。相反地，我們發現對於在沒有反方辯論者的情況下訓練，以說服評審的諮詢模型，並不存在這種關係。在我們的辯論模型和新諮詢基準之間的量化和定性比較中，我們發現證據表明辯論訓練鼓勵更強而有力的論點，顯示它有望為難以直接評估的任務提供高品質的監督。

##### **Judgment of Thoughts: Courtroom of the Binary Logical Reasoning in Large Language Models**
2409.16635v1 by Sungjune Park, Daeseon Choi

This paper proposes a novel prompt engineering technique called Judgment of
Thought (JoT) that is specifically tailored for binary logical reasoning tasks.
JoT employs three roles$\unicode{x2014}$lawyer, prosecutor, and
judge$\unicode{x2014}$to facilitate more reliable and accurate reasoning by the
model. In this framework, the judge utilizes a high$\unicode{x2010}$level
model, while the lawyer and prosecutor utilize low$\unicode{x2010}$level
models. This structure helps the judge better understand the responses from
both the lawyer and prosecutor, enabling a more accurate judgment. Experimental
results on large language model (LLM) benchmark datasets, such as BigBenchHard
and Winogrande, demonstrate that JoT outperforms existing methods, including
Chain of Thought (CoT) and Self$\unicode{x2010}$Consistency (SC), in binary
logical reasoning tasks. Additionally, in real$\unicode{x2010}$world tasks,
such as Fake News Detection and SMS Spam Detection, JoT shows comparable or
improved performance compared to existing techniques. JoT significantly
enhances the accuracy and reliability of models in binary reasoning tasks and
show potential for practical applicability across various domains. Future
research should aim to further broaden the applicability of JoT and optimize
its implementation for real$\unicode{x2010}$world
problem$\unicode{x2010}$solving.

摘要：本文提出了一種名為「思考判斷」(JoT) 的新穎提示工程技術，專門針對二元邏輯推理任務而設計。
JoT 採用了三種角色：律師、檢察官和法官，以促進模型更可靠、更準確的推理。在此架構中，法官使用高層級模型，而律師和檢察官則使用低層級模型。這種結構有助於法官更好地理解律師和檢察官的回應，從而做出更準確的判斷。在大型語言模型 (LLM) 基準數據集（例如 BigBenchHard 和 Winogrande）上的實驗結果表明，JoT 在二元邏輯推理任務中優於現有方法，包括思考鏈 (CoT) 和自我一致性 (SC)。此外，在現實世界任務中，例如假新聞檢測和簡訊垃圾郵件檢測，JoT 與現有技術相比表現相當或有所提升。JoT 大幅提升了模型在二元推理任務中的準確性和可靠性，並顯示出在各種領域中實際應用的潛力。未來的研究應旨在進一步擴展 JoT 的適用性，並針對現實世界的問題解決方案最佳化其實作。

##### **Stochastic Subsampling With Average Pooling**
2409.16630v1 by Bum Jun Kim, Sang Woo Kim

Regularization of deep neural networks has been an important issue to achieve
higher generalization performance without overfitting problems. Although the
popular method of Dropout provides a regularization effect, it causes
inconsistent properties in the output, which may degrade the performance of
deep neural networks. In this study, we propose a new module called stochastic
average pooling, which incorporates Dropout-like stochasticity in pooling. We
describe the properties of stochastic subsampling and average pooling and
leverage them to design a module without any inconsistency problem. The
stochastic average pooling achieves a regularization effect without any
potential performance degradation due to the inconsistency issue and can easily
be plugged into existing architectures of deep neural networks. Experiments
demonstrate that replacing existing average pooling with stochastic average
pooling yields consistent improvements across a variety of tasks, datasets, and
models.

摘要：深度神经网络的正则化一直是实现更高泛化性能而不出现过拟合问题的一个重要课题。尽管流行的 Dropout 方法提供了一种正则化效果，但它会导致输出中的属性不一致，这可能会降低深度神经网络的性能。在本研究中，我们提出了一种称为随机平均池化的全新模块，它在池化中纳入了类似 Dropout 的随机性。我们描述了随机子采样和平均池化的属性，并利用它们设计了一个不存在任何不一致问题的模块。随机平均池化实现了一种正则化效果，不会因不一致问题而导致任何潜在的性能下降，并且可以轻松插入现有深度神经网络架构中。实验表明，用随机平均池化替换现有的平均池化，可以在各种任务、数据集和模型中产生一致的改进。

##### **Ascend HiFloat8 Format for Deep Learning**
2409.16626v2 by Yuanyong Luo, Zhongxing Zhang, Richard Wu, Hu Liu, Ying Jin, Kai Zheng, Minmin Wang, Zhanying He, Guipeng Hu, Luyao Chen, Tianchi Hu, Junsong Wang, Minqi Chen, Mikhaylov Dmitry, Korviakov Vladimir, Bobrin Maxim, Yuhao Hu, Guanfu Chen, Zeyi Huang

This preliminary white paper proposes a novel 8-bit floating-point data
format HiFloat8 (abbreviated as HiF8) for deep learning. HiF8 features tapered
precision. For normal value encoding, it provides 7 exponent values with 3-bit
mantissa, 8 exponent values with 2-bit mantissa, and 16 exponent values with
1-bit mantissa. For denormal value encoding, it extends the dynamic range by 7
extra powers of 2, from 31 to 38 binades (notice that FP16 covers 40 binades).
Meanwhile, HiF8 encodes all the special values except that positive zero and
negative zero are represented by only one bit-pattern. Thanks to the better
balance between precision and dynamic range, HiF8 can be simultaneously used in
both forward and backward passes of AI training. In this paper, we will
describe the definition and rounding methods of HiF8, as well as the tentative
training and inference solutions. To demonstrate the efficacy of HiF8, massive
simulation results on various neural networks, including traditional neural
networks and large language models (LLMs), will also be presented.

摘要：這份初步白皮書提出了一種創新的 8 位元浮點數資料格式 HiFloat8（簡稱 HiF8），用於深度學習。HiF8 具有漸變精度。對於一般數值編碼，它提供 7 個指數值，具有 3 位元尾數，8 個指數值，具有 2 位元尾數，以及 16 個指數值，具有 1 位元尾數。對於非正規數值編碼，它將動態範圍延伸 7 個 2 的次方，從 31 到 38 個二進位（請注意 FP16 涵蓋 40 個二進位）。同時，HiF8 編碼所有特殊值，除了正零和負零僅用一個位元模式表示。由於精度和動態範圍之間取得更好的平衡，因此 HiF8 可同時用於 AI 訓練的前向和後向傳遞。在本文中，我們將說明 HiF8 的定義和捨入方法，以及暫定的訓練和推論解決方案。為了證明 HiF8 的效能，我們還將展示各種神經網路的大量模擬結果，包括傳統神經網路和大型語言模型 (LLM)。


### Medical
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-09-25**|**Ctrl-GenAug: Controllable Generative Augmentation for Medical Sequence Classification**|Xinrui Zhou et.al.|[2409.17091v1](http://arxiv.org/abs/2409.17091v1)|null|
|**2024-09-25**|**DRIM: Learning Disentangled Representations from Incomplete Multimodal Healthcare Data**|Lucas Robinet et.al.|[2409.17055v1](http://arxiv.org/abs/2409.17055v1)|[link](https://github.com/lucas-rbnt/drim)|
|**2024-09-25**|**Using LLM for Real-Time Transcription and Summarization of Doctor-Patient Interactions into ePuskesmas in Indonesia**|Azmul Asmar Irfan et.al.|[2409.17054v1](http://arxiv.org/abs/2409.17054v1)|null|
|**2024-09-25**|**GeoBiked: A Dataset with Geometric Features and Automated Labeling Techniques to Enable Deep Generative Models in Engineering Design**|Phillip Mueller et.al.|[2409.17045v1](http://arxiv.org/abs/2409.17045v1)|null|
|**2024-09-25**|**AI-driven View Guidance System in Intra-cardiac Echocardiography Imaging**|Jaeyoung Huh et.al.|[2409.16898v1](http://arxiv.org/abs/2409.16898v1)|null|
|**2024-09-25**|**The Role of Language Models in Modern Healthcare: A Comprehensive Review**|Amna Khalid et.al.|[2409.16860v1](http://arxiv.org/abs/2409.16860v1)|null|
|**2024-09-25**|**A Multi-Dataset Classification-Based Deep Learning Framework for Electronic Health Records and Predictive Analysis in Healthcare**|Syed Mohd Faisal Malik et.al.|[2409.16721v1](http://arxiv.org/abs/2409.16721v1)|null|
|**2024-09-25**|**Enhancing disease detection in radiology reports through fine-tuning lightweight LLM on weak labels**|Yishu Wei et.al.|[2409.16563v1](http://arxiv.org/abs/2409.16563v1)|null|
|**2024-09-24**|**To Explore the Potential Inhibitors against Multitarget Proteins of COVID 19 using In Silico Study**|Imra Aqeel et.al.|[2409.16486v1](http://arxiv.org/abs/2409.16486v1)|null|
|**2024-09-24**|**Design and Evaluation of a CDSS for Drug Allergy Management Using LLMs and Pharmaceutical Data Integration**|Gabriele De Vito et.al.|[2409.16395v1](http://arxiv.org/abs/2409.16395v1)|null|
|**2024-09-24**|**Future-Proofing Medical Imaging with Privacy-Preserving Federated Learning and Uncertainty Quantification: A Review**|Nikolas Koutsoubis et.al.|[2409.16340v1](http://arxiv.org/abs/2409.16340v1)|null|
|**2024-09-24**|**Predicting Deterioration in Mild Cognitive Impairment with Survival Transformers, Extreme Gradient Boosting and Cox Proportional Hazard Modelling**|Henry Musto et.al.|[2409.16231v1](http://arxiv.org/abs/2409.16231v1)|null|
|**2024-09-24**|**Scenario of Use Scheme: Threat Model Specification for Speaker Privacy Protection in the Medical Domain**|Mehtab Ur Rahman et.al.|[2409.16106v2](http://arxiv.org/abs/2409.16106v2)|null|
|**2024-09-24**|**The Digital Transformation in Health: How AI Can Improve the Performance of Health Systems**|África Periáñez et.al.|[2409.16098v1](http://arxiv.org/abs/2409.16098v1)|null|
|**2024-09-24**|**Enhancing IoT based Plant Health Monitoring through Advanced Human Plant Interaction using Large Language Models and Mobile Applications**|Kriti Agarwal et.al.|[2409.15910v1](http://arxiv.org/abs/2409.15910v1)|null|
|**2024-09-24**|**AsthmaBot: Multi-modal, Multi-Lingual Retrieval Augmented Generation For Asthma Patient Support**|Adil Bahaj et.al.|[2409.15815v1](http://arxiv.org/abs/2409.15815v1)|null|
|**2024-09-24**|**Interactive Example-based Explanations to Improve Health Professionals' Onboarding with AI for Human-AI Collaborative Decision Making**|Min Hun Lee et.al.|[2409.15814v1](http://arxiv.org/abs/2409.15814v1)|null|
|**2024-09-24**|**Development and Validation of Heparin Dosing Policies Using an Offline Reinforcement Learning Algorithm**|Yooseok Lim et.al.|[2409.15753v1](http://arxiv.org/abs/2409.15753v1)|null|
|**2024-09-24**|**dnaGrinder: a lightweight and high-capacity genomic foundation model**|Qihang Zhao et.al.|[2409.15697v1](http://arxiv.org/abs/2409.15697v1)|null|
|**2024-09-24**|**Safe Navigation for Robotic Digestive Endoscopy via Human Intervention-based Reinforcement Learning**|Min Tan et.al.|[2409.15688v1](http://arxiv.org/abs/2409.15688v1)|null|
|**2024-09-24**|**A Comprehensive Evaluation of Large Language Models on Mental Illnesses**|Abdelrahman Hanafi et.al.|[2409.15687v1](http://arxiv.org/abs/2409.15687v1)|null|
|**2024-09-23**|**TFT-multi: simultaneous forecasting of vital sign trajectories in the ICU**|Rosemary Y. He et.al.|[2409.15586v2](http://arxiv.org/abs/2409.15586v2)|null|
|**2024-09-23**|**MRI Radiomics for IDH Genotype Prediction in Glioblastoma Diagnosis**|Stanislav Kozák et.al.|[2409.16329v1](http://arxiv.org/abs/2409.16329v1)|null|
|**2024-09-23**|**Computational Pathology for Accurate Prediction of Breast Cancer Recurrence: Development and Validation of a Deep Learning-based Tool**|Ziyu Su et.al.|[2409.15491v1](http://arxiv.org/abs/2409.15491v1)|null|
|**2024-09-23**|**A Preliminary Study of o1 in Medicine: Are We Closer to an AI Doctor?**|Yunfei Xie et.al.|[2409.15277v1](http://arxiv.org/abs/2409.15277v1)|null|
|**2024-09-23**|**Generative AI Is Not Ready for Clinical Use in Patient Education for Lower Back Pain Patients, Even With Retrieval-Augmented Generation**|Yi-Fei Zhao et.al.|[2409.15260v1](http://arxiv.org/abs/2409.15260v1)|null|
|**2024-09-23**|**Boosting Healthcare LLMs Through Retrieved Context**|Jordi Bayarri-Planas et.al.|[2409.15127v1](http://arxiv.org/abs/2409.15127v1)|null|
|**2024-09-23**|**Generalizing monocular colonoscopy image depth estimation by uncertainty-based global and local fusion network**|Sijia Du et.al.|[2409.15006v1](http://arxiv.org/abs/2409.15006v1)|null|
|**2024-09-23**|**DSG-KD: Knowledge Distillation from Domain-Specific to General Language Models**|Sangyeon Cho et.al.|[2409.14904v1](http://arxiv.org/abs/2409.14904v1)|[link](https://github.com/josangyeon/dsg-kd)|
|**2024-09-23**|**Mammo-Clustering:A Weakly Supervised Multi-view Global-Local Context Clustering Network for Detection and Classification in Mammography**|Shilong Yang et.al.|[2409.14876v1](http://arxiv.org/abs/2409.14876v1)|null|
|**2024-09-23**|**Towards Ground-truth-free Evaluation of Any Segmentation in Medical Images**|Ahjol Senbi et.al.|[2409.14874v2](http://arxiv.org/abs/2409.14874v2)|null|
|**2024-09-23**|**A-VL: Adaptive Attention for Large Vision-Language Models**|Junyang Zhang et.al.|[2409.14846v1](http://arxiv.org/abs/2409.14846v1)|null|
|**2024-09-22**|**Can Large Language Models Logically Predict Myocardial Infarction? Evaluation based on UK Biobank Cohort**|Yuxing Zhi et.al.|[2409.14478v1](http://arxiv.org/abs/2409.14478v1)|null|
|**2024-09-22**|**Detection of pulmonary pathologies using convolutional neural networks, Data Augmentation, ResNet50 and Vision Transformers**|Pablo Ramirez Amador et.al.|[2409.14446v1](http://arxiv.org/abs/2409.14446v1)|null|
|**2024-09-22**|**Data-Driven Spatiotemporal Feature Representation and Mining in Multidimensional Time Series**|Xu Yan et.al.|[2409.14327v1](http://arxiv.org/abs/2409.14327v1)|null|
|**2024-09-22**|**PretextTrans: Investigating Medical Factual Knowledge Mastery of LLMs with Predicate-text Dual Transformation**|Yuxuan Zhou et.al.|[2409.14302v1](http://arxiv.org/abs/2409.14302v1)|null|
|**2024-09-21**|**Data-Driven Approach to assess and identify gaps in healthcare set up in South Asia**|Rusham Elahi et.al.|[2409.14194v1](http://arxiv.org/abs/2409.14194v1)|null|
|**2024-09-21**|**Democratising Artificial Intelligence for Pandemic Preparedness and Global Governance in Latin American and Caribbean Countries**|Andre de Carvalho et.al.|[2409.14181v1](http://arxiv.org/abs/2409.14181v1)|null|
|**2024-09-20**|**CI-Bench: Benchmarking Contextual Integrity of AI Assistants on Synthetic Data**|Zhao Cheng et.al.|[2409.13903v1](http://arxiv.org/abs/2409.13903v1)|null|
|**2024-09-20**|**Enhancing Large Language Models with Domain-specific Retrieval Augment Generation: A Case Study on Long-form Consumer Health Question Answering in Ophthalmology**|Aidan Gilson et.al.|[2409.13902v1](http://arxiv.org/abs/2409.13902v1)|null|
|**2024-09-20**|**A Personalised 3D+t Mesh Generative Model for Unveiling Normal Heart Dynamics**|Mengyun Qiao et.al.|[2409.13825v1](http://arxiv.org/abs/2409.13825v1)|null|
|**2024-09-20**|**Morphological Detection and Classification of Microplastics and Nanoplastics Emerged from Consumer Products by Deep Learning**|Hadi Rezvani et.al.|[2409.13688v1](http://arxiv.org/abs/2409.13688v1)|null|
|**2024-09-20**|**Depression Diagnosis Dialogue Simulation: Self-improving Psychiatrist with Tertiary Memory**|Kunyao Lan et.al.|[2409.15084v1](http://arxiv.org/abs/2409.15084v1)|null|
|**2024-09-20**|**Toward Automated Clinical Transcriptions**|Mitchell A. Klusty et.al.|[2409.15378v1](http://arxiv.org/abs/2409.15378v1)|null|
|**2024-09-20**|**Dermatologist-like explainable AI enhances melanoma diagnosis accuracy: eye-tracking study**|Tirtha Chanda et.al.|[2409.13476v1](http://arxiv.org/abs/2409.13476v1)|null|
|**2024-09-20**|**Differentially Private Multimodal Laplacian Dropout (DP-MLD) for EEG Representative Learning**|Xiaowen Fu et.al.|[2409.13440v1](http://arxiv.org/abs/2409.13440v1)|null|
|**2024-09-20**|**FPBoost: Fully Parametric Gradient Boosting for Survival Analysis**|Alberto Archetti et.al.|[2409.13363v1](http://arxiv.org/abs/2409.13363v1)|null|
|**2024-09-20**|**Multi-omics data integration for early diagnosis of hepatocellular carcinoma (HCC) using machine learning**|Annette Spooner et.al.|[2409.13791v1](http://arxiv.org/abs/2409.13791v1)|null|
|**2024-09-20**|**Recent Advancement of Emotion Cognition in Large Language Models**|Yuyan Chen et.al.|[2409.13354v1](http://arxiv.org/abs/2409.13354v1)|null|
|**2024-09-20**|**SLaVA-CXR: Small Language and Vision Assistant for Chest X-ray Report Automation**|Jinge Wu et.al.|[2409.13321v1](http://arxiv.org/abs/2409.13321v1)|null|
|**2024-09-20**|**OMG-RL:Offline Model-based Guided Reward Learning for Heparin Treatment**|Yooseok Lim et.al.|[2409.13299v1](http://arxiv.org/abs/2409.13299v1)|null|
|**2024-09-20**|**Prompting Large Language Models for Supporting the Differential Diagnosis of Anemia**|Elisa Castagnari et.al.|[2409.15377v1](http://arxiv.org/abs/2409.15377v1)|null|
|**2024-09-20**|**An adapted large language model facilitates multiple medical tasks in diabetes care**|Lai Wei et.al.|[2409.13191v1](http://arxiv.org/abs/2409.13191v1)|[link](https://github.com/waltonfuture/Diabetica)|
|**2024-09-19**|**Explainable AI for Autism Diagnosis: Identifying Critical Brain Regions Using fMRI Data**|Suryansh Vidya et.al.|[2409.15374v1](http://arxiv.org/abs/2409.15374v1)|null|
|**2024-09-19**|**Personalized 2D Binary Patient Codes of Tissue Images and Immunogenomic Data Through Multimodal Self-Supervised Fusion**|Areej Alsaafin et.al.|[2409.13115v1](http://arxiv.org/abs/2409.13115v1)|null|
|**2024-09-19**|**DenoMamba: A fused state-space model for low-dose CT denoising**|Şaban Öztürk et.al.|[2409.13094v1](http://arxiv.org/abs/2409.13094v1)|null|
|**2024-09-19**|**AutoPET III Challenge: Tumor Lesion Segmentation using ResEnc-Model Ensemble**|Tanya Chutani et.al.|[2409.13779v1](http://arxiv.org/abs/2409.13779v1)|null|
|**2024-09-19**|**HeadCT-ONE: Enabling Granular and Controllable Automated Evaluation of Head CT Radiology Report Generation**|Julián N. Acosta et.al.|[2409.13038v1](http://arxiv.org/abs/2409.13038v1)|null|
|**2024-09-19**|**iCost: A Novel Instance Complexity Based Cost-Sensitive Learning Framework for Imbalanced Classification**|Asif Newaz et.al.|[2409.13007v1](http://arxiv.org/abs/2409.13007v1)|null|
|**2024-09-19**|**Fuzzy Rule based Intelligent Cardiovascular Disease Prediction using Complex Event Processing**|Shashi Shekhar Kumar et.al.|[2409.15372v1](http://arxiv.org/abs/2409.15372v1)|null|
|**2024-09-19**|**Improving Prototypical Parts Abstraction for Case-Based Reasoning Explanations Designed for the Kidney Stone Type Recognition**|Daniel Flores-Araiza et.al.|[2409.12883v1](http://arxiv.org/abs/2409.12883v1)|null|
|**2024-09-19**|**Introducing the Large Medical Model: State of the art healthcare cost and risk prediction with transformers trained on patient event sequences**|Ricky Sahu et.al.|[2409.13000v1](http://arxiv.org/abs/2409.13000v1)|null|
|**2024-09-19**|**Fine Tuning Large Language Models for Medicine: The Role and Importance of Direct Preference Optimization**|Thomas Savage et.al.|[2409.12741v2](http://arxiv.org/abs/2409.12741v2)|null|
|**2024-09-19**|**SurgPLAN++: Universal Surgical Phase Localization Network for Online and Offline Inference**|Zhen Chen et.al.|[2409.12467v1](http://arxiv.org/abs/2409.12467v1)|[link](https://github.com/lxj22/surgplan-plus)|
|**2024-09-19**|**FoME: A Foundation Model for EEG using Adaptive Temporal-Lateral Attention Scaling**|Enze Shi et.al.|[2409.12454v1](http://arxiv.org/abs/2409.12454v1)|null|
|**2024-09-19**|**Domain Generalization for Endoscopic Image Segmentation by Disentangling Style-Content Information and SuperPixel Consistency**|Mansoor Ali Teevno et.al.|[2409.12450v1](http://arxiv.org/abs/2409.12450v1)|null|
|**2024-09-19**|**Bundle Fragments into a Whole: Mining More Complete Clusters via Submodular Selection of Interesting webpages for Web Topic Detection**|Junbiao Pang et.al.|[2409.12380v1](http://arxiv.org/abs/2409.12380v1)|null|
|**2024-09-18**|**Extracting Memorized Training Data via Decomposition**|Ellen Su et.al.|[2409.12367v1](http://arxiv.org/abs/2409.12367v1)|null|
|**2024-09-18**|**Axial Attention Transformer Networks: A New Frontier in Breast Cancer Detection**|Weijie He et.al.|[2409.12347v1](http://arxiv.org/abs/2409.12347v1)|null|
|**2024-09-18**|**Deep vessel segmentation with joint multi-prior encoding**|Amine Sadikine et.al.|[2409.12334v1](http://arxiv.org/abs/2409.12334v1)|null|
|**2024-09-18**|**MedCodER: A Generative AI Assistant for Medical Coding**|Krishanu Das Baksi et.al.|[2409.15368v1](http://arxiv.org/abs/2409.15368v1)|null|
|**2024-09-18**|**Towards Interpretable End-Stage Renal Disease (ESRD) Prediction: Utilizing Administrative Claims Data with Explainable AI Techniques**|Yubo Li et.al.|[2409.12087v1](http://arxiv.org/abs/2409.12087v1)|null|
|**2024-09-18**|**EFCM: Efficient Fine-tuning on Compressed Models for deployment of large models in medical image analysis**|Shaojie Li et.al.|[2409.11817v1](http://arxiv.org/abs/2409.11817v1)|null|
|**2024-09-18**|**Detecting Underdiagnosed Medical Conditions with Deep Learning-Based Opportunistic CT Imaging**|Asad Aali et.al.|[2409.11686v1](http://arxiv.org/abs/2409.11686v1)|null|
|**2024-09-18**|**Agent Aggregator with Mask Denoise Mechanism for Histopathology Whole Slide Image Analysis**|Xitong Ling et.al.|[2409.11664v1](http://arxiv.org/abs/2409.11664v1)|null|
|**2024-09-18**|**A Metric Hybrid Planning Approach to Solving Pandemic Planning Problems with Simple SIR Models**|Ari Gestetner et.al.|[2409.11631v1](http://arxiv.org/abs/2409.11631v1)|null|
|**2024-09-17**|**Automating proton PBS treatment planning for head and neck cancers using policy gradient-based deep reinforcement learning**|Qingqing Wang et.al.|[2409.11576v1](http://arxiv.org/abs/2409.11576v1)|null|
|**2024-09-17**|**Two Stage Segmentation of Cervical Tumors using PocketNet**|Awj Twam et.al.|[2409.11456v1](http://arxiv.org/abs/2409.11456v1)|null|
|**2024-09-17**|**Multi-OCT-SelfNet: Integrating Self-Supervised Learning with Multi-Source Data Fusion for Enhanced Multi-Class Retinal Disease Classification**|Fatema-E- Jannat et.al.|[2409.11375v1](http://arxiv.org/abs/2409.11375v1)|null|
|**2024-09-17**|**Clinical Validation of a Real-Time Machine Learning-based System for the Detection of Acute Myeloid Leukemia by Flow Cytometry**|Lauren M. Zuromski et.al.|[2409.11350v1](http://arxiv.org/abs/2409.11350v1)|null|
|**2024-09-17**|**TTT-Unet: Enhancing U-Net with Test-Time Training Layers for Biomedical Image Segmentation**|Rong Zhou et.al.|[2409.11299v2](http://arxiv.org/abs/2409.11299v2)|[link](https://github.com/rongzhou7/ttt-unet)|
|**2024-09-17**|**EIA: Environmental Injection Attack on Generalist Web Agents for Privacy Leakage**|Zeyi Liao et.al.|[2409.11295v1](http://arxiv.org/abs/2409.11295v1)|[link](https://github.com/osu-nlp-group/eia_against_webagent)|
|**2024-09-17**|**Towards Ethical Personal AI Applications: Practical Considerations for AI Assistants with Long-Term Memory**|Eunhae Lee et.al.|[2409.11192v1](http://arxiv.org/abs/2409.11192v1)|null|
|**2024-09-17**|**Early Detection of Coronary Heart Disease Using Hybrid Quantum Machine Learning Approach**|Mehroush Banday et.al.|[2409.10932v1](http://arxiv.org/abs/2409.10932v1)|null|
|**2024-09-16**|**Self-supervised Speech Models for Word-Level Stuttered Speech Detection**|Yi-Jen Shih et.al.|[2409.10704v1](http://arxiv.org/abs/2409.10704v1)|null|
|**2024-09-16**|**A Knowledge-Enhanced Disease Diagnosis Method Based on Prompt Learning and BERT Integration**|Zhang Zheng et.al.|[2409.10403v1](http://arxiv.org/abs/2409.10403v1)|null|
|**2024-09-16**|**Robust image representations with counterfactual contrastive learning**|Mélanie Roschewitz et.al.|[2409.10365v1](http://arxiv.org/abs/2409.10365v1)|[link](https://github.com/biomedia-mira/counterfactual-contrastive)|
|**2024-09-16**|**Algorithmic Behaviors Across Regions: A Geolocation Audit of YouTube Search for COVID-19 Misinformation between the United States and South Africa**|Hayoung Jung et.al.|[2409.10168v1](http://arxiv.org/abs/2409.10168v1)|null|
|**2024-09-16**|**Machine listening in a neonatal intensive care unit**|Modan Tailleur et.al.|[2409.11439v1](http://arxiv.org/abs/2409.11439v1)|null|
|**2024-09-16**|**DAE-Fuse: An Adaptive Discriminative Autoencoder for Multi-Modality Image Fusion**|Yuchen Guo et.al.|[2409.10080v1](http://arxiv.org/abs/2409.10080v1)|null|
|**2024-09-16**|**MindGuard: Towards Accessible and Sitgma-free Mental Health First Aid via Edge LLM**|Sijie Ji et.al.|[2409.10064v1](http://arxiv.org/abs/2409.10064v1)|null|
|**2024-09-16**|**HALO: Hallucination Analysis and Learning Optimization to Empower LLMs with Retrieval-Augmented Context for Guided Clinical Decision Making**|Sumera Anjum et.al.|[2409.10011v2](http://arxiv.org/abs/2409.10011v2)|[link](https://github.com/responsibleailab/halo)|
|**2024-09-16**|**Artificial Intelligence-Based Opportunistic Coronary Calcium Screening in the Veterans Affairs National Healthcare System**|Raffi Hagopian et.al.|[2409.09968v1](http://arxiv.org/abs/2409.09968v1)|null|
|**2024-09-15**|**GP-GPT: Large Language Model for Gene-Phenotype Mapping**|Yanjun Lyu et.al.|[2409.09825v1](http://arxiv.org/abs/2409.09825v1)|null|
|**2024-09-15**|**Veridical Data Science for Medical Foundation Models**|Ahmed Alaa et.al.|[2409.10580v1](http://arxiv.org/abs/2409.10580v1)|null|
|**2024-09-15**|**From Challenges and Pitfalls to Recommendations and Opportunities: Implementing Federated Learning in Healthcare**|Ming Li et.al.|[2409.09727v1](http://arxiv.org/abs/2409.09727v1)|null|
|**2024-09-15**|**ExploreSelf: Fostering User-driven Exploration and Reflection on Personal Challenges with Adaptive Guidance by Large Language Models**|Inhwa Song et.al.|[2409.09662v2](http://arxiv.org/abs/2409.09662v2)|null|
|**2024-09-15**|**MindScape Study: Integrating LLM and Behavioral Sensing for Personalized AI-Driven Journaling Experiences**|Subigya Nepal et.al.|[2409.09570v1](http://arxiv.org/abs/2409.09570v1)|null|
|**2024-09-14**|**COMFORT: A Continual Fine-Tuning Framework for Foundation Models Targeted at Consumer Healthcare**|Chia-Hao Li et.al.|[2409.09549v1](http://arxiv.org/abs/2409.09549v1)|null|
|**2024-09-14**|**Enhancing Skin Disease Diagnosis: Interpretable Visual Concept Discovery with SAM Empowerment**|Xin Hu et.al.|[2409.09520v1](http://arxiv.org/abs/2409.09520v1)|null|

#### Abstracts
##### **Ctrl-GenAug: Controllable Generative Augmentation for Medical Sequence Classification**
2409.17091v1 by Xinrui Zhou, Yuhao Huang, Haoran Dou, Shijing Chen, Ao Chang, Jia Liu, Weiran Long, Jian Zheng, Erjiao Xu, Jie Ren, Ruobing Huang, Jun Cheng, Wufeng Xue, Dong Ni

In the medical field, the limited availability of large-scale datasets and
labor-intensive annotation processes hinder the performance of deep models.
Diffusion-based generative augmentation approaches present a promising solution
to this issue, having been proven effective in advancing downstream medical
recognition tasks. Nevertheless, existing works lack sufficient semantic and
sequential steerability for challenging video/3D sequence generation, and
neglect quality control of noisy synthesized samples, resulting in unreliable
synthetic databases and severely limiting the performance of downstream tasks.
In this work, we present Ctrl-GenAug, a novel and general generative
augmentation framework that enables highly semantic- and sequential-customized
sequence synthesis and suppresses incorrectly synthesized samples, to aid
medical sequence classification. Specifically, we first design a multimodal
conditions-guided sequence generator for controllably synthesizing
diagnosis-promotive samples. A sequential augmentation module is integrated to
enhance the temporal/stereoscopic coherence of generated samples. Then, we
propose a noisy synthetic data filter to suppress unreliable cases at semantic
and sequential levels. Extensive experiments on 3 medical datasets, using 11
networks trained on 3 paradigms, comprehensively analyze the effectiveness and
generality of Ctrl-GenAug, particularly in underrepresented high-risk
populations and out-domain conditions.

摘要：在医学領域中，大規模數據集的可用性有限，且人工標註過程繁瑣，阻礙了深度模型的執行。基於擴散的生成式擴充方法為此問題提供了有前景的解決方案，已被證實能有效推進下游醫療識別任務。儘管如此，現有作品缺乏足夠的語義和序列可控性，難以進行具有挑戰性的視訊/3D 序列生成，且忽略了對有雜訊合成樣本的品質控制，導致合成式資料庫不可靠，並嚴重限制了下游任務的執行。在這項工作中，我們提出了 Ctrl-GenAug，一個新穎且通用的生成式擴充架構，能實現高度語義和序列自訂的序列合成，並抑制錯誤合成的樣本，以協助醫療序列分類。具體來說，我們首先設計了一個多模態條件引導序列生成器，用於可控地合成促進診斷的樣本。整合了一個序列擴充模組，以增強生成樣本的時間/立體一致性。然後，我們提出了一個有雜訊的合成資料濾波器，以抑制語義和序列層級中不可靠的案例。在 3 個醫療數據集上進行的廣泛實驗，使用在 3 個範例中訓練的 11 個網路，全面分析了 Ctrl-GenAug 的有效性和普遍性，特別是在代表性不足的高風險族群和領域外條件中。

##### **DRIM: Learning Disentangled Representations from Incomplete Multimodal Healthcare Data**
2409.17055v1 by Lucas Robinet, Ahmad Berjaoui, Ziad Kheil, Elizabeth Cohen-Jonathan Moyal

Real-life medical data is often multimodal and incomplete, fueling the
growing need for advanced deep learning models capable of integrating them
efficiently. The use of diverse modalities, including histopathology slides,
MRI, and genetic data, offers unprecedented opportunities to improve prognosis
prediction and to unveil new treatment pathways. Contrastive learning, widely
used for deriving representations from paired data in multimodal tasks, assumes
that different views contain the same task-relevant information and leverages
only shared information. This assumption becomes restrictive when handling
medical data since each modality also harbors specific knowledge relevant to
downstream tasks. We introduce DRIM, a new multimodal method for capturing
these shared and unique representations, despite data sparsity. More
specifically, given a set of modalities, we aim to encode a representation for
each one that can be divided into two components: one encapsulating
patient-related information common across modalities and the other,
encapsulating modality-specific details. This is achieved by increasing the
shared information among different patient modalities while minimizing the
overlap between shared and unique components within each modality. Our method
outperforms state-of-the-art algorithms on glioma patients survival prediction
tasks, while being robust to missing modalities. To promote reproducibility,
the code is made publicly available at https://github.com/Lucas-rbnt/DRIM

摘要：真實生活中的醫療數據通常是多模態且不完整的，這使得對能夠有效整合它們的高級深度學習模型的需求不斷增長。使用多種形式，包括組織病理切片、核磁共振和遺傳數據，提供了前所未有的機會來改進預後預測並揭示新的治療途徑。對比學習廣泛用於從多模態任務中的配對數據中推導出表示，它假設不同的觀點包含相同的與任務相關的信息，並且僅利用共享信息。在處理醫療數據時，這一假設變得具有限制性，因為每種形式也包含與下游任務相關的具體知識。我們介紹了 DRIM，這是一種新的多模態方法，用於捕獲這些共享和唯一的表示，儘管數據稀疏。更具體地說，給定一組形式，我們旨在對每個形式編碼一個表示，該表示可以分為兩個組成部分：一個封裝跨形式的患者相關信息，另一個封裝形式特定的細節。這是通過增加不同患者形式之間的共享信息，同時最大程度地減少每個形式中共享和唯一組成部分之間的重疊來實現的。我們的算法在神經膠質瘤患者的生存預測任務中優於最先進的算法，同時對缺失的形式具有魯棒性。為了促進可重複性，代碼已在 https://github.com/Lucas-rbnt/DRIM 上公開。

##### **Using LLM for Real-Time Transcription and Summarization of Doctor-Patient Interactions into ePuskesmas in Indonesia**
2409.17054v1 by Azmul Asmar Irfan, Nur Ahmad Khatim, Mansur M. Arief

One of the key issues contributing to inefficiency in Puskesmas is the
time-consuming nature of doctor-patient interactions. Doctors need to conduct
thorough consultations, which include diagnosing the patient's condition,
providing treatment advice, and transcribing detailed notes into medical
records. In regions with diverse linguistic backgrounds, doctors often have to
ask clarifying questions, further prolonging the process. While diagnosing is
essential, transcription and summarization can often be automated using AI to
improve time efficiency and help doctors enhance care quality and enable early
diagnosis and intervention. This paper proposes a solution using a localized
large language model (LLM) to transcribe, translate, and summarize
doctor-patient conversations. We utilize the Whisper model for transcription
and GPT-3 to summarize them into the ePuskemas medical records format. This
system is implemented as an add-on to an existing web browser extension,
allowing doctors to fill out patient forms while talking. By leveraging this
solution for real-time transcription, translation, and summarization, doctors
can improve the turnaround time for patient care while enhancing the quality of
records, which become more detailed and insightful for future visits. This
innovation addresses challenges like overcrowded facilities and the
administrative burden on healthcare providers in Indonesia. We believe this
solution will help doctors save time, provide better care, and produce more
accurate medical records, representing a significant step toward modernizing
healthcare and ensuring patients receive timely, high-quality care, even in
resource-constrained settings.

摘要：<paragraph>導致 Puskesmas 效率低下的關鍵問題之一是，醫生和病人互動耗時。醫生需要進行徹底的諮詢，包括診斷病人的病情、提供治療建議，以及將詳細的筆記記錄在醫療記錄中。在語言背景多元的地區，醫生經常必須提出澄清問題，進一步延長流程。雖然診斷至關重要，但使用 AI 進行轉錄和摘要通常可以自動化，以提高時間效率，並幫助醫生提高護理品質，並實現早期診斷和干預。本文提出了一個使用本地化大型語言模型 (LLM) 來轉錄、翻譯和摘要醫生與病人對話的解決方案。我們利用 Whisper 模型進行轉錄，並使用 GPT-3 將其摘要成 ePuskemas 醫療記錄格式。此系統實作為現有網路瀏覽器擴充功能的附加元件，讓醫生可以在交談時填寫病患表單。透過利用此解決方案進行即時轉錄、翻譯和摘要，醫生可以改善病患照護的周轉時間，同時提升記錄品質，讓記錄變得更詳細且更有洞見，以利於後續就診。此創新解決了像醫療機構人滿為患和印尼醫療保健提供者的行政負擔等挑戰。我們相信此解決方案將幫助醫生節省時間、提供更好的照護，並產生更準確的醫療記錄，代表著現代化醫療保健並確保病人即使在資源受限的環境中也能獲得及時、高品質的照護的重要一步。</paragraph>

##### **GeoBiked: A Dataset with Geometric Features and Automated Labeling Techniques to Enable Deep Generative Models in Engineering Design**
2409.17045v1 by Phillip Mueller, Sebastian Mueller, Lars Mikelsons

We provide a dataset for enabling Deep Generative Models (DGMs) in
engineering design and propose methods to automate data labeling by utilizing
large-scale foundation models. GeoBiked is curated to contain 4 355 bicycle
images, annotated with structural and technical features and is used to
investigate two automated labeling techniques: The utilization of consolidated
latent features (Hyperfeatures) from image-generation models to detect
geometric correspondences (e.g. the position of the wheel center) in structural
images and the generation of diverse text descriptions for structural images.
GPT-4o, a vision-language-model (VLM), is instructed to analyze images and
produce diverse descriptions aligned with the system-prompt. By representing
technical images as Diffusion-Hyperfeatures, drawing geometric correspondences
between them is possible. The detection accuracy of geometric points in unseen
samples is improved by presenting multiple annotated source images. GPT-4o has
sufficient capabilities to generate accurate descriptions of technical images.
Grounding the generation only on images leads to diverse descriptions but
causes hallucinations, while grounding it on categorical labels restricts the
diversity. Using both as input balances creativity and accuracy. Successfully
using Hyperfeatures for geometric correspondence suggests that this approach
can be used for general point-detection and annotation tasks in technical
images. Labeling such images with text descriptions using VLMs is possible, but
dependent on the models detection capabilities, careful prompt-engineering and
the selection of input information. Applying foundation models in engineering
design is largely unexplored. We aim to bridge this gap with a dataset to
explore training, finetuning and conditioning DGMs in this field and suggesting
approaches to bootstrap foundation models to process technical images.

摘要：<paragraph>我們提供了一個資料集，用於在工程設計中啟用深度生成模型 (DGM)，並提出透過利用大規模基礎模型自動化資料標籤的方法。GeoBiked 經過策展，包含 4,355 張自行車影像，並附有結構和技術特徵註解，且用於調查兩種自動化標籤技術：利用影像生成模型的整合潛在特徵（超特徵）來偵測結構影像中的幾何對應（例如車輪中心的位子），以及為結構影像產生多樣化的文字描述。GPT-4o 是一個視覺語言模型 (VLM)，指示要分析影像並產生與系統提示一致的多樣化描述。透過將技術影像表示為擴散超特徵，就可以繪製它們之間的幾何對應。透過呈現多個帶註解的來源影像，可以改善在未見樣本中幾何點的偵測準確度。GPT-4o 具有足夠的能力來產生技術影像的準確描述。僅根據影像進行基礎會產生多樣化的描述，但會產生幻覺，而根據分類標籤進行基礎則會限制多樣性。將兩者都用作輸入，可以平衡創造力和準確性。成功地將超特徵用於幾何對應，表示這種方法可用於技術影像中的一般點偵測和註解任務。使用 VLM 標籤此類影像的文字描述是可行的，但取決於模型的偵測能力、仔細的提示工程和輸入資訊的選擇。在工程設計中應用基礎模型在很大程度上尚未探索。我們旨在透過一個資料集來填補這個空白，以探索在這個領域訓練、微調和調整 DGM，並建議引導基礎模型處理技術影像的方法。</paragraph>

##### **AI-driven View Guidance System in Intra-cardiac Echocardiography Imaging**
2409.16898v1 by Jaeyoung Huh, Paul Klein, Gareth Funka-Lea, Puneet Sharma, Ankur Kapoor, Young-Ho Kim

Intra-cardiac Echocardiography (ICE) is a crucial imaging modality used in
electrophysiology (EP) and structural heart disease (SHD) interventions,
providing real-time, high-resolution views from within the heart. Despite its
advantages, effective manipulation of the ICE catheter requires significant
expertise, which can lead to inconsistent outcomes, particularly among less
experienced operators. To address this challenge, we propose an AI-driven
closed-loop view guidance system with human-in-the-loop feedback, designed to
assist users in navigating ICE imaging without requiring specialized knowledge.
Our method models the relative position and orientation vectors between
arbitrary views and clinically defined ICE views in a spatial coordinate
system, guiding users on how to manipulate the ICE catheter to transition from
the current view to the desired view over time. Operating in a closed-loop
configuration, the system continuously predicts and updates the necessary
catheter manipulations, ensuring seamless integration into existing clinical
workflows. The effectiveness of the proposed system is demonstrated through a
simulation-based evaluation, achieving an 89% success rate with the 6532 test
dataset, highlighting its potential to improve the accuracy and efficiency of
ICE imaging procedures.

摘要：心內超音波檢查 (ICE) 是一種關鍵的影像模式，用於電生理學 (EP) 和結構性心臟疾病 (SHD) 的介入治療，可從心臟內部提供即時、高解析度的影像。儘管有這些優點，但有效操作 ICE 導管需要相當的專業知識，這可能會導致不一致的結果，尤其是在經驗較少的操作員中。為了應對這個挑戰，我們提出一個以 AI 為驅動的閉環視圖引導系統，並結合人機環回饋，旨在協助使用者在不需要專業知識的情況下導航 ICE 影像。我們的模型模擬了任意視圖和臨床定義的 ICE 視圖之間的相對位置和方向向量，在一個空間座標系統中引導使用者如何操作 ICE 導管，以隨著時間從目前的視圖過渡到期望的視圖。在閉環配置中操作時，系統會持續預測和更新必要的導管操作，確保無縫整合到現有的臨床工作流程中。所提出的系統的有效性透過基於模擬的評估得到證明，在 6532 個測試資料集中達到 89% 的成功率，突顯其改善 ICE 影像程序的準確性和效率的潛力。

##### **The Role of Language Models in Modern Healthcare: A Comprehensive Review**
2409.16860v1 by Amna Khalid, Ayma Khalid, Umar Khalid

The application of large language models (LLMs) in healthcare has gained
significant attention due to their ability to process complex medical data and
provide insights for clinical decision-making. These models have demonstrated
substantial capabilities in understanding and generating natural language,
which is crucial for medical documentation, diagnostics, and patient
interaction. This review examines the trajectory of language models from their
early stages to the current state-of-the-art LLMs, highlighting their strengths
in healthcare applications and discussing challenges such as data privacy,
bias, and ethical considerations. The potential of LLMs to enhance healthcare
delivery is explored, alongside the necessary steps to ensure their ethical and
effective integration into medical practice.

摘要：大型語言模型 (LLM) 在醫療保健中的應用已獲得顯著關注，因為它們能夠處理複雜的醫療數據並提供臨床決策的見解。這些模型已展示出在理解和產生自然語言方面的實質能力，這對於醫療文件、診斷和患者互動至關重要。本篇評論探討了語言模型從早期階段到當前最先進的 LLM 的軌跡，重點介紹了它們在醫療保健應用中的優勢，並討論了數據隱私、偏見和道德考量等挑戰。探討了 LLM 提升醫療保健服務的潛力，以及確保它們道德且有效整合到醫療實務中的必要步驟。

##### **A Multi-Dataset Classification-Based Deep Learning Framework for Electronic Health Records and Predictive Analysis in Healthcare**
2409.16721v1 by Syed Mohd Faisal Malik, Md Tabrez Nafis, Mohd Abdul Ahad, Safdar Tanweer

In contemporary healthcare, to protect patient data, electronic health
records have become invaluable repositories, creating vast opportunities to
leverage deep learning techniques for predictive analysis. Retinal fundus
images, cirrhosis stages, and heart disease diagnostic predictions have shown
promising results through the integration of deep learning techniques for
classifying diverse datasets. This study proposes a novel deep learning
predictive analysis framework for classifying multiple datasets by
pre-processing data from three distinct sources. A hybrid deep learning model
combining Residual Networks and Artificial Neural Networks is proposed to
detect acute and chronic diseases such as heart diseases, cirrhosis, and
retinal conditions, outperforming existing models. Dataset preparation involves
aspects such as categorical data transformation, dimensionality reduction, and
missing data synthesis. Feature extraction is effectively performed using
scaler transformation for categorical datasets and ResNet architecture for
image datasets. The resulting features are integrated into a unified
classification model. Rigorous experimentation and evaluation resulted in high
accuracies of 93%, 99%, and 95% for retinal fundus images, cirrhosis stages,
and heart disease diagnostic predictions, respectively. The efficacy of the
proposed method is demonstrated through a detailed analysis of F1-score,
precision, and recall metrics. This study offers a comprehensive exploration of
methodologies and experiments, providing in-depth knowledge of deep learning
predictive analysis in electronic health records.

摘要：<paragraph>在當代醫療保健中，為了保護患者數據，電子健康記錄已成為無價的儲存庫，創造了利用深度學習技術進行預測分析的廣闊機會。視網膜眼底圖像、肝硬化分期和心臟病診斷預測已透過整合深度學習技術來分類不同的數據集，顯示出有希望的結果。本研究提出一個新的深度學習預測分析架構，透過預處理來自三個不同來源的數據來分類多個數據集。提出了一個結合殘差網路和人工神經網路的混合深度學習模型，用於檢測急性病和慢性病，例如心臟病、肝硬化和視網膜疾病，其效能優於現有的模型。數據集準備涉及範疇資料轉換、降維和遺失資料合成等方面。特徵萃取使用範疇資料集的縮放器轉換和影像資料集的 ResNet 架構來有效執行。產生的特徵被整合到一個統一的分類模型中。嚴謹的實驗和評估導致視網膜眼底圖像、肝硬化分期和心臟病診斷預測的準確度分別高達 93%、99% 和 95%。所提出方法的有效性透過對 F1 分數、精確度和召回率指標的詳細分析來證明。本研究提供了方法論和實驗的全面探討，深入了解電子健康記錄中的深度學習預測分析。</paragraph>

##### **Enhancing disease detection in radiology reports through fine-tuning lightweight LLM on weak labels**
2409.16563v1 by Yishu Wei, Xindi Wang, Hanley Ong, Yiliang Zhou, Adam Flanders, George Shih, Yifan Peng

Despite significant progress in applying large language models (LLMs) to the
medical domain, several limitations still prevent them from practical
applications. Among these are the constraints on model size and the lack of
cohort-specific labeled datasets. In this work, we investigated the potential
of improving a lightweight LLM, such as Llama 3.1-8B, through fine-tuning with
datasets using synthetic labels. Two tasks are jointly trained by combining
their respective instruction datasets. When the quality of the task-specific
synthetic labels is relatively high (e.g., generated by GPT4- o), Llama 3.1-8B
achieves satisfactory performance on the open-ended disease detection task,
with a micro F1 score of 0.91. Conversely, when the quality of the
task-relevant synthetic labels is relatively low (e.g., from the MIMIC-CXR
dataset), fine-tuned Llama 3.1-8B is able to surpass its noisy teacher labels
(micro F1 score of 0.67 v.s. 0.63) when calibrated against curated labels,
indicating the strong inherent underlying capability of the model. These
findings demonstrate the potential of fine-tuning LLMs with synthetic labels,
offering a promising direction for future research on LLM specialization in the
medical domain.

摘要：儘管將大型語言模型 (LLM) 應用於醫療領域已取得顯著進展，但仍有若干限制阻礙它們實際應用。其中包括模型大小的限制和缺乏特定於群體的標籤資料集。在這項工作中，我們探討了透過使用合成標籤微調資料集來改善輕量級 LLM（例如 Llama 3.1-8B）的潛力。透過結合各自的指令資料集，共同訓練兩個任務。當特定於任務的合成標籤品質相對較高時（例如，由 GPT4-o 產生），Llama 3.1-8B 在開放式疾病偵測任務中取得令人滿意的表現，微觀 F1 分數為 0.91。相反地，當與任務相關的合成標籤品質相對較低時（例如，來自 MIMIC-CXR 資料集），微調後的 Llama 3.1-8B 能夠超越其有雜訊的教師標籤（微觀 F1 分數為 0.67，相較於 0.63），並根據經過整理的標籤進行校準，這表示該模型具有強大的內在潛在能力。這些發現證明了使用合成標籤微調 LLM 的潛力，為未來針對 LLM 在醫療領域的專門化研究提供了有前景的方向。

##### **To Explore the Potential Inhibitors against Multitarget Proteins of COVID 19 using In Silico Study**
2409.16486v1 by Imra Aqeel

The global pandemic due to emergence of COVID 19 has created the unrivaled
public health crisis. It has huge morbidity rate never comprehended in the
recent decades. Researchers have made many efforts to find the optimal solution
of this pandemic. Progressively, drug repurposing is an emergent and powerful
strategy with saving cost, time, and labor. Lacking of identified repurposed
drug candidates against COVID 19 demands more efforts to explore the potential
inhibitors for effective cure. In this study, we used the combination of
molecular docking and machine learning regression approaches to explore the
potential inhibitors for the treatment of COVID 19. We calculated the binding
affinities of these drugs to multitarget proteins using molecular docking
process. We perform the QSAR modeling by employing various machine learning
regression approaches to identify the potential inhibitors against COVID 19.
Our findings with best scores of R2 and RMSE demonstrated that our proposed
Decision Tree Regression (DTR) model is the most appropriate model to explore
the potential inhibitors. We proposed five novel promising inhibitors with
their respective Zinc IDs ZINC (3873365, 85432544, 8214470, 85536956, and
261494640) within the range of -19.7 kcal/mol to -12.6 kcal/mol. We further
analyzed the physiochemical and pharmacokinetic properties of these most potent
inhibitors to examine their behavior. The analysis of these properties is the
key factor to promote an effective cure for public health. Our work constructs
an efficient structure with which to probe the potential inhibitors against
COVID-19, creating the combination of molecular docking with machine learning
regression approaches.

摘要：由於 COVID-19 的出現，全球大流行造成了無與倫比的公共衛生危機。它在最近幾十年來從未見過如此高的發病率。研究人員已做出許多努力來尋找此一流行病的最佳解決方案。漸進式藥物再利用是一種新興且強大的策略，可節省成本、時間和勞力。缺乏針對 COVID-19 的已識別再利用藥物候選藥物，需要更多努力來探索潛在的抑制劑以進行有效治療。在本研究中，我們結合了分子對接和機器學習回歸方法來探索治療 COVID-19 的潛在抑制劑。我們使用分子對接程序計算這些藥物與多目標蛋白的結合親和力。我們透過採用各種機器學習回歸方法來執行 QSAR 建模，以識別針對 COVID-19 的潛在抑制劑。我們在 R2 和 RMSE 中獲得的最佳分數發現，我們提出的決策樹回歸 (DTR) 模型是最合適的模型，可探索潛在的抑制劑。我們提出了五種新穎且有希望的抑制劑，它們各自的 Zinc ID 為 ZINC (3873365、85432544、8214470、85536956 和 261494640)，範圍在 -19.7 kcal/mol 至 -12.6 kcal/mol 之間。我們進一步分析了這些最強效抑制劑的理化和藥代動力學特性，以檢驗它們的行為。這些特性的分析是促進公共衛生有效治療的關鍵因素。我們的研究建立了一個有效的結構，可用於探測針對 COVID-19 的潛在抑制劑，結合分子對接與機器學習回歸方法。

##### **Design and Evaluation of a CDSS for Drug Allergy Management Using LLMs and Pharmaceutical Data Integration**
2409.16395v1 by Gabriele De Vito, Filomena Ferrucci, Athanasios Angelakis

Medication errors significantly threaten patient safety, leading to adverse
drug events and substantial economic burdens on healthcare systems. Clinical
Decision Support Systems (CDSSs) aimed at mitigating these errors often face
limitations, including reliance on static databases and rule-based algorithms,
which can result in high false alert rates and alert fatigue among clinicians.
This paper introduces HELIOT, an innovative CDSS for drug allergy management,
integrating Large Language Models (LLMs) with a comprehensive pharmaceutical
data repository. HELIOT leverages advanced natural language processing
capabilities to interpret complex medical texts and synthesize unstructured
data, overcoming the limitations of traditional CDSSs. An empirical evaluation
using a synthetic patient dataset and expert-verified ground truth demonstrates
HELIOT's high accuracy, precision, recall, and F1 score, uniformly reaching
100\% across multiple experimental runs. The results underscore HELIOT's
potential to enhance decision support in clinical settings, offering a
scalable, efficient, and reliable solution for managing drug allergies.

摘要：藥物錯誤嚴重威脅患者安全，導致不良藥物事件和醫療系統的重大經濟負擔。旨在減輕這些錯誤的臨床決策支援系統 (CDSS) 經常面臨限制，包括依賴靜態資料庫和基於規則的演算法，這可能會導致臨床醫生之間的高誤報率和警報疲勞。本文介紹 HELIOT，一種創新的藥物過敏管理 CDSS，將大型語言模型 (LLM) 與全面的藥物資料庫整合在一起。HELIOT 利用先進的自然語言處理能力來解釋複雜的醫學文本並綜合非結構化資料，克服傳統 CDSS 的限制。使用合成患者資料集和專家驗證的地面實況進行的經驗評估證明了 HELIOT 的高準確度、精確度、召回率和 F1 分數，在多次實驗運行中均達到 100%。結果強調了 HELIOT 在臨床環境中增強決策支援的潛力，為管理藥物過敏提供可擴充、高效且可靠的解決方案。

##### **Future-Proofing Medical Imaging with Privacy-Preserving Federated Learning and Uncertainty Quantification: A Review**
2409.16340v1 by Nikolas Koutsoubis, Asim Waqas, Yasin Yilmaz, Ravi P. Ramachandran, Matthew Schabath, Ghulam Rasool

Artificial Intelligence (AI) has demonstrated significant potential in
automating various medical imaging tasks, which could soon become routine in
clinical practice for disease diagnosis, prognosis, treatment planning, and
post-treatment surveillance. However, the privacy concerns surrounding patient
data present a major barrier to the widespread adoption of AI in medical
imaging, as large, diverse training datasets are essential for developing
accurate, generalizable, and robust Artificial intelligence models. Federated
Learning (FL) offers a solution that enables organizations to train AI models
collaboratively without sharing sensitive data. federated learning exchanges
model training information, such as gradients, between the participating sites.
Despite its promise, federated learning is still in its developmental stages
and faces several challenges. Notably, sensitive information can still be
inferred from the gradients shared during model training. Quantifying AI
models' uncertainty is vital due to potential data distribution shifts
post-deployment, which can affect model performance. Uncertainty quantification
(UQ) in FL is particularly challenging due to data heterogeneity across
participating sites. This review provides a comprehensive examination of FL,
privacy-preserving FL (PPFL), and UQ in FL. We identify key gaps in current FL
methodologies and propose future research directions to enhance data privacy
and trustworthiness in medical imaging applications.

摘要：人工智慧 (AI) 已在自動化各種醫學影像任務中展現出顯著的潛力，這可能很快就會在疾病診斷、預後、治療規劃和治療後監測的臨床實務中成為例行公事。然而，圍繞著病患資料的隱私疑慮對 AI 在醫學影像中的廣泛採用構成了一項重大的障礙，因為龐大且多樣化的訓練資料集對於開發準確、可概括且強健的人工智慧模型至關重要。聯合學習 (FL) 提供了一項解決方案，讓組織能夠在不共享敏感資料的情況下協同訓練 AI 模型。聯合學習會在參與的各個站點之間交換模型訓練資訊，例如梯度。儘管聯合學習前景看好，但它仍處於開發階段，並面臨著若干挑戰。值得注意的是，即使在模型訓練期間共享，敏感資訊仍可能被推斷出來。由於模型部署後潛在的資料分佈轉移可能會影響模型效能，因此量化 AI 模型的不確定性至關重要。由於參與站點之間資料的異質性，聯合學習中的不確定性量化 (UQ) 特別具有挑戰性。此篇評論對聯合學習、隱私保護聯合學習 (PPFL) 和聯合學習中的不確定性量化進行了全面的探討。我們找出目前聯合學習方法中的關鍵差距，並提出未來的研究方向，以增強醫學影像應用中的資料隱私和可信度。

##### **Predicting Deterioration in Mild Cognitive Impairment with Survival Transformers, Extreme Gradient Boosting and Cox Proportional Hazard Modelling**
2409.16231v1 by Henry Musto, Daniel Stamate, Doina Logofatu, Daniel Stahl

The paper proposes a novel approach of survival transformers and extreme
gradient boosting models in predicting cognitive deterioration in individuals
with mild cognitive impairment (MCI) using metabolomics data in the ADNI
cohort. By leveraging advanced machine learning and transformer-based
techniques applied in survival analysis, the proposed approach highlights the
potential of these techniques for more accurate early detection and
intervention in Alzheimer's dementia disease. This research also underscores
the importance of non-invasive biomarkers and innovative modelling tools in
enhancing the accuracy of dementia risk assessments, offering new avenues for
clinical practice and patient care. A comprehensive Monte Carlo simulation
procedure consisting of 100 repetitions of a nested cross-validation in which
models were trained and evaluated, indicates that the survival machine learning
models based on Transformer and XGBoost achieved the highest mean C-index
performances, namely 0.85 and 0.8, respectively, and that they are superior to
the conventional survival analysis Cox Proportional Hazards model which
achieved a mean C-Index of 0.77. Moreover, based on the standard deviations of
the C-Index performances obtained in the Monte Carlo simulation, we established
that both survival machine learning models above are more stable than the
conventional statistical model.

摘要：這篇論文提出了一種新的方法，使用 ADNI 隊伍中的代謝組學資料，在認知功能輕微受損 (MCI) 的個體中預測認知惡化，這種方法結合了生存轉換器和極端梯度提升模型。透過利用進階機器學習和基於轉換器的技術，應用於存活分析，提出的方法突顯了這些技術在阿茲海默症失智症中更準確的早期檢測和干預的潛力。這項研究也強調了非侵入性生物標記和創新建模工具在提升失智症風險評估準確度中的重要性，為臨床實務和病人照護提供了新途徑。一個包含 100 次巢狀交叉驗證重複的綜合蒙地卡羅模擬程序，其中模型經過訓練和評估，顯示基於轉換器和 XGBoost 的生存機器學習模型達到了最高的平均 C 指數表現，分別為 0.85 和 0.8，而且它們優於傳統的生存分析 Cox 比例風險模型，後者的平均 C 指數為 0.77。此外，根據蒙地卡羅模擬中獲得的 C 指數表現的標準差，我們確立了上述兩種生存機器學習模型都比傳統的統計模型更穩定。

##### **Scenario of Use Scheme: Threat Model Specification for Speaker Privacy Protection in the Medical Domain**
2409.16106v2 by Mehtab Ur Rahman, Martha Larson, Louis ten Bosch, Cristian Tejedor-García

Speech recordings are being more frequently used to detect and monitor
disease, leading to privacy concerns. Beyond cryptography, protection of speech
can be addressed by approaches, such as perturbation, disentanglement, and
re-synthesis, that eliminate sensitive information of the speaker, leaving the
information necessary for medical analysis purposes. In order for such privacy
protective approaches to be developed, clear and systematic specifications of
assumptions concerning medical settings and the needs of medical professionals
are necessary. In this paper, we propose a Scenario of Use Scheme that
incorporates an Attacker Model, which characterizes the adversary against whom
the speaker's privacy must be defended, and a Protector Model, which specifies
the defense. We discuss the connection of the scheme with previous work on
speech privacy. Finally, we present a concrete example of a specified Scenario
of Use and a set of experiments about protecting speaker data against gender
inference attacks while maintaining utility for Parkinson's detection.

摘要：語音錄音正越來越常被用於偵測和監測疾病，進而引發隱私疑慮。除了密碼學之外，語音保護還能透過擾動、解糾纏和重新合成等方法來達成，這些方法消除了說話者的敏感資訊，保留了醫療分析目的所需資訊。為了發展出此類保護隱私的方法，必須清楚且系統性地說明有關醫療環境的假設和醫療專業人員的需求。在本文中，我們提出了一個使用情境方案，其中包含攻擊者模型（用於描述必須保護說話者隱私的對手）和保護者模型（用於說明防禦措施）。我們探討了該方案與先前語音隱私研究的關聯。最後，我們提出了一個具體的使用情境範例，以及一組關於在維持帕金森氏症偵測效用的同時保護說話者資料免於性別推論攻擊的實驗。

##### **The Digital Transformation in Health: How AI Can Improve the Performance of Health Systems**
2409.16098v1 by África Periáñez, Ana Fernández del Río, Ivan Nazarov, Enric Jané, Moiz Hassan, Aditya Rastogi, Dexian Tang

Mobile health has the potential to revolutionize health care delivery and
patient engagement. In this work, we discuss how integrating Artificial
Intelligence into digital health applications-focused on supply chain, patient
management, and capacity building, among other use cases-can improve the health
system and public health performance. We present an Artificial Intelligence and
Reinforcement Learning platform that allows the delivery of adaptive
interventions whose impact can be optimized through experimentation and
real-time monitoring. The system can integrate multiple data sources and
digital health applications. The flexibility of this platform to connect to
various mobile health applications and digital devices and send personalized
recommendations based on past data and predictions can significantly improve
the impact of digital tools on health system outcomes. The potential for
resource-poor settings, where the impact of this approach on health outcomes
could be more decisive, is discussed specifically. This framework is, however,
similarly applicable to improving efficiency in health systems where scarcity
is not an issue.

摘要：行動醫療具有革新醫療保健服務和患者參與的潛力。在這項工作中，我們討論如何將人工智慧整合到數位健康應用程式中，專注於供應鏈、患者管理和能力建構，以及其他使用案例，可以改善健康系統和公共衛生績效。我們提出一個人工智慧和強化學習平台，允許提供適應性介入措施，其影響可以透過實驗和即時監控進行最佳化。該系統可以整合多個資料來源和數位健康應用程式。此平台連接到各種行動醫療應用程式和數位裝置的靈活性，並根據過去的資料和預測發送個人化建議，可以顯著改善數位工具對健康系統成果的影響。特別討論了資源匱乏環境的潛力，在該環境中，這種方法對健康成果的影響可能更具決定性。然而，此架構同樣適用於改善健康系統的效率，其中稀缺性並非問題。

##### **Enhancing IoT based Plant Health Monitoring through Advanced Human Plant Interaction using Large Language Models and Mobile Applications**
2409.15910v1 by Kriti Agarwal, Samhruth Ananthanarayanan, Srinitish Srinivasan, Abirami S

This paper presents the development of a novel plant communication
application that allows plants to "talk" to humans using real-time sensor data
and AI-powered language models. Utilizing soil sensors that track moisture,
temperature, and nutrient levels, the system feeds this data into the Gemini
API, where it is processed and transformed into natural language insights about
the plant's health and "mood." Developed using Flutter, Firebase, and
ThingSpeak, the app offers a seamless user experience with real-time
interaction capabilities. By fostering human-plant connectivity, this system
enhances plant care practices, promotes sustainability, and introduces
innovative applications for AI and IoT technologies in both personal and
agricultural contexts. The paper explores the technical architecture, system
integration, and broader implications of AI-driven plant communication.

摘要：本文介紹了一款新穎的植物溝通應用程式的開發，它允許植物利用即時感測器資料和 AI 語言模型與人類「對話」。系統利用追蹤水分、溫度和養分含量的土壤感測器，將這些資料輸入 Gemini API，並在其中進行處理，轉換成關於植物健康和「情緒」的自然語言見解。此應用程式使用 Flutter、Firebase 和 ThingSpeak 開發，提供與即時互動功能無縫接軌的使用者體驗。透過促進人與植物的連結，此系統提升了植物照護方式，促進永續性，並在個人和農業情境中引進了 AI 和 IoT 技術的創新應用。本文探討了 AI 驅動的植物溝通技術架構、系統整合和更廣泛的意涵。

##### **AsthmaBot: Multi-modal, Multi-Lingual Retrieval Augmented Generation For Asthma Patient Support**
2409.15815v1 by Adil Bahaj, Mounir Ghogho

Asthma rates have risen globally, driven by environmental and lifestyle
factors. Access to immediate medical care is limited, particularly in
developing countries, necessitating automated support systems. Large Language
Models like ChatGPT (Chat Generative Pre-trained Transformer) and Gemini have
advanced natural language processing in general and question answering in
particular, however, they are prone to producing factually incorrect responses
(i.e. hallucinations). Retrieval-augmented generation systems, integrating
curated documents, can improve large language models' performance and reduce
the incidence of hallucination. We introduce AsthmaBot, a multi-lingual,
multi-modal retrieval-augmented generation system for asthma support.
Evaluation of an asthma-related frequently asked questions dataset shows
AsthmaBot's efficacy. AsthmaBot has an added interactive and intuitive
interface that integrates different data modalities (text, images, videos) to
make it accessible to the larger public. AsthmaBot is available online via
\url{asthmabot.datanets.org}.

摘要：氣喘發生率在全球上升，原因在於環境和生活方式的因素。立即獲得醫療照護的管道有限，特別是在開發中國家，這使得自動化支援系統變得必要。大型語言模型，例如 ChatGPT（Chat Generative Pre-trained Transformer）和 Gemini，已提升一般自然語言處理和特別是問答的進展，然而，它們容易產生事實上不正確的回應（即幻覺）。擷取增強生成系統，整合策展文件，可以提升大型語言模型的效能並減少幻覺發生的機率。我們介紹 AsthmaBot，一個多語言、多模態擷取增強生成系統，用於氣喘支援。評估與氣喘相關的常見問題資料集顯示 AsthmaBot 的效能。AsthmaBot 有一個額外的互動且直覺的介面，它整合不同的資料模式（文字、圖片、影片），使其能讓更多大眾使用。AsthmaBot 可透過 \url{asthmabot.datanets.org} 線上取得。

##### **Interactive Example-based Explanations to Improve Health Professionals' Onboarding with AI for Human-AI Collaborative Decision Making**
2409.15814v1 by Min Hun Lee, Renee Bao Xuan Ng, Silvana Xinyi Choo, Shamala Thilarajah

A growing research explores the usage of AI explanations on user's decision
phases for human-AI collaborative decision-making. However, previous studies
found the issues of overreliance on `wrong' AI outputs. In this paper, we
propose interactive example-based explanations to improve health professionals'
onboarding with AI for their better reliance on AI during AI-assisted
decision-making. We implemented an AI-based decision support system that
utilizes a neural network to assess the quality of post-stroke survivors'
exercises and interactive example-based explanations that systematically
surface the nearest neighborhoods of a test/task sample from the training set
of the AI model to assist users' onboarding with the AI model. To investigate
the effect of interactive example-based explanations, we conducted a study with
domain experts, health professionals to evaluate their performance and reliance
on AI. Our interactive example-based explanations during onboarding assisted
health professionals in having a better reliance on AI and making a higher
ratio of making `right' decisions and a lower ratio of `wrong' decisions than
providing only feature-based explanations during the decision-support phase.
Our study discusses new challenges of assisting user's onboarding with AI for
human-AI collaborative decision-making.

摘要：越來越多研究探討在人類與 AI 協作決策時，使用 AI 解釋對使用者決策階段的影響。然而，先前的研究發現過度依賴「錯誤」的 AI 輸出的問題。在本文中，我們提出互動式範例為基礎的解釋，以改善醫療專業人員與 AI 的整合，讓他們在 AI 輔助決策時能更依賴 AI。我們實作了一個基於 AI 的決策支援系統，它利用神經網路評估中風後倖存者運動的品質，並利用互動式範例為基礎的解釋，系統性地從 AI 模型的訓練集中找出測試/任務範例最近的鄰域，以協助使用者與 AI 模型整合。為了探討互動式範例為基礎的解釋的效果，我們進行了一項研究，找來領域專家和醫療專業人員評估他們的表現與對 AI 的依賴。我們在整合期間提供的互動式範例為基礎的解釋，協助醫療專業人員更依賴 AI，並且在決策支援階段中做出「正確」決策的比率較高，而做出「錯誤」決策的比率較低，優於只提供基於特徵的解釋。我們的研究探討了在人類與 AI 協作決策時，協助使用者與 AI 整合的新挑戰。

##### **Development and Validation of Heparin Dosing Policies Using an Offline Reinforcement Learning Algorithm**
2409.15753v1 by Yooseok Lim, Inbeom Park, Sujee Lee

Appropriate medication dosages in the intensive care unit (ICU) are critical
for patient survival. Heparin, used to treat thrombosis and inhibit blood
clotting in the ICU, requires careful administration due to its complexity and
sensitivity to various factors, including patient clinical characteristics,
underlying medical conditions, and potential drug interactions. Incorrect
dosing can lead to severe complications such as strokes or excessive bleeding.
To address these challenges, this study proposes a reinforcement learning
(RL)-based personalized optimal heparin dosing policy that guides dosing
decisions reliably within the therapeutic range based on individual patient
conditions. A batch-constrained policy was implemented to minimize
out-of-distribution errors in an offline RL environment and effectively
integrate RL with existing clinician policies. The policy's effectiveness was
evaluated using weighted importance sampling, an off-policy evaluation method,
and the relationship between state representations and Q-values was explored
using t-SNE. Both quantitative and qualitative analyses were conducted using
the Medical Information Mart for Intensive Care III (MIMIC-III) database,
demonstrating the efficacy of the proposed RL-based medication policy.
Leveraging advanced machine learning techniques and extensive clinical data,
this research enhances heparin administration practices and establishes a
precedent for the development of sophisticated decision-support tools in
medicine.

摘要：在重症监护病房 (ICU) 中，适当的药物剂量对于患者的存活至关重要。肝素用于治疗血栓形成并抑制 ICU 中的血液凝结，由于其复杂性和对各种因素的敏感性，包括患者的临床特征、潜在的药物相互作用和基础疾病，因此需要谨慎给药。剂量不当会导致严重并发症，例如中风或过度出血。为了应对这些挑战，本研究提出了一种基于强化学习 (RL) 的个性化最佳肝素给药策略，该策略可以根据患者的个体情况在治疗范围内可靠地指导给药决策。实施了批约束策略以最大程度地减少离线 RL 环境中的分布外误差，并有效地将 RL 与现有的临床医生策略相结合。该策略的有效性使用加权重要性抽样（一种非策略评估方法）进行了评估，并使用 t-SNE 探索了状态表示和 Q 值之间的关系。使用重症监护 III（MIMIC-III）数据库进行了定量和定性分析，证明了所提出的基于 RL 的药物策略的有效性。利用先进的机器学习技术和广泛的临床数据，本研究增强了肝素给药实践，并为医学中复杂决策支持工具的开发树立了先例。

##### **dnaGrinder: a lightweight and high-capacity genomic foundation model**
2409.15697v1 by Qihang Zhao, Chi Zhang, Weixiong Zhang

The task of understanding and interpreting the complex information encoded
within genomic sequences remains a grand challenge in biological research and
clinical applications. In this context, recent advancements in large language
model research have led to the development of both encoder-only and
decoder-only foundation models designed to decode intricate information in DNA
sequences. However, several issues persist, particularly regarding the
efficient management of long-range dependencies inherent in genomic sequences,
the effective representation of nucleotide variations, and the considerable
computational costs associated with large model architectures and extensive
pretraining datasets. Current genomic foundation models often face a critical
tradeoff: smaller models with mediocre performance versus large models with
improved performance. To address these challenges, we introduce dnaGrinder, a
unique and efficient genomic foundation model. dnaGrinder excels at managing
long-range dependencies within genomic sequences while minimizing computational
costs without compromising performance. It achieves results that are not just
comparable but often superior to leading DNA models such as Nucleotide
Transformer and DNABERT-2. Furthermore, dnaGrinder is designed for easy
fine-tuning on workstation-grade GPUs, accommodating input lengths exceeding
17,000 tokens. On a single high-performance GPU, it supports sequences longer
than 140,000 tokens, making it a highly efficient and accessible tool for both
basic biological research and clinical applications.

摘要：理解和詮釋編碼在基因組序列中的複雜資訊，在生物研究和臨床應用中仍是一項重大挑戰。在此背景下，大型語言模型研究的最新進展已導致編碼器專用和解碼器專用基礎模型的開發，旨在解碼 DNA 序列中的複雜資訊。然而，仍存在一些問題，特別是在基因組序列中固有的長距離依賴性的有效管理、核苷酸變異的有效表示，以及與大型模型架構和廣泛預訓練資料集相關的龐大計算成本。目前的基因組基礎模型通常面臨一個關鍵的權衡：效能平庸的小型模型與效能提升的大型模型。為了解決這些挑戰，我們引入了 dnaGrinder，一個獨特且高效的基因組基礎模型。dnaGrinder 擅長管理基因組序列中的長距離依賴性，同時最小化計算成本，而不會損害效能。它所取得的成果不僅與領先的 DNA 模型（例如 Nucleotide Transformer 和 DNABERT-2）相當，而且往往更勝一籌。此外，dnaGrinder 設計為可輕鬆在工作站級 GPU 上進行微調，可容納長度超過 17,000 個符號的輸入。在單一高效能 GPU 上，它支援長度超過 140,000 個符號的序列，使其成為基礎生物研究和臨床應用中高效且易於存取的工具。

##### **Safe Navigation for Robotic Digestive Endoscopy via Human Intervention-based Reinforcement Learning**
2409.15688v1 by Min Tan, Yushun Tao, Boyun Zheng, GaoSheng Xie, Lijuan Feng, Zeyang Xia, Jing Xiong

With the increasing application of automated robotic digestive endoscopy
(RDE), ensuring safe and efficient navigation in the unstructured and narrow
digestive tract has become a critical challenge. Existing automated
reinforcement learning navigation algorithms, often result in potentially risky
collisions due to the absence of essential human intervention, which
significantly limits the safety and effectiveness of RDE in actual clinical
practice. To address this limitation, we proposed a Human Intervention
(HI)-based Proximal Policy Optimization (PPO) framework, dubbed HI-PPO, which
incorporates expert knowledge to enhance RDE's safety. Specifically, we
introduce an Enhanced Exploration Mechanism (EEM) to address the low
exploration efficiency of the standard PPO. Additionally, a reward-penalty
adjustment (RPA) is implemented to penalize unsafe actions during initial
interventions. Furthermore, Behavior Cloning Similarity (BCS) is included as an
auxiliary objective to ensure the agent emulates expert actions. Comparative
experiments conducted in a simulated platform across various anatomical colon
segments demonstrate that our model effectively and safely guides RDE.

摘要：隨著自動化機器人消化道內視鏡檢查 (RDE) 的應用日益廣泛，在結構化且狹窄的消化道中確保安全且有效率的導航已成為一項重大的挑戰。現有的自動化強化學習導航演算法，由於缺乏必要的介入，經常導致潛在的風險碰撞，這顯著限制了 RDE 在實際臨床實務中的安全性和有效性。為了解決此限制，我們提出了一個基於人類介入 (HI) 的近端策略最佳化 (PPO) 架構，稱為 HI-PPO，它結合了專家知識來增強 RDE 的安全性。具體來說，我們引入了一個增強探索機制 (EEM) 來解決標準 PPO 的低探索效率。此外，實施了獎勵懲罰調整 (RPA) 來懲罰在最初介入期間的不安全行為。此外，行為複製相似性 (BCS) 被納入作為輔助目標，以確保代理模擬專家行為。在模擬平台中進行的比較實驗，橫跨各種解剖結腸片段，證明我們的模型有效且安全地引導 RDE。

##### **A Comprehensive Evaluation of Large Language Models on Mental Illnesses**
2409.15687v1 by Abdelrahman Hanafi, Mohammed Saad, Noureldin Zahran, Radwa J. Hanafy, Mohammed E. Fouda

Large language models have shown promise in various domains, including
healthcare. In this study, we conduct a comprehensive evaluation of LLMs in the
context of mental health tasks using social media data. We explore the
zero-shot (ZS) and few-shot (FS) capabilities of various LLMs, including GPT-4,
Llama 3, Gemini, and others, on tasks such as binary disorder detection,
disorder severity evaluation, and psychiatric knowledge assessment. Our
evaluation involved 33 models testing 9 main prompt templates across the tasks.
Key findings revealed that models like GPT-4 and Llama 3 exhibited superior
performance in binary disorder detection, with accuracies reaching up to 85% on
certain datasets. Moreover, prompt engineering played a crucial role in
enhancing model performance. Notably, the Mixtral 8x22b model showed an
improvement of over 20%, while Gemma 7b experienced a similar boost in
performance. In the task of disorder severity evaluation, we observed that FS
learning significantly improved the model's accuracy, highlighting the
importance of contextual examples in complex assessments. Notably, the
Phi-3-mini model exhibited a substantial increase in performance, with balanced
accuracy improving by over 6.80% and mean average error dropping by nearly 1.3
when moving from ZS to FS learning. In the psychiatric knowledge task, recent
models generally outperformed older, larger counterparts, with the Llama 3.1
405b achieving an accuracy of 91.2%. Despite promising results, our analysis
identified several challenges, including variability in performance across
datasets and the need for careful prompt engineering. Furthermore, the ethical
guards imposed by many LLM providers hamper the ability to accurately evaluate
their performance, due to tendency to not respond to potentially sensitive
queries.

摘要：大型語言模型已在醫療保健等各個領域展現潛力。在本研究中，我們使用社群媒體資料對 LLM 在心理健康任務中的表現進行全面評估。我們探討各種 LLM，包括 GPT-4、Llama 3、Gemini 等，在二元障礙偵測、障礙嚴重性評估和精神疾病知識評估等任務上的零次學習 (ZS) 和少次學習 (FS) 能力。我們的評估涉及 33 個模型，在各項任務中測試 9 個主要提示範本。主要發現顯示，GPT-4 和 Llama 3 等模型在二元障礙偵測中表現出優異的效能，在特定資料集上的準確率高達 85%。此外，提示工程在提升模型效能方面扮演至關重要的角色。值得注意的是，Mixtral 8x22b 模型的進步幅度超過 20%，而 Gemma 7b 的效能也獲得類似的提升。在障礙嚴重性評估任務中，我們觀察到 FS 學習顯著提升模型的準確度，突顯出背景範例在複雜評估中的重要性。值得注意的是，Phi-3-mini 模型的效能大幅提升，從 ZS 學習轉換到 FS 學習後，平衡準確度提升超過 6.80%，平均平均誤差降低近 1.3。在精神疾病知識任務中，較新的模型通常優於較舊、較大的模型，其中 Llama 3.1 405b 達到 91.2% 的準確度。儘管有令人振奮的結果，我們的分析發現了幾個挑戰，包括跨資料集的效能變異性，以及仔細提示工程的需求。此外，許多 LLM 提供者施加的道德守則阻礙了準確評估其效能的能力，因為它們傾向於不回應潛在的敏感查詢。

##### **TFT-multi: simultaneous forecasting of vital sign trajectories in the ICU**
2409.15586v2 by Rosemary Y. He, Jeffrey N. Chiang

Trajectory forecasting in healthcare data has been an important area of
research in precision care and clinical integration for computational methods.
In recent years, generative AI models have demonstrated promising results in
capturing short and long range dependencies in time series data. While these
models have also been applied in healthcare, most of them only predict one
value at a time, which is unrealistic in a clinical setting where multiple
measures are taken at once. In this work, we extend the framework temporal
fusion transformer (TFT), a multi-horizon time series prediction tool, and
propose TFT-multi, an end-to-end framework that can predict multiple vital
trajectories simultaneously. We apply TFT-multi to forecast 5 vital signs
recorded in the intensive care unit: blood pressure, pulse, SpO2, temperature
and respiratory rate. We hypothesize that by jointly predicting these measures,
which are often correlated with one another, we can make more accurate
predictions, especially in variables with large missingness. We validate our
model on the public MIMIC dataset and an independent institutional dataset, and
demonstrate that this approach outperforms state-of-the-art univariate
prediction tools including the original TFT and Prophet, as well as vector
regression modeling for multivariate prediction. Furthermore, we perform a
study case analysis by applying our pipeline to forecast blood pressure changes
in response to actual and hypothetical pressor administration.

摘要：醫療數據中的軌跡預測一直是精準照護和臨床整合中計算方法的重要研究領域。近年來，生成式 AI 模型在捕捉時間序列資料中的短程和長程依賴關係方面已展現出令人滿意的成果。儘管這些模型也已應用於醫療保健，但其中大多數一次只預測一個值，這在一次採取多項測量的臨床環境中是不切實際的。在這項工作中，我們擴充了時序融合Transformer (TFT) 這個多地平線時間序列預測工具，並提出 TFT-multi，這是一個可以同時預測多個重要軌跡的端對端框架。我們將 TFT-multi 應用於預測在加護病房中記錄的 5 個生命徵象：血壓、脈搏、SpO2、體溫和呼吸速率。我們假設透過共同預測這些通常彼此相關的測量值，我們可以做出更準確的預測，特別是在缺失值較多的變數中。我們在公開的 MIMIC 資料集和一個獨立的機構資料集上驗證我們的模型，並證明這種方法優於最先進的單變量預測工具，包括原始的 TFT 和 Prophet，以及用於多變量預測的向量回歸建模。此外，我們透過將我們的管道應用於預測對實際和假設的升壓劑給藥的反應，來執行案例分析研究血壓變化。

##### **MRI Radiomics for IDH Genotype Prediction in Glioblastoma Diagnosis**
2409.16329v1 by Stanislav Kozák

Radiomics is a relatively new field which utilises automatically identified
features from radiological scans. It has found a widespread application,
particularly in oncology because many of the important oncological biomarkers
are not visible to the naked eye. The recent advent of big data, including in
medical imaging, and the development of new ML techniques brought the
possibility of faster and more accurate oncological diagnosis. Furthermore,
standardised mathematical feature extraction based on radiomics helps to
eliminate possible radiologist bias. This paper reviews the recent development
in the oncological use of MRI radiomic features. It focuses on the
identification of the isocitrate dehydrogenase (IDH) mutation status, which is
an important biomarker for the diagnosis of glioblastoma and grade IV
astrocytoma.

摘要：放射組學是一個相對較新的領域，它利用放射掃描自動識別的特徵。它已廣泛應用，特別是在腫瘤學中，因為許多重要的腫瘤生物標誌物肉眼不可見。包括醫學影像在內的大數據最近的出現以及新機器學習技術的發展帶來了更快、更準確的腫瘤學診斷的可能性。此外，基於放射組學的標準化數學特徵提取有助於消除可能的放射科醫師偏見。本文回顧了放射組學特徵在腫瘤學應用中的最新發展。它側重於異檸檬酸脫氫酶 (IDH) 突變狀態的識別，這是診斷膠質母細胞瘤和 IV 級星形細胞瘤的重要生物標誌物。

##### **Computational Pathology for Accurate Prediction of Breast Cancer Recurrence: Development and Validation of a Deep Learning-based Tool**
2409.15491v1 by Ziyu Su, Yongxin Guo, Robert Wesolowski, Gary Tozbikian, Nathaniel S. O'Connell, M. Khalid Khan Niazi, Metin N. Gurcan

Accurate recurrence risk stratification is crucial for optimizing treatment
plans for breast cancer patients. Current prognostic tools like Oncotype DX
(ODX) offer valuable genomic insights for HR+/HER2- patients but are limited by
cost and accessibility, particularly in underserved populations. In this study,
we present Deep-BCR-Auto, a deep learning-based computational pathology
approach that predicts breast cancer recurrence risk from routine H&E-stained
whole slide images (WSIs). Our methodology was validated on two independent
cohorts: the TCGA-BRCA dataset and an in-house dataset from The Ohio State
University (OSU). Deep-BCR-Auto demonstrated robust performance in stratifying
patients into low- and high-recurrence risk categories. On the TCGA-BRCA
dataset, the model achieved an area under the receiver operating characteristic
curve (AUROC) of 0.827, significantly outperforming existing weakly supervised
models (p=0.041). In the independent OSU dataset, Deep-BCR-Auto maintained
strong generalizability, achieving an AUROC of 0.832, along with 82.0%
accuracy, 85.0% specificity, and 67.7% sensitivity. These findings highlight
the potential of computational pathology as a cost-effective alternative for
recurrence risk assessment, broadening access to personalized treatment
strategies. This study underscores the clinical utility of integrating deep
learning-based computational pathology into routine pathological assessment for
breast cancer prognosis across diverse clinical settings.

摘要：精準的復發風險分層對於最佳化乳癌病患的治療計畫至關重要。目前的預後工具，例如 Oncotype DX (ODX)，為 HR+/HER2- 病患提供了有價值的基因體見解，但成本和可及性有限，特別是在服務不足的人群中。在本研究中，我們提出 Deep-BCR-Auto，一種基於深度學習的計算病理學方法，可從常規 H&E 染色的全玻片影像 (WSI) 預測乳癌復發風險。我們的技術在兩個獨立的群組中得到驗證：TCGA-BRCA 資料集和來自俄亥俄州立大學 (OSU) 的內部資料集。Deep-BCR-Auto 在將患者分層為低和高復發風險類別方面表現出強大的效能。在 TCGA-BRCA 資料集上，該模型在受試者作業特徵曲線 (AUROC) 下方達到了 0.827 的面積，顯著優於現有的弱監督模型 (p=0.041)。在獨立的 OSU 資料集中，Deep-BCR-Auto 保持了很強的泛化性，達到了 0.832 的 AUROC，以及 82.0% 的準確度、85.0% 的特異度和 67.7% 的敏感度。這些發現突顯了計算病理學作為復發風險評估的經濟有效替代方案的潛力，擴大了個人化治療策略的可及性。這項研究強調了將基於深度學習的計算病理學整合到乳癌預後的常規病理評估中，在不同的臨床環境中具有臨床效用。

##### **A Preliminary Study of o1 in Medicine: Are We Closer to an AI Doctor?**
2409.15277v1 by Yunfei Xie, Juncheng Wu, Haoqin Tu, Siwei Yang, Bingchen Zhao, Yongshuo Zong, Qiao Jin, Cihang Xie, Yuyin Zhou

Large language models (LLMs) have exhibited remarkable capabilities across
various domains and tasks, pushing the boundaries of our knowledge in learning
and cognition. The latest model, OpenAI's o1, stands out as the first LLM with
an internalized chain-of-thought technique using reinforcement learning
strategies. While it has demonstrated surprisingly strong capabilities on
various general language tasks, its performance in specialized fields such as
medicine remains unknown. To this end, this report provides a comprehensive
exploration of o1 on different medical scenarios, examining 3 key aspects:
understanding, reasoning, and multilinguality. Specifically, our evaluation
encompasses 6 tasks using data from 37 medical datasets, including two newly
constructed and more challenging question-answering (QA) tasks based on
professional medical quizzes from the New England Journal of Medicine (NEJM)
and The Lancet. These datasets offer greater clinical relevance compared to
standard medical QA benchmarks such as MedQA, translating more effectively into
real-world clinical utility. Our analysis of o1 suggests that the enhanced
reasoning ability of LLMs may (significantly) benefit their capability to
understand various medical instructions and reason through complex clinical
scenarios. Notably, o1 surpasses the previous GPT-4 in accuracy by an average
of 6.2% and 6.6% across 19 datasets and two newly created complex QA scenarios.
But meanwhile, we identify several weaknesses in both the model capability and
the existing evaluation protocols, including hallucination, inconsistent
multilingual ability, and discrepant metrics for evaluation. We release our raw
data and model outputs at https://ucsc-vlaa.github.io/o1_medicine/ for future
research.

摘要：大型語言模型 (LLM) 在各種領域和任務中展現出非凡的能力，推動了我們在學習和認知方面的知識界限。最新的模型，OpenAI 的 o1，脫穎而出，成為第一個使用強化學習策略內化思想鏈技術的 LLM。雖然它在各種一般語言任務中展現出驚人強大的能力，但它在醫學等專業領域的表現仍然未知。為此，本報告全面探討了 o1 在不同醫療情境中的表現，檢視了 3 個關鍵面向：理解、推理和多語言能力。具體來說，我們的評估涵蓋了使用來自 37 個醫療資料集的資料的 6 項任務，包括兩個新建構且更具挑戰性的問答 (QA) 任務，這些任務是根據新英格蘭醫學期刊 (NEJM) 和刺胳針雜誌的專業醫療測驗而來。與 MedQA 等標準醫療 QA 基準相比，這些資料集提供了更高的臨床相關性，更有效地轉化為實際的臨床效用。我們對 o1 的分析表明，LLM 增強的推理能力可能（顯著地）提升它們理解各種醫療指示和推理複雜臨床情境的能力。值得注意的是，o1 在 19 個資料集和兩個新建立的複雜 QA 情境中的準確度平均比先前的 GPT-4 高出 6.2% 和 6.6%。但同時，我們發現模型能力和現有評估協定中存在若干弱點，包括幻覺、不一致的多語言能力和評估的差異化指標。我們在 https://ucsc-vlaa.github.io/o1_medicine/ 發布我們的原始資料和模型輸出，以供未來研究。

##### **Generative AI Is Not Ready for Clinical Use in Patient Education for Lower Back Pain Patients, Even With Retrieval-Augmented Generation**
2409.15260v1 by Yi-Fei Zhao, Allyn Bove, David Thompson, James Hill, Yi Xu, Yufan Ren, Andrea Hassman, Leming Zhou, Yanshan Wang

Low back pain (LBP) is a leading cause of disability globally. Following the
onset of LBP and subsequent treatment, adequate patient education is crucial
for improving functionality and long-term outcomes. Despite advancements in
patient education strategies, significant gaps persist in delivering
personalized, evidence-based information to patients with LBP. Recent
advancements in large language models (LLMs) and generative artificial
intelligence (GenAI) have demonstrated the potential to enhance patient
education. However, their application and efficacy in delivering educational
content to patients with LBP remain underexplored and warrant further
investigation. In this study, we introduce a novel approach utilizing LLMs with
Retrieval-Augmented Generation (RAG) and few-shot learning to generate tailored
educational materials for patients with LBP. Physical therapists manually
evaluated our model responses for redundancy, accuracy, and completeness using
a Likert scale. In addition, the readability of the generated education
materials is assessed using the Flesch Reading Ease score. The findings
demonstrate that RAG-based LLMs outperform traditional LLMs, providing more
accurate, complete, and readable patient education materials with less
redundancy. Having said that, our analysis reveals that the generated materials
are not yet ready for use in clinical practice. This study underscores the
potential of AI-driven models utilizing RAG to improve patient education for
LBP; however, significant challenges remain in ensuring the clinical relevance
and granularity of content generated by these models.

摘要：下背痛 (LBP) 是全球導致殘疾的主要原因。在 LBP 發作和後續治療後，充分的患者教育對於改善功能和長期結果至關重要。儘管患者教育策略取得進展，但向 LBP 患者提供個性化、循證信息的過程中仍存在顯著差距。大型語言模型 (LLM) 和生成式人工智能 (GenAI) 的最新進展已證明有增強患者教育的潛力。然而，它們在向 LBP 患者傳遞教育內容方面的應用和功效仍未得到充分探索，有待進一步調查。在本研究中，我們引入一種新方法，利用具有檢索增強生成 (RAG) 和少次學習的 LLM，為 LBP 患者生成量身定制的教育材料。物理治療師使用李克特量表手動評估我們的模型反應的冗餘性、準確性和完整性。此外，使用弗萊施閱讀簡易度評分評估生成的教育材料的可讀性。研究結果表明，基於 RAG 的 LLM 優於傳統 LLM，提供更準確、完整且可讀的患者教育材料，且冗餘性更低。話雖如此，我們的分析表明，生成的材料還不適合在臨床實務中使用。本研究強調了利用 RAG 的 AI 驅動模型在改善 LBP 患者教育方面的潛力；然而，確保這些模型生成的內容的臨床相關性和精細度仍存在重大挑戰。

##### **Boosting Healthcare LLMs Through Retrieved Context**
2409.15127v1 by Jordi Bayarri-Planas, Ashwin Kumar Gururajan, Dario Garcia-Gasulla

Large Language Models (LLMs) have demonstrated remarkable capabilities in
natural language processing, and yet, their factual inaccuracies and
hallucinations limits their application, particularly in critical domains like
healthcare. Context retrieval methods, by introducing relevant information as
input, have emerged as a crucial approach for enhancing LLM factuality and
reliability. This study explores the boundaries of context retrieval methods
within the healthcare domain, optimizing their components and benchmarking
their performance against open and closed alternatives. Our findings reveal how
open LLMs, when augmented with an optimized retrieval system, can achieve
performance comparable to the biggest private solutions on established
healthcare benchmarks (multiple-choice question answering). Recognizing the
lack of realism of including the possible answers within the question (a setup
only found in medical exams), and after assessing a strong LLM performance
degradation in the absence of those options, we extend the context retrieval
system in that direction. In particular, we propose OpenMedPrompt a pipeline
that improves the generation of more reliable open-ended answers, moving this
technology closer to practical application.

摘要：大型語言模型 (LLM) 在自然語言處理方面展現了卓越的能力，然而，它們的事實不準確和幻覺限制了它們的應用，特別是在醫療保健等關鍵領域。情境檢索方法透過引入相關資訊作為輸入，成為增強 LLM 事實性和可靠性的關鍵方法。本研究探討了情境檢索方法在醫療保健領域的界線，最佳化其元件，並根據開放和封閉的替代方案對其效能進行基準測試。我們的研究結果揭示了開放式 LLM 在結合最佳化檢索系統後，如何在既定的醫療保健基準（多選題答題）上達到與最大的私人解決方案相當的效能。認識到在問題中包含可能的答案（僅在醫學考試中發現的設定）缺乏現實性，並在評估在沒有這些選項的情況下 LLM 效能大幅下降後，我們將情境檢索系統擴展到該方向。特別是，我們提出 OpenMedPrompt，一個管道，用於改善更可靠的開放式答案的產生，讓這項技術更接近實際應用。

##### **Generalizing monocular colonoscopy image depth estimation by uncertainty-based global and local fusion network**
2409.15006v1 by Sijia Du, Chengfeng Zhou, Suncheng Xiang, Jianwei Xu, Dahong Qian

Objective: Depth estimation is crucial for endoscopic navigation and
manipulation, but obtaining ground-truth depth maps in real clinical scenarios,
such as the colon, is challenging. This study aims to develop a robust
framework that generalizes well to real colonoscopy images, overcoming
challenges like non-Lambertian surface reflection and diverse data
distributions. Methods: We propose a framework combining a convolutional neural
network (CNN) for capturing local features and a Transformer for capturing
global information. An uncertainty-based fusion block was designed to enhance
generalization by identifying complementary contributions from the CNN and
Transformer branches. The network can be trained with simulated datasets and
generalize directly to unseen clinical data without any fine-tuning. Results:
Our method is validated on multiple datasets and demonstrates an excellent
generalization ability across various datasets and anatomical structures.
Furthermore, qualitative analysis in real clinical scenarios confirmed the
robustness of the proposed method. Conclusion: The integration of local and
global features through the CNN-Transformer architecture, along with the
uncertainty-based fusion block, improves depth estimation performance and
generalization in both simulated and real-world endoscopic environments.
Significance: This study offers a novel approach to estimate depth maps for
endoscopy images despite the complex conditions in clinic, serving as a
foundation for endoscopic automatic navigation and other clinical tasks, such
as polyp detection and segmentation.

摘要：目標：深度估計對於內視鏡導航和操作至關重要，但在實際臨床場景中（例如結腸）取得真實深度圖非常具有挑戰性。本研究旨在開發一個強大的框架，可以很好地推廣到實際的結腸鏡檢查影像，克服非朗伯反射面和多樣化資料分佈等挑戰。方法：我們提出一個結合卷積神經網路（CNN）來擷取局部特徵和 Transformer 來擷取全局資訊的框架。設計了一個基於不確定性的融合區塊，透過識別 CNN 和 Transformer 分支的互補貢獻來增強泛化能力。網路可以用模擬資料集進行訓練，並直接推廣到未見過的臨床資料，而無需任何微調。結果：我們的模型在多個資料集上得到驗證，並展示出跨越各種資料集和解剖結構的出色泛化能力。此外，在實際臨床場景中的定性分析證實了所提出模型的穩健性。結論：透過 CNN-Transformer 架構整合局部和全局特徵，以及基於不確定性的融合區塊，改善了模擬和真實世界內視鏡環境中的深度估計效能和泛化能力。意義：本研究提供了一種新穎的方法來估計內視鏡影像的深度圖，儘管在臨床上有複雜的條件，但作為內視鏡自動導航和其他臨床任務（例如息肉檢測和分割）的基礎。

##### **DSG-KD: Knowledge Distillation from Domain-Specific to General Language Models**
2409.14904v1 by Sangyeon Cho, Jangyeong Jeon, Dongjoon Lee, Changhee Lee, Junyeong Kim

The use of pre-trained language models fine-tuned to address specific
downstream tasks is a common approach in natural language processing (NLP).
However, acquiring domain-specific knowledge via fine-tuning is challenging.
Traditional methods involve pretraining language models using vast amounts of
domain-specific data before fine-tuning for particular tasks. This study
investigates emergency/non-emergency classification tasks based on electronic
medical record (EMR) data obtained from pediatric emergency departments (PEDs)
in Korea. Our findings reveal that existing domain-specific pre-trained
language models underperform compared to general language models in handling
N-lingual free-text data characteristics of non-English-speaking regions. To
address these limitations, we propose a domain knowledge transfer methodology
that leverages knowledge distillation to infuse general language models with
domain-specific knowledge via fine-tuning. This study demonstrates the
effective transfer of specialized knowledge between models by defining a
general language model as the student model and a domain-specific pre-trained
model as the teacher model. In particular, we address the complexities of EMR
data obtained from PEDs in non-English-speaking regions, such as Korea, and
demonstrate that the proposed method enhances classification performance in
such contexts. The proposed methodology not only outperforms baseline models on
Korean PED EMR data, but also promises broader applicability in various
professional and technical domains. In future works, we intend to extend this
methodology to include diverse non-English-speaking regions and address
additional downstream tasks, with the aim of developing advanced model
architectures using state-of-the-art KD techniques. The code is available in
https://github.com/JoSangYeon/DSG-KD.

摘要：<paragraph>使用針對特定下游任務進行微調的預先訓練語言模型是自然語言處理 (NLP) 中的常見方法。然而，透過微調來獲取特定領域的知識具有挑戰性。傳統方法涉及使用大量的特定領域資料來預訓練語言模型，然後針對特定任務進行微調。本研究調查了基於從韓國小兒急診科 (PED) 取得的電子醫療紀錄 (EMR) 資料的緊急/非緊急分類任務。我們的研究結果顯示，現有的特定領域預訓練語言模型在處理非英語系地區的 N 語言自由文字資料特性時，表現不如一般語言模型。為了解決這些限制，我們提出了一種領域知識轉移方法，該方法利用知識蒸餾，透過微調將一般語言模型注入特定領域的知識。本研究透過將一般語言模型定義為學生模型，將特定領域的預訓練模型定義為老師模型，展示了模型之間專業知識的有效轉移。特別是，我們解決了從非英語系地區（例如韓國）的 PED 取得的 EMR 資料的複雜性，並展示了所提出的方法增強了此類情境中的分類效能。所提出的方法不僅在韓文 PED EMR 資料上優於基準模型，還承諾在各種專業和技術領域中更廣泛的應用性。在未來的研究中，我們打算擴展此方法以納入不同的非英語系地區，並解決其他下游任務，目標是使用最先進的 KD 技術開發先進的模型架構。程式碼可在 https://github.com/JoSangYeon/DSG-KD 取得。</paragraph>

##### **Mammo-Clustering:A Weakly Supervised Multi-view Global-Local Context Clustering Network for Detection and Classification in Mammography**
2409.14876v1 by Shilong Yang, Chulong Zhang, Qi Zang, Juan Yu, Liang Zeng, Xiao Luo, Yexuan Xing, Xin Pan, Qi Li, Xiaokun Liang, Yaoqin Xie

Breast cancer has long posed a significant threat to women's health, making
early screening crucial for mitigating its impact. However, mammography, the
preferred method for early screening, faces limitations such as the burden of
double reading by radiologists, challenges in widespread adoption in remote and
underdeveloped areas, and obstacles in intelligent early screening development
due to data constraints. To address these challenges, we propose a weakly
supervised multi-view mammography early screening model for breast cancer based
on context clustering. Context clustering, a feature extraction structure that
is neither CNN nor transformer, combined with multi-view learning for
information complementation, presents a promising approach. The weak
supervision design specifically addresses data limitations. Our model achieves
state-of-the-art performance with fewer parameters on two public datasets, with
an AUC of 0.828 on the Vindr-Mammo dataset and 0.805 on the CBIS-DDSM dataset.
Our model shows potential in reducing the burden on doctors and increasing the
feasibility of breast cancer screening for women in underdeveloped regions.

摘要：乳癌長期以來對女性健康構成重大威脅，及早篩檢對於減輕其影響至關重要。然而，乳房攝影術作為早期篩檢的首選方式，卻面臨放射科醫師雙重判讀的負擔、在偏遠和未開發地區廣泛採用所面臨的挑戰，以及由於資料限制而導致的智慧型早期篩檢開發障礙等限制。為了應對這些挑戰，我們提出一個基於脈絡聚類的乳癌弱監督多視角乳房攝影早期篩檢模型。脈絡聚類是一種既非 CNN 也非轉換器的特徵提取結構，結合多視角學習進行資訊互補，提供了一個有前景的方法。弱監督設計特別解決了資料限制的問題。我們的模型在兩個公開資料集上以較少的參數達到了最先進的效能，在 Vindr-Mammo 資料集上的 AUC 為 0.828，在 CBIS-DDSM 資料集上的 AUC 為 0.805。我們的模型顯示出減輕醫生負擔和增加未開發地區女性乳癌篩檢可行性的潛力。

##### **Towards Ground-truth-free Evaluation of Any Segmentation in Medical Images**
2409.14874v2 by Ahjol Senbi, Tianyu Huang, Fei Lyu, Qing Li, Yuhui Tao, Wei Shao, Qiang Chen, Chengyan Wang, Shuo Wang, Tao Zhou, Yizhe Zhang

We explore the feasibility and potential of building a ground-truth-free
evaluation model to assess the quality of segmentations generated by the
Segment Anything Model (SAM) and its variants in medical imaging. This
evaluation model estimates segmentation quality scores by analyzing the
coherence and consistency between the input images and their corresponding
segmentation predictions. Based on prior research, we frame the task of
training this model as a regression problem within a supervised learning
framework, using Dice scores (and optionally other metrics) along with mean
squared error to compute the training loss. The model is trained utilizing a
large collection of public datasets of medical images with segmentation
predictions from SAM and its variants. We name this model EvanySeg (Evaluation
of Any Segmentation in Medical Images). Our exploration of convolution-based
models (e.g., ResNet) and transformer-based models (e.g., ViT) suggested that
ViT yields better performance for this task. EvanySeg can be employed for
various tasks, including: (1) identifying poorly segmented samples by detecting
low-percentile segmentation quality scores; (2) benchmarking segmentation
models without ground truth by averaging quality scores across test samples;
(3) alerting human experts to poor-quality segmentation predictions during
human-AI collaboration by applying a threshold within the score space; and (4)
selecting the best segmentation prediction for each test sample at test time
when multiple segmentation models are available, by choosing the prediction
with the highest quality score. Models and code will be made available at
https://github.com/ahjolsenbics/EvanySeg.

摘要：<paragraph>我們探討建立一個無地面實相的評估模型，以評估由 Segment Anything Model (SAM) 及其在醫學影像中的變體所產生的分割品質的可行性和潛力。此評估模型透過分析輸入影像與其對應分割預測之間的相干性和一致性來估計分割品質分數。根據先前的研究，我們將訓練此模型的任務設定為監督式學習架構中的回歸問題，使用 Dice 分數（以及其他指標，可選擇）與平均平方誤差一起計算訓練損失。此模型使用來自 SAM 及其變體的分割預測的大型公共醫學影像資料集進行訓練。我們將此模型命名為 EvanySeg（醫學影像中任何分割的評估）。我們對基於卷積的模型（例如 ResNet）和基於Transformer的模型（例如 ViT）的探討表明，ViT 在此任務中表現得更好。EvanySeg 可用於各種任務，包括：(1) 透過偵測低百分位數分割品質分數來識別分割不良的樣本；(2) 透過平均測試樣本的品質分數來對沒有地面實相的分割模型進行基準測試；(3) 在人機協作期間，透過在分數空間中應用閾值來提醒人類專家注意品質不佳的分割預測；(4) 在測試時間為每個測試樣本選擇最佳分割預測（當有多個分割模型可用時），透過選擇具有最高品質分數的預測。模型和程式碼將在 https://github.com/ahjolsenbics/EvanySeg 提供。</paragraph>

##### **A-VL: Adaptive Attention for Large Vision-Language Models**
2409.14846v1 by Junyang Zhang, Mu Yuan, Ruiguang Zhong, Puhan Luo, Huiyou Zhan, Ningkang Zhang, Chengchen Hu, Xiangyang Li

The Large Vision-Language Model (LVLM) integrates computer vision and natural
language processing techniques, offering substantial application potential.
However, these models demand extensive resources during inference. Adaptive
attention techniques can dynamically reduce computational redundancy and thus
improve efficiency. Although current adaptive attention methods significantly
reduce the memory requirements of Transformer-based language models, they are
not tailored for LVLMs. We observe that LVLMs generate responses from both
remote image tokens and local text tokens, and different modalities have
different attention patterns. This observation inspires us to manage the
attention for each modality separately. Specifically, for visual input, we
store the cache of potentially useful information but only compute the most
critical parts. For language input, we care more about local information. Based
on our observation and analysis of vision-language attention patterns, we
develop A-VL, a plug-and-play adaptive attention tailored for LVLM inference.
Extensive evaluations on three vision-language tasks and five datasets show the
effectiveness of our designs. Our approach A-VL outperforms existing adaptive
attention methods in reducing memory usage and computational load without
compromising performance.

摘要：大型视觉语言模型 (LVLM) 整合了计算机视觉和自然语言处理技术，提供了大量的应用潜力。然而，这些模型在推理过程中需要大量的资源。自适应注意力技术可以动态减少计算冗余，从而提高效率。虽然当前的自适应注意力方法显著减少了基于 Transformer 的语言模型的内存需求，但它们并不适合 LVLM。我们观察到，LVLM 从远程图像标记和局部文本标记生成响应，并且不同的模态具有不同的注意力模式。这一观察启发了我们分别管理每个模态的注意力。具体来说，对于视觉输入，我们存储潜在有用信息的缓存，但只计算最关键的部分。对于语言输入，我们更关心局部信息。基于我们对视觉语言注意力模式的观察和分析，我们开发了 A-VL，这是一种针对 LVLM 推理量身定制的即插即用自适应注意力。在三个视觉语言任务和五个数据集上的广泛评估表明了我们设计的有效性。我们的方法 A-VL 在减少内存使用和计算负载方面优于现有的自适应注意力方法，同时不影响性能。

##### **Can Large Language Models Logically Predict Myocardial Infarction? Evaluation based on UK Biobank Cohort**
2409.14478v1 by Yuxing Zhi, Yuan Guo, Kai Yuan, Hesong Wang, Heng Xu, Haina Yao, Albert C Yang, Guangrui Huang, Yuping Duan

Background: Large language models (LLMs) have seen extraordinary advances
with applications in clinical decision support. However, high-quality evidence
is urgently needed on the potential and limitation of LLMs in providing
accurate clinical decisions based on real-world medical data. Objective: To
evaluate quantitatively whether universal state-of-the-art LLMs (ChatGPT and
GPT-4) can predict the incidence risk of myocardial infarction (MI) with
logical inference, and to further make comparison between various models to
assess the performance of LLMs comprehensively. Methods: In this retrospective
cohort study, 482,310 participants recruited from 2006 to 2010 were initially
included in UK Biobank database and later on resampled into a final cohort of
690 participants. For each participant, tabular data of the risk factors of MI
were transformed into standardized textual descriptions for ChatGPT
recognition. Responses were generated by asking ChatGPT to select a score
ranging from 0 to 10 representing the risk. Chain of Thought (CoT) questioning
was used to evaluate whether LLMs make prediction logically. The predictive
performance of ChatGPT was compared with published medical indices, traditional
machine learning models and other large language models. Conclusions: Current
LLMs are not ready to be applied in clinical medicine fields. Future medical
LLMs are suggested to be expert in medical domain knowledge to understand both
natural languages and quantified medical data, and further make logical
inferences.

摘要：<paragraph>背景：大型語言模型 (LLM) 已在臨床決策支持應用中取得非凡進展。然而，迫切需要高品質的證據來證明 LLM 在根據現實世界醫療數據提供準確臨床決策方面的潛力和限制。目標：定量評估通用最先進的 LLM（ChatGPT 和 GPT-4）是否能通過邏輯推理預測心肌梗塞 (MI) 的發生風險，並進一步在各種模型之間進行比較，以全面評估 LLM 的效能。方法：在這項回顧性隊列研究中，最初將 2006 年至 2010 年招募的 482,310 名參與者納入英國生物銀行資料庫，並隨後重新抽樣成 690 名參與者的最終隊列。對於每位參與者，MI 風險因子的表格資料都轉換成 ChatGPT 辨識的標準文字描述。回應是透過要求 ChatGPT 選擇一個介於 0 到 10 之間的評分來代表風險。思想鏈 (CoT) 提問用於評估 LLM 是否以邏輯方式進行預測。將 ChatGPT 的預測效能與已發表的醫療指數、傳統機器學習模型和其他大型語言模型進行比較。結論：目前的 LLM 尚未準備好應用於臨床醫學領域。建議未來的醫療 LLM 專精於醫療領域知識，以了解自然語言和量化的醫療數據，並進一步進行邏輯推理。</paragraph>

##### **Detection of pulmonary pathologies using convolutional neural networks, Data Augmentation, ResNet50 and Vision Transformers**
2409.14446v1 by Pablo Ramirez Amador, Dinarle Milagro Ortega, Arnold Cesarano

Pulmonary diseases are a public health problem that requires accurate and
fast diagnostic techniques. In this paper, a method based on convolutional
neural networks (CNN), Data Augmentation, ResNet50 and Vision Transformers
(ViT) is proposed to detect lung pathologies from medical images. A dataset of
X-ray images and CT scans of patients with different lung diseases, such as
cancer, pneumonia, tuberculosis and fibrosis, is used. The results obtained by
the proposed method are compared with those of other existing methods, using
performance metrics such as accuracy, sensitivity, specificity and area under
the ROC curve. The results show that the proposed method outperforms the other
methods in all metrics, achieving an accuracy of 98% and an area under the ROC
curve of 99%. It is concluded that the proposed method is an effective and
promising tool for the diagnosis of pulmonary pathologies by medical imaging.

摘要：肺部疾病是一種公共衛生問題，需要準確且快速的診斷技術。在本文中，提出了一種基於卷積神經網路 (CNN)、資料擴充、ResNet50 和視覺Transformer (ViT) 的方法，以從醫學影像中偵測肺部病理。我們使用了一組 X 光影像和不同肺部疾病患者的電腦斷層掃描，例如癌症、肺炎、肺結核和纖維化。將所提出的方法獲得的結果與其他現有方法的結果進行比較，使用準確度、敏感度、特異度和 ROC 曲線下的面積等效能指標。結果顯示，所提出的方法在所有指標上都優於其他方法，準確度達到 98%，ROC 曲線下的面積為 99%。結論是，所提出的方法是一種有效且有前途的工具，可透過醫學影像診斷肺部病理。

##### **Data-Driven Spatiotemporal Feature Representation and Mining in Multidimensional Time Series**
2409.14327v1 by Xu Yan, Yaoting Jiang, Wenyi Liu, Didi Yi, Haoyang Sang, Jianjun Wei

This paper explores a new method for time series data analysis, aiming to
overcome the limitations of traditional mining techniques when dealing with
multidimensional time series data. Time series data are extensively utilized in
diverse fields, including backend services for monitoring and optimizing IT
infrastructure, medical diagnosis through continuous patient monitoring and
health trend analysis, and internet business for tracking user behavior and
forecasting sales. However, since the effective information in time series data
is often hidden in sequence fragments, the uncertainty of their length,
quantity, and morphological variables brings challenges to mining. To this end,
this paper proposes a new spatiotemporal feature representation method, which
converts multidimensional time series (MTS) into one-dimensional event
sequences by transforming spatially varying events, and uses a series of event
symbols to represent the spatial structural information of multidimensional
coupling in the sequence, which has good interpretability. Then, this paper
introduces a variable-length tuple mining method to extract non-redundant key
event subsequences in event sequences as spatiotemporal structural features of
motion sequences. This method is an unsupervised method that does not rely on
large-scale training samples and defines a new model for representing the
spatiotemporal structural features of multidimensional time series. The
superior performance of the STEM model is verified by pattern classification
experiments on a variety of motion sequences. The research results of this
paper provide an important theoretical basis and technical support for
understanding and predicting human behavior patterns, and have far-reaching
practical application value.

摘要：<paragraph>本文探討了一種新的時間序列資料分析方法，旨在克服傳統挖掘技術在處理多維時間序列資料時的限制。時間序列資料廣泛用於各種領域，包括用於監控和最佳化 IT 基礎架構的後端服務、透過持續監控患者和健康趨勢分析進行的醫療診斷，以及用於追蹤使用者行為和預測銷售的網路業務。然而，由於時間序列資料中的有效資訊通常隱藏在序列片段中，因此其長度、數量和形態變數的不確定性為挖掘帶來了挑戰。為此，本文提出了一種新的時空特徵表示方法，該方法透過轉換空間上變化的事件將多維時間序列 (MTS) 轉換為一維事件序列，並使用一系列事件符號來表示序列中多維耦合的空間結構資訊，具有良好的可解釋性。然後，本文引入一種變長元組挖掘方法，以提取事件序列中非冗餘的關鍵事件子序列，作為動作序列的時空結構特徵。此方法是一種無監督方法，不依賴於大規模訓練樣本，並定義了一個新的模型來表示多維時間序列的時空結構特徵。STEM 模型的優異效能已通過各種動作序列上的模式分類實驗得到驗證。本文的研究成果為理解和預測人類行為模式提供了重要的理論基礎和技術支援，並具有深遠的實用應用價值。</paragraph>

##### **PretextTrans: Investigating Medical Factual Knowledge Mastery of LLMs with Predicate-text Dual Transformation**
2409.14302v1 by Yuxuan Zhou, Xien Liu, Chen Ning, Ji Wu

In the study, we aim to investigate current LLMs' mastery of medical factual
knowledge with a dynamic evaluation schema, which can automatically generate
multiple test samples for each medical factual knowledge point. Test samples
produced directly by LLMs always introduce factual errors and lack diversity in
the manner of knowledge expression. To overcome the drawbacks, here we propose
a novel evaluation method, Predicate-text Dual Transformation (PretextTrans),
by introducing predicate transformations into the dynamic evaluation schema.
Specifically, each medical knowledge point is firstly transformed into a
predicate expression; then, the predicate expression derives a series of
variants through predicate transformations; lastly, the produced predicate
variants are transformed back into textual expressions, resulting in a series
of test samples with both factual reliability and expression diversity. Using
the proposed PretextTrans method, we systematically investigate 12 well-known
LLMs' mastery of medical factual knowledge based on two medical datasets. The
comparison results show that current LLMs still have significant deficiencies
in fully mastering medical knowledge, which may illustrate why current LLMs
still perform unsatisfactorily in real-world medical scenarios despite having
achieved considerable performance on public benchmarks. Our proposed method
serves as an effective solution for evaluation of LLMs in medical domain and
offers valuable insights for developing medical-specific LLMs.

摘要：<paragraph>在研究中，我們旨在使用動態評估架構來調查當前 LLM 對醫學事實知識的掌握情況，該架構可以自動為每個醫學事實知識點生成多個測試樣本。由 LLM 直接產生的測試樣本總是會引入事實錯誤，並且在知識表達方式上缺乏多樣性。為了克服這些缺點，我們在此提出了一種新的評估方法，即謂詞-文本雙重轉換 (PretextTrans)，通過將謂詞轉換引入動態評估架構中。具體來說，每個醫學知識點首先被轉換為謂詞表達式；然後，謂詞表達式通過謂詞轉換得到一系列變體；最後，產生的謂詞變體被轉換回文本表達式，從而產生一系列既具有事實可靠性又具有表達多樣性的測試樣本。使用所提出的 PretextTrans 方法，我們系統地調查了 12 個著名的 LLM 對基於兩個醫學數據集的醫學事實知識的掌握情況。比較結果表明，當前 LLM 在完全掌握醫學知識方面仍然存在顯著的缺陷，這可能說明了為什麼當前 LLM 在現實世界的醫學場景中表現仍然不令人滿意，儘管在公共基準上取得了顯著的表現。我們提出的方法作為一種有效的解決方案，用於評估醫學領域的 LLM，並為開發特定於醫學的 LLM 提供了寶貴的見解。</paragraph>

##### **Data-Driven Approach to assess and identify gaps in healthcare set up in South Asia**
2409.14194v1 by Rusham Elahi, Zia Tahseen, Tehreem Fatima, Syed Wafa Zahra, Hafiz Muhammad Abubakar, Tehreem Zafar, Aqs Younas, Muhammad Talha Quddoos, Usman Nazir

Primary healthcare is a crucial strategy for achieving universal health
coverage. South Asian countries are working to improve their primary healthcare
system through their country specific policies designed in line with WHO health
system framework using the six thematic pillars: Health Financing, Health
Service delivery, Human Resource for Health, Health Information Systems,
Governance, Essential Medicines and Technology, and an addition area of
Cross-Sectoral Linkages. Measuring the current accessibility of healthcare
facilities and workforce availability is essential for improving healthcare
standards and achieving universal health coverage in developing countries.
Data-driven surveillance approaches are required that can provide rapid,
reliable, and geographically scalable solutions to understand a) which
communities and areas are most at risk of inequitable access and when, b) what
barriers to health access exist, and c) how they can be overcome in ways
tailored to the specific challenges faced by individual communities. We propose
to harness current breakthroughs in Earth-observation (EO) technology, which
provide the ability to generate accurate, up-to-date, publicly accessible, and
reliable data, which is necessary for equitable access planning and resource
allocation to ensure that vaccines, and other interventions reach everyone,
particularly those in greatest need, during normal and crisis times. This
requires collaboration among countries to identify evidence based solutions to
shape health policy and interventions, and drive innovations and research in
the region.

摘要：初級保健是實現全民健保的關鍵策略。南亞國家透過制定符合 WHO 健保系統架構的國家特定政策，使用六大主題支柱來改善其初級保健系統：健保融資、健保服務提供、健保人力資源、健保資訊系統、治理、基本藥物與技術，以及跨部門連結的附加領域。衡量當前健保設施的可及性和人力可得性，對於提升健保標準和在開發中國家實現全民健保至關重要。需要以資料為基礎的監控方法，才能提供快速、可靠且在地域上可擴充的解決方案，以了解 a) 哪些社區和地區最容易遭受不公平的醫療服務，以及何時會發生、b) 醫療服務存有哪方面的障礙，以及 c) 如何以針對各個社區所面臨特定挑戰的方式克服這些障礙。我們提議利用地球觀測 (EO) 技術的最新突破，這些技術能產生準確、最新、公開且可靠的資料，這對於公平的醫療服務規劃和資源分配至關重要，以確保疫苗和其他干預措施能惠及所有人，特別是在正常和危機時期最需要的人。這需要各國合作，找出證據為基礎的解決方案，以制定健保政策和干預措施，並推動該地區的創新和研究。

##### **Democratising Artificial Intelligence for Pandemic Preparedness and Global Governance in Latin American and Caribbean Countries**
2409.14181v1 by Andre de Carvalho, Robson Bonidia, Jude Dzevela Kong, Mariana Dauhajre, Claudio Struchiner, Guilherme Goedert, Peter F. Stadler, Maria Emilia Walter, Danilo Sanches, Troy Day, Marcia Castro, John Edmunds, Manuel Colome-Hidalgo, Demian Arturo Herrera Morban, Edian F. Franco, Cesar Ugarte-Gil, Patricia Espinoza-Lopez, Gabriel Carrasco-Escobar, Ulisses Rocha

Infectious diseases, transmitted directly or indirectly, are among the
leading causes of epidemics and pandemics. Consequently, several open
challenges exist in predicting epidemic outbreaks, detecting variants, tracing
contacts, discovering new drugs, and fighting misinformation. Artificial
Intelligence (AI) can provide tools to deal with these scenarios, demonstrating
promising results in the fight against the COVID-19 pandemic. AI is becoming
increasingly integrated into various aspects of society. However, ensuring that
AI benefits are distributed equitably and that they are used responsibly is
crucial. Multiple countries are creating regulations to address these concerns,
but the borderless nature of AI requires global cooperation to define
regulatory and guideline consensus. Considering this, The Global South AI for
Pandemic & Epidemic Preparedness & Response Network (AI4PEP) has developed an
initiative comprising 16 projects across 16 countries in the Global South,
seeking to strengthen equitable and responsive public health systems that
leverage Southern-led responsible AI solutions to improve prevention,
preparedness, and response to emerging and re-emerging infectious disease
outbreaks. This opinion introduces our branches in Latin American and Caribbean
(LAC) countries and discusses AI governance in LAC in the light of
biotechnology. Our network in LAC has high potential to help fight infectious
diseases, particularly in low- and middle-income countries, generating
opportunities for the widespread use of AI techniques to improve the health and
well-being of their communities.

摘要：傳染病的直接或間接傳播是造成流行病和全球大流行的主要原因之一。因此，在預測流行病爆發、檢測變異株、追蹤接觸者、發現新藥物和對抗錯誤訊息方面存在許多未解決的挑戰。人工智慧 (AI) 可提供應對這些情境的工具，在對抗 COVID-19 大流行方面展現出令人振奮的成果。AI 正日益融入社會的各個層面。然而，確保 AI 的好處能公平分配且負責任地使用至關重要。許多國家正制定法規來解決這些問題，但 AI 的無國界性質需要全球合作才能定義法規和指導方針的共識。有鑑於此，全球南方 AI 防疫和流行病防範及應變網路 (AI4PEP) 已開發一項計畫，包含全球南方 16 個國家/地區的 16 個專案，旨在強化公平且具應變能力的公共衛生系統，並利用南方主導的負責任 AI 解決方案來改善對新興和再興傳染病爆發的預防、防範和應變。本意見書介紹我們在拉丁美洲和加勒比海 (LAC) 國家的分支機構，並根據生物技術探討 LAC 中的 AI 治理。我們在 LAC 的網路極具潛力，有助於對抗傳染病，特別是在低收入和中等收入國家，並為廣泛使用 AI 技術創造機會，以改善其社區的健康和福祉。

##### **CI-Bench: Benchmarking Contextual Integrity of AI Assistants on Synthetic Data**
2409.13903v1 by Zhao Cheng, Diane Wan, Matthew Abueg, Sahra Ghalebikesabi, Ren Yi, Eugene Bagdasarian, Borja Balle, Stefan Mellem, Shawn O'Banion

Advances in generative AI point towards a new era of personalized
applications that perform diverse tasks on behalf of users. While general AI
assistants have yet to fully emerge, their potential to share personal data
raises significant privacy challenges. This paper introduces CI-Bench, a
comprehensive synthetic benchmark for evaluating the ability of AI assistants
to protect personal information during model inference. Leveraging the
Contextual Integrity framework, our benchmark enables systematic assessment of
information flow across important context dimensions, including roles,
information types, and transmission principles. We present a novel, scalable,
multi-step synthetic data pipeline for generating natural communications,
including dialogues and emails. Unlike previous work with smaller, narrowly
focused evaluations, we present a novel, scalable, multi-step data pipeline
that synthetically generates natural communications, including dialogues and
emails, which we use to generate 44 thousand test samples across eight domains.
Additionally, we formulate and evaluate a naive AI assistant to demonstrate the
need for further study and careful training towards personal assistant tasks.
We envision CI-Bench as a valuable tool for guiding future language model
development, deployment, system design, and dataset construction, ultimately
contributing to the development of AI assistants that align with users' privacy
expectations.

摘要：生成式 AI 的進展指向一個新的個人化應用程式時代，這些應用程式可以代表使用者執行各種任務。儘管通用 AI 助理尚未完全出現，但它們共享個人資料的潛力引發了重大的隱私挑戰。本文介紹 CI-Bench，一個全面的合成基準，用於評估 AI 助理在模型推論期間保護個人資訊的能力。利用情境完整性架構，我們的基準可以系統性地評估跨越重要情境維度的資訊流，包括角色、資訊類型和傳輸原則。我們提出了一個新穎、可擴充、多步驟的合成資料管道，用於產生自然溝通，包括對話和電子郵件。與先前針對較小、重點較窄的評估所做的工作不同，我們提出了一個新穎、可擴充、多步驟的資料管道，可以合成產生自然溝通，包括對話和電子郵件，我們使用這些資料在八個網域中產生了 44,000 個測試範例。此外，我們制定並評估了一個天真的 AI 助理，以證明需要進一步研究和仔細培訓，才能執行個人助理任務。我們將 CI-Bench 視為指導未來語言模型開發、部署、系統設計和資料集建構的寶貴工具，最終有助於開發符合使用者隱私預期的 AI 助理。

##### **Enhancing Large Language Models with Domain-specific Retrieval Augment Generation: A Case Study on Long-form Consumer Health Question Answering in Ophthalmology**
2409.13902v1 by Aidan Gilson, Xuguang Ai, Thilaka Arunachalam, Ziyou Chen, Ki Xiong Cheong, Amisha Dave, Cameron Duic, Mercy Kibe, Annette Kaminaka, Minali Prasad, Fares Siddig, Maxwell Singer, Wendy Wong, Qiao Jin, Tiarnan D. L. Keenan, Xia Hu, Emily Y. Chew, Zhiyong Lu, Hua Xu, Ron A. Adelman, Yih-Chung Tham, Qingyu Chen

Despite the potential of Large Language Models (LLMs) in medicine, they may
generate responses lacking supporting evidence or based on hallucinated
evidence. While Retrieval Augment Generation (RAG) is popular to address this
issue, few studies implemented and evaluated RAG in downstream domain-specific
applications. We developed a RAG pipeline with 70,000 ophthalmology-specific
documents that retrieve relevant documents to augment LLMs during inference
time. In a case study on long-form consumer health questions, we systematically
evaluated the responses including over 500 references of LLMs with and without
RAG on 100 questions with 10 healthcare professionals. The evaluation focuses
on factuality of evidence, selection and ranking of evidence, attribution of
evidence, and answer accuracy and completeness. LLMs without RAG provided 252
references in total. Of which, 45.3% hallucinated, 34.1% consisted of minor
errors, and 20.6% were correct. In contrast, LLMs with RAG significantly
improved accuracy (54.5% being correct) and reduced error rates (18.8% with
minor hallucinations and 26.7% with errors). 62.5% of the top 10 documents
retrieved by RAG were selected as the top references in the LLM response, with
an average ranking of 4.9. The use of RAG also improved evidence attribution
(increasing from 1.85 to 2.49 on a 5-point scale, P<0.001), albeit with slight
decreases in accuracy (from 3.52 to 3.23, P=0.03) and completeness (from 3.47
to 3.27, P=0.17). The results demonstrate that LLMs frequently exhibited
hallucinated and erroneous evidence in the responses, raising concerns for
downstream applications in the medical domain. RAG substantially reduced the
proportion of such evidence but encountered challenges.

摘要：儘管大型語言模型（LLM）在醫學領域具有潛力，但它們可能會產生缺乏支持證據或基於虛構證據的回應。雖然檢索擴充生成（RAG）很受歡迎，用於解決此問題，但很少有研究在下游特定領域的應用中實施和評估 RAG。我們開發了一個 RAG 管線，其中包含 70,000 份特定於眼科的文件，這些文件會在推理時間檢索相關文件以擴充 LLM。在針對長篇消費者健康問題的案例研究中，我們系統性地評估了 LLM 的回應，包括 100 個問題中 500 多個引用，其中 10 個問題由 10 位醫療保健專業人員提出。評估重點在於證據的真實性、證據的選擇和排名、證據的歸因，以及答案的準確性和完整性。沒有 RAG 的 LLM 總共提供了 252 個參考。其中，45.3% 是虛構的，34.1% 包含輕微錯誤，20.6% 是正確的。相比之下，帶有 RAG 的 LLM 大幅提高了準確度（54.5% 是正確的）並降低了錯誤率（18.8% 有輕微虛構，26.7% 有錯誤）。RAG 檢索的前 10 份文件中有 62.5% 被選為 LLM 回應中的首要參考，平均排名為 4.9。RAG 的使用也改進了證據歸因（在 5 分量表上從 1.85 增加到 2.49，P<0.001），儘管準確度（從 3.52 降低到 3.23，P=0.03）和完整性（從 3.47 降低到 3.27，P=0.17）略有下降。結果表明，LLM 在回應中經常表現出虛構和錯誤的證據，這引起了對醫療領域下游應用程序的擔憂。RAG 大幅減少了此類證據的比例，但遇到了挑戰。

##### **A Personalised 3D+t Mesh Generative Model for Unveiling Normal Heart Dynamics**
2409.13825v1 by Mengyun Qiao, Kathryn A McGurk, Shuo Wang, Paul M. Matthews, Declan P O Regan, Wenjia Bai

Understanding the structure and motion of the heart is crucial for diagnosing
and managing cardiovascular diseases, the leading cause of global death. There
is wide variation in cardiac shape and motion patterns, that are influenced by
demographic, anthropometric and disease factors. Unravelling the normal
patterns of shape and motion, as well as understanding how each individual
deviates from the norm, would facilitate accurate diagnosis and personalised
treatment strategies. To this end, we developed a novel conditional generative
model, MeshHeart, to learn the distribution of cardiac shape and motion
patterns. MeshHeart is capable of generating 3D+t cardiac mesh sequences,
taking into account clinical factors such as age, sex, weight and height. To
model the high-dimensional and complex spatio-temporal mesh data, MeshHeart
employs a geometric encoder to represent cardiac meshes in a latent space,
followed by a temporal Transformer to model the motion dynamics of latent
representations. Based on MeshHeart, we investigate the latent space of 3D+t
cardiac mesh sequences and propose a novel distance metric termed latent delta,
which quantifies the deviation of a real heart from its personalised normative
pattern in the latent space. In experiments using a large dataset of 38,309
subjects, MeshHeart demonstrates a high performance in cardiac mesh sequence
reconstruction and generation. Features defined in the latent space are highly
discriminative for cardiac disease classification, whereas the latent delta
exhibits strong correlation with clinical phenotypes in phenome-wide
association studies. The codes and models of this study will be released to
benefit further research on digital heart modelling.

摘要：<paragraph>了解心脏的结构和运动对于诊断和管理心血管疾病至关重要，而心血管疾病是全球主要的死亡原因。心脏的形状和运动模式有很大的差异，这些差异受人口统计学、人体测量学和疾病因素的影响。解开形状和运动的正常模式，以及了解每个人如何偏离常态，将有助于准确诊断和个性化治疗策略。为此，我们开发了一种新颖的条件生成模型 MeshHeart，以学习心脏形状和运动模式的分布。MeshHeart 能够生成 3D+t 心脏网格序列，同时考虑年龄、性别、体重和身高等临床因素。为了对高维和复杂的时空网格数据建模，MeshHeart 采用几何编码器在潜在空间中表示心脏网格，然后采用时间转换器对潜在表示的运动动态进行建模。基于 MeshHeart，我们研究了 3D+t 心脏网格序列的潜在空间，并提出了一个新颖的距离度量，称为潜在增量，该度量量化了真实心脏在其潜在空间中与其个性化规范模式的偏差。在使用包含 38,309 名受试者的庞大数据集进行的实验中，MeshHeart 在心脏网格序列重建和生成方面表现出很高的性能。在潜在空间中定义的特征对于心脏疾病分类具有很高的判别力，而潜在增量在全表型关联研究中与临床表型表现出很强的相关性。本研究的代码和模型将发布，以造福对数字心脏建模的进一步研究。</paragraph>

##### **Morphological Detection and Classification of Microplastics and Nanoplastics Emerged from Consumer Products by Deep Learning**
2409.13688v1 by Hadi Rezvani, Navid Zarrabi, Ishaan Mehta, Christopher Kolios, Hussein Ali Jaafar, Cheng-Hao Kao, Sajad Saeedi, Nariman Yousefi

Plastic pollution presents an escalating global issue, impacting health and
environmental systems, with micro- and nanoplastics found across mediums from
potable water to air. Traditional methods for studying these contaminants are
labor-intensive and time-consuming, necessitating a shift towards more
efficient technologies. In response, this paper introduces micro- and
nanoplastics (MiNa), a novel and open-source dataset engineered for the
automatic detection and classification of micro and nanoplastics using object
detection algorithms. The dataset, comprising scanning electron microscopy
images simulated under realistic aquatic conditions, categorizes plastics by
polymer type across a broad size spectrum. We demonstrate the application of
state-of-the-art detection algorithms on MiNa, assessing their effectiveness
and identifying the unique challenges and potential of each method. The dataset
not only fills a critical gap in available resources for microplastic research
but also provides a robust foundation for future advancements in the field.

摘要：塑膠污染是一個日益嚴重的全球議題，影響健康和環境系統，從飲用水到空氣中都發現了微塑膠和奈米塑膠。傳統研究這些污染物的技術費時費力，因此有必要轉向更有效率的技術。為了解決這個問題，本文介紹微塑膠和奈米塑膠 (MiNa)，這是一個新穎的開源資料集，專門用於使用物件偵測演算法自動偵測和分類微塑膠和奈米塑膠。該資料集包含在逼真的水生環境下模擬的掃描電子顯微鏡影像，並根據聚合物類型對塑膠進行分類，涵蓋廣泛的尺寸範圍。我們展示了在 MiNa 上應用最先進的偵測演算法，評估其有效性，並找出每種方法的獨特挑戰和潛力。該資料集不僅填補了微塑膠研究可用資源的關鍵缺口，也為該領域未來的進展奠定了穩固的基礎。

##### **Depression Diagnosis Dialogue Simulation: Self-improving Psychiatrist with Tertiary Memory**
2409.15084v1 by Kunyao Lan, Bingui Jin, Zichen Zhu, Siyuan Chen, Shu Zhang, Kenny Q. Zhu, Mengyue Wu

Mental health issues, particularly depressive disorders, present significant
challenges in contemporary society, necessitating the development of effective
automated diagnostic methods. This paper introduces the Agent Mental Clinic
(AMC), a self-improving conversational agent system designed to enhance
depression diagnosis through simulated dialogues between patient and
psychiatrist agents. To enhance the dialogue quality and diagnosis accuracy, we
design a psychiatrist agent consisting of a tertiary memory structure, a
dialogue control and reflect plugin that acts as ``supervisor'' and a memory
sampling module, fully leveraging the skills reflected by the psychiatrist
agent, achieving great accuracy on depression risk and suicide risk diagnosis
via conversation. Experiment results on datasets collected in real-life
scenarios demonstrate that the system, simulating the procedure of training
psychiatrists, can be a promising optimization method for aligning LLMs with
real-life distribution in specific domains without modifying the weights of
LLMs, even when only a few representative labeled cases are available.

摘要：心理健康問題，尤其是憂鬱症，對現代社會構成重大挑戰，因此有必要開發有效的自動診斷方法。本文介紹了 Agent Mental Clinic (AMC)，這是一個自我提升的對話代理系統，旨在透過患者和精神科醫師代理之間的模擬對話來加強憂鬱症的診斷。為了提升對話品質和診斷準確度，我們設計了一個精神科醫師代理，它包含一個三級記憶結構、一個對話控制和反映插件（作為「監督者」）和一個記憶體抽樣模組，充分利用精神科醫師代理反映的技能，透過對話在憂鬱症風險和自殺風險診斷上取得極高的準確度。在現實生活中收集的資料集上的實驗結果表明，這個系統模擬了精神科醫師的訓練程序，可以成為一種有前途的最佳化方法，用於在不修改 LLM 權重的條件下，將 LLM 與特定領域的真實生活分佈對齊，即使只有少數具有代表性的標記案例可用。

##### **Toward Automated Clinical Transcriptions**
2409.15378v1 by Mitchell A. Klusty, W. Vaiden Logan, Samuel E. Armstrong, Aaron D. Mullen, Caroline N. Leach, Jeff Talbert, V. K. Cody Bumgardner

Administrative documentation is a major driver of rising healthcare costs and
is linked to adverse outcomes, including physician burnout and diminished
quality of care. This paper introduces a secure system that applies recent
advancements in speech-to-text transcription and speaker-labeling (diarization)
to patient-provider conversations. This system is optimized to produce accurate
transcriptions and highlight potential errors to promote rapid human
verification, further reducing the necessary manual effort. Applied to over 40
hours of simulated conversations, this system offers a promising foundation for
automating clinical transcriptions.

摘要：行政文件是醫療保健成本上升的主要驅動力，並與不良結果有關，包括醫師倦怠和醫療品質下降。本文介紹了一個安全的系統，該系統將語音轉文字轉錄和說話者標籤（日記）的最新進展應用於患者與提供者的對話。此系統經過最佳化，可產生準確的轉錄並強調潛在錯誤，以促進快速的人工驗證，進一步減少必要的作業。應用於超過 40 小時的模擬對話，此系統為自動化臨床轉錄提供了有希望的基礎。

##### **Dermatologist-like explainable AI enhances melanoma diagnosis accuracy: eye-tracking study**
2409.13476v1 by Tirtha Chanda, Sarah Haggenmueller, Tabea-Clara Bucher, Tim Holland-Letz, Harald Kittler, Philipp Tschandl, Markus V. Heppt, Carola Berking, Jochen S. Utikal, Bastian Schilling, Claudia Buerger, Cristian Navarrete-Dechent, Matthias Goebeler, Jakob Nikolas Kather, Carolin V. Schneider, Benjamin Durani, Hendrike Durani, Martin Jansen, Juliane Wacker, Joerg Wacker, Reader Study Consortium, Titus J. Brinker

Artificial intelligence (AI) systems have substantially improved
dermatologists' diagnostic accuracy for melanoma, with explainable AI (XAI)
systems further enhancing clinicians' confidence and trust in AI-driven
decisions. Despite these advancements, there remains a critical need for
objective evaluation of how dermatologists engage with both AI and XAI tools.
In this study, 76 dermatologists participated in a reader study, diagnosing 16
dermoscopic images of melanomas and nevi using an XAI system that provides
detailed, domain-specific explanations. Eye-tracking technology was employed to
assess their interactions. Diagnostic performance was compared with that of a
standard AI system lacking explanatory features. Our findings reveal that XAI
systems improved balanced diagnostic accuracy by 2.8 percentage points relative
to standard AI. Moreover, diagnostic disagreements with AI/XAI systems and
complex lesions were associated with elevated cognitive load, as evidenced by
increased ocular fixations. These insights have significant implications for
clinical practice, the design of AI tools for visual tasks, and the broader
development of XAI in medical diagnostics.

摘要：人工智慧 (AI) 系統已大幅改善皮膚科醫師對黑色素瘤的診斷準確度，而可解釋 AI (XAI) 系統進一步提升臨床醫師對 AI 驅動決策的信心與信賴。儘管有這些進展，對於皮膚科醫師如何使用 AI 和 XAI 工具，仍有客觀評估的迫切需求。在這項研究中，76 位皮膚科醫師參與了一項讀者研究，使用 XAI 系統診斷 16 張黑色素瘤和痣的皮膚鏡影像，該系統提供詳細的領域特定說明。採用眼球追蹤技術來評估他們的互動。將診斷表現與缺乏說明功能的標準 AI 系統進行比較。我們的研究結果顯示，XAI 系統相較於標準 AI，將平衡診斷準確度提升了 2.8 個百分點。此外，與 AI/XAI 系統的診斷分歧和複雜的病灶與認知負擔升高有關，這由增加的眼睛注視次數所證實。這些見解對臨床實務、視覺任務 AI 工具的設計和醫學診斷中 XAI 的廣泛發展具有重大意義。

##### **Differentially Private Multimodal Laplacian Dropout (DP-MLD) for EEG Representative Learning**
2409.13440v1 by Xiaowen Fu, Bingxin Wang, Xinzhou Guo, Guoqing Liu, Yang Xiang

Recently, multimodal electroencephalogram (EEG) learning has shown great
promise in disease detection. At the same time, ensuring privacy in clinical
studies has become increasingly crucial due to legal and ethical concerns. One
widely adopted scheme for privacy protection is differential privacy (DP)
because of its clear interpretation and ease of implementation. Although
numerous methods have been proposed under DP, it has not been extensively
studied for multimodal EEG data due to the complexities of models and signal
data considered there. In this paper, we propose a novel Differentially Private
Multimodal Laplacian Dropout (DP-MLD) scheme for multimodal EEG learning. Our
approach proposes a novel multimodal representative learning model that
processes EEG data by language models as text and other modal data by vision
transformers as images, incorporating well-designed cross-attention mechanisms
to effectively extract and integrate cross-modal features. To achieve DP, we
design a novel adaptive feature-level Laplacian dropout scheme, where
randomness allocation and performance are dynamically optimized within given
privacy budgets. In the experiment on an open-source multimodal dataset of
Freezing of Gait (FoG) in Parkinson's Disease (PD), our proposed method
demonstrates an approximate 4\% improvement in classification accuracy, and
achieves state-of-the-art performance in multimodal EEG learning under DP.

摘要：<paragraph>最近，多模态脑电图 (EEG) 学习在疾病检测方面显示出了巨大的前景。与此同时，由于法律和道德方面的考虑，在临床研究中确保隐私变得越来越重要。差分隐私 (DP) 是一种被广泛采用的隐私保护方案，因为它具有清晰的解释和易于实现的特点。尽管在 DP 下已经提出了许多方法，但由于所考虑的模型和信号数据的复杂性，尚未对其在多模态 EEG 数据中进行广泛的研究。在本文中，我们提出了一种新颖的差分隐私多模态拉普拉斯 Dropout（DP-MLD）方案，用于多模态 EEG 学习。我们的方法提出了一种新颖的多模态表示学习模型，该模型通过语言模型将 EEG 数据处理为文本，并将其他模态数据通过视觉转换器处理为图像，并结合精心设计的交叉注意力机制来有效提取和整合跨模态特征。为了实现 DP，我们设计了一种新颖的自适应特征级拉普拉斯 Dropout 方案，其中在给定的隐私预算内动态优化随机性分配和性能。在帕金森病 (PD) 中步态冻结 (FoG) 的开源多模态数据集上的实验中，我们提出的方法在分类准确性方面显示出约 4% 的提升，并在 DP 下的多模态 EEG 学习中实现了最先进的性能。</paragraph>

##### **FPBoost: Fully Parametric Gradient Boosting for Survival Analysis**
2409.13363v1 by Alberto Archetti, Eugenio Lomurno, Diego Piccinotti, Matteo Matteucci

Survival analysis is a critical tool for analyzing time-to-event data and
extracting valuable clinical insights. Recently, numerous machine learning
techniques leveraging neural networks and decision trees have been developed
for this task. Among these, the most successful approaches often rely on
specific assumptions about the shape of the modeled hazard function. These
assumptions include proportional hazard, accelerated failure time, or discrete
estimation at a predefined set of time points. In this study, we propose a
novel paradigm for survival model design based on the weighted sum of
individual fully parametric hazard contributions. We build upon well-known
ensemble techniques to deliver a novel contribution to the field by applying
additive hazard functions, improving over approaches based on survival or
cumulative hazard functions. Furthermore, the proposed model, which we call
FPBoost, is the first algorithm to directly optimize the survival likelihood
via gradient boosting. We evaluated our approach across a diverse set of
datasets, comparing it against a variety of state-of-the-art models. The
results demonstrate that FPBoost improves risk estimation, according to both
concordance and calibration metrics.

摘要：生存分析是分析事件发生时间数据和提取有价值的临床见解的关键工具。最近，已经开发出许多利用神经网络和决策树的机器学习技术来完成此任务。其中，最成功的做法通常依赖于对建模风险函数形状的特定假设。这些假设包括比例风险、加速失效时间或在预定义时间点进行离散估计。在这项研究中，我们提出了一种基于加权和的个体全参数风险贡献的新型生存模型设计范例。我们建立在众所周知的集成技术之上，通过应用加性风险函数，对该领域做出新的贡献，改进基于生存或累积风险函数的方法。此外，我们称之为 FPBoost 的提议模型是第一个直接通过梯度提升优化生存可能性的算法。我们对各种数据集评估了我们的方法，并将其与各种最先进的模型进行了比较。结果表明，根据一致性和校准指标，FPBoost 改进了风险估计。

##### **Multi-omics data integration for early diagnosis of hepatocellular carcinoma (HCC) using machine learning**
2409.13791v1 by Annette Spooner, Mohammad Karimi Moridani, Azadeh Safarchi, Salim Maher, Fatemeh Vafaee, Amany Zekry, Arcot Sowmya

The complementary information found in different modalities of patient data
can aid in more accurate modelling of a patient's disease state and a better
understanding of the underlying biological processes of a disease. However, the
analysis of multi-modal, multi-omics data presents many challenges, including
high dimensionality and varying size, statistical distribution, scale and
signal strength between modalities. In this work we compare the performance of
a variety of ensemble machine learning algorithms that are capable of late
integration of multi-class data from different modalities. The ensemble methods
and their variations tested were i) a voting ensemble, with hard and soft vote,
ii) a meta learner, iii) a multi-modal Adaboost model using a hard vote, a soft
vote and a meta learner to integrate the modalities on each boosting round, the
PB-MVBoost model and a novel application of a mixture of experts model. These
were compared to simple concatenation as a baseline. We examine these methods
using data from an in-house study on hepatocellular carcinoma (HCC), along with
four validation datasets on studies from breast cancer and irritable bowel
disease (IBD). Using the area under the receiver operating curve as a measure
of performance we develop models that achieve a performance value of up to 0.85
and find that two boosted methods, PB-MVBoost and Adaboost with a soft vote
were the overall best performing models. We also examine the stability of
features selected, and the size of the clinical signature determined. Finally,
we provide recommendations for the integration of multi-modal multi-class data.

摘要：<paragraph>在不同模式的患者數據中發現的互補信息，有助於更準確地建立患者疾病狀態的模型，並更深入了解疾病的基礎生物過程。然而，多模態、多組學數據的分析提出了許多挑戰，包括高維度和不同的數據規模、統計分佈、比例和模態之間的信號強度。在這項工作中，我們比較了各種集成機器學習演算法的效能，這些演算法能夠對來自不同模態的多類別數據進行後整合。測試的集成方法及其變體為：i) 投票集成，採用硬投票和軟投票，ii) 元學習器，iii) 多模態 Adaboost 模型，使用硬投票、軟投票和元學習器在每次提升回合中整合模態，PB-MVBoost 模型和專家混合模型的新應用。這些方法與作為基準的簡單串接進行了比較。我們使用來自肝細胞癌 (HCC) 內部研究的數據，以及來自乳癌和腸躁症 (IBD) 研究的四個驗證數據集，來檢驗這些方法。使用受試者操作曲線下的面積作為效能衡量標準，我們開發了效能值高達 0.85 的模型，並發現兩種提升方法，PB-MVBoost 和採用軟投票的 Adaboost 是整體效能最佳的模型。我們還檢驗了所選特徵的穩定性，以及所確定的臨床特徵的大小。最後，我們針對多模態多類別數據的整合提供了建議。</paragraph>

##### **Recent Advancement of Emotion Cognition in Large Language Models**
2409.13354v1 by Yuyan Chen, Yanghua Xiao

Emotion cognition in large language models (LLMs) is crucial for enhancing
performance across various applications, such as social media, human-computer
interaction, and mental health assessment. We explore the current landscape of
research, which primarily revolves around emotion classification, emotionally
rich response generation, and Theory of Mind assessments, while acknowledge the
challenges like dependency on annotated data and complexity in emotion
processing. In this paper, we present a detailed survey of recent progress in
LLMs for emotion cognition. We explore key research studies, methodologies,
outcomes, and resources, aligning them with Ulric Neisser's cognitive stages.
Additionally, we outline potential future directions for research in this
evolving field, including unsupervised learning approaches and the development
of more complex and interpretable emotion cognition LLMs. We also discuss
advanced methods such as contrastive learning used to improve LLMs' emotion
cognition capabilities.

摘要：大型語言模型（LLM）的情緒認知對於增強各種應用程式的效能至關重要，例如社群媒體、人機互動和心理健康評估。我們探討了當前研究領域，其主要圍繞著情緒分類、情緒豐富的回應產生和心智理論評估，同時承認依賴註解資料和情緒處理的複雜性等挑戰。在本文中，我們對 LLM 在情緒認知方面的近期進展進行了詳細的調查。我們探討了關鍵的研究、方法、成果和資源，並將它們與烏爾里希·奈瑟的認知階段相結合。此外，我們概述了這個不斷演進的領域中未來研究的潛在方向，包括無監督學習方法和更複雜且可解釋的情緒認知 LLM 的開發。我們還討論了對比學習等先進方法，用於提升 LLM 的情緒認知能力。

##### **SLaVA-CXR: Small Language and Vision Assistant for Chest X-ray Report Automation**
2409.13321v1 by Jinge Wu, Yunsoo Kim, Daqian Shi, David Cliffton, Fenglin Liu, Honghan Wu

Inspired by the success of large language models (LLMs), there is growing
research interest in developing LLMs in the medical domain to assist
clinicians. However, for hospitals, using closed-source commercial LLMs
involves privacy issues, and developing open-source public LLMs requires
large-scale computational resources, which are usually limited, especially in
resource-efficient regions and low-income countries. We propose an open-source
Small Language and Vision Assistant (SLaVA-CXR) that can be used for Chest
X-Ray report automation. To efficiently train a small assistant, we first
propose the Re$^3$Training method, which simulates the cognitive development of
radiologists and optimizes the model in the Recognition, Reasoning, and
Reporting training manner. Then, we introduce a data synthesis method, RADEX,
which can generate a high-quality and diverse training corpus with privacy
regulation compliance. The extensive experiments show that our SLaVA-CXR built
on a 2.7B backbone not only outperforms but also achieves 6 times faster
inference efficiency than previous state-of-the-art larger models.

摘要：受到大型語言模型 (LLM) 成功啟發，在醫療領域開發 LLM 以協助臨床醫生引起了越來越多的研究興趣。然而，對於醫院而言，使用封閉原始碼的商業 LLM 涉及隱私問題，而開發開放原始碼的公共 LLM 需要大規模的計算資源，這些資源通常有限，特別是在資源效率高的地區和低收入國家。我們提出了一個開放原始碼的小語言和視覺助理 (SLaVA-CXR)，可用於胸部 X 光報告自動化。為了有效訓練一個小型助理，我們首先提出了 Re$^3$Training 方法，它模擬了放射科醫生的認知發展，並以識別、推理和報告訓練方式優化模型。然後，我們引入了一種數據合成方法 RADEX，它可以在符合隱私法規的情況下生成一個高品質且多樣化的訓練語料庫。大量的實驗表明，我們建立在 2.7B 主幹上的 SLaVA-CXR 不僅表現出色，而且推理效率比以前最先進的較大模型快 6 倍。

##### **OMG-RL:Offline Model-based Guided Reward Learning for Heparin Treatment**
2409.13299v1 by Yooseok Lim, Sujee Lee

Accurate diagnosis of individual patient conditions and appropriate
medication dosing strategies are core elements of personalized medical
decision-making processes. This therapeutic procedure, which entails
recursively assessing the patient's condition and administering suitable
medications, can effectively be modeled as a reinforcement learning (RL)
problem. Crucially, the success of RL in this context depends on the
establishment of a well-defined reward function that accurately represents the
optimal treatment strategy. However, defining the learning direction in RL with
only a limited set of explicit indicators complicates the task due to the
inherent complexity of the required domain knowledge. This approach may also
increase the likelihood that the RL policy does not adequately reflect the
clinician's treatment intentions, which are determined by considering various
situations and indicators. In this study, we focus on developing a reward
function that reflects the clinician's intentions and introduce Offline
Model-based Guided Reward Learning (OMG-RL), which performs offline inverse
reinforcement learning (IRL) aligned with the offline RL environment. Through
OMG-RL, we learn a parameterized reward function that includes the expert's
intentions from limited data, thereby enhancing the agent's policy. We validate
the proposed approach on the heparin dosing task. The results demonstrate that
policy learning through OMG-RL is meaningful and confirm that the learned
policy is positively reinforced in terms of activated partial thromboplastin
time (aPTT), a key indicator for monitoring the effects of heparin. This
approach can be broadly utilized not only for the heparin dosing problem but
also for RL-based medication dosing tasks in general.

摘要：準確診斷個別病患狀況和適當的藥物給藥策略是個人化醫療決策過程中核心元素。這個治療程序包含反覆評估病患狀況和給予適當藥物，可以有效地建模為強化學習 (RL) 問題。至關重要的是，RL 在此脈絡中的成功取決於建立一個定義良好的回饋函數，能準確代表最佳治療策略。然而，僅使用有限的明確指標來定義 RL 中的學習方向會使任務複雜化，因為需要領域知識的複雜性。這種方法也可能增加 RL 政策無法充分反映臨床醫師治療意圖的可能性，而臨床醫師的治療意圖是由考量各種情況和指標來決定的。在本研究中，我們專注於開發一個反映臨床醫師意圖的回饋函數，並引入離線模型引導回饋學習 (OMG-RL)，它執行與離線 RL 環境一致的離線逆向強化學習 (IRL)。透過 OMG-RL，我們從有限的資料中學習一個參數化的回饋函數，其中包含專家的意圖，從而增強代理的政策。我們在肝素給藥任務中驗證了所提出的方法。結果表明，透過 OMG-RL 進行政策學習是有意義的，並確認所學習的政策在活化部分凝血活酶時間 (aPTT) 方面得到正向加強，而 aPTT 是監測肝素效果的關鍵指標。這種方法不僅可以廣泛用於肝素給藥問題，還可以用於一般的基於 RL 的藥物給藥任務。

##### **Prompting Large Language Models for Supporting the Differential Diagnosis of Anemia**
2409.15377v1 by Elisa Castagnari, Lillian Muyama, Adrien Coulet

In practice, clinicians achieve a diagnosis by following a sequence of steps,
such as laboratory exams, observations, or imaging. The pathways to reach
diagnosis decisions are documented by guidelines authored by expert
organizations, which guide clinicians to reach a correct diagnosis through
these sequences of steps. While these guidelines are beneficial for following
medical reasoning and consolidating medical knowledge, they have some
drawbacks. They often fail to address patients with uncommon conditions due to
their focus on the majority population, and are slow and costly to update,
making them unsuitable for rapidly emerging diseases or new practices. Inspired
by clinical guidelines, our study aimed to develop pathways similar to those
that can be obtained in clinical guidelines. We tested three Large Language
Models (LLMs) -Generative Pretrained Transformer 4 (GPT-4), Large Language
Model Meta AI (LLaMA), and Mistral -on a synthetic yet realistic dataset to
differentially diagnose anemia and its subtypes. By using advanced prompting
techniques to enhance the decision-making process, we generated diagnostic
pathways using these models. Experimental results indicate that LLMs hold huge
potential in clinical pathway discovery from patient data, with GPT-4
exhibiting the best performance in all conducted experiments.

摘要：<paragraph>在實務上，臨床醫生會遵循一系列步驟來診斷，
例如實驗室檢查、觀察或影像。診斷決策的途徑由專家組織編寫的指南記錄下來，這些指南引導臨床醫生透過這些步驟序列得出正確的診斷。雖然這些指南有助於遵循醫療推理並彙整醫療知識，但它們有一些缺點。由於專注於大多數族群，它們常常無法針對罕見疾病的患者提供建議，而且更新既緩慢又昂貴，這使得它們不適合用於快速出現的疾病或新療法。受到臨床指南的啟發，我們的研究旨在開發出類似於臨床指南中可以獲得的途徑。我們在一個合成但逼真的資料集上測試了三個大型語言模型 (LLM) - 生成式預訓練Transformer 4 (GPT-4)、大型語言模型 Meta AI (LLaMA) 和 Mistral - 以區分診斷貧血及其亞型。透過使用進階提示技術來增強決策制定過程，我們使用這些模型生成了診斷途徑。實驗結果表明，LLM 在從患者資料中發現臨床途徑方面具有巨大的潛力，其中 GPT-4 在所有進行的實驗中表現最佳。</paragraph>

##### **An adapted large language model facilitates multiple medical tasks in diabetes care**
2409.13191v1 by Lai Wei, Zhen Ying, Muyang He, Yutong Chen, Qian Yang, Yanzhe Hong, Jiaping Lu, Xiaoying Li, Weiran Huang, Ying Chen

Diabetes is a chronic disease that poses a significant global health burden,
and optimizing diabetes management requires multi-stakeholder collaboration.
Large language models (LLMs) have shown promise in various healthcare
scenarios, but their effectiveness across a diverse range of diabetes tasks
remains unproven. In this study, we introduced a framework to train and
validate diabetes-specific LLMs. We first developed a comprehensive data
processing pipeline that includes data collection, filtering, augmentation and
refinement. This approach contributes to creating a high-quality,
diabetes-specific dataset, and several evaluation benchmarks entirely from
scratch. Utilizing the collected training dataset, we fine-tuned a
diabetes-specific LLM family that demonstrated state-of-the-art proficiency in
understanding and processing various diabetes tasks compared to other LLMs.
Furthermore, clinical studies showed the potential applications of our models
in diabetes care, including providing personalized healthcare, assisting
medical education, and streamlining clinical tasks. In conclusion, our study
introduced a framework to develop and evaluate a diabetes-specific LLM family,
and highlighted its potential to enhance clinical practice and provide
personalized, data-driven support for diabetes support when facing different
end users. The code is provided via GitHub at
https://github.com/waltonfuture/Diabetica.

摘要：糖尿病是一種慢性疾病，對全球健康造成重大負擔，而優化糖尿病管理需要多方利益相關者的合作。大型語言模型 (LLM) 已在各種醫療保健場景中展現出潛力，但它們在各種糖尿病任務中的有效性仍未得到證實。在這個研究中，我們引入了一個訓練和驗證糖尿病特定 LLM 的框架。我們首先開發了一個全面的數據處理管道，其中包括數據收集、過濾、擴充和優化。這種方法有助於創建一個高品質、特定於糖尿病的數據集，以及從頭開始的幾個評估基準。利用收集的訓練數據集，我們微調了一個特定於糖尿病的 LLM 家族，與其他 LLM 相比，在理解和處理各種糖尿病任務方面展示了最先進的熟練度。此外，臨床研究表明我們的模型在糖尿病護理中具有潛在應用，包括提供個性化醫療保健、協助醫學教育和簡化臨床任務。總之，我們的研究引入了一個開發和評估特定於糖尿病的 LLM 家族的框架，並強調了其增強臨床實務和在面對不同最終用戶時提供個性化、數據驅動的糖尿病支持的潛力。該程式碼透過 GitHub 提供，網址為 https://github.com/waltonfuture/Diabetica。

##### **Explainable AI for Autism Diagnosis: Identifying Critical Brain Regions Using fMRI Data**
2409.15374v1 by Suryansh Vidya, Kush Gupta, Amir Aly, Andy Wills, Emmanuel Ifeachor, Rohit Shankar

Early diagnosis and intervention for Autism Spectrum Disorder (ASD) has been
shown to significantly improve the quality of life of autistic individuals.
However, diagnostics methods for ASD rely on assessments based on clinical
presentation that are prone to bias and can be challenging to arrive at an
early diagnosis. There is a need for objective biomarkers of ASD which can help
improve diagnostic accuracy. Deep learning (DL) has achieved outstanding
performance in diagnosing diseases and conditions from medical imaging data.
Extensive research has been conducted on creating models that classify ASD
using resting-state functional Magnetic Resonance Imaging (fMRI) data. However,
existing models lack interpretability. This research aims to improve the
accuracy and interpretability of ASD diagnosis by creating a DL model that can
not only accurately classify ASD but also provide explainable insights into its
working. The dataset used is a preprocessed version of the Autism Brain Imaging
Data Exchange (ABIDE) with 884 samples. Our findings show a model that can
accurately classify ASD and highlight critical brain regions differing between
ASD and typical controls, with potential implications for early diagnosis and
understanding of the neural basis of ASD. These findings are validated by
studies in the literature that use different datasets and modalities,
confirming that the model actually learned characteristics of ASD and not just
the dataset. This study advances the field of explainable AI in medical imaging
by providing a robust and interpretable model, thereby contributing to a future
with objective and reliable ASD diagnostics.

摘要：自閉症譜系障礙 (ASD) 的早期診斷和介入已被證實能顯著改善自閉症患者的生活品質。然而，ASD 的診斷方法依賴於基於臨床表現的評估，容易產生偏見，且可能難以做出早期診斷。有必要找出 ASD 的客觀生物標記，以幫助提高診斷準確性。深度學習 (DL) 在從醫學影像資料診斷疾病和病症方面取得傑出的表現。已經針對建立使用靜態功能性磁振造影 (fMRI) 資料對 ASD 進行分類的模型進行廣泛的研究。然而，現有的模型缺乏可解釋性。本研究旨在透過建立一個不僅能準確分類 ASD，還能提供可解釋見解說明其運作原理的 DL 模型，來改善 ASD 診斷的準確性和可解釋性。所使用的資料集是自閉症大腦影像資料交換 (ABIDE) 的預處理版本，包含 884 個樣本。我們的研究結果顯示，該模型能準確分類 ASD，並強調 ASD 與典型對照組之間存在差異的關鍵腦區，對於 ASD 的早期診斷和神經基礎的理解具有潛在的意義。這些研究結果已由使用不同資料集和方式的文獻研究驗證，證實該模型實際上學習了 ASD 的特徵，而不僅僅是資料集。本研究透過提供一個強健且可解釋的模型，推動了醫學影像中可解釋 AI 的領域，從而為未來提供客觀且可靠的 ASD 診斷做出貢獻。

##### **Personalized 2D Binary Patient Codes of Tissue Images and Immunogenomic Data Through Multimodal Self-Supervised Fusion**
2409.13115v1 by Areej Alsaafin, Abubakr Shafique, Saghir Alfasly, H. R. Tizhoosh

The field of medical diagnostics has witnessed a transformative convergence
of artificial intelligence (AI) and healthcare data, offering promising avenues
for enhancing patient care and disease comprehension. However, this integration
of multimodal data, specifically histopathology whole slide images (WSIs) and
genetic sequencing data, presents unique challenges due to modality disparities
and the need for scalable computational solutions. This paper addresses the
scarcity of multimodal solutions, primarily centered around unimodal data
solutions, thus limiting the realization of the rich insights that can be
derived from integrating images and genomic data. Here, we introduce MarbliX
``Multimodal Association and Retrieval with Binary Latent Indexed matriX,'' an
innovative multimodal framework that integrates histopathology images with
immunogenomic sequencing data, encapsulating them into a concise binary patient
code, referred to as ``monogram.'' This binary representation facilitates the
establishment of a comprehensive archive, enabling clinicians to match similar
cases. The experimental results demonstrate the potential of MarbliX to empower
healthcare professionals with in-depth insights, leading to more precise
diagnoses, reduced variability, and expanded personalized treatment options,
particularly in the context of cancer.

摘要：醫療診斷領域見證了人工智慧 (AI) 與醫療保健資料的變革性融合，為提升病患照護和疾病理解提供了有希望的途徑。然而，這種整合多模式資料，特別是組織病理學全切片影像 (WSI) 和基因定序資料，由於模式差異和對可擴充計算解決方案的需求，因此提出了獨特的挑戰。本文探討了多模式解決方案的稀缺性，主要集中在單模式資料解決方案，因此限制了從整合影像和基因體資料中獲得豐富見解的實現。在此，我們介紹 MarbliX ``使用二進制潛在索引矩陣的多模式關聯和擷取''，一個創新的多模式架構，它將組織病理學影像與免疫基因組定序資料整合，將它們封裝成一個簡潔的二進制病患代碼，稱為 ``單字''。這種二進制表示有助於建立一個全面的檔案，讓臨床醫生能夠比對類似的案例。實驗結果證明了 MarbliX 能夠讓醫療保健專業人員獲得深入見解的潛力，從而導致更精確的診斷、減少變異性，並擴展個人化治療選項，特別是在癌症的背景下。

##### **DenoMamba: A fused state-space model for low-dose CT denoising**
2409.13094v1 by Şaban Öztürk, Oğuz Can Duran, Tolga Çukur

Low-dose computed tomography (LDCT) lower potential risks linked to radiation
exposure while relying on advanced denoising algorithms to maintain diagnostic
quality in reconstructed images. The reigning paradigm in LDCT denoising is
based on neural network models that learn data-driven image priors to separate
noise evoked by dose reduction from underlying tissue signals. Naturally, the
fidelity of these priors depend on the model's ability to capture the broad
range of contextual features evident in CT images. Earlier convolutional neural
networks (CNN) are highly adept at efficiently capturing short-range spatial
context, but their limited receptive fields reduce sensitivity to interactions
over longer distances. Although transformers based on self-attention mechanisms
have recently been posed to increase sensitivity to long-range context, they
can suffer from suboptimal performance and efficiency due to elevated model
complexity, particularly for high-resolution CT images. For high-quality
restoration of LDCT images, here we introduce DenoMamba, a novel denoising
method based on state-space modeling (SSM), that efficiently captures short-
and long-range context in medical images. Following an hourglass architecture
with encoder-decoder stages, DenoMamba employs a spatial SSM module to encode
spatial context and a novel channel SSM module equipped with a secondary gated
convolution network to encode latent features of channel context at each stage.
Feature maps from the two modules are then consolidated with low-level input
features via a convolution fusion module (CFM). Comprehensive experiments on
LDCT datasets with 25\% and 10\% dose reduction demonstrate that DenoMamba
outperforms state-of-the-art denoisers with average improvements of 1.4dB PSNR,
1.1% SSIM, and 1.6% RMSE in recovered image quality.

摘要：低劑量電腦斷層掃描 (LDCT) 降低與輻射有關的潛在風險，同時依賴進階的去噪演算法，以維持重建影像的診斷品質。LDCT 去噪的主流典範基於神經網路模型，該模型會學習資料驅動的影像先驗，以區分劑量降低所產生的雜訊與底層組織訊號。自然而然，這些先驗的保真度取決於模型擷取 CT 影像中廣泛脈絡特徵的能力。較早的卷積神經網路 (CNN) 非常擅長有效擷取短程空間脈絡，但其有限的感受野會降低對較長距離交互作用的敏感度。儘管基於自我注意機制的Transformer最近被提出用於增加對長程脈絡的敏感度，但由於模型複雜度提高，它們可能會因次佳效能和效率而受限，特別是對於高解析度 CT 影像。為了高品質復原 LDCT 影像，我們在此介紹 DenoMamba，這是一種基於狀態空間模型 (SSM) 的創新去噪方法，它能有效擷取醫學影像中的短程和長程脈絡。DenoMamba 採用具有編碼器-解碼器階段的沙漏架構，並使用空間 SSM 模組來編碼空間脈絡，以及配備次要閘控卷積網路的新型通道 SSM 模組，以編碼各個階段中通道脈絡的潛在特徵。然後透過卷積融合模組 (CFM) 將兩個模組中的特徵圖與低階輸入特徵合併。在劑量降低 25% 和 10% 的 LDCT 資料集上進行的全面實驗證明，DenoMamba 的效能優於最先進的去噪器，在復原影像品質方面平均改善了 1.4dB PSNR、1.1% SSIM 和 1.6% RMSE。

##### **AutoPET III Challenge: Tumor Lesion Segmentation using ResEnc-Model Ensemble**
2409.13779v1 by Tanya Chutani, Saikiran Bonthu, Pranab Samanta, Nitin Singhal

Positron Emission Tomography (PET) /Computed Tomography (CT) is crucial for
diagnosing, managing, and planning treatment for various cancers. Developing
reliable deep learning models for the segmentation of tumor lesions in PET/CT
scans in a multi-tracer multicenter environment, is a critical area of
research. Different tracers, such as Fluorodeoxyglucose (FDG) and
Prostate-Specific Membrane Antigen (PSMA), have distinct physiological uptake
patterns and data from different centers often vary in terms of acquisition
protocols, scanner types, and patient populations. Because of this variability,
it becomes more difficult to design reliable segmentation algorithms and
generalization techniques due to variations in image quality and lesion
detectability. To address this challenge, We trained a 3D Residual encoder
U-Net within the no new U-Net framework, aiming to generalize the performance
of automatic lesion segmentation of whole body PET/CT scans, across different
tracers and clinical sites. Further, We explored several preprocessing
techniques and ultimately settled on using the Total Segmentator to crop our
training data. Additionally, we applied resampling during this process. During
inference, we leveraged test-time augmentations and other post-processing
techniques to enhance tumor lesion segmentation. Our team currently hold the
top position in the Auto-PET III challenge and outperformed the challenge
baseline model in the preliminary test set with Dice score of 0.9627.

摘要：正子斷層掃描 (PET)/電腦斷層掃描 (CT) 對於診斷、管理和規劃各種癌症的治療至關重要。開發可靠的深度學習模型，用於在多示蹤劑多中心環境中對 PET/CT 掃描中的腫瘤病灶進行分割，是一個重要的研究領域。不同的示蹤劑，例如氟代氧葡萄糖 (FDG) 和前列腺特異性膜抗原 (PSMA)，具有不同的生理攝取模式，來自不同中心的數據通常在採集協議、掃描儀類型和患者群體方面有所不同。由於這種變異性，由於圖像質量和病灶檢測能力的差異，設計可靠的分割演算法和泛化技術變得更加困難。為了應對這一挑戰，我們在沒有新的 U-Net 框架內訓練了一個 3D 殘差編碼器 U-Net，旨在概括全身上下 PET/CT 掃描自動病灶分割的性能，跨越不同的示蹤劑和臨床部位。此外，我們探索了幾種預處理技術，最終決定使用 Total Segmentator 來裁剪我們的訓練數據。此外，我們在此過程中應用重新採樣。在推理期間，我們利用測試時擴充和其他後處理技術來增強腫瘤病灶分割。我們的團隊目前在 Auto-PET III 挑戰中排名第一，並在預賽測試集中以 0.9627 的 Dice 分數優於挑戰基準模型。

##### **HeadCT-ONE: Enabling Granular and Controllable Automated Evaluation of Head CT Radiology Report Generation**
2409.13038v1 by Julián N. Acosta, Xiaoman Zhang, Siddhant Dogra, Hong-Yu Zhou, Seyedmehdi Payabvash, Guido J. Falcone, Eric K. Oermann, Pranav Rajpurkar

We present Head CT Ontology Normalized Evaluation (HeadCT-ONE), a metric for
evaluating head CT report generation through ontology-normalized entity and
relation extraction. HeadCT-ONE enhances current information extraction derived
metrics (such as RadGraph F1) by implementing entity normalization through
domain-specific ontologies, addressing radiological language variability.
HeadCT-ONE compares normalized entities and relations, allowing for
controllable weighting of different entity types or specific entities. Through
experiments on head CT reports from three health systems, we show that
HeadCT-ONE's normalization and weighting approach improves the capture of
semantically equivalent reports, better distinguishes between normal and
abnormal reports, and aligns with radiologists' assessment of clinically
significant errors, while offering flexibility to prioritize specific aspects
of report content. Our results demonstrate how HeadCT-ONE enables more
flexible, controllable, and granular automated evaluation of head CT reports.

摘要：我們提出 Head CT Ontology Normalized Evaluation (HeadCT-ONE)，一種透過 ontology 正規化實體和關係萃取來評估頭部 CT 報告產生的指標。HeadCT-ONE 透過領域特定 ontology 實作實體正規化，來提升目前資訊萃取衍生的指標（例如 RadGraph F1），以解決放射科語言的可變性。HeadCT-ONE 比較正規化實體和關係，允許控制不同實體類型或特定實體的加權。透過對來自三個醫療系統的頭部 CT 報告進行實驗，我們展示 HeadCT-ONE 的正規化和加權方法改進了語義等效報告的擷取，更好地區分正常和異常報告，並與放射科醫師對臨床重大錯誤的評估保持一致，同時提供優先考慮報告內容特定層面的彈性。我們的結果展示 HeadCT-ONE 如何讓頭部 CT 報告的自動化評估更靈活、可控和細緻。

##### **iCost: A Novel Instance Complexity Based Cost-Sensitive Learning Framework for Imbalanced Classification**
2409.13007v1 by Asif Newaz, Asif Ur Rahman Adib, Taskeed Jabid

Class imbalance in data presents significant challenges for classification
tasks. It is fairly common and requires careful handling to obtain desirable
performance. Traditional classification algorithms become biased toward the
majority class. One way to alleviate the scenario is to make the classifiers
cost-sensitive. This is achieved by assigning a higher misclassification cost
to minority-class instances. One issue with this implementation is that all the
minority-class instances are treated equally, and assigned with the same
penalty value. However, the learning difficulties of all the instances are not
the same. Instances that are located near the decision boundary are harder to
classify, whereas those further away are easier. Without taking into
consideration the instance complexity and naively weighting all the
minority-class samples uniformly, results in an unwarranted bias and
consequently, a higher number of misclassifications of the majority-class
instances. This is undesirable and to overcome the situation, we propose a
novel instance complexity-based cost-sensitive approach in this study. We first
categorize all the minority-class instances based on their difficulty level and
then the instances are penalized accordingly. This ensures a more equitable
instance weighting and prevents excessive penalization. The performance of the
proposed approach is tested on 66 imbalanced datasets against the traditional
cost-sensitive learning frameworks and a significant improvement in performance
is noticeable, demonstrating the effectiveness of our method.

摘要：資料中的類別不平衡對於分類任務來說是一項重大的挑戰。這相當普遍，需要小心處理才能獲得理想的效能。傳統的分類演算法會偏向多數類別。一種緩解這種情況的方法是讓分類器對成本敏感。這是透過對少數類別的實例指定較高的錯誤分類成本來達成。這種實作的一個問題是，所有少數類別的實例都受到平等對待，並指定相同的懲罰值。然而，所有實例的學習難度並不相同。位於決策邊界附近的實例較難分類，而較遠的實例則較容易。在沒有考慮實例複雜性並天真地對所有少數類別樣本進行均勻加權的情況下，會導致不合理的偏差，進而導致對多數類別實例的誤分類數量增加。這是不可取的，為了克服這種情況，我們在這項研究中提出了一種新的基於實例複雜性的成本敏感方法。我們首先根據少數類別實例的難度等級對它們進行分類，然後對實例進行相應的懲罰。這確保了更公平的實例加權，並防止過度懲罰。所提出的方法的效能已在 66 個不平衡的資料集上針對傳統的成本敏感學習架構進行測試，並且效能有顯著的提升，證明了我們方法的有效性。

##### **Fuzzy Rule based Intelligent Cardiovascular Disease Prediction using Complex Event Processing**
2409.15372v1 by Shashi Shekhar Kumar, Anurag Harsh, Ritesh Chandra, Sonali Agarwal

Cardiovascular disease (CVDs) is a rapidly rising global concern due to
unhealthy diets, lack of physical activity, and other factors. According to the
World Health Organization (WHO), primary risk factors include elevated blood
pressure, glucose, blood lipids, and obesity. Recent research has focused on
accurate and timely disease prediction to reduce risk and fatalities, often
relying on predictive models trained on large datasets, which require intensive
training. An intelligent system for CVDs patients could greatly assist in
making informed decisions by effectively analyzing health parameters. Complex
Event Processing (CEP) has emerged as a valuable method for solving real-time
challenges by aggregating patterns of interest and their causes and effects on
end users. In this work, we propose a fuzzy rule-based system for monitoring
clinical data to provide real-time decision support. We designed fuzzy rules
based on clinical and WHO standards to ensure accurate predictions. Our
integrated approach uses Apache Kafka and Spark for data streaming, and the
Siddhi CEP engine for event processing. Additionally, we pass numerous
cardiovascular disease-related parameters through CEP engines to ensure fast
and reliable prediction decisions. To validate the effectiveness of our
approach, we simulated real-time, unseen data to predict cardiovascular
disease. Using synthetic data (1000 samples), we categorized it into "Very Low
Risk, Low Risk, Medium Risk, High Risk, and Very High Risk." Validation results
showed that 20% of samples were categorized as very low risk, 15-45% as low
risk, 35-65% as medium risk, 55-85% as high risk, and 75% as very high risk.

摘要：心血管疾病 (CVD) 由于不健康的饮食、缺乏身体活动和其他因素，正迅速成为全球关注的问题。根据世界卫生组织 (WHO) 的说法，主要危险因素包括血压升高、葡萄糖、血脂和肥胖。最近的研究重点在于准确及时地预测疾病，以降低风险和死亡率，通常依赖于在大数据集上训练的预测模型，这需要大量的训练。一个针对心血管疾病患者的智能系统可以通过有效分析健康参数来极大地帮助做出明智的决策。复杂事件处理 (CEP) 已成为通过聚合感兴趣的模式及其对最终用户的影响和原因来解决实时挑战的宝贵方法。在这项工作中，我们提出了一种基于模糊规则的系统来监控临床数据，以提供实时决策支持。我们基于临床和 WHO 标准设计了模糊规则，以确保准确的预测。我们的集成方法使用 Apache Kafka 和 Spark 进行数据流式传输，并使用 Siddhi CEP 引擎进行事件处理。此外，我们通过 CEP 引擎传递了许多与心血管疾病相关的参数，以确保快速且可靠的预测决策。为了验证我们方法的有效性，我们模拟了实时、不可见的数据来预测心血管疾病。使用合成数据（1000 个样本），我们将它们分类为“极低风险、低风险、中风险、高风险和极高风险”。验证结果表明，20% 的样本被归类为极低风险，15-45% 为低风险，35-65% 为中风险，55-85% 为高风险，75% 为极高风险。

##### **Improving Prototypical Parts Abstraction for Case-Based Reasoning Explanations Designed for the Kidney Stone Type Recognition**
2409.12883v1 by Daniel Flores-Araiza, Francisco Lopez-Tiro, Clément Larose, Salvador Hinojosa, Andres Mendez-Vazquez, Miguel Gonzalez-Mendoza, Gilberto Ochoa-Ruiz, Christian Daul

The in-vivo identification of the kidney stone types during an ureteroscopy
would be a major medical advance in urology, as it could reduce the time of the
tedious renal calculi extraction process, while diminishing infection risks.
Furthermore, such an automated procedure would make possible to prescribe
anti-recurrence treatments immediately. Nowadays, only few experienced
urologists are able to recognize the kidney stone types in the images of the
videos displayed on a screen during the endoscopy. Thus, several deep learning
(DL) models have recently been proposed to automatically recognize the kidney
stone types using ureteroscopic images. However, these DL models are of black
box nature whicl limits their applicability in clinical settings. This
contribution proposes a case-based reasoning DL model which uses prototypical
parts (PPs) and generates local and global descriptors. The PPs encode for each
class (i.e., kidney stone type) visual feature information (hue, saturation,
intensity and textures) similar to that used by biologists. The PPs are
optimally generated due a new loss function used during the model training.
Moreover, the local and global descriptors of PPs allow to explain the
decisions ("what" information, "where in the images") in an understandable way
for biologists and urologists. The proposed DL model has been tested on a
database including images of the six most widespread kidney stone types. The
overall average classification accuracy was 90.37. When comparing this results
with that of the eight other DL models of the kidney stone state-of-the-art, it
can be seen that the valuable gain in explanability was not reached at the
expense of accuracy which was even slightly increased with respect to that
(88.2) of the best method of the literature. These promising and interpretable
results also encourage urologists to put their trust in AI-based solutions.

摘要：尿路鏡檢查中腎結石類型的體內識別將是泌尿科的一項重大進展，因為它可以減少繁瑣的腎結石取出過程的時間，同時降低感染風險。此外，這種自動化程序將使立即開立抗復發治療成為可能。如今，只有少數經驗豐富的泌尿科醫生能夠在內視鏡檢查期間屏幕上顯示的視頻圖像中識別腎結石類型。因此，最近已提出多種深度學習 (DL) 模型，以使用輸尿管鏡圖像自動識別腎結石類型。然而，這些 DL 模型本質上是黑盒子，這限制了它們在臨床環境中的應用性。本文提出了一個基於案例推理的 DL 模型，它使用原型部分 (PP) 並生成局部和全局描述符。PP 為每種類型（即腎結石類型）編碼視覺特徵信息（色調、飽和度、強度和紋理），類似於生物學家使用的信息。由於在模型訓練期間使用的新損失函數，PP 得到了最佳生成。此外，PP 的局部和全局描述符允許以生物學家和泌尿科醫生可以理解的方式解釋決策（“什麼”信息，“圖像中的什麼位置”）。所提出的 DL 模型已在一個包含六種最廣泛的腎結石類型圖像的數據庫上進行了測試。總體平均分類準確率為 90.37。將此結果與腎結石最先進的八個其他 DL 模型的結果進行比較時，可以看出，可解釋性的寶貴增益並未以準確性為代價，甚至略有增加與文獻中最好的方法 (88.2) 相比。這些有希望且可解釋的結果也鼓勵泌尿科醫生相信基於人工智能的解決方案。

##### **Introducing the Large Medical Model: State of the art healthcare cost and risk prediction with transformers trained on patient event sequences**
2409.13000v1 by Ricky Sahu, Eric Marriott, Ethan Siegel, David Wagner, Flore Uzan, Troy Yang, Asim Javed

With U.S. healthcare spending approaching $5T (NHE Fact Sheet 2024), and 25%
of it estimated to be wasteful (Waste in the US the health care system:
estimated costs and potential for savings, n.d.), the need to better predict
risk and optimal patient care is evermore important. This paper introduces the
Large Medical Model (LMM), a generative pre-trained transformer (GPT) designed
to guide and predict the broad facets of patient care and healthcare
administration. The model is trained on medical event sequences from over 140M
longitudinal patient claims records with a specialized vocabulary built from
medical terminology systems and demonstrates a superior capability to forecast
healthcare costs and identify potential risk factors. Through experimentation
and validation, we showcase the LMM's proficiency in not only in cost and risk
predictions, but also in discerning intricate patterns within complex medical
conditions and an ability to identify novel relationships in patient care. The
LMM is able to improve both cost prediction by 14.1% over the best commercial
models and chronic conditions prediction by 1.9% over the best transformer
models in research predicting a broad set of conditions. The LMM is a
substantial advancement in healthcare analytics, offering the potential to
significantly enhance risk assessment, cost management, and personalized
medicine.

摘要：隨著美國醫療保健支出逼近 5 兆美元（2024 年 NHE 事實表），其中估計有 25% 是浪費的（美國醫療保健系統中的浪費：估計成本和節約潛力，無日期），因此需要更好地預測風險和最佳患者照護變得越來越重要。本文介紹了大型醫療模型 (LMM)，一種生成式預訓練轉換器 (GPT)，旨在引導和預測患者照護和醫療保健管理的廣泛面向。該模型使用超過 1.4 億個縱向患者索賠記錄中的醫療事件序列進行訓練，並使用從醫療術語系統建立的專業詞彙，並展示出預測醫療保健成本和識別潛在風險因子的卓越能力。透過實驗和驗證，我們展示了 LMM 不僅在成本和風險預測方面具有專業知識，還展示了在複雜醫療狀況中辨別複雜模式和識別患者照護中新關係的能力。LMM 能夠將成本預測提高 14.1%，優於最佳商業模型，並將慢性病預測提高 1.9%，優於研究中預測廣泛病況的最佳轉換器模型。LMM 是醫療保健分析的一項重大進展，具有顯著提升風險評估、成本管理和個人化醫療的潛力。

##### **Fine Tuning Large Language Models for Medicine: The Role and Importance of Direct Preference Optimization**
2409.12741v2 by Thomas Savage, Stephen Ma, Abdessalem Boukil, Vishwesh Patel, Ekanath Rangan, Ivan Rodriguez, Jonathan H Chen

Large Language Model (LLM) fine tuning is underutilized in the field of
medicine. Two of the most common methods of fine tuning are Supervised Fine
Tuning (SFT) and Direct Preference Optimization (DPO), but there is little
guidance informing users when to use either technique. In this investigation,
we compare the performance of SFT and DPO for five common natural language
tasks in medicine: Classification with text data, Classification with numeric
data, Clinical Reasoning, Summarization, and Clinical Triage. We find that SFT
alone is sufficient for Classification with text data, whereas DPO improves
performance for the more complex tasks of Clinical Reasoning, Summarization and
Clinical Triage. Our results establish the role and importance of DPO fine
tuning within medicine, and consequently call attention to current software
gaps that prevent widespread deployment of this technique.

摘要：大型語言模型 (LLM) 微調在醫學領域的使用率不足。微調最常見的兩種方法是監督式微調 (SFT) 和直接偏好最佳化 (DPO)，但鮮少有指南告訴使用者何時使用這兩種技術。在此研究中，我們比較了 SFT 和 DPO 在醫學中五項常見自然語言任務的表現：文字資料分類、數字資料分類、臨床推理、摘要和臨床分流。我們發現，僅 SFT 就足以應付文字資料分類，而 DPO 則能提升臨床推理、摘要和臨床分流等較複雜任務的表現。我們的結果確立了 DPO 微調在醫學中的角色和重要性，並因此提醒目前軟體的不足之處，這些不足之處妨礙了此技術的廣泛部署。

##### **SurgPLAN++: Universal Surgical Phase Localization Network for Online and Offline Inference**
2409.12467v1 by Zhen Chen, Xingjian Luo, Jinlin Wu, Long Bai, Zhen Lei, Hongliang Ren, Sebastien Ourselin, Hongbin Liu

Surgical phase recognition is critical for assisting surgeons in
understanding surgical videos. Existing studies focused more on online surgical
phase recognition, by leveraging preceding frames to predict the current frame.
Despite great progress, they formulated the task as a series of frame-wise
classification, which resulted in a lack of global context of the entire
procedure and incoherent predictions. Moreover, besides online analysis,
accurate offline surgical phase recognition is also in significant clinical
need for retrospective analysis, and existing online algorithms do not fully
analyze the entire video, thereby limiting accuracy in offline analysis. To
overcome these challenges and enhance both online and offline inference
capabilities, we propose a universal Surgical Phase Localization Network, named
SurgPLAN++, with the principle of temporal detection. To ensure a global
understanding of the surgical procedure, we devise a phase localization
strategy for SurgPLAN++ to predict phase segments across the entire video
through phase proposals. For online analysis, to generate high-quality phase
proposals, SurgPLAN++ incorporates a data augmentation strategy to extend the
streaming video into a pseudo-complete video through mirroring,
center-duplication, and down-sampling. For offline analysis, SurgPLAN++
capitalizes on its global phase prediction framework to continuously refine
preceding predictions during each online inference step, thereby significantly
improving the accuracy of phase recognition. We perform extensive experiments
to validate the effectiveness, and our SurgPLAN++ achieves remarkable
performance in both online and offline modes, which outperforms
state-of-the-art methods. The source code is available at
https://github.com/lxj22/SurgPLAN-Plus.

摘要：手術階段辨識對於協助外科醫生理解手術影片至關重要。現有研究較著重於線上手術階段辨識，藉由利用前一幀來預測當前幀。儘管進展顯著，但他們將任務制定為一系列逐幀分類，這導致缺乏整個過程的整體脈絡和不連貫的預測。此外，除了線上分析之外，精準的離線手術階段辨識在回顧性分析中也具有重要的臨床需求，而現有的線上演算法並未完全分析整個影片，因此限制了離線分析的準確性。為了克服這些挑戰並增強線上和離線推論能力，我們提出了一個名為 SurgPLAN++ 的通用手術階段定位網路，其原理為時間偵測。為了確保對手術過程有整體的了解，我們為 SurgPLAN++ 設計了一個階段定位策略，以透過階段提案預測整個影片中的階段區段。對於線上分析，為了產生高品質的階段提案，SurgPLAN++ 結合了一個資料擴充策略，透過鏡像、中心複製和降採樣將串流影片延伸為一個偽完成影片。對於離線分析，SurgPLAN++ 利用其全球階段預測架構，在每個線上推論步驟中持續改善前一預測，從而顯著提高階段辨識的準確性。我們進行了廣泛的實驗來驗證其有效性，而我們的 SurgPLAN++ 在線上和離線模式下都達到了顯著的效能，優於最先進的方法。原始程式碼可在 https://github.com/lxj22/SurgPLAN-Plus 取得。

##### **FoME: A Foundation Model for EEG using Adaptive Temporal-Lateral Attention Scaling**
2409.12454v1 by Enze Shi, Kui Zhao, Qilong Yuan, Jiaqi Wang, Huawen Hu, Sigang Yu, Shu Zhang

Electroencephalography (EEG) is a vital tool to measure and record brain
activity in neuroscience and clinical applications, yet its potential is
constrained by signal heterogeneity, low signal-to-noise ratios, and limited
labeled datasets. In this paper, we propose FoME (Foundation Model for EEG), a
novel approach using adaptive temporal-lateral attention scaling to address
above-mentioned challenges. FoME is pre-trained on a diverse 1.7TB dataset of
scalp and intracranial EEG recordings, comprising 745M parameters trained for
1,096k steps. Our model introduces two key innovations: a time-frequency fusion
embedding technique and an adaptive time-lateral attention scaling (ATLAS)
mechanism. These components synergistically capture complex temporal and
spectral EEG dynamics, enabling FoME to adapt to varying patterns across
diverse data streams and facilitate robust multi-channel modeling. Evaluations
across four downstream tasks demonstrate FoME's superior performance in
classification and forecasting applications, consistently achieving
state-of-the-art results. To conclude, FoME establishes a new paradigm for EEG
analysis, offering a versatile foundation that advances brain-computer
interfaces, clinical diagnostics, and cognitive research across neuroscience
and related fields. Our code will be available at
https://github.com/1061413241/FoME.

摘要：腦電圖（EEG）是神經科學和臨床應用中用於測量和記錄大腦活動的重要工具，但其潛力受到訊號異質性、低信噪比和標籤資料集有限的限制。在本文中，我們提出 FoME（EEG 基礎模型），一種使用適應性時間側向注意力調整來解決上述挑戰的新方法。FoME 在一個多樣化的 1.7TB 頭皮和顱內 EEG 紀錄資料集上進行預訓練，包含 7.45 億個參數，訓練了 1,096k 步驟。我們的模型引入了兩項關鍵創新：時頻融合嵌入技術和適應性時間側向注意力調整（ATLAS）機制。這些組成部分協同捕捉複雜的時間和頻譜 EEG 動態，使 FoME 能夠適應不同資料流中的不同模式，並促進穩健的多通道建模。在四項下游任務中的評估證明了 FoME 在分類和預測應用中的優異效能，始終達到最先進的結果。總之，FoME 為 EEG 分析建立了一個新的範例，提供了一個通用的基礎，推動了腦電腦介面、臨床診斷和神經科學及相關領域的認知研究。我們的程式碼將在 https://github.com/1061413241/FoME 上提供。

##### **Domain Generalization for Endoscopic Image Segmentation by Disentangling Style-Content Information and SuperPixel Consistency**
2409.12450v1 by Mansoor Ali Teevno, Rafael Martinez-Garcia-Pena, Gilberto Ochoa-Ruiz, Sharib Ali

Frequent monitoring is necessary to stratify individuals based on their
likelihood of developing gastrointestinal (GI) cancer precursors. In clinical
practice, white-light imaging (WLI) and complementary modalities such as
narrow-band imaging (NBI) and fluorescence imaging are used to assess risk
areas. However, conventional deep learning (DL) models show degraded
performance due to the domain gap when a model is trained on one modality and
tested on a different one. In our earlier approach, we used a superpixel-based
method referred to as "SUPRA" to effectively learn domain-invariant information
using color and space distances to generate groups of pixels. One of the main
limitations of this earlier work is that the aggregation does not exploit
structural information, making it suboptimal for segmentation tasks, especially
for polyps and heterogeneous color distributions. Therefore, in this work, we
propose an approach for style-content disentanglement using instance
normalization and instance selective whitening (ISW) for improved domain
generalization when combined with SUPRA. We evaluate our approach on two
datasets: EndoUDA Barrett's Esophagus and EndoUDA polyps, and compare its
performance with three state-of-the-art (SOTA) methods. Our findings
demonstrate a notable enhancement in performance compared to both baseline and
SOTA methods across the target domain data. Specifically, our approach
exhibited improvements of 14%, 10%, 8%, and 18% over the baseline and three
SOTA methods on the polyp dataset. Additionally, it surpassed the second-best
method (EndoUDA) on the Barrett's Esophagus dataset by nearly 2%.

摘要：為了根據個人罹患胃腸道 (GI) 癌前驅病變的可能性對其進行分層，頻繁監控是必要的。在臨床實務中，白光影像 (WLI) 和補充方式（例如窄頻影像 (NBI) 和螢光影像）用於評估風險區域。然而，當模型在一個方式上訓練並在不同的方式上測試時，傳統深度學習 (DL) 模型會因為領域差距而顯示出降低的效能。在我們之前的方法中，我們使用稱為「SUPRA」的超像素為基礎的方法，使用顏色和空間距離有效地學習領域不變資訊以產生像素群組。這項早期工作的其中一項主要限制是，聚合並未利用結構資訊，這使得它不適合分割任務，特別是對於息肉和異質性顏色分佈。因此，在這項工作中，我們提出一個使用實例正規化和實例選擇性白化 (ISW) 進行風格內容解開的方法，以在與 SUPRA 結合時改善領域概化。我們在兩個資料集上評估我們的方法：EndoUDA Barrett 食道和 EndoUDA 息肉，並將其效能與三種最先進 (SOTA) 方法進行比較。我們的研究結果顯示，與目標領域資料上的基線和 SOTA 方法相比，效能有顯著的提升。具體來說，我們的方法在息肉資料集上比基線和三種 SOTA 方法分別提升了 14%、10%、8% 和 18%。此外，它在 Barrett 食道資料集上比第二好的方法 (EndoUDA) 高出近 2%。

##### **Bundle Fragments into a Whole: Mining More Complete Clusters via Submodular Selection of Interesting webpages for Web Topic Detection**
2409.12380v1 by Junbiao Pang, Anjing Hu, Qingming Huang

Organizing interesting webpages into hot topics is one of key steps to
understand the trends of multimodal web data. A state-of-the-art solution is
firstly to organize webpages into a large volume of multi-granularity topic
candidates; hot topics are further identified by estimating their
interestingness. However, these topic candidates contain a large number of
fragments of hot topics due to both the inefficient feature representations and
the unsupervised topic generation. This paper proposes a bundling-refining
approach to mine more complete hot topics from fragments. Concretely, the
bundling step organizes the fragment topics into coarse topics; next, the
refining step proposes a submodular-based method to refine coarse topics in a
scalable approach. The propose unconventional method is simple, yet powerful by
leveraging submodular optimization, our approach outperforms the traditional
ranking methods which involve the careful design and complex steps. Extensive
experiments demonstrate that the proposed approach surpasses the
state-of-the-art method (i.e., latent Poisson deconvolution Pang et al. (2016))
20% accuracy and 10% one on two public data sets, respectively.

摘要：將有趣的網頁整理成熱門話題是了解多模態網路資料趨勢的關鍵步驟之一。最先進的解決方案首先是將網頁整理成大量的多粒度主題候選者；熱門話題進一步透過評估其趣味性來識別。然而，這些主題候選者包含大量的熱門話題片段，這是由於特徵表徵效率不彰和非監督式主題產生。本文提出一個成束精煉方法，從片段中挖掘出更完整的熱門話題。具體來說，成束步驟將片段主題整理成粗略主題；接著，精煉步驟提出一個基於次模組的方法，以可擴充的方式精煉粗略主題。所提出的非傳統方法很簡單，但透過利用次模組最佳化卻很強大，我們的做法優於涉及謹慎設計和複雜步驟的傳統排名方法。廣泛的實驗證明，所提出的方法超越了最先進的方法（即潛在的 Poisson 反摺疊 Pang 等人 (2016)）在兩個公開資料集上分別提升了 20% 的準確度和 10% 的一對一。

##### **Extracting Memorized Training Data via Decomposition**
2409.12367v1 by Ellen Su, Anu Vellore, Amy Chang, Raffaele Mura, Blaine Nelson, Paul Kassianik, Amin Karbasi

The widespread use of Large Language Models (LLMs) in society creates new
information security challenges for developers, organizations, and end-users
alike. LLMs are trained on large volumes of data, and their susceptibility to
reveal the exact contents of the source training datasets poses security and
safety risks. Although current alignment procedures restrict common risky
behaviors, they do not completely prevent LLMs from leaking data. Prior work
demonstrated that LLMs may be tricked into divulging training data by using
out-of-distribution queries or adversarial techniques. In this paper, we
demonstrate a simple, query-based decompositional method to extract news
articles from two frontier LLMs. We use instruction decomposition techniques to
incrementally extract fragments of training data. Out of 3723 New York Times
articles, we extract at least one verbatim sentence from 73 articles, and over
20% of verbatim sentences from 6 articles. Our analysis demonstrates that this
method successfully induces the LLM to generate texts that are reliable
reproductions of news articles, meaning that they likely originate from the
source training dataset. This method is simple, generalizable, and does not
fine-tune or change the production model. If replicable at scale, this training
data extraction methodology could expose new LLM security and safety
vulnerabilities, including privacy risks and unauthorized data leaks. These
implications require careful consideration from model development to its
end-use.

摘要：大型語言模型（LLM）在社會中的廣泛使用為開發人員、組織和最終用戶創造了新的資訊安全挑戰。LLM 在大量資料上訓練，它們容易揭露原始訓練資料集的精確內容，這會造成安全和隱私風險。儘管目前校準程序限制了常見的風險行為，但它們並不能完全防止 LLM 洩漏資料。先前的研究表明，LLM 可能被誘騙通過使用非分佈查詢或對抗技術來洩露訓練資料。在本文中，我們展示了一個簡單的、基於查詢的分解方法，從兩個前沿 LLM 中提取新聞文章。我們使用指令分解技術逐步提取訓練資料片段。在 3723 篇紐約時報文章中，我們從 73 篇文章中至少提取了一個逐字逐句的句子，並且從 6 篇文章中提取了 20% 以上的逐字逐句句子。我們的分析表明，此方法成功地誘導 LLM 生成可靠的新聞文章重現文字，這意味著它們很可能來自原始訓練資料集。此方法簡單、可概括，並且不會微調或更改生產模型。如果可以大規模複製，此訓練資料提取方法可能會暴露新的 LLM 安全和隱私漏洞，包括隱私風險和未經授權的資料洩漏。這些影響需要從模型開發到最終使用仔細考量。

##### **Axial Attention Transformer Networks: A New Frontier in Breast Cancer Detection**
2409.12347v1 by Weijie He, Runyuan Bao, Yiru Cang, Jianjun Wei, Yang Zhang, Jiacheng Hu

This paper delves into the challenges and advancements in the field of
medical image segmentation, particularly focusing on breast cancer diagnosis.
The authors propose a novel Transformer-based segmentation model that addresses
the limitations of traditional convolutional neural networks (CNNs), such as
U-Net, in accurately localizing and segmenting small lesions within breast
cancer images. The model introduces an axial attention mechanism to enhance the
computational efficiency and address the issue of global contextual information
that is often overlooked by CNNs. Additionally, the paper discusses
improvements tailored to the small dataset challenge, including the
incorporation of relative position information and a gated axial attention
mechanism to refine the model's focus on relevant features. The proposed model
aims to significantly improve the segmentation accuracy of breast cancer
images, offering a more efficient and effective tool for computer-aided
diagnosis.

摘要：本文探討了醫療影像分割領域的挑戰和進展，特別著重於乳癌診斷。作者提出了一個基於 Transformer 的新分割模型，它解決了傳統卷積神經網路 (CNN) 的限制，例如 U-Net 在準確定位和分割乳癌影像中小的病灶。該模型引入了一個軸向注意力機制來增強運算效率並解決 CNN 經常忽略的全局上下文資訊問題。此外，本文討論了針對小資料集挑戰量身打造的改進，包括整合相對位置資訊和門控軸向注意力機制，以改善模型對相關特徵的關注。所提出的模型旨在顯著提高乳癌影像的分割準確度，為電腦輔助診斷提供更有效率且更有效的工具。

##### **Deep vessel segmentation with joint multi-prior encoding**
2409.12334v1 by Amine Sadikine, Bogdan Badic, Enzo Ferrante, Vincent Noblet, Pascal Ballet, Dimitris Visvikis, Pierre-Henri Conze

The precise delineation of blood vessels in medical images is critical for
many clinical applications, including pathology detection and surgical
planning. However, fully-automated vascular segmentation is challenging because
of the variability in shape, size, and topology. Manual segmentation remains
the gold standard but is time-consuming, subjective, and impractical for
large-scale studies. Hence, there is a need for automatic and reliable
segmentation methods that can accurately detect blood vessels from medical
images. The integration of shape and topological priors into vessel
segmentation models has been shown to improve segmentation accuracy by offering
contextual information about the shape of the blood vessels and their spatial
relationships within the vascular tree. To further improve anatomical
consistency, we propose a new joint prior encoding mechanism which incorporates
both shape and topology in a single latent space. The effectiveness of our
method is demonstrated on the publicly available 3D-IRCADb dataset. More
globally, the proposed approach holds promise in overcoming the challenges
associated with automatic vessel delineation and has the potential to advance
the field of deep priors encoding.

摘要：在醫療影像中精確描繪血管對於許多臨床應用至關重要，包括病理偵測和手術規劃。然而，全自動血管分割具有挑戰性，因為形狀、大小和拓撲結構的變異性。手動分割仍然是黃金標準，但耗時、主觀且不適用於大規模研究。因此，需要自動且可靠的分割方法，可以從醫療影像中精確偵測血管。已證明將形狀和拓撲先驗整合到血管分割模型中，可以透過提供有關血管形狀及其在血管樹中的空間關係的脈絡資訊來提高分割準確度。為了進一步提高解剖一致性，我們提出了一種新的聯合先驗編碼機制，它在單一的潛在空間中整合了形狀和拓撲。我們的方法的有效性在公開的 3D-IRCADb 資料集上得到證明。更普遍地說，所提出的方法有望克服與自動血管描繪相關的挑戰，並有可能推進深度先驗編碼領域。

##### **MedCodER: A Generative AI Assistant for Medical Coding**
2409.15368v1 by Krishanu Das Baksi, Elijah Soba, John J. Higgins, Ravi Saini, Jaden Wood, Jane Cook, Jack Scott, Nirmala Pudota, Tim Weninger, Edward Bowen, Sanmitra Bhattacharya

Medical coding is essential for standardizing clinical data and communication
but is often time-consuming and prone to errors. Traditional Natural Language
Processing (NLP) methods struggle with automating coding due to the large label
space, lengthy text inputs, and the absence of supporting evidence annotations
that justify code selection. Recent advancements in Generative Artificial
Intelligence (AI) offer promising solutions to these challenges. In this work,
we introduce MedCodER, a Generative AI framework for automatic medical coding
that leverages extraction, retrieval, and re-ranking techniques as core
components. MedCodER achieves a micro-F1 score of 0.60 on International
Classification of Diseases (ICD) code prediction, significantly outperforming
state-of-the-art methods. Additionally, we present a new dataset containing
medical records annotated with disease diagnoses, ICD codes, and supporting
evidence texts (https://doi.org/10.5281/zenodo.13308316). Ablation tests
confirm that MedCodER's performance depends on the integration of each of its
aforementioned components, as performance declines when these components are
evaluated in isolation.

摘要：醫療編碼對於標準化臨床資料和溝通至關重要，但通常很耗時且容易出錯。傳統的自然語言處理 (NLP) 方法由於標籤空間大、文字輸入長且缺乏證明編碼選擇的佐證註解，因此難以自動化編碼。生成式人工智慧 (AI) 的最新進展為這些挑戰提供了有希望的解決方案。在這項工作中，我們介紹了 MedCodER，這是一個用於自動醫療編碼的生成式 AI 框架，它利用萃取、檢索和重新排序技術作為核心組成部分。MedCodER 在國際疾病分類 (ICD) 代碼預測上達到了 0.60 的微 F1 分數，顯著優於最先進的方法。此外，我們還提供了一個新的資料集，其中包含註有疾病診斷、ICD 代碼和佐證文字的新醫療記錄 (https://doi.org/10.5281/zenodo.13308316)。消融測試證實，MedCodER 的效能取決於其上述各組成部分的整合，因為當這些組成部分被孤立評估時，效能會下降。

##### **Towards Interpretable End-Stage Renal Disease (ESRD) Prediction: Utilizing Administrative Claims Data with Explainable AI Techniques**
2409.12087v1 by Yubo Li, Saba Al-Sayouri, Rema Padman

This study explores the potential of utilizing administrative claims data,
combined with advanced machine learning and deep learning techniques, to
predict the progression of Chronic Kidney Disease (CKD) to End-Stage Renal
Disease (ESRD). We analyze a comprehensive, 10-year dataset provided by a major
health insurance organization to develop prediction models for multiple
observation windows using traditional machine learning methods such as Random
Forest and XGBoost as well as deep learning approaches such as Long Short-Term
Memory (LSTM) networks. Our findings demonstrate that the LSTM model,
particularly with a 24-month observation window, exhibits superior performance
in predicting ESRD progression, outperforming existing models in the
literature. We further apply SHapley Additive exPlanations (SHAP) analysis to
enhance interpretability, providing insights into the impact of individual
features on predictions at the individual patient level. This study underscores
the value of leveraging administrative claims data for CKD management and
predicting ESRD progression.

摘要：本研究探討利用行政索賠資料的潛力，結合進階機器學習和深度學習技術，預測慢性腎臟病 (CKD) 進展至末期腎臟疾病 (ESRD)。我們分析由一家大型健康保險組織提供的十年綜合資料集，使用傳統機器學習方法（例如隨機森林和 XGBoost）以及深度學習方法（例如長短期記憶 (LSTM) 網路）開發多個觀察時段的預測模型。我們的研究結果表明，LSTM 模型，特別是具有 24 個月的觀察時段，在預測 ESRD 進展方面表現優異，優於文獻中的現有模型。我們進一步應用 SHapley 加法解釋 (SHAP) 分析來增強可解釋性，深入了解個別特徵對個別患者層級預測的影響。本研究強調了利用行政索賠資料進行 CKD 管理和預測 ESRD 進展的價值。

##### **EFCM: Efficient Fine-tuning on Compressed Models for deployment of large models in medical image analysis**
2409.11817v1 by Shaojie Li, Zhaoshuo Diao

The recent development of deep learning large models in medicine shows
remarkable performance in medical image analysis and diagnosis, but their large
number of parameters causes memory and inference latency challenges. Knowledge
distillation offers a solution, but the slide-level gradients cannot be
backpropagated for student model updates due to high-resolution pathological
images and slide-level labels. This study presents an Efficient Fine-tuning on
Compressed Models (EFCM) framework with two stages: unsupervised feature
distillation and fine-tuning. In the distillation stage, Feature Projection
Distillation (FPD) is proposed with a TransScan module for adaptive receptive
field adjustment to enhance the knowledge absorption capability of the student
model. In the slide-level fine-tuning stage, three strategies (Reuse CLAM,
Retrain CLAM, and End2end Train CLAM (ETC)) are compared. Experiments are
conducted on 11 downstream datasets related to three large medical models:
RETFound for retina, MRM for chest X-ray, and BROW for histopathology. The
experimental results demonstrate that the EFCM framework significantly improves
accuracy and efficiency in handling slide-level pathological image problems,
effectively addressing the challenges of deploying large medical models.
Specifically, it achieves a 4.33% increase in ACC and a 5.2% increase in AUC
compared to the large model BROW on the TCGA-NSCLC and TCGA-BRCA datasets. The
analysis of model inference efficiency highlights the high efficiency of the
distillation fine-tuning method.

摘要：<paragraph>最近在醫學領域中深度學習大型模型的發展，在醫學影像分析和診斷方面展現了卓越的表現，但其龐大的參數量卻導致記憶體和推論延遲的挑戰。知識蒸餾提供了一種解決方案，但由於高解析度的病理影像和幻燈片層級標籤，幻燈片層級的梯度無法反向傳播以更新學生模型。本研究提出了一個壓縮模型的有效微調 (EFCM) 架構，包含兩個階段：無監督特徵蒸餾和微調。在蒸餾階段，提出特徵投影蒸餾 (FPD) 與 TransScan 模組，以進行適應性感受野調整，以增強學生模型的知識吸收能力。在幻燈片層級微調階段，比較了三種策略（重複使用 CLAM、重新訓練 CLAM 和端對端訓練 CLAM (ETC)）。針對與三個大型醫學模型相關的 11 個下游資料集進行了實驗：針對視網膜的 RETFound、針對胸部 X 光的 MRM 和針對組織病理學的 BROW。實驗結果表明，EFCM 架構顯著提升了處理幻燈片層級病理影像問題的準確性和效率，有效應對了部署大型醫學模型的挑戰。具體來說，與大型模型 BROW 相比，它在 TCGA-NSCLC 和 TCGA-BRCA 資料集上分別提升了 4.33% 的 ACC 和 5.2% 的 AUC。模型推論效率的分析突出了蒸餾微調方法的高效率。</paragraph>

##### **Detecting Underdiagnosed Medical Conditions with Deep Learning-Based Opportunistic CT Imaging**
2409.11686v1 by Asad Aali, Andrew Johnston, Louis Blankemeier, Dave Van Veen, Laura T Derry, David Svec, Jason Hom, Robert D. Boutin, Akshay S. Chaudhari

Abdominal computed tomography (CT) scans are frequently performed in clinical
settings. Opportunistic CT involves repurposing routine CT images to extract
diagnostic information and is an emerging tool for detecting underdiagnosed
conditions such as sarcopenia, hepatic steatosis, and ascites. This study
utilizes deep learning methods to promote accurate diagnosis and clinical
documentation. We analyze 2,674 inpatient CT scans to identify discrepancies
between imaging phenotypes (characteristics derived from opportunistic CT
scans) and their corresponding documentation in radiology reports and ICD
coding. Through our analysis, we find that only 0.5%, 3.2%, and 30.7% of scans
diagnosed with sarcopenia, hepatic steatosis, and ascites (respectively)
through either opportunistic imaging or radiology reports were ICD-coded. Our
findings demonstrate opportunistic CT's potential to enhance diagnostic
precision and accuracy of risk adjustment models, offering advancements in
precision medicine.

摘要：腹部電腦斷層掃描 (CT) 在臨床環境中經常執行。機會性 CT 涉及將例行 CT 影像重新用於提取診斷資訊，並且是偵測未診斷疾病（例如肌肉減少症、肝臟脂肪變性、腹水）的新興工具。本研究利用深度學習方法促進準確診斷和臨床文件編寫。我們分析 2,674 個住院病人 CT 掃描，以找出影像表型（從機會性 CT 掃描衍生的特徵）與其在放射科報告和 ICD 編碼中對應的文件之間的差異。透過我們的分析，我們發現僅有 0.5%、3.2% 和 30.7% 的掃描被診斷為肌肉減少症、肝臟脂肪變性和腹水（分別）透過機會性影像或放射科報告進行 ICD 編碼。我們的研究結果證明了機會性 CT 增強診斷精準度和風險調整模型精確度的潛力，提供了精準醫療的進展。

##### **Agent Aggregator with Mask Denoise Mechanism for Histopathology Whole Slide Image Analysis**
2409.11664v1 by Xitong Ling, Minxi Ouyang, Yizhi Wang, Xinrui Chen, Renao Yan, Hongbo Chu, Junru Cheng, Tian Guan, Sufang Tian, Xiaoping Liu, Yonghong He

Histopathology analysis is the gold standard for medical diagnosis. Accurate
classification of whole slide images (WSIs) and region-of-interests (ROIs)
localization can assist pathologists in diagnosis. The gigapixel resolution of
WSI and the absence of fine-grained annotations make direct classification and
analysis challenging. In weakly supervised learning, multiple instance learning
(MIL) presents a promising approach for WSI classification. The prevailing
strategy is to use attention mechanisms to measure instance importance for
classification. However, attention mechanisms fail to capture inter-instance
information, and self-attention causes quadratic computational complexity. To
address these challenges, we propose AMD-MIL, an agent aggregator with a mask
denoise mechanism. The agent token acts as an intermediate variable between the
query and key for computing instance importance. Mask and denoising matrices,
mapped from agents-aggregated value, dynamically mask low-contribution
representations and eliminate noise. AMD-MIL achieves better attention
allocation by adjusting feature representations, capturing micro-metastases in
cancer, and improving interpretability. Extensive experiments on CAMELYON-16,
CAMELYON-17, TCGA-KIDNEY, and TCGA-LUNG show AMD-MIL's superiority over
state-of-the-art methods.

摘要：<paragraph>組織病理學分析是醫學診斷的金標準。準確分類全幻燈片影像 (WSI) 和感興趣區域 (ROI) 定位有助於病理學家進行診斷。WSI 的吉像素解析度和缺乏細粒度註解使得直接分類和分析具有挑戰性。在弱監督學習中，多例學習 (MIL) 為 WSI 分類提供了一種有前景的方法。普遍的策略是使用注意力機制來衡量例子的重要性以進行分類。然而，注意力機制無法捕捉例間資訊，而自注意力會導致二次計算複雜度。為了應對這些挑戰，我們提出了 AMD-MIL，一種具有遮罩去噪機制的代理聚合器。代理權杖充當查詢和鍵之間的中間變數，用於計算例子的重要性。從代理聚合值映射的遮罩和去噪矩陣，動態遮罩低貢獻表示並消除雜訊。AMD-MIL 透過調整特徵表示、捕捉癌症中的微轉移和提高可解釋性來實現更好的注意力分配。在 CAMELYON-16、CAMELYON-17、TCGA-KIDNEY 和 TCGA-LUNG 上的廣泛實驗顯示 AMD-MIL 優於最先進的方法。</paragraph>

##### **A Metric Hybrid Planning Approach to Solving Pandemic Planning Problems with Simple SIR Models**
2409.11631v1 by Ari Gestetner, Buser Say

A pandemic is the spread of a disease across large regions, and can have
devastating costs to the society in terms of health, economic and social. As
such, the study of effective pandemic mitigation strategies can yield
significant positive impact on the society. A pandemic can be mathematically
described using a compartmental model, such as the Susceptible Infected Removed
(SIR) model. In this paper, we extend the solution equations of the SIR model
to a state transition model with lockdowns. We formalize a metric hybrid
planning problem based on this state transition model, and solve it using a
metric hybrid planner. We improve the runtime effectiveness of the metric
hybrid planner with the addition of valid inequalities, and demonstrate the
success of our approach both theoretically and experimentally under various
challenging settings.

摘要：流行病是指疾病在大範圍地區傳播，且可能對社會在健康、經濟和社會方面造成毀滅性的成本。因此，研究有效的流行病緩解策略可以對社會產生顯著的正面影響。流行病可以用區室模型來數學描述，例如易感者、感染者、移除者 (SIR) 模型。在本文中，我們將 SIR 模型的求解方程式擴展到帶封鎖的狀態轉換模型。我們根據此狀態轉換模型形式化了一個度量混合規劃問題，並使用度量混合規劃器來解決它。我們透過新增有效不等式來改善度量混合規劃器的執行時間效率，並在各種具有挑戰性的設定下理論上和實驗上證明了我們方法的成功。

##### **Automating proton PBS treatment planning for head and neck cancers using policy gradient-based deep reinforcement learning**
2409.11576v1 by Qingqing Wang, Chang Chang

Proton pencil beam scanning (PBS) treatment planning for head and neck (H&N)
cancers is a time-consuming and experience-demanding task where a large number
of planning objectives are involved. Deep reinforcement learning (DRL) has
recently been introduced to the planning processes of intensity-modulated
radiation therapy and brachytherapy for prostate, lung, and cervical cancers.
However, existing approaches are built upon the Q-learning framework and
weighted linear combinations of clinical metrics, suffering from poor
scalability and flexibility and only capable of adjusting a limited number of
planning objectives in discrete action spaces. We propose an automatic
treatment planning model using the proximal policy optimization (PPO) algorithm
and a dose distribution-based reward function for proton PBS treatment planning
of H&N cancers. Specifically, a set of empirical rules is used to create
auxiliary planning structures from target volumes and organs-at-risk (OARs),
along with their associated planning objectives. These planning objectives are
fed into an in-house optimization engine to generate the spot monitor unit (MU)
values. A decision-making policy network trained using PPO is developed to
iteratively adjust the involved planning objective parameters in a continuous
action space and refine the PBS treatment plans using a novel dose
distribution-based reward function. Proton H&N treatment plans generated by the
model show improved OAR sparing with equal or superior target coverage when
compared with human-generated plans. Moreover, additional experiments on liver
cancer demonstrate that the proposed method can be successfully generalized to
other treatment sites. To the best of our knowledge, this is the first
DRL-based automatic treatment planning model capable of achieving human-level
performance for H&N cancers.

摘要：質子筆狀束掃描（PBS）治療計畫的頭頸部（H&N）癌症是一個耗時且需要經驗的任務，其中涉及大量的計畫目標。深度強化學習（DRL）最近被引入強度調控放射治療和前列腺、肺和子宮頸癌的近接治療的計畫過程中。然而，現有的方法建立在 Q 學習架構和臨床指標的加權線性組合之上，存在可擴充性和靈活性差，只能在離散動作空間中調整有限數量的計畫目標。我們提出了一個使用近端策略最佳化（PPO）演算法和基於劑量分佈的獎勵函數的自動治療計畫模型，用於 H&N 癌症的質子 PBS 治療計畫。具體來說，使用一組經驗法則從目標體積和受風險器官（OAR）建立輔助計畫結構，連同它們相關的計畫目標。這些計畫目標被輸入到內部最佳化引擎中以產生點監測單位（MU）值。開發了一個使用 PPO 訓練的決策制定策略網路，以在連續動作空間中反覆調整所涉及的計畫目標參數，並使用新的基於劑量分佈的獎勵函數優化 PBS 治療計畫。與人為產生的計畫相比，模型產生的質子 H&N 治療計畫顯示出改善的 OAR 保護，同時具有相等或更好的目標覆蓋率。此外，對肝癌的額外實驗表明，所提出的方法可以成功地推廣到其他治療部位。據我們所知，這是第一個基於 DRL 的自動治療計畫模型，能夠為 H&N 癌症實現人類等級的效能。

##### **Two Stage Segmentation of Cervical Tumors using PocketNet**
2409.11456v1 by Awj Twam, Megan Jacobsen, Rachel Glenn, Ann Klopp, Aradhana M. Venkatesan, David Fuentes

Cervical cancer remains the fourth most common malignancy amongst women
worldwide.1 Concurrent chemoradiotherapy (CRT) serves as the mainstay
definitive treatment regimen for locally advanced cervical cancers and includes
external beam radiation followed by brachytherapy.2 Integral to radiotherapy
treatment planning is the routine contouring of both the target tumor at the
level of the cervix, associated gynecologic anatomy and the adjacent organs at
risk (OARs). However, manual contouring of these structures is both time and
labor intensive and associated with known interobserver variability that can
impact treatment outcomes. While multiple tools have been developed to
automatically segment OARs and the high-risk clinical tumor volume (HR-CTV)
using computed tomography (CT) images,3,4,5,6 the development of deep
learning-based tumor segmentation tools using routine T2-weighted (T2w)
magnetic resonance imaging (MRI) addresses an unmet clinical need to improve
the routine contouring of both anatomical structures and cervical cancers,
thereby increasing quality and consistency of radiotherapy planning. This work
applied a novel deep-learning model (PocketNet) to segment the cervix, vagina,
uterus, and tumor(s) on T2w MRI. The performance of the PocketNet architecture
was evaluated, when trained on data via 5-fold cross validation. PocketNet
achieved a mean Dice-Sorensen similarity coefficient (DSC) exceeding 70% for
tumor segmentation and 80% for organ segmentation. These results suggest that
PocketNet is robust to variations in contrast protocols, providing reliable
segmentation of the ROIs.

摘要：<paragraph>子宮頸癌在全球女性中仍然是第四常見的惡性腫瘤。1 同時進行的化學放射治療 (CRT) 是局部晚期子宮頸癌的主要明確治療方案，包括外部放射線治療後進行近接放射治療。2 放射治療計畫中不可或缺的是例行勾勒出子宮頸處的目標腫瘤、相關的婦科解剖結構和鄰近的危險器官 (OAR)。然而，手動勾勒這些結構既費時又費力，且與已知的觀察者間變異有關，這可能會影響治療結果。雖然已開發出多種工具，可使用電腦斷層掃描 (CT) 影像自動區隔 OAR 和高風險臨床腫瘤體積 (HR-CTV)，3、4、5、6 但使用例行 T2 加權 (T2w) 磁振造影 (MRI) 的深度學習腫瘤區隔工具的開發，解決了改善解剖結構和子宮頸癌例行勾勒的未滿足臨床需求，從而提高了放射治療計畫的品質和一致性。這項工作應用了一種新穎的深度學習模型 (PocketNet) 來區隔 T2w MRI 上的子宮頸、陰道、子宮和腫瘤。評估了 PocketNet 架構的效能，並透過 5 倍交叉驗證對資料進行訓練。PocketNet 在腫瘤區隔方面達到了平均 Dice-Sorensen 相似性係數 (DSC) 超過 70%，在器官區隔方面達到了 80%。這些結果表明 PocketNet 對對比度協定的變化具有穩健性，可提供可靠的 ROI 區隔。</paragraph>

##### **Multi-OCT-SelfNet: Integrating Self-Supervised Learning with Multi-Source Data Fusion for Enhanced Multi-Class Retinal Disease Classification**
2409.11375v1 by Fatema-E- Jannat, Sina Gholami, Jennifer I. Lim, Theodore Leng, Minhaj Nur Alam, Hamed Tabkhi

In the medical domain, acquiring large datasets poses significant challenges
due to privacy concerns. Nonetheless, the development of a robust deep-learning
model for retinal disease diagnosis necessitates a substantial dataset for
training. The capacity to generalize effectively on smaller datasets remains a
persistent challenge. The scarcity of data presents a significant barrier to
the practical implementation of scalable medical AI solutions. To address this
issue, we've combined a wide range of data sources to improve performance and
generalization to new data by giving it a deeper understanding of the data
representation from multi-modal datasets and developed a self-supervised
framework based on large language models (LLMs), SwinV2 to gain a deeper
understanding of multi-modal dataset representations, enhancing the model's
ability to extrapolate to new data for the detection of eye diseases using
optical coherence tomography (OCT) images. We adopt a two-phase training
methodology, self-supervised pre-training, and fine-tuning on a downstream
supervised classifier. An ablation study conducted across three datasets
employing various encoder backbones, without data fusion, with low data
availability setting, and without self-supervised pre-training scenarios,
highlights the robustness of our method. Our findings demonstrate consistent
performance across these diverse conditions, showcasing superior generalization
capabilities compared to the baseline model, ResNet-50.

摘要：在醫療領域，由於隱私問題，獲取大型資料集會造成重大挑戰。儘管如此，對於視網膜疾病診斷的強健深度學習模型的開發需要一個龐大的資料集進行訓練。對較小的資料集進行有效概括的能力仍然是一個持續的挑戰。資料的稀缺性對可擴充醫療 AI 解決方案的實際實施構成重大障礙。為了解決此問題，我們結合了各種資料來源，通過讓其更深入地了解多模式資料集的資料表示，來改善效能和對新資料的概括性，並開發了一個基於大型語言模型 (LLM) 的自監督框架，SwinV2，以更深入地了解多模式資料集表示，增強模型推斷新資料的能力，以使用光學相干斷層掃描 (OCT) 影像偵測眼疾。我們採用兩階段訓練方法，自監督預訓練和對下游監督分類器進行微調。在三個資料集上進行的消融研究，採用各種編碼主幹，沒有資料融合，在資料可用性設定較低的情況下，以及沒有自監督預訓練場景，突出了我們方法的穩健性。我們的研究結果證明了在這些不同條件下的一致效能，與基準模型 ResNet-50 相比，展示了卓越的概括能力。

##### **Clinical Validation of a Real-Time Machine Learning-based System for the Detection of Acute Myeloid Leukemia by Flow Cytometry**
2409.11350v1 by Lauren M. Zuromski, Jacob Durtschi, Aimal Aziz, Jeffrey Chumley, Mark Dewey, Paul English, Muir Morrison, Keith Simmon, Blaine Whipple, Brendan O'Fallon, David P. Ng

Machine-learning (ML) models in flow cytometry have the potential to reduce
error rates, increase reproducibility, and boost the efficiency of clinical
labs. While numerous ML models for flow cytometry data have been proposed, few
studies have described the clinical deployment of such models. Realizing the
potential gains of ML models in clinical labs requires not only an accurate
model, but infrastructure for automated inference, error detection, analytics
and monitoring, and structured data extraction. Here, we describe an ML model
for detection of Acute Myeloid Leukemia (AML), along with the infrastructure
supporting clinical implementation. Our infrastructure leverages the resilience
and scalability of the cloud for model inference, a Kubernetes-based workflow
system that provides model reproducibility and resource management, and a
system for extracting structured diagnoses from full-text reports. We also
describe our model monitoring and visualization platform, an essential element
for ensuring continued model accuracy. Finally, we present a post-deployment
analysis of impacts on turn-around time and compare production accuracy to the
original validation statistics.

摘要：機器學習 (ML) 模型在流式細胞術中具有降低錯誤率、提高可重現性和提升臨床實驗室效率的潛力。雖然已經提出許多用於流式細胞術數據的 ML 模型，但很少有研究描述此類模型的臨床部署。要實現 ML 模型在臨床實驗室中的潛在收益，不僅需要準確的模型，還需要用於自動推理、錯誤檢測、分析和監控以及結構化數據提取的基礎設施。在這裡，我們描述了一個用於檢測急性髓性白血病 (AML) 的 ML 模型，以及支持臨床實施的基礎設施。我們的基礎設施利用雲端的復原力和可擴充性進行模型推理，一個基於 Kubernetes 的工作流程系統提供模型可重現性和資源管理，以及一個從全文報告中提取結構化診斷的系統。我們還描述了我們的模型監控和視覺化平台，這是確保持續模型準確性的基本要素。最後，我們提出了對周轉時間影響的部署後分析，並將生產準確度與原始驗證統計數據進行比較。

##### **TTT-Unet: Enhancing U-Net with Test-Time Training Layers for Biomedical Image Segmentation**
2409.11299v2 by Rong Zhou, Zhengqing Yuan, Zhiling Yan, Weixiang Sun, Kai Zhang, Yiwei Li, Yanfang Ye, Xiang Li, Lifang He, Lichao Sun

Biomedical image segmentation is crucial for accurately diagnosing and
analyzing various diseases. However, Convolutional Neural Networks (CNNs) and
Transformers, the most commonly used architectures for this task, struggle to
effectively capture long-range dependencies due to the inherent locality of
CNNs and the computational complexity of Transformers. To address this
limitation, we introduce TTT-Unet, a novel framework that integrates Test-Time
Training (TTT) layers into the traditional U-Net architecture for biomedical
image segmentation. TTT-Unet dynamically adjusts model parameters during the
testing time, enhancing the model's ability to capture both local and
long-range features. We evaluate TTT-Unet on multiple medical imaging datasets,
including 3D abdominal organ segmentation in CT and MR images, instrument
segmentation in endoscopy images, and cell segmentation in microscopy images.
The results demonstrate that TTT-Unet consistently outperforms state-of-the-art
CNN-based and Transformer-based segmentation models across all tasks. The code
is available at https://github.com/rongzhou7/TTT-Unet.

摘要：生物医学影像分割对于准确诊断和分析各种疾病至关重要。然而，卷积神经网络 (CNN) 和 Transformer，是此任务最常用的架构，由于 CNN 的固有局部性和 Transformer 的计算复杂性，难以有效捕捉远程依赖关系。为了解决这一限制，我们引入了 TTT-Unet，这是一个新颖的框架，它将测试时训练 (TTT) 层集成到用于生物医学影像分割的传统 U-Net 架构中。TTT-Unet 在测试时动态调整模型参数，增强了模型捕捉局部和远程特征的能力。我们在多个医学影像数据集上评估了 TTT-Unet，包括 CT 和 MR 影像中的 3D 腹部器官分割、内窥镜影像中的仪器分割以及显微镜影像中的细胞分割。结果表明，TTT-Unet 在所有任务中始终优于最先进的基于 CNN 和基于 Transformer 的分割模型。代码可在 https://github.com/rongzhou7/TTT-Unet 获得。

##### **EIA: Environmental Injection Attack on Generalist Web Agents for Privacy Leakage**
2409.11295v1 by Zeyi Liao, Lingbo Mo, Chejian Xu, Mintong Kang, Jiawei Zhang, Chaowei Xiao, Yuan Tian, Bo Li, Huan Sun

Generalist web agents have evolved rapidly and demonstrated remarkable
potential. However, there are unprecedented safety risks associated with these
them, which are nearly unexplored so far. In this work, we aim to narrow this
gap by conducting the first study on the privacy risks of generalist web agents
in adversarial environments. First, we present a threat model that discusses
the adversarial targets, constraints, and attack scenarios. Particularly, we
consider two types of adversarial targets: stealing users' specific personally
identifiable information (PII) or stealing the entire user request. To achieve
these objectives, we propose a novel attack method, termed Environmental
Injection Attack (EIA). This attack injects malicious content designed to adapt
well to different environments where the agents operate, causing them to
perform unintended actions. This work instantiates EIA specifically for the
privacy scenario. It inserts malicious web elements alongside persuasive
instructions that mislead web agents into leaking private information, and can
further leverage CSS and JavaScript features to remain stealthy. We collect 177
actions steps that involve diverse PII categories on realistic websites from
the Mind2Web dataset, and conduct extensive experiments using one of the most
capable generalist web agent frameworks to date, SeeAct. The results
demonstrate that EIA achieves up to 70% ASR in stealing users' specific PII.
Stealing full user requests is more challenging, but a relaxed version of EIA
can still achieve 16% ASR. Despite these concerning results, it is important to
note that the attack can still be detectable through careful human inspection,
highlighting a trade-off between high autonomy and security. This leads to our
detailed discussion on the efficacy of EIA under different levels of human
supervision as well as implications on defenses for generalist web agents.

摘要：<paragraph>通用網路代理快速演化，展現出驚人的潛力。然而，這些代理伴隨著前所未有的安全風險，而這些風險目前幾乎尚未被探索。在這項工作中，我們旨在透過執行通用網路代理在對抗環境中的隱私風險的第一個研究來縮小這個差距。首先，我們提出一個威脅模型，討論對抗目標、限制和攻擊情境。特別是，我們考慮兩種類型的對抗目標：竊取使用者的特定個人可識別資訊 (PII) 或竊取整個使用者要求。為了達成這些目標，我們提出了一種新穎的攻擊方法，稱為環境注入攻擊 (EIA)。此攻擊注入惡意內容，旨在適應代理運作的不同環境，導致代理執行非預期的動作。這項工作特別針對隱私情境實例化 EIA。它在具有說服力的指令旁插入惡意網路元素，誤導網路代理洩露私人資訊，並可進一步利用 CSS 和 JavaScript 功能保持隱密。我們從 Mind2Web 資料集的現實網站收集了 177 個涉及不同 PII 類別的動作步驟，並使用迄今為止功能最強大的通用網路代理框架 SeeAct 進行廣泛的實驗。結果證明，EIA 在竊取使用者的特定 PII 方面達到了 70% 的 ASR。竊取完整的使用者要求更具挑戰性，但 EIA 的放寬版本仍可達到 16% 的 ASR。儘管有這些令人擔憂的結果，但重要的是要注意，攻擊仍然可以透過仔細的人工檢查來偵測，突顯了高度自主性與安全性之間的權衡。這導致我們詳細討論了 EIA 在不同層級的人工監督下的效能，以及對通用網路代理防禦的影響。</paragraph>

##### **Towards Ethical Personal AI Applications: Practical Considerations for AI Assistants with Long-Term Memory**
2409.11192v1 by Eunhae Lee

One application area of long-term memory (LTM) capabilities with increasing
traction is personal AI companions and assistants. With the ability to retain
and contextualize past interactions and adapt to user preferences, personal AI
companions and assistants promise a profound shift in how we interact with AI
and are on track to become indispensable in personal and professional settings.
However, this advancement introduces new challenges and vulnerabilities that
require careful consideration regarding the deployment and widespread use of
these systems. The goal of this paper is to explore the broader implications of
building and deploying personal AI applications with LTM capabilities using a
holistic evaluation approach. This will be done in three ways: 1) reviewing the
technological underpinnings of LTM in Large Language Models, 2) surveying
current personal AI companions and assistants, and 3) analyzing critical
considerations and implications of deploying and using these applications.

摘要：長期記憶 (LTM) 能力的應用領域之一是個人 AI 伴侶和助理，其吸引力正與日俱增。個人 AI 伴侶和助理具備保留和將過去互動脈絡化，以及適應使用者偏好的能力，承諾將徹底改變我們與 AI 互動的方式，並有望在個人和專業領域中變得不可或缺。然而，這項進展帶來了新的挑戰和漏洞，需要仔細考量這些系統的部署和廣泛使用。本文的目標是利用整體評估方法探討建構和部署具備 LTM 能力的個人 AI 應用程式的廣泛影響。這將透過三種方式進行：1) 檢視大型語言模型中 LTM 的技術基礎，2) 調查目前的個人 AI 伴侶和助理，以及 3) 分析部署和使用這些應用程式的關鍵考量和影響。

##### **Early Detection of Coronary Heart Disease Using Hybrid Quantum Machine Learning Approach**
2409.10932v1 by Mehroush Banday, Sherin Zafar, Parul Agarwal, M Afshar Alam, Abubeker K M

Coronary heart disease (CHD) is a severe cardiac disease, and hence, its
early diagnosis is essential as it improves treatment results and saves money
on medical care. The prevailing development of quantum computing and machine
learning (ML) technologies may bring practical improvement to the performance
of CHD diagnosis. Quantum machine learning (QML) is receiving tremendous
interest in various disciplines due to its higher performance and capabilities.
A quantum leap in the healthcare industry will increase processing power and
optimise multiple models. Techniques for QML have the potential to forecast
cardiac disease and help in early detection. To predict the risk of coronary
heart disease, a hybrid approach utilizing an ensemble machine learning model
based on QML classifiers is presented in this paper. Our approach, with its
unique ability to address multidimensional healthcare data, reassures the
method's robustness by fusing quantum and classical ML algorithms in a
multi-step inferential framework. The marked rise in heart disease and death
rates impacts worldwide human health and the global economy. Reducing cardiac
morbidity and mortality requires early detection of heart disease. In this
research, a hybrid approach utilizes techniques with quantum computing
capabilities to tackle complex problems that are not amenable to conventional
machine learning algorithms and to minimize computational expenses. The
proposed method has been developed in the Raspberry Pi 5 Graphics Processing
Unit (GPU) platform and tested on a broad dataset that integrates clinical and
imaging data from patients suffering from CHD and healthy controls. Compared to
classical machine learning models, the accuracy, sensitivity, F1 score, and
specificity of the proposed hybrid QML model used with CHD are manifold higher.

摘要：冠狀動脈心臟病 (CHD) 是一種嚴重的疾病，因此，早期診斷至關重要，因為它可以改善治療結果並節省醫療保健費用。量子計算和機器學習 (ML) 技術的盛行發展可能會對 CHD 診斷的性能帶來實際改善。量子機器學習 (QML) 由於其更高的性能和能力，在各個領域引起了極大的興趣。醫療保健行業的量子飛躍將增加處理能力並優化多個模型。QML 的技術有潛力預測心臟病並幫助早期發現。為了預測冠狀動脈心臟病的風險，本文提出了一種基於 QML 分類器的混合機器學習模型的混合方法。我們的這種方法具備處理多維醫療保健數據的獨特能力，通過在多步驟推理框架中融合量子和經典 ML 演算法，確保了該方法的穩健性。心臟病和死亡率的顯著上升影響了全球人類健康和全球經濟。降低心臟發病率和死亡率需要對心臟病進行早期發現。在這項研究中，一種混合方法利用具有量子計算能力的技術來解決傳統機器學習演算法無法解決的複雜問題，並最大程度地減少計算開銷。所提出的方法已在 Raspberry Pi 5 繪圖處理單元 (GPU) 平臺上開發，並在一個廣泛的資料集上進行了測試，該資料集整合了患有 CHD 和健康對照者的臨床和影像數據。與經典機器學習模型相比，所提出的混合 QML 模型與 CHD 一起使用的準確性、敏感性、F1 分數和特異性更高。

##### **Self-supervised Speech Models for Word-Level Stuttered Speech Detection**
2409.10704v1 by Yi-Jen Shih, Zoi Gkalitsiou, Alexandros G. Dimakis, David Harwath

Clinical diagnosis of stuttering requires an assessment by a licensed
speech-language pathologist. However, this process is time-consuming and
requires clinicians with training and experience in stuttering and fluency
disorders. Unfortunately, only a small percentage of speech-language
pathologists report being comfortable working with individuals who stutter,
which is inadequate to accommodate for the 80 million individuals who stutter
worldwide. Developing machine learning models for detecting stuttered speech
would enable universal and automated screening for stuttering, enabling speech
pathologists to identify and follow up with patients who are most likely to be
diagnosed with a stuttering speech disorder. Previous research in this area has
predominantly focused on utterance-level detection, which is not sufficient for
clinical settings where word-level annotation of stuttering is the norm. In
this study, we curated a stuttered speech dataset with word-level annotations
and introduced a word-level stuttering speech detection model leveraging
self-supervised speech models. Our evaluation demonstrates that our model
surpasses previous approaches in word-level stuttering speech detection.
Additionally, we conducted an extensive ablation analysis of our method,
providing insight into the most important aspects of adapting self-supervised
speech models for stuttered speech detection.

摘要：臨床口吃診斷需要由執照語言病理學家評估。然而，這個過程很耗時，需要受過口吃和流利障礙訓練和經驗的臨床醫生。不幸的是，只有一小部分語言病理學家表示願意與口吃者合作，這不足以容納全球 8000 萬名口吃者。開發用於檢測口吃語音的機器學習模型將能對口吃進行普遍且自動化的篩查，使語言病理學家能夠識別並追蹤最有可能被診斷出患有口吃言語障礙的患者。這方面的先前研究主要集中於話語層級的檢測，這不足以用於口吃的單字層級註解為常態的臨床環境。在本研究中，我們策劃了一個帶有單字層級註解的口吃語音資料集，並引入了一個利用自我監督語音模型的單字層級口吃語音檢測模型。我們的評估證明，我們的模型在單字層級口吃語音檢測中優於先前的做法。此外，我們對我們的方法進行了廣泛的消融分析，提供了對調整自我監督語音模型以進行口吃語音檢測的最重要面向的見解。

##### **A Knowledge-Enhanced Disease Diagnosis Method Based on Prompt Learning and BERT Integration**
2409.10403v1 by Zhang Zheng

This paper proposes a knowledge-enhanced disease diagnosis method based on a
prompt learning framework. The method retrieves structured knowledge from
external knowledge graphs related to clinical cases, encodes it, and injects it
into the prompt templates to enhance the language model's understanding and
reasoning capabilities for the task.We conducted experiments on three public
datasets: CHIP-CTC, IMCS-V2-NER, and KUAKE-QTR. The results show that the
proposed method significantly outperforms existing models across multiple
evaluation metrics, with an F1 score improvement of 2.4% on the CHIP-CTC
dataset, 3.1% on the IMCS-V2-NER dataset,and 4.2% on the KUAKE-QTR dataset.
Additionally,ablation studies confirmed the critical role of the knowledge
injection module,as the removal of this module resulted in a significant drop
in F1 score. The experimental results demonstrate that the proposed method not
only effectively improves the accuracy of disease diagnosis but also enhances
the interpretability of the predictions, providing more reliable support and
evidence for clinical diagnosis.

摘要：本文提出了一种基于提示学习框架的知识增强疾病诊断方法。该方法从与临床病例相关的外部知识图谱中检索结构化知识，对其进行编码，并将其注入到提示模板中，以增强语言模型对任务的理解和推理能力。我们在三个公共数据集上进行了实验：CHIP-CTC、IMCS-V2-NER 和 KUAKE-QTR。结果表明，所提出的方法在多个评估指标上明显优于现有模型，在 CHIP-CTC 数据集上的 F1 得分提高了 2.4%，在 IMCS-V2-NER 数据集上提高了 3.1%，在 KUAKE-QTR 数据集上提高了 4.2%。此外，消融研究证实了知识注入模块的关键作用，因为移除此模块会导致 F1 得分显着下降。实验结果表明，所提出的方法不仅有效提高了疾病诊断的准确性，而且增强了预测的可解释性，为临床诊断提供了更可靠的支持和证据。

##### **Robust image representations with counterfactual contrastive learning**
2409.10365v1 by Mélanie Roschewitz, Fabio De Sousa Ribeiro, Tian Xia, Galvin Khara, Ben Glocker

Contrastive pretraining can substantially increase model generalisation and
downstream performance. However, the quality of the learned representations is
highly dependent on the data augmentation strategy applied to generate positive
pairs. Positive contrastive pairs should preserve semantic meaning while
discarding unwanted variations related to the data acquisition domain.
Traditional contrastive pipelines attempt to simulate domain shifts through
pre-defined generic image transformations. However, these do not always mimic
realistic and relevant domain variations for medical imaging such as scanner
differences. To tackle this issue, we herein introduce counterfactual
contrastive learning, a novel framework leveraging recent advances in causal
image synthesis to create contrastive positive pairs that faithfully capture
relevant domain variations. Our method, evaluated across five datasets
encompassing both chest radiography and mammography data, for two established
contrastive objectives (SimCLR and DINO-v2), outperforms standard contrastive
learning in terms of robustness to acquisition shift. Notably, counterfactual
contrastive learning achieves superior downstream performance on both
in-distribution and on external datasets, especially for images acquired with
scanners under-represented in the training set. Further experiments show that
the proposed framework extends beyond acquisition shifts, with models trained
with counterfactual contrastive learning substantially improving subgroup
performance across biological sex.

摘要：對比預訓練可以大幅提升模型的泛化能力和下游效能。然而，學習到的表徵品質高度依賴於用來產生正向配對的資料擴充策略。正向對比配對應當保留語意意義，同時捨棄與資料擷取領域相關的不必要變異。傳統的對比管線會嘗試透過預先定義的通用影像轉換來模擬領域轉移。然而，這些轉換並不總是能模仿醫療影像的實際且相關領域變異，例如掃描儀的差異。為了解決這個問題，我們在此提出反事實對比學習，一個利用因果影像合成近期進展來建立忠實捕捉相關領域變異的對比正向配對的新穎架構。我們的做法在涵蓋胸部 X 光和乳房攝影資料的五個資料集上進行評估，對於兩個已建立的對比目標（SimCLR 和 DINO-v2），在對於擷取轉移的穩健性方面優於標準對比學習。值得注意的是，反事實對比學習在內部分佈和外部資料集上都能達成優異的下游效能，特別是對於訓練集中代表性不足的掃描儀所擷取的影像。進一步的實驗顯示，所提出的架構延伸到擷取轉移之外，使用反事實對比學習訓練的模型大幅提升了生物性別的子群效能。

##### **Algorithmic Behaviors Across Regions: A Geolocation Audit of YouTube Search for COVID-19 Misinformation between the United States and South Africa**
2409.10168v1 by Hayoung Jung, Prerna Juneja, Tanushree Mitra

Despite being an integral tool for finding health-related information online,
YouTube has faced criticism for disseminating COVID-19 misinformation globally
to its users. Yet, prior audit studies have predominantly investigated YouTube
within the Global North contexts, often overlooking the Global South. To
address this gap, we conducted a comprehensive 10-day geolocation-based audit
on YouTube to compare the prevalence of COVID-19 misinformation in search
results between the United States (US) and South Africa (SA), the countries
heavily affected by the pandemic in the Global North and the Global South,
respectively. For each country, we selected 3 geolocations and placed
sock-puppets, or bots emulating "real" users, that collected search results for
48 search queries sorted by 4 search filters for 10 days, yielding a dataset of
915K results. We found that 31.55% of the top-10 search results contained
COVID-19 misinformation. Among the top-10 search results, bots in SA faced
significantly more misinformative search results than their US counterparts.
Overall, our study highlights the contrasting algorithmic behaviors of YouTube
search between two countries, underscoring the need for the platform to
regulate algorithmic behavior consistently across different regions of the
Globe.

摘要：儘管 YouTube 是在網路上尋找與健康相關資訊的一項重要工具，但它也因為向全球使用者散播 COVID-19 錯誤資訊而受到批評。然而，先前的稽核研究主要在全球北方的背景下調查 YouTube，常常忽略了全球南方。為了解決這個差距，我們在 YouTube 上進行了一項為期 10 天的綜合地理位置稽核，以比較美國（美國）和南非（南非）搜尋結果中 COVID-19 錯誤資訊的盛行率，這兩個國家分別是全球北方和全球南方中受疫情嚴重影響的國家。對於每個國家，我們選擇了 3 個地理位置，並放置了模擬「真實」使用者的襪子傀儡或機器人，收集了 48 個搜尋查詢的搜尋結果，並根據 4 個搜尋篩選條件進行了 10 天的排序，產生了 915K 筆結果的資料集。我們發現，31.55% 的前 10 名搜尋結果包含 COVID-19 錯誤資訊。在排名前 10 名的搜尋結果中，南非的機器人面臨的錯誤資訊搜尋結果明顯多於美國的機器人。總體而言，我們的研究突出了 YouTube 搜尋在兩個國家之間對比的演算法行為，強調了該平台需要在全球不同地區一致地規範演算法行為。

##### **Machine listening in a neonatal intensive care unit**
2409.11439v1 by Modan Tailleur, Vincent Lostanlen, Jean-Philippe Rivière, Pierre Aumond

Oxygenators, alarm devices, and footsteps are some of the most common sound
sources in a hospital. Detecting them has scientific value for environmental
psychology but comes with challenges of its own: namely, privacy preservation
and limited labeled data. In this paper, we address these two challenges via a
combination of edge computing and cloud computing. For privacy preservation, we
have designed an acoustic sensor which computes third-octave spectrograms on
the fly instead of recording audio waveforms. For sample-efficient machine
learning, we have repurposed a pretrained audio neural network (PANN) via
spectral transcoding and label space adaptation. A small-scale study in a
neonatological intensive care unit (NICU) confirms that the time series of
detected events align with another modality of measurement: i.e., electronic
badges for parents and healthcare professionals. Hence, this paper demonstrates
the feasibility of polyphonic machine listening in a hospital ward while
guaranteeing privacy by design.

摘要：氧合器、警報裝置和腳步聲是醫院中最常見的聲音來源。偵測它們對環境心理學具有科學價值，但同時也面臨著挑戰：即隱私保護和標記資料有限。在本文中，我們通過結合邊緣運算和雲端運算來解決這兩個挑戰。對於隱私保護，我們設計了一個聲學感測器，它可以即時計算三分之一倍頻程譜圖，而不是記錄音訊波形。對於樣本效率高的機器學習，我們通過頻譜轉碼和標籤空間適應重新利用了一個預訓練的音訊神經網路 (PANN)。在新生兒重症監護病房 (NICU) 中進行的一項小規模研究證實，檢測到的事件的時間序列與另一種測量方式一致：即父母和醫療保健專業人員的電子證件。因此，本文展示了在醫院病房中進行多音機器聆聽的可行性，同時保證了隱私設計。

##### **DAE-Fuse: An Adaptive Discriminative Autoencoder for Multi-Modality Image Fusion**
2409.10080v1 by Yuchen Guo, Ruoxiang Xu, Rongcheng Li, Zhenghao Wu, Weifeng Su

Multi-modality image fusion aims to integrate complementary data information
from different imaging modalities into a single image. Existing methods often
generate either blurry fused images that lose fine-grained semantic information
or unnatural fused images that appear perceptually cropped from the inputs. In
this work, we propose a novel two-phase discriminative autoencoder framework,
termed DAE-Fuse, that generates sharp and natural fused images. In the
adversarial feature extraction phase, we introduce two discriminative blocks
into the encoder-decoder architecture, providing an additional adversarial loss
to better guide feature extraction by reconstructing the source images. While
the two discriminative blocks are adapted in the attention-guided
cross-modality fusion phase to distinguish the structural differences between
the fused output and the source inputs, injecting more naturalness into the
results. Extensive experiments on public infrared-visible, medical image
fusion, and downstream object detection datasets demonstrate our method's
superiority and generalizability in both quantitative and qualitative
evaluations.

摘要：多模態影像融合旨在將來自不同影像模態的互補資料資訊整合到單一影像中。現有方法通常會產生模糊的融合影像，失去細緻的語意資訊，或是不自然的融合影像，在感知上看起來像是從輸入中裁切出來的。在這項工作中，我們提出一個新穎的兩階段判別式自編碼器框架，稱為 DAE-Fuse，可產生清晰且自然的融合影像。在對抗特徵提取階段，我們在編碼器-解碼器架構中引入兩個判別式區塊，提供額外的對抗損失，藉由重建原始影像來更好地引導特徵提取。雖然兩個判別式區塊在注意力引導的跨模態融合階段中進行調整，以區分融合輸出與原始輸入之間的結構差異，為結果注入更多自然性。針對公開紅外線可見光、醫學影像融合和下游物件偵測資料集進行的廣泛實驗證明了我們的方法在量化和定性評估中的優越性和泛化性。

##### **MindGuard: Towards Accessible and Sitgma-free Mental Health First Aid via Edge LLM**
2409.10064v1 by Sijie Ji, Xinzhe Zheng, Jiawei Sun, Renqi Chen, Wei Gao, Mani Srivastava

Mental health disorders are among the most prevalent diseases worldwide,
affecting nearly one in four people. Despite their widespread impact, the
intervention rate remains below 25%, largely due to the significant cooperation
required from patients for both diagnosis and intervention. The core issue
behind this low treatment rate is stigma, which discourages over half of those
affected from seeking help. This paper presents MindGuard, an accessible,
stigma-free, and professional mobile mental healthcare system designed to
provide mental health first aid. The heart of MindGuard is an innovative edge
LLM, equipped with professional mental health knowledge, that seamlessly
integrates objective mobile sensor data with subjective Ecological Momentary
Assessment records to deliver personalized screening and intervention
conversations. We conduct a broad evaluation of MindGuard using open datasets
spanning four years and real-world deployment across various mobile devices
involving 20 subjects for two weeks. Remarkably, MindGuard achieves results
comparable to GPT-4 and outperforms its counterpart with more than 10 times the
model size. We believe that MindGuard paves the way for mobile LLM
applications, potentially revolutionizing mental healthcare practices by
substituting self-reporting and intervention conversations with passive,
integrated monitoring within daily life, thus ensuring accessible and
stigma-free mental health support.

摘要：心理健康疾病是全球最普遍的疾病之一，
影響了近四分之一的人。儘管其影響廣泛，
但介入率仍低於 25%，很大程度上是因為
患者在診斷和介入時需要大量配合。背後導致
治療率低下的核心問題是污名化，這讓超過一半的
受影響者不願意尋求幫助。本文提出了 MindGuard，一個
易於取得、無污名化且專業的手機心理保健系統，旨在
提供心理急救。MindGuard 的核心是一個創新的邊緣
大型語言模型 (LLM)，具備專業的心理健康知識，它能無縫
整合客觀的手機感測器資料與主觀的生態瞬時評估記錄，提供
個人化的篩檢和介入對話。我們使用橫跨四年的開放資料集
對 MindGuard 進行廣泛的評估，並在各種行動裝置上進行為期
兩週、涉及 20 位受試者的實際部署。值得注意的是，MindGuard
達到的結果與 GPT-4 相當，並且優於模型規模大於其 10 倍以上的
對應模型。我們相信 MindGuard 為行動 LLM 應用鋪平了道路，
有可能透過在日常生活中進行被動、整合的監控來取代自我報告
和介入對話，從而徹底改變心理保健實務，進而確保可取得且
無污名化的精神健康支持。

##### **HALO: Hallucination Analysis and Learning Optimization to Empower LLMs with Retrieval-Augmented Context for Guided Clinical Decision Making**
2409.10011v2 by Sumera Anjum, Hanzhi Zhang, Wenjun Zhou, Eun Jin Paek, Xiaopeng Zhao, Yunhe Feng

Large language models (LLMs) have significantly advanced natural language
processing tasks, yet they are susceptible to generating inaccurate or
unreliable responses, a phenomenon known as hallucination. In critical domains
such as health and medicine, these hallucinations can pose serious risks. This
paper introduces HALO, a novel framework designed to enhance the accuracy and
reliability of medical question-answering (QA) systems by focusing on the
detection and mitigation of hallucinations. Our approach generates multiple
variations of a given query using LLMs and retrieves relevant information from
external open knowledge bases to enrich the context. We utilize maximum
marginal relevance scoring to prioritize the retrieved context, which is then
provided to LLMs for answer generation, thereby reducing the risk of
hallucinations. The integration of LangChain further streamlines this process,
resulting in a notable and robust increase in the accuracy of both open-source
and commercial LLMs, such as Llama-3.1 (from 44% to 65%) and ChatGPT (from 56%
to 70%). This framework underscores the critical importance of addressing
hallucinations in medical QA systems, ultimately improving clinical
decision-making and patient care. The open-source HALO is available at:
https://github.com/ResponsibleAILab/HALO.

摘要：大型語言模型 (LLM) 已大幅提升自然語言處理任務，但它們容易產生不準確或不可靠的回應，這種現象稱為幻覺。在健康和醫學等關鍵領域，這些幻覺可能會造成嚴重的風險。這篇論文介紹了 HALO，一種新穎的架構，旨在透過專注於偵測和減輕幻覺，來提升醫療問答 (QA) 系統的準確性和可靠性。我們的做法是使用 LLM 產生給定查詢的各種變體，並從外部開放知識庫中擷取相關資訊來豐富內容。我們利用最大邊際相關性評分來優先處理擷取的內容，然後提供給 LLM 以產生答案，從而降低幻覺的風險。LangChain 的整合進一步簡化了這個過程，導致開放原始碼和商業 LLM 的準確性顯著且穩健地提升，例如 Llama-3.1（從 44% 提升到 65%）和 ChatGPT（從 56% 提升到 70%）。這個架構強調了在醫療問答系統中處理幻覺至關重要，最終改善臨床決策制定和患者照護。開放原始碼 HALO 可在以下網址取得：https://github.com/ResponsibleAILab/HALO。

##### **Artificial Intelligence-Based Opportunistic Coronary Calcium Screening in the Veterans Affairs National Healthcare System**
2409.09968v1 by Raffi Hagopian, Timothy Strebel, Simon Bernatz, Gregory A Myers, Erik Offerman, Eric Zuniga, Cy Y Kim, Angie T Ng, James A Iwaz, Sunny P Singh, Evan P Carey, Michael J Kim, R Spencer Schaefer, Jeannie Yu, Amilcare Gentili, Hugo JWL Aerts

Coronary artery calcium (CAC) is highly predictive of cardiovascular events.
While millions of chest CT scans are performed annually in the United States,
CAC is not routinely quantified from scans done for non-cardiac purposes. A
deep learning algorithm was developed using 446 expert segmentations to
automatically quantify CAC on non-contrast, non-gated CT scans (AI-CAC). Our
study differs from prior works as we leverage imaging data across the Veterans
Affairs national healthcare system, from 98 medical centers, capturing
extensive heterogeneity in imaging protocols, scanners, and patients. AI-CAC
performance on non-gated scans was compared against clinical standard ECG-gated
CAC scoring. Non-gated AI-CAC differentiated zero vs. non-zero and less than
100 vs. 100 or greater Agatston scores with accuracies of 89.4% (F1 0.93) and
87.3% (F1 0.89), respectively, in 795 patients with paired gated scans within a
year of a non-gated CT scan. Non-gated AI-CAC was predictive of 10-year
all-cause mortality (CAC 0 vs. >400 group: 25.4% vs. 60.2%, Cox HR 3.49, p <
0.005), and composite first-time stroke, MI, or death (CAC 0 vs. >400 group:
33.5% vs. 63.8%, Cox HR 3.00, p < 0.005). In a screening dataset of 8,052
patients with low-dose lung cancer-screening CTs (LDCT), 3,091/8,052 (38.4%)
individuals had AI-CAC >400. Four cardiologists qualitatively reviewed LDCT
images from a random sample of >400 AI-CAC patients and verified that 527/531
(99.2%) would benefit from lipid-lowering therapy. To the best of our
knowledge, this is the first non-gated CT CAC algorithm developed across a
national healthcare system, on multiple imaging protocols, without filtering
intra-cardiac hardware, and compared against a strong gated CT reference. We
report superior performance relative to previous CAC algorithms evaluated
against paired gated scans that included patients with intra-cardiac hardware.

摘要：冠狀動脈鈣化 (CAC) 極具預測心血管事件的能力。
雖然美國每年進行數百萬次胸部電腦斷層掃描，
但非心臟目的掃描通常不會對 CAC 進行量化。一
個深度學習演算法使用 446 個專家分段開發，以
在非對比、非門控電腦斷層掃描 (AI-CAC) 上自動量化 CAC。我們的
研究與先前的工作不同，因為我們利用退伍軍人事務部全國醫療保健系統中來自 98 個醫療中心的影像資料，捕捉
影像協定、掃描器和患者的廣泛異質性。AI-CAC
在非門控掃描上的表現與臨床標準 ECG 門控
CAC 評分進行比較。非門控 AI-CAC 區分零與非零，以及低於
100 與 100 或更高的 Agatston 分數，在一年內進行配對門控掃描的 795 名患者中準確率分別為 89.4% (F1 0.93) 和
87.3% (F1 0.89)。非門控 AI-CAC 可預測 10 年全因死亡率 (CAC 0 對比 >400 群組：25.4% 對比 60.2%，Cox HR 3.49，p <
0.005)，以及首次複合性中風、心肌梗塞或死亡 (CAC 0 對比 >400 群組：
33.5% 對比 63.8%，Cox HR 3.00，p < 0.005)。在 8,052 名接受低劑量肺癌篩檢電腦斷層掃描 (LDCT) 的患者的篩檢資料集中，3,091/8,052 (38.4%)
個體的 AI-CAC >400。四位心臟病專家對隨機抽取的 >400 AI-CAC 患者的 LDCT
影像進行質性審查，並驗證 527/531
(99.2%) 將受益於降血脂治療。據我們所知，這是第一個非門控電腦斷層 CAC 演算法，在全國醫療保健系統中開發，採用多種影像協定，不篩選
心內硬體，並與強大的門控電腦斷層參考進行比較。我們
報告的效能優於先前針對包含心內硬體患者的配對門控掃描進行評估的 CAC 演算法。

##### **GP-GPT: Large Language Model for Gene-Phenotype Mapping**
2409.09825v1 by Yanjun Lyu, Zihao Wu, Lu Zhang, Jing Zhang, Yiwei Li, Wei Ruan, Zhengliang Liu, Xiaowei Yu, Chao Cao, Tong Chen, Minheng Chen, Yan Zhuang, Xiang Li, Rongjie Liu, Chao Huang, Wentao Li, Tianming Liu, Dajiang Zhu

Pre-trained large language models(LLMs) have attracted increasing attention
in biomedical domains due to their success in natural language processing.
However, the complex traits and heterogeneity of multi-sources genomics data
pose significant challenges when adapting these models to the bioinformatics
and biomedical field. To address these challenges, we present GP-GPT, the first
specialized large language model for genetic-phenotype knowledge representation
and genomics relation analysis. Our model is fine-tuned in two stages on a
comprehensive corpus composed of over 3,000,000 terms in genomics, proteomics,
and medical genetics, derived from multiple large-scale validated datasets and
scientific publications. GP-GPT demonstrates proficiency in accurately
retrieving medical genetics information and performing common genomics analysis
tasks, such as genomics information retrieval and relationship determination.
Comparative experiments across domain-specific tasks reveal that GP-GPT
outperforms state-of-the-art LLMs, including Llama2, Llama3 and GPT-4. These
results highlight GP-GPT's potential to enhance genetic disease relation
research and facilitate accurate and efficient analysis in the fields of
genomics and medical genetics. Our investigation demonstrated the subtle
changes of bio-factor entities' representations in the GP-GPT, which suggested
the opportunities for the application of LLMs to advancing gene-phenotype
research.

摘要：預先訓練好的大型語言模型 (LLM) 由於在自然語言處理方面取得成功，因此在生物醫學領域中備受關注。
然而，多來源基因組數據的複雜特徵和異質性在將這些模型應用於生物資訊學和生物醫學領域時，構成了重大挑戰。為了應對這些挑戰，我們提出了 GP-GPT，這是第一個用於遺傳表型知識表徵和基因組關係分析的專業大型語言模型。我們的模型分兩個階段進行微調，一個綜合語料庫包含超過 3,000,000 個基因組學、蛋白質組學和醫學遺傳學中的術語，這些術語來自多個經過驗證的大規模數據集和科學出版物。GP-GPT 顯示出準確擷取醫學遺傳學資訊和執行常見基因組分析任務（例如基因組資訊擷取和關係確定）的能力。跨領域特定任務的比較實驗顯示，GP-GPT 優於最先進的 LLM，包括 Llama2、Llama3 和 GPT-4。這些結果突出了 GP-GPT 在加強遺傳疾病關係研究以及促進基因組學和醫學遺傳學領域中準確而有效分析的潛力。我們的調查證明了 GP-GPT 中生物因子實體表徵的細微變化，這表明了將 LLM 應用於推進基因表型研究的機會。

##### **Veridical Data Science for Medical Foundation Models**
2409.10580v1 by Ahmed Alaa, Bin Yu

The advent of foundation models (FMs) such as large language models (LLMs)
has led to a cultural shift in data science, both in medicine and beyond. This
shift involves moving away from specialized predictive models trained for
specific, well-defined domain questions to generalist FMs pre-trained on vast
amounts of unstructured data, which can then be adapted to various clinical
tasks and questions. As a result, the standard data science workflow in
medicine has been fundamentally altered; the foundation model lifecycle (FMLC)
now includes distinct upstream and downstream processes, in which computational
resources, model and data access, and decision-making power are distributed
among multiple stakeholders. At their core, FMs are fundamentally statistical
models, and this new workflow challenges the principles of Veridical Data
Science (VDS), hindering the rigorous statistical analysis expected in
transparent and scientifically reproducible data science practices. We
critically examine the medical FMLC in light of the core principles of VDS:
predictability, computability, and stability (PCS), and explain how it deviates
from the standard data science workflow. Finally, we propose recommendations
for a reimagined medical FMLC that expands and refines the PCS principles for
VDS including considering the computational and accessibility constraints
inherent to FMs.

摘要：大型語言模型 (LLM) 等基礎模型 (FM) 的出現，導致了資料科學的文化轉變，無論是在醫學領域或其他領域。這個轉變涉及從針對特定、定義明確的領域問題訓練的專門預測模型，轉移到預先在大量非結構化資料上訓練的泛用型 FM，然後可以調整這些 FM 以適應各種臨床任務和問題。因此，醫學中的標準資料科學工作流程已經發生了根本性的改變；基礎模型生命週期 (FMLC) 現在包括不同的上游和下游流程，其中運算資源、模型和資料存取，以及決策權力會分配給多個利害關係人。從本質上來說，FM 基本上是統計模型，而這個新的工作流程挑戰了真實資料科學 (VDS) 的原則，阻礙了透明且科學上可複製的資料科學實務中所預期的嚴謹統計分析。我們根據 VDS 的核心原則：可預測性、可運算性和穩定性 (PCS) 來批判性地檢視醫學 FMLC，並說明它如何偏離標準的資料科學工作流程。最後，我們提出了重新構想醫學 FMLC 的建議，以擴充和完善適用於 VDS 的 PCS 原則，包括考量 FM 固有的運算和可存取性限制。

##### **From Challenges and Pitfalls to Recommendations and Opportunities: Implementing Federated Learning in Healthcare**
2409.09727v1 by Ming Li, Pengcheng Xu, Junjie Hu, Zeyu Tang, Guang Yang

Federated learning holds great potential for enabling large-scale healthcare
research and collaboration across multiple centres while ensuring data privacy
and security are not compromised. Although numerous recent studies suggest or
utilize federated learning based methods in healthcare, it remains unclear
which ones have potential clinical utility. This review paper considers and
analyzes the most recent studies up to May 2024 that describe federated
learning based methods in healthcare. After a thorough review, we find that the
vast majority are not appropriate for clinical use due to their methodological
flaws and/or underlying biases which include but are not limited to privacy
concerns, generalization issues, and communication costs. As a result, the
effectiveness of federated learning in healthcare is significantly compromised.
To overcome these challenges, we provide recommendations and promising
opportunities that might be implemented to resolve these problems and improve
the quality of model development in federated learning with healthcare.

摘要：聯邦學習在確保資料隱私和安全不致受損的情況下，為大型醫療保健研究和跨多個中心合作提供了巨大潛力。儘管許多最近的研究建議或利用基於聯邦學習的方法進行醫療保健，但哪些具有潛在的臨床效用仍不清楚。本評論文章考慮並分析了截至 2024 年 5 月描述基於聯邦學習方法的醫療保健的最新研究。在徹底檢閱後，我們發現絕大多數不適合臨床使用，因為它們存在方法論缺陷和/或潛在偏差，包括但不限於隱私問題、概化問題和通訊成本。因此，聯邦學習在醫療保健中的效力受到顯著影響。為了克服這些挑戰，我們提供了建議和有希望的機會，這些機會可能會被實施以解決這些問題並提高醫療保健中聯邦學習模型開發的品質。

##### **ExploreSelf: Fostering User-driven Exploration and Reflection on Personal Challenges with Adaptive Guidance by Large Language Models**
2409.09662v2 by Inhwa Song, SoHyun Park, Sachin R. Pendse, Jessica Lee Schleider, Munmun De Choudhury, Young-Ho Kim

Expressing stressful experiences in words is proven to improve mental and
physical health, but individuals often disengage with writing interventions as
they struggle to organize their thoughts and emotions. Reflective prompts have
been used to provide direction, and large language models (LLMs) have
demonstrated the potential to provide tailored guidance. Current systems often
limit users' flexibility to direct their reflections. We thus present
ExploreSelf, an LLM-driven application designed to empower users to control
their reflective journey. ExploreSelf allows users to receive adaptive support
through dynamically generated questions. Through an exploratory study with 19
participants, we examine how participants explore and reflect on personal
challenges using ExploreSelf. Our findings demonstrate that participants valued
the balance between guided support and freedom to control their reflective
journey, leading to deeper engagement and insight. Building on our findings, we
discuss implications for designing LLM-driven tools that promote user
empowerment through effective reflective practices.

摘要：已證實用言語表達壓力經驗有助於改善心理和身體健康，但個人常常放棄寫作介入，因為他們在整理思緒和情緒時會遇到困難。反思提示已被用來提供方向，而大型語言模型 (LLM) 已證明有提供客製化指導的潛力。目前的系統通常會限制使用者引導其反思的靈活性。因此，我們提出了 ExploreSelf，這是一個由 LLM 驅動的應用程式，旨在授權使用者控制其反思旅程。ExploreSelf 允許使用者透過動態產生的問題來接收適應性支援。透過一項與 19 位參與者進行的探索性研究，我們探討參與者如何使用 ExploreSelf 來探索和反思個人挑戰。我們的研究結果表明，參與者重視引導式支援與控制其反思旅程的自由之間的平衡，這會帶來更深入的參與和洞察力。根據我們的研究結果，我們討論了設計 LLM 驅動工具的含意，這些工具透過有效的反思實務促進使用者賦權。

##### **MindScape Study: Integrating LLM and Behavioral Sensing for Personalized AI-Driven Journaling Experiences**
2409.09570v1 by Subigya Nepal, Arvind Pillai, William Campbell, Talie Massachi, Michael V. Heinz, Ashmita Kunwar, Eunsol Soul Choi, Orson Xu, Joanna Kuc, Jeremy Huckins, Jason Holden, Sarah M. Preum, Colin Depp, Nicholas Jacobson, Mary Czerwinski, Eric Granholm, Andrew T. Campbell

Mental health concerns are prevalent among college students, highlighting the
need for effective interventions that promote self-awareness and holistic
well-being. MindScape pioneers a novel approach to AI-powered journaling by
integrating passively collected behavioral patterns such as conversational
engagement, sleep, and location with Large Language Models (LLMs). This
integration creates a highly personalized and context-aware journaling
experience, enhancing self-awareness and well-being by embedding behavioral
intelligence into AI. We present an 8-week exploratory study with 20 college
students, demonstrating the MindScape app's efficacy in enhancing positive
affect (7%), reducing negative affect (11%), loneliness (6%), and anxiety and
depression, with a significant week-over-week decrease in PHQ-4 scores (-0.25
coefficient), alongside improvements in mindfulness (7%) and self-reflection
(6%). The study highlights the advantages of contextual AI journaling, with
participants particularly appreciating the tailored prompts and insights
provided by the MindScape app. Our analysis also includes a comparison of
responses to AI-driven contextual versus generic prompts, participant feedback
insights, and proposed strategies for leveraging contextual AI journaling to
improve well-being on college campuses. By showcasing the potential of
contextual AI journaling to support mental health, we provide a foundation for
further investigation into the effects of contextual AI journaling on mental
health and well-being.

摘要：大學生普遍有心理健康問題，強調需要有效干預措施來促進自我覺察和整體福祉。MindScape 開創了 AI 驅動日誌的新方法，方法是將被動收集的行為模式（例如對話參與、睡眠和位置）與大型語言模型 (LLM) 整合在一起。這種整合創造了高度個人化且具備情境感知能力的日誌體驗，透過將行為智慧嵌入 AI 來增強自我覺察和福祉。我們提出了一項為期 8 週的探索性研究，有 20 名大學生參與，證明 MindScape 應用程式在增強正面影響 (7%)、減少負面影響 (11%)、孤獨感 (6%) 以及焦慮和憂鬱方面有效，PHQ-4 分數週週顯著下降 (-0.25 係數)，同時正念 (7%) 和自我反省 (6%) 也有所改善。這項研究強調了情境 AI 日誌的優點，參與者特別欣賞 MindScape 應用程式提供的客製化提示和見解。我們的分析還包括比較對 AI 驅動情境提示和一般提示的回應、參與者回饋見解，以及提出利用情境 AI 日誌來改善大學校園福祉的策略。透過展示情境 AI 日誌在支援心理健康的潛力，我們為進一步探討情境 AI 日誌對心理健康和福祉的影響奠定了基礎。

##### **COMFORT: A Continual Fine-Tuning Framework for Foundation Models Targeted at Consumer Healthcare**
2409.09549v1 by Chia-Hao Li, Niraj K. Jha

Wearable medical sensors (WMSs) are revolutionizing smart healthcare by
enabling continuous, real-time monitoring of user physiological signals,
especially in the field of consumer healthcare. The integration of WMSs and
modern machine learning (ML) enables unprecedented solutions to efficient
early-stage disease detection. Despite the success of Transformers in various
fields, their application to sensitive domains, such as smart healthcare,
remains underexplored due to limited data accessibility and privacy concerns.
To bridge the gap between Transformer-based foundation models and WMS-based
disease detection, we propose COMFORT, a continual fine-tuning framework for
foundation models targeted at consumer healthcare. COMFORT introduces a novel
approach for pre-training a Transformer-based foundation model on a large
dataset of physiological signals exclusively collected from healthy individuals
with commercially available WMSs. We adopt a masked data modeling (MDM)
objective to pre-train this health foundation model. We then fine-tune the
model using various parameter-efficient fine-tuning (PEFT) methods, such as
low-rank adaptation (LoRA) and its variants, to adapt it to various downstream
disease detection tasks that rely on WMS data. In addition, COMFORT continually
stores the low-rank decomposition matrices obtained from the PEFT algorithms to
construct a library for multi-disease detection. The COMFORT library enables
scalable and memory-efficient disease detection on edge devices. Our
experimental results demonstrate that COMFORT achieves highly competitive
performance while reducing memory overhead by up to 52% relative to
conventional methods. Thus, COMFORT paves the way for personalized and
proactive solutions to efficient and effective early-stage disease detection
for consumer healthcare.

摘要：<paragraph>可穿戴式醫療感測器 (WMS) 透過持續、即時監測使用者的生理訊號，特別是在消費者醫療保健領域，進而革新了智慧醫療保健。WMS 與現代機器學習 (ML) 的整合，讓有效率的早期疾病偵測有了前所未有的解決方案。儘管 Transformer 在各種領域皆獲得成功，但由於資料取得不易和隱私疑慮，其在智慧醫療保健等敏感領域的應用仍有待探索。為了彌合 Transformer 基礎模型與 WMS 基礎疾病偵測之間的差距，我們提出了 COMFORT，一個針對消費者醫療保健而設計的基礎模型持續微調架構。COMFORT 提出了一種創新的方法，可在一個龐大的生理訊號資料集上預訓練 Transformer 基礎模型，而這些資料皆是透過市售 WMS 從健康個人身上收集而來。我們採用遮罩資料建模 (MDM) 目標來預訓練這個健康基礎模型。接著，我們使用各種參數有效率的微調 (PEFT) 方法（例如低秩適應 (LoRA) 及其變體）微調模型，以使其適應依賴 WMS 資料的各種下游疾病偵測任務。此外，COMFORT 會持續儲存從 PEFT 演算法取得的低秩分解矩陣，以建構一個多疾病偵測函式庫。COMFORT 函式庫可在邊緣裝置上進行可擴充且記憶體使用率低下的疾病偵測。我們的實驗結果顯示，COMFORT 達到了極具競爭力的效能，同時將記憶體開銷相較於傳統方法降低了 52%。因此，COMFORT 為消費者醫療保健的有效且高效早期疾病偵測，開闢了個人化且主動的解決方案。</paragraph>

##### **Enhancing Skin Disease Diagnosis: Interpretable Visual Concept Discovery with SAM Empowerment**
2409.09520v1 by Xin Hu, Janet Wang, Jihun Hamm, Rie R Yotsu, Zhengming Ding

Current AI-assisted skin image diagnosis has achieved dermatologist-level
performance in classifying skin cancer, driven by rapid advancements in deep
learning architectures. However, unlike traditional vision tasks, skin images
in general present unique challenges due to the limited availability of
well-annotated datasets, complex variations in conditions, and the necessity
for detailed interpretations to ensure patient safety. Previous segmentation
methods have sought to reduce image noise and enhance diagnostic performance,
but these techniques require fine-grained, pixel-level ground truth masks for
training. In contrast, with the rise of foundation models, the Segment Anything
Model (SAM) has been introduced to facilitate promptable segmentation, enabling
the automation of the segmentation process with simple yet effective prompts.
Efforts applying SAM predominantly focus on dermatoscopy images, which present
more easily identifiable lesion boundaries than clinical photos taken with
smartphones. This limitation constrains the practicality of these approaches to
real-world applications. To overcome the challenges posed by noisy clinical
photos acquired via non-standardized protocols and to improve diagnostic
accessibility, we propose a novel Cross-Attentive Fusion framework for
interpretable skin lesion diagnosis. Our method leverages SAM to generate
visual concepts for skin diseases using prompts, integrating local visual
concepts with global image features to enhance model performance. Extensive
evaluation on two skin disease datasets demonstrates our proposed method's
effectiveness on lesion diagnosis and interpretability.

摘要：目前由 AI 輔助的皮膚影像診斷已在皮膚癌分類中達到皮膚科醫師等級的表現，這歸功於深度學習架構的快速進展。然而，與傳統的視覺任務不同，一般皮膚影像由於標註良好的資料集取得不易、狀況複雜多變，以及確保患者安全所需的詳細詮釋，因此呈現出獨特的挑戰。先前的分割方法試圖降低影像雜訊並提升診斷表現，但這些技術需要細緻的畫素級地面實況遮罩來訓練。相對地，隨著基礎模型的興起，已導入 Segment Anything Model (SAM) 以利於提示式分割，使用簡單卻有效的提示自動化分割流程。應用 SAM 的工作主要集中於皮膚鏡影像，其病灶邊界比使用智慧型手機拍攝的臨床照片更容易辨識。此限制會約束這些方法在實際應用中的實用性。為了克服非標準化程序取得的雜訊臨床照片所造成的挑戰，並改善診斷的可近性，我們提出一個新穎的跨注意力融合架構，用於可詮釋的皮膚病灶診斷。我們的方法利用 SAM 使用提示來產生皮膚疾病的視覺概念，將局部視覺概念與整體影像特徵整合，以提升模型表現。在兩個皮膚疾病資料集上的廣泛評估顯示，我們提出的方法在病灶診斷和可詮釋性上都具有成效。


### Knowledge Graphs
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-09-25**|**Probing Omissions and Distortions in Transformer-based RDF-to-Text Models**|Juliette Faille et.al.|[2409.16707v1](http://arxiv.org/abs/2409.16707v1)|null|
|**2024-09-25**|**GraphLoRA: Structure-Aware Contrastive Low-Rank Adaptation for Cross-Graph Transfer Learning**|Zhe-Rui Yang et.al.|[2409.16670v1](http://arxiv.org/abs/2409.16670v1)|null|
|**2024-09-24**|**Cyber Knowledge Completion Using Large Language Models**|Braden K Webb et.al.|[2409.16176v1](http://arxiv.org/abs/2409.16176v1)|null|
|**2024-09-24**|**Konstruktor: A Strong Baseline for Simple Knowledge Graph Question Answering**|Maria Lysyuk et.al.|[2409.15902v1](http://arxiv.org/abs/2409.15902v1)|[link](https://github.com/s-nlp/konstruktor)|
|**2024-09-24**|**Symmetries and Expressive Requirements for Learning General Policies**|Dominik Drexler et.al.|[2409.15892v1](http://arxiv.org/abs/2409.15892v1)|null|
|**2024-09-23**|**GEM-RAG: Graphical Eigen Memories For Retrieval Augmented Generation**|Brendan Hogan Rappazzo et.al.|[2409.15566v1](http://arxiv.org/abs/2409.15566v1)|null|
|**2024-09-23**|**KARMA: Augmenting Embodied AI Agents with Long-and-short Term Memory Systems**|Zixuan Wang et.al.|[2409.14908v1](http://arxiv.org/abs/2409.14908v1)|null|
|**2024-09-23**|**End-to-End Graph Flattening Method for Large Language Models**|Bin Hong et.al.|[2409.14880v1](http://arxiv.org/abs/2409.14880v1)|null|
|**2024-09-22**|**RACOON: An LLM-based Framework for Retrieval-Augmented Column Type Annotation with a Knowledge Graph**|Linxi Wei et.al.|[2409.14556v1](http://arxiv.org/abs/2409.14556v1)|null|
|**2024-09-21**|**Graph Neural Network Framework for Sentiment Analysis Using Syntactic Feature**|Linxiao Wu et.al.|[2409.14000v1](http://arxiv.org/abs/2409.14000v1)|null|
|**2024-09-20**|**ShizishanGPT: An Agricultural Large Language Model Integrating Tools and Resources**|Shuting Yang et.al.|[2409.13537v1](http://arxiv.org/abs/2409.13537v1)|null|
|**2024-09-20**|**LM-assisted keyword biasing with Aho-Corasick algorithm for Transducer-based ASR**|Iuliia Thorbecke et.al.|[2409.13514v1](http://arxiv.org/abs/2409.13514v1)|null|
|**2024-09-20**|**AQA: Adaptive Question Answering in a Society of LLMs via Contextual Multi-Armed Bandit**|Mohanna Hoveyda et.al.|[2409.13447v2](http://arxiv.org/abs/2409.13447v2)|null|
|**2024-09-20**|**GAProtoNet: A Multi-head Graph Attention-based Prototypical Network for Interpretable Text Classification**|Ximing Wen et.al.|[2409.13312v1](http://arxiv.org/abs/2409.13312v1)|null|
|**2024-09-20**|**Leveraging Knowledge Graphs and LLMs to Support and Monitor Legislative Systems**|Andrea Colombo et.al.|[2409.13252v1](http://arxiv.org/abs/2409.13252v1)|null|
|**2024-09-19**|**Knowledge-Based Domain-Oriented Data Augmentation for Enhancing Unsupervised Sentence Embedding**|Peichao Lai et.al.|[2409.12887v1](http://arxiv.org/abs/2409.12887v1)|null|
|**2024-09-19**|**KnowFormer: Revisiting Transformers for Knowledge Graph Reasoning**|Junnan Liu et.al.|[2409.12865v1](http://arxiv.org/abs/2409.12865v1)|null|
|**2024-09-19**|**A New Perspective on ADHD Research: Knowledge Graph Construction with LLMs and Network Based Insights**|Hakan T. Otal et.al.|[2409.12853v1](http://arxiv.org/abs/2409.12853v1)|null|
|**2024-09-19**|**Enhancing Logical Reasoning in Large Language Models through Graph-based Synthetic Data**|Jiaming Zhou et.al.|[2409.12437v1](http://arxiv.org/abs/2409.12437v1)|[link](https://github.com/riddickzhou/llm-graph-synthetic-reasoning)|
|**2024-09-19**|**Textualized Agent-Style Reasoning for Complex Tasks by Multiple Round LLM Generation**|Chen Liang et.al.|[2409.12411v1](http://arxiv.org/abs/2409.12411v1)|null|
|**2024-09-18**|**GUNet: A Graph Convolutional Network United Diffusion Model for Stable and Diversity Pose Generation**|Shuowen Liang et.al.|[2409.11689v1](http://arxiv.org/abs/2409.11689v1)|[link](https://github.com/liangshuowen/posediffusion)|
|**2024-09-17**|**FedNE: Surrogate-Assisted Federated Neighbor Embedding for Dimensionality Reduction**|Ziwei Li et.al.|[2409.11509v1](http://arxiv.org/abs/2409.11509v1)|null|
|**2024-09-17**|**Reasoning Graph Enhanced Exemplars Retrieval for In-Context Learning**|Yukang Lin et.al.|[2409.11147v1](http://arxiv.org/abs/2409.11147v1)|[link](https://github.com/yukang-lin/rger)|
|**2024-09-17**|**Semformer: Transformer Language Models with Semantic Planning**|Yongjing Yin et.al.|[2409.11143v1](http://arxiv.org/abs/2409.11143v1)|null|
|**2024-09-17**|**KALE: An Artwork Image Captioning System Augmented with Heterogeneous Graph**|Yanbei Jiang et.al.|[2409.10921v1](http://arxiv.org/abs/2409.10921v1)|[link](https://github.com/yanbei-jiang/artwork-interpretation)|
|**2024-09-16**|**A Knowledge-Enhanced Disease Diagnosis Method Based on Prompt Learning and BERT Integration**|Zhang Zheng et.al.|[2409.10403v1](http://arxiv.org/abs/2409.10403v1)|null|
|**2024-09-16**|**MGSA: Multi-Granularity Graph Structure Attention for Knowledge Graph-to-Text Generation**|Shanshan Wang et.al.|[2409.10294v2](http://arxiv.org/abs/2409.10294v2)|null|
|**2024-09-16**|**LLM-DER:A Named Entity Recognition Method Based on Large Language Models for Chinese Coal Chemical Domain**|Le Xiao et.al.|[2409.10077v1](http://arxiv.org/abs/2409.10077v1)|null|
|**2024-09-16**|**On the Diagram of Thought**|Yifan Zhang et.al.|[2409.10038v1](http://arxiv.org/abs/2409.10038v1)|[link](https://github.com/diagram-of-thought/diagram-of-thought)|
|**2024-09-15**|**Entity-Aware Self-Attention and Contextualized GCN for Enhanced Relation Extraction in Long Sentences**|Xin Wang et.al.|[2409.13755v1](http://arxiv.org/abs/2409.13755v1)|null|
|**2024-09-14**|**Generating Event-oriented Attribution for Movies via Two-Stage Prefix-Enhanced Multimodal LLM**|Yuanjie Lyu et.al.|[2409.09362v1](http://arxiv.org/abs/2409.09362v1)|null|
|**2024-09-14**|**ODE: Open-Set Evaluation of Hallucinations in Multimodal Large Language Models**|Yahan Tu et.al.|[2409.09318v1](http://arxiv.org/abs/2409.09318v1)|null|
|**2024-09-13**|**Towards Leveraging Contrastively Pretrained Neural Audio Embeddings for Recommender Tasks**|Florian Grötschla et.al.|[2409.09026v1](http://arxiv.org/abs/2409.09026v1)|null|
|**2024-09-13**|**Contri(e)ve: Context + Retrieve for Scholarly Question Answering**|Kanchan Shivashankar et.al.|[2409.09010v1](http://arxiv.org/abs/2409.09010v1)|null|
|**2024-09-13**|**SGFormer: Single-Layer Graph Transformers with Approximation-Free Linear Complexity**|Qitian Wu et.al.|[2409.09007v1](http://arxiv.org/abs/2409.09007v1)|[link](https://github.com/qitianwu/sgformer)|
|**2024-09-13**|**Exploring Graph Structure Comprehension Ability of Multimodal Large Language Models: Case Studies**|Zhiqiang Zhong et.al.|[2409.08864v1](http://arxiv.org/abs/2409.08864v1)|null|
|**2024-09-13**|**A RAG Approach for Generating Competency Questions in Ontology Engineering**|Xueli Pan et.al.|[2409.08820v1](http://arxiv.org/abs/2409.08820v1)|null|
|**2024-09-13**|**ATFLRec: A Multimodal Recommender System with Audio-Text Fusion and Low-Rank Adaptation via Instruction-Tuned Large Language Model**|Zezheng Qin et.al.|[2409.08543v1](http://arxiv.org/abs/2409.08543v1)|null|
|**2024-09-12**|**What Makes a Maze Look Like a Maze?**|Joy Hsu et.al.|[2409.08202v1](http://arxiv.org/abs/2409.08202v1)|null|
|**2024-09-12**|**Towards a graph-based foundation model for network traffic analysis**|Louis Van Langendonck et.al.|[2409.08111v1](http://arxiv.org/abs/2409.08111v1)|null|
|**2024-09-12**|**Learning Rules from KGs Guided by Language Models**|Zihang Peng et.al.|[2409.07869v1](http://arxiv.org/abs/2409.07869v1)|[link](https://github.com/pzh97/learning-rules-from-kgs-guided-by-language-models)|
|**2024-09-12**|**Multi-object event graph representation learning for Video Question Answering**|Yanan Wang et.al.|[2409.07747v1](http://arxiv.org/abs/2409.07747v1)|null|
|**2024-09-11**|**Demo: SGCode: A Flexible Prompt-Optimizing System for Secure Generation of Code**|Khiem Ton et.al.|[2409.07368v3](http://arxiv.org/abs/2409.07368v3)|null|
|**2024-09-11**|**Semantic Interoperability on Blockchain by Generating Smart Contracts Based on Knowledge Graphs**|William Van Woensel et.al.|[2409.12171v1](http://arxiv.org/abs/2409.12171v1)|null|
|**2024-09-11**|**Ontology-Free General-Domain Knowledge Graph-to-Text Generation Dataset Synthesis using Large Language Model**|Daehee Kim et.al.|[2409.07088v1](http://arxiv.org/abs/2409.07088v1)|[link](https://github.com/daehuikim/WikiOFGraph)|
|**2024-09-11**|**Automated Speaking Assessment of Conversation Tests with Novel Graph-based Modeling on Spoken Response Coherence**|Jiun-Ting Li et.al.|[2409.07064v1](http://arxiv.org/abs/2409.07064v1)|null|
|**2024-09-11**|**FreeRide: Harvesting Bubbles in Pipeline Parallelism**|Jiashu Zhang et.al.|[2409.06941v1](http://arxiv.org/abs/2409.06941v1)|null|
|**2024-09-10**|**Generative Hierarchical Materials Search**|Sherry Yang et.al.|[2409.06762v1](http://arxiv.org/abs/2409.06762v1)|null|
|**2024-09-10**|**Fine-tuning and Prompt Engineering with Cognitive Knowledge Graphs for Scholarly Knowledge Organization**|Gollam Rabby et.al.|[2409.06433v1](http://arxiv.org/abs/2409.06433v1)|null|
|**2024-09-10**|**TopoChat: Enhancing Topological Materials Retrieval With Large Language Model and Multi-Source Knowledge**|HuangChao Xu et.al.|[2409.13732v1](http://arxiv.org/abs/2409.13732v1)|null|
|**2024-09-10**|**KAG: Boosting LLMs in Professional Domains via Knowledge Augmented Generation**|Lei Liang et.al.|[2409.13731v3](http://arxiv.org/abs/2409.13731v3)|null|
|**2024-09-09**|**Scalable Multitask Learning Using Gradient-based Estimation of Task Affinity**|Dongyue Li et.al.|[2409.06091v1](http://arxiv.org/abs/2409.06091v1)|[link](https://github.com/virtuosoresearch/scalablemtl)|
|**2024-09-09**|**OneEdit: A Neural-Symbolic Collaboratively Knowledge Editing System**|Ningyu Zhang et.al.|[2409.07497v1](http://arxiv.org/abs/2409.07497v1)|[link](https://github.com/zjunlp/oneedit)|
|**2024-09-09**|**SciAgents: Automating scientific discovery through multi-agent intelligent graph reasoning**|Alireza Ghafarollahi et.al.|[2409.05556v1](http://arxiv.org/abs/2409.05556v1)|[link](https://github.com/lamm-mit/SciAgentsDiscovery)|
|**2024-09-09**|**Assessing SPARQL capabilities of Large Language Models**|Lars-Peter Meyer et.al.|[2409.05925v1](http://arxiv.org/abs/2409.05925v1)|[link](https://github.com/aksw/llm-kg-bench)|
|**2024-09-09**|**KARGEN: Knowledge-enhanced Automated Radiology Report Generation Using Large Language Models**|Yingshu Li et.al.|[2409.05370v1](http://arxiv.org/abs/2409.05370v1)|null|
|**2024-09-07**|**Action is the primary key: a categorical framework for episode description and logical reasoning**|Yoshiki Fukada et.al.|[2409.04793v1](http://arxiv.org/abs/2409.04793v1)|null|
|**2024-09-06**|**Accelerating Training with Neuron Interaction and Nowcasting Networks**|Boris Knyazev et.al.|[2409.04434v1](http://arxiv.org/abs/2409.04434v1)|[link](https://github.com/samsungsailmontreal/nino)|
|**2024-09-06**|**Using Large Language Models to Generate Authentic Multi-agent Knowledge Work Datasets**|Desiree Heim et.al.|[2409.04286v1](http://arxiv.org/abs/2409.04286v1)|null|
|**2024-09-06**|**GALLa: Graph Aligned Large Language Models for Improved Source Code Understanding**|Ziyin Zhang et.al.|[2409.04183v1](http://arxiv.org/abs/2409.04183v1)|null|
|**2024-09-06**|**Combining LLMs and Knowledge Graphs to Reduce Hallucinations in Question Answering**|Larissa Pusch et.al.|[2409.04181v1](http://arxiv.org/abs/2409.04181v1)|null|
|**2024-09-06**|**Refining Wikidata Taxonomy using Large Language Models**|Yiwen Peng et.al.|[2409.04056v1](http://arxiv.org/abs/2409.04056v1)|[link](https://github.com/peng-yiwen/WiKC)|
|**2024-09-06**|**Large Margin Prototypical Network for Few-shot Relation Classification with Fine-grained Features**|Miao Fan et.al.|[2409.04009v1](http://arxiv.org/abs/2409.04009v1)|null|
|**2024-09-05**|**Rx Strategist: Prescription Verification using LLM Agents System**|Phuc Phan Van et.al.|[2409.03440v1](http://arxiv.org/abs/2409.03440v1)|null|
|**2024-09-05**|**iText2KG: Incremental Knowledge Graphs Construction Using Large Language Models**|Yassir Lairgi et.al.|[2409.03284v1](http://arxiv.org/abs/2409.03284v1)|[link](https://github.com/AuvaLab/itext2kg)|
|**2024-09-05**|**GraphInsight: Unlocking Insights in Large Language Models for Graph Structure Understanding**|Yukun Cao et.al.|[2409.03258v1](http://arxiv.org/abs/2409.03258v1)|null|
|**2024-09-05**|**Debate on Graph: a Flexible and Reliable Reasoning Framework for Large Language Models**|Jie Ma et.al.|[2409.03155v1](http://arxiv.org/abs/2409.03155v1)|[link](https://github.com/reml-group/dog)|
|**2024-09-04**|**Word and Phrase Features in Graph Convolutional Network for Automatic Question Classification**|Junyoung Lee et.al.|[2409.02481v1](http://arxiv.org/abs/2409.02481v1)|null|
|**2024-09-04**|**Multi-modal Situated Reasoning in 3D Scenes**|Xiongkun Linghu et.al.|[2409.02389v1](http://arxiv.org/abs/2409.02389v1)|null|
|**2024-09-02**|**Grounding Language Models in Autonomous Loco-manipulation Tasks**|Jin Wang et.al.|[2409.01326v1](http://arxiv.org/abs/2409.01326v1)|null|
|**2024-09-02**|**LATEX-GCL: Large Language Models (LLMs)-Based Data Augmentation for Text-Attributed Graph Contrastive Learning**|Haoran Yang et.al.|[2409.01145v1](http://arxiv.org/abs/2409.01145v1)|null|
|**2024-09-01**|**Harnessing the Power of Semi-Structured Knowledge and LLMs with Triplet-Based Prefiltering for Question Answering**|Derian Boer et.al.|[2409.00861v1](http://arxiv.org/abs/2409.00861v1)|[link](https://github.com/kramerlab/4StepFocus)|
|**2024-09-01**|**Building FKG.in: a Knowledge Graph for Indian Food**|Saransh Kumar Gupta et.al.|[2409.00830v1](http://arxiv.org/abs/2409.00830v1)|null|
|**2024-09-01**|**Hound: Hunting Supervision Signals for Few and Zero Shot Node Classification on Text-attributed Graph**|Yuxiang Wang et.al.|[2409.00727v1](http://arxiv.org/abs/2409.00727v1)|null|
|**2024-08-31**|**WikiCausal: Corpus and Evaluation Framework for Causal Knowledge Graph Construction**|Oktie Hassanzadeh et.al.|[2409.00331v1](http://arxiv.org/abs/2409.00331v1)|[link](https://github.com/IBM/wikicausal)|
|**2024-08-29**|**HyPA-RAG: A Hybrid Parameter Adaptive Retrieval-Augmented Generation System for AI Legal and Policy Applications**|Rishi Kalra et.al.|[2409.09046v1](http://arxiv.org/abs/2409.09046v1)|null|
|**2024-08-29**|**LLaVA-SG: Leveraging Scene Graphs as Visual Semantic Expression in Vision-Language Models**|Jingyi Wang et.al.|[2408.16224v2](http://arxiv.org/abs/2408.16224v2)|null|
|**2024-08-28**|**LLM-Based Multi-Hop Question Answering with Knowledge Graph Integration in Evolving Environments**|Ruirui Chen et.al.|[2408.15903v1](http://arxiv.org/abs/2408.15903v1)|null|
|**2024-08-27**|**VHAKG: A Multi-modal Knowledge Graph Based on Synchronized Multi-view Videos of Daily Activities**|Shusaku Egami et.al.|[2408.14895v2](http://arxiv.org/abs/2408.14895v2)|[link](https://github.com/aistairc/virtualhome_aist)|
|**2024-08-27**|**XG-NID: Dual-Modality Network Intrusion Detection using a Heterogeneous Graph Neural Network and Large Language Model**|Yasir Ali Farrukh et.al.|[2408.16021v1](http://arxiv.org/abs/2408.16021v1)|[link](https://github.com/yasir-ali-farrukh/gnn4id)|
|**2024-08-26**|**Process Trace Querying using Knowledge Graphs and Notation3**|William Van Woensel et.al.|[2409.04452v1](http://arxiv.org/abs/2409.04452v1)|null|
|**2024-08-26**|**PatentGPT: A Large Language Model for Patent Drafting Using Knowledge-based Fine-tuning Method**|Runtao Ren et.al.|[2409.00092v1](http://arxiv.org/abs/2409.00092v1)|null|
|**2024-08-26**|**DynamicRouteGPT: A Real-Time Multi-Vehicle Dynamic Navigation Framework Based on Large Language Models**|Ziai Zhou et.al.|[2408.14185v1](http://arxiv.org/abs/2408.14185v1)|null|
|**2024-08-26**|**Exploring the Potential of Large Language Models for Heterophilic Graphs**|Yuxia Wu et.al.|[2408.14134v1](http://arxiv.org/abs/2408.14134v1)|null|
|**2024-08-26**|**Towards Graph Prompt Learning: A Survey and Beyond**|Qingqing Long et.al.|[2408.14520v3](http://arxiv.org/abs/2408.14520v3)|null|
|**2024-08-25**|**CodeGraph: Enhancing Graph Reasoning of LLMs with Code**|Qiaolong Cai et.al.|[2408.13863v1](http://arxiv.org/abs/2408.13863v1)|null|
|**2024-08-25**|**LLMs as Zero-shot Graph Learners: Alignment of GNN Representations with LLM Token Embeddings**|Duo Wang et.al.|[2408.14512v1](http://arxiv.org/abs/2408.14512v1)|null|
|**2024-08-24**|**Hierarchical Network Fusion for Multi-Modal Electron Micrograph Representation Learning with Foundational Large Language Models**|Sakhinana Sagar Srinivas et.al.|[2408.13661v1](http://arxiv.org/abs/2408.13661v1)|null|
|**2024-08-24**|**GNN: Graph Neural Network and Large Language Model for Data Discovery**|Thomas Hoang et.al.|[2408.13609v2](http://arxiv.org/abs/2408.13609v2)|null|
|**2024-08-24**|**HRGraph: Leveraging LLMs for HR Data Knowledge Graphs with Information Propagation-based Job Recommendation**|Azmine Toushik Wasi et.al.|[2408.13521v1](http://arxiv.org/abs/2408.13521v1)|[link](https://github.com/azminewasi/hrgraph)|
|**2024-08-24**|**Integrating Multi-Head Convolutional Encoders with Cross-Attention for Improved SPARQL Query Translation**|Yi-Hui Chen et.al.|[2408.13432v1](http://arxiv.org/abs/2408.13432v1)|null|
|**2024-08-23**|**CodeRefine: A Pipeline for Enhancing LLM-Generated Code Implementations of Research Papers**|Ekaterina Trofimova et.al.|[2408.13366v1](http://arxiv.org/abs/2408.13366v1)|null|
|**2024-08-23**|**Knowledge Graph Modeling-Driven Large Language Model Operating System (LLM OS) for Task Automation in Process Engineering Problem-Solving**|Sakhinana Sagar Srinivas et.al.|[2408.14494v1](http://arxiv.org/abs/2408.14494v1)|null|
|**2024-08-22**|**A Percolation Model of Emergence: Analyzing Transformers Trained on a Formal Language**|Ekdeep Singh Lubana et.al.|[2408.12578v2](http://arxiv.org/abs/2408.12578v2)|[link](https://github.com/ekdeepslubana/conceptpercolation)|
|**2024-08-22**|**Enhancing Natural Language Inference Performance with Knowledge Graph for COVID-19 Automated Fact-Checking in Indonesian Language**|Arief Purnama Muharram et.al.|[2409.00061v1](http://arxiv.org/abs/2409.00061v1)|null|
|**2024-08-22**|**Cell-ontology guided transcriptome foundation model**|Xinyu Yuan et.al.|[2408.12373v1](http://arxiv.org/abs/2408.12373v1)|null|
|**2024-08-22**|**Graph Retrieval Augmented Trustworthiness Reasoning**|Ying Zhu et.al.|[2408.12333v2](http://arxiv.org/abs/2408.12333v2)|[link](https://github.com/EvoNexusX/Graph-Retrieval-Augmented-Trustworthiness-Reasoning)|
|**2024-08-22**|**MedDiT: A Knowledge-Controlled Diffusion Transformer Framework for Dynamic Medical Image Generation in Virtual Simulated Patient**|Yanzeng Li et.al.|[2408.12236v1](http://arxiv.org/abs/2408.12236v1)|null|
|**2024-08-22**|**Geolocation Representation from Large Language Models are Generic Enhancers for Spatio-Temporal Learning**|Junlin He et.al.|[2408.12116v1](http://arxiv.org/abs/2408.12116v1)|null|
|**2024-08-21**|**Enabling Small Models for Zero-Shot Classification through Model Label Learning**|Jia Zhang et.al.|[2408.11449v1](http://arxiv.org/abs/2408.11449v1)|null|

#### Abstracts
##### **Probing Omissions and Distortions in Transformer-based RDF-to-Text Models**
2409.16707v1 by Juliette Faille, Albert Gatt, Claire Gardent

In Natural Language Generation (NLG), important information is sometimes
omitted in the output text. To better understand and analyse how this type of
mistake arises, we focus on RDF-to-Text generation and explore two methods of
probing omissions in the encoder output of BART (Lewis et al, 2020) and of T5
(Raffel et al, 2019): (i) a novel parameter-free probing method based on the
computation of cosine similarity between embeddings of RDF graphs and of RDF
graphs in which we removed some entities and (ii) a parametric probe which
performs binary classification on the encoder embeddings to detect omitted
entities. We also extend our analysis to distorted entities, i.e. entities that
are not fully correctly mentioned in the generated text (e.g. misspelling of
entity, wrong units of measurement). We found that both omitted and distorted
entities can be probed in the encoder's output embeddings. This suggests that
the encoder emits a weaker signal for these entities and therefore is
responsible for some loss of information. This also shows that probing methods
can be used to detect mistakes in the output of NLG models.

摘要：在自然語言生成 (NLG) 中，重要資訊有時會在輸出文字中被省略。為了更了解並分析這類錯誤是如何產生的，我們專注於 RDF 轉文字的生成，並探討兩種探測 BART (Lewis 等人，2020) 和 T5 (Raffel 等人，2019) 的編碼器輸出中遺漏的方法：(i) 一種基於 RDF 圖形嵌入和我們移除一些實體的 RDF 圖形之間的餘弦相似度計算的新型無參數探測方法，以及 (ii) 一種在編碼器嵌入中執行二元分類以偵測遺漏實體的參數化探測。我們也將我們的分析延伸到扭曲的實體，也就是在產生的文字中沒有被完全正確提及的實體 (例如實體拼寫錯誤、測量單位錯誤)。我們發現遺漏和扭曲的實體都可以被探測到在編碼器的輸出嵌入中。這表示編碼器針對這些實體發射較弱的訊號，因此導致一些資訊遺失。這也顯示探測方法可以用於偵測 NLG 模型輸出中的錯誤。

##### **GraphLoRA: Structure-Aware Contrastive Low-Rank Adaptation for Cross-Graph Transfer Learning**
2409.16670v1 by Zhe-Rui Yang, Jindong Han, Chang-Dong Wang, Hao Liu

Graph Neural Networks (GNNs) have demonstrated remarkable proficiency in
handling a range of graph analytical tasks across various domains, such as
e-commerce and social networks. Despite their versatility, GNNs face
significant challenges in transferability, limiting their utility in real-world
applications. Existing research in GNN transfer learning overlooks
discrepancies in distribution among various graph datasets, facing challenges
when transferring across different distributions. How to effectively adopt a
well-trained GNN to new graphs with varying feature and structural
distributions remains an under-explored problem. Taking inspiration from the
success of Low-Rank Adaptation (LoRA) in adapting large language models to
various domains, we propose GraphLoRA, an effective and parameter-efficient
method for transferring well-trained GNNs to diverse graph domains.
Specifically, we first propose a Structure-aware Maximum Mean Discrepancy
(SMMD) to align divergent node feature distributions across source and target
graphs. Moreover, we introduce low-rank adaptation by injecting a small
trainable GNN alongside the pre-trained one, effectively bridging structural
distribution gaps while mitigating the catastrophic forgetting. Additionally, a
structure-aware regularization objective is proposed to enhance the
adaptability of the pre-trained GNN to target graph with scarce supervision
labels. Extensive experiments on six real-world datasets demonstrate the
effectiveness of GraphLoRA against eleven baselines by tuning only 20% of
parameters, even across disparate graph domains. The code is available at
https://anonymous.4open.science/r/GraphLoRA.

摘要：圖形神經網路 (GNN) 已展現出在各種領域處理一系列圖形分析任務的卓越能力，例如電子商務和社群網路。儘管 GNN 具有多功能性，但在可轉移性方面仍面臨重大挑戰，限制了它們在現實世界應用中的效用。現有的 GNN 轉移學習研究忽視了各種圖形資料集之間的分布差異，在跨不同分布轉移時面臨挑戰。如何有效地將訓練良好的 GNN 應用於具有不同特徵和結構分布的新圖形，仍然是一個尚未充分探討的問題。從低秩適應 (LoRA) 在將大型語言模型適應到各種領域方面獲得的成功中汲取靈感，我們提出了 GraphLoRA，這是一種有效且參數效率高的方法，可用於將訓練良好的 GNN 轉移到不同的圖形領域。具體來說，我們首先提出一個結構感知最大平均差異 (SMMD) 來調整來源和目標圖形中的不同節點特徵分布。此外，我們通過在預先訓練的 GNN 旁邊注入一個小的可訓練 GNN 來引入低秩適應，從而有效地彌合結構分布差距，同時減輕災難性遺忘。此外，還提出了結構感知正則化目標，以增強預先訓練的 GNN 對具有稀疏監督標籤的目標圖形的適應性。在六個真實世界資料集上的大量實驗證明了 GraphLoRA 的有效性，它僅調整了 20% 的參數，即使在不同的圖形領域中也能夠勝過十一種基準。程式碼可在 https://anonymous.4open.science/r/GraphLoRA 取得。

##### **Cyber Knowledge Completion Using Large Language Models**
2409.16176v1 by Braden K Webb, Sumit Purohit, Rounak Meyur

The integration of the Internet of Things (IoT) into Cyber-Physical Systems
(CPSs) has expanded their cyber-attack surface, introducing new and
sophisticated threats with potential to exploit emerging vulnerabilities.
Assessing the risks of CPSs is increasingly difficult due to incomplete and
outdated cybersecurity knowledge. This highlights the urgent need for
better-informed risk assessments and mitigation strategies. While previous
efforts have relied on rule-based natural language processing (NLP) tools to
map vulnerabilities, weaknesses, and attack patterns, recent advancements in
Large Language Models (LLMs) present a unique opportunity to enhance
cyber-attack knowledge completion through improved reasoning, inference, and
summarization capabilities. We apply embedding models to encapsulate
information on attack patterns and adversarial techniques, generating mappings
between them using vector embeddings. Additionally, we propose a
Retrieval-Augmented Generation (RAG)-based approach that leverages pre-trained
models to create structured mappings between different taxonomies of threat
patterns. Further, we use a small hand-labeled dataset to compare the proposed
RAG-based approach to a baseline standard binary classification model. Thus,
the proposed approach provides a comprehensive framework to address the
challenge of cyber-attack knowledge graph completion.

摘要：物聯網 (IoT) 與網路實體系統 (CPS) 的整合擴大了其網路攻擊面，引入了新的和複雜的威脅，具有利用新興漏洞的潛力。由於網路安全知識不完整且過時，評估 CPS 的風險變得越來越困難。這突顯了迫切需要更完善的風險評估和緩解策略。雖然先前的努力依賴於基於規則的自然語言處理 (NLP) 工具來繪製漏洞、弱點和攻擊模式，但大型語言模型 (LLM) 的最新進展提供了一個獨特的機會，可以透過改進的推理、推論和摘要能力來增強網路攻擊知識的完成度。我們應用嵌入模型來封裝有關攻擊模式和對抗技術的資訊，使用向量嵌入在它們之間產生對應關係。此外，我們提出了一個基於檢索增強生成 (RAG) 的方法，該方法利用預先訓練的模型在威脅模式的不同分類法之間建立結構化的對應關係。此外，我們使用一個小型的手動標記資料集來比較所提出的基於 RAG 的方法與基線標準二元分類模型。因此，所提出的方法提供了一個全面的架構來解決網路攻擊知識圖完成的挑戰。

##### **Konstruktor: A Strong Baseline for Simple Knowledge Graph Question Answering**
2409.15902v1 by Maria Lysyuk, Mikhail Salnikov, Pavel Braslavski, Alexander Panchenko

While being one of the most popular question types, simple questions such as
"Who is the author of Cinderella?", are still not completely solved.
Surprisingly, even the most powerful modern Large Language Models are prone to
errors when dealing with such questions, especially when dealing with rare
entities. At the same time, as an answer may be one hop away from the question
entity, one can try to develop a method that uses structured knowledge graphs
(KGs) to answer such questions. In this paper, we introduce Konstruktor - an
efficient and robust approach that breaks down the problem into three steps:
(i) entity extraction and entity linking, (ii) relation prediction, and (iii)
querying the knowledge graph. Our approach integrates language models and
knowledge graphs, exploiting the power of the former and the interpretability
of the latter. We experiment with two named entity recognition and entity
linking methods and several relation detection techniques. We show that for
relation detection, the most challenging step of the workflow, a combination of
relation classification/generation and ranking outperforms other methods. We
report Konstruktor's strong results on four datasets.

摘要：儘管是最常見的問題類型之一，但諸如「灰姑娘的作者是誰？」這類簡單的問題仍未完全獲得解答。令人驚訝的是，即使是最強大的現代大型語言模型在處理此類問題時也容易出錯，特別是在處理罕見實體時。與此同時，由於答案可能距離問題實體僅一步之遙，因此可以嘗試開發一種使用結構化知識圖譜 (KG) 來回答此類問題的方法。在本文中，我們介紹 Konstruktor - 一種高效且強大的方法，它將問題分解為三個步驟：(i) 實體萃取和實體連結、(ii) 關係預測以及 (iii) 查詢知識圖譜。我們的做法整合了語言模型和知識圖譜，發揮了前者的能力和後者的可解釋性。我們實驗了兩種命名實體識別和實體連結方法以及多種關係偵測技術。我們表明，對於關係偵測，也就是工作流程中最具挑戰性的步驟，關係分類/生成和排名相結合的組合優於其他方法。我們報告了 Konstruktor 在四個資料集上的強勁成果。

##### **Symmetries and Expressive Requirements for Learning General Policies**
2409.15892v1 by Dominik Drexler, Simon Ståhlberg, Blai Bonet, Hector Geffner

State symmetries play an important role in planning and generalized planning.
In the first case, state symmetries can be used to reduce the size of the
search; in the second, to reduce the size of the training set. In the case of
general planning, however, it is also critical to distinguish non-symmetric
states, i.e., states that represent non-isomorphic relational structures.
However, while the language of first-order logic distinguishes non-symmetric
states, the languages and architectures used to represent and learn general
policies do not. In particular, recent approaches for learning general policies
use state features derived from description logics or learned via graph neural
networks (GNNs) that are known to be limited by the expressive power of C_2,
first-order logic with two variables and counting. In this work, we address the
problem of detecting symmetries in planning and generalized planning and use
the results to assess the expressive requirements for learning general policies
over various planning domains. For this, we map planning states to plain
graphs, run off-the-shelf algorithms to determine whether two states are
isomorphic with respect to the goal, and run coloring algorithms to determine
if C_2 features computed logically or via GNNs distinguish non-isomorphic
states. Symmetry detection results in more effective learning, while the
failure to detect non-symmetries prevents general policies from being learned
at all in certain domains.

摘要：狀態對稱性在規劃和廣義規劃中扮演著重要的角色。
在第一種情況中，狀態對稱性可用於縮小搜尋的規模；在第二種情況中，可用於縮小訓練集的規模。然而，在廣義規劃的情況中，區分非對稱狀態（即表示非同構關係結構的狀態）也很重要。然而，雖然一階邏輯的語言區分了非對稱狀態，但用於表示和學習一般策略的語言和架構卻沒有。特別是，最近用於學習一般策略的方法使用從描述邏輯中衍生的狀態特徵，或通過圖神經網路 (GNN) 學習，已知這些特徵受到具有兩個變數和計數的一階邏輯 C_2 的表達能力限制。在這項工作中，我們解決了在規劃和廣義規劃中檢測對稱性的問題，並使用結果評估在各種規劃領域中學習一般策略的表達需求。為此，我們將規劃狀態映射到平面圖形，執行現成的演算法來確定兩個狀態是否相對於目標同構，並執行著色演算法來確定透過邏輯或 GNN 計算的 C_2 特徵是否區分非同構狀態。對稱性檢測會帶來更有效的學習，而無法檢測非對稱性則會完全阻止在某些領域中學習一般策略。

##### **GEM-RAG: Graphical Eigen Memories For Retrieval Augmented Generation**
2409.15566v1 by Brendan Hogan Rappazzo, Yingheng Wang, Aaron Ferber, Carla Gomes

The ability to form, retrieve, and reason about memories in response to
stimuli serves as the cornerstone for general intelligence - shaping entities
capable of learning, adaptation, and intuitive insight. Large Language Models
(LLMs) have proven their ability, given the proper memories or context, to
reason and respond meaningfully to stimuli. However, they are still unable to
optimally encode, store, and retrieve memories - the ability to do this would
unlock their full ability to operate as AI agents, and to specialize to niche
domains. To remedy this, one promising area of research is Retrieval Augmented
Generation (RAG), which aims to augment LLMs by providing them with rich
in-context examples and information. In question-answering (QA) applications,
RAG methods embed the text of interest in chunks, and retrieve the most
relevant chunks for a prompt using text embeddings. Motivated by human memory
encoding and retrieval, we aim to improve over standard RAG methods by
generating and encoding higher-level information and tagging the chunks by
their utility to answer questions. We introduce Graphical Eigen Memories For
Retrieval Augmented Generation (GEM-RAG). GEM-RAG works by tagging each chunk
of text in a given text corpus with LLM generated ``utility'' questions,
connecting chunks in a graph based on the similarity of both their text and
utility questions, and then using the eigendecomposition of the memory graph to
build higher level summary nodes that capture the main themes of the text. We
evaluate GEM-RAG, using both UnifiedQA and GPT-3.5 Turbo as the LLMs, with
SBERT, and OpenAI's text encoders on two standard QA tasks, showing that
GEM-RAG outperforms other state-of-the-art RAG methods on these tasks. We also
discuss the implications of having a robust RAG system and future directions.

摘要：<paragraph>根據刺激形成、檢索和推理記憶的能力是通用智慧的基石，塑造了具備學習、適應和直覺洞察力的實體。大型語言模型 (LLM) 已證明其能力，在適當的記憶或背景下，對刺激進行推理和有意義地回應。然而，它們仍然無法最佳地編碼、儲存和檢索記憶，執行此操作的能力將解鎖它們作為 AI 代理運作並專門化為利基領域的全部能力。為了補救此問題，一個有前景的研究領域是檢索增強生成 (RAG)，其目標是透過提供豐富的上下文範例和資訊來擴充 LLM。在問答 (QA) 應用程式中，RAG 方法將感興趣的文字分塊嵌入，並使用文字嵌入為提示檢索最相關的區塊。受人類記憶編碼和檢索的啟發，我們旨在透過產生和編碼更高級別的資訊並根據區塊回答問題的效用標記區塊，從而改進標準 RAG 方法。我們引入了用於檢索增強生成的圖形特徵記憶 (GEM-RAG)。GEM-RAG 的工作原理是使用 LLM 生成的「效用」問題標記給定文字語料庫中每個文字區塊，根據文字和效用問題的相似性將區塊連接在圖形中，然後使用記憶圖形的特徵分解來建立擷取文字主題的高階摘要節點。我們使用 UnifiedQA 和 GPT-3.5 Turbo 作為 LLM，以及 SBERT 和 OpenAI 的文字編碼器，在兩個標準 QA 任務中評估 GEM-RAG，顯示 GEM-RAG 在這些任務中優於其他最先進的 RAG 方法。我們還討論了擁有強大的 RAG 系統的含意和未來的方向。</paragraph>

##### **KARMA: Augmenting Embodied AI Agents with Long-and-short Term Memory Systems**
2409.14908v1 by Zixuan Wang, Bo Yu, Junzhe Zhao, Wenhao Sun, Sai Hou, Shuai Liang, Xing Hu, Yinhe Han, Yiming Gan

Embodied AI agents responsible for executing interconnected, long-sequence
household tasks often face difficulties with in-context memory, leading to
inefficiencies and errors in task execution. To address this issue, we
introduce KARMA, an innovative memory system that integrates long-term and
short-term memory modules, enhancing large language models (LLMs) for planning
in embodied agents through memory-augmented prompting. KARMA distinguishes
between long-term and short-term memory, with long-term memory capturing
comprehensive 3D scene graphs as representations of the environment, while
short-term memory dynamically records changes in objects' positions and states.
This dual-memory structure allows agents to retrieve relevant past scene
experiences, thereby improving the accuracy and efficiency of task planning.
Short-term memory employs strategies for effective and adaptive memory
replacement, ensuring the retention of critical information while discarding
less pertinent data. Compared to state-of-the-art embodied agents enhanced with
memory, our memory-augmented embodied AI agent improves success rates by 1.3x
and 2.3x in Composite Tasks and Complex Tasks within the AI2-THOR simulator,
respectively, and enhances task execution efficiency by 3.4x and 62.7x.
Furthermore, we demonstrate that KARMA's plug-and-play capability allows for
seamless deployment on real-world robotic systems, such as mobile manipulation
platforms.Through this plug-and-play memory system, KARMA significantly
enhances the ability of embodied agents to generate coherent and contextually
appropriate plans, making the execution of complex household tasks more
efficient. The experimental videos from the work can be found at
https://youtu.be/4BT7fnw9ehs.

摘要：負責執行相互連接的長序列家庭任務的具身化 AI 代理經常面臨情境記憶的困難，導致任務執行效率低下和錯誤。為了解決這個問題，我們引入了 KARMA，這是一個創新的記憶系統，它整合了長期和短期記憶模組，透過記憶增強提示，增強具身化代理中用於規劃的大語言模型 (LLM)。KARMA 區分長期和短期記憶，長期記憶擷取全面的 3D 場景圖形作為環境的表示，而短期記憶則動態記錄物件位置和狀態的變化。這種雙重記憶結構允許代理擷取相關的過去場景經驗，從而提高任務規劃的準確性和效率。短期記憶採用策略來進行有效和適應性的記憶替換，確保保留關鍵資訊，同時捨棄較不相關的資料。與具備增強記憶功能的最新具身化代理相比，我們的記憶增強具身化 AI 代理在 AI2-THOR 模擬器中的複合任務和複雜任務中，分別將成功率提高了 1.3 倍和 2.3 倍，並將任務執行效率提高了 3.4 倍和 62.7 倍。此外，我們證明了 KARMA 的即插即用功能允許在真實世界的機器人系統上進行無縫部署，例如行動操作平台。透過這個即插即用記憶系統，KARMA 大幅增強了具身化代理產生一致且符合情境的計畫的能力，使複雜家庭任務的執行更有效率。這項工作的實驗影片可以在 https://youtu.be/4BT7fnw9ehs 找到。

##### **End-to-End Graph Flattening Method for Large Language Models**
2409.14880v1 by Bin Hong, Jinze Wu, Jiayu Liu, Liang Ding, Jing Sha, Kai Zhang, Shijin Wang, Zhenya Huang

In recent years, the breakthrough of Large Language Models (LLMs) offers new
ideas for achieving universal methods on graph data. The common practice of
converting graphs into natural language for LLMs, which refers to graph
flattening, exhibits good generalizability and interpretability. However, the
poor organization of the textual format results in poor performance in
long-distance scenario understanding. Inspired by human cognitive reasoning
habits, we propose a novel method for graph flattening to fit LLMs, termed as
End-to-End DAG-Path prompting (EEDP). Experiments on real-world datasets show
that EEDP enhances the reasoning performance of LLMs in long-distance scenarios
while maintaining excellent performance in short-distance scenarios,
demonstrating good robustness in the face of distance variations.

摘要：近年來，大型語言模型 (LLM) 的突破為在圖形資料中達成通用方法提供了新想法。將圖形轉換為自然語言以供 LLM 使用的常見做法，即圖形扁平化，展現出良好的通用性和可解釋性。然而，文本格式組織不佳導致在長距離場景理解中表現不佳。受到人類認知推理習慣的啟發，我們提出了一種新穎的方法來進行圖形扁平化以配合 LLM，稱為端到端 DAG 路徑提示 (EEDP)。在真實世界資料集上的實驗表明，EEDP 增強了 LLM 在長距離場景中的推理性能，同時在短距離場景中保持了出色的性能，在面對距離變化時表現出良好的魯棒性。

##### **RACOON: An LLM-based Framework for Retrieval-Augmented Column Type Annotation with a Knowledge Graph**
2409.14556v1 by Linxi Wei, Guorui Xiao, Magdalena Balazinska

As an important component of data exploration and integration, Column Type
Annotation (CTA) aims to label columns of a table with one or more semantic
types. With the recent development of Large Language Models (LLMs), researchers
have started to explore the possibility of using LLMs for CTA, leveraging their
strong zero-shot capabilities. In this paper, we build on this promising work
and improve on LLM-based methods for CTA by showing how to use a Knowledge
Graph (KG) to augment the context information provided to the LLM. Our
approach, called RACOON, combines both pre-trained parametric and
non-parametric knowledge during generation to improve LLMs' performance on CTA.
Our experiments show that RACOON achieves up to a 0.21 micro F-1 improvement
compared against vanilla LLM inference.

摘要：作為資料探勘與整合的重要組成部分，欄位類型註解 (CTA) 的目標是使用一個或多個語意類型標記表格欄位。隨著大型語言模型 (LLM) 的近期發展，研究人員已開始探討使用 LLM 來進行 CTA 的可能性，並利用其強大的零次學習能力。在本文中，我們建立在這個有前景的研究上，並透過展示如何使用知識圖譜 (KG) 來擴充提供給 LLM 的脈絡資訊，進而改善基於 LLM 的 CTA 方法。我們的方法稱為 RACOON，它在生成過程中結合預先訓練的參數式和非參數式知識，以改善 LLM 在 CTA 上的效能。我們的實驗顯示，與純粹的 LLM 推論相比，RACOON 在微型 F-1 上的進步高達 0.21。

##### **Graph Neural Network Framework for Sentiment Analysis Using Syntactic Feature**
2409.14000v1 by Linxiao Wu, Yuanshuai Luo, Binrong Zhu, Guiran Liu, Rui Wang, Qian Yu

Amidst the swift evolution of social media platforms and e-commerce
ecosystems, the domain of opinion mining has surged as a pivotal area of
exploration within natural language processing. A specialized segment within
this field focuses on extracting nuanced evaluations tied to particular
elements within textual contexts. This research advances a composite framework
that amalgamates the positional cues of topical descriptors. The proposed
system converts syntactic structures into a matrix format, leveraging
convolutions and attention mechanisms within a graph to distill salient
characteristics. Incorporating the positional relevance of descriptors relative
to lexical items enhances the sequential integrity of the input. Trials have
substantiated that this integrated graph-centric scheme markedly elevates the
efficacy of evaluative categorization, showcasing preeminence.

摘要：隨著社群媒體平台和電子商務生態系統的快速演進，意見探勘領域已成為自然語言處理中一項關鍵的探索領域。此領域中的專門區塊著重於從文字脈絡中的特定元素中萃取出細微的評價。本研究提出一個複合架構，將主題描述詞的位置線索合併在一起。所提出的系統將句法結構轉換成矩陣格式，並在圖形中運用卷積和注意力機制來萃取出顯著特徵。納入描述詞相對於詞彙項目的位置相關性，可強化輸入的順序完整性。試驗證實，這種整合圖形為中心的架構顯著提升了評估分類的效能，展現出卓越性。

##### **ShizishanGPT: An Agricultural Large Language Model Integrating Tools and Resources**
2409.13537v1 by Shuting Yang, Zehui Liu, Wolfgang Mayer

Recent developments in large language models (LLMs) have led to significant
improvements in intelligent dialogue systems'ability to handle complex
inquiries. However, current LLMs still exhibit limitations in specialized
domain knowledge, particularly in technical fields such as agriculture. To
address this problem, we propose ShizishanGPT, an intelligent question
answering system for agriculture based on the Retrieval Augmented Generation
(RAG) framework and agent architecture. ShizishanGPT consists of five key
modules: including a generic GPT-4 based module for answering general
questions; a search engine module that compensates for the problem that the
large language model's own knowledge cannot be updated in a timely manner; an
agricultural knowledge graph module for providing domain facts; a retrieval
module which uses RAG to supplement domain knowledge; and an agricultural agent
module, which invokes specialized models for crop phenotype prediction, gene
expression analysis, and so on. We evaluated the ShizishanGPT using a dataset
containing 100 agricultural questions specially designed for this study. The
experimental results show that the tool significantly outperforms general LLMs
as it provides more accurate and detailed answers due to its modular design and
integration of different domain knowledge sources. Our source code, dataset,
and model weights are publicly available at https://github.com/Zaiwen/CropGPT.

摘要：近來大型語言模型（LLM）的發展，大幅提升了智慧對話系統處理複雜詢問的能力。然而，現有的 LLM 仍展現出在專業領域知識的限制，特別是在農業等技術領域。為了解決這個問題，我們提出 ShizishanGPT，一個基於檢索擴充生成（RAG）架構和代理架構的農業智慧問答系統。ShizishanGPT 包含五個關鍵模組：包含一個用於回答一般問題的通用 GPT-4 基礎模組；一個搜尋引擎模組，用於彌補大型語言模型本身的知識無法及時更新的問題；一個農業知識圖譜模組，用於提供領域事實；一個使用 RAG 來補充領域知識的檢索模組；以及一個農業代理模組，用於呼叫用於作物表型預測、基因表現分析等的專業模型。我們使用一個特別為這項研究設計的，包含 100 個農業問題的資料集來評估 ShizishanGPT。實驗結果顯示，由於其模組化設計和整合了不同的領域知識來源，此工具顯著優於一般的 LLM，因為它提供了更準確且詳細的答案。我們的原始碼、資料集和模型權重已公開於 https://github.com/Zaiwen/CropGPT。

##### **LM-assisted keyword biasing with Aho-Corasick algorithm for Transducer-based ASR**
2409.13514v1 by Iuliia Thorbecke, Juan Zuluaga-Gomez, Esaú Villatoro-Tello, Andres Carofilis, Shashi Kumar, Petr Motlicek, Karthik Pandia, Aravind Ganapathiraju

Despite the recent success of end-to-end models for automatic speech
recognition, recognizing special rare and out-of-vocabulary words, as well as
fast domain adaptation with text, are still challenging. It often happens that
biasing to the special entities leads to a degradation in the overall
performance. We propose a light on-the-fly method to improve automatic speech
recognition performance by combining a bias list of named entities with a
word-level n-gram language model with the shallow fusion approach based on the
Aho-Corasick string matching algorithm. The Aho-Corasick algorithm has proved
to be more efficient than other methods and allows fast context adaptation. An
n-gram language model is introduced as a graph with fail and output arcs, where
the arc weights are adapted from the n-gram probabilities. The language model
is used as an additional support to keyword biasing when the language model is
combined with bias entities in a single context graph to take care of the
overall performance. We demonstrate our findings on 4 languages, 2 public and 1
private datasets including performance on named entities and out-of-vocabulary
entities. We achieve up to 21.6% relative improvement in the general word error
rate with no practical difference in the inverse real-time factor.

摘要：儘管端對端模型在自動語音辨識上獲得近期成功，辨識特殊罕見且不在詞彙表中的字詞，以及透過文字進行快速領域適應，仍具有挑戰性。偏向特殊實體經常導致整體效能降低。我們提出一個即時輕量方法，透過將命名實體的偏差清單，與基於 Aho-Corasick 字串配對演算法的淺層融合方法，結合字元等級 n-gram 語言模型，來改善自動語音辨識效能。Aho-Corasick 演算法已被證明比其他方法更有效率，並允許快速脈絡適應。n-gram 語言模型被引入為具有失敗與輸出弧線的圖形，其中弧線權重從 n-gram 機率改編而來。語言模型用作關鍵字偏差的額外支援，當語言模型與偏差實體結合在單一脈絡圖形中時，用於照顧整體效能。我們在 4 種語言、2 個公開和 1 個私人資料集上展示我們的發現，包括命名實體和不在詞彙表中的實體的效能。我們在一般字元錯誤率上獲得高達 21.6% 的相對改善，且在反向即時因子中沒有實際差異。

##### **AQA: Adaptive Question Answering in a Society of LLMs via Contextual Multi-Armed Bandit**
2409.13447v2 by Mohanna Hoveyda, Arjen P. de Vries, Maarten de Rijke, Harrie Oosterhuis, Faegheh Hasibi

In question answering (QA), different questions can be effectively addressed
with different answering strategies. Some require a simple lookup, while others
need complex, multi-step reasoning to be answered adequately. This observation
motivates the development of a dynamic method that adaptively selects the most
suitable QA strategy for each question, enabling more efficient and effective
systems capable of addressing a broader range of question types. To this aim,
we build on recent advances in the orchestration of multiple large language
models (LLMs) and formulate adaptive QA as a dynamic orchestration challenge.
We define this as a contextual multi-armed bandit problem, where the context is
defined by the characteristics of the incoming question and the action space
consists of potential communication graph configurations among the LLM agents.
We then train a linear upper confidence bound model to learn an optimal mapping
between different question types and their corresponding optimal multi-LLM
communication graph representation. Our experiments show that the proposed
solution is viable for adaptive orchestration of a QA system with multiple
modules, as it combines the superior performance of more complex strategies
while avoiding their costs when simpler strategies suffice.

摘要：在問答 (QA) 中，不同的問題可以用不同的回答策略有效地解決。有些問題只需要簡單的查詢，而另一些問題則需要複雜的多步驟推理才能得到充分的回答。這個觀察促使開發一種動態方法，能適應性地為每個問題選擇最合適的 QA 策略，從而實現更高效且有效的系統，能解決更廣泛的類型問題。為此，我們建立在多個大型語言模型 (LLM) 編排的最新進展之上，並將適應性 QA 制定為一個動態編排挑戰。我們將其定義為一個情境多重選擇問題，其中情境由輸入問題的特徵定義，而動作空間由 LLM 代理之間的潛在通信圖形配置組成。然後，我們訓練一個線性上限置信界模型，以學習不同問題類型及其對應的最佳多 LLM 通信圖形表示之間的最佳映射。我們的實驗表明，所提出的解決方案適用於具有多個模組的 QA 系統的適應性編排，因為它結合了更複雜策略的優越效能，同時在較簡單的策略足夠時避免了其成本。

##### **GAProtoNet: A Multi-head Graph Attention-based Prototypical Network for Interpretable Text Classification**
2409.13312v1 by Ximing Wen, Wenjuan Tan, Rosina O. Weber

Pretrained transformer-based Language Models (LMs) are well-known for their
ability to achieve significant improvement on text classification tasks with
their powerful word embeddings, but their black-box nature, which leads to a
lack of interpretability, has been a major concern. In this work, we introduce
GAProtoNet, a novel white-box Multi-head Graph Attention-based Prototypical
Network designed to explain the decisions of text classification models built
with LM encoders. In our approach, the input vector and prototypes are regarded
as nodes within a graph, and we utilize multi-head graph attention to
selectively construct edges between the input node and prototype nodes to learn
an interpretable prototypical representation. During inference, the model makes
decisions based on a linear combination of activated prototypes weighted by the
attention score assigned for each prototype, allowing its choices to be
transparently explained by the attention weights and the prototypes projected
into the closest matching training examples. Experiments on multiple public
datasets show our approach achieves superior results without sacrificing the
accuracy of the original black-box LMs. We also compare with four alternative
prototypical network variations and our approach achieves the best accuracy and
F1 among all. Our case study and visualization of prototype clusters also
demonstrate the efficiency in explaining the decisions of black-box models
built with LMs.

摘要：預訓練的 Transformer 基於語言模型 (LM) 以其強大的詞嵌入功能而聞名，能夠在文本分類任務中獲得顯著的改進，但其黑盒性質導致缺乏可解釋性，一直是一個主要問題。在這項工作中，我們引入了 GAProtoNet，這是一個新穎的白盒多頭圖注意力原型網路，旨在解釋使用 LM 編碼器建立的文本分類模型的決策。在我們的做法中，輸入向量和原型被視為圖形中的節點，我們利用多頭圖注意力在輸入節點和原型節點之間有選擇地構造邊緣，以學習可解釋的原型表示。在推理過程中，模型根據激活原型的線性組合做出決策，該組合由分配給每個原型的注意力分數加權，從而允許通過注意力權重和投影到最接近匹配訓練範例的原型來透明地解釋其選擇。在多個公共資料集上的實驗表明，我們的做法在不犧牲原始黑盒 LM 的準確性的情況下，取得了優異的結果。我們還與四種替代原型網路變體進行了比較，我們的做法在所有變體中取得了最佳的準確性和 F1。我們的案例研究和原型群集的可視化也證明了使用 LM 建立的黑盒模型決策的解釋效率。

##### **Leveraging Knowledge Graphs and LLMs to Support and Monitor Legislative Systems**
2409.13252v1 by Andrea Colombo

Knowledge Graphs (KGs) have been used to organize large datasets into
structured, interconnected information, enhancing data analytics across various
fields. In the legislative context, one potential natural application of KGs is
modeling the intricate set of interconnections that link laws and their
articles with each other and the broader legislative context.
  At the same time, the rise of large language models (LLMs) such as GPT has
opened new opportunities in legal applications, such as text generation and
document drafting. Despite their potential, the use of LLMs in legislative
contexts is critical since it requires the absence of hallucinations and
reliance on up-to-date information, as new laws are published on a daily basis.
  This work investigates how Legislative Knowledge Graphs and LLMs can
synergize and support legislative processes. We address three key questions:
the benefits of using KGs for legislative systems, how LLM can support
legislative activities by ensuring an accurate output, and how we can allow
non-technical users to use such technologies in their activities. To this aim,
we develop Legis AI Platform, an interactive platform focused on Italian
legislation that enhances the possibility of conducting legislative analysis
and that aims to support lawmaking activities.

摘要：知識圖譜 (KG) 已被用於將大型資料集整理成結構化、相互關聯的資訊，以增強各種領域的資料分析。在立法背景下，KG 的一個潛在自然應用是建模連結法律及其條文彼此之間以及更廣泛立法背景的複雜相互連結集。
與此同時，大型語言模型 (LLM)（例如 GPT）的興起為法律應用開闢了新的機會，例如文字產生和文件起草。儘管有其潛力，在立法背景下使用 LLM 至關重要，因為它需要沒有幻覺並且依賴於最新的資訊，因為每天都會公佈新的法律。
這項工作探討了立法知識圖譜和 LLM 如何產生協同效應並支援立法程序。我們探討了三個關鍵問題：使用 KG 對立法系統的好處、LLM 如何透過確保準確的輸出支援立法活動，以及我們如何讓非技術使用者在他們的活動中使用這些技術。為此，我們開發了 Legis AI Platform，這是一個專注於義大利立法的互動式平台，可增強進行立法分析的可能性，並旨在支援立法活動。

##### **Knowledge-Based Domain-Oriented Data Augmentation for Enhancing Unsupervised Sentence Embedding**
2409.12887v1 by Peichao Lai, Zhengfeng Zhang, Bin Cui

Recently, unsupervised sentence embedding models have received significant
attention in downstream natural language processing tasks. Using large language
models (LLMs) for data augmentation has led to considerable improvements in
previous studies. Nevertheless, these strategies emphasize data augmentation
with extensive generic corpora, neglecting the consideration of few-shot domain
data. The synthesized data lacks fine-grained information and may introduce
negative sample noise. This study introduces a novel pipeline-based data
augmentation method that leverages LLM to synthesize the domain-specific
dataset. It produces both positive and negative samples through entity- and
quantity-aware augmentation, utilizing an entity knowledge graph to synthesize
samples with fine-grained semantic distinctions, increasing training sample
diversity and relevance. We then present a Gaussian-decayed gradient-assisted
Contrastive Sentence Embedding (GCSE) model to reduce synthetic data noise and
improve model discrimination to reduce negative sample noise. Experimental
results demonstrate that our approach achieves state-of-the-art semantic
textual similarity performance with fewer synthetic data samples and lesser LLM
parameters, demonstrating its efficiency and robustness in varied backbones.

摘要：近来，无监督句子嵌入模型在自然语言处理的下游任务中受到广泛关注。在先前研究中，使用大型语言模型（LLM）进行数据扩充已带来显著的改进。然而，这些策略强调使用广泛的通用语料库进行数据扩充，忽略了对少量领域数据的考量。合成的资料缺乏细粒度信息，并可能引入负面样本噪声。本研究提出了一种新颖的基于管道的数据扩充方法，该方法利用 LLM 来合成特定于领域的资料集。它通过实体和数量感知扩充产生正面和负面样本，利用实体知识图谱来合成具有细粒度语义区别的样本，增加训练样本的多样性和相关性。然后，我们提出了一个高斯衰减梯度辅助对比句子嵌入（GCSE）模型，以减少合成数据噪声，并提高模型判别能力，以减少负面样本噪声。实验结果表明，我们的方法以更少的合成数据样本和更少的 LLM 参数实现了最先进的语义文本相似性性能，证明了其在各种骨干网中的效率和鲁棒性。

##### **KnowFormer: Revisiting Transformers for Knowledge Graph Reasoning**
2409.12865v1 by Junnan Liu, Qianren Mao, Weifeng Jiang, Jianxin Li

Knowledge graph reasoning plays a vital role in various applications and has
garnered considerable attention. Recently, path-based methods have achieved
impressive performance. However, they may face limitations stemming from
constraints in message-passing neural networks, such as missing paths and
information over-squashing. In this paper, we revisit the application of
transformers for knowledge graph reasoning to address the constraints faced by
path-based methods and propose a novel method KnowFormer.KnowFormer utilizes a
transformer architecture to perform reasoning on knowledge graphs from the
message-passing perspective, rather than reasoning by textual information like
previous pretrained language model based methods. Specifically, we define the
attention computation based on the query prototype of knowledge graph
reasoning, facilitating convenient construction and efficient optimization. To
incorporate structural information into the self-attention mechanism, we
introduce structure-aware modules to calculate query, key, and value
respectively. Additionally, we present an efficient attention computation
method for better scalability. Experimental results demonstrate the superior
performance of KnowFormer compared to prominent baseline methods on both
transductive and inductive benchmarks.

摘要：知識圖譜推理在各種應用中扮演著至關重要的角色，並已獲得相當大的關注。最近，基於路徑的方法已取得令人印象深刻的表現。然而，它們可能會面臨源自訊息傳遞神經網路中的限制，例如路徑遺失和資訊過度壓縮。在本文中，我們重新探討Transformer在知識圖譜推理中的應用，以解決基於路徑的方法所面臨的限制，並提出一個新穎的方法 KnowFormer。KnowFormer 利用Transformer架構從訊息傳遞的角度對知識圖譜執行推理，而不是像之前的預訓練語言模型所依賴的文本資訊那樣進行推理。具體來說，我們根據知識圖譜推理的查詢原型定義注意力的運算，促進便利的建構和有效的最佳化。為了將結構資訊納入自注意力機制，我們引入結構感知模組來分別計算查詢、鍵和值。此外，我們提出一個有效率的注意力運算方法以獲得更好的可擴充性。實驗結果證明，KnowFormer 在轉導和歸納基準上都優於傑出的基線方法。

##### **A New Perspective on ADHD Research: Knowledge Graph Construction with LLMs and Network Based Insights**
2409.12853v1 by Hakan T. Otal, Stephen V. Faraone, M. Abdullah Canbaz

Attention-Deficit/Hyperactivity Disorder (ADHD) is a challenging disorder to
study due to its complex symptomatology and diverse contributing factors. To
explore how we can gain deeper insights on this topic, we performed a network
analysis on a comprehensive knowledge graph (KG) of ADHD, constructed by
integrating scientific literature and clinical data with the help of
cutting-edge large language models. The analysis, including k-core techniques,
identified critical nodes and relationships that are central to understanding
the disorder. Building on these findings, we developed a context-aware chatbot
using Large Language Models (LLMs) and Retrieval-Augmented Generation (RAG),
enabling accurate and informed interactions. Our knowledge graph not only
advances the understanding of ADHD but also provides a powerful tool for
research and clinical applications.

摘要：注意力缺陷過動症 (ADHD) 是一種具有挑戰性的疾病，由於其複雜的症狀和多樣化的成因。為了探討如何深入了解這個主題，我們對一個由科學文獻和臨床數據整合而成的 ADHD 全面知識圖譜 (KG) 進行了網路分析，並借助尖端的語言模型。分析，包括 k-core 技術，識別出對於理解此疾病至關重要的關鍵節點和關係。根據這些發現，我們使用大型語言模型 (LLM) 和檢索增強生成 (RAG) 開發了一個具備情境感知能力的聊天機器人，以實現準確且有根據的互動。我們的知識圖譜不僅促進了對 ADHD 的理解，還為研究和臨床應用提供了強大的工具。

##### **Enhancing Logical Reasoning in Large Language Models through Graph-based Synthetic Data**
2409.12437v1 by Jiaming Zhou, Abbas Ghaddar, Ge Zhang, Liheng Ma, Yaochen Hu, Soumyasundar Pal, Mark Coates, Bin Wang, Yingxue Zhang, Jianye Hao

Despite recent advances in training and prompting strategies for Large
Language Models (LLMs), these models continue to face challenges with complex
logical reasoning tasks that involve long reasoning chains. In this work, we
explore the potential and limitations of using graph-based synthetic reasoning
data as training signals to enhance LLMs' reasoning capabilities. Our extensive
experiments, conducted on two established natural language reasoning tasks --
inductive reasoning and spatial reasoning -- demonstrate that supervised
fine-tuning (SFT) with synthetic graph-based reasoning data effectively
enhances LLMs' reasoning performance without compromising their effectiveness
on other standard evaluation benchmarks.

摘要：儘管在大型語言模型 (LLM) 的訓練和提示策略方面有近期的進展，這些模型在涉及長推理鏈的複雜邏輯推理任務中仍面臨挑戰。在這項工作中，我們探討了使用基於圖形的合成推理數據作為訓練訊號以增強 LLM 推理能力的潛力和限制。我們在兩個既定的自然語言推理任務（歸納推理和空間推理）上進行了廣泛的實驗，證明了使用基於圖形的合成推理數據進行監督微調 (SFT) 有效地增強了 LLM 的推理性能，而不會損害其在其他標準評估基準上的效能。

##### **Textualized Agent-Style Reasoning for Complex Tasks by Multiple Round LLM Generation**
2409.12411v1 by Chen Liang, Zhifan Feng, Zihe Liu, Wenbin Jiang, Jinan Xu, Yufeng Chen, Yong Wang

Chain-of-thought prompting significantly boosts the reasoning ability of
large language models but still faces three issues: hallucination problem,
restricted interpretability, and uncontrollable generation. To address these
challenges, we present AgentCOT, a llm-based autonomous agent framework, which
can solve complex problems in an agent-style manner by multiple round LLM
generation. At each step, AgentCOT selects an action and executes it to yield
an intermediate result with supporting evidence. In addition, we integrate the
step's index into the reasoning process to form a graph structure for complex
inference logic. We introduce two new strategies to enhance the performance of
AgentCOT.We conduct extensive experiments to verify the effectiveness of our
method on six common benchmarks. Results exhibit that our method brings in
substantial improvements over current competitive approaches.

摘要：鏈條思考提示顯著提升大型語言模型的推理能力，但仍面臨三個問題：幻覺問題、受限的可解釋性，以及無法控制的生成。為了應對這些挑戰，我們提出了 AgentCOT，一個基於 llm 的自主代理架構，它可以通過多輪 LLM 生成以代理樣式解決複雜問題。在每一步中，AgentCOT 選擇一個動作並執行它，以產生一個具有支持證據的中間結果。此外，我們將步驟索引整合到推理過程中，以形成一個圖形結構，用於複雜的推理邏輯。我們引入了兩種新策略來增強 AgentCOT 的性能。我們進行了廣泛的實驗，以驗證我們的方法在六個常見基準上的有效性。結果表明，我們的的方法比當前的競爭方法有了顯著的改進。

##### **GUNet: A Graph Convolutional Network United Diffusion Model for Stable and Diversity Pose Generation**
2409.11689v1 by Shuowen Liang, Sisi Li, Qingyun Wang, Cen Zhang, Kaiquan Zhu, Tian Yang

Pose skeleton images are an important reference in pose-controllable image
generation. In order to enrich the source of skeleton images, recent works have
investigated the generation of pose skeletons based on natural language. These
methods are based on GANs. However, it remains challenging to perform diverse,
structurally correct and aesthetically pleasing human pose skeleton generation
with various textual inputs. To address this problem, we propose a framework
with GUNet as the main model, PoseDiffusion. It is the first generative
framework based on a diffusion model and also contains a series of variants
fine-tuned based on a stable diffusion model. PoseDiffusion demonstrates
several desired properties that outperform existing methods. 1) Correct
Skeletons. GUNet, a denoising model of PoseDiffusion, is designed to
incorporate graphical convolutional neural networks. It is able to learn the
spatial relationships of the human skeleton by introducing skeletal information
during the training process. 2) Diversity. We decouple the key points of the
skeleton and characterise them separately, and use cross-attention to introduce
textual conditions. Experimental results show that PoseDiffusion outperforms
existing SoTA algorithms in terms of stability and diversity of text-driven
pose skeleton generation. Qualitative analyses further demonstrate its
superiority for controllable generation in Stable Diffusion.

摘要：姿勢骨架圖像是姿勢可控圖像生成中重要的參考。為了豐富骨架圖像的來源，最近的研究調查了基於自然語言的姿勢骨架生成。這些方法基於 GAN。然而，要執行多樣化、結構正確且美觀的人體姿勢骨架生成，並具有各種文本輸入，仍然具有挑戰性。為了解決這個問題，我們提出了以 GUNet 為主要模型的框架，PoseDiffusion。它是基於擴散模型的第一個生成框架，還包含一系列基於穩定擴散模型進行微調的變體。PoseDiffusion 展示了多項優於現有方法的理想屬性。1) 正確的骨架。PoseDiffusion 的去噪模型 GUNet 被設計為結合圖形卷積神經網路。它能夠透過在訓練過程中引入骨架資訊來學習人體骨架的空間關係。2) 多樣性。我們解耦骨架的關鍵點並分別對其進行表徵，並使用交叉注意力來引入文本條件。實驗結果表明，PoseDiffusion 在文本驅動姿勢骨架生成的穩定性和多樣性方面優於現有的 SoTA 演算法。定性分析進一步證明了它在 Stable Diffusion 中可控生成的優越性。

##### **FedNE: Surrogate-Assisted Federated Neighbor Embedding for Dimensionality Reduction**
2409.11509v1 by Ziwei Li, Xiaoqi Wang, Hong-You Chen, Han-Wei Shen, Wei-Lun Chao

Federated learning (FL) has rapidly evolved as a promising paradigm that
enables collaborative model training across distributed participants without
exchanging their local data. Despite its broad applications in fields such as
computer vision, graph learning, and natural language processing, the
development of a data projection model that can be effectively used to
visualize data in the context of FL is crucial yet remains heavily
under-explored. Neighbor embedding (NE) is an essential technique for
visualizing complex high-dimensional data, but collaboratively learning a joint
NE model is difficult. The key challenge lies in the objective function, as
effective visualization algorithms like NE require computing loss functions
among pairs of data. In this paper, we introduce \textsc{FedNE}, a novel
approach that integrates the \textsc{FedAvg} framework with the contrastive NE
technique, without any requirements of shareable data. To address the lack of
inter-client repulsion which is crucial for the alignment in the global
embedding space, we develop a surrogate loss function that each client learns
and shares with each other. Additionally, we propose a data-mixing strategy to
augment the local data, aiming to relax the problems of invisible neighbors and
false neighbors constructed by the local $k$NN graphs. We conduct comprehensive
experiments on both synthetic and real-world datasets. The results demonstrate
that our \textsc{FedNE} can effectively preserve the neighborhood data
structures and enhance the alignment in the global embedding space compared to
several baseline methods.

摘要：聯合式學習 (FL) 已迅速演變為一種有前途的範例，它可以在分布式參與者之間進行協作模型訓練，而無需交換他們的本地數據。儘管它在電腦視覺、圖形學習和自然語言處理等領域有廣泛的應用，但開發一個數據投影模型，可有效用於在 FL 的背景下視覺化數據，這一點至關重要，但仍未得到充分的探索。鄰域嵌入 (NE) 是用於視覺化複雜高維數據的一項基本技術，但協作學習一個聯合 NE 模型很困難。主要的挑戰在於目標函數，因為像 NE 這樣的有效視覺化演算法需要計算數據對之間的損失函數。在本文中，我們介紹了 \textsc{FedNE}，這是一種新穎的方法，它將 \textsc{FedAvg} 框架與對比 NE 技術相整合，而無需任何可共享數據的要求。為了解決對於在全局嵌入空間中對齊至關重要的客戶端間排斥力不足的問題，我們開發了一個代理損失函數，每個客戶端學習此函數並與彼此共享。此外，我們提出了一種數據混合策略來擴充本地數據，旨在緩解由本地 $k$NN 圖形構造的不可見鄰域和錯誤鄰域的問題。我們在合成和真實世界數據集上進行了全面的實驗。結果表明，與幾種基線方法相比，我們的 \textsc{FedNE} 可以有效地保留鄰域數據結構並增強在全局嵌入空間中的對齊。

##### **Reasoning Graph Enhanced Exemplars Retrieval for In-Context Learning**
2409.11147v1 by Yukang Lin, Bingchen Zhong, Shuoran Jiang, Joanna Siebert, Qingcai Chen

Large language models(LLMs) have exhibited remarkable few-shot learning
capabilities and unified the paradigm of NLP tasks through the in-context
learning(ICL) technique. Despite the success of ICL, the quality of the
exemplar demonstrations can significantly influence the LLM's performance.
Existing exemplar selection methods mainly focus on the semantic similarity
between queries and candidate exemplars. On the other hand, the logical
connections between reasoning steps can be beneficial to depict the
problem-solving process as well. In this paper, we proposes a novel method
named Reasoning Graph-enhanced Exemplar Retrieval(RGER). RGER first quires LLM
to generate an initial response, then expresses intermediate problem-solving
steps to a graph structure. After that, it employs graph kernel to select
exemplars with semantic and structural similarity. Extensive experiments
demonstrate the structural relationship is helpful to the alignment of queries
and candidate exemplars. The efficacy of RGER on math and logit reasoning tasks
showcases its superiority over state-of-the-art retrieval-based approaches. Our
code is released at https://github.com/Yukang-Lin/RGER.

摘要：大型語言模型 (LLM) 已展現出卓越的少量學習能力，並透過情境學習 (ICL) 技術統一了 NLP 任務的範例。儘管 ICL 已成功，範例示範的品質會顯著影響 LLM 的效能。現有的範例選擇方法主要著重於查詢與候選範例之間的語意相似性。另一方面，推理步驟之間的邏輯連結有助於描繪問題解決流程。在本文中，我們提出了一種稱為推理圖增強範例檢索 (RGER) 的新方法。RGER 首先要求 LLM 產生一個初始回應，然後將中間問題解決步驟表示為圖形結構。之後，它採用圖形核選取具有語意和結構相似性的範例。廣泛的實驗證明，結構關係有助於查詢和候選範例的對齊。RGER 在數學和邏輯推理任務上的功效展示了它優於最先進的基於檢索的方法。我們的程式碼已發布於 https://github.com/Yukang-Lin/RGER。

##### **Semformer: Transformer Language Models with Semantic Planning**
2409.11143v1 by Yongjing Yin, Junran Ding, Kai Song, Yue Zhang

Next-token prediction serves as the dominant component in current neural
language models. During the training phase, the model employs teacher forcing,
which predicts tokens based on all preceding ground truth tokens. However, this
approach has been found to create shortcuts, utilizing the revealed prefix to
spuriously fit future tokens, potentially compromising the accuracy of the
next-token predictor. In this paper, we introduce Semformer, a novel method of
training a Transformer language model that explicitly models the semantic
planning of response. Specifically, we incorporate a sequence of planning
tokens into the prefix, guiding the planning token representations to predict
the latent semantic representations of the response, which are induced by an
autoencoder. In a minimal planning task (i.e., graph path-finding), our model
exhibits near-perfect performance and effectively mitigates shortcut learning,
a feat that standard training methods and baseline models have been unable to
accomplish. Furthermore, we pretrain Semformer from scratch with 125M
parameters, demonstrating its efficacy through measures of perplexity,
in-context learning, and fine-tuning on summarization tasks.

摘要：在當前的語言模型中，下一個詞彙預測是主導組成部分。在訓練階段，模型採用教師強制法，根據所有前一個的真實詞彙來預測詞彙。然而，發現這種方法會產生捷徑，利用已揭露的前綴來虛假地符合後續的詞彙，潛在會危害下一個詞彙預測器的準確度。在本文中，我們介紹 Semformer，一種訓練 Transformer 語言模型的新方法，明確地建構回應的語意規劃。具體來說，我們將一系列規劃詞彙納入前綴，引導規劃詞彙的表徵去預測回應的潛在語意表徵，這些表徵是由自動編碼器誘導的。在一個最小的規劃任務（即圖形路徑尋找）中，我們的模型表現出接近完美的效能，並有效地減輕捷徑學習，這是標準訓練方法和基線模型無法達成的壯舉。此外，我們從頭開始使用 1.25 億個參數預訓練 Semformer，透過困惑度、語境學習和在摘要任務上的微調來證明其功效。

##### **KALE: An Artwork Image Captioning System Augmented with Heterogeneous Graph**
2409.10921v1 by Yanbei Jiang, Krista A. Ehinger, Jey Han Lau

Exploring the narratives conveyed by fine-art paintings is a challenge in
image captioning, where the goal is to generate descriptions that not only
precisely represent the visual content but also offer a in-depth interpretation
of the artwork's meaning. The task is particularly complex for artwork images
due to their diverse interpretations and varied aesthetic principles across
different artistic schools and styles. In response to this, we present KALE
Knowledge-Augmented vision-Language model for artwork Elaborations), a novel
approach that enhances existing vision-language models by integrating artwork
metadata as additional knowledge. KALE incorporates the metadata in two ways:
firstly as direct textual input, and secondly through a multimodal
heterogeneous knowledge graph. To optimize the learning of graph
representations, we introduce a new cross-modal alignment loss that maximizes
the similarity between the image and its corresponding metadata. Experimental
results demonstrate that KALE achieves strong performance (when evaluated with
CIDEr, in particular) over existing state-of-the-art work across several
artwork datasets. Source code of the project is available at
https://github.com/Yanbei-Jiang/Artwork-Interpretation.

摘要：探索由美术绘画传达的叙事是图像字幕中的挑战，其目标是生成不仅准确地表示视觉内容而且还提供对艺术品含义的深入解释的描述。由于其不同的解释和跨不同艺术流派和风格的不同美学原则，这项任务对于艺术品图像来说尤其复杂。为了应对这种情况，我们提出了 KALE 知识增强视觉语言模型用于艺术品阐释，一种通过将艺术品元数据作为附加知识来增强现有视觉语言模型的新方法。KALE 以两种方式合并元数据：首先作为直接文本输入，其次通过多模态异构知识图。为了优化图表的学习表示，我们引入了一种新的跨模态对齐损失，它最大化图像与其对应元数据之间的相似性。实验结果表明，KALE 在使用 CIDEr 评估时，在几个艺术品数据集上取得了优异的性能（特别是与现有的最先进的工作相比）。该项目的源代码可在 https://github.com/Yanbei-Jiang/Artwork-Interpretation 获得。

##### **A Knowledge-Enhanced Disease Diagnosis Method Based on Prompt Learning and BERT Integration**
2409.10403v1 by Zhang Zheng

This paper proposes a knowledge-enhanced disease diagnosis method based on a
prompt learning framework. The method retrieves structured knowledge from
external knowledge graphs related to clinical cases, encodes it, and injects it
into the prompt templates to enhance the language model's understanding and
reasoning capabilities for the task.We conducted experiments on three public
datasets: CHIP-CTC, IMCS-V2-NER, and KUAKE-QTR. The results show that the
proposed method significantly outperforms existing models across multiple
evaluation metrics, with an F1 score improvement of 2.4% on the CHIP-CTC
dataset, 3.1% on the IMCS-V2-NER dataset,and 4.2% on the KUAKE-QTR dataset.
Additionally,ablation studies confirmed the critical role of the knowledge
injection module,as the removal of this module resulted in a significant drop
in F1 score. The experimental results demonstrate that the proposed method not
only effectively improves the accuracy of disease diagnosis but also enhances
the interpretability of the predictions, providing more reliable support and
evidence for clinical diagnosis.

摘要：本文提出了一种基于提示学习框架的知识增强疾病诊断方法。该方法从与临床病例相关的外部知识图谱中检索结构化知识，对其进行编码，并将其注入到提示模板中，以增强语言模型对任务的理解和推理能力。我们在三个公共数据集上进行了实验：CHIP-CTC、IMCS-V2-NER 和 KUAKE-QTR。结果表明，所提出的方法在多个评估指标上明显优于现有模型，在 CHIP-CTC 数据集上的 F1 得分提高了 2.4%，在 IMCS-V2-NER 数据集上提高了 3.1%，在 KUAKE-QTR 数据集上提高了 4.2%。此外，消融研究证实了知识注入模块的关键作用，因为移除此模块会导致 F1 得分显着下降。实验结果表明，所提出的方法不仅有效提高了疾病诊断的准确性，而且增强了预测的可解释性，为临床诊断提供了更可靠的支持和证据。

##### **MGSA: Multi-Granularity Graph Structure Attention for Knowledge Graph-to-Text Generation**
2409.10294v2 by Shanshan Wang, Chun Zhang, Ning Zhang

The Knowledge Graph-to-Text Generation task aims to convert structured
knowledge graphs into coherent and human-readable natural language text. Recent
efforts in this field have focused on enhancing pre-trained language models
(PLMs) by incorporating graph structure information to capture the intricate
structure details of knowledge graphs. However, most of these approaches tend
to capture only single-granularity structure information, concentrating either
on the relationships between entities within the original graph or on the
relationships between words within the same entity or across different
entities. This narrow focus results in a significant limitation: models that
concentrate solely on entity-level structure fail to capture the nuanced
semantic relationships between words, while those that focus only on word-level
structure overlook the broader relationships between original entire entities.
To overcome these limitations, this paper introduces the Multi-granularity
Graph Structure Attention (MGSA), which is based on PLMs. The encoder of the
model architecture features an entity-level structure encoding module, a
word-level structure encoding module, and an aggregation module that
synthesizes information from both structure. This multi-granularity structure
encoding approach allows the model to simultaneously capture both entity-level
and word-level structure information, providing a more comprehensive
understanding of the knowledge graph's structure information, thereby
significantly improving the quality of the generated text. We conducted
extensive evaluations of the MGSA model using two widely recognized KG-to-Text
Generation benchmark datasets, WebNLG and EventNarrative, where it consistently
outperformed models that rely solely on single-granularity structure
information, demonstrating the effectiveness of our approach.

摘要：知識圖譜轉文字生成任務旨在將結構化的知識圖譜轉換為連貫且人類可讀的自然語言文字。最近在這個領域的努力集中在透過納入圖形結構資訊來增強預先訓練的語言模型 (PLM)，以擷取知識圖譜的複雜結構細節。然而，這些方法中的大多數傾向於僅擷取單一粒度的結構資訊，專注於原始圖形中實體之間的關係或同一個實體或不同實體之間的詞彙關係。這種狹隘的焦點導致了一個重大的限制：僅專注於實體層級結構的模型無法擷取詞彙之間的細微語義關係，而僅專注於詞彙層級結構的模型則忽略了原始整個實體之間的更廣泛關係。為了克服這些限制，本文引入了基於 PLM 的多粒度圖形結構注意力 (MGSA)。模型架構的編碼器具有一個實體層級結構編碼模組、一個詞彙層級結構編碼模組，以及一個從兩個結構中綜合資訊的聚合模組。這種多粒度結構編碼方法允許模型同時擷取實體層級和詞彙層級的結構資訊，提供對知識圖譜結構資訊更全面的理解，從而顯著提升所生成文字的品質。我們使用兩個廣泛認可的 KG 轉文字生成基準資料集 WebNLG 和 EventNarrative 對 MGSA 模型進行了廣泛的評估，它始終優於僅依賴單一粒度結構資訊的模型，證明了我們方法的有效性。

##### **LLM-DER:A Named Entity Recognition Method Based on Large Language Models for Chinese Coal Chemical Domain**
2409.10077v1 by Le Xiao, Yunfei Xu, Jing Zhao

Domain-specific Named Entity Recognition (NER), whose goal is to recognize
domain-specific entities and their categories, provides an important support
for constructing domain knowledge graphs. Currently, deep learning-based
methods are widely used and effective in NER tasks, but due to the reliance on
large-scale labeled data. As a result, the scarcity of labeled data in a
specific domain will limit its application.Therefore, many researches started
to introduce few-shot methods and achieved some results. However, the entity
structures in specific domains are often complex, and the current few-shot
methods are difficult to adapt to NER tasks with complex features.Taking the
Chinese coal chemical industry domain as an example,there exists a complex
structure of multiple entities sharing a single entity, as well as multiple
relationships for the same pair of entities, which affects the NER task under
the sample less condition.In this paper, we propose a Large Language Models
(LLMs)-based entity recognition framework LLM-DER for the domain-specific
entity recognition problem in Chinese, which enriches the entity information by
generating a list of relationships containing entity types through LLMs, and
designing a plausibility and consistency evaluation method to remove
misrecognized entities, which can effectively solve the complex structural
entity recognition problem in a specific domain.The experimental results of
this paper on the Resume dataset and the self-constructed coal chemical dataset
Coal show that LLM-DER performs outstandingly in domain-specific entity
recognition, not only outperforming the existing GPT-3.5-turbo baseline, but
also exceeding the fully-supervised baseline, verifying its effectiveness in
entity recognition.

摘要：<paragraph>領域特定命名實體辨識（NER），其目標是辨識領域特定實體及其類別，為建構領域知識圖譜提供重要的支援。目前，基於深度學習的方法廣泛用於 NER 任務且十分有效，但由於依賴於大規模標記資料。因此，特定領域中標記資料的稀少會限制其應用。因此，許多研究開始引入少量樣本方法並獲得一些成果。然而，特定領域中的實體結構通常很複雜，而目前的少量樣本方法難以適應具有複雜特徵的 NER 任務。以中國煤化工產業領域為例，存在多個實體共用單一實體的複雜結構，以及同一對實體有多重關係，這會影響樣本較少條件下的 NER 任務。在本文中，我們提出了一個基於大型語言模型（LLM）的實體辨識架構 LLM-DER，用於中文領域特定實體辨識問題，通過 LLM 生成包含實體類型的關係清單，並設計一個合理性和一致性評估方法來移除辨識錯誤的實體，從而可以有效解決特定領域中複雜結構實體辨識問題。本文在 Resume 資料集和自建煤化工資料集 Coal 上的實驗結果表明，LLM-DER 在領域特定實體辨識中表現出色，不僅優於現有的 GPT-3.5-turbo 基準，還超過了完全監督的基線，驗證了其在實體辨識中的有效性。</paragraph>

##### **On the Diagram of Thought**
2409.10038v1 by Yifan Zhang, Yang Yuan, Andrew Chi-Chih Yao

We introduce Diagram of Thought (DoT), a framework that models iterative
reasoning in large language models (LLMs) as the construction of a directed
acyclic graph (DAG) within a single model. Unlike traditional approaches that
represent reasoning as linear chains or trees, DoT organizes propositions,
critiques, refinements, and verifications into a cohesive DAG structure,
allowing the model to explore complex reasoning pathways while maintaining
logical consistency. Each node in the diagram corresponds to a proposition that
has been proposed, critiqued, refined, or verified, enabling the LLM to
iteratively improve its reasoning through natural language feedback. By
leveraging auto-regressive next-token prediction with role-specific tokens, DoT
facilitates seamless transitions between proposing ideas and critically
evaluating them, providing richer feedback than binary signals. Furthermore, we
formalize the DoT framework using Topos Theory, providing a mathematical
foundation that ensures logical consistency and soundness in the reasoning
process. This approach enhances both the training and inference processes
within a single LLM, eliminating the need for multiple models or external
control mechanisms. DoT offers a conceptual framework for designing
next-generation reasoning-specialized models, emphasizing training efficiency,
robust reasoning capabilities, and theoretical grounding. The code is available
at https://github.com/diagram-of-thought/diagram-of-thought.

摘要：我們介紹了思想圖（DoT），這是一個框架，它將大型語言模型（LLM）中的迭代推理建模為在單一模型內建構一個有向無環圖（DAG）。與將推理表示為線性鏈或樹的傳統方法不同，DoT 將命題、批判、修正和驗證組織成一個有凝聚力的 DAG 結構，允許模型探索複雜的推理路徑，同時保持邏輯一致性。圖表中的每個節點對應於一個已被提出、批判、修正或驗證的命題，使 LLM 能夠通過自然語言回饋迭代地改進其推理。通過利用具有角色特定標記的自動回歸下一個標記預測，DoT 促進了提出想法和批判性評估它們之間的無縫過渡，提供了比二元信號更豐富的回饋。此外，我們使用拓撲理論形式化了 DoT 框架，提供了一個數學基礎，以確保推理過程中的邏輯一致性和健全性。這種方法增強了單一 LLM 內的訓練和推理過程，消除了對多個模型或外部控制機制的需要。DoT 為設計下一代推理專用模型提供了一個概念框架，強調訓練效率、強大的推理能力和理論基礎。代碼可在 https://github.com/diagram-of-thought/diagram-of-thought 獲得。

##### **Entity-Aware Self-Attention and Contextualized GCN for Enhanced Relation Extraction in Long Sentences**
2409.13755v1 by Xin Wang, Xinyi Bai

Relation extraction as an important natural Language processing (NLP) task is
to identify relations between named entities in text. Recently, graph
convolutional networks over dependency trees have been widely used to capture
syntactic features and achieved attractive performance. However, most existing
dependency-based approaches ignore the positive influence of the words outside
the dependency trees, sometimes conveying rich and useful information on
relation extraction. In this paper, we propose a novel model, Entity-aware
Self-attention Contextualized GCN (ESC-GCN), which efficiently incorporates
syntactic structure of input sentences and semantic context of sequences. To be
specific, relative position self-attention obtains the overall semantic
pairwise correlation related to word position, and contextualized graph
convolutional networks capture rich intra-sentence dependencies between words
by adequately pruning operations. Furthermore, entity-aware attention layer
dynamically selects which token is more decisive to make final relation
prediction. In this way, our proposed model not only reduces the noisy impact
from dependency trees, but also obtains easily-ignored entity-related semantic
representation. Extensive experiments on various tasks demonstrate that our
model achieves encouraging performance as compared to existing dependency-based
and sequence-based models. Specially, our model excels in extracting relations
between entities of long sentences.

摘要：關係萃取作為一項重要的自然語言處理 (NLP) 任務，是為了辨識文本中命名實體之間的關係。最近，依存樹上的圖形卷積網路已廣泛用於擷取句法特徵，並獲得令人滿意的效能。然而，現有的基於依存的演算法大多忽略依存樹外單字的正面影響，這些單字有時會傳達豐富且有用的關係萃取資訊。在本文中，我們提出一個新穎的模型，實體感知自我注意脈絡化 GCN (ESC-GCN)，它有效地整合輸入句子的句法結構和序列的語意脈絡。具體來說，相對位置自我注意會取得與單字位置相關的整體語意成對關聯性，而脈絡化圖形卷積網路則透過適當的修剪運算，擷取單字之間豐富的句子內依存關係。此外，實體感知注意層會動態地選擇哪個記號對於做出最終關係預測較為決定性。藉由這種方式，我們提出的模型不僅減少了依存樹帶來的雜訊影響，還能取得容易被忽略的實體相關語意表徵。在各種任務上的廣泛實驗證明，與現有的基於依存和基於序列的模型相比，我們的模型達到了令人鼓舞的效能。特別是，我們的模型在萃取長句中實體之間的關係方面表現出色。

##### **Generating Event-oriented Attribution for Movies via Two-Stage Prefix-Enhanced Multimodal LLM**
2409.09362v1 by Yuanjie Lyu, Tong Xu, Zihan Niu, Bo Peng, Jing Ke, Enhong Chen

The prosperity of social media platforms has raised the urgent demand for
semantic-rich services, e.g., event and storyline attribution. However, most
existing research focuses on clip-level event understanding, primarily through
basic captioning tasks, without analyzing the causes of events across an entire
movie. This is a significant challenge, as even advanced multimodal large
language models (MLLMs) struggle with extensive multimodal information due to
limited context length. To address this issue, we propose a Two-Stage
Prefix-Enhanced MLLM (TSPE) approach for event attribution, i.e., connecting
associated events with their causal semantics, in movie videos. In the local
stage, we introduce an interaction-aware prefix that guides the model to focus
on the relevant multimodal information within a single clip, briefly
summarizing the single event. Correspondingly, in the global stage, we
strengthen the connections between associated events using an inferential
knowledge graph, and design an event-aware prefix that directs the model to
focus on associated events rather than all preceding clips, resulting in
accurate event attribution. Comprehensive evaluations of two real-world
datasets demonstrate that our framework outperforms state-of-the-art methods.

摘要：社群媒體平台的蓬勃發展，提升了對語意豐富服務（例如事件和故事線歸因）的迫切需求。然而，現有的研究大多著重於片段層級的事件理解，主要是透過基礎的字幕任務，而未分析整部電影中事件發生的原因。這是一個重大的挑戰，因為即使是進階的多模態大型語言模型 (MLLM) 也會因為受限的脈絡長度而難以處理廣泛的多模態資訊。為了解決這個問題，我們提出了一個兩階段前置詞增強 MLLM (TSPE) 方法，用於電影影片中的事件歸因，也就是將相關事件與其因果語意連結起來。在局部階段，我們引入了一個互動感知前置詞，引導模型專注於單一片段中的相關多模態資訊，簡要地總結單一事件。相應地，在整體階段，我們使用推理知識圖譜強化相關事件之間的連結，並設計了一個事件感知前置詞，引導模型專注於相關事件，而非所有前置片段，進而產生準確的事件歸因。對兩個真實世界資料集的全面評估顯示，我們的架構優於現有的最先進方法。

##### **ODE: Open-Set Evaluation of Hallucinations in Multimodal Large Language Models**
2409.09318v1 by Yahan Tu, Rui Hu, Jitao Sang

Hallucination poses a significant challenge for multimodal large language
models (MLLMs). However, existing benchmarks for evaluating hallucinations are
static, which can lead to potential data contamination. This paper introduces
ODE, an open-set, dynamic protocol for evaluating object existence
hallucinations in MLLMs. Our framework employs graph structures to model
associations between real-word concepts and generates novel samples for both
general and domain-specific scenarios. The dynamic combination of concepts,
along with various combination principles, ensures a broad sample distribution.
Experimental results show that MLLMs exhibit higher hallucination rates with
ODE-generated samples, effectively avoiding data contamination. Moreover, these
samples can also be used for fine-tuning to improve MLLM performance on
existing benchmarks.

摘要：幻覺對多模態大型語言模型 (MLLM) 構成重大挑戰。然而，現有的評估幻覺基準是靜態的，這可能導致潛在的資料污染。本文介紹了 ODE，一種開放式、動態的協定，用於評估 MLLM 中的物件存在幻覺。我們的架構採用圖形結構來建模真實世界概念之間的關聯，並為一般和特定領域情境產生新的範例。概念的動態組合，以及各種組合原則，確保了廣泛的範例分佈。實驗結果顯示，MLLM 在 ODE 生成的範例中表現出較高的幻覺率，有效避免了資料污染。此外，這些範例也可被用於微調，以改善 MLLM 在現有基準上的效能。

##### **Towards Leveraging Contrastively Pretrained Neural Audio Embeddings for Recommender Tasks**
2409.09026v1 by Florian Grötschla, Luca Strässle, Luca A. Lanzendörfer, Roger Wattenhofer

Music recommender systems frequently utilize network-based models to capture
relationships between music pieces, artists, and users. Although these
relationships provide valuable insights for predictions, new music pieces or
artists often face the cold-start problem due to insufficient initial
information. To address this, one can extract content-based information
directly from the music to enhance collaborative-filtering-based methods. While
previous approaches have relied on hand-crafted audio features for this
purpose, we explore the use of contrastively pretrained neural audio embedding
models, which offer a richer and more nuanced representation of music. Our
experiments demonstrate that neural embeddings, particularly those generated
with the Contrastive Language-Audio Pretraining (CLAP) model, present a
promising approach to enhancing music recommendation tasks within graph-based
frameworks.

摘要：音樂推薦系統經常使用基於網路的模型來擷取音樂作品、藝術家和使用者之間的關係。儘管這些關係為預測提供了有價值的見解，但由於初始資訊不足，新的音樂作品或藝術家經常面臨冷啟動問題。為了解決這個問題，可以從音樂中直接擷取基於內容的資訊，以增強基於協同過濾的方法。雖然先前的做法已依賴手工製作的音訊特徵來達成此目的，但我們探索使用對比預訓練神經音訊嵌入模型，這提供了更豐富且更細緻的音樂表示。我們的實驗證明了神經嵌入，特別是使用對比語言音訊預訓練 (CLAP) 模型產生的嵌入，展示了一種有前景的方法，可以用於增強圖形化框架中的音樂推薦任務。

##### **Contri(e)ve: Context + Retrieve for Scholarly Question Answering**
2409.09010v1 by Kanchan Shivashankar, Nadine Steinmetz

Scholarly communication is a rapid growing field containing a wealth of
knowledge. However, due to its unstructured and document format, it is
challenging to extract useful information from them through conventional
document retrieval methods. Scholarly knowledge graphs solve this problem, by
representing the documents in a semantic network, providing, hidden insights,
summaries and ease of accessibility through queries. Naturally, question
answering for scholarly graphs expands the accessibility to a wider audience.
But some of the knowledge in this domain is still presented as unstructured
text, thus requiring a hybrid solution for question answering systems. In this
paper, we present a two step solution using open source Large Language
Model(LLM): Llama3.1 for Scholarly-QALD dataset. Firstly, we extract the
context pertaining to the question from different structured and unstructured
data sources: DBLP, SemOpenAlex knowledge graphs and Wikipedia text. Secondly,
we implement prompt engineering to improve the information retrieval
performance of the LLM. Our approach achieved an F1 score of 40% and also
observed some anomalous responses from the LLM, that are discussed in the final
part of the paper.

摘要：學術交流是一個快速成長的領域，包含了豐富的知識。然而，由於其非結構化和文件格式，透過傳統的文件檢索方法很難從中萃取出有用的資訊。學術知識圖譜解決了這個問題，它以語義網路呈現文件，提供隱藏的見解、摘要和透過查詢輕鬆存取。自然地，學術圖譜的問答擴展了對更廣泛受眾的存取性。但這個領域中的一些知識仍然以非結構化文字呈現，因此需要一個混合解決方案來進行問答系統。在本文中，我們提出了一個使用開放原始碼大型語言模型 (LLM) 的兩步驟解決方案：Llama3.1 for Scholarly-QALD 資料集。首先，我們從不同的結構化和非結構化資料來源中萃取與問題相關的脈絡：DBLP、SemOpenAlex 知識圖譜和維基百科文字。其次，我們實作提示工程以改善 LLM 的資訊檢索效能。我們的做法達到了 40% 的 F1 分數，並且也觀察到 LLM 的一些異常回應，這些回應在本文的最後一部分中進行了討論。

##### **SGFormer: Single-Layer Graph Transformers with Approximation-Free Linear Complexity**
2409.09007v1 by Qitian Wu, Kai Yang, Hengrui Zhang, David Wipf, Junchi Yan

Learning representations on large graphs is a long-standing challenge due to
the inter-dependence nature. Transformers recently have shown promising
performance on small graphs thanks to its global attention for capturing
all-pair interactions beyond observed structures. Existing approaches tend to
inherit the spirit of Transformers in language and vision tasks, and embrace
complicated architectures by stacking deep attention-based propagation layers.
In this paper, we attempt to evaluate the necessity of adopting multi-layer
attentions in Transformers on graphs, which considerably restricts the
efficiency. Specifically, we analyze a generic hybrid propagation layer,
comprised of all-pair attention and graph-based propagation, and show that
multi-layer propagation can be reduced to one-layer propagation, with the same
capability for representation learning. It suggests a new technical path for
building powerful and efficient Transformers on graphs, particularly through
simplifying model architectures without sacrificing expressiveness. As
exemplified by this work, we propose a Simplified Single-layer Graph
Transformers (SGFormer), whose main component is a single-layer global
attention that scales linearly w.r.t. graph sizes and requires none of any
approximation for accommodating all-pair interactions. Empirically, SGFormer
successfully scales to the web-scale graph ogbn-papers100M, yielding
orders-of-magnitude inference acceleration over peer Transformers on
medium-sized graphs, and demonstrates competitiveness with limited labeled
data.

摘要：在大型圖表上學習表徵由於相互依賴的性質而成為一項長期的挑戰。由於 Transfomer 能夠針對所有成對互動進行全局關注，超越觀測結構，因此最近在小型圖表上展現出令人滿意的效能。現有的方法傾向於繼承 Transformer 在語言和視覺任務中的精神，並通過堆疊基於深度關注的傳播層來採用複雜的架構。在本文中，我們嘗試評估在圖表上採用多層注意力 Transformer 的必要性，這極大地限制了效率。具體來說，我們分析了一個通用的混合傳播層，它包含所有成對注意力和基於圖表的傳播，並表明多層傳播可以簡化為單層傳播，具有相同的表徵學習能力。這為在圖表上構建強大而高效的 Transformer 提供了一條新的技術路徑，特別是通過簡化模型架構，而無需犧牲表達能力。正如這項工作所例證的，我們提出了一個簡化的單層圖形 Transformer (SGFormer)，其主要組成部分是一個單層全局注意力，它與圖形大小成線性比例，並且不需要任何近似來適應所有成對互動。根據經驗，SGFormer 成功地擴展到網路規模的圖表 ogbn-papers100M，在中等大小的圖表上產生了比同儕 Transformer 快幾個數量級的推論加速，並證明了在標籤資料有限的情況下具有競爭力。

##### **Exploring Graph Structure Comprehension Ability of Multimodal Large Language Models: Case Studies**
2409.08864v1 by Zhiqiang Zhong, Davide Mottin

Large Language Models (LLMs) have shown remarkable capabilities in processing
various data structures, including graphs. While previous research has focused
on developing textual encoding methods for graph representation, the emergence
of multimodal LLMs presents a new frontier for graph comprehension. These
advanced models, capable of processing both text and images, offer potential
improvements in graph understanding by incorporating visual representations
alongside traditional textual data. This study investigates the impact of graph
visualisations on LLM performance across a range of benchmark tasks at node,
edge, and graph levels. Our experiments compare the effectiveness of multimodal
approaches against purely textual graph representations. The results provide
valuable insights into both the potential and limitations of leveraging visual
graph modalities to enhance LLMs' graph structure comprehension abilities.

摘要：大型語言模型 (LLM) 在處理各種數據結構（包括圖形）方面表現出非凡的能力。儘管先前的研究著重於開發圖形表示的文本編碼方法，但多模態 LLM 的出現為圖形理解提供了新的領域。這些先進的模型能夠處理文本和圖像，透過結合視覺表示與傳統文本資料，提供圖形理解的潛在改進。本研究探討圖形視覺化對 LLM 在節點、邊緣和圖形層級一系列基準任務的效能影響。我們的實驗比較了多模態方法與純文本圖形表示的有效性。結果提供了有價值的見解，了解利用視覺圖形模態來增強 LLM 圖形結構理解能力的潛力與限制。

##### **A RAG Approach for Generating Competency Questions in Ontology Engineering**
2409.08820v1 by Xueli Pan, Jacco van Ossenbruggen, Victor de Boer, Zhisheng Huang

Competency question (CQ) formulation is central to several ontology
development and evaluation methodologies. Traditionally, the task of crafting
these competency questions heavily relies on the effort of domain experts and
knowledge engineers which is often time-consuming and labor-intensive. With the
emergence of Large Language Models (LLMs), there arises the possibility to
automate and enhance this process. Unlike other similar works which use
existing ontologies or knowledge graphs as input to LLMs, we present a
retrieval-augmented generation (RAG) approach that uses LLMs for the automatic
generation of CQs given a set of scientific papers considered to be a domain
knowledge base. We investigate its performance and specifically, we study the
impact of different number of papers to the RAG and different temperature
setting of the LLM. We conduct experiments using GPT-4 on two domain ontology
engineering tasks and compare results against ground-truth CQs constructed by
domain experts. Empirical assessments on the results, utilizing evaluation
metrics (precision and consistency), reveal that compared to zero-shot
prompting, adding relevant domain knowledge to the RAG improves the performance
of LLMs on generating CQs for concrete ontology engineering tasks.

摘要：能力問題 (CQ) 的制定是幾個本体論發展和評估方法的中心。傳統上，制定這些能力問題的任務很大程度上依賴於領域專家和知識工程師的努力，這通常是耗時且勞力密集的。隨著大型語言模型 (LLM) 的出現，自動化和增強此過程的可能性出現了。與其他使用現有本体論或知識圖譜作為 LLM 輸入的類似工作不同，我們提出了一種檢索增強生成 (RAG) 方法，該方法使用 LLM 自動生成被認為是領域知識庫的一組科學論文的 CQ。我們研究其性能，特別是我們研究不同數量的論文對 RAG 的影響和 LLM 的不同溫度設置。我們使用 GPT-4 對兩個領域本体論工程任務進行實驗，並將結果與由領域專家構造的真實 CQ 進行比較。利用評估指標（精確度和一致性）對結果進行的實證評估表明，與零次提示相比，將相關領域知識添加到 RAG 可以提高 LLM 在為具體本体論工程任務生成 CQ 方面的性能。

##### **ATFLRec: A Multimodal Recommender System with Audio-Text Fusion and Low-Rank Adaptation via Instruction-Tuned Large Language Model**
2409.08543v1 by Zezheng Qin

Recommender Systems (RS) play a pivotal role in boosting user satisfaction by
providing personalized product suggestions in domains such as e-commerce and
entertainment. This study examines the integration of multimodal data text and
audio into large language models (LLMs) with the aim of enhancing
recommendation performance. Traditional text and audio recommenders encounter
limitations such as the cold-start problem, and recent advancements in LLMs,
while promising, are computationally expensive. To address these issues,
Low-Rank Adaptation (LoRA) is introduced, which enhances efficiency without
compromising performance. The ATFLRec framework is proposed to integrate audio
and text modalities into a multimodal recommendation system, utilizing various
LoRA configurations and modality fusion techniques. Results indicate that
ATFLRec outperforms baseline models, including traditional and graph neural
network-based approaches, achieving higher AUC scores. Furthermore, separate
fine-tuning of audio and text data with distinct LoRA modules yields optimal
performance, with different pooling methods and Mel filter bank numbers
significantly impacting performance. This research offers valuable insights
into optimizing multimodal recommender systems and advancing the integration of
diverse data modalities in LLMs.

摘要：推薦系統 (RS) 在提升使用者滿意度中扮演著舉足輕重的角色，它在電子商務和娛樂等領域提供個人化的產品建議。本研究探討將多模態資料文字和音訊整合到大型語言模型 (LLM) 中，以增強推薦效能。傳統的文字和音訊推薦器會遇到冷啟動問題等限制，而 LLM 的最新進展雖然很有前景，但計算成本很高。為了解決這些問題，引入了低秩適應 (LoRA)，它在不影響效能的情況下提升了效率。ATFLRec 框架被提出來將音訊和文字模態整合到多模態推薦系統中，利用各種 LoRA 配置和模態融合技術。結果表明，ATFLRec 優於基線模型，包括傳統和基於圖神經網路的方法，達到了更高的 AUC 分數。此外，使用不同的 LoRA 模組對音訊和文字資料進行單獨微調會產生最佳效能，不同的池化方法和 Mel 濾波器組數會對效能產生顯著影響。本研究提供了寶貴的見解，用於最佳化多模態推薦系統，並推動將不同的資料模態整合到 LLM 中。

##### **What Makes a Maze Look Like a Maze?**
2409.08202v1 by Joy Hsu, Jiayuan Mao, Joshua B. Tenenbaum, Noah D. Goodman, Jiajun Wu

A unique aspect of human visual understanding is the ability to flexibly
interpret abstract concepts: acquiring lifted rules explaining what they
symbolize, grounding them across familiar and unfamiliar contexts, and making
predictions or reasoning about them. While off-the-shelf vision-language models
excel at making literal interpretations of images (e.g., recognizing object
categories such as tree branches), they still struggle to make sense of such
visual abstractions (e.g., how an arrangement of tree branches may form the
walls of a maze). To address this challenge, we introduce Deep Schema Grounding
(DSG), a framework that leverages explicit structured representations of visual
abstractions for grounding and reasoning. At the core of DSG are
schemas--dependency graph descriptions of abstract concepts that decompose them
into more primitive-level symbols. DSG uses large language models to extract
schemas, then hierarchically grounds concrete to abstract components of the
schema onto images with vision-language models. The grounded schema is used to
augment visual abstraction understanding. We systematically evaluate DSG and
different methods in reasoning on our new Visual Abstractions Dataset, which
consists of diverse, real-world images of abstract concepts and corresponding
question-answer pairs labeled by humans. We show that DSG significantly
improves the abstract visual reasoning performance of vision-language models,
and is a step toward human-aligned understanding of visual abstractions.

摘要：人類視覺理解的獨特面向在於靈活詮釋抽象概念的能力：獲取解釋其象徵意義的提升規則，在熟悉和不熟悉的背景下奠定其基礎，並對其進行預測或推理。雖然現成的視覺語言模型擅長對影像進行字面詮釋（例如辨識樹枝等物體類別），但它們在理解此類視覺抽象概念時仍有困難（例如樹枝的排列如何形成迷宮的牆壁）。為了應對此挑戰，我們引入了深度模式基礎（DSG），這是一個框架，利用視覺抽象概念的明確結構化表示來進行基礎和推理。DSG 的核心是模式——抽象概念的依賴圖描述，將其分解為更原始層級的符號。DSG 使用大型語言模型來提取模式，然後將模式的具體組成部分分層基礎到影像上，並使用視覺語言模型。基礎模式用於擴充視覺抽象理解。我們系統性地評估了 DSG 和我們的新視覺抽象資料集上的不同推理方法，該資料集包含各種真實世界的抽象概念影像，以及由人類標記的對應問題解答對。我們證明 DSG 大幅提升了視覺語言模型的抽象視覺推理效能，並且朝著與人類一致的視覺抽象理解邁進一步。

##### **Towards a graph-based foundation model for network traffic analysis**
2409.08111v1 by Louis Van Langendonck, Ismael Castell-Uroz, Pere Barlet-Ros

Foundation models have shown great promise in various fields of study. A
potential application of such models is in computer network traffic analysis,
where these models can grasp the complexities of network traffic dynamics and
adapt to any specific task or network environment with minimal fine-tuning.
Previous approaches have used tokenized hex-level packet data and the model
architecture of large language transformer models. We propose a new, efficient
graph-based alternative at the flow-level. Our approach represents network
traffic as a dynamic spatio-temporal graph, employing a self-supervised link
prediction pretraining task to capture the spatial and temporal dynamics in
this network graph framework. To evaluate the effectiveness of our approach, we
conduct a few-shot learning experiment for three distinct downstream network
tasks: intrusion detection, traffic classification, and botnet classification.
Models finetuned from our pretrained base achieve an average performance
increase of 6.87\% over training from scratch, demonstrating their ability to
effectively learn general network traffic dynamics during pretraining. This
success suggests the potential for a large-scale version to serve as an
operational foundational model.

摘要：基礎模型已在各個研究領域中展現出極大的前景。此類模型的潛在應用之一在於電腦網路流量分析，其中這些模型可以掌握網路流量動態的複雜性，並以最小的微調適應任何特定任務或網路環境。先前的做法已使用標記化十六進位層級封包資料和大型語言轉換器模型的模型架構。我們提出一個新的、有效的流程層級圖形化替代方案。我們的做法將網路流量表示為動態時空圖形，採用自我監督連結預測預訓練任務來捕捉此網路圖形架構中的空間和時間動態。為了評估我們做法的有效性，我們對三個不同的下游網路任務（入侵偵測、流量分類和殭屍網路分類）進行少量學習實驗。從我們的預訓練基礎微調的模型，其平均效能提升 6.87%，高於從頭訓練，這證明了它們在預訓練期間有效學習一般網路流量動態的能力。這項成功顯示出大規模版本有潛力作為運作基礎模型。

##### **Learning Rules from KGs Guided by Language Models**
2409.07869v1 by Zihang Peng, Daria Stepanova, Vinh Thinh Ho, Heike Adel, Alessandra Russo, Simon Ott

Advances in information extraction have enabled the automatic construction of
large knowledge graphs (e.g., Yago, Wikidata or Google KG), which are widely
used in many applications like semantic search or data analytics. However, due
to their semi-automatic construction, KGs are often incomplete. Rule learning
methods, concerned with the extraction of frequent patterns from KGs and
casting them into rules, can be applied to predict potentially missing facts. A
crucial step in this process is rule ranking. Ranking of rules is especially
challenging over highly incomplete or biased KGs (e.g., KGs predominantly
storing facts about famous people), as in this case biased rules might fit the
data best and be ranked at the top based on standard statistical metrics like
rule confidence. To address this issue, prior works proposed to rank rules not
only relying on the original KG but also facts predicted by a KG embedding
model. At the same time, with the recent rise of Language Models (LMs), several
works have claimed that LMs can be used as alternative means for KG completion.
In this work, our goal is to verify to which extent the exploitation of LMs is
helpful for improving the quality of rule learning systems.

摘要：資訊萃取的進展已能自動建構大型知識圖譜（例如 Yago、Wikidata 或 Google KG），這些知識圖譜廣泛用於許多應用程式，例如語意搜尋或資料分析。然而，由於這些知識圖譜是半自動建構的，因此通常並不完整。規則學習方法著重於從知識圖譜中萃取頻繁模式，並將它們轉換為規則，可應用於預測潛在遺失的事實。此過程中的一個關鍵步驟是規則排序。規則排序在高度不完整或有偏差的知識圖譜（例如，主要儲存名人事實的知識圖譜）中特別具有挑戰性，因為在這種情況下，有偏差的規則可能最符合資料，並根據標準統計量度（例如規則信心）排在最前面。為了解決這個問題，先前的研究提出不只依賴原始知識圖譜，還要依賴知識圖譜嵌入模型預測的事實來對規則進行排序。同時，隨著語言模型 (LM) 的興起，一些研究聲稱 LM 可用作知識圖譜完成的替代方法。在這項研究中，我們的目標是驗證利用 LM 在多大程度上有助於提升規則學習系統的品質。

##### **Multi-object event graph representation learning for Video Question Answering**
2409.07747v1 by Yanan Wang, Shuichiro Haruta, Donghuo Zeng, Julio Vizcarra, Mori Kurokawa

Video question answering (VideoQA) is a task to predict the correct answer to
questions posed about a given video. The system must comprehend spatial and
temporal relationships among objects extracted from videos to perform causal
and temporal reasoning. While prior works have focused on modeling individual
object movements using transformer-based methods, they falter when capturing
complex scenarios involving multiple objects (e.g., "a boy is throwing a ball
in a hoop"). We propose a contrastive language event graph representation
learning method called CLanG to address this limitation. Aiming to capture
event representations associated with multiple objects, our method employs a
multi-layer GNN-cluster module for adversarial graph representation learning,
enabling contrastive learning between the question text and its relevant
multi-object event graph. Our method outperforms a strong baseline, achieving
up to 2.2% higher accuracy on two challenging VideoQA datasets, NExT-QA and
TGIF-QA-R. In particular, it is 2.8% better than baselines in handling causal
and temporal questions, highlighting its strength in reasoning multiple
object-based events.

摘要：影片問答 (VideoQA) 是一項任務，用於預測針對給定影片提出的問題的正確答案。系統必須了解從影片中提取的物件之間的空間和時間關係，才能執行因果關係和時間推理。雖然先前的研究集中於使用基於Transformer的模型來建模個別物件的動作，但在捕捉涉及多個物件的複雜場景（例如「一個男孩正在將球投進籃框」）時，它們會出現問題。我們提出了一個對比式語言事件圖表表示學習方法，稱為 CLanG，以解決此限制。為了捕捉與多個物件相關的事件表示，我們的模型採用多層 GNN 集群模組進行對抗式圖表表示學習，使問題文字及其相關的多物件事件圖表之間能夠進行對比式學習。我們的模型優於強大的基準，在兩個具有挑戰性的 VideoQA 資料集 NExT-QA 和 TGIF-QA-R 上達到了高達 2.2% 的更高準確度。特別是，在處理因果關係和時間問題方面比基準高出 2.8%，突顯了它在推理多個基於物件的事件方面的優勢。

##### **Demo: SGCode: A Flexible Prompt-Optimizing System for Secure Generation of Code**
2409.07368v3 by Khiem Ton, Nhi Nguyen, Mahmoud Nazzal, Abdallah Khreishah, Cristian Borcea, NhatHai Phan, Ruoming Jin, Issa Khalil, Yelong Shen

This paper introduces SGCode, a flexible prompt-optimizing system to generate
secure code with large language models (LLMs). SGCode integrates recent
prompt-optimization approaches with LLMs in a unified system accessible through
front-end and back-end APIs, enabling users to 1) generate secure code, which
is free of vulnerabilities, 2) review and share security analysis, and 3)
easily switch from one prompt optimization approach to another, while providing
insights on model and system performance. We populated SGCode on an AWS server
with PromSec, an approach that optimizes prompts by combining an LLM and
security tools with a lightweight generative adversarial graph neural network
to detect and fix security vulnerabilities in the generated code. Extensive
experiments show that SGCode is practical as a public tool to gain insights
into the trade-offs between model utility, secure code generation, and system
cost. SGCode has only a marginal cost compared with prompting LLMs. SGCode is
available at: https://sgcode.codes/.

摘要：本文介紹 SGCode，一個彈性的提示最佳化系統，用於生成大型語言模型 (LLM) 的安全程式碼。SGCode 將最近的提示最佳化方法與 LLM 整合在一個統一的系統中，可透過前端和後端 API 存取，使用戶能夠 1) 產生安全的程式碼，沒有漏洞，2) 檢閱和分享安全性分析，以及 3) 從一種提示最佳化方法輕鬆切換到另一種，同時提供模型和系統效能的見解。我們在 AWS 伺服器上使用 PromSec 填充 SGCode，這是一種透過結合 LLM 和安全性工具，以及輕量級生成對抗圖形神經網路來最佳化提示，以偵測和修復產生程式碼中的安全性漏洞的方法。廣泛的實驗顯示，SGCode 作為一個公用工具，在模型效用、安全程式碼產生和系統成本之間的權衡中獲得見解，是實用的。與提示 LLM 相比，SGCode 只有邊際成本。SGCode 可在 https://sgcode.codes/ 取得。

##### **Semantic Interoperability on Blockchain by Generating Smart Contracts Based on Knowledge Graphs**
2409.12171v1 by William Van Woensel, Oshani Seneviratne

Background: Health 3.0 allows decision making to be based on longitudinal
data from multiple institutions, from across the patient's healthcare journey.
In such a distributed setting, blockchain smart contracts can act as neutral
intermediaries to implement trustworthy decision making.
  Objective: In a distributed setting, transmitted data will be structured
using standards (such as HL7 FHIR) for semantic interoperability. In turn, the
smart contract will require interoperability with this standard, implement a
complex communication setup (e.g., using oracles), and be developed using
blockchain languages (e.g., Solidity). We propose the encoding of smart
contract logic using a high-level semantic Knowledge Graph, using concepts from
the domain standard. We then deploy this semantic KG on blockchain.
  Methods: Off-chain, a code generation pipeline compiles the KG into a
concrete smart contract, which is then deployed on-chain. Our pipeline targets
an intermediary bridge representation, which can be transpiled into a specific
blockchain language. Our choice avoids on-chain rule engines, with
unpredictable and likely higher computational cost; it is thus in line with the
economic rules of blockchain.
  Results: We applied our code generation approach to generate smart contracts
for 3 health insurance cases from Medicare. We discuss the suitability of our
approach - the need for a neutral intermediary - for a number of healthcare use
cases. Our evaluation finds that the generated contracts perform well in terms
of correctness and execution cost ("gas") on blockchain.
  Conclusions: We showed that it is feasible to automatically generate smart
contract code based on a semantic KG, in a way that respects the economic rules
of blockchain. Future work includes studying the use of Large Language Models
(LLM) in our approach, and evaluations on other blockchains.

摘要：<paragraph>背景：Health 3.0 允許決策制定基於來自多個機構的縱向數據，來自患者的醫療保健歷程。在這種分布式設置中，區塊鏈智能合約可以作為中立的仲介來實施值得信賴的決策制定。目標：在分布式設置中，傳輸的數據將使用標準（例如 HL7 FHIR）進行結構化，以實現語義互操作性。反過來，智能合約將需要與此標準互操作，實施複雜的通信設置（例如，使用預言機），並使用區塊鏈語言（例如，Solidity）開發。我們提議使用來自領域標準的概念，使用高級語義知識圖對智能合約邏輯進行編碼。然後我們將這個語義知識圖部署在區塊鏈上。方法：鏈下，一個代碼生成管道將知識圖編譯成具體的智能合約，然後將其部署到鏈上。我們的管道針對中間橋接表示，可以轉譯成特定的區塊鏈語言。我們的選擇避免了鏈上規則引擎，其不可預測且可能計算成本更高；因此，它符合區塊鏈的經濟規則。結果：我們應用我們的代碼生成方法來生成來自 Medicare 的 3 個健康保險案例的智能合約。我們討論了我們的方法的適用性——對中立仲介的需求——對於許多醫療保健用例。我們的評估發現，生成的合約在區塊鏈上的正確性和執行成本（“gas”）方面表現良好。結論：我們表明，以符合區塊鏈經濟規則的方式自動生成基於語義知識圖的智能合約代碼是可行的。未來的研究包括研究我們的方法中使用大型語言模型 (LLM)，以及對其他區塊鏈的評估。</paragraph>

##### **Ontology-Free General-Domain Knowledge Graph-to-Text Generation Dataset Synthesis using Large Language Model**
2409.07088v1 by Daehee Kim, Deokhyung Kang, Sangwon Ryu, Gary Geunbae Lee

Knowledge Graph-to-Text (G2T) generation involves verbalizing structured
knowledge graphs into natural language text. Recent advancements in Pretrained
Language Models (PLMs) have improved G2T performance, but their effectiveness
depends on datasets with precise graph-text alignment. However, the scarcity of
high-quality, general-domain G2T generation datasets restricts progress in the
general-domain G2T generation research. To address this issue, we introduce
Wikipedia Ontology-Free Graph-text dataset (WikiOFGraph), a new large-scale G2T
dataset generated using a novel method that leverages Large Language Model
(LLM) and Data-QuestEval. Our new dataset, which contains 5.85M general-domain
graph-text pairs, offers high graph-text consistency without relying on
external ontologies. Experimental results demonstrate that PLM fine-tuned on
WikiOFGraph outperforms those trained on other datasets across various
evaluation metrics. Our method proves to be a scalable and effective solution
for generating high-quality G2T data, significantly advancing the field of G2T
generation.

摘要：知識圖譜到文字 (G2T) 生成涉及將結構化知識圖譜表達為自然語言文字。預訓練語言模型 (PLM) 的最新進展改善了 G2T 的效能，但其有效性取決於具有精確圖形文字對齊的資料集。然而，高品質、一般領域 G2T 生成資料集的稀少性限制了一般領域 G2T 生成研究的進展。為了解決這個問題，我們引入了維基百科本体免費圖形文字資料集 (WikiOFGraph)，這是一個使用利用大型語言模型 (LLM) 和 Data-QuestEval 的新方法生成的新大型 G2T 資料集。我們的這個新資料集包含 585 萬個一般領域的圖形文字對，提供高圖形文字一致性，而不依賴於外部本体。實驗結果表明，在 WikiOFGraph 上微調的 PLM 在各種評估指標上優於在其他資料集上訓練的 PLM。我們的這個方法被證明是一個可擴充且有效的解決方案，用於生成高品質的 G2T 資料，顯著推動了 G2T 生成領域的發展。

##### **Automated Speaking Assessment of Conversation Tests with Novel Graph-based Modeling on Spoken Response Coherence**
2409.07064v1 by Jiun-Ting Li, Bi-Cheng Yan, Tien-Hong Lo, Yi-Cheng Wang, Yung-Chang Hsu, Berlin Chen

Automated speaking assessment in conversation tests (ASAC) aims to evaluate
the overall speaking proficiency of an L2 (second-language) speaker in a
setting where an interlocutor interacts with one or more candidates. Although
prior ASAC approaches have shown promising performance on their respective
datasets, there is still a dearth of research specifically focused on
incorporating the coherence of the logical flow within a conversation into the
grading model. To address this critical challenge, we propose a hierarchical
graph model that aptly incorporates both broad inter-response interactions
(e.g., discourse relations) and nuanced semantic information (e.g., semantic
words and speaker intents), which is subsequently fused with contextual
information for the final prediction. Extensive experimental results on the
NICT-JLE benchmark dataset suggest that our proposed modeling approach can
yield considerable improvements in prediction accuracy with respect to various
assessment metrics, as compared to some strong baselines. This also sheds light
on the importance of investigating coherence-related facets of spoken responses
in ASAC.

摘要：自動對話評量中的自動化口說評量（ASAC）旨在評估 L2（第二語言）話者在與一位或多位應試者互動的環境中，整體的口說能力。儘管先前的 ASAC 方法在其各自的資料集上展現出有前途的表現，但仍缺乏專注於將對話中邏輯流程的連貫性納入評分模型的研究。為了應對這項關鍵挑戰，我們提出了一個階層式圖形模型，它適當地結合了廣泛的回應間互動（例如：語篇關係）和細微的語義資訊（例如：語義字詞和說話者意圖），隨後與脈絡資訊融合，以進行最終預測。在 NICT-JLE 基準資料集上進行的廣泛實驗結果表明，與一些強大的基準線相比，我們提出的建模方法可以顯著提升預測準確度，特別是在各種評量指標方面。這也闡明了在 ASAC 中探討口語回應的連貫性相關面向的重要性。

##### **FreeRide: Harvesting Bubbles in Pipeline Parallelism**
2409.06941v1 by Jiashu Zhang, Zihan Pan, Molly, Xu, Khuzaima Daudjee, Sihang Liu

The occurrence of bubbles in pipeline parallelism is an inherent limitation
that can account for more than 40% of the large language model (LLM) training
time and is one of the main reasons for the underutilization of GPU resources
in LLM training. Harvesting these bubbles for GPU side tasks can increase
resource utilization and reduce training costs but comes with challenges.
First, because bubbles are discontinuous with various shapes, programming side
tasks becomes difficult while requiring excessive engineering effort. Second, a
side task can compete with pipeline training for GPU resources and incur
significant overhead. To address these challenges, we propose FreeRide, a
system designed to harvest bubbles in pipeline parallelism for side tasks.
FreeRide provides programmers with interfaces to implement side tasks easily,
manages bubbles and side tasks during pipeline training, and controls access to
GPU resources by side tasks to reduce overhead. We demonstrate that FreeRide
achieves 7.8% average cost savings with a negligible overhead of about 1% in
training LLMs while serving model training, graph analytics, and image
processing side tasks.

摘要：管線平行處理中發生氣泡是一個固有限制，可能佔大型語言模型 (LLM) 訓練時間的 40% 以上，並且是 LLM 訓練中 GPU 資源利用不足的主要原因之一。收集這些氣泡以進行 GPU 側面任務可以提高資源利用率並降低訓練成本，但會帶來挑戰。首先，由於氣泡是不連續的且形狀各異，因此編寫程式側面任務變得困難，同時需要過多的工程工作。其次，側面任務可能會與管線訓練競爭 GPU 資源，並造成顯著的開銷。為了應對這些挑戰，我們提出了 FreeRide，這是一個旨在收集管線平行處理中的氣泡以進行側面任務的系統。FreeRide 為程式設計師提供了輕鬆實作側面任務的介面，在管線訓練期間管理氣泡和側面任務，並控制側面任務對 GPU 資源的存取以減少開銷。我們證明 FreeRide 在訓練 LLM 時可節省 7.8% 的平均成本，同時在執行模型訓練、圖形分析和影像處理側面任務時，開銷可忽略不計，約為 1%。

##### **Generative Hierarchical Materials Search**
2409.06762v1 by Sherry Yang, Simon Batzner, Ruiqi Gao, Muratahan Aykol, Alexander L. Gaunt, Brendan McMorrow, Danilo J. Rezende, Dale Schuurmans, Igor Mordatch, Ekin D. Cubuk

Generative models trained at scale can now produce text, video, and more
recently, scientific data such as crystal structures. In applications of
generative approaches to materials science, and in particular to crystal
structures, the guidance from the domain expert in the form of high-level
instructions can be essential for an automated system to output candidate
crystals that are viable for downstream research. In this work, we formulate
end-to-end language-to-structure generation as a multi-objective optimization
problem, and propose Generative Hierarchical Materials Search (GenMS) for
controllable generation of crystal structures. GenMS consists of (1) a language
model that takes high-level natural language as input and generates
intermediate textual information about a crystal (e.g., chemical formulae), and
(2) a diffusion model that takes intermediate information as input and
generates low-level continuous value crystal structures. GenMS additionally
uses a graph neural network to predict properties (e.g., formation energy) from
the generated crystal structures. During inference, GenMS leverages all three
components to conduct a forward tree search over the space of possible
structures. Experiments show that GenMS outperforms other alternatives of
directly using language models to generate structures both in satisfying user
request and in generating low-energy structures. We confirm that GenMS is able
to generate common crystal structures such as double perovskites, or spinels,
solely from natural language input, and hence can form the foundation for more
complex structure generation in near future.

摘要：<paragraph>大規模訓練的生成模型現在可以產生文字、影片，以及最近的科學資料，例如晶體結構。在生成方法應用於材料科學，尤其是晶體結構時，領域專家的指導，以高階指令的形式，對於自動化系統輸出可行於下游研究的候選晶體至關重要。在這項工作中，我們將端對端語言到結構生成制定為多目標最佳化問題，並提出生成分層材料搜尋 (GenMS) 以控制晶體結構的生成。GenMS 包含 (1) 一個語言模型，它將高階自然語言作為輸入，並生成有關晶體的中間文字資訊（例如化學公式），以及 (2) 一個擴散模型，它將中間資訊作為輸入，並生成低階連續值晶體結構。GenMS 此外使用圖形神經網路從生成的晶體結構預測屬性（例如形成能）。在推理期間，GenMS 利用所有三個組件對可能的結構空間進行前向樹狀搜尋。實驗顯示，GenMS 優於直接使用語言模型來生成結構的其他替代方案，無論是在滿足使用者要求或生成低能結構方面。我們確認 GenMS 能夠僅從自然語言輸入生成常見的晶體結構，例如雙鈣鈦礦或尖晶石，因此可以在不久的將來形成更複雜結構生成的基礎。</paragraph>

##### **Fine-tuning and Prompt Engineering with Cognitive Knowledge Graphs for Scholarly Knowledge Organization**
2409.06433v1 by Gollam Rabby, Sören Auer, Jennifer D'Souza, Allard Oelen

The increasing amount of published scholarly articles, exceeding 2.5 million
yearly, raises the challenge for researchers in following scientific progress.
Integrating the contributions from scholarly articles into a novel type of
cognitive knowledge graph (CKG) will be a crucial element for accessing and
organizing scholarly knowledge, surpassing the insights provided by titles and
abstracts. This research focuses on effectively conveying structured scholarly
knowledge by utilizing large language models (LLMs) to categorize scholarly
articles and describe their contributions in a structured and comparable
manner. While previous studies explored language models within specific
research domains, the extensive domain-independent knowledge captured by LLMs
offers a substantial opportunity for generating structured contribution
descriptions as CKGs. Additionally, LLMs offer customizable pathways through
prompt engineering or fine-tuning, thus facilitating to leveraging of smaller
LLMs known for their efficiency, cost-effectiveness, and environmental
considerations. Our methodology involves harnessing LLM knowledge, and
complementing it with domain expert-verified scholarly data sourced from a CKG.
This strategic fusion significantly enhances LLM performance, especially in
tasks like scholarly article categorization and predicate recommendation. Our
method involves fine-tuning LLMs with CKG knowledge and additionally injecting
knowledge from a CKG with a novel prompting technique significantly increasing
the accuracy of scholarly knowledge extraction. We integrated our approach in
the Open Research Knowledge Graph (ORKG), thus enabling precise access to
organized scholarly knowledge, crucially benefiting domain-independent
scholarly knowledge exchange and dissemination among policymakers, industrial
practitioners, and the general public.

摘要：<paragraph>每年超過 250 萬篇的學術文章發表數量持續增加，對研究人員追蹤科學進展帶來挑戰。將學術文章的貢獻整合到新型態的認知知識圖譜 (CKG) 中，將成為存取和組織學術知識的關鍵要素，超越標題和摘要提供的見解。本研究專注於有效傳達結構化的學術知識，利用大型語言模型 (LLM) 來分類學術文章，並以結構化且可比較的形式描述其貢獻。雖然先前的研究在特定研究領域中探索語言模型，但 LLM 捕捉到的廣泛領域無關知識，為產生結構化的貢獻描述提供了實質機會，例如 CKG。此外，LLM 透過提示工程或微調提供可自訂路徑，從而促進利用以效率、成本效益和環境考量聞名的較小型 LLM。我們的做法包括利用 LLM 知識，並透過 CKG 來源的領域專家驗證學術資料來補充。這種策略融合顯著提升 LLM 的效能，特別是在學術文章分類和謂詞推薦等任務中。我們的方法包括以 CKG 知識微調 LLM，並透過新的提示技術注入 CKG 的知識，顯著提升學術知識萃取的準確度。我們將我們的做法整合到開放研究知識圖譜 (ORKG) 中，從而能精準存取已組織的學術知識，這對政策制定者、產業從業人員和一般大眾之間的領域無關學術知識交流和傳播至關重要。</paragraph>

##### **TopoChat: Enhancing Topological Materials Retrieval With Large Language Model and Multi-Source Knowledge**
2409.13732v1 by HuangChao Xu, Baohua Zhang, Zhong Jin, Tiannian Zhu, Quansheng Wu, Hongming Weng

Large language models (LLMs), such as ChatGPT, have demonstrated impressive
performance in the text generation task, showing the ability to understand and
respond to complex instructions. However, the performance of naive LLMs in
speciffc domains is limited due to the scarcity of domain-speciffc corpora and
specialized training. Moreover, training a specialized large-scale model
necessitates signiffcant hardware resources, which restricts researchers from
leveraging such models to drive advances. Hence, it is crucial to further
improve and optimize LLMs to meet speciffc domain demands and enhance their
scalability. Based on the condensed matter data center, we establish a material
knowledge graph (MaterialsKG) and integrate it with literature. Using large
language models and prompt learning, we develop a specialized dialogue system
for topological materials called TopoChat. Compared to naive LLMs, TopoChat
exhibits superior performance in structural and property querying, material
recommendation, and complex relational reasoning. This system enables efffcient
and precise retrieval of information and facilitates knowledge interaction,
thereby encouraging the advancement on the ffeld of condensed matter materials.

摘要：大型語言模型（LLM），例如 ChatGPT，在文本生成任務中展現了令人印象深刻的表現，展現了理解和回應複雜指令的能力。然而，由於缺乏特定領域的語料庫和專業訓練，天真的 LLM 在特定領域的表現受到限制。此外，訓練一個專業的大規模模型需要大量的硬體資源，這限制了研究人員利用這些模型來推動進展。因此，進一步改進和優化 LLM 以滿足特定領域的需求並增強其可擴充性至關重要。基於凝聚態資料中心，我們建立了一個材料知識圖譜（MaterialsKG），並將其與文獻整合。使用大型語言模型和提示學習，我們開發了一個名為 TopoChat 的拓撲材料專用對話系統。與天真的 LLM 相比，TopoChat 在結構和屬性查詢、材料推薦和複雜關係推理方面表現出優異的性能。該系統能夠有效且準確地檢索資訊，並促進知識互動，從而促進凝聚態材料領域的進步。

##### **KAG: Boosting LLMs in Professional Domains via Knowledge Augmented Generation**
2409.13731v3 by Lei Liang, Mengshu Sun, Zhengke Gui, Zhongshu Zhu, Zhouyu Jiang, Ling Zhong, Yuan Qu, Peilong Zhao, Zhongpu Bo, Jin Yang, Huaidong Xiong, Lin Yuan, Jun Xu, Zaoyang Wang, Zhiqiang Zhang, Wen Zhang, Huajun Chen, Wenguang Chen, Jun Zhou

The recently developed retrieval-augmented generation (RAG) technology has
enabled the efficient construction of domain-specific applications. However, it
also has limitations, including the gap between vector similarity and the
relevance of knowledge reasoning, as well as insensitivity to knowledge logic,
such as numerical values, temporal relations, expert rules, and others, which
hinder the effectiveness of professional knowledge services. In this work, we
introduce a professional domain knowledge service framework called Knowledge
Augmented Generation (KAG). KAG is designed to address the aforementioned
challenges with the motivation of making full use of the advantages of
knowledge graph(KG) and vector retrieval, and to improve generation and
reasoning performance by bidirectionally enhancing large language models (LLMs)
and KGs through five key aspects: (1) LLM-friendly knowledge representation,
(2) mutual-indexing between knowledge graphs and original chunks, (3)
logical-form-guided hybrid reasoning engine, (4) knowledge alignment with
semantic reasoning, and (5) model capability enhancement for KAG. We compared
KAG with existing RAG methods in multihop question answering and found that it
significantly outperforms state-of-theart methods, achieving a relative
improvement of 19.6% on 2wiki and 33.5% on hotpotQA in terms of F1 score. We
have successfully applied KAG to two professional knowledge Q&A tasks of Ant
Group, including E-Government Q&A and E-Health Q&A, achieving significant
improvement in professionalism compared to RAG methods.

摘要：最近開發的檢索增強生成 (RAG) 技術已能有效建構特定領域的應用程式。然而，它也有一些限制，包括向量相似度與知識推理相關性之間的差距，以及對知識邏輯的不敏感性，例如數字值、時間關係、專家規則等，這些限制阻礙了專業知識服務的有效性。在這項工作中，我們引入了稱為知識增強生成 (KAG) 的專業領域知識服務架構。KAG 旨在解決上述挑戰，目的是充分利用知識圖 (KG) 和向量檢索的優勢，並通過以下五個關鍵方面雙向增強大型語言模型 (LLM) 和 KG 來改善生成和推理效能：(1) LLM 友善的知識表示，(2) 知識圖與原始區塊之間的相互索引，(3) 邏輯形式引導的混合推理引擎，(4) 與語義推理的知識對齊，以及 (5) KAG 的模型功能增強。我們在多跳問題解答中比較了 KAG 與現有的 RAG 方法，發現它顯著優於現有技術，在 F1 分數方面，在 2wiki 上提高了 19.6%，在 hotpotQA 上提高了 33.5%。我們已成功將 KAG 應用於螞蟻集團的兩個專業知識問答任務，包括電子政務問答和電子健康問答，與 RAG 方法相比，專業性有顯著提升。

##### **Scalable Multitask Learning Using Gradient-based Estimation of Task Affinity**
2409.06091v1 by Dongyue Li, Aneesh Sharma, Hongyang R. Zhang

Multitask learning is a widely used paradigm for training models on diverse
tasks, with applications ranging from graph neural networks to language model
fine-tuning. Since tasks may interfere with each other, a key notion for
modeling their relationships is task affinity. This includes pairwise task
affinity, computed among pairs of tasks, and higher-order affinity, computed
among subsets of tasks. Naively computing either of them requires repeatedly
training on data from various task combinations, which is computationally
intensive. We present a new algorithm Grad-TAG that can estimate task
affinities without this repeated training.
  The key idea of Grad-TAG is to train a "base" model for all tasks and then
use a linearization technique to estimate the loss of the model for a specific
task combination. The linearization works by computing a gradient-based
approximation of the loss, using low-dimensional projections of gradients as
features in a logistic regression to predict labels for the task combination.
We show that the linearized model can provably approximate the loss when the
gradient-based approximation is accurate, and also empirically verify that on
several large models. Then, given the estimated task affinity, we design a
semi-definite program for clustering similar tasks by maximizing the average
density of clusters.
  We evaluate Grad-TAG's performance across seven datasets, including
multi-label classification on graphs, and instruction fine-tuning of language
models. Our task affinity estimates are within 2.7% distance to the true
affinities while needing only 3% of FLOPs in full training. On our largest
graph with 21M edges and 500 labeling tasks, our algorithm delivers estimates
within 5% distance to the true affinities, using only 112 GPU hours. Our
results show that Grad-TAG achieves excellent performance and runtime tradeoffs
compared to existing approaches.

摘要：多任務學習是一種廣泛使用的範例，用於在不同的任務上訓練模型，其應用範圍從圖神經網路到語言模型微調。由於任務可能會相互干擾，因此建模它們關係的一個關鍵概念是任務親和性。這包括成對任務親和性，在成對任務之間計算，以及高階親和性，在任務子集之間計算。天真地計算其中任何一個都需要重複訓練來自各種任務組合的資料，這在計算上很密集。我們提出了一種新的演算法 Grad-TAG，它可以在沒有重複訓練的情況下估計任務親和性。
Grad-TAG 的關鍵思想是為所有任務訓練一個「基礎」模型，然後使用線性化技術來估計模型對特定任務組合的損失。線性化通過計算損失的基於梯度的近似值來工作，使用梯度的低維投影作為特徵，在邏輯迴歸中預測任務組合的標籤。我們證明了當基於梯度的近似值準確時，線性化模型可以證明地近似損失，並且在幾個大型模型上經驗驗證了這一點。然後，給定估計的任務親和性，我們設計了一個半定程式，通過最大化叢集的平均密度來對類似的任務進行叢集。
我們評估了 Grad-TAG 在七個資料集上的效能，包括圖形上的多標籤分類，以及語言模型的指令微調。我們的任務親和性估計與真實親和性距離在 2.7% 以內，同時只需要 3% 的 FLOP 進行完整訓練。在我們最大的圖形（有 2100 萬條邊和 500 個標籤任務）上，我們的演算法提供的估計與真實親和性距離在 5% 以內，只使用 112 個 GPU 小時。我們的結果表明，與現有方法相比，Grad-TAG 在效能和執行時間權衡方面取得了優異的表現。

##### **OneEdit: A Neural-Symbolic Collaboratively Knowledge Editing System**
2409.07497v1 by Ningyu Zhang, Zekun Xi, Yujie Luo, Peng Wang, Bozhong Tian, Yunzhi Yao, Jintian Zhang, Shumin Deng, Mengshu Sun, Lei Liang, Zhiqiang Zhang, Xiaowei Zhu, Jun Zhou, Huajun Chen

Knowledge representation has been a central aim of AI since its inception.
Symbolic Knowledge Graphs (KGs) and neural Large Language Models (LLMs) can
both represent knowledge. KGs provide highly accurate and explicit knowledge
representation, but face scalability issue; while LLMs offer expansive coverage
of knowledge, but incur significant training costs and struggle with precise
and reliable knowledge manipulation. To this end, we introduce OneEdit, a
neural-symbolic prototype system for collaborative knowledge editing using
natural language, which facilitates easy-to-use knowledge management with KG
and LLM. OneEdit consists of three modules: 1) The Interpreter serves for user
interaction with natural language; 2) The Controller manages editing requests
from various users, leveraging the KG with rollbacks to handle knowledge
conflicts and prevent toxic knowledge attacks; 3) The Editor utilizes the
knowledge from the Controller to edit KG and LLM. We conduct experiments on two
new datasets with KGs which demonstrate that OneEdit can achieve superior
performance.

摘要：知識表徵自人工智慧誕生以來一直是其核心目標。
符號知識圖譜 (KG) 和神經語言大模型 (LLM) 都可以表徵知識。KG 提供高度準確且明確的知識表徵，但面臨可擴充性的問題；而 LLM 提供廣泛的知識涵蓋範圍，但會產生大量的訓練成本，並且在精確且可靠的知識操作方面遇到困難。為了解決這個問題，我們引入了 OneEdit，這是一個使用自然語言進行協作知識編輯的神經符號原型系統，它促進了使用 KG 和 LLM 進行易於使用的知識管理。OneEdit 包含三個模組：1) 解譯器用於使用者透過自然語言進行互動；2) 控制器管理來自不同使用者的編輯請求，利用 KG 和回滾來處理知識衝突並防止有毒的知識攻擊；3) 編輯器利用來自控制器的知識來編輯 KG 和 LLM。我們對兩個具有 KG 的新資料集進行了實驗，證明 OneEdit 可以實現優異的效能。

##### **SciAgents: Automating scientific discovery through multi-agent intelligent graph reasoning**
2409.05556v1 by Alireza Ghafarollahi, Markus J. Buehler

A key challenge in artificial intelligence is the creation of systems capable
of autonomously advancing scientific understanding by exploring novel domains,
identifying complex patterns, and uncovering previously unseen connections in
vast scientific data. In this work, we present SciAgents, an approach that
leverages three core concepts: (1) the use of large-scale ontological knowledge
graphs to organize and interconnect diverse scientific concepts, (2) a suite of
large language models (LLMs) and data retrieval tools, and (3) multi-agent
systems with in-situ learning capabilities. Applied to biologically inspired
materials, SciAgents reveals hidden interdisciplinary relationships that were
previously considered unrelated, achieving a scale, precision, and exploratory
power that surpasses traditional human-driven research methods. The framework
autonomously generates and refines research hypotheses, elucidating underlying
mechanisms, design principles, and unexpected material properties. By
integrating these capabilities in a modular fashion, the intelligent system
yields material discoveries, critique and improve existing hypotheses, retrieve
up-to-date data about existing research, and highlights their strengths and
limitations. Our case studies demonstrate scalable capabilities to combine
generative AI, ontological representations, and multi-agent modeling,
harnessing a `swarm of intelligence' similar to biological systems. This
provides new avenues for materials discovery and accelerates the development of
advanced materials by unlocking Nature's design principles.

摘要：在人工智能中，一個關鍵的挑戰是創造出有能力透過探索新領域、識別複雜模式，以及在大量的科學數據中發現前所未見的關聯，來自主推進科學理解的系統。在這項工作中，我們提出了 SciAgents，一種利用三個核心概念的方法：(1) 使用大規模的本体知識圖譜來整理和連結不同的科學概念，(2) 一套大型語言模型 (LLM) 和數據檢索工具，以及 (3) 具有原位學習能力的多代理系統。應用於生物啟發材料，SciAgents 揭示了以前被認為無關的隱藏跨學科關係，達到了超越傳統人為研究方法的規模、精確度和探索能力。該框架自主生成和優化研究假設，闡明基礎機制、設計原理和意外的材料特性。透過以模組化方式整合這些能力，智能系統產生材料發現、批判和改進現有假設、檢索關於現有研究的最新數據，並強調它們的優點和限制。我們的案例研究展示了結合生成式 AI、本体表示和多代理建模的可擴充能力，利用類似於生物系統的「智慧群體」。這為材料發現提供了新途徑，並透過解鎖大自然的設計原理來加速先進材料的開發。

##### **Assessing SPARQL capabilities of Large Language Models**
2409.05925v1 by Lars-Peter Meyer, Johannes Frey, Felix Brei, Natanael Arndt

The integration of Large Language Models (LLMs) with Knowledge Graphs (KGs)
offers significant synergistic potential for knowledge-driven applications. One
possible integration is the interpretation and generation of formal languages,
such as those used in the Semantic Web, with SPARQL being a core technology for
accessing KGs. In this paper, we focus on measuring out-of-the box capabilities
of LLMs to work with SPARQL and more specifically with SPARQL SELECT queries
applying a quantitative approach.
  We implemented various benchmarking tasks in the LLM-KG-Bench framework for
automated execution and evaluation with several LLMs. The tasks assess
capabilities along the dimensions of syntax, semantic read, semantic create,
and the role of knowledge graph prompt inclusion.
  With this new benchmarking tasks, we evaluated a selection of GPT, Gemini,
and Claude models. Our findings indicate that working with SPARQL SELECT
queries is still challenging for LLMs and heavily depends on the specific LLM
as well as the complexity of the task. While fixing basic syntax errors seems
to pose no problems for the best of the current LLMs evaluated, creating
semantically correct SPARQL SELECT queries is difficult in several cases.

摘要：大型語言模型 (LLM) 與知識圖譜 (KG) 的整合為知識驅動應用程式提供了顯著的綜效潛力。一種可能的整合是解釋和產生形式化語言，例如語義網路中使用的語言，而 SPARQL 是存取 KG 的核心技術。在本文中，我們專注於衡量 LLM 開箱即用的能力，以使用 SPARQL，更具體地說，使用 SPARQL SELECT 查詢應用量化方法。
  我們在 LLM-KG-Bench 架構中實作了各種基準測試任務，以自動執行和評估多個 LLM。這些任務評估了語法、語義讀取、語義建立和知識圖譜提示包含的角色等面向的能力。
  有了這些新的基準測試任務，我們評估了 GPT、Gemini 和 Claude 模型的選項。我們的研究結果表明，使用 SPARQL SELECT 查詢對於 LLM 來說仍然具有挑戰性，並且在很大程度上取決於具體的 LLM 以及任務的複雜性。儘管修復基本的語法錯誤似乎對目前評估的最佳 LLM 來說不成問題，但在某些情況下建立語義正確的 SPARQL SELECT 查詢很困難。

##### **KARGEN: Knowledge-enhanced Automated Radiology Report Generation Using Large Language Models**
2409.05370v1 by Yingshu Li, Zhanyu Wang, Yunyi Liu, Lei Wang, Lingqiao Liu, Luping Zhou

Harnessing the robust capabilities of Large Language Models (LLMs) for
narrative generation, logical reasoning, and common-sense knowledge
integration, this study delves into utilizing LLMs to enhance automated
radiology report generation (R2Gen). Despite the wealth of knowledge within
LLMs, efficiently triggering relevant knowledge within these large models for
specific tasks like R2Gen poses a critical research challenge. This paper
presents KARGEN, a Knowledge-enhanced Automated radiology Report GENeration
framework based on LLMs. Utilizing a frozen LLM to generate reports, the
framework integrates a knowledge graph to unlock chest disease-related
knowledge within the LLM to enhance the clinical utility of generated reports.
This is achieved by leveraging the knowledge graph to distill disease-related
features in a designed way. Since a radiology report encompasses both normal
and disease-related findings, the extracted graph-enhanced disease-related
features are integrated with regional image features, attending to both
aspects. We explore two fusion methods to automatically prioritize and select
the most relevant features. The fused features are employed by LLM to generate
reports that are more sensitive to diseases and of improved quality. Our
approach demonstrates promising results on the MIMIC-CXR and IU-Xray datasets.

摘要：<paragraph>利用大型語言模型 (LLM) 強大的功能，進行敘事生成、邏輯推理和常識知識整合，本研究深入探討利用 LLM 來增強自動化放射報告生成 (R2Gen)。儘管 LLM 擁有豐富的知識，但要有效觸發這些大型模型中與特定任務（如 R2Gen）相關的知識，是一個重要的研究挑戰。本文提出了 KARGEN，一個基於 LLM 的知識增強自動化放射報告生成框架。利用凍結的 LLM 來生成報告，該框架整合了一個知識圖譜，以解鎖 LLM 中與胸部疾病相關的知識，以增強生成報告的臨床效用。這是透過利用知識圖譜以設計的方式提取與疾病相關的特徵來實現的。由於放射報告包含正常和疾病相關的發現，因此提取的圖形增強疾病相關特徵與區域影像特徵整合，兼顧兩個方面。我們探索了兩種融合方法，以自動優先排序和選擇最相關的特徵。融合的特徵由 LLM 使用，以生成對疾病更敏感且品質更高的報告。我們的做法在 MIMIC-CXR 和 IU-Xray 資料集上展示了有希望的結果。</paragraph>

##### **Action is the primary key: a categorical framework for episode description and logical reasoning**
2409.04793v1 by Yoshiki Fukada

This research presents a computational framework for describing and
recognizing episodes and for logical reasoning. This framework, named
cognitive-logs, consists of a set of relational and graph databases.
Cognitive-logs record knowledge, particularly in episodes that consist of
"actions" represented by verbs in natural languages and "participants" who
perform the actions. These objects are connected by arrows (morphisms) that
link each action to its participant and link cause to effect. Operations based
on category theory enable comparisons between episodes and deductive
inferences, including abstractions of stories. One of the goals of this study
is to develop a database-driven artificial intelligence. This artificial
intelligence thinks like a human but possesses the accuracy and rigour of a
machine. The vast capacities of databases (up to petabyte scales in current
technologies) enable the artificial intelligence to store a greater volume of
knowledge than neural-network based artificial intelligences. Cognitive-logs
serve as a model of human cognition and designed with references to cognitive
linguistics. Cognitive-logs also have the potential to model various human mind
activities.

摘要：本研究提出一個計算框架，用來描述和辨識事件以及進行邏輯推理。這個框架名為認知日誌，包含一組關聯式和圖形資料庫。認知日誌記錄知識，特別是包含由自然語言中的動詞表示的「動作」和執行動作的「參與者」的事件。這些物件由箭頭（態射）連接，將每個動作連結到其參與者，並將原因連結到結果。基於範疇論的運算可比較事件和演繹推論，包括故事的抽象化。本研究的目標之一是開發一個資料庫驅動的人工智慧。這個人工智慧思考方式像人類，但擁有機器般的準確性和嚴謹性。資料庫的龐大容量（在目前的技術中可達皮位元組等級）使人工智慧能夠儲存比基於神經網路的人工智慧更大的知識量。認知日誌作為人類認知的模型，並參考認知語言學進行設計。認知日誌也有潛力模擬各種人類心智活動。

##### **Accelerating Training with Neuron Interaction and Nowcasting Networks**
2409.04434v1 by Boris Knyazev, Abhinav Moudgil, Guillaume Lajoie, Eugene Belilovsky, Simon Lacoste-Julien

Neural network training can be accelerated when a learnable update rule is
used in lieu of classic adaptive optimizers (e.g. Adam). However, learnable
update rules can be costly and unstable to train and use. A simpler recently
proposed approach to accelerate training is to use Adam for most of the
optimization steps and periodically, only every few steps, nowcast (predict
future) parameters. We improve this approach by Neuron interaction and
Nowcasting (NiNo) networks. NiNo leverages neuron connectivity and graph neural
networks to more accurately nowcast parameters by learning in a supervised way
from a set of training trajectories over multiple tasks. We show that in some
networks, such as Transformers, neuron connectivity is non-trivial. By
accurately modeling neuron connectivity, we allow NiNo to accelerate Adam
training by up to 50\% in vision and language tasks.

摘要：神经网络训练可以加速，当一个可学习的更新规则被用来代替经典的自适应优化器（例如 Adam）。然而，可学习的更新规则可能是昂贵且不稳定的，需要训练和使用。一种最近提出的更简单的加速训练的方法是，对于大多数的优化步骤使用 Adam，并且定期地，仅每隔几步，预测（预测未来）参数。我们通过神经元交互和预测（NiNo）网络来改进这种方法。NiNo 利用神经元连接和图神经网络，通过从多个任务中的一组训练轨迹中以监督方式学习，更准确地预测参数。我们表明，在一些网络中，例如 Transformer，神经元连接是非平凡的。通过准确地建模神经元连接，我们允许 NiNo 将 Adam 训练加速高达 50%，用于视觉和语言任务。

##### **Using Large Language Models to Generate Authentic Multi-agent Knowledge Work Datasets**
2409.04286v1 by Desiree Heim, Christian Jilek, Adrian Ulges, Andreas Dengel

Current publicly available knowledge work data collections lack diversity,
extensive annotations, and contextual information about the users and their
documents. These issues hinder objective and comparable data-driven evaluations
and optimizations of knowledge work assistance systems. Due to the considerable
resources needed to collect such data in real-life settings and the necessity
of data censorship, collecting such a dataset appears nearly impossible. For
this reason, we propose a configurable, multi-agent knowledge work dataset
generator. This system simulates collaborative knowledge work among agents
producing Large Language Model-generated documents and accompanying data
traces. Additionally, the generator captures all background information, given
in its configuration or created during the simulation process, in a knowledge
graph. Finally, the resulting dataset can be utilized and shared without
privacy or confidentiality concerns.
  This paper introduces our approach's design and vision and focuses on
generating authentic knowledge work documents using Large Language Models. Our
study involving human raters who assessed 53% of the generated and 74% of the
real documents as realistic demonstrates the potential of our approach.
Furthermore, we analyze the authenticity criteria mentioned in the
participants' comments and elaborate on potential improvements for identified
common issues.

摘要：<paragraph>目前公開可用的知識工作資料蒐集缺乏多元性、廣泛註解和使用者及其文件背景資訊。這些問題阻礙了客觀且可比較的資料驅動評估，以及知識工作協助系統的最佳化。由於在現實生活中蒐集此類資料需要大量資源，而且必須審查資料，蒐集此類資料組顯然幾乎不可能。因此，我們提出一個可設定的多重代理知識工作資料組產生器。此系統模擬代理之間的協作知識工作，產生大型語言模型產生的文件和隨附的資料追蹤。此外，產生器會擷取所有背景資訊，在組態中提供或在模擬過程中建立，並將其儲存在知識圖譜中。最後，產生的資料組可以使用和分享，無須擔心隱私或機密性。
本文介紹我們方法的設計和願景，並專注於使用大型語言模型產生真實的知識工作文件。我們的研究涉及人類評分員，他們評估了 53% 的產生文件和 74% 的真實文件為真實，這證明了我們方法的潛力。此外，我們分析參與者評論中提到的真實性標準，並詳細說明已識別常見問題的潛在改善方法。</paragraph>

##### **GALLa: Graph Aligned Large Language Models for Improved Source Code Understanding**
2409.04183v1 by Ziyin Zhang, Hang Yu, Shijie Li, Peng Di, Jianguo Li, Rui Wang

Programming languages possess rich semantic information such as data flow
that is represented by graphs and not available from the surface form of source
code. Recent code language models have scaled to billions of parameters, but
model source code solely as text tokens while ignoring any other structural
information. Conversely, models that do encode structural information of code
make modifications to the Transformer architecture, limiting their scale and
compatibility with pretrained LLMs. In this work, we take the best of both
worlds with GALLa - Graph Aligned Large Language Model. GALLa utilizes graph
neural networks and cross-modal alignment technologies to inject the structural
information of code into LLMs as an auxiliary task during finetuning. This
framework is both model-agnostic and task-agnostic, as it can be applied to any
code LLM for any code downstream task, and requires the structural graph data
only at training time from a corpus unrelated to the finetuning data, while
incurring no cost at inference time over the baseline LLM. Experiments on five
code tasks with four different baseline LLMs ranging in size from 350M to 8B
validate the effectiveness of GALLa, demonstrating consistent improvement over
the baseline, even for powerful models such as LLaMA3.

摘要：程式語言擁有豐富的語意資訊，例如由圖形表示且無法從原始碼表面形式取得的資料流程。最近的程式碼語言模型已擴充至數十億個參數，但模型原始碼僅作為文字符號，而忽略任何其他結構資訊。反之，編碼程式碼結構資訊的模型會修改 Transformer 架構，限制其規模和與預先訓練的 LLM 的相容性。在這項工作中，我們採用 GALLa（圖形對齊大型語言模型）擷取兩全其美的優點。GALLa 利用圖形神經網路和跨模態對齊技術，在微調期間將程式碼的結構資訊注入 LLM 作為輔助任務。此架構同時不依賴模型和任務，因為它可以應用於任何程式碼 LLM 的任何程式碼下游任務，並且僅在訓練期間從與微調資料無關的語料庫取得結構圖形資料，同時在推論期間不產生比基準 LLM 更高的成本。在五個程式碼任務中進行實驗，使用四個不同的基準 LLM，規模從 350M 到 8B，驗證 GALLa 的有效性，證明即使對於 LLaMA3 等強大模型，也能持續優於基準。

##### **Combining LLMs and Knowledge Graphs to Reduce Hallucinations in Question Answering**
2409.04181v1 by Larissa Pusch, Tim O. F. Conrad

Advancements in natural language processing have revolutionized the way we
can interact with digital information systems, such as databases, making them
more accessible. However, challenges persist, especially when accuracy is
critical, as in the biomedical domain. A key issue is the hallucination
problem, where models generate information unsupported by the underlying data,
potentially leading to dangerous misinformation. This paper presents a novel
approach designed to bridge this gap by combining Large Language Models (LLM)
and Knowledge Graphs (KG) to improve the accuracy and reliability of
question-answering systems, on the example of a biomedical KG. Built on the
LangChain framework, our method incorporates a query checker that ensures the
syntactical and semantic validity of LLM-generated queries, which are then used
to extract information from a Knowledge Graph, substantially reducing errors
like hallucinations. We evaluated the overall performance using a new benchmark
dataset of 50 biomedical questions, testing several LLMs, including GPT-4 Turbo
and llama3:70b. Our results indicate that while GPT-4 Turbo outperforms other
models in generating accurate queries, open-source models like llama3:70b show
promise with appropriate prompt engineering. To make this approach accessible,
a user-friendly web-based interface has been developed, allowing users to input
natural language queries, view generated and corrected Cypher queries, and
verify the resulting paths for accuracy. Overall, this hybrid approach
effectively addresses common issues such as data gaps and hallucinations,
offering a reliable and intuitive solution for question answering systems. The
source code for generating the results of this paper and for the user-interface
can be found in our Git repository: https://git.zib.de/lpusch/cyphergenkg-gui

摘要：自然語言處理的進展徹底改變了我們與數位資訊系統（例如資料庫）互動的方式，讓這些系統變得更易於存取。然而，挑戰仍然存在，尤其是在準確性至關重要的情況下，例如在生物醫學領域。一個關鍵問題是幻覺問題，其中模型會產生未經基礎資料驗證的資訊，可能導致危險的錯誤資訊。本文提出了一種新穎的方法，旨在透過結合大型語言模型 (LLM) 和知識圖譜 (KG) 來彌補這個差距，以提高生物醫學 KG 中問答系統的準確性和可靠性。我們的技術建立在 LangChain 框架上，結合了一個查詢檢查器，可確保 LLM 生成的查詢在語法和語意上有效，然後用於從知識圖譜中萃取資訊，大幅減少幻覺等錯誤。我們使用一個新的 50 個生物醫學問題基準資料集評估了整體效能，測試了包括 GPT-4 Turbo 和 llama3:70b 在內的幾個 LLM。我們的結果顯示，雖然 GPT-4 Turbo 在產生準確查詢方面優於其他模型，但像 llama3:70b 這樣的開源模型在適當的提示工程下顯示出前景。為了讓這種方法易於使用，我們開發了一個使用者友善的網路介面，讓使用者可以輸入自然語言查詢、檢視產生和更正的 Cypher 查詢，並驗證結果路徑的準確性。總體而言，這種混合方法有效地解決了資料差距和幻覺等常見問題，為問答系統提供了一個可靠且直觀的解決方案。本文結果產生的原始碼和使用者介面的原始碼可以在我們的 Git 儲存庫中找到：https://git.zib.de/lpusch/cyphergenkg-gui

##### **Refining Wikidata Taxonomy using Large Language Models**
2409.04056v1 by Yiwen Peng, Thomas Bonald, Mehwish Alam

Due to its collaborative nature, Wikidata is known to have a complex
taxonomy, with recurrent issues like the ambiguity between instances and
classes, the inaccuracy of some taxonomic paths, the presence of cycles, and
the high level of redundancy across classes. Manual efforts to clean up this
taxonomy are time-consuming and prone to errors or subjective decisions. We
present WiKC, a new version of Wikidata taxonomy cleaned automatically using a
combination of Large Language Models (LLMs) and graph mining techniques.
Operations on the taxonomy, such as cutting links or merging classes, are
performed with the help of zero-shot prompting on an open-source LLM. The
quality of the refined taxonomy is evaluated from both intrinsic and extrinsic
perspectives, on a task of entity typing for the latter, showing the practical
interest of WiKC.

摘要：由於其協作性質，Wikidata 已知具有複雜的分類法，並有重複發生的問題，例如實例和類別之間的歧義、某些分類路徑的不準確性、循環的存在，以及類別之間的高冗餘。手動清理此分類法的工作既耗時又容易出現錯誤或主觀判斷。我們提出 WiKC，這是 Wikidata 分類法的新版本，使用大型語言模型 (LLM) 和圖形挖掘技術自動清理。分類法上的操作，例如剪切鏈接或合併類別，是在開源 LLM 上借助零次提示的幫助下執行的。精煉分類法的品質從內在和外在的觀點進行評估，在後者的實體分型任務上，顯示了 WiKC 的實際興趣。

##### **Large Margin Prototypical Network for Few-shot Relation Classification with Fine-grained Features**
2409.04009v1 by Miao Fan, Yeqi Bai, Mingming Sun, Ping Li

Relation classification (RC) plays a pivotal role in both natural language
understanding and knowledge graph completion. It is generally formulated as a
task to recognize the relationship between two entities of interest appearing
in a free-text sentence. Conventional approaches on RC, regardless of feature
engineering or deep learning based, can obtain promising performance on
categorizing common types of relation leaving a large proportion of
unrecognizable long-tail relations due to insufficient labeled instances for
training. In this paper, we consider few-shot learning is of great practical
significance to RC and thus improve a modern framework of metric learning for
few-shot RC. Specifically, we adopt the large-margin ProtoNet with fine-grained
features, expecting they can generalize well on long-tail relations. Extensive
experiments were conducted by FewRel, a large-scale supervised few-shot RC
dataset, to evaluate our framework: LM-ProtoNet (FGF). The results demonstrate
that it can achieve substantial improvements over many baseline approaches.

摘要：關係分類 (RC) 在自然語言理解和知識圖譜完成中扮演著關鍵角色。它通常被表述為一個任務，用於辨識出現在自由文字句子中的兩個感興趣實體之間的關係。無論是基於特徵工程還是深度學習的傳統 RC 方法，都可以對常見的關係類型進行分類，從而獲得有希望的效能，但由於訓練標籤實例不足，因此無法辨識出大量的長尾關係。在本文中，我們認為少樣本學習對 RC 具有重要的實用意義，因此改進了度量學習的現代框架，以進行少樣本 RC。具體來說，我們採用具有細粒度特徵的大邊距 ProtoNet，期望它們能在長尾關係上很好地概括。我們使用大型監督少樣本 RC 資料集 FewRel 進行了廣泛的實驗，以評估我們的框架：LM-ProtoNet (FGF)。結果表明，它可以比許多基線方法獲得顯著改進。

##### **Rx Strategist: Prescription Verification using LLM Agents System**
2409.03440v1 by Phuc Phan Van, Dat Nguyen Minh, An Dinh Ngoc, Huy Phan Thanh

To protect patient safety, modern pharmaceutical complexity demands strict
prescription verification. We offer a new approach - Rx Strategist - that makes
use of knowledge graphs and different search strategies to enhance the power of
Large Language Models (LLMs) inside an agentic framework. This multifaceted
technique allows for a multi-stage LLM pipeline and reliable information
retrieval from a custom-built active ingredient database. Different facets of
prescription verification, such as indication, dose, and possible drug
interactions, are covered in each stage of the pipeline. We alleviate the
drawbacks of monolithic LLM techniques by spreading reasoning over these
stages, improving correctness and reliability while reducing memory demands.
Our findings demonstrate that Rx Strategist surpasses many current LLMs,
achieving performance comparable to that of a highly experienced clinical
pharmacist. In the complicated world of modern medications, this combination of
LLMs with organized knowledge and sophisticated search methods presents a
viable avenue for reducing prescription errors and enhancing patient outcomes.

摘要：為了保護患者安全，現代藥品複雜性要求嚴格的處方驗證。我們提供一種新方法 - Rx Strategist - 它利用知識圖譜和不同的搜尋策略來增強代理架構內大型語言模型 (LLM) 的功能。這種多方面的技術允許多階段的 LLM 管線和從自訂主動成分資料庫中可靠地擷取資訊。處方驗證的不同面向，例如適應症、劑量和可能的藥物交互作用，都在管線的每個階段中涵蓋。我們透過將推理分散在這些階段來減輕單一 LLM 技術的缺點，同時提高正確性和可靠性，並減少記憶體需求。我們的研究結果表明，Rx Strategist 超越許多現有的 LLM，達到與經驗豐富的臨床藥劑師相當的表現。在現代藥物複雜的世界中，這種將 LLM 與有組織的知識和先進搜尋方法相結合，為減少處方錯誤和改善患者預後提供了可行的途徑。

##### **iText2KG: Incremental Knowledge Graphs Construction Using Large Language Models**
2409.03284v1 by Yassir Lairgi, Ludovic Moncla, Rémy Cazabet, Khalid Benabdeslem, Pierre Cléau

Most available data is unstructured, making it challenging to access valuable
information. Automatically building Knowledge Graphs (KGs) is crucial for
structuring data and making it accessible, allowing users to search for
information effectively. KGs also facilitate insights, inference, and
reasoning. Traditional NLP methods, such as named entity recognition and
relation extraction, are key in information retrieval but face limitations,
including the use of predefined entity types and the need for supervised
learning. Current research leverages large language models' capabilities, such
as zero- or few-shot learning. However, unresolved and semantically duplicated
entities and relations still pose challenges, leading to inconsistent graphs
and requiring extensive post-processing. Additionally, most approaches are
topic-dependent. In this paper, we propose iText2KG, a method for incremental,
topic-independent KG construction without post-processing. This plug-and-play,
zero-shot method is applicable across a wide range of KG construction scenarios
and comprises four modules: Document Distiller, Incremental Entity Extractor,
Incremental Relation Extractor, and Graph Integrator and Visualization. Our
method demonstrates superior performance compared to baseline methods across
three scenarios: converting scientific papers to graphs, websites to graphs,
and CVs to graphs.

摘要：大部分可用資料為非結構化，這使得存取有價值的資訊變得具有挑戰性。自動建立知識圖譜 (KG) 對於結構化資料和讓資料易於存取至關重要，讓使用者能夠有效地搜尋資訊。KG 也促進見解、推論和推理。傳統的 NLP 方法，例如命名實體辨識和關係萃取，在資訊檢索中是關鍵，但面臨限制，包括使用預定義的實體類型和需要監督式學習。目前的研究所利用大型語言模型的能力，例如零次或少次學習。然而，未解決和語義重複的實體和關係仍然構成挑戰，導致圖形不一致，需要廣泛的後處理。此外，大多數方法都依賴於主題。在本文中，我們提出 iText2KG，一種用於漸進式、與主題無關的 KG 建構方法，無需後處理。這種即插即用、零次的方法適用於廣泛的 KG 建構場景，並包含四個模組：文件精餾器、漸進式實體萃取器、漸進式關係萃取器，以及圖形整合器和視覺化器。與基線方法相比，我們的模型在三種場景中展現出卓越的效能：將科學論文轉換為圖形、網站轉換為圖形，以及履歷轉換為圖形。

##### **GraphInsight: Unlocking Insights in Large Language Models for Graph Structure Understanding**
2409.03258v1 by Yukun Cao, Shuo Han, Zengyi Gao, Zezhong Ding, Xike Xie, S. Kevin Zhou

Although Large Language Models (LLMs) have demonstrated potential in
processing graphs, they struggle with comprehending graphical structure
information through prompts of graph description sequences, especially as the
graph size increases. We attribute this challenge to the uneven memory
performance of LLMs across different positions in graph description sequences,
known as ''positional biases''. To address this, we propose GraphInsight, a
novel framework aimed at improving LLMs' comprehension of both macro- and
micro-level graphical information. GraphInsight is grounded in two key
strategies: 1) placing critical graphical information in positions where LLMs
exhibit stronger memory performance, and 2) investigating a lightweight
external knowledge base for regions with weaker memory performance, inspired by
retrieval-augmented generation (RAG). Moreover, GraphInsight explores
integrating these two strategies into LLM agent processes for composite graph
tasks that require multi-step reasoning. Extensive empirical studies on
benchmarks with a wide range of evaluation tasks show that GraphInsight
significantly outperforms all other graph description methods (e.g., prompting
techniques and reordering strategies) in understanding graph structures of
varying sizes.

摘要：儘管大型語言模型 (LLM) 已展現出處理圖形的能力，但它們在透過圖形描述序列提示理解圖形結構資訊時會遇到困難，特別是在圖形大小增加時。我們將此挑戰歸因於 LLM 在圖形描述序列中不同位置的記憶力表現不均，稱為「位置偏誤」。為了解決這個問題，我們提出了 GraphInsight，一個旨在改善 LLM 對巨觀和微觀層級圖形資訊理解的新框架。GraphInsight 以兩個關鍵策略為基礎：1) 將關鍵圖形資訊放置在 LLM 展現較強記憶力表現的位置，以及 2) 調查一個受到檢索增強生成 (RAG) 啟發的、針對記憶力表現較弱區域的輕量級外部知識庫。此外，GraphInsight 探索將這兩個策略整合到 LLM 代理程序中，以處理需要多步驟推理的複合圖形任務。在具有廣泛評量任務的基準上進行的廣泛實證研究顯示，GraphInsight 在理解各種大小的圖形結構方面，明顯優於所有其他圖形描述方法（例如提示技巧和重新排序策略）。

##### **Debate on Graph: a Flexible and Reliable Reasoning Framework for Large Language Models**
2409.03155v1 by Jie Ma, Zhitao Gao, Qi Chai, Wangchun Sun, Pinghui Wang, Hongbin Pei, Jing Tao, Lingyun Song, Jun Liu, Chen Zhang, Lizhen Cui

Large Language Models (LLMs) may suffer from hallucinations in real-world
applications due to the lack of relevant knowledge. In contrast, knowledge
graphs encompass extensive, multi-relational structures that store a vast array
of symbolic facts. Consequently, integrating LLMs with knowledge graphs has
been extensively explored, with Knowledge Graph Question Answering (KGQA)
serving as a critical touchstone for the integration. This task requires LLMs
to answer natural language questions by retrieving relevant triples from
knowledge graphs. However, existing methods face two significant challenges:
\textit{excessively long reasoning paths distracting from the answer
generation}, and \textit{false-positive relations hindering the path
refinement}. In this paper, we propose an iterative interactive KGQA framework
that leverages the interactive learning capabilities of LLMs to perform
reasoning and Debating over Graphs (DoG). Specifically, DoG employs a
subgraph-focusing mechanism, allowing LLMs to perform answer trying after each
reasoning step, thereby mitigating the impact of lengthy reasoning paths. On
the other hand, DoG utilizes a multi-role debate team to gradually simplify
complex questions, reducing the influence of false-positive relations. This
debate mechanism ensures the reliability of the reasoning process. Experimental
results on five public datasets demonstrate the effectiveness and superiority
of our architecture. Notably, DoG outperforms the state-of-the-art method ToG
by 23.7\% and 9.1\% in accuracy on WebQuestions and GrailQA, respectively.
Furthermore, the integration experiments with various LLMs on the mentioned
datasets highlight the flexibility of DoG. Code is available at
\url{https://github.com/reml-group/DoG}.

摘要：<paragraph>大型語言模型 (LLM) 由於缺乏相關知識，在實際應用中可能會產生幻覺。相較之下，知識圖譜包含廣泛的多重關係結構，儲存大量符號事實。因此，將 LLM 與知識圖譜整合已廣泛探討，其中知識圖譜問題解答 (KGQA) 成為整合的重要試金石。此任務要求 LLM 透過從知識圖譜中擷取相關三元組來回答自然語言問題。然而，現有方法面臨兩項重大挑戰：\textit{過長的推理路徑會分散回答產生}，以及\textit{錯誤正向關係阻礙路徑精煉}。在本文中，我們提出一個反覆互動的 KGQA 框架，它利用 LLM 的互動學習能力來執行推理和圖形辯論 (DoG)。具體來說，DoG 採用子圖聚焦機制，允許 LLM 在每個推理步驟後執行答案嘗試，從而減輕冗長推理路徑的影響。另一方面，DoG 利用多角色辯論小組逐漸簡化複雜問題，減少錯誤正向關係的影響。這種辯論機制確保了推理過程的可靠性。在五個公共數據集上的實驗結果證明了我們架構的有效性和優越性。值得注意的是，DoG 在 WebQuestions 和 GrailQA 上的準確度分別比最先進的方法 ToG 高出 23.7% 和 9.1%。此外，在上述數據集上與各種 LLM 的整合實驗突顯了 DoG 的靈活性。程式碼可在\url{https://github.com/reml-group/DoG}取得。</paragraph>

##### **Word and Phrase Features in Graph Convolutional Network for Automatic Question Classification**
2409.02481v1 by Junyoung Lee, Ninad Dixit, Kaustav Chakrabarti, S. Supraja

Effective question classification is crucial for AI-driven educational tools,
enabling adaptive learning systems to categorize questions by skill area,
difficulty level, and competence. This classification not only supports
educational diagnostics and analytics but also enhances complex tasks like
information retrieval and question answering by associating questions with
relevant categories. Traditional methods, often based on word embeddings and
conventional classifiers, struggle to capture the nuanced relationships in
natural language, leading to suboptimal performance. To address this, we
propose a novel approach leveraging graph convolutional networks (GCNs), named
Phrase Question-Graph Convolutional Network (PQ-GCN) to better model the
inherent structure of questions. By representing questions as graphs -- where
nodes signify words or phrases and edges denote syntactic or semantic
relationships -- our method allows GCNs to learn from the interconnected nature
of language more effectively. Additionally, we explore the incorporation of
phrase-based features to enhance classification accuracy, especially in
low-resource settings. Our findings demonstrate that GCNs, augmented with these
features, offer a promising solution for more accurate and context-aware
question classification, bridging the gap between graph neural network research
and practical educational applications.

摘要：有效的問題分類對於 AI 驅動的教育工具至關重要，
讓適應性學習系統能依據技能領域、
難度等級和能力對問題進行分類。這種分類不僅支援
教育診斷和分析，還能透過將問題與
相關類別關聯起來，增強資訊檢索和問題解答等複雜任務。傳統方法通常建立在詞嵌入和
傳統分類器上，難以捕捉自然語言中的細微關係，導致次佳效能。為了解決這個問題，我們
提出了一種創新的方法，利用圖形卷積網路 (GCN)，稱為
Phrase Question-Graph Convolutional Network (PQ-GCN) 來更好地建模問題的內在結構。透過將問題表示為圖形——其中
節點表示詞或詞組，邊緣表示語法或語義關係——我們的模型允許 GCN 更有效地從語言的相互連結性質中學習。此外，我們探索了整合
基於詞組的特徵以增強分類準確度，特別是在
低資源設定中。我們的研究結果表明，GCN 在這些
特徵的增強下，為更準確且具備情境感知能力的問題分類提供了一個有前途的解決方案，縮小了圖形神經網路研究
與實際教育應用之間的差距。

##### **Multi-modal Situated Reasoning in 3D Scenes**
2409.02389v1 by Xiongkun Linghu, Jiangyong Huang, Xuesong Niu, Xiaojian Ma, Baoxiong Jia, Siyuan Huang

Situation awareness is essential for understanding and reasoning about 3D
scenes in embodied AI agents. However, existing datasets and benchmarks for
situated understanding are limited in data modality, diversity, scale, and task
scope. To address these limitations, we propose Multi-modal Situated Question
Answering (MSQA), a large-scale multi-modal situated reasoning dataset,
scalably collected leveraging 3D scene graphs and vision-language models (VLMs)
across a diverse range of real-world 3D scenes. MSQA includes 251K situated
question-answering pairs across 9 distinct question categories, covering
complex scenarios within 3D scenes. We introduce a novel interleaved
multi-modal input setting in our benchmark to provide text, image, and point
cloud for situation and question description, resolving ambiguity in previous
single-modality convention (e.g., text). Additionally, we devise the
Multi-modal Situated Next-step Navigation (MSNN) benchmark to evaluate models'
situated reasoning for navigation. Comprehensive evaluations on MSQA and MSNN
highlight the limitations of existing vision-language models and underscore the
importance of handling multi-modal interleaved inputs and situation modeling.
Experiments on data scaling and cross-domain transfer further demonstrate the
efficacy of leveraging MSQA as a pre-training dataset for developing more
powerful situated reasoning models.

摘要：情境感知對於理解和推理具身 AI 代理中的 3D 場景至關重要。然而，現有的資料集和基準在資料模態、多樣性、規模和任務範圍方面對於情境理解來說是有限的。為了解決這些限制，我們提出了多模態情境問答 (MSQA)，這是一個大型多模態情境推理資料集，可透過利用 3D 場景圖和視覺語言模型 (VLM) 在各種真實世界 3D 場景中進行可擴充收集。MSQA 包含 251K 個情境問答對，涵蓋 9 個不同的問題類別，涵蓋 3D 場景中的複雜場景。我們在基準中引入了一種新穎的交錯多模態輸入設定，以提供文字、影像和點雲，用於情境和問題描述，解決以前單一模態慣例（例如文字）中的歧義。此外，我們設計了多模態情境下一步導航 (MSNN) 基準，以評估模型的導航情境推理。MSQA 和 MSNN 的綜合評估突顯了現有視覺語言模型的限制，並強調了處理多模態交錯輸入和情境建模的重要性。資料擴充和跨領域轉移的實驗進一步證明了利用 MSQA 作為預訓練資料集來開發更強大的情境推理模型的有效性。

##### **Grounding Language Models in Autonomous Loco-manipulation Tasks**
2409.01326v1 by Jin Wang, Nikos Tsagarakis

Humanoid robots with behavioral autonomy have consistently been regarded as
ideal collaborators in our daily lives and promising representations of
embodied intelligence. Compared to fixed-based robotic arms, humanoid robots
offer a larger operational space while significantly increasing the difficulty
of control and planning. Despite the rapid progress towards general-purpose
humanoid robots, most studies remain focused on locomotion ability with few
investigations into whole-body coordination and tasks planning, thus limiting
the potential to demonstrate long-horizon tasks involving both mobility and
manipulation under open-ended verbal instructions. In this work, we propose a
novel framework that learns, selects, and plans behaviors based on tasks in
different scenarios. We combine reinforcement learning (RL) with whole-body
optimization to generate robot motions and store them into a motion library. We
further leverage the planning and reasoning features of the large language
model (LLM), constructing a hierarchical task graph that comprises a series of
motion primitives to bridge lower-level execution with higher-level planning.
Experiments in simulation and real-world using the CENTAURO robot show that the
language model based planner can efficiently adapt to new loco-manipulation
tasks, demonstrating high autonomy from free-text commands in unstructured
scenes.

摘要：具有行為自主權的人形機器人一直被視為我們日常生活中理想的合作者，也是具體智能的有希望的代表。與固定式機器手臂相比，人形機器人提供了更大的操作空間，同時顯著增加了控制和規劃的難度。儘管朝著通用人形機器人快速發展，但大多數研究仍然集中在運動能力上，很少研究全身協調和任務規劃，從而限制了展示涉及移動和操作的長期任務的潛力，同時還能接受開放式口頭指令。在這項工作中，我們提出了一個新的框架，該框架可以根據不同場景中的任務學習、選擇和規劃行為。我們將強化學習 (RL) 與全身優化相結合，以生成機器人動作並將其存儲到動作庫中。我們進一步利用大型語言模型 (LLM) 的規劃和推理功能，構建了一個分層任務圖，其中包含一系列運動原語，以橋接低級執行和高級規劃。在模擬和使用 CENTAURO 機器人的現實世界中的實驗表明，基於語言模型的規劃器可以有效適應新的運動操作任務，證明了在非結構化場景中從自由文本命令中獲得的高度自主性。

##### **LATEX-GCL: Large Language Models (LLMs)-Based Data Augmentation for Text-Attributed Graph Contrastive Learning**
2409.01145v1 by Haoran Yang, Xiangyu Zhao, Sirui Huang, Qing Li, Guandong Xu

Graph Contrastive Learning (GCL) is a potent paradigm for self-supervised
graph learning that has attracted attention across various application
scenarios. However, GCL for learning on Text-Attributed Graphs (TAGs) has yet
to be explored. Because conventional augmentation techniques like feature
embedding masking cannot directly process textual attributes on TAGs. A naive
strategy for applying GCL to TAGs is to encode the textual attributes into
feature embeddings via a language model and then feed the embeddings into the
following GCL module for processing. Such a strategy faces three key
challenges: I) failure to avoid information loss, II) semantic loss during the
text encoding phase, and III) implicit augmentation constraints that lead to
uncontrollable and incomprehensible results. In this paper, we propose a novel
GCL framework named LATEX-GCL to utilize Large Language Models (LLMs) to
produce textual augmentations and LLMs' powerful natural language processing
(NLP) abilities to address the three limitations aforementioned to pave the way
for applying GCL to TAG tasks. Extensive experiments on four high-quality TAG
datasets illustrate the superiority of the proposed LATEX-GCL method. The
source codes and datasets are released to ease the reproducibility, which can
be accessed via this link: https://anonymous.4open.science/r/LATEX-GCL-0712.

摘要：圖形對比學習 (GCL) 是自監督圖形學習的強大範例，已在各種應用場景中引起關注。然而，GCL 對於在文本註解圖形 (TAG) 上學習尚未被探討。因為特徵嵌入遮罩等傳統擴充技術無法直接處理 TAG 上的文本屬性。將 GCL 應用於 TAG 的一種天真策略是通過語言模型將文本屬性編碼到特徵嵌入中，然後將嵌入輸入後續的 GCL 模組進行處理。這種策略面臨三個關鍵挑戰：I) 無法避免資訊遺失，II) 在文本編碼階段發生語義遺失，以及 III) 導致無法控制且難以理解結果的隱式擴充約束。在本文中，我們提出一個名為 LATEX-GCL 的新穎 GCL 框架，利用大型語言模型 (LLM) 來產生文本擴充，以及 LLM 強大的自然語言處理 (NLP) 能力來解決上述三個限制，為將 GCL 應用於 TAG 任務鋪平道路。在四個高品質 TAG 資料集上的大量實驗說明了所提出的 LATEX-GCL 方法的優越性。原始碼和資料集已發布以簡化可重製性，可透過此連結存取：https://anonymous.4open.science/r/LATEX-GCL-0712。

##### **Harnessing the Power of Semi-Structured Knowledge and LLMs with Triplet-Based Prefiltering for Question Answering**
2409.00861v1 by Derian Boer, Fabian Koch, Stefan Kramer

Large Language Models (LLMs) frequently lack domain-specific knowledge and
even fine-tuned models tend to hallucinate. Hence, more reliable models that
can include external knowledge are needed. We present a pipeline, 4StepFocus,
and specifically a preprocessing step, that can substantially improve the
answers of LLMs. This is achieved by providing guided access to external
knowledge making use of the model's ability to capture relational context and
conduct rudimentary reasoning by themselves. The method narrows down
potentially correct answers by triplets-based searches in a semi-structured
knowledge base in a direct, traceable fashion, before switching to latent
representations for ranking those candidates based on unstructured data. This
distinguishes it from related methods that are purely based on latent
representations. 4StepFocus consists of the steps: 1) Triplet generation for
extraction of relational data by an LLM, 2) substitution of variables in those
triplets to narrow down answer candidates employing a knowledge graph, 3)
sorting remaining candidates with a vector similarity search involving
associated non-structured data, 4) reranking the best candidates by the LLM
with background data provided. Experiments on a medical, a product
recommendation, and an academic paper search test set demonstrate that this
approach is indeed a powerful augmentation. It not only adds relevant traceable
background information from information retrieval, but also improves
performance considerably in comparison to state-of-the-art methods. This paper
presents a novel, largely unexplored direction and therefore provides a wide
range of future work opportunities. Used source code is available at
https://github.com/kramerlab/4StepFocus.

摘要：大型語言模型 (LLM) 經常缺乏特定領域的知識，即使經過微調的模型也容易產生幻覺。因此，需要更多可靠的模型來納入外部知識。我們提出了一個流程 4StepFocus，特別是預處理步驟，可以大幅改善 LLM 的答案。這是透過提供受引導的外部知識存取，利用模型自行擷取關聯性脈絡和進行基本推理的能力來實現的。此方法透過在半結構化知識庫中進行基於三元組的搜尋，以直接且可追蹤的方式縮小潛在正確答案的範圍，然後再切換到潛在表徵，根據非結構化資料對這些候選答案進行排名。這與純粹基於潛在表徵的相關方法有所區別。4StepFocus 包含以下步驟：1) 由 LLM 進行三元組產生以擷取關聯資料，2) 在這些三元組中替換變數，以採用知識圖表縮小答案候選範圍，3) 使用涉及關聯非結構化資料的向量相似性搜尋對剩餘候選答案進行排序，4) 由 LLM 重新對最佳候選答案進行排名，並提供背景資料。在醫療、產品推薦和學術論文搜尋測試集中進行的實驗證明，這種方法確實是一種強大的擴充。它不僅增加了來自資訊檢索的相关可追蹤背景資訊，而且與最先進的方法相比，也大幅提升了效能。本文提出了一個新穎且鮮少探索的方向，因此提供了廣泛的未來工作機會。使用的原始碼可在 https://github.com/kramerlab/4StepFocus 取得。

##### **Building FKG.in: a Knowledge Graph for Indian Food**
2409.00830v1 by Saransh Kumar Gupta, Lipika Dey, Partha Pratim Das, Ramesh Jain

This paper presents an ontology design along with knowledge engineering, and
multilingual semantic reasoning techniques to build an automated system for
assimilating culinary information for Indian food in the form of a knowledge
graph. The main focus is on designing intelligent methods to derive ontology
designs and capture all-encompassing knowledge about food, recipes,
ingredients, cooking characteristics, and most importantly, nutrition, at
scale. We present our ongoing work in this workshop paper, describe in some
detail the relevant challenges in curating knowledge of Indian food, and
propose our high-level ontology design. We also present a novel workflow that
uses AI, LLM, and language technology to curate information from recipe blog
sites in the public domain to build knowledge graphs for Indian food. The
methods for knowledge curation proposed in this paper are generic and can be
replicated for any domain. The design is application-agnostic and can be used
for AI-driven smart analysis, building recommendation systems for Personalized
Digital Health, and complementing the knowledge graph for Indian food with
contextual information such as user information, food biochemistry, geographic
information, agricultural information, etc.

摘要：本文提出了一個知識工程和多語言語義推理技術的本体設計，用於建立一個自動化系統，以知識圖譜的形式吸收印度料理的烹飪資訊。重點在於設計智慧方法，以推導本体設計，並全面擷取關於食物、食譜、食材、烹飪特性，以及最重要的營養的知識，並擴大規模。我們在這個研討會論文中介紹了我們正在進行的工作，詳細描述了整理印度料理知識相關的挑戰，並提出了我們的高階本体設計。我們也提出了一種新的工作流程，它使用 AI、LLM 和語言技術，從公共領域的食譜部落格網站中整理資訊，以建立印度料理的知識圖譜。本文提出的知識整理方法是通用的，可以複製到任何領域。設計與應用無關，可用於 AI 驅動的智慧分析、建立個人化數位健康推薦系統，以及使用使用者資訊、食物生物化學、地理資訊、農業資訊等脈絡資訊，來補充印度料理的知識圖譜。

##### **Hound: Hunting Supervision Signals for Few and Zero Shot Node Classification on Text-attributed Graph**
2409.00727v1 by Yuxiang Wang, Xiao Yan, Shiyu Jin, Quanqing Xu, Chuanhui Yang, Yuanyuan Zhu, Chuang Hu, Bo Du, Jiawei Jiang

Text-attributed graph (TAG) is an important type of graph structured data
with text descriptions for each node. Few- and zero-shot node classification on
TAGs have many applications in fields such as academia and social networks.
However, the two tasks are challenging due to the lack of supervision signals,
and existing methods only use the contrastive loss to align graph-based node
embedding and language-based text embedding. In this paper, we propose Hound to
improve accuracy by introducing more supervision signals, and the core idea is
to go beyond the node-text pairs that come with data. Specifically, we design
three augmentation techniques, i.e., node perturbation, text matching, and
semantics negation to provide more reference nodes for each text and vice
versa. Node perturbation adds/drops edges to produce diversified node
embeddings that can be matched with a text. Text matching retrieves texts with
similar embeddings to match with a node. Semantics negation uses a negative
prompt to construct a negative text with the opposite semantics, which is
contrasted with the original node and text. We evaluate Hound on 5 datasets and
compare with 13 state-of-the-art baselines. The results show that Hound
consistently outperforms all baselines, and its accuracy improvements over the
best-performing baseline are usually over 5%.

摘要：文字属性圖 (TAG) 是一種重要的圖形結構化資料類型，其中每個節點都有文字描述。TAG 上的少樣本和零樣本節點分類在學術界和社交網路等領域有許多應用。然而，由於缺乏監督訊號，這兩個任務具有挑戰性，現有方法僅使用對比損失來對齊基於圖形節點的嵌入和基於語言的文字嵌入。在本文中，我們提出 Hound 來透過引入更多監督訊號來改善準確度，其核心思想是超越資料中附帶的節點文字對。具體來說，我們設計了三種擴充技術，即節點擾動、文字配對和語義否定，為每個文字提供更多參考節點，反之亦然。節點擾動新增/刪除邊緣以產生可以與文字配對的多樣化節點嵌入。文字配對擷取具有類似嵌入的文字以與節點配對。語義否定使用負面提示來建構具有相反語義的負面文字，與原始節點和文字形成對比。我們在 5 個資料集上評估 Hound，並與 13 個最先進的基線進行比較。結果表明，Hound 在所有基線上始終表現優異，其準確度通常比效能最佳的基線提高了 5% 以上。

##### **WikiCausal: Corpus and Evaluation Framework for Causal Knowledge Graph Construction**
2409.00331v1 by Oktie Hassanzadeh

Recently, there has been an increasing interest in the construction of
general-domain and domain-specific causal knowledge graphs. Such knowledge
graphs enable reasoning for causal analysis and event prediction, and so have a
range of applications across different domains. While great progress has been
made toward automated construction of causal knowledge graphs, the evaluation
of such solutions has either focused on low-level tasks (e.g., cause-effect
phrase extraction) or on ad hoc evaluation data and small manual evaluations.
In this paper, we present a corpus, task, and evaluation framework for causal
knowledge graph construction. Our corpus consists of Wikipedia articles for a
collection of event-related concepts in Wikidata. The task is to extract causal
relations between event concepts from the corpus. The evaluation is performed
in part using existing causal relations in Wikidata to measure recall, and in
part using Large Language Models to avoid the need for manual or crowd-sourced
evaluation. We evaluate a pipeline for causal knowledge graph construction that
relies on neural models for question answering and concept linking, and show
how the corpus and the evaluation framework allow us to effectively find the
right model for each task. The corpus and the evaluation framework are publicly
available.

摘要：<paragraph>最近，人們對通用領域和特定領域因果知識圖譜的建構越來越感興趣。此類知識圖譜能夠推理因果分析和事件預測，因此在不同領域中有廣泛的應用。雖然在因果知識圖譜的自動建構方面取得了重大進展，但此類解決方案的評估要嘛著重於低階任務（例如因果關係短語擷取），要嘛著重於臨時評估資料和小型手動評估。在本文中，我們提出了一個語料庫、任務和因果知識圖譜建構評估架構。我們的語料庫包含維基百科文章，其中包含 Wikidata 中一系列事件相關概念。任務是從語料庫中擷取事件概念之間的因果關係。評估部分使用 Wikidata 中現有的因果關係來衡量召回率，部分使用大型語言模型來避免手動或群眾外包評估的需要。我們評估了一個因果知識圖譜建構管道，該管道依賴於用於問答和概念連結的神經模型，並展示了語料庫和評估架構如何讓我們有效地為每個任務找到合適的模型。語料庫和評估架構公開提供。</paragraph>

##### **HyPA-RAG: A Hybrid Parameter Adaptive Retrieval-Augmented Generation System for AI Legal and Policy Applications**
2409.09046v1 by Rishi Kalra, Zekun Wu, Ayesha Gulley, Airlie Hilliard, Xin Guan, Adriano Koshiyama, Philip Treleaven

While Large Language Models (LLMs) excel in text generation and
question-answering, their effectiveness in AI legal and policy is limited by
outdated knowledge, hallucinations, and inadequate reasoning in complex
contexts. Retrieval-Augmented Generation (RAG) systems improve response
accuracy by integrating external knowledge but struggle with retrieval errors,
poor context integration, and high costs, particularly in interpreting
qualitative and quantitative AI legal texts. This paper introduces a Hybrid
Parameter-Adaptive RAG (HyPA-RAG) system tailored for AI legal and policy,
exemplified by NYC Local Law 144 (LL144). HyPA-RAG uses a query complexity
classifier for adaptive parameter tuning, a hybrid retrieval strategy combining
dense, sparse, and knowledge graph methods, and an evaluation framework with
specific question types and metrics. By dynamically adjusting parameters,
HyPA-RAG significantly improves retrieval accuracy and response fidelity.
Testing on LL144 shows enhanced correctness, faithfulness, and contextual
precision, addressing the need for adaptable NLP systems in complex,
high-stakes AI legal and policy applications.

摘要：大型語言模型 (LLM) 雖然在文字產生和問答方面表現優異，但其在 AI 法律和政策中的效能卻受到過時知識、幻覺以及在複雜脈絡中推理不足的限制。檢索增強生成 (RAG) 系統透過整合外部知識來改善回應準確性，但卻在檢索錯誤、脈絡整合不良以及成本高昂方面面臨挑戰，特別是在詮釋定性和定量的 AI 法律文本時。本文介紹了一種專為 AI 法律和政策量身打造的混合參數自適應 RAG (HyPA-RAG) 系統，以紐約市地方法律 144 (LL144) 為例。HyPA-RAG 使用查詢複雜度分類器進行自適應參數調整，結合稠密、稀疏和知識圖表方法的混合檢索策略，以及包含特定問題類型和指標的評估架構。透過動態調整參數，HyPA-RAG 大幅改善了檢索準確性和回應保真度。在 LL144 上的測試顯示出增強的正確性、忠實度和脈絡準確度，滿足了在複雜、高風險的 AI 法律和政策應用中對可適應 NLP 系統的需求。

##### **LLaVA-SG: Leveraging Scene Graphs as Visual Semantic Expression in Vision-Language Models**
2408.16224v2 by Jingyi Wang, Jianzhong Ju, Jian Luan, Zhidong Deng

Recent advances in large vision-language models (VLMs) typically employ
vision encoders based on the Vision Transformer (ViT) architecture. The
division of the images into patches by ViT results in a fragmented perception,
thereby hindering the visual understanding capabilities of VLMs. In this paper,
we propose an innovative enhancement to address this limitation by introducing
a Scene Graph Expression (SGE) module in VLMs. This module extracts and
structurally expresses the complex semantic information within images, thereby
improving the foundational perception and understanding abilities of VLMs.
Extensive experiments demonstrate that integrating our SGE module significantly
enhances the VLM's performance in vision-language tasks, indicating its
effectiveness in preserving intricate semantic details and facilitating better
visual understanding.

摘要：近來大型視覺語言模型 (VLM) 的進展通常採用基於視覺轉換器 (ViT) 架構的視覺編碼器。ViT 將影像分割成區塊會造成破碎的感知，從而阻礙 VLM 的視覺理解能力。在本文中，我們提出了一項創新的增強功能，透過在 VLM 中引入場景圖表達 (SGE) 模組來解決此限制。此模組會萃取影像中的複雜語意資訊並以結構化的方式表達，從而改善 VLM 的基礎感知和理解能力。廣泛的實驗證明，整合我們的 SGE 模組能顯著提升 VLM 在視覺語言任務中的效能，表示它在保留複雜的語意細節和促進更好的視覺理解方面很有效。

##### **LLM-Based Multi-Hop Question Answering with Knowledge Graph Integration in Evolving Environments**
2408.15903v1 by Ruirui Chen, Weifeng Jiang, Chengwei Qin, Ishaan Singh Rawal, Cheston Tan, Dongkyu Choi, Bo Xiong, Bo Ai

The rapid obsolescence of information in Large Language Models (LLMs) has
driven the development of various techniques to incorporate new facts. However,
existing methods for knowledge editing still face difficulties with multi-hop
questions that require accurate fact identification and sequential logical
reasoning, particularly among numerous fact updates. To tackle these
challenges, this paper introduces Graph Memory-based Editing for Large Language
Models (GMeLLo), a straitforward and effective method that merges the explicit
knowledge representation of Knowledge Graphs (KGs) with the linguistic
flexibility of LLMs. Beyond merely leveraging LLMs for question answering,
GMeLLo employs these models to convert free-form language into structured
queries and fact triples, facilitating seamless interaction with KGs for rapid
updates and precise multi-hop reasoning. Our results show that GMeLLo
significantly surpasses current state-of-the-art knowledge editing methods in
the multi-hop question answering benchmark, MQuAKE, especially in scenarios
with extensive knowledge edits.

摘要：大型語言模型 (LLM) 中資訊快速過時，促使各種技術發展以納入新事實。然而，現有的知識編輯方法在需要準確事實辨識和順序邏輯推理的多跳問題上仍面臨困難，特別是在眾多事實更新中。為了應對這些挑戰，本文介紹了大型語言模型的圖記憶編輯 (GMeLLo)，這是一種直接且有效的方法，結合了知識圖譜 (KG) 的明確知識表示與 LLM 的語言靈活性。GMeLLo 不僅利用 LLM 來回答問題，還使用這些模型將自由形式的語言轉換為結構化查詢和事實三元組，促進與 KG 的無縫互動，以便快速更新和精確的多跳推理。我們的結果表明，在多跳問題回答基準 MQuAKE 中，GMeLLo 明顯超越了當前最先進的知識編輯方法，特別是在廣泛知識編輯的場景中。

##### **VHAKG: A Multi-modal Knowledge Graph Based on Synchronized Multi-view Videos of Daily Activities**
2408.14895v2 by Shusaku Egami, Takahiro Ugai, Swe Nwe Nwe Htun, Ken Fukuda

Multi-modal knowledge graphs (MMKGs), which ground various non-symbolic data
(e.g., images and videos) into symbols, have attracted attention as resources
enabling knowledge processing and machine learning across modalities. However,
the construction of MMKGs for videos consisting of multiple events, such as
daily activities, is still in the early stages. In this paper, we construct an
MMKG based on synchronized multi-view simulated videos of daily activities.
Besides representing the content of daily life videos as event-centric
knowledge, our MMKG also includes frame-by-frame fine-grained changes, such as
bounding boxes within video frames. In addition, we provide support tools for
querying our MMKG. As an application example, we demonstrate that our MMKG
facilitates benchmarking vision-language models by providing the necessary
vision-language datasets for a tailored task.

摘要：多模態知識圖（MMKG）將各種非符號數據（例如，影像和影片）轉換為符號，成為一種資源，能讓跨模態的知識處理和機器學習成為可能。然而，對於包含多個事件（例如日常生活活動）的影片，其 MMKG 的建構仍處於早期階段。在本文中，我們基於每日活動的同步多視角模擬影片，建構了一個 MMKG。除了將日常生活影片的內容表示為以事件為中心的知識外，我們的 MMKG 也包含逐幀的細微變化，例如影片幀中的邊界框。此外，我們還提供了用於查詢 MMKG 的支援工具。作為應用範例，我們展示了我們的 MMKG 如何透過提供特定任務所需的視覺語言資料集，來促進視覺語言模型的基準測試。

##### **XG-NID: Dual-Modality Network Intrusion Detection using a Heterogeneous Graph Neural Network and Large Language Model**
2408.16021v1 by Yasir Ali Farrukh, Syed Wali, Irfan Khan, Nathaniel D. Bastian

In the rapidly evolving field of cybersecurity, the integration of flow-level
and packet-level information for real-time intrusion detection remains a
largely untapped area of research. This paper introduces "XG-NID," a novel
framework that, to the best of our knowledge, is the first to fuse flow-level
and packet-level data within a heterogeneous graph structure, offering a
comprehensive analysis of network traffic. Leveraging a heterogeneous graph
neural network (GNN) with graph-level classification, XG-NID uniquely enables
real-time inference while effectively capturing the intricate relationships
between flow and packet payload data. Unlike traditional GNN-based
methodologies that predominantly analyze historical data, XG-NID is designed to
accommodate the heterogeneous nature of network traffic, providing a robust and
real-time defense mechanism. Our framework extends beyond mere classification;
it integrates Large Language Models (LLMs) to generate detailed, human-readable
explanations and suggest potential remedial actions, ensuring that the insights
produced are both actionable and comprehensible. Additionally, we introduce a
new set of flow features based on temporal information, further enhancing the
contextual and explainable inferences provided by our model. To facilitate
practical application and accessibility, we developed "GNN4ID," an open-source
tool that enables the extraction and transformation of raw network traffic into
the proposed heterogeneous graph structure, seamlessly integrating flow and
packet-level data. Our comprehensive quantitative comparative analysis
demonstrates that XG-NID achieves an F1 score of 97\% in multi-class
classification, outperforming existing baseline and state-of-the-art methods.
This sets a new standard in Network Intrusion Detection Systems by combining
innovative data fusion with enhanced interpretability and real-time
capabilities.

摘要：<paragraph>在快速發展的網路安全領域中，整合流層級和封包層級資訊以進行即時入侵偵測，仍然是一個尚未開發的研究領域。本文介紹「XG-NID」，一個創新的架構，據我們所知，這是第一個在異質圖形結構中融合流層級和封包層級資料的架構，提供對網路流量的全面分析。透過利用異質圖形神經網路 (GNN) 和圖形層級分類，XG-NID 獨特地實現即時推論，同時有效擷取流和封包酬載資料之間的複雜關係。與傳統基於 GNN 的方法（主要分析歷史資料）不同，XG-NID 被設計成適應網路流量的異質性，提供強大且即時的防禦機制。我們的架構不僅限於分類；它整合大型語言模型 (LLM) 以產生詳細、人類可讀的解釋並建議潛在的補救措施，確保產生的見解既可操作又易於理解。此外，我們根據時間資訊引入一組新的流特徵，進一步增強模型提供的脈絡和可解釋推論。為了促進實際應用和可及性，我們開發了「GNN4ID」，一個開放原始碼工具，可以將原始網路流量提取並轉換為建議的異質圖形結構，無縫整合流和封包層級資料。我們全面的定量比較分析表明，XG-NID 在多類別分類中達到 97% 的 F1 分數，優於現有的基準和最先進的方法。這透過結合創新的資料融合、增強的可解釋性和即時功能，在網路入侵偵測系統中樹立了新的標準。</paragraph>

##### **Process Trace Querying using Knowledge Graphs and Notation3**
2409.04452v1 by William Van Woensel

In process mining, a log exploration step allows making sense of the event
traces; e.g., identifying event patterns and illogical traces, and gaining
insight into their variability. To support expressive log exploration, the
event log can be converted into a Knowledge Graph (KG), which can then be
queried using general-purpose languages. We explore the creation of semantic KG
using the Resource Description Framework (RDF) as a data model, combined with
the general-purpose Notation3 (N3) rule language for querying. We show how
typical trace querying constraints, inspired by the state of the art, can be
implemented in N3. We convert case- and object-centric event logs into a
trace-based semantic KG; OCEL2 logs are hereby "flattened" into traces based on
object paths through the KG. This solution offers (a) expressivity, as queries
can instantiate constraints in multiple ways and arbitrarily constrain
attributes and relations (e.g., actors, resources); (b) flexibility, as OCEL2
event logs can be serialized as traces in arbitrary ways based on the KG; and
(c) extensibility, as others can extend our library by leveraging the same
implementation patterns.

摘要：在流程挖掘中，日志探索步骤可以理解事件轨迹；例如，识别事件模式和非逻辑轨迹，并深入了解其可变性。为了支持表达性日志探索，事件日志可以转换为知识图 (KG)，然后可以使用通用语言对其进行查询。我们探索使用资源描述框架 (RDF) 作为数据模型创建语义 KG，并结合通用 Notation3 (N3) 规则语言进行查询。我们展示了如何使用 N3 实现受现有技术启发的典型轨迹查询约束。我们将案例和对象中心事件日志转换为基于轨迹的语义 KG；OCEL2 日志在此被“扁平化”为基于通过 KG 的对象路径的轨迹。此解决方案提供 (a) 表达力，因为查询可以以多种方式实例化约束并任意约束属性和关系（例如，参与者、资源）；(b) 灵活，因为 OCEL2 事件日志可以基于 KG 以任意方式序列化为轨迹；以及 (c) 可扩展性，因为其他人可以通过利用相同的实现模式来扩展我们的库。

##### **PatentGPT: A Large Language Model for Patent Drafting Using Knowledge-based Fine-tuning Method**
2409.00092v1 by Runtao Ren, Jian Ma

As humanity stands on the brink of a new era of technological innovation, the
ability to rapidly transform creative ideas into protected intellectual
property (IP) is more crucial than ever. However, the conventional processes
for patent drafting are fraught with challenges, demanding a nuanced
understanding of advanced field knowledge and technical concepts. Existing
large language models (LLMs), while powerful, often fall short in this IP
creation domain due to their lack of specialized knowledge and
context-awareness necessary for generating technically accurate patent
documents. To bridge this critical gap, we propose a groundbreaking framework
for Knowledge Fine-Tuning (KFT) of LLMs, designed to endow AI with the ability
to autonomously mine, understand, and apply domain-specific knowledge. Our
model, PatentGPT leverages a unique combination of knowledge graph-based
pre-training, domain-specific supervised fine-tuning (SFT), and reinforcement
learning from human feedback (RLHF). Through extensive evaluation, PatentGPT
has demonstrated outstanding performance, scoring up to approximately 400%
higher in patent related benchmark tests compared to state-of-the-art models.
By KFT method the model's capability to not only assist but also augment human
creativity and innovation, our approach sets a new standard for AI-driven
intellectual property generation, paving the way for more efficient and
effective invention processes.

摘要：<paragraph>隨著人類邁入科技創新的新紀元，迅速將創意點子轉化為受保護的智慧財產（IP）的能力比以往任何時候都更加重要。然而，傳統的專利起草程序充滿挑戰，需要對先進領域知識和技術概念有細緻入微的了解。現有的大型語言模型（LLM）雖然強大，但由於缺乏產生技術上準確的專利文件的專業知識和情境意識，因此常常無法滿足此 IP 創作領域的需求。為了彌補這個關鍵差距，我們提出了一個創新的 LLM 知識微調 (KFT) 架構，旨在賦予 AI 自主挖掘、理解和應用特定領域知識的能力。我們的模型 PatentGPT 充分利用了基於知識圖表的預訓練、特定領域的監督式微調 (SFT) 和人類回饋的強化學習 (RLHF) 的獨特組合。透過廣泛的評估，PatentGPT 已展現出傑出的表現，在與最先進模型相比的專利相關基準測試中，得分高出約 400%。透過 KFT 方法，此模型不僅能夠協助，還能擴增人類的創造力和創新力，我們的做法為 AI 驅動的智慧財產生成樹立了新標準，為更有效率且更有效的發明流程鋪路。</paragraph>

##### **DynamicRouteGPT: A Real-Time Multi-Vehicle Dynamic Navigation Framework Based on Large Language Models**
2408.14185v1 by Ziai Zhou, Bin Zhou, Hao Liu

Real-time dynamic path planning in complex traffic environments presents
challenges, such as varying traffic volumes and signal wait times. Traditional
static routing algorithms like Dijkstra and A* compute shortest paths but often
fail under dynamic conditions. Recent Reinforcement Learning (RL) approaches
offer improvements but tend to focus on local optima, risking dead-ends or
boundary issues. This paper proposes a novel approach based on causal inference
for real-time dynamic path planning, balancing global and local optimality. We
first use the static Dijkstra algorithm to compute a globally optimal baseline
path. A distributed control strategy then guides vehicles along this path. At
intersections, DynamicRouteGPT performs real-time decision-making for local
path selection, considering real-time traffic, driving preferences, and
unexpected events. DynamicRouteGPT integrates Markov chains, Bayesian
inference, and large-scale pretrained language models like Llama3 8B to provide
an efficient path planning solution. It dynamically adjusts to traffic
scenarios and driver preferences and requires no pre-training, offering broad
applicability across road networks. A key innovation is the construction of
causal graphs for counterfactual reasoning, optimizing path decisions.
Experimental results show that our method achieves state-of-the-art performance
in real-time dynamic path planning for multiple vehicles while providing
explainable path selections, offering a novel and efficient solution for
complex traffic environments.

摘要：在複雜交通環境中進行實時動態路徑規劃會面臨挑戰，例如交通流量變化和信號等待時間。傳統的靜態路由演算法，例如 Dijkstra 和 A*，會計算最短路徑，但通常在動態條件下會失敗。最近的強化學習 (RL) 方法提供了改進，但傾向於關注局部最優，冒著陷入死胡同或邊界問題的風險。本文提出了一種基於因果推論的新穎方法，用於實時動態路徑規劃，平衡全局和局部最優性。我們首先使用靜態 Dijkstra 演算法計算全局最優基線路徑。然後，一個分布式控制策略沿著這條路徑引導車輛。在交叉路口，DynamicRouteGPT 針對局部路徑選擇執行實時決策，考量實時交通、駕駛偏好和意外事件。DynamicRouteGPT 整合了馬可夫鏈、貝氏推論和 Llama3 8B 等大規模預先訓練的語言模型，以提供有效的路徑規劃解決方案。它會動態調整到交通狀況和駕駛偏好，並且不需要預先訓練，在道路網路上提供廣泛的適用性。一個關鍵創新是建立反事實推理的因果圖，以最佳化路徑決策。實驗結果顯示，我們的模型在多輛車輛的實時動態路徑規劃中達到最先進的效能，同時提供可解釋的路徑選擇，為複雜的交通環境提供一種新穎且有效的解決方案。

##### **Exploring the Potential of Large Language Models for Heterophilic Graphs**
2408.14134v1 by Yuxia Wu, Shujie Li, Yuan Fang, Chuan Shi

Graph Neural Networks (GNNs) are essential for various graph-based learning
tasks. Notably, classical GNN architectures operate under the assumption of
homophily, which posits that connected nodes are likely to share similar
features. However, this assumption limits the effectiveness of GNNs in handling
heterophilic graphs where connected nodes often exhibit dissimilar
characteristics. Existing approaches for homophily graphs such as non-local
neighbor extension and architectural refinement overlook the rich textual data
associated with nodes, which could unlock deeper insights into these
heterophilic contexts. With advancements in Large Language Models (LLMs), there
is significant promise to enhance GNNs by leveraging the extensive open-world
knowledge within LLMs to more effectively interpret and utilize textual data
for characterizing heterophilic graphs. In this work, we explore the potential
of LLMs for modeling heterophilic graphs and propose a novel two-stage
framework: LLM-enhanced edge discriminator and LLM-guided edge reweighting.
Specifically, in the first stage, we fine-tune the LLM to better identify
homophilic and heterophilic edges based on the textual information of their
nodes. In the second stage, we adaptively manage message propagation in GNNs
for different edge types based on node features, structures, and heterophilic
or homophilic characteristics. To cope with the computational demands when
deploying LLMs in practical scenarios, we further explore model distillation
techniques to fine-tune smaller, more efficient models that maintain
competitive performance. Extensive experiments validate the effectiveness of
our framework, demonstrating the feasibility of using LLMs to enhance GNNs for
node classification on heterophilic graphs.

摘要：圖神經網路 (GNN) 對於各種基於圖形的學習任務至關重要。值得注意的是，傳統的 GNN 架構在同質性的假設下運作，該假設認為連接的節點可能共享類似的特徵。然而，此假設限制了 GNN 在處理異質性圖形中的效能，其中連接的節點通常表現出不同的特徵。現有的同質性圖形方法（例如非局部鄰域延伸和架構改進）忽略了與節點相關的豐富文本資料，這可以深入了解這些異質性脈絡。隨著大型語言模型 (LLM) 的進步，透過利用 LLM 中廣泛的開放世界知識來增強 GNN，對於更有效地詮釋和利用文本資料來表徵異質性圖形有很大的希望。在這項工作中，我們探討了 LLM 在異質性圖形建模中的潛力，並提出了一個新穎的兩階段架構：LLM 增強邊緣判別器和 LLM 引導邊緣重新加權。具體來說，在第一階段，我們微調 LLM 以根據其節點的文本資訊，更好地識別同質性和異質性邊緣。在第二階段，我們根據節點特徵、結構和異質性或同質性特徵，自適應地管理 GNN 中不同邊緣類型的訊息傳遞。為了應對在實際場景中部署 LLM 時的計算需求，我們進一步探討模型萃取技術，以微調較小、更有效率的模型，以維持競爭力。廣泛的實驗驗證了我們架構的有效性，證明了使用 LLM 來增強 GNN 以進行異質性圖形上的節點分類的可行性。

##### **Towards Graph Prompt Learning: A Survey and Beyond**
2408.14520v3 by Qingqing Long, Yuchen Yan, Peiyan Zhang, Chen Fang, Wentao Cui, Zhiyuan Ning, Meng Xiao, Ning Cao, Xiao Luo, Lingjun Xu, Shiyue Jiang, Zheng Fang, Chong Chen, Xian-Sheng Hua, Yuanchun Zhou

Large-scale "pre-train and prompt learning" paradigms have demonstrated
remarkable adaptability, enabling broad applications across diverse domains
such as question answering, image recognition, and multimodal retrieval. This
approach fully leverages the potential of large-scale pre-trained models,
reducing downstream data requirements and computational costs while enhancing
model applicability across various tasks. Graphs, as versatile data structures
that capture relationships between entities, play pivotal roles in fields such
as social network analysis, recommender systems, and biological graphs. Despite
the success of pre-train and prompt learning paradigms in Natural Language
Processing (NLP) and Computer Vision (CV), their application in graph domains
remains nascent. In graph-structured data, not only do the node and edge
features often have disparate distributions, but the topological structures
also differ significantly. This diversity in graph data can lead to
incompatible patterns or gaps between pre-training and fine-tuning on
downstream graphs. We aim to bridge this gap by summarizing methods for
alleviating these disparities. This includes exploring prompt design
methodologies, comparing related techniques, assessing application scenarios
and datasets, and identifying unresolved problems and challenges. This survey
categorizes over 100 relevant works in this field, summarizing general design
principles and the latest applications, including text-attributed graphs,
molecules, proteins, and recommendation systems. Through this extensive review,
we provide a foundational understanding of graph prompt learning, aiming to
impact not only the graph mining community but also the broader Artificial
General Intelligence (AGI) community.

摘要：<paragraph>大規模「預訓練與提示學習」範例已展現出卓越的適應性，能廣泛應用於各種領域，例如問答、影像辨識和多模態檢索。此方法充分利用了大型預訓練模型的潛力，降低了下游資料需求和運算成本，同時提升了模型在各種任務中的適用性。圖形作為能捕捉實體之間關係的多功能資料結構，在社群網路分析、推薦系統和生物圖形等領域扮演著關鍵角色。儘管預訓練與提示學習範例在自然語言處理 (NLP) 和電腦視覺 (CV) 中獲得成功，它們在圖形領域的應用仍屬起步階段。在圖形結構資料中，節點和邊緣特徵不僅經常有不同的分佈，其拓撲結構也大不相同。圖形資料的這種多樣性可能導致預訓練和微調之間出現不相容的模式或差距。我們旨在透過總結減輕這些差異的方法來彌補此差距。這包括探索提示設計方法、比較相關技術、評估應用場景和資料集，以及找出未解決的問題和挑戰。本調查分類了此領域中 100 多項相關著作，總結了一般設計原則和最新應用，包括文字屬性圖形、分子、蛋白質和推薦系統。透過這項廣泛的回顧，我們提供了圖形提示學習的基本理解，旨在不僅影響圖形挖掘社群，也影響更廣泛的人工通用智慧 (AGI) 社群。</paragraph>

##### **CodeGraph: Enhancing Graph Reasoning of LLMs with Code**
2408.13863v1 by Qiaolong Cai, Zhaowei Wang, Shizhe Diao, James Kwok, Yangqiu Song

With the increasing popularity of large language models (LLMs), reasoning on
basic graph algorithm problems is an essential intermediate step in assessing
their abilities to process and infer complex graph reasoning tasks. Existing
methods usually convert graph-structured data to textual descriptions and then
use LLMs for reasoning and computation. However, LLMs often produce computation
errors on arithmetic parts in basic graph algorithm problems, such as counting
number of edges. In addition, they struggle to control or understand the output
of the reasoning process, raising concerns about whether LLMs are simply
guessing. In this paper, we introduce CodeGraph, a method that encodes graph
problem solutions as code. The methods solve new graph problems by learning
from exemplars, generating programs, and executing them via a program
interpreter. Using the few-shot setting, we evaluate CodeGraph with the base
LLM being GPT-3.5 Turbo, Llama3-70B Instruct, Mixtral-8x22B Instruct, and
Mixtral-8x7B Instruct. Experimental results on six tasks with six graph
encoding methods in the GraphQA dataset demonstrate that CodeGraph can boost
performance on graph reasoning tasks inside LLMs by 1.3% to 58.6%, depending on
the task. Compared to the existing methods, CodeGraph demonstrates strong
performance on arithmetic problems in graph tasks and offers a more
controllable and interpretable approach to the reasoning process.

摘要：隨著大型語言模型 (LLM) 的日漸普及，對基本圖形演算法問題進行推理是評估它們處理和推論複雜圖形推理任務的能力中一個重要的中間步驟。現有的方法通常會將圖形結構化的資料轉換成文字描述，然後使用 LLM 進行推理和運算。然而，LLM 通常會在基本圖形演算法問題中，例如計算邊緣數量，對算術部分產生運算錯誤。此外，它們難以控制或理解推理過程的輸出，這引發了 LLM 是否只是在猜測的疑慮。在本文中，我們介紹了 CodeGraph，這是一種將圖形問題解決方案編碼為程式碼的方法。這些方法透過學習範例、產生程式，並透過程式碼直譯器執行它們來解決新的圖形問題。使用少次嘗試設定，我們使用基礎 LLM 為 GPT-3.5 Turbo、Llama3-70B Instruct、Mixtral-8x22B Instruct 和 Mixtral-8x7B Instruct 來評估 CodeGraph。在 GraphQA 資料集中使用六種圖形編碼方法對六項任務進行的實驗結果表明，CodeGraph 可以將 LLM 中的圖形推理任務的效能提升 1.3% 到 58.6%，具體取決於任務。與現有方法相比，CodeGraph 在圖形任務中的算術問題上表現出強勁的效能，並為推理過程提供更具可控性和可解釋性的方法。

##### **LLMs as Zero-shot Graph Learners: Alignment of GNN Representations with LLM Token Embeddings**
2408.14512v1 by Duo Wang, Yuan Zuo, Fengzhi Li, Junjie Wu

Zero-shot graph machine learning, especially with graph neural networks
(GNNs), has garnered significant interest due to the challenge of scarce
labeled data. While methods like self-supervised learning and graph prompt
learning have been extensively explored, they often rely on fine-tuning with
task-specific labels, limiting their effectiveness in zero-shot scenarios.
Inspired by the zero-shot capabilities of instruction-fine-tuned large language
models (LLMs), we introduce a novel framework named Token Embedding-Aligned
Graph Language Model (TEA-GLM) that leverages LLMs as cross-dataset and
cross-task zero-shot learners for graph machine learning. Concretely, we
pretrain a GNN, aligning its representations with token embeddings of an LLM.
We then train a linear projector that transforms the GNN's representations into
a fixed number of graph token embeddings without tuning the LLM. A unified
instruction is designed for various graph tasks at different levels, such as
node classification (node-level) and link prediction (edge-level). These design
choices collectively enhance our method's effectiveness in zero-shot learning,
setting it apart from existing methods. Experiments show that our graph token
embeddings help the LLM predictor achieve state-of-the-art performance on
unseen datasets and tasks compared to other methods using LLMs as predictors.

摘要：零範例圖形機器學習，特別是圖形神經網路 (GNN)，由於稀有標籤資料的挑戰而備受關注。雖然自監督式學習和圖形提示學習等方法已被廣泛探索，但它們通常依賴於任務特定標籤的微調，這限制了它們在零範例場景中的有效性。受到指令微調大型語言模型 (LLM) 的零範例功能的啟發，我們引入了一個名為 Token Embedding-Aligned Graph Language Model (TEA-GLM) 的新框架，它利用 LLM 作為跨資料集和跨任務的零範例學習器，用於圖形機器學習。具體來說，我們預訓練一個 GNN，將其表示與 LLM 的 token embedding 對齊。然後，我們訓練一個線性投影機，將 GNN 的表示轉換為固定數量的圖形 token embedding，而無需調整 LLM。統一的指令是為不同層級的各種圖形任務設計的，例如節點分類（節點層級）和連結預測（邊緣層級）。這些設計選擇共同增強了我們的方法在零範例學習中的有效性，使其有別於現有方法。實驗表明，與使用 LLM 作為預測器的其他方法相比，我們的圖形 token embedding 幫助 LLM 預測器在未見過的資料集和任務上實現了最先進的效能。

##### **Hierarchical Network Fusion for Multi-Modal Electron Micrograph Representation Learning with Foundational Large Language Models**
2408.13661v1 by Sakhinana Sagar Srinivas, Geethan Sannidhi, Venkataramana Runkana

Characterizing materials with electron micrographs is a crucial task in
fields such as semiconductors and quantum materials. The complex hierarchical
structure of micrographs often poses challenges for traditional classification
methods. In this study, we propose an innovative backbone architecture for
analyzing electron micrographs. We create multi-modal representations of the
micrographs by tokenizing them into patch sequences and, additionally,
representing them as vision graphs, commonly referred to as patch attributed
graphs. We introduce the Hierarchical Network Fusion (HNF), a multi-layered
network structure architecture that facilitates information exchange between
the multi-modal representations and knowledge integration across different
patch resolutions. Furthermore, we leverage large language models (LLMs) to
generate detailed technical descriptions of nanomaterials as auxiliary
information to assist in the downstream task. We utilize a cross-modal
attention mechanism for knowledge fusion across cross-domain
representations(both image-based and linguistic insights) to predict the
nanomaterial category. This multi-faceted approach promises a more
comprehensive and accurate representation and classification of micrographs for
nanomaterial identification. Our framework outperforms traditional methods,
overcoming challenges posed by distributional shifts, and facilitating
high-throughput screening.

摘要：利用電子顯微照片來表徵材料，在半導體和量子材料等領域中是一項至關重要的任務。顯微照片複雜的分層結構通常會對傳統分類方法帶來挑戰。在這項研究中，我們提出了一種創新的主幹架構，用於分析電子顯微照片。我們透過將顯微照片代換成區塊序列來建立其多模態表示，此外，我們還將其表示為視覺圖形，通常稱為區塊屬性圖形。我們引入了分層網路融合 (HNF)，這是一種多層網路結構架構，有助於多模態表示之間的資訊交換，以及不同區塊解析度之間的知識整合。此外，我們利用大型語言模型 (LLM) 來產生奈米材料的詳細技術說明，作為輔助資訊，以協助下游任務。我們利用跨模態注意力機制，在跨領域表示（基於影像和語言洞察力）中進行知識融合，以預測奈米材料類別。這種多方面的做法有望為奈米材料識別提供更全面且準確的表示和分類。我們的架構優於傳統方法，克服了分佈轉移帶來的挑戰，並促進了高通量篩選。

##### **GNN: Graph Neural Network and Large Language Model for Data Discovery**
2408.13609v2 by Thomas Hoang

Our algorithm GNN: Graph Neural Network and Large Language Model for Data
Discovery inherit the benefits of \cite{hoang2024plod} (PLOD: Predictive
Learning Optimal Data Discovery), \cite{Hoang2024BODBO} (BOD: Blindly Optimal
Data Discovery) in terms of overcoming the challenges of having to predefine
utility function and the human input for attribute ranking, which helps prevent
the time-consuming loop process. In addition to these previous works, our
algorithm GNN leverages the advantages of graph neural networks and large
language models to understand text type values that cannot be understood by
PLOD and MOD, thus making the task of predicting outcomes more reliable. GNN
could be seen as an extension of PLOD in terms of understanding the text type
value and the user's preferences, not only numerical values but also text
values, making the promise of data science and analytics purposes.

摘要：我們的演算法 GNN：圖神經網路和大語言模型，用於資料探索，繼承了 \cite{hoang2024plod}（PLOD：預測性最佳資料探索）、\cite{Hoang2024BODBO}（BOD：盲目最佳資料探索）的優點，在於克服必須預先定義效用函數和人類輸入屬性排名的挑戰，這有助於防止耗時的迴圈處理。除了這些先前的作品，我們的演算法 GNN 利用圖神經網路和大語言模型的優點，來理解 PLOD 和 MOD 無法理解的文字類型值，從而使預測結果的任務更可靠。GNN 可以視為 PLOD 在理解文字類型值和使用者偏好方面的延伸，不僅是數值，還有文字值，這實現了資料科學和分析目的的承諾。

##### **HRGraph: Leveraging LLMs for HR Data Knowledge Graphs with Information Propagation-based Job Recommendation**
2408.13521v1 by Azmine Toushik Wasi

Knowledge Graphs (KGs) serving as semantic networks, prove highly effective
in managing complex interconnected data in different domains, by offering a
unified, contextualized, and structured representation with flexibility that
allows for easy adaptation to evolving knowledge. Processing complex Human
Resources (HR) data, KGs can help in different HR functions like recruitment,
job matching, identifying learning gaps, and enhancing employee retention.
Despite their potential, limited efforts have been made to implement practical
HR knowledge graphs. This study addresses this gap by presenting a framework
for effectively developing HR knowledge graphs from documents using Large
Language Models. The resulting KG can be used for a variety of downstream
tasks, including job matching, identifying employee skill gaps, and many more.
In this work, we showcase instances where HR KGs prove instrumental in precise
job matching, yielding advantages for both employers and employees. Empirical
evidence from experiments with information propagation in KGs and Graph Neural
Nets, along with case studies underscores the effectiveness of KGs in tasks
such as job and employee recommendations and job area classification. Code and
data are available at : https://github.com/azminewasi/HRGraph

摘要：知識圖譜 (KG) 作為語義網路，證明在管理不同領域中複雜的互連資料方面非常有效，透過提供統一、脈絡化且結構化的表示，並具備靈活性，可輕鬆適應不斷變化的知識。KG 處理複雜的人力資源 (HR) 資料，有助於不同的 HR 功能，例如招募、工作匹配、找出學習差距和提升員工留存率。儘管有其潛力，但實作實用的 HR 知識圖譜的努力有限。本研究透過提出一個架構，從文件中使用大型語言模型有效開發 HR 知識圖譜，來解決這個差距。產生的 KG 可用於各種下游任務，包括工作匹配、找出員工技能差距等。在這項工作中，我們展示了 HR KG 在精確工作匹配中證明有用的範例，為雇主和員工帶來優勢。透過 KG 和圖形神經網路中資訊傳播的實驗所得的實證，以及案例研究，強調了 KG 在工作和員工推薦以及工作領域分類等任務中的有效性。程式碼和資料可在以下位置取得：https://github.com/azminewasi/HRGraph

##### **Integrating Multi-Head Convolutional Encoders with Cross-Attention for Improved SPARQL Query Translation**
2408.13432v1 by Yi-Hui Chen, Eric Jui-Lin Lu, Kwan-Ho Cheng

The main task of the KGQA system (Knowledge Graph Question Answering) is to
convert user input questions into query syntax (such as SPARQL). With the rise
of modern popular encoders and decoders like Transformer and ConvS2S, many
scholars have shifted the research direction of SPARQL generation to the Neural
Machine Translation (NMT) architecture or the generative AI field of
Text-to-SPARQL. In NMT-based QA systems, the system treats knowledge base query
syntax as a language. It uses NMT-based translation models to translate natural
language questions into query syntax. Scholars use popular architectures
equipped with cross-attention, such as Transformer, ConvS2S, and BiLSTM, to
train translation models for query syntax. To achieve better query results,
this paper improved the ConvS2S encoder and added multi-head attention from the
Transformer, proposing a Multi-Head Conv encoder (MHC encoder) based on the
n-gram language model. The principle is to use convolutional layers to capture
local hidden features in the input sequence with different receptive fields,
using multi-head attention to calculate dependencies between them. Ultimately,
we found that the translation model based on the Multi-Head Conv encoder
achieved better performance than other encoders, obtaining 76.52\% and 83.37\%
BLEU-1 (BiLingual Evaluation Understudy) on the QALD-9 and LC-QuAD-1.0
datasets, respectively. Additionally, in the end-to-end system experiments on
the QALD-9 and LC-QuAD-1.0 datasets, we achieved leading results over other
KGQA systems, with Macro F1-measures reaching 52\% and 66\%, respectively.
Moreover, the experimental results show that with limited computational
resources, if one possesses an excellent encoder-decoder architecture and
cross-attention, experts and scholars can achieve outstanding performance
equivalent to large pre-trained models using only general embeddings.

摘要：知識圖表問答系統 (KGQA) 的主要任務是將使用者輸入的問題轉換成查詢語法 (例如 SPARQL)。隨著 Transformer 和 ConvS2S 等現代流行編碼器和解碼器的崛起，許多學者已將 SPARQL 生成的研究方向轉移到神經機器翻譯 (NMT) 架構或文字轉 SPARQL 的生成式人工智慧領域。在基於 NMT 的問答系統中，系統將知識庫查詢語法視為一種語言。它使用基於 NMT 的翻譯模型將自然語言問題轉換成查詢語法。學者使用配備跨注意力機制的熱門架構，例如 Transformer、ConvS2S 和 BiLSTM，來訓練查詢語法的翻譯模型。為了獲得更好的查詢結果，本文改進了 ConvS2S 編碼器，並從 Transformer 中加入多頭注意力機制，提出了一個基於 n-gram 語言模型的多頭卷積編碼器 (MHC 編碼器)。其原理是使用卷積層以不同的感受野擷取輸入序列中的局部隱藏特徵，並使用多頭注意力機制計算它們之間的依賴關係。最終，我們發現基於多頭卷積編碼器的翻譯模型比其他編碼器獲得了更好的效能，分別在 QALD-9 和 LC-QuAD-1.0 資料集上獲得 76.52% 和 83.37% 的 BLEU-1（雙語評估研究）分數。此外，在 QALD-9 和 LC-QuAD-1.0 資料集的端到端系統實驗中，我們在其他 KGQA 系統中取得了領先的結果，巨觀 F1 測量值分別達到 52% 和 66%。此外，實驗結果表明，如果擁有出色的編碼器-解碼器架構和跨注意力機制，即使在運算資源有限的情況下，專家和學者仍可以使用一般的嵌入來獲得等同於大型預訓練模型的傑出效能。

##### **CodeRefine: A Pipeline for Enhancing LLM-Generated Code Implementations of Research Papers**
2408.13366v1 by Ekaterina Trofimova, Emil Sataev, Abhijit Singh Jowhari

This paper presents CodeRefine, a novel framework for automatically
transforming research paper methodologies into functional code using Large
Language Models (LLMs). Our multi-step approach first extracts and summarizes
key text chunks from papers, analyzes their code relevance, and creates a
knowledge graph using a predefined ontology. Code is then generated from this
structured representation and enhanced through a proposed retrospective
retrieval-augmented generation approach. CodeRefine addresses the challenge of
bridging theoretical research and practical implementation, offering a more
accurate alternative to LLM zero-shot prompting. Evaluations on diverse
scientific papers demonstrate CodeRefine's ability to improve code
implementation from the paper, potentially accelerating the adoption of
cutting-edge algorithms in real-world applications.

摘要：本篇論文提出 CodeRefine，一個利用大型語言模型 (LLM) 將研究論文方法自動轉換為功能程式碼的新穎架構。我們的多步驟方法首先從論文中萃取並摘要出關鍵文字區塊，分析其程式碼相關性，並使用預定義的本体建立知識圖譜。接著從這個結構化表示產生程式碼，並透過提出的回溯式檢索增強產生方法進行強化。CodeRefine 解決了理論研究與實際實作之間的鴻溝，提供比 LLM 零次提示更精確的替代方案。在各種科學論文上的評估證明了 CodeRefine 從論文改善程式碼實作的能力，這有潛力加速尖端演算法在實際應用中的採用。

##### **Knowledge Graph Modeling-Driven Large Language Model Operating System (LLM OS) for Task Automation in Process Engineering Problem-Solving**
2408.14494v1 by Sakhinana Sagar Srinivas, Vijay Sri Vaikunth, Venkataramana Runkana

We present the Process Engineering Operations Assistant (PEOA), an AI-driven
framework designed to solve complex problems in the chemical and process
industries. The framework employs a modular architecture orchestrated by a
meta-agent, which serves as the central coordinator, managing an action
generator and instruction-tuned small-scale language models (expert models).
The action generator decomposes complex problems into sub-tasks and identifies
suitable expert models to execute each, delivering precise solutions for
multi-step problem-solving. Key techniques include advanced knowledge modeling
using property graphs for improved information retrieval, facilitating more
accurate and contextually relevant solutions. Additionally, the framework
utilizes a teacher-student transfer-learning approach with GPT-4 (Omni) to
fine-tune the action generator and expert models for domain adaptation,
alongside an iterative problem-solving mechanism with sophisticated error
handling. Custom datasets were developed to evaluate the framework against
leading proprietary language models on various engineering tasks. The results
demonstrate the framework effectiveness in automating calculations,
accelerating prototyping, and providing AI-augmented decision support for
industrial processes, marking a significant advancement in process engineering
capabilities.

摘要：我們提出了製程工程作業助理 (PEOA)，這是一個由 AI 驅動的架構，旨在解決化學和製程產業中的複雜問題。該架構採用模組化架構，由一個元代理程式協調，該代理程式作為中央協調器，管理動作產生器和指令調整的小規模語言模型 (專家模型)。動作產生器將複雜的問題分解為子任務，並識別合適的專家模型來執行每個任務，為多步驟問題解決提供精確的解決方案。關鍵技術包括使用屬性圖進行進階知識建模，以改善資訊檢索，提供更準確且與脈絡相關的解決方案。此外，該架構採用教師-學生傳輸學習方法，使用 GPT-4 (Omni) 來微調動作產生器和專家模型，以進行領域適應，以及具備精緻錯誤處理功能的迭代問題解決機制。開發了自訂資料集，以針對各種工程任務評估該架構與領先的專有語言模型。結果證明了該架構在自動化計算、加速建模和提供 AI 增強決策支援方面的有效性，標誌著製程工程能力的重大進展。

##### **A Percolation Model of Emergence: Analyzing Transformers Trained on a Formal Language**
2408.12578v2 by Ekdeep Singh Lubana, Kyogo Kawaguchi, Robert P. Dick, Hidenori Tanaka

Increase in data, size, or compute can lead to sudden learning of specific
capabilities by a neural network -- a phenomenon often called "emergence''.
Beyond scientific understanding, establishing the causal factors underlying
such emergent capabilities is crucial to enable risk regulation frameworks for
AI. In this work, we seek inspiration from study of emergent properties in
other fields and propose a phenomenological definition for the concept in the
context of neural networks. Our definition implicates the acquisition of
general structures underlying the data-generating process as a cause of sudden
performance growth for specific, narrower tasks. We empirically investigate
this definition by proposing an experimental system grounded in a
context-sensitive formal language and find that Transformers trained to perform
tasks on top of strings from this language indeed exhibit emergent
capabilities. Specifically, we show that once the language's underlying grammar
and context-sensitivity inducing structures are learned by the model,
performance on narrower tasks suddenly begins to improve. We then analogize our
network's learning dynamics with the process of percolation on a bipartite
graph, establishing a formal phase transition model that predicts the shift in
the point of emergence observed in our experiments when changing the data
structure. Overall, our experimental and theoretical frameworks yield a step
towards better defining, characterizing, and predicting emergence in neural
networks.

摘要：<paragraph>資料、規模或運算的增加，可能會導致神經網路突然學會特定能力——這種現象常稱為「湧現」。除了科學理解之外，確立這種湧現能力背後的基本原因，對於為 AI 建立風險法規框架至關重要。在這項工作中，我們從其他領域中對湧現特性的研究中尋求靈感，並針對神經網路中的概念提出現象學定義。我們的定義暗示，取得資料產生程序背後的通用結構，是特定、較狹隘任務突然效能提升的原因。我們透過提出一個以情境敏感形式語言為基礎的實驗系統，對這個定義進行實證研究，發現經過訓練以執行這個語言中字串頂部任務的 Transformer，確實展現出湧現能力。具體來說，我們展示出模型一旦學會語言的底層文法和情境敏感誘導結構，對較狹隘任務的效能就會突然開始提升。接著我們將網路的學習動態類比為二部圖上的滲流過程，建立一個正式的相變模型，用於預測在改變資料結構時，我們在實驗中觀察到的湧現點位移。整體而言，我們的實驗和理論框架朝著更完善地定義、描述和預測神經網路中的湧現邁進了一步。</paragraph>

##### **Enhancing Natural Language Inference Performance with Knowledge Graph for COVID-19 Automated Fact-Checking in Indonesian Language**
2409.00061v1 by Arief Purnama Muharram, Ayu Purwarianti

Automated fact-checking is a key strategy to overcome the spread of COVID-19
misinformation on the internet. These systems typically leverage deep learning
approaches through Natural Language Inference (NLI) to verify the truthfulness
of information based on supporting evidence. However, one challenge that arises
in deep learning is performance stagnation due to a lack of knowledge during
training. This study proposes using a Knowledge Graph (KG) as external
knowledge to enhance NLI performance for automated COVID-19 fact-checking in
the Indonesian language. The proposed model architecture comprises three
modules: a fact module, an NLI module, and a classifier module. The fact module
processes information from the KG, while the NLI module handles semantic
relationships between the given premise and hypothesis. The representation
vectors from both modules are concatenated and fed into the classifier module
to produce the final result. The model was trained using the generated
Indonesian COVID-19 fact-checking dataset and the COVID-19 KG Bahasa Indonesia.
Our study demonstrates that incorporating KGs can significantly improve NLI
performance in fact-checking, achieving the best accuracy of 0,8616. This
suggests that KGs are a valuable component for enhancing NLI performance in
automated fact-checking.

摘要：自動事實查核是克服網路上 COVID-19 錯誤資訊散播的一項關鍵策略。這些系統通常透過自然語言推論 (NLI) 來利用深度學習方法，根據支援證據驗證資訊的真實性。然而，在深度學習中會出現一個挑戰，那就是在訓練期間因缺乏知識而導致效能停滯。這項研究提出使用知識圖譜 (KG) 作為外部知識，以增強自動化 COVID-19 事實查核的 NLI 效能，並以印尼語進行。所提出的模型架構包含三個模組：事實模組、NLI 模組和分類器模組。事實模組處理來自 KG 的資訊，而 NLI 模組則處理給定前提和假設之間的語義關係。來自兩個模組的表示向量會串接起來，並輸入分類器模組以產生最終結果。此模型使用產生的印尼語 COVID-19 事實查核資料集和 COVID-19 KG Bahasa Indonesia 進行訓練。我們的研究證明，納入 KG 可以顯著改善事實查核中的 NLI 效能，達到 0.8616 的最佳準確度。這表示 KG 是增強自動化事實查核中 NLI 效能的寶貴組成部分。

##### **Cell-ontology guided transcriptome foundation model**
2408.12373v1 by Xinyu Yuan, Zhihao Zhan, Zuobai Zhang, Manqi Zhou, Jianan Zhao, Boyu Han, Yue Li, Jian Tang

Transcriptome foundation models TFMs hold great promises of deciphering the
transcriptomic language that dictate diverse cell functions by self-supervised
learning on large-scale single-cell gene expression data, and ultimately
unraveling the complex mechanisms of human diseases. However, current TFMs
treat cells as independent samples and ignore the taxonomic relationships
between cell types, which are available in cell ontology graphs. We argue that
effectively leveraging this ontology information during the TFM pre-training
can improve learning biologically meaningful gene co-expression patterns while
preserving TFM as a general purpose foundation model for downstream zero-shot
and fine-tuning tasks. To this end, we present \textbf{s}ingle \textbf{c}ell,
\textbf{Cell}-\textbf{o}ntology guided TFM scCello. We introduce cell-type
coherence loss and ontology alignment loss, which are minimized along with the
masked gene expression prediction loss during the pre-training. The novel loss
component guide scCello to learn the cell-type-specific representation and the
structural relation between cell types from the cell ontology graph,
respectively. We pre-trained scCello on 22 million cells from CellxGene
database leveraging their cell-type labels mapped to the cell ontology graph
from Open Biological and Biomedical Ontology Foundry. Our TFM demonstrates
competitive generalization and transferability performance over the existing
TFMs on biologically important tasks including identifying novel cell types of
unseen cells, prediction of cell-type-specific marker genes, and cancer drug
responses.

摘要：<paragraph>轉錄組基礎模型 TFM 承諾解碼轉錄組語言，它透過在大型單細胞基因表現資料上進行自我監督學習，來決定不同的細胞功能，並最終解開人類疾病的複雜機制。然而，目前的 TFM 將細胞視為獨立樣本，並忽略細胞類型之間的分類關係，而這在細胞本體論圖表中是可用的。我們認為在 TFM 預訓練期間有效利用此本體論資訊，可以改善學習生物學上有意義的基因共表現模式，同時保留 TFM 作為下游零次學習和微調任務的一般用途基礎模型。為此，我們提出單細胞、細胞本體論引導的 TFM scCello。我們引入細胞類型一致性損失和本體論對齊損失，在預訓練期間會將其與遮罩基因表現預測損失一起最小化。這個新穎的損失組件引導 scCello 分別從細胞本體論圖表中學習細胞類型特定表示和細胞類型之間的結構關係。我們在 CellxGene 資料庫中對 2200 萬個細胞進行 scCello 預訓練，利用其細胞類型標籤對應到開放生物和生物醫學本體鑄造廠的細胞本體論圖表。我們的 TFM 在生物學上重要的任務上展示了比現有 TFM 更具競爭力的泛化和可轉移性，包括識別未見細胞的新細胞類型、預測細胞類型特定標記基因和癌症藥物反應。</paragraph>

##### **Graph Retrieval Augmented Trustworthiness Reasoning**
2408.12333v2 by Ying Zhu, Shengchang Li, Ziqian Kong, Peilan Xu

Trustworthiness reasoning is crucial in multiplayer games with incomplete
information, enabling agents to identify potential allies and adversaries,
thereby enhancing reasoning and decision-making processes. Traditional
approaches relying on pre-trained models necessitate extensive domain-specific
data and considerable reward feedback, with their lack of real-time
adaptability hindering their effectiveness in dynamic environments. In this
paper, we introduce the Graph Retrieval Augmented Reasoning (GRATR) framework,
leveraging the Retrieval-Augmented Generation (RAG) technique to bolster
trustworthiness reasoning in agents. GRATR constructs a dynamic trustworthiness
graph, updating it in real-time with evidential information, and retrieves
relevant trust data to augment the reasoning capabilities of Large Language
Models (LLMs). We validate our approach through experiments on the multiplayer
game "Werewolf," comparing GRATR against baseline LLM and LLM enhanced with
Native RAG and Rerank RAG. Our results demonstrate that GRATR surpasses the
baseline methods by over 30\% in winning rate, with superior reasoning
performance. Moreover, GRATR effectively mitigates LLM hallucinations, such as
identity and objective amnesia, and crucially, it renders the reasoning process
more transparent and traceable through the use of the trustworthiness graph.

摘要：<paragraph>在信息不完整的多人遊戲中，可信度推理至關重要，讓代理人能夠識別潛在的盟友和敵人，從而增強推理和決策制定過程。依賴預先訓練模型的傳統方法需要大量的特定領域數據和大量的獎勵回饋，而它們缺乏實時適應性會阻礙它們在動態環境中的有效性。在本文中，我們介紹了圖形檢索增強推理 (GRATR) 框架，利用檢索增強生成 (RAG) 技術來加強代理人的可信度推理。GRATR 構建了一個動態可信度圖形，並使用證據信息實時更新它，並檢索相關的信任數據以增強大型語言模型 (LLM) 的推理能力。我們通過多人遊戲「狼人」的實驗驗證了我們的做法，將 GRATR 與基準 LLM 和使用 Native RAG 和 Rerank RAG 增強的 LLM 進行了比較。我們的結果表明，GRATR 在獲勝率上比基準方法高出 30%，具有卓越的推理性能。此外，GRATR 有效地減輕了 LLM 的幻覺，例如身份和目標健忘症，最重要的是，它通過使用可信度圖形使推理過程更透明且可追蹤。</paragraph>

##### **MedDiT: A Knowledge-Controlled Diffusion Transformer Framework for Dynamic Medical Image Generation in Virtual Simulated Patient**
2408.12236v1 by Yanzeng Li, Cheng Zeng, Jinchao Zhang, Jie Zhou, Lei Zou

Medical education relies heavily on Simulated Patients (SPs) to provide a
safe environment for students to practice clinical skills, including medical
image analysis. However, the high cost of recruiting qualified SPs and the lack
of diverse medical imaging datasets have presented significant challenges. To
address these issues, this paper introduces MedDiT, a novel
knowledge-controlled conversational framework that can dynamically generate
plausible medical images aligned with simulated patient symptoms, enabling
diverse diagnostic skill training. Specifically, MedDiT integrates various
patient Knowledge Graphs (KGs), which describe the attributes and symptoms of
patients, to dynamically prompt Large Language Models' (LLMs) behavior and
control the patient characteristics, mitigating hallucination during medical
conversation. Additionally, a well-tuned Diffusion Transformer (DiT) model is
incorporated to generate medical images according to the specified patient
attributes in the KG. In this paper, we present the capabilities of MedDiT
through a practical demonstration, showcasing its ability to act in diverse
simulated patient cases and generate the corresponding medical images. This can
provide an abundant and interactive learning experience for students, advancing
medical education by offering an immersive simulation platform for future
healthcare professionals. The work sheds light on the feasibility of
incorporating advanced technologies like LLM, KG, and DiT in education
applications, highlighting their potential to address the challenges faced in
simulated patient-based medical education.

摘要：醫學教育高度依賴模擬病人 (SP) 提供一個安全的環境，讓學生練習臨床技能，包括醫學影像分析。然而，招募合格 SP 的高成本和缺乏多樣的醫學影像資料集已造成顯著的挑戰。為了解決這些問題，本文介紹 MedDiT，一個新穎的知識控制對話架構，它可以動態產生符合模擬病人症狀的合理醫學影像，實現多樣的診斷技能訓練。具體來說，MedDiT 整合了各種病人知識圖譜 (KG)，描述病人的屬性和症狀，以動態提示大型語言模型 (LLM) 的行為，並控制病人特徵，減輕醫學對話中的幻覺。此外，還納入一個經過微調的擴散Transformer (DiT) 模型，根據 KG 中指定的病人屬性產生醫學影像。在本文中，我們透過實際示範展示 MedDiT 的功能，展示它在不同模擬病人案例中作用並產生相應醫學影像的能力。這可以為學生提供豐富且互動的學習體驗，透過提供身歷其境的模擬平台，提升醫學教育，造福未來的醫療保健專業人員。這項工作闡明了在教育應用中整合 LLM、KG 和 DiT 等先進技術的可行性，突顯它們在解決模擬病人為基礎的醫學教育所面臨挑戰的潛力。

##### **Geolocation Representation from Large Language Models are Generic Enhancers for Spatio-Temporal Learning**
2408.12116v1 by Junlin He, Tong Nie, Wei Ma

In the geospatial domain, universal representation models are significantly
less prevalent than their extensive use in natural language processing and
computer vision. This discrepancy arises primarily from the high costs
associated with the input of existing representation models, which often
require street views and mobility data. To address this, we develop a novel,
training-free method that leverages large language models (LLMs) and auxiliary
map data from OpenStreetMap to derive geolocation representations (LLMGeovec).
LLMGeovec can represent the geographic semantics of city, country, and global
scales, which acts as a generic enhancer for spatio-temporal learning.
Specifically, by direct feature concatenation, we introduce a simple yet
effective paradigm for enhancing multiple spatio-temporal tasks including
geographic prediction (GP), long-term time series forecasting (LTSF), and
graph-based spatio-temporal forecasting (GSTF). LLMGeovec can seamlessly
integrate into a wide spectrum of spatio-temporal learning models, providing
immediate enhancements. Experimental results demonstrate that LLMGeovec
achieves global coverage and significantly boosts the performance of leading
GP, LTSF, and GSTF models.

摘要：在空間地理領域，通用表示模型顯著少於它們在自然語言處理和電腦視覺中的廣泛使用。這種差異主要源於現有表示模型的輸入成本高，這通常需要街景和流動性資料。為了解決這個問題，我們開發一種新穎的免訓練方法，利用大型語言模型 (LLM) 和 OpenStreetMap 的輔助地圖資料來推導地理位置表示 (LLMGeovec)。LLMGeovec 可以表示城市、國家和全球規模的地理語義，作為時空學習的通用增強器。具體來說，通過直接特徵串接，我們引入了一個簡單但有效的範例，用於增強多個時空任務，包括地理預測 (GP)、長期時間序列預測 (LTSF) 和基於圖形的時空預測 (GSTF)。LLMGeovec 可以無縫整合到廣泛的時空學習模型中，提供立即的增強。實驗結果表明，LLMGeovec 達到了全球覆蓋率，並顯著提升了領先的 GP、LTSF 和 GSTF 模型的效能。

##### **Enabling Small Models for Zero-Shot Classification through Model Label Learning**
2408.11449v1 by Jia Zhang, Zhi Zhou, Lan-Zhe Guo, Yu-Feng Li

Vision-language models (VLMs) like CLIP have demonstrated impressive
zero-shot ability in image classification tasks by aligning text and images but
suffer inferior performance compared with task-specific expert models. On the
contrary, expert models excel in their specialized domains but lack zero-shot
ability for new tasks. How to obtain both the high performance of expert models
and zero-shot ability is an important research direction. In this paper, we
attempt to demonstrate that by constructing a model hub and aligning models
with their functionalities using model labels, new tasks can be solved in a
zero-shot manner by effectively selecting and reusing models in the hub. We
introduce a novel paradigm, Model Label Learning (MLL), which bridges the gap
between models and their functionalities through a Semantic Directed Acyclic
Graph (SDAG) and leverages an algorithm, Classification Head Combination
Optimization (CHCO), to select capable models for new tasks. Compared with the
foundation model paradigm, it is less costly and more scalable, i.e., the
zero-shot ability grows with the sizes of the model hub. Experiments on seven
real-world datasets validate the effectiveness and efficiency of MLL,
demonstrating that expert models can be effectively reused for zero-shot tasks.
Our code will be released publicly.

摘要：視覺語言模型（VLM），例如 CLIP，已在影像分類任務中展現令人印象深刻的零次學習能力，方法是對齊文字和影像，但與特定任務的專家模型相比，其效能較差。相反地，專家模型在其專業領域中表現出色，但對於新任務缺乏零次學習能力。如何同時獲得專家模型的高效能和零次學習能力，是一個重要的研究方向。在本文中，我們嘗試透過建立模型中心，並使用模型標籤將模型與其功能對齊，證明可以透過有效選擇和重複使用中心中的模型，以零次學習的方式解決新任務。我們提出了一種新的範例，即模型標籤學習（MLL），它透過語義導向非循環圖（SDAG）彌合模型及其功能之間的差距，並利用一種演算法，即分類頭組合最佳化（CHCO），為新任務選擇有能力的模型。與基礎模型範例相比，它的成本較低且更具可擴充性，也就是說，零次學習能力會隨著模型中心規模的擴大而增長。在七個真實世界資料集上的實驗驗證了 MLL 的有效性和效率，證明了專家模型可以有效地重複用於零次學習任務。我們的程式碼將公開發布。


### Medical explainable AI
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-09-20**|**Dermatologist-like explainable AI enhances melanoma diagnosis accuracy: eye-tracking study**|Tirtha Chanda et.al.|[2409.13476v1](http://arxiv.org/abs/2409.13476v1)|null|
|**2024-09-19**|**Explainable AI for Autism Diagnosis: Identifying Critical Brain Regions Using fMRI Data**|Suryansh Vidya et.al.|[2409.15374v1](http://arxiv.org/abs/2409.15374v1)|null|
|**2024-09-19**|**Improving Prototypical Parts Abstraction for Case-Based Reasoning Explanations Designed for the Kidney Stone Type Recognition**|Daniel Flores-Araiza et.al.|[2409.12883v1](http://arxiv.org/abs/2409.12883v1)|null|
|**2024-09-18**|**Towards Interpretable End-Stage Renal Disease (ESRD) Prediction: Utilizing Administrative Claims Data with Explainable AI Techniques**|Yubo Li et.al.|[2409.12087v1](http://arxiv.org/abs/2409.12087v1)|null|
|**2024-09-09**|**Explainable AI: Definition and attributes of a good explanation for health AI**|Evangelia Kyrimi et.al.|[2409.15338v1](http://arxiv.org/abs/2409.15338v1)|null|
|**2024-08-30**|**Exploring the Effect of Explanation Content and Format on User Comprehension and Trust**|Antonio Rago et.al.|[2408.17401v1](http://arxiv.org/abs/2408.17401v1)|null|
|**2024-08-29**|**A Survey for Large Language Models in Biomedicine**|Chong Wang et.al.|[2409.00133v1](http://arxiv.org/abs/2409.00133v1)|null|
|**2024-08-27**|**Aligning XAI with EU Regulations for Smart Biomedical Devices: A Methodology for Compliance Analysis**|Francesco Sovrano et.al.|[2408.15121v1](http://arxiv.org/abs/2408.15121v1)|null|
|**2024-08-24**|**Towards Case-based Interpretability for Medical Federated Learning**|Laura Latorre et.al.|[2408.13626v1](http://arxiv.org/abs/2408.13626v1)|null|
|**2024-08-22**|**AI in radiological imaging of soft-tissue and bone tumours: a systematic review evaluating against CLAIM and FUTURE-AI guidelines**|Douwe J. Spaanderman et.al.|[2408.12491v1](http://arxiv.org/abs/2408.12491v1)|null|
|**2024-08-14**|**Evaluating Explainable AI Methods in Deep Learning Models for Early Detection of Cerebral Palsy**|Kimji N. Pellano et.al.|[2409.00001v1](http://arxiv.org/abs/2409.00001v1)|null|
|**2024-08-06**|**MicroXercise: A Micro-Level Comparative and Explainable System for Remote Physical Therapy**|Hanchen David Wang et.al.|[2408.11837v1](http://arxiv.org/abs/2408.11837v1)|null|
|**2024-08-05**|**The Literature Review Network: An Explainable Artificial Intelligence for Systematic Literature Reviews, Meta-analyses, and Method Development**|Joshua Morriss et.al.|[2408.05239v1](http://arxiv.org/abs/2408.05239v1)|null|
|**2024-08-05**|**Enhancing Medical Learning and Reasoning Systems: A Boxology-Based Comparative Analysis of Design Patterns**|Chi Him Ng et.al.|[2408.02709v1](http://arxiv.org/abs/2408.02709v1)|null|
|**2024-08-05**|**Bayesian Kolmogorov Arnold Networks (Bayesian_KANs): A Probabilistic Approach to Enhance Accuracy and Interpretability**|Masoud Muhammed Hassan et.al.|[2408.02706v1](http://arxiv.org/abs/2408.02706v1)|null|
|**2024-07-26**|**MLtoGAI: Semantic Web based with Machine Learning for Enhanced Disease Prediction and Personalized Recommendations using Generative AI**|Shyam Dongre et.al.|[2407.20284v1](http://arxiv.org/abs/2407.20284v1)|null|
|**2024-07-25**|**Introducing δ-XAI: a novel sensitivity-based method for local AI explanations**|Alessandro De Carlo et.al.|[2407.18343v2](http://arxiv.org/abs/2407.18343v2)|null|
|**2024-07-24**|**Enhanced Deep Learning Methodologies and MRI Selection Techniques for Dementia Diagnosis in the Elderly Population**|Nikolaos Ntampakis et.al.|[2407.17324v2](http://arxiv.org/abs/2407.17324v2)|null|
|**2024-07-24**|**Using Large Language Models to Compare Explainable Models for Smart Home Human Activity Recognition**|Michele Fiori et.al.|[2408.06352v1](http://arxiv.org/abs/2408.06352v1)|null|
|**2024-07-21**|**Explainable AI-based Intrusion Detection System for Industry 5.0: An Overview of the Literature, associated Challenges, the existing Solutions, and Potential Research Directions**|Naseem Khan et.al.|[2408.03335v1](http://arxiv.org/abs/2408.03335v1)|null|
|**2024-07-18**|**A Comparative Study on Automatic Coding of Medical Letters with Explainability**|Jamie Glen et.al.|[2407.13638v1](http://arxiv.org/abs/2407.13638v1)|[link](https://github.com/Glenj01/Medical-Coding)|
|**2024-07-09**|**Explainable AI for Enhancing Efficiency of DL-based Channel Estimation**|Abdul Karim Gizzini et.al.|[2407.07009v1](http://arxiv.org/abs/2407.07009v1)|null|
|**2024-07-07**|**Explainable AI: Comparative Analysis of Normal and Dilated ResNet Models for Fundus Disease Classification**|P. N. Karthikayan et.al.|[2407.05440v2](http://arxiv.org/abs/2407.05440v2)|null|
|**2024-07-03**|**A Survey on Trustworthiness in Foundation Models for Medical Image Analysis**|Congzhen Shi et.al.|[2407.15851v1](http://arxiv.org/abs/2407.15851v1)|null|
|**2024-07-01**|**The Impact of an XAI-Augmented Approach on Binary Classification with Scarce Data**|Ximing Wen et.al.|[2407.06206v1](http://arxiv.org/abs/2407.06206v1)|null|
|**2024-06-28**|**Can GPT-4 Help Detect Quit Vaping Intentions? An Exploration of Automatic Data Annotation Approach**|Sai Krishna Revanth Vuruma et.al.|[2407.00167v1](http://arxiv.org/abs/2407.00167v1)|null|
|**2024-06-25**|**Towards Compositional Interpretability for XAI**|Sean Tull et.al.|[2406.17583v1](http://arxiv.org/abs/2406.17583v1)|null|
|**2024-06-11**|**Unlocking the Potential of Metaverse in Innovative and Immersive Digital Health**|Fatemeh Ebrahimzadeh et.al.|[2406.07114v2](http://arxiv.org/abs/2406.07114v2)|null|
|**2024-06-10**|**AI-Driven Predictive Analytics Approach for Early Prognosis of Chronic Kidney Disease Using Ensemble Learning and Explainable AI**|K M Tawsik Jawad et.al.|[2406.06728v1](http://arxiv.org/abs/2406.06728v1)|null|
|**2024-06-10**|**Explainable AI for Mental Disorder Detection via Social Media: A survey and outlook**|Yusif Ibrahimov et.al.|[2406.05984v1](http://arxiv.org/abs/2406.05984v1)|null|
|**2024-06-09**|**Methodology and Real-World Applications of Dynamic Uncertain Causality Graph for Clinical Diagnosis with Explainability and Invariance**|Zhan Zhang et.al.|[2406.05746v1](http://arxiv.org/abs/2406.05746v1)|null|
|**2024-06-07**|**Advancing Histopathology-Based Breast Cancer Diagnosis: Insights into Multi-Modality and Explainability**|Faseela Abdullakutty et.al.|[2406.12897v1](http://arxiv.org/abs/2406.12897v1)|null|
|**2024-06-07**|**Revisiting Attention Weights as Interpretations of Message-Passing Neural Networks**|Yong-Min Shin et.al.|[2406.04612v1](http://arxiv.org/abs/2406.04612v1)|[link](https://github.com/jordan7186/gatt)|
|**2024-06-04**|**Using Explainable AI for EEG-based Reduced Montage Neonatal Seizure Detection**|Dinuka Sandun Udayantha et.al.|[2406.16908v3](http://arxiv.org/abs/2406.16908v3)|[link](https://github.com/dinuka-1999/braineocare)|
|**2024-06-01**|**Breast Cancer Diagnosis: A Comprehensive Exploration of Explainable Artificial Intelligence (XAI) Techniques**|Samita Bai et.al.|[2406.00532v1](http://arxiv.org/abs/2406.00532v1)|null|
|**2024-06-01**|**Unveiling Hidden Factors: Explainable AI for Feature Boosting in Speech Emotion Recognition**|Alaa Nfissi et.al.|[2406.01624v2](http://arxiv.org/abs/2406.01624v2)|[link](https://github.com/alaanfissi/unveiling-hidden-factors-explainable-ai-for-feature-boosting-in-speech-emotion-recognition)|
|**2024-05-31**|**The Explanation Necessity for Healthcare AI**|Michail Mamalakis et.al.|[2406.00216v1](http://arxiv.org/abs/2406.00216v1)|null|
|**2024-05-29**|**Interdisciplinary Expertise to Advance Equitable Explainable AI**|Chloe R. Bennett et.al.|[2406.18563v1](http://arxiv.org/abs/2406.18563v1)|null|
|**2024-05-27**|**"It depends": Configuring AI to Improve Clinical Usefulness Across Contexts**|Hubert D. Zając et.al.|[2407.11978v1](http://arxiv.org/abs/2407.11978v1)|null|
|**2024-05-26**|**Improving Health Professionals' Onboarding with AI and XAI for Trustworthy Human-AI Collaborative Decision Making**|Min Hun Lee et.al.|[2405.16424v1](http://arxiv.org/abs/2405.16424v1)|null|
|**2024-05-26**|**Exploring Nutritional Impact on Alzheimer's Mortality: An Explainable AI Approach**|Ziming Liu et.al.|[2405.17502v1](http://arxiv.org/abs/2405.17502v1)|null|
|**2024-05-24**|**Explainable AI Enhances Glaucoma Referrals, Yet the Human-AI Team Still Falls Short of the AI Alone**|Catalina Gomez et.al.|[2407.11974v1](http://arxiv.org/abs/2407.11974v1)|null|
|**2024-05-23**|**Decoding Decision Reasoning: A Counterfactual-Powered Model for Knowledge Discovery**|Yingying Fang et.al.|[2406.18552v1](http://arxiv.org/abs/2406.18552v1)|null|
|**2024-05-21**|**The Role of Emotions in Informational Support Question-Response Pairs in Online Health Communities: A Multimodal Deep Learning Approach**|Mohsen Jozani et.al.|[2405.13099v1](http://arxiv.org/abs/2405.13099v1)|null|
|**2024-05-17**|**ChatGPT in Classrooms: Transforming Challenges into Opportunities in Education**|Harris Bin Munawar et.al.|[2405.10645v1](http://arxiv.org/abs/2405.10645v1)|null|
|**2024-05-13**|**Evaluating the Explainable AI Method Grad-CAM for Breath Classification on Newborn Time Series Data**|Camelia Oprea et.al.|[2405.07590v1](http://arxiv.org/abs/2405.07590v1)|null|
|**2024-05-10**|**XAI4LLM. Let Machine Learning Models and LLMs Collaborate for Enhanced In-Context Learning in Healthcare**|Fatemeh Nazary et.al.|[2405.06270v3](http://arxiv.org/abs/2405.06270v3)|null|
|**2024-05-09**|**To Trust or Not to Trust: Towards a novel approach to measure trust for XAI systems**|Miquel Miró-Nicolau et.al.|[2405.05766v1](http://arxiv.org/abs/2405.05766v1)|null|
|**2024-05-05**|**Region-specific Risk Quantification for Interpretable Prognosis of COVID-19**|Zhusi Zhong et.al.|[2405.02815v1](http://arxiv.org/abs/2405.02815v1)|[link](https://github.com/zzs95/RSP_COVID)|
|**2024-04-26**|**Rad4XCNN: a new agnostic method for post-hoc global explanation of CNN-derived features by means of radiomics**|Francesco Prinzi et.al.|[2405.02334v1](http://arxiv.org/abs/2405.02334v1)|null|
|**2024-04-25**|**Attributing Responsibility in AI-Induced Incidents: A Computational Reflective Equilibrium Framework for Accountability**|Yunfei Ge et.al.|[2404.16957v1](http://arxiv.org/abs/2404.16957v1)|null|
|**2024-04-19**|**Explainable AI for Fair Sepsis Mortality Predictive Model**|Chia-Hsuan Chang et.al.|[2404.13139v1](http://arxiv.org/abs/2404.13139v1)|null|
|**2024-04-19**|**Multi Class Depression Detection Through Tweets using Artificial Intelligence**|Muhammad Osama Nusrat et.al.|[2404.13104v1](http://arxiv.org/abs/2404.13104v1)|[link](https://github.com/mnusrat786/masters-thesis)|
|**2024-04-19**|**COIN: Counterfactual inpainting for weakly supervised semantic segmentation for medical images**|Dmytro Shvetsov et.al.|[2404.12832v2](http://arxiv.org/abs/2404.12832v2)|[link](https://github.com/dmytro-shvetsov/counterfactual-search)|
|**2024-04-15**|**Hybrid Intelligence for Digital Humanities**|Victor de Boer et.al.|[2406.15374v1](http://arxiv.org/abs/2406.15374v1)|null|
|**2024-04-14**|**Ethical Framework for Responsible Foundational Models in Medical Imaging**|Abhijit Das et.al.|[2406.11868v1](http://arxiv.org/abs/2406.11868v1)|null|
|**2024-04-09**|**Advancements in Radiomics and Artificial Intelligence for Thyroid Cancer Diagnosis**|Milad Yousefi et.al.|[2404.07239v1](http://arxiv.org/abs/2404.07239v1)|null|
|**2024-04-06**|**Predictive Modeling for Breast Cancer Classification in the Context of Bangladeshi Patients: A Supervised Machine Learning Approach with Explainable AI**|Taminul Islam et.al.|[2404.04686v1](http://arxiv.org/abs/2404.04686v1)|null|
|**2024-04-05**|**Enhancing Breast Cancer Diagnosis in Mammography: Evaluation and Integration of Convolutional Neural Networks and Explainable AI**|Maryam Ahmed et.al.|[2404.03892v3](http://arxiv.org/abs/2404.03892v3)|null|
|**2024-03-30**|**Advancing Multimodal Data Fusion in Pain Recognition: A Strategy Leveraging Statistical Correlation and Human-Centered Perspectives**|Xingrui Gu et.al.|[2404.00320v2](http://arxiv.org/abs/2404.00320v2)|null|
|**2024-03-26**|**Addressing Social Misattributions of Large Language Models: An HCXAI-based Approach**|Andrea Ferrario et.al.|[2403.17873v1](http://arxiv.org/abs/2403.17873v1)|null|
|**2024-03-26**|**Clinical Domain Knowledge-Derived Template Improves Post Hoc AI Explanations in Pneumothorax Classification**|Han Yuan et.al.|[2403.18871v1](http://arxiv.org/abs/2403.18871v1)|[link](https://github.com/han-yuan-med/template-explanation)|
|**2024-03-03**|**Enhancing Neural Machine Translation of Low-Resource Languages: Corpus Development, Human Evaluation and Explainable AI Architectures**|Séamus Lankford et.al.|[2403.01580v1](http://arxiv.org/abs/2403.01580v1)|null|
|**2024-02-28**|**Artificial Intelligence and Diabetes Mellitus: An Inside Look Through the Retina**|Yasin Sadeghi Bazargani et.al.|[2402.18600v1](http://arxiv.org/abs/2402.18600v1)|null|
|**2024-02-22**|**Multi-stakeholder Perspective on Responsible Artificial Intelligence and Acceptability in Education**|A. J. Karran et.al.|[2402.15027v2](http://arxiv.org/abs/2402.15027v2)|null|
|**2024-02-12**|**Deciphering Heartbeat Signatures: A Vision Transformer Approach to Explainable Atrial Fibrillation Detection from ECG Signals**|Aruna Mohan et.al.|[2402.09474v2](http://arxiv.org/abs/2402.09474v2)|null|
|**2024-02-05**|**Illuminate: A novel approach for depression detection with explainable analysis and proactive therapy using prompt engineering**|Aryan Agrawal et.al.|[2402.05127v1](http://arxiv.org/abs/2402.05127v1)|null|
|**2024-01-24**|**Information That Matters: Exploring Information Needs of People Affected by Algorithmic Decisions**|Timothée Schmude et.al.|[2401.13324v5](http://arxiv.org/abs/2401.13324v5)|null|
|**2024-01-02**|**Evaluating Large Language Models on the GMAT: Implications for the Future of Business Education**|Vahid Ashrafimoghari et.al.|[2401.02985v1](http://arxiv.org/abs/2401.02985v1)|null|
|**2023-12-29**|**XAI for In-hospital Mortality Prediction via Multimodal ICU Data**|Xingqiao Li et.al.|[2312.17624v1](http://arxiv.org/abs/2312.17624v1)|[link](https://github.com/lixingqiao/xai-icu)|
|**2023-12-22**|**Joining Forces for Pathology Diagnostics with AI Assistance: The EMPAIA Initiative**|Norman Zerbe et.al.|[2401.09450v2](http://arxiv.org/abs/2401.09450v2)|null|
|**2023-12-18**|**Robust Stochastic Graph Generator for Counterfactual Explanations**|Mario Alfonso Prado-Romero et.al.|[2312.11747v2](http://arxiv.org/abs/2312.11747v2)|null|
|**2023-12-10**|**Evaluating the Utility of Model Explanations for Model Development**|Shawn Im et.al.|[2312.06032v1](http://arxiv.org/abs/2312.06032v1)|null|
|**2023-12-05**|**Building Trustworthy NeuroSymbolic AI Systems: Consistency, Reliability, Explainability, and Safety**|Manas Gaur et.al.|[2312.06798v1](http://arxiv.org/abs/2312.06798v1)|null|
|**2023-11-28**|**Deployment of a Robust and Explainable Mortality Prediction Model: The COVID-19 Pandemic and Beyond**|Jacob R. Epifano et.al.|[2311.17133v1](http://arxiv.org/abs/2311.17133v1)|null|
|**2023-11-27**|**Variational Autoencoders for Feature Exploration and Malignancy Prediction of Lung Lesions**|Benjamin Keel et.al.|[2311.15719v1](http://arxiv.org/abs/2311.15719v1)|[link](https://github.com/benkeel/vae_lung_lesion_bmvc)|
|**2023-11-24**|**MRxaI: Black-Box Explainability for Image Classifiers in a Medical Setting**|Nathan Blake et.al.|[2311.14471v1](http://arxiv.org/abs/2311.14471v1)|null|
|**2023-11-21**|**Moderating Model Marketplaces: Platform Governance Puzzles for AI Intermediaries**|Robert Gorwa et.al.|[2311.12573v3](http://arxiv.org/abs/2311.12573v3)|null|
|**2023-11-20**|**Ovarian Cancer Data Analysis using Deep Learning: A Systematic Review from the Perspectives of Key Features of Data Analysis and AI Assurance**|Muta Tah Hira et.al.|[2311.11932v1](http://arxiv.org/abs/2311.11932v1)|null|
|**2023-11-18**|**Representing visual classification as a linear combination of words**|Shobhit Agarwal et.al.|[2311.10933v1](http://arxiv.org/abs/2311.10933v1)|[link](https://github.com/lotterlab/task_word_explainability)|
|**2023-11-03**|**Towards objective and systematic evaluation of bias in artificial intelligence for medical imaging**|Emma A. M. Stanley et.al.|[2311.02115v2](http://arxiv.org/abs/2311.02115v2)|[link](https://github.com/estanley16/simba)|
|**2023-10-29**|**Predicting recovery following stroke: deep learning, multimodal data and feature selection using explainable AI**|Adam White et.al.|[2310.19174v1](http://arxiv.org/abs/2310.19174v1)|null|
|**2023-10-03**|**Trainable Noise Model as an XAI evaluation method: application on Sobol for remote sensing image segmentation**|Hossein Shreim et.al.|[2310.01828v2](http://arxiv.org/abs/2310.01828v2)|[link](https://github.com/geoaigroup/geoai-ecrs2023)|
|**2023-09-26**|**Creating Trustworthy LLMs: Dealing with Hallucinations in Healthcare AI**|Muhammad Aurangzeb Ahmad et.al.|[2311.01463v1](http://arxiv.org/abs/2311.01463v1)|null|
|**2023-09-20**|**When to Trust AI: Advances and Challenges for Certification of Neural Networks**|Marta Kwiatkowska et.al.|[2309.11196v1](http://arxiv.org/abs/2309.11196v1)|null|
|**2023-09-19**|**Functional requirements to mitigate the Risk of Harm to Patients from Artificial Intelligence in Healthcare**|Juan M. García-Gómez et.al.|[2309.10424v1](http://arxiv.org/abs/2309.10424v1)|null|
|**2023-09-19**|**QXAI: Explainable AI Framework for Quantitative Analysis in Patient Monitoring Systems**|Thanveer Shaik et.al.|[2309.10293v3](http://arxiv.org/abs/2309.10293v3)|null|
|**2023-09-18**|**Evaluation of Human-Understandability of Global Model Explanations using Decision Tree**|Adarsa Sivaprasad et.al.|[2309.09917v1](http://arxiv.org/abs/2309.09917v1)|null|
|**2023-08-28**|**Leveraging A Medical Knowledge Graph into Large Language Models for Diagnosis Prediction**|Yanjun Gao et.al.|[2308.14321v1](http://arxiv.org/abs/2308.14321v1)|null|
|**2023-08-18**|**Deciphering knee osteoarthritis diagnostic features with explainable artificial intelligence: A systematic review**|Yun Xin Teoh et.al.|[2308.09380v1](http://arxiv.org/abs/2308.09380v1)|null|
|**2023-08-16**|**Explainable AI for clinical risk prediction: a survey of concepts, methods, and modalities**|Munib Mesinovic et.al.|[2308.08407v1](http://arxiv.org/abs/2308.08407v1)|null|
|**2023-08-11**|**FUTURE-AI: International consensus guideline for trustworthy and deployable artificial intelligence in healthcare**|Karim Lekadir et.al.|[2309.12325v3](http://arxiv.org/abs/2309.12325v3)|null|
|**2023-08-10**|**Explainable AI applications in the Medical Domain: a systematic review**|Nicoletta Prentzas et.al.|[2308.05411v1](http://arxiv.org/abs/2308.05411v1)|null|
|**2023-08-01**|**Exploring the Role of Explainability in AI-Assisted Embryo Selection**|Lucia Urcelay et.al.|[2308.02534v1](http://arxiv.org/abs/2308.02534v1)|null|
|**2023-07-26**|**A New Perspective on Evaluation Methods for Explainable Artificial Intelligence (XAI)**|Timo Speith et.al.|[2307.14246v1](http://arxiv.org/abs/2307.14246v1)|null|
|**2023-07-26**|**Revisiting the Performance-Explainability Trade-Off in Explainable Artificial Intelligence (XAI)**|Barnaby Crook et.al.|[2307.14239v1](http://arxiv.org/abs/2307.14239v1)|null|
|**2023-07-26**|**Acceptable risks in Europe's proposed AI Act: Reasonableness and other principles for deciding how much risk management is enough**|Henry Fraser et.al.|[2308.02047v1](http://arxiv.org/abs/2308.02047v1)|null|
|**2023-07-21**|**eXplainable Artificial Intelligence (XAI) in aging clock models**|Alena Kalyakulina et.al.|[2307.13704v3](http://arxiv.org/abs/2307.13704v3)|null|
|**2023-07-19**|**Interpreting and Correcting Medical Image Classification with PIP-Net**|Meike Nauta et.al.|[2307.10404v2](http://arxiv.org/abs/2307.10404v2)|[link](https://github.com/m-nauta/pipnet)|
|**2023-07-15**|**Explaining and visualizing black-box models through counterfactual paths**|Bastian Pfeifer et.al.|[2307.07764v3](http://arxiv.org/abs/2307.07764v3)|[link](https://github.com/pievos101/cpath)|

#### Abstracts
##### **Dermatologist-like explainable AI enhances melanoma diagnosis accuracy: eye-tracking study**
2409.13476v1 by Tirtha Chanda, Sarah Haggenmueller, Tabea-Clara Bucher, Tim Holland-Letz, Harald Kittler, Philipp Tschandl, Markus V. Heppt, Carola Berking, Jochen S. Utikal, Bastian Schilling, Claudia Buerger, Cristian Navarrete-Dechent, Matthias Goebeler, Jakob Nikolas Kather, Carolin V. Schneider, Benjamin Durani, Hendrike Durani, Martin Jansen, Juliane Wacker, Joerg Wacker, Reader Study Consortium, Titus J. Brinker

Artificial intelligence (AI) systems have substantially improved
dermatologists' diagnostic accuracy for melanoma, with explainable AI (XAI)
systems further enhancing clinicians' confidence and trust in AI-driven
decisions. Despite these advancements, there remains a critical need for
objective evaluation of how dermatologists engage with both AI and XAI tools.
In this study, 76 dermatologists participated in a reader study, diagnosing 16
dermoscopic images of melanomas and nevi using an XAI system that provides
detailed, domain-specific explanations. Eye-tracking technology was employed to
assess their interactions. Diagnostic performance was compared with that of a
standard AI system lacking explanatory features. Our findings reveal that XAI
systems improved balanced diagnostic accuracy by 2.8 percentage points relative
to standard AI. Moreover, diagnostic disagreements with AI/XAI systems and
complex lesions were associated with elevated cognitive load, as evidenced by
increased ocular fixations. These insights have significant implications for
clinical practice, the design of AI tools for visual tasks, and the broader
development of XAI in medical diagnostics.

摘要：人工智慧 (AI) 系統已大幅改善皮膚科醫師對黑色素瘤的診斷準確度，而可解釋 AI (XAI) 系統進一步提升臨床醫師對 AI 驅動決策的信心與信賴。儘管有這些進展，對於皮膚科醫師如何使用 AI 和 XAI 工具，仍有客觀評估的迫切需求。在這項研究中，76 位皮膚科醫師參與了一項讀者研究，使用 XAI 系統診斷 16 張黑色素瘤和痣的皮膚鏡影像，該系統提供詳細的領域特定說明。採用眼球追蹤技術來評估他們的互動。將診斷表現與缺乏說明功能的標準 AI 系統進行比較。我們的研究結果顯示，XAI 系統相較於標準 AI，將平衡診斷準確度提升了 2.8 個百分點。此外，與 AI/XAI 系統的診斷分歧和複雜的病灶與認知負擔升高有關，這由增加的眼睛注視次數所證實。這些見解對臨床實務、視覺任務 AI 工具的設計和醫學診斷中 XAI 的廣泛發展具有重大意義。

##### **Explainable AI for Autism Diagnosis: Identifying Critical Brain Regions Using fMRI Data**
2409.15374v1 by Suryansh Vidya, Kush Gupta, Amir Aly, Andy Wills, Emmanuel Ifeachor, Rohit Shankar

Early diagnosis and intervention for Autism Spectrum Disorder (ASD) has been
shown to significantly improve the quality of life of autistic individuals.
However, diagnostics methods for ASD rely on assessments based on clinical
presentation that are prone to bias and can be challenging to arrive at an
early diagnosis. There is a need for objective biomarkers of ASD which can help
improve diagnostic accuracy. Deep learning (DL) has achieved outstanding
performance in diagnosing diseases and conditions from medical imaging data.
Extensive research has been conducted on creating models that classify ASD
using resting-state functional Magnetic Resonance Imaging (fMRI) data. However,
existing models lack interpretability. This research aims to improve the
accuracy and interpretability of ASD diagnosis by creating a DL model that can
not only accurately classify ASD but also provide explainable insights into its
working. The dataset used is a preprocessed version of the Autism Brain Imaging
Data Exchange (ABIDE) with 884 samples. Our findings show a model that can
accurately classify ASD and highlight critical brain regions differing between
ASD and typical controls, with potential implications for early diagnosis and
understanding of the neural basis of ASD. These findings are validated by
studies in the literature that use different datasets and modalities,
confirming that the model actually learned characteristics of ASD and not just
the dataset. This study advances the field of explainable AI in medical imaging
by providing a robust and interpretable model, thereby contributing to a future
with objective and reliable ASD diagnostics.

摘要：自閉症譜系障礙 (ASD) 的早期診斷和介入已被證實能顯著改善自閉症患者的生活品質。然而，ASD 的診斷方法依賴於基於臨床表現的評估，容易產生偏見，且可能難以做出早期診斷。有必要找出 ASD 的客觀生物標記，以幫助提高診斷準確性。深度學習 (DL) 在從醫學影像資料診斷疾病和病症方面取得傑出的表現。已經針對建立使用靜態功能性磁振造影 (fMRI) 資料對 ASD 進行分類的模型進行廣泛的研究。然而，現有的模型缺乏可解釋性。本研究旨在透過建立一個不僅能準確分類 ASD，還能提供可解釋見解說明其運作原理的 DL 模型，來改善 ASD 診斷的準確性和可解釋性。所使用的資料集是自閉症大腦影像資料交換 (ABIDE) 的預處理版本，包含 884 個樣本。我們的研究結果顯示，該模型能準確分類 ASD，並強調 ASD 與典型對照組之間存在差異的關鍵腦區，對於 ASD 的早期診斷和神經基礎的理解具有潛在的意義。這些研究結果已由使用不同資料集和方式的文獻研究驗證，證實該模型實際上學習了 ASD 的特徵，而不僅僅是資料集。本研究透過提供一個強健且可解釋的模型，推動了醫學影像中可解釋 AI 的領域，從而為未來提供客觀且可靠的 ASD 診斷做出貢獻。

##### **Improving Prototypical Parts Abstraction for Case-Based Reasoning Explanations Designed for the Kidney Stone Type Recognition**
2409.12883v1 by Daniel Flores-Araiza, Francisco Lopez-Tiro, Clément Larose, Salvador Hinojosa, Andres Mendez-Vazquez, Miguel Gonzalez-Mendoza, Gilberto Ochoa-Ruiz, Christian Daul

The in-vivo identification of the kidney stone types during an ureteroscopy
would be a major medical advance in urology, as it could reduce the time of the
tedious renal calculi extraction process, while diminishing infection risks.
Furthermore, such an automated procedure would make possible to prescribe
anti-recurrence treatments immediately. Nowadays, only few experienced
urologists are able to recognize the kidney stone types in the images of the
videos displayed on a screen during the endoscopy. Thus, several deep learning
(DL) models have recently been proposed to automatically recognize the kidney
stone types using ureteroscopic images. However, these DL models are of black
box nature whicl limits their applicability in clinical settings. This
contribution proposes a case-based reasoning DL model which uses prototypical
parts (PPs) and generates local and global descriptors. The PPs encode for each
class (i.e., kidney stone type) visual feature information (hue, saturation,
intensity and textures) similar to that used by biologists. The PPs are
optimally generated due a new loss function used during the model training.
Moreover, the local and global descriptors of PPs allow to explain the
decisions ("what" information, "where in the images") in an understandable way
for biologists and urologists. The proposed DL model has been tested on a
database including images of the six most widespread kidney stone types. The
overall average classification accuracy was 90.37. When comparing this results
with that of the eight other DL models of the kidney stone state-of-the-art, it
can be seen that the valuable gain in explanability was not reached at the
expense of accuracy which was even slightly increased with respect to that
(88.2) of the best method of the literature. These promising and interpretable
results also encourage urologists to put their trust in AI-based solutions.

摘要：尿路鏡檢查中腎結石類型的體內識別將是泌尿科的一項重大進展，因為它可以減少繁瑣的腎結石取出過程的時間，同時降低感染風險。此外，這種自動化程序將使立即開立抗復發治療成為可能。如今，只有少數經驗豐富的泌尿科醫生能夠在內視鏡檢查期間屏幕上顯示的視頻圖像中識別腎結石類型。因此，最近已提出多種深度學習 (DL) 模型，以使用輸尿管鏡圖像自動識別腎結石類型。然而，這些 DL 模型本質上是黑盒子，這限制了它們在臨床環境中的應用性。本文提出了一個基於案例推理的 DL 模型，它使用原型部分 (PP) 並生成局部和全局描述符。PP 為每種類型（即腎結石類型）編碼視覺特徵信息（色調、飽和度、強度和紋理），類似於生物學家使用的信息。由於在模型訓練期間使用的新損失函數，PP 得到了最佳生成。此外，PP 的局部和全局描述符允許以生物學家和泌尿科醫生可以理解的方式解釋決策（“什麼”信息，“圖像中的什麼位置”）。所提出的 DL 模型已在一個包含六種最廣泛的腎結石類型圖像的數據庫上進行了測試。總體平均分類準確率為 90.37。將此結果與腎結石最先進的八個其他 DL 模型的結果進行比較時，可以看出，可解釋性的寶貴增益並未以準確性為代價，甚至略有增加與文獻中最好的方法 (88.2) 相比。這些有希望且可解釋的結果也鼓勵泌尿科醫生相信基於人工智能的解決方案。

##### **Towards Interpretable End-Stage Renal Disease (ESRD) Prediction: Utilizing Administrative Claims Data with Explainable AI Techniques**
2409.12087v1 by Yubo Li, Saba Al-Sayouri, Rema Padman

This study explores the potential of utilizing administrative claims data,
combined with advanced machine learning and deep learning techniques, to
predict the progression of Chronic Kidney Disease (CKD) to End-Stage Renal
Disease (ESRD). We analyze a comprehensive, 10-year dataset provided by a major
health insurance organization to develop prediction models for multiple
observation windows using traditional machine learning methods such as Random
Forest and XGBoost as well as deep learning approaches such as Long Short-Term
Memory (LSTM) networks. Our findings demonstrate that the LSTM model,
particularly with a 24-month observation window, exhibits superior performance
in predicting ESRD progression, outperforming existing models in the
literature. We further apply SHapley Additive exPlanations (SHAP) analysis to
enhance interpretability, providing insights into the impact of individual
features on predictions at the individual patient level. This study underscores
the value of leveraging administrative claims data for CKD management and
predicting ESRD progression.

摘要：本研究探討利用行政索賠資料的潛力，結合進階機器學習和深度學習技術，預測慢性腎臟病 (CKD) 進展至末期腎臟疾病 (ESRD)。我們分析由一家大型健康保險組織提供的十年綜合資料集，使用傳統機器學習方法（例如隨機森林和 XGBoost）以及深度學習方法（例如長短期記憶 (LSTM) 網路）開發多個觀察時段的預測模型。我們的研究結果表明，LSTM 模型，特別是具有 24 個月的觀察時段，在預測 ESRD 進展方面表現優異，優於文獻中的現有模型。我們進一步應用 SHapley 加法解釋 (SHAP) 分析來增強可解釋性，深入了解個別特徵對個別患者層級預測的影響。本研究強調了利用行政索賠資料進行 CKD 管理和預測 ESRD 進展的價值。

##### **Explainable AI: Definition and attributes of a good explanation for health AI**
2409.15338v1 by Evangelia Kyrimi, Scott McLachlan, Jared M Wohlgemut, Zane B Perkins, David A. Lagnado, William Marsh, the ExAIDSS Expert Group

Proposals of artificial intelligence (AI) solutions based on increasingly
complex and accurate predictive models are becoming ubiquitous across many
disciplines. As the complexity of these models grows, transparency and users'
understanding often diminish. This suggests that accurate prediction alone is
insufficient for making an AI-based solution truly useful. In the development
of healthcare systems, this introduces new issues related to accountability and
safety. Understanding how and why an AI system makes a recommendation may
require complex explanations of its inner workings and reasoning processes.
Although research on explainable AI (XAI) has significantly increased in recent
years and there is high demand for XAI in medicine, defining what constitutes a
good explanation remains ad hoc, and providing adequate explanations continues
to be challenging. To fully realize the potential of AI, it is critical to
address two fundamental questions about explanations for safety-critical AI
applications, such as health-AI: (1) What is an explanation in health-AI? and
(2) What are the attributes of a good explanation in health-AI? In this study,
we examined published literature and gathered expert opinions through a
two-round Delphi study. The research outputs include (1) a definition of what
constitutes an explanation in health-AI and (2) a comprehensive list of
attributes that characterize a good explanation in health-AI.

摘要：隨著越來越複雜且準確的預測模型，基於人工智慧 (AI) 解決方案的提案在許多領域中變得無處不在。隨著這些模型複雜性的增加，透明度和使用者的理解力往往會降低。這表示僅有準確的預測並不足以讓 AI 解決方案真正有用。在醫療保健系統的開發中，這引入了與問責制和安全性相關的新問題。瞭解 AI 系統如何以及為何提出建議可能需要對其內部運作和推理過程進行複雜的說明。儘管近年來對可解釋 AI (XAI) 的研究已大幅增加，且醫學領域對 XAI 有很高的需求，但定義什麼構成一個好的解釋仍是臨時性的，而提供適當的解釋仍然具有挑戰性。為了充分發揮 AI 的潛力，對於安全關鍵型 AI 應用（例如健康 AI）的解釋，探討兩個基本問題至關重要：(1) 什麼是健康 AI 中的解釋？以及 (2) 健康 AI 中一個好的解釋有哪些屬性？在本研究中，我們檢視了已發表的文獻，並透過兩輪德爾菲研究收集了專家意見。研究成果包括：(1) 健康 AI 中什麼構成解釋的定義，以及 (2) 健康 AI 中一個好解釋的屬性清單。

##### **Exploring the Effect of Explanation Content and Format on User Comprehension and Trust**
2408.17401v1 by Antonio Rago, Bence Palfi, Purin Sukpanichnant, Hannibal Nabli, Kavyesh Vivek, Olga Kostopoulou, James Kinross, Francesca Toni

In recent years, various methods have been introduced for explaining the
outputs of "black-box" AI models. However, it is not well understood whether
users actually comprehend and trust these explanations. In this paper, we focus
on explanations for a regression tool for assessing cancer risk and examine the
effect of the explanations' content and format on the user-centric metrics of
comprehension and trust. Regarding content, we experiment with two explanation
methods: the popular SHAP, based on game-theoretic notions and thus potentially
complex for everyday users to comprehend, and occlusion-1, based on feature
occlusion which may be more comprehensible. Regarding format, we present SHAP
explanations as charts (SC), as is conventional, and occlusion-1 explanations
as charts (OC) as well as text (OT), to which their simpler nature also lends
itself. The experiments amount to user studies questioning participants, with
two different levels of expertise (the general population and those with some
medical training), on their subjective and objective comprehension of and trust
in explanations for the outputs of the regression tool. In both studies we
found a clear preference in terms of subjective comprehension and trust for
occlusion-1 over SHAP explanations in general, when comparing based on content.
However, direct comparisons of explanations when controlling for format only
revealed evidence for OT over SC explanations in most cases, suggesting that
the dominance of occlusion-1 over SHAP explanations may be driven by a
preference for text over charts as explanations. Finally, we found no evidence
of a difference between the explanation types in terms of objective
comprehension. Thus overall, the choice of the content and format of
explanations needs careful attention, since in some contexts format, rather
than content, may play the critical role in improving user experience.

摘要：<paragraph>近年來，已經引進各種方法來解釋「黑箱」AI 模型的輸出。然而，目前並不清楚使用者是否實際理解和信任這些解釋。在本文中，我們專注於評估癌症風險的回歸工具的解釋，並探討解釋的內容和格式對以使用者為中心的理解和信任指標的影響。關於內容，我們實驗了兩種解釋方法：流行的 SHAP，基於博弈論概念，因此對於日常使用者來說可能很複雜，以及基於特徵遮蔽的 occlusion-1，可能更易於理解。關於格式，我們將 SHAP 解釋呈現為圖表 (SC)，這是慣例，而將 occlusion-1 解釋呈現為圖表 (OC) 以及文字 (OT)，其較為簡單的性質也適用於此。這些實驗等同於使用者研究，詢問參與者，具有兩種不同程度的專業知識（一般民眾和具備一些醫學訓練的人），他們對回歸工具輸出解釋的主觀和客觀理解和信任。在兩項研究中，我們發現，在基於內容進行比較時，一般來說，occlusion-1 優於 SHAP 解釋，在主觀理解和信任方面有明顯的偏好。然而，在僅控制格式的情況下直接比較解釋，在大多數情況下只顯示 OT 優於 SC 解釋的證據，這表明 occlusion-1 優於 SHAP 解釋的主導地位可能是由偏好文字而非圖表作為解釋所驅動的。最後，我們沒有發現解釋類型在客觀理解方面的差異證據。因此，總體而言，對解釋的內容和格式的選擇需要仔細注意，因為在某些情況下，格式而非內容，可能在改善使用者體驗方面發揮關鍵作用。</paragraph>

##### **A Survey for Large Language Models in Biomedicine**
2409.00133v1 by Chong Wang, Mengyao Li, Junjun He, Zhongruo Wang, Erfan Darzi, Zan Chen, Jin Ye, Tianbin Li, Yanzhou Su, Jing Ke, Kaili Qu, Shuxin Li, Yi Yu, Pietro Liò, Tianyun Wang, Yu Guang Wang, Yiqing Shen

Recent breakthroughs in large language models (LLMs) offer unprecedented
natural language understanding and generation capabilities. However, existing
surveys on LLMs in biomedicine often focus on specific applications or model
architectures, lacking a comprehensive analysis that integrates the latest
advancements across various biomedical domains. This review, based on an
analysis of 484 publications sourced from databases including PubMed, Web of
Science, and arXiv, provides an in-depth examination of the current landscape,
applications, challenges, and prospects of LLMs in biomedicine, distinguishing
itself by focusing on the practical implications of these models in real-world
biomedical contexts. Firstly, we explore the capabilities of LLMs in zero-shot
learning across a broad spectrum of biomedical tasks, including diagnostic
assistance, drug discovery, and personalized medicine, among others, with
insights drawn from 137 key studies. Then, we discuss adaptation strategies of
LLMs, including fine-tuning methods for both uni-modal and multi-modal LLMs to
enhance their performance in specialized biomedical contexts where zero-shot
fails to achieve, such as medical question answering and efficient processing
of biomedical literature. Finally, we discuss the challenges that LLMs face in
the biomedicine domain including data privacy concerns, limited model
interpretability, issues with dataset quality, and ethics due to the sensitive
nature of biomedical data, the need for highly reliable model outputs, and the
ethical implications of deploying AI in healthcare. To address these
challenges, we also identify future research directions of LLM in biomedicine
including federated learning methods to preserve data privacy and integrating
explainable AI methodologies to enhance the transparency of LLMs.

摘要：大型語言模型 (LLM) 的最新突破提供了前所未有的自然語言理解和生成能力。然而，現有關於生物醫學中 LLM 的調查通常專注於特定應用或模型架構，缺乏整合各種生物醫學領域最新進展的全面分析。本綜述基於對來自 PubMed、Web of Science 和 arXiv 等數據庫的 484 篇出版物的分析，深入探討了生物醫學中 LLM 的當前現況、應用、挑戰和前景，其特點是關注這些模型在現實世界生物醫學背景中的實際應用。首先，我們探討了 LLM 在廣泛的生物醫學任務中的零次學習能力，包括診斷輔助、藥物發現和個性化醫療等，並從 137 項關鍵研究中汲取見解。然後，我們討論了 LLM 的適應策略，包括單模態和多模態 LLM 的微調方法，以增強它們在零次學習無法實現的專業生物醫學背景中的性能，例如醫療問題解答和生物醫學文獻的有效處理。最後，我們討論了 LLM 在生物醫學領域面臨的挑戰，包括數據隱私問題、模型可解釋性有限、數據集質量問題以及由於生物醫學數據的敏感性、對高度可靠模型輸出的需求以及在醫療保健中部署 AI 的倫理影響而產生的倫理問題。為了應對這些挑戰，我們還確定了生物醫學中 LLM 未來的研究方向，包括用於保護數據隱私的聯合學習方法以及整合可解釋 AI 方法以增強 LLM 的透明度。

##### **Aligning XAI with EU Regulations for Smart Biomedical Devices: A Methodology for Compliance Analysis**
2408.15121v1 by Francesco Sovrano, Michael Lognoul, Giulia Vilone

Significant investment and development have gone into integrating Artificial
Intelligence (AI) in medical and healthcare applications, leading to advanced
control systems in medical technology. However, the opacity of AI systems
raises concerns about essential characteristics needed in such sensitive
applications, like transparency and trustworthiness. Our study addresses these
concerns by investigating a process for selecting the most adequate Explainable
AI (XAI) methods to comply with the explanation requirements of key EU
regulations in the context of smart bioelectronics for medical devices. The
adopted methodology starts with categorising smart devices by their control
mechanisms (open-loop, closed-loop, and semi-closed-loop systems) and delving
into their technology. Then, we analyse these regulations to define their
explainability requirements for the various devices and related goals.
Simultaneously, we classify XAI methods by their explanatory objectives. This
allows for matching legal explainability requirements with XAI explanatory
goals and determining the suitable XAI algorithms for achieving them. Our
findings provide a nuanced understanding of which XAI algorithms align better
with EU regulations for different types of medical devices. We demonstrate this
through practical case studies on different neural implants, from chronic
disease management to advanced prosthetics. This study fills a crucial gap in
aligning XAI applications in bioelectronics with stringent provisions of EU
regulations. It provides a practical framework for developers and researchers,
ensuring their AI innovations advance healthcare technology and adhere to legal
and ethical standards.

摘要：人工智慧（AI）在醫療和保健應用中投入了大量的投資和開發，進而導致醫療技術中的先進控制系統。然而，AI 系統的不透明性引發了對此類敏感應用中所需基本特性的擔憂，例如透明度和可信度。我們的研究透過調查一個程序來解決這些問題，用於選擇最充分的可解釋 AI（XAI）方法，以符合歐盟法規在醫療器材的智慧型生物電子學中的說明要求。採用的方法從透過其控制機制（開迴路、閉迴路和半閉迴路系統）對智慧型裝置進行分類，並深入探討其技術開始。然後，我們分析這些法規以定義其對各種裝置和相關目標的可解釋性要求。同時，我們透過其說明目標對 XAI 方法進行分類。這允許將法律可解釋性要求與 XAI 說明目標相匹配，並確定適當的 XAI 演算法來達成它們。我們的研究結果提供了對哪些 XAI 演算法更符合歐盟法規以適用於不同類型的醫療器材的細緻理解。我們透過不同神經植入物的實際案例研究來證明這一點，從慢性疾病管理到先進的義肢。這項研究填補了將生物電子學中的 XAI 應用與歐盟法規的嚴格規定相符的重要空白。它為開發人員和研究人員提供了一個實用的架構，確保其 AI 創新能促進醫療技術並遵守法律和道德標準。

##### **Towards Case-based Interpretability for Medical Federated Learning**
2408.13626v1 by Laura Latorre, Liliana Petrychenko, Regina Beets-Tan, Taisiya Kopytova, Wilson Silva

We explore deep generative models to generate case-based explanations in a
medical federated learning setting. Explaining AI model decisions through
case-based interpretability is paramount to increasing trust and allowing
widespread adoption of AI in clinical practice. However, medical AI training
paradigms are shifting towards federated learning settings in order to comply
with data protection regulations. In a federated scenario, past data is
inaccessible to the current user. Thus, we use a deep generative model to
generate synthetic examples that protect privacy and explain decisions. Our
proof-of-concept focuses on pleural effusion diagnosis and uses publicly
available Chest X-ray data.

摘要：我們探索深度生成模型，在醫療聯邦學習設置中生成基於案例的說明。透過基於案例的可解釋性來解釋 AI 模型決策，對於增加信任並允許 AI 在臨床實務中廣泛採用至關重要。然而，醫療 AI 訓練範例正轉向聯邦學習設置，以符合資料保護法規。在聯邦情境中，過去的資料對目前的使用者而言是無法取得的。因此，我們使用深度生成模型來產生保護隱私和解釋決策的合成範例。我們的概念驗證著重於胸腔積液診斷，並使用公開可取得的胸部 X 光資料。

##### **AI in radiological imaging of soft-tissue and bone tumours: a systematic review evaluating against CLAIM and FUTURE-AI guidelines**
2408.12491v1 by Douwe J. Spaanderman, Matthew Marzetti, Xinyi Wan, Andrew F. Scarsbrook, Philip Robinson, Edwin H. G. Oei, Jacob J. Visser, Robert Hemke, Kirsten van Langevelde, David F. Hanff, Geert J. L. H. van Leenders, Cornelis Verhoef, Dirk J. Gruühagen, Wiro J. Niessen, Stefan Klein, Martijn P. A. Starmans

Soft-tissue and bone tumours (STBT) are rare, diagnostically challenging
lesions with variable clinical behaviours and treatment approaches. This
systematic review provides an overview of Artificial Intelligence (AI) methods
using radiological imaging for diagnosis and prognosis of these tumours,
highlighting challenges in clinical translation, and evaluating study alignment
with the Checklist for AI in Medical Imaging (CLAIM) and the FUTURE-AI
international consensus guidelines for trustworthy and deployable AI to promote
the clinical translation of AI methods. The review covered literature from
several bibliographic databases, including papers published before 17/07/2024.
Original research in peer-reviewed journals focused on radiology-based AI for
diagnosing or prognosing primary STBT was included. Exclusion criteria were
animal, cadaveric, or laboratory studies, and non-English papers. Abstracts
were screened by two of three independent reviewers for eligibility. Eligible
papers were assessed against guidelines by one of three independent reviewers.
The search identified 15,015 abstracts, from which 325 articles were included
for evaluation. Most studies performed moderately on CLAIM, averaging a score
of 28.9$\pm$7.5 out of 53, but poorly on FUTURE-AI, averaging 5.1$\pm$2.1 out
of 30. Imaging-AI tools for STBT remain at the proof-of-concept stage,
indicating significant room for improvement. Future efforts by AI developers
should focus on design (e.g. define unmet clinical need, intended clinical
setting and how AI would be integrated in clinical workflow), development (e.g.
build on previous work, explainability), evaluation (e.g. evaluating and
addressing biases, evaluating AI against best practices), and data
reproducibility and availability (making documented code and data publicly
available). Following these recommendations could improve clinical translation
of AI methods.

摘要：軟組織和骨骼腫瘤（STBT）是罕見、診斷具有挑戰性的病灶，其臨床行為和治療方法各不相同。這篇系統性回顧提供了使用放射影像進行診斷和預後的人工智慧 (AI) 方法的概觀，重點說明了臨床轉譯的挑戰，並評估研究與醫療影像 AI 核查表 (CLAIM) 和 FUTURE-AI 可信賴且可部署 AI 的國際共識準則的一致性，以促進 AI 方法的臨床轉譯。這篇回顧涵蓋了幾個書目資料庫中的文獻，包括在 2024 年 7 月 17 日之前發表的論文。納入了以放射為基礎的 AI 診斷或預後原發性 STBT 的同行評審期刊中的原始研究。排除標準是動物、屍體或實驗室研究，以及非英文論文。摘要由三位獨立審查員中的兩位篩選資格。合格的論文由三位獨立審查員中的一位根據準則進行評估。搜索識別出 15,015 篇摘要，其中 325 篇文章被納入評估。大多數研究在 CLAIM 中表現中等，平均得分為 53 分中的 28.9±7.5 分，但在 FUTURE-AI 中表現不佳，平均得分為 30 分中的 5.1±2.1 分。STBT 的影像 AI 工具仍處於概念驗證階段，表明有顯著的改進空間。AI 開發人員未來的努力應集中在設計（例如定義未滿足的臨床需求、預期的臨床環境以及 AI 如何整合到臨床工作流程中）、開發（例如建立在先前的工作、可解釋性）、評估（例如評估和解決偏差、評估 AI 與最佳實務）、以及數據可複製性和可用性（公開提供文件化的代碼和數據）。遵循這些建議可以改善 AI 方法的臨床轉譯。

##### **Evaluating Explainable AI Methods in Deep Learning Models for Early Detection of Cerebral Palsy**
2409.00001v1 by Kimji N. Pellano, Inga Strümke, Daniel Groos, Lars Adde, Espen Alexander F. Ihlen

Early detection of Cerebral Palsy (CP) is crucial for effective intervention
and monitoring. This paper tests the reliability and applicability of
Explainable AI (XAI) methods using a deep learning method that predicts CP by
analyzing skeletal data extracted from video recordings of infant movements.
Specifically, we use XAI evaluation metrics -- namely faithfulness and
stability -- to quantitatively assess the reliability of Class Activation
Mapping (CAM) and Gradient-weighted Class Activation Mapping (Grad-CAM) in this
specific medical application. We utilize a unique dataset of infant movements
and apply skeleton data perturbations without distorting the original dynamics
of the infant movements. Our CP prediction model utilizes an ensemble approach,
so we evaluate the XAI metrics performances for both the overall ensemble and
the individual models. Our findings indicate that both XAI methods effectively
identify key body points influencing CP predictions and that the explanations
are robust against minor data perturbations. Grad-CAM significantly outperforms
CAM in the RISv metric, which measures stability in terms of velocity. In
contrast, CAM performs better in the RISb metric, which relates to bone
stability, and the RRS metric, which assesses internal representation
robustness. Individual models within the ensemble show varied results, and
neither CAM nor Grad-CAM consistently outperform the other, with the ensemble
approach providing a representation of outcomes from its constituent models.

摘要：腦性麻痺 (CP) 的早期偵測對於有效的介入和監測至關重要。本文測試了可解釋 AI (XAI) 方法的可靠性和適用性，使用深度學習方法，透過分析從嬰兒動作影片記錄中提取的骨骼資料來預測 CP。具體來說，我們使用 XAI 評估指標（即忠實度和穩定性）來量化評估類別激活映射 (CAM) 和梯度加權類別激活映射 (Grad-CAM) 在這個特定醫療應用中的可靠性。我們利用一個獨特的嬰兒動作資料集，並應用骨骼資料擾動，而不會扭曲嬰兒動作的原始動力。我們的 CP 預測模型利用整體方法，因此我們評估了整體整體和個別模型的 XAI 指標表現。我們的研究結果表明，兩種 XAI 方法都能有效識別影響 CP 預測的關鍵身體部位，並且這些解釋對於微小的資料擾動具有魯棒性。Grad-CAM 在 RISv 指標中顯著優於 CAM，該指標衡量速度方面的穩定性。相比之下，CAM 在 RISb 指標中表現得更好，該指標與骨骼穩定性有關，而 RRS 指標則評估內部表示的魯棒性。整體中的個別模型顯示出不同的結果，CAM 和 Grad-CAM 都不一致地優於另一種，整體方法提供了其組成模型結果的表示。

##### **MicroXercise: A Micro-Level Comparative and Explainable System for Remote Physical Therapy**
2408.11837v1 by Hanchen David Wang, Nibraas Khan, Anna Chen, Nilanjan Sarkar, Pamela Wisniewski, Meiyi Ma

Recent global estimates suggest that as many as 2.41 billion individuals have
health conditions that would benefit from rehabilitation services. Home-based
Physical Therapy (PT) faces significant challenges in providing interactive
feedback and meaningful observation for therapists and patients. To fill this
gap, we present MicroXercise, which integrates micro-motion analysis with
wearable sensors, providing therapists and patients with a comprehensive
feedback interface, including video, text, and scores. Crucially, it employs
multi-dimensional Dynamic Time Warping (DTW) and attribution-based explainable
methods to analyze the existing deep learning neural networks in monitoring
exercises, focusing on a high granularity of exercise. This synergistic
approach is pivotal, providing output matching the input size to precisely
highlight critical subtleties and movements in PT, thus transforming complex AI
analysis into clear, actionable feedback. By highlighting these micro-motions
in different metrics, such as stability and range of motion, MicroXercise
significantly enhances the understanding and relevance of feedback for
end-users. Comparative performance metrics underscore its effectiveness over
traditional methods, such as a 39% and 42% improvement in Feature Mutual
Information (FMI) and Continuity. MicroXercise is a step ahead in home-based
physical therapy, providing a technologically advanced and intuitively helpful
solution to enhance patient care and outcomes.

摘要：最近的全球估計表明，多達 24.1 億人有
健康狀況可從復健服務中受益。居家
物理治療 (PT) 在提供互動式
回饋和有意義的觀察方面面臨重大挑戰，供治療師和患者使用。為了填補這
個缺口，我們提出 MicroXercise，它將微動作分析與
可穿戴式感測器整合在一起，為治療師和患者提供一個全面的
回饋介面，包括影片、文字和分數。至關重要的是，它採用
多維動態時間規整 (DTW) 和基於歸因的可解釋
方法來分析監控運動中現有的深度學習神經網路，專注於運動的高粒度。這種協同
方法至關重要，提供與輸入大小匹配的輸出，以精確地
突出 PT 中關鍵的細微差別和動作，從而將複雜的 AI
分析轉換為清晰、可操作的回饋。透過在不同指標中突顯這些微動作，例如穩定性和動作範圍，MicroXercise
顯著提升最終使用者對回饋的理解和相關性。比較效能指標強調其優於
傳統方法的有效性，例如特徵互惠資訊 (FMI) 和連續性分別提升了 39% 和 42%。MicroXercise 在居家
物理治療方面更進一步，提供技術先進且直覺有用的
解決方案，以提升患者照護和結果。

##### **The Literature Review Network: An Explainable Artificial Intelligence for Systematic Literature Reviews, Meta-analyses, and Method Development**
2408.05239v1 by Joshua Morriss, Tod Brindle, Jessica Bah Rösman, Daniel Reibsamen, Andreas Enz

Systematic literature reviews are the highest quality of evidence in
research. However, the review process is hindered by significant resource and
data constraints. The Literature Review Network (LRN) is the first of its kind
explainable AI platform adhering to PRISMA 2020 standards, designed to automate
the entire literature review process. LRN was evaluated in the domain of
surgical glove practices using 3 search strings developed by experts to query
PubMed. A non-expert trained all LRN models. Performance was benchmarked
against an expert manual review. Explainability and performance metrics
assessed LRN's ability to replicate the experts' review. Concordance was
measured with the Jaccard index and confusion matrices. Researchers were
blinded to the other's results until study completion. Overlapping studies were
integrated into an LRN-generated systematic review. LRN models demonstrated
superior classification accuracy without expert training, achieving 84.78% and
85.71% accuracy. The highest performance model achieved high interrater
reliability (k = 0.4953) and explainability metrics, linking 'reduce',
'accident', and 'sharp' with 'double-gloving'. Another LRN model covered 91.51%
of the relevant literature despite diverging from the non-expert's judgments (k
= 0.2174), with the terms 'latex', 'double' (gloves), and 'indication'. LRN
outperformed the manual review (19,920 minutes over 11 months), reducing the
entire process to 288.6 minutes over 5 days. This study demonstrates that
explainable AI does not require expert training to successfully conduct
PRISMA-compliant systematic literature reviews like an expert. LRN summarized
the results of surgical glove studies and identified themes that were nearly
identical to the clinical researchers' findings. Explainable AI can accurately
expedite our understanding of clinical practices, potentially revolutionizing
healthcare research.

摘要：系統性文獻回顧是研究中證據品質最高的。然而，回顧過程受到顯著資源和資料限制的阻礙。文獻回顧網路 (LRN) 是第一個遵循 PRISMA 2020 標準的可解釋 AI 平台，旨在自動化整個文獻回顧過程。LRN 在外科手套實務領域中進行評估，使用專家開發的 3 個搜尋字串來查詢 PubMed。非專家訓練所有 LRN 模型。效能以專家手動回顧作為基準。可解釋性和效能指標評估 LRN 複製專家回顧的能力。一致性以 Jaccard 指數和混淆矩陣測量。研究人員在研究完成前對彼此的結果保密。重疊的研究整合到 LRN 生成的系統性回顧中。LRN 模型在沒有專家訓練的情況下展現出優異的分類準確率，達到 84.78% 和 85.71% 的準確率。效能最高的模型達到了高評分者間信賴度 (k = 0.4953) 和可解釋性指標，將「減少」、「意外」和「銳利」與「雙重戴手套」連結在一起。另一個 LRN 模型涵蓋了 91.51% 的相關文獻，儘管與非專家的判斷不同 (k = 0.2174)，但包含了「乳膠」、「雙重」（手套）和「適應症」等詞彙。LRN 優於手動回顧（11 個月超過 19,920 分鐘），將整個過程縮短為 5 天超過 288.6 分鐘。這項研究顯示，可解釋的 AI 不需要專家訓練即可成功進行專家等級的 PRISMA 相容系統性文獻回顧。LRN 總結了外科手套研究的結果，並找出與臨床研究人員發現幾乎相同的主题。可解釋的 AI 可以準確地加快我們對臨床實務的理解，有潛力革新醫療保健研究。

##### **Enhancing Medical Learning and Reasoning Systems: A Boxology-Based Comparative Analysis of Design Patterns**
2408.02709v1 by Chi Him Ng

This study analyzes hybrid AI systems' design patterns and their
effectiveness in clinical decision-making using the boxology framework. It
categorizes and copares various architectures combining machine learning and
rule-based reasoning to provide insights into their structural foundations and
healthcare applications. Addressing two main questions, how to categorize these
systems againts established design patterns and how to extract insights through
comparative analysis, the study uses design patterns from software engineering
to understand and optimize healthcare AI systems. Boxology helps identify
commonalities and create reusable solutions, enhancing these systems'
scalability, reliability, and performance. Five primary architectures are
examined: REML, MLRB, RBML, RMLT, and PERML. Each has unique strengths and
weaknesses, highlighting the need for tailored approaches in clinical tasks.
REML excels in high-accuracy prediction for datasets with limited data; MLRB in
handling large datasets and complex data integration; RBML in explainability
and trustworthiness; RMLT in managing high-dimensional data; and PERML, though
limited in analysis, shows promise in urgent care scenarios. The study
introduces four new patterns, creates five abstract categorization patterns,
and refines those five further to specific systems. These contributions enhance
Boxlogy's taxonomical organization and offer novel approaches to integrating
expert knowledge with machine learning. Boxology's structured, modular apporach
offers significant advantages in developing and analyzing hybrid AI systems,
revealing commonalities, and promoting reusable solutions. In conclusion, this
study underscores hybrid AI systems' crucial role in advancing healthcare and
Boxology's potential to drive further innovation in AI integration, ultimately
improving clinical decision support and patient outcomes.

摘要：本研究使用盒子學框架分析混合人工智慧系統的設計模式及其在臨床決策中的有效性。它分類並比較結合機器學習和基於規則的推理的各種架構，以深入了解其結構基礎和醫療保健應用。針對兩個主要問題，如何根據既定的設計模式對這些系統進行分類，以及如何通過比較分析提取見解，本研究使用軟體工程中的設計模式來了解和優化醫療保健人工智慧系統。盒子學有助於識別共性並建立可重複使用的解決方案，從而增強這些系統的可擴充性、可靠性和效能。檢查了五種主要的架構：REML、MLRB、RBML、RMLT 和 PERML。每種架構都有獨特的優缺點，強調了在臨床任務中需要量身打造的方法。REML 在資料有限的資料集中表現出高精度的預測；MLRB 在處理大型資料集和複雜資料整合方面表現出色；RBML 在可解釋性和可信度方面表現出色；RMLT 在管理高維資料方面表現出色；而 PERML 儘管在分析方面有限，但在緊急照護場景中表現出潛力。本研究引入了四種新模式，建立了五種抽象分類模式，並進一步將這五種模式細化為具體的系統。這些貢獻增強了盒子學的分類組織，並提供了將專家知識與機器學習整合的新方法。盒子學的結構化、模組化方法在開發和分析混合人工智慧系統、揭示共性以及推廣可重複使用的解決方案方面具有顯著優勢。總之，本研究強調了混合人工智慧系統在推進醫療保健中的關鍵作用，以及盒子學在推動人工智慧整合進一步創新方面的潛力，最終改善臨床決策支援和患者的治療成果。

##### **Bayesian Kolmogorov Arnold Networks (Bayesian_KANs): A Probabilistic Approach to Enhance Accuracy and Interpretability**
2408.02706v1 by Masoud Muhammed Hassan

Because of its strong predictive skills, deep learning has emerged as an
essential tool in many industries, including healthcare. Traditional deep
learning models, on the other hand, frequently lack interpretability and omit
to take prediction uncertainty into account two crucial components of clinical
decision making. In order to produce explainable and uncertainty aware
predictions, this study presents a novel framework called Bayesian Kolmogorov
Arnold Networks (BKANs), which combines the expressive capacity of Kolmogorov
Arnold Networks with Bayesian inference. We employ BKANs on two medical
datasets, which are widely used benchmarks for assessing machine learning
models in medical diagnostics: the Pima Indians Diabetes dataset and the
Cleveland Heart Disease dataset. Our method provides useful insights into
prediction confidence and decision boundaries and outperforms traditional deep
learning models in terms of prediction accuracy. Moreover, BKANs' capacity to
represent aleatoric and epistemic uncertainty guarantees doctors receive more
solid and trustworthy decision support. Our Bayesian strategy improves the
interpretability of the model and considerably minimises overfitting, which is
important for tiny and imbalanced medical datasets, according to experimental
results. We present possible expansions to further use BKANs in more
complicated multimodal datasets and address the significance of these
discoveries for future research in building reliable AI systems for healthcare.
This work paves the way for a new paradigm in deep learning model deployment in
vital sectors where transparency and reliability are crucial.

摘要：由於其強大的預測能力，深度學習已成為許多產業中不可或缺的工具，包括醫療保健。然而，傳統的深度學習模型通常缺乏可解釋性，並且忽略了將預測不確定性納入考量，而這兩個因素是臨床決策制定的關鍵組成部分。為了產生可解釋且具有不確定性意識的預測，本研究提出了一個名為貝氏柯爾莫哥洛夫阿諾德網路 (BKAN) 的新架構，它結合了柯爾莫哥洛夫阿諾德網路的表達能力與貝氏推論。我們在兩個醫學資料集上使用 BKAN，這些資料集是評估機器學習模型在醫學診斷中的廣泛使用基準：皮馬印第安人糖尿病資料集和克里夫蘭心臟病資料集。我們的模型提供了對預測信心和決策邊界的有益見解，並且在預測準確度方面優於傳統的深度學習模型。此外，BKAN 表現隨機和認識不確定性的能力，可確保醫生獲得更可靠且值得信賴的決策支援。根據實驗結果，我們的貝氏策略提高了模型的可解釋性，並大幅減少了過度擬合，這對於小型且不平衡的醫學資料集非常重要。我們提出了可能的擴充功能，以進一步將 BKAN 用於更複雜的多模式資料集，並探討這些發現對於未來建立可靠的醫療保健 AI 系統研究的重要性。這項工作為深度學習模型部署在透明度和可靠性至關重要的重要領域中開啟了一個新的典範。

##### **MLtoGAI: Semantic Web based with Machine Learning for Enhanced Disease Prediction and Personalized Recommendations using Generative AI**
2407.20284v1 by Shyam Dongre, Ritesh Chandra, Sonali Agarwal

In modern healthcare, addressing the complexities of accurate disease
prediction and personalized recommendations is both crucial and challenging.
This research introduces MLtoGAI, which integrates Semantic Web technology with
Machine Learning (ML) to enhance disease prediction and offer user-friendly
explanations through ChatGPT. The system comprises three key components: a
reusable disease ontology that incorporates detailed knowledge about various
diseases, a diagnostic classification model that uses patient symptoms to
detect specific diseases accurately, and the integration of Semantic Web Rule
Language (SWRL) with ontology and ChatGPT to generate clear, personalized
health advice. This approach significantly improves prediction accuracy and
ensures results that are easy to understand, addressing the complexity of
diseases and diverse symptoms. The MLtoGAI system demonstrates substantial
advancements in accuracy and user satisfaction, contributing to developing more
intelligent and accessible healthcare solutions. This innovative approach
combines the strengths of ML algorithms with the ability to provide
transparent, human-understandable explanations through ChatGPT, achieving
significant improvements in prediction accuracy and user comprehension. By
leveraging semantic technology and explainable AI, the system enhances the
accuracy of disease prediction and ensures that the recommendations are
relevant and easily understood by individual patients. Our research highlights
the potential of integrating advanced technologies to overcome existing
challenges in medical diagnostics, paving the way for future developments in
intelligent healthcare systems. Additionally, the system is validated using 200
synthetic patient data records, ensuring robust performance and reliability.

摘要：在現代醫療保健中，解決準確疾病預測和個性化建議的複雜性既至關重要又具有挑戰性。本研究引入了 MLtoGAI，它將語義網路技術與機器學習 (ML) 相結合，以增強疾病預測並透過 ChatGPT 提供使用者友善的說明。該系統包含三個關鍵組成部分：一個可重複使用的疾病本体，其中包含有關各種疾病的詳細知識；一個診斷分類模型，它使用患者症狀來準確檢測特定疾病；以及語義網路規則語言 (SWRL) 與本体和 ChatGPT 的整合，以產生清晰、個性化的健康建議。這種方法顯著提高了預測準確性，並確保了易於理解的結果，解決了疾病和不同症狀的複雜性。MLtoGAI 系統展示了準確性和使用者滿意度的實質性進步，有助於開發更智慧且更易於取得的醫療保健解決方案。這種創新的方法結合了 ML 演算法的優點，以及透過 ChatGPT 提供透明且人類可以理解的說明的能力，在預測準確性和使用者理解方面取得了顯著的進步。透過利用語義技術和可解釋的 AI，該系統提高了疾病預測的準確性，並確保了建議與個別患者相關且易於理解。我們的研究強調了整合先進技術以克服醫療診斷中現有挑戰的潛力，為智慧醫療保健系統的未來發展鋪路。此外，該系統使用 200 個合成患者資料記錄進行驗證，確保了穩健的效能和可靠性。

##### **Introducing δ-XAI: a novel sensitivity-based method for local AI explanations**
2407.18343v2 by Alessandro De Carlo, Enea Parimbelli, Nicola Melillo, Giovanna Nicora

Explainable Artificial Intelligence (XAI) is central to the debate on
integrating Artificial Intelligence (AI) and Machine Learning (ML) algorithms
into clinical practice. High-performing AI/ML models, such as ensemble learners
and deep neural networks, often lack interpretability, hampering clinicians'
trust in their predictions. To address this, XAI techniques are being developed
to describe AI/ML predictions in human-understandable terms. One promising
direction is the adaptation of sensitivity analysis (SA) and global sensitivity
analysis (GSA), which inherently rank model inputs by their impact on
predictions. Here, we introduce a novel delta-XAI method that provides local
explanations of ML model predictions by extending the delta index, a GSA
metric. The delta-XAI index assesses the impact of each feature's value on the
predicted output for individual instances in both regression and classification
problems. We formalize the delta-XAI index and provide code for its
implementation. The delta-XAI method was evaluated on simulated scenarios using
linear regression models, with Shapley values serving as a benchmark. Results
showed that the delta-XAI index is generally consistent with Shapley values,
with notable discrepancies in models with highly impactful or extreme feature
values. The delta-XAI index demonstrated higher sensitivity in detecting
dominant features and handling extreme feature values. Qualitatively, the
delta-XAI provides intuitive explanations by leveraging probability density
functions, making feature rankings clearer and more explainable for
practitioners. Overall, the delta-XAI method appears promising for robustly
obtaining local explanations of ML model predictions. Further investigations in
real-world clinical settings will be conducted to evaluate its impact on
AI-assisted clinical workflows.

摘要：可解釋人工智慧 (XAI) 是將人工智慧 (AI) 和機器學習 (ML) 演算法整合到臨床實務中的辯論核心。高執行效能的 AI/ML 模型，例如整體學習器和深度神經網路，通常缺乏可解釋性，阻礙臨床醫生對其預測的信任。為了解決這個問題，正在開發 XAI 技術，以人類可以理解的術語描述 AI/ML 預測。一個有希望的方向是採用敏感度分析 (SA) 和全球敏感度分析 (GSA)，它們本質上會依據模型輸入對預測的影響來對其進行排名。在此，我們介紹一種新的 delta-XAI 方法，透過擴充 GSA 指標 delta 指數來提供 ML 模型預測的局部解釋。delta-XAI 指數評估每個特徵值對回歸和分類問題中個別例項的預測輸出之影響。我們將 delta-XAI 指數形式化，並提供其實作的程式碼。使用線性回歸模型對模擬情境評估 delta-XAI 方法，並以 Shapley 值作為基準。結果顯示 delta-XAI 指數通常與 Shapley 值一致，但在具有高度影響力或極端特徵值的模型中存在顯著差異。delta-XAI 指數在偵測主要特徵和處理極端特徵值方面表現出更高的敏感度。定性地來說，delta-XAI 透過利用機率密度函數提供直觀的解釋，使特徵排名更清晰且對從業人員來說更具可解釋性。總體而言，delta-XAI 方法對於穩健地取得 ML 模型預測的局部解釋似乎很有希望。將在真實世界的臨床環境中進行進一步調查，以評估其對 AI 輔助臨床工作流程的影響。

##### **Enhanced Deep Learning Methodologies and MRI Selection Techniques for Dementia Diagnosis in the Elderly Population**
2407.17324v2 by Nikolaos Ntampakis, Konstantinos Diamantaras, Ioanna Chouvarda, Vasileios Argyriou, Panagiotis Sarigianndis

Dementia, a debilitating neurological condition affecting millions worldwide,
presents significant diagnostic challenges. In this work, we introduce a novel
methodology for the classification of demented and non-demented elderly
patients using 3D brain Magnetic Resonance Imaging (MRI) scans. Our approach
features a unique technique for selectively processing MRI slices, focusing on
the most relevant brain regions and excluding less informative sections. This
methodology is complemented by a confidence-based classification committee
composed of three custom deep learning models: Dem3D ResNet, Dem3D CNN, and
Dem3D EfficientNet. These models work synergistically to enhance
decision-making accuracy, leveraging their collective strengths. Tested on the
Open Access Series of Imaging Studies(OASIS) dataset, our method achieved an
impressive accuracy of 94.12%, surpassing existing methodologies. Furthermore,
validation on the Alzheimer's Disease Neuroimaging Initiative (ADNI) dataset
confirmed the robustness and generalizability of our approach. The use of
explainable AI (XAI) techniques and comprehensive ablation studies further
substantiate the effectiveness of our techniques, providing insights into the
decision-making process and the importance of our methodology. This research
offers a significant advancement in dementia diagnosis, providing a highly
accurate and efficient tool for clinical applications.

摘要：失智症是一種影響全球數百萬人的衰弱性神經疾病，在診斷上具有重大挑戰。在這項工作中，我們提出了一種新的方法，用於對失智和非失智老年患者進行分類，使用 3D 大腦磁振造影 (MRI) 掃描。我們的做法採用了一種獨特技術，用於選擇性處理 MRI 切片，重點關注最相關的大腦區域，並排除信息量較少的部分。這種方法由一個基於信心的分類委員會補充，該委員會由三個自定義深度學習模型組成：Dem3D ResNet、Dem3D CNN 和 Dem3D EfficientNet。這些模型協同工作以增強決策的準確性，利用它們的集體優勢。在影像研究開放存取系列 (OASIS) 資料集上進行測試，我們的模型達到了 94.12% 的驚人準確度，超過了現有方法。此外，在阿茲海默症神經影像倡議 (ADNI) 資料集上的驗證證實了我們方法的穩健性和普遍性。可解釋 AI (XAI) 技術和全面的消融研究進一步證實了我們技術的有效性，提供了對決策過程和我們方法重要性的見解。這項研究為失智症診斷提供了重大進展，為臨床應用提供了一個高度準確且高效的工具。

##### **Using Large Language Models to Compare Explainable Models for Smart Home Human Activity Recognition**
2408.06352v1 by Michele Fiori, Gabriele Civitarese, Claudio Bettini

Recognizing daily activities with unobtrusive sensors in smart environments
enables various healthcare applications. Monitoring how subjects perform
activities at home and their changes over time can reveal early symptoms of
health issues, such as cognitive decline. Most approaches in this field use
deep learning models, which are often seen as black boxes mapping sensor data
to activities. However, non-expert users like clinicians need to trust and
understand these models' outputs. Thus, eXplainable AI (XAI) methods for Human
Activity Recognition have emerged to provide intuitive natural language
explanations from these models. Different XAI methods generate different
explanations, and their effectiveness is typically evaluated through user
surveys, that are often challenging in terms of costs and fairness. This paper
proposes an automatic evaluation method using Large Language Models (LLMs) to
identify, in a pool of candidates, the best XAI approach for non-expert users.
Our preliminary results suggest that LLM evaluation aligns with user surveys.

摘要：藉由智慧環境中不引人注目的感測器辨識日常活動，能啟用各種醫療保健應用。監控受試者在家中如何執行活動，以及其隨著時間的變化，可以揭示健康問題的早期症狀，例如認知能力下降。此領域中的大多數方法都使用深度學習模型，這些模型通常被視為將感測器資料對應至活動的黑盒子。然而，非專家使用者（例如臨床醫師）需要信任並了解這些模型的輸出。因此，人類活動辨識的可解釋 AI (XAI) 方法應運而生，以提供來自這些模型的直覺自然語言說明。不同的 XAI 方法會產生不同的說明，而其有效性通常透過使用者調查來評估，這在成本和公平性方面通常具有挑戰性。本文提出使用大型語言模型 (LLM) 的自動評估方法，以在候選者中找出最適合非專家使用者的 XAI 方法。我們的初步結果表明，LLM 評估與使用者調查一致。

##### **Explainable AI-based Intrusion Detection System for Industry 5.0: An Overview of the Literature, associated Challenges, the existing Solutions, and Potential Research Directions**
2408.03335v1 by Naseem Khan, Kashif Ahmad, Aref Al Tamimi, Mohammed M. Alani, Amine Bermak, Issa Khalil

Industry 5.0, which focuses on human and Artificial Intelligence (AI)
collaboration for performing different tasks in manufacturing, involves a
higher number of robots, Internet of Things (IoTs) devices and
interconnections, Augmented/Virtual Reality (AR), and other smart devices. The
huge involvement of these devices and interconnection in various critical
areas, such as economy, health, education and defense systems, poses several
types of potential security flaws. AI itself has been proven a very effective
and powerful tool in different areas of cybersecurity, such as intrusion
detection, malware detection, and phishing detection, among others. Just as in
many application areas, cybersecurity professionals were reluctant to accept
black-box ML solutions for cybersecurity applications. This reluctance pushed
forward the adoption of eXplainable Artificial Intelligence (XAI) as a tool
that helps explain how decisions are made in ML-based systems. In this survey,
we present a comprehensive study of different XAI-based intrusion detection
systems for industry 5.0, and we also examine the impact of explainability and
interpretability on Cybersecurity practices through the lens of Adversarial
XIDS (Adv-XIDS) approaches. Furthermore, we analyze the possible opportunities
and challenges in XAI cybersecurity systems for industry 5.0 that elicit future
research toward XAI-based solutions to be adopted by high-stakes industry 5.0
applications. We believe this rigorous analysis will establish a foundational
framework for subsequent research endeavors within the specified domain.

摘要：工業 5.0 著重於人類與人工智慧 (AI) 合作執行製造中的不同任務，涉及更多機器人、物聯網 (IoT) 裝置和互連、擴增/虛擬實境 (AR) 和其他智慧裝置。這些裝置和互連在經濟、醫療保健、教育和國防系統等各種關鍵領域的廣泛參與，引發了多種類型的潛在安全漏洞。AI 本身已被證明是網路安全不同領域中非常有效且強大的工具，例如入侵偵測、惡意軟體偵測和網路釣魚偵測等。就像在許多應用領域一樣，網路安全專業人員不願意接受黑盒 ML 解決方案來應用於網路安全。這種不願意促使可解釋人工智慧 (XAI) 作為一種工具被採用，有助於說明在基於 ML 的系統中如何做出決策。在這項調查中，我們對工業 5.0 的不同基於 XAI 的入侵偵測系統進行了全面的研究，並且我們也透過對抗式 XIDS (Adv-XIDS) 方法的觀點來探討可解釋性和可詮釋性對網路安全實務的影響。此外，我們分析了工業 5.0 的 XAI 網路安全系統中可能存在的機會和挑戰，引發了未來針對 XAI 基礎解決方案的研究，以供高風險的工業 5.0 應用採用。我們相信這項嚴謹的分析將為指定領域內的後續研究工作建立基礎架構。

##### **A Comparative Study on Automatic Coding of Medical Letters with Explainability**
2407.13638v1 by Jamie Glen, Lifeng Han, Paul Rayson, Goran Nenadic

This study aims to explore the implementation of Natural Language Processing
(NLP) and machine learning (ML) techniques to automate the coding of medical
letters with visualised explainability and light-weighted local computer
settings. Currently in clinical settings, coding is a manual process that
involves assigning codes to each condition, procedure, and medication in a
patient's paperwork (e.g., 56265001 heart disease using SNOMED CT code). There
are preliminary research on automatic coding in this field using
state-of-the-art ML models; however, due to the complexity and size of the
models, the real-world deployment is not achieved. To further facilitate the
possibility of automatic coding practice, we explore some solutions in a local
computer setting; in addition, we explore the function of explainability for
transparency of AI models. We used the publicly available MIMIC-III database
and the HAN/HLAN network models for ICD code prediction purposes. We also
experimented with the mapping between ICD and SNOMED CT knowledge bases. In our
experiments, the models provided useful information for 97.98\% of codes. The
result of this investigation can shed some light on implementing automatic
clinical coding in practice, such as in hospital settings, on the local
computers used by clinicians , project page
\url{https://github.com/Glenj01/Medical-Coding}.

摘要：本研究旨在探討將自然語言處理 (NLP) 和機器學習 (ML) 技術實作於醫療信函編碼自動化，並具備視覺化說明能力和輕量化的本地電腦設定。目前在臨床環境中，編碼是一種手動流程，涉及為病患文件中的每項病症、程序和藥物指派代碼 (例如，使用 SNOMED CT 代碼 56265001 表示心臟病)。此領域有使用最新 ML 模型進行自動編碼的初步研究；然而，由於模型的複雜性和大小，並未實現實際部署。為了進一步促進自動編碼實務的可能性，我們在本地電腦設定中探討了一些解決方案；此外，我們探討了說明功能在 AI 模型透明度中的功能。我們使用公開的 MIMIC-III 資料庫和 HAN/HLAN 網路模型進行 ICD 代碼預測。我們還試驗了 ICD 和 SNOMED CT 知識庫之間的對應。在我們的實驗中，這些模型提供了 97.98% 代碼的有用資訊。這項調查結果可以為實務中的自動臨床編碼實作提供一些見解，例如在醫院環境中，由臨床醫生使用的本地電腦，專案頁面 \url{https://github.com/Glenj01/Medical-Coding}。

##### **Explainable AI for Enhancing Efficiency of DL-based Channel Estimation**
2407.07009v1 by Abdul Karim Gizzini, Yahia Medjahdi, Ali J. Ghandour, Laurent Clavier

The support of artificial intelligence (AI) based decision-making is a key
element in future 6G networks, where the concept of native AI will be
introduced. Moreover, AI is widely employed in different critical applications
such as autonomous driving and medical diagnosis. In such applications, using
AI as black-box models is risky and challenging. Hence, it is crucial to
understand and trust the decisions taken by these models. Tackling this issue
can be achieved by developing explainable AI (XAI) schemes that aim to explain
the logic behind the black-box model behavior, and thus, ensure its efficient
and safe deployment. Recently, we proposed a novel perturbation-based XAI-CHEST
framework that is oriented toward channel estimation in wireless
communications. The core idea of the XAI-CHEST framework is to identify the
relevant model inputs by inducing high noise on the irrelevant ones. This
manuscript provides the detailed theoretical foundations of the XAI-CHEST
framework. In particular, we derive the analytical expressions of the XAI-CHEST
loss functions and the noise threshold fine-tuning optimization problem. Hence
the designed XAI-CHEST delivers a smart input feature selection methodology
that can further improve the overall performance while optimizing the
architecture of the employed model. Simulation results show that the XAI-CHEST
framework provides valid interpretations, where it offers an improved bit error
rate performance while reducing the required computational complexity in
comparison to the classical DL-based channel estimation.

摘要：人工智能 (AI) 支持的決策制定是未來 6G 網路中的關鍵元素，其中將引入原生 AI 的概念。此外，AI 廣泛用於不同的關鍵應用中，例如自動駕駛和醫療診斷。在這些應用中，使用 AI 作為黑盒模型是有風險且具有挑戰性的。因此，理解和信任這些模型做出的決策至關重要。解決此問題的方法是開發可解釋 AI (XAI) 架構，旨在解釋黑盒模型行為背後的邏輯，從而確保其有效且安全的部署。最近，我們提出了一個新的基於擾動的 XAI-CHEST 框架，該框架面向無線通信中的信道估計。XAI-CHEST 框架的核心思想是通過在無關輸入上引入高噪聲來識別相關模型輸入。這份手稿提供了 XAI-CHEST 框架的詳細理論基礎。特別是，我們推導了 XAI-CHEST 損失函數和噪聲閾值微調優化問題的解析表達式。因此，設計的 XAI-CHEST 提供了一種智能輸入特徵選擇方法，可以在優化所用模型的架構的同時進一步提高整體性能。模擬結果表明，XAI-CHEST 框架提供了有效的解釋，在降低所需的計算複雜度的同時，提供了改進的比特錯誤率性能，而這與基於傳統 DL 的信道估計相比。

##### **Explainable AI: Comparative Analysis of Normal and Dilated ResNet Models for Fundus Disease Classification**
2407.05440v2 by P. N. Karthikayan, Yoga Sri Varshan V, Hitesh Gupta Kattamuri, Umarani Jayaraman

This paper presents dilated Residual Network (ResNet) models for disease
classification from retinal fundus images. Dilated convolution filters are used
to replace normal convolution filters in the higher layers of the ResNet model
(dilated ResNet) in order to improve the receptive field compared to the normal
ResNet model for disease classification. This study introduces
computer-assisted diagnostic tools that employ deep learning, enhanced with
explainable AI techniques. These techniques aim to make the tool's
decision-making process transparent, thereby enabling medical professionals to
understand and trust the AI's diagnostic decision. They are particularly
relevant in today's healthcare landscape, where there is a growing demand for
transparency in AI applications to ensure their reliability and ethical use.
The dilated ResNet is used as a replacement for the normal ResNet to enhance
the classification accuracy of retinal eye diseases and reduce the required
computing time. The dataset used in this work is the Ocular Disease Intelligent
Recognition (ODIR) dataset which is a structured ophthalmic database with eight
classes covering most of the common retinal eye diseases. The evaluation
metrics used in this work include precision, recall, accuracy, and F1 score. In
this work, a comparative study has been made between normal ResNet models and
dilated ResNet models on five variants namely ResNet-18, ResNet-34, ResNet-50,
ResNet-101, and ResNet-152. The dilated ResNet model shows promising results as
compared to normal ResNet with an average F1 score of 0.71, 0.70, 0.69, 0.67,
and 0.70 respectively for the above respective variants in ODIR multiclass
disease classification.

摘要：这篇论文提出了用于从视网膜眼底图像进行疾病分类的扩张残差网络 (ResNet) 模型。扩张卷积滤波器用于替换 ResNet 模型较高层中的正常卷积滤波器（扩张 ResNet），以改善感知场，从而针对疾病分类对正常 ResNet 模型进行改进。本研究引入了采用深度学习的计算机辅助诊断工具，并通过可解释的 AI 技术进行了增强。这些技术旨在使该工具的决策过程透明化，从而使医学专业人士能够理解和信任 AI 的诊断决策。它们与当今的医疗保健领域尤为相关，在该领域，对 AI 应用的透明度需求不断增长，以确保其可靠性和合乎道德的使用。扩张 ResNet 用作正常 ResNet 的替代品，以提高视网膜眼部疾病的分类准确性并减少所需的计算时间。本工作中使用的数据集是眼科疾病智能识别 (ODIR) 数据集，这是一个结构化的眼科数据库，包含八类涵盖大多数常见视网膜眼部疾病。本工作中使用的评估指标包括精确度、召回率、准确度和 F1 得分。在这项工作中，对 ResNet-18、ResNet-34、ResNet-50、ResNet-101 和 ResNet-152 五个变体的正常 ResNet 模型和扩张 ResNet 模型进行了比较研究。与正常 ResNet 相比，扩张 ResNet 模型显示出有希望的结果，在 ODIR 多类疾病分类中，上述各个变体的平均 F1 得分为 0.71、0.70、0.69、0.67 和 0.70。

##### **A Survey on Trustworthiness in Foundation Models for Medical Image Analysis**
2407.15851v1 by Congzhen Shi, Ryan Rezai, Jiaxi Yang, Qi Dou, Xiaoxiao Li

The rapid advancement of foundation models in medical imaging represents a
significant leap toward enhancing diagnostic accuracy and personalized
treatment. However, the deployment of foundation models in healthcare
necessitates a rigorous examination of their trustworthiness, encompassing
privacy, robustness, reliability, explainability, and fairness. The current
body of survey literature on foundation models in medical imaging reveals
considerable gaps, particularly in the area of trustworthiness. Additionally,
extant surveys on the trustworthiness of foundation models fail to address
their specific variations and applications within the medical imaging domain.
This survey paper reviews the current research on foundation models in the
major medical imaging applications, with a focus on segmentation, medical
report generation, medical question and answering (Q&A), and disease diagnosis,
which includes trustworthiness discussion in their manuscripts. We explore the
complex challenges of making foundation models for medical image analysis
trustworthy, associated with each application, and summarize the current
concerns and strategies to enhance trustworthiness. Furthermore, we explore the
future promises of these models in revolutionizing patient care. Our analysis
underscores the imperative for advancing towards trustworthy AI in medical
image analysis, advocating for a balanced approach that fosters innovation
while ensuring ethical and equitable healthcare delivery.

摘要：基礎模型在醫學影像上的快速進展代表著在增強診斷準確度和個人化治療方面邁出了一大步。然而，基礎模型在醫療保健中的部署需要嚴格檢查其可信度，包括隱私、穩健性、可靠性、可解釋性和公平性。當前關於醫學影像中基礎模型的調查文獻顯示出相當大的差距，特別是在可信度方面。此外，現有的關於基礎模型可信度的調查未能解決其在醫學影像領域內的具體變化和應用。這篇調查論文回顧了當前關於基礎模型在主要醫學影像應用中的研究，重點關注分割、醫療報告生成、醫療問題和解答 (Q&A) 以及疾病診斷，其中包括手稿中的可信度討論。我們探討了讓用於醫學影像分析的基礎模型值得信賴的複雜挑戰，與每個應用相關，並總結了當前提高可信度的問題和策略。此外，我們探討了這些模型在革新患者照護方面的未來前景。我們的分析強調了在醫學影像分析中朝著可信賴的人工智慧邁進的必要性，提倡一種平衡的方法，既能促進創新，又能確保道德和公平的醫療保健服務。

##### **The Impact of an XAI-Augmented Approach on Binary Classification with Scarce Data**
2407.06206v1 by Ximing Wen, Rosina O. Weber, Anik Sen, Darryl Hannan, Steven C. Nesbit, Vincent Chan, Alberto Goffi, Michael Morris, John C. Hunninghake, Nicholas E. Villalobos, Edward Kim, Christopher J. MacLellan

Point-of-Care Ultrasound (POCUS) is the practice of clinicians conducting and
interpreting ultrasound scans right at the patient's bedside. However, the
expertise needed to interpret these images is considerable and may not always
be present in emergency situations. This reality makes algorithms such as
machine learning classifiers extremely valuable to augment human decisions.
POCUS devices are becoming available at a reasonable cost in the size of a
mobile phone. The challenge of turning POCUS devices into life-saving tools is
that interpretation of ultrasound images requires specialist training and
experience. Unfortunately, the difficulty to obtain positive training images
represents an important obstacle to building efficient and accurate
classifiers. Hence, the problem we try to investigate is how to explore
strategies to increase accuracy of classifiers trained with scarce data. We
hypothesize that training with a few data instances may not suffice for
classifiers to generalize causing them to overfit. Our approach uses an
Explainable AI-Augmented approach to help the algorithm learn more from less
and potentially help the classifier better generalize.

摘要：床邊超音波 (POCUS) 是臨床醫師在患者床邊進行和解讀超音波掃描的實務。然而，解讀這些影像所需的專業知識相當可觀，而且在緊急情況下可能並非隨時具備。這種現實情況使得機器學習分類器等演算法對於加強人類決策變得極為有價值。POCUS 裝置正以合理成本推出，尺寸為手機大小。將 POCUS 裝置轉變為救生工具的挑戰在於，解讀超音波影像需要專門訓練和經驗。不幸的是，取得正向訓練影像的困難度代表著建置有效率且準確的分類器的一大障礙。因此，我們嘗試探討的問題是如何探索策略，以提高使用稀疏資料訓練的分類器的準確度。我們假設使用少數資料實例進行訓練可能不足以讓分類器概括，導致它們過度擬合。我們的做法使用可解釋 AI 增強方法，以協助演算法從較少的資料中學習更多，並潛在協助分類器更好地概括。

##### **Can GPT-4 Help Detect Quit Vaping Intentions? An Exploration of Automatic Data Annotation Approach**
2407.00167v1 by Sai Krishna Revanth Vuruma, Dezhi Wu, Saborny Sen Gupta, Lucas Aust, Valerie Lookingbill, Wyatt Bellamy, Yang Ren, Erin Kasson, Li-Shiun Chen, Patricia Cavazos-Rehg, Dian Hu, Ming Huang

In recent years, the United States has witnessed a significant surge in the
popularity of vaping or e-cigarette use, leading to a notable rise in cases of
e-cigarette and vaping use-associated lung injury (EVALI) that caused
hospitalizations and fatalities during the EVALI outbreak in 2019, highlighting
the urgency to comprehend vaping behaviors and develop effective strategies for
cessation. Due to the ubiquity of social media platforms, over 4.7 billion
users worldwide use them for connectivity, communications, news, and
entertainment with a significant portion of the discourse related to health,
thereby establishing social media data as an invaluable organic data resource
for public health research. In this study, we extracted a sample dataset from
one vaping sub-community on Reddit to analyze users' quit-vaping intentions.
Leveraging OpenAI's latest large language model GPT-4 for sentence-level quit
vaping intention detection, this study compares the outcomes of this model
against layman and clinical expert annotations. Using different prompting
strategies such as zero-shot, one-shot, few-shot and chain-of-thought
prompting, we developed 8 prompts with varying levels of detail to explain the
task to GPT-4 and also evaluated the performance of the strategies against each
other. These preliminary findings emphasize the potential of GPT-4 in social
media data analysis, especially in identifying users' subtle intentions that
may elude human detection.

摘要：近年來，美國見證了電子煙或電子香菸使用率大幅激增，導致電子煙和電子煙使用相關肺損傷 (EVALI) 病例顯著增加，在 2019 年 EVALI 爆發期間造成住院和死亡，凸顯了理解電子煙行為和制定有效戒菸策略的迫切性。由於社群媒體平台的普及，全球超過 47 億使用者使用它們進行連結、溝通、新聞和娛樂，其中很大一部分與健康相關，因此將社群媒體資料建立為公共衛生研究中無價的有機資料資源。在本研究中，我們從 Reddit 上一個電子煙子社群中提取一個範例資料集，以分析使用者的戒電子煙意圖。利用 OpenAI 最新的大型語言模型 GPT-4 進行句子層級的戒電子煙意圖偵測，本研究比較了此模型的結果與外行人和臨床專家註解。使用不同的提示策略，例如零次學習、一次學習、少次學習和思考鏈提示，我們開發了 8 個提示，詳細程度不同，向 GPT-4 解釋任務，並評估這些策略彼此之間的效能。這些初步發現強調了 GPT-4 在社群媒體資料分析中的潛力，特別是在識別人類偵測可能無法察覺的使用者微妙意圖方面。

##### **Towards Compositional Interpretability for XAI**
2406.17583v1 by Sean Tull, Robin Lorenz, Stephen Clark, Ilyas Khan, Bob Coecke

Artificial intelligence (AI) is currently based largely on black-box machine
learning models which lack interpretability. The field of eXplainable AI (XAI)
strives to address this major concern, being critical in high-stakes areas such
as the finance, legal and health sectors.
  We present an approach to defining AI models and their interpretability based
on category theory. For this we employ the notion of a compositional model,
which sees a model in terms of formal string diagrams which capture its
abstract structure together with its concrete implementation. This
comprehensive view incorporates deterministic, probabilistic and quantum
models. We compare a wide range of AI models as compositional models, including
linear and rule-based models, (recurrent) neural networks, transformers, VAEs,
and causal and DisCoCirc models.
  Next we give a definition of interpretation of a model in terms of its
compositional structure, demonstrating how to analyse the interpretability of a
model, and using this to clarify common themes in XAI. We find that what makes
the standard 'intrinsically interpretable' models so transparent is brought out
most clearly diagrammatically. This leads us to the more general notion of
compositionally-interpretable (CI) models, which additionally include, for
instance, causal, conceptual space, and DisCoCirc models.
  We next demonstrate the explainability benefits of CI models. Firstly, their
compositional structure may allow the computation of other quantities of
interest, and may facilitate inference from the model to the modelled
phenomenon by matching its structure. Secondly, they allow for diagrammatic
explanations for their behaviour, based on influence constraints, diagram
surgery and rewrite explanations. Finally, we discuss many future directions
for the approach, raising the question of how to learn such meaningfully
structured models in practice.

摘要：<paragraph>人工智慧（AI）目前在很大程度上依賴於缺乏可解釋性的黑盒機器學習模型。可解釋性人工智慧（XAI）領域致力於解決這個主要問題，這在金融、法律和健康等高風險領域至關重要。
我們提出了一種基於範疇論定義 AI 模型及其可解釋性的方法。為此，我們採用組合模型的概念，它以形式弦圖的形式看待模型，這些弦圖捕獲了模型的抽象結構及其具體實現。這種綜合觀點包含了確定性、概率性和量子模型。我們將各種 AI 模型作為組合模型進行比較，包括線性和基於規則的模型、（遞迴）神經網路、Transformer、VAE，以及因果和 DisCoCirc 模型。
接下來，我們根據模型的組合結構給出模型解釋的定義，展示如何分析模型的可解釋性，並使用它來澄清 XAI 中的常見主題。我們發現，讓標準的「內在可解釋」模型如此透明的原因在圖表中表現得最為清楚。這引導我們得出更一般的組合可解釋（CI）模型概念，它另外還包括因果、概念空間和 DisCoCirc 模型。
接下來，我們展示了 CI 模型的可解釋性優勢。首先，它們的組合結構允許計算其他感興趣的量，並可能通過匹配模型的結構來促進從模型到被建模現象的推理。其次，它們允許對其行為進行圖解說明，這些說明基於影響約束、圖解手術和重寫說明。最後，我們討論了這種方法的許多未來方向，提出了如何在實踐中學習這種有意義的結構化模型的問題。</paragraph>

##### **Unlocking the Potential of Metaverse in Innovative and Immersive Digital Health**
2406.07114v2 by Fatemeh Ebrahimzadeh, Ramin Safa

The concept of Metaverse has attracted a lot of attention in various fields
and one of its important applications is health and treatment. The Metaverse
has enormous potential to transform healthcare by changing patient care,
medical education, and the way teaching/learning and research are done. The
purpose of this research is to provide an introduction to the basic concepts
and fundamental technologies of the Metaverse. This paper examines the pros and
cons of the Metaverse in healthcare context and analyzes its potential from the
technology and AI perspective. In particular, the role of machine learning
methods is discussed; We will explain how machine learning algorithms can be
applied to the Metaverse generated data to gain better insights in healthcare
applications. Additionally, we examine the future visions of the Metaverse in
health delivery, by examining emerging technologies such as blockchain and also
addressing privacy concerns. The findings of this study contribute to a deeper
understanding of the applications of Metaverse in healthcare and its potential
to revolutionize the delivery of medical services.

摘要：元宇宙的概念在各個領域都備受關注，其重要應用之一便是醫療保健。元宇宙有巨大的潛力透過改變病患照護、醫學教育，以及教學/學習和研究的方式來轉型醫療保健。本研究的目的是提供元宇宙基本概念和基礎技術的介紹。本文探討了元宇宙在醫療保健背景下的優缺點，並從技術和 AI 的角度分析其潛力。特別是，討論了機器學習方法的角色；我們將說明如何將機器學習演算法應用於元宇宙產生的資料，以獲得醫療保健應用方面的更佳見解。此外，我們透過探討區塊鏈等新興技術，並解決隱私問題，來探討元宇宙在醫療保健方面的未來願景。本研究的發現有助於更深入地了解元宇宙在醫療保健中的應用，以及其在醫療服務提供方面發揮革命性變革的潛力。

##### **AI-Driven Predictive Analytics Approach for Early Prognosis of Chronic Kidney Disease Using Ensemble Learning and Explainable AI**
2406.06728v1 by K M Tawsik Jawad, Anusha Verma, Fathi Amsaad

Chronic Kidney Disease (CKD) is one of the widespread Chronic diseases with
no known ultimo cure and high morbidity. Research demonstrates that progressive
Chronic Kidney Disease (CKD) is a heterogeneous disorder that significantly
impacts kidney structure and functions, eventually leading to kidney failure.
With the progression of time, chronic kidney disease has moved from a
life-threatening disease affecting few people to a common disorder of varying
severity. The goal of this research is to visualize dominating features,
feature scores, and values exhibited for early prognosis and detection of CKD
using ensemble learning and explainable AI. For that, an AI-driven predictive
analytics approach is proposed to aid clinical practitioners in prescribing
lifestyle modifications for individual patients to reduce the rate of
progression of this disease. Our dataset is collected on body vitals from
individuals with CKD and healthy subjects to develop our proposed AI-driven
solution accurately. In this regard, blood and urine test results are provided,
and ensemble tree-based machine-learning models are applied to predict unseen
cases of CKD. Our research findings are validated after lengthy consultations
with nephrologists. Our experiments and interpretation results are compared
with existing explainable AI applications in various healthcare domains,
including CKD. The comparison shows that our developed AI models, particularly
the Random Forest model, have identified more features as significant
contributors than XgBoost. Interpretability (I), which measures the ratio of
important to masked features, indicates that our XgBoost model achieved a
higher score, specifically a Fidelity of 98\%, in this metric and naturally in
the FII index compared to competing models.

摘要：慢性腎臟病（CKD）是一種廣泛的慢性疾病，沒有已知的最終療法且發病率很高。研究表明，進行性慢性腎臟病（CKD）是一種異質性疾病，會顯著影響腎臟結構和功能，最終導致腎衰竭。隨著時間的推移，慢性腎臟病已從影響少數人的致命疾病轉變為一種嚴重程度不同的常見疾病。本研究的目標是使用集成學習和可解釋的 AI 進行早期預後和 CKD 檢測，並視覺化主導特徵、特徵分數和表現出的值。為此，提出了一種 AI 驅動的預測分析方法，以幫助臨床醫生為個別患者開具生活方式修改建議，以降低這種疾病的進展速度。我們的數據集是從 CKD 患者和健康受試者的身體生命體徵中收集的，以準確開發我們提出的 AI 驅動的解決方案。在這方面，提供了血液和尿液檢測結果，並應用基於集成樹的機器學習模型來預測未發現的 CKD 病例。我們的研究結果經過與腎臟科醫生的長期諮詢後得到驗證。我們的實驗和解釋結果與各種醫療保健領域中現有的可解釋 AI 應用進行了比較，包括 CKD。比較表明，我們開發的 AI 模型，特別是隨機森林模型，已經確定了比 XgBoost 更多作為重要貢獻者的特徵。可解釋性 (I) 衡量重要特徵與掩蓋特徵的比率，表明我們的 XgBoost 模型在這個指標中獲得了更高的分數，特別是 98% 的保真度，並且在 FII 指數中自然高於競爭模型。

##### **Explainable AI for Mental Disorder Detection via Social Media: A survey and outlook**
2406.05984v1 by Yusif Ibrahimov, Tarique Anwar, Tommy Yuan

Mental health constitutes a complex and pervasive global challenge, affecting
millions of lives and often leading to severe consequences. In this paper, we
conduct a thorough survey to explore the intersection of data science,
artificial intelligence, and mental healthcare, focusing on the recent
developments of mental disorder detection through online social media (OSM). A
significant portion of the population actively engages in OSM platforms,
creating a vast repository of personal data that holds immense potential for
mental health analytics. The paper navigates through traditional diagnostic
methods, state-of-the-art data- and AI-driven research studies, and the
emergence of explainable AI (XAI) models for mental healthcare. We review
state-of-the-art machine learning methods, particularly those based on modern
deep learning, while emphasising the need for explainability in healthcare AI
models. The experimental design section provides insights into prevalent
practices, including available datasets and evaluation approaches. We also
identify key issues and challenges in the field and propose promising future
research directions. As mental health decisions demand transparency,
interpretability, and ethical considerations, this paper contributes to the
ongoing discourse on advancing XAI in mental healthcare through social media.
The comprehensive overview presented here aims to guide researchers,
practitioners, and policymakers in developing the area of mental disorder
detection.

摘要：心理健康構成了一項複雜且普遍的全球挑戰，影響了數百萬人的生活，並經常導致嚴重的後果。在本文中，我們進行了一項徹底的調查，以探索數據科學、人工智慧和心理保健的交集，重點關注通過線上社交媒體 (OSM) 進行心理疾病檢測的最新發展。很大一部分人口積極參與 OSM 平台，創造了一個龐大的人員資料庫，對心理健康分析具有巨大的潛力。本文探討了傳統的診斷方法、最先進的資料和 AI 驅動的研究，以及心理保健中可解釋 AI (XAI) 模型的出現。我們回顧了最先進的機器學習方法，特別是那些基於現代深度學習的方法，同時強調了醫療保健 AI 模型中可解釋性的必要性。實驗設計部分提供了對普遍做法的見解，包括可用的資料集和評估方法。我們還找出該領域的主要問題和挑戰，並提出了有希望的未來研究方向。由於心理健康決策需要透明度、可解釋性和道德考量，本文有助於推進心理保健中透過社交媒體推進 XAI 的持續討論。這裡提出的全面概述旨在引導研究人員、從業人員和政策制定者發展心理疾病檢測領域。

##### **Methodology and Real-World Applications of Dynamic Uncertain Causality Graph for Clinical Diagnosis with Explainability and Invariance**
2406.05746v1 by Zhan Zhang, Qin Zhang, Yang Jiao, Lin Lu, Lin Ma, Aihua Liu, Xiao Liu, Juan Zhao, Yajun Xue, Bing Wei, Mingxia Zhang, Ru Gao, Hong Zhao, Jie Lu, Fan Li, Yang Zhang, Yiming Wang, Lei Zhang, Fengwei Tian, Jie Hu, Xin Gou

AI-aided clinical diagnosis is desired in medical care. Existing deep
learning models lack explainability and mainly focus on image analysis. The
recently developed Dynamic Uncertain Causality Graph (DUCG) approach is
causality-driven, explainable, and invariant across different application
scenarios, without problems of data collection, labeling, fitting, privacy,
bias, generalization, high cost and high energy consumption. Through close
collaboration between clinical experts and DUCG technicians, 46 DUCG models
covering 54 chief complaints were constructed. Over 1,000 diseases can be
diagnosed without triage. Before being applied in real-world, the 46 DUCG
models were retrospectively verified by third-party hospitals. The verified
diagnostic precisions were no less than 95%, in which the diagnostic precision
for every disease including uncommon ones was no less than 80%. After
verifications, the 46 DUCG models were applied in the real-world in China. Over
one million real diagnosis cases have been performed, with only 17 incorrect
diagnoses identified. Due to DUCG's transparency, the mistakes causing the
incorrect diagnoses were found and corrected. The diagnostic abilities of the
clinicians who applied DUCG frequently were improved significantly. Following
the introduction to the earlier presented DUCG methodology, the recommendation
algorithm for potential medical checks is presented and the key idea of DUCG is
extracted.

摘要：<paragraph>醫療照護中需要 AI 輔助的臨床診斷。現有的深度學習模型缺乏可解釋性，並且主要專注於影像分析。最近開發的動態不確定因果關係圖 (DUCG) 方法是因果驅動的、可解釋的，並且在不同的應用場景中是不變的，沒有資料收集、標記、擬合、隱私、偏見、概化、高成本和高能耗的問題。通過臨床專家和 DUCG 技術人員之間的密切合作，構建了涵蓋 54 個主訴的 46 個 DUCG 模型。可以在沒有分流的情況下診斷出 1,000 多種疾病。在應用於實際世界之前，46 個 DUCG 模型已由第三方醫院回溯性驗證。驗證的診斷精度不低於 95%，其中包括罕見疾病在內的每種疾病的診斷精度不低於 80%。驗證後，46 個 DUCG 模型已在中國實際應用。已經執行了超過一百萬個真實診斷案例，僅發現 17 個不正確的診斷。由於 DUCG 的透明性，發現並糾正了導致不正確診斷的錯誤。頻繁應用 DUCG 的臨床醫生的診斷能力得到了顯著提高。在介紹了前面提出的 DUCG 方法論之後，提出了潛在健康檢查的推薦演算法，並提取了 DUCG 的關鍵思想。</paragraph>

##### **Advancing Histopathology-Based Breast Cancer Diagnosis: Insights into Multi-Modality and Explainability**
2406.12897v1 by Faseela Abdullakutty, Younes Akbari, Somaya Al-Maadeed, Ahmed Bouridane, Rifat Hamoudi

It is imperative that breast cancer is detected precisely and timely to
improve patient outcomes. Diagnostic methodologies have traditionally relied on
unimodal approaches; however, medical data analytics is integrating diverse
data sources beyond conventional imaging. Using multi-modal techniques,
integrating both image and non-image data, marks a transformative advancement
in breast cancer diagnosis. The purpose of this review is to explore the
burgeoning field of multimodal techniques, particularly the fusion of
histopathology images with non-image data. Further, Explainable AI (XAI) will
be used to elucidate the decision-making processes of complex algorithms,
emphasizing the necessity of explainability in diagnostic processes. This
review utilizes multi-modal data and emphasizes explainability to enhance
diagnostic accuracy, clinician confidence, and patient engagement, ultimately
fostering more personalized treatment strategies for breast cancer, while also
identifying research gaps in multi-modality and explainability, guiding future
studies, and contributing to the strategic direction of the field.

摘要：精確且及時地偵測乳癌對於改善患者預後至關重要。診斷方法傳統上依賴於單一模式方法；然而，醫療資料分析正在整合超越傳統影像的各種資料來源。使用整合影像和非影像資料的多模式技術，標誌著乳癌診斷的變革性進展。本篇綜述的目的是探討多模式技術的新興領域，特別是將組織病理學影像與非影像資料融合。此外，可解釋人工智慧 (XAI) 將用於闡明複雜演算法的決策過程，強調診斷過程中可解釋性的必要性。本綜述利用多模式資料並強調可解釋性，以提高診斷準確性、臨床醫師的信心和患者參與度，最終促進乳癌更個人化的治療策略，同時也找出多模式和可解釋性的研究差距，引導未來的研究，並為該領域的策略方向做出貢獻。

##### **Revisiting Attention Weights as Interpretations of Message-Passing Neural Networks**
2406.04612v1 by Yong-Min Shin, Siqing Li, Xin Cao, Won-Yong Shin

The self-attention mechanism has been adopted in several widely-used
message-passing neural networks (MPNNs) (e.g., GATs), which adaptively controls
the amount of information that flows along the edges of the underlying graph.
This usage of attention has made such models a baseline for studies on
explainable AI (XAI) since interpretations via attention have been popularized
in various domains (e.g., natural language processing and computer vision).
However, existing studies often use naive calculations to derive attribution
scores from attention, and do not take the precise and careful calculation of
edge attribution into consideration. In our study, we aim to fill the gap
between the widespread usage of attention-enabled MPNNs and their potential in
largely under-explored explainability, a topic that has been actively
investigated in other areas. To this end, as the first attempt, we formalize
the problem of edge attribution from attention weights in GNNs. Then, we
propose GATT, an edge attribution calculation method built upon the computation
tree. Through comprehensive experiments, we demonstrate the effectiveness of
our proposed method when evaluating attributions from GATs. Conversely, we
empirically validate that simply averaging attention weights over graph
attention layers is insufficient to interpret the GAT model's behavior. Code is
publicly available at https://github.com/jordan7186/GAtt/tree/main.

摘要：自注意力機制已被採用於多個廣泛使用的訊息傳遞神經網路 (MPNN)（例如 GAT），它可以自適應地控制沿著底層圖形邊緣流動的資訊量。這種注意力的使用使得此類模型成為可解釋 AI (XAI) 研究的基線，因為透過注意力的詮釋已在各種領域（例如自然語言處理和電腦視覺）中普及。然而，現有的研究通常使用天真的計算方法從注意力中推導出歸因分數，並且沒有考慮到邊緣歸因的精確且仔細的計算。在我們的研究中，我們旨在填補注意力啟用 MPNN 的廣泛使用與它們在很大程度上未被充分探索的可解釋性之間的差距，這個主題已在其他領域積極研究。為此，作為第一次嘗試，我們將 GNN 中注意力權重的邊緣歸因問題形式化。然後，我們提出 GATT，一種建立在計算樹上的邊緣歸因計算方法。透過全面的實驗，我們展示了我們提出的方法在評估 GAT 的歸因時所具有的效果。相反地，我們憑經驗驗證了僅對圖注意力層上的注意力權重取平均值不足以詮釋 GAT 模型的行為。程式碼已公開於 https://github.com/jordan7186/GAtt/tree/main。

##### **Using Explainable AI for EEG-based Reduced Montage Neonatal Seizure Detection**
2406.16908v3 by Dinuka Sandun Udayantha, Kavindu Weerasinghe, Nima Wickramasinghe, Akila Abeyratne, Kithmin Wickremasinghe, Jithangi Wanigasinghe, Anjula De Silva, Chamira U. S. Edussooriya

The neonatal period is the most vulnerable time for the development of
seizures. Seizures in the immature brain lead to detrimental consequences,
therefore require early diagnosis. The gold-standard for neonatal seizure
detection currently relies on continuous video-EEG monitoring; which involves
recording multi-channel electroencephalogram (EEG) alongside real-time video
monitoring within a neonatal intensive care unit (NICU). However, video-EEG
monitoring technology requires clinical expertise and is often limited to
technologically advanced and resourceful settings. Cost-effective new
techniques could help the medical fraternity make an accurate diagnosis and
advocate treatment without delay. In this work, a novel explainable deep
learning model to automate the neonatal seizure detection process with a
reduced EEG montage is proposed, which employs convolutional nets, graph
attention layers, and fully connected layers. Beyond its ability to detect
seizures in real-time with a reduced montage, this model offers the unique
advantage of real-time interpretability. By evaluating the performance on the
Zenodo dataset with 10-fold cross-validation, the presented model achieves an
absolute improvement of 8.31% and 42.86% in area under curve (AUC) and recall,
respectively.

摘要：新生兒期是大腦發育最脆弱的時期，容易出現癲癇發作。大腦發育不成熟時出現癲癇發作會造成不良後果，因此需要及早診斷。目前新生兒癲癇發作的黃金標準依賴於連續的視訊腦電圖 (EEG) 監測；其中包括在新生兒加護病房 (NICU) 內同時進行多頻道腦電圖 (EEG) 記錄和即時視訊監控。然而，視訊腦電圖監控技術需要臨床專業知識，而且通常僅限於技術先進且資源豐富的環境。具成本效益的新技術可以幫助醫療界準確診斷並立即提倡治療。在這項工作中，提出了一個新穎的可解釋深度學習模型，以自動化新生兒癲癇發作偵測過程，並採用減少的腦電圖裝置，其中採用了卷積神經網路、圖形注意力層和全連接層。除了能夠使用減少的裝置即時偵測癲癇發作外，此模型還提供了即時可解釋性的獨特優勢。透過在 Zenodo 資料集上使用 10 倍交叉驗證評估效能，所提出的模型在曲線下面積 (AUC) 和召回率方面分別達到了 8.31% 和 42.86% 的絕對改善。

##### **Breast Cancer Diagnosis: A Comprehensive Exploration of Explainable Artificial Intelligence (XAI) Techniques**
2406.00532v1 by Samita Bai, Sidra Nasir, Rizwan Ahmed Khan, Sheeraz Arif, Alexandre Meyer, Hubert Konik

Breast cancer (BC) stands as one of the most common malignancies affecting
women worldwide, necessitating advancements in diagnostic methodologies for
better clinical outcomes. This article provides a comprehensive exploration of
the application of Explainable Artificial Intelligence (XAI) techniques in the
detection and diagnosis of breast cancer. As Artificial Intelligence (AI)
technologies continue to permeate the healthcare sector, particularly in
oncology, the need for transparent and interpretable models becomes imperative
to enhance clinical decision-making and patient care. This review discusses the
integration of various XAI approaches, such as SHAP, LIME, Grad-CAM, and
others, with machine learning and deep learning models utilized in breast
cancer detection and classification. By investigating the modalities of breast
cancer datasets, including mammograms, ultrasounds and their processing with
AI, the paper highlights how XAI can lead to more accurate diagnoses and
personalized treatment plans. It also examines the challenges in implementing
these techniques and the importance of developing standardized metrics for
evaluating XAI's effectiveness in clinical settings. Through detailed analysis
and discussion, this article aims to highlight the potential of XAI in bridging
the gap between complex AI models and practical healthcare applications,
thereby fostering trust and understanding among medical professionals and
improving patient outcomes.

摘要：乳癌 (BC) 是影響全球女性最常見的惡性腫瘤之一，因此需要進步的診斷方法，以改善臨床結果。本文全面探討了可解釋人工智慧 (XAI) 技術在乳癌偵測和診斷中的應用。隨著人工智慧 (AI) 技術持續滲透醫療保健領域，特別是在腫瘤學中，透明且可解釋的模型需求變得勢在必行，以增強臨床決策制定和患者照護。此篇評論探討了各種 XAI 方法的整合，例如 SHAP、LIME、Grad-CAM 等，以及用於乳癌偵測和分類的機器學習和深度學習模型。透過探討乳癌資料集的模式，包括乳房攝影、超音波及其在 AI 中的處理，本文重點說明 XAI 如何能導致更準確的診斷和個人化治療計畫。它也探討了實施這些技術的挑戰，以及制定標準化評量指標以評估 XAI 在臨床環境中的有效性的重要性。透過詳細的分析和討論，本文旨在強調 XAI 在縮小複雜 AI 模型與實務醫療保健應用之間差距的潛力，進而促進醫療專業人員之間的信任與理解，並改善患者的結果。

##### **Unveiling Hidden Factors: Explainable AI for Feature Boosting in Speech Emotion Recognition**
2406.01624v2 by Alaa Nfissi, Wassim Bouachir, Nizar Bouguila, Brian Mishara

Speech emotion recognition (SER) has gained significant attention due to its
several application fields, such as mental health, education, and
human-computer interaction. However, the accuracy of SER systems is hindered by
high-dimensional feature sets that may contain irrelevant and redundant
information. To overcome this challenge, this study proposes an iterative
feature boosting approach for SER that emphasizes feature relevance and
explainability to enhance machine learning model performance. Our approach
involves meticulous feature selection and analysis to build efficient SER
systems. In addressing our main problem through model explainability, we employ
a feature evaluation loop with Shapley values to iteratively refine feature
sets. This process strikes a balance between model performance and
transparency, which enables a comprehensive understanding of the model's
predictions. The proposed approach offers several advantages, including the
identification and removal of irrelevant and redundant features, leading to a
more effective model. Additionally, it promotes explainability, facilitating
comprehension of the model's predictions and the identification of crucial
features for emotion determination. The effectiveness of the proposed method is
validated on the SER benchmarks of the Toronto emotional speech set (TESS),
Berlin Database of Emotional Speech (EMO-DB), Ryerson Audio-Visual Database of
Emotional Speech and Song (RAVDESS), and Surrey Audio-Visual Expressed Emotion
(SAVEE) datasets, outperforming state-of-the-art methods. To the best of our
knowledge, this is the first work to incorporate model explainability into an
SER framework. The source code of this paper is publicly available via this
https://github.com/alaaNfissi/Unveiling-Hidden-Factors-Explainable-AI-for-Feature-Boosting-in-Speech-Emotion-Recognition.

摘要：語音情緒辨識 (SER) 由於其在心理健康、教育和人機互動等多個應用領域而備受關注。然而，SER 系統的準確性受到高維特徵集的阻礙，這些特徵集可能包含不相關和冗餘的資訊。為了克服這個挑戰，本研究提出了一種用於 SER 的迭代特徵提升方法，該方法強調特徵相關性和可解釋性，以增強機器學習模型的效能。我們的做法涉及仔細的特徵選擇和分析，以建立高效的 SER 系統。為了透過模型可解釋性解決我們的核心問題，我們採用了具有 Shapley 值的特徵評估迴圈，以反覆改善特徵集。這個過程在模型效能和透明度之間取得平衡，這使得我們能夠全面了解模型的預測。所提出的方法提供了多項優點，包括識別和移除不相關和冗餘的特徵，從而建立更有效的模型。此外，它促進了可解釋性，有助於理解模型的預測以及識別情緒決定的關鍵特徵。所提出的方法的有效性已在多倫多情緒語音集 (TESS)、柏林情緒語音資料庫 (EMO-DB)、賴爾森音訊視覺情緒語音和歌曲資料庫 (RAVDESS) 和薩里音訊視覺表達情緒 (SAVEE) 資料集的 SER 基準上得到驗證，其效能優於現有方法。據我們所知，這是第一個將模型可解釋性納入 SER 架構的研究。本文的原始碼可透過此連結公開取得：https://github.com/alaaNfissi/Unveiling-Hidden-Factors-Explainable-AI-for-Feature-Boosting-in-Speech-Emotion-Recognition。

##### **The Explanation Necessity for Healthcare AI**
2406.00216v1 by Michail Mamalakis, Héloïse de Vareilles, Graham Murray, Pietro Lio, John Suckling

Explainability is often critical to the acceptable implementation of
artificial intelligence (AI). Nowhere is this more important than healthcare
where decision-making directly impacts patients and trust in AI systems is
essential. This trust is often built on the explanations and interpretations
the AI provides. Despite significant advancements in AI interpretability, there
remains the need for clear guidelines on when and to what extent explanations
are necessary in the medical context. We propose a novel categorization system
with four distinct classes of explanation necessity, guiding the level of
explanation required: patient or sample (local) level, cohort or dataset
(global) level, or both levels. We introduce a mathematical formulation that
distinguishes these categories and offers a practical framework for researchers
to determine the necessity and depth of explanations required in medical AI
applications. Three key factors are considered: the robustness of the
evaluation protocol, the variability of expert observations, and the
representation dimensionality of the application. In this perspective, we
address the question: When does an AI medical application need to be explained,
and at what level of detail?

摘要：可解释性通常对于人工智能 (AI) 的可接受实施至关重要。在医疗保健领域，这一点尤为重要，因为决策直接影响患者，并且对 AI 系统的信任至关重要。这种信任通常建立在 AI 提供的解释和诠释之上。尽管 AI 可解释性取得了重大进展，但仍然需要明确的指导方针，说明在医疗环境中何时以及在多大程度上需要解释。我们提出了一种新颖的分类系统，该系统具有四种不同的解释必要性类别，指导所需的解释级别：患者或样本（局部）级别、队列或数据集（全局）级别，或两个级别。我们引入了一个数学公式，该公式区分了这些类别，并为研究人员提供了一个实用框架，以确定医疗 AI 应用中所需的解释的必要性和深度。考虑了三个关键因素：评估协议的稳健性、专家观察的可变性以及应用程序的表示维数。从这个角度来看，我们解决了这个问题：AI 医疗应用何时需要解释，以及需要解释到何种程度？

##### **Interdisciplinary Expertise to Advance Equitable Explainable AI**
2406.18563v1 by Chloe R. Bennett, Heather Cole-Lewis, Stephanie Farquhar, Naama Haamel, Boris Babenko, Oran Lang, Mat Fleck, Ilana Traynis, Charles Lau, Ivor Horn, Courtney Lyles

The field of artificial intelligence (AI) is rapidly influencing health and
healthcare, but bias and poor performance persists for populations who face
widespread structural oppression. Previous work has clearly outlined the need
for more rigorous attention to data representativeness and model performance to
advance equity and reduce bias. However, there is an opportunity to also
improve the explainability of AI by leveraging best practices of social
epidemiology and health equity to help us develop hypotheses for associations
found. In this paper, we focus on explainable AI (XAI) and describe a framework
for interdisciplinary expert panel review to discuss and critically assess AI
model explanations from multiple perspectives and identify areas of bias and
directions for future research. We emphasize the importance of the
interdisciplinary expert panel to produce more accurate, equitable
interpretations which are historically and contextually informed.
Interdisciplinary panel discussions can help reduce bias, identify potential
confounders, and identify opportunities for additional research where there are
gaps in the literature. In turn, these insights can suggest opportunities for
AI model improvement.

摘要：人工智慧 (AI) 領域正快速影響著健康與醫療保健，但對於面臨廣泛結構性壓迫的人群來說，偏見和不良表現依然存在。先前的研究已清楚說明，需要更嚴格地注意資料代表性和模型效能，以促進公平性並減少偏見。然而，我們有機會透過運用社會流行病學和健康公平的最佳實務，來改善 AI 的可解釋性，以幫助我們針對發現的關聯性，發展假設。在本文中，我們專注於可解釋 AI (XAI)，並描述一個跨領域專家小組審查架構，以從多重觀點討論和批判性評估 AI 模型的解釋，並找出偏見領域和未來研究的方向。我們強調跨領域專家小組對於產生更準確、公平的詮釋至關重要，而這些詮釋是根據歷史和脈絡而來的。跨領域小組討論有助於減少偏見、找出潛在的混淆因素，並在文獻中有缺口時找出額外研究的機會。反過來，這些見解可以建議 AI 模型改進的機會。

##### **"It depends": Configuring AI to Improve Clinical Usefulness Across Contexts**
2407.11978v1 by Hubert D. Zając, Jorge M. N. Ribeiro, Silvia Ingala, Simona Gentile, Ruth Wanjohi, Samuel N. Gitau, Jonathan F. Carlsen, Michael B. Nielsen, Tariq O. Andersen

Artificial Intelligence (AI) repeatedly match or outperform radiologists in
lab experiments. However, real-world implementations of radiological AI-based
systems are found to provide little to no clinical value. This paper explores
how to design AI for clinical usefulness in different contexts. We conducted 19
design sessions and design interventions with 13 radiologists from 7 clinical
sites in Denmark and Kenya, based on three iterations of a functional AI-based
prototype. Ten sociotechnical dependencies were identified as crucial for the
design of AI in radiology. We conceptualised four technical dimensions that
must be configured to the intended clinical context of use: AI functionality,
AI medical focus, AI decision threshold, and AI Explainability. We present four
design recommendations on how to address dependencies pertaining to the medical
knowledge, clinic type, user expertise level, patient context, and user
situation that condition the configuration of these technical dimensions.

摘要：人工智慧（AI）在實驗室實驗中不斷地與放射科醫師匹敵或表現得更出色。然而，發現放射科 AI 為基礎系統的實際執行幾乎沒有提供臨床價值。本文探討如何為 AI 設計在不同情境中臨床上的效用。我們根據功能性 AI 為基礎原型的三次迭代，在丹麥和肯亞的 7 個臨床場域與 13 位放射科醫師進行了 19 次設計會議和設計介入。十個社會技術依賴關係被認為對於放射科中 AI 的設計至關重要。我們概念化了四個技術面向，必須根據預期的臨床使用情境進行設定：AI 功能、AI 醫療重點、AI 決策門檻，以及 AI 可解釋性。我們提出四項設計建議，說明如何處理與醫療知識、診所類型、使用者專業知識等級、患者情境，以及影響這些技術面向設定的使用者情境相關的依賴關係。

##### **Improving Health Professionals' Onboarding with AI and XAI for Trustworthy Human-AI Collaborative Decision Making**
2405.16424v1 by Min Hun Lee, Silvana Xin Yi Choo, Shamala D/O Thilarajah

With advanced AI/ML, there has been growing research on explainable AI (XAI)
and studies on how humans interact with AI and XAI for effective human-AI
collaborative decision-making. However, we still have a lack of understanding
of how AI systems and XAI should be first presented to users without technical
backgrounds. In this paper, we present the findings of semi-structured
interviews with health professionals (n=12) and students (n=4) majoring in
medicine and health to study how to improve onboarding with AI and XAI. For the
interviews, we built upon human-AI interaction guidelines to create onboarding
materials of an AI system for stroke rehabilitation assessment and AI
explanations and introduce them to the participants. Our findings reveal that
beyond presenting traditional performance metrics on AI, participants desired
benchmark information, the practical benefits of AI, and interaction trials to
better contextualize AI performance, and refine the objectives and performance
of AI. Based on these findings, we highlight directions for improving
onboarding with AI and XAI and human-AI collaborative decision-making.

摘要：隨著先進的 AI/ML，對可解釋 AI (XAI) 的研究不斷增加，以及關於人類如何與 AI 和 XAI 互動以進行有效的人工智慧協作決策制定。然而，我們仍然缺乏對 AI 系統和 XAI 應如何首先呈現給沒有技術背景的用戶的了解。在本文中，我們展示了與醫療專業人員 (n=12) 和主修醫學和健康的學生 (n=4) 進行半結構化訪談的結果，以研究如何改善 AI 和 XAI 的入門。對於訪談，我們建立在人機互動準則之上，為中風康復評估和 AI 解釋的 AI 系統創建入門材料，並將它們介紹給參與者。我們的研究結果表明，除了呈現傳統的 AI 性能指標外，參與者還希望基准信息、AI 的實際好處以及交互試驗，以更好地將 AI 性能情境化，並完善 AI 的目標和性能。根據這些發現，我們強調了改進 AI 和 XAI 以及人機協作決策制定的入門方向。

##### **Exploring Nutritional Impact on Alzheimer's Mortality: An Explainable AI Approach**
2405.17502v1 by Ziming Liu, Longjian Liu, Robert E. Heidel, Xiaopeng Zhao

This article uses machine learning (ML) and explainable artificial
intelligence (XAI) techniques to investigate the relationship between
nutritional status and mortality rates associated with Alzheimers disease (AD).
The Third National Health and Nutrition Examination Survey (NHANES III)
database is employed for analysis. The random forest model is selected as the
base model for XAI analysis, and the Shapley Additive Explanations (SHAP)
method is used to assess feature importance. The results highlight significant
nutritional factors such as serum vitamin B12 and glycated hemoglobin. The
study demonstrates the effectiveness of random forests in predicting AD
mortality compared to other diseases. This research provides insights into the
impact of nutrition on AD and contributes to a deeper understanding of disease
progression.

摘要：本文使用機器學習 (ML) 和可解釋人工智慧 (XAI) 技術來探討營養狀況與阿茲海默症 (AD) 相關的死亡率之間的關係。採用第三次全國健康與營養檢查調查 (NHANES III) 資料庫進行分析。選擇隨機森林模型作為 XAI 分析的基礎模型，並使用 Shapley Additive Explanations (SHAP) 方法來評估特徵重要性。結果突顯了重要的營養因素，例如血清維生素 B12 和糖化血紅蛋白。該研究證明了隨機森林在預測 AD 死亡率方面相較於其他疾病的有效性。本研究提供了營養對 AD 的影響的見解，並有助於更深入地了解疾病的進展。

##### **Explainable AI Enhances Glaucoma Referrals, Yet the Human-AI Team Still Falls Short of the AI Alone**
2407.11974v1 by Catalina Gomez, Ruolin Wang, Katharina Breininger, Corinne Casey, Chris Bradley, Mitchell Pavlak, Alex Pham, Jithin Yohannan, Mathias Unberath

Primary care providers are vital for initial triage and referrals to
specialty care. In glaucoma, asymptomatic and fast progression can lead to
vision loss, necessitating timely referrals to specialists. However, primary
eye care providers may not identify urgent cases, potentially delaying care.
Artificial Intelligence (AI) offering explanations could enhance their referral
decisions. We investigate how various AI explanations help providers
distinguish between patients needing immediate or non-urgent specialist
referrals. We built explainable AI algorithms to predict glaucoma surgery needs
from routine eyecare data as a proxy for identifying high-risk patients. We
incorporated intrinsic and post-hoc explainability and conducted an online
study with optometrists to assess human-AI team performance, measuring referral
accuracy and analyzing interactions with AI, including agreement rates, task
time, and user experience perceptions. AI support enhanced referral accuracy
among 87 participants (59.9%/50.8% with/without AI), though Human-AI teams
underperformed compared to AI alone. Participants believed they included AI
advice more when using the intrinsic model, and perceived it more useful and
promising. Without explanations, deviations from AI recommendations increased.
AI support did not increase workload, confidence, and trust, but reduced
challenges. On a separate test set, our black-box and intrinsic models achieved
an accuracy of 77% and 71%, respectively, in predicting surgical outcomes. We
identify opportunities of human-AI teaming for glaucoma management in primary
eye care, noting that while AI enhances referral accuracy, it also shows a
performance gap compared to AI alone, even with explanations. Human involvement
remains essential in medical decision making, underscoring the need for future
research to optimize collaboration, ensuring positive experiences and safe AI
use.

摘要：<paragraph>初級保健提供者對於最初的分流和轉診到專科照護至關重要。在青光眼的情況下，無症狀且快速惡化可能導致視力喪失，因此需要及時轉診給專家。然而，初級眼科保健提供者可能無法識別緊急情況，可能會延誤照護。提供解釋的人工智慧 (AI) 可以加強他們的轉診決策。我們研究各種 AI 解釋如何幫助提供者區分需要立即或非緊急專科轉診的患者。我們建立了解釋性 AI 演算法，以從例行眼科護理資料預測青光眼手術需求，作為識別高風險患者的代理。我們納入了內在和事後解釋性，並與驗光師進行了一項線上研究，以評估人機團隊的表現，衡量轉診準確度並分析與 AI 的互動，包括同意率、任務時間和使用者體驗感知。在 87 名參與者中，AI 支援提高了轉診準確度（使用 AI/未使用的比例為 59.9%/50.8%），儘管人機團隊的表現不如單獨使用 AI。參與者認為他們在使用內在模型時更多地納入了 AI 建議，並認為它更有用且更有希望。沒有解釋，AI 建議的偏差會增加。AI 支援並未增加工作量、信心和信任，但減少了挑戰。在一個單獨的測試集中，我們的黑盒子和內在模型在預測手術結果方面分別達到了 77% 和 71% 的準確度。我們找出在初級眼科保健中，人機團隊合作管理青光眼的機會，並注意到雖然 AI 提高了轉診準確度，但即使有解釋，它也顯示出與單獨使用 AI 相比的效能差距。人類參與在醫療決策中仍然至關重要，這強調了未來研究優化協作、確保正面經驗和安全使用 AI 的必要性。</paragraph>

##### **Decoding Decision Reasoning: A Counterfactual-Powered Model for Knowledge Discovery**
2406.18552v1 by Yingying Fang, Zihao Jin, Xiaodan Xing, Simon Walsh, Guang Yang

In medical imaging, particularly in early disease detection and prognosis
tasks, discerning the rationale behind an AI model's predictions is crucial for
evaluating the reliability of its decisions. Conventional explanation methods
face challenges in identifying discernible decisive features in medical image
classifications, where discriminative features are subtle or not immediately
apparent. To bridge this gap, we propose an explainable model that is equipped
with both decision reasoning and feature identification capabilities. Our
approach not only detects influential image patterns but also uncovers the
decisive features that drive the model's final predictions. By implementing our
method, we can efficiently identify and visualise class-specific features
leveraged by the data-driven model, providing insights into the decision-making
processes of deep learning models. We validated our model in the demanding
realm of medical prognosis task, demonstrating its efficacy and potential in
enhancing the reliability of AI in healthcare and in discovering new knowledge
in diseases where prognostic understanding is limited.

摘要：在醫學影像中，特別是在早期疾病檢測和預後任務中，辨別 AI 模型預測背後的原理對於評估其決策的可靠性至關重要。傳統的解釋方法在識別醫學影像分類中可識別的決定性特徵時面臨挑戰，其中區別性特徵很微妙或並不明顯。為了彌合這一差距，我們提出了一個可解釋的模型，該模型具備決策推理和特徵識別能力。我們的做法不僅檢測有影響力的影像模式，還揭示了推動模型最終預測的決定性特徵。通過實施我們的模型，我們可以有效識別和視覺化由數據驅動模型利用的類特定特徵，從而深入了解深度學習模型的決策過程。我們在要求嚴格的醫學預後任務領域驗證了我們的模型，展示了其在提高 AI 在醫療保健中的可靠性和發現預後理解受限疾病的新知識方面的功效和潛力。

##### **The Role of Emotions in Informational Support Question-Response Pairs in Online Health Communities: A Multimodal Deep Learning Approach**
2405.13099v1 by Mohsen Jozani, Jason A. Williams, Ahmed Aleroud, Sarbottam Bhagat

This study explores the relationship between informational support seeking
questions, responses, and helpfulness ratings in online health communities. We
created a labeled data set of question-response pairs and developed multimodal
machine learning and deep learning models to reliably predict informational
support questions and responses. We employed explainable AI to reveal the
emotions embedded in informational support exchanges, demonstrating the
importance of emotion in providing informational support. This complex
interplay between emotional and informational support has not been previously
researched. The study refines social support theory and lays the groundwork for
the development of user decision aids. Further implications are discussed.

摘要：本研究探討線上健康社群中尋求資訊支持的問題、回應，以及有幫助的評分之間的關係。我們建立了一組標記的問答配對資料集，並開發了多模態機器學習和深度學習模型，以可靠地預測資訊支持問題和回應。我們採用可解釋的 AI 來揭示資訊支持交流中蘊含的情緒，證明情緒在提供資訊支持中的重要性。這種情緒支持和資訊支持之間的複雜交互作用以前並未被研究過。本研究改進了社會支持理論，並為使用者決策輔助工具的開發奠定了基礎。討論了進一步的影響。

##### **ChatGPT in Classrooms: Transforming Challenges into Opportunities in Education**
2405.10645v1 by Harris Bin Munawar, Nikolaos Misirlis

In the era of exponential technology growth, one unexpected guest has claimed
a seat in classrooms worldwide, Artificial Intelligence. Generative AI, such as
ChatGPT, promises a revolution in education, yet it arrives with a double-edged
sword. Its potential for personalized learning is offset by issues of cheating,
inaccuracies, and educators struggling to incorporate it effectively into their
lesson design. We are standing on the brink of this educational frontier, and
it is clear that we need to navigate this terrain with a lot of care. This is a
major challenge that could undermine the integrity and value of our educational
process. So, how can we turn these challenges into opportunities? When used
inappropriately, AI tools can become the perfect tool for the cut copy paste
mentality, and quickly begin to corrode critical thinking, creativity, and deep
understanding, the most important skills in our rapidly changing world.
Teachers feel that they are not equipped to leverage this technology, widening
the digital divide among educators and institutions. Addressing these concerns
calls for an in depth research approach. We will employ empirical research,
drawing on the Technology Acceptance Model, to assess the attitudes toward
generative AI among educators and students. Understanding their perceptions,
usage patterns, and hurdles is the first crucial step in creating an effective
solution. The present study will be used as a process manual for future
researchers to apply, running their own data, based on the steps explained here

摘要：在科技飛速發展的時代，一位意外的訪客已在全球教室中佔有一席之地，那就是人工智慧。生成式 AI，例如 ChatGPT，承諾在教育領域掀起一場革命，但它卻是一把雙面刃。它在個人化學習方面的潛力，卻因作弊、不準確以及教育工作者難以將其有效融入教學設計等問題而抵銷。我們正站在這教育前沿的邊緣，顯然我們需要非常小心地探索這片領域。這是一個重大的挑戰，可能會損害我們教育過程的完整性和價值。那麼，我們如何將這些挑戰轉化為機遇？當不適當地使用時，AI 工具可能會成為複製貼上心態的完美工具，並迅速腐蝕批判性思維、創造力和深入理解，這些都是我們快速變化的世界中最重要的技能。教師們覺得他們沒有能力利用這項技術，這擴大了教育工作者和機構之間的數位鴻溝。解決這些問題需要深入的研究方法。我們將採用實證研究，借鑑技術接受模型，來評估教育工作者和學生對生成式 AI 的態度。了解他們的看法、使用模式和障礙是創造有效解決方案的第一個關鍵步驟。本研究將作為未來研究人員應用的流程手冊，根據此處說明的步驟運行他們自己的數據

##### **Evaluating the Explainable AI Method Grad-CAM for Breath Classification on Newborn Time Series Data**
2405.07590v1 by Camelia Oprea, Mike Grüne, Mateusz Buglowski, Lena Olivier, Thorsten Orlikowsky, Stefan Kowalewski, Mark Schoberer, André Stollenwerk

With the digitalization of health care systems, artificial intelligence
becomes more present in medicine. Especially machine learning shows great
potential for complex tasks such as time series classification, usually at the
cost of transparency and comprehensibility. This leads to a lack of trust by
humans and thus hinders its active usage. Explainable artificial intelligence
tries to close this gap by providing insight into the decision-making process,
the actual usefulness of its different methods is however unclear. This paper
proposes a user study based evaluation of the explanation method Grad-CAM with
application to a neural network for the classification of breaths in time
series neonatal ventilation data. We present the perceived usefulness of the
explainability method by different stakeholders, exposing the difficulty to
achieve actual transparency and the wish for more in-depth explanations by many
of the participants.

摘要：隨著醫療保健系統的數位化，人工智慧在醫學領域中變得更加普及。特別是機器學習在時間序列分類等複雜任務中展現出極大的潛力，但通常是以透明度和可理解性為代價。這導致人類缺乏信任，從而阻礙了其積極使用。可解釋的人工智慧試圖通過提供對決策過程的洞察來彌補這一差距，但其不同方法的實際效用尚不清楚。本文提出了一個基於使用者研究的評估，其中包含了 Grad-CAM 解釋方法，並將其應用於神經網路以分類時間序列新生兒呼吸數據中的呼吸。我們展示了不同利益相關者對可解釋性方法的感知效用，揭示了實現實際透明度的難度，以及許多參與者希望獲得更深入的解釋。

##### **XAI4LLM. Let Machine Learning Models and LLMs Collaborate for Enhanced In-Context Learning in Healthcare**
2405.06270v3 by Fatemeh Nazary, Yashar Deldjoo, Tommaso Di Noia, Eugenio di Sciascio

The integration of Large Language Models (LLMs) into healthcare diagnostics
offers a promising avenue for clinical decision-making. This study outlines the
development of a novel method for zero-shot/few-shot in-context learning (ICL)
by integrating medical domain knowledge using a multi-layered structured
prompt. We also explore the efficacy of two communication styles between the
user and LLMs: the Numerical Conversational (NC) style, which processes data
incrementally, and the Natural Language Single-Turn (NL-ST) style, which
employs long narrative prompts.
  Our study systematically evaluates the diagnostic accuracy and risk factors,
including gender bias and false negative rates, using a dataset of 920 patient
records in various few-shot scenarios. Results indicate that traditional
clinical machine learning (ML) models generally outperform LLMs in zero-shot
and few-shot settings. However, the performance gap narrows significantly when
employing few-shot examples alongside effective explainable AI (XAI) methods as
sources of domain knowledge. Moreover, with sufficient time and an increased
number of examples, the conversational style (NC) nearly matches the
performance of ML models. Most notably, LLMs demonstrate comparable or superior
cost-sensitive accuracy relative to ML models.
  This research confirms that, with appropriate domain knowledge and tailored
communication strategies, LLMs can significantly enhance diagnostic processes.
The findings highlight the importance of optimizing the number of training
examples and communication styles to improve accuracy and reduce biases in LLM
applications.

摘要：大型語言模型 (LLM) 與醫療診斷整合
為臨床決策提供了一個有前景的途徑。本研究概述了一種新穎方法的開發，用於零次學習/少量學習情境學習 (ICL)，方法是使用多層結構化提示整合醫療領域知識。我們還探討了使用者與 LLM 之間兩種溝通方式的功效：數值對話 (NC) 方式，它會逐步處理資料，以及自然語言單回合 (NL-ST) 方式，它會使用長篇敘事提示。
我們的研究系統性地評估了診斷準確性和風險因子，包括性別偏見和假陰性率，使用了一個包含 920 個患者記錄的資料集，採用各種少量學習情境。結果表明，傳統的臨床機器學習 (ML) 模型通常在零次學習和少量學習設定中表現優於 LLM。然而，當使用少量學習範例以及有效的可解釋 AI (XAI) 方法作為領域知識來源時，效能差距會顯著縮小。此外，隨著時間充足和範例數量增加，對話方式 (NC) 幾乎可以媲美 ML 模型的效能。最值得注意的是，LLM 相對於 ML 模型展現出相當或更佳的成本敏感準確度。
本研究證實，透過適當的領域知識和量身打造的溝通策略，LLM 可以顯著增強診斷程序。這些發現突顯了最佳化訓練範例數量和溝通方式的重要性，以提高準確度並減少 LLM 應用中的偏差。

##### **To Trust or Not to Trust: Towards a novel approach to measure trust for XAI systems**
2405.05766v1 by Miquel Miró-Nicolau, Gabriel Moyà-Alcover, Antoni Jaume-i-Capó, Manuel González-Hidalgo, Maria Gemma Sempere Campello, Juan Antonio Palmer Sancho

The increasing reliance on Deep Learning models, combined with their inherent
lack of transparency, has spurred the development of a novel field of study
known as eXplainable AI (XAI) methods. These methods seek to enhance the trust
of end-users in automated systems by providing insights into the rationale
behind their decisions. This paper presents a novel approach for measuring user
trust in XAI systems, allowing their refinement. Our proposed metric combines
both performance metrics and trust indicators from an objective perspective. To
validate this novel methodology, we conducted a case study in a realistic
medical scenario: the usage of XAI system for the detection of pneumonia from
x-ray images.

摘要：隨著對深度學習模型依賴性的增加，加上其固有的透明度不足，促使一個新的研究領域發展，稱為可解釋 AI (XAI) 方法。這些方法旨在透過深入了解決策背後的原理，來提升最終使用者對自動化系統的信賴。本文提出了一種衡量使用者對 XAI 系統信賴度的新穎方法，允許對其進行改進。我們提出的指標結合了客觀觀點下的效能指標和信賴指標。為了驗證這個新穎的方法，我們在一個真實的醫療場景中進行了一個案例研究：使用 XAI 系統從 X 光影像中偵測肺炎。

##### **Region-specific Risk Quantification for Interpretable Prognosis of COVID-19**
2405.02815v1 by Zhusi Zhong, Jie Li, Zhuoqi Ma, Scott Collins, Harrison Bai, Paul Zhang, Terrance Healey, Xinbo Gao, Michael K. Atalay, Zhicheng Jiao

The COVID-19 pandemic has strained global public health, necessitating
accurate diagnosis and intervention to control disease spread and reduce
mortality rates. This paper introduces an interpretable deep survival
prediction model designed specifically for improved understanding and trust in
COVID-19 prognosis using chest X-ray (CXR) images. By integrating a large-scale
pretrained image encoder, Risk-specific Grad-CAM, and anatomical region
detection techniques, our approach produces regional interpretable outcomes
that effectively capture essential disease features while focusing on rare but
critical abnormal regions. Our model's predictive results provide enhanced
clarity and transparency through risk area localization, enabling clinicians to
make informed decisions regarding COVID-19 diagnosis with better understanding
of prognostic insights. We evaluate the proposed method on a multi-center
survival dataset and demonstrate its effectiveness via quantitative and
qualitative assessments, achieving superior C-indexes (0.764 and 0.727) and
time-dependent AUCs (0.799 and 0.691). These results suggest that our
explainable deep survival prediction model surpasses traditional survival
analysis methods in risk prediction, improving interpretability for clinical
decision making and enhancing AI system trustworthiness.

摘要：COVID-19 疫情對全球公共衛生造成壓力，必須進行準確的診斷和干預，以控制疾病傳播並降低死亡率。本文介紹了一個可解釋的深度生存預測模型，專門設計用於透過胸部 X 光 (CXR) 影像改善對 COVID-19 預後的理解和信賴。透過整合大規模預訓練影像編碼器、風險特定 Grad-CAM 和解剖區域偵測技術，我們的做法產生區域可解釋的結果，有效捕捉必要的疾病特徵，同時專注於罕見但關鍵的異常區域。我們的模型預測結果透過風險區域定位提供增強的清晰度和透明度，讓臨床醫生能夠在更了解預後見解的情況下，就 COVID-19 診斷做出明智的決策。我們在多中心生存資料集上評估所提出的方法，並透過量化和質化評估證明其有效性，達到優異的 C 指數（0.764 和 0.727）和時間相關 AUC（0.799 和 0.691）。這些結果表明，我們可解釋的深度生存預測模型在風險預測方面超越傳統的生存分析方法，提升臨床決策的解釋性，並增強 AI 系統的信賴度。

##### **Rad4XCNN: a new agnostic method for post-hoc global explanation of CNN-derived features by means of radiomics**
2405.02334v1 by Francesco Prinzi, Carmelo Militello, Calogero Zarcaro, Tommaso Vincenzo Bartolotta, Salvatore Gaglio, Salvatore Vitabile

In the last years, artificial intelligence (AI) in clinical decision support
systems (CDSS) played a key role in harnessing machine learning and deep
learning architectures. Despite their promising capabilities, the lack of
transparency and explainability of AI models poses significant challenges,
particularly in medical contexts where reliability is a mandatory aspect.
Achieving transparency without compromising predictive accuracy remains a key
challenge. This paper presents a novel method, namely Rad4XCNN, to enhance the
predictive power of CNN-derived features with the interpretability inherent in
radiomic features. Rad4XCNN diverges from conventional methods based on
saliency map, by associating intelligible meaning to CNN-derived features by
means of Radiomics, offering new perspectives on explanation methods beyond
visualization maps. Using a breast cancer classification task as a case study,
we evaluated Rad4XCNN on ultrasound imaging datasets, including an online
dataset and two in-house datasets for internal and external validation. Some
key results are: i) CNN-derived features guarantee more robust accuracy when
compared against ViT-derived and radiomic features; ii) conventional
visualization map methods for explanation present several pitfalls; iii)
Rad4XCNN does not sacrifice model accuracy for their explainability; iv)
Rad4XCNN provides global explanation insights enabling the physician to analyze
the model outputs and findings. In addition, we highlight the importance of
integrating interpretability into AI models for enhanced trust and adoption in
clinical practice, emphasizing how our method can mitigate some concerns
related to explainable AI methods.

摘要：<paragraph>在過去幾年，臨床決策支援系統 (CDSS) 中的人工智慧 (AI) 在利用機器學習和深度學習架構方面發揮了關鍵作用。儘管 AI 模型具有令人滿意的能力，但缺乏透明度和可解釋性，特別是在可靠性為必要考量的醫療背景下，這帶來了重大的挑戰。在不影響預測精準度的情況下實現透明度仍然是一項關鍵挑戰。本文提出了一種新方法，即 Rad4XCNN，以增強 CNN 衍生特徵的預測能力，同時具備放射特徵固有的可解釋性。Rad4XCNN 不同於基於顯著性圖的傳統方法，它通過放射組學將可理解的含義與 CNN 衍生特徵關聯起來，為超越視覺化圖表的解釋方法提供了新的觀點。我們以乳癌分類任務作為案例研究，在超音波影像資料集上評估 Rad4XCNN，包括一個線上資料集和兩個用於內部和外部驗證的內部資料集。一些關鍵結果如下：i) 與 ViT 衍生特徵和放射特徵相比，CNN 衍生特徵保證了更穩健的準確度；ii) 傳統的視覺化圖解釋方法存在一些缺陷；iii) Rad4XCNN 沒有犧牲模型準確度來換取其可解釋性；iv) Rad4XCNN 提供了全局解釋見解，使醫師能夠分析模型輸出和發現。此外，我們強調將可解釋性整合到 AI 模型中對於增強臨床實務中的信任和採用至關重要，並強調了我們的方法如何能緩解與可解釋 AI 方法相關的一些疑慮。</paragraph>

##### **Attributing Responsibility in AI-Induced Incidents: A Computational Reflective Equilibrium Framework for Accountability**
2404.16957v1 by Yunfei Ge, Quanyan Zhu

The pervasive integration of Artificial Intelligence (AI) has introduced
complex challenges in the responsibility and accountability in the event of
incidents involving AI-enabled systems. The interconnectivity of these systems,
ethical concerns of AI-induced incidents, coupled with uncertainties in AI
technology and the absence of corresponding regulations, have made traditional
responsibility attribution challenging. To this end, this work proposes a
Computational Reflective Equilibrium (CRE) approach to establish a coherent and
ethically acceptable responsibility attribution framework for all stakeholders.
The computational approach provides a structured analysis that overcomes the
limitations of conceptual approaches in dealing with dynamic and multifaceted
scenarios, showcasing the framework's explainability, coherence, and adaptivity
properties in the responsibility attribution process. We examine the pivotal
role of the initial activation level associated with claims in equilibrium
computation. Using an AI-assisted medical decision-support system as a case
study, we illustrate how different initializations lead to diverse
responsibility distributions. The framework offers valuable insights into
accountability in AI-induced incidents, facilitating the development of a
sustainable and resilient system through continuous monitoring, revision, and
reflection.

摘要：隨著人工智慧 (AI) 的普及整合，在涉及 AI 驅動系統的事故中，責任和義務歸屬產生了複雜的挑戰。這些系統的互連性、AI 引發事故的倫理問題，加上 AI 技術的不確定性和缺乏相應法規，使得傳統責任歸屬面臨挑戰。為此，本研究提出了一種計算反思均衡 (CRE) 方法，以建立一個連貫且在倫理上可接受的責任歸屬架構，適用於所有利害關係人。計算方法提供了結構化的分析，克服了概念方法在處理動態且多面向情境時的限制，展示了該架構在責任歸屬過程中具備的可解釋性、連貫性和適應性。我們探討了與均衡計算中索賠相關的初始啟動層級的關鍵作用。我們以 AI 輔助醫療決策支援系統為案例研究，說明不同的初始化如何導致不同的責任分配。該架構提供了對 AI 引發事故中問責制的寶貴見解，透過持續監控、修訂和反思，促進了永續且有韌性的系統發展。

##### **Explainable AI for Fair Sepsis Mortality Predictive Model**
2404.13139v1 by Chia-Hsuan Chang, Xiaoyang Wang, Christopher C. Yang

Artificial intelligence supports healthcare professionals with predictive
modeling, greatly transforming clinical decision-making. This study addresses
the crucial need for fairness and explainability in AI applications within
healthcare to ensure equitable outcomes across diverse patient demographics. By
focusing on the predictive modeling of sepsis-related mortality, we propose a
method that learns a performance-optimized predictive model and then employs
the transfer learning process to produce a model with better fairness. Our
method also introduces a novel permutation-based feature importance algorithm
aiming at elucidating the contribution of each feature in enhancing fairness on
predictions. Unlike existing explainability methods concentrating on explaining
feature contribution to predictive performance, our proposed method uniquely
bridges the gap in understanding how each feature contributes to fairness. This
advancement is pivotal, given sepsis's significant mortality rate and its role
in one-third of hospital deaths. Our method not only aids in identifying and
mitigating biases within the predictive model but also fosters trust among
healthcare stakeholders by improving the transparency and fairness of model
predictions, thereby contributing to more equitable and trustworthy healthcare
delivery.

摘要：人工智慧透過預測模型協助醫療專業人員，大幅轉變了臨床決策制定。本研究探討了在醫療保健中使用人工智慧應用程式時公平性和可解釋性的關鍵需求，以確保在不同的患者人口統計資料中獲得公平的結果。透過專注於敗血症相關死亡率的預測模型，我們提出了一種方法，該方法會學習一個效能最佳化的預測模型，然後採用轉移學習過程來產生一個具有更好公平性的模型。我們的模型還引入了一種新穎的基於排列的特徵重要性演算法，旨在闡明每個特徵在增強預測公平性方面的貢獻。與現有的可解釋性方法專注於解釋特徵對預測效能的貢獻不同，我們提出的方法獨特地彌補了理解每個特徵如何有助於公平性的差距。這項進展至關重要，因為敗血症的死亡率很高，且在三分之一的醫院死亡中扮演著角色。我們的模型不僅有助於識別和減輕預測模型中的偏差，還能透過提高模型預測的透明度和公平性來培養醫療保健利益相關者之間的信任，進而有助於提供更公平且值得信賴的醫療保健服務。

##### **Multi Class Depression Detection Through Tweets using Artificial Intelligence**
2404.13104v1 by Muhammad Osama Nusrat, Waseem Shahzad, Saad Ahmed Jamal

Depression is a significant issue nowadays. As per the World Health
Organization (WHO), in 2023, over 280 million individuals are grappling with
depression. This is a huge number; if not taken seriously, these numbers will
increase rapidly. About 4.89 billion individuals are social media users. People
express their feelings and emotions on platforms like Twitter, Facebook,
Reddit, Instagram, etc. These platforms contain valuable information which can
be used for research purposes. Considerable research has been conducted across
various social media platforms. However, certain limitations persist in these
endeavors. Particularly, previous studies were only focused on detecting
depression and the intensity of depression in tweets. Also, there existed
inaccuracies in dataset labeling. In this research work, five types of
depression (Bipolar, major, psychotic, atypical, and postpartum) were predicted
using tweets from the Twitter database based on lexicon labeling. Explainable
AI was used to provide reasoning by highlighting the parts of tweets that
represent type of depression. Bidirectional Encoder Representations from
Transformers (BERT) was used for feature extraction and training. Machine
learning and deep learning methodologies were used to train the model. The BERT
model presented the most promising results, achieving an overall accuracy of
0.96.

摘要：現今，憂鬱症是一個重要的議題。根據世界衛生組織 (WHO) 的資料，在 2023 年，超過 2.8 億人正在與憂鬱症搏鬥。這是一個龐大的數字；如果不認真看待，這些數字將會快速增加。大約有 48.9 億人是社群媒體使用者。人們在 Twitter、Facebook、Reddit、Instagram 等平台上表達自己的感受和情緒。這些平台包含有價值的資訊，可用於研究目的。已經在各種社群媒體平台上進行了大量的研究。然而，這些努力仍存在某些限制。特別是，先前的研究僅專注於偵測推文中的憂鬱症和憂鬱症的強度。此外，資料集標籤中存在不準確的情況。在這項研究工作中，使用基於詞彙標籤的 Twitter 資料庫中的推文預測了五種類型的憂鬱症（雙極型、重度、精神病型、非典型和產後）。可解釋的 AI 用於透過強調代表憂鬱症類型的推文部分來提供推理。從 Transformers（BERT）中提取的雙向編碼器表示用於特徵提取和訓練。機器學習和深度學習方法用於訓練模型。BERT 模型呈現出最有希望的結果，達到 0.96 的整體準確度。

##### **COIN: Counterfactual inpainting for weakly supervised semantic segmentation for medical images**
2404.12832v2 by Dmytro Shvetsov, Joonas Ariva, Marharyta Domnich, Raul Vicente, Dmytro Fishman

Deep learning is dramatically transforming the field of medical imaging and
radiology, enabling the identification of pathologies in medical images,
including computed tomography (CT) and X-ray scans. However, the performance of
deep learning models, particularly in segmentation tasks, is often limited by
the need for extensive annotated datasets. To address this challenge, the
capabilities of weakly supervised semantic segmentation are explored through
the lens of Explainable AI and the generation of counterfactual explanations.
The scope of this research is development of a novel counterfactual inpainting
approach (COIN) that flips the predicted classification label from abnormal to
normal by using a generative model. For instance, if the classifier deems an
input medical image X as abnormal, indicating the presence of a pathology, the
generative model aims to inpaint the abnormal region, thus reversing the
classifier's original prediction label. The approach enables us to produce
precise segmentations for pathologies without depending on pre-existing
segmentation masks. Crucially, image-level labels are utilized, which are
substantially easier to acquire than creating detailed segmentation masks. The
effectiveness of the method is demonstrated by segmenting synthetic targets and
actual kidney tumors from CT images acquired from Tartu University Hospital in
Estonia. The findings indicate that COIN greatly surpasses established
attribution methods, such as RISE, ScoreCAM, and LayerCAM, as well as an
alternative counterfactual explanation method introduced by Singla et al. This
evidence suggests that COIN is a promising approach for semantic segmentation
of tumors in CT images, and presents a step forward in making deep learning
applications more accessible and effective in healthcare, where annotated data
is scarce.

摘要：深度学习正大幅轉變醫學影像和放射線學領域，能辨識醫學影像中的病理，包括電腦斷層掃描 (CT) 和 X 光掃描。然而，深度學習模型的效能，特別是在分割任務中，常常受到廣泛註解資料集需求的限制。為了應對此挑戰，透過可解釋 AI 和反事實解釋的產生，探索弱監督語意分割的能力。本研究的範圍是開發一種新的反事實內插方法 (COIN)，該方法使用生成模型將預測的分類標籤從異常翻轉為正常。例如，如果分類器將輸入的醫學影像 X 視為異常，表示存在病理，則生成模型旨在內插異常區域，從而逆轉分類器的原始預測標籤。此方法使我們能夠產生病理的精確分割，而無需依賴於預先存在的分割遮罩。至關重要的是，利用影像層級標籤，這比建立詳細的分割遮罩容易取得。該方法的有效性透過分割合成目標和從愛沙尼亞塔爾圖大學醫院取得的 CT 影像中的實際腎臟腫瘤來證明。研究結果表明，COIN 遠遠超過已建立的歸因方法，例如 RISE、ScoreCAM 和 LayerCAM，以及 Singla 等人提出的另一種反事實解釋方法。此證據表明，COIN 是一種很有前途的 CT 影像中腫瘤語意分割方法，並在醫療保健中讓深度學習應用更易於取得和更有效率邁進一步，其中註解資料很稀少。

##### **Hybrid Intelligence for Digital Humanities**
2406.15374v1 by Victor de Boer, Lise Stork

In this paper, we explore the synergies between Digital Humanities (DH) as a
discipline and Hybrid Intelligence (HI) as a research paradigm. In DH research,
the use of digital methods and specifically that of Artificial Intelligence is
subject to a set of requirements and constraints. We argue that these are
well-supported by the capabilities and goals of HI. Our contribution includes
the identification of five such DH requirements: Successful AI systems need to
be able to 1) collaborate with the (human) scholar; 2) support data criticism;
3) support tool criticism; 4) be aware of and cater to various perspectives and
5) support distant and close reading. We take the CARE principles of Hybrid
Intelligence (collaborative, adaptive, responsible and explainable) as
theoretical framework and map these to the DH requirements. In this mapping, we
include example research projects. We finally address how insights from DH can
be applied to HI and discuss open challenges for the combination of the two
disciplines.

摘要：在本文中，我們探討數位人文學科 (DH) 作為一門學科與混合智能 (HI) 作為一個研究典範之間的協同作用。在 DH 研究中，數位方法的使用，特別是人工智慧的使用，受到一系列要求和限制。我們認為這些要求和限制獲得 HI 的能力和目標的充分支持。我們的貢獻包括找出五個這樣的 DH 要求：成功的 AI 系統需要能夠 1) 與（人類）學者合作；2) 支援資料批評；3) 支援工具批評；4) 察覺並迎合各種觀點；5) 支援遠距和近距離閱讀。我們將混合智能的 CARE 原則（協作、適應、負責和可解釋）作為理論架構，並將這些原則對應到 DH 要求。在此對應中，我們納入範例研究專案。最後，我們探討如何將 DH 的見解應用於 HI，並討論結合這兩個學科的開放挑戰。

##### **Ethical Framework for Responsible Foundational Models in Medical Imaging**
2406.11868v1 by Abhijit Das, Debesh Jha, Jasmer Sanjotra, Onkar Susladkar, Suramyaa Sarkar, Ashish Rauniyar, Nikhil Tomar, Vanshali Sharma, Ulas Bagci

Foundational models (FMs) have tremendous potential to revolutionize medical
imaging. However, their deployment in real-world clinical settings demands
extensive ethical considerations. This paper aims to highlight the ethical
concerns related to FMs and propose a framework to guide their responsible
development and implementation within medicine. We meticulously examine ethical
issues such as privacy of patient data, bias mitigation, algorithmic
transparency, explainability and accountability. The proposed framework is
designed to prioritize patient welfare, mitigate potential risks, and foster
trust in AI-assisted healthcare.

摘要：基礎模型 (FM) 具有徹底改變醫學影像的巨大潛力。然而，它們在現實世界臨床環境中的部署需要廣泛的倫理考量。本文旨在強調與 FM 相關的倫理問題，並提出一個框架來指導它們在醫學中的負責任開發和實施。我們仔細審查了倫理問題，例如患者數據隱私、偏差緩解、演算法透明度、可解釋性和問責制。所提出的框架旨在優先考慮患者福利、減輕潛在風險，並培養對 AI 輔助醫療保健的信任。

##### **Advancements in Radiomics and Artificial Intelligence for Thyroid Cancer Diagnosis**
2404.07239v1 by Milad Yousefi, Shadi Farabi Maleki, Ali Jafarizadeh, Mahya Ahmadpour Youshanlui, Aida Jafari, Siamak Pedrammehr, Roohallah Alizadehsani, Ryszard Tadeusiewicz, Pawel Plawiak

Thyroid cancer is an increasing global health concern that requires advanced
diagnostic methods. The application of AI and radiomics to thyroid cancer
diagnosis is examined in this review. A review of multiple databases was
conducted in compliance with PRISMA guidelines until October 2023. A
combination of keywords led to the discovery of an English academic publication
on thyroid cancer and related subjects. 267 papers were returned from the
original search after 109 duplicates were removed. Relevant studies were
selected according to predetermined criteria after 124 articles were eliminated
based on an examination of their abstract and title. After the comprehensive
analysis, an additional six studies were excluded. Among the 28 included
studies, radiomics analysis, which incorporates ultrasound (US) images,
demonstrated its effectiveness in diagnosing thyroid cancer. Various results
were noted, some of the studies presenting new strategies that outperformed the
status quo. The literature has emphasized various challenges faced by AI
models, including interpretability issues, dataset constraints, and operator
dependence. The synthesized findings of the 28 included studies mentioned the
need for standardization efforts and prospective multicenter studies to address
these concerns. Furthermore, approaches to overcome these obstacles were
identified, such as advances in explainable AI technology and personalized
medicine techniques. The review focuses on how AI and radiomics could transform
the diagnosis and treatment of thyroid cancer. Despite challenges, future
research on multidisciplinary cooperation, clinical applicability validation,
and algorithm improvement holds the potential to improve patient outcomes and
diagnostic precision in the treatment of thyroid cancer.

摘要：甲狀腺癌是一種日益嚴重的全球健康問題，需要先進的診斷方法。本篇評論探討了人工智能與放射特徵分析在甲狀腺癌診斷中的應用。在符合 PRISMA 指南的情況下，對多個資料庫進行了回顧，直到 2023 年 10 月。通過結合關鍵字，發現了一篇關於甲狀腺癌和相關主題的英文學術出版物。在移除 109 篇重複文獻後，原始搜尋共回傳 267 篇論文。在根據預先確定的標準，淘汰了 124 篇文章的摘要和標題後，選出了相關研究。在進行全面分析後，額外排除了六項研究。在納入的 28 項研究中，結合超音波 (US) 影像的放射特徵分析，證明了其在診斷甲狀腺癌方面的有效性。研究結果不一，有些研究提出了優於現狀的新策略。文獻強調了人工智能模型面臨的各種挑戰，包括可解釋性問題、資料集限制和操作員依賴性。28 項納入研究的綜合發現提到，需要標準化工作和前瞻性多中心研究來解決這些問題。此外，還確定了克服這些障礙的方法，例如可解釋人工智能技術和個人化醫療技術的進步。本篇評論重點探討了人工智能和放射特徵分析如何轉變甲狀腺癌的診斷和治療。儘管存在挑戰，但未來對多學科合作、臨床適用性驗證和演算法改進的研究，仍有潛力改善甲狀腺癌治療中的患者預後和診斷精準度。

##### **Predictive Modeling for Breast Cancer Classification in the Context of Bangladeshi Patients: A Supervised Machine Learning Approach with Explainable AI**
2404.04686v1 by Taminul Islam, Md. Alif Sheakh, Mst. Sazia Tahosin, Most. Hasna Hena, Shopnil Akash, Yousef A. Bin Jardan, Gezahign Fentahun Wondmie, Hiba-Allah Nafidi, Mohammed Bourhia

Breast cancer has rapidly increased in prevalence in recent years, making it
one of the leading causes of mortality worldwide. Among all cancers, it is by
far the most common. Diagnosing this illness manually requires significant time
and expertise. Since detecting breast cancer is a time-consuming process,
preventing its further spread can be aided by creating machine-based forecasts.
Machine learning and Explainable AI are crucial in classification as they not
only provide accurate predictions but also offer insights into how the model
arrives at its decisions, aiding in the understanding and trustworthiness of
the classification results. In this study, we evaluate and compare the
classification accuracy, precision, recall, and F-1 scores of five different
machine learning methods using a primary dataset (500 patients from Dhaka
Medical College Hospital). Five different supervised machine learning
techniques, including decision tree, random forest, logistic regression, naive
bayes, and XGBoost, have been used to achieve optimal results on our dataset.
Additionally, this study applied SHAP analysis to the XGBoost model to
interpret the model's predictions and understand the impact of each feature on
the model's output. We compared the accuracy with which several algorithms
classified the data, as well as contrasted with other literature in this field.
After final evaluation, this study found that XGBoost achieved the best model
accuracy, which is 97%.

摘要：<paragraph>近年來，乳癌的盛行率迅速增加，使其成為全球主要的死亡原因之一。在所有癌症中，乳癌迄今為止是最常見的。手動診斷此疾病需要大量的時間和專業知識。由於乳癌的檢測過程耗時，因此透過建立機器學習模型來預測，有助於防止其進一步擴散。機器學習和可解釋 AI 在分類中至關重要，因為它們不僅可以提供準確的預測，還可以深入了解模型如何做出決策，有助於理解和信賴分類結果。在此研究中，我們評估並比較了五種不同的機器學習方法的分類準確度、精確度、召回率和 F1 分數，使用了一個主要的資料集（達卡醫學院醫院的 500 名患者）。五種不同的監督式機器學習技術，包括決策樹、隨機森林、邏輯迴歸、朴素貝氏和 XGBoost，已用於在我們的資料集上取得最佳結果。此外，本研究將 SHAP 分析應用於 XGBoost 模型，以解釋模型的預測並了解每個特徵對模型輸出的影響。我們比較了幾種演算法對資料進行分類的準確度，並與該領域的其他文獻進行對比。在最後評估後，本研究發現 XGBoost 達到了最佳的模型準確度，為 97%。</paragraph>

##### **Enhancing Breast Cancer Diagnosis in Mammography: Evaluation and Integration of Convolutional Neural Networks and Explainable AI**
2404.03892v3 by Maryam Ahmed, Tooba Bibi, Rizwan Ahmed Khan, Sidra Nasir

The Deep learning (DL) models for diagnosing breast cancer from mammographic
images often operate as "black boxes", making it difficult for healthcare
professionals to trust and understand their decision-making processes. The
study presents an integrated framework combining Convolutional Neural Networks
(CNNs) and Explainable Artificial Intelligence (XAI) for the enhanced diagnosis
of breast cancer using the CBIS-DDSM dataset. The methodology encompasses an
elaborate data preprocessing pipeline and advanced data augmentation techniques
to counteract dataset limitations and transfer learning using pre-trained
networks such as VGG-16, Inception-V3 and ResNet was employed. A focal point of
our study is the evaluation of XAI's effectiveness in interpreting model
predictions, highlighted by utilizing the Hausdorff measure to assess the
alignment between AI-generated explanations and expert annotations
quantitatively. This approach is critical for XAI in promoting trustworthiness
and ethical fairness in AI-assisted diagnostics. The findings from our research
illustrate the effective collaboration between CNNs and XAI in advancing
diagnostic methods for breast cancer, thereby facilitating a more seamless
integration of advanced AI technologies within clinical settings. By enhancing
the interpretability of AI driven decisions, this work lays the groundwork for
improved collaboration between AI systems and medical practitioners, ultimately
enriching patient care. Furthermore, the implications of our research extended
well beyond the current methodologies. It encourages further research into how
to combine multimodal data and improve AI explanations to meet the needs of
clinical practice.

摘要：深度學習 (DL) 用於從乳房攝影術影像診斷乳癌的模型通常以「黑盒子」方式運作，這使得醫療保健專業人員難以信任和理解其決策過程。本研究提出一個整合架構，結合卷積神經網路 (CNN) 和可解釋人工智慧 (XAI)，以使用 CBIS-DDSM 資料集增強乳癌的診斷。方法包含一個精細的資料前處理管線和進階資料擴充技術，以對抗資料集限制，並採用預先訓練的網路（例如 VGG-16、Inception-V3 和 ResNet）進行遷移學習。我們研究的重點是評估 XAI 在解釋模型預測中的有效性，重點利用豪斯多夫測度量化評估 AI 生成的解釋和專家註解之間的一致性。這種方法對於 XAI 在促進 AI 輔助診斷中的可信度和倫理公平性至關重要。我們研究的發現說明了 CNN 和 XAI 在推進乳癌診斷方法中的有效協作，從而促進了先進 AI 技術在臨床環境中的更順暢整合。透過增強 AI 驅動決策的可解釋性，這項工作為 AI 系統和醫療從業人員之間的改善協作奠定了基礎，最終豐富了患者照護。此外，我們研究的影響遠遠超出了目前的技術。它鼓勵進一步研究如何結合多模式資料並改善 AI 解釋，以滿足臨床實務的需求。

##### **Advancing Multimodal Data Fusion in Pain Recognition: A Strategy Leveraging Statistical Correlation and Human-Centered Perspectives**
2404.00320v2 by Xingrui Gu, Zhixuan Wang, Irisa Jin, Zekun Wu

This research presents a novel multimodal data fusion methodology for pain
behavior recognition, integrating statistical correlation analysis with
human-centered insights. Our approach introduces two key innovations: 1)
integrating data-driven statistical relevance weights into the fusion strategy
to effectively utilize complementary information from heterogeneous modalities,
and 2) incorporating human-centric movement characteristics into multimodal
representation learning for detailed modeling of pain behaviors. Validated
across various deep learning architectures, our method demonstrates superior
performance and broad applicability. We propose a customizable framework that
aligns each modality with a suitable classifier based on statistical
significance, advancing personalized and effective multimodal fusion.
Furthermore, our methodology provides explainable analysis of multimodal data,
contributing to interpretable and explainable AI in healthcare. By highlighting
the importance of data diversity and modality-specific representations, we
enhance traditional fusion techniques and set new standards for recognizing
complex pain behaviors. Our findings have significant implications for
promoting patient-centered healthcare interventions and supporting explainable
clinical decision-making.

摘要：本研究提出了一種創新的多模態數據融合方法，用於疼痛行為識別，將統計相關分析與以人為中心的見解相結合。我們的做法引入了兩項關鍵創新：1) 將數據驅動的統計相關權重整合到融合策略中，以有效利用來自異質模態的補充信息，以及 2) 將以人為中心的運動特徵納入多模態表示學習中，以詳細建模疼痛行為。我們的模型在各種深度學習架構中得到驗證，展示了卓越的性能和廣泛的適用性。我們提出了一個可自定義的框架，根據統計顯著性將每個模態與合適的分類器對齊，推進個性化和有效的多模態融合。此外，我們的模型提供對多模態數據的可解釋分析，有助於醫療保健中的可解釋和可解釋 AI。通過強調數據多樣性和模態特定表示的重要性，我們增強了傳統的融合技術，並為識別複雜的疼痛行為設定了新的標準。我們的發現對促進以患者為中心的醫療保健干預和支持可解釋的臨床決策制定具有重要意義。

##### **Addressing Social Misattributions of Large Language Models: An HCXAI-based Approach**
2403.17873v1 by Andrea Ferrario, Alberto Termine, Alessandro Facchini

Human-centered explainable AI (HCXAI) advocates for the integration of social
aspects into AI explanations. Central to the HCXAI discourse is the Social
Transparency (ST) framework, which aims to make the socio-organizational
context of AI systems accessible to their users. In this work, we suggest
extending the ST framework to address the risks of social misattributions in
Large Language Models (LLMs), particularly in sensitive areas like mental
health. In fact LLMs, which are remarkably capable of simulating roles and
personas, may lead to mismatches between designers' intentions and users'
perceptions of social attributes, risking to promote emotional manipulation and
dangerous behaviors, cases of epistemic injustice, and unwarranted trust. To
address these issues, we propose enhancing the ST framework with a fifth
'W-question' to clarify the specific social attributions assigned to LLMs by
its designers and users. This addition aims to bridge the gap between LLM
capabilities and user perceptions, promoting the ethically responsible
development and use of LLM-based technology.

摘要：以人为本的可解释 AI (HCXAI) 倡导将社会层面整合到 AI 解释中。HCXAI 话语的核心是社会透明度 (ST) 框架，其目标是让 AI 系统的社会组织背景对用户来说是可理解的。在这项工作中，我们建议扩展 ST 框架以解决大型语言模型 (LLM) 中社会错误归因的风险，尤其是在心理健康等敏感领域。事实上，LLM 能够出色地模拟角色和人格，这可能导致设计者的意图和用户对社会属性的认知之间出现错配，从而有风险促进情绪操纵和危险行为、认知不公正和不合理的信任。为了解决这些问题，我们建议用第五个“W 问题”来增强 ST 框架，以明确设计者和用户赋予 LLM 的具体社会属性。此补充旨在弥合 LLM 能力和用户认知之间的差距，促进基于 LLM 的技术在道德上负责任地开发和使用。

##### **Clinical Domain Knowledge-Derived Template Improves Post Hoc AI Explanations in Pneumothorax Classification**
2403.18871v1 by Han Yuan, Chuan Hong, Pengtao Jiang, Gangming Zhao, Nguyen Tuan Anh Tran, Xinxing Xu, Yet Yen Yan, Nan Liu

Background: Pneumothorax is an acute thoracic disease caused by abnormal air
collection between the lungs and chest wall. To address the opaqueness often
associated with deep learning (DL) models, explainable artificial intelligence
(XAI) methods have been introduced to outline regions related to pneumothorax
diagnoses made by DL models. However, these explanations sometimes diverge from
actual lesion areas, highlighting the need for further improvement. Method: We
propose a template-guided approach to incorporate the clinical knowledge of
pneumothorax into model explanations generated by XAI methods, thereby
enhancing the quality of these explanations. Utilizing one lesion delineation
created by radiologists, our approach first generates a template that
represents potential areas of pneumothorax occurrence. This template is then
superimposed on model explanations to filter out extraneous explanations that
fall outside the template's boundaries. To validate its efficacy, we carried
out a comparative analysis of three XAI methods with and without our template
guidance when explaining two DL models in two real-world datasets. Results: The
proposed approach consistently improved baseline XAI methods across twelve
benchmark scenarios built on three XAI methods, two DL models, and two
datasets. The average incremental percentages, calculated by the performance
improvements over the baseline performance, were 97.8% in Intersection over
Union (IoU) and 94.1% in Dice Similarity Coefficient (DSC) when comparing model
explanations and ground-truth lesion areas. Conclusions: In the context of
pneumothorax diagnoses, we proposed a template-guided approach for improving AI
explanations. We anticipate that our template guidance will forge a fresh
approach to elucidating AI models by integrating clinical domain expertise.

摘要：<paragraph>背景：氣胸是一種因肺部與胸壁之間異常集氣所引起的急性胸腔疾病。為了解決深度學習（DL）模型經常伴隨的不透明性，可解釋人工智慧（XAI）方法已被引入，用於概述與 DL 模型做出的氣胸診斷相關的區域。然而，這些解釋有時會與實際病灶區域有所出入，突顯出進一步改進的必要性。方法：我們提出了一種模板引導式方法，將氣胸的臨床知識納入 XAI 方法產生的模型解釋中，從而提升這些解釋的品質。利用放射科醫師建立的病灶描繪，我們的做法首先產生一個模板，用於表示氣胸可能發生的區域。然後將此模板疊加在模型解釋上，以篩選出超出模板邊界的無關解釋。為了驗證其效力，我們對三種 XAI 方法進行了比較分析，在兩個真實世界資料集中解釋兩個 DL 模型時，分別採用和不採用我們的模板引導。結果：所提出的方法在建立於三種 XAI 方法、兩個 DL 模型和兩個資料集的十二種基準情境中，始終改善了基準 XAI 方法。在比較模型解釋和真實病灶區域時，透過基準效能的效能改進計算出的平均增量百分比為交集比（IoU）的 97.8% 和骰子相似性係數（DSC）的 94.1%。結論：在氣胸診斷的背景下，我們提出了一種模板引導式方法，用於改善 AI 解釋。我們預期我們的模板引導將透過整合臨床領域專業知識，為闡明 AI 模型建立一種新方法。</paragraph>

##### **Enhancing Neural Machine Translation of Low-Resource Languages: Corpus Development, Human Evaluation and Explainable AI Architectures**
2403.01580v1 by Séamus Lankford

In the current machine translation (MT) landscape, the Transformer
architecture stands out as the gold standard, especially for high-resource
language pairs. This research delves into its efficacy for low-resource
language pairs including both the English$\leftrightarrow$Irish and
English$\leftrightarrow$Marathi language pairs. Notably, the study identifies
the optimal hyperparameters and subword model type to significantly improve the
translation quality of Transformer models for low-resource language pairs.
  The scarcity of parallel datasets for low-resource languages can hinder MT
development. To address this, gaHealth was developed, the first bilingual
corpus of health data for the Irish language. Focusing on the health domain,
models developed using this in-domain dataset exhibited very significant
improvements in BLEU score when compared with models from the LoResMT2021
Shared Task. A subsequent human evaluation using the multidimensional quality
metrics error taxonomy showcased the superior performance of the Transformer
system in reducing both accuracy and fluency errors compared to an RNN-based
counterpart.
  Furthermore, this thesis introduces adaptNMT and adaptMLLM, two open-source
applications streamlined for the development, fine-tuning, and deployment of
neural machine translation models. These tools considerably simplify the setup
and evaluation process, making MT more accessible to both developers and
translators. Notably, adaptNMT, grounded in the OpenNMT ecosystem, promotes
eco-friendly natural language processing research by highlighting the
environmental footprint of model development. Fine-tuning of MLLMs by adaptMLLM
demonstrated advancements in translation performance for two low-resource
language pairs: English$\leftrightarrow$Irish and
English$\leftrightarrow$Marathi, compared to baselines from the LoResMT2021
Shared Task.

摘要：<paragraph>在當前機器翻譯 (MT) 領域中，Transformer 架構脫穎而出，成為黃金標準，特別是對於高資源語言對。本研究探討其對低資源語言對的效能，包括英語↔愛爾蘭語和英語↔馬拉地語語言對。值得注意的是，本研究識別出最佳超參數和子詞模型類型，以顯著提高 Transformer 模型對低資源語言對的翻譯品質。
低資源語言的平行資料集的稀缺會阻礙 MT 的發展。為了解決這個問題，開發了 gaHealth，這是愛爾蘭語的第一個雙語健康資料語料庫。專注於健康領域，使用此域內資料集開發的模型在 BLEU 得分方面表現出非常顯著的進步，與 LoResMT2021 共享任務中的模型相比。隨後使用多維品質指標錯誤分類法進行的人工評估顯示，與基於 RNN 的對應模型相比，Transformer 系統在減少準確性和流暢性錯誤方面表現出優異的性能。
此外，本論文介紹了 adaptNMT 和 adaptMLLM，這兩個開源應用程式簡化了神經機器翻譯模型的開發、微調和部署。這些工具大幅簡化了設定和評估流程，讓 MT 更容易讓開發人員和翻譯人員使用。值得注意的是，adaptNMT 以 OpenNMT 生態系統為基礎，通過強調模型開發的環境足跡來促進生態友好的自然語言處理研究。與 LoResMT2021 共享任務中的基準相比，adaptMLLM 對 MLLM 的微調證明了英語↔愛爾蘭語和英語↔馬拉地語這兩個低資源語言對的翻譯性能進步。</paragraph>

##### **Artificial Intelligence and Diabetes Mellitus: An Inside Look Through the Retina**
2402.18600v1 by Yasin Sadeghi Bazargani, Majid Mirzaei, Navid Sobhi, Mirsaeed Abdollahi, Ali Jafarizadeh, Siamak Pedrammehr, Roohallah Alizadehsani, Ru San Tan, Sheikh Mohammed Shariful Islam, U. Rajendra Acharya

Diabetes mellitus (DM) predisposes patients to vascular complications.
Retinal images and vasculature reflect the body's micro- and macrovascular
health. They can be used to diagnose DM complications, including diabetic
retinopathy (DR), neuropathy, nephropathy, and atherosclerotic cardiovascular
disease, as well as forecast the risk of cardiovascular events. Artificial
intelligence (AI)-enabled systems developed for high-throughput detection of DR
using digitized retinal images have become clinically adopted. Beyond DR
screening, AI integration also holds immense potential to address challenges
associated with the holistic care of the patient with DM. In this work, we aim
to comprehensively review the literature for studies on AI applications based
on retinal images related to DM diagnosis, prognostication, and management. We
will describe the findings of holistic AI-assisted diabetes care, including but
not limited to DR screening, and discuss barriers to implementing such systems,
including issues concerning ethics, data privacy, equitable access, and
explainability. With the ability to evaluate the patient's health status vis a
vis DM complication as well as risk prognostication of future cardiovascular
complications, AI-assisted retinal image analysis has the potential to become a
central tool for modern personalized medicine in patients with DM.

摘要：糖尿病（DM）使患者容易出現血管併發症。
視網膜影像和血管反映身體的微血管和巨血管健康狀況。它們可用於診斷糖尿病併發症，包括糖尿病視網膜病變（DR）、神經病變、腎病和動脈粥樣硬化性心血管疾病，以及預測心血管事件的風險。為使用數位化視網膜影像進行高通量 DR 檢測而開發的人工智慧（AI）啟用系統已在臨床採用。除了 DR 篩檢外，AI 整合也具有巨大的潛力來應對與糖尿病患者整體照護相關的挑戰。在這項工作中，我們旨在全面回顧基於視網膜影像的 AI 應用相關研究的文獻，這些研究與糖尿病的診斷、預後和管理有關。我們將描述整體 AI 輔助糖尿病照護的發現，包括但不限於 DR 篩檢，並討論實施此類系統的障礙，包括與倫理、資料隱私、公平存取和可解釋性有關的問題。透過評估患者的健康狀況，同時考量糖尿病併發症以及未來心血管併發症的風險預後，AI 輔助視網膜影像分析有潛力成為糖尿病患者現代化個人化醫療的中心工具。

##### **Multi-stakeholder Perspective on Responsible Artificial Intelligence and Acceptability in Education**
2402.15027v2 by A. J. Karran, P. Charland, J-T. Martineau, A. Ortiz de Guinea Lopez de Arana, AM. Lesage, S. Senecal, P-M. Leger

This study investigates the acceptability of different artificial
intelligence (AI) applications in education from a multi-stakeholder
perspective, including students, teachers, and parents. Acknowledging the
transformative potential of AI in education, it addresses concerns related to
data privacy, AI agency, transparency, explainability and the ethical
deployment of AI. Through a vignette methodology, participants were presented
with four scenarios where AI's agency, transparency, explainability, and
privacy were manipulated. After each scenario, participants completed a survey
that captured their perceptions of AI's global utility, individual usefulness,
justice, confidence, risk, and intention to use each scenario's AI if
available. The data collection comprising a final sample of 1198
multi-stakeholder participants was distributed through a partner institution
and social media campaigns and focused on individual responses to four AI use
cases. A mediation analysis of the data indicated that acceptance and trust in
AI varies significantly across stakeholder groups. We found that the key
mediators between high and low levels of AI's agency, transparency, and
explainability, as well as the intention to use the different educational AI,
included perceived global utility, justice, and confidence. The study
highlights that the acceptance of AI in education is a nuanced and multifaceted
issue that requires careful consideration of specific AI applications and their
characteristics, in addition to the diverse stakeholders' perceptions.

摘要：這項研究從多個利害關係人的角度探討不同的人工智慧 (AI) 應用在教育上的可接受性，包括學生、老師和家長。承認 AI 在教育上的轉型潛力，它解決了與資料隱私、AI 代理、透明度、可解釋性和 AI 的道德部署相關的疑慮。透過小插曲方法，參與者被呈現了四種情境，其中 AI 的代理、透明度、可解釋性和隱私受到操縱。在每個情境後，參與者完成了一項調查，該調查捕捉了他們對 AI 的整體效用、個人效用、正義、信心、風險和如果可用，使用每個情境的 AI 的意圖的看法。資料蒐集包含來自合作機構和社群媒體活動的 1198 位多利害關係人參與者的最終樣本，並專注於對四個 AI 使用案例的個別回應。對資料的調解分析表明，對 AI 的接受度和信任在利害關係人團體之間有顯著差異。我們發現，AI 的代理、透明度和可解釋性高低程度之間的關鍵調解者，以及使用不同教育 AI 的意圖，包括感知到的整體效用、正義和信心。這項研究強調，接受 AI 在教育上的應用是一個微妙且多面向的問題，除了不同的利害關係人的看法外，還需要仔細考慮具體的 AI 應用及其特徵。

##### **Deciphering Heartbeat Signatures: A Vision Transformer Approach to Explainable Atrial Fibrillation Detection from ECG Signals**
2402.09474v2 by Aruna Mohan, Danne Elbers, Or Zilbershot, Fatemeh Afghah, David Vorchheimer

Remote patient monitoring based on wearable single-lead electrocardiogram
(ECG) devices has significant potential for enabling the early detection of
heart disease, especially in combination with artificial intelligence (AI)
approaches for automated heart disease detection. There have been prior studies
applying AI approaches based on deep learning for heart disease detection.
However, these models are yet to be widely accepted as a reliable aid for
clinical diagnostics, in part due to the current black-box perception
surrounding many AI algorithms. In particular, there is a need to identify the
key features of the ECG signal that contribute toward making an accurate
diagnosis, thereby enhancing the interpretability of the model. In the present
study, we develop a vision transformer approach to identify atrial fibrillation
based on single-lead ECG data. A residual network (ResNet) approach is also
developed for comparison with the vision transformer approach. These models are
applied to the Chapman-Shaoxing dataset to classify atrial fibrillation, as
well as another common arrhythmia, sinus bradycardia, and normal sinus rhythm
heartbeats. The models enable the identification of the key regions of the
heartbeat that determine the resulting classification, and highlight the
importance of P-waves and T-waves, as well as heartbeat duration and signal
amplitude, in distinguishing normal sinus rhythm from atrial fibrillation and
sinus bradycardia.

摘要：<paragraph>基於可穿戴式單導程心電圖 (ECG) 裝置的遠端病患監測在早期偵測心臟疾病方面具有顯著的潛力，特別是與用於自動化心臟疾病偵測的人工智慧 (AI) 方法結合使用時。先前已有研究應用基於深度學習的 AI 方法進行心臟疾病偵測。然而，這些模型尚未被廣泛接受為臨床診斷的可靠輔助工具，部分原因在於圍繞許多 AI 演算法的當前黑箱感知。特別是，有必要找出有助於做出準確診斷的 ECG 訊號關鍵特徵，從而增強模型的可解釋性。在本研究中，我們開發了一種視覺轉換器方法，以根據單導程 ECG 資料找出心房顫動。殘差網路 (ResNet) 方法也已開發出來，以便與視覺轉換器方法進行比較。這些模型應用於 Chapman-Shaoxing 資料集，以分類心房顫動，以及另一種常見的心律不整，竇性心動過緩，和正常竇性心律的心跳。這些模型能夠找出決定最終分類的心跳關鍵區域，並強調 P 波和 T 波，以及心跳持續時間和訊號振幅在區分正常竇性心律與心房顫動和竇性心動過緩方面的重要性。</paragraph>

##### **Illuminate: A novel approach for depression detection with explainable analysis and proactive therapy using prompt engineering**
2402.05127v1 by Aryan Agrawal

This paper introduces a novel paradigm for depression detection and treatment
using advanced Large Language Models (LLMs): Generative Pre-trained Transformer
4 (GPT-4), Llama 2 chat, and Gemini. These LLMs are fine-tuned with specialized
prompts to diagnose, explain, and suggest therapeutic interventions for
depression. A unique few-shot prompting method enhances the models' ability to
analyze and explain depressive symptoms based on the DSM-5 criteria. In the
interaction phase, the models engage in empathetic dialogue management, drawing
from resources like PsychDB and a Cognitive Behavioral Therapy (CBT) Guide,
fostering supportive interactions with individuals experiencing major
depressive disorders. Additionally, the research introduces the Illuminate
Database, enriched with various CBT modules, aiding in personalized therapy
recommendations. The study evaluates LLM performance using metrics such as F1
scores, Precision, Recall, Cosine similarity, and Recall-Oriented Understudy
for Gisting Evaluation (ROUGE) across different test sets, demonstrating their
effectiveness. This comprehensive approach blends cutting-edge AI with
established psychological methods, offering new possibilities in mental health
care and showcasing the potential of LLMs in revolutionizing depression
diagnosis and treatment strategies.

摘要：本文介紹了一種使用先進大型語言模型 (LLM) 進行憂鬱症偵測和治療的新模式：生成式預訓練Transformer 4 (GPT-4)、Llama 2 聊天機器人和 Gemini。這些 LLM 經過微調，具備專業提示，可診斷、解釋並建議憂鬱症的治療介入方法。一種獨特的少次提示方法增強了模型根據 DSM-5 標準分析和解釋憂鬱症狀的能力。在互動階段，這些模型會參與同理心對話管理，從 PsychDB 和認知行為療法 (CBT) 指南等資源中汲取，促進與經歷重度憂鬱症的人們的支持性互動。此外，這項研究還介紹了 Illuminate 資料庫，其中包含各種 CBT 模組，有助於個性化治療建議。這項研究使用 F1 分數、準確率、召回率、餘弦相似度和面向召回率的 Gisting 評估替身 (ROUGE) 等指標，在不同的測試集中評估 LLM 的表現，證明了它們的有效性。這種綜合方法結合了尖端的 AI 與既定的心理方法，為心理保健提供了新的可能性，並展示了 LLM 在革新憂鬱症診斷和治療策略方面的潛力。

##### **Information That Matters: Exploring Information Needs of People Affected by Algorithmic Decisions**
2401.13324v5 by Timothée Schmude, Laura Koesten, Torsten Möller, Sebastian Tschiatschek

Every AI system that makes decisions about people has a group of stakeholders
that are personally affected by these decisions. However, explanations of AI
systems rarely address the information needs of this stakeholder group, who
often are AI novices. This creates a gap between conveyed information and
information that matters to those who are impacted by the system's decisions,
such as domain experts and decision subjects. To address this, we present the
"XAI Novice Question Bank," an extension of the XAI Question Bank containing a
catalog of information needs from AI novices in two use cases: employment
prediction and health monitoring. The catalog covers the categories of data,
system context, system usage, and system specifications. We gathered
information needs through task-based interviews where participants asked
questions about two AI systems to decide on their adoption and received verbal
explanations in response. Our analysis showed that participants' confidence
increased after receiving explanations but that their understanding faced
challenges. These included difficulties in locating information and in
assessing their own understanding, as well as attempts to outsource
understanding. Additionally, participants' prior perceptions of the systems'
risks and benefits influenced their information needs. Participants who
perceived high risks sought explanations about the intentions behind a system's
deployment, while those who perceived low risks rather asked about the system's
operation. Our work aims to support the inclusion of AI novices in
explainability efforts by highlighting their information needs, aims, and
challenges. We summarize our findings as five key implications that can inform
the design of future explanations for lay stakeholder audiences.

摘要：<paragraph>每個對人進行決策的 AI 系統都有一群個人受到這些決策影響的利益關係人。然而，AI 系統的說明很少針對這群利益關係人的資訊需求，他們通常是 AI 新手。這在傳達的資訊和對受系統決策影響的人來說重要的資訊之間，造成了一道鴻溝，例如領域專家和決策主體。為了解決這個問題，我們提出了「XAI 新手問題庫」，這是 XAI 問題庫的延伸，包含來自兩個使用案例中 AI 新手的資訊需求目錄：就業預測和健康監控。目錄涵蓋了資料、系統背景、系統使用和系統規格等類別。我們透過任務型訪談收集資訊需求，參與者在其中詢問了兩個 AI 系統的問題，以決定採用與否，並收到口頭說明作為回應。我們的分析顯示，參與者在收到說明後，信心有所提升，但他們的理解面臨挑戰。這些挑戰包括難以找到資訊和評估自己的理解，以及試圖外包理解。此外，參與者對系統風險和好處的先前認知影響了他們的資訊需求。認為風險高的人尋求有關系統部署背後意圖的說明，而認為風險低的人則詢問系統的運作。我們的研究旨在透過強調他們的資訊需求、目標和挑戰，來支持將 AI 新手納入可解釋性工作。我們將我們的研究結果總結為五個關鍵影響，這些影響可以為未來針對非專業利益相關者受眾的說明設計提供參考。</paragraph>

##### **Evaluating Large Language Models on the GMAT: Implications for the Future of Business Education**
2401.02985v1 by Vahid Ashrafimoghari, Necdet Gürkan, Jordan W. Suchow

The rapid evolution of artificial intelligence (AI), especially in the domain
of Large Language Models (LLMs) and generative AI, has opened new avenues for
application across various fields, yet its role in business education remains
underexplored. This study introduces the first benchmark to assess the
performance of seven major LLMs, OpenAI's models (GPT-3.5 Turbo, GPT-4, and
GPT-4 Turbo), Google's models (PaLM 2, Gemini 1.0 Pro), and Anthropic's models
(Claude 2 and Claude 2.1), on the GMAT, which is a key exam in the admission
process for graduate business programs. Our analysis shows that most LLMs
outperform human candidates, with GPT-4 Turbo not only outperforming the other
models but also surpassing the average scores of graduate students at top
business schools. Through a case study, this research examines GPT-4 Turbo's
ability to explain answers, evaluate responses, identify errors, tailor
instructions, and generate alternative scenarios. The latest LLM versions,
GPT-4 Turbo, Claude 2.1, and Gemini 1.0 Pro, show marked improvements in
reasoning tasks compared to their predecessors, underscoring their potential
for complex problem-solving. While AI's promise in education, assessment, and
tutoring is clear, challenges remain. Our study not only sheds light on LLMs'
academic potential but also emphasizes the need for careful development and
application of AI in education. As AI technology advances, it is imperative to
establish frameworks and protocols for AI interaction, verify the accuracy of
AI-generated content, ensure worldwide access for diverse learners, and create
an educational environment where AI supports human expertise. This research
sets the stage for further exploration into the responsible use of AI to enrich
educational experiences and improve exam preparation and assessment methods.

摘要：人工智慧 (AI) 的快速演進，尤其是在大型語言模型 (LLM) 和生成式 AI 的領域，為各個領域的應用開啟了新途徑，但其在商業教育中的角色仍未被充分探討。本研究首次引入了基準，用以評估七個主要 LLM 的效能，包括 OpenAI 的模型 (GPT-3.5 Turbo、GPT-4 和 GPT-4 Turbo)、Google 的模型 (PaLM 2、Gemini 1.0 Pro) 和 Anthropic 的模型 (Claude 2 和 Claude 2.1)，這些模型將用於研究生商業課程入學程序中的關鍵考試 GMAT。我們的分析顯示，大多數 LLM 的表現都優於人類考生，其中 GPT-4 Turbo 不僅優於其他模型，更超越了頂尖商學院的研究生平均分數。透過案例研究，本研究探討了 GPT-4 Turbo 在解釋答案、評估回應、辨識錯誤、調整說明和產生替代情境方面的能力。與前一代版本相比，最新的 LLM 版本 GPT-4 Turbo、Claude 2.1 和 Gemini 1.0 Pro 在推理任務方面有顯著的進步，凸顯了其在解決複雜問題方面的潛力。儘管 AI 在教育、評量和輔導方面的承諾很明確，但仍有挑戰存在。我們的研究不僅闡明了 LLM 的學術潛力，也強調了在教育中審慎開發和應用 AI 的必要性。隨著 AI 技術的進步，建立 AI 互動的架構和協定、驗證 AI 生成的內容的準確性、確保全球各地多元學習者的存取權，以及創造一個 AI 支持人類專業知識的教育環境至關重要。本研究為進一步探索負責任地使用 AI 來豐富教育體驗並改善考試準備和評量方法奠定了基礎。

##### **XAI for In-hospital Mortality Prediction via Multimodal ICU Data**
2312.17624v1 by Xingqiao Li, Jindong Gu, Zhiyong Wang, Yancheng Yuan, Bo Du, Fengxiang He

Predicting in-hospital mortality for intensive care unit (ICU) patients is
key to final clinical outcomes. AI has shown advantaged accuracy but suffers
from the lack of explainability. To address this issue, this paper proposes an
eXplainable Multimodal Mortality Predictor (X-MMP) approaching an efficient,
explainable AI solution for predicting in-hospital mortality via multimodal ICU
data. We employ multimodal learning in our framework, which can receive
heterogeneous inputs from clinical data and make decisions. Furthermore, we
introduce an explainable method, namely Layer-Wise Propagation to Transformer,
as a proper extension of the LRP method to Transformers, producing explanations
over multimodal inputs and revealing the salient features attributed to
prediction. Moreover, the contribution of each modality to clinical outcomes
can be visualized, assisting clinicians in understanding the reasoning behind
decision-making. We construct a multimodal dataset based on MIMIC-III and
MIMIC-III Waveform Database Matched Subset. Comprehensive experiments on
benchmark datasets demonstrate that our proposed framework can achieve
reasonable interpretation with competitive prediction accuracy. In particular,
our framework can be easily transferred to other clinical tasks, which
facilitates the discovery of crucial factors in healthcare research.

摘要：預測加護病房 (ICU) 病患的院內死亡率是最終臨床結果的關鍵。AI 已展現出優異的準確度，但卻缺乏可解釋性。為了解決這個問題，本文提出了一個可解釋的多模式死亡率預測器 (X-MMP)，採用有效且可解釋的 AI 方式，藉由多模式 ICU 資料來預測院內死亡率。我們在架構中採用多模式學習，可以接收來自臨床資料的異質輸入並做出決策。此外，我們引入了一個可解釋的方法，也就是分層傳播至 Transformer，作為 LRP 方法適當地延伸至 Transformer，對多模式輸入產生解釋，並揭露歸因於預測的顯著特徵。此外，每個模式對臨床結果的貢獻可以視覺化，協助臨床醫師了解決策背後的理由。我們根據 MIMIC-III 和 MIMIC-III 波形資料庫比對子集建構了一個多模式資料集。在基準資料集上的全面實驗證明，我們提出的架構可以達成合理的詮釋，並具備競爭力的預測準確度。特別是，我們的架構可以輕鬆地轉移到其他臨床任務，這有助於在醫療保健研究中發現關鍵因素。

##### **Joining Forces for Pathology Diagnostics with AI Assistance: The EMPAIA Initiative**
2401.09450v2 by Norman Zerbe, Lars Ole Schwen, Christian Geißler, Katja Wiesemann, Tom Bisson, Peter Boor, Rita Carvalho, Michael Franz, Christoph Jansen, Tim-Rasmus Kiehl, Björn Lindequist, Nora Charlotte Pohlan, Sarah Schmell, Klaus Strohmenger, Falk Zakrzewski, Markus Plass, Michael Takla, Tobias Küster, André Homeyer, Peter Hufnagl

Over the past decade, artificial intelligence (AI) methods in pathology have
advanced substantially. However, integration into routine clinical practice has
been slow due to numerous challenges, including technical and regulatory
hurdles in translating research results into clinical diagnostic products and
the lack of standardized interfaces. The open and vendor-neutral EMPAIA
initiative addresses these challenges. Here, we provide an overview of EMPAIA's
achievements and lessons learned. EMPAIA integrates various stakeholders of the
pathology AI ecosystem, i.e., pathologists, computer scientists, and industry.
In close collaboration, we developed technical interoperability standards,
recommendations for AI testing and product development, and explainability
methods. We implemented the modular and open-source EMPAIA platform and
successfully integrated 14 AI-based image analysis apps from 8 different
vendors, demonstrating how different apps can use a single standardized
interface. We prioritized requirements and evaluated the use of AI in real
clinical settings with 14 different pathology laboratories in Europe and Asia.
In addition to technical developments, we created a forum for all stakeholders
to share information and experiences on digital pathology and AI. Commercial,
clinical, and academic stakeholders can now adopt EMPAIA's common open-source
interfaces, providing a unique opportunity for large-scale standardization and
streamlining of processes. Further efforts are needed to effectively and
broadly establish AI assistance in routine laboratory use. To this end, a
sustainable infrastructure, the non-profit association EMPAIA International,
has been established to continue standardization and support broad
implementation and advocacy for an AI-assisted digital pathology future.

摘要：在過去的十年中，病理學中的人工智慧 (AI) 方法已大幅進步。然而，由於許多挑戰，包括將研究結果轉化為臨床診斷產品在技術和法規方面的障礙，以及缺乏標準化介面，導致整合到常規臨床實務中進展緩慢。開放且與供應商無關的 EMPAIA 計畫應對了這些挑戰。在此，我們提供 EMPAIA 的成就和經驗教訓的概述。EMPAIA 整合了病理學 AI 生態系統的各個利害關係人，即病理學家、電腦科學家和產業。在密切合作下，我們制定了技術互通性標準、AI 測試和產品開發建議，以及可解釋性方法。我們實作了模組化且開放原始碼的 EMPAIA 平臺，並成功整合了來自 8 個不同供應商的 14 個基於 AI 的影像分析應用程式，展示了不同的應用程式如何使用單一的標準化介面。我們優先考慮需求，並評估了 AI 在歐洲和亞洲的 14 個不同病理實驗室中的實際臨床應用。除了技術開發外，我們還為所有利害關係人建立了一個論壇，以分享數位病理學和 AI 的資訊和經驗。商業、臨床和學術利害關係人現在可以採用 EMPAIA 的常見開放原始碼介面，這為大規模標準化和簡化流程提供了獨特的機會。需要進一步的努力才能有效且廣泛地建立例行實驗室使用中的 AI 輔助。為此，已成立非營利協會 EMPAIA International，以作為永續基礎架構，繼續進行標準化，並支援廣泛實作和倡導 AI 輔助數位病理學的未來。

##### **Robust Stochastic Graph Generator for Counterfactual Explanations**
2312.11747v2 by Mario Alfonso Prado-Romero, Bardh Prenkaj, Giovanni Stilo

Counterfactual Explanation (CE) techniques have garnered attention as a means
to provide insights to the users engaging with AI systems. While extensively
researched in domains such as medical imaging and autonomous vehicles, Graph
Counterfactual Explanation (GCE) methods have been comparatively
under-explored. GCEs generate a new graph similar to the original one, with a
different outcome grounded on the underlying predictive model. Among these GCE
techniques, those rooted in generative mechanisms have received relatively
limited investigation despite demonstrating impressive accomplishments in other
domains, such as artistic styles and natural language modelling. The preference
for generative explainers stems from their capacity to generate counterfactual
instances during inference, leveraging autonomously acquired perturbations of
the input graph. Motivated by the rationales above, our study introduces
RSGG-CE, a novel Robust Stochastic Graph Generator for Counterfactual
Explanations able to produce counterfactual examples from the learned latent
space considering a partially ordered generation sequence. Furthermore, we
undertake quantitative and qualitative analyses to compare RSGG-CE's
performance against SoA generative explainers, highlighting its increased
ability to engendering plausible counterfactual candidates.

摘要：反事實解釋 (CE) 技術已引起關注，作為一種為與 AI 系統互動的使用者提供見解的方法。雖然在醫學影像和自動駕駛汽車等領域廣泛研究，圖形反事實解釋 (GCE) 方法相對較少被探索。GCE 會產生一個類似於原始圖形的新圖形，並根據基礎預測模型產生不同的結果。在這些 GCE 技術中，儘管在其他領域（例如藝術風格和自然語言建模）中展現出令人印象深刻的成就，但植基於生成機制的技術獲得的關注相對有限。對生成式解釋器的偏好源於它們在推理期間產生反事實實例的能力，利用輸入圖形的自主獲取擾動。基於上述理由，我們的研究引入了 RSGG-CE，一種用於反事實解釋的新型穩健隨機圖形生成器，能夠從學習到的潛在空間中產生反事實範例，考慮部分有序的生成序列。此外，我們進行定量和定性分析，以比較 RSGG-CE 的效能與 SoA 生成式解釋器，強調其增強了產生合理解釋候選的能力。

##### **Evaluating the Utility of Model Explanations for Model Development**
2312.06032v1 by Shawn Im, Jacob Andreas, Yilun Zhou

One of the motivations for explainable AI is to allow humans to make better
and more informed decisions regarding the use and deployment of AI models. But
careful evaluations are needed to assess whether this expectation has been
fulfilled. Current evaluations mainly focus on algorithmic properties of
explanations, and those that involve human subjects often employ subjective
questions to test human's perception of explanation usefulness, without being
grounded in objective metrics and measurements. In this work, we evaluate
whether explanations can improve human decision-making in practical scenarios
of machine learning model development. We conduct a mixed-methods user study
involving image data to evaluate saliency maps generated by SmoothGrad,
GradCAM, and an oracle explanation on two tasks: model selection and
counterfactual simulation. To our surprise, we did not find evidence of
significant improvement on these tasks when users were provided with any of the
saliency maps, even the synthetic oracle explanation designed to be simple to
understand and highly indicative of the answer. Nonetheless, explanations did
help users more accurately describe the models. These findings suggest caution
regarding the usefulness and potential for misunderstanding in saliency-based
explanations.

摘要：可解釋 AI 的動機之一是讓人們在使用和部署 AI 模型時做出更好、更明智的決策。但需要仔細評估以評估是否已達到此預期。目前的評估主要集中在解釋的演算法特性，而涉及人類受試者的評估通常採用主觀問題來測試人類對解釋有用性的看法，而沒有基於客觀指標和測量。在這項工作中，我們評估解釋是否可以在機器學習模型開發的實際場景中改善人類決策制定。我們進行了一項涉及影像資料的混合方法使用者研究，以評估 SmoothGrad、GradCAM 和預言解釋在兩個任務中產生的顯著性圖：模型選擇和反事實模擬。令人驚訝的是，我們沒有發現任何顯著性圖（即使是設計為易於理解且高度指示答案的合成預言解釋）能讓使用者在這些任務上顯著改善的證據。儘管如此，解釋確實有助於使用者更準確地描述模型。這些發現提示我們要對基於顯著性的解釋中可能存在誤解的有用性保持謹慎。

##### **Building Trustworthy NeuroSymbolic AI Systems: Consistency, Reliability, Explainability, and Safety**
2312.06798v1 by Manas Gaur, Amit Sheth

Explainability and Safety engender Trust. These require a model to exhibit
consistency and reliability. To achieve these, it is necessary to use and
analyze data and knowledge with statistical and symbolic AI methods relevant to
the AI application - neither alone will do. Consequently, we argue and seek to
demonstrate that the NeuroSymbolic AI approach is better suited for making AI a
trusted AI system. We present the CREST framework that shows how Consistency,
Reliability, user-level Explainability, and Safety are built on NeuroSymbolic
methods that use data and knowledge to support requirements for critical
applications such as health and well-being. This article focuses on Large
Language Models (LLMs) as the chosen AI system within the CREST framework. LLMs
have garnered substantial attention from researchers due to their versatility
in handling a broad array of natural language processing (NLP) scenarios. For
example, ChatGPT and Google's MedPaLM have emerged as highly promising
platforms for providing information in general and health-related queries,
respectively. Nevertheless, these models remain black boxes despite
incorporating human feedback and instruction-guided tuning. For instance,
ChatGPT can generate unsafe responses despite instituting safety guardrails.
CREST presents a plausible approach harnessing procedural and graph-based
knowledge within a NeuroSymbolic framework to shed light on the challenges
associated with LLMs.

摘要：可解釋性和安全性建立信任。這些需要一個模型來展示一致性和可靠性。為了實現這些，有必要使用和分析數據和知識，並使用與 AI 應用相關的統計和符號 AI 方法 - 單獨使用任何一種方法都不會奏效。因此，我們主張並試圖證明 NeuroSymbolic AI 方法更適合於使 AI 成為受信任的 AI 系統。我們提出了 CREST 框架，展示了一致性、可靠性、使用者層級的可解釋性和安全性是如何建立在 NeuroSymbolic 方法上的，該方法使用數據和知識來支持關鍵應用（例如健康和福祉）的要求。本文重點關注大型語言模型 (LLM)，因為它是 CREST 框架中選擇的 AI 系統。LLM 因其在處理廣泛的自然語言處理 (NLP) 場景方面的多功能性而備受研究人員的關注。例如，ChatGPT 和 Google 的 MedPaLM 已成為提供一般和健康相關查詢信息的極有希望的平台。儘管如此，這些模型仍然是黑盒子，儘管納入了人類反饋和指令引導的調整。例如，儘管制定了安全防護措施，ChatGPT 仍可能產生不安全的回應。CREST 提出了一種合理的方法，在 NeuroSymbolic 框架中利用程序和基於圖表的知識，以闡明與 LLM 相關的挑戰。

##### **Deployment of a Robust and Explainable Mortality Prediction Model: The COVID-19 Pandemic and Beyond**
2311.17133v1 by Jacob R. Epifano, Stephen Glass, Ravi P. Ramachandran, Sharad Patel, Aaron J. Masino, Ghulam Rasool

This study investigated the performance, explainability, and robustness of
deployed artificial intelligence (AI) models in predicting mortality during the
COVID-19 pandemic and beyond. The first study of its kind, we found that
Bayesian Neural Networks (BNNs) and intelligent training techniques allowed our
models to maintain performance amidst significant data shifts. Our results
emphasize the importance of developing robust AI models capable of matching or
surpassing clinician predictions, even under challenging conditions. Our
exploration of model explainability revealed that stochastic models generate
more diverse and personalized explanations thereby highlighting the need for AI
models that provide detailed and individualized insights in real-world clinical
settings. Furthermore, we underscored the importance of quantifying uncertainty
in AI models which enables clinicians to make better-informed decisions based
on reliable predictions. Our study advocates for prioritizing implementation
science in AI research for healthcare and ensuring that AI solutions are
practical, beneficial, and sustainable in real-world clinical environments. By
addressing unique challenges and complexities in healthcare settings,
researchers can develop AI models that effectively improve clinical practice
and patient outcomes.

摘要：本研究调查了在 COVID-19 疫情期间及以后预测死亡率时，已部署人工智能 (AI) 模型的性能、可解释性和稳健性。作为同类研究中的首例，我们发现贝叶斯神经网络 (BNN) 和智能训练技术让我们的模型在数据发生重大变化时仍能保持性能。我们的结果强调了开发稳健的 AI 模型的重要性，即使在具有挑战性的条件下，这些模型也能匹配或超越临床医生的预测。我们对模型可解释性的探索表明，随机模型会产生更多样化且个性化的解释，从而突出了在现实世界的临床环境中提供详细且个性化见解的 AI 模型的必要性。此外，我们强调了量化 AI 模型中不确定性的重要性，这使临床医生能够根据可靠的预测做出更明智的决策。我们的研究提倡在医疗保健的 AI 研究中优先考虑实施科学，并确保 AI 解决方案在现实世界的临床环境中实用、有益且可持续。通过解决医疗保健环境中的独特挑战和复杂性，研究人员可以开发出有效改善临床实践和患者预后的 AI 模型。

##### **Variational Autoencoders for Feature Exploration and Malignancy Prediction of Lung Lesions**
2311.15719v1 by Benjamin Keel, Aaron Quyn, David Jayne, Samuel D. Relton

Lung cancer is responsible for 21% of cancer deaths in the UK and five-year
survival rates are heavily influenced by the stage the cancer was identified
at. Recent studies have demonstrated the capability of AI methods for accurate
and early diagnosis of lung cancer from routine scans. However, this evidence
has not translated into clinical practice with one barrier being a lack of
interpretable models. This study investigates the application Variational
Autoencoders (VAEs), a type of generative AI model, to lung cancer lesions.
Proposed models were trained on lesions extracted from 3D CT scans in the
LIDC-IDRI public dataset. Latent vector representations of 2D slices produced
by the VAEs were explored through clustering to justify their quality and used
in an MLP classifier model for lung cancer diagnosis, the best model achieved
state-of-the-art metrics of AUC 0.98 and 93.1% accuracy. Cluster analysis shows
the VAE latent space separates the dataset of malignant and benign lesions
based on meaningful feature components including tumour size, shape, patient
and malignancy class. We also include a comparative analysis of the standard
Gaussian VAE (GVAE) and the more recent Dirichlet VAE (DirVAE), which replaces
the prior with a Dirichlet distribution to encourage a more explainable latent
space with disentangled feature representation. Finally, we demonstrate the
potential for latent space traversals corresponding to clinically meaningful
feature changes.

摘要：肺癌占英國癌症死亡人數的 21%，五年存活率很大程度取決於癌症被發現的階段。最近的研究已證明人工智能方法具有從例行掃描中準確及早診斷肺癌的能力。然而，此證據尚未轉化為臨床實務，其中一個障礙是缺乏可解釋的模型。本研究探討了應用變分自動編碼器 (VAE)，一種生成式人工智能模型，於肺癌病灶。將提出的模型訓練於從 LIDC-IDRI 公共數據集中提取的 3D 電腦斷層掃描病灶。通過聚類探索了 VAE 生成的 2D 切片的潛在向量表示，以證明其品質，並用於肺癌診斷的 MLP 分類器模型，最佳模型達到了 AUC 0.98 和 93.1% 準確度的最先進指標。聚類分析顯示，VAE 潛在空間根據有意義的特徵組成（包括腫瘤大小、形狀、患者和惡性類別）將惡性和良性病灶的數據集分開。我們還包括標準高斯 VAE (GVAE) 和更新的狄利克雷 VAE (DirVAE) 的比較分析，後者用狄利克雷分佈取代先驗，以促進具有解開特徵表示的更具可解釋性的潛在空間。最後，我們展示了與臨床有意義的特徵變化相應的潛在空間橫越的潛力。

##### **MRxaI: Black-Box Explainability for Image Classifiers in a Medical Setting**
2311.14471v1 by Nathan Blake, Hana Chockler, David A. Kelly, Santiago Calderon Pena, Akchunya Chanchal

Existing tools for explaining the output of image classifiers can be divided
into white-box, which rely on access to the model internals, and black-box,
agnostic to the model. As the usage of AI in the medical domain grows, so too
does the usage of explainability tools. Existing work on medical image
explanations focuses on white-box tools, such as gradcam. However, there are
clear advantages to switching to a black-box tool, including the ability to use
it with any classifier and the wide selection of black-box tools available. On
standard images, black-box tools are as precise as white-box. In this paper we
compare the performance of several black-box methods against gradcam on a brain
cancer MRI dataset. We demonstrate that most black-box tools are not suitable
for explaining medical image classifications and present a detailed analysis of
the reasons for their shortcomings. We also show that one black-box tool, a
causal explainability-based rex, performs as well as \gradcam.

摘要：現有的圖像分類器輸出解釋工具可分為依賴於模型內部存取權限的白盒，以及與模型無關的黑盒。隨著 AI 在醫療領域的使用增加，可解釋性工具的使用也隨之增加。現有醫學影像解釋的工作重點在於白盒工具，例如 gradcam。然而，切換到黑盒工具有明顯的優點，包括能夠與任何分類器一起使用，以及廣泛的黑盒工具可供選擇。在標準影像上，黑盒工具與白盒一樣精確。在本文中，我們比較了多種黑盒方法在腦癌 MRI 資料集上與 gradcam 的效能。我們證明大多數黑盒工具不適合解釋醫學影像分類，並詳細分析其缺點的原因。我們還表明一種黑盒工具，基於因果可解釋性的 rex，表現與 \gradcam 一樣好。

##### **Moderating Model Marketplaces: Platform Governance Puzzles for AI Intermediaries**
2311.12573v3 by Robert Gorwa, Michael Veale

The AI development community is increasingly making use of hosting
intermediaries such as Hugging Face provide easy access to user-uploaded models
and training data. These model marketplaces lower technical deployment barriers
for hundreds of thousands of users, yet can be used in numerous potentially
harmful and illegal ways. In this article, we explain ways in which AI systems,
which can both `contain' content and be open-ended tools, present one of the
trickiest platform governance challenges seen to date. We provide case studies
of several incidents across three illustrative platforms -- Hugging Face,
GitHub and Civitai -- to examine how model marketplaces moderate models.
Building on this analysis, we outline important (and yet nevertheless limited)
practices that industry has been developing to respond to moderation demands:
licensing, access and use restrictions, automated content moderation, and open
policy development. While the policy challenge at hand is a considerable one,
we conclude with some ideas as to how platforms could better mobilize resources
to act as a careful, fair, and proportionate regulatory access point.

摘要：AI 開發社群日益利用 Hugging Face 等託管中介機構提供用戶上傳的模型和訓練資料的簡易存取權限。這些模型市集降低了數十萬名用戶的技術部署障礙，但可能會被用於許多潛在有害和非法的方式。在本文中，我們說明 AI 系統既可以「包含」內容，又可以作為開放式工具，這提出了迄今為止最棘手的平台治理挑戰之一。我們提供 Hugging Face、GitHub 和 Civitai 等三個說明性平台上數起事件的案例研究，以檢視模型市集如何審核模型。根據此分析，我們概述產業為回應審核需求而開發的重要（但仍有限）實務：授權、存取和使用限制、自動化內容審核和開放政策制定。雖然當前政策挑戰相當可觀，我們最後提出一些構想，說明平台如何能更好地動員資源，作為謹慎、公平且適度的法規存取點。

##### **Ovarian Cancer Data Analysis using Deep Learning: A Systematic Review from the Perspectives of Key Features of Data Analysis and AI Assurance**
2311.11932v1 by Muta Tah Hira, Mohammad A. Razzaque, Mosharraf Sarker

Background and objectives: By extracting this information, Machine or Deep
Learning (ML/DL)-based autonomous data analysis tools can assist clinicians and
cancer researchers in discovering patterns and relationships from complex data
sets. Many DL-based analyses on ovarian cancer (OC) data have recently been
published. These analyses are highly diverse in various aspects of cancer
(e.g., subdomain(s) and cancer type they address) and data analysis features.
However, a comprehensive understanding of these analyses in terms of these
features and AI assurance (AIA) is currently lacking. This systematic review
aims to fill this gap by examining the existing literature and identifying
important aspects of OC data analysis using DL, explicitly focusing on the key
features and AI assurance perspectives. Methods: The PRISMA framework was used
to conduct comprehensive searches in three journal databases. Only studies
published between 2015 and 2023 in peer-reviewed journals were included in the
analysis. Results: In the review, a total of 96 DL-driven analyses were
examined. The findings reveal several important insights regarding DL-driven
ovarian cancer data analysis: - Most studies 71% (68 out of 96) focused on
detection and diagnosis, while no study addressed the prediction and prevention
of OC. - The analyses were predominantly based on samples from a non-diverse
population (75% (72/96 studies)), limited to a geographic location or country.
- Only a small proportion of studies (only 33% (32/96)) performed integrated
analyses, most of which used homogeneous data (clinical or omics). - Notably, a
mere 8.3% (8/96) of the studies validated their models using external and
diverse data sets, highlighting the need for enhanced model validation, and -
The inclusion of AIA in cancer data analysis is in a very early stage; only
2.1% (2/96) explicitly addressed AIA through explainability.

摘要：<paragraph>背景和目標：通過提取這些資訊，機器或深度學習 (ML/DL) 基於自主數據分析工具可以協助臨床醫生和癌症研究人員從複雜的數據集中發現模式和關係。最近已發表許多基於 DL 的卵巢癌 (OC) 數據分析。這些分析在癌症的各個方面（例如，它們涉及的子領域和癌症類型）和數據分析功能方面高度多樣化。然而，目前缺乏對這些分析在這些特徵和 AI 保證 (AIA) 方面的全面理解。這篇系統性回顧旨在通過檢視現有文獻並明確關注關鍵特徵和 AI 保證觀點，來填補這個空白。方法：使用 PRISMA 架構在三個期刊資料庫中進行全面搜尋。分析僅包括 2015 年至 2023 年間發表於同行評審期刊的研究。結果：在回顧中，總共檢視了 96 項由 DL 驅動的分析。研究結果揭示了幾個關於由 DL 驅動的卵巢癌數據分析的重要見解：- 大多數研究 71%（96 項中有 68 項）專注於檢測和診斷，而沒有研究探討 OC 的預測和預防。- 這些分析主要基於來自非多元族群的樣本（75%（96 項研究中的 72 項）），僅限於某個地理位置或國家。- 只有少部分研究（僅 33%（96 項研究中的 32 項）執行整合分析，其中大多數使用同質數據（臨床或組學）。- 值得注意的是，只有 8.3%（96 項研究中的 8 項）使用外部和多元數據集驗證了其模型，強調了加強模型驗證的必要性，以及- 將 AIA 納入癌症數據分析仍處於非常早期的階段；只有 2.1%（96 項研究中的 2 項）透過可解釋性明確探討了 AIA。</paragraph>

##### **Representing visual classification as a linear combination of words**
2311.10933v1 by Shobhit Agarwal, Yevgeniy R. Semenov, William Lotter

Explainability is a longstanding challenge in deep learning, especially in
high-stakes domains like healthcare. Common explainability methods highlight
image regions that drive an AI model's decision. Humans, however, heavily rely
on language to convey explanations of not only "where" but "what".
Additionally, most explainability approaches focus on explaining individual AI
predictions, rather than describing the features used by an AI model in
general. The latter would be especially useful for model and dataset auditing,
and potentially even knowledge generation as AI is increasingly being used in
novel tasks. Here, we present an explainability strategy that uses a
vision-language model to identify language-based descriptors of a visual
classification task. By leveraging a pre-trained joint embedding space between
images and text, our approach estimates a new classification task as a linear
combination of words, resulting in a weight for each word that indicates its
alignment with the vision-based classifier. We assess our approach using two
medical imaging classification tasks, where we find that the resulting
descriptors largely align with clinical knowledge despite a lack of
domain-specific language training. However, our approach also identifies the
potential for 'shortcut connections' in the public datasets used. Towards a
functional measure of explainability, we perform a pilot reader study where we
find that the AI-identified words can enable non-expert humans to perform a
specialized medical task at a non-trivial level. Altogether, our results
emphasize the potential of using multimodal foundational models to deliver
intuitive, language-based explanations of visual tasks.

摘要：<paragraph>解釋性是深度學習中長期的挑戰，特別是在醫療保健等高風險領域。常見的解釋性方法會強調驅動 AI 模型決策的影像區域。然而，人類很大程度依賴語言來傳達不僅是「在哪裡」，還有「是什麼」的解釋。此外，大多數解釋性方法都專注於解釋個別 AI 預測，而不是描述 AI 模型一般使用的特徵。後者對於模型和資料集稽核特別有用，甚至可能在 AI 愈來愈用於新穎任務時產生知識。在此，我們提出一個使用視覺語言模型來辨識視覺分類任務的語言描述符的解釋性策略。透過利用影像和文字之間預先訓練的聯合嵌入空間，我們的做法將新的分類任務估計為一個線性文字組合，導致每個文字都有權重，表示它與基於視覺的分類器對齊。我們使用兩個醫學影像分類任務來評估我們的做法，我們發現產生的描述符在很大程度上與臨床知識一致，儘管缺乏特定領域的語言訓練。然而，我們的做法也發現了所用公開資料集中的「捷徑連線」的可能性。為了達到解釋性的功能性衡量，我們進行了一項試驗讀者研究，發現 AI 識別的文字能讓非專家人類在非平凡的層級執行專業的醫療任務。總之，我們的結果強調了使用多模式基礎模型來提供直觀的、基於語言的視覺任務解釋的潛力。</paragraph>

##### **Towards objective and systematic evaluation of bias in artificial intelligence for medical imaging**
2311.02115v2 by Emma A. M. Stanley, Raissa Souza, Anthony Winder, Vedant Gulve, Kimberly Amador, Matthias Wilms, Nils D. Forkert

Artificial intelligence (AI) models trained using medical images for clinical
tasks often exhibit bias in the form of disparities in performance between
subgroups. Since not all sources of biases in real-world medical imaging data
are easily identifiable, it is challenging to comprehensively assess how those
biases are encoded in models, and how capable bias mitigation methods are at
ameliorating performance disparities. In this article, we introduce a novel
analysis framework for systematically and objectively investigating the impact
of biases in medical images on AI models. We developed and tested this
framework for conducting controlled in silico trials to assess bias in medical
imaging AI using a tool for generating synthetic magnetic resonance images with
known disease effects and sources of bias. The feasibility is showcased by
using three counterfactual bias scenarios to measure the impact of simulated
bias effects on a convolutional neural network (CNN) classifier and the
efficacy of three bias mitigation strategies. The analysis revealed that the
simulated biases resulted in expected subgroup performance disparities when the
CNN was trained on the synthetic datasets. Moreover, reweighing was identified
as the most successful bias mitigation strategy for this setup, and we
demonstrated how explainable AI methods can aid in investigating the
manifestation of bias in the model using this framework. Developing fair AI
models is a considerable challenge given that many and often unknown sources of
biases can be present in medical imaging datasets. In this work, we present a
novel methodology to objectively study the impact of biases and mitigation
strategies on deep learning pipelines, which can support the development of
clinical AI that is robust and responsible.

摘要：<paragraph>使用醫療影像訓練的人工智慧 (AI) 模型，用於臨床任務時，常會在效能上展現出次群體之間的差異，形成偏見。由於並非所有真實世界醫療影像資料中的偏見來源都容易辨識，因此全面評估這些偏見是如何編碼到模型中，以及偏見緩解方法在改善效能差異方面的能力，是一項挑戰。在本文中，我們介紹了一個新穎的分析架構，用於系統化且客觀地調查醫療影像中的偏見對 AI 模型的影響。我們開發並測試了這個架構，以進行受控的電腦模擬試驗，使用一個工具來評估醫療影像 AI 中的偏見，該工具用於產生具有已知疾病影響和偏見來源的合成磁共振影像。可行性透過使用三個反事實偏見情境來衡量模擬偏見效應對卷積神經網路 (CNN) 分類器和三個偏見緩解策略的影響，並展示出來。分析顯示，當 CNN 在合成資料集上受訓時，模擬偏見會導致預期的次群體效能差異。此外，重新加權被認為是此設定中最成功的偏見緩解策略，我們展示了解釋性 AI 方法如何協助使用這個架構調查模型中偏見的表現。開發公平的 AI 模型是一項重大的挑戰，因為醫療影像資料集中可能存在許多且經常未知的偏見來源。在這項工作中，我們提出了一種新穎的方法，用於客觀地研究偏見和緩解策略對深度學習管線的影響，這可以支援健全且負責任的臨床 AI 的開發。</paragraph>

##### **Predicting recovery following stroke: deep learning, multimodal data and feature selection using explainable AI**
2310.19174v1 by Adam White, Margarita Saranti, Artur d'Avila Garcez, Thomas M. H. Hope, Cathy J. Price, Howard Bowman

Machine learning offers great potential for automated prediction of
post-stroke symptoms and their response to rehabilitation. Major challenges for
this endeavour include the very high dimensionality of neuroimaging data, the
relatively small size of the datasets available for learning, and how to
effectively combine neuroimaging and tabular data (e.g. demographic information
and clinical characteristics). This paper evaluates several solutions based on
two strategies. The first is to use 2D images that summarise MRI scans. The
second is to select key features that improve classification accuracy.
Additionally, we introduce the novel approach of training a convolutional
neural network (CNN) on images that combine regions-of-interest extracted from
MRIs, with symbolic representations of tabular data. We evaluate a series of
CNN architectures (both 2D and a 3D) that are trained on different
representations of MRI and tabular data, to predict whether a composite measure
of post-stroke spoken picture description ability is in the aphasic or
non-aphasic range. MRI and tabular data were acquired from 758 English speaking
stroke survivors who participated in the PLORAS study. The classification
accuracy for a baseline logistic regression was 0.678 for lesion size alone,
rising to 0.757 and 0.813 when initial symptom severity and recovery time were
successively added. The highest classification accuracy 0.854 was observed when
8 regions-of-interest was extracted from each MRI scan and combined with lesion
size, initial severity and recovery time in a 2D Residual Neural Network.Our
findings demonstrate how imaging and tabular data can be combined for high
post-stroke classification accuracy, even when the dataset is small in machine
learning terms. We conclude by proposing how the current models could be
improved to achieve even higher levels of accuracy using images from hospital
scanners.

摘要：機器學習為自動預測中風後症狀及其對復健的反應提供了極大的潛力。這項工作的重大挑戰包括神經影像資料的維度非常高、可用於學習的資料集規模相對較小，以及如何有效結合神經影像和表格資料（例如人口統計資訊和臨床特徵）。本文根據兩種策略評估了多種解決方案。第一種是使用總結 MRI 掃描的 2D 影像。第二種是選擇有助於提高分類精確度的關鍵特徵。此外，我們引入了在結合從 MRI 中提取的感興趣區域與表格資料的符號表示的影像上訓練卷積神經網路 (CNN) 的新穎方法。我們評估了一系列 CNN 架構（2D 和 3D），這些架構在 MRI 和表格資料的不同表示上進行訓練，以預測中風後口述圖片描述能力的綜合測量是否在失語症或非失語症範圍內。MRI 和表格資料來自 758 名參與 PLORAS 研究的英語中風倖存者。僅針對病灶大小的基線邏輯迴歸分類準確度為 0.678，當依序加入初始症狀嚴重程度和恢復時間時，上升至 0.757 和 0.813。在從每個 MRI 掃描中提取 8 個感興趣區域並在 2D 殘差神經網路中與病灶大小、初始嚴重程度和恢復時間結合時，觀察到最高的分類準確度 0.854。我們的研究結果展示了如何將影像和表格資料結合起來以獲得高於中風後分類準確度，即使在機器學習術語中資料集很小的情況下也是如此。最後，我們提出如何改進目前的模型，以使用來自醫院掃描儀的影像來實現更高的準確度。

##### **Trainable Noise Model as an XAI evaluation method: application on Sobol for remote sensing image segmentation**
2310.01828v2 by Hossein Shreim, Abdul Karim Gizzini, Ali J. Ghandour

eXplainable Artificial Intelligence (XAI) has emerged as an essential
requirement when dealing with mission-critical applications, ensuring
transparency and interpretability of the employed black box AI models. The
significance of XAI spans various domains, from healthcare to finance, where
understanding the decision-making process of deep learning algorithms is
essential. Most AI-based computer vision models are often black boxes; hence,
providing explainability of deep neural networks in image processing is crucial
for their wide adoption and deployment in medical image analysis, autonomous
driving, and remote sensing applications. Recently, several XAI methods for
image classification tasks have been introduced. On the contrary, image
segmentation has received comparatively less attention in the context of
explainability, although it is a fundamental task in computer vision
applications, especially in remote sensing. Only some research proposes
gradient-based XAI algorithms for image segmentation. This paper adapts the
recent gradient-free Sobol XAI method for semantic segmentation. To measure the
performance of the Sobol method for segmentation, we propose a quantitative XAI
evaluation method based on a learnable noise model. The main objective of this
model is to induce noise on the explanation maps, where higher induced noise
signifies low accuracy and vice versa. A benchmark analysis is conducted to
evaluate and compare performance of three XAI methods, including Seg-Grad-CAM,
Seg-Grad-CAM++ and Seg-Sobol using the proposed noise-based evaluation
technique. This constitutes the first attempt to run and evaluate XAI methods
using high-resolution satellite images.

摘要：可解釋人工智慧 (XAI) 已成為處理任務關鍵應用程式時的一項基本需求，確保採用黑盒 AI 模型的透明度和可解釋性。XAI 的重要性涵蓋從醫療保健到金融的各種領域，在這些領域中，了解深度學習演算法的決策制定過程至關重要。大多數基於 AI 的電腦視覺模型通常是黑盒子；因此，在影像處理中提供深度神經網路的可解釋性對於其在醫學影像分析、自動駕駛和遙測應用中的廣泛採用和部署至關重要。最近，已針對影像分類任務引入了多種 XAI 方法。相反地，影像分割在可解釋性的背景下受到的關注相對較少，儘管它是電腦視覺應用中的一項基本任務，特別是在遙測中。只有部分研究提出用於影像分割的基於梯度的 XAI 演算法。本文改編了最近的無梯度 Sobol XAI 方法以進行語意分割。為了衡量 Sobol 方法在分割中的效能，我們提出了一種基於可學習雜訊模型的定量 XAI 評估方法。此模型的主要目的是在解釋圖上誘發雜訊，其中較高的誘發雜訊表示較低的準確度，反之亦然。進行基準分析以評估和比較三種 XAI 方法的效能，包括 Seg-Grad-CAM、Seg-Grad-CAM++ 和 Seg-Sobol，並使用所提出的基於雜訊的評估技術。這構成了使用高解析度衛星影像執行和評估 XAI 方法的首次嘗試。

##### **Creating Trustworthy LLMs: Dealing with Hallucinations in Healthcare AI**
2311.01463v1 by Muhammad Aurangzeb Ahmad, Ilker Yaramis, Taposh Dutta Roy

Large language models have proliferated across multiple domains in as short
period of time. There is however hesitation in the medical and healthcare
domain towards their adoption because of issues like factuality, coherence, and
hallucinations. Give the high stakes nature of healthcare, many researchers
have even cautioned against its usage until these issues are resolved. The key
to the implementation and deployment of LLMs in healthcare is to make these
models trustworthy, transparent (as much possible) and explainable. In this
paper we describe the key elements in creating reliable, trustworthy, and
unbiased models as a necessary condition for their adoption in healthcare.
Specifically we focus on the quantification, validation, and mitigation of
hallucinations in the context in healthcare. Lastly, we discuss how the future
of LLMs in healthcare may look like.

摘要：大型語言模型在短時間內已在多個領域中大量激增。然而，由於事實性、連貫性和幻覺等問題，醫療和保健領域對其採用猶豫不決。鑑於醫療保健的高風險性質，許多研究人員甚至警告不要使用它，直到這些問題得到解決。在醫療保健中實施和部署 LLM 的關鍵是使這些模型值得信賴、透明（盡可能多）且可解釋。在本文中，我們描述了建立可靠、值得信賴和無偏見模型的關鍵要素，作為它們在醫療保健中得到採用的必要條件。具體來說，我們專注於在醫療保健背景下對幻覺進行量化、驗證和緩解。最後，我們討論了 LLM 在醫療保健中的未來可能是什麼樣子。

##### **When to Trust AI: Advances and Challenges for Certification of Neural Networks**
2309.11196v1 by Marta Kwiatkowska, Xiyue Zhang

Artificial intelligence (AI) has been advancing at a fast pace and it is now
poised for deployment in a wide range of applications, such as autonomous
systems, medical diagnosis and natural language processing. Early adoption of
AI technology for real-world applications has not been without problems,
particularly for neural networks, which may be unstable and susceptible to
adversarial examples. In the longer term, appropriate safety assurance
techniques need to be developed to reduce potential harm due to avoidable
system failures and ensure trustworthiness. Focusing on certification and
explainability, this paper provides an overview of techniques that have been
developed to ensure safety of AI decisions and discusses future challenges.

摘要：人工智慧（AI）已快速進步，現已準備部署於廣泛的應用程式中，例如自主系統、醫療診斷和自然語言處理。及早採用 AI 技術於實際應用程式並非沒有問題，特別是對於神經網路，它可能不穩定且容易受到對抗性範例的影響。從長遠來看，需要開發適當的安全保證技術，以減少因可避免的系統故障而造成的潛在傷害，並確保可信賴性。本文著重於認證和可解釋性，概述了已開發用於確保 AI 決策安全的技術，並討論未來的挑戰。

##### **Functional requirements to mitigate the Risk of Harm to Patients from Artificial Intelligence in Healthcare**
2309.10424v1 by Juan M. García-Gómez, Vicent Blanes-Selva, José Carlos de Bartolomé Cenzano, Jaime Cebolla-Cornejo, Ascensión Doñate-Martínez

The Directorate General for Parliamentary Research Services of the European
Parliament has prepared a report to the Members of the European Parliament
where they enumerate seven main risks of Artificial Intelligence (AI) in
medicine and healthcare: patient harm due to AI errors, misuse of medical AI
tools, bias in AI and the perpetuation of existing inequities, lack of
transparency, privacy and security issues, gaps in accountability, and
obstacles in implementation.
  In this study, we propose fourteen functional requirements that AI systems
may implement to reduce the risks associated with their medical purpose: AI
passport, User management, Regulation check, Academic use only disclaimer, data
quality assessment, Clinicians double check, Continuous performance evaluation,
Audit trail, Continuous usability test, Review of retrospective/simulated
cases, Bias check, eXplainable AI, Encryption and use of field-tested
libraries, and Semantic interoperability.
  Our intention here is to provide specific high-level specifications of
technical solutions to ensure continuous good performance and use of AI systems
to benefit patients in compliance with the future EU regulatory framework.

摘要：歐洲議會議會研究服務總局已為歐洲議會議員準備了一份報告，其中列舉了人工智能 (AI) 在醫療保健領域的七項主要風險：AI 錯誤導致患者受到傷害、醫療 AI 工具被濫用、AI 存在偏見並導致現有 inequities 持續存在、缺乏透明度、隱私和安全問題、問責差距以及實施障礙。
  在這項研究中，我們提出了十四項功能性要求，AI 系統可以實施這些要求來降低與其醫療目的相關的風險：AI 護照、使用者管理、法規檢查、僅限學術用途免責聲明、資料品質評估、臨床醫生雙重檢查、持續效能評估、稽核追蹤、持續可用性測試、回顧回溯/模擬案例、偏見檢查、可解釋 AI、加密和使用經過實地測試的程式庫，以及語意互通性。
  我們在此的目的是提供技術解決方案的特定高階規格，以確保持續良好的效能，並使用 AI 系統，以符合未來的歐盟法規架構，從而使患者受益。

##### **QXAI: Explainable AI Framework for Quantitative Analysis in Patient Monitoring Systems**
2309.10293v3 by Thanveer Shaik, Xiaohui Tao, Haoran Xie, Lin Li, Juan D. Velasquez, Niall Higgins

Artificial Intelligence techniques can be used to classify a patient's
physical activities and predict vital signs for remote patient monitoring.
Regression analysis based on non-linear models like deep learning models has
limited explainability due to its black-box nature. This can require
decision-makers to make blind leaps of faith based on non-linear model results,
especially in healthcare applications. In non-invasive monitoring, patient data
from tracking sensors and their predisposing clinical attributes act as input
features for predicting future vital signs. Explaining the contributions of
various features to the overall output of the monitoring application is
critical for a clinician's decision-making. In this study, an Explainable AI
for Quantitative analysis (QXAI) framework is proposed with post-hoc model
explainability and intrinsic explainability for regression and classification
tasks in a supervised learning approach. This was achieved by utilizing the
Shapley values concept and incorporating attention mechanisms in deep learning
models. We adopted the artificial neural networks (ANN) and attention-based
Bidirectional LSTM (BiLSTM) models for the prediction of heart rate and
classification of physical activities based on sensor data. The deep learning
models achieved state-of-the-art results in both prediction and classification
tasks. Global explanation and local explanation were conducted on input data to
understand the feature contribution of various patient data. The proposed QXAI
framework was evaluated using PPG-DaLiA data to predict heart rate and mobile
health (MHEALTH) data to classify physical activities based on sensor data.
Monte Carlo approximation was applied to the framework to overcome the time
complexity and high computation power requirements required for Shapley value
calculations.

摘要：人工智慧技術可用於分類病患的身體活動並預測遠距病患監控的重要生命徵象。基於深度學習模型等非線性模型的回歸分析由於其黑盒子的性質而具有有限的可解釋性。這可能需要決策者根據非線性模型結果做出盲目的信仰飛躍，特別是在醫療保健應用中。在非侵入性監控中，來自追蹤感測器和其易感臨床屬性的病患資料充當預測未來生命徵象的輸入特徵。解釋各種特徵對監控應用程式整體輸出的貢獻對於臨床醫生的決策至關重要。在本研究中，提出了一個用於量化分析的可解釋人工智慧 (QXAI) 架構，該架構具有監督式學習方法中回歸和分類任務的事後模型可解釋性和內在可解釋性。這透過利用 Shapley 值概念並將注意力機制納入深度學習模型來實現。我們採用人工神經網路 (ANN) 和基於注意力的雙向 LSTM (BiLSTM) 模型，根據感測器資料預測心率和分類身體活動。深度學習模型在預測和分類任務中都取得了最先進的成果。對輸入資料進行全局解釋和局部解釋，以了解各種病患資料的特徵貢獻。所提出的 QXAI 架構使用 PPG-DaLiA 資料評估，以預測心率，並使用行動健康 (MHEALTH) 資料根據感測器資料對身體活動進行分類。蒙地卡羅近似法應用於該架構，以克服 Shapley 值計算所需的時間複雜度和高運算能力需求。

##### **Evaluation of Human-Understandability of Global Model Explanations using Decision Tree**
2309.09917v1 by Adarsa Sivaprasad, Ehud Reiter, Nava Tintarev, Nir Oren

In explainable artificial intelligence (XAI) research, the predominant focus
has been on interpreting models for experts and practitioners. Model agnostic
and local explanation approaches are deemed interpretable and sufficient in
many applications. However, in domains like healthcare, where end users are
patients without AI or domain expertise, there is an urgent need for model
explanations that are more comprehensible and instil trust in the model's
operations. We hypothesise that generating model explanations that are
narrative, patient-specific and global(holistic of the model) would enable
better understandability and enable decision-making. We test this using a
decision tree model to generate both local and global explanations for patients
identified as having a high risk of coronary heart disease. These explanations
are presented to non-expert users. We find a strong individual preference for a
specific type of explanation. The majority of participants prefer global
explanations, while a smaller group prefers local explanations. A task based
evaluation of mental models of these participants provide valuable feedback to
enhance narrative global explanations. This, in turn, guides the design of
health informatics systems that are both trustworthy and actionable.

摘要：在可解释人工智能 (XAI) 研究中，主要重点在于为专家和从业者解释模型。模型不可知和局部解释方法在许多应用中被认为是可解释且足够的。然而，在医疗保健等领域，最终用户是缺乏人工智能或领域专业知识的患者，因此迫切需要更易于理解且能激发对模型操作的信任的模型解释。我们假设生成叙述性、患者特定且全局（模型整体）的模型解释将能够提高可理解性并支持决策制定。我们使用决策树模型对此进行测试，为被识别为患有冠心病高风险的患者生成局部和全局解释。这些解释会呈现给非专家用户。我们发现用户强烈偏好特定类型的解释。大多数参与者偏好全局解释，而较小的一组参与者偏好局部解释。基于任务的心理模型评估为这些参与者提供了有价值的反馈，以增强叙述性全局解释。这反过来又指导了既值得信赖又可操作的健康信息学系统的设计。

##### **Leveraging A Medical Knowledge Graph into Large Language Models for Diagnosis Prediction**
2308.14321v1 by Yanjun Gao, Ruizhe Li, John Caskey, Dmitriy Dligach, Timothy Miller, Matthew M. Churpek, Majid Afshar

Electronic Health Records (EHRs) and routine documentation practices play a
vital role in patients' daily care, providing a holistic record of health,
diagnoses, and treatment. However, complex and verbose EHR narratives overload
healthcare providers, risking diagnostic inaccuracies. While Large Language
Models (LLMs) have showcased their potential in diverse language tasks, their
application in the healthcare arena needs to ensure the minimization of
diagnostic errors and the prevention of patient harm. In this paper, we outline
an innovative approach for augmenting the proficiency of LLMs in the realm of
automated diagnosis generation, achieved through the incorporation of a medical
knowledge graph (KG) and a novel graph model: Dr.Knows, inspired by the
clinical diagnostic reasoning process. We derive the KG from the National
Library of Medicine's Unified Medical Language System (UMLS), a robust
repository of biomedical knowledge. Our method negates the need for
pre-training and instead leverages the KG as an auxiliary instrument aiding in
the interpretation and summarization of complex medical concepts. Using
real-world hospital datasets, our experimental results demonstrate that the
proposed approach of combining LLMs with KG has the potential to improve the
accuracy of automated diagnosis generation. More importantly, our approach
offers an explainable diagnostic pathway, edging us closer to the realization
of AI-augmented diagnostic decision support systems.

摘要：電子健康紀錄 (EHR) 和例行文件記錄實務在病患的日常照護中扮演著至關重要的角色，提供健康、診斷和治療的整體紀錄。然而，複雜且冗長的 EHR 敘述會讓醫療保健提供者超載，有診斷不準確的風險。大型語言模型 (LLM) 已展現其在各種語言任務上的潛力，但其在醫療保健領域的應用需要確保將診斷錯誤降到最低，並防止病患受到傷害。在本文中，我們概述一種創新的方法，透過整合醫學知識圖譜 (KG) 和一種新穎的圖譜模型：Dr.Knows（靈感來自臨床診斷推理過程），來增強 LLM 在自動化診斷產生領域的能力。我們從美國國家醫學圖書館的統一醫學語言系統 (UMLS) 中衍生出 KG，這是一個強大的生物醫學知識儲存庫。我們的做法否定了預先訓練的需要，而是將 KG 作為輔助工具，協助解釋和總結複雜的醫學概念。使用真實世界的醫院資料集，我們的實驗結果證明，將 LLM 與 KG 結合的建議方法有潛力提高自動化診斷產生的準確性。更重要的是，我們的做法提供了一條可解釋的診斷途徑，讓我們更接近實現 AI 增強的診斷決策支援系統。

##### **Deciphering knee osteoarthritis diagnostic features with explainable artificial intelligence: A systematic review**
2308.09380v1 by Yun Xin Teoh, Alice Othmani, Siew Li Goh, Juliana Usman, Khin Wee Lai

Existing artificial intelligence (AI) models for diagnosing knee
osteoarthritis (OA) have faced criticism for their lack of transparency and
interpretability, despite achieving medical-expert-like performance. This
opacity makes them challenging to trust in clinical practice. Recently,
explainable artificial intelligence (XAI) has emerged as a specialized
technique that can provide confidence in the model's prediction by revealing
how the prediction is derived, thus promoting the use of AI systems in
healthcare. This paper presents the first survey of XAI techniques used for
knee OA diagnosis. The XAI techniques are discussed from two perspectives: data
interpretability and model interpretability. The aim of this paper is to
provide valuable insights into XAI's potential towards a more reliable knee OA
diagnosis approach and encourage its adoption in clinical practice.

摘要：現有的用於診斷膝骨關節炎 (OA) 的人工智慧 (AI) 模型因其缺乏透明度和可解釋性而受到批評，儘管它們達到了類似醫學專家的表現。這種不透明性使得它們在臨床實務中難以被信任。最近，可解釋人工智慧 (XAI) 已成為一種專門技術，它能透過揭示預測的推導方式來提供對模型預測的信心，從而促進在醫療保健中使用 AI 系統。本文提供了針對膝骨關節炎診斷所使用的 XAI 技術的第一份調查。XAI 技術從兩個角度進行討論：資料可解釋性和模型可解釋性。本文的目的是提供對 XAI 在更可靠的膝骨關節炎診斷方法中的潛力的寶貴見解，並鼓勵在臨床實務中採用它。

##### **Explainable AI for clinical risk prediction: a survey of concepts, methods, and modalities**
2308.08407v1 by Munib Mesinovic, Peter Watkinson, Tingting Zhu

Recent advancements in AI applications to healthcare have shown incredible
promise in surpassing human performance in diagnosis and disease prognosis.
With the increasing complexity of AI models, however, concerns regarding their
opacity, potential biases, and the need for interpretability. To ensure trust
and reliability in AI systems, especially in clinical risk prediction models,
explainability becomes crucial. Explainability is usually referred to as an AI
system's ability to provide a robust interpretation of its decision-making
logic or the decisions themselves to human stakeholders. In clinical risk
prediction, other aspects of explainability like fairness, bias, trust, and
transparency also represent important concepts beyond just interpretability. In
this review, we address the relationship between these concepts as they are
often used together or interchangeably. This review also discusses recent
progress in developing explainable models for clinical risk prediction,
highlighting the importance of quantitative and clinical evaluation and
validation across multiple common modalities in clinical practice. It
emphasizes the need for external validation and the combination of diverse
interpretability methods to enhance trust and fairness. Adopting rigorous
testing, such as using synthetic datasets with known generative factors, can
further improve the reliability of explainability methods. Open access and
code-sharing resources are essential for transparency and reproducibility,
enabling the growth and trustworthiness of explainable research. While
challenges exist, an end-to-end approach to explainability in clinical risk
prediction, incorporating stakeholders from clinicians to developers, is
essential for success.

摘要：最近在醫療保健中的人工智慧應用進展顯示出令人難以置信的承諾，在診斷和疾病預後方面超越人類表現。然而，隨著人工智能模型的日益複雜，人們對其不透明性、潛在偏差和對可解釋性的需求感到擔憂。為了確保人工智能系統的信任和可靠性，尤其是在臨床風險預測模型中，可解釋性變得至關重要。可解釋性通常被稱為人工智能系統提供其決策邏輯或決策本身對人類利益相關者的強有力解釋的能力。在臨床風險預測中，可解釋性的其他方面，如公平性、偏見、信任和透明度，也代表了超越可解釋性的重要概念。在本次審查中，我們探討了這些概念之間的關係，因為它們經常一起或互換使用。本審查還討論了為臨床風險預測開發可解釋模型的最新進展，強調了在臨床實踐中對多種常見模式進行定量和臨床評估和驗證的重要性。它強調了外部驗證和多樣化可解釋性方法相結合的必要性，以增強信任和公平性。採用嚴格的測試，例如使用具有已知生成因素的合成數據集，可以進一步提高可解釋性方法的可靠性。開放獲取和代碼共享資源對於透明度和可重複性至關重要，從而促進可解釋研究的增長和可信度。儘管存在挑戰，但從臨床醫生到開發人員，採用端到端的可解釋性方法對於臨床風險預測的成功至關重要。

##### **FUTURE-AI: International consensus guideline for trustworthy and deployable artificial intelligence in healthcare**
2309.12325v3 by Karim Lekadir, Aasa Feragen, Abdul Joseph Fofanah, Alejandro F Frangi, Alena Buyx, Anais Emelie, Andrea Lara, Antonio R Porras, An-Wen Chan, Arcadi Navarro, Ben Glocker, Benard O Botwe, Bishesh Khanal, Brigit Beger, Carol C Wu, Celia Cintas, Curtis P Langlotz, Daniel Rueckert, Deogratias Mzurikwao, Dimitrios I Fotiadis, Doszhan Zhussupov, Enzo Ferrante, Erik Meijering, Eva Weicken, Fabio A González, Folkert W Asselbergs, Fred Prior, Gabriel P Krestin, Gary Collins, Geletaw S Tegenaw, Georgios Kaissis, Gianluca Misuraca, Gianna Tsakou, Girish Dwivedi, Haridimos Kondylakis, Harsha Jayakody, Henry C Woodruf, Horst Joachim Mayer, Hugo JWL Aerts, Ian Walsh, Ioanna Chouvarda, Irène Buvat, Isabell Tributsch, Islem Rekik, James Duncan, Jayashree Kalpathy-Cramer, Jihad Zahir, Jinah Park, John Mongan, Judy W Gichoya, Julia A Schnabel, Kaisar Kushibar, Katrine Riklund, Kensaku Mori, Kostas Marias, Lameck M Amugongo, Lauren A Fromont, Lena Maier-Hein, Leonor Cerdá Alberich, Leticia Rittner, Lighton Phiri, Linda Marrakchi-Kacem, Lluís Donoso-Bach, Luis Martí-Bonmatí, M Jorge Cardoso, Maciej Bobowicz, Mahsa Shabani, Manolis Tsiknakis, Maria A Zuluaga, Maria Bielikova, Marie-Christine Fritzsche, Marina Camacho, Marius George Linguraru, Markus Wenzel, Marleen De Bruijne, Martin G Tolsgaard, Marzyeh Ghassemi, Md Ashrafuzzaman, Melanie Goisauf, Mohammad Yaqub, Mónica Cano Abadía, Mukhtar M E Mahmoud, Mustafa Elattar, Nicola Rieke, Nikolaos Papanikolaou, Noussair Lazrak, Oliver Díaz, Olivier Salvado, Oriol Pujol, Ousmane Sall, Pamela Guevara, Peter Gordebeke, Philippe Lambin, Pieta Brown, Purang Abolmaesumi, Qi Dou, Qinghua Lu, Richard Osuala, Rose Nakasi, S Kevin Zhou, Sandy Napel, Sara Colantonio, Shadi Albarqouni, Smriti Joshi, Stacy Carter, Stefan Klein, Steffen E Petersen, Susanna Aussó, Suyash Awate, Tammy Riklin Raviv, Tessa Cook, Tinashe E M Mutsvangwa, Wendy A Rogers, Wiro J Niessen, Xènia Puig-Bosch, Yi Zeng, Yunusa G Mohammed, Yves Saint James Aquino, Zohaib Salahuddin, Martijn P A Starmans

Despite major advances in artificial intelligence (AI) for medicine and
healthcare, the deployment and adoption of AI technologies remain limited in
real-world clinical practice. In recent years, concerns have been raised about
the technical, clinical, ethical and legal risks associated with medical AI. To
increase real world adoption, it is essential that medical AI tools are trusted
and accepted by patients, clinicians, health organisations and authorities.
This work describes the FUTURE-AI guideline as the first international
consensus framework for guiding the development and deployment of trustworthy
AI tools in healthcare. The FUTURE-AI consortium was founded in 2021 and
currently comprises 118 inter-disciplinary experts from 51 countries
representing all continents, including AI scientists, clinicians, ethicists,
and social scientists. Over a two-year period, the consortium defined guiding
principles and best practices for trustworthy AI through an iterative process
comprising an in-depth literature review, a modified Delphi survey, and online
consensus meetings. The FUTURE-AI framework was established based on 6 guiding
principles for trustworthy AI in healthcare, i.e. Fairness, Universality,
Traceability, Usability, Robustness and Explainability. Through consensus, a
set of 28 best practices were defined, addressing technical, clinical, legal
and socio-ethical dimensions. The recommendations cover the entire lifecycle of
medical AI, from design, development and validation to regulation, deployment,
and monitoring. FUTURE-AI is a risk-informed, assumption-free guideline which
provides a structured approach for constructing medical AI tools that will be
trusted, deployed and adopted in real-world practice. Researchers are
encouraged to take the recommendations into account in proof-of-concept stages
to facilitate future translation towards clinical practice of medical AI.

摘要：儘管在醫學和醫療保健方面的人工智慧 (AI) 有重大的進展，但 AI 技術的部署和採用在現實世界的臨床實務中仍然有限。近年來，人們對於與醫療 AI 相關的技術、臨床、倫理和法律風險提出了疑慮。為了增加現實世界的採用率，醫療 AI 工具必須獲得患者、臨床醫生、醫療機構和當局的信任和接受。這項工作將 FUTURE-AI 指南描述為指導醫療保健中可信賴 AI 工具開發和部署的第一個國際共識架構。FUTURE-AI 聯盟成立於 2021 年，目前由來自 51 個國家的 118 位跨領域專家組成，代表所有洲，包括 AI 科學家、臨床醫生、倫理學家和社會科學家。在兩年的時間裡，該聯盟通過一個反覆運算的過程定義了可信賴 AI 的指導原則和最佳實務，包括深入的文獻回顧、修改後的德爾菲調查和線上共識會議。FUTURE-AI 架構是基於醫療保健中可信賴 AI 的 6 項指導原則建立的，即公平性、普遍性、可追溯性、可用性、穩健性和可解釋性。通過共識，定義了一組 28 項最佳實務，涵蓋技術、臨床、法律和社會倫理層面。建議涵蓋了醫療 AI 的整個生命週期，從設計、開發和驗證到法規、部署和監控。FUTURE-AI 是一個基於風險、無假設的指南，提供了一個結構化的方法，用於建構將在現實世界實務中受到信任、部署和採用的醫療 AI 工具。鼓勵研究人員在概念驗證階段考慮這些建議，以促進未來將醫療 AI 轉化為臨床實務。

##### **Explainable AI applications in the Medical Domain: a systematic review**
2308.05411v1 by Nicoletta Prentzas, Antonis Kakas, Constantinos S. Pattichis

Artificial Intelligence in Medicine has made significant progress with
emerging applications in medical imaging, patient care, and other areas. While
these applications have proven successful in retrospective studies, very few of
them were applied in practice.The field of Medical AI faces various challenges,
in terms of building user trust, complying with regulations, using data
ethically.Explainable AI (XAI) aims to enable humans understand AI and trust
its results. This paper presents a literature review on the recent developments
of XAI solutions for medical decision support, based on a representative sample
of 198 articles published in recent years. The systematic synthesis of the
relevant articles resulted in several findings. (1) model-agnostic XAI
techniques were mostly employed in these solutions, (2) deep learning models
are utilized more than other types of machine learning models, (3)
explainability was applied to promote trust, but very few works reported the
physicians participation in the loop, (4) visual and interactive user interface
is more useful in understanding the explanation and the recommendation of the
system. More research is needed in collaboration between medical and AI
experts, that could guide the development of suitable frameworks for the
design, implementation, and evaluation of XAI solutions in medicine.

摘要：人工智慧在醫療領域中已取得顯著進展，在醫學影像、病人照護和其他領域中出現了新興應用。雖然這些應用已在回顧性研究中被證實是成功的，但實際上只有極少數應用於實務。醫療 AI 領域面臨著各種挑戰，包括建立使用者信任、遵守法規、使用資料符合倫理。可解釋 AI (XAI) 的目標是讓人類了解 AI 並相信其結果。本文針對最近幾年發表的 198 篇文章的具代表性樣本，提出有關醫療決策支援的 XAI 解決方案的最新發展的文獻回顧。相關文章的系統性綜合整理產生了多項發現：(1) 這些解決方案大多採用與模型無關的 XAI 技術，(2) 深度學習模型的使用率高於其他類型的機器學習模型，(3) 可解釋性被用於促進信任，但很少有研究報告醫師參與迴圈，(4) 視覺和互動式使用者介面對於理解系統的解釋和建議更有用。需要更多醫療和 AI 專家合作進行研究，這有助於為醫療領域的 XAI 解決方案的設計、實作和評估提供適當架構。

##### **Exploring the Role of Explainability in AI-Assisted Embryo Selection**
2308.02534v1 by Lucia Urcelay, Daniel Hinjos, Pablo A. Martin-Torres, Marta Gonzalez, Marta Mendez, Salva Cívico, Sergio Álvarez-Napagao, Dario Garcia-Gasulla

In Vitro Fertilization is among the most widespread treatments for
infertility. One of its main challenges is the evaluation and selection of
embryo for implantation, a process with large inter- and intra-clinician
variability. Deep learning based methods are gaining attention, but their
opaque nature compromises their acceptance in the clinical context, where
transparency in the decision making is key. In this paper we analyze the
current work in the explainability of AI-assisted embryo analysis models,
identifying the limitations. We also discuss how these models could be
integrated in the clinical context as decision support systems, considering the
needs of clinicians and patients. Finally, we propose guidelines for the sake
of increasing interpretability and trustworthiness, pushing this technology
forward towards established clinical practice.

摘要：體外受精是治療不孕症最廣泛的方法之一。其主要挑戰之一是評估和選擇胚胎進行植入，此過程具有很大的臨床間和臨床內變異性。基於深度學習的方法正受到關注，但其不透明的性質會影響其在臨床環境中的接受度，而透明度在決策制定中至關重要。在本文中，我們分析了 AI 輔助胚胎分析模型的可解釋性方面的現有工作，並找出其局限性。我們還討論了如何將這些模型作為決策支持系統整合到臨床環境中，同時考慮臨床醫生和患者的需求。最後，我們提出了提高可解釋性和可信度的準則，推進這項技術朝著既定的臨床實務邁進。

##### **A New Perspective on Evaluation Methods for Explainable Artificial Intelligence (XAI)**
2307.14246v1 by Timo Speith, Markus Langer

Within the field of Requirements Engineering (RE), the increasing
significance of Explainable Artificial Intelligence (XAI) in aligning
AI-supported systems with user needs, societal expectations, and regulatory
standards has garnered recognition. In general, explainability has emerged as
an important non-functional requirement that impacts system quality. However,
the supposed trade-off between explainability and performance challenges the
presumed positive influence of explainability. If meeting the requirement of
explainability entails a reduction in system performance, then careful
consideration must be given to which of these quality aspects takes precedence
and how to compromise between them. In this paper, we critically examine the
alleged trade-off. We argue that it is best approached in a nuanced way that
incorporates resource availability, domain characteristics, and considerations
of risk. By providing a foundation for future research and best practices, this
work aims to advance the field of RE for AI.

摘要：在需求工程 (RE) 領域中，可解釋人工智慧 (XAI) 在將 AI 支持的系統與使用者需求、社會期望和法規標準相符方面的重要性日益顯著，已獲得認可。一般來說，可解釋性已成為影響系統品質的重要非功能需求。然而，可解釋性與效能之間的假定權衡挑戰了可解釋性的假定正面影響。如果滿足可解釋性的需求需要降低系統效能，那麼必須仔細考慮這些品質面向中哪一個優先，以及如何在它們之間進行折衷。在本文中，我們批判性地探討了這種假定的權衡。我們認為，最好的方法是以一種細緻的方式來處理，這種方式包含資源可用性、領域特性和風險考量。透過提供未來研究和最佳實務的基礎，這項工作旨在提升 AI 的 RE 領域。

##### **Revisiting the Performance-Explainability Trade-Off in Explainable Artificial Intelligence (XAI)**
2307.14239v1 by Barnaby Crook, Maximilian Schlüter, Timo Speith

Within the field of Requirements Engineering (RE), the increasing
significance of Explainable Artificial Intelligence (XAI) in aligning
AI-supported systems with user needs, societal expectations, and regulatory
standards has garnered recognition. In general, explainability has emerged as
an important non-functional requirement that impacts system quality. However,
the supposed trade-off between explainability and performance challenges the
presumed positive influence of explainability. If meeting the requirement of
explainability entails a reduction in system performance, then careful
consideration must be given to which of these quality aspects takes precedence
and how to compromise between them. In this paper, we critically examine the
alleged trade-off. We argue that it is best approached in a nuanced way that
incorporates resource availability, domain characteristics, and considerations
of risk. By providing a foundation for future research and best practices, this
work aims to advance the field of RE for AI.

摘要：在需求工程（RE）领域，可解释人工智能（XAI）在将人工智能支持的系统与用户需求、社会期望和监管标准相一致方面的重要性日益凸显，并获得了认可。一般来说，可解释性已成为影响系统质量的重要非功能性需求。然而，可解释性和性能之间的权衡挑战了可解释性的正面影响。如果满足可解释性的要求需要降低系统性能，那么必须仔细考虑这些质量方面中的哪一个优先，以及如何在它们之间进行权衡。在本文中，我们批判性地考察了所谓的权衡。我们认为，最好以一种细致入微的方式来处理它，这种方式结合了资源可用性、领域特征和风险考虑。通过为未来的研究和最佳实践提供基础，这项工作旨在推进人工智能的 RE 领域。

##### **Acceptable risks in Europe's proposed AI Act: Reasonableness and other principles for deciding how much risk management is enough**
2308.02047v1 by Henry Fraser, Jose-Miguel Bello y Villarino

This paper critically evaluates the European Commission's proposed AI Act's
approach to risk management and risk acceptability for high-risk AI systems
that pose risks to fundamental rights and safety. The Act aims to promote
"trustworthy" AI with a proportionate regulatory burden. Its provisions on risk
acceptability require residual risks from high-risk systems to be reduced or
eliminated "as far as possible", having regard to the "state of the art". This
criterion, especially if interpreted narrowly, is unworkable and promotes
neither proportionate regulatory burden, nor trustworthiness. By contrast the
Parliament's most recent draft amendments to the risk management provisions
introduce "reasonableness", cost-benefit analysis, and are more transparent
about the value-laden and contextual nature of risk acceptability judgements.
This paper argues that the Parliament's approach is more workable, and better
balances the goals of proportionality and trustworthiness. It explains what
reasonableness in risk acceptability judgments would entail, drawing on
principles from negligence law and European medical devices regulation. And it
contends that the approach to risk acceptability judgments need a firm
foundation of civic legitimacy: including detailed guidance or involvement from
regulators, and meaningful input from affected stakeholders.

摘要：本文嚴格評估歐洲委員會提出的 AI 法案對風險管理和風險可接受性的方法，用於對基本權利和安全構成風險的高風險 AI 系統。該法案旨在以相稱的監管負擔促進「值得信賴」的 AI。其關於風險可接受性的條款要求將高風險系統的殘餘風險減低或消除「盡可能」，並考慮「技術狀態」。此準則，特別是如果狹義解釋，無法執行，既不促進相稱的監管負擔，也不促進可信賴性。相比之下，議會對風險管理條款的最新修正草案引入了「合理性」、成本效益分析，並且更透明地說明了風險可接受性判斷的價值觀和背景性質。本文論證議會的方法更可行，且能更好地平衡相稱性和可信賴性的目標。本文說明風險可接受性判斷中的合理性會帶來什麼，並根據過失法和歐洲醫療器材法規中的原則進行說明。本文主張風險可接受性判斷的方法需要穩固的公民合法性基礎：包括監管機構的詳細指導或參與，以及受影響利害關係人的有意義投入。

##### **eXplainable Artificial Intelligence (XAI) in aging clock models**
2307.13704v3 by Alena Kalyakulina, Igor Yusipov, Alexey Moskalev, Claudio Franceschi, Mikhail Ivanchenko

eXplainable Artificial Intelligence (XAI) is a rapidly progressing field of
machine learning, aiming to unravel the predictions of complex models. XAI is
especially required in sensitive applications, e.g. in health care, when
diagnosis, recommendations and treatment choices might rely on the decisions
made by artificial intelligence systems. AI approaches have become widely used
in aging research as well, in particular, in developing biological clock models
and identifying biomarkers of aging and age-related diseases. However, the
potential of XAI here awaits to be fully appreciated. We discuss the
application of XAI for developing the "aging clocks" and present a
comprehensive analysis of the literature categorized by the focus on particular
physiological systems.

摘要：可解釋人工智慧 (XAI) 是機器學習中快速進展的領域，旨在解開複雜模型的預測。XAI 在敏感應用中特別需要，例如在醫療保健中，當診斷、建議和治療選擇可能依賴於人工智慧系統做出的決策時。人工智慧方法也已廣泛用於老化研究，特別是在開發生物時鐘模型和識別老化和與年齡相關疾病的生物標誌物方面。然而，這裡 XAI 的潛力有待充分認識。我們討論了 XAI 在開發「老化時鐘」方面的應用，並對按特定生理系統的重點分類的文獻進行了全面的分析。

##### **Interpreting and Correcting Medical Image Classification with PIP-Net**
2307.10404v2 by Meike Nauta, Johannes H. Hegeman, Jeroen Geerdink, Jörg Schlötterer, Maurice van Keulen, Christin Seifert

Part-prototype models are explainable-by-design image classifiers, and a
promising alternative to black box AI. This paper explores the applicability
and potential of interpretable machine learning, in particular PIP-Net, for
automated diagnosis support on real-world medical imaging data. PIP-Net learns
human-understandable prototypical image parts and we evaluate its accuracy and
interpretability for fracture detection and skin cancer diagnosis. We find that
PIP-Net's decision making process is in line with medical classification
standards, while only provided with image-level class labels. Because of
PIP-Net's unsupervised pretraining of prototypes, data quality problems such as
undesired text in an X-ray or labelling errors can be easily identified.
Additionally, we are the first to show that humans can manually correct the
reasoning of PIP-Net by directly disabling undesired prototypes. We conclude
that part-prototype models are promising for medical applications due to their
interpretability and potential for advanced model debugging.

摘要：部分原型模型是可解釋設計的影像分類器，也是黑箱 AI 的一個有前途的替代方案。這篇論文探討了解釋性機器學習，特別是 PIP-Net，在真實世界醫學影像資料上自動化診斷支援的適用性和潛力。PIP-Net 學習人類可理解的原型影像部分，我們評估其在骨折檢測和皮膚癌診斷方面的準確性和可解釋性。我們發現 PIP-Net 的決策制定過程符合醫學分類標準，同時僅提供影像層級類別標籤。由於 PIP-Net 對原型的無監督預訓練，因此可以輕鬆識別資料品質問題，例如 X 光中的不需要文字或標籤錯誤。此外，我們首次展示人類可以透過直接停用不需要的原型來手動修正 PIP-Net 的推理。我們得出結論，部分原型模型由於其可解釋性和進階模型除錯的潛力，因此有望應用於醫療。

##### **Explaining and visualizing black-box models through counterfactual paths**
2307.07764v3 by Bastian Pfeifer, Mateusz Krzyzinski, Hubert Baniecki, Anna Saranti, Andreas Holzinger, Przemyslaw Biecek

Explainable AI (XAI) is an increasingly important area of machine learning
research, which aims to make black-box models transparent and interpretable. In
this paper, we propose a novel approach to XAI that uses the so-called
counterfactual paths generated by conditional permutations of features. The
algorithm measures feature importance by identifying sequential permutations of
features that most influence changes in model predictions. It is particularly
suitable for generating explanations based on counterfactual paths in knowledge
graphs incorporating domain knowledge. Counterfactual paths introduce an
additional graph dimension to current XAI methods in both explaining and
visualizing black-box models. Experiments with synthetic and medical data
demonstrate the practical applicability of our approach.

摘要：可解釋 AI (XAI) 是機器學習研究中日益重要的領域，其目標是讓黑箱模型透明且可解釋。在本文中，我們提出了一種新的 XAI 方法，該方法使用由特徵條件置換產生的所謂反事實路徑。該演算法透過識別特徵的順序置換來衡量特徵重要性，這些置換最能影響模型預測的變化。它特別適合根據包含領域知識的知識圖譜中的反事實路徑來產生解釋。反事實路徑在解釋和視覺化黑箱模型時，為目前的 XAI 方法引入了額外的圖形維度。使用合成和醫療資料進行的實驗證明了我們方法的實用適用性。

