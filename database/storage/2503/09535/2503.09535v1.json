{"2503.09535": {"publish_time": "2025-03-12", "title": "Evaluating Visual Explanations of Attention Maps for Transformer-based Medical Imaging", "paper_summary": "Although Vision Transformers (ViTs) have recently demonstrated superior\nperformance in medical imaging problems, they face explainability issues\nsimilar to previous architectures such as convolutional neural networks. Recent\nresearch efforts suggest that attention maps, which are part of decision-making\nprocess of ViTs can potentially address the explainability issue by identifying\nregions influencing predictions, especially in models pretrained with\nself-supervised learning. In this work, we compare the visual explanations of\nattention maps to other commonly used methods for medical imaging problems. To\ndo so, we employ four distinct medical imaging datasets that involve the\nidentification of (1) colonic polyps, (2) breast tumors, (3) esophageal\ninflammation, and (4) bone fractures and hardware implants. Through large-scale\nexperiments on the aforementioned datasets using various supervised and\nself-supervised pretrained ViTs, we find that although attention maps show\npromise under certain conditions and generally surpass GradCAM in\nexplainability, they are outperformed by transformer-specific interpretability\nmethods. Our findings indicate that the efficacy of attention maps as a method\nof interpretability is context-dependent and may be limited as they do not\nconsistently provide the comprehensive insights required for robust medical\ndecision-making.", "paper_summary_zh": "<paragraph>\u96d6\u7136\u8996\u89ba Transformer (ViT) \u8fd1\u671f\u5728\u91ab\u5b78\u5f71\u50cf\u554f\u984c\u4e2d\u5c55\u73fe\u51fa\u512a\u7570\u7684\u6548\u80fd\uff0c\u4f46\u5b83\u5011\u4e5f\u9762\u81e8\u8457\u8207\u5148\u524d\u67b6\u69cb\uff08\u5982\u5377\u7a4d\u795e\u7d93\u7db2\u8def\uff09\u985e\u4f3c\u7684\u53ef\u89e3\u91cb\u6027\u554f\u984c\u3002\u8fd1\u671f\u7684\u7814\u7a76\u6307\u51fa\uff0c\u6ce8\u610f\u529b\u5716\u8b5c\u4f5c\u70ba ViT \u6c7a\u7b56\u904e\u7a0b\u7684\u4e00\u90e8\u5206\uff0c\u6709\u53ef\u80fd\u900f\u904e\u8b58\u5225\u5f71\u97ff\u9810\u6e2c\u7684\u5340\u57df\u4f86\u89e3\u6c7a\u53ef\u89e3\u91cb\u6027\u554f\u984c\uff0c\u5c24\u5176\u662f\u5728\u4f7f\u7528\u81ea\u76e3\u7763\u5b78\u7fd2\u9810\u8a13\u7df4\u7684\u6a21\u578b\u4e2d\u3002\u5728\u9019\u9805\u5de5\u4f5c\u4e2d\uff0c\u6211\u5011\u5c07\u6ce8\u610f\u529b\u5716\u8b5c\u7684\u8996\u89ba\u89e3\u91cb\u8207\u5176\u4ed6\u5e38\u7528\u65bc\u91ab\u5b78\u5f71\u50cf\u554f\u984c\u7684\u65b9\u6cd5\u9032\u884c\u4e86\u6bd4\u8f03\u3002\u70ba\u6b64\uff0c\u6211\u5011\u4f7f\u7528\u4e86\u56db\u500b\u4e0d\u540c\u7684\u91ab\u5b78\u5f71\u50cf\u6578\u64da\u96c6\uff0c\u9019\u4e9b\u6578\u64da\u96c6\u6d89\u53ca\u8b58\u5225 (1) \u7d50\u8178\u606f\u8089\u3001(2) \u4e73\u817a\u816b\u7624\u3001(3) \u98df\u9053\u767c\u708e\u548c (4) \u9aa8\u6298\u548c\u786c\u4ef6\u690d\u5165\u7269\u3002\u900f\u904e\u4f7f\u7528\u5404\u7a2e\u76e3\u7763\u5f0f\u548c\u81ea\u76e3\u7763\u5f0f\u9810\u8a13\u7df4 ViT \u5c0d\u4e0a\u8ff0\u6578\u64da\u96c6\u9032\u884c\u5927\u898f\u6a21\u5be6\u9a57\uff0c\u6211\u5011\u767c\u73fe\u5118\u7ba1\u6ce8\u610f\u529b\u5716\u8b5c\u5728\u67d0\u4e9b\u689d\u4ef6\u4e0b\u986f\u793a\u51fa\u826f\u597d\u7684\u524d\u666f\uff0c\u4e26\u4e14\u5728\u53ef\u89e3\u91cb\u6027\u65b9\u9762\u901a\u5e38\u512a\u65bc GradCAM\uff0c\u4f46\u5b83\u5011\u7684\u8868\u73fe\u4e0d\u5982 Transformer \u5c08\u7528\u7684\u53ef\u89e3\u91cb\u6027\u65b9\u6cd5\u3002\u6211\u5011\u7684\u7814\u7a76\u7d50\u679c\u8868\u660e\uff0c\u6ce8\u610f\u529b\u5716\u8b5c\u4f5c\u70ba\u4e00\u7a2e\u53ef\u89e3\u91cb\u6027\u65b9\u6cd5\u7684\u6709\u6548\u6027\u53d6\u6c7a\u65bc\u5177\u9ad4\u60c5\u6cc1\uff0c\u4e26\u4e14\u53ef\u80fd\u5b58\u5728\u5c40\u9650\u6027\uff0c\u56e0\u70ba\u5b83\u5011\u7121\u6cd5\u59cb\u7d42\u5982\u4e00\u5730\u63d0\u4f9b\u53ef\u9760\u91ab\u5b78\u6c7a\u7b56\u6240\u9700\u7684\u5168\u9762\u898b\u89e3\u3002</paragraph>\n", "author": "Minjae Chung et.al.", "authors": "Minjae Chung, Jong Bum Won, Ganghyun Kim, Yujin Kim, Utku Ozbulak", "id": "2503.09535v1", "paper_url": "http://arxiv.org/abs/2503.09535v1", "repo": "null"}}