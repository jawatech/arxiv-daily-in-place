{"2307.10404": {"publish_time": "2023-07-19", "title": "Interpreting and Correcting Medical Image Classification with PIP-Net", "paper_summary": "Part-prototype models are explainable-by-design image classifiers, and a\npromising alternative to black box AI. This paper explores the applicability\nand potential of interpretable machine learning, in particular PIP-Net, for\nautomated diagnosis support on real-world medical imaging data. PIP-Net learns\nhuman-understandable prototypical image parts and we evaluate its accuracy and\ninterpretability for fracture detection and skin cancer diagnosis. We find that\nPIP-Net's decision making process is in line with medical classification\nstandards, while only provided with image-level class labels. Because of\nPIP-Net's unsupervised pretraining of prototypes, data quality problems such as\nundesired text in an X-ray or labelling errors can be easily identified.\nAdditionally, we are the first to show that humans can manually correct the\nreasoning of PIP-Net by directly disabling undesired prototypes. We conclude\nthat part-prototype models are promising for medical applications due to their\ninterpretability and potential for advanced model debugging.", "paper_summary_zh": "", "author": "Meike Nauta et.al.", "authors": "Meike Nauta,Johannes H. Hegeman,Jeroen Geerdink,J\u00f6rg Schl\u00f6tterer,Maurice van Keulen,Christin Seifert", "id": "2307.10404v2", "paper_url": "http://arxiv.org/abs/2307.10404v2", "repo": "https://github.com/m-nauta/pipnet"}}