{"2408.00435": {"publish_time": "2024-08-01", "title": "A Qualitative Study on Using ChatGPT for Software Security: Perception vs. Practicality", "paper_summary": "Artificial Intelligence (AI) advancements have enabled the development of\nLarge Language Models (LLMs) that can perform a variety of tasks with\nremarkable semantic understanding and accuracy. ChatGPT is one such LLM that\nhas gained significant attention due to its impressive capabilities for\nassisting in various knowledge-intensive tasks. Due to the knowledge-intensive\nnature of engineering secure software, ChatGPT's assistance is expected to be\nexplored for security-related tasks during the development/evolution of\nsoftware. To gain an understanding of the potential of ChatGPT as an emerging\ntechnology for supporting software security, we adopted a two-fold approach.\nInitially, we performed an empirical study to analyse the perceptions of those\nwho had explored the use of ChatGPT for security tasks and shared their views\non Twitter. It was determined that security practitioners view ChatGPT as\nbeneficial for various software security tasks, including vulnerability\ndetection, information retrieval, and penetration testing. Secondly, we\ndesigned an experiment aimed at investigating the practicality of this\ntechnology when deployed as an oracle in real-world settings. In particular, we\nfocused on vulnerability detection and qualitatively examined ChatGPT outputs\nfor given prompts within this prominent software security task. Based on our\nanalysis, responses from ChatGPT in this task are largely filled with generic\nsecurity information and may not be appropriate for industry use. To prevent\ndata leakage, we performed this analysis on a vulnerability dataset compiled\nafter the OpenAI data cut-off date from real-world projects covering 40\ndistinct vulnerability types and 12 programming languages. We assert that the\nfindings from this study would contribute to future research aimed at\ndeveloping and evaluating LLMs dedicated to software security.", "paper_summary_zh": "<paragraph>\u4eba\u5de5\u667a\u6167 (AI) \u7684\u9032\u6b65\u4fc3\u6210\u4e86\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u7684\u767c\u5c55\uff0c\u6b64\u6a21\u578b\u53ef\u4ee5\u57f7\u884c\u5404\u7a2e\u4efb\u52d9\uff0c\u5177\u5099\u5353\u8d8a\u7684\u8a9e\u610f\u7406\u89e3\u548c\u6e96\u78ba\u5ea6\u3002ChatGPT \u5c31\u662f\u5176\u4e2d\u4e00\u500b\u5927\u578b\u8a9e\u8a00\u6a21\u578b\uff0c\u7531\u65bc\u5176\u5728\u5354\u52a9\u5404\u7a2e\u77e5\u8b58\u5bc6\u96c6\u578b\u4efb\u52d9\u65b9\u9762\u5177\u6709\u4ee4\u4eba\u5370\u8c61\u6df1\u523b\u7684\u80fd\u529b\uff0c\u56e0\u6b64\u5099\u53d7\u95dc\u6ce8\u3002\u7531\u65bc\u5de5\u7a0b\u5b89\u5168\u8edf\u9ad4\u7684\u77e5\u8b58\u5bc6\u96c6\u6027\uff0c\u9810\u8a08\u5728\u8edf\u9ad4\u958b\u767c/\u6f14\u9032\u904e\u7a0b\u4e2d\uff0c\u5c07\u63a2\u7d22 ChatGPT \u7684\u5354\u52a9\uff0c\u4ee5\u57f7\u884c\u8207\u5b89\u5168\u76f8\u95dc\u7684\u4efb\u52d9\u3002\u70ba\u4e86\u4e86\u89e3 ChatGPT \u4f5c\u70ba\u652f\u63f4\u8edf\u9ad4\u5b89\u5168\u7684\u65b0\u8208\u6280\u8853\u7684\u6f5b\u529b\uff0c\u6211\u5011\u63a1\u53d6\u4e86\u96d9\u7ba1\u9f4a\u4e0b\u7684\u65b9\u6cd5\u3002\u6700\u521d\uff0c\u6211\u5011\u9032\u884c\u4e86\u4e00\u9805\u5be6\u8b49\u7814\u7a76\uff0c\u4ee5\u5206\u6790\u90a3\u4e9b\u5df2\u7d93\u63a2\u7d22\u5c07 ChatGPT \u7528\u65bc\u5b89\u5168\u4efb\u52d9\u7684\u4eba\u7684\u770b\u6cd5\uff0c\u4e26\u5728 Twitter \u4e0a\u5206\u4eab\u4ed6\u5011\u7684\u89c0\u9ede\u3002\u78ba\u5b9a\u5b89\u5168\u5f9e\u696d\u4eba\u54e1\u5c07 ChatGPT \u8996\u70ba\u5c0d\u5404\u7a2e\u8edf\u9ad4\u5b89\u5168\u4efb\u52d9\u6709\u76ca\uff0c\u5305\u62ec\u6f0f\u6d1e\u5075\u6e2c\u3001\u8cc7\u8a0a\u64f7\u53d6\u548c\u6ef2\u900f\u6e2c\u8a66\u3002\u5176\u6b21\uff0c\u6211\u5011\u8a2d\u8a08\u4e86\u4e00\u500b\u5be6\u9a57\uff0c\u65e8\u5728\u8abf\u67e5\u5728\u73fe\u5be6\u4e16\u754c\u4e2d\u5c07\u6b64\u6280\u8853\u90e8\u7f72\u70ba\u795e\u8aed\u6642\u7684\u5be6\u7528\u6027\u3002\u7279\u5225\u662f\uff0c\u6211\u5011\u5c08\u6ce8\u65bc\u6f0f\u6d1e\u5075\u6e2c\uff0c\u4e26\u5728\u9019\u500b\u7a81\u51fa\u7684\u8edf\u9ad4\u5b89\u5168\u4efb\u52d9\u4e2d\uff0c\u5c0d ChatGPT \u5c0d\u65bc\u7d66\u5b9a\u63d0\u793a\u7684\u8f38\u51fa\u9032\u884c\u5b9a\u6027\u6aa2\u67e5\u3002\u6839\u64da\u6211\u5011\u7684\u5206\u6790\uff0cChatGPT \u5728\u6b64\u4efb\u52d9\u4e2d\u7684\u56de\u61c9\u5728\u5f88\u5927\u7a0b\u5ea6\u4e0a\u5145\u65a5\u8457\u4e00\u822c\u7684\u5b89\u5168\u8cc7\u8a0a\uff0c\u53ef\u80fd\u4e0d\u9069\u5408\u7522\u696d\u4f7f\u7528\u3002\u70ba\u4e86\u9632\u6b62\u8cc7\u6599\u5916\u6d29\uff0c\u6211\u5011\u5728 OpenAI \u8cc7\u6599\u622a\u6b62\u65e5\u671f\u5f8c\u7de8\u8b6f\u7684\u6f0f\u6d1e\u8cc7\u6599\u96c6\u4e0a\u57f7\u884c\u6b64\u5206\u6790\uff0c\u8a72\u8cc7\u6599\u96c6\u6db5\u84cb\u4e86\u4f86\u81ea\u73fe\u5be6\u4e16\u754c\u5c08\u6848\u7684 40 \u7a2e\u4e0d\u540c\u7684\u6f0f\u6d1e\u985e\u578b\u548c 12 \u7a2e\u7a0b\u5f0f\u8a9e\u8a00\u3002\u6211\u5011\u65b7\u8a00\uff0c\u9019\u9805\u7814\u7a76\u7684\u767c\u73fe\u5c07\u6709\u52a9\u65bc\u672a\u4f86\u7684\u7814\u7a76\uff0c\u76ee\u7684\u662f\u958b\u767c\u548c\u8a55\u4f30\u5c08\u9580\u7528\u65bc\u8edf\u9ad4\u5b89\u5168\u7684 LLM\u3002</paragraph>", "author": "M. Mehdi Kholoosi et.al.", "authors": "M. Mehdi Kholoosi, M. Ali Babar, Roland Croft", "id": "2408.00435v1", "paper_url": "http://arxiv.org/abs/2408.00435v1", "repo": "null"}}