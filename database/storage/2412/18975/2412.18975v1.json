{"2412.18975": {"publish_time": "2024-12-25", "title": "Injecting Bias into Text Classification Models using Backdoor Attacks", "paper_summary": "The rapid growth of natural language processing (NLP) and pre-trained\nlanguage models have enabled accurate text classification in a variety of\nsettings. However, text classification models are susceptible to backdoor\nattacks, where an attacker embeds a trigger into the victim model to make the\nmodel predict attacker-desired labels in targeted scenarios. In this paper, we\npropose to utilize backdoor attacks for a new purpose: bias injection. We\ndevelop a backdoor attack in which a subset of the training dataset is poisoned\nto associate strong male actors with negative sentiment. We execute our attack\non two popular text classification datasets (IMDb and SST) and seven different\nmodels ranging from traditional Doc2Vec-based models to LSTM networks and\nmodern transformer-based BERT and RoBERTa models. Our results show that the\nreduction in backdoored models' benign classification accuracy is limited,\nimplying that our attacks remain stealthy, whereas the models successfully\nlearn to associate strong male actors with negative sentiment (100% attack\nsuccess rate with >= 3% poison rate). Attacks on BERT and RoBERTa are\nparticularly more stealthy and effective, demonstrating an increased risk of\nusing modern and larger models. We also measure the generalizability of our\nbias injection by proposing two metrics: (i) U-BBSR which uses previously\nunseen words when measuring attack success, and (ii) P-BBSR which measures\nattack success using paraphrased test samples. U-BBSR and P-BBSR results show\nthat the bias injected by our attack can go beyond memorizing a trigger phrase.", "paper_summary_zh": "\u81ea\u7136\u8a9e\u8a00\u8655\u7406 (NLP) \u548c\u9810\u5148\u8a13\u7df4\u8a9e\u8a00\u6a21\u578b\u7684\u5feb\u901f\u767c\u5c55\uff0c\u5df2\u80fd\u8b93\u5404\u7a2e\u8a2d\u5b9a\u4e0b\u6e96\u78ba\u5730\u9032\u884c\u6587\u5b57\u5206\u985e\u3002\u7136\u800c\uff0c\u6587\u5b57\u5206\u985e\u6a21\u578b\u5bb9\u6613\u53d7\u5230\u5f8c\u9580\u653b\u64ca\uff0c\u653b\u64ca\u8005\u6703\u5728\u53d7\u5bb3\u8005\u6a21\u578b\u4e2d\u5d4c\u5165\u89f8\u767c\u5668\uff0c\u8b93\u6a21\u578b\u5728\u76ee\u6a19\u60c5\u5883\u4e2d\u9810\u6e2c\u653b\u64ca\u8005\u60f3\u8981\u7684\u6a19\u7c64\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u63d0\u8b70\u5c07\u5f8c\u9580\u653b\u64ca\u7528\u65bc\u4e00\u500b\u65b0\u76ee\u7684\uff1a\u504f\u5dee\u6ce8\u5165\u3002\u6211\u5011\u767c\u5c55\u4e86\u4e00\u7a2e\u5f8c\u9580\u653b\u64ca\uff0c\u5176\u4e2d\u8a13\u7df4\u8cc7\u6599\u96c6\u7684\u5b50\u96c6\u88ab\u4e0b\u6bd2\uff0c\u5c07\u5f37\u52e2\u7537\u6027\u6f14\u54e1\u8207\u8ca0\u9762\u60c5\u7dd2\u806f\u7e6b\u5728\u4e00\u8d77\u3002\u6211\u5011\u5c0d\u5169\u500b\u6d41\u884c\u7684\u6587\u5b57\u5206\u985e\u8cc7\u6599\u96c6 (IMDb \u548c SST) \u548c\u4e03\u500b\u4e0d\u540c\u7684\u6a21\u578b\u57f7\u884c\u6211\u5011\u7684\u653b\u64ca\uff0c\u9019\u4e9b\u6a21\u578b\u5f9e\u50b3\u7d71\u7684 Doc2Vec \u6a21\u578b\u5230 LSTM \u7db2\u8def\uff0c\u4ee5\u53ca\u73fe\u4ee3\u7684\u57fa\u65bc transformer \u7684 BERT \u548c RoBERTa \u6a21\u578b\u3002\u6211\u5011\u7684\u7d50\u679c\u986f\u793a\uff0c\u5f8c\u9580\u6a21\u578b\u7684\u826f\u6027\u5206\u985e\u6e96\u78ba\u5ea6\u4e0b\u964d\u6709\u9650\uff0c\u9019\u8868\u793a\u6211\u5011\u7684\u653b\u64ca\u4ecd\u7136\u96b1\u853d\uff0c\u800c\u6a21\u578b\u6210\u529f\u5b78\u6703\u5c07\u5f37\u52e2\u7537\u6027\u6f14\u54e1\u8207\u8ca0\u9762\u60c5\u7dd2\u806f\u7e6b\u5728\u4e00\u8d77\uff08\u653b\u64ca\u6210\u529f\u7387 100%\uff0c\u4e2d\u6bd2\u7387 >= 3%\uff09\u3002\u5c0d BERT \u548c RoBERTa \u7684\u653b\u64ca\u7279\u5225\u96b1\u853d\u4e14\u6709\u6548\uff0c\u986f\u793a\u51fa\u4f7f\u7528\u73fe\u4ee3\u5316\u4e14\u8f03\u5927\u6a21\u578b\u7684\u98a8\u96aa\u589e\u52a0\u3002\u6211\u5011\u4e5f\u900f\u904e\u63d0\u51fa\u5169\u500b\u6307\u6a19\u4f86\u8861\u91cf\u6211\u5011\u7684\u504f\u5dee\u6ce8\u5165\u7684\u6982\u62ec\u6027\uff1a(i) U-BBSR\uff0c\u5728\u8861\u91cf\u653b\u64ca\u6210\u529f\u6642\u4f7f\u7528\u5148\u524d\u672a\u898b\u904e\u7684\u5b57\u8a5e\uff0c\u4ee5\u53ca (ii) P-BBSR\uff0c\u4f7f\u7528\u6539\u5beb\u7684\u6e2c\u8a66\u6a23\u672c\u4f86\u8861\u91cf\u653b\u64ca\u6210\u529f\u3002U-BBSR \u548c P-BBSR \u7684\u7d50\u679c\u986f\u793a\uff0c\u6211\u5011\u7684\u653b\u64ca\u6ce8\u5165\u7684\u504f\u5dee\u53ef\u4ee5\u8d85\u8d8a\u8a18\u61b6\u89f8\u767c\u8a5e\u7d44\u3002", "author": "A. Dilara Yavuz et.al.", "authors": "A. Dilara Yavuz, M. Emre Gursoy", "id": "2412.18975v1", "paper_url": "http://arxiv.org/abs/2412.18975v1", "repo": "null"}}