{"2410.01769": {"publish_time": "2024-10-02", "title": "Quantifying Generalization Complexity for Large Language Models", "paper_summary": "While large language models (LLMs) have shown exceptional capabilities in\nunderstanding complex queries and performing sophisticated tasks, their\ngeneralization abilities are often deeply entangled with memorization,\nnecessitating more precise evaluation. To address this challenge, we introduce\nScylla, a dynamic evaluation framework that quantitatively measures the\ngeneralization abilities of LLMs. Scylla disentangles generalization from\nmemorization via assessing model performance on both in-distribution (ID) and\nout-of-distribution (OOD) data through 20 tasks across 5 levels of complexity.\nThrough extensive experiments, we uncover a non-monotonic relationship between\ntask complexity and the performance gap between ID and OOD data, which we term\nthe generalization valley. Specifically, this phenomenon reveals a critical\nthreshold - referred to as critical complexity - where reliance on\nnon-generalizable behavior peaks, indicating the upper bound of LLMs'\ngeneralization capabilities. As model size increases, the critical complexity\nshifts toward higher levels of task complexity, suggesting that larger models\ncan handle more complex reasoning tasks before over-relying on memorization.\nLeveraging Scylla and the concept of critical complexity, we benchmark 28LLMs\nincluding both open-sourced models such as LLaMA and Qwen families, and\nclose-sourced models like Claude and GPT, providing a more robust evaluation\nand establishing a clearer understanding of LLMs' generalization capabilities.", "paper_summary_zh": "\u5118\u7ba1\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u5728\u7406\u89e3\u8907\u96dc\u67e5\u8a62\u548c\u57f7\u884c\u7cbe\u7d30\u4efb\u52d9\u65b9\u9762\u5c55\u73fe\u51fa\u975e\u51e1\u7684\u80fd\u529b\uff0c\u4f46\u5176\u6cdb\u5316\u80fd\u529b\u901a\u5e38\u8207\u8a18\u61b6\u529b\u7dca\u5bc6\u76f8\u9023\uff0c\u56e0\u800c\u9700\u8981\u66f4\u7cbe\u78ba\u7684\u8a55\u4f30\u3002\u70ba\u4e86\u61c9\u5c0d\u9019\u9805\u6311\u6230\uff0c\u6211\u5011\u5f15\u5165\u4e86 Scylla\uff0c\u4e00\u500b\u52d5\u614b\u8a55\u4f30\u67b6\u69cb\uff0c\u7528\u65bc\u91cf\u5316\u8861\u91cf LLM \u7684\u6cdb\u5316\u80fd\u529b\u3002Scylla \u900f\u904e\u8a55\u4f30\u6a21\u578b\u5728\u5206\u4f48\u5167 (ID) \u548c\u5206\u4f48\u5916 (OOD) \u8cc7\u6599\u4e0a\u7684\u6548\u80fd\uff0c\u5728 5 \u500b\u8907\u96dc\u5ea6\u5c64\u7d1a\u4e2d\u57f7\u884c 20 \u9805\u4efb\u52d9\uff0c\u5f9e\u800c\u5c07\u6cdb\u5316\u8207\u8a18\u61b6\u529b\u5340\u5206\u958b\u4f86\u3002\u900f\u904e\u5ee3\u6cdb\u7684\u5be6\u9a57\uff0c\u6211\u5011\u767c\u73fe\u4efb\u52d9\u8907\u96dc\u5ea6\u8207 ID \u8cc7\u6599\u548c OOD \u8cc7\u6599\u4e4b\u9593\u7684\u6548\u80fd\u5dee\u8ddd\u4e4b\u9593\u5b58\u5728\u975e\u55ae\u8abf\u95dc\u4fc2\uff0c\u6211\u5011\u7a31\u4e4b\u70ba\u6cdb\u5316\u8c37\u3002\u5177\u9ad4\u4f86\u8aaa\uff0c\u9019\u7a2e\u73fe\u8c61\u63ed\u793a\u4e86\u4e00\u500b\u81e8\u754c\u95be\u503c\uff0c\u7a31\u70ba\u81e8\u754c\u8907\u96dc\u5ea6\uff0c\u5728\u8a72\u95be\u503c\u4e0a\u5c0d\u4e0d\u53ef\u6cdb\u5316\u7684\u884c\u70ba\u7684\u4f9d\u8cf4\u9054\u5230\u9ad8\u5cf0\uff0c\u8868\u660e LLM \u6cdb\u5316\u80fd\u529b\u7684\u4e0a\u9650\u3002\u96a8\u8457\u6a21\u578b\u898f\u6a21\u7684\u589e\u52a0\uff0c\u81e8\u754c\u8907\u96dc\u5ea6\u8f49\u79fb\u5230\u66f4\u9ad8\u7684\u4efb\u52d9\u8907\u96dc\u5ea6\u5c64\u7d1a\uff0c\u9019\u8868\u660e\u5728\u904e\u5ea6\u4f9d\u8cf4\u8a18\u61b6\u529b\u4e4b\u524d\uff0c\u8f03\u5927\u7684\u6a21\u578b\u53ef\u4ee5\u8655\u7406\u66f4\u8907\u96dc\u7684\u63a8\u7406\u4efb\u52d9\u3002\u5229\u7528 Scylla \u548c\u81e8\u754c\u8907\u96dc\u5ea6\u7684\u6982\u5ff5\uff0c\u6211\u5011\u5c0d 28 \u500b LLM \u9032\u884c\u57fa\u6e96\u6e2c\u8a66\uff0c\u5305\u62ec\u958b\u653e\u539f\u59cb\u78bc\u6a21\u578b\uff08\u4f8b\u5982 LLaMA \u548c Qwen \u7cfb\u5217\uff09\uff0c\u4ee5\u53ca\u5c01\u9589\u539f\u59cb\u78bc\u6a21\u578b\uff08\u4f8b\u5982 Claude \u548c GPT\uff09\uff0c\u63d0\u4f9b\u66f4\u7a69\u5065\u7684\u8a55\u4f30\uff0c\u4e26\u66f4\u6e05\u695a\u5730\u4e86\u89e3 LLM \u7684\u6cdb\u5316\u80fd\u529b\u3002", "author": "Zhenting Qi et.al.", "authors": "Zhenting Qi, Hongyin Luo, Xuliang Huang, Zhuokai Zhao, Yibo Jiang, Xiangjun Fan, Himabindu Lakkaraju, James Glass", "id": "2410.01769v2", "paper_url": "http://arxiv.org/abs/2410.01769v2", "repo": "null"}}