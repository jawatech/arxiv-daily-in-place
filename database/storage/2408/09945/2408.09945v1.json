{"2408.09945": {"publish_time": "2024-08-19", "title": "Benchmarking LLMs for Translating Classical Chinese Poetry:Evaluating Adequacy, Fluency, and Elegance", "paper_summary": "Large language models (LLMs) have shown remarkable performance in general\ntranslation tasks. However, the increasing demand for high-quality translations\nthat are not only adequate but also fluent and elegant. To assess the extent to\nwhich current LLMs can meet these demands, we introduce a suitable benchmark\nfor translating classical Chinese poetry into English. This task requires not\nonly adequacy in translating culturally and historically significant content\nbut also a strict adherence to linguistic fluency and poetic elegance. Our\nstudy reveals that existing LLMs fall short of this task. To address these\nissues, we propose RAT, a \\textbf{R}etrieval-\\textbf{A}ugmented machine\n\\textbf{T}ranslation method that enhances the translation process by\nincorporating knowledge related to classical poetry. Additionally, we propose\nan automatic evaluation metric based on GPT-4, which better assesses\ntranslation quality in terms of adequacy, fluency, and elegance, overcoming the\nlimitations of traditional metrics. Our dataset and code will be made\navailable.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u5728\u4e00\u822c\u7ffb\u8b6f\u4efb\u52d9\u4e2d\u5c55\u73fe\u4e86\u5353\u8d8a\u7684\u8868\u73fe\u3002\u7136\u800c\uff0c\u5c0d\u65bc\u9ad8\u54c1\u8cea\u7ffb\u8b6f\u7684\u9700\u6c42\u8207\u65e5\u4ff1\u589e\uff0c\u9019\u4e9b\u7ffb\u8b6f\u4e0d\u50c5\u8981\u6e96\u78ba\uff0c\u9084\u8981\u6d41\u66a2\u4e14\u512a\u96c5\u3002\u70ba\u4e86\u8a55\u4f30\u76ee\u524d LLM \u6eff\u8db3\u9019\u4e9b\u9700\u6c42\u7684\u7a0b\u5ea6\uff0c\u6211\u5011\u91dd\u5c0d\u5c07\u53e4\u5178\u4e2d\u6587\u8a69\u6b4c\u7ffb\u8b6f\u6210\u82f1\u6587\u9019\u9805\u4efb\u52d9\uff0c\u5f15\u9032\u4e86\u4e00\u500b\u5408\u9069\u7684\u57fa\u6e96\u3002\u9019\u9805\u4efb\u52d9\u4e0d\u50c5\u9700\u8981\u6e96\u78ba\u7ffb\u8b6f\u5177\u6709\u6587\u5316\u548c\u6b77\u53f2\u610f\u7fa9\u7684\u5167\u5bb9\uff0c\u9084\u5fc5\u9808\u56b4\u683c\u9075\u5b88\u8a9e\u8a00\u6d41\u66a2\u6027\u548c\u8a69\u6b4c\u512a\u96c5\u6027\u3002\u6211\u5011\u7684\u7814\u7a76\u986f\u793a\uff0c\u73fe\u6709\u7684 LLM \u7121\u6cd5\u52dd\u4efb\u9019\u9805\u4efb\u52d9\u3002\u70ba\u4e86\u89e3\u6c7a\u9019\u4e9b\u554f\u984c\uff0c\u6211\u5011\u63d0\u51fa\u4e86 RAT\uff0c\u4e00\u7a2e\u900f\u904e\u7d0d\u5165\u8207\u53e4\u5178\u8a69\u6b4c\u76f8\u95dc\u7684\u77e5\u8b58\uff0c\u4f86\u589e\u5f37\u7ffb\u8b6f\u6d41\u7a0b\u7684\u300c\u6aa2\u7d22\u8f14\u52a9\u6a5f\u5668\u7ffb\u8b6f\u300d\u65b9\u6cd5\u3002\u6b64\u5916\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u4e00\u7a2e\u57fa\u65bc GPT-4 \u7684\u81ea\u52d5\u8a55\u4f30\u6307\u6a19\uff0c\u5b83\u5728\u5145\u5206\u6027\u3001\u6d41\u66a2\u6027\u548c\u512a\u96c5\u6027\u65b9\u9762\uff0c\u80fd\u66f4\u597d\u5730\u8a55\u4f30\u7ffb\u8b6f\u54c1\u8cea\uff0c\u514b\u670d\u4e86\u50b3\u7d71\u6307\u6a19\u7684\u9650\u5236\u3002\u6211\u5011\u7684\u8cc7\u6599\u96c6\u548c\u7a0b\u5f0f\u78bc\u5c07\u6703\u516c\u958b\u3002", "author": "Andong Chen et.al.", "authors": "Andong Chen, Lianzhang Lou, Kehai Chen, Xuefeng Bai, Yang Xiang, Muyun Yang, Tiejun Zhao, Min Zhang", "id": "2408.09945v1", "paper_url": "http://arxiv.org/abs/2408.09945v1", "repo": "null"}}