{"2412.18148": {"publish_time": "2024-12-24", "title": "Are We in the AI-Generated Text World Already? Quantifying and Monitoring AIGT on Social Media", "paper_summary": "Social media platforms are experiencing a growing presence of AI-Generated\nTexts (AIGTs). However, the misuse of AIGTs could have profound implications\nfor public opinion, such as spreading misinformation and manipulating\nnarratives. Despite its importance, a systematic study to assess the prevalence\nof AIGTs on social media is still lacking. To address this gap, this paper aims\nto quantify, monitor, and analyze the AIGTs on online social media platforms.\nWe first collect a dataset (SM-D) with around 2.4M posts from 3 major social\nmedia platforms: Medium, Quora, and Reddit. Then, we construct a diverse\ndataset (AIGTBench) to train and evaluate AIGT detectors. AIGTBench combines\npopular open-source datasets and our AIGT datasets generated from social media\ntexts by 12 LLMs, serving as a benchmark for evaluating mainstream detectors.\nWith this setup, we identify the best-performing detector (OSM-Det). We then\napply OSM-Det to SM-D to track AIGTs over time and observe different trends of\nAI Attribution Rate (AAR) across social media platforms from January 2022 to\nOctober 2024. Specifically, Medium and Quora exhibit marked increases in AAR,\nrising from 1.77% to 37.03% and 2.06% to 38.95%, respectively. In contrast,\nReddit shows slower growth, with AAR increasing from 1.31% to 2.45% over the\nsame period. Our further analysis indicates that AIGTs differ from\nhuman-written texts across several dimensions, including linguistic patterns,\ntopic distributions, engagement levels, and the follower distribution of\nauthors. We envision our analysis and findings on AIGTs in social media can\nshed light on future research in this domain.", "paper_summary_zh": "<paragraph>\u793e\u7fa4\u5a92\u9ad4\u5e73\u53f0\u4e0a\u51fa\u73fe\u8d8a\u4f86\u8d8a\u591a\u7531 AI \u6240\u7522\u751f\u7684\u6587\u5b57 (AIGT)\u3002\u7136\u800c\uff0cAIGT \u7684\u8aa4\u7528\u53ef\u80fd\u6703\u5c0d\u8f3f\u8ad6\u9020\u6210\u6df1\u9060\u5f71\u97ff\uff0c\u4f8b\u5982\u6563\u5e03\u932f\u8aa4\u8cc7\u8a0a\u548c\u64cd\u7e31\u6558\u8ff0\u3002\u5118\u7ba1\u5176\u91cd\u8981\u6027\uff0c\u4f46\u4ecd\u7f3a\u4e4f\u7cfb\u7d71\u6027\u7684\u7814\u7a76\u4f86\u8a55\u4f30 AIGT \u5728\u793e\u7fa4\u5a92\u9ad4\u4e0a\u7684\u76db\u884c\u7a0b\u5ea6\u3002\u70ba\u4e86\u89e3\u6c7a\u9019\u500b\u5dee\u8ddd\uff0c\u672c\u6587\u65e8\u5728\u91cf\u5316\u3001\u76e3\u63a7\u548c\u5206\u6790\u7dda\u4e0a\u793e\u7fa4\u5a92\u9ad4\u5e73\u53f0\u4e0a\u7684 AIGT\u3002\u6211\u5011\u9996\u5148\u5f9e 3 \u500b\u4e3b\u8981\u7684\u793e\u7fa4\u5a92\u9ad4\u5e73\u53f0\uff1aMedium\u3001Quora \u548c Reddit \u6536\u96c6\u4e86\u5305\u542b\u7d04 240 \u842c\u5247\u8cbc\u6587\u7684\u8cc7\u6599\u96c6 (SM-D)\u3002\u7136\u5f8c\uff0c\u6211\u5011\u5efa\u69cb\u4e86\u4e00\u500b\u591a\u5143\u5316\u7684\u8cc7\u6599\u96c6 (AIGTBench) \u4f86\u8a13\u7df4\u548c\u8a55\u4f30 AIGT \u5075\u6e2c\u5668\u3002AIGTBench \u7d50\u5408\u4e86\u71b1\u9580\u7684\u958b\u6e90\u8cc7\u6599\u96c6\u548c\u6211\u5011\u5f9e\u793e\u7fa4\u5a92\u9ad4\u6587\u5b57\u4e2d\u751f\u6210\u7684 AIGT \u8cc7\u6599\u96c6\uff0c\u7531 12 \u500b LLM \u7522\u751f\uff0c\u4f5c\u70ba\u8a55\u4f30\u4e3b\u6d41\u5075\u6e2c\u5668\u7684\u57fa\u6e96\u3002\u900f\u904e\u6b64\u8a2d\u5b9a\uff0c\u6211\u5011\u627e\u51fa\u6548\u80fd\u6700\u4f73\u7684\u5075\u6e2c\u5668 (OSM-Det)\u3002\u63a5\u8457\uff0c\u6211\u5011\u5c07 OSM-Det \u5957\u7528\u81f3 SM-D \u4ee5\u8ffd\u8e64 AIGT\uff0c\u4e26\u89c0\u5bdf\u5f9e 2022 \u5e74 1 \u6708\u5230 2024 \u5e74 10 \u6708\u4e0d\u540c\u793e\u7fa4\u5a92\u9ad4\u5e73\u53f0\u7684 AI \u6b78\u56e0\u7387 (AAR) \u8da8\u52e2\u3002\u5177\u9ad4\u4f86\u8aaa\uff0cMedium \u548c Quora \u7684 AAR \u986f\u8457\u589e\u52a0\uff0c\u5206\u5225\u5f9e 1.77% \u4e0a\u5347\u81f3 37.03% \u548c 2.06% \u4e0a\u5347\u81f3 38.95%\u3002\u76f8\u6bd4\u4e4b\u4e0b\uff0cReddit \u7684\u6210\u9577\u8f03\u6162\uff0cAAR \u5728\u540c\u4e00\u6642\u671f\u5f9e 1.31% \u4e0a\u5347\u81f3 2.45%\u3002\u6211\u5011\u7684\u9032\u4e00\u6b65\u5206\u6790\u6307\u51fa\uff0cAIGT \u5728\u8a9e\u8a00\u6a21\u5f0f\u3001\u4e3b\u984c\u5206\u4f48\u3001\u53c3\u8207\u5ea6\u548c\u4f5c\u8005\u7684\u8ffd\u8e64\u8005\u5206\u4f48\u7b49\u591a\u500b\u9762\u5411\u8207\u4eba\u985e\u64b0\u5beb\u7684\u6587\u5b57\u4e0d\u540c\u3002\u6211\u5011\u9810\u898b\u6211\u5011\u5c0d\u793e\u7fa4\u5a92\u9ad4\u4e2d AIGT \u7684\u5206\u6790\u548c\u767c\u73fe\uff0c\u53ef\u4ee5\u70ba\u6b64\u9818\u57df\u7684\u672a\u4f86\u7814\u7a76\u63d0\u4f9b\u555f\u767c\u3002</paragraph>", "author": "Zhen Sun et.al.", "authors": "Zhen Sun, Zongmin Zhang, Xinyue Shen, Ziyi Zhang, Yule Liu, Michael Backes, Yang Zhang, Xinlei He", "id": "2412.18148v1", "paper_url": "http://arxiv.org/abs/2412.18148v1", "repo": "null"}}