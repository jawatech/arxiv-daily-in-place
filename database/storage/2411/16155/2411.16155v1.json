{"2411.16155": {"publish_time": "2024-11-25", "title": "Graph Adapter of EEG Foundation Models for Parameter Efficient Fine Tuning", "paper_summary": "In diagnosing mental diseases from electroencephalography (EEG) data, neural\nnetwork models such as Transformers have been employed to capture temporal\ndynamics. Additionally, it is crucial to learn the spatial relationships\nbetween EEG sensors, for which Graph Neural Networks (GNNs) are commonly used.\nHowever, fine-tuning large-scale complex neural network models simultaneously\nto capture both temporal and spatial features increases computational costs due\nto the more significant number of trainable parameters. It causes the limited\navailability of EEG datasets for downstream tasks, making it challenging to\nfine-tune large models effectively. We propose EEG-GraphAdapter (EGA), a\nparameter-efficient fine-tuning (PEFT) approach to address these challenges.\nEGA is integrated into pre-trained temporal backbone models as a GNN-based\nmodule and fine-tuned itself alone while keeping the backbone model parameters\nfrozen. This enables the acquisition of spatial representations of EEG signals\nfor downstream tasks, significantly reducing computational overhead and data\nrequirements. Experimental evaluations on healthcare-related downstream tasks\nof Major Depressive Disorder and Abnormality Detection demonstrate that our EGA\nimproves performance by up to 16.1% in the F1-score compared with the backbone\nBENDR model.", "paper_summary_zh": "\u5728\u5229\u7528\u8166\u96fb\u5716 (EEG) \u8cc7\u6599\u8a3a\u65b7\u7cbe\u795e\u75be\u75c5\u6642\uff0c\u5df2\u63a1\u7528Transformer\u7b49\u795e\u7d93\u7db2\u8def\u6a21\u578b\u4f86\u6355\u6349\u6642\u9593\u52d5\u614b\u3002\u6b64\u5916\uff0c\u5b78\u7fd2 EEG \u611f\u6e2c\u5668\u4e4b\u9593\u7684\u7a7a\u9593\u95dc\u4fc2\u81f3\u95dc\u91cd\u8981\uff0c\u800c\u5716\u5f62\u795e\u7d93\u7db2\u8def (GNN) \u901a\u5e38\u7528\u65bc\u6b64\u76ee\u7684\u3002\u7136\u800c\uff0c\u540c\u6642\u5fae\u8abf\u5927\u578b\u8907\u96dc\u795e\u7d93\u7db2\u8def\u6a21\u578b\u4ee5\u6355\u6349\u6642\u9593\u548c\u7a7a\u9593\u7279\u5fb5\u6703\u589e\u52a0\u904b\u7b97\u6210\u672c\uff0c\u56e0\u70ba\u53ef\u8a13\u7df4\u53c3\u6578\u6578\u91cf\u8f03\u591a\u3002\u9019\u5c0e\u81f4\u4e0b\u6e38\u4efb\u52d9\u7684 EEG \u8cc7\u6599\u96c6\u53ef\u7528\u6027\u6709\u9650\uff0c\u4f7f\u5f97\u6709\u6548\u5fae\u8abf\u5927\u578b\u6a21\u578b\u5177\u6709\u6311\u6230\u6027\u3002\u6211\u5011\u63d0\u51fa EEG-GraphAdapter (EGA)\uff0c\u4e00\u7a2e\u53c3\u6578\u9ad8\u6548\u5fae\u8abf (PEFT) \u65b9\u6cd5\u4f86\u89e3\u6c7a\u9019\u4e9b\u6311\u6230\u3002EGA \u4f5c\u70ba\u57fa\u65bc GNN \u7684\u6a21\u7d44\u6574\u5408\u5230\u9810\u8a13\u7df4\u7684\u6642\u9593\u4e3b\u5e79\u6a21\u578b\u4e2d\uff0c\u4e26\u5728\u4fdd\u6301\u4e3b\u5e79\u6a21\u578b\u53c3\u6578\u51cd\u7d50\u7684\u540c\u6642\u81ea\u884c\u5fae\u8abf\u3002\u9019\u4f7f\u5f97\u80fd\u5920\u53d6\u5f97 EEG \u8a0a\u865f\u7684\u7a7a\u9593\u8868\u793a\uff0c\u4ee5\u7528\u65bc\u4e0b\u6e38\u4efb\u52d9\uff0c\u5927\u5e45\u964d\u4f4e\u904b\u7b97\u8ca0\u64d4\u548c\u8cc7\u6599\u9700\u6c42\u3002\u5728\u8207\u91ab\u7642\u4fdd\u5065\u76f8\u95dc\u7684\u4e0b\u6e38\u4efb\u52d9\uff08\u91cd\u5ea6\u6182\u9b31\u75c7\u548c\u7570\u5e38\u5075\u6e2c\uff09\u7684\u5be6\u9a57\u8a55\u4f30\u4e2d\uff0c\u6211\u5011\u7684 EGA \u8b49\u660e\u8207\u4e3b\u5e79 BENDR \u6a21\u578b\u76f8\u6bd4\uff0cF1 \u5206\u6578\u7684\u6548\u80fd\u63d0\u5347\u4e86 16.1%\u3002", "author": "Toyotaro Suzumura et.al.", "authors": "Toyotaro Suzumura, Hiroki Kanezashi, Shotaro Akahori", "id": "2411.16155v1", "paper_url": "http://arxiv.org/abs/2411.16155v1", "repo": "null"}}