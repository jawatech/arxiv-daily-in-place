{"2409.09825": {"publish_time": "2024-09-15", "title": "GP-GPT: Large Language Model for Gene-Phenotype Mapping", "paper_summary": "Pre-trained large language models(LLMs) have attracted increasing attention\nin biomedical domains due to their success in natural language processing.\nHowever, the complex traits and heterogeneity of multi-sources genomics data\npose significant challenges when adapting these models to the bioinformatics\nand biomedical field. To address these challenges, we present GP-GPT, the first\nspecialized large language model for genetic-phenotype knowledge representation\nand genomics relation analysis. Our model is fine-tuned in two stages on a\ncomprehensive corpus composed of over 3,000,000 terms in genomics, proteomics,\nand medical genetics, derived from multiple large-scale validated datasets and\nscientific publications. GP-GPT demonstrates proficiency in accurately\nretrieving medical genetics information and performing common genomics analysis\ntasks, such as genomics information retrieval and relationship determination.\nComparative experiments across domain-specific tasks reveal that GP-GPT\noutperforms state-of-the-art LLMs, including Llama2, Llama3 and GPT-4. These\nresults highlight GP-GPT's potential to enhance genetic disease relation\nresearch and facilitate accurate and efficient analysis in the fields of\ngenomics and medical genetics. Our investigation demonstrated the subtle\nchanges of bio-factor entities' representations in the GP-GPT, which suggested\nthe opportunities for the application of LLMs to advancing gene-phenotype\nresearch.", "paper_summary_zh": "\u9810\u5148\u8a13\u7df4\u597d\u7684\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u7531\u65bc\u5728\u81ea\u7136\u8a9e\u8a00\u8655\u7406\u65b9\u9762\u53d6\u5f97\u6210\u529f\uff0c\u56e0\u6b64\u5728\u751f\u7269\u91ab\u5b78\u9818\u57df\u4e2d\u5099\u53d7\u95dc\u6ce8\u3002\n\u7136\u800c\uff0c\u591a\u4f86\u6e90\u57fa\u56e0\u7d44\u6578\u64da\u7684\u8907\u96dc\u7279\u5fb5\u548c\u7570\u8cea\u6027\u5728\u5c07\u9019\u4e9b\u6a21\u578b\u61c9\u7528\u65bc\u751f\u7269\u8cc7\u8a0a\u5b78\u548c\u751f\u7269\u91ab\u5b78\u9818\u57df\u6642\uff0c\u69cb\u6210\u4e86\u91cd\u5927\u6311\u6230\u3002\u70ba\u4e86\u61c9\u5c0d\u9019\u4e9b\u6311\u6230\uff0c\u6211\u5011\u63d0\u51fa\u4e86 GP-GPT\uff0c\u9019\u662f\u7b2c\u4e00\u500b\u7528\u65bc\u907a\u50b3\u8868\u578b\u77e5\u8b58\u8868\u5fb5\u548c\u57fa\u56e0\u7d44\u95dc\u4fc2\u5206\u6790\u7684\u5c08\u696d\u5927\u578b\u8a9e\u8a00\u6a21\u578b\u3002\u6211\u5011\u7684\u6a21\u578b\u5206\u5169\u500b\u968e\u6bb5\u9032\u884c\u5fae\u8abf\uff0c\u4e00\u500b\u7d9c\u5408\u8a9e\u6599\u5eab\u5305\u542b\u8d85\u904e 3,000,000 \u500b\u57fa\u56e0\u7d44\u5b78\u3001\u86cb\u767d\u8cea\u7d44\u5b78\u548c\u91ab\u5b78\u907a\u50b3\u5b78\u4e2d\u7684\u8853\u8a9e\uff0c\u9019\u4e9b\u8853\u8a9e\u4f86\u81ea\u591a\u500b\u7d93\u904e\u9a57\u8b49\u7684\u5927\u898f\u6a21\u6578\u64da\u96c6\u548c\u79d1\u5b78\u51fa\u7248\u7269\u3002GP-GPT \u986f\u793a\u51fa\u6e96\u78ba\u64f7\u53d6\u91ab\u5b78\u907a\u50b3\u5b78\u8cc7\u8a0a\u548c\u57f7\u884c\u5e38\u898b\u57fa\u56e0\u7d44\u5206\u6790\u4efb\u52d9\uff08\u4f8b\u5982\u57fa\u56e0\u7d44\u8cc7\u8a0a\u64f7\u53d6\u548c\u95dc\u4fc2\u78ba\u5b9a\uff09\u7684\u80fd\u529b\u3002\u8de8\u9818\u57df\u7279\u5b9a\u4efb\u52d9\u7684\u6bd4\u8f03\u5be6\u9a57\u986f\u793a\uff0cGP-GPT \u512a\u65bc\u6700\u5148\u9032\u7684 LLM\uff0c\u5305\u62ec Llama2\u3001Llama3 \u548c GPT-4\u3002\u9019\u4e9b\u7d50\u679c\u7a81\u51fa\u4e86 GP-GPT \u5728\u52a0\u5f37\u907a\u50b3\u75be\u75c5\u95dc\u4fc2\u7814\u7a76\u4ee5\u53ca\u4fc3\u9032\u57fa\u56e0\u7d44\u5b78\u548c\u91ab\u5b78\u907a\u50b3\u5b78\u9818\u57df\u4e2d\u6e96\u78ba\u800c\u6709\u6548\u5206\u6790\u7684\u6f5b\u529b\u3002\u6211\u5011\u7684\u8abf\u67e5\u8b49\u660e\u4e86 GP-GPT \u4e2d\u751f\u7269\u56e0\u5b50\u5be6\u9ad4\u8868\u5fb5\u7684\u7d30\u5fae\u8b8a\u5316\uff0c\u9019\u8868\u660e\u4e86\u5c07 LLM \u61c9\u7528\u65bc\u63a8\u9032\u57fa\u56e0\u8868\u578b\u7814\u7a76\u7684\u6a5f\u6703\u3002", "author": "Yanjun Lyu et.al.", "authors": "Yanjun Lyu, Zihao Wu, Lu Zhang, Jing Zhang, Yiwei Li, Wei Ruan, Zhengliang Liu, Xiaowei Yu, Chao Cao, Tong Chen, Minheng Chen, Yan Zhuang, Xiang Li, Rongjie Liu, Chao Huang, Wentao Li, Tianming Liu, Dajiang Zhu", "id": "2409.09825v1", "paper_url": "http://arxiv.org/abs/2409.09825v1", "repo": "null"}}