{"2407.10834": {"publish_time": "2024-07-15", "title": "MetaLLM: A High-performant and Cost-efficient Dynamic Framework for Wrapping LLMs", "paper_summary": "The rapid progress in machine learning (ML) has brought forth many large\nlanguage models (LLMs) that excel in various tasks and areas. These LLMs come\nwith different abilities and costs in terms of computation or pricing. Since\nthe demand for each query can vary, e.g., because of the queried domain or its\ncomplexity, defaulting to one LLM in an application is not usually the best\nchoice, whether it is the biggest, priciest, or even the one with the best\naverage test performance. Consequently, picking the right LLM that is both\naccurate and cost-effective for an application remains a challenge. In this\npaper, we introduce MetaLLM, a framework that dynamically and intelligently\nroutes each query to the optimal LLM (among several available LLMs) for\nclassification tasks, achieving significantly improved accuracy and\ncost-effectiveness. By framing the selection problem as a multi-armed bandit,\nMetaLLM balances prediction accuracy and cost efficiency under uncertainty. Our\nexperiments, conducted on popular LLM platforms such as OpenAI's GPT models,\nAmazon's Titan, Anthropic's Claude, and Meta's LLaMa, showcase MetaLLM's\nefficacy in real-world scenarios, laying the groundwork for future extensions\nbeyond classification tasks.", "paper_summary_zh": "\u6a5f\u5668\u5b78\u7fd2 (ML) \u7684\u5feb\u901f\u9032\u5c55\u50ac\u751f\u51fa\u8a31\u591a\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM)\uff0c\u5b83\u5011\u5728\u5404\u7a2e\u4efb\u52d9\u548c\u9818\u57df\u4e2d\u8868\u73fe\u51fa\u8272\u3002\u9019\u4e9b LLM \u5728\u904b\u7b97\u6216\u5b9a\u50f9\u65b9\u9762\u5177\u6709\u4e0d\u540c\u7684\u80fd\u529b\u548c\u6210\u672c\u3002\u7531\u65bc\u6bcf\u500b\u67e5\u8a62\u7684\u9700\u6c42\u53ef\u80fd\u6709\u6240\u4e0d\u540c\uff0c\u4f8b\u5982\uff0c\u7531\u65bc\u67e5\u8a62\u7684\u9818\u57df\u6216\u5176\u8907\u96dc\u6027\uff0c\u56e0\u6b64\u5728\u61c9\u7528\u7a0b\u5f0f\u4e2d\u9810\u8a2d\u4f7f\u7528\u4e00\u500b LLM \u901a\u5e38\u4e0d\u662f\u6700\u4f73\u9078\u64c7\uff0c\u7121\u8ad6\u5b83\u662f\u6700\u9f90\u5927\u3001\u6700\u6602\u8cb4\u6216\u751a\u81f3\u5177\u6709\u6700\u4f73\u5e73\u5747\u6e2c\u8a66\u6548\u80fd\u3002\u56e0\u6b64\uff0c\u9078\u64c7\u65e2\u6e96\u78ba\u53c8\u5177\u6709\u6210\u672c\u6548\u76ca\u7684\u9069\u7576 LLM \u4ecd\u7136\u662f\u4e00\u500b\u6311\u6230\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u4ecb\u7d39\u4e86 MetaLLM\uff0c\u9019\u662f\u4e00\u500b\u52d5\u614b\u4e14\u667a\u6167\u5730\u5c07\u6bcf\u500b\u67e5\u8a62\u8def\u7531\u5230\u6700\u4f73 LLM\uff08\u5728\u5e7e\u500b\u53ef\u7528\u7684 LLM \u4e2d\uff09\u4ee5\u9032\u884c\u5206\u985e\u4efb\u52d9\u7684\u6846\u67b6\uff0c\u986f\u8457\u63d0\u9ad8\u4e86\u6e96\u78ba\u6027\u548c\u6210\u672c\u6548\u76ca\u3002\u900f\u904e\u5c07\u9078\u64c7\u554f\u984c\u8a2d\u5b9a\u70ba\u591a\u81c2\u8001\u864e\u6a5f\uff0cMetaLLM \u5728\u4e0d\u78ba\u5b9a\u6027\u4e0b\u5e73\u8861\u9810\u6e2c\u6e96\u78ba\u6027\u548c\u6210\u672c\u6548\u76ca\u3002\u6211\u5011\u7684\u5be6\u9a57\u662f\u5728\u6d41\u884c\u7684 LLM \u5e73\u53f0\u4e0a\u9032\u884c\u7684\uff0c\u4f8b\u5982 OpenAI \u7684 GPT \u6a21\u578b\u3001Amazon \u7684 Titan\u3001Anthropic \u7684 Claude \u548c Meta \u7684 LLaMa\uff0c\u5c55\u793a\u4e86 MetaLLM \u5728\u5be6\u969b\u5834\u666f\u4e2d\u7684\u529f\u6548\uff0c\u70ba\u8d85\u8d8a\u5206\u985e\u4efb\u52d9\u7684\u672a\u4f86\u64f4\u5145\u5960\u5b9a\u4e86\u57fa\u790e\u3002", "author": "Quang H. Nguyen et.al.", "authors": "Quang H. Nguyen, Duy C. Hoang, Juliette Decugis, Saurav Manchanda, Nitesh V. Chawla, Khoa D. Doan", "id": "2407.10834v1", "paper_url": "http://arxiv.org/abs/2407.10834v1", "repo": "null"}}