
### LLM
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-05-29**|**X-VILA: Cross-Modality Alignment for Large Language Model**|Hanrong Ye et.al.|[2405.19335v1](http://arxiv.org/abs/2405.19335v1)|null|
|**2024-05-29**|**LLMs Meet Multimodal Generation and Editing: A Survey**|Yingqing He et.al.|[2405.19334v1](http://arxiv.org/abs/2405.19334v1)|[link](https://github.com/yingqinghe/awesome-llms-meet-multimodal-generation)|
|**2024-05-29**|**Self-Exploring Language Models: Active Preference Elicitation for Online Alignment**|Shenao Zhang et.al.|[2405.19332v1](http://arxiv.org/abs/2405.19332v1)|[link](https://github.com/shenao-zhang/selm)|
|**2024-05-29**|**NPGA: Neural Parametric Gaussian Avatars**|Simon Giebenhain et.al.|[2405.19331v1](http://arxiv.org/abs/2405.19331v1)|null|
|**2024-05-29**|**MAP-Neo: Highly Capable and Transparent Bilingual Large Language Model Series**|Ge Zhang et.al.|[2405.19327v1](http://arxiv.org/abs/2405.19327v1)|null|
|**2024-05-29**|**Nearest Neighbor Speculative Decoding for LLM Generation and Attribution**|Minghan Li et.al.|[2405.19325v1](http://arxiv.org/abs/2405.19325v1)|null|
|**2024-05-29**|**Are Large Language Models Chameleons?**|Mingmeng Geng et.al.|[2405.19323v1](http://arxiv.org/abs/2405.19323v1)|null|
|**2024-05-29**|**Value-Incentivized Preference Optimization: A Unified Approach to Online and Offline RLHF**|Shicong Cen et.al.|[2405.19320v1](http://arxiv.org/abs/2405.19320v1)|null|
|**2024-05-29**|**Robust Preference Optimization through Reward Model Distillation**|Adam Fisch et.al.|[2405.19316v1](http://arxiv.org/abs/2405.19316v1)|null|
|**2024-05-29**|**Matryoshka Query Transformer for Large Vision-Language Models**|Wenbo Hu et.al.|[2405.19315v1](http://arxiv.org/abs/2405.19315v1)|[link](https://github.com/gordonhu608/mqt-llava)|
|**2024-05-29**|**Language Models Trained to do Arithmetic Predict Human Risky and Intertemporal Choice**|Jian-Qiao Zhu et.al.|[2405.19313v1](http://arxiv.org/abs/2405.19313v1)|null|
|**2024-05-29**|**Measuring and Mitigating Bias for Tabular Datasets with Multiple Protected Attributes**|Manh Khoi Duong et.al.|[2405.19300v1](http://arxiv.org/abs/2405.19300v1)|null|
|**2024-05-29**|**Expert-Guided Extinction of Toxic Tokens for Debiased Generation**|Xueyao Sun et.al.|[2405.19299v1](http://arxiv.org/abs/2405.19299v1)|null|
|**2024-05-29**|**Integrating Multi-scale Contextualized Information for Byte-based Neural Machine Translation**|Langlin Huang et.al.|[2405.19290v1](http://arxiv.org/abs/2405.19290v1)|[link](https://github.com/ictnlp/multiscale-contextualization)|
|**2024-05-29**|**MASSIVE Multilingual Abstract Meaning Representation: A Dataset and Baselines for Hallucination Detection**|Michael Regan et.al.|[2405.19285v1](http://arxiv.org/abs/2405.19285v1)|null|
|**2024-05-29**|**Optimizing Foundation Model Inference on a Many-tiny-core Open-source RISC-V Platform**|Viviane Potocnik et.al.|[2405.19284v1](http://arxiv.org/abs/2405.19284v1)|null|
|**2024-05-29**|**PediatricsGPT: Large Language Models as Chinese Medical Assistants for Pediatric Applications**|Dingkang Yang et.al.|[2405.19266v1](http://arxiv.org/abs/2405.19266v1)|null|
|**2024-05-29**|**AlchemistCoder: Harmonizing and Eliciting Code Capability by Hindsight Tuning on Multi-source Data**|Zifan Song et.al.|[2405.19265v1](http://arxiv.org/abs/2405.19265v1)|[link](https://github.com/internlm/alchemistcoder)|
|**2024-05-29**|**Weak-to-Strong Search: Align Large Language Models via Searching over Small Language Models**|Zhanhui Zhou et.al.|[2405.19262v1](http://arxiv.org/abs/2405.19262v1)|null|
|**2024-05-29**|**Faster Cascades via Speculative Decoding**|Harikrishna Narasimhan et.al.|[2405.19261v1](http://arxiv.org/abs/2405.19261v1)|null|
|**2024-05-29**|**Towards Next-Generation Urban Decision Support Systems through AI-Powered Generation of Scientific Ontology using Large Language Models -- A Case in Optimizing Intermodal Freight Transportation**|Jose Tupayachi et.al.|[2405.19255v1](http://arxiv.org/abs/2405.19255v1)|null|
|**2024-05-29**|**Kotlin ML Pack: Technical Report**|Sergey Titov et.al.|[2405.19250v1](http://arxiv.org/abs/2405.19250v1)|null|
|**2024-05-29**|**ConceptPrune: Concept Editing in Diffusion Models via Skilled Neuron Pruning**|Ruchika Chavhan et.al.|[2405.19237v1](http://arxiv.org/abs/2405.19237v1)|[link](https://github.com/ruchikachavhan/concept-prune)|
|**2024-05-29**|**On Generating Monolithic and Model Reconciling Explanations in Probabilistic Scenarios**|Stylianos Loukas Vasileiou et.al.|[2405.19229v1](http://arxiv.org/abs/2405.19229v1)|null|
|**2024-05-29**|**Lower Bounds on the Expressivity of Recurrent Neural Language Models**|Anej Svete et.al.|[2405.19222v1](http://arxiv.org/abs/2405.19222v1)|null|
|**2024-05-29**|**WRDScore: New Metric for Evaluation of Natural Language Generation Models**|Ravil Mussabayev et.al.|[2405.19220v1](http://arxiv.org/abs/2405.19220v1)|null|
|**2024-05-29**|**HawkVision: Low-Latency Modeless Edge AI Serving**|ChonLam Lao et.al.|[2405.19213v1](http://arxiv.org/abs/2405.19213v1)|null|
|**2024-05-29**|**Gradient Guided Hypotheses: A unified solution to enable machine learning models on scarce and noisy data regimes**|Paulo Neves et.al.|[2405.19210v1](http://arxiv.org/abs/2405.19210v1)|null|
|**2024-05-29**|**VideoTree: Adaptive Tree-based Video Representation for LLM Reasoning on Long Videos**|Ziyang Wang et.al.|[2405.19209v1](http://arxiv.org/abs/2405.19209v1)|[link](https://github.com/Ziyang412/VideoTree)|
|**2024-05-29**|**A Multi-Source Retrieval Question Answering Framework Based on RAG**|Ridong Wu et.al.|[2405.19207v1](http://arxiv.org/abs/2405.19207v1)|null|
|**2024-05-29**|**Going beyond compositional generalization, DDPMs can produce zero-shot interpolation**|Justin Deschenaux et.al.|[2405.19201v1](http://arxiv.org/abs/2405.19201v1)|[link](https://github.com/jdeschena/ddpm-zero-shot-interpolation)|
|**2024-05-29**|**MetaToken: Detecting Hallucination in Image Descriptions by Meta Classification**|Laura Fieback et.al.|[2405.19186v1](http://arxiv.org/abs/2405.19186v1)|null|
|**2024-05-29**|**Promoting Two-sided Fairness in Dynamic Vehicle Routing Problem**|Yufan Kang et.al.|[2405.19184v1](http://arxiv.org/abs/2405.19184v1)|null|
|**2024-05-29**|**Transformers as Neural Operators for Solutions of Differential Equations with Finite Regularity**|Benjamin Shih et.al.|[2405.19166v1](http://arxiv.org/abs/2405.19166v1)|null|
|**2024-05-29**|**Learning from Litigation: Graphs and LLMs for Retrieval and Reasoning in eDiscovery**|Sounak Lahiri et.al.|[2405.19164v1](http://arxiv.org/abs/2405.19164v1)|null|
|**2024-05-29**|**Does learning the right latent variables necessarily improve in-context learning?**|Sarthak Mittal et.al.|[2405.19162v1](http://arxiv.org/abs/2405.19162v1)|[link](https://github.com/ericelmoznino/explicit_implicit_icl)|
|**2024-05-29**|**DGRC: An Effective Fine-tuning Framework for Distractor Generation in Chinese Multi-choice Reading Comprehension**|Runfeng Lin et.al.|[2405.19139v1](http://arxiv.org/abs/2405.19139v1)|null|
|**2024-05-29**|**Analyzing Chat Protocols of Novice Programmers Solving Introductory Programming Tasks with ChatGPT**|Andreas Scholl et.al.|[2405.19132v1](http://arxiv.org/abs/2405.19132v1)|null|
|**2024-05-29**|**Spatio-Spectral Graph Neural Networks**|Simon Geisler et.al.|[2405.19121v1](http://arxiv.org/abs/2405.19121v1)|null|
|**2024-05-29**|**PathReasoner: Modeling Reasoning Path with Equivalent Extension for Logical Question Answering**|Fangzhi Xu et.al.|[2405.19109v1](http://arxiv.org/abs/2405.19109v1)|null|
|**2024-05-29**|**Offline Regularised Reinforcement Learning for Large Language Models Alignment**|Pierre Harvey Richemond et.al.|[2405.19107v1](http://arxiv.org/abs/2405.19107v1)|null|
|**2024-05-29**|**Efficient Black-box Adversarial Attacks via Bayesian Optimization Guided by a Function Prior**|Shuyu Cheng et.al.|[2405.19098v1](http://arxiv.org/abs/2405.19098v1)|[link](https://github.com/yibo-miao/pbo-attack)|
|**2024-05-29**|**Faithful Chart Summarization with ChaTS-Pi**|Syrine Krichene et.al.|[2405.19094v1](http://arxiv.org/abs/2405.19094v1)|null|
|**2024-05-29**|**Multi-stage Retrieve and Re-rank Model for Automatic Medical Coding Recommendation**|Xindi Wang et.al.|[2405.19093v1](http://arxiv.org/abs/2405.19093v1)|null|
|**2024-05-29**|**Cracking the Code of Juxtaposition: Can AI Models Understand the Humorous Contradictions**|Zhe Hu et.al.|[2405.19088v1](http://arxiv.org/abs/2405.19088v1)|null|
|**2024-05-29**|**MEMoE: Enhancing Model Editing with Mixture of Experts Adaptors**|Renzhi Wang et.al.|[2405.19086v1](http://arxiv.org/abs/2405.19086v1)|null|
|**2024-05-29**|**Patch-enhanced Mask Encoder Prompt Image Generation**|Shusong Xu et.al.|[2405.19085v1](http://arxiv.org/abs/2405.19085v1)|null|
|**2024-05-29**|**Cephalo: Multi-Modal Vision-Language Models for Bio-Inspired Materials Analysis and Design**|Markus J. Buehler et.al.|[2405.19076v1](http://arxiv.org/abs/2405.19076v1)|null|
|**2024-05-29**|**Resurrecting Old Classes with New Data for Exemplar-Free Continual Learning**|Dipam Goswami et.al.|[2405.19074v1](http://arxiv.org/abs/2405.19074v1)|[link](https://github.com/dipamgoswami/adc)|
|**2024-05-29**|**SIG: Efficient Self-Interpretable Graph Neural Network for Continuous-time Dynamic Graphs**|Lanting Fang et.al.|[2405.19062v1](http://arxiv.org/abs/2405.19062v1)|[link](https://github.com/2024sig/sig)|
|**2024-05-29**|**Multiscale Spatio-Temporal Enhanced Short-term Load Forecasting of Electric Vehicle Charging Stations**|Zongbao Zhang et.al.|[2405.19053v1](http://arxiv.org/abs/2405.19053v1)|null|
|**2024-05-29**|**BLSP-KD: Bootstrapping Language-Speech Pre-training via Knowledge Distillation**|Chen Wang et.al.|[2405.19041v1](http://arxiv.org/abs/2405.19041v1)|null|
|**2024-05-29**|**CiliaGraph: Enabling Expression-enhanced Hyper-Dimensional Computation in Ultra-Lightweight and One-Shot Graph Classification on Edge**|Yuxi Han et.al.|[2405.19033v1](http://arxiv.org/abs/2405.19033v1)|null|
|**2024-05-29**|**Large Language Models for Code Summarization**|Balázs Szalontai et.al.|[2405.19032v1](http://arxiv.org/abs/2405.19032v1)|null|
|**2024-05-29**|**Convex neural network synthesis for robustness in the 1-norm**|Ross Drummond et.al.|[2405.19029v1](http://arxiv.org/abs/2405.19029v1)|[link](https://github.com/r-drummond/convex-nn-synthesis-1norm)|
|**2024-05-29**|**DiveR-CT: Diversity-enhanced Red Teaming with Relaxing Constraints**|Andrew Zhao et.al.|[2405.19026v1](http://arxiv.org/abs/2405.19026v1)|null|
|**2024-05-29**|**Evaluating the External and Parametric Knowledge Fusion of Large Language Models**|Hao Zhang et.al.|[2405.19010v1](http://arxiv.org/abs/2405.19010v1)|null|
|**2024-05-29**|**Continuously Optimizing Radar Placement with Model Predictive Path Integrals**|Michael Potter et.al.|[2405.18999v2](http://arxiv.org/abs/2405.18999v2)|null|
|**2024-05-29**|**EasyAnimate: A High-Performance Long Video Generation Method based on Transformer Architecture**|Jiaqi Xu et.al.|[2405.18991v1](http://arxiv.org/abs/2405.18991v1)|[link](https://github.com/aigc-apps/easyanimate)|
|**2024-05-29**|**Encoding Hierarchical Schema via Concept Flow for Multifaceted Ideology Detection**|Songtao Liu et.al.|[2405.18974v1](http://arxiv.org/abs/2405.18974v1)|null|
|**2024-05-29**|**UniIF: Unified Molecule Inverse Folding**|Zhangyang Gao et.al.|[2405.18968v1](http://arxiv.org/abs/2405.18968v1)|null|
|**2024-05-29**|**Are You Sure? Rank Them Again: Repeated Ranking For Better Preference Datasets**|Peter Devine et.al.|[2405.18952v1](http://arxiv.org/abs/2405.18952v1)|null|
|**2024-05-29**|**Kestrel: Point Grounding Multimodal LLM for Part-Aware 3D Vision-Language Understanding**|Junjie Fei et.al.|[2405.18937v1](http://arxiv.org/abs/2405.18937v1)|null|
|**2024-05-29**|**Understanding and Addressing the Under-Translation Problem from the Perspective of Decoding Objective**|Chenze Shao et.al.|[2405.18922v1](http://arxiv.org/abs/2405.18922v1)|null|
|**2024-05-29**|**Towards Faithful Chain-of-Thought: Large Language Models are Bridging Reasoners**|Jiachun Li et.al.|[2405.18915v1](http://arxiv.org/abs/2405.18915v1)|null|
|**2024-05-29**|**Predicting Parking Availability in Singapore with Cross-Domain Data: A New Dataset and A Data-Driven Approach**|Huaiwu Zhang et.al.|[2405.18910v1](http://arxiv.org/abs/2405.18910v1)|null|
|**2024-05-29**|**Language Generation with Strictly Proper Scoring Rules**|Chenze Shao et.al.|[2405.18906v1](http://arxiv.org/abs/2405.18906v1)|[link](https://github.com/shaochenze/scoringruleslm)|
|**2024-05-29**|**A Causal Framework for Evaluating Deferring Systems**|Filippo Palomba et.al.|[2405.18902v1](http://arxiv.org/abs/2405.18902v1)|[link](https://github.com/andrepugni/pods)|
|**2024-05-29**|**Few-Shot Testing: Estimating Uncertainty of Memristive Deep Neural Networks Using One Bayesian Test Vector**|Soyed Tuhin Ahmed et.al.|[2405.18894v1](http://arxiv.org/abs/2405.18894v1)|null|
|**2024-05-29**|**Compressing Large Language Models using Low Rank and Low Precision Decomposition**|Rajarshi Saha et.al.|[2405.18886v1](http://arxiv.org/abs/2405.18886v1)|null|
|**2024-05-29**|**Tuning-Free Alignment of Diffusion Models with Direct Noise Optimization**|Zhiwei Tang et.al.|[2405.18881v1](http://arxiv.org/abs/2405.18881v1)|null|
|**2024-05-29**|**Continuous Product Graph Neural Networks**|Aref Einizade et.al.|[2405.18877v1](http://arxiv.org/abs/2405.18877v1)|null|
|**2024-05-29**|**Counterfactual Metarules for Local and Global Recourse**|Tom Bewley et.al.|[2405.18875v1](http://arxiv.org/abs/2405.18875v1)|null|
|**2024-05-29**|**Are queries and keys always relevant? A case study on Transformer wave functions**|Riccardo Rende et.al.|[2405.18874v1](http://arxiv.org/abs/2405.18874v1)|null|
|**2024-05-29**|**LLMs achieve adult human performance on higher-order theory of mind tasks**|Winnie Street et.al.|[2405.18870v1](http://arxiv.org/abs/2405.18870v1)|null|
|**2024-05-29**|**Topological Perspectives on Optimal Multimodal Embedding Spaces**|Abdul Aziz A. B et.al.|[2405.18867v1](http://arxiv.org/abs/2405.18867v1)|null|
|**2024-05-29**|**Simulation, Modelling and Classification of Wiki Contributors: Spotting The Good, The Bad, and The Ugly**|Silvia García Méndez et.al.|[2405.18845v1](http://arxiv.org/abs/2405.18845v1)|null|
|**2024-05-29**|**Data-driven Machinery Fault Detection: A Comprehensive Review**|Dhiraj Neupane et.al.|[2405.18843v1](http://arxiv.org/abs/2405.18843v1)|null|
|**2024-05-29**|**MoNDE: Mixture of Near-Data Experts for Large-Scale Sparse Models**|Taehyun Kim et.al.|[2405.18832v1](http://arxiv.org/abs/2405.18832v1)|null|
|**2024-05-29**|**Why Reinforcement Learning in Energy Systems Needs Explanations**|Hallah Shahid Butt et.al.|[2405.18823v1](http://arxiv.org/abs/2405.18823v1)|null|
|**2024-05-29**|**Toxicity Detection for Free**|Zhanhao Hu et.al.|[2405.18822v1](http://arxiv.org/abs/2405.18822v1)|null|
|**2024-05-29**|**Diffeomorphic interpolation for efficient persistence-based topological optimization**|Mathieu Carriere et.al.|[2405.18820v1](http://arxiv.org/abs/2405.18820v1)|null|
|**2024-05-29**|**Enhancing Security and Privacy in Federated Learning using Update Digests and Voting-Based Defense**|Wenjie Li et.al.|[2405.18802v1](http://arxiv.org/abs/2405.18802v1)|null|
|**2024-05-29**|**Quantitative Certification of Bias in Large Language Models**|Isha Chaudhary et.al.|[2405.18780v1](http://arxiv.org/abs/2405.18780v1)|null|
|**2024-05-29**|**LMO-DP: Optimizing the Randomization Mechanism for Differentially Private Fine-Tuning (Large) Language Models**|Qin Yang et.al.|[2405.18776v1](http://arxiv.org/abs/2405.18776v1)|null|
|**2024-05-29**|**Leveraging Many-To-Many Relationships for Defending Against Visual-Language Adversarial Attacks**|Futa Waseda et.al.|[2405.18770v1](http://arxiv.org/abs/2405.18770v1)|null|
|**2024-05-29**|**Inpaint Biases: A Pathway to Accurate and Unbiased Image Generation**|Jiyoon Myung et.al.|[2405.18762v2](http://arxiv.org/abs/2405.18762v2)|null|
|**2024-05-29**|**Learning to Continually Learn with the Bayesian Principle**|Soochan Lee et.al.|[2405.18758v1](http://arxiv.org/abs/2405.18758v1)|[link](https://github.com/soochan-lee/sb-mcl)|
|**2024-05-29**|**Provable Contrastive Continual Learning**|Yichen Wen et.al.|[2405.18756v1](http://arxiv.org/abs/2405.18756v1)|null|
|**2024-05-29**|**On the Limits of Multi-modal Meta-Learning with Auxiliary Task Modulation Using Conditional Batch Normalization**|Jordi Armengol-Estapé et.al.|[2405.18751v2](http://arxiv.org/abs/2405.18751v2)|null|
|**2024-05-29**|**Genshin: General Shield for Natural Language Processing with Large Language Models**|Xiao Peng et.al.|[2405.18741v1](http://arxiv.org/abs/2405.18741v1)|null|
|**2024-05-29**|**Reverse Image Retrieval Cues Parametric Memory in Multimodal LLMs**|Jialiang Xu et.al.|[2405.18740v1](http://arxiv.org/abs/2405.18740v1)|null|
|**2024-05-29**|**Gemini & Physical World: Large Language Models Can Estimate the Intensity of Earthquake Shaking from Multi-Modal Social Media Posts**|S. Mostafa Mousavi et.al.|[2405.18732v1](http://arxiv.org/abs/2405.18732v1)|null|
|**2024-05-29**|**VBIM-Net: Variational Born Iterative Network for Inverse Scattering Problems**|Ziqing Xing et.al.|[2405.18731v1](http://arxiv.org/abs/2405.18731v1)|null|
|**2024-05-29**|**Preferred-Action-Optimized Diffusion Policies for Offline Reinforcement Learning**|Tianle Zhang et.al.|[2405.18729v1](http://arxiv.org/abs/2405.18729v1)|null|
|**2024-05-29**|**CtrlA: Adaptive Retrieval-Augmented Generation via Probe-Guided Control**|Huanshuo Liu et.al.|[2405.18727v1](http://arxiv.org/abs/2405.18727v1)|[link](https://github.com/hsliu-initial/ctrla)|
|**2024-05-29**|**Adapting Differential Molecular Representation with Hierarchical Prompts for Multi-label Property Prediction**|Linjia Kang et.al.|[2405.18724v1](http://arxiv.org/abs/2405.18724v1)|[link](https://github.com/zhousongh/hipm)|
|**2024-05-29**|**Conformal Depression Prediction**|Yonghong Li et.al.|[2405.18723v1](http://arxiv.org/abs/2405.18723v1)|null|
|**2024-05-29**|**Correctable Landmark Discovery via Large Models for Vision-Language Navigation**|Bingqian Lin et.al.|[2405.18721v1](http://arxiv.org/abs/2405.18721v1)|[link](https://github.com/expectorlin/console)|
|**2024-05-29**|**Contextual Position Encoding: Learning to Count What's Important**|Olga Golovneva et.al.|[2405.18719v1](http://arxiv.org/abs/2405.18719v1)|null|

#### Abstracts
##### **X-VILA: Cross-Modality Alignment for Large Language Model**
2405.19335v1 by Hanrong Ye, De-An Huang, Yao Lu, Zhiding Yu, Wei Ping, Andrew Tao, Jan Kautz, Song Han, Dan Xu, Pavlo Molchanov, Hongxu Yin

We introduce X-VILA, an omni-modality model designed to extend the
capabilities of large language models (LLMs) by incorporating image, video, and
audio modalities. By aligning modality-specific encoders with LLM inputs and
diffusion decoders with LLM outputs, X-VILA achieves cross-modality
understanding, reasoning, and generation. To facilitate this cross-modality
alignment, we curate an effective interleaved any-to-any modality
instruction-following dataset. Furthermore, we identify a significant problem
with the current cross-modality alignment method, which results in visual
information loss. To address the issue, we propose a visual alignment mechanism
with a visual embedding highway module. We then introduce a resource-efficient
recipe for training X-VILA, that exhibits proficiency in any-to-any modality
conversation, surpassing previous approaches by large margins. X-VILA also
showcases emergent properties across modalities even in the absence of similar
training data. The project will be made open-source.

摘要：我們介紹 X-VILA，一種全模態模型，旨在透過納入影像、影片和音訊模態來擴充大型語言模型 (LLM) 的功能。透過將特定模態的編碼器與 LLM 輸入對齊，以及將擴散解碼器與 LLM 輸出對齊，X-VILA 達到了跨模態理解、推理和生成。為了促進這種跨模態對齊，我們策劃了一個有效的交錯任何對任何模態指令遵循資料集。此外，我們發現目前跨模態對齊方法存在一個重大問題，這會導致視覺資訊遺失。為了解決這個問題，我們提出了一個帶有視覺嵌入公路模組的視覺對齊機制。然後，我們介紹了一種訓練 X-VILA 的資源有效配方，它展示了在任何對任何模態對話中的熟練度，遠遠超過了以前的方法。即使在沒有類似訓練資料的情況下，X-VILA 也展示了跨模態的新興屬性。該專案將開放原始碼。

##### **LLMs Meet Multimodal Generation and Editing: A Survey**
2405.19334v1 by Yingqing He, Zhaoyang Liu, Jingye Chen, Zeyue Tian, Hongyu Liu, Xiaowei Chi, Runtao Liu, Ruibin Yuan, Yazhou Xing, Wenhai Wang, Jifeng Dai, Yong Zhang, Wei Xue, Qifeng Liu, Yike Guo, Qifeng Chen

With the recent advancement in large language models (LLMs), there is a
growing interest in combining LLMs with multimodal learning. Previous surveys
of multimodal large language models (MLLMs) mainly focus on understanding. This
survey elaborates on multimodal generation across different domains, including
image, video, 3D, and audio, where we highlight the notable advancements with
milestone works in these fields. Specifically, we exhaustively investigate the
key technical components behind methods and multimodal datasets utilized in
these studies. Moreover, we dig into tool-augmented multimodal agents that can
use existing generative models for human-computer interaction. Lastly, we also
comprehensively discuss the advancement in AI safety and investigate emerging
applications as well as future prospects. Our work provides a systematic and
insightful overview of multimodal generation, which is expected to advance the
development of Artificial Intelligence for Generative Content (AIGC) and world
models. A curated list of all related papers can be found at
https://github.com/YingqingHe/Awesome-LLMs-meet-Multimodal-Generation

摘要：隨著大型語言模型 (LLM) 的最新進展，將 LLM 與多模態學習相結合的興趣與日俱增。先前對多模態大型語言模型 (MLLM) 的調查主要集中在理解方面。本調查闡述了不同領域的多模態生成，包括圖像、影片、3D 和音訊，我們在這些領域中強調了具有里程碑意義的作品的顯著進展。具體來說，我們詳盡地探討了這些研究中所用方法和多模態資料集背後的主要技術組成部分。此外，我們深入探討了工具增強的多模態代理，這些代理可以使用現有的生成模型進行人機互動。最後，我們還全面討論了 AI 安全性的進展，並探討了新興應用以及未來前景。我們的研究提供了多模態生成的系統且富有洞察力的概述，預計將推進生成內容 (AIGC) 和世界模型的人工智慧發展。所有相關論文的精選清單可在 https://github.com/YingqingHe/Awesome-LLMs-meet-Multimodal-Generation 找到

##### **Self-Exploring Language Models: Active Preference Elicitation for Online Alignment**
2405.19332v1 by Shenao Zhang, Donghan Yu, Hiteshi Sharma, Ziyi Yang, Shuohang Wang, Hany Hassan, Zhaoran Wang

Preference optimization, particularly through Reinforcement Learning from
Human Feedback (RLHF), has achieved significant success in aligning Large
Language Models (LLMs) to adhere to human intentions. Unlike offline alignment
with a fixed dataset, online feedback collection from humans or AI on model
generations typically leads to more capable reward models and better-aligned
LLMs through an iterative process. However, achieving a globally accurate
reward model requires systematic exploration to generate diverse responses that
span the vast space of natural language. Random sampling from standard
reward-maximizing LLMs alone is insufficient to fulfill this requirement. To
address this issue, we propose a bilevel objective optimistically biased
towards potentially high-reward responses to actively explore
out-of-distribution regions. By solving the inner-level problem with the
reparameterized reward function, the resulting algorithm, named Self-Exploring
Language Models (SELM), eliminates the need for a separate RM and iteratively
updates the LLM with a straightforward objective. Compared to Direct Preference
Optimization (DPO), the SELM objective reduces indiscriminate favor of unseen
extrapolations and enhances exploration efficiency. Our experimental results
demonstrate that when finetuned on Zephyr-7B-SFT and Llama-3-8B-Instruct
models, SELM significantly boosts the performance on instruction-following
benchmarks such as MT-Bench and AlpacaEval 2.0, as well as various standard
academic benchmarks in different settings. Our code and models are available at
https://github.com/shenao-zhang/SELM.

摘要：偏好最佳化，尤其是透過人類回饋的強化學習 (RLHF)，在讓大型語言模型 (LLM) 符合人類意圖方面取得顯著的成功。與使用固定資料集的離線校準不同，從人類或人工智慧對模型產生的在線回饋通常會透過反覆的過程產生更有能力的獎勵模型和更佳校準的 LLM。然而，要達成全球精準的獎勵模型需要有系統的探索，以產生橫跨自然語言廣大空間的多元回應。僅從標準獎勵最大化的 LLM 進行隨機取樣不足以滿足此項需求。為了解決此問題，我們提出一個雙層次目標，樂觀偏向於潛在高獎勵回應，以積極探索分佈外區域。透過使用重新參數化的獎勵函數解決內層次問題，所產生的演算法，稱為自我探索語言模型 (SELM)，消除了對單獨 RM 的需求，並使用直接的目標反覆更新 LLM。與直接偏好最佳化 (DPO) 相比，SELM 目標減少了對未見外推的無差別偏好，並提升探索效率。我們的實驗結果顯示，當在 Zephyr-7B-SFT 和 Llama-3-8B-Instruct 模型上進行微調時，SELM 在遵循指令的基準測試（例如 MT-Bench 和 AlpacaEval 2.0）以及不同設定中的各種標準學術基準測試上大幅提升效能。我們的程式碼和模型可在 https://github.com/shenao-zhang/SELM 取得。

##### **NPGA: Neural Parametric Gaussian Avatars**
2405.19331v1 by Simon Giebenhain, Tobias Kirschstein, Martin Rünz, Lourdes Agapito, Matthias Nießner

The creation of high-fidelity, digital versions of human heads is an
important stepping stone in the process of further integrating virtual
components into our everyday lives. Constructing such avatars is a challenging
research problem, due to a high demand for photo-realism and real-time
rendering performance. In this work, we propose Neural Parametric Gaussian
Avatars (NPGA), a data-driven approach to create high-fidelity, controllable
avatars from multi-view video recordings. We build our method around 3D
Gaussian Splatting for its highly efficient rendering and to inherit the
topological flexibility of point clouds. In contrast to previous work, we
condition our avatars' dynamics on the rich expression space of neural
parametric head models (NPHM), instead of mesh-based 3DMMs. To this end, we
distill the backward deformation field of our underlying NPHM into forward
deformations which are compatible with rasterization-based rendering. All
remaining fine-scale, expression-dependent details are learned from the
multi-view videos. To increase the representational capacity of our avatars, we
augment the canonical Gaussian point cloud using per-primitive latent features
which govern its dynamic behavior. To regularize this increased dynamic
expressivity, we propose Laplacian terms on the latent features and predicted
dynamics. We evaluate our method on the public NeRSemble dataset, demonstrating
that NPGA significantly outperforms the previous state-of-the-art avatars on
the self-reenactment task by 2.6 PSNR. Furthermore, we demonstrate accurate
animation capabilities from real-world monocular videos.

摘要：<paragraph>建立高保真、數位化的人頭版本，是進一步將虛擬元件整合至我們日常生活中重要的一步。由於對寫實照片和即時渲染效能有很高的需求，因此建構此類化身是一個具有挑戰性的研究問題。在這項工作中，我們提出了神經參數化高斯化身 (NPGA)，一種從多視角影片錄製中建立高保真、可控化身，且以資料驅動的方法。我們以 3D 高斯潑濺為方法基礎，因為它具有高效率的渲染效果，並繼承點雲的拓撲彈性。與先前的研究不同，我們將化身的動態設定在神經參數化頭部模型 (NPHM) 豐富的表情空間，而不是基於網格的 3DMM。為此，我們將基礎 NPHM 的反向形變場提煉成正向形變，與基於光柵化的渲染相容。所有剩下的精細、依表情而定的細節都是從多視角影片中學習來的。為了增加化身的表現能力，我們使用每個基本原語的潛在特徵擴充正規高斯點雲，這些特徵控制其動態行為。為了規範這種增加的動態表現力，我們對潛在特徵和預測動態提出拉普拉斯項。我們在公開的 NeRSemble 資料集上評估我們的模型，證明 NPGA 在自我重演任務上顯著優於先前的最新化身，PSNR 提升了 2.6。此外，我們展示了從真實世界單眼影片中獲得的精確動畫功能。</paragraph>

##### **MAP-Neo: Highly Capable and Transparent Bilingual Large Language Model Series**
2405.19327v1 by Ge Zhang, Scott Qu, Jiaheng Liu, Chenchen Zhang, Chenghua Lin, Chou Leuang Yu, Danny Pan, Esther Cheng, Jie Liu, Qunshu Lin, Raven Yuan, Tuney Zheng, Wei Pang, Xinrun Du, Yiming Liang, Yinghao Ma, Yizhi Li, Ziyang Ma, Bill Lin, Emmanouil Benetos, Huan Yang, Junting Zhou, Kaijing Ma, Minghao Liu, Morry Niu, Noah Wang, Quehry Que, Ruibo Liu, Sine Liu, Shawn Guo, Soren Gao, Wangchunshu Zhou, Xinyue Zhang, Yizhi Zhou, Yubo Wang, Yuelin Bai, Yuhan Zhang, Yuxiang Zhang, Zenith Wang, Zhenzhu Yang, Zijian Zhao, Jiajun Zhang, Wanli Ouyang, Wenhao Huang, Wenhu Chen

Large Language Models (LLMs) have made great strides in recent years to
achieve unprecedented performance across different tasks. However, due to
commercial interest, the most competitive models like GPT, Gemini, and Claude
have been gated behind proprietary interfaces without disclosing the training
details. Recently, many institutions have open-sourced several strong LLMs like
LLaMA-3, comparable to existing closed-source LLMs. However, only the model's
weights are provided with most details (e.g., intermediate checkpoints,
pre-training corpus, and training code, etc.) being undisclosed. To improve the
transparency of LLMs, the research community has formed to open-source truly
open LLMs (e.g., Pythia, Amber, OLMo), where more details (e.g., pre-training
corpus and training code) are being provided. These models have greatly
advanced the scientific study of these large models including their strengths,
weaknesses, biases and risks. However, we observe that the existing truly open
LLMs on reasoning, knowledge, and coding tasks are still inferior to existing
state-of-the-art LLMs with similar model sizes. To this end, we open-source
MAP-Neo, a highly capable and transparent bilingual language model with 7B
parameters trained from scratch on 4.5T high-quality tokens. Our MAP-Neo is the
first fully open-sourced bilingual LLM with comparable performance compared to
existing state-of-the-art LLMs. Moreover, we open-source all details to
reproduce our MAP-Neo, where the cleaned pre-training corpus, data cleaning
pipeline, checkpoints, and well-optimized training/evaluation framework are
provided. Finally, we hope our MAP-Neo will enhance and strengthen the open
research community and inspire more innovations and creativities to facilitate
the further improvements of LLMs.

摘要：<paragraph>大型語言模型 (LLM) 近年來在各項任務上取得了長足進步，達到了前所未有的效能。然而，由於商業利益，像 GPT、Gemini 和 Claude 等最具競爭力的模型都被隱藏在專有介面之後，而未公開訓練細節。最近，許多機構開放了多個強大的 LLM 的原始碼，例如與現有的閉源 LLM 相當的 LLaMA-3。然而，大多數細節（例如中間檢查點、預訓練語料庫和訓練程式碼等）都未公開，只有模型權重被提供。為了提升 LLM 的透明度，研究社群已組成開放原始碼真正開放的 LLM（例如 Pythia、Amber、OLMo），其中提供了更多細節（例如預訓練語料庫和訓練程式碼）。這些模型大幅推動了這些大型模型的科學研究，包括它們的優點、缺點、偏差和風險。然而，我們觀察到，現有的真正開放的 LLM 在推理、知識和編碼任務上的表現仍然遜於現有具有類似模型規模的最新 LLM。為此，我們開放了 MAP-Neo 的原始碼，這是一個功能強大且透明的雙語語言模型，具有 7B 個參數，並從 4.5T 的高品質代幣中從頭訓練。我們的 MAP-Neo 是第一個完全開放原始碼的雙語 LLM，其效能可與現有的最新 LLM 相媲美。此外，我們開放了所有細節以重現 MAP-Neo，其中提供了清理過的預訓練語料庫、資料清理管道、檢查點和經過優化的訓練/評估框架。最後，我們希望我們的 MAP-Neo 能夠提升和強化開放的研究社群，並激發更多創新和創意，以促進 LLM 的進一步改進。</paragraph>

##### **Nearest Neighbor Speculative Decoding for LLM Generation and Attribution**
2405.19325v1 by Minghan Li, Xilun Chen, Ari Holtzman, Beidi Chen, Jimmy Lin, Wen-tau Yih, Xi Victoria Lin

Large language models (LLMs) often hallucinate and lack the ability to
provide attribution for their generations. Semi-parametric LMs, such as kNN-LM,
approach these limitations by refining the output of an LM for a given prompt
using its nearest neighbor matches in a non-parametric data store. However,
these models often exhibit slow inference speeds and produce non-fluent texts.
In this paper, we introduce Nearest Neighbor Speculative Decoding (NEST), a
novel semi-parametric language modeling approach that is capable of
incorporating real-world text spans of arbitrary length into the LM generations
and providing attribution to their sources. NEST performs token-level retrieval
at each inference step to compute a semi-parametric mixture distribution and
identify promising span continuations in a corpus. It then uses an approximate
speculative decoding procedure that accepts a prefix of the retrieved span or
generates a new token. NEST significantly enhances the generation quality and
attribution rate of the base LM across a variety of knowledge-intensive tasks,
surpassing the conventional kNN-LM method and performing competitively with
in-context retrieval augmentation. In addition, NEST substantially improves the
generation speed, achieving a 1.8x speedup in inference time when applied to
Llama-2-Chat 70B.

摘要：大型语言模型（LLM）经常出现幻觉，并且缺乏为其生成内容提供归因的能力。半参数语言模型（例如 kNN-LM）通过使用非参数数据存储中与其最邻近的匹配项来优化给定提示的 LM 输出，从而解决这些限制。然而，这些模型通常表现出较慢的推理速度并产生不流利的文本。在本文中，我们介绍了最近邻推测解码（NEST），这是一种新颖的半参数语言建模方法，能够将任意长度的真实文本跨度合并到 LM 生成中，并为其来源提供归因。NEST 在每个推理步骤执行令牌级检索以计算半参数混合分布，并在语料库中识别有希望的跨度延续。然后，它使用近似推测解码程序，该程序接受检索跨度的前缀或生成新令牌。NEST 显着提高了基础 LM 在各种知识密集型任务中的生成质量和归因率，超越了传统的 kNN-LM 方法，并且与上下文检索增强具有竞争力。此外，NEST 大大提高了生成速度，在应用于 Llama-2-Chat 70B 时，推理时间加快了 1.8 倍。

##### **Are Large Language Models Chameleons?**
2405.19323v1 by Mingmeng Geng, Sihong He, Roberto Trotta

Do large language models (LLMs) have their own worldviews and personality
tendencies? Simulations in which an LLM was asked to answer subjective
questions were conducted more than 1 million times. Comparison of the responses
from different LLMs with real data from the European Social Survey (ESS)
suggests that the effect of prompts on bias and variability is fundamental,
highlighting major cultural, age, and gender biases. Methods for measuring the
difference between LLMs and survey data are discussed, such as calculating
weighted means and a new proposed measure inspired by Jaccard similarity. We
conclude that it is important to analyze the robustness and variability of
prompts before using LLMs to model individual decisions or collective behavior,
as their imitation abilities are approximate at best.

摘要：大型語言模型 (LLM) 是否有自己的世界觀和人格傾向？我們進行了超過 100 萬次的模擬，在模擬中，我們要求 LLM 回答主觀問題。比較不同 LLM 的回應與歐洲社會調查 (ESS) 的真實資料，結果顯示提示對偏見和變異性的影響至關重要，突顯了重大的文化、年齡和性別偏見。我們討論了衡量 LLM 和調查資料之間差異的方法，例如計算加權平均數和一個新的建議測量，靈感來自 Jaccard 相似性。我們得出結論，在使用 LLM 來建模個人決策或集體行為之前，分析提示的穩健性和變異性非常重要，因為它們的模仿能力充其量只是近似值。

##### **Value-Incentivized Preference Optimization: A Unified Approach to Online and Offline RLHF**
2405.19320v1 by Shicong Cen, Jincheng Mei, Katayoon Goshvadi, Hanjun Dai, Tong Yang, Sherry Yang, Dale Schuurmans, Yuejie Chi, Bo Dai

Reinforcement learning from human feedback (RLHF) has demonstrated great
promise in aligning large language models (LLMs) with human preference.
Depending on the availability of preference data, both online and offline RLHF
are active areas of investigation. A key bottleneck is understanding how to
incorporate uncertainty estimation in the reward function learned from the
preference data for RLHF, regardless of how the preference data is collected.
While the principles of optimism or pessimism under uncertainty are
well-established in standard reinforcement learning (RL), a
practically-implementable and theoretically-grounded form amenable to large
language models is not yet available, as standard techniques for constructing
confidence intervals become intractable under arbitrary policy
parameterizations.
  In this paper, we introduce a unified approach to online and offline RLHF --
value-incentivized preference optimization (VPO) -- which regularizes the
maximum-likelihood estimate of the reward function with the corresponding value
function, modulated by a $\textit{sign}$ to indicate whether the optimism or
pessimism is chosen. VPO also directly optimizes the policy with implicit
reward modeling, and therefore shares a simpler RLHF pipeline similar to direct
preference optimization. Theoretical guarantees of VPO are provided for both
online and offline settings, matching the rates of their standard RL
counterparts. Moreover, experiments on text summarization and dialog verify the
practicality and effectiveness of VPO.

摘要：人類回饋強化學習 (RLHF) 已展現出極佳的潛力，能使大型語言模型 (LLM) 與人類偏好保持一致。取決於偏好資料的取得，線上和離線 RLHF 都是積極的研究領域。一個關鍵瓶頸在於了解如何將不確定性估計納入 RLHF 偏好資料所學習的獎勵函數中，而不管偏好資料是如何收集的。雖然樂觀或悲觀原則在標準強化學習 (RL) 中的不確定性下已廣為確立，但一種實用且有理論基礎且適用於大型語言模型的形式尚未出現，因為用於建構信心區間的標準技術在任意策略參數化下會變得難以處理。在本文中，我們介紹了線上和離線 RLHF 的統一方法，即價值激勵偏好最佳化 (VPO)，它使用對應的價值函數正規化獎勵函數的最大似然估計，並透過一個符號來調節，以表示選擇樂觀或悲觀。VPO 也直接最佳化具有內隱獎勵建模的策略，因此與直接偏好最佳化共享一個較為簡單的 RLHF 管線。VPO 的理論保證適用於線上和離線設定，與其標準 RL 對應項目的比率相符。此外，文本摘要和對話的實驗驗證了 VPO 的實用性和有效性。

##### **Robust Preference Optimization through Reward Model Distillation**
2405.19316v1 by Adam Fisch, Jacob Eisenstein, Vicky Zayats, Alekh Agarwal, Ahmad Beirami, Chirag Nagpal, Pete Shaw, Jonathan Berant

Language model (LM) post-training (or alignment) involves maximizing a reward
function that is derived from preference annotations. Direct Preference
Optimization (DPO) is a popular offline alignment method that trains a policy
directly on preference data without the need to train a reward model or apply
reinforcement learning. However, typical preference datasets have only a
single, or at most a few, annotation per preference pair, which causes DPO to
overconfidently assign rewards that trend towards infinite magnitude. This
frequently leads to degenerate policies, sometimes causing even the
probabilities of the preferred generations to go to zero. In this work, we
analyze this phenomenon and propose distillation to get a better proxy for the
true preference distribution over generation pairs: we train the LM to produce
probabilities that match the distribution induced by a reward model trained on
the preference data. Moreover, to account for uncertainty in the reward model
we are distilling from, we optimize against a family of reward models that, as
a whole, is likely to include at least one reasonable proxy for the preference
distribution. Our results show that distilling from such a family of reward
models leads to improved robustness to distribution shift in preference
annotations, while preserving the simple supervised nature of DPO.

摘要：語言模型 (LM) 後訓練 (或對齊) 涉及最大化從偏好標註衍生的獎勵函數。直接偏好最佳化 (DPO) 是一種流行的離線對齊方法，它直接在偏好資料上訓練政策，而無需訓練獎勵模型或應用強化學習。然而，典型的偏好資料集對於每個偏好對只有一個，或最多只有幾個標註，這導致 DPO 過於自信地分配趨向於無限大的獎勵。這常常導致策略退化，有時甚至導致偏好生成的機率趨近於零。在這項工作中，我們分析了這種現象並提出蒸餾以獲得更好的生成對偏好分佈代理：我們訓練 LM 產生與根據偏好資料訓練的獎勵模型所引發分佈相匹配的機率。此外，為了說明我們要從中進行蒸餾的獎勵模型中的不確定性，我們針對一個獎勵模型家族進行最佳化，這個家族整體而言很可能至少包含一個偏好分佈的合理代理。我們的結果表明，從這樣的獎勵模型家族進行蒸餾有助於提高偏好標註中分佈轉移的穩健性，同時保留 DPO 簡單的監督性質。

##### **Matryoshka Query Transformer for Large Vision-Language Models**
2405.19315v1 by Wenbo Hu, Zi-Yi Dou, Liunian Harold Li, Amita Kamath, Nanyun Peng, Kai-Wei Chang

Large Vision-Language Models (LVLMs) typically encode an image into a fixed
number of visual tokens (e.g., 576) and process these tokens with a language
model. Despite their strong performance, LVLMs face challenges in adapting to
varying computational constraints. This raises the question: can we achieve
flexibility in the number of visual tokens to suit different tasks and
computational resources? We answer this with an emphatic yes. Inspired by
Matryoshka Representation Learning, we introduce the Matryoshka Query
Transformer (MQT), capable of encoding an image into m visual tokens during
inference, where m can be any number up to a predefined maximum. This is
achieved by employing a query transformer with M latent query tokens to
compress the visual embeddings. During each training step, we randomly select m
<= M latent query tokens and train the model using only these first m tokens,
discarding the rest. Combining MQT with LLaVA, we train a single model once,
and flexibly and drastically reduce the number of inference-time visual tokens
while maintaining similar or better performance compared to training
independent models for each number of tokens. Our model, MQT-LLAVA, matches
LLaVA-1.5 performance across 11 benchmarks using a maximum of 256 tokens
instead of LLaVA's fixed 576. Reducing to 16 tokens (8x less TFLOPs) only
sacrifices the performance by 2.4 points on MMBench. On certain tasks such as
ScienceQA and MMMU, we can even go down to only 2 visual tokens with
performance drops of just 3% and 6% each. Our exploration of the trade-off
between the accuracy and computational cost brought about by the number of
visual tokens facilitates future research to achieve the best of both worlds.

摘要：大型視覺語言模型 (LVLMs) 通常將影像編碼成固定數量的視覺代幣（例如 576 個），並使用語言模型處理這些代幣。儘管 LVLMs 效能強大，但它們在適應不同的運算限制時會遇到挑戰。這引發了一個問題：我們能否調整視覺代幣數量以適應不同的任務和運算資源？我們的答案是肯定的。受到 Matryoshka 表徵學習的啟發，我們引入了 Matryoshka 查詢轉換器 (MQT)，它能夠在推理過程中將影像編碼成 m 個視覺代幣，其中 m 可以是任何小於預定義最大值的數字。這是透過使用具有 M 個潛在查詢代幣的查詢轉換器來壓縮視覺嵌入來實現的。在每個訓練步驟中，我們會隨機選擇 m <= M 個潛在查詢代幣，並僅使用這些前 m 個代幣來訓練模型，捨棄其餘的代幣。將 MQT 與 LLaVA 結合，我們一次訓練一個模型，並靈活且大幅減少推理時間視覺代幣的數量，同時維持與為每個代幣數量訓練獨立模型相當或更好的效能。我們的模型 MQT-LLAVA 使用最多 256 個代幣，而不是 LLaVA 的固定 576 個代幣，在 11 個基準測試中與 LLaVA-1.5 的效能相符。減少到 16 個代幣（8 倍 TFLOPs）只會在 MMBench 上犧牲 2.4 個效能點數。在某些任務上，例如 ScienceQA 和 MMMU，我們甚至可以使用只有 2 個視覺代幣，效能只下降 3% 和 6%。我們探索視覺代幣數量帶來的準確性和運算成本之間的權衡，有助於未來的研究實現兩全其美。

##### **Language Models Trained to do Arithmetic Predict Human Risky and Intertemporal Choice**
2405.19313v1 by Jian-Qiao Zhu, Haijiang Yan, Thomas L. Griffiths

The observed similarities in the behavior of humans and Large Language Models
(LLMs) have prompted researchers to consider the potential of using LLMs as
models of human cognition. However, several significant challenges must be
addressed before LLMs can be legitimately regarded as cognitive models. For
instance, LLMs are trained on far more data than humans typically encounter,
and may have been directly trained on human data in specific cognitive tasks or
aligned with human preferences. Consequently, the origins of these behavioral
similarities are not well understood. In this paper, we propose a novel way to
enhance the utility of LLMs as cognitive models. This approach involves (i)
leveraging computationally equivalent tasks that both an LLM and a rational
agent need to master for solving a cognitive problem and (ii) examining the
specific task distributions required for an LLM to exhibit human-like
behaviors. We apply this approach to decision-making -- specifically risky and
intertemporal choice -- where the key computationally equivalent task is the
arithmetic of expected value calculations. We show that an LLM pretrained on an
ecologically valid arithmetic dataset, which we call Arithmetic-GPT, predicts
human behavior better than many traditional cognitive models. Pretraining LLMs
on ecologically valid arithmetic datasets is sufficient to produce a strong
correspondence between these models and human decision-making. Our results also
suggest that LLMs used as cognitive models should be carefully investigated via
ablation studies of the pretraining data.

摘要：在人類和大型語言模型 (LLM) 的行為中觀察到的相似性促使研究人員考慮將 LLM 用作人類認知模型的可能性。然而，在 LLM 可以被合法地視為認知模型之前，必須解決幾個重大的挑戰。例如，LLM 接受的訓練數據遠多於人類通常遇到的數據，並且可能在特定認知任務中直接接受過人類數據的訓練，或與人類偏好保持一致。因此，這些行為相似性的起源並未得到很好的理解。在本文中，我們提出了一種新方法來增強 LLM 作為認知模型的效用。此方法包括：(i) 利用 LLM 和理性代理都必須掌握的計算等效任務來解決認知問題，以及 (ii) 檢查 LLM 表現出類人行為所需的特定任務分佈。我們將此方法應用於決策制定——特別是冒險和時間間選擇——其中關鍵的計算等效任務是預期值計算的算術。我們表明，在生態學上有效的算術數據集（我們稱之為 Arithmetic-GPT）上預先訓練的 LLM 比許多傳統認知模型更好地預測人類行為。在生態學上有效的算術數據集上對 LLM 進行預訓練足以在這些模型和人類決策制定之間產生強烈的對應關係。我們的結果還表明，用作認知模型的 LLM 應通過預訓練數據的消融研究進行仔細調查。

##### **Measuring and Mitigating Bias for Tabular Datasets with Multiple Protected Attributes**
2405.19300v1 by Manh Khoi Duong, Stefan Conrad

Motivated by the recital (67) of the current corrigendum of the AI Act in the
European Union, we propose and present measures and mitigation strategies for
discrimination in tabular datasets. We specifically focus on datasets that
contain multiple protected attributes, such as nationality, age, and sex. This
makes measuring and mitigating bias more challenging, as many existing methods
are designed for a single protected attribute. This paper comes with a twofold
contribution: Firstly, new discrimination measures are introduced. These
measures are categorized in our framework along with existing ones, guiding
researchers and practitioners in choosing the right measure to assess the
fairness of the underlying dataset. Secondly, a novel application of an
existing bias mitigation method, FairDo, is presented. We show that this
strategy can mitigate any type of discrimination, including intersectional
discrimination, by transforming the dataset. By conducting experiments on
real-world datasets (Adult, Bank, Compas), we demonstrate that de-biasing
datasets with multiple protected attributes is achievable. Further, the
transformed fair datasets do not compromise any of the tested machine learning
models' performances significantly when trained on these datasets compared to
the original datasets. Discrimination was reduced by up to 83% in our
experimentation. For most experiments, the disparity between protected groups
was reduced by at least 7% and 27% on average. Generally, the findings show
that the mitigation strategy used is effective, and this study contributes to
the ongoing discussion on the implementation of the European Union's AI Act.

摘要：<paragraph>受歐盟 AI 法案最新更正案 (67) 的啟發，我們提出並展示了用於表格資料集中歧視的措施和緩解策略。我們特別關注包含多重受保護屬性的資料集，例如國籍、年齡和性別。這使得衡量和減輕偏見更具挑戰性，因為許多現有方法都是針對單一受保護屬性設計的。本文具有雙重貢獻：首先，引入了新的歧視措施。這些措施與現有措施一起分類在我們的框架中，指導研究人員和從業者選擇正確的措施來評估基礎資料集的公平性。其次，展示了現有偏見緩解方法 FairDo 的一種新應用。我們表明，這種策略可以通過轉換資料集來減輕任何類型的歧視，包括交叉歧視。通過對真實世界資料集（Adult、Bank、Compas）進行實驗，我們證明了對具有多重受保護屬性的資料集進行去偏見是可行的。此外，與原始資料集相比，在這些資料集上訓練時，轉換後的公平資料集不會顯著損害任何已測試機器學習模型的性能。在我們的實驗中，歧視減少了 83%。對於大多數實驗，受保護群體之間的差異平均減少了至少 7% 和 27%。總的來說，研究結果表明所使用的緩解策略是有效的，並且本研究有助於對歐盟 AI 法案實施的持續討論。</paragraph>

##### **Expert-Guided Extinction of Toxic Tokens for Debiased Generation**
2405.19299v1 by Xueyao Sun, Kaize Shi, Haoran Tang, Guandong Xu, Qing Li

Large language models (LLMs) can elicit social bias during generations,
especially when inference with toxic prompts. Controlling the sensitive
attributes in generation encounters challenges in data distribution,
generalizability, and efficiency. Specifically, fine-tuning and retrieval
demand extensive unbiased corpus, while direct prompting requires meticulously
curated instructions for correcting the output in multiple rounds of thoughts
but poses challenges on memory and inference latency. In this work, we propose
the Expert-Guided Extinction of Toxic Tokens for Debiased Generation (EXPOSED)
to eliminate the undesired harmful outputs for LLMs without the aforementioned
requirements. EXPOSED constructs a debiasing expert based on the abundant toxic
corpus to expose and elicit the potentially dangerous tokens. It then processes
the output to the LLMs and constructs a fair distribution by suppressing and
attenuating the toxic tokens. EXPOSED is evaluated on fairness benchmarks over
three LLM families. Extensive experiments demonstrate that compared with other
baselines, the proposed EXPOSED significantly reduces the potential social bias
while balancing fairness and generation performance.

摘要：大型語言模型（LLM）在生成過程中可能會引發社會偏見，特別是在使用有毒提示進行推論時。在生成過程中控制敏感屬性會遇到數據分佈、泛化性和效率方面的挑戰。具體來說，微調和檢索需要大量的無偏數據集，而直接提示需要仔細策劃的指令，才能在多輪思考中糾正輸出，但對記憶體和推論延遲提出了挑戰。在這項工作中，我們提出了有毒符號的專家指導滅絕，用於無偏生成（EXPOSED），以消除 LLM 的不需要的有害輸出，而無需上述要求。EXPOSED 基於豐富的有毒語料庫構建了一個去偏專家，以揭露和引出潛在的危險標記。然後，它處理 LLM 的輸出，並通過抑制和衰減有毒標記來構建一個公平的分配。EXPOSED 在三個 LLM 家族的公平基準上進行了評估。大量的實驗表明，與其他基線相比，所提出的 EXPOSED 在平衡公平性和生成性能的同時，顯著降低了潛在的社會偏見。

##### **Integrating Multi-scale Contextualized Information for Byte-based Neural Machine Translation**
2405.19290v1 by Langlin Huang, Yang Feng

Subword tokenization is a common method for vocabulary building in Neural
Machine Translation (NMT) models. However, increasingly complex tasks have
revealed its disadvantages. First, a vocabulary cannot be modified once it is
learned, making it hard to adapt to new words. Second, in multilingual
translation, the imbalance in data volumes across different languages spreads
to the vocabulary, exacerbating translations involving low-resource languages.
While byte-based tokenization addresses these issues, byte-based models
struggle with the low information density inherent in UTF-8 byte sequences.
Previous works enhance token semantics through local contextualization but fail
to select an appropriate contextualizing scope based on the input.
Consequently, we propose the Multi-Scale Contextualization (MSC) method, which
learns contextualized information of varying scales across different hidden
state dimensions. It then leverages the attention module to dynamically
integrate the multi-scale contextualized information. Experiments show that MSC
significantly outperforms subword-based and other byte-based methods in both
multilingual and out-of-domain scenarios. Code can be found in
https://github.com/ictnlp/Multiscale-Contextualization.

摘要：次單元詞彙化是神經機器翻譯 (NMT) 模型中建立詞彙的常見方法。然而，日益複雜的任務揭露了它的缺點。首先，一旦詞彙被學習，它就不能被修改，這使得它難以適應新詞彙。其次，在多語言翻譯中，不同語言之間的資料量不平衡會擴散到詞彙中，加劇涉及低資源語言的翻譯。雖然基於位元組的詞彙化可解決這些問題，但基於位元組的模型難以處理 UTF-8 位元組序列中固有的低資訊密度。先前的作品透過局部脈絡化來增強詞彙語義，但無法根據輸入選擇適當的脈絡化範圍。因此，我們提出多尺度脈絡化 (MSC) 方法，它跨不同隱藏狀態維度學習不同尺度的脈絡化資訊。然後，它利用注意力模組動態整合多尺度脈絡化資訊。實驗表明，MSC 在多語言和領域外場景中都明顯優於基於次單元詞和基於位元組的其他方法。程式碼可在 https://github.com/ictnlp/Multiscale-Contextualization 中找到。

##### **MASSIVE Multilingual Abstract Meaning Representation: A Dataset and Baselines for Hallucination Detection**
2405.19285v1 by Michael Regan, Shira Wein, George Baker, Emilio Monti

Abstract Meaning Representation (AMR) is a semantic formalism that captures
the core meaning of an utterance. There has been substantial work developing
AMR corpora in English and more recently across languages, though the limited
size of existing datasets and the cost of collecting more annotations are
prohibitive. With both engineering and scientific questions in mind, we
introduce MASSIVE-AMR, a dataset with more than 84,000 text-to-graph
annotations, currently the largest and most diverse of its kind: AMR graphs for
1,685 information-seeking utterances mapped to 50+ typologically diverse
languages. We describe how we built our resource and its unique features before
reporting on experiments using large language models for multilingual AMR and
SPARQL parsing as well as applying AMRs for hallucination detection in the
context of knowledge base question answering, with results shedding light on
persistent issues using LLMs for structured parsing.

摘要：抽象語意表示（AMR）是一種語意形式化，用於捕捉語句的核心含義。
目前已有大量工作致力於開發英文 AMR 語料庫，最近更擴展到跨語言，儘管現有資料集規模有限，且收集更多標註的成本過高。
考量到工程和科學方面的問題，我們引入了 MASSIVE-AMR，這是一個包含超過 84,000 個文字轉圖形標註的資料集，目前是同類資料集中規模最大且最多樣化的：AMR 圖形涵蓋 1,685 個資訊尋求語句，對應到 50 多種語言類型多樣的語言。
我們將說明如何建構資源及其獨特功能，然後再報告使用大型語言模型進行多語言 AMR 和 SPARQL 解析的實驗，以及在知識庫問答的背景下應用 AMR 進行幻覺偵測，結果有助於釐清使用 LLM 進行結構化解析時持續存在的問題。

##### **Optimizing Foundation Model Inference on a Many-tiny-core Open-source RISC-V Platform**
2405.19284v1 by Viviane Potocnik, Luca Colagrande, Tim Fischer, Luca Bertaccini, Daniele Jahier Pagliari, Alessio Burrello, Luca Benini

Transformer-based foundation models have become crucial for various domains,
most notably natural language processing (NLP) or computer vision (CV). These
models are predominantly deployed on high-performance GPUs or hardwired
accelerators with highly customized, proprietary instruction sets. Until now,
limited attention has been given to RISC-V-based general-purpose platforms. In
our work, we present the first end-to-end inference results of transformer
models on an open-source many-tiny-core RISC-V platform implementing
distributed Softmax primitives and leveraging ISA extensions for SIMD
floating-point operand streaming and instruction repetition, as well as
specialized DMA engines to minimize costly main memory accesses and to tolerate
their latency. We focus on two foundational transformer topologies,
encoder-only and decoder-only models. For encoder-only models, we demonstrate a
speedup of up to 12.8x between the most optimized implementation and the
baseline version. We reach over 79% FPU utilization and 294 GFLOPS/W,
outperforming State-of-the-Art (SoA) accelerators by more than 2x utilizing the
HW platform while achieving comparable throughput per computational unit. For
decoder-only topologies, we achieve 16.1x speedup in the Non-Autoregressive
(NAR) mode and up to 35.6x speedup in the Autoregressive (AR) mode compared to
the baseline implementation. Compared to the best SoA dedicated accelerator, we
achieve 2.04x higher FPU utilization.

摘要：<paragraph>基於 Transformer 的基礎模型已成為各種領域的關鍵，
最著名的是自然語言處理 (NLP) 或電腦視覺 (CV)。這些
模型主要部署在高性能 GPU 或硬接線
加速器上，具有高度客製化的專有指令集。到目前為止，
基於 RISC-V 的通用平台受到的關注有限。在
我們的研究中，我們展示了 Transformer
模型在開源多微核心 RISC-V 平台上的第一個端到端推論結果，實作
分散式 Softmax 原語並利用 ISA 延伸進行 SIMD
浮點運算元串流和指令重複，以及
專用 DMA 引擎以最小化昂貴的主記憶體存取並容忍
其延遲。我們專注於兩個基礎 Transformer 拓撲，
僅編碼器和僅解碼器模型。對於僅編碼器模型，我們展示了
在最佳化實作和基線版本之間高達 12.8 倍的加速。我們達到超過 79% 的 FPU 使用率和 294 GFLOPS/W，
在利用
HW 平台的同時，其效能優於最先進 (SoA) 加速器 2 倍以上，並實現每計算單元的可比吞吐量。對於
僅解碼器拓撲，我們在非自迴歸
(NAR) 模式中實現了 16.1 倍的加速，在自迴歸
(AR) 模式中實現了高達 35.6 倍的加速，與
基線實作相比。與最佳 SoA 專用加速器相比，我們
實現了 2.04 倍更高的 FPU 使用率。</paragraph>

##### **PediatricsGPT: Large Language Models as Chinese Medical Assistants for Pediatric Applications**
2405.19266v1 by Dingkang Yang, Jinjie Wei, Dongling Xiao, Shunli Wang, Tong Wu, Gang Li, Mingcheng Li, Shuaibing Wang, Jiawei Chen, Yue Jiang, Qingyao Xu, Ke Li, Peng Zhai, Lihua Zhang

Developing intelligent pediatric consultation systems offers promising
prospects for improving diagnostic efficiency, especially in China, where
healthcare resources are scarce. Despite recent advances in Large Language
Models (LLMs) for Chinese medicine, their performance is sub-optimal in
pediatric applications due to inadequate instruction data and vulnerable
training procedures. To address the above issues, this paper builds PedCorpus,
a high-quality dataset of over 300,000 multi-task instructions from pediatric
textbooks, guidelines, and knowledge graph resources to fulfil diverse
diagnostic demands. Upon well-designed PedCorpus, we propose PediatricsGPT, the
first Chinese pediatric LLM assistant built on a systematic and robust training
pipeline. In the continuous pre-training phase, we introduce a hybrid
instruction pre-training mechanism to mitigate the internal-injected knowledge
inconsistency of LLMs for medical domain adaptation. Immediately, the
full-parameter Supervised Fine-Tuning (SFT) is utilized to incorporate the
general medical knowledge schema into the models. After that, we devise a
direct following preference optimization to enhance the generation of
pediatrician-like humanistic responses. In the parameter-efficient secondary
SFT phase, a mixture of universal-specific experts strategy is presented to
resolve the competency conflict between medical generalist and pediatric
expertise mastery. Extensive results based on the metrics, GPT-4, and doctor
evaluations on distinct doctor downstream tasks show that PediatricsGPT
consistently outperforms previous Chinese medical LLMs. Our model and dataset
will be open-source for community development.

摘要：<paragraph>開發智能兒童諮詢系統，為提高診斷效率提供了有希望的前景，特別是在醫療資源稀缺的中國。儘管中文醫學的大語言模型（LLM）最近取得進展，但由於教學資料不足和培訓程序脆弱，它們在兒科應用中的表現並非最佳。為了解決上述問題，本文構建了 PedCorpus，一個由超過 30 萬條來自兒科教科書、指南和知識圖譜資源的多任務指令組成的優質數據集，以滿足不同的診斷需求。在設計良好的 PedCorpus 上，我們提出了 PediatricsGPT，這是第一個建立在系統且強大的訓練管道上的中文兒科 LLM 助手。在持續的預訓練階段，我們引入了一個混合指令預訓練機制，以減輕 LLM 在醫學領域適應中的內部注入知識不一致。緊接著，利用全參數監督微調（SFT）將一般醫學知識架構納入模型中。在那之後，我們設計了一個直接遵循偏好最佳化，以增強類兒科醫生的人文反應生成。在參數效率的次要 SFT 階段，提出了一個通用特定專家策略的混合，以解決內科醫生和兒科專業掌握之間的能力衝突。基於指標、GPT-4 和醫生對不同醫生下游任務的評估的廣泛結果表明，PediatricsGPT 持續優於先前的中文醫學 LLM。我們的模型和數據集將對社群開發開放原始碼。</paragraph>

##### **AlchemistCoder: Harmonizing and Eliciting Code Capability by Hindsight Tuning on Multi-source Data**
2405.19265v1 by Zifan Song, Yudong Wang, Wenwei Zhang, Kuikun Liu, Chengqi Lyu, Demin Song, Qipeng Guo, Hang Yan, Dahua Lin, Kai Chen, Cairong Zhao

Open-source Large Language Models (LLMs) and their specialized variants,
particularly Code LLMs, have recently delivered impressive performance.
However, previous Code LLMs are typically fine-tuned on single-source data with
limited quality and diversity, which may insufficiently elicit the potential of
pre-trained Code LLMs. In this paper, we present AlchemistCoder, a series of
Code LLMs with enhanced code generation and generalization capabilities
fine-tuned on multi-source data. To achieve this, we pioneer to unveil inherent
conflicts among the various styles and qualities in multi-source code corpora
and introduce data-specific prompts with hindsight relabeling, termed
AlchemistPrompts, to harmonize different data sources and instruction-response
pairs. Additionally, we propose incorporating the data construction process
into the fine-tuning data as code comprehension tasks, including instruction
evolution, data filtering, and code review. Extensive experiments demonstrate
that AlchemistCoder holds a clear lead among all models of the same size
(6.7B/7B) and rivals or even surpasses larger models (15B/33B/70B), showcasing
the efficacy of our method in refining instruction-following capabilities and
advancing the boundaries of code intelligence.

摘要：<paragraph>開放原始碼大型語言模型 (LLM) 及其專用變體，尤其是程式碼大型語言模型，最近展現了令人印象深刻的效能。然而，先前的程式碼大型語言模型通常會針對單一來源資料進行微調，但品質和多樣性有限，可能無法充分引發預先訓練的程式碼大型語言模型的潛力。在本文中，我們提出 AlchemistCoder，它是一系列程式碼大型語言模型，具備增強的程式碼產生和概化能力，針對多來源資料進行微調。為達成此目的，我們率先揭示多來源程式碼語料庫中各種風格和品質之間的內在衝突，並引入具有回顧性重新標記的資料特定提示，稱為 AlchemistPrompts，以協調不同的資料來源和指令回應配對。此外，我們建議將資料建構程序納入微調資料中，作為程式碼理解任務，包括指令演進、資料篩選和程式碼檢閱。廣泛的實驗證明 AlchemistCoder 在所有相同大小的模型中（6.7B/7B）都具有明顯領先地位，並與較大的模型（15B/33B/70B）競爭甚至超越它們，展示了我們的方法在精進指令遵循能力和推進程式碼智慧邊界方面的效力。</paragraph>

##### **Weak-to-Strong Search: Align Large Language Models via Searching over Small Language Models**
2405.19262v1 by Zhanhui Zhou, Zhixuan Liu, Jie Liu, Zhichen Dong, Chao Yang, Yu Qiao

Large language models are usually fine-tuned to align with human preferences.
However, fine-tuning a large language model can be challenging. In this work,
we introduce $\textit{weak-to-strong search}$, framing the alignment of a large
language model as a test-time greedy search to maximize the log-likelihood
difference between small tuned and untuned models while sampling from the
frozen large model. This method serves both as (i) a compute-efficient model
up-scaling strategy that avoids directly tuning the large model and as (ii) an
instance of weak-to-strong generalization that enhances a strong model with
weak test-time guidance. Empirically, we demonstrate the flexibility of
weak-to-strong search across different tasks. In controlled-sentiment
generation and summarization, we use tuned and untuned $\texttt{gpt2}$s to
effectively improve the alignment of large models without additional training.
Crucially, in a more difficult instruction-following benchmark, AlpacaEval 2.0,
we show that reusing off-the-shelf small model pairs (e.g.,
$\texttt{zephyr-7b-beta}$ and its untuned version) can significantly improve
the length-controlled win rates of both white-box and black-box large models
against $\texttt{gpt-4-turbo}$ (e.g., $34.4 \rightarrow 37.9$ for
$\texttt{Llama-3-70B-Instruct}$ and $16.0 \rightarrow 20.1$ for
$\texttt{gpt-3.5-turbo-instruct}$), despite the small models' low win rates
$\approx 10.0$.

摘要：大型語言模型通常經過微調，以符合人類的偏好。
然而，微調大型語言模型可能具有挑戰性。在這項工作中，
我們引入了「弱到強搜尋」，將大型語言模型的對齊設定為測試時間貪婪搜尋，以最大化小型的調整和未調整模型之間的對數似然差異，同時從凍結的大型模型中取樣。這種方法同時作為 (i) 一種計算有效率的模型升級策略，避免直接調整大型模型，以及 (ii) 一種弱到強泛化的實例，它使用弱測試時間指導增強強模型。根據經驗，我們展示了弱到強搜尋在不同任務中的靈活性。在受控情緒生成和摘要中，我們使用調整和未調整的 $\texttt{gpt2}$ 有效地改善了大型模型的對齊，而無需額外的訓練。
至關重要的是，在一個更困難的指令遵循基準 AlpacaEval 2.0 中，我們表明重複使用現成的小型模型對（例如，
$\texttt{zephyr-7b-beta}$ 及其未調整版本）可以顯著提高白盒和黑盒大型模型相對於 $\texttt{gpt-4-turbo}$ 的長度控制獲勝率（例如，$34.4 \rightarrow 37.9$ 對於
$\texttt{Llama-3-70B-Instruct}$ 和 $16.0 \rightarrow 20.1$ 對於
$\texttt{gpt-3.5-turbo-instruct}$），儘管小型模型的獲勝率低
$\approx 10.0$。

##### **Faster Cascades via Speculative Decoding**
2405.19261v1 by Harikrishna Narasimhan, Wittawat Jitkrittum, Ankit Singh Rawat, Seungyeon Kim, Neha Gupta, Aditya Krishna Menon, Sanjiv Kumar

Cascades and speculative decoding are two common approaches to improving
language models' inference efficiency. Both approaches involve interleaving
models of different sizes, but via fundamentally distinct mechanisms: cascades
employ a deferral rule that invokes the larger model only for "hard" inputs,
while speculative decoding uses speculative execution to primarily invoke the
larger model in parallel verification mode. These mechanisms offer different
benefits: empirically, cascades are often capable of yielding better quality
than even the larger model, while theoretically, speculative decoding offers a
guarantee of quality-neutrality. In this paper, we leverage the best of both
these approaches by designing new speculative cascading techniques that
implement their deferral rule through speculative execution. We characterize
the optimal deferral rule for our speculative cascades, and employ a plug-in
approximation to the optimal rule. Through experiments with T5 models on
benchmark language tasks, we show that the proposed approach yields better
cost-quality trade-offs than cascading and speculative decoding baselines.

摘要：串聯和推測解碼是改善語言模型推論效率的兩種常見方法。兩種方法都涉及交錯不同規模的模型，但透過根本不同的機制：串聯採用遞延規則，僅對「困難」輸入調用較大的模型，而推測解碼則使用推測執行，主要在平行驗證模式中調用較大的模型。這些機制提供了不同的好處：根據經驗，串聯通常能夠產生比更大模型更好的品質，而理論上，推測解碼則保證品質中立性。在本文中，我們透過設計新的推測串聯技術，並透過推測執行來實作其遞延規則，來利用這兩種方法的優點。我們描述了推測串聯的最佳遞延規則，並採用最佳規則的外掛近似值。透過在基準語言任務上使用 T5 模型進行的實驗，我們展示了所提出的方法產生的成本品質權衡優於串聯和推測解碼基準。

##### **Towards Next-Generation Urban Decision Support Systems through AI-Powered Generation of Scientific Ontology using Large Language Models -- A Case in Optimizing Intermodal Freight Transportation**
2405.19255v1 by Jose Tupayachi, Haowen Xu, Olufemi A. Omitaomu, Mustafa Can Camur, Aliza Sharmin, Xueping Li

The incorporation of Artificial Intelligence (AI) models into various
optimization systems is on the rise. Yet, addressing complex urban and
environmental management problems normally requires in-depth domain science and
informatics expertise. This expertise is essential for deriving data and
simulation-driven for informed decision support. In this context, we
investigate the potential of leveraging the pre-trained Large Language Models
(LLMs). By adopting ChatGPT API as the reasoning core, we outline an integrated
workflow that encompasses natural language processing, methontology-based
prompt tuning, and transformers. This workflow automates the creation of
scenario-based ontology using existing research articles and technical manuals
of urban datasets and simulations. The outcomes of our methodology are
knowledge graphs in widely adopted ontology languages (e.g., OWL, RDF, SPARQL).
These facilitate the development of urban decision support systems by enhancing
the data and metadata modeling, the integration of complex datasets, the
coupling of multi-domain simulation models, and the formulation of
decision-making metrics and workflow. The feasibility of our methodology is
evaluated through a comparative analysis that juxtaposes our AI-generated
ontology with the well-known Pizza Ontology employed in tutorials for popular
ontology software (e.g., prot\'eg\'e). We close with a real-world case study of
optimizing the complex urban system of multi-modal freight transportation by
generating anthologies of various domain data and simulations to support
informed decision-making.

摘要：人工智能 (AI) 模型整合到各種最佳化系統中正方興未艾。然而，解決複雜的都市和環境管理問題通常需要深入的領域科學和資訊專業知識。這種專業知識對於從資料和模擬中推導出資料驅動的明智決策支援至關重要。在此脈絡下，我們探討利用預先訓練的大語言模型 (LLM) 的潛力。透過採用 ChatGPT API 作為推理核心，我們概述一個整合的工作流程，其中包含自然語言處理、基於方法論的提示調整和轉換器。此工作流程自動化使用現有研究文章和都市資料集及模擬技術手冊建立基於情境的本体。我們方法論的成果是廣泛採用的本体語言（例如 OWL、RDF、SPARQL）中的知識圖譜。這些知識圖譜透過增強資料和元資料建模、整合複雜的資料集、結合多領域模擬模型，以及制定決策指標和工作流程，促進都市決策支援系統的發展。我們透過比較分析評估我們方法論的可行性，該分析將我們 AI 生成的本体與廣泛用於熱門本体軟體 (例如 prot\'eg\'e) 教學課程的知名 Pizza 本体並置。我們以一個真實世界的案例研究作結，透過產生各種領域資料和模擬的選集來最佳化多式聯運貨運的複雜都市系統，以支援明智的決策制定。

##### **Kotlin ML Pack: Technical Report**
2405.19250v1 by Sergey Titov, Mikhail Evtikhiev, Anton Shapkin, Oleg Smirnov, Sergei Boytsov, Sergei Boytsov, Dariia Karaeva, Maksim Sheptyakov, Mikhail Arkhipov, Timofey Bryksin, Egor Bogomolov

In this technical report, we present three novel datasets of Kotlin code:
KStack, KStack-clean, and KExercises. We also describe the results of
fine-tuning CodeLlama and DeepSeek models on this data. Additionally, we
present a version of the HumanEval benchmark rewritten by human experts into
Kotlin - both the solutions and the tests. Our results demonstrate that small,
high-quality datasets (KStack-clean and KExercises) can significantly improve
model performance on code generation tasks, achieving up to a 16-point increase
in pass rate on the HumanEval benchmark. Lastly, we discuss potential future
work in the field of improving language modeling for Kotlin, including the use
of static analysis tools in the learning process and the introduction of more
intricate and realistic benchmarks.

摘要：在這份技術報告中，我們展示了三個新的 Kotlin 程式碼資料集：
KStack、KStack-clean 和 KExercises。我們也描述了在這些資料上微調 CodeLlama 和 DeepSeek 模型的結果。此外，我們展示了由人類專家改寫成 Kotlin 的 HumanEval 基準測試版本，包括解答和測試。我們的結果證明，小型、高品質的資料集（KStack-clean 和 KExercises）可以大幅提升程式碼產生任務的模型效能，在 HumanEval 基準測試中達成通過率提升 16 點。最後，我們討論了 Kotlin 語言模型改進領域的潛在未來工作，包括在學習過程中使用靜態分析工具，以及引入更複雜且更貼近現實的基準測試。

##### **ConceptPrune: Concept Editing in Diffusion Models via Skilled Neuron Pruning**
2405.19237v1 by Ruchika Chavhan, Da Li, Timothy Hospedales

While large-scale text-to-image diffusion models have demonstrated impressive
image-generation capabilities, there are significant concerns about their
potential misuse for generating unsafe content, violating copyright, and
perpetuating societal biases. Recently, the text-to-image generation community
has begun addressing these concerns by editing or unlearning undesired concepts
from pre-trained models. However, these methods often involve data-intensive
and inefficient fine-tuning or utilize various forms of token remapping,
rendering them susceptible to adversarial jailbreaks. In this paper, we present
a simple and effective training-free approach, ConceptPrune, wherein we first
identify critical regions within pre-trained models responsible for generating
undesirable concepts, thereby facilitating straightforward concept unlearning
via weight pruning. Experiments across a range of concepts including artistic
styles, nudity, object erasure, and gender debiasing demonstrate that target
concepts can be efficiently erased by pruning a tiny fraction, approximately
0.12% of total weights, enabling multi-concept erasure and robustness against
various white-box and black-box adversarial attacks.

摘要：儘管大規模文字轉圖像擴散模型已經展示出令人印象深刻的影像生成能力，對於它們在產生不安全內容、侵犯版權和延續社會偏見方面的潛在濫用，仍有相當大的疑慮。最近，文字轉圖像生成社群已經開始透過編輯或遺忘預訓練模型中的不良概念來解決這些疑慮。然而，這些方法通常涉及資料密集且低效率的微調，或使用各種形式的權杖重新對應，使其容易受到對抗性的越獄攻擊。在本文中，我們提出一個簡單且有效的無訓練方法，ConceptPrune，其中我們首先識別預訓練模型中負責產生不良概念的重要區域，從而透過權重剪枝來促進直接的概念遺忘。透過包含藝術風格、裸露、物體消除和性別去偏見等一系列概念的實驗，證明目標概念可以透過剪枝極小的部分（約為總權重的 0.12%）來有效消除，從而實現多概念消除並對抗各種白盒和黑盒對抗攻擊的穩健性。

##### **On Generating Monolithic and Model Reconciling Explanations in Probabilistic Scenarios**
2405.19229v1 by Stylianos Loukas Vasileiou, William Yeoh, Alessandro Previti, Tran Cao Son

Explanation generation frameworks aim to make AI systems' decisions
transparent and understandable to human users. However, generating explanations
in uncertain environments characterized by incomplete information and
probabilistic models remains a significant challenge. In this paper, we propose
a novel framework for generating probabilistic monolithic explanations and
model reconciling explanations. Monolithic explanations provide self-contained
reasons for an explanandum without considering the agent receiving the
explanation, while model reconciling explanations account for the knowledge of
the agent receiving the explanation. For monolithic explanations, our approach
integrates uncertainty by utilizing probabilistic logic to increase the
probability of the explanandum. For model reconciling explanations, we propose
a framework that extends the logic-based variant of the model reconciliation
problem to account for probabilistic human models, where the goal is to find
explanations that increase the probability of the explanandum while minimizing
conflicts between the explanation and the probabilistic human model. We
introduce explanatory gain and explanatory power as quantitative metrics to
assess the quality of these explanations. Further, we present algorithms that
exploit the duality between minimal correction sets and minimal unsatisfiable
sets to efficiently compute both types of explanations in probabilistic
contexts. Extensive experimental evaluations on various benchmarks demonstrate
the effectiveness and scalability of our approach in generating explanations
under uncertainty.

摘要：解釋產生架構旨在使 AI 系統的決策對人類使用者透明且易於理解。然而，在不完整資訊和機率模型所特徵的不確定環境中產生解釋仍然是一項重大的挑戰。在本文中，我們提出了一個產生機率性整體解釋和模型調和解釋的新穎架構。整體解釋提供了解釋對象的獨立原因，而不考慮接收解釋的代理，而模型調和解釋則考量接收解釋的代理的知識。對於整體解釋，我們的做法透過利用機率邏輯來整合不確定性，以增加解釋對象的機率。對於模型調和解釋，我們提出一個架構，將模型調和問題的基於邏輯變體延伸，以考量機率性人類模型，目標是找到在最小化解釋與機率性人類模型之間衝突的同時，增加解釋對象機率的解釋。我們引入了解釋增益和解釋力作為量化指標，以評估這些解釋的品質。此外，我們提出利用最小修正集和最小不可滿足集之間的對偶性，在機率脈絡中有效率地計算這兩種類型的解釋的演算法。在各種基準上的廣泛實驗評估證明了我們在不確定性下產生解釋的方法的有效性和可擴充性。

##### **Lower Bounds on the Expressivity of Recurrent Neural Language Models**
2405.19222v1 by Anej Svete, Franz Nowak, Anisha Mohamed Sahabdeen, Ryan Cotterell

The recent successes and spread of large neural language models (LMs) call
for a thorough understanding of their computational ability. Describing their
computational abilities through LMs' \emph{representational capacity} is a
lively area of research. However, investigation into the representational
capacity of neural LMs has predominantly focused on their ability to
\emph{recognize} formal languages. For example, recurrent neural networks
(RNNs) with Heaviside activations are tightly linked to regular languages,
i.e., languages defined by finite-state automata (FSAs). Such results, however,
fall short of describing the capabilities of RNN \emph{language models} (LMs),
which are definitionally \emph{distributions} over strings. We take a fresh
look at the representational capacity of RNN LMs by connecting them to
\emph{probabilistic} FSAs and demonstrate that RNN LMs with linearly bounded
precision can express arbitrary regular LMs.

摘要：近期大型神经语言模型 (LM) 的成功与扩散，呼吁人们彻底了解其计算能力。透过 LM 的「表征能力」来描述其计算能力，是研究领域中的热门议题。然而，对于神经 LM 表征能力的研究，主要集中于其「辨识」形式语言的能力。举例来说，具有 Heaviside 激活函数的循环神经网络 (RNN) 与正则语言紧密相关，亦即由有限状态自动机 (FSA) 所定义的语言。然而，此类结果无法充分描述 RNN「语言模型」(LM) 的能力，而语言模型在定义上是字串上的「分布」。我们透过将 RNN LM 与「概率」FSA 联系起来，重新审视 RNN LM 的表征能力，并证明具有线性有界精度的 RNN LM 可以表达任意正则 LM。

##### **WRDScore: New Metric for Evaluation of Natural Language Generation Models**
2405.19220v1 by Ravil Mussabayev

The problem of natural language generation, and, more specifically, method
name prediction, faces significant difficulties when proposed models need to be
evaluated on test data. Such a metric would need to consider the versatility
with which a single method can be named, with respect to both semantics and
syntax. Measuring the direct overlap between the predicted and reference (true)
sequences will not be able to capture these subtleties. Other existing
embedding based metrics either do not measure precision and recall or impose
strict unrealistic assumptions on both sequences. To address these issues, we
propose a new metric that, on the one hand, is very simple and lightweight,
and, on the other hand, is able to calculate precision and recall without
resorting to any assumptions while obtaining good performance with respect to
the human judgement.

摘要：自然語言生成的問題，更具體來說，方法名稱預測，在提議的模型需要在測試資料上進行評估時，會面臨重大的困難。這樣的指標需要考慮單一方法可以被命名的多功能性，無論是在語義還是語法上。測量預測序列和參考（真實）序列之間的直接重疊將無法捕捉到這些細微差別。其他現有的基於嵌入的指標，要不就是沒有測量準確度和召回率，要不就是對兩個序列施加嚴格不切實際的假設。為了解決這些問題，我們提出一個新的指標，一方面非常簡單且輕量級，另一方面，能夠計算準確度和召回率，而無需訴諸任何假設，同時在人類判斷方面獲得良好的效能。

##### **HawkVision: Low-Latency Modeless Edge AI Serving**
2405.19213v1 by ChonLam Lao, Jiaqi Gao, Ganesh Ananthanarayanan, Aditya Akella, Minlan Yu

The trend of modeless ML inference is increasingly growing in popularity as
it hides the complexity of model inference from users and caters to diverse
user and application accuracy requirements. Previous work mostly focuses on
modeless inference in data centers. To provide low-latency inference, in this
paper, we promote modeless inference at the edge. The edge environment
introduces additional challenges related to low power consumption, limited
device memory, and volatile network environments.
  To address these challenges, we propose HawkVision, which provides
low-latency modeless serving of vision DNNs. HawkVision leverages a two-layer
edge-DC architecture that employs confidence scaling to reduce the number of
model options while meeting diverse accuracy requirements. It also supports
lossy inference under volatile network environments. Our experimental results
show that HawkVision outperforms current serving systems by up to 1.6X in P99
latency for providing modeless service. Our FPGA prototype demonstrates similar
performance at certain accuracy levels with up to a 3.34X reduction in power
consumption.

摘要：無模式 ML 推論趨勢越來越受到歡迎，因為它隱藏了模型推論的複雜性，且能滿足不同的使用者和應用程式準確度需求。先前的研究大多著重於資料中心的無模式推論。為了提供低延遲推論，我們在這篇論文中推廣邊緣的無模式推論。邊緣環境引入了其他挑戰，例如低功耗、有限的裝置記憶體和不穩定的網路環境。
為了應對這些挑戰，我們提出 HawkVision，它提供低延遲的視覺 DNN 無模式服務。HawkVision 採用雙層邊緣-DC 架構，運用信心縮放來減少模型選項數量，同時滿足不同的準確度需求。它還支援不穩定網路環境下的有損推論。我們的實驗結果顯示，HawkVision 在提供無模式服務時，P99 延遲比目前的服務系統快 1.6 倍。我們的 FPGA 原型在某些準確度等級下展現類似的效能，同時將功耗降低多達 3.34 倍。

##### **Gradient Guided Hypotheses: A unified solution to enable machine learning models on scarce and noisy data regimes**
2405.19210v1 by Paulo Neves, Joerg K. Wegner, Philippe Schwaller

Ensuring high-quality data is paramount for maximizing the performance of
machine learning models and business intelligence systems. However, challenges
in data quality, including noise in data capture, missing records, limited data
production, and confounding variables, significantly constrain the potential
performance of these systems. In this study, we propose an
architecture-agnostic algorithm, Gradient Guided Hypotheses (GGH), designed to
address these challenges. GGH analyses gradients from hypotheses as a proxy of
distinct and possibly contradictory patterns in the data. This framework
entails an additional step in machine learning training, where gradients can be
included or excluded from backpropagation. In this manner, missing and noisy
data are addressed through a unified solution that perceives both challenges as
facets of the same overarching issue: the propagation of erroneous information.
Experimental validation of GGH is conducted using real-world open-source
datasets, where records with missing rates of up to 98.5% are simulated.
Comparative analysis with state-of-the-art imputation methods demonstrates a
substantial improvement in model performance achieved by GGH. Specifically in
very high scarcity regimes, GGH was found to be the only viable solution.
Additionally, GGH's noise detection capabilities are showcased by introducing
simulated noise into the datasets and observing enhanced model performance
after filtering out the noisy data. This study presents GGH as a promising
solution for improving data quality and model performance in various
applications.

摘要：確保高品質的資料對於最大化機器學習模型和商業智慧系統的效能至關重要。然而，資料品質上的挑戰，包括資料擷取中的雜訊、遺失的記錄、有限的資料產生和混淆變數，大幅限制了這些系統的潛在效能。在本研究中，我們提出了一個與架構無關的演算法，稱為梯度引導假設 (GGH)，旨在解決這些挑戰。GGH 將假設中的梯度分析為資料中不同且可能相互矛盾模式的代理。此架構包含機器學習訓練中的額外步驟，其中梯度可以包含或排除在反向傳播中。以這種方式，遺失和有雜訊的資料透過一個統一的解決方案得到處理，該解決方案將這兩個挑戰視為同一整體問題的層面：錯誤資訊的傳播。GGH 的實驗驗證是使用真實世界的開源資料集進行的，其中模擬了遺失率高達 98.5% 的記錄。與最先進的插補方法進行比較分析，證明 GGH 在模型效能方面有了顯著的提升。特別是在非常高的稀缺情況下，發現 GGH 是唯一可行的解決方案。此外，GGH 的雜訊偵測功能透過在資料集中引入模擬雜訊並在過濾掉有雜訊的資料後觀察增強的模型效能而得到展示。本研究將 GGH 提出為一個有前途的解決方案，用於改善各種應用中的資料品質和模型效能。

##### **VideoTree: Adaptive Tree-based Video Representation for LLM Reasoning on Long Videos**
2405.19209v1 by Ziyang Wang, Shoubin Yu, Elias Stengel-Eskin, Jaehong Yoon, Feng Cheng, Gedas Bertasius, Mohit Bansal

Video-language understanding tasks have focused on short video clips, often
struggling with long-form video understanding tasks. Recently, many long
video-language understanding approaches have leveraged the reasoning
capabilities of Large Language Models (LLMs) to perform long video QA,
transforming videos into densely sampled frame captions, and asking LLMs to
respond to text queries over captions. However, the frames used for captioning
are often redundant and contain irrelevant information, making dense sampling
inefficient, and ignoring the fact that video QA requires varying levels of
granularity, with some video segments being highly relevant to the question
(needing more fine-grained detail) while others being less relevant. Thus,
these LLM-based approaches are prone to missing information and operate on
large numbers of irrelevant captions, lowering both performance and efficiency.
To address these issues, we introduce VideoTree, a query-adaptive and
hierarchical framework for long-video understanding with LLMs. VideoTree
dynamically extracts query-related information from a video and builds a
tree-based representation for LLM reasoning. First, VideoTree adaptively
selects frames for captioning by iteratively clustering frames based on their
visual features and scoring clusters using their relevance to the query.
Second, it organizes visual clusters into a query-adaptive and hierarchical
tree structure; the tree encodes varying levels of granularity, with higher
resolution on relevant segments. Finally, VideoTree produces an answer by
traversing the tree's keyframes and passing their captions to an LLM answerer.
Our method improves both reasoning accuracy and efficiency compared to existing
methods: VideoTree achieves a 7.0%, 2.2%, and 2.7% accuracy gain over baselines
on the EgoSchema, NExT-QA, and IntentQA benchmarks, respectively, while
reducing inference time by 40%.

摘要：影片語言理解任務一直專注於短影片片段，通常難以理解長篇影片理解任務。最近，許多長影片語言理解方法利用大型語言模型 (LLM) 的推理能力執行長影片問答，將影片轉換成密集採樣的幀字幕，並要求 LLM 回應字幕上的文字查詢。然而，用於字幕的幀通常是冗餘的，且包含不相關的資訊，這使得密集採樣效率低下，且忽略了影片問答需要不同層級的詳細程度，其中某些影片片段與問題高度相關（需要更細緻的細節），而其他影片片段則相關性較低。因此，這些基於 LLM 的方法容易遺漏資訊，並運作於大量的無關字幕上，降低了效能和效率。為了解決這些問題，我們引入了 VideoTree，這是一個針對 LLM 的長影片理解查詢適應性且階層化的架構。VideoTree 動態地從影片中擷取與查詢相關的資訊，並建立一個基於樹狀結構的 LLM 推理表示。首先，VideoTree 透過根據視覺特徵反覆對幀進行分群，並使用與查詢相關性對分群進行評分，自適應地選擇用於字幕的幀。其次，它將視覺分群組織成一個與查詢相關且階層化的樹狀結構；這棵樹編碼了不同層級的詳細程度，相關片段具有較高的解析度。最後，VideoTree 透過遍歷樹狀結構的關鍵幀，並將其字幕傳遞給 LLM 回答器來產生答案。與現有方法相比，我們的模型改善了推理準確度和效率：VideoTree 在 EgoSchema、NExT-QA 和 IntentQA 基準上分別比基線高出 7.0%、2.2% 和 2.7% 的準確度，同時將推理時間減少了 40%。

##### **A Multi-Source Retrieval Question Answering Framework Based on RAG**
2405.19207v1 by Ridong Wu, Shuhong Chen, Xiangbiao Su, Yuankai Zhu, Yifei Liao, Jianming Wu

With the rapid development of large-scale language models,
Retrieval-Augmented Generation (RAG) has been widely adopted. However, existing
RAG paradigms are inevitably influenced by erroneous retrieval information,
thereby reducing the reliability and correctness of generated results.
Therefore, to improve the relevance of retrieval information, this study
proposes a method that replaces traditional retrievers with GPT-3.5, leveraging
its vast corpus knowledge to generate retrieval information. We also propose a
web retrieval based method to implement fine-grained knowledge retrieval,
Utilizing the powerful reasoning capability of GPT-3.5 to realize semantic
partitioning of problem.In order to mitigate the illusion of GPT retrieval and
reduce noise in Web retrieval,we proposes a multi-source retrieval framework,
named MSRAG, which combines GPT retrieval with web retrieval. Experiments on
multiple knowledge-intensive QA datasets demonstrate that the proposed
framework in this study performs better than existing RAG framework in
enhancing the overall efficiency and accuracy of QA systems.

摘要：隨著大型語言模型的快速發展，
檢索增強生成（RAG）已被廣泛採用。然而，現有的
RAG 典範不可避免地受到錯誤檢索資訊的影響，
從而降低生成結果的可靠性和正確性。
因此，為了提高檢索資訊的相關性，本研究
提出了一種以 GPT-3.5 取代傳統檢索器的的方法，利用
其龐大的語料知識來生成檢索資訊。我們還提出了一種
基於網路檢索的方法來實作細粒度的知識檢索，
利用 GPT-3.5 強大的推理能力來實現問題的語義
分割。為了減輕 GPT 檢索的錯覺並降低網路檢索中的雜訊，我們提出了
一個多來源檢索框架，稱為 MSRAG，它結合了 GPT 檢索和網路檢索。在
多個知識密集型問答資料集上的實驗表明，本研究中提出的
框架在提高問答系統的整體效率和準確性方面優於現有的 RAG 框架。

##### **Going beyond compositional generalization, DDPMs can produce zero-shot interpolation**
2405.19201v1 by Justin Deschenaux, Igor Krawczuk, Grigorios Chrysos, Volkan Cevher

Denoising Diffusion Probabilistic Models (DDPMs) exhibit remarkable
capabilities in image generation, with studies suggesting that they can
generalize by composing latent factors learned from the training data. In this
work, we go further and study DDPMs trained on strictly separate subsets of the
data distribution with large gaps on the support of the latent factors. We show
that such a model can effectively generate images in the unexplored,
intermediate regions of the distribution. For instance, when trained on clearly
smiling and non-smiling faces, we demonstrate a sampling procedure which can
generate slightly smiling faces without reference images (zero-shot
interpolation). We replicate these findings for other attributes as well as
other datasets.
$\href{https://github.com/jdeschena/ddpm-zero-shot-interpolation}{\text{Our
code is available on GitHub.}}$

摘要：去噪擴散機率模型 (DDPM) 在影像生成方面展現出卓越的能力，研究顯示它們可透過組合從訓練資料中學習到的潛在因子來進行概化。在這項工作中，我們進一步研究在資料分佈的嚴格獨立子集上訓練的 DDPM，這些子集在潛在因子的支持上存在很大的差距。我們展示了這樣的模型可以有效地生成分佈中未探索的、中間區域的影像。例如，在經過明顯微笑和不微笑的臉部訓練後，我們展示了一個取樣程序，它可以在沒有參考影像的情況下生成輕微微笑的臉部（零次插值）。我們也針對其他屬性和其他資料集複製了這些發現。
$\href{https://github.com/jdeschena/ddpm-zero-shot-interpolation}{\text{我們的程式碼可在 GitHub 上取得。}}$

##### **MetaToken: Detecting Hallucination in Image Descriptions by Meta Classification**
2405.19186v1 by Laura Fieback, Jakob Spiegelberg, Hanno Gottschalk

Large Vision Language Models (LVLMs) have shown remarkable capabilities in
multimodal tasks like visual question answering or image captioning. However,
inconsistencies between the visual information and the generated text, a
phenomenon referred to as hallucinations, remain an unsolved problem with
regard to the trustworthiness of LVLMs. To address this problem, recent works
proposed to incorporate computationally costly Large (Vision) Language Models
in order to detect hallucinations on a sentence- or subsentence-level. In this
work, we introduce MetaToken, a lightweight binary classifier to detect
hallucinations on the token-level at negligible cost. Based on a statistical
analysis, we reveal key factors of hallucinations in LVLMs which have been
overseen in previous works. MetaToken can be applied to any open-source LVLM
without any knowledge about ground truth data providing a reliable detection of
hallucinations. We evaluate our method on four state-of-the-art LVLMs
demonstrating the effectiveness of our approach.

摘要：大型視覺語言模型 (LVLMs) 在視覺問答或圖片標題等多模態任務中展現了卓越的能力。然而，視覺資訊和產生的文字之間的不一致，也就是所謂的幻覺現象，仍然是 LVLMs 可信度方面未解決的問題。為了解決這個問題，最近的研究建議結合計算成本高昂的大型 (視覺) 語言模型，以便在句子或子句層級偵測幻覺。在這項研究中，我們引入了 MetaToken，一個輕量級的二元分類器，可以在不增加成本的情況下，在代幣層級偵測幻覺。根據統計分析，我們揭露了 LVLMs 中幻覺的主要因素，這些因素在先前的研究中被忽略了。MetaToken 可以應用於任何開源 LVLM，而無需任何關於基本事實資料的知識，從而提供可靠的幻覺偵測。我們在四個最先進的 LVLMs 上評估了我們的模型，證明了我們方法的有效性。

##### **Promoting Two-sided Fairness in Dynamic Vehicle Routing Problem**
2405.19184v1 by Yufan Kang, Rongsheng Zhang, Wei Shao, Flora D. Salim, Jeffrey Chan

Dynamic Vehicle Routing Problem (DVRP), is an extension of the classic
Vehicle Routing Problem (VRP), which is a fundamental problem in logistics and
transportation. Typically, DVRPs involve two stakeholders: service providers
that deliver services to customers and customers who raise requests from
different locations. Many real-world applications can be formulated as DVRP
such as ridesharing and non-compliance capture. Apart from original objectives
like optimising total utility or efficiency, DVRP should also consider fairness
for all parties. Unfairness can induce service providers and customers to give
up on the systems, leading to negative financial and social impacts. However,
most existing DVRP-related applications focus on improving fairness from a
single side, and there have been few works considering two-sided fairness and
utility optimisation concurrently. To this end, we propose a novel framework, a
Two-sided Fairness-aware Genetic Algorithm (named 2FairGA), which expands the
genetic algorithm from the original objective solely focusing on utility to
multi-objectives that incorporate two-sided fairness. Subsequently, the impact
of injecting two fairness definitions into the utility-focused model and the
correlation between any pair of the three objectives are explored. Extensive
experiments demonstrate the superiority of our proposed framework compared to
the state-of-the-art.

摘要：動態車輛路線問題 (DVRP) 是經典車輛路線問題 (VRP) 的延伸，而 VRP 是物流和運輸中的基本問題。通常，DVRP 涉及兩個利害關係人：向客戶提供服務的服務提供者和提出不同地點要求的客戶。許多真實世界的應用程式可以表述為 DVRP，例如共乘和非順從性擷取。除了優化總效用或效率等原始目標之外，DVRP 還應考慮所有方的公平性。不公平會導致服務提供者和客戶放棄系統，進而造成負面的財務和社會影響。然而，大多數現有的 DVRP 相關應用程式都專注於從單方面改善公平性，而且很少有同時考慮雙邊公平性和效用最佳化的研究。為此，我們提出了一個新的框架，一個雙邊公平感知遺傳演算法（稱為 2FairGA），它將遺傳演算法從原本僅關注效用的目標擴展到包含雙邊公平性的多目標。隨後，探討將兩個公平性定義注入以效用為中心的模型的影響，以及三個目標之間任何一對的相關性。廣泛的實驗證明了我們提出的框架優於最先進的技術。

##### **Transformers as Neural Operators for Solutions of Differential Equations with Finite Regularity**
2405.19166v1 by Benjamin Shih, Ahmad Peyvan, Zhongqiang Zhang, George Em Karniadakis

Neural operator learning models have emerged as very effective surrogates in
data-driven methods for partial differential equations (PDEs) across different
applications from computational science and engineering. Such operator learning
models not only predict particular instances of a physical or biological system
in real-time but also forecast classes of solutions corresponding to a
distribution of initial and boundary conditions or forcing terms. % DeepONet is
the first neural operator model and has been tested extensively for a broad
class of solutions, including Riemann problems. Transformers have not been used
in that capacity, and specifically, they have not been tested for solutions of
PDEs with low regularity. %
  In this work, we first establish the theoretical groundwork that transformers
possess the universal approximation property as operator learning models.
  We then apply transformers to forecast solutions of diverse dynamical systems
with solutions of finite regularity for a plurality of initial conditions and
forcing terms. In particular, we consider three examples: the Izhikevich neuron
model, the tempered fractional-order Leaky Integrate-and-Fire (LIF) model, and
the one-dimensional Euler equation Riemann problem. For the latter problem, we
also compare with variants of DeepONet, and we find that transformers
outperform DeepONet in accuracy but they are computationally more expensive.

摘要：神經算子學習模型已成為跨越計算科學和工程不同應用中偏微分方程式 (PDE) 的數據驅動方法中非常有效的替代品。此類算子學習模型不僅可以實時預測物理或生物系統的特定實例，還能預測對應於初始和邊界條件或強迫項分佈的解類別。DeepONet 是第一個神經算子模型，並且已針對廣泛的解類別（包括黎曼問題）進行了廣泛測試。Transformer尚未用於該容量，特別是它們尚未針對低正則性的偏微分方程式解進行測試。在這項工作中，我們首先建立了Transformer作為算子學習模型具備通用逼近特性的理論基礎。然後，我們應用Transformer來預測具有有限正則性解的多個初始條件和強迫項的各種動態系統的解。特別是，我們考慮三個範例：Izhikevich 神經元模型、緩和分數階 Leaky Integrate-and-Fire (LIF) 模型和一維歐拉方程黎曼問題。對於後一個問題，我們還與 DeepONet 的變體進行了比較，我們發現Transformer在準確性方面優於 DeepONet，但它們在計算上更昂貴。

##### **Learning from Litigation: Graphs and LLMs for Retrieval and Reasoning in eDiscovery**
2405.19164v1 by Sounak Lahiri, Sumit Pai, Tim Weninger, Sanmitra Bhattacharya

Electronic Discovery (eDiscovery) involves identifying relevant documents
from a vast collection based on legal production requests. The integration of
artificial intelligence (AI) and natural language processing (NLP) has
transformed this process, helping document review and enhance efficiency and
cost-effectiveness. Although traditional approaches like BM25 or fine-tuned
pre-trained models are common in eDiscovery, they face performance,
computational, and interpretability challenges. In contrast, Large Language
Model (LLM)-based methods prioritize interpretability but sacrifice performance
and throughput. This paper introduces DISCOvery Graph (DISCOG), a hybrid
approach that combines the strengths of two worlds: a heterogeneous graph-based
method for accurate document relevance prediction and subsequent LLM-driven
approach for reasoning. Graph representational learning generates embeddings
and predicts links, ranking the corpus for a given request, and the LLMs
provide reasoning for document relevance. Our approach handles datasets with
balanced and imbalanced distributions, outperforming baselines in F1-score,
precision, and recall by an average of 12%, 3%, and 16%, respectively. In an
enterprise context, our approach drastically reduces document review costs by
99.9% compared to manual processes and by 95% compared to LLM-based
classification methods

摘要：電子發現 (eDiscovery) 涉及根據法律製作要求從大量集合中識別相關文件。人工智慧 (AI) 和自然語言處理 (NLP) 的整合已轉變此程序，協助文件檢閱並提升效率和成本效益。儘管傳統方法（例如 BM25 或微調預先訓練的模型）在電子發現中很常見，但它們面臨效能、運算和可解釋性方面的挑戰。相對地，大型語言模型 (LLM) 為基礎的方法優先考量可解釋性，但犧牲效能和處理量。本文介紹 DISCOvery Graph (DISCOG)，這是一種結合兩個世界的優勢的混合方法：一種用於準確文件相關性預測的異質圖形為基礎的方法和後續的 LLM 驅動方法用於推理。圖形表徵學習會產生嵌入和預測連結，針對特定要求對語料庫進行排名，而 LLM 則提供文件相關性的推理。我們的做法處理具有平衡和不平衡分佈的資料集，在 F1 分數、準確度和召回率方面優於基準，平均分別高出 12%、3% 和 16%。在企業環境中，與手動程序相比，我們的做法大幅減少文件審查成本 99.9%，與基於 LLM 的分類方法相比，減少 95%。

##### **Does learning the right latent variables necessarily improve in-context learning?**
2405.19162v1 by Sarthak Mittal, Eric Elmoznino, Leo Gagnon, Sangnie Bhardwaj, Dhanya Sridhar, Guillaume Lajoie

Large autoregressive models like Transformers can solve tasks through
in-context learning (ICL) without learning new weights, suggesting avenues for
efficiently solving new tasks. For many tasks, e.g., linear regression, the
data factorizes: examples are independent given a task latent that generates
the data, e.g., linear coefficients. While an optimal predictor leverages this
factorization by inferring task latents, it is unclear if Transformers
implicitly do so or if they instead exploit heuristics and statistical
shortcuts enabled by attention layers. Both scenarios have inspired active
ongoing work. In this paper, we systematically investigate the effect of
explicitly inferring task latents. We minimally modify the Transformer
architecture with a bottleneck designed to prevent shortcuts in favor of more
structured solutions, and then compare performance against standard
Transformers across various ICL tasks. Contrary to intuition and some recent
works, we find little discernible difference between the two; biasing towards
task-relevant latent variables does not lead to better out-of-distribution
performance, in general. Curiously, we find that while the bottleneck
effectively learns to extract latent task variables from context, downstream
processing struggles to utilize them for robust prediction. Our study
highlights the intrinsic limitations of Transformers in achieving structured
ICL solutions that generalize, and shows that while inferring the right latents
aids interpretability, it is not sufficient to alleviate this problem.

摘要：大型自迴歸模型，例如 Transformer，可以透過情境學習 (ICL) 解決任務，而無需學習新的權重，這表示有途徑可有效率地解決新任務。對於許多任務，例如線性迴歸，資料會因式分解：範例會在產生資料的任務潛在變數（例如線性係數）下獨立。雖然最佳預測器會透過推論任務潛在變數來利用此因式分解，但目前尚不清楚 Transformer 是否會隱含地這樣做，或者它們是否會利用注意力層所啟用的啟發法和統計捷徑。這兩種情況都激發了積極的持續研究。在本文中，我們系統性地探討了明確推論任務潛在變數的效果。我們使用瓶頸對 Transformer 架構進行最小的修改，目的是防止捷徑，並支持更結構化的解決方案，然後比較標準 Transformer 在各種 ICL 任務中的效能。與直覺和一些近期研究相反，我們發現兩者之間幾乎沒有明顯差異；一般而言，偏向與任務相關的潛在變數並不會導致更好的分佈外效能。奇怪的是，我們發現雖然瓶頸有效地學會從情境中提取潛在任務變數，但下游處理卻難以利用它們進行穩健的預測。我們的研究強調了 Transformer 在達成結構化 ICL 解決方案（可進行概括）方面的內在限制，並顯示雖然推論正確的潛在變數有助於可解釋性，但不足以緩解此問題。

##### **DGRC: An Effective Fine-tuning Framework for Distractor Generation in Chinese Multi-choice Reading Comprehension**
2405.19139v1 by Runfeng Lin, Dacheng Xu, Huijiang Wang, Zebiao Chen, Yating Wang, Shouqiang Liu

When evaluating a learner's knowledge proficiency, the multiple-choice
question is an efficient and widely used format in standardized tests.
Nevertheless, generating these questions, particularly plausible distractors
(incorrect options), poses a considerable challenge. Generally, the distractor
generation can be classified into cloze-style distractor generation (CDG) and
natural questions distractor generation (NQDG). In contrast to the CDG,
utilizing pre-trained language models (PLMs) for NQDG presents three primary
challenges: (1) PLMs are typically trained to generate ``correct'' content,
like answers, while rarely trained to generate ``plausible" content, like
distractors; (2) PLMs often struggle to produce content that aligns well with
specific knowledge and the style of exams; (3) NQDG necessitates the model to
produce longer, context-sensitive, and question-relevant distractors. In this
study, we introduce a fine-tuning framework named DGRC for NQDG in Chinese
multi-choice reading comprehension from authentic examinations. DGRC comprises
three major components: hard chain-of-thought, multi-task learning, and
generation mask patterns. The experiment results demonstrate that DGRC
significantly enhances generation performance, achieving a more than 2.5-fold
improvement in BLEU scores.

摘要：在評估學習者的知識能力時，多選題是一種標準化考試中有效且廣泛使用的格式。儘管如此，產生這些問題，尤其是合理的干擾項（錯誤選項），是一個相當大的挑戰。一般來說，干擾項產生可以分為填空式干擾項產生（CDG）和自然問題干擾項產生（NQDG）。與 CDG 相比，利用預先訓練的語言模型（PLM）進行 NQDG 會產生三個主要挑戰：（1）PLM 通常被訓練來產生「正確」的內容，例如答案，而很少被訓練來產生「合理的」內容，例如干擾項；（2）PLM 經常難以產生與特定知識和考試風格相符的內容；（3）NQDG 需要模型產生更長、與上下文相關且與問題相關的干擾項。在這項研究中，我們引入了一個名為 DGRC 的微調框架，用於從真實考試中進行中文多選題閱讀理解的 NQDG。DGRC 包含三個主要組成部分：硬鏈式思考、多任務學習和生成遮罩模式。實驗結果表明，DGRC 大大增強了生成性能，BLEU 分數提高了 2.5 倍以上。

##### **Analyzing Chat Protocols of Novice Programmers Solving Introductory Programming Tasks with ChatGPT**
2405.19132v1 by Andreas Scholl, Daniel Schiffner, Natalie Kiesler

Large Language Models (LLMs) have taken the world by storm, and students are
assumed to use related tools at a great scale. In this research paper we aim to
gain an understanding of how introductory programming students chat with LLMs
and related tools, e.g., ChatGPT-3.5. To address this goal, computing students
at a large German university were motivated to solve programming exercises with
the assistance of ChatGPT as part of their weekly introductory course
exercises. Then students (n=213) submitted their chat protocols (with 2335
prompts in sum) as data basis for this analysis. The data was analyzed w.r.t.
the prompts, frequencies, the chats' progress, contents, and other use pattern,
which revealed a great variety of interactions, both potentially supportive and
concerning. Learning about students' interactions with ChatGPT will help inform
and align teaching practices and instructions for future introductory
programming courses in higher education.

摘要：大型語言模型 (LLM) 席捲全球，學生們被假設會大規模使用相關工具。在這篇研究論文中，我們旨在了解入門程式設計學生如何與 LLM 和相關工具（例如 ChatGPT-3.5）聊天。為了達成此目標，德國一所大型大學的電腦系學生被鼓勵在每週的入門課程練習中，在 ChatGPT 的協助下解決程式設計練習。接著，學生們（n=213）提交了他們的聊天記錄（總共 2335 則提示），作為此分析的資料基礎。資料針對提示、頻率、聊天的進度、內容和其他使用模式進行分析，揭露了各種互動，既有潛在的支持，也有令人擔憂的。了解學生與 ChatGPT 的互動，將有助於為未來高等教育的入門程式設計課程提供資訊，並調整教學實務和教學。

##### **Spatio-Spectral Graph Neural Networks**
2405.19121v1 by Simon Geisler, Arthur Kosmala, Daniel Herbst, Stephan Günnemann

Spatial Message Passing Graph Neural Networks (MPGNNs) are widely used for
learning on graph-structured data. However, key limitations of l-step MPGNNs
are that their "receptive field" is typically limited to the l-hop neighborhood
of a node and that information exchange between distant nodes is limited by
over-squashing. Motivated by these limitations, we propose Spatio-Spectral
Graph Neural Networks (S$^2$GNNs) -- a new modeling paradigm for Graph Neural
Networks (GNNs) that synergistically combines spatially and spectrally
parametrized graph filters. Parameterizing filters partially in the frequency
domain enables global yet efficient information propagation. We show that
S$^2$GNNs vanquish over-squashing and yield strictly tighter
approximation-theoretic error bounds than MPGNNs. Further, rethinking graph
convolutions at a fundamental level unlocks new design spaces. For example,
S$^2$GNNs allow for free positional encodings that make them strictly more
expressive than the 1-Weisfeiler-Lehman (WL) test. Moreover, to obtain
general-purpose S$^2$GNNs, we propose spectrally parametrized filters for
directed graphs. S$^2$GNNs outperform spatial MPGNNs, graph transformers, and
graph rewirings, e.g., on the peptide long-range benchmark tasks, and are
competitive with state-of-the-art sequence modeling. On a 40 GB GPU, S$^2$GNNs
scale to millions of nodes.

摘要：空間訊息傳遞圖神經網路 (MPGNN) 廣泛用於學習圖形結構資料。然而，l 步 MPGNN 的主要限制在於其「感受野」通常僅限於節點的 l 跳鄰域，而遠距離節點之間的資訊交換受到過度壓縮的限制。基於這些限制，我們提出時空譜圖神經網路 (S$^2$GNN) -- 一種圖神經網路 (GNN) 的新建模範式，它協同結合空間和頻譜參數化的圖形濾波器。在頻率域中部分參數化濾波器可實現全局且有效的資訊傳播。我們證明 S$^2$GNN 消除過度壓縮，並產生比 MPGNN 更嚴格的近似理論誤差界限。此外，在基本層面上重新思考圖形卷積，開啟了新的設計空間。例如，S$^2$GNN 允許自由位置編碼，使其比 1-Weisfeiler-Lehman (WL) 測試更具表達力。此外，為了獲得通用 S$^2$GNN，我們提出針對有向圖的頻譜參數化濾波器。S$^2$GNN 優於空間 MPGNN、圖形Transformer和圖形重新連線，例如在胜肽長程基準任務上，並且與最先進的序列建模具有競爭力。在 40 GB GPU 上，S$^2$GNN 可擴充至數百萬個節點。

##### **PathReasoner: Modeling Reasoning Path with Equivalent Extension for Logical Question Answering**
2405.19109v1 by Fangzhi Xu, Qika Lin, Tianzhe Zhao, Jiawei Han, Jun Liu

Logical reasoning task has attracted great interest since it was proposed.
Faced with such a task, current competitive models, even large language models
(e.g., ChatGPT and PaLM 2), still perform badly. Previous promising LMs
struggle in logical consistency modeling and logical structure perception. To
this end, we model the logical reasoning task by transforming each logical
sample into reasoning paths and propose an architecture \textbf{PathReasoner}.
It addresses the task from the views of both data and model. To expand the
diversity of the logical samples, we propose an atom extension strategy
supported by equivalent logical formulas, to form new reasoning paths. From the
model perspective, we design a stack of transformer-style blocks. In
particular, we propose a path-attention module to joint model in-atom and
cross-atom relations with the high-order diffusion strategy. Experiments show
that PathReasoner achieves competitive performances on two logical reasoning
benchmarks and great generalization abilities.

摘要：邏輯推理任務自提出以來便引起了極大的興趣。
面對這樣的任務，當前的競爭模型，甚至是大型語言模型
（例如 ChatGPT 和 PaLM 2），表現仍然很差。先前有前景的 LM
在邏輯一致性建模和邏輯結構感知方面遇到困難。為此，我們通過將每個邏輯
範例轉換為推理路徑來建模邏輯推理任務，並提出一個架構 \textbf{PathReasoner}。
它從數據和模型的角度來處理任務。為了擴展邏輯範例的多樣性，我們提出了一個
由等效邏輯公式支持的原子擴展策略，以形成新的推理路徑。從
模型的角度來看，我們設計了一堆Transformer風格的區塊。特別是，我們提出了一個路徑注意力模組，以高階擴散策略聯合建模原子內和原子間關係。實驗表明
PathReasoner 在兩個邏輯推理基準測試中實現了競爭效能，並具有極佳的泛化能力。

##### **Offline Regularised Reinforcement Learning for Large Language Models Alignment**
2405.19107v1 by Pierre Harvey Richemond, Yunhao Tang, Daniel Guo, Daniele Calandriello, Mohammad Gheshlaghi Azar, Rafael Rafailov, Bernardo Avila Pires, Eugene Tarassov, Lucas Spangher, Will Ellsworth, Aliaksei Severyn, Jonathan Mallinson, Lior Shani, Gil Shamir, Rishabh Joshi, Tianqi Liu, Remi Munos, Bilal Piot

The dominant framework for alignment of large language models (LLM), whether
through reinforcement learning from human feedback or direct preference
optimisation, is to learn from preference data. This involves building datasets
where each element is a quadruplet composed of a prompt, two independent
responses (completions of the prompt) and a human preference between the two
independent responses, yielding a preferred and a dis-preferred response. Such
data is typically scarce and expensive to collect. On the other hand,
\emph{single-trajectory} datasets where each element is a triplet composed of a
prompt, a response and a human feedback is naturally more abundant. The
canonical element of such datasets is for instance an LLM's response to a
user's prompt followed by a user's feedback such as a thumbs-up/down.
Consequently, in this work, we propose DRO, or \emph{Direct Reward
Optimisation}, as a framework and associated algorithms that do not require
pairwise preferences. DRO uses a simple mean-squared objective that can be
implemented in various ways. We validate our findings empirically, using T5
encoder-decoder language models, and show DRO's performance over selected
baselines such as Kahneman-Tversky Optimization (KTO). Thus, we confirm that
DRO is a simple and empirically compelling method for single-trajectory policy
optimisation.

摘要：大型語言模型 (LLM) 對齊的主流架構，無論是透過人類回饋的強化學習或直接偏好最佳化，都是從偏好資料中學習。這涉及建立資料集，其中每個元素都是一個四元組，由提示、兩個獨立的回應（提示的完成）和人類對兩個獨立回應之間的偏好組成，產生一個偏好的回應和一個不偏好的回應。此類資料通常稀缺且收集成本高昂。另一方面，每個元素都是由提示、回應和人類回饋組成的一個三元組，單軌資料集自然更豐富。此類資料集的典型元素例如 LLM 對使用者提示的回應，後面接著使用者的回饋，例如按讚/按倒讚。因此，在這項工作中，我們提出 DRO，或直接回饋最佳化，作為一個架構和相關演算法，不需要成對偏好。DRO 使用一個簡單的均方目標，可以用各種方式實作。我們使用 T5 編碼器-解碼器語言模型，以經驗方式驗證我們的發現，並展示 DRO 在選擇的基準（例如 Kahneman-Tversky 最佳化 (KTO)）上的效能。因此，我們確認 DRO 是一種簡單且經驗上令人信服的單軌政策最佳化方法。

##### **Efficient Black-box Adversarial Attacks via Bayesian Optimization Guided by a Function Prior**
2405.19098v1 by Shuyu Cheng, Yibo Miao, Yinpeng Dong, Xiao Yang, Xiao-Shan Gao, Jun Zhu

This paper studies the challenging black-box adversarial attack that aims to
generate adversarial examples against a black-box model by only using output
feedback of the model to input queries. Some previous methods improve the query
efficiency by incorporating the gradient of a surrogate white-box model into
query-based attacks due to the adversarial transferability. However, the
localized gradient is not informative enough, making these methods still
query-intensive. In this paper, we propose a Prior-guided Bayesian Optimization
(P-BO) algorithm that leverages the surrogate model as a global function prior
in black-box adversarial attacks. As the surrogate model contains rich prior
information of the black-box one, P-BO models the attack objective with a
Gaussian process whose mean function is initialized as the surrogate model's
loss. Our theoretical analysis on the regret bound indicates that the
performance of P-BO may be affected by a bad prior. Therefore, we further
propose an adaptive integration strategy to automatically adjust a coefficient
on the function prior by minimizing the regret bound. Extensive experiments on
image classifiers and large vision-language models demonstrate the superiority
of the proposed algorithm in reducing queries and improving attack success
rates compared with the state-of-the-art black-box attacks. Code is available
at https://github.com/yibo-miao/PBO-Attack.

摘要：本論文探討具挑戰性的黑箱對抗攻擊，目標是透過僅使用模型的輸出回饋至輸入查詢，來產生針對黑箱模型的對抗範例。一些先前的研究方法透過將替代白箱模型的梯度納入基於查詢的攻擊中，藉由對抗可傳遞性來提升查詢效率。然而，局部梯度並未提供足夠資訊，導致這些方法仍然需要大量的查詢。在本文中，我們提出一個先驗引導的貝氏最佳化（P-BO）演算法，將替代模型視為黑箱對抗攻擊中的全局函數先驗。由於替代模型包含黑箱模型豐富的先驗資訊，因此 P-BO 以高斯程序對攻擊目標進行建模，其平均函數初始化為替代模型的損失。我們對後悔邊界的理論分析指出，P-BO 的效能可能會受到不良先驗的影響。因此，我們進一步提出一個自適應整合策略，透過最小化後悔邊界來自動調整函數先驗的係數。在影像分類器和大型視覺語言模型上的廣泛實驗證明了所提出的演算法在減少查詢次數和提升攻擊成功率方面的優越性，優於最先進的黑箱攻擊。程式碼可於 https://github.com/yibo-miao/PBO-Attack 取得。

##### **Faithful Chart Summarization with ChaTS-Pi**
2405.19094v1 by Syrine Krichene, Francesco Piccinno, Fangyu Liu, Julian Martin Eisenschlos

Chart-to-summary generation can help explore data, communicate insights, and
help the visually impaired people. Multi-modal generative models have been used
to produce fluent summaries, but they can suffer from factual and perceptual
errors. In this work we present CHATS-CRITIC, a reference-free chart
summarization metric for scoring faithfulness. CHATS-CRITIC is composed of an
image-to-text model to recover the table from a chart, and a tabular entailment
model applied to score the summary sentence by sentence. We find that
CHATS-CRITIC evaluates the summary quality according to human ratings better
than reference-based metrics, either learned or n-gram based, and can be
further used to fix candidate summaries by removing not supported sentences. We
then introduce CHATS-PI, a chart-to-summary pipeline that leverages
CHATS-CRITIC during inference to fix and rank sampled candidates from any
chart-summarization model. We evaluate CHATS-PI and CHATS-CRITIC using human
raters, establishing state-of-the-art results on two popular chart-to-summary
datasets.

摘要：圖表到摘要的生成有助於探索數據、傳達見解，並幫助視障人士。多模態生成模型已被用於產生流利的摘要，但它們可能會出現事實和感知錯誤。在這項工作中，我們提出了 CHATS-CRITIC，這是一個無參考圖表摘要指標，用於評分保真度。CHATS-CRITIC 由一個將表格從圖表中恢復的圖像到文本模型組成，以及一個用於逐句評分摘要句子的表格蘊涵模型。我們發現 CHATS-CRITIC 根據人類評分評估摘要品質優於基於參考或 n-gram 的指標，並且可以進一步用於通過移除不受支持的句子來修正候選摘要。然後我們介紹 CHATS-PI，這是一個圖表到摘要管道，它在推論期間利用 CHATS-CRITIC 來修正和排名從任何圖表摘要模型採樣的候選項。我們使用人類評分員評估 CHATS-PI 和 CHATS-CRITIC，在兩個流行的圖表到摘要資料集上建立了最先進的結果。

##### **Multi-stage Retrieve and Re-rank Model for Automatic Medical Coding Recommendation**
2405.19093v1 by Xindi Wang, Robert E. Mercer, Frank Rudzicz

The International Classification of Diseases (ICD) serves as a definitive
medical classification system encompassing a wide range of diseases and
conditions. The primary objective of ICD indexing is to allocate a subset of
ICD codes to a medical record, which facilitates standardized documentation and
management of various health conditions. Most existing approaches have suffered
from selecting the proper label subsets from an extremely large ICD collection
with a heavy long-tailed label distribution. In this paper, we leverage a
multi-stage ``retrieve and re-rank'' framework as a novel solution to ICD
indexing, via a hybrid discrete retrieval method, and re-rank retrieved
candidates with contrastive learning that allows the model to make more
accurate predictions from a simplified label space. The retrieval model is a
hybrid of auxiliary knowledge of the electronic health records (EHR) and a
discrete retrieval method (BM25), which efficiently collects high-quality
candidates. In the last stage, we propose a label co-occurrence guided
contrastive re-ranking model, which re-ranks the candidate labels by pulling
together the clinical notes with positive ICD codes. Experimental results show
the proposed method achieves state-of-the-art performance on a number of
measures on the MIMIC-III benchmark.

摘要：國際疾病分類（ICD）作為一個明確的醫療分類系統，涵蓋了廣泛的疾病和病症。ICD 編碼的主要目的是將 ICD 編碼的子集分配給醫療記錄，這有助於標準化各種健康狀況的記錄和管理。現有的方法大多會從極大量的 ICD 集合中，以極度長尾標籤分佈來選擇適當的標籤子集，因此而有所不足。在本文中，我們利用多階段「檢索和重新排序」架構作為 ICD 編碼的新解決方案，透過混合離散檢索方法，並使用對比學習重新排序檢索到的候選項目，讓模型能夠從簡化的標籤空間中做出更準確的預測。檢索模型是電子健康記錄 (EHR) 的輔助知識和離散檢索方法 (BM25) 的混合，可有效收集高品質的候選項目。在最後階段，我們提出一個標籤共現引導的對比重新排序模型，透過將帶有正向 ICD 編碼的臨床註記彙整在一起，重新對候選標籤進行排序。實驗結果顯示，所提出的方法在 MIMIC-III 基準上針對多項指標達到了最先進的效能。

##### **Cracking the Code of Juxtaposition: Can AI Models Understand the Humorous Contradictions**
2405.19088v1 by Zhe Hu, Tuo Liang, Jing Li, Yiren Lu, Yunlai Zhou, Yiran Qiao, Jing Ma, Yu Yin

Recent advancements in large multimodal language models have demonstrated
remarkable proficiency across a wide range of tasks. Yet, these models still
struggle with understanding the nuances of human humor through juxtaposition,
particularly when it involves nonlinear narratives that underpin many jokes and
humor cues. This paper investigates this challenge by focusing on comics with
contradictory narratives, where each comic consists of two panels that create a
humorous contradiction. We introduce the YesBut benchmark, which comprises
tasks of varying difficulty aimed at assessing AI's capabilities in recognizing
and interpreting these comics, ranging from literal content comprehension to
deep narrative reasoning. Through extensive experimentation and analysis of
recent commercial or open-sourced large (vision) language models, we assess
their capability to comprehend the complex interplay of the narrative humor
inherent in these comics. Our results show that even state-of-the-art models
still lag behind human performance on this task. Our findings offer insights
into the current limitations and potential improvements for AI in understanding
human creative expressions.

摘要：最近大型多模态语言模型的进步已在广泛的任务中展示出卓越的能力。然而，这些模型仍然难以通过并列理解人类幽默的细微差别，尤其是在涉及支撑许多笑话和幽默暗示的非线性叙述时。本文通过关注具有矛盾叙述的漫画来研究这一挑战，其中每个漫画都包含两个面板，从而产生幽默的矛盾。我们引入了 YesBut 基准，其中包含难度各异的任务，旨在评估人工智能在识别和解释这些漫画的能力，从字面内容理解到深度叙述推理。通过对最近的商业或开源大型（视觉）语言模型进行广泛的实验和分析，我们评估了它们理解这些漫画中固有的叙述幽默的复杂相互作用的能力。我们的结果表明，即使是最先进的模型在这个任务上仍然落后于人类的表现。我们的发现为人工智能理解人类创造性表达的当前局限性和潜在改进提供了见解。

##### **MEMoE: Enhancing Model Editing with Mixture of Experts Adaptors**
2405.19086v1 by Renzhi Wang, Piji Li

Model editing aims to efficiently alter the behavior of Large Language Models
(LLMs) within a desired scope, while ensuring no adverse impact on other
inputs. Recent years have witnessed various model editing methods been
proposed. However, these methods either exhibit poor overall performance or
struggle to strike a balance between generalization and locality. We propose
MOMoE, a model editing adapter utilizing a Mixture of Experts (MoE)
architecture with a knowledge anchor routing strategy. MOMoE updates knowledge
using a bypass MoE structure, keeping the original parameters unchanged to
preserve the general ability of LLMs. And, the knowledge anchor routing ensures
that inputs requiring similar knowledge are routed to the same expert, thereby
enhancing the generalization of the updated knowledge. Experimental results
show the superiority of our approach over both batch editing and sequential
batch editing tasks, exhibiting exceptional overall performance alongside
outstanding balance between generalization and locality. Our code will be
available.

摘要：模型編輯旨在有效地改變大型語言模型 (LLM) 在所需範圍內的行為，同時確保不會對其他輸入產生不利影響。近年來見證了各種模型編輯方法的提出。然而，這些方法要么表現出整體性能不佳，要么難以在泛化和局部性之間取得平衡。我們提出 MOMoE，一種利用專家混合 (MoE) 架構和知識錨定路由策略的模型編輯適配器。MOMoE 使用旁路 MoE 結構更新知識，保持原始參數不變以保留 LLM 的一般能力。而且，知識錨定路由確保需要類似知識的輸入被路由到同一個專家，從而增強更新知識的泛化性。實驗結果表明，我們的做法優於批次編輯和順序批次編輯任務，表現出卓越的整體性能以及泛化和局部性之間的出色平衡。我們的代碼將會提供。

##### **Patch-enhanced Mask Encoder Prompt Image Generation**
2405.19085v1 by Shusong Xu, Peiye Liu

Artificial Intelligence Generated Content(AIGC), known for its superior
visual results, represents a promising mitigation method for high-cost
advertising applications. Numerous approaches have been developed to manipulate
generated content under different conditions. However, a crucial limitation
lies in the accurate description of products in advertising applications.
Applying previous methods directly may lead to considerable distortion and
deformation of advertised products, primarily due to oversimplified content
control conditions. Hence, in this work, we propose a patch-enhanced mask
encoder approach to ensure accurate product descriptions while preserving
diverse backgrounds. Our approach consists of three components Patch Flexible
Visibility, Mask Encoder Prompt Adapter and an image Foundation Model. Patch
Flexible Visibility is used for generating a more reasonable background image.
Mask Encoder Prompt Adapter enables region-controlled fusion. We also conduct
an analysis of the structure and operational mechanisms of the Generation
Module. Experimental results show our method can achieve the highest visual
results and FID scores compared with other methods.

摘要：人工智能生成內容 (AIGC) 以其卓越的視覺效果而聞名，代表著一種有望減輕高成本廣告應用問題的緩解方法。已經開發出許多方法來在不同條件下操縱生成內容。然而，一個關鍵的限制在於廣告應用中對產品的準確描述。直接應用以前的方法可能會導致所宣傳產品的嚴重失真和變形，這主要是由於內容控制條件過於簡化。因此，在這項工作中，我們提出了一種補丁增強遮罩編碼器方法，以確保準確的產品描述，同時保留不同的背景。我們的做法包括三個組成部分：補丁靈活可見性、遮罩編碼器提示適配器和圖像基礎模型。補丁靈活可見性用於生成更合理的背景圖像。遮罩編碼器提示適配器啟用區域控制融合。我們還對生成模組的結構和操作機制進行了分析。實驗結果表明，與其他方法相比，我們的模型可以實現最高的視覺效果和 FID 分數。

##### **Cephalo: Multi-Modal Vision-Language Models for Bio-Inspired Materials Analysis and Design**
2405.19076v1 by Markus J. Buehler

We present Cephalo, a series of multimodal vision large language models
(V-LLMs) designed for materials science applications, integrating visual and
linguistic data for enhanced understanding and interaction within human-AI and
multi-agent AI frameworks. A key innovation of Cephalo is its advanced dataset
generation method, which employs a sophisticated algorithm to accurately detect
and separate images and their corresponding textual descriptions from PDF
documents, such as scientific papers. The method includes a careful refinement
of image-text pairs through integrated vision and language processing, ensuring
high-quality, contextually relevant, and well reasoned training data. Cephalo
is trained on integrated image and text data extracted from thousands of
scientific papers and science-focused Wikipedia pages demonstrates can
interpret complex visual scenes, generate precise language descriptions, and
answer queries about images effectively. The combination of a vision encoder
with an autoregressive transformer supports complex natural language
understanding in an integrated model, which can be coupled with other
generative methods to create an image-to-text-to-image or image-to-text-to-3D
pipeline. To explore the development of larger models from smaller ones, we
merge sets of layers that originate from different pre-trained source models.
This hybrid approach allows us to leverage the domain-specific expertise and
general conversational capabilities to harness the strengths of multiple
models. We examine the models in diverse use cases that incorporate biological
materials, fracture and engineering analysis, protein biophysics, and
bio-inspired design based on insect behavior. Generative applications include
bio-inspired designs, including pollen-inspired architected materials, as well
as the synthesis of bio-inspired material microstructures from a photograph of
a solar eclipse.

摘要：<paragraph>我們提出 Cephalo，一系列多模態視覺大型語言模型 (V-LLM)，專為材料科學應用而設計，整合視覺和語言數據，以增強人類 AI 和多代理 AI 框架內的理解和互動。Cephalo 的一項關鍵創新是其先進的數據集生成方法，它採用一種精密的演算法來準確檢測和分離 PDF 文件中的影像及其對應的文字說明，例如科學論文。該方法包括透過整合視覺和語言處理來仔細改善影像文字對，確保訓練數據的高品質、與語境相關且經過充分論證。Cephalo 訓練於從數千篇科學論文和以科學為重點的維基百科頁面中萃取的整合影像和文字數據，證明可以詮釋複雜的視覺場景、產生精確的語言說明，並有效回答有關影像的查詢。將視覺編碼器與自迴歸轉換器相結合，在整合模型中支援複雜的自然語言理解，可以與其他生成方法結合，以建立影像轉文字轉影像或影像轉文字轉 3D 管線。為了探索從較小的模型開發較大的模型，我們合併源自不同預先訓練的來源模型的層級組。這種混合方法讓我們能夠利用領域特定的專業知識和一般的對話能力，來利用多個模型的優勢。我們在不同的使用案例中檢驗這些模型，這些案例包含生物材料、斷裂和工程分析、蛋白質生物物理學，以及基於昆蟲行為的生物啟發設計。生成應用程式包括生物啟發設計，例如受花粉啟發的建築材料，以及從日食照片合成生物啟發材料微結構。</paragraph>

##### **Resurrecting Old Classes with New Data for Exemplar-Free Continual Learning**
2405.19074v1 by Dipam Goswami, Albin Soutif--Cormerais, Yuyang Liu, Sandesh Kamath, Bartłomiej Twardowski, Joost van de Weijer

Continual learning methods are known to suffer from catastrophic forgetting,
a phenomenon that is particularly hard to counter for methods that do not store
exemplars of previous tasks. Therefore, to reduce potential drift in the
feature extractor, existing exemplar-free methods are typically evaluated in
settings where the first task is significantly larger than subsequent tasks.
Their performance drops drastically in more challenging settings starting with
a smaller first task. To address this problem of feature drift estimation for
exemplar-free methods, we propose to adversarially perturb the current samples
such that their embeddings are close to the old class prototypes in the old
model embedding space. We then estimate the drift in the embedding space from
the old to the new model using the perturbed images and compensate the
prototypes accordingly. We exploit the fact that adversarial samples are
transferable from the old to the new feature space in a continual learning
setting. The generation of these images is simple and computationally cheap. We
demonstrate in our experiments that the proposed approach better tracks the
movement of prototypes in embedding space and outperforms existing methods on
several standard continual learning benchmarks as well as on fine-grained
datasets. Code is available at https://github.com/dipamgoswami/ADC.

摘要：持續學習方法已知會遭受災難性遺忘，
這是一個特別難以對抗的現象，對於不儲存先前任務範例的方法而言更是如此。因此，為了減少特徵萃取器中的潛在偏移，現有的無範例方法通常在第一個任務顯著大於後續任務的設定中進行評估。他們的表現會在從較小的第一個任務開始的更具挑戰性的設定中急劇下降。為了解決無範例方法的特徵偏移估計問題，我們建議對當前樣本進行對抗性擾動，使其嵌入與舊模型嵌入空間中的舊類別原型相近。然後，我們使用擾動的影像從舊模型估計到新模型的嵌入空間中的偏移，並相應地補償原型。我們利用對抗樣本在持續學習設定中可以從舊特徵空間傳輸到新特徵空間的事實。這些影像的生成簡單且計算成本低廉。我們在實驗中證明，所提出的方法可以更好地追蹤嵌入空間中原型的移動，並在多個標準持續學習基準以及細粒度資料集上優於現有方法。程式碼可在 https://github.com/dipamgoswami/ADC 取得。

##### **SIG: Efficient Self-Interpretable Graph Neural Network for Continuous-time Dynamic Graphs**
2405.19062v1 by Lanting Fang, Yulian Yang, Kai Wang, Shanshan Feng, Kaiyu Feng, Jie Gui, Shuliang Wang, Yew-Soon Ong

While dynamic graph neural networks have shown promise in various
applications, explaining their predictions on continuous-time dynamic graphs
(CTDGs) is difficult. This paper investigates a new research task:
self-interpretable GNNs for CTDGs. We aim to predict future links within the
dynamic graph while simultaneously providing causal explanations for these
predictions. There are two key challenges: (1) capturing the underlying
structural and temporal information that remains consistent across both
independent and identically distributed (IID) and out-of-distribution (OOD)
data, and (2) efficiently generating high-quality link prediction results and
explanations. To tackle these challenges, we propose a novel causal inference
model, namely the Independent and Confounded Causal Model (ICCM). ICCM is then
integrated into a deep learning architecture that considers both effectiveness
and efficiency. Extensive experiments demonstrate that our proposed model
significantly outperforms existing methods across link prediction accuracy,
explanation quality, and robustness to shortcut features. Our code and datasets
are anonymously released at https://github.com/2024SIG/SIG.

摘要：儘管動態圖神經網路在各種應用中展現出前景，但要說明它們在連續時間動態圖 (CTDG) 上的預測卻很困難。本文探討了一項新的研究任務：CTDG 的自我解釋 GNN。我們的目標是在動態圖中預測未來的連結，同時為這些預測提供因果解釋。有兩個關鍵挑戰：(1) 擷取獨立且同分布 (IID) 和分布外 (OOD) 資料中保持一致的底層結構和時間資訊，以及 (2) 有效率地產生高品質的連結預測結果和解釋。為了應對這些挑戰，我們提出了一種新的因果推論模型，即獨立且混淆的因果模型 (ICCM)。然後將 ICCM 整合到一個深度學習架構中，同時考量到有效性和效率。廣泛的實驗證明，我們提出的模型在連結預測準確度、解釋品質和對捷徑特徵的穩健性方面都顯著優於現有方法。我們的程式碼和資料集已匿名發布在 https://github.com/2024SIG/SIG。

##### **Multiscale Spatio-Temporal Enhanced Short-term Load Forecasting of Electric Vehicle Charging Stations**
2405.19053v1 by Zongbao Zhang, Jiao Hao, Wenmeng Zhao, Yan Liu, Yaohui Huang, Xinhang Luo

The rapid expansion of electric vehicles (EVs) has rendered the load
forecasting of electric vehicle charging stations (EVCS) increasingly critical.
The primary challenge in achieving precise load forecasting for EVCS lies in
accounting for the nonlinear of charging behaviors, the spatial interactions
among different stations, and the intricate temporal variations in usage
patterns. To address these challenges, we propose a Multiscale Spatio-Temporal
Enhanced Model (MSTEM) for effective load forecasting at EVCS. MSTEM
incorporates a multiscale graph neural network to discern hierarchical
nonlinear temporal dependencies across various time scales. Besides, it also
integrates a recurrent learning component and a residual fusion mechanism,
enhancing its capability to accurately capture spatial and temporal variations
in charging patterns. The effectiveness of the proposed MSTEM has been
validated through comparative analysis with six baseline models using three
evaluation metrics. The case studies utilize real-world datasets for both fast
and slow charging loads at EVCS in Perth, UK. The experimental results
demonstrate the superiority of MSTEM in short-term continuous load forecasting
for EVCS.

摘要：電動車（EV）的快速擴張，使得電動車充電站（EVCS）的負載預測變得越來越重要。
對於 EVCS 進行精準負載預測的主要挑戰在於考量充電行為的非線性、不同站點之間的空間交互作用，以及使用模式中複雜的時間變化。
為了應對這些挑戰，我們提出了一個多尺度時空增強模型（MSTEM），用於在 EVCS 進行有效的負載預測。
MSTEM 結合了一個多尺度圖形神經網路，以辨別不同時間尺度上的階層式非線性時間依賴性。
此外，它還整合了一個遞迴學習組成部分和一個殘差融合機制，增強其準確捕捉充電模式中空間和時間變化的能力。
所提出的 MSTEM 的有效性已通過使用三個評估指標與六個基準模型進行比較分析得到驗證。
案例研究利用了英國伯斯的 EVCS 中快速和慢速充電負載的真實世界資料集。
實驗結果證明了 MSTEM 在 EVCS 的短期連續負載預測中的優越性。

##### **BLSP-KD: Bootstrapping Language-Speech Pre-training via Knowledge Distillation**
2405.19041v1 by Chen Wang, Minpeng Liao, Zhongqiang Huang, Jiajun Zhang

Recent end-to-end approaches have shown promise in extending large language
models (LLMs) to speech inputs, but face limitations in directly assessing and
optimizing alignment quality and fail to achieve fine-grained alignment due to
speech-text length mismatch. We introduce BLSP-KD, a novel approach for
Bootstrapping Language-Speech Pretraining via Knowledge Distillation, which
addresses these limitations through two key techniques. First, it optimizes
speech-text alignment by minimizing the divergence between the LLM's next-token
prediction distributions for speech and text inputs using knowledge
distillation. Second, it employs a continuous-integrate-andfire strategy to
segment speech into tokens that correspond one-to-one with text tokens,
enabling fine-grained alignment. We also introduce Partial LoRA (PLoRA), a new
adaptation method supporting LLM finetuning for speech inputs under knowledge
distillation. Quantitative evaluation shows that BLSP-KD outperforms previous
end-to-end baselines and cascaded systems with comparable scale of parameters,
facilitating general instruction-following capabilities for LLMs with speech
inputs. This approach provides new possibilities for extending LLMs to spoken
language interactions.

摘要：最近的端到端方法已显示出将大型语言模型 (LLM) 扩展到语音输入方面的前景，但在直接评估和优化对齐质量方面面临限制，并且由于语音文本长度不匹配而无法实现细粒度对齐。我们引入了 BLSP-KD，这是一种通过知识蒸馏引导语言语音预训练的新方法，它通过两种关键技术解决了这些限制。首先，它通过使用知识蒸馏最小化 LLM 的语音和文本输入的下一个标记预测分布之间的差异来优化语音文本对齐。其次，它采用连续集成和触发策略将语音细分为与文本标记一一对应的标记，从而实现细粒度对齐。我们还引入了部分 LoRA (PLoRA)，这是一种新的自适应方法，支持在知识蒸馏下对 LLM 微调语音输入。定量评估表明，BLSP-KD 优于具有可比参数规模的先前端到端基线和级联系统，从而促进了 LLM 具有语音输入的一般指令遵循能力。这种方法为将 LLM 扩展到口语交互提供了新的可能性。

##### **CiliaGraph: Enabling Expression-enhanced Hyper-Dimensional Computation in Ultra-Lightweight and One-Shot Graph Classification on Edge**
2405.19033v1 by Yuxi Han, Jihe Wang, Danghui Wang

Graph Neural Networks (GNNs) are computationally demanding and inefficient
when applied to graph classification tasks in resource-constrained edge
scenarios due to their inherent process, involving multiple rounds of forward
and backward propagation. As a lightweight alternative, Hyper-Dimensional
Computing (HDC), which leverages high-dimensional vectors for data encoding and
processing, offers a more efficient solution by addressing computational
bottleneck. However, current HDC methods primarily focus on static graphs and
neglect to effectively capture node attributes and structural information,
which leads to poor accuracy. In this work, we propose CiliaGraph, an enhanced
expressive yet ultra-lightweight HDC model for graph classification. This model
introduces a novel node encoding strategy that preserves relative distance
isomorphism for accurate node connection representation. In addition, node
distances are utilized as edge weights for information aggregation, and the
encoded node attributes and structural information are concatenated to obtain a
comprehensive graph representation. Furthermore, we explore the relationship
between orthogonality and dimensionality to reduce the dimensions, thereby
further enhancing computational efficiency. Compared to the SOTA GNNs,
extensive experiments show that CiliaGraph reduces memory usage and accelerates
training speed by an average of 292 times(up to 2341 times) and 103 times(up to
313 times) respectively while maintaining comparable accuracy.

摘要：圖神經網路 (GNN) 在應用於資源受限的邊緣場景中的圖形分類任務時，由於其固有的流程涉及多輪正向和反向傳播，因此計算量大且效率低。作為一種輕量級的替代方案，超維計算 (HDC) 利用高維向量進行數據編碼和處理，通過解決計算瓶頸提供了一個更有效的解決方案。然而，當前的 HDC 方法主要關注靜態圖形，而忽略了有效捕獲節點屬性和結構信息，這導致了較差的準確性。在這項工作中，我們提出了 CiliaGraph，這是一個增強的表達性但超輕量級的 HDC 模型，用於圖形分類。該模型引入了一種新的節點編碼策略，它保留了相對距離同構性以實現準確的節點連接表示。此外，節點距離被用作信息聚合的邊權重，並且對編碼的節點屬性和結構信息進行串聯以獲得一個全面的圖形表示。此外，我們探索了正交性與維度之間的關係以降低維度，從而進一步提高計算效率。與 SOTA GNN 相比，大量的實驗表明，CiliaGraph 將內存使用量減少了 292 倍（最多 2341 倍）並將訓練速度提高了 103 倍（最多 313 倍），同時保持了可比的準確性。

##### **Large Language Models for Code Summarization**
2405.19032v1 by Balázs Szalontai, Gergő Szalay, Tamás Márton, Anna Sike, Balázs Pintér, Tibor Gregorics

Recently, there has been increasing activity in using deep learning for
software engineering, including tasks like code generation and summarization.
In particular, the most recent coding Large Language Models seem to perform
well on these problems. In this technical report, we aim to review how these
models perform in code explanation/summarization, while also investigating
their code generation capabilities (based on natural language descriptions).

摘要：最近，使用深度學習進行軟體工程的活動越來越多，包括程式碼生成和摘要等任務。
特別是，最近的編碼大型語言模型似乎在這些問題上表現良好。在這個技術報告中，我們旨在回顧這些模型在程式碼說明/摘要中的表現，同時也研究它們的程式碼生成能力（基於自然語言描述）。

##### **Convex neural network synthesis for robustness in the 1-norm**
2405.19029v1 by Ross Drummond, Chris Guiver, Matthew C. Turner

With neural networks being used to control safety-critical systems, they
increasingly have to be both accurate (in the sense of matching inputs to
outputs) and robust. However, these two properties are often at odds with each
other and a trade-off has to be navigated. To address this issue, this paper
proposes a method to generate an approximation of a neural network which is
certifiably more robust. Crucially, the method is fully convex and posed as a
semi-definite programme. An application to robustifying model predictive
control is used to demonstrate the results. The aim of this work is to
introduce a method to navigate the neural network robustness/accuracy
trade-off.

摘要：隨著神經網路被用於控制安全關鍵系統，它們越來越必須既準確（在將輸入與輸出匹配的意義上）又健全。然而，這兩個特性通常相互矛盾，必須權衡取捨。為了解決這個問題，本文提出了一種方法來產生神經網路的近似值，該近似值經過證明更健全。至關重要的是，該方法完全凸出並作為半定明確定程式提出。用於加強模型預測控制的應用用於展示結果。這項工作的目的是引入一種方法來應對神經網路健全性/準確性權衡。

##### **DiveR-CT: Diversity-enhanced Red Teaming with Relaxing Constraints**
2405.19026v1 by Andrew Zhao, Quentin Xu, Matthieu Lin, Shenzhi Wang, Yong-jin Liu, Zilong Zheng, Gao Huang

Recent advances in large language models (LLMs) have made them indispensable,
raising significant concerns over managing their safety. Automated red teaming
offers a promising alternative to the labor-intensive and error-prone manual
probing for vulnerabilities, providing more consistent and scalable safety
evaluations. However, existing approaches often compromise diversity by
focusing on maximizing attack success rate. Additionally, methods that decrease
the cosine similarity from historical embeddings with semantic diversity
rewards lead to novelty stagnation as history grows. To address these issues,
we introduce DiveR-CT, which relaxes conventional constraints on the objective
and semantic reward, granting greater freedom for the policy to enhance
diversity. Our experiments demonstrate DiveR-CT's marked superiority over
baselines by 1) generating data that perform better in various diversity
metrics across different attack success rate levels, 2) better-enhancing
resiliency in blue team models through safety tuning based on collected data,
3) allowing dynamic control of objective weights for reliable and controllable
attack success rates, and 4) reducing susceptibility to reward
overoptimization. Project details and code can be found at
https://andrewzh112.github.io/#diverct.

摘要：大型語言模型 (LLM) 的最新進展讓它們變得不可或缺，
對管理其安全性提出了重大的疑慮。自動化紅隊演練
提供了一個有希望的替代方案，可以取代勞力密集且容易出錯的手動
漏洞探測，提供更一致且可擴充的安全
評估。然而，現有方法通常會透過
專注於最大化攻擊成功率來損害多樣性。此外，減少
歷史嵌入與語義多樣性獎勵之間的餘弦相似性的方法會導致歷史增長時的新穎性停滯。為了解決這些問題，
我們引入了 DiveR-CT，它放寬了對目標的傳統約束
和語義獎勵，讓策略有更大的自由度來增強
多樣性。我們的實驗證明了 DiveR-CT 明顯優於
基準，原因有 1) 在不同的攻擊成功率層級中產生在各種多樣性
指標中表現更好的資料，2) 透過基於收集資料的安全調整，更好地增強
藍隊模型的韌性，3) 允許動態控制目標權重以確保可靠且可控的
攻擊成功率，以及 4) 降低對獎勵
過度最佳化的敏感性。專案詳細資訊和程式碼可以在
https://andrewzh112.github.io/#diverct 找到。

##### **Evaluating the External and Parametric Knowledge Fusion of Large Language Models**
2405.19010v1 by Hao Zhang, Yuyang Zhang, Xiaoguang Li, Wenxuan Shi, Haonan Xu, Huanshuo Liu, Yasheng Wang, Lifeng Shang, Qun Liu, Yong Liu, Ruiming Tang

Integrating external knowledge into large language models (LLMs) presents a
promising solution to overcome the limitations imposed by their antiquated and
static parametric memory. Prior studies, however, have tended to over-reliance
on external knowledge, underestimating the valuable contributions of an LLMs'
intrinsic parametric knowledge. The efficacy of LLMs in blending external and
parametric knowledge remains largely unexplored, especially in cases where
external knowledge is incomplete and necessitates supplementation by their
parametric knowledge. We propose to deconstruct knowledge fusion into four
distinct scenarios, offering the first thorough investigation of LLM behavior
across each. We develop a systematic pipeline for data construction and
knowledge infusion to simulate these fusion scenarios, facilitating a series of
controlled experiments. Our investigation reveals that enhancing parametric
knowledge within LLMs can significantly bolster their capability for knowledge
integration. Nonetheless, we identify persistent challenges in memorizing and
eliciting parametric knowledge, and determining parametric knowledge
boundaries. Our findings aim to steer future explorations on harmonizing
external and parametric knowledge within LLMs.

摘要：將外部知識整合到大型語言模型 (LLM) 中，提供了一個有前景的解決方案，可以克服其過時的靜態參數記憶所施加的限制。然而，先前的研究傾向於過度依賴外部知識，低估了 LLM 內在參數知識的寶貴貢獻。LLM 在融合外部和參數知識方面的效能仍未得到充分的探索，特別是在外部知識不完整且需要參數知識補充的情況下。我們建議將知識融合解構為四種不同的情境，提供 LLM 在每種情境中的首次徹底調查。我們開發了一個用於數據建構和知識注入的系統化管道，以模擬這些融合情境，並促進一系列受控實驗。我們的調查顯示，增強 LLM 中的參數知識可以顯著提升其知識整合能力。儘管如此，我們發現了在記憶和引發參數知識以及確定參數知識邊界方面持續存在的挑戰。我們的研究結果旨在引導未來在 LLM 中協調外部和參數知識的探索。

##### **Continuously Optimizing Radar Placement with Model Predictive Path Integrals**
2405.18999v2 by Michael Potter, Shuo Tang, Paul Ghanem, Milica Stojanovic, Pau Closas, Murat Akcakaya, Ben Wright, Marius Necsoiu, Deniz Erdogmus, Michael Everett, Tales Imbiriba

Continuously optimizing sensor placement is essential for precise target
localization in various military and civilian applications. While information
theory has shown promise in optimizing sensor placement, many studies
oversimplify sensor measurement models or neglect dynamic constraints of mobile
sensors. To address these challenges, we employ a range measurement model that
incorporates radar parameters and radar-target distance, coupled with Model
Predictive Path Integral (MPPI) control to manage complex environmental
obstacles and dynamic constraints. We compare the proposed approach against
stationary radars or simplified range measurement models based on the root mean
squared error (RMSE) of the Cubature Kalman Filter (CKF) estimator for the
targets' state. Additionally, we visualize the evolving geometry of radars and
targets over time, highlighting areas of highest measurement information gain,
demonstrating the strengths of the approach. The proposed strategy outperforms
stationary radars and simplified range measurement models in target
localization, achieving a 38-74% reduction in mean RMSE and a 33-79% reduction
in the upper tail of the 90% Highest Density Interval (HDI) over 500 Monte Carl
(MC) trials across all time steps.
  Code will be made publicly available upon acceptance.

摘要：持續最佳化感測器配置對於各種軍用和民用應用中的精確目標定位至關重要。雖然資訊理論在最佳化感測器配置中展現潛力，但許多研究過於簡化感測器測量模型，或忽略行動感測器的動態限制。為了解決這些挑戰，我們採用了結合雷達參數和雷達目標距離的距離測量模型，並結合模型預測路徑積分 (MPPI) 控制來管理複雜的環境障礙和動態限制。我們將提出的方法與基於卡爾曼濾波器 (CKF) 估計器的均方根誤差 (RMSE) 的固定雷達或簡化的距離測量模型進行比較，以了解目標狀態。此外，我們可視化雷達和目標隨時間演變的幾何形狀，重點標示測量資訊獲取量最高的區域，以展示此方法的優點。提出的策略在目標定位方面優於固定雷達和簡化的距離測量模型，在 500 次蒙地卡羅 (MC) 試驗中，將所有時間步驟的平均 RMSE 降低了 38-74%，並將 90% 最高密度區間 (HDI) 的上尾降低了 33-79%。程式碼將在接受後公開。

##### **EasyAnimate: A High-Performance Long Video Generation Method based on Transformer Architecture**
2405.18991v1 by Jiaqi Xu, Xinyi Zou, Kunzhe Huang, Yunkuo Chen, Bo Liu, MengLi Cheng, Xing Shi, Jun Huang

This paper presents EasyAnimate, an advanced method for video generation that
leverages the power of transformer architecture for high-performance outcomes.
We have expanded the DiT framework originally designed for 2D image synthesis
to accommodate the complexities of 3D video generation by incorporating a
motion module block. It is used to capture temporal dynamics, thereby ensuring
the production of consistent frames and seamless motion transitions. The motion
module can be adapted to various DiT baseline methods to generate video with
different styles. It can also generate videos with different frame rates and
resolutions during both training and inference phases, suitable for both images
and videos. Moreover, we introduce slice VAE, a novel approach to condense the
temporal axis, facilitating the generation of long duration videos. Currently,
EasyAnimate exhibits the proficiency to generate videos with 144 frames. We
provide a holistic ecosystem for video production based on DiT, encompassing
aspects such as data pre-processing, VAE training, DiT models training (both
the baseline model and LoRA model), and end-to-end video inference. Code is
available at: https://github.com/aigc-apps/EasyAnimate. We are continuously
working to enhance the performance of our method.

摘要：本文提出了 EasyAnimate，這是一種先進的影片生成方法，它利用Transformer架構的力量來獲得高性能的結果。我們擴充了原本設計用於 2D 影像合成的 DiT 架構，以容納 3D 影片生成的複雜性，方法是加入一個動作模組區塊。它用於捕捉時間動態，從而確保產生一致的畫面和流暢的動作轉換。動作模組可以適應各種 DiT 基準方法，以產生不同風格的影片。它還可以在訓練和推理階段產生不同幀率和解析度的影片，適用於影像和影片。此外，我們引入了切片 VAE，這是一種濃縮時間軸的新方法，有助於產生長時影片。目前，EasyAnimate 展示了產生 144 幀影片的能力。我們提供了一個基於 DiT 的整體影片製作生態系統，包含資料前處理、VAE 訓練、DiT 模型訓練（基線模型和 LoRA 模型）和端到端影片推理等面向。程式碼可在 https://github.com/aigc-apps/EasyAnimate 取得。我們持續致力於提升我們的方法的效能。

##### **Encoding Hierarchical Schema via Concept Flow for Multifaceted Ideology Detection**
2405.18974v1 by Songtao Liu, Bang Wang, Wei Xiang, Han Xu, Minghua Xu

Multifaceted ideology detection (MID) aims to detect the ideological leanings
of texts towards multiple facets. Previous studies on ideology detection mainly
focus on one generic facet and ignore label semantics and explanatory
descriptions of ideologies, which are a kind of instructive information and
reveal the specific concepts of ideologies. In this paper, we develop a novel
concept semantics-enhanced framework for the MID task. Specifically, we propose
a bidirectional iterative concept flow (BICo) method to encode multifaceted
ideologies. BICo enables the concepts to flow across levels of the schema tree
and enriches concept representations with multi-granularity semantics.
Furthermore, we explore concept attentive matching and concept-guided
contrastive learning strategies to guide the model to capture ideology features
with the learned concept semantics. Extensive experiments on the benchmark
dataset show that our approach achieves state-of-the-art performance in MID,
including in the cross-topic scenario.

摘要：多面向意識形態偵測（MID）旨在偵測文本對多個面向的意識形態傾向。先前關於意識形態偵測的研究主要關注於一個通用面向，而忽略了標籤語意和意識形態的說明性描述，這些描述是一種有指導性的資訊，且揭示了意識形態的特定概念。在本文中，我們為 MID 任務開發了一個新穎的概念語意增強框架。具體來說，我們提出了一個雙向迭代概念流（BICo）方法來編碼多面向意識形態。BICo 使概念能夠跨架構樹的層級流動，並使用多粒度語意豐富概念表示。此外，我們探討了概念注意力比對和概念引導對比學習策略，以指導模型使用學習的概念語意擷取意識形態特徵。基準資料集上的廣泛實驗表明，我們的做法在 MID 中達到了最先進的效能，包括跨主題情境。

##### **UniIF: Unified Molecule Inverse Folding**
2405.18968v1 by Zhangyang Gao, Jue Wang, Cheng Tan, Lirong Wu, Yufei Huang, Siyuan Li, Zhirui Ye, Stan Z. Li

Molecule inverse folding has been a long-standing challenge in chemistry and
biology, with the potential to revolutionize drug discovery and material
science. Despite specified models have been proposed for different small- or
macro-molecules, few have attempted to unify the learning process, resulting in
redundant efforts. Complementary to recent advancements in molecular structure
prediction, such as RoseTTAFold All-Atom and AlphaFold3, we propose the unified
model UniIF for the inverse folding of all molecules. We do such unification in
two levels: 1) Data-Level: We propose a unified block graph data form for all
molecules, including the local frame building and geometric feature
initialization. 2) Model-Level: We introduce a geometric block attention
network, comprising a geometric interaction, interactive attention and virtual
long-term dependency modules, to capture the 3D interactions of all molecules.
Through comprehensive evaluations across various tasks such as protein design,
RNA design, and material design, we demonstrate that our proposed method
surpasses state-of-the-art methods on all tasks. UniIF offers a versatile and
effective solution for general molecule inverse folding.

摘要：分子逆折叠一直是化学和生物学领域的一项长期挑战，它有可能彻底改变药物发现和材料科学。尽管已经针对不同的小型或大型分子提出了特定的模型，但很少有人尝试统一学习过程，导致了重复的工作。作为分子结构预测领域最新进展的补充，例如 RoseTTAFold All-Atom 和 AlphaFold3，我们提出了统一模型 UniIF，用于所有分子的逆折叠。我们在两个层面上进行这种统一：1) 数据层：我们为所有分子提出了一种统一的块状图数据形式，包括局部框架构建和几何特征初始化。2) 模型层：我们引入了一个几何块注意力网络，包括几何交互、交互注意力和虚拟长期依赖模块，以捕获所有分子的 3D 相互作用。通过对蛋白质设计、RNA 设计和材料设计等各种任务进行综合评估，我们证明了我们提出的方法在所有任务上都超越了最先进的方法。UniIF 为通用的分子逆折叠提供了一个通用且有效的解决方案。

##### **Are You Sure? Rank Them Again: Repeated Ranking For Better Preference Datasets**
2405.18952v1 by Peter Devine

Training Large Language Models (LLMs) with Reinforcement Learning from AI
Feedback (RLAIF) aligns model outputs more closely with human preferences. This
involves an evaluator model ranking multiple candidate responses to user
prompts. However, the rankings from popular evaluator models such as GPT-4 can
be inconsistent. We propose the Repeat Ranking method - where we evaluate the
same responses multiple times and train only on those responses which are
consistently ranked. Using 2,714 prompts in 62 languages, we generated
responses from 7 top multilingual LLMs and had GPT-4 rank them five times each.
Evaluating on MT-Bench chat benchmarks in six languages, our method
outperformed the standard practice of training on all available prompts. Our
work highlights the quality versus quantity trade-off in RLAIF dataset
generation and offers a stackable strategy for enhancing dataset and thus model
quality.

摘要：使用來自 AI 的強化學習訓練大型語言模型 (LLM)（RLAIF）可讓模型輸出與人類偏好更為一致。這涉及評估模型對使用者提示的排名，其中有多個候選回應。然而，來自熱門評估模型（例如 GPT-4）的排名可能不一致。我們提出重複排名方法，其中我們對相同的回應進行多次評估，並只針對持續排名的回應進行訓練。我們在 62 種語言中使用 2,714 個提示，從 7 個頂尖多語言 LLM 中產生回應，並讓 GPT-4 對每個回應進行五次排名。在六種語言的 MT-Bench 聊天基準中進行評估，我們的做法優於在所有可用提示上進行訓練的標準做法。我們的研究重點在於 RLAIF 資料集生成中品質與數量的權衡，並提供可堆疊的策略來增強資料集，進而提升模型品質。

##### **Kestrel: Point Grounding Multimodal LLM for Part-Aware 3D Vision-Language Understanding**
2405.18937v1 by Junjie Fei, Mahmoud Ahmed, Jian Ding, Eslam Mohamed Bakr, Mohamed Elhoseiny

While 3D MLLMs have achieved significant progress, they are restricted to
object and scene understanding and struggle to understand 3D spatial structures
at the part level. In this paper, we introduce Kestrel, representing a novel
approach that empowers 3D MLLMs with part-aware understanding, enabling better
interpretation and segmentation grounding of 3D objects at the part level.
Despite its significance, the current landscape lacks tasks and datasets that
endow and assess this capability. Therefore, we propose two novel tasks: (1)
Part-Aware Point Grounding, the model is tasked with directly predicting a
part-level segmentation mask based on user instructions, and (2) Part-Aware
Point Grounded Captioning, the model provides a detailed caption that includes
part-level descriptions and their corresponding masks. To support learning and
evaluating for these tasks, we introduce 3DCoMPaT Grounded Instructions Dataset
(3DCoMPaT-GRIN). 3DCoMPaT-GRIN Vanilla, comprising 789k part-aware point
cloud-instruction-segmentation mask triplets, is used to evaluate MLLMs'
ability of part-aware segmentation grounding. 3DCoMPaT-GRIN Grounded Caption,
containing 107k part-aware point cloud-instruction-grounded caption triplets,
assesses both MLLMs' part-aware language comprehension and segmentation
grounding capabilities. Our introduced tasks, dataset, and Kestrel represent a
preliminary effort to bridge the gap between human cognition and 3D MLLMs,
i.e., the ability to perceive and engage with the environment at both global
and part levels. Extensive experiments on the 3DCoMPaT-GRIN show that Kestrel
can generate user-specified segmentation masks, a capability not present in any
existing 3D MLLM. Kestrel thus established a benchmark for evaluating the
part-aware language comprehension and segmentation grounding of 3D objects.
Project page at https://feielysia.github.io/Kestrel.github.io/

摘要：儘管 3D MLLM 已取得顯著進展，但它們僅限於物體和場景理解，並難以理解零件層級的 3D 空間結構。在本文中，我們介紹 Kestrel，它代表一種創新的方法，賦予 3D MLLM 具有部分感知理解的能力，進而可以在零件層級對 3D 物件進行更好的解釋和分割基礎。儘管很重要，但目前的現況缺乏賦予和評估此功能的任務和資料集。因此，我們提出了兩個新任務：(1) 部分感知點基礎，模型的任務是根據使用者的指示直接預測零件層級分割遮罩，以及 (2) 部分感知點基礎標題，模型提供包含零件層級描述及其對應遮罩的詳細標題。為了支援這些任務的學習和評估，我們引入了 3DCoMPaT 基礎指示資料集 (3DCoMPaT-GRIN)。3DCoMPaT-GRIN Vanilla 包含 789k 個具有部分感知的點雲指令分割遮罩三元組，用於評估 MLLM 部分感知分割基礎的能力。3DCoMPaT-GRIN 基礎標題包含 107k 個具有部分感知的點雲指令基礎標題三元組，評估 MLLM 的部分感知語言理解和分割基礎功能。我們引入的任務、資料集和 Kestrel 代表了彌合人類認知和 3D MLLM 之間差距的初步努力，即在全球和局部層級感知和參與環境的能力。在 3DCoMPaT-GRIN 上進行的廣泛實驗表明，Kestrel 可以生成使用者指定的分割遮罩，這項功能在任何現有的 3D MLLM 中都沒有。因此，Kestrel 為評估 3D 物件的部分感知語言理解和分割基礎建立了一個基準。專案頁面位於 https://feielysia.github.io/Kestrel.github.io/

##### **Understanding and Addressing the Under-Translation Problem from the Perspective of Decoding Objective**
2405.18922v1 by Chenze Shao, Fandong Meng, Jiali Zeng, Jie Zhou

Neural Machine Translation (NMT) has made remarkable progress over the past
years. However, under-translation and over-translation remain two challenging
problems in state-of-the-art NMT systems. In this work, we conduct an in-depth
analysis on the underlying cause of under-translation in NMT, providing an
explanation from the perspective of decoding objective. To optimize the beam
search objective, the model tends to overlook words it is less confident about,
leading to the under-translation phenomenon. Correspondingly, the model's
confidence in predicting the End Of Sentence (EOS) diminishes when
under-translation occurs, serving as a mild penalty for under-translated
candidates. Building upon this analysis, we propose employing the confidence of
predicting EOS as a detector for under-translation, and strengthening the
confidence-based penalty to penalize candidates with a high risk of
under-translation. Experiments on both synthetic and real-world data show that
our method can accurately detect and rectify under-translated outputs, with
minor impact on other correct translations.

摘要：神經機器翻譯 (NMT) 近年來取得顯著進展。然而，譯漏和譯過頭仍然是現今最先進的 NMT 系統中的兩個挑戰性問題。在此研究中，我們深入探討 NMT 中譯漏的根本原因，並從解碼目標的角度提供解釋。為了最佳化波束搜尋目標，模型傾向於忽略它較不確定的字詞，導致譯漏現象。相對應地，當譯漏發生時，模型預測句子結束 (EOS) 的信心會降低，作為對譯漏候選項的輕微懲罰。根據此分析，我們建議使用預測 EOS 的信心作為譯漏的偵測器，並強化基於信心的懲罰，以懲罰具有高譯漏風險的候選項。在合成和真實世界資料上的實驗顯示，我們的方法可以準確偵測和修正譯漏的輸出，對其他正確翻譯的影響很小。

##### **Towards Faithful Chain-of-Thought: Large Language Models are Bridging Reasoners**
2405.18915v1 by Jiachun Li, Pengfei Cao, Yubo Chen, Kang Liu, Jun Zhao

Large language models (LLMs) suffer from serious unfaithful chain-of-thought
(CoT) issues. Previous work attempts to measure and explain it but lacks
in-depth analysis within CoTs and does not consider the interactions among all
reasoning components jointly. In this paper, we first study the CoT
faithfulness issue at the granularity of CoT steps, identify two reasoning
paradigms: centralized reasoning and distributed reasoning, and find their
relationship with faithfulness. Subsequently, we conduct a joint analysis of
the causal relevance among the context, CoT, and answer during reasoning. The
result proves that, when the LLM predicts answers, it can recall correct
information missing in the CoT from the context, leading to unfaithfulness
issues. Finally, we propose the inferential bridging method to mitigate this
issue, in which we use the attribution method to recall information as hints
for CoT generation and filter out noisy CoTs based on their semantic
consistency and attribution scores. Extensive experiments demonstrate that our
approach effectively alleviates the unfaithful CoT problem.

摘要：大型語言模型 (LLM) 存在嚴重的推理鏈 (CoT) 不忠實問題。先前的研究嘗試測量和解釋它，但缺乏對 CoT 內部的深入分析，並且沒有共同考慮所有推理組成部分之間的互動。在本文中，我們首先研究 CoT 步驟粒度的 CoT 忠實度問題，識別出兩種推理範例：集中推理和分散推理，並找出它們與忠實度的關係。隨後，我們對推理過程中的背景、CoT 和答案之間的因果關聯進行聯合分析。結果證明，當 LLM 預測答案時，它可以從背景中召回 CoT 中遺漏的正確資訊，導致不忠實問題。最後，我們提出了推理橋接方法來減輕這個問題，我們在其中使用歸因方法將資訊作為 CoT 生成的提示進行召回，並根據它們的語義一致性和歸因分數過濾掉有雜訊的 CoT。大量的實驗證明，我們的做法有效地緩解了不忠實的 CoT 問題。

##### **Predicting Parking Availability in Singapore with Cross-Domain Data: A New Dataset and A Data-Driven Approach**
2405.18910v1 by Huaiwu Zhang, Yutong Xia, Siru Zhong, Kun Wang, Zekun Tong, Qingsong Wen, Roger Zimmermann, Yuxuan Liang

The increasing number of vehicles highlights the need for efficient parking
space management. Predicting real-time Parking Availability (PA) can help
mitigate traffic congestion and the corresponding social problems, which is a
pressing issue in densely populated cities like Singapore. In this study, we
aim to collectively predict future PA across Singapore with complex factors
from various domains. The contributions in this paper are listed as follows:
(1) A New Dataset: We introduce the \texttt{SINPA} dataset, containing a year's
worth of PA data from 1,687 parking lots in Singapore, enriched with various
spatial and temporal factors. (2) A Data-Driven Approach: We present DeepPA, a
novel deep-learning framework, to collectively and efficiently predict future
PA across thousands of parking lots. (3) Extensive Experiments and Deployment:
DeepPA demonstrates a 9.2% reduction in prediction error for up to 3-hour
forecasts compared to existing advanced models. Furthermore, we implement
DeepPA in a practical web-based platform to provide real-time PA predictions to
aid drivers and inform urban planning for the governors in Singapore. We
release the dataset and source code at https://github.com/yoshall/SINPA.

摘要：隨著車輛數量增加，凸顯出有效停車空間管理的需求。預測即時停車可用性 (PA) 可有助於緩解交通擁塞和相應的社會問題，這是人口稠密城市（例如新加坡）中的緊迫問題。在本研究中，我們旨在透過來自不同領域的複雜因素，共同預測新加坡未來的 PA。本文的貢獻如下：(1) 新資料集：我們推出 \texttt{SINPA} 資料集，其中包含新加坡 1,687 個停車場一年的 PA 資料，並豐富了各種空間和時間因素。(2) 資料驅動方法：我們提出 DeepPA，一種新穎的深度學習架構，用於共同且有效預測數千個停車場的未來 PA。(3) 廣泛的實驗和部署：與現有的進階模型相比，DeepPA 展示了預測誤差降低 9.2%，最長可達 3 小時預測。此外，我們在實用的網路平台中實作 DeepPA，以提供即時 PA 預測，協助駕駛並為新加坡的管理者提供城市規劃資訊。我們在 https://github.com/yoshall/SINPA 上釋出資料集和原始碼。

##### **Language Generation with Strictly Proper Scoring Rules**
2405.18906v1 by Chenze Shao, Fandong Meng, Yijin Liu, Jie Zhou

Language generation based on maximum likelihood estimation (MLE) has become
the fundamental approach for text generation. Maximum likelihood estimation is
typically performed by minimizing the log-likelihood loss, also known as the
logarithmic score in statistical decision theory. The logarithmic score is
strictly proper in the sense that it encourages honest forecasts, where the
expected score is maximized only when the model reports true probabilities.
Although many strictly proper scoring rules exist, the logarithmic score is the
only local scoring rule among them that depends exclusively on the probability
of the observed sample, making it capable of handling the exponentially large
sample space of natural text. In this work, we propose a straightforward
strategy for adapting scoring rules to language generation, allowing for
language modeling with any non-local scoring rules. Leveraging this strategy,
we train language generation models using two classic strictly proper scoring
rules, the Brier score and the Spherical score, as alternatives to the
logarithmic score. Experimental results indicate that simply substituting the
loss function, without adjusting other hyperparameters, can yield substantial
improvements in model's generation capabilities. Moreover, these improvements
can scale up to large language models (LLMs) such as LLaMA-7B and LLaMA-13B.
Source code: \url{https://github.com/shaochenze/ScoringRulesLM}.

摘要：基於最大似然估計 (MLE) 的語言生成已成為文本生成的基礎方法。最大似然估計通常透過最小化對數似然損失來執行，這在統計決策理論中也稱為對數得分。對數得分在嚴格意義上是適當的，因為它鼓勵誠實的預測，其中預期得分僅在模型報告真實機率時最大化。儘管存在許多嚴格適當的評分規則，但對數得分是其中唯一僅依賴於觀察樣本機率的局部評分規則，使其能夠處理自然文本的指數級大型樣本空間。在這項工作中，我們提出了一個將評分規則適應語言生成的直接策略，允許使用任何非局部評分規則進行語言建模。利用此策略，我們使用兩個經典的嚴格適當評分規則（Brier 得分和球面得分）訓練語言生成模型，作為對數得分的替代方案。實驗結果表明，僅替換損失函數，而不調整其他超參數，就能顯著提升模型的生成能力。此外，這些改進可以擴展到大型語言模型 (LLM)，例如 LLaMA-7B 和 LLaMA-13B。原始碼：\url{https://github.com/shaochenze/ScoringRulesLM}。

##### **A Causal Framework for Evaluating Deferring Systems**
2405.18902v1 by Filippo Palomba, Andrea Pugnana, José Manuel Alvarez, Salvatore Ruggieri

Deferring systems extend supervised Machine Learning (ML) models with the
possibility to defer predictions to human experts. However, evaluating the
impact of a deferring strategy on system accuracy is still an overlooked area.
This paper fills this gap by evaluating deferring systems through a causal
lens. We link the potential outcomes framework for causal inference with
deferring systems. This allows us to identify the causal impact of the
deferring strategy on predictive accuracy. We distinguish two scenarios. In the
first one, we can access both the human and the ML model predictions for the
deferred instances. In such a case, we can identify the individual causal
effects for deferred instances and aggregates of them. In the second scenario,
only human predictions are available for the deferred instances. In this case,
we can resort to regression discontinuity design to estimate a local causal
effect. We empirically evaluate our approach on synthetic and real datasets for
seven deferring systems from the literature.

摘要：延遲系統擴充了監督式機器學習 (ML) 模型，讓人類專家可以延遲預測。然而，評估延遲策略對系統精確度的影響仍是一個被忽略的領域。本文透過因果關係透鏡評估延遲系統，填補了這項空白。我們將因果推論的潛在結果架構與延遲系統連結起來。這讓我們可以找出延遲策略對預測精確度的因果影響。我們區分出兩種情境。在第一種情境中，我們可以取得人類和 ML 模型對延遲個體的預測。在這種情況下，我們可以找出延遲個體和其彙總資料的個別因果效應。在第二種情境中，只有延遲個體的人類預測可用。在這種情況下，我們可以訴諸回歸不連續性設計來估計局部因果效應。我們透過文獻中的七個延遲系統，對合成和真實資料集實證評估我們的做法。

##### **Few-Shot Testing: Estimating Uncertainty of Memristive Deep Neural Networks Using One Bayesian Test Vector**
2405.18894v1 by Soyed Tuhin Ahmed, Mehdi Tahoori

The performance of deep learning algorithms such as neural networks (NNs) has
increased tremendously recently, and they can achieve state-of-the-art
performance in many domains. However, due to memory and computation resource
constraints, implementing NNs on edge devices is a challenging task. Therefore,
hardware accelerators such as computation-in-memory (CIM) with memristive
devices have been developed to accelerate the most common operations, i.e.,
matrix-vector multiplication. However, due to inherent device properties,
external environmental factors such as temperature, and an immature fabrication
process, memristors suffer from various non-idealities, including defects and
variations occurring during manufacturing and runtime. Consequently, there is a
lack of complete confidence in the predictions made by the model. To improve
confidence in NN predictions made by hardware accelerators in the presence of
device non-idealities, in this paper, we propose a Bayesian test vector
generation framework that can estimate the model uncertainty of NNs implemented
on memristor-based CIM hardware. Compared to the conventional point estimate
test vector generation method, our method is more generalizable across
different model dimensions and requires storing only one test Bayesian vector
in the hardware. Our method is evaluated on different model dimensions, tasks,
fault rates, and variation noise to show that it can consistently achieve
$100\%$ coverage with only $0.024$ MB of memory overhead.

摘要：深度學習演算法（例如神經網路 (NN)) 的效能近期大幅提升，且在許多領域中能達到最先進的效能。然而，由於記憶體和運算資源的限制，在邊緣裝置上實作 NN 是一項具有挑戰性的任務。因此，已開發出具備憶阻器裝置的記憶體中運算 (CIM) 等硬體加速器，以加速最常見的運算，即矩陣向量相乘。然而，由於內在裝置特性、溫度等外部環境因素，以及不成熟的製造流程，憶阻器會產生各種非理想性，包括在製造和執行期間發生的缺陷和變異。因此，對於模型所做的預測缺乏完全的信心。為了在裝置非理想性存在的情況下，提升硬體加速器所做 NN 預測的信心，我們在本文中提出一個貝氏測試向量產生架構，它可以估算實作於基於憶阻器的 CIM 硬體上的 NN 模型的不確定性。與傳統的點估計測試向量產生方法相比，我們的模型更能概括至不同的模型維度，且僅需在硬體中儲存一個測試貝氏向量。我們的模型在不同的模型維度、任務、故障率和變異雜訊下進行評估，以顯示它能始終如一地達成 100% 的覆蓋率，且記憶體開銷僅為 0.024 MB。

##### **Compressing Large Language Models using Low Rank and Low Precision Decomposition**
2405.18886v1 by Rajarshi Saha, Naomi Sagan, Varun Srivastava, Andrea J. Goldsmith, Mert Pilanci

The prohibitive sizes of Large Language Models (LLMs) today make it difficult
to deploy them on memory-constrained edge devices. This work introduces $\rm
CALDERA$ -- a new post-training LLM compression algorithm that harnesses the
inherent low-rank structure of a weight matrix $\mathbf{W}$ by approximating it
via a low-rank, low-precision decomposition as $\mathbf{W} \approx \mathbf{Q} +
\mathbf{L}\mathbf{R}$. Here, $\mathbf{L}$ and $\mathbf{R}$ are low rank
factors, and the entries of $\mathbf{Q}$, $\mathbf{L}$ and $\mathbf{R}$ are
quantized. The model is compressed by substituting each layer with its
$\mathbf{Q} + \mathbf{L}\mathbf{R}$ decomposition, and the zero-shot
performance of the compressed model is evaluated. Additionally, $\mathbf{L}$
and $\mathbf{R}$ are readily amenable to low-rank adaptation, consequently
enhancing the zero-shot performance. $\rm CALDERA$ obtains this decomposition
by formulating it as an optimization problem
$\min_{\mathbf{Q},\mathbf{L},\mathbf{R}}\lVert(\mathbf{Q} +
\mathbf{L}\mathbf{R} - \mathbf{W})\mathbf{X}^\top\rVert_{\rm F}^2$, where
$\mathbf{X}$ is the calibration data, and $\mathbf{Q}, \mathbf{L}, \mathbf{R}$
are constrained to be representable using low-precision formats. Theoretical
upper bounds on the approximation error of $\rm CALDERA$ are established using
a rank-constrained regression framework, and the tradeoff between compression
ratio and model performance is studied by analyzing the impact of target rank
and quantization bit budget. Results illustrate that compressing LlaMa-$2$
$7$B/$70$B and LlaMa-$3$ $8$B models obtained using $\rm CALDERA$ outperforms
existing post-training LLM compression techniques in the regime of less than
$2.5$ bits per parameter. The implementation is available at:
\href{https://github.com/pilancilab/caldera}{https://github.com/pilancilab/caldera}.

摘要：由於大型語言模型（LLM）的規模過於龐大，因此難以將其部署在記憶體受限的邊緣裝置上。本研究介紹了 $\rm CALDERA$，這是一種新的訓練後 LLM 壓縮演算法，它利用權重矩陣 $\mathbf{W}$ 固有的低秩結構，並透過低秩、低精度的分解將其近似為 $\mathbf{W} \approx \mathbf{Q} + \mathbf{L}\mathbf{R}$。其中，$\mathbf{L}$ 和 $\mathbf{R}$ 是低秩因子，而 $\mathbf{Q}$、$\mathbf{L}$ 和 $\mathbf{R}$ 的條目則已量化。模型透過將每一層替換為其 $\mathbf{Q} + \mathbf{L}\mathbf{R}$ 分解來進行壓縮，並評估壓縮模型的零次學習效能。此外，$\mathbf{L}$ 和 $\mathbf{R}$ 容易適應低秩，因此增強了零次學習效能。$\rm CALDERA$ 將此分解表述為最佳化問題 $\min_{\mathbf{Q},\mathbf{L},\mathbf{R}}\lVert(\mathbf{Q} + \mathbf{L}\mathbf{R} - \mathbf{W})\mathbf{X}^\top\rVert_{\rm F}^2$ 來取得此分解，其中 $\mathbf{X}$ 是校正資料，而 $\mathbf{Q}, \mathbf{L}, \mathbf{R}$ 則受限於使用低精度格式表示。$\rm CALDERA$ 的近似誤差的理論上限是使用秩約束迴歸架構建立的，而壓縮比和模型效能之間的權衡則是透過分析目標秩和量化位元預算的影響來研究的。結果顯示，使用 $\rm CALDERA$ 取得的 LlaMa-$2$ $7$B/$70$B 和 LlaMa-$3$ $8$B 模型的壓縮優於現有的訓練後 LLM 壓縮技術，效能低於每參數 $2.5$ 位元。實作可於以下網址取得：\href{https://github.com/pilancilab/caldera}{https://github.com/pilancilab/caldera}。

##### **Tuning-Free Alignment of Diffusion Models with Direct Noise Optimization**
2405.18881v1 by Zhiwei Tang, Jiangweizhi Peng, Jiasheng Tang, Mingyi Hong, Fan Wang, Tsung-Hui Chang

In this work, we focus on the alignment problem of diffusion models with a
continuous reward function, which represents specific objectives for downstream
tasks, such as improving human preference. The central goal of the alignment
problem is to adjust the distribution learned by diffusion models such that the
generated samples maximize the target reward function. We propose a novel
alignment approach, named Direct Noise Optimization (DNO), that optimizes the
injected noise during the sampling process of diffusion models. By design, DNO
is tuning-free and prompt-agnostic, as the alignment occurs in an online
fashion during generation. We rigorously study the theoretical properties of
DNO and also propose variants to deal with non-differentiable reward functions.
Furthermore, we identify that naive implementation of DNO occasionally suffers
from the out-of-distribution reward hacking problem, where optimized samples
have high rewards but are no longer in the support of the pretrained
distribution. To remedy this issue, we leverage classical high-dimensional
statistics theory and propose to augment the DNO loss with certain probability
regularization. We conduct extensive experiments on several popular reward
functions trained on human feedback data and demonstrate that the proposed DNO
approach achieves state-of-the-art reward scores as well as high image quality,
all within a reasonable time budget for generation.

摘要：在這項工作中，我們專注於擴散模型與連續獎勵函數的對齊問題，該函數表示下游任務的具體目標，例如改善人類偏好。對齊問題的核心目標是調整擴散模型所學習的分布，使得生成的樣本最大化目標獎勵函數。我們提出了一種新穎的對齊方法，稱為直接噪聲優化 (DNO)，它優化了擴散模型採樣過程中注入的噪聲。根據設計，DNO 是無調諧且提示無關的，因為對齊在生成過程中以在線方式發生。我們嚴謹地研究了 DNO 的理論特性，並提出了處理不可微分獎勵函數的變體。此外，我們發現 DNO 的天真實現偶爾會遭受分布外獎勵破解問題，其中優化的樣本具有高獎勵，但不再受過訓練分布的支持。為了解決此問題，我們利用經典的高維統計理論，並提出用某個機率正則化來擴充 DNO 損失。我們對在人類回饋資料上訓練的幾個流行獎勵函數進行了廣泛的實驗，並證明所提出的 DNO 方法達到了最先進的獎勵分數以及高影像品質，所有這些都在合理的生成時間預算內。

##### **Continuous Product Graph Neural Networks**
2405.18877v1 by Aref Einizade, Fragkiskos D. Malliaros, Jhony H. Giraldo

Processing multidomain data defined on multiple graphs holds significant
potential in various practical applications in computer science. However,
current methods are mostly limited to discrete graph filtering operations.
Tensorial partial differential equations on graphs (TPDEGs) provide a
principled framework for modeling structured data across multiple interacting
graphs, addressing the limitations of the existing discrete methodologies. In
this paper, we introduce Continuous Product Graph Neural Networks (CITRUS) that
emerge as a natural solution to the TPDEG. CITRUS leverages the separability of
continuous heat kernels from Cartesian graph products to efficiently implement
graph spectral decomposition. We conduct thorough theoretical analyses of the
stability and over-smoothing properties of CITRUS in response to
domain-specific graph perturbations and graph spectra effects on the
performance. We evaluate CITRUS on well-known traffic and weather
spatiotemporal forecasting datasets, demonstrating superior performance over
existing approaches.

摘要：處理定義在多個圖形上的多域數據在電腦科學的各種實際應用中具有顯著的潛力。然而，目前的技術大多限於離散圖形過濾運算。圖形上的張量偏微分方程式 (TPDEG) 提供了一個原則性的架構，用於對多個相互作用圖形中的結構化數據進行建模，從而解決現有離散方法的限制。在本文中，我們介紹了連續乘積圖形神經網路 (CITRUS)，它作為 TPDEG 的自然解決方案而出現。CITRUS 利用笛卡兒圖形乘積中連續熱核的可分離性來有效實作圖形譜分解。我們對 CITRUS 的穩定性和過平滑特性進行了徹底的理論分析，以響應特定於領域的圖形擾動和圖形譜對效能的影響。我們在眾所周知的交通和天氣時空預測資料集上評估 CITRUS，證明其效能優於現有方法。

##### **Counterfactual Metarules for Local and Global Recourse**
2405.18875v1 by Tom Bewley, Salim I. Amoukou, Saumitra Mishra, Daniele Magazzeni, Manuela Veloso

We introduce T-CREx, a novel model-agnostic method for local and global
counterfactual explanation (CE), which summarises recourse options for both
individuals and groups in the form of human-readable rules. It leverages
tree-based surrogate models to learn the counterfactual rules, alongside
'metarules' denoting their regions of optimality, providing both a global
analysis of model behaviour and diverse recourse options for users. Experiments
indicate that T-CREx achieves superior aggregate performance over existing
rule-based baselines on a range of CE desiderata, while being orders of
magnitude faster to run.

摘要：我們介紹 T-CREx，一種新的模型不可知方法，用於局部和全局反事實解釋 (CE)，它以人類可讀規則的形式總結了個人和群體的追索權選項。它利用基於樹的代理模型來學習反事實規則，以及表示其最佳區域的「元規則」，同時提供模型行為的全局分析和使用者多樣化的追索權選項。實驗表明，T-CREx 在一系列 CE 理想條件下，獲得優於現有基於規則基準的總體效能，同時執行速度快上好幾個數量級。

##### **Are queries and keys always relevant? A case study on Transformer wave functions**
2405.18874v1 by Riccardo Rende, Luciano Loris Viteritti

The dot product attention mechanism, originally designed for natural language
processing (NLP) tasks, is a cornerstone of modern Transformers. It adeptly
captures semantic relationships between word pairs in sentences by computing a
similarity overlap between queries and keys. In this work, we explore the
suitability of Transformers, focusing on their attention mechanisms, in the
specific domain of the parametrization of variational wave functions to
approximate ground states of quantum many-body spin Hamiltonians. Specifically,
we perform numerical simulations on the two-dimensional $J_1$-$J_2$ Heisenberg
model, a common benchmark in the field of quantum-many body systems on lattice.
By comparing the performance of standard attention mechanisms with a simplified
version that excludes queries and keys, relying solely on positions, we achieve
competitive results while reducing computational cost and parameter usage.
Furthermore, through the analysis of the attention maps generated by standard
attention mechanisms, we show that the attention weights become effectively
input-independent at the end of the optimization. We support the numerical
results with analytical calculations, providing physical insights of why
queries and keys should be, in principle, omitted from the attention mechanism
when studying large systems. Interestingly, the same arguments can be extended
to the NLP domain, in the limit of long input sentences.

摘要：點積注意機制最初是為自然語言處理 (NLP) 任務而設計的，是現代 Transformer 的基石。它透過計算查詢和鍵之間的相似性重疊，巧妙地捕捉句子中字詞對之間的語義關係。在這項工作中，我們探討了 Transformer 的適用性，重點放在它們在變分波函數參數化的特定領域中的注意機制，以逼近量子多體自旋哈密頓量的基態。具體來說，我們對二維 $J_1$-$J_2$ 海森堡模型進行數值模擬，這是晶格上量子多體系統領域中的常見基準。透過比較標準注意機制與排除查詢和鍵的簡化版本的效能，僅依賴於位置，我們在降低運算成本和參數使用量的同時，達到了競爭力的結果。此外，透過分析標準注意機制生成的注意圖，我們展示了注意權重在最佳化結束時有效地變得與輸入無關。我們以分析計算支持數值結果，提供物理見解，說明為什麼在研究大型系統時，原則上應該從注意機制中省略查詢和鍵。有趣的是，相同的論點可以擴展到 NLP 領域，在長輸入句子的限制下。

##### **LLMs achieve adult human performance on higher-order theory of mind tasks**
2405.18870v1 by Winnie Street, John Oliver Siy, Geoff Keeling, Adrien Baranes, Benjamin Barnett, Michael McKibben, Tatenda Kanyere, Alison Lentz, Blaise Aguera y Arcas, Robin I. M. Dunbar

This paper examines the extent to which large language models (LLMs) have
developed higher-order theory of mind (ToM); the human ability to reason about
multiple mental and emotional states in a recursive manner (e.g. I think that
you believe that she knows). This paper builds on prior work by introducing a
handwritten test suite -- Multi-Order Theory of Mind Q&A -- and using it to
compare the performance of five LLMs to a newly gathered adult human benchmark.
We find that GPT-4 and Flan-PaLM reach adult-level and near adult-level
performance on ToM tasks overall, and that GPT-4 exceeds adult performance on
6th order inferences. Our results suggest that there is an interplay between
model size and finetuning for the realisation of ToM abilities, and that the
best-performing LLMs have developed a generalised capacity for ToM. Given the
role that higher-order ToM plays in a wide range of cooperative and competitive
human behaviours, these findings have significant implications for user-facing
LLM applications.

摘要：本文探討大型語言模型 (LLM) 發展高階心智理論 (ToM) 的程度；人類以遞迴方式推理多種心智與情緒狀態的能力 (例如：我認為你相信她知道)。本文建立在先前的工作上，引入了手寫測試套件 -- 多階心智理論問答 -- 並使用它來比較五個 LLM 的效能與新收集的成人人類基準。我們發現 GPT-4 和 Flan-PaLM 在 ToM 任務上整體達到成人等級和接近成人等級的效能，而 GPT-4 在第 6 階推理上超過成人效能。我們的結果表明，模型大小和微調對於實現 ToM 能力之間存在交互作用，並且效能最佳的 LLM 已發展出廣義的 ToM 能力。考量到高階 ToM 在廣泛的合作和競爭人類行為中所扮演的角色，這些發現對使用者導向的 LLM 應用程式具有重要的意義。

##### **Topological Perspectives on Optimal Multimodal Embedding Spaces**
2405.18867v1 by Abdul Aziz A. B, A. B Abdul Rahim

Recent strides in multimodal model development have ignited a paradigm shift
in the realm of text-to-image generation. Among these advancements, CLIP stands
out as a remarkable achievement which is a sophisticated autoencoder adept at
encoding both textual and visual information within a unified latent space.
This paper delves into a comparative analysis between CLIP and its recent
counterpart, CLOOB. To unravel the intricate distinctions within the embedding
spaces crafted by these models, we employ topological data analysis. Our
approach encompasses a comprehensive examination of the modality gap drivers,
the clustering structures existing across both high and low dimensions, and the
pivotal role that dimension collapse plays in shaping their respective
embedding spaces. Empirical experiments substantiate the implications of our
analyses on downstream performance across various contextual scenarios. Through
this investigation, we aim to shed light on the nuanced intricacies that
underlie the comparative efficacy of CLIP and CLOOB, offering insights into
their respective strengths and weaknesses, and providing a foundation for
further refinement and advancement in multimodal model research.

摘要：最近多模态模型开发的进步点燃了文本到图像生成的范式转变。在这些进步中，CLIP 作为一个杰出的成就脱颖而出，它是一个复杂的自动编码器，擅长在统一的潜在空间内对文本和视觉信息进行编码。本文深入比较分析了 CLIP 和其最近的对应物 CLOOB。为了解开这些模型创建的嵌入空间内的复杂差异，我们采用了拓扑数据分析。我们的方法包括对模态差距驱动因素、高维和低维中存在的聚类结构以及维度坍缩在塑造各自嵌入空间中所扮演的关键角色的全面检查。实证实验证实了我们的分析对各种上下文场景中下游性能的影响。通过这项调查，我们旨在阐明 CLIP 和 CLOOB 的比较功效背后的细微差别，深入了解它们各自的优势和劣势，并为多模态模型研究的进一步完善和进步奠定基础。

##### **Simulation, Modelling and Classification of Wiki Contributors: Spotting The Good, The Bad, and The Ugly**
2405.18845v1 by Silvia García Méndez, Fátima Leal, Benedita Malheiro, Juan Carlos Burguillo Rial, Bruno Veloso, Adriana E. Chis, Horacio González Vélez

Data crowdsourcing is a data acquisition process where groups of voluntary
contributors feed platforms with highly relevant data ranging from news,
comments, and media to knowledge and classifications. It typically processes
user-generated data streams to provide and refine popular services such as
wikis, collaborative maps, e-commerce sites, and social networks. Nevertheless,
this modus operandi raises severe concerns regarding ill-intentioned data
manipulation in adversarial environments. This paper presents a simulation,
modelling, and classification approach to automatically identify human and
non-human (bots) as well as benign and malign contributors by using data
fabrication to balance classes within experimental data sets, data stream
modelling to build and update contributor profiles and, finally, autonomic data
stream classification. By employing WikiVoyage - a free worldwide wiki travel
guide open to contribution from the general public - as a testbed, our approach
proves to significantly boost the confidence and quality of the classifier by
using a class-balanced data stream, comprising both real and synthetic data.
Our empirical results show that the proposed method distinguishes between
benign and malign bots as well as human contributors with a classification
accuracy of up to 92 %.

摘要：資料群眾外包是一種資料取得程序，在其中一群自願的貢獻者提供平台與高度相關的資料，範圍從新聞、評論和媒體到知識和分類。它通常會處理使用者產生的資料串流，以提供和改善熱門服務，例如 wiki、協作式地圖、電子商務網站和社群網路。然而，這種運作模式對於在對抗環境中惡意的資料操作提出了嚴重的疑慮。本文提出一個模擬、建模和分類方法，以自動識別人類和非人類（機器人），以及良善和惡意的貢獻者，方法是使用資料捏造來平衡實驗資料集中的類別，資料串流建模來建立和更新貢獻者檔案，最後是自主資料串流分類。透過採用 WikiVoyage（一個免費的全球 wiki 旅遊指南，開放給一般大眾貢獻）作為測試平台，我們的做法證明，透過使用類別平衡的資料串流（包含真實和人工資料），可以顯著提升分類器的信心和品質。我們的經驗結果顯示，建議的方法可以區分良善和惡意的機器人，以及人類貢獻者，分類準確度高達 92%。

##### **Data-driven Machinery Fault Detection: A Comprehensive Review**
2405.18843v1 by Dhiraj Neupane, Mohamed Reda Bouadjenek, Richard Dazeley, Sunil Aryal

In this era of advanced manufacturing, it's now more crucial than ever to
diagnose machine faults as early as possible to guarantee their safe and
efficient operation. With the massive surge in industrial big data and
advancement in sensing and computational technologies, data-driven Machinery
Fault Diagnosis (MFD) solutions based on machine/deep learning approaches have
been used ubiquitously in manufacturing. Timely and accurately identifying
faulty machine signals is vital in industrial applications for which many
relevant solutions have been proposed and are reviewed in many articles.
Despite the availability of numerous solutions and reviews on MFD, existing
works often lack several aspects. Most of the available literature has limited
applicability in a wide range of manufacturing settings due to their
concentration on a particular type of equipment or method of analysis.
Additionally, discussions regarding the challenges associated with implementing
data-driven approaches, such as dealing with noisy data, selecting appropriate
features, and adapting models to accommodate new or unforeseen faults, are
often superficial or completely overlooked. Thus, this survey provides a
comprehensive review of the articles using different types of machine learning
approaches for the detection and diagnosis of various types of machinery
faults, highlights their strengths and limitations, provides a review of the
methods used for condition-based analyses, comprehensively discusses the
available machinery fault datasets, introduces future researchers to the
possible challenges they have to encounter while using these approaches for MFD
and recommends the probable solutions to mitigate those problems. The future
research prospects are also pointed out for a better understanding of the
field. We believe this article will help researchers and contribute to the
further development of the field.

摘要：<paragraph>在這個先進製造的時代，比以往任何時候都更需要盡早診斷機器故障，以確保其安全且有效地操作。隨著工業大數據的激增以及感測和計算技術的進步，基於機器/深度學習方法的數據驅動機器故障診斷 (MFD) 解决方案已廣泛用於製造業。及時準確地識別故障機器信號對於工業應用至關重要，許多相關解決方案已被提出並在許多文章中得到回顧。儘管有許多關於 MFD 的解決方案和回顧，但現有工作通常缺乏幾個方面。由於專注於特定類型的設備或分析方法，大多數現有文獻在廣泛的製造環境中的應用性有限。此外，關於實施數據驅動方法所面臨的挑戰（例如處理雜訊資料、選擇適當特徵以及調整模型以適應新的或無法預見的故障）的討論通常很膚淺或完全被忽視。因此，這項調查對使用不同類型機器學習方法來檢測和診斷各種類型機器故障的文章提供了全面的回顧，重點介紹它們的優點和缺點，回顧了用於基於條件分析的方法，全面討論了可用的機器故障數據集，向未來的研究人員介紹了在使用這些方法進行 MFD 時可能遇到的挑戰，並建議了解決這些問題的可能解決方案。未來研究前景也指出了對該領域的更深入理解。我們相信這篇文章將有助於研究人員並有助於該領域的進一步發展。</paragraph>

##### **MoNDE: Mixture of Near-Data Experts for Large-Scale Sparse Models**
2405.18832v1 by Taehyun Kim, Kwanseok Choi, Youngmock Cho, Jaehoon Cho, Hyuk-Jae Lee, Jaewoong Sim

Mixture-of-Experts (MoE) large language models (LLM) have memory requirements
that often exceed the GPU memory capacity, requiring costly parameter movement
from secondary memories to the GPU for expert computation. In this work, we
present Mixture of Near-Data Experts (MoNDE), a near-data computing solution
that efficiently enables MoE LLM inference. MoNDE reduces the volume of MoE
parameter movement by transferring only the $\textit{hot}$ experts to the GPU,
while computing the remaining $\textit{cold}$ experts inside the host memory
device. By replacing the transfers of massive expert parameters with the ones
of small activations, MoNDE enables far more communication-efficient MoE
inference, thereby resulting in substantial speedups over the existing
parameter offloading frameworks for both encoder and decoder operations.

摘要：混合專家 (MoE) 大型語言模型 (LLM) 具有記憶體需求，通常會超過 GPU 記憶體容量，需要從次要記憶體將昂貴的參數移動到 GPU 進行專家運算。在這項工作中，我們提出近資料專家混合 (MoNDE)，一種近資料運算解決方案，可有效啟用 MoE LLM 推論。MoNDE 透過僅將「熱門」專家傳輸到 GPU 來減少 MoE 參數移動的量，同時在主機記憶體裝置內運算其餘的「冷門」專家。透過將大量專家參數的傳輸替換為少量活化的傳輸，MoNDE 能夠實現更具通訊效率的 MoE 推論，從而大幅提升編碼器和解碼器操作現有參數卸載架構的速度。

##### **Why Reinforcement Learning in Energy Systems Needs Explanations**
2405.18823v1 by Hallah Shahid Butt, Benjamin Schäfer

With economic development, the complexity of infrastructure has increased
drastically. Similarly, with the shift from fossil fuels to renewable sources
of energy, there is a dire need for such systems that not only predict and
forecast with accuracy but also help in understanding the process of
predictions. Artificial intelligence and machine learning techniques have
helped in finding out wellperforming solutions to different problems in the
energy sector. However, the usage of state-of-the-art techniques like
reinforcement learning is not surprisingly convincing. This paper discusses the
application of reinforcement techniques in energy systems and how explanations
of these models can be helpful

摘要：隨著經濟發展，基礎設施的複雜性大幅增加。同樣地，隨著從化石燃料轉向可再生能源，迫切需要這樣的系統，不僅可以準確預測和預測，還可以幫助理解預測過程。人工智能和機器學習技術有助於找出能源部門不同問題的表現良好的解決方案。然而，使用最先進的技術（如強化學習）並不出人意料地令人信服。本文討論了強化技術在能源系統中的應用，以及這些模型的解釋如何提供幫助

##### **Toxicity Detection for Free**
2405.18822v1 by Zhanhao Hu, Julien Piet, Geng Zhao, Jiantao Jiao, David Wagner

Current LLMs are generally aligned to follow safety requirements and tend to
refuse toxic prompts. However, LLMs can fail to refuse toxic prompts or be
overcautious and refuse benign examples. In addition, state-of-the-art toxicity
detectors have low TPRs at low FPR, incurring high costs in real-world
applications where toxic examples are rare. In this paper, we explore
Moderation Using LLM Introspection (MULI), which detects toxic prompts using
the information extracted directly from LLMs themselves. We found significant
gaps between benign and toxic prompts in the distribution of alternative
refusal responses and in the distribution of the first response token's logits.
These gaps can be used to detect toxicities: We show that a toy model based on
the logits of specific starting tokens gets reliable performance, while
requiring no training or additional computational cost. We build a more robust
detector using a sparse logistic regression model on the first response token
logits, which greatly exceeds SOTA detectors under multiple metrics.

摘要：目前的 LLM 通常會調整以遵循安全要求，並傾向於拒絕有毒提示。然而，LLM 可能無法拒絕有毒提示，或過於謹慎而拒絕良性範例。此外，最先進的毒性偵測器在低 FPR 下具有低 TPR，在有毒範例罕見的實際應用中會產生高成本。在本文中，我們探索了使用 LLM 內省（MULI）進行審核，它使用從 LLM 自身直接提取的資訊來偵測有毒提示。我們發現良性和有毒提示在備用拒絕回應的分配和第一個回應權杖的 logit 分配中存在顯著差距。這些差距可用於偵測毒性：我們展示了一個基於特定起始權杖的 logit 的玩具模型獲得了可靠的效能，同時不需要訓練或額外的運算成本。我們使用一個稀疏邏輯迴歸模型在第一個回應權杖 logit 上建立了一個更強大的偵測器，它在多項指標下大大超過了 SOTA 偵測器。

##### **Diffeomorphic interpolation for efficient persistence-based topological optimization**
2405.18820v1 by Mathieu Carriere, Marc Theveneau, Théo Lacombe

Topological Data Analysis (TDA) provides a pipeline to extract quantitative
topological descriptors from structured objects. This enables the definition of
topological loss functions, which assert to what extent a given object exhibits
some topological properties. These losses can then be used to perform
topological optimizationvia gradient descent routines. While theoretically
sounded, topological optimization faces an important challenge: gradients tend
to be extremely sparse, in the sense that the loss function typically depends
on only very few coordinates of the input object, yielding dramatically slow
optimization schemes in practice.Focusing on the central case of topological
optimization for point clouds, we propose in this work to overcome this
limitation using diffeomorphic interpolation, turning sparse gradients into
smooth vector fields defined on the whole space, with quantifiable Lipschitz
constants. In particular, we show that our approach combines efficiently with
subsampling techniques routinely used in TDA, as the diffeomorphism derived
from the gradient computed on a subsample can be used to update the coordinates
of the full input object, allowing us to perform topological optimization on
point clouds at an unprecedented scale. Finally, we also showcase the relevance
of our approach for black-box autoencoder (AE) regularization, where we aim at
enforcing topological priors on the latent spaces associated to fixed,
pre-trained, black-box AE models, and where we show thatlearning a
diffeomorphic flow can be done once and then re-applied to new data in linear
time (while vanilla topological optimization has to be re-run from scratch).
Moreover, reverting the flow allows us to generate data by sampling the
topologically-optimized latent space directly, yielding better interpretability
of the model.

摘要：<paragraph>拓撲資料分析 (TDA) 提供一個管道，從結構化物件中萃取出定量的拓撲描述符。這使得拓撲損失函數的定義成為可能，而拓撲損失函數斷言給定物件展現出某種拓撲性質的程度。這些損失接著可用於透過梯度下降例程執行拓撲最佳化。雖然在理論上站得住腳，但拓撲最佳化面臨一個重要的挑戰：梯度往往極度稀疏，換句話說，損失函數通常僅取決於輸入物件的極少數座標，在實務上導致最佳化架構的進度極慢。專注於點雲拓撲最佳化的核心案例，我們在這項工作中提出使用同胚插值來克服這個限制，將稀疏梯度轉換為定義在整個空間上的平滑向量場，並具有可量化的 Lipschitz 常數。特別是，我們展示我們的做法與 TDA 中例行使用的子抽樣技術有效結合，因為從子樣本中計算出的梯度所衍生的同胚可用於更新完整輸入物件的座標，讓我們得以在空前規模上對點雲執行拓撲最佳化。最後，我們也展示我們的做法與黑箱自動編碼器 (AE) 正則化的關聯性，我們在其中旨在對與固定、預先訓練的黑箱 AE 模型相關聯的潛在空間施加拓撲先驗，並展示學習同胚流可以執行一次，然後以線性時間重新套用於新資料（而傳統的拓撲最佳化必須從頭開始重新執行）。此外，逆轉流讓我們能夠透過直接抽樣拓撲最佳化的潛在空間來產生資料，進而提升模型的可解釋性。</paragraph>

##### **Enhancing Security and Privacy in Federated Learning using Update Digests and Voting-Based Defense**
2405.18802v1 by Wenjie Li, Kai Fan, Jingyuan Zhang, Hui Li, Wei Yang Bryan Lim, Qiang Yang

Federated Learning (FL) is a promising privacy-preserving machine learning
paradigm that allows data owners to collaboratively train models while keeping
their data localized. Despite its potential, FL faces challenges related to the
trustworthiness of both clients and servers, especially in the presence of
curious or malicious adversaries. In this paper, we introduce a novel framework
named \underline{\textbf{F}}ederated \underline{\textbf{L}}earning with
\underline{\textbf{U}}pdate \underline{\textbf{D}}igest (FLUD), which addresses
the critical issues of privacy preservation and resistance to Byzantine attacks
within distributed learning environments. FLUD utilizes an innovative approach,
the $\mathsf{LinfSample}$ method, allowing clients to compute the $l_{\infty}$
norm across sliding windows of updates as an update digest. This digest enables
the server to calculate a shared distance matrix, significantly reducing the
overhead associated with Secure Multi-Party Computation (SMPC) by three orders
of magnitude while effectively distinguishing between benign and malicious
updates. Additionally, FLUD integrates a privacy-preserving, voting-based
defense mechanism that employs optimized SMPC protocols to minimize
communication rounds. Our comprehensive experiments demonstrate FLUD's
effectiveness in countering Byzantine adversaries while incurring low
communication and runtime overhead. FLUD offers a scalable framework for secure
and reliable FL in distributed environments, facilitating its application in
scenarios requiring robust data management and security.

摘要：联邦學習 (FL) 是一種有前途的隱私保護機器學習範例，它允許資料擁有者在保留資料本機化的同時，共同訓練模型。儘管有其潛力，FL 面臨與用戶端和伺服器可信度相關的挑戰，特別是在存在好奇或惡意攻擊者的情況下。在本文中，我們介紹了一個名為\underline{\textbf{F}}ederated \underline{\textbf{L}}earning with \underline{\textbf{U}}pdate \underline{\textbf{D}}igest (FLUD) 的新框架，它解決了在分散式學習環境中隱私保護和對抗拜占庭攻擊的關鍵問題。FLUD 利用了一種創新的方法，即 $\mathsf{LinfSample}$ 方法，允許用戶端計算更新滑動視窗上的 $l_{\infty}$ 範數作為更新摘要。此摘要使伺服器能夠計算共享距離矩陣，將安全多方計算 (SMPC) 相關的開銷有效減少了三個數量級，同時有效區分良性和惡意更新。此外，FLUD 整合了一個基於隱私保護的投票式防禦機制，該機制採用最佳化的 SMPC 協定來最小化通訊回合。我們的綜合實驗證明了 FLUD 在對抗拜占庭攻擊者時的有效性，同時產生低通訊和執行時間開銷。FLUD 為分散式環境中的安全且可靠的 FL 提供了一個可擴充的框架，促進其在需要強健資料管理和安全性的場景中的應用。

##### **Quantitative Certification of Bias in Large Language Models**
2405.18780v1 by Isha Chaudhary, Qian Hu, Manoj Kumar, Morteza Ziyadi, Rahul Gupta, Gagandeep Singh

Large Language Models (LLMs) can produce responses that exhibit social biases
and support stereotypes. However, conventional benchmarking is insufficient to
thoroughly evaluate LLM bias, as it can not scale to large sets of prompts and
provides no guarantees. Therefore, we propose a novel certification framework
QuaCer-B (Quantitative Certification of Bias) that provides formal guarantees
on obtaining unbiased responses from target LLMs under large sets of prompts. A
certificate consists of high-confidence bounds on the probability of obtaining
biased responses from the LLM for any set of prompts containing sensitive
attributes, sampled from a distribution. We illustrate the bias certification
in LLMs for prompts with various prefixes drawn from given distributions. We
consider distributions of random token sequences, mixtures of manual
jailbreaks, and jailbreaks in the LLM's embedding space to certify its bias. We
certify popular LLMs with QuaCer-B and present novel insights into their
biases.

摘要：大型語言模型 (LLM) 可以產生表現出社會偏見和支持刻板印象的回應。然而，傳統的基準測試不足以徹底評估 LLM 偏見，因為它無法擴展到大量的提示，而且無法提供保證。因此，我們提出了一個新的認證框架 QuaCer-B（偏見的定量認證），它提供了在大量提示下從目標 LLM 獲得無偏見回應的正式保證。證書包含從分佈中抽取的包含敏感屬性的任何一組提示，從 LLM 獲得偏見回應的機率的高置信度界限。我們說明了 LLM 在具有從給定分佈中抽取的各種前綴的提示中的偏見認證。我們考慮隨機令牌序列的分佈、手動越獄的混合以及 LLM 嵌入空間中的越獄來驗證其偏見。我們使用 QuaCer-B 認證流行的 LLM，並提出對其偏見的新見解。

##### **LMO-DP: Optimizing the Randomization Mechanism for Differentially Private Fine-Tuning (Large) Language Models**
2405.18776v1 by Qin Yang, Meisam Mohammad, Han Wang, Ali Payani, Ashish Kundu, Kai Shu, Yan Yan, Yuan Hong

Differentially Private Stochastic Gradient Descent (DP-SGD) and its variants
have been proposed to ensure rigorous privacy for fine-tuning large-scale
pre-trained language models. However, they rely heavily on the Gaussian
mechanism, which may overly perturb the gradients and degrade the accuracy,
especially in stronger privacy regimes (e.g., the privacy budget $\epsilon <
3$). To address such limitations, we propose a novel Language Model-based
Optimal Differential Privacy (LMO-DP) mechanism, which takes the first step to
enable the tight composition of accurately fine-tuning (large) language models
with a sub-optimal DP mechanism, even in strong privacy regimes (e.g., $0.1\leq
\epsilon<3$). Furthermore, we propose a novel offline optimal noise search
method to efficiently derive the sub-optimal DP that significantly reduces the
noise magnitude. For instance, fine-tuning RoBERTa-large (with 300M parameters)
on the SST-2 dataset can achieve an accuracy of 92.20% (given $\epsilon=0.3$,
$\delta=10^{-10}$) by drastically outperforming the Gaussian mechanism (e.g.,
$\sim 50\%$ for small $\epsilon$ and $\delta$). We also draw similar findings
on the text generation tasks on GPT-2. Finally, to our best knowledge, LMO-DP
is also the first solution to accurately fine-tune Llama-2 with strong
differential privacy guarantees. The code will be released soon and available
upon request.

摘要：差異化私人隨機梯度下降 (DP-SGD) 及其變體已被提出，以確保對大型預訓練語言模型進行微調的嚴格隱私。然而，它們嚴重依賴於高斯機制，這可能會過度擾動梯度並降低準確性，特別是在更強的隱私制度中（例如，隱私預算 $\epsilon < 3$）。為了解決這些限制，我們提出了一種新穎的基於語言模型的最佳差異隱私 (LMO-DP) 機制，它邁出了第一步，即使在強隱私制度（例如，$0.1\leq \epsilon<3$）下，也能夠對（大型）語言模型進行準確微調的嚴密組合。此外，我們提出了一種新穎的離線最佳雜訊搜尋方法，以有效地推導出顯著降低雜訊幅度的次最佳 DP。例如，在 SST-2 資料集上對 RoBERTa-large（具有 300M 參數）進行微調，可以達到 92.20% 的準確度（給定 $\epsilon=0.3$，$\delta=10^{-10}$），大幅優於高斯機制（例如，對於較小的 $\epsilon$ 和 $\delta$，約為 50%）。我們還在 GPT-2 上的文本生成任務中得出了類似的發現。最後，據我們所知，LMO-DP 也是第一個準確微調 Llama-2 的解決方案，並具有強大的差異隱私保證。該程式碼將很快發布，並可應要求提供。

##### **Leveraging Many-To-Many Relationships for Defending Against Visual-Language Adversarial Attacks**
2405.18770v1 by Futa Waseda, Antonio Tejero-de-Pablos

Recent studies have revealed that vision-language (VL) models are vulnerable
to adversarial attacks for image-text retrieval (ITR). However, existing
defense strategies for VL models primarily focus on zero-shot image
classification, which do not consider the simultaneous manipulation of image
and text, as well as the inherent many-to-many (N:N) nature of ITR, where a
single image can be described in numerous ways, and vice versa. To this end,
this paper studies defense strategies against adversarial attacks on VL models
for ITR for the first time. Particularly, we focus on how to leverage the N:N
relationship in ITR to enhance adversarial robustness. We found that, although
adversarial training easily overfits to specific one-to-one (1:1) image-text
pairs in the train data, diverse augmentation techniques to create one-to-many
(1:N) / many-to-one (N:1) image-text pairs can significantly improve
adversarial robustness in VL models. Additionally, we show that the alignment
of the augmented image-text pairs is crucial for the effectiveness of the
defense strategy, and that inappropriate augmentations can even degrade the
model's performance. Based on these findings, we propose a novel defense
strategy that leverages the N:N relationship in ITR, which effectively
generates diverse yet highly-aligned N:N pairs using basic augmentations and
generative model-based augmentations. This work provides a novel perspective on
defending against adversarial attacks in VL tasks and opens up new research
directions for future work.

摘要：<paragraph>最近的研究表明，视觉语言 (VL) 模型容易受到图像文本检索 (ITR) 的对抗性攻击。然而，现有的 VL 模型防御策略主要集中于零样本图像分类，这并未考虑图像和文本的同时操纵，以及 ITR 固有的多对多 (N:N) 特性，其中一张图像可以用多种方式描述，反之亦然。为此，本文首次研究了针对 ITR 上 VL 模型对抗性攻击的防御策略。特别是，我们专注于如何利用 ITR 中的 N:N 关系来增强对抗鲁棒性。我们发现，尽管对抗训练很容易过度拟合训练数据中的特定一对一 (1:1) 图像文本对，但创建一对多 (1:N) / 多对一 (N:1) 图像文本对的多样化增强技术可以显着提高 VL 模型的对抗鲁棒性。此外，我们表明，增强图像文本对的排列对于防御策略的有效性至关重要，并且不适当的增强甚至会降低模型的性能。基于这些发现，我们提出了一种利用 ITR 中 N:N 关系的新型防御策略，该策略有效地使用基本增强和基于生成模型的增强生成多样化但高度对齐的 N:N 对。这项工作为防御 VL 任务中的对抗性攻击提供了新视角，并为未来的工作开辟了新的研究方向。</paragraph>

##### **Inpaint Biases: A Pathway to Accurate and Unbiased Image Generation**
2405.18762v2 by Jiyoon Myung, Jihyeon Park

This paper examines the limitations of advanced text-to-image models in
accurately rendering unconventional concepts which are scarcely represented or
absent in their training datasets. We identify how these limitations not only
confine the creative potential of these models but also pose risks of
reinforcing stereotypes. To address these challenges, we introduce the Inpaint
Biases framework, which employs user-defined masks and inpainting techniques to
enhance the accuracy of image generation, particularly for novel or
inaccurately rendered objects. Through experimental validation, we demonstrate
how this framework significantly improves the fidelity of generated images to
the user's intent, thereby expanding the models' creative capabilities and
mitigating the risk of perpetuating biases. Our study contributes to the
advancement of text-to-image models as unbiased, versatile tools for creative
expression.

摘要：本文探討進階文字轉圖片模型在精確呈現訓練資料集鮮少呈現或不存在的非傳統概念時所面臨的限制。我們找出這些限制不僅侷限了這些模型的創意潛力，也可能強化刻板印象。為了應對這些挑戰，我們引進 Inpaint Biases 框架，它採用使用者定義的遮罩和補繪技術，以提升圖片生成的精確度，特別是針對新穎或呈現不準確的物件。透過實驗驗證，我們展示了這個框架如何大幅提升生成圖片對使用者意圖的忠實度，進而擴展模型的創意能力，並減輕延續偏見的風險。我們的研究有助於推動文字轉圖片模型成為無偏見、多功能的創意表達工具。

##### **Learning to Continually Learn with the Bayesian Principle**
2405.18758v1 by Soochan Lee, Hyeonseong Jeon, Jaehyeon Son, Gunhee Kim

In the present era of deep learning, continual learning research is mainly
focused on mitigating forgetting when training a neural network with stochastic
gradient descent on a non-stationary stream of data. On the other hand, in the
more classical literature of statistical machine learning, many models have
sequential Bayesian update rules that yield the same learning outcome as the
batch training, i.e., they are completely immune to catastrophic forgetting.
However, they are often overly simple to model complex real-world data. In this
work, we adopt the meta-learning paradigm to combine the strong
representational power of neural networks and simple statistical models'
robustness to forgetting. In our novel meta-continual learning framework,
continual learning takes place only in statistical models via ideal sequential
Bayesian update rules, while neural networks are meta-learned to bridge the raw
data and the statistical models. Since the neural networks remain fixed during
continual learning, they are protected from catastrophic forgetting. This
approach not only achieves significantly improved performance but also exhibits
excellent scalability. Since our approach is domain-agnostic and
model-agnostic, it can be applied to a wide range of problems and easily
integrated with existing model architectures.

摘要：在深度學習的當代，持續學習的研究主要集中在減輕遺忘，當使用隨機梯度下降方法在非穩態資料串流上訓練神經網路時。另一方面，在更經典的統計機器學習文獻中，許多模型具有循序貝氏更新規則，可產生與批次訓練相同的學習結果，即它們完全不受災難性遺忘的影響。然而，它們通常過於簡單，無法模擬複雜的真實世界資料。在這項工作中，我們採用元學習範例來結合神經網路的強大表示能力和簡單統計模型對遺忘的穩健性。在我們新穎的元持續學習架構中，持續學習僅透過理想的循序貝氏更新規則在統計模型中進行，而神經網路則透過元學習來橋接原始資料和統計模型。由於神經網路在持續學習期間保持固定，因此它們受到保護，不會發生災難性遺忘。這種方法不僅顯著提升了效能，還展現出優異的可擴充性。由於我們的方法與領域無關且與模型無關，因此可以應用於廣泛的問題，並輕鬆與現有的模型架構整合。

##### **Provable Contrastive Continual Learning**
2405.18756v1 by Yichen Wen, Zhiquan Tan, Kaipeng Zheng, Chuanlong Xie, Weiran Huang

Continual learning requires learning incremental tasks with dynamic data
distributions. So far, it has been observed that employing a combination of
contrastive loss and distillation loss for training in continual learning
yields strong performance. To the best of our knowledge, however, this
contrastive continual learning framework lacks convincing theoretical
explanations. In this work, we fill this gap by establishing theoretical
performance guarantees, which reveal how the performance of the model is
bounded by training losses of previous tasks in the contrastive continual
learning framework. Our theoretical explanations further support the idea that
pre-training can benefit continual learning. Inspired by our theoretical
analysis of these guarantees, we propose a novel contrastive continual learning
algorithm called CILA, which uses adaptive distillation coefficients for
different tasks. These distillation coefficients are easily computed by the
ratio between average distillation losses and average contrastive losses from
previous tasks. Our method shows great improvement on standard benchmarks and
achieves new state-of-the-art performance.

摘要：持續學習需要學習具有動態資料分佈的增量任務。到目前為止，已經觀察到採用對比損失和蒸餾損失的組合來訓練持續學習會產生強大的效能。然而，就我們所知，這個對比持續學習架構缺乏令人信服的理論解釋。在這項工作中，我們透過建立理論效能保證來填補這個差距，揭示模型的效能如何受到對比持續學習架構中先前任務訓練損失的約束。我們的理論解釋進一步支持了預訓練可以使持續學習受益的想法。受到我們對這些保證的理論分析啟發，我們提出了一種名為 CILA 的新對比持續學習演算法，它使用自適應蒸餾係數來處理不同的任務。這些蒸餾係數很容易透過先前任務的平均蒸餾損失和平均對比損失之間的比率來計算。我們的模型在標準基準上顯示出極大的進步，並達到了新的最先進效能。

##### **On the Limits of Multi-modal Meta-Learning with Auxiliary Task Modulation Using Conditional Batch Normalization**
2405.18751v2 by Jordi Armengol-Estapé, Vincent Michalski, Ramnath Kumar, Pierre-Luc St-Charles, Doina Precup, Samira Ebrahimi Kahou

Few-shot learning aims to learn representations that can tackle novel tasks
given a small number of examples. Recent studies show that cross-modal learning
can improve representations for few-shot classification. More specifically,
language is a rich modality that can be used to guide visual learning. In this
work, we experiment with a multi-modal architecture for few-shot learning that
consists of three components: a classifier, an auxiliary network, and a bridge
network. While the classifier performs the main classification task, the
auxiliary network learns to predict language representations from the same
input, and the bridge network transforms high-level features of the auxiliary
network into modulation parameters for layers of the few-shot classifier using
conditional batch normalization. The bridge should encourage a form of
lightweight semantic alignment between language and vision which could be
useful for the classifier. However, after evaluating the proposed approach on
two popular few-shot classification benchmarks we find that a) the improvements
do not reproduce across benchmarks, and b) when they do, the improvements are
due to the additional compute and parameters introduced by the bridge network.
We contribute insights and recommendations for future work in multi-modal
meta-learning, especially when using language representations.

摘要：<paragraph>小样本学习旨在学习能够处理新任务的表征，而这些任务只有少量示例。最近的研究表明，跨模态学习可以改善小样本分类的表征。更具体地说，语言是一种可用于指导视觉学习的丰富模态。在这项工作中，我们尝试了一种用于小样本学习的多模态架构，该架构由三个组件组成：分类器、辅助网络和桥接网络。虽然分类器执行主要的分类任务，但辅助网络学习从同一输入预测语言表征，而桥接网络使用条件批归一化将辅助网络的高级特征转换为小样本分类器层级的调制参数。该桥接应鼓励语言和视觉之间的一种轻量级语义对齐形式，这可能对分类器有用。然而，在两个流行的小样本分类基准上评估所提出的方法后，我们发现 a) 改进无法在基准之间复制，并且 b) 当它们这样做时，改进是由于桥接网络引入的额外计算和参数。我们为多模态元学习中的未来工作提供见解和建议，尤其是在使用语言表征时。</paragraph>

##### **Genshin: General Shield for Natural Language Processing with Large Language Models**
2405.18741v1 by Xiao Peng, Tao Liu, Ying Wang

Large language models (LLMs) like ChatGPT, Gemini, or LLaMA have been
trending recently, demonstrating considerable advancement and generalizability
power in countless domains. However, LLMs create an even bigger black box
exacerbating opacity, with interpretability limited to few approaches. The
uncertainty and opacity embedded in LLMs' nature restrict their application in
high-stakes domains like financial fraud, phishing, etc. Current approaches
mainly rely on traditional textual classification with posterior interpretable
algorithms, suffering from attackers who may create versatile adversarial
samples to break the system's defense, forcing users to make trade-offs between
efficiency and robustness. To address this issue, we propose a novel cascading
framework called Genshin (General Shield for Natural Language Processing with
Large Language Models), utilizing LLMs as defensive one-time plug-ins. Unlike
most applications of LLMs that try to transform text into something new or
structural, Genshin uses LLMs to recover text to its original state. Genshin
aims to combine the generalizability of the LLM, the discrimination of the
median model, and the interpretability of the simple model. Our experiments on
the task of sentimental analysis and spam detection have shown fatal flaws of
the current median models and exhilarating results on LLMs' recovery ability,
demonstrating that Genshin is both effective and efficient. In our ablation
study, we unearth several intriguing observations. Utilizing the LLM defender,
a tool derived from the 4th paradigm, we have reproduced BERT's 15% optimal
mask rate results in the 3rd paradigm of NLP. Additionally, when employing the
LLM as a potential adversarial tool, attackers are capable of executing
effective attacks that are nearly semantically lossless.

摘要：大型語言模型（LLM），例如 ChatGPT、Gemini 或 LLaMA，最近一直處於趨勢中，在無數領域展示了顯著的進步和泛化能力。然而，LLM 創造了一個更大的黑盒子，加劇了不透明性，可解釋性僅限於少數方法。LLM 本質中嵌入的不確定性和不透明性限制了它們在金融詐欺、網路釣魚等高風險領域的應用。目前的做法主要依賴於傳統文本分類和後驗可解釋演算法，遭受攻擊者可能創造出多功能對抗樣本以突破系統防禦的困擾，迫使用戶在效率和穩健性之間做出取捨。為了解決這個問題，我們提出了一個名為 Genshin（使用大型語言模型的自然語言處理通用防護罩）的新級聯框架，利用 LLM 作為一次性的防禦性外掛程式。與大多數嘗試將文字轉換成新事物或結構的 LLM 應用不同，Genshin 使用 LLM 將文字還原到其原始狀態。Genshin 旨在結合 LLM 的泛化能力、中位數模型的判別能力和簡單模型的可解釋性。我們在情感分析和垃圾郵件偵測任務上的實驗顯示了當前中位數模型的致命缺陷和 LLM 復原能力的振奮人心的結果，證明了 Genshin 既有效又高效。在我們的消融研究中，我們發現了幾個有趣的觀察結果。利用源自第四範式的工具 LLM 防禦者，我們在 NLP 的第三範式中複製了 BERT 的 15% 最佳遮罩率結果。此外，當將 LLM 用作潛在的對抗工具時，攻擊者能夠執行幾乎沒有語義損失的有效攻擊。

##### **Reverse Image Retrieval Cues Parametric Memory in Multimodal LLMs**
2405.18740v1 by Jialiang Xu, Michael Moor, Jure Leskovec

Despite impressive advances in recent multimodal large language models
(MLLMs), state-of-the-art models such as from the GPT-4 suite still struggle
with knowledge-intensive tasks. To address this, we consider Reverse Image
Retrieval (RIR) augmented generation, a simple yet effective strategy to
augment MLLMs with web-scale reverse image search results. RIR robustly
improves knowledge-intensive visual question answering (VQA) of GPT-4V by
37-43%, GPT-4 Turbo by 25-27%, and GPT-4o by 18-20% in terms of open-ended VQA
evaluation metrics. To our surprise, we discover that RIR helps the model to
better access its own world knowledge. Concretely, our experiments suggest that
RIR augmentation helps by providing further visual and textual cues without
necessarily containing the direct answer to a query. In addition, we elucidate
cases in which RIR can hurt performance and conduct a human evaluation.
Finally, we find that the overall advantage of using RIR makes it difficult for
an agent that can choose to use RIR to perform better than an approach where
RIR is the default setting.

摘要：儘管最近的多模態大型語言模型 (MLLM) 取得令人印象深刻的進展，但來自 GPT-4 套件等最先進的模型在知識密集型任務中仍面臨挑戰。為了解決這個問題，我們考慮反向圖片檢索 (RIR) 增強生成，這是一種簡單卻有效的策略，可以透過網路規模的反向圖片搜尋結果來擴充 MLLM。RIR 穩健地改善了 GPT-4V 的知識密集型視覺問答 (VQA) 37-43%、GPT-4 Turbo 25-27% 和 GPT-4o 18-20%，就開放式 VQA 評估指標而言。令我們驚訝的是，我們發現 RIR 幫助模型更佳地存取其自身的世界知識。具體來說，我們的實驗表明，RIR 擴充透過提供進一步的視覺和文字提示來提供幫助，而並非一定要包含對查詢的直接答案。此外，我們闡明了 RIR 可能損害效能的情況，並進行了人類評估。最後，我們發現使用 RIR 的整體優勢讓代理難以選擇使用 RIR 來表現得比 RIR 為預設設定的方法更好。

##### **Gemini & Physical World: Large Language Models Can Estimate the Intensity of Earthquake Shaking from Multi-Modal Social Media Posts**
2405.18732v1 by S. Mostafa Mousavi, Marc Stogaitis, Tajinder Gadh, Richard M Allen, Alexei Barski, Robert Bosch, Patrick Robertson, Nivetha Thiruverahan, Youngmin Cho

This paper presents a novel approach for estimating the ground shaking
intensity using social media data and CCTV footage. Employing the Gemini Pro
(Reid et al. 2024) model, a multi-modal language model, we demonstrate the
ability to extract relevant information from unstructured data utilizing
generative AI and natural language processing. The model output, in the form of
Modified Mercalli Intensity (MMI) values, align well with independent
observational data. Furthermore, our results suggest that beyond its advanced
visual and auditory understanding abilities, Gemini appears to utilize
additional sources of knowledge, including a simplified understanding of the
general relationship between earthquake magnitude, distance, and MMI intensity,
which it presumably acquired during its training, in its reasoning and
decision-making processes. These findings raise intriguing questions about the
extent of Gemini's general understanding of the physical world and its
phenomena. The ability of Gemini to generate results consistent with
established scientific knowledge highlights the potential of LLMs like Gemini
in augmenting our understanding of complex physical phenomena such as
earthquakes. More specifically, the results of this study highlight the
potential of LLMs like Gemini to revolutionize citizen seismology by enabling
rapid, effective, and flexible analysis of crowdsourced data from eyewitness
accounts for assessing earthquake impact and providing crisis situational
awareness. This approach holds great promise for improving early warning
systems, disaster response, and overall resilience in earthquake-prone regions.
This study provides a significant step toward harnessing the power of social
media and AI for earthquake disaster mitigation.

摘要：<paragraph>這篇論文提出一個新穎的方法，使用社群媒體資料和監視器畫面來評估地面震動強度。採用多模態語言模型 Gemini Pro（Reid et al. 2024），我們展示了從非結構化資料中萃取相關資訊的能力，利用生成式 AI 和自然語言處理。模型的輸出，以修正麥卡利強度（MMI）值的形式，與獨立的觀測資料吻合良好。此外，我們的結果顯示，除了進階的視覺和聽覺理解能力之外，Gemini 似乎利用了其他知識來源，包括在訓練過程中獲得的，對地震震級、距離和 MMI 強度之間一般關係的簡化理解，在其推理和決策過程中。這些發現提出了關於 Gemini 對物理世界及其現象的廣泛理解程度的有趣問題。Gemini 產生與已建立的科學知識一致的結果的能力，突顯了像 Gemini 這樣的 LLM 在擴展我們對複雜物理現象（例如地震）的理解方面的潛力。更具體地說，這項研究的結果突顯了像 Gemini 這樣的 LLM 透過讓群眾外包資料的目擊者報告得以快速、有效且彈性地分析，進而革新公民地震學的潛力，用於評估地震影響並提供危機狀況意識。這種方法對於改善地震多發地區的預警系統、災害應變和整體復原力具有很大的前景。這項研究為利用社群媒體和 AI 的力量來減輕地震災害邁出了一大步。</paragraph>

##### **VBIM-Net: Variational Born Iterative Network for Inverse Scattering Problems**
2405.18731v1 by Ziqing Xing, Zhaoyang Zhang, Zirui Chen, Yusong Wang, Haoran Ma, Zhun Wei, Gang Bao

Recently, studies have shown the potential of integrating field-type
iterative methods with deep learning (DL) techniques in solving inverse
scattering problems (ISPs). In this article, we propose a novel Variational
Born Iterative Network, namely, VBIM-Net, to solve the full-wave ISPs with
significantly improved flexibility and inversion quality. The proposed VBIM-Net
emulates the alternating updates of the total electric field and the contrast
in the variational Born iterative method (VBIM) by multiple layers of
subnetworks. We embed the calculation of the contrast variation into each of
the subnetworks, converting the scattered field residual into an approximate
contrast variation and then enhancing it by a U-Net, thus avoiding the
requirement of matched measurement dimension and grid resolution as in existing
approaches. The total field and contrast of each layer's output is supervised
in the loss function of VBIM-Net, which guarantees the physical
interpretability of variables of the subnetworks. In addition, we design a
training scheme with extra noise to enhance the model's stability. Extensive
numerical results on synthetic and experimental data both verify the inversion
quality, generalization ability, and robustness of the proposed VBIM-Net. This
work may provide some new inspiration for the design of efficient field-type DL
schemes.

摘要：<paragraph>最近的研究表明，將場類型迭代方法與深度學習 (DL) 技術整合，在解決逆散射問題 (ISP) 方面具有潛力。在本文中，我們提出了一種新穎的變分 Born 迭代網路，即 VBIM-Net，以解決全波 ISP，大幅提升靈活性與反演品質。所提出的 VBIM-Net 模擬變分 Born 迭代方法 (VBIM) 中總電場與對比度的交替更新，透過多層子網路。我們將對比度變化的計算嵌入每個子網路中，將散射場殘差轉換為近似的對比度變化，然後透過 U-Net 強化，因此避免了現有方法中匹配量測維度與網格解析度的需求。在 VBIM-Net 的損失函數中監督每一層輸出的總場與對比度，這保證了子網路變數的物理可解釋性。此外，我們設計了一個訓練方案，其中包含額外的雜訊，以增強模型的穩定性。在合成資料與實驗資料上的廣泛數值結果驗證了所提出的 VBIM-Net 的反演品質、泛化能力與穩健性。這項工作可能為高效場類型 DL 架構的設計提供一些新的靈感。</paragraph>

##### **Preferred-Action-Optimized Diffusion Policies for Offline Reinforcement Learning**
2405.18729v1 by Tianle Zhang, Jiayi Guan, Lin Zhao, Yihang Li, Dongjiang Li, Zecui Zeng, Lei Sun, Yue Chen, Xuelong Wei, Lusong Li, Xiaodong He

Offline reinforcement learning (RL) aims to learn optimal policies from
previously collected datasets. Recently, due to their powerful representational
capabilities, diffusion models have shown significant potential as policy
models for offline RL issues. However, previous offline RL algorithms based on
diffusion policies generally adopt weighted regression to improve the policy.
This approach optimizes the policy only using the collected actions and is
sensitive to Q-values, which limits the potential for further performance
enhancement. To this end, we propose a novel preferred-action-optimized
diffusion policy for offline RL. In particular, an expressive conditional
diffusion model is utilized to represent the diverse distribution of a behavior
policy. Meanwhile, based on the diffusion model, preferred actions within the
same behavior distribution are automatically generated through the critic
function. Moreover, an anti-noise preference optimization is designed to
achieve policy improvement by using the preferred actions, which can adapt to
noise-preferred actions for stable training. Extensive experiments demonstrate
that the proposed method provides competitive or superior performance compared
to previous state-of-the-art offline RL methods, particularly in sparse reward
tasks such as Kitchen and AntMaze. Additionally, we empirically prove the
effectiveness of anti-noise preference optimization.

摘要：離線強 reinforcement learning (RL) 旨在從先前收集的資料集學習最佳策略。最近，由於其強大的表徵能力，擴散模型已顯示出作為離線 RL 問題的策略模型的顯著潛力。然而，基於擴散策略的先前離線 RL 演算法通常採用加權回歸來改善策略。此方法僅使用收集的動作來最佳化策略，且對 Q 值很敏感，這限制了進一步效能提升的可能性。為此，我們提出了一種用於離線 RL 的新穎偏好動作最佳化擴散策略。特別是，利用表達式條件擴散模型來表示行為策略的多元分佈。同時，根據擴散模型，透過評論功能自動產生相同行為分佈中的偏好動作。此外，反噪聲偏好最佳化旨在透過使用偏好動作來實現策略改善，它可以適應穩定訓練的噪聲偏好動作。廣泛的實驗證明，與先前的最先進離線 RL 方法相比，所提出的方法提供了具有競爭力或優越的效能，特別是在稀疏獎勵任務中，例如 Kitchen 和 AntMaze。此外，我們憑經驗證明了反噪聲偏好最佳化的有效性。

##### **CtrlA: Adaptive Retrieval-Augmented Generation via Probe-Guided Control**
2405.18727v1 by Huanshuo Liu, Hao Zhang, Zhijiang Guo, Kuicai Dong, Xiangyang Li, Yi Quan Lee, Cong Zhang, Yong Liu

Retrieval-augmented generation (RAG) has emerged as a promising solution for
mitigating hallucinations of large language models (LLMs) with retrieved
external knowledge. Adaptive RAG enhances this approach by dynamically
assessing the retrieval necessity, aiming to balance external and internal
knowledge usage. However, existing adaptive RAG methods primarily realize
retrieval on demand by relying on superficially verbalize-based or
probability-based feedback of LLMs, or directly fine-tuning LLMs via carefully
crafted datasets, resulting in unreliable retrieval necessity decisions, heavy
extra costs, and sub-optimal response generation. We present the first attempts
to delve into the internal states of LLMs to mitigate such issues by
introducing an effective probe-guided adaptive RAG framework, termed CtrlA.
Specifically, CtrlA employs an honesty probe to regulate the LLM's behavior by
manipulating its representations for increased honesty, and a confidence probe
to monitor the internal states of LLM and assess confidence levels, determining
the retrieval necessity during generation. Experiments show that CtrlA is
superior to existing adaptive RAG methods on a diverse set of tasks, the
honesty control can effectively make LLMs more honest and confidence monitoring
is proven to be a promising indicator of retrieval trigger. Our codes are
available at https://github.com/HSLiu-Initial/CtrlA.git.

摘要：檢索增強生成（RAG）已成為一種有前途的解決方案，可透過檢索的外部知識來減輕大型語言模型（LLM）的幻覺。自適應 RAG 透過動態評估檢索必要性來增強此方法，旨在平衡外部和內部知識的使用。然而，現有的自適應 RAG 方法主要透過依賴 LLM 的表面言語化或基於機率的回饋來依需求進行檢索，或透過精心製作的資料集直接微調 LLM，導致不可靠的檢索必要性決策、龐大的額外成本和次佳的回應產生。我們提出首次嘗試深入探討 LLM 的內部狀態，以透過引進稱為 CtrlA 的有效探針導引自適應 RAG 架構來減輕此類問題。具體來說，CtrlA 使用誠實探針透過調整 LLM 的表示來規範其行為，以提高誠實度，並使用信心探針來監控 LLM 的內部狀態和評估信心層級，進而決定生成期間的檢索必要性。實驗顯示，CtrlA 在各種任務上都優於現有的自適應 RAG 方法，誠實控制可以有效讓 LLM 更加誠實，而信心監控已被證明是檢索觸發的有前途指標。我們的程式碼可在 https://github.com/HSLiu-Initial/CtrlA.git 取得。

##### **Adapting Differential Molecular Representation with Hierarchical Prompts for Multi-label Property Prediction**
2405.18724v1 by Linjia Kang, Songhua Zhou, Shuyan Fang, Shichao Liu, Wen Zhang

Accurate prediction of molecular properties is critical in the field of drug
discovery. However, existing methods do not fully consider the fact that
molecules in the real world usually possess multiple property labels, and
complex high-order relationships may exist among these labels. Therefore,
molecular representation learning models should generate differential molecular
representations that consider multi-granularity correlation information among
tasks. To this end, our research introduces a Hierarchical Prompted Molecular
Representation Learning Framework (HiPM), which enhances the differential
expression of tasks in molecular representations through task-aware prompts,
and utilizes shared information among labels to mitigate negative transfer
between different tasks. HiPM primarily consists of two core components: the
Molecular Representation Encoder (MRE) and the Task-Aware Prompter (TAP). The
MRE employs a hierarchical message-passing network architecture to capture
molecular features at both the atomic and motif levels, while the TAP uses
agglomerative hierarchical clustering to build a prompt tree that reflects the
affinity and distinctiveness of tasks, enabling the model to effectively handle
the complexity of multi-label property predictions. Extensive experiments
demonstrate that HiPM achieves state-of-the-art performance across various
multi-label datasets, offering a new perspective on multi-label molecular
representation learning.

摘要：分子性質的準確預測在藥物發現領域至關重要。然而，現有方法並未充分考慮到現實世界中的分子通常具有多個屬性標籤，並且這些標籤之間可能存在複雜的高階關係。因此，分子表示學習模型應產生考慮任務之間多粒度關聯資訊的差異分子表示。為此，我們的研究引入了一個分層提示式分子表示學習架構 (HiPM)，它通過任務感知提示增強了分子表示中任務的差異表達，並利用標籤之間的共享資訊來減輕不同任務之間的負面轉移。HiPM 主要包含兩個核心組成部分：分子表示編碼器 (MRE) 和任務感知提示器 (TAP)。MRE 採用分層訊息傳遞網路架構來擷取原子和基序層級的分子特徵，而 TAP 使用凝聚式分層聚類來建立一個提示樹，反映任務的親和性和獨特性，使模型能夠有效地處理多標籤屬性預測的複雜性。廣泛的實驗表明，HiPM 在各種多標籤資料集上實現了最先進的效能，為多標籤分子表示學習提供了新的觀點。

##### **Conformal Depression Prediction**
2405.18723v1 by Yonghong Li, Shan Qu, Xiuzhuang Zhou

While existing depression recognition methods based on deep learning show
promise, their practical application is hindered by the lack of
trustworthiness, as these deep models are often deployed as \textit{black box}
models, leaving us uncertain about the confidence of the model predictions. For
high-risk clinical applications like depression recognition, uncertainty
quantification is essential in decision-making. In this paper, we introduce
conformal depression prediction (CDP), a depression recognition method with
uncertainty quantification based on conformal prediction (CP), giving valid
confidence intervals with theoretical coverage guarantees for the model
predictions. CDP is a plug-and-play module that requires neither model
retraining nor an assumption about the depression data distribution. As CDP
provides only an average performance guarantee across all inputs rather than
per-input performance guarantee, we propose CDP-ACC, an improved conformal
prediction with approximate conditional coverage. CDP-ACC firstly estimates the
prediction distribution through neighborhood relaxation, and then introduces a
conformal score function by constructing nested sequences, so as to provide
tighter prediction interval for each specific input. We empirically demonstrate
the application of uncertainty quantification in depression recognition, and
the effectiveness and superiority of CDP and CDP-ACC on the AVEC 2013 and AVEC
2014 datasets

摘要：儘管現有的基於深度學習的憂鬱症辨識方法顯示出前景，其實際應用卻受到可信度的不足所阻礙，因為這些深度模型經常被部署為「黑箱」模型，讓我們無法確定模型預測的置信度。對於憂鬱症辨識等高風險的臨床應用，不確定性量化在決策制定中至關重要。在本文中，我們介紹了共形憂鬱症預測 (CDP)，這是一種基於共形預測 (CP) 的憂鬱症辨識方法，具有不確定性量化，可提供模型預測的有效置信區間，並保證理論涵蓋率。CDP 是一個即插即用的模組，既不需要重新訓練模型，也不需要假設憂鬱症資料分佈。由於 CDP 僅提供所有輸入的平均效能保證，而不是每個輸入的效能保證，因此我們提出了 CDP-ACC，這是一種具有近似條件涵蓋率的改良共形預測。CDP-ACC 首先透過鄰域放鬆來估計預測分佈，然後透過建構巢狀序列來引入共形評分函數，以便為每個特定輸入提供更嚴格的預測區間。我們憑經驗證明了不確定性量化在憂鬱症辨識中的應用，以及 CDP 和 CDP-ACC 在 AVEC 2013 和 AVEC 2014 資料集上的有效性和優越性

##### **Correctable Landmark Discovery via Large Models for Vision-Language Navigation**
2405.18721v1 by Bingqian Lin, Yunshuang Nie, Ziming Wei, Yi Zhu, Hang Xu, Shikui Ma, Jianzhuang Liu, Xiaodan Liang

Vision-Language Navigation (VLN) requires the agent to follow language
instructions to reach a target position. A key factor for successful navigation
is to align the landmarks implied in the instruction with diverse visual
observations. However, previous VLN agents fail to perform accurate modality
alignment especially in unexplored scenes, since they learn from limited
navigation data and lack sufficient open-world alignment knowledge. In this
work, we propose a new VLN paradigm, called COrrectable LaNdmark DiScOvery via
Large ModEls (CONSOLE). In CONSOLE, we cast VLN as an open-world sequential
landmark discovery problem, by introducing a novel correctable landmark
discovery scheme based on two large models ChatGPT and CLIP. Specifically, we
use ChatGPT to provide rich open-world landmark cooccurrence commonsense, and
conduct CLIP-driven landmark discovery based on these commonsense priors. To
mitigate the noise in the priors due to the lack of visual constraints, we
introduce a learnable cooccurrence scoring module, which corrects the
importance of each cooccurrence according to actual observations for accurate
landmark discovery. We further design an observation enhancement strategy for
an elegant combination of our framework with different VLN agents, where we
utilize the corrected landmark features to obtain enhanced observation features
for action decision. Extensive experimental results on multiple popular VLN
benchmarks (R2R, REVERIE, R4R, RxR) show the significant superiority of CONSOLE
over strong baselines. Especially, our CONSOLE establishes the new
state-of-the-art results on R2R and R4R in unseen scenarios. Code is available
at https://github.com/expectorlin/CONSOLE.

摘要：<paragraph>視覺語言導航 (VLN) 要求代理遵循語言指示以到達目標位置。成功導航的關鍵因素是將指令中暗示的地標與不同的視覺觀察對齊。然而，先前的 VLN 代理無法執行準確的模態對齊，特別是在未探索場景中，因為它們從有限的導航數據中學習，並且缺乏足夠的開放世界對齊知識。在這項工作中，我們提出了一個新的 VLN 典範，稱為透過大型模型進行可校正地標發現 (CONSOLE)。在 CONSOLE 中，我們將 VLN 視為一個開放世界的順序地標發現問題，方法是引入一種基於兩個大型模型 ChatGPT 和 CLIP 的新可校正地標發現機制。具體來說，我們使用 ChatGPT 來提供豐富的開放世界地標共現常識，並根據這些常識先驗進行 CLIP 驅動的地標發現。為了減輕先驗中因缺乏視覺約束而產生的雜訊，我們引入了一個可學習的共現評分模組，該模組根據實際觀察校正每個共現的重要性，以進行準確的地標發現。我們進一步設計了一個觀察增強策略，以優雅地將我們的框架與不同的 VLN 代理結合起來，在其中我們利用校正的地標特徵來獲取增強的觀察特徵以進行動作決策。在多個流行的 VLN 基準 (R2R、REVERIE、R4R、RxR) 上進行的廣泛實驗結果顯示，CONSOLE 優於強大的基線。特別是，我們的 CONSOLE 在未見場景中建立了 R2R 和 R4R 的新技術水準。程式碼可在 https://github.com/expectorlin/CONSOLE 獲得。</paragraph>

##### **Contextual Position Encoding: Learning to Count What's Important**
2405.18719v1 by Olga Golovneva, Tianlu Wang, Jason Weston, Sainbayar Sukhbaatar

The attention mechanism is a critical component of Large Language Models
(LLMs) that allows tokens in a sequence to interact with each other, but is
order-invariant. Incorporating position encoding (PE) makes it possible to
address by position, such as attending to the i-th token. However, current PE
methods use token counts to derive position, and thus cannot generalize to
higher levels of abstraction, such as attending to the i-th sentence. In this
paper, we propose a new position encoding method, Contextual Position Encoding
(CoPE), that allows positions to be conditioned on context by incrementing
position only on certain tokens determined by the model. This allows more
general position addressing such as attending to the $i$-th particular word,
noun, or sentence. We show that CoPE can solve the selective copy, counting and
Flip-Flop tasks where popular position embeddings fail, and improves perplexity
on language modeling and coding tasks.

摘要：注意力机制是大型语言模型 (LLM) 中的关键组件，它允许序列中的标记相互交互，但与顺序无关。合并位置编码 (PE) 可以按位置进行寻址，例如关注第 i 个标记。但是，当前的 PE 方法使用标记计数来推导出位置，因此无法概括到更高的抽象级别，例如关注第 i 个句子。在本文中，我们提出了一种新的位置编码方法，即上下文位置编码 (CoPE)，它允许位置通过仅在模型确定的某些标记上增加位置来根据上下文进行调节。这允许更通用的位置寻址，例如关注第 i 个特定单词、名词或句子。我们表明，CoPE 可以解决选择性复制、计数和触发器任务，而流行的位置嵌入会失败，并且可以提高语言建模和编码任务的困惑度。

