{"2408.11587": {"publish_time": "2024-08-21", "title": "Large Language Models are Good Attackers: Efficient and Stealthy Textual Backdoor Attacks", "paper_summary": "With the burgeoning advancements in the field of natural language processing\n(NLP), the demand for training data has increased significantly. To save costs,\nit has become common for users and businesses to outsource the labor-intensive\ntask of data collection to third-party entities. Unfortunately, recent research\nhas unveiled the inherent risk associated with this practice, particularly in\nexposing NLP systems to potential backdoor attacks. Specifically, these attacks\nenable malicious control over the behavior of a trained model by poisoning a\nsmall portion of the training data. Unlike backdoor attacks in computer vision,\ntextual backdoor attacks impose stringent requirements for attack stealthiness.\nHowever, existing attack methods meet significant trade-off between\neffectiveness and stealthiness, largely due to the high information entropy\ninherent in textual data. In this paper, we introduce the Efficient and\nStealthy Textual backdoor attack method, EST-Bad, leveraging Large Language\nModels (LLMs). Our EST-Bad encompasses three core strategies: optimizing the\ninherent flaw of models as the trigger, stealthily injecting triggers with\nLLMs, and meticulously selecting the most impactful samples for backdoor\ninjection. Through the integration of these techniques, EST-Bad demonstrates an\nefficient achievement of competitive attack performance while maintaining\nsuperior stealthiness compared to prior methods across various text classifier\ndatasets.", "paper_summary_zh": "\u96a8\u8457\u81ea\u7136\u8a9e\u8a00\u8655\u7406 (NLP) \u9818\u57df\u7684\u84ec\u52c3\u767c\u5c55\uff0c\u5c0d\u8a13\u7df4\u8cc7\u6599\u7684\u9700\u6c42\u5927\u5e45\u589e\u52a0\u3002\u70ba\u4e86\u7bc0\u7701\u6210\u672c\uff0c\u4f7f\u7528\u8005\u548c\u4f01\u696d\u5df2\u666e\u904d\u5c07\u8cc7\u6599\u6536\u96c6\u7684\u52de\u529b\u5bc6\u96c6\u578b\u4efb\u52d9\u5916\u5305\u7d66\u7b2c\u4e09\u65b9\u5be6\u9ad4\u3002\u4e0d\u5e78\u7684\u662f\uff0c\u6700\u8fd1\u7684\u7814\u7a76\u63ed\u9732\u4e86\u9019\u7a2e\u505a\u6cd5\u56fa\u6709\u7684\u98a8\u96aa\uff0c\u7279\u5225\u662f\u5728\u5c07 NLP \u7cfb\u7d71\u66b4\u9732\u65bc\u6f5b\u5728\u5f8c\u9580\u653b\u64ca\u6642\u3002\u5177\u9ad4\u4f86\u8aaa\uff0c\u9019\u4e9b\u653b\u64ca\u900f\u904e\u6bd2\u5316\u8a13\u7df4\u8cc7\u6599\u7684\u4e00\u5c0f\u90e8\u5206\u4f86\u5be6\u73fe\u5c0d\u8a13\u7df4\u6a21\u578b\u884c\u70ba\u7684\u60e1\u610f\u63a7\u5236\u3002\u8207\u96fb\u8166\u8996\u89ba\u4e2d\u7684\u5f8c\u9580\u653b\u64ca\u4e0d\u540c\uff0c\u6587\u5b57\u5f8c\u9580\u653b\u64ca\u5c0d\u653b\u64ca\u96b1\u853d\u6027\u63d0\u51fa\u4e86\u56b4\u683c\u7684\u8981\u6c42\u3002\u7136\u800c\uff0c\u73fe\u6709\u7684\u653b\u64ca\u65b9\u6cd5\u5728\u6709\u6548\u6027\u8207\u96b1\u853d\u6027\u4e4b\u9593\u5b58\u5728\u986f\u8457\u7684\u6b0a\u8861\uff0c\u9019\u4e3b\u8981\u662f\u56e0\u70ba\u6587\u5b57\u8cc7\u6599\u4e2d\u56fa\u6709\u7684\u9ad8\u8cc7\u8a0a\u71b5\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u4ecb\u7d39\u4e86\u9ad8\u6548\u4e14\u96b1\u853d\u7684\u6587\u5b57\u5f8c\u9580\u653b\u64ca\u65b9\u6cd5 EST-Bad\uff0c\u5b83\u5229\u7528\u4e86\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM)\u3002\u6211\u5011\u7684 EST-Bad \u6db5\u84cb\u4e86\u4e09\u500b\u6838\u5fc3\u7b56\u7565\uff1a\u5c07\u6a21\u578b\u7684\u56fa\u6709\u7f3a\u9677\u6700\u4f73\u5316\u70ba\u89f8\u767c\u5668\u3001\u4f7f\u7528 LLM \u96b1\u853d\u5730\u6ce8\u5165\u89f8\u767c\u5668\uff0c\u4ee5\u53ca\u4ed4\u7d30\u9078\u64c7\u5c0d\u5f8c\u9580\u6ce8\u5165\u5f71\u97ff\u6700\u5927\u7684\u7bc4\u4f8b\u3002\u900f\u904e\u6574\u5408\u9019\u4e9b\u6280\u8853\uff0cEST-Bad \u5c55\u793a\u4e86\u5728\u8207\u5404\u7a2e\u6587\u5b57\u5206\u985e\u5668\u8cc7\u6599\u96c6\u76f8\u6bd4\u4e4b\u4e0b\uff0c\u5728\u7dad\u6301\u512a\u7570\u96b1\u853d\u6027\u7684\u540c\u6642\uff0c\u6709\u6548\u9054\u6210\u5177\u6709\u7af6\u722d\u529b\u7684\u653b\u64ca\u6548\u80fd\u3002", "author": "Ziqiang Li et.al.", "authors": "Ziqiang Li, Yueqi Zeng, Pengfei Xia, Lei Liu, Zhangjie Fu, Bin Li", "id": "2408.11587v1", "paper_url": "http://arxiv.org/abs/2408.11587v1", "repo": "null"}}