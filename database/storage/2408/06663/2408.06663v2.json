{"2408.06663": {"publish_time": "2024-08-13", "title": "Amuro & Char: Analyzing the Relationship between Pre-Training and Fine-Tuning of Large Language Models", "paper_summary": "The development of large language models leads to the formation of a\npre-train-then-align paradigm, in which the model is typically pre-trained on a\nlarge text corpus and undergoes a tuning stage to align the model with human\npreference or downstream tasks. In this work, we investigate the relationship\nbetween pre-training and fine-tuning by fine-tuning multiple intermediate\npre-trained model checkpoints. Our results on 18 datasets suggest that i)\ncontinual pre-training improves the model in a latent way that unveils after\nfine-tuning; ii) with extra fine-tuning, the datasets that the model does not\ndemonstrate capability gain much more than those that the model performs well\nduring the pre-training stage; iii) although model benefits significantly\nthrough supervised fine-tuning, it may forget previously known domain knowledge\nand the tasks that are not seen during fine-tuning; iv) the model resembles\nhigh sensitivity to evaluation prompts after supervised fine-tuning, but this\nsensitivity can be alleviated by more pre-training.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b\u7684\u767c\u5c55\u5c0e\u81f4\u5f62\u6210\u9810\u8a13\u7df4\u5f8c\u5c0d\u9f4a\u7684\u7bc4\u4f8b\uff0c\u5176\u4e2d\u6a21\u578b\u901a\u5e38\u5728\u5927\u578b\u6587\u672c\u8a9e\u6599\u5eab\u4e0a\u9032\u884c\u9810\u8a13\u7df4\uff0c\u4e26\u7d93\u6b77\u8abf\u6574\u968e\u6bb5\uff0c\u4ee5\u5c07\u6a21\u578b\u8207\u4eba\u985e\u504f\u597d\u6216\u4e0b\u6e38\u4efb\u52d9\u5c0d\u9f4a\u3002\u5728\u9019\u9805\u5de5\u4f5c\u4e2d\uff0c\u6211\u5011\u900f\u904e\u5fae\u8abf\u591a\u500b\u4e2d\u9593\u9810\u8a13\u7df4\u6a21\u578b\u6aa2\u67e5\u9ede\u4f86\u63a2\u8a0e\u9810\u8a13\u7df4\u548c\u5fae\u8abf\u4e4b\u9593\u7684\u95dc\u4fc2\u3002\u6211\u5011\u5728 18 \u500b\u8cc7\u6599\u96c6\u4e0a\u7684\u7d50\u679c\u8868\u660e\uff1ai) \u6301\u7e8c\u9810\u8a13\u7df4\u4ee5\u6f5b\u5728\u7684\u65b9\u5f0f\u6539\u5584\u6a21\u578b\uff0c\u9019\u7a2e\u65b9\u5f0f\u5728\u5fae\u8abf\u5f8c\u63ed\u793a\u51fa\u4f86\uff1bii) \u900f\u904e\u984d\u5916\u7684\u5fae\u8abf\uff0c\u6a21\u578b\u672a\u5c55\u73fe\u80fd\u529b\u7684\u8cc7\u6599\u96c6\u6bd4\u5728\u9810\u8a13\u7df4\u968e\u6bb5\u8868\u73fe\u826f\u597d\u7684\u8cc7\u6599\u96c6\u7372\u5f97\u66f4\u591a\u6536\u76ca\uff1biii) \u5118\u7ba1\u6a21\u578b\u900f\u904e\u76e3\u7763\u5f0f\u5fae\u8abf\u986f\u8457\u53d7\u76ca\uff0c\u4f46\u5b83\u53ef\u80fd\u6703\u5fd8\u8a18\u5148\u524d\u5df2\u77e5\u7684\u9818\u57df\u77e5\u8b58\u548c\u5fae\u8abf\u671f\u9593\u672a\u898b\u7684\u4efb\u52d9\uff1biv) \u6a21\u578b\u5728\u76e3\u7763\u5f0f\u5fae\u8abf\u5f8c\u5c0d\u8a55\u4f30\u63d0\u793a\u5c55\u73fe\u51fa\u9ad8\u5ea6\u654f\u611f\u6027\uff0c\u4f46\u9019\u7a2e\u654f\u611f\u6027\u53ef\u4ee5\u900f\u904e\u66f4\u591a\u9810\u8a13\u7df4\u4f86\u7de9\u89e3\u3002", "author": "Kaiser Sun et.al.", "authors": "Kaiser Sun, Mark Dredze", "id": "2408.06663v2", "paper_url": "http://arxiv.org/abs/2408.06663v2", "repo": "null"}}