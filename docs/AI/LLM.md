
### LLM
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-07-30**|**ThinK: Thinner Key Cache by Query-Driven Pruning**|Yuhui Xu et.al.|[2407.21018v1](http://arxiv.org/abs/2407.21018v1)|null|
|**2024-07-30**|**CLEFT: Language-Image Contrastive Learning with Efficient Large Language Model and Prompt Fine-Tuning**|Yuexi Du et.al.|[2407.21011v1](http://arxiv.org/abs/2407.21011v1)|[link](https://github.com/xypb/cleft)|
|**2024-07-30**|**AI-Assisted Generation of Difficult Math Questions**|Vedant Shah et.al.|[2407.21009v1](http://arxiv.org/abs/2407.21009v1)|null|
|**2024-07-30**|**Evolver: Chain-of-Evolution Prompting to Boost Large Multimodal Models for Hateful Meme Detection**|Jinfa Huang et.al.|[2407.21004v1](http://arxiv.org/abs/2407.21004v1)|null|
|**2024-07-30**|**GABInsight: Exploring Gender-Activity Binding Bias in Vision-Language Models**|Ali Abdollahi et.al.|[2407.21001v1](http://arxiv.org/abs/2407.21001v1)|null|
|**2024-07-30**|**MoFO: Momentum-Filtered Optimizer for Mitigating Forgetting in LLM Fine-Tuning**|Yupeng Chen et.al.|[2407.20999v1](http://arxiv.org/abs/2407.20999v1)|null|
|**2024-07-30**|**From Feature Importance to Natural Language Explanations Using LLMs with RAG**|Sule Tekkesinoglu et.al.|[2407.20990v1](http://arxiv.org/abs/2407.20990v1)|null|
|**2024-07-30**|**Large Language Models (LLMs) for Semantic Communication in Edge-based IoT Networks**|Alakesh Kalita et.al.|[2407.20970v1](http://arxiv.org/abs/2407.20970v1)|null|
|**2024-07-30**|**An Effective Dynamic Gradient Calibration Method for Continual Learning**|Weichen Lin et.al.|[2407.20956v1](http://arxiv.org/abs/2407.20956v1)|null|
|**2024-07-30**|**Emotion-driven Piano Music Generation via Two-stage Disentanglement and Functional Representation**|Jingyue Huang et.al.|[2407.20955v1](http://arxiv.org/abs/2407.20955v1)|[link](https://github.com/yuer867/emo-disentanger)|
|**2024-07-30**|**An evidence-based methodology for human rights impact assessment (HRIA) in the development of AI data-intensive systems**|Alessandro Mantelero et.al.|[2407.20951v1](http://arxiv.org/abs/2407.20951v1)|null|
|**2024-07-30**|**Automated Review Generation Method Based on Large Language Models**|Shican Wu et.al.|[2407.20906v1](http://arxiv.org/abs/2407.20906v1)|[link](https://github.com/tju-ecat-ai/automaticreviewgeneration)|
|**2024-07-30**|**Faithful and Plausible Natural Language Explanations for Image Classification: A Pipeline Approach**|Adam Wojciechowski et.al.|[2407.20899v1](http://arxiv.org/abs/2407.20899v1)|null|
|**2024-07-30**|**MambaCapsule: Towards Transparent Cardiac Disease Diagnosis with Electrocardiography Using Mamba Capsule Network**|Yinlong Xu et.al.|[2407.20893v1](http://arxiv.org/abs/2407.20893v1)|null|
|**2024-07-30**|**Bayesian Low-Rank LeArning (Bella): A Practical Approach to Bayesian Neural Networks**|Bao Gia Doan et.al.|[2407.20891v1](http://arxiv.org/abs/2407.20891v1)|null|
|**2024-07-30**|**Effective Black Box Testing of Sentiment Analysis Classification Networks**|Parsa Karbasizadeh et.al.|[2407.20884v1](http://arxiv.org/abs/2407.20884v1)|null|
|**2024-07-30**|**Learn by Selling: Equipping Large Language Models with Product Knowledge for Context-Driven Recommendations**|Sarthak Anand et.al.|[2407.20856v1](http://arxiv.org/abs/2407.20856v1)|null|
|**2024-07-30**|**Federated Knowledge Recycling: Privacy-Preserving Synthetic Data Sharing**|Eugenio Lomurno et.al.|[2407.20830v1](http://arxiv.org/abs/2407.20830v1)|null|
|**2024-07-30**|**How to Measure the Intelligence of Large Language Models?**|Nils Körber et.al.|[2407.20828v1](http://arxiv.org/abs/2407.20828v1)|null|
|**2024-07-30**|**ARCLE: The Abstraction and Reasoning Corpus Learning Environment for Reinforcement Learning**|Hosung Lee et.al.|[2407.20806v1](http://arxiv.org/abs/2407.20806v1)|[link](https://github.com/confeitohs/arcle)|
|**2024-07-30**|**Diffusion Augmented Agents: A Framework for Efficient Exploration and Transfer Learning**|Norman Di Palo et.al.|[2407.20798v1](http://arxiv.org/abs/2407.20798v1)|null|
|**2024-07-30**|**Be aware of overfitting by hyperparameter optimization!**|Igor V. Tetko et.al.|[2407.20786v1](http://arxiv.org/abs/2407.20786v1)|null|
|**2024-07-30**|**Metaheuristic Enhanced with Feature-Based Guidance and Diversity Management for Solving the Capacitated Vehicle Routing Problem**|Bachtiar Herdianto et.al.|[2407.20777v1](http://arxiv.org/abs/2407.20777v1)|null|
|**2024-07-30**|**Interpretable Pre-Trained Transformers for Heart Time-Series Data**|Harry J. Davies et.al.|[2407.20775v1](http://arxiv.org/abs/2407.20775v1)|null|
|**2024-07-30**|**OmniBal: Towards Fast Instruct-tuning for Vision-Language Models via Omniverse Computation Balance**|Yongqiang Yao et.al.|[2407.20761v1](http://arxiv.org/abs/2407.20761v1)|[link](https://github.com/modeltc/omnibal)|
|**2024-07-30**|**SynthVLM: High-Efficiency and High-Quality Synthetic Data for Vision Language Models**|Zheng Liu et.al.|[2407.20756v1](http://arxiv.org/abs/2407.20756v1)|[link](https://github.com/starriver030515/synthvlm)|
|**2024-07-30**|**Efficient Quantum One-Class Support Vector Machines for Anomaly Detection Using Randomized Measurements and Variable Subsampling**|Michael Kölle et.al.|[2407.20753v1](http://arxiv.org/abs/2407.20753v1)|null|
|**2024-07-30**|**JaColBERTv2.5: Optimising Multi-Vector Retrievers to Create State-of-the-Art Japanese Retrievers with Constrained Resources**|Benjamin Clavié et.al.|[2407.20750v1](http://arxiv.org/abs/2407.20750v1)|null|
|**2024-07-30**|**Meltemi: The first open Large Language Model for Greek**|Leon Voukoutis et.al.|[2407.20743v1](http://arxiv.org/abs/2407.20743v1)|null|
|**2024-07-30**|**Adapting Safe-for-Work Classifier for Malaysian Language Text: Enhancing Alignment in LLM-Ops Framework**|Aisyah Razak et.al.|[2407.20729v1](http://arxiv.org/abs/2407.20729v1)|null|
|**2024-07-30**|**Exploring Loss Landscapes through the Lens of Spin Glass Theory**|Hao Liao et.al.|[2407.20724v1](http://arxiv.org/abs/2407.20724v1)|null|
|**2024-07-30**|**Cocobo: Exploring Large Language Models as the Engine for End-User Robot Programming**|Yate Ge et.al.|[2407.20712v1](http://arxiv.org/abs/2407.20712v1)|null|
|**2024-07-30**|**Industrial-Grade Smart Troubleshooting through Causal Technical Language Processing: a Proof of Concept**|Alexandre Trilla et.al.|[2407.20700v1](http://arxiv.org/abs/2407.20700v1)|null|
|**2024-07-30**|**Boosting Audio Visual Question Answering via Key Semantic-Aware Cues**|Guangyao Li et.al.|[2407.20693v1](http://arxiv.org/abs/2407.20693v1)|[link](https://github.com/gewu-lab/tspm)|
|**2024-07-30**|**CultureVo: The Serious Game of Utilizing Gen AI for Enhancing Cultural Intelligence**|Ajita Agarwala et.al.|[2407.20685v1](http://arxiv.org/abs/2407.20685v1)|null|
|**2024-07-30**|**RevGNN: Negative Sampling Enhanced Contrastive Graph Learning for Academic Reviewer Recommendation**|Weibin Liao et.al.|[2407.20684v1](http://arxiv.org/abs/2407.20684v1)|null|
|**2024-07-30**|**Label-Guided Prompt for Multi-label Few-shot Aspect Category Detection**|ChaoFeng Guan et.al.|[2407.20673v1](http://arxiv.org/abs/2407.20673v1)|null|
|**2024-07-30**|**Mimicking the Mavens: Agent-based Opinion Synthesis and Emotion Prediction for Social Media Influencers**|Qinglan Wei et.al.|[2407.20668v1](http://arxiv.org/abs/2407.20668v1)|null|
|**2024-07-30**|**ArabicNLU 2024: The First Arabic Natural Language Understanding Shared Task**|Mohammed Khalilia et.al.|[2407.20663v1](http://arxiv.org/abs/2407.20663v1)|null|
|**2024-07-30**|**Prompt-Driven Contrastive Learning for Transferable Adversarial Attacks**|Hunmin Yang et.al.|[2407.20657v1](http://arxiv.org/abs/2407.20657v1)|null|
|**2024-07-30**|**Prompting Encoder Models for Zero-Shot Classification: A Cross-Domain Study in Italian**|Serena Auriemma et.al.|[2407.20654v1](http://arxiv.org/abs/2407.20654v1)|null|
|**2024-07-30**|**FACL-Attack: Frequency-Aware Contrastive Learning for Transferable Adversarial Attacks**|Hunmin Yang et.al.|[2407.20653v1](http://arxiv.org/abs/2407.20653v1)|null|
|**2024-07-30**|**Leveraging Multi-facet Paths for Heterogeneous Graph Representation Learning**|JongWoo Kim et.al.|[2407.20648v1](http://arxiv.org/abs/2407.20648v1)|null|
|**2024-07-30**|**Autonomous Improvement of Instruction Following Skills via Foundation Models**|Zhiyuan Zhou et.al.|[2407.20635v1](http://arxiv.org/abs/2407.20635v1)|null|
|**2024-07-30**|**Decoding Linguistic Representations of Human Brain**|Yu Wang et.al.|[2407.20622v1](http://arxiv.org/abs/2407.20622v1)|null|
|**2024-07-30**|**Questionnaires for Everyone: Streamlining Cross-Cultural Questionnaire Adaptation with GPT-Based Translation Quality Evaluation**|Otso Haavisto et.al.|[2407.20608v1](http://arxiv.org/abs/2407.20608v1)|null|
|**2024-07-30**|**Harvesting Textual and Structured Data from the HAL Publication Repository**|Francis Kulumba et.al.|[2407.20595v1](http://arxiv.org/abs/2407.20595v1)|null|
|**2024-07-30**|**Enhancing Agricultural Machinery Management through Advanced LLM Integration**|Emily Johnson et.al.|[2407.20588v1](http://arxiv.org/abs/2407.20588v1)|null|
|**2024-07-30**|**Pruning Large Language Models with Semi-Structural Adaptive Sparse Training**|Weiyu Huang et.al.|[2407.20584v1](http://arxiv.org/abs/2407.20584v1)|null|
|**2024-07-30**|**Image-based Detection of Segment Misalignment in Multi-mirror Satellites using Transfer Learning**|C. Tanner Fredieu et.al.|[2407.20582v1](http://arxiv.org/abs/2407.20582v1)|null|
|**2024-07-30**|**Knesset-DictaBERT: A Hebrew Language Model for Parliamentary Proceedings**|Gili Goldin et.al.|[2407.20581v1](http://arxiv.org/abs/2407.20581v1)|null|
|**2024-07-30**|**Comparison of Large Language Models for Generating Contextually Relevant Questions**|Ivo Lodovico Molina et.al.|[2407.20578v1](http://arxiv.org/abs/2407.20578v1)|[link](https://github.com/limu-research/2024-ectel-qg)|
|**2024-07-30**|**CLR-Fact: Evaluating the Complex Logical Reasoning Capability of Large Language Models over Factual Knowledge**|Tianshi Zheng et.al.|[2407.20564v1](http://arxiv.org/abs/2407.20564v1)|null|
|**2024-07-30**|**Pyramid Coder: Hierarchical Code Generator for Compositional Visual Question Answering**|Ruoyue Shen et.al.|[2407.20563v1](http://arxiv.org/abs/2407.20563v1)|null|
|**2024-07-30**|**CELLM: An Efficient Communication in Large Language Models Training for Federated Learning**|Raja Vavekanand et.al.|[2407.20557v1](http://arxiv.org/abs/2407.20557v1)|null|
|**2024-07-30**|**Survey of Design Paradigms for Social Robots**|Rita Frieske et.al.|[2407.20556v1](http://arxiv.org/abs/2407.20556v1)|null|
|**2024-07-30**|**Contrastive Feedback Mechanism for Simultaneous Speech Translation**|Haotian Tan et.al.|[2407.20524v1](http://arxiv.org/abs/2407.20524v1)|null|
|**2024-07-30**|**DuA: Dual Attentive Transformer in Long-Term Continuous EEG Emotion Analysis**|Yue Pan et.al.|[2407.20519v1](http://arxiv.org/abs/2407.20519v1)|null|
|**2024-07-30**|**High-Resolution Spatial Transcriptomics from Histology Images using HisToSGE**|Zhiceng Shi et.al.|[2407.20518v1](http://arxiv.org/abs/2407.20518v1)|[link](https://github.com/wenwenmin/histosge)|
|**2024-07-30**|**Machine Unlearning in Generative AI: A Survey**|Zheyuan Liu et.al.|[2407.20516v1](http://arxiv.org/abs/2407.20516v1)|[link](https://github.com/franciscoliu/genai-mu-reading)|
|**2024-07-30**|**Prompt2DeModel: Declarative Neuro-Symbolic Modeling with Natural Language**|Hossein Rajaby Faghihi et.al.|[2407.20513v1](http://arxiv.org/abs/2407.20513v1)|null|
|**2024-07-30**|**Unveiling the Potential of Spiking Dynamics in Graph Representation Learning through Spatial-Temporal Normalization and Coding Strategies**|Mingkun Xu et.al.|[2407.20508v1](http://arxiv.org/abs/2407.20508v1)|null|
|**2024-07-30**|**Boosting Efficiency in Task-Agnostic Exploration through Causal Knowledge**|Yupei Yang et.al.|[2407.20506v1](http://arxiv.org/abs/2407.20506v1)|[link](https://github.com/cmach508/causalexploration)|
|**2024-07-30**|**A federated large language model for long-term time series forecasting**|Raed Abdel-Sater et.al.|[2407.20503v1](http://arxiv.org/abs/2407.20503v1)|null|
|**2024-07-30**|**Toward Efficient Permutation for Hierarchical N:M Sparsity on GPUs**|Seungmin Yu et.al.|[2407.20496v1](http://arxiv.org/abs/2407.20496v1)|null|
|**2024-07-30**|**A2SF: Accumulative Attention Scoring with Forgetting Factor for Token Pruning in Transformer Decoder**|Hyun Rae Jo et.al.|[2407.20485v1](http://arxiv.org/abs/2407.20485v1)|null|
|**2024-07-29**|**CoMMIT: Coordinated Instruction Tuning for Multimodal Large Language Models**|Junda Wu et.al.|[2407.20454v1](http://arxiv.org/abs/2407.20454v1)|null|
|**2024-07-29**|**Domain Adaptable Prescriptive AI Agent for Enterprise**|Piero Orderique et.al.|[2407.20447v1](http://arxiv.org/abs/2407.20447v1)|null|
|**2024-07-29**|**Futga: Towards Fine-grained Music Understanding through Temporally-enhanced Generative Augmentation**|Junda Wu et.al.|[2407.20445v1](http://arxiv.org/abs/2407.20445v1)|null|
|**2024-07-29**|**Generating Gender Alternatives in Machine Translation**|Sarthak Garg et.al.|[2407.20438v1](http://arxiv.org/abs/2407.20438v1)|null|
|**2024-07-29**|**Through the Looking Glass, and what Horn Clause Programs Found There**|Paul Tarau et.al.|[2407.20413v1](http://arxiv.org/abs/2407.20413v1)|null|
|**2024-07-29**|**Appraisal-Guided Proximal Policy Optimization: Modeling Psychological Disorders in Dynamic Grid World**|Hari Prasad et.al.|[2407.20383v1](http://arxiv.org/abs/2407.20383v1)|null|
|**2024-07-29**|**What if Red Can Talk? Dynamic Dialogue Generation Using Large Language Models**|Navapat Nananukul et.al.|[2407.20382v1](http://arxiv.org/abs/2407.20382v1)|null|
|**2024-07-29**|**Leveraging Natural Language and Item Response Theory Models for ESG Scoring**|César Pedrosa Soares et.al.|[2407.20377v1](http://arxiv.org/abs/2407.20377v1)|null|
|**2024-07-29**|**Gender, Race, and Intersectional Bias in Resume Screening via Language Model Retrieval**|Kyra Wilson et.al.|[2407.20371v1](http://arxiv.org/abs/2407.20371v1)|null|
|**2024-07-29**|**Evaluating Large Language Models for automatic analysis of teacher simulations**|David de-Fitero-Dominguez et.al.|[2407.20360v1](http://arxiv.org/abs/2407.20360v1)|null|
|**2024-07-29**|**BRIDGE: Bridging Gaps in Image Captioning Evaluation with Stronger Visual Cues**|Sara Sarto et.al.|[2407.20341v1](http://arxiv.org/abs/2407.20341v1)|[link](https://github.com/aimagelab/bridge-score)|
|**2024-07-29**|**Contrasting Deepfakes Diffusion via Contrastive Learning and Global-Local Similarities**|Lorenzo Baraldi et.al.|[2407.20337v1](http://arxiv.org/abs/2407.20337v1)|[link](https://github.com/aimagelab/code)|
|**2024-07-29**|**Specify and Edit: Overcoming Ambiguity in Text-Based Image Editing**|Ekaterina Iakovleva et.al.|[2407.20232v1](http://arxiv.org/abs/2407.20232v1)|null|
|**2024-07-29**|**Can Editing LLMs Inject Harm?**|Canyu Chen et.al.|[2407.20224v1](http://arxiv.org/abs/2407.20224v1)|null|
|**2024-07-29**|**Physics of Language Models: Part 2.1, Grade-School Math and the Hidden Reasoning Process**|Tian Ye et.al.|[2407.20311v1](http://arxiv.org/abs/2407.20311v1)|null|
|**2024-07-29**|**SANGRIA: Surgical Video Scene Graph Optimization for Surgical Workflow Prediction**|Çağhan Köksal et.al.|[2407.20214v1](http://arxiv.org/abs/2407.20214v1)|null|
|**2024-07-29**|**QAEA-DR: A Unified Text Augmentation Framework for Dense Retrieval**|Hongming Tan et.al.|[2407.20207v1](http://arxiv.org/abs/2407.20207v1)|null|
|**2024-07-29**|**Aligning Query Representation with Rewritten Query and Relevance Judgments in Conversational Search**|Fengran Mo et.al.|[2407.20189v1](http://arxiv.org/abs/2407.20189v1)|null|
|**2024-07-29**|**MindSearch: Mimicking Human Minds Elicits Deep AI Searcher**|Zehui Chen et.al.|[2407.20183v1](http://arxiv.org/abs/2407.20183v1)|[link](https://github.com/internlm/mindsearch)|
|**2024-07-29**|**Theia: Distilling Diverse Vision Foundation Models for Robot Learning**|Jinghuan Shang et.al.|[2407.20179v1](http://arxiv.org/abs/2407.20179v1)|[link](https://github.com/bdaiinstitute/theia)|
|**2024-07-29**|**AutoScale: Automatic Prediction of Compute-optimal Data Composition for Training LLMs**|Feiyang Kang et.al.|[2407.20177v1](http://arxiv.org/abs/2407.20177v1)|null|
|**2024-07-29**|**Emotion-Driven Melody Harmonization via Melodic Variation and Functional Representation**|Jingyue Huang et.al.|[2407.20176v1](http://arxiv.org/abs/2407.20176v1)|[link](https://github.com/yuer867/emo_harmonizer)|
|**2024-07-29**|**Advancing Multimodal Large Language Models in Chart Question Answering with Visualization-Referenced Instruction Tuning**|Xingchen Zeng et.al.|[2407.20174v1](http://arxiv.org/abs/2407.20174v1)|[link](https://github.com/zengxingchen/chartqa-mllm)|
|**2024-07-29**|**LatentArtiFusion: An Effective and Efficient Histological Artifacts Restoration Framework**|Zhenqi He et.al.|[2407.20172v1](http://arxiv.org/abs/2407.20172v1)|[link](https://github.com/bugs-creator/latentartifusion)|
|**2024-07-29**|**Language-Conditioned Offline RL for Multi-Robot Navigation**|Steven Morad et.al.|[2407.20164v1](http://arxiv.org/abs/2407.20164v1)|null|
|**2024-07-29**|**rLLM: Relational Table Learning with LLMs**|Weichen Li et.al.|[2407.20157v1](http://arxiv.org/abs/2407.20157v1)|[link](https://github.com/rllm-project/rllm)|
|**2024-07-29**|**Quantum Machine Learning Architecture Search via Deep Reinforcement Learning**|Xin Dai et.al.|[2407.20147v1](http://arxiv.org/abs/2407.20147v1)|null|
|**2024-07-29**|**ByteCheckpoint: A Unified Checkpointing System for LLM Development**|Borui Wan et.al.|[2407.20143v1](http://arxiv.org/abs/2407.20143v1)|null|
|**2024-07-29**|**To accept or not to accept? An IRT-TOE Framework to Understand Educators' Resistance to Generative AI in Higher Education**|Jan-Erik Kalmus et.al.|[2407.20130v1](http://arxiv.org/abs/2407.20130v1)|null|
|**2024-07-29**|**AxiomVision: Accuracy-Guaranteed Adaptive Visual Model Selection for Perspective-Aware Video Analytics**|Xiangxiang Dai et.al.|[2407.20124v2](http://arxiv.org/abs/2407.20124v2)|[link](https://github.com/zeyuzhangzyz/axiomvision)|
|**2024-07-29**|**EXIT: An EXplicit Interest Transfer Framework for Cross-Domain Recommendation**|Lei Huang et.al.|[2407.20121v1](http://arxiv.org/abs/2407.20121v1)|null|
|**2024-07-29**|**Adaptive Self-supervised Robust Clustering for Unstructured Data with Unknown Cluster Number**|Chen-Lu Ding et.al.|[2407.20119v2](http://arxiv.org/abs/2407.20119v2)|null|
|**2024-07-29**|**FiCo-ITR: bridging fine-grained and coarse-grained image-text retrieval for comparative performance analysis**|Mikel Williams-Lekuona et.al.|[2407.20114v1](http://arxiv.org/abs/2407.20114v1)|null|
|**2024-07-29**|**Diffusion-DICE: In-Sample Diffusion Guidance for Offline Reinforcement Learning**|Liyuan Mao et.al.|[2407.20109v1](http://arxiv.org/abs/2407.20109v1)|null|

#### Abstracts
##### **ThinK: Thinner Key Cache by Query-Driven Pruning**
2407.21018v1 by Yuhui Xu, Zhanming Jie, Hanze Dong, Lei Wang, Xudong Lu, Aojun Zhou, Amrita Saha, Caiming Xiong, Doyen Sahoo

Large Language Models (LLMs) have revolutionized the field of natural
language processing, achieving unprecedented performance across a variety of
applications by leveraging increased model sizes and sequence lengths. However,
the associated rise in computational and memory costs poses significant
challenges, particularly in managing long sequences due to the quadratic
complexity of the transformer attention mechanism. This paper focuses on the
long-context scenario, addressing the inefficiencies in KV cache memory
consumption during inference. Unlike existing approaches that optimize the
memory based on the sequence lengths, we uncover that the channel dimension of
the KV cache exhibits significant redundancy, characterized by unbalanced
magnitude distribution and low-rank structure in attention weights. Based on
these observations, we propose ThinK, a novel query-dependent KV cache pruning
method designed to minimize attention weight loss while selectively pruning the
least significant channels. Our approach not only maintains or enhances model
accuracy but also achieves a reduction in memory costs by over 20% compared
with vanilla KV cache eviction methods. Extensive evaluations on the LLaMA3 and
Mistral models across various long-sequence datasets confirm the efficacy of
ThinK, setting a new precedent for efficient LLM deployment without
compromising performance. We also outline the potential of extending our method
to value cache pruning, demonstrating ThinK's versatility and broad
applicability in reducing both memory and computational overheads.

摘要：大型語言模型 (LLM) 徹底改變了自然語言處理領域，透過運用更大的模型規模和序列長度，在各種應用中達到了前所未有的效能。然而，與此相關的運算和記憶體成本上升，帶來了重大的挑戰，特別是在管理長序列時，因為Transformer注意力機制有二次複雜度。本文重點探討長脈絡場景，解決推論期間 KV 快取記憶體消耗的低效率。與根據序列長度最佳化記憶體的現有方法不同，我們發現 KV 快取的通道維度展現出顯著的冗餘，其特徵在於注意力權重的失衡幅度分佈和低秩結構。根據這些觀察，我們提出 ThinK，一種新穎的與查詢相關的 KV 快取修剪方法，旨在最小化注意力權重損失，同時選擇性地修剪最不重要的通道。我們的做法不僅維持或增強了模型準確度，還與香草 KV 快取驅逐方法相比，將記憶體成本降低了 20% 以上。在 LLaMA3 和 Mistral 模型上針對各種長序列資料集進行的廣泛評估，證實了 ThinK 的效能，為高效 LLM 部署樹立了新的先例，同時不影響效能。我們還概述了將我們的修改方法擴充到值快取修剪的可能性，展示了 ThinK 在降低記憶體和運算開銷方面的多功能性和廣泛適用性。

##### **CLEFT: Language-Image Contrastive Learning with Efficient Large Language Model and Prompt Fine-Tuning**
2407.21011v1 by Yuexi Du, Brian Chang, Nicha C. Dvornek

Recent advancements in Contrastive Language-Image Pre-training (CLIP) have
demonstrated notable success in self-supervised representation learning across
various tasks. However, the existing CLIP-like approaches often demand
extensive GPU resources and prolonged training times due to the considerable
size of the model and dataset, making them poor for medical applications, in
which large datasets are not always common. Meanwhile, the language model
prompts are mainly manually derived from labels tied to images, potentially
overlooking the richness of information within training samples. We introduce a
novel language-image Contrastive Learning method with an Efficient large
language model and prompt Fine-Tuning (CLEFT) that harnesses the strengths of
the extensive pre-trained language and visual models. Furthermore, we present
an efficient strategy for learning context-based prompts that mitigates the gap
between informative clinical diagnostic data and simple class labels. Our
method demonstrates state-of-the-art performance on multiple chest X-ray and
mammography datasets compared with various baselines. The proposed parameter
efficient framework can reduce the total trainable model size by 39% and reduce
the trainable language model to only 4% compared with the current BERT encoder.

摘要：對比語言影像預訓練 (CLIP) 的近期進展已在各種任務中展現出在自我監督表徵學習上的顯著成功。然而，現有的 CLIP 類似方法通常需要大量的 GPU 資源和長時間的訓練，這是因為模型和資料集的大小相當可觀，這使得它們不適合醫療應用，因為大型資料集並不總是常見的。同時，語言模型提示主要是從與影像相關的標籤手動衍生而來，這可能會忽略訓練樣本中豐富的資訊。我們引入一種新穎的語言影像對比學習方法，其中包含一個高效的大語言模型和提示微調 (CLEFT)，它利用了廣泛預訓練的語言和視覺模型的優勢。此外，我們提出了一個用於學習基於脈絡的提示的有效策略，該策略可縮小資訊豐富的臨床診斷資料和簡單類別標籤之間的差距。與各種基準相比，我們的模型在多個胸部 X 光和乳房攝影資料集上展示了最先進的效能。所提出的參數有效架構可以將總可訓練模型大小減少 39%，並將可訓練語言模型減少到僅 4%，與目前的 BERT 編碼器相比。

##### **AI-Assisted Generation of Difficult Math Questions**
2407.21009v1 by Vedant Shah, Dingli Yu, Kaifeng Lyu, Simon Park, Nan Rosemary Ke, Michael Mozer, Yoshua Bengio, Sanjeev Arora, Anirudh Goyal

Current LLM training positions mathematical reasoning as a core capability.
With publicly available sources fully tapped, there is unmet demand for diverse
and challenging math questions. Relying solely on human experts is both
time-consuming and costly, while LLM-generated questions often lack the
requisite diversity and difficulty. We present a design framework that combines
the strengths of LLMs with a human-in-the-loop approach to generate a diverse
array of challenging math questions. We leverage LLM metacognition skills
[Didolkar et al., 2024] of a strong LLM to extract core "skills" from existing
math datasets. These skills serve as the basis for generating novel and
difficult questions by prompting the LLM with random pairs of core skills. The
use of two different skills within each question makes finding such questions
an "out of distribution" task for both LLMs and humans. Our pipeline employs
LLMs to iteratively generate and refine questions and solutions through
multiturn prompting. Human annotators then verify and further refine the
questions, with their efficiency enhanced via further LLM interactions.
Applying this pipeline on skills extracted from the MATH dataset [Hendrycks et
al., 2021] resulted in MATH$^2$ - a dataset of higher-quality math questions,
as evidenced by: (a) Lower performance of all models on MATH$^2$ than on MATH
(b) Higher performance on MATH when using MATH$^2$ questions as in-context
examples. Although focused on mathematics, our methodology seems applicable to
other domains requiring structured reasoning, and potentially as a component of
scalable oversight. Also of interest is a striking relationship observed
between models' performance on the new dataset: the success rate on MATH$^2$ is
the square on MATH, suggesting that successfully solving the question in
MATH$^2$ requires a nontrivial combination of two distinct math skills.

摘要：目前的 LLM 訓練將數學推理定位為核心能力。
由於公開的來源已被充分利用，因此對於多樣化且具有挑戰性的數學問題存在未滿足的需求。僅依賴人類專家既耗時又昂貴，而 LLM 生成的問題通常缺乏必要的 diversity 和難度。我們提出了一個設計框架，結合了 LLM 的優勢和人機協作的方法，以生成多樣化的具有挑戰性的數學問題。我們利用強大的 LLM 的 LLM 元認知技能 [Didolkar 等人，2024] 從現有的數學數據集中提取核心「技能」。這些技能作為通過提示 LLM 隨機配對核心技能來生成新穎且困難的問題的基礎。在每個問題中使用兩種不同的技能，使得尋找此類問題成為 LLM 和人類的「分佈外」任務。我們的管道採用 LLM 通過多輪提示反覆生成和改進問題和解決方案。然後，人類註解者驗證並進一步改進問題，並通過進一步的 LLM 交互來提高其效率。將此管道應用於從 MATH 數據集 [Hendrycks 等人，2021] 中提取的技能，產生了 MATH^2 - 一個更高品質的數學問題數據集，這由以下事實證明：(a) 所有模型在 MATH^2 上的性能低於 MATH(b) 在使用 MATH^2 問題作為上下文範例時，MATH 上的性能更高。儘管重點在數學上，但我們的方法似乎適用於需要結構化推理的其他領域，並且可能作為可擴展監督的一個組成部分。同樣有趣的是在模型在新數據集上的表現之間觀察到一個顯著的關係：MATH^2 上的成功率是 MATH 上的平方，這表明在 MATH^2 中成功解決問題需要兩個不同的數學技能的非平凡組合。

##### **Evolver: Chain-of-Evolution Prompting to Boost Large Multimodal Models for Hateful Meme Detection**
2407.21004v1 by Jinfa Huang, Jinsheng Pan, Zhongwei Wan, Hanjia Lyu, Jiebo Luo

Recent advances show that two-stream approaches have achieved outstanding
performance in hateful meme detection. However, hateful memes constantly evolve
as new memes emerge by fusing progressive cultural ideas, making existing
methods obsolete or ineffective. In this work, we explore the potential of
Large Multimodal Models (LMMs) for hateful meme detection. To this end, we
propose Evolver, which incorporates LMMs via Chain-of-Evolution (CoE)
Prompting, by integrating the evolution attribute and in-context information of
memes. Specifically, Evolver simulates the evolving and expressing process of
memes and reasons through LMMs in a step-by-step manner. First, an evolutionary
pair mining module retrieves the top-k most similar memes in the external
curated meme set with the input meme. Second, an evolutionary information
extractor is designed to summarize the semantic regularities between the paired
memes for prompting. Finally, a contextual relevance amplifier enhances the
in-context hatefulness information to boost the search for evolutionary
processes. Extensive experiments on public FHM, MAMI, and HarM datasets show
that CoE prompting can be incorporated into existing LMMs to improve their
performance. More encouragingly, it can serve as an interpretive tool to
promote the understanding of the evolution of social memes.

摘要：最近的研究進展表明，雙流方法在仇恨迷因偵測中取得了傑出的表現。然而，隨著融合進步文化思想的新迷因不斷出現，仇恨迷因也在不斷演變，使現有方法過時或無效。在這項工作中，我們探討了大型多模態模型 (LMM) 在仇恨迷因偵測中的潛力。為此，我們提出了 Evolver，它透過演化鏈 (CoE) 提示整合了 LMM，方法是整合迷因的演化屬性和上下文資訊。具體來說，Evolver 模擬了迷因的演化和表達過程，並逐步透過 LMM 推理。首先，一個演化對挖掘模組會在外部策展的迷因集中擷取與輸入迷因最相似的 top-k 迷因。其次，設計了一個演化資訊萃取器，用於總結配對迷因之間的語義規律，以進行提示。最後，一個上下文關聯放大器增強了上下文中的仇恨資訊，以促進對演化過程的搜尋。在公共 FHM、MAMI 和 HarM 資料集上進行的廣泛實驗表明，CoE 提示可以整合到現有的 LMM 中，以提高其效能。更令人鼓舞的是，它可以用作一種詮釋工具，以促進對社交迷因演化的理解。

##### **GABInsight: Exploring Gender-Activity Binding Bias in Vision-Language Models**
2407.21001v1 by Ali Abdollahi, Mahdi Ghaznavi, Mohammad Reza Karimi Nejad, Arash Mari Oriyad, Reza Abbasi, Ali Salesi, Melika Behjati, Mohammad Hossein Rohban, Mahdieh Soleymani Baghshah

Vision-language models (VLMs) are intensively used in many downstream tasks,
including those requiring assessments of individuals appearing in the images.
While VLMs perform well in simple single-person scenarios, in real-world
applications, we often face complex situations in which there are persons of
different genders doing different activities. We show that in such cases, VLMs
are biased towards identifying the individual with the expected gender
(according to ingrained gender stereotypes in the model or other forms of
sample selection bias) as the performer of the activity. We refer to this bias
in associating an activity with the gender of its actual performer in an image
or text as the Gender-Activity Binding (GAB) bias and analyze how this bias is
internalized in VLMs. To assess this bias, we have introduced the GAB dataset
with approximately 5500 AI-generated images that represent a variety of
activities, addressing the scarcity of real-world images for some scenarios. To
have extensive quality control, the generated images are evaluated for their
diversity, quality, and realism. We have tested 12 renowned pre-trained VLMs on
this dataset in the context of text-to-image and image-to-text retrieval to
measure the effect of this bias on their predictions. Additionally, we have
carried out supplementary experiments to quantify the bias in VLMs' text
encoders and to evaluate VLMs' capability to recognize activities. Our
experiments indicate that VLMs experience an average performance decline of
about 13.2% when confronted with gender-activity binding bias.

摘要：視覺語言模型 (VLM) 被廣泛用於許多下游任務，
包括需要評估出現在影像中的人員。
雖然 VLM 在簡單的單人情境中表現良好，但在現實世界
的應用中，我們經常會遇到複雜的情況，其中有不同性別的人從事不同的活動。我們表明，在這種情況下，VLM 傾向於將具有預期性別的個人（根據模型中根深蒂固的性別刻板印象或其他形式的樣本選擇偏差）識別為活動的執行者。我們將這種將活動與其實際執行者的性別聯繫起來的偏差稱為性別活動綁定 (GAB) 偏差，並分析此偏差如何在 VLM 中內化。為了評估此偏差，我們引入了 GAB 資料集，其中包含約 5500 張 AI 生成的影像，這些影像代表了各種活動，解決了某些情境中缺乏真實世界影像的問題。為了進行廣泛的品質控管，我們對生成的影像進行了多樣性、品質和真實性的評估。我們在這個資料集上測試了 12 個著名的預訓練 VLM，在文字轉影像和影像轉文字檢索的背景下，以衡量此偏差對其預測的影響。此外，我們還進行了補充實驗，以量化 VLM 文字編碼器中的偏差，並評估 VLM 識別活動的能力。我們的實驗表明，當面對性別活動綁定偏差時，VLM 的平均效能下降約 13.2%。

##### **MoFO: Momentum-Filtered Optimizer for Mitigating Forgetting in LLM Fine-Tuning**
2407.20999v1 by Yupeng Chen, Senmiao Wang, Zhihang Lin, Zeyu Qin, Yushun Zhang, Tian Ding, Ruoyu Sun

Recently, large language models (LLMs) have demonstrated remarkable
capabilities in a wide range of tasks. Typically, an LLM is pre-trained on
large corpora and subsequently fine-tuned on task-specific datasets. However,
during finetuning, LLMs may forget the knowledge acquired in the pretraining
stage, leading to a decline in general capabilities. To address this issue, we
propose a new fine-tuning algorithm termed Momentum-Filtered Optimizer (MoFO).
The key idea of MoFO is to iteratively select and update the model parameters
with the largest momentum magnitudes. Compared to full-parameter training, MoFO
achieves similar fine-tuning performance while keeping parameters closer to the
pre-trained model, thereby mitigating knowledge forgetting. Unlike most
existing methods for forgetting mitigation, MoFO combines the following two
advantages. First, MoFO does not require access to pre-training data. This
makes MoFO particularly suitable for fine-tuning scenarios where pre-training
data is unavailable, such as fine-tuning checkpoint-only open-source LLMs.
Second, MoFO does not alter the original loss function. This could avoid
impairing the model performance on the fine-tuning tasks. We validate MoFO
through rigorous convergence analysis and extensive experiments, demonstrating
its superiority over existing methods in mitigating forgetting and enhancing
fine-tuning performance.

摘要：最近，大型语言模型 (LLM) 已在广泛的任务中展示出非凡的能力。通常，LLM 在大型语料库上进行预训练，然后在特定于任务的数据集上进行微调。然而，在微调过程中，LLM 可能会忘记在预训练阶段获得的知识，从而导致一般能力下降。为了解决这个问题，我们提出了一种新的微调算法，称为动量滤波优化器 (MoFO)。MoFO 的关键思想是迭代选择和更新具有最大动量幅度的模型参数。与全参数训练相比，MoFO 在保持参数更接近预训练模型的同时实现了类似的微调性能，从而减轻了知识遗忘。与大多数现有的缓解遗忘的方法不同，MoFO 结合了以下两个优点。首先，MoFO 不需要访问预训练数据。这使得 MoFO 特别适用于预训练数据不可用的微调场景，例如微调仅限于检查点的开源 LLM。其次，MoFO 不会改变原始损失函数。这可以避免损害模型在微调任务上的性能。我们通过严格的收敛分析和广泛的实验验证了 MoFO，证明了其在减轻遗忘和增强微调性能方面优于现有方法。

##### **From Feature Importance to Natural Language Explanations Using LLMs with RAG**
2407.20990v1 by Sule Tekkesinoglu, Lars Kunze

As machine learning becomes increasingly integral to autonomous
decision-making processes involving human interaction, the necessity of
comprehending the model's outputs through conversational means increases. Most
recently, foundation models are being explored for their potential as post hoc
explainers, providing a pathway to elucidate the decision-making mechanisms of
predictive models. In this work, we introduce traceable question-answering,
leveraging an external knowledge repository to inform the responses of Large
Language Models (LLMs) to user queries within a scene understanding task. This
knowledge repository comprises contextual details regarding the model's output,
containing high-level features, feature importance, and alternative
probabilities. We employ subtractive counterfactual reasoning to compute
feature importance, a method that entails analysing output variations resulting
from decomposing semantic features. Furthermore, to maintain a seamless
conversational flow, we integrate four key characteristics - social, causal,
selective, and contrastive - drawn from social science research on human
explanations into a single-shot prompt, guiding the response generation
process. Our evaluation demonstrates that explanations generated by the LLMs
encompassed these elements, indicating its potential to bridge the gap between
complex model outputs and natural language expressions.

摘要：隨著機器學習在涉及人類互動的自主決策過程中變得越來越不可或缺，透過對話方式理解模型輸出的必要性也隨之增加。最近，基礎模型正因其作為事後解釋器的潛力而受到探索，為闡明預測模型的決策機制提供了一條途徑。在這項工作中，我們引入了可追溯的問答，利用外部知識庫為大型語言模型 (LLM) 在場景理解任務中對使用者查詢的回應提供資訊。這個知識庫包含有關模型輸出的背景詳細資料，包含高階特徵、特徵重要性以及替代機率。我們採用減法反事實推理來計算特徵重要性，這是一種需要分析由語義特徵分解產生的輸出變化的方法。此外，為了維持無縫的對話流程，我們將來自人類解釋社會科學研究的四個關鍵特徵（社會、因果、選擇和對比）整合到單次提示中，引導回應產生過程。我們的評估表明，LLM 生成的解釋涵蓋了這些元素，這表明它有可能彌合複雜模型輸出與自然語言表達之間的差距。

##### **Large Language Models (LLMs) for Semantic Communication in Edge-based IoT Networks**
2407.20970v1 by Alakesh Kalita

With the advent of Fifth Generation (5G) and Sixth Generation (6G)
communication technologies, as well as the Internet of Things (IoT), semantic
communication is gaining attention among researchers as current communication
technologies are approaching Shannon's limit. On the other hand, Large Language
Models (LLMs) can understand and generate human-like text, based on extensive
training on diverse datasets with billions of parameters. Considering the
recent near-source computational technologies like Edge, in this article, we
give an overview of a framework along with its modules, where LLMs can be used
under the umbrella of semantic communication at the network edge for efficient
communication in IoT networks. Finally, we discuss a few applications and
analyze the challenges and opportunities to develop such systems.

摘要：隨著第五代（5G）和第六代（6G）通訊技術的出現，以及物聯網（IoT），語意通訊正受到研究人員的關注，因為目前的通訊技術正接近香農極限。另一方面，大型語言模型（LLM）可以理解並產生類人文字，這基於對具有數十億個參數的不同資料集進行廣泛訓練。考慮到最近的近源計算技術，例如 Edge，在本文中，我們概述了一個框架及其模組，其中 LLM 可以用於網路邊緣的語意通訊，以在 IoT 網路中進行高效通訊。最後，我們討論了一些應用，並分析了開發此類系統的挑戰和機會。

##### **An Effective Dynamic Gradient Calibration Method for Continual Learning**
2407.20956v1 by Weichen Lin, Jiaxiang Chen, Ruomin Huang, Hu Ding

Continual learning (CL) is a fundamental topic in machine learning, where the
goal is to train a model with continuously incoming data and tasks. Due to the
memory limit, we cannot store all the historical data, and therefore confront
the ``catastrophic forgetting'' problem, i.e., the performance on the previous
tasks can substantially decrease because of the missing information in the
latter period. Though a number of elegant methods have been proposed, the
catastrophic forgetting phenomenon still cannot be well avoided in practice. In
this paper, we study the problem from the gradient perspective, where our aim
is to develop an effective algorithm to calibrate the gradient in each updating
step of the model; namely, our goal is to guide the model to be updated in the
right direction under the situation that a large amount of historical data are
unavailable. Our idea is partly inspired by the seminal stochastic variance
reduction methods (e.g., SVRG and SAGA) for reducing the variance of gradient
estimation in stochastic gradient descent algorithms. Another benefit is that
our approach can be used as a general tool, which is able to be incorporated
with several existing popular CL methods to achieve better performance. We also
conduct a set of experiments on several benchmark datasets to evaluate the
performance in practice.

摘要：持續學習 (CL) 是機器學習中的一項基本主題，其目標是使用持續輸入的資料和任務訓練模型。由於記憶體限制，我們無法儲存所有歷史資料，因此面臨「災難性遺忘」問題，亦即在後期的任務中，由於缺少資訊，之前任務的效能可能會大幅下降。儘管已經提出許多優雅的方法，但災難性遺忘現象在實務上仍無法有效避免。在本文中，我們從梯度觀點探討這個問題，我們的目標是開發一種有效的演算法來校正模型在每個更新步驟中的梯度；換句話說，我們的目標是在大量歷史資料不可用的情況下，引導模型朝正確的方向更新。我們的想法部分受到影響，影響來自於用於減少隨機梯度下降演算法中梯度估計變異的開創性隨機變異減少方法 (例如 SVRG 和 SAGA)。另一個好處是，我們的做法可用作一般工具，可以與現有的幾種流行 CL 方法結合使用，以達成更好的效能。我們也對幾個基準資料集進行一組實驗，以評估在實務中的效能。

##### **Emotion-driven Piano Music Generation via Two-stage Disentanglement and Functional Representation**
2407.20955v1 by Jingyue Huang, Ke Chen, Yi-Hsuan Yang

Managing the emotional aspect remains a challenge in automatic music
generation. Prior works aim to learn various emotions at once, leading to
inadequate modeling. This paper explores the disentanglement of emotions in
piano performance generation through a two-stage framework. The first stage
focuses on valence modeling of lead sheet, and the second stage addresses
arousal modeling by introducing performance-level attributes. To further
capture features that shape valence, an aspect less explored by previous
approaches, we introduce a novel functional representation of symbolic music.
This representation aims to capture the emotional impact of major-minor
tonality, as well as the interactions among notes, chords, and key signatures.
Objective and subjective experiments validate the effectiveness of our
framework in both emotional valence and arousal modeling. We further leverage
our framework in a novel application of emotional controls, showing a broad
potential in emotion-driven music generation.

摘要：在自動音樂生成中，管理情緒層面仍然是一項挑戰。先前的研究旨在一次學習各種情緒，導致建模不足。本文探討了通過兩階段框架在鋼琴演奏生成中解開情緒。第一階段專注於主導樂譜的情緒價建模，而第二階段則通過引入表演級別屬性來解決喚醒建模。為了進一步捕捉塑造情緒價的特徵，這是以前方法較少探索的一個方面，我們引入了一個符號音樂的新型功能表示。這種表示旨在捕捉大調-小調音調的情緒影響，以及音符、和弦和調號之間的相互作用。客觀和主觀實驗驗證了我們框架在情緒價和喚醒建模中的有效性。我們進一步在情緒控制的新應用中利用我們的框架，展示了在情緒驅動的音樂生成中的廣泛潛力。

##### **An evidence-based methodology for human rights impact assessment (HRIA) in the development of AI data-intensive systems**
2407.20951v1 by Alessandro Mantelero, Maria Samantha Esposito

Different approaches have been adopted in addressing the challenges of
Artificial Intelligence (AI), some centred on personal data and others on
ethics, respectively narrowing and broadening the scope of AI regulation. This
contribution aims to demonstrate that a third way is possible, starting from
the acknowledgement of the role that human rights can play in regulating the
impact of data-intensive systems. The focus on human rights is neither a
paradigm shift nor a mere theoretical exercise. Through the analysis of more
than 700 decisions and documents of the data protection authorities of six
countries, we show that human rights already underpin the decisions in the
field of data use. Based on empirical analysis of this evidence, this work
presents a methodology and a model for a Human Rights Impact Assessment (HRIA).
The methodology and related assessment model are focused on AI applications,
whose nature and scale require a proper contextualisation of HRIA methodology.
Moreover, the proposed models provide a more measurable approach to risk
assessment which is consistent with the regulatory proposals centred on risk
thresholds. The proposed methodology is tested in concrete case-studies to
prove its feasibility and effectiveness. The overall goal is to respond to the
growing interest in HRIA, moving from a mere theoretical debate to a concrete
and context-specific implementation in the field of data-intensive applications
based on AI.

摘要：不同的方法已經被採用來解決人工智慧 (AI) 的挑戰，有些集中在個人資料上，而另一些則集中在倫理上，分別縮小和擴大 AI 法規的範圍。這篇貢獻旨在證明第三條道路是可能的，從承認人權在規範數據密集型系統的影響中所扮演的角色開始。關注人權既不是典範轉移，也不是單純的理論練習。透過分析六個國家資料保護機關的 700 多項決策和文件，我們表明人權已經支撐了資料使用領域的決策。基於對這些證據的實證分析，這項工作提出了一種人權影響評估 (HRIA) 的方法和模型。該方法和相關評估模型專注於 AI 應用，其性質和規模需要適當地對 HRIA 方法進行情境化。此外，所提出的模型提供了一種更具可衡量性的風險評估方法，這與以風險閾值為中心的監管提案一致。所提出的方法在具體案例研究中經過測試，以證明其可行性和有效性。總體目標是回應對 HRIA 日益增長的興趣，從單純的理論辯論轉向在基於 AI 的數據密集型應用領域中具體且特定於情境的實施。

##### **Automated Review Generation Method Based on Large Language Models**
2407.20906v1 by Shican Wu, Xiao Ma, Dehui Luo, Lulu Li, Xiangcheng Shi, Xin Chang, Xiaoyun Lin, Ran Luo, Chunlei Pei, Zhi-Jian Zhao, Jinlong Gong

Literature research, vital for scientific advancement, is overwhelmed by the
vast ocean of available information. Addressing this, we propose an automated
review generation method based on Large Language Models (LLMs) to streamline
literature processing and reduce cognitive load. In case study on propane
dehydrogenation (PDH) catalysts, our method swiftly generated comprehensive
reviews from 343 articles, averaging seconds per article per LLM account.
Extended analysis of 1041 articles provided deep insights into catalysts'
composition, structure, and performance. Recognizing LLMs' hallucinations, we
employed a multi-layered quality control strategy, ensuring our method's
reliability and effective hallucination mitigation. Expert verification
confirms the accuracy and citation integrity of generated reviews,
demonstrating LLM hallucination risks reduced to below 0.5% with over 95%
confidence. Released Windows application enables one-click review generation,
aiding researchers in tracking advancements and recommending literature. This
approach showcases LLMs' role in enhancing scientific research productivity and
sets the stage for further exploration.

摘要：文獻研究對於科學進步至關重要，但會被浩瀚的可用資訊淹沒。為了解決這個問題，我們提出一個基於大型語言模型 (LLM) 的自動化評論生成方法，以簡化文獻處理並減少認知負擔。在丙烷脫氫 (PDH) 催化劑的案例研究中，我們的模型從 343 篇論文中快速生成了全面的評論，平均每個 LLM 帳戶每篇論文花費幾秒鐘。對 1041 篇論文的延伸分析提供了對催化劑組成、結構和性能的深入見解。我們認識到 LLM 的幻覺，因此採用了多層品質控管策略，確保我們的方法可靠且能有效減輕幻覺。專家驗證確認了所生成評論的準確性和引文完整性，證明 LLM 的幻覺風險已降低到 0.5% 以下，且有超過 95% 的信心。發布的 Windows 應用程式支援一鍵生成評論，協助研究人員追蹤進展並推薦文獻。這種方法展示了 LLM 在提升科學研究生產力方面的作用，並為進一步探索奠定了基礎。

##### **Faithful and Plausible Natural Language Explanations for Image Classification: A Pipeline Approach**
2407.20899v1 by Adam Wojciechowski, Mateusz Lango, Ondrej Dusek

Existing explanation methods for image classification struggle to provide
faithful and plausible explanations. This paper addresses this issue by
proposing a post-hoc natural language explanation method that can be applied to
any CNN-based classifier without altering its training process or affecting
predictive performance. By analysing influential neurons and the corresponding
activation maps, the method generates a faithful description of the
classifier's decision process in the form of a structured meaning
representation, which is then converted into text by a language model. Through
this pipeline approach, the generated explanations are grounded in the neural
network architecture, providing accurate insight into the classification
process while remaining accessible to non-experts. Experimental results show
that the NLEs constructed by our method are significantly more plausible and
faithful. In particular, user interventions in the neural network structure
(masking of neurons) are three times more effective than the baselines.

摘要：現有的影像分類說明方法難以提供忠實且合理的說明。本文透過提出事後自然語言說明方法來解決此問題，該方法可套用於任何基於 CNN 的分類器，而不會改變其訓練過程或影響預測效能。此方法透過分析具影響力的神經元和對應的啟用映射，以結構化意義表示的形式產生分類器決策過程的忠實描述，然後再由語言模型將其轉換為文字。透過此管道方法，產生的說明植基於神經網路架構，提供對分類過程的準確見解，同時仍讓非專家也能理解。實驗結果顯示，我們的方法建構的 NLE 大幅提升了合理性和忠實度。特別是，使用者在神經網路結構中進行的介入（遮蔽神經元）比基準線有效三倍。

##### **MambaCapsule: Towards Transparent Cardiac Disease Diagnosis with Electrocardiography Using Mamba Capsule Network**
2407.20893v1 by Yinlong Xu, Xiaoqiang Liu, Zitai Kong, Yixuan Wu, Yue Wang, Yingzhou Lu, Honghao Gao, Jian Wu, Hongxia Xu

Cardiac arrhythmia, a condition characterized by irregular heartbeats, often
serves as an early indication of various heart ailments. With the advent of
deep learning, numerous innovative models have been introduced for diagnosing
arrhythmias using Electrocardiogram (ECG) signals. However, recent studies
solely focus on the performance of models, neglecting the interpretation of
their results. This leads to a considerable lack of transparency, posing a
significant risk in the actual diagnostic process. To solve this problem, this
paper introduces MambaCapsule, a deep neural networks for ECG arrhythmias
classification, which increases the explainability of the model while enhancing
the accuracy.Our model utilizes Mamba for feature extraction and Capsule
networks for prediction, providing not only a confidence score but also signal
features. Akin to the processing mechanism of human brain, the model learns
signal features and their relationship between them by reconstructing ECG
signals in the predicted selection. The model evaluation was conducted on
MIT-BIH and PTB dataset, following the AAMI standard. MambaCapsule has achieved
a total accuracy of 99.54% and 99.59% on the test sets respectively. These
results demonstrate the promising performance of under the standard test
protocol.

摘要：心律不整是一种以不规则的心跳为特征的疾病，通常是各种心脏疾病的早期征兆。随着深度学习的出现，已经引入了许多创新的模型，用于使用心电图 (ECG) 信号诊断心律失常。然而，最近的研究仅关注模型的性能，而忽略了对其结果的解释。这导致了相当大的透明度缺乏，在实际诊断过程中构成了重大风险。为了解决这个问题，本文介绍了 MambaCapsule，这是一种用于 ECG 心律失常分类的深度神经网络，它提高了模型的可解释性，同时提高了准确性。我们的模型利用 Mamba 进行特征提取，利用胶囊网络进行预测，不仅提供置信度得分，还提供信号特征。类似于人脑的处理机制，该模型通过在预测选择中重建 ECG 信号来学习信号特征及其之间的关系。模型评估是在 MIT-BIH 和 PTB 数据集上进行的，遵循 AAMI 标准。MambaCapsule 在测试集上分别实现了 99.54% 和 99.59% 的总准确率。这些结果证明了在标准测试协议下的良好性能。

##### **Bayesian Low-Rank LeArning (Bella): A Practical Approach to Bayesian Neural Networks**
2407.20891v1 by Bao Gia Doan, Afshar Shamsi, Xiao-Yu Guo, Arash Mohammadi, Hamid Alinejad-Rokny, Dino Sejdinovic, Damith C. Ranasinghe, Ehsan Abbasnejad

Computational complexity of Bayesian learning is impeding its adoption in
practical, large-scale tasks. Despite demonstrations of significant merits such
as improved robustness and resilience to unseen or out-of-distribution inputs
over their non- Bayesian counterparts, their practical use has faded to near
insignificance. In this study, we introduce an innovative framework to mitigate
the computational burden of Bayesian neural networks (BNNs). Our approach
follows the principle of Bayesian techniques based on deep ensembles, but
significantly reduces their cost via multiple low-rank perturbations of
parameters arising from a pre-trained neural network. Both vanilla version of
ensembles as well as more sophisticated schemes such as Bayesian learning with
Stein Variational Gradient Descent (SVGD), previously deemed impractical for
large models, can be seamlessly implemented within the proposed framework,
called Bayesian Low-Rank LeArning (Bella). In a nutshell, i) Bella achieves a
dramatic reduction in the number of trainable parameters required to
approximate a Bayesian posterior; and ii) it not only maintains, but in some
instances, surpasses the performance of conventional Bayesian learning methods
and non-Bayesian baselines. Our results with large-scale tasks such as
ImageNet, CAMELYON17, DomainNet, VQA with CLIP, LLaVA demonstrate the
effectiveness and versatility of Bella in building highly scalable and
practical Bayesian deep models for real-world applications.

摘要：貝氏學習的計算複雜度阻礙了它在實用、大規模任務中的採用。儘管展示了顯著的優點，例如提高了對未見或分佈外輸入的穩健性和韌性，但與非貝氏對應物相比，它們的實際使用已逐漸變得微不足道。在本研究中，我們引入了一個創新的框架來減輕貝氏神經網路 (BNN) 的計算負擔。我們的做法遵循基於深度合奏的貝氏技術原理，但透過對預先訓練的神經網路產生的參數進行多重低秩擾動，大幅降低其成本。合奏的香草版本以及更複雜的方案，例如使用 Stein 變分梯度下降 (SVGD) 的貝氏學習，以前被認為不適用於大型模型，可以在稱為貝氏低秩學習 (Bella) 的提議框架中無縫實作。簡而言之，i) Bella 大幅減少了近似貝氏後驗所需的訓練參數數量；ii) 它不僅維持，而且在某些情況下，超越了傳統貝氏學習方法和非貝氏基線的效能。我們在 ImageNet、CAMELYON17、DomainNet、VQA with CLIP、LLaVA 等大型任務中的結果證明了 Bella 在建立高度可擴充且實用的貝氏深度模型以進行真實世界應用方面的有效性和多功能性。

##### **Effective Black Box Testing of Sentiment Analysis Classification Networks**
2407.20884v1 by Parsa Karbasizadeh, Fathiyeh Faghih, Pouria Golshanrad

Transformer-based neural networks have demonstrated remarkable performance in
natural language processing tasks such as sentiment analysis. Nevertheless, the
issue of ensuring the dependability of these complicated architectures through
comprehensive testing is still open. This paper presents a collection of
coverage criteria specifically designed to assess test suites created for
transformer-based sentiment analysis networks. Our approach utilizes input
space partitioning, a black-box method, by considering emotionally relevant
linguistic features such as verbs, adjectives, adverbs, and nouns. In order to
effectively produce test cases that encompass a wide range of emotional
elements, we utilize the k-projection coverage metric. This metric minimizes
the complexity of the problem by examining subsets of k features at the same
time, hence reducing dimensionality. Large language models are employed to
generate sentences that display specific combinations of emotional features.
The findings from experiments obtained from a sentiment analysis dataset
illustrate that our criteria and generated tests have led to an average
increase of 16\% in test coverage. In addition, there is a corresponding
average decrease of 6.5\% in model accuracy, showing the ability to identify
vulnerabilities. Our work provides a foundation for improving the dependability
of transformer-based sentiment analysis systems through comprehensive test
evaluation.

摘要：<paragraph>基於 Transformer 的神經網路在自然語言處理任務（例如情緒分析）中展現出非凡的效能。然而，透過全面測試來確保這些複雜架構的可靠性問題仍未解決。本文提出了一系列涵蓋準則，專門用於評估為基於 Transformer 的情緒分析網路建立的測試套件。我們的做法利用輸入空間分割（一種黑盒方法），考慮情緒相關的語言特徵，例如動詞、形容詞、副詞和名詞。為了有效產生涵蓋廣泛情緒元素的測試案例，我們使用 k 投影涵蓋度量數。此量數透過同時檢查 k 個特徵的子集來最小化問題的複雜度，從而降低維度。大型語言模型用於產生顯示特定情緒特徵組合的句子。從情緒分析資料集取得的實驗結果顯示，我們的準則和產生的測試導致測試涵蓋率平均增加 16%。此外，模型準確度相應平均下降 6.5%，顯示出識別漏洞的能力。我們的研究為透過全面的測試評估來改善基於 Transformer 的情緒分析系統的可靠性提供了基礎。</paragraph>

##### **Learn by Selling: Equipping Large Language Models with Product Knowledge for Context-Driven Recommendations**
2407.20856v1 by Sarthak Anand, Yutong Jiang, Giorgi Kokaia

The rapid evolution of large language models (LLMs) has opened up new
possibilities for applications such as context-driven product recommendations.
However, the effectiveness of these models in this context is heavily reliant
on their comprehensive understanding of the product inventory. This paper
presents a novel approach to equipping LLMs with product knowledge by training
them to respond contextually to synthetic search queries that include product
IDs. We delve into an extensive analysis of this method, evaluating its
effectiveness, outlining its benefits, and highlighting its constraints. The
paper also discusses the potential improvements and future directions for this
approach, providing a comprehensive understanding of the role of LLMs in
product recommendations.

摘要：大型語言模型 (LLM) 的快速發展為情境驅動產品推薦等應用程式開啟了新的可能性。然而，這些模型在此情境中的有效性極度仰賴它們對產品庫存的全面理解。本文提出了一種創新的方法，透過訓練 LLM 回應包含產品 ID 的合成搜尋查詢，來為它們提供產品知識。我們深入分析此方法，評估其有效性、概述其優點，並強調其限制。本文也討論了此方法的潛在改進和未來方向，提供對 LLM 在產品推薦中扮演的角色的全面理解。

##### **Federated Knowledge Recycling: Privacy-Preserving Synthetic Data Sharing**
2407.20830v1 by Eugenio Lomurno, Matteo Matteucci

Federated learning has emerged as a paradigm for collaborative learning,
enabling the development of robust models without the need to centralise
sensitive data. However, conventional federated learning techniques have
privacy and security vulnerabilities due to the exposure of models, parameters
or updates, which can be exploited as an attack surface. This paper presents
Federated Knowledge Recycling (FedKR), a cross-silo federated learning approach
that uses locally generated synthetic data to facilitate collaboration between
institutions. FedKR combines advanced data generation techniques with a dynamic
aggregation process to provide greater security against privacy attacks than
existing methods, significantly reducing the attack surface. Experimental
results on generic and medical datasets show that FedKR achieves competitive
performance, with an average improvement in accuracy of 4.24% compared to
training models from local data, demonstrating particular effectiveness in data
scarcity scenarios.

摘要：聯邦學習已成為協作學習的典範，
無需集中敏感資料即可開發穩健模型。然而，由於模型、參數
或更新的公開，傳統的聯邦學習技術具有隱私和安全漏洞，可用作攻擊面。本文提出
聯邦知識再利用 (FedKR)，一種跨孤島的聯邦學習方法
使用本地生成的合成資料來促進
機構之間的合作。FedKR 將先進的資料生成技術與動態
聚合過程相結合，以提供比
現有方法更能抵禦隱私攻擊的安全保障，大幅縮小攻擊面。實驗
結果顯示，在一般和醫療資料集上，FedKR 達到競爭力
表現，與訓練模型相比，準確率平均提升 4.24%
來自本地資料，在資料稀缺的情況下展現出特別的有效性。

##### **How to Measure the Intelligence of Large Language Models?**
2407.20828v1 by Nils Körber, Silvan Wehrli, Christopher Irrgang

With the release of ChatGPT and other large language models (LLMs) the
discussion about the intelligence, possibilities, and risks, of current and
future models have seen large attention. This discussion included much debated
scenarios about the imminent rise of so-called "super-human" AI, i.e., AI
systems that are orders of magnitude smarter than humans. In the spirit of Alan
Turing, there is no doubt that current state-of-the-art language models already
pass his famous test. Moreover, current models outperform humans in several
benchmark tests, so that publicly available LLMs have already become versatile
companions that connect everyday life, industry and science. Despite their
impressive capabilities, LLMs sometimes fail completely at tasks that are
thought to be trivial for humans. In other cases, the trustworthiness of LLMs
becomes much more elusive and difficult to evaluate. Taking the example of
academia, language models are capable of writing convincing research articles
on a given topic with only little input. Yet, the lack of trustworthiness in
terms of factual consistency or the existence of persistent hallucinations in
AI-generated text bodies has led to a range of restrictions for AI-based
content in many scientific journals. In view of these observations, the
question arises as to whether the same metrics that apply to human intelligence
can also be applied to computational methods and has been discussed
extensively. In fact, the choice of metrics has already been shown to
dramatically influence assessments on potential intelligence emergence. Here,
we argue that the intelligence of LLMs should not only be assessed by
task-specific statistical metrics, but separately in terms of qualitative and
quantitative measures.

摘要：<paragraph>隨著 ChatGPT 和其他大型語言模型 (LLM) 的發布，關於當前和未來模型的智慧、可能性和風險的討論備受關注。這場討論包括許多關於所謂「超級人類」AI即將興起的爭論，即比人類聰明好幾個數量級的 AI 系統。依據艾倫·圖靈的精神，毫無疑問，當前最先進的語言模型已經通過了他的著名測試。此外，當前模型在多項基準測試中優於人類，因此公開可用的 LLM 已成為連接日常生活、產業和科學的多功能伴侶。儘管具備令人印象深刻的能力，LLM 有時會在被認為對人類來說微不足道的任務中徹底失敗。在其他情況下，LLM 的可信度變得更加難以捉摸且難以評估。以學術界為例，語言模型能夠僅憑一點輸入就撰寫出令人信服的研究文章。然而，在事實一致性方面缺乏可信度或 AI 生成的文字主體中存在持續的幻覺，導致許多科學期刊對基於 AI 的內容進行了一系列限制。有鑑於這些觀察，出現了一個問題，即適用於人類智慧的相同指標是否也可以應用於計算方法，並且已經過廣泛討論。事實上，指標的選擇已被證明會顯著影響對潛在智慧出現的評估。在此，我們認為 LLM 的智慧不應僅由特定任務的統計指標評估，還應根據質量和數量指標分別評估。</paragraph>

##### **ARCLE: The Abstraction and Reasoning Corpus Learning Environment for Reinforcement Learning**
2407.20806v1 by Hosung Lee, Sejin Kim, Seungpil Lee, Sanha Hwang, Jihwan Lee, Byung-Jun Lee, Sundong Kim

This paper introduces ARCLE, an environment designed to facilitate
reinforcement learning research on the Abstraction and Reasoning Corpus (ARC).
Addressing this inductive reasoning benchmark with reinforcement learning
presents these challenges: a vast action space, a hard-to-reach goal, and a
variety of tasks. We demonstrate that an agent with proximal policy
optimization can learn individual tasks through ARCLE. The adoption of
non-factorial policies and auxiliary losses led to performance enhancements,
effectively mitigating issues associated with action spaces and goal
attainment. Based on these insights, we propose several research directions and
motivations for using ARCLE, including MAML, GFlowNets, and World Models.

摘要：本文介紹了 ARCLE，一種環境，旨在促進抽象與推理語料庫 (ARC) 上的強化學習研究。使用強化學習來解決這個歸納推理基準會產生以下挑戰：廣大的動作空間、難以達成的目標，以及各種任務。我們證明了一個具有近端策略最佳化的代理可以透過 ARCLE 學習個別任務。採用非階乘策略和輔助損失導致效能提升，有效減輕與動作空間和目標達成相關的問題。根據這些見解，我們提出了幾個研究方向和使用 ARCLE 的動機，包括 MAML、GFlowNets 和世界模型。

##### **Diffusion Augmented Agents: A Framework for Efficient Exploration and Transfer Learning**
2407.20798v1 by Norman Di Palo, Leonard Hasenclever, Jan Humplik, Arunkumar Byravan

We introduce Diffusion Augmented Agents (DAAG), a novel framework that
leverages large language models, vision language models, and diffusion models
to improve sample efficiency and transfer learning in reinforcement learning
for embodied agents. DAAG hindsight relabels the agent's past experience by
using diffusion models to transform videos in a temporally and geometrically
consistent way to align with target instructions with a technique we call
Hindsight Experience Augmentation. A large language model orchestrates this
autonomous process without requiring human supervision, making it well-suited
for lifelong learning scenarios. The framework reduces the amount of
reward-labeled data needed to 1) finetune a vision language model that acts as
a reward detector, and 2) train RL agents on new tasks. We demonstrate the
sample efficiency gains of DAAG in simulated robotics environments involving
manipulation and navigation. Our results show that DAAG improves learning of
reward detectors, transferring past experience, and acquiring new tasks - key
abilities for developing efficient lifelong learning agents. Supplementary
material and visualizations are available on our website
https://sites.google.com/view/diffusion-augmented-agents/

摘要：我們引入了擴散增強代理 (DAAG)，這是一個新穎的框架，
利用大型語言模型、視覺語言模型和擴散模型來提升樣本效率和
強化學習中具體代理的遷移學習。DAAG 回顧標籤代理的過往經驗，
使用擴散模型以時間和幾何一致的方式轉換影片，以與目標指令對齊，
使用我們稱之為回顧經驗增強的技術。大型語言模型編排此
自主流程，無需人工監督，使其非常適合終身學習場景。該框架減少了
所需獎勵標籤資料的數量，以 1) 微調充當獎勵偵測器的視覺語言模型，
以及 2) 在新任務上訓練 RL 代理。我們在涉及操作和導航的模擬機器人環境中展示了 DAAG 的樣本效率增益。我們的結果顯示，DAAG 改善了獎勵偵測器的學習，傳輸過去的經驗，並習得新任務 - 這是開發有效終身學習代理的關鍵能力。補充資料和視覺化可在我們的網站上取得 https://sites.google.com/view/diffusion-augmented-agents/

##### **Be aware of overfitting by hyperparameter optimization!**
2407.20786v1 by Igor V. Tetko, Ruud van Deursen, Guillaume Godin

Hyperparameter optimization is very frequently employed in machine learning.
However, an optimization of a large space of parameters could result in
overfitting of models. In recent studies on solubility prediction the authors
collected seven thermodynamic and kinetic solubility datasets from different
data sources. They used state-of-the-art graph-based methods and compared
models developed for each dataset using different data cleaning protocols and
hyperparameter optimization. In our study we showed that hyperparameter
optimization did not always result in better models, possibly due to
overfitting when using the same statistical measures. Similar results could be
calculated using pre-set hyperparameters, reducing the computational effort by
around 10,000 times. We also extended the previous analysis by adding a
representation learning method based on Natural Language Processing of smiles
called Transformer CNN. We show that across all analyzed sets using exactly the
same protocol, Transformer CNN provided better results than graph-based methods
for 26 out of 28 pairwise comparisons by using only a tiny fraction of time as
compared to other methods. Last but not least we stressed the importance of
comparing calculation results using exactly the same statistical measures.

摘要：機器學習中非常頻繁地使用超參數最佳化。
然而，對大參數空間進行最佳化可能會導致模型過擬合。在最近對溶解度預測的研究中，作者從不同的數據源收集了七個熱力學和動力學溶解度數據集。他們使用了最先進的基於圖形的方法，並比較了使用不同的數據清洗協議和超參數最佳化為每個數據集開發的模型。在我們的研究中，我們表明超參數最佳化並非總是會產生更好的模型，這可能是由於在使用相同的統計測量時發生過擬合。可以使用預設的超參數計算類似的結果，從而將計算工作量減少約 10,000 倍。我們還通過添加基於笑容的自然語言處理的表示學習方法（稱為 Transformer CNN）來擴展先前的分析。我們表明，在使用完全相同的協議對所有分析的集合進行分析時，Transformer CNN 在 28 個成對比較中有 26 個比較比基於圖形的方法提供了更好的結果，而與其他方法相比，所用的時間只是很小的一部分。最後但並非最不重要的是，我們強調了使用完全相同的統計測量來比較計算結果的重要性。

##### **Metaheuristic Enhanced with Feature-Based Guidance and Diversity Management for Solving the Capacitated Vehicle Routing Problem**
2407.20777v1 by Bachtiar Herdianto, Romain Billot, Flavien Lucas, Marc Sevaux

We propose a metaheuristic algorithm enhanced with feature-based guidance
that is designed to solve the Capacitated Vehicle Routing Problem (CVRP). To
formulate the proposed guidance, we developed and explained a supervised
Machine Learning (ML) model, that is used to formulate the guidance and control
the diversity of the solution during the optimization process. We propose a
metaheuristic algorithm combining neighborhood search and a novel mechanism of
hybrid split and path relinking to implement the proposed guidance. The
proposed guidance has proven to give a statistically significant improvement to
the proposed metaheuristic algorithm when solving CVRP. Moreover, the proposed
guided metaheuristic is also capable of producing competitive solutions among
state-of-the-art metaheuristic algorithms.

摘要：我們提出了一種增強型元啟發式演算法，其中包含基於特徵的引導，旨在解決容量限制載具路徑問題 (CVRP)。為了制定建議的引導，我們開發並解釋了一個監督式機器學習 (ML) 模型，用於制定引導並控制最佳化過程中解的多樣性。我們提出了一種元啟發式演算法，結合鄰域搜尋和混合分割和路徑重新連結的新機制來實作建議的引導。建議的引導已被證明在解決 CVRP 時，可以顯著改善建議的元啟發式演算法。此外，建議的引導式元啟發式演算法也能够在最先進的元啟發式演算法中產生具有競爭力的解。

##### **Interpretable Pre-Trained Transformers for Heart Time-Series Data**
2407.20775v1 by Harry J. Davies, James Monsen, Danilo P. Mandic

Decoder-only transformers are the backbone of the popular generative
pre-trained transformer (GPT) series of large language models. In this work, we
apply the same framework to periodic heart time-series data to create two
pre-trained general purpose cardiac models, namely PPG-PT and ECG-PT. We
demonstrate that both such pre-trained models are fully interpretable. This is
achieved firstly through aggregate attention maps which show that the model
focuses on similar points in previous cardiac cycles in order to make
predictions and gradually broadens its attention in deeper layers. Next, tokens
with the same value, that occur at different distinct points in the ECG and PPG
cycle, form separate clusters in high dimensional space based on their phase as
they propagate through the transformer blocks. Finally, we highlight that
individual attention heads respond to specific physiologically relevent
features, such as the dicrotic notch in PPG and the P-wave in ECG. It is also
demonstrated that these pre-trained models can be easily fine-tuned for tasks
such as classification of atrial fibrillation. In this specific example, the
fine-tuning took 11 minutes of computer time, and achieved a
leave-one-subject-out AUCs of 0.99 and 0.93 for ECG and PPG respectively.
Importantly, these fine-tuned models are also fully explainable, with attention
shifting to regions in the context that are strongly indicative of atrial
fibrillation.

摘要：僅解碼器Transformer是大型語言模型的熱門生成預訓練Transformer (GPT) 系列的骨幹。在這項工作中，我們將相同的架構應用於週期性心臟時間序列數據，以建立兩個預訓練的一般用途心臟模型，即 PPG-PT 和 ECG-PT。我們證明這兩個預訓練模型都是完全可解釋的。首先，這是透過總計注意力圖實現的，該圖顯示模型關注於先前心臟週期中的相似點，以進行預測，並逐漸擴展其在更深層中的注意力。接下來，在 ECG 和 PPG 週期中不同特定點出現的具有相同值的符號，會根據它們在Transformer區塊中傳播時的相位，在高維空間中形成獨立的群集。最後，我們強調個別注意力頭部會對特定的生理相關特徵做出反應，例如 PPG 中的二尖凹口和 ECG 中的 P 波。它也證明了這些預訓練模型可以輕鬆地微調，以執行分類心房顫動等任務。在這個特定範例中，微調耗時 11 分鐘，並且分別為 ECG 和 PPG 達到了 0.99 和 0.93 的留一受試者法 AUC。重要的是，這些微調模型也完全可以解釋，注意力會轉移到脈絡中強烈指示心房顫動的區域。

##### **OmniBal: Towards Fast Instruct-tuning for Vision-Language Models via Omniverse Computation Balance**
2407.20761v1 by Yongqiang Yao, Jingru Tan, Jiahao Hu, Feizhao Zhang, Xin Jin, Bo Li, Ruihao Gong, Pengfei Liu

Recently, vision-language instruct-tuning models have made significant
progress due to their more comprehensive understanding of the world. In this
work, we discovered that large-scale 3D parallel training on those models leads
to an imbalanced computation load across different devices. The vision and
language parts are inherently heterogeneous: their data distribution and model
architecture differ significantly, which affects distributed training
efficiency. We rebalanced the computational loads from data, model, and memory
perspectives to address this issue, achieving more balanced computation across
devices. These three components are not independent but are closely connected,
forming an omniverse balanced training framework. Specifically, for the data,
we grouped instances into new balanced mini-batches within and across devices.
For the model, we employed a search-based method to achieve a more balanced
partitioning. For memory optimization, we adaptively adjusted the
re-computation strategy for each partition to utilize the available memory
fully. We conducted extensive experiments to validate the effectiveness of our
method. Compared with the open-source training code of InternVL-Chat, we
significantly reduced GPU days, achieving about 1.8x speed-up. Our method's
efficacy and generalizability were further demonstrated across various models
and datasets. Codes will be released at https://github.com/ModelTC/OmniBal.

摘要：近期，视觉语言指令调优模型因其对世界的更全面理解而取得了重大进展。在这项工作中，我们发现对这些模型进行大规模 3D 并行训练会导致不同设备之间的计算负载不平衡。视觉和语言部分本质上是异构的：它们的数据分布和模型架构差异很大，这会影响分布式训练效率。我们从数据、模型和内存的角度重新平衡了计算负载以解决此问题，从而在设备之间实现了更平衡的计算。这三个组件不是独立的，而是紧密连接的，形成了一个全宇宙平衡训练框架。具体来说，对于数据，我们将实例分组到设备内部和设备之间的新的平衡迷你批次中。对于模型，我们采用了一种基于搜索的方法来实现更平衡的分区。对于内存优化，我们自适应地调整了每个分区的重新计算策略，以充分利用可用内存。我们进行了广泛的实验来验证我们方法的有效性。与 InternVL-Chat 的开源训练代码相比，我们显着减少了 GPU 天数，实现了约 1.8 倍的加速。我们方法的有效性和普遍性在各种模型和数据集上得到了进一步证明。代码将在 https://github.com/ModelTC/OmniBal 上发布。

##### **SynthVLM: High-Efficiency and High-Quality Synthetic Data for Vision Language Models**
2407.20756v1 by Zheng Liu, Hao Liang, Wentao Xiong, Qinhan Yu, Conghui He, Bin Cui, Wentao Zhang

Recently, with the rise of web images, managing and understanding large-scale
image datasets has become increasingly important. Vision Large Language Models
(VLLMs) have recently emerged due to their robust vision-understanding
capabilities. However, training these models requires vast amounts of data,
posing challenges to efficiency, effectiveness, data quality, and privacy. In
this paper, we introduce SynthVLM, a novel data synthesis pipeline for VLLMs.
Unlike existing methods that generate captions from images, SynthVLM employs
advanced diffusion models and high-quality captions to automatically generate
and select high-resolution images from captions, creating precisely aligned
image-text pairs. Leveraging these pairs, we achieve state-of-the-art (SoTA)
performance on various vision question answering tasks, maintaining high
alignment quality and preserving advanced language abilities. Moreover,
SynthVLM surpasses traditional GPT-4 Vision-based caption generation methods in
performance while significantly reducing computational overhead. Crucially, our
method's reliance on purely generated data ensures the preservation of privacy,
achieving SoTA performance with just 100k data points (only 18% of the official
dataset size).

摘要：<paragraph>最近，隨著網路影像的興起，管理和理解大規模影像資料集變得越來越重要。視覺大型語言模型 (VLLM) 近期因其強大的視覺理解能力而備受矚目。然而，訓練這些模型需要大量的資料，對效率、效能、資料品質和隱私都提出了挑戰。在本文中，我們介紹了 SynthVLM，一種用於 VLLM 的新資料合成管道。與從影像產生標題的現有方法不同，SynthVLM 採用先進的擴散模型和高品質標題，從標題自動產生並選擇高解析度影像，建立精確對齊的影像文字配對。透過利用這些配對，我們在各種視覺問題解答任務中達到了最先進 (SoTA) 的效能，維持了高對齊品質並保留了先進的語言能力。此外，SynthVLM 在效能上超越了傳統的 GPT-4 視覺化標題產生方法，同時大幅降低了運算開銷。至關重要的是，我們的方法依賴於純粹產生的資料，確保了隱私的保護，僅使用 10 萬個資料點（僅為官方資料集大小的 18%）就達到了 SoTA 效能。</paragraph>

##### **Efficient Quantum One-Class Support Vector Machines for Anomaly Detection Using Randomized Measurements and Variable Subsampling**
2407.20753v1 by Michael Kölle, Afrae Ahouzi, Pascal Debus, Elif Çetiner, Robert Müller, Daniëlle Schuman, Claudia Linnhoff-Popien

Quantum one-class support vector machines leverage the advantage of quantum
kernel methods for semi-supervised anomaly detection. However, their quadratic
time complexity with respect to data size poses challenges when dealing with
large datasets. In recent work, quantum randomized measurements kernels and
variable subsampling were proposed, as two independent methods to address this
problem. The former achieves higher average precision, but suffers from
variance, while the latter achieves linear complexity to data size and has
lower variance. The current work focuses instead on combining these two
methods, along with rotated feature bagging, to achieve linear time complexity
both to data size and to number of features. Despite their instability, the
resulting models exhibit considerably higher performance and faster training
and testing times.

摘要：量子一类支持向量机利用量子核方法的优势进行半监督异常检测。然而，它们关于数据大小的二次时间复杂度在处理大型数据集时提出了挑战。在最近的工作中，提出了量子随机测量核和可变子采样，作为解决此问题的两种独立方法。前者实现了更高的平均精度，但存在方差，而后者实现了关于数据大小的线性复杂度，并且具有较低的方差。当前工作则专注于将这两种方法与旋转特征袋装相结合，以实现关于数据大小和特征数量的线性时间复杂度。尽管它们不稳定，但由此产生的模型表现出明显更高的性能，以及更快的训练和测试时间。

##### **JaColBERTv2.5: Optimising Multi-Vector Retrievers to Create State-of-the-Art Japanese Retrievers with Constrained Resources**
2407.20750v1 by Benjamin Clavié

Neural Information Retrieval has advanced rapidly in high-resource languages,
but progress in lower-resource ones such as Japanese has been hindered by data
scarcity, among other challenges. Consequently, multilingual models have
dominated Japanese retrieval, despite their computational inefficiencies and
inability to capture linguistic nuances. While recent multi-vector monolingual
models like JaColBERT have narrowed this gap, they still lag behind
multilingual methods in large-scale evaluations. This work addresses the
suboptimal training methods of multi-vector retrievers in lower-resource
settings, focusing on Japanese. We systematically evaluate and improve key
aspects of the inference and training settings of JaColBERT, and more broadly,
multi-vector models. We further enhance performance through a novel checkpoint
merging step, showcasing it to be an effective way of combining the benefits of
fine-tuning with the generalization capabilities of the original checkpoint.
Building on our analysis, we introduce a novel training recipe, resulting in
the JaColBERTv2.5 model. JaColBERTv2.5, with only 110 million parameters and
trained in under 15 hours on 4 A100 GPUs, significantly outperforms all
existing methods across all common benchmarks, reaching an average score of
0.754, significantly above the previous best of 0.720. To support future
research, we make our final models, intermediate checkpoints and all data used
publicly available.

摘要：神經資訊檢索在高資源語言中已快速進展，
但日語等低資源語言的進展受到資料
稀少等挑戰所阻礙。因此，多語言模型主導了日語檢索，儘管它們在計算上效率低下，且無法捕捉語言上的細微差別。雖然最近的多向量單語模型，如 JaColBERT，縮小了這個差距，但它們在大型評估中仍然落後於多語言方法。這項工作探討了低資源環境中多向量檢索器的次優訓練方法，重點放在日語上。我們系統性地評估和改進了 JaColBERT 的推論和訓練設定，更廣泛地說，還有多向量模型。我們進一步透過一個新穎的檢查點合併步驟來增強效能，展示了這是一種結合微調優點與原始檢查點的概括能力的有效方法。根據我們的分析，我們引入了一個新穎的訓練配方，產生了 JaColBERTv2.5 模型。JaColBERTv2.5 僅有 1.1 億個參數，且在 4 個 A100 GPU 上不到 15 小時內訓練完成，在所有常見基準上都顯著優於所有現有方法，達到 0.754 的平均分數，顯著高於先前的最佳分數 0.720。為了支持未來的研究，我們公開了我們的最終模型、中間檢查點和所有使用資料。

##### **Meltemi: The first open Large Language Model for Greek**
2407.20743v1 by Leon Voukoutis, Dimitris Roussis, Georgios Paraskevopoulos, Sokratis Sofianopoulos, Prokopis Prokopidis, Vassilis Papavasileiou, Athanasios Katsamanis, Stelios Piperidis, Vassilis Katsouros

We describe the development and capabilities of Meltemi 7B, the first open
Large Language Model for the Greek language. Meltemi 7B has 7 billion
parameters and is trained on a 40 billion token Greek corpus. For the
development of Meltemi 7B, we adapt Mistral, by continuous pretraining on the
Greek Corpus. Meltemi 7B contains up-to-date information up to September 2023.
Furthermore, we have translated and curated a Greek instruction corpus, which
has been used for the instruction-tuning of a chat model, named Meltemi 7B
Instruct. Special care has been given to the alignment and the removal of toxic
content for the Meltemi 7B Instruct. The developed models are evaluated on a
broad set of collected evaluation corpora, and examples of prompts and
responses are presented. Both Meltemi 7B and Meltemi 7B Instruct are available
at https://huggingface.co/ilsp under the Apache 2.0 license.

摘要：我們描述了 Meltemi 7B 的開發和功能，這是第一個開放的希臘語大型語言模型。Meltemi 7B 有 70 億個參數，並在 400 億個希臘語語料庫令牌上進行訓練。對於 Meltemi 7B 的開發，我們透過在希臘語語料庫上持續預訓練來改編 Mistral。Meltemi 7B 包含截至 2023 年 9 月的最新資訊。此外，我們翻譯並策劃了一個希臘語指令語料庫，已用於名為 Meltemi 7B Instruct 的聊天模型的指令微調。已特別注意 Meltemi 7B Instruct 的對齊和移除有毒內容。已在廣泛收集的評量語料庫上評估已開發的模型，並提供提示和回應範例。Meltemi 7B 和 Meltemi 7B Instruct 都可以在 https://huggingface.co/ilsp 下根據 Apache 2.0 授權取得。

##### **Adapting Safe-for-Work Classifier for Malaysian Language Text: Enhancing Alignment in LLM-Ops Framework**
2407.20729v1 by Aisyah Razak, Ariff Nazhan, Kamarul Adha, Wan Adzhar Faiq Adzlan, Mas Aisyah Ahmad, Ammar Azman

As large language models (LLMs) become increasingly integrated into
operational workflows (LLM-Ops), there is a pressing need for effective
guardrails to ensure safe and aligned interactions, including the ability to
detect potentially unsafe or inappropriate content across languages. However,
existing safe-for-work classifiers are primarily focused on English text. To
address this gap for the Malaysian language, we present a novel safe-for-work
text classifier tailored specifically for Malaysian language content. By
curating and annotating a first-of-its-kind dataset of Malaysian text spanning
multiple content categories, we trained a classification model capable of
identifying potentially unsafe material using state-of-the-art natural language
processing techniques. This work represents an important step in enabling safer
interactions and content filtering to mitigate potential risks and ensure
responsible deployment of LLMs. To maximize accessibility and promote further
research towards enhancing alignment in LLM-Ops for the Malaysian context, the
model is publicly released at
https://huggingface.co/malaysia-ai/malaysian-sfw-classifier.

摘要：隨著大型語言模型（LLM）越來越融入作業流程（LLM-Ops），迫切需要有效的防護措施來確保安全且一致的互動，包括跨語言偵測潛在不安全或不適當內容的能力。然而，現有的安全工作分類器主要針對英文文本。為了填補馬來文語言的這個空白，我們提出了一個新穎的安全工作文字分類器，專門針對馬來文語言內容量身打造。通過策劃和註解第一個涵蓋多個內容類別的馬來文文本資料集，我們訓練了一個分類模型，能夠使用最先進的自然語言處理技術識別潛在不安全的材料。這項工作代表著在確保更安全的互動和內容過濾方面邁出的重要一步，以減輕潛在風險並確保負責任地部署 LLM。為了最大化可訪問性並促進進一步研究以增強馬來西亞語境中 LLM-Ops 的對齊，該模型已在 https://huggingface.co/malaysia-ai/malaysian-sfw-classifier 公開發布。

##### **Exploring Loss Landscapes through the Lens of Spin Glass Theory**
2407.20724v1 by Hao Liao, Wei Zhang, Zhanyi Huang, Zexiao Long, Mingyang Zhou, Xiaoqun Wu, Rui Mao, Chi Ho Yeung

In the past decade, significant strides in deep learning have led to numerous
groundbreaking applications. Despite these advancements, the understanding of
the high generalizability of deep learning, especially in such an
over-parametrized space, remains limited. Successful applications are often
considered as empirical rather than scientific achievements. For instance, deep
neural networks' (DNNs) internal representations, decision-making mechanism,
absence of overfitting in an over-parametrized space, high generalizability,
etc., remain less understood. This paper delves into the loss landscape of DNNs
through the lens of spin glass in statistical physics, i.e. a system
characterized by a complex energy landscape with numerous metastable states, to
better understand how DNNs work. We investigated a single hidden layer
Rectified Linear Unit (ReLU) neural network model, and introduced several
protocols to examine the analogy between DNNs (trained with datasets including
MNIST and CIFAR10) and spin glass. Specifically, we used (1) random walk in the
parameter space of DNNs to unravel the structures in their loss landscape; (2)
a permutation-interpolation protocol to study the connection between copies of
identical regions in the loss landscape due to the permutation symmetry in the
hidden layers; (3) hierarchical clustering to reveal the hierarchy among
trained solutions of DNNs, reminiscent of the so-called Replica Symmetry
Breaking (RSB) phenomenon (i.e. the Parisi solution) in analogy to spin glass;
(4) finally, we examine the relationship between the degree of the ruggedness
of the loss landscape of the DNN and its generalizability, showing an
improvement of flattened minima.

摘要：<paragraph>在過去十年中，深度學習領域取得了長足的進展，帶來了許多具有開創性的應用。儘管取得了這些進展，但對深度學習的高泛化性的理解，特別是在這種過度參數化的空間中，仍然有限。成功的應用通常被視為經驗性的，而不是科學性的成就。例如，深度神經網路 (DNN) 的內部表示、決策機制、在過度參數化的空間中沒有過擬合、高泛化性等，仍然知之甚少。本文通過統計物理中的自旋玻璃的視角深入探討了 DNN 的損失函數圖景，即一個具有複雜能量函數圖景並具有許多亞穩態的系統，以更好地理解 DNN 的工作原理。我們研究了一個單隱藏層整流線性單元 (ReLU) 神經網路模型，並引入了幾個協議來檢驗 DNN（使用包括 MNIST 和 CIFAR10 在內的數據集進行訓練）和自旋玻璃之間的類比。具體來說，我們使用了 (1) DNN 參數空間中的隨機遊走來解開其損失函數圖景中的結構；(2) 一個置換插值協議來研究由於隱藏層中的置換對稱性而導致的損失函數圖景中相同區域的副本之間的聯繫；(3) 分層聚類來揭示 DNN 訓練解之間的層次結構，讓人聯想到自旋玻璃中所謂的複製對稱性破缺 (RSB) 現象（即 Parisi 解）；(4) 最後，我們檢查了 DNN 損失函數圖景的崎嶇程度與其泛化性之間的關係，展示了平坦最小值的改進。</paragraph>

##### **Cocobo: Exploring Large Language Models as the Engine for End-User Robot Programming**
2407.20712v1 by Yate Ge, Yi Dai, Run Shan, Kechun Li, Yuanda Hu, Xiaohua Sun

End-user development allows everyday users to tailor service robots or
applications to their needs. One user-friendly approach is natural language
programming. However, it encounters challenges such as an expansive user
expression space and limited support for debugging and editing, which restrict
its application in end-user programming. The emergence of large language models
(LLMs) offers promising avenues for the translation and interpretation between
human language instructions and the code executed by robots, but their
application in end-user programming systems requires further study. We
introduce Cocobo, a natural language programming system with interactive
diagrams powered by LLMs. Cocobo employs LLMs to understand users' authoring
intentions, generate and explain robot programs, and facilitate the conversion
between executable code and flowchart representations. Our user study shows
that Cocobo has a low learning curve, enabling even users with zero coding
experience to customize robot programs successfully.

摘要：終端使用者開發允許一般使用者依據其需求調整服務機器人或應用程式。一種使用者友善的方法是自然語言程式設計。然而，它會遭遇挑戰，例如廣泛的使用者表達空間，以及對除錯和編輯的支援有限，這限制了它在終端使用者程式設計中的應用。大型語言模型 (LLM) 的出現為人類語言指令與機器人執行的程式碼之間的翻譯和詮釋提供了有希望的途徑，但它們在終端使用者程式設計系統中的應用需要進一步研究。我們介紹 Cocobo，一個由 LLM 驅動的互動式圖表自然語言程式設計系統。Cocobo 使用 LLM 來理解使用者的編寫意圖，產生並解釋機器人程式，並促進可執行程式碼和流程圖表示之間的轉換。我們的使用者研究顯示，Cocobo 具有低學習曲線，即使是沒有任何程式設計經驗的使用者也能成功自訂機器人程式。

##### **Industrial-Grade Smart Troubleshooting through Causal Technical Language Processing: a Proof of Concept**
2407.20700v1 by Alexandre Trilla, Ossee Yiboe, Nenad Mijatovic, Jordi Vitrià

This paper describes the development of a causal diagnosis approach for
troubleshooting an industrial environment on the basis of the technical
language expressed in Return on Experience records. The proposed method
leverages the vectorized linguistic knowledge contained in the distributed
representation of a Large Language Model, and the causal associations entailed
by the embedded failure modes and mechanisms of the industrial assets. The
paper presents the elementary but essential concepts of the solution, which is
conceived as a causality-aware retrieval augmented generation system, and
illustrates them experimentally on a real-world Predictive Maintenance setting.
Finally, it discusses avenues of improvement for the maturity of the utilized
causal technology to meet the robustness challenges of increasingly complex
scenarios in the industry.

摘要：本文描述了在經驗回饋記錄中表達的技術語言基礎上，開發了一種因果診斷方法，用於對工業環境進行故障排除。所提出的方法利用了大型語言模型的分布式表示中包含的向量化語言知識，以及工業資產的嵌入故障模式和機制所帶來的因果關聯。本文提出了解決方案的基本但必要的概念，該解決方案被認為是一種因果感知檢索增強生成系統，並在現實世界的預測性維護設置中對其進行了實驗性說明。最後，它討論了所利用因果技術的成熟度改進途徑，以應對工業中日益複雜的場景的魯棒性挑戰。

##### **Boosting Audio Visual Question Answering via Key Semantic-Aware Cues**
2407.20693v1 by Guangyao Li, Henghui Du, Di Hu

The Audio Visual Question Answering (AVQA) task aims to answer questions
related to various visual objects, sounds, and their interactions in videos.
Such naturally multimodal videos contain rich and complex dynamic audio-visual
components, with only a portion of them closely related to the given questions.
Hence, effectively perceiving audio-visual cues relevant to the given questions
is crucial for correctly answering them. In this paper, we propose a
Temporal-Spatial Perception Model (TSPM), which aims to empower the model to
perceive key visual and auditory cues related to the questions. Specifically,
considering the challenge of aligning non-declarative questions and visual
representations into the same semantic space using visual-language pretrained
models, we construct declarative sentence prompts derived from the question
template, to assist the temporal perception module in better identifying
critical segments relevant to the questions. Subsequently, a spatial perception
module is designed to merge visual tokens from selected segments to highlight
key latent targets, followed by cross-modal interaction with audio to perceive
potential sound-aware areas. Finally, the significant temporal-spatial cues
from these modules are integrated to answer the question. Extensive experiments
on multiple AVQA benchmarks demonstrate that our framework excels not only in
understanding audio-visual scenes but also in answering complex questions
effectively. Code is available at https://github.com/GeWu-Lab/TSPM.

摘要：視覺聽覺問答 (AVQA) 任務旨在回答與影片中各種視覺物件、聲音及其互動相關的問題。此類自然多模態影片包含豐富且複雜的動態視聽元件，其中僅有一部分與所提供的問題密切相關。因此，有效感知與所提供問題相關的視聽線索對於正確回答問題至關重要。在本文中，我們提出了一個時空感知模型 (TSPM)，旨在賦能模型以感知與問題相關的主要視覺和聽覺線索。具體來說，考慮到使用視覺語言預訓練模型將非宣告性問題和視覺表示對齊到相同語義空間的挑戰，我們建構了從問題範本中衍生的宣告式句子提示，以協助時間感知模組更好地識別與問題相關的重要區段。隨後，設計一個空間感知模組，以合併來自所選區段的視覺標記，以突顯關鍵潛在目標，然後與音訊進行跨模態互動，以感知潛在的聲音感知區域。最後，整合來自這些模組的重要時空線索以回答問題。在多個 AVQA 基準上進行的廣泛實驗表明，我們的架構不僅在理解視聽場景方面表現出色，而且在有效回答複雜問題方面也表現出色。程式碼可在 https://github.com/GeWu-Lab/TSPM 取得。

##### **CultureVo: The Serious Game of Utilizing Gen AI for Enhancing Cultural Intelligence**
2407.20685v1 by Ajita Agarwala, Anupam Purwar, Viswanadhasai Rao

CultureVo, Inc. has developed the Integrated Culture Learning Suite (ICLS) to
deliver foundational knowledge of world cultures through a combination of
interactive lessons and gamified experiences. This paper explores how
Generative AI powered by open source Large Langauge Models are utilized within
the ICLS to enhance cultural intelligence. The suite employs Generative AI
techniques to automate the assessment of learner knowledge, analyze behavioral
patterns, and manage interactions with non-player characters using real time
learner assessment. Additionally, ICLS provides contextual hint and recommend
course content by assessing learner proficiency, while Generative AI
facilitates the automated creation and validation of educational content.

摘要：CultureVo, Inc. 已開發出整合文化學習套件 (ICLS)，透過互動式課程和遊戲化體驗，提供世界文化的基礎知識。本文探討由開放原始碼大型語言模型驅動的生成式 AI 如何在 ICLS 中被用於提升文化智能。該套件採用生成式 AI 技術，自動化學習者知識評量、分析行為模式，並使用即時學習者評量管理與非玩家角色的互動。此外，ICLS 透過評量學習者的能力提供情境提示和推薦課程內容，而生成式 AI 則促進教育內容的自動化建立和驗證。

##### **RevGNN: Negative Sampling Enhanced Contrastive Graph Learning for Academic Reviewer Recommendation**
2407.20684v1 by Weibin Liao, Yifan Zhu, Yanyan Li, Qi Zhang, Zhonghong Ou, Xuesong Li

Acquiring reviewers for academic submissions is a challenging recommendation
scenario. Recent graph learning-driven models have made remarkable progress in
the field of recommendation, but their performance in the academic reviewer
recommendation task may suffer from a significant false negative issue. This
arises from the assumption that unobserved edges represent negative samples. In
fact, the mechanism of anonymous review results in inadequate exposure of
interactions between reviewers and submissions, leading to a higher number of
unobserved interactions compared to those caused by reviewers declining to
participate. Therefore, investigating how to better comprehend the negative
labeling of unobserved interactions in academic reviewer recommendations is a
significant challenge. This study aims to tackle the ambiguous nature of
unobserved interactions in academic reviewer recommendations. Specifically, we
propose an unsupervised Pseudo Neg-Label strategy to enhance graph contrastive
learning (GCL) for recommending reviewers for academic submissions, which we
call RevGNN. RevGNN utilizes a two-stage encoder structure that encodes both
scientific knowledge and behavior using Pseudo Neg-Label to approximate review
preference. Extensive experiments on three real-world datasets demonstrate that
RevGNN outperforms all baselines across four metrics. Additionally, detailed
further analyses confirm the effectiveness of each component in RevGNN.

摘要：學術投稿審查人推薦是一個具有挑戰性的推薦情境。最近的圖形學習驅動模型在推薦領域取得了顯著進展，但它們在學術審查人推薦任務中的表現可能會受到顯著的假陰性問題影響。這是源於未觀察到的邊緣代表負面樣本的假設。事實上，匿名審查的機制導致審查人和投稿之間的互動曝光不足，與審查人拒絕參與造成的互動相比，導致未觀察到的互動數量更高。因此，探討如何更好地理解學術審查人推薦中未觀察到的互動的負面標記是一個重大的挑戰。本研究旨在解決學術審查人推薦中未觀察到的互動的模糊性質。具體來說，我們提出了一個無監督的偽負標籤策略來增強圖對比學習 (GCL)，以便為學術投稿推薦審查人，我們稱之為 RevGNN。RevGNN 利用一個兩階段編碼器結構，使用偽負標籤對科學知識和行為進行編碼，以近似審查偏好。在三個真實世界數據集上進行的廣泛實驗表明，RevGNN 在四個指標上優於所有基線。此外，詳細的進一步分析證實了 RevGNN 中每個組件的有效性。

##### **Label-Guided Prompt for Multi-label Few-shot Aspect Category Detection**
2407.20673v1 by ChaoFeng Guan, YaoHui Zhu, Yu Bai, LingYun Wang

Multi-label few-shot aspect category detection aims at identifying multiple
aspect categories from sentences with a limited number of training instances.
The representation of sentences and categories is a key issue in this task.
Most of current methods extract keywords for the sentence representations and
the category representations. Sentences often contain many category-independent
words, which leads to suboptimal performance of keyword-based methods. Instead
of directly extracting keywords, we propose a label-guided prompt method to
represent sentences and categories. To be specific, we design label-specific
prompts to represent sentences by combining crucial contextual and semantic
information. Further, the label is introduced into a prompt to obtain category
descriptions by utilizing a large language model. This kind of category
descriptions contain the characteristics of the aspect categories, guiding the
construction of discriminative category prototypes. Experimental results on two
public datasets show that our method outperforms current state-of-the-art
methods with a 3.86% - 4.75% improvement in the Macro-F1 score.

摘要：多標籤小樣本面向分類偵測旨在從具有有限訓練實例的句子中識別多個面向分類。
句子和分類的表示是此任務中的關鍵問題。
大多數當前方法為句子表示和分類表示提取關鍵字。
句子通常包含許多與分類無關的詞彙，這導致基於關鍵字的方法的次優性能。
我們沒有直接提取關鍵字，而是提出了一種標籤引導提示方法來表示句子和分類。
具體來說，我們設計了標籤特定的提示，通過結合關鍵的上下文和語義信息來表示句子。
此外，將標籤引入提示中以利用大型語言模型來獲取類別描述。
這種類別描述包含面向類別的特徵，指導判別類別原型的構建。
在兩個公共數據集上的實驗結果表明，我們的模型優於當前最先進的模型，在宏觀 F1 分數上改進了 3.86% - 4.75%。

##### **Mimicking the Mavens: Agent-based Opinion Synthesis and Emotion Prediction for Social Media Influencers**
2407.20668v1 by Qinglan Wei, Ruiqi Xue, Yutian Wang, Hongjiang Xiao, Yuhao Wang, Xiaoyan Duan

Predicting influencers' views and public sentiment on social media is crucial
for anticipating societal trends and guiding strategic responses. This study
introduces a novel computational framework to predict opinion leaders'
perspectives and the emotive reactions of the populace, addressing the inherent
challenges posed by the unstructured, context-sensitive, and heterogeneous
nature of online communication. Our research introduces an innovative module
that starts with the automatic 5W1H (Where, Who, When, What, Why, and How)
questions formulation engine, tailored to emerging news stories and trending
topics. We then build a total of 60 anonymous opinion leader agents in six
domains and realize the views generation based on an enhanced large language
model (LLM) coupled with retrieval-augmented generation (RAG). Subsequently, we
synthesize the potential views of opinion leaders and predicted the emotional
responses to different events. The efficacy of our automated 5W1H module is
corroborated by an average GPT-4 score of 8.83/10, indicative of high fidelity.
The influencer agents exhibit a consistent performance, achieving an average
GPT-4 rating of 6.85/10 across evaluative metrics. Utilizing the
'Russia-Ukraine War' as a case study, our methodology accurately foresees key
influencers' perspectives and aligns emotional predictions with real-world
sentiment trends in various domains.

摘要：預測影響者觀點和社群媒體上的公眾情緒，對於預測社會趨勢和指導策略回應至關重要。本研究引入了創新的計算架構，用於預測意見領袖的觀點和民眾的情緒反應，並解決了線上溝通非結構化、與脈絡相關且異質的本質所帶來的固有挑戰。我們的研究引入了創新的模組，從自動化的 5W1H（何處、何人、何時、何事、為何和如何）問題表述引擎開始，針對新興新聞故事和熱門話題進行調整。然後，我們在六個領域建立了總共 60 個匿名意見領袖代理，並根據增強的大語言模型 (LLM) 加上檢索增強生成 (RAG) 來實現觀點生成。隨後，我們綜合了意見領袖的潛在觀點，並預測了對不同事件的情緒反應。我們自動化的 5W1H 模組的效能通過 GPT-4 的平均分數 8.83/10 得到證實，這表示高度保真。影響者代理表現一致，在評估指標中獲得 GPT-4 平均評分 6.85/10。以「俄烏戰爭」為案例研究，我們的研究方法準確預見了關鍵影響者的觀點，並將情緒預測與各個領域的真實世界情緒趨勢相結合。

##### **ArabicNLU 2024: The First Arabic Natural Language Understanding Shared Task**
2407.20663v1 by Mohammed Khalilia, Sanad Malaysha, Reem Suwaileh, Mustafa Jarrar, Alaa Aljabari, Tamer Elsayed, Imed Zitouni

This paper presents an overview of the Arabic Natural Language Understanding
(ArabicNLU 2024) shared task, focusing on two subtasks: Word Sense
Disambiguation (WSD) and Location Mention Disambiguation (LMD). The task aimed
to evaluate the ability of automated systems to resolve word ambiguity and
identify locations mentioned in Arabic text. We provided participants with
novel datasets, including a sense-annotated corpus for WSD, called SALMA with
approximately 34k annotated tokens, and the IDRISI-DA dataset with 3,893
annotations and 763 unique location mentions. These are challenging tasks. Out
of the 38 registered teams, only three teams participated in the final
evaluation phase, with the highest accuracy being 77.8% for WSD and the highest
MRR@1 being 95.0% for LMD. The shared task not only facilitated the evaluation
and comparison of different techniques, but also provided valuable insights and
resources for the continued advancement of Arabic NLU technologies.

摘要：這篇論文概述了阿拉伯自然語言理解（ArabicNLU 2024）共享任務，重點關注兩個子任務：詞彙意義消歧（WSD）和地點標記消歧（LMD）。該任務旨在評估自動化系統解決詞彙歧義和識別阿拉伯語文本中所提地點的能力。我們為參與者提供了新穎的資料集，包括一個用於 WSD 的感官註釋語料庫，稱為 SALMA，大約有 34k 個註釋符號，以及 IDRISI-DA 資料集，其中有 3,893 個註釋和 763 個唯一的地點標記。這些都是艱鉅的任務。在 38 個註冊團隊中，只有三個團隊參與了最終評估階段，WSD 的最高準確度為 77.8%，LMD 的最高 MRR@1 為 95.0%。共享任務不僅促进了不同技術的評估和比較，而且還為阿拉伯語 NLU 技術的持續進步提供了寶貴的見解和資源。

##### **Prompt-Driven Contrastive Learning for Transferable Adversarial Attacks**
2407.20657v1 by Hunmin Yang, Jongoh Jeong, Kuk-Jin Yoon

Recent vision-language foundation models, such as CLIP, have demonstrated
superior capabilities in learning representations that can be transferable
across diverse range of downstream tasks and domains. With the emergence of
such powerful models, it has become crucial to effectively leverage their
capabilities in tackling challenging vision tasks. On the other hand, only a
few works have focused on devising adversarial examples that transfer well to
both unknown domains and model architectures. In this paper, we propose a novel
transfer attack method called PDCL-Attack, which leverages the CLIP model to
enhance the transferability of adversarial perturbations generated by a
generative model-based attack framework. Specifically, we formulate an
effective prompt-driven feature guidance by harnessing the semantic
representation power of text, particularly from the ground-truth class labels
of input images. To the best of our knowledge, we are the first to introduce
prompt learning to enhance the transferable generative attacks. Extensive
experiments conducted across various cross-domain and cross-model settings
empirically validate our approach, demonstrating its superiority over
state-of-the-art methods.

摘要：最近的视觉语言基础模型（例如 CLIP）已展示出学习表征的卓越能力，这些表征可以在各种下游任务和领域中转移。随着这些强大模型的出现，有效利用它们的能力来解决具有挑战性的视觉任务变得至关重要。另一方面，只有少数工作专注于设计对抗性示例，这些示例可以很好地转移到未知域和模型架构中。在本文中，我们提出了一种新颖的转移攻击方法，称为 PDCL-Attack，它利用 CLIP 模型来增强由生成模型攻击框架生成的对抗性扰动的可转移性。具体来说，我们通过利用文本的语义表示能力（特别是来自输入图像的真实类标签）来制定有效的提示驱动的特征指导。据我们所知，我们是第一个引入提示学习来增强可转移生成攻击的人。在各种跨域和跨模型设置中进行的广泛实验从经验上验证了我们的方法，证明了它优于最先进的方法。

##### **Prompting Encoder Models for Zero-Shot Classification: A Cross-Domain Study in Italian**
2407.20654v1 by Serena Auriemma, Martina Miliani, Mauro Madeddu, Alessandro Bondielli, Lucia Passaro, Alessandro Lenci

Addressing the challenge of limited annotated data in specialized fields and
low-resource languages is crucial for the effective use of Language Models
(LMs). While most Large Language Models (LLMs) are trained on general-purpose
English corpora, there is a notable gap in models specifically tailored for
Italian, particularly for technical and bureaucratic jargon. This paper
explores the feasibility of employing smaller, domain-specific encoder LMs
alongside prompting techniques to enhance performance in these specialized
contexts. Our study concentrates on the Italian bureaucratic and legal
language, experimenting with both general-purpose and further pre-trained
encoder-only models. We evaluated the models on downstream tasks such as
document classification and entity typing and conducted intrinsic evaluations
using Pseudo-Log-Likelihood. The results indicate that while further
pre-trained models may show diminished robustness in general knowledge, they
exhibit superior adaptability for domain-specific tasks, even in a zero-shot
setting. Furthermore, the application of calibration techniques and in-domain
verbalizers significantly enhances the efficacy of encoder models. These
domain-specialized models prove to be particularly advantageous in scenarios
where in-domain resources or expertise are scarce. In conclusion, our findings
offer new insights into the use of Italian models in specialized contexts,
which may have a significant impact on both research and industrial
applications in the digital transformation era.

摘要：<paragraph>解決專業領域中標註資料有限和低資源語言的挑戰對於語言模型 (LM) 的有效使用至關重要。雖然大多數大型語言模型 (LLM) 都在通用英語語料庫上進行訓練，但專門針對義大利語的模型，特別是針對技術和官僚術語的模型，存在明顯的差距。本文探討了使用較小的、特定於領域的編碼器 LM，並結合提示技術來增強這些專業語境中的效能的可行性。我們的研究集中在義大利官僚和法律語言上，並對通用和進一步預訓練的僅編碼器模型進行實驗。我們在文件分類和實體輸入等下游任務上評估了這些模型，並使用偽對數似然度進行內在評估。結果表明，雖然進一步預訓練的模型在一般知識方面可能表現出較低的穩健性，但它們在特定於領域的任務中表現出優異的適應性，即使在零次學習設定中也是如此。此外，校準技術和領域內言語化的應用顯著增強了編碼器模型的效能。這些特定於領域的模型被證明在領域內資源或專業知識稀缺的情況下特別有利。總之，我們的發現為在專業語境中使用義大利模型提供了新的見解，這可能對數位轉型時代的研究和產業應用產生重大影響。</paragraph>

##### **FACL-Attack: Frequency-Aware Contrastive Learning for Transferable Adversarial Attacks**
2407.20653v1 by Hunmin Yang, Jongoh Jeong, Kuk-Jin Yoon

Deep neural networks are known to be vulnerable to security risks due to the
inherent transferable nature of adversarial examples. Despite the success of
recent generative model-based attacks demonstrating strong transferability, it
still remains a challenge to design an efficient attack strategy in a
real-world strict black-box setting, where both the target domain and model
architectures are unknown. In this paper, we seek to explore a feature
contrastive approach in the frequency domain to generate adversarial examples
that are robust in both cross-domain and cross-model settings. With that goal
in mind, we propose two modules that are only employed during the training
phase: a Frequency-Aware Domain Randomization (FADR) module to randomize
domain-variant low- and high-range frequency components and a
Frequency-Augmented Contrastive Learning (FACL) module to effectively separate
domain-invariant mid-frequency features of clean and perturbed image. We
demonstrate strong transferability of our generated adversarial perturbations
through extensive cross-domain and cross-model experiments, while keeping the
inference time complexity.

摘要：深度神经网络因其对抗性范例固有的可转移性而容易受到安全风险的攻击。尽管最近基于生成模型的攻击取得了成功，展示了很强的可转移性，但在实际严格的黑盒设置中设计一种有效的攻击策略仍然是一个挑战，其中目标域和模型架构都是未知的。在本文中，我们试图在频域中探索一种特征对比方法，以生成在跨域和跨模型设置中都鲁棒的对抗性示例。基于这一目标，我们提出了两个仅在训练阶段使用的模块：一个频率感知域随机化 (FADR) 模块，用于随机化域变体低频和高频分量，以及一个频率增强对比学习 (FACL) 模块，用于有效分离干净图像和扰动图像的域不变中频特征。我们通过广泛的跨域和跨模型实验展示了我们生成的对抗性扰动的强大可转移性，同时保持了推理时间复杂度。

##### **Leveraging Multi-facet Paths for Heterogeneous Graph Representation Learning**
2407.20648v1 by JongWoo Kim, SeongYeub Chu, HyeongMin Park, Bryan Wong, MunYong Yi

Recent advancements in graph neural networks (GNNs) and heterogeneous GNNs
(HGNNs) have advanced node embeddings and relationship learning for various
tasks. However, existing methods often rely on domain-specific predefined
meta-paths, which are coarse-grained and focus solely on aspects like node
type, limiting their ability to capture complex interactions. We introduce
MF2Vec, a model that uses multi-faceted (fine-grained) paths instead of
predefined meta-paths. MF2Vec extracts paths via random walks and generates
multi-faceted vectors, ignoring predefined schemas. This method learns diverse
aspects of nodes and their relationships, constructs a homogeneous network, and
creates node embeddings for classification, link prediction, and clustering.
Extensive experiments show that MF2Vec outperforms existing methods, offering a
more flexible and comprehensive framework for analyzing complex networks. The
code is available at https://anonymous.4open.science/r/MF2Vec-6ABC.

摘要：圖形神經網路 (GNN) 和異質 GNN (HGNN) 的最新進展推動了各種任務的節點嵌入和關係學習。然而，現有方法通常依賴於特定領域的預定義元路徑，這些路徑是粗略的，僅關注節點類型等方面，這限制了它們捕捉複雜交互的能力。我們引入了 MF2Vec，一種使用多面向（細粒度）路徑而不是預定義元路徑的模型。MF2Vec 通過隨機遊走提取路徑並生成多面向向量，忽略預定義的模式。此方法學習節點及其關係的不同方面，構建同質網路，並建立節點嵌入，用於分類、連結預測和聚類。大量的實驗表明，MF2Vec 優於現有方法，為分析複雜網路提供了更靈活和全面的框架。代碼可在 https://anonymous.4open.science/r/MF2Vec-6ABC 獲得。

##### **Autonomous Improvement of Instruction Following Skills via Foundation Models**
2407.20635v1 by Zhiyuan Zhou, Pranav Atreya, Abraham Lee, Homer Walke, Oier Mees, Sergey Levine

Intelligent instruction-following robots capable of improving from
autonomously collected experience have the potential to transform robot
learning: instead of collecting costly teleoperated demonstration data,
large-scale deployment of fleets of robots can quickly collect larger
quantities of autonomous data that can collectively improve their performance.
However, autonomous improvement requires solving two key problems: (i) fully
automating a scalable data collection procedure that can collect diverse and
semantically meaningful robot data and (ii) learning from non-optimal,
autonomous data with no human annotations. To this end, we propose a novel
approach that addresses these challenges, allowing instruction-following
policies to improve from autonomously collected data without human supervision.
Our framework leverages vision-language models to collect and evaluate
semantically meaningful experiences in new environments, and then utilizes a
decomposition of instruction following tasks into (semantic)
language-conditioned image generation and (non-semantic) goal reaching, which
makes it significantly more practical to improve from this autonomously
collected data without any human annotations. We carry out extensive
experiments in the real world to demonstrate the effectiveness of our approach,
and find that in a suite of unseen environments, the robot policy can be
improved significantly with autonomously collected data. We open-source the
code for our semantic autonomous improvement pipeline, as well as our
autonomous dataset of 30.5K trajectories collected across five tabletop
environments.

摘要：具有從自主收集的經驗中改進能力的智慧指令遵循機器人具有轉變機器人學習的潛力：大規模部署機器人機隊無需收集昂貴的遠程操作示範資料，即可快速收集大量自主資料，並能共同提升其效能。
然而，自主改進需要解決兩個關鍵問題：(i) 完全自動化可收集多元且語意有意義的機器人資料的可擴充資料收集程序，以及 (ii) 從沒有人類註解的非最佳自主資料中學習。為此，我們提出了一種新穎的方法來應對這些挑戰，讓指令遵循政策能夠在沒有人類監督的情況下從自主收集的資料中改進。
我們的架構利用視覺語言模型來收集和評估新環境中的語意有意義的經驗，然後將指令遵循任務分解為（語意）語言條件的影像生成和（非語意）目標達成，這使得在沒有任何人類註解的情況下從這些自主收集的資料中改進變得更實用。我們在現實世界中進行了廣泛的實驗，以展示我們方法的有效性，並發現在一系列未見過的環境中，機器人政策可以透過自主收集的資料獲得顯著改進。我們開放原始碼，提供我們的語意自主改進管線，以及我們在五個桌面環境中收集的 30.5K 軌跡的自主資料集。

##### **Decoding Linguistic Representations of Human Brain**
2407.20622v1 by Yu Wang, Heyang Liu, Yuhao Wang, Chuan Xuan, Yixuan Hou, Sheng Feng, Hongcheng Liu, Yusheng Liao, Yanfeng Wang

Language, as an information medium created by advanced organisms, has always
been a concern of neuroscience regarding how it is represented in the brain.
Decoding linguistic representations in the evoked brain has shown
groundbreaking achievements, thanks to the rapid improvement of neuroimaging,
medical technology, life sciences and artificial intelligence. In this work, we
present a taxonomy of brain-to-language decoding of both textual and speech
formats. This work integrates two types of research: neuroscience focusing on
language understanding and deep learning-based brain decoding. Generating
discernible language information from brain activity could not only help those
with limited articulation, especially amyotrophic lateral sclerosis (ALS)
patients but also open up a new way for the next generation's brain-computer
interface (BCI). This article will help brain scientists and deep-learning
researchers to gain a bird's eye view of fine-grained language perception, and
thus facilitate their further investigation and research of neural process and
language decoding.

摘要：語言作為高級生物創造的資訊媒介，其在大腦中如何表徵一直是神經科學關注的議題。
由於神經影像、醫學技術、生命科學和人工智慧的快速進步，解碼誘發大腦中的語言表徵已展現突破性的成就。
在這項工作中，我們提出了一種大腦到語言解碼的分類法，涵蓋文字和語音格式。
這項工作整合了兩種研究類型：專注於語言理解的神經科學和基於深度學習的大腦解碼。
從大腦活動中產生可辨識的語言資訊不僅可以幫助表達能力受限的人，特別是肌萎縮性脊髓側索硬化症 (ALS) 患者，還能為下一代腦電腦介面 (BCI) 開闢一條新路。
這篇文章將幫助大腦科學家和深度學習研究人員對細緻的語言感知有一個全面的了解，進而促進他們進一步探討和研究神經過程和語言解碼。

##### **Questionnaires for Everyone: Streamlining Cross-Cultural Questionnaire Adaptation with GPT-Based Translation Quality Evaluation**
2407.20608v1 by Otso Haavisto, Robin Welsch

Adapting questionnaires to new languages is a resource-intensive process
often requiring the hiring of multiple independent translators, which limits
the ability of researchers to conduct cross-cultural research and effectively
creates inequalities in research and society. This work presents a prototype
tool that can expedite the questionnaire translation process. The tool
incorporates forward-backward translation using DeepL alongside GPT-4-generated
translation quality evaluations and improvement suggestions. We conducted two
online studies in which participants translated questionnaires from English to
either German (Study 1; n=10) or Portuguese (Study 2; n=20) using our
prototype. To evaluate the quality of the translations created using the tool,
evaluation scores between conventionally translated and tool-supported versions
were compared. Our results indicate that integrating LLM-generated translation
quality evaluations and suggestions for improvement can help users
independently attain results similar to those provided by conventional,
non-NLP-supported translation methods. This is the first step towards more
equitable questionnaire-based research, powered by AI.

摘要：將問卷改編為新語言需要大量資源，通常需要聘請多位獨立翻譯人員，這限制了研究人員進行跨文化研究的能力，並有效地在研究和社會中造成不平等。這項工作提出了一個原型工具，可以加快問卷翻譯過程。該工具結合了使用 DeepL 的正向反向翻譯以及 GPT-4 生成的翻譯品質評估和改進建議。我們進行了兩項線上研究，參與者使用我們的原型將問卷從英文翻譯成德文（研究 1；n=10）或葡萄牙文（研究 2；n=20）。為了評估使用該工具建立的翻譯品質，我們比較了傳統翻譯版本和工具支援版本的評分。我們的結果表明，整合 LLM 生成的翻譯品質評估和改進建議，可以幫助使用者獨立獲得與傳統、非 NLP 支援翻譯方法所提供的結果類似的結果。這是由 AI 支援的更公平問卷研究的第一步。

##### **Harvesting Textual and Structured Data from the HAL Publication Repository**
2407.20595v1 by Francis Kulumba, Wissam Antoun, Guillaume Vimont, Laurent Romary

HAL (Hyper Articles en Ligne) is the French national publication repository,
used by most higher education and research organizations for their open science
policy. As a digital library, it is a rich repository of scholarly documents,
but its potential for advanced research has been underutilized. We present
HALvest, a unique dataset that bridges the gap between citation networks and
the full text of papers submitted on HAL. We craft our dataset by filtering HAL
for scholarly publications, resulting in approximately 700,000 documents,
spanning 34 languages across 13 identified domains, suitable for language model
training, and yielding approximately 16.5 billion tokens (with 8 billion in
French and 7 billion in English, the most represented languages). We transform
the metadata of each paper into a citation network, producing a directed
heterogeneous graph. This graph includes uniquely identified authors on HAL, as
well as all open submitted papers, and their citations. We provide a baseline
for authorship attribution using the dataset, implement a range of
state-of-the-art models in graph representation learning for link prediction,
and discuss the usefulness of our generated knowledge graph structure.

摘要：HAL（線上超連結文章）是法國國家出版物資料庫，
大多數高等教育和研究組織都使用它來制定開放科學
政策。作為一個數位圖書館，它是一個豐富的學術文件資料庫，
但它在進階研究的潛力尚未被充分利用。我們提出
HALvest，一個獨特的資料集，它彌補了引文網路和
在 HAL 上提交的論文全文之間的差距。我們透過篩選 HAL
中的學術出版品來建立我們的資料集，最後得到約 70 萬份文件，
涵蓋 13 個已識別領域的 34 種語言，適合語言模型
訓練，並產生約 165 億個詞彙（其中法文有 80 億個，
英文有 70 億個，是最具代表性的語言）。我們將
每篇論文的元資料轉換成引文網路，產生一個有向
異質圖形。此圖形包含在 HAL 上唯一識別的作者，以及
所有公開提交的論文及其引文。我們提供一個基準
使用資料集進行作者歸屬，實作一系列
最先進的圖形表示學習模型進行連結預測，
並討論我們產生的知識圖形結構的實用性。

##### **Enhancing Agricultural Machinery Management through Advanced LLM Integration**
2407.20588v1 by Emily Johnson, Noah Wilson

The integration of artificial intelligence into agricultural practices,
specifically through Consultation on Intelligent Agricultural Machinery
Management (CIAMM), has the potential to revolutionize efficiency and
sustainability in farming. This paper introduces a novel approach that
leverages large language models (LLMs), particularly GPT-4, combined with
multi-round prompt engineering to enhance decision-making processes in
agricultural machinery management. We systematically developed and refined
prompts to guide the LLMs in generating precise and contextually relevant
outputs. Our approach was evaluated using a manually curated dataset from
various online sources, and performance was assessed with accuracy and GPT-4
Scores. Comparative experiments were conducted using LLama-2-70B, ChatGPT, and
GPT-4 models, alongside baseline and state-of-the-art methods such as Chain of
Thought (CoT) and Thought of Thought (ThoT). The results demonstrate that our
method significantly outperforms these approaches, achieving higher accuracy
and relevance in generated responses. This paper highlights the potential of
advanced prompt engineering techniques in improving the robustness and
applicability of AI in agricultural contexts.

摘要：將人工智慧整合至農業實務中，特別是透過諮詢智慧農業機械管理（CIAMM），有潛力革新農業中的效率和永續性。這篇論文介紹了一種創新的方法，它利用大型語言模型（LLM），特別是 GPT-4，結合多輪提示工程，以增強農業機械管理中的決策過程。我們系統性地開發並改善提示，以引導 LLM 產生精確且與情境相關的輸出。我們的做法使用從各種線上來源手動策劃的資料集進行評估，並以準確度和 GPT-4 分數評估效能。我們使用 LLama-2-70B、ChatGPT 和 GPT-4 模型，以及基線和最新方法（例如思想鏈（CoT）和思想的思想（ThoT））進行比較實驗。結果顯示，我們的方法顯著優於這些方法，在產生的回應中獲得更高的準確度和相關性。這篇論文強調了進階提示工程技術在改善農業情境中 AI 的穩健性和適用性方面的潛力。

##### **Pruning Large Language Models with Semi-Structural Adaptive Sparse Training**
2407.20584v1 by Weiyu Huang, Guohao Jian, Yuezhou Hu, Jun Zhu, Jianfei Chen

Transformer-based Large Language Models (LLMs) have demonstrated remarkable
success across various challenging tasks. However, the deployment of LLMs is
hindered by their substantial parameter count and memory consumption. Recently,
numerous studies have attempted to compress LLMs by pruning them using
training-free methods. However, these pruned models often experience
significant performance degradation on complex tasks. To address this issue, we
propose a novel training pipeline for semi-structured sparse models, named
Adaptive Sparse Trainer (AST). By distilling the knowledge stored in its dense
counterpart, we prevent the sparse model from overfitting and ensure a stable
training process. Moreover, AST allows the model to adaptively select better
lottery tickets (e.g., masks) during training. Additionally, we discovered that
adding extra well-initialized parameters can further enhance model performance
with only a small increase in memory footprint. Our method significantly
narrows the performance gap between dense and sparse models while maintaining
limited computational cost. Furthermore, when combined with existing
quantization methods, AST can compress language models by up to 16x compared to
dense FP32 precision models with minimal performance loss. AST outperforms
previous state-of-the-art methods by reducing the zero-shot accuracy gap
between dense and semi-structured sparse models to 1.12% across multiple
zero-shot tasks on Llama2-7B, using less than 0.4% of the pretraining tokens.

摘要：<paragraph>基於 Transformer 的大型語言模型 (LLM) 已在各種具挑戰性的任務中展現出非凡的成功。然而，LLM 的部署受到其龐大的參數數量和記憶體消耗的阻礙。最近，許多研究嘗試透過使用無需訓練的方法剪枝來壓縮 LLM。然而，這些剪枝模型在複雜任務中經常會遭遇顯著的效能下降。為了解決這個問題，我們提出了一個名為自適應稀疏訓練器 (AST) 的半結構稀疏模型的新訓練管道。透過萃取儲存在其稠密對應模型中的知識，我們可以防止稀疏模型過度擬合並確保穩定的訓練過程。此外，AST 允許模型在訓練期間自適應地選擇更好的樂透彩券（例如遮罩）。此外，我們發現加入額外的良好初始化參數可以在僅小幅增加記憶體使用量的狀況下進一步提升模型效能。我們的模型大幅縮小了稠密模型和稀疏模型之間的效能差距，同時維持有限的運算成本。此外，AST 結合現有的量化方法後，與稠密 FP32 精度模型相比，可以將語言模型壓縮至 16 倍，效能損失卻極小。AST 的表現優於先前的最先進方法，將 Llama2-7B 上多個零次學習任務中稠密模型和半結構稀疏模型之間的零次學習準確度差距縮小至 1.12%，使用的預訓練代幣不到 0.4%。</paragraph>

##### **Image-based Detection of Segment Misalignment in Multi-mirror Satellites using Transfer Learning**
2407.20582v1 by C. Tanner Fredieu, Jonathan Tesch, Andrew Kee, David Redding

In this paper, we introduce a system based on transfer learning for detecting
segment misalignment in multimirror satellites, such as future CubeSat designs
and the James Webb Space Telescope (JWST), using image-based methods. When a
mirror segment becomes misaligned due to various environmental factors, such as
space debris, the images can become distorted with a shifted copy of itself
called a "ghost image". To detect whether segments are misaligned, we use
pre-trained, large-scale image models trained on the Fast Fourier Transform
(FFT) of patches of satellite images in grayscale. Multi-mirror designs can use
any arbitrary number of mirrors. For our purposes, the tests were performed on
simulated CubeSats with 4, 6, and 8 segments. For system design, we took this
into account when we want to know when a satellite has a misaligned segment and
how many segments are misaligned. The intensity of the ghost image is directly
proportional to the number of segments misaligned. Models trained for intensity
classification attempted to classify N-1 segments. Across eight classes, binary
models were able to achieve a classification accuracy of 98.75%, and models for
intensity classification were able to achieve an accuracy of 98.05%.

摘要：<paragraph>在本文中，我們介紹一個基於轉移學習的系統，用於檢測多鏡面衛星（例如未來的 CubeSat 設計和詹姆斯韋伯太空望遠鏡 (JWST)）中的分段錯位，使用基於圖像的方法。當鏡段由於各種環境因素（例如太空碎片）而錯位時，圖像可能會因其本身的偏移副本（稱為「鬼影」）而失真。為了檢測分段是否錯位，我們使用在灰階衛星圖像補丁的快速傅立葉變換 (FFT) 上訓練的大規模預訓練圖像模型。多鏡面設計可以使用任意數量的鏡面。就我們的目的而言，測試是在模擬的 4、6 和 8 段 CubeSat 上進行的。對於系統設計，當我們想知道衛星何時有錯位分段以及有多少分段錯位時，我們會考慮這一點。鬼影的強度與錯位分段的數量成正比。為強度分類訓練的模型嘗試對 N-1 個分段進行分類。在八個類別中，二元模型能夠實現 98.75% 的分類準確度，而強度分類模型能夠實現 98.05% 的準確度。</paragraph>

##### **Knesset-DictaBERT: A Hebrew Language Model for Parliamentary Proceedings**
2407.20581v1 by Gili Goldin, Shuly Wintner

We present Knesset-DictaBERT, a large Hebrew language model fine-tuned on the
Knesset Corpus, which comprises Israeli parliamentary proceedings. The model is
based on the DictaBERT architecture and demonstrates significant improvements
in understanding parliamentary language according to the MLM task. We provide a
detailed evaluation of the model's performance, showing improvements in
perplexity and accuracy over the baseline DictaBERT model.

摘要：我們提出 Knesset-DictaBERT，一個針對 Knesset 語料庫（包含以色列議會程序）進行微調的大型希伯來語語言模型。該模型基於 DictaBERT 架構，並根據 MLM 任務顯示出在理解議會語言方面有顯著的改進。我們提供了對模型效能的詳細評估，顯示出困惑度和準確度優於基準 DictaBERT 模型。

##### **Comparison of Large Language Models for Generating Contextually Relevant Questions**
2407.20578v1 by Ivo Lodovico Molina, Valdemar Švábenský, Tsubasa Minematsu, Li Chen, Fumiya Okubo, Atsushi Shimada

This study explores the effectiveness of Large Language Models (LLMs) for
Automatic Question Generation in educational settings. Three LLMs are compared
in their ability to create questions from university slide text without
fine-tuning. Questions were obtained in a two-step pipeline: first, answer
phrases were extracted from slides using Llama 2-Chat 13B; then, the three
models generated questions for each answer. To analyze whether the questions
would be suitable in educational applications for students, a survey was
conducted with 46 students who evaluated a total of 246 questions across five
metrics: clarity, relevance, difficulty, slide relation, and question-answer
alignment. Results indicate that GPT-3.5 and Llama 2-Chat 13B outperform Flan
T5 XXL by a small margin, particularly in terms of clarity and question-answer
alignment. GPT-3.5 especially excels at tailoring questions to match the input
answers. The contribution of this research is the analysis of the capacity of
LLMs for Automatic Question Generation in education.

摘要：本研究探討大型語言模型 (LLM) 在教育環境中自動產生問題的有效性。比較了三種 LLM 在不微調的情況下，從大學投影片文字建立問題的能力。問題是透過兩步驟流程取得：首先，使用 Llama 2-Chat 13B 從投影片中擷取答案短語；然後，這三個模型為每個答案產生問題。為了分析這些問題是否適合用於學生的教育應用程式，對 46 名學生進行了一項調查，他們根據五個指標評估了總共 246 個問題：清晰度、相關性、難度、投影片關聯性和問題答案對齊。結果顯示，GPT-3.5 和 Llama 2-Chat 13B 以微小差距勝過 Flan T5 XXL，特別是在清晰度和問題答案對齊方面。GPT-3.5 特別擅長根據輸入答案調整問題。本研究的貢獻在於分析 LLM 在教育中自動產生問題的能力。

##### **CLR-Fact: Evaluating the Complex Logical Reasoning Capability of Large Language Models over Factual Knowledge**
2407.20564v1 by Tianshi Zheng, Jiaxin Bai, Yicheng Wang, Tianqing Fang, Yue Guo, Yauwai Yim, Yangqiu Song

While large language models (LLMs) have demonstrated impressive capabilities
across various natural language processing tasks by acquiring rich factual
knowledge from their broad training data, their ability to synthesize and
logically reason with this knowledge in complex ways remains underexplored. In
this work, we present a systematic evaluation of state-of-the-art LLMs' complex
logical reasoning abilities through a novel benchmark of automatically
generated complex reasoning questions over general domain and biomedical
knowledge graphs. Our extensive experiments, employing diverse in-context
learning techniques, reveal that LLMs excel at reasoning over general world
knowledge but face significant challenges with specialized domain-specific
knowledge. We find that prompting with explicit Chain-of-Thought demonstrations
can substantially improve LLM performance on complex logical reasoning tasks
with diverse logical operations. Interestingly, our controlled evaluations
uncover an asymmetry where LLMs display proficiency at set union operations,
but struggle considerably with set intersections - a key building block of
logical reasoning. To foster further work, we will publicly release our
evaluation benchmark and code.

摘要：儘管大型語言模型 (LLM) 已展現出令人印象深刻的能力，可透過從廣泛的訓練資料中獲取豐富的事實知識，執行各種自然語言處理任務，但它們綜合運用並以複雜的方式運用此知識進行邏輯推理的能力仍有待進一步探討。在這項工作中，我們透過一個自動生成的一般領域和生物醫學知識圖表複雜推理問題的新基準，對最先進的 LLM 複雜邏輯推理能力進行系統性評估。我們的廣泛實驗採用多樣化的情境學習技術，揭示出 LLM 擅長對一般世界知識進行推理，但在處理特定領域的專業知識時則面臨重大挑戰。我們發現，使用明確的思考鏈條示範進行提示，可以大幅改善 LLM 在具有多樣化邏輯運算的複雜邏輯推理任務中的表現。有趣的是，我們的受控評估揭露了一個不對稱性，其中 LLM 展現出在集合聯集運算方面的熟練度，但在集合交集方面卻顯得相當吃力，而集合交集正是邏輯推理的關鍵組成部分。為了促進後續研究，我們將公開發布我們的評估基準和程式碼。

##### **Pyramid Coder: Hierarchical Code Generator for Compositional Visual Question Answering**
2407.20563v1 by Ruoyue Shen, Nakamasa Inoue, Koichi Shinoda

Visual question answering (VQA) is the task of providing accurate answers to
natural language questions based on visual input. Programmatic VQA (PVQA)
models have been gaining attention recently. These use large language models
(LLMs) to formulate executable programs that address questions requiring
complex visual reasoning. However, there are challenges in enabling LLMs to
comprehend the usage of image processing modules and generate relevant code. To
overcome these challenges, this paper introduces PyramidCoder, a novel
prompting framework for PVQA models. PyramidCoder consists of three
hierarchical levels, each serving a distinct purpose: query rephrasing, code
generation, and answer aggregation. Notably, PyramidCoder utilizes a single
frozen LLM and pre-defined prompts at each level, eliminating the need for
additional training and ensuring flexibility across various LLM architectures.
Compared to the state-of-the-art PVQA model, our approach improves accuracy by
at least 0.5% on the GQA dataset, 1.4% on the VQAv2 dataset, and 2.9% on the
NLVR2 dataset.

摘要：視覺問答 (VQA) 是一項任務，它根據視覺輸入提供自然語言問題的準確答案。程式化 VQA (PVQA) 模型最近備受關注。這些模型使用大型語言模型 (LLM) 來制定執行程式，解決需要複雜視覺推理的問題。然而，讓 LLM 理解影像處理模組的使用方式並產生相關程式碼存在挑戰。為了克服這些挑戰，本文介紹了 PyramidCoder，這是一個針對 PVQA 模型的新提示框架。PyramidCoder 由三個層級組成，每個層級都有不同的用途：查詢改寫、程式碼產生和答案彙總。特別是，PyramidCoder 在每個層級利用單一的凍結 LLM 和預定義提示，消除了額外訓練的需要，並確保了各種 LLM 架構的靈活性。與最先進的 PVQA 模型相比，我們的做法至少在 GQA 資料集上提高了 0.5% 的準確度，在 VQAv2 資料集上提高了 1.4%，在 NLVR2 資料集上提高了 2.9%。

##### **CELLM: An Efficient Communication in Large Language Models Training for Federated Learning**
2407.20557v1 by Raja Vavekanand, Kira Sam

Federated Learning (FL) is a recent model training paradigm in which client
devices collaboratively train a model without ever aggregating their data.
Crucially, this scheme offers users potential privacy and security benefits by
only ever communicating updates to the model weights to a central server as
opposed to traditional machine learning (ML) training which directly
communicates and aggregates data. However, FL training suffers from statistical
heterogeneity as clients may have differing local data distributions. Large
language models (LLMs) offer a potential solution to this issue of
heterogeneity given that they have consistently been shown to be able to learn
on vast amounts of noisy data. While LLMs are a promising development for
resolving the consistent issue of non-I.I.D. Clients in federated settings
exacerbate two other bottlenecks in FL: limited local computing and expensive
communication. This thesis aims to develop efficient training methods for LLMs
in FL. To this end, we employ two critical techniques in enabling efficient
training. First, we use low-rank adaptation (LoRA) to reduce the computational
load of local model training. Second, we communicate sparse updates throughout
training to significantly cut down on communication costs. Taken together, our
method reduces communication costs by up to 10x over vanilla LoRA and up to 5x
over more complex sparse LoRA baselines while achieving greater utility. We
emphasize the importance of carefully applying sparsity and picking effective
rank and sparsity configurations for federated LLM training.

摘要：聯邦學習 (FL) 是一種新興的模型訓練範例，其中用戶端裝置協作訓練模型，卻從不彙總其資料。至關重要的是，此方案僅透過將模型權重更新傳送至中央伺服器的方式，提供使用者潛在的隱私和安全性優勢，這與直接傳送和彙總資料的傳統機器學習 (ML) 訓練相反。然而，FL 訓練會受到統計異質性的影響，因為用戶端可能擁有不同的本地資料分佈。大型語言模型 (LLM) 為此異質性問題提供了潛在的解決方案，因為它們始終被證明能夠在大量的雜訊資料中學習。儘管 LLM 是解決非 I.I.D. 用戶端一致性問題的有望發展，但聯邦設定中會加劇 FL 的另外兩個瓶頸：有限的本地運算和昂貴的通訊。本論文旨在為 FL 中的 LLM 開發高效的訓練方法。為此，我們採用兩種關鍵技術來實現高效訓練。首先，我們使用低秩適應 (LoRA) 來降低本地模型訓練的運算負載。其次，我們在整個訓練過程中傳送稀疏更新，以大幅降低通訊成本。綜合來說，我們的方法將通訊成本降低了最多 10 倍（相較於原生的 LoRA），並比更複雜的稀疏 LoRA 基準降低了最多 5 倍，同時獲得更高的效用。我們強調仔細應用稀疏性以及挑選有效的秩和稀疏性配置對於聯邦 LLM 訓練的重要性。

##### **Survey of Design Paradigms for Social Robots**
2407.20556v1 by Rita Frieske, Xiaoyu Mo, Yini Fang, Jay Nieles, Bertram E. Shi

The demand for social robots in fields like healthcare, education, and
entertainment increases due to their emotional adaptation features. These
robots leverage multimodal communication, incorporating speech, facial
expressions, and gestures to enhance user engagement and emotional support. The
understanding of design paradigms of social robots is obstructed by the
complexity of the system and the necessity to tune it to a specific task. This
article provides a structured review of social robot design paradigms,
categorizing them into cognitive architectures, role design models, linguistic
models, communication flow, activity system models, and integrated design
models. By breaking down the articles on social robot design and application
based on these paradigms, we highlight the strengths and areas for improvement
in current approaches. We further propose our original integrated design model
that combines the most important aspects of the design of social robots. Our
approach shows the importance of integrating operational, communicational, and
emotional dimensions to create more adaptive and empathetic interactions
between robots and humans.

摘要：由於社交機器人在醫療保健、教育和娛樂等領域的情緒適應功能，對它們的需求也隨之增加。這些機器人利用多模態溝通，結合語音、面部表情和手勢來增強使用者參與度和情緒支持。對社交機器人設計範例的理解受到系統複雜性和根據特定任務調整系統的必要性的阻礙。本文提供了對社交機器人設計範例的結構化回顧，將它們分類為認知架構、角色設計模型、語言模型、溝通流程、活動系統模型和整合設計模型。通過根據這些範例分析社交機器人設計和應用方面的文章，我們突出了當前方法的優點和改進領域。我們進一步提出了我們的原始整合設計模型，該模型結合了社交機器人設計中最重要的方面。我們的做法顯示了整合操作、溝通和情緒層面的重要性，以創造機器人和人類之間更具適應性和同理心的互動。

##### **Contrastive Feedback Mechanism for Simultaneous Speech Translation**
2407.20524v1 by Haotian Tan, Sakriani Sakti

Recent advances in simultaneous speech translation (SST) focus on the
decision policies that enable the use of offline-trained ST models for
simultaneous inference. These decision policies not only control the
quality-latency trade-off in SST but also mitigate the impact of unstable
predictions on translation quality by delaying translation for more context or
discarding these predictions through stable hypothesis detection. However,
these policies often overlook the potential benefits of utilizing unstable
predictions. We introduce the contrastive feedback mechanism (CFM) for SST, a
novel method that leverages these unstable predictions as feedback to improve
translation quality. CFM guides the system to eliminate undesired model
behaviors from these predictions through a contrastive objective. The
experiments on 3 state-of-the-art decision policies across 8 languages in the
MuST-C v1.0 dataset show that CFM effectively improves the performance of SST.

摘要：近來在同時語音翻譯 (SST) 的發展重點在於，讓離線訓練的 ST 模型能夠同時進行推論的決策政策。這些決策政策不僅控制 SST 中品質與延遲的取捨，也透過延後翻譯以獲得更多脈絡或透過穩定的假說偵測來捨棄這些預測，以減輕不穩定預測對翻譯品質的影響。然而，這些政策常常忽略利用不穩定預測的潛在好處。我們為 SST 提出對比回饋機制 (CFM)，這是一種新穎的方法，利用這些不穩定預測作為回饋來提升翻譯品質。CFM 透過對比目標引導系統消除這些預測中不需要的模型行為。在 MuST-C v1.0 資料集中的 8 種語言中，對 3 種最先進的決策政策進行的實驗顯示，CFM 有效提升了 SST 的效能。

##### **DuA: Dual Attentive Transformer in Long-Term Continuous EEG Emotion Analysis**
2407.20519v1 by Yue Pan, Qile Liu, Qing Liu, Li Zhang, Gan Huang, Xin Chen, Fali Li, Peng Xu, Zhen Liang

Affective brain-computer interfaces (aBCIs) are increasingly recognized for
their potential in monitoring and interpreting emotional states through
electroencephalography (EEG) signals. Current EEG-based emotion recognition
methods perform well with short segments of EEG data. However, these methods
encounter significant challenges in real-life scenarios where emotional states
evolve over extended periods. To address this issue, we propose a Dual
Attentive (DuA) transformer framework for long-term continuous EEG emotion
analysis. Unlike segment-based approaches, the DuA transformer processes an
entire EEG trial as a whole, identifying emotions at the trial level, referred
to as trial-based emotion analysis. This framework is designed to adapt to
varying signal lengths, providing a substantial advantage over traditional
methods. The DuA transformer incorporates three key modules: the
spatial-spectral network module, the temporal network module, and the transfer
learning module. The spatial-spectral network module simultaneously captures
spatial and spectral information from EEG signals, while the temporal network
module detects temporal dependencies within long-term EEG data. The transfer
learning module enhances the model's adaptability across different subjects and
conditions. We extensively evaluate the DuA transformer using a
self-constructed long-term EEG emotion database, along with two benchmark EEG
emotion databases. On the basis of the trial-based leave-one-subject-out
cross-subject cross-validation protocol, our experimental results demonstrate
that the proposed DuA transformer significantly outperforms existing methods in
long-term continuous EEG emotion analysis, with an average enhancement of
5.28%.

摘要：情感腦機介面 (aBCIs) 在透過腦電圖 (EEG) 信號監控和詮釋情緒狀態方面的潛力日益受到重視。目前的基於 EEG 的情緒辨識方法在處理短區段 EEG 資料時表現良好。然而，這些方法在情緒狀態在長時間內演化的實際情況中會遭遇重大挑戰。為了解決這個問題，我們提出一個雙重注意力 (DuA) 轉換器架構，用於長期連續 EEG 情緒分析。與基於區段的方法不同，DuA 轉換器將整個 EEG 試驗視為一個整體，在試驗層級辨識情緒，稱為基於試驗的情緒分析。這個架構旨在適應不同的訊號長度，與傳統方法相比具有顯著的優勢。DuA 轉換器包含三個關鍵模組：時空網路模組、時序網路模組和遷移學習模組。時空網路模組同時擷取 EEG 訊號的時空資訊，而時序網路模組則偵測長期 EEG 資料中的時序依賴性。遷移學習模組增強模型在不同受試者和條件下的適應力。我們使用一個自行建構的長期 EEG 情緒資料庫以及兩個基準 EEG 情緒資料庫廣泛評估 DuA 轉換器。根據基於試驗的留一受試者交叉驗證協定，我們的實驗結果證明，所提出的 DuA 轉換器在長期連續 EEG 情緒分析中顯著優於現有方法，平均提升 5.28%。

##### **High-Resolution Spatial Transcriptomics from Histology Images using HisToSGE**
2407.20518v1 by Zhiceng Shi, Shuailin Xue, Fangfang Zhu, Wenwen Min

Spatial transcriptomics (ST) is a groundbreaking genomic technology that
enables spatial localization analysis of gene expression within tissue
sections. However, it is significantly limited by high costs and sparse spatial
resolution. An alternative, more cost-effective strategy is to use deep
learning methods to predict high-density gene expression profiles from
histological images. However, existing methods struggle to capture rich image
features effectively or rely on low-dimensional positional coordinates, making
it difficult to accurately predict high-resolution gene expression profiles. To
address these limitations, we developed HisToSGE, a method that employs a
Pathology Image Large Model (PILM) to extract rich image features from
histological images and utilizes a feature learning module to robustly generate
high-resolution gene expression profiles. We evaluated HisToSGE on four ST
datasets, comparing its performance with five state-of-the-art baseline
methods. The results demonstrate that HisToSGE excels in generating
high-resolution gene expression profiles and performing downstream tasks such
as spatial domain identification. All code and public datasets used in this
paper are available at https://github.com/wenwenmin/HisToSGE and
https://zenodo.org/records/12792163.

摘要：空間轉錄組學 (ST) 是一項創新基因組技術，可對組織切片內的基因表現進行空間定位分析。然而，它受到高成本和稀疏空間解析度顯著限制。一種替代的、更具成本效益的策略是使用深度學習方法從組織學影像預測高密度基因表現輪廓。然而，現有方法難以有效擷取豐富的影像特徵，或依賴低維度位置座標，這使得準確預測高解析度基因表現輪廓變得困難。為了解決這些限制，我們開發了 HisToSGE，這是一種使用病理影像大模型 (PILM) 從組織學影像中擷取豐富影像特徵，並利用特徵學習模組穩健地生成高解析度基因表現輪廓的方法。我們在四個 ST 資料集上評估 HisToSGE，並將其效能與五種最先進的基線方法進行比較。結果表明，HisToSGE 在生成高解析度基因表現輪廓和執行下游任務（例如空間域識別）方面表現出色。本文中使用的所有程式碼和公開資料集都可以在 https://github.com/wenwenmin/HisToSGE 和 https://zenodo.org/records/12792163 找到。

##### **Machine Unlearning in Generative AI: A Survey**
2407.20516v1 by Zheyuan Liu, Guangyao Dou, Zhaoxuan Tan, Yijun Tian, Meng Jiang

Generative AI technologies have been deployed in many places, such as
(multimodal) large language models and vision generative models. Their
remarkable performance should be attributed to massive training data and
emergent reasoning abilities. However, the models would memorize and generate
sensitive, biased, or dangerous information originated from the training data
especially those from web crawl. New machine unlearning (MU) techniques are
being developed to reduce or eliminate undesirable knowledge and its effects
from the models, because those that were designed for traditional
classification tasks could not be applied for Generative AI. We offer a
comprehensive survey on many things about MU in Generative AI, such as a new
problem formulation, evaluation methods, and a structured discussion on the
advantages and limitations of different kinds of MU techniques. It also
presents several critical challenges and promising directions in MU research. A
curated list of readings can be found:
https://github.com/franciscoliu/GenAI-MU-Reading.

摘要：生成式 AI 技術已部署在許多地方，例如（多模態）大型語言模型和視覺生成模型。他們的卓越表現應歸功於大量的訓練資料和新興的推理能力。然而，這些模型會記住並產生來自訓練資料的敏感、有偏見或危險的資訊，特別是來自網路爬蟲的資訊。新的機器遺忘（MU）技術正在開發中，以減少或消除模型中不良的知識及其影響，因為那些專為傳統分類任務而設計的技術無法應用於生成式 AI。我們對生成式 AI 中 MU 的許多事情進行了全面的調查，例如新的問題表述、評估方法，以及對不同種類 MU 技術的優缺點進行結構化討論。它還提出了 MU 研究中的幾個關鍵挑戰和有希望的方向。可以找到精選的閱讀清單：
https://github.com/franciscoliu/GenAI-MU-Reading。

##### **Prompt2DeModel: Declarative Neuro-Symbolic Modeling with Natural Language**
2407.20513v1 by Hossein Rajaby Faghihi, Aliakbar Nafar, Andrzej Uszok, Hamid Karimian, Parisa Kordjamshidi

This paper presents a conversational pipeline for crafting domain knowledge
for complex neuro-symbolic models through natural language prompts. It
leverages large language models to generate declarative programs in the
DomiKnowS framework. The programs in this framework express concepts and their
relationships as a graph in addition to logical constraints between them. The
graph, later, can be connected to trainable neural models according to those
specifications. Our proposed pipeline utilizes techniques like dynamic
in-context demonstration retrieval, model refinement based on feedback from a
symbolic parser, visualization, and user interaction to generate the tasks'
structure and formal knowledge representation. This approach empowers domain
experts, even those not well-versed in ML/AI, to formally declare their
knowledge to be incorporated in customized neural models in the DomiKnowS
framework.

摘要：本文提出了一個對話式管道，透過自然語言提示，為複雜的神經符號模型建立領域知識。它利用大型語言模型在 DomiKnowS 框架中產生宣告式程式。此框架中的程式會將概念及其關係表示為圖形，並在它們之間加上邏輯約束。之後，可以根據這些規格將圖形連接到可訓練的神經模型。我們提出的管道利用動態情境中示範檢索、基於符號解析器回饋的模型精煉、視覺化和使用者互動等技術，以產生任務結構和形式知識表示。這種方法讓領域專家，即使是不熟悉機器學習／人工智慧的人，也能正式宣告他們的知識，並將其納入 DomiKnowS 框架中的自訂神經模型。

##### **Unveiling the Potential of Spiking Dynamics in Graph Representation Learning through Spatial-Temporal Normalization and Coding Strategies**
2407.20508v1 by Mingkun Xu, Huifeng Yin, Yujie Wu, Guoqi Li, Faqiang Liu, Jing Pei, Shuai Zhong, Lei Deng

In recent years, spiking neural networks (SNNs) have attracted substantial
interest due to their potential to replicate the energy-efficient and
event-driven processing of biological neurons. Despite this, the application of
SNNs in graph representation learning, particularly for non-Euclidean data,
remains underexplored, and the influence of spiking dynamics on graph learning
is not yet fully understood. This work seeks to address these gaps by examining
the unique properties and benefits of spiking dynamics in enhancing graph
representation learning. We propose a spike-based graph neural network model
that incorporates spiking dynamics, enhanced by a novel spatial-temporal
feature normalization (STFN) technique, to improve training efficiency and
model stability. Our detailed analysis explores the impact of rate coding and
temporal coding on SNN performance, offering new insights into their advantages
for deep graph networks and addressing challenges such as the oversmoothing
problem. Experimental results demonstrate that our SNN models can achieve
competitive performance with state-of-the-art graph neural networks (GNNs)
while considerably reducing computational costs, highlighting the potential of
SNNs for efficient neuromorphic computing applications in complex graph-based
scenarios.

摘要：近年來，尖峰神經網路 (SNN) 吸引了大量的關注，因為它們具有複製生物神經元節能且事件驅動處理的潛力。儘管如此，SNN 在圖表表示學習中的應用，特別是非歐幾里得數據，仍未得到充分的探討，並且尖峰動態對圖表學習的影響尚未完全了解。這項工作旨在透過探討尖峰動態在增強圖表表示學習中的獨特屬性和優點來解決這些差距。我們提出了一個基於尖峰的圖神經網路模型，它結合了尖峰動態，並透過一種新穎的時空特徵正規化 (STFN) 技術進行增強，以提高訓練效率和模型穩定性。我們詳細的分析探討了速率編碼和時間編碼對 SNN 效能的影響，提供了對其在深度圖形網路中的優勢的新見解，並解決了過平滑問題等挑戰。實驗結果表明，我們的 SNN 模型可以實現與最先進的圖神經網路 (GNN) 相媲美的效能，同時大幅降低運算成本，突顯了 SNN 在複雜的基於圖表的場景中用於高效神經形態運算應用的潛力。

##### **Boosting Efficiency in Task-Agnostic Exploration through Causal Knowledge**
2407.20506v1 by Yupei Yang, Biwei Huang, Shikui Tu, Lei Xu

The effectiveness of model training heavily relies on the quality of
available training resources. However, budget constraints often impose
limitations on data collection efforts. To tackle this challenge, we introduce
causal exploration in this paper, a strategy that leverages the underlying
causal knowledge for both data collection and model training. We, in
particular, focus on enhancing the sample efficiency and reliability of the
world model learning within the domain of task-agnostic reinforcement learning.
During the exploration phase, the agent actively selects actions expected to
yield causal insights most beneficial for world model training. Concurrently,
the causal knowledge is acquired and incrementally refined with the ongoing
collection of data. We demonstrate that causal exploration aids in learning
accurate world models using fewer data and provide theoretical guarantees for
its convergence. Empirical experiments, on both synthetic data and real-world
applications, further validate the benefits of causal exploration.

摘要：模型訓練的有效性嚴重依賴於可用的訓練資源品質。然而，預算限制通常會對資料蒐集工作造成限制。為了應對此挑戰，我們在此論文中引入了因果探索，這是一種利用基礎因果知識進行資料蒐集和模型訓練的策略。我們特別專注於加強任務不可知強化學習領域中世界模型學習的樣本效率和可靠性。在探索階段，代理會主動選擇預期能產生對世界模型訓練最有利的因果洞察的動作。同時，因果知識會隨著持續蒐集資料而被獲取並逐步精煉。我們證明了因果探索有助於使用較少資料學習精確的世界模型，並為其收斂提供理論保證。在合成資料和真實世界應用程式上的實證實驗進一步驗證了因果探索的好處。

##### **A federated large language model for long-term time series forecasting**
2407.20503v1 by Raed Abdel-Sater, A. Ben Hamza

Long-term time series forecasting in centralized environments poses unique
challenges regarding data privacy, communication overhead, and scalability. To
address these challenges, we propose FedTime, a federated large language model
(LLM) tailored for long-range time series prediction. Specifically, we
introduce a federated pre-trained LLM with fine-tuning and alignment
strategies. Prior to the learning process, we employ K-means clustering to
partition edge devices or clients into distinct clusters, thereby facilitating
more focused model training. We also incorporate channel independence and
patching to better preserve local semantic information, ensuring that important
contextual details are retained while minimizing the risk of information loss.
We demonstrate the effectiveness of our FedTime model through extensive
experiments on various real-world forecasting benchmarks, showcasing
substantial improvements over recent approaches. In addition, we demonstrate
the efficiency of FedTime in streamlining resource usage, resulting in reduced
communication overhead.

摘要：長期時間序列預測在集中式環境中會造成獨特的挑戰，包括資料隱私、通訊負擔和可擴充性。為了應對這些挑戰，我們提出 FedTime，一種針對長期時間序列預測量身打造的聯邦大型語言模型 (LLM)。具體而言，我們引入了一個聯邦預先訓練的 LLM，並採用微調和對齊策略。在學習過程中，我們採用 K 平均值分群法將邊緣裝置或客戶端分群到不同的分群中，從而促進更專注的模型訓練。我們還納入了通道獨立性和修補，以更好地保留局部語義資訊，確保保留重要的背景細節，同時將資訊遺失的風險降到最低。我們透過在各種實際預測基準上進行廣泛的實驗，展示了我們的 FedTime 模型的有效性，展示了相較於近期方法有顯著的改進。此外，我們展示了 FedTime 在簡化資源使用方面的效率，從而減少了通訊負擔。

##### **Toward Efficient Permutation for Hierarchical N:M Sparsity on GPUs**
2407.20496v1 by Seungmin Yu, Xiaodie Yi, Hayun Lee, Dongkun Shin

N:M sparsity pruning is a powerful technique for compressing deep neural
networks, utilizing NVIDIA's Sparse Tensor Core technology. This method
benefits from hardware support for sparse indexing, enabling the adoption of
fine-grained sparsity to maintain model accuracy while minimizing the overhead
typically associated with irregular data access. Although restricted to a fixed
level of sparsity due to its reliance on hardware, N:M sparsity can be combined
with coarser sparsity techniques to achieve diverse compression ratios.
Initially, column-wise vector sparsity is applied to a dense model, followed by
row-wise N:M sparsity on the preserved column vectors. We call this multi-level
approach as hierarchical N:M (HiNM) sparsity. Similar to earlier single-level
sparsity techniques, HiNM sparsity necessitates an effective channel
permutation strategy to maximize the accuracy of the compressed networks.
However, it introduces further complexities by requiring the rearrangement of
both input and output channels, addressing challenges such as permutation
sequence, HiNM-sparsity-aware permutation, and maintaining consistency in
channel ordering across layers. In this paper, we introduce a channel
permutation method designed specifically for HiNM sparsity, named
gyro-permutation. This method is crafted to exploit the unique characteristics
of HiNM pruning, incorporating a strategic policy in each permutation phase,
including channel sampling, clustering, and assignment, to circumvent local
minima. Additionally, we have developed a GPU kernel that facilitates
independent layer permutation during the execution of HiNM sparse networks. Our
extensive experimental evaluations on various DNN models demonstrate that our
gyro-permutation significantly enhances the accuracy of HiNM sparse networks,
allowing them to reach performance levels comparable to those of unstructured
sparse networks.

摘要：N:M 稀疏剪枝是一种压缩深度神经网络的强大技术，利用了 NVIDIA 的稀疏张量核技术。这种方法得益于对稀疏索引的硬件支持，从而能够采用细粒度的稀疏性来保持模型准确性，同时最大程度地减少通常与不规则数据访问相关的开销。虽然由于依赖于硬件而限制在固定的稀疏性级别，但 N:M 稀疏性可以与更粗糙的稀疏性技术相结合，以实现不同的压缩比。最初，列向量稀疏性应用于稠密模型，然后在保留的列向量上应用行 N:M 稀疏性。我们将这种多级方法称为分层 N:M (HiNM) 稀疏性。与早期的单级稀疏性技术类似，HiNM 稀疏性需要一种有效的通道置换策略，以最大化压缩网络的准确性。然而，它通过要求重新排列输入和输出通道引入了进一步的复杂性，解决了诸如置换序列、HiNM 稀疏感知置换以及跨层保持通道顺序的一致性等挑战。在本文中，我们介绍了一种专门为 HiNM 稀疏性设计的通道置换方法，称为陀螺置换。该方法旨在利用 HiNM 剪枝的独特特性，在每个置换阶段纳入战略策略，包括通道采样、聚类和分配，以规避局部极小值。此外，我们还开发了一个 GPU 内核，该内核在 HiNM 稀疏网络执行期间促进了独立层置换。我们在各种 DNN 模型上进行的广泛实验评估表明，我们的陀螺置换显著提高了 HiNM 稀疏网络的准确性，使其能够达到与非结构化稀疏网络相当的性能水平。

##### **A2SF: Accumulative Attention Scoring with Forgetting Factor for Token Pruning in Transformer Decoder**
2407.20485v1 by Hyun Rae Jo, Dong Kun Shin

Recently, large language models (LLM) based on transformers are facing memory
bottleneck issues due to KV cache, especially in long sequence handling.
Previous researches proposed KV cache compression techniques that identify
insignificant tokens based on Accumulative Attention Scores and removes their
items from KV cache, noting that only few tokens play an important role in
attention operations. However, we have observed that the existing Accumulative
Attention Score is not suitable for the transformer decoder structure. In the
decoder model, the number of times the Attention Score accumulates varies
depending on the order of token appearance due to the effect of masking,
causing an uneven comparison between tokens. To solve this, we propose
Accumulative Attention Score with Forgetting Factor (A2SF) technique, which
introduces a Forgetting Factor in the Attention Score accumulation process.
A2SF applies a penalty to the past Attention Score generated from old tokens by
repeatedly multiplying the Forgetting Factor to the Attention Score over time.
Therefore, older tokens receive a larger penalty, providing fairness among
different ages of tokens. Through the fair comparison among tokens, we can more
effectively select important tokens. We have verified the accuracy improvement
through A2SF in the OPT and LLaMA models and A2SF improves the accuracy of
LLaMA 2 by up to 7.8% and 5.1% on 1-shot and 0-shot.

摘要：最近，基于 Transformer 的大型语言模型 (LLM) 在长序列处理中，因 KV 缓存而面临内存瓶颈问题。
先前的研究提出了 KV 缓存压缩技术，该技术基于累积注意力分数识别不重要的标记，并从 KV 缓存中删除其项目，因为只有少数标记在注意力操作中发挥重要作用。然而，我们观察到现有的累积注意力分数不适用于 Transformer 解码器结构。在解码器模型中，由于遮蔽效应，注意力分数累积的次数会根据标记出现顺序而有所不同，从而导致标记之间的比较不均匀。为了解决这个问题，我们提出了带有遗忘因子的累积注意力分数 (A2SF) 技术，该技术在注意力分数累积过程中引入了遗忘因子。A2SF 通过反复将遗忘因子乘以注意力分数，对旧标记产生的过去注意力分数施加惩罚。因此，较旧的标记会受到更大的惩罚，从而在不同年龄的标记之间提供公平性。通过在标记之间进行公平比较，我们可以更有效地选择重要的标记。我们通过 A2SF 在 OPT 和 LLaMA 模型中验证了准确性的提高，A2SF 将 LLaMA 2 在 1 次和 0 次中的准确性分别提高了 7.8% 和 5.1%。

##### **CoMMIT: Coordinated Instruction Tuning for Multimodal Large Language Models**
2407.20454v1 by Junda Wu, Xintong Li, Tong Yu, Yu Wang, Xiang Chen, Jiuxiang Gu, Lina Yao, Jingbo Shang, Julian McAuley

Instruction tuning in multimodal large language models (MLLMs) aims to
smoothly integrate a backbone LLM with a pre-trained feature encoder for
downstream tasks. The major challenge is how to efficiently find the synergy
through cooperative learning where LLMs adapt their reasoning abilities in
downstream tasks while feature encoders adjust their encoding to provide more
relevant modal information. In this paper, we analyze the MLLM instruction
tuning from both theoretical and empirical perspectives, where we find
unbalanced learning between the two components, i.e., the feature encoder and
the LLM, can cause diminishing learning gradients that slow the model
convergence and often lead to sub-optimal results due to insufficient learning.
Inspired by our findings, we propose a measurement to quantitatively evaluate
the learning balance, based on which we further design a dynamic learning
scheduler that better coordinates the learning. In addition, we introduce an
auxiliary loss regularization method to promote updating of the generation
distribution of MLLMs considering the learning state of each model component,
which potentially prevents each component from gradient diminishing and enables
a more accurate estimation of the learning balance coefficient. We conduct
experiments with multiple LLM backbones and feature encoders, where our
techniques are model-agnostic and can be generically integrated with various
MLLM backbones. Experiment results on multiple downstream tasks and modalities
in vision and audio, demonstrate the proposed method's better efficiency and
effectiveness in MLLM instruction tuning.

摘要：多模态大型语言模型 (MLLM) 中的指令微调旨在将主干 LLM 与预先训练的功能编码器平滑集成，以用于下游任务。主要挑战是如何通过协作学习有效地找到协同作用，其中 LLM 在下游任务中调整其推理能力，而功能编码器调整其编码以提供更多相关的模态信息。在本文中，我们从理论和经验的角度分析了 MLLM 指令微调，我们发现两个组件（即功能编码器和 LLM）之间的学习不平衡会导致学习梯度减小，从而减慢模型收敛速度，并且由于学习不足，通常会导致次优结果。受我们的发现启发，我们提出了一种度量来定量评估学习平衡，在此基础上，我们进一步设计了一个动态学习调度器，以更好地协调学习。此外，我们引入了一种辅助损失正则化方法来促进 MLLM 生成分布的更新，同时考虑每个模型组件的学习状态，这有可能防止每个组件的梯度减小，并能够更准确地估计学习平衡系数。我们使用多个 LLM 主干和功能编码器进行实验，我们的技术与模型无关，并且可以与各种 MLLM 主干通用集成。在视觉和音频中的多个下游任务和模态上的实验结果证明了所提出的方法在 MLLM 指令微调中具有更好的效率和有效性。

##### **Domain Adaptable Prescriptive AI Agent for Enterprise**
2407.20447v1 by Piero Orderique, Wei Sun, Kristjan Greenewald

Despite advancements in causal inference and prescriptive AI, its adoption in
enterprise settings remains hindered primarily due to its technical complexity.
Many users lack the necessary knowledge and appropriate tools to effectively
leverage these technologies. This work at the MIT-IBM Watson AI Lab focuses on
developing the proof-of-concept agent, PrecAIse, a domain-adaptable
conversational agent equipped with a suite of causal and prescriptive tools to
help enterprise users make better business decisions. The objective is to make
advanced, novel causal inference and prescriptive tools widely accessible
through natural language interactions. The presented Natural Language User
Interface (NLUI) enables users with limited expertise in machine learning and
data science to harness prescriptive analytics in their decision-making
processes without requiring intensive computing resources. We present an agent
capable of function calling, maintaining faithful, interactive, and dynamic
conversations, and supporting new domains.

摘要：儘管因果推論和規範性 AI 有所進展，但由於技術複雜性，其在企業環境中的採用仍受到阻礙。許多使用者缺乏必要的知識和適當的工具來有效利用這些技術。麻省理工學院 IBM Watson AI 實驗室的這項工作專注於開發概念驗證代理 PrecAIse，這是一個具備因果和規範工具套件的領域適應對話代理，以幫助企業使用者做出更好的商業決策。目標是透過自然語言互動讓先進、新穎的因果推論和規範工具廣泛使用。所提出的自然語言使用者介面 (NLUI) 讓機器學習和資料科學專業知識有限的使用者能夠在他們的決策過程中利用規範分析，而不需要密集的運算資源。我們提出了一個代理，它能夠呼叫函數、維護忠實、互動和動態對話，並支援新的領域。

##### **Futga: Towards Fine-grained Music Understanding through Temporally-enhanced Generative Augmentation**
2407.20445v1 by Junda Wu, Zachary Novack, Amit Namburi, Jiaheng Dai, Hao-Wen Dong, Zhouhang Xie, Carol Chen, Julian McAuley

Existing music captioning methods are limited to generating concise global
descriptions of short music clips, which fail to capture fine-grained musical
characteristics and time-aware musical changes. To address these limitations,
we propose FUTGA, a model equipped with fined-grained music understanding
capabilities through learning from generative augmentation with temporal
compositions. We leverage existing music caption datasets and large language
models (LLMs) to synthesize fine-grained music captions with structural
descriptions and time boundaries for full-length songs. Augmented by the
proposed synthetic dataset, FUTGA is enabled to identify the music's temporal
changes at key transition points and their musical functions, as well as
generate detailed descriptions for each music segment. We further introduce a
full-length music caption dataset generated by FUTGA, as the augmentation of
the MusicCaps and the Song Describer datasets. We evaluate the automatically
generated captions on several downstream tasks, including music generation and
retrieval. The experiments demonstrate the quality of the generated captions
and the better performance in various downstream tasks achieved by the proposed
music captioning approach. Our code and datasets can be found in
\href{https://huggingface.co/JoshuaW1997/FUTGA}{\textcolor{blue}{https://huggingface.co/JoshuaW1997/FUTGA}}.

摘要：現有的音樂標題方法僅限於產生簡潔的全局描述，用於描述簡短的音樂片段，無法捕捉細緻的音樂特徵和時間感知的音樂變化。為了解決這些限制，我們提出 FUTGA，一種具備細緻音樂理解能力的模型，通過從生成擴充和時間組成中學習來實現。我們利用現有的音樂標題數據集和大型語言模型 (LLM) 來合成具有結構描述和時間邊界的細緻音樂標題，用於全長歌曲。通過提議的合成數據集進行擴充後，FUTGA 能夠識別音樂在關鍵轉換點的時間變化及其音樂功能，並為每個音樂片段生成詳細的描述。我們進一步介紹了一個由 FUTGA 生成的全長音樂標題數據集，作為 MusicCaps 和 Song Describer 數據集的擴充。我們在幾個下游任務（包括音樂生成和檢索）上評估自動生成的標題。實驗證明了生成標題的品質，以及提出的音樂標題方法在各種下游任務中取得的更好性能。我們的程式碼和數據集可以在 \href{https://huggingface.co/JoshuaW1997/FUTGA}{\textcolor{blue}{https://huggingface.co/JoshuaW1997/FUTGA}} 中找到。

##### **Generating Gender Alternatives in Machine Translation**
2407.20438v1 by Sarthak Garg, Mozhdeh Gheini, Clara Emmanuel, Tatiana Likhomanenko, Qin Gao, Matthias Paulik

Machine translation (MT) systems often translate terms with ambiguous gender
(e.g., English term "the nurse") into the gendered form that is most prevalent
in the systems' training data (e.g., "enfermera", the Spanish term for a female
nurse). This often reflects and perpetuates harmful stereotypes present in
society. With MT user interfaces in mind that allow for resolving gender
ambiguity in a frictionless manner, we study the problem of generating all
grammatically correct gendered translation alternatives. We open source train
and test datasets for five language pairs and establish benchmarks for this
task. Our key technical contribution is a novel semi-supervised solution for
generating alternatives that integrates seamlessly with standard MT models and
maintains high performance without requiring additional components or
increasing inference overhead.

摘要：機器翻譯 (MT) 系統通常會將性別含糊的術語（例如英文術語「the nurse」）翻譯成系統訓練資料中最普遍的性別形式（例如「enfermera」，西班牙文中的女性護士）。這通常反映並延續了社會中存在的有害刻板印象。考量到 MT 使用者介面允許以無摩擦的方式解決性別歧義，我們研究了產生所有文法正確的性別翻譯替代方案的問題。我們公開原始碼訓練和測試五種語言對應的資料集，並為此任務建立基準。我們的主要技術貢獻是一種新穎的半監督解決方案，用於產生與標準 MT 模型無縫整合的替代方案，並在不需額外元件或增加推論負擔的情況下維持高性能。

##### **Through the Looking Glass, and what Horn Clause Programs Found There**
2407.20413v1 by Paul Tarau

Dual Horn clauses mirror key properties of Horn clauses. This paper explores
the ``other side of the looking glass'' to reveal some expected and unexpected
symmetries and their practical uses.
  We revisit Dual Horn clauses as enablers of a form of constructive negation
that supports goal-driven forward reasoning and is valid both
intuitionistically and classically. In particular, we explore the ability to
falsify a counterfactual hypothesis in the context of a background theory
expressed as a Dual Horn clause program.
  With Dual Horn clause programs, by contrast to negation as failure, the
variable bindings in their computed answers provide explanations for the
reasons why a statement is successfully falsified. Moreover, in the
propositional case, by contrast to negation as failure as implemented with
stable models semantics in ASP systems, and similarly to Horn clause programs,
Dual Horn clause programs have polynomial complexity.
  After specifying their execution model with a metainterpreter, we devise a
compilation scheme from Dual Horn clause programs to Horn clause programs,
ensuring their execution with no performance penalty and we design the embedded
SymLP language to support combined Horn clause and Dual Horn clause programs.
  As a (motivating) application, we cast LLM reasoning chains into
propositional Horn and Dual Horn clauses that work together to constructively
prove and disprove goals and enhance Generative AI with explainability of
reasoning chains.

摘要：對偶霍恩子句反映了霍恩子句的主要屬性。本文探討了「鏡子的另一面」以揭示一些預期和未預期的對稱性及其實際用途。
我們重新審視對偶霍恩子句，作為建構式否定的一種形式的啟用器，它支援目標驅動的前向推理，並且在直覺主義和古典主義上都是有效的。特別是，我們探討了在表達為對偶霍恩子句程式的背景理論的背景下，證偽反事實假設的能力。
與否定即失敗相反，透過對偶霍恩子句程式，其計算答案中的變數繫結提供了陳述成功被證偽的原因的說明。此外，在命題情況下，與在 ASP 系統中使用穩定模型語義實作的否定即失敗相反，且與霍恩子句程式類似，對偶霍恩子句程式具有多項式複雜度。
在使用元詮釋器指定其執行模型後，我們設計了一個從對偶霍恩子句程式到霍恩子句程式的編譯方案，確保它們的執行沒有效能損失，並且我們設計了嵌入式 SymLP 語言以支援組合霍恩子句和對偶霍恩子句程式。
作為一個（激勵）應用，我們將 LLM 推理鏈轉換為命題霍恩和對偶霍恩子句，它們共同建構性地證明和反駁目標，並透過推理鏈的可解釋性增強生成式 AI。

##### **Appraisal-Guided Proximal Policy Optimization: Modeling Psychological Disorders in Dynamic Grid World**
2407.20383v1 by Hari Prasad, Chinnu Jacob, Imthias Ahamed T. P

The integration of artificial intelligence across multiple domains has
emphasized the importance of replicating human-like cognitive processes in AI.
By incorporating emotional intelligence into AI agents, their emotional
stability can be evaluated to enhance their resilience and dependability in
critical decision-making tasks. In this work, we develop a methodology for
modeling psychological disorders using Reinforcement Learning (RL) agents. We
utilized Appraisal theory to train RL agents in a dynamic grid world
environment with an Appraisal-Guided Proximal Policy Optimization (AG-PPO)
algorithm. Additionally, we investigated numerous reward-shaping strategies to
simulate psychological disorders and regulate the behavior of the agents. A
comparison of various configurations of the modified PPO algorithm identified
variants that simulate Anxiety disorder and Obsessive-Compulsive Disorder
(OCD)-like behavior in agents. Furthermore, we compared standard PPO with
AG-PPO and its configurations, highlighting the performance improvement in
terms of generalization capabilities. Finally, we conducted an analysis of the
agents' behavioral patterns in complex test environments to evaluate the
associated symptoms corresponding to the psychological disorders. Overall, our
work showcases the benefits of the appraisal-guided PPO algorithm over the
standard PPO algorithm and the potential to simulate psychological disorders in
a controlled artificial environment and evaluate them on RL agents.

摘要：跨多個領域整合人工智慧強調了在人工智慧中複製類人認知過程的重要性。透過將情緒智能納入人工智慧代理中，可以評估它們的情緒穩定性，以增強它們在關鍵決策任務中的復原力和可靠性。在這項工作中，我們開發了一種使用強化學習 (RL) 代理對心理疾病建模的方法。我們利用評估理論在具有評估引導近端策略優化 (AG-PPO) 演算法的動態網格世界環境中訓練 RL 代理。此外，我們研究了許多獎勵塑造策略，以模擬心理疾病並調節代理的行為。比較修改後 PPO 演算法的各種配置，找出模擬代理中焦慮症和強迫症 (OCD) 類似行為的變體。此外，我們將標準 PPO 與 AG-PPO 及其配置進行比較，強調了在泛化能力方面的效能改善。最後，我們對代理在複雜測試環境中的行為模式進行分析，以評估與心理疾病對應的相關症狀。總的來說，我們的研究展示了評估引導 PPO 演算法優於標準 PPO 演算法的優點，以及在受控人工環境中模擬心理疾病並在 RL 代理上評估它們的潛力。

##### **What if Red Can Talk? Dynamic Dialogue Generation Using Large Language Models**
2407.20382v1 by Navapat Nananukul, Wichayaporn Wongkamjan

Role-playing games (RPGs) provide players with a rich, interactive world to
explore. Dialogue serves as the primary means of communication between
developers and players, manifesting in various forms such as guides, NPC
interactions, and storytelling. While most games rely on written scripts to
define the main story and character personalities, player immersion can be
significantly enhanced through casual interactions between characters. With the
advent of large language models (LLMs), we introduce a dialogue filler
framework that utilizes LLMs enhanced by knowledge graphs to generate dynamic
and contextually appropriate character interactions. We test this framework
within the environments of Final Fantasy VII Remake and Pokemon, providing
qualitative and quantitative evidence that demonstrates GPT-4's capability to
act with defined personalities and generate dialogue. However, some flaws
remain, such as GPT-4 being overly positive or more subtle personalities, such
as maturity, tend to be of lower quality compared to more overt traits like
timidity. This study aims to assist developers in crafting more nuanced filler
dialogues, thereby enriching player immersion and enhancing the overall RPG
experience.

摘要：角色扮演遊戲 (RPG) 為玩家提供一個豐富且互動的世界供其探索。對話作為開發者與玩家之間的主要溝通方式，以指南、NPC 互動和說故事等各種形式呈現。雖然大多數遊戲依賴於書面腳本來定義主線故事和角色個性，但透過角色之間的閒聊互動，可以大幅提升玩家的沉浸感。隨著大型語言模型 (LLM) 的出現，我們引入了一個對話填充框架，利用由知識圖譜增強的 LLM 來產生動態且符合情境的對話互動。我們在 Final Fantasy VII Remake 和寶可夢的環境中測試了這個框架，提供了定性和定量的證據，證明了 GPT-4 具備以定義好的個性行動並產生對話的能力。然而，仍存在一些缺陷，例如 GPT-4 過於正面，或者較為細微的個性，例如成熟度，往往品質低於較明顯的特質，例如膽怯。本研究旨在協助開發者打造更細緻的填充對話，從而豐富玩家的沉浸感並提升整體 RPG 體驗。

##### **Leveraging Natural Language and Item Response Theory Models for ESG Scoring**
2407.20377v1 by César Pedrosa Soares

This paper explores an innovative approach to Environmental, Social, and
Governance (ESG) scoring by integrating Natural Language Processing (NLP)
techniques with Item Response Theory (IRT), specifically the Rasch model. The
study utilizes a comprehensive dataset of news articles in Portuguese related
to Petrobras, a major oil company in Brazil, collected from 2022 and 2023. The
data is filtered and classified for ESG-related sentiments using advanced NLP
methods. The Rasch model is then applied to evaluate the psychometric
properties of these ESG measures, providing a nuanced assessment of ESG
sentiment trends over time. The results demonstrate the efficacy of this
methodology in offering a more precise and reliable measurement of ESG factors,
highlighting significant periods and trends. This approach may enhance the
robustness of ESG metrics and contribute to the broader field of sustainability
and finance by offering a deeper understanding of the temporal dynamics in ESG
reporting.

摘要：本文探討一種創新的環境、社會和治理 (ESG) 評分方法，結合自然語言處理 (NLP) 技術與項目反應理論 (IRT)，特別是 Rasch 模型。本研究利用 2022 年和 2023 年收集的與巴西主要石油公司 Petrobras 相關的葡萄牙語新聞文章的綜合資料集。資料使用進階 NLP 方法進行過濾和分類，以找出與 ESG 相關的情緒。然後套用 Rasch 模型評估這些 ESG 測量的精神測量屬性，提供對 ESG 情緒趨勢的細微評估。結果證明此方法論有效，可以更精確、可靠地衡量 ESG 因素，並強調重要的時期和趨勢。此方法可以提升 ESG 指標的穩健性，並透過提供對 ESG 報告中時間動態的更深入理解，為永續性和金融的更廣泛領域做出貢獻。

##### **Gender, Race, and Intersectional Bias in Resume Screening via Language Model Retrieval**
2407.20371v1 by Kyra Wilson, Aylin Caliskan

Artificial intelligence (AI) hiring tools have revolutionized resume
screening, and large language models (LLMs) have the potential to do the same.
However, given the biases which are embedded within LLMs, it is unclear whether
they can be used in this scenario without disadvantaging groups based on their
protected attributes. In this work, we investigate the possibilities of using
LLMs in a resume screening setting via a document retrieval framework that
simulates job candidate selection. Using that framework, we then perform a
resume audit study to determine whether a selection of Massive Text Embedding
(MTE) models are biased in resume screening scenarios. We simulate this for
nine occupations, using a collection of over 500 publicly available resumes and
500 job descriptions. We find that the MTEs are biased, significantly favoring
White-associated names in 85.1\% of cases and female-associated names in only
11.1\% of cases, with a minority of cases showing no statistically significant
differences. Further analyses show that Black males are disadvantaged in up to
100\% of cases, replicating real-world patterns of bias in employment settings,
and validate three hypotheses of intersectionality. We also find an impact of
document length as well as the corpus frequency of names in the selection of
resumes. These findings have implications for widely used AI tools that are
automating employment, fairness, and tech policy.

摘要：人工智慧（AI）招聘工具徹底改變了履歷審查，而大型語言模型（LLM）也有潛力做到這一點。
然而，鑑於 LLM 中存在偏見，目前尚不清楚是否可以在不讓群體因其受保護的屬性而處於不利地位的情況下使用 LLM。在這項工作中，我們透過模擬求職者甄選的文件檢索框架來探討在履歷審查設定中使用 LLM 的可能性。然後，我們使用該框架執行履歷稽核研究，以確定大規模文本嵌入（MTE）模型的選擇是否在履歷審查情境中存在偏見。我們模擬了九項職業，使用超過 500 份公開履歷和 500 份工作說明的集合。我們發現 MTE 存在偏見，在 85.1% 的情況下顯著偏好與白人相關的名字，而在只有 11.1% 的情況下偏好與女性相關的名字，少數情況沒有顯示出統計顯著差異。進一步的分析顯示，黑人男性在高達 100% 的情況下處於不利地位，複製了就業環境中偏見的真實模式，並驗證了三個交叉性的假設。我們還發現文件長度以及名字在履歷選擇中的語料庫頻率會產生影響。這些發現對廣泛使用的自動化就業、公平性和技術政策的 AI 工具具有影響。

##### **Evaluating Large Language Models for automatic analysis of teacher simulations**
2407.20360v1 by David de-Fitero-Dominguez, Mariano Albaladejo-González, Antonio Garcia-Cabot, Eva Garcia-Lopez, Antonio Moreno-Cediel, Erin Barno, Justin Reich

Digital Simulations (DS) provide safe environments where users interact with
an agent through conversational prompts, providing engaging learning
experiences that can be used to train teacher candidates in realistic classroom
scenarios. These simulations usually include open-ended questions, allowing
teacher candidates to express their thoughts but complicating an automatic
response analysis. To address this issue, we have evaluated Large Language
Models (LLMs) to identify characteristics (user behaviors) in the responses of
DS for teacher education. We evaluated the performance of DeBERTaV3 and Llama
3, combined with zero-shot, few-shot, and fine-tuning. Our experiments
discovered a significant variation in the LLMs' performance depending on the
characteristic to identify. Additionally, we noted that DeBERTaV3 significantly
reduced its performance when it had to identify new characteristics. In
contrast, Llama 3 performed better than DeBERTaV3 in detecting new
characteristics and showing more stable performance. Therefore, in DS where
teacher educators need to introduce new characteristics because they change
depending on the simulation or the educational objectives, it is more
recommended to use Llama 3. These results can guide other researchers in
introducing LLMs to provide the highly demanded automatic evaluations in DS.

摘要：數位模擬 (DS) 提供安全的環境，使用者透過對話提示與代理互動，提供引人入勝的學習體驗，可用於在逼真的教室場景中訓練教師候選人。這些模擬通常包含開放式問題，允許教師候選人表達他們的想法，但會使自動回應分析變得複雜。為了解決這個問題，我們評估了大型語言模型 (LLM)，以識別 DS 回應中教師教育的特徵（使用者行為）。我們評估了 DeBERTaV3 和 Llama 3 的效能，並結合了零次學習、少次學習和微調。我們的實驗發現，LLM 的效能會根據要識別的特徵而有顯著差異。此外，我們注意到 DeBERTaV3 在必須識別新特徵時，其效能會顯著下降。相反地，Llama 3 在偵測新特徵和展現更穩定的效能方面，表現優於 DeBERTaV3。因此，在教師教育者需要引入新特徵的 DS 中，因為這些特徵會根據模擬或教育目標而改變，建議使用 Llama 3。這些結果可以引導其他研究人員將 LLM 引入 DS 中，以提供高度需求的自動評估。

##### **BRIDGE: Bridging Gaps in Image Captioning Evaluation with Stronger Visual Cues**
2407.20341v1 by Sara Sarto, Marcella Cornia, Lorenzo Baraldi, Rita Cucchiara

Effectively aligning with human judgment when evaluating machine-generated
image captions represents a complex yet intriguing challenge. Existing
evaluation metrics like CIDEr or CLIP-Score fall short in this regard as they
do not take into account the corresponding image or lack the capability of
encoding fine-grained details and penalizing hallucinations. To overcome these
issues, in this paper, we propose BRIDGE, a new learnable and reference-free
image captioning metric that employs a novel module to map visual features into
dense vectors and integrates them into multi-modal pseudo-captions which are
built during the evaluation process. This approach results in a multimodal
metric that properly incorporates information from the input image without
relying on reference captions, bridging the gap between human judgment and
machine-generated image captions. Experiments spanning several datasets
demonstrate that our proposal achieves state-of-the-art results compared to
existing reference-free evaluation scores. Our source code and trained models
are publicly available at: https://github.com/aimagelab/bridge-score.

摘要：在評估機器產生的影像標題時，有效地與人類判斷一致，是一個複雜但有趣的挑戰。現有的評估指標，例如 CIDEr 或 CLIP-Score，在這方面做得並不好，因為它們沒有考慮對應的影像，或缺乏編碼細微細節和懲罰幻覺的能力。為了克服這些問題，我們在這篇論文中提出了 BRIDGE，一個新的可學習且無參考的影像標題評估指標，它採用了一個新穎的模組，將視覺特徵映射到稠密向量中，並將它們整合到多模態偽標題中，這些偽標題是在評估過程中建立的。這種方法產生了一個多模態指標，它適當地納入了輸入影像中的資訊，而不需要依賴參考標題，從而縮小了人類判斷與機器產生的影像標題之間的差距。跨越幾個資料集的實驗表明，與現有的無參考評估分數相比，我們的提案達到了最先進的結果。我們的原始碼和訓練模型可在以下網址公開取得：https://github.com/aimagelab/bridge-score。

##### **Contrasting Deepfakes Diffusion via Contrastive Learning and Global-Local Similarities**
2407.20337v1 by Lorenzo Baraldi, Federico Cocchi, Marcella Cornia, Lorenzo Baraldi, Alessandro Nicolosi, Rita Cucchiara

Discerning between authentic content and that generated by advanced AI
methods has become increasingly challenging. While previous research primarily
addresses the detection of fake faces, the identification of generated natural
images has only recently surfaced. This prompted the recent exploration of
solutions that employ foundation vision-and-language models, like CLIP.
However, the CLIP embedding space is optimized for global image-to-text
alignment and is not inherently designed for deepfake detection, neglecting the
potential benefits of tailored training and local image features. In this
study, we propose CoDE (Contrastive Deepfake Embeddings), a novel embedding
space specifically designed for deepfake detection. CoDE is trained via
contrastive learning by additionally enforcing global-local similarities. To
sustain the training of our model, we generate a comprehensive dataset that
focuses on images generated by diffusion models and encompasses a collection of
9.2 million images produced by using four different generators. Experimental
results demonstrate that CoDE achieves state-of-the-art accuracy on the newly
collected dataset, while also showing excellent generalization capabilities to
unseen image generators. Our source code, trained models, and collected dataset
are publicly available at: https://github.com/aimagelab/CoDE.

摘要：區分真實內容和由進階人工智慧方法產生的內容已變得越來越具有挑戰性。雖然先前的研究主要針對假臉的偵測，但生成自然影像的辨識直到最近才浮現。這促使最近探討採用基礎視覺和語言模型（例如 CLIP）的解決方案。然而，CLIP 嵌入空間針對全球影像對文字比對進行最佳化，並非專門設計用於深度偽造偵測，忽略了客製化訓練和局部影像特徵的潛在好處。在本研究中，我們提出 CoDE（對比深度偽造嵌入），一種專門設計用於深度偽造偵測的新嵌入空間。CoDE 透過對比學習進行訓練，並額外強制執行全局局部相似性。為了持續訓練我們的模型，我們產生了一個綜合資料集，專注於由擴散模型產生的影像，並包含使用四種不同產生器產生的 920 萬張影像集合。實驗結果證明，CoDE 在新收集的資料集上達到了最先進的準確度，同時也對未見過的影像產生器展現出極佳的泛化能力。我們的原始碼、訓練過的模型和收集的資料集公開於：https://github.com/aimagelab/CoDE。

##### **Specify and Edit: Overcoming Ambiguity in Text-Based Image Editing**
2407.20232v1 by Ekaterina Iakovleva, Fabio Pizzati, Philip Torr, Stéphane Lathuilière

Text-based editing diffusion models exhibit limited performance when the
user's input instruction is ambiguous. To solve this problem, we propose
$\textit{Specify ANd Edit}$ (SANE), a zero-shot inference pipeline for
diffusion-based editing systems. We use a large language model (LLM) to
decompose the input instruction into specific instructions, i.e. well-defined
interventions to apply to the input image to satisfy the user's request. We
benefit from the LLM-derived instructions along the original one, thanks to a
novel denoising guidance strategy specifically designed for the task. Our
experiments with three baselines and on two datasets demonstrate the benefits
of SANE in all setups. Moreover, our pipeline improves the interpretability of
editing models, and boosts the output diversity. We also demonstrate that our
approach can be applied to any edit, whether ambiguous or not. Our code is
public at https://github.com/fabvio/SANE.

摘要：<paragraph>基於文字的編輯擴散模型在使用者的輸入指示不明確時，會展現有限的效能。為了解決這個問題，我們提出 $\textit{Specify ANd Edit}$ (SANE)，一個零次推論管線，適用於基於擴散的編輯系統。我們使用大型語言模型 (LLM) 將輸入指令分解成特定指令，也就是針對輸入影像套用良好定義的介入措施，以滿足使用者的要求。我們受益於 LLM 衍生的指令以及原始指令，這要歸功於專門為此任務設計的新穎去噪引導策略。我們使用三個基準和兩個資料集進行的實驗，證明了 SANE 在所有設定中的優點。此外，我們的管線改善了編輯模型的可解釋性，並提升了輸出多樣性。我們也證明了我們的做法可以應用於任何編輯，無論是否含糊不清。我們的程式碼已公開於 https://github.com/fabvio/SANE。</paragraph>

##### **Can Editing LLMs Inject Harm?**
2407.20224v1 by Canyu Chen, Baixiang Huang, Zekun Li, Zhaorun Chen, Shiyang Lai, Xiongxiao Xu, Jia-Chen Gu, Jindong Gu, Huaxiu Yao, Chaowei Xiao, Xifeng Yan, William Yang Wang, Philip Torr, Dawn Song, Kai Shu

Knowledge editing techniques have been increasingly adopted to efficiently
correct the false or outdated knowledge in Large Language Models (LLMs), due to
the high cost of retraining from scratch. Meanwhile, one critical but
under-explored question is: can knowledge editing be used to inject harm into
LLMs? In this paper, we propose to reformulate knowledge editing as a new type
of safety threat for LLMs, namely Editing Attack, and conduct a systematic
investigation with a newly constructed dataset EditAttack. Specifically, we
focus on two typical safety risks of Editing Attack including Misinformation
Injection and Bias Injection. For the risk of misinformation injection, we
first categorize it into commonsense misinformation injection and long-tail
misinformation injection. Then, we find that editing attacks can inject both
types of misinformation into LLMs, and the effectiveness is particularly high
for commonsense misinformation injection. For the risk of bias injection, we
discover that not only can biased sentences be injected into LLMs with high
effectiveness, but also one single biased sentence injection can cause a high
bias increase in general outputs of LLMs, which are even highly irrelevant to
the injected sentence, indicating a catastrophic impact on the overall fairness
of LLMs. Then, we further illustrate the high stealthiness of editing attacks,
measured by their impact on the general knowledge and reasoning capacities of
LLMs, and show the hardness of defending editing attacks with empirical
evidence. Our discoveries demonstrate the emerging misuse risks of knowledge
editing techniques on compromising the safety alignment of LLMs.

摘要：<paragraph>由於從頭開始重新訓練的成本很高，知識編輯技術已被廣泛採用，以有效修正大型語言模型 (LLM) 中錯誤或過時的知識。與此同時，一個關鍵但未充分探討的問題是：知識編輯是否可用於向 LLM 注入危害？在本文中，我們提議將知識編輯重新表述為 LLM 的一種新型安全威脅，即編輯攻擊，並使用新構建的資料集 EditAttack 進行系統性調查。具體來說，我們專注於編輯攻擊的兩個典型安全風險，包括錯誤訊息注入和偏差注入。對於錯誤訊息注入的風險，我們首先將其分類為常識錯誤訊息注入和長尾錯誤訊息注入。然後，我們發現編輯攻擊可以將這兩種錯誤訊息注入 LLM，且常識錯誤訊息注入的有效性特別高。對於偏差注入的風險，我們發現不僅可以將有偏差的句子以高效率注入 LLM，而且單一有偏差的句子注入會導致 LLM 整體輸出出現高偏差，甚至與注入的句子高度無關，這表示對 LLM 整體公平性的影響是災難性的。然後，我們進一步說明編輯攻擊的高度隱密性，透過其對 LLM 的一般知識和推理能力的影響來衡量，並透過經驗證據顯示防禦編輯攻擊的難度。我們的發現證明了知識編輯技術在危害 LLM 的安全比對方面出現的新興誤用風險。</paragraph>

##### **Physics of Language Models: Part 2.1, Grade-School Math and the Hidden Reasoning Process**
2407.20311v1 by Tian Ye, Zicheng Xu, Yuanzhi Li, Zeyuan Allen-Zhu

Recent advances in language models have demonstrated their capability to
solve mathematical reasoning problems, achieving near-perfect accuracy on
grade-school level math benchmarks like GSM8K. In this paper, we formally study
how language models solve these problems. We design a series of controlled
experiments to address several fundamental questions: (1) Can language models
truly develop reasoning skills, or do they simply memorize templates? (2) What
is the model's hidden (mental) reasoning process? (3) Do models solve math
questions using skills similar to or different from humans? (4) Do models
trained on GSM8K-like datasets develop reasoning skills beyond those necessary
for solving GSM8K problems? (5) What mental process causes models to make
reasoning mistakes? (6) How large or deep must a model be to effectively solve
GSM8K-level math questions?
  Our study uncovers many hidden mechanisms by which language models solve
mathematical questions, providing insights that extend beyond current
understandings of LLMs.

摘要：語言模型的最新進展已證明它們有能力解決數學推理問題，在小學程度的數學基準（如 GSM8K）上達到了近乎完美的準確度。在本文中，我們正式研究語言模型如何解決這些問題。我們設計了一系列受控實驗來解決幾個基本問題：(1) 語言模型是否能真正培養推理技能，還是它們只是記住模板？(2) 模型的隱藏（心智）推理過程是什麼？(3) 模型是否使用與人類相似或不同的技能來解決數學問題？(4) 在類似 GSM8K 的數據集上訓練的模型是否會發展出超出解決 GSM8K 問題所需的推理技能？(5) 什麼樣的心智過程會導致模型產生推理錯誤？(6) 模型必須多大或多深才能有效解決 GSM8K 級別的數學問題？我們的研究揭示了語言模型解決數學問題的許多隱藏機制，提供了超出目前對 LLM 理解的見解。

##### **SANGRIA: Surgical Video Scene Graph Optimization for Surgical Workflow Prediction**
2407.20214v1 by Çağhan Köksal, Ghazal Ghazaei, Felix Holm, Azade Farshad, Nassir Navab

Graph-based holistic scene representations facilitate surgical workflow
understanding and have recently demonstrated significant success. However, this
task is often hindered by the limited availability of densely annotated
surgical scene data. In this work, we introduce an end-to-end framework for the
generation and optimization of surgical scene graphs on a downstream task. Our
approach leverages the flexibility of graph-based spectral clustering and the
generalization capability of foundation models to generate unsupervised scene
graphs with learnable properties. We reinforce the initial spatial graph with
sparse temporal connections using local matches between consecutive frames to
predict temporally consistent clusters across a temporal neighborhood. By
jointly optimizing the spatiotemporal relations and node features of the
dynamic scene graph with the downstream task of phase segmentation, we address
the costly and annotation-burdensome task of semantic scene comprehension and
scene graph generation in surgical videos using only weak surgical phase
labels. Further, by incorporating effective intermediate scene representation
disentanglement steps within the pipeline, our solution outperforms the SOTA on
the CATARACTS dataset by 8% accuracy and 10% F1 score in surgical workflow
recognition

摘要：圖形化全景場景表示有助於了解手術流程，並在近期展現顯著的成就。然而，此任務通常受限於密集標註手術場景資料的有限取得。在此研究中，我們針對下游任務引進一個端對端架構，用於產生和最佳化手術場景圖。我們的做法利用了基於圖形的頻譜聚類的靈活性，以及基礎模型的概化能力，以產生具有可學習特性的非監督式場景圖。我們使用連續幀之間的局部配對，以稀疏時間連接強化初始空間圖，以預測時間一致的群集，跨時間鄰域。透過共同最佳化動態場景圖的時空關係和節點特徵，以及階段分割的下游任務，我們使用僅有的弱手術階段標籤，解決了語意場景理解和場景圖產生成本高且標註負擔大的任務。此外，透過在管道中納入有效的中間場景表示解糾纏步驟，我們的解決方案在 CATARACTS 資料集上，在手術流程識別中，優於 SOTA，準確率高出 8%，F1 分數高出 10%。

##### **QAEA-DR: A Unified Text Augmentation Framework for Dense Retrieval**
2407.20207v1 by Hongming Tan, Shaoxiong Zhan, Hai Lin, Hai-Tao Zheng, Wai Kin, Chan

In dense retrieval, embedding long texts into dense vectors can result in
information loss, leading to inaccurate query-text matching. Additionally,
low-quality texts with excessive noise or sparse key information are unlikely
to align well with relevant queries. Recent studies mainly focus on improving
the sentence embedding model or retrieval process. In this work, we introduce a
novel text augmentation framework for dense retrieval. This framework
transforms raw documents into information-dense text formats, which supplement
the original texts to effectively address the aforementioned issues without
modifying embedding or retrieval methodologies. Two text representations are
generated via large language models (LLMs) zero-shot prompting: question-answer
pairs and element-driven events. We term this approach QAEA-DR: unifying
question-answer generation and event extraction in a text augmentation
framework for dense retrieval. To further enhance the quality of generated
texts, a scoring-based evaluation and regeneration mechanism is introduced in
LLM prompting. Our QAEA-DR model has a positive impact on dense retrieval,
supported by both theoretical analysis and empirical experiments.

摘要：在稠密檢索中，將長文本嵌入稠密向量中可能會導致資訊遺失，進而導致不準確的查詢文字配對。此外，品質低劣、雜訊過多或關鍵資訊稀疏的文字不太可能與相關查詢相符。最近的研究主要集中在改進句子嵌入模型或檢索流程。在這項工作中，我們引入了一個用於稠密檢索的新穎文字擴充架構。此架構將原始文件轉換為資訊密集的文字格式，補充原始文字以有效解決上述問題，而無需修改嵌入或檢索方法。透過大型語言模型 (LLM) 零次提示產生兩個文字表徵：問答對和元素驅動事件。我們將此方法稱為 QAEA-DR：統一問答產生和事件萃取，用於稠密檢索的文字擴充架構。為了進一步提升產生文字的品質，在 LLM 提示中引入了基於評分的評估和再生機制。我們的 QAEA-DR 模型對稠密檢索有正面的影響，理論分析和實證實驗都支持這一點。

##### **Aligning Query Representation with Rewritten Query and Relevance Judgments in Conversational Search**
2407.20189v1 by Fengran Mo, Chen Qu, Kelong Mao, Yihong Wu, Zhan Su, Kaiyu Huang, Jian-Yun Nie

Conversational search supports multi-turn user-system interactions to solve
complex information needs. Different from the traditional single-turn ad-hoc
search, conversational search encounters a more challenging problem of
context-dependent query understanding with the lengthy and long-tail
conversational history context. While conversational query rewriting methods
leverage explicit rewritten queries to train a rewriting model to transform the
context-dependent query into a stand-stone search query, this is usually done
without considering the quality of search results. Conversational dense
retrieval methods use fine-tuning to improve a pre-trained ad-hoc query
encoder, but they are limited by the conversational search data available for
training. In this paper, we leverage both rewritten queries and relevance
judgments in the conversational search data to train a better query
representation model. The key idea is to align the query representation with
those of rewritten queries and relevant documents. The proposed model -- Query
Representation Alignment Conversational Dense Retriever, QRACDR, is tested on
eight datasets, including various settings in conversational search and ad-hoc
search. The results demonstrate the strong performance of QRACDR compared with
state-of-the-art methods, and confirm the effectiveness of representation
alignment.

摘要：對話式搜尋支援多輪使用者系統互動，以解決複雜的資訊需求。與傳統的單輪即席搜尋不同，對話式搜尋會遇到一個更具挑戰性的問題，即在冗長且長尾的對話式歷程記錄中，依據脈絡來理解查詢。儘管對話式查詢改寫方法利用明確改寫的查詢，來訓練一個改寫模型，將依據脈絡的查詢轉換為一個獨立的搜尋查詢，但這通常並未考慮搜尋結果的品質。對話式稠密檢索方法使用微調來改善預先訓練的即席查詢編碼器，但它們受到可用於訓練的對話式搜尋資料限制。在本文中，我們利用對話式搜尋資料中的改寫查詢和相關性判斷，來訓練一個更好的查詢表示模型。其關鍵構想是將查詢表示與改寫查詢和相關文件對齊。建議的模型——查詢表示對齊對話式稠密檢索器 QRACDR，在八個資料集上進行測試，包括對話式搜尋和即席搜尋的各種設定。結果顯示 QRACDR 的效能優於現有技術，並確認表示對齊的有效性。

##### **MindSearch: Mimicking Human Minds Elicits Deep AI Searcher**
2407.20183v1 by Zehui Chen, Kuikun Liu, Qiuchen Wang, Jiangning Liu, Wenwei Zhang, Kai Chen, Feng Zhao

Information seeking and integration is a complex cognitive task that consumes
enormous time and effort. Inspired by the remarkable progress of Large Language
Models, recent works attempt to solve this task by combining LLMs and search
engines. However, these methods still obtain unsatisfying performance due to
three challenges: (1) complex requests often cannot be accurately and
completely retrieved by the search engine once (2) corresponding information to
be integrated is spread over multiple web pages along with massive noise, and
(3) a large number of web pages with long contents may quickly exceed the
maximum context length of LLMs. Inspired by the cognitive process when humans
solve these problems, we introduce MindSearch to mimic the human minds in web
information seeking and integration, which can be instantiated by a simple yet
effective LLM-based multi-agent framework. The WebPlanner models the human mind
of multi-step information seeking as a dynamic graph construction process: it
decomposes the user query into atomic sub-questions as nodes in the graph and
progressively extends the graph based on the search result from WebSearcher.
Tasked with each sub-question, WebSearcher performs hierarchical information
retrieval with search engines and collects valuable information for WebPlanner.
The multi-agent design of MindSearch enables the whole framework to seek and
integrate information parallelly from larger-scale (e.g., more than 300) web
pages in 3 minutes, which is worth 3 hours of human effort. MindSearch
demonstrates significant improvement in the response quality in terms of depth
and breadth, on both close-set and open-set QA problems. Besides, responses
from MindSearch based on InternLM2.5-7B are preferable by humans to ChatGPT-Web
and Perplexity.ai applications, which implies that MindSearch can already
deliver a competitive solution to the proprietary AI search engine.

摘要：資訊搜尋與整合是一項複雜的認知任務，會耗費大量時間與精力。在大型語言模型顯著進展的啟發下，近期研究嘗試結合大型語言模型與搜尋引擎來解決此任務。然而，這些方法仍因三項挑戰而無法獲得令人滿意的效能：(1) 複雜的查詢通常無法由搜尋引擎一次準確且完整地擷取，(2) 要整合的對應資訊散布在多個網頁中且伴隨著大量雜訊，以及 (3) 大量內容過長的網頁可能會快速超過大型語言模型的最大脈絡長度。在人類解決這些問題的認知過程中獲得靈感，我們引入了 MindSearch 來模擬人類心智在網頁資訊搜尋與整合中的行為，這可以用一個簡單但有效的基於大型語言模型的多代理架構來實例化。WebPlanner 以動態圖形建構過程來建模人類心智的多步驟資訊搜尋：它將使用者查詢分解成圖形中的節點，作為原子化子問題，並根據 WebSearcher 的搜尋結果逐步延伸圖形。WebSearcher 以每個子問題為任務，執行搜尋引擎的分層式資訊擷取，並為 WebPlanner 收集有價值的資訊。MindSearch 的多代理設計讓整個架構可以在 3 分鐘內平行地從更大規模（例如超過 300 個）的網頁中搜尋並整合資訊，這相當於 3 小時的人力。MindSearch 在深度和廣度方面都顯著提升了回應品質，無論是在封閉式或開放式問答問題上。此外，人類更偏好基於 InternLM2.5-7B 的 MindSearch 回應，勝過 ChatGPT-Web 和 Perplexity.ai 應用程式，這表示 MindSearch 已經可以為專有 AI 搜尋引擎提供有競爭力的解決方案。

##### **Theia: Distilling Diverse Vision Foundation Models for Robot Learning**
2407.20179v1 by Jinghuan Shang, Karl Schmeckpeper, Brandon B. May, Maria Vittoria Minniti, Tarik Kelestemur, David Watkins, Laura Herlant

Vision-based robot policy learning, which maps visual inputs to actions,
necessitates a holistic understanding of diverse visual tasks beyond
single-task needs like classification or segmentation. Inspired by this, we
introduce Theia, a vision foundation model for robot learning that distills
multiple off-the-shelf vision foundation models trained on varied vision tasks.
Theia's rich visual representations encode diverse visual knowledge, enhancing
downstream robot learning. Extensive experiments demonstrate that Theia
outperforms its teacher models and prior robot learning models using less
training data and smaller model sizes. Additionally, we quantify the quality of
pre-trained visual representations and hypothesize that higher entropy in
feature norm distributions leads to improved robot learning performance. Code
and models are available at https://github.com/bdaiinstitute/theia.

摘要：基於視覺的機器人策略學習，將視覺輸入對應到動作，需要對多樣化視覺任務有整體的理解，超越單一任務需求，例如分類或分割。受到此啟發，我們介紹 Theia，這是一個機器人學習的視覺基礎模型，它萃取多個針對不同視覺任務訓練的現成視覺基礎模型。Theia 豐富的視覺表徵編碼多樣化的視覺知識，增強下游機器人學習。廣泛的實驗證明，Theia 使用較少的訓練資料和較小的模型大小，就能超越其教師模型和先前的機器人學習模型。此外，我們量化預訓練視覺表徵的品質，並假設特徵範數分佈中較高的熵會帶來改善的機器人學習效能。程式碼和模型可在 https://github.com/bdaiinstitute/theia 取得。

##### **AutoScale: Automatic Prediction of Compute-optimal Data Composition for Training LLMs**
2407.20177v1 by Feiyang Kang, Yifan Sun, Bingbing Wen, Si Chen, Dawn Song, Rafid Mahmood, Ruoxi Jia

To ensure performance on a diverse set of downstream tasks, LLMs are
pretrained via data mixtures over different domains. In this work, we
demonstrate that the optimal data composition for a fixed compute budget varies
depending on the scale of the training data, suggesting that the common
practice of empirically determining an optimal composition using small-scale
experiments will not yield the optimal data mixtures when scaling up to the
final model. To address this challenge, we propose *AutoScale*, an automated
tool that finds a compute-optimal data composition for training at any desired
target scale. AutoScale first determines the optimal composition at a small
scale using a novel bilevel optimization framework, Direct Data Optimization
(*DDO*), and then fits a predictor to estimate the optimal composition at
larger scales. The predictor's design is inspired by our theoretical analysis
of scaling laws related to data composition, which could be of independent
interest. In empirical studies with pre-training 774M Decoder-only LMs (GPT-2
Large) on RedPajama dataset, AutoScale decreases validation perplexity at least
25% faster than any baseline with up to 38% speed up compared to without
reweighting, achieving the best overall performance across downstream tasks. On
pre-training Encoder-only LMs (BERT) with masked language modeling, DDO is
shown to decrease loss on all domains while visibly improving average task
performance on GLUE benchmark by 8.7% and on large-scale QA dataset (SQuAD) by
5.9% compared with without reweighting. AutoScale speeds up training by up to
28%. Our codes are open-sourced.

摘要：<paragraph>為了確保在各種下游任務上的效能，LLM 會透過不同領域的資料混合進行預先訓練。在這項工作中，我們證明了在固定的運算預算下，最佳的資料組成會依訓練資料的規模而有所不同，這表示在擴充到最終模型時，使用小規模實驗來經驗性地決定最佳組成的常見做法，將無法產生最佳的資料混合。為了應對這項挑戰，我們提出了「AutoScale」，一個自動化工具，可以為任何所需的目標規模的訓練找到一個運算最佳的資料組成。AutoScale 首先使用一種新穎的雙層次最佳化架構，直接資料最佳化（DDO），來決定小規模的最佳組成，然後擬合一個預測器來估計較大規模的最佳組成。預測器的設計靈感來自我們對與資料組成相關的規模定律的理論分析，這可能是獨立的興趣。在使用預訓練 774M 僅解碼器 LMs（GPT-2 Large）於 RedPajama 資料集進行的實證研究中，AutoScale 驗證困惑度降低的速度比任何基線快至少 25%，與不重新加權相比，速度提升多達 38%，在所有下游任務中都取得最佳的整體效能。在使用遮罩語言模型預訓練僅編碼器 LMs（BERT）時，DDO 已被證明可以減少所有領域的損失，同時在 GLUE 基準上將平均任務效能顯著提升 8.7%，在大型 QA 資料集（SQuAD）上提升 5.9%，與不重新加權相比。AutoScale 將訓練速度提升多達 28%。我們的程式碼是開源的。</paragraph>

##### **Emotion-Driven Melody Harmonization via Melodic Variation and Functional Representation**
2407.20176v1 by Jingyue Huang, Yi-Hsuan Yang

Emotion-driven melody harmonization aims to generate diverse harmonies for a
single melody to convey desired emotions. Previous research found it hard to
alter the perceived emotional valence of lead sheets only by harmonizing the
same melody with different chords, which may be attributed to the constraints
imposed by the melody itself and the limitation of existing music
representation. In this paper, we propose a novel functional representation for
symbolic music. This new method takes musical keys into account, recognizing
their significant role in shaping music's emotional character through
major-minor tonality. It also allows for melodic variation with respect to keys
and addresses the problem of data scarcity for better emotion modeling. A
Transformer is employed to harmonize key-adaptable melodies, allowing for keys
determined in rule-based or model-based manner. Experimental results confirm
the effectiveness of our new representation in generating key-aware harmonies,
with objective and subjective evaluations affirming the potential of our
approach to convey specific valence for versatile melody.

摘要：情感驅動的旋律和聲化旨在為單一旋律產生多樣化的和聲，以傳達所需的的情緒。先前的研究發現，僅通過使用不同的和弦來和聲化同一旋律，很難改變主旋律的感知情緒價，這可能歸因於旋律本身的約束和現有音樂表現形式的限制。在本文中，我們提出了一個符號音樂的新功能表示。這種新方法考慮了音樂的調性，承認了它們通過大調小調音調塑造音樂的情感特徵的重要作用。它還允許根據調性進行旋律變化，並解決了數據稀疏的問題，以進行更好的情緒建模。採用 Transformer 來和聲化可調整調性的旋律，允許以基於規則或基於模型的方式確定調性。實驗結果證實了我們的新表示在產生調性感知和聲方面的有效性，客觀和主觀評估肯定了我們的方法在傳達多功能旋律的特定價的潛力。

##### **Advancing Multimodal Large Language Models in Chart Question Answering with Visualization-Referenced Instruction Tuning**
2407.20174v1 by Xingchen Zeng, Haichuan Lin, Yilin Ye, Wei Zeng

Emerging multimodal large language models (MLLMs) exhibit great potential for
chart question answering (CQA). Recent efforts primarily focus on scaling up
training datasets (i.e., charts, data tables, and question-answer (QA) pairs)
through data collection and synthesis. However, our empirical study on existing
MLLMs and CQA datasets reveals notable gaps. First, current data collection and
synthesis focus on data volume and lack consideration of fine-grained visual
encodings and QA tasks, resulting in unbalanced data distribution divergent
from practical CQA scenarios. Second, existing work follows the training recipe
of the base MLLMs initially designed for natural images, under-exploring the
adaptation to unique chart characteristics, such as rich text elements. To fill
the gap, we propose a visualization-referenced instruction tuning approach to
guide the training dataset enhancement and model development. Specifically, we
propose a novel data engine to effectively filter diverse and high-quality data
from existing datasets and subsequently refine and augment the data using
LLM-based generation techniques to better align with practical QA tasks and
visual encodings. Then, to facilitate the adaptation to chart characteristics,
we utilize the enriched data to train an MLLM by unfreezing the vision encoder
and incorporating a mixture-of-resolution adaptation strategy for enhanced
fine-grained recognition. Experimental results validate the effectiveness of
our approach. Even with fewer training examples, our model consistently
outperforms state-of-the-art CQA models on established benchmarks. We also
contribute a dataset split as a benchmark for future research. Source codes and
datasets of this paper are available at
https://github.com/zengxingchen/ChartQA-MLLM.

摘要：新興的多模態大型語言模型 (MLLM) 在圖表問答 (CQA) 方面展現了巨大的潛力。最近的研究主要著重於透過資料收集和綜合，擴充訓練資料集（即圖表、資料表格和問答 (QA) 配對）。然而，我們對現有 MLLM 和 CQA 資料集的實證研究揭露了顯著的差距。首先，目前的資料收集和綜合著重於資料量，而忽略了細微的視覺編碼和 QA 任務，導致不平衡的資料分佈與實際 CQA 情境產生差異。其次，現有研究遵循最初為自然影像設計的基本 MLLM 訓練範例，低估了對圖表獨特特徵（例如豐富的文字元素）的適應性。為了填補這個差距，我們提出了一種以視覺化參考的指令調整方法，以引導訓練資料集的增強和模型開發。具體來說，我們提出了一種新穎的資料引擎，以有效地從現有資料集中過濾多樣化且高品質的資料，並隨後使用基於 LLM 的生成技術精煉和擴充資料，以更好地與實際的 QA 任務和視覺編碼保持一致。然後，為了促進對圖表特徵的適應，我們利用豐富的資料來訓練 MLLM，方法是解凍視覺編碼器，並結合混合解析度適應策略，以增強細微的辨識能力。實驗結果驗證了我們方法的有效性。即使訓練範例較少，我們的模型在既有的基準上仍持續優於最先進的 CQA 模型。我們也貢獻了一個資料集分割，作為未來研究的基準。本文的原始碼和資料集可以在 https://github.com/zengxingchen/ChartQA-MLLM 取得。

##### **LatentArtiFusion: An Effective and Efficient Histological Artifacts Restoration Framework**
2407.20172v1 by Zhenqi He, Wenrui Liu, Minghao Yin, Kai Han

Histological artifacts pose challenges for both pathologists and
Computer-Aided Diagnosis (CAD) systems, leading to errors in analysis. Current
approaches for histological artifact restoration, based on Generative
Adversarial Networks (GANs) and pixel-level Diffusion Models, suffer from
performance limitations and computational inefficiencies. In this paper, we
propose a novel framework, LatentArtiFusion, which leverages the latent
diffusion model (LDM) to reconstruct histological artifacts with high
performance and computational efficiency. Unlike traditional pixel-level
diffusion frameworks, LatentArtiFusion executes the restoration process in a
lower-dimensional latent space, significantly improving computational
efficiency. Moreover, we introduce a novel regional artifact reconstruction
algorithm in latent space to prevent mistransfer in non-artifact regions,
distinguishing our approach from GAN-based methods. Through extensive
experiments on real-world histology datasets, LatentArtiFusion demonstrates
remarkable speed, outperforming state-of-the-art pixel-level diffusion
frameworks by more than 30X. It also consistently surpasses GAN-based methods
by at least 5% across multiple evaluation metrics. Furthermore, we evaluate the
effectiveness of our proposed framework in downstream tissue classification
tasks, showcasing its practical utility. Code is available at
https://github.com/bugs-creator/LatentArtiFusion.

摘要：組織病理學製品對病理學家和電腦輔助診斷 (CAD) 系統構成挑戰，導致分析錯誤。目前基於生成對抗網路 (GAN) 和像素級擴散模型的組織病理學製品修復方法，存在效能限制和運算效率低下的問題。在本文中，我們提出一個創新的架構 LatentArtiFusion，它利用潛在擴散模型 (LDM) 以高性能和運算效率重建組織病理學製品。與傳統的像素級擴散架構不同，LatentArtiFusion 在較低維度的潛在空間中執行修復程序，大幅提升運算效率。此外，我們在潛在空間中引入一種新穎的區域製品重建演算法，以防止非製品區域的錯誤傳輸，將我們的方法與基於 GAN 的方法區分開來。透過對真實世界組織病理學資料集進行廣泛的實驗，LatentArtiFusion 展現出驚人的速度，效能優於最先進的像素級擴散架構 30 倍以上。它還透過多項評估指標，始終優於基於 GAN 的方法至少 5%。此外，我們評估了我們提出的架構在下游組織分類任務中的有效性，展示了它的實用性。程式碼可於 https://github.com/bugs-creator/LatentArtiFusion 取得。

##### **Language-Conditioned Offline RL for Multi-Robot Navigation**
2407.20164v1 by Steven Morad, Ajay Shankar, Jan Blumenkamp, Amanda Prorok

We present a method for developing navigation policies for multi-robot teams
that interpret and follow natural language instructions. We condition these
policies on embeddings from pretrained Large Language Models (LLMs), and train
them via offline reinforcement learning with as little as 20 minutes of
randomly-collected data. Experiments on a team of five real robots show that
these policies generalize well to unseen commands, indicating an understanding
of the LLM latent space. Our method requires no simulators or environment
models, and produces low-latency control policies that can be deployed directly
to real robots without finetuning. We provide videos of our experiments at
https://sites.google.com/view/llm-marl.

摘要：我們提出了一種為多機器人團隊開發導航策略的方法，該策略會解譯和遵循自然語言指令。我們根據預訓練大型語言模型 (LLM) 的嵌入來設定這些策略，並透過離線強化學習訓練它們，所需資料少至 20 分鐘的隨機收集資料。對五個真實機器人團隊進行的實驗顯示，這些策略可以很好地概括到未見過的命令，這表示對 LLM 潛在空間的理解。我們的模型不需要模擬器或環境模型，而且產生的低延遲控制策略可以直接部署到真實機器人，而無需微調。我們在 https://sites.google.com/view/llm-marl 提供了我們的實驗影片。

##### **rLLM: Relational Table Learning with LLMs**
2407.20157v1 by Weichen Li, Xiaotong Huang, Jianwu Zheng, Zheng Wang, Chaokun Wang, Li Pan, Jianhua Li

We introduce rLLM (relationLLM), a PyTorch library designed for Relational
Table Learning (RTL) with Large Language Models (LLMs). The core idea is to
decompose state-of-the-art Graph Neural Networks, LLMs, and Table Neural
Networks into standardized modules, to enable the fast construction of novel
RTL-type models in a simple "combine, align, and co-train" manner. To
illustrate the usage of rLLM, we introduce a simple RTL method named
\textbf{BRIDGE}. Additionally, we present three novel relational tabular
datasets (TML1M, TLF2K, and TACM12K) by enhancing classic datasets. We hope
rLLM can serve as a useful and easy-to-use development framework for
RTL-related tasks. Our code is available at:
https://github.com/rllm-project/rllm.

摘要：我們引入了 rLLM (relationLLM)，一個專為大型語言模型 (LLM) 的關係表學習 (RTL) 所設計的 PyTorch 函式庫。核心概念是將最先進的圖形神經網路、LLM 和表神經網路分解為標準化模組，以便以簡單的「組合、對齊和共同訓練」方式快速建構新型 RTL 類型模型。為了說明 rLLM 的用法，我們引入了名為 \textbf{BRIDGE} 的簡單 RTL 方法。此外，我們透過強化經典資料集來呈現三個新穎的關係表格資料集 (TML1M、TLF2K 和 TACM12K)。我們希望 rLLM 能夠作為 RTL 相關任務有用的且易於使用的開發架構。我們的程式碼可在以下網址取得：
https://github.com/rllm-project/rllm。

##### **Quantum Machine Learning Architecture Search via Deep Reinforcement Learning**
2407.20147v1 by Xin Dai, Tzu-Chieh Wei, Shinjae Yoo, Samuel Yen-Chi Chen

The rapid advancement of quantum computing (QC) and machine learning (ML) has
given rise to the burgeoning field of quantum machine learning (QML), aiming to
capitalize on the strengths of quantum computing to propel ML forward. Despite
its promise, crafting effective QML models necessitates profound expertise to
strike a delicate balance between model intricacy and feasibility on Noisy
Intermediate-Scale Quantum (NISQ) devices. While complex models offer robust
representation capabilities, their extensive circuit depth may impede seamless
execution on extant noisy quantum platforms. In this paper, we address this
quandary of QML model design by employing deep reinforcement learning to
explore proficient QML model architectures tailored for designated supervised
learning tasks. Specifically, our methodology involves training an RL agent to
devise policies that facilitate the discovery of QML models without
predetermined ansatz. Furthermore, we integrate an adaptive mechanism to
dynamically adjust the learning objectives, fostering continuous improvement in
the agent's learning process. Through extensive numerical simulations, we
illustrate the efficacy of our approach within the realm of classification
tasks. Our proposed method successfully identifies VQC architectures capable of
achieving high classification accuracy while minimizing gate depth. This
pioneering approach not only advances the study of AI-driven quantum circuit
design but also holds significant promise for enhancing performance in the NISQ
era.

摘要：量子運算 (QC) 和機器學習 (ML) 的快速進展已催生出蓬勃發展的量子機器學習 (QML) 領域，旨在利用量子運算的優勢來推動 ML 的進步。儘管前景看好，但打造有效的 QML 模型需要深厚的專業知識，才能在雜訊中型量子 (NISQ) 裝置上，在模型複雜性和可行性之間取得微妙的平衡。雖然複雜的模型提供了強大的表示能力，但其廣泛的電路深度可能會阻礙在現有的雜訊量子平台上進行無縫執行。在本文中，我們通過採用深度強化學習來探索針對指定監督學習任務量身打造的熟練 QML 模型架構，來解決 QML 模型設計的這個難題。具體來說，我們的方法涉及訓練一個 RL 代理，以制定策略，促進在沒有預定 ansatz 的情況下發現 QML 模型。此外，我們整合了一個自適應機制來動態調整學習目標，促進代理學習過程中持續改進。通過廣泛的數值模擬，我們說明了我們的方法在分類任務領域內的功效。我們提出的方法成功識別出 VQC 架構，該架構能夠在最小化閘極深度的情況下實現高分類準確度。這種開創性的方法不僅推動了 AI 驅動的量子電路設計研究，而且也為增強 NISQ 時代的性能提供了重大的前景。

##### **ByteCheckpoint: A Unified Checkpointing System for LLM Development**
2407.20143v1 by Borui Wan, Mingji Han, Yiyao Sheng, Zhichao Lai, Mofan Zhang, Junda Zhang, Yanghua Peng, Haibin Lin, Xin Liu, Chuan Wu

The development of real-world Large Language Models (LLMs) necessitates
checkpointing of training states in persistent storage to mitigate potential
software and hardware failures, as well as to facilitate checkpoint
transferring within the training pipeline and across various tasks. Due to the
immense size of LLMs, saving and loading checkpoints often incur intolerable
minute-level stalls, significantly diminishing training efficiency. Besides,
when transferring checkpoints across tasks, checkpoint resharding, defined as
loading checkpoints into parallel configurations differing from those used for
saving, is often required according to the characteristics and resource quota
of specific tasks. Previous checkpointing systems [16,3,33,6] assume consistent
parallel configurations, failing to address the complexities of checkpoint
transformation during resharding. Furthermore, in the industry platform,
developers create checkpoints from different training frameworks[23,36,21,11],
each with its own unique storage and I/O logic. This diversity complicates the
implementation of unified checkpoint management and optimization. To address
these challenges, we introduce ByteCheckpoint, a PyTorch-native multi-framework
LLM checkpointing system that supports automatic online checkpoint resharding.
ByteCheckpoint employs a data/metadata disaggregated storage architecture,
decoupling checkpoint storage from the adopted parallelism strategies and
training frameworks. We design an efficient asynchronous tensor merging
technique to settle the irregular tensor sharding problem and propose several
I/O performance optimizations to significantly enhance the efficiency of
checkpoint saving and loading. Experimental results demonstrate
ByteCheckpoint's substantial advantages in reducing checkpoint saving (by up to
529.22X) and loading (by up to 3.51X) costs, compared to baseline methods.

摘要：<paragraph>由於軟體和硬體故障的潛在風險，以及為了在訓練流程和各種任務中促進檢查點轉移，現實世界的大型語言模型 (LLM) 的開發需要將訓練狀態檢查點儲存在永久儲存裝置中以減輕風險。由於 LLM 的規模龐大，儲存和載入檢查點通常會造成無法忍受的分鐘級停滯，大幅降低訓練效率。此外，在任務間轉移檢查點時，通常需要根據特定任務的特徵和資源配額，將檢查點重新分片，這定義為將檢查點載入與儲存時不同的平行組態。先前的檢查點系統 [16,3,33,6] 假設一致的平行組態，無法解決重新分片期間檢查點轉換的複雜性。此外，在產業平台中，開發人員會從不同的訓練架構 [23,36,21,11] 建立檢查點，每個架構都有自己獨特的儲存和 I/O 邏輯。這種多樣性讓統一的檢查點管理和最佳化的實作變得複雜。為了應對這些挑戰，我們引入了 ByteCheckpoint，一個 PyTorch 原生的多架構 LLM 檢查點系統，它支援自動線上檢查點重新分片。ByteCheckpoint 使用資料/元資料分離儲存架構，將檢查點儲存與採用的平行處理策略和訓練架構脫鉤。我們設計了一種高效的非同步張量合併技術來解決不規則張量分片問題，並提出多項 I/O 效能最佳化措施，以大幅提升檢查點儲存和載入的效率。實驗結果證明，與基線方法相比，ByteCheckpoint 在減少檢查點儲存 (最多減少 529.22 倍) 和載入 (最多減少 3.51 倍) 成本方面具有顯著優勢。</paragraph>

##### **To accept or not to accept? An IRT-TOE Framework to Understand Educators' Resistance to Generative AI in Higher Education**
2407.20130v1 by Jan-Erik Kalmus, Anastasija Nikiforova

Since the public release of Chat Generative Pre-Trained Transformer
(ChatGPT), extensive discourse has emerged concerning the potential advantages
and challenges of integrating Generative Artificial Intelligence (GenAI) into
education. In the realm of information systems, research on technology adoption
is crucial for understanding the diverse factors influencing the uptake of
specific technologies. Theoretical frameworks, refined and validated over
decades, serve as guiding tools to elucidate the individual and organizational
dynamics, obstacles, and perceptions surrounding technology adoption. However,
while several models have been proposed, they often prioritize elucidating the
factors that facilitate acceptance over those that impede it, typically
focusing on the student perspective and leaving a gap in empirical evidence
regarding educators viewpoints. Given the pivotal role educators play in higher
education, this study aims to develop a theoretical model to empirically
predict the barriers preventing educators from adopting GenAI in their
classrooms. Acknowledging the lack of theoretical models tailored to
identifying such barriers, our approach is grounded in the Innovation
Resistance Theory (IRT) framework and augmented with constructs from the
Technology-Organization-Environment (TOE) framework. This model is transformed
into a measurement instrument employing a quantitative approach, complemented
by a qualitative approach to enrich the analysis and uncover concerns related
to GenAI adoption in the higher education domain.

摘要：自從 Chat Generative Pre-Trained Transformer (ChatGPT) 公開發布以來，關於將生成式人工智慧 (GenAI) 整合到教育中的潛在優點和挑戰，已經出現廣泛的討論。在資訊系統領域中，技術採用研究對於了解影響特定技術採用率的不同因素至關重要。經過數十年提煉和驗證的理論架構，可用作指導工具，用以闡明與技術採用相關的個人和組織動態、障礙和認知。然而，儘管已經提出多種模型，但它們通常優先闡明促進接受的因素，甚於阻礙接受的因素，通常側重於學生的觀點，並在實證證據方面留下有關教育者觀點的空白。鑑於教育者在高等教育中扮演著舉足輕重的角色，本研究旨在開發一個理論模型，以實證預測阻礙教育者在其課堂中採用 GenAI 的障礙。承認缺乏量身打造以找出此類障礙的理論模型，我們的做法以創新抗拒理論 (IRT) 架構為基礎，並結合技術-組織-環境 (TOE) 架構中的構念進行擴充。此模型轉變為採用量化方法的測量工具，並輔以質化方法以豐富分析，並揭露與高等教育領域中採用 GenAI 相關的疑慮。

##### **AxiomVision: Accuracy-Guaranteed Adaptive Visual Model Selection for Perspective-Aware Video Analytics**
2407.20124v2 by Xiangxiang Dai, Zeyu Zhang, Peng Yang, Yuedong Xu, Xutong Liu, John C. S. Lui

The rapid evolution of multimedia and computer vision technologies requires
adaptive visual model deployment strategies to effectively handle diverse tasks
and varying environments. This work introduces AxiomVision, a novel framework
that can guarantee accuracy by leveraging edge computing to dynamically select
the most efficient visual models for video analytics under diverse scenarios.
Utilizing a tiered edge-cloud architecture, AxiomVision enables the deployment
of a broad spectrum of visual models, from lightweight to complex DNNs, that
can be tailored to specific scenarios while considering camera source impacts.
In addition, AxiomVision provides three core innovations: (1) a dynamic visual
model selection mechanism utilizing continual online learning, (2) an efficient
online method that efficiently takes into account the influence of the camera's
perspective, and (3) a topology-driven grouping approach that accelerates the
model selection process. With rigorous theoretical guarantees, these
advancements provide a scalable and effective solution for visual tasks
inherent to multimedia systems, such as object detection, classification, and
counting. Empirically, AxiomVision achieves a 25.7\% improvement in accuracy.

摘要：多媒體和電腦視覺技術的快速演進需要自適應視覺模型部署策略，才能有效處理各種任務和變動的環境。這項工作介紹了 AxiomVision，一個新穎的架構，它能透過利用邊緣運算來動態選擇在各種場景下最有效的視覺模型，從而保證準確性。利用分層邊緣雲架構，AxiomVision 能部署廣泛的視覺模型，從輕量級到複雜的 DNN，這些模型可以根據特定場景進行調整，同時考慮相機來源的影響。此外，AxiomVision 提供了三項核心創新：(1) 利用持續在線學習的動態視覺模型選擇機制，(2) 有效考慮相機視角影響的有效在線方法，以及 (3) 加速模型選擇過程的拓撲驅動分組方法。透過嚴謹的理論保證，這些進展為多媒體系統固有的視覺任務（例如物體偵測、分類和計數）提供了可擴充且有效的解決方案。根據經驗，AxiomVision 在準確度上獲得了 25.7% 的提升。

##### **EXIT: An EXplicit Interest Transfer Framework for Cross-Domain Recommendation**
2407.20121v1 by Lei Huang, Weitao Li, Chenrui Zhang, Jinpeng Wang, Xianchun Yi, Sheng Chen

Cross-domain recommendation has attracted substantial interest in industrial
apps such as Meituan, which serves multiple business domains via knowledge
transfer and meets the diverse interests of users. However, existing methods
typically follow an implicit modeling paradigm that blends the knowledge from
both the source and target domains, and design intricate network structures to
share learned embeddings or patterns between domains to improve recommendation
accuracy. Since the transfer of interest signals is unsupervised, these
implicit paradigms often struggle with the negative transfer resulting from
differences in service functions and presentation forms across different
domains. In this paper, we propose a simple and effective EXplicit Interest
Transfer framework named EXIT to address the stated challenge. Specifically, we
propose a novel label combination approach that enables the model to directly
learn beneficial source domain interests through supervised learning, while
excluding inappropriate interest signals. Moreover, we introduce a scene
selector network to model the interest transfer intensity under fine-grained
scenes. Offline experiments conducted on the industrial production dataset and
online A/B tests validate the superiority and effectiveness of our proposed
framework. Without complex network structures or training processes, EXIT can
be easily deployed in the industrial recommendation system. EXIT has been
successfully deployed in the online homepage recommendation system of Meituan
App, serving the main traffic.

摘要：跨域推薦在工業應用中引起了極大的興趣，例如美團，它通過知識轉移服務於多個業務領域，並滿足了用戶的多樣化興趣。然而，現有方法通常遵循隱式建模範例，該範例融合了源域和目標域的知識，並設計複雜的網路結構，以在域之間共享學習的嵌入或模式，以提高推薦準確度。由於興趣信號的傳遞不受監督，因此這些隱式範例通常難以應對由於不同域之間的服務功能和呈現形式的差異而產生的負面傳遞。在本文中，我們提出了一個簡單有效的 EXplicit Interest Transfer 框架，名為 EXIT，以應對所述挑戰。具體來說，我們提出了一種新穎的標籤組合方法，使模型能夠通過監督學習直接學習有益的源域興趣，同時排除不適當的興趣信號。此外，我們引入了一個場景選擇器網路，以在細粒度場景下對興趣傳遞強度進行建模。在工業生產資料集上進行的離線實驗和線上 A/B 測試驗證了我們提出的框架的優越性和有效性。EXIT 可以在沒有複雜網路結構或訓練過程的情況下輕鬆部署在工業推薦系統中。EXIT 已成功部署在美團 App 的線上首頁推薦系統中，服務於主要流量。

##### **Adaptive Self-supervised Robust Clustering for Unstructured Data with Unknown Cluster Number**
2407.20119v2 by Chen-Lu Ding, Jiancan Wu, Wei Lin, Shiyang Shen, Xiang Wang, Yancheng Yuan

We introduce a novel self-supervised deep clustering approach tailored for
unstructured data without requiring prior knowledge of the number of clusters,
termed Adaptive Self-supervised Robust Clustering (ASRC). In particular, ASRC
adaptively learns the graph structure and edge weights to capture both local
and global structural information. The obtained graph enables us to learn
clustering-friendly feature representations by an enhanced graph auto-encoder
with contrastive learning technique. It further leverages the clustering
results adaptively obtained by robust continuous clustering (RCC) to generate
prototypes for negative sampling, which can further contribute to promoting
consistency among positive pairs and enlarging the gap between positive and
negative samples. ASRC obtains the final clustering results by applying RCC to
the learned feature representations with their consistent graph structure and
edge weights. Extensive experiments conducted on seven benchmark datasets
demonstrate the efficacy of ASRC, demonstrating its superior performance over
other popular clustering models. Notably, ASRC even outperforms methods that
rely on prior knowledge of the number of clusters, highlighting its
effectiveness in addressing the challenges of clustering unstructured data.

摘要：我們提出了一種新穎的自監督深度聚類方法，專門針對非結構化資料，無需事先了解群集數量，稱為自適應自監督穩健聚類 (ASRC)。具體來說，ASRC 自適應地學習圖形結構和邊緣權重，以擷取局部和全局結構資訊。所獲得的圖形使我們能夠透過增強的圖形自動編碼器與對比學習技術，學習對聚類友善的特徵表示。它進一步利用穩健連續聚類 (RCC) 自適應獲得的聚類結果，為負面抽樣產生原型，這可以進一步促進正對之間的一致性，並擴大正負樣本之間的差距。ASRC 將 RCC 套用於學習的特徵表示及其一致的圖形結構和邊緣權重，以獲得最終的聚類結果。在七個基準資料集上進行的廣泛實驗證明了 ASRC 的功效，證明了它優於其他流行的聚類模型。值得注意的是，ASRC 甚至優於依賴於群集數量先驗知識的方法，突顯了它在解決非結構化資料聚類挑戰方面的有效性。

##### **FiCo-ITR: bridging fine-grained and coarse-grained image-text retrieval for comparative performance analysis**
2407.20114v1 by Mikel Williams-Lekuona, Georgina Cosma

In the field of Image-Text Retrieval (ITR), recent advancements have
leveraged large-scale Vision-Language Pretraining (VLP) for Fine-Grained (FG)
instance-level retrieval, achieving high accuracy at the cost of increased
computational complexity. For Coarse-Grained (CG) category-level retrieval,
prominent approaches employ Cross-Modal Hashing (CMH) to prioritise efficiency,
albeit at the cost of retrieval performance. Due to differences in
methodologies, FG and CG models are rarely compared directly within evaluations
in the literature, resulting in a lack of empirical data quantifying the
retrieval performance-efficiency tradeoffs between the two. This paper
addresses this gap by introducing the \texttt{FiCo-ITR} library, which
standardises evaluation methodologies for both FG and CG models, facilitating
direct comparisons. We conduct empirical evaluations of representative models
from both subfields, analysing precision, recall, and computational complexity
across varying data scales. Our findings offer new insights into the
performance-efficiency trade-offs between recent representative FG and CG
models, highlighting their respective strengths and limitations. These findings
provide the foundation necessary to make more informed decisions regarding
model selection for specific retrieval tasks and highlight avenues for future
research into hybrid systems that leverage the strengths of both FG and CG
approaches.

摘要：在影像文字檢索 (ITR) 領域，最近的進展已利用大規模視覺語言預訓練 (VLP) 進行細粒度 (FG) 個體層級檢索，以增加運算複雜度為代價，達成高準確度。對於粗粒度 (CG) 類別層級檢索，著名的做法採用跨模態雜湊 (CMH) 優先考量效率，儘管是以犧牲檢索效能為代價。由於方法論不同，FG 與 CG 模型在文獻中的評估中很少直接比較，導致缺乏量化兩者之間檢索效能與效率折衷的經驗數據。本文透過引入 \texttt{FiCo-ITR} 庫來解決這個差距，該庫標準化了 FG 與 CG 模型的評估方法，促成直接比較。我們對兩個子領域的代表性模型進行經驗評估，分析不同數據規模下的精準度、召回率和運算複雜度。我們的發現提供了對近期代表性 FG 和 CG 模型之間效能與效率折衷的新見解，強調它們各自的優點和限制。這些發現提供了必要的基礎，以便針對特定檢索任務做出更明智的模型選擇決策，並強調了未來研究混合系統的途徑，該系統利用 FG 和 CG 方法的優點。

##### **Diffusion-DICE: In-Sample Diffusion Guidance for Offline Reinforcement Learning**
2407.20109v1 by Liyuan Mao, Haoran Xu, Weinan Zhang, Xianyuan Zhan, Amy Zhang

One important property of DIstribution Correction Estimation (DICE) methods
is that the solution is the optimal stationary distribution ratio between the
optimized and data collection policy. In this work, we show that DICE-based
methods can be viewed as a transformation from the behavior distribution to the
optimal policy distribution. Based on this, we propose a novel approach,
Diffusion-DICE, that directly performs this transformation using diffusion
models. We find that the optimal policy's score function can be decomposed into
two terms: the behavior policy's score function and the gradient of a guidance
term which depends on the optimal distribution ratio. The first term can be
obtained from a diffusion model trained on the dataset and we propose an
in-sample learning objective to learn the second term. Due to the
multi-modality contained in the optimal policy distribution, the transformation
in Diffusion-DICE may guide towards those local-optimal modes. We thus generate
a few candidate actions and carefully select from them to approach
global-optimum. Different from all other diffusion-based offline RL methods,
the guide-then-select paradigm in Diffusion-DICE only uses in-sample actions
for training and brings minimal error exploitation in the value function. We
use a didatic toycase example to show how previous diffusion-based methods fail
to generate optimal actions due to leveraging these errors and how
Diffusion-DICE successfully avoids that. We then conduct extensive experiments
on benchmark datasets to show the strong performance of Diffusion-DICE.

摘要：分佈修正估計 (DICE) 方法的一個重要屬性是，解為最佳化和資料收集政策之間的最佳穩態分佈比率。在這項工作中，我們展示基於 DICE 的方法可以視為從行為分佈到最佳政策分佈的轉換。基於此，我們提出了一種新穎的方法，擴散-DICE，它使用擴散模型直接執行此轉換。我們發現最佳政策的評分函數可以分解為兩個術語：行為政策的評分函數和依賴於最佳分佈比率的引導項的梯度。第一個術語可以從在資料集上訓練的擴散模型中獲得，我們提出了一個樣本內學習目標來學習第二個術語。由於最佳政策分佈中包含多模態，因此擴散-DICE 中的轉換可能會朝向那些局部最佳模式。因此，我們會產生一些候選動作，並從中仔細選擇以接近全局最優。與所有其他基於擴散的離線 RL 方法不同，擴散-DICE 中的先引導後選擇範例僅使用樣本內動作進行訓練，並在價值函數中帶來最小的錯誤利用。我們使用一個教學玩具案例來說明先前的基於擴散的方法如何因利用這些錯誤而無法產生最佳動作，以及擴散-DICE 如何成功避免這種情況。然後，我們在基準資料集上進行廣泛的實驗，以展示擴散-DICE 的強大效能。

