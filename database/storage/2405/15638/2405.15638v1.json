{"2405.15638": {"publish_time": "2024-05-24", "title": "M4U: Evaluating Multilingual Understanding and Reasoning for Large Multimodal Models", "paper_summary": "Multilingual multimodal reasoning is a core component in achieving\nhuman-level intelligence. However, most existing benchmarks for multilingual\nmultimodal reasoning struggle to differentiate between models of varying\nperformance; even language models without visual capabilities can easily\nachieve high scores. This leaves a comprehensive evaluation of leading\nmultilingual multimodal models largely unexplored. In this work, we introduce\nM4U, a novel and challenging benchmark for assessing the capability of\nmulti-discipline multilingual multimodal understanding and reasoning. M4U\ncontains 8,931 samples covering 64 disciplines across 16 subfields in Science,\nEngineering, and Healthcare in Chinese, English, and German. Using M4U, we\nconduct extensive evaluations of 21 leading Large Multimodal Models (LMMs) and\nLarge Language Models (LLMs) with external tools. The evaluation results show\nthat the state-of-the-art model, GPT-4o, achieves only 47.6% average accuracy\non M4U. Additionally, we observe that the leading LMMs exhibit significant\nlanguage preferences. Our in-depth analysis indicates that leading LMMs,\nincluding GPT-4o, suffer performance degradation when prompted with\ncross-lingual multimodal questions, such as images with key textual information\nin Chinese while the question is in German. We believe that M4U can serve as a\ncrucial tool for systematically evaluating LMMs based on their multilingual\nmultimodal reasoning capabilities and monitoring their development. The\nhomepage, codes and data are public available.", "paper_summary_zh": "<paragraph>\u591a\u6a21\u614b\u7684\u591a\u8a9e\u8a00\u63a8\u7406\u662f\u5be6\u73fe\u4eba\u985e\u667a\u6167\u7684\u6838\u5fc3\u7d44\u6210\u90e8\u5206\u3002\u7136\u800c\uff0c\u73fe\u6709\u7684\u591a\u6a21\u614b\u591a\u8a9e\u8a00\u63a8\u7406\u57fa\u6e96\u5728\u5340\u5206\u4e0d\u540c\u6548\u80fd\u7684\u6a21\u578b\u4e0a\u9047\u5230\u56f0\u96e3\uff1b\u5373\u4f7f\u6c92\u6709\u8996\u89ba\u80fd\u529b\u7684\u8a9e\u8a00\u6a21\u578b\u4e5f\u80fd\u8f15\u6613\u7372\u5f97\u9ad8\u5206\u3002\u9019\u4f7f\u5f97\u5c0d\u9818\u5148\u7684\u591a\u6a21\u614b\u591a\u8a9e\u8a00\u6a21\u578b\u7684\u5168\u9762\u8a55\u4f30\u5728\u5f88\u5927\u7a0b\u5ea6\u4e0a\u4ecd\u672a\u63a2\u7d22\u3002\u5728\u9019\u9805\u5de5\u4f5c\u4e2d\uff0c\u6211\u5011\u4ecb\u7d39\u4e86 M4U\uff0c\u9019\u662f\u4e00\u500b\u7528\u65bc\u8a55\u4f30\u591a\u5b78\u79d1\u591a\u8a9e\u8a00\u591a\u6a21\u614b\u7406\u89e3\u548c\u63a8\u7406\u80fd\u529b\u7684\u65b0\u7a4e\u4e14\u5177\u6709\u6311\u6230\u6027\u7684\u57fa\u6e96\u3002M4U \u5305\u542b 8,931 \u500b\u7bc4\u4f8b\uff0c\u6db5\u84cb\u79d1\u5b78\u3001\u5de5\u7a0b\u548c\u91ab\u7642\u4fdd\u5065\u9818\u57df\u7684 16 \u500b\u5b50\u9818\u57df\u7684 64 \u500b\u5b78\u79d1\uff0c\u8a9e\u8a00\u5305\u62ec\u4e2d\u6587\u3001\u82f1\u6587\u548c\u5fb7\u6587\u3002\u4f7f\u7528 M4U\uff0c\u6211\u5011\u5c0d 21 \u500b\u9818\u5148\u7684\u5927\u578b\u591a\u6a21\u614b\u6a21\u578b (LMM) \u548c\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u9032\u884c\u4e86\u5ee3\u6cdb\u8a55\u4f30\uff0c\u4e26\u4f7f\u7528\u4e86\u5916\u90e8\u5de5\u5177\u3002\u8a55\u4f30\u7d50\u679c\u986f\u793a\uff0c\u6700\u5148\u9032\u7684\u6a21\u578b GPT-4o \u5728 M4U \u4e0a\u50c5\u7372\u5f97 47.6% \u7684\u5e73\u5747\u6e96\u78ba\u5ea6\u3002\u6b64\u5916\uff0c\u6211\u5011\u89c0\u5bdf\u5230\u9818\u5148\u7684 LMM \u8868\u73fe\u51fa\u986f\u8457\u7684\u8a9e\u8a00\u504f\u597d\u3002\u6211\u5011\u7684\u6df1\u5165\u5206\u6790\u8868\u660e\uff0c\u5305\u62ec GPT-4o \u5728\u5167\u7684\u9818\u5148 LMM \u5728\u63d0\u793a\u4f7f\u7528\u8de8\u8a9e\u8a00\u591a\u6a21\u614b\u554f\u984c\u6642\u6703\u51fa\u73fe\u6548\u80fd\u4e0b\u964d\uff0c\u4f8b\u5982\u5716\u50cf\u4e2d\u5305\u542b\u4e2d\u6587\u95dc\u9375\u6587\u5b57\u8cc7\u8a0a\uff0c\u800c\u554f\u984c\u662f\u7528\u5fb7\u6587\u63d0\u51fa\u7684\u3002\u6211\u5011\u76f8\u4fe1 M4U \u53ef\u4ee5\u4f5c\u70ba\u4e00\u500b\u91cd\u8981\u7684\u5de5\u5177\uff0c\u7528\u65bc\u6839\u64da LMM \u7684\u591a\u8a9e\u8a00\u591a\u6a21\u614b\u63a8\u7406\u80fd\u529b\u5c0d\u5176\u9032\u884c\u7cfb\u7d71\u8a55\u4f30\uff0c\u4e26\u76e3\u63a7\u5176\u767c\u5c55\u3002\u9996\u9801\u3001\u7a0b\u5f0f\u78bc\u548c\u8cc7\u6599\u516c\u958b\u53ef\u7528\u3002</paragraph>", "author": "Hongyu Wang et.al.", "authors": "Hongyu Wang, Jiayu Xu, Senwei Xie, Ruiping Wang, Jialin Li, Zhaojie Xie, Bin Zhang, Chuyan Xiong, Xilin Chen", "id": "2405.15638v1", "paper_url": "http://arxiv.org/abs/2405.15638v1", "repo": "https://github.com/m4u-benchmark/m4u"}}