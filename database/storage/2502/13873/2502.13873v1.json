{"2502.13873": {"publish_time": "2025-02-19", "title": "NVR: Vector Runahead on NPUs for Sparse Memory Access", "paper_summary": "Deep Neural Networks are increasingly leveraging sparsity to reduce the\nscaling up of model parameter size. However, reducing wall-clock time through\nsparsity and pruning remains challenging due to irregular memory access\npatterns, leading to frequent cache misses. In this paper, we present NPU\nVector Runahead (NVR), a prefetching mechanism tailored for NPUs to address\ncache miss problems in sparse DNN workloads. Rather than optimising memory\npatterns with high overhead and poor portability, NVR adapts runahead execution\nto the unique architecture of NPUs. NVR provides a general micro-architectural\nsolution for sparse DNN workloads without requiring compiler or algorithmic\nsupport, operating as a decoupled, speculative, lightweight hardware sub-thread\nalongside the NPU, with minimal hardware overhead (under 5%). NVR achieves an\naverage 90% reduction in cache misses compared to SOTA prefetching in\ngeneral-purpose processors, delivering 4x average speedup on sparse workloads\nversus NPUs without prefetching. Moreover, we investigate the advantages of\nincorporating a small cache (16KB) into the NPU combined with NVR. Our\nevaluation shows that expanding this modest cache delivers 5x higher\nperformance benefits than increasing the L2 cache size by the same amount.", "paper_summary_zh": "\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u8d8a\u6765\u8d8a\u591a\u5730\u5229\u7528\u7a00\u758f\u6027\u6765\u51cf\u5c11\u6a21\u578b\u53c2\u6570\u5927\u5c0f\u7684\u6269\u5c55\u3002\u7136\u800c\uff0c\u7531\u4e8e\u4e0d\u89c4\u5219\u7684\u5185\u5b58\u8bbf\u95ee\u6a21\u5f0f\uff0c\u901a\u8fc7\u7a00\u758f\u6027\u548c\u526a\u679d\u6765\u51cf\u5c11\u65f6\u949f\u65f6\u95f4\u4ecd\u7136\u5177\u6709\u6311\u6218\u6027\uff0c\u5bfc\u81f4\u9891\u7e41\u7684\u7f13\u5b58\u672a\u547d\u4e2d\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u4eec\u63d0\u51fa\u4e86 NPU \u77e2\u91cf\u8d85\u524d (NVR)\uff0c\u8fd9\u662f\u4e00\u79cd\u9488\u5bf9 NPU \u91cf\u8eab\u5b9a\u5236\u7684\u9884\u53d6\u673a\u5236\uff0c\u4ee5\u89e3\u51b3\u7a00\u758f DNN \u5de5\u4f5c\u8d1f\u8f7d\u4e2d\u7684\u7f13\u5b58\u672a\u547d\u4e2d\u95ee\u9898\u3002NVR \u4e0d\u4f1a\u901a\u8fc7\u9ad8\u5f00\u9500\u548c\u8f83\u5dee\u7684\u53ef\u79fb\u690d\u6027\u6765\u4f18\u5316\u5185\u5b58\u6a21\u5f0f\uff0c\u800c\u662f\u5c06\u8d85\u524d\u6267\u884c\u8c03\u6574\u4e3a NPU \u7684\u72ec\u7279\u67b6\u6784\u3002NVR \u4e3a\u7a00\u758f DNN \u5de5\u4f5c\u8d1f\u8f7d\u63d0\u4f9b\u4e86\u4e00\u79cd\u901a\u7528\u7684\u5fae\u67b6\u6784\u89e3\u51b3\u65b9\u6848\uff0c\u65e0\u9700\u7f16\u8bd1\u5668\u6216\u7b97\u6cd5\u652f\u6301\uff0c\u4f5c\u4e3a NPU \u65c1\u8def\u7684\u4e00\u4e2a\u89e3\u8026\u7684\u3001\u63a8\u6d4b\u6027\u7684\u3001\u8f7b\u91cf\u7ea7\u7684\u786c\u4ef6\u5b50\u7ebf\u7a0b\u8fd0\u884c\uff0c\u4e14\u786c\u4ef6\u5f00\u9500\u6781\u5c0f\uff08\u4f4e\u4e8e 5%\uff09\u3002\u4e0e\u901a\u7528\u5904\u7406\u5668\u4e2d\u7684 SOTA \u9884\u53d6\u76f8\u6bd4\uff0cNVR \u5c06\u7f13\u5b58\u672a\u547d\u4e2d\u7387\u5e73\u5747\u964d\u4f4e\u4e86 90%\uff0c\u5728\u6ca1\u6709\u9884\u53d6\u7684 NPU \u4e0a\uff0c\u7a00\u758f\u5de5\u4f5c\u8d1f\u8f7d\u7684\u5e73\u5747\u52a0\u901f\u6bd4\u4e3a 4 \u500d\u3002\u6b64\u5916\uff0c\u6211\u4eec\u7814\u7a76\u4e86\u5c06\u4e00\u4e2a\u5c0f\u7f13\u5b58\uff0816KB\uff09\u4e0e NVR \u7ed3\u5408\u5230 NPU \u4e2d\u7684\u4f18\u52bf\u3002\u6211\u4eec\u7684\u8bc4\u4f30\u8868\u660e\uff0c\u6269\u5c55\u6b64\u9002\u5ea6\u7f13\u5b58\u63d0\u4f9b\u7684\u6027\u80fd\u4f18\u52bf\u6bd4\u5c06 L2 \u7f13\u5b58\u5927\u5c0f\u589e\u52a0\u76f8\u540c\u91cf\u9ad8 5 \u500d\u3002", "author": "Hui Wang et.al.", "authors": "Hui Wang, Zhengpeng Zhao, Jing Wang, Yushu Du, Yuan Cheng, Bing Guo, He Xiao, Chenhao Ma, Xiaomeng Han, Dean You, Jiapeng Guan, Ran Wei, Dawei Yang, Zhe Jiang", "id": "2502.13873v1", "paper_url": "http://arxiv.org/abs/2502.13873v1", "repo": "null"}}