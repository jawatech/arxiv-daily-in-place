{"2407.07087": {"publish_time": "2024-07-09", "title": "CopyBench: Measuring Literal and Non-Literal Reproduction of Copyright-Protected Text in Language Model Generation", "paper_summary": "Evaluating the degree of reproduction of copyright-protected content by\nlanguage models (LMs) is of significant interest to the AI and legal\ncommunities. Although both literal and non-literal similarities are considered\nby courts when assessing the degree of reproduction, prior research has focused\nonly on literal similarities. To bridge this gap, we introduce CopyBench, a\nbenchmark designed to measure both literal and non-literal copying in LM\ngenerations. Using copyrighted fiction books as text sources, we provide\nautomatic evaluation protocols to assess literal and non-literal copying,\nbalanced against the model utility in terms of the ability to recall facts from\nthe copyrighted works and generate fluent completions. We find that, although\nliteral copying is relatively rare, two types of non-literal copying -- event\ncopying and character copying -- occur even in models as small as 7B\nparameters. Larger models demonstrate significantly more copying, with literal\ncopying rates increasing from 0.2% to 10.5% and non-literal copying from 2.3%\nto 6.9% when comparing Llama3-8B and 70B models, respectively. We further\nevaluate the effectiveness of current strategies for mitigating copying and\nshow that (1) training-time alignment can reduce literal copying but may\nincrease non-literal copying, and (2) current inference-time mitigation methods\nprimarily reduce literal but not non-literal copying.", "paper_summary_zh": "\u8a55\u4f30\u8a9e\u8a00\u6a21\u578b (LM) \u8907\u88fd\u53d7\u7248\u6b0a\u4fdd\u8b77\u5167\u5bb9\u7684\u7a0b\u5ea6\uff0c\u5c0d AI \u548c\u6cd5\u5f8b\u793e\u7fa4\u800c\u8a00\u610f\u7fa9\u91cd\u5927\u3002\u5118\u7ba1\u6cd5\u9662\u5728\u8a55\u4f30\u8907\u88fd\u7a0b\u5ea6\u6642\u6703\u8003\u616e\u6587\u5b57\u548c\u975e\u6587\u5b57\u7684\u76f8\u4f3c\u6027\uff0c\u4f46\u5148\u524d\u7684\u7814\u7a76\u50c5\u95dc\u6ce8\u6587\u5b57\u76f8\u4f3c\u6027\u3002\u70ba\u4e86\u5f4c\u88dc\u9019\u500b\u5dee\u8ddd\uff0c\u6211\u5011\u5f15\u5165\u4e86 CopyBench\uff0c\u4e00\u500b\u57fa\u6e96\u6e2c\u8a66\uff0c\u65e8\u5728\u8861\u91cf LM \u751f\u6210\u4e2d\u7684\u6587\u5b57\u548c\u975e\u6587\u5b57\u8907\u88fd\u3002\u4f7f\u7528\u53d7\u7248\u6b0a\u4fdd\u8b77\u7684\u5c0f\u8aaa\u66f8\u7c4d\u4f5c\u70ba\u6587\u672c\u4f86\u6e90\uff0c\u6211\u5011\u63d0\u4f9b\u4e86\u81ea\u52d5\u8a55\u4f30\u5354\u5b9a\uff0c\u4ee5\u8a55\u4f30\u6587\u5b57\u548c\u975e\u6587\u5b57\u8907\u88fd\uff0c\u4e26\u6839\u64da\u5f9e\u53d7\u7248\u6b0a\u4fdd\u8b77\u7684\u4f5c\u54c1\u4e2d\u63d0\u53d6\u4e8b\u5be6\u548c\u7522\u751f\u6d41\u66a2\u5b8c\u6210\u7684\u80fd\u529b\uff0c\u4f86\u8861\u91cf\u6a21\u578b\u5be6\u7528\u6027\u3002\u6211\u5011\u767c\u73fe\uff0c\u5118\u7ba1\u6587\u5b57\u8907\u88fd\u76f8\u5c0d\u7f55\u898b\uff0c\u4f46\u5373\u4f7f\u5728\u53c3\u6578\u5c0f\u81f3 7B \u7684\u6a21\u578b\u4e2d\uff0c\u4e5f\u6703\u767c\u751f\u5169\u7a2e\u975e\u6587\u5b57\u8907\u88fd\u2014\u2014\u4e8b\u4ef6\u8907\u88fd\u548c\u89d2\u8272\u8907\u88fd\u3002\u8f03\u5927\u7684\u6a21\u578b\u986f\u793a\u51fa\u986f\u8457\u66f4\u591a\u7684\u8907\u88fd\uff0c\u7576\u6bd4\u8f03 Llama3-8B \u548c 70B \u6a21\u578b\u6642\uff0c\u6587\u5b57\u8907\u88fd\u7387\u5f9e 0.2% \u589e\u52a0\u5230 10.5%\uff0c\u975e\u6587\u5b57\u8907\u88fd\u5f9e 2.3% \u589e\u52a0\u5230 6.9%\u3002\u6211\u5011\u9032\u4e00\u6b65\u8a55\u4f30\u4e86\u7576\u524d\u6e1b\u8f15\u8907\u88fd\u7b56\u7565\u7684\u6709\u6548\u6027\uff0c\u4e26\u8868\u660e (1) \u8a13\u7df4\u6642\u9593\u6821\u6e96\u53ef\u4ee5\u6e1b\u5c11\u6587\u5b57\u8907\u88fd\uff0c\u4f46\u53ef\u80fd\u6703\u589e\u52a0\u975e\u6587\u5b57\u8907\u88fd\uff0c\u4ee5\u53ca (2) \u7576\u524d\u7684\u63a8\u8ad6\u6642\u9593\u6e1b\u8f15\u65b9\u6cd5\u4e3b\u8981\u6e1b\u5c11\u6587\u5b57\u8907\u88fd\uff0c\u4f46\u4e0d\u6703\u6e1b\u5c11\u975e\u6587\u5b57\u8907\u88fd\u3002", "author": "Tong Chen et.al.", "authors": "Tong Chen, Akari Asai, Niloofar Mireshghallah, Sewon Min, James Grimmelmann, Yejin Choi, Hannaneh Hajishirzi, Luke Zettlemoyer, Pang Wei Koh", "id": "2407.07087v1", "paper_url": "http://arxiv.org/abs/2407.07087v1", "repo": "null"}}