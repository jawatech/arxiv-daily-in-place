{"2501.18362": {"publish_time": "2025-01-30", "title": "MedXpertQA: Benchmarking Expert-Level Medical Reasoning and Understanding", "paper_summary": "We introduce MedXpertQA, a highly challenging and comprehensive benchmark to\nevaluate expert-level medical knowledge and advanced reasoning. MedXpertQA\nincludes 4,460 questions spanning 17 specialties and 11 body systems. It\nincludes two subsets, Text for text evaluation and MM for multimodal\nevaluation. Notably, MM introduces expert-level exam questions with diverse\nimages and rich clinical information, including patient records and examination\nresults, setting it apart from traditional medical multimodal benchmarks with\nsimple QA pairs generated from image captions. MedXpertQA applies rigorous\nfiltering and augmentation to address the insufficient difficulty of existing\nbenchmarks like MedQA, and incorporates specialty board questions to improve\nclinical relevance and comprehensiveness. We perform data synthesis to mitigate\ndata leakage risk and conduct multiple rounds of expert reviews to ensure\naccuracy and reliability. We evaluate 16 leading models on MedXpertQA.\nMoreover, medicine is deeply connected to real-world decision-making, providing\na rich and representative setting for assessing reasoning abilities beyond\nmathematics and code. To this end, we develop a reasoning-oriented subset to\nfacilitate the assessment of o1-like models.", "paper_summary_zh": "\u6211\u5011\u63a8\u51fa\u4e86 MedXpertQA\uff0c\u9019\u662f\u4e00\u500b\u6975\u5177\u6311\u6230\u6027\u4e14\u5168\u9762\u7684\u57fa\u6e96\uff0c\u7528\u65bc\u8a55\u4f30\u5c08\u5bb6\u7d1a\u7684\u91ab\u5b78\u77e5\u8b58\u548c\u5148\u9032\u7684\u63a8\u7406\u80fd\u529b\u3002MedXpertQA \u5305\u542b 4,460 \u500b\u554f\u984c\uff0c\u6db5\u84cb 17 \u500b\u5c08\u79d1\u548c 11 \u500b\u8eab\u9ad4\u7cfb\u7d71\u3002\u5b83\u5305\u542b\u5169\u500b\u5b50\u96c6\uff0c\u6587\u672c\u7528\u65bc\u6587\u672c\u8a55\u4f30\uff0cMM \u7528\u65bc\u591a\u6a21\u5f0f\u8a55\u4f30\u3002\u503c\u5f97\u6ce8\u610f\u7684\u662f\uff0cMM \u5f15\u5165\u4e86\u5c08\u5bb6\u7d1a\u8003\u8a66\u984c\u76ee\uff0c\u5176\u4e2d\u5305\u542b\u591a\u6a23\u5316\u7684\u5f71\u50cf\u548c\u8c50\u5bcc\u7684\u81e8\u5e8a\u8cc7\u8a0a\uff0c\u5305\u62ec\u60a3\u8005\u8a18\u9304\u548c\u6aa2\u67e5\u7d50\u679c\uff0c\u9019\u8b93\u5b83\u6709\u5225\u65bc\u50b3\u7d71\u7684\u91ab\u5b78\u591a\u6a21\u5f0f\u57fa\u6e96\uff0c\u5f8c\u8005\u662f\u5f9e\u5f71\u50cf\u6a19\u984c\u4e2d\u7522\u751f\u7684\u7c21\u55ae\u554f\u7b54\u5c0d\u3002MedXpertQA \u63a1\u7528\u56b4\u683c\u7684\u904e\u6ffe\u548c\u64f4\u5145\uff0c\u4ee5\u89e3\u6c7a MedQA \u7b49\u73fe\u6709\u57fa\u6e96\u7684\u96e3\u5ea6\u4e0d\u8db3\u554f\u984c\uff0c\u4e26\u7d0d\u5165\u5c08\u79d1\u59d4\u54e1\u6703\u554f\u984c\u4ee5\u63d0\u9ad8\u81e8\u5e8a\u76f8\u95dc\u6027\u548c\u5168\u9762\u6027\u3002\u6211\u5011\u57f7\u884c\u8cc7\u6599\u5408\u6210\u4ee5\u964d\u4f4e\u8cc7\u6599\u5916\u6d29\u98a8\u96aa\uff0c\u4e26\u9032\u884c\u591a\u8f2a\u5c08\u5bb6\u5be9\u67e5\u4ee5\u78ba\u4fdd\u6e96\u78ba\u6027\u548c\u53ef\u9760\u6027\u3002\u6211\u5011\u5728 MedXpertQA \u4e0a\u8a55\u4f30\u4e86 16 \u500b\u9818\u5148\u7684\u6a21\u578b\u3002\u6b64\u5916\uff0c\u91ab\u5b78\u8207\u73fe\u5be6\u4e16\u754c\u7684\u6c7a\u7b56\u5236\u5b9a\u6709\u5bc6\u5207\u7684\u806f\u7e6b\uff0c\u63d0\u4f9b\u4e86\u8c50\u5bcc\u4e14\u5177\u4ee3\u8868\u6027\u7684\u74b0\u5883\uff0c\u7528\u65bc\u8a55\u4f30\u8d85\u8d8a\u6578\u5b78\u548c\u7a0b\u5f0f\u78bc\u7684\u63a8\u7406\u80fd\u529b\u3002\u70ba\u6b64\uff0c\u6211\u5011\u958b\u767c\u4e86\u4e00\u500b\u4ee5\u63a8\u7406\u70ba\u5c0e\u5411\u7684\u5b50\u96c6\uff0c\u4ee5\u5229\u65bc\u8a55\u4f30\u985e o1 \u7684\u6a21\u578b\u3002", "author": "Yuxin Zuo et.al.", "authors": "Yuxin Zuo, Shang Qu, Yifei Li, Zhangren Chen, Xuekai Zhu, Ermo Hua, Kaiyan Zhang, Ning Ding, Bowen Zhou", "id": "2501.18362v1", "paper_url": "http://arxiv.org/abs/2501.18362v1", "repo": "null"}}