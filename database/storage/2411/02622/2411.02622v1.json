{"2411.02622": {"publish_time": "2024-11-04", "title": "Pseudo-Probability Unlearning: Towards Efficient and Privacy-Preserving Machine Unlearning", "paper_summary": "Machine unlearning--enabling a trained model to forget specific data--is\ncrucial for addressing biased data and adhering to privacy regulations like the\nGeneral Data Protection Regulation (GDPR)'s \"right to be forgotten\". Recent\nworks have paid little attention to privacy concerns, leaving the data intended\nfor forgetting vulnerable to membership inference attacks. Moreover, they often\ncome with high computational overhead. In this work, we propose\nPseudo-Probability Unlearning (PPU), a novel method that enables models to\nforget data efficiently and in a privacy-preserving manner. Our method replaces\nthe final-layer output probabilities of the neural network with\npseudo-probabilities for the data to be forgotten. These pseudo-probabilities\nfollow either a uniform distribution or align with the model's overall\ndistribution, enhancing privacy and reducing risk of membership inference\nattacks. Our optimization strategy further refines the predictive probability\ndistributions and updates the model's weights accordingly, ensuring effective\nforgetting with minimal impact on the model's overall performance. Through\ncomprehensive experiments on multiple benchmarks, our method achieves over 20%\nimprovements in forgetting error compared to the state-of-the-art.\nAdditionally, our method enhances privacy by preventing the forgotten set from\nbeing inferred to around random guesses.", "paper_summary_zh": "\u6a5f\u5668\u907a\u5fd8\u2014\u2014\u8b93\u8a13\u7df4\u597d\u7684\u6a21\u578b\u5fd8\u8a18\u7279\u5b9a\u8cc7\u6599\u2014\u2014\u5c0d\u65bc\u89e3\u6c7a\u6709\u504f\u5dee\u7684\u8cc7\u6599\u548c\u9075\u5b88\u96b1\u79c1\u6cd5\u898f\uff08\u4f8b\u5982\u4e00\u822c\u8cc7\u6599\u4fdd\u8b77\u6cd5\u898f (GDPR) \u7684\u300c\u88ab\u907a\u5fd8\u6b0a\u300d\uff09\u81f3\u95dc\u91cd\u8981\u3002\u6700\u8fd1\u7684\u7814\u7a76\u9bae\u5c11\u95dc\u6ce8\u96b1\u79c1\u554f\u984c\uff0c\u5c0e\u81f4\u9810\u8a08\u8981\u907a\u5fd8\u7684\u8cc7\u6599\u5bb9\u6613\u53d7\u5230\u6210\u54e1\u63a8\u8ad6\u653b\u64ca\u3002\u6b64\u5916\uff0c\u5b83\u5011\u901a\u5e38\u4f34\u96a8\u8457\u9ad8\u904b\u7b97\u8ca0\u64d4\u3002\u5728\u9019\u9805\u7814\u7a76\u4e2d\uff0c\u6211\u5011\u63d0\u51fa\u507d\u6a5f\u7387\u907a\u5fd8 (PPU)\uff0c\u4e00\u7a2e\u5275\u65b0\u7684\u65b9\u6cd5\uff0c\u8b93\u6a21\u578b\u80fd\u5920\u6709\u6548\u4e14\u4ee5\u4fdd\u8b77\u96b1\u79c1\u7684\u65b9\u5f0f\u907a\u5fd8\u8cc7\u6599\u3002\u6211\u5011\u7684\u505a\u6cd5\u662f\u5c07\u795e\u7d93\u7db2\u8def\u7684\u6700\u7d42\u5c64\u8f38\u51fa\u6a5f\u7387\u66ff\u63db\u70ba\u8981\u907a\u5fd8\u8cc7\u6599\u7684\u507d\u6a5f\u7387\u3002\u9019\u4e9b\u507d\u6a5f\u7387\u9075\u5faa\u5747\u52fb\u5206\u4f48\u6216\u8207\u6a21\u578b\u7684\u6574\u9ad4\u5206\u4f48\u4e00\u81f4\uff0c\u589e\u5f37\u96b1\u79c1\u4e26\u964d\u4f4e\u6210\u54e1\u63a8\u8ad6\u653b\u64ca\u7684\u98a8\u96aa\u3002\u6211\u5011\u7684\u6700\u4f73\u5316\u7b56\u7565\u9032\u4e00\u6b65\u6539\u5584\u9810\u6e2c\u6a5f\u7387\u5206\u4f48\uff0c\u4e26\u76f8\u61c9\u5730\u66f4\u65b0\u6a21\u578b\u7684\u6b0a\u91cd\uff0c\u78ba\u4fdd\u6709\u6548\u907a\u5fd8\uff0c\u540c\u6642\u5c07\u5c0d\u6a21\u578b\u6574\u9ad4\u6548\u80fd\u7684\u5f71\u97ff\u964d\u81f3\u6700\u4f4e\u3002\u900f\u904e\u5728\u591a\u500b\u57fa\u6e96\u4e0a\u9032\u884c\u5168\u9762\u5be6\u9a57\uff0c\u6211\u5011\u7684\u505a\u6cd5\u5728\u907a\u5fd8\u932f\u8aa4\u65b9\u9762\u6bd4\u6700\u5148\u9032\u6280\u8853\u9032\u6b65\u4e86 20% \u4ee5\u4e0a\u3002\u6b64\u5916\uff0c\u6211\u5011\u7684\u505a\u6cd5\u900f\u904e\u9632\u6b62\u63a8\u8ad6\u51fa\u907a\u5fd8\u7684\u96c6\u5408\u800c\u589e\u5f37\u96b1\u79c1\uff0c\u63a8\u8ad6\u7d50\u679c\u63a5\u8fd1\u96a8\u6a5f\u731c\u6e2c\u3002", "author": "Zihao Zhao et.al.", "authors": "Zihao Zhao, Yijiang Li, Yuchen Yang, Wenqing Zhang, Nuno Vasconcelos, Yinzhi Cao", "id": "2411.02622v1", "paper_url": "http://arxiv.org/abs/2411.02622v1", "repo": "null"}}