{"2408.02201": {"publish_time": "2024-08-05", "title": "Evaluating the Performance of Large Language Models for SDG Mapping (Technical Report)", "paper_summary": "The use of large language models (LLMs) is expanding rapidly, and open-source\nversions are becoming available, offering users safer and more adaptable\noptions. These models enable users to protect data privacy by eliminating the\nneed to provide data to third parties and can be customized for specific tasks.\nIn this study, we compare the performance of various language models on the\nSustainable Development Goal (SDG) mapping task, using the output of GPT-4o as\nthe baseline. The selected open-source models for comparison include Mixtral,\nLLaMA 2, LLaMA 3, Gemma, and Qwen2. Additionally, GPT-4o-mini, a more\nspecialized version of GPT-4o, was included to extend the comparison. Given the\nmulti-label nature of the SDG mapping task, we employed metrics such as F1\nscore, precision, and recall with micro-averaging to evaluate different aspects\nof the models' performance. These metrics are derived from the confusion matrix\nto ensure a comprehensive evaluation. We provide a clear observation and\nanalysis of each model's performance by plotting curves based on F1 score,\nprecision, and recall at different thresholds. According to the results of this\nexperiment, LLaMA 2 and Gemma still have significant room for improvement. The\nother four models do not exhibit particularly large differences in performance.\nThe outputs from all seven models are available on Zenodo:\nhttps://doi.org/10.5281/zenodo.12789375.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u4f7f\u7528\u6b63\u5728\u8fc5\u901f\u64f4\u5c55\uff0c\u4e14\u958b\u653e\u539f\u59cb\u78bc\u7248\u672c\u4e5f\u6b63\u8b8a\u5f97\u53ef\u5f97\uff0c\u70ba\u4f7f\u7528\u8005\u63d0\u4f9b\u66f4\u5b89\u5168\u4e14\u66f4\u5177\u9069\u61c9\u6027\u7684\u9078\u9805\u3002\u9019\u4e9b\u6a21\u578b\u8b93\u4f7f\u7528\u8005\u80fd\u900f\u904e\u6d88\u9664\u63d0\u4f9b\u8cc7\u6599\u7d66\u7b2c\u4e09\u65b9\u7684\u9700\u6c42\u4f86\u4fdd\u8b77\u8cc7\u6599\u96b1\u79c1\uff0c\u4e14\u80fd\u91dd\u5c0d\u7279\u5b9a\u4efb\u52d9\u9032\u884c\u5ba2\u88fd\u5316\u3002\u5728\u6b64\u7814\u7a76\u4e2d\uff0c\u6211\u5011\u6bd4\u8f03\u4e86\u5404\u7a2e\u8a9e\u8a00\u6a21\u578b\u5728\u6c38\u7e8c\u767c\u5c55\u76ee\u6a19\uff08SDG\uff09\u5c0d\u61c9\u4efb\u52d9\u4e0a\u7684\u8868\u73fe\uff0c\u4e26\u4f7f\u7528 GPT-4o \u7684\u8f38\u51fa\u4f5c\u70ba\u57fa\u6e96\u3002\u6240\u9078\u7528\u65bc\u6bd4\u8f03\u4e4b\u958b\u653e\u539f\u59cb\u78bc\u6a21\u578b\u5305\u62ec Mixtral\u3001LLaMA 2\u3001LLaMA 3\u3001Gemma \u548c Qwen2\u3002\u6b64\u5916\uff0c\u9084\u52a0\u5165\u4e86 GPT-4o \u7684\u66f4\u5c08\u696d\u7248\u672c GPT-4o-mini \u4ee5\u64f4\u5145\u6bd4\u8f03\u3002\u8003\u91cf\u5230 SDG \u5c0d\u61c9\u4efb\u52d9\u7684\u591a\u6a19\u7c64\u6027\u8cea\uff0c\u6211\u5011\u63a1\u7528\u4e86 F1 \u5206\u6578\u3001\u7cbe\u78ba\u5ea6\u548c\u53ec\u56de\u7387\u7b49\u6307\u6a19\uff0c\u4e26\u4f7f\u7528\u5fae\u5e73\u5747\u4f86\u8a55\u4f30\u6a21\u578b\u8868\u73fe\u7684\u4e0d\u540c\u9762\u5411\u3002\u9019\u4e9b\u6307\u6a19\u7686\u884d\u751f\u81ea\u6df7\u6dc6\u77e9\u9663\uff0c\u4ee5\u78ba\u4fdd\u8a55\u4f30\u7684\u5168\u9762\u6027\u3002\u6211\u5011\u900f\u904e\u7e6a\u88fd\u57fa\u65bc\u4e0d\u540c\u95be\u503c\u7684 F1 \u5206\u6578\u3001\u7cbe\u78ba\u5ea6\u548c\u53ec\u56de\u7387\u7684\u66f2\u7dda\uff0c\u63d0\u4f9b\u6bcf\u500b\u6a21\u578b\u8868\u73fe\u7684\u660e\u78ba\u89c0\u5bdf\u548c\u5206\u6790\u3002\u6839\u64da\u6b64\u5be6\u9a57\u7684\u7d50\u679c\uff0cLLaMA 2 \u548c Gemma \u4ecd\u6709\u986f\u8457\u7684\u9032\u6b65\u7a7a\u9593\u3002\u5176\u4ed6\u56db\u500b\u6a21\u578b\u5728\u8868\u73fe\u4e0a\u6c92\u6709\u7279\u5225\u5927\u7684\u5dee\u7570\u3002\u6240\u6709\u4e03\u500b\u6a21\u578b\u7684\u8f38\u51fa\u7686\u53ef\u5728 Zenodo \u4e0a\u53d6\u5f97\uff1ahttps://doi.org/10.5281/zenodo.12789375\u3002", "author": "Hui Yin et.al.", "authors": "Hui Yin, Amir Aryani, Nakul Nambiar", "id": "2408.02201v1", "paper_url": "http://arxiv.org/abs/2408.02201v1", "repo": "null"}}