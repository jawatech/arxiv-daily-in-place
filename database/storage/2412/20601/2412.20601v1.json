{"2412.20601": {"publish_time": "2024-12-29", "title": "MATEY: multiscale adaptive foundation models for spatiotemporal physical systems", "paper_summary": "Accurate representation of the multiscale features in spatiotemporal physical\nsystems using vision transformer (ViT) architectures requires extremely long,\ncomputationally prohibitive token sequences. To address this issue, we propose\ntwo adaptive tokenization schemes that dynamically adjust patch sizes based on\nlocal features: one ensures convergent behavior to uniform patch refinement,\nwhile the other offers better computational efficiency. Moreover, we present a\nset of spatiotemporal attention schemes, where the temporal or axial spatial\ndimensions are decoupled, and evaluate their computational and data\nefficiencies. We assess the performance of the proposed multiscale adaptive\nmodel, MATEY, in a sequence of experiments. The results show that adaptive\ntokenization schemes achieve improved accuracy without significantly increasing\nthe length of the token sequence. Compared to a full spatiotemporal attention\nscheme or a scheme that decouples only the temporal dimension, we find that\nfully decoupled axial attention is less efficient and expressive, requiring\nmore training time and model weights to achieve the same accuracy. Finally, we\ndemonstrate in two fine-tuning tasks featuring different physics that models\npretrained on PDEBench data outperform the ones trained from scratch,\nespecially in the low data regime with frozen attention.", "paper_summary_zh": "\u4f7f\u7528\u8996\u89baTransformer (ViT) \u67b6\u69cb\u7cbe\u78ba\u8868\u793a\u6642\u7a7a\u7269\u7406\u7cfb\u7d71\u4e2d\u7684\u591a\u5c3a\u5ea6\u7279\u5fb5\u9700\u8981\u6975\u9577\u4e14\u8a08\u7b97\u6210\u672c\u904e\u9ad8\u7684\u6a19\u8a18\u5e8f\u5217\u3002\u70ba\u4e86\u89e3\u6c7a\u6b64\u554f\u984c\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u5169\u7a2e\u81ea\u9069\u61c9\u6a19\u8a18\u5316\u67b6\u69cb\uff0c\u53ef\u6839\u64da\u5c40\u90e8\u7279\u5fb5\u52d5\u614b\u8abf\u6574\u5340\u584a\u5927\u5c0f\uff1a\u4e00\u7a2e\u78ba\u4fdd\u6536\u6582\u884c\u70ba\u4ee5\u9032\u884c\u5747\u52fb\u5340\u584a\u7d30\u5316\uff0c\u800c\u53e6\u4e00\u7a2e\u5247\u63d0\u4f9b\u66f4\u597d\u7684\u8a08\u7b97\u6548\u7387\u3002\u6b64\u5916\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u4e00\u7d44\u6642\u7a7a\u6ce8\u610f\u529b\u67b6\u69cb\uff0c\u5176\u4e2d\u6642\u5e8f\u6216\u8ef8\u5411\u7a7a\u9593\u7dad\u5ea6\u662f\u89e3\u8026\u7684\uff0c\u4e26\u8a55\u4f30\u5176\u8a08\u7b97\u548c\u8cc7\u6599\u6548\u7387\u3002\u6211\u5011\u5728\u5be6\u9a57\u5e8f\u5217\u4e2d\u8a55\u4f30\u6240\u63d0\u51fa\u7684\u591a\u5c3a\u5ea6\u81ea\u9069\u61c9\u6a21\u578b MATEY \u7684\u6548\u80fd\u3002\u7d50\u679c\u986f\u793a\uff0c\u81ea\u9069\u61c9\u6a19\u8a18\u5316\u67b6\u69cb\u5728\u672a\u986f\u8457\u589e\u52a0\u6a19\u8a18\u5e8f\u5217\u9577\u5ea6\u7684\u60c5\u6cc1\u4e0b\uff0c\u53ef\u63d0\u9ad8\u6e96\u78ba\u5ea6\u3002\u8207\u5b8c\u5168\u6642\u7a7a\u6ce8\u610f\u529b\u67b6\u69cb\u6216\u50c5\u89e3\u8026\u6642\u5e8f\u7dad\u5ea6\u7684\u67b6\u69cb\u76f8\u6bd4\uff0c\u6211\u5011\u767c\u73fe\u5b8c\u5168\u89e3\u8026\u7684\u8ef8\u5411\u6ce8\u610f\u529b\u6548\u7387\u8f03\u4f4e\u4e14\u8868\u9054\u529b\u8f03\u5dee\uff0c\u9700\u8981\u66f4\u591a\u8a13\u7df4\u6642\u9593\u548c\u6a21\u578b\u6b0a\u91cd\u624d\u80fd\u9054\u5230\u76f8\u540c\u7684\u6e96\u78ba\u5ea6\u3002\u6700\u5f8c\uff0c\u6211\u5011\u5728\u5169\u500b\u5177\u6709\u4e0d\u540c\u7269\u7406\u7279\u6027\u7684\u5fae\u8abf\u4efb\u52d9\u4e2d\u8b49\u660e\uff0c\u5728 PDEBench \u8cc7\u6599\u4e0a\u9810\u5148\u8a13\u7df4\u7684\u6a21\u578b\u512a\u65bc\u5f9e\u982d\u958b\u59cb\u8a13\u7df4\u7684\u6a21\u578b\uff0c\u7279\u5225\u662f\u5728\u51cd\u7d50\u6ce8\u610f\u529b\u7684\u4f4e\u8cc7\u6599\u7bc4\u570d\u5167\u3002", "author": "Pei Zhang et.al.", "authors": "Pei Zhang, M. Paul Laiu, Matthew Norman, Doug Stefanski, John Gounley", "id": "2412.20601v1", "paper_url": "http://arxiv.org/abs/2412.20601v1", "repo": "null"}}