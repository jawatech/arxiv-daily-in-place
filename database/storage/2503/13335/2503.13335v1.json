{"2503.13335": {"publish_time": "2025-03-17", "title": "Reliable and Efficient Amortized Model-based Evaluation", "paper_summary": "Comprehensive evaluations of language models (LM) during both development and\ndeployment phases are necessary because these models possess numerous\ncapabilities (e.g., mathematical reasoning, legal support, or medical\ndiagnostic) as well as safety risks (e.g., racial bias, toxicity, or\nmisinformation). The average score across a wide range of benchmarks provides a\nsignal that helps guide the use of these LMs in practice. Currently, holistic\nevaluations are costly due to the large volume of benchmark questions, making\nfrequent evaluations impractical. A popular attempt to lower the cost is to\ncompute the average score on a subset of the benchmark. This approach,\nunfortunately, often renders an unreliable measure of LM performance because\nthe average score is often confounded with the difficulty of the questions in\nthe benchmark subset. Item response theory (IRT) was designed to address this\nchallenge, providing a reliable measurement by careful controlling for question\ndifficulty. Unfortunately, question difficulty is expensive to estimate. Facing\nthis challenge, we train a model that predicts question difficulty from its\ncontent, enabling a reliable measurement at a fraction of the cost. In\naddition, we leverage this difficulty predictor to further improve the\nevaluation efficiency through training a question generator given a difficulty\nlevel. This question generator is essential in adaptive testing, where, instead\nof using a random subset of the benchmark questions, informative questions are\nadaptively chosen based on the current estimation of LLM performance.\nExperiments on 22 common natural language benchmarks and 172 LMs show that this\napproach is more reliable and efficient compared to current common practice.", "paper_summary_zh": "<paragraph>\u5728\u958b\u767c\u548c\u90e8\u7f72\u968e\u6bb5\uff0c\u5c0d\u8a9e\u8a00\u6a21\u578b (LM) \u9032\u884c\u5168\u9762\u8a55\u4f30\u81f3\u95dc\u91cd\u8981\uff0c\u56e0\u70ba\u9019\u4e9b\u6a21\u578b\u5177\u5099\u773e\u591a\u529f\u80fd\uff08\u4f8b\u5982\uff1a\u6578\u5b78\u63a8\u7406\u3001\u6cd5\u5f8b\u652f\u63f4\u6216\u91ab\u7642\u8a3a\u65b7\uff09\uff0c\u540c\u6642\u4e5f\u5b58\u5728\u5b89\u5168\u98a8\u96aa\uff08\u4f8b\u5982\uff1a\u7a2e\u65cf\u504f\u898b\u3001\u60e1\u610f\u8a00\u8ad6\u6216\u932f\u8aa4\u8cc7\u8a0a\uff09\u3002\u8de8\u591a\u7a2e\u57fa\u6e96\u6e2c\u8a66\u7684\u5e73\u5747\u5206\u6578\u63d0\u4f9b\u4e86\u4e00\u500b\u4fe1\u865f\uff0c\u6709\u52a9\u65bc\u6307\u5c0e\u5728\u5be6\u52d9\u4e2d\u4f7f\u7528\u9019\u4e9b LM\u3002\u76ee\u524d\uff0c\u7531\u65bc\u57fa\u6e96\u6e2c\u8a66\u984c\u91cf\u9f90\u5927\uff0c\u6574\u9ad4\u8a55\u4f30\u6210\u672c\u9ad8\u6602\uff0c\u4f7f\u5f97\u983b\u7e41\u8a55\u4f30\u8b8a\u5f97\u4e0d\u5207\u5be6\u969b\u3002\u964d\u4f4e\u6210\u672c\u7684\u4e00\u500b\u5e38\u898b\u505a\u6cd5\u662f\u8a08\u7b97\u57fa\u6e96\u6e2c\u8a66\u5b50\u96c6\u7684\u5e73\u5747\u5206\u6578\u3002\u907a\u61be\u7684\u662f\uff0c\u9019\u7a2e\u65b9\u6cd5\u901a\u5e38\u6703\u5c0e\u81f4 LM \u6027\u80fd\u8861\u91cf\u6307\u6a19\u4e0d\u53ef\u9760\uff0c\u56e0\u70ba\u5e73\u5747\u5206\u6578\u5f80\u5f80\u6703\u8207\u57fa\u6e96\u6e2c\u8a66\u5b50\u96c6\u4e2d\u984c\u76ee\u7684\u96e3\u5ea6\u6df7\u6dc6\u3002\u9805\u76ee\u53cd\u61c9\u7406\u8ad6 (IRT) \u7684\u8a2d\u8a08\u65e8\u5728\u61c9\u5c0d\u9019\u4e00\u6311\u6230\uff0c\u5b83\u900f\u904e\u4ed4\u7d30\u63a7\u5236\u984c\u76ee\u96e3\u5ea6\u4f86\u63d0\u4f9b\u53ef\u9760\u7684\u8861\u91cf\u6a19\u6e96\u3002\u907a\u61be\u7684\u662f\uff0c\u4f30\u7b97\u984c\u76ee\u96e3\u5ea6\u6210\u672c\u9ad8\u6602\u3002\u9762\u5c0d\u9019\u4e00\u6311\u6230\uff0c\u6211\u5011\u8a13\u7df4\u4e86\u4e00\u500b\u6a21\u578b\uff0c\u53ef\u4ee5\u6839\u64da\u984c\u76ee\u5167\u5bb9\u9810\u6e2c\u984c\u76ee\u96e3\u5ea6\uff0c\u5f9e\u800c\u4ee5\u4e00\u5c0f\u90e8\u5206\u6210\u672c\u5be6\u73fe\u53ef\u9760\u7684\u8861\u91cf\u3002\u6b64\u5916\uff0c\u6211\u5011\u5229\u7528\u9019\u500b\u96e3\u5ea6\u9810\u6e2c\u5668\uff0c\u900f\u904e\u6839\u64da\u96e3\u5ea6\u7d1a\u5225\u8a13\u7df4\u4e00\u500b\u984c\u76ee\u751f\u6210\u5668\uff0c\u4f86\u9032\u4e00\u6b65\u63d0\u9ad8\u8a55\u4f30\u6548\u7387\u3002\u9019\u500b\u984c\u76ee\u751f\u6210\u5668\u5728\u81ea\u9069\u61c9\u6e2c\u8a66\u4e2d\u81f3\u95dc\u91cd\u8981\uff0c\u5728\u81ea\u9069\u61c9\u6e2c\u8a66\u4e2d\uff0c\u4e0d\u662f\u4f7f\u7528\u57fa\u6e96\u6e2c\u8a66\u984c\u76ee\u7684\u96a8\u6a5f\u5b50\u96c6\uff0c\u800c\u662f\u6839\u64da\u7576\u524d\u5c0d LLM \u6027\u80fd\u7684\u4f30\u8a08\u81ea\u9069\u61c9\u5730\u9078\u64c7\u8cc7\u8a0a\u91cf\u5927\u7684\u984c\u76ee\u3002\u5728 22 \u500b\u5e38\u898b\u81ea\u7136\u8a9e\u8a00\u57fa\u6e96\u6e2c\u8a66\u548c 172 \u500b LM \u4e0a\u9032\u884c\u7684\u5be6\u9a57\u8868\u660e\uff0c\u8207\u76ee\u524d\u7684\u5e38\u898b\u505a\u6cd5\u76f8\u6bd4\uff0c\u9019\u7a2e\u65b9\u6cd5\u66f4\u53ef\u9760\u3001\u66f4\u9ad8\u6548\u3002</paragraph>\n", "author": "Sang Truong et.al.", "authors": "Sang Truong, Yuheng Tu, Percy Liang, Bo Li, Sanmi Koyejo", "id": "2503.13335v1", "paper_url": "http://arxiv.org/abs/2503.13335v1", "repo": "null"}}