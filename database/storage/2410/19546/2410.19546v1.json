{"2410.19546": {"publish_time": "2024-10-25", "title": "Bongard in Wonderland: Visual Puzzles that Still Make AI Go Mad?", "paper_summary": "Recently, newly developed Vision-Language Models (VLMs), such as OpenAI's\nGPT-4o, have emerged, seemingly demonstrating advanced reasoning capabilities\nacross text and image modalities. Yet, the depth of these advances in\nlanguage-guided perception and abstract reasoning remains underexplored, and it\nis unclear whether these models can truly live up to their ambitious promises.\nTo assess the progress and identify shortcomings, we enter the wonderland of\nBongard problems, a set of classical visual reasoning puzzles that require\nhuman-like abilities of pattern recognition and abstract reasoning. While VLMs\noccasionally succeed in identifying discriminative concepts and solving some of\nthe problems, they frequently falter, failing to understand and reason about\nvisual concepts. Surprisingly, even elementary concepts that may seem trivial\nto humans, such as simple spirals, pose significant challenges. Moreover, even\nwhen asked to explicitly focus on and analyze these concepts, they continue to\nfalter, suggesting not only a lack of understanding of these elementary visual\nconcepts but also an inability to generalize to unseen concepts. These\nobservations underscore the current limitations of VLMs, emphasize that a\nsignificant gap remains between human-like visual reasoning and machine\ncognition, and highlight the ongoing need for innovation in this area.", "paper_summary_zh": "\u6700\u8fd1\uff0c\u65b0\u5f00\u53d1\u7684\u89c6\u89c9\u8bed\u8a00\u6a21\u578b (VLM)\uff0c\u4f8b\u5982 OpenAI \u7684 GPT-4o\uff0c\u5df2\u5e94\u8fd0\u800c\u751f\uff0c\u4f3c\u4e4e\u5c55\u793a\u4e86\u8de8\u6587\u672c\u548c\u56fe\u50cf\u6a21\u5f0f\u7684\u9ad8\u7ea7\u63a8\u7406\u80fd\u529b\u3002\u7136\u800c\uff0c\u8bed\u8a00\u5f15\u5bfc\u611f\u77e5\u548c\u62bd\u8c61\u63a8\u7406\u7684\u8fd9\u4e9b\u8fdb\u6b65\u7684\u6df1\u5ea6\u4ecd\u672a\u5f97\u5230\u5145\u5206\u63a2\u7d22\uff0c\u5e76\u4e14\u76ee\u524d\u5c1a\u4e0d\u6e05\u695a\u8fd9\u4e9b\u6a21\u578b\u662f\u5426\u771f\u6b63\u80fd\u591f\u5151\u73b0\u5176\u96c4\u5fc3\u52c3\u52c3\u7684\u627f\u8bfa\u3002\u4e3a\u4e86\u8bc4\u4f30\u8fdb\u5c55\u5e76\u627e\u51fa\u4e0d\u8db3\u4e4b\u5904\uff0c\u6211\u4eec\u8fdb\u5165\u4e86\u90a6\u52a0\u5fb7\u95ee\u9898\u7684\u795e\u5947\u4e16\u754c\uff0c\u8fd9\u662f\u4e00\u7ec4\u7ecf\u5178\u7684\u89c6\u89c9\u63a8\u7406\u96be\u9898\uff0c\u9700\u8981\u4eba\u7c7b\u822c\u7684\u6a21\u5f0f\u8bc6\u522b\u548c\u62bd\u8c61\u63a8\u7406\u80fd\u529b\u3002\u867d\u7136 VLM \u5076\u5c14\u80fd\u591f\u6210\u529f\u8bc6\u522b\u8fa8\u522b\u6027\u6982\u5ff5\u5e76\u89e3\u51b3\u5176\u4e2d\u4e00\u4e9b\u95ee\u9898\uff0c\u4f46\u5b83\u4eec\u7ecf\u5e38\u51fa\u73b0\u5931\u8bef\uff0c\u65e0\u6cd5\u7406\u89e3\u548c\u63a8\u7406\u89c6\u89c9\u6982\u5ff5\u3002\u4ee4\u4eba\u60ca\u8bb6\u7684\u662f\uff0c\u5373\u4f7f\u662f\u4eba\u7c7b\u770b\u6765\u5fae\u4e0d\u8db3\u9053\u7684\u57fa\u672c\u6982\u5ff5\uff0c\u4f8b\u5982\u7b80\u5355\u7684\u87ba\u65cb\uff0c\u4e5f\u6784\u6210\u4e86\u91cd\u5927\u6311\u6218\u3002\u6b64\u5916\uff0c\u5373\u4f7f\u8981\u6c42\u5b83\u4eec\u660e\u786e\u5173\u6ce8\u5e76\u5206\u6790\u8fd9\u4e9b\u6982\u5ff5\uff0c\u5b83\u4eec\u4ecd\u7136\u4f1a\u5931\u8bef\uff0c\u8fd9\u4e0d\u4ec5\u8868\u660e\u5b83\u4eec\u7f3a\u4e4f\u5bf9\u8fd9\u4e9b\u57fa\u672c\u89c6\u89c9\u6982\u5ff5\u7684\u7406\u89e3\uff0c\u8fd8\u8868\u660e\u5b83\u4eec\u65e0\u6cd5\u63a8\u5e7f\u5230\u770b\u4e0d\u89c1\u7684\u6982\u5ff5\u3002\u8fd9\u4e9b\u89c2\u5bdf\u7ed3\u679c\u5f3a\u8c03\u4e86 VLM \u5f53\u524d\u7684\u5c40\u9650\u6027\uff0c\u5f3a\u8c03\u4eba\u7c7b\u822c\u7684\u89c6\u89c9\u63a8\u7406\u548c\u673a\u5668\u8ba4\u77e5\u4e4b\u95f4\u4ecd\u7136\u5b58\u5728\u5de8\u5927\u5dee\u8ddd\uff0c\u5e76\u7a81\u51fa\u4e86\u5728\u8fd9\u4e2a\u9886\u57df\u6301\u7eed\u521b\u65b0\u7684\u5fc5\u8981\u6027\u3002", "author": "Antonia W\u00fcst et.al.", "authors": "Antonia W\u00fcst, Tim Tobiasch, Lukas Helff, Devendra S. Dhami, Constantin A. Rothkopf, Kristian Kersting", "id": "2410.19546v1", "paper_url": "http://arxiv.org/abs/2410.19546v1", "repo": "https://github.com/ml-research/bongard-in-wonderland"}}