{"2408.04203": {"publish_time": "2024-08-08", "title": "MMRole: A Comprehensive Framework for Developing and Evaluating Multimodal Role-Playing Agents", "paper_summary": "Recently, Role-Playing Agents (RPAs) have garnered increasing attention for\ntheir potential to deliver emotional value and facilitate sociological\nresearch. However, existing studies are primarily confined to the textual\nmodality, unable to simulate humans' multimodal perceptual capabilities. To\nbridge this gap, we introduce the concept of Multimodal Role-Playing Agents\n(MRPAs), and propose a comprehensive framework, MMRole, for their development\nand evaluation, which comprises a personalized multimodal dataset and a robust\nevaluation method. Specifically, we construct a large-scale, high-quality\ndataset, MMRole-Data, consisting of 85 characters, 11K images, and 14K single\nor multi-turn dialogues. Additionally, we present a robust evaluation method,\nMMRole-Eval, encompassing eight metrics across three dimensions, where a reward\nmodel is trained to score MRPAs with the constructed ground-truth data for\ncomparison. Moreover, we develop the first specialized MRPA, MMRole-Agent.\nExtensive evaluation results demonstrate the improved performance of\nMMRole-Agent and highlight the primary challenges in developing MRPAs,\nemphasizing the need for enhanced multimodal understanding and role-playing\nconsistency. The data, code, and models will be available at\nhttps://github.com/YanqiDai/MMRole.", "paper_summary_zh": "<paragraph>\u6700\u8fd1\uff0c\u89d2\u8272\u626e\u6f14\u4ee3\u7406\uff08RPA\uff09\u56e0\u5176\u63d0\u4f9b\u60c5\u611f\u4ef7\u503c\u548c\u4fc3\u8fdb\u793e\u4f1a\u5b66\u7814\u7a76\u7684\u6f5c\u529b\u800c\u5907\u53d7\u5173\u6ce8\u3002\u7136\u800c\uff0c\u73b0\u6709\u7814\u7a76\u4e3b\u8981\u5c40\u9650\u4e8e\u6587\u672c\u6a21\u5f0f\uff0c\u65e0\u6cd5\u6a21\u62df\u4eba\u7c7b\u7684\u591a\u6a21\u6001\u611f\u77e5\u80fd\u529b\u3002\u4e3a\u4e86\u5f25\u5408\u7406\u8bba\u5dee\u8ddd\uff0c\u6211\u4eec\u5f15\u5165\u4e86\u591a\u6a21\u6001\u89d2\u8272\u626e\u6f14\u4ee3\u7406\uff08MRPA\uff09\u7684\u6982\u5ff5\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u4e2a\u7528\u4e8e\u5f00\u53d1\u548c\u8bc4\u4f30\u7684\u7efc\u5408\u6846\u67b6 MMRole\uff0c\u5176\u4e2d\u5305\u62ec\u4e2a\u6027\u5316\u591a\u6a21\u6001\u6570\u636e\u96c6\u548c\u5065\u58ee\u7684\u8bc4\u4f30\u65b9\u6cd5\u3002\u5177\u4f53\u6765\u8bf4\uff0c\u6211\u4eec\u6784\u5efa\u4e86\u4e00\u4e2a\u5927\u89c4\u6a21\u3001\u9ad8\u8d28\u91cf\u7684\u6570\u636e\u96c6 MMRole-Data\uff0c\u5176\u4e2d\u5305\u62ec 85 \u4e2a\u89d2\u8272\u300111K \u5f20\u56fe\u50cf\u548c 14K \u4e2a\u5355\u8f6e\u6216\u591a\u8f6e\u5bf9\u8bdd\u3002\u6b64\u5916\uff0c\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u4e2a\u5065\u58ee\u7684\u8bc4\u4f30\u65b9\u6cd5 MMRole-Eval\uff0c\u5b83\u5305\u542b\u4e09\u4e2a\u7ef4\u5ea6\u4e0a\u7684\u516b\u4e2a\u6307\u6807\uff0c\u5176\u4e2d\u8bad\u7ec3\u4e86\u4e00\u4e2a\u5956\u52b1\u6a21\u578b\uff0c\u4f7f\u7528\u6784\u5efa\u597d\u7684\u57fa\u672c\u4e8b\u5b9e\u6570\u636e\u5bf9 MRPA \u8fdb\u884c\u8bc4\u5206\u4ee5\u8fdb\u884c\u6bd4\u8f83\u3002\u6b64\u5916\uff0c\u6211\u4eec\u5f00\u53d1\u4e86\u7b2c\u4e00\u4e2a\u4e13\u95e8\u7684 MRPA\uff0c\u5373 MMRole-Agent\u3002\u5e7f\u6cdb\u7684\u8bc4\u4f30\u7ed3\u679c\u8bc1\u660e\u4e86 MMRole-Agent \u7684\u6027\u80fd\u5f97\u5230\u6539\u5584\uff0c\u5e76\u7a81\u51fa\u4e86\u5f00\u53d1 MRPA \u7684\u4e3b\u8981\u6311\u6218\uff0c\u5f3a\u8c03\u4e86\u5bf9\u589e\u5f3a\u7684\u591a\u6a21\u6001\u7406\u89e3\u548c\u89d2\u8272\u626e\u6f14\u4e00\u81f4\u6027\u7684\u9700\u6c42\u3002\u6570\u636e\u3001\u4ee3\u7801\u548c\u6a21\u578b\u5c06\u5728 https://github.com/YanqiDai/MMRole \u4e0a\u63d0\u4f9b\u3002</paragraph>", "author": "Yanqi Dai et.al.", "authors": "Yanqi Dai, Huanran Hu, Lei Wang, Shengjie Jin, Xu Chen, Zhiwu Lu", "id": "2408.04203v1", "paper_url": "http://arxiv.org/abs/2408.04203v1", "repo": "https://github.com/yanqidai/mmrole"}}