{"2501.14679": {"publish_time": "2025-01-24", "title": "Surface Vision Mamba: Leveraging Bidirectional State Space Model for Efficient Spherical Manifold Representation", "paper_summary": "Attention-based methods have demonstrated exceptional performance in\nmodelling long-range dependencies on spherical cortical surfaces, surpassing\ntraditional Geometric Deep Learning (GDL) models. However, their extensive\ninference time and high memory demands pose challenges for application to large\ndatasets with limited computing resources. Inspired by the state space model in\ncomputer vision, we introduce the attention-free Vision Mamba (Vim) to\nspherical surfaces, presenting a domain-agnostic architecture for analyzing\ndata on spherical manifolds. Our method achieves surface patching by\nrepresenting spherical data as a sequence of triangular patches derived from a\nsubdivided icosphere. The proposed Surface Vision Mamba (SiM) is evaluated on\nmultiple neurodevelopmental phenotype regression tasks using cortical surface\nmetrics from neonatal brains. Experimental results demonstrate that SiM\noutperforms both attention- and GDL-based methods, delivering 4.8 times faster\ninference and achieving 91.7% lower memory consumption compared to the Surface\nVision Transformer (SiT) under the Ico-4 grid partitioning. Sensitivity\nanalysis further underscores the potential of SiM to identify subtle cognitive\ndevelopmental patterns. The code is available at\nhttps://github.com/Rongzhao-He/surface-vision-mamba.", "paper_summary_zh": "<paragraph>\u57fa\u65bc\u6ce8\u610f\u529b\u7684\u65b9\u6cd5\u5df2\u8b49\u660e\u5728\u7403\u5f62\u76ae\u8cea\u8868\u9762\u4e0a\u5efa\u6a21\u9577\u7a0b\u4f9d\u8cf4\u6027\u65b9\u9762\u8868\u73fe\u51fa\u8272\uff0c\u8d85\u8d8a\u4e86\u50b3\u7d71\u7684\u5e7e\u4f55\u6df1\u5ea6\u5b78\u7fd2 (GDL) \u6a21\u578b\u3002\u7136\u800c\uff0c\u5b83\u5011\u5ee3\u6cdb\u7684\u63a8\u8ad6\u6642\u9593\u548c\u9ad8\u8a18\u61b6\u9ad4\u9700\u6c42\u5c0d\u61c9\u7528\u65bc\u5177\u6709\u6709\u9650\u904b\u7b97\u8cc7\u6e90\u7684\u5927\u578b\u8cc7\u6599\u96c6\u69cb\u6210\u6311\u6230\u3002\u53d7\u96fb\u8166\u8996\u89ba\u4e2d\u7684\u72c0\u614b\u7a7a\u9593\u6a21\u578b\u555f\u767c\uff0c\u6211\u5011\u5c07\u7121\u6ce8\u610f\u529b\u7684 Vision Mamba (Vim) \u5f15\u5165\u7403\u5f62\u8868\u9762\uff0c\u63d0\u51fa\u4e86\u4e00\u500b\u8207\u9818\u57df\u7121\u95dc\u7684\u67b6\u69cb\uff0c\u7528\u65bc\u5206\u6790\u7403\u5f62\u6d41\u5f62\u4e0a\u7684\u8cc7\u6599\u3002\u6211\u5011\u7684\u900f\u904e\u5c07\u7403\u5f62\u8cc7\u6599\u8868\u793a\u70ba\u5f9e\u7d30\u5206\u7b49\u89d2\u7403\u9ad4\u884d\u751f\u7684\u4e09\u89d2\u5f62\u88dc\u4e01\u5e8f\u5217\uff0c\u4f86\u5be6\u73fe\u8868\u9762\u8cbc\u7247\u3002\u6240\u63d0\u51fa\u7684 Surface Vision Mamba (SiM) \u4f7f\u7528\u4f86\u81ea\u65b0\u751f\u5152\u5927\u8166\u7684\u76ae\u8cea\u8868\u9762\u6307\u6a19\uff0c\u5728\u591a\u500b\u795e\u7d93\u767c\u80b2\u8868\u578b\u56de\u6b78\u4efb\u52d9\u4e0a\u9032\u884c\u8a55\u4f30\u3002\u5be6\u9a57\u7d50\u679c\u8868\u660e\uff0c\u8207\u57fa\u65bc\u6ce8\u610f\u529b\u548c GDL \u7684\u65b9\u6cd5\u76f8\u6bd4\uff0cSiM \u8868\u73fe\u51fa\u8272\uff0c\u5728 Ico-4 \u7db2\u683c\u5206\u5272\u4e0b\u63d0\u4f9b\u5feb 4.8 \u500d\u7684\u63a8\u8ad6\u901f\u5ea6\uff0c\u4e26\u5be6\u73fe\u4f4e 91.7% \u7684\u8a18\u61b6\u9ad4\u6d88\u8017\uff0c\u4f4e\u65bc Surface Vision Transformer (SiT)\u3002\u654f\u611f\u6027\u5206\u6790\u9032\u4e00\u6b65\u5f37\u8abf\u4e86 SiM \u8b58\u5225\u5fae\u5999\u8a8d\u77e5\u767c\u80b2\u6a21\u5f0f\u7684\u6f5b\u529b\u3002\u7a0b\u5f0f\u78bc\u53ef\u5728 https://github.com/Rongzhao-He/surface-vision-mamba \u53d6\u5f97\u3002</paragraph>", "author": "Rongzhao He et.al.", "authors": "Rongzhao He, Weihao Zheng", "id": "2501.14679v1", "paper_url": "http://arxiv.org/abs/2501.14679v1", "repo": "null"}}