
### LLM
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2025-01-02**|**Unifying Specialized Visual Encoders for Video Language Models**|Jihoon Chung et.al.|[2501.01426v1](http://arxiv.org/abs/2501.01426v1)|null|
|**2025-01-02**|**Object-level Visual Prompts for Compositional Image Generation**|Gaurav Parmar et.al.|[2501.01424v1](http://arxiv.org/abs/2501.01424v1)|null|
|**2025-01-02**|**Multi-Modal Video Feature Extraction for Popularity Prediction**|Haixu Liu et.al.|[2501.01422v1](http://arxiv.org/abs/2501.01422v1)|null|
|**2025-01-02**|**On Unifying Video Generation and Camera Pose Estimation**|Chun-Hao Paul Huang et.al.|[2501.01409v1](http://arxiv.org/abs/2501.01409v1)|null|
|**2025-01-02**|**A Unified Hyperparameter Optimization Pipeline for Transformer-Based Time Series Forecasting Models**|Jingjing Xu et.al.|[2501.01394v1](http://arxiv.org/abs/2501.01394v1)|null|
|**2025-01-02**|**OmniChat: Enhancing Spoken Dialogue Systems with Scalable Synthetic Data for Diverse Scenarios**|Xize Cheng et.al.|[2501.01384v1](http://arxiv.org/abs/2501.01384v1)|null|
|**2025-01-02**|**Training Medical Large Vision-Language Models with Abnormal-Aware Feedback**|Yucheng Zhou et.al.|[2501.01377v1](http://arxiv.org/abs/2501.01377v1)|null|
|**2025-01-02**|**ScarNet: A Novel Foundation Model for Automated Myocardial Scar Quantification from LGE in Cardiac MRI**|Neda Tavakoli et.al.|[2501.01372v1](http://arxiv.org/abs/2501.01372v1)|null|
|**2025-01-02**|**ViGiL3D: A Linguistically Diverse Dataset for 3D Visual Grounding**|Austin T. Wang et.al.|[2501.01366v1](http://arxiv.org/abs/2501.01366v1)|null|
|**2025-01-02**|**Rethinking Relation Extraction: Beyond Shortcuts to Generalization with a Debiased Benchmark**|Liang He et.al.|[2501.01349v1](http://arxiv.org/abs/2501.01349v1)|null|
|**2025-01-02**|**AdaptVC: High Quality Voice Conversion with Adaptive Learning**|Jaehun Kim et.al.|[2501.01347v1](http://arxiv.org/abs/2501.01347v1)|null|
|**2025-01-02**|**Large Vision-Language Model Alignment and Misalignment: A Survey Through the Lens of Explainability**|Dong Shu et.al.|[2501.01346v1](http://arxiv.org/abs/2501.01346v1)|null|
|**2025-01-02**|**DeepFilter: An Instrumental Baseline for Accurate and Efficient Process Monitoring**|Hao Wang et.al.|[2501.01342v1](http://arxiv.org/abs/2501.01342v1)|null|
|**2025-01-02**|**Aligning Large Language Models for Faithful Integrity Against Opposing Argument**|Yong Zhao et.al.|[2501.01336v1](http://arxiv.org/abs/2501.01336v1)|null|
|**2025-01-02**|**CySecBench: Generative AI-based CyberSecurity-focused Prompt Dataset for Benchmarking Large Language Models**|Johan Wahréus et.al.|[2501.01335v1](http://arxiv.org/abs/2501.01335v1)|null|
|**2025-01-02**|**Decoding Knowledge in Large Language Models: A Framework for Categorization and Comprehension**|Yanbo Fang et.al.|[2501.01332v1](http://arxiv.org/abs/2501.01332v1)|null|
|**2025-01-02**|**The Prompt Alchemist: Automated LLM-Tailored Prompt Optimization for Test Case Generation**|Shuzheng Gao et.al.|[2501.01329v1](http://arxiv.org/abs/2501.01329v1)|null|
|**2025-01-02**|**Understanding Difficult-to-learn Examples in Contrastive Learning: A Theoretical Framework for Spectral Contrastive Learning**|Yi-Ge Zhang et.al.|[2501.01317v1](http://arxiv.org/abs/2501.01317v1)|null|
|**2025-01-02**|**Multi-Head Explainer: A General Framework to Improve Explainability in CNNs and Transformers**|Bohang Sun et.al.|[2501.01311v1](http://arxiv.org/abs/2501.01311v1)|null|
|**2025-01-02**|**Think More, Hallucinate Less: Mitigating Hallucinations via Dual Process of Fast and Slow Thinking**|Xiaoxue Cheng et.al.|[2501.01306v1](http://arxiv.org/abs/2501.01306v1)|null|
|**2025-01-02**|**Large Language Models for Mental Health Diagnostic Assessments: Exploring The Potential of Large Language Models for Assisting with Mental Health Diagnostic Assessments -- The Depression and Anxiety Case**|Kaushik Roy et.al.|[2501.01305v1](http://arxiv.org/abs/2501.01305v1)|null|
|**2025-01-02**|**LEO-Split: A Semi-Supervised Split Learning Framework over LEO Satellite Networks**|Zheng Lin et.al.|[2501.01293v1](http://arxiv.org/abs/2501.01293v1)|null|
|**2025-01-02**|**Change Detection-Based Procedures for Piecewise Stationary MABs: A Modular Approach**|Yu-Han Huang et.al.|[2501.01291v1](http://arxiv.org/abs/2501.01291v1)|null|
|**2025-01-02**|**ToolComp: A Multi-Tool Reasoning & Process Supervision Benchmark**|Vaskar Nath et.al.|[2501.01290v1](http://arxiv.org/abs/2501.01290v1)|null|
|**2025-01-02**|**NeutraSum: A Language Model can help a Balanced Media Diet by Neutralizing News Summaries**|Xi Luo et.al.|[2501.01284v1](http://arxiv.org/abs/2501.01284v1)|null|
|**2025-01-02**|**CultureVLM: Characterizing and Improving Cultural Understanding of Vision-Language Models for over 100 Countries**|Shudong Liu et.al.|[2501.01282v1](http://arxiv.org/abs/2501.01282v1)|null|
|**2025-01-02**|**Does a Large Language Model Really Speak in Human-Like Language?**|Mose Park et.al.|[2501.01273v1](http://arxiv.org/abs/2501.01273v1)|null|
|**2025-01-02**|**ProgCo: Program Helps Self-Correction of Large Language Models**|Xiaoshuai Song et.al.|[2501.01264v1](http://arxiv.org/abs/2501.01264v1)|null|
|**2025-01-02**|**Stealthy Backdoor Attack to Real-world Models in Android Apps**|Jiali Wei et.al.|[2501.01263v1](http://arxiv.org/abs/2501.01263v1)|null|
|**2025-01-02**|**CodeElo: Benchmarking Competition-level Code Generation of LLMs with Human-comparable Elo Ratings**|Shanghaoran Quan et.al.|[2501.01257v1](http://arxiv.org/abs/2501.01257v1)|null|
|**2025-01-02**|**Digital Guardians: Can GPT-4, Perspective API, and Moderation API reliably detect hate speech in reader comments of German online newspapers?**|Manuel Weber et.al.|[2501.01256v1](http://arxiv.org/abs/2501.01256v1)|null|
|**2025-01-02**|**Large Language Model-Enhanced Symbolic Reasoning for Knowledge Base Completion**|Qiyuan He et.al.|[2501.01246v1](http://arxiv.org/abs/2501.01246v1)|null|
|**2025-01-02**|**Face-Human-Bench: A Comprehensive Benchmark of Face and Human Understanding for Multi-modal Assistants**|Lixiong Qin et.al.|[2501.01243v1](http://arxiv.org/abs/2501.01243v1)|null|
|**2025-01-02**|**An Efficient Attention Mechanism for Sequential Recommendation Tasks: HydraRec**|Uzma Mushtaque et.al.|[2501.01242v1](http://arxiv.org/abs/2501.01242v1)|null|
|**2025-01-02**|**Automated Self-Refinement and Self-Correction for LLM-based Product Attribute Value Extraction**|Alexander Brinkmann et.al.|[2501.01237v1](http://arxiv.org/abs/2501.01237v1)|null|
|**2025-01-02**|**A redescription mining framework for post-hoc explaining and relating deep learning models**|Matej Mihelčić et.al.|[2501.01209v1](http://arxiv.org/abs/2501.01209v1)|null|
|**2025-01-02**|**Harnessing Multi-Agent LLMs for Complex Engineering Problem-Solving: A Framework for Senior Design Projects**|Abdullah Mushtaq et.al.|[2501.01205v1](http://arxiv.org/abs/2501.01205v1)|null|
|**2025-01-02**|**Data Augmentation Techniques for Chinese Disease Name Normalization**|Wenqian Cui et.al.|[2501.01195v1](http://arxiv.org/abs/2501.01195v1)|null|
|**2025-01-02**|**Blind Men and the Elephant: Diverse Perspectives on Gender Stereotypes in Benchmark Datasets**|Mahdi Zakizadeh et.al.|[2501.01168v1](http://arxiv.org/abs/2501.01168v1)|null|
|**2025-01-02**|**Leveraging Full Dependency Parsing Graph Information For Biomedical Event Extraction**|Farshad Noravesh et.al.|[2501.01158v1](http://arxiv.org/abs/2501.01158v1)|null|
|**2025-01-02**|**TexAVi: Generating Stereoscopic VR Video Clips from Text Descriptions**|Vriksha Srihari et.al.|[2501.01156v1](http://arxiv.org/abs/2501.01156v1)|null|
|**2025-01-02**|**A3: Android Agent Arena for Mobile GUI Agents**|Yuxiang Chai et.al.|[2501.01149v1](http://arxiv.org/abs/2501.01149v1)|null|
|**2025-01-02**|**BlockDialect: Block-wise Fine-grained Mixed Format for Energy-Efficient LLM Inference**|Wonsuk Jang et.al.|[2501.01144v1](http://arxiv.org/abs/2501.01144v1)|null|
|**2025-01-02**|**Missing Data as Augmentation in the Earth Observation Domain: A Multi-View Learning Approach**|Francisco Mena et.al.|[2501.01132v1](http://arxiv.org/abs/2501.01132v1)|null|
|**2025-01-02**|**TED: Turn Emphasis with Dialogue Feature Attention for Emotion Recognition in Conversation**|Junya Ono et.al.|[2501.01123v1](http://arxiv.org/abs/2501.01123v1)|null|
|**2025-01-02**|**Pruning-based Data Selection and Network Fusion for Efficient Deep Learning**|Humaira Kousar et.al.|[2501.01118v1](http://arxiv.org/abs/2501.01118v1)|null|
|**2025-01-02**|**Robust COVID-19 Detection from Cough Sounds using Deep Neural Decision Tree and Forest: A Comprehensive Cross-Datasets Evaluation**|Rofiqul Islam et.al.|[2501.01117v1](http://arxiv.org/abs/2501.01117v1)|null|
|**2025-01-02**|**MalCL: Leveraging GAN-Based Generative Replay to Combat Catastrophic Forgetting in Malware Classification**|Jimin Park et.al.|[2501.01110v1](http://arxiv.org/abs/2501.01110v1)|null|
|**2025-01-02**|**BatStyler: Advancing Multi-category Style Generation for Source-free Domain Generalization**|Xiusheng Xu et.al.|[2501.01109v1](http://arxiv.org/abs/2501.01109v1)|null|
|**2025-01-02**|**MuQ: Self-Supervised Music Representation Learning with Mel Residual Vector Quantization**|Haina Zhu et.al.|[2501.01108v1](http://arxiv.org/abs/2501.01108v1)|null|
|**2025-01-02**|**Disambiguation of Chinese Polyphones in an End-to-End Framework with Semantic Features Extracted by Pre-trained BERT**|Dongyang Dai et.al.|[2501.01102v1](http://arxiv.org/abs/2501.01102v1)|null|
|**2025-01-02**|**Graph Generative Pre-trained Transformer**|Xiaohui Chen et.al.|[2501.01073v1](http://arxiv.org/abs/2501.01073v1)|null|
|**2025-01-02**|**BeliN: A Novel Corpus for Bengali Religious News Headline Generation using Contextual Feature Fusion**|Md Osama et.al.|[2501.01069v1](http://arxiv.org/abs/2501.01069v1)|null|
|**2025-01-02**|**Dynamic Attention-Guided Context Decoding for Mitigating Context Faithfulness Hallucinations in Large Language Models**|Yanwen Huang et.al.|[2501.01059v1](http://arxiv.org/abs/2501.01059v1)|null|
|**2025-01-02**|**Risks of Cultural Erasure in Large Language Models**|Rida Qadri et.al.|[2501.01056v1](http://arxiv.org/abs/2501.01056v1)|null|
|**2025-01-02**|**Dynamic Scaling of Unit Tests for Code Reward Modeling**|Zeyao Ma et.al.|[2501.01054v1](http://arxiv.org/abs/2501.01054v1)|null|
|**2025-01-02**|**FED: Fast and Efficient Dataset Deduplication Framework with GPU Acceleration**|Youngjun Son et.al.|[2501.01046v1](http://arxiv.org/abs/2501.01046v1)|null|
|**2025-01-02**|**MSWA: Refining Local Attention with Multi-ScaleWindow Attention**|Yixing Xu et.al.|[2501.01039v1](http://arxiv.org/abs/2501.01039v1)|null|
|**2025-01-02**|**MSC-Bench: Benchmarking and Analyzing Multi-Sensor Corruption for Driving Perception**|Xiaoshuai Hao et.al.|[2501.01037v1](http://arxiv.org/abs/2501.01037v1)|null|
|**2025-01-02**|**Advancing Singlish Understanding: Bridging the Gap with Datasets and Multimodal Models**|Bin Wang et.al.|[2501.01034v1](http://arxiv.org/abs/2501.01034v1)|null|
|**2025-01-02**|**ValuesRAG: Enhancing Cultural Alignment Through Retrieval-Augmented Contextual Learning**|Wonduk Seo et.al.|[2501.01031v1](http://arxiv.org/abs/2501.01031v1)|null|
|**2025-01-02**|**KaLM-Embedding: Superior Training Data Brings A Stronger Embedding Model**|Xinshuo Hu et.al.|[2501.01028v1](http://arxiv.org/abs/2501.01028v1)|[link](https://github.com/HITsz-TMG/KaLM-Embedding)|
|**2025-01-02**|**Towards Adversarially Robust Deep Metric Learning**|Xiaopeng Ke et.al.|[2501.01025v1](http://arxiv.org/abs/2501.01025v1)|null|
|**2025-01-02**|**MDSF: Context-Aware Multi-Dimensional Data Storytelling Framework based on Large language Model**|Chengze Zhang et.al.|[2501.01014v1](http://arxiv.org/abs/2501.01014v1)|null|
|**2025-01-02**|**CryptoMamba: Leveraging State Space Models for Accurate Bitcoin Price Prediction**|Mohammad Shahab Sepehri et.al.|[2501.01010v1](http://arxiv.org/abs/2501.01010v1)|null|
|**2025-01-02**|**Deep Reinforcement Learning for Job Scheduling and Resource Management in Cloud Computing: An Algorithm-Level Review**|Yan Gu et.al.|[2501.01007v1](http://arxiv.org/abs/2501.01007v1)|null|
|**2025-01-02**|**FlashInfer: Efficient and Customizable Attention Engine for LLM Inference Serving**|Zihao Ye et.al.|[2501.01005v1](http://arxiv.org/abs/2501.01005v1)|[link](https://github.com/flashinfer-ai/flashinfer)|
|**2025-01-02**|**Exploring Information Processing in Large Language Models: Insights from Information Bottleneck Theory**|Zhou Yang et.al.|[2501.00999v1](http://arxiv.org/abs/2501.00999v1)|null|
|**2025-01-02**|**Are LLMs effective psychological assessors? Leveraging adaptive RAG for interpretable mental health screening through psychometric practice**|Federico Ravenda et.al.|[2501.00982v1](http://arxiv.org/abs/2501.00982v1)|null|
|**2025-01-01**|**The Silent Majority: Demystifying Memorization Effect in the Presence of Spurious Correlations**|Chenyu You et.al.|[2501.00961v1](http://arxiv.org/abs/2501.00961v1)|null|
|**2025-01-01**|**2.5 Years in Class: A Multimodal Textbook for Vision-Language Pretraining**|Wenqi Zhang et.al.|[2501.00958v1](http://arxiv.org/abs/2501.00958v1)|null|
|**2025-01-01**|**Enhancing Early Diabetic Retinopathy Detection through Synthetic DR1 Image Generation: A StyleGAN3 Approach**|Sagarnil Das et.al.|[2501.00954v1](http://arxiv.org/abs/2501.00954v1)|null|
|**2025-01-01**|**Incremental Dialogue Management: Survey, Discussion, and Implications for HRI**|Casey Kennington et.al.|[2501.00953v1](http://arxiv.org/abs/2501.00953v1)|null|
|**2025-01-01**|**AutoPresent: Designing Structured Visuals from Scratch**|Jiaxin Ge et.al.|[2501.00912v1](http://arxiv.org/abs/2501.00912v1)|null|
|**2025-01-01**|**Population Aware Diffusion for Time Series Generation**|Yang Li et.al.|[2501.00910v1](http://arxiv.org/abs/2501.00910v1)|[link](https://github.com/wmd3i/PaD-TS)|
|**2025-01-01**|**U-GIFT: Uncertainty-Guided Firewall for Toxic Speech in Few-Shot Scenario**|Jiaxin Song et.al.|[2501.00907v1](http://arxiv.org/abs/2501.00907v1)|null|
|**2025-01-01**|**Large Language Model Based Multi-Agent System Augmented Complex Event Processing Pipeline for Internet of Multimedia Things**|Talha Zeeshan et.al.|[2501.00906v1](http://arxiv.org/abs/2501.00906v1)|null|
|**2025-01-01**|**Unfolding the Headline: Iterative Self-Questioning for News Retrieval and Timeline Summarization**|Weiqi Wu et.al.|[2501.00888v1](http://arxiv.org/abs/2501.00888v1)|null|
|**2025-01-01**|**Representation in large language models**|Cameron C. Yetman et.al.|[2501.00885v1](http://arxiv.org/abs/2501.00885v1)|null|
|**2025-01-01**|**TrustRAG: Enhancing Robustness and Trustworthiness in RAG**|Huichi Zhou et.al.|[2501.00879v1](http://arxiv.org/abs/2501.00879v1)|[link](https://github.com/huichizhou/trustrag)|
|**2025-01-01**|**LUSIFER: Language Universal Space Integration for Enhanced Multilingual Embeddings with Large Language Models**|Hieu Man et.al.|[2501.00874v1](http://arxiv.org/abs/2501.00874v1)|null|
|**2025-01-01**|**Large Language Models Are Read/Write Policy-Makers for Simultaneous Generation**|Shoutao Guo et.al.|[2501.00868v1](http://arxiv.org/abs/2501.00868v1)|null|
|**2025-01-01**|**Negative to Positive Co-learning with Aggressive Modality Dropout**|Nicholas Magal et.al.|[2501.00865v1](http://arxiv.org/abs/2501.00865v1)|null|
|**2025-01-01**|**DiffETM: Diffusion Process Enhanced Embedded Topic Model**|Wei Shao et.al.|[2501.00862v1](http://arxiv.org/abs/2501.00862v1)|null|
|**2025-01-01**|**LLM+AL: Bridging Large Language Models and Action Languages for Complex Reasoning about Actions**|Adam Ishay et.al.|[2501.00830v1](http://arxiv.org/abs/2501.00830v1)|null|
|**2025-01-01**|**An LLM-Empowered Adaptive Evolutionary Algorithm For Multi-Component Deep Learning Systems**|Haoxiang Tian et.al.|[2501.00829v1](http://arxiv.org/abs/2501.00829v1)|null|
|**2025-01-01**|**Embedding Style Beyond Topics: Analyzing Dispersion Effects Across Different Language Models**|Benjamin Icard et.al.|[2501.00828v1](http://arxiv.org/abs/2501.00828v1)|null|
|**2025-01-01**|**LLM-Powered Multi-Agent System for Automated Crypto Portfolio Management**|Yichen Luo et.al.|[2501.00826v1](http://arxiv.org/abs/2501.00826v1)|null|
|**2025-01-01**|**SLIDE: Integrating Speech Language Model with LLM for Spontaneous Spoken Dialogue Generation**|Haitian Lu et.al.|[2501.00805v1](http://arxiv.org/abs/2501.00805v1)|null|
|**2025-01-01**|**Automatic Text Pronunciation Correlation Generation and Application for Contextual Biasing**|Gaofeng Cheng et.al.|[2501.00804v1](http://arxiv.org/abs/2501.00804v1)|null|
|**2025-01-01**|**Reasoning-Oriented and Analogy-Based Methods for Locating and Editing in Zero-Shot Event-Relational Reasoning**|Jingyao Tang et.al.|[2501.00803v1](http://arxiv.org/abs/2501.00803v1)|null|
|**2025-01-01**|**Make Shuffling Great Again: A Side-Channel Resistant Fisher-Yates Algorithm for Protecting Neural Networks**|Leonard Puškáč et.al.|[2501.00798v1](http://arxiv.org/abs/2501.00798v1)|null|
|**2025-01-01**|**LENS-XAI: Redefining Lightweight and Explainable Network Security through Knowledge Distillation and Variational Autoencoders for Scalable Intrusion Detection in Cybersecurity**|Muhammet Anil Yagiz et.al.|[2501.00790v1](http://arxiv.org/abs/2501.00790v1)|null|
|**2025-01-01**|**Navigating Nuance: In Quest for Political Truth**|Soumyadeep Sar et.al.|[2501.00782v1](http://arxiv.org/abs/2501.00782v1)|null|
|**2025-01-01**|**REM: A Scalable Reinforced Multi-Expert Framework for Multiplex Influence Maximization**|Huyen Nguyen et.al.|[2501.00779v1](http://arxiv.org/abs/2501.00779v1)|null|
|**2025-01-01**|**Decoding the Flow: CauseMotion for Emotional Causality Analysis in Long-form Conversations**|Yuxuan Zhang et.al.|[2501.00778v1](http://arxiv.org/abs/2501.00778v1)|null|
|**2025-01-01**|**FitCF: A Framework for Automatic Feature Importance-guided Counterfactual Example Generation**|Qianli Wang et.al.|[2501.00777v1](http://arxiv.org/abs/2501.00777v1)|null|
|**2025-01-01**|**Revisiting Graph Neural Networks on Graph-level Tasks: Comprehensive Experiments, Analysis, and Improvements**|Haoyang Li et.al.|[2501.00773v1](http://arxiv.org/abs/2501.00773v1)|null|
|**2025-01-01**|**An AI-powered Bayesian generative modeling approach for causal inference in observational studies**|Qiao Liu et.al.|[2501.00755v1](http://arxiv.org/abs/2501.00755v1)|null|
|**2025-01-01**|**Beyond Text: Implementing Multimodal Large Language Model-Powered Multi-Agent Systems Using a No-Code Platform**|Cheonsu Jeong et.al.|[2501.00750v1](http://arxiv.org/abs/2501.00750v1)|null|

#### Abstracts
##### **Unifying Specialized Visual Encoders for Video Language Models**
2501.01426v1 by Jihoon Chung, Tyler Zhu, Max Gonzalez Saez-Diez, Juan Carlos Niebles, Honglu Zhou, Olga Russakovsky

The recent advent of Large Language Models (LLMs) has ushered sophisticated
reasoning capabilities into the realm of video through Video Large Language
Models (VideoLLMs). However, VideoLLMs currently rely on a single vision
encoder for all of their visual processing, which limits the amount and type of
visual information that can be conveyed to the LLM. Our method, MERV,
Multi-Encoder Representation of Videos, instead leverages multiple frozen
visual encoders to create a unified representation of a video, providing the
VideoLLM with a comprehensive set of specialized visual knowledge.
Spatio-temporally aligning the features from each encoder allows us to tackle a
wider range of open-ended and multiple-choice video understanding questions and
outperform prior state-of-the-art works. MERV is up to 3.7% better in accuracy
than Video-LLaVA across the standard suite video understanding benchmarks,
while also having a better Video-ChatGPT score. We also improve upon SeViLA,
the previous best on zero-shot Perception Test accuracy, by 2.2%. MERV
introduces minimal extra parameters and trains faster than equivalent
single-encoder methods while parallelizing the visual processing. Finally, we
provide qualitative evidence that MERV successfully captures domain knowledge
from each of its encoders. Our results offer promising directions in utilizing
multiple vision encoders for comprehensive video understanding.

摘要：大型語言模型 (LLM) 近期問世，透過影片大型語言模型 (VideoLLM) 將精密的推理能力引進影片領域。然而，VideoLLM 目前依賴單一視覺編碼器處理所有視覺，這限制了傳達給 LLM 的視覺資訊量和類型。我們的 MERV 方法，影片的多編碼器表徵，改用多個凍結的視覺編碼器來建立影片的統一表徵，為 VideoLLM 提供一套全面的專業視覺知識。透過空間時間對齊每個編碼器的特徵，讓我們能夠處理更廣泛的開放式和多選項影片理解問題，並超越先前的最先進技術。在標準套件影片理解基準上，MERV 的準確度比 Video-LLaVA 高達 3.7%，同時也有更好的 Video-ChatGPT 分數。我們也改進了 SeViLA，在零次學習感知測試準確度上，比前一個最佳方法高出 2.2%。MERV 引入最小的額外參數，並比等效的單一編碼器方法訓練得更快，同時並行處理視覺。最後，我們提供定性的證據，證明 MERV 成功從每個編碼器擷取領域知識。我們的結果為利用多個視覺編碼器進行全面的影片理解提供了有前景的方向。

##### **Object-level Visual Prompts for Compositional Image Generation**
2501.01424v1 by Gaurav Parmar, Or Patashnik, Kuan-Chieh Wang, Daniil Ostashev, Srinivasa Narasimhan, Jun-Yan Zhu, Daniel Cohen-Or, Kfir Aberman

We introduce a method for composing object-level visual prompts within a
text-to-image diffusion model. Our approach addresses the task of generating
semantically coherent compositions across diverse scenes and styles, similar to
the versatility and expressiveness offered by text prompts. A key challenge in
this task is to preserve the identity of the objects depicted in the input
visual prompts, while also generating diverse compositions across different
images. To address this challenge, we introduce a new KV-mixed cross-attention
mechanism, in which keys and values are learned from distinct visual
representations. The keys are derived from an encoder with a small bottleneck
for layout control, whereas the values come from a larger bottleneck encoder
that captures fine-grained appearance details. By mixing keys and values from
these complementary sources, our model preserves the identity of the visual
prompts while supporting flexible variations in object arrangement, pose, and
composition. During inference, we further propose object-level compositional
guidance to improve the method's identity preservation and layout correctness.
Results show that our technique produces diverse scene compositions that
preserve the unique characteristics of each visual prompt, expanding the
creative potential of text-to-image generation.

摘要：我們提出了一種在文本到影像擴散模型中組成物件層級視覺提示的方法。我們的做法處理在不同的場景和風格中產生語意連貫的組合任務，類似於文字提示所提供的多樣性和表現力。此任務中的關鍵挑戰是保留輸入視覺提示中所描繪物件的身份，同時在不同的影像中產生多樣化的組合。為了應對此挑戰，我們引入了一種新的 KV 混合交叉注意機制，其中鍵和值從不同的視覺表示中學習。鍵源自具有小型瓶頸的編碼器，用於布局控制，而值則來自擷取細緻外觀細節的較大型瓶頸編碼器。透過混合來自這些互補來源的鍵和值，我們的模型保留了視覺提示的身份，同時支援物件排列、姿勢和組合的靈活變化。在推理期間，我們進一步提出物件層級的組合指導，以改善方法的身份保留和布局正確性。結果顯示我們的技術產生了多樣的場景組合，保留了每個視覺提示的獨特特徵，擴展了文字到影像生成的創意潛力。

##### **Multi-Modal Video Feature Extraction for Popularity Prediction**
2501.01422v1 by Haixu Liu, Wenning Wang, Haoxiang Zheng, Penghao Jiang, Qirui Wang, Ruiqing Yan, Qiuzhuang Sun

This work aims to predict the popularity of short videos using the videos
themselves and their related features. Popularity is measured by four key
engagement metrics: view count, like count, comment count, and share count.
This study employs video classification models with different architectures and
training methods as backbone networks to extract video modality features.
Meanwhile, the cleaned video captions are incorporated into a carefully
designed prompt framework, along with the video, as input for video-to-text
generation models, which generate detailed text-based video content
understanding. These texts are then encoded into vectors using a pre-trained
BERT model. Based on the six sets of vectors mentioned above, a neural network
is trained for each of the four prediction metrics. Moreover, the study
conducts data mining and feature engineering based on the video and tabular
data, constructing practical features such as the total frequency of hashtag
appearances, the total frequency of mention appearances, video duration, frame
count, frame rate, and total time online. Multiple machine learning models are
trained, and the most stable model, XGBoost, is selected. Finally, the
predictions from the neural network and XGBoost models are averaged to obtain
the final result.

摘要：本研究旨在利用影片本身及其相關功能來預測短影片的熱門程度。熱門程度由四個關鍵參與指標衡量：觀看次數、按讚次數、留言次數和分享次數。本研究採用具有不同架構和訓練方法的影片分類模型作為主幹網路，以萃取影片形式特徵。同時，將整理後的影片字幕與影片一起納入精心設計的提示架構中，作為影片到文字生成模型的輸入，以產生詳細的文字化影片內容理解。然後，使用預先訓練的 BERT 模型將這些文字編碼成向量。根據上述六組向量，針對四個預測指標中的每一個訓練一個神經網路。此外，本研究根據影片和表格資料進行資料探勘和特徵工程，建構實用的特徵，例如標籤出現的總頻率、提及出現的總頻率、影片長度、影格數、影格率和線上總時間。訓練多個機器學習模型，並選出最穩定的模型 XGBoost。最後，將神經網路和 XGBoost 模型的預測結果取平均值，以取得最終結果。

##### **On Unifying Video Generation and Camera Pose Estimation**
2501.01409v1 by Chun-Hao Paul Huang, Jae Shin Yoon, Hyeonho Jeong, Niloy Mitra, Duygu Ceylan

Inspired by the emergent 3D capabilities in image generators, we explore
whether video generators similarly exhibit 3D awareness. Using
structure-from-motion (SfM) as a benchmark for 3D tasks, we investigate if
intermediate features from OpenSora, a video generation model, can support
camera pose estimation. We first examine native 3D awareness in video
generation features by routing raw intermediate outputs to SfM-prediction
modules like DUSt3R. Then, we explore the impact of fine-tuning on camera pose
estimation to enhance 3D awareness. Results indicate that while video generator
features have limited inherent 3D awareness, task-specific supervision
significantly boosts their accuracy for camera pose estimation, resulting in
competitive performance. The proposed unified model, named JOG3R, produces
camera pose estimates with competitive quality without degrading video
generation quality.

摘要：受图像生成器中新兴的 3D 功能启发，我们探索视频生成器是否同样表现出 3D 感知。使用运动结构 (SfM) 作为 3D 任务的基准，我们研究视频生成模型 OpenSora 中的中间特征是否可以支持相机位姿估计。我们首先通过将原始中间输出路由到 SfM 预测模块（如 DUSt3R）来检查视频生成特征中的原生 3D 感知。然后，我们探索微调对相机位姿估计的影响，以增强 3D 感知。结果表明，虽然视频生成器特征具有有限的固有 3D 感知，但特定于任务的监督极大地提高了它们在相机位姿估计方面的准确性，从而产生了具有竞争力的性能。所提出的统一模型 JOG3R 产生了具有竞争质量的相机位姿估计，而不会降低视频生成质量。

##### **A Unified Hyperparameter Optimization Pipeline for Transformer-Based Time Series Forecasting Models**
2501.01394v1 by Jingjing Xu, Caesar Wu, Yuan-Fang Li, Grégoire Danoy, Pascal Bouvry

Transformer-based models for time series forecasting (TSF) have attracted
significant attention in recent years due to their effectiveness and
versatility. However, these models often require extensive hyperparameter
optimization (HPO) to achieve the best possible performance, and a unified
pipeline for HPO in transformer-based TSF remains lacking. In this paper, we
present one such pipeline and conduct extensive experiments on several
state-of-the-art (SOTA) transformer-based TSF models. These experiments are
conducted on standard benchmark datasets to evaluate and compare the
performance of different models, generating practical insights and examples.
Our pipeline is generalizable beyond transformer-based architectures and can be
applied to other SOTA models, such as Mamba and TimeMixer, as demonstrated in
our experiments. The goal of this work is to provide valuable guidance to both
industry practitioners and academic researchers in efficiently identifying
optimal hyperparameters suited to their specific domain applications. The code
and complete experimental results are available on GitHub.

摘要：基於Transformer的時序預測 (TSF) 模型近年來因其有效性和多功能性而備受關注。然而，這些模型通常需要廣泛的超參數最佳化 (HPO) 才能達到最佳效能，而基於Transformer的 TSF 中的統一 HPO 管線仍然不足。在本文中，我們提出了一個這樣的管線，並對幾個最先進 (SOTA) 的基於Transformer的 TSF 模型進行廣泛的實驗。這些實驗是在標準基準資料集上進行的，以評估和比較不同模型的效能，產生實用的見解和範例。我們的管線可以推廣到基於Transformer的架構之外，並可以應用於其他 SOTA 模型，例如 Mamba 和 TimeMixer，正如我們的實驗中所示。這項工作的目標是為產業從業者和學術研究人員提供有價值的指導，以有效找出適合其特定領域應用程式的最佳超參數。程式碼和完整的實驗結果可在 GitHub 上取得。

##### **OmniChat: Enhancing Spoken Dialogue Systems with Scalable Synthetic Data for Diverse Scenarios**
2501.01384v1 by Xize Cheng, Dongjie Fu, Xiaoda Yang, Minghui Fang, Ruofan Hu, Jingyu Lu, Bai Jionghao, Zehan Wang, Shengpeng Ji, Rongjie Huang, Linjun Li, Yu Chen, Tao Jin, Zhou Zhao

With the rapid development of large language models, researchers have created
increasingly advanced spoken dialogue systems that can naturally converse with
humans. However, these systems still struggle to handle the full complexity of
real-world conversations, including audio events, musical contexts, and
emotional expressions, mainly because current dialogue datasets are constrained
in both scale and scenario diversity. In this paper, we propose leveraging
synthetic data to enhance the dialogue models across diverse scenarios. We
introduce ShareChatX, the first comprehensive, large-scale dataset for spoken
dialogue that spans diverse scenarios. Based on this dataset, we introduce
OmniChat, a multi-turn dialogue system with a heterogeneous feature fusion
module, designed to optimize feature selection in different dialogue contexts.
In addition, we explored critical aspects of training dialogue systems using
synthetic data. Through comprehensive experimentation, we determined the ideal
balance between synthetic and real data, achieving state-of-the-art results on
the real-world dialogue dataset DailyTalk. We also highlight the crucial
importance of synthetic data in tackling diverse, complex dialogue scenarios,
especially those involving audio and music. For more details, please visit our
demo page at \url{https://sharechatx.github.io/}.

摘要：隨著大型語言模型的快速發展，研究人員已建立了越來越先進的口語對話系統，能自然地與人類對話。然而，這些系統仍然難以處理現實世界對話的全部複雜性，包括音訊事件、音樂背景和情緒表達，這主要是因為目前的對話資料集在規模和場景多樣性上受到限制。在本文中，我們建議利用合成資料來增強各種場景中的對話模型。我們介紹 ShareChatX，這是第一個針對口語對話的全面、大規模資料集，涵蓋各種場景。根據此資料集，我們引入了 OmniChat，這是一個具有異質特徵融合模組的多回合對話系統，旨在最佳化不同對話情境中的特徵選擇。此外，我們探討了使用合成資料訓練對話系統的重要面向。透過全面的實驗，我們確定了合成資料和真實資料之間的理想平衡，在現實世界對話資料集 DailyTalk 上取得了最先進的成果。我們也強調了合成資料在處理多樣化、複雜的對話場景（特別是涉及音訊和音樂的場景）方面至關重要。如需更多詳細資訊，請前往我們的示範頁面：\url{https://sharechatx.github.io/}。

##### **Training Medical Large Vision-Language Models with Abnormal-Aware Feedback**
2501.01377v1 by Yucheng Zhou, Lingran Song, Jianbing Shen

Existing Medical Large Vision-Language Models (Med-LVLMs), which encapsulate
extensive medical knowledge, demonstrate excellent capabilities in
understanding medical images and responding to human queries based on these
images. However, there remain challenges in visual localization in medical
images, which is crucial for abnormality detection and interpretation. To
address these issues, we propose a novel UMed-LVLM designed with Unveiling
Medical abnormalities. Specifically, we collect a Medical Abnormalities
Unveiling (MAU) dataset and propose a two-stage training method for UMed-LVLM
training. To collect MAU dataset, we propose a prompt method utilizing the
GPT-4V to generate diagnoses based on identified abnormal areas in medical
images. Moreover, the two-stage training method includes Abnormal-Aware
Instruction Tuning and Abnormal-Aware Rewarding, comprising Abnormal
Localization Rewarding and Vision Relevance Rewarding. Experimental results
demonstrate that our UMed-LVLM surpasses existing Med-LVLMs in identifying and
understanding medical abnormality. In addition, this work shows that enhancing
the abnormality detection capabilities of Med-LVLMs significantly improves
their understanding of medical images and generalization capability.

摘要：現有的醫療大型視覺語言模型 (Med-LVLMs) 封裝了廣泛的醫療知識，在理解醫療影像和根據這些影像回應人類查詢方面表現出色的能力。然而，在醫療影像中進行視覺定位仍存在挑戰，這對於異常偵測和解讀至關重要。為了解決這些問題，我們提出了一種新穎的 UMed-LVLM，其設計用於揭示醫療異常。具體來說，我們收集了一個醫療異常揭示 (MAU) 資料集，並為 UMed-LVLM 訓練提出了一個兩階段訓練方法。為了收集 MAU 資料集，我們提出了一種提示方法，利用 GPT-4V 根據醫療影像中識別出的異常區域生成診斷。此外，兩階段訓練方法包括異常感知指導調整和異常感知獎勵，包括異常定位獎勵和視覺相關性獎勵。實驗結果表明，我們的 UMed-LVLM 在識別和理解醫療異常方面優於現有的 Med-LVLMs。此外，這項工作表明，增強 Med-LVLMs 的異常偵測能力可以顯著提升它們對醫療影像的理解和泛化能力。

##### **ScarNet: A Novel Foundation Model for Automated Myocardial Scar Quantification from LGE in Cardiac MRI**
2501.01372v1 by Neda Tavakoli, Amir Ali Rahsepar, Brandon C. Benefield, Daming Shen, Santiago López-Tapia, Florian Schiffers, Jeffrey J. Goldberger, Christine M. Albert, Edwin Wu, Aggelos K. Katsaggelos, Daniel C. Lee, Daniel Kim

Background: Late Gadolinium Enhancement (LGE) imaging is the gold standard
for assessing myocardial fibrosis and scarring, with left ventricular (LV) LGE
extent predicting major adverse cardiac events (MACE). Despite its importance,
routine LGE-based LV scar quantification is hindered by labor-intensive manual
segmentation and inter-observer variability. Methods: We propose ScarNet, a
hybrid model combining a transformer-based encoder from the Medical Segment
Anything Model (MedSAM) with a convolution-based U-Net decoder, enhanced by
tailored attention blocks. ScarNet was trained on 552 ischemic cardiomyopathy
patients with expert segmentations of myocardial and scar boundaries and tested
on 184 separate patients. Results: ScarNet achieved robust scar segmentation in
184 test patients, yielding a median Dice score of 0.912 (IQR: 0.863--0.944),
significantly outperforming MedSAM (median Dice = 0.046, IQR: 0.043--0.047) and
nnU-Net (median Dice = 0.638, IQR: 0.604--0.661). ScarNet demonstrated lower
bias (-0.63%) and coefficient of variation (4.3%) compared to MedSAM (bias:
-13.31%, CoV: 130.3%) and nnU-Net (bias: -2.46%, CoV: 20.3%). In Monte Carlo
simulations with noise perturbations, ScarNet achieved significantly higher
scar Dice (0.892 \pm 0.053, CoV = 5.9%) than MedSAM (0.048 \pm 0.112, CoV =
233.3%) and nnU-Net (0.615 \pm 0.537, CoV = 28.7%). Conclusion: ScarNet
outperformed MedSAM and nnU-Net in accurately segmenting myocardial and scar
boundaries in LGE images. The model exhibited robust performance across diverse
image qualities and scar patterns.

摘要：<paragraph>背景：延迟钆增强（LGE）成像用于评估心肌纤维化和瘢痕的黄金标准，左心室 (LV) LGE 范围预测重大的心脏不良事件 (MACE)。尽管其重要性，但基于 LGE 的常规 LV 瘢痕量化受到劳动密集型手动分割和观察者间差异的阻碍。方法：我们提出 ScarNet，一种混合模型，它将来自医学分割任何模型 (MedSAM) 的基于 Transformer 的编码器与基于卷积的 U-Net 解码器相结合，并通过定制的注意力块进行增强。ScarNet 在 552 例缺血性心肌病患者上接受训练，这些患者的心肌和瘢痕边界由专家分割，并在 184 例单独患者上进行测试。结果：ScarNet 在 184 例测试患者中实现了稳健的瘢痕分割，产生 0.912 的中值 Dice 得分（IQR：0.863--0.944），明显优于 MedSAM（中值 Dice = 0.046，IQR：0.043--0.047）和 nnU-Net（中值 Dice = 0.638，IQR：0.604--0.661）。与 MedSAM（偏差：-13.31%，CoV：130.3%）和 nnU-Net（偏差：-2.46%，CoV：20.3%）相比，ScarNet 表现出较低的偏差（-0.63%）和变异系数（4.3%）。在带有噪声扰动的蒙特卡罗模拟中，ScarNet 实现了明显高于 MedSAM（0.048 ± 0.112，CoV = 233.3%）和 nnU-Net（0.615 ± 0.537，CoV = 28.7%）的瘢痕 Dice（0.892 ± 0.053，CoV = 5.9%）。结论：ScarNet 在准确分割 LGE 图像中的心肌和瘢痕边界方面优于 MedSAM 和 nnU-Net。该模型在不同的图像质量和瘢痕模式下表现出稳健的性能。</paragraph>

##### **ViGiL3D: A Linguistically Diverse Dataset for 3D Visual Grounding**
2501.01366v1 by Austin T. Wang, ZeMing Gong, Angel X. Chang

3D visual grounding (3DVG) involves localizing entities in a 3D scene
referred to by natural language text. Such models are useful for embodied AI
and scene retrieval applications, which involve searching for objects or
patterns using natural language descriptions. While recent works have focused
on LLM-based scaling of 3DVG datasets, these datasets do not capture the full
range of potential prompts which could be specified in the English language. To
ensure that we are scaling up and testing against a useful and representative
set of prompts, we propose a framework for linguistically analyzing 3DVG
prompts and introduce Visual Grounding with Diverse Language in 3D (ViGiL3D), a
diagnostic dataset for evaluating visual grounding methods against a diverse
set of language patterns. We evaluate existing open-vocabulary 3DVG methods to
demonstrate that these methods are not yet proficient in understanding and
identifying the targets of more challenging, out-of-distribution prompts,
toward real-world applications.

摘要：3D 視覺接地 (3DVG) 涉及將自然語言文字所指的實體定位在 3D 場景中。此類模型對於具身 AI 和場景擷取應用程式很有用，其中涉及使用自然語言描述來搜尋物件或模式。儘管最近的工作重點在於 3DVG 資料集的 LLM 擴充，但這些資料集並未擷取到可以用英語指定的潛在提示的完整範圍。為了確保我們正在擴充並針對一組有用且具代表性的提示進行測試，我們提出了一個用於語言分析 3DVG 提示的框架，並引入了 3D 中具有多樣化語言的視覺接地 (ViGiL3D)，這是一個用於針對多樣化的語言模式評估視覺接地方法的診斷資料集。我們評估現有的開放式詞彙 3DVG 方法，以證明這些方法在理解和識別更具挑戰性、超出分佈提示的目標方面還不夠熟練，朝向實際應用邁進。

##### **Rethinking Relation Extraction: Beyond Shortcuts to Generalization with a Debiased Benchmark**
2501.01349v1 by Liang He, Yougang Chu, Zhen Wu, Jianbing Zhang, Xinyu Dai, Jiajun Chen

Benchmarks are crucial for evaluating machine learning algorithm performance,
facilitating comparison and identifying superior solutions. However, biases
within datasets can lead models to learn shortcut patterns, resulting in
inaccurate assessments and hindering real-world applicability. This paper
addresses the issue of entity bias in relation extraction tasks, where models
tend to rely on entity mentions rather than context. We propose a debiased
relation extraction benchmark DREB that breaks the pseudo-correlation between
entity mentions and relation types through entity replacement. DREB utilizes
Bias Evaluator and PPL Evaluator to ensure low bias and high naturalness,
providing a reliable and accurate assessment of model generalization in entity
bias scenarios. To establish a new baseline on DREB, we introduce MixDebias, a
debiasing method combining data-level and model training-level techniques.
MixDebias effectively improves model performance on DREB while maintaining
performance on the original dataset. Extensive experiments demonstrate the
effectiveness and robustness of MixDebias compared to existing methods,
highlighting its potential for improving the generalization ability of relation
extraction models. We will release DREB and MixDebias publicly.

摘要：基準測試對於評估機器學習演算法效能至關重要，
有助於比較並找出優越的解決方案。然而，資料集中的偏差
會導致模型學習捷徑模式，造成評估不準確並阻礙實際應用。本文
探討實體偏差在關係抽取任務中的問題，其中模型傾向於依賴實體提及，而非內容。我們提出一個去偏關係抽取基準 DREB，透過實體替換打破實體提及與關係類型之間的偽相關性。DREB 利用偏差評估器和 PPL 評估器來確保低偏差和高自然度，提供對實體偏差場景中模型概括性的可靠且準確的評估。為了在 DREB 上建立新的基準，我們引入了 MixDebias，一種結合資料層級和模型訓練層級技術的去偏方法。MixDebias 有效地改善了模型在 DREB 上的效能，同時維持在原始資料集上的效能。廣泛的實驗證明了 MixDebias 與現有方法相比的有效性和穩健性，突顯了其在改善關係抽取模型概括能力方面的潛力。我們將公開發布 DREB 和 MixDebias。

##### **AdaptVC: High Quality Voice Conversion with Adaptive Learning**
2501.01347v1 by Jaehun Kim, Ji-Hoon Kim, Yeunju Choi, Tan Dat Nguyen, Seongkyu Mun, Joon Son Chung

The goal of voice conversion is to transform the speech of a source speaker
to sound like that of a reference speaker while preserving the original
content. A key challenge is to extract disentangled linguistic content from the
source and voice style from the reference. While existing approaches leverage
various methods to isolate the two, a generalization still requires further
attention, especially for robustness in zero-shot scenarios. In this paper, we
achieve successful disentanglement of content and speaker features by tuning
self-supervised speech features with adapters. The adapters are trained to
dynamically encode nuanced features from rich self-supervised features, and the
decoder fuses them to produce speech that accurately resembles the reference
with minimal loss of content. Moreover, we leverage a conditional flow matching
decoder with cross-attention speaker conditioning to further boost the
synthesis quality and efficiency. Subjective and objective evaluations in a
zero-shot scenario demonstrate that the proposed method outperforms existing
models in speech quality and similarity to the reference speech.

摘要：語音轉換的目標是將來源說話者的語音轉換成聽起來像參考說話者的聲音，同時保留原始內容。一個關鍵挑戰是從來源中提取出糾纏的語言內容，以及從參考中提取出聲音風格。雖然現有的方法利用各種方法來隔離這兩者，但概括化仍需要進一步關注，特別是在零次學習場景中的穩健性。在本文中，我們通過使用適配器調整自我監督的語音特徵，成功地解開了內容和說話者特徵的糾纏。適配器經過訓練，可以從豐富的自我監督特徵中動態編碼細微特徵，並且解碼器將它們融合起來，以產生準確類似於參考的語音，同時最小化內容損失。此外，我們利用條件流匹配解碼器和交叉注意力說話者條件來進一步提升合成品質和效率。在零次學習場景中的主觀和客觀評估表明，所提出的方法在語音品質和與參考語音的相似性方面優於現有的模型。

##### **Large Vision-Language Model Alignment and Misalignment: A Survey Through the Lens of Explainability**
2501.01346v1 by Dong Shu, Haiyan Zhao, Jingyu Hu, Weiru Liu, Lu Cheng, Mengnan Du

Large Vision-Language Models (LVLMs) have demonstrated remarkable
capabilities in processing both visual and textual information. However, the
critical challenge of alignment between visual and linguistic representations
is not fully understood. This survey presents a comprehensive examination of
alignment and misalignment in LVLMs through an explainability lens. We first
examine the fundamentals of alignment, exploring its representational and
behavioral aspects, training methodologies, and theoretical foundations. We
then analyze misalignment phenomena across three semantic levels: object,
attribute, and relational misalignment. Our investigation reveals that
misalignment emerges from challenges at multiple levels: the data level, the
model level, and the inference level. We provide a comprehensive review of
existing mitigation strategies, categorizing them into parameter-frozen and
parameter-tuning approaches. Finally, we outline promising future research
directions, emphasizing the need for standardized evaluation protocols and
in-depth explainability studies.

摘要：大型視覺語言模型 (LVLMs) 在處理視覺和文字資訊方面展現出非凡的能力。然而，視覺和語言表徵之間對齊的關鍵挑戰尚未完全了解。本調查透過可解釋性的觀點，對 LVLMs 中的對齊和失衡進行全面檢視。我們首先檢視對齊的基本原理，探討其表徵和行為面向、訓練方法和理論基礎。接著，我們在三個語義層面分析失衡現象：物件失衡、屬性失衡和關係失衡。我們的調查顯示，失衡源自於多個層面的挑戰：資料層面、模型層面和推論層面。我們提供現有緩解策略的全面回顧，將它們分類為參數凍結和參數調整方法。最後，我們概述有前景的未來研究方向，強調標準化評估協定和深入可解釋性研究的必要性。

##### **DeepFilter: An Instrumental Baseline for Accurate and Efficient Process Monitoring**
2501.01342v1 by Hao Wang, Zhichao Chen, Licheng Pan, Xiaoyu Jiang, Yichen Song, Qunshan He, Xinggao Liu

Effective process monitoring is increasingly vital in industrial automation
for ensuring operational safety, necessitating both high accuracy and
efficiency. Although Transformers have demonstrated success in various fields,
their canonical form based on the self-attention mechanism is inadequate for
process monitoring due to two primary limitations: (1) the step-wise
correlations captured by self-attention mechanism are difficult to capture
discriminative patterns in monitoring logs due to the lacking semantics of each
step, thus compromising accuracy; (2) the quadratic computational complexity of
self-attention hampers efficiency. To address these issues, we propose
DeepFilter, a Transformer-style framework for process monitoring. The core
innovation is an efficient filtering layer that excel capturing long-term and
periodic patterns with reduced complexity. Equipping with the global filtering
layer, DeepFilter enhances both accuracy and efficiency, meeting the stringent
demands of process monitoring. Experimental results on real-world process
monitoring datasets validate DeepFilter's superiority in terms of accuracy and
efficiency compared to existing state-of-the-art models.

摘要：有效製程監控在工業自動化中日益重要，用於確保作業安全，需要高準確度和效率。儘管 Transformer 已在各領域證明其成功，但其基於自我注意機制的標準形式由於兩個主要限制而不足以進行製程監控：(1) 自我注意機制所擷取的逐步關聯性難以擷取監控記錄中的區分模式，因為每個步驟缺乏語意，因此會影響準確度；(2) 自我注意的二次運算複雜度會阻礙效率。為了解決這些問題，我們提出了 DeepFilter，這是一個用於製程監控的 Transformer 風格架構。其核心創新是一個高效的過濾層，其優點是可以降低複雜度，並擷取長期和週期性模式。透過配備全球過濾層，DeepFilter 可同時提升準確度和效率，以滿足製程監控的嚴格要求。在真實世界的製程監控資料集上的實驗結果驗證了 DeepFilter 在準確度和效率方面優於現有最先進模型的優越性。

##### **Aligning Large Language Models for Faithful Integrity Against Opposing Argument**
2501.01336v1 by Yong Zhao, Yang Deng, See-Kiong Ng, Tat-Seng Chua

Large Language Models (LLMs) have demonstrated impressive capabilities in
complex reasoning tasks. However, they can be easily misled by unfaithful
arguments during conversations, even when their original statements are
correct. To this end, we investigate the problem of maintaining faithful
integrity in LLMs. This involves ensuring that LLMs adhere to their faithful
statements in the face of opposing arguments and are able to correct their
incorrect statements when presented with faithful arguments. In this work, we
propose a novel framework, named Alignment for Faithful Integrity with
Confidence Estimation (AFICE), which aims to align the LLM responses with
faithful integrity. Specifically, AFICE first designs a Bilateral Confidence
Estimation (BCE) approach for estimating the uncertainty of each response
generated by the LLM given a specific context, which simultaneously estimate
the model's confidence to the question based on the internal states during
decoding as well as to the answer based on cumulative probability ratios. With
the BCE, we construct a conversational preference dataset composed of context,
original statement, and argument, which is adopted for aligning the LLM for
faithful integrity using Direct Preference Optimization (DPO). Extensive
experimental results on a wide range of benchmarks demonstrate significant
improvements in the LLM's ability to maintain faithful responses when
encountering opposing arguments, ensuring both the practical utility and
trustworthiness of LLMs in complex interactive settings. Code and data will be
released via https://github.com/zhaoy777/AFICE.git

摘要：大型語言模型 (LLM) 在複雜推理任務中展現出令人印象深刻的能力。然而，即使它們的原始陳述正確，它們也可能在對話中輕易被不忠實的論點誤導。為此，我們研究了在 LLM 中維持忠實性的問題。這包括確保 LLM 在面對反對論點時堅持其忠實陳述，並能夠在提出忠實論點時糾正其不正確的陳述。在這項工作中，我們提出了一個名為「具有信心估計的忠實整合對齊」(AFICE) 的新框架，旨在將 LLM 回應與忠實整合保持一致。具體來說，AFICE 首先設計了一個雙邊信心估計 (BCE) 方法，用於估計 LLM 在特定背景下產生的每個回應的不確定性，它同時估計模型在解碼過程中基於內部狀態對問題的信心，以及基於累積機率比對答案的信心。有了 BCE，我們構建了一個對話偏好資料集，其中包含背景、原始陳述和論點，它被用於使用直接偏好最佳化 (DPO) 來調整 LLM 以獲得忠實的整合。在廣泛基準上的大量實驗結果證明，在遇到反對論點時，LLM 維持忠實回應的能力有顯著的提升，確保了 LLM 在複雜互動設定中的實用性和可信度。程式碼和資料將透過 https://github.com/zhaoy777/AFICE.git 發布

##### **CySecBench: Generative AI-based CyberSecurity-focused Prompt Dataset for Benchmarking Large Language Models**
2501.01335v1 by Johan Wahréus, Ahmed Mohamed Hussain, Panos Papadimitratos

Numerous studies have investigated methods for jailbreaking Large Language
Models (LLMs) to generate harmful content. Typically, these methods are
evaluated using datasets of malicious prompts designed to bypass security
policies established by LLM providers. However, the generally broad scope and
open-ended nature of existing datasets can complicate the assessment of
jailbreaking effectiveness, particularly in specific domains, notably
cybersecurity. To address this issue, we present and publicly release
CySecBench, a comprehensive dataset containing 12662 prompts specifically
designed to evaluate jailbreaking techniques in the cybersecurity domain. The
dataset is organized into 10 distinct attack-type categories, featuring
close-ended prompts to enable a more consistent and accurate assessment of
jailbreaking attempts. Furthermore, we detail our methodology for dataset
generation and filtration, which can be adapted to create similar datasets in
other domains. To demonstrate the utility of CySecBench, we propose and
evaluate a jailbreaking approach based on prompt obfuscation. Our experimental
results show that this method successfully elicits harmful content from
commercial black-box LLMs, achieving Success Rates (SRs) of 65% with ChatGPT
and 88% with Gemini; in contrast, Claude demonstrated greater resilience with a
jailbreaking SR of 17%. Compared to existing benchmark approaches, our method
shows superior performance, highlighting the value of domain-specific
evaluation datasets for assessing LLM security measures. Moreover, when
evaluated using prompts from a widely used dataset (i.e., AdvBench), it
achieved an SR of 78.5%, higher than the state-of-the-art methods.

摘要：<paragraph>許多研究探討了越獄大型語言模型 (LLM) 以產生有害內容的方法。通常，這些方法使用惡意提示的資料集進行評估，這些提示旨在繞過 LLM 提供者建立的安全政策。然而，現有資料集的廣泛範圍和開放式性質通常會使越獄有效性的評估變得複雜，特別是在特定領域，尤其是網路安全。為了解決這個問題，我們提出並公開發布 CySecBench，這是一個全面的資料集，包含 12662 個提示，專門用於評估網路安全領域的越獄技術。該資料集組織成 10 個不同的攻擊類型類別，採用封閉式提示，以便對越獄嘗試進行更一致且準確的評估。此外，我們詳細說明了我們的資料集生成和過濾方法，該方法可以調整以在其他領域建立類似的資料集。為了展示 CySecBench 的效用，我們提出並評估了一種基於提示混淆的越獄方法。我們的實驗結果顯示，此方法成功地從商業黑盒 LLM 獲取有害內容，在 ChatGPT 中達到 65% 的成功率 (SR)，在 Gemini 中達到 88%；相比之下，Claude 以 17% 的越獄 SR 表現出更大的韌性。與現有的基準方法相比，我們的模型顯示出優異的性能，突顯了特定領域評估資料集對於評估 LLM 安全措施的價值。此外，當使用來自廣泛使用資料集 (即 AdvBench) 的提示進行評估時，它達到了 78.5% 的 SR，高於最先進的方法。</paragraph>

##### **Decoding Knowledge in Large Language Models: A Framework for Categorization and Comprehension**
2501.01332v1 by Yanbo Fang, Ruixiang Tang

Understanding how large language models (LLMs) acquire, retain, and apply
knowledge remains an open challenge. This paper introduces a novel framework,
K-(CSA)^2, which categorizes LLM knowledge along two dimensions: correctness
and confidence. The framework defines six categories of knowledge, ranging from
highly confident correctness to confidently held misconceptions, enabling a
nuanced evaluation of model comprehension beyond binary accuracy. Using this
framework, we demonstrate how techniques like chain-of-thought prompting and
reinforcement learning with human feedback fundamentally alter the knowledge
structures of internal (pre-trained) and external (context-dependent) knowledge
in LLMs. CoT particularly enhances base model performance and shows synergistic
benefits when applied to aligned LLMs. Moreover, our layer-wise analysis
reveals that higher layers in LLMs encode more high-confidence knowledge, while
low-confidence knowledge tends to emerge in middle-to-lower layers.

摘要：了解大型語言模型 (LLM) 如何獲取、保留和應用知識仍然是一項公開挑戰。本文介紹了一個新框架 K-(CSA)^2，它將 LLM 知識分為兩個面向：正確性和信心。該框架定義了六類知識，範圍從高度自信的正確性到自信地堅持錯誤觀念，從而能夠對模型理解進行細緻的評估，而不仅仅是二元準確性。使用此框架，我們展示了像思考鏈提示和帶有人類回饋的強化學習這樣的技術如何從根本上改變 LLM 中內部（預訓練）和外部（上下文相關）知識的知識結構。CoT 特別增強了基礎模型的性能，並在應用於對齊的 LLM 時顯示出協同效應。此外，我們的逐層分析表明，LLM 中的較高層編碼了更多的高信心知識，而低信心知識則傾向於出現在中低層。

##### **The Prompt Alchemist: Automated LLM-Tailored Prompt Optimization for Test Case Generation**
2501.01329v1 by Shuzheng Gao, Chaozheng Wang, Cuiyun Gao, Xiaoqian Jiao, Chun Yong Chong, Shan Gao, Michael Lyu

Test cases are essential for validating the reliability and quality of
software applications. Recent studies have demonstrated the capability of Large
Language Models (LLMs) to generate useful test cases for given source code.
However, the existing work primarily relies on human-written plain prompts,
which often leads to suboptimal results since the performance of LLMs can be
highly influenced by the prompts. Moreover, these approaches use the same
prompt for all LLMs, overlooking the fact that different LLMs might be best
suited to different prompts. Given the wide variety of possible prompt
formulations, automatically discovering the optimal prompt for each LLM
presents a significant challenge. Although there are methods on automated
prompt optimization in the natural language processing field, they are hard to
produce effective prompts for the test case generation task. First, the methods
iteratively optimize prompts by simply combining and mutating existing ones
without proper guidance, resulting in prompts that lack diversity and tend to
repeat the same errors in the generated test cases. Second, the prompts are
generally lack of domain contextual knowledge, limiting LLMs' performance in
the task.

摘要：測試案例對於驗證軟體應用的可靠性和品質至關重要。最近的研究已證明大型語言模型 (LLM) 能夠為給定的原始碼產生有用的測試案例。然而，現有的工作主要依賴人工撰寫的簡單提示，這通常會導致次佳的結果，因為 LLM 的效能可能會受到提示的極大影響。此外，這些方法對所有 LLM 使用相同的提示，忽略了不同的 LLM 可能最適合不同的提示這個事實。考量到各種可能的提示表述，自動找出每個 LLM 的最佳提示是一項重大的挑戰。儘管自然語言處理領域有自動提示最佳化的方式，但它們難以產生有效的提示以進行測試案例產生任務。首先，這些方法透過簡單地組合和改變現有的提示，在沒有適當指導的情況下反覆最佳化提示，導致提示缺乏多樣性，並且傾向於在產生的測試案例中重複相同的錯誤。其次，提示通常缺乏領域脈絡知識，這會限制 LLM 在任務中的效能。

##### **Understanding Difficult-to-learn Examples in Contrastive Learning: A Theoretical Framework for Spectral Contrastive Learning**
2501.01317v1 by Yi-Ge Zhang, Jingyi Cui, Qiran Li, Yisen Wang

Unsupervised contrastive learning has shown significant performance
improvements in recent years, often approaching or even rivaling supervised
learning in various tasks. However, its learning mechanism is fundamentally
different from that of supervised learning. Previous works have shown that
difficult-to-learn examples (well-recognized in supervised learning as examples
around the decision boundary), which are essential in supervised learning,
contribute minimally in unsupervised settings. In this paper, perhaps
surprisingly, we find that the direct removal of difficult-to-learn examples,
although reduces the sample size, can boost the downstream classification
performance of contrastive learning. To uncover the reasons behind this, we
develop a theoretical framework modeling the similarity between different pairs
of samples. Guided by this theoretical framework, we conduct a thorough
theoretical analysis revealing that the presence of difficult-to-learn examples
negatively affects the generalization of contrastive learning. Furthermore, we
demonstrate that the removal of these examples, and techniques such as margin
tuning and temperature scaling can enhance its generalization bounds, thereby
improving performance. Empirically, we propose a simple and efficient mechanism
for selecting difficult-to-learn examples and validate the effectiveness of the
aforementioned methods, which substantiates the reliability of our proposed
theoretical framework.

摘要：無監督對比學習在近年來展現出顯著的效能提升，通常接近甚至與各種任務中的監督式學習相匹敵。然而，其學習機制與監督式學習有根本上的不同。先前的研究已顯示，難以學習的範例（在監督式學習中公認為決策邊界附近的範例），在監督式學習中至關重要，但在無監督式設定中貢獻甚微。在本文中，或許令人驚訝的是，我們發現難以學習的範例直接移除，儘管會減少樣本大小，但能提升對比學習的下游分類效能。為了找出背後的原因，我們建構了一個理論架構，對不同範例對之間的相似性進行建模。在這個理論架構的指導下，我們進行了徹底的理論分析，揭示了難以學習的範例的存在對比學習的泛化產生負面影響。此外，我們證明了移除這些範例，以及邊界調整和溫度調整等技術，可以增強其泛化界限，進而提升效能。在經驗上，我們提出了一個簡單且有效的機制來選擇難以學習的範例，並驗證了上述方法的有效性，這證實了我們提出的理論架構的可靠性。

##### **Multi-Head Explainer: A General Framework to Improve Explainability in CNNs and Transformers**
2501.01311v1 by Bohang Sun, Pietro Liò

In this study, we introduce the Multi-Head Explainer (MHEX), a versatile and
modular framework that enhances both the explainability and accuracy of
Convolutional Neural Networks (CNNs) and Transformer-based models. MHEX
consists of three core components: an Attention Gate that dynamically
highlights task-relevant features, Deep Supervision that guides early layers to
capture fine-grained details pertinent to the target class, and an Equivalent
Matrix that unifies refined local and global representations to generate
comprehensive saliency maps. Our approach demonstrates superior compatibility,
enabling effortless integration into existing residual networks like ResNet and
Transformer architectures such as BERT with minimal modifications. Extensive
experiments on benchmark datasets in medical imaging and text classification
show that MHEX not only improves classification accuracy but also produces
highly interpretable and detailed saliency scores.

摘要：在這項研究中，我們引入了多頭解釋器 (MHEX)，一個多功能且模組化的架構，用於增強卷積神經網路 (CNN) 和 Transformer 為基礎的模型的可解釋性和準確性。MHEX 包含三個核心元件：一個動態突顯與任務相關特徵的注意力閘門、引導早期層捕捉與目標類別相關的細緻細節的深度監督，以及一個統一精緻的局部和全局表示以產生全面的顯著性圖的等效矩陣。我們的做法展現出優異的相容性，讓 ResNet 等現有的殘差網路和 BERT 等 Transformer 架構能夠輕鬆整合，而且修改幅度極小。在醫學影像和文字分類的基準資料集上進行的廣泛實驗顯示，MHEX 不僅能提升分類準確性，還能產生高度可解釋且詳細的顯著性分數。

##### **Think More, Hallucinate Less: Mitigating Hallucinations via Dual Process of Fast and Slow Thinking**
2501.01306v1 by Xiaoxue Cheng, Junyi Li, Wayne Xin Zhao, Ji-Rong Wen

Large language models (LLMs) demonstrate exceptional capabilities, yet still
face the hallucination issue. Typical text generation approaches adopt an
auto-regressive generation without deliberate reasoning, which often results in
untrustworthy and factually inaccurate responses. In this paper, we propose
HaluSearch, a novel framework that incorporates tree search-based algorithms
(e.g. MCTS) to enable an explicit slow thinking generation process for
mitigating hallucinations of LLMs during inference. Specifically, HaluSearch
frames text generation as a step-by-step reasoning process, using a
self-evaluation reward model to score each generation step and guide the tree
search towards the most reliable generation pathway for fully exploiting the
internal knowledge of LLMs. To balance efficiency and quality, we introduce a
hierarchical thinking system switch mechanism inspired by the dual process
theory in cognitive science, which dynamically alternates between fast and slow
thinking modes at both the instance and step levels, adapting to the complexity
of questions and reasoning states. We conduct extensive experiments on both
English and Chinese datasets and the results show that our approach
significantly outperforms baseline approaches.

摘要：大型語言模型 (LLM) 展現出色的能力，但仍面臨幻覺問題。典型的文字生成方法採用自動回歸生成，沒有經過深思熟慮的推理，這通常會導致不可靠且事實不正確的回應。在本文中，我們提出 HaluSearch，一個新的框架，它結合了基於樹狀搜尋的演算法（例如 MCTS），以便在推理過程中啟用明確的慢速思考生成程序，以減輕 LLM 的幻覺。具體來說，HaluSearch 將文字生成設定為一個逐步推理的過程，使用自我評估獎勵模型來評分每個生成步驟，並引導樹狀搜尋朝向最可靠的生成路徑，以充分利用 LLM 的內部知識。為了平衡效率和品質，我們引入了一個分層思考系統切換機制，靈感來自認知科學中的雙重過程理論，它在實例和步驟層級上動態地在快速和慢速思考模式之間交替，以適應問題和推理狀態的複雜性。我們對英文和中文資料集進行了廣泛的實驗，結果表明，我們的做法明顯優於基線做法。

##### **Large Language Models for Mental Health Diagnostic Assessments: Exploring The Potential of Large Language Models for Assisting with Mental Health Diagnostic Assessments -- The Depression and Anxiety Case**
2501.01305v1 by Kaushik Roy, Harshul Surana, Darssan Eswaramoorthi, Yuxin Zi, Vedant Palit, Ritvik Garimella, Amit Sheth

Large language models (LLMs) are increasingly attracting the attention of
healthcare professionals for their potential to assist in diagnostic
assessments, which could alleviate the strain on the healthcare system caused
by a high patient load and a shortage of providers. For LLMs to be effective in
supporting diagnostic assessments, it is essential that they closely replicate
the standard diagnostic procedures used by clinicians. In this paper, we
specifically examine the diagnostic assessment processes described in the
Patient Health Questionnaire-9 (PHQ-9) for major depressive disorder (MDD) and
the Generalized Anxiety Disorder-7 (GAD-7) questionnaire for generalized
anxiety disorder (GAD). We investigate various prompting and fine-tuning
techniques to guide both proprietary and open-source LLMs in adhering to these
processes, and we evaluate the agreement between LLM-generated diagnostic
outcomes and expert-validated ground truth. For fine-tuning, we utilize the
Mentalllama and Llama models, while for prompting, we experiment with
proprietary models like GPT-3.5 and GPT-4o, as well as open-source models such
as llama-3.1-8b and mixtral-8x7b.

摘要：大型語言模型（LLM）越來越受到醫療保健專業人士的關注，因為它們有可能協助診斷評估，這可以減輕由高患者負擔和提供者短缺造成的醫療保健系統壓力。對於 LLM 在支持診斷評估方面能發揮作用，至關重要的是它們必須嚴格複製臨床醫生使用的標準診斷程序。在本文中，我們特別檢查了主要憂鬱症（MDD）的患者健康問卷-9（PHQ-9）和廣泛性焦慮症（GAD）的廣泛性焦慮症-7（GAD-7）問卷中描述的診斷評估程序。我們研究了各種提示和微調技術，以指導專有和開源 LLM 遵循這些程序，並且我們評估了 LLM 生成的診斷結果與專家驗證的地面真實性之間的一致性。對於微調，我們利用了 Mentalllama 和 Llama 模型，而對於提示，我們嘗試了專有模型，如 GPT-3.5 和 GPT-4o，以及開源模型，如 llama-3.1-8b 和 mixtral-8x7b。

##### **LEO-Split: A Semi-Supervised Split Learning Framework over LEO Satellite Networks**
2501.01293v1 by Zheng Lin, Yuxin Zhang, Zhe Chen, Zihan Fang, Cong Wu, Xianhao Chen, Yue Gao, Jun Luo

Recently, the increasing deployment of LEO satellite systems has enabled
various space analytics (e.g., crop and climate monitoring), which heavily
relies on the advancements in deep learning (DL). However, the intermittent
connectivity between LEO satellites and ground station (GS) significantly
hinders the timely transmission of raw data to GS for centralized learning,
while the scaled-up DL models hamper distributed learning on
resource-constrained LEO satellites. Though split learning (SL) can be a
potential solution to these problems by partitioning a model and offloading
primary training workload to GS, the labor-intensive labeling process remains
an obstacle, with intermittent connectivity and data heterogeneity being other
challenges. In this paper, we propose LEO-Split, a semi-supervised (SS) SL
design tailored for satellite networks to combat these challenges. Leveraging
SS learning to handle (labeled) data scarcity, we construct an auxiliary model
to tackle the training failure of the satellite-GS non-contact time. Moreover,
we propose a pseudo-labeling algorithm to rectify data imbalances across
satellites. Lastly, an adaptive activation interpolation scheme is devised to
prevent the overfitting of server-side sub-model training at GS. Extensive
experiments with real-world LEO satellite traces (e.g., Starlink) demonstrate
that our LEO-Split framework achieves superior performance compared to
state-ofthe-art benchmarks.

摘要：<paragraph>最近，LEO 卫星系统的日益部署已启用各种空间分析（例如，作物和气候监测），这在很大程度上依赖于深度学习 (DL) 的进步。然而，LEO 卫星和地面站 (GS) 之间的间歇连接极大地阻碍了原始数据及时传输到 GS 以进行集中学习，而规模扩大的 DL 模型阻碍了对资源受限的 LEO 卫星进行分布式学习。尽管拆分学习 (SL) 可以通过对模型进行分区并将主要训练工作负载卸载到 GS 来解决这些问题，但劳动密集型的标记过程仍然是一个障碍，间歇连接和数据异构性是其他挑战。在本文中，我们提出了 LEO-Split，这是一种针对卫星网络定制的半监督 (SS) SL 设计，以应对这些挑战。利用 SS 学习来处理（标记的）数据稀缺性，我们构建了一个辅助模型来解决卫星-GS 非接触时间的训练失败问题。此外，我们提出了一种伪标记算法来纠正卫星之间的数据不平衡。最后，设计了一种自适应激活插值方案，以防止 GS 中服务器端子模型训练过度拟合。使用真实世界的 LEO 卫星轨迹（例如，Starlink）进行的广泛实验表明，与最先进的基准相比，我们的 LEO-Split 框架实现了卓越的性能。</paragraph>

##### **Change Detection-Based Procedures for Piecewise Stationary MABs: A Modular Approach**
2501.01291v1 by Yu-Han Huang, Argyrios Gerogiannis, Subhonmesh Bose, Venugopal V. Veeravalli

Conventional Multi-Armed Bandit (MAB) algorithms are designed for stationary
environments, where the reward distributions associated with the arms do not
change with time. In many applications, however, the environment is more
accurately modeled as being nonstationary. In this work, piecewise stationary
MAB (PS-MAB) environments are investigated, in which the reward distributions
associated with a subset of the arms change at some change-points and remain
stationary between change-points. Our focus is on the asymptotic analysis of
PS-MABs, for which practical algorithms based on change detection (CD) have
been previously proposed. Our goal is to modularize the design and analysis of
such CD-based Bandit (CDB) procedures. To this end, we identify the
requirements for stationary bandit algorithms and change detectors in a CDB
procedure that are needed for the modularization. We assume that the rewards
are sub-Gaussian. Under this assumption and a condition on the separation of
the change-points, we show that the analysis of CDB procedures can indeed be
modularized, so that regret bounds can be obtained in a unified manner for
various combinations of change detectors and bandit algorithms. Through this
analysis, we develop new modular CDB procedures that are order-optimal. We
compare the performance of our modular CDB procedures with various other
methods in simulations.

摘要：傳統的多臂老虎機 (MAB) 演算法是為靜態環境所設計，其中與手臂相關的獎勵分佈不會隨著時間而改變。然而，在許多應用中，環境更精確地被建模為非靜態的。在這項工作中，研究了分段靜態 MAB (PS-MAB) 環境，其中與手臂子集相關的獎勵分佈在某些變動點發生變化，並在變動點之間保持靜態。我們的重點在於 PS-MAB 的漸近分析，其中先前已提出基於變動偵測 (CD) 的實用演算法。我們的目標是將此類基於 CD 的老虎機 (CDB) 程序的設計和分析模組化。為此，我們在 CDB 程序中找出模組化所需的靜態老虎機演算法和變動偵測器的需求。我們假設獎勵是次高斯分佈的。在此假設和變動點分離的條件下，我們證明 CDB 程序的分析確實可以模組化，因此可以統一的方式為變動偵測器和老虎機演算法的各種組合取得遺憾界限。透過此分析，我們開發了新的模組化 CDB 程序，其為次佳。我們在模擬中將我們的模組化 CDB 程序的效能與其他各種方法進行比較。

##### **ToolComp: A Multi-Tool Reasoning & Process Supervision Benchmark**
2501.01290v1 by Vaskar Nath, Pranav Raja, Claire Yoon, Sean Hendryx

Despite recent advances in AI, the development of systems capable of
executing complex, multi-step reasoning tasks involving multiple tools remains
a significant challenge. Current benchmarks fall short in capturing the
real-world complexity of tool-use reasoning, where verifying the correctness of
not only the final answer but also the intermediate steps is important for
evaluation, development, and identifying failures during inference time. To
bridge this gap, we introduce ToolComp, a comprehensive benchmark designed to
evaluate multi-step tool-use reasoning. ToolComp is developed through a
collaboration between models and human annotators, featuring
human-edited/verified prompts, final answers, and process supervision labels,
allowing for the evaluation of both final outcomes and intermediate reasoning.
Evaluation across six different model families demonstrates the challenging
nature of our dataset, with the majority of models achieving less than 50%
accuracy. Additionally, we generate synthetic training data to compare the
performance of outcome-supervised reward models (ORMs) with process-supervised
reward models (PRMs) to assess their ability to improve complex tool-use
reasoning as evaluated by ToolComp. Our results show that PRMs generalize
significantly better than ORMs, achieving a 19% and 11% improvement in rank@1
accuracy for ranking base and fine-tuned model trajectories, respectively.
These findings highlight the critical role of process supervision in both the
evaluation and training of AI models, paving the way for more robust and
capable systems in complex, multi-step tool-use tasks.

摘要：儘管 AI 近期有長足進展，但開發能夠執行複雜、多步驟推理任務，且涉及多種工具的系統，仍然是一項重大挑戰。目前的基準在捕捉工具使用推理的真實世界複雜性方面有所不足，其中驗證不僅最終答案，還驗證中間步驟的正確性，對於評估、開發和在推理期間識別失敗非常重要。為了彌補這一差距，我們引入了 ToolComp，一個旨在評估多步驟工具使用推理的綜合基準。ToolComp 是在模型和人類註解者的協作下開發的，具有經過人為編輯/驗證的提示、最終答案和流程監督標籤，允許評估最終結果和中間推理。在六個不同的模型系列中進行的評估證明了我們資料集的挑戰性，大多數模型的準確度低於 50%。此外，我們生成了合成訓練資料，以比較結果監督獎勵模型 (ORM) 與流程監督獎勵模型 (PRM) 的效能，以評估它們提升 ToolComp 評估的複雜工具使用推理的能力。我們的結果顯示，PRM 的泛化效果顯著優於 ORM，在基本和微調模型軌跡的排名@1 準確度方面分別提升了 19% 和 11%。這些發現突顯了流程監督在 AI 模型評估和訓練中的關鍵作用，為在複雜、多步驟工具使用任務中建立更強健且更強大的系統鋪平了道路。

##### **NeutraSum: A Language Model can help a Balanced Media Diet by Neutralizing News Summaries**
2501.01284v1 by Xi Luo, Junjie Liu, Sirong Wu, Yuhui Deng

Media bias in news articles arises from the political polarisation of media
outlets, which can reinforce societal stereotypes and beliefs. Reporting on the
same event often varies significantly between outlets, reflecting their
political leanings through polarised language and focus. Although previous
studies have attempted to generate bias-free summaries from multiperspective
news articles, they have not effectively addressed the challenge of mitigating
inherent media bias. To address this gap, we propose \textbf{NeutraSum}, a
novel framework that integrates two neutrality losses to adjust the semantic
space of generated summaries, thus minimising media bias. These losses,
designed to balance the semantic distances across polarised inputs and ensure
alignment with expert-written summaries, guide the generation of neutral and
factually rich summaries. To evaluate media bias, we employ the political
compass test, which maps political leanings based on economic and social
dimensions. Experimental results on the Allsides dataset demonstrate that
NeutraSum not only improves summarisation performance but also achieves
significant reductions in media bias, offering a promising approach for neutral
news summarisation.

摘要：媒體偏見在新聞文章中源自媒體機構的政治兩極分化，這可能會強化社會刻板印象和信念。對於同一事件的報導通常在各個媒體機構間有顯著差異，反映出他們透過兩極化的語言和焦點來表達政治傾向。儘管先前的研究已嘗試從多觀點新聞文章中產生無偏見的摘要，但它們並未有效解決減輕固有媒體偏見的挑戰。為了解決這個差距，我們提出了 \textbf{NeutraSum}，一個整合了兩個中立性損失以調整生成摘要的語義空間的新框架，從而最大程度地減少媒體偏見。這些損失旨在平衡兩極化輸入之間的語義距離，並確保與專家撰寫的摘要保持一致，指導生成中立且內容豐富的摘要。為了評估媒體偏見，我們採用了政治羅盤測試，該測試根據經濟和社會層面來描繪政治傾向。在 Allsides 資料集上的實驗結果表明，NeutraSum 不僅提高了摘要性能，還顯著減少了媒體偏見，為中立新聞摘要提供了一種有前景的方法。

##### **CultureVLM: Characterizing and Improving Cultural Understanding of Vision-Language Models for over 100 Countries**
2501.01282v1 by Shudong Liu, Yiqiao Jin, Cheng Li, Derek F. Wong, Qingsong Wen, Lichao Sun, Haipeng Chen, Xing Xie, Jindong Wang

Vision-language models (VLMs) have advanced human-AI interaction but struggle
with cultural understanding, often misinterpreting symbols, gestures, and
artifacts due to biases in predominantly Western-centric training data. In this
paper, we construct CultureVerse, a large-scale multimodal benchmark covering
19, 682 cultural concepts, 188 countries/regions, 15 cultural concepts, and 3
question types, with the aim of characterizing and improving VLMs'
multicultural understanding capabilities. Then, we propose CultureVLM, a series
of VLMs fine-tuned on our dataset to achieve significant performance
improvement in cultural understanding. Our evaluation of 16 models reveals
significant disparities, with a stronger performance in Western concepts and
weaker results in African and Asian contexts. Fine-tuning on our CultureVerse
enhances cultural perception, demonstrating cross-cultural, cross-continent,
and cross-dataset generalization without sacrificing performance on models'
general VLM benchmarks. We further present insights on cultural generalization
and forgetting. We hope that this work could lay the foundation for more
equitable and culturally aware multimodal AI systems.

摘要：視覺語言模型 (VLM) 促進了人類與人工智慧的互動，但卻在文化理解方面遇到困難，由於以西方為主的訓練資料中的偏見，常常誤解符號、手勢和文物。在本文中，我們建構了 CultureVerse，一個涵蓋 19,682 個文化概念、188 個國家/地區、15 個文化概念和 3 種問題類型的大規模多模態基準，目的是描述和改善 VLM 的多元文化理解能力。然後，我們提出了 CultureVLM，這是一系列針對我們的資料集進行微調的 VLM，以在文化理解方面實現顯著的效能提升。我們對 16 個模型的評估顯示出顯著的差異，在西方概念中表現較佳，而在非洲和亞洲背景中的結果較差。針對我們的 CultureVerse 進行微調可以增強文化認知，展示跨文化、跨洲和跨資料集的概化，而不會犧牲模型在一般 VLM 基準上的效能。我們進一步提出了關於文化概化和遺忘的見解。我們希望這項工作可以為更公平且具有文化意識的多模態人工智慧系統奠定基礎。

##### **Does a Large Language Model Really Speak in Human-Like Language?**
2501.01273v1 by Mose Park, Yunjin Choi, Jong-June Jeon

Large Language Models (LLMs) have recently emerged, attracting considerable
attention due to their ability to generate highly natural, human-like text.
This study compares the latent community structures of LLM-generated text and
human-written text within a hypothesis testing procedure. Specifically, we
analyze three text sets: original human-written texts ($\mathcal{O}$), their
LLM-paraphrased versions ($\mathcal{G}$), and a twice-paraphrased set
($\mathcal{S}$) derived from $\mathcal{G}$. Our analysis addresses two key
questions: (1) Is the difference in latent community structures between
$\mathcal{O}$ and $\mathcal{G}$ the same as that between $\mathcal{G}$ and
$\mathcal{S}$? (2) Does $\mathcal{G}$ become more similar to $\mathcal{O}$ as
the LLM parameter controlling text variability is adjusted? The first question
is based on the assumption that if LLM-generated text truly resembles human
language, then the gap between the pair ($\mathcal{O}$, $\mathcal{G}$) should
be similar to that between the pair ($\mathcal{G}$, $\mathcal{S}$), as both
pairs consist of an original text and its paraphrase. The second question
examines whether the degree of similarity between LLM-generated and human text
varies with changes in the breadth of text generation. To address these
questions, we propose a statistical hypothesis testing framework that leverages
the fact that each text has corresponding parts across all datasets due to
their paraphrasing relationship. This relationship enables the mapping of one
dataset's relative position to another, allowing two datasets to be mapped to a
third dataset. As a result, both mapped datasets can be quantified with respect
to the space characterized by the third dataset, facilitating a direct
comparison between them. Our results indicate that GPT-generated text remains
distinct from human-authored text.

摘要：大型語言模型 (LLM) 最近浮出檯面，由於它們生成高度自然、類似人類文字的能力而備受關注。本研究比較了 LLM 生成的文字和人類撰寫的文字在假設檢定程序中的潛在社群結構。具體來說，我們分析了三組文字：原始的人類撰寫文字（$\mathcal{O}$）、它們的 LLM 釋義版本（$\mathcal{G}$）以及從 $\mathcal{G}$ 衍生的二次釋義組（$\mathcal{S}$）。我們的分析探討了兩個關鍵問題：(1) $\mathcal{O}$ 和 $\mathcal{G}$ 之間潛在社群結構的差異是否與 $\mathcal{G}$ 和 $\mathcal{S}$ 之間的差異相同？(2) 隨著控制文字變異性的 LLM 參數進行調整，$\mathcal{G}$ 是否會變得更類似於 $\mathcal{O}$？第一個問題基於以下假設：如果 LLM 生成的文字確實類似於人類語言，那麼成對（$\mathcal{O}$，$\mathcal{G}$）之間的差距應該類似於成對（$\mathcal{G}$，$\mathcal{S}$）之間的差距，因為這兩對都包含原始文字及其釋義。第二個問題探討 LLM 生成的文字和人類文字之間的相似度是否會隨著文字生成廣度的變化而變化。為了探討這些問題，我們提出了一個統計假設檢定架構，利用了每個文字在所有資料集之間都有對應部分的事實，因為它們之間存在釋義關係。這種關係使得一個資料集的相對位置可以對應到另一個資料集，從而允許兩個資料集對應到第三個資料集。因此，這兩個對應的資料集都可以根據第三個資料集的特徵空間進行量化，從而便於在它們之間進行直接比較。我們的結果表明，GPT 生成的文字仍然有別於人類撰寫的文字。

##### **ProgCo: Program Helps Self-Correction of Large Language Models**
2501.01264v1 by Xiaoshuai Song, Yanan Wu, Weixun Wang, Jiaheng Liu, Wenbo Su, Bo Zheng

Self-Correction aims to enable large language models (LLMs) to self-verify
and self-refine their initial responses without external feedback. However,
LLMs often fail to effectively self-verify and generate correct feedback,
further misleading refinement and leading to the failure of self-correction,
especially in complex reasoning tasks. In this paper, we propose Program-driven
Self-Correction (ProgCo). First, program-driven verification (ProgVe) achieves
complex verification logic and extensive validation through self-generated,
self-executing verification pseudo-programs. Then, program-driven refinement
(ProgRe) receives feedback from ProgVe, conducts dual reflection and refinement
on both responses and verification programs to mitigate misleading of incorrect
feedback in complex reasoning tasks. Experiments on three instruction-following
and mathematical benchmarks indicate that ProgCo achieves effective
self-correction, and can be further enhance performance when combined with real
program tools.

摘要：自我修正旨在讓大型語言模型 (LLM) 能自我驗證和自我修正其初始回應，而無需外部回饋。然而，LLM 經常無法有效自我驗證並產生正確的回饋，進一步誤導修正並導致自我修正失敗，特別是在複雜的推理任務中。在本文中，我們提出程式驅動的自我修正 (ProgCo)。首先，程式驅動驗證 (ProgVe) 透過自我產生的、自我執行的驗證偽程式，實現複雜的驗證邏輯和廣泛的驗證。然後，程式驅動修正 (ProgRe) 接收 ProgVe 的回饋，對回應和驗證程式進行雙重反思和修正，以減輕錯誤回饋在複雜推理任務中的誤導。在三個指令遵循和數學基準上的實驗表明，ProgCo 達到了有效的自我修正，並且與真實的程式工具結合使用時，可以進一步提升效能。

##### **Stealthy Backdoor Attack to Real-world Models in Android Apps**
2501.01263v1 by Jiali Wei, Ming Fan, Xicheng Zhang, Wenjing Jiao, Haijun Wang, Ting Liu

Powered by their superior performance, deep neural networks (DNNs) have found
widespread applications across various domains. Many deep learning (DL) models
are now embedded in mobile apps, making them more accessible to end users
through on-device DL. However, deploying on-device DL to users' smartphones
simultaneously introduces several security threats. One primary threat is
backdoor attacks. Extensive research has explored backdoor attacks for several
years and has proposed numerous attack approaches. However, few studies have
investigated backdoor attacks on DL models deployed in the real world, or they
have shown obvious deficiencies in effectiveness and stealthiness. In this
work, we explore more effective and stealthy backdoor attacks on real-world DL
models extracted from mobile apps. Our main justification is that imperceptible
and sample-specific backdoor triggers generated by DNN-based steganography can
enhance the efficacy of backdoor attacks on real-world models. We first confirm
the effectiveness of steganography-based backdoor attacks on four
state-of-the-art DNN models. Subsequently, we systematically evaluate and
analyze the stealthiness of the attacks to ensure they are difficult to
perceive. Finally, we implement the backdoor attacks on real-world models and
compare our approach with three baseline methods. We collect 38,387 mobile
apps, extract 89 DL models from them, and analyze these models to obtain the
prerequisite model information for the attacks. After identifying the target
models, our approach achieves an average of 12.50% higher attack success rate
than DeepPayload while better maintaining the normal performance of the models.
Extensive experimental results demonstrate that our method enables more
effective, robust, and stealthy backdoor attacks on real-world models.

摘要：<paragraph>深度神经網路（DNN）憑藉其卓越的效能，已廣泛應用於各個領域。許多深度學習（DL）模型現已內嵌於行動應用程式中，讓使用者透過裝置上的 DL 更容易取得這些模型。然而，將裝置上的 DL 部署到使用者的智慧型手機中，同時也引入了多項安全威脅。其中一項主要威脅就是後門攻擊。多年來，針對後門攻擊已進行了廣泛的研究，並提出了許多攻擊方法。然而，鮮少有研究探討部署於真實世界中的 DL 模型所遭受的後門攻擊，或是在有效性和隱匿性方面顯示出明顯的缺陷。在這項工作中，我們探討了針對從行動應用程式中萃取的真實世界 DL 模型，更有效且隱匿的後門攻擊。我們的論點主要是，基於 DNN 隱寫術所產生的難以察覺且特定於樣本的後門觸發器，可以提升後門攻擊對真實世界模型的效力。我們首先確認了基於隱寫術的後門攻擊對四種最先進的 DNN 模型的有效性。接著，我們系統性地評估和分析攻擊的隱匿性，以確保它們難以察覺。最後，我們在真實世界模型上實作後門攻擊，並將我們的做法與三種基準方法進行比較。我們收集了 38,387 個行動應用程式，從中萃取了 89 個 DL 模型，並分析這些模型以取得攻擊所需的模型資訊。在找出目標模型後，我們的做法比 DeepPayload 達到了平均高出 12.50% 的攻擊成功率，同時更能維持模型的正常效能。廣泛的實驗結果證明，我們的做法讓後門攻擊對真實世界模型更有效、更強健且更隱匿。</paragraph>

##### **CodeElo: Benchmarking Competition-level Code Generation of LLMs with Human-comparable Elo Ratings**
2501.01257v1 by Shanghaoran Quan, Jiaxi Yang, Bowen Yu, Bo Zheng, Dayiheng Liu, An Yang, Xuancheng Ren, Bofei Gao, Yibo Miao, Yunlong Feng, Zekun Wang, Jian Yang, Zeyu Cui, Yang Fan, Yichang Zhang, Binyuan Hui, Junyang Lin

With the increasing code reasoning capabilities of existing large language
models (LLMs) and breakthroughs in reasoning models like OpenAI o1 and o3,
there is a growing need to develop more challenging and comprehensive
benchmarks that effectively test their sophisticated competition-level coding
abilities. Existing benchmarks, like LiveCodeBench and USACO, fall short due to
the unavailability of private test cases, lack of support for special judges,
and misaligned execution environments. To bridge this gap, we introduce
CodeElo, a standardized competition-level code generation benchmark that
effectively addresses all these challenges for the first time. CodeElo
benchmark is mainly based on the official CodeForces platform and tries to
align with the platform as much as possible. We compile the recent six months
of contest problems on CodeForces with detailed information such as contest
divisions, problem difficulty ratings, and problem algorithm tags. We introduce
a unique judging method in which problems are submitted directly to the
platform and develop a reliable Elo rating calculation system that aligns with
the platform and is comparable with human participants but has lower variance.
By testing on our CodeElo, we provide the Elo ratings of 30 existing popular
open-source and 3 proprietary LLMs for the first time. The results show that
o1-mini and QwQ-32B-Preview stand out significantly, achieving Elo ratings of
1578 and 1261, respectively, while other models struggle even with the easiest
problems, placing in the lowest 20 percent among all human participants.
Detailed analysis experiments are also conducted to provide insights into
performance across algorithms and comparisons between using C++ and Python,
which can suggest directions for future studies.

摘要：<paragraph>隨著現有大型語言模型 (LLM) 的程式碼推理能力不斷提升，以及 OpenAI o1 和 o3 等推理模型的突破，對於開發更具挑戰性和全面的基準測試的需求也日益增加，以有效測試其複雜的競賽級程式碼能力。現有的基準測試，例如 LiveCodeBench 和 USACO，由於缺乏私人測試案例、不支援特殊評審以及執行環境不一致等因素而有所不足。為了彌補這個差距，我們引入了 CodeElo，一個標準化的競賽級程式碼生成基準測試，首次有效地解決了所有這些挑戰。CodeElo 基準測試主要基於官方 CodeForces 平台，並盡可能與該平台保持一致。我們編譯了 CodeForces 上最近六個月的比賽題目，並附有詳細資訊，例如比賽組別、題目難度評級和題目演算法標籤。我們引入了一種獨特的評審方法，其中題目直接提交到平台，並開發了一個可靠的 Elo 評分計算系統，該系統與平台保持一致，並且與人類參與者相當，但變異性較低。透過在我們的 CodeElo 上進行測試，我們首次提供了 30 個現有流行開源和 3 個專有的 LLM 的 Elo 評分。結果顯示，o1-mini 和 QwQ-32B-Preview 表現顯著，分別獲得 1578 和 1261 的 Elo 評分，而其他模型即使是最簡單的題目也難以應付，在所有人類參與者中排在最低的 20%。我們還進行了詳細的分析實驗，以深入了解演算法的效能，以及使用 C++ 和 Python 之間的比較，這可以為未來的研究提供方向。</paragraph>

##### **Digital Guardians: Can GPT-4, Perspective API, and Moderation API reliably detect hate speech in reader comments of German online newspapers?**
2501.01256v1 by Manuel Weber, Moritz Huber, Maximilian Auch, Alexander Döschl, Max-Emanuel Keller, Peter Mandl

In recent years, toxic content and hate speech have become widespread
phenomena on the internet. Moderators of online newspapers and forums are now
required, partly due to legal regulations, to carefully review and, if
necessary, delete reader comments. This is a labor-intensive process. Some
providers of large language models already offer solutions for automated hate
speech detection or the identification of toxic content. These include GPT-4o
from OpenAI, Jigsaw's (Google) Perspective API, and OpenAI's Moderation API.
Based on the selected German test dataset HOCON34k, which was specifically
created for developing tools to detect hate speech in reader comments of online
newspapers, these solutions are compared with each other and against the
HOCON34k baseline. The test dataset contains 1,592 annotated text samples. For
GPT-4o, three different promptings are used, employing a Zero-Shot, One-Shot,
and Few-Shot approach. The results of the experiments demonstrate that GPT-4o
outperforms both the Perspective API and the Moderation API, and exceeds the
HOCON34k baseline by approximately 5 percentage points, as measured by a
combined metric of MCC and F2-score.

摘要：近年來，網路上的有毒內容和仇恨言論已成為普遍現象。線上報紙和論壇的管理員現在必須仔細審查讀者留言，並在必要時刪除，這部分是基於法規要求。這是一個勞力密集的程序。一些大型語言模型的提供者已提供自動仇恨言論偵測或有毒內容識別的解決方案。這些解決方案包括 OpenAI 的 GPT-4o、Jigsaw（Google）的 Perspective API，以及 OpenAI 的 Moderation API。基於專門為開發用於偵測線上報紙讀者留言中仇恨言論的工具而建立的德語測試資料集 HOCON34k，這些解決方案彼此之間以及與 HOCON34k 基準進行比較。測試資料集包含 1,592 個註解文字範例。對於 GPT-4o，使用了三種不同的提示，採用零次學習、一次學習和少次學習方法。實驗結果顯示，GPT-4o 的表現優於 Perspective API 和 Moderation API，並且比 HOCON34k 基準高出約 5 個百分點，這是根據 MCC 和 F2 分數的綜合指標測量的。

##### **Large Language Model-Enhanced Symbolic Reasoning for Knowledge Base Completion**
2501.01246v1 by Qiyuan He, Jianfei Yu, Wenya Wang

Integrating large language models (LLMs) with rule-based reasoning offers a
powerful solution for improving the flexibility and reliability of Knowledge
Base Completion (KBC). Traditional rule-based KBC methods offer verifiable
reasoning yet lack flexibility, while LLMs provide strong semantic
understanding yet suffer from hallucinations. With the aim of combining LLMs'
understanding capability with the logical and rigor of rule-based approaches,
we propose a novel framework consisting of a Subgraph Extractor, an LLM
Proposer, and a Rule Reasoner. The Subgraph Extractor first samples subgraphs
from the KB. Then, the LLM uses these subgraphs to propose diverse and
meaningful rules that are helpful for inferring missing facts. To effectively
avoid hallucination in LLMs' generations, these proposed rules are further
refined by a Rule Reasoner to pinpoint the most significant rules in the KB for
Knowledge Base Completion. Our approach offers several key benefits: the
utilization of LLMs to enhance the richness and diversity of the proposed rules
and the integration with rule-based reasoning to improve reliability. Our
method also demonstrates strong performance across diverse KB datasets,
highlighting the robustness and generalizability of the proposed framework.

摘要：將大型語言模型 (LLM) 與基於規則的推理整合，提供了一個強大的解決方案，用於提升知識庫完成 (KBC) 的彈性和可靠性。傳統的基於規則的 KBC 方法提供可驗證的推理，但缺乏彈性，而 LLM 提供強大的語義理解，但會產生幻覺。為了結合 LLM 的理解能力與基於規則方法的邏輯和嚴謹性，我們提出了一個創新的架構，包含一個子圖萃取器、一個 LLM 建議器和一個規則推理器。子圖萃取器首先從 KB 中取樣子圖。然後，LLM 使用這些子圖提出多樣且有意義的規則，有助於推論出遺失的事實。為了有效避免 LLM 生成中的幻覺，這些提出的規則會進一步由規則推理器提煉，以找出 KB 中對知識庫完成最重要的規則。我們的做法提供了幾個關鍵的好處：利用 LLM 來加強所提出規則的豐富性和多樣性，以及與基於規則的推理整合以提升可靠性。我們的做法也展現出在各種 KB 資料集中的強勁效能，突顯了所提出架構的穩健性和概括性。

##### **Face-Human-Bench: A Comprehensive Benchmark of Face and Human Understanding for Multi-modal Assistants**
2501.01243v1 by Lixiong Qin, Shilong Ou, Miaoxuan Zhang, Jiangning Wei, Yuhang Zhang, Xiaoshuai Song, Yuchen Liu, Mei Wang, Weiran Xu

Faces and humans are crucial elements in social interaction and are widely
included in everyday photos and videos. Therefore, a deep understanding of
faces and humans will enable multi-modal assistants to achieve improved
response quality and broadened application scope. Currently, the multi-modal
assistant community lacks a comprehensive and scientific evaluation of face and
human understanding abilities. In this paper, we first propose a hierarchical
ability taxonomy that includes three levels of abilities. Then, based on this
taxonomy, we collect images and annotations from publicly available datasets in
the face and human community and build a semi-automatic data pipeline to
produce problems for the new benchmark. Finally, the obtained Face-Human-Bench
comprises a development set with 900 problems and a test set with 1800
problems, supporting both English and Chinese. We conduct evaluations over 25
mainstream multi-modal large language models (MLLMs) with our Face-Human-Bench,
focusing on the correlation between abilities, the impact of the relative
position of targets on performance, and the impact of Chain of Thought (CoT)
prompting on performance. Moreover, inspired by multi-modal agents, we also
explore which abilities of MLLMs need to be supplemented by specialist models.

摘要：臉部和人類是社交互動中至關重要的元素，並廣泛包含在日常照片和影片中。因此，對臉部和人類的深入了解將使多模態助理能夠獲得更好的回應品質和更廣泛的應用範圍。目前，多模態助理社群缺乏對臉部和人類理解能力的全面且科學的評估。在本文中，我們首先提出一個分層能力分類法，其中包含三級能力。然後，基於此分類法，我們從人臉和人類社群中公開可用的資料集收集影像和註解，並建立一個半自動化資料管道，以產生新基準的問題。最後，獲得的 Face-Human-Bench 包含一個有 900 個問題的開發集和一個有 1800 個問題的測試集，同時支援英文和中文。我們使用我們的 Face-Human-Bench 對 25 個主流多模態大型語言模型 (MLLM) 進行評估，重點關注能力之間的關聯性、目標的相對位置對效能的影響，以及思考鏈 (CoT) 提示對效能的影響。此外，受到多模態代理的啟發，我們也探討了哪些 MLLM 的能力需要由專家模型補充。

##### **An Efficient Attention Mechanism for Sequential Recommendation Tasks: HydraRec**
2501.01242v1 by Uzma Mushtaque

Transformer based models are increasingly being used in various domains
including recommender systems (RS). Pretrained transformer models such as BERT
have shown good performance at language modelling. With the greater ability to
model sequential tasks, variants of Encoder-only models (like BERT4Rec, SASRec
etc.) have found success in sequential RS problems. Computing dot-product
attention in traditional transformer models has quadratic complexity in
sequence length. This is a bigger problem with RS because unlike language
models, new items are added to the catalogue every day. User buying history is
a dynamic sequence which depends on multiple factors. Recently, various linear
attention models have tried to solve this problem by making the model linear in
sequence length (token dimensions). Hydra attention is one such linear
complexity model proposed for vision transformers which reduces the complexity
of attention for both the number of tokens as well as model embedding
dimensions. Building on the idea of Hydra attention, we introduce an efficient
Transformer based Sequential RS (HydraRec) which significantly improves
theoretical complexity of computing attention for longer sequences and bigger
datasets while preserving the temporal context. Extensive experiments are
conducted to evaluate other linear transformer-based RS models and compared
with HydraRec across various evaluation metrics. HydraRec outperforms other
linear attention-based models as well as dot-product based attention models
when used with causal masking for sequential recommendation next item
prediction tasks. For bi-directional models its performance is comparable to
the BERT4Rec model with an improvement in running time.

摘要：<paragraph>基於 Transformer 的模型愈來愈多地用於各種領域，包括推薦系統 (RS)。預訓練的 Transformer 模型，例如 BERT，已在語言建模方面展現出良好的效能。隨著對序列任務建模能力的提升，僅編碼器模型的變體（例如 BERT4Rec、SASRec 等）已在序列 RS 問題中獲得成功。在傳統 Transformer 模型中計算點積注意力時，其序列長度具有二次複雜度。這對於 RS 來說是一個更大的問題，因為與語言模型不同，每天都會有新的項目新增到目錄中。使用者的購買記錄是一個動態序列，取決於多重因素。最近，各種線性注意力模型已嘗試通過使模型在序列長度（標記維度）中線性化來解決此問題。Hydra 注意力是一種針對視覺 Transformer 提出、具有此類線性複雜度的模型，它降低了對標記數量和模型嵌入維度的注意力的複雜度。基於 Hydra 注意力的概念，我們引入了一個高效的基於 Transformer 的序列 RS（HydraRec），它顯著改善了計算較長序列和較大資料集注意力的理論複雜度，同時保留了時間脈絡。我們進行了廣泛的實驗，以評估其他基於線性 Transformer 的 RS 模型，並在各種評估指標中將其與 HydraRec 進行了比較。在用於序列推薦下一個項目預測任務的因果遮罩時，HydraRec 優於其他基於線性注意力的模型以及基於點積的注意力模型。對於雙向模型，其效能可與 BERT4Rec 模型相媲美，同時縮短了執行時間。</paragraph>

##### **Automated Self-Refinement and Self-Correction for LLM-based Product Attribute Value Extraction**
2501.01237v1 by Alexander Brinkmann, Christian Bizer

Structured product data, in the form of attribute-value pairs, is essential
for e-commerce platforms to support features such as faceted product search and
attribute-based product comparison. However, vendors often provide unstructured
product descriptions, making attribute value extraction necessary to ensure
data consistency and usability. Large language models (LLMs) have demonstrated
their potential for product attribute value extraction in few-shot scenarios.
Recent research has shown that self-refinement techniques can improve the
performance of LLMs on tasks such as code generation and text-to-SQL
translation. For other tasks, the application of these techniques has resulted
in increased costs due to processing additional tokens, without achieving any
improvement in performance. This paper investigates applying two
self-refinement techniques, error-based prompt rewriting and self-correction,
to the product attribute value extraction task. The self-refinement techniques
are evaluated across zero-shot, few-shot in-context learning, and fine-tuning
scenarios using GPT-4o. The experiments show that both self-refinement
techniques have only a marginal impact on the model's performance across the
different scenarios, while significantly increasing processing costs. For
scenarios with training data, fine-tuning yields the highest performance, while
the ramp-up costs of fine-tuning are balanced out as the amount of product
descriptions increases.

摘要：結構化產品資料，以屬性值對的形式，對於電子商務平台支援多面向產品搜尋和基於屬性的產品比較等功能至關重要。然而，供應商通常提供非結構化的產品描述，這使得屬性值萃取對於確保資料一致性和可用性變得必要。大型語言模型 (LLM) 已展現出其在少量範例場景中進行產品屬性值萃取的潛力。最近的研究表明，自我精進技術可以提升 LLM 在程式碼產生和文字轉 SQL 翻譯等任務上的效能。對於其他任務，這些技術的應用會因處理額外的符號而導致成本增加，而並未提升效能。本文探討將兩種自我精進技術，即基於錯誤的提示重寫和自我修正，應用於產品屬性值萃取任務。自我精進技術在 GPT-4o 上使用零次學習、少量範例情境學習和微調情境進行評估。實驗顯示，兩種自我精進技術對於模型在不同情境下的效能只有邊際影響，同時大幅增加了處理成本。對於有訓練資料的情境，微調會產生最高的效能，而微調的啟動成本會隨著產品描述的數量增加而達到平衡。

##### **A redescription mining framework for post-hoc explaining and relating deep learning models**
2501.01209v1 by Matej Mihelčić, Ivan Grubišić, Miha Keber

Deep learning models (DLMs) achieve increasingly high performance both on
structured and unstructured data. They significantly extended applicability of
machine learning to various domains. Their success in making predictions,
detecting patterns and generating new data made significant impact on science
and industry. Despite these accomplishments, DLMs are difficult to explain
because of their enormous size. In this work, we propose a novel framework for
post-hoc explaining and relating DLMs using redescriptions. The framework
allows cohort analysis of arbitrary DLMs by identifying statistically
significant redescriptions of neuron activations. It allows coupling neurons to
a set of target labels or sets of descriptive attributes, relating layers
within a single DLM or associating different DLMs. The proposed framework is
independent of the artificial neural network architecture and can work with
more complex target labels (e.g. multi-label or multi-target scenario).
Additionally, it can emulate both pedagogical and decompositional approach to
rule extraction. The aforementioned properties of the proposed framework can
increase explainability and interpretability of arbitrary DLMs by providing
different information compared to existing explainable-AI approaches.

摘要：深度學習模型 (DLM) 在結構化和非結構化資料上都獲得越來越高的效能。它們顯著地將機器學習的應用範圍擴展到各種領域。它們在進行預測、偵測模式和產生新資料方面的成功，對科學和產業產生了重大的影響。儘管有這些成就，但 DLM 很難解釋，因為它們的規模龐大。在這項工作中，我們提出了一個新的架構，用於使用重新描述來事後解釋和關聯 DLM。該框架允許通過識別神經元激活的統計顯著重新描述，對任意 DLM 進行群體分析。它允許將神經元與一組目標標籤或一組描述性屬性相結合，關聯單個 DLM 中的層或關聯不同的 DLM。所提出的框架獨立於人工神經網路架構，並且可以處理更複雜的目標標籤（例如多標籤或多目標場景）。此外，它可以模擬教學和分解方法來進行規則提取。與現有的可解釋 AI 方法相比，所提出的框架的上述特性可以通過提供不同的資訊來提高任意 DLM 的可解釋性和可詮釋性。

##### **Harnessing Multi-Agent LLMs for Complex Engineering Problem-Solving: A Framework for Senior Design Projects**
2501.01205v1 by Abdullah Mushtaq, Muhammad Rafay Naeem, Ibrahim Ghaznavi, Muhammad Imran Taj, Imran Hashmi, Junaid Qadir

Multi-Agent Large Language Models (LLMs) are gaining significant attention
for their ability to harness collective intelligence in complex
problem-solving, decision-making, and planning tasks. This aligns with the
concept of the wisdom of crowds, where diverse agents contribute collectively
to generating effective solutions, making it particularly suitable for
educational settings. Senior design projects, also known as capstone or final
year projects, are pivotal in engineering education as they integrate
theoretical knowledge with practical application, fostering critical thinking,
teamwork, and real-world problem-solving skills. In this paper, we explore the
use of Multi-Agent LLMs in supporting these senior design projects undertaken
by engineering students, which often involve multidisciplinary considerations
and conflicting objectives, such as optimizing technical performance while
addressing ethical, social, and environmental concerns. We propose a framework
where distinct LLM agents represent different expert perspectives, such as
problem formulation agents, system complexity agents, societal and ethical
agents, or project managers, thus facilitating a holistic problem-solving
approach. This implementation leverages standard multi-agent system (MAS)
concepts such as coordination, cooperation, and negotiation, incorporating
prompt engineering to develop diverse personas for each agent. These agents
engage in rich, collaborative dialogues to simulate human engineering teams,
guided by principles from swarm AI to efficiently balance individual
contributions towards a unified solution. We adapt these techniques to create a
collaboration structure for LLM agents, encouraging interdisciplinary reasoning
and negotiation similar to real-world senior design projects. To assess the
efficacy of this framework, we collected six proposals of engineering and
computer science of...

摘要：多代理大型語言模型 (LLM) 因其在複雜問題解決、決策制定和規劃任務中利用集體智慧的能力而備受關注。這與集體智慧的概念相一致，其中不同的代理集體貢獻於產生有效的解決方案，使其特別適用於教育環境。高級設計專題，也稱為頂點或最後一年專題，在工程教育中至關重要，因為它們將理論知識與實際應用相結合，培養批判性思維、團隊合作和現實世界問題解決技能。在本文中，我們探討了多代理 LLM 在支持工程學生承擔的高級設計專題中的應用，這些專題通常涉及多學科考慮因素和相互衝突的目標，例如在解決道德、社會和環境問題的同時優化技術性能。我們提出了一個框架，其中不同的 LLM 代理代表不同的專家觀點，例如問題表述代理、系統複雜性代理、社會和道德代理或專案經理，從而促進全面的問題解決方法。此實作利用標準多代理系統 (MAS) 概念，例如協調、合作和協商，並結合提示工程來為每個代理開發不同的角色。這些代理參與豐富的協作對話，以模擬人類工程團隊，並遵循群體 AI 的原則，以有效平衡個人貢獻，朝向統一的解決方案。我們採用這些技術為 LLM 代理建立協作結構，鼓勵跨學科推理和協商，類似於現實世界的高級設計專題。為了評估此架構的效能，我們收集了六個工程和電腦科學的提案......

##### **Data Augmentation Techniques for Chinese Disease Name Normalization**
2501.01195v1 by Wenqian Cui, Xiangling Fu, Shaohui Liu, Mingjun Gu, Xien Liu, Ji Wu, Irwin King

Disease name normalization is an important task in the medical domain. It
classifies disease names written in various formats into standardized names,
serving as a fundamental component in smart healthcare systems for various
disease-related functions. Nevertheless, the most significant obstacle to
existing disease name normalization systems is the severe shortage of training
data. Consequently, we present a novel data augmentation approach that includes
a series of data augmentation techniques and some supporting modules to help
mitigate the problem. Through extensive experimentation, we illustrate that our
proposed approach exhibits significant performance improvements across various
baseline models and training objectives, particularly in scenarios with limited
training data

摘要：疾病名稱正規化是醫學領域中一項重要的任務。它將以各種格式書寫的疾病名稱分類為標準化名稱，作為智慧醫療系統中各種疾病相關功能的基本組成部分。然而，現有疾病名稱正規化系統最顯著的障礙是訓練資料嚴重短缺。因此，我們提出了一種新穎的資料擴充方法，其中包括一系列資料擴充技術和一些輔助模組，以幫助減輕這個問題。透過廣泛的實驗，我們說明我們提出的方法在各種基線模型和訓練目標中展現出顯著的效能提升，特別是在訓練資料有限的情況下

##### **Blind Men and the Elephant: Diverse Perspectives on Gender Stereotypes in Benchmark Datasets**
2501.01168v1 by Mahdi Zakizadeh, Mohammad Taher Pilehvar

The multifaceted challenge of accurately measuring gender stereotypical bias
in language models is akin to discerning different segments of a broader,
unseen entity. This short paper primarily focuses on intrinsic bias mitigation
and measurement strategies for language models, building on prior research that
demonstrates a lack of correlation between intrinsic and extrinsic approaches.
We delve deeper into intrinsic measurements, identifying inconsistencies and
suggesting that these benchmarks may reflect different facets of gender
stereotype. Our methodology involves analyzing data distributions across
datasets and integrating gender stereotype components informed by social
psychology. By adjusting the distribution of two datasets, we achieve a better
alignment of outcomes. Our findings underscore the complexity of gender
stereotyping in language models and point to new directions for developing more
refined techniques to detect and reduce bias.

摘要：準確衡量語言模型中的性別刻板印象偏見這項多面向的挑戰，就像辨識更廣泛、未見實體的不同區段。這篇簡短的論文主要關注語言模型的內在偏見減緩和衡量策略，建立在先前的研究基礎上，證明內在和外在方法之間缺乏相關性。我們更深入地探討內在衡量，找出不一致之處，並提出這些基準可能反映性別刻板印象的不同面向。我們的做法包括分析資料集中的資料分佈，並整合社會心理學所提供的性別刻板印象組成。透過調整兩個資料集的分佈，我們獲得更一致的結果。我們的發現強調語言模型中性別刻板印象的複雜性，並指出開發更精緻的技術以偵測和減少偏見的新方向。

##### **Leveraging Full Dependency Parsing Graph Information For Biomedical Event Extraction**
2501.01158v1 by Farshad Noravesh, Reza Haffari, Ong Huey Fang, Layki Soon, Sailaja Rajalana, Arghya Pal

Many models are proposed in the literature on biomedical event
extraction(BEE). Some of them use the shortest dependency path(SDP) information
to represent the argument classification task. There is an issue with this
representation since even missing one word from the dependency parsing graph
may totally change the final prediction. To this end, the full adjacency matrix
of the dependency graph is used to embed individual tokens using a graph
convolutional network(GCN). An ablation study is also done to show the effect
of the dependency graph on the overall performance. The results show a
significant improvement when dependency graph information is used. The proposed
model slightly outperforms state-of-the-art models on BEE over different
datasets.

摘要：許多模型在生物醫學事件萃取（BEE）文獻中被提出。其中一些使用最短依存路徑（SDP）資訊來表示論證分類任務。這個表示存在一個問題，因為即使從依存解析圖中遺漏一個字，也可能完全改變最終預測。為此，依存圖的完整鄰接矩陣用於使用圖形卷積網路（GCN）嵌入個別符號。還進行了一項消融研究，以顯示依存圖對整體效能的影響。結果顯示，當使用依存圖資訊時，有顯著的改善。所提出的模型在 BEE 上略勝過不同資料集上的最新模型。

##### **TexAVi: Generating Stereoscopic VR Video Clips from Text Descriptions**
2501.01156v1 by Vriksha Srihari, R. Bhavya, Shruti Jayaraman, V. Mary Anita Rajam

While generative models such as text-to-image, large language models and
text-to-video have seen significant progress, the extension to
text-to-virtual-reality remains largely unexplored, due to a deficit in
training data and the complexity of achieving realistic depth and motion in
virtual environments. This paper proposes an approach to coalesce existing
generative systems to form a stereoscopic virtual reality video from text.
  Carried out in three main stages, we start with a base text-to-image model
that captures context from an input text. We then employ Stable Diffusion on
the rudimentary image produced, to generate frames with enhanced realism and
overall quality. These frames are processed with depth estimation algorithms to
create left-eye and right-eye views, which are stitched side-by-side to create
an immersive viewing experience. Such systems would be highly beneficial in
virtual reality production, since filming and scene building often require
extensive hours of work and post-production effort.
  We utilize image evaluation techniques, specifically Fr\'echet Inception
Distance and CLIP Score, to assess the visual quality of frames produced for
the video. These quantitative measures establish the proficiency of the
proposed method.
  Our work highlights the exciting possibilities of using natural
language-driven graphics in fields like virtual reality simulations.

摘要：<paragraph>儘管生成模型（例如文字轉圖像、大型語言模型和文字轉影片）已取得顯著進展，但文字轉虛擬實境擴充仍未廣泛探索，原因在於訓練資料不足，以及在虛擬環境中實現逼真深度和動作的複雜性。本文提出了一種方法，將現有的生成系統合併，以從文字形成立體虛擬實境影片。
  分為三個主要階段進行，我們從基礎文字轉圖像模型開始，該模型會擷取輸入文字的內容。然後，我們在產生的基本圖像上使用 Stable Diffusion，以生成具有增強真實感和整體品質的畫面。這些畫面會使用深度估計演算法進行處理，以建立左眼和右眼的視圖，並將其並排縫合，以創造身歷其境的觀看體驗。此類系統在虛擬實境製作中將非常有益，因為拍攝和場景建置通常需要大量工時和後製工作。
  我們利用圖像評估技術，特別是 Fr\'echet Inception Distance 和 CLIP Score，來評估為影片產生的畫面的視覺品質。這些量化措施確立了所提出方法的熟練度。
  我們的研究突顯了在虛擬實境模擬等領域使用自然語言驅動圖形的令人興奮的可能性。</paragraph>

##### **A3: Android Agent Arena for Mobile GUI Agents**
2501.01149v1 by Yuxiang Chai, Hanhao Li, Jiayu Zhang, Liang Liu, Guozhi Wang, Shuai Ren, Siyuan Huang, Hongsheng Li

AI agents have become increasingly prevalent in recent years, driven by
significant advancements in the field of large language models (LLMs). Mobile
GUI agents, a subset of AI agents, are designed to autonomously perform tasks
on mobile devices. While numerous studies have introduced agents, datasets, and
benchmarks to advance mobile GUI agent research, many existing datasets focus
on static frame evaluations and fail to provide a comprehensive platform for
assessing performance on real-world, in-the-wild tasks. To address this gap, we
present Android Agent Arena (A3), a novel evaluation platform. Unlike existing
in-the-wild systems, A3 offers: (1) meaningful and practical tasks, such as
real-time online information retrieval and operational instructions; (2) a
larger, more flexible action space, enabling compatibility with agents trained
on any dataset; and (3) automated business-level LLM-based evaluation process.
A3 includes 21 widely used general third-party apps and 201 tasks
representative of common user scenarios, providing a robust foundation for
evaluating mobile GUI agents in real-world situations and a new autonomous
evaluation process for less human labor and coding expertise. The project is
available at \url{https://yuxiangchai.github.io/Android-Agent-Arena/}.

摘要：近年來，由於大型語言模型 (LLM) 領域的重大進展，AI 代理變得越來越普遍。行動 GUI 代理是 AI 代理的子集，旨在自動執行行動裝置上的任務。雖然許多研究已經引進代理、資料集和基準測試來推動行動 GUI 代理研究，但許多現有的資料集都專注於靜態框架評估，而且無法提供一個全面的平台來評估實際的野外任務效能。為了解決這個差距，我們提出 Android Agent Arena (A3)，一個新穎的評估平台。與現有的野外系統不同，A3 提供：(1) 有意義且實用的任務，例如即時線上資訊檢索和操作說明；(2) 一個更大、更靈活的動作空間，讓與在任何資料集上訓練的代理相容；以及 (3) 自動化業務層級 LLM 評估流程。A3 包含 21 個廣泛使用的通用第三方應用程式和 201 個代表常見使用者情境的任務，為評估實際情況下的行動 GUI 代理提供穩固的基礎，以及一個新的自動評估流程，以減少人力和編碼專業知識。該專案可在以下網址取得：\url{https://yuxiangchai.github.io/Android-Agent-Arena/}。

##### **BlockDialect: Block-wise Fine-grained Mixed Format for Energy-Efficient LLM Inference**
2501.01144v1 by Wonsuk Jang, Thierry Tambe

Large Language Models (LLMs) have achieved remarkable success, but their
increasing size poses significant challenges in memory usage and computational
costs. Quantizing both weights and activations can address these issues, with
fine-grained block-wise quantization emerging as a promising hardware-supported
solution to mitigate outliers. However, existing methods struggle to capture
nuanced block data distributions. To address this, we propose BlockDialect, a
block-wise fine-grained mixed format technique that assigns a per-block optimal
number format from formatbook for better data representation. Additionally, we
introduce DialectFP4, a formatbook of FP4 variants (akin to dialects) that
adapt to diverse data distributions. Importantly, DialectFP4 ensures hardware
efficiency by selecting representable values as scaled integers compatible with
low-precision integer arithmetic. Furthermore, we propose a two-stage approach
for online DialectFP4 activation quantization. BlockDialect achieves 11.40%
(6.90%) accuracy gain on the LLaMA3-8B (LLaMA2-7B) model compared to MXFP4
format with a comparable bit usage per data, while being only 5.89% (3.31%)
below full precision even when quantizing full-path matrix multiplication.
Focusing on how to represent over how to scale, our work presents a promising
path for energy-efficient LLM inference.

摘要：大型語言模型 (LLM) 已取得顯著的成功，但其日益增加的大小對記憶體使用和運算成本構成重大挑戰。量化權重和激活可以解決這些問題，其中以區塊為單位的精細量化作為一個有前途的硬體支援解決方案，以減輕異常值。然而，現有方法難以捕捉細微的區塊資料分佈。為了解決這個問題，我們提出了 BlockDialect，這是一種以區塊為單位的精細混合格式技術，它為每個區塊指定一個最佳數字格式，以獲得更好的資料表示。此外，我們引入了 DialectFP4，這是一個 FP4 變體（類似於方言）的格式手冊，可以適應不同的資料分佈。重要的是，DialectFP4 透過選擇可表示的值作為與低精度整數運算相容的縮放整數，確保硬體效率。此外，我們提出了一個用於線上 DialectFP4 激活量化的兩階段方法。與使用相同每資料位元的 MXFP4 格式相比，BlockDialect 在 LLaMA3-8B (LLaMA2-7B) 模型上獲得了 11.40% (6.90%) 的準確度提升，即使在量化全路徑矩陣乘法時，也僅比全精度低 5.89% (3.31%)。我們的研究專注於如何表示而不是如何縮放，為節能的 LLM 推論提供了一條有前景的途徑。

##### **Missing Data as Augmentation in the Earth Observation Domain: A Multi-View Learning Approach**
2501.01132v1 by Francisco Mena, Diego Arenas, Andreas Dengel

Multi-view learning (MVL) leverages multiple sources or views of data to
enhance machine learning model performance and robustness. This approach has
been successfully used in the Earth Observation (EO) domain, where views have a
heterogeneous nature and can be affected by missing data. Despite the negative
effect that missing data has on model predictions, the ML literature has used
it as an augmentation technique to improve model generalization, like masking
the input data. Inspired by this, we introduce novel methods for EO
applications tailored to MVL with missing views. Our methods integrate the
combination of a set to simulate all combinations of missing views as different
training samples. Instead of replacing missing data with a numerical value, we
use dynamic merge functions, like average, and more complex ones like
Transformer. This allows the MVL model to entirely ignore the missing views,
enhancing its predictive robustness. We experiment on four EO datasets with
temporal and static views, including state-of-the-art methods from the EO
domain. The results indicate that our methods improve model robustness under
conditions of moderate missingness, and improve the predictive performance when
all views are present. The proposed methods offer a single adaptive solution to
operate effectively with any combination of available views.

摘要：多視圖學習 (MVL) 透過利用多個來源或資料視圖來提升機器學習模型的效能和穩健性。此方法已成功用於地球觀測 (EO) 領域，其中視圖具有異質性，且可能會受到資料遺失的影響。儘管資料遺失對模型預測有負面影響，但 ML 文獻已將其用作擴充技術來改善模型概化，例如遮蔽輸入資料。受此啟發，我們針對 MVL 提出創新的方法，專門用於處理視圖遺失的 EO 應用。我們的整合方法結合一組設定，模擬所有遺失視圖組合，作為不同的訓練範例。我們不使用數值來取代遺失資料，而是使用動態合併函數，例如平均值，以及更複雜的函數，例如 Transformer。這讓 MVL 模型能完全忽略遺失視圖，進而提升其預測穩健性。我們針對四個 EO 資料集進行實驗，其中包含時間和靜態視圖，包括來自 EO 領域的最新方法。結果顯示，我們的模型在遺失程度適中的情況下能提升模型穩健性，並在所有視圖都存在時改善預測效能。所提出的方法提供單一的適應性解決方案，能有效處理任何組合的可用視圖。

##### **TED: Turn Emphasis with Dialogue Feature Attention for Emotion Recognition in Conversation**
2501.01123v1 by Junya Ono, Hiromi Wakaki

Emotion recognition in conversation (ERC) has been attracting attention by
methods for modeling multi-turn contexts. The multi-turn input to a pretraining
model implicitly assumes that the current turn and other turns are
distinguished during the training process by inserting special tokens into the
input sequence. This paper proposes a priority-based attention method to
distinguish each turn explicitly by adding dialogue features into the attention
mechanism, called Turn Emphasis with Dialogue (TED). It has a priority for each
turn according to turn position and speaker information as dialogue features.
It takes multi-head self-attention between turn-based vectors for multi-turn
input and adjusts attention scores with the dialogue features. We evaluate TED
on four typical benchmarks. The experimental results demonstrate that TED has
high overall performance in all datasets and achieves state-of-the-art
performance on IEMOCAP with numerous turns.

摘要：對話中的情緒辨識 (ERC) 已引起人們的注意，其方法是建構多輪次脈絡模型。多輪次輸入到預訓練模型中，隱含地假設在訓練過程中，透過在輸入序列中插入特殊代碼，可以區分目前的輪次和其它輪次。本文提出一個基於優先順序的注意方法，透過將對話特徵加入注意機制中，明確區分每個輪次，稱為對話輪次強調 (TED)。根據輪次位置和講話者資訊作為對話特徵，每個輪次都有其優先順序。它採用基於輪次的向量的多頭自我注意，作為多輪次輸入，並使用對話特徵調整注意分數。我們在四個典型的基準上評估 TED。實驗結果顯示，TED 在所有資料集上都有很高的整體表現，並在具有許多輪次的 IEMOCAP 上獲得最先進的表現。

##### **Pruning-based Data Selection and Network Fusion for Efficient Deep Learning**
2501.01118v1 by Humaira Kousar, Hasnain Irshad Bhatti, Jaekyun Moon

Efficient data selection is essential for improving the training efficiency
of deep neural networks and reducing the associated annotation costs. However,
traditional methods tend to be computationally expensive, limiting their
scalability and real-world applicability. We introduce PruneFuse, a novel
method that combines pruning and network fusion to enhance data selection and
accelerate network training. In PruneFuse, the original dense network is pruned
to generate a smaller surrogate model that efficiently selects the most
informative samples from the dataset. Once this iterative data selection
selects sufficient samples, the insights learned from the pruned model are
seamlessly integrated with the dense model through network fusion, providing an
optimized initialization that accelerates training. Extensive experimentation
on various datasets demonstrates that PruneFuse significantly reduces
computational costs for data selection, achieves better performance than
baselines, and accelerates the overall training process.

摘要：有效率的資料選擇對於提升深度神經網路的訓練效率和減少相關的註解成本至關重要。然而，傳統方法往往在運算上較為昂貴，限制了它們的可擴充性和實際應用性。我們引入了 PruneFuse，一種結合剪枝和網路融合的新方法，以增強資料選擇並加速網路訓練。在 PruneFuse 中，原始稠密網路會被剪枝以產生一個較小的代理模型，該模型可以有效率地從資料集中選擇最有資訊性的樣本。一旦這個反覆的資料選擇選擇了足夠的樣本，從剪枝模型中學到的見解便會透過網路融合無縫地整合到稠密模型中，提供一個最佳化的初始化，以加速訓練。在各種資料集上的廣泛實驗證明，PruneFuse 大幅降低了資料選擇的運算成本，達到了比基準更好的效能，並加速了整體訓練過程。

##### **Robust COVID-19 Detection from Cough Sounds using Deep Neural Decision Tree and Forest: A Comprehensive Cross-Datasets Evaluation**
2501.01117v1 by Rofiqul Islam, Nihad Karim Chowdhury, Muhammad Ashad Kabir

This research presents a robust approach to classifying COVID-19 cough sounds
using cutting-edge machine-learning techniques. Leveraging deep neural decision
trees and deep neural decision forests, our methodology demonstrates consistent
performance across diverse cough sound datasets. We begin with a comprehensive
extraction of features to capture a wide range of audio features from
individuals, whether COVID-19 positive or negative. To determine the most
important features, we use recursive feature elimination along with
cross-validation. Bayesian optimization fine-tunes hyper-parameters of deep
neural decision tree and deep neural decision forest models. Additionally, we
integrate the SMOTE during training to ensure a balanced representation of
positive and negative data. Model performance refinement is achieved through
threshold optimization, maximizing the ROC-AUC score. Our approach undergoes a
comprehensive evaluation in five datasets: Cambridge, Coswara, COUGHVID,
Virufy, and the combined Virufy with the NoCoCoDa dataset. Consistently
outperforming state-of-the-art methods, our proposed approach yields notable
AUC scores of 0.97, 0.98, 0.92, 0.93, 0.99, and 0.99 across the respective
datasets. Merging all datasets into a combined dataset, our method, using a
deep neural decision forest classifier, achieves an AUC of 0.97. Also, our
study includes a comprehensive cross-datasets analysis, revealing demographic
and geographic differences in the cough sounds associated with COVID-19. These
differences highlight the challenges in transferring learned features across
diverse datasets and underscore the potential benefits of dataset integration,
improving generalizability and enhancing COVID-19 detection from audio signals.

摘要：本研究提出了一個穩健的方法來分類 COVID-19 咳嗽聲，使用最先進的機器學習技術。利用深度神經決策樹和深度神經決策森林，我們的技術在不同的咳嗽聲數據集上表現出一致的性能。我們從全面提取特徵開始，以捕捉來自個人（無論是 COVID-19 陽性還是陰性）的廣泛音訊特徵。為了確定最重要的特徵，我們使用遞迴特徵消除和交叉驗證。貝葉斯優化微調深度神經決策樹和深度神經決策森林模型的超參數。此外，我們在訓練期間整合 SMOTE，以確保正負資料的平衡表示。模型效能的改進是透過閾值優化來實現的，最大化 ROC-AUC 分數。我們的做法在五個數據集：劍橋、Coswara、COUGHVID、Virufy 和 Virufy 與 NoCoCoDa 數據集的結合中進行了全面的評估。我們的建議方法持續優於最先進的方法，在各個數據集中產生了顯著的 AUC 分數，分別為 0.97、0.98、0.92、0.93、0.99 和 0.99。將所有數據集合併到一個合併的數據集後，我們的模型使用深度神經決策森林分類器，達到 0.97 的 AUC。此外，我們的研究包括一個全面的跨數據集分析，揭示了與 COVID-19 相關的咳嗽聲在人口統計和地理上的差異。這些差異突出了在不同的數據集之間轉移學習特徵的挑戰，並強調了數據集整合的潛在好處，改善了泛化性並增強了從音訊訊號中檢測 COVID-19 的能力。

##### **MalCL: Leveraging GAN-Based Generative Replay to Combat Catastrophic Forgetting in Malware Classification**
2501.01110v1 by Jimin Park, AHyun Ji, Minji Park, Mohammad Saidur Rahman, Se Eun Oh

Continual Learning (CL) for malware classification tackles the rapidly
evolving nature of malware threats and the frequent emergence of new types.
Generative Replay (GR)-based CL systems utilize a generative model to produce
synthetic versions of past data, which are then combined with new data to
retrain the primary model. Traditional machine learning techniques in this
domain often struggle with catastrophic forgetting, where a model's performance
on old data degrades over time.
  In this paper, we introduce a GR-based CL system that employs Generative
Adversarial Networks (GANs) with feature matching loss to generate high-quality
malware samples. Additionally, we implement innovative selection schemes for
replay samples based on the model's hidden representations.
  Our comprehensive evaluation across Windows and Android malware datasets in a
class-incremental learning scenario -- where new classes are introduced
continuously over multiple tasks -- demonstrates substantial performance
improvements over previous methods. For example, our system achieves an average
accuracy of 55% on Windows malware samples, significantly outperforming other
GR-based models by 28%. This study provides practical insights for advancing
GR-based malware classification systems. The implementation is available at
\url {https://github.com/MalwareReplayGAN/MalCL}\footnote{The code will be made
public upon the presentation of the paper}.

摘要：持續學習 (CL) 用於惡意軟體分類，應對惡意軟體威脅快速演變的本質和新類型的頻繁出現。基於生成式重播 (GR) 的 CL 系統利用生成式模型來產生過去資料的合成版本，然後將其與新資料結合以重新訓練主要模型。此領域的傳統機器學習技術通常會陷入災難性遺忘，其中模型對舊資料的效能會隨著時間推移而下降。
在本文中，我們介紹了一個基於 GR 的 CL 系統，該系統採用具有特徵匹配損失的生成式對抗網路 (GAN) 來產生高品質的惡意軟體範例。此外，我們實作創新的重播範例選擇方案，這些方案基於模型的隱藏表示。
我們在 Windows 和 Android 惡意軟體資料集中的全面評估，在類別遞增學習場景中（其中新類別會在多個任務中持續引入），證明了相較於先前的方法有顯著的效能提升。例如，我們的系統在 Windows 惡意軟體範例上達到了 55% 的平均準確度，顯著優於其他基於 GR 的模型 28%。這項研究提供了實用的見解，用於推進基於 GR 的惡意軟體分類系統。實作可在以下網址取得：\url {https://github.com/MalwareReplayGAN/MalCL}\footnote{程式碼將在論文發表後公開}。

##### **BatStyler: Advancing Multi-category Style Generation for Source-free Domain Generalization**
2501.01109v1 by Xiusheng Xu, Lei Qi, Jingyang Zhou, Xin Geng

Source-Free Domain Generalization (SFDG) aims to develop a model that
performs on unseen domains without relying on any source domains. However, the
implementation remains constrained due to the unavailability of training data.
Research on SFDG focus on knowledge transfer of multi-modal models and style
synthesis based on joint space of multiple modalities, thus eliminating the
dependency on source domain images. However, existing works primarily work for
multi-domain and less-category configuration, but performance on multi-domain
and multi-category configuration is relatively poor. In addition, the
efficiency of style synthesis also deteriorates in multi-category scenarios.
How to efficiently synthesize sufficiently diverse data and apply it to
multi-category configuration is a direction with greater practical value. In
this paper, we propose a method called BatStyler, which is utilized to improve
the capability of style synthesis in multi-category scenarios. BatStyler
consists of two modules: Coarse Semantic Generation and Uniform Style
Generation modules. The Coarse Semantic Generation module extracts
coarse-grained semantics to prevent the compression of space for style
diversity learning in multi-category configuration, while the Uniform Style
Generation module provides a template of styles that are uniformly distributed
in space and implements parallel training. Extensive experiments demonstrate
that our method exhibits comparable performance on less-category datasets,
while surpassing state-of-the-art methods on multi-category datasets.

摘要：無來源領域泛化 (SFDG) 旨在開發一個模型，在不依賴任何來源領域的情況下，對未見過的領域執行。然而，由於訓練資料的不可用性，實作仍受到限制。SFDG 的研究重點在於多模態模型的知識轉移和基於多模態聯合空間的樣式合成，從而消除了對來源領域影像的依賴性。然而，現有作品主要適用於多領域和較少類別的組態，但對多領域和多類別組態的效能相對較差。此外，在多類別場景中，樣式合成的效率也會下降。如何有效合成足夠多樣化的資料並將其應用於多類別組態是一個實用價值較高的方向。在本文中，我們提出了一種稱為 BatStyler 的方法，用於提升多類別場景中樣式合成的能力。BatStyler 包含兩個模組：粗略語義生成和統一樣式生成模組。粗略語義生成模組提取粗略語義，以防止在多類別組態中樣式多樣性學習的空間壓縮，而統一樣式生成模組提供了一個在空間中均勻分佈的樣式範本，並實作平行訓練。廣泛的實驗證明，我們的模型在較少類別的資料集上表現出可比較的效能，同時在多類別資料集上超越了最先進的方法。

##### **MuQ: Self-Supervised Music Representation Learning with Mel Residual Vector Quantization**
2501.01108v1 by Haina Zhu, Yizhi Zhou, Hangting Chen, Jianwei Yu, Ziyang Ma, Rongzhi Gu, Wei Tan, Xie Chen

Recent years have witnessed the success of foundation models pre-trained with
self-supervised learning (SSL) in various music informatics understanding
tasks, including music tagging, instrument classification, key detection, and
more. In this paper, we propose a self-supervised music representation learning
model for music understanding. Distinguished from previous studies adopting
random projection or existing neural codec, the proposed model, named MuQ, is
trained to predict tokens generated by Mel Residual Vector Quantization
(Mel-RVQ). Our Mel-RVQ utilizes residual linear projection structure for Mel
spectrum quantization to enhance the stability and efficiency of target
extraction and lead to better performance. Experiments in a large variety of
downstream tasks demonstrate that MuQ outperforms previous self-supervised
music representation models with only 0.9K hours of open-source pre-training
data. Scaling up the data to over 160K hours and adopting iterative training
consistently improve the model performance. To further validate the strength of
our model, we present MuQ-MuLan, a joint music-text embedding model based on
contrastive learning, which achieves state-of-the-art performance in the
zero-shot music tagging task on the MagnaTagATune dataset. Code and checkpoints
are open source in https://github.com/tencent-ailab/MuQ.

摘要：近年来，在各种音乐信息学理解任务中，利用自我监督学习 (SSL) 预训练的基础模型取得了成功，包括音乐标记、乐器分类、键检测等。在本文中，我们提出了一种用于音乐理解的自我监督音乐表征学习模型。与采用随机投影或现有神经编解码器的先前的研究不同，所提出的模型 MuQ 被训练为预测 Mel 残差矢量量化 (Mel-RVQ) 生成的标记。我们的 Mel-RVQ 利用残差线性投影结构对 Mel 谱进行量化，以增强目标提取的稳定性和效率，并带来更好的性能。在各种下游任务中的实验表明，MuQ 仅使用 0.9K 小时的开源预训练数据就优于先前的自我监督音乐表征模型。将数据扩展到超过 160K 小时并采用迭代训练可以持续提高模型性能。为了进一步验证我们模型的优势，我们提出了 MuQ-MuLan，这是一种基于对比学习的联合音乐文本嵌入模型，在 MagnaTagATune 数据集上的零样本音乐标记任务中实现了最先进的性能。代码和检查点在 https://github.com/tencent-ailab/MuQ 中开源。

##### **Disambiguation of Chinese Polyphones in an End-to-End Framework with Semantic Features Extracted by Pre-trained BERT**
2501.01102v1 by Dongyang Dai, Zhiyong Wu, Shiyin Kang, Xixin Wu, Jia Jia, Dan Su, Dong Yu, Helen Meng

Grapheme-to-phoneme (G2P) conversion serves as an essential component in
Chinese Mandarin text-to-speech (TTS) system, where polyphone disambiguation is
the core issue. In this paper, we propose an end-to-end framework to predict
the pronunciation of a polyphonic character, which accepts sentence containing
polyphonic character as input in the form of Chinese character sequence without
the necessity of any preprocessing. The proposed method consists of a
pre-trained bidirectional encoder representations from Transformers (BERT)
model and a neural network (NN) based classifier. The pre-trained BERT model
extracts semantic features from a raw Chinese character sequence and the NN
based classifier predicts the polyphonic character's pronunciation according to
BERT output. In out experiments, we implemented three classifiers, a
fully-connected network based classifier, a long short-term memory (LSTM)
network based classifier and a Transformer block based classifier. The
experimental results compared with the baseline approach based on LSTM
demonstrate that, the pre-trained model extracts effective semantic features,
which greatly enhances the performance of polyphone disambiguation. In
addition, we also explored the impact of contextual information on polyphone
disambiguation.

摘要：音素转换 (G2P) 是中文普通话文本到语音 (TTS) 系统中的一个重要组成部分，其中多音字消除歧义是核心问题。在本文中，我们提出一个端到端框架来预测多音字的发音，该框架接受包含多音字的句子作为输入，形式为中文汉字序列，无需任何预处理。所提出的方法由预训练的来自 Transformer 的双向编码器表示 (BERT) 模型和基于神经网络 (NN) 的分类器组成。预训练的 BERT 模型从原始中文汉字序列中提取语义特征，而基于 NN 的分类器根据 BERT 输出预测多音字的发音。在我们的实验中，我们实现了三个分类器，一个基于全连接网络的分类器，一个基于长短期记忆 (LSTM) 网络的分类器和一个基于 Transformer 块的分类器。与基于 LSTM 的基线方法相比，实验结果表明，预训练模型提取了有效的语义特征，极大地提高了消除多音字歧义的性能。此外，我们还探讨了上下文信息对消除多音字歧义的影响。

##### **Graph Generative Pre-trained Transformer**
2501.01073v1 by Xiaohui Chen, Yinkai Wang, Jiaxing He, Yuanqi Du, Soha Hassoun, Xiaolin Xu, Li-Ping Liu

Graph generation is a critical task in numerous domains, including molecular
design and social network analysis, due to its ability to model complex
relationships and structured data. While most modern graph generative models
utilize adjacency matrix representations, this work revisits an alternative
approach that represents graphs as sequences of node set and edge set. We
advocate for this approach due to its efficient encoding of graphs and propose
a novel representation. Based on this representation, we introduce the Graph
Generative Pre-trained Transformer (G2PT), an auto-regressive model that learns
graph structures via next-token prediction. To further exploit G2PT's
capabilities as a general-purpose foundation model, we explore fine-tuning
strategies for two downstream applications: goal-oriented generation and graph
property prediction. We conduct extensive experiments across multiple datasets.
Results indicate that G2PT achieves superior generative performance on both
generic graph and molecule datasets. Furthermore, G2PT exhibits strong
adaptability and versatility in downstream tasks from molecular design to
property prediction.

摘要：圖形生成在許多領域中是一項重要的任務，包括分子設計和社交網路分析，因為它能夠建模複雜的關係和結構化資料。雖然大多數現代圖形生成模型使用鄰接矩陣表示法，但本研究重新探討了另一種方法，將圖形表示為節點集和邊緣集的序列。我們提倡這種方法，因為它能有效編碼圖形，並提出一個新穎的表示法。基於此表示法，我們引入了圖形生成預訓練Transformer (G2PT)，這是一個自迴歸模型，透過下一個標記預測來學習圖形結構。為了進一步利用 G2PT 作為通用基礎模型的能力，我們探討了針對兩個下游應用程式進行微調的策略：目標導向生成和圖形屬性預測。我們在多個資料集上進行了廣泛的實驗。結果表明，G2PT 在通用圖形和分子資料集上都達到了優異的生成效能。此外，G2PT 在從分子設計到屬性預測的下游任務中展現出強大的適應性和多功能性。

##### **BeliN: A Novel Corpus for Bengali Religious News Headline Generation using Contextual Feature Fusion**
2501.01069v1 by Md Osama, Ashim Dey, Kawsar Ahmed, Muhammad Ashad Kabir

Automatic text summarization, particularly headline generation, remains a
critical yet underexplored area for Bengali religious news. Existing approaches
to headline generation typically rely solely on the article content,
overlooking crucial contextual features such as sentiment, category, and
aspect. This limitation significantly hinders their effectiveness and overall
performance. This study addresses this limitation by introducing a novel
corpus, BeliN (Bengali Religious News) - comprising religious news articles
from prominent Bangladeshi online newspapers, and MultiGen - a contextual
multi-input feature fusion headline generation approach. Leveraging
transformer-based pre-trained language models such as BanglaT5, mBART, mT5, and
mT0, MultiGen integrates additional contextual features - including category,
aspect, and sentiment - with the news content. This fusion enables the model to
capture critical contextual information often overlooked by traditional
methods. Experimental results demonstrate the superiority of MultiGen over the
baseline approach that uses only news content, achieving a BLEU score of 18.61
and ROUGE-L score of 24.19, compared to baseline approach scores of 16.08 and
23.08, respectively. These findings underscore the importance of incorporating
contextual features in headline generation for low-resource languages. By
bridging linguistic and cultural gaps, this research advances natural language
processing for Bengali and other underrepresented languages. To promote
reproducibility and further exploration, the dataset and implementation code
are publicly accessible at https://github.com/akabircs/BeliN.

摘要：自動文本摘要，特別是標題生成，仍然是孟加拉宗教新聞的一個關鍵但未被充分探索的領域。現有的標題生成方法通常僅依賴於文章內容，忽視了情緒、類別和方面等關鍵的上下文特徵。這種限制顯著地阻礙了它們的有效性和整體表現。本研究通過引入一個新的語料庫 BeliN（孟加拉宗教新聞）來解決這個限制，該語料庫包含來自孟加拉國著名網路報紙的宗教新聞文章，以及 MultiGen，一種基於上下文的、多輸入特徵融合標題生成方法。利用基於轉換器的預訓練語言模型，例如 BanglaT5、mBART、mT5 和 mT0，MultiGen 將其他上下文特徵（包括類別、方面和情緒）與新聞內容整合在一起。這種融合使模型能夠捕捉傳統方法經常忽視的關鍵上下文信息。實驗結果證明了 MultiGen 優於僅使用新聞內容的基線方法，實現了 18.61 的 BLEU 分數和 24.19 的 ROUGE-L 分數，而基線方法的分數分別為 16.08 和 23.08。這些發現強調了在低資源語言的標題生成中納入上下文特徵的重要性。通過彌合語言和文化鴻溝，這項研究推動了孟加拉語和其他代表性不足的語言的自然語言處理。為了促進可複製性和進一步探索，數據集和實現代碼可以在 https://github.com/akabircs/BeliN 公開訪問。

##### **Dynamic Attention-Guided Context Decoding for Mitigating Context Faithfulness Hallucinations in Large Language Models**
2501.01059v1 by Yanwen Huang, Yong Zhang, Ning Cheng, Zhitao Li, Shaojun Wang, Jing Xiao

Large language models (LLMs) often suffer from context faithfulness
hallucinations, where outputs deviate from retrieved information due to
insufficient context utilization and high output uncertainty. Our uncertainty
evaluation experiments reveal a strong correlation between high uncertainty and
hallucinations. We hypothesize that attention mechanisms encode signals
indicative of contextual utilization, validated through probing analysis. Based
on these insights, we propose Dynamic Attention-Guided Context Decoding
(DAGCD), a lightweight framework that integrates attention distributions and
uncertainty signals in a single-pass decoding process. Experiments across QA
datasets demonstrate DAGCD's effectiveness, achieving significant improvements
in faithfulness and robustness while maintaining computational efficiency.

摘要：大型語言模型 (LLM) 經常會出現語境忠實度幻覺，其中輸出會因為語境利用不足和高輸出不確定性而偏離擷取的資訊。我們的語境評估實驗揭露了高不確定性和幻覺之間的強相關性。我們假設注意力機制會編碼出指示語境利用的訊號，並透過探測分析得到驗證。根據這些見解，我們提出動態注意力引導語境解碼 (DAGCD)，這是一個輕量級框架，在單次通過解碼過程中整合注意力分佈和不確定性訊號。跨 QA 資料集的實驗顯示 DAGCD 的有效性，在維持運算效率的同時，在忠實度和穩健性方面獲得顯著的進步。

##### **Risks of Cultural Erasure in Large Language Models**
2501.01056v1 by Rida Qadri, Aida M. Davani, Kevin Robinson, Vinodkumar Prabhakaran

Large language models are increasingly being integrated into applications
that shape the production and discovery of societal knowledge such as search,
online education, and travel planning. As a result, language models will shape
how people learn about, perceive and interact with global cultures making it
important to consider whose knowledge systems and perspectives are represented
in models. Recognizing this importance, increasingly work in Machine Learning
and NLP has focused on evaluating gaps in global cultural representational
distribution within outputs. However, more work is needed on developing
benchmarks for cross-cultural impacts of language models that stem from a
nuanced sociologically-aware conceptualization of cultural impact or harm. We
join this line of work arguing for the need of metricizable evaluations of
language technologies that interrogate and account for historical power
inequities and differential impacts of representation on global cultures,
particularly for cultures already under-represented in the digital corpora. We
look at two concepts of erasure: omission: where cultures are not represented
at all and simplification i.e. when cultural complexity is erased by presenting
one-dimensional views of a rich culture. The former focuses on whether
something is represented, and the latter on how it is represented. We focus our
analysis on two task contexts with the potential to influence global cultural
production. First, we probe representations that a language model produces
about different places around the world when asked to describe these contexts.
Second, we analyze the cultures represented in the travel recommendations
produced by a set of language model applications. Our study shows ways in which
the NLP community and application developers can begin to operationalize
complex socio-cultural considerations into standard evaluations and benchmarks.

摘要：大型語言模型正越來越融入應用程式中，而這些應用程式形塑了社會知識的產生與發現，例如搜尋、線上教育和旅遊規劃。因此，語言模型將形塑人們如何學習、感知和與全球文化互動，這使得考量哪些知識系統和觀點在模型中獲得代表性變得十分重要。認識到這項重要性，機器學習和自然語言處理的相關工作越來越多地專注於評估輸出中全球文化表徵分佈的差距。然而，對於建立語言模型的跨文化影響基準，仍需要更多努力，而這些基準源自對文化影響或傷害的細緻社會學概念化。我們加入這條工作路線，主張需要對語言技術進行可度量評估，以質疑和說明歷史權力不平等以及表徵對全球文化產生不同的影響，尤其是對在數位語料庫中已經代表性不足的文化。我們探討了兩種抹除概念：遺漏：文化完全沒有獲得表徵，以及簡化，亦即透過呈現豐富文化的單一面向來抹除文化複雜性。前者著重於某事物是否獲得表徵，而後者著重於如何表徵。我們將分析重點放在兩個任務脈絡上，它們具有影響全球文化產出的潛力。首先，我們探究語言模型在被要求描述這些脈絡時，針對世界各地不同地點產生的表徵。其次，我們分析語言模型應用程式產生的旅遊建議中所表徵的文化。我們的研究顯示，自然語言處理社群和應用程式開發人員可以開始將複雜的社會文化考量納入標準評估和基準中，並使其具備可操作性。

##### **Dynamic Scaling of Unit Tests for Code Reward Modeling**
2501.01054v1 by Zeyao Ma, Xiaokang Zhang, Jing Zhang, Jifan Yu, Sijia Luo, Jie Tang

Current large language models (LLMs) often struggle to produce accurate
responses on the first attempt for complex reasoning tasks like code
generation. Prior research tackles this challenge by generating multiple
candidate solutions and validating them with LLM-generated unit tests. The
execution results of unit tests serve as reward signals to identify correct
solutions. As LLMs always confidently make mistakes, these unit tests are not
reliable, thereby diminishing the quality of reward signals. Motivated by the
observation that scaling the number of solutions improves LLM performance, we
explore the impact of scaling unit tests to enhance reward signal quality. Our
pioneer experiment reveals a positive correlation between the number of unit
tests and reward signal quality, with greater benefits observed in more
challenging problems. Based on these insights, we propose CodeRM-8B, a
lightweight yet effective unit test generator that enables efficient and
high-quality unit test scaling. Additionally, we implement a dynamic scaling
mechanism that adapts the number of unit tests based on problem difficulty,
further improving efficiency. Experimental results show that our approach
significantly improves performance across various models on three benchmarks
(e.g., with gains of 18.43% for Llama3-8B and 3.42% for GPT-4o-mini on
HumanEval Plus).

摘要：<paragraph>當前的巨量語言模型 (LLM) 在首次嘗試複雜的推理任務（例如程式碼生成）時，通常難以產生準確的回應。先前的研究透過產生多個候選解，並使用 LLM 生成的單元測試驗證它們來應對此挑戰。單元測試的執行結果用作獎勵訊號，以識別正確的解。由於 LLM 總是自信地犯錯，因此這些單元測試並不可靠，從而降低了獎勵訊號的品質。受到擴充解的數量會改善 LLM 效能的觀察所激勵，我們探討了擴充單元測試以提升獎勵訊號品質的影響。我們的先驅實驗揭示了單元測試數量與獎勵訊號品質之間的正相關，在更具挑戰性的問題中觀察到更大的好處。根據這些見解，我們提出了 CodeRM-8B，這是一個輕量級但有效的單元測試產生器，可實現高效且高品質的單元測試擴充。此外，我們實作了一個動態擴充機制，根據問題難度調整單元測試的數量，進一步提高效率。實驗結果顯示，我們的做法在三個基準上顯著提升了各種模型的效能（例如，在 HumanEval Plus 上，Llama3-8B 提升了 18.43%，GPT-4o-mini 提升了 3.42%）。</paragraph>

##### **FED: Fast and Efficient Dataset Deduplication Framework with GPU Acceleration**
2501.01046v1 by Youngjun Son, Chaewon Kim, Jaejin Lee

Dataset deduplication plays a crucial role in enhancing data quality,
ultimately improving training performance and efficiency of LLMs. A commonly
used method for data deduplication is the MinHash LSH algorithm. Recently,
NVIDIA introduced a GPU-based MinHash LSH deduplication method, but it remains
suboptimal, leaving room for further improvement in processing efficiency. This
paper proposes a GPU-accelerated deduplication framework \sys that optimizes
MinHash LSH for GPU clusters and leverages computationally efficient and
partially reusable non-cryptographic hash functions. \sys significantly
outperforms the CPU-based deduplication tool included in SlimPajama by up to
58.3 times and the GPU-based deduplication tool included in NVIDIA NeMo Curator
by up to 8.6 times when processing 1 million documents with a node of four
GPUs. Deduplication of 1.2 trillion tokens is completed in just 5.1 hours in a
four-node, 16-GPU environment. The related code is publicly available on GitHub
(https://github.com/mcrl/FED).

摘要：資料集重複資料刪除在提升資料品質上扮演關鍵角色，最終提升大型語言模型的訓練效能和效率。一種常見的資料重複資料刪除方法是 MinHash LSH 演算法。最近，NVIDIA 提出了一種基於 GPU 的 MinHash LSH 重複資料刪除方法，但它仍然不是最佳，在處理效率上還有進一步改進的空間。本文提出了一個 GPU 加速的重複資料刪除架構 \sys，它針對 GPU 叢集最佳化 MinHash LSH，並利用計算效率高且部分可重複使用的非加密雜湊函數。\sys 在處理 100 萬份文件時，效能顯著優於 SlimPajama 中包含的 CPU 基礎重複資料刪除工具，最多可達 58.3 倍，也優於 NVIDIA NeMo Curator 中包含的 GPU 基礎重複資料刪除工具，最多可達 8.6 倍，且使用一個節點的四個 GPU。在一個四節點、16 個 GPU 的環境中，僅在 5.1 小時內就完成了 1.2 兆個代幣的重複資料刪除。相關程式碼已公開在 GitHub (https://github.com/mcrl/FED) 上。

##### **MSWA: Refining Local Attention with Multi-ScaleWindow Attention**
2501.01039v1 by Yixing Xu, Shivank Nag, Dong Li, Lu Tian, Emad Barsoum

Transformer-based LLMs have achieved exceptional performance across a wide
range of NLP tasks. However, the standard self-attention mechanism suffers from
quadratic time complexity and linearly increased cache size. Sliding window
attention (SWA) solves this problem by restricting the attention range to a
fixed-size local context window. Nevertheless, SWA employs a uniform window
size for each head in each layer, making it inefficient in capturing context of
varying scales. To mitigate this limitation, we propose Multi-Scale Window
Attention (MSWA) which applies diverse window sizes across heads and layers in
the Transformer. It not only allows for different window sizes among heads
within the same layer but also progressively increases window size allocation
from shallow to deep layers, thus enabling the model to capture contextual
information with different lengths and distances. Experimental results on
language modeling and common-sense reasoning tasks substantiate that MSWA
outperforms traditional local attention in both effectiveness and efficiency.

摘要：基於 Transformer 的 LLM 在廣泛的 NLP 任務中已取得卓越的效能。然而，標準自我注意機制會產生二次時間複雜度和線性增加的快取大小。滑動視窗注意力 (SWA) 透過將注意力範圍限制在固定大小的局部內容視窗中來解決這個問題。儘管如此，SWA 在每一層的每個頭部都使用統一的視窗大小，這使得它在擷取不同規模的內容時效率不彰。為了減輕這個限制，我們提出多尺度視窗注意力 (MSWA)，它在 Transformer 中對頭部和層級套用不同的視窗大小。它不僅允許在同一層中的頭部之間使用不同的視窗大小，而且還逐步增加從淺層到深層的視窗大小配置，從而使模型能夠擷取具有不同長度和距離的內容資訊。在語言建模和常識推理任務上的實驗結果證實，MSWA 在有效性和效率方面都優於傳統的局部注意力。

##### **MSC-Bench: Benchmarking and Analyzing Multi-Sensor Corruption for Driving Perception**
2501.01037v1 by Xiaoshuai Hao, Guanqun Liu, Yuting Zhao, Yuheng Ji, Mengchuan Wei, Haimei Zhao, Lingdong Kong, Rong Yin, Yu Liu

Multi-sensor fusion models play a crucial role in autonomous driving
perception, particularly in tasks like 3D object detection and HD map
construction. These models provide essential and comprehensive static
environmental information for autonomous driving systems. While camera-LiDAR
fusion methods have shown promising results by integrating data from both
modalities, they often depend on complete sensor inputs. This reliance can lead
to low robustness and potential failures when sensors are corrupted or missing,
raising significant safety concerns. To tackle this challenge, we introduce the
Multi-Sensor Corruption Benchmark (MSC-Bench), the first comprehensive
benchmark aimed at evaluating the robustness of multi-sensor autonomous driving
perception models against various sensor corruptions. Our benchmark includes 16
combinations of corruption types that disrupt both camera and LiDAR inputs,
either individually or concurrently. Extensive evaluations of six 3D object
detection models and four HD map construction models reveal substantial
performance degradation under adverse weather conditions and sensor failures,
underscoring critical safety issues. The benchmark toolkit and affiliated code
and model checkpoints have been made publicly accessible.

摘要：多感測器融合模型在自動駕駛感知中扮演著至關重要的角色，特別是在 3D 物體偵測和 HD 地圖建構等任務中。這些模型為自動駕駛系統提供了必要且全面的靜態環境資訊。雖然相機-LiDAR 融合方法透過整合來自兩種方式的資料而展現出有前景的成果，但它們通常依賴於完整的感測器輸入。這種依賴性可能導致感測器損壞或遺失時的低健壯性和潛在故障，引發重大的安全問題。為了應對這個挑戰，我們引入了多感測器損壞基準 (MSC-Bench)，這是第一個旨在評估多感測器自動駕駛感知模型對各種感測器損壞的健壯性的綜合基準。我們的基準包括 16 種損壞類型的組合，這些損壞會破壞相機和 LiDAR 輸入，無論是單獨還是同時進行。對六個 3D 物體偵測模型和四個 HD 地圖建構模型的廣泛評估揭示了在惡劣天氣條件和感測器故障下的顯著效能下降，突顯了關鍵的安全問題。基準工具組和附屬程式碼與模型檢查點已公開提供。

##### **Advancing Singlish Understanding: Bridging the Gap with Datasets and Multimodal Models**
2501.01034v1 by Bin Wang, Xunlong Zou, Shuo Sun, Wenyu Zhang, Yingxu He, Zhuohan Liu, Chengwei Wei, Nancy F. Chen, AiTi Aw

Singlish, a Creole language rooted in English, is a key focus in linguistic
research within multilingual and multicultural contexts. However, its spoken
form remains underexplored, limiting insights into its linguistic structure and
applications. To address this gap, we standardize and annotate the largest
spoken Singlish corpus, introducing the Multitask National Speech Corpus
(MNSC). These datasets support diverse tasks, including Automatic Speech
Recognition (ASR), Spoken Question Answering (SQA), Spoken Dialogue
Summarization (SDS), and Paralinguistic Question Answering (PQA). We release
standardized splits and a human-verified test set to facilitate further
research. Additionally, we propose SingAudioLLM, a multi-task multimodal model
leveraging multimodal large language models to handle these tasks concurrently.
Experiments reveal our models adaptability to Singlish context, achieving
state-of-the-art performance and outperforming prior models by 10-30% in
comparison with other AudioLLMs and cascaded solutions.

摘要：Singlish，一種以英語為基礎的克里奧爾語，是多語言和多元文化背景下語言研究的重要重點。然而，它的口語形式仍然未被充分探索，這限制了對其語言結構和應用的見解。為了解決這個差距，我們標準化並註釋了最大的口語 Singlish 語料庫，並引入了多任務國家語音語料庫 (MNSC)。這些數據集支持多種任務，包括自動語音識別 (ASR)、口語問答 (SQA)、口語對話摘要 (SDS) 和副語言問題解答 (PQA)。我們發布了標準化的分割和人工驗證的測試集，以促進進一步的研究。此外，我們提出了 SingAudioLLM，這是一個多任務多模態模型，利用多模態大語言模型來同時處理這些任務。實驗表明，我們的模型適應 Singlish 語境的靈活性，實現了最先進的性能，並且在與其他 AudioLLM 和級聯解決方案進行比較時，其性能比之前的模型高出 10-30%。

##### **ValuesRAG: Enhancing Cultural Alignment Through Retrieval-Augmented Contextual Learning**
2501.01031v1 by Wonduk Seo, Zonghao Yuan, Yi Bu

Cultural values alignment in Large Language Models (LLMs) is a critical
challenge due to their tendency to embed Western-centric biases from training
data, leading to misrepresentations and fairness issues in cross-cultural
contexts. Recent approaches, such as role-assignment and few-shot learning,
often struggle with reliable cultural alignment as they heavily rely on
pre-trained knowledge, lack scalability, and fail to capture nuanced cultural
values effectively. To address these issues, we propose ValuesRAG, a novel and
effective framework that applies Retrieval-Augmented Generation (RAG) with
in-context learning to integrate cultural and demographic knowledge dynamically
during text generation. Leveraging the World Values Survey (WVS) dataset,
ValuesRAG first generates summaries of values for each individual.
Subsequently, we curated several representative regional datasets to serve as
test datasets and retrieve relevant summaries of values based on demographic
features, followed by a reranking step to select the top-k relevant summaries.
ValuesRAG consistently outperforms baseline methods, both in the main
experiment and in the ablation study where only the values summary was
provided, highlighting ValuesRAG's potential to foster culturally aligned AI
systems and enhance the inclusivity of AI-driven applications.

摘要：大型語言模型 (LLM) 中的文化價值觀一致性是一項嚴峻的挑戰，因為它們傾向於從訓練資料中嵌入以西方為中心的偏見，導致跨文化脈絡中的錯誤表述和公平性問題。最近的方法，例如角色分配和少次學習，通常難以實現可靠的文化一致性，因為它們嚴重依賴於預先訓練的知識，缺乏可擴充性，並且無法有效捕捉細微的文化價值觀。為了解決這些問題，我們提出了 ValuesRAG，這是一個新穎且有效的框架，它將檢索增強生成 (RAG) 與情境學習應用於在文本生成期間動態整合文化和人口統計知識。利用世界價值觀調查 (WVS) 資料集，ValuesRAG 首先為每個個體生成價值觀摘要。隨後，我們策劃了幾個具有代表性的區域資料集作為測試資料集，並根據人口統計特徵檢索相關的價值觀摘要，然後進行重新排序步驟以選擇前 k 個相關摘要。ValuesRAG 在主要實驗和僅提供價值觀摘要的消融研究中始終優於基準方法，這突顯了 ValuesRAG 促進文化一致的人工智慧系統和增強人工智慧驅動應用包容性的潛力。

##### **KaLM-Embedding: Superior Training Data Brings A Stronger Embedding Model**
2501.01028v1 by Xinshuo Hu, Zifei Shan, Xinping Zhao, Zetian Sun, Zhenyu Liu, Dongfang Li, Shaolin Ye, Xinyuan Wei, Qian Chen, Baotian Hu, Min Zhang

As retrieval-augmented generation prevails in large language models,
embedding models are becoming increasingly crucial. Despite the growing number
of general embedding models, prior work often overlooks the critical role of
training data quality. In this work, we introduce KaLM-Embedding, a general
multilingual embedding model that leverages a large quantity of cleaner, more
diverse, and domain-specific training data. Our model has been trained with key
techniques proven to enhance performance: (1) persona-based synthetic data to
create diversified examples distilled from LLMs, (2) ranking consistency
filtering to remove less informative samples, and (3) semi-homogeneous task
batch sampling to improve training efficacy. Departing from traditional
BERT-like architectures, we adopt Qwen2-0.5B as the pre-trained model,
facilitating the adaptation of auto-regressive language models for general
embedding tasks. Extensive evaluations of the MTEB benchmark across multiple
languages show that our model outperforms others of comparable size, setting a
new standard for multilingual embedding models with <1B parameters.

摘要：随着检索增强生成在大语言模型中盛行，嵌入模型变得越来越关键。尽管通用嵌入模型的数量不断增加，但先前的研究常常忽视训练数据质量的关键作用。在这项工作中，我们引入了 KaLM-Embedding，这是一种通用多语言嵌入模型，它利用了大量更干净、更多样化和特定于领域的训练数据。我们的模型已经过关键技术的培训，事实证明这些技术可以提高性能：(1) 基于角色的合成数据，用于创建从 LLM 中提取的多样化示例，(2) 排名一致性过滤，用于去除信息量较少的样本，以及 (3) 半同质任务批量采样，以提高训练效率。我们采用 Qwen2-0.5B 作为预训练模型，摆脱了传统的 BERT 类架构，促进了自回归语言模型对通用嵌入任务的适应。对多个语言的 MTEB 基准的广泛评估表明，我们的模型优于其他具有可比大小的模型，为具有 <1B 参数的多语言嵌入模型设定了新标准。

##### **Towards Adversarially Robust Deep Metric Learning**
2501.01025v1 by Xiaopeng Ke

Deep Metric Learning (DML) has shown remarkable successes in many domains by
taking advantage of powerful deep neural networks. Deep neural networks are
prone to adversarial attacks and could be easily fooled by adversarial
examples. The current progress on this robustness issue is mainly about deep
classification models but pays little attention to DML models. Existing works
fail to thoroughly inspect the robustness of DML and neglect an important DML
scenario, the clustering-based inference. In this work, we first point out the
robustness issue of DML models in clustering-based inference scenarios. We find
that, for the clustering-based inference, existing defenses designed DML are
unable to be reused and the adaptions of defenses designed for deep
classification models cannot achieve satisfactory robustness performance. To
alleviate the hazard of adversarial examples, we propose a new defense, the
Ensemble Adversarial Training (EAT), which exploits ensemble learning and
adversarial training. EAT promotes the diversity of the ensemble, encouraging
each model in the ensemble to have different robustness features, and employs a
self-transferring mechanism to make full use of the robustness statistics of
the whole ensemble in the update of every single model. We evaluate the EAT
method on three widely-used datasets with two popular model architectures. The
results show that the proposed EAT method greatly outperforms the adaptions of
defenses designed for deep classification models.

摘要：深度度量學習 (DML) 已在許多領域中展現出顯著的成功，藉由利用強大的深度神經網路。深度神經網路容易受到對抗性攻擊，且可能輕易地被對抗性範例所愚弄。目前關於此健全性問題的進度主要在於深度分類模型，但鮮少關注 DML 模型。現有作品未能徹底檢查 DML 的健全性，且忽略了一個重要的 DML 情境，即基於群集的推論。在這項工作中，我們首先指出 DML 模型在基於群集的推論情境中的健全性問題。我們發現，對於基於群集的推論，現有的防禦措施無法重複使用，而針對深度分類模型所設計的防禦措施的改編也無法達到令人滿意的健全性表現。為了減輕對抗性範例的危害，我們提出了一種新的防禦措施，即整體對抗訓練 (EAT)，它利用整體學習和對抗性訓練。EAT 促進整體的多樣性，鼓勵整體中的每個模型擁有不同的健全性特徵，並採用自轉移機制，在每個單一模型的更新中充分利用整體的健全性統計資料。我們在三個廣泛使用的資料集上，使用兩個流行的模型架構，評估 EAT 方法。結果顯示，所提出的 EAT 方法大幅優於針對深度分類模型所設計的防禦措施的改編。

##### **MDSF: Context-Aware Multi-Dimensional Data Storytelling Framework based on Large language Model**
2501.01014v1 by Chengze Zhang, Changshan Li, Shiyang Gao

The exponential growth of data and advancements in big data technologies have
created a demand for more efficient and automated approaches to data analysis
and storytelling. However, automated data analysis systems still face
challenges in leveraging large language models (LLMs) for data insight
discovery, augmented analysis, and data storytelling. This paper introduces the
Multidimensional Data Storytelling Framework (MDSF) based on large language
models for automated insight generation and context-aware storytelling. The
framework incorporates advanced preprocessing techniques, augmented analysis
algorithms, and a unique scoring mechanism to identify and prioritize
actionable insights. The use of fine-tuned LLMs enhances contextual
understanding and generates narratives with minimal manual intervention. The
architecture also includes an agent-based mechanism for real-time storytelling
continuation control. Key findings reveal that MDSF outperforms existing
methods across various datasets in terms of insight ranking accuracy,
descriptive quality, and narrative coherence. The experimental evaluation
demonstrates MDSF's ability to automate complex analytical tasks, reduce
interpretive biases, and improve user satisfaction. User studies further
underscore its practical utility in enhancing content structure, conclusion
extraction, and richness of detail.

摘要：隨著資料的指數成長與大數據技術的進步，對於更有效率且自動化的資料分析與說故事方法的需求也隨之而生。然而，自動化資料分析系統在利用大型語言模型 (LLM) 進行資料洞察發現、擴增分析和資料說故事時，仍面臨挑戰。本文介紹了基於大型語言模型的多維資料說故事架構 (MDSF)，用於自動洞察產生和情境感知說故事。此架構結合了先進的預處理技術、擴增分析演算法和獨特的計分機制，以識別和優先處理可操作的洞察。微調 LLM 的使用增強了脈絡理解，並在最少人工介入的情況下產生敘述。此架構還包括一個基於代理的機制，用於即時說故事的延續控制。主要發現顯示，MDSF 在洞察排名準確度、描述品質和敘事一致性方面，優於各種資料集中的現有方法。實驗評估證明了 MDSF 自動化複雜分析任務、減少詮釋偏差和提升使用者滿意度的能力。使用者研究進一步強調了其在增強內容結構、結論萃取和豐富細節方面的實用性。

##### **CryptoMamba: Leveraging State Space Models for Accurate Bitcoin Price Prediction**
2501.01010v1 by Mohammad Shahab Sepehri, Asal Mehradfar, Mahdi Soltanolkotabi, Salman Avestimehr

Predicting Bitcoin price remains a challenging problem due to the high
volatility and complex non-linear dynamics of cryptocurrency markets.
Traditional time-series models, such as ARIMA and GARCH, and recurrent neural
networks, like LSTMs, have been widely applied to this task but struggle to
capture the regime shifts and long-range dependencies inherent in the data. In
this work, we propose CryptoMamba, a novel Mamba-based State Space Model (SSM)
architecture designed to effectively capture long-range dependencies in
financial time-series data. Our experiments show that CryptoMamba not only
provides more accurate predictions but also offers enhanced generalizability
across different market conditions, surpassing the limitations of previous
models. Coupled with trading algorithms for real-world scenarios, CryptoMamba
demonstrates its practical utility by translating accurate forecasts into
financial outcomes. Our findings signal a huge advantage for SSMs in stock and
cryptocurrency price forecasting tasks.

摘要：由於加密貨幣市場的高波動性和複雜的非線性動態，預測比特幣價格仍然是一個具有挑戰性的問題。
傳統的時間序列模型，例如 ARIMA 和 GARCH，以及遞迴神經網路，例如 LSTM，已被廣泛應用於此任務，但難以捕捉資料中固有的政權轉移和長程依賴性。
在這項工作中，我們提出了 CryptoMamba，一種基於 Mamba 的新穎狀態空間模型 (SSM) 架構，旨在有效捕捉財務時間序列資料中的長程依賴性。我們的實驗表明，CryptoMamba 不僅提供了更準確的預測，還提供了跨不同市場條件的增強泛化能力，超越了先前模型的限制。結合用於實際場景的交易演算法，CryptoMamba 通過將準確的預測轉化為財務成果，展示了其實用性。我們的發現表明 SSM 在股票和加密貨幣價格預測任務中具有巨大的優勢。

##### **Deep Reinforcement Learning for Job Scheduling and Resource Management in Cloud Computing: An Algorithm-Level Review**
2501.01007v1 by Yan Gu, Zhaoze Liu, Shuhong Dai, Cong Liu, Ying Wang, Shen Wang, Georgios Theodoropoulos, Long Cheng

Cloud computing has revolutionized the provisioning of computing resources,
offering scalable, flexible, and on-demand services to meet the diverse
requirements of modern applications. At the heart of efficient cloud operations
are job scheduling and resource management, which are critical for optimizing
system performance and ensuring timely and cost-effective service delivery.
However, the dynamic and heterogeneous nature of cloud environments presents
significant challenges for these tasks, as workloads and resource availability
can fluctuate unpredictably. Traditional approaches, including heuristic and
meta-heuristic algorithms, often struggle to adapt to these real-time changes
due to their reliance on static models or predefined rules. Deep Reinforcement
Learning (DRL) has emerged as a promising solution to these challenges by
enabling systems to learn and adapt policies based on continuous observations
of the environment, facilitating intelligent and responsive decision-making.
This survey provides a comprehensive review of DRL-based algorithms for job
scheduling and resource management in cloud computing, analyzing their
methodologies, performance metrics, and practical applications. We also
highlight emerging trends and future research directions, offering valuable
insights into leveraging DRL to advance both job scheduling and resource
management in cloud computing.

摘要：雲端運算徹底改變了運算資源的供應方式，提供可擴充、彈性且依需求提供的服務，以滿足現代化應用程式的多元需求。在高效能雲端運作的核心是工作排程和資源管理，這對於最佳化系統效能，並確保及時且具成本效益的服務交付至關重要。然而，雲端環境的動態和異質特性對這些任務構成重大挑戰，因為工作負載和資源可用性可能會難以預測地波動。傳統方法，包括啟發式和元啟發式演算法，通常難以適應這些即時變更，因為它們依賴於靜態模型或預先定義的規則。深度強化學習 (DRL) 已成為解決這些挑戰的潛在解決方案，它讓系統能夠根據環境的持續觀察來學習和調整政策，促進智慧且靈敏的決策制定。本調查提供了基於 DRL 的工作排程和雲端運算資源管理演算法的全面回顧，分析其方法論、效能指標和實際應用。我們也重點介紹新興趨勢和未來的研究方向，提供寶貴的見解，以利用 DRL 來提升雲端運算中的工作排程和資源管理。

##### **FlashInfer: Efficient and Customizable Attention Engine for LLM Inference Serving**
2501.01005v1 by Zihao Ye, Lequn Chen, Ruihang Lai, Wuwei Lin, Yineng Zhang, Stephanie Wang, Tianqi Chen, Baris Kasikci, Vinod Grover, Arvind Krishnamurthy, Luis Ceze

Transformers, driven by attention mechanisms, form the foundation of large
language models (LLMs). As these models scale up, efficient GPU attention
kernels become essential for high-throughput and low-latency inference. Diverse
LLM applications demand flexible and high-performance attention solutions. We
present FlashInfer: a customizable and efficient attention engine for LLM
serving. FlashInfer tackles KV-cache storage heterogeneity using block-sparse
format and composable formats to optimize memory access and reduce redundancy.
It also offers a customizable attention template, enabling adaptation to
various settings through Just-In-Time (JIT) compilation. Additionally,
FlashInfer's load-balanced scheduling algorithm adjusts to dynamism of user
requests while maintaining compatibility with CUDAGraph which requires static
configuration. FlashInfer have been integrated into leading LLM serving
frameworks like SGLang, vLLM and MLC-Engine. Comprehensive kernel-level and
end-to-end evaluations demonstrate FlashInfer's ability to significantly boost
kernel performance across diverse inference scenarios: compared to
state-of-the-art LLM serving solutions, FlashInfer achieve 29-69%
inter-token-latency reduction compared to compiler backends for LLM serving
benchmark, 28-30% latency reduction for long-context inference, and 13-17%
speedup for LLM serving with parallel generation.

摘要：<paragraph>受注意力机制驱动的 Transformer 构成了大型语言模型 (LLM) 的基础。随着这些模型的扩展，高效的 GPU 注意力内核对于高吞吐量和低延迟推理变得至关重要。各种 LLM 应用程序需要灵活且高性能的注意力解决方案。我们展示了 FlashInfer：一个可定制且高效的注意力引擎，用于 LLM 服务。FlashInfer 使用块稀疏格式和可组合格式来解决 KV 缓存存储异构性，以优化内存访问并减少冗余。它还提供了一个可定制的注意力模板，通过即时 (JIT) 编译实现对各种设置的适应。此外，FlashInfer 的负载均衡调度算法可调整用户请求的动态性，同时保持与需要静态配置的 CUDAGraph 的兼容性。FlashInfer 已集成到领先的 LLM 服务框架中，如 SGLang、vLLM 和 MLC-Engine。全面的内核级和端到端评估证明了 FlashInfer 在各种推理场景中显着提升内核性能的能力：与最先进的 LLM 服务解决方案相比，FlashInfer 实现 29-69% 的令牌间延迟降低，与 LLM 服务基准的编译器后端相比，延迟降低 28-30%，长上下文推理延迟降低 13-17%，并加快 LLM 服务与并行生成的速度 13-17%。</paragraph>

##### **Exploring Information Processing in Large Language Models: Insights from Information Bottleneck Theory**
2501.00999v1 by Zhou Yang, Zhengyu Qi, Zhaochun Ren, Zhikai Jia, Haizhou Sun, Xiaofei Zhu, Xiangwen Liao

Large Language Models (LLMs) have demonstrated remarkable performance across
a wide range of tasks by understanding input information and predicting
corresponding outputs. However, the internal mechanisms by which LLMs
comprehend input and make effective predictions remain poorly understood. In
this paper, we explore the working mechanism of LLMs in information processing
from the perspective of Information Bottleneck Theory. We propose a
non-training construction strategy to define a task space and identify the
following key findings: (1) LLMs compress input information into specific task
spaces (e.g., sentiment space, topic space) to facilitate task understanding;
(2) they then extract and utilize relevant information from the task space at
critical moments to generate accurate predictions. Based on these insights, we
introduce two novel approaches: an Information Compression-based Context
Learning (IC-ICL) and a Task-Space-guided Fine-Tuning (TS-FT). IC-ICL enhances
reasoning performance and inference efficiency by compressing retrieved example
information into the task space. TS-FT employs a space-guided loss to fine-tune
LLMs, encouraging the learning of more effective compression and selection
mechanisms. Experiments across multiple datasets validate the effectiveness of
task space construction. Additionally, IC-ICL not only improves performance but
also accelerates inference speed by over 40\%, while TS-FT achieves superior
results with a minimal strategy adjustment.

摘要：大型語言模型 (LLM) 已在各種任務中展現出卓越的效能，透過了解輸入資訊和預測對應的輸出。然而，LLM 理解輸入和做出有效預測的內部機制仍未被充分理解。在本文中，我們從資訊瓶頸理論的角度探討 LLM 在資訊處理中的工作機制。我們提出一個非訓練建構策略來定義任務空間並找出以下關鍵發現：(1) LLM 將輸入資訊壓縮到特定的任務空間（例如，情緒空間、主題空間）以促進任務理解；(2) 它們接著在關鍵時刻從任務空間中萃取和利用相關資訊，以產生準確的預測。根據這些見解，我們介紹兩種新穎的方法：基於資訊壓縮的脈絡學習 (IC-ICL) 和任務空間引導的微調 (TS-FT)。IC-ICL 透過將擷取的範例資訊壓縮到任務空間中，增強推理效能和推論效率。TS-FT 使用空間引導損失對 LLM 進行微調，鼓勵學習更有效的壓縮和選擇機制。跨多個資料集的實驗驗證了任務空間建構的有效性。此外，IC-ICL 不僅提升效能，還將推論速度提升超過 40%，而 TS-FT 則透過最小的策略調整獲得卓越的結果。

##### **Are LLMs effective psychological assessors? Leveraging adaptive RAG for interpretable mental health screening through psychometric practice**
2501.00982v1 by Federico Ravenda, Seyed Ali Bahrainian, Andrea Raballo, Antonietta Mira, Noriko Kando

In psychological practice, standardized questionnaires serve as essential
tools for assessing mental constructs (e.g., attitudes, traits, and emotions)
through structured questions (aka items). With the increasing prevalence of
social media platforms where users share personal experiences and emotions,
researchers are exploring computational methods to leverage this data for rapid
mental health screening. In this study, we propose a novel adaptive
Retrieval-Augmented Generation (RAG) approach that completes psychological
questionnaires by analyzing social media posts. Our method retrieves the most
relevant user posts for each question in a psychological survey and uses Large
Language Models (LLMs) to predict questionnaire scores in a zero-shot setting.
Our findings are twofold. First we demonstrate that this approach can
effectively predict users' responses to psychological questionnaires, such as
the Beck Depression Inventory II (BDI-II), achieving performance comparable to
or surpassing state-of-the-art models on Reddit-based benchmark datasets
without relying on training data. Second, we show how this methodology can be
generalized as a scalable screening tool, as the final assessment is
systematically derived by completing standardized questionnaires and tracking
how individual item responses contribute to the diagnosis, aligning with
established psychometric practices.

摘要：<paragraph>在心理學實務中，標準化問卷作為評量心理建構（例如態度、特質和情緒）的必要工具，透過結構化問題（又稱項目）來進行評量。隨著社群媒體平台的普及，使用者會在上面分享個人經驗和情緒，研究人員正在探討運算方法，以利用這些資料進行快速的的心理健康篩檢。在這項研究中，我們提出了一種創新的適應性擷取增強生成（RAG）方法，透過分析社群媒體貼文來完成心理問卷。我們的做法是針對心理調查中的每個問題，擷取與之最相關的使用者貼文，並使用大型語言模型（LLM）在零次學習的設定下預測問卷分數。我們的發現有兩方面。首先，我們證明了這種方法可以有效預測使用者對心理問卷的回答，例如貝克憂鬱量表第二版（BDI-II），在基於 Reddit 的基準資料集上達到了與最先進模型相當或超越的表現，而且並未依賴訓練資料。其次，我們展示了這個方法如何能被概括為一種可擴充的篩檢工具，因為最終評量是透過完成標準化問卷並追蹤個別項目回答如何促成診斷而系統性地得出的，這與既定的心理測量實務相符。</paragraph>

##### **The Silent Majority: Demystifying Memorization Effect in the Presence of Spurious Correlations**
2501.00961v1 by Chenyu You, Haocheng Dai, Yifei Min, Jasjeet S. Sekhon, Sarang Joshi, James S. Duncan

Machine learning models often rely on simple spurious features -- patterns in
training data that correlate with targets but are not causally related to them,
like image backgrounds in foreground classification. This reliance typically
leads to imbalanced test performance across minority and majority groups. In
this work, we take a closer look at the fundamental cause of such imbalanced
performance through the lens of memorization, which refers to the ability to
predict accurately on \textit{atypical} examples (minority groups) in the
training set but failing in achieving the same accuracy in the testing set.
This paper systematically shows the ubiquitous existence of spurious features
in a small set of neurons within the network, providing the first-ever evidence
that memorization may contribute to imbalanced group performance. Through three
experimental sources of converging empirical evidence, we find the property of
a small subset of neurons or channels in memorizing minority group information.
Inspired by these findings, we articulate the hypothesis: the imbalanced group
performance is a byproduct of ``noisy'' spurious memorization confined to a
small set of neurons. To further substantiate this hypothesis, we show that
eliminating these unnecessary spurious memorization patterns via a novel
framework during training can significantly affect the model performance on
minority groups. Our experimental results across various architectures and
benchmarks offer new insights on how neural networks encode core and spurious
knowledge, laying the groundwork for future research in demystifying robustness
to spurious correlation.

摘要：機器學習模型通常依賴於簡單的虛假特徵 -- 訓練資料中的模式與目標相關，但與目標沒有因果關係，例如前景分類中的影像背景。這種依賴通常會導致少數和多數群體在測試效能上的不平衡。在這項工作中，我們透過記憶化的角度更仔細地檢視這種不平衡效能的基本原因，記憶化是指能夠準確預測訓練組中\textit{非典型}範例（少數群體），但在測試組中無法達到相同準確度的能力。這篇論文系統性地顯示出虛假特徵普遍存在於網路中的一小組神經元中，提供記憶化可能導致群組效能不平衡的首例證據。透過三個收斂實證證據的實驗來源，我們發現一小部分神經元或通道具有記憶少數群體資訊的特性。受到這些發現的啟發，我們提出假設：群組效能不平衡是侷限於一小組神經元的「雜訊」虛假記憶化的副產品。為了進一步證實這個假設，我們顯示在訓練期間透過一個新穎的架構消除這些不必要的虛假記憶化模式，可以顯著影響模型在少數群體上的效能。我們在各種架構和基準上的實驗結果，提供了神經網路如何編碼核心和虛假知識的新見解，為未來在破解對虛假相關性的穩健性方面奠定基礎。

##### **2.5 Years in Class: A Multimodal Textbook for Vision-Language Pretraining**
2501.00958v1 by Wenqi Zhang, Hang Zhang, Xin Li, Jiashuo Sun, Yongliang Shen, Weiming Lu, Deli Zhao, Yueting Zhuang, Lidong Bing

Compared to image-text pair data, interleaved corpora enable Vision-Language
Models (VLMs) to understand the world more naturally like humans. However, such
existing datasets are crawled from webpage, facing challenges like low
knowledge density, loose image-text relations, and poor logical coherence
between images. On the other hand, the internet hosts vast instructional videos
(e.g., online geometry courses) that are widely used by humans to learn
foundational subjects, yet these valuable resources remain underexplored in VLM
training. In this paper, we introduce a high-quality \textbf{multimodal
textbook} corpus with richer foundational knowledge for VLM pretraining. It
collects over 2.5 years of instructional videos, totaling 22,000 class hours.
We first use an LLM-proposed taxonomy to systematically gather instructional
videos. Then we progressively extract and refine visual (keyframes), audio
(ASR), and textual knowledge (OCR) from the videos, and organize as an
image-text interleaved corpus based on temporal order. Compared to its
counterparts, our video-centric textbook offers more coherent context, richer
knowledge, and better image-text alignment. Experiments demonstrate its superb
pretraining performance, particularly in knowledge- and reasoning-intensive
tasks like ScienceQA and MathVista. Moreover, VLMs pre-trained on our textbook
exhibit outstanding interleaved context awareness, leveraging visual and
textual cues in their few-shot context for task solving~\footnote{Our code are
available at \url{https://github.com/DAMO-NLP-SG/multimodal_textbook}}.

摘要：<paragraph>與影像文字配對資料相比，交錯語料庫能讓視覺語言模型 (VLM) 更像人類一樣自然地理解世界。然而，此類現有資料集是由網頁爬取而來，面臨知識密度低、影像文字關係鬆散，以及影像間邏輯連貫性差的挑戰。另一方面，網際網路上有大量教學影片（例如線上幾何課程），被廣泛用於人類學習基礎科目，但這些寶貴資源在 VLM 訓練中仍未被充分探索。在本文中，我們引入了具有豐富基礎知識的高品質**多模態教科書**語料庫，用於 VLM 預訓練。它收集了超過 2.5 年的教學影片，總計 22,000 小時的課程。我們首先使用 LLM 提出的分類法系統性地收集教學影片。然後，我們逐步從影片中萃取和精煉視覺（關鍵影格）、音訊（ASR）和文字知識（OCR），並根據時間順序組織成影像文字交錯語料庫。與其對應的教科書相比，我們以影片為中心的教科書提供了更連貫的脈絡、更豐富的知識，以及更好的影像文字對齊。實驗證明了它優異的預訓練效能，特別是在需要知識和推理的任務中，例如 ScienceQA 和 MathVista。此外，在我們的教科書上預訓練的 VLM 展現出傑出的交錯脈絡感知能力，在任務解決中運用視覺和文字提示進行少量次數的脈絡推論~\footnote{我們的程式碼可在 \url{https://github.com/DAMO-NLP-SG/multimodal_textbook} 取得}。</paragraph>

##### **Enhancing Early Diabetic Retinopathy Detection through Synthetic DR1 Image Generation: A StyleGAN3 Approach**
2501.00954v1 by Sagarnil Das, Pradeep Walia

Diabetic Retinopathy (DR) is a leading cause of preventable blindness. Early
detection at the DR1 stage is critical but is hindered by a scarcity of
high-quality fundus images. This study uses StyleGAN3 to generate synthetic DR1
images characterized by microaneurysms with high fidelity and diversity. The
aim is to address data scarcity and enhance the performance of supervised
classifiers. A dataset of 2,602 DR1 images was used to train the model,
followed by a comprehensive evaluation using quantitative metrics, including
Frechet Inception Distance (FID), Kernel Inception Distance (KID), and
Equivariance with respect to translation (EQ-T) and rotation (EQ-R).
Qualitative assessments included Human Turing tests, where trained
ophthalmologists evaluated the realism of synthetic images. Spectral analysis
further validated image quality. The model achieved a final FID score of 17.29,
outperforming the mean FID of 21.18 (95 percent confidence interval - 20.83 to
21.56) derived from bootstrap resampling. Human Turing tests demonstrated the
model's ability to produce highly realistic images, though minor artifacts near
the borders were noted. These findings suggest that StyleGAN3-generated
synthetic DR1 images hold significant promise for augmenting training datasets,
enabling more accurate early detection of Diabetic Retinopathy. This
methodology highlights the potential of synthetic data in advancing medical
imaging and AI-driven diagnostics.

摘要：糖尿病視網膜病變 (DR) 是可預防失明的主要原因。在 DR1 階段早期發現至關重要，但由於缺乏高品質眼底圖像而受到阻礙。本研究使用 StyleGAN3 生成合成 DR1 圖像，其特徵是具有高保真度和多樣性的微動脈瘤。目的是解決資料稀少的問題，並提升監督分類器的效能。使用 2,602 張 DR1 圖像的資料集來訓練模型，然後使用量化指標進行全面評估，包括 Fréchet Inception Distance (FID)、Kernel Inception Distance (KID) 以及相對於平移 (EQ-T) 和旋轉 (EQ-R) 的等變異性。定性評估包括人類圖靈測試，其中訓練有素的眼科醫生評估合成圖像的真實性。光譜分析進一步驗證了影像品質。該模型達到了 17.29 的最終 FID 分數，優於從 bootstrap 重抽樣得出的 21.18 的平均 FID（95% 信賴區間 - 20.83 到 21.56）。人類圖靈測試證明了該模型產生高度逼真圖像的能力，儘管注意到邊緣附近有輕微的人工製品。這些發現表明，StyleGAN3 生成的合成 DR1 圖像對於擴充訓練資料集具有顯著的希望，能夠更準確地早期發現糖尿病視網膜病變。這種方法突顯了合成資料在推進醫學影像和 AI 驅動診斷方面的潛力。

##### **Incremental Dialogue Management: Survey, Discussion, and Implications for HRI**
2501.00953v1 by Casey Kennington, Pierre Lison, David Schlangen

Efforts towards endowing robots with the ability to speak have benefited from
recent advancements in NLP, in particular large language models. However, as
powerful as current models have become, they still operate on sentence or
multi-sentence level input, not on the word-by-word input that humans operate
on, affecting the degree of responsiveness that they offer, which is critical
in situations where humans interact with robots using speech. In this paper, we
review the literature on interactive systems that operate incrementally (i.e.,
at the word level or below it). We motivate the need for incremental systems,
survey incremental modeling of important aspects of dialogue like speech
recognition and language generation. Primary focus is on the part of the system
that makes decisions, known as the dialogue manager. We find that there is very
little research on incremental dialogue management, offer some requirements for
practical incremental dialogue management, and the implications of incremental
dialogue for embodied, robotic platforms.

摘要：機器人賦予說話能力的努力受益於自然語言處理的最新進展，特別是大語言模型。然而，儘管當前模型已經變得強大，但它們仍然在句子或多句子層級的輸入上運作，而不是人類運作的逐字輸入，這影響了它們提供的響應程度，這在人類使用語音與機器人互動的情況中至關重要。在本文中，我們回顧了以增量方式運作的互動式系統（即在字詞層級或其以下）的文獻。我們激勵了對增量系統的需求，調查了對話重要面向的增量建模，例如語音辨識和語言產生。主要的重點在於系統中做出決策的部分，稱為對話管理員。我們發現對增量對話管理的研究非常少，提供了一些實用增量對話管理的要求，以及增量對話對具體機器人平台的影響。

##### **AutoPresent: Designing Structured Visuals from Scratch**
2501.00912v1 by Jiaxin Ge, Zora Zhiruo Wang, Xuhui Zhou, Yi-Hao Peng, Sanjay Subramanian, Qinyue Tan, Maarten Sap, Alane Suhr, Daniel Fried, Graham Neubig, Trevor Darrell

Designing structured visuals such as presentation slides is essential for
communicative needs, necessitating both content creation and visual planning
skills. In this work, we tackle the challenge of automated slide generation,
where models produce slide presentations from natural language (NL)
instructions. We first introduce the SlidesBench benchmark, the first benchmark
for slide generation with 7k training and 585 testing examples derived from 310
slide decks across 10 domains. SlidesBench supports evaluations that are
(i)reference-based to measure similarity to a target slide, and
(ii)reference-free to measure the design quality of generated slides alone. We
benchmark end-to-end image generation and program generation methods with a
variety of models, and find that programmatic methods produce higher-quality
slides in user-interactable formats. Built on the success of program
generation, we create AutoPresent, an 8B Llama-based model trained on 7k pairs
of instructions paired with code for slide generation, and achieve results
comparable to the closed-source model GPT-4o. We further explore iterative
design refinement where the model is tasked to self-refine its own output, and
we found that this process improves the slide's quality. We hope that our work
will provide a basis for future work on generating structured visuals.

摘要：設計結構化視覺效果（例如簡報投影片）對於溝通需求至關重要，這需要內容創作和視覺規劃技能。在這項工作中，我們應對自動化投影片產生的挑戰，其中模型會根據自然語言 (NL) 指示產生投影片簡報。我們首先介紹 SlidesBench 基準，這是投影片產生的第一個基準，有 7k 個訓練範例和 585 個測試範例，取自 10 個領域的 310 個投影片組。SlidesBench 支援評估，（i）以參考為基礎，測量與目標投影片的相似度，以及（ii）不以參考為基礎，單獨測量產生的投影片的設計品質。我們以各種模型對端到端影像產生和程式產生方法進行基準測試，並發現程式化方法會產生使用者可互動格式的高品質投影片。建立在程式產生成功的基礎上，我們建立了 AutoPresent，這是一個基於 8B Llama 的模型，針對 7k 對說明與投影片產生程式碼進行訓練，並取得與封閉原始碼模型 GPT-4o 相當的結果。我們進一步探討反覆設計改良，其中模型被賦予自行改良其輸出的任務，我們發現這個程序改善了投影片的品質。我們希望我們的工作將為未來產生結構化視覺效果的工作提供基礎。

##### **Population Aware Diffusion for Time Series Generation**
2501.00910v1 by Yang Li, Han Meng, Zhenyu Bi, Ingolv T. Urnes, Haipeng Chen

Diffusion models have shown promising ability in generating high-quality time
series (TS) data. Despite the initial success, existing works mostly focus on
the authenticity of data at the individual level, but pay less attention to
preserving the population-level properties on the entire dataset. Such
population-level properties include value distributions for each dimension and
distributions of certain functional dependencies (e.g., cross-correlation, CC)
between different dimensions. For instance, when generating house energy
consumption TS data, the value distributions of the outside temperature and the
kitchen temperature should be preserved, as well as the distribution of CC
between them. Preserving such TS population-level properties is critical in
maintaining the statistical insights of the datasets, mitigating model bias,
and augmenting downstream tasks like TS prediction. Yet, it is often overlooked
by existing models. Hence, data generated by existing models often bear
distribution shifts from the original data. We propose Population-aware
Diffusion for Time Series (PaD-TS), a new TS generation model that better
preserves the population-level properties. The key novelties of PaD-TS include
1) a new training method explicitly incorporating TS population-level property
preservation, and 2) a new dual-channel encoder model architecture that better
captures the TS data structure. Empirical results in major benchmark datasets
show that PaD-TS can improve the average CC distribution shift score between
real and synthetic data by 5.9x while maintaining a performance comparable to
state-of-the-art models on individual-level authenticity.

摘要：擴散模型已展現出產生高品質時間序列 (TS) 資料的潛力。儘管有初步的成功，現有作品大多關注資料在個別層級的真實性，但較少注意保留整個資料集的族群層級屬性。此類族群層級屬性包括每個維度的值分佈，以及不同維度之間特定函數依賴性（例如，互相關係，CC）的分佈。例如，在產生房屋能源消耗 TS 資料時，應保留外部溫度和廚房溫度的值分佈，以及它們之間的 CC 分佈。保留此類 TS 族群層級屬性對於維護資料集的統計見解、減輕模型偏差，以及擴充時間序列預測等下游任務至關重要。然而，現有模型常常忽略這一點。因此，現有模型產生的資料通常會與原始資料產生分佈轉移。我們提出適用於時間序列的族群感知擴散 (PaD-TS)，這是一種新的 TS 產生模型，可以更好地保留族群層級屬性。PaD-TS 的主要創新包括 1) 一種新的訓練方法，明確納入 TS 族群層級屬性保留，以及 2) 一種新的雙通道編碼器模型架構，可以更好地擷取 TS 資料結構。主要基準資料集中的經驗結果顯示，PaD-TS 可以將真實資料與合成資料之間的平均 CC 分佈轉移分數提高 5.9 倍，同時在個別層級真實性上維持與最先進模型相當的效能。

##### **U-GIFT: Uncertainty-Guided Firewall for Toxic Speech in Few-Shot Scenario**
2501.00907v1 by Jiaxin Song, Xinyu Wang, Yihao Wang, Yifan Tang, Ru Zhang, Jianyi Liu, Gongshen Liu

With the widespread use of social media, user-generated content has surged on
online platforms. When such content includes hateful, abusive, offensive, or
cyberbullying behavior, it is classified as toxic speech, posing a significant
threat to the online ecosystem's integrity and safety. While manual content
moderation is still prevalent, the overwhelming volume of content and the
psychological strain on human moderators underscore the need for automated
toxic speech detection. Previously proposed detection methods often rely on
large annotated datasets; however, acquiring such datasets is both costly and
challenging in practice. To address this issue, we propose an
uncertainty-guided firewall for toxic speech in few-shot scenarios, U-GIFT,
that utilizes self-training to enhance detection performance even when labeled
data is limited. Specifically, U-GIFT combines active learning with Bayesian
Neural Networks (BNNs) to automatically identify high-quality samples from
unlabeled data, prioritizing the selection of pseudo-labels with higher
confidence for training based on uncertainty estimates derived from model
predictions. Extensive experiments demonstrate that U-GIFT significantly
outperforms competitive baselines in few-shot detection scenarios. In the
5-shot setting, it achieves a 14.92\% performance improvement over the basic
model. Importantly, U-GIFT is user-friendly and adaptable to various
pre-trained language models (PLMs). It also exhibits robust performance in
scenarios with sample imbalance and cross-domain settings, while showcasing
strong generalization across various language applications. We believe that
U-GIFT provides an efficient solution for few-shot toxic speech detection,
offering substantial support for automated content moderation in cyberspace,
thereby acting as a firewall to promote advancements in cybersecurity.

摘要：<paragraph>隨著社群媒體的廣泛使用，使用者產生的內容在線上平台上激增。當此類內容包含仇恨、辱罵、攻擊或網路霸凌行為時，即被歸類為有毒言論，對線上生態系統的完整性和安全性構成重大威脅。儘管手動內容審核仍然普遍，但龐大的內容數量和人類審核員的心理壓力凸顯了自動化有毒言論偵測的必要性。先前提出的偵測方法通常依賴於大量標註資料集；然而，在實務上取得此類資料集既昂貴又具有挑戰性。為了解決這個問題，我們提出了一個在少樣本場景中用於有毒言論的不確定性引導防火牆 U-GIFT，它利用自訓練來增強偵測效能，即使在標籤資料有限的情況下也是如此。具體來說，U-GIFT 將主動學習與貝氏神經網路 (BNN) 結合，以自動從未標籤資料中識別出高品質樣本，根據從模型預測中衍生的不確定性估計，優先選擇具有較高信心的偽標籤進行訓練。廣泛的實驗證明，U-GIFT 在少樣本偵測場景中顯著優於競爭基準。在 5 個樣本的設定中，它比基本模型的效能提升了 14.92%。重要的是，U-GIFT 對使用者友善，且能適應各種預先訓練的語言模型 (PLM)。它在樣本不平衡和跨網域設定的場景中也展現出穩健的效能，同時在各種語言應用中展現出強大的泛化性。我們相信 U-GIFT 為少樣本有毒言論偵測提供了一個有效的解決方案，為網際網路空間中的自動化內容審核提供實質支援，進而作為防火牆來促進網路安全的進步。</paragraph>

##### **Large Language Model Based Multi-Agent System Augmented Complex Event Processing Pipeline for Internet of Multimedia Things**
2501.00906v1 by Talha Zeeshan, Abhishek Kumar, Susanna Pirttikangas, Sasu Tarkoma

This paper presents the development and evaluation of a Large Language Model
(LLM), also known as foundation models, based multi-agent system framework for
complex event processing (CEP) with a focus on video query processing use
cases. The primary goal is to create a proof-of-concept (POC) that integrates
state-of-the-art LLM orchestration frameworks with publish/subscribe (pub/sub)
tools to address the integration of LLMs with current CEP systems. Utilizing
the Autogen framework in conjunction with Kafka message brokers, the system
demonstrates an autonomous CEP pipeline capable of handling complex workflows.
Extensive experiments evaluate the system's performance across varying
configurations, complexities, and video resolutions, revealing the trade-offs
between functionality and latency. The results show that while higher agent
count and video complexities increase latency, the system maintains high
consistency in narrative coherence. This research builds upon and contributes
to, existing novel approaches to distributed AI systems, offering detailed
insights into integrating such systems into existing infrastructures.

摘要：本文介紹了一個大型語言模型 (LLM) 的開發和評估，也稱為基礎模型，基於多代理系統架構，用於複雜事件處理 (CEP)，重點放在影片查詢處理使用案例。主要目標是建立一個概念驗證 (POC)，將最先進的 LLM 編排架構與發布/訂閱 (pub/sub) 工具整合，以解決 LLM 與當前 CEP 系統的整合。利用 Autogen 框架與 Kafka 訊息代理一起，系統展示了一個自主 CEP 管道，能夠處理複雜的工作流程。廣泛的實驗評估了系統在不同配置、複雜性和影片解析度下的效能，揭示了功能和延遲之間的權衡。結果顯示，雖然代理數量和影片複雜度較高會增加延遲，但系統在敘事連貫性方面保持高度一致性。這項研究建立在現有的分布式 AI 系統新穎方法之上，並對其有所貢獻，提供將此類系統整合到現有基礎架構中的詳細見解。

##### **Unfolding the Headline: Iterative Self-Questioning for News Retrieval and Timeline Summarization**
2501.00888v1 by Weiqi Wu, Shen Huang, Yong Jiang, Pengjun Xie, Fei Huang, Hai Zhao

In the fast-changing realm of information, the capacity to construct coherent
timelines from extensive event-related content has become increasingly
significant and challenging. The complexity arises in aggregating related
documents to build a meaningful event graph around a central topic. This paper
proposes CHRONOS - Causal Headline Retrieval for Open-domain News Timeline
SummarizatiOn via Iterative Self-Questioning, which offers a fresh perspective
on the integration of Large Language Models (LLMs) to tackle the task of
Timeline Summarization (TLS). By iteratively reflecting on how events are
linked and posing new questions regarding a specific news topic to gather
information online or from an offline knowledge base, LLMs produce and refresh
chronological summaries based on documents retrieved in each round.
Furthermore, we curate Open-TLS, a novel dataset of timelines on recent news
topics authored by professional journalists to evaluate open-domain TLS where
information overload makes it impossible to find comprehensive relevant
documents from the web. Our experiments indicate that CHRONOS is not only adept
at open-domain timeline summarization, but it also rivals the performance of
existing state-of-the-art systems designed for closed-domain applications,
where a related news corpus is provided for summarization.

摘要：在資訊快速變遷的領域中，從大量的事件相關內容建構連貫的時間軸的能力變得越來越重要且具有挑戰性。複雜性在於彙總相關文件，以圍繞中心主題建立有意義的事件圖。本文提出了 CHRONOS - 開放領域新聞時間軸摘要的因果標題檢索，透過反覆自我提問，提供整合大型語言模型 (LLM) 來處理時間軸摘要 (TLS) 任務的新觀點。透過反覆思考事件如何連結，並對特定新聞主題提出新問題，以從線上或離線知識庫收集資訊，LLM 會根據每輪檢索的文件產生並更新時間摘要。此外，我們策劃了 Open-TLS，一個由專業記者編寫的近期新聞主題時間軸的新穎資料集，以評估開放領域的 TLS，其中資訊過載使得無法從網路上找到全面的相關文件。我們的實驗表明，CHRONOS 不僅擅長開放領域的時間軸摘要，而且還與專為封閉領域應用設計的現有最先進系統的效能相媲美，其中提供了相關的新聞語料庫用於摘要。

##### **Representation in large language models**
2501.00885v1 by Cameron C. Yetman

The extraordinary success of recent Large Language Models (LLMs) on a diverse
array of tasks has led to an explosion of scientific and philosophical
theorizing aimed at explaining how they do what they do. Unfortunately,
disagreement over fundamental theoretical issues has led to stalemate, with
entrenched camps of LLM optimists and pessimists often committed to very
different views of how these systems work. Overcoming stalemate requires
agreement on fundamental questions, and the goal of this paper is to address
one such question, namely: is LLM behavior driven partly by
representation-based information processing of the sort implicated in
biological cognition, or is it driven entirely by processes of memorization and
stochastic table look-up? This is a question about what kind of algorithm LLMs
implement, and the answer carries serious implications for higher level
questions about whether these systems have beliefs, intentions, concepts,
knowledge, and understanding. I argue that LLM behavior is partially driven by
representation-based information processing, and then I describe and defend a
series of practical techniques for investigating these representations and
developing explanations on their basis. The resulting account provides a
groundwork for future theorizing about language models and their successors.

摘要：最近的大型语言模型 (LLM) 在各种任务上取得了非凡的成功，这引发了科学和哲学理论的爆炸式增长，旨在解释它们如何发挥作用。不幸的是，对基本理论问题的分歧导致了僵局，LLM 乐观主义者和悲观主义者的根深蒂固的阵营经常对这些系统如何工作持有截然不同的看法。克服僵局需要就基本问题达成一致，本文的目标是解决这样一个问题，即：LLM 行为是否部分由涉及生物认知的基于表示的信息处理驱动，还是完全由记忆和随机查找表驱动？这是一个关于 LLM 实现哪种算法的问题，答案对关于这些系统是否有信念、意图、概念、知识和理解的高级问题具有严重影响。我认为 LLM 行为部分是由基于表示的信息处理驱动的，然后我描述并捍卫了一系列用于调查这些表示并在此基础上制定解释的实用技术。由此产生的解释为未来关于语言模型及其继任者的理论化提供了基础。

##### **TrustRAG: Enhancing Robustness and Trustworthiness in RAG**
2501.00879v1 by Huichi Zhou, Kin-Hei Lee, Zhonghao Zhan, Yue Chen, Zhenhao Li

Retrieval-Augmented Generation (RAG) systems enhance large language models
(LLMs) by integrating external knowledge sources, enabling more accurate and
contextually relevant responses tailored to user queries. However, these
systems remain vulnerable to corpus poisoning attacks that can significantly
degrade LLM performance through the injection of malicious content. To address
these challenges, we propose TrustRAG, a robust framework that systematically
filters compromised and irrelevant content before it reaches the language
model. Our approach implements a two-stage defense mechanism: first, it employs
K-means clustering to identify potential attack patterns in retrieved documents
based on their semantic embeddings, effectively isolating suspicious content.
Second, it leverages cosine similarity and ROUGE metrics to detect malicious
documents while resolving discrepancies between the model's internal knowledge
and external information through a self-assessment process. TrustRAG functions
as a plug-and-play, training-free module that integrates seamlessly with any
language model, whether open or closed-source, maintaining high contextual
relevance while strengthening defenses against attacks. Through extensive
experimental validation, we demonstrate that TrustRAG delivers substantial
improvements in retrieval accuracy, efficiency, and attack resistance compared
to existing approaches across multiple model architectures and datasets. We
have made TrustRAG available as open-source software at
\url{https://github.com/HuichiZhou/TrustRAG}.

摘要：檢索增強生成 (RAG) 系統透過整合外部知識來源來增強大型語言模型 (LLM)，進而提供更準確且與脈絡相關的回應，以針對使用者查詢量身打造。然而，這些系統仍然容易受到語料庫中毒攻擊，這種攻擊會透過注入惡意內容來大幅降低 LLM 效能。為了應對這些挑戰，我們提出 TrustRAG，這是一個強健的架構，可以在語言模型接收之前系統性地過濾受損且不相關的內容。我們的做法實作了一個兩階段防禦機制：首先，它採用 K 平均群集來辨識檢索文件中潛在的攻擊模式，依據它們的語義嵌入，有效地隔離可疑內容。其次，它利用餘弦相似度和 ROUGE 指標來偵測惡意文件，同時透過自我評估程序解決模型內部知識和外部資訊之間的差異。TrustRAG 的功能就像即插即用、免培訓的模組，可以與任何語言模型（不論是開放原始碼或閉源）無縫整合，同時維持高度的脈絡相關性，並加強對抗攻擊的防禦能力。透過廣泛的實驗驗證，我們證明 TrustRAG 在檢索準確度、效率和抗攻擊性方面，與多個模型架構和資料集上的現有方法相比，都有顯著的進步。我們已將 TrustRAG 以開放原始碼軟體的形式提供在 \url{https://github.com/HuichiZhou/TrustRAG}。

##### **LUSIFER: Language Universal Space Integration for Enhanced Multilingual Embeddings with Large Language Models**
2501.00874v1 by Hieu Man, Nghia Trung Ngo, Viet Dac Lai, Ryan A. Rossi, Franck Dernoncourt, Thien Huu Nguyen

Recent advancements in large language models (LLMs) based embedding models
have established new state-of-the-art benchmarks for text embedding tasks,
particularly in dense vector-based retrieval. However, these models
predominantly focus on English, leaving multilingual embedding capabilities
largely unexplored. To address this limitation, we present LUSIFER, a novel
zero-shot approach that adapts LLM-based embedding models for multilingual
tasks without requiring multilingual supervision. LUSIFER's architecture
combines a multilingual encoder, serving as a language-universal learner, with
an LLM-based embedding model optimized for embedding-specific tasks. These
components are seamlessly integrated through a minimal set of trainable
parameters that act as a connector, effectively transferring the multilingual
encoder's language understanding capabilities to the specialized embedding
model. Additionally, to comprehensively evaluate multilingual embedding
performance, we introduce a new benchmark encompassing 5 primary embedding
tasks, 123 diverse datasets, and coverage across 14 languages. Extensive
experimental results demonstrate that LUSIFER significantly enhances the
multilingual performance across various embedding tasks, particularly for
medium and low-resource languages, without requiring explicit multilingual
training data.

摘要：大型語言模型（LLM）的最新進展建立了基於嵌入模型的文本嵌入任務的新技術基準，特別是在基於稠密向量的檢索中。然而，這些模型主要關注英語，而多語言嵌入功能在很大程度上尚未得到探索。為了解決這個限制，我們提出了 LUSIFER，這是一種新穎的零次學習方法，它可以將基於 LLM 的嵌入模型適應到多語言任務，而不需要多語言監督。LUSIFER 的架構結合了一個多語言編碼器（作為一個語言通用學習器），以及一個針對特定嵌入任務進行優化的基於 LLM 的嵌入模型。這些組件通過一組最小的可訓練參數無縫集成，這些參數充當連接器，有效地將多語言編碼器的語言理解能力傳遞給專門的嵌入模型。此外，為了全面評估多語言嵌入性能，我們引入了一個新的基準，包括 5 個主要的嵌入任務、123 個不同的數據集，以及涵蓋 14 種語言。大量的實驗結果表明，LUSIFER 顯著增強了各種嵌入任務的多語言性能，特別是對於中低資源語言，而不需要明確的多語言訓練數據。

##### **Large Language Models Are Read/Write Policy-Makers for Simultaneous Generation**
2501.00868v1 by Shoutao Guo, Shaolei Zhang, Zhengrui Ma, Yang Feng

Simultaneous generation models write generation results while reading
streaming inputs, necessitating a policy-maker to determine the appropriate
output timing. Existing simultaneous generation methods generally adopt the
traditional encoder-decoder architecture and learn the generation and
policy-making capabilities through complex dynamic programming techniques.
Although LLMs excel at text generation, they face challenges in taking on the
role of policy-makers through traditional training methods, limiting their
exploration in simultaneous generation. To overcome these limitations, we
propose a novel LLM-driven Simultaneous Generation (LSG) framework, which
allows the off-the-shelf LLM to decide the generation timing and produce output
concurrently. Specifically, LSG selects the generation policy that minimizes
latency as the baseline policy. Referring to the baseline policy, LSG enables
the LLM to devise an improved generation policy that better balances latency
and generation quality, and writes generation results accordingly. Experiments
on simultaneous translation and streaming automatic speech recognition tasks
show that our method can achieve state-of-the-art performance utilizing the
open-source LLMs and demonstrate practicality in real-world scenarios.

摘要：同步生成模型在讀取串流輸入時撰寫生成結果，需要一位策略制定者來決定適當的輸出時間。現有的同步生成方法通常採用傳統編碼器解碼器架構，並透過複雜的動態規劃技術來學習生成和策略制定能力。儘管大型語言模型 (LLM) 擅長文字生成，但它們在透過傳統訓練方法擔任策略制定者的角色時面臨挑戰，這限制了它們在同步生成中的探索。為了克服這些限制，我們提出一個新穎的 LLM 驅動同步生成 (LSG) 架構，它允許現成的 LLM 決定生成時間並同時產生輸出。具體來說，LSG 選擇將延遲最小化的生成策略作為基準策略。參照基準策略，LSG 能讓 LLM 設計出一個改進的生成策略，以更好地平衡延遲和生成品質，並相應地撰寫生成結果。在同步翻譯和串流自動語音辨識任務上的實驗顯示，我們的方法可以使用開源 LLM 達到最先進的效能，並證明在實際場景中的實用性。

##### **Negative to Positive Co-learning with Aggressive Modality Dropout**
2501.00865v1 by Nicholas Magal, Minh Tran, Riku Arakawa, Suzanne Nie

This paper aims to document an effective way to improve multimodal
co-learning by using aggressive modality dropout. We find that by using
aggressive modality dropout we are able to reverse negative co-learning (NCL)
to positive co-learning (PCL). Aggressive modality dropout can be used to
"prep" a multimodal model for unimodal deployment, and dramatically increases
model performance during negative co-learning, where during some experiments we
saw a 20% gain in accuracy. We also benchmark our modality dropout technique
against PCL to show that our modality drop out technique improves co-learning
during PCL, although it does not have as much as an substantial effect as it
does during NCL. Github: https://github.com/nmagal/modality_drop_for_colearning

摘要：本文旨在记录一种通过使用激进模态 dropout 来改善多模态协同学习的有效方法。我们发现，通过使用激进模态 dropout，我们能够将负协同学习 (NCL) 逆转为正协同学习 (PCL)。激进模态 dropout 可用于“准备”多模态模型进行单模态部署，并显著提高模型在负协同学习期间的性能，在某些实验中，我们观察到准确度提高了 20%。我们还将我们的模态 dropout 技术与 PCL 进行基准测试，以表明我们的模态 dropout 技术改善了 PCL 期间的协同学习，尽管它不像在 NCL 期间那样具有实质性影响。Github：https://github.com/nmagal/modality_drop_for_colearning

##### **DiffETM: Diffusion Process Enhanced Embedded Topic Model**
2501.00862v1 by Wei Shao, Mingyang Liu, Linqi Song

The embedded topic model (ETM) is a widely used approach that assumes the
sampled document-topic distribution conforms to the logistic normal
distribution for easier optimization. However, this assumption oversimplifies
the real document-topic distribution, limiting the model's performance. In
response, we propose a novel method that introduces the diffusion process into
the sampling process of document-topic distribution to overcome this limitation
and maintain an easy optimization process. We validate our method through
extensive experiments on two mainstream datasets, proving its effectiveness in
improving topic modeling performance.

摘要：嵌入式主题模型 (ETM) 是一种广泛使用的方法，该方法假设采样的文档主题分布符合逻辑正态分布，以便更轻松地进行优化。然而，此假设过度简化了真实的文档主题分布，从而限制了模型的性能。对此，我们提出了一种新方法，将扩散过程引入文档主题分布的采样过程中，以克服此限制并维持一个简单的优化过程。我们通过对两个主流数据集进行广泛的实验验证了我们的方法，证明了其在提高主题建模性能方面的有效性。

##### **LLM+AL: Bridging Large Language Models and Action Languages for Complex Reasoning about Actions**
2501.00830v1 by Adam Ishay, Joohyung Lee

Large Language Models (LLMs) have made significant strides in various
intelligent tasks but still struggle with complex action reasoning tasks that
require systematic search. To address this limitation, we propose a method that
bridges the natural language understanding capabilities of LLMs with the
symbolic reasoning strengths of action languages. Our approach, termed
"LLM+AL," leverages the LLM's strengths in semantic parsing and commonsense
knowledge generation alongside the action language's proficiency in automated
reasoning based on encoded knowledge. We compare LLM+AL against
state-of-the-art LLMs, including ChatGPT-4, Claude 3 Opus, Gemini Ultra 1.0,
and o1-preview, using benchmarks for complex reasoning about actions. Our
findings indicate that, although all methods exhibit errors, LLM+AL, with
relatively minimal human corrections, consistently leads to correct answers,
whereas standalone LLMs fail to improve even with human feedback. LLM+AL also
contributes to automated generation of action languages.

摘要：大型語言模型 (LLM) 在各種智能任務上取得顯著進展，但仍難以應付需要系統性搜尋的複雜動作推理任務。為了解決這個限制，我們提出了一種方法，將 LLM 的自然語言理解能力與動作語言的符號推理優勢結合起來。我們的做法稱為「LLM+AL」，它利用 LLM 在語義解析和常識知識生成方面的優勢，以及動作語言在基於編碼知識的自動推理方面的能力。我們使用複雜動作推理基準，將 LLM+AL 與最先進的 LLM（包括 ChatGPT-4、Claude 3 Opus、Gemini Ultra 1.0 和 o1-preview）進行比較。我們的研究結果表明，儘管所有方法都會出現錯誤，但 LLM+AL 在相對最少的修正下，始終能得出正確答案，而獨立的 LLM 即使在有人類回饋的情況下也無法改善。LLM+AL 也能協助自動生成動作語言。

##### **An LLM-Empowered Adaptive Evolutionary Algorithm For Multi-Component Deep Learning Systems**
2501.00829v1 by Haoxiang Tian, Xingshuo Han, Guoquan Wu, An Guo, Yuan Zhou. Jie Zhang, Shuo Li, Jun Wei, Tianwei Zhang

Multi-objective evolutionary algorithms (MOEAs) are widely used for searching
optimal solutions in complex multi-component applications. Traditional MOEAs
for multi-component deep learning (MCDL) systems face challenges in enhancing
the search efficiency while maintaining the diversity. To combat these, this
paper proposes $\mu$MOEA, the first LLM-empowered adaptive evolutionary search
algorithm to detect safety violations in MCDL systems. Inspired by the
context-understanding ability of Large Language Models (LLMs), $\mu$MOEA
promotes the LLM to comprehend the optimization problem and generate an initial
population tailed to evolutionary objectives. Subsequently, it employs adaptive
selection and variation to iteratively produce offspring, balancing the
evolutionary efficiency and diversity. During the evolutionary process, to
navigate away from the local optima, $\mu$MOEA integrates the evolutionary
experience back into the LLM. This utilization harnesses the LLM's quantitative
reasoning prowess to generate differential seeds, breaking away from current
optimal solutions. We evaluate $\mu$MOEA in finding safety violations of MCDL
systems, and compare its performance with state-of-the-art MOEA methods.
Experimental results show that $\mu$MOEA can significantly improve the
efficiency and diversity of the evolutionary search.

摘要：多目標演化算法 (MOEA) 廣泛用於在複雜的多元件應用程式中搜尋最佳解。傳統的 MOEA 在多組成深度學習 (MCDL) 系統中面臨在維持多樣性的同時提升搜尋效率的挑戰。為了應對這些挑戰，本文提出 $\mu$MOEA，這是一個首個由大型語言模型 (LLM) 賦能的自適應演化搜尋演算法，用於偵測 MCDL 系統中的安全漏洞。在大型語言模型 (LLM) 的語境理解能力的啟發下，$\mu$MOEA 促進 LLM 理解最佳化問題，並產生一個針對演化目標的初始族群。隨後，它採用自適應選擇和變異來反覆產生後代，平衡演化效率和多樣性。在演化過程中，為了避開局部最佳化，$\mu$MOEA 將演化經驗整合回 LLM。這種利用方式運用 LLM 的量化推理能力來產生差異種子，跳脫目前的最佳解。我們評估 $\mu$MOEA 在尋找 MCDL 系統的安全漏洞方面的表現，並將其效能與最先進的 MOEA 方法進行比較。實驗結果顯示 $\mu$MOEA 能夠顯著提升演化搜尋的效率和多樣性。

##### **Embedding Style Beyond Topics: Analyzing Dispersion Effects Across Different Language Models**
2501.00828v1 by Benjamin Icard, Evangelia Zve, Lila Sainero, Alice Breton, Jean-Gabriel Ganascia

This paper analyzes how writing style affects the dispersion of embedding
vectors across multiple, state-of-the-art language models. While early
transformer models primarily aligned with topic modeling, this study examines
the role of writing style in shaping embedding spaces. Using a literary corpus
that alternates between topics and styles, we compare the sensitivity of
language models across French and English. By analyzing the particular impact
of style on embedding dispersion, we aim to better understand how language
models process stylistic information, contributing to their overall
interpretability.

摘要：這篇論文分析寫作風格如何影響嵌入向量的分散在多個最先進的語言模型中。雖然早期的變換器模型主要與主題建模保持一致，但本研究探討了寫作風格在塑造嵌入空間中的作用。使用在主題和風格之間交替的文學語料庫，我們比較了法語和英語中語言模型的敏感性。透過分析風格對嵌入分散的特定影響，我們旨在更好地理解語言模型如何處理風格資訊，從而有助於它們的整體可解釋性。

##### **LLM-Powered Multi-Agent System for Automated Crypto Portfolio Management**
2501.00826v1 by Yichen Luo, Yebo Feng, Jiahua Xu, Paolo Tasca, Yang Liu

Cryptocurrency investment is inherently difficult due to its shorter history
compared to traditional assets, the need to integrate vast amounts of data from
various modalities, and the requirement for complex reasoning. While deep
learning approaches have been applied to address these challenges, their
black-box nature raises concerns about trust and explainability. Recently,
large language models (LLMs) have shown promise in financial applications due
to their ability to understand multi-modal data and generate explainable
decisions. However, single LLM faces limitations in complex, comprehensive
tasks such as asset investment. These limitations are even more pronounced in
cryptocurrency investment, where LLMs have less domain-specific knowledge in
their training corpora.
  To overcome these challenges, we propose an explainable, multi-modal,
multi-agent framework for cryptocurrency investment. Our framework uses
specialized agents that collaborate within and across teams to handle subtasks
such as data analysis, literature integration, and investment decision-making
for the top 30 cryptocurrencies by market capitalization. The expert training
module fine-tunes agents using multi-modal historical data and professional
investment literature, while the multi-agent investment module employs
real-time data to make informed cryptocurrency investment decisions. Unique
intrateam and interteam collaboration mechanisms enhance prediction accuracy by
adjusting final predictions based on confidence levels within agent teams and
facilitating information sharing between teams. Empirical evaluation using data
from November 2023 to September 2024 demonstrates that our framework
outperforms single-agent models and market benchmarks in classification, asset
pricing, portfolio, and explainability performance.

摘要：加密貨幣投資本質上很困難，因為與傳統資產相比，它的歷史較短，需要整合來自各種方式的大量資料，並且需要複雜的推理。雖然深度學習方法已被應用於應對這些挑戰，但它們的黑箱性質引起了對信任和可解釋性的擔憂。最近，大型語言模型 (LLM) 由於能夠理解多模態資料並產生可解釋的決策，在金融應用中顯示出前景。然而，單一的 LLM 在複雜、全面的任務（例如資產投資）中面臨限制。在加密貨幣投資中，這些限制更加明顯，因為 LLM 在其訓練語料庫中缺乏特定領域的知識。
為了克服這些挑戰，我們提出了一個可解釋的、多模態的、多主體的加密貨幣投資框架。我們的框架使用專業代理，它們在團隊內部和跨團隊合作，以處理子任務，例如資料分析、文獻整合，以及對市值排名前 30 的加密貨幣進行投資決策。專家訓練模組使用多模態歷史資料和專業投資文獻微調代理，而多主體投資模組使用即時資料來做出明智的加密貨幣投資決策。獨特的小組內部和跨小組合作機制通過根據代理團隊內的信心水準調整最終預測，並促進團隊之間的資訊共享，來提高預測準確度。使用 2023 年 11 月至 2024 年 9 月的資料進行的實證評估表明，我們的框架在分類、資產定價、投資組合和可解釋性表現方面優於單一代理模型和市場基準。

##### **SLIDE: Integrating Speech Language Model with LLM for Spontaneous Spoken Dialogue Generation**
2501.00805v1 by Haitian Lu, Gaofeng Cheng, Liuping Luo, Leying Zhang, Yanmin Qian, Pengyuan Zhang

Recently, ``textless" speech language models (SLMs) based on speech units
have made huge progress in generating naturalistic speech, including non-verbal
vocalizations. However, the generated speech samples often lack semantic
coherence. In this paper, we propose SLM and LLM Integration for spontaneous
spoken Dialogue gEneration (SLIDE). Specifically, we first utilize an LLM to
generate the textual content of spoken dialogue. Next, we convert the textual
dialogues into phoneme sequences and use a two-tower transformer-based duration
predictor to predict the duration of each phoneme. Finally, an SLM conditioned
on the spoken phoneme sequences is used to vocalize the textual dialogue.
Experimental results on the Fisher dataset demonstrate that our system can
generate naturalistic spoken dialogue while maintaining high semantic
coherence.

摘要：最近，基於語音單元的「無文字」語音語言模型 (SLM) 在生成自然語音方面取得了巨大進展，包括非語言化的發聲。然而，生成的語音樣本通常缺乏語義連貫性。在本文中，我們提出 SLM 和 LLM 整合用於自發口語對話生成 (SLIDE)。具體來說，我們首先利用 LLM 生成口語對話的文字內容。接下來，我們將文字對話轉換為音素序列，並使用基於雙塔Transformer的持續時間預測器來預測每個音素的持續時間。最後，使用以口語音素序列為條件的 SLM 來發聲文字對話。在 Fisher 數據集上的實驗結果表明，我們的系統可以生成自然口語對話，同時保持高度的語義連貫性。

##### **Automatic Text Pronunciation Correlation Generation and Application for Contextual Biasing**
2501.00804v1 by Gaofeng Cheng, Haitian Lu, Chengxu Yang, Xuyang Wang, Ta Li, Yonghong Yan

Effectively distinguishing the pronunciation correlations between different
written texts is a significant issue in linguistic acoustics. Traditionally,
such pronunciation correlations are obtained through manually designed
pronunciation lexicons. In this paper, we propose a data-driven method to
automatically acquire these pronunciation correlations, called automatic text
pronunciation correlation (ATPC). The supervision required for this method is
consistent with the supervision needed for training end-to-end automatic speech
recognition (E2E-ASR) systems, i.e., speech and corresponding text annotations.
First, the iteratively-trained timestamp estimator (ITSE) algorithm is employed
to align the speech with their corresponding annotated text symbols. Then, a
speech encoder is used to convert the speech into speech embeddings. Finally,
we compare the speech embeddings distances of different text symbols to obtain
ATPC. Experimental results on Mandarin show that ATPC enhances E2E-ASR
performance in contextual biasing and holds promise for dialects or languages
lacking artificial pronunciation lexicons.

摘要：有效區分不同書面文本之間的發音關聯性是語言聲學中的重要議題。傳統上，此類發音關聯性是透過人工設計的發音辭典取得。在本文中，我們提出一個資料驅動的方法，以自動取得這些發音關聯性，稱為自動文字發音關聯性 (ATPC)。此方法所需的監督與訓練端到端自動語音辨識 (E2E-ASR) 系統所需的監督一致，即語音和對應的文字註解。首先，採用反覆訓練的時間戳估計器 (ITSE) 演算法，將語音與其對應的註解文字符號對齊。然後，使用語音編碼器將語音轉換為語音嵌入。最後，我們比較不同文字符號的語音嵌入距離，以取得 ATPC。在普通話上的實驗結果顯示，ATPC 增強了 E2E-ASR 在情境偏誤中的效能，並對缺乏人工發音辭典的方言或語言帶來希望。

##### **Reasoning-Oriented and Analogy-Based Methods for Locating and Editing in Zero-Shot Event-Relational Reasoning**
2501.00803v1 by Jingyao Tang, Lishuang Li, Liteng Mi, Haiming Wu, Hongbin Lu

Zero-shot event-relational reasoning is an important task in natural language
processing, and existing methods jointly learn a variety of event-relational
prefixes and inference-form prefixes to achieve such tasks. However, training
prefixes consumes large computational resources and lacks interpretability.
Additionally, learning various relational and inferential knowledge
inefficiently exploits the connections between tasks. Therefore, we first
propose a method for Reasoning-Oriented Locating and Editing (ROLE), which
locates and edits the key modules of the language model for reasoning about
event relations, enhancing interpretability and also resource-efficiently
optimizing the reasoning ability. Subsequently, we propose a method for
Analogy-Based Locating and Editing (ABLE), which efficiently exploits the
similarities and differences between tasks to optimize the zero-shot reasoning
capability. Experimental results show that ROLE improves interpretability and
reasoning performance with reduced computational cost. ABLE achieves SOTA
results in zero-shot reasoning.

摘要：零次發射事件關係推理是自然語言處理中的一項重要任務，現有方法聯合學習各種事件關係前綴和推理形式前綴來實現此類任務。然而，訓練前綴消耗大量的計算資源且缺乏可解釋性。此外，學習各種關係和推理知識無法有效利用任務之間的聯繫。因此，我們首先提出了一個面向推理的定位和編輯 (ROLE) 方法，它定位和編輯語言模型中用於推理事件關係的關鍵模組，增強可解釋性，同時以資源有效的方式優化推理能力。隨後，我們提出了一個基於類比的定位和編輯 (ABLE) 方法，它有效地利用任務之間的相似性和差異來優化零次發射推理能力。實驗結果表明，ROLE 以降低的計算成本提高了可解釋性和推理性能。ABLE 在零次發射推理中取得了 SOTA 結果。

##### **Make Shuffling Great Again: A Side-Channel Resistant Fisher-Yates Algorithm for Protecting Neural Networks**
2501.00798v1 by Leonard Puškáč, Marek Benovič, Jakub Breier, Xiaolu Hou

Neural network models implemented in embedded devices have been shown to be
susceptible to side-channel attacks (SCAs), allowing recovery of proprietary
model parameters, such as weights and biases. There are already available
countermeasure methods currently used for protecting cryptographic
implementations that can be tailored to protect embedded neural network models.
Shuffling, a hiding-based countermeasure that randomly shuffles the order of
computations, was shown to be vulnerable to SCA when the Fisher-Yates algorithm
is used. In this paper, we propose a design of an SCA-secure version of the
Fisher-Yates algorithm. By integrating the masking technique for modular
reduction and Blakely's method for modular multiplication, we effectively
remove the vulnerability in the division operation that led to side-channel
leakage in the original version of the algorithm. We experimentally evaluate
that the countermeasure is effective against SCA by implementing a correlation
power analysis attack on an embedded neural network model implemented on ARM
Cortex-M4. Compared to the original proposal, the memory overhead is $2\times$
the biggest layer of the network, while the time overhead varies from $4\%$ to
$0.49\%$ for a layer with $100$ and $1000$ neurons, respectively.

摘要：已證實嵌入式裝置中實作的神經網路模型容易受到側信道攻擊 (SCA)，導致專有模型參數（例如權重和偏差）被還原。目前已有可保護嵌入式神經網路模型的對策方法，這些方法目前用於保護密碼實作。隨機洗牌運算順序的隱藏式對策方法洗牌，已證實當使用 Fisher-Yates 演算法時容易受到 SCA 攻擊。在本文中，我們提出一個 Fisher-Yates 演算法的 SCA 安全版本設計。透過整合用於模組化簡約的遮罩技術和用於模組化乘法的 Blakely 方法，我們有效消除了導致演算法原始版本中側信道洩漏的除法運算中的漏洞。我們透過對實作於 ARM Cortex-M4 的嵌入式神經網路模型執行相關功率分析攻擊，實驗性地評估了對策方法對 SCA 的有效性。與原始提案相比，記憶體開銷是網路中最大層的 $2\times$，而時間開銷則從擁有 $100$ 和 $1000$ 個神經元的層分別變化為 $4\%$ 到 $0.49\%$。

##### **LENS-XAI: Redefining Lightweight and Explainable Network Security through Knowledge Distillation and Variational Autoencoders for Scalable Intrusion Detection in Cybersecurity**
2501.00790v1 by Muhammet Anil Yagiz, Polat Goktas

The rapid proliferation of Industrial Internet of Things (IIoT) systems
necessitates advanced, interpretable, and scalable intrusion detection systems
(IDS) to combat emerging cyber threats. Traditional IDS face challenges such as
high computational demands, limited explainability, and inflexibility against
evolving attack patterns. To address these limitations, this study introduces
the Lightweight Explainable Network Security framework (LENS-XAI), which
combines robust intrusion detection with enhanced interpretability and
scalability. LENS-XAI integrates knowledge distillation, variational
autoencoder models, and attribution-based explainability techniques to achieve
high detection accuracy and transparency in decision-making. By leveraging a
training set comprising 10% of the available data, the framework optimizes
computational efficiency without sacrificing performance. Experimental
evaluation on four benchmark datasets: Edge-IIoTset, UKM-IDS20, CTU-13, and
NSL-KDD, demonstrates the framework's superior performance, achieving detection
accuracies of 95.34%, 99.92%, 98.42%, and 99.34%, respectively. Additionally,
the framework excels in reducing false positives and adapting to complex attack
scenarios, outperforming existing state-of-the-art methods. Key strengths of
LENS-XAI include its lightweight design, suitable for resource-constrained
environments, and its scalability across diverse IIoT and cybersecurity
contexts. Moreover, the explainability module enhances trust and transparency,
critical for practical deployment in dynamic and sensitive applications. This
research contributes significantly to advancing IDS by addressing computational
efficiency, feature interpretability, and real-world applicability. Future work
could focus on extending the framework to ensemble AI systems for distributed
environments, further enhancing its robustness and adaptability.

摘要：工業物聯網 (IIoT) 系統的快速擴散
需要進階、可解釋、可擴充的入侵偵測系統 (IDS) 來對抗新興的網路威脅。傳統的 IDS 面臨諸如
高運算需求、有限的可解釋性和對抗演化攻擊模式的彈性不足等挑戰。為了解決這些限制，本研究引入了輕量級可解釋網路安全架構 (LENS-XAI)，它
結合了穩健的入侵偵測與增強的可解釋性和可擴充性。LENS-XAI 整合了知識萃取、變異自動編碼器模型和基於歸因的可解釋性技術，以在決策制定中實現高偵測準確度和透明度。透過利用包含 10% 可用資料的訓練組，該架構最佳化了運算效率，同時不犧牲效能。在四個基準資料集：Edge-IIoTset、UKM-IDS20、CTU-13 和 NSL-KDD 上的實驗評估顯示了該架構的優異效能，分別達到了 95.34%、99.92%、98.42% 和 99.34% 的偵測準確度。此外，該架構在減少誤報和適應複雜的攻擊場景方面表現出色，優於現有的最先進方法。LENS-XAI 的主要優點包括其輕量級設計，適用於資源受限的環境，以及其在不同 IIoT 和網路安全情境中的可擴充性。此外，可解釋性模組增強了信任和透明度，這對於在動態且敏感的應用中進行實際部署至關重要。本研究透過解決運算效率、特徵可解釋性和實際應用性，為 IDS 的進展做出了重大貢獻。未來的研究可以專注於將該架構擴充到分散式環境的整體 AI 系統，進一步增強其穩健性和適應性。

##### **Navigating Nuance: In Quest for Political Truth**
2501.00782v1 by Soumyadeep Sar, Dwaipayan Roy

This study investigates the several nuanced rationales for countering the
rise of political bias. We evaluate the performance of the Llama-3 (70B)
language model on the Media Bias Identification Benchmark (MBIB), based on a
novel prompting technique that incorporates subtle reasons for identifying
political leaning. Our findings underscore the challenges of detecting
political bias and highlight the potential of transfer learning methods to
enhance future models. Through our framework, we achieve a comparable
performance with the supervised and fully fine-tuned ConvBERT model, which is
the state-of-the-art model, performing best among other baseline models for the
political bias task on MBIB. By demonstrating the effectiveness of our
approach, we contribute to the development of more robust tools for mitigating
the spread of misinformation and polarization. Our codes and dataset are made
publicly available in github.

摘要：本研究探討了對抗政治偏見興起的幾種微妙理由。我們根據一種新的提示技術，它包含了識別政治傾向的微妙理由，評估了 Llama-3 (70B) 語言模型在媒體偏見識別基準 (MBIB) 上的表現。我們的發現強調了檢測政治偏見的挑戰，並突出了遷移學習方法增強未來模型的潛力。透過我們的架構，我們達到了與監督式和完全微調的 ConvBERT 模型相當的表現，這是最先進的模型，在 MBIB 的政治偏見任務中表現優於其他基準模型。透過展示我們方法的有效性，我們有助於開發更強大的工具來減輕錯誤資訊和兩極分化的傳播。我們的程式碼和資料集已公開在 github 中。

##### **REM: A Scalable Reinforced Multi-Expert Framework for Multiplex Influence Maximization**
2501.00779v1 by Huyen Nguyen, Hieu Dam, Nguyen Do, Cong Tran, Cuong Pham

In social online platforms, identifying influential seed users to maximize
influence spread is a crucial as it can greatly diminish the cost and efforts
required for information dissemination. While effective, traditional methods
for Multiplex Influence Maximization (MIM) have reached their performance
limits, prompting the emergence of learning-based approaches. These novel
methods aim for better generalization and scalability for more sizable graphs
but face significant challenges, such as (1) inability to handle unknown
diffusion patterns and (2) reliance on high-quality training samples. To
address these issues, we propose the Reinforced Expert Maximization framework
(REM). REM leverages a Propagation Mixture of Experts technique to encode
dynamic propagation of large multiplex networks effectively in order to
generate enhanced influence propagation. Noticeably, REM treats a generative
model as a policy to autonomously generate different seed sets and learn how to
improve them from a Reinforcement Learning perspective. Extensive experiments
on several real-world datasets demonstrate that REM surpasses state-of-the-art
methods in terms of influence spread, scalability, and inference time in
influence maximization tasks.

摘要：在社交線上平台中，找出有影響力的種子用戶以最大化影響力傳播至關重要，因為它可以大幅降低資訊傳播所需的成本和精力。雖然有效，但傳統的多重影響最大化 (MIM) 方法已達到其效能極限，促使學習型方法的出現。這些新穎的方法旨在針對規模更大的圖形進行更好的概括和擴充，但面臨重大挑戰，例如 (1) 無法處理未知的傳播模式和 (2) 依賴於高品質的訓練樣本。為了解決這些問題，我們提出了強化專家最大化框架 (REM)。REM 利用專家傳播混合技術有效編碼大型多重網路的動態傳播，以產生增強的影響力傳播。值得注意的是，REM 將生成模型視為一種政策，以自主產生不同的種子集，並從強化學習的角度學習如何改進它們。在多個真實世界資料集上的廣泛實驗證明，REM 在影響力傳播、可擴充性和影響力最大化任務中的推論時間方面都超越了最先進的方法。

##### **Decoding the Flow: CauseMotion for Emotional Causality Analysis in Long-form Conversations**
2501.00778v1 by Yuxuan Zhang, Yulong Li, Zichen Yu, Feilong Tang, Zhixiang Lu, Chong Li, Kang Dang, Jionglong Su

Long-sequence causal reasoning seeks to uncover causal relationships within
extended time series data but is hindered by complex dependencies and the
challenges of validating causal links. To address the limitations of
large-scale language models (e.g., GPT-4) in capturing intricate emotional
causality within extended dialogues, we propose CauseMotion, a long-sequence
emotional causal reasoning framework grounded in Retrieval-Augmented Generation
(RAG) and multimodal fusion. Unlike conventional methods relying only on
textual information, CauseMotion enriches semantic representations by
incorporating audio-derived features-vocal emotion, emotional intensity, and
speech rate-into textual modalities. By integrating RAG with a sliding window
mechanism, it effectively retrieves and leverages contextually relevant
dialogue segments, thus enabling the inference of complex emotional causal
chains spanning multiple conversational turns. To evaluate its effectiveness,
we constructed the first benchmark dataset dedicated to long-sequence emotional
causal reasoning, featuring dialogues with over 70 turns. Experimental results
demonstrate that the proposed RAG-based multimodal integrated approach, the
efficacy of substantially enhances both the depth of emotional understanding
and the causal inference capabilities of large-scale language models. A GLM-4
integrated with CauseMotion achieves an 8.7% improvement in causal accuracy
over the original model and surpasses GPT-4o by 1.2%. Additionally, on the
publicly available DiaASQ dataset, CauseMotion-GLM-4 achieves state-of-the-art
results in accuracy, F1 score, and causal reasoning accuracy.

摘要：長序列因果推理旨在揭示延伸時間序列資料中的因果關係，但因複雜的依賴關係和驗證因果連結的挑戰而受阻。為了解決大規模語言模型（例如 GPT-4）在捕捉延伸對話中錯綜複雜的情緒因果關係方面的限制，我們提出了 CauseMotion，這是一個基於檢索擴充生成（RAG）和多模態融合的長序列情緒因果推理框架。與僅依賴文字資訊的傳統方法不同，CauseMotion 透過將音訊衍生特徵（語音情緒、情緒強度和語速）融入文字模式來豐富語義表徵。透過將 RAG 與滑動視窗機制整合，它有效地擷取和利用與脈絡相關的對話片段，從而推論跨越多個對話回合的複雜情緒因果鏈。為了評估其有效性，我們建構了第一個專門用於長序列情緒因果推理的基準資料集，其中包含超過 70 回合的對話。實驗結果表明，所提出的基於 RAG 的多模態整合方法顯著提升了大規模語言模型的情緒理解深度和因果推理能力。與 CauseMotion 整合的 GLM-4 在因果準確度上比原始模型提升了 8.7%，並比 GPT-4o 高出 1.2%。此外，在公開的 DiaASQ 資料集上，CauseMotion-GLM-4 在準確度、F1 分數和因果推理準確度方面達到了最先進的結果。

##### **FitCF: A Framework for Automatic Feature Importance-guided Counterfactual Example Generation**
2501.00777v1 by Qianli Wang, Nils Feldhus, Simon Ostermann, Luis Felipe Villa-Arenas, Sebastian Möller, Vera Schmitt

Counterfactual examples are widely used in natural language processing (NLP)
as valuable data to improve models, and in explainable artificial intelligence
(XAI) to understand model behavior. The automated generation of counterfactual
examples remains a challenging task even for large language models (LLMs),
despite their impressive performance on many tasks. In this paper, we first
introduce ZeroCF, a faithful approach for leveraging important words derived
from feature attribution methods to generate counterfactual examples in a
zero-shot setting. Second, we present a new framework, FitCF, which further
verifies aforementioned counterfactuals by label flip verification and then
inserts them as demonstrations for few-shot prompting, outperforming two
state-of-the-art baselines. Through ablation studies, we identify the
importance of each of FitCF's core components in improving the quality of
counterfactuals, as assessed through flip rate, perplexity, and similarity
measures. Furthermore, we show the effectiveness of LIME and Integrated
Gradients as backbone attribution methods for FitCF and find that the number of
demonstrations has the largest effect on performance. Finally, we reveal a
strong correlation between the faithfulness of feature attribution scores and
the quality of generated counterfactuals.

摘要：反事實範例廣泛用於自然語言處理 (NLP) 中，作為改進模型的有價值資料，以及在可解釋人工智慧 (XAI) 中用於了解模型行為。即使對於大型語言模型 (LLM)，自動產生反事實範例仍然是一項具有挑戰性的任務，儘管它們在許多任務上表現出色。在本文中，我們首先介紹 ZeroCF，這是一種忠實的方法，用於利用從特徵歸因方法中衍生的重要字詞，在零次學習設定中產生反事實範例。其次，我們提出了一個新的框架 FitCF，它通過標籤翻轉驗證進一步驗證上述反事實，然後將它們插入作為少次學習提示的範例，優於兩個最先進的基準。通過消融研究，我們確定了 FitCF 各個核心組成部分在提升反事實品質方面的重要性，評估方法為翻轉率、困惑度和相似性測量。此外，我們展示了 LIME 和整合梯度作為 FitCF 的主幹歸因方法的有效性，並發現範例數量對效能有最大的影響。最後，我們揭示了特徵歸因分數的忠實度與產生的反事實品質之間的強相關性。

##### **Revisiting Graph Neural Networks on Graph-level Tasks: Comprehensive Experiments, Analysis, and Improvements**
2501.00773v1 by Haoyang Li, Yuming Xu, Chen Jason Zhang, Alexander Zhou, Lei Chen, Qing Li

Graphs are essential data structures for modeling complex interactions in
domains such as social networks, molecular structures, and biological systems.
Graph-level tasks, which predict properties or classes for the entire graph,
are critical for applications, such as molecular property prediction and
subgraph counting. Graph Neural Networks (GNNs) have shown promise in these
tasks, but their evaluations are often limited to narrow datasets, tasks, and
inconsistent experimental setups, restricting their generalizability. To
address these limitations, we propose a unified evaluation framework for
graph-level GNNs. This framework provides a standardized setting to evaluate
GNNs across diverse datasets, various graph tasks (e.g., graph classification
and regression), and challenging scenarios, including noisy, imbalanced, and
few-shot graphs. Additionally, we propose a novel GNN model with enhanced
expressivity and generalization capabilities. Specifically, we enhance the
expressivity of GNNs through a $k$-path rooted subgraph approach, enabling the
model to effectively count subgraphs (e.g., paths and cycles). Moreover, we
introduce a unified graph contrastive learning algorithm for graphs across
diverse domains, which adaptively removes unimportant edges to augment graphs,
thereby significantly improving generalization performance. Extensive
experiments demonstrate that our model achieves superior performance against
fourteen effective baselines across twenty-seven graph datasets, establishing
it as a robust and generalizable model for graph-level tasks.

摘要：圖形是對社交網路、分子結構和生物系統等領域中複雜交互建模的基本資料結構。預測整個圖形屬性或類別的圖形級任務對於分子屬性預測和子圖形計數等應用至關重要。圖形神經網路 (GNN) 已在這些任務中展現出潛力，但其評估通常僅限於狹窄的資料集、任務和不一致的實驗設定，限制了其泛化性。為了解決這些限制，我們提出了統一的圖形級 GNN 評估框架。此框架提供了一個標準化的設定，可以在不同的資料集、各種圖形任務（例如圖形分類和回歸）和具有挑戰性的場景（包括雜訊、不平衡和少次取樣圖形）中評估 GNN。此外，我們提出了一個新穎的 GNN 模型，具有增強的表達力和泛化能力。具體來說，我們透過 $k$-路徑根子圖方法增強 GNN 的表達力，使模型能夠有效地計算子圖形（例如路徑和循環）。此外，我們引入了一個統一的圖形對比學習演算法，適用於不同領域的圖形，它會自適應地移除不重要的邊緣來擴充圖形，從而顯著提高泛化效能。廣泛的實驗表明，我們的模型在 27 個圖形資料集上針對 14 個有效的基準測試達到了卓越的效能，確立了其作為圖形級任務的強健且可泛化的模型地位。

##### **An AI-powered Bayesian generative modeling approach for causal inference in observational studies**
2501.00755v1 by Qiao Liu, Wing Hung Wong

Causal inference in observational studies with high-dimensional covariates
presents significant challenges. We introduce CausalBGM, an AI-powered Bayesian
generative modeling approach that captures the causal relationship among
covariates, treatment, and outcome variables. The core innovation of CausalBGM
lies in its ability to estimate the individual treatment effect (ITE) by
learning individual-specific distributions of a low-dimensional latent feature
set (e.g., latent confounders) that drives changes in both treatment and
outcome. This approach not only effectively mitigates confounding effects but
also provides comprehensive uncertainty quantification, offering reliable and
interpretable causal effect estimates at the individual level. CausalBGM adopts
a Bayesian model and uses a novel iterative algorithm to update the model
parameters and the posterior distribution of latent features until convergence.
This framework leverages the power of AI to capture complex dependencies among
variables while adhering to the Bayesian principles. Extensive experiments
demonstrate that CausalBGM consistently outperforms state-of-the-art methods,
particularly in scenarios with high-dimensional covariates and large-scale
datasets. Its Bayesian foundation ensures statistical rigor, providing robust
and well-calibrated posterior intervals. By addressing key limitations of
existing methods, CausalBGM emerges as a robust and promising framework for
advancing causal inference in modern applications in fields such as genomics,
healthcare, and social sciences. CausalBGM is maintained at the website
https://causalbgm.readthedocs.io/.

摘要：在具有高維度協變量的觀察性研究中，因果推論提出了重大挑戰。我們引入了 CausalBGM，一種由人工智慧推動的貝氏生成模型方法，它捕捉了協變量、治療和結果變量之間的因果關係。CausalBGM 的核心創新在於它能夠通過學習低維潛在特徵集（例如，潛在混雜因素）的特定於個體的分布來估計個體治療效果 (ITE)，該分布推動了治療和結果的變化。這種方法不僅有效地減輕了混雜效應，還提供了全面的不確定性量化，在個體層面上提供了可靠且可解釋的因果效應估計。CausalBGM 採用貝氏模型，並使用一種新穎的迭代演算法來更新模型參數和潛在特徵的後驗分布，直到收斂。此框架利用人工智慧的力量來捕捉變量之間的複雜依賴關係，同時遵守貝氏原理。廣泛的實驗表明，CausalBGM 持續優於最先進的方法，特別是在具有高維度協變量和大規模資料集的情況下。其貝氏基礎確保了統計嚴謹性，提供了穩健且校準良好的後驗區間。通過解決現有方法的主要限制，CausalBGM 成為一個穩健且有前途的框架，用於推進現代應用（例如基因組學、醫療保健和社會科學）中的因果推論。CausalBGM 在網站 https://causalbgm.readthedocs.io/ 上進行維護。

##### **Beyond Text: Implementing Multimodal Large Language Model-Powered Multi-Agent Systems Using a No-Code Platform**
2501.00750v1 by Cheonsu Jeong

This study proposes the design and implementation of a multimodal LLM-based
Multi-Agent System (MAS) leveraging a No-Code platform to address the practical
constraints and significant entry barriers associated with AI adoption in
enterprises. Advanced AI technologies, such as Large Language Models (LLMs),
often pose challenges due to their technical complexity and high implementation
costs, making them difficult for many organizations to adopt. To overcome these
limitations, this research develops a No-Code-based Multi-Agent System designed
to enable users without programming knowledge to easily build and manage AI
systems. The study examines various use cases to validate the applicability of
AI in business processes, including code generation from image-based notes,
Advanced RAG-based question-answering systems, text-based image generation, and
video generation using images and prompts. These systems lower the barriers to
AI adoption, empowering not only professional developers but also general users
to harness AI for significantly improved productivity and efficiency. By
demonstrating the scalability and accessibility of No-Code platforms, this
study advances the democratization of AI technologies within enterprises and
validates the practical applicability of Multi-Agent Systems, ultimately
contributing to the widespread adoption of AI across various industries.

摘要：本研究提出一個多模態 LLM 為基礎的多主體系統 (MAS) 的設計與實作，利用無程式碼平台來解決企業採用 AI 時所面臨的實際限制和顯著的進入障礙。進階 AI 技術（例如大型語言模型 (LLM)）通常會因為技術複雜性和高實作成本而帶來挑戰，讓許多組織難以採用。為了克服這些限制，本研究開發了一個基於無程式碼的多主體系統，讓沒有程式設計知識的使用者可以輕鬆建置和管理 AI 系統。本研究檢視了各種使用案例，驗證 AI 在商業流程中的適用性，包括從影像筆記產生程式碼、基於 RAG 的進階問答系統、基於文字的影像產生，以及使用影像和提示產生影片。這些系統降低了 AI 採用的障礙，不僅讓專業開發人員，也讓一般使用者能夠利用 AI 大幅提升生產力和效率。透過展示無程式碼平台的可擴充性和可近性，本研究推動了企業內 AI 技術的民主化，並驗證了多主體系統的實際適用性，最終有助於 AI 在各產業的廣泛採用。

