
### LLM
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-08-30**|**Bridging Episodes and Semantics: A Novel Framework for Long-Form Video Understanding**|Gueter Josmy Faure et.al.|[2408.17443v1](http://arxiv.org/abs/2408.17443v1)|[link](https://github.com/joslefaure/HERMES)|
|**2024-08-30**|**SYNTHEVAL: Hybrid Behavioral Testing of NLP Models with Synthetic CheckLists**|Raoyuan Zhao et.al.|[2408.17437v1](http://arxiv.org/abs/2408.17437v1)|[link](https://github.com/loreley99/syntheval_checklist)|
|**2024-08-30**|**Advancing Multi-talker ASR Performance with Large Language Models**|Mohan Shi et.al.|[2408.17431v1](http://arxiv.org/abs/2408.17431v1)|null|
|**2024-08-30**|**CLOCR-C: Context Leveraging OCR Correction with Pre-trained Language Models**|Jonathan Bourne et.al.|[2408.17428v1](http://arxiv.org/abs/2408.17428v1)|null|
|**2024-08-30**|**Open-vocabulary Temporal Action Localization using VLMs**|Naoki Wake et.al.|[2408.17422v2](http://arxiv.org/abs/2408.17422v2)|null|
|**2024-08-30**|**Getting Inspiration for Feature Elicitation: App Store- vs. LLM-based Approach**|Jialiang Wei et.al.|[2408.17404v1](http://arxiv.org/abs/2408.17404v1)|null|
|**2024-08-30**|**Exploring the Effect of Explanation Content and Format on User Comprehension and Trust**|Antonio Rago et.al.|[2408.17401v1](http://arxiv.org/abs/2408.17401v1)|null|
|**2024-08-30**|**MoRe Fine-Tuning with 10x Fewer Parameters**|Wenxuan Tan et.al.|[2408.17383v1](http://arxiv.org/abs/2408.17383v1)|[link](https://github.com/sprocketlab/sparse_matrix_fine_tuning)|
|**2024-08-30**|**Traffic expertise meets residual RL: Knowledge-informed model-based residual reinforcement learning for CAV trajectory control**|Zihao Sheng et.al.|[2408.17380v1](http://arxiv.org/abs/2408.17380v1)|[link](https://github.com/zihaosheng/traffic-expertise-rl)|
|**2024-08-30**|**EMPOWER: Embodied Multi-role Open-vocabulary Planning with Online Grounding and Execution**|Francesco Argenziano et.al.|[2408.17379v1](http://arxiv.org/abs/2408.17379v1)|null|
|**2024-08-30**|**NDP: Next Distribution Prediction as a More Broad Target**|Junhao Ruan et.al.|[2408.17377v1](http://arxiv.org/abs/2408.17377v1)|null|
|**2024-08-30**|**Leveraging Graph Neural Networks to Forecast Electricity Consumption**|Eloi Campagne et.al.|[2408.17366v1](http://arxiv.org/abs/2408.17366v1)|null|
|**2024-08-30**|**Assessing Generative Language Models in Classification Tasks: Performance and Self-Evaluation Capabilities in the Environmental and Climate Change Domain**|Francesca Grasso et.al.|[2408.17362v1](http://arxiv.org/abs/2408.17362v1)|[link](https://github.com/stefanolocci/LLMClassification)|
|**2024-08-30**|**Forget to Flourish: Leveraging Machine-Unlearning on Pretrained Language Models for Privacy Leakage**|Md Rafi Ur Rashid et.al.|[2408.17354v1](http://arxiv.org/abs/2408.17354v1)|null|
|**2024-08-30**|**rerankers: A Lightweight Python Library to Unify Ranking Methods**|Benjamin Clavié et.al.|[2408.17344v2](http://arxiv.org/abs/2408.17344v2)|[link](https://github.com/answerdotai/rerankers)|
|**2024-08-30**|**Impact of ChatGPT on the writing style of condensed matter physicists**|Shaojun Xu et.al.|[2408.17325v1](http://arxiv.org/abs/2408.17325v1)|null|
|**2024-08-30**|**Modularity in Transformers: Investigating Neuron Separability & Specialization**|Nicholas Pochinkov et.al.|[2408.17324v1](http://arxiv.org/abs/2408.17324v1)|null|
|**2024-08-30**|**Investigating Neuron Ablation in Attention Heads: The Case for Peak Activation Centering**|Nicholas Pochinkov et.al.|[2408.17322v1](http://arxiv.org/abs/2408.17322v1)|[link](https://github.com/nickypro/investigating-ablation)|
|**2024-08-30**|**Bridging Domain Knowledge and Process Discovery Using Large Language Models**|Ali Norouzifar et.al.|[2408.17316v1](http://arxiv.org/abs/2408.17316v1)|[link](https://github.com/alinorouzifar/imr-llm)|
|**2024-08-30**|**Fair Best Arm Identification with Fixed Confidence**|Alessio Russo et.al.|[2408.17313v1](http://arxiv.org/abs/2408.17313v1)|[link](https://github.com/rssalessio/fair-best-arm-identification)|
|**2024-08-30**|**Hybridizing Base-Line 2D-CNN Model with Cat Swarm Optimization for Enhanced Advanced Persistent Threat Detection**|Ali M. Bakhiet et.al.|[2408.17307v1](http://arxiv.org/abs/2408.17307v1)|null|
|**2024-08-30**|**Stationary Policies are Optimal in Risk-averse Total-reward MDPs with EVaR**|Xihong Su et.al.|[2408.17286v1](http://arxiv.org/abs/2408.17286v1)|null|
|**2024-08-30**|**Flexible and Effective Mixing of Large Language Models into a Mixture of Domain Experts**|Rhui Dih Lee et.al.|[2408.17280v1](http://arxiv.org/abs/2408.17280v1)|null|
|**2024-08-30**|**UrBench: A Comprehensive Benchmark for Evaluating Large Multimodal Models in Multi-View Urban Scenarios**|Baichuan Zhou et.al.|[2408.17267v1](http://arxiv.org/abs/2408.17267v1)|null|
|**2024-08-30**|**VisionTS: Visual Masked Autoencoders Are Free-Lunch Zero-Shot Time Series Forecasters**|Mouxiang Chen et.al.|[2408.17253v1](http://arxiv.org/abs/2408.17253v1)|[link](https://github.com/keytoyze/visionts)|
|**2024-08-30**|**Abstracted Gaussian Prototypes for One-Shot Concept Learning**|Chelsea Zou et.al.|[2408.17251v1](http://arxiv.org/abs/2408.17251v1)|[link](https://github.com/bosonphoton/abstractedgaussianprototypes)|
|**2024-08-30**|**AI-Driven Intrusion Detection Systems (IDS) on the ROAD dataset: A Comparative Analysis for automotive Controller Area Network (CAN)**|Lorenzo Guerra et.al.|[2408.17235v1](http://arxiv.org/abs/2408.17235v1)|null|
|**2024-08-30**|**A methodological framework for Resilience as a Service (RaaS) in multimodal urban transportation networks**|Sara Jaber et.al.|[2408.17233v1](http://arxiv.org/abs/2408.17233v1)|null|
|**2024-08-30**|**Towards Symbolic XAI -- Explanation Through Human Understandable Logical Relationships Between Features**|Thomas Schnake et.al.|[2408.17198v1](http://arxiv.org/abs/2408.17198v1)|null|
|**2024-08-30**|**Improving Extraction of Clinical Event Contextual Properties from Electronic Health Records: A Comparative Study**|Shubham Agarwal et.al.|[2408.17181v1](http://arxiv.org/abs/2408.17181v1)|null|
|**2024-08-30**|**Identifying and Clustering Counter Relationships of Team Compositions in PvP Games for Efficient Balance Analysis**|Chiu-Chou Lin et.al.|[2408.17180v1](http://arxiv.org/abs/2408.17180v1)|[link](https://github.com/DSobscure/cgi_drl_platform)|
|**2024-08-30**|**Codec Does Matter: Exploring the Semantic Shortcoming of Codec for Audio Language Model**|Zhen Ye et.al.|[2408.17175v1](http://arxiv.org/abs/2408.17175v1)|[link](https://github.com/zhenye234/xcodec)|
|**2024-08-30**|**Look, Compare, Decide: Alleviating Hallucination in Large Vision-Language Models via Multi-View Multi-Path Reasoning**|Xiaoye Qu et.al.|[2408.17150v1](http://arxiv.org/abs/2408.17150v1)|[link](https://github.com/gasolsun36/mvp)|
|**2024-08-30**|**Towards Hyper-parameter-free Federated Learning**|Geetika et.al.|[2408.17145v1](http://arxiv.org/abs/2408.17145v1)|[link](https://github.com/zk23du/fedli)|
|**2024-08-30**|**VQ4DiT: Efficient Post-Training Vector Quantization for Diffusion Transformers**|Juncan Deng et.al.|[2408.17131v1](http://arxiv.org/abs/2408.17131v1)|null|
|**2024-08-30**|**Controllable Edge-Type-Specific Interpretation in Multi-Relational Graph Neural Networks for Drug Response Prediction**|Xiaodi Li et.al.|[2408.17129v2](http://arxiv.org/abs/2408.17129v2)|[link](https://github.com/ahaubioinformatics/cetexplainer)|
|**2024-08-30**|**Exploring User Acceptance Of Portable Intelligent Personal Assistants: A Hybrid Approach Using PLS-SEM And fsQCA**|Gustave Florentin Nkoulou Mvondo et.al.|[2408.17119v1](http://arxiv.org/abs/2408.17119v1)|null|
|**2024-08-30**|**Understanding the User: An Intent-Based Ranking Dataset**|Abhijit Anand et.al.|[2408.17103v1](http://arxiv.org/abs/2408.17103v1)|null|
|**2024-08-30**|**FissionVAE: Federated Non-IID Image Generation with Latent Space and Decoder Decomposition**|Chen Hu et.al.|[2408.17090v1](http://arxiv.org/abs/2408.17090v1)|[link](https://github.com/rand2ai/fissionvae)|
|**2024-08-30**|**MaFeRw: Query Rewriting with Multi-Aspect Feedbacks for Retrieval-Augmented Large Language Models**|Yujing Wang et.al.|[2408.17072v1](http://arxiv.org/abs/2408.17072v1)|null|
|**2024-08-30**|**Novel-WD: Exploring acquisition of Novel World Knowledge in LLMs Using Prefix-Tuning**|Maxime Méloux et.al.|[2408.17070v1](http://arxiv.org/abs/2408.17070v1)|null|
|**2024-08-30**|**Instant Adversarial Purification with Adversarial Consistency Distillation**|Chun Tong Lei et.al.|[2408.17064v2](http://arxiv.org/abs/2408.17064v2)|null|
|**2024-08-30**|**A Survey of the Self Supervised Learning Mechanisms for Vision Transformers**|Asifullah Khan et.al.|[2408.17059v1](http://arxiv.org/abs/2408.17059v1)|null|
|**2024-08-30**|**From Text to Emotion: Unveiling the Emotion Annotation Capabilities of LLMs**|Minxue Niu et.al.|[2408.17026v1](http://arxiv.org/abs/2408.17026v1)|[link](https://github.com/chailab-umich/GPT-4-Emotion-Annotation)|
|**2024-08-30**|**InkubaLM: A small language model for low-resource African languages**|Atnafu Lambebo Tonja et.al.|[2408.17024v2](http://arxiv.org/abs/2408.17024v2)|null|
|**2024-08-30**|**Dynamic Self-Consistency: Leveraging Reasoning Paths for Efficient LLM Sampling**|Guangya Wan et.al.|[2408.17017v1](http://arxiv.org/abs/2408.17017v1)|null|
|**2024-08-30**|**Disease Classification and Impact of Pretrained Deep Convolution Neural Networks on Diverse Medical Imaging Datasets across Imaging Modalities**|Jutika Borah et.al.|[2408.17011v2](http://arxiv.org/abs/2408.17011v2)|null|
|**2024-08-30**|**Improving Time Series Classification with Representation Soft Label Smoothing**|Hengyi Ma et.al.|[2408.17010v1](http://arxiv.org/abs/2408.17010v1)|null|
|**2024-08-30**|**Safety Layers of Aligned Large Language Models: The Key to LLM Security**|Shen Li et.al.|[2408.17003v1](http://arxiv.org/abs/2408.17003v1)|null|
|**2024-08-30**|**Tool-Assisted Agent on SQL Inspection and Refinement in Real-World Scenarios**|Zhongyuan Wang et.al.|[2408.16991v1](http://arxiv.org/abs/2408.16991v1)|null|
|**2024-08-30**|**Beyond Preferences in AI Alignment**|Tan Zhi-Xuan et.al.|[2408.16984v1](http://arxiv.org/abs/2408.16984v1)|null|
|**2024-08-30**|**Training Ultra Long Context Language Model with Fully Pipelined Distributed Transformer**|Jinghan Yao et.al.|[2408.16978v1](http://arxiv.org/abs/2408.16978v1)|[link](https://github.com/microsoft/DeepSpeed)|
|**2024-08-30**|**Technical Report of HelixFold3 for Biomolecular Structure Prediction**|Lihang Liu et.al.|[2408.16975v1](http://arxiv.org/abs/2408.16975v1)|null|
|**2024-08-30**|**MemLong: Memory-Augmented Retrieval for Long Text Modeling**|Weijie Liu et.al.|[2408.16967v1](http://arxiv.org/abs/2408.16967v1)|[link](https://github.com/bui1dmysea/memlong)|
|**2024-08-30**|**UserSumBench: A Benchmark Framework for Evaluating User Summarization Approaches**|Chao Wang et.al.|[2408.16966v1](http://arxiv.org/abs/2408.16966v1)|null|
|**2024-08-30**|**Transient Fault Tolerant Semantic Segmentation for Autonomous Driving**|Leonardo Iurada et.al.|[2408.16952v1](http://arxiv.org/abs/2408.16952v1)|[link](https://github.com/iurada/neutron-segmentation)|
|**2024-08-29**|**Different Victims, Same Layout: Email Visual Similarity Detection for Enhanced Email Protection**|Sachin Shukla et.al.|[2408.16945v3](http://arxiv.org/abs/2408.16945v3)|null|
|**2024-08-29**|**A longitudinal sentiment analysis of Sinophobia during COVID-19 using large language models**|Chen Wang et.al.|[2408.16942v1](http://arxiv.org/abs/2408.16942v1)|null|
|**2024-08-29**|**Plausible-Parrots @ MSP2023: Enhancing Semantic Plausibility Modeling using Entity and Event Knowledge**|Chong Shen et.al.|[2408.16937v1](http://arxiv.org/abs/2408.16937v1)|[link](https://github.com/st143575/SemPlaus-plausibleparrots)|
|**2024-08-29**|**Event Extraction for Portuguese: A QA-driven Approach using ACE-2005**|Luís Filipe Cunha et.al.|[2408.16932v1](http://arxiv.org/abs/2408.16932v1)|null|
|**2024-08-29**|**ACE-2005-PT: Corpus for Event Extraction in Portuguese**|Luís Filipe Cunha et.al.|[2408.16928v1](http://arxiv.org/abs/2408.16928v1)|null|
|**2024-08-29**|**Analyzing Inference Privacy Risks Through Gradients in Machine Learning**|Zhuohang Li et.al.|[2408.16913v1](http://arxiv.org/abs/2408.16913v1)|null|
|**2024-08-29**|**Exploring Multiple Strategies to Improve Multilingual Coreference Resolution in CorefUD**|Ondřej Pražák et.al.|[2408.16893v1](http://arxiv.org/abs/2408.16893v1)|[link](https://github.com/ondfa/coref-multiling)|
|**2024-08-29**|**LLaVA-Chef: A Multi-modal Generative Model for Food Recipes**|Fnu Mohbat et.al.|[2408.16889v1](http://arxiv.org/abs/2408.16889v1)|[link](https://github.com/mohbattharani/LLaVA-Chef)|
|**2024-08-29**|**Modeling offensive content detection for TikTok**|Kasper Cools et.al.|[2408.16857v1](http://arxiv.org/abs/2408.16857v1)|null|
|**2024-08-29**|**See or Guess: Counterfactually Regularized Image Captioning**|Qian Cao et.al.|[2408.16809v1](http://arxiv.org/abs/2408.16809v1)|[link](https://github.com/aman-4-real/see-or-guess)|
|**2024-08-29**|**SAM2Point: Segment Any 3D as Videos in Zero-shot and Promptable Manners**|Ziyu Guo et.al.|[2408.16768v1](http://arxiv.org/abs/2408.16768v1)|[link](https://github.com/ziyuguo99/sam2point)|
|**2024-08-29**|**ReconX: Reconstruct Any Scene from Sparse Views with Video Diffusion Model**|Fangfu Liu et.al.|[2408.16767v1](http://arxiv.org/abs/2408.16767v1)|null|
|**2024-08-29**|**A Score-Based Density Formula, with Applications in Diffusion Generative Models**|Gen Li et.al.|[2408.16765v1](http://arxiv.org/abs/2408.16765v1)|null|
|**2024-08-29**|**Dissecting Out-of-Distribution Detection and Open-Set Recognition: A Critical Analysis of Methods and Benchmarks**|Hongjun Wang et.al.|[2408.16757v2](http://arxiv.org/abs/2408.16757v2)|[link](https://github.com/visual-ai/dissect-ood-osr)|
|**2024-08-29**|**How Far Can Cantonese NLP Go? Benchmarking Cantonese Capabilities of Large Language Models**|Jiyue Jiang et.al.|[2408.16756v1](http://arxiv.org/abs/2408.16756v1)|null|
|**2024-08-29**|**Reinforcement Learning without Human Feedback for Last Mile Fine-Tuning of Large Language Models**|Alec Solway et.al.|[2408.16753v1](http://arxiv.org/abs/2408.16753v1)|null|
|**2024-08-29**|**A Gradient Analysis Framework for Rewarding Good and Penalizing Bad Examples in Language Models**|Yi-Lin Tuan et.al.|[2408.16751v1](http://arxiv.org/abs/2408.16751v1)|null|
|**2024-08-29**|**Assessing Large Language Models for Online Extremism Research: Identification, Explanation, and New Knowledge**|Beidi Dong et.al.|[2408.16749v1](http://arxiv.org/abs/2408.16749v1)|null|
|**2024-08-29**|**Theoretical and Methodological Framework for Studying Texts Produced by Large Language Models**|Jiří Milička et.al.|[2408.16740v1](http://arxiv.org/abs/2408.16740v1)|null|
|**2024-08-29**|**Smaller, Weaker, Yet Better: Training LLM Reasoners via Compute-Optimal Sampling**|Hritik Bansal et.al.|[2408.16737v1](http://arxiv.org/abs/2408.16737v1)|null|
|**2024-08-29**|**Mini-Omni: Language Models Can Hear, Talk While Thinking in Streaming**|Zhifei Xie et.al.|[2408.16725v2](http://arxiv.org/abs/2408.16725v2)|[link](https://github.com/gpt-omni/mini-omni)|
|**2024-08-29**|**A GREAT Architecture for Edge-Based Graph Problems Like TSP**|Attila Lischka et.al.|[2408.16717v1](http://arxiv.org/abs/2408.16717v1)|null|
|**2024-08-29**|**Jina-ColBERT-v2: A General-Purpose Multilingual Late Interaction Retriever**|Rohan Jha et.al.|[2408.16672v3](http://arxiv.org/abs/2408.16672v3)|null|
|**2024-08-29**|**Entropic Distribution Matching in Supervised Fine-tuning of LLMs: Less Overfitting and Better Diversity**|Ziniu Li et.al.|[2408.16673v1](http://arxiv.org/abs/2408.16673v1)|null|
|**2024-08-29**|**Iterative Graph Alignment**|Fangyuan Yu et.al.|[2408.16667v1](http://arxiv.org/abs/2408.16667v1)|null|
|**2024-08-29**|**DriveGenVLM: Real-world Video Generation for Vision Language Model based Autonomous Driving**|Yongjie Fu et.al.|[2408.16647v1](http://arxiv.org/abs/2408.16647v1)|null|
|**2024-08-29**|**RLCP: A Reinforcement Learning-based Copyright Protection Method for Text-to-Image Diffusion Model**|Zhuan Shi et.al.|[2408.16634v2](http://arxiv.org/abs/2408.16634v2)|null|
|**2024-08-29**|**Optimizing Automated Picking Systems in Warehouse Robots Using Machine Learning**|Keqin Li et.al.|[2408.16633v1](http://arxiv.org/abs/2408.16633v1)|null|
|**2024-08-29**|**Maelstrom Networks**|Matthew Evanusa et.al.|[2408.16632v1](http://arxiv.org/abs/2408.16632v1)|null|
|**2024-08-29**|**LLMs generate structurally realistic social networks but overestimate political homophily**|Serina Chang et.al.|[2408.16629v1](http://arxiv.org/abs/2408.16629v1)|[link](https://github.com/snap-stanford/llm-social-network)|
|**2024-08-29**|**Towards Infusing Auxiliary Knowledge for Distracted Driver Detection**|Ishwar B Balappanawar et.al.|[2408.16621v1](http://arxiv.org/abs/2408.16621v1)|[link](https://github.com/ishwarbb/kid3)|
|**2024-08-29**|**Hyperdimensional Vector Tsetlin Machines with Applications to Sequence Learning and Generation**|Christian D. Blakely et.al.|[2408.16620v1](http://arxiv.org/abs/2408.16620v1)|[link](https://github.com/clisztian/HypervectorTsetlin)|
|**2024-08-29**|**Examination of Code generated by Large Language Models**|Robin Beer et.al.|[2408.16601v1](http://arxiv.org/abs/2408.16601v1)|[link](https://github.com/t-muras/ai-code-analysis)|
|**2024-08-29**|**Enhancing Dialogue Generation in Werewolf Game Through Situation Analysis and Persuasion Strategies**|Zhiyang Qi et.al.|[2408.16586v2](http://arxiv.org/abs/2408.16586v2)|null|
|**2024-08-29**|**Seeking the Sufficiency and Necessity Causal Features in Multimodal Representation Learning**|Boyu Chen et.al.|[2408.16577v1](http://arxiv.org/abs/2408.16577v1)|null|
|**2024-08-29**|**Predictability maximization and the origins of word order harmony**|Ramon Ferrer-i-Cancho et.al.|[2408.16570v1](http://arxiv.org/abs/2408.16570v1)|null|
|**2024-08-29**|**SALSA: Speedy ASR-LLM Synchronous Aggregation**|Ashish Mittal et.al.|[2408.16542v1](http://arxiv.org/abs/2408.16542v1)|[link](https://github.com/csalt-research/salsa)|
|**2024-08-29**|**SFR-GNN: Simple and Fast Robust GNNs against Structural Attacks**|Xing Ai et.al.|[2408.16537v2](http://arxiv.org/abs/2408.16537v2)|null|
|**2024-08-29**|**CNIMA: A Universal Evaluation Framework and Automated Approach for Assessing Second Language Dialogues**|Rena Gao et.al.|[2408.16518v1](http://arxiv.org/abs/2408.16518v1)|[link](https://github.com/renagao/csl2024)|
|**2024-08-29**|**Adaptive Variational Continual Learning via Task-Heuristic Modelling**|Fan Yang et.al.|[2408.16517v1](http://arxiv.org/abs/2408.16517v1)|[link](https://github.com/lukeyf/auto_vcl)|
|**2024-08-29**|**HLogformer: A Hierarchical Transformer for Representing Log Data**|Zhichao Hou et.al.|[2408.16803v1](http://arxiv.org/abs/2408.16803v1)|null|
|**2024-08-29**|**LLMs vs Established Text Augmentation Techniques for Classification: When do the Benefits Outweight the Costs?**|Jan Cegin et.al.|[2408.16502v1](http://arxiv.org/abs/2408.16502v1)|null|
|**2024-08-29**|**On-device AI: Quantization-aware Training of Transformers in Time-Series**|Tianheng Ling et.al.|[2408.16495v1](http://arxiv.org/abs/2408.16495v1)|null|
|**2024-08-29**|**Learning from Negative Samples in Generative Biomedical Entity Linking**|Chanhwi Kim et.al.|[2408.16493v1](http://arxiv.org/abs/2408.16493v1)|[link](https://github.com/dmis-lab/angel)|

#### Abstracts
##### **Bridging Episodes and Semantics: A Novel Framework for Long-Form Video Understanding**
2408.17443v1 by Gueter Josmy Faure, Jia-Fong Yeh, Min-Hung Chen, Hung-Ting Su, Winston H. Hsu, Shang-Hong Lai

While existing research often treats long-form videos as extended short
videos, we propose a novel approach that more accurately reflects human
cognition. This paper introduces BREASE: BRidging Episodes And SEmantics for
Long-Form Video Understanding, a model that simulates episodic memory
accumulation to capture action sequences and reinforces them with semantic
knowledge dispersed throughout the video. Our work makes two key contributions:
First, we develop an Episodic COmpressor (ECO) that efficiently aggregates
crucial representations from micro to semi-macro levels. Second, we propose a
Semantics reTRiever (SeTR) that enhances these aggregated representations with
semantic information by focusing on the broader context, dramatically reducing
feature dimensionality while preserving relevant macro-level information.
Extensive experiments demonstrate that BREASE achieves state-of-the-art
performance across multiple long video understanding benchmarks in both
zero-shot and fully-supervised settings. The project page and code are at:
https://joslefaure.github.io/assets/html/hermes.html.

摘要：儘管現有研究通常將長影片視為延伸的短影片，但我們提出了一種新穎的方法，能更精確地反映人類認知。本文介紹了 BREASE：橋接片段與語義以理解長影片，這是一種模擬情節記憶累積以擷取動作序列，並透過影片中分散的語義知識來強化這些序列的模型。我們的研究做出了兩項關鍵貢獻：首先，我們開發了一個情節壓縮器 (ECO)，可以有效地從微觀到半巨觀層級彙總關鍵表示式。其次，我們提出了一個語義檢索器 (SeTR)，透過關注更廣泛的脈絡來增強這些彙總表示式中的語義資訊，大幅降低特徵維度，同時保留相關的巨觀層級資訊。廣泛的實驗證明，BREASE 在多個長影片理解基準中達到了最先進的效能，無論是在零次學習或完全監督的設定中皆是如此。專案頁面和程式碼位於：https://joslefaure.github.io/assets/html/hermes.html。

##### **SYNTHEVAL: Hybrid Behavioral Testing of NLP Models with Synthetic CheckLists**
2408.17437v1 by Raoyuan Zhao, Abdullatif Köksal, Yihong Liu, Leonie Weissweiler, Anna Korhonen, Hinrich Schütze

Traditional benchmarking in NLP typically involves using static held-out test
sets. However, this approach often results in an overestimation of performance
and lacks the ability to offer comprehensive, interpretable, and dynamic
assessments of NLP models. Recently, works like DynaBench (Kiela et al., 2021)
and CheckList (Ribeiro et al., 2020) have addressed these limitations through
behavioral testing of NLP models with test types generated by a multistep
human-annotated pipeline. Unfortunately, manually creating a variety of test
types requires much human labor, often at prohibitive cost. In this work, we
propose SYNTHEVAL, a hybrid behavioral testing framework that leverages large
language models (LLMs) to generate a wide range of test types for a
comprehensive evaluation of NLP models. SYNTHEVAL first generates sentences via
LLMs using controlled generation, and then identifies challenging examples by
comparing the predictions made by LLMs with task-specific NLP models. In the
last stage, human experts investigate the challenging examples, manually design
templates, and identify the types of failures the taskspecific models
consistently exhibit. We apply SYNTHEVAL to two classification tasks, sentiment
analysis and toxic language detection, and show that our framework is effective
in identifying weaknesses of strong models on these tasks. We share our code in
https://github.com/Loreley99/SynthEval_CheckList.

摘要：傳統的 NLP 基準測試通常涉及使用靜態保留的測試組。然而，此方法通常會導致高估效能，且缺乏提供全面、可解釋和動態的 NLP 模型評估的能力。最近，如 DynaBench（Kiela 等人，2021）和 CheckList（Ribeiro 等人，2020）等著作已透過行為測試 NLP 模型（測試類型由多步驟人工標註管道產生）來解決這些限制。不幸的是，手動建立各種測試類型需要大量人工，通常成本高昂。在這項工作中，我們提出 SYNTHEVAL，這是一個混合行為測試架構，它利用大型語言模型 (LLM) 為 NLP 模型的全面評估產生廣泛的測試類型。SYNTHEVAL 首先透過受控產生使用 LLM 產生句子，然後透過比較 LLM 做出的預測與特定任務 NLP 模型所做的預測，來找出具有挑戰性的範例。在最後階段，人類專家會調查具有挑戰性的範例，手動設計範本，並找出特定任務模型持續展現的失敗類型。我們將 SYNTHEVAL 套用於兩個分類任務，即情緒分析和有害語言偵測，並顯示我們的架構在找出這些任務上強大模型的弱點時非常有效。我們在 https://github.com/Loreley99/SynthEval_CheckList 分享我們的程式碼。

##### **Advancing Multi-talker ASR Performance with Large Language Models**
2408.17431v1 by Mohan Shi, Zengrui Jin, Yaoxun Xu, Yong Xu, Shi-Xiong Zhang, Kun Wei, Yiwen Shao, Chunlei Zhang, Dong Yu

Recognizing overlapping speech from multiple speakers in conversational
scenarios is one of the most challenging problem for automatic speech
recognition (ASR). Serialized output training (SOT) is a classic method to
address multi-talker ASR, with the idea of concatenating transcriptions from
multiple speakers according to the emission times of their speech for training.
However, SOT-style transcriptions, derived from concatenating multiple related
utterances in a conversation, depend significantly on modeling long contexts.
Therefore, compared to traditional methods that primarily emphasize encoder
performance in attention-based encoder-decoder (AED) architectures, a novel
approach utilizing large language models (LLMs) that leverages the capabilities
of pre-trained decoders may be better suited for such complex and challenging
scenarios. In this paper, we propose an LLM-based SOT approach for multi-talker
ASR, leveraging pre-trained speech encoder and LLM, fine-tuning them on
multi-talker dataset using appropriate strategies. Experimental results
demonstrate that our approach surpasses traditional AED-based methods on the
simulated dataset LibriMix and achieves state-of-the-art performance on the
evaluation set of the real-world dataset AMI, outperforming the AED model
trained with 1000 times more supervised data in previous works.

摘要：識別對話場景中多位說話者的重疊語音是自動語音辨識 (ASR) 最具挑戰性的問題之一。序列化輸出訓練 (SOT) 是一種用於處理多說話者 ASR 的經典方法，其概念是根據說話者的發話時間，將多位說話者的轉錄內容串接起來進行訓練。然而，從對話中串接多個相關語句而衍生的 SOT 風格轉錄內容，高度依賴於對長語境的建模。因此，與傳統方法（主要強調注意力式編碼器-解碼器 (AED) 架構中編碼器的效能）相比，一種利用大型語言模型 (LLM) 的新穎方法（該方法運用預先訓練解碼器的功能），可能更適合這種複雜且具挑戰性的場景。在本文中，我們提出了一種基於 LLM 的 SOT 方法，用於多說話者 ASR，該方法運用預先訓練的語音編碼器和 LLM，並使用適當的策略對多說話者資料集進行微調。實驗結果表明，我們的方法在模擬資料集 LibriMix 上超越了傳統的基於 AED 的方法，並在真實世界資料集 AMI 的評估集上取得了最先進的效能，優於先前工作中使用多 1000 倍監督資料訓練的 AED 模型。

##### **CLOCR-C: Context Leveraging OCR Correction with Pre-trained Language Models**
2408.17428v1 by Jonathan Bourne

The digitisation of historical print media archives is crucial for increasing
accessibility to contemporary records. However, the process of Optical
Character Recognition (OCR) used to convert physical records to digital text is
prone to errors, particularly in the case of newspapers and periodicals due to
their complex layouts. This paper introduces Context Leveraging OCR Correction
(CLOCR-C), which utilises the infilling and context-adaptive abilities of
transformer-based language models (LMs) to improve OCR quality. The study aims
to determine if LMs can perform post-OCR correction, improve downstream NLP
tasks, and the value of providing the socio-cultural context as part of the
correction process. Experiments were conducted using seven LMs on three
datasets: the 19th Century Serials Edition (NCSE) and two datasets from the
Overproof collection. The results demonstrate that some LMs can significantly
reduce error rates, with the top-performing model achieving over a 60%
reduction in character error rate on the NCSE dataset. The OCR improvements
extend to downstream tasks, such as Named Entity Recognition, with increased
Cosine Named Entity Similarity. Furthermore, the study shows that providing
socio-cultural context in the prompts improves performance, while misleading
prompts lower performance. In addition to the findings, this study releases a
dataset of 91 transcribed articles from the NCSE, containing a total of 40
thousand words, to support further research in this area. The findings suggest
that CLOCR-C is a promising approach for enhancing the quality of existing
digital archives by leveraging the socio-cultural information embedded in the
LMs and the text requiring correction.

摘要：<paragraph>歷史印刷媒體檔案的數位化對於增加對當代記錄的可存取性至關重要。然而，用於將實體記錄轉換為數位文字的光學字元辨識 (OCR) 處理容易出錯，特別是報紙和期刊由於其複雜的版面設計。本文介紹了情境槓桿 OCR 校正 (CLOCR-C)，它利用基於轉換器的語言模型 (LM) 的填補和情境適應能力來提升 OCR 品質。本研究旨在確定 LM 是否可以執行 OCR 後校正、改善下游 NLP 任務，以及在校正過程中提供社會文化情境的價值。使用七個 LM 對三個資料集進行了實驗：19 世紀連續出版品版本 (NCSE) 和 Overproof 蒐藏中的兩個資料集。結果表明，某些 LM 可以顯著降低錯誤率，表現最佳的模型在 NCSE 資料集上的字元錯誤率降低了 60% 以上。OCR 改進延伸到下游任務，例如命名實體辨識，並提高了餘弦命名實體相似度。此外，本研究表明在提示中提供社會文化情境會提升效能，而誤導性提示則會降低效能。除了這些發現外，本研究還發布了一個包含 91 篇來自 NCSE 的轉錄文章的資料集，總共包含 40,000 個字，以支持此領域的進一步研究。這些發現表明，CLOCR-C 是一項有前景的方法，可以透過利用 LM 中嵌入的社會文化資訊和需要校正的文字來提升現有數位檔案的品質。</paragraph>

##### **Open-vocabulary Temporal Action Localization using VLMs**
2408.17422v2 by Naoki Wake, Atsushi Kanehira, Kazuhiro Sasabuchi, Jun Takamatsu, Katsushi Ikeuchi

Video action localization aims to find timings of a specific action from a
long video. Although existing learning-based approaches have been successful,
those require annotating videos that come with a considerable labor cost. This
paper proposes a learning-free, open-vocabulary approach based on emerging
off-the-shelf vision-language models (VLM). The challenge stems from the fact
that VLMs are neither designed to process long videos nor tailored for finding
actions. We overcome these problems by extending an iterative visual prompting
technique. Specifically, we sample video frames into a concatenated image with
frame index labels, making a VLM guess a frame that is considered to be closest
to the start/end of the action. Iterating this process by narrowing a sampling
time window results in finding a specific frame of start and end of an action.
We demonstrate that this sampling technique yields reasonable results,
illustrating a practical extension of VLMs for understanding videos. A sample
code is available at
https://microsoft.github.io/VLM-Video-Action-Localization/.

摘要：影片動作定位旨在從長影片中找出特定動作的時間點。儘管現有的基於學習的方法已成功，但這些方法需要註解影片，而這需要大量的勞動力成本。本文提出了一個免學習、開放詞彙的方法，該方法基於新興的現成視覺語言模型 (VLM)。挑戰在於 VLM 既不是設計來處理長影片，也不是專門用來尋找動作。我們透過擴充反覆視覺提示技術來克服這些問題。具體來說，我們將影片幀採樣成一個串聯影像，並加上幀索引標籤，讓 VLM 猜測被認為最接近動作開始/結束的幀。透過縮小採樣時間視窗來反覆這個程序，可以找到動作開始和結束的特定幀。我們證明了這種採樣技術產生了合理的結果，說明了 VLM 在理解影片方面的實用擴充。範例程式碼可在 https://microsoft.github.io/VLM-Video-Action-Localization/ 取得。

##### **Getting Inspiration for Feature Elicitation: App Store- vs. LLM-based Approach**
2408.17404v1 by Jialiang Wei, Anne-Lise Courbis, Thomas Lambolais, Binbin Xu, Pierre Louis Bernard, Gérard Dray, Walid Maalej

Over the past decade, app store (AppStore)-inspired requirements elicitation
has proven to be highly beneficial. Developers often explore competitors' apps
to gather inspiration for new features. With the advance of Generative AI,
recent studies have demonstrated the potential of large language model
(LLM)-inspired requirements elicitation. LLMs can assist in this process by
providing inspiration for new feature ideas. While both approaches are gaining
popularity in practice, there is a lack of insight into their differences. We
report on a comparative study between AppStore- and LLM-based approaches for
refining features into sub-features. By manually analyzing 1,200 sub-features
recommended from both approaches, we identified their benefits, challenges, and
key differences. While both approaches recommend highly relevant sub-features
with clear descriptions, LLMs seem more powerful particularly concerning novel
unseen app scopes. Moreover, some recommended features are imaginary with
unclear feasibility, which suggests the importance of a human-analyst in the
elicitation loop.

摘要：在過去十年中，應用程式商店 (AppStore) 靈感所激發的需求引導已被證實具有高度益處。開發人員經常探索競爭對手的應用程式，以收集新功能的靈感。隨著生成式 AI 的進步，最近的研究已展示出大型語言模型 (LLM) 靈感所激發的需求引導的潛力。LLM 可藉由提供新功能點子的靈感來協助此流程。雖然這兩種方法在實務上都越來越受到歡迎，但對於它們之間的差異卻缺乏見解。我們針對 AppStore 和 LLM 為基礎的方法進行比較研究，以將功能精煉成子功能。透過人工分析兩種方法所建議的 1,200 個子功能，我們找出它們的優點、挑戰和主要差異。雖然兩種方法都建議具備明確說明的高度相關子功能，但 LLM 似乎更強大，特別是在新穎且前所未見的應用程式範圍方面。此外，有些建議功能是想像中的，且可行性不明確，這表示在引導迴圈中加入人類分析師的重要性。

##### **Exploring the Effect of Explanation Content and Format on User Comprehension and Trust**
2408.17401v1 by Antonio Rago, Bence Palfi, Purin Sukpanichnant, Hannibal Nabli, Kavyesh Vivek, Olga Kostopoulou, James Kinross, Francesca Toni

In recent years, various methods have been introduced for explaining the
outputs of "black-box" AI models. However, it is not well understood whether
users actually comprehend and trust these explanations. In this paper, we focus
on explanations for a regression tool for assessing cancer risk and examine the
effect of the explanations' content and format on the user-centric metrics of
comprehension and trust. Regarding content, we experiment with two explanation
methods: the popular SHAP, based on game-theoretic notions and thus potentially
complex for everyday users to comprehend, and occlusion-1, based on feature
occlusion which may be more comprehensible. Regarding format, we present SHAP
explanations as charts (SC), as is conventional, and occlusion-1 explanations
as charts (OC) as well as text (OT), to which their simpler nature also lends
itself. The experiments amount to user studies questioning participants, with
two different levels of expertise (the general population and those with some
medical training), on their subjective and objective comprehension of and trust
in explanations for the outputs of the regression tool. In both studies we
found a clear preference in terms of subjective comprehension and trust for
occlusion-1 over SHAP explanations in general, when comparing based on content.
However, direct comparisons of explanations when controlling for format only
revealed evidence for OT over SC explanations in most cases, suggesting that
the dominance of occlusion-1 over SHAP explanations may be driven by a
preference for text over charts as explanations. Finally, we found no evidence
of a difference between the explanation types in terms of objective
comprehension. Thus overall, the choice of the content and format of
explanations needs careful attention, since in some contexts format, rather
than content, may play the critical role in improving user experience.

摘要：<paragraph>近年來，已經引進各種方法來解釋「黑箱」AI 模型的輸出。然而，目前並不清楚使用者是否實際理解和信任這些解釋。在本文中，我們專注於評估癌症風險的回歸工具的解釋，並探討解釋的內容和格式對以使用者為中心的理解和信任指標的影響。關於內容，我們實驗了兩種解釋方法：流行的 SHAP，基於博弈論概念，因此對於日常使用者來說可能很複雜，以及基於特徵遮蔽的 occlusion-1，可能更易於理解。關於格式，我們將 SHAP 解釋呈現為圖表 (SC)，這是慣例，而將 occlusion-1 解釋呈現為圖表 (OC) 以及文字 (OT)，其較為簡單的性質也適用於此。這些實驗等同於使用者研究，詢問參與者，具有兩種不同程度的專業知識（一般民眾和具備一些醫學訓練的人），他們對回歸工具輸出解釋的主觀和客觀理解和信任。在兩項研究中，我們發現，在基於內容進行比較時，一般來說，occlusion-1 優於 SHAP 解釋，在主觀理解和信任方面有明顯的偏好。然而，在僅控制格式的情況下直接比較解釋，在大多數情況下只顯示 OT 優於 SC 解釋的證據，這表明 occlusion-1 優於 SHAP 解釋的主導地位可能是由偏好文字而非圖表作為解釋所驅動的。最後，我們沒有發現解釋類型在客觀理解方面的差異證據。因此，總體而言，對解釋的內容和格式的選擇需要仔細注意，因為在某些情況下，格式而非內容，可能在改善使用者體驗方面發揮關鍵作用。</paragraph>

##### **MoRe Fine-Tuning with 10x Fewer Parameters**
2408.17383v1 by Wenxuan Tan, Nicholas Roberts, Tzu-Heng Huang, Jitian Zhao, John Cooper, Samuel Guo, Chengyu Duan, Frederic Sala

Parameter-efficient fine-tuning (PEFT) techniques have unlocked the potential
to cheaply and easily specialize large pretrained models. However, the most
prominent approaches, like low-rank adapters (LoRA), depend on heuristics or
rules-of-thumb for their architectural choices -- potentially limiting their
performance for new models and architectures. This limitation suggests that
techniques from neural architecture search could be used to obtain optimal
adapter architectures, but these are often expensive and difficult to
implement. We address this challenge with Monarch Rectangular Fine-tuning
(MoRe), a simple framework to search over adapter architectures that relies on
the Monarch matrix class. Theoretically, we show that MoRe is more expressive
than LoRA. Empirically, our approach is more parameter-efficient and performant
than state-of-the-art PEFTs on a range of tasks and models, with as few as 5\%
of LoRA's parameters.

摘要：參數有效微調 (PEFT) 技術已釋放了以低成本且輕鬆的方式對大型預訓練模型進行專業化的潛力。然而，最顯著的方法，例如低秩適配器 (LoRA)，依賴於經驗法則或架構選擇的經驗法則——這可能會限制其在新的模型和架構中的效能。此限制表明可以利用神經架構搜尋的技術來取得最佳的適配器架構，但這些技術通常成本高且難以執行。我們透過 Monarch 矩形微調 (MoRe) 來解決此挑戰，這是一個簡單的架構，用於搜尋依賴於 Monarch 矩陣類別的適配器架構。理論上，我們展示 MoRe 比 LoRA 更具表現力。根據經驗，我們的做法比最先進的 PEFT 在一系列任務和模型上更具參數效率和效能，LoRA 的參數少至 5%。

##### **Traffic expertise meets residual RL: Knowledge-informed model-based residual reinforcement learning for CAV trajectory control**
2408.17380v1 by Zihao Sheng, Zilin Huang, Sikai Chen

Model-based reinforcement learning (RL) is anticipated to exhibit higher
sample efficiency compared to model-free RL by utilizing a virtual environment
model. However, it is challenging to obtain sufficiently accurate
representations of the environmental dynamics due to uncertainties in complex
systems and environments. An inaccurate environment model may degrade the
sample efficiency and performance of model-based RL. Furthermore, while
model-based RL can improve sample efficiency, it often still requires
substantial training time to learn from scratch, potentially limiting its
advantages over model-free approaches. To address these challenges, this paper
introduces a knowledge-informed model-based residual reinforcement learning
framework aimed at enhancing learning efficiency by infusing established expert
knowledge into the learning process and avoiding the issue of beginning from
zero. Our approach integrates traffic expert knowledge into a virtual
environment model, employing the Intelligent Driver Model (IDM) for basic
dynamics and neural networks for residual dynamics, thus ensuring adaptability
to complex scenarios. We propose a novel strategy that combines traditional
control methods with residual RL, facilitating efficient learning and policy
optimization without the need to learn from scratch. The proposed approach is
applied to CAV trajectory control tasks for the dissipation of stop-and-go
waves in mixed traffic flow. Experimental results demonstrate that our proposed
approach enables the CAV agent to achieve superior performance in trajectory
control compared to the baseline agents in terms of sample efficiency, traffic
flow smoothness and traffic mobility. The source code and supplementary
materials are available at https://github.com/zihaosheng/traffic-expertise-RL/.

摘要：<paragraph>基於模型的強化學習 (RL) 預期將展現比無模型 RL 更高的範例效率，方法是利用虛擬環境模型。然而，由於複雜系統和環境的不確定性，取得環境動態的充分精確表徵具有挑戰性。不精確的環境模型可能會降低基於模型的 RL 的範例效率和效能。此外，雖然基於模型的 RL 能夠提升範例效率，但它通常仍需要大量的訓練時間才能從頭開始學習，這可能會限制其優於無模型方法的優勢。為了應對這些挑戰，本文引入了一個知識資訊的基於模型的殘差強化學習架構，旨在透過在學習過程中注入既定的專家知識並避免從零開始的問題，來增強學習效率。我們的做法將交通專家知識整合到虛擬環境模型中，採用智慧駕駛員模型 (IDM) 來進行基本動態，並採用神經網路來進行殘差動態，從而確保對複雜場景的適應性。我們提出了一種新的策略，將傳統控制方法與殘差 RL 結合起來，促進了有效率的學習和策略最佳化，無需從頭開始學習。所提出的方法被應用於 CAV 軌跡控制任務，以消除混合交通流中的走走停停波。實驗結果表明，與基準代理相比，我們提出的方法使 CAV 代理在軌跡控制方面實現了優異的效能，在範例效率、交通流順暢度和交通流動性方面表現出色。原始程式碼和補充材料可在 https://github.com/zihaosheng/traffic-expertise-RL/ 取得。</paragraph>

##### **EMPOWER: Embodied Multi-role Open-vocabulary Planning with Online Grounding and Execution**
2408.17379v1 by Francesco Argenziano, Michele Brienza, Vincenzo Suriani, Daniele Nardi, Domenico D. Bloisi

Task planning for robots in real-life settings presents significant
challenges. These challenges stem from three primary issues: the difficulty in
identifying grounded sequences of steps to achieve a goal; the lack of a
standardized mapping between high-level actions and low-level commands; and the
challenge of maintaining low computational overhead given the limited resources
of robotic hardware. We introduce EMPOWER, a framework designed for
open-vocabulary online grounding and planning for embodied agents aimed at
addressing these issues. By leveraging efficient pre-trained foundation models
and a multi-role mechanism, EMPOWER demonstrates notable improvements in
grounded planning and execution. Quantitative results highlight the
effectiveness of our approach, achieving an average success rate of 0.73 across
six different real-life scenarios using a TIAGo robot.

摘要：現實生活中機器人的任務規劃面臨重大挑戰。這些挑戰源自三個主要問題：難以找出實現目標的接地步驟序列；高層級動作與低層級命令之間缺乏標準化對應；以及在機器人硬體資源有限的情況下，維持低運算負擔的挑戰。我們引入了 EMPOWER，一個專為具身代理人的開放詞彙線上接地和規劃而設計的架構，旨在解決這些問題。透過利用高效的預訓練基礎模型和多角色機制，EMPOWER 在接地規劃和執行方面展示出顯著的進步。定量結果突顯了我們方法的有效性，使用 TIAGo 機器人，在六種不同的現實生活場景中，平均成功率達到 0.73。

##### **NDP: Next Distribution Prediction as a More Broad Target**
2408.17377v1 by Junhao Ruan, Abudukeyumu Abudula, Xinyu Liu, Bei Li, Yinqiao Li, Chenglong Wang, Yuchun Fan, Yuan Ge, Tong Xiao, Jingbo Zhu

Large language models (LLMs) trained on next-token prediction (NTP) paradigm
have demonstrated powerful capabilities. However, the existing NTP paradigm
contains several limitations, particularly related to planned task
complications and error propagation during inference. In our work, we extend
the critique of NTP, highlighting its limitation also due to training with a
narrow objective: the prediction of a sub-optimal one-hot distribution. To
support this critique, we conducted a pre-experiment treating the output
distribution from powerful LLMs as efficient world data compression. By
evaluating the similarity between the $n$-gram distribution and the one-hot
distribution with LLMs, we observed that the $n$-gram distributions align more
closely with the output distribution of LLMs. Based on this insight, we
introduce Next Distribution Prediction (NDP), which uses $n$-gram distributions
to replace the one-hot targets, enhancing learning without extra online
training time. We conducted experiments across translation, general task,
language transfer, and medical domain adaptation. Compared to NTP, NDP can
achieve up to +2.97 COMET improvement in translation tasks, +0.61 average
improvement in general tasks, and incredible +10.75 average improvement in the
medical domain. This demonstrates the concrete benefits of addressing the
target narrowing problem, pointing to a new direction for future work on
improving NTP.

摘要：大型語言模型 (LLM) 根據下一個符號預測 (NTP) 範例進行訓練，已展現強大的功能。然而，現有的 NTP 範例包含了幾個限制，特別是與計畫任務複雜性和推論期間的錯誤傳播有關。在我們的研究中，我們擴展了 NTP 的批判，強調其限制也由於使用狹隘的目標進行訓練：預測次佳的一熱分佈。為了支持這項批判，我們進行了一個前置實驗，將強大 LLM 的輸出分佈視為有效的世界資料壓縮。透過評估 $n$-gram 分佈與 LLM 的一熱分佈之間的相似性，我們觀察到 $n$-gram 分佈與 LLM 的輸出分佈更為接近。基於這個見解，我們引入了下一個分佈預測 (NDP)，它使用 $n$-gram 分佈來取代一熱目標，在沒有額外線上訓練時間的情況下，加強學習。我們進行了翻譯、一般任務、語言轉移和醫學領域適應的實驗。與 NTP 相比，NDP 在翻譯任務中可以達到 +2.97 COMET 改進，在一般任務中平均改進 +0.61，在醫學領域中令人難以置信的平均改進 +10.75。這證明了解決目標收窄問題的具體好處，指出了改進 NTP 未來工作的全新方向。

##### **Leveraging Graph Neural Networks to Forecast Electricity Consumption**
2408.17366v1 by Eloi Campagne, Yvenn Amara-Ouali, Yannig Goude, Argyris Kalogeratos

Accurate electricity demand forecasting is essential for several reasons,
especially as the integration of renewable energy sources and the transition to
a decentralized network paradigm introduce greater complexity and uncertainty.
The proposed methodology leverages graph-based representations to effectively
capture the spatial distribution and relational intricacies inherent in this
decentralized network structure. This research work offers a novel approach
that extends beyond the conventional Generalized Additive Model framework by
considering models like Graph Convolutional Networks or Graph SAGE. These
graph-based models enable the incorporation of various levels of
interconnectedness and information sharing among nodes, where each node
corresponds to the combined load (i.e. consumption) of a subset of consumers
(e.g. the regions of a country). More specifically, we introduce a range of
methods for inferring graphs tailored to consumption forecasting, along with a
framework for evaluating the developed models in terms of both performance and
explainability. We conduct experiments on electricity forecasting, in both a
synthetic and a real framework considering the French mainland regions, and the
performance and merits of our approach are discussed.

摘要：準確的電力需求預測對於幾個原因來說是必要的，
特別是隨著可再生能源的整合和過渡到
分散式網路範例引入了更大的複雜性和不確定性。
提出的方法利用基於圖形表示來有效
擷取這個分散式網路結構中固有的空間分佈和關係複雜性。這項研究工作提供了一個超越傳統廣義加成模型架構的新穎方法，方法是
考慮圖形卷積網路或圖形 SAGE 等模型。這些
基於圖形的模型能結合不同層級的
節點之間的互連性和資訊共享，其中每個節點
對應於一群消費者（例如一個國家的區域）的合併負載（即消耗）。更具體地說，我們介紹了一系列
用於推論針對消費預測量身打造的圖形的方法，以及一個
用於評估已開發模型在效能和
可解釋性方面的架構。我們在電力預測上進行實驗，在
合成和真實的架構中考慮法國本土區域，並且
討論了我們方法的效能和優點。

##### **Assessing Generative Language Models in Classification Tasks: Performance and Self-Evaluation Capabilities in the Environmental and Climate Change Domain**
2408.17362v1 by Francesca Grasso, Stefano Locci

This paper examines the performance of two Large Language Models (LLMs),
GPT3.5 and Llama2 and one Small Language Model (SLM) Gemma, across three
different classification tasks within the climate change (CC) and environmental
domain. Employing BERT-based models as a baseline, we compare their efficacy
against these transformer-based models. Additionally, we assess the models'
self-evaluation capabilities by analyzing the calibration of verbalized
confidence scores in these text classification tasks. Our findings reveal that
while BERT-based models generally outperform both the LLMs and SLM, the
performance of the large generative models is still noteworthy. Furthermore,
our calibration analysis reveals that although Gemma is well-calibrated in
initial tasks, it thereafter produces inconsistent results; Llama is reasonably
calibrated, and GPT consistently exhibits strong calibration. Through this
research, we aim to contribute to the ongoing discussion on the utility and
effectiveness of generative LMs in addressing some of the planet's most urgent
issues, highlighting their strengths and limitations in the context of ecology
and CC.

摘要：本文探討了兩個大型語言模型 (LLM)，GPT3.5 和 Llama2，以及一個小型語言模型 (SLM) Gemma，在氣候變遷 (CC) 和環境領域中三個不同的分類任務中的表現。使用 BERT 為基礎的模型作為基準，我們比較它們對抗這些基於轉換器的模型的功效。此外，我們透過分析在這些文字分類任務中口頭化信心評分的校準，來評估模型的自我評估能力。我們的發現顯示，雖然基於 BERT 的模型通常優於 LLM 和 SLM，但大型生成模型的表現仍值得注意。此外，我們的校準分析顯示，儘管 Gemma 在初始任務中校準良好，但此後產生的結果不一致；Llama 的校準相當合理，而 GPT 則持續展現強勁的校準。透過這項研究，我們旨在為關於生成式 LM 在解決地球上最迫切問題方面的效用和有效性的持續討論做出貢獻，強調它們在生態和 CC 背景下的優勢和限制。

##### **Forget to Flourish: Leveraging Machine-Unlearning on Pretrained Language Models for Privacy Leakage**
2408.17354v1 by Md Rafi Ur Rashid, Jing Liu, Toshiaki Koike-Akino, Shagufta Mehnaz, Ye Wang

Fine-tuning large language models on private data for downstream applications
poses significant privacy risks in potentially exposing sensitive information.
Several popular community platforms now offer convenient distribution of a
large variety of pre-trained models, allowing anyone to publish without
rigorous verification. This scenario creates a privacy threat, as pre-trained
models can be intentionally crafted to compromise the privacy of fine-tuning
datasets. In this study, we introduce a novel poisoning technique that uses
model-unlearning as an attack tool. This approach manipulates a pre-trained
language model to increase the leakage of private data during the fine-tuning
process. Our method enhances both membership inference and data extraction
attacks while preserving model utility. Experimental results across different
models, datasets, and fine-tuning setups demonstrate that our attacks
significantly surpass baseline performance. This work serves as a cautionary
note for users who download pre-trained models from unverified sources,
highlighting the potential risks involved.

摘要：針對下游應用程式微調大型語言模型的私人資料可能會暴露敏感資訊，造成重大的隱私風險。現在有許多受歡迎的社群平台提供各種預先訓練模型的便利散布，讓任何人都能發佈，而無需嚴格驗證。這個情況會造成隱私威脅，因為預先訓練模型可以被蓄意設計成危害微調資料集的隱私。在這項研究中，我們提出了一種新穎的攻擊技術，使用模型取消學習作為攻擊工具。此方法會操控預先訓練的語言模型，以增加微調過程中私人資料的洩漏。我們的技術同時強化了成員推論和資料萃取攻擊，同時保留模型效用。跨不同模型、資料集和微調設定的實驗結果顯示，我們的攻擊顯著超越基準效能。這項研究對從未驗證來源下載預先訓練模型的使用者提出警示，強調潛在的風險。

##### **rerankers: A Lightweight Python Library to Unify Ranking Methods**
2408.17344v2 by Benjamin Clavié

This paper presents rerankers, a Python library which provides an easy-to-use
interface to the most commonly used re-ranking approaches. Re-ranking is an
integral component of many retrieval pipelines; however, there exist numerous
approaches to it, relying on different implementation methods. rerankers
unifies these methods into a single user-friendly interface, allowing
practitioners and researchers alike to explore different methods while only
changing a single line of Python code. Moreover ,rerankers ensures that its
implementations are done with the fewest dependencies possible, and re-uses the
original implementation whenever possible, guaranteeing that our simplified
interface results in no performance degradation compared to more complex ones.
The full source code and list of supported models are updated regularly and
available at https://github.com/answerdotai/rerankers.

摘要：這篇論文提出了 rerankers，一個 Python 函式庫，它提供了一個易於使用的介面，來使用最常用的重新排序方法。重新排序是許多檢索管線中不可或缺的組成部分；然而，有許多方法可以達成，仰賴不同的實作方式。rerankers 將這些方法統一到一個使用者友善的介面中，讓實務工作者和研究人員都能探索不同的方法，同時只需變更一行 Python 程式碼。此外，rerankers 確保其實作使用最少的依賴關係，並在可能的情況下重複使用原始實作，保證我們簡化的介面不會造成效能下降，與更複雜的介面相比。完整的原始程式碼和支援的模型清單會定期更新，並在 https://github.com/answerdotai/rerankers 提供。

##### **Impact of ChatGPT on the writing style of condensed matter physicists**
2408.17325v1 by Shaojun Xu, Xiaohui Ye, Mengqi Zhang, Pei Wang

We apply a state-of-the-art difference-in-differences approach to estimate
the impact of ChatGPT's release on the writing style of condensed matter papers
on arXiv. Our analysis reveals a statistically significant improvement in the
English quality of abstracts written by non-native English speakers.
Importantly, this improvement remains robust even after accounting for other
potential factors, confirming that it can be attributed to the release of
ChatGPT. This indicates widespread adoption of the tool. Following the release
of ChatGPT, there is a significant increase in the use of unique words, while
the frequency of rare words decreases. Across language families, the changes in
writing style are significant for authors from the Latin and Ural-Altaic
groups, but not for those from the Germanic or other Indo-European groups.

摘要：我們運用最先進的差異中差異法來估計 ChatGPT 的發布對 arXiv 上凝聚態物質論文寫作風格的影響。我們的分析揭示了一個統計上顯著的改善，由非英語母語人士所寫的摘要的英語品質。重要的是，即使在考慮其他潛在因素後，這種改善仍然強勁，這證實了它可以歸因於 ChatGPT 的發布。這表示該工具被廣泛採用。在 ChatGPT 發布後，獨特單詞的使用顯著增加，而罕見單詞的頻率則下降。在語言家族中，拉丁語和烏拉爾-阿爾泰語族作者的寫作風格發生了顯著變化，但日耳曼語或其他印歐語族作者則沒有。

##### **Modularity in Transformers: Investigating Neuron Separability & Specialization**
2408.17324v1 by Nicholas Pochinkov, Thomas Jones, Mohammed Rashidur Rahman

Transformer models are increasingly prevalent in various applications, yet
our understanding of their internal workings remains limited. This paper
investigates the modularity and task specialization of neurons within
transformer architectures, focusing on both vision (ViT) and language (Mistral
7B) models. Using a combination of selective pruning and MoEfication clustering
techniques, we analyze the overlap and specialization of neurons across
different tasks and data subsets. Our findings reveal evidence of task-specific
neuron clusters, with varying degrees of overlap between related tasks. We
observe that neuron importance patterns persist to some extent even in randomly
initialized models, suggesting an inherent structure that training refines.
Additionally, we find that neuron clusters identified through MoEfication
correspond more strongly to task-specific neurons in earlier and later layers
of the models. This work contributes to a more nuanced understanding of
transformer internals and offers insights into potential avenues for improving
model interpretability and efficiency.

摘要：Transformer模型在各種應用中越來越普遍，然而
我們對其內部運作的理解仍然有限。本文
研究了Transformer架構中神經元的模組化和任務專精化，重點關注視覺 (ViT) 和語言 (Mistral
7B) 模型。使用選擇性修剪和 MoE 化群集
技術的組合，我們分析了神經元在不同任務和資料子集中的重疊和專精化。我們的發現揭示了任務特定
神經元群集的證據，相關任務之間存在不同程度的重疊。我們
觀察到神經元重要性模式在某種程度上甚至在隨機
初始化模型中仍然存在，這表明訓練會優化的內在結構。
此外，我們發現透過 MoE 化識別的神經元群集在模型的早期和後續層中與任務特定神經元的對應關係更強。這項工作有助於更細緻地了解
Transformer內部結構，並提供見解以改善
模型的可解釋性和效率。

##### **Investigating Neuron Ablation in Attention Heads: The Case for Peak Activation Centering**
2408.17322v1 by Nicholas Pochinkov, Ben Pasero, Skylar Shibayama

The use of transformer-based models is growing rapidly throughout society.
With this growth, it is important to understand how they work, and in
particular, how the attention mechanisms represent concepts. Though there are
many interpretability methods, many look at models through their neuronal
activations, which are poorly understood. We describe different lenses through
which to view neuron activations, and investigate the effectiveness in language
models and vision transformers through various methods of neural ablation: zero
ablation, mean ablation, activation resampling, and a novel approach we term
'peak ablation'. Through experimental analysis, we find that in different
regimes and models, each method can offer the lowest degradation of model
performance compared to other methods, with resampling usually causing the most
significant performance deterioration. We make our code available at
https://github.com/nickypro/investigating-ablation.

摘要：Transformer模型的使用在整個社會中正快速增長。
隨著這種增長，了解它們如何運作很重要，尤其是注意機制如何表示概念。儘管有許多可解釋的方法，但許多方法透過神經元活化來查看模型，而這方面了解甚少。我們描述了不同的鏡頭，透過這些鏡頭可以查看神經元活化，並透過各種神經消融方法探討語言模型和視覺Transformer的有效性：零消融、平均消融、活化再抽樣，以及我們稱之為「峰值消融」的新方法。透過實驗分析，我們發現，在不同的模式和模型中，與其他方法相比，每種方法都能提供模型效能的最低降低，而再抽樣通常會造成最顯著的效能惡化。我們在 https://github.com/nickypro/investigating-ablation 提供我們的程式碼。

##### **Bridging Domain Knowledge and Process Discovery Using Large Language Models**
2408.17316v1 by Ali Norouzifar, Humam Kourani, Marcus Dees, Wil van der Aalst

Discovering good process models is essential for different process analysis
tasks such as conformance checking and process improvements. Automated process
discovery methods often overlook valuable domain knowledge. This knowledge,
including insights from domain experts and detailed process documentation,
remains largely untapped during process discovery. This paper leverages Large
Language Models (LLMs) to integrate such knowledge directly into process
discovery. We use rules derived from LLMs to guide model construction, ensuring
alignment with both domain knowledge and actual process executions. By
integrating LLMs, we create a bridge between process knowledge expressed in
natural language and the discovery of robust process models, advancing process
discovery methodologies significantly. To showcase the usability of our
framework, we conducted a case study with the UWV employee insurance agency,
demonstrating its practical benefits and effectiveness.

摘要：發現良好的流程模型對於不同的流程分析任務至關重要，例如符合性檢查和流程改進。自動化流程發現方法通常會忽略有價值的領域知識。這種知識，包括來自領域專家的見解和詳細的流程文件，在流程發現過程中仍然很大程度上未被利用。本文利用大型語言模型 (LLM) 將此類知識直接整合到流程發現中。我們使用從 LLM 中衍生的規則來指導模型構建，確保與領域知識和實際流程執行保持一致。通過整合 LLM，我們在以自然語言表達的流程知識和健壯流程模型的發現之間建立了一座橋樑，顯著推動了流程發現方法。為了展示我們框架的可用性，我們與 UWV 員工保險機構進行了一項案例研究，證明了它的實用好處和有效性。

##### **Fair Best Arm Identification with Fixed Confidence**
2408.17313v1 by Alessio Russo, Filippo Vannella

In this work, we present a novel framework for Best Arm Identification (BAI)
under fairness constraints, a setting that we refer to as \textit{F-BAI} (fair
BAI). Unlike traditional BAI, which solely focuses on identifying the optimal
arm with minimal sample complexity, F-BAI also includes a set of fairness
constraints. These constraints impose a lower limit on the selection rate of
each arm and can be either model-agnostic or model-dependent. For this setting,
we establish an instance-specific sample complexity lower bound and analyze the
\textit{price of fairness}, quantifying how fairness impacts sample complexity.
Based on the sample complexity lower bound, we propose F-TaS, an algorithm
provably matching the sample complexity lower bound, while ensuring that the
fairness constraints are satisfied. Numerical results, conducted using both a
synthetic model and a practical wireless scheduling application, show the
efficiency of F-TaS in minimizing the sample complexity while achieving low
fairness violations.

摘要：在這項工作中，我們提出了一個用於最佳臂辨識 (BAI) 的新框架，在公平性約束下，我們將此設定稱為「F-BAI」(公平 BAI)。與僅專注於以最小的樣本複雜度辨識最佳臂的傳統 BAI 不同，F-BAI 也包含一組公平性約束。這些約束對每個臂的選擇率施加了下限，並且可以是與模型無關或依賴模型的。針對此設定，我們建立了一個特定於實例的樣本複雜度下界，並分析「公平性的代價」，量化公平性如何影響樣本複雜度。根據樣本複雜度下界，我們提出 F-TaS，一種演算法可證明與樣本複雜度下界相符，同時確保滿足公平性約束。使用合成模型和實際無線排程應用程式進行的數值結果顯示，F-TaS 在最小化樣本複雜度的同時，還能達成低公平性違規的效率。

##### **Hybridizing Base-Line 2D-CNN Model with Cat Swarm Optimization for Enhanced Advanced Persistent Threat Detection**
2408.17307v1 by Ali M. Bakhiet, Salah A. Aly

In the realm of cyber-security, detecting Advanced Persistent Threats (APTs)
remains a formidable challenge due to their stealthy and sophisticated nature.
This research paper presents an innovative approach that leverages
Convolutional Neural Networks (CNNs) with a 2D baseline model, enhanced by the
cutting-edge Cat Swarm Optimization (CSO) algorithm, to significantly improve
APT detection accuracy. By seamlessly integrating the 2D-CNN baseline model
with CSO, we unlock the potential for unprecedented accuracy and efficiency in
APT detection. The results unveil an impressive accuracy score of $98.4\%$,
marking a significant enhancement in APT detection across various attack
stages, illuminating a path forward in combating these relentless and
sophisticated threats.

摘要：在網路安全領域，由於進階持續性威脅 (APT) 具有隱匿且複雜的本質，因此偵測它們仍然是一項艱鉅的挑戰。本研究論文提出了一種創新的方法，該方法利用具有 2D 基準模型的卷積神經網路 (CNN)，並透過尖端的貓群最佳化 (CSO) 演算法加以強化，以顯著提升 APT 偵測的準確度。透過將 2D-CNN 基準模型與 CSO 無縫整合，我們發揮了前所未有的準確度和效率，用於 APT 偵測的潛力。結果揭示了一個令人印象深刻的準確度分數，為 $98.4\%$，這標誌著在各種攻擊階段中 APT 偵測的顯著提升，照亮了對抗這些無情且複雜威脅的道路。

##### **Stationary Policies are Optimal in Risk-averse Total-reward MDPs with EVaR**
2408.17286v1 by Xihong Su, Marek Petrik, Julien Grand-Clément

Optimizing risk-averse objectives in discounted MDPs is challenging because
most models do not admit direct dynamic programming equations and require
complex history-dependent policies. In this paper, we show that the risk-averse
{\em total reward criterion}, under the Entropic Risk Measure (ERM) and
Entropic Value at Risk (EVaR) risk measures, can be optimized by a stationary
policy, making it simple to analyze, interpret, and deploy. We propose
exponential value iteration, policy iteration, and linear programming to
compute optimal policies. In comparison with prior work, our results only
require the relatively mild condition of transient MDPs and allow for {\em
both} positive and negative rewards. Our results indicate that the total reward
criterion may be preferable to the discounted criterion in a broad range of
risk-averse reinforcement learning domains.

摘要：在打折 MDP 中优化风险规避目标具有挑战性，因为大多数模型不接受直接动态规划方程，并且需要复杂的依赖于历史的策略。在本文中，我们表明在熵风险度量 (ERM) 和风险价值 (EVaR) 风险度量下，风险规避的{\em 总回报标准}可以通过固定策略进行优化，从而使其易于分析、解释和部署。我们提出指数值迭代、策略迭代和线性规划来计算最优策略。与之前的工作相比，我们的结果仅需要瞬态 MDP 的相对温和条件，并且允许{\em 同时}获得正向和负向奖励。我们的结果表明，总回报标准在广泛的风险规避强化学习领域可能优于打折标准。

##### **Flexible and Effective Mixing of Large Language Models into a Mixture of Domain Experts**
2408.17280v1 by Rhui Dih Lee, Laura Wynter, Raghu Kiran Ganti

We present a toolkit for creating low-cost Mixture-of-Domain-Experts (MOE)
from trained models. The toolkit can be used for creating a mixture from models
or from adapters. We perform extensive tests and offer guidance on defining the
architecture of the resulting MOE using the toolkit. A public repository is
available.

摘要：我們提供一個工具組，用於從訓練好的模型建立低成本的 Mixture-of-Domain-Experts (MOE)。此工具組可用於從模型或適配器建立混合體。我們執行廣泛的測試，並提供有關使用工具組定義結果 MOE 架構的指導。已提供公開存放庫。

##### **UrBench: A Comprehensive Benchmark for Evaluating Large Multimodal Models in Multi-View Urban Scenarios**
2408.17267v1 by Baichuan Zhou, Haote Yang, Dairong Chen, Junyan Ye, Tianyi Bai, Jinhua Yu, Songyang Zhang, Dahua Lin, Conghui He, Weijia Li

Recent evaluations of Large Multimodal Models (LMMs) have explored their
capabilities in various domains, with only few benchmarks specifically focusing
on urban environments. Moreover, existing urban benchmarks have been limited to
evaluating LMMs with basic region-level urban tasks under singular views,
leading to incomplete evaluations of LMMs' abilities in urban environments. To
address these issues, we present UrBench, a comprehensive benchmark designed
for evaluating LMMs in complex multi-view urban scenarios. UrBench contains
11.6K meticulously curated questions at both region-level and role-level that
cover 4 task dimensions: Geo-Localization, Scene Reasoning, Scene
Understanding, and Object Understanding, totaling 14 task types. In
constructing UrBench, we utilize data from existing datasets and additionally
collect data from 11 cities, creating new annotations using a cross-view
detection-matching method. With these images and annotations, we then integrate
LMM-based, rule-based, and human-based methods to construct large-scale
high-quality questions. Our evaluations on 21 LMMs show that current LMMs
struggle in the urban environments in several aspects. Even the best performing
GPT-4o lags behind humans in most tasks, ranging from simple tasks such as
counting to complex tasks such as orientation, localization and object
attribute recognition, with an average performance gap of 17.4%. Our benchmark
also reveals that LMMs exhibit inconsistent behaviors with different urban
views, especially with respect to understanding cross-view relations. UrBench
datasets and benchmark results will be publicly available at
https://opendatalab.github.io/UrBench/.

摘要：<paragraph>最近對大型多模態模型 (LMM) 的評估已探討其在各種領域的能力，只有少數基準特別專注於城市環境。此外，現有的城市基準僅限於在單一視圖下使用基本的區域級城市任務來評估 LMM，導致對 LMM 在城市環境中的能力進行不完全的評估。為了解決這些問題，我們提出了 UrBench，這是一個全面的基準，旨在評估複雜的多視圖城市場景中的 LMM。UrBench 包含 11.6K 個精心策劃的問題，既有區域級別，也有角色級別，涵蓋 4 個任務維度：地理定位、場景推理、場景理解和對象理解，總共 14 個任務類型。在構建 UrBench 時，我們利用現有數據集中的數據，並額外從 11 個城市收集數據，使用跨視圖檢測匹配方法創建新的註解。有了這些圖像和註解，我們整合了基於 LMM、基於規則和基於人類的方法來構建大規模的高質量問題。我們對 21 個 LMM 的評估表明，當前的 LMM 在幾個方面在城市環境中掙扎。即使性能最好的 GPT-4o 在大多數任務中也落後於人類，從簡單任務（例如計數）到複雜任務（例如方向、定位和對象屬性識別），平均性能差距為 17.4%。我們的基準還表明，LMM 對不同的城市視圖表現出不一致的行為，尤其是在理解跨視圖關係方面。UrBench 數據集和基準結果將在 https://opendatalab.github.io/UrBench/ 公開。</paragraph>

##### **VisionTS: Visual Masked Autoencoders Are Free-Lunch Zero-Shot Time Series Forecasters**
2408.17253v1 by Mouxiang Chen, Lefei Shen, Zhuo Li, Xiaoyun Joy Wang, Jianling Sun, Chenghao Liu

Foundation models have emerged as a promising approach in time series
forecasting (TSF). Existing approaches either fine-tune large language models
(LLMs) or build large-scale time-series datasets to develop TSF foundation
models. However, these methods face challenges due to the severe cross-domain
gap or in-domain heterogeneity. In this paper, we explore a new road to
building a TSF foundation model from rich and high-quality natural images,
based on the intrinsic similarities between images and time series. To bridge
the gap between the two domains, we reformulate the TSF task as an image
reconstruction task, which is further processed by a visual masked autoencoder
(MAE) self-supervised pre-trained on the ImageNet dataset. Surprisingly,
without further adaptation in the time-series domain, the proposed VisionTS
could achieve superior zero-shot forecasting performance compared to existing
TSF foundation models. With minimal fine-tuning, VisionTS could further improve
the forecasting and achieve state-of-the-art performance in most cases. These
findings suggest that visual models could be a free lunch for TSF and highlight
the potential for future cross-domain research between computer vision and TSF.
Our code is publicly available at https://github.com/Keytoyze/VisionTS.

摘要：基礎模型已成為時間序列預測 (TSF) 中有前途的方法。現有方法會微調大型語言模型 (LLM)，或建立大型時間序列資料集來開發 TSF 基礎模型。然而，這些方法會因嚴重的跨領域差距或領域內異質性而面臨挑戰。在本文中，我們探索了一條從豐富且高品質自然影像建立 TSF 基礎模型的新途徑，基礎是影像和時間序列之間的內在相似性。為了彌合兩個領域之間的差距，我們將 TSF 任務重新表述為影像重建任務，這個任務進一步由在 ImageNet 資料集上預先訓練的視覺遮罩自動編碼器 (MAE) 自我監督處理。令人驚訝的是，在時間序列領域沒有進一步適應的情況下，所提出的 VisionTS 能夠達成優於現有 TSF 基礎模型的零次學習預測效能。透過最小的微調，VisionTS 能夠進一步改善預測，並在大部分情況下達成最先進的效能。這些發現表明視覺模型可能是 TSF 的免費午餐，並強調了電腦視覺和 TSF 之間未來跨領域研究的潛力。我們的程式碼公開於 https://github.com/Keytoyze/VisionTS。

##### **Abstracted Gaussian Prototypes for One-Shot Concept Learning**
2408.17251v1 by Chelsea Zou, Kenneth J. Kurtz

We introduce a cluster-based generative image segmentation framework to
encode higher-level representations of visual concepts based on one-shot
learning inspired by the Omniglot Challenge. The inferred parameters of each
component of a Gaussian Mixture Model (GMM) represent a distinct topological
subpart of a visual concept. Sampling new data from these parameters generates
augmented subparts to build a more robust prototype for each concept, i.e., the
Abstracted Gaussian Prototype (AGP). This framework addresses one-shot
classification tasks using a cognitively-inspired similarity metric and
addresses one-shot generative tasks through a novel AGP-VAE pipeline employing
variational autoencoders (VAEs) to generate new class variants. Results from
human judges reveal that the generative pipeline produces novel examples and
classes of visual concepts that are broadly indistinguishable from those made
by humans. The proposed framework leads to impressive but not state-of-the-art
classification accuracy; thus, the contribution is two-fold: 1) the system is
uniquely low in theoretical and computational complexity and operates in a
completely standalone manner compared while existing approaches draw heavily on
pre-training or knowledge engineering; and 2) in contrast with competing neural
network models, the AGP approach addresses the importance of breadth of task
capability emphasized in the Omniglot challenge (i.e., successful performance
on generative tasks). These two points are critical as we advance toward an
understanding of how learning/reasoning systems can produce viable, robust, and
flexible concepts based on literally nothing more than a single example.

摘要：<paragraph>我們引入一個基於叢集的生成式影像分割架構，以編碼視覺概念的高階表示，其靈感來自 Omniglot 挑戰中的一發學習。高斯混合模型 (GMM) 各個組成部分的推論參數代表視覺概念中一個明確的拓撲子部分。從這些參數中採樣新資料會產生擴增的子部分，以建立每個概念的更穩健原型，即抽象高斯原型 (AGP)。此架構使用認知靈感的相似度量度來處理一發分類任務，並透過採用變異自動編碼器 (VAE) 的新穎 AGP-VAE 管線來處理一發生成任務，以產生新的類別變體。人類評審員的結果顯示，生成管線產生新穎的範例和視覺概念類別，這些範例和類別與人類製作的範例和類別廣泛無法區分。所提出的架構會帶來令人印象深刻但並非最先進的分類準確度；因此，貢獻有兩個面向：1) 與現有方法嚴重依賴於預訓練或知識工程相比，系統在理論和運算複雜度方面獨特地低，並以完全獨立的方式運作；以及 2) 與競爭的神經網路模型相反，AGP 方法解決了 Omniglot 挑戰中強調的任務能力廣度的重要性（即在生成任務上的成功表現）。隨著我們進一步了解學習/推理系統如何僅根據單一範例產生可行、穩健且彈性的概念，這兩點至關重要。</paragraph>

##### **AI-Driven Intrusion Detection Systems (IDS) on the ROAD dataset: A Comparative Analysis for automotive Controller Area Network (CAN)**
2408.17235v1 by Lorenzo Guerra, Linhan Xu, Pavlo Mozharovskyi, Paolo Bellavista, Thomas Chapuis, Guillaume Duc, Van-Tam Nguyen

The integration of digital devices in modern vehicles has revolutionized
automotive technology, enhancing safety and the overall driving experience. The
Controller Area Network (CAN) bus is a central system for managing in-vehicle
communication between the electronic control units (ECUs). However, the CAN
protocol poses security challenges due to inherent vulnerabilities, lacking
encryption and authentication, which, combined with an expanding attack
surface, necessitates robust security measures. In response to this challenge,
numerous Intrusion Detection Systems (IDS) have been developed and deployed.
Nonetheless, an open, comprehensive, and realistic dataset to test the
effectiveness of such IDSs remains absent in the existing literature. This
paper addresses this gap by considering the latest ROAD dataset, containing
stealthy and sophisticated injections. The methodology involves dataset
labelling and the implementation of both state-of-the-art deep learning models
and traditional machine learning models to show the discrepancy in performance
between the datasets most commonly used in the literature and the ROAD dataset,
a more realistic alternative.

摘要：現代車輛中數位裝置的整合徹底改變了汽車技術，提升了安全性與整體駕駛體驗。控制器區域網路 (CAN) 匯流排是管理車輛內電子控制單元 (ECU) 之間通訊的中央系統。然而，CAN 通訊協定由於缺乏加密和驗證等內在弱點，因此會造成安全威脅，而這與不斷擴大的攻擊面相結合，就需要強固的安全措施。為了因應這個挑戰，已經開發並部署了許多入侵偵測系統 (IDS)。儘管如此，現有的文獻中仍然缺少一個開放、全面且真實的資料集，來測試此類 IDS 的效能。本文考量包含隱密且複雜注入的最新 ROAD 資料集，來探討這個差距。方法包含資料集標籤，以及實作最先進的深度學習模型和傳統機器學習模型，以顯示在文獻中使用最頻繁的資料集與 ROAD 資料集（一個更真實的替代方案）之間的效能差異。

##### **A methodological framework for Resilience as a Service (RaaS) in multimodal urban transportation networks**
2408.17233v1 by Sara Jaber, Mostafa Ameli, S. M. Hassan Mahdavi, Neila Bhouri

Public transportation systems are experiencing an increase in commuter
traffic. This increase underscores the need for resilience strategies to manage
unexpected service disruptions, ensuring rapid and effective responses that
minimize adverse effects on stakeholders and enhance the system's ability to
maintain essential functions and recover quickly. This study aims to explore
the management of public transport disruptions through resilience as a service
(RaaS) strategies, developing an optimization model to effectively allocate
resources and minimize the cost for operators and passengers. The proposed
model includes multiple transportation options, such as buses, taxis, and
automated vans, and evaluates them as bridging alternatives to rail-disrupted
services based on factors such as their availability, capacity, speed, and
proximity to the disrupted station. This ensures that the most suitable
vehicles are deployed to maintain service continuity. Applied to a case study
in the Ile de France region, Paris and suburbs, complemented by a microscopic
simulation, the model is compared to existing solutions such as bus bridging
and reserve fleets. The results highlight the model's performance in minimizing
costs and enhancing stakeholder satisfaction, optimizing transport management
during disruptions.

摘要：大眾運輸系統正經歷通勤交通流量的增加。這種增加凸顯出管理意外服務中斷的復原力策略的需求，以確保迅速且有效的應變措施，將對利害關係人的不利影響降至最低，並提升系統維持必要功能和快速復原的能力。本研究旨在透過身為服務 (RaaS) 策略的復原力來探討大眾運輸中斷的管理，開發一個最佳化模型，以有效分配資源，並將營運商和乘客的成本降至最低。所提出的模型包含多種運輸選項，例如公車、計程車和自動駕駛廂型車，並根據其可用性、運量、速度和與中斷車站的距離等因素，將其評估為鐵路中斷服務的替代方案。這可確保部署最合適的車輛來維持服務的連續性。應用於法蘭西島地區（巴黎和郊區）的案例研究，並輔以微觀模擬，將該模型與現有的解決方案（例如公車中繼和後備車隊）進行比較。結果突顯了該模型在降低成本和提升利害關係人滿意度方面的效能，並在中斷期間最佳化運輸管理。

##### **Towards Symbolic XAI -- Explanation Through Human Understandable Logical Relationships Between Features**
2408.17198v1 by Thomas Schnake, Farnoush Rezaei Jafaria, Jonas Lederer, Ping Xiong, Shinichi Nakajima, Stefan Gugler, Grégoire Montavon, Klaus-Robert Müller

Explainable Artificial Intelligence (XAI) plays a crucial role in fostering
transparency and trust in AI systems, where traditional XAI approaches
typically offer one level of abstraction for explanations, often in the form of
heatmaps highlighting single or multiple input features. However, we ask
whether abstract reasoning or problem-solving strategies of a model may also be
relevant, as these align more closely with how humans approach solutions to
problems. We propose a framework, called Symbolic XAI, that attributes
relevance to symbolic queries expressing logical relationships between input
features, thereby capturing the abstract reasoning behind a model's
predictions. The methodology is built upon a simple yet general multi-order
decomposition of model predictions. This decomposition can be specified using
higher-order propagation-based relevance methods, such as GNN-LRP, or
perturbation-based explanation methods commonly used in XAI. The effectiveness
of our framework is demonstrated in the domains of natural language processing
(NLP), vision, and quantum chemistry (QC), where abstract symbolic domain
knowledge is abundant and of significant interest to users. The Symbolic XAI
framework provides an understanding of the model's decision-making process that
is both flexible for customization by the user and human-readable through
logical formulas.

摘要：可解釋人工智慧 (XAI) 在促進人工智慧系統的透明度和信任方面扮演著至關重要的角色，傳統的 XAI 方法通常提供一個抽象層級的解釋，通常以熱點圖的形式突顯單一或多個輸入特徵。然而，我們探討一個模型的抽象推理或問題解決策略是否也可能相關，因為這些策略與人類解決問題的方式更為接近。我們提出一個稱為符號 XAI 的架構，它將相關性歸因於表達輸入特徵之間邏輯關係的符號查詢，從而捕捉模型預測背後的抽象推理。此方法建立在模型預測的簡單但通用的多階分解之上。此分解可以使用基於高階傳播相關性的方法（例如 GNN-LRP）或 XAI 中常用的基於擾動的解釋方法來指定。我們架構的有效性在自然語言處理 (NLP)、視覺和量子化學 (QC) 領域得到證明，這些領域中抽象符號領域知識豐富且對使用者而言非常重要。符號 XAI 架構提供了對模型決策過程的理解，它既可以由使用者靈活自訂，又可以透過邏輯公式讓人讀懂。

##### **Improving Extraction of Clinical Event Contextual Properties from Electronic Health Records: A Comparative Study**
2408.17181v1 by Shubham Agarwal, Thomas Searle, Mart Ratas, Anthony Shek, James Teo, Richard Dobson

Electronic Health Records are large repositories of valuable clinical data,
with a significant portion stored in unstructured text format. This textual
data includes clinical events (e.g., disorders, symptoms, findings, medications
and procedures) in context that if extracted accurately at scale can unlock
valuable downstream applications such as disease prediction. Using an existing
Named Entity Recognition and Linking methodology, MedCAT, these identified
concepts need to be further classified (contextualised) for their relevance to
the patient, and their temporal and negated status for example, to be useful
downstream. This study performs a comparative analysis of various natural
language models for medical text classification. Extensive experimentation
reveals the effectiveness of transformer-based language models, particularly
BERT. When combined with class imbalance mitigation techniques, BERT
outperforms Bi-LSTM models by up to 28% and the baseline BERT model by up to
16% for recall of the minority classes. The method has been implemented as part
of CogStack/MedCAT framework and made available to the community for further
research.

摘要：電子健康記錄是大量有價值的臨床資料的儲存庫，其中大部分儲存在非結構化文字格式中。此文字資料包含臨床事件（例如疾病、症狀、發現、藥物和程序），如果能大規模準確地萃取出來，就能解鎖有價值的下游應用程式，例如疾病預測。使用現有的命名實體辨識和連結方法 MedCAT，這些已辨識的概念需要進一步分類（脈絡化），以便了解它們與病人的相關性，例如它們的時間性和否定狀態，以便在下游應用中發揮作用。本研究對各種自然語言模型進行比較分析，以進行醫學文字分類。廣泛的實驗揭示了基於轉換器的語言模型的有效性，特別是 BERT。當與類別不平衡緩解技術結合使用時，BERT 在召回少數類別方面比 Bi-LSTM 模型高出 28%，比基準 BERT 模型高出 16%。此方法已作為 CogStack/MedCAT 框架的一部分實作，並提供給社群以供進一步研究。

##### **Identifying and Clustering Counter Relationships of Team Compositions in PvP Games for Efficient Balance Analysis**
2408.17180v1 by Chiu-Chou Lin, Yu-Wei Shih, Kuei-Ting Kuo, Yu-Cheng Chen, Chien-Hua Chen, Wei-Chen Chiu, I-Chen Wu

How can balance be quantified in game settings? This question is crucial for
game designers, especially in player-versus-player (PvP) games, where analyzing
the strength relations among predefined team compositions-such as hero
combinations in multiplayer online battle arena (MOBA) games or decks in card
games-is essential for enhancing gameplay and achieving balance. We have
developed two advanced measures that extend beyond the simplistic win rate to
quantify balance in zero-sum competitive scenarios. These measures are derived
from win value estimations, which employ strength rating approximations via the
Bradley-Terry model and counter relationship approximations via vector
quantization, significantly reducing the computational complexity associated
with traditional win value estimations. Throughout the learning process of
these models, we identify useful categories of compositions and pinpoint their
counter relationships, aligning with the experiences of human players without
requiring specific game knowledge. Our methodology hinges on a simple technique
to enhance codebook utilization in discrete representation with a deterministic
vector quantization process for an extremely small state space. Our framework
has been validated in popular online games, including Age of Empires II,
Hearthstone, Brawl Stars, and League of Legends. The accuracy of the observed
strength relations in these games is comparable to traditional pairwise win
value predictions, while also offering a more manageable complexity for
analysis. Ultimately, our findings contribute to a deeper understanding of PvP
game dynamics and present a methodology that significantly improves game
balance evaluation and design.

摘要：如何量化遊戲設定中的平衡？此問題對於遊戲設計師至關重要，特別是在玩家對戰 (PvP) 遊戲中，分析預先定義的團隊組合（例如多人線上戰鬥競技場 (MOBA) 遊戲中的英雄組合或卡牌遊戲中的套牌）之間的強度關係對於提升遊戲體驗和達成平衡至關重要。我們開發了兩種進階指標，超越了簡化的勝率，用於量化零和競爭場景中的平衡。這些指標源自於勝率估計，透過 Bradley-Terry 模型使用強度評分近似值，以及透過向量量化使用反制關係近似值，大幅降低與傳統勝率估計相關的運算複雜度。在這些模型的學習過程中，我們識別出有用的組合類別，並精確找出它們的反制關係，與人類玩家的經驗一致，而不需要特定的遊戲知識。我們的做法基於一個簡單的技術，用於透過一個極小的狀態空間的確定性向量量化程序，提升離散表示中的碼本利用率。我們的架構已在熱門線上遊戲中獲得驗證，包括世紀帝國 II、爐石戰記、荒野亂鬥和英雄聯盟。在這些遊戲中觀察到的強度關係準確度與傳統的成對勝率預測相當，同時也提供了更易於管理的分析複雜度。最終，我們的發現有助於更深入地理解 PvP 遊戲動態，並提出了一種方法，大幅改善遊戲平衡評估和設計。

##### **Codec Does Matter: Exploring the Semantic Shortcoming of Codec for Audio Language Model**
2408.17175v1 by Zhen Ye, Peiwen Sun, Jiahe Lei, Hongzhan Lin, Xu Tan, Zheqi Dai, Qiuqiang Kong, Jianyi Chen, Jiahao Pan, Qifeng Liu, Yike Guo, Wei Xue

Recent advancements in audio generation have been significantly propelled by
the capabilities of Large Language Models (LLMs). The existing research on
audio LLM has primarily focused on enhancing the architecture and scale of
audio language models, as well as leveraging larger datasets, and generally,
acoustic codecs, such as EnCodec, are used for audio tokenization. However,
these codecs were originally designed for audio compression, which may lead to
suboptimal performance in the context of audio LLM. Our research aims to
address the shortcomings of current audio LLM codecs, particularly their
challenges in maintaining semantic integrity in generated audio. For instance,
existing methods like VALL-E, which condition acoustic token generation on text
transcriptions, often suffer from content inaccuracies and elevated word error
rates (WER) due to semantic misinterpretations of acoustic tokens, resulting in
word skipping and errors. To overcome these issues, we propose a
straightforward yet effective approach called X-Codec. X-Codec incorporates
semantic features from a pre-trained semantic encoder before the Residual
Vector Quantization (RVQ) stage and introduces a semantic reconstruction loss
after RVQ. By enhancing the semantic ability of the codec, X-Codec
significantly reduces WER in speech synthesis tasks and extends these benefits
to non-speech applications, including music and sound generation. Our
experiments in text-to-speech, music continuation, and text-to-sound tasks
demonstrate that integrating semantic information substantially improves the
overall performance of language models in audio generation. Our code and demo
are available (Demo: https://x-codec-audio.github.io Code:
https://github.com/zhenye234/xcodec)

摘要：<paragraph>最近在音訊生成方面有顯著進展，主要是受惠於大型語言模型 (LLM) 的功能。現有的音訊 LLM 研究主要集中於增強音訊語言模型的架構和規模，以及利用更大的資料集，一般來說，音訊編解碼器（例如 EnCodec）用於音訊符號化。然而，這些編解碼器最初是為音訊壓縮而設計的，這可能會導致在音訊 LLM 的情況下效能不佳。我們的研究旨在解決當前音訊 LLM 編解碼器的缺點，特別是它們在維持生成音訊中的語義完整性方面的挑戰。例如，現有的方法（例如 VALL-E）會根據文字轉錄對音訊符號產生進行條件化，由於音訊符號的語義誤解，通常會導致內容不準確和字元錯誤率 (WER) 升高，從而導致跳字和錯誤。為了克服這些問題，我們提出了一個簡單但有效的方法，稱為 X-Codec。X-Codec 在殘差向量量化 (RVQ) 階段之前納入了來自預訓練語義編碼器的語義特徵，並在 RVQ 之後引入了語義重建損失。透過增強編解碼器的語義能力，X-Codec 大幅降低了語音合成任務中的 WER，並將這些優點擴展到非語音應用程式，包括音樂和聲音生成。我們在文字轉語音、音樂延續和文字轉聲音任務中的實驗表明，整合語義資訊可以大幅改善語言模型在音訊生成中的整體效能。我們的程式碼和示範可用（示範：https://x-codec-audio.github.io 程式碼：https://github.com/zhenye234/xcodec）</paragraph>

##### **Look, Compare, Decide: Alleviating Hallucination in Large Vision-Language Models via Multi-View Multi-Path Reasoning**
2408.17150v1 by Xiaoye Qu, Jiashuo Sun, Wei Wei, Yu Cheng

Recently, Large Vision-Language Models (LVLMs) have demonstrated impressive
capabilities in multi-modal context comprehension. However, they still suffer
from hallucination problems referring to generating inconsistent outputs with
the image content. To mitigate hallucinations, previous studies mainly focus on
retraining LVLMs with custom datasets. Although effective, they inherently come
with additional computational costs. In this paper, we propose a training-free
framework, \textbf{MVP}, that aims to reduce hallucinations by making the most
of the innate capabilities of the LVLMs via \textbf{M}ulti-\textbf{V}iew
Multi-\textbf{P}ath Reasoning. Specifically, we first devise a multi-view
information-seeking strategy to thoroughly perceive the comprehensive
information in the image, which enriches the general global information
captured by the original vision encoder in LVLMs. Furthermore, during the
answer decoding, we observe that the occurrence of hallucinations has a strong
correlation with the certainty of the answer tokens. Thus, we propose
multi-path reasoning for each information view to quantify and aggregate the
certainty scores for each potential answer among multiple decoding paths and
finally decide the output answer. By fully grasping the information in the
image and carefully considering the certainty of the potential answers when
decoding, our MVP can effectively reduce hallucinations in LVLMs.The extensive
experiments verify that our proposed MVP significantly mitigates the
hallucination problem across four well-known LVLMs. The source code is
available at: \url{https://github.com/GasolSun36/MVP}.

摘要：<paragraph>最近，大型视觉语言模型 (LVLMs) 已在多模态上下文理解中展现出令人印象深刻的能力。然而，它们仍然存在幻觉问题，指的是生成与图像内容不一致的输出。为了减轻幻觉，先前的研究主要专注于使用自定义数据集重新训练 LVLMs。尽管有效，但它们本质上会带来额外的计算成本。在本文中，我们提出了一个免训练框架，即 \textbf{MVP}，其旨在通过利用 LVLMs 的固有能力，通过 \textbf{M}ulti-\textbf{V}iew Multi-\textbf{P}ath Reasoning 来最大程度地减少幻觉。具体来说，我们首先设计了一个多视图信息搜索策略，以彻底感知图像中的综合信息，这丰富了 LVLMs 中原始视觉编码器捕获的一般全局信息。此外，在答案解码期间，我们观察到幻觉的发生与答案标记的确定性有很强的相关性。因此，我们针对每个信息视图提出了多路径推理，以量化和汇总多个解码路径中每个潜在答案的确定性分数，并最终决定输出答案。通过充分掌握图像中的信息，并在解码时仔细考虑潜在答案的确定性，我们的 MVP 可以有效减少 LVLMs 中的幻觉。大量的实验验证了我们提出的 MVP 在四个著名的 LVLMs 中显著减轻了幻觉问题。源代码可在以下位置获得：\url{https://github.com/GasolSun36/MVP}。</paragraph>

##### **Towards Hyper-parameter-free Federated Learning**
2408.17145v1 by Geetika, Drishya Uniyal, Bapi Chatterjee

The adaptive synchronization techniques in federated learning (FL) for scaled
global model updates show superior performance over the vanilla federated
averaging (FedAvg) scheme. However, existing methods employ additional tunable
hyperparameters on the server to determine the scaling factor. A contrasting
approach is automated scaling analogous to tuning-free step-size schemes in
stochastic gradient descent (SGD) methods, which offer competitive convergence
rates and exhibit good empirical performance. In this work, we introduce two
algorithms for automated scaling of global model updates. In our first
algorithm, we establish that a descent-ensuring step-size regime at the clients
ensures descent for the server objective. We show that such a scheme enables
linear convergence for strongly convex federated objectives. Our second
algorithm shows that the average of objective values of sampled clients is a
practical and effective substitute for the objective function value at the
server required for computing the scaling factor, whose computation is
otherwise not permitted. Our extensive empirical results show that the proposed
methods perform at par or better than the popular federated learning algorithms
for both convex and non-convex problems. Our work takes a step towards
designing hyper-parameter-free federated learning.

摘要：在用于大規模全球模型更新的聯合學習 (FL) 中，自適應同步技術展現出優於香草聯合平均 (FedAvg) 計劃的卓越效能。然而，現有方法在伺服器上採用額外的可調整超參數來決定縮放因子。一種對比手法是自動化縮放，類似於隨機梯度下降 (SGD) 方法中無調諧步驟大小的計劃，提供具競爭力的收斂速度，並展現良好的經驗效能。在這項工作中，我們介紹了兩種用於全球模型更新的自動化縮放演算法。在我們的首個演算法中，我們建立了在客戶端確保下降的步驟大小機制，以確保伺服器目標下降。我們展示了此一計劃如何針對強凸聯合目標啟用線性收斂。我們的第二個演算法顯示，取樣客戶端的目標值平均值是伺服器上用於計算縮放因子的目標函數值的實用且有效的替代品，否則不允許計算該值。我們廣泛的經驗結果顯示，所提出的方法在凸和非凸問題上執行時，與熱門的聯合學習演算法表現相同或更好。我們的這項工作朝著設計無超參數聯合學習邁進一步。

##### **VQ4DiT: Efficient Post-Training Vector Quantization for Diffusion Transformers**
2408.17131v1 by Juncan Deng, Shuaiting Li, Zeyu Wang, Hong Gu, Kedong Xu, Kejie Huang

The Diffusion Transformers Models (DiTs) have transitioned the network
architecture from traditional UNets to transformers, demonstrating exceptional
capabilities in image generation. Although DiTs have been widely applied to
high-definition video generation tasks, their large parameter size hinders
inference on edge devices. Vector quantization (VQ) can decompose model weight
into a codebook and assignments, allowing extreme weight quantization and
significantly reducing memory usage. In this paper, we propose VQ4DiT, a fast
post-training vector quantization method for DiTs. We found that traditional VQ
methods calibrate only the codebook without calibrating the assignments. This
leads to weight sub-vectors being incorrectly assigned to the same assignment,
providing inconsistent gradients to the codebook and resulting in a suboptimal
result. To address this challenge, VQ4DiT calculates the candidate assignment
set for each weight sub-vector based on Euclidean distance and reconstructs the
sub-vector based on the weighted average. Then, using the zero-data and
block-wise calibration method, the optimal assignment from the set is
efficiently selected while calibrating the codebook. VQ4DiT quantizes a DiT
XL/2 model on a single NVIDIA A100 GPU within 20 minutes to 5 hours depending
on the different quantization settings. Experiments show that VQ4DiT
establishes a new state-of-the-art in model size and performance trade-offs,
quantizing weights to 2-bit precision while retaining acceptable image
generation quality.

摘要：擴散Transformer模型 (DiT) 已將網路架構從傳統的 UNet 轉換為Transformer，在影像生成方面展現出非凡的能力。儘管 DiT 已廣泛應用於高畫質影片生成任務，但其龐大的參數規模會阻礙邊緣裝置上的推論。向量量化 (VQ) 可以將模型權重分解為碼本和指派，允許極端權重量化並大幅減少記憶體使用量。在本文中，我們提出 VQ4DiT，這是一種針對 DiT 的快速訓練後向量量化方法。我們發現傳統的 VQ 方法只校準碼本，而不校準指派。這導致權重子向量被錯誤地指派給相同的指派，提供不一致的梯度給碼本，並導致次佳結果。為了應對這個挑戰，VQ4DiT 根據歐幾里得距離計算每個權重子向量的候選指派集，並根據加權平均值重建子向量。然後，使用零資料和區塊校準方法，在校準碼本的同時有效地從集合中選擇最佳指派。VQ4DiT 在單一 NVIDIA A100 GPU 上將 DiT XL/2 模型量化到 2 位元精確度，具備可接受的影像生成品質，具體時間取決於不同的量化設定，約在 20 分鐘到 5 小時之間。實驗顯示，VQ4DiT 在模型大小和效能權衡方面建立了新的技術水準。

##### **Controllable Edge-Type-Specific Interpretation in Multi-Relational Graph Neural Networks for Drug Response Prediction**
2408.17129v2 by Xiaodi Li, Jianfeng Gui, Qian Gao, Haoyuan Shi, Zhenyu Yue

Graph Neural Networks have been widely applied in critical decision-making
areas that demand interpretable predictions, leading to the flourishing
development of interpretability algorithms. However, current graph
interpretability algorithms tend to emphasize generality and often overlook
biological significance, thereby limiting their applicability in predicting
cancer drug responses. In this paper, we propose a novel post-hoc
interpretability algorithm for cancer drug response prediction, CETExplainer,
which incorporates a controllable edge-type-specific weighting mechanism. It
considers the mutual information between subgraphs and predictions, proposing a
structural scoring approach to provide fine-grained, biologically meaningful
explanations for predictive models. We also introduce a method for constructing
ground truth based on real-world datasets to quantitatively evaluate the
proposed interpretability algorithm. Empirical analysis on the real-world
dataset demonstrates that CETExplainer achieves superior stability and improves
explanation quality compared to leading algorithms, thereby offering a robust
and insightful tool for cancer drug prediction.

摘要：圖神經網路已廣泛應用於需要可解釋預測的重要決策領域，這導致可解釋性演算法蓬勃發展。然而，目前的圖形可解釋性演算法往往強調普遍性，而經常忽略生物意義，從而限制了它們在預測癌症藥物反應方面的適用性。在本文中，我們提出了一種用於癌症藥物反應預測的新型事後可解釋性演算法 CETExplainer，它結合了一個可控的邊緣類型特定加權機制。它考慮了子圖和預測之間的互信息，提出了一種結構化評分方法，為預測模型提供細緻、生物學上有意義的解釋。我們還介紹了一種基於真實世界資料集構建地面真實的方法，以定量評估所提出的可解釋性演算法。對真實世界資料集的實證分析表明，與領先演算法相比，CETExplainer 達到了更高的穩定性並改進了說明品質，從而為癌症藥物預測提供了一個強大且有見地的工具。

##### **Exploring User Acceptance Of Portable Intelligent Personal Assistants: A Hybrid Approach Using PLS-SEM And fsQCA**
2408.17119v1 by Gustave Florentin Nkoulou Mvondo, Ben Niu

This research explores the factors driving user acceptance of Rabbit R1, a
newly developed portable intelligent personal assistant (PIPA) that aims to
redefine user interaction and control. The study extends the technology
acceptance model (TAM) by incorporating artificial intelligence-specific
factors (conversational intelligence, task intelligence, and perceived
naturalness), user interface design factors (simplicity in information design
and visual aesthetics), and user acceptance and loyalty. Using a purposive
sampling method, we gathered data from 824 users in the US and analyzed the
sample through partial least squares structural equation modeling (PLS-SEM) and
fuzzy set qualitative comparative analysis (fsQCA). The findings reveal that
all hypothesized relationships, including both direct and indirect effects, are
supported. Additionally, fsQCA supports the PLS-SEM findings and identifies
three configurations leading to high and low user acceptance. This research
enriches the literature and provides valuable insights for system designers and
marketers of PIPAs, guiding strategic decisions to foster widespread adoption
and long-term engagement.

摘要：本研究探討了驅動使用者接受 Rabbit R1 的因素，Rabbit R1 是一款新開發的可攜式智慧個人助理 (PIPA)，旨在重新定義使用者互動和控制。此研究透過納入特定於人工智慧的因素（對話智慧、任務智慧和感知自然性）、使用者介面設計因素（資訊設計的簡潔性和視覺美學）以及使用者接受度和忠誠度，來擴充技術接受模式 (TAM)。我們使用目的性抽樣方法，從美國蒐集了 824 位使用者的資料，並透過偏最小平方法結構方程式模型 (PLS-SEM) 和模糊集合定性比較分析 (fsQCA) 來分析樣本。研究結果顯示，所有假設的關係（包括直接和間接影響）都獲得支持。此外，fsQCA 支持 PLS-SEM 的研究結果，並找出導致使用者接受度高和低的 3 種組態。本研究豐富了文獻，並為 PIPA 的系統設計者和行銷人員提供了有價值的見解，引導策略決策以促進廣泛採用和長期參與。

##### **Understanding the User: An Intent-Based Ranking Dataset**
2408.17103v1 by Abhijit Anand, Jurek Leonhardt, V Venktesh, Avishek Anand

As information retrieval systems continue to evolve, accurate evaluation and
benchmarking of these systems become pivotal. Web search datasets, such as MS
MARCO, primarily provide short keyword queries without accompanying intent or
descriptions, posing a challenge in comprehending the underlying information
need. This paper proposes an approach to augmenting such datasets to annotate
informative query descriptions, with a focus on two prominent benchmark
datasets: TREC-DL-21 and TREC-DL-22. Our methodology involves utilizing
state-of-the-art LLMs to analyze and comprehend the implicit intent within
individual queries from benchmark datasets. By extracting key semantic
elements, we construct detailed and contextually rich descriptions for these
queries. To validate the generated query descriptions, we employ crowdsourcing
as a reliable means of obtaining diverse human perspectives on the accuracy and
informativeness of the descriptions. This information can be used as an
evaluation set for tasks such as ranking, query rewriting, or others.

摘要：隨著資訊檢索系統持續演進，這些系統的準確評量與基準測試變得至關重要。網路搜尋資料集（例如 MS MARCO）主要提供簡短的關鍵字查詢，而沒有附帶的意圖或描述，這對理解底層的資訊需求構成挑戰。本文提出了一種擴充此類資料集的方法，以註解有意義的查詢描述，重點放在兩個著名的基準資料集：TREC-DL-21 和 TREC-DL-22。我們的做法包括利用最先進的 LLM 來分析和理解基準資料集中個別查詢中的隱含意圖。透過萃取關鍵的語意元素，我們為這些查詢建構了詳細且語境豐富的描述。為了驗證所產生的查詢描述，我們採用眾包作為取得關於描述準確性和資訊性的多元化人為觀點的可靠方法。這些資訊可用作排名、查詢改寫或其他任務的評量集。

##### **FissionVAE: Federated Non-IID Image Generation with Latent Space and Decoder Decomposition**
2408.17090v1 by Chen Hu, Jingjing Deng, Xianghua Xie, Xiaoke Ma

Federated learning is a machine learning paradigm that enables decentralized
clients to collaboratively learn a shared model while keeping all the training
data local. While considerable research has focused on federated image
generation, particularly Generative Adversarial Networks, Variational
Autoencoders have received less attention. In this paper, we address the
challenges of non-IID (independently and identically distributed) data
environments featuring multiple groups of images of different types.
Specifically, heterogeneous data distributions can lead to difficulties in
maintaining a consistent latent space and can also result in local generators
with disparate texture features being blended during aggregation. We introduce
a novel approach, FissionVAE, which decomposes the latent space and constructs
decoder branches tailored to individual client groups. This method allows for
customized learning that aligns with the unique data distributions of each
group. Additionally, we investigate the incorporation of hierarchical VAE
architectures and demonstrate the use of heterogeneous decoder architectures
within our model. We also explore strategies for setting the latent prior
distributions to enhance the decomposition process. To evaluate our approach,
we assemble two composite datasets: the first combines MNIST and FashionMNIST;
the second comprises RGB datasets of cartoon and human faces, wild animals,
marine vessels, and remote sensing images of Earth. Our experiments demonstrate
that FissionVAE greatly improves generation quality on these datasets compared
to baseline federated VAE models.

摘要：聯邦學習是一種機器學習範例，可讓分散式用戶端在保留所有訓練資料本機的同時，協同學習共享模型。雖然大量研究都集中在聯邦影像生成，特別是生成對抗網路，但變異自動編碼器受到的關注較少。在本文中，我們探討非 IID（獨立同分布）資料環境的挑戰，其中包含多個不同類型的影像群組。具體來說，異質資料分佈可能導致難以維持一致的潛在空間，並且可能導致在聚合期間混合具有不同紋理特徵的本機生成器。我們引入一種新方法 FissionVAE，它分解潛在空間並建構針對個別用戶端群組量身打造的解碼器分支。此方法允許自訂學習，與每個群組的獨特資料分佈保持一致。此外，我們探討了分層 VAE 架構的整合，並展示在我們的模型中使用異質解碼器架構。我們還探索設定潛在先驗分佈的策略，以增強分解過程。為了評估我們的做法，我們組裝了兩個複合資料集：第一個結合了 MNIST 和 FashionMNIST；第二個包含卡通和人臉、野生動物、海上船隻和地球遙測影像的 RGB 資料集。我們的實驗表明，與基線聯邦 VAE 模型相比，FissionVAE 大幅提升了這些資料集的生成品質。

##### **MaFeRw: Query Rewriting with Multi-Aspect Feedbacks for Retrieval-Augmented Large Language Models**
2408.17072v1 by Yujing Wang, Hainan Zhang, Liang Pang, Liang Pang, Hongwei Zheng, Zhiming Zheng

In a real-world RAG system, the current query often involves spoken ellipses
and ambiguous references from dialogue contexts, necessitating query rewriting
to better describe user's information needs. However, traditional context-based
rewriting has minimal enhancement on downstream generation tasks due to the
lengthy process from query rewriting to response generation. Some researchers
try to utilize reinforcement learning with generation feedback to assist the
rewriter, but these sparse rewards provide little guidance in most cases,
leading to unstable training and generation results. We find that user's needs
are also reflected in the gold document, retrieved documents and ground truth.
Therefore, by feeding back these multi-aspect dense rewards to query rewriting,
more stable and satisfactory responses can be achieved. In this paper, we
propose a novel query rewriting method MaFeRw, which improves RAG performance
by integrating multi-aspect feedback from both the retrieval process and
generated results. Specifically, we first use manual data to train a T5 model
for the rewriter initialization. Next, we design three metrics as reinforcement
learning feedback: the similarity between the rewritten query and the gold
document, the ranking metrics, and ROUGE between the generation and the ground
truth. Inspired by RLAIF, we train three kinds of reward models for the above
metrics to achieve more efficient training. Finally, we combine the scores of
these reward models as feedback, and use PPO algorithm to explore the optimal
query rewriting strategy. Experimental results on two conversational RAG
datasets demonstrate that MaFeRw achieves superior generation metrics and more
stable training compared to baselines.

摘要：<paragraph>在真實世界的 RAG 系統中，目前的查詢通常包含對話語境中的口語省略號和模稜兩可的引用，需要查詢改寫才能更準確地描述使用者的資訊需求。然而，傳統的基於語境的改寫由於從查詢改寫到回應產生的過程冗長，因此對下游產生任務的增強效果很小。一些研究人員嘗試利用強化學習和產生回饋來協助改寫器，但這些稀疏的獎勵在多數情況下提供的指導很少，導致訓練和產生結果不穩定。我們發現使用者的需求也反映在黃金文件、檢索文件和基本事實中。因此，透過將這些多面向的密集獎勵回饋到查詢改寫中，可以獲得更穩定且令人滿意的回應。在本文中，我們提出了一種新穎的查詢改寫方法 MaFeRw，它透過整合來自檢索過程和產生結果的多面向回饋來改善 RAG 效能。具體來說，我們首先使用手動資料來訓練 T5 模型，以初始化改寫器。接下來，我們設計了三個指標作為強化學習回饋：改寫查詢與黃金文件之間的相似度、排名指標以及產生結果與基本事實之間的 ROUGE。在 RLAIF 的啟發下，我們訓練了三種類型的獎勵模型，以達成更有效率的訓練。最後，我們將這些獎勵模型的分數結合為回饋，並使用 PPO 演算法來探索最佳的查詢改寫策略。在兩個對話式 RAG 資料集上的實驗結果表明，與基準相比，MaFeRw 達到了優異的產生指標和更穩定的訓練。</paragraph>

##### **Novel-WD: Exploring acquisition of Novel World Knowledge in LLMs Using Prefix-Tuning**
2408.17070v1 by Maxime Méloux, Christophe Cerisara

Teaching new information to pre-trained large language models (PLM) is a
crucial but challenging task. Model adaptation techniques, such as fine-tuning
and parameter-efficient training have been shown to store new facts at a slow
rate; continual learning is an option but is costly and prone to catastrophic
forgetting. This work studies and quantifies how PLM may learn and remember new
world knowledge facts that do not occur in their pre-training corpus, which
only contains world knowledge up to a certain date. To that purpose, we first
propose Novel-WD, a new dataset consisting of sentences containing novel facts
extracted from recent Wikidata updates, along with two evaluation tasks in the
form of causal language modeling and multiple choice questions (MCQ). We make
this dataset freely available to the community, and release a procedure to
later build new versions of similar datasets with up-to-date information. We
also explore the use of prefix-tuning for novel information learning, and
analyze how much information can be stored within a given prefix. We show that
a single fact can reliably be encoded within a single prefix, and that the
prefix capacity increases with its length and with the base model size.

摘要：教導預先訓練好的大型語言模型 (PLM) 新資訊是一項至關重要但具有挑戰性的任務。模型適應技術，例如微調和參數有效訓練，已被證明可以緩慢儲存新事實；持續學習是一種選擇，但成本高昂且容易發生災難性遺忘。本研究探討並量化 PLM 如何學習和記住其預訓練語料庫中未出現的新世界知識事實，而該語料庫僅包含截至特定日期的世界知識。為此，我們首先提出 Novel-WD，這是一個新的資料集，包含從最近的 Wikidata 更新中提取的新事實句子，以及兩種評估任務，採用因果語言模型和多選題 (MCQ) 的形式。我們將此資料集免費提供給社群，並發布一個程序，以便稍後使用最新資訊建立類似資料集的新版本。我們還探討了使用前綴微調進行新資訊學習，並分析了可以在給定前綴中儲存多少資訊。我們表明，單一事實可以可靠地編碼在單一前綴中，並且前綴容量會隨著其長度和基礎模型大小而增加。

##### **Instant Adversarial Purification with Adversarial Consistency Distillation**
2408.17064v2 by Chun Tong Lei, Hon Ming Yam, Zhongliang Guo, Chun Pong Lau

Neural networks, despite their remarkable performance in widespread
applications, including image classification, are also known to be vulnerable
to subtle adversarial noise. Although some diffusion-based purification methods
have been proposed, for example, DiffPure, those methods are time-consuming. In
this paper, we propose One Step Control Purification (OSCP), a diffusion-based
purification model that can purify the adversarial image in one Neural Function
Evaluation (NFE) in diffusion models. We use Latent Consistency Model (LCM) and
ControlNet for our one-step purification. OSCP is computationally friendly and
time efficient compared to other diffusion-based purification methods; we
achieve defense success rate of 74.19\% on ImageNet, only requiring 0.1s for
each purification. Moreover, there is a fundamental incongruence between
consistency distillation and adversarial perturbation. To address this
ontological dissonance, we propose Gaussian Adversarial Noise Distillation
(GAND), a novel consistency distillation framework that facilitates a more
nuanced reconciliation of the latent space dynamics, effectively bridging the
natural and adversarial manifolds. Our experiments show that the GAND does not
need a Full Fine Tune (FFT); PEFT, e.g., LoRA is sufficient.

摘要：儘管神經網路在包括影像分類在內的廣泛應用中表現卓越，但眾所周知，神經網路也容易受到細微對抗性雜訊的影響。雖然已經提出了一些基於擴散的淨化方法，例如 DiffPure，但這些方法非常耗時。在本文中，我們提出了一步控制淨化 (OSCP)，這是一個基於擴散的淨化模型，可以在擴散模型中對抗性影像進行一次神經功能評估 (NFE) 的淨化。我們使用潛在一致性模型 (LCM) 和 ControlNet 進行一步淨化。與其他基於擴散的淨化方法相比，OSCP 在計算上更友善，且更省時；我們在 ImageNet 上達到了 74.19% 的防禦成功率，每次淨化只需 0.1 秒。此外，一致性蒸餾和對抗性擾動之間存在根本的不一致性。為了解決這種本體論上的不協調，我們提出了高斯對抗性雜訊蒸餾 (GAND)，這是一個新穎的一致性蒸餾框架，有助於對潛在空間動態進行更細緻的調和，有效地橋接自然和對抗性流形。我們的實驗表明，GAND 不需要完全微調 (FFT)；PEFT，例如 LoRA 就已經足夠了。

##### **A Survey of the Self Supervised Learning Mechanisms for Vision Transformers**
2408.17059v1 by Asifullah Khan, Anabia Sohail, Mustansar Fiaz, Mehdi Hassan, Tariq Habib Afridi, Sibghat Ullah Marwat, Farzeen Munir, Safdar Ali, Hannan Naseem, Muhammad Zaigham Zaheer, Kamran Ali, Tangina Sultana, Ziaurrehman Tanoli, Naeem Akhter

Deep supervised learning models require high volume of labeled data to attain
sufficiently good results. Although, the practice of gathering and annotating
such big data is costly and laborious. Recently, the application of self
supervised learning (SSL) in vision tasks has gained significant attention. The
intuition behind SSL is to exploit the synchronous relationships within the
data as a form of self-supervision, which can be versatile. In the current big
data era, most of the data is unlabeled, and the success of SSL thus relies in
finding ways to improve this vast amount of unlabeled data available. Thus its
better for deep learning algorithms to reduce reliance on human supervision and
instead focus on self-supervision based on the inherent relationships within
the data. With the advent of ViTs, which have achieved remarkable results in
computer vision, it is crucial to explore and understand the various SSL
mechanisms employed for training these models specifically in scenarios where
there is less label data available. In this survey we thus develop a
comprehensive taxonomy of systematically classifying the SSL techniques based
upon their representations and pre-training tasks being applied. Additionally,
we discuss the motivations behind SSL, review popular pre-training tasks, and
highlight the challenges and advancements in this field. Furthermore, we
present a comparative analysis of different SSL methods, evaluate their
strengths and limitations, and identify potential avenues for future research.

摘要：深度监督学习模型需要大量标记数据才能获得足够好的结果。尽管如此，收集和注释如此大数据的做法既昂贵又费力。最近，自监督学习 (SSL) 在视觉任务中的应用已引起广泛关注。SSL 背后的直觉是利用数据中同步的关系作为一种自监督形式，这可以是多方面的。在当前大数据时代，大多数数据都是未标记的，因此 SSL 的成功依赖于找到方法来改进大量可用的未标记数据。因此，对于深度学习算法来说，最好减少对人工监督的依赖，而专注于基于数据中固有关系的自监督。随着在计算机视觉中取得卓越成果的 ViT 的出现，探索和理解用于训练这些模型的各种 SSL 机制至关重要，尤其是在可用的标签数据较少的情况下。因此，在本次调查中，我们开发了一个全面的分类法，根据 SSL 技术的表示和应用的预训练任务对其进行系统分类。此外，我们讨论了 SSL 背后的动机，回顾了流行的预训练任务，并重点介绍了该领域的挑战和进步。此外，我们对不同的 SSL 方法进行了比较分析，评估了它们的优势和局限性，并确定了未来研究的潜在途径。

##### **From Text to Emotion: Unveiling the Emotion Annotation Capabilities of LLMs**
2408.17026v1 by Minxue Niu, Mimansa Jaiswal, Emily Mower Provost

Training emotion recognition models has relied heavily on human annotated
data, which present diversity, quality, and cost challenges. In this paper, we
explore the potential of Large Language Models (LLMs), specifically GPT4, in
automating or assisting emotion annotation. We compare GPT4 with supervised
models and or humans in three aspects: agreement with human annotations,
alignment with human perception, and impact on model training. We find that
common metrics that use aggregated human annotations as ground truth can
underestimate the performance, of GPT-4 and our human evaluation experiment
reveals a consistent preference for GPT-4 annotations over humans across
multiple datasets and evaluators. Further, we investigate the impact of using
GPT-4 as an annotation filtering process to improve model training. Together,
our findings highlight the great potential of LLMs in emotion annotation tasks
and underscore the need for refined evaluation methodologies.

摘要：訓練情緒辨識模型極度依賴人工標註的資料，這會產生多樣性、品質和成本的挑戰。在本文中，我們探索大型語言模型 (LLM)，特別是 GPT4，在自動化或協助情緒標註方面的潛力。我們在三個方面比較 GPT4 與監督式模型和人類：與人工標註的一致性、與人類感知的一致性，以及對模型訓練的影響。我們發現使用匯總的人工標註作為基本事實的常見指標可能會低估 GPT-4 的效能，而我們的人工評估實驗顯示，在多個資料集和評估者中，GPT-4 標註始終優於人工。此外，我們探討使用 GPT-4 作為標註過濾程序以改善模型訓練的影響。我們的研究結果共同突顯了 LLM 在情緒標註任務中的巨大潛力，並強調需要精進的評估方法。

##### **InkubaLM: A small language model for low-resource African languages**
2408.17024v2 by Atnafu Lambebo Tonja, Bonaventure F. P. Dossou, Jessica Ojo, Jenalea Rajab, Fadel Thior, Eric Peter Wairagala, Anuoluwapo Aremu, Pelonomi Moiloa, Jade Abbott, Vukosi Marivate, Benjamin Rosman

High-resource language models often fall short in the African context, where
there is a critical need for models that are efficient, accessible, and locally
relevant, even amidst significant computing and data constraints. This paper
introduces InkubaLM, a small language model with 0.4 billion parameters, which
achieves performance comparable to models with significantly larger parameter
counts and more extensive training data on tasks such as machine translation,
question-answering, AfriMMLU, and the AfriXnli task. Notably, InkubaLM
outperforms many larger models in sentiment analysis and demonstrates
remarkable consistency across multiple languages. This work represents a
pivotal advancement in challenging the conventional paradigm that effective
language models must rely on substantial resources. Our model and datasets are
publicly available at https://huggingface.co/lelapa to encourage research and
development on low-resource languages.

摘要：高資源語言模型在非洲語境中常常表現不佳，那裡迫切需要在大量運算和資料限制下，能有效率、容易取得且與當地相關的模型。本文介紹 InkubaLM，一個只有 0.4 億個參數的小型語言模型，在機器翻譯、問答、AfriMMLU 和 AfriXnli 等任務上，達到與參數數量大得多且訓練資料更廣泛的模型相當的效能。值得注意的是，InkubaLM 在情緒分析中優於許多較大的模型，並且在多種語言中展現出顯著的一致性。這項工作代表了挑戰傳統觀念的關鍵進展，即有效的語言模型必須依賴於大量的資源。我們的模型和資料集在 https://huggingface.co/lelapa 公開，以鼓勵對低資源語言的研究和開發。

##### **Dynamic Self-Consistency: Leveraging Reasoning Paths for Efficient LLM Sampling**
2408.17017v1 by Guangya Wan, Yuqi Wu, Jie Chen, Sheng Li

Self-Consistency (SC) is a widely used method to mitigate hallucinations in
Large Language Models (LLMs) by sampling the LLM multiple times and outputting
the most frequent solution. Despite its benefits, SC results in significant
computational costs proportional to the number of samples generated. Previous
early-stopping approaches, such as Early Stopping Self Consistency and Adaptive
Consistency, have aimed to reduce these costs by considering output
consistency, but they do not analyze the quality of the reasoning paths (RPs)
themselves. To address this issue, we propose Reasoning-Aware Self-Consistency
(RASC), an innovative early-stopping framework that dynamically adjusts the
number of sample generations by considering both the output answer and the RPs
from Chain of Thought (CoT) prompting. RASC assigns confidence scores
sequentially to the generated samples, stops when certain criteria are met, and
then employs weighted majority voting to optimize sample usage and enhance
answer reliability. We comprehensively test RASC with multiple LLMs across
varied QA datasets. RASC outperformed existing methods and significantly
reduces sample usage by an average of 80% while maintaining or improving
accuracy up to 5% compared to the original SC

摘要：自洽性 (SC) 是一種廣泛使用的減少大型語言模型 (LLM) 中幻覺的方法，方法是多次對 LLM 進行抽樣，並輸出出現頻率最高的解答。儘管有其好處，但 SC 會產生與所產生樣本數量成正比的顯著運算成本。先前的早期停止方法，例如早期停止自洽性和自適應一致性，旨在透過考慮輸出一致性來降低這些成本，但它們並未分析推理路徑 (RP) 本身的品質。為了解決這個問題，我們提出推理感知自洽性 (RASC)，這是一個創新的早期停止架構，透過考慮鏈式思考 (CoT) 提示所產生的輸出答案和 RP，動態調整樣本產生的數量。RASC 會循序漸кратно地為產生的樣本指定信心分數，在符合特定標準時停止，然後採用加權多數投票來最佳化樣本使用率並提升答案的可靠性。我們使用多個 LLM 在各種問答資料集上全面測試 RASC。與現有方法相比，RASC 表現更佳，並顯著降低了 80% 的平均樣本使用率，同時維持或提升了與原始 SC 相比高達 5% 的準確度

##### **Disease Classification and Impact of Pretrained Deep Convolution Neural Networks on Diverse Medical Imaging Datasets across Imaging Modalities**
2408.17011v2 by Jutika Borah, Kumaresh Sarmah, Hidam Kumarjit Singh

Imaging techniques such as Chest X-rays, whole slide images, and optical
coherence tomography serve as the initial screening and detection for a wide
variety of medical pulmonary and ophthalmic conditions respectively. This paper
investigates the intricacies of using pretrained deep convolutional neural
networks with transfer learning across diverse medical imaging datasets with
varying modalities for binary and multiclass classification. We conducted a
comprehensive performance analysis with ten network architectures and model
families each with pretraining and random initialization. Our finding showed
that the use of pretrained models as fixed feature extractors yields poor
performance irrespective of the datasets. Contrary, histopathology microscopy
whole slide images have better performance. It is also found that deeper and
more complex architectures did not necessarily result in the best performance.
This observation implies that the improvements in ImageNet are not parallel to
the medical imaging tasks. Within a medical domain, the performance of the
network architectures varies within model families with shifts in datasets.
This indicates that the performance of models within a specific modality may
not be conclusive for another modality within the same domain. This study
provides a deeper understanding of the applications of deep learning techniques
in medical imaging and highlights the impact of pretrained networks across
different medical imaging datasets under five different experimental settings.

摘要：影像技術，例如胸部 X 光、全切片影像和光學相干斷層掃描，分別作為各種醫學肺部和眼科疾病的初步篩檢和偵測。本文探討了使用預訓練深度卷積神經網路搭配遷移學習，橫跨不同醫療影像資料集，以進行二元和多類別分類的複雜性。我們對十種網路架構和模型系列進行了全面的效能分析，每個架構和系列都經過預訓練和隨機初始化。我們的發現顯示，將預訓練模型用作固定特徵萃取器會產生不佳的效能，與資料集無關。相反地，組織病理學顯微鏡全切片影像有較好的效能。我們也發現，較深且複雜的架構並非一定會產生最佳效能。此觀察結果意味著 ImageNet 的改良並未與醫療影像任務平行。在醫療領域內，網路架構的效能會隨著資料集的轉換而改變模型系列。這表示在特定模式中模型的效能可能無法決定在同一個領域中另一種模式的效能。本研究提供了對深度學習技術在醫療影像中的應用更深入的理解，並強調了預訓練網路在五種不同實驗設定下跨不同醫療影像資料集的影響。

##### **Improving Time Series Classification with Representation Soft Label Smoothing**
2408.17010v1 by Hengyi Ma, Weitong Chen

Previous research has indicated that deep neural network based models for
time series classification (TSC) tasks are prone to overfitting. This issue can
be mitigated by employing strategies that prevent the model from becoming
overly confident in its predictions, such as label smoothing and confidence
penalty. Building upon the concept of label smoothing, we propose a novel
approach to generate more reliable soft labels, which we refer to as
representation soft label smoothing. We apply label smoothing, confidence
penalty, and our method representation soft label smoothing to several TSC
models and compare their performance with baseline method which only uses hard
labels for training. Our results demonstrate that the use of these enhancement
techniques yields competitive results compared to the baseline method.
Importantly, our method demonstrates strong performance across models with
varying structures and complexities.

摘要：先前的研究指出，用於時序分類 (TSC) 任務的深度神經網路模型容易過度擬合。此問題可透過採用策略來緩解，避免模型對其預測過於自信，例如標籤平滑和信心懲罰。基於標籤平滑的概念，我們提出了一種新的方法來產生更可靠的軟標籤，我們稱之為表示式軟標籤平滑。我們將標籤平滑、信心懲罰和我們的表示式軟標籤平滑方法應用於多個 TSC 模型，並將其效能與僅使用硬標籤進行訓練的基準方法進行比較。我們的結果證明，與基準方法相比，使用這些增強技術可產生具競爭力的結果。重要的是，我們的模型在結構和複雜度不同的模型中都展現出強大的效能。

##### **Safety Layers of Aligned Large Language Models: The Key to LLM Security**
2408.17003v1 by Shen Li, Liuyi Yao, Lan Zhang, Yaliang Li

Aligned LLMs are highly secure, capable of recognizing and refusing to answer
malicious questions. However, the role of internal parameters in maintaining
this security is not well understood, further these models are vulnerable to
security degradation when fine-tuned with non-malicious backdoor data or normal
data. To address these challenges, our work uncovers the mechanism behind
security in aligned LLMs at the parameter level, identifying a small set of
contiguous layers in the middle of the model that are crucial for
distinguishing malicious queries from normal ones, referred to as "safety
layers." We first confirm the existence of these safety layers by analyzing
variations in input vectors within the model's internal layers. Additionally,
we leverage the over-rejection phenomenon and parameters scaling analysis to
precisely locate the safety layers. Building on this understanding, we propose
a novel fine-tuning approach, Safely Partial-Parameter Fine-Tuning (SPPFT),
that fixes the gradient of the safety layers during fine-tuning to address the
security degradation. Our experiments demonstrate that this approach
significantly preserves model security while maintaining performance and
reducing computational resources compared to full fine-tuning.

摘要：對齊的 LLM 具有高度安全性，能夠識別和拒絕回答惡意問題。然而，內部參數在維護此安全性中的作用尚未得到充分理解，此外，這些模型在使用非惡意後門數據或正常數據進行微調時容易受到安全性下降的影響。為了應對這些挑戰，我們的研究揭示了參數級別對齊 LLM 中安全性的機制，識別了一組位於模型中間的連續層，這些層對於區分惡意查詢和正常查詢至關重要，稱為「安全層」。我們首先通過分析模型內部層中輸入向量的變化來確認這些安全層的存在。此外，我們利用過度拒絕現象和參數縮放分析來精確定位安全層。基於這種理解，我們提出了一種新穎的微調方法，安全部分參數微調 (SPPFT)，它在微調過程中修復了安全層的梯度，以解決安全性下降問題。我們的實驗表明，與完全微調相比，這種方法顯著地保留了模型安全性，同時保持了性能並減少了計算資源。

##### **Tool-Assisted Agent on SQL Inspection and Refinement in Real-World Scenarios**
2408.16991v1 by Zhongyuan Wang, Richong Zhang, Zhijie Nie, Jaein Kim

Recent Text-to-SQL methods leverage large language models (LLMs) by
incorporating feedback from the database management system. While these methods
effectively address execution errors in SQL queries, they struggle with
database mismatches -- errors that do not trigger execution exceptions.
Database mismatches include issues such as condition mismatches and stricter
constraint mismatches, both of which are more prevalent in real-world
scenarios. To address these challenges, we propose a tool-assisted agent
framework for SQL inspection and refinement, equipping the LLM-based agent with
two specialized tools: a retriever and a detector, designed to diagnose and
correct SQL queries with database mismatches. These tools enhance the
capability of LLMs to handle real-world queries more effectively. We also
introduce Spider-Mismatch, a new dataset specifically constructed to reflect
the condition mismatch problems encountered in real-world scenarios.
Experimental results demonstrate that our method achieves the highest
performance on the averaged results of the Spider and Spider-Realistic datasets
in few-shot settings, and it significantly outperforms baseline methods on the
more realistic dataset, Spider-Mismatch.

摘要：最近的文本到 SQL 方法通过纳入来自数据库管理系统的反馈来利用大型语言模型 (LLM)。虽然这些方法有效地解决了 SQL 查询中的执行错误，但它们在数据库不匹配方面遇到了困难——不会触发执行异常的错误。数据库不匹配包括条件不匹配和更严格的约束不匹配等问题，这两个问题在实际场景中更为普遍。为了应对这些挑战，我们提出了一种工具辅助代理框架，用于 SQL 检查和细化，为基于 LLM 的代理配备了两个专门工具：检索器和检测器，旨在诊断和更正带有数据库不匹配的 SQL 查询。这些工具增强了 LLM 处理实际查询的更有效的能力。我们还引入了 Spider-Mismatch，这是一个专门构建的新数据集，以反映实际场景中遇到的条件不匹配问题。实验结果表明，我们的方法在 Spider 和 Spider-Realistic 数据集的平均结果上实现了最高性能，并且在更现实的数据集 Spider-Mismatch 上明显优于基线方法。

##### **Beyond Preferences in AI Alignment**
2408.16984v1 by Tan Zhi-Xuan, Micah Carroll, Matija Franklin, Hal Ashton

The dominant practice of AI alignment assumes (1) that preferences are an
adequate representation of human values, (2) that human rationality can be
understood in terms of maximizing the satisfaction of preferences, and (3) that
AI systems should be aligned with the preferences of one or more humans to
ensure that they behave safely and in accordance with our values. Whether
implicitly followed or explicitly endorsed, these commitments constitute what
we term a preferentist approach to AI alignment. In this paper, we characterize
and challenge the preferentist approach, describing conceptual and technical
alternatives that are ripe for further research. We first survey the limits of
rational choice theory as a descriptive model, explaining how preferences fail
to capture the thick semantic content of human values, and how utility
representations neglect the possible incommensurability of those values. We
then critique the normativity of expected utility theory (EUT) for humans and
AI, drawing upon arguments showing how rational agents need not comply with
EUT, while highlighting how EUT is silent on which preferences are normatively
acceptable. Finally, we argue that these limitations motivate a reframing of
the targets of AI alignment: Instead of alignment with the preferences of a
human user, developer, or humanity-writ-large, AI systems should be aligned
with normative standards appropriate to their social roles, such as the role of
a general-purpose assistant. Furthermore, these standards should be negotiated
and agreed upon by all relevant stakeholders. On this alternative conception of
alignment, a multiplicity of AI systems will be able to serve diverse ends,
aligned with normative standards that promote mutual benefit and limit harm
despite our plural and divergent values.

摘要：AI 調整的主流做法假設 (1) 偏好充分代表人類價值觀，(2) 人類理性可以用最大化偏好滿足度來理解，(3) AI 系統應與一個或多個人類的偏好保持一致，以確保他們行為安全且符合我們的價值觀。無論是隱含遵循或明確認可，這些承諾構成我們所謂的 AI 調整偏好主義方法。在本文中，我們描述並挑戰偏好主義方法，描述概念和技術替代方案，這些替代方案已成熟，可以進一步研究。我們首先調查理性選擇理論作為描述性模型的局限性，解釋偏好如何無法捕捉人類價值觀的豐富語義內容，以及效用表徵如何忽略這些價值觀可能的不可通約性。然後，我們批判人類和 AI 的期望效用理論 (EUT) 的規範性，引用論點說明理性代理人不必遵守 EUT，同時強調 EUT 對哪些偏好具有規範可接受性保持沉默。最後，我們認為這些限制促使重新界定 AI 調整的目標：AI 系統不應與人類使用者、開發者或廣義人類的偏好保持一致，而應與符合其社會角色的規範標準保持一致，例如一般用途助理的角色。此外，這些標準應由所有相關利益相關者協商並達成一致。在這種替代性的調整概念中，多個 AI 系統將能夠服務於不同的目的，與促進共同利益和限制傷害的規範標準保持一致，儘管我們的價值觀是多元且不同的。

##### **Training Ultra Long Context Language Model with Fully Pipelined Distributed Transformer**
2408.16978v1 by Jinghan Yao, Sam Ade Jacobs, Masahiro Tanaka, Olatunji Ruwase, Aamir Shafi, Hari Subramoni, Dhabaleswar K. Panda

Large Language Models (LLMs) with long context capabilities are integral to
complex tasks in natural language processing and computational biology, such as
text generation and protein sequence analysis. However, training LLMs directly
on extremely long contexts demands considerable GPU resources and increased
memory, leading to higher costs and greater complexity. Alternative approaches
that introduce long context capabilities via downstream finetuning or
adaptations impose significant design limitations. In this paper, we propose
Fully Pipelined Distributed Transformer (FPDT) for efficiently training
long-context LLMs with extreme hardware efficiency. For GPT and Llama models,
we achieve a 16x increase in sequence length that can be trained on the same
hardware compared to current state-of-the-art solutions. With our dedicated
sequence chunk pipeline design, we can now train 8B LLM with 2 million sequence
length on only 4 GPUs, while also maintaining over 55% of MFU. Our proposed
FPDT is agnostic to existing training techniques and is proven to work
efficiently across different LLM models.

摘要：具備長語境能力的大型語言模型 (LLM) 對於自然語言處理和計算生物學中的複雜任務至關重要，例如文本生成和蛋白質序列分析。然而，直接在極長的語境上訓練 LLM 需要大量的 GPU 資源和增加的記憶體，導致更高的成本和更大的複雜性。透過下游微調或適應來引入長語境能力的替代方法會造成重大的設計限制。在本文中，我們提出全管線分散式Transformer (FPDT) 來有效訓練具有極高硬體效率的長語境 LLM。對於 GPT 和 Llama 模型，我們實現了序列長度 16 倍的增長，可以在與當前最先進的解決方案相同的硬體上進行訓練。透過我們專用的序列區塊管線設計，我們現在可以使用僅 4 個 GPU 訓練具有 200 萬序列長度的 8B LLM，同時還維持超過 55% 的 MFU。我們提出的 FPDT 與現有的訓練技術無關，並且已證明可以在不同的 LLM 模型中有效運作。

##### **Technical Report of HelixFold3 for Biomolecular Structure Prediction**
2408.16975v1 by Lihang Liu, Shanzhuo Zhang, Yang Xue, Xianbin Ye, Kunrui Zhu, Yuxin Li, Yang Liu, Xiaonan Zhang, Xiaomin Fang

The AlphaFold series has transformed protein structure prediction with
remarkable accuracy, often matching experimental methods. AlphaFold2,
AlphaFold-Multimer, and the latest AlphaFold3 represent significant strides in
predicting single protein chains, protein complexes, and biomolecular
structures. While AlphaFold2 and AlphaFold-Multimer are open-sourced,
facilitating rapid and reliable predictions, AlphaFold3 remains partially
accessible through a limited online server and has not been open-sourced,
restricting further development. To address these challenges, the PaddleHelix
team is developing HelixFold3, aiming to replicate AlphaFold3's capabilities.
Using insights from previous models and extensive datasets, HelixFold3 achieves
an accuracy comparable to AlphaFold3 in predicting the structures of
conventional ligands, nucleic acids, and proteins. The initial release of
HelixFold3 is available as open source on GitHub for academic research,
promising to advance biomolecular research and accelerate discoveries. We also
provide online service at PaddleHelix website at
https://paddlehelix.baidu.com/app/all/helixfold3/forecast.

摘要：AlphaFold 系列已經以驚人的準確度改變了蛋白質結構預測，通常與實驗方法相匹配。AlphaFold2、AlphaFold-Multimer 和最新的 AlphaFold3 在預測單一蛋白質鏈、蛋白質複合體和生物分子結構方面代表著重大的進展。雖然 AlphaFold2 和 AlphaFold-Multimer 是開源的，可以促進快速和可靠的預測，但 AlphaFold3 仍然部分通過一個有限的線上伺服器訪問，而且還沒有開源，限制了進一步的開發。為了應對這些挑戰，PaddleHelix 團隊正在開發 HelixFold3，目標是複製 AlphaFold3 的功能。HelixFold3 利用先前模型和廣泛數據集的見解，在預測傳統配體、核酸和蛋白質的結構方面達到了與 AlphaFold3 相當的準確度。HelixFold3 的初始版本在 GitHub 上作為開源軟體提供給學術研究，有望推進生物分子研究並加速發現。我們還提供線上服務，網址為 https://paddlehelix.baidu.com/app/all/helixfold3/forecast。

##### **MemLong: Memory-Augmented Retrieval for Long Text Modeling**
2408.16967v1 by Weijie Liu, Zecheng Tang, Juntao Li, Kehai Chen, Min Zhang

Recent advancements in Large Language Models (LLMs) have yielded remarkable
success across diverse fields. However, handling long contexts remains a
significant challenge for LLMs due to the quadratic time and space complexity
of attention mechanisms and the growing memory consumption of the key-value
cache during generation. This work introduces MemLong: Memory-Augmented
Retrieval for Long Text Generation, a method designed to enhance the
capabilities of long-context language modeling by utilizing an external
retriever for historical information retrieval. MemLong combines a
non-differentiable ``ret-mem'' module with a partially trainable decoder-only
language model and introduces a fine-grained, controllable retrieval attention
mechanism that leverages semantic-level relevant chunks. Comprehensive
evaluations on multiple long-context language modeling benchmarks demonstrate
that MemLong consistently outperforms other state-of-the-art LLMs. More
importantly, MemLong can extend the context length on a single 3090 GPU from 4k
up to 80k. Our code is available at https://github.com/Bui1dMySea/MemLong

摘要：大型語言模型 (LLM) 近期的進展在各個領域都取得了顯著的成功。然而，由於注意力機制的二次時間和空間複雜度，以及生成過程中鍵值快取不斷增加的記憶體消耗，處理長語境對於 LLM 來說仍然是一個重大的挑戰。這項工作介紹了 MemLong：長文本生成記憶體擴充檢索，一種透過利用外部檢索器進行歷史資訊檢索來增強長語境語言建模能力的方法。MemLong 將一個不可微分的 ``ret-mem'' 模組與一個部分可訓練的僅解碼器語言模型結合起來，並引入了一種精細且可控的檢索注意力機制，該機制利用了語義層級相關的區塊。在多個長語境語言建模基準上的全面評估表明，MemLong 持續優於其他最先進的 LLM。更重要的是，MemLong 可以將單個 3090 GPU 上的語境長度從 4k 擴展到 80k。我們的程式碼可在 https://github.com/Bui1dMySea/MemLong 取得

##### **UserSumBench: A Benchmark Framework for Evaluating User Summarization Approaches**
2408.16966v1 by Chao Wang, Neo Wu, Lin Ning, Luyang Liu, Jun Xie, Shawn O'Banion, Bradley Green

Large language models (LLMs) have shown remarkable capabilities in generating
user summaries from a long list of raw user activity data. These summaries
capture essential user information such as preferences and interests, and
therefore are invaluable for LLM-based personalization applications, such as
explainable recommender systems. However, the development of new summarization
techniques is hindered by the lack of ground-truth labels, the inherent
subjectivity of user summaries, and human evaluation which is often costly and
time-consuming. To address these challenges, we introduce \UserSumBench, a
benchmark framework designed to facilitate iterative development of LLM-based
summarization approaches. This framework offers two key components: (1) A
reference-free summary quality metric. We show that this metric is effective
and aligned with human preferences across three diverse datasets (MovieLens,
Yelp and Amazon Review). (2) A novel robust summarization method that leverages
time-hierarchical summarizer and self-critique verifier to produce high-quality
summaries while eliminating hallucination. This method serves as a strong
baseline for further innovation in summarization techniques.

摘要：大型語言模型 (LLM) 在根據大量原始使用者活動資料產生使用者摘要方面展現出非凡的能力。這些摘要擷取了使用者的基本資訊，例如偏好和興趣，因此對於基於 LLM 的個人化應用程式來說非常有價值，例如可解釋的推薦系統。然而，新的摘要技術的發展受到缺乏基本事實標籤、使用者摘要固有的主觀性以及通常成本高且耗時的評估所阻礙。為了應對這些挑戰，我們引入了 \UserSumBench，一個基準架構，旨在促進基於 LLM 的摘要方法的迭代開發。此架構提供了兩個關鍵組成部分：(1) 無參考摘要品質指標。我們展示了此指標有效且與三個不同資料集 (MovieLens、Yelp 和 Amazon Review) 中的人類偏好一致。(2) 一種新穎的穩健摘要方法，利用時間階層摘要器和自我批評驗證器來產生高品質摘要，同時消除幻覺。此方法作為摘要技術進一步創新的強大基線。

##### **Transient Fault Tolerant Semantic Segmentation for Autonomous Driving**
2408.16952v1 by Leonardo Iurada, Niccolò Cavagnero, Fernando Fernandes Dos Santos, Giuseppe Averta, Paolo Rech, Tatiana Tommasi

Deep learning models are crucial for autonomous vehicle perception, but their
reliability is challenged by algorithmic limitations and hardware faults. We
address the latter by examining fault-tolerance in semantic segmentation
models. Using established hardware fault models, we evaluate existing hardening
techniques both in terms of accuracy and uncertainty and introduce ReLUMax, a
novel simple activation function designed to enhance resilience against
transient faults. ReLUMax integrates seamlessly into existing architectures
without time overhead. Our experiments demonstrate that ReLUMax effectively
improves robustness, preserving performance and boosting prediction confidence,
thus contributing to the development of reliable autonomous driving systems.

摘要：深度學習模型對於自動駕駛感知至關重要，但其可靠性受到演算法限制和硬體故障的挑戰。我們透過檢視語意分割模型中的容錯性來解決後者。使用已建立的硬體故障模型，我們在準確性和不確定性方面評估現有的強化技術，並引入 ReLUMax，一種新穎且簡單的激活函數，旨在增強對暫態故障的復原力。ReLUMax 可無縫整合到現有架構中，且無時間開銷。我們的實驗表明，ReLUMax 有效地提高了穩健性，保留了效能並提升了預測信心，從而為可靠的自動駕駛系統開發做出了貢獻。

##### **Different Victims, Same Layout: Email Visual Similarity Detection for Enhanced Email Protection**
2408.16945v3 by Sachin Shukla, Omid Mirzaei

In the pursuit of an effective spam detection system, the focus has often
been on identifying known spam patterns either through rule-based detection
systems or machine learning (ML) solutions that rely on keywords. However, both
systems are susceptible to evasion techniques and zero-day attacks that can be
achieved at low cost. Therefore, an email that bypassed the defense system once
can do it again in the following days, even though rules are updated or the ML
models are retrained. The recurrence of failures to detect emails that exhibit
layout similarities to previously undetected spam is concerning for customers
and can erode their trust in a company. Our observations show that threat
actors reuse email kits extensively and can bypass detection with little
effort, for example, by making changes to the content of emails. In this work,
we propose an email visual similarity detection approach, named Pisco, to
improve the detection capabilities of an email threat defense system. We apply
our proof of concept to some real-world samples received from different
sources. Our results show that email kits are being reused extensively and
visually similar emails are sent to our customers at various time intervals.
Therefore, this method could be very helpful in situations where detection
engines that rely on textual features and keywords are bypassed, an occurrence
our observations show happens frequently.

摘要：在追求有效的垃圾郵件偵測系統時，重點通常在於透過基於規則的偵測系統或依賴關鍵字的機器學習 (ML) 解決方案來識別已知的垃圾郵件模式。然而，這兩種系統都容易受到逃避技術和零時差攻擊，而這些攻擊可以用低成本達成。因此，一封曾經繞過防禦系統的電子郵件，即使規則已更新或 ML 模型已重新訓練，它也可以在接下來的幾天再次繞過。重複偵測不到與先前未偵測到的垃圾郵件在版面配置上相似的電子郵件，這一點讓客戶感到憂心，並且會侵蝕他們對公司的信任。我們的觀察顯示，威脅行為者廣泛地重複使用電子郵件套件，而且幾乎不費吹灰之力就能繞過偵測，例如透過變更電子郵件的內容。在這項工作中，我們提出稱為 Pisco 的電子郵件視覺相似度偵測方法，以提升電子郵件威脅防禦系統的偵測能力。我們將概念驗證應用於從不同來源收到的部分真實世界範例。我們的結果顯示，電子郵件套件被廣泛地重複使用，而且在不同的時間間隔內會傳送視覺上相似的電子郵件給我們的客戶。因此，這種方法在依賴文字特徵和關鍵字的偵測引擎遭到繞過時可能非常有幫助，我們的觀察顯示這種情況經常發生。

##### **A longitudinal sentiment analysis of Sinophobia during COVID-19 using large language models**
2408.16942v1 by Chen Wang, Rohitash Chandra

The COVID-19 pandemic has exacerbated xenophobia, particularly Sinophobia,
leading to widespread discrimination against individuals of Chinese descent.
Large language models (LLMs) are pre-trained deep learning models used for
natural language processing (NLP) tasks. The ability of LLMs to understand and
generate human-like text makes them particularly useful for analysing social
media data to detect and evaluate sentiments. We present a sentiment analysis
framework utilising LLMs for longitudinal sentiment analysis of the Sinophobic
sentiments expressed in X (Twitter) during the COVID-19 pandemic. The results
show a significant correlation between the spikes in Sinophobic tweets,
Sinophobic sentiments and surges in COVID-19 cases, revealing that the
evolution of the pandemic influenced public sentiment and the prevalence of
Sinophobic discourse. Furthermore, the sentiment analysis revealed a
predominant presence of negative sentiments, such as annoyance and denial,
which underscores the impact of political narratives and misinformation shaping
public opinion. The lack of empathetic sentiment which was present in previous
studies related to COVID-19 highlights the way the political narratives in
media viewed the pandemic and how it blamed the Chinese community. Our study
highlights the importance of transparent communication in mitigating xenophobic
sentiments during global crises.

摘要：COVID-19 疫情加劇了仇外心理，特別是仇視中國人的情緒，導致對華人後裔的歧視行為廣泛存在。大型語言模型 (LLM) 是預先訓練好的深度學習模型，用於自然語言處理 (NLP) 任務。LLM 理解和生成類似人類文字的能力使其特別適用於分析社群媒體資料，以偵測和評估情緒。我們提出一個情緒分析架構，利用 LLM 對 X（Twitter）在 COVID-19 疫情期間表達的仇視中國人情緒進行縱向情緒分析。結果顯示，仇視中國人的推文、仇視中國人的情緒與 COVID-19 病例激增之間存在顯著相關性，這表明疫情的演變影響了公眾情緒和仇視中國人言論的盛行。此外，情緒分析揭示了負面情緒（例如厭惡和否認）的普遍存在，這突顯了政治敘事和錯誤資訊對塑造輿論的影響。在先前與 COVID-19 相關的研究中存在同理心情緒的缺乏，這凸顯了媒體中的政治敘事如何看待疫情，以及如何將其歸咎於華人社群。我們的研究強調了在全球危機期間緩解仇外情緒的透明溝通的重要性。

##### **Plausible-Parrots @ MSP2023: Enhancing Semantic Plausibility Modeling using Entity and Event Knowledge**
2408.16937v1 by Chong Shen, Chenyue Zhou

In this work, we investigate the effectiveness of injecting external
knowledge to a large language model (LLM) to identify semantic plausibility of
simple events. Specifically, we enhance the LLM with fine-grained entity types,
event types and their definitions extracted from an external knowledge base.
These knowledge are injected into our system via designed templates. We also
augment the data to balance the label distribution and adapt the task setting
to real world scenarios in which event mentions are expressed as natural
language sentences. The experimental results show the effectiveness of the
injected knowledge on modeling semantic plausibility of events. An error
analysis further emphasizes the importance of identifying non-trivial entity
and event types.

摘要：在這項工作中，我們探討將外部知識注入大型語言模型 (LLM) 以識別簡單事件的語義合理性的有效性。具體來說，我們使用從外部知識庫中提取的細粒度實體類型、事件類型及其定義來增強 LLM。這些知識透過設計好的範本注入到我們的系統中。我們還擴增數據以平衡標籤分佈，並將任務設定調整為事件提及以自然語言句子表達的真實世界場景。實驗結果顯示了注入的知識在建模事件語義合理性方面的有效性。錯誤分析進一步強調了識別非平凡實體和事件類型的重要性。

##### **Event Extraction for Portuguese: A QA-driven Approach using ACE-2005**
2408.16932v1 by Luís Filipe Cunha, Ricardo Campos, Alípio Jorge

Event extraction is an Information Retrieval task that commonly consists of
identifying the central word for the event (trigger) and the event's arguments.
This task has been extensively studied for English but lags behind for
Portuguese, partly due to the lack of task-specific annotated corpora. This
paper proposes a framework in which two separated BERT-based models were
fine-tuned to identify and classify events in Portuguese documents. We
decompose this task into two sub-tasks. Firstly, we use a token classification
model to detect event triggers. To extract event arguments, we train a Question
Answering model that queries the triggers about their corresponding event
argument roles. Given the lack of event annotated corpora in Portuguese, we
translated the original version of the ACE-2005 dataset (a reference in the
field) into Portuguese, producing a new corpus for Portuguese event extraction.
To accomplish this, we developed an automatic translation pipeline. Our
framework obtains F1 marks of 64.4 for trigger classification and 46.7 for
argument classification setting, thus a new state-of-the-art reference for
these tasks in Portuguese.

摘要：事件抽取是一種資訊檢索任務，通常包含識別事件的中心詞（觸發器）和事件的論元。
此任務已針對英文廣泛研究，但葡萄牙文則落後，部分原因是缺乏特定於任務的註解語料庫。
本文提出了一個架構，其中微調了兩個分離的 BERT 基礎模型，以識別和分類葡萄牙文文件中的事件。
我們將此任務分解為兩個子任務。首先，我們使用符號分類模型來偵測事件觸發器。
為了抽取事件論元，我們訓練一個問答模型，對觸發器查詢其對應的事件論元角色。
由於缺乏葡萄牙文的事件註解語料庫，我們將 ACE-2005 資料集（該領域的參考）的原始版本翻譯成葡萄牙文，產生一個新的葡萄牙文事件抽取語料庫。
為了達成此目的，我們開發了一個自動翻譯管道。我們的架構在觸發器分類中獲得 64.4 的 F1 分數，在論元分類設定中獲得 46.7，因此成為葡萄牙文中這些任務的新技術標準。

##### **ACE-2005-PT: Corpus for Event Extraction in Portuguese**
2408.16928v1 by Luís Filipe Cunha, Purificação Silvano, Ricardo Campos, Alípio Jorge

Event extraction is an NLP task that commonly involves identifying the
central word (trigger) for an event and its associated arguments in text.
ACE-2005 is widely recognised as the standard corpus in this field. While other
corpora, like PropBank, primarily focus on annotating predicate-argument
structure, ACE-2005 provides comprehensive information about the overall event
structure and semantics. However, its limited language coverage restricts its
usability. This paper introduces ACE-2005-PT, a corpus created by translating
ACE-2005 into Portuguese, with European and Brazilian variants. To speed up the
process of obtaining ACE-2005-PT, we rely on automatic translators. This,
however, poses some challenges related to automatically identifying the correct
alignments between multi-word annotations in the original text and in the
corresponding translated sentence. To achieve this, we developed an alignment
pipeline that incorporates several alignment techniques: lemmatization, fuzzy
matching, synonym matching, multiple translations and a BERT-based word
aligner. To measure the alignment effectiveness, a subset of annotations from
the ACE-2005-PT corpus was manually aligned by a linguist expert. This subset
was then compared against our pipeline results which achieved exact and relaxed
match scores of 70.55\% and 87.55\% respectively. As a result, we successfully
generated a Portuguese version of the ACE-2005 corpus, which has been accepted
for publication by LDC.

摘要：事件萃取是一項自然語言處理任務，通常涉及識別文本中事件的中心詞（觸發器）及其相關論元。
ACE-2005 被廣泛認為是該領域的標準語料庫。雖然其他語料庫（如 PropBank）主要專注於標註謂詞-論元結構，但 ACE-2005 提供了有關整體事件結構和語義的全面資訊。然而，其有限的語言涵蓋範圍限制了其可用性。本文介紹了 ACE-2005-PT，這是一個語料庫，透過將 ACE-2005 翻譯成葡萄牙語（包含歐洲和巴西變體）而建立。為了加速取得 ACE-2005-PT 的過程，我們依賴自動翻譯。然而，這會帶來一些挑戰，包括自動識別原始文字中的多字標註與對應翻譯句子之間的正確對齊。為了達成此目的，我們開發了一個對齊管道，其中包含了多種對齊技術：詞形還原、模糊比對、同義詞比對、多重翻譯和一個基於 BERT 的詞彙對齊器。為了測量對齊效果，由一位語言學家專家手動對齊了 ACE-2005-PT 語料庫中的一部分標註。然後將此部分與我們的管道結果進行比較，分別達到了 70.55% 和 87.55% 的完全匹配和放寬匹配分數。因此，我們成功產生了 ACE-2005 語料庫的葡萄牙語版本，該版本已被 LDC 接受出版。

##### **Analyzing Inference Privacy Risks Through Gradients in Machine Learning**
2408.16913v1 by Zhuohang Li, Andrew Lowy, Jing Liu, Toshiaki Koike-Akino, Kieran Parsons, Bradley Malin, Ye Wang

In distributed learning settings, models are iteratively updated with shared
gradients computed from potentially sensitive user data. While previous work
has studied various privacy risks of sharing gradients, our paper aims to
provide a systematic approach to analyze private information leakage from
gradients. We present a unified game-based framework that encompasses a broad
range of attacks including attribute, property, distributional, and user
disclosures. We investigate how different uncertainties of the adversary affect
their inferential power via extensive experiments on five datasets across
various data modalities. Our results demonstrate the inefficacy of solely
relying on data aggregation to achieve privacy against inference attacks in
distributed learning. We further evaluate five types of defenses, namely,
gradient pruning, signed gradient descent, adversarial perturbations,
variational information bottleneck, and differential privacy, under both static
and adaptive adversary settings. We provide an information-theoretic view for
analyzing the effectiveness of these defenses against inference from gradients.
Finally, we introduce a method for auditing attribute inference privacy,
improving the empirical estimation of worst-case privacy through crafting
adversarial canary records.

摘要：在分布式學習設定中，模型會使用由潛在敏感使用者資料計算出的共享梯度反覆更新。雖然先前的研究已探討分享梯度的各種隱私風險，但我們的論文旨在提供一種系統性方法來分析梯度中私人資訊的洩漏。我們提出一個統一的基於遊戲的架構，其中包含廣泛的攻擊，包括屬性、特性、分佈和使用者揭露。我們透過五個資料集在各種資料形式中進行廣泛的實驗，探討對手的不同不確定性如何影響其推論能力。我們的結果證明，僅依賴資料彙總來在分布式學習中對抗推論攻擊無法達到隱私。我們進一步評估五種類型的防禦措施，即梯度修剪、有符號梯度下降、對抗性擾動、變異資訊瓶頸和差分隱私，在靜態和自適應對手的設定下。我們提供了一個資訊理論觀點，用於分析這些防禦措施對抗梯度推論的有效性。最後，我們介紹一種審計屬性推論隱私的方法，透過建立對抗性金絲雀記錄來改善最差情況隱私的經驗估計。

##### **Exploring Multiple Strategies to Improve Multilingual Coreference Resolution in CorefUD**
2408.16893v1 by Ondřej Pražák, Miloslav Konopík

Coreference resolution, the task of identifying expressions in text that
refer to the same entity, is a critical component in various natural language
processing (NLP) applications. This paper presents our end-to-end neural
coreference resolution system, utilizing the CorefUD 1.1 dataset, which spans
17 datasets across 12 languages. We first establish strong baseline models,
including monolingual and cross-lingual variations, and then propose several
extensions to enhance performance across diverse linguistic contexts. These
extensions include cross-lingual training, incorporation of syntactic
information, a Span2Head model for optimized headword prediction, and advanced
singleton modeling. We also experiment with headword span representation and
long-documents modeling through overlapping segments. The proposed extensions,
particularly the heads-only approach, singleton modeling, and long document
prediction significantly improve performance across most datasets. We also
perform zero-shot cross-lingual experiments, highlighting the potential and
limitations of cross-lingual transfer in coreference resolution. Our findings
contribute to the development of robust and scalable coreference systems for
multilingual coreference resolution. Finally, we evaluate our model on CorefUD
1.1 test set and surpass the best model from CRAC 2023 shared task of a
comparable size by a large margin. Our nodel is available on GitHub:
\url{https://github.com/ondfa/coref-multiling}

摘要：核心指代消解，指識別文本中指涉相同實體的表達式的任務，是各種自然語言處理 (NLP) 應用中的關鍵組成部分。本文展示了我們的端到端神經核心指代消解系統，利用 CorefUD 1.1 資料集，該資料集涵蓋 12 種語言的 17 個資料集。我們首先建立強大的基準模型，包括單語和跨語言變體，然後提出多項擴充，以增強在不同語言環境中的效能。這些擴充包括跨語言訓練、語法資訊整合、用於最佳化詞首預測的 Span2Head 模型，以及進階單例建模。我們還透過重疊區段來實驗詞首跨距表示和長文件建模。建議的擴充，特別是僅詞首方法、單例建模和長文件預測，大幅改善了大多數資料集的效能。我們還執行零次學習跨語言實驗，強調跨語言轉移在核心指代消解中的潛力與限制。我們的發現有助於開發強健且可擴充的核心指代系統，用於多語言核心指代消解。最後，我們在 CorefUD 1.1 測試集上評估我們的模型，並大幅超越 CRAC 2023 共享任務中同等規模的最佳模型。我們的模型可在 GitHub 上取得：\url{https://github.com/ondfa/coref-multiling}

##### **LLaVA-Chef: A Multi-modal Generative Model for Food Recipes**
2408.16889v1 by Fnu Mohbat, Mohammed J. Zaki

In the rapidly evolving landscape of online recipe sharing within a
globalized context, there has been a notable surge in research towards
comprehending and generating food recipes. Recent advancements in large
language models (LLMs) like GPT-2 and LLaVA have paved the way for Natural
Language Processing (NLP) approaches to delve deeper into various facets of
food-related tasks, encompassing ingredient recognition and comprehensive
recipe generation. Despite impressive performance and multi-modal adaptability
of LLMs, domain-specific training remains paramount for their effective
application. This work evaluates existing LLMs for recipe generation and
proposes LLaVA-Chef, a novel model trained on a curated dataset of diverse
recipe prompts in a multi-stage approach. First, we refine the mapping of
visual food image embeddings to the language space. Second, we adapt LLaVA to
the food domain by fine-tuning it on relevant recipe data. Third, we utilize
diverse prompts to enhance the model's recipe comprehension. Finally, we
improve the linguistic quality of generated recipes by penalizing the model
with a custom loss function. LLaVA-Chef demonstrates impressive improvements
over pretrained LLMs and prior works. A detailed qualitative analysis reveals
that LLaVA-Chef generates more detailed recipes with precise ingredient
mentions, compared to existing approaches.

摘要：<paragraph>在全球化的背景下，在线食谱分享领域迅速发展，人们对理解和生成食谱的研究激增。GPT-2 和 LLaVA 等大型语言模型 (LLM) 的最新进展为自然语言处理 (NLP) 方法开辟了道路，可以深入研究与食物相关的任务的各个方面，包括成分识别和全面食谱生成。尽管 LLM 具有令人印象深刻的性能和多模态适应性，但特定领域的培训仍然是其有效应用的关键。这项工作评估了现有的 LLM 用于食谱生成，并提出了 LLaVA-Chef，这是一种经过多阶段方法在精选的多样化食谱提示数据集上训练的新模型。首先，我们改进了视觉食物图像嵌入到语言空间的映射。其次，我们通过在相关的食谱数据上进行微调，将 LLaVA 调整到食品领域。第三，我们利用各种提示来增强模型的食谱理解力。最后，我们通过使用自定义损失函数惩罚模型来提高生成食谱的语言质量。LLaVA-Chef 展示了对预训练 LLM 和先前工作的令人印象深刻的改进。详细的定性分析表明，与现有方法相比，LLaVA-Chef 生成了更详细的食谱，并精确提到了成分。</paragraph>

##### **Modeling offensive content detection for TikTok**
2408.16857v1 by Kasper Cools, Gideon Mailette de Buy Wenniger, Clara Maathuis

The advent of social media transformed interpersonal communication and
information consumption processes. This digital landscape accommodates user
intentions, also resulting in an increase of offensive language and harmful
behavior. Concurrently, social media platforms collect vast datasets comprising
user-generated content and behavioral information. These datasets are
instrumental for platforms deploying machine learning and data-driven
strategies, facilitating customer insights and countermeasures against social
manipulation mechanisms like disinformation and offensive content.
Nevertheless, the availability of such datasets, along with the application of
various machine learning techniques, to researchers and practitioners, for
specific social media platforms regarding particular events, is limited. In
particular for TikTok, which offers unique tools for personalized content
creation and sharing, the existing body of knowledge would benefit from having
diverse comprehensive datasets and associated data analytics solutions on
offensive content. While efforts from social media platforms, research, and
practitioner communities are seen on this behalf, such content continues to
proliferate. This translates to an essential need to make datasets publicly
available and build corresponding intelligent solutions. On this behalf, this
research undertakes the collection and analysis of TikTok data containing
offensive content, building a series of machine learning and deep learning
models for offensive content detection. This is done aiming at answering the
following research question: "How to develop a series of computational models
to detect offensive content on TikTok?". To this end, a Data Science
methodological approach is considered, 120.423 TikTok comments are collected,
and on a balanced, binary classification approach, F1 score performance results
of 0.863 is obtained.

摘要：社群媒體的出現改變了人際溝通和資訊消費的歷程。這個數位環境容納了使用者的意圖，也導致攻擊性語言和有害行為的增加。同時，社群媒體平台收集了包含使用者生成內容和行為資訊的龐大資料集。這些資料集是平台部署機器學習和資料驅動策略的工具，促進對客戶的洞察，並對抗虛假資訊和攻擊性內容等社群操縱機制。儘管如此，研究人員和實務工作者對於特定社群媒體平台關於特定事件的此類資料集的取得，以及各種機器學習技術的應用，仍然有限。特別是對於 TikTok，它提供了個人化內容建立和分享的獨特工具，現有的知識體系將受益於擁有關於攻擊性內容的多元且全面的資料集和相關資料分析解決方案。儘管社群媒體平台、研究和實務工作者社群在這方面做出了努力，但此類內容仍持續激增。這轉化為公開資料集和建立相應的智慧解決方案的基本需求。在此方面，本研究承擔了收集和分析包含攻擊性內容的 TikTok 資料，建立一系列用於攻擊性內容偵測的機器學習和深度學習模型。這樣做的目的是為了回答以下的研究問題：「如何開發一系列計算模型來偵測 TikTok 上的攻擊性內容？」。為此，考慮採用資料科學的方法論，收集了 120.423 則 TikTok 留言，並在平衡的二元分類方法中，獲得了 0.863 的 F1 分數效能結果。

##### **See or Guess: Counterfactually Regularized Image Captioning**
2408.16809v1 by Qian Cao, Xu Chen, Ruihua Song, Xiting Wang, Xinting Huang, Yuchen Ren

Image captioning, which generates natural language descriptions of the visual
information in an image, is a crucial task in vision-language research.
Previous models have typically addressed this task by aligning the generative
capabilities of machines with human intelligence through statistical fitting of
existing datasets. While effective for normal images, they may struggle to
accurately describe those where certain parts of the image are obscured or
edited, unlike humans who excel in such cases. These weaknesses they exhibit,
including hallucinations and limited interpretability, often hinder performance
in scenarios with shifted association patterns. In this paper, we present a
generic image captioning framework that employs causal inference to make
existing models more capable of interventional tasks, and counterfactually
explainable. Our approach includes two variants leveraging either total effect
or natural direct effect. Integrating them into the training process enables
models to handle counterfactual scenarios, increasing their generalizability.
Extensive experiments on various datasets show that our method effectively
reduces hallucinations and improves the model's faithfulness to images,
demonstrating high portability across both small-scale and large-scale
image-to-text models. The code is available at
https://github.com/Aman-4-Real/See-or-Guess.

摘要：影像標題，產生影像中視覺資訊的自然語言描述，是視覺語言研究中的一項重要任務。
先前的模型通常透過統計擬合現有資料集，將機器生成能力與人類智慧結合，來處理這項任務。雖然對一般影像有效，但與擅長此類情況的人類不同，這些模型可能難以精確描述影像中某些部分被遮蔽或編輯的影像。這些模型展現的弱點，包括幻覺和有限的可解釋性，通常會阻礙在關聯模式轉移的情況下的效能。在本文中，我們提出一個通用影像標題框架，它採用因果推論，讓現有模型更能執行介入任務，並反事實地解釋。我們的做法包括兩種變體，利用總體效應或自然直接效應。將這些變體整合到訓練過程中，能讓模型處理反事實場景，進而提升模型的概括性。在各種資料集上的廣泛實驗顯示，我們的方法有效減少幻覺，並提升模型對影像的忠實度，證明在小規模和大型影像轉文字模型中都具有高度可移植性。程式碼可於 https://github.com/Aman-4-Real/See-or-Guess 取得。

##### **SAM2Point: Segment Any 3D as Videos in Zero-shot and Promptable Manners**
2408.16768v1 by Ziyu Guo, Renrui Zhang, Xiangyang Zhu, Chengzhuo Tong, Peng Gao, Chunyuan Li, Pheng-Ann Heng

We introduce SAM2Point, a preliminary exploration adapting Segment Anything
Model 2 (SAM 2) for zero-shot and promptable 3D segmentation. SAM2Point
interprets any 3D data as a series of multi-directional videos, and leverages
SAM 2 for 3D-space segmentation, without further training or 2D-3D projection.
Our framework supports various prompt types, including 3D points, boxes, and
masks, and can generalize across diverse scenarios, such as 3D objects, indoor
scenes, outdoor environments, and raw sparse LiDAR. Demonstrations on multiple
3D datasets, e.g., Objaverse, S3DIS, ScanNet, Semantic3D, and KITTI, highlight
the robust generalization capabilities of SAM2Point. To our best knowledge, we
present the most faithful implementation of SAM in 3D, which may serve as a
starting point for future research in promptable 3D segmentation. Online Demo:
https://huggingface.co/spaces/ZiyuG/SAM2Point . Code:
https://github.com/ZiyuGuo99/SAM2Point .

摘要：我們介紹 SAM2Point，這是一種初步探索，將 Segment Anything Model 2 (SAM 2) 改編為零次學習和可提示的 3D 分割。SAM2Point 將任何 3D 資料詮釋為一系列多方向影片，並利用 SAM 2 進行 3D 空間分割，而無需進一步訓練或 2D-3D 投影。我們的架構支援各種提示類型，包括 3D 點、方塊和遮罩，並且可以在不同的場景中泛化，例如 3D 物件、室內場景、戶外環境和原始稀疏 LiDAR。在多個 3D 資料集上的示範，例如 Objaverse、S3DIS、ScanNet、Semantic3D 和 KITTI，突出了 SAM2Point 的強大泛化能力。據我們所知，我們展示了 SAM 在 3D 中最忠實的實作，這可以作為未來可提示 3D 分割研究的起點。線上示範：https://huggingface.co/spaces/ZiyuG/SAM2Point。程式碼：https://github.com/ZiyuGuo99/SAM2Point。

##### **ReconX: Reconstruct Any Scene from Sparse Views with Video Diffusion Model**
2408.16767v1 by Fangfu Liu, Wenqiang Sun, Hanyang Wang, Yikai Wang, Haowen Sun, Junliang Ye, Jun Zhang, Yueqi Duan

Advancements in 3D scene reconstruction have transformed 2D images from the
real world into 3D models, producing realistic 3D results from hundreds of
input photos. Despite great success in dense-view reconstruction scenarios,
rendering a detailed scene from insufficient captured views is still an
ill-posed optimization problem, often resulting in artifacts and distortions in
unseen areas. In this paper, we propose ReconX, a novel 3D scene reconstruction
paradigm that reframes the ambiguous reconstruction challenge as a temporal
generation task. The key insight is to unleash the strong generative prior of
large pre-trained video diffusion models for sparse-view reconstruction.
However, 3D view consistency struggles to be accurately preserved in directly
generated video frames from pre-trained models. To address this, given limited
input views, the proposed ReconX first constructs a global point cloud and
encodes it into a contextual space as the 3D structure condition. Guided by the
condition, the video diffusion model then synthesizes video frames that are
both detail-preserved and exhibit a high degree of 3D consistency, ensuring the
coherence of the scene from various perspectives. Finally, we recover the 3D
scene from the generated video through a confidence-aware 3D Gaussian Splatting
optimization scheme. Extensive experiments on various real-world datasets show
the superiority of our ReconX over state-of-the-art methods in terms of quality
and generalizability.

摘要：3D 場景重建的進展已將現實世界的 2D 影像轉換為 3D 模型，從數百張輸入照片產生逼真的 3D 結果。儘管在密集視圖重建場景中取得巨大成功，但從不足的擷取視圖中渲染出詳細場景仍然是一個欠約束的最佳化問題，通常會在未見區域中產生偽像和失真。在本文中，我們提出 ReconX，這是一個新穎的 3D 場景重建範例，將模稜兩可的重建挑戰重新定義為一個時間生成任務。關鍵見解是釋放預先訓練好的影片擴散模型的強大生成先驗，以進行稀疏視圖重建。然而，3D 視圖一致性難以直接從預先訓練好的模型中生成的影片格中準確保留。為了解決這個問題，在給定有限的輸入視圖下，提議的 ReconX 首先建構一個全域點雲，並將其編碼到一個脈絡空間中作為 3D 結構條件。在條件的引導下，影片擴散模型接著合成既保留細節又展現高度 3D 一致性的影片格，確保場景從各種角度的一致性。最後，我們透過一個具有信心感知的 3D 高斯噴繪最佳化架構，從生成的影片中恢復 3D 場景。在各種真實世界資料集上的大量實驗顯示，我們的 ReconX 在品質和概括性方面優於最先進的方法。

##### **A Score-Based Density Formula, with Applications in Diffusion Generative Models**
2408.16765v1 by Gen Li, Yuling Yan

Score-based generative models (SGMs) have revolutionized the field of
generative modeling, achieving unprecedented success in generating realistic
and diverse content. Despite empirical advances, the theoretical basis for why
optimizing the evidence lower bound (ELBO) on the log-likelihood is effective
for training diffusion generative models, such as DDPMs, remains largely
unexplored. In this paper, we address this question by establishing a density
formula for a continuous-time diffusion process, which can be viewed as the
continuous-time limit of the forward process in an SGM. This formula reveals
the connection between the target density and the score function associated
with each step of the forward process. Building on this, we demonstrate that
the minimizer of the optimization objective for training DDPMs nearly coincides
with that of the true objective, providing a theoretical foundation for
optimizing DDPMs using the ELBO. Furthermore, we offer new insights into the
role of score-matching regularization in training GANs, the use of ELBO in
diffusion classifiers, and the recently proposed diffusion loss.

摘要：基於分數的生成模型 (SGM) 已徹底改變生成模型領域，在生成逼真且多樣化的內容方面取得了前所未有的成功。儘管有經驗上的進步，但優化對數似然上的證據下界 (ELBO) 對於訓練擴散生成模型（例如 DDPM）有效的原因，其理論基礎在很大程度上仍未得到探索。在本文中，我們通過建立連續時間擴散過程的密度公式來解決這個問題，該公式可以視為 SGM 中前向過程的連續時間極限。這個公式揭示了目標密度與與前向過程的每一步相關的分數函數之間的聯繫。在此基礎上，我們證明了訓練 DDPM 的優化目標的極小值幾乎與真實目標的極小值一致，為使用 ELBO 優化 DDPM 提供了理論基礎。此外，我們對生成對抗網路 (GAN) 訓練中分數匹配正則化的作用、擴散分類器中 ELBO 的使用以及最近提出的擴散損失提供了新的見解。

##### **Dissecting Out-of-Distribution Detection and Open-Set Recognition: A Critical Analysis of Methods and Benchmarks**
2408.16757v2 by Hongjun Wang, Sagar Vaze, Kai Han

Detecting test-time distribution shift has emerged as a key capability for
safely deployed machine learning models, with the question being tackled under
various guises in recent years. In this paper, we aim to provide a consolidated
view of the two largest sub-fields within the community: out-of-distribution
(OOD) detection and open-set recognition (OSR). In particular, we aim to
provide rigorous empirical analysis of different methods across settings and
provide actionable takeaways for practitioners and researchers. Concretely, we
make the following contributions: (i) We perform rigorous cross-evaluation
between state-of-the-art methods in the OOD detection and OSR settings and
identify a strong correlation between the performances of methods for them;
(ii) We propose a new, large-scale benchmark setting which we suggest better
disentangles the problem tackled by OOD detection and OSR, re-evaluating
state-of-the-art OOD detection and OSR methods in this setting; (iii) We
surprisingly find that the best performing method on standard benchmarks
(Outlier Exposure) struggles when tested at scale, while scoring rules which
are sensitive to the deep feature magnitude consistently show promise; and (iv)
We conduct empirical analysis to explain these phenomena and highlight
directions for future research. Code:
https://github.com/Visual-AI/Dissect-OOD-OSR

摘要：<paragraph>偵測測試時間的分配轉移已成為安全部署機器學習模型的一項關鍵能力，這個問題在近年來以各種形式被解決。在本文中，我們旨在提供社群中兩個最大的子領域的統合觀點：分佈外 (OOD) 偵測和開放式識別 (OSR)。特別是，我們旨在提供在不同設定中對不同方法進行嚴謹的實證分析，並為實務工作者和研究人員提供可行的外賣。具體來說，我們做出以下貢獻：(i) 我們在 OOD 偵測和 OSR 設定中對最先進的方法進行嚴謹的交叉評估，並找出它們方法的效能之間有很強的相關性；(ii) 我們提出一個新的、大規模的基準設定，我們建議它能更好地解開 OOD 偵測和 OSR 所解決的問題，重新評估在此設定中的最先進的 OOD 偵測和 OSR 方法；(iii) 我們驚訝地發現，在標準基準上表現最好的方法（異常值暴露）在擴大規模時會遇到困難，而對深度特徵量大小敏感的計分規則則持續表現出前景；以及 (iv) 我們進行實證分析來解釋這些現象，並重點說明未來研究的方向。程式碼：
https://github.com/Visual-AI/Dissect-OOD-OSR</paragraph>

##### **How Far Can Cantonese NLP Go? Benchmarking Cantonese Capabilities of Large Language Models**
2408.16756v1 by Jiyue Jiang, Liheng Chen, Pengan Chen, Sheng Wang, Qinghang Bao, Lingpeng Kong, Yu Li, Chuan Wu

The rapid evolution of large language models (LLMs) has transformed the
competitive landscape in natural language processing (NLP), particularly for
English and other data-rich languages. However, underrepresented languages like
Cantonese, spoken by over 85 million people, face significant development gaps,
which is particularly concerning given the economic significance of the
Guangdong-Hong Kong-Macau Greater Bay Area, and in substantial
Cantonese-speaking populations in places like Singapore and North America.
Despite its wide use, Cantonese has scant representation in NLP research,
especially compared to other languages from similarly developed regions. To
bridge these gaps, we outline current Cantonese NLP methods and introduce new
benchmarks designed to evaluate LLM performance in factual generation,
mathematical logic, complex reasoning, and general knowledge in Cantonese,
which aim to advance open-source Cantonese LLM technology. We also propose
future research directions and recommended models to enhance Cantonese LLM
development.

摘要：大型語言模型 (LLM) 的快速演進已經改變了自然語言處理 (NLP) 的競爭格局，特別是對於英語和其他資料豐富的語言。然而，像廣東話這樣被低估的語言，擁有超過 8500 萬人口使用，卻面臨著重大的發展差距，這特別令人擔憂，因為粵港澳大灣區的經濟重要性，以及像新加坡和北美這樣擁有大量廣東話人口的地方。儘管廣東話被廣泛使用，但在 NLP 研究中卻鮮有代表性，特別是與來自類似發達地區的其他語言相比。為了彌合這些差距，我們概述了目前的廣東話 NLP 方法，並引入了新的基準，旨在評估 LLM 在廣東話的事實生成、數學邏輯、複雜推理和一般知識方面的表現，目標是推進開源廣東話 LLM 技術。我們還提出了未來的研究方向和建議的模型，以增強廣東話 LLM 的發展。

##### **Reinforcement Learning without Human Feedback for Last Mile Fine-Tuning of Large Language Models**
2408.16753v1 by Alec Solway

Reinforcement learning is used to align language models with human preference
signals after first pre-training the model to predict the next token of text
within a large corpus using likelihood maximization. Before being deployed in a
specific domain, models are often further fine-tuned on task specific data.
Since human preferences are often unavailable for the last step, it is
performed using likelihood maximization as that is the typical default method.
However, reinforcement learning has other advantages besides facilitating
alignment to a human derived reward function. For one, whereas likelihood
maximization is a form of imitation learning in which the model is trained on
what to do under ideal conditions, reinforcement learning is not limited to
demonstrating actions just for optimally reached states and trains a model what
to do under a range of scenarios as it explores the policy space. In addition,
it also trains a model what not to do, suppressing competitive but poor
actions. This work develops a framework for last-mile fine-tuning using
reinforcement learning and tests whether it garners performance gains. The
experiments center on abstractive summarization, but the framework is general
and broadly applicable. Use of the procedure produced significantly better
results than likelihood maximization when comparing raw predictions. For the
specific data tested, the gap could be bridged by employing post-processing of
the maximum likelihood outputs. Nonetheless, the framework offers a new avenue
for model optimization in situations where post-processing may be less
straightforward or effective, and it can be extended to include more complex
classes of undesirable outputs to penalize and train against, such as
hallucinations.

摘要：強化學習被用於在使用似然最大化預測語料中下一個文本符號後，將語言模型與人類偏好信號對齊。在特定領域部署之前，模型通常會進一步針對特定任務的數據進行微調。由於在最後一步中通常無法獲得人類偏好，因此使用似然最大化進行，這是典型的默認方法。然而，強化學習除了促進與人類衍生的獎勵函數對齊之外，還有其他優點。首先，儘管似然最大化是一種模仿學習形式，其中模型在理想條件下訓練要執行什麼操作，但強化學習不僅限於展示僅針對最佳狀態達成的動作，並訓練模型在探索策略空間時在各種場景下要執行什麼操作。此外，它還訓練模型不要執行什麼操作，抑制有競爭力但效果不佳的動作。這項工作開發了一個使用強化學習進行最後一英里微調的框架，並測試它是否能獲得性能提升。實驗集中在抽象摘要上，但該框架是通用的，廣泛適用的。與比較原始預測時，使用該程序產生的結果顯著優於似然最大化。對於測試的具體數據，可以使用最大似然輸出後處理來彌合差距。儘管如此，該框架為模型優化提供了一個新的途徑，在這種情況下，後處理可能不太直接或有效，並且可以擴展到包括更多類型的不可取輸出以進行懲罰和訓練，例如幻覺。

##### **A Gradient Analysis Framework for Rewarding Good and Penalizing Bad Examples in Language Models**
2408.16751v1 by Yi-Lin Tuan, William Yang Wang

Beyond maximum likelihood estimation (MLE), the standard objective of a
language model (LM) that optimizes good examples probabilities, many studies
have explored ways that also penalize bad examples for enhancing the quality of
output distribution, including unlikelihood training, exponential maximizing
average treatment effect (ExMATE), and direct preference optimization (DPO). To
systematically compare these methods and further provide a unified recipe for
LM optimization, in this paper, we present a unique angle of gradient analysis
of loss functions that simultaneously reward good examples and penalize bad
ones in LMs. Through both mathematical results and experiments on
CausalDialogue and Anthropic HH-RLHF datasets, we identify distinct functional
characteristics among these methods. We find that ExMATE serves as a superior
surrogate for MLE, and that combining DPO with ExMATE instead of MLE further
enhances both the statistical (5-7%) and generative (+18% win rate)
performance.

摘要：除了最大似然估计 (MLE) 之外，语言模型 (LM) 的标准目标是优化好例子的概率，许多研究探索了同时惩罚坏例子以提高输出分布质量的方法，包括非似然训练、指数最大化平均处理效果 (ExMATE) 和直接偏好优化 (DPO)。为了系统地比较这些方法并进一步为 LM 优化提供统一的配方，在本文中，我们提出了对损失函数进行梯度分析的独特角度，该损失函数同时奖励好例子并惩罚 LM 中的坏例子。通过对 CausalDialogue 和 Anthropic HH-RLHF 数据集的数学结果和实验，我们识别了这些方法之间不同的功能特征。我们发现 ExMATE 作为 MLE 的优秀替代品，并且将 DPO 与 ExMATE（而不是 MLE）结合使用进一步提高了统计（5-7%）和生成（+18% 获胜率）性能。

##### **Assessing Large Language Models for Online Extremism Research: Identification, Explanation, and New Knowledge**
2408.16749v1 by Beidi Dong, Jin R. Lee, Ziwei Zhu, Balassubramanian Srinivasan

The United States has experienced a significant increase in violent
extremism, prompting the need for automated tools to detect and limit the
spread of extremist ideology online. This study evaluates the performance of
Bidirectional Encoder Representations from Transformers (BERT) and Generative
Pre-Trained Transformers (GPT) in detecting and classifying online domestic
extremist posts. We collected social media posts containing "far-right" and
"far-left" ideological keywords and manually labeled them as extremist or
non-extremist. Extremist posts were further classified into one or more of five
contributing elements of extremism based on a working definitional framework.
The BERT model's performance was evaluated based on training data size and
knowledge transfer between categories. We also compared the performance of GPT
3.5 and GPT 4 models using different prompts: na\"ive, layperson-definition,
role-playing, and professional-definition. Results showed that the best
performing GPT models outperformed the best performing BERT models, with more
detailed prompts generally yielding better results. However, overly complex
prompts may impair performance. Different versions of GPT have unique
sensitives to what they consider extremist. GPT 3.5 performed better at
classifying far-left extremist posts, while GPT 4 performed better at
classifying far-right extremist posts. Large language models, represented by
GPT models, hold significant potential for online extremism classification
tasks, surpassing traditional BERT models in a zero-shot setting. Future
research should explore human-computer interactions in optimizing GPT models
for extremist detection and classification tasks to develop more efficient
(e.g., quicker, less effort) and effective (e.g., fewer errors or mistakes)
methods for identifying extremist content.

摘要：<paragraph>美國經歷了暴力極端主義的顯著增加，促使需要自動化工具來偵測和限制極端主義意識形態在網路上散布。本研究評估了來自 Transformer 的雙向編碼器表徵 (BERT) 和生成式預訓練 Transformer (GPT) 在偵測和分類線上國內極端主義貼文中的表現。我們收集了包含「極右派」和「極左派」意識形態關鍵字的社群媒體貼文，並手動標記它們為極端主義或非極端主義。極端主義貼文進一步根據一個工作定義架構分類為極端主義的五個促成元素中的其中一個或多個。BERT 模型的表現根據訓練資料大小和類別之間的知識轉移進行評估。我們也比較了使用不同提示的 GPT 3.5 和 GPT 4 模型的表現：天真的、外行人的定義、角色扮演和專業定義。結果顯示表現最好的 GPT 模型優於表現最好的 BERT 模型，而更詳細的提示通常會產生更好的結果。然而，過於複雜的提示可能會損害表現。不同版本的 GPT 對它們認為極端的內容有獨特的敏感性。GPT 3.5 在分類極左派極端主義貼文方面表現得更好，而 GPT 4 在分類極右派極端主義貼文方面表現得更好。以 GPT 模型為代表的大語言模型在線上極端主義分類任務中具有顯著的潛力，在零次學習設置中超越了傳統的 BERT 模型。未來的研究應探索人機互動，以最佳化 GPT 模型，用於極端主義偵測和分類任務，以開發更有效率（例如，更快、更省力）和有效（例如，更少的錯誤或失誤）的方法來識別極端主義內容。</paragraph>

##### **Theoretical and Methodological Framework for Studying Texts Produced by Large Language Models**
2408.16740v1 by Jiří Milička

This paper addresses the conceptual, methodological and technical challenges
in studying large language models (LLMs) and the texts they produce from a
quantitative linguistics perspective. It builds on a theoretical framework that
distinguishes between the LLM as a substrate and the entities the model
simulates. The paper advocates for a strictly non-anthropomorphic approach to
models while cautiously applying methodologies used in studying human
linguistic behavior to the simulated entities. While natural language
processing researchers focus on the models themselves, their architecture,
evaluation, and methods for improving performance, we as quantitative linguists
should strive to build a robust theory concerning the characteristics of texts
produced by LLMs, how they differ from human-produced texts, and the properties
of simulated entities. Additionally, we should explore the potential of LLMs as
an instrument for studying human culture, of which language is an integral
part.

摘要：本文探討從量化語言學的角度研究大型語言模型 (LLM) 及其產生的文本時，在概念、方法和技術上會遇到的挑戰。本文建立在一個理論架構上，將 LLM 視為一個基底，以及模型模擬的實體。本文主張對模型採取嚴格非擬人化的方式，同時謹慎地將用於研究人類語言行為的方法應用於模擬實體。雖然自然語言處理研究人員專注於模型本身、其架構、評估和改善效能的方法，但我們作為量化語言學家應致力於建立一個強健的理論，探討 LLM 產生的文本特徵、它們與人類產生的文本有何不同，以及模擬實體的特性。此外，我們應探索 LLM 作為研究人類文化的工具的潛力，而語言是其中不可或缺的一部分。

##### **Smaller, Weaker, Yet Better: Training LLM Reasoners via Compute-Optimal Sampling**
2408.16737v1 by Hritik Bansal, Arian Hosseini, Rishabh Agarwal, Vinh Q. Tran, Mehran Kazemi

Training on high-quality synthetic data from strong language models (LMs) is
a common strategy to improve the reasoning performance of LMs. In this work, we
revisit whether this strategy is compute-optimal under a fixed inference budget
(e.g., FLOPs). To do so, we investigate the trade-offs between generating
synthetic data using a stronger but more expensive (SE) model versus a weaker
but cheaper (WC) model. We evaluate the generated data across three key
metrics: coverage, diversity, and false positive rate, and show that the data
from WC models may have higher coverage and diversity, but also exhibit higher
false positive rates. We then finetune LMs on data from SE and WC models in
different settings: knowledge distillation, self-improvement, and a novel
weak-to-strong improvement setup where a weaker LM teaches reasoning to a
stronger LM. Our findings reveal that models finetuned on WC-generated data
consistently outperform those trained on SE-generated data across multiple
benchmarks and multiple choices of WC and SE models. These results challenge
the prevailing practice of relying on SE models for synthetic data generation,
suggesting that WC may be the compute-optimal approach for training advanced LM
reasoners.

摘要：訓練強大的語言模型 (LM) 中的高品質合成資料是改善 LM 推論效能的常見策略。在這項工作中，我們重新探討此策略在固定推論預算（例如 FLOP）下是否為運算最佳化。為此，我們研究使用較強但較昂貴 (SE) 模型與較弱但較便宜 (WC) 模型產生合成資料之間的取捨。我們根據三個關鍵指標（涵蓋範圍、多樣性和誤報率）評估所產生的資料，並顯示來自 WC 模型的資料可能具有較高的涵蓋範圍和多樣性，但也會顯示較高的誤報率。然後，我們在不同的設定中對來自 SE 和 WC 模型的資料進行微調 LM：知識萃取、自我改善，以及一個新的弱轉強的改善設定，其中較弱的 LM 教導較強的 LM 推理。我們的研究結果顯示，在 WC 產生的資料上進行微調的模型在多個基準和多種 WC 和 SE 模型的選擇中，始終優於在 SE 產生的資料上訓練的模型。這些結果挑戰了依賴 SE 模型進行合成資料產生的普遍做法，表明 WC 可能是在訓練進階 LM 推論器時運算最佳化的途徑。

##### **Mini-Omni: Language Models Can Hear, Talk While Thinking in Streaming**
2408.16725v2 by Zhifei Xie, Changqiao Wu

Recent advances in language models have achieved significant progress.
GPT-4o, as a new milestone, has enabled real-time conversations with humans,
demonstrating near-human natural fluency. Such human-computer interaction
necessitates models with the capability to perform reasoning directly with the
audio modality and generate output in streaming. However, this remains beyond
the reach of current academic models, as they typically depend on extra TTS
systems for speech synthesis, resulting in undesirable latency. This paper
introduces the Mini-Omni, an audio-based end-to-end conversational model,
capable of real-time speech interaction. To achieve this capability, we propose
a text-instructed speech generation method, along with batch-parallel
strategies during inference to further boost the performance. Our method also
helps to retain the original model's language capabilities with minimal
degradation, enabling other works to establish real-time interaction
capabilities. We call this training method "Any Model Can Talk". We also
introduce the VoiceAssistant-400K dataset to fine-tune models optimized for
speech output. To our best knowledge, Mini-Omni is the first fully end-to-end,
open-source model for real-time speech interaction, offering valuable potential
for future research.

摘要：語言模型的最新進展取得重大進展。
GPT-4o 作為一個新的里程碑，實現了與人類的即時對話，
展示了接近人類的自然流暢度。這種人機互動
需要模型具備直接使用音訊模式進行推理並生成串流輸出的能力。然而，這仍然超出了當前學術模型的範圍，因為它們通常依賴於額外的 TTS 系統進行語音合成，從而導致不希望的延遲。本文介紹了 Mini-Omni，一個基於音訊的端到端對話模型，能夠進行實時語音互動。為了實現這一能力，我們提出
一種文字指導的語音生成方法，以及在推理過程中採用批次並行策略以進一步提升效能。我們的技術也有助於保留原始模型的語言能力，同時將退化降至最低，使其他作品能夠建立實時互動能力。我們將這種訓練方法稱為「任何模型都能說話」。我們還引入了 VoiceAssistant-400K 資料集，以微調針對語音輸出最佳化的模型。據我們所知，Mini-Omni 是第一個完全端到端、開放原始碼的實時語音互動模型，為未來的研究提供了寶貴的潛力。

##### **A GREAT Architecture for Edge-Based Graph Problems Like TSP**
2408.16717v1 by Attila Lischka, Jiaming Wu, Morteza Haghir Chehreghani, Balázs Kulcsár

In the last years, many neural network-based approaches have been proposed to
tackle combinatorial optimization problems such as routing problems. Many of
these approaches are based on graph neural networks (GNNs) or related
transformers, operating on the Euclidean coordinates representing the routing
problems. However, GNNs are inherently not well suited to operate on dense
graphs, such as in routing problems. Furthermore, models operating on Euclidean
coordinates cannot be applied to non-Euclidean versions of routing problems
that are often found in real-world settings. To overcome these limitations, we
propose a novel GNN-related edge-based neural model called Graph Edge Attention
Network (GREAT). We evaluate the performance of GREAT in the
edge-classification task to predict optimal edges in the Traveling Salesman
Problem (TSP). We can use such a trained GREAT model to produce sparse TSP
graph instances, keeping only the edges GREAT finds promising. Compared to
other, non-learning-based methods to sparsify TSP graphs, GREAT can produce
very sparse graphs while keeping most of the optimal edges. Furthermore, we
build a reinforcement learning-based GREAT framework which we apply to
Euclidean and non-Euclidean asymmetric TSP. This framework achieves
state-of-the-art results.

摘要：在过去几年中，许多基于神经网络的方法已被提出用于解决组合优化问题，例如路径问题。其中许多方法基于图神经网络 (GNN) 或相关转换器，它们在表示路径问题的欧几里得坐标上运行。然而，GNN 本质上不适合在稠密图上运行，例如在路径问题中。此外，在欧几里得坐标上运行的模型不能应用于在现实世界环境中经常发现的非欧几里得版本的路径问题。为了克服这些限制，我们提出了一种新颖的 GNN 相关边基神经模型，称为图边注意力网络 (GREAT)。我们在边分类任务中评估了 GREAT 的性能，以预测旅行商问题 (TSP) 中的最佳边。我们可以使用这种经过训练的 GREAT 模型来生成稀疏 TSP 图实例，只保留 GREAT 发现有希望的边。与其他基于非学习的方法来稀疏化 TSP 图相比，GREAT 可以生成非常稀疏的图，同时保留大部分最佳边。此外，我们构建了一个基于强化学习的 GREAT 框架，我们将其应用于欧几里得和非欧几里得非对称 TSP。该框架实现了最先进的结果。

##### **Jina-ColBERT-v2: A General-Purpose Multilingual Late Interaction Retriever**
2408.16672v3 by Rohan Jha, Bo Wang, Michael Günther, Georgios Mastrapas, Saba Sturua, Isabelle Mohr, Andreas Koukounas, Mohammad Kalim Akram, Nan Wang, Han Xiao

Multi-vector dense models, such as ColBERT, have proven highly effective in
information retrieval. ColBERT's late interaction scoring approximates the
joint query-document attention seen in cross-encoders while maintaining
inference efficiency closer to traditional dense retrieval models, thanks to
its bi-encoder architecture and recent optimizations in indexing and search. In
this paper, we introduce a novel architecture and a training framework to
support long context window and multilingual retrieval. Our new model,
Jina-ColBERT-v2, demonstrates strong performance across a range of English and
multilingual retrieval tasks,

摘要：多向量稠密模型（例如 ColBERT）已被证明在信息检索中非常有效。ColBERT 的后期交互评分近似于交叉编码器中看到的联合查询文档注意力，同时由于其双编码器架构和索引和搜索中的最新优化，保持了更接近于传统密集检索模型的推理效率。在本文中，我们介绍了一种新颖的架构和一个训练框架，以支持长上下文窗口和多语言检索。我们的新模型 Jina-ColBERT-v2 在一系列英语和多语言检索任务中展示了强大的性能，

##### **Entropic Distribution Matching in Supervised Fine-tuning of LLMs: Less Overfitting and Better Diversity**
2408.16673v1 by Ziniu Li, Congliang Chen, Tian Xu, Zeyu Qin, Jiancong Xiao, Ruoyu Sun, Zhi-Quan Luo

Large language models rely on Supervised Fine-Tuning (SFT) to specialize in
downstream tasks. Cross Entropy (CE) loss is the de facto choice in SFT, but it
often leads to overfitting and limited output diversity due to its aggressive
updates to the data distribution. This paper aim to address these issues by
introducing the maximum entropy principle, which favors models with flatter
distributions that still effectively capture the data. Specifically, we develop
a new distribution matching method called GEM, which solves reverse
Kullback-Leibler divergence minimization with an entropy regularizer.
  For the SFT of Llama-3-8B models, GEM outperforms CE in several aspects.
First, when applied to the UltraFeedback dataset to develop general
instruction-following abilities, GEM exhibits reduced overfitting, evidenced by
lower perplexity and better performance on the IFEval benchmark. Furthermore,
GEM enhances output diversity, leading to performance gains of up to 7 points
on math reasoning and code generation tasks using best-of-n sampling, even
without domain-specific data. Second, when fine-tuning with domain-specific
datasets for math reasoning and code generation, GEM also shows less
overfitting and improvements of up to 10 points compared with CE.

摘要：大型語言模型依賴受控微調 (SFT) 來專精於下游任務。交叉熵 (CE) 損失是 SFT 中的實際選擇，但由於其對資料分佈的激進更新，它經常導致過度擬合和輸出多樣性受限。本文旨在透過引入最大熵原理來解決這些問題，該原理有利於具有較平坦分佈且仍能有效擷取資料的模型。具體來說，我們開發了一種稱為 GEM 的新分佈匹配方法，它以熵正則化求解反向 Kullback-Leibler 散度最小化。對於 Llama-3-8B 模型的 SFT，GEM 在幾個方面優於 CE。首先，當應用於 UltraFeedback 資料集以開發一般的指令遵循能力時，GEM 展現出減少的過度擬合，這由較低的困惑度和在 IFEval 基準上的更好效能所證明。此外，GEM 增強了輸出多樣性，即使沒有特定領域的資料，也能在數學推理和程式碼產生任務中使用最佳 n 採樣獲得高達 7 分的效能提升。其次，當使用特定領域的資料集進行微調以進行數學推理和程式碼產生時，與 CE 相比，GEM 也顯示出較少的過度擬合和高達 10 分的改進。

##### **Iterative Graph Alignment**
2408.16667v1 by Fangyuan Yu, Hardeep Singh Arora, Matt Johnson

By compressing diverse narratives, LLMs go beyond memorization, achieving
intelligence by capturing generalizable causal relationships. However, they
suffer from local 'representation gaps' due to insufficient training data
diversity, limiting their real-world utility, especially in tasks requiring
strict alignment to rules. Traditional alignment methods relying on heavy human
annotations are inefficient and unscalable. Recent self-alignment techniques
also fall short, as they often depend on self-selection based prompting and
memorization-based learning. To address these issues, we introduce Iterative
Graph Alignment (IGA), an annotation-free rule-based alignment algorithm. A
teacher model (VLM) employs Iterative Graph Prompting (IGP) to create logical
graphs and reference answers. The student model (LLM) identifies local
knowledge gaps by attempting to align its responses with these references,
collaborating with helper models to generate diverse answers. These aligned
responses are then used for iterative supervised fine-tuning (SFT). Our
evaluations across five rule-based scenarios demonstrate IGP's effectiveness,
with a 73.12\% alignment improvement in Claude Sonnet 3.5, and
Llama3-8B-Instruct achieving an 86.20\% improvement, outperforming Claude
Sonnet 3.5 in rule-based alignment.

摘要：透過壓縮各種敘述，LLM 不再只是記憶，而是透過擷取可概括的因果關係來實現智能。然而，由於訓練資料的多樣性不足，它們會出現區域性的「表示差距」，這限制了它們在現實世界中的效用，特別是在需要嚴格遵守規則的任務中。傳統的比對方法仰賴大量的人工標註，既沒有效率又無法擴展。最近的自我比對技術也做得不夠好，因為它們通常依賴於基於提示的自我選擇和基於記憶的學習。為了解決這些問題，我們引入了迭代圖形比對 (IGA)，這是一個無需標註的基於規則的比對演算法。教師模型 (VLM) 使用迭代圖形提示 (IGP) 來建立邏輯圖形和參考答案。學生模型 (LLM) 嘗試將其回應與這些參考內容比對，並與輔助模型合作產生多樣化的答案，藉此找出局部知識差距。接著，這些比對後的回應會用於反覆的監督微調 (SFT)。我們在五種基於規則的情境中進行評估，證明了 IGP 的有效性，Claude Sonnet 3.5 的比對改善了 73.12%，而 Llama3-8B-Instruct 的改善達到 86.20%，在基於規則的比對中優於 Claude Sonnet 3.5。

##### **DriveGenVLM: Real-world Video Generation for Vision Language Model based Autonomous Driving**
2408.16647v1 by Yongjie Fu, Anmol Jain, Xuan Di, Xu Chen, Zhaobin Mo

The advancement of autonomous driving technologies necessitates increasingly
sophisticated methods for understanding and predicting real-world scenarios.
Vision language models (VLMs) are emerging as revolutionary tools with
significant potential to influence autonomous driving. In this paper, we
propose the DriveGenVLM framework to generate driving videos and use VLMs to
understand them. To achieve this, we employ a video generation framework
grounded in denoising diffusion probabilistic models (DDPM) aimed at predicting
real-world video sequences. We then explore the adequacy of our generated
videos for use in VLMs by employing a pre-trained model known as Efficient
In-context Learning on Egocentric Videos (EILEV). The diffusion model is
trained with the Waymo open dataset and evaluated using the Fr\'echet Video
Distance (FVD) score to ensure the quality and realism of the generated videos.
Corresponding narrations are provided by EILEV for these generated videos,
which may be beneficial in the autonomous driving domain. These narrations can
enhance traffic scene understanding, aid in navigation, and improve planning
capabilities. The integration of video generation with VLMs in the DriveGenVLM
framework represents a significant step forward in leveraging advanced AI
models to address complex challenges in autonomous driving.

摘要：自動駕駛技術的進展需要越來越精密的方法來理解和預測真實世界的場景。視覺語言模型 (VLM) 正在成為革命性的工具，具有影響自動駕駛的巨大潛力。在本文中，我們提出 DriveGenVLM 架構來生成駕駛影片，並使用 VLM 來理解它們。為此，我們採用了一個基於去噪擴散機率模型 (DDPM) 的影片生成架構，旨在預測真實世界的影片序列。然後，我們透過採用一種稱為自視影片上高效情境學習 (EILEV) 的預訓練模型，來探討我們生成的影片是否足以用於 VLM。擴散模型使用 Waymo 開放資料集進行訓練，並使用 Fr\'echet 影片距離 (FVD) 分數進行評估，以確保生成影片的品質和真實性。EILEV 為這些生成的影片提供了對應的旁白，這可能有助於自動駕駛領域。這些旁白可以增強對交通場景的理解、協助導航，並改善規劃能力。在 DriveGenVLM 架構中整合影片生成和 VLM，代表了在利用進階 AI 模型來解決自動駕駛中的複雜挑戰方面向前邁進了一大步。

##### **RLCP: A Reinforcement Learning-based Copyright Protection Method for Text-to-Image Diffusion Model**
2408.16634v2 by Zhuan Shi, Jing Yan, Xiaoli Tang, Lingjuan Lyu, Boi Faltings

The increasing sophistication of text-to-image generative models has led to
complex challenges in defining and enforcing copyright infringement criteria
and protection. Existing methods, such as watermarking and dataset
deduplication, fail to provide comprehensive solutions due to the lack of
standardized metrics and the inherent complexity of addressing copyright
infringement in diffusion models. To deal with these challenges, we propose a
Reinforcement Learning-based Copyright Protection(RLCP) method for
Text-to-Image Diffusion Model, which minimizes the generation of
copyright-infringing content while maintaining the quality of the
model-generated dataset. Our approach begins with the introduction of a novel
copyright metric grounded in copyright law and court precedents on
infringement. We then utilize the Denoising Diffusion Policy Optimization
(DDPO) framework to guide the model through a multi-step decision-making
process, optimizing it using a reward function that incorporates our proposed
copyright metric. Additionally, we employ KL divergence as a regularization
term to mitigate some failure modes and stabilize RL fine-tuning. Experiments
conducted on 3 mixed datasets of copyright and non-copyright images demonstrate
that our approach significantly reduces copyright infringement risk while
maintaining image quality.

摘要：隨著文字轉圖片生成模型的複雜性日益提升，在定義和執行著作權侵權標準及保護方面產生了複雜的挑戰。現有的方法，例如浮水印和資料集去重，由於缺乏標準化指標和處理擴散模型中著作權侵權的固有複雜性，無法提供全面的解決方案。為了解決這些挑戰，我們提出了一種基於強化學習的文字轉圖片擴散模型著作權保護 (RLCP) 方法，該方法在維持模型生成資料集品質的同時，將著作權侵權內容的生成降至最低。我們的做法始於引入一種新的著作權指標，該指標基於著作權法和侵權方面的法院判例。然後，我們利用去噪擴散策略最佳化 (DDPO) 架構引導模型進行多步驟決策制定，使用結合我們提出的著作權指標的獎勵函數對其進行最佳化。此外，我們採用 KL 散度作為正則化項，以減輕某些失敗模式並穩定 RL 微調。在 3 個著作權和非著作權圖像的混合資料集上進行的實驗表明，我們的做法顯著降低了著作權侵權風險，同時維持了圖像品質。

##### **Optimizing Automated Picking Systems in Warehouse Robots Using Machine Learning**
2408.16633v1 by Keqin Li, Jin Wang, Xubo Wu, Xirui Peng, Runmian Chang, Xiaoyu Deng, Yiwen Kang, Yue Yang, Fanghao Ni, Bo Hong

With the rapid growth of global e-commerce, the demand for automation in the
logistics industry is increasing. This study focuses on automated picking
systems in warehouses, utilizing deep learning and reinforcement learning
technologies to enhance picking efficiency and accuracy while reducing system
failure rates. Through empirical analysis, we demonstrate the effectiveness of
these technologies in improving robot picking performance and adaptability to
complex environments. The results show that the integrated machine learning
model significantly outperforms traditional methods, effectively addressing the
challenges of peak order processing, reducing operational errors, and improving
overall logistics efficiency. Additionally, by analyzing environmental factors,
this study further optimizes system design to ensure efficient and stable
operation under variable conditions. This research not only provides innovative
solutions for logistics automation but also offers a theoretical and empirical
foundation for future technological development and application.

摘要：隨著全球電子商務的快速發展，物流產業對自動化的需求與日俱增。本研究著重於倉庫中的自動化揀貨系統，利用深度學習與強化學習技術，以提升揀貨效率與準確度，同時降低系統故障率。透過實證分析，我們證明了這些技術在提升機器人揀貨效能與適應複雜環境的有效性。結果顯示，整合機器學習模型顯著優於傳統方法，有效解決尖峰訂單處理的挑戰，減少作業錯誤，並提升整體物流效率。此外，本研究透過分析環境因素，進一步最佳化系統設計，以確保在變動的條件下能有效且穩定的運作。本研究不僅為物流自動化提供了創新的解決方案，也為未來的技術發展與應用奠定了理論與實證基礎。

##### **Maelstrom Networks**
2408.16632v1 by Matthew Evanusa, Cornelia Fermüller, Yiannis Aloimonos

Artificial Neural Networks has struggled to devise a way to incorporate
working memory into neural networks. While the ``long term'' memory can be seen
as the learned weights, the working memory consists likely more of dynamical
activity, that is missing from feed-forward models. Current state of the art
models such as transformers tend to ``solve'' this by ignoring working memory
entirely and simply process the sequence as an entire piece of data; however
this means the network cannot process the sequence in an online fashion, and
leads to an immense explosion in memory requirements. Here, inspired by a
combination of controls, reservoir computing, deep learning, and recurrent
neural networks, we offer an alternative paradigm that combines the strength of
recurrent networks, with the pattern matching capability of feed-forward neural
networks, which we call the \textit{Maelstrom Networks} paradigm. This paradigm
leaves the recurrent component - the \textit{Maelstrom} - unlearned, and
offloads the learning to a powerful feed-forward network. This allows the
network to leverage the strength of feed-forward training without unrolling the
network, and allows for the memory to be implemented in new neuromorphic
hardware. It endows a neural network with a sequential memory that takes
advantage of the inductive bias that data is organized causally in the temporal
domain, and imbues the network with a state that represents the agent's
``self'', moving through the environment. This could also lead the way to
continual learning, with the network modularized and ``'protected'' from
overwrites that come with new data. In addition to aiding in solving these
performance problems that plague current non-temporal deep networks, this also
could finally lead towards endowing artificial networks with a sense of
``self''.

摘要：人工神经网络一直努力想办法将工作记忆纳入神经网络中。虽然「长期」记忆可以看作是学习到的权重，但工作记忆可能更多地由动态活动组成，而这在前馈模型中是不存在的。目前最先进的模型（例如变压器）倾向于通过完全忽略工作记忆并简单地将序列处理为整个数据块来「解决」这个问题；然而，这意味着网络无法在线处理序列，并导致内存需求激增。在这里，受控制、储层计算、深度学习和循环神经网络的组合启发，我们提供了一种替代范例，它结合了循环网络的优势和前馈神经网络的模式匹配能力，我们称之为\textit{Maelstrom Networks}范例。此范例将循环组件（即\textit{Maelstrom}）保持未学习状态，并将学习卸载到强大的前馈网络。这使网络能够利用前馈训练的优势，而无需展开网络，并允许在新的神经形态硬件中实现内存。它赋予神经网络一种顺序记忆，该记忆利用了数据在时间域中因果组织的归纳偏置，并赋予网络一种状态，该状态表示代理的「自我」，在环境中移动。这还可以为持续学习铺平道路，网络模块化并「受保护」，免受新数据带来的覆盖。除了帮助解决困扰当前非时间深度网络的这些性能问题之外，这最终还可以赋予人工网络一种「自我」意识。

##### **LLMs generate structurally realistic social networks but overestimate political homophily**
2408.16629v1 by Serina Chang, Alicja Chaszczewicz, Emma Wang, Maya Josifovska, Emma Pierson, Jure Leskovec

Generating social networks is essential for many applications, such as
epidemic modeling and social simulations. Prior approaches either involve deep
learning models, which require many observed networks for training, or stylized
models, which are limited in their realism and flexibility. In contrast, LLMs
offer the potential for zero-shot and flexible network generation. However, two
key questions are: (1) are LLM's generated networks realistic, and (2) what are
risks of bias, given the importance of demographics in forming social ties? To
answer these questions, we develop three prompting methods for network
generation and compare the generated networks to real social networks. We find
that more realistic networks are generated with "local" methods, where the LLM
constructs relations for one persona at a time, compared to "global" methods
that construct the entire network at once. We also find that the generated
networks match real networks on many characteristics, including density,
clustering, community structure, and degree. However, we find that LLMs
emphasize political homophily over all other types of homophily and
overestimate political homophily relative to real-world measures.

摘要：生成社交網路對於許多應用程式來說至關重要，例如流行病建模和社交模擬。先前的做法包括深度學習模型，這需要許多已觀察到的網路進行訓練，或樣式化模型，其真實性和靈活性受到限制。相比之下，LLM 提供了零次學習和靈活網路生成的潛力。然而，有兩個關鍵問題：(1) LLM 生成的網路是否真實，以及 (2) 鑑於人口統計資料在形成社交關係中的重要性，有哪些偏見風險？為了回答這些問題，我們開發了三種提示方法來生成網路，並將生成的網路與真實的社交網路進行比較。我們發現使用「局部」方法生成了更真實的網路，其中 LLM 一次為一個角色建立關係，相比之下，「全域」方法一次建立整個網路。我們還發現生成的網路在許多特徵上與真實網路相符，包括密度、群集、社群結構和程度。然而，我們發現 LLM 強調政治同質性勝過所有其他類型的同質性，並且高估了政治同質性相對於真實世界的衡量標準。

##### **Towards Infusing Auxiliary Knowledge for Distracted Driver Detection**
2408.16621v1 by Ishwar B Balappanawar, Ashmit Chamoli, Ruwan Wickramarachchi, Aditya Mishra, Ponnurangam Kumaraguru, Amit P. Sheth

Distracted driving is a leading cause of road accidents globally.
Identification of distracted driving involves reliably detecting and
classifying various forms of driver distraction (e.g., texting, eating, or
using in-car devices) from in-vehicle camera feeds to enhance road safety. This
task is challenging due to the need for robust models that can generalize to a
diverse set of driver behaviors without requiring extensive annotated datasets.
In this paper, we propose KiD3, a novel method for distracted driver detection
(DDD) by infusing auxiliary knowledge about semantic relations between entities
in a scene and the structural configuration of the driver's pose. Specifically,
we construct a unified framework that integrates the scene graphs, and driver
pose information with the visual cues in video frames to create a holistic
representation of the driver's actions.Our results indicate that KiD3 achieves
a 13.64% accuracy improvement over the vision-only baseline by incorporating
such auxiliary knowledge with visual information.

摘要：分心駕駛是全球道路事故的主要原因。
分心駕駛的識別涉及從車載相機饋送中可靠地檢測和分類各種形式的駕駛分心（例如發簡訊、進食或使用車載設備），以增強道路安全。由於需要強大的模型才能概括到各種駕駛行為，而無需大量的註釋數據集，因此這項任務具有挑戰性。
在本文中，我們提出了 KiD3，這是一種新的分心駕駛檢測 (DDD) 方法，通過注入場景中實體之間語義關係和駕駛員姿勢結構配置的輔助知識。具體來說，我們構建了一個統一的框架，將場景圖、駕駛員姿勢信息與視頻幀中的視覺線索集成在一起，以創建駕駛員動作的整體表示。我們的結果表明，KiD3 通過將這種輔助知識與視覺信息相結合，比僅視覺基準提高了 13.64% 的準確率。

##### **Hyperdimensional Vector Tsetlin Machines with Applications to Sequence Learning and Generation**
2408.16620v1 by Christian D. Blakely

We construct a two-layered model for learning and generating sequential data
that is both computationally fast and competitive with vanilla Tsetlin
machines, adding numerous advantages. Through the use of hyperdimensional
vector computing (HVC) algebras and Tsetlin machine clause structures, we
demonstrate that the combination of both inherits the generality of data
encoding and decoding of HVC with the fast interpretable nature of Tsetlin
machines to yield a powerful machine learning model. We apply the approach in
two areas, namely in forecasting, generating new sequences, and classification.
For the latter, we derive results for the entire UCR Time Series Archive and
compare with the standard benchmarks to see how well the method competes in
time series classification.

摘要：我們建構了一個兩層模型來學習和生成順序資料，它在計算上既快速又與香草 Tsetlin 機器競爭，並增加了許多優點。透過使用超維度向量運算 (HVC) 代數和 Tsetlin 機器子句結構，我們證明了兩者的結合繼承了 HVC 資料編碼和解碼的普遍性，以及 Tsetlin 機器的快速可解釋性質，產生了一個強大的機器學習模型。我們在兩個領域應用此方法，即預測、產生新序列和分類。對於後者，我們導出整個 UCR 時間序列檔案的結果，並與標準基準進行比較，以了解該方法在時間序列分類中的競爭程度。

##### **Examination of Code generated by Large Language Models**
2408.16601v1 by Robin Beer, Alexander Feix, Tim Guttzeit, Tamara Muras, Vincent Müller, Maurice Rauscher, Florian Schäffler, Welf Löwe

Large language models (LLMs), such as ChatGPT and Copilot, are transforming
software development by automating code generation and, arguably, enable rapid
prototyping, support education, and boost productivity. Therefore, correctness
and quality of the generated code should be on par with manually written code.
To assess the current state of LLMs in generating correct code of high quality,
we conducted controlled experiments with ChatGPT and Copilot: we let the LLMs
generate simple algorithms in Java and Python along with the corresponding unit
tests and assessed the correctness and the quality (coverage) of the generated
(test) codes. We observed significant differences between the LLMs, between the
languages, between algorithm and test codes, and over time. The present paper
reports these results together with the experimental methods allowing repeated
and comparable assessments for more algorithms, languages, and LLMs over time.

摘要：大型語言模型 (LLM)，例如 ChatGPT 和 Copilot，透過自動化程式碼產生，並可快速建構原型、支援教育，以及提升生產力，轉變軟體開發。因此，產生的程式碼的正確性和品質應與手寫程式碼相當。為評估 LLM 在產生高品質正確程式碼的現況，我們對 ChatGPT 和 Copilot 進行受控實驗：我們讓 LLM 產生 Java 和 Python 中的簡單演算法以及對應的單元測試，並評估產生的 (測試) 程式碼的正確性和品質 (涵蓋範圍)。我們觀察到 LLM 之間、語言之間、演算法和測試程式碼之間，以及隨著時間推移的顯著差異。本文報告了這些結果以及實驗方法，允許隨著時間推移對更多演算法、語言和 LLM 進行重複且可比較的評估。

##### **Enhancing Dialogue Generation in Werewolf Game Through Situation Analysis and Persuasion Strategies**
2408.16586v2 by Zhiyang Qi, Michimasa Inaba

Recent advancements in natural language processing, particularly with large
language models (LLMs) like GPT-4, have significantly enhanced dialogue
systems, enabling them to generate more natural and fluent conversations.
Despite these improvements, challenges persist, such as managing continuous
dialogues, memory retention, and minimizing hallucinations. The AIWolfDial2024
addresses these challenges by employing the Werewolf Game, an incomplete
information game, to test the capabilities of LLMs in complex interactive
environments. This paper introduces a LLM-based Werewolf Game AI, where each
role is supported by situation analysis to aid response generation.
Additionally, for the werewolf role, various persuasion strategies, including
logical appeal, credibility appeal, and emotional appeal, are employed to
effectively persuade other players to align with its actions.

摘要：自然語言處理的最新進展，特別是 GPT-4 等大型語言模型 (LLM)，已顯著增強對話系統，讓它們能夠產生更自然且流暢的對話。儘管有這些改進，但挑戰依然存在，例如管理連續對話、記憶保留和最小化幻覺。AIWolfDial2024 採用不完全資訊遊戲狼人遊戲來解決這些挑戰，以測試 LLM 在複雜互動環境中的能力。本文介紹了基於 LLM 的狼人遊戲 AI，其中每個角色都透過情境分析來協助回應產生。此外，對於狼人角色，採用各種說服策略，包括邏輯訴求、信譽訴求和情感訴求，以有效說服其他玩家配合其行動。

##### **Seeking the Sufficiency and Necessity Causal Features in Multimodal Representation Learning**
2408.16577v1 by Boyu Chen, Junjie Liu, Zhu Li, Mengyue yang

Learning representations with a high Probability of Necessary and Sufficient
Causes (PNS) has been shown to enhance deep learning models' ability. This task
involves identifying causal features that are both sufficient (guaranteeing the
outcome) and necessary (without which the outcome cannot occur). However,
current research predominantly focuses on unimodal data, and extending PNS
learning to multimodal settings presents significant challenges. The challenges
arise as the conditions for PNS identifiability, Exogeneity and Monotonicity,
need to be reconsidered in a multimodal context, where sufficient and necessary
causal features are distributed across different modalities. To address this,
we first propose conceptualizing multimodal representations as comprising
modality-invariant and modality-specific components. We then analyze PNS
identifiability for each component, while ensuring non-trivial PNS estimation.
Finally, we formulate tractable optimization objectives that enable multimodal
models to learn high-PNS representations, thereby enhancing their predictive
performance. Experiments demonstrate the effectiveness of our method on both
synthetic and real-world data.

摘要：學習具有必要的和充分原因 (PNS) 的高機率表示法已被證明可以增強深度學習模型的能力。此任務涉及識別既充分（保證結果）又必要（沒有它結果無法發生）的因果特徵。然而，目前的研究所主要集中於單模態資料，將 PNS 學習擴展到多模態設定會產生重大挑戰。挑戰在於 PNS 可識別性、外生性和單調性的條件需要在多模態上下文中重新考慮，其中充分且必要的因果特徵分布在不同的模態中。為了解決這個問題，我們首先提出將多模態表示概念化為包含模態不變和模態特定組成部分。然後，我們分析每個組成部分的 PNS 可識別性，同時確保非平凡的 PNS 估計。最後，我們制定可行的最佳化目標，使多模態模型能夠學習高 PNS 表示，從而增強其預測性能。實驗證明了我們的方法在合成和真實世界資料上的有效性。

##### **Predictability maximization and the origins of word order harmony**
2408.16570v1 by Ramon Ferrer-i-Cancho

We address the linguistic problem of the sequential arrangement of a head and
its dependents from an information theoretic perspective. In particular, we
consider the optimal placement of a head that maximizes the predictability of
the sequence. We assume that dependents are statistically independent given a
head, in line with the open-choice principle and the core assumptions of
dependency grammar. We demonstrate the optimality of harmonic order, i.e.,
placing the head last maximizes the predictability of the head whereas placing
the head first maximizes the predictability of dependents. We also show that
postponing the head is the optimal strategy to maximize its predictability
while bringing it forward is the optimal strategy to maximize the
predictability of dependents. We unravel the advantages of the strategy of
maximizing the predictability of the head over maximizing the predictability of
dependents. Our findings shed light on the placements of the head adopted by
real languages or emerging in different kinds of experiments.

摘要：我們從資訊理論的角度探討頭部及其依賴項的順序排列的語言學問題。特別是，我們考慮頭部的最佳位置，以最大化序列的可預測性。我們假設依賴項在給定頭部時在統計上是獨立的，這符合開放選擇原則和依賴語法的核心假設。我們證明了諧波順序的最優性，即把頭部放在最後可以最大化頭部的可預測性，而把頭部放在第一個可以最大化依賴項的可預測性。我們還表明，延後頭部是最大化其可預測性的最佳策略，而提前頭部是最大化依賴項可預測性的最佳策略。我們揭示了最大化頭部可預測性策略相對於最大化依賴項可預測性的優點。我們的發現揭示了實際語言採用的頭部位置或在不同類型的實驗中出現的頭部位置。

##### **SALSA: Speedy ASR-LLM Synchronous Aggregation**
2408.16542v1 by Ashish Mittal, Darshan Prabhu, Sunita Sarawagi, Preethi Jyothi

Harnessing pre-trained LLMs to improve ASR systems, particularly for
low-resource languages, is now an emerging area of research. Existing methods
range from using LLMs for ASR error correction to tightly coupled systems that
replace the ASR decoder with the LLM. These approaches either increase decoding
time or require expensive training of the cross-attention layers. We propose
SALSA, which couples the decoder layers of the ASR to the LLM decoder, while
synchronously advancing both decoders. Such coupling is performed with a simple
projection of the last decoder state, and is thus significantly more training
efficient than earlier approaches. A challenge of our proposed coupling is
handling the mismatch between the tokenizers of the LLM and ASR systems. We
handle this mismatch using cascading tokenization with respect to the LLM and
ASR vocabularies. We evaluate SALSA on 8 low-resource languages in the FLEURS
benchmark, yielding substantial WER reductions of up to 38%.

摘要：利用預先訓練的 LLM 來改善 ASR 系統，特別針對低資源語言，現在是一個新興的研究領域。現有方法從使用 LLM 進行 ASR 錯誤修正到使用 LLM 取代 ASR 解碼器的緊密耦合系統。這些方法會增加解碼時間或需要對交叉注意層進行昂貴的訓練。我們提出 SALSA，它將 ASR 的解碼器層與 LLM 解碼器耦合，同時同步推進兩個解碼器。這種耦合是通過對最後解碼器狀態進行簡單投影來執行，因此比早期的訓練方法顯著提高了訓練效率。我們提出的耦合面臨的挑戰是處理 LLM 和 ASR 系統的標記化器之間的不匹配。我們使用針對 LLM 和 ASR 詞彙表進行串聯標記化來處理這種不匹配。我們在 FLEURS 基準測試中的 8 種低資源語言上評估 SALSA，獲得了高達 38% 的 WER 顯著降低。

##### **SFR-GNN: Simple and Fast Robust GNNs against Structural Attacks**
2408.16537v2 by Xing Ai, Guanyu Zhu, Yulin Zhu, Yu Zheng, Gaolei Li, Jianhua Li, Kai Zhou

Graph Neural Networks (GNNs) have demonstrated commendable performance for
graph-structured data. Yet, GNNs are often vulnerable to adversarial structural
attacks as embedding generation relies on graph topology. Existing efforts are
dedicated to purifying the maliciously modified structure or applying adaptive
aggregation, thereby enhancing the robustness against adversarial structural
attacks. It is inevitable for a defender to consume heavy computational costs
due to lacking prior knowledge about modified structures. To this end, we
propose an efficient defense method, called Simple and Fast Robust Graph Neural
Network (SFR-GNN), supported by mutual information theory. The SFR-GNN first
pre-trains a GNN model using node attributes and then fine-tunes it over the
modified graph in the manner of contrastive learning, which is free of
purifying modified structures and adaptive aggregation, thus achieving great
efficiency gains. Consequently, SFR-GNN exhibits a 24%--162% speedup compared
to advanced robust models, demonstrating superior robustness for node
classification tasks.

摘要：圖形神經網路 (GNN) 已證明在圖形結構資料中表現優異。然而，GNN 經常容易受到對抗性結構攻擊，因為嵌入產生依賴於圖形拓撲。現有的努力專注於淨化惡意修改的結構或應用自適應聚合，從而增強對抗對抗性結構攻擊的魯棒性。由於缺乏關於修改結構的先驗知識，因此防禦者不可避免地會消耗大量的運算成本。為此，我們提出了一種稱為簡單且快速的魯棒圖形神經網路 (SFR-GNN) 的高效防禦方法，該方法由互信息理論支持。SFR-GNN 首先使用節點屬性預訓練 GNN 模型，然後以對比學習的方式對修改後的圖形進行微調，這無需淨化修改後的結構和自適應聚合，從而獲得巨大的效率提升。因此，與先進的魯棒模型相比，SFR-GNN 表現出 24%--162% 的加速，證明了節點分類任務的卓越魯棒性。

##### **CNIMA: A Universal Evaluation Framework and Automated Approach for Assessing Second Language Dialogues**
2408.16518v1 by Rena Gao, Jingxuan Wu, Carsten Roever, Xuetong Wu, Jing Wu, Long Lv, Jey Han Lau

We develop CNIMA (Chinese Non-Native Interactivity Measurement and
Automation), a Chinese-as-a-second-language labelled dataset with 10K
dialogues. We annotate CNIMA using an evaluation framework -- originally
introduced for English-as-a-second-language dialogues -- that assesses
micro-level features (e.g.\ backchannels) and macro-level interactivity labels
(e.g.\ topic management) and test the framework's transferability from English
to Chinese. We found the framework robust across languages and revealed
universal and language-specific relationships between micro-level and
macro-level features. Next, we propose an approach to automate the evaluation
and find strong performance, creating a new tool for automated second language
assessment. Our system can be adapted to other languages easily as it uses
large language models and as such does not require large-scale annotated
training data.

摘要：我們開發了 CNIMA（華語非母語互動測量與自動化），這是一個標有 10K 對話的華語作為第二語言的標記資料集。我們使用原本用於英語作為第二語言對話的評估架構來標記 CNIMA，該架構評估微觀層級特徵（例如反向頻道）和巨觀層級互動標籤（例如主題管理），並測試該架構從英語到華語的可移植性。我們發現該架構在各語言間具有強健性，並揭示了微觀層級和巨觀層級特徵之間的通用和特定於語言的關係。接下來，我們提出了一種自動化評估的方法，並發現強大的效能，創造了一個用於自動化第二語言評估的新工具。我們的系統可以輕鬆地調整到其他語言，因為它使用大型語言模型，因此不需要大量標記的訓練資料。

##### **Adaptive Variational Continual Learning via Task-Heuristic Modelling**
2408.16517v1 by Fan Yang

Variational continual learning (VCL) is a turn-key learning algorithm that
has state-of-the-art performance among the best continual learning models. In
our work, we explore an extension of the generalized variational continual
learning (GVCL) model, named AutoVCL, which combines task heuristics for
informed learning and model optimization. We demonstrate that our model
outperforms the standard GVCL with fixed hyperparameters, benefiting from the
automatic adjustment of the hyperparameter based on the difficulty and
similarity of the incoming task compared to the previous tasks.

摘要：變異持續學習 (VCL) 是一種交鑰匙學習演算法，在最佳持續學習模型中具有最先進的效能。在我們的研究中，我們探討廣義變異持續學習 (GVCL) 模型的延伸，稱為 AutoVCL，它結合任務啟發法，用於明智的學習和模型最佳化。我們證明我們的模型優於具有固定超參數的標準 GVCL，受益於根據與前一個任務相比的新進任務的難度和相似性自動調整超參數。

##### **HLogformer: A Hierarchical Transformer for Representing Log Data**
2408.16803v1 by Zhichao Hou, Mina Ghashami, Mikhail Kuznetsov, MohamadAli Torkamani

Transformers have gained widespread acclaim for their versatility in handling
diverse data structures, yet their application to log data remains
underexplored. Log data, characterized by its hierarchical, dictionary-like
structure, poses unique challenges when processed using conventional
transformer models. Traditional methods often rely on manually crafted
templates for parsing logs, a process that is labor-intensive and lacks
generalizability. Additionally, the linear treatment of log sequences by
standard transformers neglects the rich, nested relationships within log
entries, leading to suboptimal representations and excessive memory usage.
  To address these issues, we introduce HLogformer, a novel hierarchical
transformer framework specifically designed for log data. HLogformer leverages
the hierarchical structure of log entries to significantly reduce memory costs
and enhance representation learning. Unlike traditional models that treat log
data as flat sequences, our framework processes log entries in a manner that
respects their inherent hierarchical organization. This approach ensures
comprehensive encoding of both fine-grained details and broader contextual
relationships.
  Our contributions are threefold: First, HLogformer is the first framework to
design a dynamic hierarchical transformer tailored for dictionary-like log
data. Second, it dramatically reduces memory costs associated with processing
extensive log sequences. Third, comprehensive experiments demonstrate that
HLogformer more effectively encodes hierarchical contextual information,
proving to be highly effective for downstream tasks such as synthetic anomaly
detection and product recommendation.

摘要：<paragraph>Transformer因其處理各種數據結構的多功能性而廣受好評，但其在日誌數據中的應用仍未得到充分探索。日誌數據以其分層、字典般的結構為特徵，在使用傳統Transformer模型處理時會帶來獨特的挑戰。傳統方法通常依賴於人工製作的模板來解析日誌，這是一個勞動密集且缺乏普遍性的過程。此外，標準Transformer對日誌序列的線性處理忽略了日誌條目中豐富的嵌套關係，導致次優表示和過度內存使用。
為了解決這些問題，我們引入了 HLogformer，這是一個專門為日誌數據設計的新型分層Transformer框架。HLogformer 利用日誌條目的分層結構來顯著降低內存成本並增強表示學習。與將日誌數據視為平面序列的傳統模型不同，我們的框架以尊重其固有分層組織的方式處理日誌條目。這種方法確保了對細粒度細節和更廣泛的上下文關係的全面編碼。
我們的貢獻有三方面：首先，HLogformer 是第一個設計了針對字典式日誌數據的動態分層Transformer的框架。其次，它顯著降低了與處理大量日誌序列相關的內存成本。第三，綜合實驗表明，HLogformer 更有效地編碼分層上下文信息，證明對合成異常檢測和產品推薦等下游任務非常有效。</paragraph>

##### **LLMs vs Established Text Augmentation Techniques for Classification: When do the Benefits Outweight the Costs?**
2408.16502v1 by Jan Cegin, Jakub Simko, Peter Brusilovsky

The generative large language models (LLMs) are increasingly being used for
data augmentation tasks, where text samples are LLM-paraphrased and then used
for classifier fine-tuning. However, a research that would confirm a clear
cost-benefit advantage of LLMs over more established augmentation methods is
largely missing. To study if (and when) is the LLM-based augmentation
advantageous, we compared the effects of recent LLM augmentation methods with
established ones on 6 datasets, 3 classifiers and 2 fine-tuning methods. We
also varied the number of seeds and collected samples to better explore the
downstream model accuracy space. Finally, we performed a cost-benefit analysis
and show that LLM-based methods are worthy of deployment only when very small
number of seeds is used. Moreover, in many cases, established methods lead to
similar or better model accuracies.

摘要：生成式大型語言模型（LLM）正越來越多地用於資料擴充任務，其中文字範例經過 LLM 重新詮釋，然後用於分類器微調。然而，一項研究將確認 LLM 相較於更既定的擴充方法具有明顯的成本效益優勢，這在很大程度上是缺失的。為了研究 LLM 基於擴充是否（以及何時）具有優勢，我們比較了近期 LLM 擴充方法與既定方法在 6 個資料集、3 個分類器和 2 個微調方法上的效果。我們也改變了種子數和收集的範例，以更好地探索下游模型準確性空間。最後，我們執行了一個成本效益分析，並顯示基於 LLM 的方法只有在使用極少數的種子時才值得部署。此外，在許多情況下，既定方法會導致相似或更好的模型準確性。

##### **On-device AI: Quantization-aware Training of Transformers in Time-Series**
2408.16495v1 by Tianheng Ling, Gregor Schiele

Artificial Intelligence (AI) models for time-series in pervasive computing
keep getting larger and more complicated. The Transformer model is by far the
most compelling of these AI models. However, it is difficult to obtain the
desired performance when deploying such a massive model on a sensor device with
limited resources. My research focuses on optimizing the Transformer model for
time-series forecasting tasks. The optimized model will be deployed as hardware
accelerators on embedded Field Programmable Gate Arrays (FPGAs). I will
investigate the impact of applying Quantization-aware Training to the
Transformer model to reduce its size and runtime memory footprint while
maximizing the advantages of FPGAs.

摘要：人工智慧（AI）模型在普遍運算中的時間序列持續變大且更複雜。Transformer 模型是目前最引人注目的 AI 模型。然而，在資源有限的感測器裝置上部署如此龐大的模型時，難以獲得理想的效能。我的研究重點在於最佳化 Transformer 模型，以進行時間序列預測任務。最佳化的模型將部署為嵌入式現場可編程閘陣列（FPGA）上的硬體加速器。我將探討將量化感知訓練應用於 Transformer 模型的影響，以縮小其大小和執行時期記憶體佔用空間，同時最大化 FPGA 的優勢。

##### **Learning from Negative Samples in Generative Biomedical Entity Linking**
2408.16493v1 by Chanhwi Kim, Hyunjae Kim, Sihyeon Park, Jiwoo Lee, Mujeen Sung, Jaewoo Kang

Generative models have become widely used in biomedical entity linking
(BioEL) due to their excellent performance and efficient memory usage. However,
these models are usually trained only with positive samples--entities that
match the input mention's identifier--and do not explicitly learn from hard
negative samples, which are entities that look similar but have different
meanings. To address this limitation, we introduce ANGEL (Learning from
Negative Samples in Generative Biomedical Entity Linking), the first framework
that trains generative BioEL models using negative samples. Specifically, a
generative model is initially trained to generate positive samples from the
knowledge base for given input entities. Subsequently, both correct and
incorrect outputs are gathered from the model's top-k predictions. The model is
then updated to prioritize the correct predictions through direct preference
optimization. Our models fine-tuned with ANGEL outperform the previous best
baseline models by up to an average top-1 accuracy of 1.4% on five benchmarks.
When incorporating our framework into pre-training, the performance improvement
further increases to 1.7%, demonstrating its effectiveness in both the
pre-training and fine-tuning stages. Our code is available at
https://github.com/dmis-lab/ANGEL.

摘要：生成模型因其出色的性能和高效的内存使用而被广泛用于生物医学实体链接 (BioEL)。然而，这些模型通常仅使用正面样本（与输入提及的标识符匹配的实体）进行训练，并且不会明确地从硬负面样本（看起来相似但具有不同含义的实体）中学习。为了解决这一限制，我们引入了 ANGEL（生成生物医学实体链接中的负样本学习），这是第一个使用负样本训练生成 BioEL 模型的框架。具体来说，最初训练一个生成模型，以便为给定的输入实体从知识库中生成正样本。随后，从模型的 top-k 预测中收集正确和不正确的输出。然后更新模型以通过直接偏好优化来优先考虑正确的预测。我们用 ANGEL 微调的模型在五个基准上将之前的最佳基线模型的平均 top-1 准确率提高了 1.4%。当将我们的框架纳入预训练时，性能提升进一步提高到 1.7%，这证明了其在预训练和微调阶段的有效性。我们的代码可在 https://github.com/dmis-lab/ANGEL 获得。

