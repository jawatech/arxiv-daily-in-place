{"2308.02047": {"publish_time": "2023-07-26", "title": "Acceptable risks in Europe's proposed AI Act: Reasonableness and other principles for deciding how much risk management is enough", "paper_summary": "This paper critically evaluates the European Commission's proposed AI Act's\napproach to risk management and risk acceptability for high-risk AI systems\nthat pose risks to fundamental rights and safety. The Act aims to promote\n\"trustworthy\" AI with a proportionate regulatory burden. Its provisions on risk\nacceptability require residual risks from high-risk systems to be reduced or\neliminated \"as far as possible\", having regard to the \"state of the art\". This\ncriterion, especially if interpreted narrowly, is unworkable and promotes\nneither proportionate regulatory burden, nor trustworthiness. By contrast the\nParliament's most recent draft amendments to the risk management provisions\nintroduce \"reasonableness\", cost-benefit analysis, and are more transparent\nabout the value-laden and contextual nature of risk acceptability judgements.\nThis paper argues that the Parliament's approach is more workable, and better\nbalances the goals of proportionality and trustworthiness. It explains what\nreasonableness in risk acceptability judgments would entail, drawing on\nprinciples from negligence law and European medical devices regulation. And it\ncontends that the approach to risk acceptability judgments need a firm\nfoundation of civic legitimacy: including detailed guidance or involvement from\nregulators, and meaningful input from affected stakeholders.", "paper_summary_zh": "", "author": "Henry Fraser et.al.", "authors": "Henry Fraser,Jose-Miguel Bello y Villarino", "id": "2308.02047v1", "paper_url": "http://arxiv.org/abs/2308.02047v1", "repo": "null"}}