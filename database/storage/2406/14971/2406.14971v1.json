{"2406.14971": {"publish_time": "2024-06-21", "title": "Domain Adaptation of Llama3-70B-Instruct through Continual Pre-Training and Model Merging: A Comprehensive Evaluation", "paper_summary": "We conducted extensive experiments on domain adaptation of the\nMeta-Llama-3-70B-Instruct model on SEC data, exploring its performance on both\ngeneral and domain-specific benchmarks. Our focus included continual\npre-training (CPT) and model merging, aiming to enhance the model's\ndomain-specific capabilities while mitigating catastrophic forgetting. Through\nthis study, we evaluated the impact of integrating financial regulatory data\ninto a robust language model and examined the effectiveness of our model\nmerging techniques in preserving and improving the model's instructive\nabilities. The model is accessible at hugging face:\nhttps://huggingface.co/arcee-ai/Llama-3-SEC-Base, arcee-ai/Llama-3-SEC-Base.\nThis is an intermediate checkpoint of our final model, which has seen 20B\ntokens so far. The full model is still in the process of training. This is a\npreprint technical report with thorough evaluations to understand the entire\nprocess.", "paper_summary_zh": "\u6211\u5011\u5c0d Meta-Llama-3-70B-Instruct \u6a21\u578b\u5728 SEC \u6578\u64da\u4e0a\u7684\u9818\u57df\u9069\u61c9\u9032\u884c\u4e86\u5ee3\u6cdb\u7684\u5be6\u9a57\uff0c\u63a2\u8a0e\u4e86\u5b83\u5728\u901a\u7528\u548c\u7279\u5b9a\u9818\u57df\u57fa\u6e96\u4e0a\u7684\u6548\u80fd\u3002\u6211\u5011\u7684\u91cd\u9ede\u5305\u62ec\u6301\u7e8c\u9810\u8a13\u7df4 (CPT) \u548c\u6a21\u578b\u5408\u4f75\uff0c\u76ee\u7684\u662f\u589e\u5f37\u6a21\u578b\u7684\u7279\u5b9a\u9818\u57df\u80fd\u529b\uff0c\u540c\u6642\u6e1b\u8f15\u707d\u96e3\u6027\u907a\u5fd8\u3002\u900f\u904e\u9019\u9805\u7814\u7a76\uff0c\u6211\u5011\u8a55\u4f30\u4e86\u5c07\u91d1\u878d\u76e3\u7ba1\u6578\u64da\u6574\u5408\u5230\u5f37\u5927\u7684\u8a9e\u8a00\u6a21\u578b\u4e2d\u7684\u5f71\u97ff\uff0c\u4e26\u6aa2\u8996\u4e86\u6211\u5011\u7684\u6a21\u578b\u5408\u4f75\u6280\u8853\u5728\u4fdd\u7559\u548c\u6539\u5584\u6a21\u578b\u6307\u5c0e\u80fd\u529b\u65b9\u9762\u7684\u6709\u6548\u6027\u3002\u6a21\u578b\u53ef\u4ee5\u5728 hugging face \u53d6\u5f97\uff1a\nhttps://huggingface.co/arcee-ai/Llama-3-SEC-Base, arcee-ai/Llama-3-SEC-Base\u3002\n\u9019\u662f\u6211\u5011\u6700\u7d42\u6a21\u578b\u7684\u5176\u4e2d\u4e00\u500b\u4e2d\u9593\u6aa2\u67e5\u9ede\uff0c\u5230\u76ee\u524d\u70ba\u6b62\u5df2\u7d93\u770b\u5230 20B \u500b\u4ee3\u5e63\u3002\u5b8c\u6574\u6a21\u578b\u4ecd\u5728\u8a13\u7df4\u904e\u7a0b\u4e2d\u3002\u9019\u662f\u4e00\u4efd\u9810\u5370\u672c\u6280\u8853\u5831\u544a\uff0c\u5305\u542b\u6df1\u5165\u7684\u8a55\u4f30\uff0c\u4ee5\u4e86\u89e3\u6574\u500b\u904e\u7a0b\u3002", "author": "Shamane Siriwardhana et.al.", "authors": "Shamane Siriwardhana, Mark McQuade, Thomas Gauthier, Lucas Atkins, Fernando Fernandes Neto, Luke Meyers, Anneketh Vij, Tyler Odenthal, Charles Goddard, Mary MacCarthy, Jacob Solawetz", "id": "2406.14971v1", "paper_url": "http://arxiv.org/abs/2406.14971v1", "repo": "null"}}