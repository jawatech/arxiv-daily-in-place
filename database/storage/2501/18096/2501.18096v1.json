{"2501.18096": {"publish_time": "2025-01-30", "title": "LLMs can see and hear without any training", "paper_summary": "We present MILS: Multimodal Iterative LLM Solver, a surprisingly simple,\ntraining-free approach, to imbue multimodal capabilities into your favorite\nLLM. Leveraging their innate ability to perform multi-step reasoning, MILS\nprompts the LLM to generate candidate outputs, each of which are scored and fed\nback iteratively, eventually generating a solution to the task. This enables\nvarious applications that typically require training specialized models on\ntask-specific data. In particular, we establish a new state-of-the-art on\nemergent zero-shot image, video and audio captioning. MILS seamlessly applies\nto media generation as well, discovering prompt rewrites to improve\ntext-to-image generation, and even edit prompts for style transfer! Finally,\nbeing a gradient-free optimization approach, MILS can invert multimodal\nembeddings into text, enabling applications like cross-modal arithmetic.", "paper_summary_zh": "\u6211\u5011\u63d0\u51fa MILS\uff1a\u591a\u6a21\u614b\u53cd\u8986 LLM \u89e3\u6c7a\u65b9\u6848\uff0c\u4e00\u7a2e\u9a5a\u4eba\u5730\u7c21\u55ae\u3001\u7121\u9700\u8a13\u7df4\u7684\u65b9\u6cd5\uff0c\u5c07\u591a\u6a21\u614b\u529f\u80fd\u878d\u5165\u60a8\u6700\u611b\u7684 LLM\u3002\u904b\u7528\u5176\u57f7\u884c\u591a\u6b65\u9a5f\u63a8\u7406\u7684\u5167\u5728\u80fd\u529b\uff0cMILS \u6703\u63d0\u793a LLM \u7522\u751f\u5019\u9078\u8f38\u51fa\uff0c\u6bcf\u500b\u8f38\u51fa\u90fd\u6703\u88ab\u8a55\u5206\u4e26\u53cd\u8986\u56de\u994b\uff0c\u6700\u7d42\u7522\u751f\u4efb\u52d9\u7684\u89e3\u6c7a\u65b9\u6848\u3002\u9019\u80fd\u555f\u7528\u5404\u7a2e\u61c9\u7528\u7a0b\u5f0f\uff0c\u9019\u4e9b\u61c9\u7528\u7a0b\u5f0f\u901a\u5e38\u9700\u8981\u5728\u7279\u5b9a\u65bc\u4efb\u52d9\u7684\u8cc7\u6599\u4e0a\u8a13\u7df4\u5c08\u9580\u6a21\u578b\u3002\u7279\u5225\u662f\uff0c\u6211\u5011\u5728\u6d6e\u73fe\u96f6\u6b21\u5b78\u7fd2\u5f71\u50cf\u3001\u5f71\u7247\u548c\u97f3\u8a0a\u5b57\u5e55\u4e0a\u5efa\u7acb\u4e86\u65b0\u7684\u5148\u9032\u6280\u8853\u3002MILS \u4e5f\u80fd\u7121\u7e2b\u61c9\u7528\u65bc\u5a92\u9ad4\u7522\u751f\uff0c\u767c\u73fe\u63d0\u793a\u91cd\u5beb\u4ee5\u6539\u5584\u6587\u5b57\u8f49\u5f71\u50cf\u7522\u751f\uff0c\u751a\u81f3\u7de8\u8f2f\u63d0\u793a\u4ee5\u9032\u884c\u98a8\u683c\u8f49\u79fb\uff01\u6700\u5f8c\uff0c\u7531\u65bc\u662f\u4e00\u7a2e\u7121\u68af\u5ea6\u6700\u4f73\u5316\u65b9\u6cd5\uff0cMILS \u80fd\u5c07\u591a\u6a21\u614b\u5d4c\u5165\u53cd\u8f49\u70ba\u6587\u5b57\uff0c\u555f\u7528\u8de8\u6a21\u614b\u904b\u7b97\u7b49\u61c9\u7528\u7a0b\u5f0f\u3002", "author": "Kumar Ashutosh et.al.", "authors": "Kumar Ashutosh, Yossi Gandelsman, Xinlei Chen, Ishan Misra, Rohit Girdhar", "id": "2501.18096v1", "paper_url": "http://arxiv.org/abs/2501.18096v1", "repo": "https://github.com/facebookresearch/mils"}}