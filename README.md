# arxiv-daily
 Automated deployment @ 2025-01-10 20:36:00 Asia/Taipei
> Welcome to contribute! Add your topics and keywords in [`topic.yml`](https://github.com/jawatech/arxiv-daily-in-place/blob/main/database/topic.yml).
> You can also view historical data through the [storage](https://github.com/jawatech/arxiv-daily-in-place/blob/main/database/storage).

## AI

### Medical explainable AI
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2025-01-06**|**Explaining Humour Style Classifications: An XAI Approach to Understanding Computational Humour Analysis**|Mary Ogbuka Kenneth et.al.|[2501.02891v1](http://arxiv.org/abs/2501.02891v1)|null|
|**2024-12-28**|**The Emotional Spectrum of LLMs: Leveraging Empathy and Emotion-Based Markers for Mental Health Support**|Alessandro De Grandi et.al.|[2412.20068v1](http://arxiv.org/abs/2412.20068v1)|null|
|**2024-12-27**|**A Review on the Integration of Artificial Intelligence and Medical Imaging in IVF Ovarian Stimulation**|Jana Zakall et.al.|[2412.19688v1](http://arxiv.org/abs/2412.19688v1)|null|
|**2024-12-23**|**Enhancing Cancer Diagnosis with Explainable & Trustworthy Deep Learning Models**|Badaru I. Olumuyiwa et.al.|[2412.17527v1](http://arxiv.org/abs/2412.17527v1)|null|
|**2024-12-20**|**Towards Interpretable Radiology Report Generation via Concept Bottlenecks using a Multi-Agentic RAG**|Hasan Md Tusfiqur Alam et.al.|[2412.16086v1](http://arxiv.org/abs/2412.16086v1)|[link](https://github.com/tifat58/irr-with-cbm-rag)|
|**2024-12-20**|**Critique of Impure Reason: Unveiling the reasoning behaviour of medical Large Language Models**|Shamus Sim et.al.|[2412.15748v1](http://arxiv.org/abs/2412.15748v1)|null|
|**2024-12-18**|**Cognition Chain for Explainable Psychological Stress Detection on Social Media**|Xin Wang et.al.|[2412.14009v1](http://arxiv.org/abs/2412.14009v1)|null|
|**2024-11-30**|**2-Factor Retrieval for Improved Human-AI Decision Making in Radiology**|Jim Solomon et.al.|[2412.00372v1](http://arxiv.org/abs/2412.00372v1)|null|
|**2024-11-28**|**Mapping Public Perception of Artificial Intelligence: Expectations, Risk-Benefit Tradeoffs, and Value As Determinants for Societal Acceptance**|Philipp Brauner et.al.|[2411.19356v1](http://arxiv.org/abs/2411.19356v1)|null|
|**2024-11-26**|**Explainable AI for Classifying UTI Risk Groups Using a Real-World Linked EHR and Pathology Lab Dataset**|Yujie Dai et.al.|[2411.17645v1](http://arxiv.org/abs/2411.17645v1)|null|
|**2024-11-18**|**Exploring the Requirements of Clinicians for Explainable AI Decision Support Systems in Intensive Care**|Jeffrey N. Clark et.al.|[2411.11774v1](http://arxiv.org/abs/2411.11774v1)|null|
|**2024-11-15**|**Artificial Intelligence in Pediatric Echocardiography: Exploring Challenges, Opportunities, and Clinical Applications with Explainable AI and Federated Learning**|Mohammed Yaseen Jabarulla et.al.|[2411.10255v1](http://arxiv.org/abs/2411.10255v1)|null|
|**2024-11-01**|**Enhancing Osteoporosis Detection: An Explainable Multi-Modal Learning Framework with Feature Fusion and Variable Clustering**|Mehdi Hosseini Chagahi et.al.|[2411.00916v2](http://arxiv.org/abs/2411.00916v2)|null|
|**2024-10-25**|**A Review of Deep Learning Approaches for Non-Invasive Cognitive Impairment Detection**|Muath Alsuhaibani et.al.|[2410.19898v1](http://arxiv.org/abs/2410.19898v1)|null|
|**2024-10-23**|**An Ontology-Enabled Approach For User-Centered and Knowledge-Enabled Explanations of AI Systems**|Shruthi Chari et.al.|[2410.17504v1](http://arxiv.org/abs/2410.17504v1)|[link](https://github.com/tetherless-world/metaexplainer)|
|**2024-10-22**|**Contrasting Attitudes Towards Current and Future AI Applications for Computerised Interpretation of ECG: A Clinical Stakeholder Interview Study**|Lukas Hughes-Noehrer et.al.|[2410.16879v1](http://arxiv.org/abs/2410.16879v1)|null|
|**2024-10-19**|**Pathologist-like explainable AI for interpretable Gleason grading in prostate cancer**|Gesa Mittmann et.al.|[2410.15012v1](http://arxiv.org/abs/2410.15012v1)|null|
|**2024-10-15**|**Explainable AI Methods for Multi-Omics Analysis: A Survey**|Ahmad Hussein et.al.|[2410.11910v1](http://arxiv.org/abs/2410.11910v1)|null|
|**2024-10-14**|**Study on the Helpfulness of Explainable Artificial Intelligence**|Tobias Labarta et.al.|[2410.11896v1](http://arxiv.org/abs/2410.11896v1)|[link](https://github.com/tlabarta/helpfulnessofxai)|
|**2024-10-12**|**Use of What-if Scenarios to Help Explain Artificial Intelligence Models for Neonatal Health**|Abdullah Mamun et.al.|[2410.09635v1](http://arxiv.org/abs/2410.09635v1)|[link](https://github.com/ab9mamun/aimen)|
|**2024-10-10**|**Artificial intelligence techniques in inherited retinal diseases: A review**|Han Trinh et.al.|[2410.09105v1](http://arxiv.org/abs/2410.09105v1)|null|
|**2024-10-07**|**CasiMedicos-Arg: A Medical Question Answering Dataset Annotated with Explanatory Argumentative Structures**|Ekaterina Sviridova et.al.|[2410.05235v2](http://arxiv.org/abs/2410.05235v2)|[link](https://github.com/ixa-ehu/antidote-casimedicos)|
|**2024-10-01**|**Explainable Diagnosis Prediction through Neuro-Symbolic Integration**|Qiuhao Lu et.al.|[2410.01855v2](http://arxiv.org/abs/2410.01855v2)|null|
|**2024-10-01**|**Easydiagnos: a framework for accurate feature selection for automatic diagnosis in smart healthcare**|Prasenjit Maji et.al.|[2410.00366v1](http://arxiv.org/abs/2410.00366v1)|null|
|**2024-09-20**|**Dermatologist-like explainable AI enhances melanoma diagnosis accuracy: eye-tracking study**|Tirtha Chanda et.al.|[2409.13476v1](http://arxiv.org/abs/2409.13476v1)|null|
|**2024-09-19**|**Explainable AI for Autism Diagnosis: Identifying Critical Brain Regions Using fMRI Data**|Suryansh Vidya et.al.|[2409.15374v1](http://arxiv.org/abs/2409.15374v1)|null|
|**2024-09-19**|**Improving Prototypical Parts Abstraction for Case-Based Reasoning Explanations Designed for the Kidney Stone Type Recognition**|Daniel Flores-Araiza et.al.|[2409.12883v1](http://arxiv.org/abs/2409.12883v1)|null|
|**2024-09-18**|**Towards Interpretable End-Stage Renal Disease (ESRD) Prediction: Utilizing Administrative Claims Data with Explainable AI Techniques**|Yubo Li et.al.|[2409.12087v3](http://arxiv.org/abs/2409.12087v3)|null|
|**2024-09-09**|**Explainable AI: Definition and attributes of a good explanation for health AI**|Evangelia Kyrimi et.al.|[2409.15338v1](http://arxiv.org/abs/2409.15338v1)|null|
|**2024-08-30**|**Exploring the Effect of Explanation Content and Format on User Comprehension and Trust**|Antonio Rago et.al.|[2408.17401v1](http://arxiv.org/abs/2408.17401v1)|null|
|**2024-08-29**|**A Survey for Large Language Models in Biomedicine**|Chong Wang et.al.|[2409.00133v1](http://arxiv.org/abs/2409.00133v1)|null|
|**2024-08-27**|**Aligning XAI with EU Regulations for Smart Biomedical Devices: A Methodology for Compliance Analysis**|Francesco Sovrano et.al.|[2408.15121v1](http://arxiv.org/abs/2408.15121v1)|null|
|**2024-08-24**|**Towards Case-based Interpretability for Medical Federated Learning**|Laura Latorre et.al.|[2408.13626v1](http://arxiv.org/abs/2408.13626v1)|null|
|**2024-08-22**|**AI in radiological imaging of soft-tissue and bone tumours: a systematic review evaluating against CLAIM and FUTURE-AI guidelines**|Douwe J. Spaanderman et.al.|[2408.12491v1](http://arxiv.org/abs/2408.12491v1)|null|
|**2024-08-14**|**Evaluating Explainable AI Methods in Deep Learning Models for Early Detection of Cerebral Palsy**|Kimji N. Pellano et.al.|[2409.00001v1](http://arxiv.org/abs/2409.00001v1)|null|
|**2024-08-06**|**MicroXercise: A Micro-Level Comparative and Explainable System for Remote Physical Therapy**|Hanchen David Wang et.al.|[2408.11837v1](http://arxiv.org/abs/2408.11837v1)|null|
|**2024-08-05**|**The Literature Review Network: An Explainable Artificial Intelligence for Systematic Literature Reviews, Meta-analyses, and Method Development**|Joshua Morriss et.al.|[2408.05239v1](http://arxiv.org/abs/2408.05239v1)|null|
|**2024-08-05**|**Enhancing Medical Learning and Reasoning Systems: A Boxology-Based Comparative Analysis of Design Patterns**|Chi Him Ng et.al.|[2408.02709v1](http://arxiv.org/abs/2408.02709v1)|null|
|**2024-08-05**|**Bayesian Kolmogorov Arnold Networks (Bayesian_KANs): A Probabilistic Approach to Enhance Accuracy and Interpretability**|Masoud Muhammed Hassan et.al.|[2408.02706v1](http://arxiv.org/abs/2408.02706v1)|null|
|**2024-07-26**|**MLtoGAI: Semantic Web based with Machine Learning for Enhanced Disease Prediction and Personalized Recommendations using Generative AI**|Shyam Dongre et.al.|[2407.20284v1](http://arxiv.org/abs/2407.20284v1)|null|
|**2024-07-25**|**Introducing Î´-XAI: a novel sensitivity-based method for local AI explanations**|Alessandro De Carlo et.al.|[2407.18343v2](http://arxiv.org/abs/2407.18343v2)|null|
|**2024-07-24**|**Enhanced Deep Learning Methodologies and MRI Selection Techniques for Dementia Diagnosis in the Elderly Population**|Nikolaos Ntampakis et.al.|[2407.17324v2](http://arxiv.org/abs/2407.17324v2)|null|
|**2024-07-24**|**Using Large Language Models to Compare Explainable Models for Smart Home Human Activity Recognition**|Michele Fiori et.al.|[2408.06352v1](http://arxiv.org/abs/2408.06352v1)|null|
|**2024-07-21**|**Explainable AI-based Intrusion Detection System for Industry 5.0: An Overview of the Literature, associated Challenges, the existing Solutions, and Potential Research Directions**|Naseem Khan et.al.|[2408.03335v1](http://arxiv.org/abs/2408.03335v1)|null|
|**2024-07-18**|**A Comparative Study on Automatic Coding of Medical Letters with Explainability**|Jamie Glen et.al.|[2407.13638v1](http://arxiv.org/abs/2407.13638v1)|[link](https://github.com/Glenj01/Medical-Coding)|
|**2024-07-09**|**Explainable AI for Enhancing Efficiency of DL-based Channel Estimation**|Abdul Karim Gizzini et.al.|[2407.07009v1](http://arxiv.org/abs/2407.07009v1)|null|
|**2024-07-07**|**Explainable AI: Comparative Analysis of Normal and Dilated ResNet Models for Fundus Disease Classification**|P. N. Karthikayan et.al.|[2407.05440v2](http://arxiv.org/abs/2407.05440v2)|null|
|**2024-07-03**|**A Survey on Trustworthiness in Foundation Models for Medical Image Analysis**|Congzhen Shi et.al.|[2407.15851v2](http://arxiv.org/abs/2407.15851v2)|null|
|**2024-07-01**|**The Impact of an XAI-Augmented Approach on Binary Classification with Scarce Data**|Ximing Wen et.al.|[2407.06206v1](http://arxiv.org/abs/2407.06206v1)|null|
|**2024-06-28**|**Can GPT-4 Help Detect Quit Vaping Intentions? An Exploration of Automatic Data Annotation Approach**|Sai Krishna Revanth Vuruma et.al.|[2407.00167v1](http://arxiv.org/abs/2407.00167v1)|null|
|**2024-06-25**|**Towards Compositional Interpretability for XAI**|Sean Tull et.al.|[2406.17583v1](http://arxiv.org/abs/2406.17583v1)|null|
|**2024-06-17**|**Slicing Through Bias: Explaining Performance Gaps in Medical Image Analysis using Slice Discovery Methods**|Vincent Olesen et.al.|[2406.12142v2](http://arxiv.org/abs/2406.12142v2)|[link](https://github.com/volesen/slicing-through-bias)|
|**2024-06-11**|**Unlocking the Potential of Metaverse in Innovative and Immersive Digital Health**|Fatemeh Ebrahimzadeh et.al.|[2406.07114v2](http://arxiv.org/abs/2406.07114v2)|null|
|**2024-06-10**|**AI-Driven Predictive Analytics Approach for Early Prognosis of Chronic Kidney Disease Using Ensemble Learning and Explainable AI**|K M Tawsik Jawad et.al.|[2406.06728v1](http://arxiv.org/abs/2406.06728v1)|null|
|**2024-06-10**|**Explainable AI for Mental Disorder Detection via Social Media: A survey and outlook**|Yusif Ibrahimov et.al.|[2406.05984v1](http://arxiv.org/abs/2406.05984v1)|null|
|**2024-06-09**|**Methodology and Real-World Applications of Dynamic Uncertain Causality Graph for Clinical Diagnosis with Explainability and Invariance**|Zhan Zhang et.al.|[2406.05746v1](http://arxiv.org/abs/2406.05746v1)|null|
|**2024-06-07**|**Advancing Histopathology-Based Breast Cancer Diagnosis: Insights into Multi-Modality and Explainability**|Faseela Abdullakutty et.al.|[2406.12897v1](http://arxiv.org/abs/2406.12897v1)|null|
|**2024-06-04**|**Using Explainable AI for EEG-based Reduced Montage Neonatal Seizure Detection**|Dinuka Sandun Udayantha et.al.|[2406.16908v3](http://arxiv.org/abs/2406.16908v3)|[link](https://github.com/dinuka-1999/braineocare)|
|**2024-06-01**|**Breast Cancer Diagnosis: A Comprehensive Exploration of Explainable Artificial Intelligence (XAI) Techniques**|Samita Bai et.al.|[2406.00532v1](http://arxiv.org/abs/2406.00532v1)|null|
|**2024-06-01**|**Unveiling Hidden Factors: Explainable AI for Feature Boosting in Speech Emotion Recognition**|Alaa Nfissi et.al.|[2406.01624v2](http://arxiv.org/abs/2406.01624v2)|[link](https://github.com/alaanfissi/unveiling-hidden-factors-explainable-ai-for-feature-boosting-in-speech-emotion-recognition)|
|**2024-05-31**|**The Explanation Necessity for Healthcare AI**|Michail Mamalakis et.al.|[2406.00216v1](http://arxiv.org/abs/2406.00216v1)|null|
|**2024-05-29**|**Interdisciplinary Expertise to Advance Equitable Explainable AI**|Chloe R. Bennett et.al.|[2406.18563v1](http://arxiv.org/abs/2406.18563v1)|null|
|**2024-05-27**|**"It depends": Configuring AI to Improve Clinical Usefulness Across Contexts**|Hubert D. ZajÄc et.al.|[2407.11978v1](http://arxiv.org/abs/2407.11978v1)|null|
|**2024-05-26**|**Improving Health Professionals' Onboarding with AI and XAI for Trustworthy Human-AI Collaborative Decision Making**|Min Hun Lee et.al.|[2405.16424v1](http://arxiv.org/abs/2405.16424v1)|null|
|**2024-05-26**|**Exploring Nutritional Impact on Alzheimer's Mortality: An Explainable AI Approach**|Ziming Liu et.al.|[2405.17502v1](http://arxiv.org/abs/2405.17502v1)|null|
|**2024-05-24**|**Explainable AI Enhances Glaucoma Referrals, Yet the Human-AI Team Still Falls Short of the AI Alone**|Catalina Gomez et.al.|[2407.11974v1](http://arxiv.org/abs/2407.11974v1)|null|
|**2024-05-23**|**Decoding Decision Reasoning: A Counterfactual-Powered Model for Knowledge Discovery**|Yingying Fang et.al.|[2406.18552v1](http://arxiv.org/abs/2406.18552v1)|null|
|**2024-05-21**|**The Role of Emotions in Informational Support Question-Response Pairs in Online Health Communities: A Multimodal Deep Learning Approach**|Mohsen Jozani et.al.|[2405.13099v1](http://arxiv.org/abs/2405.13099v1)|null|
|**2024-05-17**|**ChatGPT in Classrooms: Transforming Challenges into Opportunities in Education**|Harris Bin Munawar et.al.|[2405.10645v1](http://arxiv.org/abs/2405.10645v1)|null|
|**2024-05-13**|**Evaluating the Explainable AI Method Grad-CAM for Breath Classification on Newborn Time Series Data**|Camelia Oprea et.al.|[2405.07590v1](http://arxiv.org/abs/2405.07590v1)|null|
|**2024-05-10**|**XAI4LLM. Let Machine Learning Models and LLMs Collaborate for Enhanced In-Context Learning in Healthcare**|Fatemeh Nazary et.al.|[2405.06270v3](http://arxiv.org/abs/2405.06270v3)|null|
|**2024-05-09**|**To Trust or Not to Trust: Towards a novel approach to measure trust for XAI systems**|Miquel MirÃ³-Nicolau et.al.|[2405.05766v1](http://arxiv.org/abs/2405.05766v1)|null|
|**2024-05-05**|**Region-specific Risk Quantification for Interpretable Prognosis of COVID-19**|Zhusi Zhong et.al.|[2405.02815v1](http://arxiv.org/abs/2405.02815v1)|[link](https://github.com/zzs95/RSP_COVID)|
|**2024-04-26**|**Rad4XCNN: a new agnostic method for post-hoc global explanation of CNN-derived features by means of radiomics**|Francesco Prinzi et.al.|[2405.02334v2](http://arxiv.org/abs/2405.02334v2)|null|
|**2024-04-25**|**Attributing Responsibility in AI-Induced Incidents: A Computational Reflective Equilibrium Framework for Accountability**|Yunfei Ge et.al.|[2404.16957v1](http://arxiv.org/abs/2404.16957v1)|null|
|**2024-04-19**|**Explainable AI for Fair Sepsis Mortality Predictive Model**|Chia-Hsuan Chang et.al.|[2404.13139v1](http://arxiv.org/abs/2404.13139v1)|null|
|**2024-04-19**|**Multi Class Depression Detection Through Tweets using Artificial Intelligence**|Muhammad Osama Nusrat et.al.|[2404.13104v1](http://arxiv.org/abs/2404.13104v1)|[link](https://github.com/mnusrat786/masters-thesis)|
|**2024-04-19**|**COIN: Counterfactual inpainting for weakly supervised semantic segmentation for medical images**|Dmytro Shvetsov et.al.|[2404.12832v2](http://arxiv.org/abs/2404.12832v2)|[link](https://github.com/dmytro-shvetsov/counterfactual-search)|
|**2024-04-15**|**Hybrid Intelligence for Digital Humanities**|Victor de Boer et.al.|[2406.15374v1](http://arxiv.org/abs/2406.15374v1)|null|
|**2024-04-14**|**Ethical Framework for Responsible Foundational Models in Medical Imaging**|Abhijit Das et.al.|[2406.11868v1](http://arxiv.org/abs/2406.11868v1)|null|
|**2024-04-09**|**Advancements in Radiomics and Artificial Intelligence for Thyroid Cancer Diagnosis**|Milad Yousefi et.al.|[2404.07239v1](http://arxiv.org/abs/2404.07239v1)|null|
|**2024-04-06**|**Predictive Modeling for Breast Cancer Classification in the Context of Bangladeshi Patients: A Supervised Machine Learning Approach with Explainable AI**|Taminul Islam et.al.|[2404.04686v1](http://arxiv.org/abs/2404.04686v1)|null|
|**2024-04-05**|**Enhancing Breast Cancer Diagnosis in Mammography: Evaluation and Integration of Convolutional Neural Networks and Explainable AI**|Maryam Ahmed et.al.|[2404.03892v3](http://arxiv.org/abs/2404.03892v3)|null|
|**2024-03-30**|**Advancing Multimodal Data Fusion in Pain Recognition: A Strategy Leveraging Statistical Correlation and Human-Centered Perspectives**|Xingrui Gu et.al.|[2404.00320v2](http://arxiv.org/abs/2404.00320v2)|null|
|**2024-03-26**|**Addressing Social Misattributions of Large Language Models: An HCXAI-based Approach**|Andrea Ferrario et.al.|[2403.17873v1](http://arxiv.org/abs/2403.17873v1)|null|
|**2024-03-26**|**Clinical Domain Knowledge-Derived Template Improves Post Hoc AI Explanations in Pneumothorax Classification**|Han Yuan et.al.|[2403.18871v1](http://arxiv.org/abs/2403.18871v1)|[link](https://github.com/han-yuan-med/template-explanation)|
|**2024-03-03**|**Enhancing Neural Machine Translation of Low-Resource Languages: Corpus Development, Human Evaluation and Explainable AI Architectures**|SÃ©amus Lankford et.al.|[2403.01580v1](http://arxiv.org/abs/2403.01580v1)|null|
|**2024-02-28**|**Cause and Effect: Can Large Language Models Truly Understand Causality?**|Swagata Ashwani et.al.|[2402.18139v3](http://arxiv.org/abs/2402.18139v3)|null|
|**2024-02-28**|**Artificial Intelligence and Diabetes Mellitus: An Inside Look Through the Retina**|Yasin Sadeghi Bazargani et.al.|[2402.18600v1](http://arxiv.org/abs/2402.18600v1)|null|
|**2024-02-22**|**Multi-stakeholder Perspective on Responsible Artificial Intelligence and Acceptability in Education**|A. J. Karran et.al.|[2402.15027v2](http://arxiv.org/abs/2402.15027v2)|null|
|**2024-02-12**|**Deciphering Heartbeat Signatures: A Vision Transformer Approach to Explainable Atrial Fibrillation Detection from ECG Signals**|Aruna Mohan et.al.|[2402.09474v2](http://arxiv.org/abs/2402.09474v2)|null|
|**2024-02-05**|**Illuminate: A novel approach for depression detection with explainable analysis and proactive therapy using prompt engineering**|Aryan Agrawal et.al.|[2402.05127v1](http://arxiv.org/abs/2402.05127v1)|null|
|**2024-01-24**|**Information That Matters: Exploring Information Needs of People Affected by Algorithmic Decisions**|TimothÃ©e Schmude et.al.|[2401.13324v6](http://arxiv.org/abs/2401.13324v6)|null|
|**2024-01-02**|**Evaluating Large Language Models on the GMAT: Implications for the Future of Business Education**|Vahid Ashrafimoghari et.al.|[2401.02985v1](http://arxiv.org/abs/2401.02985v1)|null|
|**2023-12-29**|**XAI for In-hospital Mortality Prediction via Multimodal ICU Data**|Xingqiao Li et.al.|[2312.17624v1](http://arxiv.org/abs/2312.17624v1)|[link](https://github.com/lixingqiao/xai-icu)|
|**2023-12-22**|**Joining Forces for Pathology Diagnostics with AI Assistance: The EMPAIA Initiative**|Norman Zerbe et.al.|[2401.09450v2](http://arxiv.org/abs/2401.09450v2)|null|
|**2023-12-18**|**Robust Stochastic Graph Generator for Counterfactual Explanations**|Mario Alfonso Prado-Romero et.al.|[2312.11747v2](http://arxiv.org/abs/2312.11747v2)|null|
|**2023-12-10**|**Evaluating the Utility of Model Explanations for Model Development**|Shawn Im et.al.|[2312.06032v1](http://arxiv.org/abs/2312.06032v1)|null|
|**2023-12-05**|**Building Trustworthy NeuroSymbolic AI Systems: Consistency, Reliability, Explainability, and Safety**|Manas Gaur et.al.|[2312.06798v1](http://arxiv.org/abs/2312.06798v1)|null|
|**2023-12-04**|**Class-Discriminative Attention Maps for Vision Transformers**|Lennart Brocki et.al.|[2312.02364v3](http://arxiv.org/abs/2312.02364v3)|null|

#### Abstracts
##### **Explaining Humour Style Classifications: An XAI Approach to Understanding Computational Humour Analysis**
2501.02891v1 by Mary Ogbuka Kenneth, Foaad Khosmood, Abbas Edalat

Humour styles can have either a negative or a positive impact on well-being.
Given the importance of these styles to mental health, significant research has
been conducted on their automatic identification. However, the automated
machine learning models used for this purpose are black boxes, making their
prediction decisions opaque. Clarity and transparency are vital in the field of
mental health. This paper presents an explainable AI (XAI) framework for
understanding humour style classification, building upon previous work in
computational humour analysis. Using the best-performing single model
(ALI+XGBoost) from prior research, we apply comprehensive XAI techniques to
analyse how linguistic, emotional, and semantic features contribute to humour
style classification decisions. Our analysis reveals distinct patterns in how
different humour styles are characterised and misclassified, with particular
emphasis on the challenges in distinguishing affiliative humour from other
styles. Through detailed examination of feature importance, error patterns, and
misclassification cases, we identify key factors influencing model decisions,
including emotional ambiguity, context misinterpretation, and target
identification. The framework demonstrates significant utility in understanding
model behaviour, achieving interpretable insights into the complex interplay of
features that define different humour styles. Our findings contribute to both
the theoretical understanding of computational humour analysis and practical
applications in mental health, content moderation, and digital humanities
research.

æè¦ï¼å¹½é»é¢¨æ ¼å°å¹¸ç¦æå¯è½ç¢çè² é¢ææ­£é¢çå½±é¿ã
éæ¼éäºé¢¨æ ¼å°å¿çå¥åº·çéè¦æ§ï¼å·²ç¶å°å¶èªåè­å¥é²è¡äºå¤§éç ç©¶ãç¶èï¼ç¨æ¼æ­¤ç®ççèªåæ©å¨å­¸ç¿æ¨¡åæ¯é»çå­ï¼ä½¿å¾å¶é æ¸¬æ±ºç­ä¸éæãæ¸æ°åº¦åéæåº¦å¨å¿çå¥åº·é åè³ééè¦ãæ¬ææåºäºä¸åå¯è§£éç AI (XAI) æ¡æ¶ï¼ç¨æ¼çè§£å¹½é»é¢¨æ ¼åé¡ï¼å»ºç«å¨è¨ç®å¹½é»åæçååå·¥ä½ä¹ä¸ãä½¿ç¨ååç ç©¶ä¸­è¡¨ç¾æå¥½çå®ä¸æ¨¡å (ALI+XGBoost)ï¼æåæç¨å¨é¢ç XAI æè¡ä¾åæèªè¨ãæç·åèªç¾©ç¹å¾µå¦ä½å½±é¿å¹½é»é¢¨æ ¼åé¡æ±ºç­ãæåçåææ­ç¤ºäºä¸åå¹½é»é¢¨æ ¼å¦ä½è¢«è¡¨å¾µåé¯èª¤åé¡çä¸åæ¨¡å¼ï¼ç¹å¥å¼·èª¿äºååè¯å±¬å¹½é»èå¶ä»é¢¨æ ¼çææ°ãééä»ç´°æª¢æ¥ç¹å¾µéè¦æ§ãé¯èª¤æ¨¡å¼åé¯èª¤åé¡æ¡ä¾ï¼æåç¢ºå®äºå½±é¿æ¨¡åæ±ºç­çééµå ç´ ï¼åæ¬æç·æ¨¡ç³ãæå¢èª¤è§£åç®æ¨è­å¥ãè©²æ¡æ¶å±ç¤ºäºå¨çè§£æ¨¡åè¡çºæ¹é¢çé¡¯èæç¨ï¼å¯¦ç¾äºå°å®ç¾©ä¸åå¹½é»é¢¨æ ¼çç¹å¾µä¹éè¤éç¸äºä½ç¨çå¯è§£éè¦è§£ãæåçç¼ç¾æå©æ¼è¨ç®å¹½é»åæççè«çè§£åå¿çå¥åº·ãå§å®¹å¯©æ ¸åæ¸å­äººæç ç©¶ä¸­çå¯¦éæç¨ã

##### **The Emotional Spectrum of LLMs: Leveraging Empathy and Emotion-Based Markers for Mental Health Support**
2412.20068v1 by Alessandro De Grandi, Federico Ravenda, Andrea Raballo, Fabio Crestani

The increasing demand for mental health services has highlighted the need for
innovative solutions, particularly in the realm of psychological conversational
AI, where the availability of sensitive data is scarce. In this work, we
explored the development of a system tailored for mental health support with a
novel approach to psychological assessment based on explainable emotional
profiles in combination with empathetic conversational models, offering a
promising tool for augmenting traditional care, particularly where immediate
expertise is unavailable. Our work can be divided into two main parts,
intrinsecaly connected to each other. First, we present RACLETTE, a
conversational system that demonstrates superior emotional accuracy compared to
state-of-the-art benchmarks in both understanding users' emotional states and
generating empathetic responses during conversations, while progressively
building an emotional profile of the user through their interactions. Second,
we show how the emotional profiles of a user can be used as interpretable
markers for mental health assessment. These profiles can be compared with
characteristic emotional patterns associated with different mental disorders,
providing a novel approach to preliminary screening and support.

æè¦ï¼é¨èå°å¿çå¥åº·æåéæ±çå¢å ï¼å¸é¡¯äºåµæ°è§£æ±ºæ¹æ¡çéæ±ï¼ç¹å¥æ¯å¨å¿çå°è©±å¼äººå·¥æºæ§é åï¼é£è£¡ç¼ºä¹ææè³æãå¨éé å·¥ä½ä¸­ï¼æåæ¢ç´¢äºéç¼ä¸åéå°å¿çå¥åº·æ¯æçç³»çµ±ï¼æ¡ç¨ä¸ç¨®åºæ¼å¯è§£éçæç·ç¹å¾µçæ°æ¹æ³é²è¡å¿çè©ä¼°ï¼çµååçå¿å°è©±æ¨¡å¼ï¼æä¾äºä¸åæåéçå·¥å·ï¼ç¨æ¼æ´åå³çµ±ç§è­·ï¼ç¹å¥æ¯å¨ç¡æ³ç«å³ç²å¾å°æ¥­ç¥è­çææ³ä¸ãæåçå·¥ä½å¯ä»¥åçºå©åä¸»è¦é¨åï¼å½¼æ­¤å§å¨ç¸éãé¦åï¼æåå±ç¤ºäº RACLETTEï¼ä¸åå°è©±ç³»çµ±ï¼èæåé²çåºæºç¸æ¯ï¼å¨çè§£ä½¿ç¨èæç·çæåå¨å°è©±ä¸­ç¢çåçå¿åææ¹é¢è¡¨ç¾åºåªè¶çæç·æºç¢ºæ§ï¼åæééä»åçäºåéæ¼¸å»ºç«ä½¿ç¨èçæç·ç¹å¾µãå¶æ¬¡ï¼æåå±ç¤ºäºä½¿ç¨èçæç·ç¹å¾µå¦ä½å¯ç¨ä½å¿çå¥åº·è©ä¼°çå¯è§£éæ¨è¨ãéäºç¹å¾µå¯ä»¥èèä¸åå¿çç¾çç¸éçå¸åæç·æ¨¡å¼é²è¡æ¯è¼ï¼æä¾äºä¸ç¨®åæ­¥ç¯©é¸åæ¯æçæ°æ¹æ³ã

##### **A Review on the Integration of Artificial Intelligence and Medical Imaging in IVF Ovarian Stimulation**
2412.19688v1 by Jana Zakall, Birgit Pohn, Antonia Graf, Daniel Kovatchki, Arezoo Borji, Ragib Shahriar Islam, Hossam Haick, Heinz Strohmer, Sepideh Hatamikia

Artificial intelligence (AI) has emerged as a powerful tool to enhance
decision-making and optimize treatment protocols in in vitro fertilization
(IVF). In particular, AI shows significant promise in supporting
decision-making during the ovarian stimulation phase of the IVF process. This
review evaluates studies focused on the applications of AI combined with
medical imaging in ovarian stimulation, examining methodologies, outcomes, and
current limitations. Our analysis of 13 studies on this topic reveals that,
reveal that while AI algorithms demonstrated notable potential in predicting
optimal hormonal dosages, trigger timing, and oocyte retrieval outcomes, the
medical imaging data utilized predominantly came from two-dimensional (2D)
ultrasound which mainly involved basic quantifications, such as follicle size
and number, with limited use of direct feature extraction or advanced image
analysis techniques. This points to an underexplored opportunity where advanced
image analysis approaches, such as deep learning, and more diverse imaging
modalities, like three-dimensional (3D) ultrasound, could unlock deeper
insights. Additionally, the lack of explainable AI (XAI) in most studies raises
concerns about the transparency and traceability of AI-driven decisions - key
factors for clinical adoption and trust. Furthermore, many studies relied on
single-center designs and small datasets, which limit the generalizability of
their findings. This review highlights the need for integrating advanced
imaging analysis techniques with explainable AI methodologies, as well as the
importance of leveraging multicenter collaborations and larger datasets.
Addressing these gaps has the potential to enhance ovarian stimulation
management, paving the way for efficient, personalized, and data-driven
treatment pathways that improve IVF outcomes.

æè¦ï¼äººå·¥æºæ§ï¼AIï¼å·²æçºå¢å¼·é«å¤åç²¾ï¼IVFï¼æ±ºç­å¶å®ååªåæ²»çæ¹æ¡çå¼·å¤§å·¥å·ãç¹å¥æ¯ï¼AI å¨æ¯æ IVF éç¨ä¸­åµå·¢åºæ¿éæ®µçæ±ºç­å¶å®æ¹é¢é¡¯ç¤ºåºé¡¯èçåæ¯ãæ¬ç¶è¿°è©ä¼°äºå°æ³¨æ¼ AI çµååµå·¢åºæ¿ä¸­çé«å­¸å½±åæç¨ãæª¢é©æ¹æ³ãçµæåç¶åéå¶çç ç©¶ãæåå° 13 é éæ¼æ­¤ä¸»é¡çç ç©¶åæé¡¯ç¤ºï¼éç¶ AI æ¼ç®æ³å¨é æ¸¬æä½³è·ç¾èåéãè§¸ç¼ææ©ååµå­ååºçµææ¹é¢è¡¨ç¾åºé¡¯èçæ½åï¼ä½æå©ç¨çé«å­¸å½±åæ¸æä¸»è¦ä¾èªæ¼äºæ¬¡åï¼2Dï¼è¶é³æ³¢ï¼èäºæ¬¡åè¶é³æ³¢ä¸»è¦æ¶ååºæ¬éåï¼ä¾å¦æ¿¾æ³¡å¤§å°åæ¸éï¼ä¸æéä½¿ç¨ç´æ¥ç¹å¾µæåæé²éå½±ååææè¡ãéæåä¸åå°æªæ¢ç´¢çæ©æï¼ä¾å¦æ·±åº¦å­¸ç¿ç­é²éå½±ååææ¹æ³ï¼ä»¥åæ´å¤åçå½±åæ¨¡å¼ï¼ä¾å¦ä¸ç¶­ï¼3Dï¼è¶é³æ³¢ï¼å¯ä»¥è§£éæ´æ·±å¥çè¦è§£ãæ­¤å¤ï¼å¤§å¤æ¸ç ç©¶ç¼ºä¹å¯è§£é AIï¼XAIï¼ï¼éå¼èµ·äºäººåå° AI é©åæ±ºç­çéæåº¦åå¯è¿½æº¯æ§çææï¼èéæåº¦åå¯è¿½æº¯æ§æ¯è¨åºæ¡ç¨åä¿¡ä»»çééµå ç´ ãæ­¤å¤ï¼è¨±å¤ç ç©¶ä¾è³´æ¼å®ä¸­å¿è¨­è¨åå°åæ¸æéï¼ééå¶äºå¶ç¼ç¾çæ®éæ§ãæ¬ç¶è¿°å¼·èª¿äºå°é²éå½±ååææè¡èå¯è§£é AI æ¹æ³æ´åèµ·ä¾çå¿è¦æ§ï¼ä»¥åå©ç¨å¤ä¸­å¿åä½åå¤§åæ¸æéçéè¦æ§ãè§£æ±ºéäºå·®è·æå¯è½å¢å¼·åµå·¢åºæ¿ç®¡çï¼çºææãåäººååæ¸æé©åçæ²»çéå¾éªå¹³éè·¯ï¼é²èæ¹å IVF çµæã

##### **Enhancing Cancer Diagnosis with Explainable & Trustworthy Deep Learning Models**
2412.17527v1 by Badaru I. Olumuyiwa, The Anh Han, Zia U. Shamszaman

This research presents an innovative approach to cancer diagnosis and
prediction using explainable Artificial Intelligence (XAI) and deep learning
techniques. With cancer causing nearly 10 million deaths globally in 2020,
early and accurate diagnosis is crucial. Traditional methods often face
challenges in cost, accuracy, and efficiency. Our study develops an AI model
that provides precise outcomes and clear insights into its decision-making
process, addressing the "black box" problem of deep learning models. By
employing XAI techniques, we enhance interpretability and transparency,
building trust among healthcare professionals and patients. Our approach
leverages neural networks to analyse extensive datasets, identifying patterns
for cancer detection. This model has the potential to revolutionise diagnosis
by improving accuracy, accessibility, and clarity in medical decision-making,
possibly leading to earlier detection and more personalised treatment
strategies. Furthermore, it could democratise access to high-quality
diagnostics, particularly in resource-limited settings, contributing to global
health equity. The model's applications extend beyond cancer diagnosis,
potentially transforming various aspects of medical decision-making and saving
millions of lives worldwide.

æè¦ï¼æ¬ç ç©¶æåºäºä¸ååµæ°çççè¨ºæ·åé æ¸¬æ¹æ³ï¼ä½¿ç¨å¯è§£éçäººå·¥æºæ§ (XAI) åæ·±åº¦å­¸ç¿æè¡ãç±æ¼ççå¨ 2020 å¹´é æå¨çè¿ 1,000 è¬äººæ­»äº¡ï¼å æ­¤æ©ææºç¢ºçè¨ºæ·è³ééè¦ãå³çµ±æ¹æ³éå¸¸é¢è¨ææ¬ãæºç¢ºæ§åæçæ¹é¢çææ°ãæåçç ç©¶éç¼äºä¸å AI æ¨¡åï¼å®æä¾ç²¾ç¢ºççµæä¸¦æ¸æ¥å°äºè§£å¶æ±ºç­éç¨ï¼è§£æ±ºäºæ·±åº¦å­¸ç¿æ¨¡åçãé»ç®±ãåé¡ãééæ¡ç¨ XAI æè¡ï¼æåå¢å¼·äºè§£éæ§åéæåº¦ï¼å¨é«çå°æ¥­äººå¡åæ£èä¹éå»ºç«ä¿¡ä»»ãæåçåæ³å©ç¨ç¥ç¶ç¶²è·¯åæå»£æ³çæ¸æéï¼è­å¥ççæª¢æ¸¬æ¨¡å¼ãéåæ¨¡åæå¯è½ééæé«é«çæ±ºç­çæºç¢ºæ§ãå¯åæ§åæ¸æ°åº¦ä¾é©æ°è¨ºæ·ï¼å¯è½å°è´æ´æ©çæª¢æ¸¬åæ´åæ§åçæ²»çç­ç¥ãæ­¤å¤ï¼å®å¯ä»¥ä½¿æ´å¤äººç²å¾é«åè³ªçè¨ºæ·ï¼ç¹å¥æ¯å¨è³æºæéçç°å¢ä¸­ï¼æå©æ¼å¨çå¥åº·å¬å¹³ãè©²æ¨¡åçæç¨ç¯åä¸åéæ¼ççè¨ºæ·ï¼éå¯è½è½è®é«çæ±ºç­çååæ¹é¢ï¼ä¸¦æ¯æå¨çæ¸ç¾è¬äººççå½ã

##### **Towards Interpretable Radiology Report Generation via Concept Bottlenecks using a Multi-Agentic RAG**
2412.16086v1 by Hasan Md Tusfiqur Alam, Devansh Srivastav, Md Abdul Kadir, Daniel Sonntag

Deep learning has advanced medical image classification, but interpretability
challenges hinder its clinical adoption. This study enhances interpretability
in Chest X-ray (CXR) classification by using concept bottleneck models (CBMs)
and a multi-agent Retrieval-Augmented Generation (RAG) system for report
generation. By modeling relationships between visual features and clinical
concepts, we create interpretable concept vectors that guide a multi-agent RAG
system to generate radiology reports, enhancing clinical relevance,
explainability, and transparency. Evaluation of the generated reports using an
LLM-as-a-judge confirmed the interpretability and clinical utility of our
model's outputs. On the COVID-QU dataset, our model achieved 81% classification
accuracy and demonstrated robust report generation performance, with five key
metrics ranging between 84% and 90%. This interpretable multi-agent framework
bridges the gap between high-performance AI and the explainability required for
reliable AI-driven CXR analysis in clinical settings.

æè¦ï¼æ·±åº¦å­¸ç¿å·²é²æ­¥äºé«å­¸å½±ååé¡ï¼ä½å¯è§£éæ§ææ°é»ç¤äºå¶è¨åºæ¡ç¨ãæ¬ç ç©¶ééä½¿ç¨æ¦å¿µç¶é ¸æ¨¡å (CBM) åå¤éä»£çæª¢ç´¢å¢å¼·çæ (RAG) ç³»çµ±é²è¡å ±åçæï¼å¢å¼·äºè¸é¨ X å (CXR) åé¡çå¯è§£éæ§ãééå°è¦è¦ºç¹å¾µåè¨åºæ¦å¿µä¹éçéä¿é²è¡å»ºæ¨¡ï¼æåå»ºç«äºå¯è§£éçæ¦å¿µåéï¼ç¨ä¾å¼å°å¤éä»£ç RAG ç³»çµ±çææ¾å°ç§å ±åï¼ä»¥å¢å¼·è¨åºç¸éæ§ãå¯è§£éæ§åéææ§ãä½¿ç¨ LLM ä½çºå¤æ·èå°çæçå ±åé²è¡è©ä¼°ï¼ç¢ºèªäºæåæ¨¡åè¼¸åºçå¯è§£éæ§åè¨åºå¯¦ç¨æ§ãå¨ COVID-QU è³æéä¸ï¼æåçæ¨¡åéå°äº 81% çåé¡æºç¢ºåº¦ï¼ä¸¦å±ç¤ºäºå¼·å¥çå ±åçææè½ï¼äºé ééµææ¨ä»æ¼ 84% å° 90% ä¹éãéåå¯è§£éçå¤éä»£çæ¶æ§å½åäºé«æ§è½ AI èå¨è¨åºç°å¢ä¸­é²è¡å¯é  AI é©å CXR åææéçå¯è§£éæ§ä¹éçå·®è·ã

##### **Critique of Impure Reason: Unveiling the reasoning behaviour of medical Large Language Models**
2412.15748v1 by Shamus Sim, Tyrone Chen

Background: Despite the current ubiquity of Large Language Models (LLMs)
across the medical domain, there is a surprising lack of studies which address
their reasoning behaviour. We emphasise the importance of understanding
reasoning behaviour as opposed to high-level prediction accuracies, since it is
equivalent to explainable AI (XAI) in this context. In particular, achieving
XAI in medical LLMs used in the clinical domain will have a significant impact
across the healthcare sector. Results: Therefore, we define the concept of
reasoning behaviour in the specific context of medical LLMs. We then categorise
and discuss the current state of the art of methods which evaluate reasoning
behaviour in medical LLMs. Finally, we propose theoretical frameworks which can
empower medical professionals or machine learning engineers to gain insight
into the low-level reasoning operations of these previously obscure models.
Conclusion: The subsequent increased transparency and trust in medical machine
learning models by clinicians as well as patients will accelerate the
integration, application as well as further development of medical AI for the
healthcare system as a whole

æè¦ï¼èæ¯ï¼åç®¡å¤§åèªè¨æ¨¡å (LLM) ç®åå¨é«çé åç¡æä¸å¨ï¼ä½ä»¤äººé©è¨çæ¯ï¼æ¢è¨å¶æ¨çè¡çºçç ç©¶å»ç¸ç¶ç¼ºä¹ãæåå¼·èª¿äºè§£æ¨çè¡çºèéé«å±¤ç´çé æ¸¬æºç¢ºåº¦éå¸¸éè¦ï¼å çºå¨éç¨®ææ³ä¸ï¼éç­åæ¼å¯è§£é AI (XAI)ãå°¤å¶æ¯å¨è¨åºé åä¸­ä½¿ç¨çé«ç LLM ä¸­å¯¦ç¾ XAIï¼å°å°æ´åé«çä¿å¥ç¢æ¥­ç¢çéå¤§å½±é¿ãçµæï¼å æ­¤ï¼æåå¨é«ç LLM çç¹å®èæ¯ä¸å®ç¾©äºæ¨çè¡çºçæ¦å¿µãæ¥èæååé¡ä¸¦æ¢è¨ç¶åè©ä¼°é«ç LLM ä¸­æ¨çè¡çºçæ¹æ³çææ°æè¡ãæå¾ï¼æåæåºçè«æ¶æ§ï¼è®é«çå°æ¥­äººå¡ææ©å¨å­¸ç¿å·¥ç¨å¸«å¾ä»¥æ·±å¥äºè§£éäºååæ¨¡ç³æ¨¡åçä½å±¤ç´æ¨çéç®ãçµè«ï¼è¨åºé«çåæ£èå°é«çæ©å¨å­¸ç¿æ¨¡åçéæåº¦åä¿¡ä»»åº¦é¨ä¹æåï¼å°å éé«ç AI å¨æ´åé«çä¿å¥ç³»çµ±ä¸­çæ´åãæç¨åé²ä¸æ­¥ç¼å±ã

##### **Cognition Chain for Explainable Psychological Stress Detection on Social Media**
2412.14009v1 by Xin Wang, Boyan Gao, Yi Dai, Lei Cao, Liang Zhao, Yibo Yang, David Clifton

Stress is a pervasive global health issue that can lead to severe mental
health problems. Early detection offers timely intervention and prevention of
stress-related disorders. The current early detection models perform "black
box" inference suffering from limited explainability and trust which blocks the
real-world clinical application. Thanks to the generative properties introduced
by the Large Language Models (LLMs), the decision and the prediction from such
models are semi-interpretable through the corresponding description. However,
the existing LLMs are mostly trained for general purposes without the guidance
of psychological cognitive theory. To this end, we first highlight the
importance of prior theory with the observation of performance boosted by the
chain-of-thoughts tailored for stress detection. This method termed Cognition
Chain explicates the generation of stress through a step-by-step cognitive
perspective based on cognitive appraisal theory with a progress pipeline:
Stimulus $\rightarrow$ Evaluation $\rightarrow$ Reaction $\rightarrow$ Stress
State, guiding LLMs to provide comprehensive reasoning explanations. We further
study the benefits brought by the proposed Cognition Chain format by utilising
it as a synthetic dataset generation template for LLMs instruction-tuning and
introduce CogInstruct, an instruction-tuning dataset for stress detection. This
dataset is developed using a three-stage self-reflective annotation pipeline
that enables LLMs to autonomously generate and refine instructional data. By
instruction-tuning Llama3 with CogInstruct, we develop CogLLM, an explainable
stress detection model. Evaluations demonstrate that CogLLM achieves
outstanding performance while enhancing explainability. Our work contributes a
novel approach by integrating cognitive theories into LLM reasoning processes,
offering a promising direction for future explainable AI research.

æè¦ï¼å£åæ¯ä¸åæ®éçå¨çæ§å¥åº·åé¡ï¼å¯è½æå°è´å´éçç²¾ç¥
å¥åº·åé¡ãæ©æç¼ç¾æä¾åæçå¹²é åé é²
å£åç¸éç¾çãç®åçæ©æç¼ç¾æ¨¡åå·è¡ãé»
çå­ãæ¨è«ï¼å­å¨å¯è§£éæ§åä¿¡ä»»åº¦æéçåé¡ï¼é»ç¤äº
ç¾å¯¦ä¸ççè¨åºæç¨ãå¤è§äºå¤§åèªè¨æ¨¡å (LLM) å¼å¥ççæå±¬æ§ï¼æ­¤é¡
æ¨¡åçæ±ºç­åé æ¸¬ééå°ææè¿°å·æåå¯è§£éæ§ãç¶èï¼
ç¾æç LLM ä¸»è¦éå°ä¸è¬ç¨éé²è¡è¨ç·´ï¼æ²æå¿çèªç¥çè«çæå°ãçºæ­¤ï¼æåé¦åå¼·èª¿
åé©çè«çéè¦æ§ï¼ä¸¦è§å¯å°éå°å£åæª¢æ¸¬éèº«å®å¶çææ³éæåäºæ§è½ãéç¨®æ¹æ³ç¨±çºèªç¥
éééåºæ¼èªç¥è©ä¼°çè«çå¾ªåºæ¼¸é²çèªç¥è¦è§é¡æäºå£åçç¢çï¼ä¸¦å·æé²åº¦ç®¡éï¼
åºæ¿ $\rightarrow$ è©ä¼° $\rightarrow$ åæ $\rightarrow$ å£å
çæï¼æå° LLM æä¾å¨é¢çæ¨çè§£éãæåé²ä¸æ­¥
ééå°å¶ç¨ä½ LLM æä»¤èª¿æ´çåææ¸æéçææ¨¡æ¿ä¾ç ç©¶ææåºçèªç¥éæ ¼å¼å¸¶ä¾çåªé»ï¼ä¸¦ä»ç´¹ CogInstructï¼éæ¯ä¸åéå°å£åæª¢æ¸¬çæä»¤èª¿æ´æ¸æéãéå
æ¸æéæ¯ä½¿ç¨ä¸åä¸éæ®µçèªçæ¨è¨»ç®¡ééç¼çï¼ä½¿ LLM è½å¤ èªä¸»çæååªåæä»¤æ¸æãéé
ä½¿ç¨ CogInstruct å° Llama3 é²è¡æä»¤èª¿æ´ï¼æåéç¼äº CogLLMï¼éæ¯ä¸åå¯è§£éç
å£åæª¢æ¸¬æ¨¡åãè©ä¼°è¡¨æï¼CogLLM å¨æé«å¯è§£éæ§çåæå¯¦ç¾äºåºè²çæ§è½ãæåçç ç©¶ééå°èªç¥çè«æ´åå° LLM æ¨çéç¨ä¸­ï¼æåºäºä¸ç¨®æ°ç©çæ¹æ³ï¼
çºæªä¾çå¯è§£éäººå·¥æºè½ç ç©¶æä¾äºä¸åæå¸æçæ¹åã

##### **2-Factor Retrieval for Improved Human-AI Decision Making in Radiology**
2412.00372v1 by Jim Solomon, Laleh Jalilian, Alexander Vilesov, Meryl Mathew, Tristan Grogan, Arash Bedayat, Achuta Kadambi

Human-machine teaming in medical AI requires us to understand to what degree
a trained clinician should weigh AI predictions. While previous work has shown
the potential of AI assistance at improving clinical predictions, existing
clinical decision support systems either provide no explainability of their
predictions or use techniques like saliency and Shapley values, which do not
allow for physician-based verification. To address this gap, this study
compares previously used explainable AI techniques with a newly proposed
technique termed '2-factor retrieval (2FR)', which is a combination of
interface design and search retrieval that returns similarly labeled data
without processing this data. This results in a 2-factor security blanket
where: (a) correct images need to be retrieved by the AI; and (b) humans should
associate the retrieved images with the current pathology under test. We find
that when tested on chest X-ray diagnoses, 2FR leads to increases in clinician
accuracy, with particular improvements when clinicians are radiologists and
have low confidence in their decision. Our results highlight the importance of
understanding how different modes of human-AI decision making may impact
clinician accuracy in clinical decision support systems.

æè¦ï¼äººæ©åä½å¨é«ç AI ä¸­ï¼éè¦æåçè§£åéè¨ç·´çè¨åºé«çå¨å¤å¤§ç¨åº¦ä¸æéè¦ AI é æ¸¬ãéç¶ååçç ç©¶é¡¯ç¤º AI è¼å©å¨æ¹åè¨åºé æ¸¬æ¹é¢çæ½åï¼ä½ç¾æçè¨åºæ±ºç­æ¯æ´ç³»çµ±ï¼è¦ä¸å°±æ²ææä¾é æ¸¬çå¯è§£éæ§ï¼è¦ä¸å°±æ¯ä½¿ç¨åé¡¯èæ§å Shapley å¼ä¹é¡çæè¡ï¼éäºæè¡ä¸åè¨±åºæ¼é«ççé©è­ãçºäºè§£æ±ºéåå·®è·ï¼æ¬ç ç©¶å°ååä½¿ç¨çå¯è§£é AI æè¡èä¸ç¨®æ°æåºçç¨±çºã2 å å­æª¢ç´¢ (2FR)ãçæè¡é²è¡æ¯è¼ï¼å¾èæ¯ä¸ç¨®ä»é¢è¨­è¨åæå°æª¢ç´¢ççµåï¼å®æå³åæ¨ç±¤ç¸ä¼¼çè³æï¼èä¸æèçéäºè³æãéæç¢çä¸å 2 å å­å®å¨æ©å¶ï¼å¶ä¸­ï¼(a) æ­£ç¢ºçå½±åéè¦ç± AI æª¢ç´¢ï¼(b) äººé¡æå°æª¢ç´¢çå½±åèæ­£å¨æ¸¬è©¦ä¸­çççè¯æ³èµ·ä¾ãæåç¼ç¾ï¼ç¶å¨è¸é¨ X åè¨ºæ·ä¸é²è¡æ¸¬è©¦æï¼2FR ææé«è¨åºé«ççæºç¢ºåº¦ï¼ç¹å¥æ¯å¨è¨åºé«çæ¯æ¾å°ç§é«çä¸å°å¶æ±ºç­ä¿¡å¿ä¸è¶³æï¼ææé¡¯èçæ¹åãæåççµæå¼·èª¿äºçè§£äººæ©æ±ºç­çä¸åæ¨¡å¼å¦ä½å½±é¿è¨åºé«çå¨è¨åºæ±ºç­æ¯æ´ç³»çµ±ä¸­çæºç¢ºæ§çéè¦æ§ã

##### **Mapping Public Perception of Artificial Intelligence: Expectations, Risk-Benefit Tradeoffs, and Value As Determinants for Societal Acceptance**
2411.19356v1 by Philipp Brauner, Felix Glawe, Gian Luca Liehner, Luisa Vervier, Martina Ziefle

Understanding public perception of artificial intelligence (AI) and the
tradeoffs between potential risks and benefits is crucial, as these perceptions
might shape policy decisions, influence innovation trajectories for successful
market strategies, and determine individual and societal acceptance of AI
technologies. Using a representative sample of 1100 participants from Germany,
this study examines mental models of AI. Participants quantitatively evaluated
71 statements about AI's future capabilities (e.g., autonomous driving, medical
care, art, politics, warfare, and societal divides), assessing the expected
likelihood of occurrence, perceived risks, benefits, and overall value. We
present rankings of these projections alongside visual mappings illustrating
public risk-benefit tradeoffs. While many scenarios were deemed likely,
participants often associated them with high risks, limited benefits, and low
overall value. Across all scenarios, 96.4% ($r^2=96.4\%$) of the variance in
value assessment can be explained by perceived risks ($\beta=-.504$) and
perceived benefits ($\beta=+.710$), with no significant relation to expected
likelihood. Demographics and personality traits influenced perceptions of
risks, benefits, and overall evaluations, underscoring the importance of
increasing AI literacy and tailoring public information to diverse user needs.
These findings provide actionable insights for researchers, developers, and
policymakers by highlighting critical public concerns and individual factors
essential to align AI development with individual values.

æè¦ï¼<paragraph>äºè§£å¬ç¾å°äººå·¥æºæ§ (AI) çèªç¥ä»¥åæ½å¨é¢¨éªèå¥½èä¹éçæ¬è¡¡è³ééè¦ï¼å çºéäºèªç¥å¯è½æå½±é¿æ¿ç­æ±ºç­ãå½±é¿æåå¸å ´ç­ç¥çåµæ°è»è·¡ï¼ä¸¦æ±ºå®åäººåç¤¾æå° AI æè¡çæ¥ååº¦ãæ¬ç ç©¶ä½¿ç¨ä¾èªå¾·åç 1100 ååèèçä»£è¡¨æ§æ¨£æ¬ï¼æ¢è¨äº AI çå¿æºæ¨¡åãåèèå° 71 é éæ¼ AI æªä¾è½åçé³è¿°ï¼ä¾å¦ï¼èªåé§é§ãé«çä¿å¥ãèè¡ãæ¿æ²»ãæ°ç­åç¤¾æåæ­§ï¼é²è¡äºå®éè©ä¼°ï¼è©ä¼°é æçç¼çå¯è½æ§ãæç¥é¢¨éªãå¥½èåæ´é«å¹å¼ãæåå±ç¤ºäºéäºé æ¸¬çæåï¼ä¸¦éä¸è¦è¦ºåæ å°ï¼èªªæäºå¬ç¾çé¢¨éªæ¶çæ¬è¡¡ãåç®¡è¨±å¤å ´æ¯è¢«èªçºæ¯å¯è½çï¼ä½åèèéå¸¸å°å®åèé«é¢¨éªãæéçå¥½èåä½æ´é«å¹å¼è¯ç¹«èµ·ä¾ãå¨ææå ´æ¯ä¸­ï¼96.4% ($r^2=96.4\%$) çå¹å¼è©ä¼°å·®ç°å¯ä»¥ç¨æç¥é¢¨éª ($\beta=-.504$) åæç¥å¥½è ($\beta=+.710$) ä¾è§£éï¼èé æçå¯è½æ§æ²æé¡¯èéä¿ãäººå£çµ±è¨åäººæ ¼ç¹è³ªå½±é¿äºå°é¢¨éªãå¥½èåæ´é«è©ä¼°ççæ³ï¼éå¸é¡¯äºæé« AI ç´ é¤åæ ¹æä¸åçä½¿ç¨èéæ±èª¿æ´å¬å±è³è¨çéè¦æ§ãéäºç¼ç¾ééå¼·èª¿ééµçå¬å±éæ³¨åèåäººå¹å¼è§ä¸è´ç AI éç¼å¿ä¸å¯å°çåäººå ç´ ï¼çºç ç©¶äººå¡ãéç¼äººå¡åæ¿ç­å¶å®èæä¾äºå¯è¡çè¦è§£ã</paragraph>

##### **Explainable AI for Classifying UTI Risk Groups Using a Real-World Linked EHR and Pathology Lab Dataset**
2411.17645v1 by Yujie Dai, Brian Sullivan, Axel Montout, Amy Dillon, Chris Waller, Peter Acs, Rachel Denholm, Philip Williams, Alastair D Hay, Raul Santos-Rodriguez, Andrew Dowsey

The use of machine learning and AI on electronic health records (EHRs) holds
substantial potential for clinical insight. However, this approach faces
significant challenges due to data heterogeneity, sparsity, temporal
misalignment, and limited labeled outcomes. In this context, we leverage a
linked EHR dataset of approximately one million de-identified individuals from
Bristol, North Somerset, and South Gloucestershire, UK, to characterize urinary
tract infections (UTIs) and develop predictive models focused on data quality,
fairness and transparency. A comprehensive data pre-processing and curation
pipeline transforms the raw EHR data into a structured format suitable for AI
modeling. Given the limited availability and biases of ground truth UTI
outcomes, we introduce a UTI risk estimation framework informed by clinical
expertise to estimate UTI risk across individual patient timelines. Using this
framework, we built pairwise XGBoost models to differentiate UTI risk
categories with explainable AI techniques to identify key predictors while
ensuring interpretability. Our findings reveal differences in clinical and
demographic factors across risk groups, offering insights into UTI risk
stratification and progression. This study demonstrates the added value of
AI-driven insights into UTI clinical decision-making while prioritizing
interpretability, transparency, and fairness, underscoring the importance of
sound data practices in advancing health outcomes.

æè¦ï¼æ©å¨å­¸ç¿åäººå·¥æºæ§å¨é»å­å¥åº·ç´é (EHR) ä¸çæç¨å·æ
è¨åºè¦è§£çå·¨å¤§æ½åãç¶èï¼éç¨®æ¹æ³ç±æ¼è³æç°è³ªæ§ãç¨çæ§ãæéé¯ä½åæ¨è¨çµææéï¼å æ­¤é¢è¨éå¤§ææ°ãå¨æ­¤èæ¯ä¸ï¼æåå©ç¨ä¾èªè±åå¸éæ¯æãåè©é»å¡ç¹é¡ååæ ¼æ´æ¯ç¹é¡çå¤§ç´ä¸ç¾è¬åå»è­å¥ååäººçé£çµå¼ EHR è³æéï¼ä»¥æè¿°æ³å°¿éææ (UTI) ä¸¦éç¼å°æ³¨æ¼è³æåè³ªãå¬å¹³æ§åéæåº¦çé æ¸¬æ¨¡åãå¨é¢çè³æåèçåæ´çç®¡éå°åå§ EHR è³æè½æçºé©å AI å»ºæ¨¡ççµæ§åæ ¼å¼ãéæ¼å¯¦é UTI çµæçå¯ç¨æ§æéååè¦ï¼æåå¼å¥äºä¸åç±è¨åºå°æ¥­ç¥è­æä¾è³è¨ç UTI é¢¨éªè©ä¼°æ¶æ§ï¼ä»¥ä¼°è¨åäººæ£èæéç·ä¸ç UTI é¢¨éªãä½¿ç¨æ­¤æ¶æ§ï¼æåå»ºç«äºæå°ç XGBoost æ¨¡åï¼ä»¥åå UTI é¢¨éªé¡å¥ï¼ä¸¦ä½¿ç¨å¯è§£éç AI æè¡ä¾è­å¥ééµé æ¸¬å å­ï¼åæç¢ºä¿å¯è§£éæ§ãæåçç ç©¶çµææ­ç¤ºäºä¸åé¢¨éªç¾¤çµçè¨åºåäººå£çµ±è¨å ç´ çå·®ç°ï¼æä¾äºå° UTI é¢¨éªåå±¤åé²å±çè¦è§£ãæ¬ç ç©¶å±ç¤ºäº AI é©åçè¦è§£å¨ UTI è¨åºæ±ºç­ä¸­çéå å¹å¼ï¼åæåªåèæ®å¯è§£éæ§ãéæåº¦åå¬å¹³æ§ï¼å¼·èª¿äºå¥å¨è³æå¯¦åå¨ä¿é²å¥åº·çµæä¸­çéè¦æ§ã

##### **Exploring the Requirements of Clinicians for Explainable AI Decision Support Systems in Intensive Care**
2411.11774v1 by Jeffrey N. Clark, Matthew Wragg, Emily Nielsen, Miquel Perello-Nieto, Nawid Keshtmand, Michael Ambler, Shiv Sharma, Christopher P. Bourdeaux, Amberly Brigden, Raul Santos-Rodriguez

There is a growing need to understand how digital systems can support
clinical decision-making, particularly as artificial intelligence (AI) models
become increasingly complex and less human-interpretable. This complexity
raises concerns about trustworthiness, impacting safe and effective adoption of
such technologies. Improved understanding of decision-making processes and
requirements for explanations coming from decision support tools is a vital
component in providing effective explainable solutions. This is particularly
relevant in the data-intensive, fast-paced environments of intensive care units
(ICUs). To explore these issues, group interviews were conducted with seven ICU
clinicians, representing various roles and experience levels. Thematic analysis
revealed three core themes: (T1) ICU decision-making relies on a wide range of
factors, (T2) the complexity of patient state is challenging for shared
decision-making, and (T3) requirements and capabilities of AI decision support
systems. We include design recommendations from clinical input, providing
insights to inform future AI systems for intensive care.

æè¦ï¼é¨èäººå·¥æºæ§ (AI) æ¨¡åè®å¾è¶ä¾è¶è¤éï¼ä¸è¶ä¾è¶é£ä»¥è¢«äººçè§£ï¼äºè§£æ¸ä½ç³»çµ±å¦ä½æ¯æ´è¨åºæ±ºç­çéæ±ä¹æ¥çå¢å ãéç¨®è¤éæ§å¼ç¼äºå°å¯ä¿¡åº¦ççæ®ï¼å½±é¿äºæ­¤é¡æè¡çå®å¨ä¸æææ¡ç¨ãæ¹åå°æ±ºç­å¶å®æµç¨ççè§£ï¼ä»¥åå°æ±ºç­æ¯æ´å·¥å·ææä¾èªªæçè¦æ±ï¼æ¯æä¾ææå¯è§£éè§£æ±ºæ¹æ¡çéè¦çµæé¨åãéå¨è³æå¯éãå¿«ç¯å¥çå è­·çæ¿ (ICU) ç°å¢ä¸­ç¹å¥ç¸éãçºäºæ¢è¨éäºåé¡ï¼å°ä¸ä½ ICU è¨åºé«å¸«é²è¡äºå°çµè¨ªè«ï¼éäºé«å¸«ä»£è¡¨äºä¸åçè§è²åç¶é©å±¤ç´ãä¸»é¡åææ­é²äºä¸åæ ¸å¿ä¸»é¡ï¼(T1) ICU æ±ºç­å¶å®ä¾è³´æ¼å»£æ³çå ç´ ï¼(T2) çæ£çæçè¤éæ§å°å±åæ±ºç­å¶å®æ§æææ°ï¼ä»¥å (T3) AI æ±ºç­æ¯æ´ç³»çµ±çè¦æ±åè½åãæåç´å¥äºè¨åºè¼¸å¥çè¨­è¨å»ºè­°ï¼æä¾è¦è§£ä»¥æä¾è³è¨çµ¦æªä¾ç¨æ¼å è­·ç AI ç³»çµ±ã

##### **Artificial Intelligence in Pediatric Echocardiography: Exploring Challenges, Opportunities, and Clinical Applications with Explainable AI and Federated Learning**
2411.10255v1 by Mohammed Yaseen Jabarulla, Theodor Uden, Thomas Jack, Philipp Beerbaum, Steffen Oeltze-Jafra

Pediatric heart diseases present a broad spectrum of congenital and acquired
diseases. More complex congenital malformations require a differentiated and
multimodal decision-making process, usually including echocardiography as a
central imaging method. Artificial intelligence (AI) offers considerable
promise for clinicians by facilitating automated interpretation of pediatric
echocardiography data. However, adapting AI technologies for pediatric
echocardiography analysis has challenges such as limited public data
availability, data privacy, and AI model transparency. Recently, researchers
have focused on disruptive technologies, such as federated learning (FL) and
explainable AI (XAI), to improve automatic diagnostic and decision support
workflows. This study offers a comprehensive overview of the limitations and
opportunities of AI in pediatric echocardiography, emphasizing the synergistic
workflow and role of XAI and FL, identifying research gaps, and exploring
potential future developments. Additionally, three relevant clinical use cases
demonstrate the functionality of XAI and FL with a focus on (i) view
recognition, (ii) disease classification, (iii) segmentation of cardiac
structures, and (iv) quantitative assessment of cardiac function.

æè¦ï¼å°åå¿èç¾çåç¾åå¤©æ§èå¾å¤©æ§ç¾ççå»£æ³åè­ãè¼è¤éçåå¤©æ§ç¸å½¢éè¦ä¸åå·®ç°åä¸å¤æ¨¡å¼çæ±ºç­éç¨ï¼éå¸¸åæ¬è¶é³æ³¢æª¢æ¥ä½çºä¸»è¦çå½±åæ¹æ³ãäººå·¥æºæ§ (AI) çºè¨åºé«çæä¾äºç¸ç¶å¤§çå¸æï¼å çºå®å¯ä»¥ä¿é²å°åè¶é³æ³¢æª¢æ¥è³æçèªååè§£è®ãç¶èï¼å°äººå·¥æºæ§æè¡æç¨æ¼å°åè¶é³æ³¢æª¢æ¥åææè¨±å¤ææ°ï¼ä¾å¦æéçå¬éè³æå¯ç¨æ§ãè³æé±ç§åäººå·¥æºæ§æ¨¡åéæåº¦ãæè¿ï¼ç ç©¶äººå¡å°æ³¨æ¼ç ´å£æ§æè¡ï¼ä¾å¦è¯åå­¸ç¿ (FL) åå¯è§£éäººå·¥æºæ§ (XAI)ï¼ä»¥æ¹åèªåè¨ºæ·åæ±ºç­æ¯æ´å·¥ä½æµç¨ãæ¬ç ç©¶æä¾äºäººå·¥æºæ§å¨å°åè¶é³æ³¢æª¢æ¥ä¸­çéå¶åæ©æçå¨é¢æ¦è¿°ï¼å¼·èª¿äº XAI å FL çååå·¥ä½æµç¨åè§è²ï¼æ¾åºç ç©¶å·®è·ä¸¦æ¢è¨æ½å¨çæªä¾ç¼å±ãæ­¤å¤ï¼ä¸åç¸éçè¨åºä½¿ç¨æ¡ä¾å±ç¤ºäº XAI å FL çåè½ï¼éé»å¨æ¼ (i) æª¢è¦è¾¨è­ã(ii) ç¾çåé¡ã(iii) å¿èçµæ§åå²å (iv) å¿èåè½çéåè©ä¼°ã

##### **Enhancing Osteoporosis Detection: An Explainable Multi-Modal Learning Framework with Feature Fusion and Variable Clustering**
2411.00916v2 by Mehdi Hosseini Chagahi, Saeed Mohammadi Dashtaki, Niloufar Delfan, Nadia Mohammadi, Alireza Samari, Behzad Moshiri, Md. Jalil Piran, Oliver Faust

Osteoporosis is a common condition that increases fracture risk, especially
in older adults. Early diagnosis is vital for preventing fractures, reducing
treatment costs, and preserving mobility. However, healthcare providers face
challenges like limited labeled data and difficulties in processing medical
images. This study presents a novel multi-modal learning framework that
integrates clinical and imaging data to improve diagnostic accuracy and model
interpretability. The model utilizes three pre-trained networks-VGG19,
InceptionV3, and ResNet50-to extract deep features from X-ray images. These
features are transformed using PCA to reduce dimensionality and focus on the
most relevant components. A clustering-based selection process identifies the
most representative components, which are then combined with preprocessed
clinical data and processed through a fully connected network (FCN) for final
classification. A feature importance plot highlights key variables, showing
that Medical History, BMI, and Height were the main contributors, emphasizing
the significance of patient-specific data. While imaging features were
valuable, they had lower importance, indicating that clinical data are crucial
for accurate predictions. This framework promotes precise and interpretable
predictions, enhancing transparency and building trust in AI-driven diagnoses
for clinical integration.

æè¦ï¼éª¨è³ªçé¬çæ¯ä¸ç¨®å¸¸è¦çç¾çï¼æå¢å éª¨æçé¢¨éªï¼ç¹å¥æ¯èå¹´äººãæ©æè¨ºæ·å°æ¼é é²éª¨æãéä½æ²»çææ¬åç¶­æè¡åè½åè³ééè¦ãç¶èï¼é«çä¿å¥æä¾èé¢è¨èæ¨è¨æ¸ææéåèçé«å­¸å½±åå°é£ç­ææ°ãæ¬ç ç©¶æåºäºä¸åæ°ç©çå¤æ¨¡å¼å­¸ç¿æ¡æ¶ï¼è©²æ¡æ¶æ´åäºè¨åºåå½±åæ¸æï¼ä»¥æé«è¨ºæ·æºç¢ºæ§åæ¨¡åå¯è§£éæ§ãè©²æ¨¡åå©ç¨ä¸åé è¨ç·´çç¶²è·¯ï¼VGG19ãInceptionV3 å ResNet50ï¼å¾ X å°ç·å½±åä¸­æåæ·±åº¦ç¹å¾µãéäºç¹å¾µä½¿ç¨ PCA è½æä»¥éä½ç¶­åº¦ä¸¦å°æ³¨æ¼æç¸éççµæé¨åãåºæ¼èé¡çé¸æéç¨è­å¥åºæå·ä»£è¡¨æ§ççµæé¨åï¼ç¶å¾å°éäºçµæé¨åèé èççè¨åºæ¸æçµåï¼ä¸¦ééå¨é£æ¥ç¶²è·¯ (FCN) é²è¡æçµåé¡ãç¹å¾µéè¦æ§åçªåºäºééµè®æ¸ï¼è¡¨æçå²ãBMI åèº«é«æ¯ä¸»è¦è²¢ç»å ç´ ï¼å¼·èª¿äºæ£èç¹å®æ¸æçéè¦æ§ãéç¶å½±åç¹å¾µå¾æå¹å¼ï¼ä½å®åçéè¦æ§è¼ä½ï¼éè¡¨æè¨åºæ¸æå°æ¼æºç¢ºé æ¸¬è³ééè¦ãæ­¤æ¡æ¶ä¿è¿äºæºç¢ºä¸å¯è§£éçé æ¸¬ï¼æé«äºéæåº¦ï¼ä¸¦å»ºç«äºå° AI é©åè¨ºæ·å¨è¨åºæ´åä¸­çä¿¡ä»»ã

##### **A Review of Deep Learning Approaches for Non-Invasive Cognitive Impairment Detection**
2410.19898v1 by Muath Alsuhaibani, Ali Pourramezan Fard, Jian Sun, Farida Far Poor, Peter S. Pressman, Mohammad H. Mahoor

This review paper explores recent advances in deep learning approaches for
non-invasive cognitive impairment detection. We examine various non-invasive
indicators of cognitive decline, including speech and language, facial, and
motoric mobility. The paper provides an overview of relevant datasets,
feature-extracting techniques, and deep-learning architectures applied to this
domain. We have analyzed the performance of different methods across modalities
and observed that speech and language-based methods generally achieved the
highest detection performance. Studies combining acoustic and linguistic
features tended to outperform those using a single modality. Facial analysis
methods showed promise for visual modalities but were less extensively studied.
Most papers focused on binary classification (impaired vs. non-impaired), with
fewer addressing multi-class or regression tasks. Transfer learning and
pre-trained language models emerged as popular and effective techniques,
especially for linguistic analysis. Despite significant progress, several
challenges remain, including data standardization and accessibility, model
explainability, longitudinal analysis limitations, and clinical adaptation.
Lastly, we propose future research directions, such as investigating
language-agnostic speech analysis methods, developing multi-modal diagnostic
systems, and addressing ethical considerations in AI-assisted healthcare. By
synthesizing current trends and identifying key obstacles, this review aims to
guide further development of deep learning-based cognitive impairment detection
systems to improve early diagnosis and ultimately patient outcomes.

æè¦ï¼æ¬ç¯è©è«æ¢è¨äºæ·±åº¦å­¸ç¿æ¹æ³å¨éä¾µå¥å¼èªç¥åè½éç¤æª¢æ¸¬ä¸çææ°é²å±ãæåæª¢è¦äºåç¨®éä¾µå¥å¼çèªç¥è¡°éææ¨ï¼åæ¬èªè¨åèªè¨ãé¢é¨åéåæ©è½ãæ¬ææ¦è¿°äºèæ­¤é åç¸éçè³æéãç¹å¾µæåæè¡åæ·±åº¦å­¸ç¿æ¶æ§ãæååæäºä¸åæ¹æ³å¨ä¸åæ¹å¼ä¸çè¡¨ç¾ï¼ä¸¦è§å¯å°åºæ¼èªè¨åèªè¨çæ¹æ³éå¸¸è½éå°æé«çæª¢æ¸¬è¡¨ç¾ãçµåè²å­¸åèªè¨ç¹å¾µçç ç©¶å¾å¾åªæ¼ä½¿ç¨å®ä¸æ¹å¼çç ç©¶ãé¢é¨åææ¹æ³é¡¯ç¤ºåºè¦è¦ºæ¹å¼çæ½åï¼ä½ç ç©¶è¼å°ãå¤§å¤æ¸è«æå°æ³¨æ¼äºååé¡ï¼åæèæªåæï¼ï¼è¼å°æ¢è¨å¤é¡æåæ­¸ä»»åãé·ç§»å­¸ç¿åé è¨ç·´èªè¨æ¨¡åå·²æçºæµè¡ä¸ææçæè¡ï¼ç¹å¥æ¯å°æ¼èªè¨åæãåç®¡åå¾äºéå¤§é²å±ï¼ä½ä»å­å¨ä¸äºææ°ï¼åæ¬è³ææ¨æºååå¯åæ§ãæ¨¡åå¯è§£éæ§ãç¸±ååæéå¶åè¨åºé©ææ§ãæå¾ï¼æåæåºäºæªä¾çç ç©¶æ¹åï¼ä¾å¦èª¿æ¥èèªè¨ç¡éçèªé³åææ¹æ³ãéç¼å¤æ¨¡å¼è¨ºæ·ç³»çµ±ï¼ä»¥åè§£æ±ºäººå·¥æºæ§è¼å©é«çä¿å¥ä¸­çå«çèéãééç¶åç®åçè¶¨å¢åæ¾åºééµéç¤ï¼æ¬ç¯è©è«æ¨å¨å¼å°æ·±åº¦å­¸ç¿çºåºç¤çèªç¥åè½éç¤æª¢æ¸¬ç³»çµ±çé²ä¸æ­¥ç¼å±ï¼ä»¥æ¹åæ©æè¨ºæ·ï¼ä¸¦æçµæ¹åæ£èçæ²»ççµæã

##### **An Ontology-Enabled Approach For User-Centered and Knowledge-Enabled Explanations of AI Systems**
2410.17504v1 by Shruthi Chari

Explainable Artificial Intelligence (AI) focuses on helping humans understand
the working of AI systems or their decisions and has been a cornerstone of AI
for decades. Recent research in explainability has focused on explaining the
workings of AI models or model explainability. There have also been several
position statements and review papers detailing the needs of end-users for
user-centered explainability but fewer implementations. Hence, this thesis
seeks to bridge some gaps between model and user-centered explainability. We
create an explanation ontology (EO) to represent literature-derived explanation
types via their supporting components. We implement a knowledge-augmented
question-answering (QA) pipeline to support contextual explanations in a
clinical setting. Finally, we are implementing a system to combine explanations
from different AI methods and data modalities. Within the EO, we can represent
fifteen different explanation types, and we have tested these representations
in six exemplar use cases. We find that knowledge augmentations improve the
performance of base large language models in the contextualized QA, and the
performance is variable across disease groups. In the same setting, clinicians
also indicated that they prefer to see actionability as one of the main foci in
explanations. In our explanations combination method, we plan to use similarity
metrics to determine the similarity of explanations in a chronic disease
detection setting. Overall, through this thesis, we design methods that can
support knowledge-enabled explanations across different use cases, accounting
for the methods in today's AI era that can generate the supporting components
of these explanations and domain knowledge sources that can enhance them.

æè¦ï¼å¯è§£éäººå·¥æºæ§ï¼AIï¼å°æ³¨æ¼åå©äººé¡äºè§£ AI ç³»çµ±éä½æå¶æ±ºç­ï¼æ¸åå¹´ä¾ä¸ç´æ¯ AI çåºç³ãæè¿çå¯è§£éæ§ç ç©¶å°æ³¨æ¼è§£é AI æ¨¡åææ¨¡åå¯è§£éæ§çéä½ãä¹æå¹¾ä»½ç«å ´è²æåè©è«è«æè©³ç´°èªªæäºæçµä½¿ç¨èå°ä»¥ä½¿ç¨èçºä¸­å¿çå¯è§£éæ§çéæ±ï¼ä½å¯¦ä½è¼å°ãå æ­¤ï¼æ¬è«ææ¨å¨å½è£æ¨¡ååä»¥ä½¿ç¨èçºä¸­å¿çå¯è§£éæ§ä¹éçä¸äºå·®è·ãæåå»ºç«ä¸åè§£éæ¬é«ï¼EOï¼ä»¥ééå¶æ¯æ´åä»¶ä¾è¡¨ç¤ºå¾æç»ä¸­è¡ççè§£éé¡åãæåå¯¦ä½ä¸åç¥è­å¢å¼·çåç­ï¼QAï¼ç®¡ç·ï¼ä»¥å¨è¨åºç°å¢ä¸­æ¯æ´æå¢è§£éãæå¾ï¼æåæ­£å¨å¯¦ä½ä¸åç³»çµ±ï¼ä»¥çµåä¾èªä¸å AI æ¹æ³åè³ææ¨¡å¼çè§£éãå¨ EO ä¸­ï¼æåå¯ä»¥è¡¨ç¤º 15 ç¨®ä¸åçè§£éé¡åï¼ä¸¦ä¸æåå·²å¨å­åç¯ä¾ä½¿ç¨æ¡ä¾ä¸­æ¸¬è©¦éäºè¡¨ç¤ºãæåç¼ç¾ï¼ç¥è­å¢å¼·æ¹åäºåºç¤å¤§åèªè¨æ¨¡åå¨æå¢å QA ä¸­çæè½ï¼ä¸¦ä¸æè½å ç¾çç¾¤çµèç°ãå¨ç¸åçç°å¢ä¸­ï¼è¨åºé«çä¹è¡¨ç¤ºä»åå¸æå°å¯æä½æ§è¦çºè§£éä¸­çä¸»è¦ç¦é»ä¹ä¸ãå¨æåçè§£éçµåæ¹æ³ä¸­ï¼æåè¨ç«ä½¿ç¨ç¸ä¼¼æ§ææ¨ä¾ç¢ºå®æ¢æ§çåµæ¸¬ç°å¢ä¸­è§£éçç¸ä¼¼æ§ãç¸½é«èè¨ï¼ééæ¬è«æï¼æåè¨­è¨äºå¯ä»¥å¨ä¸åä½¿ç¨æ¡ä¾ä¸­æ¯æ´ç¥è­åç¨è§£éçæ¹æ³ï¼èéå°ç¶ä» AI æä»£ä¸­å¯ä»¥ç¢çéäºè§£éçæ¯æ´åä»¶åå¯ä»¥å¢å¼·éäºè§£éçé åç¥è­ä¾æºçæ¹æ³ã

##### **Contrasting Attitudes Towards Current and Future AI Applications for Computerised Interpretation of ECG: A Clinical Stakeholder Interview Study**
2410.16879v1 by Lukas Hughes-Noehrer, Leda Channer, Gabriel Strain, Gregory Yates, Richard Body, Caroline Jay

Objectives: To investigate clinicians' attitudes towards current automated
interpretation of ECG and novel AI technologies and their perception of
computer-assisted interpretation. Materials and Methods: We conducted a series
of interviews with clinicians in the UK. Our study: (i) explores the potential
for AI, specifically future 'human-like' computing approaches, to facilitate
ECG interpretation and support clinical decision making, and (ii) elicits their
opinions about the importance of explainability and trustworthiness of AI
algorithms. Results: We performed inductive thematic analysis on interview
transcriptions from 23 clinicians and identified the following themes: (i) a
lack of trust in current systems, (ii) positive attitudes towards future AI
applications and requirements for these, (iii) the relationship between the
accuracy and explainability of algorithms, and (iv) opinions on education,
possible deskilling, and the impact of AI on clinical competencies. Discussion:
Clinicians do not trust current computerised methods, but welcome future 'AI'
technologies. Where clinicians trust future AI interpretation to be accurate,
they are less concerned that it is explainable. They also preferred ECG
interpretation that demonstrated the results of the algorithm visually. Whilst
clinicians do not fear job losses, they are concerned about deskilling and the
need to educate the workforce to use AI responsibly. Conclusion: Clinicians are
positive about the future application of AI in clinical decision-making.
Accuracy is a key factor of uptake and visualisations are preferred over
current computerised methods. This is viewed as a potential means of training
and upskilling, in contrast to the deskilling that automation might be
perceived to bring.

æè¦ï¼<paragraph>ç®çï¼èª¿æ¥è¨åºé«çå°ç®åèªååå¿é»åè§£è®åæ°çäººå·¥æºæ§æè¡çæåº¦ï¼ä»¥åä»åå°é»è¦è¼å©è§£è®ççæ³ãææåæ¹æ³ï¼æåå°è±åçè¨åºé«çé²è¡äºä¸ç³»åè¨ªè«ãæåçç ç©¶ï¼(i) æ¢è¨äººå·¥æºæ§çæ½åï¼ç¹å¥æ¯æªä¾çãé¡äººé¡ãéç®æ¹æ³ï¼ä»¥ä¿é²å¿é»åè§£è®ä¸¦æ¯æè¨åºæ±ºç­å¶å®ï¼ä»¥å (ii) å¾µæ±ä»åå°äººå·¥æºæ§æ¼ç®æ³çå¯è§£éæ§åå¯ä¿¡åº¦ççæ³ãçµæï¼æåå° 23 ä½è¨åºé«ççè¨ªè«è¨éé²è¡äºæ­¸ç´ä¸»é¡åæï¼ä¸¦æ¾åºä»¥ä¸ä¸»é¡ï¼(i) å°ç®åç³»çµ±ç¼ºä¹ä¿¡ä»»ï¼(ii) å°æªä¾äººå·¥æºæ§æç¨åå°éäºæç¨çè¦æ±ææ­£é¢æåº¦ï¼(iii) æ¼ç®æ³çæºç¢ºæ§åå¯è§£éæ§ä¹éçéä¿ï¼ä»¥å (iv) å°æè²ãå¯è½çæè½éåï¼ä»¥åäººå·¥æºæ§å°è¨åºè½åçå½±é¿ççæ³ãè¨è«ï¼è¨åºé«çä¸ä¿¡ä»»ç®åçé»è¦åæ¹æ³ï¼ä½æ­¡è¿æªä¾çãäººå·¥æºæ§ãæè¡ãå¨è¨åºé«çç¸ä¿¡æªä¾ç AI è§£è®æºç¢ºçææ³ä¸ï¼ä»åä¸å¤ªæå¿å®æ¯å¦å¯è§£éãä»åä¹æ¯è¼åæ­¡è½ä»¥è¦è¦ºæ¹å¼åç¾æ¼ç®æ³çµæçå¿é»åè§£è®ãéç¶è¨åºé«çä¸å®³æå¤±æ¥­ï¼ä½ä»åæå¿æè½éåï¼ä»¥åéè¦æè²å¡å·¥è² è²¬ä»»å°ä½¿ç¨äººå·¥æºæ§ãçµè«ï¼è¨åºé«çå°äººå·¥æºæ§å¨è¨åºæ±ºç­å¶å®ä¸­çæªä¾æç¨ææ­£é¢æåº¦ãæºç¢ºæ§æ¯æ¡ç¨äººå·¥æºæ§çä¸åééµå ç´ ï¼èè¦è¦ºåæ¯ç®åçé»è¦åæ¹æ³æ´åéçãéè¢«è¦çºä¸ç¨®æ½å¨çå¹è¨åæåæè½çæ¹æ³ï¼èèªååå¯è½å¸¶ä¾çæè½éåå½¢æå°æ¯ã</paragraph>

##### **Pathologist-like explainable AI for interpretable Gleason grading in prostate cancer**
2410.15012v1 by Gesa Mittmann, Sara Laiouar-Pedari, Hendrik A. Mehrtens, Sarah HaggenmÃ¼ller, Tabea-Clara Bucher, Tirtha Chanda, Nadine T. Gaisa, Mathias Wagner, Gilbert Georg Klamminger, Tilman T. Rau, Christina Neppl, Eva Maria CompÃ©rat, Andreas Gocht, Monika HÃ¤mmerle, Niels J. Rupp, Jula Westhoff, Irene KrÃ¼cken, Maximillian Seidl, Christian M. SchÃ¼rch, Marcus Bauer, Wiebke Solass, Yu Chun Tam, Florian Weber, Rainer Grobholz, Jaroslaw Augustyniak, Thomas Kalinski, Christian HÃ¶rner, Kirsten D. Mertz, Constanze DÃ¶ring, Andreas Erbersdobler, Gabriele Deubler, Felix Bremmer, Ulrich Sommer, Michael Brodhun, Jon Griffin, Maria Sarah L. Lenon, Kiril Trpkov, Liang Cheng, Fei Chen, Angelique Levi, Guoping Cai, Tri Q. Nguyen, Ali Amin, Alessia Cimadamore, Ahmed Shabaik, Varsha Manucha, Nazeel Ahmad, Nidia Messias, Francesca Sanguedolce, Diana Taheri, Ezra Baraban, Liwei Jia, Rajal B. Shah, Farshid Siadat, Nicole Swarbrick, Kyung Park, Oudai Hassan, Siamak Sakhaie, Michelle R. Downes, Hiroshi Miyamoto, Sean R. Williamson, Tim Holland-Letz, Carolin V. Schneider, Jakob Nikolas Kather, Yuri Tolkach, Titus J. Brinker

The aggressiveness of prostate cancer, the most common cancer in men
worldwide, is primarily assessed based on histopathological data using the
Gleason scoring system. While artificial intelligence (AI) has shown promise in
accurately predicting Gleason scores, these predictions often lack inherent
explainability, potentially leading to distrust in human-machine interactions.
To address this issue, we introduce a novel dataset of 1,015 tissue microarray
core images, annotated by an international group of 54 pathologists. The
annotations provide detailed localized pattern descriptions for Gleason grading
in line with international guidelines. Utilizing this dataset, we develop an
inherently explainable AI system based on a U-Net architecture that provides
predictions leveraging pathologists' terminology. This approach circumvents
post-hoc explainability methods while maintaining or exceeding the performance
of methods trained directly for Gleason pattern segmentation (Dice score: 0.713
$\pm$ 0.003 trained on explanations vs. 0.691 $\pm$ 0.010 trained on Gleason
patterns). By employing soft labels during training, we capture the intrinsic
uncertainty in the data, yielding strong results in Gleason pattern
segmentation even in the context of high interobserver variability. With the
release of this dataset, we aim to encourage further research into segmentation
in medical tasks with high levels of subjectivity and to advance the
understanding of pathologists' reasoning processes.

æè¦ï¼ååèºçæ¯å¨çç·æ§æå¸¸è¦çççï¼å¶æ¡æ§ç¨åº¦ä¸»è¦æ ¹æ Gleason è©åç³»çµ±ä½¿ç¨çµç¹ççå­¸æ¸æé²è¡è©ä¼°ãéç¶äººå·¥æºæ§ (AI) å¨æºç¢ºé æ¸¬ Gleason è©åæ¹é¢å·²å±ç¾æ½åï¼ä½éäºé æ¸¬éå¸¸ç¼ºä¹å§å¨çå¯è§£éæ§ï¼å¯è½æå°è´å°äººæ©äºåçä¸ä¿¡ä»»ãçºäºè§£æ±ºéååé¡ï¼æåå¼é²äºä¸åç± 54 ä½ççå­¸å®¶çµæçåéåéè¨»è§£ç 1,015 åçµç¹å¾®é£åæ ¸å¿å½±åçæ°ç©è³æéãéäºè¨»è§£æä¾äºè©³ç´°çå±é¨æ¨¡å¼æè¿°ï¼ç¨æ¼ç¬¦ååéæºåç Gleason åç´ãå©ç¨éåè³æéï¼æåéç¼äºä¸ååºæ¼ U-Net æ¶æ§çå§å¨å¯è§£é AI ç³»çµ±ï¼è©²ç³»çµ±æä¾äºå©ç¨ççå­¸å®¶è¡èªé²è¡é æ¸¬ãéç¨®æ¹æ³è¦é¿äºäºå¾å¯è§£éæ§æ¹æ³ï¼åæç¶­ææè¶è¶äºç´æ¥è¨ç·´ç¨æ¼ Gleason æ¨¡å¼åå²çæ¹æ³çæè½ï¼Dice åæ¸ï¼0.713 Â± 0.003ï¼è¨ç·´æ¼è§£éï¼ç¸å°æ¼ 0.691 Â± 0.010ï¼è¨ç·´æ¼ Gleason æ¨¡å¼ï¼ãééå¨è¨ç·´æéæ¡ç¨è»æ¨ç±¤ï¼æåææäºè³æä¸­çå§å¨ä¸ç¢ºå®æ§ï¼å³ä½¿å¨è§å¯èéè®ç°æ§é«çææ³ä¸ï¼ä¹è½å¨ Gleason æ¨¡å¼åå²ä¸­ç¢çå¼·å¤§ççµæãéééåºéåè³æéï¼æåæ¨å¨é¼åµé²ä¸æ­¥ç ç©¶ä¸»è§æ§é«çé«çä»»åä¸­çåå²ï¼ä¸¦å¢é²å°ççå­¸å®¶æ¨çéç¨ççè§£ã

##### **Explainable AI Methods for Multi-Omics Analysis: A Survey**
2410.11910v1 by Ahmad Hussein, Mukesh Prasad, Ali Braytee

Advancements in high-throughput technologies have led to a shift from
traditional hypothesis-driven methodologies to data-driven approaches.
Multi-omics refers to the integrative analysis of data derived from multiple
'omes', such as genomics, proteomics, transcriptomics, metabolomics, and
microbiomics. This approach enables a comprehensive understanding of biological
systems by capturing different layers of biological information. Deep learning
methods are increasingly utilized to integrate multi-omics data, offering
insights into molecular interactions and enhancing research into complex
diseases. However, these models, with their numerous interconnected layers and
nonlinear relationships, often function as black boxes, lacking transparency in
decision-making processes. To overcome this challenge, explainable artificial
intelligence (xAI) methods are crucial for creating transparent models that
allow clinicians to interpret and work with complex data more effectively. This
review explores how xAI can improve the interpretability of deep learning
models in multi-omics research, highlighting its potential to provide
clinicians with clear insights, thereby facilitating the effective application
of such models in clinical settings.

æè¦ï¼é«ééæè¡çé²æ­¥å°è´å¾å³çµ±çåè¨­é©åæ¹æ³è½è®çºè³æé©åçæ¹æ³ãå¤çµå­¸æ¯ææ´ååæä¾èªå¤åãçµå­¸ãçè³æï¼ä¾å¦åºå çµå­¸ãèç½è³ªçµå­¸ãè½éçµå­¸ãä»£è¬çµå­¸åå¾®çç©çµå­¸ãæ­¤æ¹æ³ééæ·åçç©è³è¨çä¸åå±¤é¢ï¼è½å¨é¢äºè§£çç©ç³»çµ±ãæ·±åº¦å­¸ç¿æ¹æ³æä¾æå¸¸è¢«ç¨æ¼æ´åå¤çµå­¸è³æï¼æä¾åå­äº¤äºä½ç¨çæ´å¯åï¼ä¸¦å å¼·å°è¤éç¾ççç ç©¶ãç¶èï¼éäºæ¨¡åå·æè¨±å¤ç¸äºé£æ¥çå±¤ç´åéç·æ§éä¿ï¼éå¸¸æåé»çå­ä¸æ¨£éä½ï¼ç¼ºä¹æ±ºç­éç¨çéæåº¦ãçºäºåææ­¤ææ°ï¼å¯è§£éäººå·¥æºæ§ (xAI) æ¹æ³å°æ¼å»ºç«éææ¨¡åè³ééè¦ï¼è®è¨åºé«çå¯ä»¥æ´ææå°è§£éåèçè¤éè³æãæ­¤è©è«æ¢è¨ xAI å¦ä½è½æ¹åå¤çµå­¸ç ç©¶ä¸­æ·±åº¦å­¸ç¿æ¨¡åçå¯è§£éæ§ï¼å¼·èª¿å¶æä¾è¨åºé«çæç¢ºè¦è§£çæ½åï¼é²èä¿é²æ­¤é¡æ¨¡åå¨è¨åºç°å¢ä¸­çæææç¨ã

##### **Study on the Helpfulness of Explainable Artificial Intelligence**
2410.11896v1 by Tobias Labarta, Elizaveta Kulicheva, Ronja Froelian, Christian GeiÃler, Xenia Melman, Julian von Klitzing

Explainable Artificial Intelligence (XAI) is essential for building advanced
machine learning-powered applications, especially in critical domains such as
medical diagnostics or autonomous driving. Legal, business, and ethical
requirements motivate using effective XAI, but the increasing number of
different methods makes it challenging to pick the right ones. Further, as
explanations are highly context-dependent, measuring the effectiveness of XAI
methods without users can only reveal a limited amount of information,
excluding human factors such as the ability to understand it. We propose to
evaluate XAI methods via the user's ability to successfully perform a proxy
task, designed such that a good performance is an indicator for the explanation
to provide helpful information. In other words, we address the helpfulness of
XAI for human decision-making. Further, a user study on state-of-the-art
methods was conducted, showing differences in their ability to generate trust
and skepticism and the ability to judge the rightfulness of an AI decision
correctly. Based on the results, we highly recommend using and extending this
approach for more objective-based human-centered user studies to measure XAI
performance in an end-to-end fashion.

æè¦ï¼å¯è§£éäººå·¥æºæ§ (XAI) å°æ¼å»ºæ§åé²çæ©å¨å­¸ç¿é©åæç¨ç¨å¼è³ééè¦ï¼ç¹å¥æ¯å¨é«çè¨ºæ·æèªåé§é§ç­ééµé åãæ³å¾ãåæ¥­åå«çè¦æ±ä¿ä½¿ä½¿ç¨ææç XAIï¼ä½æ¸éæ¥çå¢å çä¸åæ¹æ³ä½¿å¾æé¸æ­£ç¢ºçæ¹æ³å·æææ°æ§ãæ­¤å¤ï¼ç±æ¼è§£éé«åº¦ä¾è³´æ¼èæ¯ï¼å¨æ²æä½¿ç¨èçææ³ä¸è¡¡é XAI æ¹æ³çæææ§åªè½æ­ç¤ºæéçè³è¨ï¼æé¤äººé¡å ç´ ï¼ä¾å¦çè§£å®çè½åãæåå»ºè­°ééä½¿ç¨èæåå·è¡ä»£çä»»åçè½åä¾è©ä¼° XAI æ¹æ³ï¼è¨­è¨ä½¿å¾è¯å¥½çå·è¡è¡¨ç¾æ¯è§£éæä¾æç¨è³è¨çææ¨ãæå¥è©±èªªï¼æåæ¢è¨ XAI å°äººé¡æ±ºç­å¶å®çå¹«å©ãæ­¤å¤ï¼å°æåé²çæ¹æ³é²è¡ä½¿ç¨èç ç©¶ï¼é¡¯ç¤ºåºå®åå¨ç¢çä¿¡ä»»åæ·ççè½åä»¥åæ­£ç¢ºå¤æ· AI æ±ºç­æ¯å¦æ­£ç¢ºçè½åæ¹é¢å­å¨å·®ç°ãæ ¹æçµæï¼æåå¼·çå»ºè­°ä½¿ç¨åæ´åéç¨®æ¹æ³ï¼ä»¥é²è¡æ´å¤ä»¥ç®æ¨çºåºç¤çäººçºä¸­å¿ä½¿ç¨èç ç©¶ï¼ä»¥çµç«¯å°çµç«¯çæ¹å¼è¡¡é XAI æè½ã

##### **Use of What-if Scenarios to Help Explain Artificial Intelligence Models for Neonatal Health**
2410.09635v1 by Abdullah Mamun, Lawrence D. Devoe, Mark I. Evans, David W. Britt, Judith Klein-Seetharaman, Hassan Ghasemzadeh

Early detection of intrapartum risk enables interventions to potentially
prevent or mitigate adverse labor outcomes such as cerebral palsy. Currently,
there is no accurate automated system to predict such events to assist with
clinical decision-making. To fill this gap, we propose "Artificial Intelligence
(AI) for Modeling and Explaining Neonatal Health" (AIMEN), a deep learning
framework that not only predicts adverse labor outcomes from maternal, fetal,
obstetrical, and intrapartum risk factors but also provides the model's
reasoning behind the predictions made. The latter can provide insights into
what modifications in the input variables of the model could have changed the
predicted outcome. We address the challenges of imbalance and small datasets by
synthesizing additional training data using Adaptive Synthetic Sampling
(ADASYN) and Conditional Tabular Generative Adversarial Networks (CTGAN). AIMEN
uses an ensemble of fully-connected neural networks as the backbone for its
classification with the data augmentation supported by either ADASYN or CTGAN.
AIMEN, supported by CTGAN, outperforms AIMEN supported by ADASYN in
classification. AIMEN can predict a high risk for adverse labor outcomes with
an average F1 score of 0.784. It also provides counterfactual explanations that
can be achieved by changing 2 to 3 attributes on average. Resources available:
https://github.com/ab9mamun/AIMEN.

æè¦ï¼ç¢ç¨ä¸­é¢¨éªçæ©æåµæ¸¬æå©æ¼é²è¡å¹²é æªæ½ï¼ä»¥é é²ææ¸è¼ä¸å©ççç¢çµæï¼ä¾å¦è¦æ§éº»çºãç®åï¼æ²ææºç¢ºçèªååç³»çµ±å¯ä»¥é æ¸¬æ­¤é¡äºä»¶ï¼ä»¥åå©è¨åºæ±ºç­ãçºäºå¡«è£éä¸ç©ºç½ï¼æåæåºãç¨æ¼å»ºæ¨¡åè§£éæ°çåå¥åº·çäººå·¥æºæ§ã(AIMEN)ï¼éæ¯ä¸åæ·±åº¦å­¸ç¿æ¶æ§ï¼å®ä¸åå¯ä»¥æ ¹æå­ç¢å©¦ãèåãç¢ç§åç¢ç¨é¢¨éªå ç´ é æ¸¬ä¸å©ççç¢çµæï¼éè½æä¾æ¨¡åååºé æ¸¬èå¾çåå ãå¾èå¯ä»¥æä¾è¦è§£ï¼èªªææ¨¡åè¼¸å¥è®æ¸ä¸­çåªäºä¿®æ¹å¯è½ææ¹è®é æ¸¬çµæãæåééä½¿ç¨é©ææ§åææ½æ¨£ (ADASYN) åæ¢ä»¶è¡¨æ ¼çæå°æç¶²è·¯ (CTGAN) ä¾åæé¡å¤çè¨ç·´è³æï¼ä»¥è§£æ±ºä¸å¹³è¡¡åå°åè³æéçææ°ãAIMEN ä½¿ç¨å¨é£æ¥ç¥ç¶ç¶²è·¯çéåä½çºå¶åé¡çéª¨å¹¹ï¼ä¸¦éé ADASYN æ CTGAN æ¯æ´è³ææ´åãç± CTGAN æ¯æ´ç AIMEN å¨åé¡æ¹é¢åªæ¼ç± ADASYN æ¯æ´ç AIMENãAIMEN å¯ä»¥é æ¸¬ä¸å©ççç¢çµæçé«é¢¨éªï¼å¹³å F1 åæ¸çº 0.784ãå®éæä¾åäºå¯¦è§£éï¼å¯ééå¹³åè®æ´ 2 è³ 3 åå±¬æ§ä¾éæãå¯ç¨è³æºï¼https://github.com/ab9mamun/AIMENã

##### **Artificial intelligence techniques in inherited retinal diseases: A review**
2410.09105v1 by Han Trinh, Jordan Vice, Jason Charng, Zahra Tajbakhsh, Khyber Alam, Fred K. Chen, Ajmal Mian

Inherited retinal diseases (IRDs) are a diverse group of genetic disorders
that lead to progressive vision loss and are a major cause of blindness in
working-age adults. The complexity and heterogeneity of IRDs pose significant
challenges in diagnosis, prognosis, and management. Recent advancements in
artificial intelligence (AI) offer promising solutions to these challenges.
However, the rapid development of AI techniques and their varied applications
have led to fragmented knowledge in this field. This review consolidates
existing studies, identifies gaps, and provides an overview of AI's potential
in diagnosing and managing IRDs. It aims to structure pathways for advancing
clinical applications by exploring AI techniques like machine learning and deep
learning, particularly in disease detection, progression prediction, and
personalized treatment planning. Special focus is placed on the effectiveness
of convolutional neural networks in these areas. Additionally, the integration
of explainable AI is discussed, emphasizing its importance in clinical settings
to improve transparency and trust in AI-based systems. The review addresses the
need to bridge existing gaps in focused studies on AI's role in IRDs, offering
a structured analysis of current AI techniques and outlining future research
directions. It concludes with an overview of the challenges and opportunities
in deploying AI for IRDs, highlighting the need for interdisciplinary
collaboration and the continuous development of robust, interpretable AI models
to advance clinical applications.

æè¦ï¼éºå³æ§è¦ç¶²èç¾ç (IRD) æ¯ä¸çµå¤æ¨£åçéºå³ç¾çï¼
æå°è´è¦åéæ¼¸åªå¤±ï¼æ¯å·¥ä½å¹´é½¡æäººå¤±æçä¸»è¦åå ãIRD çè¤éæ§åç°è³ªæ§å°è¨ºæ·ãé å¾åç®¡çæåºäºéå¤§ææ°ãæè¿äººå·¥æºè½ (AI) çé²æ­¥çºéäºææ°æä¾äºæå¸æçè§£æ±ºæ¹æ¡ã
ç¶èï¼AI æè¡çå¿«éç¼å±åå¶å¤ç¨®æç¨å°è´äºè©²é åçç¥è­åæ£ãæ¬ç¶è¿°æ´åäºç¾æç ç©¶ï¼æ¾åºå·®è·ï¼ä¸¦æ¦è¿°äº AI å¨è¨ºæ·åç®¡ç IRD ä¸­çæ½åãå®æ¨å¨ééæ¢ç´¢æ©å¨å­¸ç¿åæ·±åº¦å­¸ç¿ç­ AI æè¡ï¼ç¹å¥æ¯å¨ç¾çæª¢æ¸¬ãé²ç¨é æ¸¬ååæ§åæ²»çè¨åä¸­ï¼çºæ¨é²è¨åºæç¨æ§å»ºéå¾ãç¹å¥éæ³¨éäºé åä¸­å·ç©ç¥ç¶ç¶²è·¯çæææ§ãæ­¤å¤ï¼è¨è«äºå¯è§£é AI çæ´åï¼å¼·èª¿äºå¶å¨è¨åºç°å¢ä¸­æé«éæåº¦åå°åºæ¼ AI çç³»çµ±çä¿¡ä»»çéè¦æ§ãè©²ç¶è¿°è§£æ±ºäºå½å AI å¨ IRD ä¸­ä½ç¨çéé»ç ç©¶ä¸­ç¾æå·®è·çå¿è¦æ§ï¼æä¾äºå°ç¶å AI æè¡ççµæ§ååæï¼ä¸¦æ¦è¿°äºæªä¾çç ç©¶æ¹åãæå¾æ¦è¿°äºå¨ IRD ä¸­é¨ç½² AI çææ°åæ©éï¼å¼·èª¿äºè·¨å­¸ç§åä½åæçºéç¼å¼·å¤§ãå¯è§£éç AI æ¨¡åä»¥æ¨é²è¨åºæç¨çå¿è¦æ§ã

##### **CasiMedicos-Arg: A Medical Question Answering Dataset Annotated with Explanatory Argumentative Structures**
2410.05235v2 by Ekaterina Sviridova, Anar Yeginbergen, Ainara Estarrona, Elena Cabrio, Serena Villata, Rodrigo Agerri

Explaining Artificial Intelligence (AI) decisions is a major challenge
nowadays in AI, in particular when applied to sensitive scenarios like medicine
and law. However, the need to explain the rationale behind decisions is a main
issue also for human-based deliberation as it is important to justify
\textit{why} a certain decision has been taken. Resident medical doctors for
instance are required not only to provide a (possibly correct) diagnosis, but
also to explain how they reached a certain conclusion. Developing new tools to
aid residents to train their explanation skills is therefore a central
objective of AI in education. In this paper, we follow this direction, and we
present, to the best of our knowledge, the first multilingual dataset for
Medical Question Answering where correct and incorrect diagnoses for a clinical
case are enriched with a natural language explanation written by doctors. These
explanations have been manually annotated with argument components (i.e.,
premise, claim) and argument relations (i.e., attack, support), resulting in
the Multilingual CasiMedicos-Arg dataset which consists of 558 clinical cases
in four languages (English, Spanish, French, Italian) with explanations, where
we annotated 5021 claims, 2313 premises, 2431 support relations, and 1106
attack relations. We conclude by showing how competitive baselines perform over
this challenging dataset for the argument mining task.

æè¦ï¼è§£éäººå·¥æºæ§ (AI) çæ±ºç­æ¯ç¾å¨ AI çä¸é éå¤§ææ°ï¼ç¹å¥æ¯æç¨æ¼åé«å­¸åæ³å¾ç­æææå¢æãç¶èï¼è§£éæ±ºç­èå¾çç±çéæ±ä¹æ¯åºæ¼äººé¡çèéçä¸åä¸»è¦åé¡ï¼å çºæå¿è¦è­æçºä»éº¼ååºæåæ±ºç­ãä¾å¦ï¼ä½é¢é«å¸«ä¸åéè¦æä¾ï¼å¯è½æ¯æ­£ç¢ºçï¼è¨ºæ·ï¼ééè¦è§£éä»åå¦ä½éææåçµè«ãå æ­¤ï¼éç¼æ°çå·¥å·ä¾å¹«å©ä½é¢é«å¸«è¨ç·´ä»åçè§£éæå·§æ¯æè²ä¸­ AI çä¸é æ ¸å¿ç®æ¨ãå¨æ¬æä¸­ï¼æåéµå¾ªéåæ¹åï¼ä¸¦ä¸æ ¹ææåçäºè§£ï¼æåºç¬¬ä¸åå¤èªè¨é«å­¸åç­è³æéï¼å¶ä¸­è¨åºçä¾çæ­£ç¢ºåä¸æ­£ç¢ºè¨ºæ·é½éæç±é«çæ°å¯«çèªç¶èªè¨è§£éãéäºè§£éå·²ä½¿ç¨è«è­çµæï¼å³åæãä¸»å¼µï¼åè«è­éä¿ï¼å³æ»æãæ¯æï¼é²è¡æåè¨»è§£ï¼ç¢çå¤èªè¨ CasiMedicos-Arg è³æéï¼å¶ä¸­åå« 558 åå·æè§£éçåç¨®èªè¨ï¼è±èªãè¥¿ç­çèªãæ³èªãç¾©å¤§å©èªï¼çè¨åºçä¾ï¼æåè¨»è§£äº 5021 åä¸»å¼µã2313 ååæã2431 åæ¯æéä¿å 1106 åæ»æéä¿ãæåæå¾å±ç¤ºäºç«¶ç­åºæºå¦ä½éå°è«è­æ¢åä»»åå·è¡æ­¤å·ææ°æ§çè³æéã

##### **Explainable Diagnosis Prediction through Neuro-Symbolic Integration**
2410.01855v2 by Qiuhao Lu, Rui Li, Elham Sagheb, Andrew Wen, Jinlian Wang, Liwei Wang, Jungwei W. Fan, Hongfang Liu

Diagnosis prediction is a critical task in healthcare, where timely and
accurate identification of medical conditions can significantly impact patient
outcomes. Traditional machine learning and deep learning models have achieved
notable success in this domain but often lack interpretability which is a
crucial requirement in clinical settings. In this study, we explore the use of
neuro-symbolic methods, specifically Logical Neural Networks (LNNs), to develop
explainable models for diagnosis prediction. Essentially, we design and
implement LNN-based models that integrate domain-specific knowledge through
logical rules with learnable thresholds. Our models, particularly
$M_{\text{multi-pathway}}$ and $M_{\text{comprehensive}}$, demonstrate superior
performance over traditional models such as Logistic Regression, SVM, and
Random Forest, achieving higher accuracy (up to 80.52\%) and AUROC scores (up
to 0.8457) in the case study of diabetes prediction. The learned weights and
thresholds within the LNN models provide direct insights into feature
contributions, enhancing interpretability without compromising predictive
power. These findings highlight the potential of neuro-symbolic approaches in
bridging the gap between accuracy and explainability in healthcare AI
applications. By offering transparent and adaptable diagnostic models, our work
contributes to the advancement of precision medicine and supports the
development of equitable healthcare solutions. Future research will focus on
extending these methods to larger and more diverse datasets to further validate
their applicability across different medical conditions and populations.

æè¦ï¼è¨ºæ·é æ¸¬æ¯é«çä¿å¥ä¸­çééµä»»åï¼åæä¸æºç¢ºå°è­å¥é«ççæ³æé¡¯èå½±é¿æ£èççµæãå³çµ±çæ©å¨å­¸ç¿åæ·±åº¦å­¸ç¿æ¨¡åå·²å¨éåé ååå¾é¡¯èæåï¼ä½éå¸¸ç¼ºä¹å¯è§£éæ§ï¼éå¨è¨åºç°å¢ä¸­æ¯ä¸é ééµè¦æ±ãå¨æ¬ç ç©¶ä¸­ï¼æåæ¢è¨äºç¥ç¶ç¬¦èæ¹æ³çæç¨ï¼ç¹å¥æ¯éè¼¯ç¥ç¶ç¶²è·¯ (LNN)ï¼ä»¥éç¼ç¨æ¼è¨ºæ·é æ¸¬çå¯è§£éæ¨¡åãåºæ¬ä¸ï¼æåè¨­è¨ä¸¦å¯¦ä½äºåºæ¼ LNN çæ¨¡åï¼éäºæ¨¡åééå·æå¯å­¸ç¿é¾å¼çéè¼¯è¦åæ´åé åç¹å®ç¥è­ãæåçæ¨¡åï¼ç¹å¥æ¯ $M_{\text{multi-pathway}}$ å $M_{\text{comprehensive}}$ï¼è¡¨ç¾åºåªæ¼å³çµ±æ¨¡åï¼ä¾å¦éè¼¯è¿´æ­¸ãSVM åé¨æ©æ£®æï¼çåªç°æè½ï¼å¨ç³å°¿çé æ¸¬çæ¡ä¾ç ç©¶ä¸­éå°äºæ´é«çæºç¢ºåº¦ï¼é«é 80.52%ï¼å AUROC åæ¸ï¼é«é 0.8457ï¼ãLNN æ¨¡åä¸­å­¸ç¿å°çæ¬éåé¾å¼æä¾äºå°ç¹å¾µè²¢ç»çç´æ¥è¦è§£ï¼å¢å¼·äºå¯è§£éæ§ï¼åæä¸å½±é¿é æ¸¬è½åãéäºç¼ç¾çªé¡¯äºç¥ç¶ç¬¦èæ¹æ³å¨å½åé«çä¿å¥ AI æç¨ä¸­æºç¢ºæ§åå¯è§£éæ§å·®è·æ¹é¢çæ½åãééæä¾éæä¸é©ææ§å¼·çè¨ºæ·æ¨¡åï¼æåçç ç©¶æå©æ¼æ¨é²ç²¾æºé«çï¼ä¸¦æ¯æ´å¬å¹³é«çä¿å¥è§£æ±ºæ¹æ¡çéç¼ãæªä¾çç ç©¶å°å°æ³¨æ¼å°éäºæ¹æ³æ´å±å°æ´å¤§ä¸æ´å¤æ¨£åçè³æéï¼ä»¥é²ä¸æ­¥é©è­å¶å¨ä¸åé«ççæ³åäººç¾¤ä¸­çé©ç¨æ§ã

##### **Easydiagnos: a framework for accurate feature selection for automatic diagnosis in smart healthcare**
2410.00366v1 by Prasenjit Maji, Amit Kumar Mondal, Hemanta Kumar Mondal, Saraju P. Mohanty

The rapid advancements in artificial intelligence (AI) have revolutionized
smart healthcare, driving innovations in wearable technologies, continuous
monitoring devices, and intelligent diagnostic systems. However, security,
explainability, robustness, and performance optimization challenges remain
critical barriers to widespread adoption in clinical environments. This
research presents an innovative algorithmic method using the Adaptive Feature
Evaluator (AFE) algorithm to improve feature selection in healthcare datasets
and overcome problems. AFE integrating Genetic Algorithms (GA), Explainable
Artificial Intelligence (XAI), and Permutation Combination Techniques (PCT),
the algorithm optimizes Clinical Decision Support Systems (CDSS), thereby
enhancing predictive accuracy and interpretability. The proposed method is
validated across three diverse healthcare datasets using six distinct machine
learning algorithms, demonstrating its robustness and superiority over
conventional feature selection techniques. The results underscore the
transformative potential of AFE in smart healthcare, enabling personalized and
transparent patient care. Notably, the AFE algorithm, when combined with a
Multi-layer Perceptron (MLP), achieved an accuracy of up to 98.5%, highlighting
its capability to improve clinical decision-making processes in real-world
healthcare applications.

æè¦ï¼äººå·¥æºæ§ (AI) çå¿«éé²å±å¾¹åºæ¹è®äºæºæ§é«çä¿å¥ï¼æ¨åäºå¯ç©¿æ´æè¡ãæçºç£æ§è£ç½®åæºæ§è¨ºæ·ç³»çµ±çåµæ°ãç¶èï¼å®å¨æ§ãå¯è§£éæ§ãç©©å¥æ§åæè½æä½³åææ°ä»ç¶æ¯è¨åºç°å¢ä¸­å»£æ³æ¡ç¨çééµéç¤ãæ¬ç ç©¶æåºä¸ååµæ°çæ¼ç®æ³æ¹æ³ï¼ä½¿ç¨èªé©æç¹å¾µè©ä¼°å¨ (AFE) æ¼ç®æ³ä¾æ¹åé«çä¿å¥è³æéä¸­çç¹å¾µé¸åä¸¦åæåé¡ãAFE æ´åäºéºå³æ¼ç®æ³ (GA)ãå¯è§£éäººå·¥æºæ§ (XAI) åæåçµåæè¡ (PCT)ï¼è©²æ¼ç®æ³æä½³åäºè¨åºæ±ºç­æ¯æ´ç³»çµ± (CDSS)ï¼å¾èæé«äºé æ¸¬æºç¢ºæ§åå¯è§£éæ§ãææåºçæ¹æ³ä½¿ç¨å­ç¨®ä¸åçæ©å¨å­¸ç¿æ¼ç®æ³é©è­äºä¸åä¸åçé«çä¿å¥è³æéï¼è­æäºå¶ç©©å¥æ§ååªæ¼å³çµ±ç¹å¾µé¸åæè¡ãçµæå¼·èª¿äº AFE å¨æºæ§é«çä¿å¥ä¸­çè½è®æ½åï¼å¯¦ç¾äºåäººååéæçæ£èç§è­·ãå¼å¾æ³¨æçæ¯ï¼AFE æ¼ç®æ³èå¤å±¤æç¥å¨ (MLP) çµåä½¿ç¨æï¼æºç¢ºåº¦é«é 98.5%ï¼çªé¡¯äºå¶æ¹åå¯¦éé«çä¿å¥æç¨ä¸­è¨åºæ±ºç­å¶å®æµç¨çè½åã

##### **Dermatologist-like explainable AI enhances melanoma diagnosis accuracy: eye-tracking study**
2409.13476v1 by Tirtha Chanda, Sarah Haggenmueller, Tabea-Clara Bucher, Tim Holland-Letz, Harald Kittler, Philipp Tschandl, Markus V. Heppt, Carola Berking, Jochen S. Utikal, Bastian Schilling, Claudia Buerger, Cristian Navarrete-Dechent, Matthias Goebeler, Jakob Nikolas Kather, Carolin V. Schneider, Benjamin Durani, Hendrike Durani, Martin Jansen, Juliane Wacker, Joerg Wacker, Reader Study Consortium, Titus J. Brinker

Artificial intelligence (AI) systems have substantially improved
dermatologists' diagnostic accuracy for melanoma, with explainable AI (XAI)
systems further enhancing clinicians' confidence and trust in AI-driven
decisions. Despite these advancements, there remains a critical need for
objective evaluation of how dermatologists engage with both AI and XAI tools.
In this study, 76 dermatologists participated in a reader study, diagnosing 16
dermoscopic images of melanomas and nevi using an XAI system that provides
detailed, domain-specific explanations. Eye-tracking technology was employed to
assess their interactions. Diagnostic performance was compared with that of a
standard AI system lacking explanatory features. Our findings reveal that XAI
systems improved balanced diagnostic accuracy by 2.8 percentage points relative
to standard AI. Moreover, diagnostic disagreements with AI/XAI systems and
complex lesions were associated with elevated cognitive load, as evidenced by
increased ocular fixations. These insights have significant implications for
clinical practice, the design of AI tools for visual tasks, and the broader
development of XAI in medical diagnostics.

æè¦ï¼äººå·¥æºæ§ (AI) ç³»çµ±å·²å¤§å¹æ¹åç®èç§é«å¸«å°é»è²ç´ ç¤çè¨ºæ·æºç¢ºåº¦ï¼èå¯è§£é AI (XAI) ç³»çµ±é²ä¸æ­¥æåè¨åºé«å¸«å° AI é©åæ±ºç­çä¿¡å¿èä¿¡è³´ãåç®¡æéäºé²å±ï¼å°æ¼ç®èç§é«å¸«å¦ä½ä½¿ç¨ AI å XAI å·¥å·ï¼ä»æå®¢è§è©ä¼°çè¿«åéæ±ãå¨éé ç ç©¶ä¸­ï¼76 ä½ç®èç§é«å¸«åèäºä¸é è®èç ç©¶ï¼ä½¿ç¨ XAI ç³»çµ±è¨ºæ· 16 å¼µé»è²ç´ ç¤åç£çç®èé¡å½±åï¼è©²ç³»çµ±æä¾è©³ç´°çé åç¹å®èªªæãæ¡ç¨ç¼çè¿½è¹¤æè¡ä¾è©ä¼°ä»åçäºåãå°è¨ºæ·è¡¨ç¾èç¼ºä¹èªªæåè½çæ¨æº AI ç³»çµ±é²è¡æ¯è¼ãæåçç ç©¶çµæé¡¯ç¤ºï¼XAI ç³»çµ±ç¸è¼æ¼æ¨æº AIï¼å°å¹³è¡¡è¨ºæ·æºç¢ºåº¦æåäº 2.8 åç¾åé»ãæ­¤å¤ï¼è AI/XAI ç³»çµ±çè¨ºæ·åæ­§åè¤éççç¶èèªç¥è² æåé«æéï¼éç±å¢å çç¼çæ³¨è¦æ¬¡æ¸æè­å¯¦ãéäºè¦è§£å°è¨åºå¯¦åãè¦è¦ºä»»å AI å·¥å·çè¨­è¨åé«å­¸è¨ºæ·ä¸­ XAI çå»£æ³ç¼å±å·æéå¤§æç¾©ã

##### **Explainable AI for Autism Diagnosis: Identifying Critical Brain Regions Using fMRI Data**
2409.15374v1 by Suryansh Vidya, Kush Gupta, Amir Aly, Andy Wills, Emmanuel Ifeachor, Rohit Shankar

Early diagnosis and intervention for Autism Spectrum Disorder (ASD) has been
shown to significantly improve the quality of life of autistic individuals.
However, diagnostics methods for ASD rely on assessments based on clinical
presentation that are prone to bias and can be challenging to arrive at an
early diagnosis. There is a need for objective biomarkers of ASD which can help
improve diagnostic accuracy. Deep learning (DL) has achieved outstanding
performance in diagnosing diseases and conditions from medical imaging data.
Extensive research has been conducted on creating models that classify ASD
using resting-state functional Magnetic Resonance Imaging (fMRI) data. However,
existing models lack interpretability. This research aims to improve the
accuracy and interpretability of ASD diagnosis by creating a DL model that can
not only accurately classify ASD but also provide explainable insights into its
working. The dataset used is a preprocessed version of the Autism Brain Imaging
Data Exchange (ABIDE) with 884 samples. Our findings show a model that can
accurately classify ASD and highlight critical brain regions differing between
ASD and typical controls, with potential implications for early diagnosis and
understanding of the neural basis of ASD. These findings are validated by
studies in the literature that use different datasets and modalities,
confirming that the model actually learned characteristics of ASD and not just
the dataset. This study advances the field of explainable AI in medical imaging
by providing a robust and interpretable model, thereby contributing to a future
with objective and reliable ASD diagnostics.

æè¦ï¼èªéçè­ç³»éç¤ (ASD) çæ©æè¨ºæ·åä»å¥å·²è¢«è­å¯¦è½é¡¯èæ¹åèªéçæ£èççæ´»åè³ªãç¶èï¼ASD çè¨ºæ·æ¹æ³ä¾è³´æ¼åºæ¼è¨åºè¡¨ç¾çè©ä¼°ï¼å®¹æç¢çåè¦ï¼ä¸å¯è½é£ä»¥ååºæ©æè¨ºæ·ãæå¿è¦æ¾åº ASD çå®¢è§çç©æ¨è¨ï¼ä»¥å¹«å©æé«è¨ºæ·æºç¢ºæ§ãæ·±åº¦å­¸ç¿ (DL) å¨å¾é«å­¸å½±åè³æè¨ºæ·ç¾çåççæ¹é¢åå¾ååºçè¡¨ç¾ãå·²ç¶éå°å»ºç«ä½¿ç¨éæåè½æ§ç£æ¯é å½± (fMRI) è³æå° ASD é²è¡åé¡çæ¨¡åé²è¡å»£æ³çç ç©¶ãç¶èï¼ç¾æçæ¨¡åç¼ºä¹å¯è§£éæ§ãæ¬ç ç©¶æ¨å¨ééå»ºç«ä¸åä¸åè½æºç¢ºåé¡ ASDï¼éè½æä¾å¯è§£éè¦è§£èªªæå¶éä½åçç DL æ¨¡åï¼ä¾æ¹å ASD è¨ºæ·çæºç¢ºæ§åå¯è§£éæ§ãæä½¿ç¨çè³æéæ¯èªéçå¤§è¦å½±åè³æäº¤æ (ABIDE) çé èççæ¬ï¼åå« 884 åæ¨£æ¬ãæåçç ç©¶çµæé¡¯ç¤ºï¼è©²æ¨¡åè½æºç¢ºåé¡ ASDï¼ä¸¦å¼·èª¿ ASD èå¸åå°ç§çµä¹éå­å¨å·®ç°çééµè¦åï¼å°æ¼ ASD çæ©æè¨ºæ·åç¥ç¶åºç¤ççè§£å·ææ½å¨çæç¾©ãéäºç ç©¶çµæå·²ç±ä½¿ç¨ä¸åè³æéåæ¹å¼çæç»ç ç©¶é©è­ï¼è­å¯¦è©²æ¨¡åå¯¦éä¸å­¸ç¿äº ASD çç¹å¾µï¼èä¸ååæ¯è³æéãæ¬ç ç©¶ééæä¾ä¸åå¼·å¥ä¸å¯è§£éçæ¨¡åï¼æ¨åäºé«å­¸å½±åä¸­å¯è§£é AI çé åï¼å¾èçºæªä¾æä¾å®¢è§ä¸å¯é ç ASD è¨ºæ·ååºè²¢ç»ã

##### **Improving Prototypical Parts Abstraction for Case-Based Reasoning Explanations Designed for the Kidney Stone Type Recognition**
2409.12883v1 by Daniel Flores-Araiza, Francisco Lopez-Tiro, ClÃ©ment Larose, Salvador Hinojosa, Andres Mendez-Vazquez, Miguel Gonzalez-Mendoza, Gilberto Ochoa-Ruiz, Christian Daul

The in-vivo identification of the kidney stone types during an ureteroscopy
would be a major medical advance in urology, as it could reduce the time of the
tedious renal calculi extraction process, while diminishing infection risks.
Furthermore, such an automated procedure would make possible to prescribe
anti-recurrence treatments immediately. Nowadays, only few experienced
urologists are able to recognize the kidney stone types in the images of the
videos displayed on a screen during the endoscopy. Thus, several deep learning
(DL) models have recently been proposed to automatically recognize the kidney
stone types using ureteroscopic images. However, these DL models are of black
box nature whicl limits their applicability in clinical settings. This
contribution proposes a case-based reasoning DL model which uses prototypical
parts (PPs) and generates local and global descriptors. The PPs encode for each
class (i.e., kidney stone type) visual feature information (hue, saturation,
intensity and textures) similar to that used by biologists. The PPs are
optimally generated due a new loss function used during the model training.
Moreover, the local and global descriptors of PPs allow to explain the
decisions ("what" information, "where in the images") in an understandable way
for biologists and urologists. The proposed DL model has been tested on a
database including images of the six most widespread kidney stone types. The
overall average classification accuracy was 90.37. When comparing this results
with that of the eight other DL models of the kidney stone state-of-the-art, it
can be seen that the valuable gain in explanability was not reached at the
expense of accuracy which was even slightly increased with respect to that
(88.2) of the best method of the literature. These promising and interpretable
results also encourage urologists to put their trust in AI-based solutions.

æè¦ï¼å°¿è·¯é¡æª¢æ¥ä¸­èçµç³é¡åçé«å§è­å¥å°æ¯æ³å°¿ç§çä¸é éå¤§é²å±ï¼å çºå®å¯ä»¥æ¸å°ç¹ç£çèçµç³ååºéç¨çæéï¼åæéä½ææé¢¨éªãæ­¤å¤ï¼éç¨®èªååç¨åºå°ä½¿ç«å³éç«æå¾©ç¼æ²»çæçºå¯è½ãå¦ä»ï¼åªæå°æ¸ç¶é©è±å¯çæ³å°¿ç§é«çè½å¤ å¨å§è¦é¡æª¢æ¥æéå±å¹ä¸é¡¯ç¤ºçè¦é »ååä¸­è­å¥èçµç³é¡åãå æ­¤ï¼æè¿å·²æåºå¤ç¨®æ·±åº¦å­¸ç¿ (DL) æ¨¡åï¼ä»¥ä½¿ç¨è¼¸å°¿ç®¡é¡ååèªåè­å¥èçµç³é¡åãç¶èï¼éäº DL æ¨¡åæ¬è³ªä¸æ¯é»çå­ï¼ééå¶äºå®åå¨è¨åºç°å¢ä¸­çæç¨æ§ãæ¬ææåºäºä¸ååºæ¼æ¡ä¾æ¨çç DL æ¨¡åï¼å®ä½¿ç¨ååé¨å (PP) ä¸¦çæå±é¨åå¨å±æè¿°ç¬¦ãPP çºæ¯ç¨®é¡åï¼å³èçµç³é¡åï¼ç·¨ç¢¼è¦è¦ºç¹å¾µä¿¡æ¯ï¼è²èª¿ãé£½ååº¦ãå¼·åº¦åç´çï¼ï¼é¡ä¼¼æ¼çç©å­¸å®¶ä½¿ç¨çä¿¡æ¯ãç±æ¼å¨æ¨¡åè¨ç·´æéä½¿ç¨çæ°æå¤±å½æ¸ï¼PP å¾å°äºæä½³çæãæ­¤å¤ï¼PP çå±é¨åå¨å±æè¿°ç¬¦åè¨±ä»¥çç©å­¸å®¶åæ³å°¿ç§é«çå¯ä»¥çè§£çæ¹å¼è§£éæ±ºç­ï¼âä»éº¼âä¿¡æ¯ï¼âååä¸­çä»éº¼ä½ç½®âï¼ãææåºç DL æ¨¡åå·²å¨ä¸ååå«å­ç¨®æå»£æ³çèçµç³é¡åååçæ¸æåº«ä¸é²è¡äºæ¸¬è©¦ãç¸½é«å¹³ååé¡æºç¢ºççº 90.37ãå°æ­¤çµæèèçµç³æåé²çå«åå¶ä» DL æ¨¡åççµæé²è¡æ¯è¼æï¼å¯ä»¥çåºï¼å¯è§£éæ§çå¯¶è²´å¢çä¸¦æªä»¥æºç¢ºæ§çºä»£å¹ï¼çè³ç¥æå¢å èæç»ä¸­æå¥½çæ¹æ³ (88.2) ç¸æ¯ãéäºæå¸æä¸å¯è§£éççµæä¹é¼åµæ³å°¿ç§é«çç¸ä¿¡åºæ¼äººå·¥æºè½çè§£æ±ºæ¹æ¡ã

##### **Towards Interpretable End-Stage Renal Disease (ESRD) Prediction: Utilizing Administrative Claims Data with Explainable AI Techniques**
2409.12087v3 by Yubo Li, Saba Al-Sayouri, Rema Padman

This study explores the potential of utilizing administrative claims data,
combined with advanced machine learning and deep learning techniques, to
predict the progression of Chronic Kidney Disease (CKD) to End-Stage Renal
Disease (ESRD). We analyze a comprehensive, 10-year dataset provided by a major
health insurance organization to develop prediction models for multiple
observation windows using traditional machine learning methods such as Random
Forest and XGBoost as well as deep learning approaches such as Long Short-Term
Memory (LSTM) networks. Our findings demonstrate that the LSTM model,
particularly with a 24-month observation window, exhibits superior performance
in predicting ESRD progression, outperforming existing models in the
literature. We further apply SHapley Additive exPlanations (SHAP) analysis to
enhance interpretability, providing insights into the impact of individual
features on predictions at the individual patient level. This study underscores
the value of leveraging administrative claims data for CKD management and
predicting ESRD progression.

æè¦ï¼æ¬ç ç©¶æ¢è¨å©ç¨è¡æ¿ç³å ±è³æï¼çµååé²æ©å¨å­¸ç¿èæ·±åº¦å­¸ç¿æè¡ï¼é æ¸¬æ¢æ§èèç (CKD) é²å±è³æ«æèèç¾ç (ESRD) çå¯è½æ§ãæååæä¸å®¶å¤§åå¥åº·ä¿éªçµç¹æä¾ç 10 å¹´ç¶åè³æéï¼ä½¿ç¨å³çµ±æ©å¨å­¸ç¿æ¹æ³ï¼ä¾å¦é¨æ©æ£®æå XGBoostï¼ä»¥åæ·±åº¦å­¸ç¿æ¹æ³ï¼ä¾å¦é·æç­æè¨æ¶ (LSTM) ç¶²è·¯ï¼éç¼å¤åè§å¯è¦çªçé æ¸¬æ¨¡åãæåçç ç©¶çµæé¡¯ç¤ºï¼LSTM æ¨¡åï¼å°¤å¶æ¯ 24 åæè§å¯è¦çªï¼å¨é æ¸¬ ESRD é²å±æ¹é¢è¡¨ç¾åªç°ï¼åªæ¼æç»ä¸­çç¾ææ¨¡åãæåé²ä¸æ­¥æç¨ SHapley å¯å æ§è§£é (SHAP) åæä»¥å¢å¼·å¯è§£éæ§ï¼æ·±å¥äºè§£åå¥ç¹å¾µå°åå¥æ£èå±¤ç´é æ¸¬çå½±é¿ãæ¬ç ç©¶å¼·èª¿äºå©ç¨è¡æ¿ç³å ±è³æé²è¡ CKD ç®¡çåé æ¸¬ ESRD é²å±çå¹å¼ã

##### **Explainable AI: Definition and attributes of a good explanation for health AI**
2409.15338v1 by Evangelia Kyrimi, Scott McLachlan, Jared M Wohlgemut, Zane B Perkins, David A. Lagnado, William Marsh, the ExAIDSS Expert Group

Proposals of artificial intelligence (AI) solutions based on increasingly
complex and accurate predictive models are becoming ubiquitous across many
disciplines. As the complexity of these models grows, transparency and users'
understanding often diminish. This suggests that accurate prediction alone is
insufficient for making an AI-based solution truly useful. In the development
of healthcare systems, this introduces new issues related to accountability and
safety. Understanding how and why an AI system makes a recommendation may
require complex explanations of its inner workings and reasoning processes.
Although research on explainable AI (XAI) has significantly increased in recent
years and there is high demand for XAI in medicine, defining what constitutes a
good explanation remains ad hoc, and providing adequate explanations continues
to be challenging. To fully realize the potential of AI, it is critical to
address two fundamental questions about explanations for safety-critical AI
applications, such as health-AI: (1) What is an explanation in health-AI? and
(2) What are the attributes of a good explanation in health-AI? In this study,
we examined published literature and gathered expert opinions through a
two-round Delphi study. The research outputs include (1) a definition of what
constitutes an explanation in health-AI and (2) a comprehensive list of
attributes that characterize a good explanation in health-AI.

æè¦ï¼é¨èè¶ä¾è¶è¤éä¸æºç¢ºçé æ¸¬æ¨¡åï¼åºæ¼äººå·¥æºæ§ (AI) è§£æ±ºæ¹æ¡çææ¡å¨è¨±å¤é åä¸­è®å¾ç¡èä¸å¨ãé¨èéäºæ¨¡åè¤éæ§çå¢å ï¼éæåº¦åä½¿ç¨èççè§£åå¾å¾æéä½ãéè¡¨ç¤ºåææºç¢ºçé æ¸¬ä¸¦ä¸è¶³ä»¥è® AI è§£æ±ºæ¹æ¡çæ­£æç¨ãå¨é«çä¿å¥ç³»çµ±çéç¼ä¸­ï¼éå¼å¥äºèåè²¬å¶åå®å¨æ§ç¸éçæ°åé¡ãç­è§£ AI ç³»çµ±å¦ä½ä»¥åçºä½æåºå»ºè­°å¯è½éè¦å°å¶å§é¨éä½åæ¨çéç¨é²è¡è¤éçèªªæãåç®¡è¿å¹´ä¾å°å¯è§£é AI (XAI) çç ç©¶å·²å¤§å¹å¢å ï¼ä¸é«å­¸é åå° XAI æå¾é«çéæ±ï¼ä½å®ç¾©ä»éº¼æ§æä¸åå¥½çè§£éä»æ¯è¨ææ§çï¼èæä¾é©ç¶çè§£éä»ç¶å·æææ°æ§ãçºäºååç¼æ® AI çæ½åï¼å°æ¼å®å¨ééµå AI æç¨ï¼ä¾å¦å¥åº· AIï¼çè§£éï¼æ¢è¨å©ååºæ¬åé¡è³ééè¦ï¼(1) ä»éº¼æ¯å¥åº· AI ä¸­çè§£éï¼ä»¥å (2) å¥åº· AI ä¸­ä¸åå¥½çè§£éæåªäºå±¬æ§ï¼å¨æ¬ç ç©¶ä¸­ï¼æåæª¢è¦äºå·²ç¼è¡¨çæç»ï¼ä¸¦ééå©è¼ªå¾·ç¾è²ç ç©¶æ¶éäºå°å®¶æè¦ãç ç©¶ææåæ¬ï¼(1) å¥åº· AI ä¸­ä»éº¼æ§æè§£éçå®ç¾©ï¼ä»¥å (2) å¥åº· AI ä¸­ä¸åå¥½è§£éçå±¬æ§æ¸å®ã

##### **Exploring the Effect of Explanation Content and Format on User Comprehension and Trust**
2408.17401v1 by Antonio Rago, Bence Palfi, Purin Sukpanichnant, Hannibal Nabli, Kavyesh Vivek, Olga Kostopoulou, James Kinross, Francesca Toni

In recent years, various methods have been introduced for explaining the
outputs of "black-box" AI models. However, it is not well understood whether
users actually comprehend and trust these explanations. In this paper, we focus
on explanations for a regression tool for assessing cancer risk and examine the
effect of the explanations' content and format on the user-centric metrics of
comprehension and trust. Regarding content, we experiment with two explanation
methods: the popular SHAP, based on game-theoretic notions and thus potentially
complex for everyday users to comprehend, and occlusion-1, based on feature
occlusion which may be more comprehensible. Regarding format, we present SHAP
explanations as charts (SC), as is conventional, and occlusion-1 explanations
as charts (OC) as well as text (OT), to which their simpler nature also lends
itself. The experiments amount to user studies questioning participants, with
two different levels of expertise (the general population and those with some
medical training), on their subjective and objective comprehension of and trust
in explanations for the outputs of the regression tool. In both studies we
found a clear preference in terms of subjective comprehension and trust for
occlusion-1 over SHAP explanations in general, when comparing based on content.
However, direct comparisons of explanations when controlling for format only
revealed evidence for OT over SC explanations in most cases, suggesting that
the dominance of occlusion-1 over SHAP explanations may be driven by a
preference for text over charts as explanations. Finally, we found no evidence
of a difference between the explanation types in terms of objective
comprehension. Thus overall, the choice of the content and format of
explanations needs careful attention, since in some contexts format, rather
than content, may play the critical role in improving user experience.

æè¦ï¼<paragraph>è¿å¹´ä¾ï¼å·²ç¶å¼é²åç¨®æ¹æ³ä¾è§£éãé»ç®±ãAI æ¨¡åçè¼¸åºãç¶èï¼ç®åä¸¦ä¸æ¸æ¥ä½¿ç¨èæ¯å¦å¯¦éçè§£åä¿¡ä»»éäºè§£éãå¨æ¬æä¸­ï¼æåå°æ³¨æ¼è©ä¼°ççé¢¨éªçåæ­¸å·¥å·çè§£éï¼ä¸¦æ¢è¨è§£éçå§å®¹åæ ¼å¼å°ä»¥ä½¿ç¨èçºä¸­å¿ççè§£åä¿¡ä»»ææ¨çå½±é¿ãéæ¼å§å®¹ï¼æåå¯¦é©äºå©ç¨®è§£éæ¹æ³ï¼æµè¡ç SHAPï¼åºæ¼åå¼è«æ¦å¿µï¼å æ­¤å°æ¼æ¥å¸¸ä½¿ç¨èä¾èªªå¯è½å¾è¤éï¼ä»¥ååºæ¼ç¹å¾µé®è½ç occlusion-1ï¼å¯è½æ´ææ¼çè§£ãéæ¼æ ¼å¼ï¼æåå° SHAP è§£éåç¾çºåè¡¨ (SC)ï¼éæ¯æ£ä¾ï¼èå° occlusion-1 è§£éåç¾çºåè¡¨ (OC) ä»¥åæå­ (OT)ï¼å¶è¼çºç°¡å®çæ§è³ªä¹é©ç¨æ¼æ­¤ãéäºå¯¦é©ç­åæ¼ä½¿ç¨èç ç©¶ï¼è©¢ååèèï¼å·æå©ç¨®ä¸åç¨åº¦çå°æ¥­ç¥è­ï¼ä¸è¬æ°ç¾åå·åä¸äºé«å­¸è¨ç·´çäººï¼ï¼ä»åå°åæ­¸å·¥å·è¼¸åºè§£éçä¸»è§åå®¢è§çè§£åä¿¡ä»»ãå¨å©é ç ç©¶ä¸­ï¼æåç¼ç¾ï¼å¨åºæ¼å§å®¹é²è¡æ¯è¼æï¼ä¸è¬ä¾èªªï¼occlusion-1 åªæ¼ SHAP è§£éï¼å¨ä¸»è§çè§£åä¿¡ä»»æ¹é¢ææé¡¯çåå¥½ãç¶èï¼å¨åæ§å¶æ ¼å¼çææ³ä¸ç´æ¥æ¯è¼è§£éï¼å¨å¤§å¤æ¸ææ³ä¸åªé¡¯ç¤º OT åªæ¼ SC è§£éçè­æï¼éè¡¨æ occlusion-1 åªæ¼ SHAP è§£éçä¸»å°å°ä½å¯è½æ¯ç±åå¥½æå­èéåè¡¨ä½çºè§£éæé©åçãæå¾ï¼æåæ²æç¼ç¾è§£éé¡åå¨å®¢è§çè§£æ¹é¢çå·®ç°è­æãå æ­¤ï¼ç¸½é«èè¨ï¼å°è§£éçå§å®¹åæ ¼å¼çé¸æéè¦ä»ç´°æ³¨æï¼å çºå¨æäºææ³ä¸ï¼æ ¼å¼èéå§å®¹ï¼å¯è½å¨æ¹åä½¿ç¨èé«é©æ¹é¢ç¼æ®ééµä½ç¨ã</paragraph>

##### **A Survey for Large Language Models in Biomedicine**
2409.00133v1 by Chong Wang, Mengyao Li, Junjun He, Zhongruo Wang, Erfan Darzi, Zan Chen, Jin Ye, Tianbin Li, Yanzhou Su, Jing Ke, Kaili Qu, Shuxin Li, Yi Yu, Pietro LiÃ², Tianyun Wang, Yu Guang Wang, Yiqing Shen

Recent breakthroughs in large language models (LLMs) offer unprecedented
natural language understanding and generation capabilities. However, existing
surveys on LLMs in biomedicine often focus on specific applications or model
architectures, lacking a comprehensive analysis that integrates the latest
advancements across various biomedical domains. This review, based on an
analysis of 484 publications sourced from databases including PubMed, Web of
Science, and arXiv, provides an in-depth examination of the current landscape,
applications, challenges, and prospects of LLMs in biomedicine, distinguishing
itself by focusing on the practical implications of these models in real-world
biomedical contexts. Firstly, we explore the capabilities of LLMs in zero-shot
learning across a broad spectrum of biomedical tasks, including diagnostic
assistance, drug discovery, and personalized medicine, among others, with
insights drawn from 137 key studies. Then, we discuss adaptation strategies of
LLMs, including fine-tuning methods for both uni-modal and multi-modal LLMs to
enhance their performance in specialized biomedical contexts where zero-shot
fails to achieve, such as medical question answering and efficient processing
of biomedical literature. Finally, we discuss the challenges that LLMs face in
the biomedicine domain including data privacy concerns, limited model
interpretability, issues with dataset quality, and ethics due to the sensitive
nature of biomedical data, the need for highly reliable model outputs, and the
ethical implications of deploying AI in healthcare. To address these
challenges, we also identify future research directions of LLM in biomedicine
including federated learning methods to preserve data privacy and integrating
explainable AI methodologies to enhance the transparency of LLMs.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) çææ°çªç ´æä¾äºåææªæçèªç¶èªè¨çè§£åçæè½åãç¶èï¼ç¾æéæ¼çç©é«å­¸ä¸­ LLM çèª¿æ¥éå¸¸å°æ³¨æ¼ç¹å®æç¨ææ¨¡åæ¶æ§ï¼ç¼ºä¹æ´ååç¨®çç©é«å­¸é åææ°é²å±çå¨é¢åæãæ¬ç¶è¿°åºæ¼å°ä¾èª PubMedãWeb of Science å arXiv ç­æ¸æåº«ç 484 ç¯åºçç©çåæï¼æ·±å¥æ¢è¨äºçç©é«å­¸ä¸­ LLM çç¶åç¾æ³ãæç¨ãææ°ååæ¯ï¼å¶ç¹é»æ¯éæ³¨éäºæ¨¡åå¨ç¾å¯¦ä¸ççç©é«å­¸èæ¯ä¸­çå¯¦éæç¨ãé¦åï¼æåæ¢è¨äº LLM å¨å»£æ³ççç©é«å­¸ä»»åä¸­çé¶æ¬¡å­¸ç¿è½åï¼åæ¬è¨ºæ·è¼å©ãè¥ç©ç¼ç¾ååæ§åé«çç­ï¼ä¸¦å¾ 137 é ééµç ç©¶ä¸­æ±²åè¦è§£ãç¶å¾ï¼æåè¨è«äº LLM çé©æç­ç¥ï¼åæ¬å®æ¨¡æåå¤æ¨¡æ LLM çå¾®èª¿æ¹æ³ï¼ä»¥å¢å¼·å®åå¨é¶æ¬¡å­¸ç¿ç¡æ³å¯¦ç¾çå°æ¥­çç©é«å­¸èæ¯ä¸­çæ§è½ï¼ä¾å¦é«çåé¡è§£ç­åçç©é«å­¸æç»çææèçãæå¾ï¼æåè¨è«äº LLM å¨çç©é«å­¸é åé¢è¨çææ°ï¼åæ¬æ¸æé±ç§åé¡ãæ¨¡åå¯è§£éæ§æéãæ¸æéè³ªéåé¡ä»¥åç±æ¼çç©é«å­¸æ¸æçæææ§ãå°é«åº¦å¯é æ¨¡åè¼¸åºçéæ±ä»¥åå¨é«çä¿å¥ä¸­é¨ç½² AI çå«çå½±é¿èç¢ççå«çåé¡ãçºäºæå°éäºææ°ï¼æåéç¢ºå®äºçç©é«å­¸ä¸­ LLM æªä¾çç ç©¶æ¹åï¼åæ¬ç¨æ¼ä¿è­·æ¸æé±ç§çè¯åå­¸ç¿æ¹æ³ä»¥åæ´åå¯è§£é AI æ¹æ³ä»¥å¢å¼· LLM çéæåº¦ã

##### **Aligning XAI with EU Regulations for Smart Biomedical Devices: A Methodology for Compliance Analysis**
2408.15121v1 by Francesco Sovrano, Michael Lognoul, Giulia Vilone

Significant investment and development have gone into integrating Artificial
Intelligence (AI) in medical and healthcare applications, leading to advanced
control systems in medical technology. However, the opacity of AI systems
raises concerns about essential characteristics needed in such sensitive
applications, like transparency and trustworthiness. Our study addresses these
concerns by investigating a process for selecting the most adequate Explainable
AI (XAI) methods to comply with the explanation requirements of key EU
regulations in the context of smart bioelectronics for medical devices. The
adopted methodology starts with categorising smart devices by their control
mechanisms (open-loop, closed-loop, and semi-closed-loop systems) and delving
into their technology. Then, we analyse these regulations to define their
explainability requirements for the various devices and related goals.
Simultaneously, we classify XAI methods by their explanatory objectives. This
allows for matching legal explainability requirements with XAI explanatory
goals and determining the suitable XAI algorithms for achieving them. Our
findings provide a nuanced understanding of which XAI algorithms align better
with EU regulations for different types of medical devices. We demonstrate this
through practical case studies on different neural implants, from chronic
disease management to advanced prosthetics. This study fills a crucial gap in
aligning XAI applications in bioelectronics with stringent provisions of EU
regulations. It provides a practical framework for developers and researchers,
ensuring their AI innovations advance healthcare technology and adhere to legal
and ethical standards.

æè¦ï¼äººå·¥æºæ§ï¼AIï¼å¨é«çåä¿å¥æç¨ä¸­æå¥äºå¤§éçæè³åéç¼ï¼é²èå°è´é«çæè¡ä¸­çåé²æ§å¶ç³»çµ±ãç¶èï¼AI ç³»çµ±çä¸éææ§å¼ç¼äºå°æ­¤é¡æææç¨ä¸­æéåºæ¬ç¹æ§çææï¼ä¾å¦éæåº¦åå¯ä¿¡åº¦ãæåçç ç©¶ééèª¿æ¥ä¸åç¨åºä¾è§£æ±ºéäºåé¡ï¼ç¨æ¼é¸ææååçå¯è§£é AIï¼XAIï¼æ¹æ³ï¼ä»¥ç¬¦åæ­çæ³è¦å¨é«çå¨æçæºæ§åçç©é»å­å­¸ä¸­çèªªæè¦æ±ãæ¡ç¨çæ¹æ³å¾ééå¶æ§å¶æ©å¶ï¼éè¿´è·¯ãéè¿´è·¯ååéè¿´è·¯ç³»çµ±ï¼å°æºæ§åè£ç½®é²è¡åé¡ï¼ä¸¦æ·±å¥æ¢è¨å¶æè¡éå§ãç¶å¾ï¼æååæéäºæ³è¦ä»¥å®ç¾©å¶å°åç¨®è£ç½®åç¸éç®æ¨çå¯è§£éæ§è¦æ±ãåæï¼æåééå¶èªªæç®æ¨å° XAI æ¹æ³é²è¡åé¡ãéåè¨±å°æ³å¾å¯è§£éæ§è¦æ±è XAI èªªæç®æ¨ç¸å¹éï¼ä¸¦ç¢ºå®é©ç¶ç XAI æ¼ç®æ³ä¾éæå®åãæåçç ç©¶çµææä¾äºå°åªäº XAI æ¼ç®æ³æ´ç¬¦åæ­çæ³è¦ä»¥é©ç¨æ¼ä¸åé¡åçé«çå¨æçç´°ç·»çè§£ãæåééä¸åç¥ç¶æ¤å¥ç©çå¯¦éæ¡ä¾ç ç©¶ä¾è­æéä¸é»ï¼å¾æ¢æ§ç¾çç®¡çå°åé²çç¾©è¢ãéé ç ç©¶å¡«è£äºå°çç©é»å­å­¸ä¸­ç XAI æç¨èæ­çæ³è¦çå´æ ¼è¦å®ç¸ç¬¦çéè¦ç©ºç½ãå®çºéç¼äººå¡åç ç©¶äººå¡æä¾äºä¸åå¯¦ç¨çæ¶æ§ï¼ç¢ºä¿å¶ AI åµæ°è½ä¿é²é«çæè¡ä¸¦éµå®æ³å¾åéå¾·æ¨æºã

##### **Towards Case-based Interpretability for Medical Federated Learning**
2408.13626v1 by Laura Latorre, Liliana Petrychenko, Regina Beets-Tan, Taisiya Kopytova, Wilson Silva

We explore deep generative models to generate case-based explanations in a
medical federated learning setting. Explaining AI model decisions through
case-based interpretability is paramount to increasing trust and allowing
widespread adoption of AI in clinical practice. However, medical AI training
paradigms are shifting towards federated learning settings in order to comply
with data protection regulations. In a federated scenario, past data is
inaccessible to the current user. Thus, we use a deep generative model to
generate synthetic examples that protect privacy and explain decisions. Our
proof-of-concept focuses on pleural effusion diagnosis and uses publicly
available Chest X-ray data.

æè¦ï¼æåæ¢ç´¢æ·±åº¦çææ¨¡åï¼å¨é«çè¯é¦å­¸ç¿è¨­ç½®ä¸­çæåºæ¼æ¡ä¾çèªªæãééåºæ¼æ¡ä¾çå¯è§£éæ§ä¾è§£é AI æ¨¡åæ±ºç­ï¼å°æ¼å¢å ä¿¡ä»»ä¸¦åè¨± AI å¨è¨åºå¯¦åä¸­å»£æ³æ¡ç¨è³ééè¦ãç¶èï¼é«ç AI è¨ç·´ç¯ä¾æ­£è½åè¯é¦å­¸ç¿è¨­ç½®ï¼ä»¥ç¬¦åè³æä¿è­·æ³è¦ãå¨è¯é¦æå¢ä¸­ï¼éå»çè³æå°ç®åçä½¿ç¨èèè¨æ¯ç¡æ³åå¾çãå æ­¤ï¼æåä½¿ç¨æ·±åº¦çææ¨¡åä¾ç¢çä¿è­·é±ç§åè§£éæ±ºç­çåæç¯ä¾ãæåçæ¦å¿µé©è­èéæ¼è¸èç©æ¶²è¨ºæ·ï¼ä¸¦ä½¿ç¨å¬éå¯åå¾çè¸é¨ X åè³æã

##### **AI in radiological imaging of soft-tissue and bone tumours: a systematic review evaluating against CLAIM and FUTURE-AI guidelines**
2408.12491v1 by Douwe J. Spaanderman, Matthew Marzetti, Xinyi Wan, Andrew F. Scarsbrook, Philip Robinson, Edwin H. G. Oei, Jacob J. Visser, Robert Hemke, Kirsten van Langevelde, David F. Hanff, Geert J. L. H. van Leenders, Cornelis Verhoef, Dirk J. GruÃ¼hagen, Wiro J. Niessen, Stefan Klein, Martijn P. A. Starmans

Soft-tissue and bone tumours (STBT) are rare, diagnostically challenging
lesions with variable clinical behaviours and treatment approaches. This
systematic review provides an overview of Artificial Intelligence (AI) methods
using radiological imaging for diagnosis and prognosis of these tumours,
highlighting challenges in clinical translation, and evaluating study alignment
with the Checklist for AI in Medical Imaging (CLAIM) and the FUTURE-AI
international consensus guidelines for trustworthy and deployable AI to promote
the clinical translation of AI methods. The review covered literature from
several bibliographic databases, including papers published before 17/07/2024.
Original research in peer-reviewed journals focused on radiology-based AI for
diagnosing or prognosing primary STBT was included. Exclusion criteria were
animal, cadaveric, or laboratory studies, and non-English papers. Abstracts
were screened by two of three independent reviewers for eligibility. Eligible
papers were assessed against guidelines by one of three independent reviewers.
The search identified 15,015 abstracts, from which 325 articles were included
for evaluation. Most studies performed moderately on CLAIM, averaging a score
of 28.9$\pm$7.5 out of 53, but poorly on FUTURE-AI, averaging 5.1$\pm$2.1 out
of 30. Imaging-AI tools for STBT remain at the proof-of-concept stage,
indicating significant room for improvement. Future efforts by AI developers
should focus on design (e.g. define unmet clinical need, intended clinical
setting and how AI would be integrated in clinical workflow), development (e.g.
build on previous work, explainability), evaluation (e.g. evaluating and
addressing biases, evaluating AI against best practices), and data
reproducibility and availability (making documented code and data publicly
available). Following these recommendations could improve clinical translation
of AI methods.

æè¦ï¼è»çµç¹åéª¨éª¼è«ç¤ï¼STBTï¼æ¯ç½è¦ãè¨ºæ·å·æææ°æ§ççç¶ï¼å¶è¨åºè¡çºåæ²»çæ¹æ³åä¸ç¸åãéç¯ç³»çµ±æ§åé¡§æä¾äºä½¿ç¨æ¾å°å½±åé²è¡è¨ºæ·åé å¾çäººå·¥æºæ§ (AI) æ¹æ³çæ¦è§ï¼éé»èªªæäºè¨åºè½è­¯çææ°ï¼ä¸¦è©ä¼°ç ç©¶èé«çå½±å AI æ ¸æ¥è¡¨ (CLAIM) å FUTURE-AI å¯ä¿¡è³´ä¸å¯é¨ç½² AI çåéå±è­æºåçä¸è´æ§ï¼ä»¥ä¿é² AI æ¹æ³çè¨åºè½è­¯ãéç¯åé¡§æ¶µèäºå¹¾åæ¸ç®è³æåº«ä¸­çæç»ï¼åæ¬å¨ 2024 å¹´ 7 æ 17 æ¥ä¹åç¼è¡¨çè«æãç´å¥äºä»¥æ¾å°çºåºç¤ç AI è¨ºæ·æé å¾åç¼æ§ STBT çåè¡è©å¯©æåä¸­çåå§ç ç©¶ãæé¤æ¨æºæ¯åç©ãå±é«æå¯¦é©å®¤ç ç©¶ï¼ä»¥åéè±æè«æãæè¦ç±ä¸ä½ç¨ç«å¯©æ¥å¡ä¸­çå©ä½ç¯©é¸è³æ ¼ãåæ ¼çè«æç±ä¸ä½ç¨ç«å¯©æ¥å¡ä¸­çä¸ä½æ ¹ææºåé²è¡è©ä¼°ãæç´¢è­å¥åº 15,015 ç¯æè¦ï¼å¶ä¸­ 325 ç¯æç« è¢«ç´å¥è©ä¼°ãå¤§å¤æ¸ç ç©¶å¨ CLAIM ä¸­è¡¨ç¾ä¸­ç­ï¼å¹³åå¾åçº 53 åä¸­ç 28.9Â±7.5 åï¼ä½å¨ FUTURE-AI ä¸­è¡¨ç¾ä¸ä½³ï¼å¹³åå¾åçº 30 åä¸­ç 5.1Â±2.1 åãSTBT çå½±å AI å·¥å·ä»èæ¼æ¦å¿µé©è­éæ®µï¼è¡¨ææé¡¯èçæ¹é²ç©ºéãAI éç¼äººå¡æªä¾çåªåæéä¸­å¨è¨­è¨ï¼ä¾å¦å®ç¾©æªæ»¿è¶³çè¨åºéæ±ãé æçè¨åºç°å¢ä»¥å AI å¦ä½æ´åå°è¨åºå·¥ä½æµç¨ä¸­ï¼ãéç¼ï¼ä¾å¦å»ºç«å¨ååçå·¥ä½ãå¯è§£éæ§ï¼ãè©ä¼°ï¼ä¾å¦è©ä¼°åè§£æ±ºåå·®ãè©ä¼° AI èæä½³å¯¦åï¼ãä»¥åæ¸æå¯è¤è£½æ§åå¯ç¨æ§ï¼å¬éæä¾æä»¶åçä»£ç¢¼åæ¸æï¼ãéµå¾ªéäºå»ºè­°å¯ä»¥æ¹å AI æ¹æ³çè¨åºè½è­¯ã

##### **Evaluating Explainable AI Methods in Deep Learning Models for Early Detection of Cerebral Palsy**
2409.00001v1 by Kimji N. Pellano, Inga StrÃ¼mke, Daniel Groos, Lars Adde, Espen Alexander F. Ihlen

Early detection of Cerebral Palsy (CP) is crucial for effective intervention
and monitoring. This paper tests the reliability and applicability of
Explainable AI (XAI) methods using a deep learning method that predicts CP by
analyzing skeletal data extracted from video recordings of infant movements.
Specifically, we use XAI evaluation metrics -- namely faithfulness and
stability -- to quantitatively assess the reliability of Class Activation
Mapping (CAM) and Gradient-weighted Class Activation Mapping (Grad-CAM) in this
specific medical application. We utilize a unique dataset of infant movements
and apply skeleton data perturbations without distorting the original dynamics
of the infant movements. Our CP prediction model utilizes an ensemble approach,
so we evaluate the XAI metrics performances for both the overall ensemble and
the individual models. Our findings indicate that both XAI methods effectively
identify key body points influencing CP predictions and that the explanations
are robust against minor data perturbations. Grad-CAM significantly outperforms
CAM in the RISv metric, which measures stability in terms of velocity. In
contrast, CAM performs better in the RISb metric, which relates to bone
stability, and the RRS metric, which assesses internal representation
robustness. Individual models within the ensemble show varied results, and
neither CAM nor Grad-CAM consistently outperform the other, with the ensemble
approach providing a representation of outcomes from its constituent models.

æè¦ï¼è¦æ§éº»çº (CP) çæ©æåµæ¸¬å°æ¼ææçä»å¥åç£æ¸¬è³ééè¦ãæ¬ææ¸¬è©¦äºå¯è§£é AI (XAI) æ¹æ³çå¯é æ§åé©ç¨æ§ï¼ä½¿ç¨æ·±åº¦å­¸ç¿æ¹æ³ï¼ééåæå¾å¬°ååä½å½±çè¨éä¸­æåçéª¨éª¼è³æä¾é æ¸¬ CPãå·é«ä¾èªªï¼æåä½¿ç¨ XAI è©ä¼°ææ¨ï¼å³å¿ å¯¦åº¦åç©©å®æ§ï¼ä¾éåè©ä¼°é¡å¥æ¿æ´»æ å° (CAM) åæ¢¯åº¦å æ¬é¡å¥æ¿æ´»æ å° (Grad-CAM) å¨éåç¹å®é«çæç¨ä¸­çå¯é æ§ãæåå©ç¨ä¸åç¨ç¹çå¬°ååä½è³æéï¼ä¸¦æç¨éª¨éª¼è³ææ¾åï¼èä¸ææ­æ²å¬°ååä½çåå§ååãæåç CP é æ¸¬æ¨¡åå©ç¨æ´é«æ¹æ³ï¼å æ­¤æåè©ä¼°äºæ´é«æ´é«ååå¥æ¨¡åç XAI ææ¨è¡¨ç¾ãæåçç ç©¶çµæè¡¨æï¼å©ç¨® XAI æ¹æ³é½è½ææè­å¥å½±é¿ CP é æ¸¬çééµèº«é«é¨ä½ï¼ä¸¦ä¸éäºè§£éå°æ¼å¾®å°çè³ææ¾åå·æé­¯æ£æ§ãGrad-CAM å¨ RISv ææ¨ä¸­é¡¯èåªæ¼ CAMï¼è©²ææ¨è¡¡ééåº¦æ¹é¢çç©©å®æ§ãç¸æ¯ä¹ä¸ï¼CAM å¨ RISb ææ¨ä¸­è¡¨ç¾å¾æ´å¥½ï¼è©²ææ¨èéª¨éª¼ç©©å®æ§æéï¼è RRS ææ¨åè©ä¼°å§é¨è¡¨ç¤ºçé­¯æ£æ§ãæ´é«ä¸­çåå¥æ¨¡åé¡¯ç¤ºåºä¸åççµæï¼CAM å Grad-CAM é½ä¸ä¸è´å°åªæ¼å¦ä¸ç¨®ï¼æ´é«æ¹æ³æä¾äºå¶çµææ¨¡åçµæçè¡¨ç¤ºã

##### **MicroXercise: A Micro-Level Comparative and Explainable System for Remote Physical Therapy**
2408.11837v1 by Hanchen David Wang, Nibraas Khan, Anna Chen, Nilanjan Sarkar, Pamela Wisniewski, Meiyi Ma

Recent global estimates suggest that as many as 2.41 billion individuals have
health conditions that would benefit from rehabilitation services. Home-based
Physical Therapy (PT) faces significant challenges in providing interactive
feedback and meaningful observation for therapists and patients. To fill this
gap, we present MicroXercise, which integrates micro-motion analysis with
wearable sensors, providing therapists and patients with a comprehensive
feedback interface, including video, text, and scores. Crucially, it employs
multi-dimensional Dynamic Time Warping (DTW) and attribution-based explainable
methods to analyze the existing deep learning neural networks in monitoring
exercises, focusing on a high granularity of exercise. This synergistic
approach is pivotal, providing output matching the input size to precisely
highlight critical subtleties and movements in PT, thus transforming complex AI
analysis into clear, actionable feedback. By highlighting these micro-motions
in different metrics, such as stability and range of motion, MicroXercise
significantly enhances the understanding and relevance of feedback for
end-users. Comparative performance metrics underscore its effectiveness over
traditional methods, such as a 39% and 42% improvement in Feature Mutual
Information (FMI) and Continuity. MicroXercise is a step ahead in home-based
physical therapy, providing a technologically advanced and intuitively helpful
solution to enhance patient care and outcomes.

æè¦ï¼æè¿çå¨çä¼°è¨è¡¨æï¼å¤é 24.1 åäººæ
å¥åº·çæ³å¯å¾å¾©å¥æåä¸­åçãå±å®¶
ç©çæ²»ç (PT) å¨æä¾äºåå¼
åé¥åææç¾©çè§å¯æ¹é¢é¢è¨éå¤§ææ°ï¼ä¾æ²»çå¸«åæ£èä½¿ç¨ãçºäºå¡«è£é
åç¼ºå£ï¼æåæåº MicroXerciseï¼å®å°å¾®åä½åæè
å¯ç©¿æ´å¼ææ¸¬å¨æ´åå¨ä¸èµ·ï¼çºæ²»çå¸«åæ£èæä¾ä¸åå¨é¢ç
åé¥ä»é¢ï¼åæ¬å½±çãæå­ååæ¸ãè³ééè¦çæ¯ï¼å®æ¡ç¨
å¤ç¶­åææéè¦æ´ (DTW) ååºæ¼æ­¸å çå¯è§£é
æ¹æ³ä¾åæç£æ§éåä¸­ç¾æçæ·±åº¦å­¸ç¿ç¥ç¶ç¶²è·¯ï¼å°æ³¨æ¼éåçé«ç²åº¦ãéç¨®åå
æ¹æ³è³ééè¦ï¼æä¾èè¼¸å¥å¤§å°å¹éçè¼¸åºï¼ä»¥ç²¾ç¢ºå°
çªåº PT ä¸­ééµçç´°å¾®å·®å¥ååä½ï¼å¾èå°è¤éç AI
åæè½æçºæ¸æ°ãå¯æä½çåé¥ãééå¨ä¸åææ¨ä¸­çªé¡¯éäºå¾®åä½ï¼ä¾å¦ç©©å®æ§ååä½ç¯åï¼MicroXercise
é¡¯èæåæçµä½¿ç¨èå°åé¥ççè§£åç¸éæ§ãæ¯è¼æè½ææ¨å¼·èª¿å¶åªæ¼
å³çµ±æ¹æ³çæææ§ï¼ä¾å¦ç¹å¾µäºæ è³è¨ (FMI) åé£çºæ§åå¥æåäº 39% å 42%ãMicroXercise å¨å±å®¶
ç©çæ²»çæ¹é¢æ´é²ä¸æ­¥ï¼æä¾æè¡åé²ä¸ç´è¦ºæç¨ç
è§£æ±ºæ¹æ¡ï¼ä»¥æåæ£èç§è­·åçµæã

##### **The Literature Review Network: An Explainable Artificial Intelligence for Systematic Literature Reviews, Meta-analyses, and Method Development**
2408.05239v1 by Joshua Morriss, Tod Brindle, Jessica Bah RÃ¶sman, Daniel Reibsamen, Andreas Enz

Systematic literature reviews are the highest quality of evidence in
research. However, the review process is hindered by significant resource and
data constraints. The Literature Review Network (LRN) is the first of its kind
explainable AI platform adhering to PRISMA 2020 standards, designed to automate
the entire literature review process. LRN was evaluated in the domain of
surgical glove practices using 3 search strings developed by experts to query
PubMed. A non-expert trained all LRN models. Performance was benchmarked
against an expert manual review. Explainability and performance metrics
assessed LRN's ability to replicate the experts' review. Concordance was
measured with the Jaccard index and confusion matrices. Researchers were
blinded to the other's results until study completion. Overlapping studies were
integrated into an LRN-generated systematic review. LRN models demonstrated
superior classification accuracy without expert training, achieving 84.78% and
85.71% accuracy. The highest performance model achieved high interrater
reliability (k = 0.4953) and explainability metrics, linking 'reduce',
'accident', and 'sharp' with 'double-gloving'. Another LRN model covered 91.51%
of the relevant literature despite diverging from the non-expert's judgments (k
= 0.2174), with the terms 'latex', 'double' (gloves), and 'indication'. LRN
outperformed the manual review (19,920 minutes over 11 months), reducing the
entire process to 288.6 minutes over 5 days. This study demonstrates that
explainable AI does not require expert training to successfully conduct
PRISMA-compliant systematic literature reviews like an expert. LRN summarized
the results of surgical glove studies and identified themes that were nearly
identical to the clinical researchers' findings. Explainable AI can accurately
expedite our understanding of clinical practices, potentially revolutionizing
healthcare research.

æè¦ï¼ç³»çµ±æ§æç»åé¡§æ¯ç ç©¶ä¸­è­æåè³ªæé«çãç¶èï¼åé¡§éç¨åå°é¡¯èè³æºåè³æéå¶çé»ç¤ãæç»åé¡§ç¶²è·¯ (LRN) æ¯ç¬¬ä¸åéµå¾ª PRISMA 2020 æ¨æºçå¯è§£é AI å¹³å°ï¼æ¨å¨èªååæ´åæç»åé¡§éç¨ãLRN å¨å¤ç§æå¥å¯¦åé åä¸­é²è¡è©ä¼°ï¼ä½¿ç¨å°å®¶éç¼ç 3 åæå°å­ä¸²ä¾æ¥è©¢ PubMedãéå°å®¶è¨ç·´ææ LRN æ¨¡åãæè½ä»¥å°å®¶æååé¡§ä½çºåºæºãå¯è§£éæ§åæè½ææ¨è©ä¼° LRN è¤è£½å°å®¶åé¡§çè½åãä¸è´æ§ä»¥ Jaccard ææ¸åæ··æ·ç©é£æ¸¬éãç ç©¶äººå¡å¨ç ç©¶å®æåå°å½¼æ­¤ççµæä¿å¯ãéççç ç©¶æ´åå° LRN çæçç³»çµ±æ§åé¡§ä¸­ãLRN æ¨¡åå¨æ²æå°å®¶è¨ç·´çææ³ä¸å±ç¾åºåªç°çåé¡æºç¢ºçï¼éå° 84.78% å 85.71% çæºç¢ºçãæè½æé«çæ¨¡åéå°äºé«è©åèéä¿¡è³´åº¦ (k = 0.4953) åå¯è§£éæ§ææ¨ï¼å°ãæ¸å°ãããæå¤ãåãé³å©ãèãééæ´æå¥ãé£çµå¨ä¸èµ·ãå¦ä¸å LRN æ¨¡åæ¶µèäº 91.51% çç¸éæç»ï¼åç®¡èéå°å®¶çå¤æ·ä¸å (k = 0.2174)ï¼ä½åå«äºãä¹³è ãããééãï¼æå¥ï¼åãé©æçãç­è©å½ãLRN åªæ¼æååé¡§ï¼11 åæè¶é 19,920 åéï¼ï¼å°æ´åéç¨ç¸®ç­çº 5 å¤©è¶é 288.6 åéãéé ç ç©¶é¡¯ç¤ºï¼å¯è§£éç AI ä¸éè¦å°å®¶è¨ç·´å³å¯æåé²è¡å°å®¶ç­ç´ç PRISMA ç¸å®¹ç³»çµ±æ§æç»åé¡§ãLRN ç¸½çµäºå¤ç§æå¥ç ç©¶ççµæï¼ä¸¦æ¾åºèè¨åºç ç©¶äººå¡ç¼ç¾å¹¾ä¹ç¸åçä¸»é¢ãå¯è§£éç AI å¯ä»¥æºç¢ºå°å å¿«æåå°è¨åºå¯¦åççè§£ï¼ææ½åé©æ°é«çä¿å¥ç ç©¶ã

##### **Enhancing Medical Learning and Reasoning Systems: A Boxology-Based Comparative Analysis of Design Patterns**
2408.02709v1 by Chi Him Ng

This study analyzes hybrid AI systems' design patterns and their
effectiveness in clinical decision-making using the boxology framework. It
categorizes and copares various architectures combining machine learning and
rule-based reasoning to provide insights into their structural foundations and
healthcare applications. Addressing two main questions, how to categorize these
systems againts established design patterns and how to extract insights through
comparative analysis, the study uses design patterns from software engineering
to understand and optimize healthcare AI systems. Boxology helps identify
commonalities and create reusable solutions, enhancing these systems'
scalability, reliability, and performance. Five primary architectures are
examined: REML, MLRB, RBML, RMLT, and PERML. Each has unique strengths and
weaknesses, highlighting the need for tailored approaches in clinical tasks.
REML excels in high-accuracy prediction for datasets with limited data; MLRB in
handling large datasets and complex data integration; RBML in explainability
and trustworthiness; RMLT in managing high-dimensional data; and PERML, though
limited in analysis, shows promise in urgent care scenarios. The study
introduces four new patterns, creates five abstract categorization patterns,
and refines those five further to specific systems. These contributions enhance
Boxlogy's taxonomical organization and offer novel approaches to integrating
expert knowledge with machine learning. Boxology's structured, modular apporach
offers significant advantages in developing and analyzing hybrid AI systems,
revealing commonalities, and promoting reusable solutions. In conclusion, this
study underscores hybrid AI systems' crucial role in advancing healthcare and
Boxology's potential to drive further innovation in AI integration, ultimately
improving clinical decision support and patient outcomes.

æè¦ï¼æ¬ç ç©¶ä½¿ç¨çå­å­¸æ¡æ¶åææ··åäººå·¥æºæ§ç³»çµ±çè¨­è¨æ¨¡å¼åå¶å¨è¨åºæ±ºç­ä¸­çæææ§ãå®åé¡ä¸¦æ¯è¼çµåæ©å¨å­¸ç¿ååºæ¼è¦åçæ¨ççåç¨®æ¶æ§ï¼ä»¥æ·±å¥äºè§£å¶çµæ§åºç¤åé«çä¿å¥æç¨ãéå°å©åä¸»è¦åé¡ï¼å¦ä½æ ¹ææ¢å®çè¨­è¨æ¨¡å¼å°éäºç³»çµ±é²è¡åé¡ï¼ä»¥åå¦ä½ééæ¯è¼åææåè¦è§£ï¼æ¬ç ç©¶ä½¿ç¨è»é«å·¥ç¨ä¸­çè¨­è¨æ¨¡å¼ä¾äºè§£ååªåé«çä¿å¥äººå·¥æºæ§ç³»çµ±ãçå­å­¸æå©æ¼è­å¥å±æ§ä¸¦å»ºç«å¯éè¤ä½¿ç¨çè§£æ±ºæ¹æ¡ï¼å¾èå¢å¼·éäºç³»çµ±çå¯æ´åæ§ãå¯é æ§åæè½ãæª¢æ¥äºäºç¨®ä¸»è¦çæ¶æ§ï¼REMLãMLRBãRBMLãRMLT å PERMLãæ¯ç¨®æ¶æ§é½æç¨ç¹çåªç¼ºé»ï¼å¼·èª¿äºå¨è¨åºä»»åä¸­éè¦éèº«æé çæ¹æ³ãREML å¨è³ææéçè³æéä¸­è¡¨ç¾åºé«ç²¾åº¦çé æ¸¬ï¼MLRB å¨èçå¤§åè³æéåè¤éè³ææ´åæ¹é¢è¡¨ç¾åºè²ï¼RBML å¨å¯è§£éæ§åå¯ä¿¡åº¦æ¹é¢è¡¨ç¾åºè²ï¼RMLT å¨ç®¡çé«ç¶­è³ææ¹é¢è¡¨ç¾åºè²ï¼è PERML åç®¡å¨åææ¹é¢æéï¼ä½å¨ç·æ¥ç§è­·å ´æ¯ä¸­è¡¨ç¾åºæ½åãæ¬ç ç©¶å¼å¥äºåç¨®æ°æ¨¡å¼ï¼å»ºç«äºäºç¨®æ½è±¡åé¡æ¨¡å¼ï¼ä¸¦é²ä¸æ­¥å°éäºç¨®æ¨¡å¼ç´°åçºå·é«çç³»çµ±ãéäºè²¢ç»å¢å¼·äºçå­å­¸çåé¡çµç¹ï¼ä¸¦æä¾äºå°å°å®¶ç¥è­èæ©å¨å­¸ç¿æ´åçæ°æ¹æ³ãçå­å­¸ççµæ§åãæ¨¡çµåæ¹æ³å¨éç¼ååææ··åäººå·¥æºæ§ç³»çµ±ãæ­ç¤ºå±æ§ä»¥åæ¨å»£å¯éè¤ä½¿ç¨çè§£æ±ºæ¹æ¡æ¹é¢å·æé¡¯èåªå¢ãç¸½ä¹ï¼æ¬ç ç©¶å¼·èª¿äºæ··åäººå·¥æºæ§ç³»çµ±å¨æ¨é²é«çä¿å¥ä¸­çééµä½ç¨ï¼ä»¥åçå­å­¸å¨æ¨åäººå·¥æºæ§æ´åé²ä¸æ­¥åµæ°æ¹é¢çæ½åï¼æçµæ¹åè¨åºæ±ºç­æ¯æ´åæ£èçæ²»çææã

##### **Bayesian Kolmogorov Arnold Networks (Bayesian_KANs): A Probabilistic Approach to Enhance Accuracy and Interpretability**
2408.02706v1 by Masoud Muhammed Hassan

Because of its strong predictive skills, deep learning has emerged as an
essential tool in many industries, including healthcare. Traditional deep
learning models, on the other hand, frequently lack interpretability and omit
to take prediction uncertainty into account two crucial components of clinical
decision making. In order to produce explainable and uncertainty aware
predictions, this study presents a novel framework called Bayesian Kolmogorov
Arnold Networks (BKANs), which combines the expressive capacity of Kolmogorov
Arnold Networks with Bayesian inference. We employ BKANs on two medical
datasets, which are widely used benchmarks for assessing machine learning
models in medical diagnostics: the Pima Indians Diabetes dataset and the
Cleveland Heart Disease dataset. Our method provides useful insights into
prediction confidence and decision boundaries and outperforms traditional deep
learning models in terms of prediction accuracy. Moreover, BKANs' capacity to
represent aleatoric and epistemic uncertainty guarantees doctors receive more
solid and trustworthy decision support. Our Bayesian strategy improves the
interpretability of the model and considerably minimises overfitting, which is
important for tiny and imbalanced medical datasets, according to experimental
results. We present possible expansions to further use BKANs in more
complicated multimodal datasets and address the significance of these
discoveries for future research in building reliable AI systems for healthcare.
This work paves the way for a new paradigm in deep learning model deployment in
vital sectors where transparency and reliability are crucial.

æè¦ï¼ç±æ¼å¶å¼·å¤§çé æ¸¬è½åï¼æ·±åº¦å­¸ç¿å·²æçºè¨±å¤ç¢æ¥­ä¸­ä¸å¯æç¼ºçå·¥å·ï¼åæ¬é«çä¿å¥ãç¶èï¼å³çµ±çæ·±åº¦å­¸ç¿æ¨¡åéå¸¸ç¼ºä¹å¯è§£éæ§ï¼ä¸¦ä¸å¿½ç¥äºå°é æ¸¬ä¸ç¢ºå®æ§ç´å¥èéï¼èéå©åå ç´ æ¯è¨åºæ±ºç­å¶å®çééµçµæé¨åãçºäºç¢çå¯è§£éä¸å·æä¸ç¢ºå®æ§æè­çé æ¸¬ï¼æ¬ç ç©¶æåºäºä¸ååçºè²æ°æ¯ç¾è«å¥æ´å¤«é¿è«¾å¾·ç¶²è·¯ (BKAN) çæ°æ¶æ§ï¼å®çµåäºæ¯ç¾è«å¥æ´å¤«é¿è«¾å¾·ç¶²è·¯çè¡¨éè½åèè²æ°æ¨è«ãæåå¨å©åé«å­¸è³æéä¸ä½¿ç¨ BKANï¼éäºè³æéæ¯è©ä¼°æ©å¨å­¸ç¿æ¨¡åå¨é«å­¸è¨ºæ·ä¸­çå»£æ³ä½¿ç¨åºæºï¼ç®é¦¬å°ç¬¬å®äººç³å°¿çè³æéååéå¤«è­å¿èçè³æéãæåçæ¨¡åæä¾äºå°é æ¸¬ä¿¡å¿åæ±ºç­éççæçè¦è§£ï¼ä¸¦ä¸å¨é æ¸¬æºç¢ºåº¦æ¹é¢åªæ¼å³çµ±çæ·±åº¦å­¸ç¿æ¨¡åãæ­¤å¤ï¼BKAN è¡¨ç¾é¨æ©åèªè­ä¸ç¢ºå®æ§çè½åï¼å¯ç¢ºä¿é«çç²å¾æ´å¯é ä¸å¼å¾ä¿¡è³´çæ±ºç­æ¯æ´ãæ ¹æå¯¦é©çµæï¼æåçè²æ°ç­ç¥æé«äºæ¨¡åçå¯è§£éæ§ï¼ä¸¦å¤§å¹æ¸å°äºéåº¦æ¬åï¼éå°æ¼å°åä¸ä¸å¹³è¡¡çé«å­¸è³æééå¸¸éè¦ãæåæåºäºå¯è½çæ´ååè½ï¼ä»¥é²ä¸æ­¥å° BKAN ç¨æ¼æ´è¤éçå¤æ¨¡å¼è³æéï¼ä¸¦æ¢è¨éäºç¼ç¾å°æ¼æªä¾å»ºç«å¯é çé«çä¿å¥ AI ç³»çµ±ç ç©¶çéè¦æ§ãéé å·¥ä½çºæ·±åº¦å­¸ç¿æ¨¡åé¨ç½²å¨éæåº¦åå¯é æ§è³ééè¦çéè¦é åä¸­éåäºä¸åæ°çå¸ç¯ã

##### **MLtoGAI: Semantic Web based with Machine Learning for Enhanced Disease Prediction and Personalized Recommendations using Generative AI**
2407.20284v1 by Shyam Dongre, Ritesh Chandra, Sonali Agarwal

In modern healthcare, addressing the complexities of accurate disease
prediction and personalized recommendations is both crucial and challenging.
This research introduces MLtoGAI, which integrates Semantic Web technology with
Machine Learning (ML) to enhance disease prediction and offer user-friendly
explanations through ChatGPT. The system comprises three key components: a
reusable disease ontology that incorporates detailed knowledge about various
diseases, a diagnostic classification model that uses patient symptoms to
detect specific diseases accurately, and the integration of Semantic Web Rule
Language (SWRL) with ontology and ChatGPT to generate clear, personalized
health advice. This approach significantly improves prediction accuracy and
ensures results that are easy to understand, addressing the complexity of
diseases and diverse symptoms. The MLtoGAI system demonstrates substantial
advancements in accuracy and user satisfaction, contributing to developing more
intelligent and accessible healthcare solutions. This innovative approach
combines the strengths of ML algorithms with the ability to provide
transparent, human-understandable explanations through ChatGPT, achieving
significant improvements in prediction accuracy and user comprehension. By
leveraging semantic technology and explainable AI, the system enhances the
accuracy of disease prediction and ensures that the recommendations are
relevant and easily understood by individual patients. Our research highlights
the potential of integrating advanced technologies to overcome existing
challenges in medical diagnostics, paving the way for future developments in
intelligent healthcare systems. Additionally, the system is validated using 200
synthetic patient data records, ensuring robust performance and reliability.

æè¦ï¼å¨ç¾ä»£é«çä¿å¥ä¸­ï¼è§£æ±ºæºç¢ºç¾çé æ¸¬ååæ§åå»ºè­°çè¤éæ§æ¢è³ééè¦åå·æææ°æ§ãæ¬ç ç©¶å¼å¥äº MLtoGAIï¼å®å°èªç¾©ç¶²è·¯æè¡èæ©å¨å­¸ç¿ (ML) ç¸çµåï¼ä»¥å¢å¼·ç¾çé æ¸¬ä¸¦éé ChatGPT æä¾ä½¿ç¨èååçèªªæãè©²ç³»çµ±åå«ä¸åééµçµæé¨åï¼ä¸åå¯éè¤ä½¿ç¨çç¾çæ¬ä½ï¼å¶ä¸­åå«æéåç¨®ç¾ççè©³ç´°ç¥è­ï¼ä¸åè¨ºæ·åé¡æ¨¡åï¼å®ä½¿ç¨æ£èççä¾æºç¢ºæª¢æ¸¬ç¹å®ç¾çï¼ä»¥åèªç¾©ç¶²è·¯è¦åèªè¨ (SWRL) èæ¬ä½å ChatGPT çæ´åï¼ä»¥ç¢çæ¸æ°ãåæ§åçå¥åº·å»ºè­°ãéç¨®æ¹æ³é¡¯èæé«äºé æ¸¬æºç¢ºæ§ï¼ä¸¦ç¢ºä¿äºææ¼çè§£ççµæï¼è§£æ±ºäºç¾çåä¸åçççè¤éæ§ãMLtoGAI ç³»çµ±å±ç¤ºäºæºç¢ºæ§åä½¿ç¨èæ»¿æåº¦çå¯¦è³ªæ§é²æ­¥ï¼æå©æ¼éç¼æ´æºæ§ä¸æ´ææ¼åå¾çé«çä¿å¥è§£æ±ºæ¹æ¡ãéç¨®åµæ°çæ¹æ³çµåäº ML æ¼ç®æ³çåªé»ï¼ä»¥åéé ChatGPT æä¾éæä¸äººé¡å¯ä»¥çè§£çèªªæçè½åï¼å¨é æ¸¬æºç¢ºæ§åä½¿ç¨èçè§£æ¹é¢åå¾äºé¡¯èçé²æ­¥ãééå©ç¨èªç¾©æè¡åå¯è§£éç AIï¼è©²ç³»çµ±æé«äºç¾çé æ¸¬çæºç¢ºæ§ï¼ä¸¦ç¢ºä¿äºå»ºè­°èåå¥æ£èç¸éä¸ææ¼çè§£ãæåçç ç©¶å¼·èª¿äºæ´ååé²æè¡ä»¥åæé«çè¨ºæ·ä¸­ç¾æææ°çæ½åï¼çºæºæ§é«çä¿å¥ç³»çµ±çæªä¾ç¼å±éªè·¯ãæ­¤å¤ï¼è©²ç³»çµ±ä½¿ç¨ 200 ååææ£èè³æè¨éé²è¡é©è­ï¼ç¢ºä¿äºç©©å¥çæè½åå¯é æ§ã

##### **Introducing Î´-XAI: a novel sensitivity-based method for local AI explanations**
2407.18343v2 by Alessandro De Carlo, Enea Parimbelli, Nicola Melillo, Giovanna Nicora

Explainable Artificial Intelligence (XAI) is central to the debate on
integrating Artificial Intelligence (AI) and Machine Learning (ML) algorithms
into clinical practice. High-performing AI/ML models, such as ensemble learners
and deep neural networks, often lack interpretability, hampering clinicians'
trust in their predictions. To address this, XAI techniques are being developed
to describe AI/ML predictions in human-understandable terms. One promising
direction is the adaptation of sensitivity analysis (SA) and global sensitivity
analysis (GSA), which inherently rank model inputs by their impact on
predictions. Here, we introduce a novel delta-XAI method that provides local
explanations of ML model predictions by extending the delta index, a GSA
metric. The delta-XAI index assesses the impact of each feature's value on the
predicted output for individual instances in both regression and classification
problems. We formalize the delta-XAI index and provide code for its
implementation. The delta-XAI method was evaluated on simulated scenarios using
linear regression models, with Shapley values serving as a benchmark. Results
showed that the delta-XAI index is generally consistent with Shapley values,
with notable discrepancies in models with highly impactful or extreme feature
values. The delta-XAI index demonstrated higher sensitivity in detecting
dominant features and handling extreme feature values. Qualitatively, the
delta-XAI provides intuitive explanations by leveraging probability density
functions, making feature rankings clearer and more explainable for
practitioners. Overall, the delta-XAI method appears promising for robustly
obtaining local explanations of ML model predictions. Further investigations in
real-world clinical settings will be conducted to evaluate its impact on
AI-assisted clinical workflows.

æè¦ï¼å¯è§£éäººå·¥æºæ§ (XAI) æ¯å°äººå·¥æºæ§ (AI) åæ©å¨å­¸ç¿ (ML) æ¼ç®æ³æ´åå°è¨åºå¯¦åä¸­çè¾¯è«æ ¸å¿ãé«å·è¡æè½ç AI/ML æ¨¡åï¼ä¾å¦æ´é«å­¸ç¿å¨åæ·±åº¦ç¥ç¶ç¶²è·¯ï¼éå¸¸ç¼ºä¹å¯è§£éæ§ï¼é»ç¤è¨åºé«çå°å¶é æ¸¬çä¿¡ä»»ãçºäºè§£æ±ºéååé¡ï¼æ­£å¨éç¼ XAI æè¡ï¼ä»¥äººé¡å¯ä»¥çè§£çè¡èªæè¿° AI/ML é æ¸¬ãä¸åæå¸æçæ¹åæ¯æ¡ç¨ææåº¦åæ (SA) åå¨çææåº¦åæ (GSA)ï¼å®åæ¬è³ªä¸æä¾ææ¨¡åè¼¸å¥å°é æ¸¬çå½±é¿ä¾å°å¶é²è¡æåãå¨æ­¤ï¼æåä»ç´¹ä¸ç¨®æ°ç delta-XAI æ¹æ³ï¼ééæ´å GSA ææ¨ delta ææ¸ä¾æä¾ ML æ¨¡åé æ¸¬çå±é¨è§£éãdelta-XAI ææ¸è©ä¼°æ¯åç¹å¾µå¼å°åæ­¸ååé¡åé¡ä¸­åå¥ä¾é çé æ¸¬è¼¸åºä¹å½±é¿ãæåå° delta-XAI ææ¸å½¢å¼åï¼ä¸¦æä¾å¶å¯¦ä½çç¨å¼ç¢¼ãä½¿ç¨ç·æ§åæ­¸æ¨¡åå°æ¨¡æ¬æå¢è©ä¼° delta-XAI æ¹æ³ï¼ä¸¦ä»¥ Shapley å¼ä½çºåºæºãçµæé¡¯ç¤º delta-XAI ææ¸éå¸¸è Shapley å¼ä¸è´ï¼ä½å¨å·æé«åº¦å½±é¿åææ¥µç«¯ç¹å¾µå¼çæ¨¡åä¸­å­å¨é¡¯èå·®ç°ãdelta-XAI ææ¸å¨åµæ¸¬ä¸»è¦ç¹å¾µåèçæ¥µç«¯ç¹å¾µå¼æ¹é¢è¡¨ç¾åºæ´é«çææåº¦ãå®æ§å°ä¾èªªï¼delta-XAI ééå©ç¨æ©çå¯åº¦å½æ¸æä¾ç´è§çè§£éï¼ä½¿ç¹å¾µæåæ´æ¸æ°ä¸å°å¾æ¥­äººå¡ä¾èªªæ´å·å¯è§£éæ§ãç¸½é«èè¨ï¼delta-XAI æ¹æ³å°æ¼ç©©å¥å°åå¾ ML æ¨¡åé æ¸¬çå±é¨è§£éä¼¼ä¹å¾æå¸æãå°å¨çå¯¦ä¸ççè¨åºç°å¢ä¸­é²è¡é²ä¸æ­¥èª¿æ¥ï¼ä»¥è©ä¼°å¶å° AI è¼å©è¨åºå·¥ä½æµç¨çå½±é¿ã

##### **Enhanced Deep Learning Methodologies and MRI Selection Techniques for Dementia Diagnosis in the Elderly Population**
2407.17324v2 by Nikolaos Ntampakis, Konstantinos Diamantaras, Ioanna Chouvarda, Vasileios Argyriou, Panagiotis Sarigianndis

Dementia, a debilitating neurological condition affecting millions worldwide,
presents significant diagnostic challenges. In this work, we introduce a novel
methodology for the classification of demented and non-demented elderly
patients using 3D brain Magnetic Resonance Imaging (MRI) scans. Our approach
features a unique technique for selectively processing MRI slices, focusing on
the most relevant brain regions and excluding less informative sections. This
methodology is complemented by a confidence-based classification committee
composed of three custom deep learning models: Dem3D ResNet, Dem3D CNN, and
Dem3D EfficientNet. These models work synergistically to enhance
decision-making accuracy, leveraging their collective strengths. Tested on the
Open Access Series of Imaging Studies(OASIS) dataset, our method achieved an
impressive accuracy of 94.12%, surpassing existing methodologies. Furthermore,
validation on the Alzheimer's Disease Neuroimaging Initiative (ADNI) dataset
confirmed the robustness and generalizability of our approach. The use of
explainable AI (XAI) techniques and comprehensive ablation studies further
substantiate the effectiveness of our techniques, providing insights into the
decision-making process and the importance of our methodology. This research
offers a significant advancement in dementia diagnosis, providing a highly
accurate and efficient tool for clinical applications.

æè¦ï¼å¤±æºçæ¯ä¸ç¨®å½±é¿å¨çæ¸ç¾è¬äººçè¡°å¼±æ§ç¥ç¶ç¾çï¼å¨è¨ºæ·ä¸å·æéå¤§ææ°ãå¨éé å·¥ä½ä¸­ï¼æåæåºäºä¸ç¨®æ°çæ¹æ³ï¼ç¨æ¼å°å¤±æºåéå¤±æºèå¹´æ£èé²è¡åé¡ï¼ä½¿ç¨ 3D å¤§è¦ç£æ¯é å½± (MRI) ææãæåçåæ³æ¡ç¨äºä¸ç¨®ç¨ç¹æè¡ï¼ç¨æ¼é¸ææ§èç MRI åçï¼éé»éæ³¨æç¸éçå¤§è¦ååï¼ä¸¦æé¤ä¿¡æ¯éè¼å°çé¨åãéç¨®æ¹æ³ç±ä¸ååºæ¼ä¿¡å¿çåé¡å§å¡æè£åï¼è©²å§å¡æç±ä¸åèªå®ç¾©æ·±åº¦å­¸ç¿æ¨¡åçµæï¼Dem3D ResNetãDem3D CNN å Dem3D EfficientNetãéäºæ¨¡åååå·¥ä½ä»¥å¢å¼·æ±ºç­çæºç¢ºæ§ï¼å©ç¨å®åçéé«åªå¢ãå¨å½±åç ç©¶éæ¾å­åç³»å (OASIS) è³æéä¸é²è¡æ¸¬è©¦ï¼æåçæ¨¡åéå°äº 94.12% çé©äººæºç¢ºåº¦ï¼è¶éäºç¾ææ¹æ³ãæ­¤å¤ï¼å¨é¿è²æµ·é»çç¥ç¶å½±åå¡è­° (ADNI) è³æéä¸çé©è­è­å¯¦äºæåæ¹æ³çç©©å¥æ§åæ®éæ§ãå¯è§£é AI (XAI) æè¡åå¨é¢çæ¶èç ç©¶é²ä¸æ­¥è­å¯¦äºæåæè¡çæææ§ï¼æä¾äºå°æ±ºç­éç¨åæåæ¹æ³éè¦æ§çè¦è§£ãéé ç ç©¶çºå¤±æºçè¨ºæ·æä¾äºéå¤§é²å±ï¼çºè¨åºæç¨æä¾äºä¸åé«åº¦æºç¢ºä¸é«æçå·¥å·ã

##### **Using Large Language Models to Compare Explainable Models for Smart Home Human Activity Recognition**
2408.06352v1 by Michele Fiori, Gabriele Civitarese, Claudio Bettini

Recognizing daily activities with unobtrusive sensors in smart environments
enables various healthcare applications. Monitoring how subjects perform
activities at home and their changes over time can reveal early symptoms of
health issues, such as cognitive decline. Most approaches in this field use
deep learning models, which are often seen as black boxes mapping sensor data
to activities. However, non-expert users like clinicians need to trust and
understand these models' outputs. Thus, eXplainable AI (XAI) methods for Human
Activity Recognition have emerged to provide intuitive natural language
explanations from these models. Different XAI methods generate different
explanations, and their effectiveness is typically evaluated through user
surveys, that are often challenging in terms of costs and fairness. This paper
proposes an automatic evaluation method using Large Language Models (LLMs) to
identify, in a pool of candidates, the best XAI approach for non-expert users.
Our preliminary results suggest that LLM evaluation aligns with user surveys.

æè¦ï¼èç±æºæ§ç°å¢ä¸­ä¸å¼äººæ³¨ç®çææ¸¬å¨è¾¨è­æ¥å¸¸æ´»åï¼è½åç¨åç¨®é«çä¿å¥æç¨ãç£æ§åè©¦èå¨å®¶ä¸­å¦ä½å·è¡æ´»åï¼ä»¥åå¶é¨èæéçè®åï¼å¯ä»¥æ­ç¤ºå¥åº·åé¡çæ©æççï¼ä¾å¦èªç¥è½åä¸éãæ­¤é åä¸­çå¤§å¤æ¸æ¹æ³é½ä½¿ç¨æ·±åº¦å­¸ç¿æ¨¡åï¼éäºæ¨¡åéå¸¸è¢«è¦çºå°ææ¸¬å¨è³æå°æè³æ´»åçé»çå­ãç¶èï¼éå°å®¶ä½¿ç¨èï¼ä¾å¦è¨åºé«å¸«ï¼éè¦ä¿¡ä»»ä¸¦äºè§£éäºæ¨¡åçè¼¸åºãå æ­¤ï¼äººé¡æ´»åè¾¨è­çå¯è§£é AI (XAI) æ¹æ³æéèçï¼ä»¥æä¾ä¾èªéäºæ¨¡åçç´è¦ºèªç¶èªè¨èªªæãä¸åç XAI æ¹æ³æç¢çä¸åçèªªæï¼èå¶æææ§éå¸¸ééä½¿ç¨èèª¿æ¥ä¾è©ä¼°ï¼éå¨ææ¬åå¬å¹³æ§æ¹é¢éå¸¸å·æææ°æ§ãæ¬ææåºä½¿ç¨å¤§åèªè¨æ¨¡å (LLM) çèªåè©ä¼°æ¹æ³ï¼ä»¥å¨åé¸èä¸­æ¾åºæé©åéå°å®¶ä½¿ç¨èç XAI æ¹æ³ãæåçåæ­¥çµæè¡¨æï¼LLM è©ä¼°èä½¿ç¨èèª¿æ¥ä¸è´ã

##### **Explainable AI-based Intrusion Detection System for Industry 5.0: An Overview of the Literature, associated Challenges, the existing Solutions, and Potential Research Directions**
2408.03335v1 by Naseem Khan, Kashif Ahmad, Aref Al Tamimi, Mohammed M. Alani, Amine Bermak, Issa Khalil

Industry 5.0, which focuses on human and Artificial Intelligence (AI)
collaboration for performing different tasks in manufacturing, involves a
higher number of robots, Internet of Things (IoTs) devices and
interconnections, Augmented/Virtual Reality (AR), and other smart devices. The
huge involvement of these devices and interconnection in various critical
areas, such as economy, health, education and defense systems, poses several
types of potential security flaws. AI itself has been proven a very effective
and powerful tool in different areas of cybersecurity, such as intrusion
detection, malware detection, and phishing detection, among others. Just as in
many application areas, cybersecurity professionals were reluctant to accept
black-box ML solutions for cybersecurity applications. This reluctance pushed
forward the adoption of eXplainable Artificial Intelligence (XAI) as a tool
that helps explain how decisions are made in ML-based systems. In this survey,
we present a comprehensive study of different XAI-based intrusion detection
systems for industry 5.0, and we also examine the impact of explainability and
interpretability on Cybersecurity practices through the lens of Adversarial
XIDS (Adv-XIDS) approaches. Furthermore, we analyze the possible opportunities
and challenges in XAI cybersecurity systems for industry 5.0 that elicit future
research toward XAI-based solutions to be adopted by high-stakes industry 5.0
applications. We believe this rigorous analysis will establish a foundational
framework for subsequent research endeavors within the specified domain.

æè¦ï¼å·¥æ¥­ 5.0 èéæ¼äººé¡èäººå·¥æºæ§ (AI) åä½å·è¡è£½é ä¸­çä¸åä»»åï¼æ¶åæ´å¤æ©å¨äººãç©è¯ç¶² (IoT) è£ç½®åäºé£ãæ´å¢/èæ¬å¯¦å¢ (AR) åå¶ä»æºæ§è£ç½®ãéäºè£ç½®åäºé£å¨ç¶æ¿ãé«çä¿å¥ãæè²ååé²ç³»çµ±ç­åç¨®ééµé åçå»£æ³åèï¼å¼ç¼äºå¤ç¨®é¡åçæ½å¨å®å¨æ¼æ´ãAI æ¬èº«å·²è¢«è­ææ¯ç¶²è·¯å®å¨ä¸åé åä¸­éå¸¸ææä¸å¼·å¤§çå·¥å·ï¼ä¾å¦å¥ä¾µåµæ¸¬ãæ¡æè»é«åµæ¸¬åç¶²è·¯é£é­åµæ¸¬ç­ãå°±åå¨è¨±å¤æç¨é åä¸æ¨£ï¼ç¶²è·¯å®å¨å°æ¥­äººå¡ä¸é¡ææ¥åé»ç ML è§£æ±ºæ¹æ¡ä¾æç¨æ¼ç¶²è·¯å®å¨ãéç¨®ä¸é¡æä¿ä½¿å¯è§£éäººå·¥æºæ§ (XAI) ä½çºä¸ç¨®å·¥å·è¢«æ¡ç¨ï¼æå©æ¼èªªæå¨åºæ¼ ML çç³»çµ±ä¸­å¦ä½ååºæ±ºç­ãå¨éé èª¿æ¥ä¸­ï¼æåå°å·¥æ¥­ 5.0 çä¸ååºæ¼ XAI çå¥ä¾µåµæ¸¬ç³»çµ±é²è¡äºå¨é¢çç ç©¶ï¼ä¸¦ä¸æåä¹ééå°æå¼ XIDS (Adv-XIDS) æ¹æ³çè§é»ä¾æ¢è¨å¯è§£éæ§åå¯è©®éæ§å°ç¶²è·¯å®å¨å¯¦åçå½±é¿ãæ­¤å¤ï¼æååæäºå·¥æ¥­ 5.0 ç XAI ç¶²è·¯å®å¨ç³»çµ±ä¸­å¯è½å­å¨çæ©æåææ°ï¼å¼ç¼äºæªä¾éå° XAI åºç¤è§£æ±ºæ¹æ¡çç ç©¶ï¼ä»¥ä¾é«é¢¨éªçå·¥æ¥­ 5.0 æç¨æ¡ç¨ãæåç¸ä¿¡éé å´è¬¹çåæå°çºæå®é åå§çå¾çºç ç©¶å·¥ä½å»ºç«åºç¤æ¶æ§ã

##### **A Comparative Study on Automatic Coding of Medical Letters with Explainability**
2407.13638v1 by Jamie Glen, Lifeng Han, Paul Rayson, Goran Nenadic

This study aims to explore the implementation of Natural Language Processing
(NLP) and machine learning (ML) techniques to automate the coding of medical
letters with visualised explainability and light-weighted local computer
settings. Currently in clinical settings, coding is a manual process that
involves assigning codes to each condition, procedure, and medication in a
patient's paperwork (e.g., 56265001 heart disease using SNOMED CT code). There
are preliminary research on automatic coding in this field using
state-of-the-art ML models; however, due to the complexity and size of the
models, the real-world deployment is not achieved. To further facilitate the
possibility of automatic coding practice, we explore some solutions in a local
computer setting; in addition, we explore the function of explainability for
transparency of AI models. We used the publicly available MIMIC-III database
and the HAN/HLAN network models for ICD code prediction purposes. We also
experimented with the mapping between ICD and SNOMED CT knowledge bases. In our
experiments, the models provided useful information for 97.98\% of codes. The
result of this investigation can shed some light on implementing automatic
clinical coding in practice, such as in hospital settings, on the local
computers used by clinicians , project page
\url{https://github.com/Glenj01/Medical-Coding}.

æè¦ï¼æ¬ç ç©¶æ¨å¨æ¢è¨å°èªç¶èªè¨èç (NLP) åæ©å¨å­¸ç¿ (ML) æè¡å¯¦ä½æ¼é«çä¿¡å½ç·¨ç¢¼èªååï¼ä¸¦å·åè¦è¦ºåèªªæè½ååè¼éåçæ¬å°é»è¦è¨­å®ãç®åå¨è¨åºç°å¢ä¸­ï¼ç·¨ç¢¼æ¯ä¸ç¨®æåæµç¨ï¼æ¶åçºçæ£æä»¶ä¸­çæ¯é ççãç¨åºåè¥ç©ææ´¾ä»£ç¢¼ (ä¾å¦ï¼ä½¿ç¨ SNOMED CT ä»£ç¢¼ 56265001 è¡¨ç¤ºå¿èç)ãæ­¤é åæä½¿ç¨ææ° ML æ¨¡åé²è¡èªåç·¨ç¢¼çåæ­¥ç ç©¶ï¼ç¶èï¼ç±æ¼æ¨¡åçè¤éæ§åå¤§å°ï¼ä¸¦æªå¯¦ç¾å¯¦éé¨ç½²ãçºäºé²ä¸æ­¥ä¿é²èªåç·¨ç¢¼å¯¦åçå¯è½æ§ï¼æåå¨æ¬å°é»è¦è¨­å®ä¸­æ¢è¨äºä¸äºè§£æ±ºæ¹æ¡ï¼æ­¤å¤ï¼æåæ¢è¨äºèªªæåè½å¨ AI æ¨¡åéæåº¦ä¸­çåè½ãæåä½¿ç¨å¬éç MIMIC-III è³æåº«å HAN/HLAN ç¶²è·¯æ¨¡åé²è¡ ICD ä»£ç¢¼é æ¸¬ãæåéè©¦é©äº ICD å SNOMED CT ç¥è­åº«ä¹éçå°æãå¨æåçå¯¦é©ä¸­ï¼éäºæ¨¡åæä¾äº 97.98% ä»£ç¢¼çæç¨è³è¨ãéé èª¿æ¥çµæå¯ä»¥çºå¯¦åä¸­çèªåè¨åºç·¨ç¢¼å¯¦ä½æä¾ä¸äºè¦è§£ï¼ä¾å¦å¨é«é¢ç°å¢ä¸­ï¼ç±è¨åºé«çä½¿ç¨çæ¬å°é»è¦ï¼å°æ¡é é¢ \url{https://github.com/Glenj01/Medical-Coding}ã

##### **Explainable AI for Enhancing Efficiency of DL-based Channel Estimation**
2407.07009v1 by Abdul Karim Gizzini, Yahia Medjahdi, Ali J. Ghandour, Laurent Clavier

The support of artificial intelligence (AI) based decision-making is a key
element in future 6G networks, where the concept of native AI will be
introduced. Moreover, AI is widely employed in different critical applications
such as autonomous driving and medical diagnosis. In such applications, using
AI as black-box models is risky and challenging. Hence, it is crucial to
understand and trust the decisions taken by these models. Tackling this issue
can be achieved by developing explainable AI (XAI) schemes that aim to explain
the logic behind the black-box model behavior, and thus, ensure its efficient
and safe deployment. Recently, we proposed a novel perturbation-based XAI-CHEST
framework that is oriented toward channel estimation in wireless
communications. The core idea of the XAI-CHEST framework is to identify the
relevant model inputs by inducing high noise on the irrelevant ones. This
manuscript provides the detailed theoretical foundations of the XAI-CHEST
framework. In particular, we derive the analytical expressions of the XAI-CHEST
loss functions and the noise threshold fine-tuning optimization problem. Hence
the designed XAI-CHEST delivers a smart input feature selection methodology
that can further improve the overall performance while optimizing the
architecture of the employed model. Simulation results show that the XAI-CHEST
framework provides valid interpretations, where it offers an improved bit error
rate performance while reducing the required computational complexity in
comparison to the classical DL-based channel estimation.

æè¦ï¼äººå·¥æºè½ (AI) æ¯æçæ±ºç­å¶å®æ¯æªä¾ 6G ç¶²è·¯ä¸­çééµåç´ ï¼å¶ä¸­å°å¼å¥åç AI çæ¦å¿µãæ­¤å¤ï¼AI å»£æ³ç¨æ¼ä¸åçééµæç¨ä¸­ï¼ä¾å¦èªåé§é§åé«çè¨ºæ·ãå¨éäºæç¨ä¸­ï¼ä½¿ç¨ AI ä½çºé»çæ¨¡åæ¯æé¢¨éªä¸å·æææ°æ§çãå æ­¤ï¼çè§£åä¿¡ä»»éäºæ¨¡åååºçæ±ºç­è³ééè¦ãè§£æ±ºæ­¤åé¡çæ¹æ³æ¯éç¼å¯è§£é AI (XAI) æ¶æ§ï¼æ¨å¨è§£éé»çæ¨¡åè¡çºèå¾çéè¼¯ï¼å¾èç¢ºä¿å¶ææä¸å®å¨çé¨ç½²ãæè¿ï¼æåæåºäºä¸åæ°çåºæ¼æ¾åç XAI-CHEST æ¡æ¶ï¼è©²æ¡æ¶é¢åç¡ç·éä¿¡ä¸­çä¿¡éä¼°è¨ãXAI-CHEST æ¡æ¶çæ ¸å¿ææ³æ¯ééå¨ç¡éè¼¸å¥ä¸å¼å¥é«åªè²ä¾è­å¥ç¸éæ¨¡åè¼¸å¥ãéä»½æç¨¿æä¾äº XAI-CHEST æ¡æ¶çè©³ç´°çè«åºç¤ãç¹å¥æ¯ï¼æåæ¨å°äº XAI-CHEST æå¤±å½æ¸ååªè²é¾å¼å¾®èª¿åªååé¡çè§£æè¡¨éå¼ãå æ­¤ï¼è¨­è¨ç XAI-CHEST æä¾äºä¸ç¨®æºè½è¼¸å¥ç¹å¾µé¸ææ¹æ³ï¼å¯ä»¥å¨åªåæç¨æ¨¡åçæ¶æ§çåæé²ä¸æ­¥æé«æ´é«æ§è½ãæ¨¡æ¬çµæè¡¨æï¼XAI-CHEST æ¡æ¶æä¾äºææçè§£éï¼å¨éä½æéçè¨ç®è¤éåº¦çåæï¼æä¾äºæ¹é²çæ¯ç¹é¯èª¤çæ§è½ï¼èéèåºæ¼å³çµ± DL çä¿¡éä¼°è¨ç¸æ¯ã

##### **Explainable AI: Comparative Analysis of Normal and Dilated ResNet Models for Fundus Disease Classification**
2407.05440v2 by P. N. Karthikayan, Yoga Sri Varshan V, Hitesh Gupta Kattamuri, Umarani Jayaraman

This paper presents dilated Residual Network (ResNet) models for disease
classification from retinal fundus images. Dilated convolution filters are used
to replace normal convolution filters in the higher layers of the ResNet model
(dilated ResNet) in order to improve the receptive field compared to the normal
ResNet model for disease classification. This study introduces
computer-assisted diagnostic tools that employ deep learning, enhanced with
explainable AI techniques. These techniques aim to make the tool's
decision-making process transparent, thereby enabling medical professionals to
understand and trust the AI's diagnostic decision. They are particularly
relevant in today's healthcare landscape, where there is a growing demand for
transparency in AI applications to ensure their reliability and ethical use.
The dilated ResNet is used as a replacement for the normal ResNet to enhance
the classification accuracy of retinal eye diseases and reduce the required
computing time. The dataset used in this work is the Ocular Disease Intelligent
Recognition (ODIR) dataset which is a structured ophthalmic database with eight
classes covering most of the common retinal eye diseases. The evaluation
metrics used in this work include precision, recall, accuracy, and F1 score. In
this work, a comparative study has been made between normal ResNet models and
dilated ResNet models on five variants namely ResNet-18, ResNet-34, ResNet-50,
ResNet-101, and ResNet-152. The dilated ResNet model shows promising results as
compared to normal ResNet with an average F1 score of 0.71, 0.70, 0.69, 0.67,
and 0.70 respectively for the above respective variants in ODIR multiclass
disease classification.

æè¦ï¼è¿ç¯è®ºææåºäºç¨äºä»è§ç½èç¼åºå¾åè¿è¡ç¾çåç±»çæ©å¼ æ®å·®ç½ç» (ResNet) æ¨¡åãæ©å¼ å·ç§¯æ»¤æ³¢å¨ç¨äºæ¿æ¢ ResNet æ¨¡åè¾é«å±ä¸­çæ­£å¸¸å·ç§¯æ»¤æ³¢å¨ï¼æ©å¼  ResNetï¼ï¼ä»¥æ¹åæç¥åºï¼ä»èéå¯¹ç¾çåç±»å¯¹æ­£å¸¸ ResNet æ¨¡åè¿è¡æ¹è¿ãæ¬ç ç©¶å¼å¥äºéç¨æ·±åº¦å­¦ä¹ çè®¡ç®æºè¾å©è¯æ­å·¥å·ï¼å¹¶éè¿å¯è§£éç AI ææ¯è¿è¡äºå¢å¼ºãè¿äºææ¯æ¨å¨ä½¿è¯¥å·¥å·çå³ç­è¿ç¨éæåï¼ä»èä½¿å»å­¦ä¸ä¸äººå£«è½å¤çè§£åä¿¡ä»» AI çè¯æ­å³ç­ãå®ä»¬ä¸å½ä»çå»çä¿å¥é¢åå°¤ä¸ºç¸å³ï¼å¨è¯¥é¢åï¼å¯¹ AI åºç¨çéæåº¦éæ±ä¸æ­å¢é¿ï¼ä»¥ç¡®ä¿å¶å¯é æ§ååä¹éå¾·çä½¿ç¨ãæ©å¼  ResNet ç¨ä½æ­£å¸¸ ResNet çæ¿ä»£åï¼ä»¥æé«è§ç½èç¼é¨ç¾ççåç±»åç¡®æ§å¹¶åå°æéçè®¡ç®æ¶é´ãæ¬å·¥ä½ä¸­ä½¿ç¨çæ°æ®éæ¯ç¼ç§ç¾çæºè½è¯å« (ODIR) æ°æ®éï¼è¿æ¯ä¸ä¸ªç»æåçç¼ç§æ°æ®åºï¼åå«å«ç±»æ¶µçå¤§å¤æ°å¸¸è§è§ç½èç¼é¨ç¾çãæ¬å·¥ä½ä¸­ä½¿ç¨çè¯ä¼°ææ åæ¬ç²¾ç¡®åº¦ãå¬åçãåç¡®åº¦å F1 å¾åãå¨è¿é¡¹å·¥ä½ä¸­ï¼å¯¹ ResNet-18ãResNet-34ãResNet-50ãResNet-101 å ResNet-152 äºä¸ªåä½çæ­£å¸¸ ResNet æ¨¡ååæ©å¼  ResNet æ¨¡åè¿è¡äºæ¯è¾ç ç©¶ãä¸æ­£å¸¸ ResNet ç¸æ¯ï¼æ©å¼  ResNet æ¨¡åæ¾ç¤ºåºæå¸æçç»æï¼å¨ ODIR å¤ç±»ç¾çåç±»ä¸­ï¼ä¸è¿°åä¸ªåä½çå¹³å F1 å¾åä¸º 0.71ã0.70ã0.69ã0.67 å 0.70ã

##### **A Survey on Trustworthiness in Foundation Models for Medical Image Analysis**
2407.15851v2 by Congzhen Shi, Ryan Rezai, Jiaxi Yang, Qi Dou, Xiaoxiao Li

The rapid advancement of foundation models in medical imaging represents a
significant leap toward enhancing diagnostic accuracy and personalized
treatment. However, the deployment of foundation models in healthcare
necessitates a rigorous examination of their trustworthiness, encompassing
privacy, robustness, reliability, explainability, and fairness. The current
body of survey literature on foundation models in medical imaging reveals
considerable gaps, particularly in the area of trustworthiness. Additionally,
existing surveys on the trustworthiness of foundation models do not adequately
address their specific variations and applications within the medical imaging
domain. This survey aims to fill that gap by presenting a novel taxonomy of
foundation models used in medical imaging and analyzing the key motivations for
ensuring their trustworthiness. We review current research on foundation models
in major medical imaging applications, focusing on segmentation, medical report
generation, medical question and answering (Q\&A), and disease diagnosis. These
areas are highlighted because they have seen a relatively mature and
substantial number of foundation models compared to other applications. We
focus on literature that discusses trustworthiness in medical image analysis
manuscripts. We explore the complex challenges of building trustworthy
foundation models for each application, summarizing current concerns and
strategies for enhancing trustworthiness. Furthermore, we examine the potential
of these models to revolutionize patient care. Our analysis underscores the
imperative for advancing towards trustworthy AI in medical image analysis,
advocating for a balanced approach that fosters innovation while ensuring
ethical and equitable healthcare delivery.

æè¦ï¼åºç¤æ¨¡åå¨é«å­¸å½±åæ¹é¢çå¿«éé²å±ï¼ä»£è¡¨èå¨å å¼·è¨ºæ·æºç¢ºæ§ååäººåæ²»çæ¹é¢éåºä¸å¤§æ­¥ãç¶èï¼åºç¤æ¨¡åå¨é«çä¿å¥ä¸­çé¨ç½²éè¦å°å¶å¯ä¿¡åº¦é²è¡å´æ ¼çå¯©æ¥ï¼åæ¬é±ç§ãç©©å¥æ§ãå¯é æ§ãå¯è§£éæ§åå¬å¹³æ§ãç®åéæ¼é«å­¸å½±åä¸­åºç¤æ¨¡åçèª¿æ¥æç»ä¸­é¡¯ç¤ºåºç¸ç¶å¤§çå·®è·ï¼ç¹å¥æ¯å¨å¯ä¿¡åº¦æ¹é¢ãæ­¤å¤ï¼ç¾æéæ¼åºç¤æ¨¡åå¯ä¿¡åº¦çèª¿æ¥ä¸¦æªååè§£æ±ºå¶å¨é«å­¸å½±åé åä¸­çç¹å®è®ååæç¨ãæ¬èª¿æ¥æ¨å¨ééæåºé«å­¸å½±åä¸­ä½¿ç¨çåºç¤æ¨¡åçæ°åé¡æ³ä¸¦åæç¢ºä¿å¶å¯ä¿¡åº¦çééµåæ©ï¼ä¾å¡«è£éä¸ç©ºç½ãæååé¡§äºåºç¤æ¨¡åå¨ä¸»è¦é«å­¸å½±åæç¨ä¸­çç¶åç ç©¶ï¼éé»éæ³¨åå²ãé«çå ±åçæãé«çåé¡ååç­ (Q&A) ä»¥åç¾çè¨ºæ·ãéäºé åä¹æä»¥è¢«å¼·èª¿ï¼æ¯å çºèå¶ä»æç¨ç¸æ¯ï¼å®åå·²ç¶çå°ç¸å°æçä¸å¤§éçåºç¤æ¨¡åãæåå°æ³¨æ¼æ¢è¨é«å­¸å½±ååææç¨¿ä¸­å¯ä¿¡åº¦çæç»ãæåæ¢è¨äºçºæ¯åæç¨æ§å»ºå¯ä¿¡åºç¤æ¨¡åçè¤éææ°ï¼ç¸½çµäºç¶åéæ³¨é»åå¢å¼·å¯ä¿¡åº¦çç­ç¥ãæ­¤å¤ï¼æåæ¢è¨äºéäºæ¨¡åå¨é©æ°æ£èè­·çæ¹é¢çæ½åãæåçåæå¼·èª¿äºå¨é«å­¸å½±ååæä¸­æèå¯ä¿¡è³´çäººå·¥æºæ§éé²çå¿è¦æ§ï¼ä¸¦å¡å°ä¸ç¨®å¹³è¡¡çæ¹æ³ï¼æ¢è½ä¿é²åµæ°ï¼åè½ç¢ºä¿éå¾·åå¬å¹³çé«çä¿å¥æåã

##### **The Impact of an XAI-Augmented Approach on Binary Classification with Scarce Data**
2407.06206v1 by Ximing Wen, Rosina O. Weber, Anik Sen, Darryl Hannan, Steven C. Nesbit, Vincent Chan, Alberto Goffi, Michael Morris, John C. Hunninghake, Nicholas E. Villalobos, Edward Kim, Christopher J. MacLellan

Point-of-Care Ultrasound (POCUS) is the practice of clinicians conducting and
interpreting ultrasound scans right at the patient's bedside. However, the
expertise needed to interpret these images is considerable and may not always
be present in emergency situations. This reality makes algorithms such as
machine learning classifiers extremely valuable to augment human decisions.
POCUS devices are becoming available at a reasonable cost in the size of a
mobile phone. The challenge of turning POCUS devices into life-saving tools is
that interpretation of ultrasound images requires specialist training and
experience. Unfortunately, the difficulty to obtain positive training images
represents an important obstacle to building efficient and accurate
classifiers. Hence, the problem we try to investigate is how to explore
strategies to increase accuracy of classifiers trained with scarce data. We
hypothesize that training with a few data instances may not suffice for
classifiers to generalize causing them to overfit. Our approach uses an
Explainable AI-Augmented approach to help the algorithm learn more from less
and potentially help the classifier better generalize.

æè¦ï¼åºéè¶é³æ³¢ (POCUS) æ¯è¨åºé«å¸«å¨æ£èåºéé²è¡åè§£è®è¶é³æ³¢ææçå¯¦åãç¶èï¼è§£è®éäºå½±åæéçå°æ¥­ç¥è­ç¸ç¶å¯è§ï¼èä¸å¨ç·æ¥ææ³ä¸å¯è½ä¸¦éé¨æå·åãéç¨®ç¾å¯¦ææ³ä½¿å¾æ©å¨å­¸ç¿åé¡å¨ç­æ¼ç®æ³å°æ¼å å¼·äººé¡æ±ºç­è®å¾æ¥µçºæå¹å¼ãPOCUS è£ç½®æ­£ä»¥åçææ¬æ¨åºï¼å°ºå¯¸çºææ©å¤§å°ãå° POCUS è£ç½®è½è®çºæçå·¥å·çææ°å¨æ¼ï¼è§£è®è¶é³æ³¢å½±åéè¦å°éè¨ç·´åç¶é©ãä¸å¹¸çæ¯ï¼åå¾æ­£åè¨ç·´å½±åçå°é£åº¦ä»£è¡¨èå»ºç½®ææçä¸æºç¢ºçåé¡å¨çä¸å¤§éç¤ãå æ­¤ï¼æååè©¦æ¢è¨çåé¡æ¯å¦ä½æ¢ç´¢ç­ç¥ï¼ä»¥æé«ä½¿ç¨ç¨çè³æè¨ç·´çåé¡å¨çæºç¢ºåº¦ãæååè¨­ä½¿ç¨å°æ¸è³æå¯¦ä¾é²è¡è¨ç·´å¯è½ä¸è¶³ä»¥è®åé¡å¨æ¦æ¬ï¼å°è´å®åéåº¦æ¬åãæåçåæ³ä½¿ç¨å¯è§£é AI å¢å¼·æ¹æ³ï¼ä»¥åå©æ¼ç®æ³å¾è¼å°çè³æä¸­å­¸ç¿æ´å¤ï¼ä¸¦æ½å¨åå©åé¡å¨æ´å¥½å°æ¦æ¬ã

##### **Can GPT-4 Help Detect Quit Vaping Intentions? An Exploration of Automatic Data Annotation Approach**
2407.00167v1 by Sai Krishna Revanth Vuruma, Dezhi Wu, Saborny Sen Gupta, Lucas Aust, Valerie Lookingbill, Wyatt Bellamy, Yang Ren, Erin Kasson, Li-Shiun Chen, Patricia Cavazos-Rehg, Dian Hu, Ming Huang

In recent years, the United States has witnessed a significant surge in the
popularity of vaping or e-cigarette use, leading to a notable rise in cases of
e-cigarette and vaping use-associated lung injury (EVALI) that caused
hospitalizations and fatalities during the EVALI outbreak in 2019, highlighting
the urgency to comprehend vaping behaviors and develop effective strategies for
cessation. Due to the ubiquity of social media platforms, over 4.7 billion
users worldwide use them for connectivity, communications, news, and
entertainment with a significant portion of the discourse related to health,
thereby establishing social media data as an invaluable organic data resource
for public health research. In this study, we extracted a sample dataset from
one vaping sub-community on Reddit to analyze users' quit-vaping intentions.
Leveraging OpenAI's latest large language model GPT-4 for sentence-level quit
vaping intention detection, this study compares the outcomes of this model
against layman and clinical expert annotations. Using different prompting
strategies such as zero-shot, one-shot, few-shot and chain-of-thought
prompting, we developed 8 prompts with varying levels of detail to explain the
task to GPT-4 and also evaluated the performance of the strategies against each
other. These preliminary findings emphasize the potential of GPT-4 in social
media data analysis, especially in identifying users' subtle intentions that
may elude human detection.

æè¦ï¼è¿å¹´ä¾ï¼ç¾åè¦è­äºé»å­çæé»å­é¦è¸ä½¿ç¨çå¤§å¹æ¿å¢ï¼å°è´é»å­çåé»å­çä½¿ç¨ç¸éèºæå· (EVALI) çä¾é¡¯èå¢å ï¼å¨ 2019 å¹´ EVALI çç¼æéé æä½é¢åæ­»äº¡ï¼å¸é¡¯äºçè§£é»å­çè¡çºåå¶å®æææè¸ç­ç¥çè¿«åæ§ãç±æ¼ç¤¾ç¾¤åªé«å¹³å°çæ®åï¼å¨çè¶é 47 åä½¿ç¨èä½¿ç¨å®åé²è¡é£çµãæºéãæ°èåå¨æ¨ï¼å¶ä¸­å¾å¤§ä¸é¨åèå¥åº·ç¸éï¼å æ­¤å°ç¤¾ç¾¤åªé«è³æå»ºç«çºå¬å±è¡çç ç©¶ä¸­ç¡å¹çææ©è³æè³æºãå¨æ¬ç ç©¶ä¸­ï¼æåå¾ Reddit ä¸ä¸åé»å­çå­ç¤¾ç¾¤ä¸­æåä¸åç¯ä¾è³æéï¼ä»¥åæä½¿ç¨èçæé»å­çæåãå©ç¨ OpenAI ææ°çå¤§åèªè¨æ¨¡å GPT-4 é²è¡å¥å­å±¤ç´çæé»å­çæååµæ¸¬ï¼æ¬ç ç©¶æ¯è¼äºæ­¤æ¨¡åççµæèå¤è¡äººåè¨åºå°å®¶è¨»è§£ãä½¿ç¨ä¸åçæç¤ºç­ç¥ï¼ä¾å¦é¶æ¬¡å­¸ç¿ãä¸æ¬¡å­¸ç¿ãå°æ¬¡å­¸ç¿åæèéæç¤ºï¼æåéç¼äº 8 åæç¤ºï¼è©³ç´°ç¨åº¦ä¸åï¼å GPT-4 è§£éä»»åï¼ä¸¦è©ä¼°éäºç­ç¥å½¼æ­¤ä¹éçæè½ãéäºåæ­¥ç¼ç¾å¼·èª¿äº GPT-4 å¨ç¤¾ç¾¤åªé«è³æåæä¸­çæ½åï¼ç¹å¥æ¯å¨è­å¥äººé¡åµæ¸¬å¯è½ç¡æ³å¯è¦ºçä½¿ç¨èå¾®å¦æåæ¹é¢ã

##### **Towards Compositional Interpretability for XAI**
2406.17583v1 by Sean Tull, Robin Lorenz, Stephen Clark, Ilyas Khan, Bob Coecke

Artificial intelligence (AI) is currently based largely on black-box machine
learning models which lack interpretability. The field of eXplainable AI (XAI)
strives to address this major concern, being critical in high-stakes areas such
as the finance, legal and health sectors.
  We present an approach to defining AI models and their interpretability based
on category theory. For this we employ the notion of a compositional model,
which sees a model in terms of formal string diagrams which capture its
abstract structure together with its concrete implementation. This
comprehensive view incorporates deterministic, probabilistic and quantum
models. We compare a wide range of AI models as compositional models, including
linear and rule-based models, (recurrent) neural networks, transformers, VAEs,
and causal and DisCoCirc models.
  Next we give a definition of interpretation of a model in terms of its
compositional structure, demonstrating how to analyse the interpretability of a
model, and using this to clarify common themes in XAI. We find that what makes
the standard 'intrinsically interpretable' models so transparent is brought out
most clearly diagrammatically. This leads us to the more general notion of
compositionally-interpretable (CI) models, which additionally include, for
instance, causal, conceptual space, and DisCoCirc models.
  We next demonstrate the explainability benefits of CI models. Firstly, their
compositional structure may allow the computation of other quantities of
interest, and may facilitate inference from the model to the modelled
phenomenon by matching its structure. Secondly, they allow for diagrammatic
explanations for their behaviour, based on influence constraints, diagram
surgery and rewrite explanations. Finally, we discuss many future directions
for the approach, raising the question of how to learn such meaningfully
structured models in practice.

æè¦ï¼<paragraph>äººå·¥æºæ§ï¼AIï¼ç®åå¨å¾å¤§ç¨åº¦ä¸ä¾è³´æ¼ç¼ºä¹å¯è§£éæ§çé»çæ©å¨å­¸ç¿æ¨¡åãå¯è§£éæ§äººå·¥æºæ§ï¼XAIï¼é åè´åæ¼è§£æ±ºéåä¸»è¦åé¡ï¼éå¨éèãæ³å¾åå¥åº·ç­é«é¢¨éªé åè³ééè¦ã
æåæåºäºä¸ç¨®åºæ¼ç¯çè«å®ç¾© AI æ¨¡ååå¶å¯è§£éæ§çæ¹æ³ãçºæ­¤ï¼æåæ¡ç¨çµåæ¨¡åçæ¦å¿µï¼å®ä»¥å½¢å¼å¼¦åçå½¢å¼çå¾æ¨¡åï¼éäºå¼¦åæç²äºæ¨¡åçæ½è±¡çµæ§åå¶å·é«å¯¦ç¾ãéç¨®ç¶åè§é»åå«äºç¢ºå®æ§ãæ¦çæ§åéå­æ¨¡åãæåå°åç¨® AI æ¨¡åä½çºçµåæ¨¡åé²è¡æ¯è¼ï¼åæ¬ç·æ§ååºæ¼è¦åçæ¨¡åãï¼éè¿´ï¼ç¥ç¶ç¶²è·¯ãTransformerãVAEï¼ä»¥åå æå DisCoCirc æ¨¡åã
æ¥ä¸ä¾ï¼æåæ ¹ææ¨¡åççµåçµæ§çµ¦åºæ¨¡åè§£éçå®ç¾©ï¼å±ç¤ºå¦ä½åææ¨¡åçå¯è§£éæ§ï¼ä¸¦ä½¿ç¨å®ä¾æ¾æ¸ XAI ä¸­çå¸¸è¦ä¸»é¡ãæåç¼ç¾ï¼è®æ¨æºçãå§å¨å¯è§£éãæ¨¡åå¦æ­¤éæçåå å¨åè¡¨ä¸­è¡¨ç¾å¾æçºæ¸æ¥ãéå¼å°æåå¾åºæ´ä¸è¬ççµåå¯è§£éï¼CIï¼æ¨¡åæ¦å¿µï¼å®å¦å¤éåæ¬å æãæ¦å¿µç©ºéå DisCoCirc æ¨¡åã
æ¥ä¸ä¾ï¼æåå±ç¤ºäº CI æ¨¡åçå¯è§£éæ§åªå¢ãé¦åï¼å®åççµåçµæ§åè¨±è¨ç®å¶ä»æèè¶£çéï¼ä¸¦å¯è½ééå¹éæ¨¡åççµæ§ä¾ä¿é²å¾æ¨¡åå°è¢«å»ºæ¨¡ç¾è±¡çæ¨çãå¶æ¬¡ï¼å®ååè¨±å°å¶è¡çºé²è¡åè§£èªªæï¼éäºèªªæåºæ¼å½±é¿ç´æãåè§£æè¡åéå¯«èªªæãæå¾ï¼æåè¨è«äºéç¨®æ¹æ³çè¨±å¤æªä¾æ¹åï¼æåºäºå¦ä½å¨å¯¦è¸ä¸­å­¸ç¿éç¨®ææç¾©ççµæ§åæ¨¡åçåé¡ã</paragraph>

##### **Slicing Through Bias: Explaining Performance Gaps in Medical Image Analysis using Slice Discovery Methods**
2406.12142v2 by Vincent Olesen, Nina Weng, Aasa Feragen, Eike Petersen

Machine learning models have achieved high overall accuracy in medical image
analysis. However, performance disparities on specific patient groups pose
challenges to their clinical utility, safety, and fairness. This can affect
known patient groups - such as those based on sex, age, or disease subtype - as
well as previously unknown and unlabeled groups. Furthermore, the root cause of
such observed performance disparities is often challenging to uncover,
hindering mitigation efforts. In this paper, to address these issues, we
leverage Slice Discovery Methods (SDMs) to identify interpretable
underperforming subsets of data and formulate hypotheses regarding the cause of
observed performance disparities. We introduce a novel SDM and apply it in a
case study on the classification of pneumothorax and atelectasis from chest
x-rays. Our study demonstrates the effectiveness of SDMs in hypothesis
formulation and yields an explanation of previously observed but unexplained
performance disparities between male and female patients in widely used chest
X-ray datasets and models. Our findings indicate shortcut learning in both
classification tasks, through the presence of chest drains and ECG wires,
respectively. Sex-based differences in the prevalence of these shortcut
features appear to cause the observed classification performance gap,
representing a previously underappreciated interaction between shortcut
learning and model fairness analyses.

æè¦ï¼æ©å¨å­¸ç¿æ¨¡åå¨é«å­¸å½±ååæä¸­å·²éå°æ´é«é«æºç¢ºåº¦ãç¶èï¼ç¹å®æ£èç¾¤é«çæè½å·®ç°å°å¶è¨åºæç¨ãå®å¨æ§èå¬å¹³æ§æ§æææ°ãéå¯è½æå½±é¿å·²ç¥çæ£èç¾¤é«ï¼ä¾å¦åºæ¼æ§å¥ãå¹´é½¡æç¾çäºåï¼ä»¥åååæªç¥ä¸æªæ¨ç±¤çç¾¤é«ãæ­¤å¤ï¼æ­¤é¡è§å¯å°çæè½å·®ç°çæ ¹æ¬åå éå¸¸é£ä»¥ç¼ç¾ï¼é»ç¤äºç·©è§£æªæ½ãå¨æ¬æä¸­ï¼çºäºè§£æ±ºéäºåé¡ï¼æåå©ç¨åçç¼ç¾æ¹æ³ (SDM) ä¾è­å¥å¯è§£éçè³ææè½ä¸ä½³å­éï¼ä¸¦éå°è§å¯å°çæè½å·®ç°åå å¶å®åè¨­ãæåå¼å¥ä¸ç¨®æ°ç SDMï¼ä¸¦å¨è¸é¨ X åçä¸­èºçåèºä¸å¼µåé¡çæ¡ä¾ç ç©¶ä¸­æç¨å®ãæåçç ç©¶è­æäº SDM å¨åè¨­å¶å®ä¸­çæææ§ï¼ä¸¦å°å»£æ³ä½¿ç¨çè¸é¨ X åçè³æéåæ¨¡åä¸­ååè§å¯å°ä½ç¡æ³è§£éçç·æ§åå¥³æ§æ£èä¹éçæè½å·®ç°æä¾äºè§£éãæåçç¼ç¾è¡¨æï¼å¨åé¡ä»»åä¸­ï¼ééè¸èå¼æµç®¡åå¿é»åå°ç·çå­å¨ï¼å­å¨æ·å¾å­¸ç¿ãéäºæ·å¾ç¹å¾µççè¡çå­å¨åºæ¼æ§å¥çå·®ç°ï¼ä¼¼ä¹æå°è´è§å¯å°çåé¡æè½å·®è·ï¼éä»£è¡¨æ·å¾å­¸ç¿åæ¨¡åå¬å¹³æ§åæä¹éååæªåå°éè¦çäº¤äºä½ç¨ã

##### **Unlocking the Potential of Metaverse in Innovative and Immersive Digital Health**
2406.07114v2 by Fatemeh Ebrahimzadeh, Ramin Safa

The concept of Metaverse has attracted a lot of attention in various fields
and one of its important applications is health and treatment. The Metaverse
has enormous potential to transform healthcare by changing patient care,
medical education, and the way teaching/learning and research are done. The
purpose of this research is to provide an introduction to the basic concepts
and fundamental technologies of the Metaverse. This paper examines the pros and
cons of the Metaverse in healthcare context and analyzes its potential from the
technology and AI perspective. In particular, the role of machine learning
methods is discussed; We will explain how machine learning algorithms can be
applied to the Metaverse generated data to gain better insights in healthcare
applications. Additionally, we examine the future visions of the Metaverse in
health delivery, by examining emerging technologies such as blockchain and also
addressing privacy concerns. The findings of this study contribute to a deeper
understanding of the applications of Metaverse in healthcare and its potential
to revolutionize the delivery of medical services.

æè¦ï¼åå®å®çæ¦å¿µå¨ååé åé½ååéæ³¨ï¼å¶éè¦æç¨ä¹ä¸ä¾¿æ¯é«çä¿å¥ãåå®å®æå·¨å¤§çæ½åééæ¹è®çæ£ç§è­·ãé«å­¸æè²ï¼ä»¥åæå­¸/å­¸ç¿åç ç©¶çæ¹å¼ä¾è½åé«çä¿å¥ãæ¬ç ç©¶çç®çæ¯æä¾åå®å®åºæ¬æ¦å¿µååºç¤æè¡çä»ç´¹ãæ¬ææ¢è¨äºåå®å®å¨é«çä¿å¥èæ¯ä¸çåªç¼ºé»ï¼ä¸¦å¾æè¡å AI çè§åº¦åæå¶æ½åãç¹å¥æ¯ï¼è¨è«äºæ©å¨å­¸ç¿æ¹æ³çè§è²ï¼æåå°èªªæå¦ä½å°æ©å¨å­¸ç¿æ¼ç®æ³æç¨æ¼åå®å®ç¢ççè³æï¼ä»¥ç²å¾é«çä¿å¥æç¨æ¹é¢çæ´ä½³è¦è§£ãæ­¤å¤ï¼æåééæ¢è¨åå¡éç­æ°èæè¡ï¼ä¸¦è§£æ±ºé±ç§åé¡ï¼ä¾æ¢è¨åå®å®å¨é«çä¿å¥æ¹é¢çæªä¾é¡æ¯ãæ¬ç ç©¶çç¼ç¾æå©æ¼æ´æ·±å¥å°äºè§£åå®å®å¨é«çä¿å¥ä¸­çæç¨ï¼ä»¥åå¶å¨é«çæåæä¾æ¹é¢ç¼æ®é©å½æ§è®é©çæ½åã

##### **AI-Driven Predictive Analytics Approach for Early Prognosis of Chronic Kidney Disease Using Ensemble Learning and Explainable AI**
2406.06728v1 by K M Tawsik Jawad, Anusha Verma, Fathi Amsaad

Chronic Kidney Disease (CKD) is one of the widespread Chronic diseases with
no known ultimo cure and high morbidity. Research demonstrates that progressive
Chronic Kidney Disease (CKD) is a heterogeneous disorder that significantly
impacts kidney structure and functions, eventually leading to kidney failure.
With the progression of time, chronic kidney disease has moved from a
life-threatening disease affecting few people to a common disorder of varying
severity. The goal of this research is to visualize dominating features,
feature scores, and values exhibited for early prognosis and detection of CKD
using ensemble learning and explainable AI. For that, an AI-driven predictive
analytics approach is proposed to aid clinical practitioners in prescribing
lifestyle modifications for individual patients to reduce the rate of
progression of this disease. Our dataset is collected on body vitals from
individuals with CKD and healthy subjects to develop our proposed AI-driven
solution accurately. In this regard, blood and urine test results are provided,
and ensemble tree-based machine-learning models are applied to predict unseen
cases of CKD. Our research findings are validated after lengthy consultations
with nephrologists. Our experiments and interpretation results are compared
with existing explainable AI applications in various healthcare domains,
including CKD. The comparison shows that our developed AI models, particularly
the Random Forest model, have identified more features as significant
contributors than XgBoost. Interpretability (I), which measures the ratio of
important to masked features, indicates that our XgBoost model achieved a
higher score, specifically a Fidelity of 98\%, in this metric and naturally in
the FII index compared to competing models.

æè¦ï¼æ¢æ§èèçï¼CKDï¼æ¯ä¸ç¨®å»£æ³çæ¢æ§ç¾çï¼æ²æå·²ç¥çæçµçæ³ä¸ç¼ççå¾é«ãç ç©¶è¡¨æï¼é²è¡æ§æ¢æ§èèçï¼CKDï¼æ¯ä¸ç¨®ç°è³ªæ§ç¾çï¼æé¡¯èå½±é¿èèçµæ§ååè½ï¼æçµå°è´èè¡°ç«­ãé¨èæéçæ¨ç§»ï¼æ¢æ§èèçå·²å¾å½±é¿å°æ¸äººçè´å½ç¾çè½è®çºä¸ç¨®å´éç¨åº¦ä¸åçå¸¸è¦ç¾çãæ¬ç ç©¶çç®æ¨æ¯ä½¿ç¨éæå­¸ç¿åå¯è§£éç AI é²è¡æ©æé å¾å CKD æª¢æ¸¬ï¼ä¸¦è¦è¦ºåä¸»å°ç¹å¾µãç¹å¾µåæ¸åè¡¨ç¾åºçå¼ãçºæ­¤ï¼æåºäºä¸ç¨® AI é©åçé æ¸¬åææ¹æ³ï¼ä»¥å¹«å©è¨åºé«ççºåå¥æ£èéå·çæ´»æ¹å¼ä¿®æ¹å»ºè­°ï¼ä»¥éä½éç¨®ç¾ççé²å±éåº¦ãæåçæ¸æéæ¯å¾ CKD æ£èåå¥åº·åè©¦èçèº«é«çå½é«å¾µä¸­æ¶éçï¼ä»¥æºç¢ºéç¼æåæåºç AI é©åçè§£æ±ºæ¹æ¡ãå¨éæ¹é¢ï¼æä¾äºè¡æ¶²åå°¿æ¶²æª¢æ¸¬çµæï¼ä¸¦æç¨åºæ¼éææ¨¹çæ©å¨å­¸ç¿æ¨¡åä¾é æ¸¬æªç¼ç¾ç CKD çä¾ãæåçç ç©¶çµæç¶éèèèç§é«ççé·æè«®è©¢å¾å¾å°é©è­ãæåçå¯¦é©åè§£éçµæèåç¨®é«çä¿å¥é åä¸­ç¾æçå¯è§£é AI æç¨é²è¡äºæ¯è¼ï¼åæ¬ CKDãæ¯è¼è¡¨æï¼æåéç¼ç AI æ¨¡åï¼ç¹å¥æ¯é¨æ©æ£®ææ¨¡åï¼å·²ç¶ç¢ºå®äºæ¯ XgBoost æ´å¤ä½çºéè¦è²¢ç»èçç¹å¾µãå¯è§£éæ§ (I) è¡¡ééè¦ç¹å¾µèæ©èç¹å¾µçæ¯çï¼è¡¨ææåç XgBoost æ¨¡åå¨éåææ¨ä¸­ç²å¾äºæ´é«çåæ¸ï¼ç¹å¥æ¯ 98% çä¿çåº¦ï¼ä¸¦ä¸å¨ FII ææ¸ä¸­èªç¶é«æ¼ç«¶ç­æ¨¡åã

##### **Explainable AI for Mental Disorder Detection via Social Media: A survey and outlook**
2406.05984v1 by Yusif Ibrahimov, Tarique Anwar, Tommy Yuan

Mental health constitutes a complex and pervasive global challenge, affecting
millions of lives and often leading to severe consequences. In this paper, we
conduct a thorough survey to explore the intersection of data science,
artificial intelligence, and mental healthcare, focusing on the recent
developments of mental disorder detection through online social media (OSM). A
significant portion of the population actively engages in OSM platforms,
creating a vast repository of personal data that holds immense potential for
mental health analytics. The paper navigates through traditional diagnostic
methods, state-of-the-art data- and AI-driven research studies, and the
emergence of explainable AI (XAI) models for mental healthcare. We review
state-of-the-art machine learning methods, particularly those based on modern
deep learning, while emphasising the need for explainability in healthcare AI
models. The experimental design section provides insights into prevalent
practices, including available datasets and evaluation approaches. We also
identify key issues and challenges in the field and propose promising future
research directions. As mental health decisions demand transparency,
interpretability, and ethical considerations, this paper contributes to the
ongoing discourse on advancing XAI in mental healthcare through social media.
The comprehensive overview presented here aims to guide researchers,
practitioners, and policymakers in developing the area of mental disorder
detection.

æè¦ï¼å¿çå¥åº·æ§æäºä¸é è¤éä¸æ®éçå¨çææ°ï¼å½±é¿äºæ¸ç¾è¬äººççæ´»ï¼ä¸¦ç¶å¸¸å°è´å´éçå¾æãå¨æ¬æä¸­ï¼æåé²è¡äºä¸é å¾¹åºçèª¿æ¥ï¼ä»¥æ¢ç´¢æ¸æç§å­¸ãäººå·¥æºæ§åå¿çä¿å¥çäº¤éï¼éé»éæ³¨ééç·ä¸ç¤¾äº¤åªé« (OSM) é²è¡å¿çç¾çæª¢æ¸¬çææ°ç¼å±ãå¾å¤§ä¸é¨åäººå£ç©æ¥µåè OSM å¹³å°ï¼åµé äºä¸åé¾å¤§çäººå¡è³æåº«ï¼å°å¿çå¥åº·åæå·æå·¨å¤§çæ½åãæ¬ææ¢è¨äºå³çµ±çè¨ºæ·æ¹æ³ãæåé²çè³æå AI é©åçç ç©¶ï¼ä»¥åå¿çä¿å¥ä¸­å¯è§£é AI (XAI) æ¨¡åçåºç¾ãæååé¡§äºæåé²çæ©å¨å­¸ç¿æ¹æ³ï¼ç¹å¥æ¯é£äºåºæ¼ç¾ä»£æ·±åº¦å­¸ç¿çæ¹æ³ï¼åæå¼·èª¿äºé«çä¿å¥ AI æ¨¡åä¸­å¯è§£éæ§çå¿è¦æ§ãå¯¦é©è¨­è¨é¨åæä¾äºå°æ®éåæ³çè¦è§£ï¼åæ¬å¯ç¨çè³æéåè©ä¼°æ¹æ³ãæåéæ¾åºè©²é åçä¸»è¦åé¡åææ°ï¼ä¸¦æåºäºæå¸æçæªä¾ç ç©¶æ¹åãç±æ¼å¿çå¥åº·æ±ºç­éè¦éæåº¦ãå¯è§£éæ§åéå¾·èéï¼æ¬ææå©æ¼æ¨é²å¿çä¿å¥ä¸­ééç¤¾äº¤åªé«æ¨é² XAI çæçºè¨è«ãéè£¡æåºçå¨é¢æ¦è¿°æ¨å¨å¼å°ç ç©¶äººå¡ãå¾æ¥­äººå¡åæ¿ç­å¶å®èç¼å±å¿çç¾çæª¢æ¸¬é åã

##### **Methodology and Real-World Applications of Dynamic Uncertain Causality Graph for Clinical Diagnosis with Explainability and Invariance**
2406.05746v1 by Zhan Zhang, Qin Zhang, Yang Jiao, Lin Lu, Lin Ma, Aihua Liu, Xiao Liu, Juan Zhao, Yajun Xue, Bing Wei, Mingxia Zhang, Ru Gao, Hong Zhao, Jie Lu, Fan Li, Yang Zhang, Yiming Wang, Lei Zhang, Fengwei Tian, Jie Hu, Xin Gou

AI-aided clinical diagnosis is desired in medical care. Existing deep
learning models lack explainability and mainly focus on image analysis. The
recently developed Dynamic Uncertain Causality Graph (DUCG) approach is
causality-driven, explainable, and invariant across different application
scenarios, without problems of data collection, labeling, fitting, privacy,
bias, generalization, high cost and high energy consumption. Through close
collaboration between clinical experts and DUCG technicians, 46 DUCG models
covering 54 chief complaints were constructed. Over 1,000 diseases can be
diagnosed without triage. Before being applied in real-world, the 46 DUCG
models were retrospectively verified by third-party hospitals. The verified
diagnostic precisions were no less than 95%, in which the diagnostic precision
for every disease including uncommon ones was no less than 80%. After
verifications, the 46 DUCG models were applied in the real-world in China. Over
one million real diagnosis cases have been performed, with only 17 incorrect
diagnoses identified. Due to DUCG's transparency, the mistakes causing the
incorrect diagnoses were found and corrected. The diagnostic abilities of the
clinicians who applied DUCG frequently were improved significantly. Following
the introduction to the earlier presented DUCG methodology, the recommendation
algorithm for potential medical checks is presented and the key idea of DUCG is
extracted.

æè¦ï¼<paragraph>é«çç§è­·ä¸­éè¦ AI è¼å©çè¨åºè¨ºæ·ãç¾æçæ·±åº¦å­¸ç¿æ¨¡åç¼ºä¹å¯è§£éæ§ï¼ä¸¦ä¸ä¸»è¦å°æ³¨æ¼å½±ååæãæè¿éç¼çåæä¸ç¢ºå®å æéä¿å (DUCG) æ¹æ³æ¯å æé©åçãå¯è§£éçï¼ä¸¦ä¸å¨ä¸åçæç¨å ´æ¯ä¸­æ¯ä¸è®çï¼æ²æè³ææ¶éãæ¨è¨ãæ¬åãé±ç§ãåè¦ãæ¦åãé«ææ¬åé«è½èçåé¡ãééè¨åºå°å®¶å DUCG æè¡äººå¡ä¹éçå¯ååä½ï¼æ§å»ºäºæ¶µè 54 åä¸»è¨´ç 46 å DUCG æ¨¡åãå¯ä»¥å¨æ²æåæµçææ³ä¸è¨ºæ·åº 1,000 å¤ç¨®ç¾çãå¨æç¨æ¼å¯¦éä¸çä¹åï¼46 å DUCG æ¨¡åå·²ç±ç¬¬ä¸æ¹é«é¢åæº¯æ§é©è­ãé©è­çè¨ºæ·ç²¾åº¦ä¸ä½æ¼ 95%ï¼å¶ä¸­åæ¬ç½è¦ç¾çå¨å§çæ¯ç¨®ç¾ççè¨ºæ·ç²¾åº¦ä¸ä½æ¼ 80%ãé©è­å¾ï¼46 å DUCG æ¨¡åå·²å¨ä¸­åå¯¦éæç¨ãå·²ç¶å·è¡äºè¶éä¸ç¾è¬åçå¯¦è¨ºæ·æ¡ä¾ï¼åç¼ç¾ 17 åä¸æ­£ç¢ºçè¨ºæ·ãç±æ¼ DUCG çéææ§ï¼ç¼ç¾ä¸¦ç³¾æ­£äºå°è´ä¸æ­£ç¢ºè¨ºæ·çé¯èª¤ãé »ç¹æç¨ DUCG çè¨åºé«ççè¨ºæ·è½åå¾å°äºé¡¯èæé«ãå¨ä»ç´¹äºåé¢æåºç DUCG æ¹æ³è«ä¹å¾ï¼æåºäºæ½å¨å¥åº·æª¢æ¥çæ¨è¦æ¼ç®æ³ï¼ä¸¦æåäº DUCG çééµææ³ã</paragraph>

##### **Advancing Histopathology-Based Breast Cancer Diagnosis: Insights into Multi-Modality and Explainability**
2406.12897v1 by Faseela Abdullakutty, Younes Akbari, Somaya Al-Maadeed, Ahmed Bouridane, Rifat Hamoudi

It is imperative that breast cancer is detected precisely and timely to
improve patient outcomes. Diagnostic methodologies have traditionally relied on
unimodal approaches; however, medical data analytics is integrating diverse
data sources beyond conventional imaging. Using multi-modal techniques,
integrating both image and non-image data, marks a transformative advancement
in breast cancer diagnosis. The purpose of this review is to explore the
burgeoning field of multimodal techniques, particularly the fusion of
histopathology images with non-image data. Further, Explainable AI (XAI) will
be used to elucidate the decision-making processes of complex algorithms,
emphasizing the necessity of explainability in diagnostic processes. This
review utilizes multi-modal data and emphasizes explainability to enhance
diagnostic accuracy, clinician confidence, and patient engagement, ultimately
fostering more personalized treatment strategies for breast cancer, while also
identifying research gaps in multi-modality and explainability, guiding future
studies, and contributing to the strategic direction of the field.

æè¦ï¼ç²¾ç¢ºä¸åæå°åµæ¸¬ä¹³çå°æ¼æ¹åæ£èé å¾è³ééè¦ãè¨ºæ·æ¹æ³å³çµ±ä¸ä¾è³´æ¼å®ä¸æ¨¡å¼æ¹æ³ï¼ç¶èï¼é«çè³æåææ­£å¨æ´åè¶è¶å³çµ±å½±åçåç¨®è³æä¾æºãä½¿ç¨æ´åå½±ååéå½±åè³æçå¤æ¨¡å¼æè¡ï¼æ¨èªèä¹³çè¨ºæ·çè®é©æ§é²å±ãæ¬ç¯ç¶è¿°çç®çæ¯æ¢è¨å¤æ¨¡å¼æè¡çæ°èé åï¼ç¹å¥æ¯å°çµç¹ççå­¸å½±åèéå½±åè³æèåãæ­¤å¤ï¼å¯è§£éäººå·¥æºæ§ (XAI) å°ç¨æ¼é¡æè¤éæ¼ç®æ³çæ±ºç­éç¨ï¼å¼·èª¿è¨ºæ·éç¨ä¸­å¯è§£éæ§çå¿è¦æ§ãæ¬ç¶è¿°å©ç¨å¤æ¨¡å¼è³æä¸¦å¼·èª¿å¯è§£éæ§ï¼ä»¥æé«è¨ºæ·æºç¢ºæ§ãè¨åºé«å¸«çä¿¡å¿åæ£èåèåº¦ï¼æçµä¿é²ä¹³çæ´åäººåçæ²»çç­ç¥ï¼åæä¹æ¾åºå¤æ¨¡å¼åå¯è§£éæ§çç ç©¶å·®è·ï¼å¼å°æªä¾çç ç©¶ï¼ä¸¦çºè©²é åçç­ç¥æ¹åååºè²¢ç»ã

##### **Using Explainable AI for EEG-based Reduced Montage Neonatal Seizure Detection**
2406.16908v3 by Dinuka Sandun Udayantha, Kavindu Weerasinghe, Nima Wickramasinghe, Akila Abeyratne, Kithmin Wickremasinghe, Jithangi Wanigasinghe, Anjula De Silva, Chamira U. S. Edussooriya

The neonatal period is the most vulnerable time for the development of
seizures. Seizures in the immature brain lead to detrimental consequences,
therefore require early diagnosis. The gold-standard for neonatal seizure
detection currently relies on continuous video-EEG monitoring; which involves
recording multi-channel electroencephalogram (EEG) alongside real-time video
monitoring within a neonatal intensive care unit (NICU). However, video-EEG
monitoring technology requires clinical expertise and is often limited to
technologically advanced and resourceful settings. Cost-effective new
techniques could help the medical fraternity make an accurate diagnosis and
advocate treatment without delay. In this work, a novel explainable deep
learning model to automate the neonatal seizure detection process with a
reduced EEG montage is proposed, which employs convolutional nets, graph
attention layers, and fully connected layers. Beyond its ability to detect
seizures in real-time with a reduced montage, this model offers the unique
advantage of real-time interpretability. By evaluating the performance on the
Zenodo dataset with 10-fold cross-validation, the presented model achieves an
absolute improvement of 8.31% and 42.86% in area under curve (AUC) and recall,
respectively.

æè¦ï¼æ°çåææ¯å¤§è¦ç¼è²æèå¼±çææï¼å®¹æåºç¾ç²çç¼ä½ãå¤§è¦ç¼è²ä¸æçæåºç¾ç²çç¼ä½æé æä¸è¯å¾æï¼å æ­¤éè¦åæ©è¨ºæ·ãç®åæ°çåç²çç¼ä½çé»éæ¨æºä¾è³´æ¼é£çºçè¦è¨è¦é»å (EEG) ç£æ¸¬ï¼å¶ä¸­åæ¬å¨æ°çåå è­·çæ¿ (NICU) å§åæé²è¡å¤é »éè¦é»å (EEG) è¨éåå³æè¦è¨ç£æ§ãç¶èï¼è¦è¨è¦é»åç£æ§æè¡éè¦è¨åºå°æ¥­ç¥è­ï¼èä¸éå¸¸åéæ¼æè¡åé²ä¸è³æºè±å¯çç°å¢ãå·ææ¬æççæ°æè¡å¯ä»¥å¹«å©é«ççæºç¢ºè¨ºæ·ä¸¦ç«å³æå¡æ²»çãå¨éé å·¥ä½ä¸­ï¼æåºäºä¸åæ°ç©çå¯è§£éæ·±åº¦å­¸ç¿æ¨¡åï¼ä»¥èªååæ°çåç²çç¼ä½åµæ¸¬éç¨ï¼ä¸¦æ¡ç¨æ¸å°çè¦é»åè£ç½®ï¼å¶ä¸­æ¡ç¨äºå·ç©ç¥ç¶ç¶²è·¯ãåå½¢æ³¨æåå±¤åå¨é£æ¥å±¤ãé¤äºè½å¤ ä½¿ç¨æ¸å°çè£ç½®å³æåµæ¸¬ç²çç¼ä½å¤ï¼æ­¤æ¨¡åéæä¾äºå³æå¯è§£éæ§çç¨ç¹åªå¢ãééå¨ Zenodo è³æéä¸ä½¿ç¨ 10 åäº¤åé©è­è©ä¼°æè½ï¼ææåºçæ¨¡åå¨æ²ç·ä¸é¢ç© (AUC) åå¬åçæ¹é¢åå¥éå°äº 8.31% å 42.86% ççµå°æ¹åã

##### **Breast Cancer Diagnosis: A Comprehensive Exploration of Explainable Artificial Intelligence (XAI) Techniques**
2406.00532v1 by Samita Bai, Sidra Nasir, Rizwan Ahmed Khan, Sheeraz Arif, Alexandre Meyer, Hubert Konik

Breast cancer (BC) stands as one of the most common malignancies affecting
women worldwide, necessitating advancements in diagnostic methodologies for
better clinical outcomes. This article provides a comprehensive exploration of
the application of Explainable Artificial Intelligence (XAI) techniques in the
detection and diagnosis of breast cancer. As Artificial Intelligence (AI)
technologies continue to permeate the healthcare sector, particularly in
oncology, the need for transparent and interpretable models becomes imperative
to enhance clinical decision-making and patient care. This review discusses the
integration of various XAI approaches, such as SHAP, LIME, Grad-CAM, and
others, with machine learning and deep learning models utilized in breast
cancer detection and classification. By investigating the modalities of breast
cancer datasets, including mammograms, ultrasounds and their processing with
AI, the paper highlights how XAI can lead to more accurate diagnoses and
personalized treatment plans. It also examines the challenges in implementing
these techniques and the importance of developing standardized metrics for
evaluating XAI's effectiveness in clinical settings. Through detailed analysis
and discussion, this article aims to highlight the potential of XAI in bridging
the gap between complex AI models and practical healthcare applications,
thereby fostering trust and understanding among medical professionals and
improving patient outcomes.

æè¦ï¼ä¹³ç (BC) æ¯å½±é¿å¨çå¥³æ§æå¸¸è¦çæ¡æ§è«ç¤ä¹ä¸ï¼å æ­¤éè¦é²æ­¥çè¨ºæ·æ¹æ³ï¼ä»¥æ¹åè¨åºçµæãæ¬æå¨é¢æ¢è¨äºå¯è§£éäººå·¥æºæ§ (XAI) æè¡å¨ä¹³çåµæ¸¬åè¨ºæ·ä¸­çæç¨ãé¨èäººå·¥æºæ§ (AI) æè¡æçºæ»²éé«çä¿å¥é åï¼ç¹å¥æ¯å¨è«ç¤å­¸ä¸­ï¼éæä¸å¯è§£éçæ¨¡åéæ±è®å¾å¢å¨å¿è¡ï¼ä»¥å¢å¼·è¨åºæ±ºç­å¶å®åæ£èç§è­·ãæ­¤ç¯è©è«æ¢è¨äºåç¨® XAI æ¹æ³çæ´åï¼ä¾å¦ SHAPãLIMEãGrad-CAM ç­ï¼ä»¥åç¨æ¼ä¹³çåµæ¸¬ååé¡çæ©å¨å­¸ç¿åæ·±åº¦å­¸ç¿æ¨¡åãééæ¢è¨ä¹³çè³æéçæ¨¡å¼ï¼åæ¬ä¹³æ¿æå½±ãè¶é³æ³¢åå¶å¨ AI ä¸­çèçï¼æ¬æéé»èªªæ XAI å¦ä½è½å°è´æ´æºç¢ºçè¨ºæ·ååäººåæ²»çè¨ç«ãå®ä¹æ¢è¨äºå¯¦æ½éäºæè¡çææ°ï¼ä»¥åå¶å®æ¨æºåè©éææ¨ä»¥è©ä¼° XAI å¨è¨åºç°å¢ä¸­çæææ§çéè¦æ§ãééè©³ç´°çåæåè¨è«ï¼æ¬ææ¨å¨å¼·èª¿ XAI å¨ç¸®å°è¤é AI æ¨¡åèå¯¦åé«çä¿å¥æç¨ä¹éå·®è·çæ½åï¼é²èä¿é²é«çå°æ¥­äººå¡ä¹éçä¿¡ä»»èçè§£ï¼ä¸¦æ¹åæ£èççµæã

##### **Unveiling Hidden Factors: Explainable AI for Feature Boosting in Speech Emotion Recognition**
2406.01624v2 by Alaa Nfissi, Wassim Bouachir, Nizar Bouguila, Brian Mishara

Speech emotion recognition (SER) has gained significant attention due to its
several application fields, such as mental health, education, and
human-computer interaction. However, the accuracy of SER systems is hindered by
high-dimensional feature sets that may contain irrelevant and redundant
information. To overcome this challenge, this study proposes an iterative
feature boosting approach for SER that emphasizes feature relevance and
explainability to enhance machine learning model performance. Our approach
involves meticulous feature selection and analysis to build efficient SER
systems. In addressing our main problem through model explainability, we employ
a feature evaluation loop with Shapley values to iteratively refine feature
sets. This process strikes a balance between model performance and
transparency, which enables a comprehensive understanding of the model's
predictions. The proposed approach offers several advantages, including the
identification and removal of irrelevant and redundant features, leading to a
more effective model. Additionally, it promotes explainability, facilitating
comprehension of the model's predictions and the identification of crucial
features for emotion determination. The effectiveness of the proposed method is
validated on the SER benchmarks of the Toronto emotional speech set (TESS),
Berlin Database of Emotional Speech (EMO-DB), Ryerson Audio-Visual Database of
Emotional Speech and Song (RAVDESS), and Surrey Audio-Visual Expressed Emotion
(SAVEE) datasets, outperforming state-of-the-art methods. To the best of our
knowledge, this is the first work to incorporate model explainability into an
SER framework. The source code of this paper is publicly available via this
https://github.com/alaaNfissi/Unveiling-Hidden-Factors-Explainable-AI-for-Feature-Boosting-in-Speech-Emotion-Recognition.

æè¦ï¼èªé³æç·è¾¨è­ (SER) ç±æ¼å¶å¨å¿çå¥åº·ãæè²åäººæ©äºåç­å¤åæç¨é åèååéæ³¨ãç¶èï¼SER ç³»çµ±çæºç¢ºæ§åå°é«ç¶­ç¹å¾µéçé»ç¤ï¼éäºç¹å¾µéå¯è½åå«ä¸ç¸éååé¤çè³è¨ãçºäºåæéåææ°ï¼æ¬ç ç©¶æåºäºä¸ç¨®ç¨æ¼ SER çè¿­ä»£ç¹å¾µæåæ¹æ³ï¼è©²æ¹æ³å¼·èª¿ç¹å¾µç¸éæ§åå¯è§£éæ§ï¼ä»¥å¢å¼·æ©å¨å­¸ç¿æ¨¡åçæè½ãæåçåæ³æ¶åä»ç´°çç¹å¾µé¸æååæï¼ä»¥å»ºç«é«æç SER ç³»çµ±ãçºäºééæ¨¡åå¯è§£éæ§è§£æ±ºæåçæ ¸å¿åé¡ï¼æåæ¡ç¨äºå·æ Shapley å¼çç¹å¾µè©ä¼°è¿´åï¼ä»¥åè¦æ¹åç¹å¾µéãéåéç¨å¨æ¨¡åæè½åéæåº¦ä¹éåå¾å¹³è¡¡ï¼éä½¿å¾æåè½å¤ å¨é¢äºè§£æ¨¡åçé æ¸¬ãææåºçæ¹æ³æä¾äºå¤é åªé»ï¼åæ¬è­å¥åç§»é¤ä¸ç¸éååé¤çç¹å¾µï¼å¾èå»ºç«æ´ææçæ¨¡åãæ­¤å¤ï¼å®ä¿é²äºå¯è§£éæ§ï¼æå©æ¼çè§£æ¨¡åçé æ¸¬ä»¥åè­å¥æç·æ±ºå®çééµç¹å¾µãææåºçæ¹æ³çæææ§å·²å¨å¤å«å¤æç·èªé³é (TESS)ãæææç·èªé³è³æåº« (EMO-DB)ãè³´ç¾æ£®é³è¨è¦è¦ºæç·èªé³åæ­æ²è³æåº« (RAVDESS) åè©éé³è¨è¦è¦ºè¡¨éæç· (SAVEE) è³æéç SER åºæºä¸å¾å°é©è­ï¼å¶æè½åªæ¼ç¾ææ¹æ³ãææåæç¥ï¼éæ¯ç¬¬ä¸åå°æ¨¡åå¯è§£éæ§ç´å¥ SER æ¶æ§çç ç©¶ãæ¬æçåå§ç¢¼å¯ééæ­¤é£çµå¬éåå¾ï¼https://github.com/alaaNfissi/Unveiling-Hidden-Factors-Explainable-AI-for-Feature-Boosting-in-Speech-Emotion-Recognitionã

##### **The Explanation Necessity for Healthcare AI**
2406.00216v1 by Michail Mamalakis, HÃ©loÃ¯se de Vareilles, Graham Murray, Pietro Lio, John Suckling

Explainability is often critical to the acceptable implementation of
artificial intelligence (AI). Nowhere is this more important than healthcare
where decision-making directly impacts patients and trust in AI systems is
essential. This trust is often built on the explanations and interpretations
the AI provides. Despite significant advancements in AI interpretability, there
remains the need for clear guidelines on when and to what extent explanations
are necessary in the medical context. We propose a novel categorization system
with four distinct classes of explanation necessity, guiding the level of
explanation required: patient or sample (local) level, cohort or dataset
(global) level, or both levels. We introduce a mathematical formulation that
distinguishes these categories and offers a practical framework for researchers
to determine the necessity and depth of explanations required in medical AI
applications. Three key factors are considered: the robustness of the
evaluation protocol, the variability of expert observations, and the
representation dimensionality of the application. In this perspective, we
address the question: When does an AI medical application need to be explained,
and at what level of detail?

æè¦ï¼å¯è§£éæ§éå¸¸å¯¹äºäººå·¥æºè½ (AI) çå¯æ¥åå®æ½è³å³éè¦ãå¨å»çä¿å¥é¢åï¼è¿ä¸ç¹å°¤ä¸ºéè¦ï¼å ä¸ºå³ç­ç´æ¥å½±åæ£èï¼å¹¶ä¸å¯¹ AI ç³»ç»çä¿¡ä»»è³å³éè¦ãè¿ç§ä¿¡ä»»éå¸¸å»ºç«å¨ AI æä¾çè§£éåè¯ éä¹ä¸ãå°½ç®¡ AI å¯è§£éæ§åå¾äºéå¤§è¿å±ï¼ä½ä»ç¶éè¦æç¡®çæå¯¼æ¹éï¼è¯´æå¨å»çç¯å¢ä¸­ä½æ¶ä»¥åå¨å¤å¤§ç¨åº¦ä¸éè¦è§£éãæä»¬æåºäºä¸ç§æ°é¢çåç±»ç³»ç»ï¼è¯¥ç³»ç»å·æåç§ä¸åçè§£éå¿è¦æ§ç±»å«ï¼æå¯¼æéçè§£éçº§å«ï¼æ£èææ ·æ¬ï¼å±é¨ï¼çº§å«ãéåææ°æ®éï¼å¨å±ï¼çº§å«ï¼æä¸¤ä¸ªçº§å«ãæä»¬å¼å¥äºä¸ä¸ªæ°å­¦å¬å¼ï¼è¯¥å¬å¼åºåäºè¿äºç±»å«ï¼å¹¶ä¸ºç ç©¶äººåæä¾äºä¸ä¸ªå®ç¨æ¡æ¶ï¼ä»¥ç¡®å®å»ç AI åºç¨ä¸­æéçè§£éçå¿è¦æ§åæ·±åº¦ãèèäºä¸ä¸ªå³é®å ç´ ï¼è¯ä¼°åè®®çç¨³å¥æ§ãä¸å®¶è§å¯çå¯åæ§ä»¥ååºç¨ç¨åºçè¡¨ç¤ºç»´æ°ãä»è¿ä¸ªè§åº¦æ¥çï¼æä»¬è§£å³äºè¿ä¸ªé®é¢ï¼AI å»çåºç¨ä½æ¶éè¦è§£éï¼ä»¥åéè¦è§£éå°ä½ç§ç¨åº¦ï¼

##### **Interdisciplinary Expertise to Advance Equitable Explainable AI**
2406.18563v1 by Chloe R. Bennett, Heather Cole-Lewis, Stephanie Farquhar, Naama Haamel, Boris Babenko, Oran Lang, Mat Fleck, Ilana Traynis, Charles Lau, Ivor Horn, Courtney Lyles

The field of artificial intelligence (AI) is rapidly influencing health and
healthcare, but bias and poor performance persists for populations who face
widespread structural oppression. Previous work has clearly outlined the need
for more rigorous attention to data representativeness and model performance to
advance equity and reduce bias. However, there is an opportunity to also
improve the explainability of AI by leveraging best practices of social
epidemiology and health equity to help us develop hypotheses for associations
found. In this paper, we focus on explainable AI (XAI) and describe a framework
for interdisciplinary expert panel review to discuss and critically assess AI
model explanations from multiple perspectives and identify areas of bias and
directions for future research. We emphasize the importance of the
interdisciplinary expert panel to produce more accurate, equitable
interpretations which are historically and contextually informed.
Interdisciplinary panel discussions can help reduce bias, identify potential
confounders, and identify opportunities for additional research where there are
gaps in the literature. In turn, these insights can suggest opportunities for
AI model improvement.

æè¦ï¼äººå·¥æºæ§ (AI) é åæ­£å¿«éå½±é¿èå¥åº·èé«çä¿å¥ï¼ä½å°æ¼é¢è¨å»£æ³çµæ§æ§å£è¿«çäººç¾¤ä¾èªªï¼åè¦åä¸è¯è¡¨ç¾ä¾ç¶å­å¨ãååçç ç©¶å·²æ¸æ¥èªªæï¼éè¦æ´å´æ ¼å°æ³¨æè³æä»£è¡¨æ§åæ¨¡åæè½ï¼ä»¥ä¿é²å¬å¹³æ§ä¸¦æ¸å°åè¦ãç¶èï¼æåææ©æéééç¨ç¤¾ææµè¡çå­¸åå¥åº·å¬å¹³çæä½³å¯¦åï¼ä¾æ¹å AI çå¯è§£éæ§ï¼ä»¥å¹«å©æåéå°ç¼ç¾çéè¯æ§ï¼ç¼å±åè¨­ãå¨æ¬æä¸­ï¼æåå°æ³¨æ¼å¯è§£é AI (XAI)ï¼ä¸¦æè¿°ä¸åè·¨é åå°å®¶å°çµå¯©æ¥æ¶æ§ï¼ä»¥å¾å¤éè§é»è¨è«åæ¹å¤æ§è©ä¼° AI æ¨¡åçè§£éï¼ä¸¦æ¾åºåè¦é ååæªä¾ç ç©¶çæ¹åãæåå¼·èª¿è·¨é åå°å®¶å°çµå°æ¼ç¢çæ´æºç¢ºãå¬å¹³çè©®éè³ééè¦ï¼èéäºè©®éæ¯æ ¹ææ­·å²åèçµ¡èä¾çãè·¨é åå°çµè¨è«æå©æ¼æ¸å°åè¦ãæ¾åºæ½å¨çæ··æ·å ç´ ï¼ä¸¦å¨æç»ä¸­æç¼ºå£ææ¾åºé¡å¤ç ç©¶çæ©æãåéä¾ï¼éäºè¦è§£å¯ä»¥å»ºè­° AI æ¨¡åæ¹é²çæ©æã

##### **"It depends": Configuring AI to Improve Clinical Usefulness Across Contexts**
2407.11978v1 by Hubert D. ZajÄc, Jorge M. N. Ribeiro, Silvia Ingala, Simona Gentile, Ruth Wanjohi, Samuel N. Gitau, Jonathan F. Carlsen, Michael B. Nielsen, Tariq O. Andersen

Artificial Intelligence (AI) repeatedly match or outperform radiologists in
lab experiments. However, real-world implementations of radiological AI-based
systems are found to provide little to no clinical value. This paper explores
how to design AI for clinical usefulness in different contexts. We conducted 19
design sessions and design interventions with 13 radiologists from 7 clinical
sites in Denmark and Kenya, based on three iterations of a functional AI-based
prototype. Ten sociotechnical dependencies were identified as crucial for the
design of AI in radiology. We conceptualised four technical dimensions that
must be configured to the intended clinical context of use: AI functionality,
AI medical focus, AI decision threshold, and AI Explainability. We present four
design recommendations on how to address dependencies pertaining to the medical
knowledge, clinic type, user expertise level, patient context, and user
situation that condition the configuration of these technical dimensions.

æè¦ï¼äººå·¥æºæ§ï¼AIï¼å¨å¯¦é©å®¤å¯¦é©ä¸­ä¸æ·å°èæ¾å°ç§é«å¸«å¹æµæè¡¨ç¾å¾æ´åºè²ãç¶èï¼ç¼ç¾æ¾å°ç§ AI çºåºç¤ç³»çµ±çå¯¦éå·è¡å¹¾ä¹æ²ææä¾è¨åºå¹å¼ãæ¬ææ¢è¨å¦ä½çº AI è¨­è¨å¨ä¸åæå¢ä¸­è¨åºä¸çæç¨ãæåæ ¹æåè½æ§ AI çºåºç¤ååçä¸æ¬¡è¿­ä»£ï¼å¨ä¸¹éº¥åè¯äºç 7 åè¨åºå ´åè 13 ä½æ¾å°ç§é«å¸«é²è¡äº 19 æ¬¡è¨­è¨æè­°åè¨­è¨ä»å¥ãååç¤¾ææè¡ä¾è³´éä¿è¢«èªçºå°æ¼æ¾å°ç§ä¸­ AI çè¨­è¨è³ééè¦ãæåæ¦å¿µåäºååæè¡é¢åï¼å¿é æ ¹æé æçè¨åºä½¿ç¨æå¢é²è¡è¨­å®ï¼AI åè½ãAI é«çéé»ãAI æ±ºç­éæª»ï¼ä»¥å AI å¯è§£éæ§ãæåæåºåé è¨­è¨å»ºè­°ï¼èªªæå¦ä½èçèé«çç¥è­ãè¨ºæé¡åãä½¿ç¨èå°æ¥­ç¥è­ç­ç´ãæ£èæå¢ï¼ä»¥åå½±é¿éäºæè¡é¢åè¨­å®çä½¿ç¨èæå¢ç¸éçä¾è³´éä¿ã

##### **Improving Health Professionals' Onboarding with AI and XAI for Trustworthy Human-AI Collaborative Decision Making**
2405.16424v1 by Min Hun Lee, Silvana Xin Yi Choo, Shamala D/O Thilarajah

With advanced AI/ML, there has been growing research on explainable AI (XAI)
and studies on how humans interact with AI and XAI for effective human-AI
collaborative decision-making. However, we still have a lack of understanding
of how AI systems and XAI should be first presented to users without technical
backgrounds. In this paper, we present the findings of semi-structured
interviews with health professionals (n=12) and students (n=4) majoring in
medicine and health to study how to improve onboarding with AI and XAI. For the
interviews, we built upon human-AI interaction guidelines to create onboarding
materials of an AI system for stroke rehabilitation assessment and AI
explanations and introduce them to the participants. Our findings reveal that
beyond presenting traditional performance metrics on AI, participants desired
benchmark information, the practical benefits of AI, and interaction trials to
better contextualize AI performance, and refine the objectives and performance
of AI. Based on these findings, we highlight directions for improving
onboarding with AI and XAI and human-AI collaborative decision-making.

æè¦ï¼é¨èåé²ç AI/MLï¼å°å¯è§£é AI (XAI) çç ç©¶ä¸æ·å¢å ï¼ä»¥åéæ¼äººé¡å¦ä½è AI å XAI äºåä»¥é²è¡ææçäººå·¥æºæ§åä½æ±ºç­å¶å®ãç¶èï¼æåä»ç¶ç¼ºä¹å° AI ç³»çµ±å XAI æå¦ä½é¦ååç¾çµ¦æ²ææè¡èæ¯çç¨æ¶çäºè§£ãå¨æ¬æä¸­ï¼æåå±ç¤ºäºèé«çå°æ¥­äººå¡ (n=12) åä¸»ä¿®é«å­¸åå¥åº·çå­¸ç (n=4) é²è¡åçµæ§åè¨ªè«ççµæï¼ä»¥ç ç©¶å¦ä½æ¹å AI å XAI çå¥éãå°æ¼è¨ªè«ï¼æåå»ºç«å¨äººæ©äºåæºåä¹ä¸ï¼çºä¸­é¢¨åº·å¾©è©ä¼°å AI è§£éç AI ç³»çµ±åµå»ºå¥éææï¼ä¸¦å°å®åä»ç´¹çµ¦åèèãæåçç ç©¶çµæè¡¨æï¼é¤äºåç¾å³çµ±ç AI æ§è½ææ¨å¤ï¼åèèéå¸æåºåä¿¡æ¯ãAI çå¯¦éå¥½èä»¥åäº¤äºè©¦é©ï¼ä»¥æ´å¥½å°å° AI æ§è½æå¢åï¼ä¸¦å®å AI çç®æ¨åæ§è½ãæ ¹æéäºç¼ç¾ï¼æåå¼·èª¿äºæ¹é² AI å XAI ä»¥åäººæ©åä½æ±ºç­å¶å®çå¥éæ¹åã

##### **Exploring Nutritional Impact on Alzheimer's Mortality: An Explainable AI Approach**
2405.17502v1 by Ziming Liu, Longjian Liu, Robert E. Heidel, Xiaopeng Zhao

This article uses machine learning (ML) and explainable artificial
intelligence (XAI) techniques to investigate the relationship between
nutritional status and mortality rates associated with Alzheimers disease (AD).
The Third National Health and Nutrition Examination Survey (NHANES III)
database is employed for analysis. The random forest model is selected as the
base model for XAI analysis, and the Shapley Additive Explanations (SHAP)
method is used to assess feature importance. The results highlight significant
nutritional factors such as serum vitamin B12 and glycated hemoglobin. The
study demonstrates the effectiveness of random forests in predicting AD
mortality compared to other diseases. This research provides insights into the
impact of nutrition on AD and contributes to a deeper understanding of disease
progression.

æè¦ï¼æ¬æä½¿ç¨æ©å¨å­¸ç¿ (ML) åå¯è§£éäººå·¥æºæ§ (XAI) æè¡ä¾æ¢è¨çé¤çæ³èé¿è²æµ·é»ç (AD) ç¸éçæ­»äº¡çä¹éçéä¿ãæ¡ç¨ç¬¬ä¸æ¬¡å¨åå¥åº·èçé¤æª¢æ¥èª¿æ¥ (NHANES III) è³æåº«é²è¡åæãé¸æé¨æ©æ£®ææ¨¡åä½çº XAI åæçåºç¤æ¨¡åï¼ä¸¦ä½¿ç¨ Shapley Additive Explanations (SHAP) æ¹æ³ä¾è©ä¼°ç¹å¾µéè¦æ§ãçµæçªé¡¯äºéè¦ççé¤å ç´ ï¼ä¾å¦è¡æ¸ç¶­çç´  B12 åç³åè¡ç´èç½ãè©²ç ç©¶è­æäºé¨æ©æ£®æå¨é æ¸¬ AD æ­»äº¡çæ¹é¢ç¸è¼æ¼å¶ä»ç¾ççæææ§ãæ¬ç ç©¶æä¾äºçé¤å° AD çå½±é¿çè¦è§£ï¼ä¸¦æå©æ¼æ´æ·±å¥å°äºè§£ç¾ççé²å±ã

##### **Explainable AI Enhances Glaucoma Referrals, Yet the Human-AI Team Still Falls Short of the AI Alone**
2407.11974v1 by Catalina Gomez, Ruolin Wang, Katharina Breininger, Corinne Casey, Chris Bradley, Mitchell Pavlak, Alex Pham, Jithin Yohannan, Mathias Unberath

Primary care providers are vital for initial triage and referrals to
specialty care. In glaucoma, asymptomatic and fast progression can lead to
vision loss, necessitating timely referrals to specialists. However, primary
eye care providers may not identify urgent cases, potentially delaying care.
Artificial Intelligence (AI) offering explanations could enhance their referral
decisions. We investigate how various AI explanations help providers
distinguish between patients needing immediate or non-urgent specialist
referrals. We built explainable AI algorithms to predict glaucoma surgery needs
from routine eyecare data as a proxy for identifying high-risk patients. We
incorporated intrinsic and post-hoc explainability and conducted an online
study with optometrists to assess human-AI team performance, measuring referral
accuracy and analyzing interactions with AI, including agreement rates, task
time, and user experience perceptions. AI support enhanced referral accuracy
among 87 participants (59.9%/50.8% with/without AI), though Human-AI teams
underperformed compared to AI alone. Participants believed they included AI
advice more when using the intrinsic model, and perceived it more useful and
promising. Without explanations, deviations from AI recommendations increased.
AI support did not increase workload, confidence, and trust, but reduced
challenges. On a separate test set, our black-box and intrinsic models achieved
an accuracy of 77% and 71%, respectively, in predicting surgical outcomes. We
identify opportunities of human-AI teaming for glaucoma management in primary
eye care, noting that while AI enhances referral accuracy, it also shows a
performance gap compared to AI alone, even with explanations. Human involvement
remains essential in medical decision making, underscoring the need for future
research to optimize collaboration, ensuring positive experiences and safe AI
use.

æè¦ï¼<paragraph>åç´ä¿å¥æä¾èå°æ¼æåçåæµåè½è¨ºå°å°ç§ç§è­·è³ééè¦ãå¨éåç¼çææ³ä¸ï¼ç¡ççä¸å¿«éæ¡åå¯è½å°è´è¦ååªå¤±ï¼å æ­¤éè¦åæè½è¨ºçµ¦å°å®¶ãç¶èï¼åç´ç¼ç§ä¿å¥æä¾èå¯è½ç¡æ³è­å¥ç·æ¥ææ³ï¼å¯è½æå»¶èª¤ç§è­·ãæä¾è§£éçäººå·¥æºæ§ (AI) å¯ä»¥å å¼·ä»åçè½è¨ºæ±ºç­ãæåç ç©¶åç¨® AI è§£éå¦ä½å¹«å©æä¾èååéè¦ç«å³æéç·æ¥å°ç§è½è¨ºçæ£èãæåå»ºç«äºè§£éæ§ AI æ¼ç®æ³ï¼ä»¥å¾ä¾è¡ç¼ç§è­·çè³æé æ¸¬éåç¼æè¡éæ±ï¼ä½çºè­å¥é«é¢¨éªæ£èçä»£çãæåç´å¥äºå§å¨åäºå¾è§£éæ§ï¼ä¸¦èé©åå¸«é²è¡äºä¸é ç·ä¸ç ç©¶ï¼ä»¥è©ä¼°äººæ©åéçè¡¨ç¾ï¼è¡¡éè½è¨ºæºç¢ºåº¦ä¸¦åæè AI çäºåï¼åæ¬åæçãä»»åæéåä½¿ç¨èé«é©æç¥ãå¨ 87 ååèèä¸­ï¼AI æ¯æ´æé«äºè½è¨ºæºç¢ºåº¦ï¼ä½¿ç¨ AI/æªä½¿ç¨çæ¯ä¾çº 59.9%/50.8%ï¼ï¼åç®¡äººæ©åéçè¡¨ç¾ä¸å¦å®ç¨ä½¿ç¨ AIãåèèèªçºä»åå¨ä½¿ç¨å§å¨æ¨¡åææ´å¤å°ç´å¥äº AI å»ºè­°ï¼ä¸¦èªçºå®æ´æç¨ä¸æ´æå¸æãæ²æè§£éï¼AI å»ºè­°çåå·®æå¢å ãAI æ¯æ´ä¸¦æªå¢å å·¥ä½éãä¿¡å¿åä¿¡ä»»ï¼ä½æ¸å°äºææ°ãå¨ä¸åå®ç¨çæ¸¬è©¦éä¸­ï¼æåçé»çå­åå§å¨æ¨¡åå¨é æ¸¬æè¡çµææ¹é¢åå¥éå°äº 77% å 71% çæºç¢ºåº¦ãæåæ¾åºå¨åç´ç¼ç§ä¿å¥ä¸­ï¼äººæ©åéåä½ç®¡çéåç¼çæ©æï¼ä¸¦æ³¨æå°éç¶ AI æé«äºè½è¨ºæºç¢ºåº¦ï¼ä½å³ä½¿æè§£éï¼å®ä¹é¡¯ç¤ºåºèå®ç¨ä½¿ç¨ AI ç¸æ¯çæè½å·®è·ãäººé¡åèå¨é«çæ±ºç­ä¸­ä»ç¶è³ééè¦ï¼éå¼·èª¿äºæªä¾ç ç©¶åªååä½ãç¢ºä¿æ­£é¢ç¶é©åå®å¨ä½¿ç¨ AI çå¿è¦æ§ã</paragraph>

##### **Decoding Decision Reasoning: A Counterfactual-Powered Model for Knowledge Discovery**
2406.18552v1 by Yingying Fang, Zihao Jin, Xiaodan Xing, Simon Walsh, Guang Yang

In medical imaging, particularly in early disease detection and prognosis
tasks, discerning the rationale behind an AI model's predictions is crucial for
evaluating the reliability of its decisions. Conventional explanation methods
face challenges in identifying discernible decisive features in medical image
classifications, where discriminative features are subtle or not immediately
apparent. To bridge this gap, we propose an explainable model that is equipped
with both decision reasoning and feature identification capabilities. Our
approach not only detects influential image patterns but also uncovers the
decisive features that drive the model's final predictions. By implementing our
method, we can efficiently identify and visualise class-specific features
leveraged by the data-driven model, providing insights into the decision-making
processes of deep learning models. We validated our model in the demanding
realm of medical prognosis task, demonstrating its efficacy and potential in
enhancing the reliability of AI in healthcare and in discovering new knowledge
in diseases where prognostic understanding is limited.

æè¦ï¼å¨é«å­¸å½±åä¸­ï¼ç¹å¥æ¯å¨æ©æç¾çæª¢æ¸¬åé å¾ä»»åä¸­ï¼è¾¨å¥ AI æ¨¡åé æ¸¬èå¾çåçå°æ¼è©ä¼°å¶æ±ºç­çå¯é æ§è³ééè¦ãå³çµ±çè§£éæ¹æ³å¨è­å¥é«å­¸å½±ååé¡ä¸­å¯è­å¥çæ±ºå®æ§ç¹å¾µæé¢è¨ææ°ï¼å¶ä¸­åå¥æ§ç¹å¾µå¾å¾®å¦æä¸¦ä¸æé¡¯ãçºäºå½åéä¸å·®è·ï¼æåæåºäºä¸åå¯è§£éçæ¨¡åï¼è©²æ¨¡åå·åæ±ºç­æ¨çåç¹å¾µè­å¥è½åãæåçåæ³ä¸åæª¢æ¸¬æå½±é¿åçå½±åæ¨¡å¼ï¼éæ­ç¤ºäºæ¨åæ¨¡åæçµé æ¸¬çæ±ºå®æ§ç¹å¾µãééå¯¦æ½æåçæ¨¡åï¼æåå¯ä»¥ææè­å¥åè¦è¦ºåç±æ¸æé©åæ¨¡åå©ç¨çé¡ç¹å®ç¹å¾µï¼å¾èæ·±å¥äºè§£æ·±åº¦å­¸ç¿æ¨¡åçæ±ºç­éç¨ãæåå¨è¦æ±å´æ ¼çé«å­¸é å¾ä»»åé åé©è­äºæåçæ¨¡åï¼å±ç¤ºäºå¶å¨æé« AI å¨é«çä¿å¥ä¸­çå¯é æ§åç¼ç¾é å¾çè§£åéç¾ççæ°ç¥è­æ¹é¢çåæåæ½åã

##### **The Role of Emotions in Informational Support Question-Response Pairs in Online Health Communities: A Multimodal Deep Learning Approach**
2405.13099v1 by Mohsen Jozani, Jason A. Williams, Ahmed Aleroud, Sarbottam Bhagat

This study explores the relationship between informational support seeking
questions, responses, and helpfulness ratings in online health communities. We
created a labeled data set of question-response pairs and developed multimodal
machine learning and deep learning models to reliably predict informational
support questions and responses. We employed explainable AI to reveal the
emotions embedded in informational support exchanges, demonstrating the
importance of emotion in providing informational support. This complex
interplay between emotional and informational support has not been previously
researched. The study refines social support theory and lays the groundwork for
the development of user decision aids. Further implications are discussed.

æè¦ï¼æ¬ç ç©¶æ¢è¨ç·ä¸å¥åº·ç¤¾ç¾¤ä¸­å°æ±è³è¨æ¯æçåé¡ãåæï¼ä»¥åæå¹«å©çè©åä¹éçéä¿ãæåå»ºç«äºä¸çµæ¨è¨çåç­éå°è³æéï¼ä¸¦éç¼äºå¤æ¨¡ææ©å¨å­¸ç¿åæ·±åº¦å­¸ç¿æ¨¡åï¼ä»¥å¯é å°é æ¸¬è³è¨æ¯æåé¡ååæãæåæ¡ç¨å¯è§£éç AI ä¾æ­ç¤ºè³è¨æ¯æäº¤æµä¸­èå«çæç·ï¼è­ææç·å¨æä¾è³è¨æ¯æä¸­çéè¦æ§ãéç¨®æç·æ¯æåè³è¨æ¯æä¹éçè¤éäº¤äºä½ç¨ä»¥åä¸¦æªè¢«ç ç©¶éãæ¬ç ç©¶æ¹é²äºç¤¾ææ¯æçè«ï¼ä¸¦çºä½¿ç¨èæ±ºç­è¼å©å·¥å·çéç¼å¥ å®äºåºç¤ãè¨è«äºé²ä¸æ­¥çå½±é¿ã

##### **ChatGPT in Classrooms: Transforming Challenges into Opportunities in Education**
2405.10645v1 by Harris Bin Munawar, Nikolaos Misirlis

In the era of exponential technology growth, one unexpected guest has claimed
a seat in classrooms worldwide, Artificial Intelligence. Generative AI, such as
ChatGPT, promises a revolution in education, yet it arrives with a double-edged
sword. Its potential for personalized learning is offset by issues of cheating,
inaccuracies, and educators struggling to incorporate it effectively into their
lesson design. We are standing on the brink of this educational frontier, and
it is clear that we need to navigate this terrain with a lot of care. This is a
major challenge that could undermine the integrity and value of our educational
process. So, how can we turn these challenges into opportunities? When used
inappropriately, AI tools can become the perfect tool for the cut copy paste
mentality, and quickly begin to corrode critical thinking, creativity, and deep
understanding, the most important skills in our rapidly changing world.
Teachers feel that they are not equipped to leverage this technology, widening
the digital divide among educators and institutions. Addressing these concerns
calls for an in depth research approach. We will employ empirical research,
drawing on the Technology Acceptance Model, to assess the attitudes toward
generative AI among educators and students. Understanding their perceptions,
usage patterns, and hurdles is the first crucial step in creating an effective
solution. The present study will be used as a process manual for future
researchers to apply, running their own data, based on the steps explained here

æè¦ï¼å¨ç§æé£éç¼å±çæä»£ï¼ä¸ä½æå¤çè¨ªå®¢å·²å¨å¨çæå®¤ä¸­ä½æä¸å¸­ä¹å°ï¼é£å°±æ¯äººå·¥æºæ§ãçæå¼ AIï¼ä¾å¦ ChatGPTï¼æ¿è«¾å¨æè²é åæèµ·ä¸å ´é©å½ï¼ä½å®å»æ¯ä¸æéé¢åãå®å¨åäººåå­¸ç¿æ¹é¢çæ½åï¼å»å ä½å¼ãä¸æºç¢ºä»¥åæè²å·¥ä½èé£ä»¥å°å¶ææèå¥æå­¸è¨­è¨ç­åé¡èæµé·ãæåæ­£ç«å¨éæè²åæ²¿çéç·£ï¼é¡¯ç¶æåéè¦éå¸¸å°å¿å°æ¢ç´¢éçé åãéæ¯ä¸åéå¤§çææ°ï¼å¯è½ææå®³æåæè²éç¨çå®æ´æ§åå¹å¼ãé£éº¼ï¼æåå¦ä½å°éäºææ°è½åçºæ©éï¼ç¶ä¸é©ç¶å°ä½¿ç¨æï¼AI å·¥å·å¯è½ææçºè¤è£½è²¼ä¸å¿æçå®ç¾å·¥å·ï¼ä¸¦è¿éèèæ¹å¤æ§æç¶­ãåµé ååæ·±å¥çè§£ï¼éäºé½æ¯æåå¿«éè®åçä¸çä¸­æéè¦çæè½ãæå¸«åè¦ºå¾ä»åæ²æè½åå©ç¨éé æè¡ï¼éæ´å¤§äºæè²å·¥ä½èåæ©æ§ä¹éçæ¸ä½é´»æºãè§£æ±ºéäºåé¡éè¦æ·±å¥çç ç©¶æ¹æ³ãæåå°æ¡ç¨å¯¦è­ç ç©¶ï¼åéæè¡æ¥åæ¨¡åï¼ä¾è©ä¼°æè²å·¥ä½èåå­¸çå°çæå¼ AI çæåº¦ãäºè§£ä»åççæ³ãä½¿ç¨æ¨¡å¼åéç¤æ¯åµé ææè§£æ±ºæ¹æ¡çç¬¬ä¸åééµæ­¥é©ãæ¬ç ç©¶å°ä½çºæªä¾ç ç©¶äººå¡æç¨çæµç¨æåï¼æ ¹ææ­¤èèªªæçæ­¥é©éè¡ä»åèªå·±çæ¸æ

##### **Evaluating the Explainable AI Method Grad-CAM for Breath Classification on Newborn Time Series Data**
2405.07590v1 by Camelia Oprea, Mike GrÃ¼ne, Mateusz Buglowski, Lena Olivier, Thorsten Orlikowsky, Stefan Kowalewski, Mark Schoberer, AndrÃ© Stollenwerk

With the digitalization of health care systems, artificial intelligence
becomes more present in medicine. Especially machine learning shows great
potential for complex tasks such as time series classification, usually at the
cost of transparency and comprehensibility. This leads to a lack of trust by
humans and thus hinders its active usage. Explainable artificial intelligence
tries to close this gap by providing insight into the decision-making process,
the actual usefulness of its different methods is however unclear. This paper
proposes a user study based evaluation of the explanation method Grad-CAM with
application to a neural network for the classification of breaths in time
series neonatal ventilation data. We present the perceived usefulness of the
explainability method by different stakeholders, exposing the difficulty to
achieve actual transparency and the wish for more in-depth explanations by many
of the participants.

æè¦ï¼é¨èé«çä¿å¥ç³»çµ±çæ¸ä½åï¼äººå·¥æºæ§å¨é«å­¸é åä¸­è®å¾æ´å æ®åãç¹å¥æ¯æ©å¨å­¸ç¿å¨æéåºååé¡ç­è¤éä»»åä¸­å±ç¾åºæ¥µå¤§çæ½åï¼ä½éå¸¸æ¯ä»¥éæåº¦åå¯çè§£æ§çºä»£å¹ãéå°è´äººé¡ç¼ºä¹ä¿¡ä»»ï¼å¾èé»ç¤äºå¶ç©æ¥µä½¿ç¨ãå¯è§£éçäººå·¥æºæ§è©¦åééæä¾å°æ±ºç­éç¨çæ´å¯ä¾å½è£éä¸å·®è·ï¼ä½å¶ä¸åæ¹æ³çå¯¦éæç¨å°ä¸æ¸æ¥ãæ¬ææåºäºä¸ååºæ¼ä½¿ç¨èç ç©¶çè©ä¼°ï¼å¶ä¸­åå«äº Grad-CAM è§£éæ¹æ³ï¼ä¸¦å°å¶æç¨æ¼ç¥ç¶ç¶²è·¯ä»¥åé¡æéåºåæ°çåå¼å¸æ¸æä¸­çå¼å¸ãæåå±ç¤ºäºä¸åå©çç¸éèå°å¯è§£éæ§æ¹æ³çæç¥æç¨ï¼æ­ç¤ºäºå¯¦ç¾å¯¦ééæåº¦çé£åº¦ï¼ä»¥åè¨±å¤åèèå¸æç²å¾æ´æ·±å¥çè§£éã

##### **XAI4LLM. Let Machine Learning Models and LLMs Collaborate for Enhanced In-Context Learning in Healthcare**
2405.06270v3 by Fatemeh Nazary, Yashar Deldjoo, Tommaso Di Noia, Eugenio di Sciascio

The integration of Large Language Models (LLMs) into healthcare diagnostics
offers a promising avenue for clinical decision-making. This study outlines the
development of a novel method for zero-shot/few-shot in-context learning (ICL)
by integrating medical domain knowledge using a multi-layered structured
prompt. We also explore the efficacy of two communication styles between the
user and LLMs: the Numerical Conversational (NC) style, which processes data
incrementally, and the Natural Language Single-Turn (NL-ST) style, which
employs long narrative prompts.
  Our study systematically evaluates the diagnostic accuracy and risk factors,
including gender bias and false negative rates, using a dataset of 920 patient
records in various few-shot scenarios. Results indicate that traditional
clinical machine learning (ML) models generally outperform LLMs in zero-shot
and few-shot settings. However, the performance gap narrows significantly when
employing few-shot examples alongside effective explainable AI (XAI) methods as
sources of domain knowledge. Moreover, with sufficient time and an increased
number of examples, the conversational style (NC) nearly matches the
performance of ML models. Most notably, LLMs demonstrate comparable or superior
cost-sensitive accuracy relative to ML models.
  This research confirms that, with appropriate domain knowledge and tailored
communication strategies, LLMs can significantly enhance diagnostic processes.
The findings highlight the importance of optimizing the number of training
examples and communication styles to improve accuracy and reduce biases in LLM
applications.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) èé«çè¨ºæ·æ´å
çºè¨åºæ±ºç­æä¾äºä¸åæåæ¯çéå¾ãæ¬ç ç©¶æ¦è¿°äºä¸ç¨®æ°ç©æ¹æ³çéç¼ï¼ç¨æ¼é¶æ¬¡å­¸ç¿/å°éå­¸ç¿æå¢å­¸ç¿ (ICL)ï¼æ¹æ³æ¯ä½¿ç¨å¤å±¤çµæ§åæç¤ºæ´åé«çé åç¥è­ãæåéæ¢è¨äºä½¿ç¨èè LLM ä¹éå©ç¨®æºéæ¹å¼çåæï¼æ¸å¼å°è©± (NC) æ¹å¼ï¼å®æéæ­¥èçè³æï¼ä»¥åèªç¶èªè¨å®åå (NL-ST) æ¹å¼ï¼å®æä½¿ç¨é·ç¯æäºæç¤ºã
æåçç ç©¶ç³»çµ±æ§å°è©ä¼°äºè¨ºæ·æºç¢ºæ§åé¢¨éªå å­ï¼åæ¬æ§å¥åè¦ååé°æ§çï¼ä½¿ç¨äºä¸ååå« 920 åæ£èè¨éçè³æéï¼æ¡ç¨åç¨®å°éå­¸ç¿æå¢ãçµæè¡¨æï¼å³çµ±çè¨åºæ©å¨å­¸ç¿ (ML) æ¨¡åéå¸¸å¨é¶æ¬¡å­¸ç¿åå°éå­¸ç¿è¨­å®ä¸­è¡¨ç¾åªæ¼ LLMãç¶èï¼ç¶ä½¿ç¨å°éå­¸ç¿ç¯ä¾ä»¥åææçå¯è§£é AI (XAI) æ¹æ³ä½çºé åç¥è­ä¾æºæï¼æè½å·®è·æé¡¯èç¸®å°ãæ­¤å¤ï¼é¨èæéåè¶³åç¯ä¾æ¸éå¢å ï¼å°è©±æ¹å¼ (NC) å¹¾ä¹å¯ä»¥åª²ç¾ ML æ¨¡åçæè½ãæå¼å¾æ³¨æçæ¯ï¼LLM ç¸å°æ¼ ML æ¨¡åå±ç¾åºç¸ç¶ææ´ä½³çææ¬æææºç¢ºåº¦ã
æ¬ç ç©¶è­å¯¦ï¼ééé©ç¶çé åç¥è­åéèº«æé çæºéç­ç¥ï¼LLM å¯ä»¥é¡¯èå¢å¼·è¨ºæ·ç¨åºãéäºç¼ç¾çªé¡¯äºæä½³åè¨ç·´ç¯ä¾æ¸éåæºéæ¹å¼çéè¦æ§ï¼ä»¥æé«æºç¢ºåº¦ä¸¦æ¸å° LLM æç¨ä¸­çåå·®ã

##### **To Trust or Not to Trust: Towards a novel approach to measure trust for XAI systems**
2405.05766v1 by Miquel MirÃ³-Nicolau, Gabriel MoyÃ -Alcover, Antoni Jaume-i-CapÃ³, Manuel GonzÃ¡lez-Hidalgo, Maria Gemma Sempere Campello, Juan Antonio Palmer Sancho

The increasing reliance on Deep Learning models, combined with their inherent
lack of transparency, has spurred the development of a novel field of study
known as eXplainable AI (XAI) methods. These methods seek to enhance the trust
of end-users in automated systems by providing insights into the rationale
behind their decisions. This paper presents a novel approach for measuring user
trust in XAI systems, allowing their refinement. Our proposed metric combines
both performance metrics and trust indicators from an objective perspective. To
validate this novel methodology, we conducted a case study in a realistic
medical scenario: the usage of XAI system for the detection of pneumonia from
x-ray images.

æè¦ï¼é¨èå°æ·±åº¦å­¸ç¿æ¨¡åä¾è³´æ§çå¢å ï¼å ä¸å¶åºæçéæåº¦ä¸è¶³ï¼ä¿ä½¿ä¸åæ°çç ç©¶é åç¼å±ï¼ç¨±çºå¯è§£é AI (XAI) æ¹æ³ãéäºæ¹æ³æ¨å¨ééæ·±å¥äºè§£æ±ºç­èå¾çåçï¼ä¾æåæçµä½¿ç¨èå°èªååç³»çµ±çä¿¡è³´ãæ¬ææåºäºä¸ç¨®è¡¡éä½¿ç¨èå° XAI ç³»çµ±ä¿¡è³´åº¦çæ°ç©æ¹æ³ï¼åè¨±å°å¶é²è¡æ¹é²ãæåæåºçææ¨çµåäºå®¢è§è§é»ä¸çæè½ææ¨åä¿¡è³´ææ¨ãçºäºé©è­éåæ°ç©çæ¹æ³ï¼æåå¨ä¸åçå¯¦çé«çå ´æ¯ä¸­é²è¡äºä¸åæ¡ä¾ç ç©¶ï¼ä½¿ç¨ XAI ç³»çµ±å¾ X åå½±åä¸­åµæ¸¬èºçã

##### **Region-specific Risk Quantification for Interpretable Prognosis of COVID-19**
2405.02815v1 by Zhusi Zhong, Jie Li, Zhuoqi Ma, Scott Collins, Harrison Bai, Paul Zhang, Terrance Healey, Xinbo Gao, Michael K. Atalay, Zhicheng Jiao

The COVID-19 pandemic has strained global public health, necessitating
accurate diagnosis and intervention to control disease spread and reduce
mortality rates. This paper introduces an interpretable deep survival
prediction model designed specifically for improved understanding and trust in
COVID-19 prognosis using chest X-ray (CXR) images. By integrating a large-scale
pretrained image encoder, Risk-specific Grad-CAM, and anatomical region
detection techniques, our approach produces regional interpretable outcomes
that effectively capture essential disease features while focusing on rare but
critical abnormal regions. Our model's predictive results provide enhanced
clarity and transparency through risk area localization, enabling clinicians to
make informed decisions regarding COVID-19 diagnosis with better understanding
of prognostic insights. We evaluate the proposed method on a multi-center
survival dataset and demonstrate its effectiveness via quantitative and
qualitative assessments, achieving superior C-indexes (0.764 and 0.727) and
time-dependent AUCs (0.799 and 0.691). These results suggest that our
explainable deep survival prediction model surpasses traditional survival
analysis methods in risk prediction, improving interpretability for clinical
decision making and enhancing AI system trustworthiness.

æè¦ï¼COVID-19 ç«æå°å¨çå¬å±è¡çé æå£åï¼å¿é é²è¡æºç¢ºçè¨ºæ·åå¹²é ï¼ä»¥æ§å¶ç¾çå³æ­ä¸¦éä½æ­»äº¡çãæ¬æä»ç´¹äºä¸åå¯è§£éçæ·±åº¦çå­é æ¸¬æ¨¡åï¼å°éè¨­è¨ç¨æ¼ééè¸é¨ X å (CXR) å½±åæ¹åå° COVID-19 é å¾ççè§£åä¿¡è³´ãééæ´åå¤§è¦æ¨¡é è¨ç·´å½±åç·¨ç¢¼å¨ãé¢¨éªç¹å® Grad-CAM åè§£ååååµæ¸¬æè¡ï¼æåçåæ³ç¢çååå¯è§£éççµæï¼ææææå¿è¦çç¾çç¹å¾µï¼åæå°æ³¨æ¼ç½è¦ä½ééµçç°å¸¸ååãæåçæ¨¡åé æ¸¬çµæééé¢¨éªååå®ä½æä¾å¢å¼·çæ¸æ°åº¦åéæåº¦ï¼è®è¨åºé«çè½å¤ å¨æ´äºè§£é å¾è¦è§£çææ³ä¸ï¼å°± COVID-19 è¨ºæ·ååºææºçæ±ºç­ãæåå¨å¤ä¸­å¿çå­è³æéä¸è©ä¼°ææåºçæ¹æ³ï¼ä¸¦éééååè³ªåè©ä¼°è­æå¶æææ§ï¼éå°åªç°ç C ææ¸ï¼0.764 å 0.727ï¼åæéç¸é AUCï¼0.799 å 0.691ï¼ãéäºçµæè¡¨æï¼æåå¯è§£éçæ·±åº¦çå­é æ¸¬æ¨¡åå¨é¢¨éªé æ¸¬æ¹é¢è¶è¶å³çµ±ççå­åææ¹æ³ï¼æåè¨åºæ±ºç­çè§£éæ§ï¼ä¸¦å¢å¼· AI ç³»çµ±çä¿¡è³´åº¦ã

##### **Rad4XCNN: a new agnostic method for post-hoc global explanation of CNN-derived features by means of radiomics**
2405.02334v2 by Francesco Prinzi, Carmelo Militello, Calogero Zarcaro, Tommaso Vincenzo Bartolotta, Salvatore Gaglio, Salvatore Vitabile

In recent years, machine learning-based clinical decision support systems
(CDSS) have played a key role in the analysis of several medical conditions.
Despite their promising capabilities, the lack of transparency in AI models
poses significant challenges, particularly in medical contexts where
reliability is a mandatory aspect. However, it appears that explainability is
inversely proportional to accuracy. For this reason, achieving transparency
without compromising predictive accuracy remains a key challenge. This paper
presents a novel method, namely Rad4XCNN, to enhance the predictive power of
CNN-derived features with the inherent interpretability of radiomic features.
Rad4XCNN diverges from conventional methods based on saliency maps, by
associating intelligible meaning to CNN-derived features by means of Radiomics,
offering new perspectives on explanation methods beyond visualization maps.
Using a breast cancer classification task as a case study, we evaluated
Rad4XCNN on ultrasound imaging datasets, including an online dataset and two
in-house datasets for internal and external validation. Some key results are:
i) CNN-derived features guarantee more robust accuracy when compared against
ViT-derived and radiomic features; ii) conventional visualization map methods
for explanation present several pitfalls; iii) Rad4XCNN does not sacrifice
model accuracy for their explainability; iv) Rad4XCNN provides a global
explanation enabling the physician to extract global insights and findings. Our
method can mitigate some concerns related to the explainability-accuracy
trade-off. This study highlighted the importance of proposing new methods for
model explanation without affecting their accuracy.

æè¦ï¼<paragraph>è¿å¹´æ¥ï¼åºäºæºå¨å­¦ä¹ çä¸´åºå³ç­æ¯æç³»ç» (CDSS) å¨å¤ç§ç¾ççåæä¸­æ®æ¼äºå³é®è§è²ãå°½ç®¡å®ä»¬å·æå¹¿éçåæ¯ï¼ä½ AI æ¨¡åç¼ºä¹éæåº¦ï¼å°¤å¶å¨å»çé¢åï¼å¯é æ§æ¯å¼ºå¶æ§æ¹é¢ï¼è¿å¸¦æ¥äºéå¤§ææãç¶èï¼è§£éæ§ä¼¼ä¹ä¸åç¡®æ§æåæ¯ãå æ­¤ï¼å¨ä¸å½±åé¢æµåç¡®æ§çæåµä¸å®ç°éæåº¦ä»ç¶æ¯ä¸ä¸ªå³é®ææãæ¬ææåºäºä¸ç§æ°æ¹æ³ï¼å³ Rad4XCNNï¼ä»¥éè¿æ¾å°ç»å­¦çåå¨å¯è§£éæ§æ¥å¢å¼º CNN è¡çç¹å¾çé¢æµè½åãRad4XCNN éè¿æ¾å°ç»å­¦å°å¯çè§£çå«ä¹ä¸ CNN è¡çç¹å¾å³èèµ·æ¥ï¼ä»èåç¦»äºåºäºæ¾çæ§å¾çä¼ ç»æ¹æ³ï¼ä¸ºè¶è¶å¯è§åå¾çè§£éæ¹æ³æä¾äºæ°çè§è§ãä½¿ç¨ä¹³èºçåç±»ä»»å¡ä½ä¸ºæ¡ä¾ç ç©¶ï¼æä»¬å¨è¶å£°æåæ°æ®éä¸è¯ä¼°äº Rad4XCNNï¼åæ¬ä¸ä¸ªå¨çº¿æ°æ®éåä¸¤ä¸ªç¨äºåé¨åå¤é¨éªè¯çåé¨æ°æ®éãä¸äºå³é®ç»ææ¯ï¼i) ä¸ ViT è¡çåæ¾å°ç»å­¦ç¹å¾ç¸æ¯ï¼CNN è¡çç¹å¾ä¿è¯äºæ´ç¨³å¥çåç¡®æ§ï¼ii) ç¨äºè§£éçä¼ ç»å¯è§åå¾æ¹æ³å­å¨ä¸äºç¼ºé·ï¼iii) Rad4XCNN ä¸ä¼ä¸ºäºå¯è§£éæ§èçºç²æ¨¡ååç¡®æ§ï¼iv) Rad4XCNN æä¾å¨å±è§£éï¼ä½¿å»çè½å¤æåå¨å±è§è§£ååç°ãæä»¬çæ¹æ³å¯ä»¥åè½»ä¸äºä¸å¯è§£éæ§-åç¡®æ§æè¡¡ç¸å³çæå¿§ãæ¬ç ç©¶å¼ºè°äºæåºæ°æ¹æ³æ¥è§£éæ¨¡åèä¸å½±åå¶åç¡®æ§çéè¦æ§ã</paragraph>

##### **Attributing Responsibility in AI-Induced Incidents: A Computational Reflective Equilibrium Framework for Accountability**
2404.16957v1 by Yunfei Ge, Quanyan Zhu

The pervasive integration of Artificial Intelligence (AI) has introduced
complex challenges in the responsibility and accountability in the event of
incidents involving AI-enabled systems. The interconnectivity of these systems,
ethical concerns of AI-induced incidents, coupled with uncertainties in AI
technology and the absence of corresponding regulations, have made traditional
responsibility attribution challenging. To this end, this work proposes a
Computational Reflective Equilibrium (CRE) approach to establish a coherent and
ethically acceptable responsibility attribution framework for all stakeholders.
The computational approach provides a structured analysis that overcomes the
limitations of conceptual approaches in dealing with dynamic and multifaceted
scenarios, showcasing the framework's explainability, coherence, and adaptivity
properties in the responsibility attribution process. We examine the pivotal
role of the initial activation level associated with claims in equilibrium
computation. Using an AI-assisted medical decision-support system as a case
study, we illustrate how different initializations lead to diverse
responsibility distributions. The framework offers valuable insights into
accountability in AI-induced incidents, facilitating the development of a
sustainable and resilient system through continuous monitoring, revision, and
reflection.

æè¦ï¼é¨èäººå·¥æºæ§ (AI) çæ®åæ´åï¼å¨æ¶å AI é©åç³»çµ±çäºæä¸­ï¼è²¬ä»»åç¾©åæ­¸å±¬ç¢çäºè¤éçææ°ãéäºç³»çµ±çäºé£æ§ãAI å¼ç¼äºæçå«çåé¡ï¼å ä¸ AI æè¡çä¸ç¢ºå®æ§åç¼ºä¹ç¸ææ³è¦ï¼ä½¿å¾å³çµ±è²¬ä»»æ­¸å±¬é¢è¨ææ°ãçºæ­¤ï¼æ¬ç ç©¶æåºäºä¸ç¨®è¨ç®åæåè¡¡ (CRE) æ¹æ³ï¼ä»¥å»ºç«ä¸åé£è²«ä¸å¨å«çä¸å¯æ¥åçè²¬ä»»æ­¸å±¬æ¶æ§ï¼é©ç¨æ¼ææå©å®³éä¿äººãè¨ç®æ¹æ³æä¾äºçµæ§åçåæï¼åæäºæ¦å¿µæ¹æ³å¨èçåæä¸å¤é¢åæå¢æçéå¶ï¼å±ç¤ºäºè©²æ¶æ§å¨è²¬ä»»æ­¸å±¬éç¨ä¸­å·åçå¯è§£éæ§ãé£è²«æ§åé©ææ§ãæåæ¢è¨äºèåè¡¡è¨ç®ä¸­ç´¢è³ ç¸éçåå§ååå±¤ç´çééµä½ç¨ãæåä»¥ AI è¼å©é«çæ±ºç­æ¯æ´ç³»çµ±çºæ¡ä¾ç ç©¶ï¼èªªæä¸åçåå§åå¦ä½å°è´ä¸åçè²¬ä»»åéãè©²æ¶æ§æä¾äºå° AI å¼ç¼äºæä¸­åè²¬å¶çå¯¶è²´è¦è§£ï¼ééæçºç£æ§ãä¿®è¨ååæï¼ä¿é²äºæ°¸çºä¸æéæ§çç³»çµ±ç¼å±ã

##### **Explainable AI for Fair Sepsis Mortality Predictive Model**
2404.13139v1 by Chia-Hsuan Chang, Xiaoyang Wang, Christopher C. Yang

Artificial intelligence supports healthcare professionals with predictive
modeling, greatly transforming clinical decision-making. This study addresses
the crucial need for fairness and explainability in AI applications within
healthcare to ensure equitable outcomes across diverse patient demographics. By
focusing on the predictive modeling of sepsis-related mortality, we propose a
method that learns a performance-optimized predictive model and then employs
the transfer learning process to produce a model with better fairness. Our
method also introduces a novel permutation-based feature importance algorithm
aiming at elucidating the contribution of each feature in enhancing fairness on
predictions. Unlike existing explainability methods concentrating on explaining
feature contribution to predictive performance, our proposed method uniquely
bridges the gap in understanding how each feature contributes to fairness. This
advancement is pivotal, given sepsis's significant mortality rate and its role
in one-third of hospital deaths. Our method not only aids in identifying and
mitigating biases within the predictive model but also fosters trust among
healthcare stakeholders by improving the transparency and fairness of model
predictions, thereby contributing to more equitable and trustworthy healthcare
delivery.

æè¦ï¼äººå·¥æºæ§ééé æ¸¬æ¨¡ååå©é«çå°æ¥­äººå¡ï¼å¤§å¹è½è®äºè¨åºæ±ºç­å¶å®ãæ¬ç ç©¶æ¢è¨äºå¨é«çä¿å¥ä¸­ä½¿ç¨äººå·¥æºæ§æç¨ç¨å¼æå¬å¹³æ§åå¯è§£éæ§çééµéæ±ï¼ä»¥ç¢ºä¿å¨ä¸åçæ£èäººå£çµ±è¨è³æä¸­ç²å¾å¬å¹³ççµæãééå°æ³¨æ¼æè¡çç¸éæ­»äº¡ççé æ¸¬æ¨¡åï¼æåæåºäºä¸ç¨®æ¹æ³ï¼è©²æ¹æ³æå­¸ç¿ä¸åæè½æä½³åçé æ¸¬æ¨¡åï¼ç¶å¾æ¡ç¨è½ç§»å­¸ç¿éç¨ä¾ç¢çä¸åå·ææ´å¥½å¬å¹³æ§çæ¨¡åãæåçæ¨¡åéå¼å¥äºä¸ç¨®æ°ç©çåºæ¼æåçç¹å¾µéè¦æ§æ¼ç®æ³ï¼æ¨å¨é¡ææ¯åç¹å¾µå¨å¢å¼·é æ¸¬å¬å¹³æ§æ¹é¢çè²¢ç»ãèç¾æçå¯è§£éæ§æ¹æ³å°æ³¨æ¼è§£éç¹å¾µå°é æ¸¬æè½çè²¢ç»ä¸åï¼æåæåºçæ¹æ³ç¨ç¹å°å½è£äºçè§£æ¯åç¹å¾µå¦ä½æå©æ¼å¬å¹³æ§çå·®è·ãéé é²å±è³ééè¦ï¼å çºæè¡ççæ­»äº¡çå¾é«ï¼ä¸å¨ä¸åä¹ä¸çé«é¢æ­»äº¡ä¸­æ®æ¼èè§è²ãæåçæ¨¡åä¸åæå©æ¼è­å¥åæ¸è¼é æ¸¬æ¨¡åä¸­çåå·®ï¼éè½ééæé«æ¨¡åé æ¸¬çéæåº¦åå¬å¹³æ§ä¾å¹é¤é«çä¿å¥å©çç¸éèä¹éçä¿¡ä»»ï¼é²èæå©æ¼æä¾æ´å¬å¹³ä¸å¼å¾ä¿¡è³´çé«çä¿å¥æåã

##### **Multi Class Depression Detection Through Tweets using Artificial Intelligence**
2404.13104v1 by Muhammad Osama Nusrat, Waseem Shahzad, Saad Ahmed Jamal

Depression is a significant issue nowadays. As per the World Health
Organization (WHO), in 2023, over 280 million individuals are grappling with
depression. This is a huge number; if not taken seriously, these numbers will
increase rapidly. About 4.89 billion individuals are social media users. People
express their feelings and emotions on platforms like Twitter, Facebook,
Reddit, Instagram, etc. These platforms contain valuable information which can
be used for research purposes. Considerable research has been conducted across
various social media platforms. However, certain limitations persist in these
endeavors. Particularly, previous studies were only focused on detecting
depression and the intensity of depression in tweets. Also, there existed
inaccuracies in dataset labeling. In this research work, five types of
depression (Bipolar, major, psychotic, atypical, and postpartum) were predicted
using tweets from the Twitter database based on lexicon labeling. Explainable
AI was used to provide reasoning by highlighting the parts of tweets that
represent type of depression. Bidirectional Encoder Representations from
Transformers (BERT) was used for feature extraction and training. Machine
learning and deep learning methodologies were used to train the model. The BERT
model presented the most promising results, achieving an overall accuracy of
0.96.

æè¦ï¼ç¾ä»ï¼æé¬±çæ¯ä¸åéè¦çè­°é¡ãæ ¹æä¸çè¡ççµç¹ (WHO) çè³æï¼å¨ 2023 å¹´ï¼è¶é 2.8 åäººæ­£å¨èæé¬±çæé¬¥ãéæ¯ä¸åé¾å¤§çæ¸å­ï¼å¦æä¸èªççå¾ï¼éäºæ¸å­å°æå¿«éå¢å ãå¤§ç´æ 48.9 åäººæ¯ç¤¾ç¾¤åªé«ä½¿ç¨èãäººåå¨ TwitterãFacebookãRedditãInstagram ç­å¹³å°ä¸è¡¨éèªå·±çæååæç·ãéäºå¹³å°åå«æå¹å¼çè³è¨ï¼å¯ç¨æ¼ç ç©¶ç®çãå·²ç¶å¨åç¨®ç¤¾ç¾¤åªé«å¹³å°ä¸é²è¡äºå¤§éçç ç©¶ãç¶èï¼éäºåªåä»å­å¨æäºéå¶ãç¹å¥æ¯ï¼ååçç ç©¶åå°æ³¨æ¼åµæ¸¬æ¨æä¸­çæé¬±çåæé¬±ççå¼·åº¦ãæ­¤å¤ï¼è³æéæ¨ç±¤ä¸­å­å¨ä¸æºç¢ºçææ³ãå¨éé ç ç©¶å·¥ä½ä¸­ï¼ä½¿ç¨åºæ¼è©å½æ¨ç±¤ç Twitter è³æåº«ä¸­çæ¨æé æ¸¬äºäºç¨®é¡åçæé¬±çï¼éæ¥µåãéåº¦ãç²¾ç¥çåãéå¸ååç¢å¾ï¼ãå¯è§£éç AI ç¨æ¼ééå¼·èª¿ä»£è¡¨æé¬±çé¡åçæ¨æé¨åä¾æä¾æ¨çãå¾ Transformersï¼BERTï¼ä¸­æåçéåç·¨ç¢¼å¨è¡¨ç¤ºç¨æ¼ç¹å¾µæååè¨ç·´ãæ©å¨å­¸ç¿åæ·±åº¦å­¸ç¿æ¹æ³ç¨æ¼è¨ç·´æ¨¡åãBERT æ¨¡ååç¾åºææå¸æççµæï¼éå° 0.96 çæ´é«æºç¢ºåº¦ã

##### **COIN: Counterfactual inpainting for weakly supervised semantic segmentation for medical images**
2404.12832v2 by Dmytro Shvetsov, Joonas Ariva, Marharyta Domnich, Raul Vicente, Dmytro Fishman

Deep learning is dramatically transforming the field of medical imaging and
radiology, enabling the identification of pathologies in medical images,
including computed tomography (CT) and X-ray scans. However, the performance of
deep learning models, particularly in segmentation tasks, is often limited by
the need for extensive annotated datasets. To address this challenge, the
capabilities of weakly supervised semantic segmentation are explored through
the lens of Explainable AI and the generation of counterfactual explanations.
The scope of this research is development of a novel counterfactual inpainting
approach (COIN) that flips the predicted classification label from abnormal to
normal by using a generative model. For instance, if the classifier deems an
input medical image X as abnormal, indicating the presence of a pathology, the
generative model aims to inpaint the abnormal region, thus reversing the
classifier's original prediction label. The approach enables us to produce
precise segmentations for pathologies without depending on pre-existing
segmentation masks. Crucially, image-level labels are utilized, which are
substantially easier to acquire than creating detailed segmentation masks. The
effectiveness of the method is demonstrated by segmenting synthetic targets and
actual kidney tumors from CT images acquired from Tartu University Hospital in
Estonia. The findings indicate that COIN greatly surpasses established
attribution methods, such as RISE, ScoreCAM, and LayerCAM, as well as an
alternative counterfactual explanation method introduced by Singla et al. This
evidence suggests that COIN is a promising approach for semantic segmentation
of tumors in CT images, and presents a step forward in making deep learning
applications more accessible and effective in healthcare, where annotated data
is scarce.

æè¦ï¼æ·±åº¦å­¦ä¹ æ­£å¤§å¹è½è®é«å­¸å½±ååæ¾å°ç·å­¸é åï¼è½è¾¨è­é«å­¸å½±åä¸­çççï¼åæ¬é»è¦æ·å±¤ææ (CT) å X åææãç¶èï¼æ·±åº¦å­¸ç¿æ¨¡åçæè½ï¼ç¹å¥æ¯å¨åå²ä»»åä¸­ï¼å¸¸å¸¸åå°å»£æ³è¨»è§£è³æééæ±çéå¶ãçºäºæå°æ­¤ææ°ï¼ééå¯è§£é AI ååäºå¯¦è§£éçç¢çï¼æ¢ç´¢å¼±ç£ç£èªæåå²çè½åãæ¬ç ç©¶çç¯åæ¯éç¼ä¸ç¨®æ°çåäºå¯¦å§ææ¹æ³ (COIN)ï¼è©²æ¹æ³ä½¿ç¨çææ¨¡åå°é æ¸¬çåé¡æ¨ç±¤å¾ç°å¸¸ç¿»è½çºæ­£å¸¸ãä¾å¦ï¼å¦æåé¡å¨å°è¼¸å¥çé«å­¸å½±å X è¦çºç°å¸¸ï¼è¡¨ç¤ºå­å¨ççï¼åçææ¨¡åæ¨å¨å§æç°å¸¸ååï¼å¾èéè½åé¡å¨çåå§é æ¸¬æ¨ç±¤ãæ­¤æ¹æ³ä½¿æåè½å¤ ç¢ççççç²¾ç¢ºåå²ï¼èç¡éä¾è³´æ¼é åå­å¨çåå²é®ç½©ãè³ééè¦çæ¯ï¼å©ç¨å½±åå±¤ç´æ¨ç±¤ï¼éæ¯å»ºç«è©³ç´°çåå²é®ç½©å®¹æåå¾ãè©²æ¹æ³çæææ§ééåå²åæç®æ¨åå¾ææ²å°¼äºå¡ç¾åå¤§å­¸é«é¢åå¾ç CT å½±åä¸­çå¯¦éèèè«ç¤ä¾è­æãç ç©¶çµæè¡¨æï¼COIN é é è¶éå·²å»ºç«çæ­¸å æ¹æ³ï¼ä¾å¦ RISEãScoreCAM å LayerCAMï¼ä»¥å Singla ç­äººæåºçå¦ä¸ç¨®åäºå¯¦è§£éæ¹æ³ãæ­¤è­æè¡¨æï¼COIN æ¯ä¸ç¨®å¾æåéç CT å½±åä¸­è«ç¤èªæåå²æ¹æ³ï¼ä¸¦å¨é«çä¿å¥ä¸­è®æ·±åº¦å­¸ç¿æç¨æ´ææ¼åå¾åæ´ææçéé²ä¸æ­¥ï¼å¶ä¸­è¨»è§£è³æå¾ç¨å°ã

##### **Hybrid Intelligence for Digital Humanities**
2406.15374v1 by Victor de Boer, Lise Stork

In this paper, we explore the synergies between Digital Humanities (DH) as a
discipline and Hybrid Intelligence (HI) as a research paradigm. In DH research,
the use of digital methods and specifically that of Artificial Intelligence is
subject to a set of requirements and constraints. We argue that these are
well-supported by the capabilities and goals of HI. Our contribution includes
the identification of five such DH requirements: Successful AI systems need to
be able to 1) collaborate with the (human) scholar; 2) support data criticism;
3) support tool criticism; 4) be aware of and cater to various perspectives and
5) support distant and close reading. We take the CARE principles of Hybrid
Intelligence (collaborative, adaptive, responsible and explainable) as
theoretical framework and map these to the DH requirements. In this mapping, we
include example research projects. We finally address how insights from DH can
be applied to HI and discuss open challenges for the combination of the two
disciplines.

æè¦ï¼å¨æ¬æä¸­ï¼æåæ¢è¨æ¸ä½äººæå­¸ç§ (DH) ä½çºä¸éå­¸ç§èæ··åæºè½ (HI) ä½çºä¸åç ç©¶å¸ç¯ä¹éçååä½ç¨ãå¨ DH ç ç©¶ä¸­ï¼æ¸ä½æ¹æ³çä½¿ç¨ï¼ç¹å¥æ¯äººå·¥æºæ§çä½¿ç¨ï¼åå°ä¸ç³»åè¦æ±åéå¶ãæåèªçºéäºè¦æ±åéå¶ç²å¾ HI çè½ååç®æ¨çååæ¯æãæåçè²¢ç»åæ¬æ¾åºäºåéæ¨£ç DH è¦æ±ï¼æåç AI ç³»çµ±éè¦è½å¤  1) èï¼äººé¡ï¼å­¸èåä½ï¼2) æ¯æ´è³ææ¹è©ï¼3) æ¯æ´å·¥å·æ¹è©ï¼4) å¯è¦ºä¸¦è¿ååç¨®è§é»ï¼5) æ¯æ´é è·åè¿è·é¢é±è®ãæåå°æ··åæºè½ç CARE ååï¼åä½ãé©æãè² è²¬åå¯è§£éï¼ä½çºçè«æ¶æ§ï¼ä¸¦å°éäºååå°æå° DH è¦æ±ãå¨æ­¤å°æä¸­ï¼æåç´å¥ç¯ä¾ç ç©¶å°æ¡ãæå¾ï¼æåæ¢è¨å¦ä½å° DH çè¦è§£æç¨æ¼ HIï¼ä¸¦è¨è«çµåéå©åå­¸ç§çéæ¾ææ°ã

##### **Ethical Framework for Responsible Foundational Models in Medical Imaging**
2406.11868v1 by Abhijit Das, Debesh Jha, Jasmer Sanjotra, Onkar Susladkar, Suramyaa Sarkar, Ashish Rauniyar, Nikhil Tomar, Vanshali Sharma, Ulas Bagci

Foundational models (FMs) have tremendous potential to revolutionize medical
imaging. However, their deployment in real-world clinical settings demands
extensive ethical considerations. This paper aims to highlight the ethical
concerns related to FMs and propose a framework to guide their responsible
development and implementation within medicine. We meticulously examine ethical
issues such as privacy of patient data, bias mitigation, algorithmic
transparency, explainability and accountability. The proposed framework is
designed to prioritize patient welfare, mitigate potential risks, and foster
trust in AI-assisted healthcare.

æè¦ï¼åºç¤æ¨¡å (FM) å·æå¾¹åºæ¹è®é«å­¸å½±åçå·¨å¤§æ½åãç¶èï¼å®åå¨ç¾å¯¦ä¸çè¨åºç°å¢ä¸­çé¨ç½²éè¦å»£æ³çå«çèéãæ¬ææ¨å¨å¼·èª¿è FM ç¸éçå«çåé¡ï¼ä¸¦æåºä¸åæ¡æ¶ä¾æå°å®åå¨é«å­¸ä¸­çè² è²¬ä»»éç¼åå¯¦æ½ãæåä»ç´°å¯©æ¥äºå«çåé¡ï¼ä¾å¦æ£èæ¸æé±ç§ãåå·®ç·©è§£ãæ¼ç®æ³éæåº¦ãå¯è§£éæ§ååè²¬å¶ãææåºçæ¡æ¶æ¨å¨åªåèæ®æ£èç¦å©ãæ¸è¼æ½å¨é¢¨éªï¼ä¸¦å¹é¤å° AI è¼å©é«çä¿å¥çä¿¡ä»»ã

##### **Advancements in Radiomics and Artificial Intelligence for Thyroid Cancer Diagnosis**
2404.07239v1 by Milad Yousefi, Shadi Farabi Maleki, Ali Jafarizadeh, Mahya Ahmadpour Youshanlui, Aida Jafari, Siamak Pedrammehr, Roohallah Alizadehsani, Ryszard Tadeusiewicz, Pawel Plawiak

Thyroid cancer is an increasing global health concern that requires advanced
diagnostic methods. The application of AI and radiomics to thyroid cancer
diagnosis is examined in this review. A review of multiple databases was
conducted in compliance with PRISMA guidelines until October 2023. A
combination of keywords led to the discovery of an English academic publication
on thyroid cancer and related subjects. 267 papers were returned from the
original search after 109 duplicates were removed. Relevant studies were
selected according to predetermined criteria after 124 articles were eliminated
based on an examination of their abstract and title. After the comprehensive
analysis, an additional six studies were excluded. Among the 28 included
studies, radiomics analysis, which incorporates ultrasound (US) images,
demonstrated its effectiveness in diagnosing thyroid cancer. Various results
were noted, some of the studies presenting new strategies that outperformed the
status quo. The literature has emphasized various challenges faced by AI
models, including interpretability issues, dataset constraints, and operator
dependence. The synthesized findings of the 28 included studies mentioned the
need for standardization efforts and prospective multicenter studies to address
these concerns. Furthermore, approaches to overcome these obstacles were
identified, such as advances in explainable AI technology and personalized
medicine techniques. The review focuses on how AI and radiomics could transform
the diagnosis and treatment of thyroid cancer. Despite challenges, future
research on multidisciplinary cooperation, clinical applicability validation,
and algorithm improvement holds the potential to improve patient outcomes and
diagnostic precision in the treatment of thyroid cancer.

æè¦ï¼ç²çèºçæ¯ä¸ç¨®æ¥çå´éçå¨çå¥åº·åé¡ï¼éè¦åé²çè¨ºæ·æ¹æ³ãæ¬ç¯è©è«æ¢è¨äºäººå·¥æºè½èæ¾å°ç¹å¾µåæå¨ç²çèºçè¨ºæ·ä¸­çæç¨ãå¨ç¬¦å PRISMA æåçææ³ä¸ï¼å°å¤åè³æåº«é²è¡äºåé¡§ï¼ç´å° 2023 å¹´ 10 æãééçµåééµå­ï¼ç¼ç¾äºä¸ç¯éæ¼ç²çèºçåç¸éä¸»é¡çè±æå­¸è¡åºçç©ãå¨ç§»é¤ 109 ç¯éè¤æç»å¾ï¼åå§æå°å±åå³ 267 ç¯è«æãå¨æ ¹æé åç¢ºå®çæ¨æºï¼æ·æ±°äº 124 ç¯æç« çæè¦åæ¨é¡å¾ï¼é¸åºäºç¸éç ç©¶ãå¨é²è¡å¨é¢åæå¾ï¼é¡å¤æé¤äºå­é ç ç©¶ãå¨ç´å¥ç 28 é ç ç©¶ä¸­ï¼çµåè¶é³æ³¢ (US) å½±åçæ¾å°ç¹å¾µåæï¼è­æäºå¶å¨è¨ºæ·ç²çèºçæ¹é¢çæææ§ãç ç©¶çµæä¸ä¸ï¼æäºç ç©¶æåºäºåªæ¼ç¾ççæ°ç­ç¥ãæç»å¼·èª¿äºäººå·¥æºè½æ¨¡åé¢è¨çåç¨®ææ°ï¼åæ¬å¯è§£éæ§åé¡ãè³æééå¶åæä½å¡ä¾è³´æ§ã28 é ç´å¥ç ç©¶çç¶åç¼ç¾æå°ï¼éè¦æ¨æºåå·¥ä½ååç»æ§å¤ä¸­å¿ç ç©¶ä¾è§£æ±ºéäºåé¡ãæ­¤å¤ï¼éç¢ºå®äºåæéäºéç¤çæ¹æ³ï¼ä¾å¦å¯è§£éäººå·¥æºè½æè¡ååäººåé«çæè¡çé²æ­¥ãæ¬ç¯è©è«éé»æ¢è¨äºäººå·¥æºè½åæ¾å°ç¹å¾µåæå¦ä½è½è®ç²çèºççè¨ºæ·åæ²»çãåç®¡å­å¨ææ°ï¼ä½æªä¾å°å¤å­¸ç§åä½ãè¨åºé©ç¨æ§é©è­åæ¼ç®æ³æ¹é²çç ç©¶ï¼ä»ææ½åæ¹åç²çèºçæ²»çä¸­çæ£èé å¾åè¨ºæ·ç²¾æºåº¦ã

##### **Predictive Modeling for Breast Cancer Classification in the Context of Bangladeshi Patients: A Supervised Machine Learning Approach with Explainable AI**
2404.04686v1 by Taminul Islam, Md. Alif Sheakh, Mst. Sazia Tahosin, Most. Hasna Hena, Shopnil Akash, Yousef A. Bin Jardan, Gezahign Fentahun Wondmie, Hiba-Allah Nafidi, Mohammed Bourhia

Breast cancer has rapidly increased in prevalence in recent years, making it
one of the leading causes of mortality worldwide. Among all cancers, it is by
far the most common. Diagnosing this illness manually requires significant time
and expertise. Since detecting breast cancer is a time-consuming process,
preventing its further spread can be aided by creating machine-based forecasts.
Machine learning and Explainable AI are crucial in classification as they not
only provide accurate predictions but also offer insights into how the model
arrives at its decisions, aiding in the understanding and trustworthiness of
the classification results. In this study, we evaluate and compare the
classification accuracy, precision, recall, and F-1 scores of five different
machine learning methods using a primary dataset (500 patients from Dhaka
Medical College Hospital). Five different supervised machine learning
techniques, including decision tree, random forest, logistic regression, naive
bayes, and XGBoost, have been used to achieve optimal results on our dataset.
Additionally, this study applied SHAP analysis to the XGBoost model to
interpret the model's predictions and understand the impact of each feature on
the model's output. We compared the accuracy with which several algorithms
classified the data, as well as contrasted with other literature in this field.
After final evaluation, this study found that XGBoost achieved the best model
accuracy, which is 97%.

æè¦ï¼<paragraph>è¿å¹´ä¾ï¼ä¹³çççè¡çè¿éå¢å ï¼ä½¿å¶æçºå¨çä¸»è¦çæ­»äº¡åå ä¹ä¸ãå¨ææççä¸­ï¼ä¹³çè¿ä»çºæ­¢æ¯æå¸¸è¦çãæåè¨ºæ·æ­¤ç¾çéè¦å¤§éçæéåå°æ¥­ç¥è­ãç±æ¼ä¹³ççæª¢æ¸¬éç¨èæï¼å æ­¤ééå»ºç«æ©å¨å­¸ç¿æ¨¡åä¾é æ¸¬ï¼æå©æ¼é²æ­¢å¶é²ä¸æ­¥æ´æ£ãæ©å¨å­¸ç¿åå¯è§£é AI å¨åé¡ä¸­è³ééè¦ï¼å çºå®åä¸åå¯ä»¥æä¾æºç¢ºçé æ¸¬ï¼éå¯ä»¥æ·±å¥äºè§£æ¨¡åå¦ä½ååºæ±ºç­ï¼æå©æ¼çè§£åä¿¡è³´åé¡çµæãå¨æ­¤ç ç©¶ä¸­ï¼æåè©ä¼°ä¸¦æ¯è¼äºäºç¨®ä¸åçæ©å¨å­¸ç¿æ¹æ³çåé¡æºç¢ºåº¦ãç²¾ç¢ºåº¦ãå¬åçå F1 åæ¸ï¼ä½¿ç¨äºä¸åä¸»è¦çè³æéï¼éå¡é«å­¸é¢é«é¢ç 500 åæ£èï¼ãäºç¨®ä¸åçç£ç£å¼æ©å¨å­¸ç¿æè¡ï¼åæ¬æ±ºç­æ¨¹ãé¨æ©æ£®æãéè¼¯è¿´æ­¸ãæ´ç´ è²æ°å XGBoostï¼å·²ç¨æ¼å¨æåçè³æéä¸åå¾æä½³çµæãæ­¤å¤ï¼æ¬ç ç©¶å° SHAP åææç¨æ¼ XGBoost æ¨¡åï¼ä»¥è§£éæ¨¡åçé æ¸¬ä¸¦äºè§£æ¯åç¹å¾µå°æ¨¡åè¼¸åºçå½±é¿ãæåæ¯è¼äºå¹¾ç¨®æ¼ç®æ³å°è³æé²è¡åé¡çæºç¢ºåº¦ï¼ä¸¦èè©²é åçå¶ä»æç»é²è¡å°æ¯ãå¨æå¾è©ä¼°å¾ï¼æ¬ç ç©¶ç¼ç¾ XGBoost éå°äºæä½³çæ¨¡åæºç¢ºåº¦ï¼çº 97%ã</paragraph>

##### **Enhancing Breast Cancer Diagnosis in Mammography: Evaluation and Integration of Convolutional Neural Networks and Explainable AI**
2404.03892v3 by Maryam Ahmed, Tooba Bibi, Rizwan Ahmed Khan, Sidra Nasir

The Deep learning (DL) models for diagnosing breast cancer from mammographic
images often operate as "black boxes", making it difficult for healthcare
professionals to trust and understand their decision-making processes. The
study presents an integrated framework combining Convolutional Neural Networks
(CNNs) and Explainable Artificial Intelligence (XAI) for the enhanced diagnosis
of breast cancer using the CBIS-DDSM dataset. The methodology encompasses an
elaborate data preprocessing pipeline and advanced data augmentation techniques
to counteract dataset limitations and transfer learning using pre-trained
networks such as VGG-16, Inception-V3 and ResNet was employed. A focal point of
our study is the evaluation of XAI's effectiveness in interpreting model
predictions, highlighted by utilizing the Hausdorff measure to assess the
alignment between AI-generated explanations and expert annotations
quantitatively. This approach is critical for XAI in promoting trustworthiness
and ethical fairness in AI-assisted diagnostics. The findings from our research
illustrate the effective collaboration between CNNs and XAI in advancing
diagnostic methods for breast cancer, thereby facilitating a more seamless
integration of advanced AI technologies within clinical settings. By enhancing
the interpretability of AI driven decisions, this work lays the groundwork for
improved collaboration between AI systems and medical practitioners, ultimately
enriching patient care. Furthermore, the implications of our research extended
well beyond the current methodologies. It encourages further research into how
to combine multimodal data and improve AI explanations to meet the needs of
clinical practice.

æè¦ï¼æ·±åº¦å­¸ç¿ (DL) ç¨æ¼å¾ä¹³æ¿æå½±è¡å½±åè¨ºæ·ä¹³ççæ¨¡åéå¸¸ä»¥ãé»çå­ãæ¹å¼éä½ï¼éä½¿å¾é«çä¿å¥å°æ¥­äººå¡é£ä»¥ä¿¡ä»»åçè§£å¶æ±ºç­éç¨ãæ¬ç ç©¶æåºä¸åæ´åæ¶æ§ï¼çµåå·ç©ç¥ç¶ç¶²è·¯ (CNN) åå¯è§£éäººå·¥æºæ§ (XAI)ï¼ä»¥ä½¿ç¨ CBIS-DDSM è³æéå¢å¼·ä¹³ççè¨ºæ·ãæ¹æ³åå«ä¸åç²¾ç´°çè³æåèçç®¡ç·åé²éè³ææ´åæè¡ï¼ä»¥å°æè³æééå¶ï¼ä¸¦æ¡ç¨é åè¨ç·´çç¶²è·¯ï¼ä¾å¦ VGG-16ãInception-V3 å ResNetï¼é²è¡é·ç§»å­¸ç¿ãæåç ç©¶çéé»æ¯è©ä¼° XAI å¨è§£éæ¨¡åé æ¸¬ä¸­çæææ§ï¼éé»å©ç¨è±ªæ¯å¤å¤«æ¸¬åº¦éåè©ä¼° AI çæçè§£éåå°å®¶è¨»è§£ä¹éçä¸è´æ§ãéç¨®æ¹æ³å°æ¼ XAI å¨ä¿é² AI è¼å©è¨ºæ·ä¸­çå¯ä¿¡åº¦åå«çå¬å¹³æ§è³ééè¦ãæåç ç©¶çç¼ç¾èªªæäº CNN å XAI å¨æ¨é²ä¹³çè¨ºæ·æ¹æ³ä¸­çææåä½ï¼å¾èä¿é²äºåé² AI æè¡å¨è¨åºç°å¢ä¸­çæ´é æ¢æ´åãééå¢å¼· AI é©åæ±ºç­çå¯è§£éæ§ï¼éé å·¥ä½çº AI ç³»çµ±åé«çå¾æ¥­äººå¡ä¹éçæ¹ååä½å¥ å®äºåºç¤ï¼æçµè±å¯äºæ£èç§è­·ãæ­¤å¤ï¼æåç ç©¶çå½±é¿é é è¶åºäºç®åçæè¡ãå®é¼åµé²ä¸æ­¥ç ç©¶å¦ä½çµåå¤æ¨¡å¼è³æä¸¦æ¹å AI è§£éï¼ä»¥æ»¿è¶³è¨åºå¯¦åçéæ±ã

##### **Advancing Multimodal Data Fusion in Pain Recognition: A Strategy Leveraging Statistical Correlation and Human-Centered Perspectives**
2404.00320v2 by Xingrui Gu, Zhixuan Wang, Irisa Jin, Zekun Wu

This research presents a novel multimodal data fusion methodology for pain
behavior recognition, integrating statistical correlation analysis with
human-centered insights. Our approach introduces two key innovations: 1)
integrating data-driven statistical relevance weights into the fusion strategy
to effectively utilize complementary information from heterogeneous modalities,
and 2) incorporating human-centric movement characteristics into multimodal
representation learning for detailed modeling of pain behaviors. Validated
across various deep learning architectures, our method demonstrates superior
performance and broad applicability. We propose a customizable framework that
aligns each modality with a suitable classifier based on statistical
significance, advancing personalized and effective multimodal fusion.
Furthermore, our methodology provides explainable analysis of multimodal data,
contributing to interpretable and explainable AI in healthcare. By highlighting
the importance of data diversity and modality-specific representations, we
enhance traditional fusion techniques and set new standards for recognizing
complex pain behaviors. Our findings have significant implications for
promoting patient-centered healthcare interventions and supporting explainable
clinical decision-making.

æè¦ï¼æ¬ç ç©¶æåºäºä¸ç¨®åµæ°çå¤æ¨¡ææ¸æèåæ¹æ³ï¼ç¨æ¼ç¼çè¡çºè­å¥ï¼å°çµ±è¨ç¸éåæèä»¥äººçºä¸­å¿çè¦è§£ç¸çµåãæåçåæ³å¼å¥äºå©é ééµåµæ°ï¼1) å°æ¸æé©åççµ±è¨ç¸éæ¬éæ´åå°èåç­ç¥ä¸­ï¼ä»¥ææå©ç¨ä¾èªç°è³ªæ¨¡æçè£åä¿¡æ¯ï¼ä»¥å 2) å°ä»¥äººçºä¸­å¿çéåç¹å¾µç´å¥å¤æ¨¡æè¡¨ç¤ºå­¸ç¿ä¸­ï¼ä»¥è©³ç´°å»ºæ¨¡ç¼çè¡çºãæåçæ¨¡åå¨åç¨®æ·±åº¦å­¸ç¿æ¶æ§ä¸­å¾å°é©è­ï¼å±ç¤ºäºåè¶çæ§è½åå»£æ³çé©ç¨æ§ãæåæåºäºä¸åå¯èªå®ç¾©çæ¡æ¶ï¼æ ¹æçµ±è¨é¡¯èæ§å°æ¯åæ¨¡æèåé©çåé¡å¨å°é½ï¼æ¨é²åæ§ååææçå¤æ¨¡æèåãæ­¤å¤ï¼æåçæ¨¡åæä¾å°å¤æ¨¡ææ¸æçå¯è§£éåæï¼æå©æ¼é«çä¿å¥ä¸­çå¯è§£éåå¯è§£é AIãééå¼·èª¿æ¸æå¤æ¨£æ§åæ¨¡æç¹å®è¡¨ç¤ºçéè¦æ§ï¼æåå¢å¼·äºå³çµ±çèåæè¡ï¼ä¸¦çºè­å¥è¤éçç¼çè¡çºè¨­å®äºæ°çæ¨æºãæåçç¼ç¾å°ä¿é²ä»¥æ£èçºä¸­å¿çé«çä¿å¥å¹²é åæ¯æå¯è§£éçè¨åºæ±ºç­å¶å®å·æéè¦æç¾©ã

##### **Addressing Social Misattributions of Large Language Models: An HCXAI-based Approach**
2403.17873v1 by Andrea Ferrario, Alberto Termine, Alessandro Facchini

Human-centered explainable AI (HCXAI) advocates for the integration of social
aspects into AI explanations. Central to the HCXAI discourse is the Social
Transparency (ST) framework, which aims to make the socio-organizational
context of AI systems accessible to their users. In this work, we suggest
extending the ST framework to address the risks of social misattributions in
Large Language Models (LLMs), particularly in sensitive areas like mental
health. In fact LLMs, which are remarkably capable of simulating roles and
personas, may lead to mismatches between designers' intentions and users'
perceptions of social attributes, risking to promote emotional manipulation and
dangerous behaviors, cases of epistemic injustice, and unwarranted trust. To
address these issues, we propose enhancing the ST framework with a fifth
'W-question' to clarify the specific social attributions assigned to LLMs by
its designers and users. This addition aims to bridge the gap between LLM
capabilities and user perceptions, promoting the ethically responsible
development and use of LLM-based technology.

æè¦ï¼ä»¥äººä¸ºæ¬çå¯è§£é AI (HCXAI) å¡å¯¼å°ç¤¾ä¼å±é¢æ´åå° AI è§£éä¸­ãHCXAI è¯è¯­çæ ¸å¿æ¯ç¤¾ä¼éæåº¦ (ST) æ¡æ¶ï¼å¶ç®æ æ¯è®© AI ç³»ç»çç¤¾ä¼ç»ç»èæ¯å¯¹ç¨æ·æ¥è¯´æ¯å¯çè§£çãå¨è¿é¡¹å·¥ä½ä¸­ï¼æä»¬å»ºè®®æ©å± ST æ¡æ¶ä»¥è§£å³å¤§åè¯­è¨æ¨¡å (LLM) ä¸­ç¤¾ä¼éè¯¯å½å çé£é©ï¼å°¤å¶æ¯å¨å¿çå¥åº·ç­ææé¢åãäºå®ä¸ï¼LLM è½å¤åºè²å°æ¨¡æè§è²åäººæ ¼ï¼è¿å¯è½å¯¼è´è®¾è®¡èçæå¾åç¨æ·å¯¹ç¤¾ä¼å±æ§çè®¤ç¥ä¹é´åºç°ééï¼ä»èæé£é©ä¿è¿æç»ªæçºµåå±é©è¡ä¸ºãè®¤ç¥ä¸å¬æ­£åä¸åççä¿¡ä»»ãä¸ºäºè§£å³è¿äºé®é¢ï¼æä»¬å»ºè®®ç¨ç¬¬äºä¸ªâW é®é¢âæ¥å¢å¼º ST æ¡æ¶ï¼ä»¥æç¡®è®¾è®¡èåç¨æ·èµäº LLM çå·ä½ç¤¾ä¼å±æ§ãæ­¤è¡¥åæ¨å¨å¼¥å LLM è½ååç¨æ·è®¤ç¥ä¹é´çå·®è·ï¼ä¿è¿åºäº LLM çææ¯å¨éå¾·ä¸è´è´£ä»»å°å¼ååä½¿ç¨ã

##### **Clinical Domain Knowledge-Derived Template Improves Post Hoc AI Explanations in Pneumothorax Classification**
2403.18871v1 by Han Yuan, Chuan Hong, Pengtao Jiang, Gangming Zhao, Nguyen Tuan Anh Tran, Xinxing Xu, Yet Yen Yan, Nan Liu

Background: Pneumothorax is an acute thoracic disease caused by abnormal air
collection between the lungs and chest wall. To address the opaqueness often
associated with deep learning (DL) models, explainable artificial intelligence
(XAI) methods have been introduced to outline regions related to pneumothorax
diagnoses made by DL models. However, these explanations sometimes diverge from
actual lesion areas, highlighting the need for further improvement. Method: We
propose a template-guided approach to incorporate the clinical knowledge of
pneumothorax into model explanations generated by XAI methods, thereby
enhancing the quality of these explanations. Utilizing one lesion delineation
created by radiologists, our approach first generates a template that
represents potential areas of pneumothorax occurrence. This template is then
superimposed on model explanations to filter out extraneous explanations that
fall outside the template's boundaries. To validate its efficacy, we carried
out a comparative analysis of three XAI methods with and without our template
guidance when explaining two DL models in two real-world datasets. Results: The
proposed approach consistently improved baseline XAI methods across twelve
benchmark scenarios built on three XAI methods, two DL models, and two
datasets. The average incremental percentages, calculated by the performance
improvements over the baseline performance, were 97.8% in Intersection over
Union (IoU) and 94.1% in Dice Similarity Coefficient (DSC) when comparing model
explanations and ground-truth lesion areas. Conclusions: In the context of
pneumothorax diagnoses, we proposed a template-guided approach for improving AI
explanations. We anticipate that our template guidance will forge a fresh
approach to elucidating AI models by integrating clinical domain expertise.

æè¦ï¼<paragraph>èæ¯ï¼æ°£è¸æ¯ä¸ç¨®å èºé¨èè¸å£ä¹éç°å¸¸éæ°£æå¼èµ·çæ¥æ§è¸èç¾çãçºäºè§£æ±ºæ·±åº¦å­¸ç¿ï¼DLï¼æ¨¡åç¶å¸¸ä¼´é¨çä¸éææ§ï¼å¯è§£éäººå·¥æºæ§ï¼XAIï¼æ¹æ³å·²è¢«å¼å¥ï¼ç¨æ¼æ¦è¿°è DL æ¨¡åååºçæ°£è¸è¨ºæ·ç¸éçååãç¶èï¼éäºè§£éæææèå¯¦éçç¶ååææåºå¥ï¼çªé¡¯åºé²ä¸æ­¥æ¹é²çå¿è¦æ§ãæ¹æ³ï¼æåæåºäºä¸ç¨®æ¨¡æ¿å¼å°å¼æ¹æ³ï¼å°æ°£è¸çè¨åºç¥è­ç´å¥ XAI æ¹æ³ç¢ççæ¨¡åè§£éä¸­ï¼å¾èæåéäºè§£éçåè³ªãå©ç¨æ¾å°ç§é«å¸«å»ºç«ççç¶æç¹ªï¼æåçåæ³é¦åç¢çä¸åæ¨¡æ¿ï¼ç¨æ¼è¡¨ç¤ºæ°£è¸å¯è½ç¼ççååãç¶å¾å°æ­¤æ¨¡æ¿çå å¨æ¨¡åè§£éä¸ï¼ä»¥ç¯©é¸åºè¶åºæ¨¡æ¿éççç¡éè§£éãçºäºé©è­å¶æåï¼æåå°ä¸ç¨® XAI æ¹æ³é²è¡äºæ¯è¼åæï¼å¨å©åçå¯¦ä¸çè³æéä¸­è§£éå©å DL æ¨¡åæï¼åå¥æ¡ç¨åä¸æ¡ç¨æåçæ¨¡æ¿å¼å°ãçµæï¼ææåºçæ¹æ³å¨å»ºç«æ¼ä¸ç¨® XAI æ¹æ³ãå©å DL æ¨¡ååå©åè³æéçåäºç¨®åºæºæå¢ä¸­ï¼å§çµæ¹åäºåºæº XAI æ¹æ³ãå¨æ¯è¼æ¨¡åè§£éåçå¯¦çç¶ååæï¼ééåºæºæè½çæè½æ¹é²è¨ç®åºçå¹³åå¢éç¾åæ¯çºäº¤éæ¯ï¼IoUï¼ç 97.8% åéª°å­ç¸ä¼¼æ§ä¿æ¸ï¼DSCï¼ç 94.1%ãçµè«ï¼å¨æ°£è¸è¨ºæ·çèæ¯ä¸ï¼æåæåºäºä¸ç¨®æ¨¡æ¿å¼å°å¼æ¹æ³ï¼ç¨æ¼æ¹å AI è§£éãæåé ææåçæ¨¡æ¿å¼å°å°ééæ´åè¨åºé åå°æ¥­ç¥è­ï¼çºé¡æ AI æ¨¡åå»ºç«ä¸ç¨®æ°æ¹æ³ã</paragraph>

##### **Enhancing Neural Machine Translation of Low-Resource Languages: Corpus Development, Human Evaluation and Explainable AI Architectures**
2403.01580v1 by SÃ©amus Lankford

In the current machine translation (MT) landscape, the Transformer
architecture stands out as the gold standard, especially for high-resource
language pairs. This research delves into its efficacy for low-resource
language pairs including both the English$\leftrightarrow$Irish and
English$\leftrightarrow$Marathi language pairs. Notably, the study identifies
the optimal hyperparameters and subword model type to significantly improve the
translation quality of Transformer models for low-resource language pairs.
  The scarcity of parallel datasets for low-resource languages can hinder MT
development. To address this, gaHealth was developed, the first bilingual
corpus of health data for the Irish language. Focusing on the health domain,
models developed using this in-domain dataset exhibited very significant
improvements in BLEU score when compared with models from the LoResMT2021
Shared Task. A subsequent human evaluation using the multidimensional quality
metrics error taxonomy showcased the superior performance of the Transformer
system in reducing both accuracy and fluency errors compared to an RNN-based
counterpart.
  Furthermore, this thesis introduces adaptNMT and adaptMLLM, two open-source
applications streamlined for the development, fine-tuning, and deployment of
neural machine translation models. These tools considerably simplify the setup
and evaluation process, making MT more accessible to both developers and
translators. Notably, adaptNMT, grounded in the OpenNMT ecosystem, promotes
eco-friendly natural language processing research by highlighting the
environmental footprint of model development. Fine-tuning of MLLMs by adaptMLLM
demonstrated advancements in translation performance for two low-resource
language pairs: English$\leftrightarrow$Irish and
English$\leftrightarrow$Marathi, compared to baselines from the LoResMT2021
Shared Task.

æè¦ï¼<paragraph>å¨ç¶åæ©å¨ç¿»è­¯ (MT) é åä¸­ï¼Transformer æ¶æ§è«ç©èåºï¼æçºé»éæ¨æºï¼ç¹å¥æ¯å°æ¼é«è³æºèªè¨å°ãæ¬ç ç©¶æ¢è¨å¶å°ä½è³æºèªè¨å°çæè½ï¼åæ¬è±èªâæç¾è­èªåè±èªâé¦¬æå°èªèªè¨å°ãå¼å¾æ³¨æçæ¯ï¼æ¬ç ç©¶è­å¥åºæä½³è¶åæ¸åå­è©æ¨¡åé¡åï¼ä»¥é¡¯èæé« Transformer æ¨¡åå°ä½è³æºèªè¨å°çç¿»è­¯åè³ªã
ä½è³æºèªè¨çå¹³è¡è³æéçç¨ç¼ºæé»ç¤ MT çç¼å±ãçºäºè§£æ±ºéååé¡ï¼éç¼äº gaHealthï¼éæ¯æç¾è­èªçç¬¬ä¸åéèªå¥åº·è³æèªæåº«ãå°æ³¨æ¼å¥åº·é åï¼ä½¿ç¨æ­¤åå§è³æééç¼çæ¨¡åå¨ BLEU å¾åæ¹é¢è¡¨ç¾åºéå¸¸é¡¯èçé²æ­¥ï¼è LoResMT2021 å±äº«ä»»åä¸­çæ¨¡åç¸æ¯ãé¨å¾ä½¿ç¨å¤ç¶­åè³ªææ¨é¯èª¤åé¡æ³é²è¡çäººå·¥è©ä¼°é¡¯ç¤ºï¼èåºæ¼ RNN çå°ææ¨¡åç¸æ¯ï¼Transformer ç³»çµ±å¨æ¸å°æºç¢ºæ§åæµæ¢æ§é¯èª¤æ¹é¢è¡¨ç¾åºåªç°çæ§è½ã
æ­¤å¤ï¼æ¬è«æä»ç´¹äº adaptNMT å adaptMLLMï¼éå©åéæºæç¨ç¨å¼ç°¡åäºç¥ç¶æ©å¨ç¿»è­¯æ¨¡åçéç¼ãå¾®èª¿åé¨ç½²ãéäºå·¥å·å¤§å¹ç°¡åäºè¨­å®åè©ä¼°æµç¨ï¼è® MT æ´å®¹æè®éç¼äººå¡åç¿»è­¯äººå¡ä½¿ç¨ãå¼å¾æ³¨æçæ¯ï¼adaptNMT ä»¥ OpenNMT çæç³»çµ±çºåºç¤ï¼ééå¼·èª¿æ¨¡åéç¼çç°å¢è¶³è·¡ä¾ä¿é²çæåå¥½çèªç¶èªè¨èçç ç©¶ãè LoResMT2021 å±äº«ä»»åä¸­çåºæºç¸æ¯ï¼adaptMLLM å° MLLM çå¾®èª¿è­æäºè±èªâæç¾è­èªåè±èªâé¦¬æå°èªéå©åä½è³æºèªè¨å°çç¿»è­¯æ§è½é²æ­¥ã</paragraph>

##### **Cause and Effect: Can Large Language Models Truly Understand Causality?**
2402.18139v3 by Swagata Ashwani, Kshiteesh Hegde, Nishith Reddy Mannuru, Mayank Jindal, Dushyant Singh Sengar, Krishna Chaitanya Rao Kathala, Dishant Banga, Vinija Jain, Aman Chadha

With the rise of Large Language Models(LLMs), it has become crucial to
understand their capabilities and limitations in deciphering and explaining the
complex web of causal relationships that language entails. Current methods use
either explicit or implicit causal reasoning, yet there is a strong need for a
unified approach combining both to tackle a wide array of causal relationships
more effectively. This research proposes a novel architecture called Context
Aware Reasoning Enhancement with Counterfactual Analysis(CARE CA) framework to
enhance causal reasoning and explainability. The proposed framework
incorporates an explicit causal detection module with ConceptNet and
counterfactual statements, as well as implicit causal detection through LLMs.
Our framework goes one step further with a layer of counterfactual explanations
to accentuate LLMs understanding of causality. The knowledge from ConceptNet
enhances the performance of multiple causal reasoning tasks such as causal
discovery, causal identification and counterfactual reasoning. The
counterfactual sentences add explicit knowledge of the not caused by scenarios.
By combining these powerful modules, our model aims to provide a deeper
understanding of causal relationships, enabling enhanced interpretability.
Evaluation of benchmark datasets shows improved performance across all metrics,
such as accuracy, precision, recall, and F1 scores. We also introduce
CausalNet, a new dataset accompanied by our code, to facilitate further
research in this domain.

æè¦ï¼é¨èå¤§åèªè¨æ¨¡å (LLM) çèèµ·ï¼äºè§£å®åå¨è§£ç¢¼åè§£éèªè¨æèå«çè¤éå æéä¿ç¶²è·¯ä¸­çè½ååéå¶è®å¾è³ééè¦ãç®åçæè¡ä½¿ç¨æç¢ºæé±å«çå ææ¨çï¼ä½å¼·çéè¦ä¸ç¨®çµ±ä¸çæ¹æ³ï¼çµåå©èä»¥æ´ææå°èçå»£æ³çå æéä¿ãæ¬ç ç©¶æåºäºä¸ç¨®ç¨±çºæå¢æç¥æ¨çå¢å¼·èåäºå¯¦åæ (CARE CA) æ¡æ¶çæ°æ¶æ§ï¼ä»¥å¢å¼·å ææ¨çåå¯è§£éæ§ãæåºçæ¡æ¶çµåäºä½¿ç¨ ConceptNet ååäºå¯¦é³è¿°çæç¢ºå ææª¢æ¸¬æ¨¡çµï¼ä»¥åéé LLM é²è¡çé±å«å ææª¢æ¸¬ãæåçæ¡æ¶æ´é²ä¸æ­¥ï¼å å¥ä¸å±¤åäºå¯¦è§£éï¼ä»¥å¼·èª¿ LLM å°å æéä¿ççè§£ãä¾èª ConceptNet çç¥è­å¢å¼·äºå¤é å ææ¨çä»»åçå·è¡ï¼ä¾å¦å æç¼ç¾ãå æè­å¥ååäºå¯¦æ¨çãåäºå¯¦å¥å å¥äºæªç±æå¢é æçæç¢ºç¥è­ãééçµåéäºå¼·å¤§çæ¨¡çµï¼æåçæ¨¡åæ¨å¨æä¾å°å æéä¿æ´æ·±å¥ççè§£ï¼å¯¦ç¾å¢å¼·çå¯è§£éæ§ãåºæºè³æéçè©ä¼°é¡¯ç¤ºå¨ææææ¨ï¼ä¾å¦æºç¢ºåº¦ãç²¾ç¢ºåº¦ãå¬åçå F1 åæ¸ï¼ä¸é½æææåãæåéå¼å¥äº CausalNetï¼ä¸åæ°çè³æéï¼ä¸¦éä¸äºæåçç¨å¼ç¢¼ï¼ä»¥ä¿é²å¨éåé åçé²ä¸æ­¥ç ç©¶ã

##### **Artificial Intelligence and Diabetes Mellitus: An Inside Look Through the Retina**
2402.18600v1 by Yasin Sadeghi Bazargani, Majid Mirzaei, Navid Sobhi, Mirsaeed Abdollahi, Ali Jafarizadeh, Siamak Pedrammehr, Roohallah Alizadehsani, Ru San Tan, Sheikh Mohammed Shariful Islam, U. Rajendra Acharya

Diabetes mellitus (DM) predisposes patients to vascular complications.
Retinal images and vasculature reflect the body's micro- and macrovascular
health. They can be used to diagnose DM complications, including diabetic
retinopathy (DR), neuropathy, nephropathy, and atherosclerotic cardiovascular
disease, as well as forecast the risk of cardiovascular events. Artificial
intelligence (AI)-enabled systems developed for high-throughput detection of DR
using digitized retinal images have become clinically adopted. Beyond DR
screening, AI integration also holds immense potential to address challenges
associated with the holistic care of the patient with DM. In this work, we aim
to comprehensively review the literature for studies on AI applications based
on retinal images related to DM diagnosis, prognostication, and management. We
will describe the findings of holistic AI-assisted diabetes care, including but
not limited to DR screening, and discuss barriers to implementing such systems,
including issues concerning ethics, data privacy, equitable access, and
explainability. With the ability to evaluate the patient's health status vis a
vis DM complication as well as risk prognostication of future cardiovascular
complications, AI-assisted retinal image analysis has the potential to become a
central tool for modern personalized medicine in patients with DM.

æè¦ï¼ç³å°¿çï¼DMï¼ä½¿æ£èå®¹æåºç¾è¡ç®¡ä½µç¼çã
è¦ç¶²èå½±ååè¡ç®¡åæ èº«é«çå¾®è¡ç®¡åå·¨è¡ç®¡å¥åº·çæ³ãå®åå¯ç¨æ¼è¨ºæ·ç³å°¿çä½µç¼çï¼åæ¬ç³å°¿çè¦ç¶²èçè®ï¼DRï¼ãç¥ç¶çè®ãèçååèç²¥æ¨£ç¡¬åæ§å¿è¡ç®¡ç¾çï¼ä»¥åé æ¸¬å¿è¡ç®¡äºä»¶çé¢¨éªãçºä½¿ç¨æ¸ä½åè¦ç¶²èå½±åé²è¡é«éé DR æª¢æ¸¬èéç¼çäººå·¥æºæ§ï¼AIï¼åç¨ç³»çµ±å·²å¨è¨åºæ¡ç¨ãé¤äº DR ç¯©æª¢å¤ï¼AI æ´åä¹å·æå·¨å¤§çæ½åä¾æå°èç³å°¿çæ£èæ´é«ç§è­·ç¸éçææ°ãå¨éé å·¥ä½ä¸­ï¼æåæ¨å¨å¨é¢åé¡§åºæ¼è¦ç¶²èå½±åç AI æç¨ç¸éç ç©¶çæç»ï¼éäºç ç©¶èç³å°¿ççè¨ºæ·ãé å¾åç®¡çæéãæåå°æè¿°æ´é« AI è¼å©ç³å°¿çç§è­·çç¼ç¾ï¼åæ¬ä½ä¸éæ¼ DR ç¯©æª¢ï¼ä¸¦è¨è«å¯¦æ½æ­¤é¡ç³»çµ±çéç¤ï¼åæ¬èå«çãè³æé±ç§ãå¬å¹³å­ååå¯è§£éæ§æéçåé¡ãééè©ä¼°æ£èçå¥åº·çæ³ï¼åæèéç³å°¿çä½µç¼çä»¥åæªä¾å¿è¡ç®¡ä½µç¼ççé¢¨éªé å¾ï¼AI è¼å©è¦ç¶²èå½±ååæææ½åæçºç³å°¿çæ£èç¾ä»£ååäººåé«ççä¸­å¿å·¥å·ã

##### **Multi-stakeholder Perspective on Responsible Artificial Intelligence and Acceptability in Education**
2402.15027v2 by A. J. Karran, P. Charland, J-T. Martineau, A. Ortiz de Guinea Lopez de Arana, AM. Lesage, S. Senecal, P-M. Leger

This study investigates the acceptability of different artificial
intelligence (AI) applications in education from a multi-stakeholder
perspective, including students, teachers, and parents. Acknowledging the
transformative potential of AI in education, it addresses concerns related to
data privacy, AI agency, transparency, explainability and the ethical
deployment of AI. Through a vignette methodology, participants were presented
with four scenarios where AI's agency, transparency, explainability, and
privacy were manipulated. After each scenario, participants completed a survey
that captured their perceptions of AI's global utility, individual usefulness,
justice, confidence, risk, and intention to use each scenario's AI if
available. The data collection comprising a final sample of 1198
multi-stakeholder participants was distributed through a partner institution
and social media campaigns and focused on individual responses to four AI use
cases. A mediation analysis of the data indicated that acceptance and trust in
AI varies significantly across stakeholder groups. We found that the key
mediators between high and low levels of AI's agency, transparency, and
explainability, as well as the intention to use the different educational AI,
included perceived global utility, justice, and confidence. The study
highlights that the acceptance of AI in education is a nuanced and multifaceted
issue that requires careful consideration of specific AI applications and their
characteristics, in addition to the diverse stakeholders' perceptions.

æè¦ï¼éé ç ç©¶å¾å¤åå©å®³éä¿äººçè§åº¦æ¢è¨ä¸åçäººå·¥æºæ§ (AI) æç¨å¨æè²ä¸çå¯æ¥åæ§ï¼åæ¬å­¸çãèå¸«åå®¶é·ãæ¿èª AI å¨æè²ä¸çè½åæ½åï¼å®è§£æ±ºäºèè³æé±ç§ãAI ä»£çãéæåº¦ãå¯è§£éæ§å AI çéå¾·é¨ç½²ç¸éççæ®ãééå°ææ²æ¹æ³ï¼åèèè¢«åç¾äºåç¨®æå¢ï¼å¶ä¸­ AI çä»£çãéæåº¦ãå¯è§£éæ§åé±ç§åå°æç¸±ãå¨æ¯åæå¢å¾ï¼åèèå®æäºä¸é èª¿æ¥ï¼è©²èª¿æ¥ææäºä»åå° AI çæ´é«æç¨ãåäººæç¨ãæ­£ç¾©ãä¿¡å¿ãé¢¨éªåå¦æå¯ç¨ï¼ä½¿ç¨æ¯åæå¢ç AI çæåççæ³ãè³æèéåå«ä¾èªåä½æ©æ§åç¤¾ç¾¤åªé«æ´»åç 1198 ä½å¤å©å®³éä¿äººåèèçæçµæ¨£æ¬ï¼ä¸¦å°æ³¨æ¼å°åå AI ä½¿ç¨æ¡ä¾çåå¥åæãå°è³æçèª¿è§£åæè¡¨æï¼å° AI çæ¥ååº¦åä¿¡ä»»å¨å©å®³éä¿äººåé«ä¹éæé¡¯èå·®ç°ãæåç¼ç¾ï¼AI çä»£çãéæåº¦åå¯è§£éæ§é«ä½ç¨åº¦ä¹éçééµèª¿è§£èï¼ä»¥åä½¿ç¨ä¸åæè² AI çæåï¼åæ¬æç¥å°çæ´é«æç¨ãæ­£ç¾©åä¿¡å¿ãéé ç ç©¶å¼·èª¿ï¼æ¥å AI å¨æè²ä¸çæç¨æ¯ä¸åå¾®å¦ä¸å¤é¢åçåé¡ï¼é¤äºä¸åçå©å®³éä¿äººççæ³å¤ï¼ééè¦ä»ç´°èæ®å·é«ç AI æç¨åå¶ç¹å¾µã

##### **Deciphering Heartbeat Signatures: A Vision Transformer Approach to Explainable Atrial Fibrillation Detection from ECG Signals**
2402.09474v2 by Aruna Mohan, Danne Elbers, Or Zilbershot, Fatemeh Afghah, David Vorchheimer

Remote patient monitoring based on wearable single-lead electrocardiogram
(ECG) devices has significant potential for enabling the early detection of
heart disease, especially in combination with artificial intelligence (AI)
approaches for automated heart disease detection. There have been prior studies
applying AI approaches based on deep learning for heart disease detection.
However, these models are yet to be widely accepted as a reliable aid for
clinical diagnostics, in part due to the current black-box perception
surrounding many AI algorithms. In particular, there is a need to identify the
key features of the ECG signal that contribute toward making an accurate
diagnosis, thereby enhancing the interpretability of the model. In the present
study, we develop a vision transformer approach to identify atrial fibrillation
based on single-lead ECG data. A residual network (ResNet) approach is also
developed for comparison with the vision transformer approach. These models are
applied to the Chapman-Shaoxing dataset to classify atrial fibrillation, as
well as another common arrhythmia, sinus bradycardia, and normal sinus rhythm
heartbeats. The models enable the identification of the key regions of the
heartbeat that determine the resulting classification, and highlight the
importance of P-waves and T-waves, as well as heartbeat duration and signal
amplitude, in distinguishing normal sinus rhythm from atrial fibrillation and
sinus bradycardia.

æè¦ï¼<paragraph>åºæ¼å¯ç©¿æ´å¼å®å°ç¨å¿é»å (ECG) è£ç½®çé ç«¯çæ£ç£æ¸¬å¨æ©æåµæ¸¬å¿èç¾çæ¹é¢å·æé¡¯èçæ½åï¼ç¹å¥æ¯èç¨æ¼èªååå¿èç¾çåµæ¸¬çäººå·¥æºæ§ (AI) æ¹æ³çµåä½¿ç¨æãååå·²æç ç©¶æç¨åºæ¼æ·±åº¦å­¸ç¿ç AI æ¹æ³é²è¡å¿èç¾çåµæ¸¬ãç¶èï¼éäºæ¨¡åå°æªè¢«å»£æ³æ¥åçºè¨åºè¨ºæ·çå¯é è¼å©å·¥å·ï¼é¨ååå å¨æ¼åç¹è¨±å¤ AI æ¼ç®æ³çç¶åé»ç®±æç¥ãç¹å¥æ¯ï¼æå¿è¦æ¾åºæå©æ¼ååºæºç¢ºè¨ºæ·ç ECG è¨èééµç¹å¾µï¼å¾èå¢å¼·æ¨¡åçå¯è§£éæ§ãå¨æ¬ç ç©¶ä¸­ï¼æåéç¼äºä¸ç¨®è¦è¦ºè½æå¨æ¹æ³ï¼ä»¥æ ¹æå®å°ç¨ ECG è³ææ¾åºå¿æ¿é¡«åãæ®å·®ç¶²è·¯ (ResNet) æ¹æ³ä¹å·²éç¼åºä¾ï¼ä»¥ä¾¿èè¦è¦ºè½æå¨æ¹æ³é²è¡æ¯è¼ãéäºæ¨¡åæç¨æ¼ Chapman-Shaoxing è³æéï¼ä»¥åé¡å¿æ¿é¡«åï¼ä»¥åå¦ä¸ç¨®å¸¸è¦çå¿å¾ä¸æ´ï¼ç«æ§å¿åéç·©ï¼åæ­£å¸¸ç«æ§å¿å¾çå¿è·³ãéäºæ¨¡åè½å¤ æ¾åºæ±ºå®æçµåé¡çå¿è·³ééµååï¼ä¸¦å¼·èª¿ P æ³¢å T æ³¢ï¼ä»¥åå¿è·³æçºæéåè¨èæ¯å¹å¨ååæ­£å¸¸ç«æ§å¿å¾èå¿æ¿é¡«ååç«æ§å¿åéç·©æ¹é¢çéè¦æ§ã</paragraph>

##### **Illuminate: A novel approach for depression detection with explainable analysis and proactive therapy using prompt engineering**
2402.05127v1 by Aryan Agrawal

This paper introduces a novel paradigm for depression detection and treatment
using advanced Large Language Models (LLMs): Generative Pre-trained Transformer
4 (GPT-4), Llama 2 chat, and Gemini. These LLMs are fine-tuned with specialized
prompts to diagnose, explain, and suggest therapeutic interventions for
depression. A unique few-shot prompting method enhances the models' ability to
analyze and explain depressive symptoms based on the DSM-5 criteria. In the
interaction phase, the models engage in empathetic dialogue management, drawing
from resources like PsychDB and a Cognitive Behavioral Therapy (CBT) Guide,
fostering supportive interactions with individuals experiencing major
depressive disorders. Additionally, the research introduces the Illuminate
Database, enriched with various CBT modules, aiding in personalized therapy
recommendations. The study evaluates LLM performance using metrics such as F1
scores, Precision, Recall, Cosine similarity, and Recall-Oriented Understudy
for Gisting Evaluation (ROUGE) across different test sets, demonstrating their
effectiveness. This comprehensive approach blends cutting-edge AI with
established psychological methods, offering new possibilities in mental health
care and showcasing the potential of LLMs in revolutionizing depression
diagnosis and treatment strategies.

æè¦ï¼æ¬æä»ç´¹äºä¸ç¨®ä½¿ç¨åé²å¤§åèªè¨æ¨¡å (LLM) é²è¡æé¬±çåµæ¸¬åæ²»ççæ°æ¨¡å¼ï¼çæå¼é è¨ç·´Transformer 4 (GPT-4)ãLlama 2 èå¤©æ©å¨äººå Geminiãéäº LLM ç¶éå¾®èª¿ï¼å·åå°æ¥­æç¤ºï¼å¯è¨ºæ·ãè§£éä¸¦å»ºè­°æé¬±ççæ²»çä»å¥æ¹æ³ãä¸ç¨®ç¨ç¹çå°æ¬¡æç¤ºæ¹æ³å¢å¼·äºæ¨¡åæ ¹æ DSM-5 æ¨æºåæåè§£éæé¬±çççè½åãå¨äºåéæ®µï¼éäºæ¨¡åæåèåçå¿å°è©±ç®¡çï¼å¾ PsychDB åèªç¥è¡çºçæ³ (CBT) æåç­è³æºä¸­æ±²åï¼ä¿é²èç¶æ­·éåº¦æé¬±ççäººåçæ¯ææ§äºåãæ­¤å¤ï¼éé ç ç©¶éä»ç´¹äº Illuminate è³æåº«ï¼å¶ä¸­åå«åç¨® CBT æ¨¡çµï¼æå©æ¼åæ§åæ²»çå»ºè­°ãéé ç ç©¶ä½¿ç¨ F1 åæ¸ãæºç¢ºçãå¬åçãé¤å¼¦ç¸ä¼¼åº¦åé¢åå¬åçç Gisting è©ä¼°æ¿èº« (ROUGE) ç­ææ¨ï¼å¨ä¸åçæ¸¬è©¦éä¸­è©ä¼° LLM çè¡¨ç¾ï¼è­æäºå®åçæææ§ãéç¨®ç¶åæ¹æ³çµåäºå°ç«¯ç AI èæ¢å®çå¿çæ¹æ³ï¼çºå¿çä¿å¥æä¾äºæ°çå¯è½æ§ï¼ä¸¦å±ç¤ºäº LLM å¨é©æ°æé¬±çè¨ºæ·åæ²»çç­ç¥æ¹é¢çæ½åã

##### **Information That Matters: Exploring Information Needs of People Affected by Algorithmic Decisions**
2401.13324v6 by TimothÃ©e Schmude, Laura Koesten, Torsten MÃ¶ller, Sebastian Tschiatschek

Every AI system that makes decisions about people has a group of stakeholders
that are personally affected by these decisions. However, explanations of AI
systems rarely address the information needs of this stakeholder group, who
often are AI novices. This creates a gap between conveyed information and
information that matters to those who are impacted by the system's decisions,
such as domain experts and decision subjects. To address this, we present the
"XAI Novice Question Bank," an extension of the XAI Question Bank containing a
catalog of information needs from AI novices in two use cases: employment
prediction and health monitoring. The catalog covers the categories of data,
system context, system usage, and system specifications. We gathered
information needs through task-based interviews where participants asked
questions about two AI systems to decide on their adoption and received verbal
explanations in response. Our analysis showed that participants' confidence
increased after receiving explanations but that their understanding faced
challenges. These included difficulties in locating information and in
assessing their own understanding, as well as attempts to outsource
understanding. Additionally, participants' prior perceptions of the systems'
risks and benefits influenced their information needs. Participants who
perceived high risks sought explanations about the intentions behind a system's
deployment, while those who perceived low risks rather asked about the system's
operation. Our work aims to support the inclusion of AI novices in
explainability efforts by highlighting their information needs, aims, and
challenges. We summarize our findings as five key implications that can inform
the design of future explanations for lay stakeholder audiences.

æè¦ï¼<paragraph>æ¯åå°äººååºæ±ºå®ç AI ç³»çµ±é½æä¸ç¾¤å©å®³éä¿äºº
åå°éäºæ±ºå®çè¦ªèº«å½±é¿ãç¶èï¼AI
ç³»çµ±çè§£éå¾å°è½æ»¿è¶³éç¾¤å©å®³éä¿äººçè³è¨éæ±ï¼èä»å
éå¸¸é½æ¯ AI æ°æãéé æäºå³éè³è¨è
åå°ç³»çµ±æ±ºç­å½±é¿çäººå£«ï¼ä¾å¦é åå°å®¶åæ±ºç­ä¸»é«ï¼éè¦çè³è¨ä¹éçè½å·®ãçºäºè§£æ±ºéååé¡ï¼æåæåºäº
ãXAI æ°æåé¡åº«ãï¼å®æ¯ XAI åé¡åº«çå»¶ä¼¸ï¼åå«ä¾èª AI æ°æå¨å©åä½¿ç¨æ¡ä¾ä¸­çè³è¨éæ±ç®éï¼å°±æ¥­
é æ¸¬åå¥åº·ç£æ¸¬ãç®éæ¶µèäºè³æã
ç³»çµ±èæ¯ãç³»çµ±ä½¿ç¨åç³»çµ±è¦æ ¼ç­é¡å¥ãæåééä»»ååè¨ªè«æ¶éè³è¨éæ±ï¼åèèå¨è¨ªè«ä¸­è©¢åäºå©å AI ç³»çµ±çåé¡ï¼ä»¥æ±ºå®æ¯å¦æ¡ç¨å®åï¼ä¸¦æ¶å°å£é ­
è§£éä½çºåæãæåçåæé¡¯ç¤ºï¼åèèå¨æ¶å°è§£éå¾ä¿¡å¿æææåï¼ä½ä»åççè§£å»é¢è¨ææ°ãéäºææ°åæ¬é£ä»¥æ¾å°è³è¨åè©ä¼°èªå·±ççè§£ï¼ä»¥åè©¦åå¤å
çè§£ãæ­¤å¤ï¼åèèå°ç³»çµ±é¢¨éªåå¥½èçåååé¥å½±é¿äºä»åçè³è¨éæ±ãèªçºé¢¨éªé«çåèèå°æ±è§£éç³»çµ±é¨ç½²èå¾çæåï¼èèªçºé¢¨éªä½çäººåè©¢åç³»çµ±ç
æä½ãæåçç ç©¶æ¨å¨ééå¼·èª¿ AI æ°æçè³è¨éæ±ãç®æ¨å
ææ°ï¼ä¾æ¯æå° AI æ°æç´å¥å¯è§£éæ§å·¥ä½ä¸­ãæåå°æåçç ç©¶çµæç¸½çµçºäºåééµåç¤ºï¼éäºåç¤ºå¯ä»¥çºæªä¾éå°éå°æ¥­å©å®³éä¿äººåç¾çè§£éè¨­è¨æä¾åèã</paragraph>

##### **Evaluating Large Language Models on the GMAT: Implications for the Future of Business Education**
2401.02985v1 by Vahid Ashrafimoghari, Necdet GÃ¼rkan, Jordan W. Suchow

The rapid evolution of artificial intelligence (AI), especially in the domain
of Large Language Models (LLMs) and generative AI, has opened new avenues for
application across various fields, yet its role in business education remains
underexplored. This study introduces the first benchmark to assess the
performance of seven major LLMs, OpenAI's models (GPT-3.5 Turbo, GPT-4, and
GPT-4 Turbo), Google's models (PaLM 2, Gemini 1.0 Pro), and Anthropic's models
(Claude 2 and Claude 2.1), on the GMAT, which is a key exam in the admission
process for graduate business programs. Our analysis shows that most LLMs
outperform human candidates, with GPT-4 Turbo not only outperforming the other
models but also surpassing the average scores of graduate students at top
business schools. Through a case study, this research examines GPT-4 Turbo's
ability to explain answers, evaluate responses, identify errors, tailor
instructions, and generate alternative scenarios. The latest LLM versions,
GPT-4 Turbo, Claude 2.1, and Gemini 1.0 Pro, show marked improvements in
reasoning tasks compared to their predecessors, underscoring their potential
for complex problem-solving. While AI's promise in education, assessment, and
tutoring is clear, challenges remain. Our study not only sheds light on LLMs'
academic potential but also emphasizes the need for careful development and
application of AI in education. As AI technology advances, it is imperative to
establish frameworks and protocols for AI interaction, verify the accuracy of
AI-generated content, ensure worldwide access for diverse learners, and create
an educational environment where AI supports human expertise. This research
sets the stage for further exploration into the responsible use of AI to enrich
educational experiences and improve exam preparation and assessment methods.

æè¦ï¼äººå·¥æºæ§ (AI) çå¿«éæ¼é²ï¼å°¤å¶æ¯å¨å¤§åèªè¨æ¨¡å (LLM) åçæå¼ AI çé åï¼çºååé åçæç¨éåäºæ°éå¾ï¼ä½å¶å¨åæ¥­æè²ä¸­çè§è²ä»æªè¢«ååæ¢è¨ãæ¬ç ç©¶é¦æ¬¡å¼å¥äºåºæºï¼ç¨ä»¥è©ä¼°ä¸åä¸»è¦ LLM çæè½ï¼åæ¬ OpenAI çæ¨¡å (GPT-3.5 TurboãGPT-4 å GPT-4 Turbo)ãGoogle çæ¨¡å (PaLM 2ãGemini 1.0 Pro) å Anthropic çæ¨¡å (Claude 2 å Claude 2.1)ï¼éäºæ¨¡åå°ç¨æ¼ç ç©¶çåæ¥­èª²ç¨å¥å­¸ç¨åºä¸­çééµèè©¦ GMATãæåçåæé¡¯ç¤ºï¼å¤§å¤æ¸ LLM çè¡¨ç¾é½åªæ¼äººé¡èçï¼å¶ä¸­ GPT-4 Turbo ä¸ååªæ¼å¶ä»æ¨¡åï¼æ´è¶è¶äºé å°åå­¸é¢çç ç©¶çå¹³ååæ¸ãééæ¡ä¾ç ç©¶ï¼æ¬ç ç©¶æ¢è¨äº GPT-4 Turbo å¨è§£éç­æ¡ãè©ä¼°åæãè¾¨è­é¯èª¤ãèª¿æ´èªªæåç¢çæ¿ä»£æå¢æ¹é¢çè½åãèåä¸ä»£çæ¬ç¸æ¯ï¼ææ°ç LLM çæ¬ GPT-4 TurboãClaude 2.1 å Gemini 1.0 Pro å¨æ¨çä»»åæ¹é¢æé¡¯èçé²æ­¥ï¼å¸é¡¯äºå¶å¨è§£æ±ºè¤éåé¡æ¹é¢çæ½åãåç®¡ AI å¨æè²ãè©éåè¼å°æ¹é¢çæ¿è«¾å¾æç¢ºï¼ä½ä»æææ°å­å¨ãæåçç ç©¶ä¸åé¡æäº LLM çå­¸è¡æ½åï¼ä¹å¼·èª¿äºå¨æè²ä¸­å¯©æéç¼åæç¨ AI çå¿è¦æ§ãé¨è AI æè¡çé²æ­¥ï¼å»ºç« AI äºåçæ¶æ§ååå®ãé©è­ AI çæçå§å®¹çæºç¢ºæ§ãç¢ºä¿å¨çåå°å¤åå­¸ç¿èçå­åæ¬ï¼ä»¥ååµé ä¸å AI æ¯æäººé¡å°æ¥­ç¥è­çæè²ç°å¢è³ééè¦ãæ¬ç ç©¶çºé²ä¸æ­¥æ¢ç´¢è² è²¬ä»»å°ä½¿ç¨ AI ä¾è±å¯æè²é«é©ä¸¦æ¹åèè©¦æºååè©éæ¹æ³å¥ å®äºåºç¤ã

##### **XAI for In-hospital Mortality Prediction via Multimodal ICU Data**
2312.17624v1 by Xingqiao Li, Jindong Gu, Zhiyong Wang, Yancheng Yuan, Bo Du, Fengxiang He

Predicting in-hospital mortality for intensive care unit (ICU) patients is
key to final clinical outcomes. AI has shown advantaged accuracy but suffers
from the lack of explainability. To address this issue, this paper proposes an
eXplainable Multimodal Mortality Predictor (X-MMP) approaching an efficient,
explainable AI solution for predicting in-hospital mortality via multimodal ICU
data. We employ multimodal learning in our framework, which can receive
heterogeneous inputs from clinical data and make decisions. Furthermore, we
introduce an explainable method, namely Layer-Wise Propagation to Transformer,
as a proper extension of the LRP method to Transformers, producing explanations
over multimodal inputs and revealing the salient features attributed to
prediction. Moreover, the contribution of each modality to clinical outcomes
can be visualized, assisting clinicians in understanding the reasoning behind
decision-making. We construct a multimodal dataset based on MIMIC-III and
MIMIC-III Waveform Database Matched Subset. Comprehensive experiments on
benchmark datasets demonstrate that our proposed framework can achieve
reasonable interpretation with competitive prediction accuracy. In particular,
our framework can be easily transferred to other clinical tasks, which
facilitates the discovery of crucial factors in healthcare research.

æè¦ï¼é æ¸¬å è­·çæ¿ (ICU) çæ£çé¢å§æ­»äº¡çæ¯æçµè¨åºçµæçééµãAI å·²å±ç¾åºåªç°çæºç¢ºåº¦ï¼ä½å»ç¼ºä¹å¯è§£éæ§ãçºäºè§£æ±ºéååé¡ï¼æ¬ææåºäºä¸åå¯è§£éçå¤æ¨¡å¼æ­»äº¡çé æ¸¬å¨ (X-MMP)ï¼æ¡ç¨ææä¸å¯è§£éç AI æ¹å¼ï¼èç±å¤æ¨¡å¼ ICU è³æä¾é æ¸¬é¢å§æ­»äº¡çãæåå¨æ¶æ§ä¸­æ¡ç¨å¤æ¨¡å¼å­¸ç¿ï¼å¯ä»¥æ¥æ¶ä¾èªè¨åºè³æçç°è³ªè¼¸å¥ä¸¦ååºæ±ºç­ãæ­¤å¤ï¼æåå¼å¥äºä¸åå¯è§£éçæ¹æ³ï¼ä¹å°±æ¯åå±¤å³æ­è³ Transformerï¼ä½çº LRP æ¹æ³é©ç¶å°å»¶ä¼¸è³ Transformerï¼å°å¤æ¨¡å¼è¼¸å¥ç¢çè§£éï¼ä¸¦æ­é²æ­¸å æ¼é æ¸¬çé¡¯èç¹å¾µãæ­¤å¤ï¼æ¯åæ¨¡å¼å°è¨åºçµæçè²¢ç»å¯ä»¥è¦è¦ºåï¼åå©è¨åºé«å¸«äºè§£æ±ºç­èå¾ççç±ãæåæ ¹æ MIMIC-III å MIMIC-III æ³¢å½¢è³æåº«æ¯å°å­éå»ºæ§äºä¸åå¤æ¨¡å¼è³æéãå¨åºæºè³æéä¸çå¨é¢å¯¦é©è­æï¼æåæåºçæ¶æ§å¯ä»¥éæåççè©®éï¼ä¸¦å·åç«¶ç­åçé æ¸¬æºç¢ºåº¦ãç¹å¥æ¯ï¼æåçæ¶æ§å¯ä»¥è¼é¬å°è½ç§»å°å¶ä»è¨åºä»»åï¼éæå©æ¼å¨é«çä¿å¥ç ç©¶ä¸­ç¼ç¾ééµå ç´ ã

##### **Joining Forces for Pathology Diagnostics with AI Assistance: The EMPAIA Initiative**
2401.09450v2 by Norman Zerbe, Lars Ole Schwen, Christian GeiÃler, Katja Wiesemann, Tom Bisson, Peter Boor, Rita Carvalho, Michael Franz, Christoph Jansen, Tim-Rasmus Kiehl, BjÃ¶rn Lindequist, Nora Charlotte Pohlan, Sarah Schmell, Klaus Strohmenger, Falk Zakrzewski, Markus Plass, Michael Takla, Tobias KÃ¼ster, AndrÃ© Homeyer, Peter Hufnagl

Over the past decade, artificial intelligence (AI) methods in pathology have
advanced substantially. However, integration into routine clinical practice has
been slow due to numerous challenges, including technical and regulatory
hurdles in translating research results into clinical diagnostic products and
the lack of standardized interfaces. The open and vendor-neutral EMPAIA
initiative addresses these challenges. Here, we provide an overview of EMPAIA's
achievements and lessons learned. EMPAIA integrates various stakeholders of the
pathology AI ecosystem, i.e., pathologists, computer scientists, and industry.
In close collaboration, we developed technical interoperability standards,
recommendations for AI testing and product development, and explainability
methods. We implemented the modular and open-source EMPAIA platform and
successfully integrated 14 AI-based image analysis apps from 8 different
vendors, demonstrating how different apps can use a single standardized
interface. We prioritized requirements and evaluated the use of AI in real
clinical settings with 14 different pathology laboratories in Europe and Asia.
In addition to technical developments, we created a forum for all stakeholders
to share information and experiences on digital pathology and AI. Commercial,
clinical, and academic stakeholders can now adopt EMPAIA's common open-source
interfaces, providing a unique opportunity for large-scale standardization and
streamlining of processes. Further efforts are needed to effectively and
broadly establish AI assistance in routine laboratory use. To this end, a
sustainable infrastructure, the non-profit association EMPAIA International,
has been established to continue standardization and support broad
implementation and advocacy for an AI-assisted digital pathology future.

æè¦ï¼å¨éå»çåå¹´ä¸­ï¼ççå­¸ä¸­çäººå·¥æºæ§ (AI) æ¹æ³å·²å¤§å¹é²æ­¥ãç¶èï¼ç±æ¼è¨±å¤ææ°ï¼åæ¬å°ç ç©¶çµæè½åçºè¨åºè¨ºæ·ç¢åå¨æè¡åæ³è¦æ¹é¢çéç¤ï¼ä»¥åç¼ºä¹æ¨æºåä»é¢ï¼å°è´æ´åå°å¸¸è¦è¨åºå¯¦åä¸­é²å±ç·©æ¢ãéæ¾ä¸èä¾æåç¡éç EMPAIA è¨ç«æå°äºéäºææ°ãå¨æ­¤ï¼æåæä¾ EMPAIA çæå°±åç¶é©æè¨çæ¦è¿°ãEMPAIA æ´åäºççå­¸ AI çæç³»çµ±çååå©å®³éä¿äººï¼å³ççå­¸å®¶ãé»è¦ç§å­¸å®¶åç¢æ¥­ãå¨å¯ååä½ä¸ï¼æåå¶å®äºæè¡äºéæ§æ¨æºãAI æ¸¬è©¦åç¢åéç¼å»ºè­°ï¼ä»¥åå¯è§£éæ§æ¹æ³ãæåå¯¦ä½äºæ¨¡çµåä¸éæ¾åå§ç¢¼ç EMPAIA å¹³èºï¼ä¸¦æåæ´åäºä¾èª 8 åä¸åä¾æåç 14 ååºæ¼ AI çå½±ååææç¨ç¨å¼ï¼å±ç¤ºäºä¸åçæç¨ç¨å¼å¦ä½ä½¿ç¨å®ä¸çæ¨æºåä»é¢ãæååªåèæ®éæ±ï¼ä¸¦è©ä¼°äº AI å¨æ­æ´²åäºæ´²ç 14 åä¸åççå¯¦é©å®¤ä¸­çå¯¦éè¨åºæç¨ãé¤äºæè¡éç¼å¤ï¼æåéçºææå©å®³éä¿äººå»ºç«äºä¸åè«å£ï¼ä»¥åäº«æ¸ä½ççå­¸å AI çè³è¨åç¶é©ãåæ¥­ãè¨åºåå­¸è¡å©å®³éä¿äººç¾å¨å¯ä»¥æ¡ç¨ EMPAIA çå¸¸è¦éæ¾åå§ç¢¼ä»é¢ï¼éçºå¤§è¦æ¨¡æ¨æºååç°¡åæµç¨æä¾äºç¨ç¹çæ©æãéè¦é²ä¸æ­¥çåªåæè½ææä¸å»£æ³å°å»ºç«ä¾è¡å¯¦é©å®¤ä½¿ç¨ä¸­ç AI è¼å©ãçºæ­¤ï¼å·²æç«éçå©åæ EMPAIA Internationalï¼ä»¥ä½çºæ°¸çºåºç¤æ¶æ§ï¼ç¹¼çºé²è¡æ¨æºåï¼ä¸¦æ¯æ´å»£æ³å¯¦ä½åå¡å° AI è¼å©æ¸ä½ççå­¸çæªä¾ã

##### **Robust Stochastic Graph Generator for Counterfactual Explanations**
2312.11747v2 by Mario Alfonso Prado-Romero, Bardh Prenkaj, Giovanni Stilo

Counterfactual Explanation (CE) techniques have garnered attention as a means
to provide insights to the users engaging with AI systems. While extensively
researched in domains such as medical imaging and autonomous vehicles, Graph
Counterfactual Explanation (GCE) methods have been comparatively
under-explored. GCEs generate a new graph similar to the original one, with a
different outcome grounded on the underlying predictive model. Among these GCE
techniques, those rooted in generative mechanisms have received relatively
limited investigation despite demonstrating impressive accomplishments in other
domains, such as artistic styles and natural language modelling. The preference
for generative explainers stems from their capacity to generate counterfactual
instances during inference, leveraging autonomously acquired perturbations of
the input graph. Motivated by the rationales above, our study introduces
RSGG-CE, a novel Robust Stochastic Graph Generator for Counterfactual
Explanations able to produce counterfactual examples from the learned latent
space considering a partially ordered generation sequence. Furthermore, we
undertake quantitative and qualitative analyses to compare RSGG-CE's
performance against SoA generative explainers, highlighting its increased
ability to engendering plausible counterfactual candidates.

æè¦ï¼åäºå¯¦è§£é (CE) æè¡å·²å¼èµ·éæ³¨ï¼ä½çºä¸ç¨®çºè AI ç³»çµ±äºåçä½¿ç¨èæä¾è¦è§£çæ¹æ³ãéç¶å¨é«å­¸å½±ååèªåé§é§æ±½è»ç­é åå»£æ³ç ç©¶ï¼åå½¢åäºå¯¦è§£é (GCE) æ¹æ³ç¸å°è¼å°è¢«æ¢ç´¢ãGCE æç¢çä¸åé¡ä¼¼æ¼åå§åå½¢çæ°åå½¢ï¼ä¸¦æ ¹æåºç¤é æ¸¬æ¨¡åç¢çä¸åççµæãå¨éäº GCE æè¡ä¸­ï¼åç®¡å¨å¶ä»é åï¼ä¾å¦èè¡é¢¨æ ¼åèªç¶èªè¨å»ºæ¨¡ï¼ä¸­å±ç¾åºä»¤äººå°è±¡æ·±å»çæå°±ï¼ä½æ¤åºæ¼çææ©å¶çæè¡ç²å¾çéæ³¨ç¸å°æéãå°çæå¼è§£éå¨çåå¥½æºæ¼å®åå¨æ¨çæéç¢çåäºå¯¦å¯¦ä¾çè½åï¼å©ç¨è¼¸å¥åå½¢çèªä¸»ç²åæ¾åãåºæ¼ä¸è¿°çç±ï¼æåçç ç©¶å¼å¥äº RSGG-CEï¼ä¸ç¨®ç¨æ¼åäºå¯¦è§£éçæ°åç©©å¥é¨æ©åå½¢çæå¨ï¼è½å¤ å¾å­¸ç¿å°çæ½å¨ç©ºéä¸­ç¢çåäºå¯¦ç¯ä¾ï¼èæ®é¨åæåºççæåºåãæ­¤å¤ï¼æåé²è¡å®éåå®æ§åæï¼ä»¥æ¯è¼ RSGG-CE çæè½è SoA çæå¼è§£éå¨ï¼å¼·èª¿å¶å¢å¼·äºç¢çåçè§£éåé¸çè½åã

##### **Evaluating the Utility of Model Explanations for Model Development**
2312.06032v1 by Shawn Im, Jacob Andreas, Yilun Zhou

One of the motivations for explainable AI is to allow humans to make better
and more informed decisions regarding the use and deployment of AI models. But
careful evaluations are needed to assess whether this expectation has been
fulfilled. Current evaluations mainly focus on algorithmic properties of
explanations, and those that involve human subjects often employ subjective
questions to test human's perception of explanation usefulness, without being
grounded in objective metrics and measurements. In this work, we evaluate
whether explanations can improve human decision-making in practical scenarios
of machine learning model development. We conduct a mixed-methods user study
involving image data to evaluate saliency maps generated by SmoothGrad,
GradCAM, and an oracle explanation on two tasks: model selection and
counterfactual simulation. To our surprise, we did not find evidence of
significant improvement on these tasks when users were provided with any of the
saliency maps, even the synthetic oracle explanation designed to be simple to
understand and highly indicative of the answer. Nonetheless, explanations did
help users more accurately describe the models. These findings suggest caution
regarding the usefulness and potential for misunderstanding in saliency-based
explanations.

æè¦ï¼å¯è§£é AI çåæ©ä¹ä¸æ¯è®äººåå¨ä½¿ç¨åé¨ç½² AI æ¨¡åæååºæ´å¥½ãæ´ææºçæ±ºç­ãä½éè¦ä»ç´°è©ä¼°ä»¥è©ä¼°æ¯å¦å·²éå°æ­¤é æãç®åçè©ä¼°ä¸»è¦éä¸­å¨è§£éçæ¼ç®æ³ç¹æ§ï¼èæ¶åäººé¡åè©¦èçè©ä¼°éå¸¸æ¡ç¨ä¸»è§åé¡ä¾æ¸¬è©¦äººé¡å°è§£éæç¨æ§ççæ³ï¼èæ²æåºæ¼å®¢è§ææ¨åæ¸¬éãå¨éé å·¥ä½ä¸­ï¼æåè©ä¼°è§£éæ¯å¦å¯ä»¥å¨æ©å¨å­¸ç¿æ¨¡åéç¼çå¯¦éå ´æ¯ä¸­æ¹åäººé¡æ±ºç­å¶å®ãæåé²è¡äºä¸é æ¶åå½±åè³æçæ··åæ¹æ³ä½¿ç¨èç ç©¶ï¼ä»¥è©ä¼° SmoothGradãGradCAM åé è¨è§£éå¨å©åä»»åä¸­ç¢ççé¡¯èæ§åï¼æ¨¡åé¸æååäºå¯¦æ¨¡æ¬ãä»¤äººé©è¨çæ¯ï¼æåæ²æç¼ç¾ä»»ä½é¡¯èæ§åï¼å³ä½¿æ¯è¨­è¨çºææ¼çè§£ä¸é«åº¦æç¤ºç­æ¡çåæé è¨è§£éï¼è½è®ä½¿ç¨èå¨éäºä»»åä¸é¡¯èæ¹åçè­æãåç®¡å¦æ­¤ï¼è§£éç¢ºå¯¦æå©æ¼ä½¿ç¨èæ´æºç¢ºå°æè¿°æ¨¡åãéäºç¼ç¾æç¤ºæåè¦å°åºæ¼é¡¯èæ§çè§£éä¸­å¯è½å­å¨èª¤è§£çæç¨æ§ä¿æè¬¹æã

##### **Building Trustworthy NeuroSymbolic AI Systems: Consistency, Reliability, Explainability, and Safety**
2312.06798v1 by Manas Gaur, Amit Sheth

Explainability and Safety engender Trust. These require a model to exhibit
consistency and reliability. To achieve these, it is necessary to use and
analyze data and knowledge with statistical and symbolic AI methods relevant to
the AI application - neither alone will do. Consequently, we argue and seek to
demonstrate that the NeuroSymbolic AI approach is better suited for making AI a
trusted AI system. We present the CREST framework that shows how Consistency,
Reliability, user-level Explainability, and Safety are built on NeuroSymbolic
methods that use data and knowledge to support requirements for critical
applications such as health and well-being. This article focuses on Large
Language Models (LLMs) as the chosen AI system within the CREST framework. LLMs
have garnered substantial attention from researchers due to their versatility
in handling a broad array of natural language processing (NLP) scenarios. For
example, ChatGPT and Google's MedPaLM have emerged as highly promising
platforms for providing information in general and health-related queries,
respectively. Nevertheless, these models remain black boxes despite
incorporating human feedback and instruction-guided tuning. For instance,
ChatGPT can generate unsafe responses despite instituting safety guardrails.
CREST presents a plausible approach harnessing procedural and graph-based
knowledge within a NeuroSymbolic framework to shed light on the challenges
associated with LLMs.

æè¦ï¼å¯è§£éæ§åå®å¨æ§å»ºç«ä¿¡ä»»ãéäºéè¦ä¸åæ¨¡åä¾å±ç¤ºä¸è´æ§åå¯é æ§ãçºäºå¯¦ç¾éäºï¼æå¿è¦ä½¿ç¨ååææ¸æåç¥è­ï¼ä¸¦ä½¿ç¨è AI æç¨ç¸éççµ±è¨åç¬¦è AI æ¹æ³ - å®ç¨ä½¿ç¨ä»»ä½ä¸ç¨®æ¹æ³é½ä¸æå¥æãå æ­¤ï¼æåä¸»å¼µä¸¦è©¦åè­æ NeuroSymbolic AI æ¹æ³æ´é©åæ¼ä½¿ AI æçºåä¿¡ä»»ç AI ç³»çµ±ãæåæåºäº CREST æ¡æ¶ï¼å±ç¤ºäºä¸è´æ§ãå¯é æ§ãä½¿ç¨èå±¤ç´çå¯è§£éæ§åå®å¨æ§æ¯å¦ä½å»ºç«å¨ NeuroSymbolic æ¹æ³ä¸çï¼è©²æ¹æ³ä½¿ç¨æ¸æåç¥è­ä¾æ¯æééµæç¨ï¼ä¾å¦å¥åº·åç¦ç¥ï¼çè¦æ±ãæ¬æéé»éæ³¨å¤§åèªè¨æ¨¡å (LLM)ï¼å çºå®æ¯ CREST æ¡æ¶ä¸­é¸æç AI ç³»çµ±ãLLM å å¶å¨èçå»£æ³çèªç¶èªè¨èç (NLP) å ´æ¯æ¹é¢çå¤åè½æ§èååç ç©¶äººå¡çéæ³¨ãä¾å¦ï¼ChatGPT å Google ç MedPaLM å·²æçºæä¾ä¸è¬åå¥åº·ç¸éæ¥è©¢ä¿¡æ¯çæ¥µæå¸æçå¹³å°ãåç®¡å¦æ­¤ï¼éäºæ¨¡åä»ç¶æ¯é»çå­ï¼åç®¡ç´å¥äºäººé¡åé¥åæä»¤å¼å°çèª¿æ´ãä¾å¦ï¼åç®¡å¶å®äºå®å¨é²è­·æªæ½ï¼ChatGPT ä»å¯è½ç¢çä¸å®å¨çåæãCREST æåºäºä¸ç¨®åççæ¹æ³ï¼å¨ NeuroSymbolic æ¡æ¶ä¸­å©ç¨ç¨åºååºæ¼åè¡¨çç¥è­ï¼ä»¥é¡æè LLM ç¸éçææ°ã

##### **Class-Discriminative Attention Maps for Vision Transformers**
2312.02364v3 by Lennart Brocki, Jakub Binda, Neo Christopher Chung

Importance estimators are explainability methods that quantify feature
importance for deep neural networks (DNN). In vision transformers (ViT), the
self-attention mechanism naturally leads to attention maps, which are sometimes
interpreted as importance scores that indicate which input features ViT models
are focusing on. However, attention maps do not account for signals from
downstream tasks. To generate explanations that are sensitive to downstream
tasks, we have developed class-discriminative attention maps (CDAM), a
gradient-based extension that estimates feature importance with respect to a
known class or a latent concept. CDAM scales attention scores by how relevant
the corresponding tokens are for the predictions of a classifier head. In
addition to targeting the supervised classifier, CDAM can explain an arbitrary
concept shared by selected samples by measuring similarity in the latent space
of ViT. Additionally, we introduce Smooth CDAM and Integrated CDAM, which
average a series of CDAMs with slightly altered tokens. Our quantitative
benchmarks include correctness, compactness, and class sensitivity, in
comparison to 7 other importance estimators. Vanilla, Smooth, and Integrated
CDAM excel across all three benchmarks. In particular, our results suggest that
existing importance estimators may not provide sufficient class-sensitivity. We
demonstrate the utility of CDAM in medical images by training and explaining
malignancy and biomarker prediction models based on lung Computed Tomography
(CT) scans. Overall, CDAM is shown to be highly class-discriminative and
semantically relevant, while providing compact explanations.

æè¦ï¼<paragraph>éè¦æ§ä¼°è¨å¨æ¯ä¸ç¨®å¯è§£éæ§æ¹æ³ï¼ç¨æ¼éåæ·±åº¦ç¥ç¶ç¶²è·¯ (DNN) çç¹å¾µéè¦æ§ãå¨è¦è¦ºTransformer (ViT) ä¸­ï¼èªææ³¨ææ©å¶èªç¶æå°è´æ³¨æååï¼æææå°å¶è§£éçºéè¦æ§åæ¸ï¼è¡¨ç¤º ViT æ¨¡åéæ³¨åªäºè¼¸å¥ç¹å¾µãç¶èï¼æ³¨æååä¸¦æªèæ®ä¾èªä¸æ¸¸ä»»åçä¿¡èãçºäºç¢çå°ä¸æ¸¸ä»»åææçè§£éï¼æåéç¼äºé¡å¥ååæ³¨æåå (CDAM)ï¼éæ¯ä¸ç¨®åºæ¼æ¢¯åº¦çæ´åï¼ç¨æ¼ä¼°è¨ç¸å°æ¼å·²ç¥é¡å¥ææ½å¨æ¦å¿µçç¹å¾µéè¦æ§ãCDAM æ ¹æå°æçç¬¦èèåé¡å¨é ­çé æ¸¬ç¸éç¨åº¦ï¼èª¿æ´æ³¨æååæ¸ãé¤äºéå°ç£ç£åé¡å¨å¤ï¼CDAM éå¯ä»¥ééæ¸¬é ViT çæ½å¨ç©ºéä¸­çç¸ä¼¼æ§ä¾è§£éé¸å®æ¨£æ¬å±æçä»»ææ¦å¿µãæ­¤å¤ï¼æåå¼å¥äºå¹³æ» CDAM åç©å CDAMï¼å®åå°ä¸ç³»åå·æç¥å¾®æ¹è®çç¬¦èç CDAM é²è¡å¹³åãæåçéååºæºåæ¬æ­£ç¢ºæ§ãç·æ¹æ§åé¡å¥æææ§ï¼èå¶ä» 7 åéè¦æ§ä¼°è¨å¨ç¸æ¯ãé¦èãå¹³æ»åç©å CDAM å¨ææä¸ååºæºä¸­è¡¨ç¾åºè²ãç¹å¥æ¯ï¼æåççµæè¡¨æç¾æçéè¦æ§ä¼°è¨å¨å¯è½ç¡æ³æä¾è¶³å¤ çé¡å¥æææ§ãæåééåºæ¼èºé¨é»è¦æ·å±¤ææ (CT) ææè¨ç·´åè§£éæ¡æ§è«ç¤åçç©æ¨è¨é æ¸¬æ¨¡åï¼è­æäº CDAM å¨é«å­¸å½±åä¸­çæç¨ãç¸½çä¾èªªï¼CDAM è¢«è­æå·æé«åº¦é¡å¥ååæ§åèªç¾©ç¸éæ§ï¼åææä¾ç°¡æ½çè§£éã</paragraph>


### Knowledge Graphs
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2025-01-08**|**FlairGPT: Repurposing LLMs for Interior Designs**|Gabrielle Littlefair et.al.|[2501.04648v1](http://arxiv.org/abs/2501.04648v1)|null|
|**2025-01-08**|**CGP-Tuning: Structure-Aware Soft Prompt Tuning for Code Vulnerability Detection**|Ruijun Feng et.al.|[2501.04510v1](http://arxiv.org/abs/2501.04510v1)|null|
|**2025-01-08**|**Multimodal Graph Constrastive Learning and Prompt for ChartQA**|Yue Dai et.al.|[2501.04303v1](http://arxiv.org/abs/2501.04303v1)|null|
|**2025-01-07**|**Applying Large Language Models in Knowledge Graph-based Enterprise Modeling: Challenges and Opportunities**|Benedikt Reitemeyer et.al.|[2501.03566v1](http://arxiv.org/abs/2501.03566v1)|null|
|**2025-01-07**|**KG-TRICK: Unifying Textual and Relational Information Completion of Knowledge for Multilingual Knowledge Graphs**|Zelin Zhou et.al.|[2501.03560v1](http://arxiv.org/abs/2501.03560v1)|null|
|**2025-01-06**|**Semantic Captioning: Benchmark Dataset and Graph-Aware Few-Shot In-Context Learning for SQL2Text**|Ali Al-Lawati et.al.|[2501.03166v1](http://arxiv.org/abs/2501.03166v1)|[link](https://github.com/aliwister/ast-icl)|
|**2025-01-06**|**Personalized Fashion Recommendation with Image Attributes and Aesthetics Assessment**|Chongxian Chen et.al.|[2501.03085v1](http://arxiv.org/abs/2501.03085v1)|null|
|**2025-01-06**|**Graph-based Retrieval Augmented Generation for Dynamic Few-shot Text Classification**|Yubo Wang et.al.|[2501.02844v1](http://arxiv.org/abs/2501.02844v1)|null|
|**2025-01-06**|**KG-CF: Knowledge Graph Completion with Context Filtering under the Guidance of Large Language Models**|Zaiyi Zheng et.al.|[2501.02711v1](http://arxiv.org/abs/2501.02711v1)|null|
|**2025-01-04**|**Graph-Aware Isomorphic Attention for Adaptive Dynamics in Transformers**|Markus J. Buehler et.al.|[2501.02393v2](http://arxiv.org/abs/2501.02393v2)|[link](https://github.com/lamm-mit/graph-aware-transformers)|
|**2025-01-04**|**What Kind of Visual Tokens Do We Need? Training-free Visual Token Pruning for Multi-modal Large Language Models from the Perspective of Graph**|Yutao Jiang et.al.|[2501.02268v1](http://arxiv.org/abs/2501.02268v1)|null|
|**2025-01-04**|**Personalized Graph-Based Retrieval for Large Language Models**|Steven Au et.al.|[2501.02157v1](http://arxiv.org/abs/2501.02157v1)|[link](https://github.com/pgraphrag-benchmark/pgr-llm)|
|**2025-01-03**|**Cold-Start Recommendation towards the Era of Large Language Models (LLMs): A Comprehensive Survey and Roadmap**|Weizhi Zhang et.al.|[2501.01945v1](http://arxiv.org/abs/2501.01945v1)|null|
|**2025-01-03**|**Multimodal Contrastive Representation Learning in Augmented Biomedical Knowledge Graphs**|Tien Dang et.al.|[2501.01644v1](http://arxiv.org/abs/2501.01644v1)|null|
|**2025-01-02**|**Enhancing Uncertainty Modeling with Semantic Graph for Hallucination Detection**|Kedi Chen et.al.|[2501.02020v1](http://arxiv.org/abs/2501.02020v1)|null|
|**2025-01-01**|**Unfolding the Headline: Iterative Self-Questioning for News Retrieval and Timeline Summarization**|Weiqi Wu et.al.|[2501.00888v1](http://arxiv.org/abs/2501.00888v1)|[link](https://github.com/Alibaba-NLP/CHRONOS)|
|**2025-01-01**|**Breaking Through the Spike: Spike Window Decoding for Accelerated and Precise Automatic Speech Recognition**|Wei Zhang et.al.|[2501.03257v1](http://arxiv.org/abs/2501.03257v1)|null|
|**2025-01-01**|**SmartSpatial: Enhancing the 3D Spatial Arrangement Capabilities of Stable Diffusion Models and Introducing a Novel 3D Spatial Evaluation Framework**|Mao Xun Huang et.al.|[2501.01998v1](http://arxiv.org/abs/2501.01998v1)|null|
|**2024-12-31**|**Causal Graph Guided Steering of LLM Values via Prompts and Sparse Autoencoders**|Yipeng Kang et.al.|[2501.00581v1](http://arxiv.org/abs/2501.00581v1)|null|
|**2024-12-31**|**CancerKG.ORG A Web-scale, Interactive, Verifiable Knowledge Graph-LLM Hybrid for Assisting with Optimal Cancer Treatment and Care**|Michael Gubanov et.al.|[2501.00223v1](http://arxiv.org/abs/2501.00223v1)|null|
|**2024-12-31**|**The Potential of LLMs in Automating Software Testing: From Generation to Reporting**|Betim Sherifi et.al.|[2501.00217v1](http://arxiv.org/abs/2501.00217v1)|null|
|**2024-12-30**|**Detection-Fusion for Knowledge Graph Extraction from Videos**|Taniya Das et.al.|[2501.00136v1](http://arxiv.org/abs/2501.00136v1)|[link](https://github.com/Taniya-Das/video_annotation)|
|**2024-12-30**|**Machine Learning-Based Security Policy Analysis**|Krish Jain et.al.|[2501.00085v2](http://arxiv.org/abs/2501.00085v2)|null|
|**2024-12-30**|**KARPA: A Training-free Method of Adapting Knowledge Graph as References for Large Language Model's Reasoning Path Aggregation**|Siyuan Fang et.al.|[2412.20995v1](http://arxiv.org/abs/2412.20995v1)|null|
|**2024-12-30**|**Ontology-grounded Automatic Knowledge Graph Construction by LLM under Wikidata schema**|Xiaohan Feng et.al.|[2412.20942v1](http://arxiv.org/abs/2412.20942v1)|null|
|**2024-12-29**|**ICLR: In-Context Learning of Representations**|Core Francisco Park et.al.|[2501.00070v1](http://arxiv.org/abs/2501.00070v1)|null|
|**2024-12-28**|**Topic-Aware Knowledge Graph with Large Language Models for Interoperability in Recommender Systems**|Minhye Jeon et.al.|[2412.20163v1](http://arxiv.org/abs/2412.20163v1)|null|
|**2024-12-28**|**From Generalist to Specialist: A Survey of Large Language Models for Chemistry**|Yang Han et.al.|[2412.19994v1](http://arxiv.org/abs/2412.19994v1)|[link](https://github.com/opendfm/llm4chemistry)|
|**2024-12-27**|**Toward Adaptive Reasoning in Large Language Models with Thought Rollback**|Sijia Chen et.al.|[2412.19707v1](http://arxiv.org/abs/2412.19707v1)|[link](https://github.com/iQua/llmpebase)|
|**2024-12-26**|**Dynamic Skill Adaptation for Large Language Models**|Jiaao Chen et.al.|[2412.19361v1](http://arxiv.org/abs/2412.19361v1)|null|
|**2024-12-26**|**Relation-aware Hierarchical Prompt for Open-vocabulary Scene Graph Generation**|Tao Liu et.al.|[2412.19021v1](http://arxiv.org/abs/2412.19021v1)|null|
|**2024-12-25**|**PhyloGen: Language Model-Enhanced Phylogenetic Inference via Graph Structure Generation**|ChenRui Duan et.al.|[2412.18827v1](http://arxiv.org/abs/2412.18827v1)|null|
|**2024-12-24**|**CypherBench: Towards Precise Retrieval over Full-scale Modern Knowledge Graphs in the LLM Era**|Yanlin Feng et.al.|[2412.18702v1](http://arxiv.org/abs/2412.18702v1)|[link](https://github.com/megagonlabs/cypherbench)|
|**2024-12-24**|**From Hallucinations to Facts: Enhancing Language Models with Curated Knowledge Graphs**|Ratnesh Kumar Joshi et.al.|[2412.18672v1](http://arxiv.org/abs/2412.18672v1)|null|
|**2024-12-24**|**Harnessing Large Language Models for Knowledge Graph Question Answering via Adaptive Multi-Aspect Retrieval-Augmentation**|Derong Xu et.al.|[2412.18537v2](http://arxiv.org/abs/2412.18537v2)|null|
|**2024-12-24**|**DynaGRAG: Improving Language Understanding and Generation through Dynamic Subgraph Representation in Graph Retrieval-Augmented Generation**|Karishma Thakrar et.al.|[2412.18644v1](http://arxiv.org/abs/2412.18644v1)|null|
|**2024-12-24**|**Is Large Language Model Good at Triple Set Prediction? An Empirical Study**|Yuan Yuan et.al.|[2412.18443v1](http://arxiv.org/abs/2412.18443v1)|null|
|**2024-12-24**|**Investigating Large Language Models for Code Vulnerability Detection: An Experimental Study**|Xuefeng Jiang et.al.|[2412.18260v2](http://arxiv.org/abs/2412.18260v2)|[link](https://github.com/sakirinn/llm4cvd)|
|**2024-12-24**|**An Automatic Graph Construction Framework based on Large Language Models for Recommendation**|Rong Shan et.al.|[2412.18241v1](http://arxiv.org/abs/2412.18241v1)|[link](https://github.com/lavieenrose365/autograph)|
|**2024-12-23**|**CARL-GT: Evaluating Causal Reasoning Capabilities of Large Language Models**|Ruibo Tu et.al.|[2412.17970v1](http://arxiv.org/abs/2412.17970v1)|[link](https://github.com/turuibo/cautabbench)|
|**2024-12-23**|**Path-of-Thoughts: Extracting and Following Paths for Robust Relational Reasoning with Large Language Models**|Ge Zhang et.al.|[2412.17963v1](http://arxiv.org/abs/2412.17963v1)|null|
|**2024-12-23**|**ResearchTown: Simulator of Human Research Community**|Haofei Yu et.al.|[2412.17767v1](http://arxiv.org/abs/2412.17767v1)|[link](https://github.com/ulab-uiuc/research-town)|
|**2024-12-23**|**RAGONITE: Iterative Retrieval on Induced Databases and Verbalized RDF for Conversational QA over KGs with RAG**|Rishiraj Saha Roy et.al.|[2412.17690v3](http://arxiv.org/abs/2412.17690v3)|null|
|**2024-12-23**|**A Dual-Perspective Metaphor Detection Framework Using Large Language Models**|Yujie Lin et.al.|[2412.17332v2](http://arxiv.org/abs/2412.17332v2)|[link](https://github.com/deeplearnxmu/dmd)|
|**2024-12-22**|**GraphAgent: Agentic Graph Language Assistant**|Yuhao Yang et.al.|[2412.17029v1](http://arxiv.org/abs/2412.17029v1)|null|
|**2024-12-22**|**Enhancing Supply Chain Transparency in Emerging Economies Using Online Contents and LLMs**|Bohan Jin et.al.|[2412.16922v1](http://arxiv.org/abs/2412.16922v1)|null|
|**2024-12-22**|**KG4Diagnosis: A Hierarchical Multi-Agent LLM Framework with Knowledge Graph Enhancement for Medical Diagnosis**|Kaiwen Zuo et.al.|[2412.16833v2](http://arxiv.org/abs/2412.16833v2)|null|
|**2024-12-21**|**Apples to Apples: Establishing Comparability in Knowledge Generation Tasks Involving Users**|Christophe Debruyne et.al.|[2412.16766v1](http://arxiv.org/abs/2412.16766v1)|null|
|**2024-12-21**|**Self-guided Knowledgeable Network of Thoughts: Amplifying Reasoning with Large Language Models**|Chao-Chi Chen et.al.|[2412.16533v1](http://arxiv.org/abs/2412.16533v1)|null|
|**2024-12-21**|**Beyond End-to-End VLMs: Leveraging Intermediate Text Representations for Superior Flowchart Understanding**|Junyi Ye et.al.|[2412.16420v1](http://arxiv.org/abs/2412.16420v1)|[link](https://github.com/junyiye/textflow)|
|**2024-12-20**|**HybGRAG: Hybrid Retrieval-Augmented Generation on Textual and Relational Knowledge Bases**|Meng-Chieh Lee et.al.|[2412.16311v1](http://arxiv.org/abs/2412.16311v1)|null|
|**2024-12-20**|**Logical Consistency of Large Language Models in Fact-checking**|Bishwamittra Ghosh et.al.|[2412.16100v1](http://arxiv.org/abs/2412.16100v1)|null|
|**2024-12-20**|**GraphSeqLM: A Unified Graph Language Framework for Omic Graph Learning**|Heming Zhang et.al.|[2412.15790v1](http://arxiv.org/abs/2412.15790v1)|null|
|**2024-12-20**|**KRAIL: A Knowledge-Driven Framework for Base Human Reliability Analysis Integrating IDHEAS and Large Language Models**|Xingyu Xiao et.al.|[2412.18627v1](http://arxiv.org/abs/2412.18627v1)|null|
|**2024-12-20**|**NGQA: A Nutritional Graph Question Answering Benchmark for Personalized Health-aware Nutritional Reasoning**|Zheyuan Zhang et.al.|[2412.15547v1](http://arxiv.org/abs/2412.15547v1)|null|
|**2024-12-19**|**SKETCH: Structured Knowledge Enhanced Text Comprehension for Holistic Retrieval**|Aakash Mahalingam et.al.|[2412.15443v1](http://arxiv.org/abs/2412.15443v1)|null|
|**2024-12-19**|**Graph-Convolutional Networks: Named Entity Recognition and Large Language Model Embedding in Document Clustering**|Imed Keraghel et.al.|[2412.14867v1](http://arxiv.org/abs/2412.14867v1)|null|
|**2024-12-19**|**Answer Set Networks: Casting Answer Set Programming into Deep Learning**|Arseny Skryagin et.al.|[2412.14814v1](http://arxiv.org/abs/2412.14814v1)|null|
|**2024-12-19**|**IOHunter: Graph Foundation Model to Uncover Online Information Operations**|Marco Minici et.al.|[2412.14663v1](http://arxiv.org/abs/2412.14663v1)|[link](https://github.com/mminici/socgfm)|
|**2024-12-19**|**GraphEQA: Using 3D Semantic Scene Graphs for Real-time Embodied Question Answering**|Saumya Saxena et.al.|[2412.14480v1](http://arxiv.org/abs/2412.14480v1)|null|
|**2024-12-18**|**Discovering maximally consistent distribution of causal tournaments with Large Language Models**|Federico Baldo et.al.|[2412.14019v1](http://arxiv.org/abs/2412.14019v1)|null|
|**2024-12-18**|**DODGE: Ontology-Aware Risk Assessment via Object-Oriented Disruption Graphs**|Stefano M. Nicoletti et.al.|[2412.13964v1](http://arxiv.org/abs/2412.13964v1)|null|
|**2024-12-18**|**Knowledge Editing with Dynamic Knowledge Graphs for Multi-Hop Question Answering**|Yifan Lu et.al.|[2412.13782v2](http://arxiv.org/abs/2412.13782v2)|null|
|**2024-12-18**|**Bridging the User-side Knowledge Gap in Knowledge-aware Recommendations with Large Language Models**|Zheng Hu et.al.|[2412.13544v1](http://arxiv.org/abs/2412.13544v1)|[link](https://github.com/laowangzi/cikgrec)|
|**2024-12-18**|**Benchmarking and Improving Large Vision-Language Models for Fundamental Visual Graph Understanding and Reasoning**|Yingjie Zhu et.al.|[2412.13540v1](http://arxiv.org/abs/2412.13540v1)|[link](https://github.com/aaandy-zhu/vgcure)|
|**2024-12-18**|**Transducer Tuning: Efficient Model Adaptation for Software Tasks Using Code Property Graphs**|Imam Nur Bani Yusuf et.al.|[2412.13467v1](http://arxiv.org/abs/2412.13467v1)|[link](https://github.com/imamnurby/transducer-tuning)|
|**2024-12-17**|**Enhancing Persona Classification in Dialogue Systems: A Graph Neural Network Approach**|Konstantin Zaitsev et.al.|[2412.13283v1](http://arxiv.org/abs/2412.13283v1)|null|
|**2024-12-17**|**SimGRAG: Leveraging Similar Subgraphs for Knowledge Graphs Driven Retrieval-Augmented Generation**|Yuzheng Cai et.al.|[2412.15272v1](http://arxiv.org/abs/2412.15272v1)|[link](https://github.com/YZ-Cai/SimGRAG)|
|**2024-12-17**|**Detecting Emotional Incongruity of Sarcasm by Commonsense Reasoning**|Ziqi Qiu et.al.|[2412.12808v2](http://arxiv.org/abs/2412.12808v2)|null|
|**2024-12-17**|**AnalogXpert: Automating Analog Topology Synthesis by Incorporating Circuit Design Expertise into Large Language Models**|Haoyi Zhang et.al.|[2412.19824v1](http://arxiv.org/abs/2412.19824v1)|null|
|**2024-12-17**|**LLM-based Discriminative Reasoning for Knowledge Graph Question Answering**|Mufan Xu et.al.|[2412.12643v1](http://arxiv.org/abs/2412.12643v1)|null|
|**2024-12-17**|**SynthCypher: A Fully Synthetic Data Generation Framework for Text-to-Cypher Querying in Knowledge Graphs**|Aman Tiwari et.al.|[2412.12612v1](http://arxiv.org/abs/2412.12612v1)|null|
|**2024-12-17**|**Enhancing LLM-based Hatred and Toxicity Detection with Meta-Toxic Knowledge Graph**|Yibo Zhao et.al.|[2412.15268v2](http://arxiv.org/abs/2412.15268v2)|null|
|**2024-12-17**|**Graph Learning in the Era of LLMs: A Survey from the Perspective of Data, Models, and Tasks**|Xunkai Li et.al.|[2412.12456v1](http://arxiv.org/abs/2412.12456v1)|null|
|**2024-12-16**|**Graph-Guided Textual Explanation Generation Framework**|Shuzhou Yuan et.al.|[2412.12318v1](http://arxiv.org/abs/2412.12318v1)|null|
|**2024-12-16**|**Cost-Effective Label-free Node Classification with LLMs**|Taiyan Zhang et.al.|[2412.11983v1](http://arxiv.org/abs/2412.11983v1)|null|
|**2024-12-16**|**SE-GCL: An Event-Based Simple and Effective Graph Contrastive Learning for Text Representation**|Tao Meng et.al.|[2412.11652v1](http://arxiv.org/abs/2412.11652v1)|null|
|**2024-12-16**|**EvoLlama: Enhancing LLMs' Understanding of Proteins via Multimodal Structure and Sequence Representations**|Nuowei Liu et.al.|[2412.11618v1](http://arxiv.org/abs/2412.11618v1)|null|
|**2024-12-16**|**Embodied CoT Distillation From LLM To Off-the-shelf Agents**|Wonje Choi et.al.|[2412.11499v1](http://arxiv.org/abs/2412.11499v1)|null|
|**2024-12-16**|**Structured Extraction of Real World Medical Knowledge using LLMs for Summarization and Search**|Edward Kim et.al.|[2412.15256v1](http://arxiv.org/abs/2412.15256v1)|null|
|**2024-12-16**|**How Can LLMs and Knowledge Graphs Contribute to Robot Safety? A Few-Shot Learning Approach**|Abdulrahman Althobaiti et.al.|[2412.11387v1](http://arxiv.org/abs/2412.11387v1)|null|
|**2024-12-15**|**Embracing Large Language Models in Traffic Flow Forecasting**|Yusheng Zhao et.al.|[2412.12201v1](http://arxiv.org/abs/2412.12201v1)|null|
|**2024-12-15**|**SceneLLM: Implicit Language Reasoning in LLM for Dynamic Scene Graph Generation**|Hang Zhang et.al.|[2412.11026v1](http://arxiv.org/abs/2412.11026v1)|null|
|**2024-12-14**|**MedG-KRP: Medical Graph Knowledge Representation Probing**|Gabriel R. Rosenbaum et.al.|[2412.10982v2](http://arxiv.org/abs/2412.10982v2)|null|
|**2024-12-14**|**Thinking with Knowledge Graphs: Enhancing LLM Reasoning Through Structured Data**|Xue Wu et.al.|[2412.10654v1](http://arxiv.org/abs/2412.10654v1)|null|
|**2024-12-13**|**WHAT-IF: Exploring Branching Narratives by Meta-Prompting Large Language Models**|Runsheng "Anson" Huang et.al.|[2412.10582v2](http://arxiv.org/abs/2412.10582v2)|null|
|**2024-12-13**|**A Decade of Deep Learning: A Survey on The Magnificent Seven**|Dilshod Azizov et.al.|[2412.16188v1](http://arxiv.org/abs/2412.16188v1)|null|
|**2024-12-13**|**Can LLMs Convert Graphs to Text-Attributed Graphs?**|Zehong Wang et.al.|[2412.10136v1](http://arxiv.org/abs/2412.10136v1)|[link](https://github.com/zehong-wang/tans)|
|**2024-12-13**|**Lost in the Middle, and In-Between: Enhancing Language Models' Ability to Reason Over Long Contexts in Multi-Hop QA**|George Arthur Baker et.al.|[2412.10079v1](http://arxiv.org/abs/2412.10079v1)|[link](https://github.com/spongeorge/long-context-multihop)|
|**2024-12-13**|**Low-Resource Fast Text Classification Based on Intra-Class and Inter-Class Distance Calculation**|Yanxu Mao et.al.|[2412.09922v1](http://arxiv.org/abs/2412.09922v1)|null|
|**2024-12-12**|**MGM: Global Understanding of Audience Overlap Graphs for Predicting the Factuality and the Bias of News Media**|Muhammad Arslan Manzoor et.al.|[2412.10467v1](http://arxiv.org/abs/2412.10467v1)|[link](https://github.com/marslanm/mgm_code)|
|**2024-12-12**|**Uncommon Belief in Rationality**|Qi Shi et.al.|[2412.09407v1](http://arxiv.org/abs/2412.09407v1)|null|
|**2024-12-12**|**Foundation Models and Adaptive Feature Selection: A Synergistic Approach to Video Question Answering**|Sai Bhargav Rongali et.al.|[2412.09230v1](http://arxiv.org/abs/2412.09230v1)|null|
|**2024-12-12**|**Filter-then-Generate: Large Language Models with Structure-Text Adapter for Knowledge Graph Completion**|Ben Liu et.al.|[2412.09094v2](http://arxiv.org/abs/2412.09094v2)|[link](https://github.com/lb0828/ftg)|
|**2024-12-12**|**Neural Interactive Proofs**|Lewis Hammond et.al.|[2412.08897v1](http://arxiv.org/abs/2412.08897v1)|null|
|**2024-12-12**|**A Graph-Based Synthetic Data Pipeline for Scaling High-Quality Reasoning Instructions**|Jiankang Wang et.al.|[2412.08864v1](http://arxiv.org/abs/2412.08864v1)|null|
|**2024-12-11**|**In-Context Learning with Topological Information for Knowledge Graph Completion**|Udari Madhushani Sehwag et.al.|[2412.08742v1](http://arxiv.org/abs/2412.08742v1)|null|
|**2024-12-11**|**VEL: A Formally Verified Reasoner for OWL2 EL Profile**|Atalay Mert Ileri et.al.|[2412.08739v1](http://arxiv.org/abs/2412.08739v1)|null|
|**2024-12-11**|**From communities to interpretable network and word embedding: an unified approach**|Thibault Prouteau et.al.|[2412.08187v1](http://arxiv.org/abs/2412.08187v1)|null|
|**2024-12-11**|**Can Graph Neural Networks Learn Language with Extremely Weak Text Supervision?**|Zihao Li et.al.|[2412.08174v2](http://arxiv.org/abs/2412.08174v2)|null|

#### Abstracts
##### **FlairGPT: Repurposing LLMs for Interior Designs**
2501.04648v1 by Gabrielle Littlefair, Niladri Shekhar Dutt, Niloy J. Mitra

Interior design involves the careful selection and arrangement of objects to
create an aesthetically pleasing, functional, and harmonized space that aligns
with the client's design brief. This task is particularly challenging, as a
successful design must not only incorporate all the necessary objects in a
cohesive style, but also ensure they are arranged in a way that maximizes
accessibility, while adhering to a variety of affordability and usage
considerations. Data-driven solutions have been proposed, but these are
typically room- or domain-specific and lack explainability in their design
design considerations used in producing the final layout. In this paper, we
investigate if large language models (LLMs) can be directly utilized for
interior design. While we find that LLMs are not yet capable of generating
complete layouts, they can be effectively leveraged in a structured manner,
inspired by the workflow of interior designers. By systematically probing LLMs,
we can reliably generate a list of objects along with relevant constraints that
guide their placement. We translate this information into a design layout
graph, which is then solved using an off-the-shelf constrained optimization
setup to generate the final layouts. We benchmark our algorithm in various
design configurations against existing LLM-based methods and human designs, and
evaluate the results using a variety of quantitative and qualitative metrics
along with user studies. In summary, we demonstrate that LLMs, when used in a
structured manner, can effectively generate diverse high-quality layouts,
making them a viable solution for creating large-scale virtual scenes. Project
webpage at https://flairgpt.github.io/

æè¦ï¼å®¤å§è¨­è¨æ¶åä»ç´°æé¸åå®æç©ä»¶ï¼ä»¥åµé ä¸åç¾è§ãå¯¦ç¨ä¸åè«§çç©ºéï¼ç¬¦åå®¢æ¶çè¨­è¨ç°¡å ±ãéé ä»»åç¹å¥å·æææ°æ§ï¼å çºæåçè¨­è¨ä¸åå¿é ä»¥ä¸è´çé¢¨æ ¼ç´å¥ææå¿è¦çç©ä»¶ï¼éå¿é ç¢ºä¿å®åçæåæ¹å¼è½æå¤§åå¯åæ§ï¼åæç¬¦ååç¨®è² æè½ååä½¿ç¨èéãå·²ç¶æåºäºè³æé©åçè§£æ±ºæ¹æ¡ï¼ä½éäºè§£æ±ºæ¹æ¡éå¸¸æ¯ç¹å®æ¼æ¿éæé åï¼èä¸ç¼ºä¹å¨ç¢çæçµä½å±ææä½¿ç¨çè¨­è¨èéçå¯è§£éæ§ãå¨æ¬æä¸­ï¼æåæ¢è¨å¤§åèªè¨æ¨¡å (LLM) æ¯å¦å¯ä»¥ç´æ¥ç¨æ¼å®¤å§è¨­è¨ãéç¶æåç¼ç¾ LLM å°æªè½å¤ ç¢çå®æ´çä½å±ï¼ä½å®åå¯ä»¥ææå°ä»¥çµæ§åçæ¹å¼å©ç¨ï¼éæä¾èªå®¤å§è¨­è¨å¸«çå·¥ä½æµç¨ãééç³»çµ±æ§å°æ¢æ¥ LLMï¼æåå¯ä»¥å¯é å°ç¢çä¸åç©ä»¶æ¸å®ï¼ä»¥åæå°å®åæ¾ç½®ä½ç½®çç¸å³ç´æãæåå°éäºè³è¨è½ææè¨­è¨ä½å±åï¼ç¶å¾ä½¿ç¨ç¾æçç´æå¼æä½³åè¨­å®ä¾è§£æ±ºï¼ä»¥ç¢çæçµä½å±ãæåå¨åç¨®è¨­è¨éç½®ä¸­å°æåçæ¼ç®æ³èç¾æçåºæ¼ LLM çæ¹æ³åäººé¡è¨­è¨é²è¡åºæºæ¸¬è©¦ï¼ä¸¦ä½¿ç¨åç¨®éååè³ªåææ¨ä»¥åä½¿ç¨èç ç©¶ä¾è©ä¼°çµæãç¸½ä¹ï¼æåè­æäº LLM å¨ä»¥çµæ§åçæ¹å¼ä½¿ç¨æï¼å¯ä»¥ææå°ç¢çå¤æ¨£åçé«åè³ªä½å±ï¼ä½¿å¶æçºåµé å¤§åèæ¬å ´æ¯çå¯è¡è§£æ±ºæ¹æ¡ãå°æ¡ç¶²é å¨ https://flairgpt.github.io/

##### **CGP-Tuning: Structure-Aware Soft Prompt Tuning for Code Vulnerability Detection**
2501.04510v1 by Ruijun Feng, Hammond Pearce, Pietro Liguori, Yulei Sui

Large language models (LLMs) have been proposed as powerful tools for
detecting software vulnerabilities, where task-specific fine-tuning is
typically employed to provide vulnerability-specific knowledge to the LLMs for
this purpose. However, traditional full-parameter fine-tuning is inefficient
for modern, complex LLMs, which contain billions of parameters.
  Soft prompt tuning has been suggested as a more efficient alternative for
fine-tuning LLMs in general cases. However, pure soft prompt tuning treats
source code as plain text, losing structural information inherent in source
code. Meanwhile, graph-enhanced soft prompt tuning methods, which aim to
address this issue, are unable to preserve the rich semantic information within
code graphs, as they are primarily designed for general graph-related tasks and
focus more on adjacency information. They also fail to ensure computational
efficiency while accounting for graph-text interactions.
  This paper, therefore, introduces a new code graph-enhanced, structure-aware
soft prompt tuning method for vulnerability detection, referred to as
CGP-Tuning. It employs innovative type-aware embeddings to capture the rich
semantic information within code graphs, along with a novel and efficient
cross-modal alignment module that achieves linear computational cost while
incorporating graph-text interactions. The proposed CGP-Tuning is evaluated on
the latest DiverseVul dataset and the most recent open-source code LLMs,
CodeLlama and CodeGemma. Experimental results demonstrate that CGP-Tuning
outperforms the best state-of-the-art method by an average of 3.5 percentage
points in accuracy, without compromising its vulnerability detection
capabilities for long source code.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å·²è¢«æåºç¨æ¼åµæ¸¬è»é«æ¼æ´çå¼·å¤§å·¥å·ï¼å¶ä¸­ä»»åç¹å®å¾®èª¿éå¸¸ç¨æ¼æä¾æ¼æ´ç¹å®ç¥è­çµ¦ LLM ä»¥éå°æ­¤ç®çãç¶èï¼å³çµ±çå®æ´åæ¸å¾®èª¿å°æ¼åå«æ¸ååååæ¸çç¾ä»£è¤é LLM ä¾èªªæçä½ä¸ã
è»æç¤ºå¾®èª¿å·²è¢«å»ºè­°ä½çºä¸è¬ææ³ä¸å¾®èª¿ LLM çæ´æææ¿ä»£æ¹æ¡ãç¶èï¼ç´è»æç¤ºå¾®èª¿å°åå§ç¢¼è¦çºç´æå­ï¼å¤±å»äºåå§ç¢¼ä¸­åºæççµæ§è³è¨ãåæï¼æ¨å¨è§£æ±ºæ­¤åé¡çåå½¢å¢å¼·è»æç¤ºå¾®èª¿æ¹æ³ç¡æ³ä¿çç¨å¼ç¢¼åå½¢ä¸­çè±å¯èªç¾©è³è¨ï¼å çºå®åä¸»è¦è¨­è¨ç¨æ¼ä¸è¬çåå½¢ç¸éä»»åï¼ä¸æ´å°æ³¨æ¼é°æ¥è³è¨ãå®åä¹ç¡æ³å¨èéåå½¢æå­äºåçåæç¢ºä¿éç®æçã
å æ­¤ï¼æ¬æä»ç´¹äºä¸ç¨®æ°çç¨å¼ç¢¼åå½¢å¢å¼·ãçµæ§æç¥è»æç¤ºå¾®èª¿æ¹æ³ä¾åµæ¸¬æ¼æ´ï¼ç¨±çº CGP-Tuningãå®æ¡ç¨åµæ°çé¡åæç¥åµå¥ä¾æ·åç¨å¼ç¢¼åå½¢ä¸­çè±å¯èªç¾©è³è¨ï¼ä»¥åä¸åæ°ç©ä¸ææçè·¨æ¨¡æå°é½æ¨¡çµï¼è©²æ¨¡çµå¨ç´å¥åå½¢æå­äºåçåæå¯¦ç¾ç·æ§éç®ææ¬ãæè­°ç CGP-Tuning å¨ææ°ç DiverseVul è³æéåææ°çéæºç¨å¼ç¢¼ LLMï¼CodeLlama å CodeGemmaï¼ä¸é²è¡è©ä¼°ãå¯¦é©çµæè­æï¼CGP-Tuning å¨æºç¢ºåº¦æ¹é¢å¹³åæ¯æä½³çç¾ææè¡é«åº 3.5 åç¾åé»ï¼åæä¸æå®³å¶å°é·åå§ç¢¼çæ¼æ´åµæ¸¬è½åã

##### **Multimodal Graph Constrastive Learning and Prompt for ChartQA**
2501.04303v1 by Yue Dai, Soyeon Caren Han, Wei Liu

ChartQA presents significant challenges due to the complex distribution of
chart elements and the implicit patterns embedded within the underlying data.
In this chapter, we have developed a joint multimodal scene graph for charts,
explicitly representing the relationships between chart elements and their
associated patterns.
  Our proposed multimodal scene graph consists of two components: a visual
graph and a textual graph, each designed to capture the structural and semantic
information within the chart. To unify representations across these different
modalities, we introduce a multimodal graph contrastive learning approach that
learns unified representations by maximizing similarity between nodes
representing the same object across multimodal graphs. The learned graph
representations can be seamlessly incorporated into a transformer decoder as a
soft prompt.
  Additionally, given the growing need for Multimodal Large Language Models
(MLLMs) in zero-shot scenarios, we have designed Chain-of-Thought (CoT) prompts
for MLLMs to reduce hallucinations. We tested both methods on public benchmarks
such as ChartQA, OpenCQA, and ChartX, demonstrating improved performance and
validating the effectiveness of our proposed methods.

æè¦ï¼ChartQA å åè¡¨åç´ çè¤éåä½ååºç¤è³æä¸­å§åµçé±å«æ¨¡å¼èé¢è¨éå¤§ææ°ã
å¨æ¬ç« ä¸­ï¼æåçºåè¡¨éç¼äºä¸åè¯åå¤æ¨¡æå ´æ¯åå½¢ï¼æç¢ºè¡¨ç¤ºåè¡¨åç´ ä¹éçéä¿åå¶éè¯æ¨¡å¼ã
æåæåºçå¤æ¨¡æå ´æ¯åå½¢åå«å©åçµæé¨åï¼ä¸åè¦è¦ºåå½¢åä¸åææ¬åå½¢ï¼æ¯åçµæé¨åé½æ¨å¨æ·ååè¡¨ä¸­ççµæ§ååèªç¾©è³è¨ã
çºäºçµ±ä¸éäºä¸åæ¨¡æçè¡¨ç¤ºï¼æåå¼å¥äºä¸åå¤æ¨¡æåå½¢å°æ¯å­¸ç¿æ¹æ³ï¼ééæå¤§åè·¨å¤æ¨¡æåå½¢è¡¨ç¤ºç¸åç©ä»¶çç¯é»ä¹éçç¸ä¼¼æ§ä¾å­¸ç¿çµ±ä¸çè¡¨ç¤ºã
å­¸ç¿å°çåå½¢è¡¨ç¤ºå¯ä»¥ç¡ç¸«å°æ´åå°Transformerè§£ç¢¼å¨ä¸­ï¼ä½çºä¸åè»æç¤ºã
æ­¤å¤ï¼éæ¼å¤æ¨¡æå¤§åèªè¨æ¨¡å (MLLM) å¨é¶æ¬¡å­¸ç¿å ´æ¯ä¸­çéæ±æ¥çå¢å ï¼æåçº MLLM è¨­è¨äºæèé (CoT) æç¤ºï¼ä»¥æ¸å°å¹»è¦ºã
æåå¨å¬ç¾åºæºä¸æ¸¬è©¦äºéå©ç¨®æ¹æ³ï¼ä¾å¦ ChartQAãOpenCQA å ChartXï¼è­æäºæè½çæåï¼ä¸¦é©è­äºæåæåºçæ¹æ³çæææ§ã

##### **Applying Large Language Models in Knowledge Graph-based Enterprise Modeling: Challenges and Opportunities**
2501.03566v1 by Benedikt Reitemeyer, Hans-Georg Fill

The role of large language models (LLMs) in enterprise modeling has recently
started to shift from academic research to that of industrial applications.
Thereby, LLMs represent a further building block for the machine-supported
generation of enterprise models. In this paper we employ a knowledge
graph-based approach for enterprise modeling and investigate the potential
benefits of LLMs in this context. In addition, the findings of an expert survey
and ChatGPT-4o-based experiments demonstrate that LLM-based model generations
exhibit minimal variability, yet remain constrained to specific tasks, with
reliability declining for more intricate tasks. The survey results further
suggest that the supervision and intervention of human modeling experts are
essential to ensure the accuracy and integrity of the generated models.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å¨ä¼æ¥­å»ºæ¨¡ä¸­çè§è²æè¿å·²éå§å¾å­¸è¡ç ç©¶è½è®çºç¢æ¥­æç¨ãå æ­¤ï¼LLM ä»£è¡¨äºæ©å¨æ¯æ´çä¼æ¥­æ¨¡åçæçé²ä¸æ­¥å»ºæ§æ¨¡çµãå¨æ¬æä¸­ï¼æåæ¡ç¨åºæ¼ç¥è­åè¡¨çä¼æ¥­å»ºæ¨¡æ¹æ³ï¼ä¸¦æ¢è¨ LLM å¨æ­¤èçµ¡ä¸­çæ½å¨æçãæ­¤å¤ï¼å°å®¶èª¿æ¥ååºæ¼ ChatGPT-4o çå¯¦é©çµæè¡¨æï¼åºæ¼ LLM çæ¨¡åçæå±ç¾æå°çå¯è®æ§ï¼ä½ä»ä¾·éæ¼ç¹å®ä»»åï¼èå¯é æ§æé¨èä»»åçè¤éæ§èä¸éãèª¿æ¥çµæé²ä¸æ­¥è¡¨æï¼äººé¡å»ºæ¨¡å°å®¶çç£ç£åä»å¥å°æ¼ç¢ºä¿çææ¨¡åçæºç¢ºæ§åå®æ´æ§è³ééè¦ã

##### **KG-TRICK: Unifying Textual and Relational Information Completion of Knowledge for Multilingual Knowledge Graphs**
2501.03560v1 by Zelin Zhou, Simone Conia, Daniel Lee, Min Li, Shenglei Huang, Umar Farooq Minhas, Saloni Potdar, Henry Xiao, Yunyao Li

Multilingual knowledge graphs (KGs) provide high-quality relational and
textual information for various NLP applications, but they are often
incomplete, especially in non-English languages. Previous research has shown
that combining information from KGs in different languages aids either
Knowledge Graph Completion (KGC), the task of predicting missing relations
between entities, or Knowledge Graph Enhancement (KGE), the task of predicting
missing textual information for entities. Although previous efforts have
considered KGC and KGE as independent tasks, we hypothesize that they are
interdependent and mutually beneficial. To this end, we introduce KG-TRICK, a
novel sequence-to-sequence framework that unifies the tasks of textual and
relational information completion for multilingual KGs. KG-TRICK demonstrates
that: i) it is possible to unify the tasks of KGC and KGE into a single
framework, and ii) combining textual information from multiple languages is
beneficial to improve the completeness of a KG. As part of our contributions,
we also introduce WikiKGE10++, the largest manually-curated benchmark for
textual information completion of KGs, which features over 25,000 entities
across 10 diverse languages.

æè¦ï¼å¤èªè¨ç¥è­åè­ (KG) çºåç¨® NLP æç¨ç¨å¼æä¾é«åè³ªçéä¿åæå­è³è¨ï¼ä½å®åéå¸¸æ¯ä¸å®æ´çï¼ç¹å¥æ¯éè±èªèªè¨ãååçç ç©¶é¡¯ç¤ºï¼çµåä¸åèªè¨ä¸­ KG çè³è¨æå©æ¼ç¥è­åè­å®æåè½ (KGC)ï¼å³é æ¸¬å¯¦é«ä¹ééºå¤±çéä¿ï¼æç¥è­åè­å¢å¼· (KGE)ï¼å³é æ¸¬å¯¦é«éºå¤±çæå­è³è¨ãåç®¡ååçåªåå° KGC å KGE è¦çºç¨ç«çä»»åï¼æååè¨­å®åæ¯ç¸äºä¾è³´ä¸äºå©çãçºæ­¤ï¼æåå¼å¥äº KG-TRICKï¼ä¸åæ°ç©çåºåå°åºåæ¶æ§ï¼å®çµ±ä¸äºå¤èªè¨ KG çæå­åéä¿è³è¨å®æä»»åãKG-TRICK è­æï¼i) å¯ä»¥å° KGC å KGE çä»»åçµ±ä¸å°å®ä¸æ¶æ§ä¸­ï¼ä»¥å ii) çµåå¤ç¨®èªè¨çæå­è³è¨æå©æ¼æé« KG çå®æ´æ§ãä½çºæåè²¢ç»çä¸é¨åï¼æåéå¼å¥äº WikiKGE10++ï¼éæ¯ KG æå­è³è¨å®ææå¤§çæåæ´çåºæºï¼å¶ç¹é»æ¯è¶é 10 ç¨®ä¸åèªè¨ä¸­ç 25,000 åå¯¦é«ã

##### **Semantic Captioning: Benchmark Dataset and Graph-Aware Few-Shot In-Context Learning for SQL2Text**
2501.03166v1 by Ali Al-Lawati, Jason Lucas, Prasenjit Mitra

Large Language Models (LLMs) have demonstrated remarkable performance in
various NLP tasks, including semantic parsing, which trans lates natural
language into formal code representations. However, the reverse process,
translating code into natural language, termed semantic captioning, has
received less attention. This task is becoming increasingly important as LLMs
are integrated into platforms for code generation, security analysis, and
educational purposes. In this paper, we focus on the captioning of SQL query
(SQL2Text) to address the critical need for understanding and explaining SQL
queries in an era where LLM-generated code poses potential security risks. We
repurpose Text2SQL datasets for SQL2Text by introducing an iterative ICL prompt
using GPT-4o to generate multiple additional utterances, which enhances the
robustness of the datasets for the reverse task. We conduct our experiments
using in-context learning (ICL) based on different sample selection methods,
emphasizing smaller, more computationally efficient LLMs. Our findings
demonstrate that leveraging the inherent graph properties of SQL for ICL sample
selection significantly outperforms random selection by up to 39% on BLEU score
and provides better results than alternative methods. Dataset and codes are
published: \url{https://github.com/aliwister/ast-icl}.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å·²å¨åç¨® NLP ä»»åä¸­å±ç¾åºé©äººçæè½ï¼åæ¬èªæåæï¼å®å°èªç¶èªè¨è½æçºæ­£å¼çç¨å¼ç¢¼è¡¨ç¤ºãç¶èï¼ååéç¨ï¼å°ç¨å¼ç¢¼è½æçºèªç¶èªè¨ï¼ç¨±çºèªææ¨é¡ï¼åè¼å°åå°éæ³¨ãé¨è LLM æ´åå°ç¨å¼ç¢¼ç¢çãå®å¨æ§åæåæè²ç®ççå¹³å°ä¸­ï¼éé ä»»åæ­£è®å¾è¶ä¾è¶éè¦ãå¨æ¬æä¸­ï¼æåå°æ³¨æ¼ SQL æ¥è©¢çæ¨é¡ (SQL2Text)ï¼ä»¥æ»¿è¶³å¨ LLM ç¢ççç¨å¼ç¢¼æ§ææ½å¨å®å¨é¢¨éªçæä»£ä¸­ï¼çè§£åè§£é SQL æ¥è©¢çééµéæ±ãæåééä½¿ç¨ GPT-4o å°å¥åè¦ç ICL æç¤ºä¾ç¢çå¤åé¡å¤çèªå¥ï¼éæ°èª¿æ´ Text2SQL è³æéä»¥ç¨æ¼ SQL2Textï¼éå¢å¼·äºè³æéå°ååä»»åçç©©å¥æ§ãæåä½¿ç¨åºæ¼ä¸åç¯ä¾é¸åæ¹æ³çæå¢å­¸ç¿ (ICL) é²è¡å¯¦é©ï¼å¼·èª¿è¼å°ãè¨ç®æçè¼é«ç LLMãæåçç ç©¶çµæè­æï¼å©ç¨ SQL çå§å¨åå½¢å±¬æ§é²è¡ ICL ç¯ä¾é¸åï¼å¨ BLEU åæ¸ä¸é¡¯èåªæ¼é¨æ©é¸åï¼æå¤å¯é 39%ï¼ä¸¦æä¾æ¯å¶ä»æ¹æ³æ´å¥½ççµæãè³æéåç¨å¼ç¢¼å·²ç¼å¸ï¼\url{https://github.com/aliwister/ast-icl}ã

##### **Personalized Fashion Recommendation with Image Attributes and Aesthetics Assessment**
2501.03085v1 by Chongxian Chen, Fan Mo, Xin Fan, Hayato Yamana

Personalized fashion recommendation is a difficult task because 1) the
decisions are highly correlated with users' aesthetic appetite, which previous
work frequently overlooks, and 2) many new items are constantly rolling out
that cause strict cold-start problems in the popular identity (ID)-based
recommendation methods. These new items are critical to recommend because of
trend-driven consumerism. In this work, we aim to provide more accurate
personalized fashion recommendations and solve the cold-start problem by
converting available information, especially images, into two attribute graphs
focusing on optimized image utilization and noise-reducing user modeling.
Compared with previous methods that separate image and text as two components,
the proposed method combines image and text information to create a richer
attributes graph. Capitalizing on the advancement of large language and vision
models, we experiment with extracting fine-grained attributes efficiently and
as desired using two different prompts. Preliminary experiments on the IQON3000
dataset have shown that the proposed method achieves competitive accuracy
compared with baselines.

æè¦ï¼å®¢è£½åæå°æ¨è¦æ¯ä¸é å°é£çä»»åï¼å çº 1) æ±ºç­èä½¿ç¨èçç¾å­¸åå¥½é«åº¦ç¸éï¼èååçç ç©¶ç¶å¸¸å¿½ç¥éä¸é»ï¼ä»¥å 2) è¨±å¤æ°ååä¸æ·æ¨åºï¼éæå¨æµè¡çèº«å (ID) çºåºç¤çæ¨è¦æ¹æ³ä¸­é æå´éçå·åååé¡ãéäºæ°ååå°æ¼æ¨è¦è³ééè¦ï¼å çºå®åæå¼é æ¶è²»è¶¨å¢ãå¨éé ç ç©¶ä¸­ï¼æåæ¨å¨æä¾æ´æºç¢ºçå®¢è£½åæå°æ¨è¦ï¼ä¸¦ééå°å¯ç¨è³è¨ï¼å°¤å¶æ¯åçï¼è½ææå©åå±¬æ§åè¡¨ä¾è§£æ±ºå·åååé¡ï¼éé»å¨æ¼æä½³ååçä½¿ç¨åéä½éè¨çä½¿ç¨èå»ºæ¨¡ãèå°åçåæå­åéçºå©åçµæçååæ¹æ³ç¸æ¯ï¼ææåºçæ¹æ³çµååçåæå­è³è¨ï¼ä»¥å»ºç«æ´è±å¯çå±¬æ§åè¡¨ãå©ç¨å¤§åèªè¨åè¦è¦ºæ¨¡åçé²æ­¥ï¼æååè©¦ä½¿ç¨å©ç¨®ä¸åçæç¤ºææçä¸å¦é æè¬å°èåç´°ç·»çå±¬æ§ãå¨ IQON3000 è³æéä¸çåæ­¥å¯¦é©é¡¯ç¤ºï¼èåºæºç¸æ¯ï¼ææåºçæ¹æ³éå°äºç«¶ç­åçæºç¢ºåº¦ã

##### **Graph-based Retrieval Augmented Generation for Dynamic Few-shot Text Classification**
2501.02844v1 by Yubo Wang, Haoyang Li, Fei Teng, Lei Chen

Text classification is a fundamental task in natural language processing,
pivotal to various applications such as query optimization, data integration,
and schema matching. While neural network-based models, such as CNN and BERT,
have demonstrated remarkable performance in text classification, their
effectiveness heavily relies on abundant labeled training data. This dependency
makes these models less effective in dynamic few-shot text classification,
where labeled data is scarce, and target labels frequently evolve based on
application needs. Recently, large language models (LLMs) have shown promise
due to their extensive pretraining and contextual understanding. Current
approaches provide LLMs with text inputs, candidate labels, and additional side
information (e.g., descriptions) to predict text labels. However, their
effectiveness is hindered by the increased input size and the noise introduced
through side information processing. To address these limitations, we propose a
graph-based online retrieval-augmented generation framework, namely GORAG, for
dynamic few-shot text classification. GORAG constructs and maintains an
adaptive information graph by extracting side information across all target
texts, rather than treating each input independently. It employs a weighted
edge mechanism to prioritize the importance and reliability of extracted
information and dynamically retrieves relevant context using a minimum-cost
spanning tree tailored for each text input. Empirical evaluations demonstrate
that GORAG outperforms existing approaches by providing more comprehensive and
accurate contextual information.

æè¦ï¼ææ¬åé¡æ¯èªç¶èªè¨èçä¸­çåºæ¬ä»»åï¼
å°æ¼åç¨®æç¨è³ééè¦ï¼ä¾å¦æ¥è©¢åªåãè³ææ´åï¼
åæ¨¡å¼å¹éãéç¶åºæ¼ç¥ç¶ç¶²è·¯çæ¨¡åï¼ä¾å¦ CNN å BERTï¼
å¨ææ¬åé¡ä¸­è¡¨ç¾åºè²ï¼ä½å¶
æææ§å¨å¾å¤§ç¨åº¦ä¸ä¾è³´æ¼å¤§éçæ¨ç±¤è¨ç·´è³æãéåä¾è³´æ§
ä½¿å¾éäºæ¨¡åå¨åæå°æ¨£æ¬ææ¬åé¡ä¸­ææè¼å·®ï¼
å¶ä¸­æ¨ç±¤è³æç¨ç¼ºï¼ä¸¦ä¸ç®æ¨æ¨ç±¤ææ ¹æ
æç¨éæ±é »ç¹æ¼è®ãæè¿ï¼å¤§åèªè¨æ¨¡å (LLM) ç±æ¼å¶å»£æ³çé è¨ç·´åä¸ä¸æçè§£èé¡¯ç¤ºåºåæ¯ãç®å
æ¹æ³çº LLM æä¾ææ¬è¼¸å¥ãåé¸æ¨ç±¤åéå å´é
è³è¨ï¼ä¾å¦ï¼æè¿°ï¼ä»¥é æ¸¬ææ¬æ¨ç±¤ãç¶èï¼å¶
æææ§åå°è¼¸å¥å¤§å°å¢å åå´éè³è¨èçå¼å¥çéè¨çé»ç¤ãçºäºè§£æ±ºéäºéå¶ï¼æåæåºä¸å
åºæ¼åè¡¨çç·ä¸æª¢ç´¢å¢å¼·çææ¶æ§ï¼å³ GORAGï¼ç¨æ¼
åæå°æ¨£æ¬ææ¬åé¡ãGORAG ééæåææç®æ¨çå´éè³è¨ä¾å»ºæ§ä¸¦ç¶­è­·ä¸å
èªé©æè³è¨åè¡¨
ææ¬ï¼èä¸æ¯ç¨ç«èçæ¯åè¼¸å¥ãå®æ¡ç¨å æ¬
éç·£æ©å¶ä¾åªåèæ®æåè³è¨çéè¦æ§åå¯é æ§ï¼ä¸¦ä½¿ç¨éå°æ¯åææ¬è¼¸å¥éèº«æé çæå°ææ¬
çææ¨¹åææª¢ç´¢ç¸éçä¸ä¸æãå¯¦è­è©ä¼°è¡¨æ
GORAG ééæä¾æ´å¨é¢ä¸æºç¢ºçä¸ä¸æè³è¨ï¼åªæ¼ç¾ææ¹æ³ã

##### **KG-CF: Knowledge Graph Completion with Context Filtering under the Guidance of Large Language Models**
2501.02711v1 by Zaiyi Zheng, Yushun Dong, Song Wang, Haochen Liu, Qi Wang, Jundong Li

Large Language Models (LLMs) have shown impressive performance in various
tasks, including knowledge graph completion (KGC). However, current studies
mostly apply LLMs to classification tasks, like identifying missing triplets,
rather than ranking-based tasks, where the model ranks candidate entities based
on plausibility. This focus limits the practical use of LLMs in KGC, as
real-world applications prioritize highly plausible triplets. Additionally,
while graph paths can help infer the existence of missing triplets and improve
completion accuracy, they often contain redundant information. To address these
issues, we propose KG-CF, a framework tailored for ranking-based KGC tasks.
KG-CF leverages LLMs' reasoning abilities to filter out irrelevant contexts,
achieving superior results on real-world datasets. The code and datasets are
available at \url{https://anonymous.4open.science/r/KG-CF}.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å¨åç¨®ä»»åä¸­å±ç¾åºä»¤äººå°è±¡æ·±å»çè¡¨ç¾ï¼åæ¬ç¥è­åè­å®æåè½ (KGC)ãç¶èï¼ç®åçç ç©¶å¤§å¤å° LLM æç¨æ¼åé¡ä»»åï¼ä¾å¦è­å¥éºæ¼çä¸åçµï¼èéåºæ¼æåçä»»åï¼å¶ä¸­æ¨¡åæ ¹æåçæ§å°åé¸å¯¦é«é²è¡æåãéç¨®éé»éå¶äº LLM å¨ KGC ä¸­çå¯¦éæç¨ï¼å çºç¾å¯¦ä¸ççæç¨åªåèæ®é«åº¦åçççä¸åçµãæ­¤å¤ï¼åç®¡åå½¢è·¯å¾æå©æ¼æ¨æ·éºæ¼çä¸åçµçå­å¨ä¸¦æé«å®æçæºç¢ºæ§ï¼ä½å®åéå¸¸åå«åé¤è³è¨ãçºäºè§£æ±ºéäºåé¡ï¼æåæåº KG-CFï¼ä¸åå°ééå°åºæ¼æåç KGC ä»»åçæ¡æ¶ãKG-CF å©ç¨ LLM çæ¨çè½åä¾éæ¿¾ä¸ç¸éçä¸ä¸æï¼å¨ç¾å¯¦ä¸ççè³æéä¸åå¾åè¶çææãç¨å¼ç¢¼åè³æéå¯å¨ \url{https://anonymous.4open.science/r/KG-CF} åå¾ã

##### **Graph-Aware Isomorphic Attention for Adaptive Dynamics in Transformers**
2501.02393v2 by Markus J. Buehler

We present an approach to modifying Transformer architectures by integrating
graph-aware relational reasoning into the attention mechanism, merging concepts
from graph neural networks and language modeling. Building on the inherent
connection between attention and graph theory, we reformulate the Transformer's
attention mechanism as a graph operation and propose Graph-Aware Isomorphic
Attention. This method leverages advanced graph modeling strategies, including
Graph Isomorphism Networks (GIN) and Principal Neighborhood Aggregation (PNA),
to enrich the representation of relational structures. Our approach captures
complex dependencies and generalizes across tasks, as evidenced by a reduced
generalization gap and improved learning performance. Additionally, we expand
the concept of graph-aware attention to introduce Sparse GIN-Attention, a
fine-tuning approach that employs sparse GINs. By interpreting attention
matrices as sparse adjacency graphs, this technique enhances the adaptability
of pre-trained foundational models with minimal computational overhead,
endowing them with graph-aware capabilities. Sparse GIN-Attention fine-tuning
achieves improved training dynamics and better generalization compared to
alternative methods like low-rank adaption (LoRA). We discuss latent graph-like
structures within traditional attention mechanisms, offering a new lens through
which Transformers can be understood. By evolving Transformers as hierarchical
GIN models for relational reasoning. This perspective suggests profound
implications for foundational model development, enabling the design of
architectures that dynamically adapt to both local and global dependencies.
Applications in bioinformatics, materials science, language modeling, and
beyond could benefit from this synthesis of relational and sequential data
modeling, setting the stage for interpretable and generalizable modeling
strategies.

æè¦ï¼<paragraph>æåæåºäºä¸ç¨®ä¿®æ¹ Transformer æ¶æ§çæ¹æ³ï¼æ¹æ³æ¯å°åæç¥éè¯æ¨çæ´åå°æ³¨æåæ©å¶ä¸­ï¼åä½µåç¥ç¶ç¶²è·¯åèªè¨æ¨¡åçæ¦å¿µãåºæ¼æ³¨æåååè«ä¹éçå§å¨è¯ç¹«ï¼æåå° Transformer çæ³¨æåæ©å¶éæ°è¡¨è¿°çºåæä½ï¼ä¸¦æåºåæç¥åæ§æ³¨æåãæ­¤æ¹æ³å©ç¨åé²çåæ¨¡åç­ç¥ï¼åæ¬ååæ§ç¶²è·¯ (GIN) åä¸»é°åèå (PNA)ï¼ä»¥è±å¯éä¿çµæ§çè¡¨ç¤ºãæåçåæ³ææäºè¤éçä¾è³´éä¿ï¼ä¸¦å¨åé ä»»åä¸­é²è¡æ¦æ¬ï¼éå¾ç¸®å°çæ¦æ¬å·®è·åæ¹åçå­¸ç¿è¡¨ç¾ä¸­å¾å°è­æãæ­¤å¤ï¼æåæ´å±äºåæç¥æ³¨æåçæ¦å¿µï¼å¼å¥äºç¨ç GIN æ³¨æåï¼éæ¯ä¸ç¨®æ¡ç¨ç¨ç GIN çå¾®èª¿æ¹æ³ãééå°æ³¨æåç©é£è§£éçºç¨çé°æ¥åï¼æ­¤æè¡ä»¥æå°çè¨ç®éé·å¢å¼·äºé è¨ç·´åºç¤æ¨¡åçé©ææ§ï¼è³¦äºå®ååæç¥è½åãèä½ç§©é©æ (LoRA) ç­æ¿ä»£æ¹æ³ç¸æ¯ï¼ç¨ç GIN æ³¨æåå¾®èª¿å¯¦ç¾äºæ¹é²çè¨ç·´åæåæ´å¥½çæ¦æ¬ãæåè¨è«äºå³çµ±æ³¨æåæ©å¶ä¸­çæ½å¨åå½¢çµæ§ï¼æä¾äºä¸åæ°çè¦è§ï¼ééå®å¯ä»¥çè§£ Transformerãééå° Transformer æ¼åçºç¨æ¼éä¿æ¨ççåå±¤ GIN æ¨¡åãéç¨®è§é»å°åºç¤æ¨¡åçéç¼å·ææ·±é çå½±é¿ï¼å¯ä»¥è¨­è¨åºåæé©æå±é¨åå¨å±ä¾è³´éä¿çæ¶æ§ãçç©è³è¨å­¸ãææç§å­¸ãèªè¨å»ºæ¨¡ç­é åçæç¨å¯ä»¥å¾éç¨®éä¿ååºåè³æå»ºæ¨¡çç¶åä¸­åçï¼çºå¯è§£éåå¯æ¦æ¬çå»ºæ¨¡ç­ç¥å¥ å®åºç¤ã</paragraph>

##### **What Kind of Visual Tokens Do We Need? Training-free Visual Token Pruning for Multi-modal Large Language Models from the Perspective of Graph**
2501.02268v1 by Yutao Jiang, Qiong Wu, Wenhao Lin, Wei Yu, Yiyi Zhou

Recent Multimodal Large Language Models(MLLMs) often use a large number of
visual tokens to compensate their visual shortcoming, leading to excessive
computation and obvious visual redundancy. In this paper, we investigate what
kind of visual tokens are needed for MLLMs, and reveal that both foreground and
background tokens are critical for MLLMs given the varying difficulties of
examples. Based on this observation, we propose a graph-based method towards
training-free visual token pruning, termed G-Prune.In particular, G-Prune
regards visual tokens as nodes, and construct their connections based on their
semantic similarities. Afterwards, the information flow is propagated via
weighted links, and the most important tokens after iterations are kept for
MLLMs, which can be front or background.To validate G-Prune, we apply it to a
recent MLLM called LLaVA-NeXT, and conduct extensive experiments on a set of
benchmarks.The experiment results show that G-Prune can greatly reduce
computation overhead while retaining high performance on both coarse- and
fine-grained tasks. For instance, G-Prune can reduce 63.57\% FLOPs of
LLaVA-NeXT on VQA2.0 and TextVQA with only 0.95\% and 2.34\% accuracy drops,
respectively.

æè¦ï¼æè¿çå¤æ¨¡æå¤§åè¯­è¨æ¨¡å (MLLM) ç»å¸¸ä½¿ç¨å¤§éçè§è§æ è®°æ¥å¼¥è¡¥å¶è§è§ä¸çç¼ºç¹ï¼å¯¼è´è¿åº¦çè®¡ç®åææ¾çè§è§åä½ãå¨æ¬æä¸­ï¼æä»¬è°æ¥äº MLLM éè¦åªç§è§è§æ è®°ï¼å¹¶æ­ç¤ºäºé´äºç¤ºä¾çé¾åº¦ä¸åï¼åæ¯æ è®°åèæ¯æ è®°å¯¹äº MLLM é½æ¯è³å³éè¦çãåºäºæ­¤è§å¯ï¼æä»¬æåºäºä¸ç§åºäºå¾çæ è®­ç»è§è§æ è®°åªææ¹æ³ï¼ç§°ä¸º G-Pruneãç¹å«æ¯ï¼G-Prune å°è§è§æ è®°è§ä¸ºèç¹ï¼å¹¶æ ¹æ®å¶è¯­ä¹ç¸ä¼¼æ§æå»ºå®ä»¬çè¿æ¥ãä¹åï¼ä¿¡æ¯æµéè¿å æé¾æ¥ä¼ æ­ï¼å¹¶ä¸å¨è¿­ä»£åæéè¦çæ è®°ä¿çç¨äº MLLMï¼å®å¯ä»¥æ¯åæ¯æèæ¯ãä¸ºäºéªè¯ G-Pruneï¼æä»¬å°å¶åºç¨äºç§°ä¸º LLaVA-NeXT çææ° MLLMï¼å¹¶å¨ä¸ç»åºåä¸è¿è¡äºå¹¿æ³çå®éªãå®éªç»æè¡¨æï¼G-Prune å¯ä»¥æå¤§å°åå°è®¡ç®å¼éï¼åæ¶å¨ç²ç²åº¦åç»ç²åº¦ä»»å¡ä¸ä¿æé«æ§è½ãä¾å¦ï¼G-Prune å¯ä»¥å° LLaVA-NeXT å¨ VQA2.0 å TextVQA ä¸ç FLOP åå° 63.57%ï¼èåç¡®åº¦åå«ä»ä¸é 0.95% å 2.34%ã

##### **Personalized Graph-Based Retrieval for Large Language Models**
2501.02157v1 by Steven Au, Cameron J. Dimacali, Ojasmitha Pedirappagari, Namyong Park, Franck Dernoncourt, Yu Wang, Nikos Kanakaris, Hanieh Deilamsalehy, Ryan A. Rossi, Nesreen K. Ahmed

As large language models (LLMs) evolve, their ability to deliver personalized
and context-aware responses offers transformative potential for improving user
experiences. Existing personalization approaches, however, often rely solely on
user history to augment the prompt, limiting their effectiveness in generating
tailored outputs, especially in cold-start scenarios with sparse data. To
address these limitations, we propose Personalized Graph-based
Retrieval-Augmented Generation (PGraphRAG), a framework that leverages
user-centric knowledge graphs to enrich personalization. By directly
integrating structured user knowledge into the retrieval process and augmenting
prompts with user-relevant context, PGraphRAG enhances contextual understanding
and output quality. We also introduce the Personalized Graph-based Benchmark
for Text Generation, designed to evaluate personalized text generation tasks in
real-world settings where user history is sparse or unavailable. Experimental
results show that PGraphRAG significantly outperforms state-of-the-art
personalization methods across diverse tasks, demonstrating the unique
advantages of graph-based retrieval for personalization.

æè¦ï¼é¨èå¤§åèªè¨æ¨¡å (LLM) çæ¼é²ï¼å®åæä¾åäººååæå¢æç¥åæçè½åï¼çºæåä½¿ç¨èé«é©æä¾äºè®é©æ½åãç¶èï¼ç¾æçåäººåæ¹æ³éå¸¸åä¾è³´ä½¿ç¨èè¨éä¾æ´åæç¤ºï¼ééå¶äºå®åå¨ç¢çå®¢è£½åè¼¸åºçæè½ï¼ç¹å¥æ¯å¨è³æç¨ççå·ååæå¢ä¸­ãçºäºè§£æ±ºéäºéå¶ï¼æåæåºäºãåäººååå½¢åæª¢ç´¢æ´åç¢çã(PGraphRAG)ï¼ä¸åå©ç¨ä»¥ä½¿ç¨èçºä¸­å¿çç¥è­åå½¢ä¾è±å¯åäººåçæ¶æ§ãééå°çµæ§åçä½¿ç¨èç¥è­ç´æ¥æ´åå°æª¢ç´¢ç¨åºä¸­ï¼ä¸¦ä½¿ç¨èä½¿ç¨èç¸éçå§å®¹æ´åæç¤ºï¼PGraphRAG å¢å¼·äºæå¢çè§£åè¼¸åºåè³ªãæåä¹å¼å¥äºãåäººååå½¢ååºæºææ¬ç¢çãï¼æ¨å¨è©ä¼°å¨ä½¿ç¨èè¨éç¨çæä¸å¯ç¨ççå¯¦ä¸çè¨­å®ä¸­çåäººåææ¬ç¢çä»»åãå¯¦é©çµæé¡¯ç¤ºï¼PGraphRAG å¨åç¨®ä»»åä¸­é¡¯èåªæ¼æåé²çåäººåæ¹æ³ï¼è­æäºåå½¢åæª¢ç´¢å¨åäººåæ¹é¢çç¨ç¹åªå¢ã

##### **Cold-Start Recommendation towards the Era of Large Language Models (LLMs): A Comprehensive Survey and Roadmap**
2501.01945v1 by Weizhi Zhang, Yuanchen Bei, Liangwei Yang, Henry Peng Zou, Peilin Zhou, Aiwei Liu, Yinghui Li, Hao Chen, Jianling Wang, Yu Wang, Feiran Huang, Sheng Zhou, Jiajun Bu, Allen Lin, James Caverlee, Fakhri Karray, Irwin King, Philip S. Yu

Cold-start problem is one of the long-standing challenges in recommender
systems, focusing on accurately modeling new or interaction-limited users or
items to provide better recommendations. Due to the diversification of internet
platforms and the exponential growth of users and items, the importance of
cold-start recommendation (CSR) is becoming increasingly evident. At the same
time, large language models (LLMs) have achieved tremendous success and possess
strong capabilities in modeling user and item information, providing new
potential for cold-start recommendations. However, the research community on
CSR still lacks a comprehensive review and reflection in this field. Based on
this, in this paper, we stand in the context of the era of large language
models and provide a comprehensive review and discussion on the roadmap,
related literature, and future directions of CSR. Specifically, we have
conducted an exploration of the development path of how existing CSR utilizes
information, from content features, graph relations, and domain information, to
the world knowledge possessed by large language models, aiming to provide new
insights for both the research and industrial communities on CSR. Related
resources of cold-start recommendations are collected and continuously updated
for the community in
https://github.com/YuanchenBei/Awesome-Cold-Start-Recommendation.

æè¦ï¼å·åååé¡æ¯æ¨è¦ç³»çµ±ä¸­é·ä¹ä»¥ä¾çææ°ä¹ä¸ï¼å°æ³¨æ¼æºç¢ºå»ºæ¨¡æ°ä½¿ç¨èæäºåæéçä½¿ç¨èæé ç®ï¼ä»¥æä¾æ´å¥½çæ¨è¦ãç±æ¼ç¶²è·¯å¹³å°çå¤æ¨£åä»¥åä½¿ç¨èåé ç®çææ¸ç´å¢é·ï¼å·ååæ¨è¦ (CSR) çéè¦æ§è®å¾è¶ä¾è¶æé¡¯ãåæï¼å¤§åèªè¨æ¨¡å (LLM) å·²åå¾å·¨å¤§çæåï¼ä¸¦å·åå»ºæ¨¡ä½¿ç¨èåé ç®è³è¨çå¼·å¤§è½åï¼çºå·ååæ¨è¦æä¾äºæ°çæ½åãç¶èï¼CSR çç ç©¶ç¤¾ç¾¤ä»ç¶ç¼ºä¹å°æ­¤é åçå¨é¢åé¡§ååæãåºæ¼æ­¤ï¼å¨æ¬æä¸­ï¼æåç«å¨å¤§åèªè¨æ¨¡åçæä»£èæ¯ä¸ï¼å° CSR çè·¯ç·åãç¸éæç»åæªä¾æ¹åé²è¡äºå¨é¢çåé¡§åè¨è«ãå·é«ä¾èªªï¼æåæ¢è¨äºç¾æ CSR å¦ä½å©ç¨è³è¨çç¼å±è·¯å¾ï¼å¾å§å®¹ç¹å¾µãåå½¢éä¿åé åè³è¨ï¼å°å¤§åèªè¨æ¨¡åæææçä¸çç¥è­ï¼æ¨å¨çºç ç©¶åç¢æ¥­ç¤¾ç¾¤å¨ CSR ä¸æä¾æ°çè¦è§£ãå·ååæ¨è¦çç¸éè³æºå·²æ¶éä¸¦æçºæ´æ°ï¼ä¾ç¤¾ç¾¤å¨ https://github.com/YuanchenBei/Awesome-Cold-Start-Recommendation ä¸­ä½¿ç¨ã

##### **Multimodal Contrastive Representation Learning in Augmented Biomedical Knowledge Graphs**
2501.01644v1 by Tien Dang, Viet Thanh Duy Nguyen, Minh Tuan Le, Truong-Son Hy

Biomedical Knowledge Graphs (BKGs) integrate diverse datasets to elucidate
complex relationships within the biomedical field. Effective link prediction on
these graphs can uncover valuable connections, such as potential novel
drug-disease relations. We introduce a novel multimodal approach that unifies
embeddings from specialized Language Models (LMs) with Graph Contrastive
Learning (GCL) to enhance intra-entity relationships while employing a
Knowledge Graph Embedding (KGE) model to capture inter-entity relationships for
effective link prediction. To address limitations in existing BKGs, we present
PrimeKG++, an enriched knowledge graph incorporating multimodal data, including
biological sequences and textual descriptions for each entity type. By
combining semantic and relational information in a unified representation, our
approach demonstrates strong generalizability, enabling accurate link
predictions even for unseen nodes. Experimental results on PrimeKG++ and the
DrugBank drug-target interaction dataset demonstrate the effectiveness and
robustness of our method across diverse biomedical datasets. Our source code,
pre-trained models, and data are publicly available at
https://github.com/HySonLab/BioMedKG

æè¦ï¼çç©å»å­¦ç¥è­åè­ (BKG) æ´åå¤æ¨£åçè³æéï¼ä»¥é¡æçç©é«å­¸é åå§çè¤ééä¿ãå¨éäºåè­ä¸é²è¡ææçé£çµé æ¸¬ï¼å¯ä»¥ç¼ç¾æå¹å¼çé£çµï¼ä¾å¦æ½å¨çæ°è¥ç©-ç¾çéä¿ãæåå¼å¥äºä¸ç¨®æ°ç©çå¤æ¨¡ææ¹æ³ï¼å®å°ä¾èªå°ç¨èªè¨æ¨¡å (LM) çåµå¥èåå½¢å°æ¯å­¸ç¿ (GCL) çµ±ä¸èµ·ä¾ï¼ä»¥å¢å¼·å¯¦é«å§éä¿ï¼åææ¡ç¨ç¥è­åå½¢åµå¥ (KGE) æ¨¡åä¾ææå¯¦é«ééä¿ï¼ä»¥é²è¡ææçé£çµé æ¸¬ãçºäºè§£æ±ºç¾æ BKG ä¸­çéå¶ï¼æåæåºäº PrimeKG++ï¼éæ¯ä¸åè±å¯çç¥è­åå½¢ï¼å®çµåäºå¤æ¨¡ææ¸æï¼åæ¬æ¯ç¨®é¡åå¯¦é«ççç©åºååæå­æè¿°ãééå¨çµ±ä¸è¡¨ç¤ºä¸­çµåèªç¾©åéä¿è³è¨ï¼æåçåæ³å±ç¤ºäºå¼·å¤§çæ¦æ¬æ§ï¼å³ä½¿å°æ¼æªè¦ç¯é»ä¹è½é²è¡æºç¢ºçé£çµé æ¸¬ãå¨ PrimeKG++ å DrugBank è¥ç©-æ¨é¶äº¤äºä½ç¨è³æéä¸çå¯¦é©çµæè­æäºæåçæ¹æ³å¨åç¨®çç©é«å­¸è³æéä¸­çæææ§åç©©å¥æ§ãæåçåå§ç¢¼ãé è¨ç·´æ¨¡ååè³æå¯å¨ https://github.com/HySonLab/BioMedKG å¬éåå¾ã

##### **Enhancing Uncertainty Modeling with Semantic Graph for Hallucination Detection**
2501.02020v1 by Kedi Chen, Qin Chen, Jie Zhou, Xinqi Tao, Bowen Ding, Jingwen Xie, Mingchen Xie, Peilong Li, Feng Zheng, Liang He

Large Language Models (LLMs) are prone to hallucination with non-factual or
unfaithful statements, which undermines the applications in real-world
scenarios. Recent researches focus on uncertainty-based hallucination
detection, which utilizes the output probability of LLMs for uncertainty
calculation and does not rely on external knowledge or frequent sampling from
LLMs. Whereas, most approaches merely consider the uncertainty of each
independent token, while the intricate semantic relations among tokens and
sentences are not well studied, which limits the detection of hallucination
that spans over multiple tokens and sentences in the passage. In this paper, we
propose a method to enhance uncertainty modeling with semantic graph for
hallucination detection. Specifically, we first construct a semantic graph that
well captures the relations among entity tokens and sentences. Then, we
incorporate the relations between two entities for uncertainty propagation to
enhance sentence-level hallucination detection. Given that hallucination occurs
due to the conflict between sentences, we further present a graph-based
uncertainty calibration method that integrates the contradiction probability of
the sentence with its neighbors in the semantic graph for uncertainty
calculation. Extensive experiments on two datasets show the great advantages of
our proposed approach. In particular, we obtain substantial improvements with
19.78% in passage-level hallucination detection.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å®¹æåºç¾éäºå¯¦æ§æä¸å¿ å¯¦çé³è¿°ï¼éæç ´å£ç¾å¯¦ä¸çå ´æ¯ä¸­çæç¨ãæè¿çç ç©¶éé»éæ³¨åºæ¼ä¸ç¢ºå®æ§çå¹»è¦ºæª¢æ¸¬ï¼å®å©ç¨ LLM çè¼¸åºæ©çé²è¡ä¸ç¢ºå®æ§è¨ç®ï¼ä¸¦ä¸ä¸ä¾è³´æ¼å¤é¨ç¥è­æå¾ LLM ä¸­é »ç¹åæ¨£ãç¶èï¼å¤§å¤æ¸æ¹æ³åèæ®æ¯åç¨ç«ç¬¦èçä¸ç¢ºå®æ§ï¼èç¬¦èåå¥å­ä¹éçè¤éèªç¾©éä¿å°æªå¾å°å¾å¥½çç ç©¶ï¼ééå¶äºå°è·¨è¶æ®µè½ä¸­å¤åç¬¦èåå¥å­çå¹»è¦ºçæª¢æ¸¬ãå¨æ¬æä¸­ï¼æåæåºäºä¸ç¨®ä½¿ç¨èªç¾©åå¢å¼·ä¸ç¢ºå®æ§å»ºæ¨¡ä»¥é²è¡å¹»è¦ºæª¢æ¸¬çæ¹æ³ãå·é«ä¾èªªï¼æåé¦åæ§å»ºä¸åèªç¾©åï¼å®å¾å¥½å°ææäºå¯¦é«ç¬¦èåå¥å­ä¹éçéä¿ãç¶å¾ï¼æåå°å©åå¯¦é«ä¹éçéä¿ç´å¥ä¸ç¢ºå®æ§å³æ­ï¼ä»¥å¢å¼·å¥å­ç´å¥çå¹»è¦ºæª¢æ¸¬ãç±æ¼å¹»è¦ºæ¯å å¥å­ä¹éçè¡çªèç¼ççï¼å æ­¤æåé²ä¸æ­¥æåºäºä¸ç¨®åºæ¼åçä¸ç¢ºå®æ§æ ¡æºæ¹æ³ï¼å®å°å¥å­ççç¾æ©çèå¶å¨èªç¾©åä¸­çé°å±çµåèµ·ä¾é²è¡ä¸ç¢ºå®æ§è¨ç®ãå¨å©åæ¸æéä¸çå»£æ³å¯¦é©é¡¯ç¤ºäºæåæåºçæ¹æ³çå·¨å¤§åªå¢ãç¹å¥æ¯ï¼æåå¨æ®µè½ç´å¥çå¹»è¦ºæª¢æ¸¬ä¸­ç²å¾äº 19.78% çé¡¯èæ¹é²ã

##### **Unfolding the Headline: Iterative Self-Questioning for News Retrieval and Timeline Summarization**
2501.00888v1 by Weiqi Wu, Shen Huang, Yong Jiang, Pengjun Xie, Fei Huang, Hai Zhao

In the fast-changing realm of information, the capacity to construct coherent
timelines from extensive event-related content has become increasingly
significant and challenging. The complexity arises in aggregating related
documents to build a meaningful event graph around a central topic. This paper
proposes CHRONOS - Causal Headline Retrieval for Open-domain News Timeline
SummarizatiOn via Iterative Self-Questioning, which offers a fresh perspective
on the integration of Large Language Models (LLMs) to tackle the task of
Timeline Summarization (TLS). By iteratively reflecting on how events are
linked and posing new questions regarding a specific news topic to gather
information online or from an offline knowledge base, LLMs produce and refresh
chronological summaries based on documents retrieved in each round.
Furthermore, we curate Open-TLS, a novel dataset of timelines on recent news
topics authored by professional journalists to evaluate open-domain TLS where
information overload makes it impossible to find comprehensive relevant
documents from the web. Our experiments indicate that CHRONOS is not only adept
at open-domain timeline summarization, but it also rivals the performance of
existing state-of-the-art systems designed for closed-domain applications,
where a related news corpus is provided for summarization.

æè¦ï¼å¨è³è¨å¿«éè®é·çé åä¸­ï¼å¾å¤§éçäºä»¶ç¸éå§å®¹å»ºæ§é£è²«çæéè»¸çè½åè®å¾è¶ä¾è¶éè¦ä¸å·æææ°æ§ãè¤éæ§å¨æ¼å½ç¸½ç¸éæä»¶ï¼ä»¥åç¹ä¸­å¿ä¸»é¡å»ºç«ææç¾©çäºä»¶åãæ¬ææåºäº CHRONOS - éæ¾é åæ°èæéè»¸æè¦çå ææ¨é¡æª¢ç´¢ï¼ééåè¦èªææåï¼æä¾æ´åå¤§åèªè¨æ¨¡å (LLM) ä¾èçæéè»¸æè¦ (TLS) ä»»åçæ°è§é»ãééåè¦æèäºä»¶å¦ä½é£çµï¼ä¸¦å°ç¹å®æ°èä¸»é¡æåºæ°åé¡ï¼ä»¥å¾ç·ä¸æé¢ç·ç¥è­åº«æ¶éè³è¨ï¼LLM ææ ¹ææ¯è¼ªæª¢ç´¢çæä»¶ç¢çä¸¦æ´æ°æéæè¦ãæ­¤å¤ï¼æåç­åäº Open-TLSï¼ä¸åç±å°æ¥­è¨èç·¨å¯«çè¿ææ°èä¸»é¡æéè»¸çæ°ç©è³æéï¼ä»¥è©ä¼°éæ¾é åç TLSï¼å¶ä¸­è³è¨éè¼ä½¿å¾ç¡æ³å¾ç¶²è·¯ä¸æ¾å°å¨é¢çç¸éæä»¶ãæåçå¯¦é©è¡¨æï¼CHRONOS ä¸åæé·éæ¾é åçæéè»¸æè¦ï¼èä¸éèå°çºå°éé åæç¨è¨­è¨çç¾ææåé²ç³»çµ±çæè½ç¸åª²ç¾ï¼å¶ä¸­æä¾äºç¸éçæ°èèªæåº«ç¨æ¼æè¦ã

##### **Breaking Through the Spike: Spike Window Decoding for Accelerated and Precise Automatic Speech Recognition**
2501.03257v1 by Wei Zhang, Tian-Hao Zhang, Chao Luo, Hui Zhou, Chao Yang, Xinyuan Qian, Xu-Cheng Yin

Recently, end-to-end automatic speech recognition has become the mainstream
approach in both industry and academia. To optimize system performance in
specific scenarios, the Weighted Finite-State Transducer (WFST) is extensively
used to integrate acoustic and language models, leveraging its capacity to
implicitly fuse language models within static graphs, thereby ensuring robust
recognition while also facilitating rapid error correction. However, WFST
necessitates a frame-by-frame search of CTC posterior probabilities through
autoregression, which significantly hampers inference speed. In this work, we
thoroughly investigate the spike property of CTC outputs and further propose
the conjecture that adjacent frames to non-blank spikes carry semantic
information beneficial to the model. Building on this, we propose the Spike
Window Decoding algorithm, which greatly improves the inference speed by making
the number of frames decoded in WFST linearly related to the number of spiking
frames in the CTC output, while guaranteeing the recognition performance. Our
method achieves SOTA recognition accuracy with significantly accelerates
decoding speed, proven across both AISHELL-1 and large-scale In-House datasets,
establishing a pioneering approach for integrating CTC output with WFST.

æè¦ï¼è¿å¹´æ¥ï¼ç«¯å°ç«¯çèªå¨è¯­é³è¯å«å·²æä¸ºå·¥ä¸çåå­¦æ¯ççæµè¡æ¹æ³ãä¸ºäºä¼åç¹å®åºæ¯ä¸­çç³»ç»æ§è½ï¼å ææéç¶æè½¬æ¢å¨ (WFST) è¢«å¹¿æ³ç¨äºéæå£°å­¦åè¯­è¨æ¨¡åï¼å©ç¨å¶å¨éæå¾ä¸­éå¼èåè¯­è¨æ¨¡åçè½åï¼ä»èç¡®ä¿ç¨³å¥çè¯å«ï¼åæ¶ä¿è¿å¿«éçº éãç¶èï¼WFST éè¦éè¿èªåå½éå¸§æç´¢ CTC åéªæ¦çï¼è¿æå¤§å°é»ç¢äºæ¨çéåº¦ãå¨è¿é¡¹å·¥ä½ä¸­ï¼æä»¬å½»åºç ç©¶äº CTC è¾åºçå°å³°ç¹æ§ï¼å¹¶è¿ä¸æ­¥æåºä¸ä¸ªçæ³ï¼å³éç©ºç½å°å³°çç¸é»å¸§æºå¸¦å¯¹æ¨¡åæççè¯­ä¹ä¿¡æ¯ãå¨æ­¤åºç¡ä¸ï¼æä»¬æåºäº Spike Window è§£ç ç®æ³ï¼è¯¥ç®æ³éè¿ä½¿ WFST ä¸­è§£ç çå¸§æ°ä¸ CTC è¾åºä¸­å°å³°å¸§æ°çº¿æ§ç¸å³ï¼åæ¶ä¿è¯è¯å«æ§è½ï¼æå¤§å°æé«äºæ¨çéåº¦ãæä»¬çæ¹æ³å¨ AISHELL-1 åå¤§è§æ¨¡åé¨æ°æ®éä¸é½å®ç°äº SOTA è¯å«åç¡®åº¦ï¼å¹¶æ¾èå å¿«äºè§£ç éåº¦ï¼ä¸ºå° CTC è¾åºä¸ WFST éæå»ºç«äºåé©±æ¹æ³ã

##### **SmartSpatial: Enhancing the 3D Spatial Arrangement Capabilities of Stable Diffusion Models and Introducing a Novel 3D Spatial Evaluation Framework**
2501.01998v1 by Mao Xun Huang, Hen-Hsen Huang

Stable Diffusion models have made remarkable strides in generating
photorealistic images from text prompts but often falter when tasked with
accurately representing complex spatial arrangements, particularly involving
intricate 3D relationships. To address this limitation, we introduce
SmartSpatial, an innovative approach that enhances the spatial arrangement
capabilities of Stable Diffusion models through 3D-aware conditioning and
attention-guided mechanisms. SmartSpatial incorporates depth information and
employs cross-attention control to ensure precise object placement, delivering
notable improvements in spatial accuracy metrics. In conjunction with
SmartSpatial, we present SmartSpatialEval, a comprehensive evaluation framework
designed to assess spatial relationships. This framework utilizes
vision-language models and graph-based dependency parsing for performance
analysis. Experimental results on the COCO and SpatialPrompts datasets show
that SmartSpatial significantly outperforms existing methods, setting new
benchmarks for spatial arrangement accuracy in image generation.

æè¦ï¼Stable Diffusion æ¨¡åå¨æ ¹ææå­æç¤ºçæé¼ççå½±åæ¹é¢åå¾äºé¡¯èé²å±ï¼ä½å¨æºç¢ºåç¾è¤éçç©ºééç½®æï¼ç¹å¥æ¯æ¶åè¤éç 3D éä¿æï¼å¸¸å¸¸æå¤±æãçºäºè§£æ±ºéåéå¶ï¼æåå¼å¥äº SmartSpatialï¼éæ¯ä¸ååµæ°çæ¹æ³ï¼éé 3D æç¥æ¢ä»¶åæ³¨æåå¼å°æ©å¶ï¼å¢å¼· Stable Diffusion æ¨¡åçç©ºééç½®è½åãSmartSpatial çµåæ·±åº¦è³è¨ä¸¦æ¡ç¨äº¤åæ³¨æåæ§å¶ï¼ä»¥ç¢ºä¿ç²¾ç¢ºçç©ä»¶æ¾ç½®ï¼å¨ç©ºéæºç¢ºåº¦ææ¨æ¹é¢å¸¶ä¾é¡¯èçæ¹é²ãçµå SmartSpatialï¼æåæåºäº SmartSpatialEvalï¼éæ¯ä¸åå¨é¢çè©ä¼°æ¶æ§ï¼æ¨å¨è©ä¼°ç©ºééä¿ãéåæ¶æ§å©ç¨è¦è¦ºèªè¨æ¨¡åååºæ¼åå½¢çä¾å­åæé²è¡æè½åæãå¨ COCO å SpatialPrompts è³æéä¸çå¯¦é©çµæé¡¯ç¤ºï¼SmartSpatial æé¡¯åªæ¼ç¾ææ¹æ³ï¼çºå½±åçæçç©ºééç½®æºç¢ºåº¦è¨­å®äºæ°çåºæºã

##### **Causal Graph Guided Steering of LLM Values via Prompts and Sparse Autoencoders**
2501.00581v1 by Yipeng Kang, Junqi Wang, Yexin Li, Fangwei Zhong, Xue Feng, Mengmeng Wang, Wenming Tu, Quansen Wang, Hengli Li, Zilong Zheng

As large language models (LLMs) become increasingly integrated into critical
applications, aligning their behavior with human values presents significant
challenges. Current methods, such as Reinforcement Learning from Human Feedback
(RLHF), often focus on a limited set of values and can be resource-intensive.
Furthermore, the correlation between values has been largely overlooked and
remains underutilized. Our framework addresses this limitation by mining a
causal graph that elucidates the implicit relationships among various values
within the LLMs. Leveraging the causal graph, we implement two lightweight
mechanisms for value steering: prompt template steering and Sparse Autoencoder
feature steering, and analyze the effects of altering one value dimension on
others. Extensive experiments conducted on Gemma-2B-IT and Llama3-8B-IT
demonstrate the effectiveness and controllability of our steering methods.

æè¦ï¼é¨èå¤§åèªè¨æ¨¡å (LLM) æ¥çæ´åå°ééµæç¨ç¨å¼ä¸­ï¼è®å¶è¡çºèäººé¡å¹å¼è§ä¸è´æå¸¶ä¾éå¤§ææ°ãç¾æçæ¹æ³ï¼ä¾å¦äººé¡åé¥å¼·åå­¸ç¿ (RLHF)ï¼éå¸¸å°æ³¨æ¼æéçå¹å¼è§ï¼ä¸å¯è½èè²»å¤§éè³æºãæ­¤å¤ï¼å¹å¼è§ä¹éçéè¯æ§å¨å¾å¤§ç¨åº¦ä¸è¢«å¿½è¦ï¼ä¸æªè¢«ååå©ç¨ãæåçæ¶æ§ééæ¢åå æåè¡¨ä¾è§£æ±ºæ­¤éå¶ï¼è©²åè¡¨é¡æäº LLM ä¸­åç¨®å¹å¼è§ä¹éçé±å«éä¿ãå©ç¨å æåè¡¨ï¼æåå¯¦ä½äºå©ç¨®è¼éç´çå¹å¼å¼å°æ©å¶ï¼æç¤ºç¯æ¬å¼å°åç¨çèªç·¨ç¢¼å¨ç¹å¾µå¼å°ï¼ä¸¦åæäºæ¹è®ä¸åå¹å¼ç¶­åº¦å°å¶ä»ç¶­åº¦çå½±é¿ãå¨ Gemma-2B-IT å Llama3-8B-IT ä¸é²è¡çå»£æ³å¯¦é©è­æäºæåçå¼å°æ¹æ³çæææ§åå¯æ§æ§ã

##### **CancerKG.ORG A Web-scale, Interactive, Verifiable Knowledge Graph-LLM Hybrid for Assisting with Optimal Cancer Treatment and Care**
2501.00223v1 by Michael Gubanov, Anna Pyayt, Aleksandra Karolak

Here, we describe one of the first Web-scale hybrid Knowledge Graph
(KG)-Large Language Model (LLM), populated with the latest peer-reviewed
medical knowledge on colorectal Cancer. It is currently being evaluated to
assist with both medical research and clinical information retrieval tasks at
Moffitt Cancer Center, which is one of the top Cancer centers in the U.S. and
in the world. Our hybrid is remarkable as it serves the user needs better than
just an LLM, KG or a search-engine in isolation. LLMs as is are known to
exhibit hallucinations and catastrophic forgetting as well as are trained on
outdated corpora. The state of the art KGs, such as PrimeKG, cBioPortal,
ChEMBL, NCBI, and other require manual curation, hence are quickly getting
stale. CancerKG is unsupervised and is capable of automatically ingesting and
organizing the latest medical findings. To alleviate the LLMs shortcomings, the
verified KG serves as a Retrieval Augmented Generation (RAG) guardrail.
CancerKG exhibits 5 different advanced user interfaces, each tailored to serve
different data modalities better and more convenient for the user.

æè¦ï¼å¨æ­¤ï¼æä»¬æè¿°äºç¬¬ä¸ä¸ª Web çº§æ··åç¥è¯å¾è°± (KG) - å¤§åè¯­è¨æ¨¡å (LLM)ï¼å¶ä¸­åæ¥çæå³ç»ç´è ççææ°åè¡è¯å®¡å»å­¦ç¥è¯ãç®åæ­£å¨è¯ä¼°å®ä»¥åå© Moffitt ççä¸­å¿è¿è¡å»å­¦ç ç©¶åä¸´åºä¿¡æ¯æ£ç´¢ä»»å¡ï¼è¯¥ä¸­å¿æ¯ç¾å½åä¸çé¡¶çº§ççä¸­å¿ä¹ä¸ãæä»¬çæ··åä½éå¸¸åºè²ï¼å ä¸ºå®æ¯å­¤ç«ç LLMãKG ææç´¢å¼ææ´å¥½å°æ»¡è¶³ç¨æ·éæ±ãä¼æå¨ç¥ï¼LLM ä¼åºç°å¹»è§åç¾é¾æ§éå¿ï¼å¹¶ä¸æ¯å¨è¿æ¶çè¯­æåºä¸è¿è¡è®­ç»çãæåè¿ç KGï¼ä¾å¦ PrimeKGãcBioPortalãChEMBLãNCBI ç­éè¦äººå·¥æ´çï¼å æ­¤å¾å¿«å°±ä¼è¿æ¶ãCancerKG æ éçç£ï¼è½å¤èªå¨æååç»ç»ææ°çå»å­¦åç°ãä¸ºäºåè½» LLM çç¼ºç¹ï¼ç»è¿éªè¯ç KG åå½æ£ç´¢å¢å¼ºçæ (RAG) æ¤æ ãCancerKG å±ç¤ºäº 5 ç§ä¸åçé«çº§ç¨æ·çé¢ï¼æ¯ç§çé¢é½éå¯¹æå¡ä¸åçæ°æ®æ¨¡å¼ï¼ä¸ºç¨æ·æä¾æ´å¥½ãæ´æ¹ä¾¿çæå¡ã

##### **The Potential of LLMs in Automating Software Testing: From Generation to Reporting**
2501.00217v1 by Betim Sherifi, Khaled Slhoub, Fitzroy Nembhard

Having a high quality software is essential in software engineering, which
requires robust validation and verification processes during testing
activities. Manual testing, while effective, can be time consuming and costly,
leading to an increased demand for automated methods. Recent advancements in
Large Language Models (LLMs) have significantly influenced software
engineering, particularly in areas like requirements analysis, test automation,
and debugging. This paper explores an agent-oriented approach to automated
software testing, using LLMs to reduce human intervention and enhance testing
efficiency. The proposed framework integrates LLMs to generate unit tests,
visualize call graphs, and automate test execution and reporting. Evaluations
across multiple applications in Python and Java demonstrate the system's high
test coverage and efficient operation. This research underscores the potential
of LLM-powered agents to streamline software testing workflows while addressing
challenges in scalability and accuracy.

æè¦ï¼å¨è»é«å·¥ç¨ä¸­ï¼ææé«åè³ªçè»é«è³ééè¦ï¼ééè¦å¨æ¸¬è©¦æ´»åä¸­é²è¡å¼·å¥çé©è­åé©è­ç¨åºãæåæ¸¬è©¦éç¶ææï¼ä½å¯è½èæä¸ææ¬é«æï¼å°è´å°èªååæ¹æ³çéæ±å¢å ãå¤§åèªè¨æ¨¡å (LLM) çææ°é²å±é¡¯èå½±é¿äºè»é«å·¥ç¨ï¼ç¹å¥æ¯å¨éæ±åæãæ¸¬è©¦èªåååé¤é¯ç­é åãæ¬ææ¢è¨äºä¸ç¨®é¢åä»£ççèªååè»é«æ¸¬è©¦æ¹æ³ï¼ä½¿ç¨ LLM ä¾æ¸å°äººå·¥å¹²é ä¸¦æé«æ¸¬è©¦æçãææåºçæ¡æ¶æ´åäº LLM ä¾ç¢çå®åæ¸¬è©¦ãè¦è¦ºåå¼å«åè¡¨ä»¥åèªååæ¸¬è©¦å·è¡åå ±åãå¨ Python å Java ä¸­çè·¨å¤åæç¨ç¨å¼çè©ä¼°è­æäºç³»çµ±çé«æ¸¬è©¦è¦èçåé«æéä½ãéé ç ç©¶å¼·èª¿äº LLM é©åçä»£çå¨ç°¡åè»é«æ¸¬è©¦å·¥ä½æµç¨æ¹é¢çæ½åï¼åææå°å¯æ´åæ§åæºç¢ºæ§æ¹é¢çææ°ã

##### **Detection-Fusion for Knowledge Graph Extraction from Videos**
2501.00136v1 by Taniya Das, Louis Mahon, Thomas Lukasiewicz

One of the challenging tasks in the field of video understanding is
extracting semantic content from video inputs. Most existing systems use
language models to describe videos in natural language sentences, but this has
several major shortcomings. Such systems can rely too heavily on the language
model component and base their output on statistical regularities in natural
language text rather than on the visual contents of the video. Additionally,
natural language annotations cannot be readily processed by a computer, are
difficult to evaluate with performance metrics and cannot be easily translated
into a different natural language. In this paper, we propose a method to
annotate videos with knowledge graphs, and so avoid these problems.
Specifically, we propose a deep-learning-based model for this task that first
predicts pairs of individuals and then the relations between them.
Additionally, we propose an extension of our model for the inclusion of
background knowledge in the construction of knowledge graphs.

æè¦ï¼å½±ççè§£é åä¸­ä¸é å·æææ°æ§çä»»åï¼æ¯å¾å½±çè¼¸å¥ä¸­èåèªæå§å®¹ãç¾æçå¤§é¨åç³»çµ±ä½¿ç¨èªè¨æ¨¡åä»¥èªç¶èªè¨å¥å­æè¿°å½±çï¼ä½éæå¹¾åä¸»è¦çç¼ºé»ãæ­¤é¡ç³»çµ±å¯è½éåº¦ä¾è³´èªè¨æ¨¡åçµä»¶ï¼ä¸¦æ ¹æèªç¶èªè¨æå­ä¸­ççµ±è¨è¦å¾ï¼èéå½±ççè¦è¦ºå§å®¹ï¼ä¾å»ºæ§å¶è¼¸åºãæ­¤å¤ï¼èªç¶èªè¨è¨»è§£ç¡æ³è¼æå°ç±é»è¦èçï¼é£ä»¥ä½¿ç¨æè½ææ¨é²è¡è©ä¼°ï¼ä¸ç¡æ³è¼æç¿»è­¯æä¸åçèªç¶èªè¨ãå¨æ¬æä¸­ï¼æåæåºä¸åä½¿ç¨ç¥è­åè¡¨çºå½±çå ä¸è¨»è§£çæ¹æ³ï¼ä¸¦èæ­¤é¿åéäºåé¡ãå·é«ä¾èªªï¼æåæåºä¸ååºæ¼æ·±åº¦å­¸ç¿çæ¨¡åä¾å·è¡éé ä»»åï¼å®æåé æ¸¬åé«å°ï¼ç¶å¾åé æ¸¬åé«ä¹éçéä¿ãæ­¤å¤ï¼æåæåºä¸åæ¨¡åå»¶ä¼¸ï¼ä»¥å°èæ¯ç¥è­ç´å¥ç¥è­åè¡¨çå»ºæ§ä¸­ã

##### **Machine Learning-Based Security Policy Analysis**
2501.00085v2 by Krish Jain, Joann Sum, Pranav Kapoor, Amir Eaman

Security-Enhanced Linux (SELinux) is a robust security mechanism that
enforces mandatory access controls (MAC), but its policy language's complexity
creates challenges for policy analysis and management. This research
investigates the automation of SELinux policy analysis using graph-based
techniques combined with machine learning approaches to detect policy
anomalies. The study addresses two key questions: Can SELinux policy analysis
be automated through graph analysis, and how do different anomaly detection
models compare in analyzing SELinux policies? We will be comparing different
machine learning models by evaluating their effectiveness in detecting policy
violations and anomalies. Our approach utilizes Neo4j for graph representation
of policies, with Node2vec transforming these graph structures into meaningful
vector embeddings that can be processed by our machine learning models. In our
results, the MLP Neural Network consistently demonstrated superior performance
across different dataset sizes, achieving 95% accuracy with balanced precision
and recall metrics, while both Random Forest and SVM models showed competitive
but slightly lower performance in detecting policy violations. This combination
of graph-based modeling and machine learning provides a more sophisticated and
automated approach to understanding and analyzing complex SELinux policies
compared to traditional manual analysis methods.

æè¦ï¼SELinuxï¼å®å¨å¼·åå Linuxï¼æ¯ä¸ç¨®å¼·å¤§çå®å¨æ©å¶ï¼å®å¼·å¶å·è¡å¼·å¶è¨ªåæ§å¶ (MAC)ï¼ä½å¶æ¿ç­èªè¨çè¤éæ§å°æ¿ç­åæåç®¡çæåºäºææ°ãæ¬ç ç©¶æ¢è¨äºä½¿ç¨åºæ¼åå½¢æè¡çµåæ©å¨å­¸ç¿æ¹æ³ä¾èªåå SELinux æ¿ç­åæï¼ä»¥æª¢æ¸¬æ¿ç­ç°å¸¸ãæ¬ç ç©¶è§£æ±ºäºå©åééµåé¡ï¼æ¯å¦è½ééåå½¢åæèªåå SELinux æ¿ç­åæï¼ä»¥åä¸åçç°å¸¸æª¢æ¸¬æ¨¡åå¨åæ SELinux æ¿ç­ææä½æ¯è¼ï¼æåå°æ¯è¼ä¸åçæ©å¨å­¸ç¿æ¨¡åï¼è©ä¼°å®åå¨æª¢æ¸¬æ¿ç­éè¦åç°å¸¸æ¹é¢çæææ§ãæåçåæ³å©ç¨ Neo4j é²è¡æ¿ç­çåå½¢è¡¨ç¤ºï¼Node2vec å°éäºåå½¢çµæ§è½ææææç¾©çåéåµå¥ï¼æåçæ©å¨å­¸ç¿æ¨¡åå¯ä»¥èçéäºåµå¥ãå¨æåççµæä¸­ï¼MLP ç¥ç¶ç¶²è·¯å¨ä¸åçè³æéå¤§å°ä¸­å§çµè¡¨ç¾åºåªç°çæè½ï¼å¨å¹³è¡¡çæºç¢ºåº¦ãç²¾ç¢ºåº¦åå¬åçææ¨ä¸éå° 95% çæºç¢ºåº¦ï¼èé¨æ©æ£®æå SVM æ¨¡åå¨æª¢æ¸¬æ¿ç­éè¦æ¹é¢è¡¨ç¾åºç«¶ç­åï¼ä½æè½ç¥ä½ãéç¨®åºæ¼åå½¢å»ºæ¨¡åæ©å¨å­¸ç¿ççµåæä¾äºä¸åæ´ç²¾ç·»ä¸èªååçæ¹å¼ï¼èå³çµ±çæååææ¹æ³ç¸æ¯ï¼å¯ä»¥çè§£ååæè¤éç SELinux æ¿ç­ã

##### **KARPA: A Training-free Method of Adapting Knowledge Graph as References for Large Language Model's Reasoning Path Aggregation**
2412.20995v1 by Siyuan Fang, Kaijing Ma, Tianyu Zheng, Xinrun Du, Ningxuan Lu, Ge Zhang, Qingkun Tang

Large language models (LLMs) demonstrate exceptional performance across a
variety of tasks, yet they are often affected by hallucinations and the
timeliness of knowledge. Leveraging knowledge graphs (KGs) as external
knowledge sources has emerged as a viable solution, but existing methods for
LLM-based knowledge graph question answering (KGQA) are often limited by
step-by-step decision-making on KGs, restricting the global planning and
reasoning capabilities of LLMs, or they require fine-tuning or pre-training on
specific KGs. To address these challenges, we propose Knowledge graph Assisted
Reasoning Path Aggregation (KARPA), a novel framework that harnesses the global
planning abilities of LLMs for efficient and accurate KG reasoning. KARPA
operates in three steps: pre-planning relation paths using the LLM's global
planning capabilities, matching semantically relevant paths via an embedding
model, and reasoning over these paths to generate answers. Unlike existing KGQA
methods, KARPA avoids stepwise traversal, requires no additional training, and
is adaptable to various LLM architectures. Extensive experimental results show
that KARPA achieves state-of-the-art performance in KGQA tasks, delivering both
high efficiency and accuracy. Our code will be available on Github.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å¨åç¨®ä»»åä¸­è¡¨ç¾åºè²çè¡¨ç¾ï¼ä½å®åç¶å¸¸åå°å¹»è¦ºåç¥è­æææ§çå½±é¿ãå©ç¨ç¥è­åè­ (KG) ä½çºå¤é¨ç¥è­ä¾æºå·²æçºä¸åå¯è¡çè§£æ±ºæ¹æ¡ï¼ä½ç¾æç LLM åºæ¼ç¥è­åè­åç­ (KGQA) çæ¹æ³éå¸¸åå° KG ä¸éæ­¥æ±ºç­çéå¶ï¼éå¶äº LLM çå¨å±è¦ååæ¨çè½åï¼æèå®åéè¦éå°ç¹å® KG é²è¡å¾®èª¿æé è¨ç·´ãçºäºæå°éäºææ°ï¼æåæåºäºç¥è­åè­è¼å©æ¨çè·¯å¾èå (KARPA)ï¼éæ¯ä¸åæ°ç©çæ¡æ¶ï¼å©ç¨ LLM çå¨å±è¦åè½åé²è¡é«æä¸æºç¢ºç KG æ¨çãKARPA åä¸æ­¥æä½ï¼ä½¿ç¨ LLM çå¨å±è¦åè½åé åè¦åéä¿è·¯å¾ãééåµå¥æ¨¡åå¹éèªç¾©ç¸éè·¯å¾ï¼ä»¥åæ¨çéäºè·¯å¾ä»¥ç¢çç­æ¡ãèç¾æç KGQA æ¹æ³ä¸åï¼KARPA é¿åéæ­¥éæ­·ï¼ä¸éè¦é¡å¤çè¨ç·´ï¼ä¸¦ä¸å¯ä»¥é©æåç¨® LLM æ¶æ§ãå¤§éçå¯¦é©çµæè¡¨æï¼KARPA å¨ KGQA ä»»åä¸­å¯¦ç¾äºæåé²çæ§è½ï¼æ¢æä¾äºé«æçåæä¾äºé«æºç¢ºåº¦ãæåçç¨å¼ç¢¼å°å¨ Github ä¸æä¾ã

##### **Ontology-grounded Automatic Knowledge Graph Construction by LLM under Wikidata schema**
2412.20942v1 by Xiaohan Feng, Xixin Wu, Helen Meng

We propose an ontology-grounded approach to Knowledge Graph (KG) construction
using Large Language Models (LLMs) on a knowledge base. An ontology is authored
by generating Competency Questions (CQ) on knowledge base to discover knowledge
scope, extracting relations from CQs, and attempt to replace equivalent
relations by their counterpart in Wikidata. To ensure consistency and
interpretability in the resulting KG, we ground generation of KG with the
authored ontology based on extracted relations. Evaluation on benchmark
datasets demonstrates competitive performance in knowledge graph construction
task. Our work presents a promising direction for scalable KG construction
pipeline with minimal human intervention, that yields high quality and
human-interpretable KGs, which are interoperable with Wikidata semantics for
potential knowledge base expansion.

æè¦ï¼æåæåºä¸åä»¥æ¬ä½çºåºç¤çæ¹æ³ä¾å»ºæ§ç¥è­åè­ï¼KGï¼ï¼æ¹æ³æ¯ä½¿ç¨å¤§åèªè¨æ¨¡åï¼LLMï¼å¨ç¥è­åº«ä¸ãæ¬ä½æ¯ç±å¨ç¥è­åº«ä¸ç¢çè½ååé¡ï¼CQï¼ä¾ç¼ç¾ç¥è­ç¯åï¼å¾ CQ ä¸­æåéä¿ï¼ä¸¦åè©¦ç¨ Wikidata ä¸­çå°æéä¿æ¿æç­æéä¿èç·¨å¯«çãçºäºç¢ºä¿çµæ KG çä¸è´æ§åå¯è§£éæ§ï¼æåæ ¹ææåçéä¿ï¼ä»¥ç·¨å¯«çæ¬ä½çºåºç¤ä¾å»ºç« KG çç¢çãå¨åºæºè³æéä¸çè©ä¼°é¡¯ç¤ºå¨ç¥è­åè­å»ºæ§ä»»åä¸­æç«¶ç­åçæè½ãæåçç ç©¶æåºäºä¸åæå¸æçæ¹åï¼å¯ä»¥ééæ¥µå°çäººå·¥ä»å¥ä¾å»ºæ§å¯æ´åç KG ç®¡ç·ï¼ç¢çé«åè³ªä¸äººé¡å¯è§£éç KGï¼éäº KG è Wikidata èªç¾©å¯ä»¥äºéï¼ä»¥æ´åæ½å¨çç¥è­åº«ã

##### **ICLR: In-Context Learning of Representations**
2501.00070v1 by Core Francisco Park, Andrew Lee, Ekdeep Singh Lubana, Yongyi Yang, Maya Okawa, Kento Nishi, Martin Wattenberg, Hidenori Tanaka

Recent work has demonstrated that semantics specified by pretraining data
influence how representations of different concepts are organized in a large
language model (LLM). However, given the open-ended nature of LLMs, e.g., their
ability to in-context learn, we can ask whether models alter these pretraining
semantics to adopt alternative, context-specified ones. Specifically, if we
provide in-context exemplars wherein a concept plays a different role than what
the pretraining data suggests, do models reorganize their representations in
accordance with these novel semantics? To answer this question, we take
inspiration from the theory of conceptual role semantics and define a toy
"graph tracing" task wherein the nodes of the graph are referenced via concepts
seen during training (e.g., apple, bird, etc.) and the connectivity of the
graph is defined via some predefined structure (e.g., a square grid). Given
exemplars that indicate traces of random walks on the graph, we analyze
intermediate representations of the model and find that as the amount of
context is scaled, there is a sudden re-organization from pretrained semantic
representations to in-context representations aligned with the graph structure.
Further, we find that when reference concepts have correlations in their
semantics (e.g., Monday, Tuesday, etc.), the context-specified graph structure
is still present in the representations, but is unable to dominate the
pretrained structure. To explain these results, we analogize our task to energy
minimization for a predefined graph topology, providing evidence towards an
implicit optimization process to infer context-specified semantics. Overall,
our findings indicate scaling context-size can flexibly re-organize model
representations, possibly unlocking novel capabilities.

æè¦ï¼<paragraph>æè¿çç ç©¶è¡¨æï¼ç±é¢è®­ç»æ°æ®æå®çè¯­ä¹ä¼å½±åå¤§åè¯­è¨æ¨¡å (LLM) ä¸­ä¸åæ¦å¿µçè¡¨å¾ç»ç»æ¹å¼ãç¶èï¼é´äº LLM çå¼æ¾å¼æ¬è´¨ï¼ä¾å¦å®ä»¬å¨è¯­å¢ä¸­å­¦ä¹ çè½åï¼æä»¬å¯ä»¥è¯¢é®æ¨¡åæ¯å¦ä¼æ¹åè¿äºé¢è®­ç»è¯­ä¹ä»¥éç¨æ¿ä»£çãè¯­å¢æå®çè¯­ä¹ãå·ä½æ¥è¯´ï¼å¦ææä»¬å¨è¯­å¢ä¸­æä¾ç¤ºä¾ï¼å¶ä¸­ä¸ä¸ªæ¦å¿µæ®æ¼çè§è²ä¸é¢è®­ç»æ°æ®ææç¤ºçä¸åï¼æ¨¡åæ¯å¦ä¼æ ¹æ®è¿äºæ°è¯­ä¹éæ°ç»ç»å®ä»¬çè¡¨å¾ï¼ä¸ºäºåç­è¿ä¸ªé®é¢ï¼æä»¬ä»æ¦å¿µè§è²è¯­ä¹çè®ºä¸­æ±²åçµæï¼å¹¶å®ä¹äºä¸ä¸ªç©å·âå¾ç¤ºè¿½è¸ªâä»»å¡ï¼å¶ä¸­å¾çèç¹éè¿è®­ç»æé´çå°çæ¦å¿µï¼ä¾å¦ï¼è¹æãé¸ç­ï¼è¿è¡å¼ç¨ï¼å¹¶ä¸å¾çè¿éæ§æ¯éè¿ä¸äºé¢å®ä¹çç»æï¼ä¾å¦ï¼æ­£æ¹å½¢ç½æ ¼ï¼å®ä¹çãç»å®æç¤ºå¨å¾ä¸éæºæ¸¸èµ°çè½¨è¿¹çç¤ºä¾ï¼æä»¬åæäºæ¨¡åçä¸­é´è¡¨å¾ï¼åç°éçè¯­å¢éçå¢å ï¼ä»é¢è®­ç»è¯­ä¹è¡¨å¾å°ä¸å¾ç»æå¯¹é½çè¯­å¢è¡¨å¾çªç¶åçäºéæ°ç»ç»ãæ­¤å¤ï¼æä»¬åç°å½åèæ¦å¿µå¨å¶è¯­ä¹ä¸­å·æç¸å³æ§ï¼ä¾å¦ï¼ææä¸ãææäºç­ï¼æ¶ï¼è¯­å¢æå®çå¾ç»æä»ç¶å­å¨äºè¡¨å¾ä¸­ï¼ä½æ æ³æ¯éé¢è®­ç»ç»æãä¸ºäºè§£éè¿äºç»æï¼æä»¬å°æä»¬çä»»å¡ç±»æ¯ä¸ºé¢å®ä¹å¾ææçè½éæå°åï¼ä¸ºæ¨æ­è¯­å¢æå®è¯­ä¹çéå¼ä¼åè¿ç¨æä¾äºè¯æ®ãæ»ä½èè¨ï¼æä»¬çç ç©¶ç»æè¡¨æï¼æ©å±è¯­å¢å¤§å°å¯ä»¥çµæ´»å°éæ°ç»ç»æ¨¡åè¡¨å¾ï¼æå¯è½è§£éæ°çåè½ã</paragraph>

##### **Topic-Aware Knowledge Graph with Large Language Models for Interoperability in Recommender Systems**
2412.20163v1 by Minhye Jeon, Seokho Ahn, Young-Duk Seo

The use of knowledge graphs in recommender systems has become one of the
common approaches to addressing data sparsity and cold start problems. Recent
advances in large language models (LLMs) offer new possibilities for processing
side and context information within knowledge graphs. However, consistent
integration across various systems remains challenging due to the need for
domain expert intervention and differences in system characteristics. To
address these issues, we propose a consistent approach that extracts both
general and specific topics from both side and context information using LLMs.
First, general topics are iteratively extracted and updated from side
information. Then, specific topics are extracted using context information.
Finally, to address synonymous topics generated during the specific topic
extraction process, a refining algorithm processes and resolves these issues
effectively. This approach allows general topics to capture broad knowledge
across diverse item characteristics, while specific topics emphasize detailed
attributes, providing a more comprehensive understanding of the semantic
features of items and the preferences of users. Experimental results
demonstrate significant improvements in recommendation performance across
diverse knowledge graphs.

æè¦ï¼ç¥è­åè­å¨æ¨è¦ç³»çµ±ä¸­çæç¨å·²æçºè§£æ±ºè³æç¨çæ§åå·åååé¡çå¸¸è¦æ¹æ³ä¹ä¸ãå¤§åèªè¨æ¨¡å (LLM) çææ°é²å±çºèçç¥è­åè­ä¸­çå´éåèæ¯è³è¨æä¾äºæ°çå¯è½æ§ãç¶èï¼ç±æ¼éè¦é åå°å®¶çä»å¥åç³»çµ±ç¹æ§çå·®ç°ï¼è·¨åç¨®ç³»çµ±çä¸è´æ´åä»ç¶å·æææ°æ§ãçºäºè§£æ±ºéäºåé¡ï¼æåæåºäºä¸ç¨®ä¸è´çæ¹æ³ï¼å®ä½¿ç¨ LLM å¾å´éåèæ¯è³è¨ä¸­æåä¸è¬åç¹å®ä¸»é¡ãé¦åï¼å¾å´éè³è¨ä¸­åè¦æååæ´æ°ä¸è¬ä¸»é¡ãç¶å¾ï¼ä½¿ç¨èæ¯è³è¨æåç¹å®ä¸»é¡ãæå¾ï¼çºäºè§£æ±ºå¨ç¹å®ä¸»é¡æåéç¨ä¸­ç¢ççåç¾©ä¸»é¡ï¼ä¸åç²¾çæ¼ç®æ³ææå°èçä¸¦è§£æ±ºäºéäºåé¡ãéç¨®æ¹æ³åè¨±ä¸è¬ä¸»é¡æ·ååç¨®é ç®ç¹å¾µçå»£æ³ç¥è­ï¼èç¹å®ä¸»é¡åå¼·èª¿è©³ç´°å±¬æ§ï¼æä¾å°é ç®èªç¾©ç¹å¾µåä½¿ç¨èåå¥½çæ´å¨é¢çè§£ãå¯¦é©çµæè­æäºè·¨ä¸åç¥è­åè­çæ¨è¦æè½æé¡¯èçæåã

##### **From Generalist to Specialist: A Survey of Large Language Models for Chemistry**
2412.19994v1 by Yang Han, Ziping Wan, Lu Chen, Kai Yu, Xin Chen

Large Language Models (LLMs) have significantly transformed our daily life
and established a new paradigm in natural language processing (NLP). However,
the predominant pretraining of LLMs on extensive web-based texts remains
insufficient for advanced scientific discovery, particularly in chemistry. The
scarcity of specialized chemistry data, coupled with the complexity of
multi-modal data such as 2D graph, 3D structure and spectrum, present distinct
challenges. Although several studies have reviewed Pretrained Language Models
(PLMs) in chemistry, there is a conspicuous absence of a systematic survey
specifically focused on chemistry-oriented LLMs. In this paper, we outline
methodologies for incorporating domain-specific chemistry knowledge and
multi-modal information into LLMs, we also conceptualize chemistry LLMs as
agents using chemistry tools and investigate their potential to accelerate
scientific research. Additionally, we conclude the existing benchmarks to
evaluate chemistry ability of LLMs. Finally, we critically examine the current
challenges and identify promising directions for future research. Through this
comprehensive survey, we aim to assist researchers in staying at the forefront
of developments in chemistry LLMs and to inspire innovative applications in the
field.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å·²é¡¯èæ¹è®æåçæ¥å¸¸çæ´»ï¼ä¸¦å¨èªç¶èªè¨èç (NLP) ä¸­å»ºç«äºä¸åæ°çå¸ç¯ãç¶èï¼LLM å¨å»£æ³çåºæ¼ç¶²è·¯çææ¬ä¸é²è¡ççè¡é è¨ç·´å°æ¼åé²çç§å­¸ç¼ç¾ä»ç¶ä¸è¶³ï¼ç¹å¥æ¯å¨åå­¸é åãå°æ¥­åå­¸æ¸æçç¨ç¼ºï¼å ä¸ 2D åå½¢ã3D çµæ§ååè­ç­å¤æ¨¡ææ¸æçè¤éæ§ï¼æåºäºä¸åçææ°ãåç®¡ä¸äºç ç©¶åé¡§äºåå­¸ä¸­çé è¨ç·´èªè¨æ¨¡å (PLM)ï¼ä½é¡¯èç¼ºä¹å°æ³¨æ¼ä»¥åå­¸çºå°åç LLM çç³»çµ±æ§èª¿æ¥ãå¨æ¬æä¸­ï¼æåæ¦è¿°äºå°ç¹å®é åçåå­¸ç¥è­åå¤æ¨¡æè³è¨ç´å¥ LLM çæ¹æ³ï¼æåéå°åå­¸ LLM æ¦å¿µåçºä½¿ç¨åå­¸å·¥å·çä»£çï¼ä¸¦ç ç©¶å®åå éç§å­¸ç ç©¶çæ½åãæ­¤å¤ï¼æåç¸½çµäºç¾æçåºæºä¾è©ä¼° LLM çåå­¸è½åãæå¾ï¼æåæ¹å¤æ§å°å¯©æ¥äºç¶åçææ°ï¼ä¸¦ç¢ºå®äºæªä¾ç ç©¶çæå¸æçæ¹åãéééé å¨é¢çèª¿æ¥ï¼æåæ¨å¨åå©ç ç©¶äººå¡ææ¡åå­¸ LLM ç¼å±çæåæ²¿ï¼ä¸¦æ¿ç¼è©²é åçåµæ°æç¨ã

##### **Toward Adaptive Reasoning in Large Language Models with Thought Rollback**
2412.19707v1 by Sijia Chen, Baochun Li

Large language models (LLMs) have been routinely used to solve various tasks
using step-by-step reasoning. However, the structure of intermediate reasoning
steps, or thoughts, is rigid and unidirectional, such as chains, trees, or
acyclic-directed graphs. Consequently, the resulting inflexible and
forward-only reasoning may not address challenging tasks and fail when the LLM
frequently gives false responses, i.e., ``hallucinations''. This paper proposes
a new reasoning framework, called Thought Rollback (TR), allowing LLMs to
adaptively build thought structure while maintaining effective reasoning toward
problem-solving under ``hallucinations''. The core mechanism of TR is rolling
back thoughts, which allows LLMs to perform error analysis on thoughts, and
thus roll back to any previously mistaken thought for revision. Subsequently,
by including such trial-and-error in the prompt to guide the LLM, each rollback
leads to one more reliable reasoning path. Therefore, starting with a simple
prompt without human annotations, LLM with TR adaptively and gradually explores
thoughts for a correct solution. Comprehensive experiments on mathematical
problems and multi-task reasoning demonstrate the state-of-the-art performance
of TR in terms of problem-solving rate and interaction cost. For instance, the
solving rate of GPT-4 with TR outperforms the current best by $9\%$ on the MATH
dataset.

æè¦ï¼å¤§åèªè¨æ¨¡åï¼LLMï¼å·²å¸¸è¦ç¨æ¼è§£æ±ºåç¨®ä»»åï¼ä½¿ç¨éæ­¥æ¨çãç¶èï¼ä¸­éæ¨çæ­¥é©ææ³æ³ççµæ§æ¯åµåä¸å®åçï¼ä¾å¦éãæ¨¹æç¡ç°æååãå æ­¤ï¼ç¢ççåµåä¸åååæ¨çå¯è½ç¡æ³è§£æ±ºå·æææ°æ§çä»»åï¼ä¸¦ä¸ç¶ LLM é »ç¹çµ¦åºé¯èª¤çåæï¼å³ãå¹»è¦ºãï¼ææå¤±æãæ¬ææåºäºä¸åæ°çæ¨çæ¡æ¶ï¼ç¨±çº Thought Rollbackï¼TRï¼ï¼åè¨± LLM å¨è§£æ±ºãå¹»è¦ºãåé¡æèªé©æå°æ§å»ºææ³çµæ§ï¼åæä¿æææçæ¨çãTR çæ ¸å¿æ©å¶æ¯åæ»¾ææ³ï¼å®åè¨± LLM å°ææ³å·è¡é¯èª¤åæï¼ä¸¦å æ­¤åæ»¾å°ä»»ä½ååé¯èª¤çææ³é²è¡ä¿®æ¹ãé¨å¾ï¼ééå¨æç¤ºä¸­åå«æ­¤é¡è©¦é¯ä¾æå° LLMï¼æ¯æ¬¡åæ»¾é½æå°è´ä¸æ¢æ´å¯é çæ¨çè·¯å¾ãå æ­¤ï¼å¾ä¸åæ²æäººå·¥è¨»éçç°¡å®æç¤ºéå§ï¼å¸¶æ TR ç LLM èªé©æå°éæ¼¸æ¢ç´¢ææ³ä»¥ç²å¾æ­£ç¢ºçè§£æ±ºæ¹æ¡ãå¨æ¸å­¸åé¡åå¤ä»»åæ¨çä¸çç¶åå¯¦é©è­æäº TR å¨åé¡è§£æ±ºçåäº¤äºææ¬æ¹é¢çæåé²æ§è½ãä¾å¦ï¼å¸¶æ TR ç GPT-4 çæ±è§£çå¨ MATH æ¸æéä¸æ¯ç®åçæä½³æ§è½é«åº 9%ã

##### **Dynamic Skill Adaptation for Large Language Models**
2412.19361v1 by Jiaao Chen, Diyi Yang

We present Dynamic Skill Adaptation (DSA), an adaptive and dynamic framework
to adapt novel and complex skills to Large Language Models (LLMs). Compared
with previous work which learns from human-curated and static data in random
orders, we propose to first automatically generate and organize the training
data by mimicking the learning pathways of human and then dynamically tailor
the training data based on the training dynamics. Specifically, inspired by the
learning structures and teaching strategies in the human education system, we
first construct a skill graph by decomposing complex skills into sub-skills and
arranging them based on their dependencies in human syllables. For every skill,
we utilize LLMs to generate both textbook-like data which contains detailed
descriptions of skills for pre-training and exercise-like data which targets at
explicitly utilizing the skills to solve problems for instruction-tuning.
Furthermore, during the instruction-tuning, we dynamically update the training
data which down-weight easy-to-learn examples, generate more complex examples,
and filter out data with errors. Experiments on large language models such as
LLAMA and Mistral demonstrate the effectiveness of our proposed methods in
adapting math reasoning skills and social study skills.

æè¦ï¼æåæåºåææè½é©æ (DSA)ï¼ä¸ç¨®é©ææ§ååææ¡æ¶ï¼ç¨æ¼å°æ°ç©ä¸è¤éçæè½é©æå°å¤§åèªè¨æ¨¡å (LLM)ãèååå¾äººé¡ç­ååéæè³æä¸­ä»¥é¨æ©é åºå­¸ç¿çå·¥ä½ç¸æ¯ï¼æåå»ºè­°é¦åééæ¨¡æ¬äººé¡çå­¸ç¿è·¯å¾èªåç¢çåçµç¹è¨ç·´è³æï¼ç¶å¾æ ¹æè¨ç·´åæåæèª¿æ´è¨ç·´è³æãå·é«ä¾èªªï¼åå°äººé¡æè²ç³»çµ±ä¸­çå­¸ç¿çµæ§åæå­¸ç­ç¥çåç¼ï¼æåé¦åééå°è¤éæè½åè§£æå­æè½ä¸¦æ ¹æå®åå¨äººé¡é³ç¯ä¸­çä¾è³´æ§ä¾æåå®åä¾æ§å»ºæè½åãå°æ¼æ¯é æè½ï¼æåå©ç¨ LLM ç¢çé¡ä¼¼æç§æ¸çè³æï¼å¶ä¸­åå«æè½çè©³ç´°æè¿°ï¼ç¨æ¼é è¨ç·´åç·´ç¿é¡åçè³æï¼å¶ç®æ¨æ¯æç¢ºå©ç¨æè½è§£æ±ºåé¡ï¼ä»¥é²è¡æä»¤èª¿æ´ãæ­¤å¤ï¼å¨æä»¤èª¿æ´æéï¼æåæåææ´æ°è¨ç·´è³æï¼å¶ä¸­æéä½ææ¼å­¸ç¿ç¯ä¾çæ¬éãç¢çæ´è¤éçç¯ä¾ï¼ä¸¦éæ¿¾ææé¯èª¤çè³æãå¨ LLAMA å Mistral ç­å¤§åèªè¨æ¨¡åä¸é²è¡çå¯¦é©è­æäºæåæåºçæ¹æ³å¨é©ææ¸å­¸æ¨çæè½åç¤¾æç ç©¶æè½æ¹é¢çæææ§ã

##### **Relation-aware Hierarchical Prompt for Open-vocabulary Scene Graph Generation**
2412.19021v1 by Tao Liu, Rongjie Li, Chongyu Wang, Xuming He

Open-vocabulary Scene Graph Generation (OV-SGG) overcomes the limitations of
the closed-set assumption by aligning visual relationship representations with
open-vocabulary textual representations. This enables the identification of
novel visual relationships, making it applicable to real-world scenarios with
diverse relationships. However, existing OV-SGG methods are constrained by
fixed text representations, limiting diversity and accuracy in image-text
alignment. To address these challenges, we propose the Relation-Aware
Hierarchical Prompting (RAHP) framework, which enhances text representation by
integrating subject-object and region-specific relation information. Our
approach utilizes entity clustering to address the complexity of relation
triplet categories, enabling the effective integration of subject-object
information. Additionally, we utilize a large language model (LLM) to generate
detailed region-aware prompts, capturing fine-grained visual interactions and
improving alignment between visual and textual modalities. RAHP also introduces
a dynamic selection mechanism within Vision-Language Models (VLMs), which
adaptively selects relevant text prompts based on the visual content, reducing
noise from irrelevant prompts. Extensive experiments on the Visual Genome and
Open Images v6 datasets demonstrate that our framework consistently achieves
state-of-the-art performance, demonstrating its effectiveness in addressing the
challenges of open-vocabulary scene graph generation.

æè¦ï¼éæ¾è©å½å ´æ¯åçæ (OV-SGG) åæäºå°éå¼åè¨­çéå¶ï¼ééå°è¦è¦ºéä¿è¡¨å¾µèéæ¾è©å½ææ¬è¡¨å¾µå°é½ãéä½¿å¾è½å¤ è­å¥æ°çè¦è¦ºéä¿ï¼ä½¿å¶é©ç¨æ¼å·æå¤æ¨£åéä¿ççå¯¦ä¸çå ´æ¯ãç¶èï¼ç¾æç OV-SGG æ¹æ³åå°åºå®ææ¬è¡¨å¾µçéå¶ï¼éå¶äºååææ¬å°é½çå¤æ¨£æ§åæºç¢ºæ§ãçºäºæå°éäºææ°ï¼æåæåºäºéä¿æç¥éå±¤å¼æç¤º (RAHP) æ¶æ§ï¼ééæ´åä¸»é«å®¢é«åç¹å®ååçéä¿è³è¨ä¾å¢å¼·ææ¬è¡¨å¾µãæåçåæ³å©ç¨å¯¦é«èé¡ä¾è§£æ±ºéä¿ä¸åçµé¡å¥çè¤éæ§ï¼ä½¿ä¸»é«å®¢é«è³è¨è½å¤ æææ´åãæ­¤å¤ï¼æåå©ç¨å¤§åèªè¨æ¨¡å (LLM) ä¾ç¢çè©³ç´°çååæç¥æç¤ºï¼ææç´°å¾®çè¦è¦ºäºåä¸¦æ¹åè¦è¦ºåææ¬æ¨¡å¼ä¹éçå°é½ãRAHP ä¹å¨è¦è¦ºèªè¨æ¨¡å (VLM) ä¸­å¼å¥äºåæé¸ææ©å¶ï¼æ ¹æè¦è¦ºå§å®¹èªé©æå°é¸æç¸éææ¬æç¤ºï¼æ¸å°ä¸ç¸éæç¤ºçéè¨ãå¨ Visual Genome å Open Images v6 è³æéä¸çå¤§éå¯¦é©è­æï¼æåçæ¶æ§æçºéææåé²çæè½ï¼è­æå¶å¨è§£æ±ºéæ¾è©å½å ´æ¯åçæçææ°ä¸å·ææè½ã

##### **PhyloGen: Language Model-Enhanced Phylogenetic Inference via Graph Structure Generation**
2412.18827v1 by ChenRui Duan, Zelin Zang, Siyuan Li, Yongjie Xu, Stan Z. Li

Phylogenetic trees elucidate evolutionary relationships among species, but
phylogenetic inference remains challenging due to the complexity of combining
continuous (branch lengths) and discrete parameters (tree topology).
Traditional Markov Chain Monte Carlo methods face slow convergence and
computational burdens. Existing Variational Inference methods, which require
pre-generated topologies and typically treat tree structures and branch lengths
independently, may overlook critical sequence features, limiting their accuracy
and flexibility. We propose PhyloGen, a novel method leveraging a pre-trained
genomic language model to generate and optimize phylogenetic trees without
dependence on evolutionary models or aligned sequence constraints. PhyloGen
views phylogenetic inference as a conditionally constrained tree structure
generation problem, jointly optimizing tree topology and branch lengths through
three core modules: (i) Feature Extraction, (ii) PhyloTree Construction, and
(iii) PhyloTree Structure Modeling. Meanwhile, we introduce a Scoring Function
to guide the model towards a more stable gradient descent. We demonstrate the
effectiveness and robustness of PhyloGen on eight real-world benchmark
datasets. Visualization results confirm PhyloGen provides deeper insights into
phylogenetic relationships.

æè¦ï¼ç³»çµ±ç¼çæ¨¹é¡æäºç©ç¨®ä¹éçæ¼åéä¿ï¼ä½ç±æ¼é£çºåæ¸ï¼åæ¯é·åº¦ï¼åé¢æ£åæ¸ï¼æ¨¹å½¢çµæ§ï¼çµåçè¤éæ§ï¼ç³»çµ±ç¼çæ¨è«ä»ç¶å·æææ°æ§ãå³çµ±çé¦¬å¯å¤«éèç¹å¡ç¾æ¹æ³é¢è¨æ¶æéåº¦æ¢åè¨ç®è² æéãç¾æçè®åæ¨è«æ¹æ³éè¦é åç¢ççææ²çµæ§ï¼ä¸¦ä¸éå¸¸ç¨ç«èçæ¨¹å½¢çµæ§ååæ¯é·åº¦ï¼å¯è½æå¿½ç¥ééµçåºåç¹å¾µï¼å¾èéå¶å¶æºç¢ºæ§åéæ´»æ§ãæåæåºäº PhyloGenï¼éæ¯ä¸ç¨®æ°ç©çæ¹æ³ï¼å©ç¨é è¨ç·´çåºå çµèªè¨æ¨¡åä¾çæååªåç³»çµ±ç¼çæ¨¹ï¼èä¸éè¦ä¾è³´æ¼åæ¨¡åææ¯å°åºåç´æãPhyloGen å°ç³»çµ±ç¼çæ¨è«è¦çºä¸åæ¢ä»¶ç´æçæ¨¹å½¢çµæ§çæåé¡ï¼ééä¸åæ ¸å¿æ¨¡çµå±ååªåæ¨¹å½¢çµæ§ååæ¯é·åº¦ï¼(i) ç¹å¾µæåã(ii) PhyloTree æ§å»ºï¼ä»¥å (iii) PhyloTree çµæ§å»ºæ¨¡ãåæï¼æåå¼å¥äºè©åå½æ¸ä¾å¼å°æ¨¡åæèæ´ç©©å®çæ¢¯åº¦ä¸éæ¹åç¼å±ãæåå¨å«åçå¯¦ä¸ççåºæºæ¸æéä¸å±ç¤ºäº PhyloGen çæææ§åé­¯æ£æ§ãå¯è¦åçµæè­å¯¦ï¼PhyloGen è½å¤ æ´æ·±å¥å°äºè§£ç³»çµ±ç¼çéä¿ã

##### **CypherBench: Towards Precise Retrieval over Full-scale Modern Knowledge Graphs in the LLM Era**
2412.18702v1 by Yanlin Feng, Simone Papicchio, Sajjadur Rahman

Retrieval from graph data is crucial for augmenting large language models
(LLM) with both open-domain knowledge and private enterprise data, and it is
also a key component in the recent GraphRAG system (edge et al., 2024). Despite
decades of research on knowledge graphs and knowledge base question answering,
leading LLM frameworks (e.g. Langchain and LlamaIndex) have only minimal
support for retrieval from modern encyclopedic knowledge graphs like Wikidata.
In this paper, we analyze the root cause and suggest that modern RDF knowledge
graphs (e.g. Wikidata, Freebase) are less efficient for LLMs due to overly
large schemas that far exceed the typical LLM context window, use of resource
identifiers, overlapping relation types and lack of normalization. As a
solution, we propose property graph views on top of the underlying RDF graph
that can be efficiently queried by LLMs using Cypher. We instantiated this idea
on Wikidata and introduced CypherBench, the first benchmark with 11
large-scale, multi-domain property graphs with 7.8 million entities and over
10,000 questions. To achieve this, we tackled several key challenges, including
developing an RDF-to-property graph conversion engine, creating a systematic
pipeline for text-to-Cypher task generation, and designing new evaluation
metrics.

æè¦ï¼å¾åå½¢è³æä¸­æ·åå°æ¼æ´å¢å¤§åèªè¨æ¨¡å (LLM) éå¸¸éè¦ï¼å®çµåäºéæ¾é åç¥è­åç§äººä¼æ¥­è³æï¼åæä¹æ¯è¿æ GraphRAG ç³»çµ± (edge et al., 2024) çééµçµæé¨åãåç®¡ç¶éæ¸åå¹´çç¥è­åè­åç¥è­åº«åé¡è§£ç­ç ç©¶ï¼ä½é åç LLM æ¡æ¶ï¼ä¾å¦ Langchain å LlamaIndexï¼åè½æä½éåº¦æ¯æ´å¾ç¾ä»£ç¾ç§ç¥è­åè­ï¼ä¾å¦ Wikidataï¼æ·åãå¨æ¬æä¸­ï¼æååæäºæ ¹æ¬åå ï¼ä¸¦æåºç¾ä»£ RDF ç¥è­åè­ï¼ä¾å¦ WikidataãFreebaseï¼å°æ¼ LLM ä¾èªªæçè¼ä½ï¼éæ¯å çºéæ¼é¾å¤§çæ¶æ§é é è¶éå¸åç LLM èæ¯è¦çªãä½¿ç¨è³æºè­å¥ç¢¼ãéççéä¿é¡ååç¼ºä¹æ¨æºåãä½çºè§£æ±ºæ¹æ¡ï¼æåæåºå¨åºå±¤ RDF åå½¢ä¸å»ºç«å±¬æ§åå½¢æª¢è¦ï¼LLM å¯ä»¥ä½¿ç¨ Cypher ææå°æ¥è©¢éäºæª¢è¦ãæåå¨ Wikidata ä¸å¯¦ä¾åäºéåæ³æ³ï¼ä¸¦å¼å¥äº CypherBenchï¼éæ¯ç¬¬ä¸ååºæºï¼åå« 11 åå¤§åãå¤é åçå±¬æ§åå½¢ï¼ææ 780 è¬åå¯¦é«åè¶é 10,000 ååé¡ãçºäºéææ­¤ç®æ¨ï¼æåæå°äºå¹¾åééµææ°ï¼åæ¬éç¼ RDF å°å±¬æ§åå½¢è½æå¼æãå»ºç«æå­å° Cypher ä»»åç¢çç³»çµ±åæµç¨ï¼ä»¥åè¨­è¨æ°çè©ä¼°ææ¨ã

##### **From Hallucinations to Facts: Enhancing Language Models with Curated Knowledge Graphs**
2412.18672v1 by Ratnesh Kumar Joshi, Sagnik Sengupta, Asif Ekbal

Hallucination, a persistent challenge plaguing language models, undermines
their efficacy and trustworthiness in various natural language processing
endeavors by generating responses that deviate from factual accuracy or
coherence. This paper addresses language model hallucination by integrating
curated knowledge graph (KG) triples to anchor responses in empirical data. We
meticulously select and integrate relevant KG triples tailored to specific
contexts, enhancing factual grounding and alignment with input. Our
contribution involves constructing a comprehensive KG repository from Wikipedia
and refining data to spotlight essential information for model training. By
imbuing language models with access to this curated knowledge, we aim to
generate both linguistically fluent responses and deeply rooted in factual
accuracy and context relevance. This integration mitigates hallucinations by
providing a robust foundation of information, enabling models to draw upon a
rich reservoir of factual data during response generation. Experimental
evaluations demonstrate the effectiveness of multiple approaches in reducing
hallucinatory responses, underscoring the role of curated knowledge graphs in
improving the reliability and trustworthiness of language model outputs.

æè¦ï¼å¹»è¦ºï¼ä¸ç¨®æçºå°æ¾èªè¨æ¨¡åçææ°ï¼ç ´å£äºå®åå¨åç¨®èªç¶èªè¨èçå·¥ä½ä¸­çæçåå¯ä¿¡åº¦ï¼å çºå®åç¢ççåæåé¢äºäºå¯¦çæºç¢ºæ§æé£è²«æ§ãæ¬æééæ´åç¶éæ´ççç¥è­åè­ (KG) ä¸åçµä¾é¨å®ç¶é©æ¸æä¸­çåæï¼ä¾è§£æ±ºèªè¨æ¨¡åçå¹»è¦ºãæåä»ç´°å°é¸æä¸¦æ´åèç¹å®èçµ¡ç¸ç¬¦çç¸é KG ä¸åçµï¼å¢å¼·äºå¯¦ä¾æä¸¦èè¼¸å¥ä¿æä¸è´ãæåçè²¢ç»åæ¬å¾ç¶­åºç¾ç§æ§å»ºä¸åå¨é¢ç KG å²å­åº«ï¼ä¸¦ç²¾çæ¸æï¼ä»¥çªé¡¯æ¨¡åè¨ç·´çéè¦è³è¨ãééè®èªè¨æ¨¡åå­åéåç¶éæ´ççç¥è­ï¼æåæ¨å¨ç¢çæ¢èªè¨æµæ¢ï¼åæ·±æ¤æ¼äºå¯¦æºç¢ºæ§åèçµ¡ç¸éæ§çåæãéç¨®æ´åééæä¾ç©©å¥çè³è¨åºç¤ä¾æ¸è¼å¹»è¦ºï¼è®æ¨¡åå¨åæç¢çæéè½å¤ å©ç¨è±å¯çäºå¯¦æ¸æå²åãå¯¦é©è©ä¼°è­æäºå¤ç¨®æ¹æ³å¨æ¸å°å¹»è¦ºåææ¹é¢çæææ§ï¼å¼·èª¿äºç¶éæ´ççç¥è­åè­å¨æ¹åèªè¨æ¨¡åè¼¸åºçå¯é æ§åå¯ä¿¡åº¦æ¹é¢ææ®æ¼çè§è²ã

##### **Harnessing Large Language Models for Knowledge Graph Question Answering via Adaptive Multi-Aspect Retrieval-Augmentation**
2412.18537v2 by Derong Xu, Xinhang Li, Ziheng Zhang, Zhenxi Lin, Zhihong Zhu, Zhi Zheng, Xian Wu, Xiangyu Zhao, Tong Xu, Enhong Chen

Large Language Models (LLMs) demonstrate remarkable capabilities, yet
struggle with hallucination and outdated knowledge when tasked with complex
knowledge reasoning, resulting in factually incorrect outputs. Previous studies
have attempted to mitigate it by retrieving factual knowledge from large-scale
knowledge graphs (KGs) to assist LLMs in logical reasoning and prediction of
answers. However, this kind of approach often introduces noise and irrelevant
data, especially in situations with extensive context from multiple knowledge
aspects. In this way, LLM attention can be potentially mislead from question
and relevant information. In our study, we introduce an Adaptive Multi-Aspect
Retrieval-augmented over KGs (Amar) framework. This method retrieves knowledge
including entities, relations, and subgraphs, and converts each piece of
retrieved text into prompt embeddings. The Amar framework comprises two key
sub-components: 1) a self-alignment module that aligns commonalities among
entities, relations, and subgraphs to enhance retrieved text, thereby reducing
noise interference; 2) a relevance gating module that employs a soft gate to
learn the relevance score between question and multi-aspect retrieved data, to
determine which information should be used to enhance LLMs' output, or even
filtered altogether. Our method has achieved state-of-the-art performance on
two common datasets, WebQSP and CWQ, showing a 1.9\% improvement in accuracy
over its best competitor and a 6.6\% improvement in logical form generation
over a method that directly uses retrieved text as context prompts. These
results demonstrate the effectiveness of Amar in improving the reasoning of
LLMs.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å±ç¤ºäºéå¡çè½åï¼ä½å¨å·è¡è¤éçç¥è­æ¨çæï¼å»æåºç¾å¹»è¦ºåéæçç¥è­ï¼å°è´äºå¯¦ä¸ä¸æ­£ç¢ºçè¼¸åºãååçç ç©¶å·²åè©¦ééå¾å¤§è¦æ¨¡ç¥è­åè­ (KG) ä¸­æ·åäºå¯¦ç¥è­ä¾æ¸è¼éååé¡ï¼ä»¥åå© LLM é²è¡éè¼¯æ¨çåç­æ¡é æ¸¬ãç¶èï¼éç¨®æ¹æ³éå¸¸æå¼å¥éè¨åä¸ç¸éçè³æï¼ç¹å¥æ¯å¨å·æä¾èªå¤åç¥è­é¢åçå»£æ³èçµ¡çææ³ä¸ãéæ¨£ä¸ä¾ï¼LLM çæ³¨æåå¯è½æè¢«åé¡åç¸éè³è¨èª¤å°ãå¨æåçç ç©¶ä¸­ï¼æåä»ç´¹äºä¸åé©ææ§å¤é¢åæ·åå¢å¼·åç¥è­åè­ (Amar) æ¡æ¶ãæ­¤æ¹æ³æ·ååæ¬å¯¦é«ãéä¿åå­åçç¥è­ï¼ä¸¦å°æ¯åæ·åçæå­è½æçºæç¤ºåµå¥ãAmar æ¡æ¶åå«å©åééµå­åä»¶ï¼1) ä¸åèªæå°é½æ¨¡çµï¼ç¨æ¼å°é½å¯¦é«ãéä¿åå­åä¹éçå±æ§ï¼ä»¥å¢å¼·æ·åçæå­ï¼å¾èæ¸å°éè¨å¹²æ¾ï¼2) ä¸åç¸éæ§éæ§æ¨¡çµï¼æ¡ç¨è»éæ§ä¾å­¸ç¿åé¡åå¤é¢åæ·åè³æä¹éçç¸å³æ§åæ¸ï¼ä»¥ç¢ºå®åªäºè³è¨æä½¿ç¨ä¾å¢å¼· LLM çè¼¸åºï¼çè³å®å¨éæ¿¾æãæåçæ¨¡åå¨å©åå¸¸è¦çè³æé WebQSP å CWQ ä¸éå°äºæåé²çæè½ï¼èæä½³ç«¶ç­èç¸æ¯ï¼æºç¢ºåº¦æåäº 1.9%ï¼èç´æ¥ä½¿ç¨æ·åæå­ä½çºèçµ¡æç¤ºçæ¹æ³ç¸æ¯ï¼éè¼¯å½¢å¼çææåäº 6.6%ãéäºçµæè­æäº Amar å¨æ¹å LLM æ¨çæ¹é¢çæææ§ã

##### **DynaGRAG: Improving Language Understanding and Generation through Dynamic Subgraph Representation in Graph Retrieval-Augmented Generation**
2412.18644v1 by Karishma Thakrar

Graph Retrieval-Augmented Generation (GRAG or Graph RAG) architectures aim to
enhance language understanding and generation by leveraging external knowledge.
However, effectively capturing and integrating the rich semantic information
present in textual and structured data remains a challenge. To address this, a
novel GRAG framework is proposed to focus on enhancing subgraph representation
and diversity within the knowledge graph. By improving graph density, capturing
entity and relation information more effectively, and dynamically prioritizing
relevant and diverse subgraphs, the proposed approach enables a more
comprehensive understanding of the underlying semantic structure. This is
achieved through a combination of de-duplication processes, two-step mean
pooling of embeddings, query-aware retrieval considering unique nodes, and a
Dynamic Similarity-Aware BFS (DSA-BFS) traversal algorithm. Integrating Graph
Convolutional Networks (GCNs) and Large Language Models (LLMs) through hard
prompting further enhances the learning of rich node and edge representations
while preserving the hierarchical subgraph structure. Experimental results on
multiple benchmark datasets demonstrate the effectiveness of the proposed GRAG
framework, showcasing the significance of enhanced subgraph representation and
diversity for improved language understanding and generation.

æè¦ï¼åè¡¨æ·åå¢å¼·çæï¼GRAG æ Graph RAGï¼æ¶æ§æ¨å¨
éééç¨å¤é¨ç¥è­ä¾å¢å¼·èªè¨çè§£åçæã
ç¶èï¼æææ·ååæ´åææ¬åçµæ§åè³æä¸­è±å¯çèªç¾©è³è¨ä»ç¶æ¯ä¸é ææ°ãçºäºè§£æ±ºéååé¡ï¼æåºäºä¸åæ°ç GRAG æ¡æ¶ï¼å°æ³¨æ¼å¢å¼·ç¥è­åè­ä¸­çå­åè¡¨ç¤ºåå¤æ¨£æ§ãééæ¹ååå½¢å¯åº¦ãæ´ææå°æ·åå¯¦é«åéä¿è³è¨ï¼ä»¥ååæåªåèæ®ç¸éä¸å¤æ¨£åçå­åï¼ææåºçæ¹æ³è½æ´å¨é¢å°çè§£åºå±¤èªç¾©çµæ§ãéæ¯ééçµåéè¤è³æåªé¤ç¨åºãåµå¥çå©æ­¥é©å¹³åæ± åãèæ®å¯ä¸ç¯é»çæ¥è©¢æç¥æ·åï¼ä»¥ååæç¸ä¼¼åº¦æç¥å»£åº¦åªåæå°ï¼DSA-BFSï¼æ¼ç®æ³ä¾å¯¦ç¾çãééç¡¬æç¤ºæ´ååå½¢å·ç©ç¶²è·¯ï¼GCNï¼åå¤§èªè¨æ¨¡åï¼LLMï¼ï¼é²ä¸æ­¥å¢å¼·è±å¯ç¯é»åéç·£è¡¨ç¤ºçå­¸ç¿ï¼åæä¿çéå±¤å¼å­åçµæ§ãå¨å¤ååºæºè³æéä¸çå¯¦é©çµæè­æäºææåºç GRAG æ¡æ¶çæææ§ï¼å±ç¤ºäºå¢å¼·å­åè¡¨ç¤ºåå¤æ¨£æ§å°æ¼æ¹åèªè¨çè§£åçæçéè¦æ§ã

##### **Is Large Language Model Good at Triple Set Prediction? An Empirical Study**
2412.18443v1 by Yuan Yuan, Yajing Xu, Wen Zhang

The core of the Knowledge Graph Completion (KGC) task is to predict and
complete the missing relations or nodes in a KG. Common KGC tasks are mostly
about inferring unknown elements with one or two elements being known in a
triple. In comparison, the Triple Set Prediction (TSP) task is a more realistic
knowledge graph completion task. It aims to predict all elements of unknown
triples based on the information from known triples. In recent years, large
language models (LLMs) have exhibited significant advancements in language
comprehension, demonstrating considerable potential for KGC tasks. However, the
potential of LLM on the TSP task has not yet to be investigated. Thus in this
paper we proposed a new framework to explore the strengths and limitations of
LLM in the TSP task. Specifically, the framework consists of LLM-based rule
mining and LLM-based triple set prediction. The relation list of KG embedded
within rich semantic information is first leveraged to prompt LLM in the
generation of rules. This process is both efficient and independent of
statistical information, making it easier to mine effective and realistic
rules. For each subgraph, the specified rule is applied in conjunction with the
relevant triples within that subgraph to guide the LLM in predicting the
missing triples. Subsequently, the predictions from all subgraphs are
consolidated to derive the complete set of predicted triples on KG. Finally,
the method is evaluated on the relatively complete CFamily dataset. The
experimental results indicate that when LLMs are required to adhere to a large
amount of factual knowledge to predict missing triples, significant
hallucinations occurs, leading to a noticeable decline in performance. To
further explore the causes of this phenomenon, this paper presents a
comprehensive analysis supported by a detailed case study.

æè¦ï¼ç¥è­åè­å®æ (KGC) ä»»åçæ ¸å¿æ¯é æ¸¬åå®æ KG ä¸­éºå¤±çéä¿æç¯é»ãå¸¸è¦ç KGC ä»»åå¤§å¤æ¯éæ¼æ¨è«æªç¥åç´ ï¼å¶ä¸­ä¸åæå©ååç´ å¨ä¸åçµä¸­å·²ç¥ãç¸æ¯ä¹ä¸ï¼ä¸åçµéåé æ¸¬ (TSP) ä»»åæ¯ä¸åæ´å¯¦éçç¥è­åè­å®æä»»åãå®æ¨å¨æ ¹æå·²ç¥ä¸åçµä¸­çè³è¨é æ¸¬æªç¥ä¸åçµçææåç´ ãè¿å¹´ä¾ï¼å¤§åèªè¨æ¨¡å (LLM) å¨èªè¨çè§£æ¹é¢è¡¨ç¾åºé¡¯èçé²æ­¥ï¼é¡¯ç¤ºåº KGC ä»»åçå·¨å¤§æ½åãç¶èï¼LLM å¨ TSP ä»»åä¸çæ½åå°æªå¾å°æ¢è¨ãå æ­¤ï¼å¨æ¬æä¸­ï¼æåæåºäºä¸åæ°çæ¡æ¶ä¾æ¢ç´¢ LLM å¨ TSP ä»»åä¸­çåªå¢åå±éæ§ãå·é«ä¾èªªï¼è©²æ¡æ¶åå«åºæ¼ LLM çè¦åææååºæ¼ LLM çä¸åçµéåé æ¸¬ãåµå¥è±å¯èªç¾©è³è¨ç KG éä¿æ¸å®é¦åè¢«å©ç¨ä¾æç¤º LLM çæè¦åãéåéç¨æ¢ææçåç¨ç«æ¼çµ±è¨è³è¨ï¼ä½¿å¾ææææä¸å¯¦éçè¦åè®å¾æ´å®¹æãå°æ¼æ¯åå­åï¼æå®è¦åèè©²å­åä¸­ç¸éçä¸åçµçµåä½¿ç¨ï¼ä»¥æå° LLM é æ¸¬éºå¤±çä¸åçµãé¨å¾ï¼åä½µææå­åçé æ¸¬ï¼ä»¥æ¨å° KG ä¸é æ¸¬ä¸åçµçå®æ´éåãæå¾ï¼è©²æ¹æ³å¨ç¸å°å®æ´ç CFamily è³æéä¸é²è¡è©ä¼°ãå¯¦é©çµæè¡¨æï¼ç¶è¦æ± LLM éµå¾ªå¤§éäºå¯¦ç¥è­ä¾é æ¸¬éºå¤±çä¸åçµæï¼æç¼çé¡¯èçå¹»è¦ºï¼å°è´æè½é¡¯èä¸éãçºäºé²ä¸æ­¥æ¢è¨éç¨®ç¾è±¡çåå ï¼æ¬ææåºäºç±è©³ç´°æ¡ä¾ç ç©¶æ¯æ´çå¨é¢åæã

##### **Investigating Large Language Models for Code Vulnerability Detection: An Experimental Study**
2412.18260v2 by Xuefeng Jiang, Lvhua Wu, Sheng Sun, Jia Li, Jingjing Xue, Yuwei Wang, Tingting Wu, Min Liu

Code vulnerability detection (CVD) is essential for addressing and preventing
system security issues, playing a crucial role in ensuring software security.
Previous learning-based vulnerability detection methods rely on either
fine-tuning medium-size sequence models or training smaller neural networks
from scratch. Recent advancements in large pre-trained language models (LLMs)
have showcased remarkable capabilities in various code intelligence tasks
including code understanding and generation. However, the effectiveness of LLMs
in detecting code vulnerabilities is largely under-explored. This work aims to
investigate the gap by fine-tuning LLMs for the CVD task, involving four
widely-used open-source LLMs. We also implement other five previous graph-based
or medium-size sequence models for comparison. Experiments are conducted on
five commonly-used CVD datasets, including both the part of short samples and
long samples. In addition, we conduct quantitative experiments to investigate
the class imbalance issue and the model's performance on samples of different
lengths, which are rarely studied in previous works. To better facilitate
communities, we open-source all codes and resources of this study in
https://github.com/SakiRinn/LLM4CVD and
https://huggingface.co/datasets/xuefen/VulResource.

æè¦ï¼ç¨å¼ç¢¼æ¼æ´åµæ¸¬ (CVD) å°è§£æ±ºåé é²ç³»çµ±å®å¨åé¡è³ééè¦ï¼å¨ç¢ºä¿è»é«å®å¨ä¸æ®æ¼ééµè§è²ã
ååçåºæ¼å­¸ç¿çæ¼æ´åµæ¸¬æ¹æ³ä»°è³´å¾®èª¿ä¸­ååºåæ¨¡åæå¾é ­è¨ç·´è¼å°çç¥ç¶ç¶²è·¯ã
å¤§åé è¨ç·´èªè¨æ¨¡å (LLM) çææ°é²å±å¨åç¨®ç¨å¼ç¢¼æºæ§ä»»åä¸­å±ç¾åºåè¶çè½åï¼åæ¬ç¨å¼ç¢¼çè§£åç¢çã
ç¶èï¼LLM å¨åµæ¸¬ç¨å¼ç¢¼æ¼æ´çæè½å»é®®å°è¢«æ¢è¨ãæ¬ç ç©¶æ¨å¨ééå¾®èª¿ LLM ä¾å¡«è£éåç¼ºå£ï¼æ¶åååå»£æ³ä½¿ç¨çéæº LLMã
æåä¹å¯¦ä½äºå¶ä»äºåååçåºæ¼åå½¢çæä¸­ååºåæ¨¡åé²è¡æ¯è¼ã
å¯¦é©å¨äºåå¸¸ç¨ç CVD è³æéä¸é²è¡ï¼åå«ç­ç¯ä¾åé·ç¯ä¾çé¨åã
æ­¤å¤ï¼æåé²è¡éåå¯¦é©ä¾æ¢è¨é¡å¥ä¸å¹³è¡¡åé¡åæ¨¡åå¨ä¸åé·åº¦ç¯ä¾ä¸çè¡¨ç¾ï¼éäºå¨ååçç ç©¶ä¸­å¾å°è¢«æ¢è¨ã
çºæ´å¥½å°ä¿é²ç¤¾ç¾¤ï¼æåå¨ https://github.com/SakiRinn/LLM4CVD å https://huggingface.co/datasets/xuefen/VulResource éæºæ¬ç ç©¶çææç¨å¼ç¢¼åè³æºã

##### **An Automatic Graph Construction Framework based on Large Language Models for Recommendation**
2412.18241v1 by Rong Shan, Jianghao Lin, Chenxu Zhu, Bo Chen, Menghui Zhu, Kangning Zhang, Jieming Zhu, Ruiming Tang, Yong Yu, Weinan Zhang

Graph neural networks (GNNs) have emerged as state-of-the-art methods to
learn from graph-structured data for recommendation. However, most existing
GNN-based recommendation methods focus on the optimization of model structures
and learning strategies based on pre-defined graphs, neglecting the importance
of the graph construction stage. Earlier works for graph construction usually
rely on speciffic rules or crowdsourcing, which are either too simplistic or
too labor-intensive. Recent works start to utilize large language models (LLMs)
to automate the graph construction, in view of their abundant open-world
knowledge and remarkable reasoning capabilities. Nevertheless, they generally
suffer from two limitations: (1) invisibility of global view (e.g., overlooking
contextual information) and (2) construction inefficiency. To this end, we
introduce AutoGraph, an automatic graph construction framework based on LLMs
for recommendation. Specifically, we first use LLMs to infer the user
preference and item knowledge, which is encoded as semantic vectors. Next, we
employ vector quantization to extract the latent factors from the semantic
vectors. The latent factors are then incorporated as extra nodes to link the
user/item nodes, resulting in a graph with in-depth global-view semantics. We
further design metapath-based message aggregation to effectively aggregate the
semantic and collaborative information. The framework is model-agnostic and
compatible with different backbone models. Extensive experiments on three
real-world datasets demonstrate the efficacy and efffciency of AutoGraph
compared to existing baseline methods. We have deployed AutoGraph in Huawei
advertising platform, and gain a 2.69% improvement on RPM and a 7.31%
improvement on eCPM in the online A/B test. Currently AutoGraph has been used
as the main trafffc model, serving hundreds of millions of people.

æè¦ï¼åç¥ç¶ç¶²è·¯ (GNN) å·²æçºæåé²çæ¹æ³ï¼å¯å¾åå½¢çµæ§åè³æä¸­å­¸ç¿æ¨è¦ãç¶èï¼ç¾æçåºæ¼ GNN çæ¨è¦æ¹æ³å¤§å¤å´éæ¼é å®ç¾©åå½¢ä¸çæ¨¡åçµæ§åå­¸ç¿ç­ç¥çæä½³åï¼å¿½ç¥äºåå½¢å»ºæ§éæ®µçéè¦æ§ãæ©æåå½¢å»ºæ§å·¥ä½éå¸¸ä¾è³´æ¼ç¹å®è¦åæç¾¤ç¾å¤åï¼éäºæ¹æ³éæ¼ç°¡åæéæ¼ååå¯éãæè¿çå·¥ä½éå§å©ç¨å¤§åèªè¨æ¨¡å (LLM) ä¾èªåååå½¢å»ºæ§ï¼å çºå®åå·æè±å¯çéæ¾ä¸çç¥è­ååè¶çæ¨çè½åãåç®¡å¦æ­¤ï¼å®åéå¸¸å­å¨å©åéå¶ï¼(1) å¨åæª¢è¦çä¸å¯è¦æ§ï¼ä¾å¦ï¼å¿½ç¥ä¸ä¸æè³è¨ï¼å (2) å»ºæ§æçä½ä¸ãçºæ­¤ï¼æåå¼å¥äº AutoGraphï¼ä¸ååºæ¼ LLM çèªååå½¢å»ºæ§æ¡æ¶ï¼ç¨æ¼æ¨è¦ãå·é«ä¾èªªï¼æåé¦åä½¿ç¨ LLM æ¨æ·ä½¿ç¨èåå¥½åé ç®ç¥è­ï¼ä¸¦å°å¶ç·¨ç¢¼çºèªç¾©åéãæ¥ä¸ä¾ï¼æåæ¡ç¨åééåå¾èªç¾©åéä¸­æåæ½å¨å å­ãç¶å¾å°æ½å¨å å­ä½çºé¡å¤ç¯é»å å¥ï¼ä»¥é£çµä½¿ç¨è/é ç®ç¯é»ï¼å¾èå½¢æä¸åå·ææ·±å¥å¨åæª¢è¦èªç¾©çåå½¢ãæåé²ä¸æ­¥è¨­è¨äºåºæ¼åè·¯å¾çè¨æ¯èåï¼ä»¥ææèåèªç¾©ååä½è³è¨ãè©²æ¡æ¶èæ¨¡åç¡éï¼ä¸¦èä¸åçä¸»å¹¹æ¨¡åç¸å®¹ãå¨ä¸åçå¯¦ä¸çè³æéä¸é²è¡çå»£æ³å¯¦é©è­æäº AutoGraph èç¾æåºæºæ¹æ³ç¸æ¯çæè½åæçãæåå·²å¨è¯çºå»£åå¹³å°ä¸é¨ç½²äº AutoGraphï¼ä¸¦å¨ç·ä¸ A/B æ¸¬è©¦ä¸­ç²å¾äº RPM æå 2.69% å eCPM æå 7.31%ãç®å AutoGraph å·²è¢«ç¨ä½ä¸»è¦çæµéæ¨¡åï¼æåæ¼æ¸åäººã

##### **CARL-GT: Evaluating Causal Reasoning Capabilities of Large Language Models**
2412.17970v1 by Ruibo Tu, Hedvig KjellstrÃ¶m, Gustav Eje Henter, Cheng Zhang

Causal reasoning capabilities are essential for large language models (LLMs)
in a wide range of applications, such as education and healthcare. But there is
still a lack of benchmarks for a better understanding of such capabilities.
Current LLM benchmarks are mainly based on conversational tasks, academic math
tests, and coding tests. Such benchmarks evaluate LLMs in well-regularized
settings, but they are limited in assessing the skills and abilities to solve
real-world problems. In this work, we provide a benchmark, named by CARL-GT,
which evaluates CAusal Reasoning capabilities of large Language models using
Graphs and Tabular data. The benchmark has a diverse range of tasks for
evaluating LLMs from causal graph reasoning, knowledge discovery, and
decision-making aspects. In addition, effective zero-shot learning prompts are
developed for the tasks. In our experiments, we leverage the benchmark for
evaluating open-source LLMs and provide a detailed comparison of LLMs for
causal reasoning abilities. We found that LLMs are still weak in casual
reasoning, especially with tabular data to discover new insights. Furthermore,
we investigate and discuss the relationships of different benchmark tasks by
analyzing the performance of LLMs. The experimental results show that LLMs have
different strength over different tasks and that their performance on tasks in
different categories, i.e., causal graph reasoning, knowledge discovery, and
decision-making, shows stronger correlation than tasks in the same category.

æè¦ï¼å ææ¨çè½åå¯¹äºå¤§åè¯­è¨æ¨¡å (LLM) è³å³éè¦ï¼éç¨äºå¹¿æ³çåºç¨ï¼ä¾å¦æè²åå»çä¿å¥ãä½å¯¹äºæ´å¥½å°çè§£æ­¤ç±»è½åï¼ä»ç¶ç¼ºä¹åºåãå½åç LLM åºåä¸»è¦åºäºä¼è¯ä»»å¡ãå­¦æ¯æ°å­¦æµè¯åç¼ç æµè¯ãæ­¤ç±»åºåå¨ç»è¿è¯å¥½è§èçç¯å¢ä¸­è¯ä¼° LLMï¼ä½å®ä»¬å¨è¯ä¼°è§£å³å®éé®é¢çè½ååæè½æ¹é¢åå°éå¶ãå¨è¿é¡¹å·¥ä½ä¸­ï¼æä»¬æä¾äºä¸ä¸ªåºåï¼åä¸º CARL-GTï¼å®ä½¿ç¨å¾åè¡¨æ ¼æ°æ®æ¥è¯ä¼°å¤§åè¯­è¨æ¨¡åçå ææ¨çè½åãè¯¥åºåå·æåç§ä»»å¡ï¼ç¨äºä»å æå¾æ¨çãç¥è¯åç°åå³ç­æ¹é¢è¯ä¼° LLMãæ­¤å¤ï¼éå¯¹è¿äºä»»å¡å¼åäºææçé¶æ ·æ¬å­¦ä¹ æç¤ºãå¨æä»¬çå®éªä¸­ï¼æä»¬å©ç¨åºåæ¥è¯ä¼°å¼æº LLMï¼å¹¶å¯¹ LLM çå ææ¨çè½åè¿è¡äºè¯¦ç»æ¯è¾ãæä»¬åç° LLM å¨å ææ¨çæ¹é¢ä»ç¶å¾å¼±ï¼å°¤å¶æ¯å¨ä½¿ç¨è¡¨æ ¼æ°æ®åç°æ°è§è§£æ¶ãæ­¤å¤ï¼æä»¬éè¿åæ LLM çæ§è½æ¥è°æ¥åè®¨è®ºä¸ååºåä»»å¡ä¹é´çå³ç³»ãå®éªç»æè¡¨æï¼LLM å¨ä¸åä»»å¡ä¸å·æä¸åçä¼å¿ï¼å¹¶ä¸å®ä»¬å¨ä¸åç±»å«ä¸­çä»»å¡ä¸çè¡¨ç°ï¼å³å æå¾æ¨çãç¥è¯åç°åå³ç­ï¼æ¯åä¸ç±»å«ä¸­çä»»å¡è¡¨ç°åºæ´å¼ºçç¸å³æ§ã

##### **Path-of-Thoughts: Extracting and Following Paths for Robust Relational Reasoning with Large Language Models**
2412.17963v1 by Ge Zhang, Mohammad Ali Alomrani, Hongjian Gu, Jiaming Zhou, Yaochen Hu, Bin Wang, Qun Liu, Mark Coates, Yingxue Zhang, Jianye Hao

Large language models (LLMs) possess vast semantic knowledge but often
struggle with complex reasoning tasks, particularly in relational reasoning
problems such as kinship or spatial reasoning. In this paper, we present
Path-of-Thoughts (PoT), a novel framework designed to tackle relation reasoning
by decomposing the task into three key stages: graph extraction, path
identification, and reasoning. Unlike previous approaches, PoT efficiently
extracts a task-agnostic graph that identifies crucial entities, relations, and
attributes within the problem context. Subsequently, PoT identifies relevant
reasoning chains within the graph corresponding to the posed question,
facilitating inference of potential answers. Experimental evaluations on four
benchmark datasets, demanding long reasoning chains, demonstrate that PoT
surpasses state-of-the-art baselines by a significant margin (maximum 21.3%)
without necessitating fine-tuning or extensive LLM calls. Furthermore, as
opposed to prior neuro-symbolic methods, PoT exhibits improved resilience
against LLM errors by leveraging the compositional nature of graphs.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) ææå»£æ³çèªç¾©ç¥è­ï¼ä½å¨è¤éçæ¨çä»»åä¸­ç¶å¸¸éå°å°é£ï¼ç¹å¥æ¯å¨éä¿æ¨çåé¡ä¸­ï¼ä¾å¦è¦ªå±¬éä¿æç©ºéæ¨çãå¨æ¬æä¸­ï¼æåæåºæèè·¯å¾ (PoT)ï¼éæ¯ä¸åæ°ç©çæ¡æ¶ï¼æ¨å¨ééå°ä»»ååè§£çºä¸åééµéæ®µä¾è§£æ±ºéä¿æ¨çï¼åå½¢æåãè·¯å¾è­å¥åæ¨çãèä¹åçåæ³ä¸åï¼PoT ææå°æåäºä¸åèä»»åç¡éçåå½¢ï¼è©²åå½¢è­å¥äºåé¡èæ¯ä¸­çééµå¯¦é«ãéä¿åå±¬æ§ãé¨å¾ï¼PoT å¨èææåºçåé¡ç¸æçåå½¢ä¸­è­å¥åºç¸éçæ¨çéï¼å¾èæ¨æ·åºæ½å¨ç­æ¡ãå¨éè¦é·æ¨çéçåååºæºæ¸æéä¸çå¯¦é©è©ä¼°è¡¨æï¼PoT ä»¥é¡¯èçåªå¢ï¼æå¤§ 21.3%ï¼è¶è¶äºæåé²çåºæºï¼èç¡éå¾®èª¿æå»£æ³ç LLM èª¿ç¨ãæ­¤å¤ï¼èååçç¥ç¶ç¬¦èæ¹æ³ç¸åï¼PoT ééå©ç¨åå½¢ççµåç¹æ§è¡¨ç¾åºå° LLM é¯èª¤çå¢å¼·çå½æ§ã

##### **ResearchTown: Simulator of Human Research Community**
2412.17767v1 by Haofei Yu, Zhaochen Hong, Zirui Cheng, Kunlun Zhu, Keyang Xuan, Jinwei Yao, Tao Feng, Jiaxuan You

Large Language Models (LLMs) have demonstrated remarkable potential in
scientific domains, yet a fundamental question remains unanswered: Can we
simulate human research communities with LLMs? Addressing this question can
deepen our understanding of the processes behind idea brainstorming and inspire
the automatic discovery of novel scientific insights. In this work, we propose
ResearchTown, a multi-agent framework for research community simulation. Within
this framework, the human research community is simplified and modeled as an
agent-data graph, where researchers and papers are represented as agent-type
and data-type nodes, respectively, and connected based on their collaboration
relationships. We also introduce TextGNN, a text-based inference framework that
models various research activities (e.g., paper reading, paper writing, and
review writing) as special forms of a unified message-passing process on the
agent-data graph. To evaluate the quality of the research simulation, we
present ResearchBench, a benchmark that uses a node-masking prediction task for
scalable and objective assessment based on similarity. Our experiments reveal
three key findings: (1) ResearchTown can provide a realistic simulation of
collaborative research activities, including paper writing and review writing;
(2) ResearchTown can maintain robust simulation with multiple researchers and
diverse papers; (3) ResearchTown can generate interdisciplinary research ideas
that potentially inspire novel research directions.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å¨ç§å­¸é åå±ç¾äºéå¡çæ½åï¼ä½ä»æä¸ååºæ¬åé¡å°æªè§£ç­ï¼æåè½ç¨ LLM æ¨¡æ¬äººé¡ç ç©¶ç¤¾ç¾¤åï¼æ¢è¨éååé¡è½å æ·±æåå°è¦åæ¿çªèå¾æµç¨ççè§£ï¼ä¸¦æ¿ç¼èªåç¼ç¾æ°ç§å­¸è¦è§£ãå¨éé å·¥ä½ä¸­ï¼æåæåº ResearchTownï¼ä¸åç¨æ¼ç ç©¶ç¤¾ç¾¤æ¨¡æ¬çå¤ä»£çæ¶æ§ãå¨éåæ¶æ§ä¸­ï¼äººé¡ç ç©¶ç¤¾ç¾¤è¢«ç°¡åä¸¦å»ºæ¨¡çºä»£çè³æåï¼å¶ä¸­ç ç©¶äººå¡åè«æåå¥è¡¨ç¤ºçºä»£çé¡åç¯é»åè³æé¡åç¯é»ï¼ä¸¦æ ¹æä»åçåä½éä¿é²è¡é£æ¥ãæåéä»ç´¹äº TextGNNï¼ä¸ååºæ¼æå­çæ¨è«æ¶æ§ï¼å®å°åç¨®ç ç©¶æ´»åï¼ä¾å¦ï¼é±è®è«æãæ°å¯«è«æåæ°å¯«è©è«ï¼å»ºæ¨¡çºä»£çè³æåä¸çµ±ä¸è¨æ¯å³ééç¨çç¹æ®å½¢å¼ãçºäºè©ä¼°ç ç©¶æ¨¡æ¬çåè³ªï¼æåæåºäº ResearchBenchï¼ä¸åä½¿ç¨ç¯é»é®ç½©é æ¸¬ä»»åé²è¡åºæ¼ç¸ä¼¼æ§çå¯æ´åä¸å®¢è§è©ä¼°çåºæºãæåçå¯¦é©æ­ç¤ºäºä¸åééµç¼ç¾ï¼(1) ResearchTown å¯ä»¥æä¾åä½ç ç©¶æ´»åçé¼çæ¨¡æ¬ï¼åæ¬æ°å¯«è«æåæ°å¯«è©è«ï¼(2) ResearchTown å¯ä»¥ç¶­æå¤ä½ç ç©¶äººå¡åä¸åè«æçç©©å¥æ¨¡æ¬ï¼(3) ResearchTown å¯ä»¥ç¢çè·¨å­¸ç§ç ç©¶æ§æ³ï¼æ½å¨æ¿ç¼æ°çç ç©¶æ¹åã

##### **RAGONITE: Iterative Retrieval on Induced Databases and Verbalized RDF for Conversational QA over KGs with RAG**
2412.17690v3 by Rishiraj Saha Roy, Chris Hinze, Joel Schlotthauer, Farzad Naderi, Viktor Hangya, Andreas Foltyn, Luzian Hahn, Fabian Kuech

Conversational question answering (ConvQA) is a convenient means of searching
over RDF knowledge graphs (KGs), where a prevalent approach is to translate
natural language questions to SPARQL queries. However, SPARQL has certain
shortcomings: (i) it is brittle for complex intents and conversational
questions, and (ii) it is not suitable for more abstract needs. Instead, we
propose a novel two-pronged system where we fuse: (i) SQL-query results over a
database automatically derived from the KG, and (ii) text-search results over
verbalizations of KG facts. Our pipeline supports iterative retrieval: when the
results of any branch are found to be unsatisfactory, the system can
automatically opt for further rounds. We put everything together in a retrieval
augmented generation (RAG) setup, where an LLM generates a coherent response
from accumulated search results. We demonstrate the superiority of our proposed
system over several baselines on a knowledge graph of BMW automobiles.

æè¦ï¼å°è©±å¼åç­ï¼ConvQAï¼æ¯ä¸ç¨®æå° RDF ç¥è­åè­ï¼KGï¼çä¾¿å©æ¹æ³ï¼å¶ä¸­ä¸ç¨®æ®éçæ¹æ³æ¯å°èªç¶èªè¨åé¡è½æçº SPARQL æ¥è©¢ãç¶èï¼SPARQL ææäºç¼ºé»ï¼(i) å°æ¼è¤éçæååå°è©±å¼åé¡èè¨ï¼å®å¾èå¼±ï¼(ii) å®ä¸é©åæ´æ½è±¡çéæ±ãç¸åï¼æåæåºäºä¸åæ°ç©çéç®¡é½ä¸çç³»çµ±ï¼å¶ä¸­æåèåï¼(i) å¾èªåå¾ KG ä¸­æ´¾ççè³æåº«ä¸ç SQL æ¥è©¢çµæï¼ä»¥å (ii) KG äºå¯¦çè¨èªåä¸çæå­æå°çµæãæåçç®¡ç·æ¯æ´åè¦æª¢ç´¢ï¼ç¶ç¼ç¾ä»»ä½åæ¯ççµæä¸ä»¤äººæ»¿ææï¼ç³»çµ±å¯ä»¥èªåé¸æé²ä¸æ­¥çååãæåå°ææå§å®¹æ´åå°æª¢ç´¢æ´åçæï¼RAGï¼è¨­å®ä¸­ï¼å¶ä¸­ LLM å¾ç´¯ç©çæå°çµæä¸­ç¢çé£è²«çåæãæåå¨ BMW æ±½è»çç¥è­åè­ä¸å±ç¤ºäºæåæåºçç³»çµ±åªæ¼å¹¾ååºç·çåªè¶æ§ã

##### **A Dual-Perspective Metaphor Detection Framework Using Large Language Models**
2412.17332v2 by Yujie Lin, Jingyao Liu, Yan Gao, Ante Wang, Jinsong Su

Metaphor detection, a critical task in natural language processing, involves
identifying whether a particular word in a sentence is used metaphorically.
Traditional approaches often rely on supervised learning models that implicitly
encode semantic relationships based on metaphor theories. However, these
methods often suffer from a lack of transparency in their decision-making
processes, which undermines the reliability of their predictions. Recent
research indicates that LLMs (large language models) exhibit significant
potential in metaphor detection. Nevertheless, their reasoning capabilities are
constrained by predefined knowledge graphs. To overcome these limitations, we
propose DMD, a novel dual-perspective framework that harnesses both implicit
and explicit applications of metaphor theories to guide LLMs in metaphor
detection and adopts a self-judgment mechanism to validate the responses from
the aforementioned forms of guidance. In comparison to previous methods, our
framework offers more transparent reasoning processes and delivers more
reliable predictions. Experimental results prove the effectiveness of DMD,
demonstrating state-of-the-art performance across widely-used datasets.

æè¦ï¼é±å»åµæ¸¬æ¯èªç¶èªè¨èçä¸­çä¸é éè¦ä»»åï¼æ¶åè­å¥å¥å­ä¸­ç¹å®å®å­æ¯å¦ä»¥é±å»æ¹å¼ä½¿ç¨ãå³çµ±æ¹æ³éå¸¸ä¾è³´ç£ç£å¼å­¸ç¿æ¨¡åï¼éäºæ¨¡åæ ¹æé±å»çè«é±å«ç·¨ç¢¼èªç¾©éä¿ãç¶èï¼éäºæ¹æ³éå¸¸å¨æ±ºç­éç¨ä¸­ç¼ºä¹éæåº¦ï¼éææå®³å¶é æ¸¬çå¯é æ§ãæè¿çç ç©¶è¡¨æï¼LLMï¼å¤§åèªè¨æ¨¡åï¼å¨é±å»åµæ¸¬ä¸­å±ç¾åºé¡¯èçæ½åãåç®¡å¦æ­¤ï¼å®åçæ¨çè½ååå°é å®ç¾©ç¥è­åè¡¨çéå¶ãçºäºåæéäºéå¶ï¼æåæåºäº DMDï¼éæ¯ä¸ç¨®æ°ç©çééè§é»æ¶æ§ï¼å®å©ç¨é±å»çè«çé±å«åæç¢ºæç¨ä¾å¼å° LLM é²è¡é±å»åµæ¸¬ï¼ä¸¦æ¡ç¨èªæå¤æ·æ©å¶ä¾é©è­ä¸è¿°æå°å½¢å¼çåæãèååçæ¨¡åç¸æ¯ï¼æåçæ¶æ§æä¾äºæ´éæçæ¨çéç¨ï¼ä¸¦æä¾äºæ´å¯é çé æ¸¬ãå¯¦é©çµæè­æäº DMD çæææ§ï¼è­æäºå¨å»£æ³ä½¿ç¨çè³æéä¸­çæåé²æè½ã

##### **GraphAgent: Agentic Graph Language Assistant**
2412.17029v1 by Yuhao Yang, Jiabin Tang, Lianghao Xia, Xingchen Zou, Yuxuan Liang, Chao Huang

Real-world data is represented in both structured (e.g., graph connections)
and unstructured (e.g., textual, visual information) formats, encompassing
complex relationships that include explicit links (such as social connections
and user behaviors) and implicit interdependencies among semantic entities,
often illustrated through knowledge graphs. In this work, we propose
GraphAgent, an automated agent pipeline that addresses both explicit graph
dependencies and implicit graph-enhanced semantic inter-dependencies, aligning
with practical data scenarios for predictive tasks (e.g., node classification)
and generative tasks (e.g., text generation). GraphAgent comprises three key
components: (i) a Graph Generator Agent that builds knowledge graphs to reflect
complex semantic dependencies; (ii) a Task Planning Agent that interprets
diverse user queries and formulates corresponding tasks through agentic
self-planning; and (iii) a Task Execution Agent that efficiently executes
planned tasks while automating tool matching and invocation in response to user
queries. These agents collaborate seamlessly, integrating language models with
graph language models to uncover intricate relational information and data
semantic dependencies. Through extensive experiments on various graph-related
predictive and text generative tasks on diverse datasets, we demonstrate the
effectiveness of our GraphAgent across various settings. We have made our
proposed GraphAgent open-source at: https://github.com/HKUDS/GraphAgent.

æè¦ï¼çå¯¦ä¸ççè³æä»¥çµæ§åï¼ä¾å¦åå½¢é£æ¥ï¼åéçµæ§åï¼ä¾å¦æå­ãè¦è¦ºè³è¨ï¼æ ¼å¼åç¾ï¼åå«è¤éçéä¿ï¼åæ¬æç¢ºçé£çµï¼ä¾å¦ç¤¾äº¤é£çµåä½¿ç¨èè¡çºï¼åèªæå¯¦é«ä¹éçé±å«ç¸äºä¾è³´ï¼éå¸¸ééç¥è­åè¡¨ä¾èªªæãå¨éé å·¥ä½ä¸­ï¼æåæåº GraphAgentï¼ä¸åèªååä»£çç¨å¼ç®¡éï¼å®èçæç¢ºçåå½¢ä¾è³´éä¿åé±å«çåå½¢å¢å¼·èªæç¸äºä¾è³´éä¿ï¼èé æ¸¬ä»»åï¼ä¾å¦ç¯é»åé¡ï¼åçæä»»åï¼ä¾å¦æå­çæï¼çå¯¦éè³ææå¢ä¿æä¸è´ãGraphAgent åå«ä¸åééµçµæé¨åï¼(i) ä¸ååå½¢ç¢çå¨ä»£çç¨å¼ï¼ç¨ä¾å»ºæ§ç¥è­åè¡¨ä»¥åæ è¤éçèªæä¾è³´éä¿ï¼(ii) ä¸åä»»åè¦åä»£çç¨å¼ï¼ç¨ä¾è©®éä¸åçä½¿ç¨èæ¥è©¢ï¼ä¸¦ééä»£çèªè¦åå¶å®ç¸æçä»»åï¼ä»¥å (iii) ä¸åä»»åå·è¡ä»£çç¨å¼ï¼ç¨ä¾å¨åæä½¿ç¨èæ¥è©¢æï¼ææçå°å·è¡å·²è¦åçä»»åï¼åæèªååå·¥å·éå°åå¼å«ãéäºä»£çç¨å¼ç¡ç¸«å°åä½ï¼å°èªè¨æ¨¡åèåå½¢èªè¨æ¨¡åæ´åå¨ä¸èµ·ï¼ä»¥æ­é²è¤éçéä¿è³è¨åè³æèªæä¾è³´éä¿ãééå¨ä¸åè³æéä¸é²è¡åç¨®èåå½¢ç¸éçé æ¸¬åæå­çæä»»åçå»£æ³å¯¦é©ï¼æåè­æäº GraphAgent å¨åç¨®è¨­å®ä¸­çæææ§ãæåå·²å°æåæåºç GraphAgent éæºï¼https://github.com/HKUDS/GraphAgentã

##### **Enhancing Supply Chain Transparency in Emerging Economies Using Online Contents and LLMs**
2412.16922v1 by Bohan Jin, Qianyou Sun, Lihua Chen

In the current global economy, supply chain transparency plays a pivotal role
in ensuring this security by enabling companies to monitor supplier performance
and fostering accountability and responsibility. Despite the advancements in
supply chain relationship datasets like Bloomberg and FactSet, supply chain
transparency remains a significant challenge in emerging economies due to
issues such as information asymmetry and institutional gaps in regulation. This
study proposes a novel approach to enhance supply chain transparency in
emerging economies by leveraging online content and large language models
(LLMs). We develop a Supply Chain Knowledge Graph Mining System that integrates
advanced LLMs with web crawler technology to automatically collect and analyze
supply chain information. The system's effectiveness is validated through a
case study focusing on the semiconductor supply chain, a domain that has
recently gained significant attention due to supply chain risks. Our results
demonstrate that the proposed system provides greater applicability for
emerging economies, such as mainland China, complementing the data gaps in
existing datasets. However, challenges including the accurate estimation of
monetary and material flows, the handling of time series data, synonyms
disambiguation, and mitigating biases from online contents still remains.
Future research should focus on addressing these issues to further enhance the
system's capabilities and broaden its application to other emerging economies
and industries.

æè¦ï¼å¨ç¶ä»å¨çç¶æ¿ä¸­ï¼ä¾æééæåº¦å¨ç¢ºä¿æ­¤å®å¨æ§æ¹é¢ç¼æ®èééµä½ç¨ï¼è®å¬å¸è½å¤ ç£æ§ä¾æåç¸¾æä¸¦ä¿é²åè²¬å¶åè²¬ä»»æãåç®¡å½­åç¤¾å FactSet ç­ä¾æééä¿æ¸æéåå¾é²å±ï¼ä½ç±æ¼è³è¨ä¸å°ç¨±åæ³è¦å¶åº¦å·®è·ç­åé¡ï¼ä¾æééæåº¦å¨éç¼ä¸­åå®¶ä»æ¯ä¸é éå¤§ææ°ãæ¬ç ç©¶æåºäºä¸ç¨®æ°æ¹æ³ï¼å©ç¨ç·ä¸å§å®¹åå¤§åèªè¨æ¨¡å (LLM) ä¾å å¼·éç¼ä¸­åå®¶çä¾æééæåº¦ãæåéç¼äºä¸åä¾æéç¥è­åè­ææç³»çµ±ï¼å°åé²ç LLM èç¶²è·¯ç¬è²æè¡æ´åå¨ä¸èµ·ï¼ä»¥èªåæ¶éååæä¾æéè³è¨ãè©²ç³»çµ±çæææ§å·²éééå°åå°é«ä¾æéçæ¡ä¾ç ç©¶å¾å°é©è­ï¼åå°é«ä¾æéæ¯ä¸åç±æ¼ä¾æéé¢¨éªèæè¿åå°æ¥µå¤§éæ³¨çé åãæåççµæè¡¨æï¼ææåºçç³»çµ±çºéç¼ä¸­åå®¶ï¼ä¾å¦ä¸­åå¤§é¸ï¼æä¾äºæ´å¤§çé©ç¨æ§ï¼è£åäºç¾ææ¸æéä¸­çæ¸æå·®è·ãç¶èï¼åæ¬æºç¢ºä¼°è¨è²¨å¹£åç©ææµãèçæéåºåæ¸æãæ¶é¤åç¾©è©æ­§ç¾©åæ¸è¼ç·ä¸å§å®¹åè¦å¨å§çææ°ä»ç¶å­å¨ãæªä¾çç ç©¶æå°æ³¨æ¼è§£æ±ºéäºåé¡ï¼ä»¥é²ä¸æ­¥å¢å¼·ç³»çµ±çè½åä¸¦æ´å¤§å¶å¨å¶ä»éç¼ä¸­åå®¶åç¢æ¥­çæç¨ã

##### **KG4Diagnosis: A Hierarchical Multi-Agent LLM Framework with Knowledge Graph Enhancement for Medical Diagnosis**
2412.16833v2 by Kaiwen Zuo, Yirui Jiang, Fan Mo, Pietro Lio

Integrating Large Language Models (LLMs) in healthcare diagnosis demands
systematic frameworks that can handle complex medical scenarios while
maintaining specialized expertise. We present KG4Diagnosis, a novel
hierarchical multi-agent framework that combines LLMs with automated knowledge
graph construction, encompassing 362 common diseases across medical
specialties. Our framework mirrors real-world medical systems through a
two-tier architecture: a general practitioner (GP) agent for initial assessment
and triage, coordinating with specialized agents for in-depth diagnosis in
specific domains. The core innovation lies in our end-to-end knowledge graph
generation methodology, incorporating: (1) semantic-driven entity and relation
extraction optimized for medical terminology, (2) multi-dimensional decision
relationship reconstruction from unstructured medical texts, and (3)
human-guided reasoning for knowledge expansion. KG4Diagnosis serves as an
extensible foundation for specialized medical diagnosis systems, with
capabilities to incorporate new diseases and medical knowledge. The framework's
modular design enables seamless integration of domain-specific enhancements,
making it valuable for developing targeted medical diagnosis systems. We
provide architectural guidelines and protocols to facilitate adoption across
medical contexts.

æè¦ï¼æ´åå¤§åèªè¨æ¨¡å (LLM) æ¼é«çè¨ºæ·ä¸­éè¦ç³»çµ±æ§æ¶æ§ï¼æ­¤æ¶æ§å¿é è½èçè¤éçé«çæå¢ï¼åæä¿æå°æ¥­ç¥è­ãæåæåº KG4Diagnosisï¼ä¸åçµå LLM èèªååç¥è­åè¡¨å»ºæ§çæ°åéå±¤å¼å¤éä»£çæ¶æ§ï¼æ¶µè 362 ç¨®å¸¸è¦ç¾çï¼æ©«è·¨ååé«çå°ç§ãæåçæ¶æ§éééå±¤æ¶æ§åæ çå¯¦ä¸ççé«çç³»çµ±ï¼ä¸ä½è² è²¬åæ­¥è©ä¼°ååæµçå®¶åº­é«å¸« (GP) ä»£çï¼åèª¿ååå°ç§ä»£çé²è¡æ·±å¥è¨ºæ·ãæ ¸å¿åµæ°å¨æ¼æåçç«¯å°ç«¯ç¥è­åè¡¨ç¢çæ¹æ³ï¼çµåï¼(1) èªæé©åçå¯¦é«èéä¿èåï¼éå°é«çè¡èªé²è¡æä½³åï¼(2) å¾éçµæ§åé«çææ¬éå»ºå¤ç¶­åº¦æ±ºç­éä¿ï¼ä»¥å (3) äººé¡å¼å°çæ¨çï¼ç¨æ¼ç¥è­æ´åãKG4Diagnosis å¯ä½çºå°éé«çè¨ºæ·ç³»çµ±çå¯å»¶ä¼¸åºç¤ï¼æè½åæ´åæ°çç¾çåé«çç¥è­ãæ­¤æ¶æ§çæ¨¡çµåè¨­è¨è½ç¡ç¸«æ´åç¹å®é åçå¼·ååè½ï¼ä½¿å¶å°æ¼éç¼ç®æ¨å°åçé«çè¨ºæ·ç³»çµ±æ¥µå·å¹å¼ãæåæä¾æ¶æ§æå¼ååå®ï¼ä»¥ä¿é²å¨åç¨®é«çæå¢ä¸­çæ¡ç¨ã

##### **Apples to Apples: Establishing Comparability in Knowledge Generation Tasks Involving Users**
2412.16766v1 by Christophe Debruyne, Ademar Crotti Junior

Knowledge graph construction (KGC) from (semi-)structured data is
challenging, and facilitating user involvement is an issue frequently brought
up within this community. We cannot deny the progress we have made with respect
to (declarative) knowledge generation languages and tools to help build such
mappings. However, it is surprising that no two studies report on similar
protocols. This heterogeneity does not allow for a comparison of KGC languages,
techniques, and tools. This paper first analyses the various studies that
report on studies involving users to identify the points of comparison. These
gaps include a lack of systematic consistency in task design, participant
selection, and evaluation metrics. Moreover, there needs to be a systematic way
of analyzing the data and reporting the findings, which is also lacking. We
thus propose and introduce a user protocol for KGC designed to address this
challenge. Where possible, we draw and take elements from the literature we
deem fit for such a protocol. The protocol, as such, allows for the comparison
of languages and techniques for the RDF Mapping Languages core functionality,
which is covered by most of the other state-of-the-art techniques and tools. We
also propose how the protocol can be amended to compare extensions (of RML).
This protocol provides an important step towards a more comparable evaluation
of KGC user studies.

æè¦ï¼ç¥è­åè­å»ºæ§ (KGC) å¾ (å) çµæ§åè³æä¸­é²è¡éå¸¸å·æææ°æ§ï¼èä¿é²ä½¿ç¨èåèæ¯éåç¤¾ç¾¤ä¸­ç¶å¸¸æåºçè­°é¡ãæåç¡æ³å¦èªæåå¨åå©å»ºæ§æ­¤é¡å°æç (å®£åå¼) ç¥è­ç¢çèªè¨åå·¥å·æ¹é¢æåçé²å±ãç¶èï¼ä»¤äººé©è¨çæ¯ï¼æ²æå©é ç ç©¶å ±åé¡ä¼¼çåå®ãéç¨®ç°è³ªæ§ä¸åè¨±æ¯è¼ KGC èªè¨ãæè¡åå·¥å·ãæ¬æé¦ååæåç¨®ç ç©¶ï¼éäºç ç©¶å ±åæ¶åä½¿ç¨èçç ç©¶ï¼ä»¥æ¾åºæ¯è¼é»ãéäºå·®è·åæ¬ä»»åè¨­è¨ãåèèé¸æåè©éææ¨ç¼ºä¹ç³»çµ±æ§çä¸è´æ§ãæ­¤å¤ï¼éè¦æç³»çµ±çæ¹æ³ä¾åæè³æåå ±åçµæï¼éä¹æ¯æç¼ºä¹çãå æ­¤ï¼æåæåºä¸¦ä»ç´¹ä¸åä½¿ç¨èåå®ï¼ç¨æ¼ KGCï¼æ¨å¨è§£æ±ºéåææ°ãå¨å¯è½çç¯åå§ï¼æåå¾æåèªçºé©åæ­¤é¡åå®çæç»ä¸­æ±²åä¸¦æ¡ç¨åç´ ãå æ­¤ï¼è©²åå®åè¨±æ¯è¼ RDF å°æèªè¨æ ¸å¿åè½çèªè¨åæè¡ï¼èå¤§å¤æ¸å¶ä»æåé²çæè¡åå·¥å·é½æ¶µèäºéä¸é»ãæåéæåºå¦ä½ä¿®æ¹åå®ä»¥æ¯è¼å»¶ä¼¸ (RML)ãæ­¤åå®æä¾äºä¸åéè¦çæ­¥é©ï¼æåæ´å·å¯æ¯è¼æ§ç KGC ä½¿ç¨èç ç©¶è©ééé²ã

##### **Self-guided Knowledgeable Network of Thoughts: Amplifying Reasoning with Large Language Models**
2412.16533v1 by Chao-Chi Chen, Chin-Yuan Yeh, Hsi-Wen Chen, De-Nian Yang, Ming-Syan Chen

We introduce Knowledgeable Network of Thoughts (kNoT): a prompt scheme that
advances the capabilities of large language models (LLMs) beyond existing
paradigms like Chain-of-Thought (CoT), Tree of Thoughts (ToT), and Graph of
Thoughts (GoT). The key innovation of kNoT is the LLM Workflow Template (LWT),
which allows for an executable plan to be specified by LLMs for LLMs. LWT
allows these plans to be arbitrary networks, where single-step LLM operations
are nodes, and edges correspond to message passing between these steps.
Furthermore, LWT supports selection of individual elements through indexing,
facilitating kNoT to produce intricate plans where each LLM operation can be
limited to elementary operations, greatly enhancing reliability over extended
task sequences. We demonstrate that kNoT significantly outperforms the state of
the art on six use cases, while reducing the need for extensive prompt
engineering. For instance, kNoT finds 92% accuracy for sorting 32 numbers over
12% and 31% for ToT and GoT, while utilizing up to 84.4% and 87.3% less
task-specific prompts, respectively.

æè¦ï¼æåå¼å¥äºææ³ç¥è­ç¶²è·¯ (kNoT)ï¼ä¸ç¨®æç¤ºæ¶æ§ï¼å®å°å¤§åèªè¨æ¨¡å (LLM) çè½åæåå°äºè¶è¶ç¾æç¯ä¾çå¢çï¼ä¾å¦ææ³é (CoT)ãææ³æ¨¹ (ToT) åææ³å (GoT)ãkNoT çééµåµæ°æ¯ LLM å·¥ä½æµç¨ç¯æ¬ (LWT)ï¼å®åè¨± LLM çº LLM æå®ä¸åå¯å·è¡çè¨ç«ãLWT åè¨±éäºè¨ç«æçºä»»æç¶²è·¯ï¼å¶ä¸­å®æ­¥ LLM æä½çºç¯é»ï¼èéç·£å°ææ¼éäºæ­¥é©ä¹éçè¨æ¯å³éãæ­¤å¤ï¼LWT æ¯æ´ééç´¢å¼é¸ååå¥åç´ ï¼é²èè® kNoT è½å¤ å¶å®è¤éçè¨ç«ï¼å¶ä¸­æ¯å LLM æä½é½å¯ä»¥éå¶çºåºæ¬æä½ï¼å¤§å¹æåå»¶ä¼¸ä»»ååºåçå¯é æ§ãæåè­æ kNoT å¨å­åç¨ä¾ä¸é¡¯èåªæ¼ç¾ææè¡ï¼åææ¸å°äºå°å»£æ³æç¤ºå·¥ç¨çéæ±ãä¾å¦ï¼kNoT å¨å° 32 åæ¸å­é²è¡æåºæç¼ç¾ 92% çæºç¢ºçï¼è ToT å GoT çº 12% å 31%ï¼åæåå¥å©ç¨äºå°é 84.4% å 87.3% çç¹å®ä»»åæç¤ºã

##### **Beyond End-to-End VLMs: Leveraging Intermediate Text Representations for Superior Flowchart Understanding**
2412.16420v1 by Junyi Ye, Ankan Dash, Wenpeng Yin, Guiling Wang

Flowcharts are typically presented as images, driving the trend of using
vision-language models (VLMs) for end-to-end flowchart understanding. However,
two key challenges arise: (i) Limited controllability--users have minimal
influence over the downstream task, as they can only modify input images, while
the training of VLMs is often out of reach for most researchers. (ii) Lack of
explainability--it is difficult to trace VLM errors to specific causes, such as
failures in visual encoding or reasoning. We propose TextFlow, addressing
aforementioned issues with two stages: (i) Vision Textualizer--which generates
textual representations from flowchart images; and (ii) Textual Reasoner--which
performs question-answering based on the text representations. TextFlow offers
three key advantages: (i) users can select the type of text representations
(e.g., Graphviz, Mermaid, PlantUML), or further convert them into executable
graph object to call tools, enhancing performance and controllability; (ii) it
improves explainability by helping to attribute errors more clearly to visual
or textual processing components; and (iii) it promotes the modularization of
the solution, such as allowing advanced LLMs to be used in the Reasoner stage
when VLMs underperform in end-to-end fashion. Experiments on the FlowVQA and
FlowLearn benchmarks demonstrate TextFlow's state-of-the-art performance as
well as its robustness. All code is publicly available.

æè¦ï¼æµç¨åéå¸¸ä»¥å½±ååç¾ï¼æ¨åäºä½¿ç¨è¦è¦ºèªè¨æ¨¡å (VLM) é²è¡ç«¯å°ç«¯æµç¨åçè§£çè¶¨å¢ãç¶èï¼åºç¾äºå©åééµææ°ï¼(i) å¯æ§æ§æéââä½¿ç¨èå°ä¸æ¸¸ä»»åçå½±é¿å¾å°ï¼å çºä»ååªè½ä¿®æ¹è¼¸å¥å½±åï¼èå¤§å¤æ¸ç ç©¶äººå¡å¾å¾ç¡æ³è¨ç·´ VLMã(ii) ç¼ºä¹å¯è§£éæ§ââé£ä»¥è¿½æº¯ VLM é¯èª¤å°å·é«åå ï¼ä¾å¦è¦è¦ºç·¨ç¢¼ææ¨çå¤±æãæåæåº TextFlowï¼ééå©åéæ®µä¾è§£æ±ºä¸è¿°åé¡ï¼(i) è¦è¦ºæå­åå¨ââå¾æµç¨åå½±åç¢çæå­è¡¨ç¤ºï¼(ii) æå­æ¨çå¨ââæ ¹ææå­è¡¨ç¤ºå·è¡åç­ãTextFlow æä¾äºä¸åä¸»è¦åªé»ï¼(i) ä½¿ç¨èå¯ä»¥é¸ææå­è¡¨ç¤ºçé¡åï¼ä¾å¦ GraphvizãMermaidãPlantUMLï¼ï¼æé²ä¸æ­¥å°å®åè½æçºå¯å·è¡çåå½¢ç©ä»¶ä¾å¼å«å·¥å·ï¼å¢å¼·æè½åå¯æ§æ§ï¼(ii) å®ééå¹«å©æ´æ¸æ¥å°å°é¯èª¤æ­¸å æ¼è¦è¦ºææå­èçåä»¶ä¾æ¹åå¯è§£éæ§ï¼(iii) å®ä¿é²äºè§£æ±ºæ¹æ¡çæ¨¡çµåï¼ä¾å¦åè¨±å¨ VLM å¨ç«¯å°ç«¯æ¨¡å¼ä¸è¡¨ç¾ä¸ä½³æï¼å¨æ¨çå¨éæ®µä½¿ç¨é²é LLMãå¨ FlowVQA å FlowLearn åºæºä¸çå¯¦é©è­æäº TextFlow çæåé²æè½ä»¥åå¶ç©©å¥æ§ãææç¨å¼ç¢¼é½å¬éå¯ç¨ã

##### **HybGRAG: Hybrid Retrieval-Augmented Generation on Textual and Relational Knowledge Bases**
2412.16311v1 by Meng-Chieh Lee, Qi Zhu, Costas Mavromatis, Zhen Han, Soji Adeshina, Vassilis N. Ioannidis, Huzefa Rangwala, Christos Faloutsos

Given a semi-structured knowledge base (SKB), where text documents are
interconnected by relations, how can we effectively retrieve relevant
information to answer user questions? Retrieval-Augmented Generation (RAG)
retrieves documents to assist large language models (LLMs) in question
answering; while Graph RAG (GRAG) uses structured knowledge bases as its
knowledge source. However, many questions require both textual and relational
information from SKB - referred to as "hybrid" questions - which complicates
the retrieval process and underscores the need for a hybrid retrieval method
that leverages both information. In this paper, through our empirical analysis,
we identify key insights that show why existing methods may struggle with
hybrid question answering (HQA) over SKB. Based on these insights, we propose
HybGRAG for HQA consisting of a retriever bank and a critic module, with the
following advantages: (1) Agentic, it automatically refines the output by
incorporating feedback from the critic module, (2) Adaptive, it solves hybrid
questions requiring both textual and relational information with the retriever
bank, (3) Interpretable, it justifies decision making with intuitive refinement
path, and (4) Effective, it surpasses all baselines on HQA benchmarks. In
experiments on the STaRK benchmark, HybGRAG achieves significant performance
gains, with an average relative improvement in Hit@1 of 51%.

æè¦ï¼<paragraph>çµ¦å®ä¸ååçµæ§åç¥è­åº« (SKB)ï¼å¶ä¸­ææ¬æä»¶ç±éä¿ç¸äºé£æ¥ï¼æåå¦ä½ææå°æ·åç¸éè³è¨ä¾åç­ä½¿ç¨èçåé¡ï¼æ·åå¢å¼·çæ (RAG) æ·åæä»¶ä»¥åå©å¤§åèªè¨æ¨¡å (LLM) åç­åé¡ï¼èåå½¢ RAG (GRAG) ä½¿ç¨çµæ§åç¥è­åº«ä½çºå¶ç¥è­ä¾æºãç¶èï¼è¨±å¤åé¡éè¦ä¾èª SKB çæå­åéä¿è³è¨ï¼ç¨±çºãæ··åãåé¡ï¼éä½¿å¾æ·åéç¨è¤éåï¼ä¸¦å¼·èª¿éè¦ä¸ç¨®å©ç¨éå©ç¨®è³è¨çæ··åæ·åæ¹æ³ãå¨æ¬æä¸­ï¼ééæåçå¯¦è­åæï¼æåæ¾åºé¡¯ç¤ºç¾ææ¹æ³å¯è½é£ä»¥å¨ SKB ä¸é²è¡æ··ååé¡è§£ç­ (HQA) çééµè¦è§£ãæ ¹æéäºè¦è§£ï¼æåæåºç±æ·åå¨åº«åæ¹è©æ¨¡çµçµæãå·æä»¥ä¸åªé»ç HQA HybGRAGï¼(1) ä»£çï¼å®ééç´å¥æ¹è©æ¨¡çµçåé¥èªåç²¾çè¼¸åºï¼(2) é©æï¼å®ä½¿ç¨æ·åå¨åº«è§£æ±ºéè¦æå­åéä¿è³è¨çæ··ååé¡ï¼(3) å¯è§£éï¼å®ä»¥ç´è¦ºçç²¾çè·¯å¾è­ææ±ºç­ï¼ä»¥å (4) ææï¼å®è¶è¶äº HQA åºæºçææåºæºãå¨ STaRK åºæºçå¯¦é©ä¸­ï¼HybGRAG éå°äºé¡¯èçæè½æåï¼Hit@1 çå¹³åç¸å°æ¹åçº 51%ã</paragraph>

##### **Logical Consistency of Large Language Models in Fact-checking**
2412.16100v1 by Bishwamittra Ghosh, Sarah Hasan, Naheed Anjum Arafat, Arijit Khan

In recent years, large language models (LLMs) have demonstrated significant
success in performing varied natural language tasks such as language
translation, question-answering, summarizing, fact-checking, etc. Despite LLMs'
impressive ability to generate human-like texts, LLMs are infamous for their
inconsistent responses -- a meaning-preserving change in the input query
results in an inconsistent response and attributes to vulnerabilities of LLMs
such as hallucination, jailbreaking, etc. Consequently, existing research
focuses on simple paraphrasing-based consistency assessment of LLMs, and
ignores complex queries that necessitates an even better understanding of
logical reasoning by an LLM. Our work therefore addresses the logical
inconsistency of LLMs under complex logical queries with primitive logical
operators, e.g., negation, conjunction, and disjunction. As a test bed, we
consider retrieval-augmented LLMs on a fact-checking task involving
propositional logic queries from real-world knowledge graphs (KGs). Our
contributions are three-fold. Benchmark: We introduce three logical
fact-checking datasets over KGs for community development towards logically
consistent LLMs. Assessment: We propose consistency measures of LLMs on
propositional logic queries as input and demonstrate that existing LLMs lack
logical consistency, specially on complex queries. Improvement: We employ
supervised fine-tuning to improve the logical consistency of LLMs on the
complex fact-checking task with KG contexts.

æè¦ï¼è¿å¹´ä¾ï¼å¤§åèªè¨æ¨¡å (LLM) å¨å·è¡åç¨®èªç¶èªè¨ä»»åï¼ä¾å¦èªè¨ç¿»è­¯ãåç­ãæè¦ãäºå¯¦æ¥æ ¸ç­ï¼æ¹é¢å±ç¾åºé¡¯èçæåãåç®¡ LLM è½ç¢çé¡ä¼¼äººé¡çæå­ï¼ä½ LLM ä»¥å¶ä¸ä¸è´çåæèè­åæ­èââè¼¸å¥æ¥è©¢ä¸­ä¸åä¿ææ¹è®æå°è´ä¸ä¸è´çåæï¼ä¸¦æ­¸å æ¼ LLM çæ¼æ´ï¼ä¾å¦å¹»è¦ºãè¶çç­ãå æ­¤ï¼ç¾æçç ç©¶å°æ³¨æ¼ LLM çåºæ¼ç°¡å®æ¹å¯«çä¸è´æ§è©ä¼°ï¼èå¿½ç¥äºéè¦ LLM æ´æ·±å¥çè§£éè¼¯æ¨ççè¤éæ¥è©¢ãå æ­¤ï¼æåçç ç©¶è§£æ±ºäº LLM å¨å·æåºæ¬éè¼¯éç®åï¼ä¾å¦å¦å®ãåååæåï¼çè¤ééè¼¯æ¥è©¢ä¸çéè¼¯ä¸ä¸è´æ§ãä½çºä¸åæ¸¬è©¦å¹³å°ï¼æåèæ®å¨ä¸åæ¶åä¾èªçå¯¦ä¸çç¥è­åè­ (KG) çå½é¡éè¼¯æ¥è©¢çäºå¯¦æ¥æ ¸ä»»åä¸­ï¼æª¢ç´¢å¢å¼·ç LLMãæåçè²¢ç»æä¸æ¹é¢ãåºæºï¼æåå¨ KG ä¸å¼å¥äºä¸åéè¼¯äºå¯¦æ¥æ ¸æ¸æéï¼ä»¥ä¿é²ç¤¾åéç¼éè¼¯ä¸è´ç LLMãè©ä¼°ï¼æåæåºäº LLM å¨å½é¡éè¼¯æ¥è©¢ä½çºè¼¸å¥ä¸çä¸è´æ§æ¸¬éï¼ä¸¦è­æç¾æç LLM ç¼ºä¹éè¼¯ä¸è´æ§ï¼ç¹å¥æ¯å¨è¤éæ¥è©¢ä¸ãæ¹é²ï¼æåæ¡ç¨ç£ç£å¾®èª¿ä¾æé« LLM å¨å·æ KG èæ¯çè¤éäºå¯¦æ¥æ ¸ä»»åä¸çéè¼¯ä¸è´æ§ã

##### **GraphSeqLM: A Unified Graph Language Framework for Omic Graph Learning**
2412.15790v1 by Heming Zhang, Di Huang, Yixin Chen, Fuhai Li

The integration of multi-omic data is pivotal for understanding complex
diseases, but its high dimensionality and noise present significant challenges.
Graph Neural Networks (GNNs) offer a robust framework for analyzing large-scale
signaling pathways and protein-protein interaction networks, yet they face
limitations in expressivity when capturing intricate biological relationships.
To address this, we propose Graph Sequence Language Model (GraphSeqLM), a
framework that enhances GNNs with biological sequence embeddings generated by
Large Language Models (LLMs). These embeddings encode structural and biological
properties of DNA, RNA, and proteins, augmenting GNNs with enriched features
for analyzing sample-specific multi-omic data. By integrating topological,
sequence-derived, and biological information, GraphSeqLM demonstrates superior
predictive accuracy and outperforms existing methods, paving the way for more
effective multi-omic data integration in precision medicine.

æè¦ï¼æ´åå¤çµå­¸è³æå°æ¼çè§£è¤éç¾çè³ééè¦ï¼ä½å¶é«ç¶­åº¦åéè¨æé æé¡¯èçææ°ãåç¥ç¶ç¶²è·¯ (GNN) æä¾äºä¸åå¼·å¥çæ¶æ§ï¼ç¨æ¼åæå¤§è¦æ¨¡ä¿¡èè·¯å¾åèç½è³ª-èç½è³ªäº¤äºç¶²è·¯ï¼ç¶èå®åå¨ææè¤éççç©éä¿æï¼å¨è¡¨ç¾åæ¹é¢é¢è¨éå¶ãçºäºè§£æ±ºéååé¡ï¼æåæåºäºååºåèªè¨æ¨¡å (GraphSeqLM)ï¼ä¸åå¢å¼· GNN çæ¶æ§ï¼ééå¤§åèªè¨æ¨¡å (LLM) çæççç©åºååµå¥ãéäºåµå¥ç·¨ç¢¼äº DNAãRNA åèç½è³ªççµæ§åçç©ç¹æ§ï¼ééè±å¯çç¹æ§æ´å GNNï¼ç¨æ¼åæç¹å®æ¨£æ¬çå¤çµå­¸è³æãééæ´åææ²ãåºåè¡çåçç©è³è¨ï¼GraphSeqLM å±ç¾äºåªè¶çé æ¸¬æºç¢ºåº¦ï¼ä¸¦åªæ¼ç¾ææ¹æ³ï¼çºç²¾æºé«çä¸­æ´ææçå¤çµå­¸è³ææ´åéªè·¯ã

##### **KRAIL: A Knowledge-Driven Framework for Base Human Reliability Analysis Integrating IDHEAS and Large Language Models**
2412.18627v1 by Xingyu Xiao, Peng Chen, Ben Qi, Hongru Zhao, Jingang Liang, Jiejuan Tong, Haitao Wang

Human reliability analysis (HRA) is crucial for evaluating and improving the
safety of complex systems. Recent efforts have focused on estimating human
error probability (HEP), but existing methods often rely heavily on expert
knowledge,which can be subjective and time-consuming. Inspired by the success
of large language models (LLMs) in natural language processing, this paper
introduces a novel two-stage framework for knowledge-driven reliability
analysis, integrating IDHEAS and LLMs (KRAIL). This innovative framework
enables the semi-automated computation of base HEP values. Additionally,
knowledge graphs are utilized as a form of retrieval-augmented generation (RAG)
for enhancing the framework' s capability to retrieve and process relevant data
efficiently. Experiments are systematically conducted and evaluated on
authoritative datasets of human reliability. The experimental results of the
proposed methodology demonstrate its superior performance on base HEP
estimation under partial information for reliability assessment.

æè¦ï¼äººé¡å¯é åº¦åæ (HRA) å°æ¼è©ä¼°åæåè¤éç³»çµ±çå®å¨æ§è³ééè¦ãæè¿çåªåå°æ³¨æ¼ä¼°è¨äººçºé¯èª¤æ©ç (HEP)ï¼ä½ç¾ææ¹æ³éå¸¸é«åº¦ä¾è³´å°å®¶ç¥è­ï¼èéå¯è½æå¸¶æä¸»è§æ§ä¸èæãåå°å¤§åèªè¨æ¨¡å (LLM) å¨èªç¶èªè¨èçä¸­æåçåç¼ï¼æ¬æä»ç´¹äºä¸åæ°ç©çå©éæ®µæ¶æ§ï¼ç¨æ¼ç¥è­é©åçå¯é åº¦åæï¼æ´å IDHEAS å LLM (KRAIL)ãéååµæ°çæ¶æ§è½åèªååè¨ç®åºæ¬ HEP å¼ãæ­¤å¤ï¼ç¥è­åè­è¢«ç¨ä½æª¢ç´¢å¢å¼·çæ (RAG) çä¸ç¨®å½¢å¼ï¼ç¨æ¼å¢å¼·æ¶æ§ææçå°æª¢ç´¢åèçç¸éè³æçè½åãç³»çµ±æ§å°éå°äººé¡å¯é åº¦çæ¬å¨è³æéé²è¡å¯¦é©ä¸¦è©ä¼°ãææåºçæ¹æ³çå¯¦é©çµæè­æäºå¶å¨é¨åè³è¨ä¸é²è¡å¯é åº¦è©ä¼°æï¼å¨åºæ¬ HEP ä¼°è¨ä¸çåªç°æè½ã

##### **NGQA: A Nutritional Graph Question Answering Benchmark for Personalized Health-aware Nutritional Reasoning**
2412.15547v1 by Zheyuan Zhang, Yiyang Li, Nhi Ha Lan Le, Zehong Wang, Tianyi Ma, Vincent Galassi, Keerthiram Murugesan, Nuno Moniz, Werner Geyer, Nitesh V Chawla, Chuxu Zhang, Yanfang Ye

Diet plays a critical role in human health, yet tailoring dietary reasoning
to individual health conditions remains a major challenge. Nutrition Question
Answering (QA) has emerged as a popular method for addressing this problem.
However, current research faces two critical limitations. On one hand, the
absence of datasets involving user-specific medical information severely limits
\textit{personalization}. This challenge is further compounded by the wide
variability in individual health needs. On the other hand, while large language
models (LLMs), a popular solution for this task, demonstrate strong reasoning
abilities, they struggle with the domain-specific complexities of personalized
healthy dietary reasoning, and existing benchmarks fail to capture these
challenges. To address these gaps, we introduce the Nutritional Graph Question
Answering (NGQA) benchmark, the first graph question answering dataset designed
for personalized nutritional health reasoning. NGQA leverages data from the
National Health and Nutrition Examination Survey (NHANES) and the Food and
Nutrient Database for Dietary Studies (FNDDS) to evaluate whether a food is
healthy for a specific user, supported by explanations of the key contributing
nutrients. The benchmark incorporates three question complexity settings and
evaluates reasoning across three downstream tasks. Extensive experiments with
LLM backbones and baseline models demonstrate that the NGQA benchmark
effectively challenges existing models. In sum, NGQA addresses a critical
real-world problem while advancing GraphQA research with a novel
domain-specific benchmark.

æè¦ï¼é£²é£å¨äººé¡å¥åº·ä¸­æ®æ¼èè³ééè¦çè§è²ï¼ç¶èæ ¹æåäººå¥åº·çæ³èª¿æ´é£²é£æ¨çä»ç¶æ¯ä¸é éå¤§çææ°ãçé¤åé¡åç­ (QA) å·²æçºè§£æ±ºæ­¤åé¡çæµè¡æ¹æ³ãä¸éï¼ç®åçç ç©¶é¢è¨å©é éå¤§çéå¶ãä¸æ¹é¢ï¼ç¼ºä¹åå«ä½¿ç¨èç¹å®é«çè³è¨çè³æéå´ééå¶äºãåäººåããéåææ°é²ä¸æ­¥åå°åäººå¥åº·éæ±å»£æ³è®ç°çå½±é¿ãå¦ä¸æ¹é¢ï¼éç¶å¤§åèªè¨æ¨¡å (LLM) æ¯æ­¤ä»»åçç±éè§£æ±ºæ¹æ¡ï¼å±ç¤ºåºå¼·å¤§çæ¨çè½åï¼ä½å®åå¨åäººåå¥åº·é£²é£æ¨ççç¹å®é åè¤éæ§ä¸ä»æå°é£ï¼èç¾æçåºæºä¹ç¡æ³ææéäºææ°ãçºäºè§£æ±ºéäºå·®è·ï¼æåå¼å¥äºçé¤åè¡¨åç­ (NGQA) åºæºï¼éæ¯ç¬¬ä¸åå°çºåäººåçé¤å¥åº·æ¨çè¨­è¨çåè¡¨åç­è³æéãNGQA å©ç¨åå®¶å¥åº·èçé¤æª¢æ¥èª¿æ¥ (NHANES) åé£²é£ç ç©¶é£ç©èçé¤è³æåº« (FNDDS) çè³æï¼è©ä¼°é£ç©æ¯å¦å°ç¹å®ä½¿ç¨èå¥åº·ï¼ä¸¦èªªæä¸»è¦è²¢ç»çé¤ç´ ãæ­¤åºæºç´å¥äºä¸ååé¡è¤éåº¦è¨­å®ï¼ä¸¦è©ä¼°ä¸åä¸æ¸¸ä»»åçæ¨çãä½¿ç¨ LLM ä¸»å¹¹ååºç·æ¨¡åé²è¡çå»£æ³å¯¦é©è­æï¼NGQA åºæºææææ°äºç¾ææ¨¡åãç¸½ä¹ï¼NGQA è§£æ±ºäºä¸åéå¤§çç¾å¯¦ä¸çåé¡ï¼åæééæ°ç©çç¹å®é ååºæºæ¨åäº GraphQA ç ç©¶ã

##### **SKETCH: Structured Knowledge Enhanced Text Comprehension for Holistic Retrieval**
2412.15443v1 by Aakash Mahalingam, Vinesh Kumar Gande, Aman Chadha, Vinija Jain, Divya Chaudhary

Retrieval-Augmented Generation (RAG) systems have become pivotal in
leveraging vast corpora to generate informed and contextually relevant
responses, notably reducing hallucinations in Large Language Models. Despite
significant advancements, these systems struggle to efficiently process and
retrieve information from large datasets while maintaining a comprehensive
understanding of the context. This paper introduces SKETCH, a novel methodology
that enhances the RAG retrieval process by integrating semantic text retrieval
with knowledge graphs, thereby merging structured and unstructured data for a
more holistic comprehension. SKETCH, demonstrates substantial improvements in
retrieval performance and maintains superior context integrity compared to
traditional methods. Evaluated across four diverse datasets: QuALITY, QASPER,
NarrativeQA, and Italian Cuisine-SKETCH consistently outperforms baseline
approaches on key RAGAS metrics such as answer_relevancy, faithfulness,
context_precision and context_recall. Notably, on the Italian Cuisine dataset,
SKETCH achieved an answer relevancy of 0.94 and a context precision of 0.99,
representing the highest performance across all evaluated metrics. These
results highlight SKETCH's capability in delivering more accurate and
contextually relevant responses, setting new benchmarks for future retrieval
systems.

æè¦ï¼æ·åå¢å¼·çæ (RAG) ç³»çµ±å·²æçºå©ç¨é¾å¤§èªæåº«ä¾ç¢çææºä¸èæå¢ç¸éåæçééµï¼ç¹å¥æ¯æ¸å°å¤§åèªè¨æ¨¡åä¸­çå¹»è¦ºãåç®¡æé¡¯èçé²å±ï¼ä½éäºç³»çµ±å¨èçåæ·åä¾èªå¤§åè³æéçè³è¨æä»æå°é£ï¼åæéè¦ç¶­æå°æå¢çå¨é¢çè§£ãæ¬æä»ç´¹ SKETCHï¼ä¸ç¨®ééå°èªææå­æ·åèç¥è­åè¡¨æ´åï¼èæ­¤åä½µçµæ§ååéçµæ§åè³æä»¥ç²å¾æ´å¨é¢ççè§£ï¼ä¾å¢å¼· RAG æ·åç¨åºçåµæ°æ¹æ³ãSKETCH å¨æ·åæè½æ¹é¢å±ç¾åºé¡¯èçé²æ­¥ï¼ä¸¦èå³çµ±æ¹æ³ç¸æ¯ç¶­æè¼ä½³çæå¢å®æ´æ§ãå¨ååä¸åçè³æéï¼QuALITYãQASPERãNarrativeQA å Italian Cuisine ä¸­é²è¡è©ä¼°ï¼SKETCH å¨ééµç RAGAS ææ¨ï¼ä¾å¦ answer_relevancyãfaithfulnessãcontext_precision å context_recallï¼ä¸å§çµåªæ¼åºæºæ¹æ³ãå¼å¾æ³¨æçæ¯ï¼å¨ Italian Cuisine è³æéä¸ï¼SKETCH ç answer relevancy éå° 0.94ï¼context precision éå° 0.99ï¼ä»£è¡¨å¨ææè©ä¼°ææ¨ä¸­è¡¨ç¾æä½³ãéäºçµæçªé¡¯äº SKETCH å¨æä¾æ´æºç¢ºä¸èæå¢ç¸éåæçè½åï¼çºæªä¾çæ·åç³»çµ±æ¨¹ç«äºæ°çåºæºã

##### **Graph-Convolutional Networks: Named Entity Recognition and Large Language Model Embedding in Document Clustering**
2412.14867v1 by Imed Keraghel, Mohamed Nadif

Recent advances in machine learning, particularly Large Language Models
(LLMs) such as BERT and GPT, provide rich contextual embeddings that improve
text representation. However, current document clustering approaches often
ignore the deeper relationships between named entities (NEs) and the potential
of LLM embeddings. This paper proposes a novel approach that integrates Named
Entity Recognition (NER) and LLM embeddings within a graph-based framework for
document clustering. The method builds a graph with nodes representing
documents and edges weighted by named entity similarity, optimized using a
graph-convolutional network (GCN). This ensures a more effective grouping of
semantically related documents. Experimental results indicate that our approach
outperforms conventional co-occurrence-based methods in clustering, notably for
documents rich in named entities.

æè¦ï¼è¿ææ©å¨å­¸ç¿çé²å±ï¼ç¹å¥æ¯å¤§åèªè¨æ¨¡å (LLM)ï¼ä¾å¦ BERT å GPTï¼æä¾äºè±å¯çä¸ä¸æåµå¥ï¼æ¹é²äºææ¬è¡¨å¾µãç¶èï¼ç¶åçæä»¶åç¾¤æ¹æ³éå¸¸å¿½ç¥å½åå¯¦é« (NE) ä¹éæ´æ·±å±¤çéä¿å LLM åµå¥çæ½åãæ¬ææåºäºä¸ç¨®åµæ°çæ¹æ³ï¼å°å½åå¯¦é«è¾¨è­ (NER) å LLM åµå¥æ´åå°åºæ¼åå½¢çæ¶æ§ä¸­ï¼ä»¥é²è¡æä»¶åç¾¤ãè©²æ¹æ³å»ºç«äºä¸ååå½¢ï¼å¶ä¸­ç¯é»ä»£è¡¨æä»¶ï¼éç·£åç±å½åå¯¦é«ç¸ä¼¼æ§å æ¬ï¼ä¸¦ä½¿ç¨åå½¢å·ç©ç¶²è·¯ (GCN) é²è¡æä½³åãéç¢ºä¿äºèªç¾©ç¸éæä»¶æ´ææçåçµãå¯¦é©çµæè¡¨æï¼æåçåæ³åªæ¼å³çµ±çå±ç¾æ¹æ³å¨åç¾¤ä¸­çè¡¨ç¾ï¼ç¹å¥æ¯å°æ¼å¯å«å½åå¯¦é«çæä»¶ã

##### **Answer Set Networks: Casting Answer Set Programming into Deep Learning**
2412.14814v1 by Arseny Skryagin, Daniel Ochs, Phillip Deibert, Simon Kohaut, Devendra Singh Dhami, Kristian Kersting

Although Answer Set Programming (ASP) allows constraining neural-symbolic
(NeSy) systems, its employment is hindered by the prohibitive costs of
computing stable models and the CPU-bound nature of state-of-the-art solvers.
To this end, we propose Answer Set Networks (ASN), a NeSy solver. Based on
Graph Neural Networks (GNN), ASNs are a scalable approach to ASP-based Deep
Probabilistic Logic Programming (DPPL). Specifically, we show how to translate
ASPs into ASNs and demonstrate how ASNs can efficiently solve the encoded
problem by leveraging GPU's batching and parallelization capabilities. Our
experimental evaluations demonstrate that ASNs outperform state-of-the-art
CPU-bound NeSy systems on multiple tasks. Simultaneously, we make the following
two contributions based on the strengths of ASNs. Namely, we are the first to
show the finetuning of Large Language Models (LLM) with DPPLs, employing ASNs
to guide the training with logic. Further, we show the "constitutional
navigation" of drones, i.e., encoding public aviation laws in an ASN for
routing Unmanned Aerial Vehicles in uncertain environments.

æè¦ï¼åç®¡ç­æ¡éç¨å¼è¨­è¨ï¼ASPï¼åè¨±ç´æç¥ç¶ç¬¦èï¼NeSyï¼ç³»çµ±ï¼ä½å¶æç¨åå°è¨ç®ç©©å®æ¨¡åçéé«ææ¬åç¾ææ±è§£å¨å CPU éå¶çæ¬è³ªæé»ç¤ãçºæ­¤ï¼æåæåºç­æ¡éç¶²è·¯ï¼ASNï¼ï¼ä¸å NeSy æ±è§£å¨ãASN åºæ¼åç¥ç¶ç¶²è·¯ï¼GNNï¼ï¼æ¯ä¸ç¨®åºæ¼ ASP çæ·±åº¦æ©çéè¼¯ç¨å¼è¨­è¨ï¼DPPLï¼çå¯æ´åæ¹æ³ãå·é«ä¾èªªï¼æåå±ç¤ºå¦ä½å° ASP è½æçº ASNï¼ä¸¦å±ç¤º ASN å¦ä½ééå©ç¨ GPU çæ¹æ¬¡èçåä¸¦è¡ååè½ææå°è§£æ±ºç·¨ç¢¼åé¡ãæåçå¯¦é©è©ä¼°è¡¨æï¼ASN å¨å¤é ä»»åä¸åªæ¼ç¾æçå CPU éå¶ç NeSy ç³»çµ±ãåæï¼æåæ ¹æ ASN çåªå¢ååºäºä»¥ä¸å©é è²¢ç»ãä¹å°±æ¯èªªï¼æåé¦æ¬¡å±ç¤ºä½¿ç¨ DPPL å°å¤§åèªè¨æ¨¡åï¼LLMï¼é²è¡å¾®èª¿ï¼ä½¿ç¨ ASN ä»¥éè¼¯å¼å°è¨ç·´ãæ­¤å¤ï¼æåå±ç¤ºäºç¡äººæ©çãæ²æ³å°èªãï¼å³å¨ ASN ä¸­ç·¨ç¢¼å¬å±èªç©ºæ³ï¼ä»¥ä¾¿å¨ä¸ç¢ºå®çç°å¢ä¸­å°ç¡äººæ©é²è¡è·¯ç±ã

##### **IOHunter: Graph Foundation Model to Uncover Online Information Operations**
2412.14663v1 by Marco Minici, Luca Luceri, Francesco Fabbri, Emilio Ferrara

Social media platforms have become vital spaces for public discourse, serving
as modern agor\'as where a wide range of voices influence societal narratives.
However, their open nature also makes them vulnerable to exploitation by
malicious actors, including state-sponsored entities, who can conduct
information operations (IOs) to manipulate public opinion. The spread of
misinformation, false news, and misleading claims threatens democratic
processes and societal cohesion, making it crucial to develop methods for the
timely detection of inauthentic activity to protect the integrity of online
discourse. In this work, we introduce a methodology designed to identify users
orchestrating information operations, a.k.a. \textit{IO drivers}, across
various influence campaigns. Our framework, named \texttt{IOHunter}, leverages
the combined strengths of Language Models and Graph Neural Networks to improve
generalization in \emph{supervised}, \emph{scarcely-supervised}, and
\emph{cross-IO} contexts. Our approach achieves state-of-the-art performance
across multiple sets of IOs originating from six countries, significantly
surpassing existing approaches. This research marks a step toward developing
Graph Foundation Models specifically tailored for the task of IO detection on
social media platforms.

æè¦ï¼ç¤¾äº¤åªé«å¹³å°å·²æçºå¬å±è«è¿°çéè¦ç©ºéï¼ä½çºç¾ä»£å»£å ´ï¼åç¨®è²é³å½±é¿èç¤¾ææäºãç¶èï¼å®åçéæ¾æ§ä¹ä½¿å¾å®åå®¹æåå°æ¡æè¡çºèçå©ç¨ï¼åæ¬åå®¶è³å©çå¯¦é«ï¼ä»åå¯ä»¥é²è¡ä¿¡æ¯æä½ (IO) ä»¥æç¸±è¼¿è«ãé¯èª¤ä¿¡æ¯çå³æ­ãèåæ°èåèª¤å°æ§èªªæ³å¨èèæ°ä¸»é²ç¨åç¤¾æåèåï¼å æ­¤å¶å®åææª¢æ¸¬èåæ´»åä»¥ä¿è­·å¨ç·è«è¿°çå®æ´æ§çæ¹æ³è³ééè¦ãå¨éé å·¥ä½ä¸­ï¼æåä»ç´¹äºä¸ç¨®æ¹æ³ï¼æ¨å¨è­å¥å¨åç¨®å½±é¿åéåä¸­ç­åä¿¡æ¯è¡åçç¨æ¶ï¼å³æè¬çãIO é©åç¨åºããæåçæ¡æ¶åçº \texttt{IOHunter}ï¼å®å©ç¨èªè¨æ¨¡åååç¥ç¶ç¶²è·¯çç¶ååªå¢ä¾æ¹åãç£ç£ãããç¨çç£ç£ãåãè·¨ IOãæå¢ä¸­çæ³åè½åãæåçåæ³å¨ä¾èªå­ååå®¶çå¤çµ IO ä¸­å¯¦ç¾äºæåé²çæ§è½ï¼é¡¯èè¶è¶äºç¾ææ¹æ³ãéé ç ç©¶æ¨èªèå°ééå°ç¤¾äº¤åªé«å¹³å°ä¸ç IO æª¢æ¸¬ä»»åéç¼ååºç¤æ¨¡åéåºäºä¸æ­¥ã

##### **GraphEQA: Using 3D Semantic Scene Graphs for Real-time Embodied Question Answering**
2412.14480v1 by Saumya Saxena, Blake Buchanan, Chris Paxton, Bingqing Chen, Narunas Vaskevicius, Luigi Palmieri, Jonathan Francis, Oliver Kroemer

In Embodied Question Answering (EQA), agents must explore and develop a
semantic understanding of an unseen environment in order to answer a situated
question with confidence. This remains a challenging problem in robotics, due
to the difficulties in obtaining useful semantic representations, updating
these representations online, and leveraging prior world knowledge for
efficient exploration and planning. Aiming to address these limitations, we
propose GraphEQA, a novel approach that utilizes real-time 3D metric-semantic
scene graphs (3DSGs) and task relevant images as multi-modal memory for
grounding Vision-Language Models (VLMs) to perform EQA tasks in unseen
environments. We employ a hierarchical planning approach that exploits the
hierarchical nature of 3DSGs for structured planning and semantic-guided
exploration. Through experiments in simulation on the HM-EQA dataset and in the
real world in home and office environments, we demonstrate that our method
outperforms key baselines by completing EQA tasks with higher success rates and
fewer planning steps.

æè¦ï¼å¨å·èº«åç­ (EQA) ä¸­ï¼ä»£çå¿é æ¢ç´¢ä¸¦ç¼å±å°æªè¦éç°å¢çèªç¾©çè§£ï¼æè½æä¿¡å¿å°åç­æå¢åé¡ãç±æ¼é£ä»¥åå¾æç¨çèªç¾©è¡¨ç¤ºãç·ä¸æ´æ°éäºè¡¨ç¤ºï¼ä»¥åå©ç¨ååçä¸çç¥è­é²è¡ææççæ¢ç´¢åè¦åï¼éå¨æ©å¨äººå­¸ä¸­ä»ç¶æ¯ä¸åå·æææ°æ§çåé¡ãçºäºè§£æ±ºéäºéå¶ï¼æåæåº GraphEQAï¼ä¸ç¨®å©ç¨å³æ 3D åº¦éèªç¾©å ´æ¯å (3DSG) åèä»»åç¸éçå½±åä½çºå¤æ¨¡å¼è¨æ¶é«çæ°ç©æ¹æ³ï¼ä»¥æ¥å°è¦è¦ºèªè¨æ¨¡å (VLM) ä¾å·è¡æªè¦éç°å¢ä¸­ç EQA ä»»åãæåæ¡ç¨åå±¤è¦åæ¹æ³ï¼å©ç¨ 3DSG çåå±¤æ§è³ªé²è¡çµæ§åè¦ååèªç¾©å¼å°æ¢ç´¢ãééå¨ HM-EQA è³æéä¸çæ¨¡æ¬å¯¦é©ï¼ä»¥åå¨å®¶åº­åè¾¦å¬å®¤ç°å¢ä¸­ççå¯¦ä¸çä¸­ï¼æåè­ææåçæ¨¡åééä»¥è¼é«çæåçåè¼å°çè¦åæ­¥é©å®æ EQA ä»»åï¼åªæ¼ä¸»è¦çåºç·ã

##### **Discovering maximally consistent distribution of causal tournaments with Large Language Models**
2412.14019v1 by Federico Baldo, Simon Ferreira, Charles K. Assaad

Causal discovery is essential for understanding complex systems, yet
traditional methods often depend on strong, untestable assumptions, making the
process challenging. Large Language Models (LLMs) present a promising
alternative for extracting causal insights from text-based metadata, which
consolidates domain expertise. However, LLMs are prone to unreliability and
hallucinations, necessitating strategies that account for their limitations.
One such strategy involves leveraging a consistency measure to evaluate
reliability. Additionally, most text metadata does not clearly distinguish
direct causal relationships from indirect ones, further complicating the
inference of causal graphs. As a result, focusing on causal orderings, rather
than causal graphs, emerges as a more practical and robust approach. We propose
a novel method to derive a distribution of acyclic tournaments (representing
plausible causal orders) that maximizes a consistency score. Our approach
begins by computing pairwise consistency scores between variables, yielding a
cyclic tournament that aggregates these scores. From this structure, we
identify optimal acyclic tournaments compatible with the original tournament,
prioritizing those that maximize consistency across all configurations. We
tested our method on both classical and well-established bechmarks, as well as
real-world datasets from epidemiology and public health. Our results
demonstrate the effectiveness of our approach in recovering distributions
causal orders with minimal error.

æè¦ï¼å æç¼ç¾å°æ¼çè§£è¤éç³»çµ±è³ééè¦ï¼ä½å³çµ±æ¹æ³éå¸¸ä¾è³´æ¼å¼·èä¸å¯æ¸¬è©¦çåè¨­ï¼éä½¿å¾éåéç¨åæ»¿ææ°ãå¤§åèªè¨æ¨¡å (LLM) æä¾äºä¸åå¾åºæ¼ææ¬çåæ¸æä¸­æåå æè¦è§£çæå¸æçæ¿ä»£æ¹æ¡ï¼å®æ´åäºé åå°æ¥­ç¥è­ãç¶èï¼LLM å®¹æåºç¾ä¸å¯é æ§åå¹»è¦ºï¼ééè¦èæ®å¶éå¶çç­ç¥ãä¸ç¨®éæ¨£çç­ç¥æ¶åå©ç¨ä¸è´æ§åº¦éä¾è©ä¼°å¯é æ§ãæ­¤å¤ï¼å¤§å¤æ¸ææ¬åæ¸æä¸¦æªæ¸æ¥å°ååç´æ¥å æéä¿åéæ¥å æéä¿ï¼éé²ä¸æ­¥è¤éåäºå æåçæ¨è«ãå æ­¤ï¼å°æ³¨æ¼å æé åºï¼èä¸æ¯å æåï¼æçºä¸ç¨®æ´å¯¦ç¨ãæ´ç©©å¥çæ¹æ³ãæåæåºäºä¸ç¨®æ°æ¹æ³ä¾æ¨å°ç¡ç°é¦æ¨è³½çåå¸ï¼è¡¨ç¤ºåççå æé åºï¼ï¼éæå¤§åäºä¸è´æ§åæ¸ãæåçåæ³é¦åè¨ç®è®éä¹éæå°çä¸è´æ§åæ¸ï¼ç¢çä¸åå½ç¸½éäºåæ¸çå¾ªç°é¦æ¨è³½ãå¾éåçµæ§ä¸­ï¼æåè­å¥åºèåå§é¦æ¨è³½ç¸å®¹çæä½³ç¡ç°é¦æ¨è³½ï¼åªåèæ®é£äºå¨ææéç½®ä¸­æå¤§åä¸è´æ§çé¦æ¨è³½ãæåå¨ç¶å¸ä¸å®åçåºæºä»¥åä¾èªæµè¡çå­¸åå¬å±è¡çççå¯¦ä¸çæ¸æéä¸æ¸¬è©¦äºæåçæ¨¡åãæåççµæè­æäºæåçæ¹æ³å¨ä»¥æå°èª¤å·®æ¢å¾©å æé åºåå¸æ¹é¢çæææ§ã

##### **DODGE: Ontology-Aware Risk Assessment via Object-Oriented Disruption Graphs**
2412.13964v1 by Stefano M. Nicoletti, E. Moritz Hahn, Mattia Fumagalli, Giancarlo Guizzardi, MariÃ«lle Stoelinga

When considering risky events or actions, we must not downplay the role of
involved objects: a charged battery in our phone averts the risk of being
stranded in the desert after a flat tyre, and a functional firewall mitigates
the risk of a hacker intruding the network. The Common Ontology of Value and
Risk (COVER) highlights how the role of objects and their relationships remains
pivotal to performing transparent, complete and accountable risk assessment. In
this paper, we operationalize some of the notions proposed by COVER -- such as
parthood between objects and participation of objects in events/actions -- by
presenting a new framework for risk assessment: DODGE. DODGE enriches the
expressivity of vetted formal models for risk -- i.e., fault trees and attack
trees -- by bridging the disciplines of ontology and formal methods into an
ontology-aware formal framework composed by a more expressive modelling
formalism, Object-Oriented Disruption Graphs (ODGs), logic (ODGLog) and an
intermediate query language (ODGLang). With these, DODGE allows risk assessors
to pose questions about disruption propagation, disruption likelihood and risk
levels, keeping the fundamental role of objects at risk always in sight.

æè¦ï¼å¨èéé«é¢¨éªäºä»¶æè¡åæï¼æåä¸è½ä½ä¼°ææ¶ç©ä»¶çè§è²ï¼ææ©ä¸­çåé»é»æ± å¯é¿åå¨çèå¾åå°æ²æ¼ çé¢¨éªï¼èåè½æ­£å¸¸çé²ç«çåå¯éä½é§­å®¢å¥ä¾µç¶²è·¯çé¢¨éªãå¹å¼èé¢¨éªçå±ç¨æ¬ä½è« (COVER) å¼·èª¿ç©ä»¶åå¶éä¿çè§è²ï¼å°æ¼å·è¡éæãå®æ´ä¸è² è²¬ä»»çé¢¨éªè©ä¼°ä»ç¶è³ééè¦ãå¨æ¬æä¸­ï¼æåå° COVER ææåºçé¨åæ¦å¿µï¼ä¾å¦ç©ä»¶ä¹éççµæé¨åéä¿ï¼ä»¥åç©ä»¶åèäºä»¶/è¡åï¼å·é«åï¼èç±æåºä¸åæ°çé¢¨éªè©ä¼°æ¶æ§ï¼DODGEãDODGE ééå°æ¬ä½è«èå½¢å¼åæ¹æ³æ©æ¥è³ä¸åæ¬ä½è«æç¥å½¢å¼åæ¶æ§ä¸­ï¼è±å¯äºé¢¨éªé©è­å½¢å¼åæ¨¡åï¼ä¾å¦æéæ¨¹åæ»ææ¨¹ï¼çè¡¨éåï¼è©²æ¶æ§ç±æ´å·è¡¨éåçå»ºæ¨¡å½¢å¼ä¸»ç¾©ãç©ä»¶å°åä¸­æ·å (ODG)ãéè¼¯ (ODGLog) åä¸åä¸­éæ¥è©¢èªè¨ (ODGLang) çµæãéééäºï¼DODGE è®é¢¨éªè©ä¼°èè½å¤ æåºæéä¸­æ·å³æ­ãä¸­æ·å¯è½æ§åé¢¨éªå±¤ç´çåé¡ï¼åæå§çµä¿æå°é¢¨éªç©ä»¶çåºæ¬è§è²çéæ³¨ã

##### **Knowledge Editing with Dynamic Knowledge Graphs for Multi-Hop Question Answering**
2412.13782v2 by Yifan Lu, Yigeng Zhou, Jing Li, Yequan Wang, Xuebo Liu, Daojing He, Fangming Liu, Min Zhang

Multi-hop question answering (MHQA) poses a significant challenge for large
language models (LLMs) due to the extensive knowledge demands involved.
Knowledge editing, which aims to precisely modify the LLMs to incorporate
specific knowledge without negatively impacting other unrelated knowledge,
offers a potential solution for addressing MHQA challenges with LLMs. However,
current solutions struggle to effectively resolve issues of knowledge
conflicts. Most parameter-preserving editing methods are hindered by inaccurate
retrieval and overlook secondary editing issues, which can introduce noise into
the reasoning process of LLMs. In this paper, we introduce KEDKG, a novel
knowledge editing method that leverages a dynamic knowledge graph for MHQA,
designed to ensure the reliability of answers. KEDKG involves two primary
steps: dynamic knowledge graph construction and knowledge graph augmented
generation. Initially, KEDKG autonomously constructs a dynamic knowledge graph
to store revised information while resolving potential knowledge conflicts.
Subsequently, it employs a fine-grained retrieval strategy coupled with an
entity and relation detector to enhance the accuracy of graph retrieval for LLM
generation. Experimental results on benchmarks show that KEDKG surpasses
previous state-of-the-art models, delivering more accurate and reliable answers
in environments with dynamic information.

æè¦ï¼å¤è·³åç­ (MHQA) ç±æ¼æ¶åå»£æ³çç¥è­éæ±ï¼å æ­¤å°å¤§åèªè¨æ¨¡å (LLM) æ§æéå¤§ææ°ãç¥è­ç·¨è¼¯æ¨å¨ç²¾ç¢ºä¿®æ¹ LLM ä»¥ç´å¥ç¹å®ç¥è­ï¼åæä¸å°å¶ä»ç¡éç¥è­ç¢çè² é¢å½±é¿ï¼çºäºè§£æ±º LLM ä¸­ç MHQA ææ°æä¾äºæ½å¨è§£æ±ºæ¹æ¡ãç¶èï¼ç¶åçè§£æ±ºæ¹æ¡é£ä»¥ææè§£æ±ºç¥è­è¡çªåé¡ãå¤§å¤æ¸ä¿çåæ¸çç·¨è¼¯æ¹æ³åå°ä¸æºç¢ºæª¢ç´¢çé»ç¤ï¼ä¸¦ä¸å¿½è¦äºæ¬¡è¦ç·¨è¼¯åé¡ï¼éå¯è½æå¨ LLM çæ¨çéç¨ä¸­å¼å¥éè¨ãå¨æ¬æä¸­ï¼æåä»ç´¹äº KEDKGï¼éæ¯ä¸ç¨®æ°ç©çç¥è­ç·¨è¼¯æ¹æ³ï¼å®å©ç¨åæç¥è­åè­é²è¡ MHQAï¼æ¨å¨ç¢ºä¿ç­æ¡çå¯é æ§ãKEDKG æ¶åå©åä¸»è¦æ­¥é©ï¼åæç¥è­åè­æ§å»ºåç¥è­åè­å¢å¼·çæãæåï¼KEDKG èªä¸»æ§å»ºä¸ååæç¥è­åè­ä¾å²å­ä¿®æ¹å¾çè³è¨ï¼åæè§£æ±ºæ½å¨çç¥è­è¡çªãé¨å¾ï¼å®æ¡ç¨ç´°ç²åº¦çæª¢ç´¢ç­ç¥ï¼çµåå¯¦é«åéä¿æª¢æ¸¬å¨ï¼ä»¥æé« LLM çæçåè­æª¢ç´¢æºç¢ºåº¦ãåºæºä¸çå¯¦é©çµæè¡¨æï¼KEDKG è¶è¶äºååçæåé²æ¨¡åï¼å¨å·æåæè³è¨çç°å¢ä¸­æä¾äºæ´æºç¢ºåå¯é çç­æ¡ã

##### **Bridging the User-side Knowledge Gap in Knowledge-aware Recommendations with Large Language Models**
2412.13544v1 by Zheng Hu, Zhe Li, Ziyun Jiao, Satoshi Nakagawa, Jiawen Deng, Shimin Cai, Tao Zhou, Fuji Ren

In recent years, knowledge graphs have been integrated into recommender
systems as item-side auxiliary information, enhancing recommendation accuracy.
However, constructing and integrating structural user-side knowledge remains a
significant challenge due to the improper granularity and inherent scarcity of
user-side features. Recent advancements in Large Language Models (LLMs) offer
the potential to bridge this gap by leveraging their human behavior
understanding and extensive real-world knowledge. Nevertheless, integrating
LLM-generated information into recommender systems presents challenges,
including the risk of noisy information and the need for additional knowledge
transfer. In this paper, we propose an LLM-based user-side knowledge inference
method alongside a carefully designed recommendation framework to address these
challenges. Our approach employs LLMs to infer user interests based on
historical behaviors, integrating this user-side information with item-side and
collaborative data to construct a hybrid structure: the Collaborative Interest
Knowledge Graph (CIKG). Furthermore, we propose a CIKG-based recommendation
framework that includes a user interest reconstruction module and a
cross-domain contrastive learning module to mitigate potential noise and
facilitate knowledge transfer. We conduct extensive experiments on three
real-world datasets to validate the effectiveness of our method. Our approach
achieves state-of-the-art performance compared to competitive baselines,
particularly for users with sparse interactions.

æè¦ï¼è¿å¹´ä¾ï¼ç¥è­åè­å·²æ´åå°æ¨è¦ç³»çµ±ä¸­ï¼ä½çºé ç®å´è¼å©è³è¨ï¼æåæ¨è¦æºç¢ºåº¦ã
ç¶èï¼ç±æ¼ä½¿ç¨èå´ç¹å¾µçç²åº¦ä¸ç¶åå§å¨ç¨å°æ§ï¼å»ºæ§åæ´åçµæ§åä½¿ç¨èå´ç¥è­ä»ç¶æ¯ä¸é éå¤§ææ°ã
å¤§åèªè¨æ¨¡å (LLM) çææ°é²å±æä¾äºå½åæ­¤å·®è·çæ½åï¼æ¹æ³æ¯å©ç¨å®åå°äººé¡è¡çºççè§£åå»£æ³ççå¯¦ä¸çç¥è­ã
åç®¡å¦æ­¤ï¼å° LLM çæçè³è¨æ´åå°æ¨è¦ç³»çµ±ä¸­æå¸¶ä¾ææ°ï¼åæ¬éè¨è³è¨çé¢¨éªåéè¦é¡å¤çç¥è­è½ç§»ã
å¨æ¬æä¸­ï¼æåæåºäºä¸ç¨®åºæ¼ LLM çä½¿ç¨èå´ç¥è­æ¨è«æ¹æ³ï¼ä»¥åä¸åç²¾å¿è¨­è¨çæ¨è¦æ¶æ§ï¼ä»¥æå°éäºææ°ã
æåçåæ³æ¡ç¨ LLM ä¾æ¨è«åºæ¼æ­·å²è¡çºçä½¿ç¨èèè¶£ï¼å°æ­¤ä½¿ç¨èå´è³è¨èé ç®å´ååä½è³ææ´åèµ·ä¾ï¼ä»¥å»ºæ§ä¸åæ··åçµæ§ï¼åä½èè¶£ç¥è­åè­ (CIKG)ã
æ­¤å¤ï¼æåæåºäºä¸ååºæ¼ CIKG çæ¨è¦æ¶æ§ï¼å¶ä¸­åæ¬ä½¿ç¨èèè¶£éå»ºæ¨¡çµåè·¨ç¶²åå°æ¯å­¸ç¿æ¨¡çµï¼ä»¥æ¸è¼æ½å¨éè¨ä¸¦ä¿é²ç¥è­è½ç§»ã
æåå°ä¸åçå¯¦ä¸çè³æéé²è¡äºå»£æ³çå¯¦é©ï¼ä»¥é©è­æåæ¹æ³çæææ§ã
èç«¶ç­åºæºç¸æ¯ï¼æåçåæ³éå°äºæåé²çæè½ï¼ç¹å¥æ¯å°æ¼äºåç¨ççä½¿ç¨èã

##### **Benchmarking and Improving Large Vision-Language Models for Fundamental Visual Graph Understanding and Reasoning**
2412.13540v1 by Yingjie Zhu, Xuefeng Bai, Kehai Chen, Yang Xiang, Min Zhang

Large Vision-Language Models (LVLMs) have demonstrated remarkable performance
across diverse tasks. Despite great success, recent studies show that LVLMs
encounter substantial limitations when engaging with visual graphs. To study
the reason behind these limitations, we propose VGCure, a comprehensive
benchmark covering 22 tasks for examining the fundamental graph understanding
and reasoning capacities of LVLMs. Extensive evaluations conducted on 14 LVLMs
reveal that LVLMs are weak in basic graph understanding and reasoning tasks,
particularly those concerning relational or structurally complex information.
Based on this observation, we propose a structure-aware fine-tuning framework
to enhance LVLMs with structure learning abilities through 3 self-supervised
learning tasks. Experiments validate the effectiveness of our method in
improving LVLMs' zero-shot performance on fundamental graph learning tasks, as
well as enhancing the robustness of LVLMs against complex visual graphs.

æè¦ï¼å¤§åè¦è¦ºèªè¨æ¨¡å (LVLMs) å·²å¨åç¨®ä»»åä¸­å±ç¾åºéå¡çè¡¨ç¾ãåç®¡ç²å¾å·¨å¤§çæåï¼æè¿çç ç©¶é¡¯ç¤ºï¼LVLMs å¨èçè¦è¦ºåå½¢ææéå°éå¤§çéå¶ãçºäºç ç©¶éäºéå¶èå¾çåå ï¼æåæåºäº VGCureï¼éæ¯ä¸åæ¶µè 22 é ä»»åçç¶ååºæºï¼ç¨æ¼æª¢æ¥ LVLMs çåºæ¬åå½¢çè§£åæ¨çè½åãå° 14 å LVLMs é²è¡çå»£æ³è©ä¼°é¡¯ç¤ºï¼LVLMs å¨åºæ¬çåå½¢çè§£åæ¨çä»»åä¸­è¼å¼±ï¼ç¹å¥æ¯é£äºæ¶åéä¿æçµæ§è¤éè³è¨çä»»åãåºæ¼æ­¤è§å¯ï¼æåæåºäºä¸åçµæ§æç¥å¾®èª¿æ¡æ¶ï¼ä»¥éé 3 åèªæç£ç£å­¸ç¿ä»»åä¾å¢å¼· LVLMs ççµæ§å­¸ç¿è½åãå¯¦é©é©è­äºæåçæ¹æ³å¨æå LVLMs å¨åºæ¬åå½¢å­¸ç¿ä»»åä¸çé¶æ¬¡å­¸ç¿è¡¨ç¾çæææ§ï¼ä»¥åå¢å¼· LVLMs å°è¤éè¦è¦ºåå½¢çé­¯æ£æ§ã

##### **Transducer Tuning: Efficient Model Adaptation for Software Tasks Using Code Property Graphs**
2412.13467v1 by Imam Nur Bani Yusuf, Lingxiao Jiang

Large language models have demonstrated promising performance across various
software engineering tasks. While fine-tuning is a common practice to adapt
these models for downstream tasks, it becomes challenging in
resource-constrained environments due to increased memory requirements from
growing trainable parameters in increasingly large language models. We
introduce \approach, a technique to adapt large models for downstream code
tasks using Code Property Graphs (CPGs). Our approach introduces a modular
component called \transducer that enriches code embeddings with structural and
dependency information from CPGs. The Transducer comprises two key components:
Graph Vectorization Engine (GVE) and Attention-Based Fusion Layer (ABFL). GVE
extracts CPGs from input source code and transforms them into graph feature
vectors. ABFL then fuses those graphs feature vectors with initial code
embeddings from a large language model. By optimizing these transducers for
different downstream tasks, our approach enhances the models without the need
to fine-tune them for specific tasks. We have evaluated \approach on three
downstream tasks: code summarization, assert generation, and code translation.
Our results demonstrate competitive performance compared to full parameter
fine-tuning while reducing up to 99\% trainable parameters to save memory.
\approach also remains competitive against other fine-tuning approaches (e.g.,
LoRA, Prompt-Tuning, Prefix-Tuning) while using only 1.5\%-80\% of their
trainable parameters. Our findings show that integrating structural and
dependency information through Transducer Tuning enables more efficient model
adaptation, making it easier for users to adapt large models in
resource-constrained settings.

æè¦ï¼å¤§åèªè¨æ¨¡åå·²å¨åç¨®è»é«å·¥ç¨ä»»åä¸­å±ç¾åºä»¤äººæ»¿æçæè½ãéç¶å¾®èª¿æ¯èª¿æ´éäºæ¨¡åä»¥å·è¡ä¸æ¸¸ä»»åçå¸¸è¦åæ³ï¼ä½ç±æ¼å¤§åèªè¨æ¨¡åä¸­å¯è¨ç·´åæ¸ä¸æ·å¢å ï¼å°è´è¨æ¶é«éæ±å¢å ï¼å æ­¤å¨è³æºåéçç°å¢ä¸­è®å¾å·æææ°æ§ãæåå¼å¥äº \approachï¼éæ¯ä¸ç¨®ä½¿ç¨ç¨å¼ç¢¼å±¬æ§å (CPG) ä¾èª¿æ´å¤§åæ¨¡åä»¥å·è¡ä¸æ¸¸ç¨å¼ç¢¼ä»»åçæè¡ãæåçåæ³å¼å¥äºç¨±çº \transducer çæ¨¡çµååä»¶ï¼å®ä½¿ç¨ä¾èª CPG ççµæ§åä¾è³´éä¿è³è¨ä¾è±å¯ç¨å¼ç¢¼åµå¥ãTransducer åå«å©åééµåä»¶ï¼ååéåå¼æ (GVE) ååºæ¼æ³¨æåçèåå±¤ (ABFL)ãGVE å¾è¼¸å¥åå§ç¢¼ä¸­èå CPGï¼ä¸¦å°å®åè½æçºåå½¢ç¹å¾µåéãABFL æ¥èå°éäºåå½¢ç¹å¾µåéèä¾èªå¤§åèªè¨æ¨¡åçåå§ç¨å¼ç¢¼åµå¥èåãéééå°ä¸åçä¸æ¸¸ä»»åæä½³åéäºè½æå¨ï¼æåçåæ³å¢å¼·äºæ¨¡åï¼èç¡ééå°ç¹å®ä»»åé²è¡å¾®èª¿ãæåå·²å¨ä¸åä¸æ¸¸ä»»åä¸­è©ä¼° \approachï¼ç¨å¼ç¢¼æè¦ãæ·è¨ç¢çåç¨å¼ç¢¼ç¿»è­¯ãæåççµæé¡¯ç¤ºï¼èå®å¨åæ¸å¾®èª¿ç¸æ¯ï¼å·æç«¶ç­åçæè½ï¼åææ¸å°äºå¤é 99% çå¯è¨ç·´åæ¸ä»¥ç¯çè¨æ¶é«ã\approach å¨åä½¿ç¨ 1.5% - 80% å¯è¨ç·´åæ¸çææ³ä¸ï¼ä»ç¶å¨èå¶ä»å¾®èª¿æ¹æ³ï¼ä¾å¦ LoRAãPrompt-TuningãPrefix-Tuningï¼çç«¶ç­ä¸­ä¿æç«¶ç­åãæåçç¼ç¾è¡¨æï¼éé Transducer Tuning æ´åçµæ§åä¾è³´éä¿è³è¨å¯ä»¥å¯¦ç¾æ´ææççæ¨¡åèª¿æ´ï¼ä½¿ç¨æ¶æ´å®¹æå¨è³æºåéçè¨­å®ä¸­èª¿æ´å¤§åæ¨¡åã

##### **Enhancing Persona Classification in Dialogue Systems: A Graph Neural Network Approach**
2412.13283v1 by Konstantin Zaitsev

In recent years, Large Language Models (LLMs) gain considerable attention for
their potential to enhance personalized experiences in virtual assistants and
chatbots. A key area of interest is the integration of personas into LLMs to
improve dialogue naturalness and user engagement. This study addresses the
challenge of persona classification, a crucial component in dialogue
understanding, by proposing a framework that combines text embeddings with
Graph Neural Networks (GNNs) for effective persona classification. Given the
absence of dedicated persona classification datasets, we create a manually
annotated dataset to facilitate model training and evaluation. Our method
involves extracting semantic features from persona statements using text
embeddings and constructing a graph where nodes represent personas and edges
capture their similarities. The GNN component uses this graph structure to
propagate relevant information, thereby improving classification performance.
Experimental results show that our approach, in particular the integration of
GNNs, significantly improves classification performance, especially with
limited data. Our contributions include the development of a persona
classification framework and the creation of a dataset.

æè¦ï¼è¿å¹´ä¾ï¼å¤§åèªè¨æ¨¡å (LLM) å å¶å¢å¼·èæ¬å©çåèå¤©æ©å¨äººä¸­åäººåé«é©çæ½åèååéæ³¨ãä¸åééµçèè¶£é åæ¯å°è§è²èå¥ LLMï¼ä»¥æ¹åå°è©±çèªç¶æ§åä½¿ç¨èåèåº¦ãæ¬ç ç©¶æ¢è¨è§è²åé¡çææ°ï¼éæ¯å°è©±çè§£ä¸­çééµçµæé¨åï¼æåºä¸åçµåææ¬åµå¥èåç¥ç¶ç¶²è·¯ (GNN) çæ¶æ§ï¼ä»¥é²è¡ææçè§è²åé¡ãéæ¼ç¼ºä¹å°ç¨çè§è²åé¡è³æéï¼æåå»ºç«äºä¸åæåæ¨è¨»çè³æéï¼ä»¥å©æ¼æ¨¡åè¨ç·´åè©ä¼°ãæåçæ¹æ³åæ¬ä½¿ç¨ææ¬åµå¥å¾è§è²é³è¿°ä¸­æåèªç¾©ç¹å¾µï¼ä¸¦å»ºæ§ä¸ååï¼å¶ä¸­ç¯é»è¡¨ç¤ºè§è²ï¼èéç·£ææå®åçç¸ä¼¼æ§ãGNN çµä»¶ä½¿ç¨éååçµæ§ä¾å³æ­ç¸éè³è¨ï¼å¾èæ¹ååé¡æè½ãå¯¦é©çµæé¡¯ç¤ºï¼æåçæ¹æ³ï¼ç¹å¥æ¯ GNN çæ´åï¼é¡¯èæ¹åäºåé¡æè½ï¼ç¹å¥æ¯å¨è³ææéçææ³ä¸ãæåçè²¢ç»åæ¬éç¼è§è²åé¡æ¶æ§åå»ºç«è³æéã

##### **SimGRAG: Leveraging Similar Subgraphs for Knowledge Graphs Driven Retrieval-Augmented Generation**
2412.15272v1 by Yuzheng Cai, Zhenyue Guo, Yiwen Pei, Wanrui Bian, Weiguo Zheng

Recent advancements in large language models (LLMs) have shown impressive
versatility across various tasks. To eliminate its hallucinations,
retrieval-augmented generation (RAG) has emerged as a powerful approach,
leveraging external knowledge sources like knowledge graphs (KGs). In this
paper, we study the task of KG-driven RAG and propose a novel Similar Graph
Enhanced Retrieval-Augmented Generation (SimGRAG) method. It effectively
addresses the challenge of aligning query texts and KG structures through a
two-stage process: (1) query-to-pattern, which uses an LLM to transform queries
into a desired graph pattern, and (2) pattern-to-subgraph, which quantifies the
alignment between the pattern and candidate subgraphs using a graph semantic
distance (GSD) metric. We also develop an optimized retrieval algorithm that
efficiently identifies the top-$k$ subgraphs within 1-second latency on a
10-million-scale KG. Extensive experiments show that SimGRAG outperforms
state-of-the-art KG-driven RAG methods in both question answering and fact
verification, offering superior plug-and-play usability and scalability.

æè¦ï¼å¤§åèªè¨æ¨¡åï¼LLMï¼çææ°é²å±å¨åç¨®ä»»åä¸­å±ç¾åºä»¤äººå°è±¡æ·±å»çå¤åè½æ§ãçºäºæ¶é¤å¶å¹»è¦ºï¼æ·åå¢å¼·çæï¼RAGï¼å·²æçºä¸ç¨®å¼·å¤§çæ¹æ³ï¼å©ç¨å¤é¨ç¥è­ä¾æºï¼ä¾å¦ç¥è­åè­ï¼KGï¼ãå¨æ¬æä¸­ï¼æåç ç©¶äº KG é©å RAG çä»»åï¼ä¸¦æåºäºä¸ç¨®æ°ç©çé¡ä¼¼åå½¢å¢å¼·æ·åå¢å¼·çæï¼SimGRAGï¼æ¹æ³ãå®ééä¸åå©éæ®µéç¨ææå°æå°äºå°é½æ¥è©¢ææ¬å KG çµæ§çææ°ï¼(1) æ¥è©¢å°æ¨¡å¼ï¼å®ä½¿ç¨ LLM å°æ¥è©¢è½æçºæéçåå½¢æ¨¡å¼ï¼ä»¥å (2) æ¨¡å¼å°å­åï¼å®ä½¿ç¨åå½¢èªç¾©è·é¢ (GSD) åº¦éä¾éåæ¨¡å¼ååé¸å­åä¹éçå°é½ãæåééç¼äºä¸ç¨®æä½³åçæ·åæ¼ç®æ³ï¼å¯ä»¥å¨ 1000 è¬è¦æ¨¡ç KG ä¸ä»¥ 1 ç§çå»¶é²ææå°è­å¥å $k$ åå­åãå¤§éçå¯¦é©è¡¨æï¼SimGRAG å¨åç­åäºå¯¦é©è­æ¹é¢é½åªæ¼æåé²ç KG é©å RAG æ¹æ³ï¼æä¾äºåè¶çå³æå³ç¨å¯ç¨æ§åå¯æ´å±æ§ã

##### **Detecting Emotional Incongruity of Sarcasm by Commonsense Reasoning**
2412.12808v2 by Ziqi Qiu, Jianxing Yu, Yufeng Zhang, Hanjiang Lai, Yanghui Rao, Qinliang Su, Jian Yin

This paper focuses on sarcasm detection, which aims to identify whether given
statements convey criticism, mockery, or other negative sentiment opposite to
the literal meaning. To detect sarcasm, humans often require a comprehensive
understanding of the semantics in the statement and even resort to external
commonsense to infer the fine-grained incongruity. However, existing methods
lack commonsense inferential ability when they face complex real-world
scenarios, leading to unsatisfactory performance. To address this problem, we
propose a novel framework for sarcasm detection, which conducts incongruity
reasoning based on commonsense augmentation, called EICR. Concretely, we first
employ retrieval-augmented large language models to supplement the missing but
indispensable commonsense background knowledge. To capture complex contextual
associations, we construct a dependency graph and obtain the optimized topology
via graph refinement. We further introduce an adaptive reasoning skeleton that
integrates prior rules to extract sentiment-inconsistent subgraphs explicitly.
To eliminate the possible spurious relations between words and labels, we
employ adversarial contrastive learning to enhance the robustness of the
detector. Experiments conducted on five datasets demonstrate the effectiveness
of EICR.

æè¦ï¼æ¬æéç¹å³æ³¨è®½åºæ£æµï¼å¶æ¨å¨è¯å«ç»å®çéè¿°æ¯å¦ä¼ è¾¾äºä¸å­é¢ææç¸åçæ¹è¯ãå²è®½æå¶ä»æ¶ææç»ªãä¸ºäºæ£æµè®½åºï¼äººç±»éå¸¸éè¦å¨é¢çè§£éè¿°ä¸­çè¯­ä¹ï¼çè³è¯è¯¸å¤é¨å¸¸è¯æ¥æ¨æ­ç»ç²åº¦ççç¾ãç¶èï¼ç°ææ¹æ³å¨é¢å¯¹å¤æçç°å®ä¸çåºæ¯æ¶ç¼ºä¹å¸¸è¯æ¨çè½åï¼å¯¼è´æ§è½ä¸ä½³ãä¸ºäºè§£å³è¿ä¸ªé®é¢ï¼æä»¬æåºäºä¸ç§ç¨äºè®½åºæ£æµçæ°åæ¡æ¶ï¼è¯¥æ¡æ¶åºäºå¸¸è¯å¢å¼ºè¿è¡ä¸ä¸è´æ¨çï¼ç§°ä¸º EICRãå·ä½æ¥è¯´ï¼æä»¬é¦åéç¨æ£ç´¢å¢å¼ºçå¤§è¯­è¨æ¨¡åæ¥è¡¥åç¼ºå¤±ä½ä¸å¯æç¼ºçå¸¸è¯èæ¯ç¥è¯ãä¸ºäºææå¤æçä¸ä¸æå³èï¼æä»¬æå»ºäºä¸ä¸ªä¾èµå¾ï¼å¹¶éè¿å¾ç»åè·å¾äºä¼åçææãæä»¬è¿ä¸æ­¥å¼å¥äºä¸ä¸ªèªéåºæ¨çæ¡æ¶ï¼è¯¥æ¡æ¶éæäºåéªè§åï¼ä»¥æç¡®æåæç»ªä¸ä¸è´çå­å¾ãä¸ºäºæ¶é¤åè¯åæ ç­¾ä¹é´å¯è½çèåå³ç³»ï¼æä»¬éç¨å¯¹æå¯¹æ¯å­¦ä¹ æ¥å¢å¼ºæ£æµå¨çé²æ£æ§ãå¨äºä¸ªæ°æ®éä¸è¿è¡çå®éªè¯æäº EICR çæææ§ã

##### **AnalogXpert: Automating Analog Topology Synthesis by Incorporating Circuit Design Expertise into Large Language Models**
2412.19824v1 by Haoyi Zhang, Shizhao Sun, Yibo Lin, Runsheng Wang, Jiang Bian

Analog circuits are crucial in modern electronic systems, and automating
their design has attracted significant research interest. One of major
challenges is topology synthesis, which determines circuit components and their
connections. Recent studies explore large language models (LLM) for topology
synthesis. However, the scenarios addressed by these studies do not align well
with practical applications. Specifically, existing work uses vague design
requirements as input and outputs an ideal model, but detailed structural
requirements and device-level models are more practical. Moreover, current
approaches either formulate topology synthesis as graph generation or Python
code generation, whereas practical topology design is a complex process that
demands extensive design knowledge. In this work, we propose AnalogXpert, a
LLM-based agent aiming at solving practical topology synthesis problem by
incorporating circuit design expertise into LLMs. First, we represent analog
topology as SPICE code and introduce a subcircuit library to reduce the design
space, in the same manner as experienced designers. Second, we decompose the
problem into two sub-task (i.e., block selection and block connection) through
the use of CoT and incontext learning techniques, to mimic the practical design
process. Third, we introduce a proofreading strategy that allows LLMs to
incrementally correct the errors in the initial design, akin to human designers
who iteratively check and adjust the initial topology design to ensure
accuracy. Finally, we construct a high-quality benchmark containing both real
data (30) and synthetic data (2k). AnalogXpert achieves 40% and 23% success
rates on the synthetic dataset and real dataset respectively, which is markedly
better than those of GPT-4o (3% on both the synthetic dataset and the real
dataset).

æè¦ï¼é¡æ¯é»è·¯å¨ç¾ä»£é»å­ç³»çµ±ä¸­è³ééè¦ï¼èèªååå¶è¨­è¨å·²å¼èµ·éå¤§ç ç©¶èè¶£ãå¶ä¸­ä¸åä¸»è¦ææ°æ¯ææ²åæï¼å®æ±ºå®é»è·¯åä»¶åå¶é£æ¥ãæè¿çç ç©¶æ¢ç´¢äºç¨æ¼ææ²åæç LLMï¼å¤§åèªè¨æ¨¡åï¼ãç¶èï¼éäºç ç©¶æè¨è«çå ´æ¯èå¯¦éæç¨ä¸¦ä¸å¤ªä¸è´ãå·é«èè¨ï¼ç¾æå·¥ä½ä½¿ç¨æ¨¡ç³çè¨­è¨éæ±ä½çºè¼¸å¥ä¸¦è¼¸åºä¸åçæ³æ¨¡åï¼ä½è©³ç´°ççµæ§éæ±åè¨­åç´å¥æ¨¡åæ´å¯¦ç¨ãæ­¤å¤ï¼ç¶åçéå¾å°ææ²åæè¡¨è¿°çºåå½¢çææ Python ç¨å¼ç¢¼çæï¼èå¯¦ç¨çææ²è¨­è¨æ¯ä¸åè¤éçéç¨ï¼éè¦å»£æ³çè¨­è¨ç¥è­ãå¨éé å·¥ä½ä¸­ï¼æåæåºäº AnalogXpertï¼ä¸ååºæ¼ LLM çä»£çï¼æ¨å¨ééå°é»è·¯è¨­è¨å°æ¥­ç¥è­æ´åå° LLM ä¸­ä¾è§£æ±ºå¯¦éçææ²åæåé¡ãé¦åï¼æåå°é¡æ¯ææ²è¡¨ç¤ºçº SPICE ç¨å¼ç¢¼ï¼ä¸¦å¼å¥ä¸åå­é»è·¯åº«ä»¥æ¸å°è¨­è¨ç©ºéï¼éèç¶é©è±å¯çè¨­è¨å¸«æåçä¸æ¨£ãå¶æ¬¡ï¼æåééä½¿ç¨ CoT åæå¢å­¸ç¿æè¡å°åé¡åè§£çºå©åå­ä»»åï¼å³ï¼åå¡é¸æååå¡é£æ¥ï¼ï¼ä»¥æ¨¡æ¬å¯¦éçè¨­è¨éç¨ãç¬¬ä¸ï¼æåå¼å¥äºä¸åæ ¡å°ç­ç¥ï¼åè¨± LLM éæ­¥æ´æ­£åå§è¨­è¨ä¸­çé¯èª¤ï¼é¡ä¼¼æ¼äººé¡è¨­è¨å¸«åè¦æª¢æ¥åèª¿æ´åå§ææ²è¨­è¨ä»¥ç¢ºä¿æºç¢ºæ§ãæå¾ï¼æåæ§å»ºäºä¸åé«åè³ªçåºæºï¼å¶ä¸­åå«çå¯¦æ¸æï¼30ï¼ååææ¸æï¼2kï¼ãå¨åææ¸æéåçå¯¦æ¸æéä¸ï¼AnalogXpert åå¥éå°äº 40% å 23% çæåçï¼éæé¡¯åªæ¼ GPT-4oï¼å¨åææ¸æéåçå¯¦æ¸æéä¸çæåçåçº 3%ï¼ã

##### **LLM-based Discriminative Reasoning for Knowledge Graph Question Answering**
2412.12643v1 by Mufan Xu, Kehai Chen, Xuefeng Bai, Muyun Yang, Tiejun Zhao, Min Zhang

Large language models (LLMs) based on generative pre-trained Transformer have
achieved remarkable performance on knowledge graph question-answering (KGQA)
tasks. However, LLMs often produce ungrounded subgraph planning or reasoning
results in KGQA due to the hallucinatory behavior brought by the generative
paradigm, which may hinder the advancement of the LLM-based KGQA model. To deal
with the issue, we propose a novel LLM-based Discriminative Reasoning (LDR)
method to explicitly model the subgraph retrieval and answer inference process.
By adopting discriminative strategies, the proposed LDR method not only
enhances the capability of LLMs to retrieve question-related subgraphs but also
alleviates the issue of ungrounded reasoning brought by the generative paradigm
of LLMs. Experimental results show that the proposed approach outperforms
multiple strong comparison methods, along with achieving state-of-the-art
performance on two widely used WebQSP and CWQ benchmarks.

æè¦ï¼å¤§åèªè¨æ¨¡åï¼LLMï¼åºæ¼çæå¼é è¨ç·´ Transformerï¼å¨ç¥è­åè­åç­ï¼KGQAï¼ä»»åä¸å·²åå¾é¡¯èçææãç¶èï¼ç±æ¼çæå¼ç¯ä¾å¸¶ä¾çå¹»è¦ºè¡çºï¼LLM å¨ KGQA ä¸­ç¶å¸¸ç¢çç¡æ ¹æçå­åè¦åææ¨ççµæï¼éå¯è½æé»ç¤åºæ¼ LLM ç KGQA æ¨¡åçé²å±ãçºäºè§£æ±ºéååé¡ï¼æåæåºäºä¸ç¨®æ°ç©çåºæ¼ LLM çå¤å¥æ¨çï¼LDRï¼æ¹æ³ï¼ä»¥æç¢ºå»ºæ¨¡å­åæª¢ç´¢åç­æ¡æ¨è«éç¨ãééæ¡ç¨å¤å¥ç­ç¥ï¼ææåºç LLM æ¹æ³ä¸åå¢å¼·äº LLM æª¢ç´¢èåé¡ç¸éçå­åçè½åï¼èä¸éç·©è§£äº LLM ççæå¼ç¯ä¾å¸¶ä¾çç¡æ ¹ææ¨çåé¡ãå¯¦é©çµæè¡¨æï¼ææåºçæ¹æ³åªæ¼å¤ç¨®å¼·å¤§çæ¯è¼æ¹æ³ï¼åæå¨å©åå»£æ³ä½¿ç¨ç WebQSP å CWQ åºæºæ¸¬è©¦ä¸­åå¾äºæåé²çæè½ã

##### **SynthCypher: A Fully Synthetic Data Generation Framework for Text-to-Cypher Querying in Knowledge Graphs**
2412.12612v1 by Aman Tiwari, Shiva Krishna Reddy Malay, Vikas Yadav, Masoud Hashemi, Sathwik Tejaswi Madhusudhan

Cypher, the query language for Neo4j graph databases, plays a critical role
in enabling graph-based analytics and data exploration. While substantial
research has been dedicated to natural language to SQL query generation
(Text2SQL), the analogous problem for graph databases referred to as
Text2Cypher remains underexplored. In this work, we introduce SynthCypher, a
fully synthetic and automated data generation pipeline designed to address this
gap. SynthCypher employs a novel LLMSupervised Generation-Verification
framework, ensuring syntactically and semantically correct Cypher queries
across diverse domains and query complexities. Using this pipeline, we create
SynthCypher Dataset, a large-scale benchmark containing 29.8k Text2Cypher
instances. Fine-tuning open-source large language models (LLMs), including
LLaMa-3.1- 8B, Mistral-7B, and QWEN-7B, on SynthCypher yields significant
performance improvements of up to 40% on the Text2Cypher test set and 30% on
the SPIDER benchmark adapted for graph databases. This work demonstrates that
high-quality synthetic data can effectively advance the state-of-the-art in
Text2Cypher tasks.

æè¦ï¼Cypher æ¯ Neo4j åå½¢è³æåº«çæ¥è©¢èªè¨ï¼å¨åç¨ä»¥åå½¢çºåºç¤çåæåè³ææ¢ç´¢æ¹é¢ç¼æ®èè³ééè¦çä½ç¨ãåç®¡å·²ç¶æå¥å¤§éç ç©¶å°èªç¶èªè¨è½æçº SQL æ¥è©¢çæ (Text2SQL)ï¼ä½ç¨±çº Text2Cypher çåå½¢è³æåº«é¡æ¯åé¡ä»æªå¾å°ååæ¢è¨ãå¨éé å·¥ä½ä¸­ï¼æåä»ç´¹äº SynthCypherï¼éæ¯ä¸åå®å¨åæä¸èªååçè³æçæç®¡éï¼æ¨å¨è§£æ±ºéåå·®è·ãSynthCypher æ¡ç¨äºä¸ç¨®æ°ç©ç LLMSupervised çæé©è­æ¡æ¶ï¼ç¢ºä¿äºè·¨è¶ä¸åé ååæ¥è©¢è¤éæ§ç Cypher æ¥è©¢å¨èªæ³åèªç¾©ä¸æ­£ç¢ºãä½¿ç¨éåç®¡éï¼æååµå»ºäº SynthCypher è³æéï¼éæ¯ä¸ååå« 29.8k Text2Cypher å¯¦ä¾çå¤§è¦æ¨¡åºæºãå¾®èª¿éæºå¤§åèªè¨æ¨¡å (LLM)ï¼åæ¬ SynthCypher ä¸ç LLaMa-3.1- 8BãMistral-7B å QWEN-7Bï¼å¨ Text2Cypher æ¸¬è©¦éä¸­ç¢çäºé«é 40% çé¡¯èæ§è½æåï¼å¨é©ç¨æ¼åå½¢è³æåº«ç SPIDER åºæºä¸æåäº 30%ãéé å·¥ä½è­æäºé«åè³ªçåæè³æå¯ä»¥ææå°æ¨å Text2Cypher ä»»åçææ°æè¡ã

##### **Enhancing LLM-based Hatred and Toxicity Detection with Meta-Toxic Knowledge Graph**
2412.15268v2 by Yibo Zhao, Jiapeng Zhu, Can Xu, Xiang Li

The rapid growth of social media platforms has raised significant concerns
regarding online content toxicity. When Large Language Models (LLMs) are used
for toxicity detection, two key challenges emerge: 1) the absence of
domain-specific toxic knowledge leads to false negatives; 2) the excessive
sensitivity of LLMs to toxic speech results in false positives, limiting
freedom of speech. To address these issues, we propose a novel method called
MetaTox, leveraging graph search on a meta-toxic knowledge graph to enhance
hatred and toxicity detection. First, we construct a comprehensive meta-toxic
knowledge graph by utilizing LLMs to extract toxic information through a
three-step pipeline, with toxic benchmark datasets serving as corpora. Second,
we query the graph via retrieval and ranking processes to supplement accurate,
relevant toxic knowledge. Extensive experiments and in-depth case studies
across multiple datasets demonstrate that our MetaTox significantly decreases
the false positive rate while boosting overall toxicity detection performance.
Our code will be available soon.

æè¦ï¼ç¤¾ç¾¤åªé«å¹³å°å¿«éæé·ï¼å°æ¼ç·ä¸å§å®¹æ¯æ§å¼ç¼é«åº¦éæ³¨ãç¶å¤§åèªè¨æ¨¡å (LLM) ç¨æ¼æ¯æ§åµæ¸¬æï¼æåºç¾å©åä¸»è¦ææ°ï¼1) ç¼ºä¹ç¹å®é åçæ¯æ§ç¥è­ï¼å°è´åé°æ§ï¼2) LLM å°æ¯æ§è¨è«éåº¦ææï¼å°è´åé½æ§ï¼éå¶è¨è«èªç±ãçºäºè§£æ±ºéäºåé¡ï¼æåæåºäºä¸ç¨®åçº MetaTox çæ°æ¹æ³ï¼å©ç¨åå½¢æå°å¨åæ¯æ§ç¥è­åè­ä¸ï¼ä»¥å¢å¼·ä»æ¨åæ¯æ§åµæ¸¬ãé¦åï¼æåéé LLM å©ç¨ä¸æ­¥é©ç®¡ç·èåæ¯æ§è³è¨ï¼å»ºæ§å¨é¢çåæ¯æ§ç¥è­åè­ï¼ä¸¦ä»¥æ¯æ§åºæºè³æéä½çºèªæåº«ãå¶æ¬¡ï¼æåééæª¢ç´¢åæåç¨åºæ¥è©¢åå½¢ï¼ä»¥è£åæºç¢ºä¸ç¸éçæ¯æ§ç¥è­ãè·¨å¤åè³æéçå»£æ³å¯¦é©åæ·±å¥æ¡ä¾ç ç©¶é¡¯ç¤ºï¼æåç MetaTox å¤§å¹éä½åé½æ§çï¼åææåæ´é«æ¯æ§åµæ¸¬æè½ãæåçç¨å¼ç¢¼å°å¾å¿«æä¾ã

##### **Graph Learning in the Era of LLMs: A Survey from the Perspective of Data, Models, and Tasks**
2412.12456v1 by Xunkai Li, Zhengyu Wu, Jiayi Wu, Hanwen Cui, Jishuo Jia, Rong-Hua Li, Guoren Wang

With the increasing prevalence of cross-domain Text-Attributed Graph (TAG)
Data (e.g., citation networks, recommendation systems, social networks, and
ai4science), the integration of Graph Neural Networks (GNNs) and Large Language
Models (LLMs) into a unified Model architecture (e.g., LLM as enhancer, LLM as
collaborators, LLM as predictor) has emerged as a promising technological
paradigm. The core of this new graph learning paradigm lies in the synergistic
combination of GNNs' ability to capture complex structural relationships and
LLMs' proficiency in understanding informative contexts from the rich textual
descriptions of graphs. Therefore, we can leverage graph description texts with
rich semantic context to fundamentally enhance Data quality, thereby improving
the representational capacity of model-centric approaches in line with
data-centric machine learning principles. By leveraging the strengths of these
distinct neural network architectures, this integrated approach addresses a
wide range of TAG-based Task (e.g., graph learning, graph reasoning, and graph
question answering), particularly in complex industrial scenarios (e.g.,
supervised, few-shot, and zero-shot settings). In other words, we can treat
text as a medium to enable cross-domain generalization of graph learning Model,
allowing a single graph model to effectively handle the diversity of downstream
graph-based Task across different data domains. This work serves as a
foundational reference for researchers and practitioners looking to advance
graph learning methodologies in the rapidly evolving landscape of LLM. We
consistently maintain the related open-source materials at
\url{https://github.com/xkLi-Allen/Awesome-GNN-in-LLMs-Papers}.

æè¦ï¼<paragraph>é¨èè·¨é åææ¬å±¬æ§å (TAG) è³æï¼ä¾å¦å¼æç¶²è·¯ãæ¨è¦ç³»çµ±ãç¤¾äº¤ç¶²è·¯å ai4scienceï¼çæ¥çæ®åï¼å°åç¥ç¶ç¶²è·¯ (GNN) åå¤§åèªè¨æ¨¡å (LLM) æ´åå°çµ±ä¸çæ¨¡åæ¶æ§ï¼ä¾å¦ï¼LLM ä½çºå¢å¼·å¨ãLLM ä½çºåä½èãLLM ä½çºé æ¸¬å¨ï¼ä¸­å·²æçºä¸ç¨®æåéçæè¡å¸ç¯ãéç¨®æ°çåå½¢å­¸ç¿å¸ç¯çæ ¸å¿å¨æ¼ GNN ææè¤éçµæ§éä¿çè½åè LLM å¾åå½¢çè±å¯æå­æè¿°ä¸­çè§£è³è¨è±å¯èæ¯ççç·´åº¦çååçµåãå æ­¤ï¼æåå¯ä»¥å©ç¨å·æè±å¯èªç¾©èæ¯çåå½¢æè¿°æå­ï¼å¾æ ¹æ¬ä¸æåè³æåè³ªï¼å¾èæ¹åä»¥æ¨¡åçºä¸­å¿çéå¾çè¡¨ç¤ºè½åï¼ä¸¦ç¬¦åä»¥è³æçºä¸­å¿çæ©å¨å­¸ç¿ååãééå©ç¨éäºä¸åçç¥ç¶ç¶²è·¯æ¶æ§çåªé»ï¼éç¨®æ´åæ¹æ³è§£æ±ºäºå»£æ³çåºæ¼ TAG çä»»åï¼ä¾å¦ï¼åå½¢å­¸ç¿ãåå½¢æ¨çååå½¢åç­ï¼ï¼ç¹å¥æ¯å¨è¤éçç¢æ¥­å ´æ¯ï¼ä¾å¦ï¼ç£ç£å¼ãå°æ¨£æ¬åé¶æ¨£æ¬è¨­å®ï¼ä¸­ãæå¥è©±èªªï¼æåå¯ä»¥å°æå­è¦çºä¸ç¨®åªä»ï¼ä»¥å¯¦ç¾åå½¢å­¸ç¿æ¨¡åçè·¨é åæ³åï¼è®å®ä¸åå½¢æ¨¡åè½å¤ ææå°èçä¸åè³æé åä¸­ä¸æ¸¸åºæ¼åå½¢çä»»åçå¤æ¨£æ§ãéé å·¥ä½ä½çºç ç©¶äººå¡åå¯¦åå·¥ä½èçåºç¤åèï¼ä»åå¸æå¨ LLM å¿«éæ¼è®çç°å¢ä¸­æ¨é²åå½¢å­¸ç¿æ¹æ³ãæåæçºå¨ \url{https://github.com/xkLi-Allen/Awesome-GNN-in-LLMs-Papers} ç¶­è­·ç¸éçéæ¾åå§ç¢¼è³æã</paragraph>

##### **Graph-Guided Textual Explanation Generation Framework**
2412.12318v1 by Shuzhou Yuan, Jingyi Sun, Ran Zhang, Michael FÃ¤rber, Steffen Eger, Pepa Atanasova, Isabelle Augenstein

Natural language explanations (NLEs) are commonly used to provide plausible
free-text explanations of a model's reasoning about its predictions. However,
recent work has questioned the faithfulness of NLEs, as they may not accurately
reflect the model's internal reasoning process regarding its predicted answer.
In contrast, highlight explanations -- input fragments identified as critical
for the model's predictions -- exhibit measurable faithfulness, which has been
incrementally improved through existing research. Building on this foundation,
we propose G-Tex, a Graph-Guided Textual Explanation Generation framework
designed to enhance the faithfulness of NLEs by leveraging highlight
explanations. Specifically, highlight explanations are extracted as highly
faithful cues representing the model's reasoning and are subsequently encoded
through a graph neural network layer, which explicitly guides the NLE
generation process. This alignment ensures that the generated explanations
closely reflect the model's underlying reasoning. Experiments on T5 and BART
using three reasoning datasets show that G-Tex improves NLE faithfulness by up
to 17.59% compared to baseline methods. Additionally, G-Tex generates NLEs with
greater semantic and lexical similarity to human-written ones. Human
evaluations show that G-Tex can decrease redundant content and enhance the
overall quality of NLEs. As our work introduces a novel method for explicitly
guiding NLE generation to improve faithfulness, we hope it will serve as a
stepping stone for addressing additional criteria for NLE and generated text
overall.

æè¦ï¼èªç¶èªè¨è§£é (NLE) å¸¸ç¨æ¼æä¾æ¨¡åå°å¶é æ¸¬çåçè§£éãç¶èï¼æè¿çç ç©¶è³ªç NLE çå¿ å¯¦åº¦ï¼å çºå®åå¯è½ç¡æ³æºç¢ºåæ æ¨¡åå¨å¶é æ¸¬ç­æ¡ä¸çå§é¨æ¨çéç¨ãç¸åï¼éé»è§£éââè¢«è­å¥çºå°æ¨¡åé æ¸¬è³ééè¦çè¼¸å¥çæ®µââè¡¨ç¾åºå¯è¡¡éçå¿ å¯¦åº¦ï¼éå·²ééç¾æç ç©¶éæ­¥å¾å°æ¹é²ãå¨æ­¤åºç¤ä¸ï¼æåæåºäº G-Texï¼ä¸ååå½¢å¼å°ææ¬è§£éçææ¡æ¶ï¼æ¨å¨ééå©ç¨éé»è§£éä¾å¢å¼· NLE çå¿ å¯¦åº¦ãå·é«ä¾èªªï¼éé»è§£éè¢«æåçºä»£è¡¨æ¨¡åæ¨ççé«åº¦å¿ å¯¦ç·ç´¢ï¼ç¶å¾ééåç¥ç¶ç¶²è·¯å±¤é²è¡ç·¨ç¢¼ï¼éæç¢ºæå°äº NLE çæéç¨ãéç¨®å°é½ç¢ºä¿çæçè§£éç·å¯åæ æ¨¡åçåºå±¤æ¨çãä½¿ç¨ä¸åæ¨çæ¸æéå° T5 å BART é²è¡çå¯¦é©è¡¨æï¼èåºç·æ¹æ³ç¸æ¯ï¼G-Tex å° NLE çå¿ å¯¦åº¦æé«äº 17.59%ãæ­¤å¤ï¼G-Tex çæç NLE èäººé¡ç·¨å¯«ç NLE å¨èªç¾©åè©å½ä¸å·ææ´é«çç¸ä¼¼æ§ãäººé¡è©ä¼°è¡¨æï¼G-Tex å¯ä»¥æ¸å°åé¤å§å®¹ä¸¦æé« NLE çæ´é«åè³ªãç±æ¼æåçç ç©¶å¼å¥äºä¸ç¨®æç¢ºæå° NLE çæçåµæ°æ¹æ³ä¾æé«å¿ å¯¦åº¦ï¼æåå¸æå®å°ä½çºè§£æ±º NLE åæ´é«çæææ¬çéå æ¨æºçå¢è³ç³ã

##### **Cost-Effective Label-free Node Classification with LLMs**
2412.11983v1 by Taiyan Zhang, Renchi Yang, Mingyu Yan, Xiaochun Ye, Dongrui Fan, Yurui Lai

Graph neural networks (GNNs) have emerged as go-to models for node
classification in graph data due to their powerful abilities in fusing graph
structures and attributes. However, such models strongly rely on adequate
high-quality labeled data for training, which are expensive to acquire in
practice. With the advent of large language models (LLMs), a promising way is
to leverage their superb zero-shot capabilities and massive knowledge for node
labeling. Despite promising results reported, this methodology either demands
considerable queries to LLMs, or suffers from compromised performance caused by
noisy labels produced by LLMs.
  To remedy these issues, this work presents Cella, an active self-training
framework that integrates LLMs into GNNs in a cost-effective manner. The design
recipe of Cella is to iteratively identify small sets of "critical" samples
using GNNs and extract informative pseudo-labels for them with both LLMs and
GNNs as additional supervision signals to enhance model training. Particularly,
Cella includes three major components: (i) an effective active node selection
strategy for initial annotations; (ii) a judicious sample selection scheme to
sift out the "critical" nodes based on label disharmonicity and entropy; and
(iii) a label refinement module combining LLMs and GNNs with rewired topology.
Our extensive experiments over five benchmark text-attributed graph datasets
demonstrate that Cella significantly outperforms the state of the arts under
the same query budget to LLMs in terms of label-free node classification. In
particular, on the DBLP dataset with 14.3k nodes, Cella is able to achieve an
8.08% conspicuous improvement in accuracy over the state-of-the-art at a cost
of less than one cent.

æè¦ï¼åå½¢ç¥ç¶ç¶²è·¯ (GNN) å·²æçºåå½¢è³æä¸­ç¯é»åé¡çç±éæ¨¡åï¼å çºå®åå¨èååå½¢çµæ§åå±¬æ§æ¹é¢å·æå¼·å¤§çè½åãç¶èï¼æ­¤é¡æ¨¡åå¨è¨ç·´æé«åº¦ä¾è³´è¶³å¤ çé«åè³ªæ¨ç±¤è³æï¼èéäºè³æå¨å¯¦åä¸åå¾çææ¬å¾é«ãé¨èå¤§åèªè¨æ¨¡å (LLM) çåºç¾ï¼ä¸åæåéçæ¹æ³æ¯å©ç¨å¶åè¶çé¶æ¬¡å­¸ç¿è½ååæµ·éç¥è­é²è¡ç¯é»æ¨ç±¤ãåç®¡å ±åäºæå¸æççµæï¼ä½æ­¤æ¹æ³ä¸æ¯éè¦å¤§éæ¥è©¢ LLMï¼å°±æ¯æå çº LLM ç¢ççæ¨ç±¤æéè¨èå°è´æè½åæã
çºäºè§£æ±ºéäºåé¡ï¼æ¬ç ç©¶æåº Cellaï¼ä¸åä¸»åèªè¨ç·´æ¶æ§ï¼ä»¥å·æææ¬æççæ¹å¼å° LLM æ´åå° GNN ä¸­ãCella çè¨­è¨ç§è¨£æ¯ä½¿ç¨ GNN è¿­ä»£è­å¥å°çµãééµãæ¨£æ¬ï¼ä¸¦ä½¿ç¨ LLM å GNN ä½çºé¡å¤çç£ç£è¨èï¼çºéäºæ¨£æ¬èåææç¾©çå½æ¨ç±¤ï¼ä»¥å¢å¼·æ¨¡åè¨ç·´ãç¹å¥æ¯ï¼Cella åå«ä¸åä¸»è¦çµæé¨åï¼(i) ä¸åææçç¯é»ä¸»åé¸æç­ç¥ï¼ç¨æ¼åå§è¨»è§£ï¼(ii) ä¸åææºçæ¨£æ¬é¸ææ¹æ¡ï¼æ ¹ææ¨ç±¤ä¸åèª¿æ§åçµç¯©é¸åºãééµãç¯é»ï¼ä»¥å (iii) ä¸åçµå LLM å GNN ä»¥åéæ°é£ç·ææ²çæ¨ç±¤ç²¾ç·»æ¨¡çµãæåå¨äºååºæºæå­å±¬æ§åå½¢è³æéä¸é²è¡çå»£æ³å¯¦é©è¡¨æï¼å¨ç¸åç LLM æ¥è©¢é ç®ä¸ï¼Cella å¨ç¡æ¨ç±¤ç¯é»åé¡æ¹é¢é¡¯èåªæ¼ç¾ææè¡ãç¹å¥æ¯å¨å·æ 14.3k åç¯é»ç DBLP è³æéä¸ï¼Cella è½å¤ ä»¥ä½æ¼ä¸ç¾åçææ¬ï¼å¨æºç¢ºåº¦ä¸æ¯ç¾ææè¡é¡¯èæå 8.08%ã

##### **SE-GCL: An Event-Based Simple and Effective Graph Contrastive Learning for Text Representation**
2412.11652v1 by Tao Meng, Wei Ai, Jianbin Li, Ze Wang, Yuntao Shou, Keqin Li

Text representation learning is significant as the cornerstone of natural
language processing. In recent years, graph contrastive learning (GCL) has been
widely used in text representation learning due to its ability to represent and
capture complex text information in a self-supervised setting. However, current
mainstream graph contrastive learning methods often require the incorporation
of domain knowledge or cumbersome computations to guide the data augmentation
process, which significantly limits the application efficiency and scope of
GCL. Additionally, many methods learn text representations only by constructing
word-document relationships, which overlooks the rich contextual semantic
information in the text. To address these issues and exploit representative
textual semantics, we present an event-based, simple, and effective graph
contrastive learning (SE-GCL) for text representation. Precisely, we extract
event blocks from text and construct internal relation graphs to represent
inter-semantic interconnections, which can ensure that the most critical
semantic information is preserved. Then, we devise a streamlined, unsupervised
graph contrastive learning framework to leverage the complementary nature of
the event semantic and structural information for intricate feature data
capture. In particular, we introduce the concept of an event skeleton for core
representation semantics and simplify the typically complex data augmentation
techniques found in existing graph contrastive learning to boost algorithmic
efficiency. We employ multiple loss functions to prompt diverse embeddings to
converge or diverge within a confined distance in the vector space, ultimately
achieving a harmonious equilibrium. We conducted experiments on the proposed
SE-GCL on four standard data sets (AG News, 20NG, SougouNews, and THUCNews) to
verify its effectiveness in text representation learning.

æè¦ï¼ææ¬è¡¨å¾µå­¸ç¿ä½çºèªç¶èªè¨èççåºç³ï¼å·æéè¦çæç¾©ãè¿å¹´ä¾ï¼åå½¢å°æ¯å­¸ç¿ (GCL) å å¶å¨èªæç£ç£è¨­å®ä¸­è¡¨å¾µåæ·åè¤éææ¬è³è¨çè½åï¼èè¢«å»£æ³ç¨æ¼ææ¬è¡¨å¾µå­¸ç¿ãç¶èï¼ç¶åçä¸»æµåå½¢å°æ¯å­¸ç¿æ¹æ³éå¸¸éè¦å å¥é åç¥è­æç¹ç£çéç®ä¾å¼å°è³ææ´åç¨åºï¼éé¡¯èå°éå¶äº GCL çæç¨æçåç¯åãæ­¤å¤ï¼è¨±å¤æ¹æ³åééå»ºæ§å­è©æä»¶éä¿ä¾å­¸ç¿ææ¬è¡¨å¾µï¼éå¿½ç¥äºææ¬ä¸­è±å¯çèçµ¡èªç¾©è³è¨ãçºäºè§£æ±ºéäºåé¡ä¸¦éç¨å·ä»£è¡¨æ§çææ¬èªç¾©ï¼æåæåºäºä¸ç¨®åºæ¼äºä»¶ãç°¡å®ä¸ææçåå½¢å°æ¯å­¸ç¿ (SE-GCL) ä¾é²è¡ææ¬è¡¨å¾µãå·é«ä¾èªªï¼æåå¾ææ¬ä¸­èåäºä»¶åå¡ä¸¦å»ºæ§å§é¨éä¿åå½¢ä¾è¡¨å¾µèªç¾©éçç¸äºé£çµï¼éè½ç¢ºä¿ä¿çæééµçèªç¾©è³è¨ãæ¥èï¼æåè¨­è¨äºä¸åç°¡åçç¡ç£ç£åå½¢å°æ¯å­¸ç¿æ¶æ§ï¼ä»¥å©ç¨äºä»¶èªç¾©åçµæ§è³è¨çäºè£ç¹æ§ä¾æ·åè¤éçç¹å¾µè³æãç¹å¥å°ï¼æåå¼å¥äºäºä»¶éª¨æ¶çæ¦å¿µï¼ç¨æ¼æ ¸å¿è¡¨å¾µèªç¾©ï¼ä¸¦ç°¡åç¾æåå½¢å°æ¯å­¸ç¿ä¸­éå¸¸è¤éçè³ææ´åæè¡ï¼ä»¥æåæ¼ç®æ³æçãæåæ¡ç¨å¤éæå¤±å½æ¸ä¾ä¿ä½¿ä¸åçåµå¥å¨åéç©ºéä¸­åéè·é¢å§æ¶ææç¼æ£ï¼æçµéæåè«§çå¹³è¡¡ãæåå¨ååæ¨æºè³æé (AG Newsã20NGãSougouNews å THUCNews) ä¸å°ææåºç SE-GCL é²è¡äºå¯¦é©ï¼ä»¥é©è­å¶å¨ææ¬è¡¨å¾µå­¸ç¿ä¸­çæææ§ã

##### **EvoLlama: Enhancing LLMs' Understanding of Proteins via Multimodal Structure and Sequence Representations**
2412.11618v1 by Nuowei Liu, Changzhi Sun, Tao Ji, Junfeng Tian, Jianxin Tang, Yuanbin Wu, Man Lan

Current Large Language Models (LLMs) for understanding proteins primarily
treats amino acid sequences as a text modality. Meanwhile, Protein Language
Models (PLMs), such as ESM-2, have learned massive sequential evolutionary
knowledge from the universe of natural protein sequences. Furthermore,
structure-based encoders like ProteinMPNN learn the structural information of
proteins through Graph Neural Networks. However, whether the incorporation of
protein encoders can enhance the protein understanding of LLMs has not been
explored. To bridge this gap, we propose EvoLlama, a multimodal framework that
connects a structure-based encoder, a sequence-based protein encoder and an LLM
for protein understanding. EvoLlama consists of a ProteinMPNN structure
encoder, an ESM-2 protein sequence encoder, a multimodal projector to align
protein and text representations and a Llama-3 text decoder. To train EvoLlama,
we fine-tune it on protein-oriented instructions and protein property
prediction datasets verbalized via natural language instruction templates. Our
experiments show that EvoLlama's protein understanding capabilities have been
significantly enhanced, outperforming other fine-tuned protein-oriented LLMs in
zero-shot settings by an average of 1%-8% and surpassing the state-of-the-art
baseline with supervised fine-tuning by an average of 6%. On protein property
prediction datasets, our approach achieves promising results that are
competitive with state-of-the-art task-specific baselines. We will release our
code in a future version.

æè¦ï¼ç®åç¨æ¼çè§£èç½è³ªçå¤§åèªè¨æ¨¡å (LLM) ä¸»è¦å°èºåºé¸åºåè¦çºæå­å½¢å¼ãåæï¼èç½è³ªèªè¨æ¨¡å (PLM)ï¼ä¾å¦ ESM-2ï¼å·²å¾èªç¶èç½è³ªåºåçå®å®ä¸­å­¸ç¿å°å¤§éçé åºé²åç¥è­ãæ­¤å¤ï¼å ProteinMPNN ç­åºæ¼çµæ§çç·¨ç¢¼å¨ééåå½¢ç¥ç¶ç¶²è·¯å­¸ç¿èç½è³ªççµæ§è³è¨ãç¶èï¼å°æªæ¢è¨çµåèç½è³ªç·¨ç¢¼å¨æ¯å¦è½å¢å¼· LLM å°èç½è³ªççè§£ãçºäºå½åéåå·®è·ï¼æåæåº EvoLlamaï¼ä¸åå¤æ¨¡ææ¶æ§ï¼å®çµåä¸ååºæ¼çµæ§çç·¨ç¢¼å¨ãä¸ååºæ¼åºåçèç½è³ªç·¨ç¢¼å¨åä¸åç¨æ¼çè§£èç½è³ªç LLMãEvoLlama åå«ä¸å ProteinMPNN çµæ§ç·¨ç¢¼å¨ãä¸å ESM-2 èç½è³ªåºåç·¨ç¢¼å¨ãä¸åå¤æ¨¡ææå½±å¨ï¼ç¨æ¼å°é½èç½è³ªåæå­è¡¨å¾µï¼ä»¥åä¸å Llama-3 æå­è§£ç¢¼å¨ãçºäºè¨ç·´ EvoLlamaï¼æåéå°èç½è³ªå°åçæä»¤åééèªç¶èªè¨æä»¤ç¯æ¬è¡¨éçèç½è³ªå±¬æ§é æ¸¬è³æéå¾®èª¿å®ãæåçå¯¦é©é¡¯ç¤ºï¼EvoLlama çèç½è³ªçè§£è½åå·²ç²å¾é¡¯èæåï¼å¨é¶æ¬¡å­¸ç¿è¨­å®ä¸­ï¼å¹³ååªæ¼å¶ä»å¾®èª¿çèç½è³ªå°å LLM 1%-8%ï¼ä¸¦å¨æç£ç£çå¾®èª¿ä¸­å¹³ååªæ¼æåé²çåºæº 6%ãå¨èç½è³ªå±¬æ§é æ¸¬è³æéä¸ï¼æåçåæ³éå°äºæå¸æççµæï¼èæåé²çç¹å®ä»»ååºæºç¸ç¶ãæåå°å¨æªä¾çæ¬ä¸­éåºæåçç¨å¼ç¢¼ã

##### **Embodied CoT Distillation From LLM To Off-the-shelf Agents**
2412.11499v1 by Wonje Choi, Woo Kyung Kim, Minjong Yoo, Honguk Woo

We address the challenge of utilizing large language models (LLMs) for
complex embodied tasks, in the environment where decision-making systems
operate timely on capacity-limited, off-the-shelf devices. We present DeDer, a
framework for decomposing and distilling the embodied reasoning capabilities
from LLMs to efficient, small language model (sLM)-based policies. In DeDer,
the decision-making process of LLM-based strategies is restructured into a
hierarchy with a reasoning-policy and planning-policy. The reasoning-policy is
distilled from the data that is generated through the embodied in-context
learning and self-verification of an LLM, so it can produce effective
rationales. The planning-policy, guided by the rationales, can render optimized
plans efficiently. In turn, DeDer allows for adopting sLMs for both policies,
deployed on off-the-shelf devices. Furthermore, to enhance the quality of
intermediate rationales, specific to embodied tasks, we devise the embodied
knowledge graph, and to generate multiple rationales timely through a single
inference, we also use the contrastively prompted attention model. Our
experiments with the ALFRED benchmark demonstrate that DeDer surpasses leading
language planning and distillation approaches, indicating the applicability and
efficiency of sLM-based embodied policies derived through DeDer.

æè¦ï¼æåè§£æ±ºäºå¨æ±ºç­ç³»çµ±æ¼å®¹éæéçç¾æè¨­åä¸å³æéä½çç°å¢ä¸­ï¼å©ç¨å¤§åèªè¨æ¨¡å (LLM) å·è¡è¤éå·èº«ä»»åçææ°ãæåæåº DeDerï¼ä¸åç¨æ¼å°å·èº«æ¨çè½åå¾ LLM åè§£ä¸¦èååºé«æè½ãå°åèªè¨æ¨¡å (sLM) çºåºç¤çæ¿ç­çæ¡æ¶ãå¨ DeDer ä¸­ï¼åºæ¼ LLM çç­ç¥çæ±ºç­æµç¨è¢«éæ°çµæ§çºä¸åå·ææ¨çæ¿ç­åè¦åæ¿ç­çéå±¤ãæ¨çæ¿ç­å¾éé LLM çå·èº«æå¢å­¸ç¿åèªæé©è­æç¢ççè³æä¸­èååºï¼å æ­¤å®å¯ä»¥ç¢çææçä¾æãè¦åæ¿ç­å¨ä¾æçå¼å°ä¸ï¼å¯ä»¥ææçå°åç¾æä½³åçè¨ç«ãåéä¾ï¼DeDer åè¨±æ¡ç¨ sLM ä¾å·è¡éå©åæ¿ç­ï¼ä¸¦é¨ç½²å¨ç¾æè¨­åä¸ãæ­¤å¤ï¼çºäºæåä¸­éä¾æçåè³ªï¼ç¹å¥æ¯éå°å·èº«ä»»åï¼æåè¨­è¨äºå·èº«ç¥è­åè­ï¼ä¸¦ééå®ä¸æ¨è«å³æç¢çå¤åä¾æï¼æåä¹ä½¿ç¨äºå°æ¯æç¤ºæ³¨æåæ¨¡åãæåä½¿ç¨ ALFRED åºæºé²è¡çå¯¦é©è­æï¼DeDer è¶è¶äºé åçèªè¨è¦ååèåæ¹æ³ï¼éè¡¨ç¤ºéé DeDer è¡ççåºæ¼ sLM çå·èº«æ¿ç­å·æé©ç¨æ§åæçã

##### **Structured Extraction of Real World Medical Knowledge using LLMs for Summarization and Search**
2412.15256v1 by Edward Kim, Manil Shrestha, Richard Foty, Tom DeLay, Vicki Seyfert-Margolis

Creation and curation of knowledge graphs can accelerate disease discovery
and analysis in real-world data. While disease ontologies aid in biological
data annotation, codified categories (SNOMED-CT, ICD10, CPT) may not capture
patient condition nuances or rare diseases. Multiple disease definitions across
data sources complicate ontology mapping and disease clustering. We propose
creating patient knowledge graphs using large language model extraction
techniques, allowing data extraction via natural language rather than rigid
ontological hierarchies. Our method maps to existing ontologies (MeSH,
SNOMED-CT, RxNORM, HPO) to ground extracted entities.
  Using a large ambulatory care EHR database with 33.6M patients, we
demonstrate our method through the patient search for Dravet syndrome, which
received ICD10 recognition in October 2020. We describe our construction of
patient-specific knowledge graphs and symptom-based patient searches. Using
confirmed Dravet syndrome ICD10 codes as ground truth, we employ LLM-based
entity extraction to characterize patients in grounded ontologies. We then
apply this method to identify Beta-propeller protein-associated
neurodegeneration (BPAN) patients, demonstrating real-world discovery where no
ground truth exists.

æè¦ï¼ç¥è­åè­çå»ºç«åç­å±å¯ä»¥å éç¾çç¼ç¾ååæçå¯¦ä¸çä¸­çè³æãéç¶ç¾çæ¬é«è«æå©æ¼çç©è³æè¨»éï¼ä½ç·¨ç¢¼é¡å¥ï¼SNOMED-CTãICD10ãCPTï¼å¯è½ç¡æ³æææ£èçæ³çç´°å¾®å·®å¥æç½è¦ç¾çãè·¨è³æä¾æºçå¤éç¾çå®ç¾©ä½¿æ¬é«è«å°æåç¾çç¾¤éè¤éåãæåå»ºè­°ä½¿ç¨å¤§åèªè¨æ¨¡åèåæè¡å»ºç«æ£èç¥è­åè­ï¼åè¨±ééèªç¶èªè¨èä¸æ¯åµåçæ¬é«è«éå±¤èåè³æãæåçæ¨¡åå°æå°ç¾ææ¬é«è«ï¼MeSHãSNOMED-CTãRxNORMãHPOï¼ä»¥å»ºç«èåå¯¦é«çåºç¤ãä½¿ç¨ä¸åææ 3360 è¬åæ£èçå¤§åéè¨ºé»å­çæ­·è³æåº«ï¼æåééæ£èæå° Dravet çåç¾¤ä¾å±ç¤ºæåçæ¨¡åï¼è©²çåç¾¤æ¼ 2020 å¹´ 10 æç²å¾ ICD10 èªå¯ãæåæè¿°æåå¦ä½å»ºæ§æ£èç¹å®çç¥è­åè­ååºæ¼çççæ£èæå°ãä½¿ç¨å·²ç¢ºèªç Dravet çåç¾¤ ICD10 ä»£ç¢¼ä½çºåºæºï¼æåä½¿ç¨åºæ¼ LLM çå¯¦é«èåä¾æè¿°ç´®æ ¹æ¼æ¬é«è«ä¸­çæ£èãç¶å¾æåæç¨æ­¤æ¨¡åä¾è­å¥è²å¡èºææ§³èç½ç¸éçç¥ç¶éåï¼BPANï¼æ£èï¼å±ç¤ºäºå¨ä¸å­å¨åºæºçææ³ä¸é²è¡çå¯¦ä¸çç¼ç¾ã

##### **How Can LLMs and Knowledge Graphs Contribute to Robot Safety? A Few-Shot Learning Approach**
2412.11387v1 by Abdulrahman Althobaiti, Angel Ayala, JingYing Gao, Ali Almutairi, Mohammad Deghat, Imran Razzak, Francisco Cruz

Large Language Models (LLMs) are transforming the robotics domain by enabling
robots to comprehend and execute natural language instructions. The cornerstone
benefits of LLM include processing textual data from technical manuals,
instructions, academic papers, and user queries based on the knowledge
provided. However, deploying LLM-generated code in robotic systems without
safety verification poses significant risks. This paper outlines a safety layer
that verifies the code generated by ChatGPT before executing it to control a
drone in a simulated environment. The safety layer consists of a fine-tuned
GPT-4o model using Few-Shot learning, supported by knowledge graph prompting
(KGP). Our approach improves the safety and compliance of robotic actions,
ensuring that they adhere to the regulations of drone operations.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) ééè®æ©å¨äººçè§£ä¸¦å·è¡èªç¶èªè¨æä»¤ï¼è½è®äºæ©å¨äººé åãLLM çåºç³åªé»åæ¬èçåºæ¼ææä¾ç¥è­çæè¡æåãèªªæãå­¸è¡è«æåä½¿ç¨èæ¥è©¢ä¸­çæå­è³æãç¶èï¼å¨æ²æå®å¨é©è­çææ³ä¸ï¼å¨æ©å¨äººç³»çµ±ä¸­é¨ç½² LLM çæçç¨å¼ç¢¼æå¸¶ä¾é¡¯èçé¢¨éªãæ¬ææ¦è¿°äºä¸åå®å¨å±¤ï¼å¨å·è¡å®ä»¥æ§å¶æ¨¡æ¬ç°å¢ä¸­çç¡äººæ©ä¹åï¼é©è­ ChatGPT çæçç¨å¼ç¢¼ãå®å¨å±¤ç±ä¸åä½¿ç¨å°æ¬¡å­¸ç¿é²è¡å¾®èª¿ç GPT-4o æ¨¡åçµæï¼ä¸¦ç±ç¥è­åè¡¨æç¤º (KGP) æ¯æ´ãæåçåæ³æ¹åäºæ©å¨äººåä½çå®å¨æ§èåè¦æ§ï¼ç¢ºä¿å®åç¬¦åç¡äººæ©æä½æ³è¦ã

##### **Embracing Large Language Models in Traffic Flow Forecasting**
2412.12201v1 by Yusheng Zhao, Xiao Luo, Haomin Wen, Zhiping Xiao, Wei Ju, Ming Zhang

Traffic flow forecasting aims to predict future traffic flows based on the
historical traffic conditions and the road network. It is an important problem
in intelligent transportation systems, with a plethora of methods been
proposed. Existing efforts mainly focus on capturing and utilizing
spatio-temporal dependencies to predict future traffic flows. Though promising,
they fall short in adapting to test-time environmental changes of traffic
conditions. To tackle this challenge, we propose to introduce large language
models (LLMs) to help traffic flow forecasting and design a novel method named
Large Language Model Enhanced Traffic Flow Predictor (LEAF). LEAF adopts two
branches, capturing different spatio-temporal relations using graph and
hypergraph structures respectively. The two branches are first pre-trained
individually, and during test-time, they yield different predictions. Based on
these predictions, a large language model is used to select the most likely
result. Then, a ranking loss is applied as the learning objective to enhance
the prediction ability of the two branches. Extensive experiments on several
datasets demonstrate the effectiveness of the proposed LEAF.

æè¦ï¼äº¤éæµéé æ¸¬æ¨å¨æ ¹ææ­·å²äº¤éçæ³åéè·¯ç¶²è·¯é æ¸¬æªä¾çäº¤éæµéãéæ¯æºæ§éè¼¸ç³»çµ±ä¸­ä¸åéè¦çåé¡ï¼å·²ç¶æåºäºè¨±å¤æ¹æ³ãç¾æåªåä¸»è¦éä¸­å¨æ·ååå©ç¨æç©ºä¾è³´æ§ä¾é æ¸¬æªä¾çäº¤éæµéãåç®¡æåæ¯ï¼ä½å®åå¨é©æäº¤éçæ³çæ¸¬è©¦æéç°å¢è®åæ¹é¢ä»æä¸è¶³ãçºäºæå°éä¸ææ°ï¼æåå»ºè­°å¼å¥å¤§åèªè¨æ¨¡å (LLM) ä¾å¹«å©äº¤éæµéé æ¸¬ï¼ä¸¦è¨­è¨ä¸ç¨®åçºå¤§åèªè¨æ¨¡åå¢å¼·äº¤éæµéé æ¸¬å¨ (LEAF) çæ°æ¹æ³ãLEAF æ¡ç¨å©ååæ¯ï¼åå¥ä½¿ç¨åå½¢åè¶åå½¢çµæ§æ·åä¸åçæç©ºéä¿ãéå©ååæ¯é¦ååå¥é²è¡é è¨ç·´ï¼å¨æ¸¬è©¦æï¼å®åç¢çä¸åçé æ¸¬ãåºæ¼éäºé æ¸¬ï¼ä½¿ç¨å¤§åèªè¨æ¨¡åé¸æææå¯è½ççµæãç¶å¾ï¼å°æåæå¤±æç¨çºå­¸ç¿ç®æ¨ï¼ä»¥å¢å¼·å©ååæ¯çé æ¸¬è½åãå¨å¹¾åæ¸æéä¸é²è¡çå»£æ³å¯¦é©è­æäºææåºç LEAF çæææ§ã

##### **SceneLLM: Implicit Language Reasoning in LLM for Dynamic Scene Graph Generation**
2412.11026v1 by Hang Zhang, Zhuoling Li, Jun Liu

Dynamic scenes contain intricate spatio-temporal information, crucial for
mobile robots, UAVs, and autonomous driving systems to make informed decisions.
Parsing these scenes into semantic triplets <Subject-Predicate-Object> for
accurate Scene Graph Generation (SGG) is highly challenging due to the
fluctuating spatio-temporal complexity. Inspired by the reasoning capabilities
of Large Language Models (LLMs), we propose SceneLLM, a novel framework that
leverages LLMs as powerful scene analyzers for dynamic SGG. Our framework
introduces a Video-to-Language (V2L) mapping module that transforms video
frames into linguistic signals (scene tokens), making the input more
comprehensible for LLMs. To better encode spatial information, we devise a
Spatial Information Aggregation (SIA) scheme, inspired by the structure of
Chinese characters, which encodes spatial data into tokens. Using Optimal
Transport (OT), we generate an implicit language signal from the frame-level
token sequence that captures the video's spatio-temporal information. To
further improve the LLM's ability to process this implicit linguistic input, we
apply Low-Rank Adaptation (LoRA) to fine-tune the model. Finally, we use a
transformer-based SGG predictor to decode the LLM's reasoning and predict
semantic triplets. Our method achieves state-of-the-art results on the Action
Genome (AG) benchmark, and extensive experiments show the effectiveness of
SceneLLM in understanding and generating accurate dynamic scene graphs.

æè¦ï¼åæå ´æ¯åå«è¤éçæç©ºè³è¨ï¼å°æ¼è¡åæ©å¨äººãç¡äººæ©åèªåé§é§ç³»çµ±ååºææºçæ±ºç­è³ééè¦ã
ç±æ¼æç©ºè¤éæ§æ³¢åï¼å°éäºå ´æ¯è§£ææèªç¾©ä¸åçµ <ä¸»è©-è¬è©-åè©> ä»¥é²è¡æºç¢ºçå ´æ¯åçæ (SGG) æ¯ä¸é æ¥µå·ææ°æ§çä»»åã
åå°å¤§åèªè¨æ¨¡å (LLM) çæ¨çè½ååç¼ï¼æåæåºäº SceneLLMï¼éæ¯ä¸åæ°ç©çæ¡æ¶ï¼å©ç¨ LLM ä½çºå¼·å¤§çå ´æ¯åæå¨ï¼ç¨æ¼åæ SGGã
æåçæ¡æ¶å¼å¥äºä¸åå½±çè½èªè¨ (V2L) æ å°æ¨¡çµï¼å°å½±çæ ¼è½ææèªè¨è¨è (å ´æ¯ä»£å¹£)ï¼è® LLM æ´å®¹æçè§£è¼¸å¥ã
çºäºæ´å¥½å°ç·¨ç¢¼ç©ºéè³è¨ï¼æåè¨­è¨äºä¸åç©ºéè³è¨èå (SIA) æ¶æ§ï¼å¶éæä¾èªæ¼¢å­ççµæ§ï¼å°ç©ºéè³æç·¨ç¢¼æä»£å¹£ã
ä½¿ç¨æä½³å³è¼¸ (OT)ï¼æåå¾å¹ç´ä»£å¹£åºåç¢çä¸åé±å«çèªè¨è¨èï¼ææå½±ççæç©ºè³è¨ã
çºäºé²ä¸æ­¥æé« LLM èçæ­¤é±å«èªè¨è¼¸å¥çè½åï¼æåæç¨ä½ç§©é©æ (LoRA) ä¾å¾®èª¿æ¨¡åã
æå¾ï¼æåä½¿ç¨ä¸ååºæ¼è½æå¨ç SGG é æ¸¬å¨ä¾è§£ç¢¼ LLM çæ¨çä¸¦é æ¸¬èªç¾©ä¸åçµã
æåçæ¨¡åå¨åä½åºå çµ (AG) åºæºä¸åå¾äºæåé²ççµæï¼å»£æ³çå¯¦é©é¡¯ç¤ºäº SceneLLM å¨çè§£åçææºç¢ºçåæå ´æ¯åæ¹é¢çæææ§ã

##### **MedG-KRP: Medical Graph Knowledge Representation Probing**
2412.10982v2 by Gabriel R. Rosenbaum, Lavender Yao Jiang, Ivaxi Sheth, Jaden Stryker, Anton Alyakin, Daniel Alexander Alber, Nicolas K. Goff, Young Joon Fred Kwon, John Markert, Mustafa Nasir-Moin, Jan Moritz Niehues, Karl L. Sangwon, Eunice Yang, Eric Karl Oermann

Large language models (LLMs) have recently emerged as powerful tools, finding
many medical applications. LLMs' ability to coalesce vast amounts of
information from many sources to generate a response-a process similar to that
of a human expert-has led many to see potential in deploying LLMs for clinical
use. However, medicine is a setting where accurate reasoning is paramount. Many
researchers are questioning the effectiveness of multiple choice question
answering (MCQA) benchmarks, frequently used to test LLMs. Researchers and
clinicians alike must have complete confidence in LLMs' abilities for them to
be deployed in a medical setting. To address this need for understanding, we
introduce a knowledge graph (KG)-based method to evaluate the biomedical
reasoning abilities of LLMs. Essentially, we map how LLMs link medical concepts
in order to better understand how they reason. We test GPT-4, Llama3-70b, and
PalmyraMed-70b, a specialized medical model. We enlist a panel of medical
students to review a total of 60 LLM-generated graphs and compare these graphs
to BIOS, a large biomedical KG. We observe GPT-4 to perform best in our human
review but worst in our ground truth comparison; vice-versa with PalmyraMed,
the medical model. Our work provides a means of visualizing the medical
reasoning pathways of LLMs so they can be implemented in clinical settings
safely and effectively.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) è¿æå·²æçºå¼·å¤§çå·¥å·ï¼å¨é«çé åä¸­ç¼ç¾è¨±å¤æç¨ãLLM å¾è¨±å¤ä¾æºå¯éå¤§éè³è¨ä»¥ç¢çåæçè½åï¼æ­¤éç¨é¡ä¼¼æ¼äººé¡å°å®¶çéç¨ï¼ï¼å·²è®è¨±å¤äººçå°å° LLM é¨ç½²æ¼è¨åºç¨éçæ½åãç¶èï¼é«å­¸æ¯ä¸åæºç¢ºæ¨çè³ééè¦çé åãè¨±å¤ç ç©¶äººå¡è³ªçå¤é¸é¡åç­ (MCQA) åºæºçæææ§ï¼èéç¶å¸¸è¢«ç¨æ¼æ¸¬è©¦ LLMãç ç©¶äººå¡åè¨åºé«çé½å¿é å° LLM çè½åæå®å¨çä¿¡å¿ï¼æè½å°å¶é¨ç½²æ¼é«çç°å¢ä¸­ãçºäºæ»¿è¶³éç¨®çè§£éæ±ï¼æåå¼å¥ä¸ååºæ¼ç¥è­åè­ (KG) çæ¹æ³ä¾è©ä¼° LLM ççç©é«å­¸æ¨çè½åãåºæ¬ä¸ï¼æåç¹ªè£½ LLM å¦ä½é£çµé«çæ¦å¿µï¼ä»¥æ´å¥½å°çè§£å®åçæ¨çæ¹å¼ãæåæ¸¬è©¦äº GPT-4ãLlama3-70b å PalmyraMed-70bï¼éæ¯ä¸åå°éçé«çæ¨¡åãæåå¾µéäºä¸çµé«å­¸çä¾æª¢é±ç¸½å± 60 å LLM çæçåè¡¨ï¼ä¸¦å°éäºåè¡¨è BIOSï¼ä¸åå¤§åçç©é«å­¸ KGï¼é²è¡æ¯è¼ãæåè§å¯å° GPT-4 å¨æåçäººå·¥å¯©æ¥ä¸­è¡¨ç¾æä½³ï¼ä½å¨æåçåºæ¬äºå¯¦æ¯è¼ä¸­è¡¨ç¾æå·®ï¼èå°éçé«çæ¨¡å PalmyraMed åç¸åãæåçç ç©¶æä¾äºä¸ç¨®å¯è¦å LLM é«çæ¨çè·¯å¾çæ¹æ³ï¼ä»¥ä¾¿å®åè½å¤ å®å¨ææå°å¯¦ä½æ¼è¨åºç°å¢ä¸­ã

##### **Thinking with Knowledge Graphs: Enhancing LLM Reasoning Through Structured Data**
2412.10654v1 by Xue Wu, Kostas Tsioutsiouliklis

Large Language Models (LLMs) have demonstrated remarkable capabilities in
natural language understanding and generation. However, they often struggle
with complex reasoning tasks and are prone to hallucination. Recent research
has shown promising results in leveraging knowledge graphs (KGs) to enhance LLM
performance. KGs provide a structured representation of entities and their
relationships, offering a rich source of information that can enhance the
reasoning capabilities of LLMs. For this work, we have developed different
techniques that tightly integrate KG structures and semantics into LLM
representations. Our results show that we are able to significantly improve the
performance of LLMs in complex reasoning scenarios, and ground the reasoning
process with KGs. We are the first to represent KGs with programming language
and fine-tune pretrained LLMs with KGs. This integration facilitates more
accurate and interpretable reasoning processes, paving the way for more
advanced reasoning capabilities of LLMs.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å¨èªç¶èªè¨çè§£åçææ¹é¢å±ç¾äºéå¡çè½åãç¶èï¼å®åç¶å¸¸å¨è¤éçæ¨çä»»åä¸­ææï¼ä¸¦ä¸å®¹æåºç¾å¹»è¦ºãæè¿çç ç©¶é¡¯ç¤ºåºå©ç¨ç¥è­åè­ (KG) ä¾å¢å¼· LLM æè½çè¯å¥½çµæãKG æä¾å¯¦é«åå¶éä¿ççµæ§åè¡¨ç¤ºï¼æä¾äºè±å¯çè³è¨ä¾æºï¼å¯ä»¥å¢å¼· LLM çæ¨çè½åãå°æ¼éé å·¥ä½ï¼æåéç¼äºä¸åçæè¡ï¼å° KG çµæ§åèªç¾©ç·å¯æ´åå° LLM è¡¨ç¤ºä¸­ãæåççµæè¡¨æï¼æåè½å¤ é¡¯èæå LLM å¨è¤éæ¨çå ´æ¯ä¸­çæè½ï¼ä¸¦ä»¥ KG çºåºç¤é²è¡æ¨çéç¨ãæåæ¯ç¬¬ä¸åä½¿ç¨ç¨å¼èªè¨è¡¨ç¤º KGï¼ä¸¦ä½¿ç¨ KG å¾®èª¿é è¨ç·´ LLM çäººãéç¨®æ´åæå©æ¼æ´æºç¢ºä¸å¯è§£éçæ¨çéç¨ï¼çº LLM æ´åé²çæ¨çè½åéªè·¯ã

##### **WHAT-IF: Exploring Branching Narratives by Meta-Prompting Large Language Models**
2412.10582v2 by Runsheng "Anson" Huang, Lara J. Martin, Chris Callison-Burch

WHAT-IF -- Writing a Hero's Alternate Timeline through Interactive Fiction --
is a system that uses zero-shot meta-prompting to create branching narratives
from a prewritten story. Played as an interactive fiction (IF) game, WHAT-IF
lets the player choose between decisions that the large language model (LLM)
GPT-4 generates as possible branches in the story. Starting with an existing
linear plot as input, a branch is created at each key decision taken by the
main character. By meta-prompting the LLM to consider the major plot points
from the story, the system produces coherent and well-structured alternate
storylines. WHAT-IF stores the branching plot tree in a graph which helps it to
both keep track of the story for prompting and maintain the structure for the
final IF system. A video demo of our system can be found here:
https://youtu.be/8vBqjqtupcc.

æè¦ï¼WHAT-IFââééäºåå°èªªæ°å¯«è±éçå¦é¡æéç·ââ
æ¯ä¸åä½¿ç¨é¶æ¬¡æç¤ºä¾å»ºç«å¾é åæ°å¯«çæäºåæ­§æäºçç³»çµ±ãä»¥äºåå°èªª (IF) éæ²çæ¹å¼éç©ï¼WHAT-IF
è®ç©å®¶å¨å¤§åèªè¨æ¨¡å (LLM)
GPT-4 ç¢ççæäºä¸­å¯è½çæ¯ç·ä¸­é¸ææ±ºå®ãå¾ç¾æçç·æ§æç¯ä½çºè¼¸å¥éå§ï¼å¨ä¸»è¦è§è²ååºçæ¯åééµæ±ºå®ä¸­ç¢çä¸åæ¯ç·ãééåæç¤º LLM èéæäºä¸­çä¸»è¦æç¯ï¼ç³»çµ±ç¢çé£è²«ä¸çµæ§è¯å¥½çå¦é¡æäºç·ãWHAT-IF å°åæ­§æç¯æ¨¹å²å­å¨åå½¢ä¸­ï¼éæå©æ¼å®åæè¿½è¹¤æäºä»¥æç¤ºåç¶­è­·æçµ IF ç³»çµ±ççµæ§ãæåç³»çµ±çå½±çç¤ºç¯å¯ä»¥å¨éè£¡æ¾å°ï¼
https://youtu.be/8vBqjqtupccã

##### **A Decade of Deep Learning: A Survey on The Magnificent Seven**
2412.16188v1 by Dilshod Azizov, Muhammad Arslan Manzoor, Velibor Bojkovic, Yingxu Wang, Zixiao Wang, Zangir Iklassov, Kailong Zhao, Liang Li, Siwei Liu, Yu Zhong, Wei Liu, Shangsong Liang

Deep learning has fundamentally reshaped the landscape of artificial
intelligence over the past decade, enabling remarkable achievements across
diverse domains. At the heart of these developments lie multi-layered neural
network architectures that excel at automatic feature extraction, leading to
significant improvements in machine learning tasks. To demystify these advances
and offer accessible guidance, we present a comprehensive overview of the most
influential deep learning algorithms selected through a broad-based survey of
the field. Our discussion centers on pivotal architectures, including Residual
Networks, Transformers, Generative Adversarial Networks, Variational
Autoencoders, Graph Neural Networks, Contrastive Language-Image Pre-training,
and Diffusion models. We detail their historical context, highlight their
mathematical foundations and algorithmic principles, and examine subsequent
variants, extensions, and practical considerations such as training
methodologies, normalization techniques, and learning rate schedules. Beyond
historical and technical insights, we also address their applications,
challenges, and potential research directions. This survey aims to serve as a
practical manual for both newcomers seeking an entry point into cutting-edge
deep learning methods and experienced researchers transitioning into this
rapidly evolving domain.

æè¦ï¼æ·±åº¦å­¸ç¿å¨éå»åå¹´ä¸­å¾æ ¹æ¬ä¸éå¡äºäººå·¥æºæ§çæ ¼å±ï¼å¨ååé ååå¾äºé¡¯èçæå°±ãéäºç¼å±çæ ¸å¿æ¯å¤å±¤ç¥ç¶ç¶²è·¯æ¶æ§ï¼å®æé·èªåç¹å¾µæåï¼å¾èé¡¯èæ¹é²æ©å¨å­¸ç¿ä»»åãçºäºæ­ééäºé²æ­¥çç¥ç§é¢ç´ä¸¦æä¾ææ¼çè§£çæå°ï¼æåå°ééå»£æ³çé åèª¿æ¥æé¸åºçææå½±é¿åçæ·±åº¦å­¸ç¿æ¼ç®æ³é²è¡äºå¨é¢çæ¦è¿°ãæåçè¨è«éä¸­å¨ééµæ¶æ§ä¸ï¼åæ¬æ®å·®ç¶²è·¯ãTransformerãçæå°æç¶²è·¯ãè®ç°èªåç·¨ç¢¼å¨ãåç¥ç¶ç¶²è·¯ãå°æ¯èªè¨å½±åé è¨ç·´åæ´æ£æ¨¡åãæåè©³ç´°èªªæäºå®åçæ­·å²èæ¯ï¼éé»ä»ç´¹äºå®åçæ¸å­¸åºç¤åæ¼ç®æ³åçï¼ä¸¦æ¢è¨äºå¾çºçè®é«ãæ´ååå¯¦åèéï¼ä¾å¦è¨ç·´æ¹æ³ãæ­£è¦åæè¡åå­¸ç¿çè¦åãé¤äºæ­·å²åæè¡è¦è§£ä¹å¤ï¼æåéæ¢è¨äºå®åçæç¨ãææ°åæ½å¨çç ç©¶æ¹åãæ¬èª¿æ¥æ¨å¨ä½çºä¸æ¬å¯¦åæåï¼æ¢é©åå°æ±é²å¥å°ç«¯æ·±åº¦å­¸ç¿æ¹æ³çæ°æï¼ä¹é©åè½åå°éåå¿«éç¼å±é åçç¶é©è±å¯çç ç©¶äººå¡ã

##### **Can LLMs Convert Graphs to Text-Attributed Graphs?**
2412.10136v1 by Zehong Wang, Sidney Liu, Zheyuan Zhang, Tianyi Ma, Chuxu Zhang, Yanfang Ye

Graphs are ubiquitous data structures found in numerous real-world
applications, such as drug discovery, recommender systems, and social network
analysis. Graph neural networks (GNNs) have become a popular tool to learn node
embeddings through message passing on these structures. However, a significant
challenge arises when applying GNNs to multiple graphs with different feature
spaces, as existing GNN architectures are not designed for cross-graph feature
alignment. To address this, recent approaches introduce text-attributed graphs,
where each node is associated with a textual description, enabling the use of a
shared textual encoder to project nodes from different graphs into a unified
feature space. While promising, this method relies heavily on the availability
of text-attributed data, which can be difficult to obtain in practice. To
bridge this gap, we propose a novel method named Topology-Aware Node
description Synthesis (TANS), which leverages large language models (LLMs) to
automatically convert existing graphs into text-attributed graphs. The key idea
is to integrate topological information with each node's properties, enhancing
the LLMs' ability to explain how graph topology influences node semantics. We
evaluate our TANS on text-rich, text-limited, and text-free graphs,
demonstrating that it enables a single GNN to operate across diverse graphs.
Notably, on text-free graphs, our method significantly outperforms existing
approaches that manually design node features, showcasing the potential of LLMs
for preprocessing graph-structured data, even in the absence of textual
information. The code and data are available at
https://github.com/Zehong-Wang/TANS.

æè¦ï¼åå½¢æ¯æ®éå­å¨æ¼è¨±å¤çå¯¦ä¸çæç¨ä¸­çè³æçµæ§ï¼ä¾å¦è¥ç©ç¼ç¾ãæ¨è¦ç³»çµ±åç¤¾äº¤ç¶²è·¯åæãåå½¢ç¥ç¶ç¶²è·¯ (GNN) å·²æçºä¸ç¨®æµè¡çå·¥å·ï¼å¯ééå¨éäºçµæ§ä¸å³éè¨æ¯ä¾å­¸ç¿ç¯é»åµå¥ãç¶èï¼ç¶å° GNN æç¨æ¼å·æä¸åç¹å¾µç©ºéçå¤ååå½¢æï¼æåºç¾ä¸åéå¤§çææ°ï¼å çºç¾æç GNN æ¶æ§ä¸¦éè¨­è¨ç¨æ¼è·¨åå½¢ç¹å¾µå°é½ãçºäºè§£æ±ºéååé¡ï¼æè¿çæ¹æ³å¼å¥äºæå­å±¬æ§åå½¢ï¼å¶ä¸­æ¯åç¯é»é½èæå­æè¿°ç¸éè¯ï¼å¾èå¯ä»¥ä½¿ç¨å±ç¨æå­ç·¨ç¢¼å¨å°ä¾èªä¸ååå½¢çç¯é»æå½±å°çµ±ä¸çç¹å¾µç©ºéä¸­ãåç®¡æå¸æï¼ä½æ­¤æ¹æ³å¨å¾å¤§ç¨åº¦ä¸ä¾è³´æ¼æå­å±¬æ§è³æçå¯ç¨æ§ï¼éå¨å¯¦åä¸å¯è½é£ä»¥åå¾ãçºäºå½è£éåå·®è·ï¼æåæåºäºä¸ç¨®åçºææ²æç¥ç¯é»æè¿°åæ (TANS) çæ°æ¹æ³ï¼è©²æ¹æ³å©ç¨å¤§åèªè¨æ¨¡å (LLM) å°ç¾æåå½¢èªåè½æçºæå­å±¬æ§åå½¢ãå¶ééµææ³æ¯å°ææ²è³è¨èæ¯åç¯é»çå±¬æ§æ´åå¨ä¸èµ·ï¼å¢å¼· LLM è§£éåå½¢ææ²å¦ä½å½±é¿ç¯é»èªç¾©çè½åãæåå¨æå­è±å¯ãæå­åéåç¡æå­åå½¢ä¸è©ä¼°æåç TANSï¼è­æå®è½è®å®ä¸ GNN å¨ä¸åçåå½¢ä¸­éä½ãå¼å¾æ³¨æçæ¯ï¼å¨ç¡æå­åå½¢ä¸ï¼æåçæ¨¡åé¡¯èåªæ¼æåè¨­è¨ç¯é»ç¹å¾µçç¾ææ¹æ³ï¼å±ç¤ºäº LLM å¨é èçåå½¢çµæ§è³ææ¹é¢çæ½åï¼å³ä½¿å¨æ²ææå­è³è¨çææ³ä¸ä¹æ¯å¦æ­¤ãç¨å¼ç¢¼åè³æå¯å¨ https://github.com/Zehong-Wang/TANS åå¾ã

##### **Lost in the Middle, and In-Between: Enhancing Language Models' Ability to Reason Over Long Contexts in Multi-Hop QA**
2412.10079v1 by George Arthur Baker, Ankush Raut, Sagi Shaier, Lawrence E Hunter, Katharina von der Wense

Previous work finds that recent long-context language models fail to make
equal use of information in the middle of their inputs, preferring pieces of
information located at the tail ends which creates an undue bias in situations
where we would like models to be equally capable of using different parts of
the input. Thus far, the problem has mainly only been considered in settings
with single pieces of critical information, leading us to question what happens
when multiple necessary pieces of information are spread out over the inputs.
Here, we demonstrate the effects of the "lost in the middle" problem in the
multi-hop question answering setting -- in which multiple reasoning "hops" over
disconnected documents are required -- and show that performance degrades not
only with respect to the distance of information from the edges of the context,
but also between pieces of information. Additionally, we experiment with means
of alleviating the problem by reducing superfluous document contents through
knowledge graph triple extraction and summarization, and prompting models to
reason more thoroughly using chain-of-thought prompting.

æè¦ï¼ååçç ç©¶ç¼ç¾ï¼æè¿çé·èªå¢èªè¨æ¨¡åç¡æ³å¹³åå©ç¨å¶è¼¸å¥ä¸­æ®µçè³è¨ï¼åå¥½ä½æ¼å°¾ç«¯çè³è¨çæ®µï¼éæé æä¸ç¶çåå·®ï¼å¨æåå¸ææ¨¡åè½å¹³åä½¿ç¨è¼¸å¥ä¸åé¨åçææ³ä¸ãå°ç®åçºæ­¢ï¼éååé¡ä¸»è¦åªå¨å·æå®ä¸ééµè³è¨çæ®µçè¨­å®ä¸­è¢«èæ®ï¼å°è´æåè³ªçç¶å¤åå¿è¦çè³è¨çæ®µæ£ä½å¨è¼¸å¥ä¸­ææç¼çä»éº¼ææ³ãå¨æ­¤ï¼æåç¤ºç¯äºãéºå¤±å¨ä¸­éãåé¡å¨å¤è·³åç­è¨­å®ä¸­çå½±é¿ï¼å¶ä¸­éè¦è·¨è¶æªé£æ¥æä»¶çå¤æ¬¡æ¨çãè·³èºãï¼ä¸¦é¡¯ç¤ºæè½ä¸åæé¨èè³è¨èèªå¢éç·£çè·é¢èä¸éï¼ä¹æé¨èè³è¨çæ®µä¹éçè·é¢èä¸éãæ­¤å¤ï¼æåå¯¦é©äºééç¥è­åè­ä¸åçµèååæè¦ä¾æ¸å°å¤é¤æä»¶å§å®¹ï¼ä¸¦æç¤ºæ¨¡åä½¿ç¨æèéæç¤ºä¾æ´å¾¹åºå°æ¨çï¼ä»¥æ¸è¼åé¡çæ¹æ³ã

##### **Low-Resource Fast Text Classification Based on Intra-Class and Inter-Class Distance Calculation**
2412.09922v1 by Yanxu Mao, Peipei Liu, Tiehan Cui, Congying Liu, Datao You

In recent years, text classification methods based on neural networks and
pre-trained models have gained increasing attention and demonstrated excellent
performance. However, these methods still have some limitations in practical
applications: (1) They typically focus only on the matching similarity between
sentences. However, there exists implicit high-value information both within
sentences of the same class and across different classes, which is very crucial
for classification tasks. (2) Existing methods such as pre-trained language
models and graph-based approaches often consume substantial memory for training
and text-graph construction. (3) Although some low-resource methods can achieve
good performance, they often suffer from excessively long processing times. To
address these challenges, we propose a low-resource and fast text
classification model called LFTC. Our approach begins by constructing a
compressor list for each class to fully mine the regularity information within
intra-class data. We then remove redundant information irrelevant to the target
classification to reduce processing time. Finally, we compute the similarity
distance between text pairs for classification. We evaluate LFTC on 9 publicly
available benchmark datasets, and the results demonstrate significant
improvements in performance and processing time, especially under limited
computational and data resources, highlighting its superior advantages.

æè¦ï¼è¿å¹´æ¥ï¼åºäºç¥ç»ç½ç»åé¢è®­ç»æ¨¡åçææ¬åç±»æ¹æ³è¶æ¥è¶åå°å³æ³¨ï¼å¹¶è¡¨ç°åºä¼å¼çæ§è½ãç¶èï¼è¿äºæ¹æ³å¨å®éåºç¨ä¸­ä»ç¶å­å¨ä¸äºå±éæ§ï¼(1) å®ä»¬éå¸¸åªå³æ³¨å¥å­ä¹é´çå¹éç¸ä¼¼æ§ãç¶èï¼åç±»å¥å­åé¨åä¸åç±»å¥å­ä¹é´é½å­å¨éå«çé«ä»·å¼ä¿¡æ¯ï¼è¿å¯¹åç±»ä»»å¡è³å³éè¦ã(2) é¢è®­ç»è¯­è¨æ¨¡åååºäºå¾çæ¹æ³ç­ç°ææ¹æ³éå¸¸éè¦å¤§éçåå­ç¨äºè®­ç»åææ¬å¾æå»ºã(3) è½ç¶ä¸äºä½èµæºæ¹æ³å¯ä»¥è¾¾å°è¯å¥½çæ§è½ï¼ä½å®ä»¬éå¸¸å¤çæ¶é´è¿é¿ãä¸ºäºåºå¯¹è¿äºææï¼æä»¬æåºäºä¸ç§ä½èµæºä¸å¿«éçææ¬åç±»æ¨¡åï¼ç§°ä¸º LFTCãæä»¬çæ¹æ³é¦åä¸ºæ¯ä¸ªç±»å«æå»ºä¸ä¸ªåç¼©å¨åè¡¨ï¼ä»¥ååææç±»åæ°æ®ä¸­çè§å¾æ§ä¿¡æ¯ãç¶åï¼æä»¬å é¤ä¸ç®æ åç±»æ å³çåä½ä¿¡æ¯ï¼ä»¥åå°å¤çæ¶é´ãæåï¼æä»¬è®¡ç®ææ¬å¯¹ä¹é´çç¸ä¼¼æ§è·ç¦»è¿è¡åç±»ãæä»¬å¨ 9 ä¸ªå¬å¼çåºåæ°æ®éä¸è¯ä¼°äº LFTCï¼ç»æè¡¨æå¨æéçè®¡ç®åæ°æ®èµæºä¸ï¼å¶æ§è½åå¤çæ¶é´é½ææ¾èæåï¼çªåºäºå¶ä¼è¶çä¼å¿ã

##### **MGM: Global Understanding of Audience Overlap Graphs for Predicting the Factuality and the Bias of News Media**
2412.10467v1 by Muhammad Arslan Manzoor, Ruihong Zeng, Dilshod Azizov, Preslav Nakov, Shangsong Liang

In the current era of rapidly growing digital data, evaluating the political
bias and factuality of news outlets has become more important for seeking
reliable information online. In this work, we study the classification problem
of profiling news media from the lens of political bias and factuality.
Traditional profiling methods, such as Pre-trained Language Models (PLMs) and
Graph Neural Networks (GNNs) have shown promising results, but they face
notable challenges. PLMs focus solely on textual features, causing them to
overlook the complex relationships between entities, while GNNs often struggle
with media graphs containing disconnected components and insufficient labels.
To address these limitations, we propose MediaGraphMind (MGM), an effective
solution within a variational Expectation-Maximization (EM) framework. Instead
of relying on limited neighboring nodes, MGM leverages features, structural
patterns, and label information from globally similar nodes. Such a framework
not only enables GNNs to capture long-range dependencies for learning
expressive node representations but also enhances PLMs by integrating
structural information and therefore improving the performance of both models.
The extensive experiments demonstrate the effectiveness of the proposed
framework and achieve new state-of-the-art results. Further, we share our
repository1 which contains the dataset, code, and documentation

æè¦ï¼<paragraph>å¨æ¸ä½è³æå¿«éæé·çæä»£ï¼è©ä¼°æ°èåªé«çæ¿æ²»åè¦åäºå¯¦æ§ï¼å°æ¼å¨ç¶²è·¯ä¸å°æ¾å¯é çè³è¨è®å¾æ´å éè¦ãå¨éé å·¥ä½ä¸­ï¼æåå¾æ¿æ²»åè¦åäºå¯¦æ§çè§åº¦ç ç©¶æ°èåªé«çåé¡åé¡ãå³çµ±çåé¡æ¹æ³ï¼ä¾å¦é åè¨ç·´çèªè¨æ¨¡å (PLM) ååç¥ç¶ç¶²è·¯ (GNN)ï¼å·²ç¶å±ç¾åºæåéçææï¼ä½å®åé¢è¨èé¡¯èçææ°ãPLM åå°æ³¨æ¼æå­ç¹å¾µï¼å°è´å®åå¿½ç¥äºå¯¦é«ä¹éçè¤ééä¿ï¼è GNN åç¶å¸¸é£ä»¥èçåå«ä¸é£éåä»¶åæ¨ç±¤ä¸è¶³çåªé«åãçºäºè§£æ±ºéäºéå¶ï¼æåæåºäº MediaGraphMind (MGM)ï¼éæ¯ä¸ç¨®å¨è®ç°æææå¤§å (EM) æ¡æ¶å§ææçè§£æ±ºæ¹æ¡ãMGM ä¸ä¾è³´æ¼æéçé°è¿ç¯é»ï¼èæ¯å©ç¨ç¹å¾µãçµæ§æ¨¡å¼åä¾èªå¨çç¸ä¼¼ç¯é»çæ¨ç±¤è³è¨ãéç¨®æ¡æ¶ä¸åä½¿ GNN è½å¤ æ·åé·ç¨ä¾è³´æ§ä»¥å­¸ç¿è¡¨éå¼ç¯é»è¡¨ç¤ºï¼èä¸éééæ´åçµæ§è³è¨ä¾å¢å¼· PLMï¼å¾èæ¹åéå©ç¨®æ¨¡åçæè½ãå»£æ³çå¯¦é©è­æäºææåºçæ¡æ¶çæææ§ï¼ä¸¦éå°äºæ°çæåé²ææãæ­¤å¤ï¼æååäº«äºæåçå²å­åº« 1ï¼å¶ä¸­åå«è³æéãç¨å¼ç¢¼åæä»¶</paragraph>

##### **Uncommon Belief in Rationality**
2412.09407v1 by Qi Shi, Pavel Naumov

Common knowledge/belief in rationality is the traditional standard assumption
in analysing interaction among agents. This paper proposes a graph-based
language for capturing significantly more complicated structures of
higher-order beliefs that agents might have about the rationality of the other
agents. The two main contributions are a solution concept that captures the
reasoning process based on a given belief structure and an efficient algorithm
for compressing any belief structure into a unique minimal form.

æè¦ï¼å¨åæä»£çä¹éçäºåæï¼çæ§ä¸­çå¸¸è­/ä¿¡å¿µæ¯å³çµ±çæ¨æºåè¨­ãæ¬ææåºäºä¸ç¨®åºæ¼åå½¢çèªè¨ï¼ç¨æ¼ææä»£çäººå¯è½å°å¶ä»ä»£çäººççæ§å·æé¡¯èæ´è¤éçé«éä¿¡å¿µçµæ§ãå©é ä¸»è¦è²¢ç»æ¯ææåºæ¼çµ¦å®ä¿¡å¿µçµæ§çæ¨çéç¨çè§£æ±ºæ¹æ¡æ¦å¿µï¼ä»¥åå°ä»»ä½ä¿¡å¿µçµæ§å£ç¸®æå¯ä¸æå°å½¢å¼çæææ¼ç®æ³ã

##### **Foundation Models and Adaptive Feature Selection: A Synergistic Approach to Video Question Answering**
2412.09230v1 by Sai Bhargav Rongali, Mohamad Hassan N C, Ankit Jha, Neha Bhargava, Saurabh Prasad, Biplab Banerjee

This paper tackles the intricate challenge of video question-answering
(VideoQA). Despite notable progress, current methods fall short of effectively
integrating questions with video frames and semantic object-level abstractions
to create question-aware video representations. We introduce Local-Global
Question Aware Video Embedding (LGQAVE), which incorporates three major
innovations to integrate multi-modal knowledge better and emphasize semantic
visual concepts relevant to specific questions. LGQAVE moves beyond traditional
ad-hoc frame sampling by utilizing a cross-attention mechanism that precisely
identifies the most relevant frames concerning the questions. It captures the
dynamics of objects within these frames using distinct graphs, grounding them
in question semantics with the miniGPT model. These graphs are processed by a
question-aware dynamic graph transformer (Q-DGT), which refines the outputs to
develop nuanced global and local video representations. An additional
cross-attention module integrates these local and global embeddings to generate
the final video embeddings, which a language model uses to generate answers.
Extensive evaluations across multiple benchmarks demonstrate that LGQAVE
significantly outperforms existing models in delivering accurate multi-choice
and open-ended answers.

æè¦ï¼æ¬ææ¢è¨äºå½±çåç­ (VideoQA) çè¤éææ°ãåç®¡åå¾é¡¯èé²å±ï¼ä½ç®åçæè¡ä»ç¡æ³ææçµååé¡ãå½±çç«é¢åèªç¾©ç©ä»¶å±¤ç´æ½è±¡ï¼ä»¥å»ºç«åé¡æç¥çå½±çè¡¨å¾µãæåå¼é²äºå±é¨-å¨ååé¡æç¥å½±çåµå¥ (LGQAVE)ï¼å®åå«ä¸é éå¤§åµæ°ï¼ä»¥æ´å¥½å°æ´åå¤æ¨¡å¼ç¥è­ï¼ä¸¦å¼·èª¿èç¹å®åé¡ç¸éçèªç¾©è¦è¦ºæ¦å¿µãLGQAVE è¶è¶äºå³çµ±çè¨æç«é¢åæ¨£ï¼å©ç¨è·¨æ³¨æåæ©å¶ç²¾ç¢ºæ¾åºèåé¡æç¸éçç«é¢ãå®ä½¿ç¨ä¸åçåå½¢ææéäºç«é¢ä¸­ç©ä»¶çåæï¼ä¸¦éé miniGPT æ¨¡åå°å®åå¥ åºæ¼åé¡èªç¾©ä¸­ãéäºåå½¢ç±åé¡æç¥åæåå½¢è½æå¨ (Q-DGT) èçï¼å®ææ¹åè¼¸åºï¼ä»¥éç¼ç´°ç·»çå¨å±åå±é¨å½±çè¡¨å¾µãé¡å¤çè·¨æ³¨æåæ¨¡çµæ´åéäºå±é¨åå¨å±åµå¥ï¼ä»¥ç¢çæçµçå½±çåµå¥ï¼èªè¨æ¨¡åä½¿ç¨éäºåµå¥ä¾ç¢çç­æ¡ãè·¨å¤ååºæºçå»£æ³è©ä¼°è­æï¼LGQAVE å¨æä¾æºç¢ºçå¤é¸åéæ¾å¼ç­æ¡æ¹é¢ï¼æé¡¯åªæ¼ç¾ææ¨¡åã

##### **Filter-then-Generate: Large Language Models with Structure-Text Adapter for Knowledge Graph Completion**
2412.09094v2 by Ben Liu, Jihai Zhang, Fangquan Lin, Cheng Yang, Min Peng

Large Language Models (LLMs) present massive inherent knowledge and superior
semantic comprehension capability, which have revolutionized various tasks in
natural language processing. Despite their success, a critical gap remains in
enabling LLMs to perform knowledge graph completion (KGC). Empirical evidence
suggests that LLMs consistently perform worse than conventional KGC approaches,
even through sophisticated prompt design or tailored instruction-tuning.
Fundamentally, applying LLMs on KGC introduces several critical challenges,
including a vast set of entity candidates, hallucination issue of LLMs, and
under-exploitation of the graph structure. To address these challenges, we
propose a novel instruction-tuning-based method, namely FtG. Specifically, we
present a \textit{filter-then-generate} paradigm and formulate the KGC task
into a multiple-choice question format. In this way, we can harness the
capability of LLMs while mitigating the issue casused by hallucinations.
Moreover, we devise a flexible ego-graph serialization prompt and employ a
structure-text adapter to couple structure and text information in a
contextualized manner. Experimental results demonstrate that FtG achieves
substantial performance gain compared to existing state-of-the-art methods. The
instruction dataset and code are available at
\url{https://github.com/LB0828/FtG}.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLMs) å·æå·¨å¤§çåºæç¥è­ååè¶çèªç¾©çè§£è½åï¼éå¾¹åºæ¹è®äºèªç¶èªè¨èçä¸­çåç¨®ä»»åãåç®¡å®ååå¾äºæåï¼ä½å¨ä½¿ LLM è½å·è¡ç¥è­åè­å®æ (KGC) æ¹é¢ä»å­å¨ä¸åééµå·®è·ãç¶é©è­æè¡¨æï¼å³ä½¿ééè¤éçæç¤ºè¨­è¨æéèº«å®å¶çæä»¤å¾®èª¿ï¼LLM çè¡¨ç¾ä¹å§çµä¸å¦å³çµ±ç KGC æ¹æ³ãå¾æ ¹æ¬ä¸ä¾èªªï¼å¨ KGC ä¸æç¨ LLM æå¸¶ä¾å¹¾åééµææ°ï¼åæ¬å¤§éçå¯¦é«åé¸èãLLM çå¹»è¦ºåé¡ä»¥åå°åå½¢çµæ§çå©ç¨ä¸è¶³ãçºäºæå°éäºææ°ï¼æåæåºäºä¸ç¨®æ°çåºæ¼æä»¤å¾®èª¿çæ¹æ³ï¼å³ FtGãå·é«ä¾èªªï¼æåæåºäºä¸åãåéæ¿¾åçæãçç¯ä¾ï¼ä¸¦å° KGC ä»»åå¶å®æå¤é¸é¡æ ¼å¼ãéæ¨£ï¼æåå¯ä»¥å©ç¨ LLM çè½åï¼åææ¸è¼å¹»è¦ºæé æçåé¡ãæ­¤å¤ï¼æåè¨­è¨äºä¸åéæ´»çèªååºååæç¤ºï¼ä¸¦æ¡ç¨çµæ§ææ¬é©éå¨ä»¥æå¢åçæ¹å¼å°çµæ§åææ¬è³è¨çµåèµ·ä¾ãå¯¦é©çµæè¡¨æï¼èç¾æçæåé²æ¹æ³ç¸æ¯ï¼FtG ç²å¾äºé¡¯èçæ§è½æåãæä»¤è³æéåç¨å¼ç¢¼å¯å¨ä»¥ä¸ç¶²ååå¾ï¼\url{https://github.com/LB0828/FtG}ã

##### **Neural Interactive Proofs**
2412.08897v1 by Lewis Hammond, Sam Adam-Day

We consider the problem of how a trusted, but computationally bounded agent
(a 'verifier') can learn to interact with one or more powerful but untrusted
agents ('provers') in order to solve a given task. More specifically, we study
the case in which agents are represented using neural networks and refer to
solutions of this problem as neural interactive proofs. First we introduce a
unifying framework based on prover-verifier games, which generalises previously
proposed interaction protocols. We then describe several new protocols for
generating neural interactive proofs, and provide a theoretical comparison of
both new and existing approaches. Finally, we support this theory with
experiments in two domains: a toy graph isomorphism problem that illustrates
the key ideas, and a code validation task using large language models. In so
doing, we aim to create a foundation for future work on neural interactive
proofs and their application in building safer AI systems.

æè¦ï¼<paragraph>æåèæ®ä¸ååé¡ï¼èªªæä¸ååä¿¡ä»»ä½è¨ç®åéçä»£çï¼ãé©è­èãï¼å¦ä½å­¸æèä¸åæå¤åå¼·å¤§ä½ä¸å¯ä¿¡çä»£çï¼ãè­æèãï¼äºåï¼ä»¥è§£æ±ºçµ¦å®çä»»åãæ´å·é«å°èªªï¼æåç ç©¶ä»£çä½¿ç¨ç¥ç¶ç¶²è·¯è¡¨ç¤ºçææ³ï¼ä¸¦å°æ­¤åé¡çè§£æ±ºæ¹æ¡ç¨±çºç¥ç¶äºåè­æãé¦åï¼æåå¼å¥ä¸ååºæ¼è­æèé©è­èéæ²ççµ±ä¸æ¡æ¶ï¼å®æ¦æ¬äºååæåºçäºååè­°ãç¶å¾ï¼æåæè¿°äºå¹¾åçæç¥ç¶äºåè­æçæ°åè­°ï¼ä¸¦å°æ°èæ¹æ³é²è¡äºçè«æ¯è¼ãæå¾ï¼æåå¨å©åé åä¸­ç¨å¯¦é©æ¯æäºéåçè«ï¼ä¸åç©å·ååæ§åé¡ï¼èªªæäºééµææ³ï¼ä»¥åä½¿ç¨å¤§åèªè¨æ¨¡åçä»£ç¢¼é©è­ä»»åãéæ¨£åï¼æåæ¨å¨çºç¥ç¶äºåè­æåå¶å¨æ§å»ºæ´å®å¨ç AI ç³»çµ±ä¸­çæç¨å¥ å®åºç¤ã</paragraph>

##### **A Graph-Based Synthetic Data Pipeline for Scaling High-Quality Reasoning Instructions**
2412.08864v1 by Jiankang Wang, Jianjun Xu, Xiaorui Wang, Yuxin Wang, Mengting Xing, Shancheng Fang, Zhineng Chen, Hongtao Xie, Yongdong Zhang

Synthesizing high-quality reasoning data for continual training has been
proven to be effective in enhancing the performance of Large Language Models
(LLMs). However, previous synthetic approaches struggle to easily scale up data
and incur high costs in the pursuit of high quality. In this paper, we propose
the Graph-based Synthetic Data Pipeline (GSDP), an economical and scalable
framework for high-quality reasoning data synthesis. Inspired by knowledge
graphs, we extracted knowledge points from seed data and constructed a
knowledge point relationships graph to explore their interconnections. By
exploring the implicit relationships among knowledge, our method achieves
$\times$255 data expansion. Furthermore, GSDP led by open-source models,
achieves synthesis quality comparable to GPT-4-0613 while maintaining
$\times$100 lower costs. To tackle the most challenging mathematical reasoning
task, we present the GSDP-MATH dataset comprising over 1.91 million pairs of
math problems and answers. After fine-tuning on GSDP-MATH, GSDP-7B based on
Mistral-7B achieves 37.7% accuracy on MATH and 78.4% on GSM8K, demonstrating
the effectiveness of our method. The dataset and models trained in this paper
will be available.

æè¦ï¼<paragraph>åæé«åè³ªæ¨çè³æä»¥é²è¡æçºè¨ç·´å·²è¢«è­å¯¦è½æææåå¤§åèªè¨æ¨¡å (LLM) çæè½ãç¶èï¼ååçåææ¹æ³é£ä»¥è¼ææ´åè³æï¼ä¸å¨è¿½æ±é«åè³ªçéç¨ä¸­æç¢çé«ææ¬ãå¨æ¬æä¸­ï¼æåæåºåºæ¼åè¡¨çåæè³æç®¡ç· (GSDP)ï¼ä¸åç¶æ¿ä¸å¯æ´åçé«åè³ªæ¨çè³æåææ¶æ§ãåç¥è­åè¡¨åç¼ï¼æåå¾ç¨®å­è³æä¸­èåç¥è­é»ï¼ä¸¦å»ºæ§ä¸åç¥è­é»éä¿åè¡¨ä»¥æ¢ç´¢å®åçç¸äºéè¯æ§ãééæ¢ç´¢ç¥è­ä¸­çé±å«éä¿ï¼æåçåæ³éå°äº $\times$255 è³ææ´åãæ­¤å¤ï¼ç±éæºæ¨¡åé å°ç GSDPï¼éå°äºè GPT-4-0613 ç¸ç¶çåæåè³ªï¼åæå°ææ¬éä½äº $\times$100ãçºäºæå°æå·ææ°æ§çæ¸å­¸æ¨çä»»åï¼æåæåºäº GSDP-MATH è³æéï¼å¶ä¸­åå«è¶é 191 è¬å°æ¸å­¸åé¡åç­æ¡ãå¨ GSDP-MATH ä¸é²è¡å¾®èª¿å¾ï¼åºæ¼ Mistral-7B ç GSDP-7B å¨ MATH ä¸éå°äº 37.7% çæºç¢ºåº¦ï¼å¨ GSM8K ä¸éå°äº 78.4%ï¼è­æäºæåæ¹æ³çæææ§ãæ¬æä¸­è¨ç·´çè³æéåæ¨¡åå°æå¬éã</paragraph>

##### **In-Context Learning with Topological Information for Knowledge Graph Completion**
2412.08742v1 by Udari Madhushani Sehwag, Kassiani Papasotiriou, Jared Vann, Sumitra Ganesh

Knowledge graphs (KGs) are crucial for representing and reasoning over
structured information, supporting a wide range of applications such as
information retrieval, question answering, and decision-making. However, their
effectiveness is often hindered by incompleteness, limiting their potential for
real-world impact. While knowledge graph completion (KGC) has been extensively
studied in the literature, recent advances in generative AI models,
particularly large language models (LLMs), have introduced new opportunities
for innovation. In-context learning has recently emerged as a promising
approach for leveraging pretrained knowledge of LLMs across a range of natural
language processing tasks and has been widely adopted in both academia and
industry. However, how to utilize in-context learning for effective KGC remains
relatively underexplored. We develop a novel method that incorporates
topological information through in-context learning to enhance KGC performance.
By integrating ontological knowledge and graph structure into the context of
LLMs, our approach achieves strong performance in the transductive setting
i.e., nodes in the test graph dataset are present in the training graph
dataset. Furthermore, we apply our approach to KGC in the more challenging
inductive setting, i.e., nodes in the training graph dataset and test graph
dataset are disjoint, leveraging the ontology to infer useful information about
missing nodes which serve as contextual cues for the LLM during inference. Our
method demonstrates superior performance compared to baselines on the
ILPC-small and ILPC-large datasets.

æè¦ï¼ç¥è­åè­ (KG) å°æ¼è¡¨ç¤ºåæ¨ççµæ§åè³è¨è³ééè¦ï¼æ¯æ´å»£æ³çæç¨ç¨å¼ï¼ä¾å¦è³è¨æª¢ç´¢ãåé¡è§£ç­åæ±ºç­å¶å®ãç¶èï¼å®åçæè½ç¶å¸¸åå°ä¸å®æ´æ§çé»ç¤ï¼éå¶äºå®åå°ç¾å¯¦ä¸çå½±é¿çæ½åãéç¶ç¥è­åè­å®æ (KGC) å·²å¨æç»ä¸­å»£æ³ç ç©¶ï¼ä½çæå¼ AI æ¨¡åçææ°é²å±ï¼ç¹å¥æ¯å¤§åèªè¨æ¨¡å (LLM)ï¼çºåµæ°å¸¶ä¾äºæ°çæ©æãæå¢å­¸ç¿æè¿å·²æçºä¸ç¨®æåéçæ¹æ³ï¼ç¨æ¼è·¨è¶ä¸ç³»åèªç¶èªè¨èçä»»åå©ç¨ LLM çé è¨ç·´ç¥è­ï¼ä¸¦å·²å»£æ³æç¨æ¼å­¸è¡çåç¢æ¥­ãç¶èï¼å¦ä½å©ç¨æå¢å­¸ç¿é²è¡ææç KGC ä»ç¶ç¸å°æªè¢«æ¢è¨ãæåéç¼äºä¸ç¨®æ°æ¹æ³ï¼ééæå¢å­¸ç¿ç´å¥ææ²è³è¨ä¾å¢å¼· KGC æè½ãééå°æ¬é«ç¥è­ååå½¢çµæ§æ´åå° LLM çæå¢ä¸­ï¼æåçåæ³å¨è½å°å¼è¨­å®ä¸­åå¾å¼·åçæè½ï¼å³æ¸¬è©¦åå½¢è³æéä¸­çç¯é»å­å¨æ¼è¨ç·´åå½¢è³æéä¸­ãæ­¤å¤ï¼æåå°æåçåæ³æç¨æ¼æ´å·ææ°æ§çæ­¸ç´å¼è¨­å®ä¸­ç KGCï¼å³è¨ç·´åå½¢è³æéåæ¸¬è©¦åå½¢è³æéä¸­çç¯é»æ¯ä¸ç¸äº¤çï¼å©ç¨æ¬é«ä¾æ¨æ·æééºå¤±ç¯é»çæç¨è³è¨ï¼éäºç¯é»å¨æ¨çéç¨ä¸­ä½çº LLM çæå¢æç¤ºãè ILPC-small å ILPC-large è³æéä¸çåºæºç¸æ¯ï¼æåçåæ³å±ç¾åºåªç°çæè½ã

##### **VEL: A Formally Verified Reasoner for OWL2 EL Profile**
2412.08739v1 by Atalay Mert Ileri, Nalen Rangarajan, Jack Cannell, Hande McGinty

Over the past two decades, the Web Ontology Language (OWL) has been
instrumental in advancing the development of ontologies and knowledge graphs,
providing a structured framework that enhances the semantic integration of
data. However, the reliability of deductive reasoning within these systems
remains challenging, as evidenced by inconsistencies among popular reasoners in
recent competitions. This evidence underscores the limitations of current
testing-based methodologies, particularly in high-stakes domains such as
healthcare. To mitigate these issues, in this paper, we have developed VEL, a
formally verified EL++ reasoner equipped with machine-checkable correctness
proofs that ensure the validity of outputs across all possible inputs. This
formalization, based on the algorithm of Baader et al., has been transformed
into executable OCaml code using the Coq proof assistant's extraction
capabilities. Our formalization revealed several errors in the original
completeness proofs, which led to changes to the algorithm to ensure its
completeness. Our work demonstrates the necessity of mechanization of reasoning
algorithms to ensure their correctness at theoretical and implementation
levels.

æè¦ï¼å¨éå»äºåå¹´ï¼Web Ontology Language (OWL) å·²å¨æ¨åæ¬ä½åç¥è­åè­çç¼å±ä¸­ç¼æ®ééµä½ç¨ï¼æä¾ä¸åå¢å¼·è³æèªææ´åççµæ§åæ¶æ§ãç¶èï¼éäºç³»çµ±ä¸­æ¼ç¹¹æ¨ççå¯é æ§ä»ç¶å·æææ°æ§ï¼æ­£å¦æè¿æ¯è³½ä¸­æµè¡çæ¨çæ©ä¹éçä¸ä¸è´æ§æè­æçé£æ¨£ãéåè­æçªé¡¯äºç¶ååºæ¼æ¸¬è©¦çæ¹æ³çå±éæ§ï¼ç¹å¥æ¯å¨é«çä¿å¥ç­é«é¢¨éªé åãçºäºæ¸è¼éäºåé¡ï¼æåå¨æ¬æä¸­éç¼äº VELï¼ä¸åæ­£å¼é©è­ç EL++ æ¨çæ©ï¼éåäºæ©å¨å¯æª¢æ¥çæ­£ç¢ºæ§è­æï¼ä»¥ç¢ºä¿å¨ææå¯è½çè¼¸å¥ä¸­è¼¸åºçæææ§ãéåå½¢å¼åï¼åºæ¼ Baader ç­äººçæ¼ç®æ³ï¼å·²ä½¿ç¨ Coq è­æå©æçæååè½è½æçºå¯å·è¡ç OCaml ç¨å¼ç¢¼ãæåçå½¢å¼åæ­ç¤ºäºåå§å®æ´æ§è­æä¸­çå¹¾åé¯èª¤ï¼éå°è´äºæ¼ç®æ³çæ¹è®ä»¥ç¢ºä¿å¶å®æ´æ§ãæåçä½åè­æäºæ¨çæ¼ç®æ³æ©æ¢°åçå¿è¦æ§ï¼ä»¥ç¢ºä¿å®åå¨çè«åå¯¦ä½å±¤é¢çæ­£ç¢ºæ§ã

##### **From communities to interpretable network and word embedding: an unified approach**
2412.08187v1 by Thibault Prouteau, Nicolas DuguÃ©, Simon Guillot

Modelling information from complex systems such as humans social interaction
or words co-occurrences in our languages can help to understand how these
systems are organized and function. Such systems can be modelled by networks,
and network theory provides a useful set of methods to analyze them. Among
these methods, graph embedding is a powerful tool to summarize the interactions
and topology of a network in a vectorized feature space. When used in input of
machine learning algorithms, embedding vectors help with common graph problems
such as link prediction, graph matching, etc. Word embedding has the goal of
representing the sense of words, extracting it from large text corpora. Despite
differences in the structure of information in input of embedding algorithms,
many graph embedding approaches are adapted and inspired from methods in NLP.
Limits of these methods are observed in both domains. Most of these methods
require long and resource greedy training. Another downside to most methods is
that they are black-box, from which understanding how the information is
structured is rather complex. Interpretability of a model allows understanding
how the vector space is structured without the need for external information,
and thus can be audited more easily. With both these limitations in mind, we
propose a novel framework to efficiently embed network vertices in an
interpretable vector space. Our Lower Dimension Bipartite Framework (LDBGF)
leverages the bipartite projection of a network using cliques to reduce
dimensionality. Along with LDBGF, we introduce two implementations of this
framework that rely on communities instead of cliques: SINr-NR and SINr-MF. We
show that SINr-MF can perform well on classical graphs and SINr-NR can produce
high-quality graph and word embeddings that are interpretable and stable across
runs.

æè¦ï¼<paragraph>ééæ¨¡æ¬äººé¡ç¤¾äº¤äºåæèªè¨ä¸­è©å½å±ç¾ç­è¤éç³»çµ±ä¸­çè³è¨ï¼æå©æ¼äºè§£éäºç³»çµ±ççµç¹åéä½æ¹å¼ãéäºç³»çµ±å¯ä»¥ç¨ç¶²è·¯ä¾å»ºæ¨¡ï¼èç¶²è·¯çè«æä¾äºæç¨çæ¹æ³éä¾åæå®åãå¨éäºæ¹æ³ä¸­ï¼åå½¢åµå¥æ¯ä¸ç¨®å¼·å¤§çå·¥å·ï¼å¯ç¨æ¼å¨åéåç¹å¾µç©ºéä¸­ç¸½çµç¶²è·¯çäº¤äºåææ²ãç¶ç¨æ¼æ©å¨å­¸ç¿æ¼ç®æ³çè¼¸å¥æï¼åµå¥åéæå©æ¼å¸¸è¦çåå½¢åé¡ï¼ä¾å¦é£çµé æ¸¬ãåå½¢éå°ç­ãè©åµå¥çç®æ¨æ¯è¡¨ç¤ºè©å½çæç¾©ï¼å¾å¤§åæå­èªæåº«ä¸­èåå®ãåç®¡åµå¥æ¼ç®æ³è¼¸å¥è³è¨ççµæ§ä¸åï¼ä½è¨±å¤åå½¢åµå¥æ¹æ³é½æ¯æ ¹æèªç¶èªè¨èçä¸­çæ¹æ³æ¹ç·¨ååç¼çãå¨å©åé åä¸­é½è§å¯å°éäºæ¹æ³çéå¶ãå¤§å¤æ¸éäºæ¹æ³éè¦æ¼«é·ä¸èè²»è³æºçè¨ç·´ãå¤§å¤æ¸æ¹æ³çå¦ä¸åç¼ºé»æ¯å®åæ¯é»çå­ï¼å¾ä¸­çè§£è³è¨å¦ä½è¢«çµæ§åç¸ç¶è¤éãæ¨¡åçå¯è§£éæ§åè¨±å¨ä¸éè¦å¤é¨è³è¨çææ³ä¸äºè§£åéç©ºéæ¯å¦ä½è¢«çµæ§åçï¼å æ­¤å¯ä»¥æ´å®¹æå°é²è¡ç¨½æ ¸ãç¢è¨éå©åéå¶ï¼æåæåºäºä¸åæ°ç©çæ¡æ¶ï¼ä»¥ææçæ¹å¼å°ç¶²è·¯é é»åµå¥å¯è§£éçåéç©ºéä¸­ãæåçä½ç¶­äºé¨åæ¡æ¶ (LDBGF) å©ç¨ç¶²è·¯çäºé¨åæå½±ä½¿ç¨æ´¾ç³»ä¾éä½ç¶­åº¦ãé¤äº LDBGF ä¹å¤ï¼æåéä»ç´¹äºå©åä¾è³´ç¤¾ç¾¤èéæ´¾ç³»çæ­¤æ¡æ¶å¯¦ä½ï¼SINr-NR å SINr-MFãæåå±ç¤ºäº SINr-MF å¨ç¶å¸åå½¢ä¸å¯ä»¥å·è¡è¯å¥½ï¼è SINr-NR å¯ä»¥ç¢çé«åè³ªçåå½¢åè©åµå¥ï¼éäºåµå¥å¨åæ¬¡å·è¡ä¸­é½æ¯å¯è§£éä¸ç©©å®çã</paragraph>

##### **Can Graph Neural Networks Learn Language with Extremely Weak Text Supervision?**
2412.08174v2 by Zihao Li, Lecheng Zheng, Bowen Jin, Dongqi Fu, Baoyu Jing, Yikun Ban, Jingrui He, Jiawei Han

While great success has been achieved in building vision models with
Contrastive Language-Image Pre-training (CLIP) over Internet-scale image-text
pairs, building transferable Graph Neural Networks (GNNs) with CLIP pipeline is
challenging because of three fundamental issues: the scarcity of labeled data
and text supervision, different levels of downstream tasks, and the conceptual
gaps between domains. In this work, to address these issues, we leverage
multi-modal prompt learning to effectively adapt pre-trained GNN to downstream
tasks and data, given only a few semantically labeled samples, each with
extremely weak text supervision. Our new paradigm embeds the graphs directly in
the same space as the Large Language Models (LLMs) by learning both graph
prompts and text prompts simultaneously. To accomplish this, we improve
state-of-the-art graph prompt method, and then propose the first graph-language
multi-modal prompt learning approach for exploiting the knowledge in
pre-trained models. Notably, due to the insufficient supervision for
fine-tuning, in our paradigm, the pre-trained GNN and the LLM are kept frozen,
so the learnable parameters are much fewer than fine-tuning any pre-trained
model. Through extensive experiments on real-world datasets, we demonstrate the
superior performance of our paradigm in few-shot, multi-task-level, and
cross-domain settings. Moreover, we build the first CLIP-style zero-shot
classification prototype that can generalize GNNs to unseen classes with
extremely weak text supervision.

æè¦ï¼<paragraph>åç®¡å¨ä½¿ç¨ç¶²éç¶²è·¯è¦æ¨¡çå½±åæå­éå°é²è¡å°æ¯èªè¨å½±åé è¨ç·´ (CLIP) ä¾å»ºç«è¦è¦ºæ¨¡åæ¹é¢åå¾äºå·¨å¤§çæåï¼ä½ä½¿ç¨ CLIP ç®¡ç·å»ºç«å¯è½ç§»åå½¢ç¥ç¶ç¶²è·¯ (GNN) å»å¾å·ææ°æ§ï¼åå å¨æ¼ä¸åæ ¹æ¬åé¡ï¼æ¨è¨è³æåæå­ç£ç£çç¨å°æ§ãä¸åå±¤ç´çä¸æ¸¸ä»»åï¼ä»¥åä¸åé åä¹éçæ¦å¿µå·®è·ãå¨éé å·¥ä½ä¸­ï¼çºäºè§£æ±ºéäºåé¡ï¼æåå©ç¨å¤æ¨¡ææç¤ºå­¸ç¿ï¼å¨åæå°æ¸èªç¾©æ¨è¨ç¯ä¾çææ³ä¸ï¼ææå°èª¿æ´é è¨ç·´ç GNN ä»¥é©ç¨æ¼ä¸æ¸¸ä»»ååè³æï¼æ¯åç¯ä¾é½å·ææ¥µå¶èå¼±çæå­ç£ç£ãæåçæ°ç¯ä¾å°åå½¢ç´æ¥åµå¥èå¤§åèªè¨æ¨¡å (LLM) ç¸åçç©ºéä¸­ï¼æ¹æ³æ¯åæå­¸ç¿åå½¢æç¤ºåæå­æç¤ºãçºäºéæéåç®æ¨ï¼æåæ¹é²äºæåé²çåå½¢æç¤ºæ¹æ³ï¼ç¶å¾æåºç¬¬ä¸ååå½¢èªè¨å¤æ¨¡ææç¤ºå­¸ç¿æ¹æ³ï¼ä»¥å©ç¨é è¨ç·´æ¨¡åä¸­çç¥è­ãå¼å¾æ³¨æçæ¯ï¼ç±æ¼å¾®èª¿çç£ç£ä¸è¶³ï¼å¨æåçç¯ä¾ä¸­ï¼é è¨ç·´ç GNN å LLM ä¿æåçµçæï¼å æ­¤å¯å­¸ç¿åæ¸é å°æ¼å¾®èª¿ä»»ä½é è¨ç·´æ¨¡åãééå°çå¯¦ä¸çè³æéé²è¡å»£æ³çå¯¦é©ï¼æåè­æäºæåçç¯ä¾å¨å°æ¨£æ¬ãå¤ä»»åå±¤ç´åè·¨é åè¨­å®ä¸­çåè¶æè½ãæ­¤å¤ï¼æåå»ºç«äºç¬¬ä¸å CLIP é¢¨æ ¼çé¶æ¨£æ¬åé¡ååï¼å®å¯ä»¥å° GNN æ¨å»£å°å·ææ¥µå¶èå¼±æå­ç£ç£çæªè¦é¡å¥ã</paragraph>


### Medical
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2025-01-09**|**From Simple to Complex Skills: The Case of In-Hand Object Reorientation**|Haozhi Qi et.al.|[2501.05439v1](http://arxiv.org/abs/2501.05439v1)|null|
|**2025-01-09**|**A Novel Pathology Foundation Model by Mayo Clinic, CharitÃ©, and Aignostics**|Maximilian Alber et.al.|[2501.05409v1](http://arxiv.org/abs/2501.05409v1)|null|
|**2025-01-09**|**An Algorithmic Approach for Causal Health Equity: A Look at Race Differentials in Intensive Care Unit (ICU) Outcomes**|Drago Plecko et.al.|[2501.05197v1](http://arxiv.org/abs/2501.05197v1)|null|
|**2025-01-09**|**Addressing Domain Shift via Imbalance-Aware Domain Adaptation in Embryo Development Assessment**|Lei Li et.al.|[2501.04958v1](http://arxiv.org/abs/2501.04958v1)|null|
|**2025-01-09**|**Quantifying Itch and its Impact on Sleep Using Machine Learning and Radio Signals**|Michail Ouroutzoglou et.al.|[2501.04896v1](http://arxiv.org/abs/2501.04896v1)|null|
|**2025-01-08**|**MedCoDi-M: A Multi-Prompt Foundation Model for Multimodal Medical Data Generation**|Daniele Molino et.al.|[2501.04614v2](http://arxiv.org/abs/2501.04614v2)|null|
|**2025-01-08**|**A 65 nm Bayesian Neural Network Accelerator with 360 fJ/Sample In-Word GRNG for AI Uncertainty Estimation**|Zephan M. Enciso et.al.|[2501.04577v1](http://arxiv.org/abs/2501.04577v1)|null|
|**2025-01-08**|**Continual Self-supervised Learning Considering Medical Domain Knowledge in Chest CT Images**|Ren Tasai et.al.|[2501.04217v1](http://arxiv.org/abs/2501.04217v1)|null|
|**2025-01-07**|**Generative Style Transfer for MRI Image Segmentation: A Case of Glioma Segmentation in Sub-Saharan Africa**|Rancy Chepchirchir et.al.|[2501.04734v1](http://arxiv.org/abs/2501.04734v1)|null|
|**2025-01-07**|**Exploring the Potential of Large Language Models in Public Transportation: San Antonio Case Study**|Ramya Jonnala et.al.|[2501.03904v1](http://arxiv.org/abs/2501.03904v1)|null|
|**2025-01-07**|**SCC-YOLO: An Improved Object Detector for Assisting in Brain Tumor Diagnosis**|Runci Bai et.al.|[2501.03836v1](http://arxiv.org/abs/2501.03836v1)|null|
|**2025-01-07**|**SelectiveFinetuning: Enhancing Transfer Learning in Sleep Staging through Selective Domain Alignment**|Siyuan Zhao et.al.|[2501.03764v1](http://arxiv.org/abs/2501.03764v1)|null|
|**2025-01-07**|**Self-adaptive vision-language model for 3D segmentation of pulmonary artery and vein**|Xiaotong Guo et.al.|[2501.03722v1](http://arxiv.org/abs/2501.03722v1)|null|
|**2025-01-07**|**Can Deep Learning Trigger Alerts from Mobile-Captured Images?**|Pritisha Sarkar et.al.|[2501.03499v1](http://arxiv.org/abs/2501.03499v1)|null|
|**2025-01-07**|**Activating Associative Disease-Aware Vision Token Memory for LLM-Based X-ray Report Generation**|Xiao Wang et.al.|[2501.03458v1](http://arxiv.org/abs/2501.03458v1)|[link](https://github.com/event-ahu/medical_image_analysis)|
|**2025-01-06**|**Existential Crisis: A Social Robot's Reason for Being**|Dora Medgyesy et.al.|[2501.03376v1](http://arxiv.org/abs/2501.03376v1)|null|
|**2025-01-06**|**Label-free Concept Based Multiple Instance Learning for Gigapixel Histopathology**|Susu Sun et.al.|[2501.02922v1](http://arxiv.org/abs/2501.02922v1)|null|
|**2025-01-06**|**Explaining Humour Style Classifications: An XAI Approach to Understanding Computational Humour Analysis**|Mary Ogbuka Kenneth et.al.|[2501.02891v1](http://arxiv.org/abs/2501.02891v1)|null|
|**2025-01-06**|**IIMedGPT: Promoting Large Language Model Capabilities of Medical Tasks by Efficient Human Preference Alignment**|Yiming Zhang et.al.|[2501.02869v1](http://arxiv.org/abs/2501.02869v1)|null|
|**2025-01-06**|**Multi-Modal One-Shot Federated Ensemble Learning for Medical Data with Vision Large Language Model**|Naibo Wang et.al.|[2501.03292v1](http://arxiv.org/abs/2501.03292v1)|null|
|**2025-01-06**|**GLoG-CSUnet: Enhancing Vision Transformers with Adaptable Radiomic Features for Medical Image Segmentation**|Niloufar Eghbali et.al.|[2501.02788v2](http://arxiv.org/abs/2501.02788v2)|null|
|**2025-01-06**|**Hybrid deep convolution model for lung cancer detection with transfer learning**|Sugandha Saxena et.al.|[2501.02785v1](http://arxiv.org/abs/2501.02785v1)|null|
|**2025-01-06**|**ICFNet: Integrated Cross-modal Fusion Network for Survival Prediction**|Binyu Zhang et.al.|[2501.02778v1](http://arxiv.org/abs/2501.02778v1)|[link](https://github.com/binging512/icfnet)|
|**2025-01-06**|**Tree-based RAG-Agent Recommendation System: A Case Study in Medical Test Data**|Yahe Yang et.al.|[2501.02727v1](http://arxiv.org/abs/2501.02727v1)|null|
|**2025-01-05**|**Representation Learning of Lab Values via Masked AutoEncoder**|David Restrepo et.al.|[2501.02648v2](http://arxiv.org/abs/2501.02648v2)|null|
|**2025-01-05**|**Trust and Dependability in Blockchain & AI Based MedIoT Applications: Research Challenges and Future Directions**|Ellis Solaiman et.al.|[2501.02647v1](http://arxiv.org/abs/2501.02647v1)|null|
|**2025-01-05**|**KM-UNet KAN Mamba UNet for medical image segmentation**|Yibo Zhang et.al.|[2501.02559v1](http://arxiv.org/abs/2501.02559v1)|[link](https://github.com/2760613195/km_unet)|
|**2025-01-05**|**Hengqin-RA-v1: Advanced Large Language Model for Diagnosis and Treatment of Rheumatoid Arthritis with Dataset based Traditional Chinese Medicine**|Yishen Liu et.al.|[2501.02471v1](http://arxiv.org/abs/2501.02471v1)|null|
|**2025-01-05**|**Enhancing Contrastive Learning for Retinal Imaging via Adjusted Augmentation Scales**|Zijie Cheng et.al.|[2501.02451v1](http://arxiv.org/abs/2501.02451v1)|null|
|**2025-01-04**|**Enhancing Workplace Productivity and Well-being Using AI Agent**|Ravirajan K et.al.|[2501.02368v1](http://arxiv.org/abs/2501.02368v1)|null|
|**2025-01-04**|**Exploring the Capabilities and Limitations of Large Language Models for Radiation Oncology Decision Support**|Florian Putz et.al.|[2501.02346v1](http://arxiv.org/abs/2501.02346v1)|null|
|**2025-01-04**|**Deep Learning-Driven Segmentation of Ischemic Stroke Lesions Using Multi-Channel MRI**|Ashiqur Rahman et.al.|[2501.02287v1](http://arxiv.org/abs/2501.02287v1)|null|
|**2025-01-04**|**The Integration of Blockchain and Artificial Intelligence for Secure Healthcare Systems**|Umar Safdar et.al.|[2501.02169v1](http://arxiv.org/abs/2501.02169v1)|null|
|**2025-01-03**|**Online Detection of Water Contamination Under Concept Drift**|Jin Li et.al.|[2501.02107v1](http://arxiv.org/abs/2501.02107v1)|null|
|**2025-01-03**|**METAGENE-1: Metagenomic Foundation Model for Pandemic Monitoring**|Ollie Liu et.al.|[2501.02045v1](http://arxiv.org/abs/2501.02045v1)|null|
|**2025-01-03**|**Advancing Pancreatic Cancer Prediction with a Next Visit Token Prediction Head on top of Med-BERT**|Jianping He et.al.|[2501.02044v1](http://arxiv.org/abs/2501.02044v1)|null|
|**2025-01-03**|**Combined Hyper-Extensible Extremely-Secured Zero-Trust CIAM-PAM architecture**|Shivom Aggarwal et.al.|[2501.01732v1](http://arxiv.org/abs/2501.01732v1)|null|
|**2025-01-03**|**EAUWSeg: Eliminating annotation uncertainty in weakly-supervised medical image segmentation**|Wang Lituan et.al.|[2501.01658v1](http://arxiv.org/abs/2501.01658v1)|null|
|**2025-01-03**|**Implications of Artificial Intelligence on Health Data Privacy and Confidentiality**|Ahmad Momani et.al.|[2501.01639v2](http://arxiv.org/abs/2501.01639v2)|null|
|**2025-01-03**|**Merging Context Clustering with Visual State Space Models for Medical Image Segmentation**|Yun Zhu et.al.|[2501.01618v1](http://arxiv.org/abs/2501.01618v1)|null|
|**2025-01-03**|**PSYCHE: A Multi-faceted Patient Simulation Framework for Evaluation of Psychiatric Assessment Conversational Agents**|Jingoo Lee et.al.|[2501.01594v1](http://arxiv.org/abs/2501.01594v1)|null|
|**2025-01-02**|**Model Checking in Medical Imaging for Tumor Detection and Segmentation**|Elhoucine Elfatimi et.al.|[2501.02024v2](http://arxiv.org/abs/2501.02024v2)|null|
|**2025-01-02**|**Training Medical Large Vision-Language Models with Abnormal-Aware Feedback**|Yucheng Zhou et.al.|[2501.01377v1](http://arxiv.org/abs/2501.01377v1)|null|
|**2025-01-02**|**ScarNet: A Novel Foundation Model for Automated Myocardial Scar Quantification from LGE in Cardiac MRI**|Neda Tavakoli et.al.|[2501.01372v1](http://arxiv.org/abs/2501.01372v1)|[link](https://github.com/nedatavakoli/scarnet)|
|**2025-01-02**|**Contrastive Learning from Exploratory Actions: Leveraging Natural Interactions for Preference Elicitation**|Nathaniel Dennler et.al.|[2501.01367v1](http://arxiv.org/abs/2501.01367v1)|null|
|**2025-01-02**|**Multi-Head Explainer: A General Framework to Improve Explainability in CNNs and Transformers**|Bohang Sun et.al.|[2501.01311v1](http://arxiv.org/abs/2501.01311v1)|null|
|**2025-01-02**|**Machine Learning-Based Differential Diagnosis of Parkinson's Disease Using Kinematic Feature Extraction and Selection**|Masahiro Matsumoto et.al.|[2501.02014v1](http://arxiv.org/abs/2501.02014v1)|null|
|**2025-01-02**|**Data Augmentation Techniques for Chinese Disease Name Normalization**|Wenqian Cui et.al.|[2501.01195v1](http://arxiv.org/abs/2501.01195v1)|[link](https://github.com/dreamtheater123/disease_name_dataset)|
|**2025-01-02**|**Reasoning based on symbolic and parametric knowledge bases: a survey**|Mayi Xu et.al.|[2501.01030v1](http://arxiv.org/abs/2501.01030v1)|null|
|**2025-01-02**|**Are LLMs effective psychological assessors? Leveraging adaptive RAG for interpretable mental health screening through psychometric practice**|Federico Ravenda et.al.|[2501.00982v1](http://arxiv.org/abs/2501.00982v1)|[link](https://github.com/fede-stack/adaptive-rag-for-psychological-assessment)|
|**2025-01-01**|**Enhancing Early Diabetic Retinopathy Detection through Synthetic DR1 Image Generation: A StyleGAN3 Approach**|Sagarnil Das et.al.|[2501.00954v1](http://arxiv.org/abs/2501.00954v1)|null|
|**2025-01-01**|**Multi-Center Study on Deep Learning-Assisted Detection and Classification of Fetal Central Nervous System Anomalies Using Ultrasound Imaging**|Yang Qi et.al.|[2501.02000v1](http://arxiv.org/abs/2501.02000v1)|null|
|**2024-12-31**|**Efficient Standardization of Clinical Notes using Large Language Models**|Daniel B. Hier et.al.|[2501.00644v1](http://arxiv.org/abs/2501.00644v1)|null|
|**2024-12-31**|**Pan-infection Foundation Framework Enables Multiple Pathogen Prediction**|Lingrui Zhang et.al.|[2501.01462v1](http://arxiv.org/abs/2501.01462v1)|null|
|**2024-12-31**|**A Hybrid Deep Learning and Model-Checking Framework for Accurate Brain Tumor Detection and Validation**|Lahcen El Fatimi et.al.|[2501.01991v1](http://arxiv.org/abs/2501.01991v1)|null|
|**2024-12-31**|**GAN-TAT: A Novel Framework Using Protein Interaction Networks in Druggable Gene Identification**|George Yuanji Wang et.al.|[2501.01458v1](http://arxiv.org/abs/2501.01458v1)|null|
|**2024-12-31**|**Autonomous Alignment with Human Value on Altruism through Considerate Self-imagination and Theory of Mind**|Haibo Tong et.al.|[2501.00320v2](http://arxiv.org/abs/2501.00320v2)|[link](https://github.com/braincog-x/brain-cog)|
|**2024-12-31**|**A Fourfold Pathogen Reference Ontology Suite**|Shane Babcock et.al.|[2501.01454v1](http://arxiv.org/abs/2501.01454v1)|null|
|**2024-12-31**|**CancerKG.ORG A Web-scale, Interactive, Verifiable Knowledge Graph-LLM Hybrid for Assisting with Optimal Cancer Treatment and Care**|Michael Gubanov et.al.|[2501.00223v1](http://arxiv.org/abs/2501.00223v1)|null|
|**2024-12-31**|**An Empirical Evaluation of Large Language Models on Consumer Health Questions**|Moaiz Abrar et.al.|[2501.00208v1](http://arxiv.org/abs/2501.00208v1)|null|
|**2024-12-31**|**GPT-4 on Clinic Depression Assessment: An LLM-Based Pilot Study**|Giuliano Lorenzoni et.al.|[2501.00199v1](http://arxiv.org/abs/2501.00199v1)|null|
|**2024-12-31**|**SepsisCalc: Integrating Clinical Calculators into Early Sepsis Prediction via Dynamic Temporal Graph Construction**|Changchang Yin et.al.|[2501.00190v1](http://arxiv.org/abs/2501.00190v1)|[link](https://github.com/yinchangchang/sepsislab)|
|**2024-12-30**|**DeepLL: Considering Linear Logic for the Analysis of Deep Learning Experiments**|Nick Papoulias et.al.|[2501.00169v1](http://arxiv.org/abs/2501.00169v1)|null|
|**2024-12-30**|**Temporal reasoning for timeline summarisation in social media**|Jiayu Song et.al.|[2501.00152v1](http://arxiv.org/abs/2501.00152v1)|null|
|**2024-12-30**|**A Data-Centric Approach to Detecting and Mitigating Demographic Bias in Pediatric Mental Health Text: A Case Study in Anxiety Detection**|Julia Ive et.al.|[2501.00129v1](http://arxiv.org/abs/2501.00129v1)|null|
|**2024-12-30**|**Leveraging AI for Automatic Classification of PCOS Using Ultrasound Imaging**|Atharva Divekar et.al.|[2501.01984v1](http://arxiv.org/abs/2501.01984v1)|[link](https://github.com/ATHdevs/Auto-PCOS)|
|**2024-12-30**|**Advancing Parkinson's Disease Progression Prediction: Comparing Long Short-Term Memory Networks and Kolmogorov-Arnold Networks**|Abhinav Roy et.al.|[2412.20744v1](http://arxiv.org/abs/2412.20744v1)|null|
|**2024-12-30**|**Latent Drifting in Diffusion Models for Counterfactual Medical Image Synthesis**|Yousef Yeganeh et.al.|[2412.20651v1](http://arxiv.org/abs/2412.20651v1)|null|
|**2024-12-29**|**HALLUCINOGEN: A Benchmark for Evaluating Object Hallucination in Large Visual-Language Models**|Ashish Seth et.al.|[2412.20622v1](http://arxiv.org/abs/2412.20622v1)|[link](https://github.com/AikyamLab/hallucinogen)|
|**2024-12-29**|**Dive into Time-Series Anomaly Detection: A Decade Review**|Paul Boniol et.al.|[2412.20512v1](http://arxiv.org/abs/2412.20512v1)|null|
|**2024-12-29**|**A Deep Subgrouping Framework for Precision Drug Repurposing via Emulating Clinical Trials on Real-world Patient Data**|Seungyeon Lee et.al.|[2412.20373v1](http://arxiv.org/abs/2412.20373v1)|null|
|**2024-12-28**|**Transforming CCTV cameras into NO$_2$ sensors at city scale for adaptive policymaking**|Mohamed R. Ibrahim et.al.|[2501.00056v1](http://arxiv.org/abs/2501.00056v1)|null|
|**2024-12-28**|**On the Compositional Generalization of Multimodal LLMs for Medical Imaging**|Zhenyang Cai et.al.|[2412.20070v1](http://arxiv.org/abs/2412.20070v1)|[link](https://github.com/freedomintelligence/med-mat)|
|**2024-12-28**|**The Emotional Spectrum of LLMs: Leveraging Empathy and Emotion-Based Markers for Mental Health Support**|Alessandro De Grandi et.al.|[2412.20068v1](http://arxiv.org/abs/2412.20068v1)|null|
|**2024-12-28**|**MobileNetV2: A lightweight classification model for home-based sleep apnea screening**|Hui Pan et.al.|[2412.19967v2](http://arxiv.org/abs/2412.19967v2)|[link](https://github.com/mindspore-lab/models/tree/master/research/arxiv_papers/Easy-MobileNetV2)|
|**2024-12-27**|**ErgoChat: a Visual Query System for the Ergonomic Risk Assessment of Construction Workers**|Chao Fan et.al.|[2412.19954v1](http://arxiv.org/abs/2412.19954v1)|null|
|**2024-12-27**|**An Integrated Optimization and Deep Learning Pipeline for Predicting Live Birth Success in IVF Using Feature Optimization and Transformer-Based Models**|Arezoo Borji et.al.|[2412.19696v1](http://arxiv.org/abs/2412.19696v1)|null|
|**2024-12-27**|**A Review on the Integration of Artificial Intelligence and Medical Imaging in IVF Ovarian Stimulation**|Jana Zakall et.al.|[2412.19688v1](http://arxiv.org/abs/2412.19688v1)|null|
|**2024-12-27**|**Disparate Model Performance and Stability in Machine Learning Clinical Support for Diabetes and Heart Diseases**|Ioannis Bilionis et.al.|[2412.19495v1](http://arxiv.org/abs/2412.19495v1)|null|
|**2024-12-26**|**Semi-Supervised Learning from Small Annotated Data and Large Unlabeled Data for Fine-grained PICO Entity Recognition**|Fangyi Chen et.al.|[2412.19346v1](http://arxiv.org/abs/2412.19346v1)|null|
|**2024-12-26**|**xSRL: Safety-Aware Explainable Reinforcement Learning -- Safety as a Product of Explainability**|Risal Shahriar Shefin et.al.|[2412.19311v1](http://arxiv.org/abs/2412.19311v1)|[link](https://github.com/risal-shefin/xsrl)|
|**2024-12-26**|**MEDEC: A Benchmark for Medical Error Detection and Correction in Clinical Notes**|Asma Ben Abacha et.al.|[2412.19260v2](http://arxiv.org/abs/2412.19260v2)|[link](https://github.com/abachaa/medec)|
|**2024-12-26**|**Leveraging Self-Training and Variational Autoencoder for Agitation Detection in People with Dementia Using Wearable Sensors**|Abeer Badawi et.al.|[2412.19254v1](http://arxiv.org/abs/2412.19254v1)|null|
|**2024-12-26**|**Evaluating Self-Supervised Learning in Medical Imaging: A Benchmark for Robustness, Generalizability, and Multi-Domain Impact**|Valay Bundele et.al.|[2412.19124v1](http://arxiv.org/abs/2412.19124v1)|null|
|**2024-12-26**|**Modality-Projection Universal Model for Comprehensive Full-Body Medical Imaging Segmentation**|Yixin Chen et.al.|[2412.19026v1](http://arxiv.org/abs/2412.19026v1)|[link](https://github.com/yixinchen-ai/mpum)|
|**2024-12-25**|**MedHallBench: A New Benchmark for Assessing Hallucination in Medical Large Language Models**|Kaiwen Zuo et.al.|[2412.18947v2](http://arxiv.org/abs/2412.18947v2)|null|
|**2024-12-25**|**HuatuoGPT-o1, Towards Medical Complex Reasoning with LLMs**|Junying Chen et.al.|[2412.18925v1](http://arxiv.org/abs/2412.18925v1)|[link](https://github.com/freedomintelligence/huatuogpt-o1)|
|**2024-12-25**|**Comprehensive Study on Lumbar Disc Segmentation Techniques Using MRI Data**|Serkan Salturk et.al.|[2412.18894v1](http://arxiv.org/abs/2412.18894v1)|null|
|**2024-12-25**|**Whose Morality Do They Speak? Unraveling Cultural Bias in Multilingual Language Models**|Meltem Aksoy et.al.|[2412.18863v1](http://arxiv.org/abs/2412.18863v1)|null|
|**2024-12-25**|**Unified Local and Global Attention Interaction Modeling for Vision Transformers**|Tan Nguyen et.al.|[2412.18778v1](http://arxiv.org/abs/2412.18778v1)|null|
|**2024-12-25**|**Successes and Limitations of Object-centric Models at Compositional Generalisation**|Milton L. Montero et.al.|[2412.18743v1](http://arxiv.org/abs/2412.18743v1)|null|
|**2024-12-24**|**SurvAttack: Black-Box Attack On Survival Models through Ontology-Informed EHR Perturbation**|Mohsen Nayebi Kerdabadi et.al.|[2412.18706v1](http://arxiv.org/abs/2412.18706v1)|null|
|**2024-12-24**|**A Review of Latent Representation Models in Neuroimaging**|C. VÃ¡zquez-GarcÃ­a et.al.|[2412.19844v1](http://arxiv.org/abs/2412.19844v1)|null|
|**2024-12-24**|**DiTCtrl: Exploring Attention Control in Multi-Modal Diffusion Transformer for Tuning-Free Multi-Prompt Longer Video Generation**|Minghong Cai et.al.|[2412.18597v1](http://arxiv.org/abs/2412.18597v1)|[link](https://github.com/tencentarc/ditctrl)|
|**2024-12-24**|**Advancing Deformable Medical Image Registration with Multi-axis Cross-covariance Attention**|Mingyuan Meng et.al.|[2412.18545v1](http://arxiv.org/abs/2412.18545v1)|null|
|**2024-12-24**|**Multi-Agent Norm Perception and Induction in Distributed Healthcare**|Chao Li et.al.|[2412.18454v1](http://arxiv.org/abs/2412.18454v1)|null|
|**2024-12-24**|**Research on the Proximity Relationships of Psychosomatic Disease Knowledge Graph Modules Extracted by Large Language Models**|Zihan Zhou et.al.|[2412.18419v1](http://arxiv.org/abs/2412.18419v1)|null|
|**2024-12-24**|**Unveiling the Threat of Fraud Gangs to Graph Neural Networks: Multi-Target Graph Injection Attacks Against GNN-Based Fraud Detectors**|Jinhyeok Choi et.al.|[2412.18370v2](http://arxiv.org/abs/2412.18370v2)|[link](https://github.com/bdi-lab/monti)|
|**2024-12-24**|**Real-world Deployment and Evaluation of PErioperative AI CHatbot (PEACH) -- a Large Language Model Chatbot for Perioperative Medicine**|Yu He Ke et.al.|[2412.18096v1](http://arxiv.org/abs/2412.18096v1)|null|
|**2024-12-23**|**Aligning AI Research with the Needs of Clinical Coding Workflows: Eight Recommendations Based on US Data Analysis and Critical Review**|Yidong Gan et.al.|[2412.18043v1](http://arxiv.org/abs/2412.18043v1)|null|

#### Abstracts
##### **From Simple to Complex Skills: The Case of In-Hand Object Reorientation**
2501.05439v1 by Haozhi Qi, Brent Yi, Mike Lambeta, Yi Ma, Roberto Calandra, Jitendra Malik

Learning policies in simulation and transferring them to the real world has
become a promising approach in dexterous manipulation. However, bridging the
sim-to-real gap for each new task requires substantial human effort, such as
careful reward engineering, hyperparameter tuning, and system identification.
In this work, we present a system that leverages low-level skills to address
these challenges for more complex tasks. Specifically, we introduce a
hierarchical policy for in-hand object reorientation based on previously
acquired rotation skills. This hierarchical policy learns to select which
low-level skill to execute based on feedback from both the environment and the
low-level skill policies themselves. Compared to learning from scratch, the
hierarchical policy is more robust to out-of-distribution changes and transfers
easily from simulation to real-world environments. Additionally, we propose a
generalizable object pose estimator that uses proprioceptive information,
low-level skill predictions, and control errors as inputs to estimate the
object pose over time. We demonstrate that our system can reorient objects,
including symmetrical and textureless ones, to a desired pose.

æè¦ï¼å¨æ¨¡æ¬ä¸­å­¸ç¿ç­ç¥ä¸¦å°å¶è½ç§»å°ç¾å¯¦ä¸çå·²æçºéå·§æä½ä¸­ä¸ç¨®æåæ¯çæ¹æ³ãç¶èï¼å°æ¼æ¯é æ°ä»»åä¾èªªï¼å½åæ¨¡æ¬å°ç¾å¯¦çå·®è·éè¦å¤§éçäººåï¼ä¾å¦ä»ç´°ççåµå·¥ç¨ãè¶åæ¸èª¿æ´åç³»çµ±è­å¥ãå¨éé å·¥ä½ä¸­ï¼æåæåºäºä¸åå©ç¨ä½å±¤æè½ä¾æå°æ´è¤éä»»åçææ°çç³»çµ±ãå·é«ä¾èªªï¼æåå¼å¥äºä¸ååºæ¼ååç²å¾çæè½æè½çæä¸­ç©é«éæ°å®åçåå±¤ç­ç¥ãéç¨®åå±¤ç­ç¥å­¸ç¿æ ¹æç°å¢åä½å±¤æè½ç­ç¥æ¬èº«çåé¥é¸æå·è¡åªç¨®ä½å±¤æè½ãèå¾é ­éå§å­¸ç¿ç¸æ¯ï¼åå±¤ç­ç¥å°åä½å¤è®åæ´å¼·å¥ï¼ä¸¦ä¸å¯ä»¥è¼é¬å°å¾æ¨¡æ¬è½ç§»å°ç¾å¯¦ä¸çç°å¢ãæ­¤å¤ï¼æåæåºäºä¸åå¯æ³åçç©é«å§¿å¢ä¼°è¨å¨ï¼å®ä½¿ç¨ proprioceptive ä¿¡æ¯ãä½å±¤æè½é æ¸¬åæ§å¶èª¤å·®ä½çºè¼¸å¥ä¾ä¼°è¨ç©é«å§¿å¢ãæåè­æäºæåçç³»çµ±å¯ä»¥å°ç©é«ï¼åæ¬å°ç¨±åç¡ç´ççç©é«ï¼éæ°å®åå°æéçå§¿å¢ã

##### **A Novel Pathology Foundation Model by Mayo Clinic, CharitÃ©, and Aignostics**
2501.05409v1 by Maximilian Alber, Stephan Tietz, Jonas Dippel, Timo Milbich, TimothÃ©e Lesort, Panos Korfiatis, Moritz KrÃ¼gener, Beatriz Perez Cancer, Neelay Shah, Alexander MÃ¶llers, Philipp Seegerer, Alexandra Carpen-Amarie, Kai Standvoss, Gabriel Dernbach, Edwin de Jong, Simon Schallenberg, Andreas Kunft, Helmut Hoffer von Ankershoffen, Gavin Schaeferle, Patrick Duffy, Matt Redlon, Philipp Jurmeister, David Horst, Lukas Ruff, Klaus-Robert MÃ¼ller, Frederick Klauschen, Andrew Norgan

Recent advances in digital pathology have demonstrated the effectiveness of
foundation models across diverse applications. In this report, we present a
novel vision foundation model based on the RudolfV approach. Our model was
trained on a dataset comprising 1.2 million histopathology whole slide images,
collected from two medical institutions: Mayo Clinic and Charit\'e -
Universt\"atsmedizin Berlin. Comprehensive evaluations show that our model
achieves state-of-the-art performance across twenty-one public benchmark
datasets, even though it is neither the largest model by parameter count nor by
training dataset size.

æè¦ï¼æè¿å¨æ¸ä½ççå­¸çé²å±å·²å±ç¤ºåºåºç¤æ¨¡åå¨åç¨®æç¨ä¸­çæææ§ãå¨æ­¤å ±åä¸­ï¼æåæåºä¸ååºæ¼ RudolfV æ¹æ³çæ°ç©è¦è¦ºåºç¤æ¨¡åãæåçæ¨¡åæ¯å¨ä¸ååå« 120 è¬å¼µçµç¹ççå­¸å¨åçå½±åçè³æéä¸è¨ç·´ï¼éäºå½±åä¾èªå©åé«çæ©æ§ï¼æ¢ç´è¨ºæåå¤éç¹å¤§å­¸é«å­¸ä¸­å¿ãå¨é¢çè©ä¼°é¡¯ç¤ºï¼æåçæ¨¡åå¨ 21 åå¬éåºæºè³æéä¸éå°äºæåé²çæè½ï¼åç®¡å®æ¢ä¸æ¯åæ¸è¨æ¸æå¤§çæ¨¡åï¼ä¹ä¸æ¯è¨ç·´è³æéè¦æ¨¡æå¤§çæ¨¡åã

##### **An Algorithmic Approach for Causal Health Equity: A Look at Race Differentials in Intensive Care Unit (ICU) Outcomes**
2501.05197v1 by Drago Plecko, Paul Secombe, Andrea Clarke, Amelia Fiske, Samarra Toby, Donisha Duff, David Pilcher, Leo Anthony Celi, Rinaldo Bellomo, Elias Bareinboim

The new era of large-scale data collection and analysis presents an
opportunity for diagnosing and understanding the causes of health inequities.
In this study, we describe a framework for systematically analyzing health
disparities using causal inference. The framework is illustrated by
investigating racial and ethnic disparities in intensive care unit (ICU)
outcome between majority and minority groups in Australia (Indigenous vs.
Non-Indigenous) and the United States (African-American vs. White). We
demonstrate that commonly used statistical measures for quantifying inequity
are insufficient, and focus on attributing the observed disparity to the causal
mechanisms that generate it. We find that minority patients are younger at
admission, have worse chronic health, are more likely to be admitted for urgent
and non-elective reasons, and have higher illness severity. At the same time,
however, we find a protective direct effect of belonging to a minority group,
with minority patients showing improved survival compared to their majority
counterparts, with all other variables kept equal. We demonstrate that this
protective effect is related to the increased probability of being admitted to
ICU, with minority patients having an increased risk of ICU admission. We also
find that minority patients, while showing improved survival, are more likely
to be readmitted to ICU. Thus, due to worse access to primary health care,
minority patients are more likely to end up in ICU for preventable conditions,
causing a reduction in the mortality rates and creating an effect that appears
to be protective. Since the baseline risk of ICU admission may serve as proxy
for lack of access to primary care, we developed the Indigenous Intensive Care
Equity (IICE) Radar, a monitoring system for tracking the over-utilization of
ICU resources by the Indigenous population of Australia across geographical
areas.

æè¦ï¼å¤§åè³ææ¶éååæçæ°æä»£ï¼æä¾äºè¨ºæ·åäºè§£å¥åº·ä¸å¹³ç­æå çæ©æãå¨éé ç ç©¶ä¸­ï¼æåæè¿°äºä¸åä½¿ç¨å ææ¨è«ç³»çµ±åæå¥åº·å·®è·çæ¶æ§ãéåæ¶æ§ééèª¿æ¥æ¾³æ´²ï¼åä½æ°å°éåä½æ°ï¼åç¾åï¼éè£ç¾åäººå°ç½äººï¼ä¸­ï¼éçå è­·çæ¿ï¼ICUï¼çµæå¨ç¨®æåæç¾¤ä¸çå·®ç°ä¾å ä»¥èªªæãæåè­æäºéå¸¸ç¨æ¼éåä¸å¹³ç­ççµ±è¨æ¸¬éæ¯ä¸å¤ çï¼ä¸¦å°æ³¨æ¼å°è§å¯å°çå·®ç°æ­¸å æ¼ç¢çå®çå ææ©å¶ãæåç¼ç¾ï¼å°æ¸æè£æ£èå¨å¥é¢æè¼å¹´è¼ï¼æ¢æ§å¥åº·çæ³è¼å·®ï¼æ´æå¯è½å ç·æ¥åéé¸ææ§åå èå¥é¢ï¼ä¸ç¾çå´éç¨åº¦è¼é«ãç¶èï¼åææåç¼ç¾å±¬æ¼å°æ¸æè£ç¾¤é«å·æä¿è­·æ§çç´æ¥å½±é¿ï¼èå¤æ¸æè£çå°ç§çµç¸æ¯ï¼å°æ¸æè£æ£èå¨å¶ä»ææè®æ¸ä¿æç¸åçææ³ä¸ï¼å­æ´»çæææ¹åãæåè­æéç¨®ä¿è­·ææèè¢«éé² ICU çæ©çå¢å æéï¼å°æ¸æè£æ£èç ICU å¥é¢é¢¨éªå¢å ãæåä¹ç¼ç¾ï¼å°æ¸æè£æ£èéç¶å­æ´»çæææ¹åï¼ä½æ´æå¯è½åæ¬¡å¥é¢å° ICUãå æ­¤ï¼ç±æ¼è¼é£ç²å¾åç´é«çä¿å¥ï¼å°æ¸æè£æ£èæ´æå¯è½å å¯é é²çç¾çèé²å¥ ICUï¼å°è´æ­»äº¡çéä½ä¸¦ç¢ççä¼¼å·æä¿è­·ä½ç¨çææãç±æ¼ ICU å¥é¢çåºæ¬é¢¨éªå¯è½ä½çºç¼ºä¹åç´ç§è­·çææ¨ï¼å æ­¤æåéç¼äºåä½æ°éçç£è­·å¬å¹³æ§ï¼IICEï¼é·éï¼éæ¯ä¸åç£æ§ç³»çµ±ï¼ç¨æ¼è¿½è¹¤æ¾³æ´²åä½æ°äººå£å¨ä¸åå°çååéåº¦ä½¿ç¨ ICU è³æºçææ³ã

##### **Addressing Domain Shift via Imbalance-Aware Domain Adaptation in Embryo Development Assessment**
2501.04958v1 by Lei Li, Xinglin Zhang, Jun Liang, Tao Chen

Deep learning models in medical imaging face dual challenges: domain shift,
where models perform poorly when deployed in settings different from their
training environment, and class imbalance, where certain disease conditions are
naturally underrepresented. We present Imbalance-Aware Domain Adaptation
(IADA), a novel framework that simultaneously tackles both challenges through
three key components: (1) adaptive feature learning with class-specific
attention mechanisms, (2) balanced domain alignment with dynamic weighting, and
(3) adaptive threshold optimization. Our theoretical analysis establishes
convergence guarantees and complexity bounds. Through extensive experiments on
embryo development assessment across four imaging modalities, IADA demonstrates
significant improvements over existing methods, achieving up to 25.19\% higher
accuracy while maintaining balanced performance across classes. In challenging
scenarios with low-quality imaging systems, IADA shows robust generalization
with AUC improvements of up to 12.56\%. These results demonstrate IADA's
potential for developing reliable and equitable medical imaging systems for
diverse clinical settings. The code is made public available at
\url{https://github.com/yinghemedical/imbalance-aware_domain_adaptation}

æè¦ï¼<paragraph>é«çå½±åä¸­çæ·±åº¦å­¸ç¿æ¨¡åé¢è¨ééææ°ï¼é åè½ç§»ï¼æ¨¡åå¨èå¶è¨ç·´ç°å¢ä¸åçè¨­å®ä¸­é¨ç½²æè¡¨ç¾ä¸ä½³ï¼ä»¥åé¡å¥ä¸å¹³è¡¡ï¼æäºç¾ççæ³å¨èªç¶çä¸­ä»£è¡¨æ§ä¸è¶³ãæåæåºä¸å¹³è¡¡æç¥åé©æ (IADA)ï¼éæ¯ä¸åæ°ç©çæ¡æ¶ï¼ééä¸åééµçµæé¨ååææå°éå©åææ°ï¼(1) å·æé¡å¥ç¹å®æ³¨æåæ©å¶çèªé©æç¹å¾µå­¸ç¿ï¼(2) å·æåæå æ¬çå¹³è¡¡åå°é½ï¼ä»¥å (3) èªé©æé¾å¼æä½³åãæåççè«åæå»ºç«äºæ¶æä¿è­åè¤éåº¦çéãééå°åç¨®å½±åæ¨¡å¼çèèç¼è²è©ä¼°é²è¡å»£æ³çå¯¦é©ï¼IADA è­æäºå°ç¾ææ¹æ³çé¡¯èæ¹é²ï¼å¨ç¶­æé¡å¥éå¹³è¡¡æ§è½çåæï¼æºç¢ºåº¦æé«äº 25.19%ãå¨ä½åè³ªå½±åç³»çµ±çææ°æ§å ´æ¯ä¸­ï¼IADA ä»¥é«é 12.56% ç AUC æ¹é²é¡¯ç¤ºåºå¼·å¤§çæ³åè½åãéäºçµæè­æäº IADA å¨çºä¸åçè¨åºè¨­å®éç¼å¯é ä¸å¬å¹³çé«çå½±åç³»çµ±æ¹é¢çæ½åãç¨å¼ç¢¼å·²å¬éæ¼ \url{https://github.com/yinghemedical/imbalance-aware_domain_adaptation}</paragraph>

##### **Quantifying Itch and its Impact on Sleep Using Machine Learning and Radio Signals**
2501.04896v1 by Michail Ouroutzoglou, Mingmin Zhao, Joshua Hellerstein, Hariharan Rahul, Asima Badic, Brian S. Kim, Dina Katabi

Chronic itch affects 13% of the US population, is highly debilitating, and
underlies many medical conditions. A major challenge in clinical care and new
therapeutics development is the lack of an objective measure for quantifying
itch, leading to reliance on subjective measures like patients' self-assessment
of itch severity. In this paper, we show that a home radio device paired with
artificial intelligence (AI) can concurrently capture scratching and evaluate
its impact on sleep quality by analyzing radio signals bouncing in the
environment. The device eliminates the need for wearable sensors or skin
contact, enabling monitoring of chronic itch over extended periods at home
without burdening patients or interfering with their skin condition. To
validate the technology, we conducted an observational clinical study of
chronic pruritus patients, monitored at home for one month using both the radio
device and an infrared camera. Comparing the output of the device to ground
truth data from the camera demonstrates its feasibility and accuracy (ROC AUC =
0.997, sensitivity = 0.825, specificity = 0.997). The results reveal a
significant correlation between scratching and low sleep quality, manifested as
a reduction in sleep efficiency (R = 0.6, p < 0.001) and an increase in sleep
latency (R = 0.68, p < 0.001). Our study underscores the potential of passive,
long-term, at-home monitoring of chronic scratching and its sleep implications,
offering a valuable tool for both clinical care of chronic itch patients and
pharmaceutical clinical trials.

æè¦ï¼æ¢æ§æç¢å½±é¿ç¾å 13% çäººå£ï¼æå´éè¡°å¼±ï¼ä¸æ¯è¨±å¤ç¾ççæ ¹æ¬åå ãè¨åºè­·çåæ°çæ³éç¼çä¸å¤§ææ°æ¯ç¼ºä¹å®¢è§çææ¨ä¾éåæç¢ï¼å°è´ä¾è³´æ¼æ£èèªæè©ä¼°æç¢å´éç¨åº¦ç­ä¸»è§ææ¨ãå¨æ¬æä¸­ï¼æåå±ç¤ºäºä¸ç¨®èäººå·¥æºæ§ (AI) éå°çå®¶ç¨ç¡ç·é»è£ç½®ï¼å¯ééåæå¨ç°å¢ä¸­å½è·³çç¡ç·é»è¨èï¼åææ·åææä¸¦è©ä¼°å¶å°ç¡ç åè³ªçå½±é¿ãæ­¤è£ç½®æ¶é¤äºå°ç©¿æ´å¼ææ¸¬å¨æç®èæ¥è§¸çéæ±ï¼è®æ£èå¨å®¶ä¸­é·æéç£æ§æ¢æ§æç¢ï¼èä¸æé æè² ææå¹²æ¾å¶ç®èçæ³ãçºäºé©è­éé æè¡ï¼æåå°æ¢æ§æç¢çæ£èé²è¡äºä¸é è§å¯æ§è¨åºç ç©¶ï¼ä½¿ç¨ç¡ç·é»è£ç½®åç´å¤ç·æå½±æ©å¨å®¶ä¸­ç£æ§ä¸åæãå°è£ç½®çè¼¸åºèæå½±æ©ççå¯¦æ¸æé²è¡æ¯è¼ï¼è­æäºå¶å¯è¡æ§åæºç¢ºæ§ (ROC AUC = 0.997ï¼éæåº¦ = 0.825ï¼ç¹ç°åº¦ = 0.997)ãçµæé¡¯ç¤ºææèç¡ç åè³ªä½ä¸ä¹éå­å¨é¡¯èç¸éæ§ï¼è¡¨ç¾çºç¡ç æçéä½ (R = 0.6ï¼p < 0.001) åç¡ç æ½ä¼æå¢å  (R = 0.68ï¼p < 0.001)ãæåçç ç©¶å¼·èª¿äºè¢«åãé·æãå¨å®¶ä¸­ç£æ§æ¢æ§ææåå¶å°ç¡ç çå½±é¿çæ½åï¼çºæ¢æ§æç¢çæ£èçè¨åºè­·çåè¥å» è¨åºè©¦é©æä¾äºæå¹å¼çå·¥å·ã

##### **MedCoDi-M: A Multi-Prompt Foundation Model for Multimodal Medical Data Generation**
2501.04614v2 by Daniele Molino, Francesco Di Feola, Eliodoro Faiella, Deborah Fazzini, Domiziana Santucci, Linlin Shen, Valerio Guarrasi, Paolo Soda

Artificial Intelligence is revolutionizing medical practice, enhancing
diagnostic accuracy and healthcare delivery. However, its adaptation in medical
settings still faces significant challenges, related to data availability and
privacy constraints. Synthetic data has emerged as a promising solution to
mitigate these issues, addressing data scarcity while preserving privacy.
Recently, Latent Diffusion Models have emerged as a powerful tool for
generating high-quality synthetic data. Meanwhile, the integration of different
modalities has gained interest, emphasizing the need of models capable of
handle multimodal medical data. Existing approaches struggle to integrate
complementary information and lack the ability to generate modalities
simultaneously. To address this challenge, we present MedCoDi-M, a
6.77-billion-parameter model, designed for multimodal medical data generation,
that, following Foundation Model paradigm, exploits contrastive learning and
large quantity of data to build a shared latent space which capture the
relationships between different data modalities. Further, we introduce the
Multi-Prompt training technique, which significantly boosts MedCoDi-M's
generation under different settings. We extensively validate MedCoDi-M: first
we benchmark it against five competitors on the MIMIC-CXR dataset, a
state-of-the-art dataset for Chest X-ray and radiological report generation.
Secondly, we perform a Visual Turing Test with expert radiologists to assess
the realism and clinical relevance of the generated data, ensuring alignment
with real-world scenarios. Finally, we assess the utility of MedCoDi-M in
addressing key challenges in the medical field, such as anonymization, data
scarcity and imbalance learning. The results are promising, demonstrating the
applicability of MedCoDi-M in medical contexts. Project page is at
https://cosbidev.github.io/MedCoDi-M/.

æè¦ï¼äººå·¥æºè½æ­£å¨é©æ°é«çå¯¦åï¼æåè¨ºæ·æºç¢ºåº¦åé«çä¿å¥æåãç¶èï¼å®å¨é«çå ´æ¯ä¸­çæç¨ä»é¢è¨èéå¤§ææ°ï¼éèè³æå¯ç¨æ§åé±ç§éå¶æéãåæè³æå·²æçºç·©è§£éäºåé¡çæ½å¨è§£æ±ºæ¹æ¡ï¼å®å¨ä¿è­·é±ç§çåæè§£æ±ºäºè³æç­ç¼ºçåé¡ãæè¿ï¼æ½å¨æ´æ£æ¨¡åå·²æçºç¢çé«åè³ªåæè³æçå¼·å¤§å·¥å·ãåæï¼æ´åä¸åæ¨¡æå·²å¼èµ·èè¶£ï¼å¼·èª¿äºéè¦è½å¤ èçå¤æ¨¡æé«çè³æçæ¨¡åãç¾ææ¹æ³é£ä»¥æ´åè£åè³è¨ï¼ä¸¦ä¸ç¼ºä¹åæç¢çæ¨¡æçè½åãçºäºæå°éä¸ææ°ï¼æåæåºäº MedCoDi-Mï¼éæ¯ä¸å 67.7 ååæ¸çæ¨¡åï¼å°çºå¤æ¨¡æé«çè³æç¢çèè¨­è¨ï¼å®éµå¾ªåºç¤æ¨¡åç¯ä¾ï¼å©ç¨å°æ¯å­¸ç¿åå¤§éçè³æä¾å»ºç«ä¸åå±äº«æ½å¨ç©ºéï¼ä»¥ææä¸åè³ææ¨¡æä¹éçéä¿ãæ­¤å¤ï¼æåå¼å¥äºå¤æç¤ºè¨ç·´æè¡ï¼å®é¡¯èæåäº MedCoDi-M å¨ä¸åè¨­å®ä¸çç¢çãæåå»£æ³é©è­äº MedCoDi-Mï¼é¦åï¼æåå¨ MIMIC-CXR è³æéä¸å°å®èäºåç«¶ç­èé²è¡äºåºæºæ¸¬è©¦ï¼éæ¯è¸é¨ X ååæ¾å°å ±åç¢çé åçææ°è³æéãå¶æ¬¡ï¼æåèæ¾å°ç§å°å®¶é²è¡äºè¦è¦ºåéæ¸¬è©¦ï¼ä»¥è©ä¼°ç¢çè³æççå¯¦æ§åè¨åºç¸éæ§ï¼ç¢ºä¿èçå¯¦å ´æ¯ä¿æä¸è´ãæå¾ï¼æåè©ä¼°äº MedCoDi-M å¨è§£æ±ºé«çé åééµææ°ä¸­çæç¨ï¼ä¾å¦å¿ååãè³æç­ç¼ºåä¸å¹³è¡¡å­¸ç¿ãçµæä»¤äººæ»¿æï¼è­æäº MedCoDi-M å¨é«çç°å¢ä¸­çé©ç¨æ§ãå°æ¡é é¢ä½æ¼ https://cosbidev.github.io/MedCoDi-M/ã

##### **A 65 nm Bayesian Neural Network Accelerator with 360 fJ/Sample In-Word GRNG for AI Uncertainty Estimation**
2501.04577v1 by Zephan M. Enciso, Boyang Cheng, Likai Pei, Jianbo Liu, Steven Davis, Ningyuan Cao, Michael Niemier

Uncertainty estimation is an indispensable capability for AI-enabled,
safety-critical applications, e.g. autonomous vehicles or medical diagnosis.
Bayesian neural networks (BNNs) use Bayesian statistics to provide both
classification predictions and uncertainty estimation, but they suffer from
high computational overhead associated with random number generation and
repeated sample iterations. Furthermore, BNNs are not immediately amenable to
acceleration through compute-in-memory architectures due to the frequent memory
writes necessary after each RNG operation. To address these challenges, we
present an ASIC that integrates 360 fJ/Sample Gaussian RNG directly into the
SRAM memory words. This integration reduces RNG overhead and enables
fully-parallel compute-in-memory operations for BNNs. The prototype chip
achieves 5.12 GSa/s RNG throughput and 102 GOp/s neural network throughput
while occupying 0.45 mm2, bringing AI uncertainty estimation to edge
computation.

æè¦ï¼ä¸ç¢ºå®æ§ä¼°è¨å°æ¼ AI é©åãå®å¨ééµçæç¨ç¨å¼ä¾èªªæ¯ä¸å¯æç¼ºçè½åï¼ä¾å¦èªåé§é§è»è¼æé«çè¨ºæ·ãè²æ°é¡ç¥ç¶ç¶²è·¯ (BNN) ä½¿ç¨è²æ°çµ±è¨ä¾æä¾åé¡é æ¸¬åä¸ç¢ºå®æ§ä¼°è¨ï¼ä½å®åæå é¨æ©æ¸çæåéè¤æ¨£æ¬è¿­ä»£èç¢çé«éç®è² æãæ­¤å¤ï¼ç±æ¼æ¯æ¬¡ RNG æä½å¾é½éè¦é »ç¹çè¨æ¶é«å¯«å¥ï¼å æ­¤ BNN ç¡æ³ç«å³é©ç¨æ¼ééè¨æ¶é«éç®æ¶æ§é²è¡å éãçºäºæå°éäºææ°ï¼æåæåºäºä¸æ¬¾ ASICï¼å° 360 fJ/Sample Gaussian RNG ç´æ¥æ´åå° SRAM è¨æ¶é«å­åä¸­ãæ­¤æ´åå¯æ¸å° RNG è² æï¼ä¸¦çº BNN åç¨å®å¨ä¸¦è¡çè¨æ¶é«éç®æä½ãååæ¶çå¯éæ 5.12 GSa/s RNG èçéå 102 GOp/s ç¥ç¶ç¶²è·¯èçéï¼åæä½ç¨ 0.45 mm2ï¼å° AI ä¸ç¢ºå®æ§ä¼°è¨å¸¶å°éç·£éç®ã

##### **Continual Self-supervised Learning Considering Medical Domain Knowledge in Chest CT Images**
2501.04217v1 by Ren Tasai, Guang Li, Ren Togo, Minghui Tang, Takaaki Yoshimura, Hiroyuki Sugimori, Kenji Hirata, Takahiro Ogawa, Kohsuke Kudo, Miki Haseyama

We propose a novel continual self-supervised learning method (CSSL)
considering medical domain knowledge in chest CT images. Our approach addresses
the challenge of sequential learning by effectively capturing the relationship
between previously learned knowledge and new information at different stages.
By incorporating an enhanced DER into CSSL and maintaining both diversity and
representativeness within the rehearsal buffer of DER, the risk of data
interference during pretraining is reduced, enabling the model to learn more
richer and robust feature representations. In addition, we incorporate a mixup
strategy and feature distillation to further enhance the model's ability to
learn meaningful representations. We validate our method using chest CT images
obtained under two different imaging conditions, demonstrating superior
performance compared to state-of-the-art methods.

æè¦ï¼æåæåºäºä¸ç¨®æ°çæçºèªæç£ç£å­¸ç¿æ¹æ³ (CSSL)ï¼èéäºè¸é¨é»è¦æ·å±¤å½±åä¸­çé«å­¸é åç¥è­ãæåçåæ³ééææææååå­¸ç¿çç¥è­èä¸åéæ®µçæ°è³è¨ä¹éçéä¿ï¼ä¾è§£æ±ºå¾ªåºå­¸ç¿çææ°ãééå°å¢å¼·ç DER ç´å¥ CSSLï¼ä¸¦å¨ DER çæç·´ç·©è¡åå§ç¶­æå¤æ¨£æ§åä»£è¡¨æ§ï¼é è¨ç·´æéè³æå¹²æ¾çé¢¨éªéä½ï¼ä½¿æ¨¡åè½å¤ å­¸ç¿æ´è±å¯ä¸å¼·å¥çç¹å¾µè¡¨å¾µãæ­¤å¤ï¼æåç´å¥æ··æ·ç­ç¥åç¹å¾µèåï¼é²ä¸æ­¥å¢å¼·æ¨¡åå­¸ç¿ææç¾©è¡¨å¾µçè½åãæåä½¿ç¨å¨å©ç¨®ä¸åå½±åæ¢ä»¶ä¸åå¾çè¸é¨é»è¦æ·å±¤å½±åé©è­æåçæ¨¡åï¼è­æèç¾ææè¡ç¸æ¯å·æåªç°çæè½ã

##### **Generative Style Transfer for MRI Image Segmentation: A Case of Glioma Segmentation in Sub-Saharan Africa**
2501.04734v1 by Rancy Chepchirchir, Jill Sunday, Raymond Confidence, Dong Zhang, Talha Chaudhry, Udunna C. Anazodo, Kendi Muchungi, Yujing Zou

In Sub-Saharan Africa (SSA), the utilization of lower-quality Magnetic
Resonance Imaging (MRI) technology raises questions about the applicability of
machine learning methods for clinical tasks. This study aims to provide a
robust deep learning-based brain tumor segmentation (BraTS) method tailored for
the SSA population using a threefold approach. Firstly, the impact of domain
shift from the SSA training data on model efficacy was examined, revealing no
significant effect. Secondly, a comparative analysis of 3D and 2D
full-resolution models using the nnU-Net framework indicates similar
performance of both the models trained for 300 epochs achieving a five-fold
cross-validation score of 0.93. Lastly, addressing the performance gap observed
in SSA validation as opposed to the relatively larger BraTS glioma (GLI)
validation set, two strategies are proposed: fine-tuning SSA cases using the
GLI+SSA best-pretrained 2D fullres model at 300 epochs, and introducing a novel
neural style transfer-based data augmentation technique for the SSA cases. This
investigation underscores the potential of enhancing brain tumor prediction
within SSA's unique healthcare landscape.

æè¦ï¼å¨æåæä»¥åéæ´² (SSA)ï¼ä½è´¨éç£å±æ¯æå (MRI) ææ¯çä½¿ç¨å¼åäºæå³æºå¨å­¦ä¹ æ¹æ³å¨ä¸´åºä»»å¡ä¸­éç¨æ§çé®é¢ãæ¬ç ç©¶æ¨å¨æä¾ä¸ç§éå¯¹ SSA äººç¾¤éèº«å®å¶çé²æ£æ·±åº¦å­¦ä¹ èè¿ç¤åå² (BraTS) æ¹æ³ï¼éç¨ä¸éæ¹æ³ãé¦åï¼æ£æ¥äº SSA è®­ç»æ°æ®å¯¹æ¨¡åæè½çååç§»å½±åï¼ç»ææ¾ç¤ºæ²¡ææ¾çå½±åãå¶æ¬¡ï¼ä½¿ç¨ nnU-Net æ¡æ¶å¯¹ 3D å 2D å¨åè¾¨çæ¨¡åè¿è¡æ¯è¾åæï¼è¡¨æéå¯¹ 300 ä¸ª epoch è®­ç»çä¸¤ä¸ªæ¨¡åçæ§è½ç¸ä¼¼ï¼å®ç°äº 0.93 çäºéäº¤åéªè¯åæ°ãæåï¼éå¯¹ SSA éªè¯ä¸­è§å¯å°çæ§è½å·®è·ï¼èä¸æ¯ç¸å¯¹è¾å¤§ç BraTS ç¥ç»è¶è´¨ç¤ (GLI) éªè¯éï¼æåºäºä¸¤ç§ç­ç¥ï¼ä½¿ç¨ GLI+SSA æä½³é¢è®­ç»ç 2D å¨åè¾¨çæ¨¡åå¨ 300 ä¸ª epoch å¯¹ SSA çä¾è¿è¡å¾®è°ï¼å¹¶ä¸º SSA çä¾å¼å¥ä¸ç§æ°é¢çç¥ç»é£æ ¼è¿ç§»æ°æ®å¢å¼ºææ¯ãè¿é¡¹è°æ¥å¼ºè°äºå¨ SSA ç¬ç¹çå»çä¿å¥ç¯å¢ä¸­æé«èè¿ç¤é¢æµæ½åçå¯è½æ§ã

##### **Exploring the Potential of Large Language Models in Public Transportation: San Antonio Case Study**
2501.03904v1 by Ramya Jonnala, Gongbo Liang, Jeong Yang, Izzat Alsmadi

The integration of large language models (LLMs) into public transit systems
presents a transformative opportunity to enhance urban mobility. This study
explores the potential of LLMs to revolutionize public transportation
management within the context of San Antonio's transit system. Leveraging the
capabilities of LLMs in natural language processing and data analysis, we
investigate their capabilities to optimize route planning, reduce wait times,
and provide personalized travel assistance. By utilizing the General Transit
Feed Specification (GTFS) and other relevant data, this research aims to
demonstrate how LLMs can potentially improve resource allocation, elevate
passenger satisfaction, and inform data-driven decision-making in transit
operations. A comparative analysis of different ChatGPT models was conducted to
assess their ability to understand transportation information, retrieve
relevant data, and provide comprehensive responses. Findings from this study
suggest that while LLMs hold immense promise for public transit, careful
engineering and fine-tuning are essential to realizing their full potential.
San Antonio serves as a case study to inform the development of LLM-powered
transit systems in other urban environments.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) æ´åå°å¬å±äº¤éç³»çµ±ä¸­ï¼çºæååå¸æµåæ§å¸¶ä¾è½åå¥æ©ãæ¬ç ç©¶æ¢è¨ LLM å¨èå®æ±å°¼å¥§äº¤éç³»çµ±èçµ¡ä¸ï¼é©æ°å¤§ç¾éè¼¸ç®¡ççæ½åãå©ç¨ LLM å¨èªç¶èªè¨èçåè³æåææ¹é¢çè½åï¼æåæ¢è¨å¶å¨åªåè·¯ç·è¦åãç¸®ç­ç­åæéï¼ä»¥åæä¾åäººåæéåå©æ¹é¢çè½åãééå©ç¨éç¨å¤§ç¾éè¼¸è³æè¦ç¯ (GTFS) åå¶ä»ç¸éè³æï¼æ¬ç ç©¶æ¨å¨è­æ LLM å¦ä½æ½å¨æåè³æºéç½®ãæåä¹å®¢æ»¿æåº¦ï¼ä»¥åå¨äº¤éçéä¸­æä¾è³æé©åçæ±ºç­ãéå°ä¸åç ChatGPT æ¨¡åé²è¡æ¯è¼åæï¼ä»¥è©ä¼°å¶çè§£äº¤éè³è¨ãæ·åç¸éè³æï¼ä»¥åæä¾å¨é¢åæçè½åãæ¬ç ç©¶çç¼ç¾é¡¯ç¤ºï¼åç®¡ LLM å°å¤§ç¾éè¼¸æ¥µå·åæ¯ï¼ä½ç²¾å¯çå·¥ç¨åå¾®èª¿å°æ¼å¯¦ç¾å¶å¨é¨æ½åè³ééè¦ãèå®æ±å°¼å¥§ä½çºä¸åæ¡ä¾ç ç©¶ï¼çºå¨å¶ä»é½å¸ç°å¢ä¸­éç¼ç± LLM é©åçäº¤éç³»çµ±æä¾åèã

##### **SCC-YOLO: An Improved Object Detector for Assisting in Brain Tumor Diagnosis**
2501.03836v1 by Runci Bai

Brain tumors can result in neurological dysfunction, alterations in cognitive
and psychological states, increased intracranial pressure, and the occurrence
of seizures, thereby presenting a substantial risk to human life and health.
The You Only Look Once(YOLO) series models have demonstrated superior accuracy
in object detection for medical imaging. In this paper, we develop a novel
SCC-YOLO architecture by integrating the SCConv attention mechanism into
YOLOv9. The SCConv module reconstructs an efficient convolutional module by
reducing spatial and channel redundancy among features, thereby enhancing the
learning of image features. We investigate the impact of intergrating different
attention mechanisms with the YOLOv9 model on brain tumor image detection using
both the Br35H dataset and our self-made dataset(Brain_Tumor_Dataset).
Experimental results show that on the Br35H dataset, SCC-YOLO achieved a 0.3%
improvement in mAp50 compared to YOLOv9, while on our self-made dataset,
SCC-YOLO exhibited a 0.5% improvement over YOLOv9. SCC-YOLO has reached
state-of-the-art performance in brain tumor detection. Source code is available
at : https://jihulab.com/healthcare-information-studio/SCC-YOLO/-/tree/master

æè¦ï¼è¦ç¤å¯è½å°è´ç¥ç¶åè½éç¤ãèªç¥åå¿ççææ¹è®ãé¡±å§å£åé«ï¼ä»¥åç²çç¼ä½ï¼å æ­¤å°äººé¡çå½åå¥åº·æ§æéå¤§é¢¨éªãYou Only Look Once (YOLO) ç³»åæ¨¡åå·²è­æå¨é«å­¸å½±åçç©ä»¶åµæ¸¬ä¸­å·æåªç°çæºç¢ºåº¦ãå¨æ¬æä¸­ï¼æåééå° SCConv æ³¨æåæ©å¶æ´åå° YOLOv9 ä¸­ï¼éç¼åºæ°ç©ç SCC-YOLO æ¶æ§ãSCConv æ¨¡çµééæ¸å°ç¹å¾µä¸­çç©ºéåééåé¤ä¾éå»ºä¸åé«æçå·ç©æ¨¡çµï¼å¾èå¢å¼·å½±åç¹å¾µçå­¸ç¿ãæåä½¿ç¨ Br35H è³æéåæåèªè£½çè³æé (Brain_Tumor_Dataset) æ¢è¨äºå°ä¸åçæ³¨æåæ©å¶è YOLOv9 æ¨¡åæ´åå°è¦ç¤å½±ååµæ¸¬çå½±é¿ãå¯¦é©çµæé¡¯ç¤ºï¼å¨ Br35H è³æéä¸ï¼SCC-YOLO å¨ mAp50 æ¹é¢æ¯ YOLOv9 æåäº 0.3%ï¼èå¨æåèªè£½çè³æéä¸ï¼SCC-YOLO æ¯ YOLOv9 æåäº 0.5%ãSCC-YOLO å·²å¨è¦ç¤åµæ¸¬æ¹é¢éå°æåé²çæè½ãåå§ç¢¼å¯æ¼ä»¥ä¸ç¶²ååå¾ï¼https://jihulab.com/healthcare-information-studio/SCC-YOLO/-/tree/master

##### **SelectiveFinetuning: Enhancing Transfer Learning in Sleep Staging through Selective Domain Alignment**
2501.03764v1 by Siyuan Zhao, Chenyu Liu, Yi Ding, Xinliang Zhou

In practical sleep stage classification, a key challenge is the variability
of EEG data across different subjects and environments. Differences in
physiology, age, health status, and recording conditions can lead to domain
shifts between data. These domain shifts often result in decreased model
accuracy and reliability, particularly when the model is applied to new data
with characteristics different from those it was originally trained on, which
is a typical manifestation of negative transfer. To address this, we propose
SelectiveFinetuning in this paper. Our method utilizes a pretrained Multi
Resolution Convolutional Neural Network (MRCNN) to extract EEG features,
capturing the distinctive characteristics of different sleep stages. To
mitigate the effect of domain shifts, we introduce a domain aligning mechanism
that employs Earth Mover Distance (EMD) to evaluate and select source domain
data closely matching the target domain. By finetuning the model with selective
source data, our SelectiveFinetuning enhances the model's performance on target
domain that exhibits domain shifts compared to the data used for training.
Experimental results show that our method outperforms existing baselines,
offering greater robustness and adaptability in practical scenarios where data
distributions are often unpredictable.

æè¦ï¼å¨å¯¦éçç¡ç éæ®µåé¡ä¸­ï¼ä¸åééµçææ°æ¯è¦é»åæ¸æå¨ä¸ååè©¦èåç°å¢ä¸­çè®ç°æ§ãççãå¹´é½¡ãå¥åº·çæ³åè¨éæ¢ä»¶çå·®ç°å¯è½å°è´æ¸æä¹éçé ååç§»ãéäºé ååç§»éå¸¸æå°è´æ¨¡åæºç¢ºåº¦åå¯é æ§ä¸éï¼ç¹å¥æ¯ç¶æ¨¡åæç¨æ¼èå¶æåè¨ç·´æä¸åçç¹å¾µçæ°æ¸ææï¼éæ¯è² é·ç§»çå¸åè¡¨ç¾ãçºäºè§£æ±ºéååé¡ï¼æåå¨æ¬æä¸­æåºé¸ææ§å¾®èª¿ãæåçæ¨¡åå©ç¨é è¨ç·´çå¤è§£æåº¦å·ç©ç¥ç¶ç¶²è·¯ (MRCNN) ä¾æåè¦é»åç¹å¾µï¼ææä¸åç¡ç éæ®µçç¨ç¹ç¹å¾µãçºäºæ¸è¼é ååç§»çå½±é¿ï¼æåå¼å¥äºä¸åé åå°é½æ©å¶ï¼å®æ¡ç¨å°çç§»åè·é¢ (EMD) ä¾è©ä¼°åé¸æèç®æ¨é åç·å¯å¹éçæºé åæ¸æãééä½¿ç¨é¸ææ§æºæ¸æå¾®èª¿æ¨¡åï¼æåçé¸ææ§å¾®èª¿å¢å¼·äºæ¨¡åå¨èç¨æ¼è¨ç·´çæ¸æç¸æ¯è¡¨ç¾åºé ååç§»çç®æ¨é åä¸çæ§è½ãå¯¦é©çµæè¡¨æï¼æåçæ¨¡ååªæ¼ç¾æçåºæºï¼å¨æ¸æåä½éå¸¸ä¸å¯é æ¸¬çå¯¦éå ´æ¯ä¸­æä¾äºæ´å¤§çç©©å¥æ§åé©ææ§ã

##### **Self-adaptive vision-language model for 3D segmentation of pulmonary artery and vein**
2501.03722v1 by Xiaotong Guo, Deqian Yang, Dan Wang, Haochen Zhao, Yuan Li, Zhilin Sui, Tao Zhou, Lijun Zhang, Yanda Meng

Accurate segmentation of pulmonary structures iscrucial in clinical
diagnosis, disease study, and treatment planning. Significant progress has been
made in deep learning-based segmentation techniques, but most require much
labeled data for training. Consequently, developing precise segmentation
methods that demand fewer labeled datasets is paramount in medical image
analysis. The emergence of pre-trained vision-language foundation models, such
as CLIP, recently opened the door for universal computer vision tasks.
Exploiting the generalization ability of these pre-trained foundation models on
downstream tasks, such as segmentation, leads to unexpected performance with a
relatively small amount of labeled data. However, exploring these models for
pulmonary artery-vein segmentation is still limited. This paper proposes a
novel framework called Language-guided self-adaptive Cross-Attention Fusion
Framework. Our method adopts pre-trained CLIP as a strong feature extractor for
generating the segmentation of 3D CT scans, while adaptively aggregating the
cross-modality of text and image representations. We propose a s pecially
designed adapter module to fine-tune pre-trained CLIP with a self-adaptive
learning strategy to effectively fuse the two modalities of embeddings. We
extensively validate our method on a local dataset, which is the largest
pulmonary artery-vein CT dataset to date and consists of 718 labeled data in
total. The experiments show that our method outperformed other state-of-the-art
methods by a large margin. Our data and code will be made publicly available
upon acceptance.

æè¦ï¼ç²¾ç¢ºåå²èºé¨çµæ§å¨è¨åºè¨ºæ·ãç¾çç ç©¶åæ²»çè¨ç«ä¸­è³ééè¦ãåºæ¼æ·±åº¦å­¸ç¿çåå²æè¡å·²åå¾éå¤§é²å±ï¼ä½å¤§å¤æ¸æè¡å¨è¨ç·´æéè¦å¤§éçæ¨è¨è³æãå æ­¤ï¼éç¼ç²¾ç¢ºçåå²æ¹æ³ï¼ä»¥æ¸å°æ¨è¨è³æéçéæ±ï¼å¨é«å­¸å½±ååæä¸­è³ééè¦ãé è¨ç·´çè¦è¦ºèªè¨åºç¤æ¨¡åï¼ä¾å¦ CLIPï¼çåºç¾ï¼æè¿çºéç¨é»è¦è¦è¦ºä»»åéåäºå¤§éãå©ç¨éäºé è¨ç·´åºç¤æ¨¡åå¨åå²ç­ä¸æ¸¸ä»»åä¸­çæ³åè½åï¼å³ä½¿æ¨è¨è³æéç¸å°è¼å°ï¼ä¹è½ç¢çææ³ä¸å°çæè½ãç¶èï¼æ¢ç´¢éäºæ¨¡åå¨èºåèéèåå²ä¸­çæç¨ä»ç¶æéãæ¬ææåºäºä¸ååçºèªè¨å¼å°èªé©æäº¤åæ³¨æåèåæ¡æ¶çæ°æ¡æ¶ãæåçæ¨¡åæ¡ç¨é è¨ç·´ç CLIP ä½çºå¼·å¤§çç¹å¾µèåå¨ï¼ç¨æ¼ç¢ç 3D é»è¦æ·å±¤ææçåå²ï¼åæèªé©æå°èåææ¬åå½±åè¡¨å¾µçè·¨æ¨¡æãæåæåºäºä¸åç¹å¥è¨­è¨çé©éå¨æ¨¡çµï¼ä»¥èªé©æå­¸ç¿ç­ç¥å¾®èª¿é è¨ç·´ç CLIPï¼ä»¥ææèåå©ç¨®åµå¥æ¨¡æãæåå¨ä¸åæ¬å°è³æéä¸å»£æ³é©è­äºæåçæ¨¡åï¼éæ¯è¿ä»çºæ­¢æå¤§çèºåèéèé»è¦æ·å±¤ææè³æéï¼ç¸½å±åå« 718 åæ¨è¨è³æãå¯¦é©è¡¨æï¼æåçæ¨¡åä»¥å¤§å¹åªæ¼å¶ä»æåé²æ¨¡åãæåçè³æåç¨å¼ç¢¼å°å¨ç²å¾æ¥åå¾å¬éã

##### **Can Deep Learning Trigger Alerts from Mobile-Captured Images?**
2501.03499v1 by Pritisha Sarkar, Duranta Durbaar Vishal Saha, Mousumi Saha

Our research presents a comprehensive approach to leveraging mobile camera
image data for real-time air quality assessment and recommendation. We develop
a regression-based Convolutional Neural Network model and tailor it explicitly
for air quality prediction by exploiting the inherent relationship between
output parameters. As a result, the Mean Squared Error of 0.0077 and 0.0112
obtained for 2 and 5 pollutants respectively outperforms existing models.
Furthermore, we aim to verify the common practice of augmenting the original
dataset with a view to introducing more variation in the training phase. It is
one of our most significant contributions that our experimental results
demonstrate minimal accuracy differences between the original and augmented
datasets. Finally, a real-time, user-friendly dashboard is implemented which
dynamically displays the Air Quality Index and pollutant values derived from
captured mobile camera images. Users' health conditions are considered to
recommend whether a location is suitable based on current air quality metrics.
Overall, this research contributes to verification of data augmentation
techniques, CNN-based regression modelling for air quality prediction, and
user-centric air quality monitoring through mobile technology. The proposed
system offers practical solutions for individuals to make informed
environmental health and well-being decisions.

æè¦ï¼æåçç ç©¶æåºäºä¸ç¨®å©ç¨è¡åè£ç½®ç¸æ©å½±åè³æé²è¡å³æç©ºæ°£åè³ªè©ä¼°åå»ºè­°çå¨é¢æ§æ¹æ³ãæåéç¼äºä¸ç¨®åºæ¼è¿´æ­¸çå·ç©ç¥ç¶ç¶²è·¯æ¨¡åï¼ä¸¦ééå©ç¨è¼¸åºåæ¸ä¹éçå§å¨éä¿ï¼éå°ç©ºæ°£åè³ªé æ¸¬éèº«æé ãå æ­¤ï¼åå¥éå° 2 å 5 ç¨®æ±¡æç©åå¾çå¹³åå¹³æ¹èª¤å·®çº 0.0077 å 0.0112ï¼åªæ¼ç¾æçæ¨¡åãæ­¤å¤ï¼æåæ¨å¨é©è­æ´ååå§è³æéçå¸¸è¦åæ³ï¼ä»¥æå¨è¨ç·´éæ®µå¼å¥æ´å¤è®ç°ãæåçå¯¦é©çµæé¡¯ç¤ºåå§è³æéåæ´åè³æéä¹éçæºç¢ºåº¦å·®ç°æ¥µå°ï¼éæ¯æåæéè¦çè²¢ç»ä¹ä¸ãæå¾ï¼æåå¯¦ä½äºä¸åå³æãä½¿ç¨èååçåè¡¨æ¿ï¼å¯åæé¡¯ç¤ºå¾æ·åçè¡åè£ç½®ç¸æ©å½±åä¸­è¡ççç©ºæ°£åè³ªææ¸åæ±¡æç©æ¸å¼ãèéä½¿ç¨èçå¥åº·çæ³ï¼å»ºè­°æ¯å¦æ ¹æç®åçç©ºæ°£åè³ªææ¨é¸æé©åçå°é»ãæ´é«èè¨ï¼éé ç ç©¶æå©æ¼é©è­è³ææ´åæè¡ãåºæ¼ CNN çè¿´æ­¸æ¨¡åï¼ç¨æ¼ç©ºæ°£åè³ªé æ¸¬ï¼ä»¥åééè¡åæè¡é²è¡ä»¥ä½¿ç¨èçºä¸­å¿çç©ºæ°£åè³ªç£æ§ãææåºçç³»çµ±çºåäººæä¾å¯¦éçè§£æ±ºæ¹æ¡ï¼ä»¥ä¾¿ååºææºçç°å¢å¥åº·åç¦ç¥æ±ºç­ã

##### **Activating Associative Disease-Aware Vision Token Memory for LLM-Based X-ray Report Generation**
2501.03458v1 by Xiao Wang, Fuling Wang, Haowen Wang, Bo Jiang, Chuanfu Li, Yaowei Wang, Yonghong Tian, Jin Tang

X-ray image based medical report generation achieves significant progress in
recent years with the help of the large language model, however, these models
have not fully exploited the effective information in visual image regions,
resulting in reports that are linguistically sound but insufficient in
describing key diseases. In this paper, we propose a novel associative
memory-enhanced X-ray report generation model that effectively mimics the
process of professional doctors writing medical reports. It considers both the
mining of global and local visual information and associates historical report
information to better complete the writing of the current report. Specifically,
given an X-ray image, we first utilize a classification model along with its
activation maps to accomplish the mining of visual regions highly associated
with diseases and the learning of disease query tokens. Then, we employ a
visual Hopfield network to establish memory associations for disease-related
tokens, and a report Hopfield network to retrieve report memory information.
This process facilitates the generation of high-quality reports based on a
large language model and achieves state-of-the-art performance on multiple
benchmark datasets, including the IU X-ray, MIMIC-CXR, and Chexpert Plus. The
source code of this work is released on
\url{https://github.com/Event-AHU/Medical_Image_Analysis}.

æè¦ï¼è¿å¹´ä¾ï¼å¨å¤§åèªè¨æ¨¡åçå¹«å©ä¸ï¼åºæ¼ X åå½±åçé«çå ±åçæåå¾äºé¡¯èé²å±ï¼ç¶èï¼éäºæ¨¡åä¸¦æªååå©ç¨è¦è¦ºå½±åååä¸­çææè³è¨ï¼å°è´å ±åå¨èªè¨ä¸éç¶æµæ¢ï¼ä½å¨æè¿°ééµç¾çæ¹é¢å»ä¸è¶³ãå¨æ¬æä¸­ï¼æåæåºäºä¸åæ°ç©çè¯æ³å¼è¨æ¶å¢å¼· X åå ±åçææ¨¡åï¼ææå°æ¨¡æ¬å°æ¥­é«çæ°å¯«é«çå ±åçéç¨ãå®åæèæ®äºå°å¨å±åå±é¨è¦è¦ºè³è¨çææï¼ä¸¦è¯ç¹«æ­·å²å ±åè³è¨ï¼ä»¥æ´å¥½å°å®æç¶åå ±åçæ°å¯«ãå·é«ä¾èªªï¼çµ¦å®ä¸å¼µ X åå½±åï¼æåé¦åå©ç¨åé¡æ¨¡ååå¶æ¿æ´»æ å°ä¾å®æèç¾çé«åº¦ç¸éçè¦è¦ºååçææåç¾çæ¥è©¢ä»¤ççå­¸ç¿ãç¶å¾ï¼æåæ¡ç¨è¦è¦ºéæ®è²ç¾å¾·ç¶²è·¯ä¾å»ºç«èç¾çç¸éçä»¤ççè¨æ¶è¯ç¹«ï¼ä¸¦æ¡ç¨å ±åéæ®è²ç¾å¾·ç¶²è·¯ä¾æª¢ç´¢å ±åè¨æ¶è³è¨ãéåéç¨æå©æ¼åºæ¼å¤§åèªè¨æ¨¡åçæé«åè³ªçå ±åï¼ä¸¦å¨åæ¬ IU X å°ç·ãMIMIC-CXR å Chexpert Plus å¨å§çå¤ååºæºè³æéä¸å¯¦ç¾äºæåé²çæè½ãæ­¤é å·¥ä½çåå§ç¢¼å·²ç¼ä½å¨\url{https://github.com/Event-AHU/Medical_Image_Analysis}ã

##### **Existential Crisis: A Social Robot's Reason for Being**
2501.03376v1 by Dora Medgyesy, Joella Galas, Julian van Pol, Rustam Eynaliyev, Thijs Vollebregt

As Robots become ever more important in our daily lives there's growing need
for understanding how they're perceived by people. This study aims to
investigate how the user perception of robots is influenced by displays of
personality. Using LLMs and speech to text technology, we designed a
within-subject study to compare two conditions: a personality-driven robot and
a purely task-oriented, personality-neutral robot. Twelve participants,
recruited from Socially Intelligent Robotics course at Vrije Universiteit
Amsterdam, interacted with a robot Nao tasked with asking them a set of medical
questions under both conditions. After completing both interactions, the
participants completed a user experience questionnaire measuring their
emotional states and robot perception using standardized questionnaires from
the SRI and Psychology literature.

æè¦ï¼é¨èæ©å¨äººå¨æåæ¥å¸¸çæ´»ä¸­çéè¦æ§æ¥çæåï¼å°æ¼äºè§£äººåå¦ä½æç¥æ©å¨äººçéæ±ä¹æ¥çå¢å ãæ¬ç ç©¶æ¨å¨æ¢è¨æ©å¨äººçä½¿ç¨èæç¥å¦ä½åå°äººæ ¼è¡¨ç¾çå½±é¿ãæåä½¿ç¨å¤§åèªè¨æ¨¡å (LLM) åèªé³è½æå­æè¡ï¼è¨­è¨äºä¸é åè©¦èå§ç ç©¶ï¼ä»¥æ¯è¼å©ç¨®ææ³ï¼ä¸ç¨®æ¯äººæ ¼é©åçæ©å¨äººï¼å¦ä¸ç¨®æ¯ç´ç²¹ä»¥ä»»åçºå°åãäººæ ¼ä¸­ç«çæ©å¨äººãæåå¾é¿å§æ¯ç¹ä¸¹èªç±å¤§å­¸çç¤¾äº¤æºè½æ©å¨äººèª²ç¨ä¸­æåäº 12 ååèèï¼ä»åèæ©å¨äºº Nao äºåï¼å¨å©ç¨®ææ³ä¸é½åä»åè©¢åä¸ç³»åé«çåé¡ãå¨å®æéå©ç¨®äºåå¾ï¼åèèå®æäºä¸ä»½ä½¿ç¨èé«é©åå·ï¼ä½¿ç¨ä¾èª SRI åå¿çå­¸æç»çæ¨æºååå·æ¸¬éä»åçæç·çæåæ©å¨äººæç¥ã

##### **Label-free Concept Based Multiple Instance Learning for Gigapixel Histopathology**
2501.02922v1 by Susu Sun, Leslie Tessier, FrÃ©dÃ©rique Meeuwsen, ClÃ©ment Grisi, Dominique van Midden, Geert Litjens, Christian F. Baumgartner

Multiple Instance Learning (MIL) methods allow for gigapixel Whole-Slide
Image (WSI) analysis with only slide-level annotations. Interpretability is
crucial for safely deploying such algorithms in high-stakes medical domains.
Traditional MIL methods offer explanations by highlighting salient regions.
However, such spatial heatmaps provide limited insights for end users. To
address this, we propose a novel inherently interpretable WSI-classification
approach that uses human-understandable pathology concepts to generate
explanations. Our proposed Concept MIL model leverages recent advances in
vision-language models to directly predict pathology concepts based on image
features. The model's predictions are obtained through a linear combination of
the concepts identified on the top-K patches of a WSI, enabling inherent
explanations by tracing each concept's influence on the prediction. In contrast
to traditional concept-based interpretable models, our approach eliminates the
need for costly human annotations by leveraging the vision-language model. We
validate our method on two widely used pathology datasets: Camelyon16 and
PANDA. On both datasets, Concept MIL achieves AUC and accuracy scores over 0.9,
putting it on par with state-of-the-art models. We further find that 87.1\%
(Camelyon16) and 85.3\% (PANDA) of the top 20 patches fall within the tumor
region. A user study shows that the concepts identified by our model align with
the concepts used by pathologists, making it a promising strategy for
human-interpretable WSI classification.

æè¦ï¼å¤å¯¦ä¾å­¸ç¿ (MIL) æ¹æ³åä½¿ç¨ç»çå±¤ç´è¨»è§£ï¼å³å¯é²è¡ååç´ å¨ç»çå½±å (WSI) åæãå¯è§£éæ§å°æ¼å¨é«é¢¨éªé«çé åå®å¨é¨ç½²æ­¤é¡æ¼ç®æ³è³ééè¦ãå³çµ±ç MIL æ¹æ³ééå¼·èª¿é¡¯èååä¾æä¾èªªæãç¶èï¼æ­¤é¡ç©ºéç±åçºæçµä½¿ç¨èæä¾çè¦è§£æéãçºäºè§£æ±ºæ­¤åé¡ï¼æåæåºäºä¸ç¨®æ°ç©ä¸æ¬è³ªä¸å¯è§£éç WSI åé¡æ¹æ³ï¼è©²æ¹æ³ä½¿ç¨äººé¡å¯çè§£çççæ¦å¿µä¾ç¢çèªªæãæåæåºçæ¦å¿µ MIL æ¨¡åå©ç¨è¦è¦ºèªè¨æ¨¡åçææ°é²å±ï¼æ ¹æå½±åç¹å¾µç´æ¥é æ¸¬ççæ¦å¿µãè©²æ¨¡åçé æ¸¬æ¯ééç·æ§çµå WSI é é¨ K ååå¡ä¸è­å¥çæ¦å¿µèç²å¾çï¼ééè¿½è¹¤æ¯åæ¦å¿µå°é æ¸¬çå½±é¿ï¼å¯ä»¥æä¾å§å¨èªªæãèå³çµ±åºæ¼æ¦å¿µçå¯è§£éæ¨¡åç¸æ¯ï¼æåçåæ³ééå©ç¨è¦è¦ºèªè¨æ¨¡åï¼æ¶é¤äºå°æè²´çäººå·¥è¨»è§£çéæ±ãæåå¨å©åå»£æ³ä½¿ç¨çççè³æéï¼Camelyon16 å PANDA ä¸é©è­äºæåçæ¨¡åãå¨å©åè³æéä¸ï¼æ¦å¿µ MIL ç AUC åæºç¢ºçé½è¶é 0.9ï¼èæåé²çæ¨¡åä¸ç¸ä¸ä¸ãæåé²ä¸æ­¥ç¼ç¾ï¼å 20 ååå¡ä¸­æ 87.1%ï¼Camelyon16ï¼å 85.3%ï¼PANDAï¼è½å¨è«ç¤ååå§ãä¸é ä½¿ç¨èç ç©¶è¡¨æï¼æåçæ¨¡åè­å¥çæ¦å¿µèççå­¸å®¶ä½¿ç¨çæ¦å¿µä¸è´ï¼ä½¿å¶æçºäººé¡å¯è§£é WSI åé¡çä¸ç¨®æåéçç­ç¥ã

##### **Explaining Humour Style Classifications: An XAI Approach to Understanding Computational Humour Analysis**
2501.02891v1 by Mary Ogbuka Kenneth, Foaad Khosmood, Abbas Edalat

Humour styles can have either a negative or a positive impact on well-being.
Given the importance of these styles to mental health, significant research has
been conducted on their automatic identification. However, the automated
machine learning models used for this purpose are black boxes, making their
prediction decisions opaque. Clarity and transparency are vital in the field of
mental health. This paper presents an explainable AI (XAI) framework for
understanding humour style classification, building upon previous work in
computational humour analysis. Using the best-performing single model
(ALI+XGBoost) from prior research, we apply comprehensive XAI techniques to
analyse how linguistic, emotional, and semantic features contribute to humour
style classification decisions. Our analysis reveals distinct patterns in how
different humour styles are characterised and misclassified, with particular
emphasis on the challenges in distinguishing affiliative humour from other
styles. Through detailed examination of feature importance, error patterns, and
misclassification cases, we identify key factors influencing model decisions,
including emotional ambiguity, context misinterpretation, and target
identification. The framework demonstrates significant utility in understanding
model behaviour, achieving interpretable insights into the complex interplay of
features that define different humour styles. Our findings contribute to both
the theoretical understanding of computational humour analysis and practical
applications in mental health, content moderation, and digital humanities
research.

æè¦ï¼å¹½é»é¢¨æ ¼å°å¹¸ç¦æå¯è½ç¢çè² é¢ææ­£é¢çå½±é¿ã
éæ¼éäºé¢¨æ ¼å°å¿çå¥åº·çéè¦æ§ï¼å·²ç¶å°å¶èªåè­å¥é²è¡äºå¤§éç ç©¶ãç¶èï¼ç¨æ¼æ­¤ç®ççèªåæ©å¨å­¸ç¿æ¨¡åæ¯é»çå­ï¼ä½¿å¾å¶é æ¸¬æ±ºç­ä¸éæãæ¸æ°åº¦åéæåº¦å¨å¿çå¥åº·é åè³ééè¦ãæ¬ææåºäºä¸åå¯è§£éç AI (XAI) æ¡æ¶ï¼ç¨æ¼çè§£å¹½é»é¢¨æ ¼åé¡ï¼å»ºç«å¨è¨ç®å¹½é»åæçååå·¥ä½ä¹ä¸ãä½¿ç¨ååç ç©¶ä¸­è¡¨ç¾æå¥½çå®ä¸æ¨¡å (ALI+XGBoost)ï¼æåæç¨å¨é¢ç XAI æè¡ä¾åæèªè¨ãæç·åèªç¾©ç¹å¾µå¦ä½å½±é¿å¹½é»é¢¨æ ¼åé¡æ±ºç­ãæåçåææ­ç¤ºäºä¸åå¹½é»é¢¨æ ¼å¦ä½è¢«è¡¨å¾µåé¯èª¤åé¡çä¸åæ¨¡å¼ï¼ç¹å¥å¼·èª¿äºååè¯å±¬å¹½é»èå¶ä»é¢¨æ ¼çææ°ãééä»ç´°æª¢æ¥ç¹å¾µéè¦æ§ãé¯èª¤æ¨¡å¼åé¯èª¤åé¡æ¡ä¾ï¼æåç¢ºå®äºå½±é¿æ¨¡åæ±ºç­çééµå ç´ ï¼åæ¬æç·æ¨¡ç³ãæå¢èª¤è§£åç®æ¨è­å¥ãè©²æ¡æ¶å±ç¤ºäºå¨çè§£æ¨¡åè¡çºæ¹é¢çé¡¯èæç¨ï¼å¯¦ç¾äºå°å®ç¾©ä¸åå¹½é»é¢¨æ ¼çç¹å¾µä¹éè¤éç¸äºä½ç¨çå¯è§£éè¦è§£ãæåçç¼ç¾æå©æ¼è¨ç®å¹½é»åæççè«çè§£åå¿çå¥åº·ãå§å®¹å¯©æ ¸åæ¸å­äººæç ç©¶ä¸­çå¯¦éæç¨ã

##### **IIMedGPT: Promoting Large Language Model Capabilities of Medical Tasks by Efficient Human Preference Alignment**
2501.02869v1 by Yiming Zhang, Zheng Chang, Wentao Cai, MengXing Ren, Kang Yuan, Yining Sun, Zenghui Ding

Recent researches of large language models(LLM), which is pre-trained on
massive general-purpose corpora, have achieved breakthroughs in responding
human queries. However, these methods face challenges including limited data
insufficiency to support extensive pre-training and can not align responses
with users' instructions. To address these issues, we introduce a medical
instruction dataset, CMedINS, containing six medical instructions derived from
actual medical tasks, which effectively fine-tunes LLM in conjunction with
other data. Subsequently, We launch our medical model, IIMedGPT, employing an
efficient preference alignment method, Direct preference Optimization(DPO). The
results show that our final model outperforms existing medical models in
medical dialogue.Datsets, Code and model checkpoints will be released upon
acceptance.

æè¦ï¼æè¿éå°å¤§åèªè¨æ¨¡å (LLM) çç ç©¶ï¼è©²æ¨¡åé åè¨ç·´æ¼é¾å¤§çéç¨èªæåº«ä¸­ï¼å·²å¨åæäººé¡æ¥è©¢æ¹é¢åå¾çªç ´ãç¶èï¼éäºæ¹æ³é¢è¨çææ°åæ¬è³æä¸è¶³ä»¥æ¯æ´å»£æ³çé è¨ç·´ï¼ä¸ç¡æ³å°åæèä½¿ç¨èçæç¤ºä¿æä¸è´ãçºäºè§£æ±ºéäºåé¡ï¼æåå¼é²ä¸åé«çæç¤ºè³æé CMedINSï¼å¶ä¸­åå«å­é å¾å¯¦éé«çä»»åä¸­è¡ççé«çæç¤ºï¼èå¶ä»è³æçµåå¾è½ææå¾®èª¿ LLMãé¨å¾ï¼æåæ¨åºæåçé«çæ¨¡å IIMedGPTï¼æ¡ç¨ä¸ç¨®ææççåå¥½å°é½æ¹æ³ï¼ç´æ¥åå¥½æä½³å (DPO)ãçµæé¡¯ç¤ºï¼æåçæçµæ¨¡åå¨é«çå°è©±ä¸­åªæ¼ç¾æçé«çæ¨¡åãè³æéãç¨å¼ç¢¼åæ¨¡åæª¢æ¥é»å°å¨ééé©è­å¾éåºã

##### **Multi-Modal One-Shot Federated Ensemble Learning for Medical Data with Vision Large Language Model**
2501.03292v1 by Naibo Wang, Yuchen Deng, Shichen Fan, Jianwei Yin, See-Kiong Ng

Federated learning (FL) has attracted considerable interest in the medical
domain due to its capacity to facilitate collaborative model training while
maintaining data privacy. However, conventional FL methods typically
necessitate multiple communication rounds, leading to significant communication
overhead and delays, especially in environments with limited bandwidth.
One-shot federated learning addresses these issues by conducting model training
and aggregation in a single communication round, thereby reducing communication
costs while preserving privacy. Among these, one-shot federated ensemble
learning combines independently trained client models using ensemble techniques
such as voting, further boosting performance in non-IID data scenarios. On the
other hand, existing machine learning methods in healthcare predominantly use
unimodal data (e.g., medical images or textual reports), which restricts their
diagnostic accuracy and comprehensiveness. Therefore, the integration of
multi-modal data is proposed to address these shortcomings. In this paper, we
introduce FedMME, an innovative one-shot multi-modal federated ensemble
learning framework that utilizes multi-modal data for medical image analysis.
Specifically, FedMME capitalizes on vision large language models to produce
textual reports from medical images, employs a BERT model to extract textual
features from these reports, and amalgamates these features with visual
features to improve diagnostic accuracy. Experimental results show that our
method demonstrated superior performance compared to existing one-shot
federated learning methods in healthcare scenarios across four datasets with
various data distributions. For instance, it surpasses existing one-shot
federated learning approaches by more than 17.5% in accuracy on the RSNA
dataset when applying a Dirichlet distribution with ($\alpha$ = 0.3).

æè¦ï¼èé¦å­¦ä¹  (FL) ç±äºå¶å¨ç»´æ¤æ°æ®éç§çåæ¶ä¿è¿åä½æ¨¡åè®­ç»çè½åï¼å¨å»å­¦é¢åå¼èµ·äºæå¤§çå´è¶£ãç¶èï¼ä¼ ç»ç FL æ¹æ³éå¸¸éè¦å¤è½®éä¿¡ï¼è¿ä¼å¯¼è´ä¸¥éçéä¿¡å¼éåå»¶è¿ï¼å°¤å¶æ¯å¨å¸¦å®½åéçç¯å¢ä¸­ãåæ¬¡èé¦å­¦ä¹ éè¿å¨åæ¬¡éä¿¡è½®ä¸­è¿è¡æ¨¡åè®­ç»åèåæ¥è§£å³è¿äºé®é¢ï¼ä»èå¨ä¿æ¤éç§çåæ¶éä½éä¿¡ææ¬ãå¶ä¸­ï¼åæ¬¡èé¦éæå­¦ä¹ ä½¿ç¨éæææ¯ï¼å¦æç¥¨ï¼å°ç¬ç«è®­ç»çå®¢æ·ç«¯æ¨¡åç»åèµ·æ¥ï¼è¿ä¸æ­¥æåäºå¨é IID æ°æ®åºæ¯ä¸­çæ§è½ãå¦ä¸æ¹é¢ï¼ç°æçå»çä¿å¥æºå¨å­¦ä¹ æ¹æ³ä¸»è¦ä½¿ç¨åæ¨¡ææ°æ®ï¼ä¾å¦å»å­¦å¾åæææ¬æ¥åï¼ï¼è¿éå¶äºå®ä»¬çè¯æ­åç¡®æ§åå¨é¢æ§ãå æ­¤ï¼æåºäºå¤æ¨¡ææ°æ®çéææ¥è§£å³è¿äºç¼ºç¹ãå¨æ¬æä¸­ï¼æä»¬ä»ç»äº FedMMEï¼ä¸ç§åæ°çåæ¬¡å¤æ¨¡æèé¦éæå­¦ä¹ æ¡æ¶ï¼å®å©ç¨å¤æ¨¡ææ°æ®è¿è¡å»å­¦å¾ååæãå·ä½æ¥è¯´ï¼FedMME å©ç¨è§è§å¤§è¯­è¨æ¨¡åä»å»å­¦å¾åä¸­çæææ¬æ¥åï¼éç¨ BERT æ¨¡åä»è¿äºæ¥åä¸­æåææ¬ç¹å¾ï¼å¹¶å°è¿äºç¹å¾ä¸è§è§ç¹å¾ç¸ç»åä»¥æé«è¯æ­åç¡®æ§ãå®éªç»æè¡¨æï¼ä¸ç°æçåæ¬¡èé¦å­¦ä¹ æ¹æ³ç¸æ¯ï¼æä»¬çæ¹æ³å¨åä¸ªå·æä¸åæ°æ®åå¸çæ°æ®éä¸­çå»çä¿å¥åºæ¯ä¸­è¡¨ç°åºä¼è¶çæ§è½ãä¾å¦ï¼å½åºç¨å·æ ($\alpha$ = 0.3) ç Dirichlet åå¸æ¶ï¼å®å¨ RSNA æ°æ®éä¸çåç¡®çæ¯ç°æçåæ¬¡èé¦å­¦ä¹ æ¹æ³é«åº 17.5% ä»¥ä¸ã

##### **GLoG-CSUnet: Enhancing Vision Transformers with Adaptable Radiomic Features for Medical Image Segmentation**
2501.02788v2 by Niloufar Eghbali, Hassan Bagher-Ebadian, Tuka Alhanai, Mohammad M. Ghassemi

Vision Transformers (ViTs) have shown promise in medical image semantic
segmentation (MISS) by capturing long-range correlations. However, ViTs often
struggle to model local spatial information effectively, which is essential for
accurately segmenting fine anatomical details, particularly when applied to
small datasets without extensive pre-training. We introduce Gabor and Laplacian
of Gaussian Convolutional Swin Network (GLoG-CSUnet), a novel architecture
enhancing Transformer-based models by incorporating learnable radiomic
features. This approach integrates dynamically adaptive Gabor and Laplacian of
Gaussian (LoG) filters to capture texture, edge, and boundary information,
enhancing the feature representation processed by the Transformer model. Our
method uniquely combines the long-range dependency modeling of Transformers
with the texture analysis capabilities of Gabor and LoG features. Evaluated on
the Synapse multi-organ and ACDC cardiac segmentation datasets, GLoG-CSUnet
demonstrates significant improvements over state-of-the-art models, achieving a
1.14% increase in Dice score for Synapse and 0.99% for ACDC, with minimal
computational overhead (only 15 and 30 additional parameters, respectively).
GLoG-CSUnet's flexible design allows integration with various base models,
offering a promising approach for incorporating radiomics-inspired feature
extraction in Transformer architectures for medical image analysis. The code
implementation is available on GitHub at: https://github.com/HAAIL/GLoG-CSUnet.

æè¦ï¼<paragraph>è¦è¦ºè½æå¨ (ViT) å·²å¨é«çå½±åèªæåå² (MISS) ä¸­å±ç¾åæ¯ï¼èç±æ·åé·ç¨éè¯æ§ãç¶èï¼ViT ç¶å¸¸é£ä»¥ææå°å»ºæ¨¡å±é¨ç©ºéè³è¨ï¼éå°æ¼ç²¾ç¢ºåå²ç²¾ç´°è§£åç´°ç¯è³ééè¦ï¼ç¹å¥æ¯å¨æç¨æ¼æ²æå»£æ³é åè¨ç·´çå°åè³æéæãæåå¼å¥äºé«æ¯å·ç© Swin ç¶²è·¯ (GLoG-CSUnet) ç Gabor å Laplacianï¼éæ¯ä¸ç¨®æ°ç©çæ¶æ§ï¼ééæ´åå¯å­¸ç¿çæ¾å°ç¹å¾µä¾å¢å¼·åºæ¼è½æå¨çæ¨¡åãæ­¤æ¹æ³æ´åäºåæèªé©æ Gabor åé«æ¯ Laplacian (LoG) æ¿¾æ³¢å¨ä¾æ·åç´çãéç·£åéçè³è¨ï¼å¢å¼·è½æå¨æ¨¡åèççç¹å¾µè¡¨ç¤ºãæåçæ¨¡åç¨ç¹å°çµåäºè½æå¨çé·ç¨ä¾è³´æ§å»ºæ¨¡è Gabor å LoG ç¹å¾µçç´çåæåè½ãå¨ Synapse å¤å¨å®å ACDC å¿èåå²è³æéä¸é²è¡è©ä¼°ï¼GLoG-CSUnet å±ç¤ºåºæ¯æåé²çæ¨¡åæé¡¯èçæ¹é²ï¼Synapse ç Dice åæ¸å¢å äº 1.14%ï¼ACDC ç Dice åæ¸å¢å äº 0.99%ï¼è¨ç®è² ææ¥µå°ï¼åå¥åªæ 15 å 30 åé¡å¤çåæ¸ï¼ãGLoG-CSUnet çå½æ§è¨­è¨åè¨±èåç¨®åºç¤æ¨¡åæ´åï¼çºå¨è½æå¨æ¶æ§ä¸­æ´åæ¾å°çµå­¸åç¼çç¹å¾µèåæä¾äºä¸åæåæ¯çæ¹æ³ï¼ä»¥é²è¡é«çå½±ååæãç¨å¼ç¢¼å¯¦ä½å¯å¨ GitHub ä¸åå¾ï¼https://github.com/HAAIL/GLoG-CSUnetã</paragraph>

##### **Hybrid deep convolution model for lung cancer detection with transfer learning**
2501.02785v1 by Sugandha Saxena, S. N. Prasad, Ashwin M Polnaya, Shweta Agarwala

Advances in healthcare research have significantly enhanced our understanding
of disease mechanisms, diagnostic precision, and therapeutic options. Yet, lung
cancer remains one of the leading causes of cancer-related mortality worldwide
due to challenges in early and accurate diagnosis. While current lung cancer
detection models show promise, there is considerable potential for further
improving the accuracy for timely intervention. To address this challenge, we
introduce a hybrid deep convolution model leveraging transfer learning, named
the Maximum Sensitivity Neural Network (MSNN). MSNN is designed to improve the
precision of lung cancer detection by refining sensitivity and specificity.
This model has surpassed existing deep learning approaches through experimental
validation, achieving an accuracy of 98% and a sensitivity of 97%. By
overlaying sensitivity maps onto lung Computed Tomography (CT) scans, it
enables the visualization of regions most indicative of malignant or benign
classifications. This innovative method demonstrates exceptional performance in
distinguishing lung cancer with minimal false positives, thereby enhancing the
accuracy of medical diagnoses.

æè¦ï¼é«çä¿å¥ç ç©¶çé²æ­¥é¡¯èå¢é²äºæåå°ç¾çæ©å¶ãè¨ºæ·ç²¾æºåº¦åæ²»çé¸æçäºè§£ãç¶èï¼ç±æ¼æ©æåæºç¢ºè¨ºæ·çææ°ï¼èºçä»ç¶æ¯å¨çççç¸éæ­»äº¡çä¸»è¦åå ä¹ä¸ãéç¶ç®åçèºçæª¢æ¸¬æ¨¡åé¡¯ç¤ºåºåæ¯ï¼ä½ä»æç¸ç¶å¤§çæ½åå¯ä»¥é²ä¸æ­¥æé«æºç¢ºæ§ï¼ä»¥ä¾¿åæä»å¥ãçºäºæå°éä¸ææ°ï¼æåå¼å¥äºå©ç¨é·ç§»å­¸ç¿çæ··åæ·±åº¦å·ç©æ¨¡åï¼åçºæå¤§ææåº¦ç¥ç¶ç¶²è·¯ (MSNN)ãMSNN æ¨å¨ééèª¿æ´ææåº¦åç¹ç°æ§ä¾æé«èºçæª¢æ¸¬çæºç¢ºæ§ãæ­¤æ¨¡åå·²ééå¯¦é©é©è­è¶è¶ç¾æçæ·±åº¦å­¸ç¿æ¹æ³ï¼éå° 98% çæºç¢ºåº¦å 97% çææåº¦ãééå°ææåº¦åçå å°èºé¨é»è¦æ·å±¤ææ (CT) ä¸ï¼å®å¯ä»¥è¦è¦ºååºæè½ä»£è¡¨æ¡æ§æè¯æ§åé¡çååãéç¨®åµæ°æ¹æ³å¨ååèºçæè¡¨ç¾åºæ¥µä½³çæè½ï¼ä¸èª¤å¤çºé½æ§çææ³æå°ï¼å¾èæé«äºé«çè¨ºæ·çæºç¢ºæ§ã

##### **ICFNet: Integrated Cross-modal Fusion Network for Survival Prediction**
2501.02778v1 by Binyu Zhang, Zhu Meng, Junhao Dong, Fei Su, Zhicheng Zhao

Survival prediction is a crucial task in the medical field and is essential
for optimizing treatment options and resource allocation. However, current
methods often rely on limited data modalities, resulting in suboptimal
performance. In this paper, we propose an Integrated Cross-modal Fusion Network
(ICFNet) that integrates histopathology whole slide images, genomic expression
profiles, patient demographics, and treatment protocols. Specifically, three
types of encoders, a residual orthogonal decomposition module and a unification
fusion module are employed to merge multi-modal features to enhance prediction
accuracy. Additionally, a balanced negative log-likelihood loss function is
designed to ensure fair training across different patients. Extensive
experiments demonstrate that our ICFNet outperforms state-of-the-art algorithms
on five public TCGA datasets, including BLCA, BRCA, GBMLGG, LUAD, and UCEC, and
shows its potential to support clinical decision-making and advance precision
medicine. The codes are available at: https://github.com/binging512/ICFNet.

æè¦ï¼å­æ´»é æ¸¬æ¯é«å­¸é åçä¸é ééµä»»åï¼å°æ¼åªåæ²»çé¸é åè³æºåéè³ééè¦ãç¶èï¼ç®åçæè¡éå¸¸ä»°è³´æéçæ¸æå½¢å¼ï¼å°è´æ¬¡ä½³çè¡¨ç¾ãå¨æ¬æä¸­ï¼æåæåºä¸åæ´åå¼è·¨å½¢å¼èåç¶²è·¯ (ICFNet)ï¼å®æ´åäºçµç¹ççå­¸å¨å¹»ççå½±åãåºå é«è¡¨ç¾ç¹å¾µãçæ£äººå£çµ±è¨è³æåæ²»çåå®ãå·é«ä¾èªªï¼ä½¿ç¨ä¸ç¨®é¡åçç·¨ç¢¼å¨ãä¸åæ®å·®æ­£äº¤åè§£æ¨¡çµåä¸åçµ±ä¸èåæ¨¡çµï¼ä»¥åä½µå¤å½¢å¼ç¹å¾µï¼ä»¥å¢å¼·é æ¸¬æºç¢ºåº¦ãæ­¤å¤ï¼è¨­è¨äºä¸åå¹³è¡¡çè² å°æ¸ä¼¼ç¶æå¤±å½æ¸ï¼ä»¥ç¢ºä¿ä¸åçæ£ä¹éçå¬å¹³è¨ç·´ãå»£æ³çå¯¦é©è­æï¼æåç ICFNet å¨äºåå¬éç TCGA è³æéä¸åªæ¼æåé²çæ¼ç®æ³ï¼åæ¬ BLCAãBRCAãGBMLGGãLUAD å UCECï¼ä¸¦å±ç¤ºå¶æ¯æ´è¨åºæ±ºç­åæ¨åç²¾æºé«ççæ½åãç¨å¼ç¢¼å¯å¨ä»¥ä¸ç¶²ååå¾ï¼https://github.com/binging512/ICFNetã

##### **Tree-based RAG-Agent Recommendation System: A Case Study in Medical Test Data**
2501.02727v1 by Yahe Yang, Chengyue Huang

We present HiRMed (Hierarchical RAG-enhanced Medical Test Recommendation), a
novel tree-structured recommendation system that leverages Retrieval-Augmented
Generation (RAG) for intelligent medical test recommendations. Unlike
traditional vector similarity-based approaches, our system performs medical
reasoning at each tree node through a specialized RAG process. Starting from
the root node with initial symptoms, the system conducts step-wise medical
analysis to identify potential underlying conditions and their corresponding
diagnostic requirements. At each level, instead of simple matching, our
RAG-enhanced nodes analyze retrieved medical knowledge to understand
symptom-disease relationships and determine the most appropriate diagnostic
path. The system dynamically adjusts its recommendation strategy based on
medical reasoning results, considering factors such as urgency levels and
diagnostic uncertainty. Experimental results demonstrate that our approach
achieves superior performance in terms of coverage rate, accuracy, and miss
rate compared to conventional retrieval-based methods. This work represents a
significant advance in medical test recommendation by introducing medical
reasoning capabilities into the traditional tree-based retrieval structure.

æè¦ï¼æåæåº HiRMedï¼åå±¤ RAG å¢å¼·åé«çæª¢æ¸¬å»ºè­°ï¼ï¼ä¸ç¨®æ°ç©çæ¨¹ççµæ§å»ºè­°ç³»çµ±ï¼å®å©ç¨æª¢ç´¢å¢å¼·çæ (RAG) ä¾é²è¡æºè½é«çæª¢æ¸¬å»ºè­°ãèå³çµ±çåºæ¼åéç¸ä¼¼æ§çæ¹æ³ä¸åï¼æåçç³»çµ±ééä¸åå°éç RAG ç¨åºå¨æ¯åæ¨¹ç¯é»å·è¡é«çæ¨çãå¾å·æåå§çççæ ¹ç¯é»éå§ï¼ç³»çµ±å·è¡éæ­¥é«çåæä»¥è­å¥æ½å¨çæ½å¨ç¾çåå¶å°æçè¨ºæ·è¦æ±ãå¨æ¯åå±¤ç´ï¼æåç RAG å¢å¼·ç¯é»æåææª¢ç´¢å°çé«çç¥è­ï¼ä»¥äºè§£ççèç¾ççéä¿ï¼ä¸¦ç¢ºå®æåé©çè¨ºæ·è·¯å¾ï¼èä¸æ¯é²è¡ç°¡å®çå¹éãç³»çµ±æ ¹æé«çæ¨ççµæåæèª¿æ´å¶å»ºè­°ç­ç¥ï¼èæ®ç·æ¥ç¨åº¦åè¨ºæ·ä¸ç¢ºå®æ§ç­å ç´ ãå¯¦é©çµæè¡¨æï¼èå³çµ±çåºæ¼æª¢ç´¢çæ¹æ³ç¸æ¯ï¼æåçåæ³å¨è¦èçãæºç¢ºæ§åéºæ¼çæ¹é¢åå¾äºåªç°çè¡¨ç¾ãéé å·¥ä½ééå°é«çæ¨çè½åå¼å¥å³çµ±çåºæ¼æ¨¹çæª¢ç´¢çµæ§ï¼ä»£è¡¨äºé«çæª¢æ¸¬å»ºè­°çéå¤§é²å±ã

##### **Representation Learning of Lab Values via Masked AutoEncoder**
2501.02648v2 by David Restrepo, Chenwei Wu, Yueran Jia, Jaden K. Sun, Jack Gallifant, Catherine G. Bielick, Yugang Jia, Leo A. Celi

Accurate imputation of missing laboratory values in electronic health records
(EHRs) is critical to enable robust clinical predictions and reduce biases in
AI systems in healthcare. Existing methods, such as variational autoencoders
(VAEs) and decision tree-based approaches such as XGBoost, struggle to model
the complex temporal and contextual dependencies in EHR data, mainly in
underrepresented groups. In this work, we propose Lab-MAE, a novel
transformer-based masked autoencoder framework that leverages self-supervised
learning for the imputation of continuous sequential lab values. Lab-MAE
introduces a structured encoding scheme that jointly models laboratory test
values and their corresponding timestamps, enabling explicit capturing temporal
dependencies. Empirical evaluation on the MIMIC-IV dataset demonstrates that
Lab-MAE significantly outperforms the state-of-the-art baselines such as
XGBoost across multiple metrics, including root mean square error (RMSE),
R-squared (R2), and Wasserstein distance (WD). Notably, Lab-MAE achieves
equitable performance across demographic groups of patients, advancing fairness
in clinical predictions. We further investigate the role of follow-up
laboratory values as potential shortcut features, revealing Lab-MAE's
robustness in scenarios where such data is unavailable. The findings suggest
that our transformer-based architecture, adapted to the characteristics of the
EHR data, offers a foundation model for more accurate and fair clinical
imputation models. In addition, we measure and compare the carbon footprint of
Lab-MAE with the baseline XGBoost model, highlighting its environmental
requirements.

æè¦ï¼<paragraph>æºç¢ºä¼°ç®é»å­å¥åº·è¨é (EHR) ä¸­éºå¤±çå¯¦é©å®¤å¼å°æ¼åç¨ç©©å¥çè¨åºé æ¸¬åæ¸å°é«çä¿å¥ä¸­ AI ç³»çµ±çåå·®è³ééè¦ãç¾ææ¹æ³ï¼ä¾å¦è®ç°èªåç·¨ç¢¼å¨ (VAE) ååºæ¼æ±ºç­æ¨¹çæ¹æ³ï¼ä¾å¦ XGBoostï¼é£ä»¥å»ºæ¨¡ EHR è³æä¸­è¤éçæéåä¸ä¸æä¾è³´æ§ï¼ç¹å¥æ¯å¨ä»£è¡¨æ§ä¸è¶³çç¾¤çµä¸­ãå¨éé å·¥ä½ä¸­ï¼æåæåº Lab-MAEï¼ä¸åæ°ç©çåºæ¼ Transformer çé®ç½©èªåç·¨ç¢¼å¨æ¡æ¶ï¼å®å©ç¨èªæç£ç£å­¸ç¿ä¾ä¼°ç®é£çºé åºå¯¦é©å®¤å¼ãLab-MAE å¼å¥äºä¸åçµæ§åç·¨ç¢¼æ¹æ¡ï¼å®è¯åå»ºæ¨¡å¯¦é©å®¤æ¸¬è©¦å¼åå¶å°æçæéæ³ï¼å¾èè½å¤ æç¢ºæææéä¾è³´æ§ãå¨ MIMIC-IV è³æéä¸çç¶é©è©ä¼°è¡¨æï¼Lab-MAE å¨åæ¬åæ¹æ ¹èª¤å·® (RMSE)ãR å¹³æ¹ (R2) å Wasserstein è·é¢ (WD) å¨å§çå¤é ææ¨ä¸é¡¯èåªæ¼ XGBoost ç­æåé²çåºæºãå¼å¾æ³¨æçæ¯ï¼Lab-MAE å¨æ£èçäººå£çµ±è¨ç¾¤çµä¸­åå¾äºå¬å¹³çè¡¨ç¾ï¼å¾èæåäºè¨åºé æ¸¬ä¸­çå¬å¹³æ§ãæåé²ä¸æ­¥ç ç©¶äºå¾çºå¯¦é©å®¤å¼ä½çºæ½å¨æ·å¾ç¹å¾µçä½ç¨ï¼æ­ç¤ºäº Lab-MAE å¨æ­¤é¡è³æä¸å¯ç¨çææ³ä¸çç©©å¥æ§ãç ç©¶çµæè¡¨æï¼æååºæ¼ Transformer çæ¶æ§ï¼èª¿æ´çº EHR è³æçç¹å¾µï¼çºæ´æºç¢ºåå¬å¹³çè¨åºä¼°ç®æ¨¡åæä¾äºä¸ååºç¤æ¨¡åãæ­¤å¤ï¼æåæ¸¬éä¸¦æ¯è¼äº Lab-MAE èåºæº XGBoost æ¨¡åçç¢³è¶³è·¡ï¼çªåºäºå¶ç°å¢éæ±ã</paragraph>

##### **Trust and Dependability in Blockchain & AI Based MedIoT Applications: Research Challenges and Future Directions**
2501.02647v1 by Ellis Solaiman, Christa Awad

This paper critically reviews the integration of Artificial Intelligence (AI)
and blockchain technologies in the context of Medical Internet of Things
(MedIoT) applications, where they collectively promise to revolutionize
healthcare delivery. By examining current research, we underscore AI's
potential in advancing diagnostics and patient care, alongside blockchain's
capacity to bolster data security and patient privacy. We focus particularly on
the imperative to cultivate trust and ensure reliability within these systems.
Our review highlights innovative solutions for managing healthcare data and
challenges such as ensuring scalability, maintaining privacy, and promoting
ethical practices within the MedIoT domain. We present a vision for integrating
AI-driven insights with blockchain security in healthcare, offering a
comprehensive review of current research and future directions. We conclude
with a set of identified research gaps and propose that addressing these is
crucial for achieving the dependable, secure, and patient -centric MedIoT
applications of tomorrow.

æè¦ï¼æ¬ææ¹å¤æ§å°åé¡§äºäººå·¥æºæ§ (AI) ååå¡éæè¡å¨é«çç©è¯ç¶² (MedIoT) æç¨ä¸­çæ´åï¼éå©èå±åæ¿è«¾å°å¾¹åºæ¹è®é«çä¿å¥æåãééæª¢è¦ç®åçç ç©¶æï¼æåå¼·èª¿ AI å¨æ¨é²è¨ºæ·åæ£èç§è­·æ¹é¢çæ½åï¼ä»¥ååå¡éå¼·åè³æå®å¨åæ£èé±ç§çè½åãæåç¹å¥éæ³¨å¨éäºç³»çµ±å§å¹é¤ä¿¡ä»»åç¢ºä¿å¯é æ§çå¿è¦æ§ãæåçåé¡§éé»å¨æ¼ç®¡çé«çä¿å¥è³æçåµæ°è§£æ±ºæ¹æ¡ï¼ä»¥åç¢ºä¿å¯æ´åæ§ãç¶­è­·é±ç§åå¨ MedIoT é åå§æ¨å»£éå¾·å¯¦åç­ææ°ãæåæåºä¸åå° AI é©åçè¦è§£èåå¡éå®å¨æ´åå¨é«çä¿å¥ä¸­çé¡æ¯ï¼æä¾ç®åçç ç©¶æåæªä¾æ¹åçå¨é¢åé¡§ãæåä»¥ä¸çµå·²è­å¥çç ç©¶å·®è·ä½çºçµè«ï¼ä¸¦æåºè§£æ±ºéäºå·®è·å°æ¼éææªä¾å¯ä¿¡è³´ãå®å¨ä¸ä»¥æ£èçºä¸­å¿ç MedIoT æç¨è³ééè¦ã

##### **KM-UNet KAN Mamba UNet for medical image segmentation**
2501.02559v1 by Yibo Zhang

Medical image segmentation is a critical task in medical imaging analysis.
Traditional CNN-based methods struggle with modeling long-range dependencies,
while Transformer-based models, despite their success, suffer from quadratic
computational complexity. To address these limitations, we propose KM-UNet, a
novel U-shaped network architecture that combines the strengths of
Kolmogorov-Arnold Networks (KANs) and state-space models (SSMs). KM-UNet
leverages the Kolmogorov-Arnold representation theorem for efficient feature
representation and SSMs for scalable long-range modeling, achieving a balance
between accuracy and computational efficiency. We evaluate KM-UNet on five
benchmark datasets: ISIC17, ISIC18, CVC, BUSI, and GLAS. Experimental results
demonstrate that KM-UNet achieves competitive performance compared to
state-of-the-art methods in medical image segmentation tasks. To the best of
our knowledge, KM-UNet is the first medical image segmentation framework
integrating KANs and SSMs. This work provides a valuable baseline and new
insights for the development of more efficient and interpretable medical image
segmentation systems. The code is open source at
https://github.com/2760613195/KM_UNet
  Keywords:KAN,Manba, state-space models,UNet, Medical image segmentation, Deep
learning

æè¦ï¼é«å­¸å½±ååå²å¨é«å­¸å½±ååæä¸­æ¯ä¸é éè¦çä»»åã
å³çµ±åºæ¼ CNN çæ¹æ³é£ä»¥æ¨¡æ¬é·è·é¢ä¾è³´æ§ï¼
èåºæ¼ Transformer çæ¨¡ååç®¡æåï¼å»æäºæ¬¡è¨ç®è¤éåº¦çåé¡ãçºäºè§£æ±ºéäºéå¶ï¼æåæåºäº KM-UNetï¼éæ¯ä¸ç¨®æ°ç©ç U å½¢ç¶²è·¯æ¶æ§ï¼çµåäº Kolmogorov-Arnold ç¶²è·¯ (KANs) åçæç©ºéæ¨¡å (SSM) çåªé»ãKM-UNet å©ç¨ Kolmogorov-Arnold è¡¨ç¤ºå®çé²è¡é«æç¹å¾µè¡¨ç¤ºï¼å©ç¨ SSM é²è¡å¯æ´åé·è·é¢æ¨¡æ¬ï¼å¨æºç¢ºåº¦åè¨ç®æçä¹éåå¾å¹³è¡¡ãæåå¨äºååºæºè³æéä¸è©ä¼° KM-UNetï¼ISIC17ãISIC18ãCVCãBUSI å GLASãå¯¦é©çµæè¡¨æï¼èé«å­¸å½±ååå²ä»»åä¸­çæåé²æ¹æ³ç¸æ¯ï¼KM-UNet éå°äºæç«¶ç­åçæè½ãææåæç¥ï¼KM-UNet æ¯ç¬¬ä¸åæ´å KAN å SSM çé«å­¸å½±ååå²æ¡æ¶ãéé å·¥ä½çºéç¼æ´ææçä¸å¯è§£éçé«å­¸å½±ååå²ç³»çµ±æä¾äºæå¹å¼çåºç·åæ°è¦è§£ãç¨å¼ç¢¼å¨ https://github.com/2760613195/KM_UNet éæº
ééµå­ï¼KANãManbaãçæç©ºéæ¨¡åãUNetãé«å­¸å½±ååå²ãæ·±åº¦å­¸ç¿

##### **Hengqin-RA-v1: Advanced Large Language Model for Diagnosis and Treatment of Rheumatoid Arthritis with Dataset based Traditional Chinese Medicine**
2501.02471v1 by Yishen Liu, Shengda Luo, Zishao Zhong, Tongtong Wu, Jianguo Zhang, Peiyao Ou, Yong Liang, Liang Liu, Hudan Pan

Large language models (LLMs) primarily trained on English texts, often face
biases and inaccuracies in Chinese contexts. Their limitations are pronounced
in fields like Traditional Chinese Medicine (TCM), where cultural and clinical
subtleties are vital, further hindered by a lack of domain-specific data, such
as rheumatoid arthritis (RA). To address these issues, this paper introduces
Hengqin-RA-v1, the first large language model specifically tailored for TCM
with a focus on diagnosing and treating RA. We also present HQ-GCM-RA-C1, a
comprehensive RA-specific dataset curated from ancient Chinese medical
literature, classical texts, and modern clinical studies. This dataset empowers
Hengqin-RA-v1 to deliver accurate and culturally informed responses,
effectively bridging the gaps left by general-purpose models. Extensive
experiments demonstrate that Hengqin-RA-v1 outperforms state-of-the-art models,
even surpassing the diagnostic accuracy of TCM practitioners in certain cases.

æè¦ï¼å¤§åèªè¨æ¨¡åï¼LLMï¼ä¸»è¦ä»¥è±æææ¬é²è¡è¨ç·´ï¼å¨ä¸­æèªå¢ä¸­ç¶å¸¸é¢è¨åè¦åä¸æºç¢ºçåé¡ãå®åçå±éæ§å¨ä¸­é«ç­é åå°¤çºæé¡¯ï¼å çºä¸­é«æ¶åæååè¨åºä¸çå¾®å¦ä¹èï¼èä¸éç¼ºä¹ç¹å®é åçæ¸æï¼ä¾å¦é¡é¢¨æ¿éç¯çï¼RAï¼ãçºäºè§£æ±ºéäºåé¡ï¼æ¬æä»ç´¹äº Hengqin-RA-v1ï¼éæ¯ç¬¬ä¸åå°ééå°ä¸­é«çå¤§åèªè¨æ¨¡åï¼éé»æ¯è¨ºæ·åæ²»ç RAãæåéæä¾äº HQ-GCM-RA-C1ï¼éæ¯ä¸åå¾å¤ä»£ä¸­é«æç»ãå¤å¸ææ¬åç¾ä»£è¨åºç ç©¶ä¸­æ´çåºä¾çãå¨é¢ç RA ç¹å®æ¸æéãéåæ¸æéè® Hengqin-RA-v1 è½å¤ æä¾æºç¢ºä¸ç¬¦åæåèæ¯çåæï¼ææå°å½è£äºéç¨æ¨¡åçä¸çç©ºç½ãå¤§éçå¯¦é©è¡¨æï¼Hengqin-RA-v1 åªæ¼æåé²çæ¨¡åï¼å¨æäºææ³ä¸çè³è¶éäºä¸­é«å¾æ¥­èçè¨ºæ·æºç¢ºæ§ã

##### **Enhancing Contrastive Learning for Retinal Imaging via Adjusted Augmentation Scales**
2501.02451v1 by Zijie Cheng, Boxuan Li, AndrÃ© Altmann, Pearse A Keane, Yukun Zhou

Contrastive learning, a prominent approach within self-supervised learning,
has demonstrated significant effectiveness in developing generalizable models
for various applications involving natural images. However, recent research
indicates that these successes do not necessarily extend to the medical imaging
domain. In this paper, we investigate the reasons for this suboptimal
performance and hypothesize that the dense distribution of medical images poses
challenges to the pretext tasks in contrastive learning, particularly in
constructing positive and negative pairs. We explore model performance under
different augmentation strategies and compare the results to those achieved
with strong augmentations. Our study includes six publicly available datasets
covering multiple clinically relevant tasks. We further assess the model's
generalizability through external evaluations. The model pre-trained with weak
augmentation outperforms those with strong augmentation, improving AUROC from
0.838 to 0.848 and AUPR from 0.523 to 0.597 on MESSIDOR2, and showing similar
enhancements across other datasets. Our findings suggest that optimizing the
scale of augmentation is critical for enhancing the efficacy of contrastive
learning in medical imaging.

æè¦ï¼å°æ¯å­¸ç¿æ¯èªç£ç£å­¸ç¿ä¸­ä¸ç¨®éè¦çæ¹æ³ï¼å¨æ¶åèªç¶å½±åçåç¨®æç¨ä¸­ï¼å·²å±ç¾åºé¡¯èçæææ§ï¼å¯éç¼åºå¯æ¦åçæ¨¡åãç¶èï¼æè¿çç ç©¶æåºï¼éäºæåä¸¦æªå¿ç¶å»¶ä¼¸è³é«å­¸å½±åé åãå¨æ¬æä¸­ï¼æåæ¢è¨é æéç¨®æ¬¡ä½³æè½çåå ï¼ä¸¦åè¨­é«å­¸å½±åçå¯éåä½å°æ¯å­¸ç¿ä¸­çèå£ä»»åé æææ°ï¼ç¹å¥æ¯å¨å»ºæ§æ­£è² å°æãæåå¨ä¸åçæ´åç­ç¥ä¸æ¢è¨æ¨¡åæè½ï¼ä¸¦å°çµæèå¼·æ´åæéæççµæé²è¡æ¯è¼ãæåçç ç©¶æ¶µèå­åå¬éå¯ç¨çè³æéï¼æ¶µèå¤é è¨åºç¸éä»»åãæåé²ä¸æ­¥ééå¤é¨è©ä¼°ä¾è©ä¼°æ¨¡åçå¯æ¦åæ§ãä½¿ç¨å¼±æ´åé²è¡é è¨ç·´çæ¨¡ååªæ¼ä½¿ç¨å¼·æ´åçæ¨¡åï¼å¨ MESSIDOR2 ä¸å° AUROC å¾ 0.838 æåè³ 0.848ï¼å° AUPR å¾ 0.523 æåè³ 0.597ï¼ä¸¦å¨å¶ä»è³æéä¸å±ç¾é¡ä¼¼çæåãæåçç ç©¶çµæé¡¯ç¤ºï¼æä½³åæ´åè¦æ¨¡å°æ¼æåå°æ¯å­¸ç¿å¨é«å­¸å½±åä¸­çæè½è³ééè¦ã

##### **Enhancing Workplace Productivity and Well-being Using AI Agent**
2501.02368v1 by Ravirajan K, Arvind Sundarajan

This paper discusses the use of Artificial Intelligence (AI) to enhance
workplace productivity and employee well-being. By integrating machine learning
(ML) techniques with neurobiological data, the proposed approaches ensure
alignment with human ethical standards through value alignment models and
Hierarchical Reinforcement Learning (HRL) for autonomous task management. The
system utilizes biometric feedback from employees to generate personalized
health prompts, fostering a supportive work environment that encourages
physical activity. Additionally, we explore decentralized multi-agent systems
for improved collaboration and decision-making frameworks that enhance
transparency. Various approaches using ML techniques in conjunction with AI
implementations are discussed. Together, these innovations aim to create a more
productive and health-conscious workplace. These outcomes assist HR management
and organizations in launching more rational career progression streams for
employees and facilitating organizational transformation.

æè¦ï¼æ¬ææ¢è¨å©ç¨äººå·¥æºæ§ï¼AIï¼ä¾æåè·å ´çç¢ååå¡å·¥ç¦ç¥ãééå°æ©å¨å­¸ç¿ï¼MLï¼æè¡èç¥ç¶çç©å­¸è³ææ´åï¼ææåºçæ¹æ³ç¢ºä¿ééå¹å¼å°é½æ¨¡ååç¨æ¼èªä¸»ä»»åç®¡ççåå±¤å¼·åå­¸ç¿ï¼HRLï¼èäººé¡å«çæ¨æºä¿æä¸è´ãè©²ç³»çµ±å©ç¨å¡å·¥ççç©ç¹å¾µåé¥ä¾ç¢çåäººåå¥åº·æç¤ºï¼çé æ¯ææ§çå·¥ä½ç°å¢ï¼é¼åµèº«é«æ´»åãæ­¤å¤ï¼æåæ¢è¨åæ£å¼å¤æºè½é«ç³»çµ±ï¼ä»¥æ¹ååä½åæ±ºç­å¶å®æ¶æ§ï¼é²èæåéæåº¦ãæ¬æè¨è«äºåç¨®çµå ML æè¡è AI å¯¦ä½çæ¹æ³ãç¸½èè¨ä¹ï¼éäºåµæ°æ¨å¨åµé ä¸åæ´å·çç¢åä¸æ³¨éå¥åº·çè·å ´ãéäºæææå©æ¼äººåè³æºç®¡çåçµç¹æ©æ§çºå¡å·¥ååæ´åççè·æ¶¯ç¼å±ç®¡éï¼ä¸¦ä¿é²çµç¹è½åã

##### **Exploring the Capabilities and Limitations of Large Language Models for Radiation Oncology Decision Support**
2501.02346v1 by Florian Putz, Marlen Haderleina, Sebastian Lettmaier, Sabine Semrau, Rainer Fietkau, Yixing Huang

Thanks to the rapidly evolving integration of LLMs into decision-support
tools, a significant transformation is happening across large-scale systems.
Like other medical fields, the use of LLMs such as GPT-4 is gaining increasing
interest in radiation oncology as well. An attempt to assess GPT-4's
performance in radiation oncology was made via a dedicated 100-question
examination on the highly specialized topic of radiation oncology physics,
revealing GPT-4's superiority over other LLMs. GPT-4's performance on a broader
field of clinical radiation oncology is further benchmarked by the ACR
Radiation Oncology In-Training (TXIT) exam where GPT-4 achieved a high accuracy
of 74.57%. Its performance on re-labelling structure names in accordance with
the AAPM TG-263 report has also been benchmarked, achieving above 96%
accuracies. Such studies shed light on the potential of LLMs in radiation
oncology. As interest in the potential and constraints of LLMs in general
healthcare applications continues to rise5, the capabilities and limitations of
LLMs in radiation oncology decision support have not yet been fully explored.

æè¦ï¼é¨è LLM å¿«éæ¼é²æ´åå°æ±ºç­æ¯æ´å·¥å·ä¸­ï¼å¤§è¦æ¨¡ç³»çµ±æ­£å¨ç¼çéå¤§è½è®ã
èå¶ä»é«çé åä¸æ¨£ï¼LLMï¼ä¾å¦ GPT-4ï¼çä½¿ç¨ä¹å¨æ¾å°è«ç¤å­¸ä¸­ç²å¾è¶ä¾è¶å¤çèè¶£ãéééå°æ¾å°è«ç¤å­¸ç©çå­¸éåé«åº¦å°æ¥­çä¸»é¡é²è¡ 100 é¡å°éèè©¦ï¼è©¦åè©ä¼° GPT-4 å¨æ¾å°è«ç¤å­¸ä¸­çè¡¨ç¾ï¼æ­ç¤ºäº GPT-4 åªæ¼å¶ä» LLMãGPT-4 å¨æ´å»£æ³çè¨åºæ¾å°è«ç¤å­¸é åçè¡¨ç¾é²ä¸æ­¥ç± ACR æ¾å°è«ç¤å­¸å¨è·è¨ç·´ (TXIT) èè©¦é²è¡è©éï¼GPT-4 å¨å¶ä¸­åå¾ 74.57% çé«æºç¢ºåº¦ãå®æ ¹æ AAPM TG-263 å ±åéæ°æ¨è¨çµæ§åç¨±çè¡¨ç¾ä¹å·²é²è¡è©éï¼æºç¢ºåº¦éå° 96% ä»¥ä¸ãéäºç ç©¶æ­ç¤ºäº LLM å¨æ¾å°è«ç¤å­¸ä¸­çæ½åãç±æ¼äººåæçºå° LLM å¨ä¸è¬é«çä¿å¥æç¨ä¸­çæ½ååéå¶æèè¶£5ï¼LLM å¨æ¾å°è«ç¤å­¸æ±ºç­æ¯æ´ä¸­çåè½åéå¶å°æªå¾å°ååæ¢ç´¢ã

##### **Deep Learning-Driven Segmentation of Ischemic Stroke Lesions Using Multi-Channel MRI**
2501.02287v1 by Ashiqur Rahman, Muhammad E. H. Chowdhury, Md Sharjis Ibne Wadud, Rusab Sarmun, Adam Mushtak, Sohaib Bassam Zoghoul, Israa Al-Hashimi

Ischemic stroke, caused by cerebral vessel occlusion, presents substantial
challenges in medical imaging due to the variability and subtlety of stroke
lesions. Magnetic Resonance Imaging (MRI) plays a crucial role in diagnosing
and managing ischemic stroke, yet existing segmentation techniques often fail
to accurately delineate lesions. This study introduces a novel deep
learning-based method for segmenting ischemic stroke lesions using
multi-channel MRI modalities, including Diffusion Weighted Imaging (DWI),
Apparent Diffusion Coefficient (ADC), and enhanced Diffusion Weighted Imaging
(eDWI). The proposed architecture integrates DenseNet121 as the encoder with
Self-Organized Operational Neural Networks (SelfONN) in the decoder, enhanced
by Channel and Space Compound Attention (CSCA) and Double
Squeeze-and-Excitation (DSE) blocks. Additionally, a custom loss function
combining Dice Loss and Jaccard Loss with weighted averages is introduced to
improve model performance. Trained and evaluated on the ISLES 2022 dataset, the
model achieved Dice Similarity Coefficients (DSC) of 83.88% using DWI alone,
85.86% with DWI and ADC, and 87.49% with the integration of DWI, ADC, and eDWI.
This approach not only outperforms existing methods but also addresses key
limitations in current segmentation practices. These advancements significantly
enhance diagnostic precision and treatment planning for ischemic stroke,
providing valuable support for clinical decision-making.

æè¦ï¼ç¼ºè¡æ§ä¸­é¢¨æ¯ç±è¦è¡ç®¡é»å¡æå¼èµ·ï¼ç±æ¼ä¸­é¢¨çç¶çå¯è®æ§åé±è½æ§ï¼å¨é«å­¸å½±åä¸­é æç¸ç¶å¤§çææ°ãç£æ¯é å½± (MRI) å¨è¨ºæ·åæ²»çç¼ºè¡æ§ä¸­é¢¨ä¸­æ®æ¼è³ééè¦çè§è²ï¼ä½ç¾æçåå²æè¡å¸¸å¸¸ç¡æ³æºç¢ºå°æç¹ªçç¶ãæ¬ç ç©¶æåºä¸åæ°çæ·±åº¦å­¸ç¿æ¹æ³ï¼ä½¿ç¨å¤éé MRI æ¨¡å¼å°ç¼ºè¡æ§ä¸­é¢¨çç¶é²è¡åå²ï¼åæ¬æ´æ£å æ¬å½±å (DWI)ãè¡¨è§æ´æ£ä¿æ¸ (ADC) åå¢å¼·åæ´æ£å æ¬å½±å (eDWI)ãææåºçæ¶æ§å° DenseNet121 æ´åçºç·¨ç¢¼å¨ï¼ä¸¦å¨è§£ç¢¼å¨ä¸­ä½¿ç¨èªçµç¹éç®ç¥ç¶ç¶²è·¯ (SelfONN)ï¼ä¸¦ç±ééåç©ºéè¤åæ³¨æå (CSCA) åééæ å£æ¿åµ (DSE) åå¡é²è¡å å¼·ãæ­¤å¤ï¼éå¼é²äºä¸åèªè¨çæå¤±å½æ¸ï¼çµåäº Dice æå¤±å Jaccard æå¤±ä»¥åå æ¬å¹³åï¼ä»¥æåæ¨¡åæè½ãå¨ ISLES 2022 è³æéä¸é²è¡è¨ç·´åè©ä¼°ï¼è©²æ¨¡åä½¿ç¨ DWI å®ç¨æéå° 83.88% ç Dice ç¸ä¼¼æ§ä¿æ¸ (DSC)ï¼ä½¿ç¨ DWI å ADC æéå° 85.86%ï¼ä½¿ç¨ DWIãADC å eDWI æ´åæéå° 87.49%ãéç¨®æ¹æ³ä¸ååªæ¼ç¾ææ¹æ³ï¼éè½è§£æ±ºç¶ååå²å¯¦åä¸­çä¸»è¦éå¶ãéäºé²å±é¡¯èæåäºç¼ºè¡æ§ä¸­é¢¨çè¨ºæ·ç²¾æºåº¦åæ²»çè¦åï¼çºè¨åºæ±ºç­æä¾æå¹å¼çæ¯æ´ã

##### **The Integration of Blockchain and Artificial Intelligence for Secure Healthcare Systems**
2501.02169v1 by Umar Safdar, Simon Gabrael

Verisign reported a 125 percent increase in data breaches within the
healthcare sector in the United States during 2022, with 18.2 million patient
records being impacted. Growing healthcare data volumes and diversification
mean that medical information is becoming more valuable. Many Health Centers
use various technologies to ease the classification, storage, and exchange of
big data. This use can also make the health data of the users at risk and
vulnerable. AI and blockchain are among the leading technologies at hand. With
AI, data-driven operations and big data efficiency have been improved with
respect to traditional techniques. Due to its potential to bring about
improvements in health services and lower medical costs, this AI technology is
regularly used in healthcare. Blockchain helps protect transactions on sharing
information and private privacy as long as the exchange of knowledge is that of
the standard. The objective of this analysis is to investigate the research and
unique contributions since 2008 regarding blockchain-integrated AI and
healthcare systems. The work sheds light on applied AI-based healthcare schemes
with machine, ballistic, and acrylic learning and disparate blockchain
structures. The use of technology in order to ensure patient data security and
manage medical information effectively in healthcare settings offers a highly
successful position for both healthcare providers and patients. From 2018 to
2021, the best year was 2021 to grow, enhancing everything to examine the
download of the device and the counting of Google Academies, for which the
joining perspective was borrowed; local research experts were asked, identified
articles in recent years, and read reviews of large research grants.

æè¦ï¼Verisign å ±å 2022 å¹´ç¾åé«çä¿å¥é¨éçè³æå¤æ´©äºä»¶å¢å äº 125%ï¼å½±é¿äº 1,820 è¬ç­çæ­·ãé«çä¿å¥è³æéä¸æ·å¢å ä¸å¤ååï¼éè¡¨ç¤ºé«çè³è¨è®å¾æ´æå¹å¼ãè¨±å¤é«çä¸­å¿ä½¿ç¨åç¨®æè¡ï¼ä»¥ç°¡åå¤§æ¸æçåé¡ãå²å­åäº¤æãéç¨®ä½¿ç¨æ¹å¼ä¹å¯è½ä½¿ä½¿ç¨èçå¥åº·è³æé¢è¨é¢¨éªåèå¼±æ§ãäººå·¥æºæ§ååå¡éæ¯ç¾æçé åæè¡ãééäººå·¥æºæ§ï¼è³æé©åçéä½åå¤§æ¸ææçå·²ç¸è¼æ¼å³çµ±æè¡ç²å¾æ¹åãç±æ¼äººå·¥æºæ§æè¡ææ½åæ¹åé«çæåä¸¦éä½é«çææ¬ï¼å æ­¤ç¶å¸¸å¨é«çä¿å¥ä¸­ä½¿ç¨ãåå¡éæå©æ¼ä¿è­·äº¤æï¼å¨è³è¨å±äº«åé±ç§æ¹é¢ï¼åªè¦ç¥è­çäº¤ææ¯æ¨æºçãæ¬åæçç®æ¨æ¯èª¿æ¥èª 2008 å¹´ä»¥ä¾èåå¡éæ´åäººå·¥æºæ§åé«çä¿å¥ç³»çµ±ç¸éçç ç©¶åç¨ç¹è²¢ç»ãéé å·¥ä½é¡æäºæç¨äººå·¥æºæ§çºåºç¤çé«çä¿å¥è¨ç«ï¼åæ¬æ©å¨ãå½éåä¸ç¯é¸å­¸ç¿ä»¥åä¸åçåå¡éçµæ§ãçºäºç¢ºä¿çæ£è³æå®å¨ä¸¦å¨é«çä¿å¥ç°å¢ä¸­ææç®¡çé«çè³è¨ï¼ä½¿ç¨æè¡çºé«çä¿å¥æä¾èåçæ£æä¾äºæ¥µçºæåçå®ä½ãå¾ 2018 å¹´å° 2021 å¹´ï¼æé©åæé·çæ¯ 2021 å¹´ï¼å å¼·ææä¸åï¼ä»¥æª¢æ¥è£ç½®çä¸è¼å Google å­¸è¡çè¨æ¸ï¼åç¨äºå å¥çè§é»ï¼è©¢åäºç¶å°ç ç©¶å°å®¶ï¼æ¾åºè¿å¹´ä¾çæç« ï¼ä¸¦é±è®å¤§åç ç©¶è£å©éçè©è«ã

##### **Online Detection of Water Contamination Under Concept Drift**
2501.02107v1 by Jin Li, Kleanthis Malialis, Stelios G. Vrachimis, Marios M. Polycarpou

Water Distribution Networks (WDNs) are vital infrastructures, and
contamination poses serious public health risks. Harmful substances can
interact with disinfectants like chlorine, making chlorine monitoring essential
for detecting contaminants. However, chlorine sensors often become unreliable
and require frequent calibration. This study introduces the Dual-Threshold
Anomaly and Drift Detection (AD&DD) method, an unsupervised approach combining
a dual-threshold drift detection mechanism with an LSTM-based Variational
Autoencoder(LSTM-VAE) for real-time contamination detection. Tested on two
realistic WDNs, AD&DD effectively identifies anomalies with sensor offsets as
concept drift, and outperforms other methods. A proposed decentralized
architecture enables accurate contamination detection and localization by
deploying AD&DD on selected nodes.

æè¦ï¼éæ°´ç¶²è·¯ (WDN) æ¯éè¦çåºç¤è¨­æ½ï¼èæ±¡ææé æå´éçå¬å±è¡çé¢¨éªãæå®³ç©è³ªå¯è½æèæ¶æ¯åï¼å¦æ°¯æ°£ï¼äº¤äºä½ç¨ï¼å æ­¤ç£æ¸¬æ°¯æ°£å°æ¼åµæ¸¬æ±¡æç©è³ééè¦ãç¶èï¼æ°¯æ°£ææ¸¬å¨å¸¸å¸¸è®å¾ä¸å¯é ï¼éè¦é »ç¹æ ¡æ­£ãæ¬ç ç©¶æåºéé¾å¼ç°å¸¸èæ¼ç§»åµæ¸¬ (AD&DD) æ¹æ³ï¼éæ¯ä¸ç¨®éç£ç£å¼æ¹æ³ï¼çµåéé¾å¼æ¼ç§»åµæ¸¬æ©å¶èåºæ¼ LSTM çè®ç°èªåç·¨ç¢¼å¨ (LSTM-VAE)ï¼ç¨æ¼å³ææ±¡æåµæ¸¬ãå¨å©åå¯¦éç WDN ä¸é²è¡æ¸¬è©¦ï¼AD&DD è½ææå°å°ææ¸¬å¨åç§»è¦çºæ¦å¿µæ¼ç§»ï¼ä¸¦åªæ¼å¶ä»æ¹æ³ãææåºçåæ£å¼æ¶æ§è½ééå¨é¸å®çç¯é»é¨ç½² AD&DDï¼å¯¦ç¾ç²¾ç¢ºçæ±¡æåµæ¸¬èå®ä½ã

##### **METAGENE-1: Metagenomic Foundation Model for Pandemic Monitoring**
2501.02045v1 by Ollie Liu, Sami Jaghouar, Johannes Hagemann, Shangshang Wang, Jason Wiemels, Jeff Kaufman, Willie Neiswanger

We pretrain METAGENE-1, a 7-billion-parameter autoregressive transformer
model, which we refer to as a metagenomic foundation model, on a novel corpus
of diverse metagenomic DNA and RNA sequences comprising over 1.5 trillion base
pairs. This dataset is sourced from a large collection of human wastewater
samples, processed and sequenced using deep metagenomic (next-generation)
sequencing methods. Unlike genomic models that focus on individual genomes or
curated sets of specific species, the aim of METAGENE-1 is to capture the full
distribution of genomic information present within this wastewater, to aid in
tasks relevant to pandemic monitoring and pathogen detection. We carry out
byte-pair encoding (BPE) tokenization on our dataset, tailored for metagenomic
sequences, and then pretrain our model. In this paper, we first detail the
pretraining dataset, tokenization strategy, and model architecture,
highlighting the considerations and design choices that enable the effective
modeling of metagenomic data. We then show results of pretraining this model on
our metagenomic dataset, providing details about our losses, system metrics,
and training stability over the course of pretraining. Finally, we demonstrate
the performance of METAGENE-1, which achieves state-of-the-art results on a set
of genomic benchmarks and new evaluations focused on human-pathogen detection
and genomic sequence embedding, showcasing its potential for public health
applications in pandemic monitoring, biosurveillance, and early detection of
emerging health threats.

æè¦ï¼<paragraph>æåé è¨ç·´äºä¸åå·æ 70 åååæ¸çèªè¿´æ­¸è½æå¨æ¨¡å METAGENE-1ï¼æåç¨±ä¹çºå®åºå çµåºç¤æ¨¡åï¼å®å»ºç«å¨ä¸åæ°ç©çèªæåº«ä¸ï¼å¶ä¸­åå«è¶é 1.5 ååé¹¼åºå°çå¤æ¨£åå®åºå çµ DNA å RNA åºåãæ­¤æ¸æéä¾èªå¤§éäººé¡å»¢æ°´æ¨£æ¬ï¼ä½¿ç¨æ·±åº¦å®åºå çµï¼ä¸ä¸ä»£ï¼å®åºæ¹æ³é²è¡èçåå®åºãèå°æ³¨æ¼åå¥åºå çµæç¹å®ç©ç¨®ç­åéåçåºå çµæ¨¡åä¸åï¼METAGENE-1 çç®æ¨æ¯æ·åæ­¤å»¢æ°´ä¸­å­å¨çåºå çµè³è¨çå®æ´åä½ï¼ä»¥åå©èå¤§æµè¡ç£æ¸¬åçåé«æª¢æ¸¬ç¸éçä»»åãæåå°æ¸æéå·è¡éå°å®åºå çµåºåéèº«æé çä½åçµå°ç·¨ç¢¼ (BPE) æ¨è¨åï¼ç¶å¾é è¨ç·´æåçæ¨¡åãå¨æ¬æä¸­ï¼æåé¦åè©³ç´°èªªæé è¨ç·´æ¸æéãæ¨è¨åç­ç¥åæ¨¡åæ¶æ§ï¼éé»èªªæè½ææå»ºæ¨¡å®åºå çµæ¸æçèéåè¨­è¨é¸æãç¶å¾ï¼æåå±ç¤ºäºå¨æåçå®åºå çµæ¸æéä¸é è¨ç·´æ­¤æ¨¡åççµæï¼æä¾æéæåçæå¤±ãç³»çµ±ææ¨åå¨é è¨ç·´éç¨ä¸­è¨ç·´ç©©å®æ§çè©³ç´°è³è¨ãæå¾ï¼æåå±ç¤ºäº METAGENE-1 çæè½ï¼å®å¨éå°äººé¡çåé«æª¢æ¸¬ååºå çµåºååµå¥çä¸çµåºå çµåºæºåæ°è©ä¼°ä¸­éå°äºæåé²ççµæï¼å±ç¤ºäºå¶å¨å¬å±è¡çæç¨ä¸­çæ½åï¼åæ¬å¤§æµè¡ç£æ¸¬ãçç©ç£æ§åæ°èå¥åº·å¨èçæ©ææª¢æ¸¬ã</paragraph>

##### **Advancing Pancreatic Cancer Prediction with a Next Visit Token Prediction Head on top of Med-BERT**
2501.02044v1 by Jianping He, Laila Rasmy, Degui Zhi, Cui Tao

Background: Recently, numerous foundation models pretrained on extensive data
have demonstrated efficacy in disease prediction using Electronic Health
Records (EHRs). However, there remains some unanswered questions on how to best
utilize such models especially with very small fine-tuning cohorts. Methods: We
utilized Med-BERT, an EHR-specific foundation model, and reformulated the
disease binary prediction task into a token prediction task and a next visit
mask token prediction task to align with Med-BERT's pretraining task format in
order to improve the accuracy of pancreatic cancer (PaCa) prediction in both
few-shot and fully supervised settings. Results: The reformulation of the task
into a token prediction task, referred to as Med-BERT-Sum, demonstrates
slightly superior performance in both few-shot scenarios and larger data
samples. Furthermore, reformulating the prediction task as a Next Visit Mask
Token Prediction task (Med-BERT-Mask) significantly outperforms the
conventional Binary Classification (BC) prediction task (Med-BERT-BC) by 3% to
7% in few-shot scenarios with data sizes ranging from 10 to 500 samples. These
findings highlight that aligning the downstream task with Med-BERT's
pretraining objectives substantially enhances the model's predictive
capabilities, thereby improving its effectiveness in predicting both rare and
common diseases. Conclusion: Reformatting disease prediction tasks to align
with the pretraining of foundation models enhances prediction accuracy, leading
to earlier detection and timely intervention. This approach improves treatment
effectiveness, survival rates, and overall patient outcomes for PaCa and
potentially other cancers.

æè¦ï¼èæ¯ï¼æè¿ï¼å¤§éåºäºå¹¿æ³æ°æ®è¿è¡é¢è®­ç»çåºç¡æ¨¡åå·²è¯æå¨ä½¿ç¨çµå­å¥åº·è®°å½ (EHR) é¢æµç¾çæ¹é¢ææãç¶èï¼å³äºå¦ä½æå¥½å°å©ç¨æ­¤ç±»æ¨¡åï¼å°¤å¶æ¯å¨æå°å¾®è°éåä¸­ï¼ä»æä¸äºæªè§£å³çé®é¢ãæ¹æ³ï¼æä»¬å©ç¨äº EHR ç¹å®çåºç¡æ¨¡å Med-BERTï¼å¹¶å°ç¾çäºåé¢æµä»»å¡éæ°è¡¨è¿°ä¸ºæ è®°é¢æµä»»å¡åä¸æ¬¡è®¿é®æ©ç æ è®°é¢æµä»»å¡ï¼ä»¥ä¸ Med-BERT çé¢è®­ç»ä»»å¡æ ¼å¼ä¿æä¸è´ï¼ä»èæé«è°èºç (PaCa) é¢æµçåç¡®æ§ï¼æ è®ºæ¯å¨å°æ ·æ¬è¿æ¯å®å¨çç£çè®¾ç½®ä¸­ãç»æï¼å°ä»»å¡éæ°è¡¨è¿°ä¸ºæ è®°é¢æµä»»å¡ï¼ç§°ä¸º Med-BERT-Sumï¼ï¼å¨å°æ ·æ¬åºæ¯åè¾å¤§æ°æ®æ ·æ¬ä¸­åè¡¨ç°åºç¥å¾®ä¼è¶çæ§è½ãæ­¤å¤ï¼å°é¢æµä»»å¡éæ°è¡¨è¿°ä¸ºä¸ä¸æ¬¡è®¿é®æ©ç æ è®°é¢æµä»»å¡ï¼Med-BERT-Maskï¼å¨å°æ ·æ¬åºæ¯ä¸­ææ¾ä¼äºä¼ ç»çäºååç±» (BC) é¢æµä»»å¡ï¼Med-BERT-BCï¼ï¼æ°æ®å¤§å°ä» 10 å° 500 ä¸ªæ ·æ¬ä¸ç­ï¼ä¼è¶å¹åº¦ä¸º 3% å° 7%ãè¿äºåç°å¼ºè°ï¼å°ä¸æ¸¸ä»»å¡ä¸ Med-BERT çé¢è®­ç»ç®æ ä¿æä¸è´ï¼å¯ä»¥æ¾çå¢å¼ºæ¨¡åçé¢æµè½åï¼ä»èæé«å¶é¢æµç½è§ç¾çåå¸¸è§ç¾ççæææ§ãç»è®ºï¼éæ°æ ¼å¼åç¾çé¢æµä»»å¡ä»¥ä¸åºç¡æ¨¡åçé¢è®­ç»ä¿æä¸è´ï¼å¯æé«é¢æµåç¡®æ§ï¼ä»èå®ç°æ©ææ£æµååæ¶å¹²é¢ãè¿ç§æ¹æ³æé«äº PaCa åå¶ä»çççæ²»çææãå­æ´»çåæ£èæ»ä½é¢åã

##### **Combined Hyper-Extensible Extremely-Secured Zero-Trust CIAM-PAM architecture**
2501.01732v1 by Shivom Aggarwal, Shourya Mehra, Safeer Sathar

Customer Identity and Access Management (CIAM) systems play a pivotal role in
securing enterprise infrastructures. However, the complexity of implementing
these systems requires careful architectural planning to ensure positive Return
on Investment (RoI) and avoid costly delays. The proliferation of Active
Persistent cyber threats, coupled with advancements in AI, cloud computing, and
geographically distributed customer populations, necessitates a paradigm shift
towards adaptive and zero-trust security frameworks. This paper introduces the
Combined Hyper-Extensible Extremely-Secured Zero-Trust (CHEZ) CIAM-PAM
architecture, designed specifically for large-scale enterprises. The CHEZ PL
CIAM-PAM framework addresses critical security gaps by integrating federated
identity management (private and public identities), password-less
authentication, adaptive multi-factor authentication (MFA), microservice-based
PEP (Policy Entitlement Point), multi-layer RBAC (Role Based Access Control)
and multi-level trust systems. This future-proof design also includes
end-to-end data encryption, and seamless integration with state-of-the-art
AI-based threat detection systems, while ensuring compliance with stringent
regulatory standards.

æè¦ï¼å®¢æ¶èº«åèå­åç®¡ç (CIAM) ç³»çµ±å¨ç¢ºä¿ä¼æ¥­åºç¤è¨­æ½å®å¨æ¹é¢æ®æ¼èééµè§è²ãç¶èï¼å¯¦ä½éäºç³»çµ±çè¤éæ§éè¦ä»ç´°çæ¶æ§è¦åï¼ä»¥ç¢ºä¿æè³å ±é¬ç (RoI) çºæ­£ï¼ä¸¦é¿åææ¬é«æçå»¶èª¤ãä¸»åæçºçç¶²è·¯å¨èçæ´æ£ï¼å ä¸äººå·¥æºæ§ãé²ç«¯éç®åå°çåå¸çå®¢æ¶ç¾¤çé²æ­¥ï¼éè¦æåé©ææ§åé¶ä¿¡ä»»å®å¨æ¶æ§è½è®ãæ¬æä»ç´¹å°çºå¤§åä¼æ¥­è¨­è¨ç Combined Hyper-Extensible Extremely-Secured Zero-Trust (CHEZ) CIAM-PAM æ¶æ§ãCHEZ PL CIAM-PAM æ¶æ§ééæ´åè¯åèº«åç®¡çï¼ç§äººåå¬ç¨èº«åï¼ãç¡å¯ç¢¼é©è­ãé©ææ§å¤éèº«åé©è­ (MFA)ãåºæ¼å¾®æåç PEPï¼æ¿ç­ææ¬é»ï¼ãå¤å±¤ RBACï¼åºæ¼è§è²çå­åæ§å¶ï¼åå¤å±¤ç´ä¿¡ä»»ç³»çµ±ä¾è§£æ±ºééµçå®å¨æ¼æ´ãéç¨®å·åæªä¾æ§çè¨­è¨ä¹åå«ç«¯å°ç«¯è³æå å¯ï¼ä¸¦èæåé²çåºæ¼äººå·¥æºæ§çå¨èåµæ¸¬ç³»çµ±ç¡ç¸«æ´åï¼åæç¢ºä¿ç¬¦åå´æ ¼çæ³è¦æ¨æºã

##### **EAUWSeg: Eliminating annotation uncertainty in weakly-supervised medical image segmentation**
2501.01658v1 by Wang Lituan, Zhang Lei, Wang Yan, Wang Zhenbin, Zhang Zhenwei, Zhang Yi

Weakly-supervised medical image segmentation is gaining traction as it
requires only rough annotations rather than accurate pixel-to-pixel labels,
thereby reducing the workload for specialists. Although some progress has been
made, there is still a considerable performance gap between the label-efficient
methods and fully-supervised one, which can be attributed to the uncertainty
nature of these weak labels. To address this issue, we propose a novel weak
annotation method coupled with its learning framework EAUWSeg to eliminate the
annotation uncertainty. Specifically, we first propose the Bounded Polygon
Annotation (BPAnno) by simply labeling two polygons for a lesion. Then, the
tailored learning mechanism that explicitly treat bounded polygons as two
separated annotations is proposed to learn invariant feature by providing
adversarial supervision signal for model training. Subsequently, a
confidence-auxiliary consistency learner incorporates with a
classification-guided confidence generator is designed to provide reliable
supervision signal for pixels in uncertain region by leveraging the feature
presentation consistency across pixels within the same category as well as
class-specific information encapsulated in bounded polygons annotation.
Experimental results demonstrate that EAUWSeg outperforms existing
weakly-supervised segmentation methods. Furthermore, compared to
fully-supervised counterparts, the proposed method not only delivers superior
performance but also costs much less annotation workload. This underscores the
superiority and effectiveness of our approach.

æè¦ï¼å¼±çç£å»å­¦å½±ååå²æ­£è·å¾å³æ³¨ï¼å ä¸ºå®åªéè¦ç²ç¥çæ³¨éï¼èä¸æ¯ç²¾ç¡®çåç´ å°åç´ æ ç­¾ï¼ä»èåå°äºä¸å®¶çå·¥ä½éãå°½ç®¡åå¾äºä¸äºè¿å±ï¼ä½å¨æ ç­¾é«ææ¹æ³åå®å¨çç£æ¹æ³ä¹é´ä»ç¶å­å¨ç¸å½å¤§çæ§è½å·®è·ï¼è¿å¯å½å äºè¿äºå¼±æ ç­¾çä¸ç¡®å®æ§ãä¸ºäºè§£å³è¿ä¸ªé®é¢ï¼æä»¬æåºäºä¸ç§æ°çå¼±æ³¨éæ¹æ³ï¼å¹¶ç»åå¶å­¦ä¹ æ¡æ¶ EAUWSeg æ¥æ¶é¤æ³¨éçä¸ç¡®å®æ§ãå·ä½æ¥è¯´ï¼æä»¬é¦åéè¿ç®åå°ä¸ºçç¶æ è®°ä¸¤ä¸ªå¤è¾¹å½¢æ¥æåºæçå¤è¾¹å½¢æ³¨é (BPAnno)ãç¶åï¼æåºäºå°æçå¤è¾¹å½¢æç¡®å°è§ä¸ºä¸¤ä¸ªåç¦»æ³¨éçå®å¶å­¦ä¹ æºå¶ï¼ä»¥éè¿ä¸ºæ¨¡åè®­ç»æä¾å¯¹ææ§çç£ä¿¡å·æ¥å­¦ä¹ ä¸åç¹å¾ãéåï¼ç½®ä¿¡è¾å©ä¸è´æ§å­¦ä¹ å¨ä¸åç±»å¼å¯¼ç½®ä¿¡åº¦çæå¨ç»åè®¾è®¡ï¼ä»¥éè¿å©ç¨åä¸ç±»å«ååç´ çç¹å¾è¡¨ç¤ºä¸è´æ§ä»¥åæçå¤è¾¹å½¢æ³¨éä¸­å°è£çç¹å®äºç±»çä¿¡æ¯ï¼ä¸ºä¸ç¡®å®åºåä¸­çåç´ æä¾å¯é ççç£ä¿¡å·ãå®éªç»æè¡¨æï¼EAUWSeg ä¼äºç°æçå¼±çç£åå²æ¹æ³ãæ­¤å¤ï¼ä¸å®å¨çç£çå¯¹åºæ¹æ³ç¸æ¯ï¼ææåºçæ¹æ³ä¸ä»æä¾äºåè¶çæ§è½ï¼èä¸æ³¨éå·¥ä½éä¹å¤§å¤§åå°ãè¿çªåºäºæä»¬æ¹æ³çä¼è¶æ§åæææ§ã

##### **Implications of Artificial Intelligence on Health Data Privacy and Confidentiality**
2501.01639v2 by Ahmad Momani

The rapid integration of artificial intelligence (AI) in healthcare is
revolutionizing medical diagnostics, personalized medicine, and operational
efficiency. However, alongside these advancements, significant challenges arise
concerning patient data privacy, ethical considerations, and regulatory
compliance. This paper examines the dual impact of AI on healthcare,
highlighting its transformative potential and the critical need for
safeguarding sensitive health information. It explores the role of the Health
Insurance Portability and Accountability Act (HIPAA) as a regulatory framework
for ensuring data privacy and security, emphasizing the importance of robust
safeguards and ethical standards in AI-driven healthcare. Through case studies,
including AI applications in diabetic retinopathy, oncology, and the
controversies surrounding data sharing, this study underscores the ethical and
legal complexities of AI implementation. A balanced approach that fosters
innovation while maintaining patient trust and privacy is imperative. The
findings emphasize the importance of continuous education, transparency, and
adherence to regulatory frameworks to harness AI's full potential responsibly
and ethically in healthcare.

æè¦ï¼äººå·¥æºæ§ (AI) å¨é«çä¿å¥é åçå¿«éæ´åï¼æ­£å¨å¾¹åºè®é©é«çè¨ºæ·ãåäººåé«çåçéæçãç¶èï¼é¨èéäºé²æ­¥ï¼ä¹åºç¾äºéæ¼æ£èè³æé±ç§ãå«çèéåæ³è¦éµå¾ªçéå¤§ææ°ãæ¬ææ¢è¨äº AI å°é«çä¿å¥çééå½±é¿ï¼å¼·èª¿å¶è½åæ½åä»¥åä¿è­·ææå¥åº·è³è¨çééµéæ±ãæ¬ææ¢è¨äºå¥åº·ä¿éªå¯ææ§åè²¬ä»»æ³æ¡ (HIPAA) ä½çºç¢ºä¿è³æé±ç§åå®å¨çæ³è¦æ¶æ§çè§è²ï¼å¼·èª¿å¨ AI é©åçé«çä¿å¥ä¸­å¥å¨ä¿éæªæ½åéå¾·æ¨æºçéè¦æ§ãæ¬ç ç©¶ééæ¡ä¾ç ç©¶ï¼åæ¬ AI å¨ç³å°¿çè¦ç¶²èçè®ãè«ç¤å­¸ä¸­çæç¨ï¼ä»¥ååç¹è³æå±äº«çç­è­°ï¼å¼·èª¿äº AI å¯¦æ½çå«çåæ³å¾è¤éæ§ãä¸ç¨®å¹³è¡¡çæ¹æ³ï¼å¨ä¿é²åµæ°çåæï¼ç¶­è­·æ£èçä¿¡ä»»åé±ç§ï¼è³ééè¦ãç ç©¶çµæå¼·èª¿äºæçºæè²ãéæåº¦åéµå®æ³è¦æ¡æ¶çéè¦æ§ï¼ä»¥è² è²¬ä»»ä¸åä¹éå¾·çæ¹å¼å©ç¨ AI å¨é«çä¿å¥ä¸­çå¨é¨æ½åã

##### **Merging Context Clustering with Visual State Space Models for Medical Image Segmentation**
2501.01618v1 by Yun Zhu, Dong Zhang, Yi Lin, Yifei Feng, Jinhui Tang

Medical image segmentation demands the aggregation of global and local
feature representations, posing a challenge for current methodologies in
handling both long-range and short-range feature interactions. Recently, vision
mamba (ViM) models have emerged as promising solutions for addressing model
complexities by excelling in long-range feature iterations with linear
complexity. However, existing ViM approaches overlook the importance of
preserving short-range local dependencies by directly flattening spatial tokens
and are constrained by fixed scanning patterns that limit the capture of
dynamic spatial context information. To address these challenges, we introduce
a simple yet effective method named context clustering ViM (CCViM), which
incorporates a context clustering module within the existing ViM models to
segment image tokens into distinct windows for adaptable local clustering. Our
method effectively combines long-range and short-range feature interactions,
thereby enhancing spatial contextual representations for medical image
segmentation tasks. Extensive experimental evaluations on diverse public
datasets, i.e., Kumar, CPM17, ISIC17, ISIC18, and Synapse demonstrate the
superior performance of our method compared to current state-of-the-art
methods. Our code can be found at https://github.com/zymissy/CCViM.

æè¦ï¼é«çå½±ååå²éè¦èåå¨å±åå±é¨ç¹å¾µè¡¨ç¤ºï¼å°ç¶åæ¹æ³èçé·ç¨åç­ç¨ç¹å¾µäº¤äºæ§æææ°ãæè¿ï¼è¦è¦ºæ¼å·´ (ViM) æ¨¡åå·²æçºè§£æ±ºæ¨¡åè¤éæ§çæåéçè§£æ±ºæ¹æ¡ï¼å®å¨ç·æ§è¤éåº¦ä¸æé·é·ç¨ç¹å¾µè¿­ä»£ãç¶èï¼ç¾æç ViM æ¹æ³å¿½è¦äºééç´æ¥å£å¹³ç©ºéæ¨è¨ä¾ä¿çç­ç¨å±é¨ä¾è³´æ§çéè¦æ§ï¼ä¸¦ä¸åå°éå¶çæææ¨¡å¼çç´æï¼éæéå¶åæç©ºéèæ¯è³è¨çæ·åãçºäºè§£æ±ºéäºææ°ï¼æåå¼å¥äºä¸ç¨®åçºèæ¯èé¡ ViM (CCViM) çç°¡å®ä½ææçæ¹æ³ï¼å®å¨ç¾æç ViM æ¨¡åä¸­å å¥äºä¸åèæ¯èé¡æ¨¡çµï¼å°å½±åæ¨è¨åå²æä¸åçè¦çªï¼ä»¥é²è¡é©ææ§å±é¨èé¡ãæåçæ¨¡åææå°çµåäºé·ç¨åç­ç¨ç¹å¾µäº¤äºï¼å¾èå¢å¼·äºç¨æ¼é«çå½±ååå²ä»»åçç©ºéèæ¯è¡¨ç¤ºãå¨åç¨®å¬éè³æéï¼å³ KumarãCPM17ãISIC17ãISIC18 å Synapseï¼ä¸é²è¡çå»£æ³å¯¦é©è©ä¼°è­æäºæåçæ¹æ³èç¶åæåé²æ¹æ³ç¸æ¯å·æåè¶çæè½ãæåçç¨å¼ç¢¼å¯ä»¥å¨ https://github.com/zymissy/CCViM æ¾å°ã

##### **PSYCHE: A Multi-faceted Patient Simulation Framework for Evaluation of Psychiatric Assessment Conversational Agents**
2501.01594v1 by Jingoo Lee, Kyungho Lim, Young-Chul Jung, Byung-Hoon Kim

Recent advances in large language models (LLMs) have accelerated the
development of conversational agents capable of generating human-like
responses. Since psychiatric assessments typically involve complex
conversational interactions between psychiatrists and patients, there is
growing interest in developing LLM-based psychiatric assessment conversational
agents (PACAs) that aim to simulate the role of psychiatrists in clinical
evaluations. However, standardized methods for benchmarking the clinical
appropriateness of PACAs' interaction with patients still remain underexplored.
Here, we propose PSYCHE, a novel framework designed to enable the 1) clinically
relevant, 2) ethically safe, 3) cost-efficient, and 4) quantitative evaluation
of PACAs. This is achieved by simulating psychiatric patients based on a
multi-faceted psychiatric construct that defines the simulated patients'
profiles, histories, and behaviors, which PACAs are expected to assess. We
validate the effectiveness of PSYCHE through a study with 10 board-certified
psychiatrists, supported by an in-depth analysis of the simulated patient
utterances.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) çææ°é²å±å éäºæè©±ä»£ççéç¼ï¼éäºä»£çè½å¤ ç¢çé¡ä¼¼äººé¡çåæãç±æ¼ç²¾ç¥ç§è©ä¼°éå¸¸æ¶åç²¾ç¥ç§é«å¸«åæ£èä¹éè¤éçæè©±äºåï¼å æ­¤å°æ¼éç¼åºæ¼ LLM çç²¾ç¥ç§è©ä¼°æè©±ä»£ç (PACA) çèè¶£èæ¥ä¿±å¢ï¼éäºä»£çæ¨å¨æ¨¡æ¬ç²¾ç¥ç§é«å¸«å¨è¨åºè©ä¼°ä¸­çè§è²ãç¶èï¼ç¨æ¼è©é PACA èæ£èäºåçè¨åºé©ç¶æ§çæ¨æºåæ¹æ³ä»æªè¢«ååæ¢è¨ãå¨æ­¤ï¼æåæåº PSYCHEï¼ä¸åæ°ç©çæ¡æ¶ï¼æ¨å¨å¯¦ç¾ 1) è¨åºç¸éã2) éå¾·å®å¨ã3) ææ¬æçï¼ä»¥å 4) PACA çå®éè©ä¼°ãéæ¯ééæ¨¡æ¬åºæ¼å¤é¢åç²¾ç¥ç§å»ºæ§çç²¾ç¥ç§æ£èä¾å¯¦ç¾çï¼è©²å»ºæ§å®ç¾©äºæ¨¡æ¬æ£èçåäººè³æãçå²åè¡çºï¼è PACA é è¨æè©ä¼°éäºå§å®¹ãæåééä¸é æ 10 ä½ç¶èªè­çç²¾ç¥ç§é«å¸«åèçç ç©¶é©è­äº PSYCHE çæææ§ï¼ä¸¦è¼ä»¥å°æ¨¡æ¬æ£èè©±èªçæ·±å¥åæã

##### **Model Checking in Medical Imaging for Tumor Detection and Segmentation**
2501.02024v2 by Elhoucine Elfatimi, Lahcen El fatimi

Recent advancements in model checking have demonstrated significant potential
across diverse applications, particularly in signal and image analysis. Medical
imaging stands out as a critical domain where model checking can be effectively
applied to design and evaluate robust frameworks. These frameworks facilitate
automatic and semi-automatic delineation of regions of interest within images,
aiding in accurate segmentation. This paper provides a comprehensive analysis
of recent works leveraging spatial logic to develop operators and tools for
identifying regions of interest, including tumorous and non-tumorous areas.
Additionally, we examine the challenges inherent to spatial model-checking
techniques, such as variability in ground truth data and the need for
streamlined procedures suitable for routine clinical practice.

æè¦ï¼è¿ä¾æ¨¡åæª¢å®çé²å±é¡¯ç¤ºåºå¨åç¨®æç¨ä¸­å·æé¡¯èçæ½åï¼ç¹å¥æ¯å¨è¨èåå½±ååæä¸­ãé«çæåä½çºä¸åééµé åï¼æ¨¡åæª¢å®å¯ä»¥ææå°æç¨æ¼è¨­è¨åè©ä¼°ç©©å¥çæ¶æ§ãéäºæ¶æ§æå©æ¼èªåååèªåå°æç¹ªå½±åä¸­çæèè¶£ååï¼æå©æ¼æºç¢ºçåå²ãæ¬æå°è¿ä¾å©ç¨ç©ºééè¼¯éç¼éç®å­åå·¥å·ä»¥è­å¥æèè¶£ååï¼åæ¬è«ç¤åéè«ç¤ååï¼çç¸éç ç©¶é²è¡äºå¨é¢çåæãæ­¤å¤ï¼æåæ¢è¨äºç©ºéæ¨¡åæª¢å®æè¡åºæçææ°ï¼ä¾å¦åºæ¬äºå¯¦è³æçå¯è®æ§ä»¥åå°é©åå¸¸è¦è¨åºå¯¦åçç°¡åç¨åºçéæ±ã

##### **Training Medical Large Vision-Language Models with Abnormal-Aware Feedback**
2501.01377v1 by Yucheng Zhou, Lingran Song, Jianbing Shen

Existing Medical Large Vision-Language Models (Med-LVLMs), which encapsulate
extensive medical knowledge, demonstrate excellent capabilities in
understanding medical images and responding to human queries based on these
images. However, there remain challenges in visual localization in medical
images, which is crucial for abnormality detection and interpretation. To
address these issues, we propose a novel UMed-LVLM designed with Unveiling
Medical abnormalities. Specifically, we collect a Medical Abnormalities
Unveiling (MAU) dataset and propose a two-stage training method for UMed-LVLM
training. To collect MAU dataset, we propose a prompt method utilizing the
GPT-4V to generate diagnoses based on identified abnormal areas in medical
images. Moreover, the two-stage training method includes Abnormal-Aware
Instruction Tuning and Abnormal-Aware Rewarding, comprising Abnormal
Localization Rewarding and Vision Relevance Rewarding. Experimental results
demonstrate that our UMed-LVLM surpasses existing Med-LVLMs in identifying and
understanding medical abnormality. In addition, this work shows that enhancing
the abnormality detection capabilities of Med-LVLMs significantly improves
their understanding of medical images and generalization capability.

æè¦ï¼ç¾æçé«çå¤§åè¦è¦ºèªè¨æ¨¡å (Med-LVLMs) å°è£äºå»£æ³çé«çç¥è­ï¼å¨çè§£é«çå½±ååæ ¹æéäºå½±ååæäººé¡æ¥è©¢æ¹é¢è¡¨ç¾åºè²çè½åãç¶èï¼å¨é«çå½±åä¸­é²è¡è¦è¦ºå®ä½ä»å­å¨ææ°ï¼éå°æ¼ç°å¸¸åµæ¸¬åè§£è®è³ééè¦ãçºäºè§£æ±ºéäºåé¡ï¼æåæåºäºä¸ç¨®æ°ç©ç UMed-LVLMï¼å¶è¨­è¨ç¨æ¼æ­ç¤ºé«çç°å¸¸ãå·é«ä¾èªªï¼æåæ¶éäºä¸åé«çç°å¸¸æ­ç¤º (MAU) è³æéï¼ä¸¦çº UMed-LVLM è¨ç·´æåºäºä¸åå©éæ®µè¨ç·´æ¹æ³ãçºäºæ¶é MAU è³æéï¼æåæåºäºä¸ç¨®æç¤ºæ¹æ³ï¼å©ç¨ GPT-4V æ ¹æé«çå½±åä¸­è­å¥åºçç°å¸¸ååçæè¨ºæ·ãæ­¤å¤ï¼å©éæ®µè¨ç·´æ¹æ³åæ¬ç°å¸¸æç¥æå°èª¿æ´åç°å¸¸æç¥çåµï¼åæ¬ç°å¸¸å®ä½çåµåè¦è¦ºç¸éæ§çåµãå¯¦é©çµæè¡¨æï¼æåç UMed-LVLM å¨è­å¥åçè§£é«çç°å¸¸æ¹é¢åªæ¼ç¾æç Med-LVLMsãæ­¤å¤ï¼éé å·¥ä½è¡¨æï¼å¢å¼· Med-LVLMs çç°å¸¸åµæ¸¬è½åå¯ä»¥é¡¯èæåå®åå°é«çå½±åççè§£åæ³åè½åã

##### **ScarNet: A Novel Foundation Model for Automated Myocardial Scar Quantification from LGE in Cardiac MRI**
2501.01372v1 by Neda Tavakoli, Amir Ali Rahsepar, Brandon C. Benefield, Daming Shen, Santiago LÃ³pez-Tapia, Florian Schiffers, Jeffrey J. Goldberger, Christine M. Albert, Edwin Wu, Aggelos K. Katsaggelos, Daniel C. Lee, Daniel Kim

Background: Late Gadolinium Enhancement (LGE) imaging is the gold standard
for assessing myocardial fibrosis and scarring, with left ventricular (LV) LGE
extent predicting major adverse cardiac events (MACE). Despite its importance,
routine LGE-based LV scar quantification is hindered by labor-intensive manual
segmentation and inter-observer variability. Methods: We propose ScarNet, a
hybrid model combining a transformer-based encoder from the Medical Segment
Anything Model (MedSAM) with a convolution-based U-Net decoder, enhanced by
tailored attention blocks. ScarNet was trained on 552 ischemic cardiomyopathy
patients with expert segmentations of myocardial and scar boundaries and tested
on 184 separate patients. Results: ScarNet achieved robust scar segmentation in
184 test patients, yielding a median Dice score of 0.912 (IQR: 0.863--0.944),
significantly outperforming MedSAM (median Dice = 0.046, IQR: 0.043--0.047) and
nnU-Net (median Dice = 0.638, IQR: 0.604--0.661). ScarNet demonstrated lower
bias (-0.63%) and coefficient of variation (4.3%) compared to MedSAM (bias:
-13.31%, CoV: 130.3%) and nnU-Net (bias: -2.46%, CoV: 20.3%). In Monte Carlo
simulations with noise perturbations, ScarNet achieved significantly higher
scar Dice (0.892 \pm 0.053, CoV = 5.9%) than MedSAM (0.048 \pm 0.112, CoV =
233.3%) and nnU-Net (0.615 \pm 0.537, CoV = 28.7%). Conclusion: ScarNet
outperformed MedSAM and nnU-Net in accurately segmenting myocardial and scar
boundaries in LGE images. The model exhibited robust performance across diverse
image qualities and scar patterns.

æè¦ï¼<paragraph>èæ¯ï¼å»¶è¿éå¢å¼ºï¼LGEï¼æåç¨äºè¯ä¼°å¿èçº¤ç»´ååç¢ççé»éæ åï¼å·¦å¿å®¤ (LV) LGE èå´é¢æµéå¤§çå¿èä¸è¯äºä»¶ (MACE)ãå°½ç®¡å¶éè¦æ§ï¼ä½åºäº LGE çå¸¸è§ LV ç¢çéååå°å³å¨å¯éåæå¨åå²åè§å¯èé´å·®å¼çé»ç¢ãæ¹æ³ï¼æä»¬æåº ScarNetï¼ä¸ç§æ··åæ¨¡åï¼å®å°æ¥èªå»å­¦åå²ä»»ä½æ¨¡å (MedSAM) çåºäº Transformer çç¼ç å¨ä¸åºäºå·ç§¯ç U-Net è§£ç å¨ç¸ç»åï¼å¹¶éè¿å®å¶çæ³¨æååè¿è¡å¢å¼ºãScarNet å¨ 552 ä¾ç¼ºè¡æ§å¿èçæ£èä¸æ¥åè®­ç»ï¼è¿äºæ£èçå¿èåç¢çè¾¹çç±ä¸å®¶åå²ï¼å¹¶å¨ 184 ä¾åç¬æ£èä¸è¿è¡æµè¯ãç»æï¼ScarNet å¨ 184 ä¾æµè¯æ£èä¸­å®ç°äºç¨³å¥çç¢çåå²ï¼äº§ç 0.912 çä¸­å¼ Dice å¾åï¼IQRï¼0.863--0.944ï¼ï¼ææ¾ä¼äº MedSAMï¼ä¸­å¼ Dice = 0.046ï¼IQRï¼0.043--0.047ï¼å nnU-Netï¼ä¸­å¼ Dice = 0.638ï¼IQRï¼0.604--0.661ï¼ãä¸ MedSAMï¼åå·®ï¼-13.31%ï¼CoVï¼130.3%ï¼å nnU-Netï¼åå·®ï¼-2.46%ï¼CoVï¼20.3%ï¼ç¸æ¯ï¼ScarNet è¡¨ç°åºè¾ä½çåå·®ï¼-0.63%ï¼ååå¼ç³»æ°ï¼4.3%ï¼ãå¨å¸¦æåªå£°æ°å¨çèç¹å¡ç½æ¨¡æä¸­ï¼ScarNet å®ç°äºææ¾é«äº MedSAMï¼0.048 Â± 0.112ï¼CoV = 233.3%ï¼å nnU-Netï¼0.615 Â± 0.537ï¼CoV = 28.7%ï¼çç¢ç Diceï¼0.892 Â± 0.053ï¼CoV = 5.9%ï¼ãç»è®ºï¼ScarNet å¨åç¡®åå² LGE å¾åä¸­çå¿èåç¢çè¾¹çæ¹é¢ä¼äº MedSAM å nnU-Netãè¯¥æ¨¡åå¨ä¸åçå¾åè´¨éåç¢çæ¨¡å¼ä¸è¡¨ç°åºç¨³å¥çæ§è½ã</paragraph>

##### **Contrastive Learning from Exploratory Actions: Leveraging Natural Interactions for Preference Elicitation**
2501.01367v1 by Nathaniel Dennler, Stefanos Nikolaidis, Maja MatariÄ

People have a variety of preferences for how robots behave. To understand and
reason about these preferences, robots aim to learn a reward function that
describes how aligned robot behaviors are with a user's preferences. Good
representations of a robot's behavior can significantly reduce the time and
effort required for a user to teach the robot their preferences. Specifying
these representations -- what "features" of the robot's behavior matter to
users -- remains a difficult problem; Features learned from raw data lack
semantic meaning and features learned from user data require users to engage in
tedious labeling processes. Our key insight is that users tasked with
customizing a robot are intrinsically motivated to produce labels through
exploratory search; they explore behaviors that they find interesting and
ignore behaviors that are irrelevant. To harness this novel data source of
exploratory actions, we propose contrastive learning from exploratory actions
(CLEA) to learn trajectory features that are aligned with features that users
care about. We learned CLEA features from exploratory actions users performed
in an open-ended signal design activity (N=25) with a Kuri robot, and evaluated
CLEA features through a second user study with a different set of users (N=42).
CLEA features outperformed self-supervised features when eliciting user
preferences over four metrics: completeness, simplicity, minimality, and
explainability.

æè¦ï¼äººåå°æ¼æ©å¨äººçè¡çºæ¹å¼æåç¨®åå¥½ãçºäºçè§£åæ¨è«éäºåå¥½ï¼æ©å¨äººæ¨å¨å­¸ç¿ä¸åçåµå½æ¸ï¼èªªææ©å¨äººçè¡çºèä½¿ç¨èçåå¥½æå¤éº¼ä¸è´ãè¯å¥½çæ©å¨äººè¡çºè¡¨ç¤ºå¯ä»¥å¤§å¹æ¸å°ä½¿ç¨èæå°æ©å¨äººå¶åå¥½æéçæéåç²¾åãèªªæéäºè¡¨ç¤ºââæ©å¨äººè¡çºçåªäºãç¹å¾µãå°ä½¿ç¨èä¾èªªå¾éè¦ââä»ç¶æ¯ä¸åå°é£çåé¡ï¼å¾åå§è³æå­¸ç¿å°çç¹å¾µç¼ºä¹èªææç¾©ï¼èå¾ä½¿ç¨èè³æå­¸ç¿å°çç¹å¾µéè¦ä½¿ç¨èåèç¹ç£çæ¨ç±¤èçç¨åºãæåçééµè¦è§£æ¯ï¼è² è²¬èªè¨æ©å¨äººçä½¿ç¨èæ¬è³ªä¸æééæ¢ç´¢æ§æå°ç¢çæ¨ç±¤ï¼ä»åææ¢ç´¢ä»åè¦ºå¾æè¶£çè¡çºï¼ä¸¦å¿½ç¥ä¸ç¸éçè¡çºãçºäºå©ç¨éåæ¢ç´¢æ§åä½çæ°ç©è³æä¾æºï¼æåæåºå¾æ¢ç´¢æ§åä½ä¸­é²è¡å°æ¯å­¸ç¿ (CLEA)ï¼ä»¥å­¸ç¿èä½¿ç¨èéå¿çç¹å¾µä¸è´çè»è·¡ç¹å¾µãæåå¾ä½¿ç¨èå¨è Kuri æ©å¨äººçéæ¾å¼è¨èè¨­è¨æ´»å (N=25) ä¸­å·è¡çæ¢ç´¢æ§åä½ä¸­å­¸ç¿äº CLEA ç¹å¾µï¼ä¸¦ééç¬¬äºåä½¿ç¨èç ç©¶å° CLEA ç¹å¾µé²è¡è©ä¼°ï¼è©²ç ç©¶ä½¿ç¨äºä¸çµä¸åçä½¿ç¨è (N=42)ãå¨å¼åºä½¿ç¨èåå¥½æï¼CLEA ç¹å¾µå¨ååææ¨ä¸åªæ¼èªç£ç£ç¹å¾µï¼å®æ´æ§ãç°¡æ½æ§ãæå°æ§ãå¯è§£éæ§ã

##### **Multi-Head Explainer: A General Framework to Improve Explainability in CNNs and Transformers**
2501.01311v1 by Bohang Sun, Pietro LiÃ²

In this study, we introduce the Multi-Head Explainer (MHEX), a versatile and
modular framework that enhances both the explainability and accuracy of
Convolutional Neural Networks (CNNs) and Transformer-based models. MHEX
consists of three core components: an Attention Gate that dynamically
highlights task-relevant features, Deep Supervision that guides early layers to
capture fine-grained details pertinent to the target class, and an Equivalent
Matrix that unifies refined local and global representations to generate
comprehensive saliency maps. Our approach demonstrates superior compatibility,
enabling effortless integration into existing residual networks like ResNet and
Transformer architectures such as BERT with minimal modifications. Extensive
experiments on benchmark datasets in medical imaging and text classification
show that MHEX not only improves classification accuracy but also produces
highly interpretable and detailed saliency scores.

æè¦ï¼å¨éé ç ç©¶ä¸­ï¼æåå¼å¥äºå¤é ­è§£éå¨ (MHEX)ï¼ä¸åå¤åè½ä¸æ¨¡çµåçæ¶æ§ï¼ç¨æ¼å¢å¼·å·ç©ç¥ç¶ç¶²è·¯ (CNN) å Transformer çºåºç¤çæ¨¡åçå¯è§£éæ§åæºç¢ºæ§ãMHEX åå«ä¸åæ ¸å¿åä»¶ï¼ä¸ååæçªé¡¯èä»»åç¸éç¹å¾µçæ³¨æåééãå¼å°æ©æå±¤ææèç®æ¨é¡å¥ç¸éçç´°ç·»ç´°ç¯çæ·±åº¦ç£ç£ï¼ä»¥åä¸åçµ±ä¸ç²¾ç·»çå±é¨åå¨å±è¡¨ç¤ºä»¥ç¢çå¨é¢çé¡¯èæ§åçç­æç©é£ãæåçåæ³å±ç¾åºåªç°çç¸å®¹æ§ï¼è® ResNet ç­ç¾æçæ®å·®ç¶²è·¯å BERT ç­ Transformer æ¶æ§è½å¤ è¼é¬æ´åï¼èä¸ä¿®æ¹å¹åº¦æ¥µå°ãå¨é«å­¸å½±ååæå­åé¡çåºæºè³æéä¸é²è¡çå»£æ³å¯¦é©é¡¯ç¤ºï¼MHEX ä¸åè½æååé¡æºç¢ºæ§ï¼éè½ç¢çé«åº¦å¯è§£éä¸è©³ç´°çé¡¯èæ§åæ¸ã

##### **Machine Learning-Based Differential Diagnosis of Parkinson's Disease Using Kinematic Feature Extraction and Selection**
2501.02014v1 by Masahiro Matsumoto, Abu Saleh Musa Miah, Nobuyoshi Asai, Jungpil Shin

Parkinson's disease (PD), the second most common neurodegenerative disorder,
is characterized by dopaminergic neuron loss and the accumulation of abnormal
synuclein. PD presents both motor and non-motor symptoms that progressively
impair daily functioning. The severity of these symptoms is typically assessed
using the MDS-UPDRS rating scale, which is subjective and dependent on the
physician's experience. Additionally, PD shares symptoms with other
neurodegenerative diseases, such as progressive supranuclear palsy (PSP) and
multiple system atrophy (MSA), complicating accurate diagnosis. To address
these diagnostic challenges, we propose a machine learning-based system for
differential diagnosis of PD, PSP, MSA, and healthy controls (HC). This system
utilizes a kinematic feature-based hierarchical feature extraction and
selection approach. Initially, 18 kinematic features are extracted, including
two newly proposed features: Thumb-to-index vector velocity and acceleration,
which provide insights into motor control patterns. In addition, 41 statistical
features were extracted here from each kinematic feature, including some new
approaches such as Average Absolute Change, Rhythm, Amplitude, Frequency,
Standard Deviation of Frequency, and Slope. Feature selection is performed
using One-way ANOVA to rank features, followed by Sequential Forward Floating
Selection (SFFS) to identify the most relevant ones, aiming to reduce the
computational complexity. The final feature set is used for classification,
achieving a classification accuracy of 66.67% for each dataset and 88.89% for
each patient, with particularly high performance for the MSA and HC groups
using the SVM algorithm. This system shows potential as a rapid and accurate
diagnostic tool in clinical practice, though further data collection and
refinement are needed to enhance its reliability.

æè¦ï¼å¸éæ£®æ°çï¼PDï¼æ¯ç¬¬äºå¸¸è§çèç¥ç»éåæ§ç¾çï¼
å¶ç¹å¾æ¯å¤å·´èºè½ç¥ç»åä¸§å¤±åå¼å¸¸Î±-çªè§¦æ ¸èç½çç§¯ç´¯ãPD åæ¶åºç°è¿å¨åéè¿å¨çç¶ï¼è¿äºçç¶ä¼éæ¸æå®³æ¥å¸¸åè½ãè¿äºçç¶çä¸¥éç¨åº¦éå¸¸ä½¿ç¨ MDS-UPDRS è¯å®éè¡¨è¿è¡è¯ä¼°ï¼è¯¥éè¡¨æ¯ä¸»è§çï¼å¹¶ä¸ä¾èµäºå»ççç»éªãæ­¤å¤ï¼PD ä¸å¶ä»ç¥ç»éåæ§ç¾çï¼ä¾å¦è¿è¡æ§æ ¸ä¸æ§éº»ç¹ (PSP) åå¤ç³»ç»èç¼© (MSA)ï¼æç¸åççç¶ï¼è¿ä½¿å¾åç¡®è¯æ­åå¾å¤æãä¸ºäºåºå¯¹è¿äºè¯æ­ææï¼æä»¬æåºäºä¸ç§åºäºæºå¨å­¦ä¹ çç³»ç»ï¼ç¨äº PDãPSPãMSA åå¥åº·å¯¹ç§ (HC) çé´å«è¯æ­ãè¯¥ç³»ç»å©ç¨åºäºè¿å¨å­¦ç¹å¾çåå±ç¹å¾æååéæ©æ¹æ³ãæåï¼æåäº 18 ä¸ªè¿å¨å­¦ç¹å¾ï¼åæ¬ä¸¤ä¸ªæ°æåºçç¹å¾ï¼ææå°é£æçç¢ééåº¦åå éåº¦ï¼å®ä»¬æä¾äºå¯¹è¿å¨æ§å¶æ¨¡å¼çè§è§£ãæ­¤å¤ï¼æ­¤å¤ä»æ¯ä¸ªè¿å¨å­¦ç¹å¾ä¸­æåäº 41 ä¸ªç»è®¡ç¹å¾ï¼åæ¬ä¸äºæ°æ¹æ³ï¼ä¾å¦å¹³åç»å¯¹ååãèå¥ãæ¯å¹ãé¢çãé¢çæ åå·®åæçãä½¿ç¨ååæ¹å·®åæå¯¹ç¹å¾è¿è¡æåï¼ç¶åä½¿ç¨é¡ºåºååæµ®å¨éæ© (SFFS) è¯å«æç¸å³çç¹å¾ï¼ä»¥éä½è®¡ç®å¤æåº¦ãæç»ç¹å¾éç¨äºåç±»ï¼å¯¹äºæ¯ä¸ªæ°æ®éï¼åç±»åç¡®çè¾¾å° 66.67%ï¼å¯¹äºæ¯ä¸ªæ£èï¼åç¡®çè¾¾å° 88.89%ï¼ä½¿ç¨ SVM ç®æ³æ¶ï¼MSA å HC ç»çæ§è½å°¤å¶é«ãè¯¥ç³»ç»æ¾ç¤ºåºä½ä¸ºä¸´åºå®è·µä¸­å¿«éä¸åç¡®çè¯æ­å·¥å·çæ½åï¼å°½ç®¡éè¦è¿ä¸æ­¥æ¶éæ°æ®åæ¹è¿ä»¥å¢å¼ºå¶å¯é æ§ã

##### **Data Augmentation Techniques for Chinese Disease Name Normalization**
2501.01195v1 by Wenqian Cui, Xiangling Fu, Shaohui Liu, Mingjun Gu, Xien Liu, Ji Wu, Irwin King

Disease name normalization is an important task in the medical domain. It
classifies disease names written in various formats into standardized names,
serving as a fundamental component in smart healthcare systems for various
disease-related functions. Nevertheless, the most significant obstacle to
existing disease name normalization systems is the severe shortage of training
data. Consequently, we present a novel data augmentation approach that includes
a series of data augmentation techniques and some supporting modules to help
mitigate the problem. Through extensive experimentation, we illustrate that our
proposed approach exhibits significant performance improvements across various
baseline models and training objectives, particularly in scenarios with limited
training data

æè¦ï¼ç¾çåç¨±æ­£è¦åæ¯é«å­¸é åä¸­ä¸é éè¦çä»»åãå®å°ä»¥åç¨®æ ¼å¼æ¸å¯«çç¾çåç¨±åé¡çºæ¨æºååç¨±ï¼ä½çºæºæ§é«çç³»çµ±ä¸­åç¨®ç¾çç¸éåè½çåºæ¬çµæé¨åãç¶èï¼ç¾æç¾çåç¨±æ­£è¦åç³»çµ±æé¡¯èçéç¤æ¯è¨ç·´è³æå´éç­ç¼ºãå æ­¤ï¼æåæåºäºä¸ç¨®æ°ç©çè³ææ´åæ¹æ³ï¼å¶ä¸­åæ¬ä¸ç³»åè³ææ´åæè¡åä¸äºè¼å©æ¨¡çµï¼ä»¥å¹«å©æ¸è¼éååé¡ãééå»£æ³çå¯¦é©ï¼æåèªªææåæåºçæ¹æ³å¨åç¨®åºç·æ¨¡ååè¨ç·´ç®æ¨ä¸­å±ç¾åºé¡¯èçæè½æåï¼ç¹å¥æ¯å¨è¨ç·´è³ææéçææ³ä¸

##### **Reasoning based on symbolic and parametric knowledge bases: a survey**
2501.01030v1 by Mayi Xu, Yunfeng Ning, Yongqi Li, Jianhao Chen, Jintao Wen, Yao Xiao, Shen Zhou, Birong Pan, Zepeng Bao, Xin Miao, Hankun Kang, Ke Sun, Tieyun Qian

Reasoning is fundamental to human intelligence, and critical for
problem-solving, decision-making, and critical thinking. Reasoning refers to
drawing new conclusions based on existing knowledge, which can support various
applications like clinical diagnosis, basic education, and financial analysis.
Though a good number of surveys have been proposed for reviewing
reasoning-related methods, none of them has systematically investigated these
methods from the viewpoint of their dependent knowledge base. Both the
scenarios to which the knowledge bases are applied and their storage formats
are significantly different. Hence, investigating reasoning methods from the
knowledge base perspective helps us better understand the challenges and future
directions. To fill this gap, this paper first classifies the knowledge base
into symbolic and parametric ones. The former explicitly stores information in
human-readable symbols, and the latter implicitly encodes knowledge within
parameters. Then, we provide a comprehensive overview of reasoning methods
using symbolic knowledge bases, parametric knowledge bases, and both of them.
Finally, we identify the future direction toward enhancing reasoning
capabilities to bridge the gap between human and machine intelligence.

æè¦ï¼æ¨çæ¯äººç±»æºè½çåºç¡ï¼å¯¹äºè§£å³é®é¢ãå³ç­åæ¹å¤æ§æç»´è³å³éè¦ãæ¨çæ¯ææ ¹æ®ç°æç¥è¯å¾åºæ°çç»è®ºï¼è¿å¯ä»¥æ¯æåç§åºç¨ç¨åºï¼å¦ä¸´åºè¯æ­ãåºç¡æè²åè´¢å¡åæãå°½ç®¡å·²ç»æåºäºå¤§éè°æ¥æ¥å®¡æ¥ä¸æ¨çç¸å³çåç§æ¹æ³ï¼ä½æ²¡æä¸ç§æ¹æ³ä»å¶ä¾èµç¥è¯åºçè§åº¦ç³»ç»å°ç ç©¶è¿äºæ¹æ³ãç¥è¯åºè¢«åºç¨å°çåºæ¯åå¶å­å¨æ ¼å¼é½ææ¾çå·®å¼ãå æ­¤ï¼ä»ç¥è¯åºçè§åº¦ç ç©¶æ¨çæ¹æ³æå©äºæä»¬æ´å¥½å°çè§£ææåæªæ¥çæ¹åãä¸ºäºå¡«è¡¥è¿ä¸ç©ºç½ï¼æ¬æé¦åå°ç¥è¯åºåä¸ºç¬¦å·ç¥è¯åºååæ°ç¥è¯åºãåèä»¥äººç±»å¯è¯»çç¬¦å·æç¡®å­å¨ä¿¡æ¯ï¼èåèåå¨åæ°ä¸­éå¼ç¼ç ç¥è¯ãç¶åï¼æä»¬å¯¹ä½¿ç¨ç¬¦å·ç¥è¯åºãåæ°ç¥è¯åºä»¥åä¸¤èç»åçæ¨çæ¹æ³è¿è¡äºå¨é¢æ¦è¿°ãæåï¼æä»¬ç¡®å®äºå¢å¼ºæ¨çè½åä»¥ç¼©å°äººåæºå¨æºè½ä¹é´å·®è·çæªæ¥æ¹åã

##### **Are LLMs effective psychological assessors? Leveraging adaptive RAG for interpretable mental health screening through psychometric practice**
2501.00982v1 by Federico Ravenda, Seyed Ali Bahrainian, Andrea Raballo, Antonietta Mira, Noriko Kando

In psychological practice, standardized questionnaires serve as essential
tools for assessing mental constructs (e.g., attitudes, traits, and emotions)
through structured questions (aka items). With the increasing prevalence of
social media platforms where users share personal experiences and emotions,
researchers are exploring computational methods to leverage this data for rapid
mental health screening. In this study, we propose a novel adaptive
Retrieval-Augmented Generation (RAG) approach that completes psychological
questionnaires by analyzing social media posts. Our method retrieves the most
relevant user posts for each question in a psychological survey and uses Large
Language Models (LLMs) to predict questionnaire scores in a zero-shot setting.
Our findings are twofold. First we demonstrate that this approach can
effectively predict users' responses to psychological questionnaires, such as
the Beck Depression Inventory II (BDI-II), achieving performance comparable to
or surpassing state-of-the-art models on Reddit-based benchmark datasets
without relying on training data. Second, we show how this methodology can be
generalized as a scalable screening tool, as the final assessment is
systematically derived by completing standardized questionnaires and tracking
how individual item responses contribute to the diagnosis, aligning with
established psychometric practices.

æè¦ï¼<paragraph>å¨å¿çå­¸å¯¦åä¸­ï¼æ¨æºååå·ä½çºè©éå¿çå»ºæ§ï¼ä¾å¦æåº¦ãç¹è³ªåæç·ï¼çå¿è¦å·¥å·ï¼ééçµæ§ååé¡ï¼åç¨±é ç®ï¼ä¾é²è¡è©éãé¨èç¤¾ç¾¤åªé«å¹³å°çæ®åï¼ä½¿ç¨èæå¨ä¸é¢åäº«åäººç¶é©åæç·ï¼ç ç©¶äººå¡æ­£å¨æ¢è¨éç®æ¹æ³ï¼ä»¥å©ç¨éäºè³æé²è¡å¿«éççå¿çå¥åº·ç¯©æª¢ãå¨éé ç ç©¶ä¸­ï¼æåæåºäºä¸ç¨®åµæ°çé©ææ§æ·åå¢å¼·çæï¼RAGï¼æ¹æ³ï¼ééåæç¤¾ç¾¤åªé«è²¼æä¾å®æå¿çåå·ãæåçåæ³æ¯éå°å¿çèª¿æ¥ä¸­çæ¯ååé¡ï¼æ·åèä¹æç¸éçä½¿ç¨èè²¼æï¼ä¸¦ä½¿ç¨å¤§åèªè¨æ¨¡åï¼LLMï¼å¨é¶æ¬¡å­¸ç¿çè¨­å®ä¸é æ¸¬åå·åæ¸ãæåçç¼ç¾æå©æ¹é¢ãé¦åï¼æåè­æäºéç¨®æ¹æ³å¯ä»¥ææé æ¸¬ä½¿ç¨èå°å¿çåå·çåç­ï¼ä¾å¦è²åæé¬±éè¡¨ç¬¬äºçï¼BDI-IIï¼ï¼å¨åºæ¼ Reddit çåºæºè³æéä¸éå°äºèæåé²æ¨¡åç¸ç¶æè¶è¶çè¡¨ç¾ï¼èä¸ä¸¦æªä¾è³´è¨ç·´è³æãå¶æ¬¡ï¼æåå±ç¤ºäºéåæ¹æ³å¦ä½è½è¢«æ¦æ¬çºä¸ç¨®å¯æ´åçç¯©æª¢å·¥å·ï¼å çºæçµè©éæ¯ééå®ææ¨æºååå·ä¸¦è¿½è¹¤åå¥é ç®åç­å¦ä½ä¿æè¨ºæ·èç³»çµ±æ§å°å¾åºçï¼éèæ¢å®çå¿çæ¸¬éå¯¦åç¸ç¬¦ã</paragraph>

##### **Enhancing Early Diabetic Retinopathy Detection through Synthetic DR1 Image Generation: A StyleGAN3 Approach**
2501.00954v1 by Sagarnil Das, Pradeep Walia

Diabetic Retinopathy (DR) is a leading cause of preventable blindness. Early
detection at the DR1 stage is critical but is hindered by a scarcity of
high-quality fundus images. This study uses StyleGAN3 to generate synthetic DR1
images characterized by microaneurysms with high fidelity and diversity. The
aim is to address data scarcity and enhance the performance of supervised
classifiers. A dataset of 2,602 DR1 images was used to train the model,
followed by a comprehensive evaluation using quantitative metrics, including
Frechet Inception Distance (FID), Kernel Inception Distance (KID), and
Equivariance with respect to translation (EQ-T) and rotation (EQ-R).
Qualitative assessments included Human Turing tests, where trained
ophthalmologists evaluated the realism of synthetic images. Spectral analysis
further validated image quality. The model achieved a final FID score of 17.29,
outperforming the mean FID of 21.18 (95 percent confidence interval - 20.83 to
21.56) derived from bootstrap resampling. Human Turing tests demonstrated the
model's ability to produce highly realistic images, though minor artifacts near
the borders were noted. These findings suggest that StyleGAN3-generated
synthetic DR1 images hold significant promise for augmenting training datasets,
enabling more accurate early detection of Diabetic Retinopathy. This
methodology highlights the potential of synthetic data in advancing medical
imaging and AI-driven diagnostics.

æè¦ï¼ç³å°¿çè¦ç¶²èçè® (DR) æ¯å¯é é²å¤±æçä¸»è¦åå ãå¨ DR1 éæ®µæ©æç¼ç¾è³ééè¦ï¼ä½ç±æ¼ç¼ºä¹é«åè³ªç¼åºååèåå°é»ç¤ãæ¬ç ç©¶ä½¿ç¨ StyleGAN3 çæåæ DR1 ååï¼å¶ç¹å¾µæ¯å·æé«ä¿çåº¦åå¤æ¨£æ§çå¾®åèç¤ãç®çæ¯è§£æ±ºè³æç¨å°çåé¡ï¼ä¸¦æåç£ç£åé¡å¨çæè½ãä½¿ç¨ 2,602 å¼µ DR1 ååçè³æéä¾è¨ç·´æ¨¡åï¼ç¶å¾ä½¿ç¨éåææ¨é²è¡å¨é¢è©ä¼°ï¼åæ¬ FrÃ©chet Inception Distance (FID)ãKernel Inception Distance (KID) ä»¥åç¸å°æ¼å¹³ç§» (EQ-T) åæè½ (EQ-R) çç­è®ç°æ§ãå®æ§è©ä¼°åæ¬äººé¡åéæ¸¬è©¦ï¼å¶ä¸­è¨ç·´æç´ çç¼ç§é«çè©ä¼°åæååççå¯¦æ§ãåè­åæé²ä¸æ­¥é©è­äºå½±ååè³ªãè©²æ¨¡åéå°äº 17.29 çæçµ FID åæ¸ï¼åªæ¼å¾ bootstrap éæ½æ¨£å¾åºç 21.18 çå¹³å FIDï¼95% ä¿¡è³´åé - 20.83 å° 21.56ï¼ãäººé¡åéæ¸¬è©¦è­æäºè©²æ¨¡åç¢çé«åº¦é¼çååçè½åï¼åç®¡æ³¨æå°éç·£éè¿æè¼å¾®çäººå·¥è£½åãéäºç¼ç¾è¡¨æï¼StyleGAN3 çæçåæ DR1 ååå°æ¼æ´åè¨ç·´è³æéå·æé¡¯èçå¸æï¼è½å¤ æ´æºç¢ºå°æ©æç¼ç¾ç³å°¿çè¦ç¶²èçè®ãéç¨®æ¹æ³çªé¡¯äºåæè³æå¨æ¨é²é«å­¸å½±åå AI é©åè¨ºæ·æ¹é¢çæ½åã

##### **Multi-Center Study on Deep Learning-Assisted Detection and Classification of Fetal Central Nervous System Anomalies Using Ultrasound Imaging**
2501.02000v1 by Yang Qi, Jiaxin Cai, Jing Lu, Runqing Xiong, Rongshang Chen, Liping Zheng, Duo Ma

Prenatal ultrasound evaluates fetal growth and detects congenital
abnormalities during pregnancy, but the examination of ultrasound images by
radiologists requires expertise and sophisticated equipment, which would
otherwise fail to improve the rate of identifying specific types of fetal
central nervous system (CNS) abnormalities and result in unnecessary patient
examinations. We construct a deep learning model to improve the overall
accuracy of the diagnosis of fetal cranial anomalies to aid prenatal diagnosis.
In our collected multi-center dataset of fetal craniocerebral anomalies
covering four typical anomalies of the fetal central nervous system (CNS):
anencephaly, encephalocele (including meningocele), holoprosencephaly, and
rachischisis, patient-level prediction accuracy reaches 94.5%, with an AUROC
value of 99.3%. In the subgroup analyzes, our model is applicable to the entire
gestational period, with good identification of fetal anomaly types for any
gestational period. Heatmaps superimposed on the ultrasound images not only
provide a visual interpretation for the algorithm but also provide an intuitive
visual aid to the physician by highlighting key areas that need to be reviewed,
helping the physician to quickly identify and validate key areas. Finally, the
retrospective reader study demonstrates that by combining the automatic
prediction of the DL system with the professional judgment of the radiologist,
the diagnostic accuracy and efficiency can be effectively improved and the
misdiagnosis rate can be reduced, which has an important clinical application
prospect.

æè¦ï¼ç¢åè¶é³æ³¢è©ä¼°èåçé·ä¸¦å¨æ·å­æéåµæ¸¬åå¤©ç°å¸¸ï¼ä½è¶é³æ³¢å½±åçæª¢æ¥éè¦æ¾å°ç§é«å¸«çå°æ¥­ç¥è­åç²¾å¯åå¨ï¼å¦åç¡æ³æ¹åç¹å®é¡åèåä¸­æ¨ç¥ç¶ç³»çµ± (CNS) ç°å¸¸çè¾¨è­çï¼ä¸¦å°è´ä¸å¿è¦ççäººæª¢æ¥ãæåå»ºæ§ä¸åæ·±åº¦å­¸ç¿æ¨¡åï¼ä»¥æ¹åèåé¡±éª¨ç°å¸¸è¨ºæ·çæ´é«æºç¢ºåº¦ï¼ä»¥åå©ç¢åè¨ºæ·ãå¨æåæ¶éçå¤ä¸­å¿èåé¡±è¦ç°å¸¸è³æéä¸­ï¼æ¶µèèåä¸­æ¨ç¥ç¶ç³»çµ± (CNS) çåç¨®å¸åç°å¸¸ï¼ç¡è¦çãè¦è¨åºï¼åæ¬è¦èè¨åºï¼ãå¨åè¦çåèè£ï¼çäººå±¤ç´çé æ¸¬æºç¢ºåº¦éå° 94.5%ï¼AUROC å¼çº 99.3%ãå¨å­ç¾¤åæä¸­ï¼æåçæ¨¡åé©ç¨æ¼æ´åå¦å¨ æï¼ä¸è½è¯å¥½è¾¨è­ä»»ä½å¦å¨ æçèåç°å¸¸é¡åãçå å¨è¶é³æ³¢å½±åä¸çç±åä¸åæä¾æ¼ç®æ³çè¦è¦ºè©®éï¼ä¹ééçªé¡¯éè¦æª¢è¦çééµååï¼æä¾ç´è¦ºçè¦è¦ºè¼å©å·¥å·çµ¦é«å¸«ï¼åå©é«å¸«å¿«éè¾¨è­åé©è­ééµååãæå¾ï¼åæº¯æ§é±è®ç ç©¶é¡¯ç¤ºï¼çµå DL ç³»çµ±çèªåé æ¸¬åæ¾å°ç§é«å¸«çå°æ¥­å¤æ·ï¼å¯ä»¥æææ¹åè¨ºæ·æºç¢ºåº¦åæçï¼ä¸¦éä½èª¤è¨ºçï¼éå·æéè¦çè¨åºæç¨åæ¯ã

##### **Efficient Standardization of Clinical Notes using Large Language Models**
2501.00644v1 by Daniel B. Hier, Michael D. Carrithers, Thanh Son Do, Tayo Obafemi-Ajayi

Clinician notes are a rich source of patient information but often contain
inconsistencies due to varied writing styles, colloquialisms, abbreviations,
medical jargon, grammatical errors, and non-standard formatting. These
inconsistencies hinder the extraction of meaningful data from electronic health
records (EHRs), posing challenges for quality improvement, population health,
precision medicine, decision support, and research.
  We present a large language model approach to standardizing a corpus of 1,618
clinical notes. Standardization corrected an average of $4.9 +/- 1.8$
grammatical errors, $3.3 +/- 5.2$ spelling errors, converted $3.1 +/- 3.0$
non-standard terms to standard terminology, and expanded $15.8 +/- 9.1$
abbreviations and acronyms per note. Additionally, notes were re-organized into
canonical sections with standardized headings. This process prepared notes for
key concept extraction, mapping to medical ontologies, and conversion to
interoperable data formats such as FHIR.
  Expert review of randomly sampled notes found no significant data loss after
standardization. This proof-of-concept study demonstrates that standardization
of clinical notes can improve their readability, consistency, and usability,
while also facilitating their conversion into interoperable data formats.

æè¦ï¼è¨åºé«å¸«çç­è¨æ¯è±å¯ççäººè³è¨ä¾æºï¼ä½å¸¸å¸¸å çºæ¸å¯«é¢¨æ ¼ä¸åãæ£ç¨èªãç¸®å¯«ãé«å­¸è¡èªãææ³é¯èª¤åéæ¨æºæ ¼å¼èåå«ä¸ä¸è´çå°æ¹ãéäºä¸ä¸è´æé»ç¤å¾é»å­å¥åº·ç´é (EHR) ä¸­èåææç¾©çè³æï¼å°åè³ªæ¹åãäººå£å¥åº·ãç²¾æºé«çãæ±ºç­æ¯æ´åç ç©¶æ§æææ°ã
æåæåºäºä¸åå¤§åèªè¨æ¨¡åæ¹æ³ä¾æ¨æºå 1,618 ä»½è¨åºç­è¨çèªæåº«ãæ¨æºåå¹³åæ´æ­£äº $4.9 +/- 1.8$ åææ³é¯èª¤ã$3.3 +/- 5.2$ åæ¼å­é¯èª¤ï¼å° $3.1 +/- 3.0$ åéæ¨æºè¡èªè½æçºæ¨æºè¡èªï¼ä¸¦æ´åäºæ¯ä»½ç­è¨ä¸­ $15.8 +/- 9.1$ åç¸®å¯«åé¦å­æ¯ç¸®ç¥å­ãæ­¤å¤ï¼ç­è¨è¢«éæ°çµç¹æå·ææ¨æºæ¨é¡çæ­£è¦ç« ç¯ãéåéç¨æºåäºç­è¨ï¼ç¨æ¼ééµæ¦å¿µèåãå°æå°é«å­¸æ¬ä½ï¼ä»¥åè½æçºå¯äºæä½çè³ææ ¼å¼ï¼ä¾å¦ FHIRã
å°é¨æ©æ½æ¨£çç­è¨é²è¡å°å®¶å¯©æ¥å¾ç¼ç¾ï¼å¨æ¨æºåå¾æ²æé¡¯èçè³æéºå¤±ãéåæ¦å¿µé©è­ç ç©¶è­æäºè¨åºç­è¨çæ¨æºåå¯ä»¥æ¹åå¶å¯è®æ§ãä¸è´æ§åå¯ç¨æ§ï¼åæä¹ä¿é²å¶è½æçºå¯äºæä½çè³ææ ¼å¼ã

##### **Pan-infection Foundation Framework Enables Multiple Pathogen Prediction**
2501.01462v1 by Lingrui Zhang, Haonan Wu, Nana Jin, Chenqing Zheng, Jize Xie, Qitai Cai, Jun Wang, Qin Cao, Xubin Zheng, Jiankun Wang, Lixin Cheng

Host-response-based diagnostics can improve the accuracy of diagnosing
bacterial and viral infections, thereby reducing inappropriate antibiotic
prescriptions. However, the existing cohorts with limited sample size and
coarse infections types are unable to support the exploration of an accurate
and generalizable diagnostic model. Here, we curate the largest infection
host-response transcriptome data, including 11,247 samples across 89 blood
transcriptome datasets from 13 countries and 21 platforms. We build a
diagnostic model for pathogen prediction starting from a pan-infection model as
foundation (AUC = 0.97) based on the pan-infection dataset. Then, we utilize
knowledge distillation to efficiently transfer the insights from this "teacher"
model to four lightweight pathogen "student" models, i.e., staphylococcal
infection (AUC = 0.99), streptococcal infection (AUC = 0.94), HIV infection
(AUC = 0.93), and RSV infection (AUC = 0.94), as well as a sepsis "student"
model (AUC = 0.99). The proposed knowledge distillation framework not only
facilitates the diagnosis of pathogens using pan-infection data, but also
enables an across-disease study from pan-infection to sepsis. Moreover, the
framework enables high-degree lightweight design of diagnostic models, which is
expected to be adaptively deployed in clinical settings.

æè¦ï¼åºæ¼å®¿ä¸»åæçè¨ºæ·å¯ä»¥æé«ç´°èåçæ¯ææçè¨ºæ·æºç¢ºåº¦ï¼å¾èæ¸å°ä¸é©ç¶çæçç´ èæ¹ãç¶èï¼ç¾ææ¨£æ¬éæéãææé¡åç²ç³çç¾¤çµç¡æ³æ¯ææºç¢ºä¸å¯æ¦åçè¨ºæ·æ¨¡åçæ¢ç´¢ãå¨æ­¤ï¼æåæ´çäºæå¤§çææå®¿ä¸»åæè½éçµæ¸æï¼åæ¬ä¾èª 13 ååå®¶å 21 åå¹³å°ç 89 åè¡æ¶²è½éçµæ¸æéä¸­ç 11,247 åæ¨£æ¬ãæåå¾æ³æææ¨¡åéå§å»ºç«ä¸åç¨æ¼çåé«é æ¸¬çè¨ºæ·æ¨¡åï¼ä½çºåºç¤ (AUC = 0.97)ï¼è©²æ¨¡ååºæ¼æ³æææ¸æéãç¶å¾ï¼æåå©ç¨ç¥è­è¸é¤¾ææå°å°éåãæå¸«ãæ¨¡åä¸­çè¦è§£è½ç§»å°ååè¼éç´çåé«ãå­¸çãæ¨¡åï¼å³è¡èçèææ (AUC = 0.99)ãéçèææ (AUC = 0.94)ãHIV ææ (AUC = 0.93) å RSV ææ (AUC = 0.94)ï¼ä»¥åä¸åæè¡çãå­¸çãæ¨¡å (AUC = 0.99)ãææåºçç¥è­è¸é¤¾æ¡æ¶ä¸åä¿é²äºä½¿ç¨æ³æææ¸æè¨ºæ·çåé«ï¼éå¯¦ç¾äºå¾æ³ææå°æè¡ççè·¨ç¾çç ç©¶ãæ­¤å¤ï¼è©²æ¡æ¶ä½¿è¨ºæ·æ¨¡åè½å¤ é²è¡é«åº¦è¼éç´è¨­è¨ï¼é è¨å°é©ææ§å°é¨ç½²å¨è¨åºç°å¢ä¸­ã

##### **A Hybrid Deep Learning and Model-Checking Framework for Accurate Brain Tumor Detection and Validation**
2501.01991v1 by Lahcen El Fatimi, Elhoucine Elfatimi, Hanifa Bouchaneb

Model checking, a formal verification technique, ensures systems meet
predefined requirements, playing a crucial role in minimizing errors and
enhancing quality during development. This paper introduces a novel hybrid
framework integrating model checking with deep learning for brain tumor
detection and validation in medical imaging. By combining model-checking
principles with CNN-based feature extraction and K-FCM clustering for
segmentation, the proposed approach enhances the reliability of tumor detection
and segmentation. Experimental results highlight the framework's effectiveness,
achieving 98\% accuracy, 96.15\% precision, and 100\% recall, demonstrating its
potential as a robust tool for advanced medical image analysis.

æè¦ï¼æ¨¡åæª¢æ¥æ¯ä¸ç¨®æ­£å¼é©è­æè¡ï¼ç¨æ¼ç¢ºä¿ç³»çµ±ç¬¦åé åå®ç¾©çè¦æ±ï¼å¨éç¼éç¨ä¸­æ®æ¼èæ¥µå¶éè¦çè§è²ï¼ç¨æ¼æå°åé¯èª¤ä¸¦æååè³ªãéç¯è«æä»ç´¹äºä¸åæ´åæ¨¡åæª¢æ¥èæ·±åº¦å­¸ç¿çåµæ°æ··åæ¡æ¶ï¼ç¨æ¼é«å­¸å½±åä¸­çè¦ç¤åµæ¸¬èé©è­ãééçµåæ¨¡åæª¢æ¥ååèåºæ¼ CNN çç¹å¾µèåä»¥åç¨æ¼åå²ç K-FCM èé¡ï¼ææåºçæ¹æ³æåäºè«ç¤åµæ¸¬èåå²çå¯é åº¦ãå¯¦é©çµæçªé¡¯äºéåæ¡æ¶çæææ§ï¼éå°äº 98% çæºç¢ºåº¦ã96.15% çç²¾ç¢ºåº¦ï¼ä»¥å 100% çå¬åçï¼é¡¯ç¤ºåºå¶ä½çºé²éé«å­¸å½±ååæçå¼·å¥å·¥å·çæ½åã

##### **GAN-TAT: A Novel Framework Using Protein Interaction Networks in Druggable Gene Identification**
2501.01458v1 by George Yuanji Wang, Srisharan Murugesan, Aditya Prince Rohatgi

Identifying druggable genes is essential for developing effective
pharmaceuticals. With the availability of extensive, high-quality data,
computational methods have become a significant asset. Protein Interaction
Network (PIN) is valuable but challenging to implement due to its high
dimensionality and sparsity. Previous methods relied on indirect integration,
leading to resolution loss. This study proposes GAN-TAT, a framework utilizing
an advanced graph embedding technology, ImGAGN, to directly integrate PIN for
druggable gene inference work. Tested on three Pharos datasets, GAN-TAT
achieved the highest AUC-ROC score of 0.951 on Tclin. Further evaluation shows
that GAN-TAT's predictions are supported by clinical evidence, highlighting its
potential practical applications in pharmacogenomics. This research represents
a methodological attempt with the direct utilization of PIN, expanding
potential new solutions for developing drug targets. The source code of GAN-TAT
is available at (https://github.com/george-yuanji-wang/GAN-TAT).

æè¦ï¼è­å¥å¯è¥ç©ååºå å°æ¼éç¼ææçè¥ç©è³ééè¦ãé¨èå¤§éé«åè³ªæ¸æçåºç¾ï¼è¨ç®æ¹æ³å·²æçºä¸é éè¦çè³ç¢ãèç½è³ªäº¤äºç¶²çµ¡ (PIN) å¾æå¹å¼ï¼ä½ç±æ¼å¶é«ç¶­åº¦åç¨çæ§ï¼å¯¦ä½èµ·ä¾å·æææ°æ§ãååçè¾¦æ³ä¾è³´æ¼éæ¥æ´åï¼å°è´è§£æåº¦éä½ãæ¬ç ç©¶æåº GAN-TATï¼ä¸åå©ç¨åé²åå½¢åµå¥æè¡ ImGAGN çæ¶æ§ï¼ç´æ¥æ´å PIN ä»¥é²è¡å¯è¥ç©ååºå æ¨è«å·¥ä½ãå¨ä¸å Pharos è³æéä¸é²è¡æ¸¬è©¦ï¼GAN-TAT å¨ Tclin ä¸éå°äºæé«ç AUC-ROC åæ¸ 0.951ãé²ä¸æ­¥çè©ä¼°é¡¯ç¤ºï¼GAN-TAT çé æ¸¬ç²å¾äºè¨åºè­æçæ¯æï¼çªé¡¯äºå¶å¨è¥ç©åºå çµå­¸ä¸­çæ½å¨å¯¦éæç¨ãæ¬ç ç©¶ä»£è¡¨äºä¸ç¨®ç´æ¥å©ç¨ PIN çæ¹æ³è«åè©¦ï¼æ´å±äºéç¼è¥ç©é¶æ¨çæ½å¨æ°è§£æ±ºæ¹æ¡ãGAN-TAT çåå§ç¢¼å¯å¨ (https://github.com/george-yuanji-wang/GAN-TAT) åå¾ã

##### **Autonomous Alignment with Human Value on Altruism through Considerate Self-imagination and Theory of Mind**
2501.00320v2 by Haibo Tong, Enmeng Lu, Yinqian Sun, Zhengqiang Han, Chao Liu, Feifei Zhao, Yi Zeng

With the widespread application of Artificial Intelligence (AI) in human
society, enabling AI to autonomously align with human values has become a
pressing issue to ensure its sustainable development and benefit to humanity.
One of the most important aspects of aligning with human values is the
necessity for agents to autonomously make altruistic, safe, and ethical
decisions, considering and caring for human well-being. Current AI extremely
pursues absolute superiority in certain tasks, remaining indifferent to the
surrounding environment and other agents, which has led to numerous safety
risks. Altruistic behavior in human society originates from humans' capacity
for empathizing others, known as Theory of Mind (ToM), combined with predictive
imaginative interactions before taking action to produce thoughtful and
altruistic behaviors. Inspired by this, we are committed to endow agents with
considerate self-imagination and ToM capabilities, driving them through
implicit intrinsic motivations to autonomously align with human altruistic
values. By integrating ToM within the imaginative space, agents keep an eye on
the well-being of other agents in real time, proactively anticipate potential
risks to themselves and others, and make thoughtful altruistic decisions that
balance negative effects on the environment. The ancient Chinese story of Sima
Guang Smashes the Vat illustrates the moral behavior of the young Sima Guang
smashed a vat to save a child who had accidentally fallen into it, which is an
excellent reference scenario for this paper. We design an experimental scenario
similar to Sima Guang Smashes the Vat and its variants with different
complexities, which reflects the trade-offs and comprehensive considerations
between self-goals, altruistic rescue, and avoiding negative side effects.

æè¦ï¼é¨èäººå·¥æºæ§ï¼AIï¼å¨äººé¡ç¤¾æä¸­çå»£æ³æç¨ï¼è® AI èªä¸»èäººé¡å¹å¼è§ä¸è´å·²æçºç¢ºä¿å¶æ°¸çºç¼å±åé ç¦äººé¡çç¶åä¹æ¥ãèäººé¡å¹å¼è§ä¸è´æéè¦çé¢åä¹ä¸ï¼å¨æ¼ä»£çäººå¿é èªä¸»ååºå©ä»ãå®å¨ãä¸åä¹éå¾·çæ±ºç­ï¼èéä¸¦éæ·äººé¡ç¦ç¥ãç®åç AI å¨ç¹å®ä»»åä¸­æ¥µåè¿½æ±çµå°åªè¶æ§ï¼å°æ¼å¨é­ç°å¢åå¶å®ä»£çäººæ¼ ä¸éå¿ï¼éå·²å°è´è¨±å¤å®å¨é¢¨éªãäººé¡ç¤¾æä¸­çå©ä»è¡çºæºèªæ¼äººé¡åçä»äººçè½åï¼ç¨±çºå¿æºçè«ï¼ToMï¼ï¼çµåå¨æ¡åè¡ååé²è¡é æ¸¬æ§çæ³åäºåï¼ä»¥ç¢çå¨å°ä¸å©ä»çè¡çºãåå°æ­¤åç¼ï¼æåè´åæ¼è³¦äºä»£çäººé«è²¼çèªææ³åå ToM è½åï¼ééé±å«çå§å¨åæ©é©ä½¿ä»åèªä¸»èäººé¡å©ä»å¹å¼è§ä¸è´ãééå° ToM æ´åå¨æ³åç©ºéä¸­ï¼ä»£çäººè½å³æéæ³¨å¶ä»ä»£çäººçç¦ç¥ï¼ä¸»åé æ¸¬å°èªèº«åä»äººæ½å¨çé¢¨éªï¼ä¸¦ååºå¨å°ä¸å©ä»çæ±ºç­ï¼å¹³è¡¡å°ç°å¢çè² é¢å½±é¿ãä¸­åå¤ä»£æäºãå¸é¦¬åç ¸ç¼¸ãèªªæäºå¹´å¹¼çå¸é¦¬åçºäºæä¸åä¸å°å¿æé²æ°´ç¼¸ä¸­çå­©å­èç ¸ç ´æ°´ç¼¸çéå¾·è¡çºï¼æ¯æ¬æççµä½³åèæå¢ãæåè¨­è¨äºä¸åèãå¸é¦¬åç ¸ç¼¸ãç¸ä¼¼çå¯¦é©æå¢ï¼ä»¥åå·æä¸åè¤éæ§çè®é«ï¼åæ äºèªæç®æ¨ãå©ä»ææ´åé¿åè² é¢å¯ä½ç¨ä¹éçæ¬è¡¡åç¶åèéã

##### **A Fourfold Pathogen Reference Ontology Suite**
2501.01454v1 by Shane Babcock, Carter Benson, Giacomo De Colle, Sydney Cohen, Alexander D. Diehl, Ram A. N. R. Challa, Anthony Huffman, Yongqun He, John Beverley

Infectious diseases remain a critical global health challenge, and the
integration of standardized ontologies plays a vital role in managing related
data. The Infectious Disease Ontology (IDO) and its extensions, such as the
Coronavirus Infectious Disease Ontology (CIDO), are essential for organizing
and disseminating information related to infectious diseases. The COVID-19
pandemic highlighted the need for updating IDO and its virus-specific
extensions. There is an additional need to update IDO extensions specific to
bacteria, fungus, and parasite infectious diseases. We adopt the "hub and
spoke" methodology to generate pathogen-specific extensions of IDO: Virus
Infectious Disease Ontology (VIDO), Bacteria Infectious Disease Ontology
(BIDO), Mycosis Infectious Disease Ontology (MIDO), and Parasite Infectious
Disease Ontology (PIDO). The creation of pathogen-specific reference ontologies
advances modularization and reusability of infectious disease data within the
IDO ecosystem. Future work will focus on further refining these ontologies,
creating new extensions, and developing application ontologies based on them,
in line with ongoing efforts to standardize biological and biomedical
terminologies for improved data sharing and analysis.

æè¦ï¼å³æçä»æ¯ä¸é å¨çæ§çå¥åº·ææ°ï¼èæ¨æºåæ¬é«çæ´åå¨ç®¡çç¸éæ¸ææ¹é¢æ®æ¼èè³ééè¦çè§è²ãå³æçæ¬é« (IDO) åå¶æ´åï¼ä¾å¦å ççæ¯å³æçæ¬é« (CIDO)ï¼å°æ¼çµç¹åå³æ­èå³æçç¸éçè³è¨è³ééè¦ãCOVID-19 å¤§æµè¡å¸é¡¯äºæ´æ° IDO åå¶ç¹å®æ¼çæ¯çæ´åçéæ±ãæ­¤å¤ï¼éææ´æ°ç¹å®æ¼ç´°èãçèåå¯çè²å³æçç IDO æ´åçéæ±ãæåæ¡ç¨ãæ¨ç´è¼»æ¢ãæ¹æ³ä¾ç¢ç IDO çç¹å®æ¼çåé«çæ´åï¼çæ¯å³æçæ¬é« (VIDO)ãç´°èå³æçæ¬é« (BIDO)ãçèçå³æçæ¬é« (MIDO) åå¯çè²å³æçæ¬é« (PIDO)ãç¹å®æ¼çåé«çåèæ¬é«çå»ºç«ï¼ä¿è¿äº IDO çæç³»çµ±å§å³æçæ¸æçæ¨¡çµååå¯éè¤ä½¿ç¨æ§ãæªä¾çç ç©¶å·¥ä½å°éé»æ¾å¨é²ä¸æ­¥å®åéäºæ¬é«ãå»ºç«æ°çæ´åï¼ä»¥åæ ¹æéäºæ¬é«éç¼æç¨æ¬é«ï¼éèæ¨æºåçç©åçç©é«å­¸è¡èªä»¥æ¹åæ¸æå±äº«ååæçæçºåªåç¸ä¸è´ã

##### **CancerKG.ORG A Web-scale, Interactive, Verifiable Knowledge Graph-LLM Hybrid for Assisting with Optimal Cancer Treatment and Care**
2501.00223v1 by Michael Gubanov, Anna Pyayt, Aleksandra Karolak

Here, we describe one of the first Web-scale hybrid Knowledge Graph
(KG)-Large Language Model (LLM), populated with the latest peer-reviewed
medical knowledge on colorectal Cancer. It is currently being evaluated to
assist with both medical research and clinical information retrieval tasks at
Moffitt Cancer Center, which is one of the top Cancer centers in the U.S. and
in the world. Our hybrid is remarkable as it serves the user needs better than
just an LLM, KG or a search-engine in isolation. LLMs as is are known to
exhibit hallucinations and catastrophic forgetting as well as are trained on
outdated corpora. The state of the art KGs, such as PrimeKG, cBioPortal,
ChEMBL, NCBI, and other require manual curation, hence are quickly getting
stale. CancerKG is unsupervised and is capable of automatically ingesting and
organizing the latest medical findings. To alleviate the LLMs shortcomings, the
verified KG serves as a Retrieval Augmented Generation (RAG) guardrail.
CancerKG exhibits 5 different advanced user interfaces, each tailored to serve
different data modalities better and more convenient for the user.

æè¦ï¼å¨æ­¤ï¼æä»¬æè¿°äºç¬¬ä¸ä¸ª Web çº§æ··åç¥è¯å¾è°± (KG) - å¤§åè¯­è¨æ¨¡å (LLM)ï¼å¶ä¸­åæ¥çæå³ç»ç´è ççææ°åè¡è¯å®¡å»å­¦ç¥è¯ãç®åæ­£å¨è¯ä¼°å®ä»¥åå© Moffitt ççä¸­å¿è¿è¡å»å­¦ç ç©¶åä¸´åºä¿¡æ¯æ£ç´¢ä»»å¡ï¼è¯¥ä¸­å¿æ¯ç¾å½åä¸çé¡¶çº§ççä¸­å¿ä¹ä¸ãæä»¬çæ··åä½éå¸¸åºè²ï¼å ä¸ºå®æ¯å­¤ç«ç LLMãKG ææç´¢å¼ææ´å¥½å°æ»¡è¶³ç¨æ·éæ±ãä¼æå¨ç¥ï¼LLM ä¼åºç°å¹»è§åç¾é¾æ§éå¿ï¼å¹¶ä¸æ¯å¨è¿æ¶çè¯­æåºä¸è¿è¡è®­ç»çãæåè¿ç KGï¼ä¾å¦ PrimeKGãcBioPortalãChEMBLãNCBI ç­éè¦äººå·¥æ´çï¼å æ­¤å¾å¿«å°±ä¼è¿æ¶ãCancerKG æ éçç£ï¼è½å¤èªå¨æååç»ç»ææ°çå»å­¦åç°ãä¸ºäºåè½» LLM çç¼ºç¹ï¼ç»è¿éªè¯ç KG åå½æ£ç´¢å¢å¼ºçæ (RAG) æ¤æ ãCancerKG å±ç¤ºäº 5 ç§ä¸åçé«çº§ç¨æ·çé¢ï¼æ¯ç§çé¢é½éå¯¹æå¡ä¸åçæ°æ®æ¨¡å¼ï¼ä¸ºç¨æ·æä¾æ´å¥½ãæ´æ¹ä¾¿çæå¡ã

##### **An Empirical Evaluation of Large Language Models on Consumer Health Questions**
2501.00208v1 by Moaiz Abrar, Yusuf Sermet, Ibrahim Demir

This study evaluates the performance of several Large Language Models (LLMs)
on MedRedQA, a dataset of consumer-based medical questions and answers by
verified experts extracted from the AskDocs subreddit. While LLMs have shown
proficiency in clinical question answering (QA) benchmarks, their effectiveness
on real-world, consumer-based, medical questions remains less understood.
MedRedQA presents unique challenges, such as informal language and the need for
precise responses suited to non-specialist queries. To assess model
performance, responses were generated using five LLMs: GPT-4o mini, Llama 3.1:
70B, Mistral-123B, Mistral-7B, and Gemini-Flash. A cross-evaluation method was
used, where each model evaluated its responses as well as those of others to
minimize bias. The results indicated that GPT-4o mini achieved the highest
alignment with expert responses according to four out of the five models'
judges, while Mistral-7B scored lowest according to three out of five models'
judges. This study highlights the potential and limitations of current LLMs for
consumer health medical question answering, indicating avenues for further
development.

æè¦ï¼æ¬ç ç©¶è©ä¼°äºå¤§åèªè¨æ¨¡å (LLM) å¨ MedRedQA ä¸çæè½ï¼MedRedQA æ¯ä¸çµæ¶è²»èé«çåé¡èç­æ¡çè³æéï¼ç± AskDocs å­çå¡ä¸­ç¶éé©è­çå°å®¶ææåºãåç®¡ LLM å·²å¨è¨åºåé¡è§£ç­ (QA) åºæºä¸­å±ç¾åºå°æ¥­ç¥è­ï¼ä½å®åå¨ç¾å¯¦ä¸çãæ¶è²»èçºåºç¤çé«çåé¡ä¸çæææ§ä»è¼ä¸æç¢ºãMedRedQA æåºç¨ç¹çææ°ï¼ä¾å¦éæ­£å¼èªè¨åå°éå°å®¶æ¥è©¢æä¾ç²¾ç¢ºåæçéæ±ãçºäºè©ä¼°æ¨¡åæè½ï¼ä½¿ç¨äºå LLM çæäºåæï¼GPT-4o miniãLlama 3.1ï¼70BãMistral-123BãMistral-7B å Gemini-Flashãä½¿ç¨äºäº¤åè©ä¼°æ¹æ³ï¼å¶ä¸­æ¯åæ¨¡åè©ä¼°èªå·±çåæä»¥åå¶ä»æ¨¡åçåæï¼ä»¥æå°ååå·®ãçµæé¡¯ç¤ºï¼æ ¹æäºåæ¨¡åä¸­çååæ¨¡åè©å¯©ï¼GPT-4o mini èå°å®¶åæçä¸è´æ§æé«ï¼èæ ¹æäºåæ¨¡åä¸­çä¸åæ¨¡åè©å¯©ï¼Mistral-7B çåæ¸æä½ãæ¬ç ç©¶å¼·èª¿äºç®å LLM å¨æ¶è²»èå¥åº·é«çåé¡è§£ç­æ¹é¢çæ½ååéå¶ï¼ä¸¦æåºé²ä¸æ­¥ç¼å±çéå¾ã

##### **GPT-4 on Clinic Depression Assessment: An LLM-Based Pilot Study**
2501.00199v1 by Giuliano Lorenzoni, Pedro Elkind Velmovitsky, Paulo Alencar, Donald Cowan

Depression has impacted millions of people worldwide and has become one of
the most prevalent mental disorders. Early mental disorder detection can lead
to cost savings for public health agencies and avoid the onset of other major
comorbidities. Additionally, the shortage of specialized personnel is a
critical issue because clinical depression diagnosis is highly dependent on
expert professionals and is time consuming.
  In this study, we explore the use of GPT-4 for clinical depression assessment
based on transcript analysis. We examine the model's ability to classify
patient interviews into binary categories: depressed and not depressed. A
comparative analysis is conducted considering prompt complexity (e.g., using
both simple and complex prompts) as well as varied temperature settings to
assess the impact of prompt complexity and randomness on the model's
performance.
  Results indicate that GPT-4 exhibits considerable variability in accuracy and
F1-Score across configurations, with optimal performance observed at lower
temperature values (0.0-0.2) for complex prompts. However, beyond a certain
threshold (temperature >= 0.3), the relationship between randomness and
performance becomes unpredictable, diminishing the gains from prompt
complexity.
  These findings suggest that, while GPT-4 shows promise for clinical
assessment, the configuration of the prompts and model parameters requires
careful calibration to ensure consistent results. This preliminary study
contributes to understanding the dynamics between prompt engineering and large
language models, offering insights for future development of AI-powered tools
in clinical settings.

æè¦ï¼æé¬±çå½±é¿å¨çæ¸ç¾è¬äººï¼å·²æçºææ®éçç²¾ç¥ç¾çä¹ä¸ãææ©åµæ¸¬ç²¾ç¥ç¾çï¼è½çºå¬å±è¡çæ©æ§ç¯çææ¬ï¼ä¸¦é¿åå¶ä»ä¸»è¦å±ççç¼çãæ­¤å¤ï¼å°æ¥­äººå¡ç­ç¼ºæ¯ä¸åééµåé¡ï¼å çºè¨åºæé¬±ççè¨ºæ·é«åº¦ä¾è³´æ¼å°æ¥­äººå¡ï¼ä¸èæè²»åã
å¨éåç ç©¶ä¸­ï¼æåæ¢è¨ä½¿ç¨ GPT-4 é²è¡è¨åºæé¬±çè©ä¼°ï¼åºç¤æ¯è¬æ¬åæãæåæª¢è¦æ¨¡åå°çäººè¨ªè«åé¡çºäºåé¡å¥ï¼æé¬±çåéæé¬±çï¼çè½åãæåé²è¡æ¯è¼åæï¼èéæç¤ºè¤éåº¦ï¼ä¾å¦ï¼åæä½¿ç¨ç°¡å®åè¤éçæç¤ºï¼ï¼ä»¥ååç¨®æº«åº¦è¨­å®ï¼ä»¥è©ä¼°æç¤ºè¤éåº¦åé¨æ©æ§å°æ¨¡åæè½çå½±é¿ã
çµæé¡¯ç¤ºï¼GPT-4 å¨åçµæä¸­çæºç¢ºåº¦å F1 åæ¸è®åå¾å¤§ï¼å¨è¤éæç¤ºçè¼ä½æº«åº¦å¼ï¼0.0-0.2ï¼ä¸è§å¯å°æä½³æè½ãç¶èï¼è¶éæåé¾å¼ï¼æº«åº¦ >= 0.3ï¼å¾ï¼é¨æ©æ§åæè½ä¹éçéä¿è®å¾é£ä»¥é æ¸¬ï¼éä½äºæç¤ºè¤éåº¦å¸¶ä¾çæ¶çã
éäºç¼ç¾è¡¨æï¼éç¶ GPT-4 å¨è¨åºè©ä¼°æ¹é¢é¡¯ç¤ºåºåæ¯ï¼ä½æç¤ºåæ¨¡ååæ¸ççµæéè¦ä»ç´°æ ¡æºï¼ä»¥ç¢ºä¿çµæçä¸è´æ§ãéé åæ­¥ç ç©¶æå©æ¼äºè§£æç¤ºå·¥ç¨åå¤§åèªè¨æ¨¡åä¹éçåæï¼çºæªä¾å¨è¨åºç°å¢ä¸­éç¼ AI é©åå·¥å·æä¾è¦è§£ã

##### **SepsisCalc: Integrating Clinical Calculators into Early Sepsis Prediction via Dynamic Temporal Graph Construction**
2501.00190v1 by Changchang Yin, Shihan Fu, Bingsheng Yao, Thai-Hoang Pham, Weidan Cao, Dakuo Wang, Jeffrey Caterino, Ping Zhang

Sepsis is an organ dysfunction caused by a deregulated immune response to an
infection. Early sepsis prediction and identification allow for timely
intervention, leading to improved clinical outcomes. Clinical calculators
(e.g., the six-organ dysfunction assessment of SOFA) play a vital role in
sepsis identification within clinicians' workflow, providing evidence-based
risk assessments essential for sepsis diagnosis. However, artificial
intelligence (AI) sepsis prediction models typically generate a single sepsis
risk score without incorporating clinical calculators for assessing organ
dysfunctions, making the models less convincing and transparent to clinicians.
To bridge the gap, we propose to mimic clinicians' workflow with a novel
framework SepsisCalc to integrate clinical calculators into the predictive
model, yielding a clinically transparent and precise model for utilization in
clinical settings. Practically, clinical calculators usually combine
information from multiple component variables in Electronic Health Records
(EHR), and might not be applicable when the variables are (partially) missing.
We mitigate this issue by representing EHRs as temporal graphs and integrating
a learning module to dynamically add the accurately estimated calculator to the
graphs. Experimental results on real-world datasets show that the proposed
model outperforms state-of-the-art methods on sepsis prediction tasks.
Moreover, we developed a system to identify organ dysfunctions and potential
sepsis risks, providing a human-AI interaction tool for deployment, which can
help clinicians understand the prediction outputs and prepare timely
interventions for the corresponding dysfunctions, paving the way for actionable
clinical decision-making support for early intervention.

æè¦ï¼æè¡çæ¯ç±å¤±èª¿çåç«åæå°ææå¼èµ·çå¨å®åè½éç¤ãæè¡ççæ©æé æ¸¬åè­å¥åè¨±åæä»å¥ï¼å¾èæ¹åè¨åºçµæãè¨åºè¨ç®å¨ï¼ä¾å¦ SOFA çå­å¨å®åè½éç¤è©ä¼°ï¼å¨è¨åºé«çå·¥ä½æµç¨ä¸­å°æè¡çè­å¥ç¼æ®èè³ééè¦çä½ç¨ï¼æä¾äºæè¡çè¨ºæ·å¿ä¸å¯å°çåºæ¼è­æçé¢¨éªè©ä¼°ãç¶èï¼äººå·¥æºè½ (AI) æè¡çé æ¸¬æ¨¡åéå¸¸æç¢çå®ä¸çæè¡çé¢¨éªè©åï¼èä¸æç´å¥è¨åºè¨ç®å¨ä¾è©ä¼°å¨å®åè½éç¤ï¼éä½¿å¾éäºæ¨¡åå°è¨åºé«çä¾èªªä¸å¤ªä»¤äººä¿¡æä¸ä¸éæãçºäºå½åéä¸å·®è·ï¼æåå»ºè­°æ¨¡æ¬è¨åºé«ççå·¥ä½æµç¨ï¼ä½¿ç¨ä¸åæ°çæ¡æ¶ SepsisCalc å°è¨åºè¨ç®å¨æ´åå°é æ¸¬æ¨¡åä¸­ï¼å¾èç¢çä¸åå¨è¨åºç°å¢ä¸­ä½¿ç¨çè¨åºéæä¸ç²¾ç¢ºçæ¨¡åãå¯¦éä¸ï¼è¨åºè¨ç®å¨éå¸¸æçµåé»å­å¥åº·è¨é (EHR) ä¸­å¤åçµæè®éçè³è¨ï¼ä¸¦ä¸å¨è®éï¼é¨åï¼ç¼ºå¤±æå¯è½ä¸é©ç¨ãæåééå° EHR è¡¨ç¤ºçºæéåä¸¦æ´åä¸åå­¸ç¿æ¨¡çµä¾åæå°å°æºç¢ºä¼°è¨çè¨ç®å¨æ°å¢å°åå½¢ä¸­ï¼å¾èç·©è§£äºéååé¡ãå¨çå¯¦ä¸çè³æéä¸çå¯¦é©çµæè¡¨æï¼ææåºçæ¨¡åå¨æè¡çé æ¸¬ä»»åä¸åªæ¼æåé²çæ¹æ³ãæ­¤å¤ï¼æåéç¼äºä¸åç³»çµ±ä¾è­å¥å¨å®åè½éç¤åæ½å¨çæè¡çé¢¨éªï¼æä¾äºä¸åå¯ä¾é¨ç½²çäººæ©äºåå·¥å·ï¼éå¯ä»¥å¹«å©è¨åºé«çç­è§£é æ¸¬è¼¸åºä¸¦çºç¸æçåè½éç¤æºååæçå¹²é æªæ½ï¼çºæ©æå¹²é çè¡åè¨åºæ±ºç­æ¯æ´éªå¹³éè·¯ã

##### **DeepLL: Considering Linear Logic for the Analysis of Deep Learning Experiments**
2501.00169v1 by Nick Papoulias

Deep Learning experiments have critical requirements regarding the careful
handling of their datasets as well as the efficient and correct usage of APIs
that interact with hardware accelerators. On the one hand, software mistakes
during data handling can contaminate experiments and lead to incorrect results.
On the other hand, poorly coded APIs that interact with the hardware can lead
to sub-optimal usage and untrustworthy conclusions. In this work we investigate
the use of Linear Logic for the analysis of Deep Learning experiments. We show
that primitives and operators of Linear Logic can be used to express: (i) an
abstract representation of the control flow of an experiment, (ii) a set of
available experimental resources, such as API calls to the underlying
data-structures and hardware as well as (iii) reasoning rules about the correct
consumption of resources during experiments. Our proposed model is not only
lightweight but also easy to comprehend having both a symbolic and a visual
component. Finally, its artifacts are themselves proofs in Linear Logic that
can be readily verified by off-the-shelf reasoners.

æè¦ï¼æ·±åº¦å­¸ç¿å¯¦é©å°æ¼è³æéçä»ç´°èçä»¥åèç¡¬é«å éå¨äºåç API çææä¸æ­£ç¢ºä½¿ç¨å·æéè¦çè¦æ±ãä¸æ¹é¢ï¼è³æèçéç¨ä¸­çè»é«é¯èª¤å¯è½ææ±¡æå¯¦é©ä¸¦å°è´ä¸æ­£ç¢ºççµæãå¦ä¸æ¹é¢ï¼èç¡¬é«äºåçç·¨ç¢¼ä¸è¯ç API å¯è½å°è´æ¬¡ä½³ä½¿ç¨åä¸å¯é ççµè«ãå¨éé å·¥ä½ä¸­ï¼æåæ¢è¨äºä½¿ç¨ç·æ§éè¼¯ä¾åææ·±åº¦å­¸ç¿å¯¦é©ãæåå±ç¤ºäºç·æ§éè¼¯çåºæ¬åçåéç®ç¬¦å¯ç¨æ¼è¡¨éï¼(i) å¯¦é©æ§å¶æµç¨çæ½è±¡è¡¨ç¤ºï¼(ii) ä¸çµå¯ç¨çå¯¦é©è³æºï¼ä¾å¦å°åºå±¤è³æçµæ§åç¡¬é«ç API å¼å«ä»¥å (iii) éæ¼å¨å¯¦é©æéæ­£ç¢ºæ¶èè³æºçæ¨çè¦åãæåæåºçæ¨¡åä¸åè¼éç´ï¼èä¸ææ¼çè§£ï¼æ¢æç¬¦èçµæï¼ä¹æè¦è¦ºçµæãæå¾ï¼å¶å·¥ä»¶æ¬èº«å°±æ¯ç·æ§éè¼¯ä¸­çè­æï¼å¯ä»¥ä½¿ç¨ç¾æçæ¨çå¨è¼é¬é©è­ã

##### **Temporal reasoning for timeline summarisation in social media**
2501.00152v1 by Jiayu Song, Mahmud Akhter, Dana Atzil Slonim, Maria Liakata

This paper explores whether enhancing temporal reasoning capabilities in
Large Language Models (LLMs) can improve the quality of timeline summarization,
the task of summarising long texts containing sequences of events, particularly
social media threads . We introduce \textit{NarrativeReason}, a novel dataset
focused on temporal relationships among sequential events within narratives,
distinguishing it from existing temporal reasoning datasets that primarily
address pair-wise event relationships. Our approach then combines temporal
reasoning with timeline summarization through a knowledge distillation
framework, where we first fine-tune a teacher model on temporal reasoning tasks
and then distill this knowledge into a student model while simultaneously
training it for the task of timeline summarization. Experimental results
demonstrate that our model achieves superior performance on mental
health-related timeline summarization tasks, which involve long social media
threads with repetitions of events and a mix of emotions, highlighting the
importance of leveraging temporal reasoning to improve timeline summarisation.

æè¦ï¼éç¯è«ææ¢è¨å¢å¼·å¤§åèªè¨æ¨¡å (LLM) ä¸­çæéæ¨çè½åæ¯å¦è½æåæéè»¸æè¦çåè³ªï¼æéè»¸æè¦æ¯éå°åå«äºä»¶é åºçé·ç¯æå­é²è¡æè¦çä»»åï¼å°¤å¶æ¯ç¤¾ç¾¤åªé«ä¸²ãæåå¼é²äº\textit{NarrativeReason}ï¼éåæ°ç©çè³æéå°æ³¨æ¼æè¿°ä¸­é åºäºä»¶ä¹éçæééä¿ï¼ä¸¦å°å¶èç¾æçæéæ¨çè³æéååéä¾ï¼å¾èä¸»è¦èçæå°çäºä»¶éä¿ãæåçåæ³æ¥èééç¥è­èåæ¶æ§å°æéæ¨çèæéè»¸æè¦çµåï¼æåé¦åéå°æéæ¨çä»»åå¾®èª¿ä¸åæå¸«æ¨¡åï¼ç¶å¾å°æ­¤ç¥è­èåå°ä¸åå­¸çæ¨¡åä¸­ï¼åæè¨ç·´å®é²è¡æéè»¸æè¦çä»»åãå¯¦é©çµæé¡¯ç¤ºæåçæ¨¡åå¨èå¿çå¥åº·ç¸éçæéè»¸æè¦ä»»åä¸­ç²å¾äºåè¶çè¡¨ç¾ï¼éæ¶åå°åå«éè¤äºä»¶ååç¨®æç·çé·ç¯ç¤¾ç¾¤åªé«ä¸²ï¼å¼·èª¿äºå©ç¨æéæ¨çä¾æåæéè»¸æè¦çéè¦æ§ã

##### **A Data-Centric Approach to Detecting and Mitigating Demographic Bias in Pediatric Mental Health Text: A Case Study in Anxiety Detection**
2501.00129v1 by Julia Ive, Paulina Bondaronek, Vishal Yadav, Daniel Santel, Tracy Glauser, Tina Cheng, Jeffrey R. Strawn, Greeshma Agasthya, Jordan Tschida, Sanghyun Choo, Mayanka Chandrashekar, Anuj J. Kapadia, John Pestian

Introduction: Healthcare AI models often inherit biases from their training
data. While efforts have primarily targeted bias in structured data, mental
health heavily depends on unstructured data. This study aims to detect and
mitigate linguistic differences related to non-biological differences in the
training data of AI models designed to assist in pediatric mental health
screening. Our objectives are: (1) to assess the presence of bias by evaluating
outcome parity across sex subgroups, (2) to identify bias sources through
textual distribution analysis, and (3) to develop a de-biasing method for
mental health text data. Methods: We examined classification parity across
demographic groups and assessed how gendered language influences model
predictions. A data-centric de-biasing method was applied, focusing on
neutralizing biased terms while retaining salient clinical information. This
methodology was tested on a model for automatic anxiety detection in pediatric
patients. Results: Our findings revealed a systematic under-diagnosis of female
adolescent patients, with a 4% lower accuracy and a 9% higher False Negative
Rate (FNR) compared to male patients, likely due to disparities in information
density and linguistic differences in patient notes. Notes for male patients
were on average 500 words longer, and linguistic similarity metrics indicated
distinct word distributions between genders. Implementing our de-biasing
approach reduced diagnostic bias by up to 27%, demonstrating its effectiveness
in enhancing equity across demographic groups. Discussion: We developed a
data-centric de-biasing framework to address gender-based content disparities
within clinical text. By neutralizing biased language and enhancing focus on
clinically essential information, our approach demonstrates an effective
strategy for mitigating bias in AI healthcare models trained on text.

æè¦ï¼<paragraph>å¼è¨ï¼é«çä¿å¥ AI æ¨¡åéå¸¸æå¾å¶è¨ç·´è³æä¸­ç¹¼æ¿åè¦ãéç¶åªåä¸»è¦éå°çµæ§åè³æä¸­çåè¦ï¼ä½å¿çå¥åº·å¨å¾å¤§ç¨åº¦ä¸ä¾è³´æ¼éçµæ§åè³æãæ¬ç ç©¶æ¨å¨æª¢æ¸¬ä¸¦æ¸è¼èè¨­è¨ç¨æ¼åå©åç«¥å¿çå¥åº·ç¯©æª¢ç AI æ¨¡åè¨ç·´è³æä¸­çéçç©å·®ç°ç¸éçèªè¨å·®ç°ãæåçç®æ¨æ¯ï¼(1) ééè©ä¼°ä¸åæ§å¥å­ç¾¤é«ççµæå¹³å¹ä¾è©ä¼°åè¦çå­å¨ï¼(2) ééææ¬åä½åæä¾æ¾åºåè¦ä¾æºï¼ä»¥å (3) éç¼ä¸ç¨®å¿çå¥åº·ææ¬è³æçå»åè¦æ¹æ³ãæ¹æ³ï¼æåæª¢æ¥äºä¸åäººå£ç¾¤é«çåé¡å¹³å¹ï¼ä¸¦è©ä¼°äºæ§å¥èªè¨å¦ä½å½±é¿æ¨¡åé æ¸¬ãæç¨äºä¸ç¨®ä»¥è³æçºä¸­å¿çå»åè¦æ¹æ³ï¼å°æ³¨æ¼å¨ä¿çé¡¯èè¨åºè³è¨çåæä¸­åæåè¦çè¡èªãæ­¤æ¹æ³å¨ä¸åç¨æ¼åç«¥æ£èèªåç¦æ®æª¢æ¸¬çæ¨¡åä¸é²è¡äºæ¸¬è©¦ãçµæï¼æåçç ç©¶çµææ­ç¤ºäºå°å¥³æ§éå°å¹´æ£èçç³»çµ±æ§è¨ºæ·ä¸è¶³ï¼èç·æ§æ£èç¸æ¯ï¼æºç¢ºçä½äº 4%ï¼åé°æ§ç (FNR) é«äº 9%ï¼éå¯è½æ¯ç±æ¼æ£èåè¨»ä¸­è³è¨å¯åº¦åèªè¨å·®ç°çå·®ç°ãç·æ§æ£èçåè¨»å¹³åé· 500 åå­ï¼èªè¨ç¸ä¼¼æ§ææ¨é¡¯ç¤ºä¸åæ§å¥ä¹éçå­è©åä½æªç¶ä¸åãå¯¦æ½æåçå»åè¦æ¹æ³å°è¨ºæ·åè¦éä½äº 27%ï¼è­æäºå¶å¨æåä¸åäººå£ç¾¤é«ä¹éå¬å¹³æ§çæææ§ãè¨è«ï¼æåéç¼äºä¸åä»¥è³æçºä¸­å¿çå»åè¦æ¶æ§ï¼ç¨æ¼è§£æ±ºè¨åºææ¬ä¸­çåºæ¼æ§å¥çå§å®¹å·®ç°ãééä¸­åæåè¦çèªè¨åå å¼·å°è¨åºå¿è¦è³è¨çéæ³¨ï¼æåçåæ³å±ç¤ºäºä¸ç¨®ææç­ç¥ï¼ç¨æ¼æ¸è¼å¨ææ¬ä¸è¨ç·´ç AI é«çä¿å¥æ¨¡åä¸­çåè¦ã</paragraph>

##### **Leveraging AI for Automatic Classification of PCOS Using Ultrasound Imaging**
2501.01984v1 by Atharva Divekar, Atharva Sonawane

The AUTO-PCOS Classification Challenge seeks to advance the diagnostic
capabilities of artificial intelligence (AI) in identifying Polycystic Ovary
Syndrome (PCOS) through automated classification of healthy and unhealthy
ultrasound frames. This report outlines our methodology for building a robust
AI pipeline utilizing transfer learning with the InceptionV3 architecture to
achieve high accuracy in binary classification. Preprocessing steps ensured the
dataset was optimized for training, validation, and testing, while
interpretability methods like LIME and saliency maps provided valuable insights
into the model's decision-making. Our approach achieved an accuracy of 90.52%,
with precision, recall, and F1-score metrics exceeding 90% on validation data,
demonstrating its efficacy. The project underscores the transformative
potential of AI in healthcare, particularly in addressing diagnostic challenges
like PCOS. Key findings, challenges, and recommendations for future
enhancements are discussed, highlighting the pathway for creating reliable,
interpretable, and scalable AI-driven medical diagnostic tools.

æè¦ï¼AUTO-PCOS åé¡ææ°æ¨å¨ééèªååé¡å¥åº·åä¸å¥åº·çè¶é³æ³¢å½±åï¼æåäººå·¥æºæ§ (AI) å¨è¾¨è­å¤åæ§åµå·¢çåç¾¤ (PCOS) çè¨ºæ·è½åãéä»½å ±åæ¦è¿°äºæåå»ºæ§å¼·å¥ AI ç®¡ç·çæ¹æ³ï¼å©ç¨ InceptionV3 æ¶æ§é²è¡é·ç§»å­¸ç¿ï¼ä»¥å¨äºååé¡ä¸­éæé«æºç¢ºåº¦ãé èçæ­¥é©ç¢ºä¿è³æéå·²éå°è¨ç·´ãé©è­åæ¸¬è©¦é²è¡æä½³åï¼è LIME åé¡¯èæ§åç­å¯è§£éæ§æ¹æ³åæä¾äºæå¹å¼çè¦è§£ï¼èªªææ¨¡åçæ±ºç­å¶å®ãæåçåæ³å¨é©è­è³æä¸éå°äº 90.52% çæºç¢ºåº¦ï¼ç²¾ç¢ºåº¦ãå¬åçå F1 åæ¸é½è¶é 90%ï¼è­æäºå®çæåãéåå°æ¡å¼·èª¿äº AI å¨é«çä¿å¥ä¸­çè½åæ½åï¼ç¹å¥æ¯å¨è§£æ±º PCOS ç­è¨ºæ·ææ°æ¹é¢ãè¨è«äºééµç¼ç¾ãææ°åæªä¾å¢å¼·å»ºè­°ï¼çªé¡¯äºå»ºç«å¯é ãå¯è§£éä¸å¯æ´åç AI é©åé«çè¨ºæ·å·¥å·çéå¾ã

##### **Advancing Parkinson's Disease Progression Prediction: Comparing Long Short-Term Memory Networks and Kolmogorov-Arnold Networks**
2412.20744v1 by Abhinav Roy, Bhavesh Gyanchandani, Aditya Oza, Abhishek Sharma

Parkinson's Disease (PD) is a degenerative neurological disorder that impairs
motor and non-motor functions, significantly reducing quality of life and
increasing mortality risk. Early and accurate detection of PD progression is
vital for effective management and improved patient outcomes. Current
diagnostic methods, however, are often costly, time-consuming, and require
specialized equipment and expertise. This work proposes an innovative approach
to predicting PD progression using regression methods, Long Short-Term Memory
(LSTM) networks, and Kolmogorov Arnold Networks (KAN). KAN, utilizing
spline-parametrized univariate functions, allows for dynamic learning of
activation patterns, unlike traditional linear models.
  The Movement Disorder Society-Sponsored Revision of the Unified Parkinson's
Disease Rating Scale (MDS-UPDRS) is a comprehensive tool for evaluating PD
symptoms and is commonly used to measure disease progression. Additionally,
protein or peptide abnormalities are linked to PD onset and progression.
Identifying these associations can aid in predicting disease progression and
understanding molecular changes.
  Comparing multiple models, including LSTM and KAN, this study aims to
identify the method that delivers the highest metrics. The analysis reveals
that KAN, with its dynamic learning capabilities, outperforms other approaches
in predicting PD progression. This research highlights the potential of AI and
machine learning in healthcare, paving the way for advanced computational
models to enhance clinical predictions and improve patient care and treatment
strategies in PD management.

æè¦ï¼å¸éæ£®æ°ç (PD) æ¯ä¸ç¨®ç¥ç¶éåæ§ç¾çï¼ææå®³éååééååè½ï¼å´ééä½çæ´»åè³ªä¸¦å¢å æ­»äº¡é¢¨éªãæ©æä¸æºç¢ºæª¢æ¸¬ PD é²ç¨å°æ¼ææç®¡çåæ¹åæ£èé å¾è³ééè¦ãç¶èï¼ç®åçè¨ºæ·æ¹æ³éå¸¸ææ¬é«æãèæä¸éè¦å°æ¥­è¨­ååå°æ¥­ç¥è­ãéé ç ç©¶æåºäºä¸ç¨®åµæ°çæ¹æ³ï¼ä½¿ç¨è¿´æ­¸æ¹æ³ãé·ç­æè¨æ¶ (LSTM) ç¶²è·¯å Kolmogorov Arnold ç¶²è·¯ (KAN) ä¾é æ¸¬ PD é²ç¨ãKAN å©ç¨æ¨£æ¢åæ¸åçå®è®éå½æ¸ï¼å¯ä»¥åæå­¸ç¿æ¿æ´»æ¨¡å¼ï¼éèå³çµ±ç·æ§æ¨¡åä¸åãéåéç¤åæè´å©ççµ±ä¸å¸éæ£®æ°çè©åéè¡¨ (MDS-UPDRS) æ¯è©ä¼° PD çççç¶åå·¥å·ï¼éå¸¸ç¨æ¼æ¸¬éç¾çé²ç¨ãæ­¤å¤ï¼èç½è³ªæèè½ç°å¸¸è PD ç¼ä½åé²ç¨æéãæ¾åºéäºéè¯å¯ä»¥å¹«å©é æ¸¬ç¾çé²ç¨ä¸¦äºè§£åå­è®åãéé ç ç©¶æ¯è¼äºåæ¬ LSTM å KAN å¨å§çå¤ç¨®æ¨¡åï¼æ¨å¨æ¾åºæä¾æé«ææ¨çæ¹æ³ãåæé¡¯ç¤ºï¼å·æåæå­¸ç¿è½åç KAN å¨é æ¸¬ PD é²ç¨æ¹é¢åªæ¼å¶ä»æ¹æ³ãéé ç ç©¶çªé¡¯äº AI åæ©å¨å­¸ç¿å¨é«çä¿å¥ä¸­çæ½åï¼çºåé²çè¨ç®æ¨¡åéªè·¯ï¼ä»¥å¢å¼·è¨åºé æ¸¬ä¸¦æ¹å PD ç®¡çä¸­çæ£èç§è­·åæ²»çç­ç¥ã

##### **Latent Drifting in Diffusion Models for Counterfactual Medical Image Synthesis**
2412.20651v1 by Yousef Yeganeh, Ioannis Charisiadis, Marta Hasny, Martin Hartenberger, BjÃ¶rn Ommer, Nassir Navab, Azade Farshad, Ehsan Adeli

Scaling by training on large datasets has been shown to enhance the quality
and fidelity of image generation and manipulation with diffusion models;
however, such large datasets are not always accessible in medical imaging due
to cost and privacy issues, which contradicts one of the main applications of
such models to produce synthetic samples where real data is scarce. Also,
finetuning on pre-trained general models has been a challenge due to the
distribution shift between the medical domain and the pre-trained models. Here,
we propose Latent Drift (LD) for diffusion models that can be adopted for any
fine-tuning method to mitigate the issues faced by the distribution shift or
employed in inference time as a condition. Latent Drifting enables diffusion
models to be conditioned for medical images fitted for the complex task of
counterfactual image generation, which is crucial to investigate how parameters
such as gender, age, and adding or removing diseases in a patient would alter
the medical images. We evaluate our method on three public longitudinal
benchmark datasets of brain MRI and chest X-rays for counterfactual image
generation. Our results demonstrate significant performance gains in various
scenarios when combined with different fine-tuning schemes. The source code of
this work will be publicly released upon its acceptance.

æè¦ï¼<paragraph>ééè¨ç·´å¤§åè³æéä¾èª¿æ´æ¯ä¾ï¼å·²è¢«è­æå¯ä»¥æåæ´æ£æ¨¡åå½±åç¢çèæä½çåè³ªåä¿çåº¦ï¼ç¶èï¼ç±æ¼ææ¬åé±ç§åé¡ï¼å¨é«å­¸å½±åä¸­ä¸¦ä¸ç¸½æ¯è½åå¾ééº¼å¤§åçè³æéï¼éèéäºæ¨¡åçä¸»è¦æç¨ä¹ä¸ç¸çç¾ï¼ä¹å°±æ¯å¨çå¯¦è³æç¨å°çææ³ä¸ç¢çåææ¨£æ¬ãæ­¤å¤ï¼ç±æ¼é«å­¸é åèé è¨ç·´æ¨¡åä¹éçåå¸è½ç§»ï¼å°é è¨ç·´çéç¨æ¨¡åé²è¡å¾®èª¿ä¸ç´æ¯ä¸é ææ°ãå¨æ­¤ï¼æåæåºæ´æ£æ¨¡åçæ½å¨æ¼ç§» (LD)ï¼å¯ä»¥æ¡ç¨ä»»ä½å¾®èª¿æ¹æ³ä¾æ¸è¼åå¸è½ç§»æé¢è¨çåé¡ï¼æå¨æ¨çæéä½çºæ¢ä»¶ä½¿ç¨ãæ½å¨æ¼ç§»ä½¿æ´æ£æ¨¡åè½å¤ éå°é©åæ¼åäºå¯¦å½±åç¢çè¤éä»»åçé«å­¸å½±åé²è¡èª¿æ´ï¼éå°æ¼æ¢è¨è«¸å¦æ§å¥ãå¹´é½¡ä»¥åå¨æ£èä¸­å¢å æç§»é¤ç¾çç­åæ¸å°å¦ä½æ¹è®é«å­¸å½±åè³ééè¦ãæåå¨ä¸åå¤§è¦ MRI åè¸é¨ X åçå¬éç¸±ååºæºè³æéä¸è©ä¼°äºæåçæ¹æ³ï¼ä»¥é²è¡åäºå¯¦å½±åç¢çãæåççµæè¡¨æï¼èä¸åçå¾®èª¿æ¹æ¡çµåä½¿ç¨æï¼å¨åç¨®ææ³ä¸é½è½é¡¯èæåæè½ãéé å·¥ä½çåå§ç¢¼å°å¨ç²å¾æ¥åå¾å¬éç¼å¸ã</paragraph>

##### **HALLUCINOGEN: A Benchmark for Evaluating Object Hallucination in Large Visual-Language Models**
2412.20622v1 by Ashish Seth, Dinesh Manocha, Chirag Agarwal

Large Vision-Language Models (LVLMs) have demonstrated remarkable performance
in performing complex multimodal tasks. However, they are still plagued by
object hallucination: the misidentification or misclassification of objects
present in images. To this end, we propose HALLUCINOGEN, a novel visual
question answering (VQA) object hallucination attack benchmark that utilizes
diverse contextual reasoning prompts to evaluate object hallucination in
state-of-the-art LVLMs. We design a series of contextual reasoning
hallucination prompts to evaluate LVLMs' ability to accurately identify objects
in a target image while asking them to perform diverse visual-language tasks
such as identifying, locating or performing visual reasoning around specific
objects. Further, we extend our benchmark to high-stakes medical applications
and introduce MED-HALLUCINOGEN, hallucination attacks tailored to the
biomedical domain, and evaluate the hallucination performance of LVLMs on
medical images, a critical area where precision is crucial. Finally, we conduct
extensive evaluations of eight LVLMs and two hallucination mitigation
strategies across multiple datasets to show that current generic and medical
LVLMs remain susceptible to hallucination attacks.

æè¦ï¼å¤§åè¦è¦ºèªè¨æ¨¡å (LVLMs) å¨å·è¡è¤éçå¤æ¨¡æä»»åæ¹é¢è¡¨ç¾åºè²ãç¶èï¼å®åä»ç¶åå°ç©é«å¹»è¦ºçå°æ¾ï¼é¯èª¤è­å¥æé¯èª¤åé¡ååä¸­å­å¨çç©é«ãçºæ­¤ï¼æåæåºäº HALLUCINOGENï¼éæ¯ä¸åæ°ç©çè¦è¦ºåç­ (VQA) ç©é«å¹»è¦ºæ»æåºæºï¼å®å©ç¨å¤æ¨£åçä¸ä¸ææ¨çæç¤ºä¾è©ä¼°æåé²ç LVLMs ä¸­çç©é«å¹»è¦ºãæåè¨­è¨äºä¸ç³»åä¸ä¸ææ¨çå¹»è¦ºæç¤ºï¼ä»¥è©ä¼° LVLMs å¨è¦æ±å®åå·è¡å¤æ¨£åçè¦è¦ºèªè¨ä»»åï¼ä¾å¦è­å¥ãå®ä½æå°ç¹å®ç©é«é²è¡è¦è¦ºæ¨çï¼çåææºç¢ºè­å¥ç®æ¨ååä¸­ç©é«çè½åãæ­¤å¤ï¼æåå°åºæºæ´å±å°é«é¢¨éªçé«å­¸æç¨ï¼ä¸¦å¼å¥äºå°ééå°çç©é«å­¸é åçå¹»è¦ºæ»æ MED-HALLUCINOGENï¼ä¸¦è©ä¼°äº LVLMs å¨é«å­¸ååï¼ä¸åç²¾ç¢ºè³ééè¦çééµé åï¼ä¸çå¹»è¦ºè¡¨ç¾ãæå¾ï¼æåå°å«å LVLMs åå©åå¹»è¦ºç·©è§£ç­ç¥é²è¡äºå»£æ³çè©ä¼°ï¼è·¨å¤åæ¸æéï¼ä»¥è¡¨æç¶åçéç¨åé«å­¸ LVLMs ä»ç¶å®¹æåå°å¹»è¦ºæ»æã

##### **Dive into Time-Series Anomaly Detection: A Decade Review**
2412.20512v1 by Paul Boniol, Qinghua Liu, Mingyi Huang, Themis Palpanas, John Paparrizos

Recent advances in data collection technology, accompanied by the ever-rising
volume and velocity of streaming data, underscore the vital need for time
series analytics. In this regard, time-series anomaly detection has been an
important activity, entailing various applications in fields such as cyber
security, financial markets, law enforcement, and health care. While
traditional literature on anomaly detection is centered on statistical
measures, the increasing number of machine learning algorithms in recent years
call for a structured, general characterization of the research methods for
time-series anomaly detection. This survey groups and summarizes anomaly
detection existing solutions under a process-centric taxonomy in the time
series context. In addition to giving an original categorization of anomaly
detection methods, we also perform a meta-analysis of the literature and
outline general trends in time-series anomaly detection research.

æè¦ï¼é¨èè³ææ¶éæè¡çææ°é²å±ï¼ä»¥åä¸²æµè³æçæ¸éåéåº¦æçºä¸åï¼å¼·èª¿äºæéåºååæçè¿«åéæ±ãå¨éæ¹é¢ï¼æéåºåç°å¸¸åµæ¸¬ä¸ç´æ¯ä¸é éè¦çæ´»åï¼åå«ç¶²è·¯å®å¨ãéèå¸å ´ãå·æ³åé«çä¿å¥ç­é åä¸­çåç¨®æç¨ãéç¶ç°å¸¸åµæ¸¬çå³çµ±æç»éä¸­æ¼çµ±è¨æ¸¬éï¼ä½è¿å¹´ä¾æ©å¨å­¸ç¿æ¼ç®æ³çæ¸éä¸æ·å¢å ï¼å æ­¤éè¦å°æéåºåç°å¸¸åµæ¸¬çç ç©¶æ¹æ³é²è¡çµæ§åãéç¨çæè¿°ãéé èª¿æ¥å¨æéåºåèçµ¡ä¸­ï¼ä¾æä»¥æµç¨çºä¸­å¿çåé¡æ³ï¼å°ç°å¸¸åµæ¸¬ç¾æè§£æ±ºæ¹æ¡é²è¡åçµåæè¦ãé¤äºå°ç°å¸¸åµæ¸¬æ¹æ³é²è¡åå§åé¡å¤ï¼æåä¹å°æç»é²è¡ååæï¼ä¸¦æ¦è¿°æéåºåç°å¸¸åµæ¸¬ç ç©¶çä¸è¬è¶¨å¢ã

##### **A Deep Subgrouping Framework for Precision Drug Repurposing via Emulating Clinical Trials on Real-world Patient Data**
2412.20373v1 by Seungyeon Lee, Ruoqi Liu, Feixiong Cheng, Ping Zhang

Drug repurposing identifies new therapeutic uses for existing drugs, reducing
the time and costs compared to traditional de novo drug discovery. Most
existing drug repurposing studies using real-world patient data often treat the
entire population as homogeneous, ignoring the heterogeneity of treatment
responses across patient subgroups. This approach may overlook promising drugs
that benefit specific subgroups but lack notable treatment effects across the
entire population, potentially limiting the number of repurposable candidates
identified. To address this, we introduce STEDR, a novel drug repurposing
framework that integrates subgroup analysis with treatment effect estimation.
Our approach first identifies repurposing candidates by emulating multiple
clinical trials on real-world patient data and then characterizes patient
subgroups by learning subgroup-specific treatment effects. We deploy \model to
Alzheimer's Disease (AD), a condition with few approved drugs and known
heterogeneity in treatment responses. We emulate trials for over one thousand
medications on a large-scale real-world database covering over 8 million
patients, identifying 14 drug candidates with beneficial effects to AD in
characterized subgroups. Experiments demonstrate STEDR's superior capability in
identifying repurposing candidates compared to existing approaches.
Additionally, our method can characterize clinically relevant patient subgroups
associated with important AD-related risk factors, paving the way for precision
drug repurposing.

æè¦ï¼è¯ç©åå©ç¨ä¸ºç°æè¯ç©æ¾åºæ°çæ²»çç¨éï¼ä¸ä¼ ç»çä»å¤´è¯ç©åç°ç¸æ¯ï¼åå°äºæ¶é´åææ¬ãå¤§å¤æ°ä½¿ç¨çå®ä¸çæ£èæ°æ®çç°æè¯ç©åå©ç¨ç ç©¶éå¸¸å°æ´ä¸ªäººç¾¤è§ä¸ºåè´¨çï¼èå¿½ç¥äºä¸åæ£èäºç»æ²»çååºçå¼è´¨æ§ãè¿ç§æ¹æ³å¯è½ä¼å¿½è§å¯¹ç¹å®äºç»æçä½æ´ä¸ªç¾¤ä½ç¼ºä¹æ¾çæ²»çææçæå¸æçè¯ç©ï¼ä»èå¯è½éå¶å·²è¯å«çå¯åå©ç¨åéè¯ç©çæ°éãä¸ºäºè§£å³è¿ä¸ªé®é¢ï¼æä»¬å¼å¥äº STEDRï¼è¿æ¯ä¸ä¸ªæ°é¢çè¯ç©åå©ç¨æ¡æ¶ï¼å®å°äºç»åæä¸æ²»çææä¼°è®¡ç¸ç»åãæä»¬çæ¹æ³é¦åéè¿æ¨¡æçå®ä¸çæ£èæ°æ®çå¤ä¸ªä¸´åºè¯éªæ¥è¯å«åå©ç¨åéè¯ç©ï¼ç¶åéè¿å­¦ä¹ äºç»ç¹å¼æ§æ²»çæææ¥è¡¨å¾æ£èäºç»ãæä»¬é¨ç½²\modelå°é¿å°è¨æµ·é»ç (AD)ï¼è¿æ¯ä¸ç§å·²è·æ¹è¯ç©è¾å°ä¸æ²»çååºå·²ç¥å¼è´¨æ§çç¾çãæä»¬å¨ä¸ä¸ªè¦çè¶è¿ 800 ä¸æ£èçå¤§è§æ¨¡çå®ä¸çæ°æ®åºä¸æ¨¡æäºè¶è¿ä¸åç§è¯ç©çè¯éªï¼ç¡®å®äº 14 ç§å¨è¡¨å¾çäºç»ä¸­å¯¹ AD æççåéè¯ç©ãå®éªè¡¨æï¼ä¸ç°ææ¹æ³ç¸æ¯ï¼STEDR å¨è¯å«åå©ç¨åéè¯ç©æ¹é¢å·ææ´å¼ºçè½åãæ­¤å¤ï¼æä»¬çæ¹æ³å¯ä»¥è¡¨å¾ä¸éè¦ç AD ç¸å³å±é©å ç´ ç¸å³çä¸´åºç¸å³æ£èäºç»ï¼ä¸ºç²¾åè¯ç©åå©ç¨éºå¹³éè·¯ã

##### **Transforming CCTV cameras into NO$_2$ sensors at city scale for adaptive policymaking**
2501.00056v1 by Mohamed R. Ibrahim, Terry Lyons

Air pollution in cities, especially NO\textsubscript{2}, is linked to
numerous health problems, ranging from mortality to mental health challenges
and attention deficits in children. While cities globally have initiated
policies to curtail emissions, real-time monitoring remains challenging due to
limited environmental sensors and their inconsistent distribution. This gap
hinders the creation of adaptive urban policies that respond to the sequence of
events and daily activities affecting pollution in cities. Here, we demonstrate
how city CCTV cameras can act as a pseudo-NO\textsubscript{2} sensors. Using a
predictive graph deep model, we utilised traffic flow from London's cameras in
addition to environmental and spatial factors, generating NO\textsubscript{2}
predictions from over 133 million frames. Our analysis of London's mobility
patterns unveiled critical spatiotemporal connections, showing how specific
traffic patterns affect NO\textsubscript{2} levels, sometimes with temporal
lags of up to 6 hours. For instance, if trucks only drive at night, their
effects on NO\textsubscript{2} levels are most likely to be seen in the morning
when people commute. These findings cast doubt on the efficacy of some of the
urban policies currently being implemented to reduce pollution. By leveraging
existing camera infrastructure and our introduced methods, city planners and
policymakers could cost-effectively monitor and mitigate the impact of
NO\textsubscript{2} and other pollutants.

æè¦ï¼åå¸ä¸­çç©ºæ°£æ±¡æï¼ç¹å¥æ¯äºæ°§åæ°®ï¼èè¨±å¤å¥åº·åé¡æéï¼å¾æ­»äº¡çå°åç«¥çç²¾ç¥å¥åº·ææ°åæ³¨æåç¼ºé·ãåç®¡å¨çåå¸å·²ååæ¿ç­ä¾æ¸å°ææ¾ï¼ä½ç±æ¼ç°å¢ææ¸¬å¨æéä¸åä½ä¸åï¼å¯¦æç£æ¸¬ä»ç¶å·æææ°æ§ãéåå·®è·é»ç¤äºé©ææ§åå¸æ¿ç­çå¶å®ï¼éäºæ¿ç­å°å½±é¿åå¸æ±¡æçäºä»¶é åºåæ¥å¸¸æ´»åååºåæãå¨æ­¤ï¼æåå±ç¤ºäºåå¸éè·¯é»è¦æå½±æ©å¦ä½åç¶å½äºæ°§åæ°®ææ¸¬å¨ãä½¿ç¨é æ¸¬åæ·±åº¦æ¨¡åï¼æåå©ç¨äºå«æ¦æå½±æ©çäº¤éæµéä»¥åç°å¢åç©ºéå ç´ ï¼å¾è¶é 1.33 ååç«é¢ä¸­çæäºäºæ°§åæ°®é æ¸¬ãæåå°å«æ¦æµåæ¨¡å¼çåææ­ç¤ºäºééµçæç©ºé£æ¥ï¼å±ç¤ºäºå·é«çäº¤éæ¨¡å¼å¦ä½å½±é¿äºæ°§åæ°®æ°´å¹³ï¼æææéæ»¯å¾é·é 6 å°æãä¾å¦ï¼å¦æå¡è»åªå¨æä¸è¡é§ï¼å®åå°äºæ°§åæ°®æ°´å¹³çå½±é¿ææå¯è½å¨äººåéå¤çæ©ä¸é¡¯ç¾ãéäºç¼ç¾å°ç®åå¯¦æ½çä¸äºæ¨å¨æ¸å°æ±¡æçåå¸æ¿ç­çæææ§æåºäºè³ªçãééå©ç¨ç¾æçæå½±æ©åºç¤è¨­æ½åæåå¼å¥çæ¹æ³ï¼åå¸è¦åèåæ¿ç­å¶å®èå¯ä»¥ç¶æ¿ææå°ç£æ§åæ¸è¼äºæ°§åæ°®åå¶ä»æ±¡æç©çå½±é¿ã

##### **On the Compositional Generalization of Multimodal LLMs for Medical Imaging**
2412.20070v1 by Zhenyang Cai, Junying Chen, Rongsheng Wang, Weihong Wang, Yonglin Deng, Dingjie Song, Yize Chen, Zixu Zhang, Benyou Wang

Multimodal large language models (MLLMs) hold significant potential in the
medical field, but their capabilities are often limited by insufficient data in
certain medical domains, highlighting the need for understanding what kinds of
images can be used by MLLMs for generalization. Current research suggests that
multi-task training outperforms single-task as different tasks can benefit each
other, but they often overlook the internal relationships within these tasks,
providing limited guidance on selecting datasets to enhance specific tasks. To
analyze this phenomenon, we attempted to employ compositional generalization
(CG)-the ability of models to understand novel combinations by recombining
learned elements-as a guiding framework. Since medical images can be precisely
defined by Modality, Anatomical area, and Task, naturally providing an
environment for exploring CG. Therefore, we assembled 106 medical datasets to
create Med-MAT for comprehensive experiments. The experiments confirmed that
MLLMs can use CG to understand unseen medical images and identified CG as one
of the main drivers of the generalization observed in multi-task training.
Additionally, further studies demonstrated that CG effectively supports
datasets with limited data and delivers consistent performance across different
backbones, highlighting its versatility and broad applicability. Med-MAT is
publicly available at https://github.com/FreedomIntelligence/Med-MAT.

æè¦ï¼å¤æ¨¡æå¤§åè¯­è¨æ¨¡å (MLLM) å¨å»çé¢åæ¥æå·¨å¤§æ½åï¼ä½å¶è½åå¾å¾åå°ç¹å®å»çé¢åæ°æ®ä¸è¶³çéå¶ï¼è¿çªåºäºçè§£ MLLM å¯ç¨äºæ³åçå¾åç±»åçå¿è¦æ§ãå½åçç ç©¶è¡¨æï¼å¤ä»»å¡è®­ç»ä¼äºåä»»å¡è®­ç»ï¼å ä¸ºä¸åçä»»å¡å¯ä»¥ç¸äºåçï¼ä½å®ä»¬å¸¸å¸¸å¿½ç¥è¿äºä»»å¡ä¸­çåé¨å³ç³»ï¼å¨éæ©æ°æ®éä»¥å¢å¼ºç¹å®ä»»å¡æ¹é¢æä¾çæå¯¼æéãä¸ºäºåæè¿ç§ç°è±¡ï¼æä»¬å°è¯éç¨ç»åæ³å (CG)ââæ¨¡åéè¿éæ°ç»åå­¦ä¹ çåç´ æ¥çè§£æ°ç»åçè½åââä½ä¸ºæå¯¼æ¡æ¶ãç±äºå»å­¦å¾åå¯ä»¥éè¿æ¹å¼ãè§£ååºååä»»å¡æ¥ç²¾ç¡®å®ä¹ï¼å æ­¤èªç¶å°ä¸ºæ¢ç´¢ CG æä¾äºä¸ä¸ªç¯å¢ãå æ­¤ï¼æä»¬ç»è£äº 106 ä¸ªå»å­¦æ°æ®éæ¥åå»º Med-MAT ä»¥è¿è¡ç»¼åå®éªãå®éªè¯å®ï¼MLLM å¯ä»¥ä½¿ç¨ CG æ¥çè§£çä¸è§çå»å­¦å¾åï¼å¹¶å° CG ç¡®å®ä¸ºå¤ä»»å¡è®­ç»ä¸­è§å¯å°çæ³åçä¸»è¦é©±å¨å ç´ ä¹ä¸ãæ­¤å¤ï¼è¿ä¸æ­¥çç ç©¶è¡¨æï¼CG ææå°æ¯æäºæ°æ®æéçæ°æ®éï¼å¹¶å¨ä¸åçä¸»å¹²ä¸­æä¾äºæç»­çæ§è½ï¼çªåºäºå¶å¤åè½æ§åå¹¿æ³çéç¨æ§ãMed-MAT å¨ https://github.com/FreedomIntelligence/Med-MAT å¬å¼å¯ç¨ã

##### **The Emotional Spectrum of LLMs: Leveraging Empathy and Emotion-Based Markers for Mental Health Support**
2412.20068v1 by Alessandro De Grandi, Federico Ravenda, Andrea Raballo, Fabio Crestani

The increasing demand for mental health services has highlighted the need for
innovative solutions, particularly in the realm of psychological conversational
AI, where the availability of sensitive data is scarce. In this work, we
explored the development of a system tailored for mental health support with a
novel approach to psychological assessment based on explainable emotional
profiles in combination with empathetic conversational models, offering a
promising tool for augmenting traditional care, particularly where immediate
expertise is unavailable. Our work can be divided into two main parts,
intrinsecaly connected to each other. First, we present RACLETTE, a
conversational system that demonstrates superior emotional accuracy compared to
state-of-the-art benchmarks in both understanding users' emotional states and
generating empathetic responses during conversations, while progressively
building an emotional profile of the user through their interactions. Second,
we show how the emotional profiles of a user can be used as interpretable
markers for mental health assessment. These profiles can be compared with
characteristic emotional patterns associated with different mental disorders,
providing a novel approach to preliminary screening and support.

æè¦ï¼é¨èå°å¿çå¥åº·æåéæ±çå¢å ï¼å¸é¡¯äºåµæ°è§£æ±ºæ¹æ¡çéæ±ï¼ç¹å¥æ¯å¨å¿çå°è©±å¼äººå·¥æºæ§é åï¼é£è£¡ç¼ºä¹ææè³æãå¨éé å·¥ä½ä¸­ï¼æåæ¢ç´¢äºéç¼ä¸åéå°å¿çå¥åº·æ¯æçç³»çµ±ï¼æ¡ç¨ä¸ç¨®åºæ¼å¯è§£éçæç·ç¹å¾µçæ°æ¹æ³é²è¡å¿çè©ä¼°ï¼çµååçå¿å°è©±æ¨¡å¼ï¼æä¾äºä¸åæåéçå·¥å·ï¼ç¨æ¼æ´åå³çµ±ç§è­·ï¼ç¹å¥æ¯å¨ç¡æ³ç«å³ç²å¾å°æ¥­ç¥è­çææ³ä¸ãæåçå·¥ä½å¯ä»¥åçºå©åä¸»è¦é¨åï¼å½¼æ­¤å§å¨ç¸éãé¦åï¼æåå±ç¤ºäº RACLETTEï¼ä¸åå°è©±ç³»çµ±ï¼èæåé²çåºæºç¸æ¯ï¼å¨çè§£ä½¿ç¨èæç·çæåå¨å°è©±ä¸­ç¢çåçå¿åææ¹é¢è¡¨ç¾åºåªè¶çæç·æºç¢ºæ§ï¼åæééä»åçäºåéæ¼¸å»ºç«ä½¿ç¨èçæç·ç¹å¾µãå¶æ¬¡ï¼æåå±ç¤ºäºä½¿ç¨èçæç·ç¹å¾µå¦ä½å¯ç¨ä½å¿çå¥åº·è©ä¼°çå¯è§£éæ¨è¨ãéäºç¹å¾µå¯ä»¥èèä¸åå¿çç¾çç¸éçå¸åæç·æ¨¡å¼é²è¡æ¯è¼ï¼æä¾äºä¸ç¨®åæ­¥ç¯©é¸åæ¯æçæ°æ¹æ³ã

##### **MobileNetV2: A lightweight classification model for home-based sleep apnea screening**
2412.19967v2 by Hui Pan, Yanxuan Yu, Jilun Ye, Xu Zhang

This study proposes a novel lightweight neural network model leveraging
features extracted from electrocardiogram (ECG) and respiratory signals for
early OSA screening. ECG signals are used to generate feature spectrograms to
predict sleep stages, while respiratory signals are employed to detect
sleep-related breathing abnormalities. By integrating these predictions, the
method calculates the apnea-hypopnea index (AHI) with enhanced accuracy,
facilitating precise OSA diagnosis.
  The method was validated on three publicly available sleep apnea databases:
the Apnea-ECG database, the UCDDB dataset, and the MIT-BIH Polysomnographic
database. Results showed an overall OSA detection accuracy of 0.978,
highlighting the model's robustness. Respiratory event classification achieved
an accuracy of 0.969 and an area under the receiver operating characteristic
curve (ROC-AUC) of 0.98. For sleep stage classification, in UCDDB dataset, the
ROC-AUC exceeded 0.85 across all stages, with recall for Sleep reaching 0.906
and specificity for REM and Wake states at 0.956 and 0.937, respectively.
  This study underscores the potential of integrating lightweight neural
networks with multi-signal analysis for accurate, portable, and cost-effective
OSA screening, paving the way for broader adoption in home-based and wearable
health monitoring systems.

æè¦ï¼æ¬ç ç©¶æåºä¸åæ°ç©çè¼éç´ç¥ç¶ç¶²è·¯æ¨¡åï¼å©ç¨å¾å¿é»å (ECG) åå¼å¸ä¿¡èä¸­æåçç¹å¾µï¼é²è¡æ©æ OSA ç¯©æª¢ãECG ä¿¡èç¨æ¼ç¢çç¹å¾µé »è­åï¼ä»¥é æ¸¬ç¡ç éæ®µï¼èå¼å¸ä¿¡èåç¨æ¼åµæ¸¬èç¡ç ç¸éçå¼å¸ç°å¸¸ãééæ´åéäºé æ¸¬ï¼æ­¤æ¹æ³è¨ç®åºå·ææ´é«ç²¾ç¢ºåº¦çå¼å¸ä¸­æ­¢ä½éæ°£ææ¸ (AHI)ï¼ä¿é²ç²¾ç¢ºç OSA è¨ºæ·ã
è©²æ¹æ³å·²å¨ä¸åå¬éçç¡ç å¼å¸ä¸­æ­¢çè³æåº«ä¸­é©è­ï¼å¼å¸ä¸­æ­¢ç-ECG è³æåº«ãUCDDB è³æéå MIT-BIH å¤éç¡ç ççæª¢æ¥è³æåº«ãçµæé¡¯ç¤ºæ´é« OSA æª¢æ¸¬æºç¢ºåº¦çº 0.978ï¼çªé¡¯äºè©²æ¨¡åçç©©å¥æ§ãå¼å¸äºä»¶åé¡çæºç¢ºåº¦éå° 0.969ï¼ä¸å¨åè©¦èæä½ç¹å¾µæ²ç· (ROC-AUC) ä¸æ¹çé¢ç©çº 0.98ãå°æ¼ç¡ç éæ®µåé¡ï¼å¨ UCDDB è³æéä¸­ï¼ææéæ®µç ROC-AUC åè¶é 0.85ï¼ç¡ç çå¬åçéå° 0.906ï¼è REM åæ¸éçæçç¹ç°æ§åå¥çº 0.956 å 0.937ã
æ¬ç ç©¶å¼·èª¿äºå°è¼éç´ç¥ç¶ç¶²è·¯èå¤ä¿¡èåææ´åçæ½åï¼ä»¥é²è¡æºç¢ºãå¯æå¼ä¸å·ææ¬æçç OSA ç¯©æª¢ï¼çºå¨å±å®¶åç©¿æ´å¼å¥åº·ç£æ¸¬ç³»çµ±ä¸­æ´å»£æ³æ¡ç¨éªè·¯ã

##### **ErgoChat: a Visual Query System for the Ergonomic Risk Assessment of Construction Workers**
2412.19954v1 by Chao Fan, Qipei Mei, Xiaonan Wang, Xinming Li

In the construction sector, workers often endure prolonged periods of
high-intensity physical work and prolonged use of tools, resulting in injuries
and illnesses primarily linked to postural ergonomic risks, a longstanding
predominant health concern. To mitigate these risks, researchers have applied
various technological methods to identify the ergonomic risks that construction
workers face. However, traditional ergonomic risk assessment (ERA) techniques
do not offer interactive feedback. The rapidly developing vision-language
models (VLMs), capable of generating textual descriptions or answering
questions about ergonomic risks based on image inputs, have not yet received
widespread attention. This research introduces an interactive visual query
system tailored to assess the postural ergonomic risks of construction workers.
The system's capabilities include visual question answering (VQA), which
responds to visual queries regarding workers' exposure to postural ergonomic
risks, and image captioning (IC), which generates textual descriptions of these
risks from images. Additionally, this study proposes a dataset designed for
training and testing such methodologies. Systematic testing indicates that the
VQA functionality delivers an accuracy of 96.5%. Moreover, evaluations using
nine metrics for IC and assessments from human experts indicate that the
proposed approach surpasses the performance of a method using the same
architecture trained solely on generic datasets. This study sets a new
direction for future developments in interactive ERA using generative
artificial intelligence (AI) technologies.

æè¦ï¼å¨å»ºç¯æ¥­ä¸­ï¼å·¥äººç¶å¸¸å¿åé·æéé«å¼·åº¦é«ååååé·æéä½¿ç¨å·¥å·ï¼å°è´åå·åç¾çï¼éäºåé¡ä¸»è¦èå§¿å¢äººé«å·¥å­¸é¢¨éªæéï¼éæ¯ä¸åé·æçä¸»è¦å¥åº·åé¡ãçºäºæ¸è¼éäºé¢¨éªï¼ç ç©¶äººå¡æç¨åç¨®æè¡æ¹æ³ä¾è­å¥å»ºç¯å·¥äººé¢è¨çäººé«å·¥å­¸é¢¨éªãç¶èï¼å³çµ±çäººé«å·¥å­¸é¢¨éªè©ä¼° (ERA) æè¡ä¸¦ä¸è½æä¾äºåå¼åé¥ãå¿«éç¼å±çè¦è¦ºèªè¨æ¨¡å (VLM) è½å¤ æ ¹æå½±åè¼¸å¥ç¢çæå­æè¿°æåç­æéäººé«å·¥å­¸é¢¨éªçåé¡ï¼ä½å°æªåå°å»£æ³éæ³¨ãæ¬ç ç©¶ä»ç´¹äºä¸åäºåå¼è¦è¦ºæ¥è©¢ç³»çµ±ï¼å°éç¨æ¼è©ä¼°å»ºç¯å·¥äººçå§¿å¢äººé«å·¥å­¸é¢¨éªãè©²ç³»çµ±çåè½åæ¬è¦è¦ºåç­ (VQA)ï¼å®å¯ä»¥åç­æéå·¥äººæ¥è§¸å§¿å¢äººé«å·¥å­¸é¢¨éªçè¦è¦ºæ¥è©¢ï¼ä»¥åå½±åæ¨é¡ (IC)ï¼å®å¯ä»¥æ ¹æå½±åç¢çéäºé¢¨éªçæå­æè¿°ãæ­¤å¤ï¼æ¬ç ç©¶æåºäºä¸åå°éç¨æ¼è¨ç·´åæ¸¬è©¦æ­¤é¡æ¹æ³çè³æéãç³»çµ±æ§æ¸¬è©¦è¡¨æï¼VQA åè½çæºç¢ºåº¦çº 96.5%ãæ­¤å¤ï¼ä½¿ç¨ä¹å IC ææ¨é²è¡çè©ä¼°åä¾èªäººé¡å°å®¶çè©ä¼°è¡¨æï¼ææåºçæ¹æ³è¶è¶äºä½¿ç¨ç¸åæ¶æ§åå¨éç¨è³æéä¸è¨ç·´çæ¹æ³çæè½ãæ¬ç ç©¶çºä½¿ç¨çæå¼äººå·¥æºæ§ (AI) æè¡çäºåå¼ ERA æªä¾ç¼å±è¨­å®äºä¸åæ°æ¹åã

##### **An Integrated Optimization and Deep Learning Pipeline for Predicting Live Birth Success in IVF Using Feature Optimization and Transformer-Based Models**
2412.19696v1 by Arezoo Borji, Hossam Haick, Birgit Pohn, Antonia Graf, Jana Zakall, S M Ragib Shahriar Islam, Gernot Kronreif, Daniel Kovatchki, Heinz Strohmer, Sepideh Hatamikia

In vitro fertilization (IVF) is a widely utilized assisted reproductive
technology, yet predicting its success remains challenging due to the
multifaceted interplay of clinical, demographic, and procedural factors. This
study develops a robust artificial intelligence (AI) pipeline aimed at
predicting live birth outcomes in IVF treatments. The pipeline uses anonymized
data from 2010 to 2018, obtained from the Human Fertilization and Embryology
Authority (HFEA). We evaluated the prediction performance of live birth success
as a binary outcome (success/failure) by integrating different feature
selection methods, such as principal component analysis (PCA) and particle
swarm optimization (PSO), with different traditional machine learning-based
classifiers including random forest (RF) and decision tree, as well as deep
learning-based classifiers including custom transformer-based model and a tab
transformer model with an attention mechanism. Our research demonstrated that
the best performance was achieved by combining PSO for feature selection with
the TabTransformer-based deep learning model, yielding an accuracy of 99.50%
and an AUC of 99.96%, highlighting its significant performance to predict live
births. This study establishes a highly accurate AI pipeline for predicting
live birth outcomes in IVF, demonstrating its potential to enhance personalized
fertility treatments.

æè¦ï¼é«å¤åç²¾ (IVF) æ¯ä¸ç¨®å»£æ³ä½¿ç¨çè¼å©çæ®æè¡ï¼ä½ç±æ¼è¨åºãäººå£çµ±è¨åç¨åºå ç´ çå¤æ¹é¢äº¤äºä½ç¨ï¼é æ¸¬å¶æåä»ç¶å·æææ°æ§ãæ¬ç ç©¶éç¼äºä¸åå¼·å¤§çäººå·¥æºæ§ (AI) ç®¡ç·ï¼æ¨å¨é æ¸¬ IVF æ²»çä¸­çæ´»ç¢çµæãè©²ç®¡ç·ä½¿ç¨ 2010 å¹´è³ 2018 å¹´çå¿åæ¸æï¼éäºæ¸æä¾èªäººé¡åç²¾åèèå­¸ç®¡çå± (HFEA)ãæåééæ´åä¸åçç¹å¾µé¸ææ¹æ³ï¼ä¾å¦ä¸»æååæ (PCA) åç²å­ç¾¤åªå (PSO)ï¼ä»¥åä¸åçå³çµ±æ©å¨å­¸ç¿åé¡å¨ï¼åæ¬é¨æ©æ£®æ (RF) åæ±ºç­æ¨¹ï¼ï¼ä»¥åæ·±åº¦å­¸ç¿åé¡å¨ï¼åæ¬èªå®ç¾©Transformeræ¨¡ååå·ææ³¨æåæ©å¶ç Tab Transformeræ¨¡åï¼ï¼ä¾è©ä¼°æ´»ç¢æåçé æ¸¬æ§è½ï¼ä½çºäºåçµæï¼æå/å¤±æï¼ãæåçç ç©¶è¡¨æï¼ééå° PSO ç¨æ¼ç¹å¾µé¸æèåºæ¼ TabTransformer çæ·±åº¦å­¸ç¿æ¨¡åç¸çµåï¼å¯ä»¥ç²å¾æä½³æ§è½ï¼æºç¢ºçéå° 99.50%ï¼AUC éå° 99.96%ï¼çªé¡¯äºå¶é æ¸¬æ´»ç¢çé¡¯èæ§è½ãæ¬ç ç©¶å»ºç«äºä¸åé«åº¦æºç¢ºç AI ç®¡ç·ï¼ç¨æ¼é æ¸¬ IVF ä¸­çæ´»ç¢çµæï¼å±ç¤ºäºå¶å¢å¼·åæ§åçè²æ²»ççæ½åã

##### **A Review on the Integration of Artificial Intelligence and Medical Imaging in IVF Ovarian Stimulation**
2412.19688v1 by Jana Zakall, Birgit Pohn, Antonia Graf, Daniel Kovatchki, Arezoo Borji, Ragib Shahriar Islam, Hossam Haick, Heinz Strohmer, Sepideh Hatamikia

Artificial intelligence (AI) has emerged as a powerful tool to enhance
decision-making and optimize treatment protocols in in vitro fertilization
(IVF). In particular, AI shows significant promise in supporting
decision-making during the ovarian stimulation phase of the IVF process. This
review evaluates studies focused on the applications of AI combined with
medical imaging in ovarian stimulation, examining methodologies, outcomes, and
current limitations. Our analysis of 13 studies on this topic reveals that,
reveal that while AI algorithms demonstrated notable potential in predicting
optimal hormonal dosages, trigger timing, and oocyte retrieval outcomes, the
medical imaging data utilized predominantly came from two-dimensional (2D)
ultrasound which mainly involved basic quantifications, such as follicle size
and number, with limited use of direct feature extraction or advanced image
analysis techniques. This points to an underexplored opportunity where advanced
image analysis approaches, such as deep learning, and more diverse imaging
modalities, like three-dimensional (3D) ultrasound, could unlock deeper
insights. Additionally, the lack of explainable AI (XAI) in most studies raises
concerns about the transparency and traceability of AI-driven decisions - key
factors for clinical adoption and trust. Furthermore, many studies relied on
single-center designs and small datasets, which limit the generalizability of
their findings. This review highlights the need for integrating advanced
imaging analysis techniques with explainable AI methodologies, as well as the
importance of leveraging multicenter collaborations and larger datasets.
Addressing these gaps has the potential to enhance ovarian stimulation
management, paving the way for efficient, personalized, and data-driven
treatment pathways that improve IVF outcomes.

æè¦ï¼äººå·¥æºæ§ï¼AIï¼å·²æçºå¢å¼·é«å¤åç²¾ï¼IVFï¼æ±ºç­å¶å®ååªåæ²»çæ¹æ¡çå¼·å¤§å·¥å·ãç¹å¥æ¯ï¼AI å¨æ¯æ IVF éç¨ä¸­åµå·¢åºæ¿éæ®µçæ±ºç­å¶å®æ¹é¢é¡¯ç¤ºåºé¡¯èçåæ¯ãæ¬ç¶è¿°è©ä¼°äºå°æ³¨æ¼ AI çµååµå·¢åºæ¿ä¸­çé«å­¸å½±åæç¨ãæª¢é©æ¹æ³ãçµæåç¶åéå¶çç ç©¶ãæåå° 13 é éæ¼æ­¤ä¸»é¡çç ç©¶åæé¡¯ç¤ºï¼éç¶ AI æ¼ç®æ³å¨é æ¸¬æä½³è·ç¾èåéãè§¸ç¼ææ©ååµå­ååºçµææ¹é¢è¡¨ç¾åºé¡¯èçæ½åï¼ä½æå©ç¨çé«å­¸å½±åæ¸æä¸»è¦ä¾èªæ¼äºæ¬¡åï¼2Dï¼è¶é³æ³¢ï¼èäºæ¬¡åè¶é³æ³¢ä¸»è¦æ¶ååºæ¬éåï¼ä¾å¦æ¿¾æ³¡å¤§å°åæ¸éï¼ä¸æéä½¿ç¨ç´æ¥ç¹å¾µæåæé²éå½±ååææè¡ãéæåä¸åå°æªæ¢ç´¢çæ©æï¼ä¾å¦æ·±åº¦å­¸ç¿ç­é²éå½±ååææ¹æ³ï¼ä»¥åæ´å¤åçå½±åæ¨¡å¼ï¼ä¾å¦ä¸ç¶­ï¼3Dï¼è¶é³æ³¢ï¼å¯ä»¥è§£éæ´æ·±å¥çè¦è§£ãæ­¤å¤ï¼å¤§å¤æ¸ç ç©¶ç¼ºä¹å¯è§£é AIï¼XAIï¼ï¼éå¼èµ·äºäººåå° AI é©åæ±ºç­çéæåº¦åå¯è¿½æº¯æ§çææï¼èéæåº¦åå¯è¿½æº¯æ§æ¯è¨åºæ¡ç¨åä¿¡ä»»çééµå ç´ ãæ­¤å¤ï¼è¨±å¤ç ç©¶ä¾è³´æ¼å®ä¸­å¿è¨­è¨åå°åæ¸æéï¼ééå¶äºå¶ç¼ç¾çæ®éæ§ãæ¬ç¶è¿°å¼·èª¿äºå°é²éå½±ååææè¡èå¯è§£é AI æ¹æ³æ´åèµ·ä¾çå¿è¦æ§ï¼ä»¥åå©ç¨å¤ä¸­å¿åä½åå¤§åæ¸æéçéè¦æ§ãè§£æ±ºéäºå·®è·æå¯è½å¢å¼·åµå·¢åºæ¿ç®¡çï¼çºææãåäººååæ¸æé©åçæ²»çéå¾éªå¹³éè·¯ï¼é²èæ¹å IVF çµæã

##### **Disparate Model Performance and Stability in Machine Learning Clinical Support for Diabetes and Heart Diseases**
2412.19495v1 by Ioannis Bilionis, Ricardo C. Berrios, Luis Fernandez-Luque, Carlos Castillo

Machine Learning (ML) algorithms are vital for supporting clinical
decision-making in biomedical informatics. However, their predictive
performance can vary across demographic groups, often due to the
underrepresentation of historically marginalized populations in training
datasets. The investigation reveals widespread sex- and age-related inequities
in chronic disease datasets and their derived ML models. Thus, a novel
analytical framework is introduced, combining systematic arbitrariness with
traditional metrics like accuracy and data complexity. The analysis of data
from over 25,000 individuals with chronic diseases revealed mild sex-related
disparities, favoring predictive accuracy for males, and significant
age-related differences, with better accuracy for younger patients. Notably,
older patients showed inconsistent predictive accuracy across seven datasets,
linked to higher data complexity and lower model performance. This highlights
that representativeness in training data alone does not guarantee equitable
outcomes, and model arbitrariness must be addressed before deploying models in
clinical settings.

æè¦ï¼æ©å¨å­¸ç¿ (ML) æ¼ç®æ³å°æ¼æ¯æ´çç©é«å­¸è³è¨å­¸ä¸­çè¨åºæ±ºç­è³ééè¦ãç¶èï¼å¶é æ¸¬æè½å¯è½å äººå£çµ±è¨ç¾¤çµèç°ï¼éå¸¸æ¯å çºå¨è¨ç·´è³æéä¸­æ­·å²ä¸è¢«éç·£åçæç¾¤ä»£è¡¨æ§ä¸è¶³ãèª¿æ¥é¡¯ç¤ºï¼å¨æ¢æ§ç¾çè³æéåå¶è¡çç ML æ¨¡åä¸­ï¼æ®éå­å¨èæ§å¥åå¹´é½¡ç¸éçä¸å¹³ç­ãå æ­¤ï¼å¼é²äºä¸åæ°ç©çåææ¶æ§ï¼å°ç³»çµ±æ§çä»»ææ§èå³çµ±ææ¨ï¼ä¾å¦æºç¢ºåº¦åè³æè¤éåº¦ï¼çµåå¨ä¸èµ·ãå°ä¾èª 25,000 å¤åæ¢æ§çæ£èçè³æé²è¡åæï¼ç¼ç¾è¼å¾®çæ§å¥ç¸éå·®ç°ï¼æå©æ¼ç·æ§é æ¸¬æºç¢ºåº¦ï¼ä»¥åé¡¯èçå¹´é½¡ç¸éå·®ç°ï¼å¹´è¼æ£èçæºç¢ºåº¦è¼é«ãå¼å¾æ³¨æçæ¯ï¼èå¹´æ£èå¨ä¸åè³æéä¸­é¡¯ç¤ºåºä¸ä¸è´çé æ¸¬æºç¢ºåº¦ï¼éèè¼é«çè³æè¤éåº¦åè¼ä½çæ¨¡åæè½æéãéçªé¡¯åºè¨ç·´è³æä¸­çä»£è¡¨æ§ä¸¦ä¸è½ä¿è­å¬å¹³ççµæï¼å¨è¨åºç°å¢ä¸­é¨ç½²æ¨¡åä¹åå¿é è§£æ±ºæ¨¡åçä»»ææ§ã

##### **Semi-Supervised Learning from Small Annotated Data and Large Unlabeled Data for Fine-grained PICO Entity Recognition**
2412.19346v1 by Fangyi Chen, Gongbo Zhang, Yilu Fang, Yifan Peng, Chunhua Weng

Objective: Extracting PICO elements -- Participants, Intervention,
Comparison, and Outcomes -- from clinical trial literature is essential for
clinical evidence retrieval, appraisal, and synthesis. Existing approaches do
not distinguish the attributes of PICO entities. This study aims to develop a
named entity recognition (NER) model to extract PICO entities with fine
granularities.
  Materials and Methods: Using a corpus of 2,511 abstracts with PICO mentions
from 4 public datasets, we developed a semi-supervised method to facilitate the
training of a NER model, FinePICO, by combining limited annotated data of PICO
entities and abundant unlabeled data. For evaluation, we divided the entire
dataset into two subsets: a smaller group with annotations and a larger group
without annotations. We then established the theoretical lower and upper
performance bounds based on the performance of supervised learning models
trained solely on the small, annotated subset and on the entire set with
complete annotations, respectively. Finally, we evaluated FinePICO on both the
smaller annotated subset and the larger, initially unannotated subset. We
measured the performance of FinePICO using precision, recall, and F1.
  Results: Our method achieved precision/recall/F1 of 0.567/0.636/0.60,
respectively, using a small set of annotated samples, outperforming the
baseline model (F1: 0.437) by more than 16\%. The model demonstrates
generalizability to a different PICO framework and to another corpus, which
consistently outperforms the benchmark in diverse experimental settings
(p-value \textless0.001).
  Conclusion: This study contributes a generalizable and effective
semi-supervised approach to named entity recognition leveraging large unlabeled
data together with small, annotated data. It also initially supports
fine-grained PICO extraction.

æè¦ï¼<paragraph>ç®æ¨ï¼å¾è¨åºè©¦é©æç»ä¸­èå PICO åç´ ï¼åèèãå¹²é æªæ½ãæ¯è¼åçµæï¼ï¼å°æ¼è¨åºè­æçæª¢ç´¢ãè©ä¼°åç¶åè³ééè¦ãç¾ææ¹æ³ç¡æ³åå PICO å¯¦é«çå±¬æ§ãæ¬ç ç©¶æ¨å¨éç¼ä¸åå½åå¯¦é«è¾¨è­ (NER) æ¨¡åï¼ä»¥ç²¾ç´°ç²åº¦èå PICO å¯¦é«ã
ææåæ¹æ³ï¼ä½¿ç¨åå«ä¾èª 4 åå¬éè³æéç 2,511 ç¯æè¦çèªæåº«ï¼æåéç¼äºä¸ç¨®åç£ç£å¼æ¹æ³ï¼ééçµåæéç PICO å¯¦é«æ¨è¨»è³æåè±å¯çæªæ¨è¨»è³æï¼ä¾ä¿é² NER æ¨¡å FinePICO çè¨ç·´ãçºäºé²è¡è©ä¼°ï¼æåå°æ´åè³æéåçºå©åå­éï¼ä¸åè¼å°çææ¨è¨»ç¾¤çµåä¸åè¼å¤§çç¡æ¨è¨»ç¾¤çµãç¶å¾ï¼æååå¥æ ¹æåå¨å°æ¨è¨»å­éä¸è¨ç·´çç£ç£å¼å­¸ç¿æ¨¡ååå¨å·æå®æ´æ¨è¨»çæ´åéåä¸è¨ç·´çç£ç£å¼å­¸ç¿æ¨¡åçæè½ï¼å»ºç«çè«ä¸çä¸éåä¸éæè½çç·ãæå¾ï¼æåå¨è¼å°çæ¨è¨»å­éåè¼å¤§çæåæªæ¨è¨»å­éä¸è©ä¼° FinePICOãæåä½¿ç¨æºç¢ºåº¦ãå¬åçå F1 ä¾è¡¡é FinePICO çæè½ã
çµæï¼æåçæ¨¡åä½¿ç¨ä¸å°çµæ¨è¨»æ¨£æ¬ï¼åå¥éå° 0.567/0.636/0.60 çæºç¢ºåº¦/å¬åç/F1ï¼æ¯åºç·æ¨¡å (F1ï¼0.437) é«åº 16% ä»¥ä¸ãè©²æ¨¡åå±ç¤ºäºå°ä¸å PICO æ¶æ§åå¦ä¸åèªæåº«çæ³åæ§ï¼å¨ä¸åçå¯¦é©è¨­å®ä¸­å§çµåªæ¼åºæº (p å¼ \textless0.001)ã
çµè«ï¼æ¬ç ç©¶è²¢ç»äºä¸ç¨®å¯æ³åä¸ææçåç£ç£å¼æ¹æ³ï¼å©ç¨å¤§éæªæ¨è¨»è³æåå°éæ¨è¨»è³æä¾é²è¡å½åå¯¦é«è¾¨è­ãå®æåä¹æ¯æ´ç²¾ç´°ç²åº¦ç PICO èåã</paragraph>

##### **xSRL: Safety-Aware Explainable Reinforcement Learning -- Safety as a Product of Explainability**
2412.19311v1 by Risal Shahriar Shefin, Md Asifur Rahman, Thai Le, Sarra Alqahtani

Reinforcement learning (RL) has shown great promise in simulated
environments, such as games, where failures have minimal consequences. However,
the deployment of RL agents in real-world systems such as autonomous vehicles,
robotics, UAVs, and medical devices demands a higher level of safety and
transparency, particularly when facing adversarial threats. Safe RL algorithms
have been developed to address these concerns by optimizing both task
performance and safety constraints. However, errors are inevitable, and when
they occur, it is essential that the RL agents can also explain their actions
to human operators. This makes trust in the safety mechanisms of RL systems
crucial for effective deployment. Explainability plays a key role in building
this trust by providing clear, actionable insights into the agent's
decision-making process, ensuring that safety-critical decisions are well
understood. While machine learning (ML) has seen significant advances in
interpretability and visualization, explainability methods for RL remain
limited. Current tools fail to address the dynamic, sequential nature of RL and
its needs to balance task performance with safety constraints over time. The
re-purposing of traditional ML methods, such as saliency maps, is inadequate
for safety-critical RL applications where mistakes can result in severe
consequences. To bridge this gap, we propose xSRL, a framework that integrates
both local and global explanations to provide a comprehensive understanding of
RL agents' behavior. xSRL also enables developers to identify policy
vulnerabilities through adversarial attacks, offering tools to debug and patch
agents without retraining. Our experiments and user studies demonstrate xSRL's
effectiveness in increasing safety in RL systems, making them more reliable and
trustworthy for real-world deployment. Code is available at
https://github.com/risal-shefin/xSRL.

æè¦ï¼å¼·åå­¸ç¿ (RL) å¨æ¨¡æ¬ç°å¢ä¸­å±ç¾åºæ¥µå¤§çæ½åï¼ä¾å¦éæ²ï¼å¨éäºç°å¢ä¸­ï¼å¤±æçå¾æå¾å°ãç¶èï¼å¨èªåé§é§æ±½è»ãæ©å¨äººãç¡äººæ©åé«çè¨­åç­çå¯¦ä¸çç³»çµ±ä¸­é¨ç½² RL ä»£çéè¦æ´é«çå®å¨æ§èéæåº¦ï¼ç¹å¥æ¯å¨é¢å°å°ææ§å¨èæãå®å¨ç RL æ¼ç®æ³å·²è¢«éç¼åºä¾ï¼ééæä½³åä»»åæè½åå®å¨éå¶ä¾è§£æ±ºéäºåé¡ãç¶èï¼é¯èª¤æ¯ä¸å¯é¿åçï¼ç¶é¯èª¤ç¼çæï¼RL ä»£çä¹å¿é åäººé¡æä½å¡è§£éå¶è¡çºè³ééè¦ãéä½¿å¾å° RL ç³»çµ±çå®å¨æ©å¶çä¿¡ä»»å°æ¼ææé¨ç½²è³ééè¦ãå¯è§£éæ§å¨å»ºç«éç¨®ä¿¡ä»»ä¸­æ®æ¼ééµè§è²ï¼ééæä¾å°ä»£çæ±ºç­éç¨æ¸æ°ä¸å¯è¡çè¦è§£ï¼ç¢ºä¿å°å®å¨è³ééè¦çæ±ºç­è½è¢«ååçè§£ãéç¶æ©å¨å­¸ç¿ (ML) å¨å¯è§£éæ§åå¯è¦åæ¹é¢å·²åå¾é¡¯èé²å±ï¼ä½ RL çå¯è§£éæ§æ¹æ³ä»ç¶æéãç®åçå·¥å·ç¡æ³è§£æ±º RL çåæãé åºæ§è³ªï¼ä»¥åå®éè¦é¨èæéæ¨ç§»å¹³è¡¡ä»»åæè½èå®å¨éå¶ãéæ°å©ç¨å³çµ±ç ML æ¹æ³ï¼ä¾å¦é¡¯èæ§åï¼å°æ¼å®å¨è³ééè¦ç RL æç¨ç¨å¼ä¾èªªæ¯ä¸å¤ çï¼å¨éäºæç¨ç¨å¼ä¸­ï¼é¯èª¤å¯è½å°è´å´éçå¾æãçºäºå½è£éä¸å·®è·ï¼æåæåºäº xSRLï¼ä¸åæ´åäºå±é¨åå¨å±è§£éçæ¡æ¶ï¼ä»¥æä¾å° RL ä»£çè¡çºçå¨é¢çè§£ãxSRL éä½¿éç¼äººå¡è½å¤ ééå°ææ§æ»æä¾è­å¥ç­ç¥æ¼æ´ï¼æä¾å¨ä¸éæ°è¨ç·´çææ³ä¸é¤é¯åä¿®è£ä»£ççå·¥å·ãæåçå¯¦é©åä½¿ç¨èç ç©¶è­æäº xSRL å¨æé« RL ç³»çµ±å®å¨æ§çæææ§ï¼ä½¿å¶æ´å¯é ä¸æ´å¼å¾ä¿¡è³´ï¼å¯é¨ç½²æ¼çå¯¦ä¸çãç¨å¼ç¢¼å¯å¨ https://github.com/risal-shefin/xSRL ä¸­åå¾ã

##### **MEDEC: A Benchmark for Medical Error Detection and Correction in Clinical Notes**
2412.19260v2 by Asma Ben Abacha, Wen-wai Yim, Yujuan Fu, Zhaoyi Sun, Meliha Yetisgen, Fei Xia, Thomas Lin

Several studies showed that Large Language Models (LLMs) can answer medical
questions correctly, even outperforming the average human score in some medical
exams. However, to our knowledge, no study has been conducted to assess the
ability of language models to validate existing or generated medical text for
correctness and consistency. In this paper, we introduce MEDEC
(https://github.com/abachaa/MEDEC), the first publicly available benchmark for
medical error detection and correction in clinical notes, covering five types
of errors (Diagnosis, Management, Treatment, Pharmacotherapy, and Causal
Organism). MEDEC consists of 3,848 clinical texts, including 488 clinical notes
from three US hospital systems that were not previously seen by any LLM. The
dataset has been used for the MEDIQA-CORR shared task to evaluate seventeen
participating systems [Ben Abacha et al., 2024]. In this paper, we describe the
data creation methods and we evaluate recent LLMs (e.g., o1-preview, GPT-4,
Claude 3.5 Sonnet, and Gemini 2.0 Flash) for the tasks of detecting and
correcting medical errors requiring both medical knowledge and reasoning
capabilities. We also conducted a comparative study where two medical doctors
performed the same task on the MEDEC test set. The results showed that MEDEC is
a sufficiently challenging benchmark to assess the ability of models to
validate existing or generated notes and to correct medical errors. We also
found that although recent LLMs have a good performance in error detection and
correction, they are still outperformed by medical doctors in these tasks. We
discuss the potential factors behind this gap, the insights from our
experiments, the limitations of current evaluation metrics, and share potential
pointers for future research.

æè¦ï¼å¤é ç ç©¶é¡¯ç¤ºï¼å¤§åèªè¨æ¨¡å (LLM) è½æ­£ç¢ºåç­é«çåé¡ï¼çè³å¨æäºé«çèè©¦ä¸­è¡¨ç¾åªæ¼äººé¡å¹³ååæ¸ãç¶èï¼ææåæç¥ï¼å°æªæç ç©¶è©ä¼°èªè¨æ¨¡åé©è­ç¾ææç¢ççé«çææ¬æ­£ç¢ºæ§åä¸è´æ§çè½åãå¨æ¬æä¸­ï¼æåä»ç´¹ MEDEC (https://github.com/abachaa/MEDEC)ï¼éæ¯ç¬¬ä¸åå¬éçè¨åºç­è¨é«çé¯èª¤åµæ¸¬åä¿®æ­£åºæºï¼æ¶µèäºç¨®é¡åçé¯èª¤ï¼è¨ºæ·ãç®¡çãæ²»çãè¥ç©æ²»çåè´çåï¼ãMEDEC åå« 3,848 åè¨åºææ¬ï¼åæ¬ä¾èªä¸åç¾åé«é¢ç³»çµ±ç 488 åè¨åºç­è¨ï¼éäºç­è¨ä»¥åæªæ¾è¢«ä»»ä½ LLM çå°ãè©²è³æéå·²ç¨æ¼ MEDIQA-CORR å±äº«ä»»åï¼ä»¥è©ä¼°åä¸ååèç³»çµ± [Ben Abacha ç­ï¼2024]ãå¨æ¬æä¸­ï¼æåæè¿°äºè³æå»ºç«æ¹æ³ï¼ä¸¦è©ä¼°äºè¿æ LLMï¼ä¾å¦ o1-previewãGPT-4ãClaude 3.5 Sonnet å Gemini 2.0 Flashï¼å¨åµæ¸¬åä¿®æ­£é«çé¯èª¤çä»»åä¸ï¼éäºä»»åéè¦é«çç¥è­åæ¨çè½åãæåéé²è¡äºä¸é æ¯è¼ç ç©¶ï¼å¶ä¸­å©ä½é«çå¨ MEDEC æ¸¬è©¦éä¸­å·è¡ç¸åçä»»åãçµæé¡¯ç¤ºï¼MEDEC æ¯è¶³å¤ å·æææ°æ§çåºæºï¼å¯ä»¥è©ä¼°æ¨¡åé©è­ç¾ææç¢ççç­è¨åä¿®æ­£é«çé¯èª¤çè½åãæåéç¼ç¾ï¼åç®¡è¿æ LLM å¨é¯èª¤åµæ¸¬åä¿®æ­£æ¹é¢è¡¨ç¾è¯å¥½ï¼ä½å¨éäºä»»åä¸­ä»ä¸å¦é«çãæåè¨è«äºé ææ­¤å·®è·çæ½å¨å ç´ ãæåå¯¦é©çè¦è§£ãç¶åè©ä¼°ææ¨çéå¶ï¼ä¸¦åäº«äºæªä¾ç ç©¶çæ½å¨ææ¨ã

##### **Leveraging Self-Training and Variational Autoencoder for Agitation Detection in People with Dementia Using Wearable Sensors**
2412.19254v1 by Abeer Badawi, Somayya Elmoghazy, Samira Choudhury, Khalid Elgazzar, Amer Burhan

Dementia is a neurodegenerative disorder that has been growing among elder
people over the past decades. This growth profoundly impacts the quality of
life for patients and caregivers due to the symptoms arising from it. Agitation
and aggression (AA) are some of the symptoms of people with severe dementia
(PwD) in long-term care or hospitals. AA not only causes discomfort but also
puts the patients or others at potential risk. Existing monitoring solutions
utilizing different wearable sensors integrated with Artificial Intelligence
(AI) offer a way to detect AA early enough for timely and adequate medical
intervention. However, most studies are limited by the availability of
accurately labeled datasets, which significantly affects the efficacy of such
solutions in real-world scenarios. This study presents a novel comprehensive
approach to detect AA in PwD using physiological data from the Empatica E4
wristbands. The research creates a diverse dataset, consisting of three
distinct datasets gathered from 14 participants across multiple hospitals in
Canada. These datasets have not been extensively explored due to their limited
labeling. We propose a novel approach employing self-training and a variational
autoencoder (VAE) to detect AA in PwD effectively. The proposed approach aims
to learn the representation of the features extracted using the VAE and then
uses a semi-supervised block to generate labels, classify events, and detect
AA. We demonstrate that combining Self-Training and Variational Autoencoder
mechanism significantly improves model performance in classifying AA in PwD.
Among the tested techniques, the XGBoost classifier achieved the highest
accuracy of 90.16\%. By effectively addressing the challenge of limited labeled
data, the proposed system not only learns new labels but also proves its
superiority in detecting AA.

æè¦ï¼å¤±æºçæ¯ä¸ç¨®ç¥ç¶éåæ§ç¾çï¼å¨éå»çå¹¾åå¹´ä¸­å¨èå¹´äººä¸­ä¸æ·å¢å ãéç¨®å¢é·æå°æ£èåç§é¡§èççæ´»åè³ªç¢çæ·±é çå½±é¿ï¼å çºå®æç¢çççãèºååæ»ææ§ (AA) æ¯éåº¦å¤±æºçæ£è (PwD) å¨é·æç§è­·æé«é¢ä¸­çççä¹ä¸ãAA ä¸åæé æä¸é©ï¼éæè®æ£èæä»äººé¢è¨æ½å¨é¢¨éªãç¾æçç£æ§è§£æ±ºæ¹æ¡å©ç¨èäººå·¥æºæ§ (AI) æ´åçä¸åç©¿æ´å¼ææ¸¬å¨ï¼æä¾ä¸ç¨®æ¹æ³ä¾åæ©åµæ¸¬ AAï¼ä»¥ä¾¿åæä¸ååå°é²è¡é«çä»å¥ãç¶èï¼å¤§å¤æ¸ç ç©¶é½åå°æºç¢ºæ¨è¨è³æéå¯ç¨æ§çéå¶ï¼éæé¡¯èå½±é¿æ­¤é¡è§£æ±ºæ¹æ¡å¨å¯¦éææ³ä¸­çæè½ãæ¬ç ç©¶æåºäºä¸ç¨®æ°ç©çç¶åæ¹æ³ï¼ä½¿ç¨ä¾èª Empatica E4 èå¸¶çççæ¸æä¾åµæ¸¬ PwD ä¸­ç AAãè©²ç ç©¶å»ºç«äºä¸åå¤åçè³æéï¼ç±ä¾èªå æ¿å¤§å¤å®¶é«é¢ç 14 ä½åèèæ¶éçä¸åä¸åè³æéçµæãç±æ¼æ¨è¨æéï¼å°æªå»£æ³æ¢è¨éäºè³æéãæåæåºäºä¸ç¨®æ°ç©çæ¹æ³ï¼æ¡ç¨èªæè¨ç·´åè®ç°èªåç·¨ç¢¼å¨ (VAE) ä¾ææåµæ¸¬ PwD ä¸­ç AAãææåºçæ¹æ³æ¨å¨å­¸ç¿ä½¿ç¨ VAE èåç¹å¾µçè¡¨ç¤ºï¼ç¶å¾ä½¿ç¨åç£ç£åå¡ä¾ç¢çæ¨ç±¤ãåé¡äºä»¶ä¸¦åµæ¸¬ AAãæåè­æäºå°èªæè¨ç·´åè®ç°èªåç·¨ç¢¼å¨æ©å¶çµåèµ·ä¾ï¼å¯ä»¥é¡¯èæåæ¨¡åå¨å° PwD ä¸­ç AA é²è¡åé¡æçæè½ãå¨æ¸¬è©¦çæè¡ä¸­ï¼XGBoost åé¡å¨éå°äº 90.16% çæé«æºç¢ºåº¦ãééææå°è§£æ±ºæ¨è¨è³ææéçææ°ï¼ææåºçç³»çµ±ä¸åå­¸ç¿äºæ°çæ¨ç±¤ï¼éè­æäºå¶å¨åµæ¸¬ AA æ¹é¢çåªè¶æ§ã

##### **Evaluating Self-Supervised Learning in Medical Imaging: A Benchmark for Robustness, Generalizability, and Multi-Domain Impact**
2412.19124v1 by Valay Bundele, OÄuz Ata Ãal, Bora Kargi, Karahan SarÄ±taÅ, KÄ±vanÃ§ TezÃ¶ren, Zohreh Ghaderi, Hendrik Lensch

Self-supervised learning (SSL) has emerged as a promising paradigm in medical
imaging, addressing the chronic challenge of limited labeled data in healthcare
settings. While SSL has shown impressive results, existing studies in the
medical domain are often limited in scope, focusing on specific datasets or
modalities, or evaluating only isolated aspects of model performance. This
fragmented evaluation approach poses a significant challenge, as models
deployed in critical medical settings must not only achieve high accuracy but
also demonstrate robust performance and generalizability across diverse
datasets and varying conditions. To address this gap, we present a
comprehensive evaluation of SSL methods within the medical domain, with a
particular focus on robustness and generalizability. Using the MedMNIST dataset
collection as a standardized benchmark, we evaluate 8 major SSL methods across
11 different medical datasets. Our study provides an in-depth analysis of model
performance in both in-domain scenarios and the detection of
out-of-distribution (OOD) samples, while exploring the effect of various
initialization strategies, model architectures, and multi-domain pre-training.
We further assess the generalizability of SSL methods through cross-dataset
evaluations and the in-domain performance with varying label proportions (1%,
10%, and 100%) to simulate real-world scenarios with limited supervision. We
hope this comprehensive benchmark helps practitioners and researchers make more
informed decisions when applying SSL methods to medical applications.

æè¦ï¼èªæç£ç£å­¸ç¿ (SSL) å·²æçºé«å­¸å½±åä¸­ä¸åæåéçç¯ä¾ï¼ç¨æ¼è§£æ±ºé«çä¿å¥ç°å¢ä¸­æ¨ç±¤è³ææéçé·æææ°ãéç¶ SSL å·²å±ç¾ä»¤äººå°è±¡æ·±å»ççµæï¼ä½é«å­¸é åä¸­çç¾æç ç©¶éå¸¸ç¯åæéï¼å°æ³¨æ¼ç¹å®è³æéææ¹å¼ï¼æåè©ä¼°æ¨¡åæè½çå­¤ç«é¢åãéç¨®çæ®µåçè©ä¼°æ¹å¼æ§æéå¤§ææ°ï¼å çºå¨ééµé«çç°å¢ä¸­é¨ç½²çæ¨¡åä¸åå¿é éå°é«æºç¢ºåº¦ï¼éå¿é å±ç¾å¼·å¥çæè½åè·¨ä¸åè³æéåä¸åæ¢ä»¶çä¸è¬åè½åãçºäºè§£æ±ºéåå·®è·ï¼æåéå°é«å­¸é åä¸­ç SSL æ¹æ³æåºå¨é¢çè©ä¼°ï¼ç¹å¥èéæ¼å¼·å¥æ§åä¸è¬åè½åãä½¿ç¨ MedMNIST è³æééåä½çºæ¨æºåºæºï¼æåå¨ 11 åä¸åçé«å­¸è³æéä¸è©ä¼° 8 ç¨®ä¸»è¦ç SSL æ¹æ³ãæåçç ç©¶æ·±å¥åæäºæ¨¡åå¨é åå§æå¢ååµæ¸¬åä½å¤ (OOD) æ¨£æ¬ä¸­çæè½ï¼åææ¢ç´¢åç¨®åå§åç­ç¥ãæ¨¡åæ¶æ§åå¤é åé è¨ç·´çå½±é¿ãæåé²ä¸æ­¥ééè·¨è³æéè©ä¼°åå¨ä¸åæ¨ç±¤æ¯ä¾ (1%ã10% å 100%) ä¸çé åå§æè½è©ä¼° SSL æ¹æ³çä¸è¬åè½åï¼ä»¥æ¨¡æ¬ç£ç£æéççå¯¦ä¸çæå¢ãæåå¸æéåå¨é¢çåºæºè½å¹«å©å¾æ¥­äººå¡åç ç©¶äººå¡å¨å° SSL æ¹æ³æç¨æ¼é«çæç¨æååºæ´ææºçæ±ºç­ã

##### **Modality-Projection Universal Model for Comprehensive Full-Body Medical Imaging Segmentation**
2412.19026v1 by Yixin Chen, Lin Gao, Yajuan Gao, Rui Wang, Jingge Lian, Xiangxi Meng, Yanhua Duan, Leiying Chai, Hongbin Han, Zhaoping Cheng, Zhaoheng Xie

The integration of deep learning in medical imaging has shown great promise
for enhancing diagnostic, therapeutic, and research outcomes. However, applying
universal models across multiple modalities remains challenging due to the
inherent variability in data characteristics. This study aims to introduce and
evaluate a Modality Projection Universal Model (MPUM). MPUM employs a novel
modality-projection strategy, which allows the model to dynamically adjust its
parameters to optimize performance across different imaging modalities. The
MPUM demonstrated superior accuracy in identifying anatomical structures,
enabling precise quantification for improved clinical decision-making. It also
identifies metabolic associations within the brain-body axis, advancing
research on brain-body physiological correlations. Furthermore, MPUM's unique
controller-based convolution layer enables visualization of saliency maps
across all network layers, significantly enhancing the model's
interpretability.

æè¦ï¼æ·±åº¦å­¸ç¿å¨é«å­¸å½±åä¸­çæ´åå·²å±ç¾åºæ¥µå¤§çåæ¯ï¼ç¨æ¼å¢å¼·è¨ºæ·ãæ²»çåç ç©¶ææãç¶èï¼ç±æ¼è³æç¹æ§çå§å¨è®ç°æ§ï¼å¨å¤ç¨®æ¹å¼ä¸­æç¨éç¨æ¨¡åä»ç¶å·æææ°æ§ãæ¬ç ç©¶æ¨å¨ä»ç´¹åè©ä¼°æ¹å¼æå½±éç¨æ¨¡å (MPUM)ãMPUM æ¡ç¨ä¸ç¨®æ°ç©çæ¹å¼æå½±ç­ç¥ï¼ä½¿æ¨¡åè½å¤ åæèª¿æ´å¶åæ¸ï¼ä»¥åªåä¸åå½±åæ¹å¼çæè½ãMPUM å¨è­å¥è§£åçµæ§æ¹é¢è¡¨ç¾åºåªç°çæºç¢ºæ§ï¼è½å¤ é²è¡ç²¾ç¢ºéåï¼ä»¥æ¹åè¨åºæ±ºç­å¶å®ãå®éè­å¥åºè¦é«è»¸å§çä»£è¬éè¯ï¼æ¨åäºå°è¦é«ççç¸éæ§çç ç©¶ãæ­¤å¤ï¼MPUM ç¨ç¹çåºæ¼æ§å¶å¨çå·ç©å±¤è½å¤ è¦è¦ºåææç¶²è·¯å±¤çé¡¯èæ§åï¼é¡¯èå¢å¼·äºæ¨¡åçå¯è§£éæ§ã

##### **MedHallBench: A New Benchmark for Assessing Hallucination in Medical Large Language Models**
2412.18947v2 by Kaiwen Zuo, Yirui Jiang

Medical Large Language Models (MLLMs) have demonstrated potential in
healthcare applications, yet their propensity for hallucinations -- generating
medically implausible or inaccurate information -- presents substantial risks
to patient care. This paper introduces MedHallBench, a comprehensive benchmark
framework for evaluating and mitigating hallucinations in MLLMs. Our
methodology integrates expert-validated medical case scenarios with established
medical databases to create a robust evaluation dataset. The framework employs
a sophisticated measurement system that combines automated ACHMI (Automatic
Caption Hallucination Measurement in Medical Imaging) scoring with rigorous
clinical expert evaluations and utilizes reinforcement learning methods to
achieve automatic annotation. Through an optimized reinforcement learning from
human feedback (RLHF) training pipeline specifically designed for medical
applications, MedHallBench enables thorough evaluation of MLLMs across diverse
clinical contexts while maintaining stringent accuracy standards. We conducted
comparative experiments involving various models, utilizing the benchmark to
establish a baseline for widely adopted large language models (LLMs). Our
findings indicate that ACHMI provides a more nuanced understanding of the
effects of hallucinations compared to traditional metrics, thereby highlighting
its advantages in hallucination assessment. This research establishes a
foundational framework for enhancing MLLMs' reliability in healthcare settings
and presents actionable strategies for addressing the critical challenge of AI
hallucinations in medical applications.

æè¦ï¼å¤§åé«çèªè¨æ¨¡å (MLLM) å·²å¨é«çä¿å¥æç¨ä¸­å±ç¾æ½åï¼ä½å®åç¢çé«å­¸ä¸ä¸åçæä¸æºç¢ºè³è¨çå¹»è¦ºå¾åï¼å°çæ£ç§è­·æ§æéå¤§é¢¨éªãæ¬æä»ç´¹ MedHallBenchï¼ä¸åç¨æ¼è©ä¼°åæ¸è¼ MLLM ä¸­å¹»è¦ºçç¶ååºæºæ¶æ§ãæåçåæ³æ´åäºå°å®¶é©è­çé«çæ¡ä¾å ´æ¯èæ¢å®çé«çè³æåº«ï¼ä»¥å»ºç«ä¸åç©©å¥çè©ä¼°è³æéãè©²æ¡æ¶æ¡ç¨ä¸åç²¾å¯çæ¸¬éç³»çµ±ï¼çµåèªåå ACHMIï¼é«å­¸å½±åä¸­èªåæ¨é¡å¹»è¦ºæ¸¬éï¼è©åèå´è¬¹çè¨åºå°å®¶è©ä¼°ï¼ä¸¦å©ç¨å¼·åå­¸ç¿æ¹æ³ä¾å¯¦ç¾èªåè¨»è§£ãééå°çºé«çæç¨è¨­è¨çæä½³åäººé¡åé¥å¼·åå­¸ç¿ (RLHF) è¨ç·´ç®¡ç·ï¼MedHallBench è½å¤ å¨ä¸åçè¨åºèæ¯ä¸å¾¹åºè©ä¼° MLLMï¼åæç¶­æå´æ ¼çæºç¢ºæ§æ¨æºãæåé²è¡äºæ¶ååç¨®æ¨¡åçæ¯è¼å¯¦é©ï¼å©ç¨åºæºä¾çºå»£æ³æ¡ç¨çå¤§åèªè¨æ¨¡å (LLM) å»ºç«åºæºãæåçç ç©¶çµæè¡¨æï¼èå³çµ±ææ¨ç¸æ¯ï¼ACHMI å°å¹»è¦ºçå½±é¿æä¾äºæ´ç´°ç·»ççè§£ï¼å¾èçªé¡¯äºå®å¨å¹»è¦ºè©ä¼°ä¸­çåªå¢ãéé ç ç©¶çºæé« MLLM å¨é«çä¿å¥ç°å¢ä¸­çå¯é æ§å»ºç«äºä¸ååºç¤æ¡æ¶ï¼ä¸¦æåºäºå¯è¡çç­ç¥ä¾æå°é«çæç¨ä¸­ AI å¹»è¦ºçééµææ°ã

##### **HuatuoGPT-o1, Towards Medical Complex Reasoning with LLMs**
2412.18925v1 by Junying Chen, Zhenyang Cai, Ke Ji, Xidong Wang, Wanlong Liu, Rongsheng Wang, Jianye Hou, Benyou Wang

The breakthrough of OpenAI o1 highlights the potential of enhancing reasoning
to improve LLM. Yet, most research in reasoning has focused on mathematical
tasks, leaving domains like medicine underexplored. The medical domain, though
distinct from mathematics, also demands robust reasoning to provide reliable
answers, given the high standards of healthcare. However, verifying medical
reasoning is challenging, unlike those in mathematics. To address this, we
propose verifiable medical problems with a medical verifier to check the
correctness of model outputs. This verifiable nature enables advancements in
medical reasoning through a two-stage approach: (1) using the verifier to guide
the search for a complex reasoning trajectory for fine-tuning LLMs, (2)
applying reinforcement learning (RL) with verifier-based rewards to enhance
complex reasoning further. Finally, we introduce HuatuoGPT-o1, a medical LLM
capable of complex reasoning, which outperforms general and medical-specific
baselines using only 40K verifiable problems. Experiments show complex
reasoning improves medical problem-solving and benefits more from RL. We hope
our approach inspires advancements in reasoning across medical and other
specialized domains.

æè¦ï¼OpenAI o1 ççªç ´çªé¡¯äºå¢å¼·æ¨çä»¥æ¹å LLM çæ½åãç¶èï¼æ¨ççå¤§é¨åç ç©¶é½éä¸­å¨æ¸å­¸ä»»åä¸ï¼èé«å­¸ç­é ååå°æªååæ¢è¨ãåç®¡é«å­¸é åèæ¸å­¸ä¸åï¼ä½éæ¼é«çä¿å¥çé«æ¨æºï¼å®ä¹éè¦å¼·å¤§çæ¨çè½åæè½æä¾å¯é çç­æ¡ãç¶èï¼é©è­é«å­¸æ¨çå·æææ°æ§ï¼éèæ¸å­¸ä¸­çæ¨çä¸åãçºäºè§£æ±ºéååé¡ï¼æåæåºäºå¯é©è­çé«å­¸åé¡ï¼ä¸¦ä½¿ç¨é«å­¸é©è­å¨ä¾æª¢æ¥æ¨¡åè¼¸åºçæ­£ç¢ºæ§ãéç¨®å¯é©è­çæ§è³ªééä»¥ä¸å©åéæ®µçæ¹æ³å¯¦ç¾äºé«å­¸æ¨ççé²æ­¥ï¼(1) ä½¿ç¨é©è­å¨ä¾æå°å°æ¾è¤éæ¨çè»è·¡ä»¥å¾®èª¿ LLMï¼(2) æç¨å¼·åå­¸ç¿ (RL) ååºæ¼é©è­å¨ççåµä¾é²ä¸æ­¥å¢å¼·è¤éæ¨çãæå¾ï¼æåä»ç´¹äº HuatuoGPT-o1ï¼éæ¯ä¸åå·åè¤éæ¨çè½åçé«å­¸ LLMï¼å®åä½¿ç¨ 40K åå¯é©è­åé¡å°±åªæ¼ä¸è¬åç¹å®æ¼é«å­¸çåºæºãå¯¦é©è¡¨æï¼è¤éæ¨çæ¹é²äºé«å­¸åé¡è§£æ±ºï¼ä¸¦å¾ RL ä¸­åçæ´å¤ãæåå¸ææåçåæ³è½æ¿åµé«å­¸åå¶ä»å°æ¥­é åçæ¨çé²æ­¥ã

##### **Comprehensive Study on Lumbar Disc Segmentation Techniques Using MRI Data**
2412.18894v1 by Serkan Salturk, Irem Sayin, Ibrahim Cem Balci, Taha Emre Pamukcu, Zafer Soydan, Huseyin Uvet

Lumbar disk segmentation is essential for diagnosing and curing spinal
disorders by enabling precise detection of disk boundaries in medical imaging.
The advent of deep learning has resulted in the development of many
segmentation methods, offering differing levels of accuracy and effectiveness.
This study assesses the effectiveness of several sophisticated deep learning
architectures, including ResUnext, Ef3 Net, UNet, and TransUNet, for lumbar
disk segmentation, highlighting key metrics like as Pixel Accuracy, Mean
Intersection over Union (Mean IoU), and Dice Coefficient. The findings indicate
that ResUnext achieved the highest segmentation accuracy, with a Pixel Accuracy
of 0.9492 and a Dice Coefficient of 0.8425, with TransUNet following closely
after. Filtering techniques somewhat enhanced the performance of most models,
particularly Dense UNet, improving stability and segmentation quality. The
findings underscore the efficacy of these models in lumbar disk segmentation
and highlight potential areas for improvement.

æè¦ï¼è°æ¤éç¤åå²å°æ¼è¨ºæ·åæ²»çèæ¤ç¾çè³ééè¦ï¼å çºå®å¯ä»¥å¨é«å­¸å½±åä¸­ç²¾ç¢ºæª¢æ¸¬æ¤éç¤çéçãæ·±åº¦å­¸ç¿çåºç¾å°è´äºè¨±å¤åå²æ¹æ³çéç¼ï¼éäºæ¹æ³æä¾äºä¸åç¨åº¦çæºç¢ºæ§åæææ§ãæ¬ç ç©¶è©ä¼°äºå¹¾ç¨®è¤éçæ·±åº¦å­¸ç¿æ¶æ§çæææ§ï¼åæ¬ ResUnextãEf3 NetãUNet å TransUNetï¼ç¨æ¼è°æ¤éç¤åå²ï¼éé»éæ³¨ééµææ¨ï¼ä¾å¦åç´ æºç¢ºåº¦ãå¹³åè¯åäº¤éï¼å¹³å IoUï¼åéª°å­ä¿æ¸ãç ç©¶çµæè¡¨æï¼ResUnext éå°äºæé«çåå²æºç¢ºåº¦ï¼åç´ æºç¢ºåº¦çº 0.9492ï¼éª°å­ä¿æ¸çº 0.8425ï¼ç·é¨å¶å¾çæ¯ TransUNetãéæ¿¾æè¡å¨ä¸å®ç¨åº¦ä¸æé«äºå¤§å¤æ¸æ¨¡åçæ§è½ï¼ç¹å¥æ¯ Dense UNetï¼æé«äºç©©å®æ§ååå²è³ªéãç ç©¶çµæå¼·èª¿äºéäºæ¨¡åå¨è°æ¤éç¤åå²ä¸­çåæï¼ä¸¦å¼·èª¿äºæ½å¨çæ¹é²é åã

##### **Whose Morality Do They Speak? Unraveling Cultural Bias in Multilingual Language Models**
2412.18863v1 by Meltem Aksoy

Large language models (LLMs) have become integral tools in diverse domains,
yet their moral reasoning capabilities across cultural and linguistic contexts
remain underexplored. This study investigates whether multilingual LLMs, such
as GPT-3.5-Turbo, GPT-4o-mini, Llama 3.1, and MistralNeMo, reflect culturally
specific moral values or impose dominant moral norms, particularly those rooted
in English. Using the updated Moral Foundations Questionnaire (MFQ-2) in eight
languages, Arabic, Farsi, English, Spanish, Japanese, Chinese, French, and
Russian, the study analyzes the models' adherence to six core moral
foundations: care, equality, proportionality, loyalty, authority, and purity.
The results reveal significant cultural and linguistic variability, challenging
the assumption of universal moral consistency in LLMs. Although some models
demonstrate adaptability to diverse contexts, others exhibit biases influenced
by the composition of the training data. These findings underscore the need for
culturally inclusive model development to improve fairness and trust in
multilingual AI systems.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å·²æçºååé åä¸å¯æç¼ºçå·¥å·ï¼
ä½å®åå¨ä¸åæååèªè¨èæ¯ä¸çéå¾·æ¨çè½å
ä»æªå¾å°ååæ¢è¨ãæ¬ç ç©¶æ¢è¨å¤èªè¨ LLMï¼ä¾å¦
GPT-3.5-TurboãGPT-4o-miniãLlama 3.1 å MistralNeMoï¼æ¯å¦åæ äºç¹å®æåç
éå¾·å¹å¼è§æå¼·å äºä¸»æµéå¾·è¦ç¯ï¼å°¤å¶æ¯æ¤æ ¹æ¼è±èªçè¦ç¯ãä½¿ç¨æ´æ°çéå¾·åºç¤åå· (MFQ-2) å«ç¨®
èªè¨ï¼é¿æä¼¯èªãæ³¢æ¯èªãè±èªãè¥¿ç­çèªãæ¥èªãä¸­æãæ³èªå
ä¿èªï¼è©²ç ç©¶åæäºæ¨¡åå°å­åæ ¸å¿éå¾·çéµå®ææ³
åºç¤ï¼éæ·ãå¹³ç­ãç¸ç¨±æ§ãå¿ èª ãæ¬å¨åç´æ½ã
çµææ­ç¤ºäºé¡¯èçæååèªè¨è®ç°æ§ï¼ææ°äº LLM ä¸­æ®ééå¾·ä¸è´æ§çåè¨­ãåç®¡ä¸äºæ¨¡å
è­æäºå°ä¸åèæ¯çé©ææ§ï¼èå¦ä¸äºæ¨¡ååè¡¨ç¾åºåè¨ç·´æ¸æçµæå½±é¿çåè¦ãéäºç¼ç¾å¼·èª¿äº
æååå®¹æ¨¡åéç¼çå¿è¦æ§ï¼ä»¥æé«å¬å¹³æ§åå°
å¤èªè¨äººå·¥æºè½ç³»çµ±çä¿¡ä»»ã

##### **Unified Local and Global Attention Interaction Modeling for Vision Transformers**
2412.18778v1 by Tan Nguyen, Coy D. Heldermon, Corey Toler-Franklin

We present a novel method that extends the self-attention mechanism of a
vision transformer (ViT) for more accurate object detection across diverse
datasets. ViTs show strong capability for image understanding tasks such as
object detection, segmentation, and classification. This is due in part to
their ability to leverage global information from interactions among visual
tokens. However, the self-attention mechanism in ViTs are limited because they
do not allow visual tokens to exchange local or global information with
neighboring features before computing global attention. This is problematic
because tokens are treated in isolation when attending (matching) to other
tokens, and valuable spatial relationships are overlooked. This isolation is
further compounded by dot-product similarity operations that make tokens from
different semantic classes appear visually similar. To address these
limitations, we introduce two modifications to the traditional self-attention
framework; a novel aggressive convolution pooling strategy for local feature
mixing, and a new conceptual attention transformation to facilitate interaction
and feature exchange between semantic concepts. Experimental results
demonstrate that local and global information exchange among visual features
before self-attention significantly improves performance on challenging object
detection tasks and generalizes across multiple benchmark datasets and
challenging medical datasets. We publish source code and a novel dataset of
cancerous tumors (chimeric cell clusters).

æè¦ï¼<paragraph>æåæåºäºä¸ç¨®æ°ç©çæ¹æ³ï¼å®æ´å±äºè¦è¦ºè½æå¨ (ViT) çèªæ³¨æåæ©å¶ï¼ä»¥å¨ä¸åçè³æéä¸é²è¡æ´æºç¢ºçç©ä»¶åµæ¸¬ãViT é¡¯ç¤ºåºå¼·å¤§çå½±åçè§£ä»»åè½åï¼ä¾å¦ç©ä»¶åµæ¸¬ãåå²ååé¡ãéé¨åæ­¸åæ¼å®åè½å¤ å©ç¨è¦è¦ºæ¨è¨ä¹éäºåçå¨å±è³è¨ãç¶èï¼ViT ä¸­çèªæ³¨æåæ©å¶åå°éå¶ï¼å çºå®åä¸åè¨±è¦è¦ºæ¨è¨å¨è¨ç®å¨å±æ³¨æåä¹åèé°è¿ç¹å¾µäº¤æå±é¨æå¨å±è³è¨ãéæ¯ååé¡ï¼å çºå¨å°å¶ä»æ¨è¨é²è¡æ³¨æåï¼æ¯å°ï¼æï¼æ¨è¨æè¢«å­¤ç«èçï¼èæå¹å¼çç©ºééä¿åè¢«å¿½ç¥ãéç¨®å­¤ç«é²ä¸æ­¥å åäºé»ç©ç¸ä¼¼åº¦éç®ï¼éä½¿å¾ä¾èªä¸åèªç¾©é¡å¥çæ¨è¨çèµ·ä¾å¨è¦è¦ºä¸ç¸ä¼¼ãçºäºè§£æ±ºéäºéå¶ï¼æåå°å³çµ±çèªæ³¨æåæ¶æ§é²è¡äºå©é ä¿®æ¹ï¼ä¸ç¨®æ°ç©çç©æ¥µå·ç©æ± åç­ç¥ï¼ç¨æ¼å±é¨ç¹å¾µæ··åï¼ä»¥åä¸ç¨®æ°çæ¦å¿µæ³¨æåè½æï¼ä»¥ä¿é²èªç¾©æ¦å¿µä¹éçäºååç¹å¾µäº¤æãå¯¦é©çµæè¡¨æï¼å¨èªæ³¨æåä¹åè¦è¦ºç¹å¾µä¹éçå±é¨åå¨å±è³è¨äº¤æï¼é¡¯èæ¹åäºå·æææ°æ§çç©ä»¶åµæ¸¬ä»»åçæè½ï¼ä¸¦å¨å¤ååºæºè³æéåå·æææ°æ§çé«çè³æéä¸é²è¡æ¦åãæåç¼å¸äºççè«ç¤ï¼åµåç´°èç°ï¼çåå§ç¢¼åæ°ç©è³æéã</paragraph>

##### **Successes and Limitations of Object-centric Models at Compositional Generalisation**
2412.18743v1 by Milton L. Montero, Jeffrey S. Bowers, Gaurav Malhotra

In recent years, it has been shown empirically that standard disentangled
latent variable models do not support robust compositional learning in the
visual domain. Indeed, in spite of being designed with the goal of factorising
datasets into their constituent factors of variations, disentangled models show
extremely limited compositional generalisation capabilities. On the other hand,
object-centric architectures have shown promising compositional skills, albeit
these have 1) not been extensively tested and 2) experiments have been limited
to scene composition -- where models must generalise to novel combinations of
objects in a visual scene instead of novel combinations of object properties.
In this work, we show that these compositional generalisation skills extend to
this later setting. Furthermore, we present evidence pointing to the source of
these skills and how they can be improved through careful training. Finally, we
point to one important limitation that still exists which suggests new
directions of research.

æè¦ï¼è¿å¹´æ¥ï¼ç»å®è¯è¡¨æï¼æ åè§£çº ç¼ æ½å¨åéæ¨¡åä¸æ¯æè§è§é¢åçé²æ£ç»åå­¦ä¹ ãäºå®ä¸ï¼å°½ç®¡è§£çº ç¼ æ¨¡åçè®¾è®¡ç®æ æ¯å°æ°æ®éåè§£ä¸ºå¶ç»æååå å­ï¼ä½å¶ç»åæ³åè½åå´æå¶æéãå¦ä¸æ¹é¢ï¼ä»¥å¯¹è±¡ä¸ºä¸­å¿çæ¶ææ¾ç¤ºåºæå¸æçç»åæè½ï¼å°½ç®¡è¿äºæè½ 1) å°æªç»è¿å¹¿æ³æµè¯ï¼å¹¶ä¸ 2) å®éªä»éäºåºæ¯ç»åââå¶ä¸­æ¨¡åå¿é¡»æ³åå°è§è§åºæ¯ä¸­å¯¹è±¡çç»åï¼èä¸æ¯å¯¹è±¡çç»åå±æ§ãå¨è¿é¡¹å·¥ä½ä¸­ï¼æä»¬è¡¨æè¿äºç»åæ³åæè½æ©å±å°åä¸ç§è®¾ç½®ãæ­¤å¤ï¼æä»¬æä¾äºæåè¿äºæè½æ¥æºçè¯æ®ï¼ä»¥åå¦ä½éè¿ä»ç»è®­ç»æ¥æ¹è¿è¿äºæè½ãæåï¼æä»¬æåºäºä»ç¶å­å¨çä¸ä¸ªéè¦éå¶ï¼è¿æç¤ºäºæ°çç ç©¶æ¹åã

##### **SurvAttack: Black-Box Attack On Survival Models through Ontology-Informed EHR Perturbation**
2412.18706v1 by Mohsen Nayebi Kerdabadi, Arya Hadizadeh Moghaddam, Bin Liu, Mei Liu, Zijun Yao

Survival analysis (SA) models have been widely studied in mining electronic
health records (EHRs), particularly in forecasting the risk of critical
conditions for prioritizing high-risk patients. However, their vulnerability to
adversarial attacks is much less explored in the literature. Developing
black-box perturbation algorithms and evaluating their impact on
state-of-the-art survival models brings two benefits to medical applications.
First, it can effectively evaluate the robustness of models in pre-deployment
testing. Also, exploring how subtle perturbations would result in significantly
different outcomes can provide counterfactual insights into the clinical
interpretation of model prediction. In this work, we introduce SurvAttack, a
novel black-box adversarial attack framework leveraging subtle clinically
compatible, and semantically consistent perturbations on longitudinal EHRs to
degrade survival models' predictive performance. We specifically develop a
greedy algorithm to manipulate medical codes with various adversarial actions
throughout a patient's medical history. Then, these adversarial actions are
prioritized using a composite scoring strategy based on multi-aspect
perturbation quality, including saliency, perturbation stealthiness, and
clinical meaningfulness. The proposed adversarial EHR perturbation algorithm is
then used in an efficient SA-specific strategy to attack a survival model when
estimating the temporal ranking of survival urgency for patients. To
demonstrate the significance of our work, we conduct extensive experiments,
including baseline comparisons, explainability analysis, and case studies. The
experimental results affirm our research's effectiveness in illustrating the
vulnerabilities of patient survival models, model interpretation, and
ultimately contributing to healthcare quality.

æè¦ï¼<paragraph>å­æ´»åæ (SA) æ¨¡åå·²å¨é»å­å¥åº·ç´é (EHR) çæ¢åä¸­å»£æ³ç ç©¶ï¼ç¹å¥æ¯å¨é æ¸¬å±æ¥çæ³çé¢¨éªä»¥åªåèçé«é¢¨éªæ£èãç¶èï¼æç»ä¸­å°æ¼å®åå°ææ»æçèå¼±æ§æ¢ç´¢è¼å°ãéç¼é»çæ¾åæ¼ç®æ³ä¸¦è©ä¼°å®åå°ææ°å­æ´»æ¨¡åçå½±é¿ï¼çºé«çæç¨å¸¶ä¾å©é å¥½èãé¦åï¼å®å¯ä»¥å¨é¨ç½²åæ¸¬è©¦ä¸­ææè©ä¼°æ¨¡åçç©©å¥æ§ãæ­¤å¤ï¼æ¢ç´¢ç´°å¾®çæ¾åå¦ä½å°è´é¡¯èä¸åççµæï¼å¯ä»¥æä¾åäºå¯¦çè¦è§£ï¼ä»¥é²è¡æ¨¡åé æ¸¬çè¨åºè§£éãå¨éé å·¥ä½ä¸­ï¼æåä»ç´¹äº SurvAttackï¼ä¸åæ°ç©çé»çå°ææ»ææ¶æ§ï¼å©ç¨å¨ç¸±å EHR ä¸ç´°å¾®çè¨åºç¸å®¹ä¸èªç¾©ä¸è´çæ¾åï¼ä¾éä½å­æ´»æ¨¡åçé æ¸¬æè½ãæåç¹å¥éç¼äºä¸åè²ªå©ªæ¼ç®æ³ï¼ä»¥åç¨®å°æåä½ä¾æç¸±çæ­·ä¸­çé«çç¢¼ãç¶å¾ï¼ä½¿ç¨åºæ¼å¤æ¹é¢æ¾ååè³ªï¼åæ¬é¡¯èæ§ãæ¾åé±è½æ§åè¨åºæç¾©ï¼çè¤åè©åç­ç¥ï¼å°éäºå°æåä½é²è¡åªåæåºãç¶å¾å°æåºçå°ææ§ EHR æ¾åæ¼ç®æ³ç¨æ¼ç¹å® SA çææç­ç¥ä¸­ï¼ä»¥å¨ä¼°è¨æ£èå­æ´»ç·æ¥æ§çæéæåºææ»æå­æ´»æ¨¡åãçºäºè­ææåå·¥ä½çæç¾©ï¼æåé²è¡äºå»£æ³çå¯¦é©ï¼åæ¬åºç·æ¯è¼ãå¯è§£éæ§åæåæ¡ä¾ç ç©¶ãå¯¦é©çµæè¯å®äºæåçç ç©¶å¨èªªææ£èå­æ´»æ¨¡åãæ¨¡åè§£éçèå¼±æ§ï¼ä¸¦æçµæå©æ¼é«çä¿å¥åè³ªæ¹é¢çæææ§ã</paragraph>

##### **A Review of Latent Representation Models in Neuroimaging**
2412.19844v1 by C. VÃ¡zquez-GarcÃ­a, F. J. MartÃ­nez-Murcia, F. Segovia RomÃ¡n, Juan M. GÃ³rriz

Neuroimaging data, particularly from techniques like MRI or PET, offer rich
but complex information about brain structure and activity. To manage this
complexity, latent representation models - such as Autoencoders, Generative
Adversarial Networks (GANs), and Latent Diffusion Models (LDMs) - are
increasingly applied. These models are designed to reduce high-dimensional
neuroimaging data to lower-dimensional latent spaces, where key patterns and
variations related to brain function can be identified. By modeling these
latent spaces, researchers hope to gain insights into the biology and function
of the brain, including how its structure changes with age or disease, or how
it encodes sensory information, predicts and adapts to new inputs. This review
discusses how these models are used for clinical applications, like disease
diagnosis and progression monitoring, but also for exploring fundamental brain
mechanisms such as active inference and predictive coding. These approaches
provide a powerful tool for both understanding and simulating the brain's
complex computational tasks, potentially advancing our knowledge of cognition,
perception, and neural disorders.

æè¦ï¼ç¥ç¶å½±åè³æï¼ç¹å¥æ¯ä¾èªæ¼ MRI æ PET ç­æè¡ï¼æä¾è±å¯ä½è¤éçå¤§è¦çµæ§èæ´»åè³è¨ãçºäºèçéç¨®è¤éæ§ï¼æ½å¨è¡¨å¾µæ¨¡åï¼ä¾å¦èªåç·¨ç¢¼å¨ãçæå°æç¶²è·¯ (GAN) åæ½å¨æ´æ£æ¨¡å (LDM)ï¼çæç¨æ¥çå¢å ãéäºæ¨¡åæ¨å¨å°é«ç¶­åº¦ç¥ç¶å½±åè³æéç¶­è³ä½ç¶­åº¦æ½å¨ç©ºéï¼å¨å¶ä¸­å¯ä»¥è­å¥èå¤§è¦åè½ç¸éçä¸»è¦æ¨¡å¼åè®åãééå°éäºæ½å¨ç©ºéå»ºæ¨¡ï¼ç ç©¶äººå¡å¸ææ·±å¥äºè§£å¤§è¦ççç©å­¸ååè½ï¼åæ¬å¶çµæ§å¦ä½é¨èå¹´é½¡æç¾çèæ¹è®ï¼æå¦ä½ç·¨ç¢¼æå®è³è¨ãé æ¸¬åé©ææ°çè¼¸å¥ãæ¬ç¯è©è«æ¢è¨éäºæ¨¡åå¦ä½ç¨æ¼è¨åºæç¨ï¼ä¾å¦ç¾çè¨ºæ·åé²ç¨ç£æ§ï¼ä»¥åæ¢ç´¢ä¸»åæ¨è«åé æ¸¬ç·¨ç¢¼ç­åºæ¬å¤§è¦æ©å¶ãéäºæ¹æ³æä¾äºä¸åå¼·å¤§çå·¥å·ï¼å¯ä»¥ç¨æ¼çè§£åæ¨¡æ¬å¤§è¦è¤éçéç®ä»»åï¼ä¸¦æå¯è½å¢é²æåå°èªç¥ãç¥è¦ºåç¥ç¶ç¾ççèªè­ã

##### **DiTCtrl: Exploring Attention Control in Multi-Modal Diffusion Transformer for Tuning-Free Multi-Prompt Longer Video Generation**
2412.18597v1 by Minghong Cai, Xiaodong Cun, Xiaoyu Li, Wenze Liu, Zhaoyang Zhang, Yong Zhang, Ying Shan, Xiangyu Yue

Sora-like video generation models have achieved remarkable progress with a
Multi-Modal Diffusion Transformer MM-DiT architecture. However, the current
video generation models predominantly focus on single-prompt, struggling to
generate coherent scenes with multiple sequential prompts that better reflect
real-world dynamic scenarios. While some pioneering works have explored
multi-prompt video generation, they face significant challenges including
strict training data requirements, weak prompt following, and unnatural
transitions. To address these problems, we propose DiTCtrl, a training-free
multi-prompt video generation method under MM-DiT architectures for the first
time. Our key idea is to take the multi-prompt video generation task as
temporal video editing with smooth transitions. To achieve this goal, we first
analyze MM-DiT's attention mechanism, finding that the 3D full attention
behaves similarly to that of the cross/self-attention blocks in the UNet-like
diffusion models, enabling mask-guided precise semantic control across
different prompts with attention sharing for multi-prompt video generation.
Based on our careful design, the video generated by DiTCtrl achieves smooth
transitions and consistent object motion given multiple sequential prompts
without additional training. Besides, we also present MPVBench, a new benchmark
specially designed for multi-prompt video generation to evaluate the
performance of multi-prompt generation. Extensive experiments demonstrate that
our method achieves state-of-the-art performance without additional training.

æè¦ï¼é¡ Sora çå½±ççææ¨¡åå¨å¤æ¨¡ææ´æ£Transformer MM-DiT æ¶æ§ä¸­åå¾é¡¯èé²å±ãç¶èï¼ç®åçå½±ççææ¨¡åä¸»è¦å°æ³¨æ¼å®ä¸æç¤ºï¼é£ä»¥çæåå«å¤åå¾ªåºæç¤ºçé£è²«å ´æ¯ï¼èéäºæç¤ºæ´è½åæ çå¯¦ä¸ççåæå ´æ¯ãåç®¡ä¸äºéåµæ§çä½åå·²æ¢ç´¢å¤æç¤ºå½±ççæï¼ä½å®åé¢è¨å´å³»çææ°ï¼åæ¬å´æ ¼çè¨ç·´è³æéæ±ãæç¤ºè¿½è¹¤è½åä¸ä½³ä»¥åä¸èªç¶çè½æãçºäºè§£æ±ºéäºåé¡ï¼æåæåº DiTCtrlï¼éæ¯ä¸ç¨®å¨ MM-DiT æ¶æ§ä¸é¦æ¬¡ä½¿ç¨çåè¨ç·´å¤æç¤ºå½±ççææ¹æ³ãæåçééµæ³æ³æ¯å°å¤æç¤ºå½±ççæä»»åè¦çºå·æå¹³æ»è½æçæåºå½±çç·¨è¼¯ãçºäºéææ­¤ç®æ¨ï¼æåé¦ååæ MM-DiT çæ³¨æåæ©å¶ï¼ç¼ç¾ 3D å¨æ³¨æåè UNet é¡æ´æ£æ¨¡åä¸­çäº¤å/èªææ³¨æååå¡æé¡ä¼¼çè¡çºï¼éä½¿å¾æåè½å¤ ééæ³¨æåå±äº«é²è¡é®ç½©å°å¼çç²¾ç¢ºèªææ§å¶ï¼ä»¥é²è¡å¤æç¤ºå½±ççæãæ ¹ææåçç²¾ç´°è¨­è¨ï¼DiTCtrl çæçå½±çå¨çµ¦å®å¤åå¾ªåºæç¤ºçææ³ä¸ï¼å¯ä»¥å¯¦ç¾å¹³æ»çè½æåä¸è´çç©ä»¶åä½ï¼èä¸éè¦é¡å¤çè¨ç·´ãæ­¤å¤ï¼æåéæåºäº MPVBenchï¼éæ¯ä¸åå°éè¨­è¨ç¨æ¼å¤æç¤ºå½±ççæçæ°åºæºï¼ç¨æ¼è©ä¼°å¤æç¤ºçæçææãå»£æ³çå¯¦é©è­æï¼æåçæ¹æ³å¨æ²æé¡å¤è¨ç·´çææ³ä¸ï¼éå°äºæåé²çæè½ã

##### **Advancing Deformable Medical Image Registration with Multi-axis Cross-covariance Attention**
2412.18545v1 by Mingyuan Meng, Michael Fulham, Lei Bi, Jinman Kim

Deformable image registration is a fundamental requirement for medical image
analysis. Recently, transformers have been widely used in deep learning-based
registration methods for their ability to capture long-range dependency via
self-attention (SA). However, the high computation and memory loads of SA
(growing quadratically with the spatial resolution) hinder transformers from
processing subtle textural information in high-resolution image features, e.g.,
at the full and half image resolutions. This limits deformable registration as
the high-resolution textural information is crucial for finding precise
pixel-wise correspondence between subtle anatomical structures.
Cross-covariance Attention (XCA), as a "transposed" version of SA that operates
across feature channels, has complexity growing linearly with the spatial
resolution, providing the feasibility of capturing long-range dependency among
high-resolution image features. However, existing XCA-based transformers merely
capture coarse global long-range dependency, which are unsuitable for
deformable image registration relying primarily on fine-grained local
correspondence. In this study, we propose to improve existing deep
learning-based registration methods by embedding a new XCA mechanism. To this
end, we design an XCA-based transformer block optimized for deformable medical
image registration, named Multi-Axis XCA (MAXCA). Our MAXCA serves as a general
network block that can be embedded into various registration network
architectures. It can capture both global and local long-range dependency among
high-resolution image features by applying regional and dilated XCA in parallel
via a multi-axis design. Extensive experiments on two well-benchmarked
inter-/intra-patient registration tasks with seven public medical datasets
demonstrate that our MAXCA block enables state-of-the-art registration
performance.

æè¦ï¼å¯è®å½¢å½±åéæºæ¯é«å­¸å½±ååæçåºæ¬éæ±ãæè¿ï¼Transformerå·²å»£æ³ç¨æ¼åºæ¼æ·±åº¦å­¸ç¿çéæºæ¹æ³ï¼å çºå®åè½ééèªææ³¨æ (SA) æ·åé·ç¨ä¾è³´æ§ãç¶èï¼SA çé«éç®åè¨æ¶é«è² è¼ï¼é¨èç©ºéè§£æåº¦åäºæ¬¡æé·ï¼æé»ç¤Transformerèçé«è§£æåº¦å½±åç¹å¾µä¸­çç´°å¾®ç´çè³è¨ï¼ä¾å¦å¨å®æ´ååå½±åè§£æåº¦ä¸­ãééå¶äºå¯è®å½¢éæºï¼å çºé«è§£æåº¦ç´çè³è¨å°æ¼å¨ç´°å¾®è§£åçµæ§ä¹éæ¾å°ç²¾ç¢ºçåç´ å°æè³ééè¦ãè·¨åæ¹å·®æ³¨æ (XCA) ä½çº SA çãè½ç½®ãçæ¬ï¼å¶éä½è·¨ç¹å¾µééï¼è¤éåº¦é¨èç©ºéè§£æåº¦åç·æ§æé·ï¼æä¾æ·åé«è§£æåº¦å½±åç¹å¾µä¹éé·ç¨ä¾è³´æ§çå¯è¡æ§ãç¶èï¼ç¾æçåºæ¼ XCA çTransformeråæ·åç²ç¥çå¨å±é·ç¨ä¾è³´æ§ï¼éä¸é©åä¸»è¦ä¾è³´ç´°ç²åº¦å±é¨å°æçå¯è®å½¢å½±åéæºãå¨æ¬ç ç©¶ä¸­ï¼æåæåºééåµå¥æ°ç XCA æ©å¶ä¾æ¹åç¾æçåºæ¼æ·±åº¦å­¸ç¿çéæºæ¹æ³ãçºæ­¤ï¼æåè¨­è¨äºä¸åéå°å¯è®å½¢é«å­¸å½±åéæºæä½³åçåºæ¼ XCA çTransformeråå¡ï¼ç¨±çºå¤è»¸ XCA (MAXCA)ãæåç MAXCA æ¯ä¸åéç¨ç¶²è·¯åå¡ï¼å¯ä»¥åµå¥å°åç¨®éæºç¶²è·¯æ¶æ§ä¸­ãå®å¯ä»¥ééå¤è»¸è¨­è¨ä¸¦è¡æç¨åååè¨è¹ç XCAï¼ä¾æ·åé«è§£æåº¦å½±åç¹å¾µä¹éçå¨å±åå±é¨é·ç¨ä¾è³´æ§ãå¨å©åå»£æ³åºæºåçæ£èé/æ£èå§éæºä»»åä¸­ï¼ä½¿ç¨ä¸åå¬å±é«å­¸è³æéé²è¡çå»£æ³å¯¦é©è­æï¼æåç MAXCA åå¡è½å¯¦ç¾æåé²çéæºæè½ã

##### **Multi-Agent Norm Perception and Induction in Distributed Healthcare**
2412.18454v1 by Chao Li, Olga Petruchik, Elizaveta Grishanina, Sergey Kovalchuk

This paper presents a Multi-Agent Norm Perception and Induction Learning
Model aimed at facilitating the integration of autonomous agent systems into
distributed healthcare environments through dynamic interaction processes. The
nature of the medical norm system and its sharing channels necessitates
distinct approaches for Multi-Agent Systems to learn two types of norms.
Building on this foundation, the model enables agents to simultaneously learn
descriptive norms, which capture collective tendencies, and prescriptive norms,
which dictate ideal behaviors. Through parameterized mixed probability density
models and practice-enhanced Markov games, the multi-agent system perceives
descriptive norms in dynamic interactions and captures emergent prescriptive
norms. We conducted experiments using a dataset from a neurological medical
center spanning from 2016 to 2020.

æè¦ï¼æ¬ææåºäºä¸åå¤ä¸»é«è¦ç¯æç¥èæ­¸ç´å­¸ç¿æ¨¡åï¼æ¨å¨ééåæäºåç¨åºä¿é²èªä¸»ä¸»é«ç³»çµ±æ´åå°åæ£å¼é«çä¿å¥ç°å¢ä¸­ãé«çè¦ç¯ç³»çµ±çæ¬è³ªåå¶å±äº«ç®¡ééè¦ä¸åçæ¹æ³ï¼è®å¤ä¸»é«ç³»çµ±å­¸ç¿å©ç¨®è¦ç¯ãåºæ¼æ­¤åºç¤ï¼è©²æ¨¡åè®ä¸»é«è½å¤ åæå­¸ç¿æè¿°æ§è¦ç¯ï¼ææéé«å¾åï¼åè¦ç¯æ§è¦ç¯ï¼è¦å®çæ³è¡çºï¼ãééåæ¸åæ··åæ©çå¯åº¦æ¨¡ååå¯¦åå¢å¼·é¦¬å¯å¤«åå¼ï¼å¤ä¸»é«ç³»çµ±å¨åæäºåä¸­æç¥æè¿°æ§è¦ç¯ï¼ä¸¦æææ°èçè¦ç¯æ§è¦ç¯ãæåä½¿ç¨ 2016 å¹´è³ 2020 å¹´æéä¸åç¥ç¶é«å­¸é«çä¸­å¿çæ°æ®éé²è¡äºå¯¦é©ã

##### **Research on the Proximity Relationships of Psychosomatic Disease Knowledge Graph Modules Extracted by Large Language Models**
2412.18419v1 by Zihan Zhou, Ziyi Zeng, Wenhao Jiang, Yihui Zhu, Jiaxin Mao, Yonggui Yuan, Min Xia, Shubin Zhao, Mengyu Yao, Yunqian Chen

As social changes accelerate, the incidence of psychosomatic disorders has
significantly increased, becoming a major challenge in global health issues.
This necessitates an innovative knowledge system and analytical methods to aid
in diagnosis and treatment. Here, we establish the ontology model and entity
types, using the BERT model and LoRA-tuned LLM for named entity recognition,
constructing the knowledge graph with 9668 triples. Next, by analyzing the
network distances between disease, symptom, and drug modules, it was found that
closer network distances among diseases can predict greater similarities in
their clinical manifestations, treatment approaches, and psychological
mechanisms, and closer distances between symptoms indicate that they are more
likely to co-occur. Lastly, by comparing the proximity d and proximity z score,
it was shown that symptom-disease pairs in primary diagnostic relationships
have a stronger association and are of higher referential value than those in
diagnostic relationships. The research results revealed the potential
connections between diseases, co-occurring symptoms, and similarities in
treatment strategies, providing new perspectives for the diagnosis and
treatment of psychosomatic disorders and valuable information for future mental
health research and practice.

æè¦ï¼é¨èç¤¾æè®é·å éï¼å¿èº«ç¾çç¼ççé¡¯èå¢å ï¼æçºå¨çè¡çè­°é¡ä¸çéå¤§ææ°ãééè¦åµæ°çç¥è­é«ç³»èåææ¹æ³ï¼ä»¥åå©è¨ºæ·èæ²»çãå¨æ­¤ï¼æåå»ºç«äºæ¬ä½æ¨¡åèå¯¦é«é¡åï¼å©ç¨ BERT æ¨¡åè LoRA èª¿æ ¡éç LLM é²è¡å½åå¯¦é«è¾¨è­ï¼å»ºæ§åº 9668 åä¸åçµçç¥è­åè­ãæ¥èï¼ééåæç¾çãççãè¥ç©æ¨¡çµéçç¶²è·¯è·é¢ï¼ç¼ç¾ç¾çéè¼è¿çç¶²è·¯è·é¢ï¼å¯é æ¸¬å¶è¨åºè¡¨ç¾ãæ²»çæ¹å¼ãå¿çæ©è½çç¸ä¼¼æ§è¼é«ï¼èççéè·é¢è¼è¿ï¼åè¡¨ç¤ºè¼å¯è½å±ç¾ãæå¾ï¼ééæ¯è¼æ¥è¿åº¦ d èæ¥è¿åº¦ z åæ¸ï¼ç¼ç¾åæ¬¡è¨ºæ·éä¿ä¸­ççç-ç¾çå°ï¼å¶éè¯æ§è¼å¼·ãåèå¹å¼è¼é«ï¼åªæ¼è¨ºæ·éä¿ä¸­ççç-ç¾çå°ãç ç©¶æææ­ç¤ºäºç¾çãå±ç¾ççãæ²»çç­ç¥éçæ½å¨éè¯ï¼çºå¿èº«ç¾ççè¨ºæ·èæ²»çæä¾äºæ°çè§é»ï¼ä¹çºæªä¾å¿çå¥åº·ç ç©¶èå¯¦åæä¾äºå¯¶è²´çè³è¨ã

##### **Unveiling the Threat of Fraud Gangs to Graph Neural Networks: Multi-Target Graph Injection Attacks Against GNN-Based Fraud Detectors**
2412.18370v2 by Jinhyeok Choi, Heehyeon Kim, Joyce Jiyoung Whang

Graph neural networks (GNNs) have emerged as an effective tool for fraud
detection, identifying fraudulent users, and uncovering malicious behaviors.
However, attacks against GNN-based fraud detectors and their risks have rarely
been studied, thereby leaving potential threats unaddressed. Recent findings
suggest that frauds are increasingly organized as gangs or groups. In this
work, we design attack scenarios where fraud gangs aim to make their fraud
nodes misclassified as benign by camouflaging their illicit activities in
collusion. Based on these scenarios, we study adversarial attacks against
GNN-based fraud detectors by simulating attacks of fraud gangs in three
real-world fraud cases: spam reviews, fake news, and medical insurance frauds.
We define these attacks as multi-target graph injection attacks and propose
MonTi, a transformer-based Multi-target one-Time graph injection attack model.
MonTi simultaneously generates attributes and edges of all attack nodes with a
transformer encoder, capturing interdependencies between attributes and edges
more effectively than most existing graph injection attack methods that
generate these elements sequentially. Additionally, MonTi adaptively allocates
the degree budget for each attack node to explore diverse injection structures
involving target, candidate, and attack nodes, unlike existing methods that fix
the degree budget across all attack nodes. Experiments show that MonTi
outperforms the state-of-the-art graph injection attack methods on five
real-world graphs.

æè¦ï¼åç¥ç¶ç¶²è·¯ (GNN) å·²æçºè©æ¬ºåµæ¸¬ãè­å¥è©é¨ä½¿ç¨èåæ­é²æ¡æè¡çºçææå·¥å·ã
ç¶èï¼éå°åºæ¼ GNN çè©æ¬ºåµæ¸¬å¨çæ»æåå¶é¢¨éªé®®å°è¢«ç ç©¶ï¼å æ­¤æ½å¨å¨èä»æªç²å¾è§£æ±ºãæè¿çç ç©¶çµæè¡¨æï¼è©æ¬ºè¡çºæ­£æ¥çä»¥å¹«æ´¾æåé«çå½¢å¼çµç¹èµ·ä¾ãå¨æ¬æä¸­ï¼æåè¨­è¨äºæ»ææå¢ï¼å¶ä¸­è©æ¬ºå¹«æ´¾æ¨å¨ééä¸²éæ©è­·å¶éæ³æ´»åï¼ä½¿ä»åçè©æ¬ºç¯é»è¢«é¯èª¤åé¡çºè¯æ§ãåºæ¼éäºæå¢ï¼æåééæ¨¡æ¬ä¸åçå¯¦ä¸ççè©æ¬ºæ¡ä¾ï¼åå¾è©è«ãåæ°èåé«çä¿éªè©æ¬ºï¼ä¸­çè©æ¬ºå¹«æ´¾æ»æä¾ç ç©¶éå°åºæ¼ GNN çè©æ¬ºåµæ¸¬å¨çå°ææ§æ»æãæåå°éäºæ»æå®ç¾©çºå¤ç®æ¨åå½¢æ³¨å¥æ»æï¼ä¸¦æåº MonTiï¼ä¸ååºæ¼ Transformer çå¤ç®æ¨ä¸æ¬¡æ§åå½¢æ³¨å¥æ»ææ¨¡åãMonTi åæä½¿ç¨ Transformer ç·¨ç¢¼å¨çææææ»æç¯é»çå±¬æ§åéç·£ï¼æ¯å¤§å¤æ¸ç¾æçåå½¢æ³¨å¥æ»ææ¹æ³æ´ææå°ææå±¬æ§åéç·£ä¹éçç¸äºä¾è³´æ§ï¼å¾èæé åºçæéäºåç´ ãæ­¤å¤ï¼èåºå®æææ»æç¯é»çåº¦é ç®çç¾ææ¹æ³ä¸åï¼MonTi èªé©æå°åéæ¯åæ»æç¯é»çåº¦é ç®ï¼ä»¥æ¢ç´¢æ¶åç®æ¨ãåé¸åæ»æç¯é»çå¤æ¨£åæ³¨å¥çµæ§ãå¯¦é©è¡¨æï¼MonTi å¨äºåçå¯¦ä¸çåå½¢ä¸åªæ¼æåé²çåå½¢æ³¨å¥æ»ææ¹æ³ã

##### **Real-world Deployment and Evaluation of PErioperative AI CHatbot (PEACH) -- a Large Language Model Chatbot for Perioperative Medicine**
2412.18096v1 by Yu He Ke, Liyuan Jin, Kabilan Elangovan, Bryan Wen Xi Ong, Chin Yang Oh, Jacqueline Sim, Kenny Wei-Tsen Loh, Chai Rick Soh, Jonathan Ming Hua Cheng, Aaron Kwang Yang Lee, Daniel Shu Wei Ting, Nan Liu, Hairil Rizal Abdullah

Large Language Models (LLMs) are emerging as powerful tools in healthcare,
particularly for complex, domain-specific tasks. This study describes the
development and evaluation of the PErioperative AI CHatbot (PEACH), a secure
LLM-based system integrated with local perioperative guidelines to support
preoperative clinical decision-making. PEACH was embedded with 35 institutional
perioperative protocols in the secure Claude 3.5 Sonet LLM framework within
Pair Chat (developed by Singapore Government) and tested in a silent deployment
with real-world data. Accuracy, safety, and usability were assessed. Deviations
and hallucinations were categorized based on potential harm, and user feedback
was evaluated using the Technology Acceptance Model (TAM). Updates were made
after the initial silent deployment to amend one protocol.
  In 240 real-world clinical iterations, PEACH achieved a first-generation
accuracy of 97.5% (78/80) and an overall accuracy of 96.7% (232/240) across
three iterations. The updated PEACH demonstrated improved accuracy of 97.9%
(235/240), with a statistically significant difference from the null hypothesis
of 95% accuracy (p = 0.018, 95% CI: 0.952-0.991). Minimal hallucinations and
deviations were observed (both 1/240 and 2/240, respectively). Clinicians
reported that PEACH expedited decisions in 95% of cases, and inter-rater
reliability ranged from kappa 0.772-0.893 within PEACH and 0.610-0.784 among
attendings.
  PEACH is an accurate, adaptable tool that enhances consistency and efficiency
in perioperative decision-making. Future research should explore its
scalability across specialties and its impact on clinical outcomes.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) æ­£æçºé«çä¿å¥é åå¼·å¤§çå·¥å·ï¼ç¹å¥é©ç¨æ¼è¤éçç¹å®é åä»»åãæ¬ç ç©¶æè¿°äºåæè¡æ AI èå¤©æ©å¨äºº (PEACH) çéç¼åè©ä¼°ï¼éæ¯ä¸åå®å¨ç LLM åºç¤ç³»çµ±ï¼èæ¬å°çåæè¡ææºåæ´åï¼ä»¥æ¯æ´è¡åè¨åºæ±ºç­å¶å®ãPEACH åµå¥ 35 åæ©æ§åæè¡æåå®ï¼å¨æ°å å¡æ¿åºéç¼ç Pair Chat ä¸­ï¼æ¡ç¨å®å¨ç Claude 3.5 Sonet LLM æ¶æ§ï¼ä¸¦å¨éé»é¨ç½²ä¸­ä½¿ç¨çå¯¦ä¸çè³æé²è¡æ¸¬è©¦ãè©ä¼°äºæºç¢ºæ§ãå®å¨æ§åå¯ç¨æ§ãåå·®åå¹»è¦ºä¾æ½å¨å±å®³é²è¡åé¡ï¼ä¸¦ä½¿ç¨æè¡æ¥åæ¨¡å (TAM) è©ä¼°ä½¿ç¨èåé¥ãå¨æåçéé»é¨ç½²å¾ï¼é²è¡æ´æ°ä»¥ä¿®æ­£ä¸ååå®ã
  å¨ 240 åçå¯¦ä¸ççè¨åºè¿­ä»£ä¸­ï¼PEACH å¨ä¸åè¿­ä»£ä¸­åå¾ 97.5% (78/80) çç¬¬ä¸ä»£æºç¢ºæ§ï¼ä»¥å 96.7% (232/240) çæ´é«æºç¢ºæ§ãæ´æ°å¾ç PEACH å±ç¤ºåº 97.9% (235/240) çæºç¢ºæ§æåï¼è 95% æºç¢ºæ§çç©ºåè¨­æçµ±è¨ä¸çé¡¯èå·®ç° (p = 0.018ï¼95% CIï¼0.952-0.991)ãè§å¯å°æå°çå¹»è¦ºååå·® (åå¥çº 1/240 å 2/240)ãè¨åºé«çåå ± PEACH å¨ 95% çæ¡ä¾ä¸­å éäºæ±ºç­ï¼èè©åèéä¿¡åº¦å¨ PEACH å§ä»æ¼ kappa 0.772-0.893ï¼å¨ä¸»æ²»é«å¸«ä¹éä»æ¼ 0.610-0.784ã
  PEACH æ¯ä¸åæºç¢ºä¸é©ææ§å¼·çå·¥å·ï¼å¯å¢é²åæè¡ææ±ºç­å¶å®çä¸è´æ§åæçãæªä¾çç ç©¶ææ¢ç´¢å¶è·¨å°æ¥­çå¯æ´å±æ§ï¼ä»¥åå¶å°è¨åºçµæçå½±é¿ã

##### **Aligning AI Research with the Needs of Clinical Coding Workflows: Eight Recommendations Based on US Data Analysis and Critical Review**
2412.18043v1 by Yidong Gan, Maciej Rybinski, Ben Hachey, Jonathan K. Kummerfeld

Clinical coding is crucial for healthcare billing and data analysis. Manual
clinical coding is labour-intensive and error-prone, which has motivated
research towards full automation of the process. However, our analysis, based
on US English electronic health records and automated coding research using
these records, shows that widely used evaluation methods are not aligned with
real clinical contexts. For example, evaluations that focus on the top 50 most
common codes are an oversimplification, as there are thousands of codes used in
practice. This position paper aims to align AI coding research more closely
with practical challenges of clinical coding. Based on our analysis, we offer
eight specific recommendations, suggesting ways to improve current evaluation
methods. Additionally, we propose new AI-based methods beyond automated coding,
suggesting alternative approaches to assist clinical coders in their workflows.

æè¦ï¼è¨åºç·¨ç¢¼å°æ¼é«çä¿å¥è¨è²»åæ¸æåæè³ééè¦ãæåè¨åºç·¨ç¢¼ååå¯éä¸å®¹æåºé¯ï¼éä¿ä½¿ç ç©¶æåæµç¨çå¨é¢èªååãç¶èï¼æåçåæåºæ¼ç¾åè±æé»å­å¥åº·è¨éåä½¿ç¨éäºè¨éçèªåç·¨ç¢¼ç ç©¶ï¼é¡¯ç¤ºå»£æ³ä½¿ç¨çè©ä¼°æ¹æ³èå¯¦éè¨åºèæ¯ä¸ç¬¦ãä¾å¦ï¼å°æ³¨æ¼å 50 åæå¸¸è¦ä»£ç¢¼çè©ä¼°éæ¼ç°¡åï¼å çºå¯¦åä¸ä½¿ç¨äºæ¸ååä»£ç¢¼ãæ¬ç«å ´æä»¶æ¨å¨è® AI ç·¨ç¢¼ç ç©¶æ´è²¼è¿è¨åºç·¨ç¢¼çå¯¦éææ°ãæ ¹ææåçåæï¼æåæåºå«é å·é«å»ºè­°ï¼æåºæ¹åç®åè©ä¼°æ¹æ³çæ¹æ³ãæ­¤å¤ï¼æåæåºè¶è¶èªåç·¨ç¢¼çæ° AI æ¹æ³ï¼æåºåå©è¨åºç·¨ç¢¼äººå¡é²è¡å·¥ä½æµç¨çæ¿ä»£æ¹æ³ã


### LLM
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2025-01-09**|**ReFocus: Visual Editing as a Chain of Thought for Structured Image Understanding**|Xingyu Fu et.al.|[2501.05452v1](http://arxiv.org/abs/2501.05452v1)|null|
|**2025-01-09**|**An Empirical Study of Autoregressive Pre-training from Videos**|Jathushan Rajasegaran et.al.|[2501.05453v1](http://arxiv.org/abs/2501.05453v1)|null|
|**2025-01-09**|**Consistent Flow Distillation for Text-to-3D Generation**|Runjie Yan et.al.|[2501.05445v1](http://arxiv.org/abs/2501.05445v1)|null|
|**2025-01-09**|**A survey of textual cyber abuse detection using cutting-edge language models and large language models**|Jose A. Diaz-Garcia et.al.|[2501.05443v1](http://arxiv.org/abs/2501.05443v1)|null|
|**2025-01-09**|**Progressive Growing of Video Tokenizers for Highly Compressed Latent Spaces**|Aniruddha Mahapatra et.al.|[2501.05442v1](http://arxiv.org/abs/2501.05442v1)|null|
|**2025-01-09**|**LongProc: Benchmarking Long-Context Language Models on Long Procedural Generation**|Xi Ye et.al.|[2501.05414v1](http://arxiv.org/abs/2501.05414v1)|null|
|**2025-01-09**|**A Novel Pathology Foundation Model by Mayo Clinic, CharitÃ©, and Aignostics**|Maximilian Alber et.al.|[2501.05409v1](http://arxiv.org/abs/2501.05409v1)|null|
|**2025-01-09**|**TimeRL: Efficient Deep Reinforcement Learning with Polyhedral Dependence Graphs**|Pedro F. Silvestre et.al.|[2501.05408v1](http://arxiv.org/abs/2501.05408v1)|null|
|**2025-01-09**|**TimeDP: Learning to Generate Multi-Domain Time Series with Domain Prompts**|Yu-Hao Huang et.al.|[2501.05403v1](http://arxiv.org/abs/2501.05403v1)|null|
|**2025-01-09**|**BRATI: Bidirectional Recurrent Attention for Time-Series Imputation**|Armando Collado-Villaverde et.al.|[2501.05401v1](http://arxiv.org/abs/2501.05401v1)|null|
|**2025-01-09**|**Mechanistic understanding and validation of large AI models with SemanticLens**|Maximilian Dreyer et.al.|[2501.05398v1](http://arxiv.org/abs/2501.05398v1)|null|
|**2025-01-09**|**FairCode: Evaluating Social Bias of LLMs in Code Generation**|Yongkang Du et.al.|[2501.05396v1](http://arxiv.org/abs/2501.05396v1)|null|
|**2025-01-09**|**Large Physics Models: Towards a collaborative approach with Large Language Models and Foundation Models**|Kristian G. Barman et.al.|[2501.05382v1](http://arxiv.org/abs/2501.05382v1)|null|
|**2025-01-09**|**Developing a Foundation of Vector Symbolic Architectures Using Category Theory**|Nolan P Shaw et.al.|[2501.05368v1](http://arxiv.org/abs/2501.05368v1)|null|
|**2025-01-09**|**Search-o1: Agentic Search-Enhanced Large Reasoning Models**|Xiaoxi Li et.al.|[2501.05366v1](http://arxiv.org/abs/2501.05366v1)|null|
|**2025-01-09**|**On Corrigibility and Alignment in Multi Agent Games**|Edmund Dable-Heath et.al.|[2501.05360v1](http://arxiv.org/abs/2501.05360v1)|null|
|**2025-01-09**|**Stream Aligner: Efficient Sentence-Level Alignment via Distribution Induction**|Hantao Lou et.al.|[2501.05336v1](http://arxiv.org/abs/2501.05336v1)|null|
|**2025-01-09**|**The Bakers and Millers Game with Restricted Locations**|Simon Krogmann et.al.|[2501.05334v1](http://arxiv.org/abs/2501.05334v1)|null|
|**2025-01-09**|**AnCoGen: Analysis, Control and Generation of Speech with a Masked Autoencoder**|Samir Sadok et.al.|[2501.05332v1](http://arxiv.org/abs/2501.05332v1)|null|
|**2025-01-09**|**Enhancing Plagiarism Detection in Marathi with a Weighted Ensemble of TF-IDF and BERT Embeddings for Low-Resource Language Processing**|Atharva Mutsaddi et.al.|[2501.05260v1](http://arxiv.org/abs/2501.05260v1)|[link](https://github.com/aditya-choudhary599/Marathi-Plagiarism-Detection)|
|**2025-01-09**|**Automating the Detection of Code Vulnerabilities by Analyzing GitHub Issues**|Daniele Cipollone et.al.|[2501.05258v1](http://arxiv.org/abs/2501.05258v1)|null|
|**2025-01-09**|**CallNavi: A Study and Challenge on Function Calling Routing and Invocation in Large Language Models**|Yewei Song et.al.|[2501.05255v1](http://arxiv.org/abs/2501.05255v1)|null|
|**2025-01-09**|**From Scientific Texts to Verifiable Code: Automating the Process with Transformers**|Changjie Wang et.al.|[2501.05252v1](http://arxiv.org/abs/2501.05252v1)|null|
|**2025-01-09**|**RAG-WM: An Efficient Black-Box Watermarking Approach for Retrieval-Augmented Generation of Large Language Models**|Peizhuo Lv et.al.|[2501.05249v1](http://arxiv.org/abs/2501.05249v1)|null|
|**2025-01-09**|**Deriving Coding-Specific Sub-Models from LLMs using Resource-Efficient Pruning**|Laura Puccioni et.al.|[2501.05248v1](http://arxiv.org/abs/2501.05248v1)|null|
|**2025-01-09**|**Online Prompt and Solver Selection for Program Synthesis**|Yixuan Li et.al.|[2501.05247v1](http://arxiv.org/abs/2501.05247v1)|null|
|**2025-01-09**|**Optimizing Estonian TV Subtitles with Semi-supervised Learning and LLMs**|Artem Fedorchenko et.al.|[2501.05234v1](http://arxiv.org/abs/2501.05234v1)|null|
|**2025-01-09**|**Leveraging Large Language Models for Zero-shot Lay Summarisation in Biomedicine and Beyond**|Tomas Goldsack et.al.|[2501.05224v1](http://arxiv.org/abs/2501.05224v1)|null|
|**2025-01-09**|**ParaRev: Building a dataset for Scientific Paragraph Revision annotated with revision instruction**|LÃ©ane Jourdan et.al.|[2501.05222v1](http://arxiv.org/abs/2501.05222v1)|null|
|**2025-01-09**|**A Novel Approach to Scalable and Automatic Topic-Controlled Question Generation in Education**|Ziqing Li et.al.|[2501.05220v1](http://arxiv.org/abs/2501.05220v1)|null|
|**2025-01-09**|**GLaM-Sign: Greek Language Multimodal Lip Reading with Integrated Sign Language Accessibility**|Dimitris Kouremenos et.al.|[2501.05213v1](http://arxiv.org/abs/2501.05213v1)|null|
|**2025-01-09**|**Discovering Hidden Visual Concepts Beyond Linguistic Input in Infant Learning**|Xueyi Ke et.al.|[2501.05205v1](http://arxiv.org/abs/2501.05205v1)|null|
|**2025-01-09**|**Bringing Order Amidst Chaos: On the Role of Artificial Intelligence in Secure Software Engineering**|Matteo Esposito et.al.|[2501.05165v1](http://arxiv.org/abs/2501.05165v1)|null|
|**2025-01-09**|**Explainable AI based System for Supply Air Temperature Forecast**|Marika Eik et.al.|[2501.05163v1](http://arxiv.org/abs/2501.05163v1)|null|
|**2025-01-09**|**Biomedical Relation Extraction via Adaptive Document-Relation Cross-Mapping and Concept Unique Identifier**|Yufei Shang et.al.|[2501.05155v1](http://arxiv.org/abs/2501.05155v1)|null|
|**2025-01-09**|**A Systematic Literature Review on Deep Learning-based Depth Estimation in Computer Vision**|Ali Rohan et.al.|[2501.05147v1](http://arxiv.org/abs/2501.05147v1)|null|
|**2025-01-09**|**Centurio: On Drivers of Multilingual Ability of Large Vision-Language Model**|Gregor Geigle et.al.|[2501.05122v1](http://arxiv.org/abs/2501.05122v1)|null|
|**2025-01-09**|**Constrained Optimization of Charged Particle Tracking with Multi-Agent Reinforcement Learning**|Tobias Kortus et.al.|[2501.05113v1](http://arxiv.org/abs/2501.05113v1)|null|
|**2025-01-09**|**Advancing ALS Applications with Large-Scale Pre-training: Dataset Development and Downstream Assessment**|Haoyi Xiu et.al.|[2501.05095v1](http://arxiv.org/abs/2501.05095v1)|null|
|**2025-01-09**|**Comparison of Feature Learning Methods for Metadata Extraction from PDF Scholarly Documents**|Zeyd Boukhers et.al.|[2501.05082v1](http://arxiv.org/abs/2501.05082v1)|null|
|**2025-01-09**|**Multimodal-to-Text Prompt Engineering in Large Language Models Using Feature Embeddings for GNSS Interference Characterization**|Harshith Manjunath et.al.|[2501.05079v1](http://arxiv.org/abs/2501.05079v1)|null|
|**2025-01-09**|**Analyzing Memorization in Large Language Models through the Lens of Model Attribution**|Tarun Ram Menta et.al.|[2501.05078v1](http://arxiv.org/abs/2501.05078v1)|null|
|**2025-01-09**|**A Text-Based Knowledge-Embedded Soft Sensing Modeling Approach for General Industrial Process Tasks Based on Large Language Model**|Shuo Tong et.al.|[2501.05075v1](http://arxiv.org/abs/2501.05075v1)|null|
|**2025-01-09**|**Commonsense Video Question Answering through Video-Grounded Entailment Tree Reasoning**|Huabin Liu et.al.|[2501.05069v1](http://arxiv.org/abs/2501.05069v1)|null|
|**2025-01-09**|**D3RM: A Discrete Denoising Diffusion Refinement Model for Piano Transcription**|Hounsu Kim et.al.|[2501.05068v1](http://arxiv.org/abs/2501.05068v1)|null|
|**2025-01-09**|**LLaVA-Octopus: Unlocking Instruction-Driven Adaptive Projector Fusion for Video Understanding**|Jiaxing Zhao et.al.|[2501.05067v1](http://arxiv.org/abs/2501.05067v1)|null|
|**2025-01-09**|**Improving Skeleton-based Action Recognition with Interactive Object Information**|Hao Wen et.al.|[2501.05066v1](http://arxiv.org/abs/2501.05066v1)|null|
|**2025-01-09**|**Simultaneous emulation and downscaling with physically-consistent deep learning-based regional ocean emulators**|Leonard Lupin-Jimenez et.al.|[2501.05058v1](http://arxiv.org/abs/2501.05058v1)|null|
|**2025-01-09**|**TAPFed: Threshold Secure Aggregation for Privacy-Preserving Federated Learning**|Runhua Xu et.al.|[2501.05053v1](http://arxiv.org/abs/2501.05053v1)|null|
|**2025-01-09**|**SWE-Fixer: Training Open-Source LLMs for Effective and Efficient GitHub Issue Resolution**|Chengxing Xie et.al.|[2501.05040v1](http://arxiv.org/abs/2501.05040v1)|null|
|**2025-01-09**|**Enhancing Human-Like Responses in Large Language Models**|Ethem YaÄÄ±z ÃalÄ±k et.al.|[2501.05032v1](http://arxiv.org/abs/2501.05032v1)|null|
|**2025-01-09**|**A General Retrieval-Augmented Generation Framework for Multimodal Case-Based Reasoning Applications**|Ofir Marom et.al.|[2501.05030v1](http://arxiv.org/abs/2501.05030v1)|null|
|**2025-01-09**|**Finding Needles in Emb(a)dding Haystacks: Legal Document Retrieval via Bagging and SVR Ensembles**|Kevin BÃ¶nisch et.al.|[2501.05018v1](http://arxiv.org/abs/2501.05018v1)|[link](https://github.com/TheItCrOw/LIRAI24)|
|**2025-01-09**|**UAV-VLA: Vision-Language-Action System for Large Scale Aerial Mission Generation**|Oleg Sautenkov et.al.|[2501.05014v1](http://arxiv.org/abs/2501.05014v1)|null|
|**2025-01-09**|**Quantum-enhanced causal discovery for a small number of samples**|Yota Maeda et.al.|[2501.05007v1](http://arxiv.org/abs/2501.05007v1)|null|
|**2025-01-09**|**GiNet: Integrating Sequential and Context-Aware Learning for Battery Capacity Prediction**|Sara Sameer et.al.|[2501.04997v1](http://arxiv.org/abs/2501.04997v1)|null|
|**2025-01-09**|**IPDN: Image-enhanced Prompt Decoding Network for 3D Referring Expression Segmentation**|Qi Chen et.al.|[2501.04995v1](http://arxiv.org/abs/2501.04995v1)|null|
|**2025-01-09**|**TreeKV: Smooth Key-Value Cache Compression with Tree Structures**|Ziwei He et.al.|[2501.04987v1](http://arxiv.org/abs/2501.04987v1)|null|
|**2025-01-09**|**CuRLA: Curriculum Learning Based Deep Reinforcement Learning for Autonomous Driving**|Bhargava Uppuluri et.al.|[2501.04982v1](http://arxiv.org/abs/2501.04982v1)|null|
|**2025-01-09**|**SensorQA: A Question Answering Benchmark for Daily-Life Monitoring**|Benjamin Reichman et.al.|[2501.04974v1](http://arxiv.org/abs/2501.04974v1)|null|
|**2025-01-09**|**Battling the Non-stationarity in Time Series Forecasting via Test-time Adaptation**|HyunGi Kim et.al.|[2501.04970v1](http://arxiv.org/abs/2501.04970v1)|null|
|**2025-01-09**|**VoxEval: Benchmarking the Knowledge Understanding Capabilities of End-to-End Spoken Language Models**|Wenqian Cui et.al.|[2501.04962v1](http://arxiv.org/abs/2501.04962v1)|null|
|**2025-01-09**|**Demystifying Domain-adaptive Post-training for Financial LLMs**|Zixuan Ke et.al.|[2501.04961v1](http://arxiv.org/abs/2501.04961v1)|null|
|**2025-01-09**|**Addressing Domain Shift via Imbalance-Aware Domain Adaptation in Embryo Development Assessment**|Lei Li et.al.|[2501.04958v1](http://arxiv.org/abs/2501.04958v1)|null|
|**2025-01-09**|**Step-by-Step Mastery: Enhancing Soft Constraint Following Ability of Large Language Models**|Qingyu Ren et.al.|[2501.04945v1](http://arxiv.org/abs/2501.04945v1)|null|
|**2025-01-09**|**Jailbreaking Multimodal Large Language Models via Shuffle Inconsistency**|Shiji Zhao et.al.|[2501.04931v1](http://arxiv.org/abs/2501.04931v1)|null|
|**2025-01-09**|**Image2CADSeq: Computer-Aided Design Sequence and Knowledge Inference from Product Images**|Xingang Li et.al.|[2501.04928v1](http://arxiv.org/abs/2501.04928v1)|null|
|**2025-01-09**|**Investigating Numerical Translation with Large Language Models**|Wei Tang et.al.|[2501.04927v1](http://arxiv.org/abs/2501.04927v1)|null|
|**2025-01-09**|**FLowHigh: Towards Efficient and High-Quality Audio Super-Resolution with Single-Step Flow Matching**|Jun-Hak Yun et.al.|[2501.04926v1](http://arxiv.org/abs/2501.04926v1)|null|
|**2025-01-09**|**JELLY: Joint Emotion Recognition and Context Reasoning with LLMs for Conversational Speech Synthesis**|Jun-Hyeok Cha et.al.|[2501.04904v1](http://arxiv.org/abs/2501.04904v1)|null|
|**2025-01-09**|**SUGAR: Leveraging Contextual Confidence for Smarter Retrieval**|Hanna Zubkova et.al.|[2501.04899v1](http://arxiv.org/abs/2501.04899v1)|null|
|**2025-01-08**|**Reach Measurement, Optimization and Frequency Capping In Targeted Online Advertising Under k-Anonymity**|Yuan Gao et.al.|[2501.04882v1](http://arxiv.org/abs/2501.04882v1)|null|
|**2025-01-08**|**Leveraging Log Probabilities in Language Models to Forecast Future Events**|Tommaso Soru et.al.|[2501.04880v1](http://arxiv.org/abs/2501.04880v1)|null|
|**2025-01-08**|**Real-Time Textless Dialogue Generation**|Long Mai et.al.|[2501.04877v1](http://arxiv.org/abs/2501.04877v1)|null|
|**2025-01-08**|**Back Home: A Machine Learning Approach to Seashell Classification and Ecosystem Restoration**|Alexander Valverde et.al.|[2501.04873v1](http://arxiv.org/abs/2501.04873v1)|null|
|**2025-01-08**|**Advancing Retrieval-Augmented Generation for Persian: Development of Language Models, Comprehensive Benchmarks, and Best Practices for Optimization**|Sara Bourbour Hosseinbeigi et.al.|[2501.04858v1](http://arxiv.org/abs/2501.04858v1)|null|
|**2025-01-08**|**Exploring Large Language Models for Semantic Analysis and Categorization of Android Malware**|Brandon J Walton et.al.|[2501.04848v1](http://arxiv.org/abs/2501.04848v1)|null|
|**2025-01-08**|**Enhancing Listened Speech Decoding from EEG via Parallel Phoneme Sequence Prediction**|Jihwan Lee et.al.|[2501.04844v1](http://arxiv.org/abs/2501.04844v1)|null|
|**2025-01-08**|**Do Code LLMs Understand Design Patterns?**|Zhenyu Pan et.al.|[2501.04835v1](http://arxiv.org/abs/2501.04835v1)|null|
|**2025-01-08**|**ActPC-Geom: Towards Scalable Online Neural-Symbolic Learning via Accelerating Active Predictive Coding with Information Geometry & Diverse Cognitive Mechanisms**|Ben Goertzel et.al.|[2501.04832v1](http://arxiv.org/abs/2501.04832v1)|null|
|**2025-01-08**|**Building Foundations for Natural Language Processing of Historical Turkish: Resources and Models**|Åaziye BetÃ¼l ÃzateÅ et.al.|[2501.04828v1](http://arxiv.org/abs/2501.04828v1)|null|
|**2025-01-08**|**Intelligent Gradient Boosting Algorithms for Estimating Strength of Modified Subgrade Soil**|Ismail B. Mustapha et.al.|[2501.04826v1](http://arxiv.org/abs/2501.04826v1)|null|
|**2025-01-08**|**Unifying the Extremes: Developing a Unified Model for Detecting and Predicting Extremist Traits and Radicalization**|Allison Lahnala et.al.|[2501.04820v1](http://arxiv.org/abs/2501.04820v1)|null|
|**2025-01-08**|**Decentralised Resource Sharing in TinyML: Wireless Bilayer Gossip Parallel SGD for Collaborative Learning**|Ziyuan Bao et.al.|[2501.04817v1](http://arxiv.org/abs/2501.04817v1)|null|
|**2025-01-08**|**Reproducing HotFlip for Corpus Poisoning Attacks in Dense Retrieval**|Yongkang Li et.al.|[2501.04802v1](http://arxiv.org/abs/2501.04802v1)|[link](https://github.com/liyongkang123/hotflip_corpus_poisoning)|
|**2025-01-08**|**Cued Speech Generation Leveraging a Pre-trained Audiovisual Text-to-Speech Model**|Sanjana Sankar et.al.|[2501.04799v1](http://arxiv.org/abs/2501.04799v1)|null|
|**2025-01-08**|**Planarian Neural Networks: Evolutionary Patterns from Basic Bilateria Shaping Modern Artificial Neural Network Architectures**|Ziyuan Huang et.al.|[2501.04700v1](http://arxiv.org/abs/2501.04700v1)|null|
|**2025-01-08**|**Grokking at the Edge of Numerical Stability**|Lucas Prieto et.al.|[2501.04697v1](http://arxiv.org/abs/2501.04697v1)|[link](https://github.com/lucasprietoal/grokking-at-the-edge-of-numerical-stability)|
|**2025-01-08**|**EpiCoder: Encompassing Diversity and Complexity in Code Generation**|Yaoxiang Wang et.al.|[2501.04694v1](http://arxiv.org/abs/2501.04694v1)|null|
|**2025-01-08**|**Beyond Sight: Finetuning Generalist Robot Policies with Heterogeneous Sensors via Language Grounding**|Joshua Jones et.al.|[2501.04693v1](http://arxiv.org/abs/2501.04693v1)|null|
|**2025-01-08**|**URSA: Understanding and Verifying Chain-of-thought Reasoning in Multimodal Mathematics**|Ruilin Luo et.al.|[2501.04686v1](http://arxiv.org/abs/2501.04686v1)|null|
|**2025-01-08**|**Towards System 2 Reasoning in LLMs: Learning How to Think With Meta Chain-of-Thought**|Violet Xiang et.al.|[2501.04682v1](http://arxiv.org/abs/2501.04682v1)|null|
|**2025-01-08**|**TREAD: Token Routing for Efficient Architecture-agnostic Diffusion Training**|Felix Krause et.al.|[2501.04765v1](http://arxiv.org/abs/2501.04765v1)|null|
|**2025-01-08**|**Enhancing Financial VQA in Vision Language Models using Intermediate Structured Representations**|Archita Srivastava et.al.|[2501.04675v1](http://arxiv.org/abs/2501.04675v1)|null|
|**2025-01-08**|**DRIVINGVQA: Analyzing Visual Chain-of-Thought Reasoning of Vision Language Models in Real-World Scenarios with Driving Theory Tests**|Charles CorbiÃ¨re et.al.|[2501.04671v1](http://arxiv.org/abs/2501.04671v1)|null|
|**2025-01-08**|**On The Origin of Cultural Biases in Language Models: From Pre-training Data to Linguistic Phenomena**|Tarek Naous et.al.|[2501.04662v1](http://arxiv.org/abs/2501.04662v1)|null|
|**2025-01-08**|**Assessing Language Comprehension in Large Language Models Using Construction Grammar**|Wesley Scivetti et.al.|[2501.04661v1](http://arxiv.org/abs/2501.04661v1)|null|
|**2025-01-08**|**Multi-task retriever fine-tuning for domain-specific and efficient RAG**|Patrice BÃ©chard et.al.|[2501.04652v1](http://arxiv.org/abs/2501.04652v1)|null|
|**2025-01-08**|**FlairGPT: Repurposing LLMs for Interior Designs**|Gabrielle Littlefair et.al.|[2501.04648v1](http://arxiv.org/abs/2501.04648v1)|null|
|**2025-01-08**|**Knowledge Retrieval Based on Generative AI**|Te-Lun Yang et.al.|[2501.04635v1](http://arxiv.org/abs/2501.04635v1)|null|

#### Abstracts
##### **ReFocus: Visual Editing as a Chain of Thought for Structured Image Understanding**
2501.05452v1 by Xingyu Fu, Minqian Liu, Zhengyuan Yang, John Corring, Yijuan Lu, Jianwei Yang, Dan Roth, Dinei Florencio, Cha Zhang

Structured image understanding, such as interpreting tables and charts,
requires strategically refocusing across various structures and texts within an
image, forming a reasoning sequence to arrive at the final answer. However,
current multimodal large language models (LLMs) lack this multihop selective
attention capability. In this work, we introduce ReFocus, a simple yet
effective framework that equips multimodal LLMs with the ability to generate
"visual thoughts" by performing visual editing on the input image through code,
shifting and refining their visual focuses. Specifically, ReFocus enables
multimodal LLMs to generate Python codes to call tools and modify the input
image, sequentially drawing boxes, highlighting sections, and masking out
areas, thereby enhancing the visual reasoning process. We experiment upon a
wide range of structured image understanding tasks involving tables and charts.
ReFocus largely improves performance on all tasks over GPT-4o without visual
editing, yielding an average gain of 11.0% on table tasks and 6.8% on chart
tasks. We present an in-depth analysis of the effects of different visual
edits, and reasons why ReFocus can improve the performance without introducing
additional information. Further, we collect a 14k training set using ReFocus,
and prove that such visual chain-of-thought with intermediate information
offers a better supervision than standard VQA data, reaching a 8.0% average
gain over the same model trained with QA pairs and 2.6% over CoT.

æè¦ï¼çµæ§åå½±åçè§£ï¼ä¾å¦è©®éè¡¨æ ¼ååè¡¨ï¼éè¦å¨å½±åä¸­çåç¨®çµæ§åæå­ä¸­ç­ç¥æ§å°éæ°èç¦ï¼å½¢ææ¨çåºåæè½å¾åºæçµç­æ¡ãç¶èï¼ç®åçå¤æ¨¡æå¤§åèªè¨æ¨¡å (LLM) ç¼ºä¹éç¨®å¤è·³é¸ææ§æ³¨æåçè½åãå¨éé å·¥ä½ä¸­ï¼æåå¼å¥äº ReFocusï¼ä¸åç°¡å®ä½ææçæ¡æ¶ï¼å®è³¦äºå¤æ¨¡æ LLM ééç¨å¼ç¢¼å°è¼¸å¥å½±åé²è¡è¦è¦ºç·¨è¼¯ãè½ç§»ååªåå¶è¦è¦ºç¦é»çè½åï¼ä»¥ç¢çãè¦è¦ºæèããå·é«ä¾èªªï¼ReFocus è½è®å¤æ¨¡æ LLM ç¢ç Python ç¨å¼ç¢¼ä¾å¼å«å·¥å·ä¸¦ä¿®æ¹è¼¸å¥å½±åï¼å¾ªåºæ¼¸é²å°ç¹ªè£½æ¹å¡ãéé»æ¨ç¤ºåæ®µï¼ä»¥åé®è½ååï¼å¾èå¢å¼·è¦è¦ºæ¨çéç¨ãæåå¨æ¶åè¡¨æ ¼ååè¡¨çåç¨®çµæ§åå½±åçè§£ä»»åä¸­é²è¡å¯¦é©ãReFocus å¤§å¹æåäº GPT-4o å¨ææä»»åä¸çè¡¨ç¾ï¼å¨æ²æè¦è¦ºç·¨è¼¯çææ³ä¸ï¼å¨è¡¨æ ¼ä»»åä¸å¹³åæåäº 11.0%ï¼å¨åè¡¨ä»»åä¸æåäº 6.8%ãæåå°ä¸åè¦è¦ºç·¨è¼¯çææé²è¡äºæ·±å¥åæï¼ä¸¦èªªæäº ReFocus å¦ä½å¨ä¸å¼å¥é¡å¤è³è¨çææ³ä¸æåè¡¨ç¾çåå ãæ­¤å¤ï¼æåä½¿ç¨ ReFocus æ¶éäºä¸å 14k è¨ç·´éï¼ä¸¦è­æéç¨®åå«ä¸­éè³è¨çè¦è¦ºæèéæ¯æ¨æºç VQA è³ææä¾äºæ´å¥½çç£ç£ï¼å¨ä½¿ç¨ QA å°è¨ç·´çç¸åæ¨¡åä¸å¹³åæåäº 8.0%ï¼å¨ CoT ä¸æåäº 2.6%ã

##### **An Empirical Study of Autoregressive Pre-training from Videos**
2501.05453v1 by Jathushan Rajasegaran, Ilija Radosavovic, Rahul Ravishankar, Yossi Gandelsman, Christoph Feichtenhofer, Jitendra Malik

We empirically study autoregressive pre-training from videos. To perform our
study, we construct a series of autoregressive video models, called Toto. We
treat videos as sequences of visual tokens and train transformer models to
autoregressively predict future tokens. Our models are pre-trained on a diverse
dataset of videos and images comprising over 1 trillion visual tokens. We
explore different architectural, training, and inference design choices. We
evaluate the learned visual representations on a range of downstream tasks
including image recognition, video classification, object tracking, and
robotics. Our results demonstrate that, despite minimal inductive biases,
autoregressive pre-training leads to competitive performance across all
benchmarks. Finally, we find that scaling our video models results in similar
scaling curves to those seen in language models, albeit with a different rate.
More details at https://brjathu.github.io/toto/

æè¦ï¼æåå¯¦è­ç ç©¶å½±ççåæ­¸åè¨ç·´ãçºäºå·è¡æåçç ç©¶ï¼æåå»ºæ§äºä¸ç³»ååæ­¸å½±çæ¨¡åï¼ç¨±çº Totoãæåå°å½±çè¦çºè¦è¦ºç¬¦èåºåï¼ä¸¦è¨ç·´Transformeræ¨¡åä»¥åæ­¸é æ¸¬æªä¾ç¬¦èãæåçæ¨¡åå¨è¶é 1 ååè¦è¦ºç¬¦èçå¤åå½±çåå½±åè³æéä¸é²è¡é è¨ç·´ãæåæ¢ç´¢ä¸åçæ¶æ§ãè¨ç·´åæ¨è«è¨­è¨é¸é ãæåå¨åç¨®ä¸æ¸¸ä»»åä¸è©ä¼°å­¸ç¿å°çè¦è¦ºè¡¨å¾µï¼åæ¬å½±åè¾¨è­ãå½±çåé¡ãç©ä»¶è¿½è¹¤åæ©å¨äººæè¡ãæåççµæè­æï¼åç®¡æ­¸ç´åèª¤æå°ï¼åæ­¸åè¨ç·´ä»è½è®ææåºæºæ¸¬è©¦çæè½å·æç«¶ç­åãæå¾ï¼æåç¼ç¾æ´åæåçå½±çæ¨¡åæç¢çèèªè¨æ¨¡åä¸­çå°çé¡ä¼¼æ´åæ²ç·ï¼åç®¡éçä¸åãæ´å¤è©³æè«åé± https://brjathu.github.io/toto/

##### **Consistent Flow Distillation for Text-to-3D Generation**
2501.05445v1 by Runjie Yan, Yinbo Chen, Xiaolong Wang

Score Distillation Sampling (SDS) has made significant strides in distilling
image-generative models for 3D generation. However, its
maximum-likelihood-seeking behavior often leads to degraded visual quality and
diversity, limiting its effectiveness in 3D applications. In this work, we
propose Consistent Flow Distillation (CFD), which addresses these limitations.
We begin by leveraging the gradient of the diffusion ODE or SDE sampling
process to guide the 3D generation. From the gradient-based sampling
perspective, we find that the consistency of 2D image flows across different
viewpoints is important for high-quality 3D generation. To achieve this, we
introduce multi-view consistent Gaussian noise on the 3D object, which can be
rendered from various viewpoints to compute the flow gradient. Our experiments
demonstrate that CFD, through consistent flows, significantly outperforms
previous methods in text-to-3D generation.

æè¦ï¼åæ¸è¸é¤¾æ¡æ¨£ (SDS) å¨è¸é¤¾ç¨æ¼ 3D çæçå½±åçææ¨¡åæ¹é¢åå¾äºéå¤§é²å±ãç¶èï¼å®å°æ±æå¤§ä¼¼ç¶çè¡ä¸ºéå¸¸æå°è´è¦è¦ºåè³ªåå¤æ¨£æ§éä½ï¼éå¶äºå®å¨ 3D æç¨ä¸­çæè½ãå¨éé å·¥ä½ä¸­ï¼æåæåºäºä¸è´æµè¸é¤¾ (CFD)ï¼ä¾è§£æ±ºéäºéå¶ãæåé¦åå©ç¨æ´æ£ ODE æ SDE æ¡æ¨£ç¨åºçæ¢¯åº¦ä¾å¼å° 3D çæãå¾åºæ¼æ¢¯åº¦çæ¡æ¨£è§é»ä¾çï¼æåç¼ç¾ä¸åè¦è§ç 2D å½±åæµçä¸è´æ§å°æ¼é«åè³ªç 3D çæéå¸¸éè¦ãçºäºéææ­¤ç®çï¼æåå¨ 3D ç©ä»¶ä¸å¼å¥äºå¤è¦åä¸è´çé«æ¯éè¨ï¼å¯ä»¥å¾åç¨®è¦è§æ¸²æå®ä¾è¨ç®æµæ¢¯åº¦ãæåçå¯¦é©è­æï¼CFD ééä¸è´çæµï¼å¨æå­è½ 3D çæä¸­é¡¯èåªæ¼ååçåç¨®æ¹æ³ã

##### **A survey of textual cyber abuse detection using cutting-edge language models and large language models**
2501.05443v1 by Jose A. Diaz-Garcia, Joao Paulo Carvalho

The success of social media platforms has facilitated the emergence of
various forms of online abuse within digital communities. This abuse manifests
in multiple ways, including hate speech, cyberbullying, emotional abuse,
grooming, and sexting. In this paper, we present a comprehensive analysis of
the different forms of abuse prevalent in social media, with a particular focus
on how emerging technologies, such as Language Models (LMs) and Large Language
Models (LLMs), are reshaping both the detection and generation of abusive
content within these networks. We delve into the mechanisms through which
social media abuse is perpetuated, exploring the psychological and social
impact. Additionally, we examine the dual role of advanced language
models-highlighting their potential to enhance automated detection systems for
abusive behavior while also acknowledging their capacity to generate harmful
content. This paper aims to contribute to the ongoing discourse on online
safety and ethics, offering insights into the evolving landscape of cyberabuse
and the technological innovations that both mitigate and exacerbate it.

æè¦ï¼ç¤¾ç¾¤åªé«å¹³å°çæåä¿æäºæ¸ä½ç¤¾ç¾¤ä¸­åç¨®å½¢å¼ç¶²è·¯é¸åçåºç¾ãéç¨®é¸åä»¥å¤ç¨®æ¹å¼è¡¨ç¾ï¼åæ¬ä»æ¨è¨è«ãç¶²è·¯é¸åãæç·èå¾ãèªé¨åæ§ç°¡è¨ãå¨æ¬æä¸­ï¼æåå°ç¤¾ç¾¤åªé«ä¸­æ®éå­å¨çä¸åå½¢å¼çé¸åé²è¡äºå¨é¢çåæï¼ç¹å¥éæ³¨äºæ°èæè¡ï¼ä¾å¦èªè¨æ¨¡å (LM) åå¤§åèªè¨æ¨¡å (LLM)ï¼å¦ä½éæ°å¡é éäºç¶²è·¯ä¸­æ»ææ§å§å®¹çåµæ¸¬åç¢çãæåæ·±å¥æ¢è¨äºç¤¾ç¾¤åªé«é¸åæçºå­å¨çæ¹å¼ï¼æ¢è¨äºå¿çåç¤¾æå½±é¿ãæ­¤å¤ï¼æåæ¢è¨äºé²éèªè¨æ¨¡åçééè§è²ï¼å¼·èª¿äºå®åå¢å¼·èªååµæ¸¬ç³»çµ±ä»¥åµæ¸¬æ»ææ§è¡çºçæ½åï¼åæä¹æ¿èªå®åç¢çæå®³å§å®¹çè½åãæ¬ææ¨å¨çºç¶²è·¯å®å¨åéå¾·çæçºè¨è«ååºè²¢ç»ï¼æä¾å°ç¶²è·¯é¸åæ¼è®æå¢çè¦è§£ï¼ä»¥åæ¸è¼åå åç¶²è·¯é¸åçæè¡åµæ°ã

##### **Progressive Growing of Video Tokenizers for Highly Compressed Latent Spaces**
2501.05442v1 by Aniruddha Mahapatra, Long Mai, Yitian Zhang, David Bourgin, Feng Liu

Video tokenizers are essential for latent video diffusion models, converting
raw video data into spatiotemporally compressed latent spaces for efficient
training. However, extending state-of-the-art video tokenizers to achieve a
temporal compression ratio beyond 4x without increasing channel capacity poses
significant challenges. In this work, we propose an alternative approach to
enhance temporal compression. We find that the reconstruction quality of
temporally subsampled videos from a low-compression encoder surpasses that of
high-compression encoders applied to original videos. This indicates that
high-compression models can leverage representations from lower-compression
models. Building on this insight, we develop a bootstrapped
high-temporal-compression model that progressively trains high-compression
blocks atop well-trained lower-compression models. Our method includes a
cross-level feature-mixing module to retain information from the pretrained
low-compression model and guide higher-compression blocks to capture the
remaining details from the full video sequence. Evaluation of video benchmarks
shows that our method significantly improves reconstruction quality while
increasing temporal compression compared to direct extensions of existing video
tokenizers. Furthermore, the resulting compact latent space effectively trains
a video diffusion model for high-quality video generation with a reduced token
budget.

æè¦ï¼å½±çåè¯å¨å¯¹äºæ½å½±çæ©æ£æ¨¡åè³å³éè¦ï¼å®å°å½±çåå§èµæè½¬æ¢ä¸ºæ¶ç©ºåç¼©æ½ç©ºé´ï¼ä»¥å©äºææççè®­ç»ãç¶èï¼å°æåè¿çå½±çåè¯å¨å»¶ä¼¸å°å¨ä¸å¢å ééå®¹éçæåµä¸ï¼å®ç°è¶è¿ 4 åçæ¶é´åç¼©æ¯ï¼ä¼å¸¦æ¥éå¤§çææãå¨è¿é¡¹ç ç©¶ä¸­ï¼æä»¬æåºäºä¸ç§å¢å¼ºæ¶é´åç¼©çæ¿ä»£æ¹æ³ãæä»¬åç°ï¼ä½åç¼©ç¼ç å¨ä¸­æ¶é´å­éæ ·çå½±ççéå»ºè´¨éï¼èè¿åºç¨äºåå§å½±ççé«åç¼©ç¼ç å¨ãè¿è¡¨ç¤ºé«åç¼©æ¨¡åå¯ä»¥å©ç¨ä½åç¼©æ¨¡åçè¡¨ç¤ºãåºäºæ­¤è§è§£ï¼æä»¬å¼åäºä¸ä¸ªèªä¸¾é«æ¶é´åç¼©æ¨¡åï¼å®å¨è®­ç»è¯å¥½çä½åç¼©æ¨¡åä¹ä¸ï¼éæ­¥è®­ç»é«åç¼©åºåãæä»¬çæ¹æ³åå«äºä¸ä¸ªè·¨å±çº§ç¹å¾æ··åæ¨¡åï¼ä»¥ä¿çé¢åè®­ç»çä½åç¼©æ¨¡åä¸­çä¿¡æ¯ï¼å¹¶å¼å¯¼æ´é«çåç¼©åºåææå®æ´å½±çåºåä¸­å©ä½çç»èãå½±çåºåçè¯ä¼°æ¾ç¤ºï¼æä»¬çæ¹æ³å¤§å¹æ¹åäºéå»ºè´¨éï¼åæ¶ä¸ç°æå½±çåè¯å¨çç´æ¥å»¶ä¼¸ç¸æ¯ï¼å¢å äºæ¶é´åç¼©ãæ­¤å¤ï¼äº§ççç´§åæ½ç©ºé´ææå°è®­ç»äºä¸ä¸ªå½±çæ©æ£æ¨¡åï¼ç¨äºé«è´¨éå½±ççæï¼åæ¶åå°äºæ è®°é¢ç®ã

##### **LongProc: Benchmarking Long-Context Language Models on Long Procedural Generation**
2501.05414v1 by Xi Ye, Fangcong Yin, Yinghui He, Joie Zhang, Howard Yen, Tianyu Gao, Greg Durrett, Danqi Chen

Existing benchmarks for evaluating long-context language models (LCLMs)
primarily focus on long-context recall, requiring models to produce short
responses based on a few critical snippets while processing thousands of
irrelevant tokens. We introduce LongProc (Long Procedural Generation), a new
benchmark that requires both the integration of highly dispersed information
and long-form generation. LongProc consists of six diverse procedural
generation tasks, such as extracting structured information from HTML pages
into a TSV format and executing complex search procedures to create travel
plans. These tasks challenge LCLMs by testing their ability to follow detailed
procedural instructions, synthesize and reason over dispersed information, and
generate structured, long-form outputs (up to 8K tokens). Furthermore, as these
tasks adhere to deterministic procedures and yield structured outputs, they
enable reliable rule-based evaluation. We evaluate 17 LCLMs on LongProc across
three difficulty levels, with maximum numbers of output tokens set at 500, 2K,
and 8K. Notably, while all tested models claim a context window size above 32K
tokens, open-weight models typically falter on 2K-token tasks, and
closed-source models like GPT-4o show significant degradation on 8K-token
tasks. Further analysis reveals that LCLMs struggle to maintain long-range
coherence in long-form generations. These findings highlight critical
limitations in current LCLMs and suggest substantial room for improvement. Data
and code available at: https://princeton-pli.github.io/LongProc

æè¦ï¼ç¾æçç¨æ¼è©ä¼°é·èªå¢èªè¨æ¨¡å (LCLM) çåºæºä¸»è¦éä¸­å¨é·èªå¢å¬åä¸ï¼è¦æ±æ¨¡åæ ¹æå¹¾åééµçæ®µç¢çç°¡ç­çåæï¼åæèçæ¸ååä¸ç¸éçç¬¦èãæåå¼å¥äº LongProcï¼é·ç¨åºçæï¼ï¼éæ¯ä¸åæ°çåºæºï¼å®éè¦é«åº¦åæ£çè³è¨æ´ååé·æ ¼å¼çæãLongProc åå«å­é ä¸åçç¨åºçæä»»åï¼ä¾å¦å°çµæ§åè³è¨å¾ HTML é é¢æåå° TSV æ ¼å¼ï¼ä»¥åå·è¡è¤éçæå°ç¨åºä¾å»ºç«æéè¨ç«ãéäºä»»åééæ¸¬è©¦ LCLM éµå¾ªè©³ç´°ç¨åºèªªæãç¶ååæ¨çåæ£è³è¨ä»¥åçæçµæ§åãé·æ ¼å¼è¼¸åºï¼æå¤ 8K åç¬¦èï¼çè½åï¼å°å¶æåºææ°ãæ­¤å¤ï¼ç±æ¼éäºä»»åéµå¾ªç¢ºå®æ§çç¨åºä¸¦ç¢ççµæ§åçè¼¸åºï¼å æ­¤å®åè½é²è¡å¯é çåºæ¼è¦åçè©ä¼°ãæåå¨ä¸åé£åº¦ç­ç´ä¸å° 17 å LCLM é²è¡ LongProc è©ä¼°ï¼å°è¼¸åºç¬¦èçæå¤§æ¸éè¨­å®çº 500ã2K å 8Kãå¼å¾æ³¨æçæ¯ï¼éç¶æææ¸¬è©¦çæ¨¡åé½å®£ç¨±å¶èªå¢çªå£å¤§å°è¶é 32K åç¬¦èï¼ä½éæ¾æ¬éæ¨¡åéå¸¸å¨ 2K ç¬¦èä»»åä¸­å¤±æï¼èå GPT-4o éæ¨£çéæºæ¨¡åå¨ 8K ç¬¦èä»»åä¸­è¡¨ç¾åºé¡¯èä¸éãé²ä¸æ­¥çåæè¡¨æï¼LCLM é£ä»¥å¨é·æ ¼å¼çæä¸­ç¶­æé·ç¨ç¸å¹²æ§ãéäºç¼ç¾çªé¡¯äºç¶å LCLM çééµéå¶ï¼ä¸¦è¡¨ææå¾å¤§çæ¹é²ç©ºéãè³æåç¨å¼ç¢¼å¯æ¼ä»¥ä¸ç¶²ååå¾ï¼https://princeton-pli.github.io/LongProc

##### **A Novel Pathology Foundation Model by Mayo Clinic, CharitÃ©, and Aignostics**
2501.05409v1 by Maximilian Alber, Stephan Tietz, Jonas Dippel, Timo Milbich, TimothÃ©e Lesort, Panos Korfiatis, Moritz KrÃ¼gener, Beatriz Perez Cancer, Neelay Shah, Alexander MÃ¶llers, Philipp Seegerer, Alexandra Carpen-Amarie, Kai Standvoss, Gabriel Dernbach, Edwin de Jong, Simon Schallenberg, Andreas Kunft, Helmut Hoffer von Ankershoffen, Gavin Schaeferle, Patrick Duffy, Matt Redlon, Philipp Jurmeister, David Horst, Lukas Ruff, Klaus-Robert MÃ¼ller, Frederick Klauschen, Andrew Norgan

Recent advances in digital pathology have demonstrated the effectiveness of
foundation models across diverse applications. In this report, we present a
novel vision foundation model based on the RudolfV approach. Our model was
trained on a dataset comprising 1.2 million histopathology whole slide images,
collected from two medical institutions: Mayo Clinic and Charit\'e -
Universt\"atsmedizin Berlin. Comprehensive evaluations show that our model
achieves state-of-the-art performance across twenty-one public benchmark
datasets, even though it is neither the largest model by parameter count nor by
training dataset size.

æè¦ï¼æè¿å¨æ¸ä½ççå­¸çé²å±å·²å±ç¤ºåºåºç¤æ¨¡åå¨åç¨®æç¨ä¸­çæææ§ãå¨æ­¤å ±åä¸­ï¼æåæåºä¸ååºæ¼ RudolfV æ¹æ³çæ°ç©è¦è¦ºåºç¤æ¨¡åãæåçæ¨¡åæ¯å¨ä¸ååå« 120 è¬å¼µçµç¹ççå­¸å¨åçå½±åçè³æéä¸è¨ç·´ï¼éäºå½±åä¾èªå©åé«çæ©æ§ï¼æ¢ç´è¨ºæåå¤éç¹å¤§å­¸é«å­¸ä¸­å¿ãå¨é¢çè©ä¼°é¡¯ç¤ºï¼æåçæ¨¡åå¨ 21 åå¬éåºæºè³æéä¸éå°äºæåé²çæè½ï¼åç®¡å®æ¢ä¸æ¯åæ¸è¨æ¸æå¤§çæ¨¡åï¼ä¹ä¸æ¯è¨ç·´è³æéè¦æ¨¡æå¤§çæ¨¡åã

##### **TimeRL: Efficient Deep Reinforcement Learning with Polyhedral Dependence Graphs**
2501.05408v1 by Pedro F. Silvestre, Peter Pietzuch

Modern deep learning (DL) workloads increasingly use complex deep
reinforcement learning (DRL) algorithms that generate training data within the
learning loop. This results in programs with several nested loops and dynamic
data dependencies between tensors. While DL systems with eager execution
support such dynamism, they lack the optimizations and smart scheduling of
graph-based execution. Graph-based execution, however, cannot express dynamic
tensor shapes, instead requiring the use of multiple static subgraphs. Either
execution model for DRL thus leads to redundant computation, reduced
parallelism, and less efficient memory management.
  We describe TimeRL, a system for executing dynamic DRL programs that combines
the dynamism of eager execution with the whole-program optimizations and
scheduling of graph-based execution. TimeRL achieves this by introducing the
declarative programming model of recurrent tensors, which allows users to
define dynamic dependencies as intuitive recurrence equations. TimeRL
translates recurrent tensors into a polyhedral dependence graph (PDG) with
dynamic dependencies as symbolic expressions. Through simple PDG
transformations, TimeRL applies whole-program optimizations, such as automatic
vectorization, incrementalization, and operator fusion. The PDG also allows for
the computation of an efficient program-wide execution schedule, which decides
on buffer deallocations, buffer donations, and GPU/CPU memory swapping. We show
that TimeRL executes current DRL algorithms up to 47$\times$ faster than
existing DRL systems, while using 16$\times$ less GPU peak memory.

æè¦ï¼ç¾ä»£æ·±åº¦å­¸ç¿ (DL) å·¥ä½è² è¼æ¥çä½¿ç¨è¤éçæ·±åº¦å¼·åå­¸ç¿ (DRL) æ¼ç®æ³ï¼å¨å­¸ç¿è¿´åä¸­ç¢çè¨ç·´è³æãéæç¢çå·æå¤åå·¢çè¿´ååå¼µéä¹éåæè³æç¸ä¾æ§çç¨å¼ãéç¶å·æç±åå·è¡åè½ç DL ç³»çµ±æ¯æ´éç¨®åææ§ï¼ä½å®åç¼ºä¹åå½¢åå·è¡æä½³ååæºæ§åæç¨ãç¶èï¼åå½¢åå·è¡ç¡æ³è¡¨éåæå¼µéå½¢çï¼åèéè¦ä½¿ç¨å¤åéæå­åå½¢ãå æ­¤ï¼DRL çä»»ä¸å·è¡æ¨¡åé½æå°è´éè¤éç®ãéä½ä¸¦è¡åº¦åè¨æ¶é«ç®¡çæçä¸å½°ã
æåæè¿° TimeRLï¼éæ¯ä¸åç¨æ¼å·è¡åæ DRL ç¨å¼çç³»çµ±ï¼å®çµåäºç±åå·è¡çåææ§èåå½¢åå·è¡çå¨ç¨å¼æä½³ååæç¨ãTimeRL ééå¼å¥éè¿´å¼µéçå®£åå¼ç¨å¼è¨­è¨æ¨¡åä¾éææ­¤ä¸ç®æ¨ï¼ä½¿ç¨æ¶è½å¤ å°åæç¸ä¾æ§å®ç¾©çºç´è¦ºçéè¿´æ¹ç¨å¼ãTimeRL å°éè¿´å¼µéè½æçºå·æåæç¸ä¾æ§ï¼ä½çºç¬¦èè¡¨éå¼ï¼çå¤é¢é«ç¸ä¾åå½¢ (PDG)ãééç°¡å®ç PDG è½æï¼TimeRL å¥ç¨å¨ç¨å¼æä½³åï¼ä¾å¦èªååéåãéå¢ååéç®å­èåãPDG ä¹åè¨±è¨ç®åºææçå¨ç¨å¼å·è¡æç¨ï¼æ±ºå®ç·©è¡ååæ¶éç½®ãç·©è¡åæè´å GPU/CPU è¨æ¶é«äº¤æãæåé¡¯ç¤º TimeRL å·è¡ç®åç DRL æ¼ç®æ³éåº¦æ¯ç¾æç DRL ç³»çµ±å¿«é 47 åï¼åæä½¿ç¨å° 16 åç GPU å³°å¼è¨æ¶é«ã

##### **TimeDP: Learning to Generate Multi-Domain Time Series with Domain Prompts**
2501.05403v1 by Yu-Hao Huang, Chang Xu, Yueying Wu, Wu-Jun Li, Jiang Bian

Time series generation models are crucial for applications like data
augmentation and privacy preservation. Most existing time series generation
models are typically designed to generate data from one specified domain. While
leveraging data from other domain for better generalization is proved to work
in other application areas, this approach remains challenging for time series
modeling due to the large divergence in patterns among different real world
time series categories. In this paper, we propose a multi-domain time series
diffusion model with domain prompts, named TimeDP. In TimeDP, we utilize a time
series semantic prototype module which defines time series prototypes to
represent time series basis, each prototype vector serving as "word"
representing some elementary time series feature. A prototype assignment module
is applied to extract the extract domain specific prototype weights, for
learning domain prompts as generation condition. During sampling, we extract
"domain prompt" with few-shot samples from the target domain and use the domain
prompts as condition to generate time series samples. Experiments demonstrate
that our method outperforms baselines to provide the state-of-the-art in-domain
generation quality and strong unseen domain generation capability.

æè¦ï¼æéåºåçææ¨¡åå°æ¼è³ææ´ååé±ç§ä¿è­·ç­æç¨è³ééè¦ãç¾æçæéåºåçææ¨¡åéå¸¸è¨­è¨ç¨æ¼å¾ä¸åæå®é åçæè³æãéç¶å©ç¨å¶ä»é åçè³æä»¥ç²å¾æ´å¥½çæ³åè½åè¢«è­æå¨å¶ä»æç¨é åææï¼ä½éç¨®æ¹æ³å°æ¼æéåºåå»ºæ¨¡ä¾èªªä»ç¶å·æææ°æ§ï¼å çºä¸åç¾å¯¦ä¸çæéåºåé¡å¥ä¹éçæ¨¡å¼å·®ç°å¾å¤§ãå¨æ¬æä¸­ï¼æåæåºäºä¸åå¸¶æé åæç¤ºçå¤é åæéåºåæ´æ£æ¨¡åï¼åçº TimeDPãå¨ TimeDP ä¸­ï¼æåå©ç¨äºä¸åæéåºåèªç¾©ååæ¨¡çµï¼å®å®ç¾©äºæéåºåååä»¥è¡¨ç¤ºæéåºååºç¤ï¼æ¯ååååéä½çºãè©å½ãè¡¨ç¤ºä¸äºåºæ¬çæéåºåç¹å¾µãæç¨åååéæ¨¡çµä¾æåæåé åç¹å®çååæ¬éï¼ä»¥å­¸ç¿é åæç¤ºä½çºçææ¢ä»¶ãå¨æ¡æ¨£éç¨ä¸­ï¼æåå¾ç®æ¨é åä¸­æåå°æ¸æ¨£æ¬çãé åæç¤ºãï¼ä¸¦ä½¿ç¨é åæç¤ºä½çºæ¢ä»¶ä¾çææéåºåæ¨£æ¬ãå¯¦é©è¡¨æï¼æåçæ¹æ³åªæ¼åºæºï¼å¨é åå§çæåè³ªåå¼·å¤§çæªç¥é åçæè½åæ¹é¢æä¾æåé²çæè¡ã

##### **BRATI: Bidirectional Recurrent Attention for Time-Series Imputation**
2501.05401v1 by Armando Collado-Villaverde, Pablo MuÃ±oz, Maria D. R-Moreno

Missing data in time-series analysis poses significant challenges, affecting
the reliability of downstream applications. Imputation, the process of
estimating missing values, has emerged as a key solution. This paper introduces
BRATI, a novel deep-learning model designed to address multivariate time-series
imputation by combining Bidirectional Recurrent Networks and Attention
mechanisms. BRATI processes temporal dependencies and feature correlations
across long and short time horizons, utilizing two imputation blocks that
operate in opposite temporal directions. Each block integrates recurrent layers
and attention mechanisms to effectively resolve long-term dependencies.
  We evaluate BRATI on three real-world datasets under diverse missing-data
scenarios: randomly missing values, fixed-length missing sequences, and
variable-length missing sequences. Our findings demonstrate that BRATI
consistently outperforms state-of-the-art models, delivering superior accuracy
and robustness in imputing multivariate time-series data.

æè¦ï¼æåºåæä¸­éºå¤±çè³ææé æéå¤§çææ°ï¼å½±é¿ä¸æ¸¸æç¨ç¨å¼çå¯é æ§ãä¼°è¨éºå¤±å¼éåéç¨ç¨±çºå§æï¼å·²æçºä¸é ééµçè§£æ±ºæ¹æ¡ãæ¬æä»ç´¹ BRATIï¼éæ¯ä¸ç¨®æ°ç©çæ·±åº¦å­¸ç¿æ¨¡åï¼æ¨å¨ééçµåéåéè¿´ç¶²è·¯åæ³¨æåæ©å¶ä¾è§£æ±ºå¤è®éæåºå§æãBRATI èçè·¨é·ç­æéç¯åçæéä¾è³´æ§åç¹å¾µç¸éæ§ï¼å©ç¨å©åä»¥ç¸åæéæ¹åéä½çå§æåå¡ãæ¯ååå¡æ´åéè¿´å±¤åæ³¨æåæ©å¶ï¼ä»¥ææè§£æ±ºé·æä¾è³´æ§ãæåå¨ä¸çµçå¯¦ä¸çè³æéä¸è©ä¼° BRATIï¼éäºè³æéå·æå¤æ¨£åçéºå¤±è³ææå¢ï¼é¨æ©éºå¤±å¼ãåºå®é·åº¦éºå¤±åºååè®åé·åº¦éºå¤±åºåãæåçç ç©¶çµæé¡¯ç¤ºï¼BRATI å¨å§æå¤è®éæåºè³ææ¹é¢å§çµåªæ¼ç¾ææè¡æ¨¡åï¼æä¾æ´ä½³çæºç¢ºæ§åç©©å¥æ§ã

##### **Mechanistic understanding and validation of large AI models with SemanticLens**
2501.05398v1 by Maximilian Dreyer, Jim Berend, Tobias Labarta, Johanna Vielhaben, Thomas Wiegand, Sebastian Lapuschkin, Wojciech Samek

Unlike human-engineered systems such as aeroplanes, where each component's
role and dependencies are well understood, the inner workings of AI models
remain largely opaque, hindering verifiability and undermining trust. This
paper introduces SemanticLens, a universal explanation method for neural
networks that maps hidden knowledge encoded by components (e.g., individual
neurons) into the semantically structured, multimodal space of a foundation
model such as CLIP. In this space, unique operations become possible, including
(i) textual search to identify neurons encoding specific concepts, (ii)
systematic analysis and comparison of model representations, (iii) automated
labelling of neurons and explanation of their functional roles, and (iv) audits
to validate decision-making against requirements. Fully scalable and operating
without human input, SemanticLens is shown to be effective for debugging and
validation, summarizing model knowledge, aligning reasoning with expectations
(e.g., adherence to the ABCDE-rule in melanoma classification), and detecting
components tied to spurious correlations and their associated training data. By
enabling component-level understanding and validation, the proposed approach
helps bridge the "trust gap" between AI models and traditional engineered
systems. We provide code for SemanticLens on
https://github.com/jim-berend/semanticlens and a demo on
https://semanticlens.hhi-research-insights.eu.

æè¦ï¼èé£æ©ç­ç±äººé¡è¨­è¨çç³»çµ±ä¸åï¼é£æ©æ¯åçµä»¶çè§è²åä¾è³´æ§é½æ¸æ¥æç­ï¼è AI æ¨¡åçå§é¨éä½å¨å¾å¤§ç¨åº¦ä¸ä»ä¸éæï¼éé»ç¤äºå¯é©è­æ§ä¸¦ç ´å£äºä¿¡ä»»ãæ¬æä»ç´¹äº SemanticLensï¼éæ¯ä¸ç¨®éå°ç¥ç¶ç¶²è·¯çéç¨è§£éæ¹æ³ï¼å®å°çµä»¶ï¼ä¾å¦åå¥ç¥ç¶åï¼ç·¨ç¢¼çé±èç¥è­æ å°å°åºç¤æ¨¡åï¼ä¾å¦ CLIPï¼çèªç¾©çµæ§åå¤æ¨¡æç©ºéä¸­ãå¨éåç©ºéä¸­ï¼å¯ä»¥é²è¡ç¨ç¹çæä½ï¼åæ¬ (i) æå­æå°ä»¥è­å¥ç·¨ç¢¼ç¹å®æ¦å¿µçç¥ç¶åï¼(ii) ç³»çµ±åæåæ¯è¼æ¨¡åè¡¨ç¤ºï¼(iii) èªåæ¨è¨ç¥ç¶åä¸¦è§£éå¶åè½è§è²ï¼ä»¥å (iv) ç¨½æ ¸ä»¥é©è­æ±ºç­å¶å®æ¯å¦ç¬¦åè¦æ±ãSemanticLens å®å¨å¯æ´å±ä¸å¨æ²æäººå·¥è¼¸å¥çææ³ä¸éè¡ï¼å·²è­æå¶å¨é¤é¯åé©è­ãç¸½çµæ¨¡åç¥è­ãå°æ¨çèææä¿æä¸è´ï¼ä¾å¦ï¼éµå®é»è²ç´ ç¤åé¡ä¸­ç ABCDE è¦åï¼ä»¥åæª¢æ¸¬èèåç¸éæ§åå¶éè¯è¨ç·´è³æç¸éççµä»¶æ¹é¢æ¯ææçãééå¯¦ç¾çµä»¶ç´å¥ççè§£åé©è­ï¼ææåºçæ¹æ³æå©æ¼å½å AI æ¨¡åèå³çµ±å·¥ç¨ç³»çµ±ä¹éçãä¿¡ä»»å·®è·ããæåå¨ https://github.com/jim-berend/semanticlens ä¸æä¾äº SemanticLens çç¨å¼ç¢¼ï¼ä¸¦å¨ https://semanticlens.hhi-research-insights.eu ä¸æä¾äºç¤ºç¯ã

##### **FairCode: Evaluating Social Bias of LLMs in Code Generation**
2501.05396v1 by Yongkang Du, Jen-tse Huang, Jieyu Zhao, Lu Lin

Large language models (LLMs) have demonstrated significant capability in code
generation, drawing increasing attention to the evaluation of the quality and
safety of their outputs. However, research on bias in code generation remains
limited. Existing studies typically assess bias by applying malicious prompts
or reapply tasks and dataset for discriminative models. Given that LLMs are
often aligned with human values and that prior datasets are not fully optimized
for code-related tasks, there is a pressing need for benchmarks specifically
designed for evaluating code models. In this study, we introduce FairCode, a
novel benchmark for evaluating bias in code generation. FairCode comprises two
tasks: function implementation and test case generation, each evaluating social
bias through diverse scenarios. Additionally, we propose a new metric,
FairScore, to assess model performance on this benchmark. We conduct
experiments on widely used LLMs and provide a comprehensive analysis of the
results. The findings reveal that all tested LLMs exhibit bias. The code is
available at https://github.com/YongkDu/FairCode.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å·²å±ç¾åºçæç¨å¼ç¢¼çé¡¯èè½åï¼ä¸¦è¶ä¾è¶éæ³¨å¶è¼¸åºçåè³ªåå®å¨æ§è©ä¼°ãç¶èï¼éæ¼ç¨å¼ç¢¼çæåå·®çç ç©¶ä»ç¶æéãç¾æç ç©¶éå¸¸ééå¥ç¨æ¡ææç¤ºæéæ°å¥ç¨ä»»ååè³æéä¾è©ä¼°åå·®ï¼ä»¥é²è¡åè¾¨æ¨¡åãéæ¼ LLM éå¸¸èäººé¡å¹å¼è§ä¸è´ï¼ä¸ååçè³æéä¸¦æªéå°ç¨å¼ç¢¼ç¸éä»»åé²è¡å®å¨æä½³åï¼å æ­¤è¿«åéè¦å°éç¨æ¼è©ä¼°ç¨å¼ç¢¼æ¨¡åçåºæºãå¨æ­¤ç ç©¶ä¸­ï¼æåä»ç´¹äº FairCodeï¼éæ¯ä¸åç¨æ¼è©ä¼°ç¨å¼ç¢¼çæåå·®çæ°åºæºãFairCode åå«å©åä»»åï¼å½å¼å¯¦ä½åæ¸¬è©¦æ¡ä¾çæï¼æ¯åä»»åé½ééä¸åçå ´æ¯è©ä¼°ç¤¾æåå·®ãæ­¤å¤ï¼æåæåºäºä¸åæ°çææ¨ FairScoreï¼ç¨æ¼è©ä¼°æ¨¡åå¨æ­¤åºæºä¸çæè½ãæåå°å»£æ³ä½¿ç¨ç LLM é²è¡å¯¦é©ï¼ä¸¦å°çµæé²è¡å¨é¢åæãç ç©¶çµæé¡¯ç¤ºï¼ææåæ¸¬ç LLM é½è¡¨ç¾åºåå·®ãç¨å¼ç¢¼å¯å¨ https://github.com/YongkDu/FairCode åå¾ã

##### **Large Physics Models: Towards a collaborative approach with Large Language Models and Foundation Models**
2501.05382v1 by Kristian G. Barman, Sascha Caron, Emily Sullivan, Henk W. de Regt, Roberto Ruiz de Austri, Mieke Boon, Michael FÃ¤rber, Stefan FrÃ¶se, Faegheh Hasibi, Andreas Ipp, Rukshak Kapoor, Gregor Kasieczka, Daniel KostiÄ, Michael KrÃ¤mer, Tobias Golling, Luis G. Lopez, Jesus Marco, Sydney Otten, Pawel Pawlowski, Pietro Vischia, Erik Weber, Christoph Weniger

This paper explores ideas and provides a potential roadmap for the
development and evaluation of physics-specific large-scale AI models, which we
call Large Physics Models (LPMs). These models, based on foundation models such
as Large Language Models (LLMs) - trained on broad data - are tailored to
address the demands of physics research. LPMs can function independently or as
part of an integrated framework. This framework can incorporate specialized
tools, including symbolic reasoning modules for mathematical manipulations,
frameworks to analyse specific experimental and simulated data, and mechanisms
for synthesizing theories and scientific literature. We begin by examining
whether the physics community should actively develop and refine dedicated
models, rather than relying solely on commercial LLMs. We then outline how LPMs
can be realized through interdisciplinary collaboration among experts in
physics, computer science, and philosophy of science. To integrate these models
effectively, we identify three key pillars: Development, Evaluation, and
Philosophical Reflection. Development focuses on constructing models capable of
processing physics texts, mathematical formulations, and diverse physical data.
Evaluation assesses accuracy and reliability by testing and benchmarking.
Finally, Philosophical Reflection encompasses the analysis of broader
implications of LLMs in physics, including their potential to generate new
scientific understanding and what novel collaboration dynamics might arise in
research. Inspired by the organizational structure of experimental
collaborations in particle physics, we propose a similarly interdisciplinary
and collaborative approach to building and refining Large Physics Models. This
roadmap provides specific objectives, defines pathways to achieve them, and
identifies challenges that must be addressed to realise physics-specific large
scale AI models.

æè¦ï¼æ¬ææ¢è¨æ³æ³ï¼ä¸¦çºç©çç¹å®çå¤§è¦æ¨¡ AI æ¨¡åï¼æåç¨±ä¹çºå¤§åç©çæ¨¡åï¼LPMï¼çéç¼åè©ä¼°æä¾æ½å¨çè·¯ç·åãéäºæ¨¡ååºæ¼å¤§åèªè¨æ¨¡åï¼LLMï¼ç­åºç¤æ¨¡åï¼ä½¿ç¨å»£æ³çæ¸æé²è¡è¨ç·´ï¼ä¸¦å°ééå°ç©çç ç©¶çéæ±é²è¡èª¿æ´ãLPM å¯ä»¥ç¨ç«éè¡ï¼æä½çºæ´åæ¶æ§çä¸é¨åãæ­¤æ¶æ§å¯ä»¥æ´åå°ç¨å·¥å·ï¼åæ¬ç¨æ¼æ¸å­¸éç®çç¬¦èæ¨çæ¨¡çµãç¨æ¼åæç¹å®å¯¦é©åæ¨¡æ¬æ¸æçæ¶æ§ï¼ä»¥åç¨æ¼ç¶åçè«åç§å­¸æç»çæ©å¶ãæåé¦åæ¢è¨ç©ççæ¯å¦æè©²ç©æ¥µéç¼åæ¹é²å°ç¨æ¨¡åï¼èä¸æ¯åä¾è³´åæ¥­ LLMãç¶å¾ï¼æåæ¦è¿°å¦ä½ééç©çå­¸ãé»è¦ç§å­¸åç§å­¸å²å­¸æ¹é¢çå°å®¶ä¹éçè·¨é ååä½ä¾å¯¦ç¾ LPMãçºäºæææ´åéäºæ¨¡åï¼æåæ¾åºä¸åééµæ¯æ±ï¼éç¼ãè©ä¼°åå²å­¸åæãéç¼çéé»å¨æ¼å»ºæ§è½å¤ èçç©çææ¬ãæ¸å­¸å¬å¼ååç¨®ç©çæ¸æçæ¨¡åãè©ä¼°ééæ¸¬è©¦ååºæºæ¸¬è©¦ä¾è©ä¼°æºç¢ºæ§åå¯é æ§ãæå¾ï¼å²å­¸åæåå«åæ LLM å¨ç©çå­¸ä¸­æ´å»£æ³çå½±é¿ï¼åæ¬å®åç¢çæ°çç§å­¸çè§£çæ½åï¼ä»¥åå¨ç ç©¶ä¸­å¯è½åºç¾ä»éº¼æ°çåä½åæãåå°ç²å­ç©çå­¸ä¸­å¯¦é©åä½ççµç¹çµæ§åç¼ï¼æåæåºä¸åé¡ä¼¼è·¨é åååä½çæ¹æ³ä¾å»ºæ§åæ¹é²å¤§åç©çæ¨¡åãæ­¤è·¯ç·åæä¾äºå·é«ç®æ¨ï¼å®ç¾©äºéæç®æ¨çéå¾ï¼ä¸¦æ¾åºå¯¦ç¾ç©çç¹å®çå¤§è¦æ¨¡ AI æ¨¡åæå¿é è§£æ±ºçææ°ã

##### **Developing a Foundation of Vector Symbolic Architectures Using Category Theory**
2501.05368v1 by Nolan P Shaw, P Michael Furlong, Britt Anderson, Jeff Orchard

At the risk of overstating the case, connectionist approaches to machine
learning, i.e. neural networks, are enjoying a small vogue right now. However,
these methods require large volumes of data and produce models that are
uninterpretable to humans. An alternative framework that is compatible with
neural networks and gradient-based learning, but explicitly models
compositionality, is Vector Symbolic Architectures (VSAs). VSAs are a family of
algebras on high-dimensional vector representations. They arose in cognitive
science from the need to unify neural processing and the kind of symbolic
reasoning that humans perform. While machine learning methods have benefited
from category theoretical analyses, VSAs have not yet received similar
treatment. In this paper, we present a first attempt at applying category
theory to VSAs. Specifically, we conduct a brief literature survey
demonstrating the lacking intersection of these two topics, provide a list of
desiderata for VSAs, and propose that VSAs may be understood as a (division)
rig in a category enriched over a monoid in Met (the category of Lawvere metric
spaces). This final contribution suggests that VSAs may be generalised beyond
current implementations. It is our hope that grounding VSAs in category theory
will lead to more rigorous connections with other research, both within and
beyond, learning and cognition.

æè¦ï¼<paragraph>å³ä½¿èªå¤§å¶è©ï¼è¯çµä¸»ç¾©æ¹æ³å°æ©å¨å­¸ç¿ä¾èªªï¼ä¹å°±æ¯ç¥ç¶ç¶²è·¯ï¼ç®åæ­£çè¡èãç¶èï¼éäºæ¹æ³éè¦å¤§éçè³æï¼ä¸¦ç¢çäººé¡ç¡æ³çè§£çæ¨¡åãä¸ç¨®èç¥ç¶ç¶²è·¯ååºæ¼æ¢¯åº¦çå­¸ç¿ç¸å®¹ï¼ä½æç¢ºå»ºæ§çµåæ§çæ¿ä»£æ¶æ§ï¼æ¯åéç¬¦èæ¶æ§ (VSA)ãVSA æ¯ä¸çµéæ¼é«ç¶­åº¦åéè¡¨ç¤ºçä»£æ¸ãå®åæºæ¼èªç¥ç§å­¸ï¼ç®çæ¯çµ±ä¸ç¥ç¶èçåäººé¡å·è¡çç¬¦èæ¨çãéç¶æ©å¨å­¸ç¿æ¹æ³åçæ¼ç¯ççè«åæï¼ä½ VSA å°æªç²å¾é¡ä¼¼çèçãå¨æ¬æä¸­ï¼æåé¦æ¬¡åè©¦å°ç¯ççè«æç¨æ¼ VSAãå·é«ä¾èªªï¼æåé²è¡äºä¸é ç°¡ç­çæç»èª¿æ¥ï¼èªªæéå©åä¸»é¡ç¼ºä¹äº¤éï¼æä¾äº VSA ççæ³æ¸å®ï¼ä¸¦æåº VSA å¯ä»¥çè§£çºä¸å (é¤æ³) ç¯çä¸­ç rigï¼è©²ç¯çè±å¯æ¼ Met ä¸­çå®å (Lawvere åº¦éç©ºéçç¯ç)ãéåæçµè²¢ç»è¡¨æ VSA å¯ä»¥æ¦æ¬å°ç®åçå¯¦ä½ä¹å¤ãæåå¸æå° VSA åºæ¼ç¯ççè«å°æå©æ¼èå¶ä»ç ç©¶å»ºç«æ´å´è¬¹çé£çµï¼ç¡è«æ¯å¨å­¸ç¿åèªç¥çç¯çå§æå¤ã</paragraph>

##### **Search-o1: Agentic Search-Enhanced Large Reasoning Models**
2501.05366v1 by Xiaoxi Li, Guanting Dong, Jiajie Jin, Yuyao Zhang, Yujia Zhou, Yutao Zhu, Peitian Zhang, Zhicheng Dou

Large reasoning models (LRMs) like OpenAI-o1 have demonstrated impressive
long stepwise reasoning capabilities through large-scale reinforcement
learning. However, their extended reasoning processes often suffer from
knowledge insufficiency, leading to frequent uncertainties and potential
errors. To address this limitation, we introduce \textbf{Search-o1}, a
framework that enhances LRMs with an agentic retrieval-augmented generation
(RAG) mechanism and a Reason-in-Documents module for refining retrieved
documents. Search-o1 integrates an agentic search workflow into the reasoning
process, enabling dynamic retrieval of external knowledge when LRMs encounter
uncertain knowledge points. Additionally, due to the verbose nature of
retrieved documents, we design a separate Reason-in-Documents module to deeply
analyze the retrieved information before injecting it into the reasoning chain,
minimizing noise and preserving coherent reasoning flow. Extensive experiments
on complex reasoning tasks in science, mathematics, and coding, as well as six
open-domain QA benchmarks, demonstrate the strong performance of Search-o1.
This approach enhances the trustworthiness and applicability of LRMs in complex
reasoning tasks, paving the way for more reliable and versatile intelligent
systems. The code is available at
\url{https://github.com/sunnynexus/Search-o1}.

æè¦ï¼å¤§åæ¨çæ¨¡åï¼LRMï¼ï¼ä¾å¦ OpenAI-o1ï¼å·²éè¿å¤§è§æ¨¡å¼ºåå­¦ä¹ å±ç¤ºäºä»¤äººå°è±¡æ·±å»çé¿æ­¥æ¨çè½åãç¶èï¼å®ä»¬æ©å±çæ¨çè¿ç¨éå¸¸ä¼åå°ç¥è¯ä¸è¶³çå½±åï¼ä»èå¯¼è´é¢ç¹çä¸ç¡®å®æ§åæ½å¨çéè¯¯ãä¸ºäºè§£å³è¿ä¸ªéå¶ï¼æä»¬å¼å¥äº \textbf{Search-o1}ï¼è¿æ¯ä¸ä¸ªæ¡æ¶ï¼å®éè¿ä»£çæ£ç´¢å¢å¼ºçæï¼RAGï¼æºå¶åç¨äºç²¾ç¼æ£ç´¢å°çææ¡£çææ¡£ä¸­æ¨çæ¨¡åæ¥å¢å¼º LRMãSearch-o1 å°ä»£çæç´¢å·¥ä½æµéæå°æ¨çè¿ç¨ä¸­ï¼ä½¿ LRM å¨éå°ä¸ç¡®å®çç¥è¯ç¹æ¶è½å¤å¨ææ£ç´¢å¤é¨ç¥è¯ãæ­¤å¤ï¼ç±äºæ£ç´¢å°çææ¡£åé¿ï¼æä»¬è®¾è®¡äºä¸ä¸ªåç¬çææ¡£ä¸­æ¨çæ¨¡åï¼ä»¥ä¾¿å¨å°æ£ç´¢å°çä¿¡æ¯æ³¨å¥æ¨çé¾ä¹åå¯¹å¶è¿è¡æ·±å¥åæï¼æå¤§ç¨åº¦å°åå°åªé³å¹¶ä¿æè¿è´¯çæ¨çæµç¨ãå¨ç§å­¦ãæ°å­¦åç¼ç ä¸­çå¤ææ¨çä»»å¡ä»¥åå­ä¸ªå¼æ¾å QA åºåä¸çå¤§éå®éªè¡¨æäº Search-o1 çå¼ºå¤§æ§è½ãè¿ç§æ¹æ³å¢å¼ºäº LRM å¨å¤ææ¨çä»»å¡ä¸­çå¯ä¿¡åº¦åéç¨æ§ï¼ä¸ºæ´å¯é åéç¨çæºè½ç³»ç»éºå¹³äºéè·¯ãä»£ç å¯å¨ \url{https://github.com/sunnynexus/Search-o1} è·å¾ã

##### **On Corrigibility and Alignment in Multi Agent Games**
2501.05360v1 by Edmund Dable-Heath, Boyko Vodenicharski, James Bishop

Corrigibility of autonomous agents is an under explored part of system
design, with previous work focusing on single agent systems. It has been
suggested that uncertainty over the human preferences acts to keep the agents
corrigible, even in the face of human irrationality. We present a general
framework for modelling corrigibility in a multi-agent setting as a 2 player
game in which the agents always have a move in which they can ask the human for
supervision. This is formulated as a Bayesian game for the purpose of
introducing uncertainty over the human beliefs. We further analyse two specific
cases. First, a two player corrigibility game, in which we want corrigibility
displayed in both agents for both common payoff (monotone) games and harmonic
games. Then we investigate an adversary setting, in which one agent is
considered to be a `defending' agent and the other an `adversary'. A general
result is provided for what belief over the games and human rationality the
defending agent is required to have to induce corrigibility.

æè¦ï¼èªä¸»ä»£ççå¯ä¿®æ­£æ§æ¯ç³»ç»è®¾è®¡ä¸­å°æªæ¢ç´¢çé¨åï¼ä»¥åçå·¥ä½éç¹æ¾å¨åä»£çç³»ç»ä¸ãæäººæåºï¼å¯¹äººç±»åå¥½çä¸ç¡®å®æ§æå©äºä¿æä»£ççå¯ä¿®æ­£æ§ï¼å³ä½¿é¢å¯¹äººç±»çä¸çæ§ãæä»¬æåºäºä¸ä¸ªéç¨çæ¡æ¶ï¼ç¨äºå¨å¤ä»£çç¯å¢ä¸­å¯¹å¯ä¿®æ­£æ§è¿è¡å»ºæ¨¡ï¼ä½ä¸ºä¸ç§ 2 äººæ¸¸æï¼å¶ä¸­ä»£çå§ç»å¯ä»¥éåè¡å¨ï¼è¦æ±äººç±»è¿è¡çç£ãè¿è¢«è¡¨è¿°ä¸ºè´å¶æ¯åå¼ï¼ç®çæ¯å¼å¥å¯¹äººç±»ä¿¡å¿µçä¸ç¡®å®æ§ãæä»¬è¿ä¸æ­¥åæäºä¸¤ä¸ªå·ä½æ¡ä¾ãé¦åï¼ä¸ä¸ªåäººå¯ä¿®æ­£æ§æ¸¸æï¼æä»¬å¸æå¨å±åæ¶çï¼åè°ï¼æ¸¸æååè°æ¸¸æä¸­æ¾ç¤ºä¸¤ä¸ªä»£ççå¯ä¿®æ­£æ§ãç¶åï¼æä»¬è°æ¥äºä¸ä¸ªå¯¹æç¯å¢ï¼å¶ä¸­ä¸ä¸ªä»£çè¢«è®¤ä¸ºæ¯âé²å¾¡âä»£çï¼å¦ä¸ä¸ªä»£çè¢«è®¤ä¸ºæ¯âå¯¹æâä»£çãæä¾äºä¸ä¸ªä¸è¬ç»æï¼è¯´æé²å¾¡ä»£çéè¦å¯¹æ¸¸æåäººç±»çæ§çä¿¡å¿µæ¯ä»ä¹ï¼æè½è¯±å¯¼å¯ä¿®æ­£æ§ã

##### **Stream Aligner: Efficient Sentence-Level Alignment via Distribution Induction**
2501.05336v1 by Hantao Lou, Jiaming Ji, Kaile Wang, Yaodong Yang

The rapid advancement of large language models (LLMs) has led to significant
improvements in their capabilities, but also to increased concerns about their
alignment with human values and intentions. Current alignment strategies,
including adaptive training and inference-time methods, have demonstrated
potential in this area. However, these approaches still struggle to balance
deployment complexity and capability across various tasks and difficulties. In
this work, we introduce the Streaming Distribution Induce Aligner (Stream
Aligner), a novel alignment paradigm that combines efficiency with enhanced
performance in various tasks throughout the generation process. Stream Aligner
achieves dynamic sentence-level correction by using a small model to learn the
preferences of the suffix sentence, iteratively correcting the suffix sentence
output by the upstream model, and then using the corrected sentence to replace
the suffix sentence in subsequent generations. Compared to Aligner, our
experiments demonstrate that Stream Aligner reduces reliance on the
capabilities of additional models, enhances the reasoning abilities of LLMs,
and decreases latency during user interaction. Specifically, Stream Aligner-2B
model has achieved an improvement of 76.1% in helpfulness, 36.0% in
harmlessness on the tested Llama2-70B-chat model, and Stream Aligner-8B has
achieved an improvement of 3.5% on the math ability of the tested
Llama3-70B-Instruct model.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) çå¿«éé²å±å·²é¡¯èæåå¶è½åï¼ä½ä¹å¼ç¼æ´å¤éæ¼å¶èäººé¡å¹å¼è§åæåä¸è´æ§ççæ®ãç®åçå°é½ç­ç¥ï¼åæ¬é©ææ§è¨ç·´åæ¨è«æéæ¹æ³ï¼å·²å¨æ­¤é åå±ç¾æ½åãç¶èï¼éäºæ¹æ³ä»é£ä»¥å¨åç¨®ä»»ååé£åº¦ä¸­åå¾é¨ç½²è¤éåº¦åè½åçå¹³è¡¡ãå¨æ¬æä¸­ï¼æåä»ç´¹äºä¸²æµåä½èªå°å°é½å¨ (Stream Aligner)ï¼éæ¯ä¸ç¨®æ°ç©çå°é½ç¯ä¾ï¼çµåäºæçèå¨æ´åçæéç¨ä¸­åç¨®ä»»åä¸­å¢å¼·çæè½ãStream Aligner ééä½¿ç¨å°åæ¨¡åä¾å­¸ç¿å¾ç¶´å¥å­çåå¥½ï¼åè¦ä¿®æ­£ä¸æ¸¸æ¨¡åè¼¸åºçå¾ç¶´å¥å­ï¼ç¶å¾ä½¿ç¨ä¿®æ­£éçå¥å­åä»£å¾çºçæä¸­çå¾ç¶´å¥å­ï¼é²èéæåæçå¥å­å±¤ç´ä¿®æ­£ãè Aligner ç¸æ¯ï¼æåçå¯¦é©è­æ Stream Aligner æ¸å°äºå°å¶ä»æ¨¡åè½åçä¾è³´ï¼å¢å¼·äº LLM çæ¨çè½åï¼ä¸¦éä½äºä½¿ç¨èäºåæéçå»¶é²ãå·é«èè¨ï¼Stream Aligner-2B æ¨¡åå¨æçæ§æ¹é¢æåäº 76.1%ï¼å¨ç¡å®³æ§æ¹é¢æåäº 36.0%ï¼å¨æ¸¬è©¦ç Llama2-70B-chat æ¨¡åä¸ï¼è Stream Aligner-8B åå¨æ¸¬è©¦ç Llama3-70B-Instruct æ¨¡åçæ¸å­¸è½åæ¹é¢æåäº 3.5%ã

##### **The Bakers and Millers Game with Restricted Locations**
2501.05334v1 by Simon Krogmann, Pascal Lenzner, Alexander Skopalik

We study strategic location choice by customers and sellers, termed the
Bakers and Millers Game in the literature. In our generalized setting, each
miller can freely choose any location for setting up a mill, while each baker
is restricted in the choice of location for setting up a bakery. For optimal
bargaining power, a baker would like to select a location with many millers to
buy flour from and with little competition from other bakers. Likewise, a
miller aims for a location with many bakers and few competing millers. Thus,
both types of agents choose locations to optimize the ratio of agents of
opposite type divided by agents of the same type at their chosen location.
Originally raised in the context of Fractional Hedonic Games, the Bakers and
Millers Game has applications that range from commerce to product design.
  We study the impact of location restrictions on the properties of the game.
While pure Nash equilibria trivially exist in the setting without location
restrictions, we show via a sophisticated, efficient algorithm that even the
more challenging restricted setting admits equilibria. Moreover, the computed
equilibrium approximates the optimal social welfare by a factor of at most
$2\left(\frac{e}{e-1}\right)$. Furthermore, we give tight bounds on the price
of anarchy/stability.
  On the conceptual side, the location choice feature adds a new layer to the
standard setting of Hedonic Games, in the sense that agents that select the
same location form a coalition. This allows to naturally restrict the possible
coalitions that can be formed. With this, our model generalizes simple
symmetric Fractional Hedonic Games on complete bipartite valuation graphs and
also Hedonic Diversity Games with utilities single-peaked at 0. We believe that
this generalization is also a very interesting direction for other types of
Hedonic Games.

æè¦ï¼<paragraph>æåç ç©¶ç±å®¢æ¶åè³£æ¹é²è¡çç­ç¥æ§ä½ç½®é¸æï¼å¨æç»ä¸­ç¨±çºéºµåå¸«åç£¨åä¸»çéæ²ãå¨æåæ¦æ¬çè¨­å®ä¸­ï¼æ¯åç£¨åä¸»å¯ä»¥èªç±é¸æä»»ä½ä½ç½®ä¾è¨­ç½®ç£¨åï¼èæ¯åéºµåå¸«å¨é¸æè¨­ç½®éºµååºçæåå°å°é»éå¶ãçºäºç²å¾æä½³çè­°å¹è½åï¼éºµåå¸«å¸æé¸æä¸åæè¨±å¤ç£¨åä¸»å¯ä»¥è³¼è²·éºµç²ä¸èå¶ä»éºµåå¸«ç«¶ç­è¼å°çå°é»ãåæ¨£å°ï¼ç£¨åä¸»æé¸æä¸åæè¨±å¤éºµåå¸«ä¸ç«¶ç­å°æè¼å°çç£¨åä¸»çå°é»ãå æ­¤ï¼éå©ç¨®é¡åçä»£çäººé½æé¸æå°é»ä¾åªåå¨ä»åæé¸æçå°é»ï¼ç¸åé¡åçä»£çäººèç¸åé¡åçä»£çäººçæ¯ä¾ãæåå¨åæ¸äº«æ¨éæ²çèæ¯ä¸æåºï¼éºµåå¸«åç£¨åä¸»çéæ²æå¾åæ¥­å°ç¢åè¨­è¨çå»£æ³æç¨ãæåç ç©¶å°é»éå¶å°éæ²å±¬æ§çå½±é¿ãéç¶å¨æ²æå°é»éå¶çè¨­å®ä¸­ï¼ç´ç´è¨±åè¡¡é¡¯ç¶å­å¨ï¼ä½æåééä¸ç¨®è¤éãææçæ¼ç®æ³è­æï¼å³ä½¿å¨æ´å·ææ°æ§çåéè¨­å®ä¸­ä¹è½æ¿èªåè¡¡ãæ­¤å¤ï¼è¨ç®åºçåè¡¡ä»¥æå¤ $2\left(\frac{e}{e-1}\right)$ çå å­è¿ä¼¼æä½³ç¤¾æç¦å©ãæ­¤å¤ï¼æåå°ç¡æ¿åºçæ/ç©©å®çå¹æ ¼çµ¦äºå´æ ¼çéå¶ãå¨æ¦å¿µæ¹é¢ï¼å°é»é¸æåè½çºäº«æ¨éæ²çæ¨æºè¨­å®å¢å äºä¸å±¤ï¼å¨æ¼é¸æç¸åå°é»çä»£çäººæçµæä¸åè¯çãéåè¨±èªç¶å°éå¶å¯ä»¥å½¢æçå¯è½è¯çãæäºéåï¼æåçæ¨¡åæ¦æ¬äºå¨å®æ´çè«äºååä¼°å¼åè¡¨ä¸çç°¡å®å°ç¨±åæ¸äº«æ¨éæ²ï¼ä»¥åå¨ 0 èå®å³°çäº«æ¨å¤æ¨£æ§éæ²ãæåç¸ä¿¡éåæ¦æ¬å°æ¼å¶ä»é¡åçäº«æ¨éæ²ä¾èªªä¹æ¯ä¸åéå¸¸æè¶£çç¼å±æ¹åã</paragraph>

##### **AnCoGen: Analysis, Control and Generation of Speech with a Masked Autoencoder**
2501.05332v1 by Samir Sadok, Simon Leglaive, Laurent Girin, GaÃ«l Richard, Xavier Alameda-Pineda

This article introduces AnCoGen, a novel method that leverages a masked
autoencoder to unify the analysis, control, and generation of speech signals
within a single model. AnCoGen can analyze speech by estimating key attributes,
such as speaker identity, pitch, content, loudness, signal-to-noise ratio, and
clarity index. In addition, it can generate speech from these attributes and
allow precise control of the synthesized speech by modifying them. Extensive
experiments demonstrated the effectiveness of AnCoGen across speech
analysis-resynthesis, pitch estimation, pitch modification, and speech
enhancement.

æè¦ï¼æ¬æä»ç´¹äº AnCoGenï¼ä¸ç¨®æ°æ¹æ³ï¼å®å©ç¨æ©è½å¼èªåç·¨ç¢¼å¨å¨å®ä¸æ¨¡åä¸­çµ±ä¸èªé³ä¿¡èçåæãæ§å¶åçæãAnCoGen å¯ä»¥ééä¼°è¨ééµå±¬æ§ä¾åæèªé³ï¼ä¾å¦èªªè©±èèº«åãé³é«ãå§å®¹ãé¿åº¦ãä¿¡åªæ¯åæ¸æ°åº¦ææ¨ãæ­¤å¤ï¼å®å¯ä»¥å¾éäºå±¬æ§çæèªé³ï¼ä¸¦ééä¿®æ¹å®åä¾ç²¾ç¢ºæ§å¶åæçèªé³ãå¤§éçå¯¦é©è­æäº AnCoGen å¨èªé³åæååæãé³é«ä¼°è¨ãé³é«ä¿®æ¹åèªé³å¢å¼·æ¹é¢çæææ§ã

##### **Enhancing Plagiarism Detection in Marathi with a Weighted Ensemble of TF-IDF and BERT Embeddings for Low-Resource Language Processing**
2501.05260v1 by Atharva Mutsaddi, Aditya Choudhary

Plagiarism involves using another person's work or concepts without proper
attribution, presenting them as original creations. With the growing amount of
data communicated in regional languages such as Marathi -- one of India's
regional languages -- it is crucial to design robust plagiarism detection
systems tailored for low-resource languages. Language models like Bidirectional
Encoder Representations from Transformers (BERT) have demonstrated exceptional
capability in text representation and feature extraction, making them essential
tools for semantic analysis and plagiarism detection. However, the application
of BERT for low-resource languages remains under-explored, particularly in the
context of plagiarism detection. This paper presents a method to enhance the
accuracy of plagiarism detection for Marathi texts using BERT sentence
embeddings in conjunction with Term Frequency-Inverse Document Frequency
(TF-IDF) feature representation. This approach effectively captures
statistical, semantic, and syntactic aspects of text features through a
weighted voting ensemble of machine learning models.

æè¦ï¼å½ç«æ¶åä½¿ç¨ä»äººçä½åææ¦å¿µï¼å»æ²æé©ç¶çåºèï¼ä¸¦å°å®ååç¾çºååµä½åãé¨èä»¥é¦¬æå°èªç­ååèªè¨ï¼å°åº¦çååèªè¨ä¹ä¸ï¼å³éçè³æéä¸æ·å¢å ï¼è¨­è¨éå°ä½è³æºèªè¨çå¼·å¤§å½ç«åµæ¸¬ç³»çµ±è³ééè¦ãå Transformer çéåç·¨ç¢¼å¨è¡¨å¾µ (BERT) ç­èªè¨æ¨¡åå¨æå­è¡¨å¾µåç¹å¾µèåæ¹é¢å±ç¾äºéå¡çè½åï¼ä½¿å¶æçºèªæåæåå½ç«åµæ¸¬çå¿è¦å·¥å·ãç¶èï¼BERT å¨ä½è³æºèªè¨ä¸­çæç¨ä»æªè¢«ååæ¢ç´¢ï¼ç¹å¥æ¯å¨å½ç«åµæ¸¬çèæ¯ä¸ãæ¬ææåºäºä¸ç¨®æ¹æ³ï¼ä½¿ç¨ BERT å¥å­åµå¥èè©é »éæä»¶é »ç (TF-IDF) ç¹å¾µè¡¨å¾µç¸çµåï¼ä¾å¢å¼·é¦¬æå°èªææ¬çå½ç«åµæ¸¬æºç¢ºåº¦ãæ­¤æ¹æ³ééæ©å¨å­¸ç¿æ¨¡åçå æ¬æç¥¨æ´åï¼æææ·åææ¬ç¹å¾µççµ±è¨ãèªæåå¥æ³é¢åã

##### **Automating the Detection of Code Vulnerabilities by Analyzing GitHub Issues**
2501.05258v1 by Daniele Cipollone, Changjie Wang, Mariano Scazzariello, Simone Ferlin, Maliheh Izadi, Dejan Kostic, Marco Chiesa

In today's digital landscape, the importance of timely and accurate
vulnerability detection has significantly increased. This paper presents a
novel approach that leverages transformer-based models and machine learning
techniques to automate the identification of software vulnerabilities by
analyzing GitHub issues. We introduce a new dataset specifically designed for
classifying GitHub issues relevant to vulnerability detection. We then examine
various classification techniques to determine their effectiveness. The results
demonstrate the potential of this approach for real-world application in early
vulnerability detection, which could substantially reduce the window of
exploitation for software vulnerabilities. This research makes a key
contribution to the field by providing a scalable and computationally efficient
framework for automated detection, enabling the prevention of compromised
software usage before official notifications. This work has the potential to
enhance the security of open-source software ecosystems.

æè¦ï¼å¨ç¶ä»çæ¸ä½ç°å¢ä¸­ï¼åæä¸æºç¢ºçæ¼æ´åµæ¸¬è®å¾æ ¼å¤éè¦ãæ¬ææåºäºä¸ç¨®åµæ°çæ¹æ³ï¼å©ç¨åºæ¼ Transformer çæ¨¡ååæ©å¨å­¸ç¿æè¡ï¼ééåæ GitHub ä¸­çåé¡ï¼èªååè»é«æ¼æ´çè¾¨è­ãæåå¼é²äºä¸åå°éè¨­è¨çæ°è³æéï¼ç¨æ¼åé¡èæ¼æ´åµæ¸¬ç¸éç GitHub åé¡ãæ¥èæåæ¢è¨åç¨®åé¡æè¡ï¼ä»¥ç¢ºå®å¶æææ§ãçµæé¡¯ç¤ºï¼éç¨®æ¹æ³å¨å¯¦éæç¨æ¼æ©ææ¼æ´åµæ¸¬ä¸å·ææ½åï¼éå¯ä»¥å¤§å¹ç¸®ç­è»é«æ¼æ´çå©ç¨æéãæ¬ç ç©¶ééæä¾å¯æ´åä¸è¨ç®æçé«çèªåååµæ¸¬æ¶æ§ï¼å°éåé åååºäºééµè²¢ç»ï¼å¯å¨å®æ¹éç¥ç¼å¸åé é²åå±å®³è»é«çä½¿ç¨ãéé å·¥ä½ææ½åæåéæºè»é«çæç³»çµ±çå®å¨æ§ã

##### **CallNavi: A Study and Challenge on Function Calling Routing and Invocation in Large Language Models**
2501.05255v1 by Yewei Song, Cedric Lothritz, Xunzhu Tang, Saad Ezzini, Jacques Klein, TegawendÃ© F. BissyandÃ©, Andrey Boytsov, Ulrick Ble, Anne Goujon

Interacting with a software system via a chatbot can be challenging,
especially when the chatbot needs to generate API calls, in the right order and
with the right parameters, to communicate with the system. API calling in
chatbot systems poses significant challenges, particularly in complex,
multi-step tasks requiring accurate API selection and execution. We contribute
to this domain in three ways: first, by introducing a novel dataset designed to
assess models on API function selection, parameter generation, and nested API
calls; second, by benchmarking state-of-the-art language models across varying
levels of complexity to evaluate their performance in API function generation
and parameter accuracy; and third, by proposing an enhanced API routing method
that combines general-purpose large language models for API selection with
fine-tuned models for parameter generation and some prompt engineering
approach. These approaches lead to substantial improvements in handling complex
API tasks, offering practical advancements for real-world API-driven chatbot
systems.

æè¦ï¼ééèå¤©æ©å¨äººèè»é«ç³»çµ±äºåå¯è½å·æææ°æ§ï¼
ç¹å¥æ¯ç¶èå¤©æ©å¨äººéè¦ç¢ç API å¼å«ï¼ä¸¦ä»¥æ­£ç¢ºçé åºå
æ­£ç¢ºçåæ¸èç³»çµ±æºéæãèå¤©æ©å¨äººç³»çµ±ä¸­ç API å¼å«æé æéå¤§çææ°ï¼ç¹å¥æ¯å¨éè¦æºç¢ºç API é¸æåå·è¡çè¤éãå¤æ­¥é©ä»»åä¸­ãæåä»¥ä¸ç¨®æ¹å¼å°éåé åååºè²¢ç»ï¼é¦åï¼ééå¼å¥ä¸åæ°ç©çè³æéï¼æ¨å¨è©ä¼°æ¨¡åç API å½å¼é¸æãåæ¸ç¢çåå·¢ç API å¼å«ï¼å¶æ¬¡ï¼ééæ¯è¼æåé²çèªè¨æ¨¡åå¨ä¸åè¤éç¨åº¦ä¸çåºæºï¼ä»¥è©ä¼°å®åå¨ API å½å¼ç¢çååæ¸æºç¢ºåº¦æ¹é¢çæè½ï¼ç¬¬ä¸ï¼ééæåºä¸åå¢å¼·ç API è·¯ç±æ¹æ³ï¼è©²æ¹æ³çµåäºéç¨å¤§åèªè¨æ¨¡åï¼ç¨æ¼ API é¸æï¼ä»¥åå¾®èª¿æ¨¡åï¼ç¨æ¼åæ¸ç¢çåä¸äºæç¤ºå·¥ç¨æ¹æ³ãéäºæ¹æ³å¤§å¹æ¹åäºèçè¤é API ä»»åçæ¹å¼ï¼çºå¯¦éä¸çç API é©åèå¤©æ©å¨äººç³»çµ±æä¾äºå¯¦ç¨çé²å±ã

##### **From Scientific Texts to Verifiable Code: Automating the Process with Transformers**
2501.05252v1 by Changjie Wang, Mariano Scazzariello, Marco Chiesa

Despite the vast body of research literature proposing algorithms with formal
guarantees, the amount of verifiable code in today's systems remains minimal.
This discrepancy stems from the inherent difficulty of verifying code,
particularly due to the time-consuming nature and strict formalism of proof
details that formal verification tools require. However, the emergence of
transformers in Large Language Models presents a promising solution to this
challenge. In this position paper, we believe that transformers have the
potential to read research papers that propose algorithms with formal proofs
and translate these proofs into verifiable code. We leverage transformers to
first build a formal structure of the proof using the original text from the
paper, and then to handle the tedious, low-level aspects of proofs that are
often omitted by humans. We argue that this approach can significantly reduce
the barrier to formal verification. The above idea of reading papers to write
verifiable code opens new avenues for automating the verification of complex
systems, enabling a future where formally verified algorithms from academic
research can more seamlessly transition into real-world software systems,
thereby improving code reliability and security.

æè¦ï¼åç®¡æå¤§éç ç©¶æç»æåºå·ææ­£å¼ä¿è­çæ¼ç®æ³ï¼ä½ç¶ä»ç³»çµ±ä¸­å¯é©è­çç¨å¼ç¢¼éä»ç¶å¾å°ã
éç¨®å·®ç°æºæ¼é©è­ç¨å¼ç¢¼çåºæå°é£ï¼ç¹å¥æ¯å çºæ­£å¼é©è­å·¥å·éè¦èæçæ¬è³ªåå´æ ¼çå½¢å¼åè­æç´°ç¯ã
ç¶èï¼å¤§åèªè¨æ¨¡åä¸­çTransformeråºç¾çºæ­¤ææ°æä¾äºä¸åæå¸æçè§£æ±ºæ¹æ¡ã
å¨æ¬æä¸­ï¼æåç¸ä¿¡Transformeræè½åé±è®æåºå·ææ­£å¼è­ææ¼ç®æ³çç ç©¶è«æï¼ä¸¦å°éäºè­æè½æçºå¯é©è­çç¨å¼ç¢¼ã
æåå©ç¨Transformeré¦åä½¿ç¨è«æä¸­çåå§æå­å»ºç«è­æçæ­£å¼çµæ§ï¼ç¶å¾èçäººé¡ç¶å¸¸éºæ¼çè­æä¸­ç¹ç£çä½éå±¤é¢ã
æåèªçºéç¨®æ¹æ³å¯ä»¥é¡¯èéä½æ­£å¼é©è­çéç¤ã
ééé±è®è«æä¾æ°å¯«å¯é©è­ç¨å¼ç¢¼ä¸è¿°æ³æ³çºèªååé©è­è¤éç³»çµ±éåäºæ°éå¾ï¼å¯¦ç¾äºä¸åæªä¾ï¼å¶ä¸­ä¾èªå­¸è¡ç ç©¶çæ­£å¼é©è­æ¼ç®æ³å¯ä»¥æ´ç¡ç¸«å°è½æçºçå¯¦ä¸ççè»é«ç³»çµ±ï¼å¾èæé«ç¨å¼ç¢¼å¯é æ§åå®å¨æ§ã

##### **RAG-WM: An Efficient Black-Box Watermarking Approach for Retrieval-Augmented Generation of Large Language Models**
2501.05249v1 by Peizhuo Lv, Mengjie Sun, Hao Wang, Xiaofeng Wang, Shengzhi Zhang, Yuxuan Chen, Kai Chen, Limin Sun

In recent years, tremendous success has been witnessed in Retrieval-Augmented
Generation (RAG), widely used to enhance Large Language Models (LLMs) in
domain-specific, knowledge-intensive, and privacy-sensitive tasks. However,
attackers may steal those valuable RAGs and deploy or commercialize them,
making it essential to detect Intellectual Property (IP) infringement. Most
existing ownership protection solutions, such as watermarks, are designed for
relational databases and texts. They cannot be directly applied to RAGs because
relational database watermarks require white-box access to detect IP
infringement, which is unrealistic for the knowledge base in RAGs. Meanwhile,
post-processing by the adversary's deployed LLMs typically destructs text
watermark information. To address those problems, we propose a novel black-box
"knowledge watermark" approach, named RAG-WM, to detect IP infringement of
RAGs. RAG-WM uses a multi-LLM interaction framework, comprising a Watermark
Generator, Shadow LLM & RAG, and Watermark Discriminator, to create watermark
texts based on watermark entity-relationship tuples and inject them into the
target RAG. We evaluate RAG-WM across three domain-specific and two
privacy-sensitive tasks on four benchmark LLMs. Experimental results show that
RAG-WM effectively detects the stolen RAGs in various deployed LLMs.
Furthermore, RAG-WM is robust against paraphrasing, unrelated content removal,
knowledge insertion, and knowledge expansion attacks. Lastly, RAG-WM can also
evade watermark detection approaches, highlighting its promising application in
detecting IP infringement of RAG systems.

æè¦ï¼è¿å¹´ä¾ï¼æª¢ç´¢å¢å¼·çæï¼RAGï¼ç²å¾äºå·¨å¤§çæåï¼å»£æ³ç¨æ¼å¢å¼·ç¹å®é åãç¥è­å¯éååé±ç§ææåä»»åä¸­çå¤§åèªè¨æ¨¡åï¼LLMï¼ãç¶èï¼æ»æèå¯è½æç«åéäºæå¹å¼ç RAGï¼ä¸¦é¨ç½²æåæ¥­åå®åï¼å æ­¤å¿é æª¢æ¸¬ç¥è­ç¢æ¬ï¼IPï¼ä¾µæ¬è¡çºãç¾æçæææ¬ä¿è­·è§£æ±ºæ¹æ¡ï¼ä¾å¦æµ®æ°´å°ï¼å¤§å¤æ¯çºéä¿è³æåº«åæå­èè¨­è¨çãå®åç¡æ³ç´æ¥æç¨æ¼ RAGï¼å çºéä¿è³æåº«æµ®æ°´å°éè¦ç½çå­åæ¬æè½æª¢æ¸¬ IP ä¾µæ¬è¡çºï¼éå°æ¼ RAG ä¸­çç¥è­åº«ä¾èªªæ¯ä¸åå¯¦éçãåæï¼å°æé¨ç½²ç LLM å¾èçéå¸¸æç ´å£æå­æµ®æ°´å°è³è¨ãçºäºè§£æ±ºéäºåé¡ï¼æåæåºäºä¸ç¨®åçº RAG-WM çæ°ç©é»çãç¥è­æµ®æ°´å°ãæ¹æ³ï¼ä»¥æª¢æ¸¬ RAG ç IP ä¾µæ¬è¡çºãRAG-WM ä½¿ç¨å¤ LLM äº¤äºæ¡æ¶ï¼åæ¬æµ®æ°´å°ç¢çå¨ãå½±å­ LLM å RAGï¼ä»¥åæµ®æ°´å°éå¥å¨ï¼ä»¥æ ¹ææµ®æ°´å°å¯¦é«éä¿åçµå»ºç«æµ®æ°´å°æå­ï¼ä¸¦å°å®åæ³¨å¥ç®æ¨ RAGãæåå¨åååºæº LLM ä¸éå°ä¸åç¹å®é ååå©åé±ç§ææåä»»åè©ä¼° RAG-WMãå¯¦é©çµæè¡¨æï¼RAG-WM å¯ä»¥ææå°æª¢æ¸¬å°åç¨®å·²é¨ç½² LLM ä¸­è¢«ç«åç RAGãæ­¤å¤ï¼RAG-WM å°æ¼æ¹å¯«ãä¸ç¸éå§å®¹ç§»é¤ãç¥è­æå¥åç¥è­æ´åæ»æå·æé­¯æ£æ§ãæå¾ï¼RAG-WM ä¹å¯ä»¥è¦é¿æµ®æ°´å°æª¢æ¸¬æ¹æ³ï¼å¸é¡¯å¶å¨æª¢æ¸¬ RAG ç³»çµ±ç IP ä¾µæ¬è¡çºä¸­çæç¨åæ¯ã

##### **Deriving Coding-Specific Sub-Models from LLMs using Resource-Efficient Pruning**
2501.05248v1 by Laura Puccioni, Alireza Farshin, Mariano Scazzariello, Changjie Wang, Marco Chiesa, Dejan Kostic

Large Language Models (LLMs) have demonstrated their exceptional performance
in various complex code generation tasks. However, their broader adoption is
limited by significant computational demands and high resource requirements,
particularly memory and processing power. To mitigate such requirements, model
pruning techniques are used to create more compact models with significantly
fewer parameters. However, current approaches do not focus on the efficient
extraction of programming-language-specific sub-models. In this work, we
explore the idea of efficiently deriving coding-specific sub-models through
unstructured pruning (i.e., Wanda). We investigate the impact of different
domain-specific calibration datasets on pruning outcomes across three distinct
domains and extend our analysis to extracting four language-specific
sub-models: Python, Java, C++, and JavaScript. We are the first to efficiently
extract programming-language-specific sub-models using appropriate calibration
datasets while maintaining acceptable accuracy w.r.t. full models. We are also
the first to provide analytical evidence that domain-specific tasks activate
distinct regions within LLMs, supporting the creation of specialized sub-models
through unstructured pruning. We believe that this work has significant
potential to enhance LLM accessibility for coding by reducing computational
requirements to enable local execution on consumer-grade hardware, and
supporting faster inference times critical for real-time development feedback.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å·²å±ç¾åºå¶å¨åç¨®è¤éç¨å¼ç¢¼ç¢çä»»åä¸­çåè¶æè½ãç¶èï¼å¶æ´å»£æ³çæ¡ç¨åå°é¡¯èçéç®éæ±åé«è³æºéæ±çéå¶ï¼ç¹å¥æ¯è¨æ¶é«åèçè½åãçºäºæ¸è¼æ­¤é¡éæ±ï¼æ¨¡ååªææè¡ç¨æ¼å»ºç«æ´ç²¾ç°¡çæ¨¡åï¼å¶åæ¸é¡¯èæ¸å°ãç¶èï¼ç®åçåæ³ä¸¦æªå°æ³¨æ¼ç¨å¼èªè¨ç¹å®å­æ¨¡åçæææåãå¨éé å·¥ä½ä¸­ï¼æåæ¢è¨äºéééçµæ§ååªæï¼å³ Wandaï¼ææè¡çç¹å®æ¼ç·¨ç¢¼çå­æ¨¡åçæ³æ³ãæåç ç©¶äºä¸åç¹å®æ¼é åçæ ¡æ­£è³æéå°ä¸åä¸åé åçåªæçµæçå½±é¿ï¼ä¸¦å°æåçåæå»¶ä¼¸è³æåååç¹å®æ¼èªè¨çå­æ¨¡åï¼PythonãJavaãC++ å JavaScriptãæåæ¯ç¬¬ä¸åä½¿ç¨é©ç¶çæ ¡æ­£è³æéæææåç¹å®æ¼ç¨å¼èªè¨çå­æ¨¡åï¼åæç¶­æå¯æ¥åçæºç¢ºåº¦ï¼ç¸å°æ¼å®æ´çæ¨¡åãæåä¹æ¯ç¬¬ä¸åæä¾åæè­æï¼è­æç¹å®æ¼é åçä»»åæå¨ LLM å§ååä¸åçååï¼æ¯æ´éééçµæ§ååªæå»ºç«å°éçå­æ¨¡åãæåç¸ä¿¡ï¼éé å·¥ä½å·æé¡¯èçæ½åï¼å¯éééä½éç®éæ±ä»¥å¨æ¶è²»ç´ç¡¬é«ä¸é²è¡æ¬å°å·è¡ï¼å¾èå¢å¼· LLM å¨ç·¨ç¢¼æ¹é¢çå¯åæ§ï¼ä¸¦æ¯æ´å°æ¼å³æéç¼åé¥è³ééè¦çæ´å¿«éçæ¨è«æéã

##### **Online Prompt and Solver Selection for Program Synthesis**
2501.05247v1 by Yixuan Li, Lewis Frampton, Federico Mora, Elizabeth Polgreen

Large Language Models (LLMs) demonstrate impressive capabilities in the
domain of program synthesis. This level of performance is not, however,
universal across all tasks, all LLMs and all prompting styles. There are many
areas where one LLM dominates, one prompting style dominates, or where calling
a symbolic solver is a better choice than an LLM. A key challenge for the user
then, is to identify not only when an LLM is the right choice of solver, and
the appropriate LLM to call for a given synthesis task, but also the right way
to call it. A non-expert user who makes the wrong choice, incurs a cost both in
terms of results (number of tasks solved, and the time it takes to solve them)
and financial cost, if using a closed-source language model via a commercial
API. We frame this choice as an online learning problem. We use a multi-armed
bandit algorithm to select which symbolic solver, or LLM and prompt combination
to deploy in order to maximize a given reward function (which may prioritize
solving time, number of synthesis tasks solved, or financial cost of solving).
We implement an instance of this approach, called CYANEA, and evaluate it on
synthesis queries from the literature in ranking function synthesis, from the
syntax-guided synthesis competition, and fresh, unseen queries generated from
SMT problems. CYANEA solves 37.2\% more queries than the best single solver and
achieves results within 4\% of the virtual best solver.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å¨ç¨å¼åæé åå±ç¾ä»¤äººå°è±¡æ·±å»çè½åãç¶èï¼éç¨®æè½ä¸¦éå¨ææä»»åãææ LLM åæææç¤ºé¢¨æ ¼ä¸­é½æ¯æ®éé©ç¨çãå¨è¨±å¤é åä¸­ï¼ä¸å LLM ä½ä¸»å°å°ä½ï¼ä¸ç¨®æç¤ºé¢¨æ ¼ä½ä¸»å°å°ä½ï¼æèå¼å«ç¬¦èæ±è§£å¨æ¯ LLM æ¯ä¸åæ´å¥½çé¸æãå æ­¤ï¼ä½¿ç¨èçééµææ°å¨æ¼ä¸åè¦è­å¥ä½æ LLM æ¯æ±è§£å¨çæ­£ç¢ºé¸æï¼ä»¥åå¨çµ¦å®çåæä»»åä¸­å¼å«é©ç¶ç LLMï¼éè¦è­å¥å¼å«å®çæ­£ç¢ºæ¹å¼ãååºé¯èª¤é¸æçéå°å®¶ä½¿ç¨èæå¨çµæï¼å·²è§£æ±ºä»»åçæ¸éåè§£æ±ºä»»åæéçæéï¼åè²¡åææ¬æ¹é¢æ¿æææ¬ï¼å¦æééåæ¥­ API ä½¿ç¨éæºèªè¨æ¨¡åçè©±ãæåå°æ­¤é¸æè¨­å®çºç·ä¸å­¸ç¿åé¡ãæåä½¿ç¨å¤èèèæ©æ¼ç®æ³ä¾é¸æè¦é¨ç½²åªåç¬¦èæ±è§£å¨ï¼æ LLM åæç¤ºçµåï¼ä»¥æå¤§åçµ¦å®çåå ±å½æ¸ï¼å¯è½æåªåèæ®è§£æ±ºæéãå·²è§£æ±ºçåæä»»åæ¸éæè§£æ±ºçè²¡åææ¬ï¼ãæåå¯¦ä½äºéç¨®æ¹æ³çä¸åå¯¦ä¾ï¼ç¨±çº CYANEAï¼ä¸¦å¨ä¾èªæåå½æ¸åæãèªæ³å¼å°åæç«¶è³½çæç»ä¸­çåææ¥è©¢ï¼ä»¥åå¾ SMT åé¡ä¸­ç¢ççææ°ãæªè¦éçæ¥è©¢ä¸å°å¶é²è¡è©ä¼°ãCYANEA è§£æ±ºçæ¥è©¢æ¯æä½³å®ä¸æ±è§£å¨å¤ 37.2%ï¼ä¸¦ä¸å¨èæ¬æä½³æ±è§£å¨ç 4% ç¯åå§åå¾çµæã

##### **Optimizing Estonian TV Subtitles with Semi-supervised Learning and LLMs**
2501.05234v1 by Artem Fedorchenko, Tanel AlumÃ¤e

This paper presents an approach for generating high-quality, same-language
subtitles for Estonian TV content. We fine-tune the Whisper model on
human-generated Estonian subtitles and enhance it with iterative
pseudo-labeling and large language model (LLM) based post-editing. Our
experiments demonstrate notable subtitle quality improvement through
pseudo-labeling with an unlabeled dataset. We find that applying LLM-based
editing at test time enhances subtitle accuracy, while its use during training
does not yield further gains. This approach holds promise for creating subtitle
quality close to human standard and could be extended to real-time
applications.

æè¦ï¼æ¬ææåºäºä¸ç¨®çºææ²å°¼äºé»è¦å§å®¹çæé«åè³ªåèªè¨å­å¹çæ¹æ³ãæåå°äººé¡çæçææ²å°¼äºèªå­å¹å¾®èª¿ Whisper æ¨¡åï¼ä¸¦ééåè¦å½æ¨ç±¤ååºæ¼å¤§èªè¨æ¨¡å (LLM) çå¾ç·¨è¼¯å°å¶é²è¡å¢å¼·ãæåçå¯¦é©ééä½¿ç¨æªæ¨è¨æ¸æéé²è¡å½æ¨ç±¤è­æäºå­å¹è³ªéçé¡¯èæé«ãæåç¼ç¾ï¼å¨æ¸¬è©¦ææç¨åºæ¼ LLM çç·¨è¼¯å¯ä»¥æé«å­å¹æºç¢ºæ§ï¼èå¶å¨è¨ç·´æéçä½¿ç¨ä¸¦ä¸æå¸¶ä¾é²ä¸æ­¥çæ¶çãéç¨®æ¹æ³ææåµé æ¥è¿äººé¡æ¨æºçå­å¹è³ªéï¼ä¸¦å¯ä»¥æ´å±å°å¯¦ææç¨ä¸­ã

##### **Leveraging Large Language Models for Zero-shot Lay Summarisation in Biomedicine and Beyond**
2501.05224v1 by Tomas Goldsack, Carolina Scarton, Chenghua Lin

In this work, we explore the application of Large Language Models to
zero-shot Lay Summarisation. We propose a novel two-stage framework for Lay
Summarisation based on real-life processes, and find that summaries generated
with this method are increasingly preferred by human judges for larger models.
To help establish best practices for employing LLMs in zero-shot settings, we
also assess the ability of LLMs as judges, finding that they are able to
replicate the preferences of human judges. Finally, we take the initial steps
towards Lay Summarisation for Natural Language Processing (NLP) articles,
finding that LLMs are able to generalise to this new domain, and further
highlighting the greater utility of summaries generated by our proposed
approach via an in-depth human evaluation.

æè¦ï¼å¨éé å·¥ä½ä¸­ï¼æåæ¢è¨å¤§åèªè¨æ¨¡åå¨é¶æ¬¡æè¦ä¸­çæç¨ãæåæåºäºä¸ååºæ¼ç¾å¯¦æµç¨çæ°ç©å©éæ®µæ¡æ¶ï¼ç¨æ¼éå°æ¥­æè¦ï¼ä¸¦ç¼ç¾ä½¿ç¨æ­¤æ¹æ³ç¢ççæè¦è¶ä¾è¶åå°äººé¡è©å¯©å¡çéçï¼é©ç¨æ¼è¼å¤§çæ¨¡åãçºäºå¹«å©å»ºç«å¨é¶æ¬¡è¨­å®ä¸­ä½¿ç¨ LLM çæä½³å¯¦åï¼æåä¹è©ä¼°äº LLM ä½çºè©å¯©å¡çè½åï¼ç¼ç¾å®åè½å¤ è¤è£½äººé¡è©å¯©å¡çåå¥½ãæå¾ï¼æåæ¡åäºéå°æ¥­æè¦çæåæ­¥é©ï¼ç¨æ¼èªç¶èªè¨èç (NLP) æç« ï¼ç¼ç¾ LLM è½å¤ æ¦æ¬å°éåæ°é åï¼ä¸¦é²ä¸æ­¥å¼·èª¿äºæåæåºçæ¹æ³ç¢ççæè¦çæ´å¤§æç¨ï¼ééæ·±å¥çäººé¡è©ä¼°ã

##### **ParaRev: Building a dataset for Scientific Paragraph Revision annotated with revision instruction**
2501.05222v1 by LÃ©ane Jourdan, Nicolas Hernandez, Richard Dufour, Florian Boudin, Akiko Aizawa

Revision is a crucial step in scientific writing, where authors refine their
work to improve clarity, structure, and academic quality. Existing approaches
to automated writing assistance often focus on sentence-level revisions, which
fail to capture the broader context needed for effective modification. In this
paper, we explore the impact of shifting from sentence-level to paragraph-level
scope for the task of scientific text revision. The paragraph level definition
of the task allows for more meaningful changes, and is guided by detailed
revision instructions rather than general ones. To support this task, we
introduce ParaRev, the first dataset of revised scientific paragraphs with an
evaluation subset manually annotated with revision instructions. Our
experiments demonstrate that using detailed instructions significantly improves
the quality of automated revisions compared to general approaches, no matter
the model or the metric considered.

æè¦ï¼ä¿®æ¹æ¯ç§å­¦å¯«ä½ä¸­è³ééè¦çä¸æ­¥ï¼ä½èå¨å¶ä¸­å®åå¶ä½åï¼ä»¥æé«æ¸æ°åº¦ãçµæ§åå­¸è¡åè³ªãç¾æçèªåå¯«ä½è¼å©æ¹æ³éå¸¸å´éæ¼å¥å­å±¤ç´çä¿®æ¹ï¼éç¡æ³ææ¡ææä¿®æ¹æéçæ´å»£æ³èçµ¡ãå¨æ¬æä¸­ï¼æåæ¢è¨äºå¾å¥å­å±¤ç´è½ç§»å°æ®µè½å±¤ç´ç¯åå°ç§å­¸ææ¬ä¿®æ¹ä»»åçå½±é¿ãä»»åçæ®µè½å±¤ç´å®ç¾©åè¨±é²è¡æ´ææç¾©çä¿®æ¹ï¼ä¸¦ä»¥è©³ç´°çä¿®æ¹èªªæçºæå°ï¼èä¸æ¯ä¸è¬çèªªæãçºäºæ¯ææ­¤ä»»åï¼æåå¼å¥äº ParaRevï¼éæ¯ç¬¬ä¸åç¶éäººå·¥æ¨è¨ä¿®æ¹èªªæçè©ä¼°å­éçå·²ä¿®æ¹ç§å­¸æ®µè½è³æéãæåçå¯¦é©è¡¨æï¼èä¸è¬æ¹æ³ç¸æ¯ï¼ä½¿ç¨è©³ç´°èªªæé¡¯èæé«äºèªåä¿®æ¹çåè³ªï¼ç¡è«èæ®åªç¨®æ¨¡åæææ¨ã

##### **A Novel Approach to Scalable and Automatic Topic-Controlled Question Generation in Education**
2501.05220v1 by Ziqing Li, Mutlu Cukurova, Sahan Bulathwela

The development of Automatic Question Generation (QG) models has the
potential to significantly improve educational practices by reducing the
teacher workload associated with creating educational content. This paper
introduces a novel approach to educational question generation that controls
the topical focus of questions. The proposed Topic-Controlled Question
Generation (T-CQG) method enhances the relevance and effectiveness of the
generated content for educational purposes. Our approach uses fine-tuning on a
pre-trained T5-small model, employing specially created datasets tailored to
educational needs. The research further explores the impacts of pre-training
strategies, quantisation, and data augmentation on the model's performance. We
specifically address the challenge of generating semantically aligned questions
with paragraph-level contexts, thereby improving the topic specificity of the
generated questions. In addition, we introduce and explore novel evaluation
methods to assess the topical relatedness of the generated questions. Our
results, validated through rigorous offline and human-backed evaluations,
demonstrate that the proposed models effectively generate high-quality,
topic-focused questions. These models have the potential to reduce teacher
workload and support personalised tutoring systems by serving as bespoke
question generators. With its relatively small number of parameters, the
proposals not only advance the capabilities of question generation models for
handling specific educational topics but also offer a scalable solution that
reduces infrastructure costs. This scalability makes them feasible for
widespread use in education without reliance on proprietary large language
models like ChatGPT.

æè¦ï¼èªååé¡çæ (QG) æ¨¡åçç¼å±å·æé¡¯èæ¹åæè²å¯¦åçæ½åï¼æ¹æ³æ¯æ¸å°æå¸«å¨å»ºç«æè²å§å®¹æçå·¥ä½è² æãæ¬æä»ç´¹ä¸ç¨®åµæ°çæè²åé¡çææ¹æ³ï¼ç¨ä»¥æ§å¶åé¡çä¸»é¡ç¦é»ãæåºçä¸»é¡æ§å¶åé¡çæ (T-CQG) æ¹æ³å¢å¼·äºçæå§å®¹å¨æè²ç®çä¸çç¸éæ§åæææ§ãæåçæ¹æ³ä½¿ç¨ç¶éå¾®èª¿çé è¨ç·´ T5-small æ¨¡åï¼æ¡ç¨å°ééå°æè²éæ±éèº«æé çè³æéãç ç©¶é²ä¸æ­¥æ¢è¨äºé è¨ç·´ç­ç¥ãéå­ååè³ææ´åå°æ¨¡åæè½çå½±é¿ãæåç¹å¥è§£æ±ºäºçæèæ®µè½å±¤ç´èçµ¡èªæå°é½çåé¡ï¼å¾èæ¹åçæåé¡çä¸»é¡ç¹å®æ§ãæ­¤å¤ï¼æåä»ç´¹ä¸¦æ¢è¨äºæ°çè©ä¼°æ¹æ³ï¼ä»¥è©ä¼°çæåé¡çä¸»é¡ç¸éæ§ãæåççµæç¶éå´æ ¼çé¢ç·åäººå·¥è©ä¼°é©è­ï¼è­ææåºçæ¨¡åææå°ç¢çäºé«åè³ªãä¸»é¡ç¦é»çåé¡ãéäºæ¨¡åå·ææ¸å°æå¸«å·¥ä½è² æåæ¯æ´åäººåæå­¸ç³»çµ±çæ½åï¼æ¹æ³æ¯ä½çºå®¢è£½ååé¡çæå¨ãç±æ¼åæ¸æ¸éç¸å°è¼å°ï¼éäºææ¡ä¸åæåäºåé¡çææ¨¡åå¨èçç¹å®æè²ä¸»é¡æ¹é¢çè½åï¼éæä¾äºä¸åå¯æ´åçè§£æ±ºæ¹æ¡ï¼ä»¥éä½åºç¤è¨­æ½ææ¬ãéç¨®å¯æ´åæ§ä½¿å®åå¨æè²ä¸­å»£æ³ä½¿ç¨æçºå¯è¡ï¼èç¡éä¾è³´å ChatGPT éæ¨£çå°æå¤§åèªè¨æ¨¡åã

##### **GLaM-Sign: Greek Language Multimodal Lip Reading with Integrated Sign Language Accessibility**
2501.05213v1 by Dimitris Kouremenos, Klimis Ntalianis

The Greek Language Multimodal Lip Reading with Integrated Sign Language
Accessibility (GLaM-Sign) [1] is a groundbreaking resource in accessibility and
multimodal AI, designed to support Deaf and Hard-of-Hearing (DHH) individuals.
Developed from the FEELIT project [2], it integrates high-resolution audio,
video, textual transcriptions, and Greek Sign Language translations for
applications like real-time sign language translation and enhanced subtitle
synchronization. While its primary focus is on promoting inclusivity in the
Greek tourism sector, its adaptability extends to education, healthcare, and
public services. Future advancements will enhance word-level precision and
scalability to additional languages, supported by advanced AI methodologies and
collaborations with diverse stakeholders. This dataset underscores the
transformative potential of multimodal resources in bridging communication
gaps, fostering innovation, and setting a benchmark for ethical AI and
inclusive technologies.

æè¦ï¼å¸èèªå¤æ¨¡æåè®èæèªæ´åç¡éç¤ï¼GLaM-Signï¼[1] æ¯ç¡éç¤åå¤æ¨¡æäººå·¥æºæ§ççªç ´æ§è³æºï¼æ¨å¨æ¯æ´è¾äººåè½åéç¤ï¼DHHï¼äººå£«ãå®ç± FEELIT å°æ¡ [2] éç¼ï¼æ´åäºé«è§£æåº¦é³è¨ãå½±çãæå­è½éåå¸èæèªç¿»è­¯ï¼å¯ç¨æ¼å³ææèªç¿»è­¯åå¢å¼·å­å¹åæ­¥ç­æç¨ç¨å¼ãéç¶å¶ä¸»è¦éé»æ¯ä¿é²å¸èæéæ¥­çåå®¹æ§ï¼ä½å®çé©ç¨æ§ä¹å»¶ä¼¸å°æè²ãé«çä¿å¥åå¬å±æåãæªä¾çé²å±å°ééåé²çäººå·¥æºæ§æ¹æ³åèä¸åå©å®³éä¿äººçåä½ï¼æåå­åç´ç²¾æºåº¦åæ´åå°å¶ä»èªè¨ãæ­¤è³æéçªé¡¯äºå¤æ¨¡æè³æºå¨å½åæºéé´»æºãä¿é²åµæ°ä»¥åçºéå¾·äººå·¥æºæ§ååå®¹æ§æè¡è¨­å®åºæºæ¹é¢çè®é©æ½åã

##### **Discovering Hidden Visual Concepts Beyond Linguistic Input in Infant Learning**
2501.05205v1 by Xueyi Ke, Satoshi Tsutsui, Yayun Zhang, Bihan Wen

Infants develop complex visual understanding rapidly, even preceding of the
acquisition of linguistic inputs. As computer vision seeks to replicate the
human vision system, understanding infant visual development may offer valuable
insights. In this paper, we present an interdisciplinary study exploring this
question: can a computational model that imitates the infant learning process
develop broader visual concepts that extend beyond the vocabulary it has heard,
similar to how infants naturally learn? To investigate this, we analyze a
recently published model in Science by Vong et al.,which is trained on
longitudinal, egocentric images of a single child paired with transcribed
parental speech. We introduce a training-free framework that can discover
visual concept neurons hidden in the model's internal representations. Our
findings show that these neurons can classify objects outside its original
vocabulary. Furthermore, we compare the visual representations in infant-like
models with those in moder computer vision models, such as CLIP or ImageNet
pre-trained model, highlighting key similarities and differences. Ultimately,
our work bridges cognitive science and computer vision by analyzing the
internal representations of a computational model trained on an infant's visual
and linguistic inputs.

æè¦ï¼å¬°åç¼å±åºè¤éçè¦è¦ºçè§£ï¼çè³æ©æ¼èªè¨è¼¸å¥çç²å¾ãç±æ¼é»è¦è¦è¦ºè©¦åè¤è£½äººé¡è¦è¦ºç³»çµ±ï¼äºè§£å¬°åè¦è¦ºç¼å±å¯è½ææä¾æå¹å¼çè¦è§£ãå¨æ¬æä¸­ï¼æåæåºäºä¸é æ¢ç´¢éååé¡çè·¨å­¸ç§ç ç©¶ï¼ä¸åæ¨¡ä»¿å¬°åå­¸ç¿éç¨çè¨ç®æ¨¡åæ¯å¦è½ç¼å±åºè¶è¶å¶è½å°çè©å½çæ´å»£æ³çè¦è¦ºæ¦å¿µï¼é¡ä¼¼æ¼å¬°åèªç¶å­¸ç¿çæ¹å¼ï¼çºäºèª¿æ¥éä¸é»ï¼æååæäº Vong ç­äººå¨ Science ä¸æè¿ç¼è¡¨çæ¨¡åï¼è©²æ¨¡åè¨ç·´æ¼ä¸åå­©å­çç¸±åèªæä¸­å¿å½±åï¼ä¸¦éæè½éçç¶æ¯èªè¨ãæåå¼å¥äºä¸åç¡éè¨ç·´çæ¡æ¶ï¼å®å¯ä»¥å¨æ¨¡åçå§é¨è¡¨ç¤ºä¸­ç¼ç¾é±èçè¦è¦ºæ¦å¿µç¥ç¶åãæåçç ç©¶çµæè¡¨æï¼éäºç¥ç¶åå¯ä»¥å°å¶åå§è©å½ä¹å¤çç©é«é²è¡åé¡ãæ­¤å¤ï¼æåå°é¡å¬°åæ¨¡åä¸­çè¦è¦ºè¡¨ç¤ºèç¾ä»£é»è¦è¦è¦ºæ¨¡åï¼ä¾å¦ CLIP æ ImageNet é è¨ç·´æ¨¡åï¼ä¸­çè¦è¦ºè¡¨ç¤ºé²è¡æ¯è¼ï¼çªåºäºééµçç¸ä¼¼æ§åå·®ç°ãæçµï¼æåçç ç©¶ééåæå¨å¬°åçè¦è¦ºåèªè¨è¼¸å¥ä¸è¨ç·´çè¨ç®æ¨¡åçå§é¨è¡¨ç¤ºï¼æ¶èµ·äºèªç¥ç§å­¸åé»è¦è¦è¦ºä¹éçæ©æ¨ã

##### **Bringing Order Amidst Chaos: On the Role of Artificial Intelligence in Secure Software Engineering**
2501.05165v1 by Matteo Esposito

Context. Developing secure and reliable software remains a key challenge in
software engineering (SE). The ever-evolving technological landscape offers
both opportunities and threats, creating a dynamic space where chaos and order
compete. Secure software engineering (SSE) must continuously address
vulnerabilities that endanger software systems and carry broader socio-economic
risks, such as compromising critical national infrastructure and causing
significant financial losses. Researchers and practitioners have explored
methodologies like Static Application Security Testing Tools (SASTTs) and
artificial intelligence (AI) approaches, including machine learning (ML) and
large language models (LLMs), to detect and mitigate these vulnerabilities.
Each method has unique strengths and limitations.
  Aim. This thesis seeks to bring order to the chaos in SSE by addressing
domain-specific differences that impact AI accuracy.
  Methodology. The research employs a mix of empirical strategies, such as
evaluating effort-aware metrics, analyzing SASTTs, conducting method-level
analysis, and leveraging evidence-based techniques like systematic dataset
reviews. These approaches help characterize vulnerability prediction datasets.
  Results. Key findings include limitations in static analysis tools for
identifying vulnerabilities, gaps in SASTT coverage of vulnerability types,
weak relationships among vulnerability severity scores, improved defect
prediction accuracy using just-in-time modeling, and threats posed by untouched
methods.
  Conclusions. This thesis highlights the complexity of SSE and the importance
of contextual knowledge in improving AI-driven vulnerability and defect
prediction. The comprehensive analysis advances effective prediction models,
benefiting both researchers and practitioners.

æè¦ï¼<paragraph>èçµ¡ãéç¼å®å¨ä¸å¯é çè»é«ä»ç¶æ¯è»é«å·¥ç¨ (SE) ä¸­çä¸é ééµææ°ãä¸æ·æ¼é²çæè¡é åæ¢å¸¶ä¾æ©æï¼ä¹å¸¶ä¾å¨èï¼åµé äºä¸åæ··äºèç§©åºç«¶ç­çåæç©ºéãå®å¨è»é«å·¥ç¨ (SSE) å¿é æçºè§£æ±ºå±å®³è»é«ç³»çµ±ä¸¦å¸¶ä¾æ´å»£æ³ç¤¾æç¶æ¿é¢¨éªçæ¼æ´ï¼ä¾å¦å±å®³éè¦çåå®¶åºç¤è¨­æ½ä¸¦é æéå¤§è²¡åæå¤±ãç ç©¶äººå¡åå¾æ¥­äººå¡å·²ç¶æ¢ç´¢äºæ¹æ³ï¼ä¾å¦éææç¨ç¨å¼å®å¨æ¸¬è©¦å·¥å· (SASTT) åäººå·¥æºæ§ (AI) æ¹æ³ï¼åæ¬æ©å¨å­¸ç¿ (ML) åå¤§åèªè¨æ¨¡å (LLM)ï¼ä»¥åµæ¸¬åæ¸è¼éäºæ¼æ´ãæ¯ç¨®æ¹æ³é½æç¨ç¹çåªé»åç¼ºé»ã
ç®æ¨ãæ¬è«ææ¨å¨ééè§£æ±ºå½±é¿ AI ç²¾ç¢ºåº¦çç¹å®é åå·®ç°ï¼çº SSE ä¸­çæ··äºå¸¶ä¾ç§©åºã
æ¹æ³ãæ¬ç ç©¶æ¡ç¨åç¨®ç¶é©ç­ç¥ï¼ä¾å¦è©ä¼°èéå·¥ä½éçææ¨ãåæ SASTTãå·è¡æ¹æ³å±¤ç´åæï¼ä»¥åå©ç¨åºæ¼è­æçæè¡ï¼ä¾å¦ç³»çµ±åè³æéåé¡§ãéäºæ¹æ³æå©æ¼æè¿°æ¼æ´é æ¸¬è³æéã
çµæãä¸»è¦ç¼ç¾åæ¬ç¨æ¼è­å¥æ¼æ´çéæåæå·¥å·çéå¶ãSASTT å°æ¼æ´é¡åçæ¶µèç¯åæå·®è·ãæ¼æ´å´éæ§è©åä¹éçéä¿èå¼±ãåå¨å³æå»ºæ¨¡ä¸­æ¹åç¼ºé·é æ¸¬çæºç¢ºåº¦ï¼ä»¥åæªè§¸åçæ¹æ³æå¸¶ä¾çå¨èã
çµè«ãæ¬è«æå¼·èª¿äº SSE çè¤éæ§ä»¥åèæ¯ç¥è­å¨æ¹å AI é©åçæ¼æ´åç¼ºé·é æ¸¬ä¸­çéè¦æ§ãå¨é¢çåææ¨åäºææçé æ¸¬æ¨¡åï¼ä½¿ç ç©¶äººå¡åå¾æ¥­äººå¡åçã</paragraph>

##### **Explainable AI based System for Supply Air Temperature Forecast**
2501.05163v1 by Marika Eik, Ahmet Kose, Hossein Nourollahi Hokmabad, Juri Belikov

This paper explores the application of Explainable AI (XAI) techniques to
improve the transparency and understanding of predictive models in control of
automated supply air temperature (ASAT) of Air Handling Unit (AHU). The study
focuses on forecasting of ASAT using a linear regression with Huber loss.
However, having only a control curve without semantic and/or physical
explanation is often not enough. The present study employs one of the XAI
methods: Shapley values, which allows to reveal the reasoning and highlight the
contribution of each feature to the final ASAT forecast. In comparison to other
XAI methods, Shapley values have solid mathematical background, resulting in
interpretation transparency. The study demonstrates the contrastive
explanations--slices, for each control value of ASAT, which makes it possible
to give the client objective justifications for curve changes.

æè¦ï¼æ¬ææ¢è¨å¯è§£é AI (XAI) æè¡å¨æé«ç©ºæ°£èçå®å (AHU) èªåä¾æç©ºæ°£æº«åº¦ (ASAT) é æ¸¬æ¨¡åçéæåº¦åçè§£åº¦ä¸­çæç¨ãæ¬ç ç©¶çéé»å¨æ¼ä½¿ç¨å¸¶æ Huber æå¤±çç·æ§åæ­¸é æ¸¬ ASATãç¶èï¼åæä¸åæ²æèªç¾©å/æç©çè§£éçæ§å¶æ²ç·éå¸¸æ¯ä¸å¤ çãæ¬ç ç©¶æ¡ç¨ XAI æ¹æ³ä¹ä¸ï¼Shapley å¼ï¼å®å¯ä»¥æ­ç¤ºæ¨çä¸¦å¼·èª¿æ¯åç¹å¾µå°æçµ ASAT é æ¸¬çè²¢ç»ãèå¶ä» XAI æ¹æ³ç¸æ¯ï¼Shapley å¼å·æç´®å¯¦çæ¸å­¸èæ¯ï¼å¾èå¯¦ç¾äºè§£ééæåº¦ãæ¬ç ç©¶å±ç¤ºäºå°æ¯è§£éââåçï¼éå° ASAT çæ¯åæ§å¶å¼ï¼éä½¿å¾å¯ä»¥çºæ²ç·è®åæä¾å®¢æ¶å®¢è§ççç±ã

##### **Biomedical Relation Extraction via Adaptive Document-Relation Cross-Mapping and Concept Unique Identifier**
2501.05155v1 by Yufei Shang, Yanrong Guo, Shijie Hao, Richang Hong

Document-Level Biomedical Relation Extraction (Bio-RE) aims to identify
relations between biomedical entities within extensive texts, serving as a
crucial subfield of biomedical text mining. Existing Bio-RE methods struggle
with cross-sentence inference, which is essential for capturing relations
spanning multiple sentences. Moreover, previous methods often overlook the
incompleteness of documents and lack the integration of external knowledge,
limiting contextual richness. Besides, the scarcity of annotated data further
hampers model training. Recent advancements in large language models (LLMs)
have inspired us to explore all the above issues for document-level Bio-RE.
Specifically, we propose a document-level Bio-RE framework via LLM Adaptive
Document-Relation Cross-Mapping (ADRCM) Fine-Tuning and Concept Unique
Identifier (CUI) Retrieval-Augmented Generation (RAG). First, we introduce the
Iteration-of-REsummary (IoRs) prompt for solving the data scarcity issue. In
this way, Bio-RE task-specific synthetic data can be generated by guiding
ChatGPT to focus on entity relations and iteratively refining synthetic data.
Next, we propose ADRCM fine-tuning, a novel fine-tuning recipe that establishes
mappings across different documents and relations, enhancing the model's
contextual understanding and cross-sentence inference capabilities. Finally,
during the inference, a biomedical-specific RAG approach, named CUI RAG, is
designed to leverage CUIs as indexes for entities, narrowing the retrieval
scope and enriching the relevant document contexts. Experiments conducted on
three Bio-RE datasets (GDA, CDR, and BioRED) demonstrate the state-of-the-art
performance of our proposed method by comparing it with other related works.

æè¦ï¼<paragraph>æä»¶ç´çç©é«å­¸éä¿èå (Bio-RE) æ¨å¨è­å¥å»£æ³ææ¬ä¸­çç©é«å­¸å¯¦é«ä¹éçéä¿ï¼æ¯çç©é«å­¸ææ¬æ¢åçééµå­é åãç¾æç Bio-RE æ¹æ³é£ä»¥é²è¡è·¨å¥æ¨è«ï¼éå°æ¼ææè·¨è¶å¤åå¥å­çéä¿è³ééè¦ãæ­¤å¤ï¼ååçç ç©¶æ¹æ³ç¶å¸¸å¿½ç¥æä»¶çå®æ´æ§ï¼ä¸ç¼ºä¹å¤é¨ç¥è­çæ´åï¼éå¶äºèçµ¡çè±å¯æ§ãæ­¤å¤ï¼æ¨è¨»è³æçç¨å°æ§é²ä¸æ­¥é»ç¤äºæ¨¡åè¨ç·´ãå¤§åèªè¨æ¨¡å (LLM) çææ°é²å±æ¿åµæåæ¢ç´¢æä»¶ç´ Bio-RE çææä¸è¿°åé¡ãå·é«ä¾èªªï¼æåéé LLM é©ææ§æä»¶éä¿äº¤åå°æ (ADRCM) å¾®èª¿åæ¦å¿µå¯ä¸è­å¥ç¢¼ (CUI) æª¢ç´¢å¢å¼·çæ (RAG) æåºä¸åæä»¶ç´ Bio-RE æ¶æ§ãé¦åï¼æåä»ç´¹ RE æè¦åè¦ (IoRs) æç¤ºï¼ä»¥è§£æ±ºè³æç¨å°çåé¡ãéééç¨®æ¹å¼ï¼å¯ä»¥ééå¼å° ChatGPT å°æ³¨æ¼å¯¦é«éä¿ååè¦åªååæè³æä¾ç¢ç Bio-RE ä»»åç¹å®çåæè³æãæ¥ä¸ä¾ï¼æåæåº ADRCM å¾®èª¿ï¼éæ¯ä¸ç¨®æ°ç©çå¾®èª¿éæ¹ï¼å¯å»ºç«ä¸åæä»¶åéä¿ä¹éçå°æï¼å¢å¼·æ¨¡åçèçµ¡çè§£åè·¨å¥æ¨è«è½åãæå¾ï¼å¨æ¨çéç¨ä¸­ï¼è¨­è¨äºä¸ç¨®åçº CUI RAG ççç©é«å­¸ç¹å® RAG æ¹æ³ï¼ä»¥å©ç¨ CUI ä½çºå¯¦é«çç´¢å¼ï¼ç¸®å°æª¢ç´¢ç¯åä¸¦è±å¯ç¸éæä»¶èçµ¡ãå¨ä¸å Bio-RE è³æé (GDAãCDR å BioRED) ä¸é²è¡çå¯¦é©è­æäºæåæåºçæ¹æ³çææ°æè¡ï¼ä¸¦å°å¶èå¶ä»ç¸éå·¥ä½é²è¡æ¯è¼ã</paragraph>

##### **A Systematic Literature Review on Deep Learning-based Depth Estimation in Computer Vision**
2501.05147v1 by Ali Rohan, Md Junayed Hasan, Andrei Petrovski

Depth estimation (DE) provides spatial information about a scene and enables
tasks such as 3D reconstruction, object detection, and scene understanding.
Recently, there has been an increasing interest in using deep learning
(DL)-based methods for DE. Traditional techniques rely on handcrafted features
that often struggle to generalise to diverse scenes and require extensive
manual tuning. However, DL models for DE can automatically extract relevant
features from input data, adapt to various scene conditions, and generalise
well to unseen environments. Numerous DL-based methods have been developed,
making it necessary to survey and synthesize the state-of-the-art (SOTA).
Previous reviews on DE have mainly focused on either monocular or stereo-based
techniques, rather than comprehensively reviewing DE. Furthermore, to the best
of our knowledge, there is no systematic literature review (SLR) that
comprehensively focuses on DE. Therefore, this SLR study is being conducted.
Initially, electronic databases were searched for relevant publications,
resulting in 1284 publications. Using defined exclusion and quality criteria,
128 publications were shortlisted and further filtered to select 59
high-quality primary studies. These studies were analysed to extract data and
answer defined research questions. Based on the results, DL methods were
developed for mainly three different types of DE: monocular, stereo, and
multi-view. 20 publicly available datasets were used to train, test, and
evaluate DL models for DE, with KITTI, NYU Depth V2, and Make 3D being the most
used datasets. 29 evaluation metrics were used to assess the performance of DE.
35 base models were reported in the primary studies, and the top five most-used
base models were ResNet-50, ResNet-18, ResNet-101, U-Net, and VGG-16. Finally,
the lack of ground truth data was among the most significant challenges
reported by primary studies.

æè¦ï¼æ·±åº¦ä¼°è¨ (DE) æä¾å ´æ¯çç©ºéè³è¨ï¼ä¸¦è½å·è¡ 3D éå»ºãç©é«åµæ¸¬åå ´æ¯çè§£ç­ä»»åãæè¿ï¼ä½¿ç¨æ·±åº¦å­¸ç¿ (DL) çæ¹æ³é²è¡ DE éæ¼¸åå°éè¦ãå³çµ±æè¡ä»°è³´æå·¥ç¹å¾µï¼èéäºç¹å¾µéå¸¸é£ä»¥æ¨å»£å°ä¸åçå ´æ¯ï¼ä¸¦ä¸éè¦å»£æ³çæåèª¿æ´ãç¶èï¼DE ç DL æ¨¡åå¯ä»¥èªåå¾è¼¸å¥è³æä¸­èåç¸éç¹å¾µãé©æåç¨®å ´æ¯æ¢ä»¶ï¼ä¸¦è½æ¨å»£å°æªç¥çç°å¢ãå·²ç¶éç¼åºè¨±å¤åºæ¼ DL çæ¹æ³ï¼å æ­¤æå¿è¦èª¿æ¥åç¶åç¾ææè¡ (SOTA)ãååéæ¼ DE çåé¡§ä¸»è¦å°æ³¨æ¼å®ç¼æç«é«æè¡ï¼èä¸æ¯å¨é¢åé¡§ DEãæ­¤å¤ï¼ææåæç¥ï¼æ²æç³»çµ±æ§çæç»åé¡§ (SLR) å¨é¢éæ³¨ DEãå æ­¤ï¼æ­£å¨é²è¡éé  SLR ç ç©¶ãæåï¼å¨é»å­è³æåº«ä¸­æå°ç¸éåºçåï¼å±å¾å° 1284 ç¯åºçåãä½¿ç¨å®ç¾©çæé¤ååè³ªæ¨æºï¼å° 128 ç¯åºçååå¥åé¸åå®ï¼ä¸¦é²ä¸æ­¥ç¯©é¸åº 59 é é«åè³ªçä¸»è¦ç ç©¶ãåæéäºç ç©¶ä»¥èåè³æä¸¦åç­å®ç¾©çç ç©¶åé¡ãæ ¹æçµæï¼DL æ¹æ³ä¸»è¦éå°ä¸ç¨®é¡åç DE é²è¡éç¼ï¼å®ç¼ãç«é«åå¤è¦åã20 åå¬éå¯ç¨çè³æéç¨æ¼è¨ç·´ãæ¸¬è©¦åè©ä¼° DE ç DL æ¨¡åï¼å¶ä¸­ KITTIãNYU Depth V2 å Make 3D æ¯æå¸¸ç¨çè³æéã29 åè©ä¼°ææ¨ç¨æ¼è©ä¼° DE çæè½ã35 ååºç¤æ¨¡åå¨ä¸»è¦ç ç©¶ä¸­è¢«å ±å°ï¼åäºåæå¸¸ä½¿ç¨çåºç¤æ¨¡åæ¯ ResNet-50ãResNet-18ãResNet-101ãU-Net å VGG-16ãæå¾ï¼ä¸»è¦ç ç©¶å ±åçéå¤§ææ°ä¹ä¸æ¯ç¼ºä¹çå¯¦è³æã

##### **Centurio: On Drivers of Multilingual Ability of Large Vision-Language Model**
2501.05122v1 by Gregor Geigle, Florian Schneider, Carolin Holtermann, Chris Biemann, Radu Timofte, Anne Lauscher, Goran GlavaÅ¡

Most Large Vision-Language Models (LVLMs) to date are trained predominantly
on English data, which makes them struggle to understand non-English input and
fail to generate output in the desired target language. Existing efforts
mitigate these issues by adding multilingual training data, but do so in a
largely ad-hoc manner, lacking insight into how different training mixes tip
the scale for different groups of languages. In this work, we present a
comprehensive investigation into the training strategies for massively
multilingual LVLMs. First, we conduct a series of multi-stage experiments
spanning 13 downstream vision-language tasks and 43 languages, systematically
examining: (1) the number of training languages that can be included without
degrading English performance and (2) optimal language distributions of
pre-training as well as (3) instruction-tuning data. Further, we (4)
investigate how to improve multilingual text-in-image understanding, and
introduce a new benchmark for the task. Surprisingly, our analysis reveals that
one can (i) include as many as 100 training languages simultaneously (ii) with
as little as 25-50\% of non-English data, to greatly improve multilingual
performance while retaining strong English performance. We further find that
(iii) including non-English OCR data in pre-training and instruction-tuning is
paramount for improving multilingual text-in-image understanding. Finally, we
put all our findings together and train Centurio, a 100-language LVLM, offering
state-of-the-art performance in an evaluation covering 14 tasks and 56
languages.

æè¦ï¼<paragraph>è¿ä»çºæ­¢ï¼å¤§å¤æ¸å¤§åè¦è¦ºèªè¨æ¨¡å (LVLMs) ä¸»è¦é½æ¯ä»¥è±æè³æé²è¡è¨ç·´ï¼éä½¿å¾å®åé£ä»¥çè§£éè±æè¼¸å¥ï¼ä¹ç¡æ³ç¢çç®æ¨èªè¨çè¼¸åºãç¾æçè§£æ±ºæ¹æ³æ¯ééå å¥å¤èªè¨è¨ç·´è³æä¾æ¸è¼éäºåé¡ï¼ä½éäºæ¹æ³å¤§å¤é½æ¯è¨ææè®ï¼ç¼ºä¹å°æ¼ä¸åè¨ç·´çµåå¦ä½å½±é¿ä¸åèªè¨ç¾¤é«çè¦è§£ãå¨æ¬æä¸­ï¼æåéå°å¤§éå¤èªè¨ LVLMs çè¨ç·´ç­ç¥é²è¡å¨é¢èª¿æ¥ãé¦åï¼æåé²è¡äºä¸ç³»åå¤éæ®µå¯¦é©ï¼æ¶µè 13 åä¸æ¸¸è¦è¦ºèªè¨ä»»åå 43 ç¨®èªè¨ï¼ç³»çµ±æ§å°æ¢è¨ï¼(1) å¨ä¸éä½è±ææè½çææ³ä¸å¯ä»¥ç´å¥çè¨ç·´èªè¨æ¸éï¼ä»¥å (2) é è¨ç·´çæä½³èªè¨åä½ï¼ä»¥å (3) æä»¤èª¿æ´è³æãæ­¤å¤ï¼æå (4) æ¢è¨å¦ä½æ¹åå¤èªè¨æå­å½±åçè§£ï¼ä¸¦çºæ­¤ä»»åå¼å¥ä¸åæ°çåºæºãä»¤äººé©è¨çæ¯ï¼æåçåæé¡¯ç¤ºï¼äººåå¯ä»¥ (i) åæç´å¥å¤é 100 ç¨®è¨ç·´èªè¨ï¼(ii) åªè¦ 25-50% çéè±æè³æï¼å°±è½å¤§å¹æ¹åå¤èªè¨æè½ï¼åæç¶­æå¼·åçè±ææè½ãæåé²ä¸æ­¥ç¼ç¾ï¼(iii) å¨é è¨ç·´åæä»¤èª¿æ´ä¸­ç´å¥éè±æ OCR è³æå°æ¼æ¹åå¤èªè¨æå­å½±åçè§£è³ééè¦ãæå¾ï¼æåå°ææç¼ç¾å½æ´èµ·ä¾ï¼è¨ç·´åº Centurioï¼éæ¯ä¸å 100 èªè¨ç LVLMï¼å¨æ¶µè 14 åä»»åå 56 ç¨®èªè¨çè©ä¼°ä¸­æä¾æåé²çæè½ã</paragraph>

##### **Constrained Optimization of Charged Particle Tracking with Multi-Agent Reinforcement Learning**
2501.05113v1 by Tobias Kortus, Ralf Keidel, Nicolas R. Gauger, Jan Kieseler

Reinforcement learning demonstrated immense success in modelling complex
physics-driven systems, providing end-to-end trainable solutions by interacting
with a simulated or real environment, maximizing a scalar reward signal. In
this work, we propose, building upon previous work, a multi-agent reinforcement
learning approach with assignment constraints for reconstructing particle
tracks in pixelated particle detectors. Our approach optimizes collaboratively
a parametrized policy, functioning as a heuristic to a multidimensional
assignment problem, by jointly minimizing the total amount of particle
scattering over the reconstructed tracks in a readout frame. To satisfy
constraints, guaranteeing a unique assignment of particle hits, we propose a
safety layer solving a linear assignment problem for every joint action.
Further, to enforce cost margins, increasing the distance of the local policies
predictions to the decision boundaries of the optimizer mappings, we recommend
the use of an additional component in the blackbox gradient estimation, forcing
the policy to solutions with lower total assignment costs. We empirically show
on simulated data, generated for a particle detector developed for proton
imaging, the effectiveness of our approach, compared to multiple single- and
multi-agent baselines. We further demonstrate the effectiveness of constraints
with cost margins for both optimization and generalization, introduced by wider
regions with high reconstruction performance as well as reduced predictive
instabilities. Our results form the basis for further developments in RL-based
tracking, offering both enhanced performance with constrained policies and
greater flexibility in optimizing tracking algorithms through the option for
individual and team rewards.

æè¦ï¼å¼·åå­¸ç¿å¨å»ºæ¨¡è¤éçç©çé©åç³»çµ±æ¹é¢å±ç¾åºå·¨å¤§çæåï¼ééèæ¨¡æ¬æçå¯¦ç°å¢äºåï¼æä¾ç«¯å°ç«¯çå¯è¨ç·´è§£æ±ºæ¹æ¡ï¼æå¤§åæ¨éçåµè¨èãå¨éé å·¥ä½ä¸­ï¼æåæåºå»ºç«å¨ååå·¥ä½ä¸çå¤éä»£çå¼·åå­¸ç¿æ¹æ³ï¼ä½¿ç¨ææ´¾ç´æä¾éå»ºåç´ åç²å­æ¢æ¸¬å¨ä¸­çç²å­è»è·¡ãæåçåæ³ééå±åæå°åè®åæ¡æ¶ä¸­éå»ºè»è·¡ä¸ç²å­çç¸½æ£å°éï¼åèª¿æä½³åä¸ååæ¸åç­ç¥ï¼ä½çºå¤ç¶­ææ´¾åé¡çåç¼æ³ãçºäºæ»¿è¶³ç´æï¼ç¢ºä¿ç²å­å½ä¸­äºä»¶çå¯ä¸ææ´¾ï¼æåæåºä¸åå®å¨å±¤ï¼çºæ¯åè¯ååä½è§£æ±ºç·æ§ææ´¾åé¡ãæ­¤å¤ï¼çºäºå¼·å¶å·è¡ææ¬ééï¼å¢å å±é¨ç­ç¥é æ¸¬èæä½³åå°æçæ±ºç­éççè·é¢ï¼æåå»ºè­°å¨é»çæ¢¯åº¦ä¼°è¨ä¸­ä½¿ç¨é¡å¤ççµæï¼è¿«ä½¿ç­ç¥æ¡åç¸½ææ´¾ææ¬è¼ä½çè§£æ±ºæ¹æ¡ãæåå¨çºè³ªå­å½±åéç¼çç²å­æ¢æ¸¬å¨ç¢ççæ¨¡æ¬è³æä¸ï¼å¯¦è­é¡¯ç¤ºæåçæ¹æ³ææï¼ä¸¦èå¤åå®ä¸åå¤éä»£çåºæºé²è¡æ¯è¼ãæåé²ä¸æ­¥å±ç¤ºäºç´æå¨æä½³ååæ¦æ¬ä¸­çæææ§ï¼éäºç´æééå·æé«éå»ºæè½çè¼å¯¬å»£ååä»¥åæ¸å°é æ¸¬ä¸ç©©å®æ§èå¼å¥ãæåççµæçºåºæ¼ RL çè¿½è¹¤é²ä¸æ­¥ç¼å±å¥ å®åºç¤ï¼ééåç´æç­ç¥æä¾å¢å¼·çæè½ï¼ä»¥åééåäººååéçåµçé¸é ï¼å¨æä½³åè¿½è¹¤æ¼ç®æ³æ¹é¢æä¾æ´å¤§çå½æ§ã

##### **Advancing ALS Applications with Large-Scale Pre-training: Dataset Development and Downstream Assessment**
2501.05095v1 by Haoyi Xiu, Xin Liu, Taehoon Kim, Kyoung-Sook Kim

The pre-training and fine-tuning paradigm has revolutionized satellite remote
sensing applications. However, this approach remains largely underexplored for
airborne laser scanning (ALS), an important technology for applications such as
forest management and urban planning. In this study, we address this gap by
constructing a large-scale ALS point cloud dataset and evaluating its impact on
downstream applications. Our dataset comprises ALS point clouds collected
across the contiguous United States, provided by the United States Geological
Survey's 3D Elevation Program. To ensure efficient data collection while
capturing diverse land cover and terrain types, we introduce a geospatial
sampling method that selects point cloud tiles based on land cover maps and
digital elevation models. As a baseline self-supervised learning model, we
adopt BEV-MAE, a state-of-the-art masked autoencoder for 3D outdoor point
clouds, and pre-train it on the constructed dataset. The pre-trained models are
subsequently fine-tuned for downstream tasks, including tree species
classification, terrain scene recognition, and point cloud semantic
segmentation. Our results show that the pre-trained models significantly
outperform their scratch counterparts across all downstream tasks,
demonstrating the transferability of the representations learned from the
proposed dataset. Furthermore, we observe that scaling the dataset using our
geospatial sampling method consistently enhances performance, whereas
pre-training on datasets constructed with random sampling fails to achieve
similar improvements. These findings highlight the utility of the constructed
dataset and the effectiveness of our sampling strategy in the pre-training and
fine-tuning paradigm. The source code and pre-trained models will be made
publicly available at \url{https://github.com/martianxiu/ALS_pretraining}.

æè¦ï¼é è¨ç·´åå¾®èª¿ç¯ä¾å·²å¾¹åºæ¹è®è¡æéæ¸¬æç¨ãç¶èï¼éç¨®æ¹æ³å¨æ©è¼é·å°ææ (ALS) ä¸ä»æªè¢«å»£æ³æ¢ç´¢ï¼è ALS æ¯ä¸é æç¨æ¼æ£®æç®¡çåé½å¸è¦åç­é åçéè¦æè¡ãå¨éé ç ç©¶ä¸­ï¼æåééå»ºæ§å¤§è¦æ¨¡ ALS é»é²è³æéä¸¦è©ä¼°å¶å°ä¸æ¸¸æç¨çå½±é¿ä¾è§£æ±ºéååé¡ãæåçè³æéåå«ç±ç¾åå°è³ªèª¿æ¥å±ç 3D é«ç¨è¨ç«ææä¾çï¼å¨ç¾åæ¬åæ¶éç ALS é»é²ãçºäºç¢ºä¿ææççè³ææ¶éï¼åææ·åå¤æ¨£çåå°è¦èåå°å½¢é¡åï¼æåå¼å¥ä¸ç¨®å°çç©ºéåæ¨£æ¹æ³ï¼æ ¹æåå°è¦èå°ååæ¸ä½é«ç¨æ¨¡åä¾é¸æé»é²ç£å¡ãèº«çºåºæºçèªç£ç£å¼å­¸ç¿æ¨¡åï¼æåæ¡ç¨ BEV-MAEï¼éæ¯ä¸ç¨®æåé²ç 3D æ¶å¤é»é²é®ç½©èªåç·¨ç¢¼å¨ï¼ä¸¦å¨å»ºæ§çè³æéä¸å°å¶é²è¡é è¨ç·´ãé è¨ç·´æ¨¡åé¨å¾éå°ä¸æ¸¸ä»»åé²è¡å¾®èª¿ï¼åæ¬æ¨¹ç¨®åé¡ãå°å½¢å ´æ¯è¾¨è­åé»é²èªæåå²ãæåççµæé¡¯ç¤ºï¼é è¨ç·´æ¨¡åå¨ææä¸æ¸¸ä»»åä¸­é½é¡¯èåªæ¼å¾é ­è¨ç·´çæ¨¡åï¼è­æäºå¾å»ºè­°è³æéä¸­å­¸ç¿å°çè¡¨å¾µçå¯è½ç§»æ§ãæ­¤å¤ï¼æåè§å¯å°ä½¿ç¨æåçå°çç©ºéåæ¨£æ¹æ³æ´åè³æéææçºæåæè½ï¼èä½¿ç¨é¨æ©åæ¨£å»ºæ§çè³æéé²è¡é è¨ç·´åç¡æ³ç²å¾é¡ä¼¼çé²æ­¥ãéäºç¼ç¾çªé¡¯äºå»ºæ§è³æéçæç¨ï¼ä»¥åæåçåæ¨£ç­ç¥å¨é è¨ç·´åå¾®èª¿ç¯ä¾ä¸­çæææ§ãåå§ç¢¼åé è¨ç·´æ¨¡åå°å¨ \url{https://github.com/martianxiu/ALS_pretraining} å¬éã

##### **Comparison of Feature Learning Methods for Metadata Extraction from PDF Scholarly Documents**
2501.05082v1 by Zeyd Boukhers, Cong Yang

The availability of metadata for scientific documents is pivotal in
propelling scientific knowledge forward and for adhering to the FAIR principles
(i.e. Findability, Accessibility, Interoperability, and Reusability) of
research findings. However, the lack of sufficient metadata in published
documents, particularly those from smaller and mid-sized publishers, hinders
their accessibility. This issue is widespread in some disciplines, such as the
German Social Sciences, where publications often employ diverse templates. To
address this challenge, our study evaluates various feature learning and
prediction methods, including natural language processing (NLP), computer
vision (CV), and multimodal approaches, for extracting metadata from documents
with high template variance. We aim to improve the accessibility of scientific
documents and facilitate their wider use. To support our comparison of these
methods, we provide comprehensive experimental results, analyzing their
accuracy and efficiency in extracting metadata. Additionally, we provide
valuable insights into the strengths and weaknesses of various feature learning
and prediction methods, which can guide future research in this field.

æè¦ï¼ç§å­¸æä»¶ä¸­çåè³æå¯ç¨æ§å°æ¼æ¨é²ç§å­¸ç¥è­é²æ­¥ä»¥åéµå®ç ç©¶ç¼ç¾ç FAIR ååï¼å³ï¼å¯å°æ¾æ§ãå¯å­åæ§ãäºæä½æ§åå¯éè¤ä½¿ç¨æ§ï¼è³ééè¦ãç¶èï¼å·²ç¼å¸æä»¶ä¸­ç¼ºä¹è¶³å¤ çåè³æï¼å°¤å¶æ¯ä¾èªè¼å°è¦æ¨¡åä¸­åè¦æ¨¡åºçåçæä»¶ï¼æé»ç¤å¶å¯å­åæ§ãéååé¡å¨æäºé åå¾æ®éï¼ä¾å¦å¾·åç¤¾æç§å­¸ï¼é£è£¡çåºçç©éå¸¸æ¡ç¨ä¸åçç¯æ¬ãçºäºæå°éåææ°ï¼æåçç ç©¶è©ä¼°äºåç¨®ç¹å¾µå­¸ç¿åé æ¸¬æ¹æ³ï¼åæ¬èªç¶èªè¨èç (NLP)ãé»è¦è¦è¦º (CV) åå¤æ¨¡å¼æ¹æ³ï¼ç¨æ¼å¾ç¯æ¬å·®ç°æ§é«çæä»¶ä¸­èååè³æãæåçç®æ¨æ¯æ¹åç§å­¸æä»¶çå¯å­åæ§ï¼ä¸¦ä¿é²å¶æ´å»£æ³çä½¿ç¨ãçºäºæ¯ææåå°éäºæ¹æ³çæ¯è¼ï¼æåæä¾äºå¨é¢çå¯¦é©çµæï¼åæäºå®åå¨èååè³ææ¹é¢çæºç¢ºæ§åæçãæ­¤å¤ï¼æåéæä¾äºå°åç¨®ç¹å¾µå­¸ç¿åé æ¸¬æ¹æ³çåªç¼ºé»çå¯¶è²´è¦è§£ï¼éäºè¦è§£å¯ä»¥æå°æ­¤é åçæªä¾ç ç©¶ã

##### **Multimodal-to-Text Prompt Engineering in Large Language Models Using Feature Embeddings for GNSS Interference Characterization**
2501.05079v1 by Harshith Manjunath, Lucas Heublein, Tobias Feigl, Felix Ott

Large language models (LLMs) are advanced AI systems applied across various
domains, including NLP, information retrieval, and recommendation systems.
Despite their adaptability and efficiency, LLMs have not been extensively
explored for signal processing tasks, particularly in the domain of global
navigation satellite system (GNSS) interference monitoring. GNSS interference
monitoring is essential to ensure the reliability of vehicle localization on
roads, a critical requirement for numerous applications. However, GNSS-based
positioning is vulnerable to interference from jamming devices, which can
compromise its accuracy. The primary objective is to identify, classify, and
mitigate these interferences. Interpreting GNSS snapshots and the associated
interferences presents significant challenges due to the inherent complexity,
including multipath effects, diverse interference types, varying sensor
characteristics, and satellite constellations. In this paper, we extract
features from a large GNSS dataset and employ LLaVA to retrieve relevant
information from an extensive knowledge base. We employ prompt engineering to
interpret the interferences and environmental factors, and utilize t-SNE to
analyze the feature embeddings. Our findings demonstrate that the proposed
method is capable of visual and logical reasoning within the GNSS context.
Furthermore, our pipeline outperforms state-of-the-art machine learning models
in interference classification tasks.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) æ¯åé²çäººå·¥æºæ§ç³»çµ±ï¼æç¨æ¼åç¨®é åï¼åæ¬èªç¶èªè¨èçãè³è¨æª¢ç´¢åæ¨è¦ç³»çµ±ãåç®¡ LLM å·æé©ææ§åæçï¼ä½å°æªå»£æ³æ¢ç´¢ç¨æ¼è¨èèçä»»åï¼ç¹å¥æ¯å¨å¨çå°èªè¡æç³»çµ± (GNSS) å¹²æ¾ç£æ§é åãGNSS å¹²æ¾ç£æ§å°æ¼ç¢ºä¿éè·¯ä¸è»è¼å®ä½çå¯é æ§è³ééè¦ï¼éå°æ¼è¨±å¤æç¨ä¾èªªæ¯ä¸é ééµè¦æ±ãç¶èï¼åºæ¼ GNSS çå®ä½å®¹æåå°å¹²æ¾è£ç½®çå¹²æ¾ï¼éå¯è½æå½±é¿å¶æºç¢ºæ§ãä¸»è¦ç®æ¨æ¯è­å¥ãåé¡åæ¸è¼éäºå¹²æ¾ãç±æ¼åºæçè¤éæ§ï¼åæ¬å¤è·¯å¾ææãå¤æ¨£åçå¹²æ¾é¡åãä¸åçææ¸¬å¨ç¹æ§åè¡ææåº§ï¼å æ­¤è§£é GNSS å¿«ç§åç¸éå¹²æ¾æå¸¶ä¾éå¤§ææ°ãå¨æ¬æä¸­ï¼æåå¾å¤§å GNSS è³æéä¸­æåç¹å¾µï¼ä¸¦ä½¿ç¨ LLaVA å¾å»£æ³çç¥è­åº«ä¸­æª¢ç´¢ç¸éè³è¨ãæåæ¡ç¨æç¤ºå·¥ç¨ä¾è§£éå¹²æ¾åç°å¢å ç´ ï¼ä¸¦å©ç¨ t-SNE ä¾åæç¹å¾µåµå¥ãæåçç ç©¶çµæè¡¨æï¼ææåºçæ¹æ³è½å¤ å¨ GNSS èæ¯ä¸é²è¡è¦è¦ºåéè¼¯æ¨çãæ­¤å¤ï¼æåçç®¡éå¨å¹²æ¾åé¡ä»»åä¸­åªæ¼æåé²çæ©å¨å­¸ç¿æ¨¡åã

##### **Analyzing Memorization in Large Language Models through the Lens of Model Attribution**
2501.05078v1 by Tarun Ram Menta, Susmit Agrawal, Chirag Agarwal

Large Language Models (LLMs) are prevalent in modern applications but often
memorize training data, leading to privacy breaches and copyright issues.
Existing research has mainly focused on posthoc analyses, such as extracting
memorized content or developing memorization metrics, without exploring the
underlying architectural factors that contribute to memorization. In this work,
we investigate memorization from an architectural lens by analyzing how
attention modules at different layers impact its memorization and
generalization performance. Using attribution techniques, we systematically
intervene in the LLM architecture by bypassing attention modules at specific
blocks while keeping other components like layer normalization and MLP
transformations intact. We provide theorems analyzing our intervention
mechanism from a mathematical view, bounding the difference in layer outputs
with and without our attributions. Our theoretical and empirical analyses
reveal that attention modules in deeper transformer blocks are primarily
responsible for memorization, whereas earlier blocks are crucial for the models
generalization and reasoning capabilities. We validate our findings through
comprehensive experiments on different LLM families (Pythia and GPTNeo) and
five benchmark datasets. Our insights offer a practical approach to mitigate
memorization in LLMs while preserving their performance, contributing to safer
and more ethical deployment in real world applications.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å¨ç¾ä»£æç¨ä¸­å¾æ®éï¼ä½ç¶å¸¸è¨ä½è¨ç·´è³æï¼å°è´é±ç§æ´©é²åçæ¬åé¡ãç¾æç ç©¶ä¸»è¦éä¸­å¨äºå¾åæï¼ä¾å¦æåè¨æ¶å§å®¹æéç¼è¨æ¶åº¦éæ¨æºï¼èæ²ææ¢è¨å°è´è¨æ¶çåºå±¤æ¶æ§å ç´ ãå¨éé å·¥ä½ä¸­ï¼æåééåæä¸åå±¤ç´çæ³¨æåæ¨¡çµå¦ä½å½±é¿å¶è¨æ¶åæ³åæè½ï¼å¾æ¶æ§è§åº¦æ¢è¨è¨æ¶ãä½¿ç¨æ­¸å æè¡ï¼æåç³»çµ±æ§å°ä»å¥ LLM æ¶æ§ï¼æ¹æ³æ¯å¨ç¹å®åå¡ä¸­ç¹éæ³¨æåæ¨¡çµï¼åæä¿æå±¤æ­£è¦åå MLP è½æç­å¶ä»åä»¶å®æ´ãæåæä¾å®çå¾æ¸å­¸è§åº¦åææåçä»å¥æ©å¶ï¼çå®æåæ²ææåçæ­¸å æå±¤è¼¸åºå·®ç°ãæåççè«åå¯¦è­åæé¡¯ç¤ºï¼è¼æ·±å±¤Transformeråå¡ä¸­çæ³¨æåæ¨¡çµä¸»è¦è² è²¬è¨æ¶ï¼èè¼æ©æçåå¡å°æ¼æ¨¡åçæ³ååæ¨çè½åè³ééè¦ãæåééå°ä¸å LLM å®¶æï¼Pythia å GPTNeoï¼åäºååºæºè³æéé²è¡å¨é¢çå¯¦é©é©è­æåçç¼ç¾ãæåçè¦è§£æä¾äºä¸ç¨®å¯¦ç¨çæ¹æ³ä¾æ¸è¼ LLM ä¸­çè¨æ¶ï¼åæä¿çå¶æè½ï¼æå©æ¼å¨å¯¦éæç¨ä¸­æ´å®å¨ãæ´åä¹éå¾·å°é¨ç½²ã

##### **A Text-Based Knowledge-Embedded Soft Sensing Modeling Approach for General Industrial Process Tasks Based on Large Language Model**
2501.05075v1 by Shuo Tong, Han Liu, Runyuan Guo, Xueqiong Tian, Wenqing Wang, Ding Liu, Youmin Zhang

Data-driven soft sensors (DDSS) have become mainstream methods for predicting
key performance indicators in process industries. However, DDSS development
requires complex and costly customized designs tailored to various tasks during
the modeling process. Moreover, DDSS are constrained to a single structured
data modality, limiting their ability to incorporate additional contextual
knowledge. Furthermore, DDSSs' limited representation learning leads to weak
predictive performance with scarce data. To address these challenges, we
propose a general framework named LLM-TKESS (large language model for
text-based knowledge-embedded soft sensing), harnessing the powerful general
problem-solving capabilities, cross-modal knowledge transfer abilities, and
few-shot capabilities of LLM for enhanced soft sensing modeling. Specifically,
an auxiliary variable series encoder (AVS Encoder) is proposed to unleash LLM's
potential for capturing temporal relationships within series and spatial
semantic relationships among auxiliary variables. Then, we propose a two-stage
fine-tuning alignment strategy: in the first stage, employing
parameter-efficient fine-tuning through autoregressive training adjusts LLM to
rapidly accommodate process variable data, resulting in a soft sensing
foundation model (SSFM). Subsequently, by training adapters, we adapt the SSFM
to various downstream tasks without modifying its architecture. Then, we
propose two text-based knowledge-embedded soft sensors, integrating new natural
language modalities to overcome the limitations of pure structured data models.
Furthermore, benefiting from LLM's pre-existing world knowledge, our model
demonstrates outstanding predictive capabilities in small sample conditions.
Using the thermal deformation of air preheater rotor as a case study, we
validate through extensive experiments that LLM-TKESS exhibits outstanding
performance.

æè¦ï¼<paragraph>è³æé©åè»ææ¸¬å¨ (DDSS) å·²æçºé æ¸¬è£½ç¨ç¢æ¥­ä¸­ééµç¸¾æææ¨çä¸»æµæ¹æ³ãç¶èï¼DDSS çéç¼éè¦è¤éä¸æè²´çå®¢è£½åè¨­è¨ï¼ä»¥é©æå»ºæ¨¡éç¨ä¸­åç¨®ä»»åãæ­¤å¤ï¼DDSS åå°å®ä¸çµæ§åè³ææ¨¡å¼çéå¶ï¼ééå¶äºå¶æ´åé¡å¤èæ¯ç¥è­çè½åãé²ä¸æ­¥ä¾èªªï¼DDSS æéçè¡¨å¾µå­¸ç¿å°è´å¨è³æç¨å°çææ³ä¸é æ¸¬æè½ä¸ä½³ãçºäºæå°éäºææ°ï¼æåæåºäºä¸ååçº LLM-TKESSï¼ç¨æ¼åºæ¼æå­ç¥è­åµå¥å¼è»ææ¸¬çå¤§åèªè¨æ¨¡åï¼çéç¨æ¶æ§ï¼å©ç¨ LLM å¼·å¤§çéç¨åé¡è§£æ±ºè½åãè·¨æ¨¡æç¥è­å³è¼¸è½ååå°æ¨£æ¬è½åä¾å¢å¼·è»ææ¸¬å»ºæ¨¡ãå·é«ä¾èªªï¼æåºäºä¸åè¼å©è®æ¸åºåç·¨ç¢¼å¨ (AVS ç·¨ç¢¼å¨) ä¾éæ¾ LLM æ·ååºåä¸­æééä¿åè¼å©è®æ¸ä¹éç©ºéèªç¾©éä¿çæ½åãç¶å¾ï¼æåæåºäºä¸åå©éæ®µå¾®èª¿å°é½ç­ç¥ï¼å¨ç¬¬ä¸éæ®µï¼ééèªè¿´æ­¸è¨ç·´æ¡ç¨åæ¸é«æçå¾®èª¿ï¼èª¿æ´ LLM ä»¥å¿«éé©æè£½ç¨è®æ¸è³æï¼å¾èç¢çè»ææ¸¬åºç¤æ¨¡å (SSFM)ãé¨å¾ï¼ééè¨ç·´é©éå¨ï¼æåå° SSFM é©æå°åç¨®ä¸æ¸¸ä»»åï¼èç¡éä¿®æ¹å¶æ¶æ§ãç¶å¾ï¼æåæåºäºå©ååºæ¼æå­çç¥è­åµå¥å¼è»ææ¸¬å¨ï¼æ´åæ°çèªç¶èªè¨æ¨¡å¼ä»¥åæç´çµæ§åè³ææ¨¡åçéå¶ãæ­¤å¤ï¼åçæ¼ LLM å·²æçä¸çç¥è­ï¼æåçæ¨¡åå¨å°æ¨£æ¬æ¢ä»¶ä¸å±ç¤ºäºåºè²çé æ¸¬è½åãä½¿ç¨ç©ºæ°£é ç±å¨è½å­çç±è®å½¢ä½çºæ¡ä¾ç ç©¶ï¼æåééå»£æ³çå¯¦é©é©è­äº LLM-TKESS å±ç¾åºè²çæè½ã</paragraph>

##### **Commonsense Video Question Answering through Video-Grounded Entailment Tree Reasoning**
2501.05069v1 by Huabin Liu, Filip Ilievski, Cees G. M. Snoek

This paper proposes the first video-grounded entailment tree reasoning method
for commonsense video question answering (VQA). Despite the remarkable progress
of large visual-language models (VLMs), there are growing concerns that they
learn spurious correlations between videos and likely answers, reinforced by
their black-box nature and remaining benchmarking biases. Our method explicitly
grounds VQA tasks to video fragments in four steps: entailment tree
construction, video-language entailment verification, tree reasoning, and
dynamic tree expansion. A vital benefit of the method is its generalizability
to current video and image-based VLMs across reasoning types. To support fair
evaluation, we devise a de-biasing procedure based on large-language models
that rewrites VQA benchmark answer sets to enforce model reasoning. Systematic
experiments on existing and de-biased benchmarks highlight the impact of our
method components across benchmarks, VLMs, and reasoning types.

æè¦ï¼æ¬ææåºç¬¬ä¸åå½±çæ¥å°æ¨è«æ¨¹æ¨çæ¹æ³ï¼ç¨æ¼å¸¸è­å½±çåç­ (VQA)ãåç®¡å¤§åè¦è¦ºèªè¨æ¨¡å (VLM) æé¡¯èé²å±ï¼ä½å°æ¼å®åå­¸ç¿å½±çèå¯è½ç­æ¡ä¹éçèåéè¯æ§ï¼ä¸¦å å¶é»çæ§è³ªåç¾æåºæºåå·®èå å¼·ï¼è¶ä¾è¶ä»¤äººææãæåçæ¨¡åæç¢ºå°å° VQA ä»»åå»ºç«å¨å½±ççæ®µä¸ï¼åçºååæ­¥é©ï¼æ¨è«æ¨¹æ§å»ºãå½±çèªè¨æ¨è«é©è­ãæ¨¹æ¨çååææ¨¹æ´åãæ­¤æ¹æ³çä¸é éè¦åªé»æ¯å¶å°åç¨®æ¨çé¡åä¸­ç¾æå½±çååºæ¼å½±åç VLM çéç¨æ§ãçºäºæ¯æå¬å¹³çè©ä¼°ï¼æåè¨­è¨äºä¸ååºæ¼å¤§åèªè¨æ¨¡åçå»åç¨åºï¼ç¨æ¼æ¹å¯« VQA åºæºç­æ¡éä»¥å¼·å¶å·è¡æ¨¡åæ¨çãå¨ç¾æåå»ååºæºä¸çç³»çµ±æ§å¯¦é©çªé¡¯äºæåçæ¨¡åçµæå¨åºæºãVLM åæ¨çé¡åä¸çå½±é¿ã

##### **D3RM: A Discrete Denoising Diffusion Refinement Model for Piano Transcription**
2501.05068v1 by Hounsu Kim, Taegyun Kwon, Juhan Nam

Diffusion models have been widely used in the generative domain due to their
convincing performance in modeling complex data distributions. Moreover, they
have shown competitive results on discriminative tasks, such as image
segmentation. While diffusion models have also been explored for automatic
music transcription, their performance has yet to reach a competitive level. In
this paper, we focus on discrete diffusion model's refinement capabilities and
present a novel architecture for piano transcription. Our model utilizes
Neighborhood Attention layers as the denoising module, gradually predicting the
target high-resolution piano roll, conditioned on the finetuned features of a
pretrained acoustic model. To further enhance refinement, we devise a novel
strategy which applies distinct transition states during training and inference
stage of discrete diffusion models. Experiments on the MAESTRO dataset show
that our approach outperforms previous diffusion-based piano transcription
models and the baseline model in terms of F1 score. Our code is available in
https://github.com/hanshounsu/d3rm.

æè¦ï¼æ´æ£æ¨¡åå å¶å¨å»ºæ¨¡è¤éè³æåä½ä¸çåºè²è¡¨ç¾ï¼èå»£æ³ç¨æ¼çæé åãæ­¤å¤ï¼å®åå¨å¤å¥ä»»åï¼ä¾å¦å½±ååå²ï¼ä¸ä¹å±ç¾åºç«¶ç­åççµæãåç®¡æ´æ£æ¨¡åä¹å·²ç¨æ¼èªåé³æ¨è½éï¼ä½å¶æè½ä»æªéå°ç«¶ç­æ°´æºãå¨æ¬æä¸­ï¼æåå°æ³¨æ¼é¢æ£æ´æ£æ¨¡åçç²¾çè½åï¼ä¸¦æåºé¼ç´è½éçæ°ç©æ¶æ§ãæåçæ¨¡åå©ç¨é°åæ³¨æåå±¤ä½çºå»åªæ¨¡çµï¼éæ¼¸é æ¸¬ç®æ¨é«è§£æåº¦é¼ç´æ²è»¸ï¼ä¸¦æ ¹æé è¨ç·´è²å­¸æ¨¡åçå¾®èª¿ç¹å¾µé²è¡æ¢ä»¶åãçºäºé²ä¸æ­¥å¢å¼·ç²¾çï¼æåè¨­è¨äºä¸ç¨®æ°ç©ç­ç¥ï¼å¨é¢æ£æ´æ£æ¨¡åçè¨ç·´åæ¨è«éæ®µæç¨ä¸åçè½æçæãå¨ MAESTRO è³æéä¸çå¯¦é©é¡¯ç¤ºï¼æåçåæ³å¨ F1 åæ¸æ¹é¢åªæ¼ååçåºæ¼æ´æ£çé¼ç´è½éæ¨¡åååºæºæ¨¡åãæåçç¨å¼ç¢¼å¯å¨ https://github.com/hanshounsu/d3rm ä¸­åå¾ã

##### **LLaVA-Octopus: Unlocking Instruction-Driven Adaptive Projector Fusion for Video Understanding**
2501.05067v1 by Jiaxing Zhao, Boyuan Sun, Xiang Chen, Xihan Wei, Qibin Hou

In this paper, we introduce LLaVA-Octopus, a novel video multimodal large
language model. LLaVA-Octopus adaptively weights features from different visual
projectors based on user instructions, enabling us to leverage the
complementary strengths of each projector. We observe that different visual
projectors exhibit distinct characteristics when handling specific tasks. For
instance, some projectors excel at capturing static details, while others are
more effective at processing temporal information, and some are better suited
for tasks requiring temporal coherence. By dynamically adjusting feature
weights according to user instructions, LLaVA-Octopus dynamically selects and
combines the most suitable features, significantly enhancing the model's
performance in multimodal tasks. Experimental results demonstrate that
LLaVA-Octopus achieves excellent performance across multiple benchmarks,
especially in tasks such as multimodal understanding, visual question
answering, and video understanding, highlighting its broad application
potential.

æè¦ï¼å¨æ¬æä¸­ï¼æåä»ç´¹ LLaVA-Octopusï¼ä¸ç¨®æ°ç©çå¤æ¨¡æå¤§åèªè¨å½±çæ¨¡åãLLaVA-Octopus ææ ¹æä½¿ç¨èçæç¤ºï¼èªé©æå°èª¿æ´ä¸åè¦è¦ºæå½±å¨çç¹å¾µæ¬éï¼ä½¿æåè½å¤ å©ç¨æ¯åæå½±å¨çäºè£åªå¢ãæåè§å¯å°ä¸åçè¦è¦ºæå½±å¨å¨èçç¹å®ä»»åæï¼æè¡¨ç¾åºä¸åçç¹å¾µãä¾å¦ï¼æäºæå½±å¨æé·æ·åéæç´°ç¯ï¼èæäºåæ´ææå°èçæéè³è¨ï¼æäºåæ´é©åéè¦æéé£è²«æ§çä»»åãééæ ¹æä½¿ç¨èçæç¤ºåæèª¿æ´ç¹å¾µæ¬éï¼LLaVA-Octopus æåæé¸æä¸¦çµåæåé©çç¹å¾µï¼å¤§å¹æåæ¨¡åå¨å¤æ¨¡æä»»åä¸­çè¡¨ç¾ãå¯¦é©çµæè­æï¼LLaVA-Octopus å¨å¤ååºæºæ¸¬è©¦ä¸­é½è½éå°æ¥µä½³çè¡¨ç¾ï¼ç¹å¥æ¯å¨å¤æ¨¡æçè§£ãè¦è¦ºåç­åå½±ççè§£ç­ä»»åä¸­ï¼çªé¡¯å¶å»£æ³çæç¨æ½åã

##### **Improving Skeleton-based Action Recognition with Interactive Object Information**
2501.05066v1 by Hao Wen, Ziqian Lu, Fengli Shen, Zhe-Ming Lu, Jialin Cui

Human skeleton information is important in skeleton-based action recognition,
which provides a simple and efficient way to describe human pose. However,
existing skeleton-based methods focus more on the skeleton, ignoring the
objects interacting with humans, resulting in poor performance in recognizing
actions that involve object interactions. We propose a new action recognition
framework introducing object nodes to supplement absent interactive object
information. We also propose Spatial Temporal Variable Graph Convolutional
Networks (ST-VGCN) to effectively model the Variable Graph (VG) containing
object nodes. Specifically, in order to validate the role of interactive object
information, by leveraging a simple self-training approach, we establish a new
dataset, JXGC 24, and an extended dataset, NTU RGB+D+Object 60, including more
than 2 million additional object nodes. At the same time, we designe the
Variable Graph construction method to accommodate a variable number of nodes
for graph structure. Additionally, we are the first to explore the overfitting
issue introduced by incorporating additional object information, and we propose
a VG-based data augmentation method to address this issue, called Random Node
Attack. Finally, regarding the network structure, we introduce two fusion
modules, CAF and WNPool, along with a novel Node Balance Loss, to enhance the
comprehensive performance by effectively fusing and balancing skeleton and
object node information. Our method surpasses the previous state-of-the-art on
multiple skeleton-based action recognition benchmarks. The accuracy of our
method on NTU RGB+D 60 cross-subject split is 96.7\%, and on cross-view split,
it is 99.2\%.

æè¦ï¼äººé«éª¨éª¼è³è¨å°æ¼åºæ¼éª¨éª¼çåä½è¾¨è­éå¸¸éè¦ï¼éæä¾äºæè¿°äººé«å§¿å¢çç°¡å®ä¸ææççæ¹æ³ãç¶èï¼ç¾æçåºæ¼éª¨éª¼çæ¹æ³æ´å°æ³¨æ¼éª¨éª¼ï¼å¿½ç¥äºèäººé¡äºåçç©é«ï¼å°è´å¨è¾¨è­æ¶åç©é«äºåçåä½ææè½ä¸ä½³ãæåæåºä¸åæ°çåä½è¾¨è­æ¶æ§ï¼å¼å¥ç©é«ç¯é»ä¾è£åç¼ºå°çäºåç©é«è³è¨ãæåä¹æåºæç©ºè®æ¸åå½¢å·ç©ç¶²è·¯ (ST-VGCN) ä¾ææå°å»ºæ¨¡åå«ç©é«ç¯é»çè®æ¸åå½¢ (VG)ãå·é«ä¾èªªï¼çºäºé©è­äºåç©é«è³è¨çè§è²ï¼æåééå©ç¨ä¸åç°¡å®çèªè¨ç·´æ¹æ³ï¼å»ºç«äºä¸åæ°çè³æé JXGC 24 åä¸åæ´åçè³æé NTU RGB+D+Object 60ï¼åå«è¶é 200 è¬åé¡å¤çç©é«ç¯é»ãåæï¼æåè¨­è¨äºè®æ¸åå½¢å»ºæ§æ¹æ³ä¾å®¹ç´åå½¢çµæ§ä¸­è®æ¸çç¯é»æ¸éãæ­¤å¤ï¼æåçåæ¢è¨äºå å¥é¡å¤ç©é«è³è¨æé æçéåº¦æ¬ååé¡ï¼ä¸¦æåºä¸ååºæ¼ VG çè³ææ´åæ¹æ³ä¾è§£æ±ºéååé¡ï¼ç¨±çºé¨æ©ç¯é»æ»æãæå¾ï¼éæ¼ç¶²è·¯çµæ§ï¼æåå¼å¥äºå©åèåæ¨¡çµï¼CAF å WNPoolï¼ä»¥åä¸åæ°ç©çç¯é»å¹³è¡¡æå¤±ï¼ééææå°èååå¹³è¡¡éª¨éª¼åç©é«ç¯é»è³è¨ä¾å¢å¼·ç¶åæè½ãæåçæ¨¡åè¶è¶äºå¤ååºæ¼éª¨éª¼çåä½è¾¨è­åºæºä¸çååæè¡æ°´æºãæåçæ¨¡åå¨ NTU RGB+D 60 äº¤åä¸»é«åå²ä¸çæºç¢ºåº¦çº 96.7%ï¼å¨äº¤åè¦è§åå²ä¸çæºç¢ºåº¦çº 99.2%ã

##### **Simultaneous emulation and downscaling with physically-consistent deep learning-based regional ocean emulators**
2501.05058v1 by Leonard Lupin-Jimenez, Moein Darman, Subhashis Hazarika, Tianning Wu, Michael Gray, Ruyoing He, Anthony Wong, Ashesh Chattopadhyay

Building on top of the success in AI-based atmospheric emulation, we propose
an AI-based ocean emulation and downscaling framework focusing on the
high-resolution regional ocean over Gulf of Mexico. Regional ocean emulation
presents unique challenges owing to the complex bathymetry and lateral boundary
conditions as well as from fundamental biases in deep learning-based
frameworks, such as instability and hallucinations. In this paper, we develop a
deep learning-based framework to autoregressively integrate ocean-surface
variables over the Gulf of Mexico at $8$ Km spatial resolution without
unphysical drifts over decadal time scales and simulataneously downscale and
bias-correct it to $4$ Km resolution using a physics-constrained generative
model. The framework shows both short-term skills as well as accurate long-term
statistics in terms of mean and variability.

æè¦ï¼å»ºç«å¨ä»¥ AI çºåºç¤çå¤§æ°£æ¨¡æ¬çæåä¹ä¸ï¼æåæåºä¸åä»¥ AI çºåºç¤çæµ·æ´æ¨¡æ¬åéå°ºåº¦æ¶æ§ï¼å°æ³¨æ¼å¢¨è¥¿å¥ç£çé«è§£æåº¦ååæµ·æ´ãååæµ·æ´æ¨¡æ¬ç±æ¼è¤éçæ°´æ·±æ¸¬éå­¸åéçæ¢ä»¶ï¼ä»¥ååºæ¼æ·±åº¦å­¸ç¿çæ¶æ§ï¼ä¾å¦ä¸ç©©å®æ§åå¹»è¦ºï¼ä¸­çåºæ¬åå·®ï¼å æ­¤åç¾åºç¨ç¹çææ°ãå¨æ¬æä¸­ï¼æåéç¼äºä¸ååºæ¼æ·±åº¦å­¸ç¿çæ¶æ§ï¼ä»¥èªè¿´æ­¸æ¹å¼æ´åå¢¨è¥¿å¥ç£çæµ·é¢è®æ¸ï¼ç©ºéè§£æåº¦çº 8 å¬éï¼å¨åå¹´æéå°ºåº¦ä¸æ²æéç©çæ¼ç§»ï¼ä¸¦ä¸åæä½¿ç¨åç©çç´æççææ¨¡åå°å¶éå°ºåº¦ä¸¦æ ¡æ­£åå·®è³ 4 å¬éè§£æåº¦ãè©²æ¶æ§å¨åå¼åè®ç°æ§æ¹é¢é¡¯ç¤ºäºç­ææè½åæºç¢ºçé·æçµ±è¨æ¸æã

##### **TAPFed: Threshold Secure Aggregation for Privacy-Preserving Federated Learning**
2501.05053v1 by Runhua Xu, Bo Li, Chao Li, James B. D. Joshi, Shuai Ma, Jianxin Li

Federated learning is a computing paradigm that enhances privacy by enabling
multiple parties to collaboratively train a machine learning model without
revealing personal data. However, current research indicates that traditional
federated learning platforms are unable to ensure privacy due to privacy leaks
caused by the interchange of gradients. To achieve privacy-preserving federated
learning, integrating secure aggregation mechanisms is essential.
Unfortunately, existing solutions are vulnerable to recently demonstrated
inference attacks such as the disaggregation attack. This paper proposes
TAPFed, an approach for achieving privacy-preserving federated learning in the
context of multiple decentralized aggregators with malicious actors. TAPFed
uses a proposed threshold functional encryption scheme and allows for a certain
number of malicious aggregators while maintaining security and privacy. We
provide formal security and privacy analyses of TAPFed and compare it to
various baselines through experimental evaluation. Our results show that TAPFed
offers equivalent performance in terms of model quality compared to
state-of-the-art approaches while reducing transmission overhead by 29%-45%
across different model training scenarios. Most importantly, TAPFed can defend
against recently demonstrated inference attacks caused by curious aggregators,
which the majority of existing approaches are susceptible to.

æè¦ï¼è¯é¦å­¸ç¿æ¯ä¸ç¨®éç®ç¯ä¾ï¼å®ééè®å¤æ¹åä½è¨ç·´æ©å¨å­¸ç¿æ¨¡åï¼èç¡éæ­é²åäººè³æï¼ä¾å¢å¼·é±ç§ãç¶èï¼ç®åçç ç©¶æé¡¯ç¤ºï¼å³çµ±çè¯é¦å­¸ç¿å¹³å°ç¡æ³ç¢ºä¿é±ç§ï¼éæ¯å çºæ¢¯åº¦çäº¤ææå°è´é±ç§å¤æ´©ãè¥è¦éæä¿è­·é±ç§çè¯é¦å­¸ç¿ï¼æ´åå®å¨çèåæ©å¶è³ééè¦ãä¸å¹¸çæ¯ï¼ç¾æçè§£æ±ºæ¹æ¡å®¹æåå°æè¿å±ç¤ºçæ¨è«æ»æï¼ä¾å¦å»èåæ»æãæ¬ææåº TAPFedï¼ä¸ç¨®å¨ææ¡æåèèçå¤ååæ£å¼èåå¨ç°å¢ä¸­ï¼éæä¿è­·é±ç§çè¯é¦å­¸ç¿çæ¹æ³ãTAPFed ä½¿ç¨ä¸ç¨®æåºçé¾å¼å½æ¸å å¯æ¹æ¡ï¼ä¸¦åè¨±ä¸å®æ¸éçæ¡æèåå¨ï¼åæç¶­è­·å®å¨æ§èé±ç§ãæåæä¾ TAPFed çæ­£å¼å®å¨èé±ç§åæï¼ä¸¦ééå¯¦é©è©ä¼°å°å¶èåç¨®åºæºé²è¡æ¯è¼ãæåççµæé¡¯ç¤ºï¼èæåé²çæ¹æ³ç¸æ¯ï¼TAPFed å¨æ¨¡ååè³ªæ¹é¢æä¾åç­çæè½ï¼åæå¨ä¸åçæ¨¡åè¨ç·´å ´æ¯ä¸­ï¼å°å³è¼¸è² æéä½äº 29%-45%ãæéè¦çæ¯ï¼TAPFed å¯ä»¥é²ç¦¦æè¿å±ç¤ºçï¼ç±å¥½å¥çèåå¨æé æçæ¨è«æ»æï¼èç¾ææ¹æ³çå¤§å¤æ¸é½å®¹æåå°éç¨®æ»æã

##### **SWE-Fixer: Training Open-Source LLMs for Effective and Efficient GitHub Issue Resolution**
2501.05040v1 by Chengxing Xie, Bowen Li, Chang Gao, He Du, Wai Lam, Difan Zou, Kai Chen

Large Language Models (LLMs) have demonstrated remarkable proficiency across
a variety of complex tasks. One significant application of LLMs is in tackling
software engineering challenges, particularly in resolving real-world tasks on
GitHub by fixing code based on the issues reported by the users. However, many
current approaches rely on proprietary LLMs, which limits reproducibility,
accessibility, and transparency. The critical components of LLMs for addressing
software engineering issues and how their capabilities can be effectively
enhanced remain unclear. To address these challenges, we introduce SWE-Fixer, a
novel open-source LLM designed to effectively and efficiently resolve GitHub
issues. SWE-Fixer comprises two essential modules: a code file retrieval module
and a code editing module. The retrieval module employs BM25 along with a
lightweight LLM model to achieve coarse-to-fine file retrieval. Subsequently,
the code editing module utilizes the other LLM model to generate patches for
the identified files. Then, to mitigate the lack of publicly available
datasets, we compile an extensive dataset that includes 110K GitHub issues
along with their corresponding patches, and train the two modules of SWE-Fixer
separately. We assess our approach on the SWE-Bench Lite and Verified
benchmarks, achieving state-of-the-art performance among open-source models
with scores of 23.3% and 30.2%, respectively. These outcomes highlight the
efficacy of our approach. We will make our model, dataset, and code publicly
available at https://github.com/InternLM/SWE-Fixer.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å·²å¨åç¨®è¤éä»»åä¸­å±ç¾åºéå¡çè½åãLLM çä¸é éè¦æç¨æ¯è§£æ±ºè»é«å·¥ç¨ææ°ï¼ç¹å¥æ¯ééä¿®å¾©ä½¿ç¨èåå ±åé¡ä¸­çç¨å¼ç¢¼ï¼ä¾è§£æ±º GitHub ä¸çå¯¦éä»»åãç¶èï¼è¨±å¤ç¾ææ¹æ³ä¾è³´æ¼å°æ LLMï¼ééå¶äºå¯è¤è£½æ§ãå¯å­åæ§åéæåº¦ãLLM è§£æ±ºè»é«å·¥ç¨åé¡çéè¦çµæé¨ååå¶è½åå¦ä½ææå¢å¼·ä»ä¸æ¸æ¥ãçºäºæå°éäºææ°ï¼æåå¼å¥äº SWE-Fixerï¼éæ¯ä¸åæ°ç©çéæº LLMï¼æ¨å¨ææä¸é«æå°è§£æ±º GitHub åé¡ãSWE-Fixer åå«å©åå¿è¦çæ¨¡çµï¼ç¨å¼ç¢¼æªæ¡æ·åæ¨¡çµåç¨å¼ç¢¼ç·¨è¼¯æ¨¡çµãæ·åæ¨¡çµæ¡ç¨ BM25 ä»¥åè¼éç´ LLM æ¨¡åï¼ä»¥å¯¦ç¾ç±ç²å°ç´°çæªæ¡æ·åãé¨å¾ï¼ç¨å¼ç¢¼ç·¨è¼¯æ¨¡çµå©ç¨å¦ä¸å LLM æ¨¡åï¼çºè­å¥çæªæ¡ç¢çä¿®è£ç¨å¼ãæ¥èï¼çºäºæ¸è¼å¬éå¯ç¨è³æéçä¸è¶³ï¼æåç·¨è­¯äºä¸ååå« 110K å GitHub åé¡åå¶å°æä¿®è£ç¨å¼çå»£æ³è³æéï¼ä¸¦åå¥è¨ç·´ SWE-Fixer çå©åæ¨¡çµãæåå¨ SWE-Bench Lite å Verified è©éåºæºä¸è©ä¼°äºæåçåæ³ï¼å¨éæºæ¨¡åä¸­åå¾äºæåé²çæè½ï¼åå¥ç²å¾ 23.3% å 30.2% çåæ¸ãéäºææçªé¡¯äºæåæ¹æ³çæææ§ãæåå°å¨ https://github.com/InternLM/SWE-Fixer å¬éæåçæ¨¡åãè³æéåç¨å¼ç¢¼ã

##### **Enhancing Human-Like Responses in Large Language Models**
2501.05032v1 by Ethem YaÄÄ±z ÃalÄ±k, Talha RÃ¼zgar AkkuÅ

This paper explores the advancements in making large language models (LLMs)
more human-like. We focus on techniques that enhance natural language
understanding, conversational coherence, and emotional intelligence in AI
systems. The study evaluates various approaches, including fine-tuning with
diverse datasets, incorporating psychological principles, and designing models
that better mimic human reasoning patterns. Our findings demonstrate that these
enhancements not only improve user interactions but also open new possibilities
for AI applications across different domains. Future work will address the
ethical implications and potential biases introduced by these human-like
attributes.

æè¦ï¼æ¬ææ¢è¨äºè®å¤§åèªè¨æ¨¡å (LLM) æ´æ¥è¿äººé¡çé²å±ãæåå°æ³¨æ¼å¢å¼·äººå·¥æºæ§ç³»çµ±ä¸­èªç¶èªè¨çè§£ãå°è©±é£è²«æ§åæç·æºåçæè¡ãæ¬ç ç©¶è©ä¼°äºåç¨®æ¹æ³ï¼åæ¬ä½¿ç¨å¤åè³æéé²è¡å¾®èª¿ãç´å¥å¿çååï¼ä»¥åè¨­è¨æ´è½æ¨¡æ¬äººé¡æ¨çæ¨¡å¼çæ¨¡åãæåçç ç©¶çµæè¡¨æï¼éäºå¢å¼·ä¸åæ¹åäºä½¿ç¨èäºåï¼ä¹çºä¸åé åçäººå·¥æºæ§æç¨éåäºæ°çå¯è½æ§ãå¾çºç ç©¶å°æ¢è¨éäºé¡äººå±¬æ§å¸¶ä¾çå«çææ¶µåæ½å¨åè¦ã

##### **A General Retrieval-Augmented Generation Framework for Multimodal Case-Based Reasoning Applications**
2501.05030v1 by Ofir Marom

Case-based reasoning (CBR) is an experience-based approach to problem
solving, where a repository of solved cases is adapted to solve new cases.
Recent research shows that Large Language Models (LLMs) with
Retrieval-Augmented Generation (RAG) can support the Retrieve and Reuse stages
of the CBR pipeline by retrieving similar cases and using them as additional
context to an LLM query. Most studies have focused on text-only applications,
however, in many real-world problems the components of a case are multimodal.
In this paper we present MCBR-RAG, a general RAG framework for multimodal CBR
applications. The MCBR-RAG framework converts non-text case components into
text-based representations, allowing it to: 1) learn application-specific
latent representations that can be indexed for retrieval, and 2) enrich the
query provided to the LLM by incorporating all case components for better
context. We demonstrate MCBR-RAG's effectiveness through experiments conducted
on a simplified Math-24 application and a more complex Backgammon application.
Our empirical results show that MCBR-RAG improves generation quality compared
to a baseline LLM with no contextual information provided.

æè¦ï¼åºæ¼æ¡ä¾çæ¨ç (CBR) æ¯ä¸ç¨®ä»¥ç¶é©çºåºç¤çåé¡è§£æ±ºæ¹æ³ï¼å¶ä¸­æèª¿æ´å·²è§£æ±ºæ¡ä¾çå²å­åº«ä¾è§£æ±ºæ°æ¡ä¾ãæè¿çç ç©¶é¡¯ç¤ºï¼å·åæª¢ç´¢å¢å¼·çæ (RAG) çå¤§åèªè¨æ¨¡å (LLM) å¯ä»¥ééæª¢ç´¢é¡ä¼¼æ¡ä¾ä¸¦å°å¶ç¨ä½ LLM æ¥è©¢çéå å§å®¹ï¼ä¾æ¯æ´ CBR ç®¡éçæª¢ç´¢åéè¤ä½¿ç¨éæ®µãå¤§å¤æ¸ç ç©¶é½å°æ³¨æ¼ç´æå­æç¨ç¨å¼ï¼ç¶èï¼å¨è¨±å¤å¯¦éåé¡ä¸­ï¼æ¡ä¾ççµææ¯å¤æ¨¡æçãå¨æ¬æä¸­ï¼æåæåº MCBR-RAGï¼ä¸åé©ç¨æ¼å¤æ¨¡æ CBR æç¨ç¨å¼çéç¨ RAG æ¡æ¶ãMCBR-RAG æ¡æ¶å°éæå­æ¡ä¾çµæè½æçºåºæ¼æå­çè¡¨ç¤ºï¼ä½¿å¶è½å¤ ï¼1) å­¸ç¿å¯ä¾æª¢ç´¢ç·¨è£½ç´¢å¼çæç¨ç¨å¼ç¹å®æ½å¨è¡¨ç¤ºï¼ä»¥å 2) ééç´å¥æææ¡ä¾çµæä¾è±å¯æä¾çµ¦ LLM çæ¥è©¢ï¼ä»¥ç²å¾æ´å¥½çå§å®¹ãæåééå¨ç°¡åç Math-24 æç¨ç¨å¼åæ´è¤éçè¥¿æ´éé¸æ£æç¨ç¨å¼ä¸é²è¡çå¯¦é©ï¼è­æäº MCBR-RAG çæææ§ãæåçå¯¦è­çµæé¡¯ç¤ºï¼èæ²ææä¾èæ¯è³è¨çåºæ¬ LLM ç¸æ¯ï¼MCBR-RAG æ¹åäºçæåè³ªã

##### **Finding Needles in Emb(a)dding Haystacks: Legal Document Retrieval via Bagging and SVR Ensembles**
2501.05018v1 by Kevin BÃ¶nisch, Alexander Mehler

We introduce a retrieval approach leveraging Support Vector Regression (SVR)
ensembles, bootstrap aggregation (bagging), and embedding spaces on the German
Dataset for Legal Information Retrieval (GerDaLIR). By conceptualizing the
retrieval task in terms of multiple binary needle-in-a-haystack subtasks, we
show improved recall over the baselines (0.849 > 0.803 | 0.829) using our
voting ensemble, suggesting promising initial results, without training or
fine-tuning any deep learning models. Our approach holds potential for further
enhancement, particularly through refining the encoding models and optimizing
hyperparameters.

æè¦ï¼æåå¼å¥äºä¸ç¨®æª¢ç´¢æ¹æ³ï¼å©ç¨æ¯æåéè¿´æ­¸ (SVR)
éæãbootstrap èå (bagging) åå¾·èªæ³å¾è³è¨æª¢ç´¢ (GerDaLIR) è³æéä¸çåµå¥ç©ºéãééå°
æª¢ç´¢ä»»åæ¦å¿µåçºå¤åäºåå¤§æµ·æéå­ä»»åï¼æå
ä½¿ç¨æåçæç¥¨éæï¼é¡¯ç¤ºåºæ¯åºç·æ´é«çå¬åç (0.849 > 0.803 | 0.829)ï¼éè¡¨ææå¸æçåæ­¥çµæï¼èç¡éè¨ç·´æ
å¾®èª¿ä»»ä½æ·±åº¦å­¸ç¿æ¨¡åãæåçåæ³æé²ä¸æ­¥å¢å¼·çæ½åï¼ç¹å¥æ¯ééèª¿æ´ç·¨ç¢¼æ¨¡ååæä½³å
è¶åæ¸ã

##### **UAV-VLA: Vision-Language-Action System for Large Scale Aerial Mission Generation**
2501.05014v1 by Oleg Sautenkov, Yasheerah Yaqoot, Artem Lykov, Muhammad Ahsan Mustafa, Grik Tadevosyan, Aibek Akhmetkazy, Miguel Altamirano Cabrera, Mikhail Martynov, Sausar Karaf, Dzmitry Tsetserukou

The UAV-VLA (Visual-Language-Action) system is a tool designed to facilitate
communication with aerial robots. By integrating satellite imagery processing
with the Visual Language Model (VLM) and the powerful capabilities of GPT,
UAV-VLA enables users to generate general flight paths-and-action plans through
simple text requests. This system leverages the rich contextual information
provided by satellite images, allowing for enhanced decision-making and mission
planning. The combination of visual analysis by VLM and natural language
processing by GPT can provide the user with the path-and-action set, making
aerial operations more efficient and accessible. The newly developed method
showed the difference in the length of the created trajectory in 22% and the
mean error in finding the objects of interest on a map in 34.22 m by Euclidean
distance in the K-Nearest Neighbors (KNN) approach.

æè¦ï¼ç¡äººæ©-VLAï¼è¦è¦ºèªè¨åä½ï¼ç³»çµ±æ¯ä¸åå·¥å·ï¼æ¨å¨ä¿é²èç©ºä¸­æ©å¨äººçæºéãééå°è¡æååèçèè¦è¦ºèªè¨æ¨¡å (VLM) å GPT çå¼·å¤§åè½æ´åå¨ä¸èµ·ï¼ç¡äººæ©-VLA ä½¿ç¨æ¶è½å¤ ééç°¡å®çæå­è«æ±çæéç¨çé£è¡è·¯å¾åè¡åè¨ç«ãæ­¤ç³»çµ±å©ç¨è¡æååæä¾çè±å¯èæ¯è³è¨ï¼å¾èå¢å¼·æ±ºç­å¶å®åä»»åè¦åãVLM çè¦è¦ºåæå GPT çèªç¶èªè¨èçç¸çµåï¼å¯ä»¥çºä½¿ç¨èæä¾è·¯å¾ååä½éï¼ä½¿ç©ºä¸­ä½æ¥­æ´ææçä¸æ´å®¹æä½¿ç¨ãæ°éç¼çæ¹æ³é¡¯ç¤ºåºå¨ 22% ä¸­å»ºç«è»è·¡çé·åº¦å·®ç°ï¼ä»¥åå¨ K æè¿é° (KNN) æ¹æ³ä¸­ï¼ééæ­å¹¾éå¾è·é¢å¨ 34.22 å¬å°ºä¸­æ¾å°å°åä¸æèè¶£ç©é«çå¹³åèª¤å·®ã

##### **Quantum-enhanced causal discovery for a small number of samples**
2501.05007v1 by Yota Maeda, Ken Arai, Yu Tanaka, Yu Terada, Hiroshi Ueno, Hiroyuki Tezuka

The discovery of causal relationships from observed data has attracted
significant interest from disciplines such as economics, social sciences,
epidemiology, and biology. In practical applications, considerable knowledge of
the underlying systems is often unavailable, and real data are often associated
with nonlinear causal structures, which make the direct use of most
conventional causality analysis methods difficult. This study proposes a novel
quantum Peter-Clark (qPC) algorithm for causal discovery that does not assume
any underlying model structures. Based on the independence conditional tests in
a class of reproducing kernel Hilbert spaces characterized by quantum circuits,
the proposed qPC algorithm can explore causal relationships from the observed
data drawn from arbitrary distributions. We conducted systematic experiments on
fundamental graph parts of causal structures, demonstrating that the qPC
algorithm exhibits a significantly better performance, particularly with
smaller sample sizes compared to its classical counterpart. Furthermore, we
proposed a novel optimization approach based on Kernel Target Alignment (KTA)
for determining hyperparameters of quantum kernels. This method effectively
reduced the risk of false positives in causal discovery, enabling more reliable
inference. Our theoretical and experimental results demonstrate that the
proposed quantum algorithm can empower classical algorithms for robust and
accurate inference in causal discovery, supporting them in regimes where
classical algorithms typically fail. Additionally, the effectiveness of this
method was validated using the Boston Housing dataset as a real-world
application. These findings demonstrate the new potential of quantum
circuit-based causal discovery methods in addressing practical challenges,
particularly in small-sample scenarios where traditional approaches have shown
limitations.

æè¦ï¼<paragraph>å¾è§å¯å°çè³æä¸­ç¼ç¾å æéä¿ï¼å·²å¼èµ·ç¶æ¿å­¸ãç¤¾æç§å­¸ãæµè¡çå­¸åçç©å­¸ç­é åçæ¥µå¤§èè¶£ãå¨å¯¦éæç¨ä¸­ï¼éå¸¸ç¡æ³ç²å¾å°åºç¤ç³»çµ±çååäºè§£ï¼èçå¯¦è³æéå¸¸èéç·æ§å æçµæ§ç¸éï¼éä½¿å¾ç´æ¥ä½¿ç¨å¤§å¤æ¸å³çµ±å æéä¿åææ¹æ³è®å¾å°é£ãæ¬ç ç©¶æåºäºä¸ç¨®æ°ç©çéå­ Peter-Clark (qPC) æ¼ç®æ³ï¼ç¨æ¼å æç¼ç¾ï¼ä¸åè¨­ä»»ä½åºç¤æ¨¡åçµæ§ãåºæ¼éå­é»è·¯è¡¨å¾µçä¸é¡åçæ ¸å¸ç¾ä¼¯ç¹ç©ºéä¸­çç¨ç«æ¢ä»¶æ¸¬è©¦ï¼æåºç qPC æ¼ç®æ³å¯ä»¥å¾ä»»æåä½ä¸­æåçè§å¯è³æä¸­æ¢ç´¢å æéä¿ãæåå°å æçµæ§çåºæ¬åå½¢é¨åé²è¡äºç³»çµ±å¯¦é©ï¼è­æ qPC æ¼ç®æ³è¡¨ç¾åºé¡¯èæ´å¥½çæè½ï¼ç¹å¥æ¯å¨èå¶ç¶å¸å°æç©ç¸æ¯ï¼æ¨£æ¬éè¼å°çææ³ä¸ãæ­¤å¤ï¼æåæåºäºä¸ç¨®åºæ¼æ ¸ç®æ¨å°é½ (KTA) çæ°ç©æä½³åæ¹æ³ï¼ç¨æ¼ç¢ºå®éå­æ ¸çè¶åæ¸ãæ­¤æ¹æ³ææéä½äºå æç¼ç¾ä¸­åé½æ§çé¢¨éªï¼å¯¦ç¾äºæ´å¯é çæ¨è«ãæåççè«åå¯¦é©çµæè¡¨æï¼ææåºçéå­æ¼ç®æ³å¯ä»¥å¢å¼·ç¶å¸æ¼ç®æ³å¨å æç¼ç¾ä¸­ç©©å¥ä¸æºç¢ºçæ¨è«ï¼å¨ç¶å¸æ¼ç®æ³éå¸¸æå¤±æççæä¸çºå¶æä¾æ¯æ´ãæ­¤å¤ï¼ä½¿ç¨æ³¢å£«é ä½æ¿è³æéä½çºçå¯¦ä¸ççæç¨ï¼é©è­äºæ­¤æ¹æ³çæææ§ãéäºç¼ç¾å±ç¤ºäºåºæ¼éå­é»è·¯çå æç¼ç¾æ¹æ³å¨æå°å¯¦éææ°æ¹é¢çæ°æ½åï¼ç¹å¥æ¯å¨å³çµ±æ¹æ³å·²é¡¯ç¤ºåºéå¶çå°æ¨£æ¬å ´æ¯ä¸­ã</paragraph>

##### **GiNet: Integrating Sequential and Context-Aware Learning for Battery Capacity Prediction**
2501.04997v1 by Sara Sameer, Wei Zhang, Xin Lou, Qingyu Yan, Terence Goh, Yulin Gao

The surging demand for batteries requires advanced battery management
systems, where battery capacity modelling is a key functionality. In this
paper, we aim to achieve accurate battery capacity prediction by learning from
historical measurements of battery dynamics. We propose GiNet, a gated
recurrent units enhanced Informer network, for predicting battery's capacity.
The novelty and competitiveness of GiNet lies in its capability of capturing
sequential and contextual information from raw battery data and reflecting the
battery's complex behaviors with both temporal dynamics and long-term
dependencies. We conducted an experimental study based on a publicly available
dataset to showcase GiNet's strength of gaining a holistic understanding of
battery behavior and predicting battery capacity accurately. GiNet achieves
0.11 mean absolute error for predicting the battery capacity in a sequence of
future time slots without knowing the historical battery capacity. It also
outperforms the latest algorithms significantly with 27% error reduction on
average compared to Informer. The promising results highlight the importance of
customized and optimized integration of algorithm and battery knowledge and
shed light on other industry applications as well.

æè¦ï¼é»æ± éæ±æ¿å¢éè¦é²éé»æ± ç®¡çç³»çµ±ï¼å¶ä¸­é»æ± å®¹éå»ºæ¨¡æ¯ä¸é ééµåè½ãå¨æ¬æä¸­ï¼æåæ¨å¨ééå­¸ç¿é»æ± åæçæ­·å²æ¸¬éå¼ä¾å¯¦ç¾æºç¢ºçé»æ± å®¹éé æ¸¬ãæåæåº GiNetï¼ä¸åéæ§éè¿´å®åå¢å¼·ç Informer ç¶²è·¯ï¼ç¨æ¼é æ¸¬é»æ± å®¹éãGiNet çæ°ç©æ§åç«¶ç­åå¨æ¼å®è½å¤ å¾åå§é»æ± è³æä¸­æ·åé åºåèæ¯è³è¨ï¼ä¸¦åæ é»æ± çè¤éè¡çºï¼åæå·ææéåæåé·æä¾è³´æ§ãæåæ ¹æå¬éå¯ç¨çè³æéé²è¡äºä¸é å¯¦é©ç ç©¶ï¼ä»¥å±ç¤º GiNet å¨å¨é¢äºè§£é»æ± è¡çºåæºç¢ºé æ¸¬é»æ± å®¹éæ¹é¢çåªå¢ãGiNet å¨ä¸ç¥éæ­·å²é»æ± å®¹éçææ³ä¸ï¼å°æ¼é æ¸¬æªä¾ææ®µåºåä¸­çé»æ± å®¹éï¼å¹³åçµå°èª¤å·®çº 0.11ãè Informer ç¸æ¯ï¼å®ä¹å¤§å¹åªæ¼ææ°çæ¼ç®æ³ï¼å¹³åé¯èª¤æ¸å° 27%ãéäºæå¸æççµæçªé¡¯äºæ¼ç®æ³åé»æ± ç¥è­çå®¢è£½ååæä½³åæ´åçéè¦æ§ï¼ä¸¦ä¹çºå¶ä»ç¢æ¥­æç¨æä¾äºåç¤ºã

##### **IPDN: Image-enhanced Prompt Decoding Network for 3D Referring Expression Segmentation**
2501.04995v1 by Qi Chen, Changli Wu, Jiayi Ji, Yiwei Ma, Danni Yang, Xiaoshuai Sun

3D Referring Expression Segmentation (3D-RES) aims to segment point cloud
scenes based on a given expression. However, existing 3D-RES approaches face
two major challenges: feature ambiguity and intent ambiguity. Feature ambiguity
arises from information loss or distortion during point cloud acquisition due
to limitations such as lighting and viewpoint. Intent ambiguity refers to the
model's equal treatment of all queries during the decoding process, lacking
top-down task-specific guidance. In this paper, we introduce an Image enhanced
Prompt Decoding Network (IPDN), which leverages multi-view images and
task-driven information to enhance the model's reasoning capabilities. To
address feature ambiguity, we propose the Multi-view Semantic Embedding (MSE)
module, which injects multi-view 2D image information into the 3D scene and
compensates for potential spatial information loss. To tackle intent ambiguity,
we designed a Prompt-Aware Decoder (PAD) that guides the decoding process by
deriving task-driven signals from the interaction between the expression and
visual features. Comprehensive experiments demonstrate that IPDN outperforms
the state-ofthe-art by 1.9 and 4.2 points in mIoU metrics on the 3D-RES and
3D-GRES tasks, respectively.

æè¦ï¼3D åèè¡¨éåå² (3D-RES) æ¨å¨æ ¹æçµ¦å®çè¡¨éå¼å°é»é²å ´æ¯é²è¡åå²ãç¶èï¼ç¾æç 3D-RES æ¹æ³é¢è¨å©å¤§ææ°ï¼ç¹å¾µæ¨¡ç³åæåæ¨¡ç³ãç¹å¾µæ¨¡ç³æ¯ç±æ¼é»é²æ¡ééç¨ä¸­ç±æ¼ç§æåè¦é»ç­éå¶èå°è´çä¿¡æ¯ä¸å¤±æå¤±çãæåæ¨¡ç³æ¯ææ¨¡åå¨è§£ç¢¼éç¨ä¸­å°æææ¥è©¢é²è¡å¹³ç­èçï¼ç¼ºä¹èªä¸èä¸çä»»åç¹å®æå°ãå¨æ¬æä¸­ï¼æåå¼å¥äºä¸åååå¢å¼·æç¤ºè§£ç¢¼ç¶²çµ¡ (IPDN)ï¼å®å©ç¨å¤è¦ååååä»»åé©åä¿¡æ¯ä¾å¢å¼·æ¨¡åçæ¨çè½åãçºäºè§£æ±ºç¹å¾µæ¨¡ç³çåé¡ï¼æåæåºäºå¤è¦åèªç¾©åµå¥ (MSE) æ¨¡å¡ï¼å®å°å¤è¦å 2D ååä¿¡æ¯æ³¨å¥å° 3D å ´æ¯ä¸­ï¼ä¸¦å½è£äºæ½å¨çç©ºéä¿¡æ¯ä¸å¤±ãçºäºè§£æ±ºæåæ¨¡ç³çåé¡ï¼æåè¨­è¨äºä¸åæç¤ºæç¥è§£ç¢¼å¨ (PAD)ï¼å®ééå¾è¡¨éå¼åè¦è¦ºç¹å¾µä¹éçäº¤äºä¸­æ¨å°åºä»»åé©åä¿¡èä¾æå°è§£ç¢¼éç¨ãç¶åå¯¦é©è¡¨æï¼IPDN å¨ 3D-RES å 3D-GRES ä»»åç mIoU ææ¨ä¸åå¥æ¯æåé²çæè¡é«åº 1.9 å 4.2 åé»ã

##### **TreeKV: Smooth Key-Value Cache Compression with Tree Structures**
2501.04987v1 by Ziwei He, Jian Yuan, Haoli Bai, Jingwen Leng, Bo Jiang

Efficient key-value (KV) cache compression is critical for scaling
transformer-based Large Language Models (LLMs) in long sequences and
resource-limited settings. Existing methods evict tokens based on their
positions or importance scores, but position-based strategies can miss crucial
information outside predefined regions, while those relying on global
importance scores resulting in strong regional biases, limiting the KV cache's
overall context retention and potentially impairing the performance of LLMs on
complex tasks. Our wavelet analysis reveals that as tokens approach the end of
sequence, their contributions to generation gradually increase and tends to
diverge more from neighboring tokens, indicating a smooth transition with
increasing complexity and variability from distant to nearby context. Motivated
by this observation, we propose TreeKV, an intuitive, training-free method that
employs a tree structure for smooth cache compression. TreeKV maintains a fixed
cache size, allowing LLMs to deliver high-quality output even in long text
scenarios. Unlike most compression methods, TreeKV is applicable to both the
generation and prefilling stages. It consistently surpasses all baseline models
in language modeling tasks on PG19 and OpenWebText2, allowing LLMs trained with
short context window to generalize to longer window with a 16x cache reduction.
On the Longbench benchmark, TreeKV achieves the best performance with only 6\%
of the budget at optimal efficiency.

æè¦ï¼é«æçéµå¼ (KV) å¿«åå£ç¸®å°æ¼ç¸®æ¾å¤§åèªè¨æ¨¡å (LLM) ä¸­çTransformerå¨é·åºååè³æºåéçè¨­å®ä¸­è³ééè¦ãç¾ææ¹æ³åºæ¼å®åçä½ç½®æéè¦æ§åæ¸é©éç¬¦èï¼ä½åºæ¼ä½ç½®çç­ç¥å¯è½æé¯å¤±é å®ç¾©ååå¤çééµè³è¨ï¼èä¾è³´æ¼å¨çéè¦æ§åæ¸çç­ç¥åæå°è´å¼·ççåååèª¤ï¼éå¶ KV å¿«åçæ´é«å§å®¹ä¿çï¼ä¸¦å¯è½æå®³ LLM å¨è¤éä»»åä¸çæè½ãæåçæ³¢æ®µåæé¡¯ç¤ºï¼ç¶ç¬¦èæ¥è¿åºåçå°¾ç«¯æï¼å®åå°çæçè²¢ç»æéæ¼¸å¢å ï¼ä¸¦ä¸å¾åæ¼èé°è¿ç¬¦èææ´å¤å·®ç°ï¼éè¡¨ç¤ºå¾é èå°éè¿çå§å®¹å·æå¹³ç©©çè½æï¼ä¸è¤éæ§åå¯è®æ§å¢å ãåå°æ­¤è§å¯çåç¼ï¼æåæåº TreeKVï¼éæ¯ä¸ç¨®ç´è¦ºä¸ç¡éè¨ç·´çæ¹æ³ï¼å®æ¡ç¨æ¨¹ççµæ§é²è¡å¹³ç©©çå¿«åå£ç¸®ãTreeKV ç¶­è­·åºå®çå¿«åå¤§å°ï¼è® LLM å³ä½¿å¨é·æå­å ´æ¯ä¸­ä¹è½æä¾é«åè³ªçè¼¸åºãèå¤§å¤æ¸å£ç¸®æ¹æ³ä¸åï¼TreeKV å¯æç¨æ¼çæåé åå¡«å¥éæ®µãå®å¨ PG19 å OpenWebText2 ä¸çèªè¨å»ºæ¨¡ä»»åä¸­æçºè¶è¶ææåºæºæ¨¡åï¼è®ä½¿ç¨ç­å§å®¹è¦çªè¨ç·´ç LLM è½å¤ æ¦æ¬çºè¼é·çè¦çªï¼å¿«åæ¸å° 16 åãå¨ Longbench åºæºæ¸¬è©¦ä¸­ï¼TreeKV ä»¥æä½³æçå 6% çé ç®éææä½³æè½ã

##### **CuRLA: Curriculum Learning Based Deep Reinforcement Learning for Autonomous Driving**
2501.04982v1 by Bhargava Uppuluri, Anjel Patel, Neil Mehta, Sridhar Kamath, Pratyush Chakraborty

In autonomous driving, traditional Computer Vision (CV) agents often struggle
in unfamiliar situations due to biases in the training data. Deep Reinforcement
Learning (DRL) agents address this by learning from experience and maximizing
rewards, which helps them adapt to dynamic environments. However, ensuring
their generalization remains challenging, especially with static training
environments. Additionally, DRL models lack transparency, making it difficult
to guarantee safety in all scenarios, particularly those not seen during
training. To tackle these issues, we propose a method that combines DRL with
Curriculum Learning for autonomous driving. Our approach uses a Proximal Policy
Optimization (PPO) agent and a Variational Autoencoder (VAE) to learn safe
driving in the CARLA simulator. The agent is trained using two-fold curriculum
learning, progressively increasing environment difficulty and incorporating a
collision penalty in the reward function to promote safety. This method
improves the agent's adaptability and reliability in complex environments, and
understand the nuances of balancing multiple reward components from different
feedback signals in a single scalar reward function. Keywords: Computer Vision,
Deep Reinforcement Learning, Variational Autoencoder, Proximal Policy
Optimization, Curriculum Learning, Autonomous Driving.

æè¦ï¼å¨èªåé§é§ä¸­ï¼å³çµ±çé»è¦è¦è¦º (CV) ä»£çå¨è¨ç·´è³æçåå·®ä¸ï¼ç¶å¸¸å¨ä¸çæçç°å¢ä¸­ææãæ·±åº¦å¼·åå­¸ç¿ (DRL) ä»£çééå¾ç¶é©ä¸­å­¸ç¿åæå¤§åçåµä¾è§£æ±ºéååé¡ï¼éæå©æ¼å®åé©æåæç°å¢ãç¶èï¼ç¢ºä¿å®åçæ³åä»ç¶å·æææ°æ§ï¼ç¹å¥æ¯å¨éæè¨ç·´ç°å¢ä¸­ãæ­¤å¤ï¼DRL æ¨¡åç¼ºä¹éæåº¦ï¼éä½¿å¾é£ä»¥ä¿è­å¨ææå ´æ¯ä¸­çå®å¨æ§ï¼ç¹å¥æ¯å¨è¨ç·´éç¨ä¸­æ²æè¦éçå ´æ¯ãçºäºè§£æ±ºéäºåé¡ï¼æåæåºäºä¸ç¨®å° DRL èèª²ç¨å­¸ç¿ç¸çµåçæ¹æ³ï¼ç¨æ¼èªåé§é§ãæåçåæ³ä½¿ç¨è¿ç«¯ç­ç¥åªå (PPO) ä»£çåè®åèªåç·¨ç¢¼å¨ (VAE) ä¾å­¸ç¿å¨ CARLA æ¨¡æ¬å¨ä¸­å®å¨é§é§ãè©²ä»£çä½¿ç¨å©åèª²ç¨å­¸ç¿é²è¡è¨ç·´ï¼éæ­¥å¢å ç°å¢é£åº¦ï¼ä¸¦å¨çåµå½æ¸ä¸­å å¥ç¢°ææ²ç½°ä»¥ä¿é²å®å¨æ§ãéç¨®æ¹æ³æé«äºä»£çå¨è¤éç°å¢ä¸­çé©ææ§åå¯é æ§ï¼ä¸¦ä¸äºè§£äºå¨å®åæ¨éçåµå½æ¸ä¸­å¹³è¡¡ä¾èªä¸ååé¥ä¿¡èç multiple reward çµä»¶çç´°å¾®å·®å¥ãééµå­ï¼é»è¦è¦è¦ºãæ·±åº¦å¼·åå­¸ç¿ãè®åèªåç·¨ç¢¼å¨ãè¿ç«¯ç­ç¥åªåãèª²ç¨å­¸ç¿ãèªåé§é§ã

##### **SensorQA: A Question Answering Benchmark for Daily-Life Monitoring**
2501.04974v1 by Benjamin Reichman, Xiaofan Yu, Lanxiang Hu, Jack Truxal, Atishay Jain, Rushil Chandrupatla, Tajana Å imuniÄ Rosing, Larry Heck

With the rapid growth in sensor data, effectively interpreting and
interfacing with these data in a human-understandable way has become crucial.
While existing research primarily focuses on learning classification models,
fewer studies have explored how end users can actively extract useful insights
from sensor data, often hindered by the lack of a proper dataset. To address
this gap, we introduce \Dataset, the first human-created question-answering
(QA) dataset for long-term time-series sensor data for daily life monitoring.
\Dataset is created by human workers and includes 5.6K diverse and practical
queries that reflect genuine human interests, paired with accurate answers
derived from sensor data. We further establish benchmarks for state-of-the-art
AI models on this dataset and evaluate their performance on typical edge
devices. Our results reveal a gap between current models and optimal QA
performance and efficiency, highlighting the need for new contributions. The
dataset and code are available at:
\url{https://github.com/benjamin-reichman/SensorQA}.

æè¦ï¼é¨èææ¸¬å¨è³æå¿«éæé·ï¼ä»¥äººé¡å¯çè§£çæ¹å¼ææè§£è®åä»æ¥éäºè³æå·²è®å¾è³ééè¦ãéç¶ç¾æç ç©¶ä¸»è¦å°æ³¨æ¼å­¸ç¿åé¡æ¨¡åï¼ä½è¼å°ç ç©¶æ¢è¨æçµä½¿ç¨èå¦ä½è½ä¸»åå¾ææ¸¬å¨è³æä¸­æåæç¨çè¦è§£ï¼ééå¸¸åå°ç¼ºä¹é©ç¶è³æéçé»ç¤ãçºäºè§£æ±ºéåå·®è·ï¼æåå¼å¥äº \Datasetï¼éæ¯ç¬¬ä¸åç±äººé¡å»ºç«çé·ææéåºåææ¸¬å¨è³æåç­ (QA) è³æéï¼ç¨æ¼æ¥å¸¸çæ´»ç£æ§ã\Dataset æ¯ç±äººé¡å·¥ä½èå»ºç«çï¼åå« 5.6K ååæ çå¯¦äººé¡èè¶£çå¤åä¸å¯¦ç¨çæ¥è©¢ï¼ä¸¦éå°å¾ææ¸¬å¨è³æè¡ççæºç¢ºç­æ¡ãæåé²ä¸æ­¥çºéåè³æéå»ºç«äºæåé² AI æ¨¡åçåºæºï¼ä¸¦è©ä¼°å®åå¨å¸åéç·£è£ç½®ä¸çæè½ãæåççµææ­é²äºç¶åæ¨¡åèæä½³ QA æè½åæçä¹éçå·®è·ï¼çªé¡¯äºå°æ°è²¢ç»çéæ±ãè³æéåç¨å¼ç¢¼å¯å¨ä»¥ä¸ä½ç½®åå¾ï¼\url{https://github.com/benjamin-reichman/SensorQA}ã

##### **Battling the Non-stationarity in Time Series Forecasting via Test-time Adaptation**
2501.04970v1 by HyunGi Kim, Siwon Kim, Jisoo Mok, Sungroh Yoon

Deep Neural Networks have spearheaded remarkable advancements in time series
forecasting (TSF), one of the major tasks in time series modeling. Nonetheless,
the non-stationarity of time series undermines the reliability of pre-trained
source time series forecasters in mission-critical deployment settings. In this
study, we introduce a pioneering test-time adaptation framework tailored for
TSF (TSF-TTA). TAFAS, the proposed approach to TSF-TTA, flexibly adapts source
forecasters to continuously shifting test distributions while preserving the
core semantic information learned during pre-training. The novel utilization of
partially-observed ground truth and gated calibration module enables proactive,
robust, and model-agnostic adaptation of source forecasters. Experiments on
diverse benchmark datasets and cutting-edge architectures demonstrate the
efficacy and generality of TAFAS, especially in long-term forecasting scenarios
that suffer from significant distribution shifts. The code is available at
https://github.com/kimanki/TAFAS.

æè¦ï¼æ·±åº¦ç¥ç»ç½ç»å¼é¢äºæ¶é´åºåé¢æµ (TSF) çæ¾çè¿æ­¥ï¼æ¶é´åºåå»ºæ¨¡ä¸­çä¸»è¦ä»»å¡ä¹ä¸ãå°½ç®¡å¦æ­¤ï¼æ¶é´åºåçéå¹³ç¨³æ§ä¼ç ´åé¢è®­ç»æºæ¶é´åºåé¢æµå¨å¨ä»»å¡å³é®é¨ç½²è®¾ç½®ä¸­çå¯é æ§ãå¨è¿é¡¹ç ç©¶ä¸­ï¼æä»¬å¼å¥äºä¸ä¸ªéå¯¹ TSFï¼TSF-TTAï¼éèº«å®å¶çå¼åæ§æµè¯æ¶é´èªéåºæ¡æ¶ãTAFAS æ¯éå¯¹ TSF-TTA çæè®®æ¹æ³ï¼å®çµæ´»å°è°æ´æºé¢æµå¨ä»¥æç»­è½¬ç§»æµè¯åå¸ï¼åæ¶ä¿çé¢è®­ç»æé´å­¦ä¹ çæ ¸å¿è¯­ä¹ä¿¡æ¯ãé¨åè§å¯å°çåºæ¬äºå®åé¨æ§æ ¡åæ¨¡åçæ°é¢å©ç¨ä½¿å¾æºé¢æµå¨çä¸»å¨ãç¨³å¥åä¸æ¨¡åæ å³çèªéåºæä¸ºå¯è½ãå¨åç§åºåæ°æ®éååæ²¿æ¶æä¸çå®éªè¡¨æäº TAFAS çæææ§åæ®éæ§ï¼å°¤å¶æ¯å¨é­åæ¾çåå¸ååçé¿ââæé¢æµåºæ¯ä¸­ãä»£ç å¯å¨ https://github.com/kimanki/TAFAS è·å¾ã

##### **VoxEval: Benchmarking the Knowledge Understanding Capabilities of End-to-End Spoken Language Models**
2501.04962v1 by Wenqian Cui, Xiaoqi Jiao, Ziqiao Meng, Irwin King

With the growing demand for developing speech-based interaction models,
end-to-end Spoken Language Models (SLMs) have emerged as a promising solution.
When engaging in conversations with humans, it is essential for these models to
comprehend a wide range of world knowledge. In this paper, we introduce
VoxEval, a novel speech question-answering benchmark specifically designed to
assess SLMs' knowledge understanding through purely speech-based interactions.
Unlike existing AudioQA benchmarks, VoxEval maintains speech format for both
questions and answers, evaluates model robustness across diverse audio
conditions (varying timbres, audio qualities, and speaking styles), and
pioneers the assessment of challenging domains like mathematical
problem-solving in spoken format. Our comprehensive evaluation of recent SLMs
using VoxEval reveals significant performance limitations in current models,
highlighting crucial areas for future improvements.

æè¦ï¼é¨èå°éç¼åºæ¼èªé³çäºåæ¨¡å¼éæ±æ¥çå¢é·ï¼ç«¯å°ç«¯çå£èªèªè¨æ¨¡å (SLM) å·²æçºä¸ç¨®æåéçè§£æ±ºæ¹æ¡ãå¨èäººé¡å°è©±æï¼éäºæ¨¡åå¿é çè§£å»£æ³çä¸çç¥è­ãå¨æ¬æä¸­ï¼æåä»ç´¹ VoxEvalï¼éæ¯ä¸åæ°ç©çèªé³åç­åºæºï¼å°éè¨­è¨ç¨æ¼ééç´ç²¹åºæ¼èªé³çäºåä¾è©ä¼° SLM çç¥è­çè§£ãèç¾æç AudioQA åºæºä¸åï¼VoxEval ç¶­æäºåé¡åç­æ¡çèªé³æ ¼å¼ï¼è©ä¼°äºæ¨¡åå¨ä¸åé³è¨æ¢ä»¶ï¼ä¸åçé³è²ãé³è¨åè³ªåèªªè©±é¢¨æ ¼ï¼ä¸çç©©å¥æ§ï¼ä¸¦çåè©ä¼°äºä»¥å£èªæ ¼å¼é²è¡æ¸å­¸åé¡è§£æ±ºç­å·æææ°æ§çé åãæåä½¿ç¨ VoxEval å°æè¿ç SLM é²è¡ç¶åè©ä¼°ï¼æ­ç¤ºäºç¶åæ¨¡åå¨æè½ä¸çé¡¯èéå¶ï¼å¼·èª¿äºæªä¾æ¹é²çéè¦é åã

##### **Demystifying Domain-adaptive Post-training for Financial LLMs**
2501.04961v1 by Zixuan Ke, Yifei Ming, Xuan-Phi Nguyen, Caiming Xiong, Shafiq Joty

Domain-adaptive post-training of large language models (LLMs) has emerged as
a promising approach for specialized domains such as medicine and finance.
However, significant challenges remain in identifying optimal adaptation
criteria and training strategies across varying data and model configurations.
To address these challenges, we introduce FINDAP, a systematic and fine-grained
investigation into domain-adaptive post-training of LLMs for the finance
domain. Our approach begins by identifying the core capabilities required for
the target domain and designing a comprehensive evaluation suite aligned with
these needs. We then analyze the effectiveness of key post-training stages,
including continual pretraining, instruction tuning, and preference alignment.
Building on these insights, we propose an effective training recipe centered on
a novel preference data distillation method, which leverages process signals
from a generative reward model. The resulting model, Llama-Fin, achieves
state-of-the-art performance across a wide range of financial tasks. Our
analysis also highlights how each post-training stage contributes to distinct
capabilities, uncovering specific challenges and effective solutions, providing
valuable insights for domain adaptation of LLMs. Project page:
https://github.com/SalesforceAIResearch/FinDap

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) çé åé©æå¾è¨ç·´å·²æçºé«å­¸åéèç­å°æ¥­é åä¸­ä¸ç¨®æåéçæ¹æ³ã
ç¶èï¼å¨ç¢ºå®æä½³é©ææ¨æºåè·¨ä¸åæ¸æåæ¨¡åéç½®çè¨ç·´ç­ç¥æ¹é¢ï¼ä»ç¶å­å¨éå¤§ææ°ã
çºäºæå°éäºææ°ï¼æåå¼å¥äº FINDAPï¼éæ¯ä¸ç¨®å° LLM çéèé åé©æå¾è¨ç·´é²è¡ç³»çµ±ä¸ç´°ç·»çèª¿æ¥ãæåçåæ³é¦åæ¯ç¢ºå®ç®æ¨é åæéçæ ¸å¿è½åï¼ä¸¦è¨­è¨ä¸åèéäºéæ±ç¸ä¸è´çç¶åè©ä¼°å¥ä»¶ãç¶å¾ï¼æååæééµå¾è¨ç·´éæ®µçæææ§ï¼åæ¬æçºé è¨ç·´ãæä»¤å¾®èª¿ååå¥½å°é½ãæ ¹æéäºè¦è§£ï¼æåæåºäºä¸åä»¥æ°ç©çåå¥½æ¸æè¸é¤¾æ¹æ³çºä¸­å¿çææè¨ç·´éæ¹ï¼è©²æ¹æ³å©ç¨çæçåµæ¨¡åä¸­çéç¨ä¿¡èãç±æ­¤ç¢ççæ¨¡å Llama-Fin å¨å»£æ³çéèä»»åä¸­å¯¦ç¾äºæåé²çæ§è½ãæåçåæéå¼·èª¿äºæ¯åå¾è¨ç·´éæ®µå¦ä½ä¿æä¸åçè½åï¼æ­ç¤ºå·é«çææ°åææçè§£æ±ºæ¹æ¡ï¼çº LLM çé åé©ææä¾äºæå¹å¼çè¦è§£ãå°æ¡é é¢ï¼
https://github.com/SalesforceAIResearch/FinDap

##### **Addressing Domain Shift via Imbalance-Aware Domain Adaptation in Embryo Development Assessment**
2501.04958v1 by Lei Li, Xinglin Zhang, Jun Liang, Tao Chen

Deep learning models in medical imaging face dual challenges: domain shift,
where models perform poorly when deployed in settings different from their
training environment, and class imbalance, where certain disease conditions are
naturally underrepresented. We present Imbalance-Aware Domain Adaptation
(IADA), a novel framework that simultaneously tackles both challenges through
three key components: (1) adaptive feature learning with class-specific
attention mechanisms, (2) balanced domain alignment with dynamic weighting, and
(3) adaptive threshold optimization. Our theoretical analysis establishes
convergence guarantees and complexity bounds. Through extensive experiments on
embryo development assessment across four imaging modalities, IADA demonstrates
significant improvements over existing methods, achieving up to 25.19\% higher
accuracy while maintaining balanced performance across classes. In challenging
scenarios with low-quality imaging systems, IADA shows robust generalization
with AUC improvements of up to 12.56\%. These results demonstrate IADA's
potential for developing reliable and equitable medical imaging systems for
diverse clinical settings. The code is made public available at
\url{https://github.com/yinghemedical/imbalance-aware_domain_adaptation}

æè¦ï¼<paragraph>é«çå½±åä¸­çæ·±åº¦å­¸ç¿æ¨¡åé¢è¨ééææ°ï¼é åè½ç§»ï¼æ¨¡åå¨èå¶è¨ç·´ç°å¢ä¸åçè¨­å®ä¸­é¨ç½²æè¡¨ç¾ä¸ä½³ï¼ä»¥åé¡å¥ä¸å¹³è¡¡ï¼æäºç¾ççæ³å¨èªç¶çä¸­ä»£è¡¨æ§ä¸è¶³ãæåæåºä¸å¹³è¡¡æç¥åé©æ (IADA)ï¼éæ¯ä¸åæ°ç©çæ¡æ¶ï¼ééä¸åééµçµæé¨ååææå°éå©åææ°ï¼(1) å·æé¡å¥ç¹å®æ³¨æåæ©å¶çèªé©æç¹å¾µå­¸ç¿ï¼(2) å·æåæå æ¬çå¹³è¡¡åå°é½ï¼ä»¥å (3) èªé©æé¾å¼æä½³åãæåççè«åæå»ºç«äºæ¶æä¿è­åè¤éåº¦çéãééå°åç¨®å½±åæ¨¡å¼çèèç¼è²è©ä¼°é²è¡å»£æ³çå¯¦é©ï¼IADA è­æäºå°ç¾ææ¹æ³çé¡¯èæ¹é²ï¼å¨ç¶­æé¡å¥éå¹³è¡¡æ§è½çåæï¼æºç¢ºåº¦æé«äº 25.19%ãå¨ä½åè³ªå½±åç³»çµ±çææ°æ§å ´æ¯ä¸­ï¼IADA ä»¥é«é 12.56% ç AUC æ¹é²é¡¯ç¤ºåºå¼·å¤§çæ³åè½åãéäºçµæè­æäº IADA å¨çºä¸åçè¨åºè¨­å®éç¼å¯é ä¸å¬å¹³çé«çå½±åç³»çµ±æ¹é¢çæ½åãç¨å¼ç¢¼å·²å¬éæ¼ \url{https://github.com/yinghemedical/imbalance-aware_domain_adaptation}</paragraph>

##### **Step-by-Step Mastery: Enhancing Soft Constraint Following Ability of Large Language Models**
2501.04945v1 by Qingyu Ren, Jie Zeng, Qianyu He, Jiaqing Liang, Yanghua Xiao, Weikang Zhou, Zeye Sun, Fei Yu

It is crucial for large language models (LLMs) to follow instructions that
involve multiple constraints. However, soft constraints are semantically
related and difficult to verify through automated methods. These constraints
remain a significant challenge for LLMs. To enhance the ability of LLMs to
follow soft constraints, we initially design a pipeline to obtain high-quality
outputs automatically. Additionally, to fully utilize the acquired data, we
introduce a training paradigm based on curriculum learning. We experimentally
evaluate the effectiveness of our methods in improving LLMs' soft constraint
following ability and analyze the factors driving the improvements. The
datasets and code are publicly available at
https://github.com/Rainier-rq/FollowSoftConstraints.

æè¦ï¼å°æ¼å¤§åèªè¨æ¨¡å (LLM) ä¾èªªï¼éµå¾ªåå«å¤éç´æçæä»¤è³ééè¦ãç¶èï¼è»ç´æå¨èªç¾©ä¸ç¸éï¼ä¸é£ä»¥ééèªååæ¹æ³é©è­ãéäºç´æå°æ¼ LLM ä¾èªªä»ç¶æ¯ä¸é éå¤§ææ°ãçºäºå¢å¼· LLM éµå¾ªè»ç´æçè½åï¼æåæåè¨­è¨äºä¸åç®¡éä»¥èªååå¾é«åè³ªçè¼¸åºãæ­¤å¤ï¼çºäºååå©ç¨æåå¾çè³æï¼æåå¼å¥äºåºæ¼èª²ç¨å­¸ç¿çè¨ç·´ç¯ä¾ãæåééå¯¦é©è©ä¼°äºæåçæ¹æ³å¨æ¹å LLM è»ç´æéµå¾ªè½åæ¹é¢çæææ§ï¼ä¸¦åæäºä¿æéäºæ¹åçå ç´ ãè³æéåç¨å¼ç¢¼å·²å¬éæ¼ https://github.com/Rainier-rq/FollowSoftConstraintsã

##### **Jailbreaking Multimodal Large Language Models via Shuffle Inconsistency**
2501.04931v1 by Shiji Zhao, Ranjie Duan, Fengxiang Wang, Chi Chen, Caixin Kang, Jialing Tao, YueFeng Chen, Hui Xue, Xingxing Wei

Multimodal Large Language Models (MLLMs) have achieved impressive performance
and have been put into practical use in commercial applications, but they still
have potential safety mechanism vulnerabilities. Jailbreak attacks are red
teaming methods that aim to bypass safety mechanisms and discover MLLMs'
potential risks. Existing MLLMs' jailbreak methods often bypass the model's
safety mechanism through complex optimization methods or carefully designed
image and text prompts. Despite achieving some progress, they have a low attack
success rate on commercial closed-source MLLMs. Unlike previous research, we
empirically find that there exists a Shuffle Inconsistency between MLLMs'
comprehension ability and safety ability for the shuffled harmful instruction.
That is, from the perspective of comprehension ability, MLLMs can understand
the shuffled harmful text-image instructions well. However, they can be easily
bypassed by the shuffled harmful instructions from the perspective of safety
ability, leading to harmful responses. Then we innovatively propose a
text-image jailbreak attack named SI-Attack. Specifically, to fully utilize the
Shuffle Inconsistency and overcome the shuffle randomness, we apply a
query-based black-box optimization method to select the most harmful shuffled
inputs based on the feedback of the toxic judge model. A series of experiments
show that SI-Attack can improve the attack's performance on three benchmarks.
In particular, SI-Attack can obviously improve the attack success rate for
commercial MLLMs such as GPT-4o or Claude-3.5-Sonnet.

æè¦ï¼å¤æ¨¡æå¤§åèªè¨æ¨¡å (MLLM) å·²åå¾ä»¤äººå°è±¡æ·±å»çè¡¨ç¾ï¼ä¸¦å·²å¯¦éæç¨æ¼åæ¥­æç¨ä¸­ï¼ä½å®åä»å·ææ½å¨çå®å¨æ©å¶æ¼æ´ãè¶çæ»ææ¯æ¨å¨ç¹éå®å¨æ©å¶ä¸¦ç¼ç¾ MLLM æ½å¨é¢¨éªçç´éæ¹æ³ãç¾æç MLLM è¶çæ¹æ³éå¸¸ééè¤éçæä½³åæ¹æ³æç²¾å¿è¨­è¨çå½±ååæå­æç¤ºï¼ä¾ç¹éæ¨¡åçå®å¨æ©å¶ãåç®¡åå¾äºä¸äºé²å±ï¼ä½å®åå°åæ¥­éæº MLLM çæ»ææåçå¾ä½ãèååçç ç©¶ä¸åï¼æåæç¶é©ç¼ç¾ï¼å°æ¼æ··æ´çæ¡ææä»¤ï¼MLLM ççè§£è½ååå®å¨æ§ä¹éå­å¨æ··æ´ä¸ä¸è´æ§ãä¹å°±æ¯èªªï¼å¾çè§£è½åçè§åº¦ä¾çï¼MLLM è½å¤ å¾å¥½å°çè§£æ··æ´çæ¡ææå­å½±åæä»¤ãç¶èï¼å¾å®å¨æ§çè§åº¦ä¾çï¼å®åå¾å®¹æè¢«æ··æ´çæ¡ææä»¤ç¹éï¼å°è´ç¢çæ¡æçåæãç¶å¾ï¼æååµæ°å°æåºäºä¸ç¨®åçº SI-Attack çæå­å½±åè¶çæ»æãå·é«ä¾èªªï¼çºäºååå©ç¨æ··æ´ä¸ä¸è´æ§ä¸¦åææ··æ´çé¨æ©æ§ï¼æåæç¨åºæ¼æ¥è©¢çé»çæä½³åæ¹æ³ï¼æ ¹æææ¯å¤æ·æ¨¡åçåé¥ä¾é¸æææå®³çæ··æ´è¼¸å¥ãä¸ç³»åçå¯¦é©è¡¨æï¼SI-Attack å¯ä»¥æé«ä¸ååºæºæ¸¬è©¦çæ»ææè½ãç¹å¥æ¯ï¼SI-Attack å¯ä»¥é¡¯èæé«å°åæ¥­ MLLMï¼ä¾å¦ GPT-4o æ Claude-3.5-Sonnetï¼çæ»ææåçã

##### **Image2CADSeq: Computer-Aided Design Sequence and Knowledge Inference from Product Images**
2501.04928v1 by Xingang Li, Zhenghui Sha

Computer-aided design (CAD) tools empower designers to design and modify 3D
models through a series of CAD operations, commonly referred to as a CAD
sequence. In scenarios where digital CAD files are not accessible, reverse
engineering (RE) has been used to reconstruct 3D CAD models. Recent advances
have seen the rise of data-driven approaches for RE, with a primary focus on
converting 3D data, such as point clouds, into 3D models in boundary
representation (B-rep) format. However, obtaining 3D data poses significant
challenges, and B-rep models do not reveal knowledge about the 3D modeling
process of designs. To this end, our research introduces a novel data-driven
approach with an Image2CADSeq neural network model. This model aims to reverse
engineer CAD models by processing images as input and generating CAD sequences.
These sequences can then be translated into B-rep models using a solid modeling
kernel. Unlike B-rep models, CAD sequences offer enhanced flexibility to modify
individual steps of model creation, providing a deeper understanding of the
construction process of CAD models. To quantitatively and rigorously evaluate
the predictive performance of the Image2CADSeq model, we have developed a
multi-level evaluation framework for model assessment. The model was trained on
a specially synthesized dataset, and various network architectures were
explored to optimize the performance. The experimental and validation results
show great potential for the model in generating CAD sequences from 2D image
data.

æè¦ï¼<paragraph>é»è¦è¼å©è¨­è¨ (CAD) å·¥å·è®è¨­è¨å¸«è½å¤ ééä¸ç³»åç CAD ä½æ¥­ï¼éå¸¸ç¨±çº CAD é åºï¼ä¾è¨­è¨åä¿®æ¹ 3D æ¨¡åãå¨ç¡æ³åå¾æ¸ä½ CAD æªæ¡çææ³ä¸ï¼éåå·¥ç¨ (RE) å·²è¢«ç¨æ¼éå»º 3D CAD æ¨¡åãæè¿çé²å±å·²çå°è³æé©åæ¹æ³å¨ RE ä¸­çå´èµ·ï¼ä¸»è¦å°æ³¨æ¼å° 3D è³æï¼ä¾å¦é»é²ï¼è½ææéçè¡¨ç¤º (B-rep) æ ¼å¼ç 3D æ¨¡åãç¶èï¼åå¾ 3D è³ææé æé¡¯èçææ°ï¼èä¸ B-rep æ¨¡åä¸¦æªæ­é²éæ¼è¨­è¨ç 3D å»ºæ¨¡ç¨åºçç¥è­ãçºæ­¤ï¼æåçç ç©¶å¼é²äºä¸ç¨®æ°ç©çè³æé©åæ¹æ³ï¼ä¸¦æ¡ç¨ Image2CADSeq ç¥ç¶ç¶²è·¯æ¨¡åãæ­¤æ¨¡åæ¨å¨ééèçå½±åä½çºè¼¸å¥åç¢ç CAD é åºä¾éåå·¥ç¨ CAD æ¨¡åãéäºé åºæ¥èå¯ä»¥ä½¿ç¨å¯¦é«å»ºæ¨¡æ ¸å¿è½ææ B-rep æ¨¡åãè B-rep æ¨¡åä¸åï¼CAD é åºæä¾å¢å¼·çå½æ§ä¾ä¿®æ¹æ¨¡åå»ºç«çåå¥æ­¥é©ï¼æä¾å° CAD æ¨¡åå»ºæ§ç¨åºçæ´æ·±å¥çè§£ãçºäºéåä¸å´è¬¹å°è©ä¼° Image2CADSeq æ¨¡åçé æ¸¬æè½ï¼æåå·²éç¼ä¸åå¤å±¤ç´è©ä¼°æ¶æ§ç¨æ¼æ¨¡åè©ä¼°ãæ­¤æ¨¡åæ¯æ ¹æç¹å¥åæçè³æéé²è¡è¨ç·´ï¼ä¸¦æ¢ç´¢äºåç¨®ç¶²è·¯æ¶æ§ä»¥æä½³åæè½ãå¯¦é©åé©è­çµæé¡¯ç¤ºæ­¤æ¨¡åå¨å¾ 2D å½±åè³æç¢ç CAD é åºæ¹é¢å·ææ¥µå¤§çæ½åã</paragraph>

##### **Investigating Numerical Translation with Large Language Models**
2501.04927v1 by Wei Tang, Jiawei Yu, Yuang Li, Yanqing Zhao, Weidong Zhang, Wei Feng, Min Zhang, Hao Yang

The inaccurate translation of numbers can lead to significant security
issues, ranging from financial setbacks to medical inaccuracies. While large
language models (LLMs) have made significant advancements in machine
translation, their capacity for translating numbers has not been thoroughly
explored. This study focuses on evaluating the reliability of LLM-based machine
translation systems when handling numerical data. In order to systematically
test the numerical translation capabilities of currently open source LLMs, we
have constructed a numerical translation dataset between Chinese and English
based on real business data, encompassing ten types of numerical translation.
Experiments on the dataset indicate that errors in numerical translation are a
common issue, with most open-source LLMs faltering when faced with our test
scenarios. Especially when it comes to numerical types involving large units
like ``million", ``billion", and "yi", even the latest llama3.1 8b model can
have error rates as high as 20%. Finally, we introduce three potential
strategies to mitigate the numerical mistranslations for large units.

æè¦ï¼æ¸å­ä¸æºç¢ºçç¿»è­¯å¯è½å°è´éå¤§å®å¨åé¡ï¼å¾è²¡åæ«æå°é«çä¸æºç¢ºãåç®¡å¤§åèªè¨æ¨¡å (LLM) å¨æ©å¨ç¿»è­¯æ¹é¢åå¾äºéå¤§é²å±ï¼ä½å®åç¿»è­¯æ¸å­çè½åå°æªå¾å°å¾¹åºæ¢è¨ãæ¬ç ç©¶çéé»æ¯è©ä¼°åºæ¼ LLM çæ©å¨ç¿»è­¯ç³»çµ±å¨èçæ¸å­æ¸ææçå¯é æ§ãçºäºç³»çµ±å°æ¸¬è©¦ç¶åéæº LLM çæ¸å­ç¿»è­¯è½åï¼æåæ ¹æçå¯¦æ¥­åæ¸ææ§å»ºäºä¸­è±ä¹éçæ¸å­ç¿»è­¯æ¸æéï¼æ¶µèåç¨®é¡åçæ¸å­ç¿»è­¯ãæ¸æéä¸çå¯¦é©è¡¨æï¼æ¸å­ç¿»è­¯ä¸­çé¯èª¤æ¯ä¸åå¸¸è¦åé¡ï¼å¤§å¤æ¸éæº LLM å¨é¢å°æåçæ¸¬è©¦å ´æ¯æé½æåºç¾é¯èª¤ãç¹å¥æ¯ç¶æ¶åå°æ¶åãç¾è¬ãããååãåãåãç­å¤§å®ä½çæ¸å­é¡åæï¼å³ä½¿æ¯ææ°æ¬¾ç llama3.1 8b æ¨¡åçé¯èª¤çä¹å¯è½é«é 20%ãæå¾ï¼æåä»ç´¹äºä¸ç¨®æ½å¨ç­ç¥ä¾æ¸è¼å¤§å®ä½çæ¸å­é¯èª¤ç¿»è­¯ã

##### **FLowHigh: Towards Efficient and High-Quality Audio Super-Resolution with Single-Step Flow Matching**
2501.04926v1 by Jun-Hak Yun, Seung-Bin Kim, Seong-Whan Lee

Audio super-resolution is challenging owing to its ill-posed nature.
Recently, the application of diffusion models in audio super-resolution has
shown promising results in alleviating this challenge. However, diffusion-based
models have limitations, primarily the necessity for numerous sampling steps,
which causes significantly increased latency when synthesizing high-quality
audio samples. In this paper, we propose FLowHigh, a novel approach that
integrates flow matching, a highly efficient generative model, into audio
super-resolution. We also explore probability paths specially tailored for
audio super-resolution, which effectively capture high-resolution audio
distributions, thereby enhancing reconstruction quality. The proposed method
generates high-fidelity, high-resolution audio through a single-step sampling
process across various input sampling rates. The experimental results on the
VCTK benchmark dataset demonstrate that FLowHigh achieves state-of-the-art
performance in audio super-resolution, as evaluated by log-spectral distance
and ViSQOL while maintaining computational efficiency with only a single-step
sampling process.

æè¦ï¼é³é¢è¶åè¾¨çå å¶ä¸è¯ç¹æ§èå·ææææ§ã
æè¿ï¼æ©æ£æ¨¡åå¨é³é¢è¶åè¾¨çä¸­çåºç¨å¨ç¼è§£è¿ä¸æææ¹é¢æ¾ç¤ºåºæå¸æçç»æãç¶èï¼åºäºæ©æ£çæ¨¡åæå¶å±éæ§ï¼ä¸»è¦æ¯éè¦å¤§éçéæ ·æ­¥éª¤ï¼è¿å¨åæé«è´¨éé³é¢æ ·æ¬æ¶ä¼å¯¼è´å»¶è¿æ¾çå¢å ãå¨æ¬æä¸­ï¼æä»¬æåºäº FLowHighï¼è¿æ¯ä¸ç§æ°é¢çæ¹æ³ï¼å°æµå¹éï¼ä¸ç§é«æççææ¨¡åï¼éæå°é³é¢è¶åè¾¨çä¸­ãæä»¬è¿æ¢ç´¢äºä¸é¨éå¯¹é³é¢è¶åè¾¨çè®¾è®¡çæ¦çè·¯å¾ï¼è¯¥è·¯å¾ææå°æè·äºé«åè¾¨çé³é¢åå¸ï¼ä»èæé«äºéå»ºè´¨éãææåºçæ¹æ³éè¿è·¨åç§è¾å¥éæ ·ççåæ­¥éæ ·è¿ç¨çæé«ä¿çãé«åè¾¨çé³é¢ãVCTK åºåæ°æ®éä¸çå®éªç»æè¡¨æï¼FLowHigh å¨é³é¢è¶åè¾¨çæ¹é¢å®ç°äºæåè¿çæ§è½ï¼å¦å¯¹æ°é¢è°±è·ç¦»å ViSQOL æè¯ä¼°çé£æ ·ï¼åæ¶ä»éè¿åæ­¥éæ ·è¿ç¨ä¿æè®¡ç®æçã

##### **JELLY: Joint Emotion Recognition and Context Reasoning with LLMs for Conversational Speech Synthesis**
2501.04904v1 by Jun-Hyeok Cha, Seung-Bin Kim, Hyung-Seok Oh, Seong-Whan Lee

Recently, there has been a growing demand for conversational speech synthesis
(CSS) that generates more natural speech by considering the conversational
context. To address this, we introduce JELLY, a novel CSS framework that
integrates emotion recognition and context reasoning for generating appropriate
speech in conversation by fine-tuning a large language model (LLM) with
multiple partial LoRA modules. We propose an Emotion-aware Q-former encoder,
which enables the LLM to perceive emotions in speech. The encoder is trained to
align speech emotions with text, utilizing datasets of emotional speech. The
entire model is then fine-tuned with conversational speech data to infer
emotional context for generating emotionally appropriate speech in
conversation. Our experimental results demonstrate that JELLY excels in
emotional context modeling, synthesizing speech that naturally aligns with
conversation, while mitigating the scarcity of emotional conversational speech
datasets.

æè¦ï¼æè¿ï¼äººä»¬å¯¹ä¼è¯å¼è¯­é³åæ (CSS) çéæ±ä¸æ­å¢é¿ï¼å®éè¿èèä¼è¯è¯­å¢æ¥çææ´èªç¶çè¯­é³ãä¸ºäºè§£å³è¿ä¸ªé®é¢ï¼æä»¬å¼å¥äº JELLYï¼è¿æ¯ä¸ä¸ªæ°é¢ç CSS æ¡æ¶ï¼å®éæäºææè¯å«åè¯­å¢æ¨çï¼ä»¥ä¾¿éè¿ä½¿ç¨å¤ä¸ªé¨å LoRA æ¨¡åå¾®è°å¤§åè¯­è¨æ¨¡å (LLM) æ¥çæå¯¹è¯ä¸­çéå½è¯­é³ãæä»¬æåºäºä¸ä¸ªæææç¥ Q-former ç¼ç å¨ï¼å®ä½¿ LLM è½å¤æç¥è¯­é³ä¸­çææãè¯¥ç¼ç å¨ç»è¿è®­ç»ï¼å¯ä»¥å°è¯­é³ææä¸ææ¬å¯¹é½ï¼å©ç¨ææè¯­é³æ°æ®éãç¶åä½¿ç¨ä¼è¯è¯­é³æ°æ®å¯¹æ´ä¸ªæ¨¡åè¿è¡å¾®è°ï¼ä»¥æ¨æ­ææè¯­å¢ï¼ä»¥ä¾¿å¨å¯¹è¯ä¸­çæææéå½çè¯­é³ãæä»¬çå®éªç»æè¡¨æï¼JELLY å¨ææè¯­å¢å»ºæ¨¡æ¹é¢è¡¨ç°åºè²ï¼åæäºä¸å¯¹è¯èªç¶å¯¹é½çè¯­é³ï¼åæ¶ç¼è§£äºææå¯¹è¯è¯­é³æ°æ®éçç¨ç¼ºæ§ã

##### **SUGAR: Leveraging Contextual Confidence for Smarter Retrieval**
2501.04899v1 by Hanna Zubkova, Ji-Hoon Park, Seong-Whan Lee

Bearing in mind the limited parametric knowledge of Large Language Models
(LLMs), retrieval-augmented generation (RAG) which supplies them with the
relevant external knowledge has served as an approach to mitigate the issue of
hallucinations to a certain extent. However, uniformly retrieving supporting
context makes response generation source-inefficient, as triggering the
retriever is not always necessary, or even inaccurate, when a model gets
distracted by noisy retrieved content and produces an unhelpful answer.
Motivated by these issues, we introduce Semantic Uncertainty Guided Adaptive
Retrieval (SUGAR), where we leverage context-based entropy to actively decide
whether to retrieve and to further determine between single-step and multi-step
retrieval. Our empirical results show that selective retrieval guided by
semantic uncertainty estimation improves the performance across diverse
question answering tasks, as well as achieves a more efficient inference.

æè¦ï¼èéå°å¤§åèªè¨æ¨¡åï¼LLMï¼æéçåæ¸ç¥è­ï¼æª¢ç´¢å¢å¼·çæï¼RAGï¼çºå¶æä¾ç¸éå¤é¨ç¥è­ï¼å¨ä¸å®ç¨åº¦ä¸ä½çºæ¸è¼å¹»è¦ºåé¡çæ¹æ³ãç¶èï¼çµ±ä¸æª¢ç´¢æ¯æ´çå§å®¹æè®åæçæä¾æºæçä½ä¸ï¼å çºç¶æ¨¡åè¢«æéè¨çæª¢ç´¢å§å®¹åæ£æ³¨æåä¸¦ç¢çç¡ççç­æ¡æï¼è§¸ç¼æª¢ç´¢å¨ä¸¦éç¸½æ¯å¿è¦çï¼çè³æ¯ä¸æºç¢ºçãå¨éäºåé¡çæ¿åµä¸ï¼æåå¼å¥äºèªç¾©ä¸ç¢ºå®æ§å¼å°çèªé©ææª¢ç´¢ï¼SUGARï¼ï¼æåå©ç¨åºæ¼å§å®¹ççµä¾ä¸»åæ±ºå®æ¯å¦æª¢ç´¢ï¼ä¸¦é²ä¸æ­¥ç¢ºå®å®æ­¥åå¤æ­¥æª¢ç´¢ä¹éçåå¥ãæåçå¯¦è­çµæè¡¨æï¼ç±èªç¾©ä¸ç¢ºå®æ§ä¼°è¨å¼å°çæé¸ææ§æª¢ç´¢æ¹åäºåç¨®åé¡åç­ä»»åçæè½ï¼ä¸¦å¯¦ç¾äºæ´ææççæ¨çã

##### **Reach Measurement, Optimization and Frequency Capping In Targeted Online Advertising Under k-Anonymity**
2501.04882v1 by Yuan Gao, Mu Qiao

The growth in the use of online advertising to foster brand awareness over
recent years is largely attributable to the ubiquity of social media. One
pivotal technology contributing to the success of online brand advertising is
frequency capping, a mechanism that enables marketers to control the number of
times an ad is shown to a specific user. However, the very foundation of this
technology is being scrutinized as the industry gravitates towards advertising
solutions that prioritize user privacy. This paper delves into the issue of
reach measurement and optimization within the context of $k$-anonymity, a
privacy-preserving model gaining traction across major online advertising
platforms. We outline how to report reach within this new privacy landscape and
demonstrate how probabilistic discounting, a probabilistic adaptation of
traditional frequency capping, can be employed to optimize campaign
performance. Experiments are performed to assess the trade-off between user
privacy and the efficacy of online brand advertising. Notably, we discern a
significant dip in performance as long as privacy is introduced, yet this comes
with a limited additional cost for advertising platforms to offer their users
more privacy.

æè¦ï¼è¿å¹´ä¾ï¼ç·ä¸å»£åçä½¿ç¨æé·ï¼ç¨æ¼å¹é¤åçæè­ï¼éå¨å¾å¤§ç¨åº¦ä¸è¦æ­¸åæ¼ç¤¾ç¾¤åªé«çæ®éæ§ãå°ç·ä¸åçå»£åæåæè²¢ç»çä¸é ééµæè¡æ¯é »çä¸éï¼éæ¯ä¸ç¨®æ©å¶ï¼ä½¿è¡é·äººå¡è½å¤ æ§å¶åç¹å®ä½¿ç¨èé¡¯ç¤ºå»£åçæ¬¡æ¸ãç¶èï¼é¨èç¢æ¥­æååªåèæ®ä½¿ç¨èé±ç§çå»£åè§£æ±ºæ¹æ¡ç¼å±ï¼éé æè¡çåºç¤æ­£åå°å¯©æ¥ãæ¬ææ·±å¥æ¢è¨å¨ $k$-å¿åæ§çèçµ¡ä¸­è§¸åçæ¸¬éåæä½³åçåé¡ï¼ä¸ç¨®å¨ä¸»è¦ç·ä¸å»£åå¹³å°ä¸ç²å¾éæ³¨çé±ç§ä¿è­·æ¨¡åãæåæ¦è¿°å¦ä½å¨éåæ°çé±ç§ç°å¢ä¸­å ±åè§¸åçï¼ä¸¦å±ç¤ºå¦ä½æ¡ç¨å³çµ±é »çä¸éçæ©çæ§èª¿æ´ï¼æ©çæ§ææ£ï¼ä¾æä½³åå»£åæ´»åææãé²è¡å¯¦é©ä»¥è©ä¼°ä½¿ç¨èé±ç§èç·ä¸åçå»£åææä¹éçåæ¨ãå¼å¾æ³¨æçæ¯ï¼æåè¾¨è­åºåªè¦å¼å¥é±ç§ï¼ææå°±æé¡¯èä¸éï¼ä½å°æ¼å»£åå¹³å°ä¾èªªï¼éåå¸¶ä¾æéçé¡å¤ææ¬ï¼è®ä»åè½å¤ çºä½¿ç¨èæä¾æ´å¤é±ç§ã

##### **Leveraging Log Probabilities in Language Models to Forecast Future Events**
2501.04880v1 by Tommaso Soru, Jim Marshall

In the constantly changing field of data-driven decision making, accurately
predicting future events is crucial for strategic planning in various sectors.
The emergence of Large Language Models (LLMs) marks a significant advancement
in this area, offering advanced tools that utilise extensive text data for
prediction. In this industry paper, we introduce a novel method for AI-driven
foresight using LLMs. Building on top of previous research, we employ data on
current trends and their trajectories for generating forecasts on 15 different
topics. Subsequently, we estimate their probabilities via a multi-step approach
based on log probabilities. We show we achieve a Brier score of 0.186, meaning
a +26% improvement over random chance and a +19% improvement over
widely-available AI systems.

æè¦ï¼å¨è³æé©åæ±ºç­å¶å®ä¸æ·è®åçé åä¸­ï¼æºç¢ºé æ¸¬æªä¾äºä»¶å°æ¼ååé åçç­ç¥è¦åè³ééè¦ãå¤§èªè¨æ¨¡å (LLM) çåºç¾æ¨èªèéæ¹é¢çä¸åéå¤§é²å±ï¼å®æä¾äºåé²çå·¥å·ï¼å©ç¨å»£æ³çæå­è³æé²è¡é æ¸¬ãå¨éç¯ç¢æ¥­è«æä¸­ï¼æåä»ç´¹äºä¸ç¨®ä½¿ç¨ LLM é²è¡ AI é©åé æ¸¬çæ°æ¹æ³ãå¨ååç ç©¶çåºç¤ä¸ï¼æåæ¡ç¨æéç¶åè¶¨å¢åå¶è»è·¡çè³æï¼å° 15 åä¸åçä¸»é¡é²è¡é æ¸¬ãé¨å¾ï¼æåééåºæ¼å°æ¸æ©ççå¤æ­¥é©æ¹æ³ä¾ä¼°è¨å¶æ©çãæåè­ææåéå°äº 0.186 çå¸éç¾åæ¸ï¼éè¡¨ç¤ºæ¯é¨æ©æ©ææé«äº +26%ï¼æ¯å»£æ³å¯ç¨ç AI ç³»çµ±æé«äº +19%ã

##### **Real-Time Textless Dialogue Generation**
2501.04877v1 by Long Mai, Julie Carson-Berndsen

Recent advancements in large language models (LLMs) have led to significant
progress in text-based dialogue systems. These systems can now generate
high-quality responses that are accurate and coherent across a wide range of
topics and tasks. However, spoken dialogue systems still lag behind in terms of
naturalness. They tend to produce robotic interactions, with issues such as
slow response times, overly generic or cautious replies, and a lack of natural
rhythm and fluid turn-taking. This shortcoming is largely due to the
over-reliance on the traditional cascaded design, which involve separate,
sequential components, as well as the use of text as an intermediate
representation. This paper propose a real-time, textless spoken dialogue
generation model (RTTL-DG) that aims to overcome these challenges. Our system
enables fluid turn-taking and generates responses with minimal delay by
processing streaming spoken conversation directly. Additionally, our model
incorporates backchannels, filters, laughter, and other paralinguistic signals,
which are often absent in cascaded dialogue systems, to create more natural and
human-like interactions. The implementations and generated samples are
available in our repository: https://github.com/mailong25/rts2s-dg

æè¦ï¼å¤§åèªè¨æ¨¡åï¼LLMï¼çææ°é²å±å·²å¤§å¹æååºæ¼æå­çå°è©±ç³»çµ±ãéäºç³»çµ±ç¾å¨å¯ä»¥ç¢çé«åè³ªçåæï¼æºç¢ºä¸é£è²«ï¼æ¶µèå»£æ³çä¸»é¡åä»»åãç¶èï¼å£èªå°è©±ç³»çµ±å¨èªç¶åº¦æ¹é¢ä»è½å¾ãå®åå¾åæ¼ç¢çæ©å¨äººå¼çäºåï¼æè«¸å¦åææéæ¢ãåè¦éæ¼ç± çµ±æè¬¹æï¼ä»¥åç¼ºä¹èªç¶ç¯å¥åæµæ¢è¼ªæµç¼è¨ç­åé¡ãéç¨®ç¼ºé»ä¸»è¦æ¯éæ¼ä¾è³´å³çµ±çä¸²è¯å¼è¨­è¨ï¼å¶ä¸­æ¶åç¨ç«çé åºçµä»¶ï¼ä»¥åä½¿ç¨æå­ä½çºä¸­éè¡¨ç¤ºãæ¬ææåºäºä¸åå³æãç¡æå­çå£èªå°è©±çææ¨¡åï¼RTTL-DGï¼ï¼æ¨å¨åæéäºææ°ãæåçç³»çµ±ééç´æ¥èçä¸²æµçå£èªå°è©±ä¾å¯¦ç¾æµæ¢çè¼ªæµç¼è¨ï¼ä¸¦ä»¥æç­çå»¶é²ç¢çåæãæ­¤å¤ï¼æåçæ¨¡åç´å¥äºååé »éãæ¿¾æ³¢å¨ãç¬è²åå¶ä»å¯èªè¨è¨èï¼éäºè¨èéå¸¸å¨ä¸²è¯å¼å°è©±ç³»çµ±ä¸­ä¸å­å¨ï¼ä»¥åµé æ´èªç¶ä¸æ´åäººé¡çäºåãå¯¦ä½åç¢ççç¯ä¾å¯å¨æåçå²å­åº«ä¸­åå¾ï¼https://github.com/mailong25/rts2s-dg

##### **Back Home: A Machine Learning Approach to Seashell Classification and Ecosystem Restoration**
2501.04873v1 by Alexander Valverde, Luis Solano

In Costa Rica, an average of 5 tons of seashells are extracted from
ecosystems annually. Confiscated seashells, cannot be returned to their
ecosystems due to the lack of origin recognition. To address this issue, we
developed a convolutional neural network (CNN) specifically for seashell
identification. We built a dataset from scratch, consisting of approximately
19000 images from the Pacific and Caribbean coasts. Using this dataset, the
model achieved a classification accuracy exceeding 85%. The model has been
integrated into a user-friendly application, which has classified over 36,000
seashells to date, delivering real-time results within 3 seconds per image. To
further enhance the system's accuracy, an anomaly detection mechanism was
incorporated to filter out irrelevant or anomalous inputs, ensuring only valid
seashell images are processed.

æè¦ï¼å¥æ¯å¤§é»å æ¯å¹´å¹³åå¾çæç³»çµ±ä¸­æå 5 å¸çè²æ®¼ãæ²æ¶çè²æ®¼ç±æ¼ç¼ºä¹ä¾æºè­å¥ï¼ç¡æ³æ­¸éå°å¶çæç³»çµ±ä¸­ãçºäºè§£æ±ºæ­¤åé¡ï¼æåç¹å¥éç¼äºä¸åç¨æ¼è²æ®¼è­å¥çå·ç©ç¥ç¶ç¶²è·¯ (CNN)ãæåå¾é ­éå§å»ºç«ä¸åè³æéï¼å¶ä¸­åå«ä¾èªå¤ªå¹³æ´åå åæ¯æµ·æ²¿å²¸çå¤§ç´ 19000 å¼µåçãä½¿ç¨æ­¤è³æéï¼è©²æ¨¡åå¯¦ç¾äºè¶é 85% çåé¡æºç¢ºåº¦ãè©²æ¨¡åå·²æ´åå°ä¸åä½¿ç¨èååçæç¨ç¨å¼ä¸­ï¼è¿ä»å·²åé¡è¶é 36,000 åè²æ®¼ï¼ä¸¦å¨æ¯å¼µåç 3 ç§å§æä¾å³æçµæãçºäºé²ä¸æ­¥æé«ç³»çµ±çæºç¢ºåº¦ï¼å·²æ´åä¸åç°å¸¸åµæ¸¬æ©å¶ï¼ä»¥éæ¿¾æä¸ç¸éæç°å¸¸çè¼¸å¥ï¼ç¢ºä¿åªèçææçè²æ®¼åçã

##### **Advancing Retrieval-Augmented Generation for Persian: Development of Language Models, Comprehensive Benchmarks, and Best Practices for Optimization**
2501.04858v1 by Sara Bourbour Hosseinbeigi, Sina Asghari, Mohammad Ali Seif Kashani, Mohammad Hossein Shalchian, Mohammad Amin Abbasi

This paper examines the specific obstacles of constructing
Retrieval-Augmented Generation(RAG) systems in low-resource languages, with a
focus on Persian's complicated morphology and versatile syntax. The research
aims to improve retrieval and generation accuracy by introducing
Persian-specific models, namely MatinaRoberta(a masked language model) and
MatinaSRoberta(a fine-tuned Sentence-BERT), along with a comprehensive
benchmarking framework. Three datasets-general knowledge(PQuad), scientifically
specialized texts, and organizational reports, were used to assess these models
after they were trained on a varied corpus of 73.11 billion Persian tokens. The
methodology involved extensive pretraining, fine-tuning with tailored loss
functions, and systematic evaluations using both traditional metrics and the
Retrieval-Augmented Generation Assessment framework. The results show that
MatinaSRoberta outperformed previous embeddings, achieving superior contextual
relevance and retrieval accuracy across datasets. Temperature tweaking, chunk
size modifications, and document summary indexing were explored to enhance RAG
setups. Larger models like Llama-3.1 (70B) consistently demonstrated the
highest generation accuracy, while smaller models faced challenges with
domain-specific and formal contexts. The findings underscore the potential for
developing RAG systems in Persian through customized embeddings and
retrieval-generation settings and highlight the enhancement of NLP applications
such as search engines and legal document analysis in low-resource languages.

æè¦ï¼æ¬è«ææ¢è¨äºå¨ä½è³æºèªè¨ä¸­å»ºæ§æª¢ç´¢å¢å¼·çæ (RAG) ç³»çµ±çç¹å®éç¤ï¼éé»å¨æ¼æ³¢æ¯èªè¤éçå½¢æåå¤åè½çèªæ³ãæ¬ç ç©¶æ¨å¨ééå¼å¥æ³¢æ¯èªç¹å®æ¨¡åï¼å³ MatinaRobertaï¼ä¸åé®ç½©èªè¨æ¨¡åï¼å MatinaSRobertaï¼ä¸åå¾®èª¿éçå¥å­ BERTï¼ï¼ä»¥åä¸åå¨é¢çåºæºæ¸¬è©¦æ¡æ¶ï¼ä¾æ¹åæª¢ç´¢åçææºç¢ºåº¦ãå¨å°åå« 731.1 ååæ³¢æ¯èªè©å½çåç¨®èªæåº«é²è¡è¨ç·´å¾ï¼ä½¿ç¨ä¸åè³æéï¼ä¸è¬ç¥è­ (PQuad)ãç§å­¸å°æ¥­ææ¬åçµç¹å ±åï¼ä¾è©ä¼°éäºæ¨¡åãè©²æ¹æ³æ¶åå»£æ³çé è¨ç·´ãä½¿ç¨å®¢è£½åæå¤±å½æ¸é²è¡å¾®èª¿ï¼ä»¥åä½¿ç¨å³çµ±ææ¨åæª¢ç´¢å¢å¼·çæè©ä¼°æ¡æ¶é²è¡ç³»çµ±è©ä¼°ãçµæé¡¯ç¤ºï¼MatinaSRoberta åªæ¼ååçåµå¥ï¼å¨ææè³æéä¸é½éå°äºæ´é«çä¸ä¸æç¸éæ§åæª¢ç´¢æºç¢ºåº¦ãæ¢ç´¢äºæº«åº¦èª¿æ´ãåå¡å¤§å°ä¿®æ¹åæä»¶æè¦ç´¢å¼ä»¥å¢å¼· RAG è¨­å®ãå Llama-3.1 (70B) éæ¨£è¼å¤§çæ¨¡åå§çµå±ç¾åºæé«ççææºç¢ºåº¦ï¼èè¼å°çæ¨¡ååå¨ç¹å®é ååæ­£å¼èªå¢ä¸­é¢è¨ææ°ãç ç©¶çµæå¼·èª¿äºééèªè¨åµå¥åæª¢ç´¢çæè¨­å®ä¾éç¼æ³¢æ¯èª RAG ç³»çµ±çæ½åï¼ä¸¦çªé¡¯äºå¨ä½è³æºèªè¨ä¸­å¢å¼·èªç¶èªè¨èçæç¨ç¨å¼ï¼ä¾å¦æå°å¼æåæ³å¾æä»¶åæï¼çéè¦æ§ã

##### **Exploring Large Language Models for Semantic Analysis and Categorization of Android Malware**
2501.04848v1 by Brandon J Walton, Mst Eshita Khatun, James M Ghawaly, Aisha Ali-Gombe

Malware analysis is a complex process of examining and evaluating malicious
software's functionality, origin, and potential impact. This arduous process
typically involves dissecting the software to understand its components,
infection vector, propagation mechanism, and payload. Over the years, deep
reverse engineering of malware has become increasingly tedious, mainly due to
modern malicious codebases' fast evolution and sophistication. Essentially,
analysts are tasked with identifying the elusive needle in the haystack within
the complexities of zero-day malware, all while under tight time constraints.
Thus, in this paper, we explore leveraging Large Language Models (LLMs) for
semantic malware analysis to expedite the analysis of known and novel samples.
Built on GPT-4o-mini model, \msp is designed to augment malware analysis for
Android through a hierarchical-tiered summarization chain and strategic prompt
engineering. Additionally, \msp performs malware categorization, distinguishing
potential malware from benign applications, thereby saving time during the
malware reverse engineering process. Despite not being fine-tuned for Android
malware analysis, we demonstrate that through optimized and advanced prompt
engineering \msp can achieve up to 77% classification accuracy while providing
highly robust summaries at functional, class, and package levels. In addition,
leveraging the backward tracing of the summaries from package to function
levels allowed us to pinpoint the precise code snippets responsible for
malicious behavior.

æè¦ï¼æ¡æè»é«åææ¯æª¢æ¥åè©ä¼°æ¡æè»é«åè½ãä¾æºåæ½å¨å½±é¿çè¤ééç¨ãéåè±é£çéç¨éå¸¸æ¶åè§£åè»é«ä»¥äºè§£å¶çµæé¨åãææåªä»ãå³æ­æ©å¶åè² è¼ãå¤å¹´ä¾ï¼æ¡æè»é«çæ·±åº¦éåå·¥ç¨è®å¾è¶ä¾è¶ç¹ç£ï¼ä¸»è¦æ¯å çºç¾ä»£æ¡æç¨å¼ç¢¼åº«çå¿«éæ¼è®åè¤éæ§ãåºæ¬ä¸ï¼åæå¸«çä»»åæ¯å¨é¶æå·®æ¡æè»é«çè¤éæ§ä¸­æ¾åºé£ä»¥ææ¸çéé ­ï¼åæéè¦å¨å´æ ¼çæééå¶ä¸é²è¡ãå æ­¤ï¼å¨æ¬æä¸­ï¼æåæ¢è¨å©ç¨å¤§åèªè¨æ¨¡å (LLM) é²è¡èªç¾©æ¡æè»é«åæï¼ä»¥å å¿«å·²ç¥åæ°æ¨£æ¬çåæãå»ºç«å¨ GPT-4o-mini æ¨¡åä¸ï¼\msp æ¨å¨ééåå±¤æè¦éåç­ç¥æç¤ºå·¥ç¨ä¾æ´å Android çæ¡æè»é«åæãæ­¤å¤ï¼\msp å·è¡æ¡æè»é«åé¡ï¼ååæ½å¨æ¡æè»é«èè¯æ§æç¨ç¨å¼ï¼å¾èç¯çæ¡æè»é«éåå·¥ç¨éç¨ä¸­çæéãåç®¡æ²æéå° Android æ¡æè»é«åæé²è¡å¾®èª¿ï¼ä½æåè­æééæä½³ååé²éæç¤ºå·¥ç¨ï¼\msp å¯ä»¥éå°é«é 77% çåé¡æºç¢ºåº¦ï¼åæå¨åè½ãé¡å¥åå¥ä»¶å±¤ç´æä¾é«åº¦ç©©å¥çæè¦ãæ­¤å¤ï¼å©ç¨å¾å¥ä»¶å°åè½å±¤ç´çæè¦ååè¿½è¹¤ï¼è®æåå¯ä»¥ç²¾ç¢ºæ¾åºè² è²¬æ¡æè¡çºçç¨å¼ç¢¼çæ®µã

##### **Enhancing Listened Speech Decoding from EEG via Parallel Phoneme Sequence Prediction**
2501.04844v1 by Jihwan Lee, Tiantian Feng, Aditya Kommineni, Sudarsana Reddy Kadiri, Shrikanth Narayanan

Brain-computer interfaces (BCI) offer numerous human-centered application
possibilities, particularly affecting people with neurological disorders. Text
or speech decoding from brain activities is a relevant domain that could
augment the quality of life for people with impaired speech perception. We
propose a novel approach to enhance listened speech decoding from
electroencephalography (EEG) signals by utilizing an auxiliary phoneme
predictor that simultaneously decodes textual phoneme sequences. The proposed
model architecture consists of three main parts: EEG module, speech module, and
phoneme predictor. The EEG module learns to properly represent EEG signals into
EEG embeddings. The speech module generates speech waveforms from the EEG
embeddings. The phoneme predictor outputs the decoded phoneme sequences in text
modality. Our proposed approach allows users to obtain decoded listened speech
from EEG signals in both modalities (speech waveforms and textual phoneme
sequences) simultaneously, eliminating the need for a concatenated sequential
pipeline for each modality. The proposed approach also outperforms previous
methods in both modalities. The source code and speech samples are publicly
available.

æè¦ï¼è¦æ©ä»é¢ (BCI) æä¾è¨±å¤ä»¥äººçºä¸­å¿çæç¨å¯è½æ§ï¼ç¹å¥æ¯å½±é¿ç¥ç¶ç¾çæ£èãå¾å¤§è¦æ´»åä¸­è§£ç¢¼æå­æèªé³æ¯ä¸åç¸éé åï¼å¯ä»¥æåè¨èªæç¥åæèççæ´»åè³ªãæåæåºä¸åæ°æ¹æ³ä¾å¢å¼·å¾è¦é»å (EEG) è¨èä¸­è§£ç¢¼è½å°çèªé³ï¼æ¹æ³æ¯å©ç¨ä¸åè¼å©é³ç´ é æ¸¬å¨ï¼å®åæè§£ç¢¼æå­é³ç´ åºåãææåºçæ¨¡åæ¶æ§åå«ä¸åä¸»è¦é¨åï¼EEG æ¨¡çµãèªé³æ¨¡çµåé³ç´ é æ¸¬å¨ãEEG æ¨¡çµå­¸ç¿å° EEG è¨èé©ç¶å°è¡¨ç¤ºæ EEG åµå¥ãèªé³æ¨¡çµå¾ EEG åµå¥ä¸­ç¢çèªé³æ³¢å½¢ãé³ç´ é æ¸¬å¨è¼¸åºä»¥æå­åæè§£ç¢¼çé³ç´ åºåãæåæåºçæ¹æ³è®ä½¿ç¨èè½å¤ åæå¾ EEG è¨èä¸­ä»¥å©ç¨®åæï¼èªé³æ³¢å½¢åæå­é³ç´ åºåï¼åå¾è§£ç¢¼çè½åèªé³ï¼æ¶é¤äºå°æ¯ååæä¸²æ¥é åºç®¡ç·çéæ±ãææåºçæ¹æ³å¨å©ç¨®åæä¸­ä¹åªæ¼ååçåæ³ãåå§ç¢¼åèªé³ç¯ä¾å¬éæä¾ã

##### **Do Code LLMs Understand Design Patterns?**
2501.04835v1 by Zhenyu Pan, Xuefeng Song, Yunkun Wang, Rongyu Cao, Binhua Li, Yongbin Li, Han Liu

Code Large Language Models (LLMs) demonstrate great versatility in adapting
to various downstream tasks, including code generation and completion, as well
as bug detection and fixing. However, Code LLMs often fail to capture existing
coding standards, leading to the generation of code that conflicts with the
required design patterns for a given project. As a result, developers must
post-process to adapt the generated code to the project's design norms. In this
work, we empirically investigate the biases of Code LLMs in software
development. Through carefully designed experiments, we assess the models'
understanding of design patterns across recognition, comprehension, and
generation. Our findings reveal that biases in Code LLMs significantly affect
the reliability of downstream tasks.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) ä»£ç¢¼å±ç¤ºåºæ¥µä½³çå¤åè½æ§ï¼å¯é©æåç¨®ä¸æ¸¸ä»»åï¼åæ¬ä»£ç¢¼çæåå®æï¼ä»¥åé¯èª¤åµæ¸¬åä¿®æ­£ãç¶èï¼LLM ä»£ç¢¼ç¶å¸¸ç¡æ³ææç¾æçç·¨ç¢¼æ¨æºï¼å°è´ç¢ççä»£ç¢¼èçµ¦å®å°æ¡æéçè¨­è¨æ¨¡å¼ç¸è¡çªãå æ­¤ï¼éç¼äººå¡å¿é é²è¡å¾èçï¼ä»¥é©æç¢ççä»£ç¢¼è³å°æ¡çè¨­è¨è¦ç¯ãå¨éé å·¥ä½ä¸­ï¼æåå¾ç¶é©ä¸æ¢è¨ LLM ä»£ç¢¼å¨è»é«éç¼ä¸­çåèª¤ãééç²¾å¿è¨­è¨çå¯¦é©ï¼æåè©ä¼°æ¨¡åå°è¨­è¨æ¨¡å¼ççè§£ï¼æ¶µèè¾¨è­ãçè§£åçæãæåçç¼ç¾é¡¯ç¤ºï¼LLM ä»£ç¢¼ä¸­çåèª¤é¡¯èå½±é¿äºä¸æ¸¸ä»»åçå¯é æ§ã

##### **ActPC-Geom: Towards Scalable Online Neural-Symbolic Learning via Accelerating Active Predictive Coding with Information Geometry & Diverse Cognitive Mechanisms**
2501.04832v1 by Ben Goertzel

This paper introduces ActPC-Geom, an approach to accelerate Active Predictive
Coding (ActPC) in neural networks by integrating information geometry,
specifically using Wasserstein-metric-based methods for measure-dependent
gradient flows. We propose replacing KL-divergence in ActPC's predictive error
assessment with the Wasserstein metric, suggesting this may enhance network
robustness.
  To make this computationally feasible, we present strategies including: (1)
neural approximators for inverse measure-dependent Laplacians, (2) approximate
kernel PCA embeddings for low-rank approximations feeding into these
approximators, and (3) compositional hypervector embeddings derived from kPCA
outputs, with algebra optimized for fuzzy FCA lattices learned through neural
architectures analyzing network states.
  This results in an ActPC architecture capable of real-time online learning
and integrating continuous (e.g., transformer-like or Hopfield-net-like) and
discrete symbolic ActPC networks, including frameworks like OpenCog Hyperon or
ActPC-Chem for algorithmic chemistry evolution. Shared probabilistic,
concept-lattice, and hypervector models enable symbolic-subsymbolic
integration.
  Key features include (1) compositional reasoning via hypervector embeddings
in transformer-like architectures for tasks like commonsense reasoning, and (2)
Hopfield-net dynamics enabling associative long-term memory and
attractor-driven cognitive features.
  We outline how ActPC-Geom combines few-shot learning with online weight
updates, enabling deliberative thinking and seamless symbolic-subsymbolic
reasoning. Ideas from Galois connections are explored for efficient hybrid
ActPC/ActPC-Chem processing. Finally, we propose a specialized HPC design
optimized for real-time focused attention and deliberative reasoning tailored
to ActPC-Geom's demands.

æè¦ï¼<paragraph>æ¬æä»ç´¹äº ActPC-Geomï¼ä¸ç¨®ééæ´åè³è¨å¹¾ä½ä¾å éç¥ç¶ç¶²è·¯ä¸­ä¸»åé æ¸¬ç·¨ç¢¼ (ActPC) çæ¹æ³ï¼ç¹å¥æ¯ä½¿ç¨åºæ¼ Wasserstein åº¦éçæ¸¬åº¦ç¸éæ¢¯åº¦æµæ¹æ³ãæåå»ºè­°ä»¥ Wasserstein åº¦éåä»£ ActPC é æ¸¬èª¤å·®è©ä¼°ä¸­ç KL åæ­§ï¼ä¸¦æåºéå¯è½æå¢å¼·ç¶²è·¯çç©©å¥æ§ã
çºäºè®éå¨éç®ä¸å¯è¡ï¼æåæåºäºä»¥ä¸ç­ç¥ï¼(1) éæ¸¬åº¦ç¸éææ®ææ¯ç®å­çç¥ç¶è¿ä¼¼å¨ï¼(2) è¿ä¼¼æ ¸ PCA åµå¥ï¼ç¨æ¼è¼¸å¥éäºè¿ä¼¼å¨çä½ç§©è¿ä¼¼ï¼ä»¥å (3) æºèª kPCA è¼¸åºççµåè¶åéåµå¥ï¼å¶ä¸­ä»£æ¸éå°ééåæç¶²è·¯çæçç¥ç¶æ¶æ§æå­¸ç¿å°çæ¨¡ç³ FCA æ ¼å­é²è¡æä½³åã
éç¢çäºä¸å ActPC æ¶æ§ï¼å®è½å¤ é²è¡å³æç·ä¸å­¸ç¿ï¼ä¸¦æ´åé£çºç (ä¾å¦é¡ Transformer æé¡ Hopfield ç¶²è·¯) åé¢æ£ç¬¦è ActPC ç¶²è·¯ï¼åæ¬ç¨æ¼æ¼ç®æ³åå­¸æ¼åç OpenCog Hyperon æ ActPC-Chem ç­æ¶æ§ãå±ç¨æ©çãæ¦å¿µæ ¼å­åè¶åéæ¨¡åå¯¦ç¾äºç¬¦èæ¬¡ç¬¦èæ´åã
ä¸»è¦ç¹é»åæ¬ (1) ééé¡ Transformer æ¶æ§ä¸­çè¶åéåµå¥é²è¡çµåæ¨çï¼ä»¥å·è¡å¸¸è­æ¨çç­ä»»åï¼ä»¥å (2) Hopfield ç¶²è·¯åæï¼å¯¦ç¾è¯æ³é·æè¨æ¶åå¸å¼å­é©åçèªç¥ç¹å¾µã
æåæ¦è¿°äº ActPC-Geom å¦ä½å°å°éå­¸ç¿èç·ä¸æ¬éæ´æ°çµåï¼å¾èå¯¦ç¾å¯©ææèåç¡ç¸«çç¬¦èæ¬¡ç¬¦èæ¨çãæ¢ç´¢äºä¾èªä¼½ç¾ç¦é£æ¥çæ³æ³ï¼ä»¥é²è¡ææçæ··å ActPC/ActPC-Chem èçãæå¾ï¼æåæåºäºä¸ç¨®éå° ActPC-Geom éæ±é²è¡æä½³åçç¹æ® HPC è¨­è¨ï¼éå°å³æç¦é»æ³¨æåå¯©ææ¨çé²è¡äºæä½³åã</paragraph>

##### **Building Foundations for Natural Language Processing of Historical Turkish: Resources and Models**
2501.04828v1 by Åaziye BetÃ¼l ÃzateÅ, TarÄ±k Emre TÄ±raÅ, Ece Elif Adak, Berat DoÄan, Fatih Burak KaragÃ¶z, Efe Eren GenÃ§, Esma F. Bilgin TaÅdemir

This paper introduces foundational resources and models for natural language
processing (NLP) of historical Turkish, a domain that has remained
underexplored in computational linguistics. We present the first named entity
recognition (NER) dataset, HisTR and the first Universal Dependencies treebank,
OTA-BOUN for a historical form of the Turkish language along with
transformer-based models trained using these datasets for named entity
recognition, dependency parsing, and part-of-speech tagging tasks.
Additionally, we introduce Ottoman Text Corpus (OTC), a clean corpus of
transliterated historical Turkish texts that spans a wide range of historical
periods. Our experimental results show significant improvements in the
computational analysis of historical Turkish, achieving promising results in
tasks that require understanding of historical linguistic structures. They also
highlight existing challenges, such as domain adaptation and language
variations across time periods. All of the presented resources and models are
made available at https://huggingface.co/bucolin to serve as a benchmark for
future progress in historical Turkish NLP.

æè¦ï¼éç¯è«æä»ç´¹äºèªç¶èªè¨èç (NLP) çåºç¤è³æºåæ¨¡åï¼ç¨æ¼èçæ­·å²åè³å¶èªï¼éæ¯ä¸åå¨è¨ç®èªè¨å­¸ä¸­ä»æªè¢«ååæ¢ç´¢çé åãæåæåºäºç¬¬ä¸åå½åå¯¦é«è­å¥ (NER) è³æé HisTR åç¬¬ä¸åéç¨ä¾å­æ¨¹åº« OTA-BOUNï¼ç¨æ¼æ­·å²å½¢å¼çåè³å¶èªï¼ä»¥åä½¿ç¨éäºè³æéè¨ç·´çè®æå¨æ¨¡åï¼ç¨æ¼å½åå¯¦é«è­å¥ãä¾å­å¥æ³åæåè©æ§æ¨è¨ä»»åãæ­¤å¤ï¼æåéä»ç´¹äºéåæ¼ææ¬èªæåº« (OTC)ï¼éæ¯ä¸åä¹¾æ·¨çè½å¯«æ­·å²åè³å¶èªææ¬èªæåº«ï¼æ¶µèäºå»£æ³çæ­·å²ææãæåçå¯¦é©çµæé¡¯ç¤ºï¼æ­·å²åè³å¶èªçè¨ç®åææäºé¡¯èçæ¹é²ï¼å¨éè¦çè§£æ­·å²èªè¨çµæ§çä»»åä¸­åå¾äºæå¸æççµæãå®åéçªåºäºç¾æçææ°ï¼ä¾å¦é åé©æåè·¨æä»£çèªè¨è®ç°ãæææåºçè³æºåæ¨¡åé½å¯ä»¥å¨ https://huggingface.co/bucolin ä¸ç²å¾ï¼ä½çºæ­·å²åè³å¶èª NLP æªä¾é²å±çåºæºã

##### **Intelligent Gradient Boosting Algorithms for Estimating Strength of Modified Subgrade Soil**
2501.04826v1 by Ismail B. Mustapha, Muyideen Abdulkareem, Shafaatunnur Hasan, Abideen Ganiyu, Hatem Nabus, Jin Chai Lee

The performance of pavement under loading depends on the strength of the
subgrade. However, experimental estimation of properties of pavement strengths
such as California bearing ratio (CBR), unconfined compressive strength (UCS)
and resistance value (R) are often tedious, time-consuming and costly, thereby
inspiring a growing interest in machine learning based tools which are simple,
cheap and fast alternatives. Thus, the potential application of two boosting
techniques; categorical boosting (CatBoost) and extreme gradient boosting
(XGBoost) and support vector regression (SVR), is similarly explored in this
study for estimation of properties of subgrade soil modified with hydrated lime
activated rice husk ash (HARSH). Using 121 experimental data samples of varying
proportions of HARSH, plastic limit, liquid limit, plasticity index, clay
activity, optimum moisture content, and maximum dry density as input for CBR,
UCS and R estimation, four evaluation metrics namely coefficient of
determination (R2), root mean squared error (RMSE), mean absolute error (MAE)
and mean absolute percentage error (MAPE) are used to evaluate the models'
performance. The results indicate that XGBoost outperformed CatBoost and SVR in
estimating these properties, yielding R2 of 0.9994, 0.9995 and 0.9999 in
estimating the CBR, UCS and R respectively. Also, SVR outperformed CatBoost in
estimating the CBR and R with R2 of 0.9997 respectively. On the other hand,
CatBoost outperformed SVR in estimating the UCS with R2 of 0.9994. Feature
sensitivity analysis shows that the three machine learning techniques are
unanimous that increasing HARSH proportion lead to values of the estimated
properties respectively. A comparison with previous results also shows
superiority of XGBoost in estimating subgrade properties.

æè¦ï¼è·¯é¢å¨åè¼è·ä½ç¨ä¸çæè½åæ±ºæ¼è·¯åºçå¼·åº¦ãç¶èï¼è·¯é¢å¼·åº¦æ§è³ªçå¯¦é©ä¼°è¨ï¼ä¾å¦å å·æ¿è¼æ¯ (CBR)ãç¡å´éæå£å¼·åº¦ (UCS) åæåå¼ (R) éå¸¸ç¹ç£ãèæä¸ææ¬é«æï¼å æ­¤æ¿ç¼äºäººåå°åºæ¼æ©å¨å­¸ç¿çå·¥å·çèè¶£ï¼éäºå·¥å·ç°¡å®ãä¾¿å®ä¸å¿«éãå æ­¤ï¼æ¬ç ç©¶åæ¨£æ¢è¨äºå©ç¨®æåæè¡çæ½å¨æç¨ï¼åé¡æå (CatBoost) åæ¥µç«¯æ¢¯åº¦æå (XGBoost) åæ¯æåéåæ­¸ (SVR)ï¼ç¨æ¼ä¼°è¨ç¶ç±æ°´åç³ç°æ´»åç¨»æ®¼ç° (HARSH) æ¹è¯çè·¯åºåçæ§è³ªãä½¿ç¨ 121 åä¸åæ¯ä¾ HARSH çå¯¦é©æ¸ææ¨£æ¬ï¼å¡æ§æ¥µéãæ¶²æ§æ¥µéãå¡æ§ææ¸ãé»åæ´»æ§ãæä½³å«æ°´éåæå¤§ä¹¾å¯åº¦ä½çº CBRãUCS å R ä¼°è¨çè¼¸å¥ï¼ååè©ä¼°ææ¨ï¼å³æ±ºå®ä¿æ¸ (R2)ãåæ¹æ ¹èª¤å·® (RMSE)ãå¹³åçµå°èª¤å·® (MAE) åå¹³åçµå°ç¾åæ¯èª¤å·® (MAPE) ç¨æ¼è©ä¼°æ¨¡åçæè½ãçµæè¡¨æï¼XGBoost å¨ä¼°è¨éäºæ§è³ªæ¹é¢åªæ¼ CatBoost å SVRï¼å¨ä¼°è¨ CBRãUCS å R æåå¥ç¢ç 0.9994ã0.9995 å 0.9999 ç R2ãæ­¤å¤ï¼SVR å¨ä¼°è¨ CBR å R æåªæ¼ CatBoostï¼R2 åå¥çº 0.9997ãå¦ä¸æ¹é¢ï¼CatBoost å¨ä¼°è¨ UCS æåªæ¼ SVRï¼R2 çº 0.9994ãç¹å¾µæææ§åæè¡¨æï¼ä¸ç¨®æ©å¨å­¸ç¿æè¡ä¸è´èªçºï¼å¢å  HARSH æ¯ä¾æå°è´ä¼°è¨æ§è³ªçå¼åå¥å¢å ãèååççµææ¯è¼ä¹é¡¯ç¤ºåº XGBoost å¨ä¼°è¨è·¯åºæ§è³ªæ¹é¢çåªè¶æ§ã

##### **Unifying the Extremes: Developing a Unified Model for Detecting and Predicting Extremist Traits and Radicalization**
2501.04820v1 by Allison Lahnala, Vasudha Varadarajan, Lucie Flek, H. Andrew Schwartz, Ryan L. Boyd

The proliferation of ideological movements into extremist factions via social
media has become a global concern. While radicalization has been studied
extensively within the context of specific ideologies, our ability to
accurately characterize extremism in more generalizable terms remains
underdeveloped. In this paper, we propose a novel method for extracting and
analyzing extremist discourse across a range of online community forums. By
focusing on verbal behavioral signatures of extremist traits, we develop a
framework for quantifying extremism at both user and community levels. Our
research identifies 11 distinct factors, which we term ``The Extremist
Eleven,'' as a generalized psychosocial model of extremism. Applying our method
to various online communities, we demonstrate an ability to characterize
ideologically diverse communities across the 11 extremist traits. We
demonstrate the power of this method by analyzing user histories from members
of the incel community. We find that our framework accurately predicts which
users join the incel community up to 10 months before their actual entry with
an AUC of $>0.6$, steadily increasing to AUC ~0.9 three to four months before
the event. Further, we find that upon entry into an extremist forum, the users
tend to maintain their level of extremism within the community, while still
remaining distinguishable from the general online discourse. Our findings
contribute to the study of extremism by introducing a more holistic,
cross-ideological approach that transcends traditional, trait-specific models.

æè¦ï¼ç¤¾ç¾¤åªé«ä¸æè­å½¢æéåæ´æ£å°æ¥µç«¯æ´¾ç³»å·²æçºå¨çéæ³¨çè­°é¡ãéç¶æ¿é²åå·²å¨ç¹å®æè­å½¢æçèçµ¡ä¸å»£æ³ç ç©¶ï¼æåæºç¢ºæè¿°æ´æ®éçæ¥µç«¯ä¸»ç¾©çè½åä»æªç¼å±ãå¨æ¬æä¸­ï¼æåæåºäºä¸ç¨®æ°ç©çæ¹æ³ï¼ç¨æ¼æ·åååæåç¨®ç·ä¸ç¤¾ç¾¤è«å£ä¸­çæ¥µç«¯ä¸»ç¾©è«è¿°ãééèç¦æ¼æ¥µç«¯ä¸»ç¾©ç¹è³ªçå£èªè¡çºç¹å¾µï¼æåéç¼äºä¸åæ¶æ§ï¼ç¨æ¼éåä½¿ç¨èåç¤¾ç¾¤å±¤ç´çæ¥µç«¯ä¸»ç¾©ãæåçç ç©¶è­å¥åº 11 åä¸åçå ç´ ï¼æåç¨±ä¹çºãæ¥µç«¯ä¸»ç¾©åä¸ç¹è³ªãï¼ä½çºæ¥µç«¯ä¸»ç¾©çå»£æ³å¿çç¤¾ææ¨¡åãå°æåçæ¨¡åæç¨æ¼åç¨®ç·ä¸ç¤¾ç¾¤ï¼æåå±ç¤ºäºæè¿° 11 åæ¥µç«¯ä¸»ç¾©ç¹è³ªä¸­æè­å½¢æå¤åç¤¾ç¾¤çè½åãæåééåæä¾èªéèªé¡ç¨èº«èç¤¾ç¾¤æå¡çä½¿ç¨èæ­·å²ï¼å±ç¤ºäºæ­¤æ¹æ³çåéãæåç¼ç¾ï¼æåçæ¶æ§æºç¢ºé æ¸¬äºåªäºä½¿ç¨èå¨å¯¦éå å¥å 10 åæå°±æå å¥éèªé¡ç¨èº«èç¤¾ç¾¤ï¼AUC è¶é 0.6ï¼å¨äºä»¶ç¼çåä¸å°ååæç©©å®å¢å è³ AUC ~0.9ãæ­¤å¤ï¼æåç¼ç¾ï¼ä½¿ç¨èå¨é²å¥æ¥µç«¯ä¸»ç¾©è«å£å¾ï¼å¾å¾æå¨ç¤¾ç¾¤ä¸­ç¶­æå¶æ¥µç«¯ä¸»ç¾©ç¨åº¦ï¼åæä»ç¶èä¸è¬çç·ä¸è«è¿°ææåå¥ãæåçç¼ç¾ééå¼å¥æ´å¨é¢ãè·¨æè­å½¢æçæ¹æ³ï¼è¶è¶å³çµ±çãç¹è³ªç¹å®çæ¨¡åï¼å°æ¥µç«¯ä¸»ç¾©çç ç©¶ææè²¢ç»ã

##### **Decentralised Resource Sharing in TinyML: Wireless Bilayer Gossip Parallel SGD for Collaborative Learning**
2501.04817v1 by Ziyuan Bao, Eiman Kanjo, Soumya Banerjee, Hasib-Al Rashid, Tinoosh Mohsenin

With the growing computational capabilities of microcontroller units (MCUs),
edge devices can now support machine learning models. However, deploying
decentralised federated learning (DFL) on such devices presents key challenges,
including intermittent connectivity, limited communication range, and dynamic
network topologies. This paper proposes a novel framework, bilayer Gossip
Decentralised Parallel Stochastic Gradient Descent (GD PSGD), designed to
address these issues in resource-constrained environments. The framework
incorporates a hierarchical communication structure using Distributed Kmeans
(DKmeans) clustering for geographic grouping and a gossip protocol for
efficient model aggregation across two layers: intra-cluster and inter-cluster.
We evaluate the framework's performance against the Centralised Federated
Learning (CFL) baseline using the MCUNet model on the CIFAR-10 dataset under
IID and Non-IID conditions. Results demonstrate that the proposed method
achieves comparable accuracy to CFL on IID datasets, requiring only 1.8
additional rounds for convergence. On Non-IID datasets, the accuracy loss
remains under 8\% for moderate data imbalance. These findings highlight the
framework's potential to support scalable and privacy-preserving learning on
edge devices with minimal performance trade-offs.

æè¦ï¼é¨èå¾®æ§å¶å¨å®å (MCU) çè¨ç®è½åä¸æ·æåï¼éç·£è£ç½®ç¾å¨å¯ä»¥æ¯æ´æ©å¨å­¸ç¿æ¨¡åãç¶èï¼å¨éäºè£ç½®ä¸é¨ç½²å»ä¸­å¿åè¯é¦å­¸ç¿ (DFL) æå¸¶ä¾ä¸äºééµææ°ï¼åæ¬éæ­æ§é£ç·ãæéçéè¨ç¯åååæç¶²è·¯ææ²ãæ¬ææåºäºä¸ååµæ°çæ¶æ§ï¼ç¨±çºéå±¤å«å¦å»ä¸­å¿åå¹³è¡é¨æ©æ¢¯åº¦ä¸é (GD PSGD)ï¼æ¨å¨è§£æ±ºè³æºåéç°å¢ä¸­çéäºåé¡ãæ­¤æ¶æ§æ¡ç¨å±¤ç´å¼éè¨çµæ§ï¼ä½¿ç¨åæ£å¼ Kmeans (DKmeans) ç¾¤éé²è¡å°çåçµï¼ä¸¦ä½¿ç¨å«å¦åå®å¨å©åå±¤ç´ï¼ç¾¤éå§åç¾¤ééï¼é²è¡ææççæ¨¡åèåãæåä½¿ç¨ MCUNet æ¨¡åå¨ CIFAR-10 è³æéä¸ï¼å¨ IID å Non-IID æ¢ä»¶ä¸è©ä¼°æ­¤æ¶æ§çæè½ï¼ä¸¦å°å¶èéä¸­å¼è¯é¦å­¸ç¿ (CFL) åºæºé²è¡æ¯è¼ãçµæé¡¯ç¤ºï¼ææåºçæ¹æ³å¨ IID è³æéä¸éå°è CFL ç¸ç¶çæºç¢ºåº¦ï¼åé 1.8 åé¡å¤ååå³å¯æ¶æãå¨ Non-IID è³æéä¸ï¼å¨ä¸­ç­è³æä¸å¹³è¡¡çææ³ä¸ï¼æºç¢ºåº¦æå¤±ä»ä½æ¼ 8%ãéäºç¼ç¾çªé¡¯äºæ­¤æ¶æ§å¨éç·£è£ç½®ä¸æ¯æ´å¯æ´åä¸é±ç§ä¿è­·çå­¸ç¿çæ½åï¼åæå°æè½åæ¨éè³æä½ã

##### **Reproducing HotFlip for Corpus Poisoning Attacks in Dense Retrieval**
2501.04802v1 by Yongkang Li, Panagiotis Eustratiadis, Evangelos Kanoulas

HotFlip is a topical gradient-based word substitution method for attacking
language models. Recently, this method has been further applied to attack
retrieval systems by generating malicious passages that are injected into a
corpus, i.e., corpus poisoning. However, HotFlip is known to be computationally
inefficient, with the majority of time being spent on gradient accumulation for
each query-passage pair during the adversarial token generation phase, making
it impossible to generate an adequate number of adversarial passages in a
reasonable amount of time. Moreover, the attack method itself assumes access to
a set of user queries, a strong assumption that does not correspond to how
real-world adversarial attacks are usually performed. In this paper, we first
significantly boost the efficiency of HotFlip, reducing the adversarial
generation process from 4 hours per document to only 15 minutes, using the same
hardware. We further contribute experiments and analysis on two additional
tasks: (1) transfer-based black-box attacks, and (2) query-agnostic attacks.
Whenever possible, we provide comparisons between the original method and our
improved version. Our experiments demonstrate that HotFlip can effectively
attack a variety of dense retrievers, with an observed trend that its attack
performance diminishes against more advanced and recent methods. Interestingly,
we observe that while HotFlip performs poorly in a black-box setting,
indicating limited capacity for generalization, in query-agnostic scenarios its
performance is correlated to the volume of injected adversarial passages.

æè¦ï¼HotFlip æ¯ä¸ç¨®ä¸»é¡æ¢¯åº¦å¼çè©å½æ¿ææ³ï¼ç¨æ¼æ»æèªè¨æ¨¡åãæè¿ï¼æ­¤æ¹æ³å·²é²ä¸æ­¥æç¨æ¼æ»ææª¢ç´¢ç³»çµ±ï¼æ¹æ³æ¯çææ¡ææ®µè½ä¸¦å°å¶æ³¨å¥èªæåº«ï¼å³èªæåº«ä¸­æ¯ãç¶èï¼ç¾æå¨ç¥ï¼HotFlip å¨è¨ç®ä¸æçä½ä¸ï¼å¤§é¨åæéé½è±å¨å°ææ§ä»¤ççæéæ®µçæ¯åæ¥è©¢-æ®µè½å°çæ¢¯åº¦ç´¯ç©ä¸ï¼éä½¿å¾ç¡æ³å¨åççæéå§çæè¶³å¤ æ¸éçå°ææ§æ®µè½ãæ­¤å¤ï¼æ»ææ¹æ³æ¬èº«åè¨­å¯ä»¥è¨ªåä¸çµä½¿ç¨èæ¥è©¢ï¼éæ¯ä¸åå¼·æåçåè¨­ï¼èéå¸¸å·è¡å¯¦éå°ææ§æ»æçæ¹å¼ä¸ç¬¦ãå¨æ¬æä¸­ï¼æåé¦åå¤§å¹æå HotFlip çæçï¼ä½¿ç¨ç¸åçç¡¬é«ï¼å°å°ææ§çæéç¨å¾æ¯åæä»¶ 4 å°æç¸®ç­å°å 15 åéãæåé²ä¸æ­¥è²¢ç»äºå°å©åé¡å¤ä»»åçå¯¦é©ååæï¼(1) åºæ¼å³è¼¸çé»çæ»æï¼ä»¥å (2) èæ¥è©¢ç¡éçæ»æãåªè¦æå¯è½ï¼æåé½ææä¾åå§æ¹æ³èæåæ¹é²çæ¬ä¹éçæ¯è¼ãæåçå¯¦é©è¡¨æï¼HotFlip å¯ä»¥æææ»æåç¨®ç¨ å¯æª¢ç´¢å¨ï¼è§å¯å°çè¶¨å¢æ¯å¶æ»ææ§è½æé¨èæ´åé²åæ´æ°çæ¹æ³èéä½ãæè¶£çæ¯ï¼æåè§å¯å°ï¼éç¶ HotFlip å¨é»çè¨­ç½®ä¸­è¡¨ç¾ä¸ä½³ï¼è¡¨æå¶æ¦åè½åæéï¼ä½å¨èæ¥è©¢ç¡éçå ´æ¯ä¸­ï¼å¶æ§è½èæ³¨å¥å°ææ§æ®µè½çæ¸éç¸éã

##### **Cued Speech Generation Leveraging a Pre-trained Audiovisual Text-to-Speech Model**
2501.04799v1 by Sanjana Sankar, Martin Lenglet, Gerard Bailly, Denis Beautemps, Thomas Hueber

This paper presents a novel approach for the automatic generation of Cued
Speech (ACSG), a visual communication system used by people with hearing
impairment to better elicit the spoken language. We explore transfer learning
strategies by leveraging a pre-trained audiovisual autoregressive
text-to-speech model (AVTacotron2). This model is reprogrammed to infer Cued
Speech (CS) hand and lip movements from text input. Experiments are conducted
on two publicly available datasets, including one recorded specifically for
this study. Performance is assessed using an automatic CS recognition system.
With a decoding accuracy at the phonetic level reaching approximately 77%, the
results demonstrate the effectiveness of our approach.

æè¦ï¼æ¬ææåºäºä¸ç¨®åµæ°çæ¹æ³ï¼ç¨æ¼èªåç¢çæç¤ºå¼èªè¨ (ACSG)ï¼éæ¯ä¸ç¨®è¦è¦ºæºéç³»çµ±ï¼ç±è½åéç¤äººå£«ä½¿ç¨ï¼ä»¥æ´å¥½å°å¼åºèªè¨ãæåééå©ç¨é åè¨ç·´çè¦è½èªè¿´æ­¸æå­è½èªé³æ¨¡å (AVTacotron2)ï¼ä¾æ¢ç´¢è½ç§»å­¸ç¿ç­ç¥ãæ­¤æ¨¡åè¢«éæ°ç·¨å¯«ï¼ä»¥å¾æå­è¼¸å¥ä¸­æ¨æ·æç¤ºå¼èªè¨ (CS) çæé¨ååé¨åä½ãå¯¦é©æ¯å¨å©åå¬éå¯ç¨çè³æéä¸é²è¡ï¼å¶ä¸­ä¸åæ¯å°éçºéé ç ç©¶èéè£½ãæè½æ¯ä½¿ç¨èªå CS è¾¨è­ç³»çµ±ä¾è©ä¼°ãå¨é³æ¨å±¤ç´çè§£ç¢¼æºç¢ºåº¦éå°ç´ 77%ï¼çµæè­æäºæåæ¹æ³çæææ§ã

##### **Planarian Neural Networks: Evolutionary Patterns from Basic Bilateria Shaping Modern Artificial Neural Network Architectures**
2501.04700v1 by Ziyuan Huang, Mark Newman, Maria Vaida, Srikar Bellur, Roozbeh Sadeghian, Andrew Siu, Hui Wang, Kevin Huggins

This study examined the viability of enhancing the prediction accuracy of
artificial neural networks (ANNs) in image classification tasks by developing
ANNs with evolution patterns similar to those of biological neural networks.
ResNet is a widely used family of neural networks with both deep and wide
variants; therefore, it was selected as the base model for our investigation.
The aim of this study is to improve the image classification performance of
ANNs via a novel approach inspired by the biological nervous system
architecture of planarians, which comprises a brain and two nerve cords. We
believe that the unique neural architecture of planarians offers valuable
insights into the performance enhancement of ANNs. The proposed planarian
neural architecture-based neural network was evaluated on the CIFAR-10 and
CIFAR-100 datasets. Our results indicate that the proposed method exhibits
higher prediction accuracy than the baseline neural network models in image
classification tasks. These findings demonstrate the significant potential of
biologically inspired neural network architectures in improving the performance
of ANNs in a wide range of applications.

æè¦ï¼æ¬ç ç©¶æ¢è¨äºéééç¼å·æèçç©ç¥ç¶ç¶²è·¯ç¸ä¼¼çæ¼åæ¨¡å¼çäººå·¥ç¥ç¶ç¶²è·¯ (ANN)ï¼ä¾æåäººå·¥ç¥ç¶ç¶²è·¯å¨å½±ååé¡ä»»åä¸­é æ¸¬ç²¾ç¢ºåº¦çå¯è¡æ§ãResNet æ¯ä¸åå»£æ³ä½¿ç¨çç¥ç¶ç¶²è·¯ç³»åï¼å·ææ·±å±¤åå»£æ³çè®ç°ï¼å æ­¤ï¼å®è¢«é¸çºæåç ç©¶çåºæ¬æ¨¡åãæ¬ç ç©¶çç®çæ¯ééä¸ç¨®æ°ç©çæ¹æ³ä¾æåäººå·¥ç¥ç¶ç¶²è·¯çå½±ååé¡æè½ï¼æ­¤æ¹æ³çéæä¾èªæ¼æè²ççç©ç¥ç¶ç³»çµ±æ¶æ§ï¼å¶ä¸­åå«ä¸åå¤§è¦åå©æ¢ç¥ç¶ç´¢ãæåç¸ä¿¡æè²ç¨ç¹çç¥ç¶æ¶æ§è½çºæåäººå·¥ç¥ç¶ç¶²è·¯çæè½æä¾æå¹å¼çè¦è§£ãææåºçåºæ¼æè²ç¥ç¶æ¶æ§çç¥ç¶ç¶²è·¯å¨ CIFAR-10 å CIFAR-100 è³æéä¸é²è¡è©ä¼°ãæåççµæé¡¯ç¤ºï¼ææåºçæ¹æ³å¨å½±ååé¡ä»»åä¸­å±ç¾åºæ¯åºæºç¥ç¶ç¶²è·¯æ¨¡åæ´é«çé æ¸¬ç²¾ç¢ºåº¦ãéäºç¼ç¾è­æäºåçç©åç¼çç¥ç¶ç¶²è·¯æ¶æ§å¨æåäººå·¥ç¥ç¶ç¶²è·¯å¨å»£æ³æç¨ä¸­çæè½æ¹é¢å·æé¡¯èçæ½åã

##### **Grokking at the Edge of Numerical Stability**
2501.04697v1 by Lucas Prieto, Melih Barsbey, Pedro A. M. Mediano, Tolga Birdal

Grokking, the sudden generalization that occurs after prolonged overfitting,
is a surprising phenomenon challenging our understanding of deep learning.
Although significant progress has been made in understanding grokking, the
reasons behind the delayed generalization and its dependence on regularization
remain unclear. In this work, we argue that without regularization, grokking
tasks push models to the edge of numerical stability, introducing floating
point errors in the Softmax function, which we refer to as Softmax Collapse
(SC). We demonstrate that SC prevents grokking and that mitigating SC enables
grokking without regularization. Investigating the root cause of SC, we find
that beyond the point of overfitting, the gradients strongly align with what we
call the na\"ive loss minimization (NLM) direction. This component of the
gradient does not alter the model's predictions but decreases the loss by
scaling the logits, typically by scaling the weights along their current
direction. We show that this scaling of the logits explains the delay in
generalization characteristic of grokking and eventually leads to SC, halting
further learning. To validate our hypotheses, we introduce two key
contributions that address the challenges in grokking tasks: StableMax, a new
activation function that prevents SC and enables grokking without
regularization, and $\perp$Grad, a training algorithm that promotes quick
generalization in grokking tasks by preventing NLM altogether. These
contributions provide new insights into grokking, elucidating its delayed
generalization, reliance on regularization, and the effectiveness of existing
grokking-inducing methods. Code for this paper is available at
https://github.com/LucasPrietoAl/grokking-at-the-edge-of-numerical-stability.

æè¦ï¼<paragraph>éæ¬åå¾çªç¶ç¼ççå»£æ³åï¼ç¨±çºãé æãï¼æ¯ä¸åä»¤äººé©è¨çç¾è±¡ï¼ææ°äºæåå°æ·±åº¦å­¸ç¿ççè§£ãéç¶å¨çè§£é ææ¹é¢å·²åå¾éå¤§é²å±ï¼ä½å»¶é²å»£æ³åèå¾çåå åå¶å°æ­£ååçä¾è³´æ§ä»ä¸æ¸æ¥ãå¨éé å·¥ä½ä¸­ï¼æåè«è­èªªï¼å¨æ²ææ­£ååçææ³ä¸ï¼é æä»»åæå°æ¨¡åæ¨å°æ¸å¼ç©©å®æ§çéç·£ï¼å¨ Softmax å½æ¸ä¸­å¼å¥æµ®é»èª¤å·®ï¼æåç¨±ä¹çº Softmax å´©æ½° (SC)ãæåè­æ SC æé»æ­¢é æï¼èæ¸è¼ SC å¯ä»¥è®é æå¨æ²ææ­£ååçææ³ä¸ç¼çãå¨èª¿æ¥ SC çæ ¹æ¬åå æï¼æåç¼ç¾ï¼å¨éæ¬åé»ä¹å¤ï¼æ¢¯åº¦èæåç¨±ä¹çºãæ¨¸ç´ æå¤±æå°åã(NLM) æ¹åå¼·çå°é½ãæ¢¯åº¦çéåçµæé¨åä¸ææ¹è®æ¨¡åçé æ¸¬ï¼ä½æééèª¿æ´ logit ä¾éä½æå¤±ï¼éå¸¸æ¯æ²¿èå¶ç¶åæ¹åèª¿æ´æ¬éãæåè¡¨æï¼logit çéç¨®èª¿æ´è§£éäºé æç¹æçå»£æ³åå»¶é²ï¼ä¸¦æçµå°è´ SCï¼é»ç¤é²ä¸æ­¥å­¸ç¿ãçºäºé©è­æåçåè¨­ï¼æåæåºäºå©åééµè²¢ç»ï¼ä»¥è§£æ±ºé æä»»åä¸­çææ°ï¼StableMaxï¼éæ¯ä¸åæ°çæ¿æ´»å½æ¸ï¼å¯ä»¥é²æ­¢ SC ä¸¦å¨æ²ææ­£ååçææ³ä¸å¯¦ç¾é æï¼ä»¥å $\perp$Gradï¼éæ¯ä¸ç¨®è¨ç·´æ¼ç®æ³ï¼ééå®å¨é²æ­¢ NLMï¼å¨é æä»»åä¸­ä¿é²å¿«éå»£æ³åãéäºè²¢ç»çºé ææä¾äºæ°çè¦è§£ï¼é¡æäºå¶å»¶é²å»£æ³åãå°æ­£ååçä¾è³´æ§ï¼ä»¥åç¾æé æèªå°æ¹æ³çæææ§ãæ¬æçç¨å¼ç¢¼å¯å¨ https://github.com/LucasPrietoAl/grokking-at-the-edge-of-numerical-stability åå¾ã</paragraph>

##### **EpiCoder: Encompassing Diversity and Complexity in Code Generation**
2501.04694v1 by Yaoxiang Wang, Haoling Li, Xin Zhang, Jie Wu, Xiao Liu, Wenxiang Hu, Zhongxin Guo, Yangyu Huang, Ying Xin, Yujiu Yang, Jinsong Su, Qi Chen, Scarlett Li

Effective instruction tuning is indispensable for optimizing code LLMs,
aligning model behavior with user expectations and enhancing model performance
in real-world applications. However, most existing methods focus on code
snippets, which are limited to specific functionalities and rigid structures,
restricting the complexity and diversity of the synthesized data. To address
these limitations, we introduce a novel feature tree-based synthesis framework
inspired by Abstract Syntax Trees (AST). Unlike AST, which captures syntactic
structure of code, our framework models semantic relationships between code
elements, enabling the generation of more nuanced and diverse data. The feature
tree is constructed from raw data and refined iteratively to increase the
quantity and diversity of the extracted features. This process enables the
identification of more complex patterns and relationships within the code. By
sampling subtrees with controlled depth and breadth, our framework allows
precise adjustments to the complexity of the generated code, supporting a wide
range of tasks from simple function-level operations to intricate multi-file
scenarios. We fine-tuned widely-used base models to create the EpiCoder series,
achieving state-of-the-art performance at both the function and file levels
across multiple benchmarks. Notably, empirical evidence indicates that our
approach shows significant potential in synthesizing highly complex
repository-level code data. Further analysis elucidates the merits of this
approach by rigorously assessing data complexity and diversity through software
engineering principles and LLM-as-a-judge method.

æè¦ï¼ææçæä»¤èª¿æ´å°æ¼æä½³åç¨å¼ç¢¼ LLM è³ééè¦ï¼å¯å°æ¨¡åè¡çºèä½¿ç¨èé æä¿æä¸è´ï¼ä¸¦æåæ¨¡åå¨å¯¦éæç¨ä¸­çæè½ãç¶èï¼ç¾æçæ¹æ³å¤§å¤èéæ¼ç¨å¼ç¢¼çæ®µï¼åéæ¼ç¹å®åè½ååµåççµæ§ï¼éå¶äºåæè³æçè¤éæ§åå¤æ¨£æ§ãçºäºè§£æ±ºéäºéå¶ï¼æåå¼å¥ä¸ç¨®æ°ç©çåºæ¼ç¹å¾µæ¨¹çåææ¶æ§ï¼éæä¾èªæ½è±¡èªæ³æ¨¹ (AST)ãèæ·åç¨å¼ç¢¼èªæ³çµæ§ç AST ä¸åï¼æåçæ¶æ§æå°ç¨å¼ç¢¼åç´ ä¹éçèªæéä¿å»ºæ¨¡ï¼è½å¤ ç¢çæ´ç´°ç·»ä¸å¤æ¨£åçè³æãç¹å¾µæ¨¹æ¯ç±åå§è³æå»ºæ§èæï¼ä¸¦åè¦ç²¾çä»¥å¢å æåç¹å¾µçæ¸éåå¤æ¨£æ§ãæ­¤ç¨åºè½è­å¥ç¨å¼ç¢¼ä¸­æ´è¤éçæ¨¡å¼åéä¿ãééä»¥åæ§æ·±åº¦åå»£åº¦åæ¨£å­æ¨¹ï¼æåçæ¶æ§åè¨±ç²¾ç¢ºèª¿æ´ç¢çç¨å¼ç¢¼çè¤éåº¦ï¼æ¯æ´å¾ç°¡å®å½å¼å±¤ç´æä½å°è¤éå¤æªæ¡å ´æ¯çåç¨®ä»»åãæåå¾®èª¿å»£æ³ä½¿ç¨çåºç¤æ¨¡åä»¥å»ºç« EpiCoder ç³»åï¼å¨å½å¼åæªæ¡å±¤ç´ä¸æ¼å¤ååºæºæ¸¬è©¦ä¸­éææåé²çæè½ãå¼å¾æ³¨æçæ¯ï¼å¯¦è­è­æé¡¯ç¤ºï¼æåçåæ³å¨åæé«åº¦è¤éçå²å­åº«å±¤ç´ç¨å¼ç¢¼è³ææ¹é¢å·æé¡¯èçæ½åãé²ä¸æ­¥çåæééè»é«å·¥ç¨ååå LLM ä½çºè©å¤æ¹æ³ï¼å´è¬¹å°è©ä¼°è³æçè¤éæ§åå¤æ¨£æ§ï¼é¡ææ­¤æ¹æ³çåªé»ã

##### **Beyond Sight: Finetuning Generalist Robot Policies with Heterogeneous Sensors via Language Grounding**
2501.04693v1 by Joshua Jones, Oier Mees, Carmelo Sferrazza, Kyle Stachowicz, Pieter Abbeel, Sergey Levine

Interacting with the world is a multi-sensory experience: achieving effective
general-purpose interaction requires making use of all available modalities --
including vision, touch, and audio -- to fill in gaps from partial observation.
For example, when vision is occluded reaching into a bag, a robot should rely
on its senses of touch and sound. However, state-of-the-art generalist robot
policies are typically trained on large datasets to predict robot actions
solely from visual and proprioceptive observations. In this work, we propose
FuSe, a novel approach that enables finetuning visuomotor generalist policies
on heterogeneous sensor modalities for which large datasets are not readily
available by leveraging natural language as a common cross-modal grounding. We
combine a multimodal contrastive loss with a sensory-grounded language
generation loss to encode high-level semantics. In the context of robot
manipulation, we show that FuSe enables performing challenging tasks that
require reasoning jointly over modalities such as vision, touch, and sound in a
zero-shot setting, such as multimodal prompting, compositional cross-modal
prompting, and descriptions of objects it interacts with. We show that the same
recipe is applicable to widely different generalist policies, including both
diffusion-based generalist policies and large vision-language-action (VLA)
models. Extensive experiments in the real world show that FuSeis able to
increase success rates by over 20% compared to all considered baselines.

æè¦ï¼èä¸çäºåæ¯ä¸ç¨®å¤æå®é«é©ï¼è¦éæææçéç¨äºåï¼å¿é å©ç¨ææå¯ç¨çæ¹å¼ï¼åæ¬è¦è¦ºãè§¸è¦ºåè½è¦ºï¼ä»¥å¡«è£é¨åè§å¯çç©ºç½ãä¾å¦ï¼ç¶è¦è¦ºè¢«é®è½æï¼æ©å¨äººæä¾è³´å¶è§¸è¦ºåè½è¦ºãç¶èï¼æåé²çéç¨æ©å¨äººç­ç¥éå¸¸å¨å¤§åè³æéä¸è¨ç·´ï¼ä»¥åå¾è¦è¦ºåæ¬é«æè¦ºè§å¯ä¾é æ¸¬æ©å¨äººçåä½ãå¨éé å·¥ä½ä¸­ï¼æåæåºäº FuSeï¼ä¸ç¨®æ°ç©çæ¹æ³ï¼å®è½å¾®èª¿è¦è¦ºéåéç¨ç­ç¥ï¼éå°å¤§åè³æéä¸æåå¾çç°è³ªææ¸¬å¨æ¨¡å¼ï¼å©ç¨èªç¶èªè¨ä½çºä¸ç¨®éç¨çè·¨æ¨¡å¼åºç¤ãæåå°å¤æ¨¡å¼å°æ¯æå¤±èæå®åºç¤èªè¨çææå¤±çµåï¼ä»¥ç·¨ç¢¼é«å±¤èªç¾©ãå¨æ©å¨äººæä½çèæ¯ä¸ï¼æåå±ç¤ºäº FuSe è½å¤ å·è¡å·æææ°æ§çä»»åï¼éäºä»»åéè¦å¨é¶æ¬¡å­¸ç¿çè¨­å®ä¸­ï¼å°è¦è¦ºãè§¸è¦ºåè²é³ç­æ¨¡å¼é²è¡è¯åæ¨çï¼ä¾å¦å¤æ¨¡å¼æç¤ºãçµåå¼è·¨æ¨¡å¼æç¤ºï¼ä»¥åèå¶äºåçç©é«æè¿°ãæåå±ç¤ºäºç¸åçéæ¹é©ç¨æ¼åç¨®ä¸åçéç¨ç­ç¥ï¼åæ¬åºæ¼æ´æ£çéç¨ç­ç¥åå¤§åè¦è¦ºèªè¨åä½ (VLA) æ¨¡åãç¾å¯¦ä¸çä¸­çå¤§éå¯¦é©è¡¨æï¼èææèæ®çåºæºç·ç¸æ¯ï¼FuSe è½å¤ å°æåçæé« 20% ä»¥ä¸ã

##### **URSA: Understanding and Verifying Chain-of-thought Reasoning in Multimodal Mathematics**
2501.04686v1 by Ruilin Luo, Zhuofan Zheng, Yifan Wang, Yiyao Yu, Xinzhe Ni, Zicheng Lin, Jin Zeng, Yujiu Yang

Chain-of-thought (CoT) reasoning has been widely applied in the mathematical
reasoning of Large Language Models (LLMs). Recently, the introduction of
derivative process supervision on CoT trajectories has sparked discussions on
enhancing scaling capabilities during test time, thereby boosting the potential
of these models. However, in multimodal mathematical reasoning, the scarcity of
high-quality CoT training data has hindered existing models from achieving
high-precision CoT reasoning and has limited the realization of reasoning
potential during test time. In this work, we propose a three-module synthesis
strategy that integrates CoT distillation, trajectory-format rewriting, and
format unification. It results in a high-quality CoT reasoning instruction
fine-tuning dataset in multimodal mathematics, MMathCoT-1M. We comprehensively
validate the state-of-the-art (SOTA) performance of the trained URSA-7B model
on multiple multimodal mathematical benchmarks. For test-time scaling, we
introduce a data synthesis strategy that automatically generates process
annotation datasets, known as DualMath-1.1M, focusing on both interpretation
and logic. By further training URSA-7B on DualMath-1.1M, we transition from CoT
reasoning capabilities to robust supervision abilities. The trained URSA-RM-7B
acts as a verifier, effectively enhancing the performance of URSA-7B at test
time. URSA-RM-7B also demonstrates excellent out-of-distribution (OOD)
verifying capabilities, showcasing its generalization. Model weights, training
data and code will be open-sourced.

æè¦ï¼<paragraph>éæ¢æèï¼CoTï¼æ¨çå·²å»£æ³æç¨æ¼å¤§åèªè¨æ¨¡åï¼LLMï¼çæ¸å­¸æ¨çä¸­ãæè¿ï¼å¨ CoT è»è·¡ä¸­å¼å¥å°æ¸éç¨ç£ç£ï¼å¼ç¼äºéæ¼å¨æ¸¬è©¦æéå¢å¼·è¦æ¨¡åè½åçè¨è«ï¼å¾èæåäºéäºæ¨¡åçæ½åãç¶èï¼å¨å¤æ¨¡ææ¸å­¸æ¨çä¸­ï¼é«åè³ª CoT è¨ç·´è³æçç¨ç¼ºæ§é»ç¤äºç¾ææ¨¡åå¯¦ç¾é«ç²¾åº¦ç CoT æ¨çï¼ä¸¦éå¶äºå¨æ¸¬è©¦æéå¯¦ç¾æ¨çæ½åçå¯è½æ§ãå¨éé å·¥ä½ä¸­ï¼æåæåºäºä¸ç¨®ä¸æ¨¡çµåæç­ç¥ï¼å®æ´åäº CoT è¸é¤¾ãè»è·¡æ ¼å¼éå¯«åæ ¼å¼çµ±ä¸ãå®ç¢çäºä¸åé«åè³ªç CoT æ¨çæä»¤å¾®èª¿è³æéï¼ç¨æ¼å¤æ¨¡ææ¸å­¸ï¼MMathCoT-1Mãæåå¨é¢é©è­äºè¨ç·´å¾ç URSA-7B æ¨¡åå¨å¤åå¤æ¨¡ææ¸å­¸åºæºä¸çææ°æè¡ï¼SOTAï¼æè½ãå°æ¼æ¸¬è©¦æéç¸®æ¾ï¼æåå¼å¥äºä¸ç¨®è³æåæç­ç¥ï¼å®èªåç¢çéç¨è¨»è§£è³æéï¼ç¨±çº DualMath-1.1Mï¼éé»éæ³¨è§£éåéè¼¯ãééé²ä¸æ­¥è¨ç·´ URSA-7B å¨ DualMath-1.1M ä¸ï¼æåå¾ CoT æ¨çè½åéæ¸¡å°å¼·å¤§çç£ç£è½åãè¨ç·´å¾ç URSA-RM-7B ä½çºé©è­å¨ï¼ææå°å¢å¼·äº URSA-7B å¨æ¸¬è©¦æéçæè½ãURSA-RM-7B éå±ç¤ºäºåºè²çåå¸å¤ï¼OODï¼é©è­è½åï¼å±ç¤ºäºå®çæ³åæ§ãæ¨¡åæ¬éãè¨ç·´è³æåç¨å¼ç¢¼å°æéæºã</paragraph>

##### **Towards System 2 Reasoning in LLMs: Learning How to Think With Meta Chain-of-Thought**
2501.04682v1 by Violet Xiang, Charlie Snell, Kanishk Gandhi, Alon Albalak, Anikait Singh, Chase Blagden, Duy Phung, Rafael Rafailov, Nathan Lile, Dakota Mahan, Louis Castricato, Jan-Philipp Franken, Nick Haber, Chelsea Finn

We propose a novel framework, Meta Chain-of-Thought (Meta-CoT), which extends
traditional Chain-of-Thought (CoT) by explicitly modeling the underlying
reasoning required to arrive at a particular CoT. We present empirical evidence
from state-of-the-art models exhibiting behaviors consistent with in-context
search, and explore methods for producing Meta-CoT via process supervision,
synthetic data generation, and search algorithms. Finally, we outline a
concrete pipeline for training a model to produce Meta-CoTs, incorporating
instruction tuning with linearized search traces and reinforcement learning
post-training. Finally, we discuss open research questions, including scaling
laws, verifier roles, and the potential for discovering novel reasoning
algorithms. This work provides a theoretical and practical roadmap to enable
Meta-CoT in LLMs, paving the way for more powerful and human-like reasoning in
artificial intelligence.

æè¦ï¼æåæåºäºä¸åæ°ç©çæ¡æ¶ï¼åæèé (Meta-CoT)ï¼å®ééæç¢ºå»ºæ¨¡å¾åºç¹å® CoT æéçåºæ¬æ¨çä¾æ´å±å³çµ±çæèé (CoT)ãæåå±ç¤ºäºä¾èªæåé²æ¨¡åçç¶é©è­æï¼éäºæ¨¡åè¡¨ç¾åºèæå¢ä¸­æå°ä¸è´çè¡çºï¼ä¸¦æ¢ç´¢äºééæµç¨ç£ç£ãåæè³æçæåæå°æ¼ç®æ³ä¾ç¢ç Meta-CoT çæ¹æ³ãæå¾ï¼æåæ¦è¿°äºä¸åå·é«çç®¡éï¼ç¨æ¼è¨ç·´æ¨¡åä»¥ç¢ç Meta-CoTï¼å¶ä¸­åå«ç·æ§åæå°è»è·¡åå¼·åå­¸ç¿å¾è¨ç·´çæä»¤èª¿æ´ãæå¾ï¼æåè¨è«äºéæ¾çç ç©¶åé¡ï¼åæ¬è¦æ¨¡å®å¾ãé©è­èè§è²ï¼ä»¥åç¼ç¾æ°æ¨çæ¼ç®æ³çæ½åãéé å·¥ä½æä¾äºä¸åçè«åå¯¦åè·¯ç·åï¼ä»¥å¨ LLM ä¸­åç¨ Meta-CoTï¼çºäººå·¥æºæ§ä¸­æ´å¼·å¤§ä¸æ´é¡ä¼¼äººé¡çæ¨çéªå¹³éè·¯ã

##### **TREAD: Token Routing for Efficient Architecture-agnostic Diffusion Training**
2501.04765v1 by Felix Krause, Timy Phan, Vincent Tao Hu, BjÃ¶rn Ommer

Diffusion models have emerged as the mainstream approach for visual
generation. However, these models usually suffer from sample inefficiency and
high training costs. This issue is particularly pronounced in the standard
diffusion transformer architecture due to its quadratic complexity relative to
input length. Recent works have addressed this by reducing the number of tokens
processed in the model, often through masking. In contrast, this work aims to
improve the training efficiency of the diffusion backbone by using predefined
routes that store this information until it is reintroduced to deeper layers of
the model, rather than discarding these tokens entirely. Further, we combine
multiple routes and introduce an adapted auxiliary loss that accounts for all
applied routes. Our method is not limited to the common transformer-based model
- it can also be applied to state-space models. Unlike most current approaches,
TREAD achieves this without architectural modifications. Finally, we show that
our method reduces the computational cost and simultaneously boosts model
performance on the standard benchmark ImageNet-1K 256 x 256 in
class-conditional synthesis. Both of these benefits multiply to a convergence
speedup of 9.55x at 400K training iterations compared to DiT and 25.39x
compared to the best benchmark performance of DiT at 7M training iterations.

æè¦ï¼æ´æ£æ¨¡åå·²æçºè¦è¦ºçæçä¸»æµæ¹æ³ãç¶èï¼éäºæ¨¡åéå¸¸æåºç¾æ¨£æ¬æçä½åè¨ç·´ææ¬é«çåé¡ãéååé¡å¨æ¨æºæ´æ£Transformeræ¶æ§ä¸­ç¹å¥æé¡¯ï¼å çºå®çäºæ¬¡è¤éåº¦èè¼¸å¥é·åº¦æéãæè¿çç ç©¶ééæ¸å°æ¨¡åä¸­èççç¬¦èæ¸éä¾è§£æ±ºéååé¡ï¼éå¸¸æ¯ééé®ç½©ãç¸æ¯ä¹ä¸ï¼éé å·¥ä½æ¨å¨ééä½¿ç¨é å®ç¾©è·¯å¾ä¾æ¹åæ´æ£ä¸»å¹¹çè¨ç·´æçï¼éäºè·¯å¾æå²å­éäºè³è¨ï¼ç´å°å°å¶éæ°å¼å¥å°æ¨¡åçæ´æ·±å±¤ï¼èä¸æ¯å®å¨æ¨æ£éäºç¬¦èãæ­¤å¤ï¼æåçµåå¤æ¢è·¯å¾ä¸¦å¼å¥ä¸åé©æè¼å©æå¤±ï¼è©²æå¤±æèéææå·²å¥ç¨çè·¯å¾ãæåçæ¨¡åä¸åéæ¼å¸¸è¦çåºæ¼Transformerçæ¨¡åï¼å®ä¹å¯ä»¥æç¨æ¼çæç©ºéæ¨¡åãèå¤§å¤æ¸ç®åçæ¹æ³ä¸åï¼TREAD å¨æ²ææ¶æ§ä¿®æ¹çææ³ä¸å¯¦ç¾äºéä¸é»ãæå¾ï¼æåè­æäºæåçæ¨¡åæ¸å°äºéç®ææ¬ï¼åæå¨æ¨æºåºæº ImageNet-1K 256 x 256 ä¸­æåäºæ¨¡åå¨é¡æ¢ä»¶åæä¸çæè½ãè DiT ç¸æ¯ï¼éå©ååªé»å¨ 400K è¨ç·´åè¦éç®ä¸­ä¹ä»¥ 9.55 åçæ¶æéåº¦ï¼è DiT å¨ 7M è¨ç·´åè¦éç®ä¸­çæä½³åºæºæè½ç¸æ¯ï¼ä¹ä»¥ 25.39 åã

##### **Enhancing Financial VQA in Vision Language Models using Intermediate Structured Representations**
2501.04675v1 by Archita Srivastava, Abhas Kumar, Rajesh Kumar, Prabhakar Srinivasan

Chart interpretation is crucial for visual data analysis, but accurately
extracting information from charts poses significant challenges for automated
models. This study investigates the fine-tuning of DEPLOT, a modality
conversion module that translates the image of a plot or chart to a linearized
table, on a custom dataset of 50,000 bar charts. The dataset comprises simple,
stacked, and grouped bar charts, targeting the unique structural features of
these visualizations. The finetuned DEPLOT model is evaluated against its base
version using a test set of 1,000 images and two metrics: Relative Mapping
Similarity (RMS), which measures categorical mapping accuracy, and Relative
Number Set Similarity (RNSS), which evaluates numerical interpretation
accuracy. To further explore the reasoning capabilities of large language
models (LLMs), we curate an additional set of 100 bar chart images paired with
question answer sets. Our findings demonstrate that providing a structured
intermediate table alongside the image significantly enhances LLM reasoning
performance compared to direct image queries.

æè¦ï¼åè¡¨è§£è®å°æ¼è¦è¦ºè³æåæè³ééè¦ï¼ä½å¾åè¡¨ä¸­æºç¢ºæ·åè³è¨å°æ¼èªååæ¨¡åä¾èªªæ¯ä¸é éå¤§ææ°ãæ¬ç ç©¶æ¢è¨äº DEPLOT çå¾®èª¿ï¼éæ¯ä¸åå°ç¹ªåæåè¡¨çå½±åè½ææç·æ§åè¡¨æ ¼çæ¨¡çµåè½ææ¨¡çµï¼éå°ä¸ååå« 50,000 åé·æ¢åçå®¢è£½åè³æéãè©²è³æéåå«ç°¡å®ãå çåç¾¤çµé·æ¢åï¼ç®æ¨çºéäºè¦è¦ºåçç¨ç¹çµæ§ç¹å¾µãå¾®èª¿å¾ç DEPLOT æ¨¡åä½¿ç¨ä¸ååå« 1,000 åå½±ååå©åææ¨çæ¸¬è©¦éï¼ä¾è©ä¼°å®èåºæ¬çæ¬çå·®ç°ï¼ç¸å°æå°ç¸ä¼¼åº¦ (RMS)ï¼ç¨æ¼è¡¡éåé¡å°æçæºç¢ºåº¦ï¼ä»¥åç¸å°æ¸å­éç¸ä¼¼åº¦ (RNSS)ï¼ç¨æ¼è©ä¼°æ¸å¼è§£è®çæºç¢ºåº¦ãçºäºé²ä¸æ­¥æ¢ç´¢å¤§åèªè¨æ¨¡å (LLM) çæ¨çè½åï¼æåç­åäºä¸åé¡å¤ç 100 å¼µé·æ¢åå½±åéï¼ä¸¦éå°åé¡è§£ç­éãæåçç ç©¶çµæè¡¨æï¼èç´æ¥å½±åæ¥è©¢ç¸æ¯ï¼å¨å½±åæéæä¾ä¸åçµæ§åçä¸­éè¡¨æ ¼ï¼å¯ä»¥é¡¯èå¢å¼· LLM çæ¨çæè½ã

##### **DRIVINGVQA: Analyzing Visual Chain-of-Thought Reasoning of Vision Language Models in Real-World Scenarios with Driving Theory Tests**
2501.04671v1 by Charles CorbiÃ¨re, Simon Roburin, Syrielle Montariol, Antoine Bosselut, Alexandre Alahi

Large vision-language models (LVLMs) augment language models with visual
understanding, enabling multimodal reasoning. However, due to the modality gap
between textual and visual data, they often face significant challenges, such
as over-reliance on text priors, hallucinations, and limited capacity for
complex visual reasoning. Existing benchmarks to evaluate visual reasoning in
LVLMs often rely on schematic or synthetic images and on imprecise
machine-generated explanations. To bridge the modality gap, we present
DrivingVQA, a new benchmark derived from driving theory tests to evaluate
visual chain-of-thought reasoning in complex real-world scenarios. It offers
3,931 expert-crafted multiple-choice problems and interleaved explanations
grounded with entities relevant to the reasoning process. We leverage this
dataset to perform an extensive study of LVLMs' ability to reason about complex
visual scenarios. Our experiments reveal that open-source and proprietary LVLMs
struggle with visual chain-of-thought reasoning under zero-shot settings. We
investigate training strategies that leverage relevant entities to improve
visual reasoning. Notably, we observe a performance boost of up to 7\% when
reasoning over image tokens of cropped regions tied to these entities.

æè¦ï¼å¤§åè§è§è¯­è¨æ¨¡å (LVLMs) ä½¿ç¨è§è§çè§£æ¥å¢å¼ºè¯­è¨æ¨¡åï¼å®ç°å¤æ¨¡ææ¨çãç¶èï¼ç±äºææ¬åè§è§æ°æ®ä¹é´çæ¨¡æå·®å¼ï¼å®ä»¬éå¸¸é¢ä¸´çéå¤§ææï¼ä¾å¦è¿åº¦ä¾èµææ¬åéªãå¹»è§ä»¥åå¤æè§è§æ¨çè½åæéãç°æçåºåç¨äºè¯ä¼° LVLMs ä¸­çè§è§æ¨çï¼éå¸¸ä¾èµäºç¤ºæå¾æåæå¾åä»¥åä¸ç²¾ç¡®çæºå¨çæçè§£éãä¸ºäºå¼¥åæ¨¡æå·®è·ï¼æä»¬æåºäº DrivingVQAï¼è¿æ¯ä¸ä¸ªæ°çåºåï¼æºèªé©¾é©¶çè®ºæµè¯ï¼ç¨äºè¯ä¼°å¤æç°å®ä¸çåºæ¯ä¸­çè§è§æç»´é¾æ¨çãå®æä¾äº 3,931 ä¸ªä¸å®¶å¶ä½çå¤é¡¹éæ©é¢åç©¿æçè§£éï¼è¿äºè§£éä»¥ä¸æ¨çè¿ç¨ç¸å³çå®ä½ä¸ºåºç¡ãæä»¬å©ç¨æ­¤æ°æ®éå¯¹ LVLMs æ¨çå¤æè§è§åºæ¯çè½åè¿è¡äºå¹¿æ³çç ç©¶ãæä»¬çå®éªè¡¨æï¼å¼æºåä¸æ LVLMs å¨é¶æ¬¡å­¦ä¹ è®¾ç½®ä¸é¾ä»¥è¿è¡è§è§æç»´é¾æ¨çãæä»¬ç ç©¶äºå©ç¨ç¸å³å®ä½æ¥æ¹åè§è§æ¨ççè®­ç»ç­ç¥ãå¼å¾æ³¨æçæ¯ï¼å½å¯¹ä¸è¿äºå®ä½ç¸å³çè£åªåºåçå¾åæ è®°è¿è¡æ¨çæ¶ï¼æä»¬è§å¯å°æ§è½æåé«è¾¾ 7%ã

##### **On The Origin of Cultural Biases in Language Models: From Pre-training Data to Linguistic Phenomena**
2501.04662v1 by Tarek Naous, Wei Xu

Language Models (LMs) have been shown to exhibit a strong preference towards
entities associated with Western culture when operating in non-Western
languages. In this paper, we aim to uncover the origins of entity-related
cultural biases in LMs by analyzing several contributing factors, including the
representation of entities in pre-training data and the impact of variations in
linguistic phenomena across languages. We introduce CAMeL-2, a parallel
Arabic-English benchmark of 58,086 entities associated with Arab and Western
cultures and 367 masked natural contexts for entities. Our evaluations using
CAMeL-2 reveal reduced performance gaps between cultures by LMs when tested in
English compared to Arabic. We find that LMs struggle in Arabic with entities
that appear at high frequencies in pre-training, where entities can hold
multiple word senses. This also extends to entities that exhibit high lexical
overlap with languages that are not Arabic but use the Arabic script. Further,
we show how frequency-based tokenization leads to this issue in LMs, which gets
worse with larger Arabic vocabularies. We will make CAMeL-2 available at:
https://github.com/tareknaous/camel2

æè¦ï¼èªè¨æ¨¡å (LM) å¨ä½¿ç¨éè¥¿æ¹èªè¨æï¼å·²è¢«è­æå°èè¥¿æ¹æåç¸éçå¯¦é«è¡¨ç¾åºå¼·ççåå¥½ãå¨æ¬æä¸­ï¼æåæ¨å¨ééåæå¹¾åä¿æå ç´ ä¾æ­é²èªè¨æ¨¡åä¸­èå¯¦é«ç¸éçæååè¦çæ ¹æºï¼åæ¬å¯¦é«å¨é è¨ç·´è³æä¸­çè¡¨ç¤ºï¼ä»¥åèªè¨ä¸­èªè¨ç¾è±¡è®åçå½±é¿ãæåå¼å¥äº CAMeL-2ï¼ä¸ååå« 58,086 åèé¿æä¼¯åè¥¿æ¹æåç¸éçå¯¦é«ï¼ä»¥å 367 åç¨æ¼å¯¦é«çé®è½èªç¶èªå¢çå¹³è¡é¿æä¼¯èª-è±èªåºæºãæåä½¿ç¨ CAMeL-2 é²è¡çè©ä¼°é¡¯ç¤ºï¼èå¨é¿æä¼¯èªä¸­æ¸¬è©¦ç¸æ¯ï¼èªè¨æ¨¡åå¨è±èªä¸­æ¸¬è©¦æï¼ä¸åæåä¹éçæè½å·®è·ç¸®å°ãæåç¼ç¾èªè¨æ¨¡åå¨é¿æä¼¯èªä¸­èçå¨é è¨ç·´ä¸­åºç¾é »çé«çå¯¦é«ææéå°å°é£ï¼å çºå¯¦é«å¯è½æå¤åè©å½æç¾©ãéä¹å»¶ä¼¸å°èéé¿æä¼¯èªä½ä½¿ç¨é¿æä¼¯æå­çèªè¨å·æé«åº¦è©å½éççå¯¦é«ãæ­¤å¤ï¼æåå±ç¤ºäºåºæ¼é »ççè©å½åå¦ä½å°è´èªè¨æ¨¡åä¸­åºç¾æ­¤åé¡ï¼èé¨èé¿æä¼¯èªè©å½éçå¢å ï¼ææ³æè®å¾æ´ç³ãæåå°å¨ä»¥ä¸ä½ç½®æä¾ CAMeL-2ï¼https://github.com/tareknaous/camel2

##### **Assessing Language Comprehension in Large Language Models Using Construction Grammar**
2501.04661v1 by Wesley Scivetti, Melissa Torgbi, Austin Blodgett, Mollie Shichman, Taylor Hudson, Claire Bonial, Harish Tayyar Madabushi

Large Language Models, despite their significant capabilities, are known to
fail in surprising and unpredictable ways. Evaluating their true
`understanding' of language is particularly challenging due to the extensive
web-scale data they are trained on. Therefore, we construct an evaluation to
systematically assess natural language understanding (NLU) in LLMs by
leveraging Construction Grammar (CxG), which provides insights into the meaning
captured by linguistic elements known as constructions (Cxns). CxG is
well-suited for this purpose because provides a theoretical basis to construct
targeted evaluation sets. These datasets are carefully constructed to include
examples which are unlikely to appear in pre-training data, yet intuitive and
easy for humans to understand, enabling a more targeted and reliable
assessment. Our experiments focus on downstream natural language inference and
reasoning tasks by comparing LLMs' understanding of the underlying meanings
communicated through 8 unique Cxns with that of humans. The results show that
while LLMs demonstrate some knowledge of constructional information, even the
latest models including GPT-o1 struggle with abstract meanings conveyed by
these Cxns, as demonstrated in cases where test sentences are dissimilar to
their pre-training data. We argue that such cases provide a more accurate test
of true language understanding, highlighting key limitations in LLMs' semantic
capabilities. We make our novel dataset and associated experimental data
including prompts and model responses publicly available.

æè¦ï¼åç®¡å¤§åèªè¨æ¨¡åå·æé¡¯èçè½åï¼ä½å®åä»¥ä»¤äººé©è¨ä¸ç¡æ³é æ¸¬çæ¹å¼å¤±æèèåãç±æ¼å®åè¨ç·´æ¼å»£æ³çç¶²è·¯è¦æ¨¡è³æï¼å æ­¤è©ä¼°å®åå°èªè¨ççæ­£ãçè§£ãç¹å¥å·æææ°æ§ãå æ­¤ï¼æåå»ºæ§äºä¸åè©éï¼ä»¥ééå©ç¨å»ºæ§ææ³ï¼CxGï¼ç³»çµ±æ§å°è©ä¼°å¤§åèªè¨æ¨¡åä¸­çèªç¶èªè¨çè§£ï¼NLUï¼ï¼å®æä¾äºå°å»ºæ§ï¼Cxnsï¼ç­èªè¨åç´ ææ·åçæç¾©çè¦è§£ãCxG éå¸¸é©åæ­¤ç®çï¼å çºå®æä¾äºå»ºæ§ç®æ¨è©ééççè«åºç¤ãéäºè³æéç¶éä»ç´°å»ºæ§ï¼åå«ä¸å¤ªå¯è½åºç¾å¨é è¨ç·´è³æä¸­çç¯ä¾ï¼ä½å°äººé¡ä¾èªªå»ç´è§ä¸ææ¼çè§£ï¼å¾èè½å¤ é²è¡æ´æéå°æ§åæ´å¯é çè©éãæåçå¯¦é©éé»å¨æ¼ä¸æ¸¸èªç¶èªè¨æ¨è«åæ¨çä»»åï¼ééå°å¤§åèªè¨æ¨¡åå°éé 8 åç¨ç¹ç Cxns å³éçåºå±¤æç¾©ççè§£èäººé¡ççè§£é²è¡æ¯è¼ãçµæé¡¯ç¤ºï¼åç®¡å¤§åèªè¨æ¨¡åå±ç¤ºåºå°å»ºæ§è³è¨çæäºç¥è­ï¼ä½å³ä½¿æ¯åæ¬ GPT-o1 å¨å§çææ°æ¨¡åï¼å¨éäº Cxns å³éçæ½è±¡æç¾©ä¸ä»æå°é£ï¼éå¨æ¸¬è©¦å¥å­èå¶é è¨ç·´è³æä¸åçææ³ä¸­å¾å°è­æãæåèªçºï¼æ­¤é¡æ¡ä¾æä¾äºå°çå¯¦èªè¨çè§£æ´æºç¢ºçæ¸¬è©¦ï¼çªé¡¯äºå¤§åèªè¨æ¨¡åèªç¾©è½åä¸­çä¸»è¦éå¶ãæåå¬éäºæåçæ°ç©è³æéåç¸éå¯¦é©è³æï¼åæ¬æç¤ºåæ¨¡ååæã

##### **Multi-task retriever fine-tuning for domain-specific and efficient RAG**
2501.04652v1 by Patrice BÃ©chard, Orlando Marquez Ayala

Retrieval-Augmented Generation (RAG) has become ubiquitous when deploying
Large Language Models (LLMs), as it can address typical limitations such as
generating hallucinated or outdated information. However, when building
real-world RAG applications, practical issues arise. First, the retrieved
information is generally domain-specific. Since it is computationally expensive
to fine-tune LLMs, it is more feasible to fine-tune the retriever to improve
the quality of the data included in the LLM input. Second, as more applications
are deployed in the same real-world system, one cannot afford to deploy
separate retrievers. Moreover, these RAG applications normally retrieve
different kinds of data. Our solution is to instruction fine-tune a small
retriever encoder on a variety of domain-specific tasks to allow us to deploy
one encoder that can serve many use cases, thereby achieving low-cost,
scalability, and speed. We show how this encoder generalizes to out-of-domain
settings as well as to an unseen retrieval task on real-world enterprise use
cases.

æè¦ï¼æª¢ç´¢å¢å¼·çæï¼RAGï¼å¨é¨ç½²å¤§åèªè¨æ¨¡åï¼LLMï¼æå·²è®å¾ç¡èä¸å¨ï¼å çºå®å¯ä»¥è§£æ±ºå¸åçéå¶ï¼ä¾å¦çæå¹»è¦ºæéæçè³è¨ãç¶èï¼å¨å»ºæ§çå¯¦ä¸çç RAG æç¨ç¨å¼æï¼æåºç¾å¯¦éåé¡ãé¦åï¼æª¢ç´¢å°çè³è¨éå¸¸æ¯ç¹å®é åçãç±æ¼å¾®èª¿ LLM å¨è¨ç®ä¸å¾æè²´ï¼å æ­¤å¾®èª¿æª¢ç´¢å¨ä»¥æé« LLM è¼¸å¥ä¸­è³æåè³ªæ´å¯è¡ãå¶æ¬¡ï¼ç±æ¼å¨åä¸åçå¯¦ä¸çç³»çµ±ä¸­é¨ç½²äºæ´å¤æç¨ç¨å¼ï¼å æ­¤ç¡æ³è² æé¨ç½²ç¨ç«çæª¢ç´¢å¨ãæ­¤å¤ï¼éäº RAG æç¨ç¨å¼éå¸¸æª¢ç´¢ä¸åç¨®é¡çè³æãæåçè§£æ±ºæ¹æ¡æ¯å¨åç¨®ç¹å®é åçä»»åä¸å°å°åæª¢ç´¢å¨ç·¨ç¢¼å¨é²è¡æä»¤å¾®èª¿ï¼è®æåè½å¤ é¨ç½²ä¸åå¯ä»¥æåæ¼è¨±å¤ä½¿ç¨æ¡ä¾çç·¨ç¢¼å¨ï¼å¾èå¯¦ç¾ä½ææ¬ãå¯æ´åæ§åéåº¦ãæåå±ç¤ºäºéåç·¨ç¢¼å¨å¦ä½æ¨å»£å°é åå¤è¨­å®ï¼ä»¥åå¨çå¯¦ä¸ççä¼æ¥­ä½¿ç¨æ¡ä¾ä¸­å°æªè¦éçæª¢ç´¢ä»»åé²è¡æ¨å»£ã

##### **FlairGPT: Repurposing LLMs for Interior Designs**
2501.04648v1 by Gabrielle Littlefair, Niladri Shekhar Dutt, Niloy J. Mitra

Interior design involves the careful selection and arrangement of objects to
create an aesthetically pleasing, functional, and harmonized space that aligns
with the client's design brief. This task is particularly challenging, as a
successful design must not only incorporate all the necessary objects in a
cohesive style, but also ensure they are arranged in a way that maximizes
accessibility, while adhering to a variety of affordability and usage
considerations. Data-driven solutions have been proposed, but these are
typically room- or domain-specific and lack explainability in their design
design considerations used in producing the final layout. In this paper, we
investigate if large language models (LLMs) can be directly utilized for
interior design. While we find that LLMs are not yet capable of generating
complete layouts, they can be effectively leveraged in a structured manner,
inspired by the workflow of interior designers. By systematically probing LLMs,
we can reliably generate a list of objects along with relevant constraints that
guide their placement. We translate this information into a design layout
graph, which is then solved using an off-the-shelf constrained optimization
setup to generate the final layouts. We benchmark our algorithm in various
design configurations against existing LLM-based methods and human designs, and
evaluate the results using a variety of quantitative and qualitative metrics
along with user studies. In summary, we demonstrate that LLMs, when used in a
structured manner, can effectively generate diverse high-quality layouts,
making them a viable solution for creating large-scale virtual scenes. Project
webpage at https://flairgpt.github.io/

æè¦ï¼å®¤å§è¨­è¨æ¶åä»ç´°æé¸åå®æç©ä»¶ï¼ä»¥åµé ä¸åç¾è§ãå¯¦ç¨ä¸åè«§çç©ºéï¼ç¬¦åå®¢æ¶çè¨­è¨ç°¡å ±ãéé ä»»åç¹å¥å·æææ°æ§ï¼å çºæåçè¨­è¨ä¸åå¿é ä»¥ä¸è´çé¢¨æ ¼ç´å¥ææå¿è¦çç©ä»¶ï¼éå¿é ç¢ºä¿å®åçæåæ¹å¼è½æå¤§åå¯åæ§ï¼åæç¬¦ååç¨®è² æè½ååä½¿ç¨èéãå·²ç¶æåºäºè³æé©åçè§£æ±ºæ¹æ¡ï¼ä½éäºè§£æ±ºæ¹æ¡éå¸¸æ¯ç¹å®æ¼æ¿éæé åï¼èä¸ç¼ºä¹å¨ç¢çæçµä½å±ææä½¿ç¨çè¨­è¨èéçå¯è§£éæ§ãå¨æ¬æä¸­ï¼æåæ¢è¨å¤§åèªè¨æ¨¡å (LLM) æ¯å¦å¯ä»¥ç´æ¥ç¨æ¼å®¤å§è¨­è¨ãéç¶æåç¼ç¾ LLM å°æªè½å¤ ç¢çå®æ´çä½å±ï¼ä½å®åå¯ä»¥ææå°ä»¥çµæ§åçæ¹å¼å©ç¨ï¼éæä¾èªå®¤å§è¨­è¨å¸«çå·¥ä½æµç¨ãééç³»çµ±æ§å°æ¢æ¥ LLMï¼æåå¯ä»¥å¯é å°ç¢çä¸åç©ä»¶æ¸å®ï¼ä»¥åæå°å®åæ¾ç½®ä½ç½®çç¸å³ç´æãæåå°éäºè³è¨è½ææè¨­è¨ä½å±åï¼ç¶å¾ä½¿ç¨ç¾æçç´æå¼æä½³åè¨­å®ä¾è§£æ±ºï¼ä»¥ç¢çæçµä½å±ãæåå¨åç¨®è¨­è¨éç½®ä¸­å°æåçæ¼ç®æ³èç¾æçåºæ¼ LLM çæ¹æ³åäººé¡è¨­è¨é²è¡åºæºæ¸¬è©¦ï¼ä¸¦ä½¿ç¨åç¨®éååè³ªåææ¨ä»¥åä½¿ç¨èç ç©¶ä¾è©ä¼°çµæãç¸½ä¹ï¼æåè­æäº LLM å¨ä»¥çµæ§åçæ¹å¼ä½¿ç¨æï¼å¯ä»¥ææå°ç¢çå¤æ¨£åçé«åè³ªä½å±ï¼ä½¿å¶æçºåµé å¤§åèæ¬å ´æ¯çå¯è¡è§£æ±ºæ¹æ¡ãå°æ¡ç¶²é å¨ https://flairgpt.github.io/

##### **Knowledge Retrieval Based on Generative AI**
2501.04635v1 by Te-Lun Yang, Jyi-Shane Liu, Yuen-Hsien Tseng, Jyh-Shing Roger Jang

This study develops a question-answering system based on Retrieval-Augmented
Generation (RAG) using Chinese Wikipedia and Lawbank as retrieval sources.
Using TTQA and TMMLU+ as evaluation datasets, the system employs BGE-M3 for
dense vector retrieval to obtain highly relevant search results and
BGE-reranker to reorder these results based on query relevance. The most
pertinent retrieval outcomes serve as reference knowledge for a Large Language
Model (LLM), enhancing its ability to answer questions and establishing a
knowledge retrieval system grounded in generative AI.
  The system's effectiveness is assessed through a two-stage evaluation:
automatic and assisted performance evaluations. The automatic evaluation
calculates accuracy by comparing the model's auto-generated labels with ground
truth answers, measuring performance under standardized conditions without
human intervention. The assisted performance evaluation involves 20
finance-related multiple-choice questions answered by 20 participants without
financial backgrounds. Initially, participants answer independently. Later,
they receive system-generated reference information to assist in answering,
examining whether the system improves accuracy when assistance is provided.
  The main contributions of this research are: (1) Enhanced LLM Capability: By
integrating BGE-M3 and BGE-reranker, the system retrieves and reorders highly
relevant results, reduces hallucinations, and dynamically accesses authorized
or public knowledge sources. (2) Improved Data Privacy: A customized RAG
architecture enables local operation of the LLM, eliminating the need to send
private data to external servers. This approach enhances data security, reduces
reliance on commercial services, lowers operational costs, and mitigates
privacy risks.

æè¦ï¼<paragraph>æ¬ç ç©¶éç¼äºä¸ååç­ç³»çµ±ï¼è©²ç³»çµ±åºæ¼æª¢ç´¢å¢å¼·çæ (RAG)ï¼ä½¿ç¨ä¸­æç¶­åºç¾ç§å Lawbank ä½çºæª¢ç´¢ä¾æºãç³»çµ±ä½¿ç¨ TTQA å TMMLU+ ä½çºè©ä¼°è³æéï¼æ¡ç¨ BGE-M3 é²è¡ç¨ å¯åéæª¢ç´¢ï¼ä»¥åå¾é«åº¦ç¸éçæå°çµæï¼ä¸¦ä½¿ç¨ BGE-reranker æ ¹ææ¥è©¢ç¸éæ§å°éäºçµæéæ°æåºãæç¸éçæª¢ç´¢çµæä½çºå¤§åèªè¨æ¨¡å (LLM) çåèç¥è­ï¼å¢å¼·å¶åç­åé¡çè½åï¼ä¸¦å»ºç«ä¸ååºæ¼çæå¼ AI çç¥è­æª¢ç´¢ç³»çµ±ãç³»çµ±çæææ§ééå©éæ®µè©ä¼°ä¾è©ä¼°ï¼èªååè¼å©æ§è½è©ä¼°ãèªåè©ä¼°ééå°æ¨¡åèªåçæçæ¨ç±¤èçå¯¦ç­æ¡é²è¡æ¯è¼ä¾è¨ç®æºç¢ºæ§ï¼å¨æ²æäººå·¥å¹²é çææ³ä¸æ¸¬éæ¨æºåæ¢ä»¶ä¸çæ§è½ãè¼å©æ§è½è©ä¼°åæ¬ 20 åèéèç¸éçå¤é¸é¡ï¼ç± 20 åæ²æéèèæ¯çåèèåç­ãæåï¼åèèç¨ç«åç­ãç¨å¾ï¼ä»åææ¶å°ç³»çµ±çæçåèè³è¨ä»¥åå©åç­ï¼æª¢æ¥å¨æä¾åå©æç³»çµ±æ¯å¦è½æé«æºç¢ºæ§ãæ¬ç ç©¶çä¸»è¦è²¢ç»æï¼(1) å¢å¼·ç LLM è½åï¼ééæ´å BGE-M3 å BGE-rerankerï¼ç³»çµ±æª¢ç´¢åéæ°æåºé«åº¦ç¸éççµæï¼æ¸å°å¹»è¦ºï¼ä¸¦åæè¨ªåææ¬æå¬éçç¥è­ä¾æºã(2) æ¹åè³æé±ç§ï¼èªè¨ç RAG æ¶æ§åè¨± LLM æ¬å°éä½ï¼ç¡éå°ç§äººè³æå³éè³å¤é¨ä¼ºæå¨ãéç¨®æ¹æ³å¢å¼·äºè³æå®å¨æ§ï¼æ¸å°äºå°åæ¥­æåçä¾è³´ï¼éä½äºéçææ¬ï¼ä¸¦æ¸è¼äºé±ç§é¢¨éªã</paragraph>

