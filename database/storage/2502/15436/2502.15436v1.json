{"2502.15436": {"publish_time": "2025-02-21", "title": "Fed-SB: A Silver Bullet for Extreme Communication Efficiency and Performance in (Private) Federated LoRA Fine-Tuning", "paper_summary": "Low-Rank Adaptation (LoRA) has become ubiquitous for efficiently fine-tuning\nfoundation models. However, federated fine-tuning using LoRA is challenging due\nto suboptimal updates arising from traditional federated averaging of\nindividual adapters. Existing solutions either incur prohibitively high\ncommunication cost that scales linearly with the number of clients or suffer\nfrom performance degradation due to limited expressivity. We introduce\nFederated Silver Bullet (Fed-SB), a novel approach for federated fine-tuning of\nLLMs using LoRA-SB, a recently proposed low-rank adaptation method. LoRA-SB\noptimally aligns the optimization trajectory with the ideal low-rank full\nfine-tuning projection by learning a small square matrix (R) between adapters B\nand A, keeping other components fixed. Direct averaging of R guarantees exact\nupdates, substantially reducing communication cost, which remains independent\nof the number of clients, and enables scalability. Fed-SB achieves\nstate-of-the-art performance across commonsense reasoning, arithmetic\nreasoning, and language inference tasks while reducing communication costs by\nup to 230x. In private settings, Fed-SB further improves performance by (1)\nreducing trainable parameters, thereby lowering the noise required for\ndifferential privacy and (2) avoiding noise amplification introduced by other\nmethods. Overall, Fed-SB establishes a new Pareto frontier in the tradeoff\nbetween communication and performance, offering an efficient and scalable\nsolution for both private and non-private federated fine-tuning. Our code is\npublicly available at https://github.com/CERT-Lab/fed-sb.", "paper_summary_zh": "\u4f4e\u79e9\u9069\u61c9\uff08LoRA\uff09\u5df2\u6210\u70ba\u6709\u6548\u5fae\u8abf\u57fa\u790e\u6a21\u578b\u7684\u666e\u904d\u6280\u8853\u3002\u7136\u800c\uff0c\u7531\u65bc\u50b3\u7d71\u7684\u500b\u5225\u9069\u914d\u5668\u806f\u90a6\u5e73\u5747\u6703\u7522\u751f\u6b21\u512a\u66f4\u65b0\uff0c\u56e0\u6b64\u4f7f\u7528 LoRA \u9032\u884c\u806f\u90a6\u5fae\u8abf\u5177\u6709\u6311\u6230\u6027\u3002\u73fe\u6709\u89e3\u6c7a\u65b9\u6848\u4e0d\u662f\u5c0e\u81f4\u8207\u5ba2\u6236\u7aef\u6578\u91cf\u6210\u7dda\u6027\u6bd4\u4f8b\u7684\u904e\u9ad8\u901a\u8a0a\u6210\u672c\uff0c\u5c31\u662f\u7531\u65bc\u8868\u9054\u80fd\u529b\u6709\u9650\u800c\u5c0e\u81f4\u6548\u80fd\u4e0b\u964d\u3002\u6211\u5011\u5f15\u5165\u4e86\u806f\u90a6\u9280\u5f48\uff08Fed-SB\uff09\uff0c\u9019\u662f\u4e00\u7a2e\u4f7f\u7528 LoRA-SB\uff08\u4e00\u7a2e\u6700\u8fd1\u63d0\u51fa\u7684\u4f4e\u79e9\u9069\u61c9\u65b9\u6cd5\uff09\u5c0d LLM \u9032\u884c\u806f\u90a6\u5fae\u8abf\u7684\u65b0\u65b9\u6cd5\u3002LoRA-SB \u900f\u904e\u5728\u9069\u914d\u5668 B \u548c A \u4e4b\u9593\u5b78\u7fd2\u4e00\u500b\u5c0f\u65b9\u584a\u77e9\u9663\uff08R\uff09\uff0c\u4e26\u56fa\u5b9a\u5176\u4ed6\u7d44\u4ef6\uff0c\u5c07\u6700\u4f73\u5316\u8ecc\u8de1\u8207\u7406\u60f3\u7684\u4f4e\u79e9\u5b8c\u6574\u5fae\u8abf\u6295\u5f71\u6700\u4f73\u5c0d\u9f4a\u3002R \u7684\u76f4\u63a5\u5e73\u5747\u4fdd\u8b49\u4e86\u7cbe\u78ba\u66f4\u65b0\uff0c\u5927\u5e45\u964d\u4f4e\u4e86\u901a\u8a0a\u6210\u672c\uff0c\u800c\u901a\u8a0a\u6210\u672c\u8207\u5ba2\u6236\u7aef\u6578\u91cf\u7121\u95dc\uff0c\u4e26\u5be6\u73fe\u4e86\u53ef\u64f4\u5145\u6027\u3002Fed-SB \u5728\u5e38\u8b58\u63a8\u7406\u3001\u7b97\u8853\u63a8\u7406\u548c\u8a9e\u8a00\u63a8\u7406\u4efb\u52d9\u4e2d\u9054\u5230\u4e86\u6700\u5148\u9032\u7684\u6548\u80fd\uff0c\u540c\u6642\u5c07\u901a\u8a0a\u6210\u672c\u964d\u4f4e\u4e86 230 \u500d\u3002\u5728\u79c1\u6709\u8a2d\u5b9a\u4e2d\uff0cFed-SB \u9032\u4e00\u6b65\u900f\u904e\uff081\uff09\u6e1b\u5c11\u53ef\u8a13\u7df4\u53c3\u6578\uff0c\u5f9e\u800c\u964d\u4f4e\u5dee\u5206\u96b1\u79c1\u6240\u9700\u7684\u96dc\u8a0a\uff0c\u4ee5\u53ca\uff082\uff09\u907f\u514d\u5176\u4ed6\u65b9\u6cd5\u5f15\u5165\u7684\u96dc\u8a0a\u653e\u5927\uff0c\u4f86\u63d0\u5347\u6548\u80fd\u3002\u7e3d\u9ad4\u800c\u8a00\uff0cFed-SB \u5728\u901a\u8a0a\u548c\u6548\u80fd\u4e4b\u9593\u7684\u6b0a\u8861\u4e2d\u5efa\u7acb\u4e86\u4e00\u500b\u65b0\u7684\u5e15\u7d2f\u6258\u524d\u7de3\uff0c\u70ba\u79c1\u6709\u548c\u975e\u79c1\u6709\u806f\u90a6\u5fae\u8abf\u63d0\u4f9b\u4e86\u9ad8\u6548\u4e14\u53ef\u64f4\u5145\u7684\u89e3\u6c7a\u65b9\u6848\u3002\u6211\u5011\u7684\u7a0b\u5f0f\u78bc\u5df2\u516c\u958b\u65bc https://github.com/CERT-Lab/fed-sb\u3002", "author": "Raghav Singhal et.al.", "authors": "Raghav Singhal, Kaustubh Ponkshe, Rohit Vartak, Lav R. Varshney, Praneeth Vepakomma", "id": "2502.15436v1", "paper_url": "http://arxiv.org/abs/2502.15436v1", "repo": "https://github.com/CERT-Lab/fed-sb"}}