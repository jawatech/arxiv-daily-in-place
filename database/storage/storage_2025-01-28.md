# arxiv-daily
 Automated deployment @ 2025-01-28 09:12:01 Asia/Taipei
> Welcome to contribute! Add your topics and keywords in [`topic.yml`](https://github.com/jawatech/arxiv-daily-in-place/blob/main/database/topic.yml).
> You can also view historical data through the [storage](https://github.com/jawatech/arxiv-daily-in-place/blob/main/database/storage).

## AI

### Medical explainable AI
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2025-01-23**|**Ensuring Medical AI Safety: Explainable AI-Driven Detection and Mitigation of Spurious Model Behavior and Associated Data**|Frederik Pahde et.al.|[2501.13818v1](http://arxiv.org/abs/2501.13818v1)|[link](https://github.com/frederikpahde/medical-ai-safety)|
|**2025-01-19**|**Enhanced Suicidal Ideation Detection from Social Media Using a CNN-BiLSTM Hybrid Model**|Mohaiminul Islam Bhuiyan et.al.|[2501.11094v1](http://arxiv.org/abs/2501.11094v1)|null|
|**2025-01-17**|**SEANN: A Domain-Informed Neural Network for Epidemiological Insights**|Jean-Baptiste Guimbaud et.al.|[2501.10273v1](http://arxiv.org/abs/2501.10273v1)|null|
|**2025-01-16**|**Artificial Intelligence-Driven Clinical Decision Support Systems**|Muhammet Alkan et.al.|[2501.09628v1](http://arxiv.org/abs/2501.09628v1)|null|
|**2025-01-12**|**MedGrad E-CLIP: Enhancing Trust and Transparency in AI-Driven Skin Lesion Diagnosis**|Sadia Kamal et.al.|[2501.06887v1](http://arxiv.org/abs/2501.06887v1)|null|
|**2025-01-06**|**Explaining Humour Style Classifications: An XAI Approach to Understanding Computational Humour Analysis**|Mary Ogbuka Kenneth et.al.|[2501.02891v1](http://arxiv.org/abs/2501.02891v1)|null|
|**2024-12-28**|**The Emotional Spectrum of LLMs: Leveraging Empathy and Emotion-Based Markers for Mental Health Support**|Alessandro De Grandi et.al.|[2412.20068v1](http://arxiv.org/abs/2412.20068v1)|null|
|**2024-12-27**|**A Review on the Integration of Artificial Intelligence and Medical Imaging in IVF Ovarian Stimulation**|Jana Zakall et.al.|[2412.19688v1](http://arxiv.org/abs/2412.19688v1)|null|
|**2024-12-23**|**Enhancing Cancer Diagnosis with Explainable & Trustworthy Deep Learning Models**|Badaru I. Olumuyiwa et.al.|[2412.17527v1](http://arxiv.org/abs/2412.17527v1)|null|
|**2024-12-20**|**Towards Interpretable Radiology Report Generation via Concept Bottlenecks using a Multi-Agentic RAG**|Hasan Md Tusfiqur Alam et.al.|[2412.16086v2](http://arxiv.org/abs/2412.16086v2)|[link](https://github.com/tifat58/irr-with-cbm-rag)|
|**2024-12-20**|**Critique of Impure Reason: Unveiling the reasoning behaviour of medical Large Language Models**|Shamus Sim et.al.|[2412.15748v1](http://arxiv.org/abs/2412.15748v1)|null|
|**2024-12-18**|**Cognition Chain for Explainable Psychological Stress Detection on Social Media**|Xin Wang et.al.|[2412.14009v1](http://arxiv.org/abs/2412.14009v1)|null|
|**2024-11-30**|**2-Factor Retrieval for Improved Human-AI Decision Making in Radiology**|Jim Solomon et.al.|[2412.00372v1](http://arxiv.org/abs/2412.00372v1)|null|
|**2024-11-28**|**Mapping Public Perception of Artificial Intelligence: Expectations, Risk-Benefit Tradeoffs, and Value As Determinants for Societal Acceptance**|Philipp Brauner et.al.|[2411.19356v1](http://arxiv.org/abs/2411.19356v1)|null|
|**2024-11-26**|**Explainable AI for Classifying UTI Risk Groups Using a Real-World Linked EHR and Pathology Lab Dataset**|Yujie Dai et.al.|[2411.17645v2](http://arxiv.org/abs/2411.17645v2)|null|
|**2024-11-18**|**Exploring the Requirements of Clinicians for Explainable AI Decision Support Systems in Intensive Care**|Jeffrey N. Clark et.al.|[2411.11774v1](http://arxiv.org/abs/2411.11774v1)|null|
|**2024-11-15**|**Artificial Intelligence in Pediatric Echocardiography: Exploring Challenges, Opportunities, and Clinical Applications with Explainable AI and Federated Learning**|Mohammed Yaseen Jabarulla et.al.|[2411.10255v1](http://arxiv.org/abs/2411.10255v1)|null|
|**2024-11-01**|**Enhancing Osteoporosis Detection: An Explainable Multi-Modal Learning Framework with Feature Fusion and Variable Clustering**|Mehdi Hosseini Chagahi et.al.|[2411.00916v2](http://arxiv.org/abs/2411.00916v2)|null|
|**2024-10-25**|**A Review of Deep Learning Approaches for Non-Invasive Cognitive Impairment Detection**|Muath Alsuhaibani et.al.|[2410.19898v1](http://arxiv.org/abs/2410.19898v1)|null|
|**2024-10-23**|**An Ontology-Enabled Approach For User-Centered and Knowledge-Enabled Explanations of AI Systems**|Shruthi Chari et.al.|[2410.17504v1](http://arxiv.org/abs/2410.17504v1)|[link](https://github.com/tetherless-world/metaexplainer)|
|**2024-10-22**|**Contrasting Attitudes Towards Current and Future AI Applications for Computerised Interpretation of ECG: A Clinical Stakeholder Interview Study**|Lukas Hughes-Noehrer et.al.|[2410.16879v1](http://arxiv.org/abs/2410.16879v1)|null|
|**2024-10-19**|**Pathologist-like explainable AI for interpretable Gleason grading in prostate cancer**|Gesa Mittmann et.al.|[2410.15012v1](http://arxiv.org/abs/2410.15012v1)|null|
|**2024-10-15**|**Explainable AI Methods for Multi-Omics Analysis: A Survey**|Ahmad Hussein et.al.|[2410.11910v1](http://arxiv.org/abs/2410.11910v1)|null|
|**2024-10-14**|**Study on the Helpfulness of Explainable Artificial Intelligence**|Tobias Labarta et.al.|[2410.11896v1](http://arxiv.org/abs/2410.11896v1)|[link](https://github.com/tlabarta/helpfulnessofxai)|
|**2024-10-12**|**Use of What-if Scenarios to Help Explain Artificial Intelligence Models for Neonatal Health**|Abdullah Mamun et.al.|[2410.09635v1](http://arxiv.org/abs/2410.09635v1)|[link](https://github.com/ab9mamun/aimen)|
|**2024-10-10**|**Artificial intelligence techniques in inherited retinal diseases: A review**|Han Trinh et.al.|[2410.09105v1](http://arxiv.org/abs/2410.09105v1)|null|
|**2024-10-07**|**CasiMedicos-Arg: A Medical Question Answering Dataset Annotated with Explanatory Argumentative Structures**|Ekaterina Sviridova et.al.|[2410.05235v2](http://arxiv.org/abs/2410.05235v2)|[link](https://github.com/ixa-ehu/antidote-casimedicos)|
|**2024-10-01**|**Explainable Diagnosis Prediction through Neuro-Symbolic Integration**|Qiuhao Lu et.al.|[2410.01855v2](http://arxiv.org/abs/2410.01855v2)|null|
|**2024-10-01**|**Easydiagnos: a framework for accurate feature selection for automatic diagnosis in smart healthcare**|Prasenjit Maji et.al.|[2410.00366v1](http://arxiv.org/abs/2410.00366v1)|null|
|**2024-09-20**|**Dermatologist-like explainable AI enhances melanoma diagnosis accuracy: eye-tracking study**|Tirtha Chanda et.al.|[2409.13476v1](http://arxiv.org/abs/2409.13476v1)|null|
|**2024-09-19**|**Explainable AI for Autism Diagnosis: Identifying Critical Brain Regions Using fMRI Data**|Suryansh Vidya et.al.|[2409.15374v1](http://arxiv.org/abs/2409.15374v1)|null|
|**2024-09-19**|**Improving Prototypical Parts Abstraction for Case-Based Reasoning Explanations Designed for the Kidney Stone Type Recognition**|Daniel Flores-Araiza et.al.|[2409.12883v1](http://arxiv.org/abs/2409.12883v1)|null|
|**2024-09-18**|**Towards Interpretable End-Stage Renal Disease (ESRD) Prediction: Utilizing Administrative Claims Data with Explainable AI Techniques**|Yubo Li et.al.|[2409.12087v3](http://arxiv.org/abs/2409.12087v3)|null|
|**2024-09-13**|**Contextual Evaluation of Large Language Models for Classifying Tropical and Infectious Diseases**|Mercy Asiedu et.al.|[2409.09201v3](http://arxiv.org/abs/2409.09201v3)|null|
|**2024-09-09**|**Explainable AI: Definition and attributes of a good explanation for health AI**|Evangelia Kyrimi et.al.|[2409.15338v1](http://arxiv.org/abs/2409.15338v1)|null|
|**2024-08-30**|**Exploring the Effect of Explanation Content and Format on User Comprehension and Trust**|Antonio Rago et.al.|[2408.17401v1](http://arxiv.org/abs/2408.17401v1)|null|
|**2024-08-29**|**A Survey for Large Language Models in Biomedicine**|Chong Wang et.al.|[2409.00133v1](http://arxiv.org/abs/2409.00133v1)|null|
|**2024-08-27**|**Aligning XAI with EU Regulations for Smart Biomedical Devices: A Methodology for Compliance Analysis**|Francesco Sovrano et.al.|[2408.15121v1](http://arxiv.org/abs/2408.15121v1)|null|
|**2024-08-24**|**Towards Case-based Interpretability for Medical Federated Learning**|Laura Latorre et.al.|[2408.13626v1](http://arxiv.org/abs/2408.13626v1)|null|
|**2024-08-22**|**AI in radiological imaging of soft-tissue and bone tumours: a systematic review evaluating against CLAIM and FUTURE-AI guidelines**|Douwe J. Spaanderman et.al.|[2408.12491v1](http://arxiv.org/abs/2408.12491v1)|null|
|**2024-08-14**|**Evaluating Explainable AI Methods in Deep Learning Models for Early Detection of Cerebral Palsy**|Kimji N. Pellano et.al.|[2409.00001v1](http://arxiv.org/abs/2409.00001v1)|null|
|**2024-08-06**|**MicroXercise: A Micro-Level Comparative and Explainable System for Remote Physical Therapy**|Hanchen David Wang et.al.|[2408.11837v1](http://arxiv.org/abs/2408.11837v1)|null|
|**2024-08-05**|**The Literature Review Network: An Explainable Artificial Intelligence for Systematic Literature Reviews, Meta-analyses, and Method Development**|Joshua Morriss et.al.|[2408.05239v1](http://arxiv.org/abs/2408.05239v1)|null|
|**2024-08-05**|**Enhancing Medical Learning and Reasoning Systems: A Boxology-Based Comparative Analysis of Design Patterns**|Chi Him Ng et.al.|[2408.02709v1](http://arxiv.org/abs/2408.02709v1)|null|
|**2024-08-05**|**Bayesian Kolmogorov Arnold Networks (Bayesian_KANs): A Probabilistic Approach to Enhance Accuracy and Interpretability**|Masoud Muhammed Hassan et.al.|[2408.02706v1](http://arxiv.org/abs/2408.02706v1)|null|
|**2024-07-26**|**MLtoGAI: Semantic Web based with Machine Learning for Enhanced Disease Prediction and Personalized Recommendations using Generative AI**|Shyam Dongre et.al.|[2407.20284v1](http://arxiv.org/abs/2407.20284v1)|null|
|**2024-07-25**|**Introducing Î´-XAI: a novel sensitivity-based method for local AI explanations**|Alessandro De Carlo et.al.|[2407.18343v2](http://arxiv.org/abs/2407.18343v2)|null|
|**2024-07-24**|**Enhanced Deep Learning Methodologies and MRI Selection Techniques for Dementia Diagnosis in the Elderly Population**|Nikolaos Ntampakis et.al.|[2407.17324v2](http://arxiv.org/abs/2407.17324v2)|null|
|**2024-07-24**|**Using Large Language Models to Compare Explainable Models for Smart Home Human Activity Recognition**|Michele Fiori et.al.|[2408.06352v1](http://arxiv.org/abs/2408.06352v1)|null|
|**2024-07-21**|**Explainable AI-based Intrusion Detection System for Industry 5.0: An Overview of the Literature, associated Challenges, the existing Solutions, and Potential Research Directions**|Naseem Khan et.al.|[2408.03335v1](http://arxiv.org/abs/2408.03335v1)|null|
|**2024-07-18**|**A Comparative Study on Automatic Coding of Medical Letters with Explainability**|Jamie Glen et.al.|[2407.13638v1](http://arxiv.org/abs/2407.13638v1)|[link](https://github.com/Glenj01/Medical-Coding)|
|**2024-07-09**|**Explainable AI for Enhancing Efficiency of DL-based Channel Estimation**|Abdul Karim Gizzini et.al.|[2407.07009v1](http://arxiv.org/abs/2407.07009v1)|null|
|**2024-07-07**|**Explainable AI: Comparative Analysis of Normal and Dilated ResNet Models for Fundus Disease Classification**|P. N. Karthikayan et.al.|[2407.05440v2](http://arxiv.org/abs/2407.05440v2)|null|
|**2024-07-03**|**A Survey on Trustworthiness in Foundation Models for Medical Image Analysis**|Congzhen Shi et.al.|[2407.15851v2](http://arxiv.org/abs/2407.15851v2)|null|
|**2024-07-01**|**The Impact of an XAI-Augmented Approach on Binary Classification with Scarce Data**|Ximing Wen et.al.|[2407.06206v1](http://arxiv.org/abs/2407.06206v1)|null|
|**2024-06-28**|**Can GPT-4 Help Detect Quit Vaping Intentions? An Exploration of Automatic Data Annotation Approach**|Sai Krishna Revanth Vuruma et.al.|[2407.00167v1](http://arxiv.org/abs/2407.00167v1)|null|
|**2024-06-25**|**Towards Compositional Interpretability for XAI**|Sean Tull et.al.|[2406.17583v1](http://arxiv.org/abs/2406.17583v1)|null|
|**2024-06-17**|**Slicing Through Bias: Explaining Performance Gaps in Medical Image Analysis using Slice Discovery Methods**|Vincent Olesen et.al.|[2406.12142v2](http://arxiv.org/abs/2406.12142v2)|[link](https://github.com/volesen/slicing-through-bias)|
|**2024-06-11**|**Unlocking the Potential of Metaverse in Innovative and Immersive Digital Health**|Fatemeh Ebrahimzadeh et.al.|[2406.07114v2](http://arxiv.org/abs/2406.07114v2)|null|
|**2024-06-10**|**AI-Driven Predictive Analytics Approach for Early Prognosis of Chronic Kidney Disease Using Ensemble Learning and Explainable AI**|K M Tawsik Jawad et.al.|[2406.06728v1](http://arxiv.org/abs/2406.06728v1)|null|
|**2024-06-10**|**Explainable AI for Mental Disorder Detection via Social Media: A survey and outlook**|Yusif Ibrahimov et.al.|[2406.05984v1](http://arxiv.org/abs/2406.05984v1)|null|
|**2024-06-09**|**Methodology and Real-World Applications of Dynamic Uncertain Causality Graph for Clinical Diagnosis with Explainability and Invariance**|Zhan Zhang et.al.|[2406.05746v1](http://arxiv.org/abs/2406.05746v1)|null|
|**2024-06-07**|**Advancing Histopathology-Based Breast Cancer Diagnosis: Insights into Multi-Modality and Explainability**|Faseela Abdullakutty et.al.|[2406.12897v1](http://arxiv.org/abs/2406.12897v1)|null|
|**2024-06-04**|**Using Explainable AI for EEG-based Reduced Montage Neonatal Seizure Detection**|Dinuka Sandun Udayantha et.al.|[2406.16908v3](http://arxiv.org/abs/2406.16908v3)|[link](https://github.com/dinuka-1999/braineocare)|
|**2024-06-01**|**Breast Cancer Diagnosis: A Comprehensive Exploration of Explainable Artificial Intelligence (XAI) Techniques**|Samita Bai et.al.|[2406.00532v1](http://arxiv.org/abs/2406.00532v1)|null|
|**2024-06-01**|**Unveiling Hidden Factors: Explainable AI for Feature Boosting in Speech Emotion Recognition**|Alaa Nfissi et.al.|[2406.01624v2](http://arxiv.org/abs/2406.01624v2)|[link](https://github.com/alaanfissi/unveiling-hidden-factors-explainable-ai-for-feature-boosting-in-speech-emotion-recognition)|
|**2024-05-31**|**The Explanation Necessity for Healthcare AI**|Michail Mamalakis et.al.|[2406.00216v1](http://arxiv.org/abs/2406.00216v1)|null|
|**2024-05-29**|**Interdisciplinary Expertise to Advance Equitable Explainable AI**|Chloe R. Bennett et.al.|[2406.18563v1](http://arxiv.org/abs/2406.18563v1)|null|
|**2024-05-27**|**"It depends": Configuring AI to Improve Clinical Usefulness Across Contexts**|Hubert D. ZajÄc et.al.|[2407.11978v1](http://arxiv.org/abs/2407.11978v1)|null|
|**2024-05-26**|**Improving Health Professionals' Onboarding with AI and XAI for Trustworthy Human-AI Collaborative Decision Making**|Min Hun Lee et.al.|[2405.16424v1](http://arxiv.org/abs/2405.16424v1)|null|
|**2024-05-26**|**Exploring Nutritional Impact on Alzheimer's Mortality: An Explainable AI Approach**|Ziming Liu et.al.|[2405.17502v1](http://arxiv.org/abs/2405.17502v1)|null|
|**2024-05-24**|**Explainable AI Enhances Glaucoma Referrals, Yet the Human-AI Team Still Falls Short of the AI Alone**|Catalina Gomez et.al.|[2407.11974v1](http://arxiv.org/abs/2407.11974v1)|null|
|**2024-05-23**|**Decoding Decision Reasoning: A Counterfactual-Powered Model for Knowledge Discovery**|Yingying Fang et.al.|[2406.18552v1](http://arxiv.org/abs/2406.18552v1)|null|
|**2024-05-21**|**The Role of Emotions in Informational Support Question-Response Pairs in Online Health Communities: A Multimodal Deep Learning Approach**|Mohsen Jozani et.al.|[2405.13099v1](http://arxiv.org/abs/2405.13099v1)|null|
|**2024-05-17**|**ChatGPT in Classrooms: Transforming Challenges into Opportunities in Education**|Harris Bin Munawar et.al.|[2405.10645v1](http://arxiv.org/abs/2405.10645v1)|null|
|**2024-05-13**|**Evaluating the Explainable AI Method Grad-CAM for Breath Classification on Newborn Time Series Data**|Camelia Oprea et.al.|[2405.07590v1](http://arxiv.org/abs/2405.07590v1)|null|
|**2024-05-10**|**XAI4LLM. Let Machine Learning Models and LLMs Collaborate for Enhanced In-Context Learning in Healthcare**|Fatemeh Nazary et.al.|[2405.06270v3](http://arxiv.org/abs/2405.06270v3)|null|
|**2024-05-09**|**To Trust or Not to Trust: Towards a novel approach to measure trust for XAI systems**|Miquel MirÃ³-Nicolau et.al.|[2405.05766v1](http://arxiv.org/abs/2405.05766v1)|null|
|**2024-05-05**|**Region-specific Risk Quantification for Interpretable Prognosis of COVID-19**|Zhusi Zhong et.al.|[2405.02815v1](http://arxiv.org/abs/2405.02815v1)|[link](https://github.com/zzs95/RSP_COVID)|
|**2024-04-26**|**Rad4XCNN: a new agnostic method for post-hoc global explanation of CNN-derived features by means of radiomics**|Francesco Prinzi et.al.|[2405.02334v2](http://arxiv.org/abs/2405.02334v2)|null|
|**2024-04-25**|**Attributing Responsibility in AI-Induced Incidents: A Computational Reflective Equilibrium Framework for Accountability**|Yunfei Ge et.al.|[2404.16957v1](http://arxiv.org/abs/2404.16957v1)|null|
|**2024-04-19**|**Explainable AI for Fair Sepsis Mortality Predictive Model**|Chia-Hsuan Chang et.al.|[2404.13139v1](http://arxiv.org/abs/2404.13139v1)|null|
|**2024-04-19**|**Multi Class Depression Detection Through Tweets using Artificial Intelligence**|Muhammad Osama Nusrat et.al.|[2404.13104v1](http://arxiv.org/abs/2404.13104v1)|[link](https://github.com/mnusrat786/masters-thesis)|
|**2024-04-19**|**COIN: Counterfactual inpainting for weakly supervised semantic segmentation for medical images**|Dmytro Shvetsov et.al.|[2404.12832v2](http://arxiv.org/abs/2404.12832v2)|[link](https://github.com/dmytro-shvetsov/counterfactual-search)|
|**2024-04-15**|**Hybrid Intelligence for Digital Humanities**|Victor de Boer et.al.|[2406.15374v1](http://arxiv.org/abs/2406.15374v1)|null|
|**2024-04-14**|**Ethical Framework for Responsible Foundational Models in Medical Imaging**|Abhijit Das et.al.|[2406.11868v1](http://arxiv.org/abs/2406.11868v1)|null|
|**2024-04-09**|**Advancements in Radiomics and Artificial Intelligence for Thyroid Cancer Diagnosis**|Milad Yousefi et.al.|[2404.07239v1](http://arxiv.org/abs/2404.07239v1)|null|
|**2024-04-06**|**Predictive Modeling for Breast Cancer Classification in the Context of Bangladeshi Patients: A Supervised Machine Learning Approach with Explainable AI**|Taminul Islam et.al.|[2404.04686v1](http://arxiv.org/abs/2404.04686v1)|null|
|**2024-04-05**|**Enhancing Breast Cancer Diagnosis in Mammography: Evaluation and Integration of Convolutional Neural Networks and Explainable AI**|Maryam Ahmed et.al.|[2404.03892v3](http://arxiv.org/abs/2404.03892v3)|null|
|**2024-03-30**|**Advancing Multimodal Data Fusion in Pain Recognition: A Strategy Leveraging Statistical Correlation and Human-Centered Perspectives**|Xingrui Gu et.al.|[2404.00320v2](http://arxiv.org/abs/2404.00320v2)|null|
|**2024-03-26**|**Addressing Social Misattributions of Large Language Models: An HCXAI-based Approach**|Andrea Ferrario et.al.|[2403.17873v1](http://arxiv.org/abs/2403.17873v1)|null|
|**2024-03-26**|**Clinical Domain Knowledge-Derived Template Improves Post Hoc AI Explanations in Pneumothorax Classification**|Han Yuan et.al.|[2403.18871v1](http://arxiv.org/abs/2403.18871v1)|[link](https://github.com/han-yuan-med/template-explanation)|
|**2024-03-03**|**Enhancing Neural Machine Translation of Low-Resource Languages: Corpus Development, Human Evaluation and Explainable AI Architectures**|SÃ©amus Lankford et.al.|[2403.01580v1](http://arxiv.org/abs/2403.01580v1)|null|
|**2024-02-28**|**Cause and Effect: Can Large Language Models Truly Understand Causality?**|Swagata Ashwani et.al.|[2402.18139v3](http://arxiv.org/abs/2402.18139v3)|null|
|**2024-02-28**|**Artificial Intelligence and Diabetes Mellitus: An Inside Look Through the Retina**|Yasin Sadeghi Bazargani et.al.|[2402.18600v1](http://arxiv.org/abs/2402.18600v1)|null|
|**2024-02-22**|**Multi-stakeholder Perspective on Responsible Artificial Intelligence and Acceptability in Education**|A. J. Karran et.al.|[2402.15027v2](http://arxiv.org/abs/2402.15027v2)|null|
|**2024-02-12**|**Deciphering Heartbeat Signatures: A Vision Transformer Approach to Explainable Atrial Fibrillation Detection from ECG Signals**|Aruna Mohan et.al.|[2402.09474v2](http://arxiv.org/abs/2402.09474v2)|null|
|**2024-02-05**|**Illuminate: A novel approach for depression detection with explainable analysis and proactive therapy using prompt engineering**|Aryan Agrawal et.al.|[2402.05127v1](http://arxiv.org/abs/2402.05127v1)|null|
|**2024-01-24**|**Information That Matters: Exploring Information Needs of People Affected by Algorithmic Decisions**|TimothÃ©e Schmude et.al.|[2401.13324v6](http://arxiv.org/abs/2401.13324v6)|null|
|**2024-01-02**|**Evaluating Large Language Models on the GMAT: Implications for the Future of Business Education**|Vahid Ashrafimoghari et.al.|[2401.02985v1](http://arxiv.org/abs/2401.02985v1)|null|

#### Abstracts
##### **Ensuring Medical AI Safety: Explainable AI-Driven Detection and Mitigation of Spurious Model Behavior and Associated Data**
2501.13818v1 by Frederik Pahde, Thomas Wiegand, Sebastian Lapuschkin, Wojciech Samek

Deep neural networks are increasingly employed in high-stakes medical
applications, despite their tendency for shortcut learning in the presence of
spurious correlations, which can have potentially fatal consequences in
practice. Detecting and mitigating shortcut behavior is a challenging task that
often requires significant labeling efforts from domain experts. To alleviate
this problem, we introduce a semi-automated framework for the identification of
spurious behavior from both data and model perspective by leveraging insights
from eXplainable Artificial Intelligence (XAI). This allows the retrieval of
spurious data points and the detection of model circuits that encode the
associated prediction rules. Moreover, we demonstrate how these shortcut
encodings can be used for XAI-based sample- and pixel-level data annotation,
providing valuable information for bias mitigation methods to unlearn the
undesired shortcut behavior. We show the applicability of our framework using
four medical datasets across two modalities, featuring controlled and
real-world spurious correlations caused by data artifacts. We successfully
identify and mitigate these biases in VGG16, ResNet50, and contemporary Vision
Transformer models, ultimately increasing their robustness and applicability
for real-world medical tasks.

æè¦ï¼æ·±åº¦ç¥ç»ç½ç»è¶æ¥è¶å¤å°ç¨äºé«é£é©å»çåºç¨ä¸­ï¼å°½ç®¡å®ä»¬å¨å­å¨èåç¸å³æ§çæåµä¸å¾åäºæ·å¾å­¦ä¹ ï¼è¿å¨å®è·µä¸­å¯è½äº§çè´å½çåæãæ£æµåç¼è§£æ·å¾è¡ä¸ºæ¯ä¸é¡¹è°å·¨çä»»å¡ï¼éå¸¸éè¦é¢åä¸å®¶çå¤§éæ è®°å·¥ä½ãä¸ºäºç¼è§£è¿ä¸ªé®é¢ï¼æä»¬å¼å¥äºä¸ä¸ªåèªå¨æ¡æ¶ï¼ç¨äºä»æ°æ®åæ¨¡åçè§åº¦è¯å«èåè¡ä¸ºï¼æ¹æ³æ¯å©ç¨å¯è§£éäººå·¥æºè½ (XAI) çè§è§£ãè¿åè®¸æ£ç´¢èåæ°æ®ç¹å¹¶æ£æµå¯¹å³èé¢æµè§åè¿è¡ç¼ç çæ¨¡åçµè·¯ãæ­¤å¤ï¼æä»¬æ¼ç¤ºäºå¦ä½ä½¿ç¨è¿äºæ·å¾ç¼ç è¿è¡åºäº XAI çæ ·æ¬ååç´ çº§æ°æ®æ³¨éï¼ä¸ºåå·®ç¼è§£æ¹æ³æä¾æä»·å¼çä¿¡æ¯ï¼ä»¥æ¶é¤ä¸éè¦çæ·å¾è¡ä¸ºãæä»¬ä½¿ç¨è·¨è¶ä¸¤ç§æ¹å¼çåä¸ªå»å­¦æ°æ®éå±ç¤ºäºæä»¬æ¡æ¶çéç¨æ§ï¼è¿äºæ°æ®éå·æç±æ°æ®ä¼ªåå¼èµ·çåæ§åçå®ä¸çèåç¸å³æ§ãæä»¬æåå°è¯å«å¹¶åè½»äº VGG16ãResNet50 åå½ä»£ Vision Transformer æ¨¡åä¸­çè¿äºåå·®ï¼æç»æé«äºå®ä»¬çé²æ£æ§åå¨çå®ä¸çå»çä»»å¡ä¸­çéç¨æ§ã

##### **Enhanced Suicidal Ideation Detection from Social Media Using a CNN-BiLSTM Hybrid Model**
2501.11094v1 by Mohaiminul Islam Bhuiyan, Nur Shazwani Kamarudin, Nur Hafieza Ismail

Suicidal ideation detection is crucial for preventing suicides, a leading
cause of death worldwide. Many individuals express suicidal thoughts on social
media, offering a vital opportunity for early detection through advanced
machine learning techniques. The identification of suicidal ideation in social
media text is improved by utilising a hybrid framework that integrates
Convolutional Neural Networks (CNN) and Bidirectional Long Short-Term Memory
(BiLSTM), enhanced with an attention mechanism. To enhance the interpretability
of the model's predictions, Explainable AI (XAI) methods are applied, with a
particular focus on SHapley Additive exPlanations (SHAP), are incorporated. At
first, the model managed to reach an accuracy of 92.81%. By applying
fine-tuning and early stopping techniques, the accuracy improved to 94.29%. The
SHAP analysis revealed key features influencing the model's predictions, such
as terms related to mental health struggles. This level of transparency boosts
the model's credibility while helping mental health professionals understand
and trust the predictions. This work highlights the potential for improving the
accuracy and interpretability of detecting suicidal tendencies, making a
valuable contribution to the progress of mental health monitoring systems. It
emphasizes the significance of blending powerful machine learning methods with
explainability to develop reliable and impactful mental health solutions.

æè¦ï¼èªæ®ºæå¿µåµæ¸¬å°æ¼é é²èªæ®ºè³ééè¦ï¼èèªæ®ºæ¯å¨çä¸»è¦çæ­»äº¡åå ãè¨±å¤äººå¨ç¤¾ç¾¤åªé«ä¸è¡¨éèªæ®ºå¿µé ­ï¼éæä¾äºééé²éæ©å¨å­¸ç¿æè¡é²è¡æ©æåµæ¸¬çéè¦æ©æãééæ´åå·ç©ç¥ç¶ç¶²è·¯ (CNN) åéåé·ç­æè¨æ¶ (BiLSTM) çæ··åæ¶æ§ï¼ä¸¦å å¥æ³¨æåæ©å¶ï¼å¯ä»¥æåå¨ç¤¾ç¾¤åªé«æå­ä¸­è¾¨è­èªæ®ºæå¿µçè½åãçºäºå å¼·æ¨¡åé æ¸¬çå¯è§£éæ§ï¼æåæ¡ç¨å¯è§£éäººå·¥æºæ§ (XAI) æ¹æ³ï¼ç¹å¥èéæ¼ SHapley å æ³è§£é (SHAP)ãä¸éå§ï¼æ¨¡åæåéå° 92.81% çæºç¢ºåº¦ãééå¥ç¨å¾®èª¿åæ©æåæ­¢æè¡ï¼æºç¢ºåº¦æåè³ 94.29%ãSHAP åææ­é²äºå½±é¿æ¨¡åé æ¸¬çééµç¹å¾µï¼ä¾å¦èå¿çå¥åº·å°å¢ç¸éçè©å½ãéç¨®éæåº¦æåäºæ¨¡åçå¯ä¿¡åº¦ï¼åæåå©å¿çå¥åº·å°æ¥­äººå¡çè§£åä¿¡è³´é æ¸¬çµæãéé å·¥ä½çªé¡¯äºæååµæ¸¬èªæ®ºå¾åçæºç¢ºåº¦åå¯è§£éæ§çæ½åï¼çºå¿çå¥åº·ç£æ§ç³»çµ±çé²å±ååºå¯¶è²´çè²¢ç»ãå®å¼·èª¿äºå°å¼·å¤§çæ©å¨å­¸ç¿æ¹æ³èå¯è§£éæ§ç¸çµåä»¥éç¼å¯é ä¸æå½±é¿åçå¿çå¥åº·è§£æ±ºæ¹æ¡çéè¦æ§ã

##### **SEANN: A Domain-Informed Neural Network for Epidemiological Insights**
2501.10273v1 by Jean-Baptiste Guimbaud, Marc Plantevit, LÃ©a MaÃ®tre, RÃ©my Cazabet

In epidemiology, traditional statistical methods such as logistic regression,
linear regression, and other parametric models are commonly employed to
investigate associations between predictors and health outcomes. However,
non-parametric machine learning techniques, such as deep neural networks
(DNNs), coupled with explainable AI (XAI) tools, offer new opportunities for
this task. Despite their potential, these methods face challenges due to the
limited availability of high-quality, high-quantity data in this field. To
address these challenges, we introduce SEANN, a novel approach for informed
DNNs that leverages a prevalent form of domain-specific knowledge: Pooled
Effect Sizes (PES). PESs are commonly found in published Meta-Analysis studies,
in different forms, and represent a quantitative form of a scientific
consensus. By direct integration within the learning procedure using a custom
loss, we experimentally demonstrate significant improvements in the
generalizability of predictive performances and the scientific plausibility of
extracted relationships compared to a domain-knowledge agnostic neural network
in a scarce and noisy data setting.

æè¦ï¼å¨æµè¡çå­¸ä¸­ï¼å³çµ±ççµ±è¨æ¹æ³ï¼ä¾å¦éè¼¯è¿´æ­¸ãç·æ§è¿´æ­¸åå¶ä»åæ¸æ¨¡åéå¸¸ç¨æ¼èª¿æ¥é æ¸¬å å­èå¥åº·çµæä¹éçéè¯ãç¶èï¼éåæ¸æ©å¨å­¸ç¿æè¡ï¼ä¾å¦æ·±åº¦ç¥ç¶ç¶²è·¯ (DNN)ï¼çµåå¯è§£éç AI (XAI) å·¥å·ï¼çºéé ä»»åæä¾äºæ°çæ©æãåç®¡éäºæ¹æ³å·ææ½åï¼ä½ç±æ¼è©²é åç¼ºä¹é«åè³ªãé«æ¸éè³æï¼å æ­¤éäºæ¹æ³é¢è¨ææ°ãçºäºæå°éäºææ°ï¼æåå¼å¥äº SEANNï¼éæ¯ä¸ç¨®æ°ç©çæ¹æ³ï¼ç¨æ¼ç²åç¥è­ç DNNï¼å®å©ç¨äºä¸ç¨®æµè¡çé åç¹å®ç¥è­å½¢å¼ï¼å½ç¸½ææé (PES)ãPES éå¸¸ä»¥ä¸åçå½¢å¼åºç¾å¨å·²ç¼è¡¨ç Meta åæç ç©¶ä¸­ï¼ä¸¦ä»£è¡¨ç§å­¸å±è­çéåå½¢å¼ãééä½¿ç¨èªè¨æå¤±å½æ¸ç´æ¥æ´åå¨å­¸ç¿ç¨åºä¸­ï¼æåä»¥å¯¦é©æ¹å¼è­æäºé æ¸¬æè½çæ¦æ¬æ§ä»¥åèå¾ç¼ºä¹é åç¥è­çç¥ç¶ç¶²è·¯ä¸­æåçéä¿ç¸æ¯ï¼ç§å­¸åçæ§çé¡¯èæåï¼ä¸æ¯å¨ç¨å°ä¸æéè¨çè³æè¨­å®ä¸­ã

##### **Artificial Intelligence-Driven Clinical Decision Support Systems**
2501.09628v1 by Muhammet Alkan, Idris Zakariyya, Samuel Leighton, Kaushik Bhargav Sivangi, Christos Anagnostopoulos, Fani Deligianni

As artificial intelligence (AI) becomes increasingly embedded in healthcare
delivery, this chapter explores the critical aspects of developing reliable and
ethical Clinical Decision Support Systems (CDSS). Beginning with the
fundamental transition from traditional statistical models to sophisticated
machine learning approaches, this work examines rigorous validation strategies
and performance assessment methods, including the crucial role of model
calibration and decision curve analysis. The chapter emphasizes that creating
trustworthy AI systems in healthcare requires more than just technical
accuracy; it demands careful consideration of fairness, explainability, and
privacy. The challenge of ensuring equitable healthcare delivery through AI is
stressed, discussing methods to identify and mitigate bias in clinical
predictive models. The chapter then delves into explainability as a cornerstone
of human-centered CDSS. This focus reflects the understanding that healthcare
professionals must not only trust AI recommendations but also comprehend their
underlying reasoning. The discussion advances in an analysis of privacy
vulnerabilities in medical AI systems, from data leakage in deep learning
models to sophisticated attacks against model explanations. The text explores
privacy-preservation strategies such as differential privacy and federated
learning, while acknowledging the inherent trade-offs between privacy
protection and model performance. This progression, from technical validation
to ethical considerations, reflects the multifaceted challenges of developing
AI systems that can be seamlessly and reliably integrated into daily clinical
practice while maintaining the highest standards of patient care and data
protection.

æè¦ï¼é¨èäººå·¥æºæ§ (AI) å¨é«çä¿å¥ä¸­çæç¨æ¥çæ®åï¼æ¬ç« æ¢è¨äºéç¼å¯é ä¸ç¬¦åéå¾·æ¨æºçè¨åºæ±ºç­æ¯æ´ç³»çµ± (CDSS) çééµé¢åãå¾å³çµ±çµ±è¨æ¨¡åå°è¤éæ©å¨å­¸ç¿æ¹æ³çåºæ¬è½è®éå§ï¼éé å·¥ä½å¯©æ¥äºå´è¬¹çé©è­ç­ç¥åæè½è©ä¼°æ¹æ³ï¼åæ¬æ¨¡åæ ¡æºåæ±ºç­æ²ç·åæçééµè§è²ãæ¬ç« å¼·èª¿ï¼å¨é«çä¿å¥ä¸­å»ºç«å¼å¾ä¿¡è³´ç AI ç³»çµ±ä¸åªæ¯æè¡ä¸çæºç¢ºæ§ï¼å®éè¦ä»ç´°èéå¬å¹³æ§ãå¯è§£éæ§åé±ç§æ¬ãæ¬ç« å¼·èª¿äºéé AI ç¢ºä¿å¬å¹³çé«çä¿å¥æåçææ°ï¼ä¸¦è¨è«äºè­å¥åæ¸è¼è¨åºé æ¸¬æ¨¡åä¸­åå·®çæ¹æ³ãæ¥èï¼æ¬ç« æ·±å¥æ¢è¨å¯è§£éæ§ï¼ä½çºä»¥äººçºä¸­å¿ç CDSS çåºç³ãéç¨®éæ³¨åæ äºé«çä¿å¥å°æ¥­äººå¡ä¸åå¿é ä¿¡ä»» AI å»ºè­°ï¼éå¿é çè§£å¶èå¾çæ¨çãè¨è«é²ä¸æ­¥åæäºé«ç AI ç³»çµ±ä¸­çé±ç§æ¼æ´ï¼å¾æ·±åº¦å­¸ç¿æ¨¡åä¸­çè³æå¤æ´©å°éå°æ¨¡åè§£éçè¤éæ»æãæ¬ææ¢è¨äºé±ç§ä¿è­·ç­ç¥ï¼ä¾å¦å·®åé±ç§åè¯åå­¸ç¿ï¼åææ¿èªé±ç§ä¿è­·åæ¨¡åæè½ä¹éçåºæåæ¨ãéç¨®å¾æè¡é©è­å°éå¾·èéçé²å±ï¼åæ äºéç¼ AI ç³»çµ±çå¤é¢åææ°ï¼éäºç³»çµ±å¯ä»¥ç¡ç¸«ä¸å¯é å°æ´åå°æ¥å¸¸è¨åºå¯¦åä¸­ï¼åæç¶­ææé«ççæ£ç§è­·åè³æä¿è­·æ¨æºã

##### **MedGrad E-CLIP: Enhancing Trust and Transparency in AI-Driven Skin Lesion Diagnosis**
2501.06887v1 by Sadia Kamal, Tim Oates

As deep learning models gain attraction in medical data, ensuring transparent
and trustworthy decision-making is essential. In skin cancer diagnosis, while
advancements in lesion detection and classification have improved accuracy, the
black-box nature of these methods poses challenges in understanding their
decision processes, leading to trust issues among physicians. This study
leverages the CLIP (Contrastive Language-Image Pretraining) model, trained on
different skin lesion datasets, to capture meaningful relationships between
visual features and diagnostic criteria terms. To further enhance transparency,
we propose a method called MedGrad E-CLIP, which builds on gradient-based
E-CLIP by incorporating a weighted entropy mechanism designed for complex
medical imaging like skin lesions. This approach highlights critical image
regions linked to specific diagnostic descriptions. The developed integrated
pipeline not only classifies skin lesions by matching corresponding
descriptions but also adds an essential layer of explainability developed
especially for medical data. By visually explaining how different features in
an image relates to diagnostic criteria, this approach demonstrates the
potential of advanced vision-language models in medical image analysis,
ultimately improving transparency, robustness, and trust in AI-driven
diagnostic systems.

æè¦ï¼éçæ·±åº¦å­¦ä¹ æ¨¡åå¨å»å­¦æ°æ®ä¸­è·å¾å³æ³¨ï¼ç¡®ä¿éæä¸å¼å¾ä¿¡èµçå³ç­è³å³éè¦ãå¨ç®è¤çè¯æ­ä¸­ï¼è½ç¶çç¶æ£æµååç±»çè¿æ­¥æé«äºåç¡®æ§ï¼ä½è¿äºæ¹æ³çé»çæ§è´¨å¯¹çè§£å¶å³ç­è¿ç¨ææäºææï¼å¯¼è´å»çä¹é´çä¿¡ä»»é®é¢ãæ¬ç ç©¶å©ç¨å¨ä¸åç®è¤çåæ°æ®éä¸è®­ç»ç CLIPï¼å¯¹æ¯è¯­è¨å¾åé¢è®­ç»ï¼æ¨¡åï¼ä»¥ææè§è§ç¹å¾åè¯æ­æ åæ¯è¯­ä¹é´çææä¹å³ç³»ãä¸ºäºè¿ä¸æ­¥æé«éæåº¦ï¼æä»¬æåºäºä¸ç§åä¸º MedGrad E-CLIP çæ¹æ³ï¼è¯¥æ¹æ³éè¿ç»åä¸ä¸ºç®è¤çåç­å¤æå»å­¦å½±åè®¾è®¡çå æçµæºå¶ï¼å»ºç«å¨åºäºæ¢¯åº¦ç E-CLIP ä¹ä¸ãæ­¤æ¹æ³çªåºäºä¸ç¹å®è¯æ­æè¿°ç¸å³èçå³é®å¾ååºåãå¼åçéæç®¡éä¸ä»éè¿å¹éç¸åºçæè¿°å¯¹ç®è¤çåè¿è¡åç±»ï¼è¿æ·»å äºä¸å±ä¸é¨ä¸ºå»å­¦æ°æ®å¼åçåºæ¬å¯è§£éæ§ãéè¿ç´è§å°è§£éå¾åä¸­ä¸åç¹å¾ä¸è¯æ­æ åçå³ç³»ï¼è¿ç§æ¹æ³å±ç¤ºäºé«çº§è§è§è¯­è¨æ¨¡åå¨å»å­¦å¾ååæä¸­çæ½åï¼æç»æé«äºéæåº¦ãç¨³å¥æ§åå¯¹äººå·¥æºè½é©±å¨çè¯æ­ç³»ç»çä¿¡ä»»ã

##### **Explaining Humour Style Classifications: An XAI Approach to Understanding Computational Humour Analysis**
2501.02891v1 by Mary Ogbuka Kenneth, Foaad Khosmood, Abbas Edalat

Humour styles can have either a negative or a positive impact on well-being.
Given the importance of these styles to mental health, significant research has
been conducted on their automatic identification. However, the automated
machine learning models used for this purpose are black boxes, making their
prediction decisions opaque. Clarity and transparency are vital in the field of
mental health. This paper presents an explainable AI (XAI) framework for
understanding humour style classification, building upon previous work in
computational humour analysis. Using the best-performing single model
(ALI+XGBoost) from prior research, we apply comprehensive XAI techniques to
analyse how linguistic, emotional, and semantic features contribute to humour
style classification decisions. Our analysis reveals distinct patterns in how
different humour styles are characterised and misclassified, with particular
emphasis on the challenges in distinguishing affiliative humour from other
styles. Through detailed examination of feature importance, error patterns, and
misclassification cases, we identify key factors influencing model decisions,
including emotional ambiguity, context misinterpretation, and target
identification. The framework demonstrates significant utility in understanding
model behaviour, achieving interpretable insights into the complex interplay of
features that define different humour styles. Our findings contribute to both
the theoretical understanding of computational humour analysis and practical
applications in mental health, content moderation, and digital humanities
research.

æè¦ï¼å¹½é»é¢¨æ ¼å°å¹¸ç¦æå¯è½ç¢çè² é¢ææ­£é¢çå½±é¿ã
éæ¼éäºé¢¨æ ¼å°å¿çå¥åº·çéè¦æ§ï¼å·²ç¶å°å¶èªåè­å¥é²è¡äºå¤§éç ç©¶ãç¶èï¼ç¨æ¼æ­¤ç®ççèªåæ©å¨å­¸ç¿æ¨¡åæ¯é»çå­ï¼ä½¿å¾å¶é æ¸¬æ±ºç­ä¸éæãæ¸æ°åº¦åéæåº¦å¨å¿çå¥åº·é åè³ééè¦ãæ¬ææåºäºä¸åå¯è§£éç AI (XAI) æ¡æ¶ï¼ç¨æ¼çè§£å¹½é»é¢¨æ ¼åé¡ï¼å»ºç«å¨è¨ç®å¹½é»åæçååå·¥ä½ä¹ä¸ãä½¿ç¨ååç ç©¶ä¸­è¡¨ç¾æå¥½çå®ä¸æ¨¡å (ALI+XGBoost)ï¼æåæç¨å¨é¢ç XAI æè¡ä¾åæèªè¨ãæç·åèªç¾©ç¹å¾µå¦ä½å½±é¿å¹½é»é¢¨æ ¼åé¡æ±ºç­ãæåçåææ­ç¤ºäºä¸åå¹½é»é¢¨æ ¼å¦ä½è¢«è¡¨å¾µåé¯èª¤åé¡çä¸åæ¨¡å¼ï¼ç¹å¥å¼·èª¿äºååè¯å±¬å¹½é»èå¶ä»é¢¨æ ¼çææ°ãééä»ç´°æª¢æ¥ç¹å¾µéè¦æ§ãé¯èª¤æ¨¡å¼åé¯èª¤åé¡æ¡ä¾ï¼æåç¢ºå®äºå½±é¿æ¨¡åæ±ºç­çééµå ç´ ï¼åæ¬æç·æ¨¡ç³ãæå¢èª¤è§£åç®æ¨è­å¥ãè©²æ¡æ¶å±ç¤ºäºå¨çè§£æ¨¡åè¡çºæ¹é¢çé¡¯èæç¨ï¼å¯¦ç¾äºå°å®ç¾©ä¸åå¹½é»é¢¨æ ¼çç¹å¾µä¹éè¤éç¸äºä½ç¨çå¯è§£éè¦è§£ãæåçç¼ç¾æå©æ¼è¨ç®å¹½é»åæççè«çè§£åå¿çå¥åº·ãå§å®¹å¯©æ ¸åæ¸å­äººæç ç©¶ä¸­çå¯¦éæç¨ã

##### **The Emotional Spectrum of LLMs: Leveraging Empathy and Emotion-Based Markers for Mental Health Support**
2412.20068v1 by Alessandro De Grandi, Federico Ravenda, Andrea Raballo, Fabio Crestani

The increasing demand for mental health services has highlighted the need for
innovative solutions, particularly in the realm of psychological conversational
AI, where the availability of sensitive data is scarce. In this work, we
explored the development of a system tailored for mental health support with a
novel approach to psychological assessment based on explainable emotional
profiles in combination with empathetic conversational models, offering a
promising tool for augmenting traditional care, particularly where immediate
expertise is unavailable. Our work can be divided into two main parts,
intrinsecaly connected to each other. First, we present RACLETTE, a
conversational system that demonstrates superior emotional accuracy compared to
state-of-the-art benchmarks in both understanding users' emotional states and
generating empathetic responses during conversations, while progressively
building an emotional profile of the user through their interactions. Second,
we show how the emotional profiles of a user can be used as interpretable
markers for mental health assessment. These profiles can be compared with
characteristic emotional patterns associated with different mental disorders,
providing a novel approach to preliminary screening and support.

æè¦ï¼é¨èå°å¿çå¥åº·æåéæ±çå¢å ï¼å¸é¡¯äºåµæ°è§£æ±ºæ¹æ¡çéæ±ï¼ç¹å¥æ¯å¨å¿çå°è©±å¼äººå·¥æºæ§é åï¼é£è£¡ç¼ºä¹ææè³æãå¨éé å·¥ä½ä¸­ï¼æåæ¢ç´¢äºéç¼ä¸åéå°å¿çå¥åº·æ¯æçç³»çµ±ï¼æ¡ç¨ä¸ç¨®åºæ¼å¯è§£éçæç·ç¹å¾µçæ°æ¹æ³é²è¡å¿çè©ä¼°ï¼çµååçå¿å°è©±æ¨¡å¼ï¼æä¾äºä¸åæåéçå·¥å·ï¼ç¨æ¼æ´åå³çµ±ç§è­·ï¼ç¹å¥æ¯å¨ç¡æ³ç«å³ç²å¾å°æ¥­ç¥è­çææ³ä¸ãæåçå·¥ä½å¯ä»¥åçºå©åä¸»è¦é¨åï¼å½¼æ­¤å§å¨ç¸éãé¦åï¼æåå±ç¤ºäº RACLETTEï¼ä¸åå°è©±ç³»çµ±ï¼èæåé²çåºæºç¸æ¯ï¼å¨çè§£ä½¿ç¨èæç·çæåå¨å°è©±ä¸­ç¢çåçå¿åææ¹é¢è¡¨ç¾åºåªè¶çæç·æºç¢ºæ§ï¼åæééä»åçäºåéæ¼¸å»ºç«ä½¿ç¨èçæç·ç¹å¾µãå¶æ¬¡ï¼æåå±ç¤ºäºä½¿ç¨èçæç·ç¹å¾µå¦ä½å¯ç¨ä½å¿çå¥åº·è©ä¼°çå¯è§£éæ¨è¨ãéäºç¹å¾µå¯ä»¥èèä¸åå¿çç¾çç¸éçå¸åæç·æ¨¡å¼é²è¡æ¯è¼ï¼æä¾äºä¸ç¨®åæ­¥ç¯©é¸åæ¯æçæ°æ¹æ³ã

##### **A Review on the Integration of Artificial Intelligence and Medical Imaging in IVF Ovarian Stimulation**
2412.19688v1 by Jana Zakall, Birgit Pohn, Antonia Graf, Daniel Kovatchki, Arezoo Borji, Ragib Shahriar Islam, Hossam Haick, Heinz Strohmer, Sepideh Hatamikia

Artificial intelligence (AI) has emerged as a powerful tool to enhance
decision-making and optimize treatment protocols in in vitro fertilization
(IVF). In particular, AI shows significant promise in supporting
decision-making during the ovarian stimulation phase of the IVF process. This
review evaluates studies focused on the applications of AI combined with
medical imaging in ovarian stimulation, examining methodologies, outcomes, and
current limitations. Our analysis of 13 studies on this topic reveals that,
reveal that while AI algorithms demonstrated notable potential in predicting
optimal hormonal dosages, trigger timing, and oocyte retrieval outcomes, the
medical imaging data utilized predominantly came from two-dimensional (2D)
ultrasound which mainly involved basic quantifications, such as follicle size
and number, with limited use of direct feature extraction or advanced image
analysis techniques. This points to an underexplored opportunity where advanced
image analysis approaches, such as deep learning, and more diverse imaging
modalities, like three-dimensional (3D) ultrasound, could unlock deeper
insights. Additionally, the lack of explainable AI (XAI) in most studies raises
concerns about the transparency and traceability of AI-driven decisions - key
factors for clinical adoption and trust. Furthermore, many studies relied on
single-center designs and small datasets, which limit the generalizability of
their findings. This review highlights the need for integrating advanced
imaging analysis techniques with explainable AI methodologies, as well as the
importance of leveraging multicenter collaborations and larger datasets.
Addressing these gaps has the potential to enhance ovarian stimulation
management, paving the way for efficient, personalized, and data-driven
treatment pathways that improve IVF outcomes.

æè¦ï¼äººå·¥æºæ§ï¼AIï¼å·²æçºå¢å¼·é«å¤åç²¾ï¼IVFï¼æ±ºç­å¶å®ååªåæ²»çæ¹æ¡çå¼·å¤§å·¥å·ãç¹å¥æ¯ï¼AI å¨æ¯æ IVF éç¨ä¸­åµå·¢åºæ¿éæ®µçæ±ºç­å¶å®æ¹é¢é¡¯ç¤ºåºé¡¯èçåæ¯ãæ¬ç¶è¿°è©ä¼°äºå°æ³¨æ¼ AI çµååµå·¢åºæ¿ä¸­çé«å­¸å½±åæç¨ãæª¢é©æ¹æ³ãçµæåç¶åéå¶çç ç©¶ãæåå° 13 é éæ¼æ­¤ä¸»é¡çç ç©¶åæé¡¯ç¤ºï¼éç¶ AI æ¼ç®æ³å¨é æ¸¬æä½³è·ç¾èåéãè§¸ç¼ææ©ååµå­ååºçµææ¹é¢è¡¨ç¾åºé¡¯èçæ½åï¼ä½æå©ç¨çé«å­¸å½±åæ¸æä¸»è¦ä¾èªæ¼äºæ¬¡åï¼2Dï¼è¶é³æ³¢ï¼èäºæ¬¡åè¶é³æ³¢ä¸»è¦æ¶ååºæ¬éåï¼ä¾å¦æ¿¾æ³¡å¤§å°åæ¸éï¼ä¸æéä½¿ç¨ç´æ¥ç¹å¾µæåæé²éå½±ååææè¡ãéæåä¸åå°æªæ¢ç´¢çæ©æï¼ä¾å¦æ·±åº¦å­¸ç¿ç­é²éå½±ååææ¹æ³ï¼ä»¥åæ´å¤åçå½±åæ¨¡å¼ï¼ä¾å¦ä¸ç¶­ï¼3Dï¼è¶é³æ³¢ï¼å¯ä»¥è§£éæ´æ·±å¥çè¦è§£ãæ­¤å¤ï¼å¤§å¤æ¸ç ç©¶ç¼ºä¹å¯è§£é AIï¼XAIï¼ï¼éå¼èµ·äºäººåå° AI é©åæ±ºç­çéæåº¦åå¯è¿½æº¯æ§çææï¼èéæåº¦åå¯è¿½æº¯æ§æ¯è¨åºæ¡ç¨åä¿¡ä»»çééµå ç´ ãæ­¤å¤ï¼è¨±å¤ç ç©¶ä¾è³´æ¼å®ä¸­å¿è¨­è¨åå°åæ¸æéï¼ééå¶äºå¶ç¼ç¾çæ®éæ§ãæ¬ç¶è¿°å¼·èª¿äºå°é²éå½±ååææè¡èå¯è§£é AI æ¹æ³æ´åèµ·ä¾çå¿è¦æ§ï¼ä»¥åå©ç¨å¤ä¸­å¿åä½åå¤§åæ¸æéçéè¦æ§ãè§£æ±ºéäºå·®è·æå¯è½å¢å¼·åµå·¢åºæ¿ç®¡çï¼çºææãåäººååæ¸æé©åçæ²»çéå¾éªå¹³éè·¯ï¼é²èæ¹å IVF çµæã

##### **Enhancing Cancer Diagnosis with Explainable & Trustworthy Deep Learning Models**
2412.17527v1 by Badaru I. Olumuyiwa, The Anh Han, Zia U. Shamszaman

This research presents an innovative approach to cancer diagnosis and
prediction using explainable Artificial Intelligence (XAI) and deep learning
techniques. With cancer causing nearly 10 million deaths globally in 2020,
early and accurate diagnosis is crucial. Traditional methods often face
challenges in cost, accuracy, and efficiency. Our study develops an AI model
that provides precise outcomes and clear insights into its decision-making
process, addressing the "black box" problem of deep learning models. By
employing XAI techniques, we enhance interpretability and transparency,
building trust among healthcare professionals and patients. Our approach
leverages neural networks to analyse extensive datasets, identifying patterns
for cancer detection. This model has the potential to revolutionise diagnosis
by improving accuracy, accessibility, and clarity in medical decision-making,
possibly leading to earlier detection and more personalised treatment
strategies. Furthermore, it could democratise access to high-quality
diagnostics, particularly in resource-limited settings, contributing to global
health equity. The model's applications extend beyond cancer diagnosis,
potentially transforming various aspects of medical decision-making and saving
millions of lives worldwide.

æè¦ï¼æ¬ç ç©¶æåºäºä¸ååµæ°çççè¨ºæ·åé æ¸¬æ¹æ³ï¼ä½¿ç¨å¯è§£éçäººå·¥æºæ§ (XAI) åæ·±åº¦å­¸ç¿æè¡ãç±æ¼ççå¨ 2020 å¹´é æå¨çè¿ 1,000 è¬äººæ­»äº¡ï¼å æ­¤æ©ææºç¢ºçè¨ºæ·è³ééè¦ãå³çµ±æ¹æ³éå¸¸é¢è¨ææ¬ãæºç¢ºæ§åæçæ¹é¢çææ°ãæåçç ç©¶éç¼äºä¸å AI æ¨¡åï¼å®æä¾ç²¾ç¢ºççµæä¸¦æ¸æ¥å°äºè§£å¶æ±ºç­éç¨ï¼è§£æ±ºäºæ·±åº¦å­¸ç¿æ¨¡åçãé»ç®±ãåé¡ãééæ¡ç¨ XAI æè¡ï¼æåå¢å¼·äºè§£éæ§åéæåº¦ï¼å¨é«çå°æ¥­äººå¡åæ£èä¹éå»ºç«ä¿¡ä»»ãæåçåæ³å©ç¨ç¥ç¶ç¶²è·¯åæå»£æ³çæ¸æéï¼è­å¥ççæª¢æ¸¬æ¨¡å¼ãéåæ¨¡åæå¯è½ééæé«é«çæ±ºç­çæºç¢ºæ§ãå¯åæ§åæ¸æ°åº¦ä¾é©æ°è¨ºæ·ï¼å¯è½å°è´æ´æ©çæª¢æ¸¬åæ´åæ§åçæ²»çç­ç¥ãæ­¤å¤ï¼å®å¯ä»¥ä½¿æ´å¤äººç²å¾é«åè³ªçè¨ºæ·ï¼ç¹å¥æ¯å¨è³æºæéçç°å¢ä¸­ï¼æå©æ¼å¨çå¥åº·å¬å¹³ãè©²æ¨¡åçæç¨ç¯åä¸åéæ¼ççè¨ºæ·ï¼éå¯è½è½è®é«çæ±ºç­çååæ¹é¢ï¼ä¸¦æ¯æå¨çæ¸ç¾è¬äººççå½ã

##### **Towards Interpretable Radiology Report Generation via Concept Bottlenecks using a Multi-Agentic RAG**
2412.16086v2 by Hasan Md Tusfiqur Alam, Devansh Srivastav, Md Abdul Kadir, Daniel Sonntag

Deep learning has advanced medical image classification, but interpretability
challenges hinder its clinical adoption. This study enhances interpretability
in Chest X-ray (CXR) classification by using concept bottleneck models (CBMs)
and a multi-agent Retrieval-Augmented Generation (RAG) system for report
generation. By modeling relationships between visual features and clinical
concepts, we create interpretable concept vectors that guide a multi-agent RAG
system to generate radiology reports, enhancing clinical relevance,
explainability, and transparency. Evaluation of the generated reports using an
LLM-as-a-judge confirmed the interpretability and clinical utility of our
model's outputs. On the COVID-QU dataset, our model achieved 81% classification
accuracy and demonstrated robust report generation performance, with five key
metrics ranging between 84% and 90%. This interpretable multi-agent framework
bridges the gap between high-performance AI and the explainability required for
reliable AI-driven CXR analysis in clinical settings. Our code is available at
https://github.com/tifat58/IRR-with-CBM-RAG.git.

æè¦ï¼æ·±åº¦å­¸ç¿å·²æåé«å­¸å½±ååé¡ï¼ä½å¯è§£éæ§ææ°é»ç¤å¶è¨åºæç¨ãæ¬ç ç©¶ééä½¿ç¨æ¦å¿µç¶é ¸æ¨¡å (CBM) åå¤ä»£çæª¢ç´¢å¢å¼·çæ (RAG) ç³»çµ±é²è¡å ±åçæï¼ä¾å¢å¼·è¸é¨ X å (CXR) åé¡çå¯è§£éæ§ãééå»ºæ¨¡è¦è¦ºç¹å¾µèè¨åºæ¦å¿µä¹éçéä¿ï¼æåå»ºç«å¯è§£éçæ¦å¿µåéï¼å¼å°å¤ä»£ç RAG ç³»çµ±çææ¾å°å ±åï¼å¢å¼·è¨åºç¸éæ§ãå¯è§£éæ§åéæåº¦ãä½¿ç¨ LLM ä½çºè©å¯©å¡å°çæå ±åé²è¡è©ä¼°ï¼ç¢ºèªäºæåæ¨¡åè¼¸åºçå¯è§£éæ§åè¨åºæç¨ãå¨ COVID-QU è³æéä¸ï¼æåçæ¨¡åéå°äº 81% çåé¡æºç¢ºçï¼ä¸¦å±ç¤ºäºç©©å¥çå ±åçææè½ï¼äºé ééµææ¨ä»æ¼ 84% è³ 90% ä¹éãéåå¯è§£éçå¤ä»£çæ¶æ§å½åäºé«æ§è½ AI èè¨åºç°å¢ä¸­å¯é ç AI é©å CXR åææéçè§£éæ§ä¹éçå·®è·ãæåçç¨å¼ç¢¼å¯æ¼ https://github.com/tifat58/IRR-with-CBM-RAG.git åå¾ã

##### **Critique of Impure Reason: Unveiling the reasoning behaviour of medical Large Language Models**
2412.15748v1 by Shamus Sim, Tyrone Chen

Background: Despite the current ubiquity of Large Language Models (LLMs)
across the medical domain, there is a surprising lack of studies which address
their reasoning behaviour. We emphasise the importance of understanding
reasoning behaviour as opposed to high-level prediction accuracies, since it is
equivalent to explainable AI (XAI) in this context. In particular, achieving
XAI in medical LLMs used in the clinical domain will have a significant impact
across the healthcare sector. Results: Therefore, we define the concept of
reasoning behaviour in the specific context of medical LLMs. We then categorise
and discuss the current state of the art of methods which evaluate reasoning
behaviour in medical LLMs. Finally, we propose theoretical frameworks which can
empower medical professionals or machine learning engineers to gain insight
into the low-level reasoning operations of these previously obscure models.
Conclusion: The subsequent increased transparency and trust in medical machine
learning models by clinicians as well as patients will accelerate the
integration, application as well as further development of medical AI for the
healthcare system as a whole

æè¦ï¼èæ¯ï¼åç®¡å¤§åèªè¨æ¨¡å (LLM) ç®åå¨é«çé åç¡æä¸å¨ï¼ä½ä»¤äººé©è¨çæ¯ï¼æ¢è¨å¶æ¨çè¡çºçç ç©¶å»ç¸ç¶ç¼ºä¹ãæåå¼·èª¿äºè§£æ¨çè¡çºèéé«å±¤ç´çé æ¸¬æºç¢ºåº¦éå¸¸éè¦ï¼å çºå¨éç¨®ææ³ä¸ï¼éç­åæ¼å¯è§£é AI (XAI)ãå°¤å¶æ¯å¨è¨åºé åä¸­ä½¿ç¨çé«ç LLM ä¸­å¯¦ç¾ XAIï¼å°å°æ´åé«çä¿å¥ç¢æ¥­ç¢çéå¤§å½±é¿ãçµæï¼å æ­¤ï¼æåå¨é«ç LLM çç¹å®èæ¯ä¸å®ç¾©äºæ¨çè¡çºçæ¦å¿µãæ¥èæååé¡ä¸¦æ¢è¨ç¶åè©ä¼°é«ç LLM ä¸­æ¨çè¡çºçæ¹æ³çææ°æè¡ãæå¾ï¼æåæåºçè«æ¶æ§ï¼è®é«çå°æ¥­äººå¡ææ©å¨å­¸ç¿å·¥ç¨å¸«å¾ä»¥æ·±å¥äºè§£éäºååæ¨¡ç³æ¨¡åçä½å±¤ç´æ¨çéç®ãçµè«ï¼è¨åºé«çåæ£èå°é«çæ©å¨å­¸ç¿æ¨¡åçéæåº¦åä¿¡ä»»åº¦é¨ä¹æåï¼å°å éé«ç AI å¨æ´åé«çä¿å¥ç³»çµ±ä¸­çæ´åãæç¨åé²ä¸æ­¥ç¼å±ã

##### **Cognition Chain for Explainable Psychological Stress Detection on Social Media**
2412.14009v1 by Xin Wang, Boyan Gao, Yi Dai, Lei Cao, Liang Zhao, Yibo Yang, David Clifton

Stress is a pervasive global health issue that can lead to severe mental
health problems. Early detection offers timely intervention and prevention of
stress-related disorders. The current early detection models perform "black
box" inference suffering from limited explainability and trust which blocks the
real-world clinical application. Thanks to the generative properties introduced
by the Large Language Models (LLMs), the decision and the prediction from such
models are semi-interpretable through the corresponding description. However,
the existing LLMs are mostly trained for general purposes without the guidance
of psychological cognitive theory. To this end, we first highlight the
importance of prior theory with the observation of performance boosted by the
chain-of-thoughts tailored for stress detection. This method termed Cognition
Chain explicates the generation of stress through a step-by-step cognitive
perspective based on cognitive appraisal theory with a progress pipeline:
Stimulus $\rightarrow$ Evaluation $\rightarrow$ Reaction $\rightarrow$ Stress
State, guiding LLMs to provide comprehensive reasoning explanations. We further
study the benefits brought by the proposed Cognition Chain format by utilising
it as a synthetic dataset generation template for LLMs instruction-tuning and
introduce CogInstruct, an instruction-tuning dataset for stress detection. This
dataset is developed using a three-stage self-reflective annotation pipeline
that enables LLMs to autonomously generate and refine instructional data. By
instruction-tuning Llama3 with CogInstruct, we develop CogLLM, an explainable
stress detection model. Evaluations demonstrate that CogLLM achieves
outstanding performance while enhancing explainability. Our work contributes a
novel approach by integrating cognitive theories into LLM reasoning processes,
offering a promising direction for future explainable AI research.

æè¦ï¼å£åæ¯ä¸åæ®éçå¨çæ§å¥åº·åé¡ï¼å¯è½æå°è´å´éçç²¾ç¥
å¥åº·åé¡ãæ©æç¼ç¾æä¾åæçå¹²é åé é²
å£åç¸éç¾çãç®åçæ©æç¼ç¾æ¨¡åå·è¡ãé»
çå­ãæ¨è«ï¼å­å¨å¯è§£éæ§åä¿¡ä»»åº¦æéçåé¡ï¼é»ç¤äº
ç¾å¯¦ä¸ççè¨åºæç¨ãå¤è§äºå¤§åèªè¨æ¨¡å (LLM) å¼å¥ççæå±¬æ§ï¼æ­¤é¡
æ¨¡åçæ±ºç­åé æ¸¬ééå°ææè¿°å·æåå¯è§£éæ§ãç¶èï¼
ç¾æç LLM ä¸»è¦éå°ä¸è¬ç¨éé²è¡è¨ç·´ï¼æ²æå¿çèªç¥çè«çæå°ãçºæ­¤ï¼æåé¦åå¼·èª¿
åé©çè«çéè¦æ§ï¼ä¸¦è§å¯å°éå°å£åæª¢æ¸¬éèº«å®å¶çææ³éæåäºæ§è½ãéç¨®æ¹æ³ç¨±çºèªç¥
éééåºæ¼èªç¥è©ä¼°çè«çå¾ªåºæ¼¸é²çèªç¥è¦è§é¡æäºå£åçç¢çï¼ä¸¦å·æé²åº¦ç®¡éï¼
åºæ¿ $\rightarrow$ è©ä¼° $\rightarrow$ åæ $\rightarrow$ å£å
çæï¼æå° LLM æä¾å¨é¢çæ¨çè§£éãæåé²ä¸æ­¥
ééå°å¶ç¨ä½ LLM æä»¤èª¿æ´çåææ¸æéçææ¨¡æ¿ä¾ç ç©¶ææåºçèªç¥éæ ¼å¼å¸¶ä¾çåªé»ï¼ä¸¦ä»ç´¹ CogInstructï¼éæ¯ä¸åéå°å£åæª¢æ¸¬çæä»¤èª¿æ´æ¸æéãéå
æ¸æéæ¯ä½¿ç¨ä¸åä¸éæ®µçèªçæ¨è¨»ç®¡ééç¼çï¼ä½¿ LLM è½å¤ èªä¸»çæååªåæä»¤æ¸æãéé
ä½¿ç¨ CogInstruct å° Llama3 é²è¡æä»¤èª¿æ´ï¼æåéç¼äº CogLLMï¼éæ¯ä¸åå¯è§£éç
å£åæª¢æ¸¬æ¨¡åãè©ä¼°è¡¨æï¼CogLLM å¨æé«å¯è§£éæ§çåæå¯¦ç¾äºåºè²çæ§è½ãæåçç ç©¶ééå°èªç¥çè«æ´åå° LLM æ¨çéç¨ä¸­ï¼æåºäºä¸ç¨®æ°ç©çæ¹æ³ï¼
çºæªä¾çå¯è§£éäººå·¥æºè½ç ç©¶æä¾äºä¸åæå¸æçæ¹åã

##### **2-Factor Retrieval for Improved Human-AI Decision Making in Radiology**
2412.00372v1 by Jim Solomon, Laleh Jalilian, Alexander Vilesov, Meryl Mathew, Tristan Grogan, Arash Bedayat, Achuta Kadambi

Human-machine teaming in medical AI requires us to understand to what degree
a trained clinician should weigh AI predictions. While previous work has shown
the potential of AI assistance at improving clinical predictions, existing
clinical decision support systems either provide no explainability of their
predictions or use techniques like saliency and Shapley values, which do not
allow for physician-based verification. To address this gap, this study
compares previously used explainable AI techniques with a newly proposed
technique termed '2-factor retrieval (2FR)', which is a combination of
interface design and search retrieval that returns similarly labeled data
without processing this data. This results in a 2-factor security blanket
where: (a) correct images need to be retrieved by the AI; and (b) humans should
associate the retrieved images with the current pathology under test. We find
that when tested on chest X-ray diagnoses, 2FR leads to increases in clinician
accuracy, with particular improvements when clinicians are radiologists and
have low confidence in their decision. Our results highlight the importance of
understanding how different modes of human-AI decision making may impact
clinician accuracy in clinical decision support systems.

æè¦ï¼äººæ©åä½å¨é«ç AI ä¸­ï¼éè¦æåçè§£åéè¨ç·´çè¨åºé«çå¨å¤å¤§ç¨åº¦ä¸æéè¦ AI é æ¸¬ãéç¶ååçç ç©¶é¡¯ç¤º AI è¼å©å¨æ¹åè¨åºé æ¸¬æ¹é¢çæ½åï¼ä½ç¾æçè¨åºæ±ºç­æ¯æ´ç³»çµ±ï¼è¦ä¸å°±æ²ææä¾é æ¸¬çå¯è§£éæ§ï¼è¦ä¸å°±æ¯ä½¿ç¨åé¡¯èæ§å Shapley å¼ä¹é¡çæè¡ï¼éäºæè¡ä¸åè¨±åºæ¼é«ççé©è­ãçºäºè§£æ±ºéåå·®è·ï¼æ¬ç ç©¶å°ååä½¿ç¨çå¯è§£é AI æè¡èä¸ç¨®æ°æåºçç¨±çºã2 å å­æª¢ç´¢ (2FR)ãçæè¡é²è¡æ¯è¼ï¼å¾èæ¯ä¸ç¨®ä»é¢è¨­è¨åæå°æª¢ç´¢ççµåï¼å®æå³åæ¨ç±¤ç¸ä¼¼çè³æï¼èä¸æèçéäºè³æãéæç¢çä¸å 2 å å­å®å¨æ©å¶ï¼å¶ä¸­ï¼(a) æ­£ç¢ºçå½±åéè¦ç± AI æª¢ç´¢ï¼(b) äººé¡æå°æª¢ç´¢çå½±åèæ­£å¨æ¸¬è©¦ä¸­çççè¯æ³èµ·ä¾ãæåç¼ç¾ï¼ç¶å¨è¸é¨ X åè¨ºæ·ä¸é²è¡æ¸¬è©¦æï¼2FR ææé«è¨åºé«ççæºç¢ºåº¦ï¼ç¹å¥æ¯å¨è¨åºé«çæ¯æ¾å°ç§é«çä¸å°å¶æ±ºç­ä¿¡å¿ä¸è¶³æï¼ææé¡¯èçæ¹åãæåççµæå¼·èª¿äºçè§£äººæ©æ±ºç­çä¸åæ¨¡å¼å¦ä½å½±é¿è¨åºé«çå¨è¨åºæ±ºç­æ¯æ´ç³»çµ±ä¸­çæºç¢ºæ§çéè¦æ§ã

##### **Mapping Public Perception of Artificial Intelligence: Expectations, Risk-Benefit Tradeoffs, and Value As Determinants for Societal Acceptance**
2411.19356v1 by Philipp Brauner, Felix Glawe, Gian Luca Liehner, Luisa Vervier, Martina Ziefle

Understanding public perception of artificial intelligence (AI) and the
tradeoffs between potential risks and benefits is crucial, as these perceptions
might shape policy decisions, influence innovation trajectories for successful
market strategies, and determine individual and societal acceptance of AI
technologies. Using a representative sample of 1100 participants from Germany,
this study examines mental models of AI. Participants quantitatively evaluated
71 statements about AI's future capabilities (e.g., autonomous driving, medical
care, art, politics, warfare, and societal divides), assessing the expected
likelihood of occurrence, perceived risks, benefits, and overall value. We
present rankings of these projections alongside visual mappings illustrating
public risk-benefit tradeoffs. While many scenarios were deemed likely,
participants often associated them with high risks, limited benefits, and low
overall value. Across all scenarios, 96.4% ($r^2=96.4\%$) of the variance in
value assessment can be explained by perceived risks ($\beta=-.504$) and
perceived benefits ($\beta=+.710$), with no significant relation to expected
likelihood. Demographics and personality traits influenced perceptions of
risks, benefits, and overall evaluations, underscoring the importance of
increasing AI literacy and tailoring public information to diverse user needs.
These findings provide actionable insights for researchers, developers, and
policymakers by highlighting critical public concerns and individual factors
essential to align AI development with individual values.

æè¦ï¼<paragraph>äºè§£å¬ç¾å°äººå·¥æºæ§ (AI) çèªç¥ä»¥åæ½å¨é¢¨éªèå¥½èä¹éçæ¬è¡¡è³ééè¦ï¼å çºéäºèªç¥å¯è½æå½±é¿æ¿ç­æ±ºç­ãå½±é¿æåå¸å ´ç­ç¥çåµæ°è»è·¡ï¼ä¸¦æ±ºå®åäººåç¤¾æå° AI æè¡çæ¥ååº¦ãæ¬ç ç©¶ä½¿ç¨ä¾èªå¾·åç 1100 ååèèçä»£è¡¨æ§æ¨£æ¬ï¼æ¢è¨äº AI çå¿æºæ¨¡åãåèèå° 71 é éæ¼ AI æªä¾è½åçé³è¿°ï¼ä¾å¦ï¼èªåé§é§ãé«çä¿å¥ãèè¡ãæ¿æ²»ãæ°ç­åç¤¾æåæ­§ï¼é²è¡äºå®éè©ä¼°ï¼è©ä¼°é æçç¼çå¯è½æ§ãæç¥é¢¨éªãå¥½èåæ´é«å¹å¼ãæåå±ç¤ºäºéäºé æ¸¬çæåï¼ä¸¦éä¸è¦è¦ºåæ å°ï¼èªªæäºå¬ç¾çé¢¨éªæ¶çæ¬è¡¡ãåç®¡è¨±å¤å ´æ¯è¢«èªçºæ¯å¯è½çï¼ä½åèèéå¸¸å°å®åèé«é¢¨éªãæéçå¥½èåä½æ´é«å¹å¼è¯ç¹«èµ·ä¾ãå¨ææå ´æ¯ä¸­ï¼96.4% ($r^2=96.4\%$) çå¹å¼è©ä¼°å·®ç°å¯ä»¥ç¨æç¥é¢¨éª ($\beta=-.504$) åæç¥å¥½è ($\beta=+.710$) ä¾è§£éï¼èé æçå¯è½æ§æ²æé¡¯èéä¿ãäººå£çµ±è¨åäººæ ¼ç¹è³ªå½±é¿äºå°é¢¨éªãå¥½èåæ´é«è©ä¼°ççæ³ï¼éå¸é¡¯äºæé« AI ç´ é¤åæ ¹æä¸åçä½¿ç¨èéæ±èª¿æ´å¬å±è³è¨çéè¦æ§ãéäºç¼ç¾ééå¼·èª¿ééµçå¬å±éæ³¨åèåäººå¹å¼è§ä¸è´ç AI éç¼å¿ä¸å¯å°çåäººå ç´ ï¼çºç ç©¶äººå¡ãéç¼äººå¡åæ¿ç­å¶å®èæä¾äºå¯è¡çè¦è§£ã</paragraph>

##### **Explainable AI for Classifying UTI Risk Groups Using a Real-World Linked EHR and Pathology Lab Dataset**
2411.17645v2 by Yujie Dai, Brian Sullivan, Axel Montout, Amy Dillon, Chris Waller, Peter Acs, Rachel Denholm, Philip Williams, Alastair D Hay, Raul Santos-Rodriguez, Andrew Dowsey

The use of machine learning and AI on electronic health records (EHRs) holds
substantial potential for clinical insight. However, this approach faces
challenges due to data heterogeneity, sparsity, temporal misalignment, and
limited labeled outcomes. In this context, we leverage a linked EHR dataset of
approximately one million de-identified individuals from Bristol, North
Somerset, and South Gloucestershire, UK, to characterize urinary tract
infections (UTIs). We implemented a data pre-processing and curation pipeline
that transforms the raw EHR data into a structured format suitable for
developing predictive models focused on data fairness, accountability and
transparency. Given the limited availability and biases of ground truth UTI
outcomes, we introduce a UTI risk estimation framework informed by clinical
expertise to estimate UTI risk across individual patient timelines. Pairwise
XGBoost models are trained using this framework to differentiate UTI risk
categories with explainable AI techniques applied to identify key predictors
and support interpretability. Our findings reveal differences in clinical and
demographic predictors across risk groups. While this study highlights the
potential of AI-driven insights to support UTI clinical decision-making,
further investigation of patient sub-strata and extensive validation are needed
to ensure robustness and applicability in clinical practice.

æè¦ï¼é»å­å¥åº·ç´é (EHR) ä¸­æ©å¨å­¸ç¿å AI çä½¿ç¨å°æ¼è¨åºè¦è§£å·æç¸ç¶å¤§çæ½åãç¶èï¼ç±æ¼è³æç°è³ªæ§ãç¨çæ§ãæéé¯ä½åæ¨ç±¤çµææéï¼æ­¤æ¹æ³é¢è¨ææ°ãå¨æ­¤èæ¯ä¸ï¼æåå©ç¨ä¾èªè±åå¸éæ¯æãåè©é»å¡ç¹ååæ ¼æ´æ¯ç¹é¡ç´ä¸ç¾è¬åå»è­å¥åäººé£çµç EHR è³æéï¼ä¾æè¿°å°¿è·¯ææ (UTI)ãæåå¯¦æ½äºå°åå§ EHR è³æè½æçºçµæ§åæ ¼å¼çè³æåèçåæ´çç®¡ç·ï¼é©åéç¼å°æ³¨æ¼è³æå¬å¹³æ§ãåè²¬å¶åéæåº¦çé æ¸¬æ¨¡åãéæ¼ UTI çå¯¦çµæçå¯ç¨æ§æéååå·®ï¼æåå¼å¥äºç±è¨åºå°æ¥­ç¥è­åç¥ç UTI é¢¨éªè©ä¼°æ¶æ§ï¼ä»¥ä¼°è¨åå¥æ£èæéè»¸ä¸ç UTI é¢¨éªãæå°ç XGBoost æ¨¡åä½¿ç¨æ­¤æ¶æ§é²è¡è¨ç·´ï¼ä»¥åå UTI é¢¨éªé¡å¥ï¼ä¸¦æç¨å¯è§£éç AI æè¡ä¾è­å¥ééµé æ¸¬å å­ä¸¦æ¯æå¯è§£éæ§ãæåçç ç©¶çµææ­ç¤ºäºä¸åé¢¨éªç¾¤çµå¨è¨åºåäººå£çµ±è¨é æ¸¬å å­ä¸çå·®ç°ãéç¶éé ç ç©¶å¼·èª¿äº AI é©åè¦è§£å¨æ¯æ´ UTI è¨åºæ±ºç­å¶å®æ¹é¢çæ½åï¼ä½ä»éè¦é²ä¸æ­¥èª¿æ¥æ£èå­ç¾¤é«åå»£æ³é©è­ï¼ä»¥ç¢ºä¿å¨è¨åºå¯¦åä¸­çç©©å¥æ§åé©ç¨æ§ã

##### **Exploring the Requirements of Clinicians for Explainable AI Decision Support Systems in Intensive Care**
2411.11774v1 by Jeffrey N. Clark, Matthew Wragg, Emily Nielsen, Miquel Perello-Nieto, Nawid Keshtmand, Michael Ambler, Shiv Sharma, Christopher P. Bourdeaux, Amberly Brigden, Raul Santos-Rodriguez

There is a growing need to understand how digital systems can support
clinical decision-making, particularly as artificial intelligence (AI) models
become increasingly complex and less human-interpretable. This complexity
raises concerns about trustworthiness, impacting safe and effective adoption of
such technologies. Improved understanding of decision-making processes and
requirements for explanations coming from decision support tools is a vital
component in providing effective explainable solutions. This is particularly
relevant in the data-intensive, fast-paced environments of intensive care units
(ICUs). To explore these issues, group interviews were conducted with seven ICU
clinicians, representing various roles and experience levels. Thematic analysis
revealed three core themes: (T1) ICU decision-making relies on a wide range of
factors, (T2) the complexity of patient state is challenging for shared
decision-making, and (T3) requirements and capabilities of AI decision support
systems. We include design recommendations from clinical input, providing
insights to inform future AI systems for intensive care.

æè¦ï¼é¨èäººå·¥æºæ§ (AI) æ¨¡åè®å¾è¶ä¾è¶è¤éï¼ä¸è¶ä¾è¶é£ä»¥è¢«äººçè§£ï¼äºè§£æ¸ä½ç³»çµ±å¦ä½æ¯æ´è¨åºæ±ºç­çéæ±ä¹æ¥çå¢å ãéç¨®è¤éæ§å¼ç¼äºå°å¯ä¿¡åº¦ççæ®ï¼å½±é¿äºæ­¤é¡æè¡çå®å¨ä¸æææ¡ç¨ãæ¹åå°æ±ºç­å¶å®æµç¨ççè§£ï¼ä»¥åå°æ±ºç­æ¯æ´å·¥å·ææä¾èªªæçè¦æ±ï¼æ¯æä¾ææå¯è§£éè§£æ±ºæ¹æ¡çéè¦çµæé¨åãéå¨è³æå¯éãå¿«ç¯å¥çå è­·çæ¿ (ICU) ç°å¢ä¸­ç¹å¥ç¸éãçºäºæ¢è¨éäºåé¡ï¼å°ä¸ä½ ICU è¨åºé«å¸«é²è¡äºå°çµè¨ªè«ï¼éäºé«å¸«ä»£è¡¨äºä¸åçè§è²åç¶é©å±¤ç´ãä¸»é¡åææ­é²äºä¸åæ ¸å¿ä¸»é¡ï¼(T1) ICU æ±ºç­å¶å®ä¾è³´æ¼å»£æ³çå ç´ ï¼(T2) çæ£çæçè¤éæ§å°å±åæ±ºç­å¶å®æ§æææ°ï¼ä»¥å (T3) AI æ±ºç­æ¯æ´ç³»çµ±çè¦æ±åè½åãæåç´å¥äºè¨åºè¼¸å¥çè¨­è¨å»ºè­°ï¼æä¾è¦è§£ä»¥æä¾è³è¨çµ¦æªä¾ç¨æ¼å è­·ç AI ç³»çµ±ã

##### **Artificial Intelligence in Pediatric Echocardiography: Exploring Challenges, Opportunities, and Clinical Applications with Explainable AI and Federated Learning**
2411.10255v1 by Mohammed Yaseen Jabarulla, Theodor Uden, Thomas Jack, Philipp Beerbaum, Steffen Oeltze-Jafra

Pediatric heart diseases present a broad spectrum of congenital and acquired
diseases. More complex congenital malformations require a differentiated and
multimodal decision-making process, usually including echocardiography as a
central imaging method. Artificial intelligence (AI) offers considerable
promise for clinicians by facilitating automated interpretation of pediatric
echocardiography data. However, adapting AI technologies for pediatric
echocardiography analysis has challenges such as limited public data
availability, data privacy, and AI model transparency. Recently, researchers
have focused on disruptive technologies, such as federated learning (FL) and
explainable AI (XAI), to improve automatic diagnostic and decision support
workflows. This study offers a comprehensive overview of the limitations and
opportunities of AI in pediatric echocardiography, emphasizing the synergistic
workflow and role of XAI and FL, identifying research gaps, and exploring
potential future developments. Additionally, three relevant clinical use cases
demonstrate the functionality of XAI and FL with a focus on (i) view
recognition, (ii) disease classification, (iii) segmentation of cardiac
structures, and (iv) quantitative assessment of cardiac function.

æè¦ï¼å°åå¿èç¾çåç¾åå¤©æ§èå¾å¤©æ§ç¾ççå»£æ³åè­ãè¼è¤éçåå¤©æ§ç¸å½¢éè¦ä¸åå·®ç°åä¸å¤æ¨¡å¼çæ±ºç­éç¨ï¼éå¸¸åæ¬è¶é³æ³¢æª¢æ¥ä½çºä¸»è¦çå½±åæ¹æ³ãäººå·¥æºæ§ (AI) çºè¨åºé«çæä¾äºç¸ç¶å¤§çå¸æï¼å çºå®å¯ä»¥ä¿é²å°åè¶é³æ³¢æª¢æ¥è³æçèªååè§£è®ãç¶èï¼å°äººå·¥æºæ§æè¡æç¨æ¼å°åè¶é³æ³¢æª¢æ¥åææè¨±å¤ææ°ï¼ä¾å¦æéçå¬éè³æå¯ç¨æ§ãè³æé±ç§åäººå·¥æºæ§æ¨¡åéæåº¦ãæè¿ï¼ç ç©¶äººå¡å°æ³¨æ¼ç ´å£æ§æè¡ï¼ä¾å¦è¯åå­¸ç¿ (FL) åå¯è§£éäººå·¥æºæ§ (XAI)ï¼ä»¥æ¹åèªåè¨ºæ·åæ±ºç­æ¯æ´å·¥ä½æµç¨ãæ¬ç ç©¶æä¾äºäººå·¥æºæ§å¨å°åè¶é³æ³¢æª¢æ¥ä¸­çéå¶åæ©æçå¨é¢æ¦è¿°ï¼å¼·èª¿äº XAI å FL çååå·¥ä½æµç¨åè§è²ï¼æ¾åºç ç©¶å·®è·ä¸¦æ¢è¨æ½å¨çæªä¾ç¼å±ãæ­¤å¤ï¼ä¸åç¸éçè¨åºä½¿ç¨æ¡ä¾å±ç¤ºäº XAI å FL çåè½ï¼éé»å¨æ¼ (i) æª¢è¦è¾¨è­ã(ii) ç¾çåé¡ã(iii) å¿èçµæ§åå²å (iv) å¿èåè½çéåè©ä¼°ã

##### **Enhancing Osteoporosis Detection: An Explainable Multi-Modal Learning Framework with Feature Fusion and Variable Clustering**
2411.00916v2 by Mehdi Hosseini Chagahi, Saeed Mohammadi Dashtaki, Niloufar Delfan, Nadia Mohammadi, Alireza Samari, Behzad Moshiri, Md. Jalil Piran, Oliver Faust

Osteoporosis is a common condition that increases fracture risk, especially
in older adults. Early diagnosis is vital for preventing fractures, reducing
treatment costs, and preserving mobility. However, healthcare providers face
challenges like limited labeled data and difficulties in processing medical
images. This study presents a novel multi-modal learning framework that
integrates clinical and imaging data to improve diagnostic accuracy and model
interpretability. The model utilizes three pre-trained networks-VGG19,
InceptionV3, and ResNet50-to extract deep features from X-ray images. These
features are transformed using PCA to reduce dimensionality and focus on the
most relevant components. A clustering-based selection process identifies the
most representative components, which are then combined with preprocessed
clinical data and processed through a fully connected network (FCN) for final
classification. A feature importance plot highlights key variables, showing
that Medical History, BMI, and Height were the main contributors, emphasizing
the significance of patient-specific data. While imaging features were
valuable, they had lower importance, indicating that clinical data are crucial
for accurate predictions. This framework promotes precise and interpretable
predictions, enhancing transparency and building trust in AI-driven diagnoses
for clinical integration.

æè¦ï¼éª¨è³ªçé¬çæ¯ä¸ç¨®å¸¸è¦çç¾çï¼æå¢å éª¨æçé¢¨éªï¼ç¹å¥æ¯èå¹´äººãæ©æè¨ºæ·å°æ¼é é²éª¨æãéä½æ²»çææ¬åç¶­æè¡åè½åè³ééè¦ãç¶èï¼é«çä¿å¥æä¾èé¢è¨èæ¨è¨æ¸ææéåèçé«å­¸å½±åå°é£ç­ææ°ãæ¬ç ç©¶æåºäºä¸åæ°ç©çå¤æ¨¡å¼å­¸ç¿æ¡æ¶ï¼è©²æ¡æ¶æ´åäºè¨åºåå½±åæ¸æï¼ä»¥æé«è¨ºæ·æºç¢ºæ§åæ¨¡åå¯è§£éæ§ãè©²æ¨¡åå©ç¨ä¸åé è¨ç·´çç¶²è·¯ï¼VGG19ãInceptionV3 å ResNet50ï¼å¾ X å°ç·å½±åä¸­æåæ·±åº¦ç¹å¾µãéäºç¹å¾µä½¿ç¨ PCA è½æä»¥éä½ç¶­åº¦ä¸¦å°æ³¨æ¼æç¸éççµæé¨åãåºæ¼èé¡çé¸æéç¨è­å¥åºæå·ä»£è¡¨æ§ççµæé¨åï¼ç¶å¾å°éäºçµæé¨åèé èççè¨åºæ¸æçµåï¼ä¸¦ééå¨é£æ¥ç¶²è·¯ (FCN) é²è¡æçµåé¡ãç¹å¾µéè¦æ§åçªåºäºééµè®æ¸ï¼è¡¨æçå²ãBMI åèº«é«æ¯ä¸»è¦è²¢ç»å ç´ ï¼å¼·èª¿äºæ£èç¹å®æ¸æçéè¦æ§ãéç¶å½±åç¹å¾µå¾æå¹å¼ï¼ä½å®åçéè¦æ§è¼ä½ï¼éè¡¨æè¨åºæ¸æå°æ¼æºç¢ºé æ¸¬è³ééè¦ãæ­¤æ¡æ¶ä¿è¿äºæºç¢ºä¸å¯è§£éçé æ¸¬ï¼æé«äºéæåº¦ï¼ä¸¦å»ºç«äºå° AI é©åè¨ºæ·å¨è¨åºæ´åä¸­çä¿¡ä»»ã

##### **A Review of Deep Learning Approaches for Non-Invasive Cognitive Impairment Detection**
2410.19898v1 by Muath Alsuhaibani, Ali Pourramezan Fard, Jian Sun, Farida Far Poor, Peter S. Pressman, Mohammad H. Mahoor

This review paper explores recent advances in deep learning approaches for
non-invasive cognitive impairment detection. We examine various non-invasive
indicators of cognitive decline, including speech and language, facial, and
motoric mobility. The paper provides an overview of relevant datasets,
feature-extracting techniques, and deep-learning architectures applied to this
domain. We have analyzed the performance of different methods across modalities
and observed that speech and language-based methods generally achieved the
highest detection performance. Studies combining acoustic and linguistic
features tended to outperform those using a single modality. Facial analysis
methods showed promise for visual modalities but were less extensively studied.
Most papers focused on binary classification (impaired vs. non-impaired), with
fewer addressing multi-class or regression tasks. Transfer learning and
pre-trained language models emerged as popular and effective techniques,
especially for linguistic analysis. Despite significant progress, several
challenges remain, including data standardization and accessibility, model
explainability, longitudinal analysis limitations, and clinical adaptation.
Lastly, we propose future research directions, such as investigating
language-agnostic speech analysis methods, developing multi-modal diagnostic
systems, and addressing ethical considerations in AI-assisted healthcare. By
synthesizing current trends and identifying key obstacles, this review aims to
guide further development of deep learning-based cognitive impairment detection
systems to improve early diagnosis and ultimately patient outcomes.

æè¦ï¼æ¬ç¯è©è«æ¢è¨äºæ·±åº¦å­¸ç¿æ¹æ³å¨éä¾µå¥å¼èªç¥åè½éç¤æª¢æ¸¬ä¸çææ°é²å±ãæåæª¢è¦äºåç¨®éä¾µå¥å¼çèªç¥è¡°éææ¨ï¼åæ¬èªè¨åèªè¨ãé¢é¨åéåæ©è½ãæ¬ææ¦è¿°äºèæ­¤é åç¸éçè³æéãç¹å¾µæåæè¡åæ·±åº¦å­¸ç¿æ¶æ§ãæååæäºä¸åæ¹æ³å¨ä¸åæ¹å¼ä¸çè¡¨ç¾ï¼ä¸¦è§å¯å°åºæ¼èªè¨åèªè¨çæ¹æ³éå¸¸è½éå°æé«çæª¢æ¸¬è¡¨ç¾ãçµåè²å­¸åèªè¨ç¹å¾µçç ç©¶å¾å¾åªæ¼ä½¿ç¨å®ä¸æ¹å¼çç ç©¶ãé¢é¨åææ¹æ³é¡¯ç¤ºåºè¦è¦ºæ¹å¼çæ½åï¼ä½ç ç©¶è¼å°ãå¤§å¤æ¸è«æå°æ³¨æ¼äºååé¡ï¼åæèæªåæï¼ï¼è¼å°æ¢è¨å¤é¡æåæ­¸ä»»åãé·ç§»å­¸ç¿åé è¨ç·´èªè¨æ¨¡åå·²æçºæµè¡ä¸ææçæè¡ï¼ç¹å¥æ¯å°æ¼èªè¨åæãåç®¡åå¾äºéå¤§é²å±ï¼ä½ä»å­å¨ä¸äºææ°ï¼åæ¬è³ææ¨æºååå¯åæ§ãæ¨¡åå¯è§£éæ§ãç¸±ååæéå¶åè¨åºé©ææ§ãæå¾ï¼æåæåºäºæªä¾çç ç©¶æ¹åï¼ä¾å¦èª¿æ¥èèªè¨ç¡éçèªé³åææ¹æ³ãéç¼å¤æ¨¡å¼è¨ºæ·ç³»çµ±ï¼ä»¥åè§£æ±ºäººå·¥æºæ§è¼å©é«çä¿å¥ä¸­çå«çèéãééç¶åç®åçè¶¨å¢åæ¾åºééµéç¤ï¼æ¬ç¯è©è«æ¨å¨å¼å°æ·±åº¦å­¸ç¿çºåºç¤çèªç¥åè½éç¤æª¢æ¸¬ç³»çµ±çé²ä¸æ­¥ç¼å±ï¼ä»¥æ¹åæ©æè¨ºæ·ï¼ä¸¦æçµæ¹åæ£èçæ²»ççµæã

##### **An Ontology-Enabled Approach For User-Centered and Knowledge-Enabled Explanations of AI Systems**
2410.17504v1 by Shruthi Chari

Explainable Artificial Intelligence (AI) focuses on helping humans understand
the working of AI systems or their decisions and has been a cornerstone of AI
for decades. Recent research in explainability has focused on explaining the
workings of AI models or model explainability. There have also been several
position statements and review papers detailing the needs of end-users for
user-centered explainability but fewer implementations. Hence, this thesis
seeks to bridge some gaps between model and user-centered explainability. We
create an explanation ontology (EO) to represent literature-derived explanation
types via their supporting components. We implement a knowledge-augmented
question-answering (QA) pipeline to support contextual explanations in a
clinical setting. Finally, we are implementing a system to combine explanations
from different AI methods and data modalities. Within the EO, we can represent
fifteen different explanation types, and we have tested these representations
in six exemplar use cases. We find that knowledge augmentations improve the
performance of base large language models in the contextualized QA, and the
performance is variable across disease groups. In the same setting, clinicians
also indicated that they prefer to see actionability as one of the main foci in
explanations. In our explanations combination method, we plan to use similarity
metrics to determine the similarity of explanations in a chronic disease
detection setting. Overall, through this thesis, we design methods that can
support knowledge-enabled explanations across different use cases, accounting
for the methods in today's AI era that can generate the supporting components
of these explanations and domain knowledge sources that can enhance them.

æè¦ï¼å¯è§£éäººå·¥æºæ§ï¼AIï¼å°æ³¨æ¼åå©äººé¡äºè§£ AI ç³»çµ±éä½æå¶æ±ºç­ï¼æ¸åå¹´ä¾ä¸ç´æ¯ AI çåºç³ãæè¿çå¯è§£éæ§ç ç©¶å°æ³¨æ¼è§£é AI æ¨¡åææ¨¡åå¯è§£éæ§çéä½ãä¹æå¹¾ä»½ç«å ´è²æåè©è«è«æè©³ç´°èªªæäºæçµä½¿ç¨èå°ä»¥ä½¿ç¨èçºä¸­å¿çå¯è§£éæ§çéæ±ï¼ä½å¯¦ä½è¼å°ãå æ­¤ï¼æ¬è«ææ¨å¨å½è£æ¨¡ååä»¥ä½¿ç¨èçºä¸­å¿çå¯è§£éæ§ä¹éçä¸äºå·®è·ãæåå»ºç«ä¸åè§£éæ¬é«ï¼EOï¼ä»¥ééå¶æ¯æ´åä»¶ä¾è¡¨ç¤ºå¾æç»ä¸­è¡ççè§£éé¡åãæåå¯¦ä½ä¸åç¥è­å¢å¼·çåç­ï¼QAï¼ç®¡ç·ï¼ä»¥å¨è¨åºç°å¢ä¸­æ¯æ´æå¢è§£éãæå¾ï¼æåæ­£å¨å¯¦ä½ä¸åç³»çµ±ï¼ä»¥çµåä¾èªä¸å AI æ¹æ³åè³ææ¨¡å¼çè§£éãå¨ EO ä¸­ï¼æåå¯ä»¥è¡¨ç¤º 15 ç¨®ä¸åçè§£éé¡åï¼ä¸¦ä¸æåå·²å¨å­åç¯ä¾ä½¿ç¨æ¡ä¾ä¸­æ¸¬è©¦éäºè¡¨ç¤ºãæåç¼ç¾ï¼ç¥è­å¢å¼·æ¹åäºåºç¤å¤§åèªè¨æ¨¡åå¨æå¢å QA ä¸­çæè½ï¼ä¸¦ä¸æè½å ç¾çç¾¤çµèç°ãå¨ç¸åçç°å¢ä¸­ï¼è¨åºé«çä¹è¡¨ç¤ºä»åå¸æå°å¯æä½æ§è¦çºè§£éä¸­çä¸»è¦ç¦é»ä¹ä¸ãå¨æåçè§£éçµåæ¹æ³ä¸­ï¼æåè¨ç«ä½¿ç¨ç¸ä¼¼æ§ææ¨ä¾ç¢ºå®æ¢æ§çåµæ¸¬ç°å¢ä¸­è§£éçç¸ä¼¼æ§ãç¸½é«èè¨ï¼ééæ¬è«æï¼æåè¨­è¨äºå¯ä»¥å¨ä¸åä½¿ç¨æ¡ä¾ä¸­æ¯æ´ç¥è­åç¨è§£éçæ¹æ³ï¼èéå°ç¶ä» AI æä»£ä¸­å¯ä»¥ç¢çéäºè§£éçæ¯æ´åä»¶åå¯ä»¥å¢å¼·éäºè§£éçé åç¥è­ä¾æºçæ¹æ³ã

##### **Contrasting Attitudes Towards Current and Future AI Applications for Computerised Interpretation of ECG: A Clinical Stakeholder Interview Study**
2410.16879v1 by Lukas Hughes-Noehrer, Leda Channer, Gabriel Strain, Gregory Yates, Richard Body, Caroline Jay

Objectives: To investigate clinicians' attitudes towards current automated
interpretation of ECG and novel AI technologies and their perception of
computer-assisted interpretation. Materials and Methods: We conducted a series
of interviews with clinicians in the UK. Our study: (i) explores the potential
for AI, specifically future 'human-like' computing approaches, to facilitate
ECG interpretation and support clinical decision making, and (ii) elicits their
opinions about the importance of explainability and trustworthiness of AI
algorithms. Results: We performed inductive thematic analysis on interview
transcriptions from 23 clinicians and identified the following themes: (i) a
lack of trust in current systems, (ii) positive attitudes towards future AI
applications and requirements for these, (iii) the relationship between the
accuracy and explainability of algorithms, and (iv) opinions on education,
possible deskilling, and the impact of AI on clinical competencies. Discussion:
Clinicians do not trust current computerised methods, but welcome future 'AI'
technologies. Where clinicians trust future AI interpretation to be accurate,
they are less concerned that it is explainable. They also preferred ECG
interpretation that demonstrated the results of the algorithm visually. Whilst
clinicians do not fear job losses, they are concerned about deskilling and the
need to educate the workforce to use AI responsibly. Conclusion: Clinicians are
positive about the future application of AI in clinical decision-making.
Accuracy is a key factor of uptake and visualisations are preferred over
current computerised methods. This is viewed as a potential means of training
and upskilling, in contrast to the deskilling that automation might be
perceived to bring.

æè¦ï¼<paragraph>ç®çï¼èª¿æ¥è¨åºé«çå°ç®åèªååå¿é»åè§£è®åæ°çäººå·¥æºæ§æè¡çæåº¦ï¼ä»¥åä»åå°é»è¦è¼å©è§£è®ççæ³ãææåæ¹æ³ï¼æåå°è±åçè¨åºé«çé²è¡äºä¸ç³»åè¨ªè«ãæåçç ç©¶ï¼(i) æ¢è¨äººå·¥æºæ§çæ½åï¼ç¹å¥æ¯æªä¾çãé¡äººé¡ãéç®æ¹æ³ï¼ä»¥ä¿é²å¿é»åè§£è®ä¸¦æ¯æè¨åºæ±ºç­å¶å®ï¼ä»¥å (ii) å¾µæ±ä»åå°äººå·¥æºæ§æ¼ç®æ³çå¯è§£éæ§åå¯ä¿¡åº¦ççæ³ãçµæï¼æåå° 23 ä½è¨åºé«ççè¨ªè«è¨éé²è¡äºæ­¸ç´ä¸»é¡åæï¼ä¸¦æ¾åºä»¥ä¸ä¸»é¡ï¼(i) å°ç®åç³»çµ±ç¼ºä¹ä¿¡ä»»ï¼(ii) å°æªä¾äººå·¥æºæ§æç¨åå°éäºæç¨çè¦æ±ææ­£é¢æåº¦ï¼(iii) æ¼ç®æ³çæºç¢ºæ§åå¯è§£éæ§ä¹éçéä¿ï¼ä»¥å (iv) å°æè²ãå¯è½çæè½éåï¼ä»¥åäººå·¥æºæ§å°è¨åºè½åçå½±é¿ççæ³ãè¨è«ï¼è¨åºé«çä¸ä¿¡ä»»ç®åçé»è¦åæ¹æ³ï¼ä½æ­¡è¿æªä¾çãäººå·¥æºæ§ãæè¡ãå¨è¨åºé«çç¸ä¿¡æªä¾ç AI è§£è®æºç¢ºçææ³ä¸ï¼ä»åä¸å¤ªæå¿å®æ¯å¦å¯è§£éãä»åä¹æ¯è¼åæ­¡è½ä»¥è¦è¦ºæ¹å¼åç¾æ¼ç®æ³çµæçå¿é»åè§£è®ãéç¶è¨åºé«çä¸å®³æå¤±æ¥­ï¼ä½ä»åæå¿æè½éåï¼ä»¥åéè¦æè²å¡å·¥è² è²¬ä»»å°ä½¿ç¨äººå·¥æºæ§ãçµè«ï¼è¨åºé«çå°äººå·¥æºæ§å¨è¨åºæ±ºç­å¶å®ä¸­çæªä¾æç¨ææ­£é¢æåº¦ãæºç¢ºæ§æ¯æ¡ç¨äººå·¥æºæ§çä¸åééµå ç´ ï¼èè¦è¦ºåæ¯ç®åçé»è¦åæ¹æ³æ´åéçãéè¢«è¦çºä¸ç¨®æ½å¨çå¹è¨åæåæè½çæ¹æ³ï¼èèªååå¯è½å¸¶ä¾çæè½éåå½¢æå°æ¯ã</paragraph>

##### **Pathologist-like explainable AI for interpretable Gleason grading in prostate cancer**
2410.15012v1 by Gesa Mittmann, Sara Laiouar-Pedari, Hendrik A. Mehrtens, Sarah HaggenmÃ¼ller, Tabea-Clara Bucher, Tirtha Chanda, Nadine T. Gaisa, Mathias Wagner, Gilbert Georg Klamminger, Tilman T. Rau, Christina Neppl, Eva Maria CompÃ©rat, Andreas Gocht, Monika HÃ¤mmerle, Niels J. Rupp, Jula Westhoff, Irene KrÃ¼cken, Maximillian Seidl, Christian M. SchÃ¼rch, Marcus Bauer, Wiebke Solass, Yu Chun Tam, Florian Weber, Rainer Grobholz, Jaroslaw Augustyniak, Thomas Kalinski, Christian HÃ¶rner, Kirsten D. Mertz, Constanze DÃ¶ring, Andreas Erbersdobler, Gabriele Deubler, Felix Bremmer, Ulrich Sommer, Michael Brodhun, Jon Griffin, Maria Sarah L. Lenon, Kiril Trpkov, Liang Cheng, Fei Chen, Angelique Levi, Guoping Cai, Tri Q. Nguyen, Ali Amin, Alessia Cimadamore, Ahmed Shabaik, Varsha Manucha, Nazeel Ahmad, Nidia Messias, Francesca Sanguedolce, Diana Taheri, Ezra Baraban, Liwei Jia, Rajal B. Shah, Farshid Siadat, Nicole Swarbrick, Kyung Park, Oudai Hassan, Siamak Sakhaie, Michelle R. Downes, Hiroshi Miyamoto, Sean R. Williamson, Tim Holland-Letz, Carolin V. Schneider, Jakob Nikolas Kather, Yuri Tolkach, Titus J. Brinker

The aggressiveness of prostate cancer, the most common cancer in men
worldwide, is primarily assessed based on histopathological data using the
Gleason scoring system. While artificial intelligence (AI) has shown promise in
accurately predicting Gleason scores, these predictions often lack inherent
explainability, potentially leading to distrust in human-machine interactions.
To address this issue, we introduce a novel dataset of 1,015 tissue microarray
core images, annotated by an international group of 54 pathologists. The
annotations provide detailed localized pattern descriptions for Gleason grading
in line with international guidelines. Utilizing this dataset, we develop an
inherently explainable AI system based on a U-Net architecture that provides
predictions leveraging pathologists' terminology. This approach circumvents
post-hoc explainability methods while maintaining or exceeding the performance
of methods trained directly for Gleason pattern segmentation (Dice score: 0.713
$\pm$ 0.003 trained on explanations vs. 0.691 $\pm$ 0.010 trained on Gleason
patterns). By employing soft labels during training, we capture the intrinsic
uncertainty in the data, yielding strong results in Gleason pattern
segmentation even in the context of high interobserver variability. With the
release of this dataset, we aim to encourage further research into segmentation
in medical tasks with high levels of subjectivity and to advance the
understanding of pathologists' reasoning processes.

æè¦ï¼ååèºçæ¯å¨çç·æ§æå¸¸è¦çççï¼å¶æ¡æ§ç¨åº¦ä¸»è¦æ ¹æ Gleason è©åç³»çµ±ä½¿ç¨çµç¹ççå­¸æ¸æé²è¡è©ä¼°ãéç¶äººå·¥æºæ§ (AI) å¨æºç¢ºé æ¸¬ Gleason è©åæ¹é¢å·²å±ç¾æ½åï¼ä½éäºé æ¸¬éå¸¸ç¼ºä¹å§å¨çå¯è§£éæ§ï¼å¯è½æå°è´å°äººæ©äºåçä¸ä¿¡ä»»ãçºäºè§£æ±ºéååé¡ï¼æåå¼é²äºä¸åç± 54 ä½ççå­¸å®¶çµæçåéåéè¨»è§£ç 1,015 åçµç¹å¾®é£åæ ¸å¿å½±åçæ°ç©è³æéãéäºè¨»è§£æä¾äºè©³ç´°çå±é¨æ¨¡å¼æè¿°ï¼ç¨æ¼ç¬¦ååéæºåç Gleason åç´ãå©ç¨éåè³æéï¼æåéç¼äºä¸ååºæ¼ U-Net æ¶æ§çå§å¨å¯è§£é AI ç³»çµ±ï¼è©²ç³»çµ±æä¾äºå©ç¨ççå­¸å®¶è¡èªé²è¡é æ¸¬ãéç¨®æ¹æ³è¦é¿äºäºå¾å¯è§£éæ§æ¹æ³ï¼åæç¶­ææè¶è¶äºç´æ¥è¨ç·´ç¨æ¼ Gleason æ¨¡å¼åå²çæ¹æ³çæè½ï¼Dice åæ¸ï¼0.713 Â± 0.003ï¼è¨ç·´æ¼è§£éï¼ç¸å°æ¼ 0.691 Â± 0.010ï¼è¨ç·´æ¼ Gleason æ¨¡å¼ï¼ãééå¨è¨ç·´æéæ¡ç¨è»æ¨ç±¤ï¼æåææäºè³æä¸­çå§å¨ä¸ç¢ºå®æ§ï¼å³ä½¿å¨è§å¯èéè®ç°æ§é«çææ³ä¸ï¼ä¹è½å¨ Gleason æ¨¡å¼åå²ä¸­ç¢çå¼·å¤§ççµæãéééåºéåè³æéï¼æåæ¨å¨é¼åµé²ä¸æ­¥ç ç©¶ä¸»è§æ§é«çé«çä»»åä¸­çåå²ï¼ä¸¦å¢é²å°ççå­¸å®¶æ¨çéç¨ççè§£ã

##### **Explainable AI Methods for Multi-Omics Analysis: A Survey**
2410.11910v1 by Ahmad Hussein, Mukesh Prasad, Ali Braytee

Advancements in high-throughput technologies have led to a shift from
traditional hypothesis-driven methodologies to data-driven approaches.
Multi-omics refers to the integrative analysis of data derived from multiple
'omes', such as genomics, proteomics, transcriptomics, metabolomics, and
microbiomics. This approach enables a comprehensive understanding of biological
systems by capturing different layers of biological information. Deep learning
methods are increasingly utilized to integrate multi-omics data, offering
insights into molecular interactions and enhancing research into complex
diseases. However, these models, with their numerous interconnected layers and
nonlinear relationships, often function as black boxes, lacking transparency in
decision-making processes. To overcome this challenge, explainable artificial
intelligence (xAI) methods are crucial for creating transparent models that
allow clinicians to interpret and work with complex data more effectively. This
review explores how xAI can improve the interpretability of deep learning
models in multi-omics research, highlighting its potential to provide
clinicians with clear insights, thereby facilitating the effective application
of such models in clinical settings.

æè¦ï¼é«ééæè¡çé²æ­¥å°è´å¾å³çµ±çåè¨­é©åæ¹æ³è½è®çºè³æé©åçæ¹æ³ãå¤çµå­¸æ¯ææ´ååæä¾èªå¤åãçµå­¸ãçè³æï¼ä¾å¦åºå çµå­¸ãèç½è³ªçµå­¸ãè½éçµå­¸ãä»£è¬çµå­¸åå¾®çç©çµå­¸ãæ­¤æ¹æ³ééæ·åçç©è³è¨çä¸åå±¤é¢ï¼è½å¨é¢äºè§£çç©ç³»çµ±ãæ·±åº¦å­¸ç¿æ¹æ³æä¾æå¸¸è¢«ç¨æ¼æ´åå¤çµå­¸è³æï¼æä¾åå­äº¤äºä½ç¨çæ´å¯åï¼ä¸¦å å¼·å°è¤éç¾ççç ç©¶ãç¶èï¼éäºæ¨¡åå·æè¨±å¤ç¸äºé£æ¥çå±¤ç´åéç·æ§éä¿ï¼éå¸¸æåé»çå­ä¸æ¨£éä½ï¼ç¼ºä¹æ±ºç­éç¨çéæåº¦ãçºäºåææ­¤ææ°ï¼å¯è§£éäººå·¥æºæ§ (xAI) æ¹æ³å°æ¼å»ºç«éææ¨¡åè³ééè¦ï¼è®è¨åºé«çå¯ä»¥æ´ææå°è§£éåèçè¤éè³æãæ­¤è©è«æ¢è¨ xAI å¦ä½è½æ¹åå¤çµå­¸ç ç©¶ä¸­æ·±åº¦å­¸ç¿æ¨¡åçå¯è§£éæ§ï¼å¼·èª¿å¶æä¾è¨åºé«çæç¢ºè¦è§£çæ½åï¼é²èä¿é²æ­¤é¡æ¨¡åå¨è¨åºç°å¢ä¸­çæææç¨ã

##### **Study on the Helpfulness of Explainable Artificial Intelligence**
2410.11896v1 by Tobias Labarta, Elizaveta Kulicheva, Ronja Froelian, Christian GeiÃler, Xenia Melman, Julian von Klitzing

Explainable Artificial Intelligence (XAI) is essential for building advanced
machine learning-powered applications, especially in critical domains such as
medical diagnostics or autonomous driving. Legal, business, and ethical
requirements motivate using effective XAI, but the increasing number of
different methods makes it challenging to pick the right ones. Further, as
explanations are highly context-dependent, measuring the effectiveness of XAI
methods without users can only reveal a limited amount of information,
excluding human factors such as the ability to understand it. We propose to
evaluate XAI methods via the user's ability to successfully perform a proxy
task, designed such that a good performance is an indicator for the explanation
to provide helpful information. In other words, we address the helpfulness of
XAI for human decision-making. Further, a user study on state-of-the-art
methods was conducted, showing differences in their ability to generate trust
and skepticism and the ability to judge the rightfulness of an AI decision
correctly. Based on the results, we highly recommend using and extending this
approach for more objective-based human-centered user studies to measure XAI
performance in an end-to-end fashion.

æè¦ï¼å¯è§£éäººå·¥æºæ§ (XAI) å°æ¼å»ºæ§åé²çæ©å¨å­¸ç¿é©åæç¨ç¨å¼è³ééè¦ï¼ç¹å¥æ¯å¨é«çè¨ºæ·æèªåé§é§ç­ééµé åãæ³å¾ãåæ¥­åå«çè¦æ±ä¿ä½¿ä½¿ç¨ææç XAIï¼ä½æ¸éæ¥çå¢å çä¸åæ¹æ³ä½¿å¾æé¸æ­£ç¢ºçæ¹æ³å·æææ°æ§ãæ­¤å¤ï¼ç±æ¼è§£éé«åº¦ä¾è³´æ¼èæ¯ï¼å¨æ²æä½¿ç¨èçææ³ä¸è¡¡é XAI æ¹æ³çæææ§åªè½æ­ç¤ºæéçè³è¨ï¼æé¤äººé¡å ç´ ï¼ä¾å¦çè§£å®çè½åãæåå»ºè­°ééä½¿ç¨èæåå·è¡ä»£çä»»åçè½åä¾è©ä¼° XAI æ¹æ³ï¼è¨­è¨ä½¿å¾è¯å¥½çå·è¡è¡¨ç¾æ¯è§£éæä¾æç¨è³è¨çææ¨ãæå¥è©±èªªï¼æåæ¢è¨ XAI å°äººé¡æ±ºç­å¶å®çå¹«å©ãæ­¤å¤ï¼å°æåé²çæ¹æ³é²è¡ä½¿ç¨èç ç©¶ï¼é¡¯ç¤ºåºå®åå¨ç¢çä¿¡ä»»åæ·ççè½åä»¥åæ­£ç¢ºå¤æ· AI æ±ºç­æ¯å¦æ­£ç¢ºçè½åæ¹é¢å­å¨å·®ç°ãæ ¹æçµæï¼æåå¼·çå»ºè­°ä½¿ç¨åæ´åéç¨®æ¹æ³ï¼ä»¥é²è¡æ´å¤ä»¥ç®æ¨çºåºç¤çäººçºä¸­å¿ä½¿ç¨èç ç©¶ï¼ä»¥çµç«¯å°çµç«¯çæ¹å¼è¡¡é XAI æè½ã

##### **Use of What-if Scenarios to Help Explain Artificial Intelligence Models for Neonatal Health**
2410.09635v1 by Abdullah Mamun, Lawrence D. Devoe, Mark I. Evans, David W. Britt, Judith Klein-Seetharaman, Hassan Ghasemzadeh

Early detection of intrapartum risk enables interventions to potentially
prevent or mitigate adverse labor outcomes such as cerebral palsy. Currently,
there is no accurate automated system to predict such events to assist with
clinical decision-making. To fill this gap, we propose "Artificial Intelligence
(AI) for Modeling and Explaining Neonatal Health" (AIMEN), a deep learning
framework that not only predicts adverse labor outcomes from maternal, fetal,
obstetrical, and intrapartum risk factors but also provides the model's
reasoning behind the predictions made. The latter can provide insights into
what modifications in the input variables of the model could have changed the
predicted outcome. We address the challenges of imbalance and small datasets by
synthesizing additional training data using Adaptive Synthetic Sampling
(ADASYN) and Conditional Tabular Generative Adversarial Networks (CTGAN). AIMEN
uses an ensemble of fully-connected neural networks as the backbone for its
classification with the data augmentation supported by either ADASYN or CTGAN.
AIMEN, supported by CTGAN, outperforms AIMEN supported by ADASYN in
classification. AIMEN can predict a high risk for adverse labor outcomes with
an average F1 score of 0.784. It also provides counterfactual explanations that
can be achieved by changing 2 to 3 attributes on average. Resources available:
https://github.com/ab9mamun/AIMEN.

æè¦ï¼ç¢ç¨ä¸­é¢¨éªçæ©æåµæ¸¬æå©æ¼é²è¡å¹²é æªæ½ï¼ä»¥é é²ææ¸è¼ä¸å©ççç¢çµæï¼ä¾å¦è¦æ§éº»çºãç®åï¼æ²ææºç¢ºçèªååç³»çµ±å¯ä»¥é æ¸¬æ­¤é¡äºä»¶ï¼ä»¥åå©è¨åºæ±ºç­ãçºäºå¡«è£éä¸ç©ºç½ï¼æåæåºãç¨æ¼å»ºæ¨¡åè§£éæ°çåå¥åº·çäººå·¥æºæ§ã(AIMEN)ï¼éæ¯ä¸åæ·±åº¦å­¸ç¿æ¶æ§ï¼å®ä¸åå¯ä»¥æ ¹æå­ç¢å©¦ãèåãç¢ç§åç¢ç¨é¢¨éªå ç´ é æ¸¬ä¸å©ççç¢çµæï¼éè½æä¾æ¨¡åååºé æ¸¬èå¾çåå ãå¾èå¯ä»¥æä¾è¦è§£ï¼èªªææ¨¡åè¼¸å¥è®æ¸ä¸­çåªäºä¿®æ¹å¯è½ææ¹è®é æ¸¬çµæãæåééä½¿ç¨é©ææ§åææ½æ¨£ (ADASYN) åæ¢ä»¶è¡¨æ ¼çæå°æç¶²è·¯ (CTGAN) ä¾åæé¡å¤çè¨ç·´è³æï¼ä»¥è§£æ±ºä¸å¹³è¡¡åå°åè³æéçææ°ãAIMEN ä½¿ç¨å¨é£æ¥ç¥ç¶ç¶²è·¯çéåä½çºå¶åé¡çéª¨å¹¹ï¼ä¸¦éé ADASYN æ CTGAN æ¯æ´è³ææ´åãç± CTGAN æ¯æ´ç AIMEN å¨åé¡æ¹é¢åªæ¼ç± ADASYN æ¯æ´ç AIMENãAIMEN å¯ä»¥é æ¸¬ä¸å©ççç¢çµæçé«é¢¨éªï¼å¹³å F1 åæ¸çº 0.784ãå®éæä¾åäºå¯¦è§£éï¼å¯ééå¹³åè®æ´ 2 è³ 3 åå±¬æ§ä¾éæãå¯ç¨è³æºï¼https://github.com/ab9mamun/AIMENã

##### **Artificial intelligence techniques in inherited retinal diseases: A review**
2410.09105v1 by Han Trinh, Jordan Vice, Jason Charng, Zahra Tajbakhsh, Khyber Alam, Fred K. Chen, Ajmal Mian

Inherited retinal diseases (IRDs) are a diverse group of genetic disorders
that lead to progressive vision loss and are a major cause of blindness in
working-age adults. The complexity and heterogeneity of IRDs pose significant
challenges in diagnosis, prognosis, and management. Recent advancements in
artificial intelligence (AI) offer promising solutions to these challenges.
However, the rapid development of AI techniques and their varied applications
have led to fragmented knowledge in this field. This review consolidates
existing studies, identifies gaps, and provides an overview of AI's potential
in diagnosing and managing IRDs. It aims to structure pathways for advancing
clinical applications by exploring AI techniques like machine learning and deep
learning, particularly in disease detection, progression prediction, and
personalized treatment planning. Special focus is placed on the effectiveness
of convolutional neural networks in these areas. Additionally, the integration
of explainable AI is discussed, emphasizing its importance in clinical settings
to improve transparency and trust in AI-based systems. The review addresses the
need to bridge existing gaps in focused studies on AI's role in IRDs, offering
a structured analysis of current AI techniques and outlining future research
directions. It concludes with an overview of the challenges and opportunities
in deploying AI for IRDs, highlighting the need for interdisciplinary
collaboration and the continuous development of robust, interpretable AI models
to advance clinical applications.

æè¦ï¼éºå³æ§è¦ç¶²èç¾ç (IRD) æ¯ä¸çµå¤æ¨£åçéºå³ç¾çï¼
æå°è´è¦åéæ¼¸åªå¤±ï¼æ¯å·¥ä½å¹´é½¡æäººå¤±æçä¸»è¦åå ãIRD çè¤éæ§åç°è³ªæ§å°è¨ºæ·ãé å¾åç®¡çæåºäºéå¤§ææ°ãæè¿äººå·¥æºè½ (AI) çé²æ­¥çºéäºææ°æä¾äºæå¸æçè§£æ±ºæ¹æ¡ã
ç¶èï¼AI æè¡çå¿«éç¼å±åå¶å¤ç¨®æç¨å°è´äºè©²é åçç¥è­åæ£ãæ¬ç¶è¿°æ´åäºç¾æç ç©¶ï¼æ¾åºå·®è·ï¼ä¸¦æ¦è¿°äº AI å¨è¨ºæ·åç®¡ç IRD ä¸­çæ½åãå®æ¨å¨ééæ¢ç´¢æ©å¨å­¸ç¿åæ·±åº¦å­¸ç¿ç­ AI æè¡ï¼ç¹å¥æ¯å¨ç¾çæª¢æ¸¬ãé²ç¨é æ¸¬ååæ§åæ²»çè¨åä¸­ï¼çºæ¨é²è¨åºæç¨æ§å»ºéå¾ãç¹å¥éæ³¨éäºé åä¸­å·ç©ç¥ç¶ç¶²è·¯çæææ§ãæ­¤å¤ï¼è¨è«äºå¯è§£é AI çæ´åï¼å¼·èª¿äºå¶å¨è¨åºç°å¢ä¸­æé«éæåº¦åå°åºæ¼ AI çç³»çµ±çä¿¡ä»»çéè¦æ§ãè©²ç¶è¿°è§£æ±ºäºå½å AI å¨ IRD ä¸­ä½ç¨çéé»ç ç©¶ä¸­ç¾æå·®è·çå¿è¦æ§ï¼æä¾äºå°ç¶å AI æè¡ççµæ§ååæï¼ä¸¦æ¦è¿°äºæªä¾çç ç©¶æ¹åãæå¾æ¦è¿°äºå¨ IRD ä¸­é¨ç½² AI çææ°åæ©éï¼å¼·èª¿äºè·¨å­¸ç§åä½åæçºéç¼å¼·å¤§ãå¯è§£éç AI æ¨¡åä»¥æ¨é²è¨åºæç¨çå¿è¦æ§ã

##### **CasiMedicos-Arg: A Medical Question Answering Dataset Annotated with Explanatory Argumentative Structures**
2410.05235v2 by Ekaterina Sviridova, Anar Yeginbergen, Ainara Estarrona, Elena Cabrio, Serena Villata, Rodrigo Agerri

Explaining Artificial Intelligence (AI) decisions is a major challenge
nowadays in AI, in particular when applied to sensitive scenarios like medicine
and law. However, the need to explain the rationale behind decisions is a main
issue also for human-based deliberation as it is important to justify
\textit{why} a certain decision has been taken. Resident medical doctors for
instance are required not only to provide a (possibly correct) diagnosis, but
also to explain how they reached a certain conclusion. Developing new tools to
aid residents to train their explanation skills is therefore a central
objective of AI in education. In this paper, we follow this direction, and we
present, to the best of our knowledge, the first multilingual dataset for
Medical Question Answering where correct and incorrect diagnoses for a clinical
case are enriched with a natural language explanation written by doctors. These
explanations have been manually annotated with argument components (i.e.,
premise, claim) and argument relations (i.e., attack, support), resulting in
the Multilingual CasiMedicos-Arg dataset which consists of 558 clinical cases
in four languages (English, Spanish, French, Italian) with explanations, where
we annotated 5021 claims, 2313 premises, 2431 support relations, and 1106
attack relations. We conclude by showing how competitive baselines perform over
this challenging dataset for the argument mining task.

æè¦ï¼è§£éäººå·¥æºæ§ (AI) çæ±ºç­æ¯ç¾å¨ AI çä¸é éå¤§ææ°ï¼ç¹å¥æ¯æç¨æ¼åé«å­¸åæ³å¾ç­æææå¢æãç¶èï¼è§£éæ±ºç­èå¾çç±çéæ±ä¹æ¯åºæ¼äººé¡çèéçä¸åä¸»è¦åé¡ï¼å çºæå¿è¦è­æçºä»éº¼ååºæåæ±ºç­ãä¾å¦ï¼ä½é¢é«å¸«ä¸åéè¦æä¾ï¼å¯è½æ¯æ­£ç¢ºçï¼è¨ºæ·ï¼ééè¦è§£éä»åå¦ä½éææåçµè«ãå æ­¤ï¼éç¼æ°çå·¥å·ä¾å¹«å©ä½é¢é«å¸«è¨ç·´ä»åçè§£éæå·§æ¯æè²ä¸­ AI çä¸é æ ¸å¿ç®æ¨ãå¨æ¬æä¸­ï¼æåéµå¾ªéåæ¹åï¼ä¸¦ä¸æ ¹ææåçäºè§£ï¼æåºç¬¬ä¸åå¤èªè¨é«å­¸åç­è³æéï¼å¶ä¸­è¨åºçä¾çæ­£ç¢ºåä¸æ­£ç¢ºè¨ºæ·é½éæç±é«çæ°å¯«çèªç¶èªè¨è§£éãéäºè§£éå·²ä½¿ç¨è«è­çµæï¼å³åæãä¸»å¼µï¼åè«è­éä¿ï¼å³æ»æãæ¯æï¼é²è¡æåè¨»è§£ï¼ç¢çå¤èªè¨ CasiMedicos-Arg è³æéï¼å¶ä¸­åå« 558 åå·æè§£éçåç¨®èªè¨ï¼è±èªãè¥¿ç­çèªãæ³èªãç¾©å¤§å©èªï¼çè¨åºçä¾ï¼æåè¨»è§£äº 5021 åä¸»å¼µã2313 ååæã2431 åæ¯æéä¿å 1106 åæ»æéä¿ãæåæå¾å±ç¤ºäºç«¶ç­åºæºå¦ä½éå°è«è­æ¢åä»»åå·è¡æ­¤å·ææ°æ§çè³æéã

##### **Explainable Diagnosis Prediction through Neuro-Symbolic Integration**
2410.01855v2 by Qiuhao Lu, Rui Li, Elham Sagheb, Andrew Wen, Jinlian Wang, Liwei Wang, Jungwei W. Fan, Hongfang Liu

Diagnosis prediction is a critical task in healthcare, where timely and
accurate identification of medical conditions can significantly impact patient
outcomes. Traditional machine learning and deep learning models have achieved
notable success in this domain but often lack interpretability which is a
crucial requirement in clinical settings. In this study, we explore the use of
neuro-symbolic methods, specifically Logical Neural Networks (LNNs), to develop
explainable models for diagnosis prediction. Essentially, we design and
implement LNN-based models that integrate domain-specific knowledge through
logical rules with learnable thresholds. Our models, particularly
$M_{\text{multi-pathway}}$ and $M_{\text{comprehensive}}$, demonstrate superior
performance over traditional models such as Logistic Regression, SVM, and
Random Forest, achieving higher accuracy (up to 80.52\%) and AUROC scores (up
to 0.8457) in the case study of diabetes prediction. The learned weights and
thresholds within the LNN models provide direct insights into feature
contributions, enhancing interpretability without compromising predictive
power. These findings highlight the potential of neuro-symbolic approaches in
bridging the gap between accuracy and explainability in healthcare AI
applications. By offering transparent and adaptable diagnostic models, our work
contributes to the advancement of precision medicine and supports the
development of equitable healthcare solutions. Future research will focus on
extending these methods to larger and more diverse datasets to further validate
their applicability across different medical conditions and populations.

æè¦ï¼è¨ºæ·é æ¸¬æ¯é«çä¿å¥ä¸­çééµä»»åï¼åæä¸æºç¢ºå°è­å¥é«ççæ³æé¡¯èå½±é¿æ£èççµæãå³çµ±çæ©å¨å­¸ç¿åæ·±åº¦å­¸ç¿æ¨¡åå·²å¨éåé ååå¾é¡¯èæåï¼ä½éå¸¸ç¼ºä¹å¯è§£éæ§ï¼éå¨è¨åºç°å¢ä¸­æ¯ä¸é ééµè¦æ±ãå¨æ¬ç ç©¶ä¸­ï¼æåæ¢è¨äºç¥ç¶ç¬¦èæ¹æ³çæç¨ï¼ç¹å¥æ¯éè¼¯ç¥ç¶ç¶²è·¯ (LNN)ï¼ä»¥éç¼ç¨æ¼è¨ºæ·é æ¸¬çå¯è§£éæ¨¡åãåºæ¬ä¸ï¼æåè¨­è¨ä¸¦å¯¦ä½äºåºæ¼ LNN çæ¨¡åï¼éäºæ¨¡åééå·æå¯å­¸ç¿é¾å¼çéè¼¯è¦åæ´åé åç¹å®ç¥è­ãæåçæ¨¡åï¼ç¹å¥æ¯ $M_{\text{multi-pathway}}$ å $M_{\text{comprehensive}}$ï¼è¡¨ç¾åºåªæ¼å³çµ±æ¨¡åï¼ä¾å¦éè¼¯è¿´æ­¸ãSVM åé¨æ©æ£®æï¼çåªç°æè½ï¼å¨ç³å°¿çé æ¸¬çæ¡ä¾ç ç©¶ä¸­éå°äºæ´é«çæºç¢ºåº¦ï¼é«é 80.52%ï¼å AUROC åæ¸ï¼é«é 0.8457ï¼ãLNN æ¨¡åä¸­å­¸ç¿å°çæ¬éåé¾å¼æä¾äºå°ç¹å¾µè²¢ç»çç´æ¥è¦è§£ï¼å¢å¼·äºå¯è§£éæ§ï¼åæä¸å½±é¿é æ¸¬è½åãéäºç¼ç¾çªé¡¯äºç¥ç¶ç¬¦èæ¹æ³å¨å½åé«çä¿å¥ AI æç¨ä¸­æºç¢ºæ§åå¯è§£éæ§å·®è·æ¹é¢çæ½åãééæä¾éæä¸é©ææ§å¼·çè¨ºæ·æ¨¡åï¼æåçç ç©¶æå©æ¼æ¨é²ç²¾æºé«çï¼ä¸¦æ¯æ´å¬å¹³é«çä¿å¥è§£æ±ºæ¹æ¡çéç¼ãæªä¾çç ç©¶å°å°æ³¨æ¼å°éäºæ¹æ³æ´å±å°æ´å¤§ä¸æ´å¤æ¨£åçè³æéï¼ä»¥é²ä¸æ­¥é©è­å¶å¨ä¸åé«ççæ³åäººç¾¤ä¸­çé©ç¨æ§ã

##### **Easydiagnos: a framework for accurate feature selection for automatic diagnosis in smart healthcare**
2410.00366v1 by Prasenjit Maji, Amit Kumar Mondal, Hemanta Kumar Mondal, Saraju P. Mohanty

The rapid advancements in artificial intelligence (AI) have revolutionized
smart healthcare, driving innovations in wearable technologies, continuous
monitoring devices, and intelligent diagnostic systems. However, security,
explainability, robustness, and performance optimization challenges remain
critical barriers to widespread adoption in clinical environments. This
research presents an innovative algorithmic method using the Adaptive Feature
Evaluator (AFE) algorithm to improve feature selection in healthcare datasets
and overcome problems. AFE integrating Genetic Algorithms (GA), Explainable
Artificial Intelligence (XAI), and Permutation Combination Techniques (PCT),
the algorithm optimizes Clinical Decision Support Systems (CDSS), thereby
enhancing predictive accuracy and interpretability. The proposed method is
validated across three diverse healthcare datasets using six distinct machine
learning algorithms, demonstrating its robustness and superiority over
conventional feature selection techniques. The results underscore the
transformative potential of AFE in smart healthcare, enabling personalized and
transparent patient care. Notably, the AFE algorithm, when combined with a
Multi-layer Perceptron (MLP), achieved an accuracy of up to 98.5%, highlighting
its capability to improve clinical decision-making processes in real-world
healthcare applications.

æè¦ï¼äººå·¥æºæ§ (AI) çå¿«éé²å±å¾¹åºæ¹è®äºæºæ§é«çä¿å¥ï¼æ¨åäºå¯ç©¿æ´æè¡ãæçºç£æ§è£ç½®åæºæ§è¨ºæ·ç³»çµ±çåµæ°ãç¶èï¼å®å¨æ§ãå¯è§£éæ§ãç©©å¥æ§åæè½æä½³åææ°ä»ç¶æ¯è¨åºç°å¢ä¸­å»£æ³æ¡ç¨çééµéç¤ãæ¬ç ç©¶æåºä¸ååµæ°çæ¼ç®æ³æ¹æ³ï¼ä½¿ç¨èªé©æç¹å¾µè©ä¼°å¨ (AFE) æ¼ç®æ³ä¾æ¹åé«çä¿å¥è³æéä¸­çç¹å¾µé¸åä¸¦åæåé¡ãAFE æ´åäºéºå³æ¼ç®æ³ (GA)ãå¯è§£éäººå·¥æºæ§ (XAI) åæåçµåæè¡ (PCT)ï¼è©²æ¼ç®æ³æä½³åäºè¨åºæ±ºç­æ¯æ´ç³»çµ± (CDSS)ï¼å¾èæé«äºé æ¸¬æºç¢ºæ§åå¯è§£éæ§ãææåºçæ¹æ³ä½¿ç¨å­ç¨®ä¸åçæ©å¨å­¸ç¿æ¼ç®æ³é©è­äºä¸åä¸åçé«çä¿å¥è³æéï¼è­æäºå¶ç©©å¥æ§ååªæ¼å³çµ±ç¹å¾µé¸åæè¡ãçµæå¼·èª¿äº AFE å¨æºæ§é«çä¿å¥ä¸­çè½è®æ½åï¼å¯¦ç¾äºåäººååéæçæ£èç§è­·ãå¼å¾æ³¨æçæ¯ï¼AFE æ¼ç®æ³èå¤å±¤æç¥å¨ (MLP) çµåä½¿ç¨æï¼æºç¢ºåº¦é«é 98.5%ï¼çªé¡¯äºå¶æ¹åå¯¦éé«çä¿å¥æç¨ä¸­è¨åºæ±ºç­å¶å®æµç¨çè½åã

##### **Dermatologist-like explainable AI enhances melanoma diagnosis accuracy: eye-tracking study**
2409.13476v1 by Tirtha Chanda, Sarah Haggenmueller, Tabea-Clara Bucher, Tim Holland-Letz, Harald Kittler, Philipp Tschandl, Markus V. Heppt, Carola Berking, Jochen S. Utikal, Bastian Schilling, Claudia Buerger, Cristian Navarrete-Dechent, Matthias Goebeler, Jakob Nikolas Kather, Carolin V. Schneider, Benjamin Durani, Hendrike Durani, Martin Jansen, Juliane Wacker, Joerg Wacker, Reader Study Consortium, Titus J. Brinker

Artificial intelligence (AI) systems have substantially improved
dermatologists' diagnostic accuracy for melanoma, with explainable AI (XAI)
systems further enhancing clinicians' confidence and trust in AI-driven
decisions. Despite these advancements, there remains a critical need for
objective evaluation of how dermatologists engage with both AI and XAI tools.
In this study, 76 dermatologists participated in a reader study, diagnosing 16
dermoscopic images of melanomas and nevi using an XAI system that provides
detailed, domain-specific explanations. Eye-tracking technology was employed to
assess their interactions. Diagnostic performance was compared with that of a
standard AI system lacking explanatory features. Our findings reveal that XAI
systems improved balanced diagnostic accuracy by 2.8 percentage points relative
to standard AI. Moreover, diagnostic disagreements with AI/XAI systems and
complex lesions were associated with elevated cognitive load, as evidenced by
increased ocular fixations. These insights have significant implications for
clinical practice, the design of AI tools for visual tasks, and the broader
development of XAI in medical diagnostics.

æè¦ï¼äººå·¥æºæ§ (AI) ç³»çµ±å·²å¤§å¹æ¹åç®èç§é«å¸«å°é»è²ç´ ç¤çè¨ºæ·æºç¢ºåº¦ï¼èå¯è§£é AI (XAI) ç³»çµ±é²ä¸æ­¥æåè¨åºé«å¸«å° AI é©åæ±ºç­çä¿¡å¿èä¿¡è³´ãåç®¡æéäºé²å±ï¼å°æ¼ç®èç§é«å¸«å¦ä½ä½¿ç¨ AI å XAI å·¥å·ï¼ä»æå®¢è§è©ä¼°çè¿«åéæ±ãå¨éé ç ç©¶ä¸­ï¼76 ä½ç®èç§é«å¸«åèäºä¸é è®èç ç©¶ï¼ä½¿ç¨ XAI ç³»çµ±è¨ºæ· 16 å¼µé»è²ç´ ç¤åç£çç®èé¡å½±åï¼è©²ç³»çµ±æä¾è©³ç´°çé åç¹å®èªªæãæ¡ç¨ç¼çè¿½è¹¤æè¡ä¾è©ä¼°ä»åçäºåãå°è¨ºæ·è¡¨ç¾èç¼ºä¹èªªæåè½çæ¨æº AI ç³»çµ±é²è¡æ¯è¼ãæåçç ç©¶çµæé¡¯ç¤ºï¼XAI ç³»çµ±ç¸è¼æ¼æ¨æº AIï¼å°å¹³è¡¡è¨ºæ·æºç¢ºåº¦æåäº 2.8 åç¾åé»ãæ­¤å¤ï¼è AI/XAI ç³»çµ±çè¨ºæ·åæ­§åè¤éççç¶èèªç¥è² æåé«æéï¼éç±å¢å çç¼çæ³¨è¦æ¬¡æ¸æè­å¯¦ãéäºè¦è§£å°è¨åºå¯¦åãè¦è¦ºä»»å AI å·¥å·çè¨­è¨åé«å­¸è¨ºæ·ä¸­ XAI çå»£æ³ç¼å±å·æéå¤§æç¾©ã

##### **Explainable AI for Autism Diagnosis: Identifying Critical Brain Regions Using fMRI Data**
2409.15374v1 by Suryansh Vidya, Kush Gupta, Amir Aly, Andy Wills, Emmanuel Ifeachor, Rohit Shankar

Early diagnosis and intervention for Autism Spectrum Disorder (ASD) has been
shown to significantly improve the quality of life of autistic individuals.
However, diagnostics methods for ASD rely on assessments based on clinical
presentation that are prone to bias and can be challenging to arrive at an
early diagnosis. There is a need for objective biomarkers of ASD which can help
improve diagnostic accuracy. Deep learning (DL) has achieved outstanding
performance in diagnosing diseases and conditions from medical imaging data.
Extensive research has been conducted on creating models that classify ASD
using resting-state functional Magnetic Resonance Imaging (fMRI) data. However,
existing models lack interpretability. This research aims to improve the
accuracy and interpretability of ASD diagnosis by creating a DL model that can
not only accurately classify ASD but also provide explainable insights into its
working. The dataset used is a preprocessed version of the Autism Brain Imaging
Data Exchange (ABIDE) with 884 samples. Our findings show a model that can
accurately classify ASD and highlight critical brain regions differing between
ASD and typical controls, with potential implications for early diagnosis and
understanding of the neural basis of ASD. These findings are validated by
studies in the literature that use different datasets and modalities,
confirming that the model actually learned characteristics of ASD and not just
the dataset. This study advances the field of explainable AI in medical imaging
by providing a robust and interpretable model, thereby contributing to a future
with objective and reliable ASD diagnostics.

æè¦ï¼èªéçè­ç³»éç¤ (ASD) çæ©æè¨ºæ·åä»å¥å·²è¢«è­å¯¦è½é¡¯èæ¹åèªéçæ£èççæ´»åè³ªãç¶èï¼ASD çè¨ºæ·æ¹æ³ä¾è³´æ¼åºæ¼è¨åºè¡¨ç¾çè©ä¼°ï¼å®¹æç¢çåè¦ï¼ä¸å¯è½é£ä»¥ååºæ©æè¨ºæ·ãæå¿è¦æ¾åº ASD çå®¢è§çç©æ¨è¨ï¼ä»¥å¹«å©æé«è¨ºæ·æºç¢ºæ§ãæ·±åº¦å­¸ç¿ (DL) å¨å¾é«å­¸å½±åè³æè¨ºæ·ç¾çåççæ¹é¢åå¾ååºçè¡¨ç¾ãå·²ç¶éå°å»ºç«ä½¿ç¨éæåè½æ§ç£æ¯é å½± (fMRI) è³æå° ASD é²è¡åé¡çæ¨¡åé²è¡å»£æ³çç ç©¶ãç¶èï¼ç¾æçæ¨¡åç¼ºä¹å¯è§£éæ§ãæ¬ç ç©¶æ¨å¨ééå»ºç«ä¸åä¸åè½æºç¢ºåé¡ ASDï¼éè½æä¾å¯è§£éè¦è§£èªªæå¶éä½åçç DL æ¨¡åï¼ä¾æ¹å ASD è¨ºæ·çæºç¢ºæ§åå¯è§£éæ§ãæä½¿ç¨çè³æéæ¯èªéçå¤§è¦å½±åè³æäº¤æ (ABIDE) çé èççæ¬ï¼åå« 884 åæ¨£æ¬ãæåçç ç©¶çµæé¡¯ç¤ºï¼è©²æ¨¡åè½æºç¢ºåé¡ ASDï¼ä¸¦å¼·èª¿ ASD èå¸åå°ç§çµä¹éå­å¨å·®ç°çééµè¦åï¼å°æ¼ ASD çæ©æè¨ºæ·åç¥ç¶åºç¤ççè§£å·ææ½å¨çæç¾©ãéäºç ç©¶çµæå·²ç±ä½¿ç¨ä¸åè³æéåæ¹å¼çæç»ç ç©¶é©è­ï¼è­å¯¦è©²æ¨¡åå¯¦éä¸å­¸ç¿äº ASD çç¹å¾µï¼èä¸ååæ¯è³æéãæ¬ç ç©¶ééæä¾ä¸åå¼·å¥ä¸å¯è§£éçæ¨¡åï¼æ¨åäºé«å­¸å½±åä¸­å¯è§£é AI çé åï¼å¾èçºæªä¾æä¾å®¢è§ä¸å¯é ç ASD è¨ºæ·ååºè²¢ç»ã

##### **Improving Prototypical Parts Abstraction for Case-Based Reasoning Explanations Designed for the Kidney Stone Type Recognition**
2409.12883v1 by Daniel Flores-Araiza, Francisco Lopez-Tiro, ClÃ©ment Larose, Salvador Hinojosa, Andres Mendez-Vazquez, Miguel Gonzalez-Mendoza, Gilberto Ochoa-Ruiz, Christian Daul

The in-vivo identification of the kidney stone types during an ureteroscopy
would be a major medical advance in urology, as it could reduce the time of the
tedious renal calculi extraction process, while diminishing infection risks.
Furthermore, such an automated procedure would make possible to prescribe
anti-recurrence treatments immediately. Nowadays, only few experienced
urologists are able to recognize the kidney stone types in the images of the
videos displayed on a screen during the endoscopy. Thus, several deep learning
(DL) models have recently been proposed to automatically recognize the kidney
stone types using ureteroscopic images. However, these DL models are of black
box nature whicl limits their applicability in clinical settings. This
contribution proposes a case-based reasoning DL model which uses prototypical
parts (PPs) and generates local and global descriptors. The PPs encode for each
class (i.e., kidney stone type) visual feature information (hue, saturation,
intensity and textures) similar to that used by biologists. The PPs are
optimally generated due a new loss function used during the model training.
Moreover, the local and global descriptors of PPs allow to explain the
decisions ("what" information, "where in the images") in an understandable way
for biologists and urologists. The proposed DL model has been tested on a
database including images of the six most widespread kidney stone types. The
overall average classification accuracy was 90.37. When comparing this results
with that of the eight other DL models of the kidney stone state-of-the-art, it
can be seen that the valuable gain in explanability was not reached at the
expense of accuracy which was even slightly increased with respect to that
(88.2) of the best method of the literature. These promising and interpretable
results also encourage urologists to put their trust in AI-based solutions.

æè¦ï¼å°¿è·¯é¡æª¢æ¥ä¸­èçµç³é¡åçé«å§è­å¥å°æ¯æ³å°¿ç§çä¸é éå¤§é²å±ï¼å çºå®å¯ä»¥æ¸å°ç¹ç£çèçµç³ååºéç¨çæéï¼åæéä½ææé¢¨éªãæ­¤å¤ï¼éç¨®èªååç¨åºå°ä½¿ç«å³éç«æå¾©ç¼æ²»çæçºå¯è½ãå¦ä»ï¼åªæå°æ¸ç¶é©è±å¯çæ³å°¿ç§é«çè½å¤ å¨å§è¦é¡æª¢æ¥æéå±å¹ä¸é¡¯ç¤ºçè¦é »ååä¸­è­å¥èçµç³é¡åãå æ­¤ï¼æè¿å·²æåºå¤ç¨®æ·±åº¦å­¸ç¿ (DL) æ¨¡åï¼ä»¥ä½¿ç¨è¼¸å°¿ç®¡é¡ååèªåè­å¥èçµç³é¡åãç¶èï¼éäº DL æ¨¡åæ¬è³ªä¸æ¯é»çå­ï¼ééå¶äºå®åå¨è¨åºç°å¢ä¸­çæç¨æ§ãæ¬ææåºäºä¸ååºæ¼æ¡ä¾æ¨çç DL æ¨¡åï¼å®ä½¿ç¨ååé¨å (PP) ä¸¦çæå±é¨åå¨å±æè¿°ç¬¦ãPP çºæ¯ç¨®é¡åï¼å³èçµç³é¡åï¼ç·¨ç¢¼è¦è¦ºç¹å¾µä¿¡æ¯ï¼è²èª¿ãé£½ååº¦ãå¼·åº¦åç´çï¼ï¼é¡ä¼¼æ¼çç©å­¸å®¶ä½¿ç¨çä¿¡æ¯ãç±æ¼å¨æ¨¡åè¨ç·´æéä½¿ç¨çæ°æå¤±å½æ¸ï¼PP å¾å°äºæä½³çæãæ­¤å¤ï¼PP çå±é¨åå¨å±æè¿°ç¬¦åè¨±ä»¥çç©å­¸å®¶åæ³å°¿ç§é«çå¯ä»¥çè§£çæ¹å¼è§£éæ±ºç­ï¼âä»éº¼âä¿¡æ¯ï¼âååä¸­çä»éº¼ä½ç½®âï¼ãææåºç DL æ¨¡åå·²å¨ä¸ååå«å­ç¨®æå»£æ³çèçµç³é¡åååçæ¸æåº«ä¸é²è¡äºæ¸¬è©¦ãç¸½é«å¹³ååé¡æºç¢ºççº 90.37ãå°æ­¤çµæèèçµç³æåé²çå«åå¶ä» DL æ¨¡åççµæé²è¡æ¯è¼æï¼å¯ä»¥çåºï¼å¯è§£éæ§çå¯¶è²´å¢çä¸¦æªä»¥æºç¢ºæ§çºä»£å¹ï¼çè³ç¥æå¢å èæç»ä¸­æå¥½çæ¹æ³ (88.2) ç¸æ¯ãéäºæå¸æä¸å¯è§£éççµæä¹é¼åµæ³å°¿ç§é«çç¸ä¿¡åºæ¼äººå·¥æºè½çè§£æ±ºæ¹æ¡ã

##### **Towards Interpretable End-Stage Renal Disease (ESRD) Prediction: Utilizing Administrative Claims Data with Explainable AI Techniques**
2409.12087v3 by Yubo Li, Saba Al-Sayouri, Rema Padman

This study explores the potential of utilizing administrative claims data,
combined with advanced machine learning and deep learning techniques, to
predict the progression of Chronic Kidney Disease (CKD) to End-Stage Renal
Disease (ESRD). We analyze a comprehensive, 10-year dataset provided by a major
health insurance organization to develop prediction models for multiple
observation windows using traditional machine learning methods such as Random
Forest and XGBoost as well as deep learning approaches such as Long Short-Term
Memory (LSTM) networks. Our findings demonstrate that the LSTM model,
particularly with a 24-month observation window, exhibits superior performance
in predicting ESRD progression, outperforming existing models in the
literature. We further apply SHapley Additive exPlanations (SHAP) analysis to
enhance interpretability, providing insights into the impact of individual
features on predictions at the individual patient level. This study underscores
the value of leveraging administrative claims data for CKD management and
predicting ESRD progression.

æè¦ï¼æ¬ç ç©¶æ¢è¨å©ç¨è¡æ¿ç³å ±è³æï¼çµååé²æ©å¨å­¸ç¿èæ·±åº¦å­¸ç¿æè¡ï¼é æ¸¬æ¢æ§èèç (CKD) é²å±è³æ«æèèç¾ç (ESRD) çå¯è½æ§ãæååæä¸å®¶å¤§åå¥åº·ä¿éªçµç¹æä¾ç 10 å¹´ç¶åè³æéï¼ä½¿ç¨å³çµ±æ©å¨å­¸ç¿æ¹æ³ï¼ä¾å¦é¨æ©æ£®æå XGBoostï¼ä»¥åæ·±åº¦å­¸ç¿æ¹æ³ï¼ä¾å¦é·æç­æè¨æ¶ (LSTM) ç¶²è·¯ï¼éç¼å¤åè§å¯è¦çªçé æ¸¬æ¨¡åãæåçç ç©¶çµæé¡¯ç¤ºï¼LSTM æ¨¡åï¼å°¤å¶æ¯ 24 åæè§å¯è¦çªï¼å¨é æ¸¬ ESRD é²å±æ¹é¢è¡¨ç¾åªç°ï¼åªæ¼æç»ä¸­çç¾ææ¨¡åãæåé²ä¸æ­¥æç¨ SHapley å¯å æ§è§£é (SHAP) åæä»¥å¢å¼·å¯è§£éæ§ï¼æ·±å¥äºè§£åå¥ç¹å¾µå°åå¥æ£èå±¤ç´é æ¸¬çå½±é¿ãæ¬ç ç©¶å¼·èª¿äºå©ç¨è¡æ¿ç³å ±è³æé²è¡ CKD ç®¡çåé æ¸¬ ESRD é²å±çå¹å¼ã

##### **Contextual Evaluation of Large Language Models for Classifying Tropical and Infectious Diseases**
2409.09201v3 by Mercy Asiedu, Nenad Tomasev, Chintan Ghate, Tiya Tiyasirichokchai, Awa Dieng, Oluwatosin Akande, Geoffrey Siwo, Steve Adudans, Sylvanus Aitkins, Odianosen Ehiakhamen, Eric Ndombi, Katherine Heller

While large language models (LLMs) have shown promise for medical question
answering, there is limited work focused on tropical and infectious
disease-specific exploration. We build on an opensource tropical and infectious
diseases (TRINDs) dataset, expanding it to include demographic and semantic
clinical and consumer augmentations yielding 11000+ prompts. We evaluate LLM
performance on these, comparing generalist and medical LLMs, as well as LLM
outcomes to human experts. We demonstrate through systematic experimentation,
the benefit of contextual information such as demographics, location, gender,
risk factors for optimal LLM response. Finally we develop a prototype of
TRINDs-LM, a research tool that provides a playground to navigate how context
impacts LLM outputs for health.

æè¦ï¼åç®¡å¤§åèªè¨æ¨¡å (LLM) å¨é«çåé¡è§£ç­æ¹é¢å±ç¾åºåæ¯ï¼ä½å°æ³¨æ¼ç±å¸¶åå³æçç¹å®æ¢ç´¢çç ç©¶æéãæåå»ºç«å¨ä¸åéæ¾åå§ç¢¼ç±å¸¶åå³æç (TRINDs) è³æéä¸ï¼ä¸¦å°å¶æ´å±çºç´å¥äººå£çµ±è¨åèªç¾©è¨åºåæ¶è²»èæ´åï¼ç¢çè¶é 11000 åæç¤ºãæåè©ä¼°äº LLM å¨éäºæ¹é¢çæè½ï¼æ¯è¼äºéæåé«ç LLMï¼ä»¥å LLM çµæèäººé¡å°å®¶çæ¯è¼ãæåééç³»çµ±æ§å¯¦é©è­æäºèæ¯è³è¨ï¼ä¾å¦äººå£çµ±è¨ãä½ç½®ãæ§å¥ãæä½³ LLM åæçé¢¨éªå ç´ ï¼çå¥½èãæå¾ï¼æåéç¼äº TRINDs-LM çååï¼éæ¯ä¸åç ç©¶å·¥å·ï¼æä¾ä¸åæ¢ç´¢èæ¯å¦ä½å½±é¿ LLM å¥åº·è¼¸åºçå¹³å°ã

##### **Explainable AI: Definition and attributes of a good explanation for health AI**
2409.15338v1 by Evangelia Kyrimi, Scott McLachlan, Jared M Wohlgemut, Zane B Perkins, David A. Lagnado, William Marsh, the ExAIDSS Expert Group

Proposals of artificial intelligence (AI) solutions based on increasingly
complex and accurate predictive models are becoming ubiquitous across many
disciplines. As the complexity of these models grows, transparency and users'
understanding often diminish. This suggests that accurate prediction alone is
insufficient for making an AI-based solution truly useful. In the development
of healthcare systems, this introduces new issues related to accountability and
safety. Understanding how and why an AI system makes a recommendation may
require complex explanations of its inner workings and reasoning processes.
Although research on explainable AI (XAI) has significantly increased in recent
years and there is high demand for XAI in medicine, defining what constitutes a
good explanation remains ad hoc, and providing adequate explanations continues
to be challenging. To fully realize the potential of AI, it is critical to
address two fundamental questions about explanations for safety-critical AI
applications, such as health-AI: (1) What is an explanation in health-AI? and
(2) What are the attributes of a good explanation in health-AI? In this study,
we examined published literature and gathered expert opinions through a
two-round Delphi study. The research outputs include (1) a definition of what
constitutes an explanation in health-AI and (2) a comprehensive list of
attributes that characterize a good explanation in health-AI.

æè¦ï¼é¨èè¶ä¾è¶è¤éä¸æºç¢ºçé æ¸¬æ¨¡åï¼åºæ¼äººå·¥æºæ§ (AI) è§£æ±ºæ¹æ¡çææ¡å¨è¨±å¤é åä¸­è®å¾ç¡èä¸å¨ãé¨èéäºæ¨¡åè¤éæ§çå¢å ï¼éæåº¦åä½¿ç¨èççè§£åå¾å¾æéä½ãéè¡¨ç¤ºåææºç¢ºçé æ¸¬ä¸¦ä¸è¶³ä»¥è® AI è§£æ±ºæ¹æ¡çæ­£æç¨ãå¨é«çä¿å¥ç³»çµ±çéç¼ä¸­ï¼éå¼å¥äºèåè²¬å¶åå®å¨æ§ç¸éçæ°åé¡ãç­è§£ AI ç³»çµ±å¦ä½ä»¥åçºä½æåºå»ºè­°å¯è½éè¦å°å¶å§é¨éä½åæ¨çéç¨é²è¡è¤éçèªªæãåç®¡è¿å¹´ä¾å°å¯è§£é AI (XAI) çç ç©¶å·²å¤§å¹å¢å ï¼ä¸é«å­¸é åå° XAI æå¾é«çéæ±ï¼ä½å®ç¾©ä»éº¼æ§æä¸åå¥½çè§£éä»æ¯è¨ææ§çï¼èæä¾é©ç¶çè§£éä»ç¶å·æææ°æ§ãçºäºååç¼æ® AI çæ½åï¼å°æ¼å®å¨ééµå AI æç¨ï¼ä¾å¦å¥åº· AIï¼çè§£éï¼æ¢è¨å©ååºæ¬åé¡è³ééè¦ï¼(1) ä»éº¼æ¯å¥åº· AI ä¸­çè§£éï¼ä»¥å (2) å¥åº· AI ä¸­ä¸åå¥½çè§£éæåªäºå±¬æ§ï¼å¨æ¬ç ç©¶ä¸­ï¼æåæª¢è¦äºå·²ç¼è¡¨çæç»ï¼ä¸¦ééå©è¼ªå¾·ç¾è²ç ç©¶æ¶éäºå°å®¶æè¦ãç ç©¶ææåæ¬ï¼(1) å¥åº· AI ä¸­ä»éº¼æ§æè§£éçå®ç¾©ï¼ä»¥å (2) å¥åº· AI ä¸­ä¸åå¥½è§£éçå±¬æ§æ¸å®ã

##### **Exploring the Effect of Explanation Content and Format on User Comprehension and Trust**
2408.17401v1 by Antonio Rago, Bence Palfi, Purin Sukpanichnant, Hannibal Nabli, Kavyesh Vivek, Olga Kostopoulou, James Kinross, Francesca Toni

In recent years, various methods have been introduced for explaining the
outputs of "black-box" AI models. However, it is not well understood whether
users actually comprehend and trust these explanations. In this paper, we focus
on explanations for a regression tool for assessing cancer risk and examine the
effect of the explanations' content and format on the user-centric metrics of
comprehension and trust. Regarding content, we experiment with two explanation
methods: the popular SHAP, based on game-theoretic notions and thus potentially
complex for everyday users to comprehend, and occlusion-1, based on feature
occlusion which may be more comprehensible. Regarding format, we present SHAP
explanations as charts (SC), as is conventional, and occlusion-1 explanations
as charts (OC) as well as text (OT), to which their simpler nature also lends
itself. The experiments amount to user studies questioning participants, with
two different levels of expertise (the general population and those with some
medical training), on their subjective and objective comprehension of and trust
in explanations for the outputs of the regression tool. In both studies we
found a clear preference in terms of subjective comprehension and trust for
occlusion-1 over SHAP explanations in general, when comparing based on content.
However, direct comparisons of explanations when controlling for format only
revealed evidence for OT over SC explanations in most cases, suggesting that
the dominance of occlusion-1 over SHAP explanations may be driven by a
preference for text over charts as explanations. Finally, we found no evidence
of a difference between the explanation types in terms of objective
comprehension. Thus overall, the choice of the content and format of
explanations needs careful attention, since in some contexts format, rather
than content, may play the critical role in improving user experience.

æè¦ï¼<paragraph>è¿å¹´ä¾ï¼å·²ç¶å¼é²åç¨®æ¹æ³ä¾è§£éãé»ç®±ãAI æ¨¡åçè¼¸åºãç¶èï¼ç®åä¸¦ä¸æ¸æ¥ä½¿ç¨èæ¯å¦å¯¦éçè§£åä¿¡ä»»éäºè§£éãå¨æ¬æä¸­ï¼æåå°æ³¨æ¼è©ä¼°ççé¢¨éªçåæ­¸å·¥å·çè§£éï¼ä¸¦æ¢è¨è§£éçå§å®¹åæ ¼å¼å°ä»¥ä½¿ç¨èçºä¸­å¿ççè§£åä¿¡ä»»ææ¨çå½±é¿ãéæ¼å§å®¹ï¼æåå¯¦é©äºå©ç¨®è§£éæ¹æ³ï¼æµè¡ç SHAPï¼åºæ¼åå¼è«æ¦å¿µï¼å æ­¤å°æ¼æ¥å¸¸ä½¿ç¨èä¾èªªå¯è½å¾è¤éï¼ä»¥ååºæ¼ç¹å¾µé®è½ç occlusion-1ï¼å¯è½æ´ææ¼çè§£ãéæ¼æ ¼å¼ï¼æåå° SHAP è§£éåç¾çºåè¡¨ (SC)ï¼éæ¯æ£ä¾ï¼èå° occlusion-1 è§£éåç¾çºåè¡¨ (OC) ä»¥åæå­ (OT)ï¼å¶è¼çºç°¡å®çæ§è³ªä¹é©ç¨æ¼æ­¤ãéäºå¯¦é©ç­åæ¼ä½¿ç¨èç ç©¶ï¼è©¢ååèèï¼å·æå©ç¨®ä¸åç¨åº¦çå°æ¥­ç¥è­ï¼ä¸è¬æ°ç¾åå·åä¸äºé«å­¸è¨ç·´çäººï¼ï¼ä»åå°åæ­¸å·¥å·è¼¸åºè§£éçä¸»è§åå®¢è§çè§£åä¿¡ä»»ãå¨å©é ç ç©¶ä¸­ï¼æåç¼ç¾ï¼å¨åºæ¼å§å®¹é²è¡æ¯è¼æï¼ä¸è¬ä¾èªªï¼occlusion-1 åªæ¼ SHAP è§£éï¼å¨ä¸»è§çè§£åä¿¡ä»»æ¹é¢ææé¡¯çåå¥½ãç¶èï¼å¨åæ§å¶æ ¼å¼çææ³ä¸ç´æ¥æ¯è¼è§£éï¼å¨å¤§å¤æ¸ææ³ä¸åªé¡¯ç¤º OT åªæ¼ SC è§£éçè­æï¼éè¡¨æ occlusion-1 åªæ¼ SHAP è§£éçä¸»å°å°ä½å¯è½æ¯ç±åå¥½æå­èéåè¡¨ä½çºè§£éæé©åçãæå¾ï¼æåæ²æç¼ç¾è§£éé¡åå¨å®¢è§çè§£æ¹é¢çå·®ç°è­æãå æ­¤ï¼ç¸½é«èè¨ï¼å°è§£éçå§å®¹åæ ¼å¼çé¸æéè¦ä»ç´°æ³¨æï¼å çºå¨æäºææ³ä¸ï¼æ ¼å¼èéå§å®¹ï¼å¯è½å¨æ¹åä½¿ç¨èé«é©æ¹é¢ç¼æ®ééµä½ç¨ã</paragraph>

##### **A Survey for Large Language Models in Biomedicine**
2409.00133v1 by Chong Wang, Mengyao Li, Junjun He, Zhongruo Wang, Erfan Darzi, Zan Chen, Jin Ye, Tianbin Li, Yanzhou Su, Jing Ke, Kaili Qu, Shuxin Li, Yi Yu, Pietro LiÃ², Tianyun Wang, Yu Guang Wang, Yiqing Shen

Recent breakthroughs in large language models (LLMs) offer unprecedented
natural language understanding and generation capabilities. However, existing
surveys on LLMs in biomedicine often focus on specific applications or model
architectures, lacking a comprehensive analysis that integrates the latest
advancements across various biomedical domains. This review, based on an
analysis of 484 publications sourced from databases including PubMed, Web of
Science, and arXiv, provides an in-depth examination of the current landscape,
applications, challenges, and prospects of LLMs in biomedicine, distinguishing
itself by focusing on the practical implications of these models in real-world
biomedical contexts. Firstly, we explore the capabilities of LLMs in zero-shot
learning across a broad spectrum of biomedical tasks, including diagnostic
assistance, drug discovery, and personalized medicine, among others, with
insights drawn from 137 key studies. Then, we discuss adaptation strategies of
LLMs, including fine-tuning methods for both uni-modal and multi-modal LLMs to
enhance their performance in specialized biomedical contexts where zero-shot
fails to achieve, such as medical question answering and efficient processing
of biomedical literature. Finally, we discuss the challenges that LLMs face in
the biomedicine domain including data privacy concerns, limited model
interpretability, issues with dataset quality, and ethics due to the sensitive
nature of biomedical data, the need for highly reliable model outputs, and the
ethical implications of deploying AI in healthcare. To address these
challenges, we also identify future research directions of LLM in biomedicine
including federated learning methods to preserve data privacy and integrating
explainable AI methodologies to enhance the transparency of LLMs.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) çææ°çªç ´æä¾äºåææªæçèªç¶èªè¨çè§£åçæè½åãç¶èï¼ç¾æéæ¼çç©é«å­¸ä¸­ LLM çèª¿æ¥éå¸¸å°æ³¨æ¼ç¹å®æç¨ææ¨¡åæ¶æ§ï¼ç¼ºä¹æ´ååç¨®çç©é«å­¸é åææ°é²å±çå¨é¢åæãæ¬ç¶è¿°åºæ¼å°ä¾èª PubMedãWeb of Science å arXiv ç­æ¸æåº«ç 484 ç¯åºçç©çåæï¼æ·±å¥æ¢è¨äºçç©é«å­¸ä¸­ LLM çç¶åç¾æ³ãæç¨ãææ°ååæ¯ï¼å¶ç¹é»æ¯éæ³¨éäºæ¨¡åå¨ç¾å¯¦ä¸ççç©é«å­¸èæ¯ä¸­çå¯¦éæç¨ãé¦åï¼æåæ¢è¨äº LLM å¨å»£æ³ççç©é«å­¸ä»»åä¸­çé¶æ¬¡å­¸ç¿è½åï¼åæ¬è¨ºæ·è¼å©ãè¥ç©ç¼ç¾ååæ§åé«çç­ï¼ä¸¦å¾ 137 é ééµç ç©¶ä¸­æ±²åè¦è§£ãç¶å¾ï¼æåè¨è«äº LLM çé©æç­ç¥ï¼åæ¬å®æ¨¡æåå¤æ¨¡æ LLM çå¾®èª¿æ¹æ³ï¼ä»¥å¢å¼·å®åå¨é¶æ¬¡å­¸ç¿ç¡æ³å¯¦ç¾çå°æ¥­çç©é«å­¸èæ¯ä¸­çæ§è½ï¼ä¾å¦é«çåé¡è§£ç­åçç©é«å­¸æç»çææèçãæå¾ï¼æåè¨è«äº LLM å¨çç©é«å­¸é åé¢è¨çææ°ï¼åæ¬æ¸æé±ç§åé¡ãæ¨¡åå¯è§£éæ§æéãæ¸æéè³ªéåé¡ä»¥åç±æ¼çç©é«å­¸æ¸æçæææ§ãå°é«åº¦å¯é æ¨¡åè¼¸åºçéæ±ä»¥åå¨é«çä¿å¥ä¸­é¨ç½² AI çå«çå½±é¿èç¢ççå«çåé¡ãçºäºæå°éäºææ°ï¼æåéç¢ºå®äºçç©é«å­¸ä¸­ LLM æªä¾çç ç©¶æ¹åï¼åæ¬ç¨æ¼ä¿è­·æ¸æé±ç§çè¯åå­¸ç¿æ¹æ³ä»¥åæ´åå¯è§£é AI æ¹æ³ä»¥å¢å¼· LLM çéæåº¦ã

##### **Aligning XAI with EU Regulations for Smart Biomedical Devices: A Methodology for Compliance Analysis**
2408.15121v1 by Francesco Sovrano, Michael Lognoul, Giulia Vilone

Significant investment and development have gone into integrating Artificial
Intelligence (AI) in medical and healthcare applications, leading to advanced
control systems in medical technology. However, the opacity of AI systems
raises concerns about essential characteristics needed in such sensitive
applications, like transparency and trustworthiness. Our study addresses these
concerns by investigating a process for selecting the most adequate Explainable
AI (XAI) methods to comply with the explanation requirements of key EU
regulations in the context of smart bioelectronics for medical devices. The
adopted methodology starts with categorising smart devices by their control
mechanisms (open-loop, closed-loop, and semi-closed-loop systems) and delving
into their technology. Then, we analyse these regulations to define their
explainability requirements for the various devices and related goals.
Simultaneously, we classify XAI methods by their explanatory objectives. This
allows for matching legal explainability requirements with XAI explanatory
goals and determining the suitable XAI algorithms for achieving them. Our
findings provide a nuanced understanding of which XAI algorithms align better
with EU regulations for different types of medical devices. We demonstrate this
through practical case studies on different neural implants, from chronic
disease management to advanced prosthetics. This study fills a crucial gap in
aligning XAI applications in bioelectronics with stringent provisions of EU
regulations. It provides a practical framework for developers and researchers,
ensuring their AI innovations advance healthcare technology and adhere to legal
and ethical standards.

æè¦ï¼äººå·¥æºæ§ï¼AIï¼å¨é«çåä¿å¥æç¨ä¸­æå¥äºå¤§éçæè³åéç¼ï¼é²èå°è´é«çæè¡ä¸­çåé²æ§å¶ç³»çµ±ãç¶èï¼AI ç³»çµ±çä¸éææ§å¼ç¼äºå°æ­¤é¡æææç¨ä¸­æéåºæ¬ç¹æ§çææï¼ä¾å¦éæåº¦åå¯ä¿¡åº¦ãæåçç ç©¶ééèª¿æ¥ä¸åç¨åºä¾è§£æ±ºéäºåé¡ï¼ç¨æ¼é¸ææååçå¯è§£é AIï¼XAIï¼æ¹æ³ï¼ä»¥ç¬¦åæ­çæ³è¦å¨é«çå¨æçæºæ§åçç©é»å­å­¸ä¸­çèªªæè¦æ±ãæ¡ç¨çæ¹æ³å¾ééå¶æ§å¶æ©å¶ï¼éè¿´è·¯ãéè¿´è·¯ååéè¿´è·¯ç³»çµ±ï¼å°æºæ§åè£ç½®é²è¡åé¡ï¼ä¸¦æ·±å¥æ¢è¨å¶æè¡éå§ãç¶å¾ï¼æååæéäºæ³è¦ä»¥å®ç¾©å¶å°åç¨®è£ç½®åç¸éç®æ¨çå¯è§£éæ§è¦æ±ãåæï¼æåééå¶èªªæç®æ¨å° XAI æ¹æ³é²è¡åé¡ãéåè¨±å°æ³å¾å¯è§£éæ§è¦æ±è XAI èªªæç®æ¨ç¸å¹éï¼ä¸¦ç¢ºå®é©ç¶ç XAI æ¼ç®æ³ä¾éæå®åãæåçç ç©¶çµææä¾äºå°åªäº XAI æ¼ç®æ³æ´ç¬¦åæ­çæ³è¦ä»¥é©ç¨æ¼ä¸åé¡åçé«çå¨æçç´°ç·»çè§£ãæåééä¸åç¥ç¶æ¤å¥ç©çå¯¦éæ¡ä¾ç ç©¶ä¾è­æéä¸é»ï¼å¾æ¢æ§ç¾çç®¡çå°åé²çç¾©è¢ãéé ç ç©¶å¡«è£äºå°çç©é»å­å­¸ä¸­ç XAI æç¨èæ­çæ³è¦çå´æ ¼è¦å®ç¸ç¬¦çéè¦ç©ºç½ãå®çºéç¼äººå¡åç ç©¶äººå¡æä¾äºä¸åå¯¦ç¨çæ¶æ§ï¼ç¢ºä¿å¶ AI åµæ°è½ä¿é²é«çæè¡ä¸¦éµå®æ³å¾åéå¾·æ¨æºã

##### **Towards Case-based Interpretability for Medical Federated Learning**
2408.13626v1 by Laura Latorre, Liliana Petrychenko, Regina Beets-Tan, Taisiya Kopytova, Wilson Silva

We explore deep generative models to generate case-based explanations in a
medical federated learning setting. Explaining AI model decisions through
case-based interpretability is paramount to increasing trust and allowing
widespread adoption of AI in clinical practice. However, medical AI training
paradigms are shifting towards federated learning settings in order to comply
with data protection regulations. In a federated scenario, past data is
inaccessible to the current user. Thus, we use a deep generative model to
generate synthetic examples that protect privacy and explain decisions. Our
proof-of-concept focuses on pleural effusion diagnosis and uses publicly
available Chest X-ray data.

æè¦ï¼æåæ¢ç´¢æ·±åº¦çææ¨¡åï¼å¨é«çè¯é¦å­¸ç¿è¨­ç½®ä¸­çæåºæ¼æ¡ä¾çèªªæãééåºæ¼æ¡ä¾çå¯è§£éæ§ä¾è§£é AI æ¨¡åæ±ºç­ï¼å°æ¼å¢å ä¿¡ä»»ä¸¦åè¨± AI å¨è¨åºå¯¦åä¸­å»£æ³æ¡ç¨è³ééè¦ãç¶èï¼é«ç AI è¨ç·´ç¯ä¾æ­£è½åè¯é¦å­¸ç¿è¨­ç½®ï¼ä»¥ç¬¦åè³æä¿è­·æ³è¦ãå¨è¯é¦æå¢ä¸­ï¼éå»çè³æå°ç®åçä½¿ç¨èèè¨æ¯ç¡æ³åå¾çãå æ­¤ï¼æåä½¿ç¨æ·±åº¦çææ¨¡åä¾ç¢çä¿è­·é±ç§åè§£éæ±ºç­çåæç¯ä¾ãæåçæ¦å¿µé©è­èéæ¼è¸èç©æ¶²è¨ºæ·ï¼ä¸¦ä½¿ç¨å¬éå¯åå¾çè¸é¨ X åè³æã

##### **AI in radiological imaging of soft-tissue and bone tumours: a systematic review evaluating against CLAIM and FUTURE-AI guidelines**
2408.12491v1 by Douwe J. Spaanderman, Matthew Marzetti, Xinyi Wan, Andrew F. Scarsbrook, Philip Robinson, Edwin H. G. Oei, Jacob J. Visser, Robert Hemke, Kirsten van Langevelde, David F. Hanff, Geert J. L. H. van Leenders, Cornelis Verhoef, Dirk J. GruÃ¼hagen, Wiro J. Niessen, Stefan Klein, Martijn P. A. Starmans

Soft-tissue and bone tumours (STBT) are rare, diagnostically challenging
lesions with variable clinical behaviours and treatment approaches. This
systematic review provides an overview of Artificial Intelligence (AI) methods
using radiological imaging for diagnosis and prognosis of these tumours,
highlighting challenges in clinical translation, and evaluating study alignment
with the Checklist for AI in Medical Imaging (CLAIM) and the FUTURE-AI
international consensus guidelines for trustworthy and deployable AI to promote
the clinical translation of AI methods. The review covered literature from
several bibliographic databases, including papers published before 17/07/2024.
Original research in peer-reviewed journals focused on radiology-based AI for
diagnosing or prognosing primary STBT was included. Exclusion criteria were
animal, cadaveric, or laboratory studies, and non-English papers. Abstracts
were screened by two of three independent reviewers for eligibility. Eligible
papers were assessed against guidelines by one of three independent reviewers.
The search identified 15,015 abstracts, from which 325 articles were included
for evaluation. Most studies performed moderately on CLAIM, averaging a score
of 28.9$\pm$7.5 out of 53, but poorly on FUTURE-AI, averaging 5.1$\pm$2.1 out
of 30. Imaging-AI tools for STBT remain at the proof-of-concept stage,
indicating significant room for improvement. Future efforts by AI developers
should focus on design (e.g. define unmet clinical need, intended clinical
setting and how AI would be integrated in clinical workflow), development (e.g.
build on previous work, explainability), evaluation (e.g. evaluating and
addressing biases, evaluating AI against best practices), and data
reproducibility and availability (making documented code and data publicly
available). Following these recommendations could improve clinical translation
of AI methods.

æè¦ï¼è»çµç¹åéª¨éª¼è«ç¤ï¼STBTï¼æ¯ç½è¦ãè¨ºæ·å·æææ°æ§ççç¶ï¼å¶è¨åºè¡çºåæ²»çæ¹æ³åä¸ç¸åãéç¯ç³»çµ±æ§åé¡§æä¾äºä½¿ç¨æ¾å°å½±åé²è¡è¨ºæ·åé å¾çäººå·¥æºæ§ (AI) æ¹æ³çæ¦è§ï¼éé»èªªæäºè¨åºè½è­¯çææ°ï¼ä¸¦è©ä¼°ç ç©¶èé«çå½±å AI æ ¸æ¥è¡¨ (CLAIM) å FUTURE-AI å¯ä¿¡è³´ä¸å¯é¨ç½² AI çåéå±è­æºåçä¸è´æ§ï¼ä»¥ä¿é² AI æ¹æ³çè¨åºè½è­¯ãéç¯åé¡§æ¶µèäºå¹¾åæ¸ç®è³æåº«ä¸­çæç»ï¼åæ¬å¨ 2024 å¹´ 7 æ 17 æ¥ä¹åç¼è¡¨çè«æãç´å¥äºä»¥æ¾å°çºåºç¤ç AI è¨ºæ·æé å¾åç¼æ§ STBT çåè¡è©å¯©æåä¸­çåå§ç ç©¶ãæé¤æ¨æºæ¯åç©ãå±é«æå¯¦é©å®¤ç ç©¶ï¼ä»¥åéè±æè«æãæè¦ç±ä¸ä½ç¨ç«å¯©æ¥å¡ä¸­çå©ä½ç¯©é¸è³æ ¼ãåæ ¼çè«æç±ä¸ä½ç¨ç«å¯©æ¥å¡ä¸­çä¸ä½æ ¹ææºåé²è¡è©ä¼°ãæç´¢è­å¥åº 15,015 ç¯æè¦ï¼å¶ä¸­ 325 ç¯æç« è¢«ç´å¥è©ä¼°ãå¤§å¤æ¸ç ç©¶å¨ CLAIM ä¸­è¡¨ç¾ä¸­ç­ï¼å¹³åå¾åçº 53 åä¸­ç 28.9Â±7.5 åï¼ä½å¨ FUTURE-AI ä¸­è¡¨ç¾ä¸ä½³ï¼å¹³åå¾åçº 30 åä¸­ç 5.1Â±2.1 åãSTBT çå½±å AI å·¥å·ä»èæ¼æ¦å¿µé©è­éæ®µï¼è¡¨ææé¡¯èçæ¹é²ç©ºéãAI éç¼äººå¡æªä¾çåªåæéä¸­å¨è¨­è¨ï¼ä¾å¦å®ç¾©æªæ»¿è¶³çè¨åºéæ±ãé æçè¨åºç°å¢ä»¥å AI å¦ä½æ´åå°è¨åºå·¥ä½æµç¨ä¸­ï¼ãéç¼ï¼ä¾å¦å»ºç«å¨ååçå·¥ä½ãå¯è§£éæ§ï¼ãè©ä¼°ï¼ä¾å¦è©ä¼°åè§£æ±ºåå·®ãè©ä¼° AI èæä½³å¯¦åï¼ãä»¥åæ¸æå¯è¤è£½æ§åå¯ç¨æ§ï¼å¬éæä¾æä»¶åçä»£ç¢¼åæ¸æï¼ãéµå¾ªéäºå»ºè­°å¯ä»¥æ¹å AI æ¹æ³çè¨åºè½è­¯ã

##### **Evaluating Explainable AI Methods in Deep Learning Models for Early Detection of Cerebral Palsy**
2409.00001v1 by Kimji N. Pellano, Inga StrÃ¼mke, Daniel Groos, Lars Adde, Espen Alexander F. Ihlen

Early detection of Cerebral Palsy (CP) is crucial for effective intervention
and monitoring. This paper tests the reliability and applicability of
Explainable AI (XAI) methods using a deep learning method that predicts CP by
analyzing skeletal data extracted from video recordings of infant movements.
Specifically, we use XAI evaluation metrics -- namely faithfulness and
stability -- to quantitatively assess the reliability of Class Activation
Mapping (CAM) and Gradient-weighted Class Activation Mapping (Grad-CAM) in this
specific medical application. We utilize a unique dataset of infant movements
and apply skeleton data perturbations without distorting the original dynamics
of the infant movements. Our CP prediction model utilizes an ensemble approach,
so we evaluate the XAI metrics performances for both the overall ensemble and
the individual models. Our findings indicate that both XAI methods effectively
identify key body points influencing CP predictions and that the explanations
are robust against minor data perturbations. Grad-CAM significantly outperforms
CAM in the RISv metric, which measures stability in terms of velocity. In
contrast, CAM performs better in the RISb metric, which relates to bone
stability, and the RRS metric, which assesses internal representation
robustness. Individual models within the ensemble show varied results, and
neither CAM nor Grad-CAM consistently outperform the other, with the ensemble
approach providing a representation of outcomes from its constituent models.

æè¦ï¼è¦æ§éº»çº (CP) çæ©æåµæ¸¬å°æ¼ææçä»å¥åç£æ¸¬è³ééè¦ãæ¬ææ¸¬è©¦äºå¯è§£é AI (XAI) æ¹æ³çå¯é æ§åé©ç¨æ§ï¼ä½¿ç¨æ·±åº¦å­¸ç¿æ¹æ³ï¼ééåæå¾å¬°ååä½å½±çè¨éä¸­æåçéª¨éª¼è³æä¾é æ¸¬ CPãå·é«ä¾èªªï¼æåä½¿ç¨ XAI è©ä¼°ææ¨ï¼å³å¿ å¯¦åº¦åç©©å®æ§ï¼ä¾éåè©ä¼°é¡å¥æ¿æ´»æ å° (CAM) åæ¢¯åº¦å æ¬é¡å¥æ¿æ´»æ å° (Grad-CAM) å¨éåç¹å®é«çæç¨ä¸­çå¯é æ§ãæåå©ç¨ä¸åç¨ç¹çå¬°ååä½è³æéï¼ä¸¦æç¨éª¨éª¼è³ææ¾åï¼èä¸ææ­æ²å¬°ååä½çåå§ååãæåç CP é æ¸¬æ¨¡åå©ç¨æ´é«æ¹æ³ï¼å æ­¤æåè©ä¼°äºæ´é«æ´é«ååå¥æ¨¡åç XAI ææ¨è¡¨ç¾ãæåçç ç©¶çµæè¡¨æï¼å©ç¨® XAI æ¹æ³é½è½ææè­å¥å½±é¿ CP é æ¸¬çééµèº«é«é¨ä½ï¼ä¸¦ä¸éäºè§£éå°æ¼å¾®å°çè³ææ¾åå·æé­¯æ£æ§ãGrad-CAM å¨ RISv ææ¨ä¸­é¡¯èåªæ¼ CAMï¼è©²ææ¨è¡¡ééåº¦æ¹é¢çç©©å®æ§ãç¸æ¯ä¹ä¸ï¼CAM å¨ RISb ææ¨ä¸­è¡¨ç¾å¾æ´å¥½ï¼è©²ææ¨èéª¨éª¼ç©©å®æ§æéï¼è RRS ææ¨åè©ä¼°å§é¨è¡¨ç¤ºçé­¯æ£æ§ãæ´é«ä¸­çåå¥æ¨¡åé¡¯ç¤ºåºä¸åççµæï¼CAM å Grad-CAM é½ä¸ä¸è´å°åªæ¼å¦ä¸ç¨®ï¼æ´é«æ¹æ³æä¾äºå¶çµææ¨¡åçµæçè¡¨ç¤ºã

##### **MicroXercise: A Micro-Level Comparative and Explainable System for Remote Physical Therapy**
2408.11837v1 by Hanchen David Wang, Nibraas Khan, Anna Chen, Nilanjan Sarkar, Pamela Wisniewski, Meiyi Ma

Recent global estimates suggest that as many as 2.41 billion individuals have
health conditions that would benefit from rehabilitation services. Home-based
Physical Therapy (PT) faces significant challenges in providing interactive
feedback and meaningful observation for therapists and patients. To fill this
gap, we present MicroXercise, which integrates micro-motion analysis with
wearable sensors, providing therapists and patients with a comprehensive
feedback interface, including video, text, and scores. Crucially, it employs
multi-dimensional Dynamic Time Warping (DTW) and attribution-based explainable
methods to analyze the existing deep learning neural networks in monitoring
exercises, focusing on a high granularity of exercise. This synergistic
approach is pivotal, providing output matching the input size to precisely
highlight critical subtleties and movements in PT, thus transforming complex AI
analysis into clear, actionable feedback. By highlighting these micro-motions
in different metrics, such as stability and range of motion, MicroXercise
significantly enhances the understanding and relevance of feedback for
end-users. Comparative performance metrics underscore its effectiveness over
traditional methods, such as a 39% and 42% improvement in Feature Mutual
Information (FMI) and Continuity. MicroXercise is a step ahead in home-based
physical therapy, providing a technologically advanced and intuitively helpful
solution to enhance patient care and outcomes.

æè¦ï¼æè¿çå¨çä¼°è¨è¡¨æï¼å¤é 24.1 åäººæ
å¥åº·çæ³å¯å¾å¾©å¥æåä¸­åçãå±å®¶
ç©çæ²»ç (PT) å¨æä¾äºåå¼
åé¥åææç¾©çè§å¯æ¹é¢é¢è¨éå¤§ææ°ï¼ä¾æ²»çå¸«åæ£èä½¿ç¨ãçºäºå¡«è£é
åç¼ºå£ï¼æåæåº MicroXerciseï¼å®å°å¾®åä½åæè
å¯ç©¿æ´å¼ææ¸¬å¨æ´åå¨ä¸èµ·ï¼çºæ²»çå¸«åæ£èæä¾ä¸åå¨é¢ç
åé¥ä»é¢ï¼åæ¬å½±çãæå­ååæ¸ãè³ééè¦çæ¯ï¼å®æ¡ç¨
å¤ç¶­åææéè¦æ´ (DTW) ååºæ¼æ­¸å çå¯è§£é
æ¹æ³ä¾åæç£æ§éåä¸­ç¾æçæ·±åº¦å­¸ç¿ç¥ç¶ç¶²è·¯ï¼å°æ³¨æ¼éåçé«ç²åº¦ãéç¨®åå
æ¹æ³è³ééè¦ï¼æä¾èè¼¸å¥å¤§å°å¹éçè¼¸åºï¼ä»¥ç²¾ç¢ºå°
çªåº PT ä¸­ééµçç´°å¾®å·®å¥ååä½ï¼å¾èå°è¤éç AI
åæè½æçºæ¸æ°ãå¯æä½çåé¥ãééå¨ä¸åææ¨ä¸­çªé¡¯éäºå¾®åä½ï¼ä¾å¦ç©©å®æ§ååä½ç¯åï¼MicroXercise
é¡¯èæåæçµä½¿ç¨èå°åé¥ççè§£åç¸éæ§ãæ¯è¼æè½ææ¨å¼·èª¿å¶åªæ¼
å³çµ±æ¹æ³çæææ§ï¼ä¾å¦ç¹å¾µäºæ è³è¨ (FMI) åé£çºæ§åå¥æåäº 39% å 42%ãMicroXercise å¨å±å®¶
ç©çæ²»çæ¹é¢æ´é²ä¸æ­¥ï¼æä¾æè¡åé²ä¸ç´è¦ºæç¨ç
è§£æ±ºæ¹æ¡ï¼ä»¥æåæ£èç§è­·åçµæã

##### **The Literature Review Network: An Explainable Artificial Intelligence for Systematic Literature Reviews, Meta-analyses, and Method Development**
2408.05239v1 by Joshua Morriss, Tod Brindle, Jessica Bah RÃ¶sman, Daniel Reibsamen, Andreas Enz

Systematic literature reviews are the highest quality of evidence in
research. However, the review process is hindered by significant resource and
data constraints. The Literature Review Network (LRN) is the first of its kind
explainable AI platform adhering to PRISMA 2020 standards, designed to automate
the entire literature review process. LRN was evaluated in the domain of
surgical glove practices using 3 search strings developed by experts to query
PubMed. A non-expert trained all LRN models. Performance was benchmarked
against an expert manual review. Explainability and performance metrics
assessed LRN's ability to replicate the experts' review. Concordance was
measured with the Jaccard index and confusion matrices. Researchers were
blinded to the other's results until study completion. Overlapping studies were
integrated into an LRN-generated systematic review. LRN models demonstrated
superior classification accuracy without expert training, achieving 84.78% and
85.71% accuracy. The highest performance model achieved high interrater
reliability (k = 0.4953) and explainability metrics, linking 'reduce',
'accident', and 'sharp' with 'double-gloving'. Another LRN model covered 91.51%
of the relevant literature despite diverging from the non-expert's judgments (k
= 0.2174), with the terms 'latex', 'double' (gloves), and 'indication'. LRN
outperformed the manual review (19,920 minutes over 11 months), reducing the
entire process to 288.6 minutes over 5 days. This study demonstrates that
explainable AI does not require expert training to successfully conduct
PRISMA-compliant systematic literature reviews like an expert. LRN summarized
the results of surgical glove studies and identified themes that were nearly
identical to the clinical researchers' findings. Explainable AI can accurately
expedite our understanding of clinical practices, potentially revolutionizing
healthcare research.

æè¦ï¼ç³»çµ±æ§æç»åé¡§æ¯ç ç©¶ä¸­è­æåè³ªæé«çãç¶èï¼åé¡§éç¨åå°é¡¯èè³æºåè³æéå¶çé»ç¤ãæç»åé¡§ç¶²è·¯ (LRN) æ¯ç¬¬ä¸åéµå¾ª PRISMA 2020 æ¨æºçå¯è§£é AI å¹³å°ï¼æ¨å¨èªååæ´åæç»åé¡§éç¨ãLRN å¨å¤ç§æå¥å¯¦åé åä¸­é²è¡è©ä¼°ï¼ä½¿ç¨å°å®¶éç¼ç 3 åæå°å­ä¸²ä¾æ¥è©¢ PubMedãéå°å®¶è¨ç·´ææ LRN æ¨¡åãæè½ä»¥å°å®¶æååé¡§ä½çºåºæºãå¯è§£éæ§åæè½ææ¨è©ä¼° LRN è¤è£½å°å®¶åé¡§çè½åãä¸è´æ§ä»¥ Jaccard ææ¸åæ··æ·ç©é£æ¸¬éãç ç©¶äººå¡å¨ç ç©¶å®æåå°å½¼æ­¤ççµæä¿å¯ãéççç ç©¶æ´åå° LRN çæçç³»çµ±æ§åé¡§ä¸­ãLRN æ¨¡åå¨æ²æå°å®¶è¨ç·´çææ³ä¸å±ç¾åºåªç°çåé¡æºç¢ºçï¼éå° 84.78% å 85.71% çæºç¢ºçãæè½æé«çæ¨¡åéå°äºé«è©åèéä¿¡è³´åº¦ (k = 0.4953) åå¯è§£éæ§ææ¨ï¼å°ãæ¸å°ãããæå¤ãåãé³å©ãèãééæ´æå¥ãé£çµå¨ä¸èµ·ãå¦ä¸å LRN æ¨¡åæ¶µèäº 91.51% çç¸éæç»ï¼åç®¡èéå°å®¶çå¤æ·ä¸å (k = 0.2174)ï¼ä½åå«äºãä¹³è ãããééãï¼æå¥ï¼åãé©æçãç­è©å½ãLRN åªæ¼æååé¡§ï¼11 åæè¶é 19,920 åéï¼ï¼å°æ´åéç¨ç¸®ç­çº 5 å¤©è¶é 288.6 åéãéé ç ç©¶é¡¯ç¤ºï¼å¯è§£éç AI ä¸éè¦å°å®¶è¨ç·´å³å¯æåé²è¡å°å®¶ç­ç´ç PRISMA ç¸å®¹ç³»çµ±æ§æç»åé¡§ãLRN ç¸½çµäºå¤ç§æå¥ç ç©¶ççµæï¼ä¸¦æ¾åºèè¨åºç ç©¶äººå¡ç¼ç¾å¹¾ä¹ç¸åçä¸»é¢ãå¯è§£éç AI å¯ä»¥æºç¢ºå°å å¿«æåå°è¨åºå¯¦åççè§£ï¼ææ½åé©æ°é«çä¿å¥ç ç©¶ã

##### **Enhancing Medical Learning and Reasoning Systems: A Boxology-Based Comparative Analysis of Design Patterns**
2408.02709v1 by Chi Him Ng

This study analyzes hybrid AI systems' design patterns and their
effectiveness in clinical decision-making using the boxology framework. It
categorizes and copares various architectures combining machine learning and
rule-based reasoning to provide insights into their structural foundations and
healthcare applications. Addressing two main questions, how to categorize these
systems againts established design patterns and how to extract insights through
comparative analysis, the study uses design patterns from software engineering
to understand and optimize healthcare AI systems. Boxology helps identify
commonalities and create reusable solutions, enhancing these systems'
scalability, reliability, and performance. Five primary architectures are
examined: REML, MLRB, RBML, RMLT, and PERML. Each has unique strengths and
weaknesses, highlighting the need for tailored approaches in clinical tasks.
REML excels in high-accuracy prediction for datasets with limited data; MLRB in
handling large datasets and complex data integration; RBML in explainability
and trustworthiness; RMLT in managing high-dimensional data; and PERML, though
limited in analysis, shows promise in urgent care scenarios. The study
introduces four new patterns, creates five abstract categorization patterns,
and refines those five further to specific systems. These contributions enhance
Boxlogy's taxonomical organization and offer novel approaches to integrating
expert knowledge with machine learning. Boxology's structured, modular apporach
offers significant advantages in developing and analyzing hybrid AI systems,
revealing commonalities, and promoting reusable solutions. In conclusion, this
study underscores hybrid AI systems' crucial role in advancing healthcare and
Boxology's potential to drive further innovation in AI integration, ultimately
improving clinical decision support and patient outcomes.

æè¦ï¼æ¬ç ç©¶ä½¿ç¨çå­å­¸æ¡æ¶åææ··åäººå·¥æºæ§ç³»çµ±çè¨­è¨æ¨¡å¼åå¶å¨è¨åºæ±ºç­ä¸­çæææ§ãå®åé¡ä¸¦æ¯è¼çµåæ©å¨å­¸ç¿ååºæ¼è¦åçæ¨ççåç¨®æ¶æ§ï¼ä»¥æ·±å¥äºè§£å¶çµæ§åºç¤åé«çä¿å¥æç¨ãéå°å©åä¸»è¦åé¡ï¼å¦ä½æ ¹ææ¢å®çè¨­è¨æ¨¡å¼å°éäºç³»çµ±é²è¡åé¡ï¼ä»¥åå¦ä½ééæ¯è¼åææåè¦è§£ï¼æ¬ç ç©¶ä½¿ç¨è»é«å·¥ç¨ä¸­çè¨­è¨æ¨¡å¼ä¾äºè§£ååªåé«çä¿å¥äººå·¥æºæ§ç³»çµ±ãçå­å­¸æå©æ¼è­å¥å±æ§ä¸¦å»ºç«å¯éè¤ä½¿ç¨çè§£æ±ºæ¹æ¡ï¼å¾èå¢å¼·éäºç³»çµ±çå¯æ´åæ§ãå¯é æ§åæè½ãæª¢æ¥äºäºç¨®ä¸»è¦çæ¶æ§ï¼REMLãMLRBãRBMLãRMLT å PERMLãæ¯ç¨®æ¶æ§é½æç¨ç¹çåªç¼ºé»ï¼å¼·èª¿äºå¨è¨åºä»»åä¸­éè¦éèº«æé çæ¹æ³ãREML å¨è³ææéçè³æéä¸­è¡¨ç¾åºé«ç²¾åº¦çé æ¸¬ï¼MLRB å¨èçå¤§åè³æéåè¤éè³ææ´åæ¹é¢è¡¨ç¾åºè²ï¼RBML å¨å¯è§£éæ§åå¯ä¿¡åº¦æ¹é¢è¡¨ç¾åºè²ï¼RMLT å¨ç®¡çé«ç¶­è³ææ¹é¢è¡¨ç¾åºè²ï¼è PERML åç®¡å¨åææ¹é¢æéï¼ä½å¨ç·æ¥ç§è­·å ´æ¯ä¸­è¡¨ç¾åºæ½åãæ¬ç ç©¶å¼å¥äºåç¨®æ°æ¨¡å¼ï¼å»ºç«äºäºç¨®æ½è±¡åé¡æ¨¡å¼ï¼ä¸¦é²ä¸æ­¥å°éäºç¨®æ¨¡å¼ç´°åçºå·é«çç³»çµ±ãéäºè²¢ç»å¢å¼·äºçå­å­¸çåé¡çµç¹ï¼ä¸¦æä¾äºå°å°å®¶ç¥è­èæ©å¨å­¸ç¿æ´åçæ°æ¹æ³ãçå­å­¸ççµæ§åãæ¨¡çµåæ¹æ³å¨éç¼ååææ··åäººå·¥æºæ§ç³»çµ±ãæ­ç¤ºå±æ§ä»¥åæ¨å»£å¯éè¤ä½¿ç¨çè§£æ±ºæ¹æ¡æ¹é¢å·æé¡¯èåªå¢ãç¸½ä¹ï¼æ¬ç ç©¶å¼·èª¿äºæ··åäººå·¥æºæ§ç³»çµ±å¨æ¨é²é«çä¿å¥ä¸­çééµä½ç¨ï¼ä»¥åçå­å­¸å¨æ¨åäººå·¥æºæ§æ´åé²ä¸æ­¥åµæ°æ¹é¢çæ½åï¼æçµæ¹åè¨åºæ±ºç­æ¯æ´åæ£èçæ²»çææã

##### **Bayesian Kolmogorov Arnold Networks (Bayesian_KANs): A Probabilistic Approach to Enhance Accuracy and Interpretability**
2408.02706v1 by Masoud Muhammed Hassan

Because of its strong predictive skills, deep learning has emerged as an
essential tool in many industries, including healthcare. Traditional deep
learning models, on the other hand, frequently lack interpretability and omit
to take prediction uncertainty into account two crucial components of clinical
decision making. In order to produce explainable and uncertainty aware
predictions, this study presents a novel framework called Bayesian Kolmogorov
Arnold Networks (BKANs), which combines the expressive capacity of Kolmogorov
Arnold Networks with Bayesian inference. We employ BKANs on two medical
datasets, which are widely used benchmarks for assessing machine learning
models in medical diagnostics: the Pima Indians Diabetes dataset and the
Cleveland Heart Disease dataset. Our method provides useful insights into
prediction confidence and decision boundaries and outperforms traditional deep
learning models in terms of prediction accuracy. Moreover, BKANs' capacity to
represent aleatoric and epistemic uncertainty guarantees doctors receive more
solid and trustworthy decision support. Our Bayesian strategy improves the
interpretability of the model and considerably minimises overfitting, which is
important for tiny and imbalanced medical datasets, according to experimental
results. We present possible expansions to further use BKANs in more
complicated multimodal datasets and address the significance of these
discoveries for future research in building reliable AI systems for healthcare.
This work paves the way for a new paradigm in deep learning model deployment in
vital sectors where transparency and reliability are crucial.

æè¦ï¼ç±æ¼å¶å¼·å¤§çé æ¸¬è½åï¼æ·±åº¦å­¸ç¿å·²æçºè¨±å¤ç¢æ¥­ä¸­ä¸å¯æç¼ºçå·¥å·ï¼åæ¬é«çä¿å¥ãç¶èï¼å³çµ±çæ·±åº¦å­¸ç¿æ¨¡åéå¸¸ç¼ºä¹å¯è§£éæ§ï¼ä¸¦ä¸å¿½ç¥äºå°é æ¸¬ä¸ç¢ºå®æ§ç´å¥èéï¼èéå©åå ç´ æ¯è¨åºæ±ºç­å¶å®çééµçµæé¨åãçºäºç¢çå¯è§£éä¸å·æä¸ç¢ºå®æ§æè­çé æ¸¬ï¼æ¬ç ç©¶æåºäºä¸ååçºè²æ°æ¯ç¾è«å¥æ´å¤«é¿è«¾å¾·ç¶²è·¯ (BKAN) çæ°æ¶æ§ï¼å®çµåäºæ¯ç¾è«å¥æ´å¤«é¿è«¾å¾·ç¶²è·¯çè¡¨éè½åèè²æ°æ¨è«ãæåå¨å©åé«å­¸è³æéä¸ä½¿ç¨ BKANï¼éäºè³æéæ¯è©ä¼°æ©å¨å­¸ç¿æ¨¡åå¨é«å­¸è¨ºæ·ä¸­çå»£æ³ä½¿ç¨åºæºï¼ç®é¦¬å°ç¬¬å®äººç³å°¿çè³æéååéå¤«è­å¿èçè³æéãæåçæ¨¡åæä¾äºå°é æ¸¬ä¿¡å¿åæ±ºç­éççæçè¦è§£ï¼ä¸¦ä¸å¨é æ¸¬æºç¢ºåº¦æ¹é¢åªæ¼å³çµ±çæ·±åº¦å­¸ç¿æ¨¡åãæ­¤å¤ï¼BKAN è¡¨ç¾é¨æ©åèªè­ä¸ç¢ºå®æ§çè½åï¼å¯ç¢ºä¿é«çç²å¾æ´å¯é ä¸å¼å¾ä¿¡è³´çæ±ºç­æ¯æ´ãæ ¹æå¯¦é©çµæï¼æåçè²æ°ç­ç¥æé«äºæ¨¡åçå¯è§£éæ§ï¼ä¸¦å¤§å¹æ¸å°äºéåº¦æ¬åï¼éå°æ¼å°åä¸ä¸å¹³è¡¡çé«å­¸è³æééå¸¸éè¦ãæåæåºäºå¯è½çæ´ååè½ï¼ä»¥é²ä¸æ­¥å° BKAN ç¨æ¼æ´è¤éçå¤æ¨¡å¼è³æéï¼ä¸¦æ¢è¨éäºç¼ç¾å°æ¼æªä¾å»ºç«å¯é çé«çä¿å¥ AI ç³»çµ±ç ç©¶çéè¦æ§ãéé å·¥ä½çºæ·±åº¦å­¸ç¿æ¨¡åé¨ç½²å¨éæåº¦åå¯é æ§è³ééè¦çéè¦é åä¸­éåäºä¸åæ°çå¸ç¯ã

##### **MLtoGAI: Semantic Web based with Machine Learning for Enhanced Disease Prediction and Personalized Recommendations using Generative AI**
2407.20284v1 by Shyam Dongre, Ritesh Chandra, Sonali Agarwal

In modern healthcare, addressing the complexities of accurate disease
prediction and personalized recommendations is both crucial and challenging.
This research introduces MLtoGAI, which integrates Semantic Web technology with
Machine Learning (ML) to enhance disease prediction and offer user-friendly
explanations through ChatGPT. The system comprises three key components: a
reusable disease ontology that incorporates detailed knowledge about various
diseases, a diagnostic classification model that uses patient symptoms to
detect specific diseases accurately, and the integration of Semantic Web Rule
Language (SWRL) with ontology and ChatGPT to generate clear, personalized
health advice. This approach significantly improves prediction accuracy and
ensures results that are easy to understand, addressing the complexity of
diseases and diverse symptoms. The MLtoGAI system demonstrates substantial
advancements in accuracy and user satisfaction, contributing to developing more
intelligent and accessible healthcare solutions. This innovative approach
combines the strengths of ML algorithms with the ability to provide
transparent, human-understandable explanations through ChatGPT, achieving
significant improvements in prediction accuracy and user comprehension. By
leveraging semantic technology and explainable AI, the system enhances the
accuracy of disease prediction and ensures that the recommendations are
relevant and easily understood by individual patients. Our research highlights
the potential of integrating advanced technologies to overcome existing
challenges in medical diagnostics, paving the way for future developments in
intelligent healthcare systems. Additionally, the system is validated using 200
synthetic patient data records, ensuring robust performance and reliability.

æè¦ï¼å¨ç¾ä»£é«çä¿å¥ä¸­ï¼è§£æ±ºæºç¢ºç¾çé æ¸¬ååæ§åå»ºè­°çè¤éæ§æ¢è³ééè¦åå·æææ°æ§ãæ¬ç ç©¶å¼å¥äº MLtoGAIï¼å®å°èªç¾©ç¶²è·¯æè¡èæ©å¨å­¸ç¿ (ML) ç¸çµåï¼ä»¥å¢å¼·ç¾çé æ¸¬ä¸¦éé ChatGPT æä¾ä½¿ç¨èååçèªªæãè©²ç³»çµ±åå«ä¸åééµçµæé¨åï¼ä¸åå¯éè¤ä½¿ç¨çç¾çæ¬ä½ï¼å¶ä¸­åå«æéåç¨®ç¾ççè©³ç´°ç¥è­ï¼ä¸åè¨ºæ·åé¡æ¨¡åï¼å®ä½¿ç¨æ£èççä¾æºç¢ºæª¢æ¸¬ç¹å®ç¾çï¼ä»¥åèªç¾©ç¶²è·¯è¦åèªè¨ (SWRL) èæ¬ä½å ChatGPT çæ´åï¼ä»¥ç¢çæ¸æ°ãåæ§åçå¥åº·å»ºè­°ãéç¨®æ¹æ³é¡¯èæé«äºé æ¸¬æºç¢ºæ§ï¼ä¸¦ç¢ºä¿äºææ¼çè§£ççµæï¼è§£æ±ºäºç¾çåä¸åçççè¤éæ§ãMLtoGAI ç³»çµ±å±ç¤ºäºæºç¢ºæ§åä½¿ç¨èæ»¿æåº¦çå¯¦è³ªæ§é²æ­¥ï¼æå©æ¼éç¼æ´æºæ§ä¸æ´ææ¼åå¾çé«çä¿å¥è§£æ±ºæ¹æ¡ãéç¨®åµæ°çæ¹æ³çµåäº ML æ¼ç®æ³çåªé»ï¼ä»¥åéé ChatGPT æä¾éæä¸äººé¡å¯ä»¥çè§£çèªªæçè½åï¼å¨é æ¸¬æºç¢ºæ§åä½¿ç¨èçè§£æ¹é¢åå¾äºé¡¯èçé²æ­¥ãééå©ç¨èªç¾©æè¡åå¯è§£éç AIï¼è©²ç³»çµ±æé«äºç¾çé æ¸¬çæºç¢ºæ§ï¼ä¸¦ç¢ºä¿äºå»ºè­°èåå¥æ£èç¸éä¸ææ¼çè§£ãæåçç ç©¶å¼·èª¿äºæ´ååé²æè¡ä»¥åæé«çè¨ºæ·ä¸­ç¾æææ°çæ½åï¼çºæºæ§é«çä¿å¥ç³»çµ±çæªä¾ç¼å±éªè·¯ãæ­¤å¤ï¼è©²ç³»çµ±ä½¿ç¨ 200 ååææ£èè³æè¨éé²è¡é©è­ï¼ç¢ºä¿äºç©©å¥çæè½åå¯é æ§ã

##### **Introducing Î´-XAI: a novel sensitivity-based method for local AI explanations**
2407.18343v2 by Alessandro De Carlo, Enea Parimbelli, Nicola Melillo, Giovanna Nicora

Explainable Artificial Intelligence (XAI) is central to the debate on
integrating Artificial Intelligence (AI) and Machine Learning (ML) algorithms
into clinical practice. High-performing AI/ML models, such as ensemble learners
and deep neural networks, often lack interpretability, hampering clinicians'
trust in their predictions. To address this, XAI techniques are being developed
to describe AI/ML predictions in human-understandable terms. One promising
direction is the adaptation of sensitivity analysis (SA) and global sensitivity
analysis (GSA), which inherently rank model inputs by their impact on
predictions. Here, we introduce a novel delta-XAI method that provides local
explanations of ML model predictions by extending the delta index, a GSA
metric. The delta-XAI index assesses the impact of each feature's value on the
predicted output for individual instances in both regression and classification
problems. We formalize the delta-XAI index and provide code for its
implementation. The delta-XAI method was evaluated on simulated scenarios using
linear regression models, with Shapley values serving as a benchmark. Results
showed that the delta-XAI index is generally consistent with Shapley values,
with notable discrepancies in models with highly impactful or extreme feature
values. The delta-XAI index demonstrated higher sensitivity in detecting
dominant features and handling extreme feature values. Qualitatively, the
delta-XAI provides intuitive explanations by leveraging probability density
functions, making feature rankings clearer and more explainable for
practitioners. Overall, the delta-XAI method appears promising for robustly
obtaining local explanations of ML model predictions. Further investigations in
real-world clinical settings will be conducted to evaluate its impact on
AI-assisted clinical workflows.

æè¦ï¼å¯è§£éäººå·¥æºæ§ (XAI) æ¯å°äººå·¥æºæ§ (AI) åæ©å¨å­¸ç¿ (ML) æ¼ç®æ³æ´åå°è¨åºå¯¦åä¸­çè¾¯è«æ ¸å¿ãé«å·è¡æè½ç AI/ML æ¨¡åï¼ä¾å¦æ´é«å­¸ç¿å¨åæ·±åº¦ç¥ç¶ç¶²è·¯ï¼éå¸¸ç¼ºä¹å¯è§£éæ§ï¼é»ç¤è¨åºé«çå°å¶é æ¸¬çä¿¡ä»»ãçºäºè§£æ±ºéååé¡ï¼æ­£å¨éç¼ XAI æè¡ï¼ä»¥äººé¡å¯ä»¥çè§£çè¡èªæè¿° AI/ML é æ¸¬ãä¸åæå¸æçæ¹åæ¯æ¡ç¨ææåº¦åæ (SA) åå¨çææåº¦åæ (GSA)ï¼å®åæ¬è³ªä¸æä¾ææ¨¡åè¼¸å¥å°é æ¸¬çå½±é¿ä¾å°å¶é²è¡æåãå¨æ­¤ï¼æåä»ç´¹ä¸ç¨®æ°ç delta-XAI æ¹æ³ï¼ééæ´å GSA ææ¨ delta ææ¸ä¾æä¾ ML æ¨¡åé æ¸¬çå±é¨è§£éãdelta-XAI ææ¸è©ä¼°æ¯åç¹å¾µå¼å°åæ­¸ååé¡åé¡ä¸­åå¥ä¾é çé æ¸¬è¼¸åºä¹å½±é¿ãæåå° delta-XAI ææ¸å½¢å¼åï¼ä¸¦æä¾å¶å¯¦ä½çç¨å¼ç¢¼ãä½¿ç¨ç·æ§åæ­¸æ¨¡åå°æ¨¡æ¬æå¢è©ä¼° delta-XAI æ¹æ³ï¼ä¸¦ä»¥ Shapley å¼ä½çºåºæºãçµæé¡¯ç¤º delta-XAI ææ¸éå¸¸è Shapley å¼ä¸è´ï¼ä½å¨å·æé«åº¦å½±é¿åææ¥µç«¯ç¹å¾µå¼çæ¨¡åä¸­å­å¨é¡¯èå·®ç°ãdelta-XAI ææ¸å¨åµæ¸¬ä¸»è¦ç¹å¾µåèçæ¥µç«¯ç¹å¾µå¼æ¹é¢è¡¨ç¾åºæ´é«çææåº¦ãå®æ§å°ä¾èªªï¼delta-XAI ééå©ç¨æ©çå¯åº¦å½æ¸æä¾ç´è§çè§£éï¼ä½¿ç¹å¾µæåæ´æ¸æ°ä¸å°å¾æ¥­äººå¡ä¾èªªæ´å·å¯è§£éæ§ãç¸½é«èè¨ï¼delta-XAI æ¹æ³å°æ¼ç©©å¥å°åå¾ ML æ¨¡åé æ¸¬çå±é¨è§£éä¼¼ä¹å¾æå¸æãå°å¨çå¯¦ä¸ççè¨åºç°å¢ä¸­é²è¡é²ä¸æ­¥èª¿æ¥ï¼ä»¥è©ä¼°å¶å° AI è¼å©è¨åºå·¥ä½æµç¨çå½±é¿ã

##### **Enhanced Deep Learning Methodologies and MRI Selection Techniques for Dementia Diagnosis in the Elderly Population**
2407.17324v2 by Nikolaos Ntampakis, Konstantinos Diamantaras, Ioanna Chouvarda, Vasileios Argyriou, Panagiotis Sarigianndis

Dementia, a debilitating neurological condition affecting millions worldwide,
presents significant diagnostic challenges. In this work, we introduce a novel
methodology for the classification of demented and non-demented elderly
patients using 3D brain Magnetic Resonance Imaging (MRI) scans. Our approach
features a unique technique for selectively processing MRI slices, focusing on
the most relevant brain regions and excluding less informative sections. This
methodology is complemented by a confidence-based classification committee
composed of three custom deep learning models: Dem3D ResNet, Dem3D CNN, and
Dem3D EfficientNet. These models work synergistically to enhance
decision-making accuracy, leveraging their collective strengths. Tested on the
Open Access Series of Imaging Studies(OASIS) dataset, our method achieved an
impressive accuracy of 94.12%, surpassing existing methodologies. Furthermore,
validation on the Alzheimer's Disease Neuroimaging Initiative (ADNI) dataset
confirmed the robustness and generalizability of our approach. The use of
explainable AI (XAI) techniques and comprehensive ablation studies further
substantiate the effectiveness of our techniques, providing insights into the
decision-making process and the importance of our methodology. This research
offers a significant advancement in dementia diagnosis, providing a highly
accurate and efficient tool for clinical applications.

æè¦ï¼å¤±æºçæ¯ä¸ç¨®å½±é¿å¨çæ¸ç¾è¬äººçè¡°å¼±æ§ç¥ç¶ç¾çï¼å¨è¨ºæ·ä¸å·æéå¤§ææ°ãå¨éé å·¥ä½ä¸­ï¼æåæåºäºä¸ç¨®æ°çæ¹æ³ï¼ç¨æ¼å°å¤±æºåéå¤±æºèå¹´æ£èé²è¡åé¡ï¼ä½¿ç¨ 3D å¤§è¦ç£æ¯é å½± (MRI) ææãæåçåæ³æ¡ç¨äºä¸ç¨®ç¨ç¹æè¡ï¼ç¨æ¼é¸ææ§èç MRI åçï¼éé»éæ³¨æç¸éçå¤§è¦ååï¼ä¸¦æé¤ä¿¡æ¯éè¼å°çé¨åãéç¨®æ¹æ³ç±ä¸ååºæ¼ä¿¡å¿çåé¡å§å¡æè£åï¼è©²å§å¡æç±ä¸åèªå®ç¾©æ·±åº¦å­¸ç¿æ¨¡åçµæï¼Dem3D ResNetãDem3D CNN å Dem3D EfficientNetãéäºæ¨¡åååå·¥ä½ä»¥å¢å¼·æ±ºç­çæºç¢ºæ§ï¼å©ç¨å®åçéé«åªå¢ãå¨å½±åç ç©¶éæ¾å­åç³»å (OASIS) è³æéä¸é²è¡æ¸¬è©¦ï¼æåçæ¨¡åéå°äº 94.12% çé©äººæºç¢ºåº¦ï¼è¶éäºç¾ææ¹æ³ãæ­¤å¤ï¼å¨é¿è²æµ·é»çç¥ç¶å½±åå¡è­° (ADNI) è³æéä¸çé©è­è­å¯¦äºæåæ¹æ³çç©©å¥æ§åæ®éæ§ãå¯è§£é AI (XAI) æè¡åå¨é¢çæ¶èç ç©¶é²ä¸æ­¥è­å¯¦äºæåæè¡çæææ§ï¼æä¾äºå°æ±ºç­éç¨åæåæ¹æ³éè¦æ§çè¦è§£ãéé ç ç©¶çºå¤±æºçè¨ºæ·æä¾äºéå¤§é²å±ï¼çºè¨åºæç¨æä¾äºä¸åé«åº¦æºç¢ºä¸é«æçå·¥å·ã

##### **Using Large Language Models to Compare Explainable Models for Smart Home Human Activity Recognition**
2408.06352v1 by Michele Fiori, Gabriele Civitarese, Claudio Bettini

Recognizing daily activities with unobtrusive sensors in smart environments
enables various healthcare applications. Monitoring how subjects perform
activities at home and their changes over time can reveal early symptoms of
health issues, such as cognitive decline. Most approaches in this field use
deep learning models, which are often seen as black boxes mapping sensor data
to activities. However, non-expert users like clinicians need to trust and
understand these models' outputs. Thus, eXplainable AI (XAI) methods for Human
Activity Recognition have emerged to provide intuitive natural language
explanations from these models. Different XAI methods generate different
explanations, and their effectiveness is typically evaluated through user
surveys, that are often challenging in terms of costs and fairness. This paper
proposes an automatic evaluation method using Large Language Models (LLMs) to
identify, in a pool of candidates, the best XAI approach for non-expert users.
Our preliminary results suggest that LLM evaluation aligns with user surveys.

æè¦ï¼èç±æºæ§ç°å¢ä¸­ä¸å¼äººæ³¨ç®çææ¸¬å¨è¾¨è­æ¥å¸¸æ´»åï¼è½åç¨åç¨®é«çä¿å¥æç¨ãç£æ§åè©¦èå¨å®¶ä¸­å¦ä½å·è¡æ´»åï¼ä»¥åå¶é¨èæéçè®åï¼å¯ä»¥æ­ç¤ºå¥åº·åé¡çæ©æççï¼ä¾å¦èªç¥è½åä¸éãæ­¤é åä¸­çå¤§å¤æ¸æ¹æ³é½ä½¿ç¨æ·±åº¦å­¸ç¿æ¨¡åï¼éäºæ¨¡åéå¸¸è¢«è¦çºå°ææ¸¬å¨è³æå°æè³æ´»åçé»çå­ãç¶èï¼éå°å®¶ä½¿ç¨èï¼ä¾å¦è¨åºé«å¸«ï¼éè¦ä¿¡ä»»ä¸¦äºè§£éäºæ¨¡åçè¼¸åºãå æ­¤ï¼äººé¡æ´»åè¾¨è­çå¯è§£é AI (XAI) æ¹æ³æéèçï¼ä»¥æä¾ä¾èªéäºæ¨¡åçç´è¦ºèªç¶èªè¨èªªæãä¸åç XAI æ¹æ³æç¢çä¸åçèªªæï¼èå¶æææ§éå¸¸ééä½¿ç¨èèª¿æ¥ä¾è©ä¼°ï¼éå¨ææ¬åå¬å¹³æ§æ¹é¢éå¸¸å·æææ°æ§ãæ¬ææåºä½¿ç¨å¤§åèªè¨æ¨¡å (LLM) çèªåè©ä¼°æ¹æ³ï¼ä»¥å¨åé¸èä¸­æ¾åºæé©åéå°å®¶ä½¿ç¨èç XAI æ¹æ³ãæåçåæ­¥çµæè¡¨æï¼LLM è©ä¼°èä½¿ç¨èèª¿æ¥ä¸è´ã

##### **Explainable AI-based Intrusion Detection System for Industry 5.0: An Overview of the Literature, associated Challenges, the existing Solutions, and Potential Research Directions**
2408.03335v1 by Naseem Khan, Kashif Ahmad, Aref Al Tamimi, Mohammed M. Alani, Amine Bermak, Issa Khalil

Industry 5.0, which focuses on human and Artificial Intelligence (AI)
collaboration for performing different tasks in manufacturing, involves a
higher number of robots, Internet of Things (IoTs) devices and
interconnections, Augmented/Virtual Reality (AR), and other smart devices. The
huge involvement of these devices and interconnection in various critical
areas, such as economy, health, education and defense systems, poses several
types of potential security flaws. AI itself has been proven a very effective
and powerful tool in different areas of cybersecurity, such as intrusion
detection, malware detection, and phishing detection, among others. Just as in
many application areas, cybersecurity professionals were reluctant to accept
black-box ML solutions for cybersecurity applications. This reluctance pushed
forward the adoption of eXplainable Artificial Intelligence (XAI) as a tool
that helps explain how decisions are made in ML-based systems. In this survey,
we present a comprehensive study of different XAI-based intrusion detection
systems for industry 5.0, and we also examine the impact of explainability and
interpretability on Cybersecurity practices through the lens of Adversarial
XIDS (Adv-XIDS) approaches. Furthermore, we analyze the possible opportunities
and challenges in XAI cybersecurity systems for industry 5.0 that elicit future
research toward XAI-based solutions to be adopted by high-stakes industry 5.0
applications. We believe this rigorous analysis will establish a foundational
framework for subsequent research endeavors within the specified domain.

æè¦ï¼å·¥æ¥­ 5.0 èéæ¼äººé¡èäººå·¥æºæ§ (AI) åä½å·è¡è£½é ä¸­çä¸åä»»åï¼æ¶åæ´å¤æ©å¨äººãç©è¯ç¶² (IoT) è£ç½®åäºé£ãæ´å¢/èæ¬å¯¦å¢ (AR) åå¶ä»æºæ§è£ç½®ãéäºè£ç½®åäºé£å¨ç¶æ¿ãé«çä¿å¥ãæè²ååé²ç³»çµ±ç­åç¨®ééµé åçå»£æ³åèï¼å¼ç¼äºå¤ç¨®é¡åçæ½å¨å®å¨æ¼æ´ãAI æ¬èº«å·²è¢«è­ææ¯ç¶²è·¯å®å¨ä¸åé åä¸­éå¸¸ææä¸å¼·å¤§çå·¥å·ï¼ä¾å¦å¥ä¾µåµæ¸¬ãæ¡æè»é«åµæ¸¬åç¶²è·¯é£é­åµæ¸¬ç­ãå°±åå¨è¨±å¤æç¨é åä¸æ¨£ï¼ç¶²è·¯å®å¨å°æ¥­äººå¡ä¸é¡ææ¥åé»ç ML è§£æ±ºæ¹æ¡ä¾æç¨æ¼ç¶²è·¯å®å¨ãéç¨®ä¸é¡æä¿ä½¿å¯è§£éäººå·¥æºæ§ (XAI) ä½çºä¸ç¨®å·¥å·è¢«æ¡ç¨ï¼æå©æ¼èªªæå¨åºæ¼ ML çç³»çµ±ä¸­å¦ä½ååºæ±ºç­ãå¨éé èª¿æ¥ä¸­ï¼æåå°å·¥æ¥­ 5.0 çä¸ååºæ¼ XAI çå¥ä¾µåµæ¸¬ç³»çµ±é²è¡äºå¨é¢çç ç©¶ï¼ä¸¦ä¸æåä¹ééå°æå¼ XIDS (Adv-XIDS) æ¹æ³çè§é»ä¾æ¢è¨å¯è§£éæ§åå¯è©®éæ§å°ç¶²è·¯å®å¨å¯¦åçå½±é¿ãæ­¤å¤ï¼æååæäºå·¥æ¥­ 5.0 ç XAI ç¶²è·¯å®å¨ç³»çµ±ä¸­å¯è½å­å¨çæ©æåææ°ï¼å¼ç¼äºæªä¾éå° XAI åºç¤è§£æ±ºæ¹æ¡çç ç©¶ï¼ä»¥ä¾é«é¢¨éªçå·¥æ¥­ 5.0 æç¨æ¡ç¨ãæåç¸ä¿¡éé å´è¬¹çåæå°çºæå®é åå§çå¾çºç ç©¶å·¥ä½å»ºç«åºç¤æ¶æ§ã

##### **A Comparative Study on Automatic Coding of Medical Letters with Explainability**
2407.13638v1 by Jamie Glen, Lifeng Han, Paul Rayson, Goran Nenadic

This study aims to explore the implementation of Natural Language Processing
(NLP) and machine learning (ML) techniques to automate the coding of medical
letters with visualised explainability and light-weighted local computer
settings. Currently in clinical settings, coding is a manual process that
involves assigning codes to each condition, procedure, and medication in a
patient's paperwork (e.g., 56265001 heart disease using SNOMED CT code). There
are preliminary research on automatic coding in this field using
state-of-the-art ML models; however, due to the complexity and size of the
models, the real-world deployment is not achieved. To further facilitate the
possibility of automatic coding practice, we explore some solutions in a local
computer setting; in addition, we explore the function of explainability for
transparency of AI models. We used the publicly available MIMIC-III database
and the HAN/HLAN network models for ICD code prediction purposes. We also
experimented with the mapping between ICD and SNOMED CT knowledge bases. In our
experiments, the models provided useful information for 97.98\% of codes. The
result of this investigation can shed some light on implementing automatic
clinical coding in practice, such as in hospital settings, on the local
computers used by clinicians , project page
\url{https://github.com/Glenj01/Medical-Coding}.

æè¦ï¼æ¬ç ç©¶æ¨å¨æ¢è¨å°èªç¶èªè¨èç (NLP) åæ©å¨å­¸ç¿ (ML) æè¡å¯¦ä½æ¼é«çä¿¡å½ç·¨ç¢¼èªååï¼ä¸¦å·åè¦è¦ºåèªªæè½ååè¼éåçæ¬å°é»è¦è¨­å®ãç®åå¨è¨åºç°å¢ä¸­ï¼ç·¨ç¢¼æ¯ä¸ç¨®æåæµç¨ï¼æ¶åçºçæ£æä»¶ä¸­çæ¯é ççãç¨åºåè¥ç©ææ´¾ä»£ç¢¼ (ä¾å¦ï¼ä½¿ç¨ SNOMED CT ä»£ç¢¼ 56265001 è¡¨ç¤ºå¿èç)ãæ­¤é åæä½¿ç¨ææ° ML æ¨¡åé²è¡èªåç·¨ç¢¼çåæ­¥ç ç©¶ï¼ç¶èï¼ç±æ¼æ¨¡åçè¤éæ§åå¤§å°ï¼ä¸¦æªå¯¦ç¾å¯¦éé¨ç½²ãçºäºé²ä¸æ­¥ä¿é²èªåç·¨ç¢¼å¯¦åçå¯è½æ§ï¼æåå¨æ¬å°é»è¦è¨­å®ä¸­æ¢è¨äºä¸äºè§£æ±ºæ¹æ¡ï¼æ­¤å¤ï¼æåæ¢è¨äºèªªæåè½å¨ AI æ¨¡åéæåº¦ä¸­çåè½ãæåä½¿ç¨å¬éç MIMIC-III è³æåº«å HAN/HLAN ç¶²è·¯æ¨¡åé²è¡ ICD ä»£ç¢¼é æ¸¬ãæåéè©¦é©äº ICD å SNOMED CT ç¥è­åº«ä¹éçå°æãå¨æåçå¯¦é©ä¸­ï¼éäºæ¨¡åæä¾äº 97.98% ä»£ç¢¼çæç¨è³è¨ãéé èª¿æ¥çµæå¯ä»¥çºå¯¦åä¸­çèªåè¨åºç·¨ç¢¼å¯¦ä½æä¾ä¸äºè¦è§£ï¼ä¾å¦å¨é«é¢ç°å¢ä¸­ï¼ç±è¨åºé«çä½¿ç¨çæ¬å°é»è¦ï¼å°æ¡é é¢ \url{https://github.com/Glenj01/Medical-Coding}ã

##### **Explainable AI for Enhancing Efficiency of DL-based Channel Estimation**
2407.07009v1 by Abdul Karim Gizzini, Yahia Medjahdi, Ali J. Ghandour, Laurent Clavier

The support of artificial intelligence (AI) based decision-making is a key
element in future 6G networks, where the concept of native AI will be
introduced. Moreover, AI is widely employed in different critical applications
such as autonomous driving and medical diagnosis. In such applications, using
AI as black-box models is risky and challenging. Hence, it is crucial to
understand and trust the decisions taken by these models. Tackling this issue
can be achieved by developing explainable AI (XAI) schemes that aim to explain
the logic behind the black-box model behavior, and thus, ensure its efficient
and safe deployment. Recently, we proposed a novel perturbation-based XAI-CHEST
framework that is oriented toward channel estimation in wireless
communications. The core idea of the XAI-CHEST framework is to identify the
relevant model inputs by inducing high noise on the irrelevant ones. This
manuscript provides the detailed theoretical foundations of the XAI-CHEST
framework. In particular, we derive the analytical expressions of the XAI-CHEST
loss functions and the noise threshold fine-tuning optimization problem. Hence
the designed XAI-CHEST delivers a smart input feature selection methodology
that can further improve the overall performance while optimizing the
architecture of the employed model. Simulation results show that the XAI-CHEST
framework provides valid interpretations, where it offers an improved bit error
rate performance while reducing the required computational complexity in
comparison to the classical DL-based channel estimation.

æè¦ï¼äººå·¥æºè½ (AI) æ¯æçæ±ºç­å¶å®æ¯æªä¾ 6G ç¶²è·¯ä¸­çééµåç´ ï¼å¶ä¸­å°å¼å¥åç AI çæ¦å¿µãæ­¤å¤ï¼AI å»£æ³ç¨æ¼ä¸åçééµæç¨ä¸­ï¼ä¾å¦èªåé§é§åé«çè¨ºæ·ãå¨éäºæç¨ä¸­ï¼ä½¿ç¨ AI ä½çºé»çæ¨¡åæ¯æé¢¨éªä¸å·æææ°æ§çãå æ­¤ï¼çè§£åä¿¡ä»»éäºæ¨¡åååºçæ±ºç­è³ééè¦ãè§£æ±ºæ­¤åé¡çæ¹æ³æ¯éç¼å¯è§£é AI (XAI) æ¶æ§ï¼æ¨å¨è§£éé»çæ¨¡åè¡çºèå¾çéè¼¯ï¼å¾èç¢ºä¿å¶ææä¸å®å¨çé¨ç½²ãæè¿ï¼æåæåºäºä¸åæ°çåºæ¼æ¾åç XAI-CHEST æ¡æ¶ï¼è©²æ¡æ¶é¢åç¡ç·éä¿¡ä¸­çä¿¡éä¼°è¨ãXAI-CHEST æ¡æ¶çæ ¸å¿ææ³æ¯ééå¨ç¡éè¼¸å¥ä¸å¼å¥é«åªè²ä¾è­å¥ç¸éæ¨¡åè¼¸å¥ãéä»½æç¨¿æä¾äº XAI-CHEST æ¡æ¶çè©³ç´°çè«åºç¤ãç¹å¥æ¯ï¼æåæ¨å°äº XAI-CHEST æå¤±å½æ¸ååªè²é¾å¼å¾®èª¿åªååé¡çè§£æè¡¨éå¼ãå æ­¤ï¼è¨­è¨ç XAI-CHEST æä¾äºä¸ç¨®æºè½è¼¸å¥ç¹å¾µé¸ææ¹æ³ï¼å¯ä»¥å¨åªåæç¨æ¨¡åçæ¶æ§çåæé²ä¸æ­¥æé«æ´é«æ§è½ãæ¨¡æ¬çµæè¡¨æï¼XAI-CHEST æ¡æ¶æä¾äºææçè§£éï¼å¨éä½æéçè¨ç®è¤éåº¦çåæï¼æä¾äºæ¹é²çæ¯ç¹é¯èª¤çæ§è½ï¼èéèåºæ¼å³çµ± DL çä¿¡éä¼°è¨ç¸æ¯ã

##### **Explainable AI: Comparative Analysis of Normal and Dilated ResNet Models for Fundus Disease Classification**
2407.05440v2 by P. N. Karthikayan, Yoga Sri Varshan V, Hitesh Gupta Kattamuri, Umarani Jayaraman

This paper presents dilated Residual Network (ResNet) models for disease
classification from retinal fundus images. Dilated convolution filters are used
to replace normal convolution filters in the higher layers of the ResNet model
(dilated ResNet) in order to improve the receptive field compared to the normal
ResNet model for disease classification. This study introduces
computer-assisted diagnostic tools that employ deep learning, enhanced with
explainable AI techniques. These techniques aim to make the tool's
decision-making process transparent, thereby enabling medical professionals to
understand and trust the AI's diagnostic decision. They are particularly
relevant in today's healthcare landscape, where there is a growing demand for
transparency in AI applications to ensure their reliability and ethical use.
The dilated ResNet is used as a replacement for the normal ResNet to enhance
the classification accuracy of retinal eye diseases and reduce the required
computing time. The dataset used in this work is the Ocular Disease Intelligent
Recognition (ODIR) dataset which is a structured ophthalmic database with eight
classes covering most of the common retinal eye diseases. The evaluation
metrics used in this work include precision, recall, accuracy, and F1 score. In
this work, a comparative study has been made between normal ResNet models and
dilated ResNet models on five variants namely ResNet-18, ResNet-34, ResNet-50,
ResNet-101, and ResNet-152. The dilated ResNet model shows promising results as
compared to normal ResNet with an average F1 score of 0.71, 0.70, 0.69, 0.67,
and 0.70 respectively for the above respective variants in ODIR multiclass
disease classification.

æè¦ï¼è¿ç¯è®ºææåºäºç¨äºä»è§ç½èç¼åºå¾åè¿è¡ç¾çåç±»çæ©å¼ æ®å·®ç½ç» (ResNet) æ¨¡åãæ©å¼ å·ç§¯æ»¤æ³¢å¨ç¨äºæ¿æ¢ ResNet æ¨¡åè¾é«å±ä¸­çæ­£å¸¸å·ç§¯æ»¤æ³¢å¨ï¼æ©å¼  ResNetï¼ï¼ä»¥æ¹åæç¥åºï¼ä»èéå¯¹ç¾çåç±»å¯¹æ­£å¸¸ ResNet æ¨¡åè¿è¡æ¹è¿ãæ¬ç ç©¶å¼å¥äºéç¨æ·±åº¦å­¦ä¹ çè®¡ç®æºè¾å©è¯æ­å·¥å·ï¼å¹¶éè¿å¯è§£éç AI ææ¯è¿è¡äºå¢å¼ºãè¿äºææ¯æ¨å¨ä½¿è¯¥å·¥å·çå³ç­è¿ç¨éæåï¼ä»èä½¿å»å­¦ä¸ä¸äººå£«è½å¤çè§£åä¿¡ä»» AI çè¯æ­å³ç­ãå®ä»¬ä¸å½ä»çå»çä¿å¥é¢åå°¤ä¸ºç¸å³ï¼å¨è¯¥é¢åï¼å¯¹ AI åºç¨çéæåº¦éæ±ä¸æ­å¢é¿ï¼ä»¥ç¡®ä¿å¶å¯é æ§ååä¹éå¾·çä½¿ç¨ãæ©å¼  ResNet ç¨ä½æ­£å¸¸ ResNet çæ¿ä»£åï¼ä»¥æé«è§ç½èç¼é¨ç¾ççåç±»åç¡®æ§å¹¶åå°æéçè®¡ç®æ¶é´ãæ¬å·¥ä½ä¸­ä½¿ç¨çæ°æ®éæ¯ç¼ç§ç¾çæºè½è¯å« (ODIR) æ°æ®éï¼è¿æ¯ä¸ä¸ªç»æåçç¼ç§æ°æ®åºï¼åå«å«ç±»æ¶µçå¤§å¤æ°å¸¸è§è§ç½èç¼é¨ç¾çãæ¬å·¥ä½ä¸­ä½¿ç¨çè¯ä¼°ææ åæ¬ç²¾ç¡®åº¦ãå¬åçãåç¡®åº¦å F1 å¾åãå¨è¿é¡¹å·¥ä½ä¸­ï¼å¯¹ ResNet-18ãResNet-34ãResNet-50ãResNet-101 å ResNet-152 äºä¸ªåä½çæ­£å¸¸ ResNet æ¨¡ååæ©å¼  ResNet æ¨¡åè¿è¡äºæ¯è¾ç ç©¶ãä¸æ­£å¸¸ ResNet ç¸æ¯ï¼æ©å¼  ResNet æ¨¡åæ¾ç¤ºåºæå¸æçç»æï¼å¨ ODIR å¤ç±»ç¾çåç±»ä¸­ï¼ä¸è¿°åä¸ªåä½çå¹³å F1 å¾åä¸º 0.71ã0.70ã0.69ã0.67 å 0.70ã

##### **A Survey on Trustworthiness in Foundation Models for Medical Image Analysis**
2407.15851v2 by Congzhen Shi, Ryan Rezai, Jiaxi Yang, Qi Dou, Xiaoxiao Li

The rapid advancement of foundation models in medical imaging represents a
significant leap toward enhancing diagnostic accuracy and personalized
treatment. However, the deployment of foundation models in healthcare
necessitates a rigorous examination of their trustworthiness, encompassing
privacy, robustness, reliability, explainability, and fairness. The current
body of survey literature on foundation models in medical imaging reveals
considerable gaps, particularly in the area of trustworthiness. Additionally,
existing surveys on the trustworthiness of foundation models do not adequately
address their specific variations and applications within the medical imaging
domain. This survey aims to fill that gap by presenting a novel taxonomy of
foundation models used in medical imaging and analyzing the key motivations for
ensuring their trustworthiness. We review current research on foundation models
in major medical imaging applications, focusing on segmentation, medical report
generation, medical question and answering (Q\&A), and disease diagnosis. These
areas are highlighted because they have seen a relatively mature and
substantial number of foundation models compared to other applications. We
focus on literature that discusses trustworthiness in medical image analysis
manuscripts. We explore the complex challenges of building trustworthy
foundation models for each application, summarizing current concerns and
strategies for enhancing trustworthiness. Furthermore, we examine the potential
of these models to revolutionize patient care. Our analysis underscores the
imperative for advancing towards trustworthy AI in medical image analysis,
advocating for a balanced approach that fosters innovation while ensuring
ethical and equitable healthcare delivery.

æè¦ï¼åºç¤æ¨¡åå¨é«å­¸å½±åæ¹é¢çå¿«éé²å±ï¼ä»£è¡¨èå¨å å¼·è¨ºæ·æºç¢ºæ§ååäººåæ²»çæ¹é¢éåºä¸å¤§æ­¥ãç¶èï¼åºç¤æ¨¡åå¨é«çä¿å¥ä¸­çé¨ç½²éè¦å°å¶å¯ä¿¡åº¦é²è¡å´æ ¼çå¯©æ¥ï¼åæ¬é±ç§ãç©©å¥æ§ãå¯é æ§ãå¯è§£éæ§åå¬å¹³æ§ãç®åéæ¼é«å­¸å½±åä¸­åºç¤æ¨¡åçèª¿æ¥æç»ä¸­é¡¯ç¤ºåºç¸ç¶å¤§çå·®è·ï¼ç¹å¥æ¯å¨å¯ä¿¡åº¦æ¹é¢ãæ­¤å¤ï¼ç¾æéæ¼åºç¤æ¨¡åå¯ä¿¡åº¦çèª¿æ¥ä¸¦æªååè§£æ±ºå¶å¨é«å­¸å½±åé åä¸­çç¹å®è®ååæç¨ãæ¬èª¿æ¥æ¨å¨ééæåºé«å­¸å½±åä¸­ä½¿ç¨çåºç¤æ¨¡åçæ°åé¡æ³ä¸¦åæç¢ºä¿å¶å¯ä¿¡åº¦çééµåæ©ï¼ä¾å¡«è£éä¸ç©ºç½ãæååé¡§äºåºç¤æ¨¡åå¨ä¸»è¦é«å­¸å½±åæç¨ä¸­çç¶åç ç©¶ï¼éé»éæ³¨åå²ãé«çå ±åçæãé«çåé¡ååç­ (Q&A) ä»¥åç¾çè¨ºæ·ãéäºé åä¹æä»¥è¢«å¼·èª¿ï¼æ¯å çºèå¶ä»æç¨ç¸æ¯ï¼å®åå·²ç¶çå°ç¸å°æçä¸å¤§éçåºç¤æ¨¡åãæåå°æ³¨æ¼æ¢è¨é«å­¸å½±ååææç¨¿ä¸­å¯ä¿¡åº¦çæç»ãæåæ¢è¨äºçºæ¯åæç¨æ§å»ºå¯ä¿¡åºç¤æ¨¡åçè¤éææ°ï¼ç¸½çµäºç¶åéæ³¨é»åå¢å¼·å¯ä¿¡åº¦çç­ç¥ãæ­¤å¤ï¼æåæ¢è¨äºéäºæ¨¡åå¨é©æ°æ£èè­·çæ¹é¢çæ½åãæåçåæå¼·èª¿äºå¨é«å­¸å½±ååæä¸­æèå¯ä¿¡è³´çäººå·¥æºæ§éé²çå¿è¦æ§ï¼ä¸¦å¡å°ä¸ç¨®å¹³è¡¡çæ¹æ³ï¼æ¢è½ä¿é²åµæ°ï¼åè½ç¢ºä¿éå¾·åå¬å¹³çé«çä¿å¥æåã

##### **The Impact of an XAI-Augmented Approach on Binary Classification with Scarce Data**
2407.06206v1 by Ximing Wen, Rosina O. Weber, Anik Sen, Darryl Hannan, Steven C. Nesbit, Vincent Chan, Alberto Goffi, Michael Morris, John C. Hunninghake, Nicholas E. Villalobos, Edward Kim, Christopher J. MacLellan

Point-of-Care Ultrasound (POCUS) is the practice of clinicians conducting and
interpreting ultrasound scans right at the patient's bedside. However, the
expertise needed to interpret these images is considerable and may not always
be present in emergency situations. This reality makes algorithms such as
machine learning classifiers extremely valuable to augment human decisions.
POCUS devices are becoming available at a reasonable cost in the size of a
mobile phone. The challenge of turning POCUS devices into life-saving tools is
that interpretation of ultrasound images requires specialist training and
experience. Unfortunately, the difficulty to obtain positive training images
represents an important obstacle to building efficient and accurate
classifiers. Hence, the problem we try to investigate is how to explore
strategies to increase accuracy of classifiers trained with scarce data. We
hypothesize that training with a few data instances may not suffice for
classifiers to generalize causing them to overfit. Our approach uses an
Explainable AI-Augmented approach to help the algorithm learn more from less
and potentially help the classifier better generalize.

æè¦ï¼åºéè¶é³æ³¢ (POCUS) æ¯è¨åºé«å¸«å¨æ£èåºéé²è¡åè§£è®è¶é³æ³¢ææçå¯¦åãç¶èï¼è§£è®éäºå½±åæéçå°æ¥­ç¥è­ç¸ç¶å¯è§ï¼èä¸å¨ç·æ¥ææ³ä¸å¯è½ä¸¦éé¨æå·åãéç¨®ç¾å¯¦ææ³ä½¿å¾æ©å¨å­¸ç¿åé¡å¨ç­æ¼ç®æ³å°æ¼å å¼·äººé¡æ±ºç­è®å¾æ¥µçºæå¹å¼ãPOCUS è£ç½®æ­£ä»¥åçææ¬æ¨åºï¼å°ºå¯¸çºææ©å¤§å°ãå° POCUS è£ç½®è½è®çºæçå·¥å·çææ°å¨æ¼ï¼è§£è®è¶é³æ³¢å½±åéè¦å°éè¨ç·´åç¶é©ãä¸å¹¸çæ¯ï¼åå¾æ­£åè¨ç·´å½±åçå°é£åº¦ä»£è¡¨èå»ºç½®ææçä¸æºç¢ºçåé¡å¨çä¸å¤§éç¤ãå æ­¤ï¼æååè©¦æ¢è¨çåé¡æ¯å¦ä½æ¢ç´¢ç­ç¥ï¼ä»¥æé«ä½¿ç¨ç¨çè³æè¨ç·´çåé¡å¨çæºç¢ºåº¦ãæååè¨­ä½¿ç¨å°æ¸è³æå¯¦ä¾é²è¡è¨ç·´å¯è½ä¸è¶³ä»¥è®åé¡å¨æ¦æ¬ï¼å°è´å®åéåº¦æ¬åãæåçåæ³ä½¿ç¨å¯è§£é AI å¢å¼·æ¹æ³ï¼ä»¥åå©æ¼ç®æ³å¾è¼å°çè³æä¸­å­¸ç¿æ´å¤ï¼ä¸¦æ½å¨åå©åé¡å¨æ´å¥½å°æ¦æ¬ã

##### **Can GPT-4 Help Detect Quit Vaping Intentions? An Exploration of Automatic Data Annotation Approach**
2407.00167v1 by Sai Krishna Revanth Vuruma, Dezhi Wu, Saborny Sen Gupta, Lucas Aust, Valerie Lookingbill, Wyatt Bellamy, Yang Ren, Erin Kasson, Li-Shiun Chen, Patricia Cavazos-Rehg, Dian Hu, Ming Huang

In recent years, the United States has witnessed a significant surge in the
popularity of vaping or e-cigarette use, leading to a notable rise in cases of
e-cigarette and vaping use-associated lung injury (EVALI) that caused
hospitalizations and fatalities during the EVALI outbreak in 2019, highlighting
the urgency to comprehend vaping behaviors and develop effective strategies for
cessation. Due to the ubiquity of social media platforms, over 4.7 billion
users worldwide use them for connectivity, communications, news, and
entertainment with a significant portion of the discourse related to health,
thereby establishing social media data as an invaluable organic data resource
for public health research. In this study, we extracted a sample dataset from
one vaping sub-community on Reddit to analyze users' quit-vaping intentions.
Leveraging OpenAI's latest large language model GPT-4 for sentence-level quit
vaping intention detection, this study compares the outcomes of this model
against layman and clinical expert annotations. Using different prompting
strategies such as zero-shot, one-shot, few-shot and chain-of-thought
prompting, we developed 8 prompts with varying levels of detail to explain the
task to GPT-4 and also evaluated the performance of the strategies against each
other. These preliminary findings emphasize the potential of GPT-4 in social
media data analysis, especially in identifying users' subtle intentions that
may elude human detection.

æè¦ï¼è¿å¹´ä¾ï¼ç¾åè¦è­äºé»å­çæé»å­é¦è¸ä½¿ç¨çå¤§å¹æ¿å¢ï¼å°è´é»å­çåé»å­çä½¿ç¨ç¸éèºæå· (EVALI) çä¾é¡¯èå¢å ï¼å¨ 2019 å¹´ EVALI çç¼æéé æä½é¢åæ­»äº¡ï¼å¸é¡¯äºçè§£é»å­çè¡çºåå¶å®æææè¸ç­ç¥çè¿«åæ§ãç±æ¼ç¤¾ç¾¤åªé«å¹³å°çæ®åï¼å¨çè¶é 47 åä½¿ç¨èä½¿ç¨å®åé²è¡é£çµãæºéãæ°èåå¨æ¨ï¼å¶ä¸­å¾å¤§ä¸é¨åèå¥åº·ç¸éï¼å æ­¤å°ç¤¾ç¾¤åªé«è³æå»ºç«çºå¬å±è¡çç ç©¶ä¸­ç¡å¹çææ©è³æè³æºãå¨æ¬ç ç©¶ä¸­ï¼æåå¾ Reddit ä¸ä¸åé»å­çå­ç¤¾ç¾¤ä¸­æåä¸åç¯ä¾è³æéï¼ä»¥åæä½¿ç¨èçæé»å­çæåãå©ç¨ OpenAI ææ°çå¤§åèªè¨æ¨¡å GPT-4 é²è¡å¥å­å±¤ç´çæé»å­çæååµæ¸¬ï¼æ¬ç ç©¶æ¯è¼äºæ­¤æ¨¡åççµæèå¤è¡äººåè¨åºå°å®¶è¨»è§£ãä½¿ç¨ä¸åçæç¤ºç­ç¥ï¼ä¾å¦é¶æ¬¡å­¸ç¿ãä¸æ¬¡å­¸ç¿ãå°æ¬¡å­¸ç¿åæèéæç¤ºï¼æåéç¼äº 8 åæç¤ºï¼è©³ç´°ç¨åº¦ä¸åï¼å GPT-4 è§£éä»»åï¼ä¸¦è©ä¼°éäºç­ç¥å½¼æ­¤ä¹éçæè½ãéäºåæ­¥ç¼ç¾å¼·èª¿äº GPT-4 å¨ç¤¾ç¾¤åªé«è³æåæä¸­çæ½åï¼ç¹å¥æ¯å¨è­å¥äººé¡åµæ¸¬å¯è½ç¡æ³å¯è¦ºçä½¿ç¨èå¾®å¦æåæ¹é¢ã

##### **Towards Compositional Interpretability for XAI**
2406.17583v1 by Sean Tull, Robin Lorenz, Stephen Clark, Ilyas Khan, Bob Coecke

Artificial intelligence (AI) is currently based largely on black-box machine
learning models which lack interpretability. The field of eXplainable AI (XAI)
strives to address this major concern, being critical in high-stakes areas such
as the finance, legal and health sectors.
  We present an approach to defining AI models and their interpretability based
on category theory. For this we employ the notion of a compositional model,
which sees a model in terms of formal string diagrams which capture its
abstract structure together with its concrete implementation. This
comprehensive view incorporates deterministic, probabilistic and quantum
models. We compare a wide range of AI models as compositional models, including
linear and rule-based models, (recurrent) neural networks, transformers, VAEs,
and causal and DisCoCirc models.
  Next we give a definition of interpretation of a model in terms of its
compositional structure, demonstrating how to analyse the interpretability of a
model, and using this to clarify common themes in XAI. We find that what makes
the standard 'intrinsically interpretable' models so transparent is brought out
most clearly diagrammatically. This leads us to the more general notion of
compositionally-interpretable (CI) models, which additionally include, for
instance, causal, conceptual space, and DisCoCirc models.
  We next demonstrate the explainability benefits of CI models. Firstly, their
compositional structure may allow the computation of other quantities of
interest, and may facilitate inference from the model to the modelled
phenomenon by matching its structure. Secondly, they allow for diagrammatic
explanations for their behaviour, based on influence constraints, diagram
surgery and rewrite explanations. Finally, we discuss many future directions
for the approach, raising the question of how to learn such meaningfully
structured models in practice.

æè¦ï¼<paragraph>äººå·¥æºæ§ï¼AIï¼ç®åå¨å¾å¤§ç¨åº¦ä¸ä¾è³´æ¼ç¼ºä¹å¯è§£éæ§çé»çæ©å¨å­¸ç¿æ¨¡åãå¯è§£éæ§äººå·¥æºæ§ï¼XAIï¼é åè´åæ¼è§£æ±ºéåä¸»è¦åé¡ï¼éå¨éèãæ³å¾åå¥åº·ç­é«é¢¨éªé åè³ééè¦ã
æåæåºäºä¸ç¨®åºæ¼ç¯çè«å®ç¾© AI æ¨¡ååå¶å¯è§£éæ§çæ¹æ³ãçºæ­¤ï¼æåæ¡ç¨çµåæ¨¡åçæ¦å¿µï¼å®ä»¥å½¢å¼å¼¦åçå½¢å¼çå¾æ¨¡åï¼éäºå¼¦åæç²äºæ¨¡åçæ½è±¡çµæ§åå¶å·é«å¯¦ç¾ãéç¨®ç¶åè§é»åå«äºç¢ºå®æ§ãæ¦çæ§åéå­æ¨¡åãæåå°åç¨® AI æ¨¡åä½çºçµåæ¨¡åé²è¡æ¯è¼ï¼åæ¬ç·æ§ååºæ¼è¦åçæ¨¡åãï¼éè¿´ï¼ç¥ç¶ç¶²è·¯ãTransformerãVAEï¼ä»¥åå æå DisCoCirc æ¨¡åã
æ¥ä¸ä¾ï¼æåæ ¹ææ¨¡åççµåçµæ§çµ¦åºæ¨¡åè§£éçå®ç¾©ï¼å±ç¤ºå¦ä½åææ¨¡åçå¯è§£éæ§ï¼ä¸¦ä½¿ç¨å®ä¾æ¾æ¸ XAI ä¸­çå¸¸è¦ä¸»é¡ãæåç¼ç¾ï¼è®æ¨æºçãå§å¨å¯è§£éãæ¨¡åå¦æ­¤éæçåå å¨åè¡¨ä¸­è¡¨ç¾å¾æçºæ¸æ¥ãéå¼å°æåå¾åºæ´ä¸è¬ççµåå¯è§£éï¼CIï¼æ¨¡åæ¦å¿µï¼å®å¦å¤éåæ¬å æãæ¦å¿µç©ºéå DisCoCirc æ¨¡åã
æ¥ä¸ä¾ï¼æåå±ç¤ºäº CI æ¨¡åçå¯è§£éæ§åªå¢ãé¦åï¼å®åççµåçµæ§åè¨±è¨ç®å¶ä»æèè¶£çéï¼ä¸¦å¯è½ééå¹éæ¨¡åççµæ§ä¾ä¿é²å¾æ¨¡åå°è¢«å»ºæ¨¡ç¾è±¡çæ¨çãå¶æ¬¡ï¼å®ååè¨±å°å¶è¡çºé²è¡åè§£èªªæï¼éäºèªªæåºæ¼å½±é¿ç´æãåè§£æè¡åéå¯«èªªæãæå¾ï¼æåè¨è«äºéç¨®æ¹æ³çè¨±å¤æªä¾æ¹åï¼æåºäºå¦ä½å¨å¯¦è¸ä¸­å­¸ç¿éç¨®ææç¾©ççµæ§åæ¨¡åçåé¡ã</paragraph>

##### **Slicing Through Bias: Explaining Performance Gaps in Medical Image Analysis using Slice Discovery Methods**
2406.12142v2 by Vincent Olesen, Nina Weng, Aasa Feragen, Eike Petersen

Machine learning models have achieved high overall accuracy in medical image
analysis. However, performance disparities on specific patient groups pose
challenges to their clinical utility, safety, and fairness. This can affect
known patient groups - such as those based on sex, age, or disease subtype - as
well as previously unknown and unlabeled groups. Furthermore, the root cause of
such observed performance disparities is often challenging to uncover,
hindering mitigation efforts. In this paper, to address these issues, we
leverage Slice Discovery Methods (SDMs) to identify interpretable
underperforming subsets of data and formulate hypotheses regarding the cause of
observed performance disparities. We introduce a novel SDM and apply it in a
case study on the classification of pneumothorax and atelectasis from chest
x-rays. Our study demonstrates the effectiveness of SDMs in hypothesis
formulation and yields an explanation of previously observed but unexplained
performance disparities between male and female patients in widely used chest
X-ray datasets and models. Our findings indicate shortcut learning in both
classification tasks, through the presence of chest drains and ECG wires,
respectively. Sex-based differences in the prevalence of these shortcut
features appear to cause the observed classification performance gap,
representing a previously underappreciated interaction between shortcut
learning and model fairness analyses.

æè¦ï¼æ©å¨å­¸ç¿æ¨¡åå¨é«å­¸å½±ååæä¸­å·²éå°æ´é«é«æºç¢ºåº¦ãç¶èï¼ç¹å®æ£èç¾¤é«çæè½å·®ç°å°å¶è¨åºæç¨ãå®å¨æ§èå¬å¹³æ§æ§æææ°ãéå¯è½æå½±é¿å·²ç¥çæ£èç¾¤é«ï¼ä¾å¦åºæ¼æ§å¥ãå¹´é½¡æç¾çäºåï¼ä»¥åååæªç¥ä¸æªæ¨ç±¤çç¾¤é«ãæ­¤å¤ï¼æ­¤é¡è§å¯å°çæè½å·®ç°çæ ¹æ¬åå éå¸¸é£ä»¥ç¼ç¾ï¼é»ç¤äºç·©è§£æªæ½ãå¨æ¬æä¸­ï¼çºäºè§£æ±ºéäºåé¡ï¼æåå©ç¨åçç¼ç¾æ¹æ³ (SDM) ä¾è­å¥å¯è§£éçè³ææè½ä¸ä½³å­éï¼ä¸¦éå°è§å¯å°çæè½å·®ç°åå å¶å®åè¨­ãæåå¼å¥ä¸ç¨®æ°ç SDMï¼ä¸¦å¨è¸é¨ X åçä¸­èºçåèºä¸å¼µåé¡çæ¡ä¾ç ç©¶ä¸­æç¨å®ãæåçç ç©¶è­æäº SDM å¨åè¨­å¶å®ä¸­çæææ§ï¼ä¸¦å°å»£æ³ä½¿ç¨çè¸é¨ X åçè³æéåæ¨¡åä¸­ååè§å¯å°ä½ç¡æ³è§£éçç·æ§åå¥³æ§æ£èä¹éçæè½å·®ç°æä¾äºè§£éãæåçç¼ç¾è¡¨æï¼å¨åé¡ä»»åä¸­ï¼ééè¸èå¼æµç®¡åå¿é»åå°ç·çå­å¨ï¼å­å¨æ·å¾å­¸ç¿ãéäºæ·å¾ç¹å¾µççè¡çå­å¨åºæ¼æ§å¥çå·®ç°ï¼ä¼¼ä¹æå°è´è§å¯å°çåé¡æè½å·®è·ï¼éä»£è¡¨æ·å¾å­¸ç¿åæ¨¡åå¬å¹³æ§åæä¹éååæªåå°éè¦çäº¤äºä½ç¨ã

##### **Unlocking the Potential of Metaverse in Innovative and Immersive Digital Health**
2406.07114v2 by Fatemeh Ebrahimzadeh, Ramin Safa

The concept of Metaverse has attracted a lot of attention in various fields
and one of its important applications is health and treatment. The Metaverse
has enormous potential to transform healthcare by changing patient care,
medical education, and the way teaching/learning and research are done. The
purpose of this research is to provide an introduction to the basic concepts
and fundamental technologies of the Metaverse. This paper examines the pros and
cons of the Metaverse in healthcare context and analyzes its potential from the
technology and AI perspective. In particular, the role of machine learning
methods is discussed; We will explain how machine learning algorithms can be
applied to the Metaverse generated data to gain better insights in healthcare
applications. Additionally, we examine the future visions of the Metaverse in
health delivery, by examining emerging technologies such as blockchain and also
addressing privacy concerns. The findings of this study contribute to a deeper
understanding of the applications of Metaverse in healthcare and its potential
to revolutionize the delivery of medical services.

æè¦ï¼åå®å®çæ¦å¿µå¨ååé åé½ååéæ³¨ï¼å¶éè¦æç¨ä¹ä¸ä¾¿æ¯é«çä¿å¥ãåå®å®æå·¨å¤§çæ½åééæ¹è®çæ£ç§è­·ãé«å­¸æè²ï¼ä»¥åæå­¸/å­¸ç¿åç ç©¶çæ¹å¼ä¾è½åé«çä¿å¥ãæ¬ç ç©¶çç®çæ¯æä¾åå®å®åºæ¬æ¦å¿µååºç¤æè¡çä»ç´¹ãæ¬ææ¢è¨äºåå®å®å¨é«çä¿å¥èæ¯ä¸çåªç¼ºé»ï¼ä¸¦å¾æè¡å AI çè§åº¦åæå¶æ½åãç¹å¥æ¯ï¼è¨è«äºæ©å¨å­¸ç¿æ¹æ³çè§è²ï¼æåå°èªªæå¦ä½å°æ©å¨å­¸ç¿æ¼ç®æ³æç¨æ¼åå®å®ç¢ççè³æï¼ä»¥ç²å¾é«çä¿å¥æç¨æ¹é¢çæ´ä½³è¦è§£ãæ­¤å¤ï¼æåééæ¢è¨åå¡éç­æ°èæè¡ï¼ä¸¦è§£æ±ºé±ç§åé¡ï¼ä¾æ¢è¨åå®å®å¨é«çä¿å¥æ¹é¢çæªä¾é¡æ¯ãæ¬ç ç©¶çç¼ç¾æå©æ¼æ´æ·±å¥å°äºè§£åå®å®å¨é«çä¿å¥ä¸­çæç¨ï¼ä»¥åå¶å¨é«çæåæä¾æ¹é¢ç¼æ®é©å½æ§è®é©çæ½åã

##### **AI-Driven Predictive Analytics Approach for Early Prognosis of Chronic Kidney Disease Using Ensemble Learning and Explainable AI**
2406.06728v1 by K M Tawsik Jawad, Anusha Verma, Fathi Amsaad

Chronic Kidney Disease (CKD) is one of the widespread Chronic diseases with
no known ultimo cure and high morbidity. Research demonstrates that progressive
Chronic Kidney Disease (CKD) is a heterogeneous disorder that significantly
impacts kidney structure and functions, eventually leading to kidney failure.
With the progression of time, chronic kidney disease has moved from a
life-threatening disease affecting few people to a common disorder of varying
severity. The goal of this research is to visualize dominating features,
feature scores, and values exhibited for early prognosis and detection of CKD
using ensemble learning and explainable AI. For that, an AI-driven predictive
analytics approach is proposed to aid clinical practitioners in prescribing
lifestyle modifications for individual patients to reduce the rate of
progression of this disease. Our dataset is collected on body vitals from
individuals with CKD and healthy subjects to develop our proposed AI-driven
solution accurately. In this regard, blood and urine test results are provided,
and ensemble tree-based machine-learning models are applied to predict unseen
cases of CKD. Our research findings are validated after lengthy consultations
with nephrologists. Our experiments and interpretation results are compared
with existing explainable AI applications in various healthcare domains,
including CKD. The comparison shows that our developed AI models, particularly
the Random Forest model, have identified more features as significant
contributors than XgBoost. Interpretability (I), which measures the ratio of
important to masked features, indicates that our XgBoost model achieved a
higher score, specifically a Fidelity of 98\%, in this metric and naturally in
the FII index compared to competing models.

æè¦ï¼æ¢æ§èèçï¼CKDï¼æ¯ä¸ç¨®å»£æ³çæ¢æ§ç¾çï¼æ²æå·²ç¥çæçµçæ³ä¸ç¼ççå¾é«ãç ç©¶è¡¨æï¼é²è¡æ§æ¢æ§èèçï¼CKDï¼æ¯ä¸ç¨®ç°è³ªæ§ç¾çï¼æé¡¯èå½±é¿èèçµæ§ååè½ï¼æçµå°è´èè¡°ç«­ãé¨èæéçæ¨ç§»ï¼æ¢æ§èèçå·²å¾å½±é¿å°æ¸äººçè´å½ç¾çè½è®çºä¸ç¨®å´éç¨åº¦ä¸åçå¸¸è¦ç¾çãæ¬ç ç©¶çç®æ¨æ¯ä½¿ç¨éæå­¸ç¿åå¯è§£éç AI é²è¡æ©æé å¾å CKD æª¢æ¸¬ï¼ä¸¦è¦è¦ºåä¸»å°ç¹å¾µãç¹å¾µåæ¸åè¡¨ç¾åºçå¼ãçºæ­¤ï¼æåºäºä¸ç¨® AI é©åçé æ¸¬åææ¹æ³ï¼ä»¥å¹«å©è¨åºé«ççºåå¥æ£èéå·çæ´»æ¹å¼ä¿®æ¹å»ºè­°ï¼ä»¥éä½éç¨®ç¾ççé²å±éåº¦ãæåçæ¸æéæ¯å¾ CKD æ£èåå¥åº·åè©¦èçèº«é«çå½é«å¾µä¸­æ¶éçï¼ä»¥æºç¢ºéç¼æåæåºç AI é©åçè§£æ±ºæ¹æ¡ãå¨éæ¹é¢ï¼æä¾äºè¡æ¶²åå°¿æ¶²æª¢æ¸¬çµæï¼ä¸¦æç¨åºæ¼éææ¨¹çæ©å¨å­¸ç¿æ¨¡åä¾é æ¸¬æªç¼ç¾ç CKD çä¾ãæåçç ç©¶çµæç¶éèèèç§é«ççé·æè«®è©¢å¾å¾å°é©è­ãæåçå¯¦é©åè§£éçµæèåç¨®é«çä¿å¥é åä¸­ç¾æçå¯è§£é AI æç¨é²è¡äºæ¯è¼ï¼åæ¬ CKDãæ¯è¼è¡¨æï¼æåéç¼ç AI æ¨¡åï¼ç¹å¥æ¯é¨æ©æ£®ææ¨¡åï¼å·²ç¶ç¢ºå®äºæ¯ XgBoost æ´å¤ä½çºéè¦è²¢ç»èçç¹å¾µãå¯è§£éæ§ (I) è¡¡ééè¦ç¹å¾µèæ©èç¹å¾µçæ¯çï¼è¡¨ææåç XgBoost æ¨¡åå¨éåææ¨ä¸­ç²å¾äºæ´é«çåæ¸ï¼ç¹å¥æ¯ 98% çä¿çåº¦ï¼ä¸¦ä¸å¨ FII ææ¸ä¸­èªç¶é«æ¼ç«¶ç­æ¨¡åã

##### **Explainable AI for Mental Disorder Detection via Social Media: A survey and outlook**
2406.05984v1 by Yusif Ibrahimov, Tarique Anwar, Tommy Yuan

Mental health constitutes a complex and pervasive global challenge, affecting
millions of lives and often leading to severe consequences. In this paper, we
conduct a thorough survey to explore the intersection of data science,
artificial intelligence, and mental healthcare, focusing on the recent
developments of mental disorder detection through online social media (OSM). A
significant portion of the population actively engages in OSM platforms,
creating a vast repository of personal data that holds immense potential for
mental health analytics. The paper navigates through traditional diagnostic
methods, state-of-the-art data- and AI-driven research studies, and the
emergence of explainable AI (XAI) models for mental healthcare. We review
state-of-the-art machine learning methods, particularly those based on modern
deep learning, while emphasising the need for explainability in healthcare AI
models. The experimental design section provides insights into prevalent
practices, including available datasets and evaluation approaches. We also
identify key issues and challenges in the field and propose promising future
research directions. As mental health decisions demand transparency,
interpretability, and ethical considerations, this paper contributes to the
ongoing discourse on advancing XAI in mental healthcare through social media.
The comprehensive overview presented here aims to guide researchers,
practitioners, and policymakers in developing the area of mental disorder
detection.

æè¦ï¼å¿çå¥åº·æ§æäºä¸é è¤éä¸æ®éçå¨çææ°ï¼å½±é¿äºæ¸ç¾è¬äººççæ´»ï¼ä¸¦ç¶å¸¸å°è´å´éçå¾æãå¨æ¬æä¸­ï¼æåé²è¡äºä¸é å¾¹åºçèª¿æ¥ï¼ä»¥æ¢ç´¢æ¸æç§å­¸ãäººå·¥æºæ§åå¿çä¿å¥çäº¤éï¼éé»éæ³¨ééç·ä¸ç¤¾äº¤åªé« (OSM) é²è¡å¿çç¾çæª¢æ¸¬çææ°ç¼å±ãå¾å¤§ä¸é¨åäººå£ç©æ¥µåè OSM å¹³å°ï¼åµé äºä¸åé¾å¤§çäººå¡è³æåº«ï¼å°å¿çå¥åº·åæå·æå·¨å¤§çæ½åãæ¬ææ¢è¨äºå³çµ±çè¨ºæ·æ¹æ³ãæåé²çè³æå AI é©åçç ç©¶ï¼ä»¥åå¿çä¿å¥ä¸­å¯è§£é AI (XAI) æ¨¡åçåºç¾ãæååé¡§äºæåé²çæ©å¨å­¸ç¿æ¹æ³ï¼ç¹å¥æ¯é£äºåºæ¼ç¾ä»£æ·±åº¦å­¸ç¿çæ¹æ³ï¼åæå¼·èª¿äºé«çä¿å¥ AI æ¨¡åä¸­å¯è§£éæ§çå¿è¦æ§ãå¯¦é©è¨­è¨é¨åæä¾äºå°æ®éåæ³çè¦è§£ï¼åæ¬å¯ç¨çè³æéåè©ä¼°æ¹æ³ãæåéæ¾åºè©²é åçä¸»è¦åé¡åææ°ï¼ä¸¦æåºäºæå¸æçæªä¾ç ç©¶æ¹åãç±æ¼å¿çå¥åº·æ±ºç­éè¦éæåº¦ãå¯è§£éæ§åéå¾·èéï¼æ¬ææå©æ¼æ¨é²å¿çä¿å¥ä¸­ééç¤¾äº¤åªé«æ¨é² XAI çæçºè¨è«ãéè£¡æåºçå¨é¢æ¦è¿°æ¨å¨å¼å°ç ç©¶äººå¡ãå¾æ¥­äººå¡åæ¿ç­å¶å®èç¼å±å¿çç¾çæª¢æ¸¬é åã

##### **Methodology and Real-World Applications of Dynamic Uncertain Causality Graph for Clinical Diagnosis with Explainability and Invariance**
2406.05746v1 by Zhan Zhang, Qin Zhang, Yang Jiao, Lin Lu, Lin Ma, Aihua Liu, Xiao Liu, Juan Zhao, Yajun Xue, Bing Wei, Mingxia Zhang, Ru Gao, Hong Zhao, Jie Lu, Fan Li, Yang Zhang, Yiming Wang, Lei Zhang, Fengwei Tian, Jie Hu, Xin Gou

AI-aided clinical diagnosis is desired in medical care. Existing deep
learning models lack explainability and mainly focus on image analysis. The
recently developed Dynamic Uncertain Causality Graph (DUCG) approach is
causality-driven, explainable, and invariant across different application
scenarios, without problems of data collection, labeling, fitting, privacy,
bias, generalization, high cost and high energy consumption. Through close
collaboration between clinical experts and DUCG technicians, 46 DUCG models
covering 54 chief complaints were constructed. Over 1,000 diseases can be
diagnosed without triage. Before being applied in real-world, the 46 DUCG
models were retrospectively verified by third-party hospitals. The verified
diagnostic precisions were no less than 95%, in which the diagnostic precision
for every disease including uncommon ones was no less than 80%. After
verifications, the 46 DUCG models were applied in the real-world in China. Over
one million real diagnosis cases have been performed, with only 17 incorrect
diagnoses identified. Due to DUCG's transparency, the mistakes causing the
incorrect diagnoses were found and corrected. The diagnostic abilities of the
clinicians who applied DUCG frequently were improved significantly. Following
the introduction to the earlier presented DUCG methodology, the recommendation
algorithm for potential medical checks is presented and the key idea of DUCG is
extracted.

æè¦ï¼<paragraph>é«çç§è­·ä¸­éè¦ AI è¼å©çè¨åºè¨ºæ·ãç¾æçæ·±åº¦å­¸ç¿æ¨¡åç¼ºä¹å¯è§£éæ§ï¼ä¸¦ä¸ä¸»è¦å°æ³¨æ¼å½±ååæãæè¿éç¼çåæä¸ç¢ºå®å æéä¿å (DUCG) æ¹æ³æ¯å æé©åçãå¯è§£éçï¼ä¸¦ä¸å¨ä¸åçæç¨å ´æ¯ä¸­æ¯ä¸è®çï¼æ²æè³ææ¶éãæ¨è¨ãæ¬åãé±ç§ãåè¦ãæ¦åãé«ææ¬åé«è½èçåé¡ãééè¨åºå°å®¶å DUCG æè¡äººå¡ä¹éçå¯ååä½ï¼æ§å»ºäºæ¶µè 54 åä¸»è¨´ç 46 å DUCG æ¨¡åãå¯ä»¥å¨æ²æåæµçææ³ä¸è¨ºæ·åº 1,000 å¤ç¨®ç¾çãå¨æç¨æ¼å¯¦éä¸çä¹åï¼46 å DUCG æ¨¡åå·²ç±ç¬¬ä¸æ¹é«é¢åæº¯æ§é©è­ãé©è­çè¨ºæ·ç²¾åº¦ä¸ä½æ¼ 95%ï¼å¶ä¸­åæ¬ç½è¦ç¾çå¨å§çæ¯ç¨®ç¾ççè¨ºæ·ç²¾åº¦ä¸ä½æ¼ 80%ãé©è­å¾ï¼46 å DUCG æ¨¡åå·²å¨ä¸­åå¯¦éæç¨ãå·²ç¶å·è¡äºè¶éä¸ç¾è¬åçå¯¦è¨ºæ·æ¡ä¾ï¼åç¼ç¾ 17 åä¸æ­£ç¢ºçè¨ºæ·ãç±æ¼ DUCG çéææ§ï¼ç¼ç¾ä¸¦ç³¾æ­£äºå°è´ä¸æ­£ç¢ºè¨ºæ·çé¯èª¤ãé »ç¹æç¨ DUCG çè¨åºé«ççè¨ºæ·è½åå¾å°äºé¡¯èæé«ãå¨ä»ç´¹äºåé¢æåºç DUCG æ¹æ³è«ä¹å¾ï¼æåºäºæ½å¨å¥åº·æª¢æ¥çæ¨è¦æ¼ç®æ³ï¼ä¸¦æåäº DUCG çééµææ³ã</paragraph>

##### **Advancing Histopathology-Based Breast Cancer Diagnosis: Insights into Multi-Modality and Explainability**
2406.12897v1 by Faseela Abdullakutty, Younes Akbari, Somaya Al-Maadeed, Ahmed Bouridane, Rifat Hamoudi

It is imperative that breast cancer is detected precisely and timely to
improve patient outcomes. Diagnostic methodologies have traditionally relied on
unimodal approaches; however, medical data analytics is integrating diverse
data sources beyond conventional imaging. Using multi-modal techniques,
integrating both image and non-image data, marks a transformative advancement
in breast cancer diagnosis. The purpose of this review is to explore the
burgeoning field of multimodal techniques, particularly the fusion of
histopathology images with non-image data. Further, Explainable AI (XAI) will
be used to elucidate the decision-making processes of complex algorithms,
emphasizing the necessity of explainability in diagnostic processes. This
review utilizes multi-modal data and emphasizes explainability to enhance
diagnostic accuracy, clinician confidence, and patient engagement, ultimately
fostering more personalized treatment strategies for breast cancer, while also
identifying research gaps in multi-modality and explainability, guiding future
studies, and contributing to the strategic direction of the field.

æè¦ï¼ç²¾ç¢ºä¸åæå°åµæ¸¬ä¹³çå°æ¼æ¹åæ£èé å¾è³ééè¦ãè¨ºæ·æ¹æ³å³çµ±ä¸ä¾è³´æ¼å®ä¸æ¨¡å¼æ¹æ³ï¼ç¶èï¼é«çè³æåææ­£å¨æ´åè¶è¶å³çµ±å½±åçåç¨®è³æä¾æºãä½¿ç¨æ´åå½±ååéå½±åè³æçå¤æ¨¡å¼æè¡ï¼æ¨èªèä¹³çè¨ºæ·çè®é©æ§é²å±ãæ¬ç¯ç¶è¿°çç®çæ¯æ¢è¨å¤æ¨¡å¼æè¡çæ°èé åï¼ç¹å¥æ¯å°çµç¹ççå­¸å½±åèéå½±åè³æèåãæ­¤å¤ï¼å¯è§£éäººå·¥æºæ§ (XAI) å°ç¨æ¼é¡æè¤éæ¼ç®æ³çæ±ºç­éç¨ï¼å¼·èª¿è¨ºæ·éç¨ä¸­å¯è§£éæ§çå¿è¦æ§ãæ¬ç¶è¿°å©ç¨å¤æ¨¡å¼è³æä¸¦å¼·èª¿å¯è§£éæ§ï¼ä»¥æé«è¨ºæ·æºç¢ºæ§ãè¨åºé«å¸«çä¿¡å¿åæ£èåèåº¦ï¼æçµä¿é²ä¹³çæ´åäººåçæ²»çç­ç¥ï¼åæä¹æ¾åºå¤æ¨¡å¼åå¯è§£éæ§çç ç©¶å·®è·ï¼å¼å°æªä¾çç ç©¶ï¼ä¸¦çºè©²é åçç­ç¥æ¹åååºè²¢ç»ã

##### **Using Explainable AI for EEG-based Reduced Montage Neonatal Seizure Detection**
2406.16908v3 by Dinuka Sandun Udayantha, Kavindu Weerasinghe, Nima Wickramasinghe, Akila Abeyratne, Kithmin Wickremasinghe, Jithangi Wanigasinghe, Anjula De Silva, Chamira U. S. Edussooriya

The neonatal period is the most vulnerable time for the development of
seizures. Seizures in the immature brain lead to detrimental consequences,
therefore require early diagnosis. The gold-standard for neonatal seizure
detection currently relies on continuous video-EEG monitoring; which involves
recording multi-channel electroencephalogram (EEG) alongside real-time video
monitoring within a neonatal intensive care unit (NICU). However, video-EEG
monitoring technology requires clinical expertise and is often limited to
technologically advanced and resourceful settings. Cost-effective new
techniques could help the medical fraternity make an accurate diagnosis and
advocate treatment without delay. In this work, a novel explainable deep
learning model to automate the neonatal seizure detection process with a
reduced EEG montage is proposed, which employs convolutional nets, graph
attention layers, and fully connected layers. Beyond its ability to detect
seizures in real-time with a reduced montage, this model offers the unique
advantage of real-time interpretability. By evaluating the performance on the
Zenodo dataset with 10-fold cross-validation, the presented model achieves an
absolute improvement of 8.31% and 42.86% in area under curve (AUC) and recall,
respectively.

æè¦ï¼æ°çåææ¯å¤§è¦ç¼è²æèå¼±çææï¼å®¹æåºç¾ç²çç¼ä½ãå¤§è¦ç¼è²ä¸æçæåºç¾ç²çç¼ä½æé æä¸è¯å¾æï¼å æ­¤éè¦åæ©è¨ºæ·ãç®åæ°çåç²çç¼ä½çé»éæ¨æºä¾è³´æ¼é£çºçè¦è¨è¦é»å (EEG) ç£æ¸¬ï¼å¶ä¸­åæ¬å¨æ°çåå è­·çæ¿ (NICU) å§åæé²è¡å¤é »éè¦é»å (EEG) è¨éåå³æè¦è¨ç£æ§ãç¶èï¼è¦è¨è¦é»åç£æ§æè¡éè¦è¨åºå°æ¥­ç¥è­ï¼èä¸éå¸¸åéæ¼æè¡åé²ä¸è³æºè±å¯çç°å¢ãå·ææ¬æççæ°æè¡å¯ä»¥å¹«å©é«ççæºç¢ºè¨ºæ·ä¸¦ç«å³æå¡æ²»çãå¨éé å·¥ä½ä¸­ï¼æåºäºä¸åæ°ç©çå¯è§£éæ·±åº¦å­¸ç¿æ¨¡åï¼ä»¥èªååæ°çåç²çç¼ä½åµæ¸¬éç¨ï¼ä¸¦æ¡ç¨æ¸å°çè¦é»åè£ç½®ï¼å¶ä¸­æ¡ç¨äºå·ç©ç¥ç¶ç¶²è·¯ãåå½¢æ³¨æåå±¤åå¨é£æ¥å±¤ãé¤äºè½å¤ ä½¿ç¨æ¸å°çè£ç½®å³æåµæ¸¬ç²çç¼ä½å¤ï¼æ­¤æ¨¡åéæä¾äºå³æå¯è§£éæ§çç¨ç¹åªå¢ãééå¨ Zenodo è³æéä¸ä½¿ç¨ 10 åäº¤åé©è­è©ä¼°æè½ï¼ææåºçæ¨¡åå¨æ²ç·ä¸é¢ç© (AUC) åå¬åçæ¹é¢åå¥éå°äº 8.31% å 42.86% ççµå°æ¹åã

##### **Breast Cancer Diagnosis: A Comprehensive Exploration of Explainable Artificial Intelligence (XAI) Techniques**
2406.00532v1 by Samita Bai, Sidra Nasir, Rizwan Ahmed Khan, Sheeraz Arif, Alexandre Meyer, Hubert Konik

Breast cancer (BC) stands as one of the most common malignancies affecting
women worldwide, necessitating advancements in diagnostic methodologies for
better clinical outcomes. This article provides a comprehensive exploration of
the application of Explainable Artificial Intelligence (XAI) techniques in the
detection and diagnosis of breast cancer. As Artificial Intelligence (AI)
technologies continue to permeate the healthcare sector, particularly in
oncology, the need for transparent and interpretable models becomes imperative
to enhance clinical decision-making and patient care. This review discusses the
integration of various XAI approaches, such as SHAP, LIME, Grad-CAM, and
others, with machine learning and deep learning models utilized in breast
cancer detection and classification. By investigating the modalities of breast
cancer datasets, including mammograms, ultrasounds and their processing with
AI, the paper highlights how XAI can lead to more accurate diagnoses and
personalized treatment plans. It also examines the challenges in implementing
these techniques and the importance of developing standardized metrics for
evaluating XAI's effectiveness in clinical settings. Through detailed analysis
and discussion, this article aims to highlight the potential of XAI in bridging
the gap between complex AI models and practical healthcare applications,
thereby fostering trust and understanding among medical professionals and
improving patient outcomes.

æè¦ï¼ä¹³ç (BC) æ¯å½±é¿å¨çå¥³æ§æå¸¸è¦çæ¡æ§è«ç¤ä¹ä¸ï¼å æ­¤éè¦é²æ­¥çè¨ºæ·æ¹æ³ï¼ä»¥æ¹åè¨åºçµæãæ¬æå¨é¢æ¢è¨äºå¯è§£éäººå·¥æºæ§ (XAI) æè¡å¨ä¹³çåµæ¸¬åè¨ºæ·ä¸­çæç¨ãé¨èäººå·¥æºæ§ (AI) æè¡æçºæ»²éé«çä¿å¥é åï¼ç¹å¥æ¯å¨è«ç¤å­¸ä¸­ï¼éæä¸å¯è§£éçæ¨¡åéæ±è®å¾å¢å¨å¿è¡ï¼ä»¥å¢å¼·è¨åºæ±ºç­å¶å®åæ£èç§è­·ãæ­¤ç¯è©è«æ¢è¨äºåç¨® XAI æ¹æ³çæ´åï¼ä¾å¦ SHAPãLIMEãGrad-CAM ç­ï¼ä»¥åç¨æ¼ä¹³çåµæ¸¬ååé¡çæ©å¨å­¸ç¿åæ·±åº¦å­¸ç¿æ¨¡åãééæ¢è¨ä¹³çè³æéçæ¨¡å¼ï¼åæ¬ä¹³æ¿æå½±ãè¶é³æ³¢åå¶å¨ AI ä¸­çèçï¼æ¬æéé»èªªæ XAI å¦ä½è½å°è´æ´æºç¢ºçè¨ºæ·ååäººåæ²»çè¨ç«ãå®ä¹æ¢è¨äºå¯¦æ½éäºæè¡çææ°ï¼ä»¥åå¶å®æ¨æºåè©éææ¨ä»¥è©ä¼° XAI å¨è¨åºç°å¢ä¸­çæææ§çéè¦æ§ãééè©³ç´°çåæåè¨è«ï¼æ¬ææ¨å¨å¼·èª¿ XAI å¨ç¸®å°è¤é AI æ¨¡åèå¯¦åé«çä¿å¥æç¨ä¹éå·®è·çæ½åï¼é²èä¿é²é«çå°æ¥­äººå¡ä¹éçä¿¡ä»»èçè§£ï¼ä¸¦æ¹åæ£èççµæã

##### **Unveiling Hidden Factors: Explainable AI for Feature Boosting in Speech Emotion Recognition**
2406.01624v2 by Alaa Nfissi, Wassim Bouachir, Nizar Bouguila, Brian Mishara

Speech emotion recognition (SER) has gained significant attention due to its
several application fields, such as mental health, education, and
human-computer interaction. However, the accuracy of SER systems is hindered by
high-dimensional feature sets that may contain irrelevant and redundant
information. To overcome this challenge, this study proposes an iterative
feature boosting approach for SER that emphasizes feature relevance and
explainability to enhance machine learning model performance. Our approach
involves meticulous feature selection and analysis to build efficient SER
systems. In addressing our main problem through model explainability, we employ
a feature evaluation loop with Shapley values to iteratively refine feature
sets. This process strikes a balance between model performance and
transparency, which enables a comprehensive understanding of the model's
predictions. The proposed approach offers several advantages, including the
identification and removal of irrelevant and redundant features, leading to a
more effective model. Additionally, it promotes explainability, facilitating
comprehension of the model's predictions and the identification of crucial
features for emotion determination. The effectiveness of the proposed method is
validated on the SER benchmarks of the Toronto emotional speech set (TESS),
Berlin Database of Emotional Speech (EMO-DB), Ryerson Audio-Visual Database of
Emotional Speech and Song (RAVDESS), and Surrey Audio-Visual Expressed Emotion
(SAVEE) datasets, outperforming state-of-the-art methods. To the best of our
knowledge, this is the first work to incorporate model explainability into an
SER framework. The source code of this paper is publicly available via this
https://github.com/alaaNfissi/Unveiling-Hidden-Factors-Explainable-AI-for-Feature-Boosting-in-Speech-Emotion-Recognition.

æè¦ï¼èªé³æç·è¾¨è­ (SER) ç±æ¼å¶å¨å¿çå¥åº·ãæè²åäººæ©äºåç­å¤åæç¨é åèååéæ³¨ãç¶èï¼SER ç³»çµ±çæºç¢ºæ§åå°é«ç¶­ç¹å¾µéçé»ç¤ï¼éäºç¹å¾µéå¯è½åå«ä¸ç¸éååé¤çè³è¨ãçºäºåæéåææ°ï¼æ¬ç ç©¶æåºäºä¸ç¨®ç¨æ¼ SER çè¿­ä»£ç¹å¾µæåæ¹æ³ï¼è©²æ¹æ³å¼·èª¿ç¹å¾µç¸éæ§åå¯è§£éæ§ï¼ä»¥å¢å¼·æ©å¨å­¸ç¿æ¨¡åçæè½ãæåçåæ³æ¶åä»ç´°çç¹å¾µé¸æååæï¼ä»¥å»ºç«é«æç SER ç³»çµ±ãçºäºééæ¨¡åå¯è§£éæ§è§£æ±ºæåçæ ¸å¿åé¡ï¼æåæ¡ç¨äºå·æ Shapley å¼çç¹å¾µè©ä¼°è¿´åï¼ä»¥åè¦æ¹åç¹å¾µéãéåéç¨å¨æ¨¡åæè½åéæåº¦ä¹éåå¾å¹³è¡¡ï¼éä½¿å¾æåè½å¤ å¨é¢äºè§£æ¨¡åçé æ¸¬ãææåºçæ¹æ³æä¾äºå¤é åªé»ï¼åæ¬è­å¥åç§»é¤ä¸ç¸éååé¤çç¹å¾µï¼å¾èå»ºç«æ´ææçæ¨¡åãæ­¤å¤ï¼å®ä¿é²äºå¯è§£éæ§ï¼æå©æ¼çè§£æ¨¡åçé æ¸¬ä»¥åè­å¥æç·æ±ºå®çééµç¹å¾µãææåºçæ¹æ³çæææ§å·²å¨å¤å«å¤æç·èªé³é (TESS)ãæææç·èªé³è³æåº« (EMO-DB)ãè³´ç¾æ£®é³è¨è¦è¦ºæç·èªé³åæ­æ²è³æåº« (RAVDESS) åè©éé³è¨è¦è¦ºè¡¨éæç· (SAVEE) è³æéç SER åºæºä¸å¾å°é©è­ï¼å¶æè½åªæ¼ç¾ææ¹æ³ãææåæç¥ï¼éæ¯ç¬¬ä¸åå°æ¨¡åå¯è§£éæ§ç´å¥ SER æ¶æ§çç ç©¶ãæ¬æçåå§ç¢¼å¯ééæ­¤é£çµå¬éåå¾ï¼https://github.com/alaaNfissi/Unveiling-Hidden-Factors-Explainable-AI-for-Feature-Boosting-in-Speech-Emotion-Recognitionã

##### **The Explanation Necessity for Healthcare AI**
2406.00216v1 by Michail Mamalakis, HÃ©loÃ¯se de Vareilles, Graham Murray, Pietro Lio, John Suckling

Explainability is often critical to the acceptable implementation of
artificial intelligence (AI). Nowhere is this more important than healthcare
where decision-making directly impacts patients and trust in AI systems is
essential. This trust is often built on the explanations and interpretations
the AI provides. Despite significant advancements in AI interpretability, there
remains the need for clear guidelines on when and to what extent explanations
are necessary in the medical context. We propose a novel categorization system
with four distinct classes of explanation necessity, guiding the level of
explanation required: patient or sample (local) level, cohort or dataset
(global) level, or both levels. We introduce a mathematical formulation that
distinguishes these categories and offers a practical framework for researchers
to determine the necessity and depth of explanations required in medical AI
applications. Three key factors are considered: the robustness of the
evaluation protocol, the variability of expert observations, and the
representation dimensionality of the application. In this perspective, we
address the question: When does an AI medical application need to be explained,
and at what level of detail?

æè¦ï¼å¯è§£éæ§éå¸¸å¯¹äºäººå·¥æºè½ (AI) çå¯æ¥åå®æ½è³å³éè¦ãå¨å»çä¿å¥é¢åï¼è¿ä¸ç¹å°¤ä¸ºéè¦ï¼å ä¸ºå³ç­ç´æ¥å½±åæ£èï¼å¹¶ä¸å¯¹ AI ç³»ç»çä¿¡ä»»è³å³éè¦ãè¿ç§ä¿¡ä»»éå¸¸å»ºç«å¨ AI æä¾çè§£éåè¯ éä¹ä¸ãå°½ç®¡ AI å¯è§£éæ§åå¾äºéå¤§è¿å±ï¼ä½ä»ç¶éè¦æç¡®çæå¯¼æ¹éï¼è¯´æå¨å»çç¯å¢ä¸­ä½æ¶ä»¥åå¨å¤å¤§ç¨åº¦ä¸éè¦è§£éãæä»¬æåºäºä¸ç§æ°é¢çåç±»ç³»ç»ï¼è¯¥ç³»ç»å·æåç§ä¸åçè§£éå¿è¦æ§ç±»å«ï¼æå¯¼æéçè§£éçº§å«ï¼æ£èææ ·æ¬ï¼å±é¨ï¼çº§å«ãéåææ°æ®éï¼å¨å±ï¼çº§å«ï¼æä¸¤ä¸ªçº§å«ãæä»¬å¼å¥äºä¸ä¸ªæ°å­¦å¬å¼ï¼è¯¥å¬å¼åºåäºè¿äºç±»å«ï¼å¹¶ä¸ºç ç©¶äººåæä¾äºä¸ä¸ªå®ç¨æ¡æ¶ï¼ä»¥ç¡®å®å»ç AI åºç¨ä¸­æéçè§£éçå¿è¦æ§åæ·±åº¦ãèèäºä¸ä¸ªå³é®å ç´ ï¼è¯ä¼°åè®®çç¨³å¥æ§ãä¸å®¶è§å¯çå¯åæ§ä»¥ååºç¨ç¨åºçè¡¨ç¤ºç»´æ°ãä»è¿ä¸ªè§åº¦æ¥çï¼æä»¬è§£å³äºè¿ä¸ªé®é¢ï¼AI å»çåºç¨ä½æ¶éè¦è§£éï¼ä»¥åéè¦è§£éå°ä½ç§ç¨åº¦ï¼

##### **Interdisciplinary Expertise to Advance Equitable Explainable AI**
2406.18563v1 by Chloe R. Bennett, Heather Cole-Lewis, Stephanie Farquhar, Naama Haamel, Boris Babenko, Oran Lang, Mat Fleck, Ilana Traynis, Charles Lau, Ivor Horn, Courtney Lyles

The field of artificial intelligence (AI) is rapidly influencing health and
healthcare, but bias and poor performance persists for populations who face
widespread structural oppression. Previous work has clearly outlined the need
for more rigorous attention to data representativeness and model performance to
advance equity and reduce bias. However, there is an opportunity to also
improve the explainability of AI by leveraging best practices of social
epidemiology and health equity to help us develop hypotheses for associations
found. In this paper, we focus on explainable AI (XAI) and describe a framework
for interdisciplinary expert panel review to discuss and critically assess AI
model explanations from multiple perspectives and identify areas of bias and
directions for future research. We emphasize the importance of the
interdisciplinary expert panel to produce more accurate, equitable
interpretations which are historically and contextually informed.
Interdisciplinary panel discussions can help reduce bias, identify potential
confounders, and identify opportunities for additional research where there are
gaps in the literature. In turn, these insights can suggest opportunities for
AI model improvement.

æè¦ï¼äººå·¥æºæ§ (AI) é åæ­£å¿«éå½±é¿èå¥åº·èé«çä¿å¥ï¼ä½å°æ¼é¢è¨å»£æ³çµæ§æ§å£è¿«çäººç¾¤ä¾èªªï¼åè¦åä¸è¯è¡¨ç¾ä¾ç¶å­å¨ãååçç ç©¶å·²æ¸æ¥èªªæï¼éè¦æ´å´æ ¼å°æ³¨æè³æä»£è¡¨æ§åæ¨¡åæè½ï¼ä»¥ä¿é²å¬å¹³æ§ä¸¦æ¸å°åè¦ãç¶èï¼æåææ©æéééç¨ç¤¾ææµè¡çå­¸åå¥åº·å¬å¹³çæä½³å¯¦åï¼ä¾æ¹å AI çå¯è§£éæ§ï¼ä»¥å¹«å©æåéå°ç¼ç¾çéè¯æ§ï¼ç¼å±åè¨­ãå¨æ¬æä¸­ï¼æåå°æ³¨æ¼å¯è§£é AI (XAI)ï¼ä¸¦æè¿°ä¸åè·¨é åå°å®¶å°çµå¯©æ¥æ¶æ§ï¼ä»¥å¾å¤éè§é»è¨è«åæ¹å¤æ§è©ä¼° AI æ¨¡åçè§£éï¼ä¸¦æ¾åºåè¦é ååæªä¾ç ç©¶çæ¹åãæåå¼·èª¿è·¨é åå°å®¶å°çµå°æ¼ç¢çæ´æºç¢ºãå¬å¹³çè©®éè³ééè¦ï¼èéäºè©®éæ¯æ ¹ææ­·å²åèçµ¡èä¾çãè·¨é åå°çµè¨è«æå©æ¼æ¸å°åè¦ãæ¾åºæ½å¨çæ··æ·å ç´ ï¼ä¸¦å¨æç»ä¸­æç¼ºå£ææ¾åºé¡å¤ç ç©¶çæ©æãåéä¾ï¼éäºè¦è§£å¯ä»¥å»ºè­° AI æ¨¡åæ¹é²çæ©æã

##### **"It depends": Configuring AI to Improve Clinical Usefulness Across Contexts**
2407.11978v1 by Hubert D. ZajÄc, Jorge M. N. Ribeiro, Silvia Ingala, Simona Gentile, Ruth Wanjohi, Samuel N. Gitau, Jonathan F. Carlsen, Michael B. Nielsen, Tariq O. Andersen

Artificial Intelligence (AI) repeatedly match or outperform radiologists in
lab experiments. However, real-world implementations of radiological AI-based
systems are found to provide little to no clinical value. This paper explores
how to design AI for clinical usefulness in different contexts. We conducted 19
design sessions and design interventions with 13 radiologists from 7 clinical
sites in Denmark and Kenya, based on three iterations of a functional AI-based
prototype. Ten sociotechnical dependencies were identified as crucial for the
design of AI in radiology. We conceptualised four technical dimensions that
must be configured to the intended clinical context of use: AI functionality,
AI medical focus, AI decision threshold, and AI Explainability. We present four
design recommendations on how to address dependencies pertaining to the medical
knowledge, clinic type, user expertise level, patient context, and user
situation that condition the configuration of these technical dimensions.

æè¦ï¼äººå·¥æºæ§ï¼AIï¼å¨å¯¦é©å®¤å¯¦é©ä¸­ä¸æ·å°èæ¾å°ç§é«å¸«å¹æµæè¡¨ç¾å¾æ´åºè²ãç¶èï¼ç¼ç¾æ¾å°ç§ AI çºåºç¤ç³»çµ±çå¯¦éå·è¡å¹¾ä¹æ²ææä¾è¨åºå¹å¼ãæ¬ææ¢è¨å¦ä½çº AI è¨­è¨å¨ä¸åæå¢ä¸­è¨åºä¸çæç¨ãæåæ ¹æåè½æ§ AI çºåºç¤ååçä¸æ¬¡è¿­ä»£ï¼å¨ä¸¹éº¥åè¯äºç 7 åè¨åºå ´åè 13 ä½æ¾å°ç§é«å¸«é²è¡äº 19 æ¬¡è¨­è¨æè­°åè¨­è¨ä»å¥ãååç¤¾ææè¡ä¾è³´éä¿è¢«èªçºå°æ¼æ¾å°ç§ä¸­ AI çè¨­è¨è³ééè¦ãæåæ¦å¿µåäºååæè¡é¢åï¼å¿é æ ¹æé æçè¨åºä½¿ç¨æå¢é²è¡è¨­å®ï¼AI åè½ãAI é«çéé»ãAI æ±ºç­éæª»ï¼ä»¥å AI å¯è§£éæ§ãæåæåºåé è¨­è¨å»ºè­°ï¼èªªæå¦ä½èçèé«çç¥è­ãè¨ºæé¡åãä½¿ç¨èå°æ¥­ç¥è­ç­ç´ãæ£èæå¢ï¼ä»¥åå½±é¿éäºæè¡é¢åè¨­å®çä½¿ç¨èæå¢ç¸éçä¾è³´éä¿ã

##### **Improving Health Professionals' Onboarding with AI and XAI for Trustworthy Human-AI Collaborative Decision Making**
2405.16424v1 by Min Hun Lee, Silvana Xin Yi Choo, Shamala D/O Thilarajah

With advanced AI/ML, there has been growing research on explainable AI (XAI)
and studies on how humans interact with AI and XAI for effective human-AI
collaborative decision-making. However, we still have a lack of understanding
of how AI systems and XAI should be first presented to users without technical
backgrounds. In this paper, we present the findings of semi-structured
interviews with health professionals (n=12) and students (n=4) majoring in
medicine and health to study how to improve onboarding with AI and XAI. For the
interviews, we built upon human-AI interaction guidelines to create onboarding
materials of an AI system for stroke rehabilitation assessment and AI
explanations and introduce them to the participants. Our findings reveal that
beyond presenting traditional performance metrics on AI, participants desired
benchmark information, the practical benefits of AI, and interaction trials to
better contextualize AI performance, and refine the objectives and performance
of AI. Based on these findings, we highlight directions for improving
onboarding with AI and XAI and human-AI collaborative decision-making.

æè¦ï¼é¨èåé²ç AI/MLï¼å°å¯è§£é AI (XAI) çç ç©¶ä¸æ·å¢å ï¼ä»¥åéæ¼äººé¡å¦ä½è AI å XAI äºåä»¥é²è¡ææçäººå·¥æºæ§åä½æ±ºç­å¶å®ãç¶èï¼æåä»ç¶ç¼ºä¹å° AI ç³»çµ±å XAI æå¦ä½é¦ååç¾çµ¦æ²ææè¡èæ¯çç¨æ¶çäºè§£ãå¨æ¬æä¸­ï¼æåå±ç¤ºäºèé«çå°æ¥­äººå¡ (n=12) åä¸»ä¿®é«å­¸åå¥åº·çå­¸ç (n=4) é²è¡åçµæ§åè¨ªè«ççµæï¼ä»¥ç ç©¶å¦ä½æ¹å AI å XAI çå¥éãå°æ¼è¨ªè«ï¼æåå»ºç«å¨äººæ©äºåæºåä¹ä¸ï¼çºä¸­é¢¨åº·å¾©è©ä¼°å AI è§£éç AI ç³»çµ±åµå»ºå¥éææï¼ä¸¦å°å®åä»ç´¹çµ¦åèèãæåçç ç©¶çµæè¡¨æï¼é¤äºåç¾å³çµ±ç AI æ§è½ææ¨å¤ï¼åèèéå¸æåºåä¿¡æ¯ãAI çå¯¦éå¥½èä»¥åäº¤äºè©¦é©ï¼ä»¥æ´å¥½å°å° AI æ§è½æå¢åï¼ä¸¦å®å AI çç®æ¨åæ§è½ãæ ¹æéäºç¼ç¾ï¼æåå¼·èª¿äºæ¹é² AI å XAI ä»¥åäººæ©åä½æ±ºç­å¶å®çå¥éæ¹åã

##### **Exploring Nutritional Impact on Alzheimer's Mortality: An Explainable AI Approach**
2405.17502v1 by Ziming Liu, Longjian Liu, Robert E. Heidel, Xiaopeng Zhao

This article uses machine learning (ML) and explainable artificial
intelligence (XAI) techniques to investigate the relationship between
nutritional status and mortality rates associated with Alzheimers disease (AD).
The Third National Health and Nutrition Examination Survey (NHANES III)
database is employed for analysis. The random forest model is selected as the
base model for XAI analysis, and the Shapley Additive Explanations (SHAP)
method is used to assess feature importance. The results highlight significant
nutritional factors such as serum vitamin B12 and glycated hemoglobin. The
study demonstrates the effectiveness of random forests in predicting AD
mortality compared to other diseases. This research provides insights into the
impact of nutrition on AD and contributes to a deeper understanding of disease
progression.

æè¦ï¼æ¬æä½¿ç¨æ©å¨å­¸ç¿ (ML) åå¯è§£éäººå·¥æºæ§ (XAI) æè¡ä¾æ¢è¨çé¤çæ³èé¿è²æµ·é»ç (AD) ç¸éçæ­»äº¡çä¹éçéä¿ãæ¡ç¨ç¬¬ä¸æ¬¡å¨åå¥åº·èçé¤æª¢æ¥èª¿æ¥ (NHANES III) è³æåº«é²è¡åæãé¸æé¨æ©æ£®ææ¨¡åä½çº XAI åæçåºç¤æ¨¡åï¼ä¸¦ä½¿ç¨ Shapley Additive Explanations (SHAP) æ¹æ³ä¾è©ä¼°ç¹å¾µéè¦æ§ãçµæçªé¡¯äºéè¦ççé¤å ç´ ï¼ä¾å¦è¡æ¸ç¶­çç´  B12 åç³åè¡ç´èç½ãè©²ç ç©¶è­æäºé¨æ©æ£®æå¨é æ¸¬ AD æ­»äº¡çæ¹é¢ç¸è¼æ¼å¶ä»ç¾ççæææ§ãæ¬ç ç©¶æä¾äºçé¤å° AD çå½±é¿çè¦è§£ï¼ä¸¦æå©æ¼æ´æ·±å¥å°äºè§£ç¾ççé²å±ã

##### **Explainable AI Enhances Glaucoma Referrals, Yet the Human-AI Team Still Falls Short of the AI Alone**
2407.11974v1 by Catalina Gomez, Ruolin Wang, Katharina Breininger, Corinne Casey, Chris Bradley, Mitchell Pavlak, Alex Pham, Jithin Yohannan, Mathias Unberath

Primary care providers are vital for initial triage and referrals to
specialty care. In glaucoma, asymptomatic and fast progression can lead to
vision loss, necessitating timely referrals to specialists. However, primary
eye care providers may not identify urgent cases, potentially delaying care.
Artificial Intelligence (AI) offering explanations could enhance their referral
decisions. We investigate how various AI explanations help providers
distinguish between patients needing immediate or non-urgent specialist
referrals. We built explainable AI algorithms to predict glaucoma surgery needs
from routine eyecare data as a proxy for identifying high-risk patients. We
incorporated intrinsic and post-hoc explainability and conducted an online
study with optometrists to assess human-AI team performance, measuring referral
accuracy and analyzing interactions with AI, including agreement rates, task
time, and user experience perceptions. AI support enhanced referral accuracy
among 87 participants (59.9%/50.8% with/without AI), though Human-AI teams
underperformed compared to AI alone. Participants believed they included AI
advice more when using the intrinsic model, and perceived it more useful and
promising. Without explanations, deviations from AI recommendations increased.
AI support did not increase workload, confidence, and trust, but reduced
challenges. On a separate test set, our black-box and intrinsic models achieved
an accuracy of 77% and 71%, respectively, in predicting surgical outcomes. We
identify opportunities of human-AI teaming for glaucoma management in primary
eye care, noting that while AI enhances referral accuracy, it also shows a
performance gap compared to AI alone, even with explanations. Human involvement
remains essential in medical decision making, underscoring the need for future
research to optimize collaboration, ensuring positive experiences and safe AI
use.

æè¦ï¼<paragraph>åç´ä¿å¥æä¾èå°æ¼æåçåæµåè½è¨ºå°å°ç§ç§è­·è³ééè¦ãå¨éåç¼çææ³ä¸ï¼ç¡ççä¸å¿«éæ¡åå¯è½å°è´è¦ååªå¤±ï¼å æ­¤éè¦åæè½è¨ºçµ¦å°å®¶ãç¶èï¼åç´ç¼ç§ä¿å¥æä¾èå¯è½ç¡æ³è­å¥ç·æ¥ææ³ï¼å¯è½æå»¶èª¤ç§è­·ãæä¾è§£éçäººå·¥æºæ§ (AI) å¯ä»¥å å¼·ä»åçè½è¨ºæ±ºç­ãæåç ç©¶åç¨® AI è§£éå¦ä½å¹«å©æä¾èååéè¦ç«å³æéç·æ¥å°ç§è½è¨ºçæ£èãæåå»ºç«äºè§£éæ§ AI æ¼ç®æ³ï¼ä»¥å¾ä¾è¡ç¼ç§è­·çè³æé æ¸¬éåç¼æè¡éæ±ï¼ä½çºè­å¥é«é¢¨éªæ£èçä»£çãæåç´å¥äºå§å¨åäºå¾è§£éæ§ï¼ä¸¦èé©åå¸«é²è¡äºä¸é ç·ä¸ç ç©¶ï¼ä»¥è©ä¼°äººæ©åéçè¡¨ç¾ï¼è¡¡éè½è¨ºæºç¢ºåº¦ä¸¦åæè AI çäºåï¼åæ¬åæçãä»»åæéåä½¿ç¨èé«é©æç¥ãå¨ 87 ååèèä¸­ï¼AI æ¯æ´æé«äºè½è¨ºæºç¢ºåº¦ï¼ä½¿ç¨ AI/æªä½¿ç¨çæ¯ä¾çº 59.9%/50.8%ï¼ï¼åç®¡äººæ©åéçè¡¨ç¾ä¸å¦å®ç¨ä½¿ç¨ AIãåèèèªçºä»åå¨ä½¿ç¨å§å¨æ¨¡åææ´å¤å°ç´å¥äº AI å»ºè­°ï¼ä¸¦èªçºå®æ´æç¨ä¸æ´æå¸æãæ²æè§£éï¼AI å»ºè­°çåå·®æå¢å ãAI æ¯æ´ä¸¦æªå¢å å·¥ä½éãä¿¡å¿åä¿¡ä»»ï¼ä½æ¸å°äºææ°ãå¨ä¸åå®ç¨çæ¸¬è©¦éä¸­ï¼æåçé»çå­åå§å¨æ¨¡åå¨é æ¸¬æè¡çµææ¹é¢åå¥éå°äº 77% å 71% çæºç¢ºåº¦ãæåæ¾åºå¨åç´ç¼ç§ä¿å¥ä¸­ï¼äººæ©åéåä½ç®¡çéåç¼çæ©æï¼ä¸¦æ³¨æå°éç¶ AI æé«äºè½è¨ºæºç¢ºåº¦ï¼ä½å³ä½¿æè§£éï¼å®ä¹é¡¯ç¤ºåºèå®ç¨ä½¿ç¨ AI ç¸æ¯çæè½å·®è·ãäººé¡åèå¨é«çæ±ºç­ä¸­ä»ç¶è³ééè¦ï¼éå¼·èª¿äºæªä¾ç ç©¶åªååä½ãç¢ºä¿æ­£é¢ç¶é©åå®å¨ä½¿ç¨ AI çå¿è¦æ§ã</paragraph>

##### **Decoding Decision Reasoning: A Counterfactual-Powered Model for Knowledge Discovery**
2406.18552v1 by Yingying Fang, Zihao Jin, Xiaodan Xing, Simon Walsh, Guang Yang

In medical imaging, particularly in early disease detection and prognosis
tasks, discerning the rationale behind an AI model's predictions is crucial for
evaluating the reliability of its decisions. Conventional explanation methods
face challenges in identifying discernible decisive features in medical image
classifications, where discriminative features are subtle or not immediately
apparent. To bridge this gap, we propose an explainable model that is equipped
with both decision reasoning and feature identification capabilities. Our
approach not only detects influential image patterns but also uncovers the
decisive features that drive the model's final predictions. By implementing our
method, we can efficiently identify and visualise class-specific features
leveraged by the data-driven model, providing insights into the decision-making
processes of deep learning models. We validated our model in the demanding
realm of medical prognosis task, demonstrating its efficacy and potential in
enhancing the reliability of AI in healthcare and in discovering new knowledge
in diseases where prognostic understanding is limited.

æè¦ï¼å¨é«å­¸å½±åä¸­ï¼ç¹å¥æ¯å¨æ©æç¾çæª¢æ¸¬åé å¾ä»»åä¸­ï¼è¾¨å¥ AI æ¨¡åé æ¸¬èå¾çåçå°æ¼è©ä¼°å¶æ±ºç­çå¯é æ§è³ééè¦ãå³çµ±çè§£éæ¹æ³å¨è­å¥é«å­¸å½±ååé¡ä¸­å¯è­å¥çæ±ºå®æ§ç¹å¾µæé¢è¨ææ°ï¼å¶ä¸­åå¥æ§ç¹å¾µå¾å¾®å¦æä¸¦ä¸æé¡¯ãçºäºå½åéä¸å·®è·ï¼æåæåºäºä¸åå¯è§£éçæ¨¡åï¼è©²æ¨¡åå·åæ±ºç­æ¨çåç¹å¾µè­å¥è½åãæåçåæ³ä¸åæª¢æ¸¬æå½±é¿åçå½±åæ¨¡å¼ï¼éæ­ç¤ºäºæ¨åæ¨¡åæçµé æ¸¬çæ±ºå®æ§ç¹å¾µãééå¯¦æ½æåçæ¨¡åï¼æåå¯ä»¥ææè­å¥åè¦è¦ºåç±æ¸æé©åæ¨¡åå©ç¨çé¡ç¹å®ç¹å¾µï¼å¾èæ·±å¥äºè§£æ·±åº¦å­¸ç¿æ¨¡åçæ±ºç­éç¨ãæåå¨è¦æ±å´æ ¼çé«å­¸é å¾ä»»åé åé©è­äºæåçæ¨¡åï¼å±ç¤ºäºå¶å¨æé« AI å¨é«çä¿å¥ä¸­çå¯é æ§åç¼ç¾é å¾çè§£åéç¾ççæ°ç¥è­æ¹é¢çåæåæ½åã

##### **The Role of Emotions in Informational Support Question-Response Pairs in Online Health Communities: A Multimodal Deep Learning Approach**
2405.13099v1 by Mohsen Jozani, Jason A. Williams, Ahmed Aleroud, Sarbottam Bhagat

This study explores the relationship between informational support seeking
questions, responses, and helpfulness ratings in online health communities. We
created a labeled data set of question-response pairs and developed multimodal
machine learning and deep learning models to reliably predict informational
support questions and responses. We employed explainable AI to reveal the
emotions embedded in informational support exchanges, demonstrating the
importance of emotion in providing informational support. This complex
interplay between emotional and informational support has not been previously
researched. The study refines social support theory and lays the groundwork for
the development of user decision aids. Further implications are discussed.

æè¦ï¼æ¬ç ç©¶æ¢è¨ç·ä¸å¥åº·ç¤¾ç¾¤ä¸­å°æ±è³è¨æ¯æçåé¡ãåæï¼ä»¥åæå¹«å©çè©åä¹éçéä¿ãæåå»ºç«äºä¸çµæ¨è¨çåç­éå°è³æéï¼ä¸¦éç¼äºå¤æ¨¡ææ©å¨å­¸ç¿åæ·±åº¦å­¸ç¿æ¨¡åï¼ä»¥å¯é å°é æ¸¬è³è¨æ¯æåé¡ååæãæåæ¡ç¨å¯è§£éç AI ä¾æ­ç¤ºè³è¨æ¯æäº¤æµä¸­èå«çæç·ï¼è­ææç·å¨æä¾è³è¨æ¯æä¸­çéè¦æ§ãéç¨®æç·æ¯æåè³è¨æ¯æä¹éçè¤éäº¤äºä½ç¨ä»¥åä¸¦æªè¢«ç ç©¶éãæ¬ç ç©¶æ¹é²äºç¤¾ææ¯æçè«ï¼ä¸¦çºä½¿ç¨èæ±ºç­è¼å©å·¥å·çéç¼å¥ å®äºåºç¤ãè¨è«äºé²ä¸æ­¥çå½±é¿ã

##### **ChatGPT in Classrooms: Transforming Challenges into Opportunities in Education**
2405.10645v1 by Harris Bin Munawar, Nikolaos Misirlis

In the era of exponential technology growth, one unexpected guest has claimed
a seat in classrooms worldwide, Artificial Intelligence. Generative AI, such as
ChatGPT, promises a revolution in education, yet it arrives with a double-edged
sword. Its potential for personalized learning is offset by issues of cheating,
inaccuracies, and educators struggling to incorporate it effectively into their
lesson design. We are standing on the brink of this educational frontier, and
it is clear that we need to navigate this terrain with a lot of care. This is a
major challenge that could undermine the integrity and value of our educational
process. So, how can we turn these challenges into opportunities? When used
inappropriately, AI tools can become the perfect tool for the cut copy paste
mentality, and quickly begin to corrode critical thinking, creativity, and deep
understanding, the most important skills in our rapidly changing world.
Teachers feel that they are not equipped to leverage this technology, widening
the digital divide among educators and institutions. Addressing these concerns
calls for an in depth research approach. We will employ empirical research,
drawing on the Technology Acceptance Model, to assess the attitudes toward
generative AI among educators and students. Understanding their perceptions,
usage patterns, and hurdles is the first crucial step in creating an effective
solution. The present study will be used as a process manual for future
researchers to apply, running their own data, based on the steps explained here

æè¦ï¼å¨ç§æé£éç¼å±çæä»£ï¼ä¸ä½æå¤çè¨ªå®¢å·²å¨å¨çæå®¤ä¸­ä½æä¸å¸­ä¹å°ï¼é£å°±æ¯äººå·¥æºæ§ãçæå¼ AIï¼ä¾å¦ ChatGPTï¼æ¿è«¾å¨æè²é åæèµ·ä¸å ´é©å½ï¼ä½å®å»æ¯ä¸æéé¢åãå®å¨åäººåå­¸ç¿æ¹é¢çæ½åï¼å»å ä½å¼ãä¸æºç¢ºä»¥åæè²å·¥ä½èé£ä»¥å°å¶ææèå¥æå­¸è¨­è¨ç­åé¡èæµé·ãæåæ­£ç«å¨éæè²åæ²¿çéç·£ï¼é¡¯ç¶æåéè¦éå¸¸å°å¿å°æ¢ç´¢éçé åãéæ¯ä¸åéå¤§çææ°ï¼å¯è½ææå®³æåæè²éç¨çå®æ´æ§åå¹å¼ãé£éº¼ï¼æåå¦ä½å°éäºææ°è½åçºæ©éï¼ç¶ä¸é©ç¶å°ä½¿ç¨æï¼AI å·¥å·å¯è½ææçºè¤è£½è²¼ä¸å¿æçå®ç¾å·¥å·ï¼ä¸¦è¿éèèæ¹å¤æ§æç¶­ãåµé ååæ·±å¥çè§£ï¼éäºé½æ¯æåå¿«éè®åçä¸çä¸­æéè¦çæè½ãæå¸«åè¦ºå¾ä»åæ²æè½åå©ç¨éé æè¡ï¼éæ´å¤§äºæè²å·¥ä½èåæ©æ§ä¹éçæ¸ä½é´»æºãè§£æ±ºéäºåé¡éè¦æ·±å¥çç ç©¶æ¹æ³ãæåå°æ¡ç¨å¯¦è­ç ç©¶ï¼åéæè¡æ¥åæ¨¡åï¼ä¾è©ä¼°æè²å·¥ä½èåå­¸çå°çæå¼ AI çæåº¦ãäºè§£ä»åççæ³ãä½¿ç¨æ¨¡å¼åéç¤æ¯åµé ææè§£æ±ºæ¹æ¡çç¬¬ä¸åééµæ­¥é©ãæ¬ç ç©¶å°ä½çºæªä¾ç ç©¶äººå¡æç¨çæµç¨æåï¼æ ¹ææ­¤èèªªæçæ­¥é©éè¡ä»åèªå·±çæ¸æ

##### **Evaluating the Explainable AI Method Grad-CAM for Breath Classification on Newborn Time Series Data**
2405.07590v1 by Camelia Oprea, Mike GrÃ¼ne, Mateusz Buglowski, Lena Olivier, Thorsten Orlikowsky, Stefan Kowalewski, Mark Schoberer, AndrÃ© Stollenwerk

With the digitalization of health care systems, artificial intelligence
becomes more present in medicine. Especially machine learning shows great
potential for complex tasks such as time series classification, usually at the
cost of transparency and comprehensibility. This leads to a lack of trust by
humans and thus hinders its active usage. Explainable artificial intelligence
tries to close this gap by providing insight into the decision-making process,
the actual usefulness of its different methods is however unclear. This paper
proposes a user study based evaluation of the explanation method Grad-CAM with
application to a neural network for the classification of breaths in time
series neonatal ventilation data. We present the perceived usefulness of the
explainability method by different stakeholders, exposing the difficulty to
achieve actual transparency and the wish for more in-depth explanations by many
of the participants.

æè¦ï¼é¨èé«çä¿å¥ç³»çµ±çæ¸ä½åï¼äººå·¥æºæ§å¨é«å­¸é åä¸­è®å¾æ´å æ®åãç¹å¥æ¯æ©å¨å­¸ç¿å¨æéåºååé¡ç­è¤éä»»åä¸­å±ç¾åºæ¥µå¤§çæ½åï¼ä½éå¸¸æ¯ä»¥éæåº¦åå¯çè§£æ§çºä»£å¹ãéå°è´äººé¡ç¼ºä¹ä¿¡ä»»ï¼å¾èé»ç¤äºå¶ç©æ¥µä½¿ç¨ãå¯è§£éçäººå·¥æºæ§è©¦åééæä¾å°æ±ºç­éç¨çæ´å¯ä¾å½è£éä¸å·®è·ï¼ä½å¶ä¸åæ¹æ³çå¯¦éæç¨å°ä¸æ¸æ¥ãæ¬ææåºäºä¸ååºæ¼ä½¿ç¨èç ç©¶çè©ä¼°ï¼å¶ä¸­åå«äº Grad-CAM è§£éæ¹æ³ï¼ä¸¦å°å¶æç¨æ¼ç¥ç¶ç¶²è·¯ä»¥åé¡æéåºåæ°çåå¼å¸æ¸æä¸­çå¼å¸ãæåå±ç¤ºäºä¸åå©çç¸éèå°å¯è§£éæ§æ¹æ³çæç¥æç¨ï¼æ­ç¤ºäºå¯¦ç¾å¯¦ééæåº¦çé£åº¦ï¼ä»¥åè¨±å¤åèèå¸æç²å¾æ´æ·±å¥çè§£éã

##### **XAI4LLM. Let Machine Learning Models and LLMs Collaborate for Enhanced In-Context Learning in Healthcare**
2405.06270v3 by Fatemeh Nazary, Yashar Deldjoo, Tommaso Di Noia, Eugenio di Sciascio

The integration of Large Language Models (LLMs) into healthcare diagnostics
offers a promising avenue for clinical decision-making. This study outlines the
development of a novel method for zero-shot/few-shot in-context learning (ICL)
by integrating medical domain knowledge using a multi-layered structured
prompt. We also explore the efficacy of two communication styles between the
user and LLMs: the Numerical Conversational (NC) style, which processes data
incrementally, and the Natural Language Single-Turn (NL-ST) style, which
employs long narrative prompts.
  Our study systematically evaluates the diagnostic accuracy and risk factors,
including gender bias and false negative rates, using a dataset of 920 patient
records in various few-shot scenarios. Results indicate that traditional
clinical machine learning (ML) models generally outperform LLMs in zero-shot
and few-shot settings. However, the performance gap narrows significantly when
employing few-shot examples alongside effective explainable AI (XAI) methods as
sources of domain knowledge. Moreover, with sufficient time and an increased
number of examples, the conversational style (NC) nearly matches the
performance of ML models. Most notably, LLMs demonstrate comparable or superior
cost-sensitive accuracy relative to ML models.
  This research confirms that, with appropriate domain knowledge and tailored
communication strategies, LLMs can significantly enhance diagnostic processes.
The findings highlight the importance of optimizing the number of training
examples and communication styles to improve accuracy and reduce biases in LLM
applications.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) èé«çè¨ºæ·æ´å
çºè¨åºæ±ºç­æä¾äºä¸åæåæ¯çéå¾ãæ¬ç ç©¶æ¦è¿°äºä¸ç¨®æ°ç©æ¹æ³çéç¼ï¼ç¨æ¼é¶æ¬¡å­¸ç¿/å°éå­¸ç¿æå¢å­¸ç¿ (ICL)ï¼æ¹æ³æ¯ä½¿ç¨å¤å±¤çµæ§åæç¤ºæ´åé«çé åç¥è­ãæåéæ¢è¨äºä½¿ç¨èè LLM ä¹éå©ç¨®æºéæ¹å¼çåæï¼æ¸å¼å°è©± (NC) æ¹å¼ï¼å®æéæ­¥èçè³æï¼ä»¥åèªç¶èªè¨å®åå (NL-ST) æ¹å¼ï¼å®æä½¿ç¨é·ç¯æäºæç¤ºã
æåçç ç©¶ç³»çµ±æ§å°è©ä¼°äºè¨ºæ·æºç¢ºæ§åé¢¨éªå å­ï¼åæ¬æ§å¥åè¦ååé°æ§çï¼ä½¿ç¨äºä¸ååå« 920 åæ£èè¨éçè³æéï¼æ¡ç¨åç¨®å°éå­¸ç¿æå¢ãçµæè¡¨æï¼å³çµ±çè¨åºæ©å¨å­¸ç¿ (ML) æ¨¡åéå¸¸å¨é¶æ¬¡å­¸ç¿åå°éå­¸ç¿è¨­å®ä¸­è¡¨ç¾åªæ¼ LLMãç¶èï¼ç¶ä½¿ç¨å°éå­¸ç¿ç¯ä¾ä»¥åææçå¯è§£é AI (XAI) æ¹æ³ä½çºé åç¥è­ä¾æºæï¼æè½å·®è·æé¡¯èç¸®å°ãæ­¤å¤ï¼é¨èæéåè¶³åç¯ä¾æ¸éå¢å ï¼å°è©±æ¹å¼ (NC) å¹¾ä¹å¯ä»¥åª²ç¾ ML æ¨¡åçæè½ãæå¼å¾æ³¨æçæ¯ï¼LLM ç¸å°æ¼ ML æ¨¡åå±ç¾åºç¸ç¶ææ´ä½³çææ¬æææºç¢ºåº¦ã
æ¬ç ç©¶è­å¯¦ï¼ééé©ç¶çé åç¥è­åéèº«æé çæºéç­ç¥ï¼LLM å¯ä»¥é¡¯èå¢å¼·è¨ºæ·ç¨åºãéäºç¼ç¾çªé¡¯äºæä½³åè¨ç·´ç¯ä¾æ¸éåæºéæ¹å¼çéè¦æ§ï¼ä»¥æé«æºç¢ºåº¦ä¸¦æ¸å° LLM æç¨ä¸­çåå·®ã

##### **To Trust or Not to Trust: Towards a novel approach to measure trust for XAI systems**
2405.05766v1 by Miquel MirÃ³-Nicolau, Gabriel MoyÃ -Alcover, Antoni Jaume-i-CapÃ³, Manuel GonzÃ¡lez-Hidalgo, Maria Gemma Sempere Campello, Juan Antonio Palmer Sancho

The increasing reliance on Deep Learning models, combined with their inherent
lack of transparency, has spurred the development of a novel field of study
known as eXplainable AI (XAI) methods. These methods seek to enhance the trust
of end-users in automated systems by providing insights into the rationale
behind their decisions. This paper presents a novel approach for measuring user
trust in XAI systems, allowing their refinement. Our proposed metric combines
both performance metrics and trust indicators from an objective perspective. To
validate this novel methodology, we conducted a case study in a realistic
medical scenario: the usage of XAI system for the detection of pneumonia from
x-ray images.

æè¦ï¼é¨èå°æ·±åº¦å­¸ç¿æ¨¡åä¾è³´æ§çå¢å ï¼å ä¸å¶åºæçéæåº¦ä¸è¶³ï¼ä¿ä½¿ä¸åæ°çç ç©¶é åç¼å±ï¼ç¨±çºå¯è§£é AI (XAI) æ¹æ³ãéäºæ¹æ³æ¨å¨ééæ·±å¥äºè§£æ±ºç­èå¾çåçï¼ä¾æåæçµä½¿ç¨èå°èªååç³»çµ±çä¿¡è³´ãæ¬ææåºäºä¸ç¨®è¡¡éä½¿ç¨èå° XAI ç³»çµ±ä¿¡è³´åº¦çæ°ç©æ¹æ³ï¼åè¨±å°å¶é²è¡æ¹é²ãæåæåºçææ¨çµåäºå®¢è§è§é»ä¸çæè½ææ¨åä¿¡è³´ææ¨ãçºäºé©è­éåæ°ç©çæ¹æ³ï¼æåå¨ä¸åçå¯¦çé«çå ´æ¯ä¸­é²è¡äºä¸åæ¡ä¾ç ç©¶ï¼ä½¿ç¨ XAI ç³»çµ±å¾ X åå½±åä¸­åµæ¸¬èºçã

##### **Region-specific Risk Quantification for Interpretable Prognosis of COVID-19**
2405.02815v1 by Zhusi Zhong, Jie Li, Zhuoqi Ma, Scott Collins, Harrison Bai, Paul Zhang, Terrance Healey, Xinbo Gao, Michael K. Atalay, Zhicheng Jiao

The COVID-19 pandemic has strained global public health, necessitating
accurate diagnosis and intervention to control disease spread and reduce
mortality rates. This paper introduces an interpretable deep survival
prediction model designed specifically for improved understanding and trust in
COVID-19 prognosis using chest X-ray (CXR) images. By integrating a large-scale
pretrained image encoder, Risk-specific Grad-CAM, and anatomical region
detection techniques, our approach produces regional interpretable outcomes
that effectively capture essential disease features while focusing on rare but
critical abnormal regions. Our model's predictive results provide enhanced
clarity and transparency through risk area localization, enabling clinicians to
make informed decisions regarding COVID-19 diagnosis with better understanding
of prognostic insights. We evaluate the proposed method on a multi-center
survival dataset and demonstrate its effectiveness via quantitative and
qualitative assessments, achieving superior C-indexes (0.764 and 0.727) and
time-dependent AUCs (0.799 and 0.691). These results suggest that our
explainable deep survival prediction model surpasses traditional survival
analysis methods in risk prediction, improving interpretability for clinical
decision making and enhancing AI system trustworthiness.

æè¦ï¼COVID-19 ç«æå°å¨çå¬å±è¡çé æå£åï¼å¿é é²è¡æºç¢ºçè¨ºæ·åå¹²é ï¼ä»¥æ§å¶ç¾çå³æ­ä¸¦éä½æ­»äº¡çãæ¬æä»ç´¹äºä¸åå¯è§£éçæ·±åº¦çå­é æ¸¬æ¨¡åï¼å°éè¨­è¨ç¨æ¼ééè¸é¨ X å (CXR) å½±åæ¹åå° COVID-19 é å¾ççè§£åä¿¡è³´ãééæ´åå¤§è¦æ¨¡é è¨ç·´å½±åç·¨ç¢¼å¨ãé¢¨éªç¹å® Grad-CAM åè§£ååååµæ¸¬æè¡ï¼æåçåæ³ç¢çååå¯è§£éççµæï¼ææææå¿è¦çç¾çç¹å¾µï¼åæå°æ³¨æ¼ç½è¦ä½ééµçç°å¸¸ååãæåçæ¨¡åé æ¸¬çµæééé¢¨éªååå®ä½æä¾å¢å¼·çæ¸æ°åº¦åéæåº¦ï¼è®è¨åºé«çè½å¤ å¨æ´äºè§£é å¾è¦è§£çææ³ä¸ï¼å°± COVID-19 è¨ºæ·ååºææºçæ±ºç­ãæåå¨å¤ä¸­å¿çå­è³æéä¸è©ä¼°ææåºçæ¹æ³ï¼ä¸¦éééååè³ªåè©ä¼°è­æå¶æææ§ï¼éå°åªç°ç C ææ¸ï¼0.764 å 0.727ï¼åæéç¸é AUCï¼0.799 å 0.691ï¼ãéäºçµæè¡¨æï¼æåå¯è§£éçæ·±åº¦çå­é æ¸¬æ¨¡åå¨é¢¨éªé æ¸¬æ¹é¢è¶è¶å³çµ±ççå­åææ¹æ³ï¼æåè¨åºæ±ºç­çè§£éæ§ï¼ä¸¦å¢å¼· AI ç³»çµ±çä¿¡è³´åº¦ã

##### **Rad4XCNN: a new agnostic method for post-hoc global explanation of CNN-derived features by means of radiomics**
2405.02334v2 by Francesco Prinzi, Carmelo Militello, Calogero Zarcaro, Tommaso Vincenzo Bartolotta, Salvatore Gaglio, Salvatore Vitabile

In recent years, machine learning-based clinical decision support systems
(CDSS) have played a key role in the analysis of several medical conditions.
Despite their promising capabilities, the lack of transparency in AI models
poses significant challenges, particularly in medical contexts where
reliability is a mandatory aspect. However, it appears that explainability is
inversely proportional to accuracy. For this reason, achieving transparency
without compromising predictive accuracy remains a key challenge. This paper
presents a novel method, namely Rad4XCNN, to enhance the predictive power of
CNN-derived features with the inherent interpretability of radiomic features.
Rad4XCNN diverges from conventional methods based on saliency maps, by
associating intelligible meaning to CNN-derived features by means of Radiomics,
offering new perspectives on explanation methods beyond visualization maps.
Using a breast cancer classification task as a case study, we evaluated
Rad4XCNN on ultrasound imaging datasets, including an online dataset and two
in-house datasets for internal and external validation. Some key results are:
i) CNN-derived features guarantee more robust accuracy when compared against
ViT-derived and radiomic features; ii) conventional visualization map methods
for explanation present several pitfalls; iii) Rad4XCNN does not sacrifice
model accuracy for their explainability; iv) Rad4XCNN provides a global
explanation enabling the physician to extract global insights and findings. Our
method can mitigate some concerns related to the explainability-accuracy
trade-off. This study highlighted the importance of proposing new methods for
model explanation without affecting their accuracy.

æè¦ï¼<paragraph>è¿å¹´æ¥ï¼åºäºæºå¨å­¦ä¹ çä¸´åºå³ç­æ¯æç³»ç» (CDSS) å¨å¤ç§ç¾ççåæä¸­æ®æ¼äºå³é®è§è²ãå°½ç®¡å®ä»¬å·æå¹¿éçåæ¯ï¼ä½ AI æ¨¡åç¼ºä¹éæåº¦ï¼å°¤å¶å¨å»çé¢åï¼å¯é æ§æ¯å¼ºå¶æ§æ¹é¢ï¼è¿å¸¦æ¥äºéå¤§ææãç¶èï¼è§£éæ§ä¼¼ä¹ä¸åç¡®æ§æåæ¯ãå æ­¤ï¼å¨ä¸å½±åé¢æµåç¡®æ§çæåµä¸å®ç°éæåº¦ä»ç¶æ¯ä¸ä¸ªå³é®ææãæ¬ææåºäºä¸ç§æ°æ¹æ³ï¼å³ Rad4XCNNï¼ä»¥éè¿æ¾å°ç»å­¦çåå¨å¯è§£éæ§æ¥å¢å¼º CNN è¡çç¹å¾çé¢æµè½åãRad4XCNN éè¿æ¾å°ç»å­¦å°å¯çè§£çå«ä¹ä¸ CNN è¡çç¹å¾å³èèµ·æ¥ï¼ä»èåç¦»äºåºäºæ¾çæ§å¾çä¼ ç»æ¹æ³ï¼ä¸ºè¶è¶å¯è§åå¾çè§£éæ¹æ³æä¾äºæ°çè§è§ãä½¿ç¨ä¹³èºçåç±»ä»»å¡ä½ä¸ºæ¡ä¾ç ç©¶ï¼æä»¬å¨è¶å£°æåæ°æ®éä¸è¯ä¼°äº Rad4XCNNï¼åæ¬ä¸ä¸ªå¨çº¿æ°æ®éåä¸¤ä¸ªç¨äºåé¨åå¤é¨éªè¯çåé¨æ°æ®éãä¸äºå³é®ç»ææ¯ï¼i) ä¸ ViT è¡çåæ¾å°ç»å­¦ç¹å¾ç¸æ¯ï¼CNN è¡çç¹å¾ä¿è¯äºæ´ç¨³å¥çåç¡®æ§ï¼ii) ç¨äºè§£éçä¼ ç»å¯è§åå¾æ¹æ³å­å¨ä¸äºç¼ºé·ï¼iii) Rad4XCNN ä¸ä¼ä¸ºäºå¯è§£éæ§èçºç²æ¨¡ååç¡®æ§ï¼iv) Rad4XCNN æä¾å¨å±è§£éï¼ä½¿å»çè½å¤æåå¨å±è§è§£ååç°ãæä»¬çæ¹æ³å¯ä»¥åè½»ä¸äºä¸å¯è§£éæ§-åç¡®æ§æè¡¡ç¸å³çæå¿§ãæ¬ç ç©¶å¼ºè°äºæåºæ°æ¹æ³æ¥è§£éæ¨¡åèä¸å½±åå¶åç¡®æ§çéè¦æ§ã</paragraph>

##### **Attributing Responsibility in AI-Induced Incidents: A Computational Reflective Equilibrium Framework for Accountability**
2404.16957v1 by Yunfei Ge, Quanyan Zhu

The pervasive integration of Artificial Intelligence (AI) has introduced
complex challenges in the responsibility and accountability in the event of
incidents involving AI-enabled systems. The interconnectivity of these systems,
ethical concerns of AI-induced incidents, coupled with uncertainties in AI
technology and the absence of corresponding regulations, have made traditional
responsibility attribution challenging. To this end, this work proposes a
Computational Reflective Equilibrium (CRE) approach to establish a coherent and
ethically acceptable responsibility attribution framework for all stakeholders.
The computational approach provides a structured analysis that overcomes the
limitations of conceptual approaches in dealing with dynamic and multifaceted
scenarios, showcasing the framework's explainability, coherence, and adaptivity
properties in the responsibility attribution process. We examine the pivotal
role of the initial activation level associated with claims in equilibrium
computation. Using an AI-assisted medical decision-support system as a case
study, we illustrate how different initializations lead to diverse
responsibility distributions. The framework offers valuable insights into
accountability in AI-induced incidents, facilitating the development of a
sustainable and resilient system through continuous monitoring, revision, and
reflection.

æè¦ï¼é¨èäººå·¥æºæ§ (AI) çæ®åæ´åï¼å¨æ¶å AI é©åç³»çµ±çäºæä¸­ï¼è²¬ä»»åç¾©åæ­¸å±¬ç¢çäºè¤éçææ°ãéäºç³»çµ±çäºé£æ§ãAI å¼ç¼äºæçå«çåé¡ï¼å ä¸ AI æè¡çä¸ç¢ºå®æ§åç¼ºä¹ç¸ææ³è¦ï¼ä½¿å¾å³çµ±è²¬ä»»æ­¸å±¬é¢è¨ææ°ãçºæ­¤ï¼æ¬ç ç©¶æåºäºä¸ç¨®è¨ç®åæåè¡¡ (CRE) æ¹æ³ï¼ä»¥å»ºç«ä¸åé£è²«ä¸å¨å«çä¸å¯æ¥åçè²¬ä»»æ­¸å±¬æ¶æ§ï¼é©ç¨æ¼ææå©å®³éä¿äººãè¨ç®æ¹æ³æä¾äºçµæ§åçåæï¼åæäºæ¦å¿µæ¹æ³å¨èçåæä¸å¤é¢åæå¢æçéå¶ï¼å±ç¤ºäºè©²æ¶æ§å¨è²¬ä»»æ­¸å±¬éç¨ä¸­å·åçå¯è§£éæ§ãé£è²«æ§åé©ææ§ãæåæ¢è¨äºèåè¡¡è¨ç®ä¸­ç´¢è³ ç¸éçåå§ååå±¤ç´çééµä½ç¨ãæåä»¥ AI è¼å©é«çæ±ºç­æ¯æ´ç³»çµ±çºæ¡ä¾ç ç©¶ï¼èªªæä¸åçåå§åå¦ä½å°è´ä¸åçè²¬ä»»åéãè©²æ¶æ§æä¾äºå° AI å¼ç¼äºæä¸­åè²¬å¶çå¯¶è²´è¦è§£ï¼ééæçºç£æ§ãä¿®è¨ååæï¼ä¿é²äºæ°¸çºä¸æéæ§çç³»çµ±ç¼å±ã

##### **Explainable AI for Fair Sepsis Mortality Predictive Model**
2404.13139v1 by Chia-Hsuan Chang, Xiaoyang Wang, Christopher C. Yang

Artificial intelligence supports healthcare professionals with predictive
modeling, greatly transforming clinical decision-making. This study addresses
the crucial need for fairness and explainability in AI applications within
healthcare to ensure equitable outcomes across diverse patient demographics. By
focusing on the predictive modeling of sepsis-related mortality, we propose a
method that learns a performance-optimized predictive model and then employs
the transfer learning process to produce a model with better fairness. Our
method also introduces a novel permutation-based feature importance algorithm
aiming at elucidating the contribution of each feature in enhancing fairness on
predictions. Unlike existing explainability methods concentrating on explaining
feature contribution to predictive performance, our proposed method uniquely
bridges the gap in understanding how each feature contributes to fairness. This
advancement is pivotal, given sepsis's significant mortality rate and its role
in one-third of hospital deaths. Our method not only aids in identifying and
mitigating biases within the predictive model but also fosters trust among
healthcare stakeholders by improving the transparency and fairness of model
predictions, thereby contributing to more equitable and trustworthy healthcare
delivery.

æè¦ï¼äººå·¥æºæ§ééé æ¸¬æ¨¡ååå©é«çå°æ¥­äººå¡ï¼å¤§å¹è½è®äºè¨åºæ±ºç­å¶å®ãæ¬ç ç©¶æ¢è¨äºå¨é«çä¿å¥ä¸­ä½¿ç¨äººå·¥æºæ§æç¨ç¨å¼æå¬å¹³æ§åå¯è§£éæ§çééµéæ±ï¼ä»¥ç¢ºä¿å¨ä¸åçæ£èäººå£çµ±è¨è³æä¸­ç²å¾å¬å¹³ççµæãééå°æ³¨æ¼æè¡çç¸éæ­»äº¡ççé æ¸¬æ¨¡åï¼æåæåºäºä¸ç¨®æ¹æ³ï¼è©²æ¹æ³æå­¸ç¿ä¸åæè½æä½³åçé æ¸¬æ¨¡åï¼ç¶å¾æ¡ç¨è½ç§»å­¸ç¿éç¨ä¾ç¢çä¸åå·ææ´å¥½å¬å¹³æ§çæ¨¡åãæåçæ¨¡åéå¼å¥äºä¸ç¨®æ°ç©çåºæ¼æåçç¹å¾µéè¦æ§æ¼ç®æ³ï¼æ¨å¨é¡ææ¯åç¹å¾µå¨å¢å¼·é æ¸¬å¬å¹³æ§æ¹é¢çè²¢ç»ãèç¾æçå¯è§£éæ§æ¹æ³å°æ³¨æ¼è§£éç¹å¾µå°é æ¸¬æè½çè²¢ç»ä¸åï¼æåæåºçæ¹æ³ç¨ç¹å°å½è£äºçè§£æ¯åç¹å¾µå¦ä½æå©æ¼å¬å¹³æ§çå·®è·ãéé é²å±è³ééè¦ï¼å çºæè¡ççæ­»äº¡çå¾é«ï¼ä¸å¨ä¸åä¹ä¸çé«é¢æ­»äº¡ä¸­æ®æ¼èè§è²ãæåçæ¨¡åä¸åæå©æ¼è­å¥åæ¸è¼é æ¸¬æ¨¡åä¸­çåå·®ï¼éè½ééæé«æ¨¡åé æ¸¬çéæåº¦åå¬å¹³æ§ä¾å¹é¤é«çä¿å¥å©çç¸éèä¹éçä¿¡ä»»ï¼é²èæå©æ¼æä¾æ´å¬å¹³ä¸å¼å¾ä¿¡è³´çé«çä¿å¥æåã

##### **Multi Class Depression Detection Through Tweets using Artificial Intelligence**
2404.13104v1 by Muhammad Osama Nusrat, Waseem Shahzad, Saad Ahmed Jamal

Depression is a significant issue nowadays. As per the World Health
Organization (WHO), in 2023, over 280 million individuals are grappling with
depression. This is a huge number; if not taken seriously, these numbers will
increase rapidly. About 4.89 billion individuals are social media users. People
express their feelings and emotions on platforms like Twitter, Facebook,
Reddit, Instagram, etc. These platforms contain valuable information which can
be used for research purposes. Considerable research has been conducted across
various social media platforms. However, certain limitations persist in these
endeavors. Particularly, previous studies were only focused on detecting
depression and the intensity of depression in tweets. Also, there existed
inaccuracies in dataset labeling. In this research work, five types of
depression (Bipolar, major, psychotic, atypical, and postpartum) were predicted
using tweets from the Twitter database based on lexicon labeling. Explainable
AI was used to provide reasoning by highlighting the parts of tweets that
represent type of depression. Bidirectional Encoder Representations from
Transformers (BERT) was used for feature extraction and training. Machine
learning and deep learning methodologies were used to train the model. The BERT
model presented the most promising results, achieving an overall accuracy of
0.96.

æè¦ï¼ç¾ä»ï¼æé¬±çæ¯ä¸åéè¦çè­°é¡ãæ ¹æä¸çè¡ççµç¹ (WHO) çè³æï¼å¨ 2023 å¹´ï¼è¶é 2.8 åäººæ­£å¨èæé¬±çæé¬¥ãéæ¯ä¸åé¾å¤§çæ¸å­ï¼å¦æä¸èªççå¾ï¼éäºæ¸å­å°æå¿«éå¢å ãå¤§ç´æ 48.9 åäººæ¯ç¤¾ç¾¤åªé«ä½¿ç¨èãäººåå¨ TwitterãFacebookãRedditãInstagram ç­å¹³å°ä¸è¡¨éèªå·±çæååæç·ãéäºå¹³å°åå«æå¹å¼çè³è¨ï¼å¯ç¨æ¼ç ç©¶ç®çãå·²ç¶å¨åç¨®ç¤¾ç¾¤åªé«å¹³å°ä¸é²è¡äºå¤§éçç ç©¶ãç¶èï¼éäºåªåä»å­å¨æäºéå¶ãç¹å¥æ¯ï¼ååçç ç©¶åå°æ³¨æ¼åµæ¸¬æ¨æä¸­çæé¬±çåæé¬±ççå¼·åº¦ãæ­¤å¤ï¼è³æéæ¨ç±¤ä¸­å­å¨ä¸æºç¢ºçææ³ãå¨éé ç ç©¶å·¥ä½ä¸­ï¼ä½¿ç¨åºæ¼è©å½æ¨ç±¤ç Twitter è³æåº«ä¸­çæ¨æé æ¸¬äºäºç¨®é¡åçæé¬±çï¼éæ¥µåãéåº¦ãç²¾ç¥çåãéå¸ååç¢å¾ï¼ãå¯è§£éç AI ç¨æ¼ééå¼·èª¿ä»£è¡¨æé¬±çé¡åçæ¨æé¨åä¾æä¾æ¨çãå¾ Transformersï¼BERTï¼ä¸­æåçéåç·¨ç¢¼å¨è¡¨ç¤ºç¨æ¼ç¹å¾µæååè¨ç·´ãæ©å¨å­¸ç¿åæ·±åº¦å­¸ç¿æ¹æ³ç¨æ¼è¨ç·´æ¨¡åãBERT æ¨¡ååç¾åºææå¸æççµæï¼éå° 0.96 çæ´é«æºç¢ºåº¦ã

##### **COIN: Counterfactual inpainting for weakly supervised semantic segmentation for medical images**
2404.12832v2 by Dmytro Shvetsov, Joonas Ariva, Marharyta Domnich, Raul Vicente, Dmytro Fishman

Deep learning is dramatically transforming the field of medical imaging and
radiology, enabling the identification of pathologies in medical images,
including computed tomography (CT) and X-ray scans. However, the performance of
deep learning models, particularly in segmentation tasks, is often limited by
the need for extensive annotated datasets. To address this challenge, the
capabilities of weakly supervised semantic segmentation are explored through
the lens of Explainable AI and the generation of counterfactual explanations.
The scope of this research is development of a novel counterfactual inpainting
approach (COIN) that flips the predicted classification label from abnormal to
normal by using a generative model. For instance, if the classifier deems an
input medical image X as abnormal, indicating the presence of a pathology, the
generative model aims to inpaint the abnormal region, thus reversing the
classifier's original prediction label. The approach enables us to produce
precise segmentations for pathologies without depending on pre-existing
segmentation masks. Crucially, image-level labels are utilized, which are
substantially easier to acquire than creating detailed segmentation masks. The
effectiveness of the method is demonstrated by segmenting synthetic targets and
actual kidney tumors from CT images acquired from Tartu University Hospital in
Estonia. The findings indicate that COIN greatly surpasses established
attribution methods, such as RISE, ScoreCAM, and LayerCAM, as well as an
alternative counterfactual explanation method introduced by Singla et al. This
evidence suggests that COIN is a promising approach for semantic segmentation
of tumors in CT images, and presents a step forward in making deep learning
applications more accessible and effective in healthcare, where annotated data
is scarce.

æè¦ï¼æ·±åº¦å­¦ä¹ æ­£å¤§å¹è½è®é«å­¸å½±ååæ¾å°ç·å­¸é åï¼è½è¾¨è­é«å­¸å½±åä¸­çççï¼åæ¬é»è¦æ·å±¤ææ (CT) å X åææãç¶èï¼æ·±åº¦å­¸ç¿æ¨¡åçæè½ï¼ç¹å¥æ¯å¨åå²ä»»åä¸­ï¼å¸¸å¸¸åå°å»£æ³è¨»è§£è³æééæ±çéå¶ãçºäºæå°æ­¤ææ°ï¼ééå¯è§£é AI ååäºå¯¦è§£éçç¢çï¼æ¢ç´¢å¼±ç£ç£èªæåå²çè½åãæ¬ç ç©¶çç¯åæ¯éç¼ä¸ç¨®æ°çåäºå¯¦å§ææ¹æ³ (COIN)ï¼è©²æ¹æ³ä½¿ç¨çææ¨¡åå°é æ¸¬çåé¡æ¨ç±¤å¾ç°å¸¸ç¿»è½çºæ­£å¸¸ãä¾å¦ï¼å¦æåé¡å¨å°è¼¸å¥çé«å­¸å½±å X è¦çºç°å¸¸ï¼è¡¨ç¤ºå­å¨ççï¼åçææ¨¡åæ¨å¨å§æç°å¸¸ååï¼å¾èéè½åé¡å¨çåå§é æ¸¬æ¨ç±¤ãæ­¤æ¹æ³ä½¿æåè½å¤ ç¢ççççç²¾ç¢ºåå²ï¼èç¡éä¾è³´æ¼é åå­å¨çåå²é®ç½©ãè³ééè¦çæ¯ï¼å©ç¨å½±åå±¤ç´æ¨ç±¤ï¼éæ¯å»ºç«è©³ç´°çåå²é®ç½©å®¹æåå¾ãè©²æ¹æ³çæææ§ééåå²åæç®æ¨åå¾ææ²å°¼äºå¡ç¾åå¤§å­¸é«é¢åå¾ç CT å½±åä¸­çå¯¦éèèè«ç¤ä¾è­æãç ç©¶çµæè¡¨æï¼COIN é é è¶éå·²å»ºç«çæ­¸å æ¹æ³ï¼ä¾å¦ RISEãScoreCAM å LayerCAMï¼ä»¥å Singla ç­äººæåºçå¦ä¸ç¨®åäºå¯¦è§£éæ¹æ³ãæ­¤è­æè¡¨æï¼COIN æ¯ä¸ç¨®å¾æåéç CT å½±åä¸­è«ç¤èªæåå²æ¹æ³ï¼ä¸¦å¨é«çä¿å¥ä¸­è®æ·±åº¦å­¸ç¿æç¨æ´ææ¼åå¾åæ´ææçéé²ä¸æ­¥ï¼å¶ä¸­è¨»è§£è³æå¾ç¨å°ã

##### **Hybrid Intelligence for Digital Humanities**
2406.15374v1 by Victor de Boer, Lise Stork

In this paper, we explore the synergies between Digital Humanities (DH) as a
discipline and Hybrid Intelligence (HI) as a research paradigm. In DH research,
the use of digital methods and specifically that of Artificial Intelligence is
subject to a set of requirements and constraints. We argue that these are
well-supported by the capabilities and goals of HI. Our contribution includes
the identification of five such DH requirements: Successful AI systems need to
be able to 1) collaborate with the (human) scholar; 2) support data criticism;
3) support tool criticism; 4) be aware of and cater to various perspectives and
5) support distant and close reading. We take the CARE principles of Hybrid
Intelligence (collaborative, adaptive, responsible and explainable) as
theoretical framework and map these to the DH requirements. In this mapping, we
include example research projects. We finally address how insights from DH can
be applied to HI and discuss open challenges for the combination of the two
disciplines.

æè¦ï¼å¨æ¬æä¸­ï¼æåæ¢è¨æ¸ä½äººæå­¸ç§ (DH) ä½çºä¸éå­¸ç§èæ··åæºè½ (HI) ä½çºä¸åç ç©¶å¸ç¯ä¹éçååä½ç¨ãå¨ DH ç ç©¶ä¸­ï¼æ¸ä½æ¹æ³çä½¿ç¨ï¼ç¹å¥æ¯äººå·¥æºæ§çä½¿ç¨ï¼åå°ä¸ç³»åè¦æ±åéå¶ãæåèªçºéäºè¦æ±åéå¶ç²å¾ HI çè½ååç®æ¨çååæ¯æãæåçè²¢ç»åæ¬æ¾åºäºåéæ¨£ç DH è¦æ±ï¼æåç AI ç³»çµ±éè¦è½å¤  1) èï¼äººé¡ï¼å­¸èåä½ï¼2) æ¯æ´è³ææ¹è©ï¼3) æ¯æ´å·¥å·æ¹è©ï¼4) å¯è¦ºä¸¦è¿ååç¨®è§é»ï¼5) æ¯æ´é è·åè¿è·é¢é±è®ãæåå°æ··åæºè½ç CARE ååï¼åä½ãé©æãè² è²¬åå¯è§£éï¼ä½çºçè«æ¶æ§ï¼ä¸¦å°éäºååå°æå° DH è¦æ±ãå¨æ­¤å°æä¸­ï¼æåç´å¥ç¯ä¾ç ç©¶å°æ¡ãæå¾ï¼æåæ¢è¨å¦ä½å° DH çè¦è§£æç¨æ¼ HIï¼ä¸¦è¨è«çµåéå©åå­¸ç§çéæ¾ææ°ã

##### **Ethical Framework for Responsible Foundational Models in Medical Imaging**
2406.11868v1 by Abhijit Das, Debesh Jha, Jasmer Sanjotra, Onkar Susladkar, Suramyaa Sarkar, Ashish Rauniyar, Nikhil Tomar, Vanshali Sharma, Ulas Bagci

Foundational models (FMs) have tremendous potential to revolutionize medical
imaging. However, their deployment in real-world clinical settings demands
extensive ethical considerations. This paper aims to highlight the ethical
concerns related to FMs and propose a framework to guide their responsible
development and implementation within medicine. We meticulously examine ethical
issues such as privacy of patient data, bias mitigation, algorithmic
transparency, explainability and accountability. The proposed framework is
designed to prioritize patient welfare, mitigate potential risks, and foster
trust in AI-assisted healthcare.

æè¦ï¼åºç¤æ¨¡å (FM) å·æå¾¹åºæ¹è®é«å­¸å½±åçå·¨å¤§æ½åãç¶èï¼å®åå¨ç¾å¯¦ä¸çè¨åºç°å¢ä¸­çé¨ç½²éè¦å»£æ³çå«çèéãæ¬ææ¨å¨å¼·èª¿è FM ç¸éçå«çåé¡ï¼ä¸¦æåºä¸åæ¡æ¶ä¾æå°å®åå¨é«å­¸ä¸­çè² è²¬ä»»éç¼åå¯¦æ½ãæåä»ç´°å¯©æ¥äºå«çåé¡ï¼ä¾å¦æ£èæ¸æé±ç§ãåå·®ç·©è§£ãæ¼ç®æ³éæåº¦ãå¯è§£éæ§ååè²¬å¶ãææåºçæ¡æ¶æ¨å¨åªåèæ®æ£èç¦å©ãæ¸è¼æ½å¨é¢¨éªï¼ä¸¦å¹é¤å° AI è¼å©é«çä¿å¥çä¿¡ä»»ã

##### **Advancements in Radiomics and Artificial Intelligence for Thyroid Cancer Diagnosis**
2404.07239v1 by Milad Yousefi, Shadi Farabi Maleki, Ali Jafarizadeh, Mahya Ahmadpour Youshanlui, Aida Jafari, Siamak Pedrammehr, Roohallah Alizadehsani, Ryszard Tadeusiewicz, Pawel Plawiak

Thyroid cancer is an increasing global health concern that requires advanced
diagnostic methods. The application of AI and radiomics to thyroid cancer
diagnosis is examined in this review. A review of multiple databases was
conducted in compliance with PRISMA guidelines until October 2023. A
combination of keywords led to the discovery of an English academic publication
on thyroid cancer and related subjects. 267 papers were returned from the
original search after 109 duplicates were removed. Relevant studies were
selected according to predetermined criteria after 124 articles were eliminated
based on an examination of their abstract and title. After the comprehensive
analysis, an additional six studies were excluded. Among the 28 included
studies, radiomics analysis, which incorporates ultrasound (US) images,
demonstrated its effectiveness in diagnosing thyroid cancer. Various results
were noted, some of the studies presenting new strategies that outperformed the
status quo. The literature has emphasized various challenges faced by AI
models, including interpretability issues, dataset constraints, and operator
dependence. The synthesized findings of the 28 included studies mentioned the
need for standardization efforts and prospective multicenter studies to address
these concerns. Furthermore, approaches to overcome these obstacles were
identified, such as advances in explainable AI technology and personalized
medicine techniques. The review focuses on how AI and radiomics could transform
the diagnosis and treatment of thyroid cancer. Despite challenges, future
research on multidisciplinary cooperation, clinical applicability validation,
and algorithm improvement holds the potential to improve patient outcomes and
diagnostic precision in the treatment of thyroid cancer.

æè¦ï¼ç²çèºçæ¯ä¸ç¨®æ¥çå´éçå¨çå¥åº·åé¡ï¼éè¦åé²çè¨ºæ·æ¹æ³ãæ¬ç¯è©è«æ¢è¨äºäººå·¥æºè½èæ¾å°ç¹å¾µåæå¨ç²çèºçè¨ºæ·ä¸­çæç¨ãå¨ç¬¦å PRISMA æåçææ³ä¸ï¼å°å¤åè³æåº«é²è¡äºåé¡§ï¼ç´å° 2023 å¹´ 10 æãééçµåééµå­ï¼ç¼ç¾äºä¸ç¯éæ¼ç²çèºçåç¸éä¸»é¡çè±æå­¸è¡åºçç©ãå¨ç§»é¤ 109 ç¯éè¤æç»å¾ï¼åå§æå°å±åå³ 267 ç¯è«æãå¨æ ¹æé åç¢ºå®çæ¨æºï¼æ·æ±°äº 124 ç¯æç« çæè¦åæ¨é¡å¾ï¼é¸åºäºç¸éç ç©¶ãå¨é²è¡å¨é¢åæå¾ï¼é¡å¤æé¤äºå­é ç ç©¶ãå¨ç´å¥ç 28 é ç ç©¶ä¸­ï¼çµåè¶é³æ³¢ (US) å½±åçæ¾å°ç¹å¾µåæï¼è­æäºå¶å¨è¨ºæ·ç²çèºçæ¹é¢çæææ§ãç ç©¶çµæä¸ä¸ï¼æäºç ç©¶æåºäºåªæ¼ç¾ççæ°ç­ç¥ãæç»å¼·èª¿äºäººå·¥æºè½æ¨¡åé¢è¨çåç¨®ææ°ï¼åæ¬å¯è§£éæ§åé¡ãè³æééå¶åæä½å¡ä¾è³´æ§ã28 é ç´å¥ç ç©¶çç¶åç¼ç¾æå°ï¼éè¦æ¨æºåå·¥ä½ååç»æ§å¤ä¸­å¿ç ç©¶ä¾è§£æ±ºéäºåé¡ãæ­¤å¤ï¼éç¢ºå®äºåæéäºéç¤çæ¹æ³ï¼ä¾å¦å¯è§£éäººå·¥æºè½æè¡ååäººåé«çæè¡çé²æ­¥ãæ¬ç¯è©è«éé»æ¢è¨äºäººå·¥æºè½åæ¾å°ç¹å¾µåæå¦ä½è½è®ç²çèºççè¨ºæ·åæ²»çãåç®¡å­å¨ææ°ï¼ä½æªä¾å°å¤å­¸ç§åä½ãè¨åºé©ç¨æ§é©è­åæ¼ç®æ³æ¹é²çç ç©¶ï¼ä»ææ½åæ¹åç²çèºçæ²»çä¸­çæ£èé å¾åè¨ºæ·ç²¾æºåº¦ã

##### **Predictive Modeling for Breast Cancer Classification in the Context of Bangladeshi Patients: A Supervised Machine Learning Approach with Explainable AI**
2404.04686v1 by Taminul Islam, Md. Alif Sheakh, Mst. Sazia Tahosin, Most. Hasna Hena, Shopnil Akash, Yousef A. Bin Jardan, Gezahign Fentahun Wondmie, Hiba-Allah Nafidi, Mohammed Bourhia

Breast cancer has rapidly increased in prevalence in recent years, making it
one of the leading causes of mortality worldwide. Among all cancers, it is by
far the most common. Diagnosing this illness manually requires significant time
and expertise. Since detecting breast cancer is a time-consuming process,
preventing its further spread can be aided by creating machine-based forecasts.
Machine learning and Explainable AI are crucial in classification as they not
only provide accurate predictions but also offer insights into how the model
arrives at its decisions, aiding in the understanding and trustworthiness of
the classification results. In this study, we evaluate and compare the
classification accuracy, precision, recall, and F-1 scores of five different
machine learning methods using a primary dataset (500 patients from Dhaka
Medical College Hospital). Five different supervised machine learning
techniques, including decision tree, random forest, logistic regression, naive
bayes, and XGBoost, have been used to achieve optimal results on our dataset.
Additionally, this study applied SHAP analysis to the XGBoost model to
interpret the model's predictions and understand the impact of each feature on
the model's output. We compared the accuracy with which several algorithms
classified the data, as well as contrasted with other literature in this field.
After final evaluation, this study found that XGBoost achieved the best model
accuracy, which is 97%.

æè¦ï¼<paragraph>è¿å¹´ä¾ï¼ä¹³çççè¡çè¿éå¢å ï¼ä½¿å¶æçºå¨çä¸»è¦çæ­»äº¡åå ä¹ä¸ãå¨ææççä¸­ï¼ä¹³çè¿ä»çºæ­¢æ¯æå¸¸è¦çãæåè¨ºæ·æ­¤ç¾çéè¦å¤§éçæéåå°æ¥­ç¥è­ãç±æ¼ä¹³ççæª¢æ¸¬éç¨èæï¼å æ­¤ééå»ºç«æ©å¨å­¸ç¿æ¨¡åä¾é æ¸¬ï¼æå©æ¼é²æ­¢å¶é²ä¸æ­¥æ´æ£ãæ©å¨å­¸ç¿åå¯è§£é AI å¨åé¡ä¸­è³ééè¦ï¼å çºå®åä¸åå¯ä»¥æä¾æºç¢ºçé æ¸¬ï¼éå¯ä»¥æ·±å¥äºè§£æ¨¡åå¦ä½ååºæ±ºç­ï¼æå©æ¼çè§£åä¿¡è³´åé¡çµæãå¨æ­¤ç ç©¶ä¸­ï¼æåè©ä¼°ä¸¦æ¯è¼äºäºç¨®ä¸åçæ©å¨å­¸ç¿æ¹æ³çåé¡æºç¢ºåº¦ãç²¾ç¢ºåº¦ãå¬åçå F1 åæ¸ï¼ä½¿ç¨äºä¸åä¸»è¦çè³æéï¼éå¡é«å­¸é¢é«é¢ç 500 åæ£èï¼ãäºç¨®ä¸åçç£ç£å¼æ©å¨å­¸ç¿æè¡ï¼åæ¬æ±ºç­æ¨¹ãé¨æ©æ£®æãéè¼¯è¿´æ­¸ãæ´ç´ è²æ°å XGBoostï¼å·²ç¨æ¼å¨æåçè³æéä¸åå¾æä½³çµæãæ­¤å¤ï¼æ¬ç ç©¶å° SHAP åææç¨æ¼ XGBoost æ¨¡åï¼ä»¥è§£éæ¨¡åçé æ¸¬ä¸¦äºè§£æ¯åç¹å¾µå°æ¨¡åè¼¸åºçå½±é¿ãæåæ¯è¼äºå¹¾ç¨®æ¼ç®æ³å°è³æé²è¡åé¡çæºç¢ºåº¦ï¼ä¸¦èè©²é åçå¶ä»æç»é²è¡å°æ¯ãå¨æå¾è©ä¼°å¾ï¼æ¬ç ç©¶ç¼ç¾ XGBoost éå°äºæä½³çæ¨¡åæºç¢ºåº¦ï¼çº 97%ã</paragraph>

##### **Enhancing Breast Cancer Diagnosis in Mammography: Evaluation and Integration of Convolutional Neural Networks and Explainable AI**
2404.03892v3 by Maryam Ahmed, Tooba Bibi, Rizwan Ahmed Khan, Sidra Nasir

The Deep learning (DL) models for diagnosing breast cancer from mammographic
images often operate as "black boxes", making it difficult for healthcare
professionals to trust and understand their decision-making processes. The
study presents an integrated framework combining Convolutional Neural Networks
(CNNs) and Explainable Artificial Intelligence (XAI) for the enhanced diagnosis
of breast cancer using the CBIS-DDSM dataset. The methodology encompasses an
elaborate data preprocessing pipeline and advanced data augmentation techniques
to counteract dataset limitations and transfer learning using pre-trained
networks such as VGG-16, Inception-V3 and ResNet was employed. A focal point of
our study is the evaluation of XAI's effectiveness in interpreting model
predictions, highlighted by utilizing the Hausdorff measure to assess the
alignment between AI-generated explanations and expert annotations
quantitatively. This approach is critical for XAI in promoting trustworthiness
and ethical fairness in AI-assisted diagnostics. The findings from our research
illustrate the effective collaboration between CNNs and XAI in advancing
diagnostic methods for breast cancer, thereby facilitating a more seamless
integration of advanced AI technologies within clinical settings. By enhancing
the interpretability of AI driven decisions, this work lays the groundwork for
improved collaboration between AI systems and medical practitioners, ultimately
enriching patient care. Furthermore, the implications of our research extended
well beyond the current methodologies. It encourages further research into how
to combine multimodal data and improve AI explanations to meet the needs of
clinical practice.

æè¦ï¼æ·±åº¦å­¸ç¿ (DL) ç¨æ¼å¾ä¹³æ¿æå½±è¡å½±åè¨ºæ·ä¹³ççæ¨¡åéå¸¸ä»¥ãé»çå­ãæ¹å¼éä½ï¼éä½¿å¾é«çä¿å¥å°æ¥­äººå¡é£ä»¥ä¿¡ä»»åçè§£å¶æ±ºç­éç¨ãæ¬ç ç©¶æåºä¸åæ´åæ¶æ§ï¼çµåå·ç©ç¥ç¶ç¶²è·¯ (CNN) åå¯è§£éäººå·¥æºæ§ (XAI)ï¼ä»¥ä½¿ç¨ CBIS-DDSM è³æéå¢å¼·ä¹³ççè¨ºæ·ãæ¹æ³åå«ä¸åç²¾ç´°çè³æåèçç®¡ç·åé²éè³ææ´åæè¡ï¼ä»¥å°æè³æééå¶ï¼ä¸¦æ¡ç¨é åè¨ç·´çç¶²è·¯ï¼ä¾å¦ VGG-16ãInception-V3 å ResNetï¼é²è¡é·ç§»å­¸ç¿ãæåç ç©¶çéé»æ¯è©ä¼° XAI å¨è§£éæ¨¡åé æ¸¬ä¸­çæææ§ï¼éé»å©ç¨è±ªæ¯å¤å¤«æ¸¬åº¦éåè©ä¼° AI çæçè§£éåå°å®¶è¨»è§£ä¹éçä¸è´æ§ãéç¨®æ¹æ³å°æ¼ XAI å¨ä¿é² AI è¼å©è¨ºæ·ä¸­çå¯ä¿¡åº¦åå«çå¬å¹³æ§è³ééè¦ãæåç ç©¶çç¼ç¾èªªæäº CNN å XAI å¨æ¨é²ä¹³çè¨ºæ·æ¹æ³ä¸­çææåä½ï¼å¾èä¿é²äºåé² AI æè¡å¨è¨åºç°å¢ä¸­çæ´é æ¢æ´åãééå¢å¼· AI é©åæ±ºç­çå¯è§£éæ§ï¼éé å·¥ä½çº AI ç³»çµ±åé«çå¾æ¥­äººå¡ä¹éçæ¹ååä½å¥ å®äºåºç¤ï¼æçµè±å¯äºæ£èç§è­·ãæ­¤å¤ï¼æåç ç©¶çå½±é¿é é è¶åºäºç®åçæè¡ãå®é¼åµé²ä¸æ­¥ç ç©¶å¦ä½çµåå¤æ¨¡å¼è³æä¸¦æ¹å AI è§£éï¼ä»¥æ»¿è¶³è¨åºå¯¦åçéæ±ã

##### **Advancing Multimodal Data Fusion in Pain Recognition: A Strategy Leveraging Statistical Correlation and Human-Centered Perspectives**
2404.00320v2 by Xingrui Gu, Zhixuan Wang, Irisa Jin, Zekun Wu

This research presents a novel multimodal data fusion methodology for pain
behavior recognition, integrating statistical correlation analysis with
human-centered insights. Our approach introduces two key innovations: 1)
integrating data-driven statistical relevance weights into the fusion strategy
to effectively utilize complementary information from heterogeneous modalities,
and 2) incorporating human-centric movement characteristics into multimodal
representation learning for detailed modeling of pain behaviors. Validated
across various deep learning architectures, our method demonstrates superior
performance and broad applicability. We propose a customizable framework that
aligns each modality with a suitable classifier based on statistical
significance, advancing personalized and effective multimodal fusion.
Furthermore, our methodology provides explainable analysis of multimodal data,
contributing to interpretable and explainable AI in healthcare. By highlighting
the importance of data diversity and modality-specific representations, we
enhance traditional fusion techniques and set new standards for recognizing
complex pain behaviors. Our findings have significant implications for
promoting patient-centered healthcare interventions and supporting explainable
clinical decision-making.

æè¦ï¼æ¬ç ç©¶æåºäºä¸ç¨®åµæ°çå¤æ¨¡ææ¸æèåæ¹æ³ï¼ç¨æ¼ç¼çè¡çºè­å¥ï¼å°çµ±è¨ç¸éåæèä»¥äººçºä¸­å¿çè¦è§£ç¸çµåãæåçåæ³å¼å¥äºå©é ééµåµæ°ï¼1) å°æ¸æé©åççµ±è¨ç¸éæ¬éæ´åå°èåç­ç¥ä¸­ï¼ä»¥ææå©ç¨ä¾èªç°è³ªæ¨¡æçè£åä¿¡æ¯ï¼ä»¥å 2) å°ä»¥äººçºä¸­å¿çéåç¹å¾µç´å¥å¤æ¨¡æè¡¨ç¤ºå­¸ç¿ä¸­ï¼ä»¥è©³ç´°å»ºæ¨¡ç¼çè¡çºãæåçæ¨¡åå¨åç¨®æ·±åº¦å­¸ç¿æ¶æ§ä¸­å¾å°é©è­ï¼å±ç¤ºäºåè¶çæ§è½åå»£æ³çé©ç¨æ§ãæåæåºäºä¸åå¯èªå®ç¾©çæ¡æ¶ï¼æ ¹æçµ±è¨é¡¯èæ§å°æ¯åæ¨¡æèåé©çåé¡å¨å°é½ï¼æ¨é²åæ§ååææçå¤æ¨¡æèåãæ­¤å¤ï¼æåçæ¨¡åæä¾å°å¤æ¨¡ææ¸æçå¯è§£éåæï¼æå©æ¼é«çä¿å¥ä¸­çå¯è§£éåå¯è§£é AIãééå¼·èª¿æ¸æå¤æ¨£æ§åæ¨¡æç¹å®è¡¨ç¤ºçéè¦æ§ï¼æåå¢å¼·äºå³çµ±çèåæè¡ï¼ä¸¦çºè­å¥è¤éçç¼çè¡çºè¨­å®äºæ°çæ¨æºãæåçç¼ç¾å°ä¿é²ä»¥æ£èçºä¸­å¿çé«çä¿å¥å¹²é åæ¯æå¯è§£éçè¨åºæ±ºç­å¶å®å·æéè¦æç¾©ã

##### **Addressing Social Misattributions of Large Language Models: An HCXAI-based Approach**
2403.17873v1 by Andrea Ferrario, Alberto Termine, Alessandro Facchini

Human-centered explainable AI (HCXAI) advocates for the integration of social
aspects into AI explanations. Central to the HCXAI discourse is the Social
Transparency (ST) framework, which aims to make the socio-organizational
context of AI systems accessible to their users. In this work, we suggest
extending the ST framework to address the risks of social misattributions in
Large Language Models (LLMs), particularly in sensitive areas like mental
health. In fact LLMs, which are remarkably capable of simulating roles and
personas, may lead to mismatches between designers' intentions and users'
perceptions of social attributes, risking to promote emotional manipulation and
dangerous behaviors, cases of epistemic injustice, and unwarranted trust. To
address these issues, we propose enhancing the ST framework with a fifth
'W-question' to clarify the specific social attributions assigned to LLMs by
its designers and users. This addition aims to bridge the gap between LLM
capabilities and user perceptions, promoting the ethically responsible
development and use of LLM-based technology.

æè¦ï¼ä»¥äººä¸ºæ¬çå¯è§£é AI (HCXAI) å¡å¯¼å°ç¤¾ä¼å±é¢æ´åå° AI è§£éä¸­ãHCXAI è¯è¯­çæ ¸å¿æ¯ç¤¾ä¼éæåº¦ (ST) æ¡æ¶ï¼å¶ç®æ æ¯è®© AI ç³»ç»çç¤¾ä¼ç»ç»èæ¯å¯¹ç¨æ·æ¥è¯´æ¯å¯çè§£çãå¨è¿é¡¹å·¥ä½ä¸­ï¼æä»¬å»ºè®®æ©å± ST æ¡æ¶ä»¥è§£å³å¤§åè¯­è¨æ¨¡å (LLM) ä¸­ç¤¾ä¼éè¯¯å½å çé£é©ï¼å°¤å¶æ¯å¨å¿çå¥åº·ç­ææé¢åãäºå®ä¸ï¼LLM è½å¤åºè²å°æ¨¡æè§è²åäººæ ¼ï¼è¿å¯è½å¯¼è´è®¾è®¡èçæå¾åç¨æ·å¯¹ç¤¾ä¼å±æ§çè®¤ç¥ä¹é´åºç°ééï¼ä»èæé£é©ä¿è¿æç»ªæçºµåå±é©è¡ä¸ºãè®¤ç¥ä¸å¬æ­£åä¸åççä¿¡ä»»ãä¸ºäºè§£å³è¿äºé®é¢ï¼æä»¬å»ºè®®ç¨ç¬¬äºä¸ªâW é®é¢âæ¥å¢å¼º ST æ¡æ¶ï¼ä»¥æç¡®è®¾è®¡èåç¨æ·èµäº LLM çå·ä½ç¤¾ä¼å±æ§ãæ­¤è¡¥åæ¨å¨å¼¥å LLM è½ååç¨æ·è®¤ç¥ä¹é´çå·®è·ï¼ä¿è¿åºäº LLM çææ¯å¨éå¾·ä¸è´è´£ä»»å°å¼ååä½¿ç¨ã

##### **Clinical Domain Knowledge-Derived Template Improves Post Hoc AI Explanations in Pneumothorax Classification**
2403.18871v1 by Han Yuan, Chuan Hong, Pengtao Jiang, Gangming Zhao, Nguyen Tuan Anh Tran, Xinxing Xu, Yet Yen Yan, Nan Liu

Background: Pneumothorax is an acute thoracic disease caused by abnormal air
collection between the lungs and chest wall. To address the opaqueness often
associated with deep learning (DL) models, explainable artificial intelligence
(XAI) methods have been introduced to outline regions related to pneumothorax
diagnoses made by DL models. However, these explanations sometimes diverge from
actual lesion areas, highlighting the need for further improvement. Method: We
propose a template-guided approach to incorporate the clinical knowledge of
pneumothorax into model explanations generated by XAI methods, thereby
enhancing the quality of these explanations. Utilizing one lesion delineation
created by radiologists, our approach first generates a template that
represents potential areas of pneumothorax occurrence. This template is then
superimposed on model explanations to filter out extraneous explanations that
fall outside the template's boundaries. To validate its efficacy, we carried
out a comparative analysis of three XAI methods with and without our template
guidance when explaining two DL models in two real-world datasets. Results: The
proposed approach consistently improved baseline XAI methods across twelve
benchmark scenarios built on three XAI methods, two DL models, and two
datasets. The average incremental percentages, calculated by the performance
improvements over the baseline performance, were 97.8% in Intersection over
Union (IoU) and 94.1% in Dice Similarity Coefficient (DSC) when comparing model
explanations and ground-truth lesion areas. Conclusions: In the context of
pneumothorax diagnoses, we proposed a template-guided approach for improving AI
explanations. We anticipate that our template guidance will forge a fresh
approach to elucidating AI models by integrating clinical domain expertise.

æè¦ï¼<paragraph>èæ¯ï¼æ°£è¸æ¯ä¸ç¨®å èºé¨èè¸å£ä¹éç°å¸¸éæ°£æå¼èµ·çæ¥æ§è¸èç¾çãçºäºè§£æ±ºæ·±åº¦å­¸ç¿ï¼DLï¼æ¨¡åç¶å¸¸ä¼´é¨çä¸éææ§ï¼å¯è§£éäººå·¥æºæ§ï¼XAIï¼æ¹æ³å·²è¢«å¼å¥ï¼ç¨æ¼æ¦è¿°è DL æ¨¡åååºçæ°£è¸è¨ºæ·ç¸éçååãç¶èï¼éäºè§£éæææèå¯¦éçç¶ååææåºå¥ï¼çªé¡¯åºé²ä¸æ­¥æ¹é²çå¿è¦æ§ãæ¹æ³ï¼æåæåºäºä¸ç¨®æ¨¡æ¿å¼å°å¼æ¹æ³ï¼å°æ°£è¸çè¨åºç¥è­ç´å¥ XAI æ¹æ³ç¢ççæ¨¡åè§£éä¸­ï¼å¾èæåéäºè§£éçåè³ªãå©ç¨æ¾å°ç§é«å¸«å»ºç«ççç¶æç¹ªï¼æåçåæ³é¦åç¢çä¸åæ¨¡æ¿ï¼ç¨æ¼è¡¨ç¤ºæ°£è¸å¯è½ç¼ççååãç¶å¾å°æ­¤æ¨¡æ¿çå å¨æ¨¡åè§£éä¸ï¼ä»¥ç¯©é¸åºè¶åºæ¨¡æ¿éççç¡éè§£éãçºäºé©è­å¶æåï¼æåå°ä¸ç¨® XAI æ¹æ³é²è¡äºæ¯è¼åæï¼å¨å©åçå¯¦ä¸çè³æéä¸­è§£éå©å DL æ¨¡åæï¼åå¥æ¡ç¨åä¸æ¡ç¨æåçæ¨¡æ¿å¼å°ãçµæï¼ææåºçæ¹æ³å¨å»ºç«æ¼ä¸ç¨® XAI æ¹æ³ãå©å DL æ¨¡ååå©åè³æéçåäºç¨®åºæºæå¢ä¸­ï¼å§çµæ¹åäºåºæº XAI æ¹æ³ãå¨æ¯è¼æ¨¡åè§£éåçå¯¦çç¶ååæï¼ééåºæºæè½çæè½æ¹é²è¨ç®åºçå¹³åå¢éç¾åæ¯çºäº¤éæ¯ï¼IoUï¼ç 97.8% åéª°å­ç¸ä¼¼æ§ä¿æ¸ï¼DSCï¼ç 94.1%ãçµè«ï¼å¨æ°£è¸è¨ºæ·çèæ¯ä¸ï¼æåæåºäºä¸ç¨®æ¨¡æ¿å¼å°å¼æ¹æ³ï¼ç¨æ¼æ¹å AI è§£éãæåé ææåçæ¨¡æ¿å¼å°å°ééæ´åè¨åºé åå°æ¥­ç¥è­ï¼çºé¡æ AI æ¨¡åå»ºç«ä¸ç¨®æ°æ¹æ³ã</paragraph>

##### **Enhancing Neural Machine Translation of Low-Resource Languages: Corpus Development, Human Evaluation and Explainable AI Architectures**
2403.01580v1 by SÃ©amus Lankford

In the current machine translation (MT) landscape, the Transformer
architecture stands out as the gold standard, especially for high-resource
language pairs. This research delves into its efficacy for low-resource
language pairs including both the English$\leftrightarrow$Irish and
English$\leftrightarrow$Marathi language pairs. Notably, the study identifies
the optimal hyperparameters and subword model type to significantly improve the
translation quality of Transformer models for low-resource language pairs.
  The scarcity of parallel datasets for low-resource languages can hinder MT
development. To address this, gaHealth was developed, the first bilingual
corpus of health data for the Irish language. Focusing on the health domain,
models developed using this in-domain dataset exhibited very significant
improvements in BLEU score when compared with models from the LoResMT2021
Shared Task. A subsequent human evaluation using the multidimensional quality
metrics error taxonomy showcased the superior performance of the Transformer
system in reducing both accuracy and fluency errors compared to an RNN-based
counterpart.
  Furthermore, this thesis introduces adaptNMT and adaptMLLM, two open-source
applications streamlined for the development, fine-tuning, and deployment of
neural machine translation models. These tools considerably simplify the setup
and evaluation process, making MT more accessible to both developers and
translators. Notably, adaptNMT, grounded in the OpenNMT ecosystem, promotes
eco-friendly natural language processing research by highlighting the
environmental footprint of model development. Fine-tuning of MLLMs by adaptMLLM
demonstrated advancements in translation performance for two low-resource
language pairs: English$\leftrightarrow$Irish and
English$\leftrightarrow$Marathi, compared to baselines from the LoResMT2021
Shared Task.

æè¦ï¼<paragraph>å¨ç¶åæ©å¨ç¿»è­¯ (MT) é åä¸­ï¼Transformer æ¶æ§è«ç©èåºï¼æçºé»éæ¨æºï¼ç¹å¥æ¯å°æ¼é«è³æºèªè¨å°ãæ¬ç ç©¶æ¢è¨å¶å°ä½è³æºèªè¨å°çæè½ï¼åæ¬è±èªâæç¾è­èªåè±èªâé¦¬æå°èªèªè¨å°ãå¼å¾æ³¨æçæ¯ï¼æ¬ç ç©¶è­å¥åºæä½³è¶åæ¸åå­è©æ¨¡åé¡åï¼ä»¥é¡¯èæé« Transformer æ¨¡åå°ä½è³æºèªè¨å°çç¿»è­¯åè³ªã
ä½è³æºèªè¨çå¹³è¡è³æéçç¨ç¼ºæé»ç¤ MT çç¼å±ãçºäºè§£æ±ºéååé¡ï¼éç¼äº gaHealthï¼éæ¯æç¾è­èªçç¬¬ä¸åéèªå¥åº·è³æèªæåº«ãå°æ³¨æ¼å¥åº·é åï¼ä½¿ç¨æ­¤åå§è³æééç¼çæ¨¡åå¨ BLEU å¾åæ¹é¢è¡¨ç¾åºéå¸¸é¡¯èçé²æ­¥ï¼è LoResMT2021 å±äº«ä»»åä¸­çæ¨¡åç¸æ¯ãé¨å¾ä½¿ç¨å¤ç¶­åè³ªææ¨é¯èª¤åé¡æ³é²è¡çäººå·¥è©ä¼°é¡¯ç¤ºï¼èåºæ¼ RNN çå°ææ¨¡åç¸æ¯ï¼Transformer ç³»çµ±å¨æ¸å°æºç¢ºæ§åæµæ¢æ§é¯èª¤æ¹é¢è¡¨ç¾åºåªç°çæ§è½ã
æ­¤å¤ï¼æ¬è«æä»ç´¹äº adaptNMT å adaptMLLMï¼éå©åéæºæç¨ç¨å¼ç°¡åäºç¥ç¶æ©å¨ç¿»è­¯æ¨¡åçéç¼ãå¾®èª¿åé¨ç½²ãéäºå·¥å·å¤§å¹ç°¡åäºè¨­å®åè©ä¼°æµç¨ï¼è® MT æ´å®¹æè®éç¼äººå¡åç¿»è­¯äººå¡ä½¿ç¨ãå¼å¾æ³¨æçæ¯ï¼adaptNMT ä»¥ OpenNMT çæç³»çµ±çºåºç¤ï¼ééå¼·èª¿æ¨¡åéç¼çç°å¢è¶³è·¡ä¾ä¿é²çæåå¥½çèªç¶èªè¨èçç ç©¶ãè LoResMT2021 å±äº«ä»»åä¸­çåºæºç¸æ¯ï¼adaptMLLM å° MLLM çå¾®èª¿è­æäºè±èªâæç¾è­èªåè±èªâé¦¬æå°èªéå©åä½è³æºèªè¨å°çç¿»è­¯æ§è½é²æ­¥ã</paragraph>

##### **Cause and Effect: Can Large Language Models Truly Understand Causality?**
2402.18139v3 by Swagata Ashwani, Kshiteesh Hegde, Nishith Reddy Mannuru, Mayank Jindal, Dushyant Singh Sengar, Krishna Chaitanya Rao Kathala, Dishant Banga, Vinija Jain, Aman Chadha

With the rise of Large Language Models(LLMs), it has become crucial to
understand their capabilities and limitations in deciphering and explaining the
complex web of causal relationships that language entails. Current methods use
either explicit or implicit causal reasoning, yet there is a strong need for a
unified approach combining both to tackle a wide array of causal relationships
more effectively. This research proposes a novel architecture called Context
Aware Reasoning Enhancement with Counterfactual Analysis(CARE CA) framework to
enhance causal reasoning and explainability. The proposed framework
incorporates an explicit causal detection module with ConceptNet and
counterfactual statements, as well as implicit causal detection through LLMs.
Our framework goes one step further with a layer of counterfactual explanations
to accentuate LLMs understanding of causality. The knowledge from ConceptNet
enhances the performance of multiple causal reasoning tasks such as causal
discovery, causal identification and counterfactual reasoning. The
counterfactual sentences add explicit knowledge of the not caused by scenarios.
By combining these powerful modules, our model aims to provide a deeper
understanding of causal relationships, enabling enhanced interpretability.
Evaluation of benchmark datasets shows improved performance across all metrics,
such as accuracy, precision, recall, and F1 scores. We also introduce
CausalNet, a new dataset accompanied by our code, to facilitate further
research in this domain.

æè¦ï¼é¨èå¤§åèªè¨æ¨¡å (LLM) çèèµ·ï¼äºè§£å®åå¨è§£ç¢¼åè§£éèªè¨æèå«çè¤éå æéä¿ç¶²è·¯ä¸­çè½ååéå¶è®å¾è³ééè¦ãç®åçæè¡ä½¿ç¨æç¢ºæé±å«çå ææ¨çï¼ä½å¼·çéè¦ä¸ç¨®çµ±ä¸çæ¹æ³ï¼çµåå©èä»¥æ´ææå°èçå»£æ³çå æéä¿ãæ¬ç ç©¶æåºäºä¸ç¨®ç¨±çºæå¢æç¥æ¨çå¢å¼·èåäºå¯¦åæ (CARE CA) æ¡æ¶çæ°æ¶æ§ï¼ä»¥å¢å¼·å ææ¨çåå¯è§£éæ§ãæåºçæ¡æ¶çµåäºä½¿ç¨ ConceptNet ååäºå¯¦é³è¿°çæç¢ºå ææª¢æ¸¬æ¨¡çµï¼ä»¥åéé LLM é²è¡çé±å«å ææª¢æ¸¬ãæåçæ¡æ¶æ´é²ä¸æ­¥ï¼å å¥ä¸å±¤åäºå¯¦è§£éï¼ä»¥å¼·èª¿ LLM å°å æéä¿ççè§£ãä¾èª ConceptNet çç¥è­å¢å¼·äºå¤é å ææ¨çä»»åçå·è¡ï¼ä¾å¦å æç¼ç¾ãå æè­å¥ååäºå¯¦æ¨çãåäºå¯¦å¥å å¥äºæªç±æå¢é æçæç¢ºç¥è­ãééçµåéäºå¼·å¤§çæ¨¡çµï¼æåçæ¨¡åæ¨å¨æä¾å°å æéä¿æ´æ·±å¥ççè§£ï¼å¯¦ç¾å¢å¼·çå¯è§£éæ§ãåºæºè³æéçè©ä¼°é¡¯ç¤ºå¨ææææ¨ï¼ä¾å¦æºç¢ºåº¦ãç²¾ç¢ºåº¦ãå¬åçå F1 åæ¸ï¼ä¸é½æææåãæåéå¼å¥äº CausalNetï¼ä¸åæ°çè³æéï¼ä¸¦éä¸äºæåçç¨å¼ç¢¼ï¼ä»¥ä¿é²å¨éåé åçé²ä¸æ­¥ç ç©¶ã

##### **Artificial Intelligence and Diabetes Mellitus: An Inside Look Through the Retina**
2402.18600v1 by Yasin Sadeghi Bazargani, Majid Mirzaei, Navid Sobhi, Mirsaeed Abdollahi, Ali Jafarizadeh, Siamak Pedrammehr, Roohallah Alizadehsani, Ru San Tan, Sheikh Mohammed Shariful Islam, U. Rajendra Acharya

Diabetes mellitus (DM) predisposes patients to vascular complications.
Retinal images and vasculature reflect the body's micro- and macrovascular
health. They can be used to diagnose DM complications, including diabetic
retinopathy (DR), neuropathy, nephropathy, and atherosclerotic cardiovascular
disease, as well as forecast the risk of cardiovascular events. Artificial
intelligence (AI)-enabled systems developed for high-throughput detection of DR
using digitized retinal images have become clinically adopted. Beyond DR
screening, AI integration also holds immense potential to address challenges
associated with the holistic care of the patient with DM. In this work, we aim
to comprehensively review the literature for studies on AI applications based
on retinal images related to DM diagnosis, prognostication, and management. We
will describe the findings of holistic AI-assisted diabetes care, including but
not limited to DR screening, and discuss barriers to implementing such systems,
including issues concerning ethics, data privacy, equitable access, and
explainability. With the ability to evaluate the patient's health status vis a
vis DM complication as well as risk prognostication of future cardiovascular
complications, AI-assisted retinal image analysis has the potential to become a
central tool for modern personalized medicine in patients with DM.

æè¦ï¼ç³å°¿çï¼DMï¼ä½¿æ£èå®¹æåºç¾è¡ç®¡ä½µç¼çã
è¦ç¶²èå½±ååè¡ç®¡åæ èº«é«çå¾®è¡ç®¡åå·¨è¡ç®¡å¥åº·çæ³ãå®åå¯ç¨æ¼è¨ºæ·ç³å°¿çä½µç¼çï¼åæ¬ç³å°¿çè¦ç¶²èçè®ï¼DRï¼ãç¥ç¶çè®ãèçååèç²¥æ¨£ç¡¬åæ§å¿è¡ç®¡ç¾çï¼ä»¥åé æ¸¬å¿è¡ç®¡äºä»¶çé¢¨éªãçºä½¿ç¨æ¸ä½åè¦ç¶²èå½±åé²è¡é«éé DR æª¢æ¸¬èéç¼çäººå·¥æºæ§ï¼AIï¼åç¨ç³»çµ±å·²å¨è¨åºæ¡ç¨ãé¤äº DR ç¯©æª¢å¤ï¼AI æ´åä¹å·æå·¨å¤§çæ½åä¾æå°èç³å°¿çæ£èæ´é«ç§è­·ç¸éçææ°ãå¨éé å·¥ä½ä¸­ï¼æåæ¨å¨å¨é¢åé¡§åºæ¼è¦ç¶²èå½±åç AI æç¨ç¸éç ç©¶çæç»ï¼éäºç ç©¶èç³å°¿ççè¨ºæ·ãé å¾åç®¡çæéãæåå°æè¿°æ´é« AI è¼å©ç³å°¿çç§è­·çç¼ç¾ï¼åæ¬ä½ä¸éæ¼ DR ç¯©æª¢ï¼ä¸¦è¨è«å¯¦æ½æ­¤é¡ç³»çµ±çéç¤ï¼åæ¬èå«çãè³æé±ç§ãå¬å¹³å­ååå¯è§£éæ§æéçåé¡ãééè©ä¼°æ£èçå¥åº·çæ³ï¼åæèéç³å°¿çä½µç¼çä»¥åæªä¾å¿è¡ç®¡ä½µç¼ççé¢¨éªé å¾ï¼AI è¼å©è¦ç¶²èå½±ååæææ½åæçºç³å°¿çæ£èç¾ä»£ååäººåé«ççä¸­å¿å·¥å·ã

##### **Multi-stakeholder Perspective on Responsible Artificial Intelligence and Acceptability in Education**
2402.15027v2 by A. J. Karran, P. Charland, J-T. Martineau, A. Ortiz de Guinea Lopez de Arana, AM. Lesage, S. Senecal, P-M. Leger

This study investigates the acceptability of different artificial
intelligence (AI) applications in education from a multi-stakeholder
perspective, including students, teachers, and parents. Acknowledging the
transformative potential of AI in education, it addresses concerns related to
data privacy, AI agency, transparency, explainability and the ethical
deployment of AI. Through a vignette methodology, participants were presented
with four scenarios where AI's agency, transparency, explainability, and
privacy were manipulated. After each scenario, participants completed a survey
that captured their perceptions of AI's global utility, individual usefulness,
justice, confidence, risk, and intention to use each scenario's AI if
available. The data collection comprising a final sample of 1198
multi-stakeholder participants was distributed through a partner institution
and social media campaigns and focused on individual responses to four AI use
cases. A mediation analysis of the data indicated that acceptance and trust in
AI varies significantly across stakeholder groups. We found that the key
mediators between high and low levels of AI's agency, transparency, and
explainability, as well as the intention to use the different educational AI,
included perceived global utility, justice, and confidence. The study
highlights that the acceptance of AI in education is a nuanced and multifaceted
issue that requires careful consideration of specific AI applications and their
characteristics, in addition to the diverse stakeholders' perceptions.

æè¦ï¼éé ç ç©¶å¾å¤åå©å®³éä¿äººçè§åº¦æ¢è¨ä¸åçäººå·¥æºæ§ (AI) æç¨å¨æè²ä¸çå¯æ¥åæ§ï¼åæ¬å­¸çãèå¸«åå®¶é·ãæ¿èª AI å¨æè²ä¸çè½åæ½åï¼å®è§£æ±ºäºèè³æé±ç§ãAI ä»£çãéæåº¦ãå¯è§£éæ§å AI çéå¾·é¨ç½²ç¸éççæ®ãééå°ææ²æ¹æ³ï¼åèèè¢«åç¾äºåç¨®æå¢ï¼å¶ä¸­ AI çä»£çãéæåº¦ãå¯è§£éæ§åé±ç§åå°æç¸±ãå¨æ¯åæå¢å¾ï¼åèèå®æäºä¸é èª¿æ¥ï¼è©²èª¿æ¥ææäºä»åå° AI çæ´é«æç¨ãåäººæç¨ãæ­£ç¾©ãä¿¡å¿ãé¢¨éªåå¦æå¯ç¨ï¼ä½¿ç¨æ¯åæå¢ç AI çæåççæ³ãè³æèéåå«ä¾èªåä½æ©æ§åç¤¾ç¾¤åªé«æ´»åç 1198 ä½å¤å©å®³éä¿äººåèèçæçµæ¨£æ¬ï¼ä¸¦å°æ³¨æ¼å°åå AI ä½¿ç¨æ¡ä¾çåå¥åæãå°è³æçèª¿è§£åæè¡¨æï¼å° AI çæ¥ååº¦åä¿¡ä»»å¨å©å®³éä¿äººåé«ä¹éæé¡¯èå·®ç°ãæåç¼ç¾ï¼AI çä»£çãéæåº¦åå¯è§£éæ§é«ä½ç¨åº¦ä¹éçééµèª¿è§£èï¼ä»¥åä½¿ç¨ä¸åæè² AI çæåï¼åæ¬æç¥å°çæ´é«æç¨ãæ­£ç¾©åä¿¡å¿ãéé ç ç©¶å¼·èª¿ï¼æ¥å AI å¨æè²ä¸çæç¨æ¯ä¸åå¾®å¦ä¸å¤é¢åçåé¡ï¼é¤äºä¸åçå©å®³éä¿äººççæ³å¤ï¼ééè¦ä»ç´°èæ®å·é«ç AI æç¨åå¶ç¹å¾µã

##### **Deciphering Heartbeat Signatures: A Vision Transformer Approach to Explainable Atrial Fibrillation Detection from ECG Signals**
2402.09474v2 by Aruna Mohan, Danne Elbers, Or Zilbershot, Fatemeh Afghah, David Vorchheimer

Remote patient monitoring based on wearable single-lead electrocardiogram
(ECG) devices has significant potential for enabling the early detection of
heart disease, especially in combination with artificial intelligence (AI)
approaches for automated heart disease detection. There have been prior studies
applying AI approaches based on deep learning for heart disease detection.
However, these models are yet to be widely accepted as a reliable aid for
clinical diagnostics, in part due to the current black-box perception
surrounding many AI algorithms. In particular, there is a need to identify the
key features of the ECG signal that contribute toward making an accurate
diagnosis, thereby enhancing the interpretability of the model. In the present
study, we develop a vision transformer approach to identify atrial fibrillation
based on single-lead ECG data. A residual network (ResNet) approach is also
developed for comparison with the vision transformer approach. These models are
applied to the Chapman-Shaoxing dataset to classify atrial fibrillation, as
well as another common arrhythmia, sinus bradycardia, and normal sinus rhythm
heartbeats. The models enable the identification of the key regions of the
heartbeat that determine the resulting classification, and highlight the
importance of P-waves and T-waves, as well as heartbeat duration and signal
amplitude, in distinguishing normal sinus rhythm from atrial fibrillation and
sinus bradycardia.

æè¦ï¼<paragraph>åºæ¼å¯ç©¿æ´å¼å®å°ç¨å¿é»å (ECG) è£ç½®çé ç«¯çæ£ç£æ¸¬å¨æ©æåµæ¸¬å¿èç¾çæ¹é¢å·æé¡¯èçæ½åï¼ç¹å¥æ¯èç¨æ¼èªååå¿èç¾çåµæ¸¬çäººå·¥æºæ§ (AI) æ¹æ³çµåä½¿ç¨æãååå·²æç ç©¶æç¨åºæ¼æ·±åº¦å­¸ç¿ç AI æ¹æ³é²è¡å¿èç¾çåµæ¸¬ãç¶èï¼éäºæ¨¡åå°æªè¢«å»£æ³æ¥åçºè¨åºè¨ºæ·çå¯é è¼å©å·¥å·ï¼é¨ååå å¨æ¼åç¹è¨±å¤ AI æ¼ç®æ³çç¶åé»ç®±æç¥ãç¹å¥æ¯ï¼æå¿è¦æ¾åºæå©æ¼ååºæºç¢ºè¨ºæ·ç ECG è¨èééµç¹å¾µï¼å¾èå¢å¼·æ¨¡åçå¯è§£éæ§ãå¨æ¬ç ç©¶ä¸­ï¼æåéç¼äºä¸ç¨®è¦è¦ºè½æå¨æ¹æ³ï¼ä»¥æ ¹æå®å°ç¨ ECG è³ææ¾åºå¿æ¿é¡«åãæ®å·®ç¶²è·¯ (ResNet) æ¹æ³ä¹å·²éç¼åºä¾ï¼ä»¥ä¾¿èè¦è¦ºè½æå¨æ¹æ³é²è¡æ¯è¼ãéäºæ¨¡åæç¨æ¼ Chapman-Shaoxing è³æéï¼ä»¥åé¡å¿æ¿é¡«åï¼ä»¥åå¦ä¸ç¨®å¸¸è¦çå¿å¾ä¸æ´ï¼ç«æ§å¿åéç·©ï¼åæ­£å¸¸ç«æ§å¿å¾çå¿è·³ãéäºæ¨¡åè½å¤ æ¾åºæ±ºå®æçµåé¡çå¿è·³ééµååï¼ä¸¦å¼·èª¿ P æ³¢å T æ³¢ï¼ä»¥åå¿è·³æçºæéåè¨èæ¯å¹å¨ååæ­£å¸¸ç«æ§å¿å¾èå¿æ¿é¡«ååç«æ§å¿åéç·©æ¹é¢çéè¦æ§ã</paragraph>

##### **Illuminate: A novel approach for depression detection with explainable analysis and proactive therapy using prompt engineering**
2402.05127v1 by Aryan Agrawal

This paper introduces a novel paradigm for depression detection and treatment
using advanced Large Language Models (LLMs): Generative Pre-trained Transformer
4 (GPT-4), Llama 2 chat, and Gemini. These LLMs are fine-tuned with specialized
prompts to diagnose, explain, and suggest therapeutic interventions for
depression. A unique few-shot prompting method enhances the models' ability to
analyze and explain depressive symptoms based on the DSM-5 criteria. In the
interaction phase, the models engage in empathetic dialogue management, drawing
from resources like PsychDB and a Cognitive Behavioral Therapy (CBT) Guide,
fostering supportive interactions with individuals experiencing major
depressive disorders. Additionally, the research introduces the Illuminate
Database, enriched with various CBT modules, aiding in personalized therapy
recommendations. The study evaluates LLM performance using metrics such as F1
scores, Precision, Recall, Cosine similarity, and Recall-Oriented Understudy
for Gisting Evaluation (ROUGE) across different test sets, demonstrating their
effectiveness. This comprehensive approach blends cutting-edge AI with
established psychological methods, offering new possibilities in mental health
care and showcasing the potential of LLMs in revolutionizing depression
diagnosis and treatment strategies.

æè¦ï¼æ¬æä»ç´¹äºä¸ç¨®ä½¿ç¨åé²å¤§åèªè¨æ¨¡å (LLM) é²è¡æé¬±çåµæ¸¬åæ²»ççæ°æ¨¡å¼ï¼çæå¼é è¨ç·´Transformer 4 (GPT-4)ãLlama 2 èå¤©æ©å¨äººå Geminiãéäº LLM ç¶éå¾®èª¿ï¼å·åå°æ¥­æç¤ºï¼å¯è¨ºæ·ãè§£éä¸¦å»ºè­°æé¬±ççæ²»çä»å¥æ¹æ³ãä¸ç¨®ç¨ç¹çå°æ¬¡æç¤ºæ¹æ³å¢å¼·äºæ¨¡åæ ¹æ DSM-5 æ¨æºåæåè§£éæé¬±çççè½åãå¨äºåéæ®µï¼éäºæ¨¡åæåèåçå¿å°è©±ç®¡çï¼å¾ PsychDB åèªç¥è¡çºçæ³ (CBT) æåç­è³æºä¸­æ±²åï¼ä¿é²èç¶æ­·éåº¦æé¬±ççäººåçæ¯ææ§äºåãæ­¤å¤ï¼éé ç ç©¶éä»ç´¹äº Illuminate è³æåº«ï¼å¶ä¸­åå«åç¨® CBT æ¨¡çµï¼æå©æ¼åæ§åæ²»çå»ºè­°ãéé ç ç©¶ä½¿ç¨ F1 åæ¸ãæºç¢ºçãå¬åçãé¤å¼¦ç¸ä¼¼åº¦åé¢åå¬åçç Gisting è©ä¼°æ¿èº« (ROUGE) ç­ææ¨ï¼å¨ä¸åçæ¸¬è©¦éä¸­è©ä¼° LLM çè¡¨ç¾ï¼è­æäºå®åçæææ§ãéç¨®ç¶åæ¹æ³çµåäºå°ç«¯ç AI èæ¢å®çå¿çæ¹æ³ï¼çºå¿çä¿å¥æä¾äºæ°çå¯è½æ§ï¼ä¸¦å±ç¤ºäº LLM å¨é©æ°æé¬±çè¨ºæ·åæ²»çç­ç¥æ¹é¢çæ½åã

##### **Information That Matters: Exploring Information Needs of People Affected by Algorithmic Decisions**
2401.13324v6 by TimothÃ©e Schmude, Laura Koesten, Torsten MÃ¶ller, Sebastian Tschiatschek

Every AI system that makes decisions about people has a group of stakeholders
that are personally affected by these decisions. However, explanations of AI
systems rarely address the information needs of this stakeholder group, who
often are AI novices. This creates a gap between conveyed information and
information that matters to those who are impacted by the system's decisions,
such as domain experts and decision subjects. To address this, we present the
"XAI Novice Question Bank," an extension of the XAI Question Bank containing a
catalog of information needs from AI novices in two use cases: employment
prediction and health monitoring. The catalog covers the categories of data,
system context, system usage, and system specifications. We gathered
information needs through task-based interviews where participants asked
questions about two AI systems to decide on their adoption and received verbal
explanations in response. Our analysis showed that participants' confidence
increased after receiving explanations but that their understanding faced
challenges. These included difficulties in locating information and in
assessing their own understanding, as well as attempts to outsource
understanding. Additionally, participants' prior perceptions of the systems'
risks and benefits influenced their information needs. Participants who
perceived high risks sought explanations about the intentions behind a system's
deployment, while those who perceived low risks rather asked about the system's
operation. Our work aims to support the inclusion of AI novices in
explainability efforts by highlighting their information needs, aims, and
challenges. We summarize our findings as five key implications that can inform
the design of future explanations for lay stakeholder audiences.

æè¦ï¼<paragraph>æ¯åå°äººååºæ±ºå®ç AI ç³»çµ±é½æä¸ç¾¤å©å®³éä¿äºº
åå°éäºæ±ºå®çè¦ªèº«å½±é¿ãç¶èï¼AI
ç³»çµ±çè§£éå¾å°è½æ»¿è¶³éç¾¤å©å®³éä¿äººçè³è¨éæ±ï¼èä»å
éå¸¸é½æ¯ AI æ°æãéé æäºå³éè³è¨è
åå°ç³»çµ±æ±ºç­å½±é¿çäººå£«ï¼ä¾å¦é åå°å®¶åæ±ºç­ä¸»é«ï¼éè¦çè³è¨ä¹éçè½å·®ãçºäºè§£æ±ºéååé¡ï¼æåæåºäº
ãXAI æ°æåé¡åº«ãï¼å®æ¯ XAI åé¡åº«çå»¶ä¼¸ï¼åå«ä¾èª AI æ°æå¨å©åä½¿ç¨æ¡ä¾ä¸­çè³è¨éæ±ç®éï¼å°±æ¥­
é æ¸¬åå¥åº·ç£æ¸¬ãç®éæ¶µèäºè³æã
ç³»çµ±èæ¯ãç³»çµ±ä½¿ç¨åç³»çµ±è¦æ ¼ç­é¡å¥ãæåééä»»ååè¨ªè«æ¶éè³è¨éæ±ï¼åèèå¨è¨ªè«ä¸­è©¢åäºå©å AI ç³»çµ±çåé¡ï¼ä»¥æ±ºå®æ¯å¦æ¡ç¨å®åï¼ä¸¦æ¶å°å£é ­
è§£éä½çºåæãæåçåæé¡¯ç¤ºï¼åèèå¨æ¶å°è§£éå¾ä¿¡å¿æææåï¼ä½ä»åççè§£å»é¢è¨ææ°ãéäºææ°åæ¬é£ä»¥æ¾å°è³è¨åè©ä¼°èªå·±ççè§£ï¼ä»¥åè©¦åå¤å
çè§£ãæ­¤å¤ï¼åèèå°ç³»çµ±é¢¨éªåå¥½èçåååé¥å½±é¿äºä»åçè³è¨éæ±ãèªçºé¢¨éªé«çåèèå°æ±è§£éç³»çµ±é¨ç½²èå¾çæåï¼èèªçºé¢¨éªä½çäººåè©¢åç³»çµ±ç
æä½ãæåçç ç©¶æ¨å¨ééå¼·èª¿ AI æ°æçè³è¨éæ±ãç®æ¨å
ææ°ï¼ä¾æ¯æå° AI æ°æç´å¥å¯è§£éæ§å·¥ä½ä¸­ãæåå°æåçç ç©¶çµæç¸½çµçºäºåééµåç¤ºï¼éäºåç¤ºå¯ä»¥çºæªä¾éå°éå°æ¥­å©å®³éä¿äººåç¾çè§£éè¨­è¨æä¾åèã</paragraph>

##### **Evaluating Large Language Models on the GMAT: Implications for the Future of Business Education**
2401.02985v1 by Vahid Ashrafimoghari, Necdet GÃ¼rkan, Jordan W. Suchow

The rapid evolution of artificial intelligence (AI), especially in the domain
of Large Language Models (LLMs) and generative AI, has opened new avenues for
application across various fields, yet its role in business education remains
underexplored. This study introduces the first benchmark to assess the
performance of seven major LLMs, OpenAI's models (GPT-3.5 Turbo, GPT-4, and
GPT-4 Turbo), Google's models (PaLM 2, Gemini 1.0 Pro), and Anthropic's models
(Claude 2 and Claude 2.1), on the GMAT, which is a key exam in the admission
process for graduate business programs. Our analysis shows that most LLMs
outperform human candidates, with GPT-4 Turbo not only outperforming the other
models but also surpassing the average scores of graduate students at top
business schools. Through a case study, this research examines GPT-4 Turbo's
ability to explain answers, evaluate responses, identify errors, tailor
instructions, and generate alternative scenarios. The latest LLM versions,
GPT-4 Turbo, Claude 2.1, and Gemini 1.0 Pro, show marked improvements in
reasoning tasks compared to their predecessors, underscoring their potential
for complex problem-solving. While AI's promise in education, assessment, and
tutoring is clear, challenges remain. Our study not only sheds light on LLMs'
academic potential but also emphasizes the need for careful development and
application of AI in education. As AI technology advances, it is imperative to
establish frameworks and protocols for AI interaction, verify the accuracy of
AI-generated content, ensure worldwide access for diverse learners, and create
an educational environment where AI supports human expertise. This research
sets the stage for further exploration into the responsible use of AI to enrich
educational experiences and improve exam preparation and assessment methods.

æè¦ï¼äººå·¥æºæ§ (AI) çå¿«éæ¼é²ï¼å°¤å¶æ¯å¨å¤§åèªè¨æ¨¡å (LLM) åçæå¼ AI çé åï¼çºååé åçæç¨éåäºæ°éå¾ï¼ä½å¶å¨åæ¥­æè²ä¸­çè§è²ä»æªè¢«ååæ¢è¨ãæ¬ç ç©¶é¦æ¬¡å¼å¥äºåºæºï¼ç¨ä»¥è©ä¼°ä¸åä¸»è¦ LLM çæè½ï¼åæ¬ OpenAI çæ¨¡å (GPT-3.5 TurboãGPT-4 å GPT-4 Turbo)ãGoogle çæ¨¡å (PaLM 2ãGemini 1.0 Pro) å Anthropic çæ¨¡å (Claude 2 å Claude 2.1)ï¼éäºæ¨¡åå°ç¨æ¼ç ç©¶çåæ¥­èª²ç¨å¥å­¸ç¨åºä¸­çééµèè©¦ GMATãæåçåæé¡¯ç¤ºï¼å¤§å¤æ¸ LLM çè¡¨ç¾é½åªæ¼äººé¡èçï¼å¶ä¸­ GPT-4 Turbo ä¸ååªæ¼å¶ä»æ¨¡åï¼æ´è¶è¶äºé å°åå­¸é¢çç ç©¶çå¹³ååæ¸ãééæ¡ä¾ç ç©¶ï¼æ¬ç ç©¶æ¢è¨äº GPT-4 Turbo å¨è§£éç­æ¡ãè©ä¼°åæãè¾¨è­é¯èª¤ãèª¿æ´èªªæåç¢çæ¿ä»£æå¢æ¹é¢çè½åãèåä¸ä»£çæ¬ç¸æ¯ï¼ææ°ç LLM çæ¬ GPT-4 TurboãClaude 2.1 å Gemini 1.0 Pro å¨æ¨çä»»åæ¹é¢æé¡¯èçé²æ­¥ï¼å¸é¡¯äºå¶å¨è§£æ±ºè¤éåé¡æ¹é¢çæ½åãåç®¡ AI å¨æè²ãè©éåè¼å°æ¹é¢çæ¿è«¾å¾æç¢ºï¼ä½ä»æææ°å­å¨ãæåçç ç©¶ä¸åé¡æäº LLM çå­¸è¡æ½åï¼ä¹å¼·èª¿äºå¨æè²ä¸­å¯©æéç¼åæç¨ AI çå¿è¦æ§ãé¨è AI æè¡çé²æ­¥ï¼å»ºç« AI äºåçæ¶æ§ååå®ãé©è­ AI çæçå§å®¹çæºç¢ºæ§ãç¢ºä¿å¨çåå°å¤åå­¸ç¿èçå­åæ¬ï¼ä»¥ååµé ä¸å AI æ¯æäººé¡å°æ¥­ç¥è­çæè²ç°å¢è³ééè¦ãæ¬ç ç©¶çºé²ä¸æ­¥æ¢ç´¢è² è²¬ä»»å°ä½¿ç¨ AI ä¾è±å¯æè²é«é©ä¸¦æ¹åèè©¦æºååè©éæ¹æ³å¥ å®äºåºç¤ã


### Knowledge Graphs
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2025-01-24**|**Evaluating and Improving Graph to Text Generation with Large Language Models**|Jie He et.al.|[2501.14497v1](http://arxiv.org/abs/2501.14497v1)|[link](https://github.com/probe2/kg_text)|
|**2025-01-24**|**Fast Think-on-Graph: Wider, Deeper and Faster Reasoning of Large Language Model on Knowledge Graph**|Xujian Liang et.al.|[2501.14300v1](http://arxiv.org/abs/2501.14300v1)|[link](https://github.com/dosonleung/fasttog)|
|**2025-01-24**|**Top Ten Challenges Towards Agentic Neural Graph Databases**|Jiaxin Bai et.al.|[2501.14224v1](http://arxiv.org/abs/2501.14224v1)|null|
|**2025-01-23**|**GraphRAG under Fire**|Jiacheng Liang et.al.|[2501.14050v1](http://arxiv.org/abs/2501.14050v1)|null|
|**2025-01-23**|**EICopilot: Search and Explore Enterprise Information over Large-scale Knowledge Graphs with LLM-driven Agents**|Yuhui Yun et.al.|[2501.13746v1](http://arxiv.org/abs/2501.13746v1)|null|
|**2025-01-23**|**Pseudocode-Injection Magic: Enabling LLMs to Tackle Graph Computational Tasks**|Chang Gong et.al.|[2501.13731v1](http://arxiv.org/abs/2501.13731v1)|null|
|**2025-01-23**|**CAPRAG: A Large Language Model Solution for Customer Service and Automatic Reporting using Vector and Graph Retrieval-Augmented Generation**|Hamza Landolsi et.al.|[2501.13993v1](http://arxiv.org/abs/2501.13993v1)|null|
|**2025-01-23**|**Dual-Branch HNSW Approach with Skip Bridges and LID-Driven Optimization**|Hy Nguyen et.al.|[2501.13992v1](http://arxiv.org/abs/2501.13992v1)|null|
|**2025-01-23**|**Comprehensive Modeling and Question Answering of Cancer Clinical Practice Guidelines using LLMs**|Bhumika Gupta et.al.|[2501.13984v1](http://arxiv.org/abs/2501.13984v1)|null|
|**2025-01-21**|**LLM-Assisted Knowledge Graph Completion for Curriculum and Domain Modelling in Personalized Higher Education Recommendations**|Hasan Abu-Rasheed et.al.|[2501.12300v1](http://arxiv.org/abs/2501.12300v1)|null|
|**2025-01-21**|**Divide-Then-Aggregate: An Efficient Tool Learning Method via Parallel Tool Invocation**|Dongsheng Zhu et.al.|[2501.12432v1](http://arxiv.org/abs/2501.12432v1)|null|
|**2025-01-21**|**InsTALL: Context-aware Instructional Task Assistance with Multi-modal Large Language Models**|Pha Nguyen et.al.|[2501.12231v1](http://arxiv.org/abs/2501.12231v1)|null|
|**2025-01-21**|**Leveraging Graph Structures and Large Language Models for End-to-End Synthetic Task-Oriented Dialogues**|Maya Medjad et.al.|[2501.11977v1](http://arxiv.org/abs/2501.11977v1)|[link](https://github.com/reecall/graphtod)|
|**2025-01-21**|**Bridging Visualization and Optimization: Multimodal Large Language Models on Graph-Structured Combinatorial Optimization**|Jie Zhao et.al.|[2501.11968v1](http://arxiv.org/abs/2501.11968v1)|null|
|**2025-01-21**|**A Survey of Graph Retrieval-Augmented Generation for Customized Large Language Models**|Qinggang Zhang et.al.|[2501.13958v1](http://arxiv.org/abs/2501.13958v1)|[link](https://github.com/deep-polyu/awesome-graphrag)|
|**2025-01-21**|**Network-informed Prompt Engineering against Organized Astroturf Campaigns under Extreme Class Imbalance**|Nikos Kanakaris et.al.|[2501.11849v1](http://arxiv.org/abs/2501.11849v1)|[link](https://github.com/nkanak/brag-fake-news-campaigns)|
|**2025-01-20**|**Zep: A Temporal Knowledge Graph Architecture for Agent Memory**|Preston Rasmussen et.al.|[2501.13956v1](http://arxiv.org/abs/2501.13956v1)|null|
|**2025-01-20**|**Explainable Lane Change Prediction for Near-Crash Scenarios Using Knowledge Graph Embeddings and Retrieval Augmented Generation**|M. Manzour et.al.|[2501.11560v1](http://arxiv.org/abs/2501.11560v1)|null|
|**2025-01-20**|**Each Graph is a New Language: Graph Learning with LLMs**|Huachi Zhou et.al.|[2501.11478v2](http://arxiv.org/abs/2501.11478v2)|null|
|**2025-01-20**|**Few-shot Policy (de)composition in Conversational Question Answering**|Kyle Erwin et.al.|[2501.11335v1](http://arxiv.org/abs/2501.11335v1)|null|
|**2025-01-20**|**Reasoning Language Models: A Blueprint**|Maciej Besta et.al.|[2501.11223v3](http://arxiv.org/abs/2501.11223v3)|[link](https://github.com/spcl/x1)|
|**2025-01-19**|**IntellAgent: A Multi-Agent Framework for Evaluating Conversational AI Systems**|Elad Levi et.al.|[2501.11067v1](http://arxiv.org/abs/2501.11067v1)|[link](https://github.com/plurai-ai/intellagent)|
|**2025-01-17**|**Agent-as-Judge for Factual Summarization of Long Narratives**|Yeonseok Jeong et.al.|[2501.09993v1](http://arxiv.org/abs/2501.09993v1)|[link](https://github.com/yeonseokjeong/narrativefactscore)|
|**2025-01-17**|**FRAG: A Flexible Modular Framework for Retrieval-Augmented Generation based on Knowledge Graphs**|Zengyi Gao et.al.|[2501.09957v2](http://arxiv.org/abs/2501.09957v2)|null|
|**2025-01-16**|**SOP-Agent: Empower General Purpose AI Agent with Domain-Specific SOPs**|Anbang Ye et.al.|[2501.09316v1](http://arxiv.org/abs/2501.09316v1)|null|
|**2025-01-16**|**Text Semantics to Flexible Design: A Residential Layout Generation Method Based on Stable Diffusion Model**|Zijin Qiu et.al.|[2501.09279v1](http://arxiv.org/abs/2501.09279v1)|null|
|**2025-01-16**|**A Simple Graph Contrastive Learning Framework for Short Text Classification**|Yonghao Liu et.al.|[2501.09219v1](http://arxiv.org/abs/2501.09219v1)|[link](https://github.com/keaml-jlu/simstc)|
|**2025-01-16**|**Boosting Short Text Classification with Multi-Source Information Exploration and Dual-Level Contrastive Learning**|Yonghao Liu et.al.|[2501.09214v1](http://arxiv.org/abs/2501.09214v1)|[link](https://github.com/keaml-jlu/mi-delight)|
|**2025-01-15**|**Leveraging Large Language Models as Knowledge-Driven Agents for Reliable Retrosynthesis Planning**|Qinyu Ma et.al.|[2501.08897v1](http://arxiv.org/abs/2501.08897v1)|[link](https://github.com/qinyuma316/retrosynthesisagent)|
|**2025-01-15**|**Knowledge Graph-based Retrieval-Augmented Generation for Schema Matching**|Chuangtao Ma et.al.|[2501.08686v1](http://arxiv.org/abs/2501.08686v1)|[link](https://github.com/machuangtao/kg-rag4sm)|
|**2025-01-15**|**Assessing the Alignment of FOL Closeness Metrics with Human Judgement**|Ramya Keerthy Thatikonda et.al.|[2501.08613v2](http://arxiv.org/abs/2501.08613v2)|[link](https://github.com/ramyakeerthy/alignmentfol)|
|**2025-01-15**|**AutoRestTest: A Tool for Automated REST API Testing Using LLMs and MARL**|Tyler Stennett et.al.|[2501.08600v1](http://arxiv.org/abs/2501.08600v1)|null|
|**2025-01-15**|**LoRS: Efficient Low-Rank Adaptation for Sparse Large Language Model**|Yuxuan Hu et.al.|[2501.08582v1](http://arxiv.org/abs/2501.08582v1)|null|
|**2025-01-14**|**Towards Zero-Shot & Explainable Video Description by Reasoning over Graphs of Events in Space and Time**|Mihai Masala et.al.|[2501.08460v1](http://arxiv.org/abs/2501.08460v1)|null|
|**2025-01-14**|**In-situ graph reasoning and knowledge expansion using Graph-PReFLexOR**|Markus J. Buehler et.al.|[2501.08120v1](http://arxiv.org/abs/2501.08120v1)|[link](https://github.com/lamm-mit/PRefLexOR)|
|**2025-01-14**|**Reasoning with Graphs: Structuring Implicit Knowledge to Enhance LLMs Reasoning**|Haoyu Han et.al.|[2501.07845v1](http://arxiv.org/abs/2501.07845v1)|null|
|**2025-01-14**|**Flow: A Modular Approach to Automated Agentic Workflow Generation**|Boye Niu et.al.|[2501.07834v1](http://arxiv.org/abs/2501.07834v1)|null|
|**2025-01-14**|**Large Language Models for Knowledge Graph Embedding Techniques, Methods, and Challenges: A Survey**|Bingchen Liu et.al.|[2501.07766v1](http://arxiv.org/abs/2501.07766v1)|null|
|**2025-01-13**|**SafePowerGraph-LLM: Novel Power Grid Graph Embedding and Optimization with Large Language Models**|Fabien Bernier et.al.|[2501.07639v1](http://arxiv.org/abs/2501.07639v1)|null|
|**2025-01-13**|**ADKGD: Anomaly Detection in Knowledge Graphs with Dual-Channel Training**|Jiayang Wu et.al.|[2501.07078v1](http://arxiv.org/abs/2501.07078v1)|[link](https://github.com/csjywu1/adkgd)|
|**2025-01-12**|**Causal Claims in Economics**|Prashant Garg et.al.|[2501.06873v1](http://arxiv.org/abs/2501.06873v1)|null|
|**2025-01-12**|**MiniRAG: Towards Extremely Simple Retrieval-Augmented Generation**|Tianyu Fan et.al.|[2501.06713v2](http://arxiv.org/abs/2501.06713v2)|[link](https://github.com/hkuds/minirag)|
|**2025-01-12**|**Large Language Models, Knowledge Graphs and Search Engines: A Crossroads for Answering Users' Questions**|Aidan Hogan et.al.|[2501.06699v1](http://arxiv.org/abs/2501.06699v1)|null|
|**2025-01-11**|**Quantifying Relational Exploration in Cultural Heritage Knowledge Graphs with LLMs: A Neuro-Symbolic Approach**|Mohammed Maree et.al.|[2501.06628v1](http://arxiv.org/abs/2501.06628v1)|null|
|**2025-01-11**|**MedCT: A Clinical Terminology Graph for Generative AI Applications in Healthcare**|Ye Chen et.al.|[2501.06465v2](http://arxiv.org/abs/2501.06465v2)|null|
|**2025-01-10**|**Dynamics of "Spontaneous" Topic Changes in Next Token Prediction with Self-Attention**|Mumin Jia et.al.|[2501.06382v1](http://arxiv.org/abs/2501.06382v1)|null|
|**2025-01-10**|**Network Diffuser for Placing-Scheduling Service Function Chains with Inverse Demonstration**|Zuyuan Zhang et.al.|[2501.05673v1](http://arxiv.org/abs/2501.05673v1)|null|
|**2025-01-08**|**FlairGPT: Repurposing LLMs for Interior Designs**|Gabrielle Littlefair et.al.|[2501.04648v1](http://arxiv.org/abs/2501.04648v1)|null|
|**2025-01-08**|**CGP-Tuning: Structure-Aware Soft Prompt Tuning for Code Vulnerability Detection**|Ruijun Feng et.al.|[2501.04510v1](http://arxiv.org/abs/2501.04510v1)|null|
|**2025-01-08**|**S2 Chunking: A Hybrid Framework for Document Segmentation Through Integrated Spatial and Semantic Analysis**|Prashant Verma et.al.|[2501.05485v1](http://arxiv.org/abs/2501.05485v1)|[link](https://github.com/Vprashant/s2-chunking-lib)|
|**2025-01-08**|**Multimodal Graph Constrastive Learning and Prompt for ChartQA**|Yue Dai et.al.|[2501.04303v1](http://arxiv.org/abs/2501.04303v1)|null|
|**2025-01-07**|**Detection, Retrieval, and Explanation Unified: A Violence Detection System Based on Knowledge Graphs and GAT**|Wen-Dong Jiang et.al.|[2501.06224v1](http://arxiv.org/abs/2501.06224v1)|null|
|**2025-01-07**|**Applying Large Language Models in Knowledge Graph-based Enterprise Modeling: Challenges and Opportunities**|Benedikt Reitemeyer et.al.|[2501.03566v1](http://arxiv.org/abs/2501.03566v1)|null|
|**2025-01-07**|**KG-TRICK: Unifying Textual and Relational Information Completion of Knowledge for Multilingual Knowledge Graphs**|Zelin Zhou et.al.|[2501.03560v1](http://arxiv.org/abs/2501.03560v1)|null|
|**2025-01-06**|**Semantic Captioning: Benchmark Dataset and Graph-Aware Few-Shot In-Context Learning for SQL2Text**|Ali Al-Lawati et.al.|[2501.03166v1](http://arxiv.org/abs/2501.03166v1)|[link](https://github.com/aliwister/ast-icl)|
|**2025-01-06**|**Personalized Fashion Recommendation with Image Attributes and Aesthetics Assessment**|Chongxian Chen et.al.|[2501.03085v1](http://arxiv.org/abs/2501.03085v1)|null|
|**2025-01-06**|**Graph-based Retrieval Augmented Generation for Dynamic Few-shot Text Classification**|Yubo Wang et.al.|[2501.02844v1](http://arxiv.org/abs/2501.02844v1)|null|
|**2025-01-06**|**KG-CF: Knowledge Graph Completion with Context Filtering under the Guidance of Large Language Models**|Zaiyi Zheng et.al.|[2501.02711v1](http://arxiv.org/abs/2501.02711v1)|null|
|**2025-01-04**|**Graph-Aware Isomorphic Attention for Adaptive Dynamics in Transformers**|Markus J. Buehler et.al.|[2501.02393v2](http://arxiv.org/abs/2501.02393v2)|[link](https://github.com/lamm-mit/graph-aware-transformers)|
|**2025-01-04**|**What Kind of Visual Tokens Do We Need? Training-free Visual Token Pruning for Multi-modal Large Language Models from the Perspective of Graph**|Yutao Jiang et.al.|[2501.02268v1](http://arxiv.org/abs/2501.02268v1)|[link](https://github.com/jytmelon/g-prune)|
|**2025-01-04**|**Personalized Graph-Based Retrieval for Large Language Models**|Steven Au et.al.|[2501.02157v1](http://arxiv.org/abs/2501.02157v1)|[link](https://github.com/pgraphrag-benchmark/pgr-llm)|
|**2025-01-03**|**Cold-Start Recommendation towards the Era of Large Language Models (LLMs): A Comprehensive Survey and Roadmap**|Weizhi Zhang et.al.|[2501.01945v2](http://arxiv.org/abs/2501.01945v2)|[link](https://github.com/yuanchenbei/awesome-cold-start-recommendation)|
|**2025-01-03**|**Multimodal Contrastive Representation Learning in Augmented Biomedical Knowledge Graphs**|Tien Dang et.al.|[2501.01644v1](http://arxiv.org/abs/2501.01644v1)|[link](https://github.com/hysonlab/biomedkg)|
|**2025-01-02**|**Enhancing Uncertainty Modeling with Semantic Graph for Hallucination Detection**|Kedi Chen et.al.|[2501.02020v1](http://arxiv.org/abs/2501.02020v1)|null|
|**2025-01-01**|**Unfolding the Headline: Iterative Self-Questioning for News Retrieval and Timeline Summarization**|Weiqi Wu et.al.|[2501.00888v1](http://arxiv.org/abs/2501.00888v1)|[link](https://github.com/Alibaba-NLP/CHRONOS)|
|**2025-01-01**|**Breaking Through the Spike: Spike Window Decoding for Accelerated and Precise Automatic Speech Recognition**|Wei Zhang et.al.|[2501.03257v1](http://arxiv.org/abs/2501.03257v1)|null|
|**2025-01-01**|**SmartSpatial: Enhancing the 3D Spatial Arrangement Capabilities of Stable Diffusion Models and Introducing a Novel 3D Spatial Evaluation Framework**|Mao Xun Huang et.al.|[2501.01998v1](http://arxiv.org/abs/2501.01998v1)|null|
|**2024-12-31**|**Causal Graph Guided Steering of LLM Values via Prompts and Sparse Autoencoders**|Yipeng Kang et.al.|[2501.00581v1](http://arxiv.org/abs/2501.00581v1)|null|
|**2024-12-31**|**CancerKG.ORG A Web-scale, Interactive, Verifiable Knowledge Graph-LLM Hybrid for Assisting with Optimal Cancer Treatment and Care**|Michael Gubanov et.al.|[2501.00223v1](http://arxiv.org/abs/2501.00223v1)|null|
|**2024-12-31**|**The Potential of LLMs in Automating Software Testing: From Generation to Reporting**|Betim Sherifi et.al.|[2501.00217v1](http://arxiv.org/abs/2501.00217v1)|null|
|**2024-12-30**|**Detection-Fusion for Knowledge Graph Extraction from Videos**|Taniya Das et.al.|[2501.00136v1](http://arxiv.org/abs/2501.00136v1)|[link](https://github.com/Taniya-Das/video_annotation)|
|**2024-12-30**|**Machine Learning-Based Security Policy Analysis**|Krish Jain et.al.|[2501.00085v2](http://arxiv.org/abs/2501.00085v2)|null|
|**2024-12-30**|**KARPA: A Training-free Method of Adapting Knowledge Graph as References for Large Language Model's Reasoning Path Aggregation**|Siyuan Fang et.al.|[2412.20995v1](http://arxiv.org/abs/2412.20995v1)|null|
|**2024-12-30**|**Ontology-grounded Automatic Knowledge Graph Construction by LLM under Wikidata schema**|Xiaohan Feng et.al.|[2412.20942v1](http://arxiv.org/abs/2412.20942v1)|null|
|**2024-12-29**|**ICLR: In-Context Learning of Representations**|Core Francisco Park et.al.|[2501.00070v1](http://arxiv.org/abs/2501.00070v1)|null|
|**2024-12-28**|**Topic-Aware Knowledge Graph with Large Language Models for Interoperability in Recommender Systems**|Minhye Jeon et.al.|[2412.20163v2](http://arxiv.org/abs/2412.20163v2)|null|
|**2024-12-28**|**From Generalist to Specialist: A Survey of Large Language Models for Chemistry**|Yang Han et.al.|[2412.19994v1](http://arxiv.org/abs/2412.19994v1)|[link](https://github.com/opendfm/llm4chemistry)|
|**2024-12-27**|**Toward Adaptive Reasoning in Large Language Models with Thought Rollback**|Sijia Chen et.al.|[2412.19707v1](http://arxiv.org/abs/2412.19707v1)|[link](https://github.com/iQua/llmpebase)|
|**2024-12-26**|**Dynamic Skill Adaptation for Large Language Models**|Jiaao Chen et.al.|[2412.19361v1](http://arxiv.org/abs/2412.19361v1)|null|
|**2024-12-26**|**Relation-aware Hierarchical Prompt for Open-vocabulary Scene Graph Generation**|Tao Liu et.al.|[2412.19021v1](http://arxiv.org/abs/2412.19021v1)|null|
|**2024-12-25**|**PhyloGen: Language Model-Enhanced Phylogenetic Inference via Graph Structure Generation**|ChenRui Duan et.al.|[2412.18827v1](http://arxiv.org/abs/2412.18827v1)|null|
|**2024-12-24**|**CypherBench: Towards Precise Retrieval over Full-scale Modern Knowledge Graphs in the LLM Era**|Yanlin Feng et.al.|[2412.18702v1](http://arxiv.org/abs/2412.18702v1)|[link](https://github.com/megagonlabs/cypherbench)|
|**2024-12-24**|**From Hallucinations to Facts: Enhancing Language Models with Curated Knowledge Graphs**|Ratnesh Kumar Joshi et.al.|[2412.18672v1](http://arxiv.org/abs/2412.18672v1)|null|
|**2024-12-24**|**Harnessing Large Language Models for Knowledge Graph Question Answering via Adaptive Multi-Aspect Retrieval-Augmentation**|Derong Xu et.al.|[2412.18537v2](http://arxiv.org/abs/2412.18537v2)|[link](https://github.com/Applied-Machine-Learning-Lab/AMAR)|
|**2024-12-24**|**DynaGRAG: Improving Language Understanding and Generation through Dynamic Subgraph Representation in Graph Retrieval-Augmented Generation**|Karishma Thakrar et.al.|[2412.18644v1](http://arxiv.org/abs/2412.18644v1)|null|
|**2024-12-24**|**Is Large Language Model Good at Triple Set Prediction? An Empirical Study**|Yuan Yuan et.al.|[2412.18443v1](http://arxiv.org/abs/2412.18443v1)|null|
|**2024-12-24**|**Investigating Large Language Models for Code Vulnerability Detection: An Experimental Study**|Xuefeng Jiang et.al.|[2412.18260v2](http://arxiv.org/abs/2412.18260v2)|[link](https://github.com/sakirinn/llm4cvd)|
|**2024-12-24**|**An Automatic Graph Construction Framework based on Large Language Models for Recommendation**|Rong Shan et.al.|[2412.18241v1](http://arxiv.org/abs/2412.18241v1)|[link](https://github.com/lavieenrose365/autograph)|
|**2024-12-23**|**CARL-GT: Evaluating Causal Reasoning Capabilities of Large Language Models**|Ruibo Tu et.al.|[2412.17970v1](http://arxiv.org/abs/2412.17970v1)|[link](https://github.com/turuibo/cautabbench)|
|**2024-12-23**|**Path-of-Thoughts: Extracting and Following Paths for Robust Relational Reasoning with Large Language Models**|Ge Zhang et.al.|[2412.17963v1](http://arxiv.org/abs/2412.17963v1)|null|
|**2024-12-23**|**ResearchTown: Simulator of Human Research Community**|Haofei Yu et.al.|[2412.17767v1](http://arxiv.org/abs/2412.17767v1)|[link](https://github.com/ulab-uiuc/research-town)|
|**2024-12-23**|**RAGONITE: Iterative Retrieval on Induced Databases and Verbalized RDF for Conversational QA over KGs with RAG**|Rishiraj Saha Roy et.al.|[2412.17690v3](http://arxiv.org/abs/2412.17690v3)|null|
|**2024-12-23**|**A Dual-Perspective Metaphor Detection Framework Using Large Language Models**|Yujie Lin et.al.|[2412.17332v2](http://arxiv.org/abs/2412.17332v2)|[link](https://github.com/deeplearnxmu/dmd)|
|**2024-12-22**|**GraphAgent: Agentic Graph Language Assistant**|Yuhao Yang et.al.|[2412.17029v1](http://arxiv.org/abs/2412.17029v1)|null|
|**2024-12-22**|**Enhancing Supply Chain Transparency in Emerging Economies Using Online Contents and LLMs**|Bohan Jin et.al.|[2412.16922v1](http://arxiv.org/abs/2412.16922v1)|null|
|**2024-12-22**|**KG4Diagnosis: A Hierarchical Multi-Agent LLM Framework with Knowledge Graph Enhancement for Medical Diagnosis**|Kaiwen Zuo et.al.|[2412.16833v2](http://arxiv.org/abs/2412.16833v2)|null|
|**2024-12-21**|**Apples to Apples: Establishing Comparability in Knowledge Generation Tasks Involving Users**|Christophe Debruyne et.al.|[2412.16766v1](http://arxiv.org/abs/2412.16766v1)|null|
|**2024-12-21**|**Self-guided Knowledgeable Network of Thoughts: Amplifying Reasoning with Large Language Models**|Chao-Chi Chen et.al.|[2412.16533v1](http://arxiv.org/abs/2412.16533v1)|null|
|**2024-12-21**|**Beyond End-to-End VLMs: Leveraging Intermediate Text Representations for Superior Flowchart Understanding**|Junyi Ye et.al.|[2412.16420v1](http://arxiv.org/abs/2412.16420v1)|[link](https://github.com/junyiye/textflow)|
|**2024-12-20**|**HybGRAG: Hybrid Retrieval-Augmented Generation on Textual and Relational Knowledge Bases**|Meng-Chieh Lee et.al.|[2412.16311v1](http://arxiv.org/abs/2412.16311v1)|null|

#### Abstracts
##### **Evaluating and Improving Graph to Text Generation with Large Language Models**
2501.14497v1 by Jie He, Yijun Yang, Wanqiu Long, Deyi Xiong, Victor Gutierrez Basulto, Jeff Z. Pan

Large language models (LLMs) have demonstrated immense potential across
various tasks. However, research for exploring and improving the capabilities
of LLMs in interpreting graph structures remains limited. To address this gap,
we conduct a comprehensive evaluation of prompting current open-source LLMs on
graph-to-text generation tasks. Although we explored the optimal prompting
strategies and proposed a novel and effective diversity-difficulty-based
few-shot sample selection method, we found that the improvements from
tuning-free approaches were incremental, as LLMs struggle with planning on
complex graphs, particularly those with a larger number of triplets. To further
improve LLMs in planning with graph sequences and grounding in truth, we
introduce a new graph-to-text dataset, PlanGTG, annotated with two sub-tasks:
reordering and attribution. Through extensive automatic and human evaluations,
we demonstrate significant improvements in the quality of generated text from
both few-shot learning and fine-tuning perspectives using the PlanGTG dataset.
Our study paves the way for new research directions in graph-to-text
generation. PlanGTG datasets can be found in https://github.com/probe2/kg_text.

æè¦ï¼å¤§åèªè¨æ¨¡åï¼LLMï¼å·²å¨åç¨®ä»»åä¸­å±ç¾åºå·¨å¤§çæ½åãç¶èï¼æ¢ç´¢åæå LLM å¨è©®éåå½¢çµæ§æ¹é¢çè½åçç ç©¶ä»ç¶æéãçºäºè§£æ±ºéåå·®è·ï¼æåå°æç¤ºç®åéæºç LLM å·è¡åå½¢è½æå­çæä»»åé²è¡å¨é¢è©ä¼°ãåç®¡æåæ¢ç´¢äºæä½³æç¤ºç­ç¥ä¸¦æåºäºä¸ç¨®æ°ç©ä¸ææçåºæ¼å¤æ¨£æ§é£åº¦çå°æ¨£æ¬é¸ææ¹æ³ï¼ä½æåç¼ç¾ç¡èª¿æ ¡æ¹æ³çæ¹é²æ¯æ¼¸é²çï¼å çº LLM é£ä»¥è¦åè¤éçåå½¢ï¼ç¹å¥æ¯é£äºå·æè¼å¤ä¸åçµçåå½¢ãçºäºé²ä¸æ­¥æå LLM å¨åå½¢åºåè¦ååçå¯¦ä¾ææ¹é¢çè½åï¼æåå¼å¥äºä¸åæ°çåå½¢è½æå­è³æé PlanGTGï¼ä¸¦è¨»è§£äºå©åå­ä»»åï¼éæ°æåºåæ­¸å ãééå»£æ³çèªåååäººå·¥è©ä¼°ï¼æåè­æäºä½¿ç¨ PlanGTG è³æéå¾å°æ¨£æ¬å­¸ç¿åå¾®èª¿è§åº¦ç¢çæå­çåè³ªæé¡¯èæåãæåçç ç©¶çºåå½¢è½æå­çæä¸­çæ°ç ç©¶æ¹åéªè·¯ãPlanGTG è³æéå¯ä»¥å¨ https://github.com/probe2/kg_text ä¸­æ¾å°ã

##### **Fast Think-on-Graph: Wider, Deeper and Faster Reasoning of Large Language Model on Knowledge Graph**
2501.14300v1 by Xujian Liang, Zhaoquan Gu

Graph Retrieval Augmented Generation (GRAG) is a novel paradigm that takes
the naive RAG system a step further by integrating graph information, such as
knowledge graph (KGs), into large-scale language models (LLMs) to mitigate
hallucination. However, existing GRAG still encounter limitations: 1) simple
paradigms usually fail with the complex problems due to the narrow and shallow
correlations capture from KGs 2) methods of strong coupling with KGs tend to be
high computation cost and time consuming if the graph is dense. In this paper,
we propose the Fast Think-on-Graph (FastToG), an innovative paradigm for
enabling LLMs to think ``community by community" within KGs. To do this,
FastToG employs community detection for deeper correlation capture and two
stages community pruning - coarse and fine pruning for faster retrieval.
Furthermore, we also develop two Community-to-Text methods to convert the graph
structure of communities into textual form for better understanding by LLMs.
Experimental results demonstrate the effectiveness of FastToG, showcasing
higher accuracy, faster reasoning, and better explainability compared to the
previous works.

æè¦ï¼åè¡¨æª¢ç´¢å¢å¼·çæ (GRAG) æ¯ä¸ç¨®æ°ç©çç¯ä¾ï¼å®ééå°åè¡¨è³è¨ï¼ä¾å¦ç¥è­åè¡¨ (KG)) æ´åå°å¤§åèªè¨æ¨¡å (LLM) ä¸­ï¼é²ä¸æ­¥æåäºæ¨¸ç´ ç RAG ç³»çµ±ä»¥æ¸è¼å¹»è¦ºãç¶èï¼ç¾æç GRAG ä»æéå°éå¶ï¼1) ç°¡å®çç¯ä¾éå¸¸æå å¾ KG ä¸­æ·åçéè¯æ§ç¹éä¸æ·ºèèç¡æ³è§£æ±ºè¤éçåé¡ 2) å¦æåè¡¨å¾å¯éï¼è KG å¼·è¦åçæ¹æ³å¾å¾æå°è´é«éç®ææ¬åèæãå¨æ¬æä¸­ï¼æåæåºäº Fast Think-on-Graph (FastToG)ï¼éæ¯ä¸ç¨®åµæ°çç¯ä¾ï¼å¯è® LLM å¨ KG ä¸­ãéåç¤¾ç¾¤ãé²è¡æèãçºæ­¤ï¼FastToG ä½¿ç¨ç¤¾ç¾¤åµæ¸¬ä¾æ·åæ´æ·±å¥çéè¯æ§ï¼ä¸¦ä½¿ç¨å©åéæ®µçç¤¾ç¾¤ä¿®åªï¼ç²ç¥ä¿®åªåç²¾ç´°ä¿®åªï¼ä¾å å¿«æª¢ç´¢éåº¦ãæ­¤å¤ï¼æåééç¼äºå©ç¨®ç¤¾ç¾¤å°æå­çæ¹æ³ï¼å°ç¤¾ç¾¤çåè¡¨çµæ§è½æçºæå­å½¢å¼ï¼ä»¥ä¾¿ LLM æ´å®¹æçè§£ãå¯¦é©çµæè­æäº FastToG çæææ§ï¼èååçç ç©¶ç¸æ¯ï¼å±ç¤ºåºæ´é«çæºç¢ºæ§ãæ´å¿«çæ¨çéåº¦åæ´å¥½çå¯è§£éæ§ã

##### **Top Ten Challenges Towards Agentic Neural Graph Databases**
2501.14224v1 by Jiaxin Bai, Zihao Wang, Yukun Zhou, Hang Yin, Weizhi Fei, Qi Hu, Zheye Deng, Jiayang Cheng, Tianshi Zheng, Hong Ting Tsang, Yisen Gao, Zhongwei Xie, Yufei Li, Lixin Fan, Binhang Yuan, Wei Wang, Lei Chen, Xiaofang Zhou, Yangqiu Song

Graph databases (GDBs) like Neo4j and TigerGraph excel at handling
interconnected data but lack advanced inference capabilities. Neural Graph
Databases (NGDBs) address this by integrating Graph Neural Networks (GNNs) for
predictive analysis and reasoning over incomplete or noisy data. However, NGDBs
rely on predefined queries and lack autonomy and adaptability. This paper
introduces Agentic Neural Graph Databases (Agentic NGDBs), which extend NGDBs
with three core functionalities: autonomous query construction, neural query
execution, and continuous learning. We identify ten key challenges in realizing
Agentic NGDBs: semantic unit representation, abductive reasoning, scalable
query execution, and integration with foundation models like large language
models (LLMs). By addressing these challenges, Agentic NGDBs can enable
intelligent, self-improving systems for modern data-driven applications, paving
the way for adaptable and autonomous data management solutions.

æè¦ï¼åå½¢è³æåº«ï¼GDBï¼ï¼ä¾å¦ Neo4j å TigerGraphï¼æé·èçç¸äºé£æ¥çè³æï¼ä½ç¼ºä¹é²éçæ¨è«è½åãç¥ç¶åå½¢è³æåº«ï¼NGDBï¼ééæ´ååå½¢ç¥ç¶ç¶²è·¯ï¼GNNï¼ä¾è§£æ±ºéååé¡ï¼ä»¥é²è¡é æ¸¬åæåå°ä¸å®æ´ææéè¨çè³æé²è¡æ¨çãç¶èï¼NGDB ä¾è³´æ¼é åå®ç¾©çæ¥è©¢ï¼ä¸¦ä¸ç¼ºä¹èªä¸»æ§åé©ææ§ãæ¬æä»ç´¹äºä»£çç¥ç¶åå½¢è³æåº«ï¼Agentic NGDBï¼ï¼å®ä»¥ä¸é æ ¸å¿åè½æ´åäº NGDBï¼èªåæ¥è©¢å»ºæ§ãç¥ç¶æ¥è©¢å·è¡åæçºå­¸ç¿ãæåæ¾åºå¯¦ç¾ Agentic NGDB çåå¤§ééµææ°ï¼èªç¾©å®åè¡¨ç¤ºãæ¼ç¹¹æ¨çãå¯æ´åæ¥è©¢å·è¡ï¼ä»¥åèåºç¤æ¨¡åï¼ä¾å¦å¤§åèªè¨æ¨¡å (LLM)ï¼æ´åãééè§£æ±ºéäºææ°ï¼Agentic NGDB å¯ä»¥çºç¾ä»£è³æé©åæç¨æé æºæ§ä¸èªææ¹åçç³»çµ±ï¼çºé©ææ§åèªä¸»è³æç®¡çè§£æ±ºæ¹æ¡éªè·¯ã

##### **GraphRAG under Fire**
2501.14050v1 by Jiacheng Liang, Yuhui Wang, Changjiang Li, Rongyi Zhu, Tanqiu Jiang, Neil Gong, Ting Wang

GraphRAG advances retrieval-augmented generation (RAG) by structuring
external knowledge as multi-scale knowledge graphs, enabling language models to
integrate both broad context and granular details in their reasoning. While
GraphRAG has demonstrated success across domains, its security implications
remain largely unexplored. To bridge this gap, this work examines GraphRAG's
vulnerability to poisoning attacks, uncovering an intriguing security paradox:
compared to conventional RAG, GraphRAG's graph-based indexing and retrieval
enhance resilience against simple poisoning attacks; meanwhile, the same
features also create new attack surfaces. We present GRAGPoison, a novel attack
that exploits shared relations in the knowledge graph to craft poisoning text
capable of compromising multiple queries simultaneously. GRAGPoison employs
three key strategies: i) relation injection to introduce false knowledge, ii)
relation enhancement to amplify poisoning influence, and iii) narrative
generation to embed malicious content within coherent text. Empirical
evaluation across diverse datasets and models shows that GRAGPoison
substantially outperforms existing attacks in terms of effectiveness (up to 98%
success rate) and scalability (using less than 68% poisoning text). We also
explore potential defensive measures and their limitations, identifying
promising directions for future research.

æè¦ï¼GraphRAG ééå°å¤é¨ç¥è­çµæ§åçºå¤å°ºåº¦ç¥è­åè­ï¼æ¨åäºæª¢ç´¢å¢å¼·çæ (RAG)ï¼ä½¿èªè¨æ¨¡åè½å¤ å¨å¶æ¨çä¸­æ´åå»£æ³çèæ¯åç´°å¾®çç´°ç¯ãåç®¡ GraphRAG å¨ååé åé½å·²å±ç¾åºæåï¼ä½å¶å®å¨æ§å½±é¿å¨å¾å¤§ç¨åº¦ä¸ä»æªè¢«æ¢ç´¢ãçºäºå½è£éä¸å·®è·ï¼æ¬ç ç©¶æ¢è¨äº GraphRAG å°ææ¯æ»æçèå¼±æ§ï¼æ­ç¤ºäºä¸åæè¶£çå®å¨æè«ï¼èå³çµ±ç RAG ç¸æ¯ï¼GraphRAG åºæ¼åè¡¨çç´¢å¼åæª¢ç´¢å¢å¼·äºå°ç°¡å®ææ¯æ»æçéæ§ï¼åæï¼ç¸åçç¹å¾µä¹åµé äºæ°çæ»æé¢ãæåæåºäº GRAGPoisonï¼éæ¯ä¸ç¨®æ°ç©çæ»æï¼å®å©ç¨ç¥è­åè­ä¸­çå±äº«éä¿ä¾è£½ä½ä¸­æ¯ææ¬ï¼è½å¤ åæå±å®³å¤åæ¥è©¢ãGRAGPoison æ¡ç¨äºä¸é ééµç­ç¥ï¼i) éä¿æ³¨å¥ä»¥å¼å¥é¯èª¤çç¥è­ï¼ii) éä¿å¢å¼·ä»¥æ´å¤§ææ¯å½±é¿ï¼ä»¥å iii) æäºçæä»¥å°æ¡æå§å®¹åµå¥é£è²«çææ¬ä¸­ãå¨åç¨®æ¸æéåæ¨¡åä¸çç¶é©è©ä¼°è¡¨æï¼GRAGPoison å¨æææ§ï¼æåçé«é 98%ï¼åå¯æ´å±æ§ï¼ä½¿ç¨ä¸å° 68% çææ¯ææ¬ï¼æ¹é¢é½æé¡¯åªæ¼ç¾æçæ»æãæåéæ¢è¨äºæ½å¨çé²ç¦¦æªæ½åå¶å±éæ§ï¼ç¢ºå®äºæªä¾ç ç©¶çæå¸æçæ¹åã

##### **EICopilot: Search and Explore Enterprise Information over Large-scale Knowledge Graphs with LLM-driven Agents**
2501.13746v1 by Yuhui Yun, Huilong Ye, Xinru Li, Ruojia Li, Jingfeng Deng, Li Li, Haoyi Xiong

The paper introduces EICopilot, an novel agent-based solution enhancing
search and exploration of enterprise registration data within extensive online
knowledge graphs like those detailing legal entities, registered capital, and
major shareholders. Traditional methods necessitate text-based queries and
manual subgraph explorations, often resulting in time-consuming processes.
EICopilot, deployed as a chatbot via Baidu Enterprise Search, improves this
landscape by utilizing Large Language Models (LLMs) to interpret natural
language queries. This solution automatically generates and executes Gremlin
scripts, providing efficient summaries of complex enterprise relationships.
Distinct feature a data pre-processing pipeline that compiles and annotates
representative queries into a vector database of examples for In-context
learning (ICL), a comprehensive reasoning pipeline combining Chain-of-Thought
with ICL to enhance Gremlin script generation for knowledge graph search and
exploration, and a novel query masking strategy that improves intent
recognition for heightened script accuracy. Empirical evaluations demonstrate
the superior performance of EICopilot, including speed and accuracy, over
baseline methods, with the \emph{Full Mask} variant achieving a syntax error
rate reduction to as low as 10.00% and an execution correctness of up to
82.14%. These components collectively contribute to superior querying
capabilities and summarization of intricate datasets, positioning EICopilot as
a groundbreaking tool in the exploration and exploitation of large-scale
knowledge graphs for enterprise information search.

æè¦ï¼æ¬æä»ç´¹äº EICopilotï¼éæ¯ä¸ç¨®åºæ¼ä»£ççæ°åè§£æ±ºæ¹æ¡ï¼å¯å¢å¼·å¨å»£æ³çç·ä¸ç¥è­åè­ä¸­æå°åæ¢ç´¢ä¼æ¥­è¨»åè³æï¼ä¾å¦è©³ç´°èªªææ³å¾å¯¦é«ãè¨»åè³æ¬åä¸»è¦è¡æ±çè³æãå³çµ±æ¹æ³éè¦åºæ¼æå­çæ¥è©¢åæåå­åæ¢ç´¢ï¼éå¸¸æå°è´èæçæµç¨ãEICopilot é¨ç½²çºç¾åº¦ä¼æ¥­æå°çèå¤©æ©å¨äººï¼ééå©ç¨å¤§åèªè¨æ¨¡å (LLM) ä¾è©®éèªç¶èªè¨æ¥è©¢ï¼é²èæ¹åéé æè¡ãæ­¤è§£æ±ºæ¹æ¡æèªåç¢çä¸¦å·è¡ Gremlin è³æ¬ï¼æä¾è¤éä¼æ¥­éä¿çæææè¦ãå¶ç¨ç¹åè½çºè³æåèçç®¡ç·ï¼å¯å°å·ä»£è¡¨æ§çæ¥è©¢ç·¨è­¯ä¸¦è¨»è§£å°ç¯ä¾çåéè³æåº«ä¸­ï¼ä»¥é²è¡èçµ¡ä¸­å­¸ç¿ (ICL)ï¼éæ¯ä¸åçµåäºæèéè ICL çç¶åæ¨çç®¡ç·ï¼ç¨æ¼å¢å¼· Gremlin è³æ¬ç¢çï¼ä»¥é²è¡ç¥è­åè­æå°åæ¢ç´¢ï¼ä»¥åä¸ç¨®æ°ç©çæ¥è©¢é®ç½©ç­ç¥ï¼å¯æ¹åæåè¾¨è­ï¼é²èæé«è³æ¬æºç¢ºåº¦ãå¯¦è­è©ä¼°é¡¯ç¤ºï¼EICopilot çæè½åªæ¼åºç·æ¹æ³ï¼åæ¬éåº¦åæºç¢ºåº¦ï¼å¶ä¸­ãå®æ´é®ç½©ãè®é«å°èªæ³é¯èª¤çéä½è³ä½æ¼ 10.00%ï¼å·è¡æ­£ç¢ºçé«é 82.14%ãéäºåä»¶å±åä¿æäºåªç°çæ¥è©¢åè½åè¤éè³æéçæè¦ï¼å° EICopilot å®ä½çºæ¢ç´¢åå©ç¨å¤§è¦æ¨¡ç¥è­åè­é²è¡ä¼æ¥­è³è¨æå°çåµæ°å·¥å·ã

##### **Pseudocode-Injection Magic: Enabling LLMs to Tackle Graph Computational Tasks**
2501.13731v1 by Chang Gong, Wanrui Bian, Zhijie Zhang, Weiguo Zheng

Graph computational tasks are inherently challenging and often demand the
development of advanced algorithms for effective solutions. With the emergence
of large language models (LLMs), researchers have begun investigating their
potential to address these tasks. However, existing approaches are constrained
by LLMs' limited capability to comprehend complex graph structures and their
high inference costs, rendering them impractical for handling large-scale
graphs. Inspired by human approaches to graph problems, we introduce a novel
framework, PIE (Pseudocode-Injection-Enhanced LLM Reasoning for Graph
Computational Tasks), which consists of three key steps: problem understanding,
prompt design, and code generation. In this framework, LLMs are tasked with
understanding the problem and extracting relevant information to generate
correct code. The responsibility for analyzing the graph structure and
executing the code is delegated to the interpreter. We inject task-related
pseudocodes into the prompts to further assist the LLMs in generating efficient
code. We also employ cost-effective trial-and-error techniques to ensure that
the LLM-generated code executes correctly. Unlike other methods that require
invoking LLMs for each individual test case, PIE only calls the LLM during the
code generation phase, allowing the generated code to be reused and
significantly reducing inference costs. Extensive experiments demonstrate that
PIE outperforms existing baselines in terms of both accuracy and computational
efficiency.

æè¦ï¼åè¡¨è¨ç®ä»»åæ¬è³ªä¸å·æææ°æ§ï¼èä¸éå¸¸éè¦éç¼åé²çæ¼ç®æ³æè½ææè§£æ±ºãé¨èå¤§åèªè¨æ¨¡å (LLM) çåºç¾ï¼ç ç©¶äººå¡å·²éå§æ¢è¨å¶è§£æ±ºéäºä»»åçå¯è½æ§ãç¶èï¼ç¾ææ¹æ³åå° LLM çè§£è¤éåå½¢çµæ§çè½åæéä»¥åå¶é«æ¨çææ¬çéå¶ï¼éä½¿å¾å®åä¸åå¯¦éå°èçå¤§è¦æ¨¡åå½¢ãåå°äººé¡è§£æ±ºåå½¢åé¡çæ¹æ³åç¼ï¼æåå¼å¥äº PIEï¼å½ä»£ç¢¼æ³¨å¥å¢å¼· LLM åå½¢è¨ç®ä»»åæ¨çï¼éåæ°æ¡æ¶ï¼å®åå«ä¸åééµæ­¥é©ï¼åé¡çè§£ãæç¤ºè¨­è¨åä»£ç¢¼çæãå¨æ­¤æ¡æ¶ä¸­ï¼LLM çä»»åæ¯çè§£åé¡ä¸¦æ·åç¸éè³è¨ä»¥ç¢çæ­£ç¢ºçä»£ç¢¼ãåæåå½¢çµæ§åå·è¡ä»£ç¢¼çè²¬ä»»å§æ´¾çµ¦è§£éå¨ãæåå°èä»»åç¸éçå½ä»£ç¢¼æ³¨å¥æç¤ºä¸­ï¼ä»¥é²ä¸æ­¥åå© LLM ç¢çææçä»£ç¢¼ãæåéæ¡ç¨å·æææ¬æççè©¦é¯æè¡ï¼ä»¥ç¢ºä¿ LLM çæçä»£ç¢¼æ­£ç¢ºå·è¡ãèéè¦çºæ¯ååå¥æ¸¬è©¦æ¡ä¾å¼å« LLM çå¶ä»æ¹æ³ä¸åï¼PIE åå¨ä»£ç¢¼ç¢çéæ®µå¼å« LLMï¼åè¨±éè¤ä½¿ç¨ç¢ççä»£ç¢¼ä¸¦å¤§å¹éä½æ¨çææ¬ãå¤§éçå¯¦é©è­æï¼PIE å¨æºç¢ºæ§åè¨ç®æçæ¹é¢é½åªæ¼ç¾æçåºæºã

##### **CAPRAG: A Large Language Model Solution for Customer Service and Automatic Reporting using Vector and Graph Retrieval-Augmented Generation**
2501.13993v1 by Hamza Landolsi, Kais Letaief, Nizar Taghouti, Ines Abdeljaoued-Tej

The introduction of new features and services in the banking sector often
overwhelms customers, creating an opportunity for banks to enhance user
experience through financial chatbots powered by large language models (LLMs).
We initiated an AI agent designed to provide customers with relevant
information about banking services and insights from annual reports. We
proposed a hybrid Customer Analysis Pipeline Retrieval-Augmented Generation
(CAPRAG) that effectively addresses both relationship-based and contextual
queries, thereby improving customer engagement in the digital banking
landscape. To implement this, we developed a processing pipeline to refine text
data, which we utilized in two main frameworks: Vector RAG and Graph RAG. This
dual approach enables us to populate both vector and graph databases with
processed data for efficient retrieval. The Cypher query component is employed
to effectively query the graph database. When a user submits a query, it is
first expanded by a query expansion module before being routed to construct a
final query from the hybrid Knowledge Base (KB). This final query is then sent
to an open-source LLM for response generation. Overall, our innovative,
designed to international banks, serves bank's customers in an increasingly
complex digital environment, enhancing clarity and accessibility of
information.

æè¦ï¼éè¡æ¥­ä¸­æ°åè½åæåçæ¨åºç¶å¸¸è®å®¢æ¶æå°ä¸ç¥ææªï¼éçºéè¡ééå¤§åèªè¨æ¨¡å (LLM) é©åçéèèå¤©æ©å¨äººä¾æåä½¿ç¨èé«é©åµé äºæ©æãæåååäºä¸åäººå·¥æºæ§ä»£çï¼æ¨å¨çºå®¢æ¶æä¾æééè¡æååå¹´åº¦å ±åè¦è§£çç¸éè³è¨ãæåæåºäºä¸åæ··åå¼å®¢æ¶åæç®¡éæª¢ç´¢æ´åçæ (CAPRAG)ï¼å®ææå°èçåºæ¼éä¿åæå¢å¼çæ¥è©¢ï¼å¾èæåæ¸ä½éè¡ç°å¢ä¸­çå®¢æ¶åèåº¦ãçºäºå¯¦ä½éä¸é»ï¼æåéç¼äºä¸åèçç®¡éä¾ç²¾çæå­è³æï¼æåå¨å©åä¸»è¦æ¶æ§ä¸­ä½¿ç¨å®ï¼Vector RAG å Graph RAGãéç¨®éç®¡é½ä¸çæ¹æ³è®æåè½å¤ ä½¿ç¨èçéçè³æä¾å¡«è£åéååå½¢è³æåº«ï¼ä»¥å©æ¼æææª¢ç´¢ãCypher æ¥è©¢åä»¶ç¨æ¼æææ¥è©¢åå½¢è³æåº«ãç¶ä½¿ç¨èæäº¤æ¥è©¢æï¼å®æåç±æ¥è©¢æ´åæ¨¡çµæ´åï¼ç¶å¾åè·¯ç±å°æ··åå¼ç¥è­åº« (KB) ä¸­å»ºæ§æçµæ¥è©¢ãç¶å¾éåæçµæ¥è©¢æå³éçµ¦éæº LLM ä»¥ç¢çåæãæ´é«èè¨ï¼æååµæ°çè¨­è¨æåæ¼åééè¡ï¼å¨æ¥çè¤éçæ¸ä½ç°å¢ä¸­æåéè¡å®¢æ¶ï¼æåè³è¨çæ¸æ°åº¦åå¯åæ§ã

##### **Dual-Branch HNSW Approach with Skip Bridges and LID-Driven Optimization**
2501.13992v1 by Hy Nguyen, Nguyen Hung Nguyen, Nguyen Linh Bao Nguyen, Srikanth Thudumu, Hung Du, Rajesh Vasa, Kon Mouzakis

The Hierarchical Navigable Small World (HNSW) algorithm is widely used for
approximate nearest neighbor (ANN) search, leveraging the principles of
navigable small-world graphs. However, it faces some limitations. The first is
the local optima problem, which arises from the algorithm's greedy search
strategy, selecting neighbors based solely on proximity at each step. This
often leads to cluster disconnections. The second limitation is that HNSW
frequently fails to achieve logarithmic complexity, particularly in
high-dimensional datasets, due to the exhaustive traversal through each layer.
To address these limitations, we propose a novel algorithm that mitigates local
optima and cluster disconnections while enhancing the construction speed,
maintaining inference speed. The first component is a dual-branch HNSW
structure with LID-based insertion mechanisms, enabling traversal from multiple
directions. This improves outlier node capture, enhances cluster connectivity,
accelerates construction speed and reduces the risk of local minima. The second
component incorporates a bridge-building technique that bypasses redundant
intermediate layers, maintaining inference and making up the additional
computational overhead introduced by the dual-branch structure. Experiments on
various benchmarks and datasets showed that our algorithm outperforms the
original HNSW in both accuracy and speed. We evaluated six datasets across
Computer Vision (CV), and Natural Language Processing (NLP), showing recall
improvements of 18\% in NLP, and up to 30\% in CV tasks while reducing the
construction time by up to 20\% and maintaining the inference speed. We did not
observe any trade-offs in our algorithm. Ablation studies revealed that
LID-based insertion had the greatest impact on performance, followed by the
dual-branch structure and bridge-building components.

æè¦ï¼åå±¤å¯å°èªå°ä¸ç (HNSW) æ¼ç®æ³å»£æ³ç¨æ¼è¿ä¼¼æè¿é°å± (ANN) æå°ï¼ä¸¦å©ç¨å¯å°èªå°ä¸çåå½¢çåçãç¶èï¼å®é¢è¨ä¸äºéå¶ãç¬¬ä¸åæ¯å±é¨æä½³ååé¡ï¼éæºèªæ¼æ¼ç®æ³çè²ªå©ªæå°ç­ç¥ï¼å¨æ¯åæ­¥é©ä¸­åæ ¹æé°è¿åº¦ä¾é¸æé°å±ãééå¸¸æå°è´ç¾¤éæ·ç·ãç¬¬äºåéå¶æ¯ï¼ç±æ¼ééæ¯ä¸å±¤ççª®èå¼éæ­·ï¼HNSW å¸¸å¸¸ç¡æ³å¨é«ç¶­åº¦è³æéä¸­éæå°æ¸è¤éåº¦ãçºäºè§£æ±ºéäºéå¶ï¼æåæåºäºä¸ç¨®æ°çæ¼ç®æ³ï¼å®å¯ä»¥æ¸è¼å±é¨æä½³ååç¾¤éæ·ç·ï¼åææé«å»ºæ§éåº¦ï¼ä¸¦ç¶­ææ¨è«éåº¦ãç¬¬ä¸åçµæé¨åæ¯ä¸åå·æåºæ¼ LID çæå¥æ©å¶çéåæ¯ HNSW çµæ§ï¼å®è½å¾å¤åæ¹åé²è¡éæ­·ãéæ¹åäºç°å¸¸å¼ç¯é»çæ·åï¼å¢å¼·äºç¾¤éé£éæ§ï¼å éäºå»ºæ§éåº¦ï¼ä¸¦éä½äºå±é¨æå°å¼çé¢¨éªãç¬¬äºåçµæé¨ååå«ä¸ç¨®æ©æ¨å»ºæ§æè¡ï¼å®ç¹éäºå¤é¤çä¸­éå±¤ï¼ç¶­ææ¨è«ä¸¦å½è£äºéåæ¯çµæ§æå¸¶ä¾çé¡å¤éç®è² æãå¨åç¨®åºæºåè³æéä¸çå¯¦é©é¡¯ç¤ºï¼æåçæ¼ç®æ³å¨æºç¢ºåº¦åéåº¦ä¸é½åªæ¼åå§ç HNSWãæåè©ä¼°äºé»è¦è¦è¦º (CV) åèªç¶èªè¨èç (NLP) ä¸­çå­åè³æéï¼é¡¯ç¤º NLP ä¸­çå¬åçæé«äº 18%ï¼CV ä»»åä¸­æé«äº 30%ï¼åæå°å»ºæ§æéç¸®ç­äº 20%ï¼ä¸¦ç¶­æäºæ¨è«éåº¦ãæåæ²æå¨æåçæ¼ç®æ³ä¸­è§å¯å°ä»»ä½åæ¨ãæ¶èç ç©¶é¡¯ç¤ºï¼åºæ¼ LID çæå¥å°æè½çå½±é¿æå¤§ï¼å¶æ¬¡æ¯éåæ¯çµæ§åæ©æ¨å»ºæ§çµæé¨åã

##### **Comprehensive Modeling and Question Answering of Cancer Clinical Practice Guidelines using LLMs**
2501.13984v1 by Bhumika Gupta, Pralaypati Ta, Keerthi Ram, Mohanasankar Sivaprakasam

The updated recommendations on diagnostic procedures and treatment pathways
for a medical condition are documented as graphical flows in Clinical Practice
Guidelines (CPGs). For effective use of the CPGs in helping medical
professionals in the treatment decision process, it is necessary to fully
capture the guideline knowledge, particularly the contexts and their
relationships in the graph. While several existing works have utilized these
guidelines to create rule bases for Clinical Decision Support Systems, limited
work has been done toward directly capturing the full medical knowledge
contained in CPGs. This work proposes an approach to create a contextually
enriched, faithful digital representation of National Comprehensive Cancer
Network (NCCN) Cancer CPGs in the form of graphs using automated extraction and
node & relationship classification. We also implement semantic enrichment of
the model by using Large Language Models (LLMs) for node classification,
achieving an accuracy of 80.86% and 88.47% with zero-shot learning and few-shot
learning, respectively. Additionally, we introduce a methodology for answering
natural language questions with constraints to guideline text by leveraging
LLMs to extract the relevant subgraph from the guideline knowledge base. By
generating natural language answers based on subgraph paths and semantic
information, we mitigate the risk of incorrect answers and hallucination
associated with LLMs, ensuring factual accuracy in medical domain Question
Answering.

æè¦ï¼å·²æ´æ°çé«ççæ³è¨ºæ·ç¨åºåæ²»çéå¾å»ºè­°ï¼ä»¥è¨åºå¯¦åæå (CPG) ä¸­çåå½¢æµç¨è¨éãçºäºææä½¿ç¨ CPG åå©é«çå°æ¥­äººå¡é²è¡æ²»çæ±ºç­ï¼å¿é å®æ´æ·åæåç¥è­ï¼ç¹å¥æ¯åè¡¨ä¸­çèçµ¡åå¶éä¿ãéç¶ç¾æè¨±å¤ç ç©¶å·²å©ç¨éäºæåçºè¨åºæ±ºç­æ¯æ´ç³»çµ±å»ºç«è¦ååºç¤ï¼ä½ç´æ¥æ·å CPG ä¸­åå«çå®æ´é«çç¥è­çå·¥ä½å»æéãéé ç ç©¶æåºäºä¸ç¨®æ¹æ³ï¼ä»¥èªååæ·ååç¯é»èéä¿åé¡çæ¹å¼ï¼å»ºç«èçµ¡è±å¯ãå¿ å¯¦çåå®¶ç¶åççç¶²è·¯ (NCCN) çç CPG åå½¢æ¸ä½è¡¨ç¤ºãæåä¹ééä½¿ç¨å¤§åèªè¨æ¨¡å (LLM) é²è¡ç¯é»åé¡ï¼å¯¦ä½æ¨¡åçèªæè±å¯åï¼åå¥å¨é¶æ¬¡å­¸ç¿åå°æ¬¡å­¸ç¿ä¸­éå° 80.86% å 88.47% çæºç¢ºåº¦ãæ­¤å¤ï¼æåå¼é²äºä¸ç¨®æ¹æ³ï¼éééç¨ LLM å¾æåç¥è­åº«ä¸­æ·åç¸éå­åï¼ä¾åç­å·ææåæå­éå¶çèªç¶èªè¨åé¡ãééæ ¹æå­åè·¯å¾åèªæè³è¨ç¢çèªç¶èªè¨ç­æ¡ï¼æåéä½äºè LLM ç¸éçé¯èª¤ç­æ¡åå¹»è¦ºé¢¨éªï¼ç¢ºä¿äºé«çé ååé¡è§£ç­ä¸­çäºå¯¦æºç¢ºæ§ã

##### **LLM-Assisted Knowledge Graph Completion for Curriculum and Domain Modelling in Personalized Higher Education Recommendations**
2501.12300v1 by Hasan Abu-Rasheed, Constance Jumbo, Rashed Al Amin, Christian Weber, Veit Wiese, Roman Obermaisser, Madjid Fathi

While learning personalization offers great potential for learners, modern
practices in higher education require a deeper consideration of domain models
and learning contexts, to develop effective personalization algorithms. This
paper introduces an innovative approach to higher education curriculum
modelling that utilizes large language models (LLMs) for knowledge graph (KG)
completion, with the goal of creating personalized learning-path
recommendations. Our research focuses on modelling university subjects and
linking their topics to corresponding domain models, enabling the integration
of learning modules from different faculties and institutions in the student's
learning path. Central to our approach is a collaborative process, where LLMs
assist human experts in extracting high-quality, fine-grained topics from
lecture materials. We develop a domain, curriculum, and user models for
university modules and stakeholders. We implement this model to create the KG
from two study modules: Embedded Systems and Development of Embedded Systems
Using FPGA. The resulting KG structures the curriculum and links it to the
domain models. We evaluate our approach through qualitative expert feedback and
quantitative graph quality metrics. Domain experts validated the relevance and
accuracy of the model, while the graph quality metrics measured the structural
properties of our KG. Our results show that the LLM-assisted graph completion
approach enhances the ability to connect related courses across disciplines to
personalize the learning experience. Expert feedback also showed high
acceptance of the proposed collaborative approach for concept extraction and
classification.

æè¦ï¼<paragraph>å¨å­¸ç¿åäººåæä¾å­¸ç¿èå·¨å¤§æ½åçåæï¼é«ç­æè²ä¸­çç¾ä»£å¯¦åéè¦æ´æ·±å¥å°èæ®é åæ¨¡ååå­¸ç¿æå¢ï¼ä»¥éç¼ææçåäººåæ¼ç®æ³ãæ¬æä»ç´¹äºä¸ç¨®åµæ°çé«ç­æè²èª²ç¨å»ºæ¨¡æ¹æ³ï¼è©²æ¹æ³å©ç¨å¤§åèªè¨æ¨¡å (LLM) ä¾å®æç¥è­åè­ (KG)ï¼ç®çæ¯å»ºç«åäººåçå­¸ç¿è·¯å¾å»ºè­°ãæåçç ç©¶éé»å¨æ¼å»ºæ¨¡å¤§å­¸ç§ç®ï¼ä¸¦å°å®åçä¸»é¡é£çµå°å°æçé åæ¨¡åï¼å¾èè½å¤ å°ä¾èªä¸åé¢ç³»åæ©æ§çå­¸ç¿æ¨¡çµæ´åå°å­¸ççå­¸ç¿è·¯å¾ä¸­ãæåçåæ³æ ¸å¿æ¯ä¸ååä½æµç¨ï¼å¶ä¸­ LLM åå©äººé¡å°å®¶å¾è¬ç¾©ææä¸­èåé«åè³ªãç´°ç·»çä¸»é¡ãæåçºå¤§å­¸æ¨¡çµåå©å®³éä¿äººéç¼äºé åãèª²ç¨åä½¿ç¨èæ¨¡åãæåå¯¦ä½éåæ¨¡åï¼å¾å©åç ç©¶æ¨¡çµå»ºç« KGï¼åµå¥å¼ç³»çµ±åä½¿ç¨ FPGA çåµå¥å¼ç³»çµ±éç¼ãç¢çç KG å»ºæ§äºèª²ç¨ä¸¦å°å¶é£çµå°é åæ¨¡åãæåééå®æ§å°å®¶åé¥åå®éåå½¢åè³ªææ¨ä¾è©ä¼°æåçåæ³ãé åå°å®¶é©è­äºæ¨¡åçç¸éæ§åæºç¢ºæ§ï¼èåå½¢åè³ªææ¨åæ¸¬éäºæå KG ççµæ§ç¹æ§ãæåççµæé¡¯ç¤ºï¼LLM è¼å©çåå½¢å®ææ¹æ³å¢å¼·äºè·¨å­¸ç§é£çµç¸éèª²ç¨çè½åï¼ä»¥åäººåå­¸ç¿é«é©ãå°å®¶åé¥ä¹é¡¯ç¤ºé«åº¦æ¥åææåºçåä½æ¹æ³ï¼ç¨æ¼æ¦å¿µèåååé¡ã</paragraph>

##### **Divide-Then-Aggregate: An Efficient Tool Learning Method via Parallel Tool Invocation**
2501.12432v1 by Dongsheng Zhu, Weixian Shi, Zhengliang Shi, Zhaochun Ren, Shuaiqiang Wang, Lingyong Yan, Dawei Yin

Although current Large Language Models (LLMs) exhibit impressive
capabilities, performing complex real-world tasks still requires tool learning.
Mainstream methods, such as CoT/ReAct, rely on step-by-step tool invocation to
interact with external environments, but they are limited in perceptual scope
and lack adequate task-planning capability. To address these limitations, other
studies introduce the first Search-based Decision Tree (DFSDT), which still
suffers from the high computational cost. In this paper, we introduce a novel
parallel tool invocation paradigm, DTA-Llama (Divide-Then-Aggregate Llama).
First, we transform traditional tree-based tool search paths into Directed
Acyclic Graph (DAG) structure, generating a high-quality parallel tool
invocation dataset. The DTA-Llama is then trained on the dataset to learn to
iteratively divide the current task into several parallel tool invocation
sub-tasks and aggregate the invocation results to decide the next actions.
Furthermore, we introduce an efficient inference framework inspired by the
Process/Threads mechanism when applying the DTA-Llama to practical tasks.
Experimental results show that our approach substantially enhances task
performance while reducing token consumption and inference time. Llama2-7B,
using our method, is comparable to the official parallel function calling
method of GPT-3.5. The relevant code, dataset, and model weights are available
at https://corn0205.github.io/

æè¦ï¼åç®¡ç®åçå¤§åèªè¨æ¨¡å (LLM) å±ç¾åºä»¤äººå°è±¡æ·±å»çè½åï¼ä½å·è¡è¤éççå¯¦ä¸çä»»åä»éè¦å·¥å·å­¸ç¿ãä¸»æµæ¹æ³ï¼ä¾å¦ CoT/ReActï¼ä¾è³´éæ­¥å·¥å·å¼å«èå¤é¨ç°å¢äºåï¼ä½å®åçæç¥ç¯åæéï¼ä¸ç¼ºä¹è¶³å¤ çä»»åè¦åè½åãçºäºè§£æ±ºéäºéå¶ï¼å¶ä»ç ç©¶å¼å¥äºç¬¬ä¸ååºæ¼æå°çæ±ºç­æ¨¹ (DFSDT)ï¼ä½ä»æå¾é«çéç®ææ¬ãå¨æ¬æä¸­ï¼æåä»ç´¹äºä¸ç¨®æ°ç©çå¹³è¡å·¥å·å¼å«ç¯ä¾ï¼DTA-Llamaï¼åèåä¹ Llamaï¼ãé¦åï¼æåå°å³çµ±çåºæ¼æ¨¹çå·¥å·æå°è·¯å¾è½æçºæåç¡ç°å (DAG) çµæ§ï¼ç¢çé«åè³ªçå¹³è¡å·¥å·å¼å«è³æéãç¶å¾å¨è³æéä¸è¨ç·´ DTA-Llamaï¼å­¸ç¿åè¦å°ç¶åä»»ååæå¹¾åå¹³è¡å·¥å·å¼å«å­ä»»åï¼ä¸¦å½ç¸½å¼å«çµæä»¥æ±ºå®å¾çºåä½ãæ­¤å¤ï¼æåå¨å° DTA-Llama æç¨æ¼å¯¦éä»»åæï¼å¼å¥äºä¸åå Process/Threads æ©å¶åç¼çé«ææ¨è«æ¡æ¶ãå¯¦é©çµæè¡¨æï¼æåçåæ³å¤§å¹æåäºä»»åæè½ï¼åææ¸å°äºç¬¦èæ¶èåæ¨è«æéãä½¿ç¨æåæ¹æ³ç Llama2-7Bï¼å¯è GPT-3.5 çå®æ¹å¹³è¡å½å¼å¼å«æ¹æ³ç¸åª²ç¾ãç¸éç¨å¼ç¢¼ãè³æéåæ¨¡åæ¬éå¯å¨ https://corn0205.github.io/ åå¾

##### **InsTALL: Context-aware Instructional Task Assistance with Multi-modal Large Language Models**
2501.12231v1 by Pha Nguyen, Sailik Sengupta, Girik Malik, Arshit Gupta, Bonan Min

The improved competence of generative models can help building multi-modal
virtual assistants that leverage modalities beyond language. By observing
humans performing multi-step tasks, one can build assistants that have
situational awareness of actions and tasks being performed, enabling them to
cater assistance based on this understanding. In this paper, we develop a
Context-aware Instructional Task Assistant with Multi-modal Large Language
Models (InsTALL) that leverages an online visual stream (e.g. a user's screen
share or video recording) and responds in real-time to user queries related to
the task at hand. To enable useful assistance, InsTALL 1) trains a multi-modal
model on task videos and paired textual data, and 2) automatically extracts
task graph from video data and leverages it at training and inference time. We
show InsTALL achieves state-of-the-art performance across proposed sub-tasks
considered for multimodal activity understanding -- task recognition (TR),
action recognition (AR), next action prediction (AP), and plan prediction (PP)
-- and outperforms existing baselines on two novel sub-tasks related to
automatic error identification.

æè¦ï¼çææ¨¡åè½åçæåæå©äºæå»ºå©ç¨è¯­è¨ä¹å¤çå¤æ¨¡æèæå©æãéè¿è§å¯äººç±»æ§è¡å¤æ­¥éª¤ä»»å¡ï¼å¯ä»¥æå»ºå¯¹æ­£å¨æ§è¡çå¨ä½åä»»å¡ææå¢æç¥çå©æï¼ä½¿ä»ä»¬è½å¤æ ¹æ®è¿ç§çè§£æä¾å¸®å©ãå¨æ¬æä¸­ï¼æä»¬å¼åäºä¸ä¸ªå·æå¤æ¨¡æå¤§è¯­è¨æ¨¡åçä¸ä¸ææç¥æä»¤ä»»å¡å©æ (InsTALL)ï¼è¯¥å©æå©ç¨å¨çº¿è§è§æµï¼ä¾å¦ç¨æ·çå±å¹å±äº«æè§é¢å½å¶ï¼ï¼å¹¶å®æ¶ååºä¸æå¤´ä»»å¡ç¸å³çç¨æ·æ¥è¯¢ãä¸ºäºæä¾æç¨çå¸®å©ï¼InsTALL 1) å¨ä»»å¡è§é¢åéå¯¹ææ¬æ°æ®ä¸è®­ç»å¤æ¨¡ææ¨¡åï¼ä»¥å 2) ä»è§é¢æ°æ®ä¸­èªå¨æåä»»å¡å¾ï¼å¹¶å¨è®­ç»åæ¨çæ¶é´å©ç¨å®ãæä»¬å±ç¤ºäº InsTALL å¨èèç¨äºå¤æ¨¡ææ´»å¨çè§£çæè®®å­ä»»å¡ä¸­å®ç°äºæåè¿çæ§è½ââä»»å¡è¯å« (TR)ãå¨ä½è¯å« (AR)ãä¸ä¸ä¸ªå¨ä½é¢æµ (AP) åè®¡åé¢æµ (PP)ââå¹¶ä¸å¨ä¸èªå¨éè¯¯è¯å«ç¸å³çä¸¤ä¸ªæ°å­ä»»å¡ä¸ä¼äºç°æçåºåã

##### **Leveraging Graph Structures and Large Language Models for End-to-End Synthetic Task-Oriented Dialogues**
2501.11977v1 by Maya Medjad, Hugo Imbert, Bruno Yun, RaphaÃ«l Szymocha, FrÃ©dÃ©ric Armetta

Training task-oriented dialogue systems is both costly and time-consuming,
due to the need for high-quality datasets encompassing diverse intents.
Traditional methods depend on extensive human annotation, while recent
advancements leverage large language models (LLMs) to generate synthetic data.
However, these approaches often require custom prompts or code, limiting
accessibility for non-technical users. We introduce GraphTOD, an end-to-end
framework that simplifies the generation of task-oriented dialogues. Users can
create dialogues by specifying transition graphs in JSON format. Our evaluation
demonstrates that GraphTOD generates high-quality dialogues across various
domains, significantly lowering the cost and complexity of dataset creation.

æè¦ï¼è¨ç·´ä»»åå°åå°è©±ç³»çµ±æ¢æè²´åèæï¼
å çºéè¦åå«åç¨®æåçé«åè³ªè³æéã
å³çµ±æ¹æ³ä¾è³´æ¼å»£æ³çäººå·¥æ¨è¨»ï¼èæè¿
çé²å±å©ç¨å¤§åèªè¨æ¨¡å (LLM) ä¾ç¢çåæè³æã
ç¶èï¼éäºæ¹æ³éå¸¸éè¦èªè¨æç¤ºæç¨å¼ç¢¼ï¼éå¶
éæè¡ä½¿ç¨èçå¯åæ§ãæåä»ç´¹ GraphTODï¼ä¸åç«¯å°ç«¯ç
æ¶æ§ï¼ç°¡åäºä»»åå°åå°è©±çç¢çãä½¿ç¨èå¯ä»¥
ééæå® JSON æ ¼å¼çè½æåè¡¨ä¾å»ºç«å°è©±ãæåçè©ä¼°
è­æ GraphTOD å¨åç¨®é åç¢çé«åè³ªå°è©±ï¼é¡¯èéä½è³æéå»ºç«çææ¬åè¤éæ§ã

##### **Bridging Visualization and Optimization: Multimodal Large Language Models on Graph-Structured Combinatorial Optimization**
2501.11968v1 by Jie Zhao, Kang Hao Cheong, Witold Pedrycz

Graph-structured combinatorial challenges are inherently difficult due to
their nonlinear and intricate nature, often rendering traditional computational
methods ineffective or expensive. However, these challenges can be more
naturally tackled by humans through visual representations that harness our
innate ability for spatial reasoning. In this study, we propose transforming
graphs into images to preserve their higher-order structural features
accurately, revolutionizing the representation used in solving graph-structured
combinatorial tasks. This approach allows machines to emulate human-like
processing in addressing complex combinatorial challenges. By combining the
innovative paradigm powered by multimodal large language models (MLLMs) with
simple search techniques, we aim to develop a novel and effective framework for
tackling such problems. Our investigation into MLLMs spanned a variety of
graph-based tasks, from combinatorial problems like influence maximization to
sequential decision-making in network dismantling, as well as addressing six
fundamental graph-related issues. Our findings demonstrate that MLLMs exhibit
exceptional spatial intelligence and a distinctive capability for handling
these problems, significantly advancing the potential for machines to
comprehend and analyze graph-structured data with a depth and intuition akin to
human cognition. These results also imply that integrating MLLMs with simple
optimization strategies could form a novel and efficient approach for
navigating graph-structured combinatorial challenges without complex
derivations, computationally demanding training and fine-tuning.

æè¦ï¼åå½¢çµæ§ççµåææ°æ¬è³ªä¸å¾å°é£ï¼å çºå®åçéç·æ§åè¤éæ§ï¼éå¸¸æä½¿å³çµ±çè¨ç®æ¹æ³ç¡æææè²´ãç¶èï¼äººé¡å¯ä»¥ééå©ç¨æåå¤©ççç©ºéæ¨çè½åçè¦è¦ºè¡¨å¾µï¼æ´èªç¶å°æå°éäºææ°ãå¨æ¬ç ç©¶ä¸­ï¼æåå»ºè­°å°åå½¢è½æçºå½±åï¼ä»¥æºç¢ºä¿çå®åçé«éçµæ§ç¹å¾µï¼å¾èé©æ°ç¨æ¼è§£æ±ºåå½¢çµæ§çµåä»»åçè¡¨å¾µãéç¨®æ¹æ³åè¨±æ©å¨å¨è§£æ±ºè¤éççµåææ°ææ¨¡æ¬é¡äººçèçãééçµåç±å¤æ¨¡æå¤§åèªè¨æ¨¡å (MLLM) æä¾ååçåµæ°ç¯ä¾èç°¡å®çæå°æè¡ï¼æåæ¨å¨çºè§£æ±ºæ­¤é¡åé¡éç¼ä¸åæ°ç©ä¸ææçæ¶æ§ãæåå° MLLM çç ç©¶æ¶µèäºåç¨®åºæ¼åå½¢çä»»åï¼å¾çµååé¡ï¼å¦å½±é¿åæå¤§åï¼å°ç¶²è·¯æé¤ä¸­çé åºæ±ºç­å¶å®ï¼ä»¥åè§£æ±ºå­ååºæ¬çåå½¢ç¸éåé¡ãæåçç ç©¶çµæè¡¨æï¼MLLM è¡¨ç¾åºéå¡çç©ºéæºè½åèçéäºåé¡çç¨ç¹è½åï¼é¡¯èæåäºæ©å¨ä»¥é¡ä¼¼äººé¡èªç¥çæ·±åº¦åç´è¦ºä¾çè§£ååæåå½¢çµæ§è³æçæ½åãéäºçµæéæç¤ºï¼å° MLLM èç°¡å®çæä½³åç­ç¥æ´åå¨ä¸èµ·ï¼å¯ä»¥å½¢æä¸ç¨®æ°ç©ä¸ææçæ¹æ³ï¼ç¨æ¼å¨æ²æè¤éæ¨å°ãè¨ç®éæ±éå¤§çè¨ç·´åå¾®èª¿çææ³ä¸æå°åå½¢çµæ§ççµåææ°ã

##### **A Survey of Graph Retrieval-Augmented Generation for Customized Large Language Models**
2501.13958v1 by Qinggang Zhang, Shengyuan Chen, Yuanchen Bei, Zheng Yuan, Huachi Zhou, Zijin Hong, Junnan Dong, Hao Chen, Yi Chang, Xiao Huang

Large language models (LLMs) have demonstrated remarkable capabilities in a
wide range of tasks, yet their application to specialized domains remains
challenging due to the need for deep expertise. Retrieval-augmented generation
(RAG) has emerged as a promising solution to customize LLMs for professional
fields by seamlessly integrating external knowledge bases, enabling real-time
access to domain-specific expertise during inference. Despite its potential,
traditional RAG systems, based on flat text retrieval, face three critical
challenges: (i) complex query understanding in professional contexts, (ii)
difficulties in knowledge integration across distributed sources, and (iii)
system efficiency bottlenecks at scale. This survey presents a systematic
analysis of Graph-based Retrieval-Augmented Generation (GraphRAG), a new
paradigm that revolutionizes domain-specific LLM applications. GraphRAG
addresses traditional RAG limitations through three key innovations: (i)
graph-structured knowledge representation that explicitly captures entity
relationships and domain hierarchies, (ii) efficient graph-based retrieval
techniques that enable context-preserving knowledge retrieval with multihop
reasoning ability, and (iii) structure-aware knowledge integration algorithms
that leverage retrieved knowledge for accurate and logical coherent generation
of LLMs. In this survey, we systematically analyze the technical foundations of
GraphRAG and examine current implementations across various professional
domains, identifying key technical challenges and promising research
directions. All the related resources of GraphRAG, including research papers,
open-source data, and projects, are collected for the community in
\textcolor{blue}{\url{https://github.com/DEEP-PolyU/Awesome-GraphRAG}}.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å·²å¨åç¨®ä»»åä¸­å±ç¾åºéå¡çè½åï¼ä½ç±æ¼éè¦æ·±å¥çå°æ¥­ç¥è­ï¼å æ­¤å°å¶æç¨æ¼å°æ¥­é åä»å·æææ°æ§ãæª¢ç´¢å¢å¼·çæ (RAG) å·²æçºä¸ç¨®æåéçè§£æ±ºæ¹æ¡ï¼å¯ééç¡ç¸«æ´åå¤é¨ç¥è­åº«ä¾å®¢è£½å LLM ä»¥é©ç¨æ¼å°æ¥­é åï¼å¾èå¨æ¨çéç¨ä¸­å³æå­åç¹å®é åçå°æ¥­ç¥è­ãåç®¡æå¶æ½åï¼ä½åºæ¼å¹³é¢æå­æª¢ç´¢çå³çµ± RAG ç³»çµ±é¢è¨ä¸é ééµææ°ï¼(i) å¨å°æ¥­æå¢ä¸­é²è¡è¤éçæ¥è©¢çè§£ï¼(ii) é£ä»¥æ´ååæ£ä¾æºçç¥è­ï¼ä»¥å (iii) ç³»çµ±æçç¶é ¸æé¨èè¦æ¨¡æ´å¤§èç¢çãæ¬èª¿æ¥ç³»çµ±æ§å°åæäºåå½¢åæª¢ç´¢å¢å¼·çæ (GraphRAG) çæè¡åºç¤ï¼GraphRAG æ¯ä¸åæ°çå¸ç¯ï¼å®å¾¹åºæ¹è®äºç¹å®é åç LLM æç¨ãGraphRAG ééä¸é ééµåµæ°ä¾è§£æ±ºå³çµ± RAG çéå¶ï¼(i) åå½¢çµæ§åçç¥è­è¡¨è¿°ï¼æç¢ºæ·åå¯¦é«éä¿åé åéå±¤ï¼(ii) ææçåå½¢åæª¢ç´¢æè¡ï¼å¯é²è¡ä¿çèçµ¡çç¥è­æª¢ç´¢ï¼ä¸¦å·åå¤è·³æ¨çè½åï¼ä»¥å (iii) çµæ§æç¥ç¥è­æ´åæ¼ç®æ³ï¼å¯å©ç¨æª¢ç´¢å°çç¥è­ä¾é²è¡ LLM çæºç¢ºä¸éè¼¯ä¸è´ççæãå¨æ¬èª¿æ¥ä¸­ï¼æåç³»çµ±æ§å°åæäº GraphRAG çæè¡åºç¤ï¼ä¸¦æª¢è¦äºå¨åç¨®å°æ¥­é åä¸­çç¾æå¯¦ä½ï¼æ¾åºééµæè¡ææ°åæåæ¯çç ç©¶æ¹åãææ GraphRAG çç¸éè³æºï¼åæ¬ç ç©¶è«æãéæ¾åå§ç¢¼è³æåå°æ¡ï¼é½å·²å¨ \textcolor{blue}{\url{https://github.com/DEEP-PolyU/Awesome-GraphRAG}} ä¸­çºç¤¾ç¾¤æ¶éã

##### **Network-informed Prompt Engineering against Organized Astroturf Campaigns under Extreme Class Imbalance**
2501.11849v1 by Nikos Kanakaris, Heng Ping, Xiongye Xiao, Nesreen K. Ahmed, Luca Luceri, Emilio Ferrara, Paul Bogdan

Detecting organized political campaigns is of paramount importance in
fighting against disinformation on social media. Existing approaches for the
identification of such organized actions employ techniques mostly from network
science, graph machine learning and natural language processing. Their ultimate
goal is to analyze the relationships and interactions (e.g. re-posting) among
users and the textual similarities of their posts. Despite their effectiveness
in recognizing astroturf campaigns, these methods face significant challenges,
notably the class imbalance in available training datasets. To mitigate this
issue, recent methods usually resort to data augmentation or increasing the
number of positive samples, which may not always be feasible or sufficient in
real-world settings. Following a different path, in this paper, we propose a
novel framework for identifying astroturf campaigns based solely on large
language models (LLMs), introducing a Balanced Retrieval-Augmented Generation
(Balanced RAG) component. Our approach first gives both textual information
concerning the posts (in our case tweets) and the user interactions of the
social network as input to a language model. Then, through prompt engineering
and the proposed Balanced RAG method, it effectively detects coordinated
disinformation campaigns on X (Twitter). The proposed framework does not
require any training or fine-tuning of the language model. Instead, by
strategically harnessing the strengths of prompt engineering and Balanced RAG,
it facilitates LLMs to overcome the effects of class imbalance and effectively
identify coordinated political campaigns. The experimental results demonstrate
that by incorporating the proposed prompt engineering and Balanced RAG methods,
our framework outperforms the traditional graph-based baselines, achieving
2x-3x improvements in terms of precision, recall and F1 scores.

æè¦ï¼<paragraph>å¨ç¤¾äº¤åªé«ä¸ææé¯èª¤è³è¨ï¼åµæ¸¬æçµç¹çæ¿æ²»å®£å³è³ééè¦ãç¾æçæ­¤é¡æçµç¹è¡åè­å¥æ¹æ³ï¼ä¸»è¦æ¡ç¨ç¶²è·¯ç§å­¸ãåå½¢æ©å¨å­¸ç¿åèªç¶èªè¨èççæè¡ãå¶æçµç®æ¨æ¯åæä½¿ç¨èä¹éçéä¿åäºåï¼ä¾å¦è½ç¼ï¼ï¼ä»¥åå¶è²¼æçæå­ç¸ä¼¼åº¦ãåç®¡éäºæ¹æ³å¨è¾¨è­åèæ ¹éåå®£å³ä¸å¾ææï¼ä½ä»é¢è¨éå¤§ææ°ï¼ç¹å¥æ¯å¯ç¨è¨ç·´è³æéä¸­çé¡å¥ä¸å¹³è¡¡ãçºäºæ¸è¼éååé¡ï¼æè¿çæ¹æ³éå¸¸è¨´è«¸æ¼è³ææ´åæå¢å æ­£åæ¨£æ¬æ¸éï¼ä½å¨ç¾å¯¦ä¸çä¸­ï¼éä¸¦ä¸ç¸½æ¯å¯è¡æè¶³å¤ çãæ¬ææ¡è¡ä¸åçéå¾ï¼æåæåºä¸ååºæ¼å¤§åèªè¨æ¨¡å (LLM) çæ°åæ¡æ¶ï¼ç¨æ¼è­å¥åèæ ¹éåå®£å³ï¼ä¸¦å¼å¥å¹³è¡¡æª¢ç´¢æ´åçæ (Balanced RAG) åä»¶ãæåçåæ³é¦åå°æéè²¼æï¼å¨æ¬ä¾ä¸­çºæ¨æï¼çæå­è³è¨åç¤¾äº¤ç¶²è·¯çä½¿ç¨èäºåä½çºè¼¸å¥ï¼æä¾çµ¦èªè¨æ¨¡åãç¶å¾ï¼ééæç¤ºå·¥ç¨åæåºçå¹³è¡¡æª¢ç´¢æ´åçææ¹æ³ï¼å®ææå°åµæ¸¬ X (Twitter) ä¸åèª¿çé¯èª¤è³è¨å®£å³ãæåºçæ¡æ¶ä¸éè¦ä»»ä½èªè¨æ¨¡åçè¨ç·´æå¾®èª¿ãç¸åå°ï¼ééç­ç¥æ§å°å©ç¨æç¤ºå·¥ç¨åå¹³è¡¡æª¢ç´¢æ´åçæçåªå¢ï¼å®è½è®å¤§åèªè¨æ¨¡ååæé¡å¥ä¸å¹³è¡¡çå½±é¿ï¼ä¸¦ææè­å¥åèª¿çæ¿æ²»å®£å³ãå¯¦é©çµæè­æï¼ééæ´åæåºçæç¤ºå·¥ç¨åå¹³è¡¡æª¢ç´¢æ´åçææ¹æ³ï¼æåçæ¡æ¶åªæ¼å³çµ±çåºæ¼åå½¢çåºæºï¼å¨ç²¾æºåº¦ãå¬åçå F1 åæ¸æ¹é¢ç²å¾ 2x-3x çæåã</paragraph>

##### **Zep: A Temporal Knowledge Graph Architecture for Agent Memory**
2501.13956v1 by Preston Rasmussen, Pavlo Paliychuk, Travis Beauvais, Jack Ryan, Daniel Chalef

We introduce Zep, a novel memory layer service for AI agents that outperforms
the current state-of-the-art system, MemGPT, in the Deep Memory Retrieval (DMR)
benchmark. Additionally, Zep excels in more comprehensive and challenging
evaluations than DMR that better reflect real-world enterprise use cases. While
existing retrieval-augmented generation (RAG) frameworks for large language
model (LLM)-based agents are limited to static document retrieval, enterprise
applications demand dynamic knowledge integration from diverse sources
including ongoing conversations and business data. Zep addresses this
fundamental limitation through its core component Graphiti -- a
temporally-aware knowledge graph engine that dynamically synthesizes both
unstructured conversational data and structured business data while maintaining
historical relationships. In the DMR benchmark, which the MemGPT team
established as their primary evaluation metric, Zep demonstrates superior
performance (94.8% vs 93.4%). Beyond DMR, Zep's capabilities are further
validated through the more challenging LongMemEval benchmark, which better
reflects enterprise use cases through complex temporal reasoning tasks. In this
evaluation, Zep achieves substantial results with accuracy improvements of up
to 18.5% while simultaneously reducing response latency by 90% compared to
baseline implementations. These results are particularly pronounced in
enterprise-critical tasks such as cross-session information synthesis and
long-term context maintenance, demonstrating Zep's effectiveness for deployment
in real-world applications.

æè¦ï¼æåæ¨åº Zepï¼éæ¯ä¸ç¨®æ°ç©çè¨æ¶å±¤æåï¼é©ç¨æ¼ AI ä»£çï¼å¶å¨æ·±åº¦è¨æ¶æ·å (DMR) åºæºæ¸¬è©¦ä¸­åªæ¼ç¾è¡çæåé²ç³»çµ± MemGPTãæ­¤å¤ï¼Zep å¨æ¯ DMR æ´å¨é¢ä¸æ´å·ææ°æ§çè©ä¼°ä¸­è¡¨ç¾åºè²ï¼éäºè©ä¼°æ´è½åæ çå¯¦ä¸ççä¼æ¥­ç¨ä¾ãéç¶ç¾æçæª¢ç´¢å¢å¼·çæ (RAG) æ¶æ§åéæ¼å¤§åèªè¨æ¨¡å (LLM) åºæ¼ä»£ççéææä»¶æª¢ç´¢ï¼ä½ä¼æ¥­æç¨éè¦å¾åæ¬æ­£å¨é²è¡çå°è©±åæ¥­åæ¸æå¨å§çä¸åä¾æºåææ´åç¥è­ãZep ééå¶æ ¸å¿çµä»¶ Graphiti ä¾è§£æ±ºéååºæ¬éå¶ï¼Graphiti æ¯ä¸åæéæç¥ç¥è­åè­å¼æï¼å¯ä»¥å¨ç¶­è­·æ­·å²éä¿çåæåæç¶åéçµæ§åå°è©±æ¸æåçµæ§åæ¥­åæ¸æãå¨ MemGPT åéç¢ºç«çºå¶ä¸»è¦è©ä¼°ææ¨ç DMR åºæºæ¸¬è©¦ä¸­ï¼Zep è¡¨ç¾åºåªç°çæè½ï¼94.8% å° 93.4%ï¼ãé¤äº DMR ä¹å¤ï¼Zep çåè½éééæ´å·ææ°æ§ç LongMemEval åºæºæ¸¬è©¦é²ä¸æ­¥å¾å°é©è­ï¼è©²åºæºæ¸¬è©¦ééè¤éçæéæ¨çä»»åæ´å¥½å°åæ äºä¼æ¥­ç¨ä¾ãå¨éåè©ä¼°ä¸­ï¼Zep ä»¥é«é 18.5% çæºç¢ºåº¦æ¹é²åå¾äºé¡¯èçææï¼åæèåºç·å¯¦ä½ç¸æ¯ï¼å°åæå»¶é²éä½äº 90%ãéäºææå¨ä¼æ¥­ééµä»»åä¸­å°¤çºæé¡¯ï¼ä¾å¦è·¨æè©±è³è¨ç¶ååé·æèçµ¡ç¶­è­·ï¼è­æäº Zep å¨å¯¦éæç¨ä¸­é¨ç½²çæææ§ã

##### **Explainable Lane Change Prediction for Near-Crash Scenarios Using Knowledge Graph Embeddings and Retrieval Augmented Generation**
2501.11560v1 by M. Manzour, A. Ballardini, R. Izquierdo, M. Ã. Sotelo

Lane-changing maneuvers, particularly those executed abruptly or in risky
situations, are a significant cause of road traffic accidents. However, current
research mainly focuses on predicting safe lane changes. Furthermore, existing
accident datasets are often based on images only and lack comprehensive sensory
data. In this work, we focus on predicting risky lane changes using the CRASH
dataset (our own collected dataset specifically for risky lane changes), and
safe lane changes (using the HighD dataset). Then, we leverage KG and Bayesian
inference to predict these maneuvers using linguistic contextual information,
enhancing the model's interpretability and transparency. The model achieved a
91.5% f1-score with anticipation time extending to four seconds for risky lane
changes, and a 90.0% f1-score for predicting safe lane changes with the same
anticipation time. We validate our model by integrating it into a vehicle
within the CARLA simulator in scenarios that involve risky lane changes. The
model managed to anticipate sudden lane changes, thus providing automated
vehicles with further time to plan and execute appropriate safe reactions.
Finally, to enhance the explainability of our model, we utilize RAG to provide
clear and natural language explanations for the given prediction.

æè¦ï¼æè»éåä½ï¼å°¤å¶æ¯çªç¶æå¨é¢¨éªææ³ä¸å·è¡çåä½ï¼æ¯éè·¯äº¤éäºæçéè¦åå ãç¶èï¼ç®åçç ç©¶æä¸»è¦éä¸­å¨é æ¸¬å®å¨çæè»éãæ­¤å¤ï¼ç¾æçäºæè³æééå¸¸ååºæ¼å½±åï¼ä¸ç¼ºä¹å¨é¢çææ¸¬è³æãå¨éé å·¥ä½ä¸­ï¼æåå°æ³¨æ¼ä½¿ç¨ CRASH è³æéï¼æåèªå·±æ¶éçå°ééå°é¢¨éªæè»éè³æéï¼ä¾é æ¸¬é¢¨éªæè»éï¼ä»¥åå®å¨æè»éï¼ä½¿ç¨ HighD è³æéï¼ãç¶å¾ï¼æåå©ç¨ KG åè²æ°æ¨çä¾ä½¿ç¨èªè¨èæ¯è³è¨é æ¸¬éäºåä½ï¼å¢å¼·æ¨¡åçå¯è§£éæ§åéæåº¦ãè©²æ¨¡åå¨é¢¨éªæè»éçé æ¸¬æéå»¶é·è³åç§æï¼éå°äº 91.5% ç f1 åæ¸ï¼å¨é æ¸¬å®å¨æè»éæï¼å¨ç¸åçé æ¸¬æéå§éå°äº 90.0% ç f1 åæ¸ãæåééå°æ¨¡åæ´åå° CARLA æ¨¡æ¬å¨ä¸­çè»è¼ä¸­ï¼å¨æ¶åé¢¨éªæè»éçå ´æ¯ä¸­é©è­æåçæ¨¡åãè©²æ¨¡åè¨­æ³é æ¸¬çªç¶çæè»éï¼å¾èçºèªåé§é§è»è¼æä¾äºæ´å¤æéä¾è¦ååå·è¡é©ç¶çå®å¨åæãæå¾ï¼çºäºå¢å¼·æåæ¨¡åçå¯è§£éæ§ï¼æåå©ç¨ RAG çºçµ¦å®çé æ¸¬æä¾æ¸æ°ä¸èªç¶çèªè¨è§£éã

##### **Each Graph is a New Language: Graph Learning with LLMs**
2501.11478v2 by Huachi Zhou, Jiahe Du, Chuang Zhou, Chang Yang, Yilin Xiao, Yuxuan Xie, Xiao Huang

Recent efforts leverage Large Language Models (LLMs) for modeling
text-attributed graph structures in node classification tasks. These approaches
describe graph structures for LLMs to understand or aggregate LLM-generated
textual attribute embeddings through graph structure. However, these approaches
face two main limitations in modeling graph structures with LLMs. (i) Graph
descriptions become verbose in describing high-order graph structure. (ii)
Textual attributes alone do not contain adequate graph structure information.
It is challenging to model graph structure concisely and adequately with LLMs.
LLMs lack built-in mechanisms to model graph structures directly. They also
struggle with complex long-range dependencies between high-order nodes and
target nodes.
  Inspired by the observation that LLMs pre-trained on one language can achieve
exceptional performance on another with minimal additional training, we propose
\textbf{G}raph-\textbf{D}efined \textbf{L}anguage for \textbf{L}arge
\textbf{L}anguage \textbf{M}odel (GDL4LLM). This novel framework enables LLMs
to transfer their powerful language understanding capabilities to
graph-structured data. GDL4LLM translates graphs into a graph language corpus
instead of graph descriptions and pre-trains LLMs on this corpus to adequately
understand graph structures. During fine-tuning, this corpus describes the
structural information of target nodes concisely with only a few tokens. By
treating graphs as a new language, GDL4LLM enables LLMs to model graph
structures adequately and concisely for node classification tasks. Extensive
experiments on three real-world datasets demonstrate that GDL4LLM outperforms
description-based and textual attribute embeddings-based baselines by
efficiently modeling different orders of graph structure with LLMs.

æè¦ï¼<paragraph>æè¿çç ç©¶å©ç¨å¤§åè¯­è¨æ¨¡å (LLM) å¯¹èç¹åç±»ä»»å¡ä¸­çææ¬å±æ§å¾ç»æè¿è¡å»ºæ¨¡ãè¿äºæ¹æ³æè¿°å¾ç»æï¼ä»¥ä¾¿ LLM çè§£æéè¿å¾ç»æèå LLM çæçææ¬å±æ§åµå¥ãç¶èï¼è¿äºæ¹æ³å¨ä½¿ç¨ LLM å¯¹å¾ç»æè¿è¡å»ºæ¨¡æ¶é¢ä¸´ä¸¤ä¸ªä¸»è¦éå¶ã(i) å¾æè¿°å¨æè¿°é«é¶å¾ç»ææ¶åå¾åé¿ã(ii) ä»ææ¬å±æ§ä¸åå«è¶³å¤çå¾ç»æä¿¡æ¯ãä½¿ç¨ LLM å¯¹å¾ç»æè¿è¡ç®æ´ä¸ååçå»ºæ¨¡å·ææææ§ãLLM ç¼ºä¹ç´æ¥å¯¹å¾ç»æè¿è¡å»ºæ¨¡çåç½®æºå¶ãå®ä»¬è¿é¾ä»¥å¤çé«é¶èç¹åç®æ èç¹ä¹é´å¤æçè¿ç¨ä¾èµå³ç³»ã
å LLM å¨ä¸ç§è¯­è¨ä¸è¿è¡é¢è®­ç»åï¼åªéè¿è¡æå°çé¢å¤è®­ç»å³å¯å¨å¦ä¸ç§è¯­è¨ä¸å®ç°åè¶æ§è½çè§å¯ç»æçå¯åï¼æä»¬æåºäº**G**raph-**D**efined **L**anguage for **L**arge **L**anguage **M**odel (GDL4LLM)ãæ­¤æ°æ¡æ¶ä½¿ LLM è½å¤å°å¶å¼ºå¤§çè¯­è¨çè§£è½åè½¬ç§»å°ç»æåæ°æ®å¾ãGDL4LLM å°å¾ç¿»è¯æå¾è¯­è¨è¯­æåºï¼èä¸æ¯å¾æè¿°ï¼å¹¶å¨è¯¥è¯­æåºä¸å¯¹ LLM è¿è¡é¢è®­ç»ï¼ä»¥ååçè§£å¾ç»æãå¨å¾®è°æé´ï¼æ­¤è¯­æåºä»ä½¿ç¨å ä¸ªæ è®°ç®æ´å°æè¿°ç®æ èç¹çç»æä¿¡æ¯ãéè¿å°å¾è§ä¸ºä¸ç§æ°è¯­è¨ï¼GDL4LLM ä½¿ LLM è½å¤ååä¸ç®æ´å°å¯¹å¾ç»æè¿è¡å»ºæ¨¡ï¼ä»¥ç¨äºèç¹åç±»ä»»å¡ãå¨ä¸ä¸ªçå®ä¸çæ°æ®éä¸è¿è¡çå¹¿æ³å®éªè¡¨æï¼GDL4LLM éè¿ä½¿ç¨ LLM ææå°å¯¹ä¸åé¶çå¾ç»æè¿è¡å»ºæ¨¡ï¼ä¼äºåºäºæè¿°ååºäºææ¬å±æ§åµå¥çåºçº¿ã</paragraph>

##### **Few-shot Policy (de)composition in Conversational Question Answering**
2501.11335v1 by Kyle Erwin, Guy Axelrod, Maria Chang, Achille Fokoue, Maxwell Crouse, Soham Dan, Tian Gao, Rosario Uceda-Sosa, Ndivhuwo Makondo, Naweed Khan, Alexander Gray

The task of policy compliance detection (PCD) is to determine if a scenario
is in compliance with respect to a set of written policies. In a conversational
setting, the results of PCD can indicate if clarifying questions must be asked
to determine compliance status. Existing approaches usually claim to have
reasoning capabilities that are latent or require a large amount of annotated
data. In this work, we propose logical decomposition for policy compliance
(LDPC): a neuro-symbolic framework to detect policy compliance using large
language models (LLMs) in a few-shot setting. By selecting only a few exemplars
alongside recently developed prompting techniques, we demonstrate that our
approach soundly reasons about policy compliance conversations by extracting
sub-questions to be answered, assigning truth values from contextual
information, and explicitly producing a set of logic statements from the given
policies. The formulation of explicit logic graphs can in turn help answer
PCDrelated questions with increased transparency and explainability. We apply
this approach to the popular PCD and conversational machine reading benchmark,
ShARC, and show competitive performance with no task-specific finetuning. We
also leverage the inherently interpretable architecture of LDPC to understand
where errors occur, revealing ambiguities in the ShARC dataset and highlighting
the challenges involved with reasoning for conversational question answering.

æè¦ï¼ç­ç¥åè¦åµæ¸¬ (PCD) çä»»åæ¯ç¢ºå®å ´æ¯æ¯å¦ç¬¦åä¸çµæ¸é¢ç­ç¥ãå¨å°è©±è¨­å®ä¸­ï¼PCD ççµæå¯ä»¥æåºæ¯å¦å¿é æåºæ¾æ¸åé¡ä»¥ç¢ºå®åè¦çæãç¾æçæ¹æ³éå¸¸è²ç¨±å·ææ½å¨çæ¨çè½åï¼æéè¦å¤§éçè¨»éè³æãå¨éé å·¥ä½ä¸­ï¼æåæåºç­ç¥åè¦çéè¼¯åè§£ (LDPC)ï¼ä¸ç¨®ä½¿ç¨å¤§åèªè¨æ¨¡å (LLM) å¨å°æ¬¡åè©¦ä¸­åµæ¸¬ç­ç¥åè¦çç¥ç¶ç¬¦èæ¡æ¶ãééåé¸æå°æ¸ç¯ä¾ä»¥åæè¿éç¼çæç¤ºæè¡ï¼æåè­ææåçåæ³ééæåè¦åç­çå­åé¡ãå¾èçµ¡è³è¨ææ´¾çå¼ï¼ä»¥åå¾çµ¦å®çç­ç¥æç¢ºç¢çä¸çµéè¼¯é³è¿°ï¼å°ç­ç¥åè¦å°è©±é²è¡åççæ¨çãæç¢ºéè¼¯åè¡¨çå¶å®åéä¾å¯ä»¥å¹«å©åç­ PCD ç¸éåé¡ï¼ä¸¦æé«éæåº¦åå¯è§£éæ§ãæåå°æ­¤æ¹æ³æç¨æ¼ç±éç PCD åå°è©±å¼æ©å¨é±è®åºæº ShARCï¼ä¸¦å¨æ²æç¹å®ä»»åå¾®èª¿çææ³ä¸å±ç¾åºç«¶ç­åãæåä¹å©ç¨ LDPC åºæçå¯è§£éæ¶æ§ä¾äºè§£é¯èª¤ç¼çå¨åªè£¡ï¼æ­é² ShARC è³æéä¸­çæ­§ç¾©ï¼ä¸¦å¼·èª¿å°è©±å¼åé¡è§£ç­æ¨ççææ°ã

##### **Reasoning Language Models: A Blueprint**
2501.11223v3 by Maciej Besta, Julia Barth, Eric Schreiber, Ales Kubicek, Afonso Catarino, Robert Gerstenberger, Piotr Nyczyk, Patrick Iff, Yueling Li, Sam Houliston, Tomasz Sternal, Marcin Copik, Grzegorz KwaÅniewski, JÃ¼rgen MÃ¼ller, Åukasz Flis, Hannes Eberhard, Hubert Niewiadomski, Torsten Hoefler

Reasoning language models (RLMs), also known as Large Reasoning Models
(LRMs), such as OpenAI's o1 and o3, DeepSeek-V3, and Alibaba's QwQ, have
redefined AI's problem-solving capabilities by extending LLMs with advanced
reasoning mechanisms. Yet, their high costs, proprietary nature, and complex
architectures - uniquely combining Reinforcement Learning (RL), search
heuristics, and LLMs - present accessibility and scalability challenges. To
address these, we propose a comprehensive blueprint that organizes RLM
components into a modular framework, based on a survey and analysis of all RLM
works. This blueprint incorporates diverse reasoning structures (chains, trees,
graphs, and nested forms), reasoning strategies (e.g., Monte Carlo Tree Search,
Beam Search), RL concepts (policy, value models and others), supervision
schemes (Outcome-Based and Process-Based Supervision), and other related
concepts (e.g., Test-Time Compute, Retrieval-Augmented Generation, agent
tools). We also provide detailed mathematical formulations and algorithmic
specifications to simplify RLM implementation. By showing how schemes like
LLaMA-Berry, QwQ, Journey Learning, and Graph of Thoughts fit as special cases,
we demonstrate the blueprint's versatility and unifying potential. To
illustrate its utility, we introduce x1, a modular implementation for rapid RLM
prototyping and experimentation. Using x1 and a literature review, we provide
key insights, such as multi-phase training for policy and value models, and the
importance of familiar training distributions. Finally, we discuss scalable RLM
cloud deployments and we outline how RLMs can integrate with a broader LLM
ecosystem. Our work demystifies RLM construction, democratizes advanced
reasoning capabilities, and fosters innovation, aiming to mitigate the gap
between "rich AI" and "poor AI" by lowering barriers to RLM design and
experimentation.

æè¦ï¼æ¨çèªè¨æ¨¡å (RLM)ï¼åç¨±çºå¤§åæ¨çæ¨¡å (LRM)ï¼ä¾å¦ OpenAI ç o1 å o3ãDeepSeek-V3 ä»¥åé¿éå·´å·´ç QwQï¼ééæ´å LLM çåé²æ¨çæ©å¶ï¼éæ°å®ç¾©äº AI çåé¡è§£æ±ºè½åãç¶èï¼å®åçé«ææ¬ãå°ææ§è³ªåè¤éæ¶æ§ï¼ç¨ç¹å°çµåäºå¼·åå­¸ç¿ (RL)ãæå°åç¼æ³å LLMï¼æåºäºå¯åæ§åå¯æ´åæ§çææ°ãçºäºè§£æ±ºéäºåé¡ï¼æåæåºäºä¸åå¨é¢çèåï¼å° RLM çµä»¶çµç¹æä¸åæ¨¡çµåæ¶æ§ï¼éæ¯åºæ¼å°ææ RLM ä½åçèª¿æ¥ååæãæ­¤èååå«å¤æ¨£åçæ¨ççµæ§ï¼éãæ¨¹ãååå·¢çå½¢å¼ï¼ãæ¨çç­ç¥ï¼ä¾å¦èå°å¡ç¾æ¨¹æå°ãæ³¢ææå°ï¼ãRL æ¦å¿µï¼ç­ç¥ãå¹å¼æ¨¡åç­ï¼ãç£ç£æ¹æ¡ï¼åºæ¼çµæååºæ¼æµç¨çç£ç£ï¼åå¶ä»ç¸éæ¦å¿µï¼ä¾å¦æ¸¬è©¦æééç®ãæª¢ç´¢å¢å¼·çæãä»£çå·¥å·ï¼ãæåéæä¾äºè©³ç´°çæ¸å­¸å¬å¼åæ¼ç®æ³è¦ç¯ï¼ä»¥ç°¡å RLM çå¯¦ä½ãééå±ç¤º LLaMA-BerryãQwQãJourney Learning å Graph of Thoughts ç­æ¹æ¡å¦ä½ä½çºç¹æ®ææ³ï¼æåå±ç¤ºäºèåçå¤åè½æ§åçµ±ä¸æ½åãçºäºèªªæå¶æç¨ï¼æåä»ç´¹äº x1ï¼éæ¯ä¸åæ¨¡çµåå¯¦ä½ï¼ç¨æ¼å¿«é RLM ååè£½ä½åå¯¦é©ãä½¿ç¨ x1 åæç»åé¡§ï¼æåæä¾äºééµè¦è§£ï¼ä¾å¦ç­ç¥åå¹å¼æ¨¡åçå¤éæ®µè¨ç·´ï¼ä»¥åçæè¨ç·´åä½çéè¦æ§ãæå¾ï¼æåè¨è«äºå¯æ´åç RLM é²ç«¯é¨ç½²ï¼ä¸¦æ¦è¿°äº RLM å¦ä½èæ´å»£æ³ç LLM çæç³»çµ±æ´åãæåçç ç©¶æ­éäº RLM å»ºæ§çç¥ç§é¢ç´ï¼ä½¿åé²çæ¨çè½åæ°ä¸»åï¼ä¸¦ä¿é²åµæ°ï¼æ¨å¨éééä½ RLM è¨­è¨åå¯¦é©çéç¤ï¼ä¾ç¸®å°ãå¯è£ AIãåãè²§çª® AIãä¹éçå·®è·ã

##### **IntellAgent: A Multi-Agent Framework for Evaluating Conversational AI Systems**
2501.11067v1 by Elad Levi, Ilan Kadar

Large Language Models (LLMs) are transforming artificial intelligence,
evolving into task-oriented systems capable of autonomous planning and
execution. One of the primary applications of LLMs is conversational AI
systems, which must navigate multi-turn dialogues, integrate domain-specific
APIs, and adhere to strict policy constraints. However, evaluating these agents
remains a significant challenge, as traditional methods fail to capture the
complexity and variability of real-world interactions. We introduce
IntellAgent, a scalable, open-source multi-agent framework designed to evaluate
conversational AI systems comprehensively. IntellAgent automates the creation
of diverse, synthetic benchmarks by combining policy-driven graph modeling,
realistic event generation, and interactive user-agent simulations. This
innovative approach provides fine-grained diagnostics, addressing the
limitations of static and manually curated benchmarks with coarse-grained
metrics. IntellAgent represents a paradigm shift in evaluating conversational
AI. By simulating realistic, multi-policy scenarios across varying levels of
complexity, IntellAgent captures the nuanced interplay of agent capabilities
and policy constraints. Unlike traditional methods, it employs a graph-based
policy model to represent relationships, likelihoods, and complexities of
policy interactions, enabling highly detailed diagnostics. IntellAgent also
identifies critical performance gaps, offering actionable insights for targeted
optimization. Its modular, open-source design supports seamless integration of
new domains, policies, and APIs, fostering reproducibility and community
collaboration. Our findings demonstrate that IntellAgent serves as an effective
framework for advancing conversational AI by addressing challenges in bridging
research and deployment. The framework is available at
https://github.com/plurai-ai/intellagent

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) æ­£å¨è½è®äººå·¥æºæ§ï¼æ¼è®æå·åèªä¸»è¦ååå·è¡è½åçä»»åå°åç³»çµ±ãLLM çä¸»è¦æç¨ä¹ä¸æ¯å°è©±å¼ AI ç³»çµ±ï¼å®å¿é æå°å¤è¼ªå°è©±ãæ´åç¹å®é åç APIï¼ä¸¦éµå®å´æ ¼çæ¿ç­ç´æãç¶èï¼è©ä¼°éäºä»£çä»ç¶æ¯ä¸é éå¤§ææ°ï¼å çºå³çµ±æ¹æ³ç¡æ³ææç¾å¯¦ä¸çäºåçè¤éæ§åè®ç°æ§ãæåå¼å¥äº IntellAgentï¼ä¸åå¯æ´åãéæ¾åå§ç¢¼çå¤ä»£çæ¶æ§ï¼æ¨å¨å¨é¢è©ä¼°å°è©±å¼ AI ç³»çµ±ãIntellAgent èªååå»ºç«å¤æ¨£åãåæçåºæºï¼æ¹æ³æ¯çµåç­ç¥é©åçåå½¢å»ºæ¨¡ãé¼ççäºä»¶ç¢çåäºåä½¿ç¨èä»£çæ¨¡æ¬ãéç¨®åµæ°æ¹æ³æä¾äºç´°ç·»çè¨ºæ·ï¼è§£æ±ºäºå·æç²ç¥ææ¨çéæåæåç­ååºæºçéå¶ãIntellAgent ä»£è¡¨äºè©ä¼°å°è©±å¼ AI çå¸ç¯è½ç§»ãééæ¨¡æ¬ä¸åå±¤ç´è¤éæ§çé¼çå¤ç­ç¥å ´æ¯ï¼IntellAgent ææå°äºä»£çåè½åç­ç¥ç´æä¹éçç´°å¾®äº¤äºãèå³çµ±æ¹æ³ä¸åï¼å®æ¡ç¨åºæ¼åå½¢çç­ç¥æ¨¡åä¾è¡¨ç¤ºç­ç¥äº¤äºçéä¿ãå¯è½æ§åè¤éæ§ï¼å¾èå¯¦ç¾é«åº¦è©³ç´°çè¨ºæ·ãIntellAgent éè­å¥åºééµæè½å·®è·ï¼æä¾å¯è¡çè¦è§£ï¼ä»¥é²è¡ç®æ¨æä½³åãå¶æ¨¡çµåãéæ¾åå§ç¢¼çè¨­è¨æ¯æ´ç¡ç¸«æ´åæ°çé åãç­ç¥å APIï¼ä¿é²äºå¯è¤è£½æ§åç¤¾ç¾¤åä½ãæåçç ç©¶çµæè¡¨æï¼IntellAgent å¯ä½çºä¸åææçæ¡æ¶ï¼ééè§£æ±ºç ç©¶åé¨ç½²ä¹éçææ°ä¾æ¨é²å°è©±å¼ AIãéåæ¡æ¶å¯å¨ https://github.com/plurai-ai/intellagent åå¾

##### **Agent-as-Judge for Factual Summarization of Long Narratives**
2501.09993v1 by Yeonseok Jeong, Minsoo Kim, Seung-won Hwang, Byung-Hak Kim

Large Language Models (LLMs) have demonstrated near-human performance in
summarization tasks based on traditional metrics such as ROUGE and BERTScore.
However, these metrics do not adequately capture critical aspects of
summarization quality, such as factual accuracy, particularly for long
narratives (>100K tokens). Recent advances, such as LLM-as-a-Judge, address the
limitations of metrics based on lexical similarity but still exhibit factual
inconsistencies, especially in understanding character relationships and
states. In this work, we introduce NarrativeFactScore, a novel
"Agent-as-a-Judge" framework for evaluating and refining summaries. By
leveraging a Character Knowledge Graph (CKG) extracted from input and generated
summaries, NarrativeFactScore assesses the factual consistency and provides
actionable guidance for refinement, such as identifying missing or erroneous
facts. We demonstrate the effectiveness of NarrativeFactScore through a
detailed workflow illustration and extensive validation on widely adopted
benchmarks, achieving superior performance compared to competitive methods. Our
results highlight the potential of agent-driven evaluation systems to improve
the factual reliability of LLM-generated summaries.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å¨æè¦ä»»åä¸­å±ç¾åºæ¥è¿äººé¡çè¡¨ç¾ï¼æ ¹æå³çµ±ææ¨ï¼ä¾å¦ ROUGE å BERTScoreãç¶èï¼éäºææ¨ä¸¦æªååææ¡æè¦åè³ªçééµé¢åï¼ä¾å¦äºå¯¦æºç¢ºæ§ï¼ç¹å¥æ¯éå°é·ç¯æäº (>100K åç¬¦è)ãæè¿çé²å±ï¼ä¾å¦ LLM-as-a-Judgeï¼è§£æ±ºäºåºæ¼è©å½ç¸ä¼¼æ§çææ¨éå¶ï¼ä½ä»ç¶è¡¨ç¾åºäºå¯¦ä¸çä¸ä¸è´æ§ï¼ç¹å¥æ¯å¨çè§£è§è²éä¿åçææ¹é¢ãå¨éé å·¥ä½ä¸­ï¼æåå¼å¥äº NarrativeFactScoreï¼ä¸ç¨®æ°ç©çãä»£çäººä½çºè©å¯©ãæ¶æ§ï¼ç¨æ¼è©ä¼°åç²¾çæè¦ãééå©ç¨å¾è¼¸å¥åç¢ççæè¦ä¸­èåçè§è²ç¥è­åè­ (CKG)ï¼NarrativeFactScore è©ä¼°äºå¯¦ä¸è´æ§ï¼ä¸¦æä¾å¯è¡çç²¾çæåï¼ä¾å¦è­å¥éºæ¼æé¯èª¤çäºå¯¦ãæåééè©³ç´°çå·¥ä½æµç¨èªªæåå»£æ³é©è­å¨å»£æ³æ¡ç¨çåºæºä¸ï¼è­æäº NarrativeFactScore çæææ§ï¼èç«¶ç­æ¹æ³ç¸æ¯ï¼éå°äºåè¶çè¡¨ç¾ãæåççµæçªé¡¯äºä»£çäººé©åè©ä¼°ç³»çµ±çæ½åï¼ä»¥æ¹å LLM çæçæè¦çäºå¯¦å¯é æ§ã

##### **FRAG: A Flexible Modular Framework for Retrieval-Augmented Generation based on Knowledge Graphs**
2501.09957v2 by Zengyi Gao, Yukun Cao, Hairu Wang, Ao Ke, Yuan Feng, Xike Xie, S Kevin Zhou

To mitigate the hallucination and knowledge deficiency in large language
models (LLMs), Knowledge Graph (KG)-based Retrieval-Augmented Generation (RAG)
has shown promising potential by utilizing KGs as external resource to enhance
LLMs reasoning. However, existing KG-RAG approaches struggle with a trade-off
between flexibility and retrieval quality. Modular methods prioritize
flexibility by avoiding the use of KG-fine-tuned models during retrieval,
leading to fixed retrieval strategies and suboptimal retrieval quality.
Conversely, coupled methods embed KG information within models to improve
retrieval quality, but at the expense of flexibility. In this paper, we propose
a novel flexible modular KG-RAG framework, termed FRAG, which synergizes the
advantages of both approaches. FRAG estimates the hop range of reasoning paths
based solely on the query and classify it as either simple or complex. To match
the complexity of the query, tailored pipelines are applied to ensure efficient
and accurate reasoning path retrieval, thus fostering the final reasoning
process. By using the query text instead of the KG to infer the structural
information of reasoning paths and employing adaptable retrieval strategies,
FRAG improves retrieval quality while maintaining flexibility. Moreover, FRAG
does not require extra LLMs fine-tuning or calls, significantly boosting
efficiency and conserving resources. Extensive experiments show that FRAG
achieves state-of-the-art performance with high efficiency and low resource
consumption.

æè¦ï¼<paragraph>çºäºæ¸è¼å¤§åèªè¨æ¨¡å (LLM) ä¸­çå¹»è¦ºåç¥è­ä¸è¶³ï¼åºæ¼ç¥è­åè­ (KG) çæª¢ç´¢å¢å¼·çæ (RAG) å·²å±ç¾åºå©ç¨ KG ä½çºå¤é¨è³æºä¾å¢å¼· LLM æ¨ççæ½åãç¶èï¼ç¾æç KG-RAG æ¹æ³å¨éæ´»æ§èæª¢ç´¢åè³ªä¹éé¢è¨åæ¨ãæ¨¡çµåæ¹æ³ééé¿åå¨æª¢ç´¢æéä½¿ç¨ KG å¾®èª¿æ¨¡åä¾åªåèæ®éæ´»æ§ï¼å°è´åºå®çæª¢ç´¢ç­ç¥åæ¬¡ä½³çæª¢ç´¢åè³ªãç¸åå°ï¼è¦åæ¹æ³å° KG è³è¨åµå¥æ¨¡åä¸­ä»¥æ¹åæª¢ç´¢åè³ªï¼ä½ç§ç²äºéæ´»æ§ãå¨æ¬æä¸­ï¼æåæåºäºä¸åæ°ç©çéæ´»æ¨¡çµå KG-RAG æ¡æ¶ï¼ç¨±çº FRAGï¼å®ååäºå©ç¨®æ¹æ³çåªé»ãFRAG åæ ¹ææ¥è©¢ä¼°è¨æ¨çè·¯å¾çè·³èºç¯åï¼ä¸¦å°å¶åé¡çºç°¡å®æè¤éãçºäºå¹éæ¥è©¢çè¤éæ§ï¼æç¨å®¢è£½åç®¡éä»¥ç¢ºä¿ææä¸æºç¢ºçæ¨çè·¯å¾æª¢ç´¢ï¼å¾èä¿é²æçµçæ¨çéç¨ãFRAG ä½¿ç¨æ¥è©¢æå­èé KG ä¾æ¨æ·æ¨çè·¯å¾ççµæ§åè³è¨ï¼ä¸¦æ¡ç¨å¯é©æçæª¢ç´¢ç­ç¥ï¼å¾èæ¹åæª¢ç´¢åè³ªï¼åæä¿æéæ´»æ§ãæ­¤å¤ï¼FRAG ä¸éè¦é¡å¤ç LLM å¾®èª¿æå¼å«ï¼é¡¯èæåæçä¸¦ç¯çè³æºãå¤§éçå¯¦é©è¡¨æï¼FRAG ä»¥é«æçåä½è³æºæ¶èå¯¦ç¾äºæåé²çæè½ã</paragraph>

##### **SOP-Agent: Empower General Purpose AI Agent with Domain-Specific SOPs**
2501.09316v1 by Anbang Ye, Qianran Ma, Jia Chen, Muqi Li, Tong Li, Fujiao Liu, Siqi Mai, Meichen Lu, Haitao Bao, Yang You

Despite significant advancements in general-purpose AI agents, several
challenges still hinder their practical application in real-world scenarios.
First, the limited planning capabilities of Large Language Models (LLM)
restrict AI agents from effectively solving complex tasks that require
long-horizon planning. Second, general-purpose AI agents struggle to
efficiently utilize domain-specific knowledge and human expertise. In this
paper, we introduce the Standard Operational Procedure-guided Agent
(SOP-agent), a novel framework for constructing domain-specific agents through
pseudocode-style Standard Operational Procedures (SOPs) written in natural
language. Formally, we represent a SOP as a decision graph, which is traversed
to guide the agent in completing tasks specified by the SOP. We conduct
extensive experiments across tasks in multiple domains, including
decision-making, search and reasoning, code generation, data cleaning, and
grounded customer service. The SOP-agent demonstrates excellent versatility,
achieving performance superior to general-purpose agent frameworks and
comparable to domain-specific agent systems. Additionally, we introduce the
Grounded Customer Service Benchmark, the first benchmark designed to evaluate
the grounded decision-making capabilities of AI agents in customer service
scenarios based on SOPs.

æè¦ï¼åç®¡éç¨ AI ä»£çå¨ä¸è¬ç¨éä¸åå¾é¡¯èé²å±ï¼ä½ä»ææ¸é ææ°é»ç¤å¶å¨å¯¦éå ´æ¯ä¸­çå¯¦ç¨æç¨ã
é¦åï¼å¤§åèªè¨æ¨¡å (LLM) æéçè¦åè½åéå¶äº AI ä»£çææè§£æ±ºéè¦é·æè¦åçè¤éä»»åãå¶æ¬¡ï¼éç¨ AI ä»£çé£ä»¥ææå©ç¨ç¹å®é åçç¥è­åäººé¡å°æ¥­ç¥è­ãå¨æ¬æä¸­ï¼æåä»ç´¹äºæ¨æºæä½ç¨åºå¼å°ä»£ç (SOP-agent)ï¼éæ¯ä¸åééä»¥èªç¶èªè¨æ°å¯«çå½ä»£ç¢¼é¢¨æ ¼æ¨æºæä½ç¨åº (SOP) ä¾å»ºæ§ç¹å®é åä»£ççæ°ç©æ¶æ§ãæ­£å¼ä¾èªªï¼æåå° SOP è¡¨ç¤ºçºæ±ºç­åï¼ä¸¦å¨å¶ä¸­ç©¿æ¢­ä»¥å¼å°ä»£çå®æ SOP æå®çä»»åãæåå¨å¤åé åä¸­çä»»åä¸­é²è¡å»£æ³çå¯¦é©ï¼åæ¬æ±ºç­å¶å®ãæå°åæ¨çãç¨å¼ç¢¼çæãè³ææ¸çååºç¤å®¢æ¶æåãSOP-agent å±ç¤ºåºåè¶çå¤åè½æ§ï¼å¶æè½åªæ¼éç¨ä»£çæ¶æ§ï¼ä¸èç¹å®é åä»£çç³»çµ±ç¸ç¶ãæ­¤å¤ï¼æåä»ç´¹äºåºç¤å®¢æ¶æååºæºï¼éæ¯ç¬¬ä¸ååºæºï¼æ¨å¨è©ä¼° AI ä»£çå¨åºæ¼ SOP çå®¢æ¶æåå ´æ¯ä¸­åºç¤æ±ºç­å¶å®è½åã

##### **Text Semantics to Flexible Design: A Residential Layout Generation Method Based on Stable Diffusion Model**
2501.09279v1 by Zijin Qiu, Jiepeng Liu, Yi Xia, Hongtuo Qi, Pengkun Liu

Flexibility in the AI-based residential layout design remains a significant
challenge, as traditional methods like rule-based heuristics and graph-based
generation often lack flexibility and require substantial design knowledge from
users. To address these limitations, we propose a cross-modal design approach
based on the Stable Diffusion model for generating flexible residential
layouts. The method offers multiple input types for learning objectives,
allowing users to specify both boundaries and layouts. It incorporates natural
language as design constraints and introduces ControlNet to enable stable
layout generation through two distinct pathways. We also present a scheme that
encapsulates design expertise within a knowledge graph and translates it into
natural language, providing an interpretable representation of design
knowledge. This comprehensibility and diversity of input options enable
professionals and non-professionals to directly express design requirements,
enhancing flexibility and controllability. Finally, experiments verify the
flexibility of the proposed methods under multimodal constraints better than
state-of-the-art models, even when specific semantic information about room
areas or connections is incomplete.

æè¦ï¼å¨åºæ¼ AI çä½å®ä½å±è¨­è¨ä¸­ï¼éæ´»æ§ä»æ¯ä¸é éå¤§ææ°ï¼å çºåºæ¼è¦åçåç¼æ³ååºæ¼åå½¢çç¢çç­å³çµ±æ¹æ³éå¸¸ç¼ºä¹éæ´»æ§ï¼ä¸éè¦ä½¿ç¨èå·åå¤§éçè¨­è¨ç¥è­ãçºäºè§£æ±ºéäºéå¶ï¼æåæåºä¸åè·¨æ¨¡æè¨­è¨æ¹æ³ï¼è©²æ¹æ³åºæ¼ Stable Diffusion æ¨¡åï¼ç¨æ¼ç¢çéæ´»çä½å®ä½å±ãæ­¤æ¹æ³æä¾å¤ç¨®è¼¸å¥é¡åä»¥é²è¡å­¸ç¿ç®æ¨ï¼ä½¿ç¨æ¶è½å¤ åææå®éçåä½å±ãå®å°èªç¶èªè¨ä½çºè¨­è¨ç´æï¼ä¸¦å¼å¥ ControlNetï¼ä»¥ééå©åä¸åçè·¯å¾å¯¦ç¾ç©©å®çä½å±ç¢çãæåéæåºäºä¸åå°è¨­è¨å°æ¥­ç¥è­å°è£å¨ç¥è­åå½¢ä¸­çæ¹æ¡ï¼ä¸¦å°å¶è½æçºèªç¶èªè¨ï¼æä¾è¨­è¨ç¥è­çå¯è©®éè¡¨ç¤ºãéç¨®å¯çè§£æ§åè¼¸å¥é¸é çå¤æ¨£æ§ä½¿å°æ¥­äººå£«åéå°æ¥­äººå£«è½å¤ ç´æ¥è¡¨éè¨­è¨éæ±ï¼å¾èå¢å¼·éæ´»æ§èå¯æ§æ§ãæå¾ï¼å¯¦é©é©è­äºææåºçæ¹æ³å¨å¤æ¨¡æç´æä¸çéæ´»æ§åªæ¼æåé²çæ¨¡åï¼å³ä½¿éæ¼æ¿éååæé£æ¥çç¹å®èªç¾©è³è¨ä¸å®æ´æä¹æ¯å¦æ­¤ã

##### **A Simple Graph Contrastive Learning Framework for Short Text Classification**
2501.09219v1 by Yonghao Liu, Fausto Giunchiglia, Lan Huang, Ximing Li, Xiaoyue Feng, Renchu Guan

Short text classification has gained significant attention in the information
age due to its prevalence and real-world applications. Recent advancements in
graph learning combined with contrastive learning have shown promising results
in addressing the challenges of semantic sparsity and limited labeled data in
short text classification. However, existing models have certain limitations.
They rely on explicit data augmentation techniques to generate contrastive
views, resulting in semantic corruption and noise. Additionally, these models
only focus on learning the intrinsic consistency between the generated views,
neglecting valuable discriminative information from other potential views. To
address these issues, we propose a Simple graph contrastive learning framework
for Short Text Classification (SimSTC). Our approach involves performing graph
learning on multiple text-related component graphs to obtain multi-view text
embeddings. Subsequently, we directly apply contrastive learning on these
embeddings. Notably, our method eliminates the need for data augmentation
operations to generate contrastive views while still leveraging the benefits of
multi-view contrastive learning. Despite its simplicity, our model achieves
outstanding performance, surpassing large language models on various datasets.

æè¦ï¼ç­ææ¬åç±»å¨ä¿¡æ¯æ¶ä»£å¾å°äºå¹¿æ³å³æ³¨ï¼å ä¸ºå®å·ææ®éæ§åç°å®ä¸ççåºç¨ãæè¿ï¼å¾å­¦ä¹ ä¸å¯¹æ¯å­¦ä¹ ç¸ç»åçè¿æ­¥å¨è§£å³ç­ææ¬åç±»ä¸­è¯­ä¹ç¨çæ§åæ è®°æ°æ®æéçæææ¹é¢æ¾ç¤ºåºæå¸æçç»æãç¶èï¼ç°æçæ¨¡åå·æä¸å®çå±éæ§ãå®ä»¬ä¾èµäºæ¾å¼çæ°æ®å¢å¼ºææ¯æ¥çæå¯¹æ¯è§å¾ï¼ä»èå¯¼è´è¯­ä¹æåååªå£°ãæ­¤å¤ï¼è¿äºæ¨¡ååªå³æ³¨å­¦ä¹ çæè§å¾ä¹é´çåå¨ä¸è´æ§ï¼èå¿½ç¥äºå¶ä»æ½å¨è§å¾ä¸­æä»·å¼çå¤å«ä¿¡æ¯ãä¸ºäºè§£å³è¿äºé®é¢ï¼æä»¬æåºäºä¸ä¸ªç¨äºç­ææ¬åç±»çç®åå¾å¯¹æ¯å­¦ä¹ æ¡æ¶ (SimSTC)ãæä»¬çæ¹æ³æ¶åå¯¹å¤ä¸ªææ¬ç¸å³ç»ä»¶å¾æ§è¡å¾å­¦ä¹ ä»¥è·å¾å¤è§å¾ææ¬åµå¥ãéåï¼æä»¬ç´æ¥å¯¹è¿äºåµå¥åºç¨å¯¹æ¯å­¦ä¹ ãå¼å¾æ³¨æçæ¯ï¼æä»¬çæ¹æ³æ¶é¤äºçæå¯¹æ¯è§å¾æ¶å¯¹æ°æ®å¢å¼ºæä½çéæ±ï¼åæ¶ä»ç¶å©ç¨äºå¤è§å¾å¯¹æ¯å­¦ä¹ çä¼å¿ãå°½ç®¡å¾ç®åï¼ä½æä»¬çæ¨¡åè·å¾äºåºè²çæ§è½ï¼å¨åç§æ°æ®éä¸è¶è¶äºå¤§åè¯­è¨æ¨¡åã

##### **Boosting Short Text Classification with Multi-Source Information Exploration and Dual-Level Contrastive Learning**
2501.09214v1 by Yonghao Liu, Mengyu Li, Wei Pang, Fausto Giunchiglia, Lan Huang, Xiaoyue Feng, Renchu Guan

Short text classification, as a research subtopic in natural language
processing, is more challenging due to its semantic sparsity and insufficient
labeled samples in practical scenarios. We propose a novel model named
MI-DELIGHT for short text classification in this work. Specifically, it first
performs multi-source information (i.e., statistical information, linguistic
information, and factual information) exploration to alleviate the sparsity
issues. Then, the graph learning approach is adopted to learn the
representation of short texts, which are presented in graph forms. Moreover, we
introduce a dual-level (i.e., instance-level and cluster-level) contrastive
learning auxiliary task to effectively capture different-grained contrastive
information within massive unlabeled data. Meanwhile, previous models merely
perform the main task and auxiliary tasks in parallel, without considering the
relationship among tasks. Therefore, we introduce a hierarchical architecture
to explicitly model the correlations between tasks. We conduct extensive
experiments across various benchmark datasets, demonstrating that MI-DELIGHT
significantly surpasses previous competitive models. It even outperforms
popular large language models on several datasets.

æè¦ï¼ç­ææ¬åé¡ä½çºèªç¶èªè¨èççç ç©¶å­ä¸»é¡ï¼ç±æ¼å¶èªç¾©ç¨çæ§åå¯¦éå ´æ¯ä¸­æ¨è¨æ¨£æ¬ä¸è¶³ï¼å æ­¤æ´å·ææ°æ§ãå¨éé å·¥ä½ä¸­ï¼æåæåºäºä¸ååçº MI-DELIGHT çæ°æ¨¡åï¼ç¨æ¼ç­ææ¬åé¡ãå·é«ä¾èªªï¼å®é¦åå·è¡å¤æºä¿¡æ¯ï¼å³çµ±è¨ä¿¡æ¯ãèªè¨ä¿¡æ¯åäºå¯¦ä¿¡æ¯ï¼æ¢ç´¢ï¼ä»¥ç·©è§£ç¨çæ§åé¡ãç¶å¾ï¼æ¡ç¨åå­¸ç¿æ¹æ³ä¾å­¸ç¿ä»¥åè¡¨å½¢å¼åç¾çç­ææ¬çè¡¨ç¤ºãæ­¤å¤ï¼æåå¼å¥äºä¸åéå±¤ç´ï¼å³å¯¦ä¾å±¤ç´åç¾¤éå±¤ç´ï¼å°æ¯å­¸ç¿è¼å©ä»»åï¼ä»¥æææç²å¤§éæªæ¨è¨æ¸æä¸­çä¸åç²åº¦å°æ¯ä¿¡æ¯ãåæï¼ä»¥åçæ¨¡ååä¸¦è¡å·è¡ä¸»ä»»ååè¼å©ä»»åï¼èæ²æèæ®ä»»åä¹éçéä¿ãå æ­¤ï¼æåå¼å¥äºä¸ååå±¤æ¶æ§ä¾æç¢ºå»ºæ¨¡ä»»åä¹éçç¸éæ§ãæåå¨åç¨®åºæºæ¸æéä¸é²è¡äºå»£æ³çå¯¦é©ï¼è­æ MI-DELIGHT æé¡¯åªæ¼ä»¥åçç«¶ç­æ¨¡åãå®çè³å¨å¹¾åæ¸æéä¸åªæ¼æµè¡çå¤§èªè¨æ¨¡åã

##### **Leveraging Large Language Models as Knowledge-Driven Agents for Reliable Retrosynthesis Planning**
2501.08897v1 by Qinyu Ma, Yuhao Zhou, Jianfeng Li

Identifying reliable synthesis pathways in materials chemistry is a complex
task, particularly in polymer science, due to the intricate and often
non-unique nomenclature of macromolecules. To address this challenge, we
propose an agent system that integrates large language models (LLMs) and
knowledge graphs (KGs). By leveraging LLMs' powerful capabilities for
extracting and recognizing chemical substance names, and storing the extracted
data in a structured knowledge graph, our system fully automates the retrieval
of relevant literatures, extraction of reaction data, database querying,
construction of retrosynthetic pathway trees, further expansion through the
retrieval of additional literature and recommendation of optimal reaction
pathways. A novel Multi-branched Reaction Pathway Search (MBRPS) algorithm
enables the exploration of all pathways, with a particular focus on
multi-branched ones, helping LLMs overcome weak reasoning in multi-branched
paths. This work represents the first attempt to develop a fully automated
retrosynthesis planning agent tailored specially for macromolecules powered by
LLMs. Applied to polyimide synthesis, our new approach constructs a
retrosynthetic pathway tree with hundreds of pathways and recommends optimized
routes, including both known and novel pathways, demonstrating its
effectiveness and potential for broader applications.

æè¦ï¼è¾¨è­ææåå­¸ä¸­å¯é çåæè·¯å¾æ¯ä¸é è¤éçä»»åï¼ç¹å¥æ¯å¨èåç©ç§å­¸ä¸­ï¼å çºå·¨åå­çå½åæ³é¯ç¶è¤éä¸ç¶å¸¸ä¸å¯ä¸ãçºäºæå°éåææ°ï¼æåæåºä¸åæ´åå¤§åèªè¨æ¨¡å (LLM) èç¥è­åè­ (KG) çä»£çç³»çµ±ãééå©ç¨ LLM å¼·å¤§çåå­¸ç©è³ªåç¨±èååè¾¨è­è½åï¼ä¸¦å°èåçè³æå²å­å¨çµæ§åçç¥è­åè­ä¸­ï¼æåçç³»çµ±å¯å®å¨èªååç¸éæç»çæª¢ç´¢ãåæè³æçèåãè³æåº«æ¥è©¢ãéåæè·¯å¾æ¨¹çå»ºæ§ãééæª¢ç´¢é¡å¤æç»é²ä¸æ­¥æ´åï¼ä»¥åæä½³åæè·¯å¾çå»ºè­°ãä¸ç¨®æ°ç©çå¤åæ¯åæè·¯å¾æå° (MBRPS) æ¼ç®æ³è½æ¢ç´¢ææè·¯å¾ï¼ç¹å¥å°æ³¨æ¼å¤åæ¯è·¯å¾ï¼åå© LLM åæå¤åæ¯è·¯å¾ä¸­çå¼±æ¨çãéé å·¥ä½ä»£è¡¨é¦æ¬¡åè©¦éç¼ä¸ç¨®å®å¨èªååçéåæè¦åä»£çï¼å°ééå°ç± LLM é©åçå·¨åå­éèº«æé ãæç¨æ¼èé¯äºèºåæï¼æåçæ°æ¹æ³å»ºæ§äºä¸ååå«æ¸ç¾æ¢è·¯å¾çéåæè·¯å¾æ¨¹ï¼ä¸¦å»ºè­°æä½³åè·¯å¾ï¼åæ¬å·²ç¥åæ°ç©çè·¯å¾ï¼è­æå¶å¨æ´å»£æ³æç¨ä¸­çæè½åæ½åã

##### **Knowledge Graph-based Retrieval-Augmented Generation for Schema Matching**
2501.08686v1 by Chuangtao Ma, Sriom Chakrabarti, Arijit Khan, BÃ¡lint MolnÃ¡r

Traditional similarity-based schema matching methods are incapable of
resolving semantic ambiguities and conflicts in domain-specific complex mapping
scenarios due to missing commonsense and domain-specific knowledge. The
hallucination problem of large language models (LLMs) also makes it challenging
for LLM-based schema matching to address the above issues. Therefore, we
propose a Knowledge Graph-based Retrieval-Augmented Generation model for Schema
Matching, referred to as the KG-RAG4SM. In particular, KG-RAG4SM introduces
novel vector-based, graph traversal-based, and query-based graph retrievals, as
well as a hybrid approach and ranking schemes that identify the most relevant
subgraphs from external large knowledge graphs (KGs). We showcase that KG-based
retrieval-augmented LLMs are capable of generating more accurate results for
complex matching cases without any re-training. Our experimental results show
that KG-RAG4SM outperforms the LLM-based state-of-the-art (SOTA) methods (e.g.,
Jellyfish-8B) by 35.89% and 30.50% in terms of precision and F1 score on the
MIMIC dataset, respectively; KG-RAG4SM with GPT-4o-mini outperforms the
pre-trained language model (PLM)-based SOTA methods (e.g., SMAT) by 69.20% and
21.97% in terms of precision and F1 score on the Synthea dataset, respectively.
The results also demonstrate that our approach is more efficient in end-to-end
schema matching, and scales to retrieve from large KGs. Our case studies on the
dataset from the real-world schema matching scenario exhibit that the
hallucination problem of LLMs for schema matching is well mitigated by our
solution.

æè¦ï¼å³çµ±åºæ¼ç¸ä¼¼åº¦çæ¨¡å¼æ¯å°æ¹æ³ç¡æ³è§£æ±ºç¹å®é åè¤éæ¯å°å ´æ¯ä¸­çèªææ¨¡ç³æ§åè¡çªï¼éæ¯å çºç¼ºä¹å¸¸è­åç¹å®é åç¥è­ãå¤§åèªè¨æ¨¡å (LLM) çå¹»è¦ºåé¡ä¹ä½¿å¾åºæ¼ LLM çæ¨¡å¼æ¯å°é£ä»¥è§£æ±ºä¸è¿°åé¡ãå æ­¤ï¼æåæåºä¸ååºæ¼ç¥è­åè­çæª¢ç´¢å¢å¼·çææ¨¡åï¼ç¨æ¼æ¨¡å¼æ¯å°ï¼ç¨±çº KG-RAG4SMãå·é«èè¨ï¼KG-RAG4SM å¼å¥äºåºæ¼åéçãåºæ¼åå½¢éæ­·çååºæ¼æ¥è©¢çåå½¢æª¢ç´¢ï¼ä»¥åä¸ç¨®æ··åæ¹æ³åæåæ¹æ¡ï¼éäºæ¹æ¡å¾å¤é¨å¤§åç¥è­åè­ (KG) ä¸­è­å¥æç¸éçå­åãæåå±ç¤ºäºåºæ¼ KG çæª¢ç´¢å¢å¼· LLM è½å¤ å¨ä¸é²è¡ä»»ä½éæ°è¨ç·´çææ³ä¸çºè¤éçæ¯å°æ¡ä¾çææ´æºç¢ºççµæãæåçå¯¦é©çµæè¡¨æï¼å¨ MIMIC è³æéä¸ï¼KG-RAG4SM å¨æºç¢ºåº¦å F1 åæ¸æ¹é¢åå¥æ¯åºæ¼ LLM çææ° (SOTA) æ¹æ³ (ä¾å¦ Jellyfish-8B) é«åº 35.89% å 30.50%ï¼å·æ GPT-4o-mini ç KG-RAG4SM å¨æºç¢ºåº¦å F1 åæ¸æ¹é¢åå¥æ¯åºæ¼é åè¨ç·´èªè¨æ¨¡å (PLM) ç SOTA æ¹æ³ (ä¾å¦ SMAT) é«åº 69.20% å 21.97% å¨ Synthea è³æéä¸ãçµæéè¡¨æï¼æåçåæ³å¨ç«¯å°ç«¯æ¨¡å¼æ¯å°ä¸­æ´ææçï¼ä¸¦ä¸å¯ä»¥æ´å±å°å¾å¤§å KG ä¸­æª¢ç´¢ãæåå°ä¾èªç¾å¯¦ä¸çæ¨¡å¼æ¯å°å ´æ¯çè³æéé²è¡çæ¡ä¾ç ç©¶è¡¨æï¼æåçè§£æ±ºæ¹æ¡å¾å¥½å°ç·©è§£äº LLM å¨æ¨¡å¼æ¯å°ä¸­çå¹»è¦ºåé¡ã

##### **Assessing the Alignment of FOL Closeness Metrics with Human Judgement**
2501.08613v2 by Ramya Keerthy Thatikonda, Wray Buntine, Ehsan Shareghi

The recent successful paradigm of solving logical reasoning problems with
tool-augmented large language models (LLMs) leverages translation of natural
language statements into First-Order Logic~(FOL) and external theorem provers.
However, the correctness of FOL statements, comprising operators and text
predicates, often goes unverified due to the lack of a reliable evaluation
metric for comparing generated and ground-truth FOLs. In this paper, we present
a comprehensive study of sensitivity of existing metrics and their alignment
with human judgement on FOL evaluation. Using ground-truth FOLs, we carefully
designed various perturbations on the ground-truth to assess metric
sensitivity. We sample FOL translation candidates for natural language
statements and measure the ranking alignment between automatic metrics and
human annotators. Our empirical findings highlight oversensitivity in the
n-gram metric BLEU for text perturbations, the semantic graph metric Smatch++
for structural perturbations, and FOL metric for operator perturbation. We also
observe a closer alignment between BertScore and human judgement. Additionally,
we show that combining metrics enhances both alignment and sensitivity compared
to using individual metrics.

æè¦ï¼è¿ææåè§£æ±ºéè¼¯æ¨çåé¡çç¯ä¾ï¼å©ç¨äºå·¥å·å¢å¼·å¼å¤§åèªè¨æ¨¡å (LLM)ï¼å°èªç¶èªè¨é³è¿°ç¿»è­¯æä¸ééè¼¯ (FOL) åå¤é¨å®çè­æå¨ã
ç¶èï¼FOL é³è¿°çæ­£ç¢ºæ§åå«éç®å­èæå­è¬è©ï¼ç±æ¼ç¼ºä¹ç¨æ¼æ¯è¼å·²ç¢çèçå¯¦ FOL çå¯é è©ä¼°ææ¨ï¼å æ­¤ç¶å¸¸ç¡æ³é©è­ãå¨æ¬æä¸­ï¼æåæåºå°ç¾æææ¨ææåº¦åå¶èäººé¡å° FOL è©ä¼°å¤æ·ä¸è´æ§çå¨é¢ç ç©¶ãä½¿ç¨çå¯¦ FOLï¼æåä»ç´°è¨­è¨äºçå¯¦ FOL çåç¨®æ¾åï¼ä»¥è©ä¼°ææ¨ææåº¦ãæåå°èªç¶èªè¨é³è¿°åæ¨£ FOL ç¿»è­¯åé¸é ï¼ä¸¦è¡¡éèªåææ¨èäººé¡è¨»è§£èä¹éçæåä¸è´æ§ãæåçç¶é©ç¼ç¾å¼·èª¿ n-gram ææ¨ BLEU å°æå­æ¾åçéåº¦æææ§ï¼èªç¾©åå½¢ææ¨ Smatch++ å°çµæ§æ¾åçéåº¦æææ§ï¼ä»¥å FOL ææ¨å°éç®å­æ¾åçéåº¦æææ§ãæåéè§å¯å° BertScore èäººé¡å¤æ·ä¹éæ´ç·å¯çå°é½ãæ­¤å¤ï¼æåè¡¨æï¼èä½¿ç¨åå¥ææ¨ç¸æ¯ï¼çµåææ¨å¯å¢å¼·å°é½åææåº¦ã

##### **AutoRestTest: A Tool for Automated REST API Testing Using LLMs and MARL**
2501.08600v1 by Tyler Stennett, Myeongsoo Kim, Saurabh Sinha, Alessandro Orso

As REST APIs have become widespread in modern web services, comprehensive
testing of these APIs has become increasingly crucial. Due to the vast search
space consisting of operations, parameters, and parameter values along with
their complex dependencies and constraints, current testing tools suffer from
low code coverage, leading to suboptimal fault detection. To address this
limitation, we present a novel tool, AutoRestTest, which integrates the
Semantic Operation Dependency Graph (SODG) with Multi-Agent Reinforcement
Learning (MARL) and large language models (LLMs) for effective REST API
testing. AutoRestTest determines operation-dependent parameters using the SODG
and employs five specialized agents (operation, parameter, value, dependency,
and header) to identify dependencies of operations and generate operation
sequences, parameter combinations, and values. AutoRestTest provides a
command-line interface and continuous telemetry on successful operation count,
unique server errors detected, and time elapsed. Upon completion, AutoRestTest
generates a detailed report highlighting errors detected and operations
exercised. In this paper, we introduce our tool and present preliminary
results.

æè¦ï¼é¨è REST API å¨ç¾ä»£ç¶²è·¯æåä¸­å»£æ³ä½¿ç¨ï¼å°éäº API é²è¡å¨é¢çæ¸¬è©¦è®å¾è¶ä¾è¶éè¦ãç±æ¼å»£å¤§çæå°ç©ºéåå«æä½ãåæ¸ååæ¸å¼ä»¥åå®åè¤éçä¾è³´éä¿åç´æï¼ç®åçæ¸¬è©¦å·¥å·å­å¨ç¨å¼ç¢¼è¦èçä½çåé¡ï¼å°è´æéåµæ¸¬ä¸ä½³ãçºäºè§£æ±ºéåéå¶ï¼æåæåºä¸åæ°å·¥å· AutoRestTestï¼å®æ´åäºèªç¾©æä½ä¾è³´å (SODG) èå¤æºè½é«å¼·åå­¸ç¿ (MARL) åå¤§åèªè¨æ¨¡å (LLM)ï¼ä»¥é²è¡ææç REST API æ¸¬è©¦ãAutoRestTest ä½¿ç¨ SODG ç¢ºå®ä¾è³´æ¼æä½çåæ¸ï¼ä¸¦ä½¿ç¨äºåå°éçä»£ç (æä½ãåæ¸ãå¼ãä¾è³´éä¿åæ¨é ­) ä¾è­å¥æä½çä¾è³´éä¿ä¸¦ç¢çæä½åºåãåæ¸çµååå¼ãAutoRestTest æä¾å½ä»¤åä»é¢åæçºéæ¸¬ï¼åæ¬æåæä½æ¬¡æ¸ãåµæ¸¬å°çå¯ä¸ä¼ºæå¨é¯èª¤åç¶éæéãå®æå¾ï¼AutoRestTest æç¢çä¸ä»½è©³ç´°å ±åï¼éé»èªªæåµæ¸¬å°çé¯èª¤åå·è¡çæä½ãå¨æ¬æä¸­ï¼æåä»ç´¹æåçå·¥å·ä¸¦æåºåæ­¥çµæã

##### **LoRS: Efficient Low-Rank Adaptation for Sparse Large Language Model**
2501.08582v1 by Yuxuan Hu, Jing Zhang, Xiaodong Chen, Zhe Zhao, Cuiping Li, Hong Chen

Existing low-rank adaptation (LoRA) methods face challenges on sparse large
language models (LLMs) due to the inability to maintain sparsity. Recent works
introduced methods that maintain sparsity by augmenting LoRA techniques with
additional masking mechanisms. Despite these successes, such approaches suffer
from an increased memory and computation overhead, which affects efficiency of
LoRA methods. In response to this limitation, we introduce LoRS, an innovative
method designed to achieve both memory and computation efficiency when
fine-tuning sparse LLMs. To mitigate the substantial memory and computation
demands associated with preserving sparsity, our approach incorporates
strategies of weight recompute and computational graph rearrangement. In
addition, we also improve the effectiveness of LoRS through better adapter
initialization. These innovations lead to a notable reduction in memory and
computation consumption during the fine-tuning phase, all while achieving
performance levels that outperform existing LoRA approaches.

æè¦ï¼ç¾æçä½ç§©é©æ (LoRA) æ¹æ³ç±æ¼ç¡æ³ç¶­æç¨çæ§ï¼å¨ç¨çå¤§åèªè¨æ¨¡å (LLM) ä¸é¢è¨ææ°ãæè¿çä½åå¼å¥äºééä½¿ç¨é¡å¤çé®ç½©æ©å¶ä¾æ´å LoRA æè¡çæ¹æ³ä¾ç¶­æç¨çæ§ãåç®¡æéäºæåï¼ä½éäºæ¹æ³æå¢å è¨æ¶é«åéç®çéé·ï¼éæå½±é¿ LoRA æ¹æ³çæçãçºäºåæéåéå¶ï¼æåå¼å¥äº LoRSï¼éæ¯ä¸ç¨®åµæ°çæ¹æ³ï¼æ¨å¨å¨å¾®èª¿ç¨ç LLM æåæå¯¦ç¾è¨æ¶é«åéç®æçãçºäºæ¸è¼èç¶­æç¨çæ§ç¸éçé¾å¤§è¨æ¶é«åéç®éæ±ï¼æåçåæ³çµåäºæ¬ééæ°è¨ç®åè¨ç®åå½¢éæ°æåçç­ç¥ãæ­¤å¤ï¼æåéééæ´å¥½çé©éå¨åå§åä¾æé« LoRS çæææ§ãéäºåµæ°å¨å¾®èª¿éæ®µé¡¯èæ¸å°äºè¨æ¶é«åéç®æ¶èï¼åæå¯¦ç¾äºåªæ¼ç¾æ LoRA æ¹æ³çæè½ç­ç´ã

##### **Towards Zero-Shot & Explainable Video Description by Reasoning over Graphs of Events in Space and Time**
2501.08460v1 by Mihai Masala, Marius Leordeanu

In the current era of Machine Learning, Transformers have become the de facto
approach across a variety of domains, such as computer vision and natural
language processing. Transformer-based solutions are the backbone of current
state-of-the-art methods for language generation, image and video
classification, segmentation, action and object recognition, among many others.
Interestingly enough, while these state-of-the-art methods produce impressive
results in their respective domains, the problem of understanding the
relationship between vision and language is still beyond our reach. In this
work, we propose a common ground between vision and language based on events in
space and time in an explainable and programmatic way, to connect
learning-based vision and language state of the art models and provide a
solution to the long standing problem of describing videos in natural language.
We validate that our algorithmic approach is able to generate coherent, rich
and relevant textual descriptions on videos collected from a variety of
datasets, using both standard metrics (e.g. Bleu, ROUGE) and the modern
LLM-as-a-Jury approach.

æè¦ï¼å¨æ©å¨å­¸ç¿çç¶ä»£ï¼Transformer å·²æçºåç¨®é åçäºå¯¦æ¨æºæ¹æ³ï¼ä¾å¦é»è¦è¦è¦ºåèªç¶èªè¨èçãåºæ¼ Transformer çè§£æ±ºæ¹æ¡æ¯ç¶åèªè¨çæãå½±ååå½±çåé¡ãåå²ãåä½åç©ä»¶è¾¨è­ç­ææ°æ¹æ³çéª¨å¹¹ãæè¶£çæ¯ï¼éç¶éäºææ°æ¹æ³å¨å¶åèªçé åä¸­ç¢çä»¤äººå°è±¡æ·±å»ççµæï¼ä½çè§£è¦è¦ºåèªè¨ä¹ééä¿çåé¡ä»ç¶è¶åºäºæåççè§£ç¯åãå¨éé å·¥ä½ä¸­ï¼æåä»¥å¯è§£éä¸ä»¥ç¨å¼çºåºç¤çæ¹å¼ï¼å¨æç©ºä¸­çäºä»¶ä¹éæåºäºè¦è¦ºåèªè¨çå±ååºç¤ï¼ä»¥é£æ¥åºæ¼å­¸ç¿çè¦è¦ºåèªè¨ææ°æ¨¡åï¼ä¸¦æä¾æè¿°å½±ççèªç¶èªè¨é·æåé¡çè§£æ±ºæ¹æ¡ãæåé©è­äºæåçæ¼ç®æ³æ¹æ³è½å¤ å¨å¾åç¨®è³æéæ¶éçå½±çä¸­ç¢çé£è²«ãè±å¯ä¸ç¸éçæå­æè¿°ï¼åæä½¿ç¨æ¨æºææ¨ï¼ä¾å¦ BleuãROUGEï¼åç¾ä»£ LLM ä½çºè©å¯©æ¹æ³ã

##### **In-situ graph reasoning and knowledge expansion using Graph-PReFLexOR**
2501.08120v1 by Markus J. Buehler

The pursuit of automated scientific discovery has fueled progress from
symbolic logic to modern AI, forging new frontiers in reasoning and pattern
recognition. Transformers function as potential systems, where every possible
relationship remains latent potentiality until tasks impose constraints, akin
to measurement. Yet, refining their sampling requires more than probabilistic
selection: solutions must conform to specific structures or rules, ensuring
consistency and the invocation of general principles. We present
Graph-PReFLexOR (Graph-based Preference-based Recursive Language Modeling for
Exploratory Optimization of Reasoning), a framework that combines graph
reasoning with symbolic abstraction to dynamically expand domain knowledge.
Inspired by reinforcement learning, Graph-PReFLexOR defines reasoning as a
structured mapping, where tasks yield knowledge graphs, abstract patterns, and
ultimately, final answers. Inspired by category theory, it encodes concepts as
nodes and their relationships as edges, supporting hierarchical inference and
adaptive learning through isomorphic representations. Demonstrations include
hypothesis generation, materials design, and creative reasoning, such as
discovering relationships between mythological concepts like 'thin places' with
materials science. We propose a 'knowledge garden growth' strategy that
integrates insights across domains, promoting interdisciplinary connections.
Results with a 3-billion-parameter Graph-PReFLexOR model show superior
reasoning depth and adaptability, underscoring the potential for transparent,
multidisciplinary AI-driven discovery. It lays the groundwork for general
autonomous reasoning solutions.

æè¦ï¼<paragraph>è¿½æ±èªååç§å­¸ç¼ç¾å·²ç¶æ¨åäºå¾ç¬¦èéè¼¯å°ç¾ä»£ AI çé²å±ï¼å¨æ¨çåæ¨¡å¼è­å¥ä¸­éé¢äºæ°çé åãTransformer ä½çºæ½å¨ç³»çµ±éä½ï¼å¶ä¸­æ¯ç¨®å¯è½çéä¿é½ä¿ææ½å¨æ½åï¼ç´å°ä»»åæ½å ç´æï¼é¡ä¼¼æ¼æ¸¬éãç¶èï¼åªåå¶æ¡æ¨£éè¦çä¸åªæ¯æ©çé¸æï¼è§£æ±ºæ¹æ¡å¿é ç¬¦åç¹å®çµæ§æè¦åï¼ä»¥ç¢ºä¿ä¸è´æ§ä¸¦å¼æä¸è¬ååãæåæåºäº Graph-PReFLexORï¼åºæ¼åå½¢çåºæ¼åå¥½çéè¿´èªè¨å»ºæ¨¡ï¼ç¨æ¼æ¨ççæ¢ç´¢æ§åªåï¼ï¼ä¸åå°åå½¢æ¨çèç¬¦èæ½è±¡ç¸çµåä»¥åææ´å±é åç¥è­çæ¡æ¶ãåå¼·åå­¸ç¿çåç¼ï¼Graph-PReFLexOR å°æ¨çå®ç¾©çºçµæ§åå°æï¼ä»»åç¢çç¥è­åå½¢ãæ½è±¡æ¨¡å¼ä»¥åæçµç­æ¡ãåç¯çè«çåç¼ï¼å®å°æ¦å¿µç·¨ç¢¼çºç¯é»ï¼å°å®åçéä¿ç·¨ç¢¼çºéç·£ï¼ééåæ§è¡¨ç¤ºæ¯æéå±¤å¼æ¨è«åèªé©æå­¸ç¿ãç¤ºç¯åæ¬åè¨­çæãææè¨­è¨ååµé æ§æ¨çï¼ä¾å¦ç¼ç¾ç¥è©±æ¦å¿µï¼å¦ãèå¼±é»ãï¼èææç§å­¸ä¹éçéä¿ãæåæåºäºä¸ç¨®ãç¥è­è±åæé·ãç­ç¥ï¼å®æ´åäºè·¨é åçè¦è§£ï¼ä¿é²äºè·¨å­¸ç§çè¯ç¹«ãä½¿ç¨ 30 ååæ¸ Graph-PReFLexOR æ¨¡åççµæé¡¯ç¤ºåºåªç°çæ¨çæ·±åº¦åé©ææ§ï¼å¼·èª¿äºéæãå¤å­¸ç§ AI é©åç¼ç¾çæ½åãå®çºéç¨çèªä¸»æ¨çè§£æ±ºæ¹æ¡å¥ å®äºåºç¤ã</paragraph>

##### **Reasoning with Graphs: Structuring Implicit Knowledge to Enhance LLMs Reasoning**
2501.07845v1 by Haoyu Han, Yaochen Xie, Hui Liu, Xianfeng Tang, Sreyashi Nag, William Headden, Hui Liu, Yang Li, Chen Luo, Shuiwang Ji, Qi He, Jiliang Tang

Large language models (LLMs) have demonstrated remarkable success across a
wide range of tasks; however, they still encounter challenges in reasoning
tasks that require understanding and inferring relationships between distinct
pieces of information within text sequences. This challenge is particularly
pronounced in tasks involving multi-step processes, such as logical reasoning
and multi-hop question answering, where understanding implicit relationships
between entities and leveraging multi-hop connections in the given context are
crucial. Graphs, as fundamental data structures, explicitly represent pairwise
relationships between entities, thereby offering the potential to enhance LLMs'
reasoning capabilities. External graphs have proven effective in supporting
LLMs across multiple tasks. However, in many reasoning tasks, no pre-existing
graph structure is provided. Can we structure implicit knowledge derived from
context into graphs to assist LLMs in reasoning? In this paper, we propose
Reasoning with Graphs (RwG) by first constructing explicit graphs from the
context and then leveraging these graphs to enhance LLM reasoning performance
on reasoning tasks. Extensive experiments demonstrate the effectiveness of the
proposed method in improving both logical reasoning and multi-hop question
answering tasks.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å·²å¨åç¨®ä»»åä¸­å±ç¾åºé¡¯èçæåï¼ç¶èï¼å®åå¨æ¨çä»»åä¸­ä»æéå°ææ°ï¼éäºä»»åéè¦çè§£åæ¨è«æå­åºåä¸­ä¸åè³è¨çæ®µä¹éçéä¿ãéåææ°å¨æ¶åå¤æ­¥é©ç¨åºçä»»åä¸­ç¹å¥æé¡¯ï¼ä¾å¦éè¼¯æ¨çåå¤è·³åé¡è§£ç­ï¼å¶ä¸­çè§£å¯¦é«ä¹éçé±å«éä¿ä¸¦å©ç¨çµ¦å®èçµ¡ä¸­çå¤è·³é£æ¥è³ééè¦ãåå½¢ä½çºåºæ¬çè³æçµæ§ï¼æç¢ºè¡¨ç¤ºå¯¦é«ä¹éæå°çéä¿ï¼å¾èæä¾å¢å¼· LLM æ¨çè½åçæ½åãå¤é¨åå½¢å·²è¢«è­æå¯ä»¥æææ¯æ´ LLM å·è¡å¤é ä»»åãç¶èï¼å¨è¨±å¤æ¨çä»»åä¸­ï¼ä¸¦æ²ææä¾é åå­å¨çåå½¢çµæ§ãæåè½å°å¾èçµ¡ä¸­è¡ççé±å«ç¥è­çµæ§æåå½¢ï¼ä»¥åå© LLM é²è¡æ¨çåï¼å¨æ¬æä¸­ï¼æåæåºä½¿ç¨åå½¢é²è¡æ¨ç (RwG)ï¼æ¹æ³æ¯é¦åå¾èçµ¡ä¸­å»ºæ§æç¢ºçåå½¢ï¼ç¶å¾å©ç¨éäºåå½¢ä¾å¢å¼· LLM å¨æ¨çä»»åä¸­çæ¨çæè½ãå»£æ³çå¯¦é©è­æäºææåºçæ¹æ³å¨æ¹é²éè¼¯æ¨çåå¤è·³åé¡è§£ç­ä»»åæ¹é¢çæææ§ã

##### **Flow: A Modular Approach to Automated Agentic Workflow Generation**
2501.07834v1 by Boye Niu, Yiliao Song, Kai Lian, Yifan Shen, Yu Yao, Kun Zhang, Tongliang Liu

Multi-agent frameworks powered by large language models (LLMs) have
demonstrated great success in automated planning and task execution. However,
the effective adjustment of Agentic workflows during execution has not been
well-studied. A effective workflow adjustment is crucial, as in many real-world
scenarios, the initial plan must adjust to unforeseen challenges and changing
conditions in real-time to ensure the efficient execution of complex tasks. In
this paper, we define workflows as an activity-on-vertex (AOV) graphs. We
continuously refine the workflow by dynamically adjusting task allocations
based on historical performance and previous AOV with LLM agents. To further
enhance system performance, we emphasize modularity in workflow design based on
measuring parallelism and dependence complexity. Our proposed multi-agent
framework achieved efficient sub-task concurrent execution, goal achievement,
and error tolerance. Empirical results across different practical tasks
demonstrate dramatic improvements in the efficiency of multi-agent frameworks
through dynamic workflow updating and modularization.

æè¦ï¼å¤§åèªè¨æ¨¡åï¼LLMï¼é©åçå¤ä»£çæ¶æ§å·²å¨èªååè¦ååä»»åå·è¡ä¸­å±ç¾åºå·¨å¤§çæåãç¶èï¼å¨å·è¡æéææèª¿æ´ä»£çå·¥ä½æµç¨å°æªå¾å°ååç ç©¶ãææçå·¥ä½æµç¨èª¿æ´è³ééè¦ï¼å çºå¨è¨±å¤å¯¦éå ´æ¯ä¸­ï¼åå§è¨ç«å¿é å³æèª¿æ´ä»¥æå°ç¡æ³é è¦çææ°åä¸æ·è®åçæ¢ä»¶ï¼ä»¥ç¢ºä¿è¤éä»»åçææå·è¡ãå¨æ¬æä¸­ï¼æåå°å·¥ä½æµç¨å®ç¾©çºé é»ä¸çæ´»åï¼AOVï¼åå½¢ãæåæ ¹ææ­·å²ç¸¾æåååç AOV è LLM ä»£çï¼ééåæèª¿æ´ä»»ååéï¼æçºåªåå·¥ä½æµç¨ãçºäºé²ä¸æ­¥æåç³»çµ±æè½ï¼æåå¼·èª¿åºæ¼æ¸¬éä¸¦è¡æ§åä¾è³´è¤éæ§çå·¥ä½æµç¨è¨­è¨ä¸­çæ¨¡çµåãæåæåºçå¤ä»£çæ¶æ§éå°äºææå­ä»»åä¸¦è¡å·è¡ãç®æ¨éæåå®¹é¯ãè·¨ä¸åå¯¦éä»»åçå¯¦è­çµæè­æï¼ééåæå·¥ä½æµç¨æ´æ°åæ¨¡çµåï¼å¤ä»£çæ¶æ§çæçæäºé¡¯èçæåã

##### **Large Language Models for Knowledge Graph Embedding Techniques, Methods, and Challenges: A Survey**
2501.07766v1 by Bingchen Liu, Xin Li

Large Language Models (LLMs) have attracted a lot of attention in various
fields due to their superior performance, aiming to train hundreds of millions
or more parameters on large amounts of text data to understand and generate
natural language. As the superior performance of LLMs becomes apparent, they
are increasingly being applied to knowledge graph embedding (KGE) related tasks
to improve the processing results. As a deep learning model in the field of
Natural Language Processing (NLP), it learns a large amount of textual data to
predict the next word or generate content related to a given text. However,
LLMs have recently been invoked to varying degrees in different types of KGE
related scenarios such as multi-modal KGE and open KGE according to their task
characteristics. In this paper, we investigate a wide range of approaches for
performing LLMs-related tasks in different types of KGE scenarios. To better
compare the various approaches, we summarize each KGE scenario in a
classification. In addition to the categorization methods, we provide a tabular
overview of the methods and their source code links for a more direct
comparison. In the article we also discuss the applications in which the
methods are mainly used and suggest several forward-looking directions for the
development of this new research area.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) ç±æ¼å¶åªç°çæ§è½ï¼å¨ååé åä¸­å¼èµ·äºè¨±å¤éæ³¨ï¼ç®æ¨æ¯è¨ç·´æ¸åææ´å¤åæ¸ï¼ä»¥çè§£åç¢çå¤§éææ¬è³æä¸­çèªç¶èªè¨ãé¨è LLM åªç°æ§è½çé¡¯ç¾ï¼å®åæ­£è¶ä¾è¶å»£æ³å°æç¨æ¼ç¥è­åè­åµå¥ (KGE) ç¸éä»»åï¼ä»¥æ¹åèççµæãä½çºèªç¶èªè¨èç (NLP) é åä¸­çæ·±åº¦å­¸ç¿æ¨¡åï¼å®å­¸ç¿å¤§éçææ¬è³æï¼ä»¥é æ¸¬ä¸ä¸åå®å­æç¢çèçµ¦å®ææ¬ç¸éçå§å®¹ãç¶èï¼æ ¹æä»»åç¹æ§ï¼LLM æè¿å·²å¨ä¸åé¡åç KGE ç¸éå ´æ¯ï¼ä¾å¦å¤æ¨¡æ KGE åéæ¾å¼ KGEï¼ä¸­ä»¥ä¸åç¨åº¦è¢«æ¡ç¨ãå¨æ¬æä¸­ï¼æåæ¢è¨äºå¨ä¸åé¡åç KGE å ´æ¯ä¸­å·è¡è LLM ç¸éä»»åçåç¨®æ¹æ³ãçºäºæ´å¥½å°æ¯è¼åç¨®æ¹æ³ï¼æåå¨åé¡ä¸­ç¸½çµäºæ¯å KGE å ´æ¯ãé¤äºåé¡æ¹æ³ä¹å¤ï¼æåéæä¾äºæ¹æ³åå¶åå§ç¢¼é£çµçè¡¨æ ¼æ¦è§ï¼ä»¥ä¾¿é²è¡æ´ç´æ¥çæ¯è¼ãå¨æ¬æä¸­ï¼æåéè¨è«äºéäºæ¹æ³ä¸»è¦ç¨æ¼åªäºæç¨ï¼ä¸¦å»ºè­°äºå¹¾åéåæ°ç ç©¶é åç¼å±çåç»æ§æ¹åã

##### **SafePowerGraph-LLM: Novel Power Grid Graph Embedding and Optimization with Large Language Models**
2501.07639v1 by Fabien Bernier, Jun Cao, Maxime Cordy, Salah Ghamizi

Efficiently solving Optimal Power Flow (OPF) problems in power systems is
crucial for operational planning and grid management. There is a growing need
for scalable algorithms capable of handling the increasing variability,
constraints, and uncertainties in modern power networks while providing
accurate and fast solutions. To address this, machine learning techniques,
particularly Graph Neural Networks (GNNs) have emerged as promising approaches.
This letter introduces SafePowerGraph-LLM, the first framework explicitly
designed for solving OPF problems using Large Language Models (LLM)s. The
proposed approach combines graph and tabular representations of power grids to
effectively query LLMs, capturing the complex relationships and constraints in
power systems. A new implementation of in-context learning and fine-tuning
protocols for LLMs is introduced, tailored specifically for the OPF problem.
SafePowerGraph-LLM demonstrates reliable performances using off-the-shelf LLM.
Our study reveals the impact of LLM architecture, size, and fine-tuning and
demonstrates our framework's ability to handle realistic grid components and
constraints.

æè¦ï¼å¨é»åç³»çµ±ä¸­ææè§£æ±ºæä½³é»åæµ (OPF) åé¡å°æ¼éçè¦ååé»ç¶²ç®¡çè³ééè¦ãå°æ¼è½å¤ èçç¾ä»£é»åç¶²è·¯ä¸­æ¥çå¢å çå¯è®æ§ãç´æåä¸ç¢ºå®æ§çå¯æ´åæ¼ç®æ³ï¼åææä¾æºç¢ºä¸å¿«éçè§£æ±ºæ¹æ¡ï¼éæ±èæ¥ä¿±å¢ãçºäºè§£æ±ºæ­¤åé¡ï¼æ©å¨å­¸ç¿æè¡ï¼ç¹å¥æ¯åç¥ç¶ç¶²è·¯ (GNN) å·²æçºæåæ¯çæ¹æ³ãæ¬ä¿¡ä»ç´¹äº SafePowerGraph-LLMï¼éæ¯ç¬¬ä¸åæç¢ºè¨­è¨ç¨æ¼ä½¿ç¨å¤§åèªè¨æ¨¡å (LLM) è§£æ±º OPF åé¡çæ¡æ¶ãææåºçæ¹æ³çµåäºé»åç¶²è·¯çåå½¢åè¡¨æ ¼è¡¨ç¤ºï¼ä»¥æææ¥è©¢ LLMï¼ææé»åç³»çµ±ä¸­çè¤ééä¿åç´æãå¼å¥äºéå° LLM çæå¢å­¸ç¿åå¾®èª¿åå®çæ°å¯¦ä½ï¼å°ééå° OPF åé¡éèº«æé ãSafePowerGraph-LLM ä½¿ç¨ç¾æç LLM å±ç¤ºäºå¯é çæè½ãæåçç ç©¶æ­ç¤ºäº LLM æ¶æ§ãå¤§å°åå¾®èª¿çå½±é¿ï¼ä¸¦å±ç¤ºäºæåçæ¡æ¶èçç¾å¯¦é»ç¶²çµæåç´æçè½åã

##### **ADKGD: Anomaly Detection in Knowledge Graphs with Dual-Channel Training**
2501.07078v1 by Jiayang Wu, Wensheng Gan, Jiahao Zhang, Philip S. Yu

In the current development of large language models (LLMs), it is important
to ensure the accuracy and reliability of the underlying data sources. LLMs are
critical for various applications, but they often suffer from hallucinations
and inaccuracies due to knowledge gaps in the training data. Knowledge graphs
(KGs), as a powerful structural tool, could serve as a vital external
information source to mitigate the aforementioned issues. By providing a
structured and comprehensive understanding of real-world data, KGs enhance the
performance and reliability of LLMs. However, it is common that errors exist in
KGs while extracting triplets from unstructured data to construct KGs. This
could lead to degraded performance in downstream tasks such as
question-answering and recommender systems. Therefore, anomaly detection in KGs
is essential to identify and correct these errors. This paper presents an
anomaly detection algorithm in knowledge graphs with dual-channel learning
(ADKGD). ADKGD leverages a dual-channel learning approach to enhance
representation learning from both the entity-view and triplet-view
perspectives. Furthermore, using a cross-layer approach, our framework
integrates internal information aggregation and context information
aggregation. We introduce a kullback-leibler (KL)-loss component to improve the
accuracy of the scoring function between the dual channels. To evaluate ADKGD's
performance, we conduct empirical studies on three real-world KGs: WN18RR,
FB15K, and NELL-995. Experimental results demonstrate that ADKGD outperforms
the state-of-the-art anomaly detection algorithms. The source code and datasets
are publicly available at https://github.com/csjywu1/ADKGD.

æè¦ï¼<paragraph>å¨å¤§èªè¨æ¨¡åï¼LLMï¼çç¶åç¼å±ä¸­ï¼ç¢ºä¿åºç¤æ¸æä¾æºçæºç¢ºæ§åå¯é æ§éå¸¸éè¦ãLLM å°æ¼åç¨®æç¨è³ééè¦ï¼ä½ç±æ¼è¨ç·´æ¸æä¸­çç¥è­å·®è·ï¼å®åç¶å¸¸æåºç¾å¹»è¦ºåä¸æºç¢ºçææ³ãç¥è­åè­ (KG) ä½çºä¸ç¨®å¼·å¤§ççµæ§åå·¥å·ï¼å¯ä»¥ä½çºä¸åéè¦çå¤é¨ä¿¡æ¯ä¾æºï¼ä»¥æ¸è¼ä¸è¿°åé¡ãééæä¾å°ç¾å¯¦ä¸çæ¸æççµæ§ååå¨é¢çè§£ï¼KG æé«äº LLM çæ§è½åå¯é æ§ãç¶èï¼å¨å¾éçµæ§åæ¸æä¸­æåä¸åçµä»¥æ§å»º KG æï¼KG ä¸­å­å¨é¯èª¤æ¯å¾å¸¸è¦çãéå¯è½æå°è´ä¸æ¸¸ä»»åï¼ä¾å¦åç­åæ¨è¦ç³»çµ±ï¼çæ§è½ä¸éãå æ­¤ï¼KG ä¸­çç°å¸¸æª¢æ¸¬å°æ¼è­å¥åç³¾æ­£éäºé¯èª¤è³ééè¦ãæ¬ææåºäºä¸åå·æéééå­¸ç¿çç¥è­åè­ç°å¸¸æª¢æ¸¬ç®æ³ (ADKGD)ãADKGD å©ç¨éééå­¸ç¿æ¹æ³å¾å¯¦é«è¦è§åä¸åçµè¦è§å¢å¼·è¡¨ç¤ºå­¸ç¿ãæ­¤å¤ï¼æåçæ¡æ¶ä½¿ç¨è·¨å±¤æ¹æ³æ´åäºå§é¨ä¿¡æ¯èååä¸ä¸æä¿¡æ¯èåãæåå¼å¥äº Kullback-Leibler (KL) æå¤±çµä»¶ï¼ä»¥æé«éééä¹éè©åå½æ¸çæºç¢ºæ§ãçºäºè©ä¼° ADKGD çæ§è½ï¼æåå°ä¸åçå¯¦ä¸ç KGï¼WN18RRãFB15K å NELL-995 é²è¡äºå¯¦è­ç ç©¶ãå¯¦é©çµæè¡¨æï¼ADKGD åªæ¼æåé²çç°å¸¸æª¢æ¸¬ç®æ³ãæºä»£ç¢¼åæ¸æéå¯å¨ https://github.com/csjywu1/ADKGD å¬éç²å¾ã</paragraph>

##### **Causal Claims in Economics**
2501.06873v1 by Prashant Garg, Thiemo Fetzer

We analyze over 44,000 NBER and CEPR working papers from 1980 to 2023 using a
custom language model to construct knowledge graphs that map economic concepts
and their relationships. We distinguish between general claims and those
documented via causal inference methods (e.g., DiD, IV, RDD, RCTs). We document
a substantial rise in the share of causal claims-from roughly 4% in 1990 to
nearly 28% in 2020-reflecting the growing influence of the "credibility
revolution." We find that causal narrative complexity (e.g., the depth of
causal chains) strongly predicts both publication in top-5 journals and higher
citation counts, whereas non-causal complexity tends to be uncorrelated or
negatively associated with these outcomes. Novelty is also pivotal for top-5
publication, but only when grounded in credible causal methods: introducing
genuinely new causal edges or paths markedly increases both the likelihood of
acceptance at leading outlets and long-run citations, while non-causal novelty
exhibits weak or even negative effects. Papers engaging with central, widely
recognized concepts tend to attract more citations, highlighting a divergence
between factors driving publication success and long-term academic impact.
Finally, bridging underexplored concept pairs is rewarded primarily when
grounded in causal methods, yet such gap filling exhibits no consistent link
with future citations. Overall, our findings suggest that methodological rigor
and causal innovation are key drivers of academic recognition, but sustained
impact may require balancing novel contributions with conceptual integration
into established economic discourse.

æè¦ï¼<paragraph>æåä½¿ç¨èªè¨èªè¨æ¨¡ååæäº 1980 å¹´è³ 2023 å¹´è¶é 44,000 ä»½ NBER å CEPR å·¥ä½è«æï¼ä»¥å»ºæ§ç¥è­åè­ï¼å°ç¶æ¿æ¦å¿µåå¶éä¿é²è¡å°æãæåååä¸è¬æ§è«è¿°åééå ææ¨è«æ¹æ³ï¼ä¾å¦ DiDãIVãRDDãRCTï¼è¨éçè«è¿°ãæåè¨éå°å æè«è¿°çä»½é¡å¤§å¹ä¸åï¼å¾ 1990 å¹´çç´ 4% ä¸åå° 2020 å¹´çè¿ 28%ï¼åæ äºãå¯ä¿¡åº¦é©å½ãçå½±é¿åæ¥çå¢å¼·ãæåç¼ç¾å ææè¿°çè¤éæ§ï¼ä¾å¦å æéçæ·±åº¦ï¼å¼·çé æ¸¬äºå¨é å° 5 å¤§æåçç¼è¡¨åè¼é«çå¼ç¨æ¬¡æ¸ï¼èéå æè¤éæ§åå¾å¾èéäºçµæç¡éæåè² ç¸éãæ°ç©æ§å°æ¼é å° 5 å¤§æåçç¼è¡¨ä¹è³ééè¦ï¼ä½åææ¯å»ºç«å¨å¯ä¿¡çå ææ¹æ³çåºç¤ä¸ï¼å¼å¥çæ­£æ°çå æéç·£æè·¯å¾é¡¯èå¢å äºå¨é å°åªé«ä¸è¢«æ¥åçå¯è½æ§åé·æå¼ç¨ï¼èéå ææ°ç©æ§åè¡¨ç¾åºå¾®å¼±çè³è² é¢çå½±é¿ãæ¢è¨ä¸­å¿ãå»£æ³èªå¯çæ¦å¿µçè«æå¾å¾æå¸å¼æ´å¤å¼ç¨ï¼çªé¡¯åºæ¨åç¼è¡¨æååé·æå­¸è¡å½±é¿çå ç´ ä¹éçå·®ç°ãæå¾ï¼å¡«è£æ¢ç´¢ä¸è¶³çæ¦å¿µå°æï¼ä¸»è¦æ¯å»ºç«å¨å ææ¹æ³çåºç¤ä¸ï¼ä½éç¨®å·®è·å¡«è£ä¸¦æªè¡¨ç¾åºèæªä¾å¼ç¨çä¸è´éè¯ãç¸½çä¾èªªï¼æåçç ç©¶çµæè¡¨æï¼æ¹æ³è«å´è¬¹æ§åå æåµæ°æ¯å­¸è¡èªå¯çä¸»è¦é©ååï¼ä½æçºçå½±é¿å¯è½éè¦å¹³è¡¡æ°ç©è²¢ç»èèå¥æ¢å®çç¶æ¿è«è¿°ä¸­çæ¦å¿µæ´åã</paragraph>

##### **MiniRAG: Towards Extremely Simple Retrieval-Augmented Generation**
2501.06713v2 by Tianyu Fan, Jingyuan Wang, Xubin Ren, Chao Huang

The growing demand for efficient and lightweight Retrieval-Augmented
Generation (RAG) systems has highlighted significant challenges when deploying
Small Language Models (SLMs) in existing RAG frameworks. Current approaches
face severe performance degradation due to SLMs' limited semantic understanding
and text processing capabilities, creating barriers for widespread adoption in
resource-constrained scenarios. To address these fundamental limitations, we
present MiniRAG, a novel RAG system designed for extreme simplicity and
efficiency. MiniRAG introduces two key technical innovations: (1) a
semantic-aware heterogeneous graph indexing mechanism that combines text chunks
and named entities in a unified structure, reducing reliance on complex
semantic understanding, and (2) a lightweight topology-enhanced retrieval
approach that leverages graph structures for efficient knowledge discovery
without requiring advanced language capabilities. Our extensive experiments
demonstrate that MiniRAG achieves comparable performance to LLM-based methods
even when using SLMs while requiring only 25\% of the storage space.
Additionally, we contribute a comprehensive benchmark dataset for evaluating
lightweight RAG systems under realistic on-device scenarios with complex
queries. We fully open-source our implementation and datasets at:
https://github.com/HKUDS/MiniRAG.

æè¦ï¼é¨èå°é«æä¸è¼éåçæª¢ç´¢å¢å¼·çæ (RAG) ç³»çµ±éæ±çå¢é·ï¼å¨ç¾æ RAG æ¶æ§ä¸­é¨ç½²å°åèªè¨æ¨¡å (SLM) æçªé¡¯äºéå¤§ææ°ãç±æ¼ SLM çèªç¾©çè§£åæå­èçè½åæéï¼ç®åçåæ³é¢è¨å´éçæè½ä¸éï¼çºå¨è³æºåéçææ³ä¸å»£æ³æ¡ç¨è£½é äºéç¤ãçºäºè§£æ±ºéäºæ ¹æ¬æ§çéå¶ï¼æåæåºäº MiniRAGï¼éæ¯ä¸åå°çºæ¥µè´ç°¡æ½åæçèè¨­è¨çæ°å RAG ç³»çµ±ãMiniRAG å°å¥äºå©é ééµæè¡åµæ°ï¼(1) ä¸ç¨®èªç¾©æç¥ç°è³ªåå½¢ç´¢å¼æ©å¶ï¼å®å°æå­åå¡åå½åå¯¦é«çµåå¨ä¸åçµ±ä¸ççµæ§ä¸­ï¼æ¸å°äºå°è¤éèªç¾©çè§£çä¾è³´ï¼ä»¥å (2) ä¸ç¨®è¼éç´ææ²å¢å¼·æª¢ç´¢æ¹æ³ï¼å®å©ç¨åå½¢çµæ§é²è¡ææççç¥è­ç¼ç¾ï¼èä¸éè¦é²éçèªè¨è½åãæåå»£æ³çå¯¦é©è­æï¼å³ä½¿å¨ä½¿ç¨ SLM æï¼MiniRAG ä¹è½éå°èåºæ¼ LLM çæ¹æ³ç¸ç¶çæè½ï¼åæåªéè¦ 25% çå²å­ç©ºéãæ­¤å¤ï¼æåæä¾äºä¸åå¨é¢çåºæºè³æéï¼ç¨æ¼å¨å·æè¤éæ¥è©¢çå¯¦éè£ç½®ææ³ä¸è©ä¼°è¼éç´ RAG ç³»çµ±ãæåå¨ https://github.com/HKUDS/MiniRAG ä¸å®å¨éæºæåçå¯¦ä½åè³æéã

##### **Large Language Models, Knowledge Graphs and Search Engines: A Crossroads for Answering Users' Questions**
2501.06699v1 by Aidan Hogan, Xin Luna Dong, Denny VrandeÄiÄ, Gerhard Weikum

Much has been discussed about how Large Language Models, Knowledge Graphs and
Search Engines can be combined in a synergistic manner. A dimension largely
absent from current academic discourse is the user perspective. In particular,
there remain many open questions regarding how best to address the diverse
information needs of users, incorporating varying facets and levels of
difficulty. This paper introduces a taxonomy of user information needs, which
guides us to study the pros, cons and possible synergies of Large Language
Models, Knowledge Graphs and Search Engines. From this study, we derive a
roadmap for future research.

æè¦ï¼å°æ¼å¤§åèªè¨æ¨¡åãç¥è­åè­åæå°å¼æå¦ä½è½ä»¥ååçæ¹å¼çµåï¼å·²ç¶æè¨±å¤è¨è«ãç®åå­¸è¡è«è¿°ä¸­å¾å¤§ç¨åº¦ä¸å¿½ç¥äºä¸åé¢åï¼é£å°±æ¯ä½¿ç¨èçè§é»ãç¹å¥æ¯ï¼éæ¼å¦ä½æå¥½å°æ»¿è¶³ä½¿ç¨èå¤åçè³è¨éæ±ï¼ä¸¦ç´å¥ä¸åé¢ååé£åº¦å±¤ç´ï¼ä»æè¨±å¤æªè§£æ±ºçåé¡ãæ¬æä»ç´¹äºä¸åä½¿ç¨èè³è¨éæ±çåé¡æ³ï¼å¼å°æåç ç©¶å¤§åèªè¨æ¨¡åãç¥è­åè­åæå°å¼æçåªç¼ºé»åå¯è½çååä½ç¨ãå¾éé ç ç©¶ä¸­ï¼æåè¡çåºæªä¾ç ç©¶çè·¯ç·åã

##### **Quantifying Relational Exploration in Cultural Heritage Knowledge Graphs with LLMs: A Neuro-Symbolic Approach**
2501.06628v1 by Mohammed Maree

This paper introduces a neuro-symbolic approach for relational exploration in
cultural heritage knowledge graphs, leveraging Large Language Models (LLMs) for
explanation generation and a novel mathematical framework to quantify the
interestingness of relationships. We demonstrate the importance of
interestingness measure using a quantitative analysis, by highlighting its
impact on the overall performance of our proposed system, particularly in terms
of precision, recall, and F1-score. Using the Wikidata Cultural Heritage Linked
Open Data (WCH-LOD) dataset, our approach yields a precision of 0.70, recall of
0.68, and an F1-score of 0.69, representing an improvement compared to
graph-based (precision: 0.28, recall: 0.25, F1-score: 0.26) and knowledge-based
baselines (precision: 0.45, recall: 0.42, F1-score: 0.43). Furthermore, our
LLM-powered explanations exhibit better quality, reflected in BLEU (0.52),
ROUGE-L (0.58), and METEOR (0.63) scores, all higher than the baseline
approaches. We show a strong correlation (0.65) between interestingness measure
and the quality of generated explanations, validating its effectiveness. The
findings highlight the importance of LLMs and a mathematical formalization for
interestingness in enhancing the effectiveness of relational exploration in
cultural heritage knowledge graphs, with results that are measurable and
testable. We further show that the system enables more effective exploration
compared to purely knowledge-based and graph-based methods.

æè¦ï¼éç¯è«æä»ç´¹äºä¸ç¨®ç¥ç¶ç¬¦èæ¹æ³ï¼ç¨æ¼æåéºç¢ç¥è­åè­ä¸­çéä¿æ¢ç´¢ï¼å©ç¨å¤§åèªè¨æ¨¡å (LLM) é²è¡è§£éçæï¼ä¸¦å©ç¨ä¸ç¨®æ°ç©çæ¸å­¸æ¡æ¶ä¾éåéä¿çè¶£å³æ§ãæåééå®éåæå±ç¤ºäºè¶£å³æ§æ¸¬éçéè¦æ§ï¼å¼·èª¿å®å°æåææåºçç³»çµ±æ´é«æè½çå½±é¿ï¼ç¹å¥æ¯å¨ç²¾ç¢ºåº¦ãå¬åçå F1 åæ¸æ¹é¢ãä½¿ç¨ Wikidata æåéºç¢é£çµéæ¾è³æ (WCH-LOD) è³æéï¼æåçåæ³ç¢çäº 0.70 çç²¾ç¢ºåº¦ã0.68 çå¬åçå 0.69 ç F1 åæ¸ï¼èåºæ¼åå½¢ (ç²¾ç¢ºåº¦ï¼0.28ãå¬åçï¼0.25ãF1 åæ¸ï¼0.26) ååºæ¼ç¥è­çåºç· (ç²¾ç¢ºåº¦ï¼0.45ãå¬åçï¼0.42ãF1 åæ¸ï¼0.43) ç¸æ¯ï¼éæ¯ä¸åé²æ­¥ãæ­¤å¤ï¼æåç± LLM ä¿æçè§£éå±ç¾åºæ´å¥½çåè³ªï¼åæ å¨ BLEU (0.52)ãROUGE-L (0.58) å METEOR (0.63) åæ¸ä¸ï¼é½é«æ¼åºç·æ¹æ³ãæåé¡¯ç¤ºäºè¶£å³æ§æ¸¬éåç¢ççè§£éåè³ªä¹éå¼·ççç¸éæ§ (0.65)ï¼é©è­äºå®çæææ§ãéäºç¼ç¾çªé¡¯äº LLM åè¶£å³æ§çæ¸å­¸å½¢å¼åå¨å¢å¼·æåéºç¢ç¥è­åè­ä¸­éä¿æ¢ç´¢çæææ§æ¹é¢çéè¦æ§ï¼å¶çµææ¯å¯ä»¥è¡¡éåæ¸¬è©¦çãæåé²ä¸æ­¥è¡¨æï¼èç´ç²¹åºæ¼ç¥è­ååºæ¼åå½¢çæ¹æ³ç¸æ¯ï¼è©²ç³»çµ±è½é²è¡æ´ææçæ¢ç´¢ã

##### **MedCT: A Clinical Terminology Graph for Generative AI Applications in Healthcare**
2501.06465v2 by Ye Chen, Dongdong Huang, Haoyun Xu, Cong Fu, Lin Sheng, Qingli Zhou, Yuqiang Shen, Kai Wang

We introduce the world's first clinical terminology for the Chinese
healthcare community, namely MedCT, accompanied by a clinical foundation model
MedBERT and an entity linking model MedLink. The MedCT system enables
standardized and programmable representation of Chinese clinical data,
successively stimulating the development of new medicines, treatment pathways,
and better patient outcomes for the populous Chinese community. Moreover, the
MedCT knowledge graph provides a principled mechanism to minimize the
hallucination problem of large language models (LLMs), therefore achieving
significant levels of accuracy and safety in LLM-based clinical applications.
By leveraging the LLMs' emergent capabilities of generativeness and
expressiveness, we were able to rapidly built a production-quality terminology
system and deployed to real-world clinical field within three months, while
classical terminologies like SNOMED CT have gone through more than twenty years
development. Our experiments show that the MedCT system achieves
state-of-the-art (SOTA) performance in semantic matching and entity linking
tasks, not only for Chinese but also for English. We also conducted a
longitudinal field experiment by applying MedCT and LLMs in a representative
spectrum of clinical tasks, including electronic health record (EHR)
auto-generation and medical document search for diagnostic decision making. Our
study shows a multitude of values of MedCT for clinical workflows and patient
outcomes, especially in the new genre of clinical LLM applications. We present
our approach in sufficient engineering detail, such that implementing a
clinical terminology for other non-English societies should be readily
reproducible. We openly release our terminology, models and algorithms, along
with real-world clinical datasets for the development.

æè¦ï¼<paragraph>æåçºä¸­æé«çç¤¾ç¾¤å¼å¥äºå¨çé¦åµçè¨åºè¡èªï¼å³ MedCTï¼ä¸¦éå¸¶è¨åºåºç¤æ¨¡å MedBERT åå¯¦é«é£çµæ¨¡å MedLinkãMedCT ç³»çµ±è½æ¨æºåä¸¦ä»¥ç¨å¼è¨­è¨æ¹å¼åç¾ä¸­æè¨åºè³æï¼é²èåºæ¿æ°è¥ãæ²»çéå¾çéç¼ï¼ä¸¦çºäººå£ç¾å¤çè¯äººç¤¾ç¾¤å¸¶ä¾æ´å¥½ççäººæ²»çææãæ­¤å¤ï¼MedCT ç¥è­åè­æä¾ä¸åæååçæ©å¶ï¼ä»¥æå°åå¤§åèªè¨æ¨¡å (LLM) çå¹»è¦ºåé¡ï¼å æ­¤å¨åºæ¼ LLM çè¨åºæç¨ä¸­éå°äºé¡¯èçæºç¢ºæ§åå®å¨æ§ãééå©ç¨ LLM çæåè¡¨éè½åçæ°èåè½ï¼æåå¾ä»¥å¿«éå»ºç½®ä¸åçç¢åè³ªçè¡èªç³»çµ±ï¼ä¸¦å¨ä¸åæå§é¨ç½²å°å¯¦éè¨åºé åï¼èå SNOMED CT éæ¨£çå³çµ±è¡èªç³»çµ±åç¶æ­·äºäºåå¤å¹´çéç¼ãæåçå¯¦é©é¡¯ç¤ºï¼MedCT ç³»çµ±å¨èªç¾©å¹éåå¯¦é«é£çµä»»åä¸­éå°äºæåé² (SOTA) çæè½ï¼ä¸åªé©ç¨æ¼ä¸­æï¼ä¹é©ç¨æ¼è±æãæåéééå¨å·ä»£è¡¨æ§çè¨åºä»»åä¸­æç¨ MedCT å LLM ä¾é²è¡ç¸±åå¯¦å°å¯¦é©ï¼åæ¬é»å­å¥åº·ç´é (EHR) èªåç¢çåç¨æ¼è¨ºæ·æ±ºç­çé«çæä»¶æå°ãæåçç ç©¶é¡¯ç¤º MedCT å°è¨åºå·¥ä½æµç¨åçäººæ²»çæææè¨±å¤å¹å¼ï¼ç¹å¥æ¯å¨æ°åæçè¨åº LLM æç¨ä¸­ãæåä»¥ååçå·¥ç¨ç´°ç¯èªªæäºæåçåæ³ï¼å æ­¤å¯¦ä½å¶ä»éè±èªç¤¾æçè¨åºè¡èªæææ¼è¤è£½ãæåéæ¾éåºæåçè¡èªãæ¨¡ååæ¼ç®æ³ï¼ä»¥åç¨æ¼éç¼çå¯¦éè¨åºè³æéã</paragraph>

##### **Dynamics of "Spontaneous" Topic Changes in Next Token Prediction with Self-Attention**
2501.06382v1 by Mumin Jia, Jairo Diaz-Rodriguez

Human cognition can spontaneously shift conversation topics, often triggered
by emotional or contextual signals. In contrast, self-attention-based language
models depend on structured statistical cues from input tokens for next-token
prediction, lacking this spontaneity. Motivated by this distinction, we
investigate the factors that influence the next-token prediction to change the
topic of the input sequence. We define concepts of topic continuity, ambiguous
sequences, and change of topic, based on defining a topic as a set of token
priority graphs (TPGs). Using a simplified single-layer self-attention
architecture, we derive analytical characterizations of topic changes.
Specifically, we demonstrate that (1) the model maintains the priority order of
tokens related to the input topic, (2) a topic change occurs only if
lower-priority tokens outnumber all higher-priority tokens of the input topic,
and (3) unlike human cognition, longer context lengths and overlapping topics
reduce the likelihood of spontaneous redirection. These insights highlight
differences between human cognition and self-attention-based models in
navigating topic changes and underscore the challenges in designing
conversational AI capable of handling "spontaneous" conversations more
naturally. To our knowledge, this is the first work to address these questions
in such close relation to human conversation and thought.

æè¦ï¼äººé¡èªç¥å¯ä»¥èªç¼å°è½æå°è©±ä¸»é¡ï¼éå¸¸æ¯ç±æç·æèªå¢ä¿¡èè§¸ç¼ãç¸æ¯ä¹ä¸ï¼åºæ¼èªææ³¨æåçèªè¨æ¨¡åä¾è³´æ¼è¼¸å¥ç¬¦èççµæ§åçµ±è¨ç·ç´¢ä¾é æ¸¬ä¸ä¸åç¬¦èï¼ç¼ºä¹éç¨®èªç¼æ§ãåéç¨®åå¥çåç¼ï¼æåæ¢è¨äºå½±é¿ä¸ä¸åç¬¦èé æ¸¬ä»¥æ¹è®è¼¸å¥åºåä¸»é¡çå ç´ ãæåæ ¹æå°ä¸»é¡å®ç¾©çºä¸çµç¬¦èåªåç´åï¼TPGï¼ä¾å®ç¾©ä¸»é¡é£çºæ§ãæ­§ç¾©åºååä¸»é¡è®åçæ¦å¿µãä½¿ç¨ç°¡åçå®å±¤èªæ³¨æåæ¶æ§ï¼æåæ¨å°åºä¸»é¡è®åçåæç¹å¾µãå·é«ä¾èªªï¼æåè­æï¼1ï¼æ¨¡åç¶­è­·èè¼¸å¥ä¸»é¡ç¸éçç¬¦èçåªåé åºï¼ï¼2ï¼åªæç¶è¼ä½åªåé åºçç¬¦èå¤æ¼è¼¸å¥ä¸»é¡çææè¼é«åªåé åºçç¬¦èæï¼ææç¼çä¸»é¡è®åï¼ä»¥åï¼3ï¼èäººé¡èªç¥ä¸åï¼è¼é·çä¸ä¸æé·åº¦åéççä¸»é¡æéä½èªç¼éå®åçå¯è½æ§ãéäºè¦è§£çªåºäºäººé¡èªç¥ååºæ¼èªæ³¨æåçæ¨¡åå¨æå°ä¸»é¡è®åæçå·®ç°ï¼ä¸¦å¼·èª¿äºå¨è¨­è¨è½å¤ æ´èªç¶å°èçãèªç¼ãå°è©±çå°è©±å¼ AI ææé¢è¨çææ°ãææåæç¥ï¼éæ¯ç¬¬ä¸åå¦æ­¤å¯åå°èäººé¡å°è©±åæç¶­ç¸éå°æ¢è¨éäºåé¡çç ç©¶ã

##### **Network Diffuser for Placing-Scheduling Service Function Chains with Inverse Demonstration**
2501.05673v1 by Zuyuan Zhang, Vaneet Aggarwal, Tian Lan

Network services are increasingly managed by considering chained-up virtual
network functions and relevant traffic flows, known as the Service Function
Chains (SFCs). To deal with sequential arrivals of SFCs in an online fashion,
we must consider two closely-coupled problems - an SFC placement problem that
maps SFCs to servers/links in the network and an SFC scheduling problem that
determines when each SFC is executed. Solving the whole SFC problem targeting
these two optimizations jointly is extremely challenging. In this paper, we
propose a novel network diffuser using conditional generative modeling for this
SFC placing-scheduling optimization. Recent advances in generative AI and
diffusion models have made it possible to generate high-quality images/videos
and decision trajectories from language description. We formulate the SFC
optimization as a problem of generating a state sequence for planning and
perform graph diffusion on the state trajectories to enable extraction of SFC
decisions, with SFC optimization constraints and objectives as conditions. To
address the lack of demonstration data due to NP-hardness and exponential
problem space of the SFC optimization, we also propose a novel and somewhat
maverick approach -- Rather than solving instances of this difficult
optimization, we start with randomly-generated solutions as input, and then
determine appropriate SFC optimization problems that render these solutions
feasible. This inverse demonstration enables us to obtain sufficient expert
demonstrations, i.e., problem-solution pairs, through further optimization. In
our numerical evaluations, the proposed network diffuser outperforms learning
and heuristic baselines, by $\sim$20\% improvement in SFC reward and $\sim$50\%
reduction in SFC waiting time and blocking rate.

æè¦ï¼ç¶²è·¯æåè¶ä¾è¶ééèæ®ä¸²é£çèæ¬ç¶²è·¯åè½åç¸éæµéé²è¡ç®¡çï¼ç¨±çºæååè½é (SFC)ãçºäºä»¥ç·ä¸æ¹å¼èç SFC çé åºå°éï¼æåå¿é èæ®å©åç·å¯çµåçåé¡ï¼å° SFC å°æå°ç¶²è·¯ä¸­çä¼ºæå¨/é£çµç SFC éç½®åé¡ï¼ä»¥åæ±ºå®æ¯å SFC ä½æå·è¡ç SFC æç¨åé¡ãåæéå°éå©åæä½³åä¾è§£æ±ºæ´å SFC åé¡æ¥µå·ææ°æ§ãå¨æ¬æä¸­ï¼æåæåºä¸åä½¿ç¨æ¢ä»¶çææ¨¡åçåµæ°ç¶²è·¯æ´æ£å¨ï¼ç¨æ¼æ­¤ SFC éç½®æç¨æä½³åãçæå¼ AI åæ´æ£æ¨¡åçææ°é²å±ä½¿å¾å¾èªè¨æè¿°ä¸­ç¢çé«åè³ªçå½±å/å½±çåæ±ºç­è»è·¡æçºå¯è½ãæåå° SFC æä½³åå¶å®çºç¢çä¸åçæåºåçåé¡ï¼ç¨æ¼è¦åï¼ä¸¦å°çæè»è·¡å·è¡åå½¢æ´æ£ï¼ä»¥æå SFC æ±ºç­ï¼ä¸¦ä»¥ SFC æä½³åç´æåç®æ¨ä½çºæ¢ä»¶ãçºäºè§£æ±ºç±æ¼ NP é£åº¦å SFC æä½³åçææ¸åé¡ç©ºéèå°è´çç¤ºç¯è³æä¸è¶³ï¼æåä¹æåºä¸ååµæ°ä¸æé»ç¹ç«ç¨è¡çåæ³ï¼ä¸æ¯è§£æ±ºéåå°é£æä½³åçå¯¦ä¾ï¼èæ¯å¾é¨æ©ç¢ççè§£ä½çºè¼¸å¥éå§ï¼ç¶å¾æ±ºå®é©ç¶ç SFC æä½³ååé¡ï¼è®éäºè§£å¯è¡ãéåéåç¤ºç¯è®æåè½å¤ ééé²ä¸æ­¥æä½³åï¼ç²å¾è¶³å¤ çå°å®¶ç¤ºç¯ï¼ä¹å°±æ¯åé¡è§£æ±ºéå°ãå¨æåçæ¸å¼è©ä¼°ä¸­ï¼ææåºçç¶²è·¯æ´æ£å¨åªæ¼å­¸ç¿ååç¼å¼åºæºï¼SFC çåµæåäºç´ 20%ï¼SFC ç­å¾æéåå°éçéä½äºç´ 50%ã

##### **FlairGPT: Repurposing LLMs for Interior Designs**
2501.04648v1 by Gabrielle Littlefair, Niladri Shekhar Dutt, Niloy J. Mitra

Interior design involves the careful selection and arrangement of objects to
create an aesthetically pleasing, functional, and harmonized space that aligns
with the client's design brief. This task is particularly challenging, as a
successful design must not only incorporate all the necessary objects in a
cohesive style, but also ensure they are arranged in a way that maximizes
accessibility, while adhering to a variety of affordability and usage
considerations. Data-driven solutions have been proposed, but these are
typically room- or domain-specific and lack explainability in their design
design considerations used in producing the final layout. In this paper, we
investigate if large language models (LLMs) can be directly utilized for
interior design. While we find that LLMs are not yet capable of generating
complete layouts, they can be effectively leveraged in a structured manner,
inspired by the workflow of interior designers. By systematically probing LLMs,
we can reliably generate a list of objects along with relevant constraints that
guide their placement. We translate this information into a design layout
graph, which is then solved using an off-the-shelf constrained optimization
setup to generate the final layouts. We benchmark our algorithm in various
design configurations against existing LLM-based methods and human designs, and
evaluate the results using a variety of quantitative and qualitative metrics
along with user studies. In summary, we demonstrate that LLMs, when used in a
structured manner, can effectively generate diverse high-quality layouts,
making them a viable solution for creating large-scale virtual scenes. Project
webpage at https://flairgpt.github.io/

æè¦ï¼å®¤å§è¨­è¨æ¶åä»ç´°æé¸åå®æç©ä»¶ï¼ä»¥åµé ä¸åç¾è§ãå¯¦ç¨ä¸åè«§çç©ºéï¼ç¬¦åå®¢æ¶çè¨­è¨ç°¡å ±ãéé ä»»åç¹å¥å·æææ°æ§ï¼å çºæåçè¨­è¨ä¸åå¿é ä»¥ä¸è´çé¢¨æ ¼ç´å¥ææå¿è¦çç©ä»¶ï¼éå¿é ç¢ºä¿å®åçæåæ¹å¼è½æå¤§åå¯åæ§ï¼åæç¬¦ååç¨®è² æè½ååä½¿ç¨èéãå·²ç¶æåºäºè³æé©åçè§£æ±ºæ¹æ¡ï¼ä½éäºè§£æ±ºæ¹æ¡éå¸¸æ¯ç¹å®æ¼æ¿éæé åï¼èä¸ç¼ºä¹å¨ç¢çæçµä½å±ææä½¿ç¨çè¨­è¨èéçå¯è§£éæ§ãå¨æ¬æä¸­ï¼æåæ¢è¨å¤§åèªè¨æ¨¡å (LLM) æ¯å¦å¯ä»¥ç´æ¥ç¨æ¼å®¤å§è¨­è¨ãéç¶æåç¼ç¾ LLM å°æªè½å¤ ç¢çå®æ´çä½å±ï¼ä½å®åå¯ä»¥ææå°ä»¥çµæ§åçæ¹å¼å©ç¨ï¼éæä¾èªå®¤å§è¨­è¨å¸«çå·¥ä½æµç¨ãééç³»çµ±æ§å°æ¢æ¥ LLMï¼æåå¯ä»¥å¯é å°ç¢çä¸åç©ä»¶æ¸å®ï¼ä»¥åæå°å®åæ¾ç½®ä½ç½®çç¸å³ç´æãæåå°éäºè³è¨è½ææè¨­è¨ä½å±åï¼ç¶å¾ä½¿ç¨ç¾æçç´æå¼æä½³åè¨­å®ä¾è§£æ±ºï¼ä»¥ç¢çæçµä½å±ãæåå¨åç¨®è¨­è¨éç½®ä¸­å°æåçæ¼ç®æ³èç¾æçåºæ¼ LLM çæ¹æ³åäººé¡è¨­è¨é²è¡åºæºæ¸¬è©¦ï¼ä¸¦ä½¿ç¨åç¨®éååè³ªåææ¨ä»¥åä½¿ç¨èç ç©¶ä¾è©ä¼°çµæãç¸½ä¹ï¼æåè­æäº LLM å¨ä»¥çµæ§åçæ¹å¼ä½¿ç¨æï¼å¯ä»¥ææå°ç¢çå¤æ¨£åçé«åè³ªä½å±ï¼ä½¿å¶æçºåµé å¤§åèæ¬å ´æ¯çå¯è¡è§£æ±ºæ¹æ¡ãå°æ¡ç¶²é å¨ https://flairgpt.github.io/

##### **CGP-Tuning: Structure-Aware Soft Prompt Tuning for Code Vulnerability Detection**
2501.04510v1 by Ruijun Feng, Hammond Pearce, Pietro Liguori, Yulei Sui

Large language models (LLMs) have been proposed as powerful tools for
detecting software vulnerabilities, where task-specific fine-tuning is
typically employed to provide vulnerability-specific knowledge to the LLMs for
this purpose. However, traditional full-parameter fine-tuning is inefficient
for modern, complex LLMs, which contain billions of parameters.
  Soft prompt tuning has been suggested as a more efficient alternative for
fine-tuning LLMs in general cases. However, pure soft prompt tuning treats
source code as plain text, losing structural information inherent in source
code. Meanwhile, graph-enhanced soft prompt tuning methods, which aim to
address this issue, are unable to preserve the rich semantic information within
code graphs, as they are primarily designed for general graph-related tasks and
focus more on adjacency information. They also fail to ensure computational
efficiency while accounting for graph-text interactions.
  This paper, therefore, introduces a new code graph-enhanced, structure-aware
soft prompt tuning method for vulnerability detection, referred to as
CGP-Tuning. It employs innovative type-aware embeddings to capture the rich
semantic information within code graphs, along with a novel and efficient
cross-modal alignment module that achieves linear computational cost while
incorporating graph-text interactions. The proposed CGP-Tuning is evaluated on
the latest DiverseVul dataset and the most recent open-source code LLMs,
CodeLlama and CodeGemma. Experimental results demonstrate that CGP-Tuning
outperforms the best state-of-the-art method by an average of 3.5 percentage
points in accuracy, without compromising its vulnerability detection
capabilities for long source code.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å·²è¢«æåºç¨æ¼åµæ¸¬è»é«æ¼æ´çå¼·å¤§å·¥å·ï¼å¶ä¸­ä»»åç¹å®å¾®èª¿éå¸¸ç¨æ¼æä¾æ¼æ´ç¹å®ç¥è­çµ¦ LLM ä»¥éå°æ­¤ç®çãç¶èï¼å³çµ±çå®æ´åæ¸å¾®èª¿å°æ¼åå«æ¸ååååæ¸çç¾ä»£è¤é LLM ä¾èªªæçä½ä¸ã
è»æç¤ºå¾®èª¿å·²è¢«å»ºè­°ä½çºä¸è¬ææ³ä¸å¾®èª¿ LLM çæ´æææ¿ä»£æ¹æ¡ãç¶èï¼ç´è»æç¤ºå¾®èª¿å°åå§ç¢¼è¦çºç´æå­ï¼å¤±å»äºåå§ç¢¼ä¸­åºæççµæ§è³è¨ãåæï¼æ¨å¨è§£æ±ºæ­¤åé¡çåå½¢å¢å¼·è»æç¤ºå¾®èª¿æ¹æ³ç¡æ³ä¿çç¨å¼ç¢¼åå½¢ä¸­çè±å¯èªç¾©è³è¨ï¼å çºå®åä¸»è¦è¨­è¨ç¨æ¼ä¸è¬çåå½¢ç¸éä»»åï¼ä¸æ´å°æ³¨æ¼é°æ¥è³è¨ãå®åä¹ç¡æ³å¨èéåå½¢æå­äºåçåæç¢ºä¿éç®æçã
å æ­¤ï¼æ¬æä»ç´¹äºä¸ç¨®æ°çç¨å¼ç¢¼åå½¢å¢å¼·ãçµæ§æç¥è»æç¤ºå¾®èª¿æ¹æ³ä¾åµæ¸¬æ¼æ´ï¼ç¨±çº CGP-Tuningãå®æ¡ç¨åµæ°çé¡åæç¥åµå¥ä¾æ·åç¨å¼ç¢¼åå½¢ä¸­çè±å¯èªç¾©è³è¨ï¼ä»¥åä¸åæ°ç©ä¸ææçè·¨æ¨¡æå°é½æ¨¡çµï¼è©²æ¨¡çµå¨ç´å¥åå½¢æå­äºåçåæå¯¦ç¾ç·æ§éç®ææ¬ãæè­°ç CGP-Tuning å¨ææ°ç DiverseVul è³æéåææ°çéæºç¨å¼ç¢¼ LLMï¼CodeLlama å CodeGemmaï¼ä¸é²è¡è©ä¼°ãå¯¦é©çµæè­æï¼CGP-Tuning å¨æºç¢ºåº¦æ¹é¢å¹³åæ¯æä½³çç¾ææè¡é«åº 3.5 åç¾åé»ï¼åæä¸æå®³å¶å°é·åå§ç¢¼çæ¼æ´åµæ¸¬è½åã

##### **S2 Chunking: A Hybrid Framework for Document Segmentation Through Integrated Spatial and Semantic Analysis**
2501.05485v1 by Prashant Verma

Document chunking is a critical task in natural language processing (NLP)
that involves dividing a document into meaningful segments. Traditional methods
often rely solely on semantic analysis, ignoring the spatial layout of
elements, which is crucial for understanding relationships in complex
documents. This paper introduces a novel hybrid approach that combines layout
structure, semantic analysis, and spatial relationships to enhance the cohesion
and accuracy of document chunks. By leveraging bounding box information (bbox)
and text embeddings, our method constructs a weighted graph representation of
document elements, which is then clustered using spectral clustering.
Experimental results demonstrate that this approach outperforms traditional
methods, particularly in documents with diverse layouts such as reports,
articles, and multi-column designs. The proposed method also ensures that no
chunk exceeds a specified token length, making it suitable for use cases where
token limits are critical (e.g., language models with input size limitations)

æè¦ï¼æä»¶åå¡æ¯èªç¶èªè¨èç (NLP) ä¸­çä¸é ééµä»»åï¼æ¶åå°æä»¶åå²æææç¾©çåå¡ãå³çµ±æ¹æ³éå¸¸åä¾è³´èªç¾©åæï¼å¿½ç¥åç´ çç©ºéä½å±ï¼èéå°æ¼çè§£è¤éæä»¶ä¸­çéä¿è³ééè¦ãæ¬æä»ç´¹ä¸ç¨®æ°ç©çæ··åæ¹æ³ï¼çµåä½å±çµæ§ãèªç¾©åæåç©ºééä¿ï¼ä»¥å¢å¼·æä»¶åå¡çå§èæ§åæºç¢ºæ§ãééå©ç¨éçæ¡è³è¨ (bbox) åæå­åµå¥ï¼æåçæ¨¡åå»ºæ§æä»¶åç´ çå æ¬åè¡¨è¡¨ç¤ºï¼ç¶å¾ä½¿ç¨è­èé¡é²è¡èé¡ãå¯¦é©çµæè¡¨æï¼æ­¤æ¹æ³åªæ¼å³çµ±æ¹æ³ï¼ç¹å¥æ¯å¨å·æä¸åä½å±çæä»¶ä¸­ï¼ä¾å¦å ±åãæç« åå¤æ¬è¨­è¨ãææåºçæ¹æ³éç¢ºä¿æ²æä»»ä½åå¡è¶éæå®çä»¤çé·åº¦ï¼ä½¿å¶é©ç¨æ¼ä»¤çéå¶è³ééè¦çä½¿ç¨æ¡ä¾ï¼ä¾å¦ï¼å·æè¼¸å¥å¤§å°éå¶çèªè¨æ¨¡åï¼

##### **Multimodal Graph Constrastive Learning and Prompt for ChartQA**
2501.04303v1 by Yue Dai, Soyeon Caren Han, Wei Liu

ChartQA presents significant challenges due to the complex distribution of
chart elements and the implicit patterns embedded within the underlying data.
In this chapter, we have developed a joint multimodal scene graph for charts,
explicitly representing the relationships between chart elements and their
associated patterns.
  Our proposed multimodal scene graph consists of two components: a visual
graph and a textual graph, each designed to capture the structural and semantic
information within the chart. To unify representations across these different
modalities, we introduce a multimodal graph contrastive learning approach that
learns unified representations by maximizing similarity between nodes
representing the same object across multimodal graphs. The learned graph
representations can be seamlessly incorporated into a transformer decoder as a
soft prompt.
  Additionally, given the growing need for Multimodal Large Language Models
(MLLMs) in zero-shot scenarios, we have designed Chain-of-Thought (CoT) prompts
for MLLMs to reduce hallucinations. We tested both methods on public benchmarks
such as ChartQA, OpenCQA, and ChartX, demonstrating improved performance and
validating the effectiveness of our proposed methods.

æè¦ï¼ChartQA å åè¡¨åç´ çè¤éåä½ååºç¤è³æä¸­å§åµçé±å«æ¨¡å¼èé¢è¨éå¤§ææ°ã
å¨æ¬ç« ä¸­ï¼æåçºåè¡¨éç¼äºä¸åè¯åå¤æ¨¡æå ´æ¯åå½¢ï¼æç¢ºè¡¨ç¤ºåè¡¨åç´ ä¹éçéä¿åå¶éè¯æ¨¡å¼ã
æåæåºçå¤æ¨¡æå ´æ¯åå½¢åå«å©åçµæé¨åï¼ä¸åè¦è¦ºåå½¢åä¸åææ¬åå½¢ï¼æ¯åçµæé¨åé½æ¨å¨æ·ååè¡¨ä¸­ççµæ§ååèªç¾©è³è¨ã
çºäºçµ±ä¸éäºä¸åæ¨¡æçè¡¨ç¤ºï¼æåå¼å¥äºä¸åå¤æ¨¡æåå½¢å°æ¯å­¸ç¿æ¹æ³ï¼ééæå¤§åè·¨å¤æ¨¡æåå½¢è¡¨ç¤ºç¸åç©ä»¶çç¯é»ä¹éçç¸ä¼¼æ§ä¾å­¸ç¿çµ±ä¸çè¡¨ç¤ºã
å­¸ç¿å°çåå½¢è¡¨ç¤ºå¯ä»¥ç¡ç¸«å°æ´åå°Transformerè§£ç¢¼å¨ä¸­ï¼ä½çºä¸åè»æç¤ºã
æ­¤å¤ï¼éæ¼å¤æ¨¡æå¤§åèªè¨æ¨¡å (MLLM) å¨é¶æ¬¡å­¸ç¿å ´æ¯ä¸­çéæ±æ¥çå¢å ï¼æåçº MLLM è¨­è¨äºæèé (CoT) æç¤ºï¼ä»¥æ¸å°å¹»è¦ºã
æåå¨å¬ç¾åºæºä¸æ¸¬è©¦äºéå©ç¨®æ¹æ³ï¼ä¾å¦ ChartQAãOpenCQA å ChartXï¼è­æäºæè½çæåï¼ä¸¦é©è­äºæåæåºçæ¹æ³çæææ§ã

##### **Detection, Retrieval, and Explanation Unified: A Violence Detection System Based on Knowledge Graphs and GAT**
2501.06224v1 by Wen-Dong Jiang, Chih-Yung Chang, Diptendu Sinha Roy

Recently, violence detection systems developed using unified multimodal
models have achieved significant success and attracted widespread attention.
However, most of these systems face two critical challenges: the lack of
interpretability as black-box models and limited functionality, offering only
classification or retrieval capabilities. To address these challenges, this
paper proposes a novel interpretable violence detection system, termed the
Three-in-One (TIO) System. The TIO system integrates knowledge graphs (KG) and
graph attention networks (GAT) to provide three core functionalities:
detection, retrieval, and explanation. Specifically, the system processes each
video frame along with text descriptions generated by a large language model
(LLM) for videos containing potential violent behavior. It employs ImageBind to
generate high-dimensional embeddings for constructing a knowledge graph, uses
GAT for reasoning, and applies lightweight time series modules to extract video
embedding features. The final step connects a classifier and retriever for
multi-functional outputs. The interpretability of KG enables the system to
verify the reasoning process behind each output. Additionally, the paper
introduces several lightweight methods to reduce the resource consumption of
the TIO system and enhance its efficiency. Extensive experiments conducted on
the XD-Violence and UCF-Crime datasets validate the effectiveness of the
proposed system. A case study further reveals an intriguing phenomenon: as the
number of bystanders increases, the occurrence of violent behavior tends to
decrease.

æè¦ï¼<paragraph>æè¿ï¼ä½¿ç¨çµ±ä¸å¤æ¨¡ææ¨¡åéç¼çæ´ååµæ¸¬ç³»çµ±åå¾é¡¯èæåï¼ä¸¦å¼èµ·å»£æ³éæ³¨ãç¶èï¼éäºç³»çµ±å¤§å¤é¢è¨å©é å´å³»ææ°ï¼ç¼ºä¹é»ç®±æ¨¡åçå¯è§£éæ§ï¼ä»¥ååè½åéï¼åæä¾åé¡ææª¢ç´¢è½åãçºäºè§£æ±ºéäºææ°ï¼æ¬ææåºäºä¸åæ°ç©çå¯è§£éæ´ååµæ¸¬ç³»çµ±ï¼ç¨±çºä¸åä¸ (TIO) ç³»çµ±ãTIO ç³»çµ±æ´åç¥è­åè­ (KG) ååå½¢æ³¨æåç¶²è·¯ (GAT)ï¼ä»¥æä¾ä¸é æ ¸å¿åè½ï¼åµæ¸¬ãæª¢ç´¢åè§£éãå·é«ä¾èªªï¼è©²ç³»çµ±èçæ¯åå½±çå¹ï¼ä»¥åå¤§åèªè¨æ¨¡å (LLM) çºåå«æ½å¨æ´åè¡çºçå½±çç¢ççæå­æè¿°ãå®æ¡ç¨ ImageBind ç¢çé«ç¶­åµå¥ï¼ç¨æ¼å»ºæ§ç¥è­åè­ï¼ä½¿ç¨ GAT é²è¡æ¨çï¼ä¸¦æç¨è¼éç´æéåºåæ¨¡çµä¾æåå½±çåµå¥ç¹å¾µãæå¾ä¸æ­¥é£æ¥åé¡å¨åæª¢ç´¢å¨ï¼ä»¥ç¢çå¤åè½è¼¸åºãKG çå¯è§£éæ§è®ç³»çµ±è½å¤ é©è­æ¯åè¼¸åºèå¾çæ¨çéç¨ãæ­¤å¤ï¼æ¬æä»ç´¹äºå¹¾ç¨®è¼éç´æ¹æ³ï¼ä»¥æ¸å° TIO ç³»çµ±çè³æºæ¶èï¼ä¸¦æåå¶æçãå¨ XD-Violence å UCF-Crime è³æéä¸é²è¡çå»£æ³å¯¦é©é©è­äºææåºç³»çµ±çæææ§ãæ¡ä¾ç ç©¶é²ä¸æ­¥æ­ç¤ºäºä¸åæè¶£çç¾è±¡ï¼é¨èæè§èäººæ¸å¢å ï¼æ´åè¡çºç¼ççæ©çæä¸éã</paragraph>

##### **Applying Large Language Models in Knowledge Graph-based Enterprise Modeling: Challenges and Opportunities**
2501.03566v1 by Benedikt Reitemeyer, Hans-Georg Fill

The role of large language models (LLMs) in enterprise modeling has recently
started to shift from academic research to that of industrial applications.
Thereby, LLMs represent a further building block for the machine-supported
generation of enterprise models. In this paper we employ a knowledge
graph-based approach for enterprise modeling and investigate the potential
benefits of LLMs in this context. In addition, the findings of an expert survey
and ChatGPT-4o-based experiments demonstrate that LLM-based model generations
exhibit minimal variability, yet remain constrained to specific tasks, with
reliability declining for more intricate tasks. The survey results further
suggest that the supervision and intervention of human modeling experts are
essential to ensure the accuracy and integrity of the generated models.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å¨ä¼æ¥­å»ºæ¨¡ä¸­çè§è²æè¿å·²éå§å¾å­¸è¡ç ç©¶è½è®çºç¢æ¥­æç¨ãå æ­¤ï¼LLM ä»£è¡¨äºæ©å¨æ¯æ´çä¼æ¥­æ¨¡åçæçé²ä¸æ­¥å»ºæ§æ¨¡çµãå¨æ¬æä¸­ï¼æåæ¡ç¨åºæ¼ç¥è­åè¡¨çä¼æ¥­å»ºæ¨¡æ¹æ³ï¼ä¸¦æ¢è¨ LLM å¨æ­¤èçµ¡ä¸­çæ½å¨æçãæ­¤å¤ï¼å°å®¶èª¿æ¥ååºæ¼ ChatGPT-4o çå¯¦é©çµæè¡¨æï¼åºæ¼ LLM çæ¨¡åçæå±ç¾æå°çå¯è®æ§ï¼ä½ä»ä¾·éæ¼ç¹å®ä»»åï¼èå¯é æ§æé¨èä»»åçè¤éæ§èä¸éãèª¿æ¥çµæé²ä¸æ­¥è¡¨æï¼äººé¡å»ºæ¨¡å°å®¶çç£ç£åä»å¥å°æ¼ç¢ºä¿çææ¨¡åçæºç¢ºæ§åå®æ´æ§è³ééè¦ã

##### **KG-TRICK: Unifying Textual and Relational Information Completion of Knowledge for Multilingual Knowledge Graphs**
2501.03560v1 by Zelin Zhou, Simone Conia, Daniel Lee, Min Li, Shenglei Huang, Umar Farooq Minhas, Saloni Potdar, Henry Xiao, Yunyao Li

Multilingual knowledge graphs (KGs) provide high-quality relational and
textual information for various NLP applications, but they are often
incomplete, especially in non-English languages. Previous research has shown
that combining information from KGs in different languages aids either
Knowledge Graph Completion (KGC), the task of predicting missing relations
between entities, or Knowledge Graph Enhancement (KGE), the task of predicting
missing textual information for entities. Although previous efforts have
considered KGC and KGE as independent tasks, we hypothesize that they are
interdependent and mutually beneficial. To this end, we introduce KG-TRICK, a
novel sequence-to-sequence framework that unifies the tasks of textual and
relational information completion for multilingual KGs. KG-TRICK demonstrates
that: i) it is possible to unify the tasks of KGC and KGE into a single
framework, and ii) combining textual information from multiple languages is
beneficial to improve the completeness of a KG. As part of our contributions,
we also introduce WikiKGE10++, the largest manually-curated benchmark for
textual information completion of KGs, which features over 25,000 entities
across 10 diverse languages.

æè¦ï¼å¤èªè¨ç¥è­åè­ (KG) çºåç¨® NLP æç¨ç¨å¼æä¾é«åè³ªçéä¿åæå­è³è¨ï¼ä½å®åéå¸¸æ¯ä¸å®æ´çï¼ç¹å¥æ¯éè±èªèªè¨ãååçç ç©¶é¡¯ç¤ºï¼çµåä¸åèªè¨ä¸­ KG çè³è¨æå©æ¼ç¥è­åè­å®æåè½ (KGC)ï¼å³é æ¸¬å¯¦é«ä¹ééºå¤±çéä¿ï¼æç¥è­åè­å¢å¼· (KGE)ï¼å³é æ¸¬å¯¦é«éºå¤±çæå­è³è¨ãåç®¡ååçåªåå° KGC å KGE è¦çºç¨ç«çä»»åï¼æååè¨­å®åæ¯ç¸äºä¾è³´ä¸äºå©çãçºæ­¤ï¼æåå¼å¥äº KG-TRICKï¼ä¸åæ°ç©çåºåå°åºåæ¶æ§ï¼å®çµ±ä¸äºå¤èªè¨ KG çæå­åéä¿è³è¨å®æä»»åãKG-TRICK è­æï¼i) å¯ä»¥å° KGC å KGE çä»»åçµ±ä¸å°å®ä¸æ¶æ§ä¸­ï¼ä»¥å ii) çµåå¤ç¨®èªè¨çæå­è³è¨æå©æ¼æé« KG çå®æ´æ§ãä½çºæåè²¢ç»çä¸é¨åï¼æåéå¼å¥äº WikiKGE10++ï¼éæ¯ KG æå­è³è¨å®ææå¤§çæåæ´çåºæºï¼å¶ç¹é»æ¯è¶é 10 ç¨®ä¸åèªè¨ä¸­ç 25,000 åå¯¦é«ã

##### **Semantic Captioning: Benchmark Dataset and Graph-Aware Few-Shot In-Context Learning for SQL2Text**
2501.03166v1 by Ali Al-Lawati, Jason Lucas, Prasenjit Mitra

Large Language Models (LLMs) have demonstrated remarkable performance in
various NLP tasks, including semantic parsing, which trans lates natural
language into formal code representations. However, the reverse process,
translating code into natural language, termed semantic captioning, has
received less attention. This task is becoming increasingly important as LLMs
are integrated into platforms for code generation, security analysis, and
educational purposes. In this paper, we focus on the captioning of SQL query
(SQL2Text) to address the critical need for understanding and explaining SQL
queries in an era where LLM-generated code poses potential security risks. We
repurpose Text2SQL datasets for SQL2Text by introducing an iterative ICL prompt
using GPT-4o to generate multiple additional utterances, which enhances the
robustness of the datasets for the reverse task. We conduct our experiments
using in-context learning (ICL) based on different sample selection methods,
emphasizing smaller, more computationally efficient LLMs. Our findings
demonstrate that leveraging the inherent graph properties of SQL for ICL sample
selection significantly outperforms random selection by up to 39% on BLEU score
and provides better results than alternative methods. Dataset and codes are
published: \url{https://github.com/aliwister/ast-icl}.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å·²å¨åç¨® NLP ä»»åä¸­å±ç¾åºé©äººçæè½ï¼åæ¬èªæåæï¼å®å°èªç¶èªè¨è½æçºæ­£å¼çç¨å¼ç¢¼è¡¨ç¤ºãç¶èï¼ååéç¨ï¼å°ç¨å¼ç¢¼è½æçºèªç¶èªè¨ï¼ç¨±çºèªææ¨é¡ï¼åè¼å°åå°éæ³¨ãé¨è LLM æ´åå°ç¨å¼ç¢¼ç¢çãå®å¨æ§åæåæè²ç®ççå¹³å°ä¸­ï¼éé ä»»åæ­£è®å¾è¶ä¾è¶éè¦ãå¨æ¬æä¸­ï¼æåå°æ³¨æ¼ SQL æ¥è©¢çæ¨é¡ (SQL2Text)ï¼ä»¥æ»¿è¶³å¨ LLM ç¢ççç¨å¼ç¢¼æ§ææ½å¨å®å¨é¢¨éªçæä»£ä¸­ï¼çè§£åè§£é SQL æ¥è©¢çééµéæ±ãæåééä½¿ç¨ GPT-4o å°å¥åè¦ç ICL æç¤ºä¾ç¢çå¤åé¡å¤çèªå¥ï¼éæ°èª¿æ´ Text2SQL è³æéä»¥ç¨æ¼ SQL2Textï¼éå¢å¼·äºè³æéå°ååä»»åçç©©å¥æ§ãæåä½¿ç¨åºæ¼ä¸åç¯ä¾é¸åæ¹æ³çæå¢å­¸ç¿ (ICL) é²è¡å¯¦é©ï¼å¼·èª¿è¼å°ãè¨ç®æçè¼é«ç LLMãæåçç ç©¶çµæè­æï¼å©ç¨ SQL çå§å¨åå½¢å±¬æ§é²è¡ ICL ç¯ä¾é¸åï¼å¨ BLEU åæ¸ä¸é¡¯èåªæ¼é¨æ©é¸åï¼æå¤å¯é 39%ï¼ä¸¦æä¾æ¯å¶ä»æ¹æ³æ´å¥½ççµæãè³æéåç¨å¼ç¢¼å·²ç¼å¸ï¼\url{https://github.com/aliwister/ast-icl}ã

##### **Personalized Fashion Recommendation with Image Attributes and Aesthetics Assessment**
2501.03085v1 by Chongxian Chen, Fan Mo, Xin Fan, Hayato Yamana

Personalized fashion recommendation is a difficult task because 1) the
decisions are highly correlated with users' aesthetic appetite, which previous
work frequently overlooks, and 2) many new items are constantly rolling out
that cause strict cold-start problems in the popular identity (ID)-based
recommendation methods. These new items are critical to recommend because of
trend-driven consumerism. In this work, we aim to provide more accurate
personalized fashion recommendations and solve the cold-start problem by
converting available information, especially images, into two attribute graphs
focusing on optimized image utilization and noise-reducing user modeling.
Compared with previous methods that separate image and text as two components,
the proposed method combines image and text information to create a richer
attributes graph. Capitalizing on the advancement of large language and vision
models, we experiment with extracting fine-grained attributes efficiently and
as desired using two different prompts. Preliminary experiments on the IQON3000
dataset have shown that the proposed method achieves competitive accuracy
compared with baselines.

æè¦ï¼å®¢è£½åæå°æ¨è¦æ¯ä¸é å°é£çä»»åï¼å çº 1) æ±ºç­èä½¿ç¨èçç¾å­¸åå¥½é«åº¦ç¸éï¼èååçç ç©¶ç¶å¸¸å¿½ç¥éä¸é»ï¼ä»¥å 2) è¨±å¤æ°ååä¸æ·æ¨åºï¼éæå¨æµè¡çèº«å (ID) çºåºç¤çæ¨è¦æ¹æ³ä¸­é æå´éçå·åååé¡ãéäºæ°ååå°æ¼æ¨è¦è³ééè¦ï¼å çºå®åæå¼é æ¶è²»è¶¨å¢ãå¨éé ç ç©¶ä¸­ï¼æåæ¨å¨æä¾æ´æºç¢ºçå®¢è£½åæå°æ¨è¦ï¼ä¸¦ééå°å¯ç¨è³è¨ï¼å°¤å¶æ¯åçï¼è½ææå©åå±¬æ§åè¡¨ä¾è§£æ±ºå·åååé¡ï¼éé»å¨æ¼æä½³ååçä½¿ç¨åéä½éè¨çä½¿ç¨èå»ºæ¨¡ãèå°åçåæå­åéçºå©åçµæçååæ¹æ³ç¸æ¯ï¼ææåºçæ¹æ³çµååçåæå­è³è¨ï¼ä»¥å»ºç«æ´è±å¯çå±¬æ§åè¡¨ãå©ç¨å¤§åèªè¨åè¦è¦ºæ¨¡åçé²æ­¥ï¼æååè©¦ä½¿ç¨å©ç¨®ä¸åçæç¤ºææçä¸å¦é æè¬å°èåç´°ç·»çå±¬æ§ãå¨ IQON3000 è³æéä¸çåæ­¥å¯¦é©é¡¯ç¤ºï¼èåºæºç¸æ¯ï¼ææåºçæ¹æ³éå°äºç«¶ç­åçæºç¢ºåº¦ã

##### **Graph-based Retrieval Augmented Generation for Dynamic Few-shot Text Classification**
2501.02844v1 by Yubo Wang, Haoyang Li, Fei Teng, Lei Chen

Text classification is a fundamental task in natural language processing,
pivotal to various applications such as query optimization, data integration,
and schema matching. While neural network-based models, such as CNN and BERT,
have demonstrated remarkable performance in text classification, their
effectiveness heavily relies on abundant labeled training data. This dependency
makes these models less effective in dynamic few-shot text classification,
where labeled data is scarce, and target labels frequently evolve based on
application needs. Recently, large language models (LLMs) have shown promise
due to their extensive pretraining and contextual understanding. Current
approaches provide LLMs with text inputs, candidate labels, and additional side
information (e.g., descriptions) to predict text labels. However, their
effectiveness is hindered by the increased input size and the noise introduced
through side information processing. To address these limitations, we propose a
graph-based online retrieval-augmented generation framework, namely GORAG, for
dynamic few-shot text classification. GORAG constructs and maintains an
adaptive information graph by extracting side information across all target
texts, rather than treating each input independently. It employs a weighted
edge mechanism to prioritize the importance and reliability of extracted
information and dynamically retrieves relevant context using a minimum-cost
spanning tree tailored for each text input. Empirical evaluations demonstrate
that GORAG outperforms existing approaches by providing more comprehensive and
accurate contextual information.

æè¦ï¼ææ¬åé¡æ¯èªç¶èªè¨èçä¸­çåºæ¬ä»»åï¼
å°æ¼åç¨®æç¨è³ééè¦ï¼ä¾å¦æ¥è©¢åªåãè³ææ´åï¼
åæ¨¡å¼å¹éãéç¶åºæ¼ç¥ç¶ç¶²è·¯çæ¨¡åï¼ä¾å¦ CNN å BERTï¼
å¨ææ¬åé¡ä¸­è¡¨ç¾åºè²ï¼ä½å¶
æææ§å¨å¾å¤§ç¨åº¦ä¸ä¾è³´æ¼å¤§éçæ¨ç±¤è¨ç·´è³æãéåä¾è³´æ§
ä½¿å¾éäºæ¨¡åå¨åæå°æ¨£æ¬ææ¬åé¡ä¸­ææè¼å·®ï¼
å¶ä¸­æ¨ç±¤è³æç¨ç¼ºï¼ä¸¦ä¸ç®æ¨æ¨ç±¤ææ ¹æ
æç¨éæ±é »ç¹æ¼è®ãæè¿ï¼å¤§åèªè¨æ¨¡å (LLM) ç±æ¼å¶å»£æ³çé è¨ç·´åä¸ä¸æçè§£èé¡¯ç¤ºåºåæ¯ãç®å
æ¹æ³çº LLM æä¾ææ¬è¼¸å¥ãåé¸æ¨ç±¤åéå å´é
è³è¨ï¼ä¾å¦ï¼æè¿°ï¼ä»¥é æ¸¬ææ¬æ¨ç±¤ãç¶èï¼å¶
æææ§åå°è¼¸å¥å¤§å°å¢å åå´éè³è¨èçå¼å¥çéè¨çé»ç¤ãçºäºè§£æ±ºéäºéå¶ï¼æåæåºä¸å
åºæ¼åè¡¨çç·ä¸æª¢ç´¢å¢å¼·çææ¶æ§ï¼å³ GORAGï¼ç¨æ¼
åæå°æ¨£æ¬ææ¬åé¡ãGORAG ééæåææç®æ¨çå´éè³è¨ä¾å»ºæ§ä¸¦ç¶­è­·ä¸å
èªé©æè³è¨åè¡¨
ææ¬ï¼èä¸æ¯ç¨ç«èçæ¯åè¼¸å¥ãå®æ¡ç¨å æ¬
éç·£æ©å¶ä¾åªåèæ®æåè³è¨çéè¦æ§åå¯é æ§ï¼ä¸¦ä½¿ç¨éå°æ¯åææ¬è¼¸å¥éèº«æé çæå°ææ¬
çææ¨¹åææª¢ç´¢ç¸éçä¸ä¸æãå¯¦è­è©ä¼°è¡¨æ
GORAG ééæä¾æ´å¨é¢ä¸æºç¢ºçä¸ä¸æè³è¨ï¼åªæ¼ç¾ææ¹æ³ã

##### **KG-CF: Knowledge Graph Completion with Context Filtering under the Guidance of Large Language Models**
2501.02711v1 by Zaiyi Zheng, Yushun Dong, Song Wang, Haochen Liu, Qi Wang, Jundong Li

Large Language Models (LLMs) have shown impressive performance in various
tasks, including knowledge graph completion (KGC). However, current studies
mostly apply LLMs to classification tasks, like identifying missing triplets,
rather than ranking-based tasks, where the model ranks candidate entities based
on plausibility. This focus limits the practical use of LLMs in KGC, as
real-world applications prioritize highly plausible triplets. Additionally,
while graph paths can help infer the existence of missing triplets and improve
completion accuracy, they often contain redundant information. To address these
issues, we propose KG-CF, a framework tailored for ranking-based KGC tasks.
KG-CF leverages LLMs' reasoning abilities to filter out irrelevant contexts,
achieving superior results on real-world datasets. The code and datasets are
available at \url{https://anonymous.4open.science/r/KG-CF}.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å¨åç¨®ä»»åä¸­å±ç¾åºä»¤äººå°è±¡æ·±å»çè¡¨ç¾ï¼åæ¬ç¥è­åè­å®æåè½ (KGC)ãç¶èï¼ç®åçç ç©¶å¤§å¤å° LLM æç¨æ¼åé¡ä»»åï¼ä¾å¦è­å¥éºæ¼çä¸åçµï¼èéåºæ¼æåçä»»åï¼å¶ä¸­æ¨¡åæ ¹æåçæ§å°åé¸å¯¦é«é²è¡æåãéç¨®éé»éå¶äº LLM å¨ KGC ä¸­çå¯¦éæç¨ï¼å çºç¾å¯¦ä¸ççæç¨åªåèæ®é«åº¦åçççä¸åçµãæ­¤å¤ï¼åç®¡åå½¢è·¯å¾æå©æ¼æ¨æ·éºæ¼çä¸åçµçå­å¨ä¸¦æé«å®æçæºç¢ºæ§ï¼ä½å®åéå¸¸åå«åé¤è³è¨ãçºäºè§£æ±ºéäºåé¡ï¼æåæåº KG-CFï¼ä¸åå°ééå°åºæ¼æåç KGC ä»»åçæ¡æ¶ãKG-CF å©ç¨ LLM çæ¨çè½åä¾éæ¿¾ä¸ç¸éçä¸ä¸æï¼å¨ç¾å¯¦ä¸ççè³æéä¸åå¾åè¶çææãç¨å¼ç¢¼åè³æéå¯å¨ \url{https://anonymous.4open.science/r/KG-CF} åå¾ã

##### **Graph-Aware Isomorphic Attention for Adaptive Dynamics in Transformers**
2501.02393v2 by Markus J. Buehler

We present an approach to modifying Transformer architectures by integrating
graph-aware relational reasoning into the attention mechanism, merging concepts
from graph neural networks and language modeling. Building on the inherent
connection between attention and graph theory, we reformulate the Transformer's
attention mechanism as a graph operation and propose Graph-Aware Isomorphic
Attention. This method leverages advanced graph modeling strategies, including
Graph Isomorphism Networks (GIN) and Principal Neighborhood Aggregation (PNA),
to enrich the representation of relational structures. Our approach captures
complex dependencies and generalizes across tasks, as evidenced by a reduced
generalization gap and improved learning performance. Additionally, we expand
the concept of graph-aware attention to introduce Sparse GIN-Attention, a
fine-tuning approach that employs sparse GINs. By interpreting attention
matrices as sparse adjacency graphs, this technique enhances the adaptability
of pre-trained foundational models with minimal computational overhead,
endowing them with graph-aware capabilities. Sparse GIN-Attention fine-tuning
achieves improved training dynamics and better generalization compared to
alternative methods like low-rank adaption (LoRA). We discuss latent graph-like
structures within traditional attention mechanisms, offering a new lens through
which Transformers can be understood. By evolving Transformers as hierarchical
GIN models for relational reasoning. This perspective suggests profound
implications for foundational model development, enabling the design of
architectures that dynamically adapt to both local and global dependencies.
Applications in bioinformatics, materials science, language modeling, and
beyond could benefit from this synthesis of relational and sequential data
modeling, setting the stage for interpretable and generalizable modeling
strategies.

æè¦ï¼<paragraph>æåæåºäºä¸ç¨®ä¿®æ¹ Transformer æ¶æ§çæ¹æ³ï¼æ¹æ³æ¯å°åæç¥éè¯æ¨çæ´åå°æ³¨æåæ©å¶ä¸­ï¼åä½µåç¥ç¶ç¶²è·¯åèªè¨æ¨¡åçæ¦å¿µãåºæ¼æ³¨æåååè«ä¹éçå§å¨è¯ç¹«ï¼æåå° Transformer çæ³¨æåæ©å¶éæ°è¡¨è¿°çºåæä½ï¼ä¸¦æåºåæç¥åæ§æ³¨æåãæ­¤æ¹æ³å©ç¨åé²çåæ¨¡åç­ç¥ï¼åæ¬ååæ§ç¶²è·¯ (GIN) åä¸»é°åèå (PNA)ï¼ä»¥è±å¯éä¿çµæ§çè¡¨ç¤ºãæåçåæ³ææäºè¤éçä¾è³´éä¿ï¼ä¸¦å¨åé ä»»åä¸­é²è¡æ¦æ¬ï¼éå¾ç¸®å°çæ¦æ¬å·®è·åæ¹åçå­¸ç¿è¡¨ç¾ä¸­å¾å°è­æãæ­¤å¤ï¼æåæ´å±äºåæç¥æ³¨æåçæ¦å¿µï¼å¼å¥äºç¨ç GIN æ³¨æåï¼éæ¯ä¸ç¨®æ¡ç¨ç¨ç GIN çå¾®èª¿æ¹æ³ãééå°æ³¨æåç©é£è§£éçºç¨çé°æ¥åï¼æ­¤æè¡ä»¥æå°çè¨ç®éé·å¢å¼·äºé è¨ç·´åºç¤æ¨¡åçé©ææ§ï¼è³¦äºå®ååæç¥è½åãèä½ç§©é©æ (LoRA) ç­æ¿ä»£æ¹æ³ç¸æ¯ï¼ç¨ç GIN æ³¨æåå¾®èª¿å¯¦ç¾äºæ¹é²çè¨ç·´åæåæ´å¥½çæ¦æ¬ãæåè¨è«äºå³çµ±æ³¨æåæ©å¶ä¸­çæ½å¨åå½¢çµæ§ï¼æä¾äºä¸åæ°çè¦è§ï¼ééå®å¯ä»¥çè§£ Transformerãééå° Transformer æ¼åçºç¨æ¼éä¿æ¨ççåå±¤ GIN æ¨¡åãéç¨®è§é»å°åºç¤æ¨¡åçéç¼å·ææ·±é çå½±é¿ï¼å¯ä»¥è¨­è¨åºåæé©æå±é¨åå¨å±ä¾è³´éä¿çæ¶æ§ãçç©è³è¨å­¸ãææç§å­¸ãèªè¨å»ºæ¨¡ç­é åçæç¨å¯ä»¥å¾éç¨®éä¿ååºåè³æå»ºæ¨¡çç¶åä¸­åçï¼çºå¯è§£éåå¯æ¦æ¬çå»ºæ¨¡ç­ç¥å¥ å®åºç¤ã</paragraph>

##### **What Kind of Visual Tokens Do We Need? Training-free Visual Token Pruning for Multi-modal Large Language Models from the Perspective of Graph**
2501.02268v1 by Yutao Jiang, Qiong Wu, Wenhao Lin, Wei Yu, Yiyi Zhou

Recent Multimodal Large Language Models(MLLMs) often use a large number of
visual tokens to compensate their visual shortcoming, leading to excessive
computation and obvious visual redundancy. In this paper, we investigate what
kind of visual tokens are needed for MLLMs, and reveal that both foreground and
background tokens are critical for MLLMs given the varying difficulties of
examples. Based on this observation, we propose a graph-based method towards
training-free visual token pruning, termed G-Prune.In particular, G-Prune
regards visual tokens as nodes, and construct their connections based on their
semantic similarities. Afterwards, the information flow is propagated via
weighted links, and the most important tokens after iterations are kept for
MLLMs, which can be front or background.To validate G-Prune, we apply it to a
recent MLLM called LLaVA-NeXT, and conduct extensive experiments on a set of
benchmarks.The experiment results show that G-Prune can greatly reduce
computation overhead while retaining high performance on both coarse- and
fine-grained tasks. For instance, G-Prune can reduce 63.57\% FLOPs of
LLaVA-NeXT on VQA2.0 and TextVQA with only 0.95\% and 2.34\% accuracy drops,
respectively.

æè¦ï¼æè¿çå¤æ¨¡æå¤§åè¯­è¨æ¨¡å (MLLM) ç»å¸¸ä½¿ç¨å¤§éçè§è§æ è®°æ¥å¼¥è¡¥å¶è§è§ä¸çç¼ºç¹ï¼å¯¼è´è¿åº¦çè®¡ç®åææ¾çè§è§åä½ãå¨æ¬æä¸­ï¼æä»¬è°æ¥äº MLLM éè¦åªç§è§è§æ è®°ï¼å¹¶æ­ç¤ºäºé´äºç¤ºä¾çé¾åº¦ä¸åï¼åæ¯æ è®°åèæ¯æ è®°å¯¹äº MLLM é½æ¯è³å³éè¦çãåºäºæ­¤è§å¯ï¼æä»¬æåºäºä¸ç§åºäºå¾çæ è®­ç»è§è§æ è®°åªææ¹æ³ï¼ç§°ä¸º G-Pruneãç¹å«æ¯ï¼G-Prune å°è§è§æ è®°è§ä¸ºèç¹ï¼å¹¶æ ¹æ®å¶è¯­ä¹ç¸ä¼¼æ§æå»ºå®ä»¬çè¿æ¥ãä¹åï¼ä¿¡æ¯æµéè¿å æé¾æ¥ä¼ æ­ï¼å¹¶ä¸å¨è¿­ä»£åæéè¦çæ è®°ä¿çç¨äº MLLMï¼å®å¯ä»¥æ¯åæ¯æèæ¯ãä¸ºäºéªè¯ G-Pruneï¼æä»¬å°å¶åºç¨äºç§°ä¸º LLaVA-NeXT çææ° MLLMï¼å¹¶å¨ä¸ç»åºåä¸è¿è¡äºå¹¿æ³çå®éªãå®éªç»æè¡¨æï¼G-Prune å¯ä»¥æå¤§å°åå°è®¡ç®å¼éï¼åæ¶å¨ç²ç²åº¦åç»ç²åº¦ä»»å¡ä¸ä¿æé«æ§è½ãä¾å¦ï¼G-Prune å¯ä»¥å° LLaVA-NeXT å¨ VQA2.0 å TextVQA ä¸ç FLOP åå° 63.57%ï¼èåç¡®åº¦åå«ä»ä¸é 0.95% å 2.34%ã

##### **Personalized Graph-Based Retrieval for Large Language Models**
2501.02157v1 by Steven Au, Cameron J. Dimacali, Ojasmitha Pedirappagari, Namyong Park, Franck Dernoncourt, Yu Wang, Nikos Kanakaris, Hanieh Deilamsalehy, Ryan A. Rossi, Nesreen K. Ahmed

As large language models (LLMs) evolve, their ability to deliver personalized
and context-aware responses offers transformative potential for improving user
experiences. Existing personalization approaches, however, often rely solely on
user history to augment the prompt, limiting their effectiveness in generating
tailored outputs, especially in cold-start scenarios with sparse data. To
address these limitations, we propose Personalized Graph-based
Retrieval-Augmented Generation (PGraphRAG), a framework that leverages
user-centric knowledge graphs to enrich personalization. By directly
integrating structured user knowledge into the retrieval process and augmenting
prompts with user-relevant context, PGraphRAG enhances contextual understanding
and output quality. We also introduce the Personalized Graph-based Benchmark
for Text Generation, designed to evaluate personalized text generation tasks in
real-world settings where user history is sparse or unavailable. Experimental
results show that PGraphRAG significantly outperforms state-of-the-art
personalization methods across diverse tasks, demonstrating the unique
advantages of graph-based retrieval for personalization.

æè¦ï¼é¨èå¤§åèªè¨æ¨¡å (LLM) çæ¼é²ï¼å®åæä¾åäººååæå¢æç¥åæçè½åï¼çºæåä½¿ç¨èé«é©æä¾äºè®é©æ½åãç¶èï¼ç¾æçåäººåæ¹æ³éå¸¸åä¾è³´ä½¿ç¨èè¨éä¾æ´åæç¤ºï¼ééå¶äºå®åå¨ç¢çå®¢è£½åè¼¸åºçæè½ï¼ç¹å¥æ¯å¨è³æç¨ççå·ååæå¢ä¸­ãçºäºè§£æ±ºéäºéå¶ï¼æåæåºäºãåäººååå½¢åæª¢ç´¢æ´åç¢çã(PGraphRAG)ï¼ä¸åå©ç¨ä»¥ä½¿ç¨èçºä¸­å¿çç¥è­åå½¢ä¾è±å¯åäººåçæ¶æ§ãééå°çµæ§åçä½¿ç¨èç¥è­ç´æ¥æ´åå°æª¢ç´¢ç¨åºä¸­ï¼ä¸¦ä½¿ç¨èä½¿ç¨èç¸éçå§å®¹æ´åæç¤ºï¼PGraphRAG å¢å¼·äºæå¢çè§£åè¼¸åºåè³ªãæåä¹å¼å¥äºãåäººååå½¢ååºæºææ¬ç¢çãï¼æ¨å¨è©ä¼°å¨ä½¿ç¨èè¨éç¨çæä¸å¯ç¨ççå¯¦ä¸çè¨­å®ä¸­çåäººåææ¬ç¢çä»»åãå¯¦é©çµæé¡¯ç¤ºï¼PGraphRAG å¨åç¨®ä»»åä¸­é¡¯èåªæ¼æåé²çåäººåæ¹æ³ï¼è­æäºåå½¢åæª¢ç´¢å¨åäººåæ¹é¢çç¨ç¹åªå¢ã

##### **Cold-Start Recommendation towards the Era of Large Language Models (LLMs): A Comprehensive Survey and Roadmap**
2501.01945v2 by Weizhi Zhang, Yuanchen Bei, Liangwei Yang, Henry Peng Zou, Peilin Zhou, Aiwei Liu, Yinghui Li, Hao Chen, Jianling Wang, Yu Wang, Feiran Huang, Sheng Zhou, Jiajun Bu, Allen Lin, James Caverlee, Fakhri Karray, Irwin King, Philip S. Yu

Cold-start problem is one of the long-standing challenges in recommender
systems, focusing on accurately modeling new or interaction-limited users or
items to provide better recommendations. Due to the diversification of internet
platforms and the exponential growth of users and items, the importance of
cold-start recommendation (CSR) is becoming increasingly evident. At the same
time, large language models (LLMs) have achieved tremendous success and possess
strong capabilities in modeling user and item information, providing new
potential for cold-start recommendations. However, the research community on
CSR still lacks a comprehensive review and reflection in this field. Based on
this, in this paper, we stand in the context of the era of large language
models and provide a comprehensive review and discussion on the roadmap,
related literature, and future directions of CSR. Specifically, we have
conducted an exploration of the development path of how existing CSR utilizes
information, from content features, graph relations, and domain information, to
the world knowledge possessed by large language models, aiming to provide new
insights for both the research and industrial communities on CSR. Related
resources of cold-start recommendations are collected and continuously updated
for the community in
https://github.com/YuanchenBei/Awesome-Cold-Start-Recommendation.

æè¦ï¼å·åååé¡æ¯æ¨è¦ç³»çµ±ä¸­é·æå­å¨çææ°ä¹ä¸ï¼å°æ³¨æ¼æºç¢ºå»ºæ¨¡æ°çæäºååéçä½¿ç¨èæé ç®ï¼ä»¥æä¾æ´å¥½çå»ºè­°ãç±æ¼ç¶²è·¯å¹³å°çå¤æ¨£åä»¥åä½¿ç¨èåé ç®çææ¸ç´å¢é·ï¼å·ååæ¨è¦ (CSR) çéè¦æ§æ­£è®å¾è¶ä¾è¶æé¡¯ãåæï¼å¤§åèªè¨æ¨¡å (LLM) å·²åå¾å·¨å¤§çæåï¼ä¸¦å·åå»ºæ¨¡ä½¿ç¨èåé ç®è³è¨çå¼·å¤§è½åï¼çºå·ååæ¨è¦æä¾äºæ°çæ½åãç¶èï¼CSR çç ç©¶ç¤¾ç¾¤å¨éåé åä»ç¶ç¼ºä¹å¨é¢çåé¡§ååæãåºæ¼æ­¤ï¼å¨æ¬æä¸­ï¼æåç«å¨å¤§åèªè¨æ¨¡åçæä»£èæ¯ä¸ï¼å° CSR çè·¯ç·åãç¸éæç»åæªä¾æ¹åæä¾å¨é¢çåé¡§åè¨è«ãå·é«ä¾èªªï¼æåå°ç¾æ CSR å¦ä½å©ç¨è³è¨é²è¡äºæ¢ç´¢ï¼å¾å§å®¹ç¹å¾µãåéä¿åé åè³è¨ï¼å°å¤§åèªè¨æ¨¡åæææçä¸çç¥è­ï¼æ¨å¨çºç ç©¶åç¢æ¥­ç¤¾ç¾¤æä¾ CSR çæ°è¦è§£ãå·ååæ¨è¦çç¸éè³æºå·²æ¶éä¸¦æçºæ´æ°ï¼ä¾ç¤¾ç¾¤å¨ https://github.com/YuanchenBei/Awesome-Cold-Start-Recommendation ä¸­ä½¿ç¨ã

##### **Multimodal Contrastive Representation Learning in Augmented Biomedical Knowledge Graphs**
2501.01644v1 by Tien Dang, Viet Thanh Duy Nguyen, Minh Tuan Le, Truong-Son Hy

Biomedical Knowledge Graphs (BKGs) integrate diverse datasets to elucidate
complex relationships within the biomedical field. Effective link prediction on
these graphs can uncover valuable connections, such as potential novel
drug-disease relations. We introduce a novel multimodal approach that unifies
embeddings from specialized Language Models (LMs) with Graph Contrastive
Learning (GCL) to enhance intra-entity relationships while employing a
Knowledge Graph Embedding (KGE) model to capture inter-entity relationships for
effective link prediction. To address limitations in existing BKGs, we present
PrimeKG++, an enriched knowledge graph incorporating multimodal data, including
biological sequences and textual descriptions for each entity type. By
combining semantic and relational information in a unified representation, our
approach demonstrates strong generalizability, enabling accurate link
predictions even for unseen nodes. Experimental results on PrimeKG++ and the
DrugBank drug-target interaction dataset demonstrate the effectiveness and
robustness of our method across diverse biomedical datasets. Our source code,
pre-trained models, and data are publicly available at
https://github.com/HySonLab/BioMedKG

æè¦ï¼çç©å»å­¦ç¥è­åè­ (BKG) æ´åå¤æ¨£åçè³æéï¼ä»¥é¡æçç©é«å­¸é åå§çè¤ééä¿ãå¨éäºåè­ä¸é²è¡ææçé£çµé æ¸¬ï¼å¯ä»¥ç¼ç¾æå¹å¼çé£çµï¼ä¾å¦æ½å¨çæ°è¥ç©-ç¾çéä¿ãæåå¼å¥äºä¸ç¨®æ°ç©çå¤æ¨¡ææ¹æ³ï¼å®å°ä¾èªå°ç¨èªè¨æ¨¡å (LM) çåµå¥èåå½¢å°æ¯å­¸ç¿ (GCL) çµ±ä¸èµ·ä¾ï¼ä»¥å¢å¼·å¯¦é«å§éä¿ï¼åææ¡ç¨ç¥è­åå½¢åµå¥ (KGE) æ¨¡åä¾ææå¯¦é«ééä¿ï¼ä»¥é²è¡ææçé£çµé æ¸¬ãçºäºè§£æ±ºç¾æ BKG ä¸­çéå¶ï¼æåæåºäº PrimeKG++ï¼éæ¯ä¸åè±å¯çç¥è­åå½¢ï¼å®çµåäºå¤æ¨¡ææ¸æï¼åæ¬æ¯ç¨®é¡åå¯¦é«ççç©åºååæå­æè¿°ãééå¨çµ±ä¸è¡¨ç¤ºä¸­çµåèªç¾©åéä¿è³è¨ï¼æåçåæ³å±ç¤ºäºå¼·å¤§çæ¦æ¬æ§ï¼å³ä½¿å°æ¼æªè¦ç¯é»ä¹è½é²è¡æºç¢ºçé£çµé æ¸¬ãå¨ PrimeKG++ å DrugBank è¥ç©-æ¨é¶äº¤äºä½ç¨è³æéä¸çå¯¦é©çµæè­æäºæåçæ¹æ³å¨åç¨®çç©é«å­¸è³æéä¸­çæææ§åç©©å¥æ§ãæåçåå§ç¢¼ãé è¨ç·´æ¨¡ååè³æå¯å¨ https://github.com/HySonLab/BioMedKG å¬éåå¾ã

##### **Enhancing Uncertainty Modeling with Semantic Graph for Hallucination Detection**
2501.02020v1 by Kedi Chen, Qin Chen, Jie Zhou, Xinqi Tao, Bowen Ding, Jingwen Xie, Mingchen Xie, Peilong Li, Feng Zheng, Liang He

Large Language Models (LLMs) are prone to hallucination with non-factual or
unfaithful statements, which undermines the applications in real-world
scenarios. Recent researches focus on uncertainty-based hallucination
detection, which utilizes the output probability of LLMs for uncertainty
calculation and does not rely on external knowledge or frequent sampling from
LLMs. Whereas, most approaches merely consider the uncertainty of each
independent token, while the intricate semantic relations among tokens and
sentences are not well studied, which limits the detection of hallucination
that spans over multiple tokens and sentences in the passage. In this paper, we
propose a method to enhance uncertainty modeling with semantic graph for
hallucination detection. Specifically, we first construct a semantic graph that
well captures the relations among entity tokens and sentences. Then, we
incorporate the relations between two entities for uncertainty propagation to
enhance sentence-level hallucination detection. Given that hallucination occurs
due to the conflict between sentences, we further present a graph-based
uncertainty calibration method that integrates the contradiction probability of
the sentence with its neighbors in the semantic graph for uncertainty
calculation. Extensive experiments on two datasets show the great advantages of
our proposed approach. In particular, we obtain substantial improvements with
19.78% in passage-level hallucination detection.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å®¹æåºç¾éäºå¯¦æ§æä¸å¿ å¯¦çé³è¿°ï¼éæç ´å£ç¾å¯¦ä¸çå ´æ¯ä¸­çæç¨ãæè¿çç ç©¶éé»éæ³¨åºæ¼ä¸ç¢ºå®æ§çå¹»è¦ºæª¢æ¸¬ï¼å®å©ç¨ LLM çè¼¸åºæ©çé²è¡ä¸ç¢ºå®æ§è¨ç®ï¼ä¸¦ä¸ä¸ä¾è³´æ¼å¤é¨ç¥è­æå¾ LLM ä¸­é »ç¹åæ¨£ãç¶èï¼å¤§å¤æ¸æ¹æ³åèæ®æ¯åç¨ç«ç¬¦èçä¸ç¢ºå®æ§ï¼èç¬¦èåå¥å­ä¹éçè¤éèªç¾©éä¿å°æªå¾å°å¾å¥½çç ç©¶ï¼ééå¶äºå°è·¨è¶æ®µè½ä¸­å¤åç¬¦èåå¥å­çå¹»è¦ºçæª¢æ¸¬ãå¨æ¬æä¸­ï¼æåæåºäºä¸ç¨®ä½¿ç¨èªç¾©åå¢å¼·ä¸ç¢ºå®æ§å»ºæ¨¡ä»¥é²è¡å¹»è¦ºæª¢æ¸¬çæ¹æ³ãå·é«ä¾èªªï¼æåé¦åæ§å»ºä¸åèªç¾©åï¼å®å¾å¥½å°ææäºå¯¦é«ç¬¦èåå¥å­ä¹éçéä¿ãç¶å¾ï¼æåå°å©åå¯¦é«ä¹éçéä¿ç´å¥ä¸ç¢ºå®æ§å³æ­ï¼ä»¥å¢å¼·å¥å­ç´å¥çå¹»è¦ºæª¢æ¸¬ãç±æ¼å¹»è¦ºæ¯å å¥å­ä¹éçè¡çªèç¼ççï¼å æ­¤æåé²ä¸æ­¥æåºäºä¸ç¨®åºæ¼åçä¸ç¢ºå®æ§æ ¡æºæ¹æ³ï¼å®å°å¥å­ççç¾æ©çèå¶å¨èªç¾©åä¸­çé°å±çµåèµ·ä¾é²è¡ä¸ç¢ºå®æ§è¨ç®ãå¨å©åæ¸æéä¸çå»£æ³å¯¦é©é¡¯ç¤ºäºæåæåºçæ¹æ³çå·¨å¤§åªå¢ãç¹å¥æ¯ï¼æåå¨æ®µè½ç´å¥çå¹»è¦ºæª¢æ¸¬ä¸­ç²å¾äº 19.78% çé¡¯èæ¹é²ã

##### **Unfolding the Headline: Iterative Self-Questioning for News Retrieval and Timeline Summarization**
2501.00888v1 by Weiqi Wu, Shen Huang, Yong Jiang, Pengjun Xie, Fei Huang, Hai Zhao

In the fast-changing realm of information, the capacity to construct coherent
timelines from extensive event-related content has become increasingly
significant and challenging. The complexity arises in aggregating related
documents to build a meaningful event graph around a central topic. This paper
proposes CHRONOS - Causal Headline Retrieval for Open-domain News Timeline
SummarizatiOn via Iterative Self-Questioning, which offers a fresh perspective
on the integration of Large Language Models (LLMs) to tackle the task of
Timeline Summarization (TLS). By iteratively reflecting on how events are
linked and posing new questions regarding a specific news topic to gather
information online or from an offline knowledge base, LLMs produce and refresh
chronological summaries based on documents retrieved in each round.
Furthermore, we curate Open-TLS, a novel dataset of timelines on recent news
topics authored by professional journalists to evaluate open-domain TLS where
information overload makes it impossible to find comprehensive relevant
documents from the web. Our experiments indicate that CHRONOS is not only adept
at open-domain timeline summarization, but it also rivals the performance of
existing state-of-the-art systems designed for closed-domain applications,
where a related news corpus is provided for summarization.

æè¦ï¼å¨è³è¨å¿«éè®é·çé åä¸­ï¼å¾å¤§éçäºä»¶ç¸éå§å®¹å»ºæ§é£è²«çæéè»¸çè½åè®å¾è¶ä¾è¶éè¦ä¸å·æææ°æ§ãè¤éæ§å¨æ¼å½ç¸½ç¸éæä»¶ï¼ä»¥åç¹ä¸­å¿ä¸»é¡å»ºç«ææç¾©çäºä»¶åãæ¬ææåºäº CHRONOS - éæ¾é åæ°èæéè»¸æè¦çå ææ¨é¡æª¢ç´¢ï¼ééåè¦èªææåï¼æä¾æ´åå¤§åèªè¨æ¨¡å (LLM) ä¾èçæéè»¸æè¦ (TLS) ä»»åçæ°è§é»ãééåè¦æèäºä»¶å¦ä½é£çµï¼ä¸¦å°ç¹å®æ°èä¸»é¡æåºæ°åé¡ï¼ä»¥å¾ç·ä¸æé¢ç·ç¥è­åº«æ¶éè³è¨ï¼LLM ææ ¹ææ¯è¼ªæª¢ç´¢çæä»¶ç¢çä¸¦æ´æ°æéæè¦ãæ­¤å¤ï¼æåç­åäº Open-TLSï¼ä¸åç±å°æ¥­è¨èç·¨å¯«çè¿ææ°èä¸»é¡æéè»¸çæ°ç©è³æéï¼ä»¥è©ä¼°éæ¾é åç TLSï¼å¶ä¸­è³è¨éè¼ä½¿å¾ç¡æ³å¾ç¶²è·¯ä¸æ¾å°å¨é¢çç¸éæä»¶ãæåçå¯¦é©è¡¨æï¼CHRONOS ä¸åæé·éæ¾é åçæéè»¸æè¦ï¼èä¸éèå°çºå°éé åæç¨è¨­è¨çç¾ææåé²ç³»çµ±çæè½ç¸åª²ç¾ï¼å¶ä¸­æä¾äºç¸éçæ°èèªæåº«ç¨æ¼æè¦ã

##### **Breaking Through the Spike: Spike Window Decoding for Accelerated and Precise Automatic Speech Recognition**
2501.03257v1 by Wei Zhang, Tian-Hao Zhang, Chao Luo, Hui Zhou, Chao Yang, Xinyuan Qian, Xu-Cheng Yin

Recently, end-to-end automatic speech recognition has become the mainstream
approach in both industry and academia. To optimize system performance in
specific scenarios, the Weighted Finite-State Transducer (WFST) is extensively
used to integrate acoustic and language models, leveraging its capacity to
implicitly fuse language models within static graphs, thereby ensuring robust
recognition while also facilitating rapid error correction. However, WFST
necessitates a frame-by-frame search of CTC posterior probabilities through
autoregression, which significantly hampers inference speed. In this work, we
thoroughly investigate the spike property of CTC outputs and further propose
the conjecture that adjacent frames to non-blank spikes carry semantic
information beneficial to the model. Building on this, we propose the Spike
Window Decoding algorithm, which greatly improves the inference speed by making
the number of frames decoded in WFST linearly related to the number of spiking
frames in the CTC output, while guaranteeing the recognition performance. Our
method achieves SOTA recognition accuracy with significantly accelerates
decoding speed, proven across both AISHELL-1 and large-scale In-House datasets,
establishing a pioneering approach for integrating CTC output with WFST.

æè¦ï¼è¿å¹´æ¥ï¼ç«¯å°ç«¯çèªå¨è¯­é³è¯å«å·²æä¸ºå·¥ä¸çåå­¦æ¯ççæµè¡æ¹æ³ãä¸ºäºä¼åç¹å®åºæ¯ä¸­çç³»ç»æ§è½ï¼å ææéç¶æè½¬æ¢å¨ (WFST) è¢«å¹¿æ³ç¨äºéæå£°å­¦åè¯­è¨æ¨¡åï¼å©ç¨å¶å¨éæå¾ä¸­éå¼èåè¯­è¨æ¨¡åçè½åï¼ä»èç¡®ä¿ç¨³å¥çè¯å«ï¼åæ¶ä¿è¿å¿«éçº éãç¶èï¼WFST éè¦éè¿èªåå½éå¸§æç´¢ CTC åéªæ¦çï¼è¿æå¤§å°é»ç¢äºæ¨çéåº¦ãå¨è¿é¡¹å·¥ä½ä¸­ï¼æä»¬å½»åºç ç©¶äº CTC è¾åºçå°å³°ç¹æ§ï¼å¹¶è¿ä¸æ­¥æåºä¸ä¸ªçæ³ï¼å³éç©ºç½å°å³°çç¸é»å¸§æºå¸¦å¯¹æ¨¡åæççè¯­ä¹ä¿¡æ¯ãå¨æ­¤åºç¡ä¸ï¼æä»¬æåºäº Spike Window è§£ç ç®æ³ï¼è¯¥ç®æ³éè¿ä½¿ WFST ä¸­è§£ç çå¸§æ°ä¸ CTC è¾åºä¸­å°å³°å¸§æ°çº¿æ§ç¸å³ï¼åæ¶ä¿è¯è¯å«æ§è½ï¼æå¤§å°æé«äºæ¨çéåº¦ãæä»¬çæ¹æ³å¨ AISHELL-1 åå¤§è§æ¨¡åé¨æ°æ®éä¸é½å®ç°äº SOTA è¯å«åç¡®åº¦ï¼å¹¶æ¾èå å¿«äºè§£ç éåº¦ï¼ä¸ºå° CTC è¾åºä¸ WFST éæå»ºç«äºåé©±æ¹æ³ã

##### **SmartSpatial: Enhancing the 3D Spatial Arrangement Capabilities of Stable Diffusion Models and Introducing a Novel 3D Spatial Evaluation Framework**
2501.01998v1 by Mao Xun Huang, Hen-Hsen Huang

Stable Diffusion models have made remarkable strides in generating
photorealistic images from text prompts but often falter when tasked with
accurately representing complex spatial arrangements, particularly involving
intricate 3D relationships. To address this limitation, we introduce
SmartSpatial, an innovative approach that enhances the spatial arrangement
capabilities of Stable Diffusion models through 3D-aware conditioning and
attention-guided mechanisms. SmartSpatial incorporates depth information and
employs cross-attention control to ensure precise object placement, delivering
notable improvements in spatial accuracy metrics. In conjunction with
SmartSpatial, we present SmartSpatialEval, a comprehensive evaluation framework
designed to assess spatial relationships. This framework utilizes
vision-language models and graph-based dependency parsing for performance
analysis. Experimental results on the COCO and SpatialPrompts datasets show
that SmartSpatial significantly outperforms existing methods, setting new
benchmarks for spatial arrangement accuracy in image generation.

æè¦ï¼Stable Diffusion æ¨¡åå¨æ ¹ææå­æç¤ºçæé¼ççå½±åæ¹é¢åå¾äºé¡¯èé²å±ï¼ä½å¨æºç¢ºåç¾è¤éçç©ºééç½®æï¼ç¹å¥æ¯æ¶åè¤éç 3D éä¿æï¼å¸¸å¸¸æå¤±æãçºäºè§£æ±ºéåéå¶ï¼æåå¼å¥äº SmartSpatialï¼éæ¯ä¸ååµæ°çæ¹æ³ï¼éé 3D æç¥æ¢ä»¶åæ³¨æåå¼å°æ©å¶ï¼å¢å¼· Stable Diffusion æ¨¡åçç©ºééç½®è½åãSmartSpatial çµåæ·±åº¦è³è¨ä¸¦æ¡ç¨äº¤åæ³¨æåæ§å¶ï¼ä»¥ç¢ºä¿ç²¾ç¢ºçç©ä»¶æ¾ç½®ï¼å¨ç©ºéæºç¢ºåº¦ææ¨æ¹é¢å¸¶ä¾é¡¯èçæ¹é²ãçµå SmartSpatialï¼æåæåºäº SmartSpatialEvalï¼éæ¯ä¸åå¨é¢çè©ä¼°æ¶æ§ï¼æ¨å¨è©ä¼°ç©ºééä¿ãéåæ¶æ§å©ç¨è¦è¦ºèªè¨æ¨¡åååºæ¼åå½¢çä¾å­åæé²è¡æè½åæãå¨ COCO å SpatialPrompts è³æéä¸çå¯¦é©çµæé¡¯ç¤ºï¼SmartSpatial æé¡¯åªæ¼ç¾ææ¹æ³ï¼çºå½±åçæçç©ºééç½®æºç¢ºåº¦è¨­å®äºæ°çåºæºã

##### **Causal Graph Guided Steering of LLM Values via Prompts and Sparse Autoencoders**
2501.00581v1 by Yipeng Kang, Junqi Wang, Yexin Li, Fangwei Zhong, Xue Feng, Mengmeng Wang, Wenming Tu, Quansen Wang, Hengli Li, Zilong Zheng

As large language models (LLMs) become increasingly integrated into critical
applications, aligning their behavior with human values presents significant
challenges. Current methods, such as Reinforcement Learning from Human Feedback
(RLHF), often focus on a limited set of values and can be resource-intensive.
Furthermore, the correlation between values has been largely overlooked and
remains underutilized. Our framework addresses this limitation by mining a
causal graph that elucidates the implicit relationships among various values
within the LLMs. Leveraging the causal graph, we implement two lightweight
mechanisms for value steering: prompt template steering and Sparse Autoencoder
feature steering, and analyze the effects of altering one value dimension on
others. Extensive experiments conducted on Gemma-2B-IT and Llama3-8B-IT
demonstrate the effectiveness and controllability of our steering methods.

æè¦ï¼é¨èå¤§åèªè¨æ¨¡å (LLM) æ¥çæ´åå°ééµæç¨ç¨å¼ä¸­ï¼è®å¶è¡çºèäººé¡å¹å¼è§ä¸è´æå¸¶ä¾éå¤§ææ°ãç¾æçæ¹æ³ï¼ä¾å¦äººé¡åé¥å¼·åå­¸ç¿ (RLHF)ï¼éå¸¸å°æ³¨æ¼æéçå¹å¼è§ï¼ä¸å¯è½èè²»å¤§éè³æºãæ­¤å¤ï¼å¹å¼è§ä¹éçéè¯æ§å¨å¾å¤§ç¨åº¦ä¸è¢«å¿½è¦ï¼ä¸æªè¢«ååå©ç¨ãæåçæ¶æ§ééæ¢åå æåè¡¨ä¾è§£æ±ºæ­¤éå¶ï¼è©²åè¡¨é¡æäº LLM ä¸­åç¨®å¹å¼è§ä¹éçé±å«éä¿ãå©ç¨å æåè¡¨ï¼æåå¯¦ä½äºå©ç¨®è¼éç´çå¹å¼å¼å°æ©å¶ï¼æç¤ºç¯æ¬å¼å°åç¨çèªç·¨ç¢¼å¨ç¹å¾µå¼å°ï¼ä¸¦åæäºæ¹è®ä¸åå¹å¼ç¶­åº¦å°å¶ä»ç¶­åº¦çå½±é¿ãå¨ Gemma-2B-IT å Llama3-8B-IT ä¸é²è¡çå»£æ³å¯¦é©è­æäºæåçå¼å°æ¹æ³çæææ§åå¯æ§æ§ã

##### **CancerKG.ORG A Web-scale, Interactive, Verifiable Knowledge Graph-LLM Hybrid for Assisting with Optimal Cancer Treatment and Care**
2501.00223v1 by Michael Gubanov, Anna Pyayt, Aleksandra Karolak

Here, we describe one of the first Web-scale hybrid Knowledge Graph
(KG)-Large Language Model (LLM), populated with the latest peer-reviewed
medical knowledge on colorectal Cancer. It is currently being evaluated to
assist with both medical research and clinical information retrieval tasks at
Moffitt Cancer Center, which is one of the top Cancer centers in the U.S. and
in the world. Our hybrid is remarkable as it serves the user needs better than
just an LLM, KG or a search-engine in isolation. LLMs as is are known to
exhibit hallucinations and catastrophic forgetting as well as are trained on
outdated corpora. The state of the art KGs, such as PrimeKG, cBioPortal,
ChEMBL, NCBI, and other require manual curation, hence are quickly getting
stale. CancerKG is unsupervised and is capable of automatically ingesting and
organizing the latest medical findings. To alleviate the LLMs shortcomings, the
verified KG serves as a Retrieval Augmented Generation (RAG) guardrail.
CancerKG exhibits 5 different advanced user interfaces, each tailored to serve
different data modalities better and more convenient for the user.

æè¦ï¼å¨æ­¤ï¼æä»¬æè¿°äºç¬¬ä¸ä¸ª Web çº§æ··åç¥è¯å¾è°± (KG) - å¤§åè¯­è¨æ¨¡å (LLM)ï¼å¶ä¸­åæ¥çæå³ç»ç´è ççææ°åè¡è¯å®¡å»å­¦ç¥è¯ãç®åæ­£å¨è¯ä¼°å®ä»¥åå© Moffitt ççä¸­å¿è¿è¡å»å­¦ç ç©¶åä¸´åºä¿¡æ¯æ£ç´¢ä»»å¡ï¼è¯¥ä¸­å¿æ¯ç¾å½åä¸çé¡¶çº§ççä¸­å¿ä¹ä¸ãæä»¬çæ··åä½éå¸¸åºè²ï¼å ä¸ºå®æ¯å­¤ç«ç LLMãKG ææç´¢å¼ææ´å¥½å°æ»¡è¶³ç¨æ·éæ±ãä¼æå¨ç¥ï¼LLM ä¼åºç°å¹»è§åç¾é¾æ§éå¿ï¼å¹¶ä¸æ¯å¨è¿æ¶çè¯­æåºä¸è¿è¡è®­ç»çãæåè¿ç KGï¼ä¾å¦ PrimeKGãcBioPortalãChEMBLãNCBI ç­éè¦äººå·¥æ´çï¼å æ­¤å¾å¿«å°±ä¼è¿æ¶ãCancerKG æ éçç£ï¼è½å¤èªå¨æååç»ç»ææ°çå»å­¦åç°ãä¸ºäºåè½» LLM çç¼ºç¹ï¼ç»è¿éªè¯ç KG åå½æ£ç´¢å¢å¼ºçæ (RAG) æ¤æ ãCancerKG å±ç¤ºäº 5 ç§ä¸åçé«çº§ç¨æ·çé¢ï¼æ¯ç§çé¢é½éå¯¹æå¡ä¸åçæ°æ®æ¨¡å¼ï¼ä¸ºç¨æ·æä¾æ´å¥½ãæ´æ¹ä¾¿çæå¡ã

##### **The Potential of LLMs in Automating Software Testing: From Generation to Reporting**
2501.00217v1 by Betim Sherifi, Khaled Slhoub, Fitzroy Nembhard

Having a high quality software is essential in software engineering, which
requires robust validation and verification processes during testing
activities. Manual testing, while effective, can be time consuming and costly,
leading to an increased demand for automated methods. Recent advancements in
Large Language Models (LLMs) have significantly influenced software
engineering, particularly in areas like requirements analysis, test automation,
and debugging. This paper explores an agent-oriented approach to automated
software testing, using LLMs to reduce human intervention and enhance testing
efficiency. The proposed framework integrates LLMs to generate unit tests,
visualize call graphs, and automate test execution and reporting. Evaluations
across multiple applications in Python and Java demonstrate the system's high
test coverage and efficient operation. This research underscores the potential
of LLM-powered agents to streamline software testing workflows while addressing
challenges in scalability and accuracy.

æè¦ï¼å¨è»é«å·¥ç¨ä¸­ï¼ææé«åè³ªçè»é«è³ééè¦ï¼ééè¦å¨æ¸¬è©¦æ´»åä¸­é²è¡å¼·å¥çé©è­åé©è­ç¨åºãæåæ¸¬è©¦éç¶ææï¼ä½å¯è½èæä¸ææ¬é«æï¼å°è´å°èªååæ¹æ³çéæ±å¢å ãå¤§åèªè¨æ¨¡å (LLM) çææ°é²å±é¡¯èå½±é¿äºè»é«å·¥ç¨ï¼ç¹å¥æ¯å¨éæ±åæãæ¸¬è©¦èªåååé¤é¯ç­é åãæ¬ææ¢è¨äºä¸ç¨®é¢åä»£ççèªååè»é«æ¸¬è©¦æ¹æ³ï¼ä½¿ç¨ LLM ä¾æ¸å°äººå·¥å¹²é ä¸¦æé«æ¸¬è©¦æçãææåºçæ¡æ¶æ´åäº LLM ä¾ç¢çå®åæ¸¬è©¦ãè¦è¦ºåå¼å«åè¡¨ä»¥åèªååæ¸¬è©¦å·è¡åå ±åãå¨ Python å Java ä¸­çè·¨å¤åæç¨ç¨å¼çè©ä¼°è­æäºç³»çµ±çé«æ¸¬è©¦è¦èçåé«æéä½ãéé ç ç©¶å¼·èª¿äº LLM é©åçä»£çå¨ç°¡åè»é«æ¸¬è©¦å·¥ä½æµç¨æ¹é¢çæ½åï¼åææå°å¯æ´åæ§åæºç¢ºæ§æ¹é¢çææ°ã

##### **Detection-Fusion for Knowledge Graph Extraction from Videos**
2501.00136v1 by Taniya Das, Louis Mahon, Thomas Lukasiewicz

One of the challenging tasks in the field of video understanding is
extracting semantic content from video inputs. Most existing systems use
language models to describe videos in natural language sentences, but this has
several major shortcomings. Such systems can rely too heavily on the language
model component and base their output on statistical regularities in natural
language text rather than on the visual contents of the video. Additionally,
natural language annotations cannot be readily processed by a computer, are
difficult to evaluate with performance metrics and cannot be easily translated
into a different natural language. In this paper, we propose a method to
annotate videos with knowledge graphs, and so avoid these problems.
Specifically, we propose a deep-learning-based model for this task that first
predicts pairs of individuals and then the relations between them.
Additionally, we propose an extension of our model for the inclusion of
background knowledge in the construction of knowledge graphs.

æè¦ï¼å½±ççè§£é åä¸­ä¸é å·æææ°æ§çä»»åï¼æ¯å¾å½±çè¼¸å¥ä¸­èåèªæå§å®¹ãç¾æçå¤§é¨åç³»çµ±ä½¿ç¨èªè¨æ¨¡åä»¥èªç¶èªè¨å¥å­æè¿°å½±çï¼ä½éæå¹¾åä¸»è¦çç¼ºé»ãæ­¤é¡ç³»çµ±å¯è½éåº¦ä¾è³´èªè¨æ¨¡åçµä»¶ï¼ä¸¦æ ¹æèªç¶èªè¨æå­ä¸­ççµ±è¨è¦å¾ï¼èéå½±ççè¦è¦ºå§å®¹ï¼ä¾å»ºæ§å¶è¼¸åºãæ­¤å¤ï¼èªç¶èªè¨è¨»è§£ç¡æ³è¼æå°ç±é»è¦èçï¼é£ä»¥ä½¿ç¨æè½ææ¨é²è¡è©ä¼°ï¼ä¸ç¡æ³è¼æç¿»è­¯æä¸åçèªç¶èªè¨ãå¨æ¬æä¸­ï¼æåæåºä¸åä½¿ç¨ç¥è­åè¡¨çºå½±çå ä¸è¨»è§£çæ¹æ³ï¼ä¸¦èæ­¤é¿åéäºåé¡ãå·é«ä¾èªªï¼æåæåºä¸ååºæ¼æ·±åº¦å­¸ç¿çæ¨¡åä¾å·è¡éé ä»»åï¼å®æåé æ¸¬åé«å°ï¼ç¶å¾åé æ¸¬åé«ä¹éçéä¿ãæ­¤å¤ï¼æåæåºä¸åæ¨¡åå»¶ä¼¸ï¼ä»¥å°èæ¯ç¥è­ç´å¥ç¥è­åè¡¨çå»ºæ§ä¸­ã

##### **Machine Learning-Based Security Policy Analysis**
2501.00085v2 by Krish Jain, Joann Sum, Pranav Kapoor, Amir Eaman

Security-Enhanced Linux (SELinux) is a robust security mechanism that
enforces mandatory access controls (MAC), but its policy language's complexity
creates challenges for policy analysis and management. This research
investigates the automation of SELinux policy analysis using graph-based
techniques combined with machine learning approaches to detect policy
anomalies. The study addresses two key questions: Can SELinux policy analysis
be automated through graph analysis, and how do different anomaly detection
models compare in analyzing SELinux policies? We will be comparing different
machine learning models by evaluating their effectiveness in detecting policy
violations and anomalies. Our approach utilizes Neo4j for graph representation
of policies, with Node2vec transforming these graph structures into meaningful
vector embeddings that can be processed by our machine learning models. In our
results, the MLP Neural Network consistently demonstrated superior performance
across different dataset sizes, achieving 95% accuracy with balanced precision
and recall metrics, while both Random Forest and SVM models showed competitive
but slightly lower performance in detecting policy violations. This combination
of graph-based modeling and machine learning provides a more sophisticated and
automated approach to understanding and analyzing complex SELinux policies
compared to traditional manual analysis methods.

æè¦ï¼SELinuxï¼å®å¨å¼·åå Linuxï¼æ¯ä¸ç¨®å¼·å¤§çå®å¨æ©å¶ï¼å®å¼·å¶å·è¡å¼·å¶è¨ªåæ§å¶ (MAC)ï¼ä½å¶æ¿ç­èªè¨çè¤éæ§å°æ¿ç­åæåç®¡çæåºäºææ°ãæ¬ç ç©¶æ¢è¨äºä½¿ç¨åºæ¼åå½¢æè¡çµåæ©å¨å­¸ç¿æ¹æ³ä¾èªåå SELinux æ¿ç­åæï¼ä»¥æª¢æ¸¬æ¿ç­ç°å¸¸ãæ¬ç ç©¶è§£æ±ºäºå©åééµåé¡ï¼æ¯å¦è½ééåå½¢åæèªåå SELinux æ¿ç­åæï¼ä»¥åä¸åçç°å¸¸æª¢æ¸¬æ¨¡åå¨åæ SELinux æ¿ç­ææä½æ¯è¼ï¼æåå°æ¯è¼ä¸åçæ©å¨å­¸ç¿æ¨¡åï¼è©ä¼°å®åå¨æª¢æ¸¬æ¿ç­éè¦åç°å¸¸æ¹é¢çæææ§ãæåçåæ³å©ç¨ Neo4j é²è¡æ¿ç­çåå½¢è¡¨ç¤ºï¼Node2vec å°éäºåå½¢çµæ§è½ææææç¾©çåéåµå¥ï¼æåçæ©å¨å­¸ç¿æ¨¡åå¯ä»¥èçéäºåµå¥ãå¨æåççµæä¸­ï¼MLP ç¥ç¶ç¶²è·¯å¨ä¸åçè³æéå¤§å°ä¸­å§çµè¡¨ç¾åºåªç°çæè½ï¼å¨å¹³è¡¡çæºç¢ºåº¦ãç²¾ç¢ºåº¦åå¬åçææ¨ä¸éå° 95% çæºç¢ºåº¦ï¼èé¨æ©æ£®æå SVM æ¨¡åå¨æª¢æ¸¬æ¿ç­éè¦æ¹é¢è¡¨ç¾åºç«¶ç­åï¼ä½æè½ç¥ä½ãéç¨®åºæ¼åå½¢å»ºæ¨¡åæ©å¨å­¸ç¿ççµåæä¾äºä¸åæ´ç²¾ç·»ä¸èªååçæ¹å¼ï¼èå³çµ±çæååææ¹æ³ç¸æ¯ï¼å¯ä»¥çè§£ååæè¤éç SELinux æ¿ç­ã

##### **KARPA: A Training-free Method of Adapting Knowledge Graph as References for Large Language Model's Reasoning Path Aggregation**
2412.20995v1 by Siyuan Fang, Kaijing Ma, Tianyu Zheng, Xinrun Du, Ningxuan Lu, Ge Zhang, Qingkun Tang

Large language models (LLMs) demonstrate exceptional performance across a
variety of tasks, yet they are often affected by hallucinations and the
timeliness of knowledge. Leveraging knowledge graphs (KGs) as external
knowledge sources has emerged as a viable solution, but existing methods for
LLM-based knowledge graph question answering (KGQA) are often limited by
step-by-step decision-making on KGs, restricting the global planning and
reasoning capabilities of LLMs, or they require fine-tuning or pre-training on
specific KGs. To address these challenges, we propose Knowledge graph Assisted
Reasoning Path Aggregation (KARPA), a novel framework that harnesses the global
planning abilities of LLMs for efficient and accurate KG reasoning. KARPA
operates in three steps: pre-planning relation paths using the LLM's global
planning capabilities, matching semantically relevant paths via an embedding
model, and reasoning over these paths to generate answers. Unlike existing KGQA
methods, KARPA avoids stepwise traversal, requires no additional training, and
is adaptable to various LLM architectures. Extensive experimental results show
that KARPA achieves state-of-the-art performance in KGQA tasks, delivering both
high efficiency and accuracy. Our code will be available on Github.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å¨åç¨®ä»»åä¸­è¡¨ç¾åºè²çè¡¨ç¾ï¼ä½å®åç¶å¸¸åå°å¹»è¦ºåç¥è­æææ§çå½±é¿ãå©ç¨ç¥è­åè­ (KG) ä½çºå¤é¨ç¥è­ä¾æºå·²æçºä¸åå¯è¡çè§£æ±ºæ¹æ¡ï¼ä½ç¾æç LLM åºæ¼ç¥è­åè­åç­ (KGQA) çæ¹æ³éå¸¸åå° KG ä¸éæ­¥æ±ºç­çéå¶ï¼éå¶äº LLM çå¨å±è¦ååæ¨çè½åï¼æèå®åéè¦éå°ç¹å® KG é²è¡å¾®èª¿æé è¨ç·´ãçºäºæå°éäºææ°ï¼æåæåºäºç¥è­åè­è¼å©æ¨çè·¯å¾èå (KARPA)ï¼éæ¯ä¸åæ°ç©çæ¡æ¶ï¼å©ç¨ LLM çå¨å±è¦åè½åé²è¡é«æä¸æºç¢ºç KG æ¨çãKARPA åä¸æ­¥æä½ï¼ä½¿ç¨ LLM çå¨å±è¦åè½åé åè¦åéä¿è·¯å¾ãééåµå¥æ¨¡åå¹éèªç¾©ç¸éè·¯å¾ï¼ä»¥åæ¨çéäºè·¯å¾ä»¥ç¢çç­æ¡ãèç¾æç KGQA æ¹æ³ä¸åï¼KARPA é¿åéæ­¥éæ­·ï¼ä¸éè¦é¡å¤çè¨ç·´ï¼ä¸¦ä¸å¯ä»¥é©æåç¨® LLM æ¶æ§ãå¤§éçå¯¦é©çµæè¡¨æï¼KARPA å¨ KGQA ä»»åä¸­å¯¦ç¾äºæåé²çæ§è½ï¼æ¢æä¾äºé«æçåæä¾äºé«æºç¢ºåº¦ãæåçç¨å¼ç¢¼å°å¨ Github ä¸æä¾ã

##### **Ontology-grounded Automatic Knowledge Graph Construction by LLM under Wikidata schema**
2412.20942v1 by Xiaohan Feng, Xixin Wu, Helen Meng

We propose an ontology-grounded approach to Knowledge Graph (KG) construction
using Large Language Models (LLMs) on a knowledge base. An ontology is authored
by generating Competency Questions (CQ) on knowledge base to discover knowledge
scope, extracting relations from CQs, and attempt to replace equivalent
relations by their counterpart in Wikidata. To ensure consistency and
interpretability in the resulting KG, we ground generation of KG with the
authored ontology based on extracted relations. Evaluation on benchmark
datasets demonstrates competitive performance in knowledge graph construction
task. Our work presents a promising direction for scalable KG construction
pipeline with minimal human intervention, that yields high quality and
human-interpretable KGs, which are interoperable with Wikidata semantics for
potential knowledge base expansion.

æè¦ï¼æåæåºä¸åä»¥æ¬ä½çºåºç¤çæ¹æ³ä¾å»ºæ§ç¥è­åè­ï¼KGï¼ï¼æ¹æ³æ¯ä½¿ç¨å¤§åèªè¨æ¨¡åï¼LLMï¼å¨ç¥è­åº«ä¸ãæ¬ä½æ¯ç±å¨ç¥è­åº«ä¸ç¢çè½ååé¡ï¼CQï¼ä¾ç¼ç¾ç¥è­ç¯åï¼å¾ CQ ä¸­æåéä¿ï¼ä¸¦åè©¦ç¨ Wikidata ä¸­çå°æéä¿æ¿æç­æéä¿èç·¨å¯«çãçºäºç¢ºä¿çµæ KG çä¸è´æ§åå¯è§£éæ§ï¼æåæ ¹ææåçéä¿ï¼ä»¥ç·¨å¯«çæ¬ä½çºåºç¤ä¾å»ºç« KG çç¢çãå¨åºæºè³æéä¸çè©ä¼°é¡¯ç¤ºå¨ç¥è­åè­å»ºæ§ä»»åä¸­æç«¶ç­åçæè½ãæåçç ç©¶æåºäºä¸åæå¸æçæ¹åï¼å¯ä»¥ééæ¥µå°çäººå·¥ä»å¥ä¾å»ºæ§å¯æ´åç KG ç®¡ç·ï¼ç¢çé«åè³ªä¸äººé¡å¯è§£éç KGï¼éäº KG è Wikidata èªç¾©å¯ä»¥äºéï¼ä»¥æ´åæ½å¨çç¥è­åº«ã

##### **ICLR: In-Context Learning of Representations**
2501.00070v1 by Core Francisco Park, Andrew Lee, Ekdeep Singh Lubana, Yongyi Yang, Maya Okawa, Kento Nishi, Martin Wattenberg, Hidenori Tanaka

Recent work has demonstrated that semantics specified by pretraining data
influence how representations of different concepts are organized in a large
language model (LLM). However, given the open-ended nature of LLMs, e.g., their
ability to in-context learn, we can ask whether models alter these pretraining
semantics to adopt alternative, context-specified ones. Specifically, if we
provide in-context exemplars wherein a concept plays a different role than what
the pretraining data suggests, do models reorganize their representations in
accordance with these novel semantics? To answer this question, we take
inspiration from the theory of conceptual role semantics and define a toy
"graph tracing" task wherein the nodes of the graph are referenced via concepts
seen during training (e.g., apple, bird, etc.) and the connectivity of the
graph is defined via some predefined structure (e.g., a square grid). Given
exemplars that indicate traces of random walks on the graph, we analyze
intermediate representations of the model and find that as the amount of
context is scaled, there is a sudden re-organization from pretrained semantic
representations to in-context representations aligned with the graph structure.
Further, we find that when reference concepts have correlations in their
semantics (e.g., Monday, Tuesday, etc.), the context-specified graph structure
is still present in the representations, but is unable to dominate the
pretrained structure. To explain these results, we analogize our task to energy
minimization for a predefined graph topology, providing evidence towards an
implicit optimization process to infer context-specified semantics. Overall,
our findings indicate scaling context-size can flexibly re-organize model
representations, possibly unlocking novel capabilities.

æè¦ï¼<paragraph>æè¿çç ç©¶è¡¨æï¼ç±é¢è®­ç»æ°æ®æå®çè¯­ä¹ä¼å½±åå¤§åè¯­è¨æ¨¡å (LLM) ä¸­ä¸åæ¦å¿µçè¡¨å¾ç»ç»æ¹å¼ãç¶èï¼é´äº LLM çå¼æ¾å¼æ¬è´¨ï¼ä¾å¦å®ä»¬å¨è¯­å¢ä¸­å­¦ä¹ çè½åï¼æä»¬å¯ä»¥è¯¢é®æ¨¡åæ¯å¦ä¼æ¹åè¿äºé¢è®­ç»è¯­ä¹ä»¥éç¨æ¿ä»£çãè¯­å¢æå®çè¯­ä¹ãå·ä½æ¥è¯´ï¼å¦ææä»¬å¨è¯­å¢ä¸­æä¾ç¤ºä¾ï¼å¶ä¸­ä¸ä¸ªæ¦å¿µæ®æ¼çè§è²ä¸é¢è®­ç»æ°æ®ææç¤ºçä¸åï¼æ¨¡åæ¯å¦ä¼æ ¹æ®è¿äºæ°è¯­ä¹éæ°ç»ç»å®ä»¬çè¡¨å¾ï¼ä¸ºäºåç­è¿ä¸ªé®é¢ï¼æä»¬ä»æ¦å¿µè§è²è¯­ä¹çè®ºä¸­æ±²åçµæï¼å¹¶å®ä¹äºä¸ä¸ªç©å·âå¾ç¤ºè¿½è¸ªâä»»å¡ï¼å¶ä¸­å¾çèç¹éè¿è®­ç»æé´çå°çæ¦å¿µï¼ä¾å¦ï¼è¹æãé¸ç­ï¼è¿è¡å¼ç¨ï¼å¹¶ä¸å¾çè¿éæ§æ¯éè¿ä¸äºé¢å®ä¹çç»æï¼ä¾å¦ï¼æ­£æ¹å½¢ç½æ ¼ï¼å®ä¹çãç»å®æç¤ºå¨å¾ä¸éæºæ¸¸èµ°çè½¨è¿¹çç¤ºä¾ï¼æä»¬åæäºæ¨¡åçä¸­é´è¡¨å¾ï¼åç°éçè¯­å¢éçå¢å ï¼ä»é¢è®­ç»è¯­ä¹è¡¨å¾å°ä¸å¾ç»æå¯¹é½çè¯­å¢è¡¨å¾çªç¶åçäºéæ°ç»ç»ãæ­¤å¤ï¼æä»¬åç°å½åèæ¦å¿µå¨å¶è¯­ä¹ä¸­å·æç¸å³æ§ï¼ä¾å¦ï¼ææä¸ãææäºç­ï¼æ¶ï¼è¯­å¢æå®çå¾ç»æä»ç¶å­å¨äºè¡¨å¾ä¸­ï¼ä½æ æ³æ¯éé¢è®­ç»ç»æãä¸ºäºè§£éè¿äºç»æï¼æä»¬å°æä»¬çä»»å¡ç±»æ¯ä¸ºé¢å®ä¹å¾ææçè½éæå°åï¼ä¸ºæ¨æ­è¯­å¢æå®è¯­ä¹çéå¼ä¼åè¿ç¨æä¾äºè¯æ®ãæ»ä½èè¨ï¼æä»¬çç ç©¶ç»æè¡¨æï¼æ©å±è¯­å¢å¤§å°å¯ä»¥çµæ´»å°éæ°ç»ç»æ¨¡åè¡¨å¾ï¼æå¯è½è§£éæ°çåè½ã</paragraph>

##### **Topic-Aware Knowledge Graph with Large Language Models for Interoperability in Recommender Systems**
2412.20163v2 by Minhye Jeon, Seokho Ahn, Young-Duk Seo

The use of knowledge graphs in recommender systems has become one of the
common approaches to addressing data sparsity and cold start problems. Recent
advances in large language models (LLMs) offer new possibilities for processing
side and context information within knowledge graphs. However, consistent
integration across various systems remains challenging due to the need for
domain expert intervention and differences in system characteristics. To
address these issues, we propose a consistent approach that extracts both
general and specific topics from both side and context information using LLMs.
First, general topics are iteratively extracted and updated from side
information. Then, specific topics are extracted using context information.
Finally, to address synonymous topics generated during the specific topic
extraction process, a refining algorithm processes and resolves these issues
effectively. This approach allows general topics to capture broad knowledge
across diverse item characteristics, while specific topics emphasize detailed
attributes, providing a more comprehensive understanding of the semantic
features of items and the preferences of users. Experimental results
demonstrate significant improvements in recommendation performance across
diverse knowledge graphs.

æè¦ï¼ç¥è­åè­å¨æ¨è¦ç³»çµ±ä¸­çä½¿ç¨å·²æçºè§£æ±ºè³æç¨çæ§åå·åååé¡çå¸¸è¦æ¹æ³ä¹ä¸ãå¤§åèªè¨æ¨¡å (LLM) çææ°é²å±çºèçç¥è­åè­ä¸­çå´éåèæ¯è³è¨æä¾äºæ°çå¯è½æ§ãç¶èï¼ç±æ¼éè¦é åå°å®¶çä»å¥ä»¥åç³»çµ±ç¹æ§çå·®ç°ï¼è·¨åç¨®ç³»çµ±çä¸è´æ´åä»ç¶å·æææ°æ§ãçºäºè§£æ±ºéäºåé¡ï¼æåæåºäºä¸ç¨®ä¸è´çæ¹æ³ï¼å®ä½¿ç¨ LLM å¾å´éåèæ¯è³è¨ä¸­æåä¸è¬åç¹å®ä¸»é¡ãé¦åï¼å¾å´éè³è¨ä¸­åè¦æååæ´æ°ä¸è¬ä¸»é¡ãç¶å¾ï¼ä½¿ç¨èæ¯è³è¨æåç¹å®ä¸»é¡ãæå¾ï¼çºäºèçå¨ç¹å®ä¸»é¡æåéç¨ä¸­ç¢ççåç¾©ä¸»é¡ï¼ä¸ç¨®ç²¾çæ¼ç®æ³ææå°èçä¸¦è§£æ±ºäºéäºåé¡ãéç¨®æ¹æ³åè¨±ä¸è¬ä¸»é¡æ·ååç¨®é ç®ç¹æ§çå»£æ³ç¥è­ï¼èç¹å®ä¸»é¡åå¼·èª¿è©³ç´°å±¬æ§ï¼å¾èæ´å¨é¢å°äºè§£é ç®çèªç¾©ç¹å¾µåä½¿ç¨èçåå¥½ãå¯¦é©çµæè¡¨æï¼å¨åç¨®ç¥è­åè­ä¸­ï¼æ¨è¦æè½é½æé¡¯èçæåã

##### **From Generalist to Specialist: A Survey of Large Language Models for Chemistry**
2412.19994v1 by Yang Han, Ziping Wan, Lu Chen, Kai Yu, Xin Chen

Large Language Models (LLMs) have significantly transformed our daily life
and established a new paradigm in natural language processing (NLP). However,
the predominant pretraining of LLMs on extensive web-based texts remains
insufficient for advanced scientific discovery, particularly in chemistry. The
scarcity of specialized chemistry data, coupled with the complexity of
multi-modal data such as 2D graph, 3D structure and spectrum, present distinct
challenges. Although several studies have reviewed Pretrained Language Models
(PLMs) in chemistry, there is a conspicuous absence of a systematic survey
specifically focused on chemistry-oriented LLMs. In this paper, we outline
methodologies for incorporating domain-specific chemistry knowledge and
multi-modal information into LLMs, we also conceptualize chemistry LLMs as
agents using chemistry tools and investigate their potential to accelerate
scientific research. Additionally, we conclude the existing benchmarks to
evaluate chemistry ability of LLMs. Finally, we critically examine the current
challenges and identify promising directions for future research. Through this
comprehensive survey, we aim to assist researchers in staying at the forefront
of developments in chemistry LLMs and to inspire innovative applications in the
field.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å·²é¡¯èæ¹è®æåçæ¥å¸¸çæ´»ï¼ä¸¦å¨èªç¶èªè¨èç (NLP) ä¸­å»ºç«äºä¸åæ°çå¸ç¯ãç¶èï¼LLM å¨å»£æ³çåºæ¼ç¶²è·¯çææ¬ä¸é²è¡ççè¡é è¨ç·´å°æ¼åé²çç§å­¸ç¼ç¾ä»ç¶ä¸è¶³ï¼ç¹å¥æ¯å¨åå­¸é åãå°æ¥­åå­¸æ¸æçç¨ç¼ºï¼å ä¸ 2D åå½¢ã3D çµæ§ååè­ç­å¤æ¨¡ææ¸æçè¤éæ§ï¼æåºäºä¸åçææ°ãåç®¡ä¸äºç ç©¶åé¡§äºåå­¸ä¸­çé è¨ç·´èªè¨æ¨¡å (PLM)ï¼ä½é¡¯èç¼ºä¹å°æ³¨æ¼ä»¥åå­¸çºå°åç LLM çç³»çµ±æ§èª¿æ¥ãå¨æ¬æä¸­ï¼æåæ¦è¿°äºå°ç¹å®é åçåå­¸ç¥è­åå¤æ¨¡æè³è¨ç´å¥ LLM çæ¹æ³ï¼æåéå°åå­¸ LLM æ¦å¿µåçºä½¿ç¨åå­¸å·¥å·çä»£çï¼ä¸¦ç ç©¶å®åå éç§å­¸ç ç©¶çæ½åãæ­¤å¤ï¼æåç¸½çµäºç¾æçåºæºä¾è©ä¼° LLM çåå­¸è½åãæå¾ï¼æåæ¹å¤æ§å°å¯©æ¥äºç¶åçææ°ï¼ä¸¦ç¢ºå®äºæªä¾ç ç©¶çæå¸æçæ¹åãéééé å¨é¢çèª¿æ¥ï¼æåæ¨å¨åå©ç ç©¶äººå¡ææ¡åå­¸ LLM ç¼å±çæåæ²¿ï¼ä¸¦æ¿ç¼è©²é åçåµæ°æç¨ã

##### **Toward Adaptive Reasoning in Large Language Models with Thought Rollback**
2412.19707v1 by Sijia Chen, Baochun Li

Large language models (LLMs) have been routinely used to solve various tasks
using step-by-step reasoning. However, the structure of intermediate reasoning
steps, or thoughts, is rigid and unidirectional, such as chains, trees, or
acyclic-directed graphs. Consequently, the resulting inflexible and
forward-only reasoning may not address challenging tasks and fail when the LLM
frequently gives false responses, i.e., ``hallucinations''. This paper proposes
a new reasoning framework, called Thought Rollback (TR), allowing LLMs to
adaptively build thought structure while maintaining effective reasoning toward
problem-solving under ``hallucinations''. The core mechanism of TR is rolling
back thoughts, which allows LLMs to perform error analysis on thoughts, and
thus roll back to any previously mistaken thought for revision. Subsequently,
by including such trial-and-error in the prompt to guide the LLM, each rollback
leads to one more reliable reasoning path. Therefore, starting with a simple
prompt without human annotations, LLM with TR adaptively and gradually explores
thoughts for a correct solution. Comprehensive experiments on mathematical
problems and multi-task reasoning demonstrate the state-of-the-art performance
of TR in terms of problem-solving rate and interaction cost. For instance, the
solving rate of GPT-4 with TR outperforms the current best by $9\%$ on the MATH
dataset.

æè¦ï¼å¤§åèªè¨æ¨¡åï¼LLMï¼å·²å¸¸è¦ç¨æ¼è§£æ±ºåç¨®ä»»åï¼ä½¿ç¨éæ­¥æ¨çãç¶èï¼ä¸­éæ¨çæ­¥é©ææ³æ³ççµæ§æ¯åµåä¸å®åçï¼ä¾å¦éãæ¨¹æç¡ç°æååãå æ­¤ï¼ç¢ççåµåä¸åååæ¨çå¯è½ç¡æ³è§£æ±ºå·æææ°æ§çä»»åï¼ä¸¦ä¸ç¶ LLM é »ç¹çµ¦åºé¯èª¤çåæï¼å³ãå¹»è¦ºãï¼ææå¤±æãæ¬ææåºäºä¸åæ°çæ¨çæ¡æ¶ï¼ç¨±çº Thought Rollbackï¼TRï¼ï¼åè¨± LLM å¨è§£æ±ºãå¹»è¦ºãåé¡æèªé©æå°æ§å»ºææ³çµæ§ï¼åæä¿æææçæ¨çãTR çæ ¸å¿æ©å¶æ¯åæ»¾ææ³ï¼å®åè¨± LLM å°ææ³å·è¡é¯èª¤åæï¼ä¸¦å æ­¤åæ»¾å°ä»»ä½ååé¯èª¤çææ³é²è¡ä¿®æ¹ãé¨å¾ï¼ééå¨æç¤ºä¸­åå«æ­¤é¡è©¦é¯ä¾æå° LLMï¼æ¯æ¬¡åæ»¾é½æå°è´ä¸æ¢æ´å¯é çæ¨çè·¯å¾ãå æ­¤ï¼å¾ä¸åæ²æäººå·¥è¨»éçç°¡å®æç¤ºéå§ï¼å¸¶æ TR ç LLM èªé©æå°éæ¼¸æ¢ç´¢ææ³ä»¥ç²å¾æ­£ç¢ºçè§£æ±ºæ¹æ¡ãå¨æ¸å­¸åé¡åå¤ä»»åæ¨çä¸çç¶åå¯¦é©è­æäº TR å¨åé¡è§£æ±ºçåäº¤äºææ¬æ¹é¢çæåé²æ§è½ãä¾å¦ï¼å¸¶æ TR ç GPT-4 çæ±è§£çå¨ MATH æ¸æéä¸æ¯ç®åçæä½³æ§è½é«åº 9%ã

##### **Dynamic Skill Adaptation for Large Language Models**
2412.19361v1 by Jiaao Chen, Diyi Yang

We present Dynamic Skill Adaptation (DSA), an adaptive and dynamic framework
to adapt novel and complex skills to Large Language Models (LLMs). Compared
with previous work which learns from human-curated and static data in random
orders, we propose to first automatically generate and organize the training
data by mimicking the learning pathways of human and then dynamically tailor
the training data based on the training dynamics. Specifically, inspired by the
learning structures and teaching strategies in the human education system, we
first construct a skill graph by decomposing complex skills into sub-skills and
arranging them based on their dependencies in human syllables. For every skill,
we utilize LLMs to generate both textbook-like data which contains detailed
descriptions of skills for pre-training and exercise-like data which targets at
explicitly utilizing the skills to solve problems for instruction-tuning.
Furthermore, during the instruction-tuning, we dynamically update the training
data which down-weight easy-to-learn examples, generate more complex examples,
and filter out data with errors. Experiments on large language models such as
LLAMA and Mistral demonstrate the effectiveness of our proposed methods in
adapting math reasoning skills and social study skills.

æè¦ï¼æåæåºåææè½é©æ (DSA)ï¼ä¸ç¨®é©ææ§ååææ¡æ¶ï¼ç¨æ¼å°æ°ç©ä¸è¤éçæè½é©æå°å¤§åèªè¨æ¨¡å (LLM)ãèååå¾äººé¡ç­ååéæè³æä¸­ä»¥é¨æ©é åºå­¸ç¿çå·¥ä½ç¸æ¯ï¼æåå»ºè­°é¦åééæ¨¡æ¬äººé¡çå­¸ç¿è·¯å¾èªåç¢çåçµç¹è¨ç·´è³æï¼ç¶å¾æ ¹æè¨ç·´åæåæèª¿æ´è¨ç·´è³æãå·é«ä¾èªªï¼åå°äººé¡æè²ç³»çµ±ä¸­çå­¸ç¿çµæ§åæå­¸ç­ç¥çåç¼ï¼æåé¦åééå°è¤éæè½åè§£æå­æè½ä¸¦æ ¹æå®åå¨äººé¡é³ç¯ä¸­çä¾è³´æ§ä¾æåå®åä¾æ§å»ºæè½åãå°æ¼æ¯é æè½ï¼æåå©ç¨ LLM ç¢çé¡ä¼¼æç§æ¸çè³æï¼å¶ä¸­åå«æè½çè©³ç´°æè¿°ï¼ç¨æ¼é è¨ç·´åç·´ç¿é¡åçè³æï¼å¶ç®æ¨æ¯æç¢ºå©ç¨æè½è§£æ±ºåé¡ï¼ä»¥é²è¡æä»¤èª¿æ´ãæ­¤å¤ï¼å¨æä»¤èª¿æ´æéï¼æåæåææ´æ°è¨ç·´è³æï¼å¶ä¸­æéä½ææ¼å­¸ç¿ç¯ä¾çæ¬éãç¢çæ´è¤éçç¯ä¾ï¼ä¸¦éæ¿¾ææé¯èª¤çè³æãå¨ LLAMA å Mistral ç­å¤§åèªè¨æ¨¡åä¸é²è¡çå¯¦é©è­æäºæåæåºçæ¹æ³å¨é©ææ¸å­¸æ¨çæè½åç¤¾æç ç©¶æè½æ¹é¢çæææ§ã

##### **Relation-aware Hierarchical Prompt for Open-vocabulary Scene Graph Generation**
2412.19021v1 by Tao Liu, Rongjie Li, Chongyu Wang, Xuming He

Open-vocabulary Scene Graph Generation (OV-SGG) overcomes the limitations of
the closed-set assumption by aligning visual relationship representations with
open-vocabulary textual representations. This enables the identification of
novel visual relationships, making it applicable to real-world scenarios with
diverse relationships. However, existing OV-SGG methods are constrained by
fixed text representations, limiting diversity and accuracy in image-text
alignment. To address these challenges, we propose the Relation-Aware
Hierarchical Prompting (RAHP) framework, which enhances text representation by
integrating subject-object and region-specific relation information. Our
approach utilizes entity clustering to address the complexity of relation
triplet categories, enabling the effective integration of subject-object
information. Additionally, we utilize a large language model (LLM) to generate
detailed region-aware prompts, capturing fine-grained visual interactions and
improving alignment between visual and textual modalities. RAHP also introduces
a dynamic selection mechanism within Vision-Language Models (VLMs), which
adaptively selects relevant text prompts based on the visual content, reducing
noise from irrelevant prompts. Extensive experiments on the Visual Genome and
Open Images v6 datasets demonstrate that our framework consistently achieves
state-of-the-art performance, demonstrating its effectiveness in addressing the
challenges of open-vocabulary scene graph generation.

æè¦ï¼éæ¾è©å½å ´æ¯åçæ (OV-SGG) åæäºå°éå¼åè¨­çéå¶ï¼ééå°è¦è¦ºéä¿è¡¨å¾µèéæ¾è©å½ææ¬è¡¨å¾µå°é½ãéä½¿å¾è½å¤ è­å¥æ°çè¦è¦ºéä¿ï¼ä½¿å¶é©ç¨æ¼å·æå¤æ¨£åéä¿ççå¯¦ä¸çå ´æ¯ãç¶èï¼ç¾æç OV-SGG æ¹æ³åå°åºå®ææ¬è¡¨å¾µçéå¶ï¼éå¶äºååææ¬å°é½çå¤æ¨£æ§åæºç¢ºæ§ãçºäºæå°éäºææ°ï¼æåæåºäºéä¿æç¥éå±¤å¼æç¤º (RAHP) æ¶æ§ï¼ééæ´åä¸»é«å®¢é«åç¹å®ååçéä¿è³è¨ä¾å¢å¼·ææ¬è¡¨å¾µãæåçåæ³å©ç¨å¯¦é«èé¡ä¾è§£æ±ºéä¿ä¸åçµé¡å¥çè¤éæ§ï¼ä½¿ä¸»é«å®¢é«è³è¨è½å¤ æææ´åãæ­¤å¤ï¼æåå©ç¨å¤§åèªè¨æ¨¡å (LLM) ä¾ç¢çè©³ç´°çååæç¥æç¤ºï¼ææç´°å¾®çè¦è¦ºäºåä¸¦æ¹åè¦è¦ºåææ¬æ¨¡å¼ä¹éçå°é½ãRAHP ä¹å¨è¦è¦ºèªè¨æ¨¡å (VLM) ä¸­å¼å¥äºåæé¸ææ©å¶ï¼æ ¹æè¦è¦ºå§å®¹èªé©æå°é¸æç¸éææ¬æç¤ºï¼æ¸å°ä¸ç¸éæç¤ºçéè¨ãå¨ Visual Genome å Open Images v6 è³æéä¸çå¤§éå¯¦é©è­æï¼æåçæ¶æ§æçºéææåé²çæè½ï¼è­æå¶å¨è§£æ±ºéæ¾è©å½å ´æ¯åçæçææ°ä¸å·ææè½ã

##### **PhyloGen: Language Model-Enhanced Phylogenetic Inference via Graph Structure Generation**
2412.18827v1 by ChenRui Duan, Zelin Zang, Siyuan Li, Yongjie Xu, Stan Z. Li

Phylogenetic trees elucidate evolutionary relationships among species, but
phylogenetic inference remains challenging due to the complexity of combining
continuous (branch lengths) and discrete parameters (tree topology).
Traditional Markov Chain Monte Carlo methods face slow convergence and
computational burdens. Existing Variational Inference methods, which require
pre-generated topologies and typically treat tree structures and branch lengths
independently, may overlook critical sequence features, limiting their accuracy
and flexibility. We propose PhyloGen, a novel method leveraging a pre-trained
genomic language model to generate and optimize phylogenetic trees without
dependence on evolutionary models or aligned sequence constraints. PhyloGen
views phylogenetic inference as a conditionally constrained tree structure
generation problem, jointly optimizing tree topology and branch lengths through
three core modules: (i) Feature Extraction, (ii) PhyloTree Construction, and
(iii) PhyloTree Structure Modeling. Meanwhile, we introduce a Scoring Function
to guide the model towards a more stable gradient descent. We demonstrate the
effectiveness and robustness of PhyloGen on eight real-world benchmark
datasets. Visualization results confirm PhyloGen provides deeper insights into
phylogenetic relationships.

æè¦ï¼ç³»çµ±ç¼çæ¨¹é¡æäºç©ç¨®ä¹éçæ¼åéä¿ï¼ä½ç±æ¼é£çºåæ¸ï¼åæ¯é·åº¦ï¼åé¢æ£åæ¸ï¼æ¨¹å½¢çµæ§ï¼çµåçè¤éæ§ï¼ç³»çµ±ç¼çæ¨è«ä»ç¶å·æææ°æ§ãå³çµ±çé¦¬å¯å¤«éèç¹å¡ç¾æ¹æ³é¢è¨æ¶æéåº¦æ¢åè¨ç®è² æéãç¾æçè®åæ¨è«æ¹æ³éè¦é åç¢ççææ²çµæ§ï¼ä¸¦ä¸éå¸¸ç¨ç«èçæ¨¹å½¢çµæ§ååæ¯é·åº¦ï¼å¯è½æå¿½ç¥ééµçåºåç¹å¾µï¼å¾èéå¶å¶æºç¢ºæ§åéæ´»æ§ãæåæåºäº PhyloGenï¼éæ¯ä¸ç¨®æ°ç©çæ¹æ³ï¼å©ç¨é è¨ç·´çåºå çµèªè¨æ¨¡åä¾çæååªåç³»çµ±ç¼çæ¨¹ï¼èä¸éè¦ä¾è³´æ¼åæ¨¡åææ¯å°åºåç´æãPhyloGen å°ç³»çµ±ç¼çæ¨è«è¦çºä¸åæ¢ä»¶ç´æçæ¨¹å½¢çµæ§çæåé¡ï¼ééä¸åæ ¸å¿æ¨¡çµå±ååªåæ¨¹å½¢çµæ§ååæ¯é·åº¦ï¼(i) ç¹å¾µæåã(ii) PhyloTree æ§å»ºï¼ä»¥å (iii) PhyloTree çµæ§å»ºæ¨¡ãåæï¼æåå¼å¥äºè©åå½æ¸ä¾å¼å°æ¨¡åæèæ´ç©©å®çæ¢¯åº¦ä¸éæ¹åç¼å±ãæåå¨å«åçå¯¦ä¸ççåºæºæ¸æéä¸å±ç¤ºäº PhyloGen çæææ§åé­¯æ£æ§ãå¯è¦åçµæè­å¯¦ï¼PhyloGen è½å¤ æ´æ·±å¥å°äºè§£ç³»çµ±ç¼çéä¿ã

##### **CypherBench: Towards Precise Retrieval over Full-scale Modern Knowledge Graphs in the LLM Era**
2412.18702v1 by Yanlin Feng, Simone Papicchio, Sajjadur Rahman

Retrieval from graph data is crucial for augmenting large language models
(LLM) with both open-domain knowledge and private enterprise data, and it is
also a key component in the recent GraphRAG system (edge et al., 2024). Despite
decades of research on knowledge graphs and knowledge base question answering,
leading LLM frameworks (e.g. Langchain and LlamaIndex) have only minimal
support for retrieval from modern encyclopedic knowledge graphs like Wikidata.
In this paper, we analyze the root cause and suggest that modern RDF knowledge
graphs (e.g. Wikidata, Freebase) are less efficient for LLMs due to overly
large schemas that far exceed the typical LLM context window, use of resource
identifiers, overlapping relation types and lack of normalization. As a
solution, we propose property graph views on top of the underlying RDF graph
that can be efficiently queried by LLMs using Cypher. We instantiated this idea
on Wikidata and introduced CypherBench, the first benchmark with 11
large-scale, multi-domain property graphs with 7.8 million entities and over
10,000 questions. To achieve this, we tackled several key challenges, including
developing an RDF-to-property graph conversion engine, creating a systematic
pipeline for text-to-Cypher task generation, and designing new evaluation
metrics.

æè¦ï¼å¾åå½¢è³æä¸­æ·åå°æ¼æ´å¢å¤§åèªè¨æ¨¡å (LLM) éå¸¸éè¦ï¼å®çµåäºéæ¾é åç¥è­åç§äººä¼æ¥­è³æï¼åæä¹æ¯è¿æ GraphRAG ç³»çµ± (edge et al., 2024) çééµçµæé¨åãåç®¡ç¶éæ¸åå¹´çç¥è­åè­åç¥è­åº«åé¡è§£ç­ç ç©¶ï¼ä½é åç LLM æ¡æ¶ï¼ä¾å¦ Langchain å LlamaIndexï¼åè½æä½éåº¦æ¯æ´å¾ç¾ä»£ç¾ç§ç¥è­åè­ï¼ä¾å¦ Wikidataï¼æ·åãå¨æ¬æä¸­ï¼æååæäºæ ¹æ¬åå ï¼ä¸¦æåºç¾ä»£ RDF ç¥è­åè­ï¼ä¾å¦ WikidataãFreebaseï¼å°æ¼ LLM ä¾èªªæçè¼ä½ï¼éæ¯å çºéæ¼é¾å¤§çæ¶æ§é é è¶éå¸åç LLM èæ¯è¦çªãä½¿ç¨è³æºè­å¥ç¢¼ãéççéä¿é¡ååç¼ºä¹æ¨æºåãä½çºè§£æ±ºæ¹æ¡ï¼æåæåºå¨åºå±¤ RDF åå½¢ä¸å»ºç«å±¬æ§åå½¢æª¢è¦ï¼LLM å¯ä»¥ä½¿ç¨ Cypher ææå°æ¥è©¢éäºæª¢è¦ãæåå¨ Wikidata ä¸å¯¦ä¾åäºéåæ³æ³ï¼ä¸¦å¼å¥äº CypherBenchï¼éæ¯ç¬¬ä¸ååºæºï¼åå« 11 åå¤§åãå¤é åçå±¬æ§åå½¢ï¼ææ 780 è¬åå¯¦é«åè¶é 10,000 ååé¡ãçºäºéææ­¤ç®æ¨ï¼æåæå°äºå¹¾åééµææ°ï¼åæ¬éç¼ RDF å°å±¬æ§åå½¢è½æå¼æãå»ºç«æå­å° Cypher ä»»åç¢çç³»çµ±åæµç¨ï¼ä»¥åè¨­è¨æ°çè©ä¼°ææ¨ã

##### **From Hallucinations to Facts: Enhancing Language Models with Curated Knowledge Graphs**
2412.18672v1 by Ratnesh Kumar Joshi, Sagnik Sengupta, Asif Ekbal

Hallucination, a persistent challenge plaguing language models, undermines
their efficacy and trustworthiness in various natural language processing
endeavors by generating responses that deviate from factual accuracy or
coherence. This paper addresses language model hallucination by integrating
curated knowledge graph (KG) triples to anchor responses in empirical data. We
meticulously select and integrate relevant KG triples tailored to specific
contexts, enhancing factual grounding and alignment with input. Our
contribution involves constructing a comprehensive KG repository from Wikipedia
and refining data to spotlight essential information for model training. By
imbuing language models with access to this curated knowledge, we aim to
generate both linguistically fluent responses and deeply rooted in factual
accuracy and context relevance. This integration mitigates hallucinations by
providing a robust foundation of information, enabling models to draw upon a
rich reservoir of factual data during response generation. Experimental
evaluations demonstrate the effectiveness of multiple approaches in reducing
hallucinatory responses, underscoring the role of curated knowledge graphs in
improving the reliability and trustworthiness of language model outputs.

æè¦ï¼å¹»è¦ºï¼ä¸ç¨®æçºå°æ¾èªè¨æ¨¡åçææ°ï¼ç ´å£äºå®åå¨åç¨®èªç¶èªè¨èçå·¥ä½ä¸­çæçåå¯ä¿¡åº¦ï¼å çºå®åç¢ççåæåé¢äºäºå¯¦çæºç¢ºæ§æé£è²«æ§ãæ¬æééæ´åç¶éæ´ççç¥è­åè­ (KG) ä¸åçµä¾é¨å®ç¶é©æ¸æä¸­çåæï¼ä¾è§£æ±ºèªè¨æ¨¡åçå¹»è¦ºãæåä»ç´°å°é¸æä¸¦æ´åèç¹å®èçµ¡ç¸ç¬¦çç¸é KG ä¸åçµï¼å¢å¼·äºå¯¦ä¾æä¸¦èè¼¸å¥ä¿æä¸è´ãæåçè²¢ç»åæ¬å¾ç¶­åºç¾ç§æ§å»ºä¸åå¨é¢ç KG å²å­åº«ï¼ä¸¦ç²¾çæ¸æï¼ä»¥çªé¡¯æ¨¡åè¨ç·´çéè¦è³è¨ãééè®èªè¨æ¨¡åå­åéåç¶éæ´ççç¥è­ï¼æåæ¨å¨ç¢çæ¢èªè¨æµæ¢ï¼åæ·±æ¤æ¼äºå¯¦æºç¢ºæ§åèçµ¡ç¸éæ§çåæãéç¨®æ´åééæä¾ç©©å¥çè³è¨åºç¤ä¾æ¸è¼å¹»è¦ºï¼è®æ¨¡åå¨åæç¢çæéè½å¤ å©ç¨è±å¯çäºå¯¦æ¸æå²åãå¯¦é©è©ä¼°è­æäºå¤ç¨®æ¹æ³å¨æ¸å°å¹»è¦ºåææ¹é¢çæææ§ï¼å¼·èª¿äºç¶éæ´ççç¥è­åè­å¨æ¹åèªè¨æ¨¡åè¼¸åºçå¯é æ§åå¯ä¿¡åº¦æ¹é¢ææ®æ¼çè§è²ã

##### **Harnessing Large Language Models for Knowledge Graph Question Answering via Adaptive Multi-Aspect Retrieval-Augmentation**
2412.18537v2 by Derong Xu, Xinhang Li, Ziheng Zhang, Zhenxi Lin, Zhihong Zhu, Zhi Zheng, Xian Wu, Xiangyu Zhao, Tong Xu, Enhong Chen

Large Language Models (LLMs) demonstrate remarkable capabilities, yet
struggle with hallucination and outdated knowledge when tasked with complex
knowledge reasoning, resulting in factually incorrect outputs. Previous studies
have attempted to mitigate it by retrieving factual knowledge from large-scale
knowledge graphs (KGs) to assist LLMs in logical reasoning and prediction of
answers. However, this kind of approach often introduces noise and irrelevant
data, especially in situations with extensive context from multiple knowledge
aspects. In this way, LLM attention can be potentially mislead from question
and relevant information. In our study, we introduce an Adaptive Multi-Aspect
Retrieval-augmented over KGs (Amar) framework. This method retrieves knowledge
including entities, relations, and subgraphs, and converts each piece of
retrieved text into prompt embeddings. The Amar framework comprises two key
sub-components: 1) a self-alignment module that aligns commonalities among
entities, relations, and subgraphs to enhance retrieved text, thereby reducing
noise interference; 2) a relevance gating module that employs a soft gate to
learn the relevance score between question and multi-aspect retrieved data, to
determine which information should be used to enhance LLMs' output, or even
filtered altogether. Our method has achieved state-of-the-art performance on
two common datasets, WebQSP and CWQ, showing a 1.9\% improvement in accuracy
over its best competitor and a 6.6\% improvement in logical form generation
over a method that directly uses retrieved text as context prompts. These
results demonstrate the effectiveness of Amar in improving the reasoning of
LLMs.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å±ç¤ºäºéå¡çè½åï¼ä½å¨å·è¡è¤éçç¥è­æ¨çæï¼å»æåºç¾å¹»è¦ºåéæçç¥è­ï¼å°è´äºå¯¦ä¸ä¸æ­£ç¢ºçè¼¸åºãååçç ç©¶å·²åè©¦ééå¾å¤§è¦æ¨¡ç¥è­åè­ (KG) ä¸­æ·åäºå¯¦ç¥è­ä¾æ¸è¼éååé¡ï¼ä»¥åå© LLM é²è¡éè¼¯æ¨çåç­æ¡é æ¸¬ãç¶èï¼éç¨®æ¹æ³éå¸¸æå¼å¥éè¨åä¸ç¸éçè³æï¼ç¹å¥æ¯å¨å·æä¾èªå¤åç¥è­é¢åçå»£æ³èçµ¡çææ³ä¸ãéæ¨£ä¸ä¾ï¼LLM çæ³¨æåå¯è½æè¢«åé¡åç¸éè³è¨èª¤å°ãå¨æåçç ç©¶ä¸­ï¼æåä»ç´¹äºä¸åé©ææ§å¤é¢åæ·åå¢å¼·åç¥è­åè­ (Amar) æ¡æ¶ãæ­¤æ¹æ³æ·ååæ¬å¯¦é«ãéä¿åå­åçç¥è­ï¼ä¸¦å°æ¯åæ·åçæå­è½æçºæç¤ºåµå¥ãAmar æ¡æ¶åå«å©åééµå­åä»¶ï¼1) ä¸åèªæå°é½æ¨¡çµï¼ç¨æ¼å°é½å¯¦é«ãéä¿åå­åä¹éçå±æ§ï¼ä»¥å¢å¼·æ·åçæå­ï¼å¾èæ¸å°éè¨å¹²æ¾ï¼2) ä¸åç¸éæ§éæ§æ¨¡çµï¼æ¡ç¨è»éæ§ä¾å­¸ç¿åé¡åå¤é¢åæ·åè³æä¹éçç¸å³æ§åæ¸ï¼ä»¥ç¢ºå®åªäºè³è¨æä½¿ç¨ä¾å¢å¼· LLM çè¼¸åºï¼çè³å®å¨éæ¿¾æãæåçæ¨¡åå¨å©åå¸¸è¦çè³æé WebQSP å CWQ ä¸éå°äºæåé²çæè½ï¼èæä½³ç«¶ç­èç¸æ¯ï¼æºç¢ºåº¦æåäº 1.9%ï¼èç´æ¥ä½¿ç¨æ·åæå­ä½çºèçµ¡æç¤ºçæ¹æ³ç¸æ¯ï¼éè¼¯å½¢å¼çææåäº 6.6%ãéäºçµæè­æäº Amar å¨æ¹å LLM æ¨çæ¹é¢çæææ§ã

##### **DynaGRAG: Improving Language Understanding and Generation through Dynamic Subgraph Representation in Graph Retrieval-Augmented Generation**
2412.18644v1 by Karishma Thakrar

Graph Retrieval-Augmented Generation (GRAG or Graph RAG) architectures aim to
enhance language understanding and generation by leveraging external knowledge.
However, effectively capturing and integrating the rich semantic information
present in textual and structured data remains a challenge. To address this, a
novel GRAG framework is proposed to focus on enhancing subgraph representation
and diversity within the knowledge graph. By improving graph density, capturing
entity and relation information more effectively, and dynamically prioritizing
relevant and diverse subgraphs, the proposed approach enables a more
comprehensive understanding of the underlying semantic structure. This is
achieved through a combination of de-duplication processes, two-step mean
pooling of embeddings, query-aware retrieval considering unique nodes, and a
Dynamic Similarity-Aware BFS (DSA-BFS) traversal algorithm. Integrating Graph
Convolutional Networks (GCNs) and Large Language Models (LLMs) through hard
prompting further enhances the learning of rich node and edge representations
while preserving the hierarchical subgraph structure. Experimental results on
multiple benchmark datasets demonstrate the effectiveness of the proposed GRAG
framework, showcasing the significance of enhanced subgraph representation and
diversity for improved language understanding and generation.

æè¦ï¼åè¡¨æ·åå¢å¼·çæï¼GRAG æ Graph RAGï¼æ¶æ§æ¨å¨
éééç¨å¤é¨ç¥è­ä¾å¢å¼·èªè¨çè§£åçæã
ç¶èï¼æææ·ååæ´åææ¬åçµæ§åè³æä¸­è±å¯çèªç¾©è³è¨ä»ç¶æ¯ä¸é ææ°ãçºäºè§£æ±ºéååé¡ï¼æåºäºä¸åæ°ç GRAG æ¡æ¶ï¼å°æ³¨æ¼å¢å¼·ç¥è­åè­ä¸­çå­åè¡¨ç¤ºåå¤æ¨£æ§ãééæ¹ååå½¢å¯åº¦ãæ´ææå°æ·åå¯¦é«åéä¿è³è¨ï¼ä»¥ååæåªåèæ®ç¸éä¸å¤æ¨£åçå­åï¼ææåºçæ¹æ³è½æ´å¨é¢å°çè§£åºå±¤èªç¾©çµæ§ãéæ¯ééçµåéè¤è³æåªé¤ç¨åºãåµå¥çå©æ­¥é©å¹³åæ± åãèæ®å¯ä¸ç¯é»çæ¥è©¢æç¥æ·åï¼ä»¥ååæç¸ä¼¼åº¦æç¥å»£åº¦åªåæå°ï¼DSA-BFSï¼æ¼ç®æ³ä¾å¯¦ç¾çãééç¡¬æç¤ºæ´ååå½¢å·ç©ç¶²è·¯ï¼GCNï¼åå¤§èªè¨æ¨¡åï¼LLMï¼ï¼é²ä¸æ­¥å¢å¼·è±å¯ç¯é»åéç·£è¡¨ç¤ºçå­¸ç¿ï¼åæä¿çéå±¤å¼å­åçµæ§ãå¨å¤ååºæºè³æéä¸çå¯¦é©çµæè­æäºææåºç GRAG æ¡æ¶çæææ§ï¼å±ç¤ºäºå¢å¼·å­åè¡¨ç¤ºåå¤æ¨£æ§å°æ¼æ¹åèªè¨çè§£åçæçéè¦æ§ã

##### **Is Large Language Model Good at Triple Set Prediction? An Empirical Study**
2412.18443v1 by Yuan Yuan, Yajing Xu, Wen Zhang

The core of the Knowledge Graph Completion (KGC) task is to predict and
complete the missing relations or nodes in a KG. Common KGC tasks are mostly
about inferring unknown elements with one or two elements being known in a
triple. In comparison, the Triple Set Prediction (TSP) task is a more realistic
knowledge graph completion task. It aims to predict all elements of unknown
triples based on the information from known triples. In recent years, large
language models (LLMs) have exhibited significant advancements in language
comprehension, demonstrating considerable potential for KGC tasks. However, the
potential of LLM on the TSP task has not yet to be investigated. Thus in this
paper we proposed a new framework to explore the strengths and limitations of
LLM in the TSP task. Specifically, the framework consists of LLM-based rule
mining and LLM-based triple set prediction. The relation list of KG embedded
within rich semantic information is first leveraged to prompt LLM in the
generation of rules. This process is both efficient and independent of
statistical information, making it easier to mine effective and realistic
rules. For each subgraph, the specified rule is applied in conjunction with the
relevant triples within that subgraph to guide the LLM in predicting the
missing triples. Subsequently, the predictions from all subgraphs are
consolidated to derive the complete set of predicted triples on KG. Finally,
the method is evaluated on the relatively complete CFamily dataset. The
experimental results indicate that when LLMs are required to adhere to a large
amount of factual knowledge to predict missing triples, significant
hallucinations occurs, leading to a noticeable decline in performance. To
further explore the causes of this phenomenon, this paper presents a
comprehensive analysis supported by a detailed case study.

æè¦ï¼ç¥è­åè­å®æ (KGC) ä»»åçæ ¸å¿æ¯é æ¸¬åå®æ KG ä¸­éºå¤±çéä¿æç¯é»ãå¸¸è¦ç KGC ä»»åå¤§å¤æ¯éæ¼æ¨è«æªç¥åç´ ï¼å¶ä¸­ä¸åæå©ååç´ å¨ä¸åçµä¸­å·²ç¥ãç¸æ¯ä¹ä¸ï¼ä¸åçµéåé æ¸¬ (TSP) ä»»åæ¯ä¸åæ´å¯¦éçç¥è­åè­å®æä»»åãå®æ¨å¨æ ¹æå·²ç¥ä¸åçµä¸­çè³è¨é æ¸¬æªç¥ä¸åçµçææåç´ ãè¿å¹´ä¾ï¼å¤§åèªè¨æ¨¡å (LLM) å¨èªè¨çè§£æ¹é¢è¡¨ç¾åºé¡¯èçé²æ­¥ï¼é¡¯ç¤ºåº KGC ä»»åçå·¨å¤§æ½åãç¶èï¼LLM å¨ TSP ä»»åä¸çæ½åå°æªå¾å°æ¢è¨ãå æ­¤ï¼å¨æ¬æä¸­ï¼æåæåºäºä¸åæ°çæ¡æ¶ä¾æ¢ç´¢ LLM å¨ TSP ä»»åä¸­çåªå¢åå±éæ§ãå·é«ä¾èªªï¼è©²æ¡æ¶åå«åºæ¼ LLM çè¦åææååºæ¼ LLM çä¸åçµéåé æ¸¬ãåµå¥è±å¯èªç¾©è³è¨ç KG éä¿æ¸å®é¦åè¢«å©ç¨ä¾æç¤º LLM çæè¦åãéåéç¨æ¢ææçåç¨ç«æ¼çµ±è¨è³è¨ï¼ä½¿å¾ææææä¸å¯¦éçè¦åè®å¾æ´å®¹æãå°æ¼æ¯åå­åï¼æå®è¦åèè©²å­åä¸­ç¸éçä¸åçµçµåä½¿ç¨ï¼ä»¥æå° LLM é æ¸¬éºå¤±çä¸åçµãé¨å¾ï¼åä½µææå­åçé æ¸¬ï¼ä»¥æ¨å° KG ä¸é æ¸¬ä¸åçµçå®æ´éåãæå¾ï¼è©²æ¹æ³å¨ç¸å°å®æ´ç CFamily è³æéä¸é²è¡è©ä¼°ãå¯¦é©çµæè¡¨æï¼ç¶è¦æ± LLM éµå¾ªå¤§éäºå¯¦ç¥è­ä¾é æ¸¬éºå¤±çä¸åçµæï¼æç¼çé¡¯èçå¹»è¦ºï¼å°è´æè½é¡¯èä¸éãçºäºé²ä¸æ­¥æ¢è¨éç¨®ç¾è±¡çåå ï¼æ¬ææåºäºç±è©³ç´°æ¡ä¾ç ç©¶æ¯æ´çå¨é¢åæã

##### **Investigating Large Language Models for Code Vulnerability Detection: An Experimental Study**
2412.18260v2 by Xuefeng Jiang, Lvhua Wu, Sheng Sun, Jia Li, Jingjing Xue, Yuwei Wang, Tingting Wu, Min Liu

Code vulnerability detection (CVD) is essential for addressing and preventing
system security issues, playing a crucial role in ensuring software security.
Previous learning-based vulnerability detection methods rely on either
fine-tuning medium-size sequence models or training smaller neural networks
from scratch. Recent advancements in large pre-trained language models (LLMs)
have showcased remarkable capabilities in various code intelligence tasks
including code understanding and generation. However, the effectiveness of LLMs
in detecting code vulnerabilities is largely under-explored. This work aims to
investigate the gap by fine-tuning LLMs for the CVD task, involving four
widely-used open-source LLMs. We also implement other five previous graph-based
or medium-size sequence models for comparison. Experiments are conducted on
five commonly-used CVD datasets, including both the part of short samples and
long samples. In addition, we conduct quantitative experiments to investigate
the class imbalance issue and the model's performance on samples of different
lengths, which are rarely studied in previous works. To better facilitate
communities, we open-source all codes and resources of this study in
https://github.com/SakiRinn/LLM4CVD and
https://huggingface.co/datasets/xuefen/VulResource.

æè¦ï¼ç¨å¼ç¢¼æ¼æ´åµæ¸¬ (CVD) å°è§£æ±ºåé é²ç³»çµ±å®å¨åé¡è³ééè¦ï¼å¨ç¢ºä¿è»é«å®å¨ä¸æ®æ¼ééµè§è²ã
ååçåºæ¼å­¸ç¿çæ¼æ´åµæ¸¬æ¹æ³ä»°è³´å¾®èª¿ä¸­ååºåæ¨¡åæå¾é ­è¨ç·´è¼å°çç¥ç¶ç¶²è·¯ã
å¤§åé è¨ç·´èªè¨æ¨¡å (LLM) çææ°é²å±å¨åç¨®ç¨å¼ç¢¼æºæ§ä»»åä¸­å±ç¾åºåè¶çè½åï¼åæ¬ç¨å¼ç¢¼çè§£åç¢çã
ç¶èï¼LLM å¨åµæ¸¬ç¨å¼ç¢¼æ¼æ´çæè½å»é®®å°è¢«æ¢è¨ãæ¬ç ç©¶æ¨å¨ééå¾®èª¿ LLM ä¾å¡«è£éåç¼ºå£ï¼æ¶åååå»£æ³ä½¿ç¨çéæº LLMã
æåä¹å¯¦ä½äºå¶ä»äºåååçåºæ¼åå½¢çæä¸­ååºåæ¨¡åé²è¡æ¯è¼ã
å¯¦é©å¨äºåå¸¸ç¨ç CVD è³æéä¸é²è¡ï¼åå«ç­ç¯ä¾åé·ç¯ä¾çé¨åã
æ­¤å¤ï¼æåé²è¡éåå¯¦é©ä¾æ¢è¨é¡å¥ä¸å¹³è¡¡åé¡åæ¨¡åå¨ä¸åé·åº¦ç¯ä¾ä¸çè¡¨ç¾ï¼éäºå¨ååçç ç©¶ä¸­å¾å°è¢«æ¢è¨ã
çºæ´å¥½å°ä¿é²ç¤¾ç¾¤ï¼æåå¨ https://github.com/SakiRinn/LLM4CVD å https://huggingface.co/datasets/xuefen/VulResource éæºæ¬ç ç©¶çææç¨å¼ç¢¼åè³æºã

##### **An Automatic Graph Construction Framework based on Large Language Models for Recommendation**
2412.18241v1 by Rong Shan, Jianghao Lin, Chenxu Zhu, Bo Chen, Menghui Zhu, Kangning Zhang, Jieming Zhu, Ruiming Tang, Yong Yu, Weinan Zhang

Graph neural networks (GNNs) have emerged as state-of-the-art methods to
learn from graph-structured data for recommendation. However, most existing
GNN-based recommendation methods focus on the optimization of model structures
and learning strategies based on pre-defined graphs, neglecting the importance
of the graph construction stage. Earlier works for graph construction usually
rely on speciffic rules or crowdsourcing, which are either too simplistic or
too labor-intensive. Recent works start to utilize large language models (LLMs)
to automate the graph construction, in view of their abundant open-world
knowledge and remarkable reasoning capabilities. Nevertheless, they generally
suffer from two limitations: (1) invisibility of global view (e.g., overlooking
contextual information) and (2) construction inefficiency. To this end, we
introduce AutoGraph, an automatic graph construction framework based on LLMs
for recommendation. Specifically, we first use LLMs to infer the user
preference and item knowledge, which is encoded as semantic vectors. Next, we
employ vector quantization to extract the latent factors from the semantic
vectors. The latent factors are then incorporated as extra nodes to link the
user/item nodes, resulting in a graph with in-depth global-view semantics. We
further design metapath-based message aggregation to effectively aggregate the
semantic and collaborative information. The framework is model-agnostic and
compatible with different backbone models. Extensive experiments on three
real-world datasets demonstrate the efficacy and efffciency of AutoGraph
compared to existing baseline methods. We have deployed AutoGraph in Huawei
advertising platform, and gain a 2.69% improvement on RPM and a 7.31%
improvement on eCPM in the online A/B test. Currently AutoGraph has been used
as the main trafffc model, serving hundreds of millions of people.

æè¦ï¼åç¥ç¶ç¶²è·¯ (GNN) å·²æçºæåé²çæ¹æ³ï¼å¯å¾åå½¢çµæ§åè³æä¸­å­¸ç¿æ¨è¦ãç¶èï¼ç¾æçåºæ¼ GNN çæ¨è¦æ¹æ³å¤§å¤å´éæ¼é å®ç¾©åå½¢ä¸çæ¨¡åçµæ§åå­¸ç¿ç­ç¥çæä½³åï¼å¿½ç¥äºåå½¢å»ºæ§éæ®µçéè¦æ§ãæ©æåå½¢å»ºæ§å·¥ä½éå¸¸ä¾è³´æ¼ç¹å®è¦åæç¾¤ç¾å¤åï¼éäºæ¹æ³éæ¼ç°¡åæéæ¼ååå¯éãæè¿çå·¥ä½éå§å©ç¨å¤§åèªè¨æ¨¡å (LLM) ä¾èªåååå½¢å»ºæ§ï¼å çºå®åå·æè±å¯çéæ¾ä¸çç¥è­ååè¶çæ¨çè½åãåç®¡å¦æ­¤ï¼å®åéå¸¸å­å¨å©åéå¶ï¼(1) å¨åæª¢è¦çä¸å¯è¦æ§ï¼ä¾å¦ï¼å¿½ç¥ä¸ä¸æè³è¨ï¼å (2) å»ºæ§æçä½ä¸ãçºæ­¤ï¼æåå¼å¥äº AutoGraphï¼ä¸ååºæ¼ LLM çèªååå½¢å»ºæ§æ¡æ¶ï¼ç¨æ¼æ¨è¦ãå·é«ä¾èªªï¼æåé¦åä½¿ç¨ LLM æ¨æ·ä½¿ç¨èåå¥½åé ç®ç¥è­ï¼ä¸¦å°å¶ç·¨ç¢¼çºèªç¾©åéãæ¥ä¸ä¾ï¼æåæ¡ç¨åééåå¾èªç¾©åéä¸­æåæ½å¨å å­ãç¶å¾å°æ½å¨å å­ä½çºé¡å¤ç¯é»å å¥ï¼ä»¥é£çµä½¿ç¨è/é ç®ç¯é»ï¼å¾èå½¢æä¸åå·ææ·±å¥å¨åæª¢è¦èªç¾©çåå½¢ãæåé²ä¸æ­¥è¨­è¨äºåºæ¼åè·¯å¾çè¨æ¯èåï¼ä»¥ææèåèªç¾©ååä½è³è¨ãè©²æ¡æ¶èæ¨¡åç¡éï¼ä¸¦èä¸åçä¸»å¹¹æ¨¡åç¸å®¹ãå¨ä¸åçå¯¦ä¸çè³æéä¸é²è¡çå»£æ³å¯¦é©è­æäº AutoGraph èç¾æåºæºæ¹æ³ç¸æ¯çæè½åæçãæåå·²å¨è¯çºå»£åå¹³å°ä¸é¨ç½²äº AutoGraphï¼ä¸¦å¨ç·ä¸ A/B æ¸¬è©¦ä¸­ç²å¾äº RPM æå 2.69% å eCPM æå 7.31%ãç®å AutoGraph å·²è¢«ç¨ä½ä¸»è¦çæµéæ¨¡åï¼æåæ¼æ¸åäººã

##### **CARL-GT: Evaluating Causal Reasoning Capabilities of Large Language Models**
2412.17970v1 by Ruibo Tu, Hedvig KjellstrÃ¶m, Gustav Eje Henter, Cheng Zhang

Causal reasoning capabilities are essential for large language models (LLMs)
in a wide range of applications, such as education and healthcare. But there is
still a lack of benchmarks for a better understanding of such capabilities.
Current LLM benchmarks are mainly based on conversational tasks, academic math
tests, and coding tests. Such benchmarks evaluate LLMs in well-regularized
settings, but they are limited in assessing the skills and abilities to solve
real-world problems. In this work, we provide a benchmark, named by CARL-GT,
which evaluates CAusal Reasoning capabilities of large Language models using
Graphs and Tabular data. The benchmark has a diverse range of tasks for
evaluating LLMs from causal graph reasoning, knowledge discovery, and
decision-making aspects. In addition, effective zero-shot learning prompts are
developed for the tasks. In our experiments, we leverage the benchmark for
evaluating open-source LLMs and provide a detailed comparison of LLMs for
causal reasoning abilities. We found that LLMs are still weak in casual
reasoning, especially with tabular data to discover new insights. Furthermore,
we investigate and discuss the relationships of different benchmark tasks by
analyzing the performance of LLMs. The experimental results show that LLMs have
different strength over different tasks and that their performance on tasks in
different categories, i.e., causal graph reasoning, knowledge discovery, and
decision-making, shows stronger correlation than tasks in the same category.

æè¦ï¼å ææ¨çè½åå¯¹äºå¤§åè¯­è¨æ¨¡å (LLM) è³å³éè¦ï¼éç¨äºå¹¿æ³çåºç¨ï¼ä¾å¦æè²åå»çä¿å¥ãä½å¯¹äºæ´å¥½å°çè§£æ­¤ç±»è½åï¼ä»ç¶ç¼ºä¹åºåãå½åç LLM åºåä¸»è¦åºäºä¼è¯ä»»å¡ãå­¦æ¯æ°å­¦æµè¯åç¼ç æµè¯ãæ­¤ç±»åºåå¨ç»è¿è¯å¥½è§èçç¯å¢ä¸­è¯ä¼° LLMï¼ä½å®ä»¬å¨è¯ä¼°è§£å³å®éé®é¢çè½ååæè½æ¹é¢åå°éå¶ãå¨è¿é¡¹å·¥ä½ä¸­ï¼æä»¬æä¾äºä¸ä¸ªåºåï¼åä¸º CARL-GTï¼å®ä½¿ç¨å¾åè¡¨æ ¼æ°æ®æ¥è¯ä¼°å¤§åè¯­è¨æ¨¡åçå ææ¨çè½åãè¯¥åºåå·æåç§ä»»å¡ï¼ç¨äºä»å æå¾æ¨çãç¥è¯åç°åå³ç­æ¹é¢è¯ä¼° LLMãæ­¤å¤ï¼éå¯¹è¿äºä»»å¡å¼åäºææçé¶æ ·æ¬å­¦ä¹ æç¤ºãå¨æä»¬çå®éªä¸­ï¼æä»¬å©ç¨åºåæ¥è¯ä¼°å¼æº LLMï¼å¹¶å¯¹ LLM çå ææ¨çè½åè¿è¡äºè¯¦ç»æ¯è¾ãæä»¬åç° LLM å¨å ææ¨çæ¹é¢ä»ç¶å¾å¼±ï¼å°¤å¶æ¯å¨ä½¿ç¨è¡¨æ ¼æ°æ®åç°æ°è§è§£æ¶ãæ­¤å¤ï¼æä»¬éè¿åæ LLM çæ§è½æ¥è°æ¥åè®¨è®ºä¸ååºåä»»å¡ä¹é´çå³ç³»ãå®éªç»æè¡¨æï¼LLM å¨ä¸åä»»å¡ä¸å·æä¸åçä¼å¿ï¼å¹¶ä¸å®ä»¬å¨ä¸åç±»å«ä¸­çä»»å¡ä¸çè¡¨ç°ï¼å³å æå¾æ¨çãç¥è¯åç°åå³ç­ï¼æ¯åä¸ç±»å«ä¸­çä»»å¡è¡¨ç°åºæ´å¼ºçç¸å³æ§ã

##### **Path-of-Thoughts: Extracting and Following Paths for Robust Relational Reasoning with Large Language Models**
2412.17963v1 by Ge Zhang, Mohammad Ali Alomrani, Hongjian Gu, Jiaming Zhou, Yaochen Hu, Bin Wang, Qun Liu, Mark Coates, Yingxue Zhang, Jianye Hao

Large language models (LLMs) possess vast semantic knowledge but often
struggle with complex reasoning tasks, particularly in relational reasoning
problems such as kinship or spatial reasoning. In this paper, we present
Path-of-Thoughts (PoT), a novel framework designed to tackle relation reasoning
by decomposing the task into three key stages: graph extraction, path
identification, and reasoning. Unlike previous approaches, PoT efficiently
extracts a task-agnostic graph that identifies crucial entities, relations, and
attributes within the problem context. Subsequently, PoT identifies relevant
reasoning chains within the graph corresponding to the posed question,
facilitating inference of potential answers. Experimental evaluations on four
benchmark datasets, demanding long reasoning chains, demonstrate that PoT
surpasses state-of-the-art baselines by a significant margin (maximum 21.3%)
without necessitating fine-tuning or extensive LLM calls. Furthermore, as
opposed to prior neuro-symbolic methods, PoT exhibits improved resilience
against LLM errors by leveraging the compositional nature of graphs.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) ææå»£æ³çèªç¾©ç¥è­ï¼ä½å¨è¤éçæ¨çä»»åä¸­ç¶å¸¸éå°å°é£ï¼ç¹å¥æ¯å¨éä¿æ¨çåé¡ä¸­ï¼ä¾å¦è¦ªå±¬éä¿æç©ºéæ¨çãå¨æ¬æä¸­ï¼æåæåºæèè·¯å¾ (PoT)ï¼éæ¯ä¸åæ°ç©çæ¡æ¶ï¼æ¨å¨ééå°ä»»ååè§£çºä¸åééµéæ®µä¾è§£æ±ºéä¿æ¨çï¼åå½¢æåãè·¯å¾è­å¥åæ¨çãèä¹åçåæ³ä¸åï¼PoT ææå°æåäºä¸åèä»»åç¡éçåå½¢ï¼è©²åå½¢è­å¥äºåé¡èæ¯ä¸­çééµå¯¦é«ãéä¿åå±¬æ§ãé¨å¾ï¼PoT å¨èææåºçåé¡ç¸æçåå½¢ä¸­è­å¥åºç¸éçæ¨çéï¼å¾èæ¨æ·åºæ½å¨ç­æ¡ãå¨éè¦é·æ¨çéçåååºæºæ¸æéä¸çå¯¦é©è©ä¼°è¡¨æï¼PoT ä»¥é¡¯èçåªå¢ï¼æå¤§ 21.3%ï¼è¶è¶äºæåé²çåºæºï¼èç¡éå¾®èª¿æå»£æ³ç LLM èª¿ç¨ãæ­¤å¤ï¼èååçç¥ç¶ç¬¦èæ¹æ³ç¸åï¼PoT ééå©ç¨åå½¢ççµåç¹æ§è¡¨ç¾åºå° LLM é¯èª¤çå¢å¼·çå½æ§ã

##### **ResearchTown: Simulator of Human Research Community**
2412.17767v1 by Haofei Yu, Zhaochen Hong, Zirui Cheng, Kunlun Zhu, Keyang Xuan, Jinwei Yao, Tao Feng, Jiaxuan You

Large Language Models (LLMs) have demonstrated remarkable potential in
scientific domains, yet a fundamental question remains unanswered: Can we
simulate human research communities with LLMs? Addressing this question can
deepen our understanding of the processes behind idea brainstorming and inspire
the automatic discovery of novel scientific insights. In this work, we propose
ResearchTown, a multi-agent framework for research community simulation. Within
this framework, the human research community is simplified and modeled as an
agent-data graph, where researchers and papers are represented as agent-type
and data-type nodes, respectively, and connected based on their collaboration
relationships. We also introduce TextGNN, a text-based inference framework that
models various research activities (e.g., paper reading, paper writing, and
review writing) as special forms of a unified message-passing process on the
agent-data graph. To evaluate the quality of the research simulation, we
present ResearchBench, a benchmark that uses a node-masking prediction task for
scalable and objective assessment based on similarity. Our experiments reveal
three key findings: (1) ResearchTown can provide a realistic simulation of
collaborative research activities, including paper writing and review writing;
(2) ResearchTown can maintain robust simulation with multiple researchers and
diverse papers; (3) ResearchTown can generate interdisciplinary research ideas
that potentially inspire novel research directions.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å¨ç§å­¸é åå±ç¾äºéå¡çæ½åï¼ä½ä»æä¸ååºæ¬åé¡å°æªè§£ç­ï¼æåè½ç¨ LLM æ¨¡æ¬äººé¡ç ç©¶ç¤¾ç¾¤åï¼æ¢è¨éååé¡è½å æ·±æåå°è¦åæ¿çªèå¾æµç¨ççè§£ï¼ä¸¦æ¿ç¼èªåç¼ç¾æ°ç§å­¸è¦è§£ãå¨éé å·¥ä½ä¸­ï¼æåæåº ResearchTownï¼ä¸åç¨æ¼ç ç©¶ç¤¾ç¾¤æ¨¡æ¬çå¤ä»£çæ¶æ§ãå¨éåæ¶æ§ä¸­ï¼äººé¡ç ç©¶ç¤¾ç¾¤è¢«ç°¡åä¸¦å»ºæ¨¡çºä»£çè³æåï¼å¶ä¸­ç ç©¶äººå¡åè«æåå¥è¡¨ç¤ºçºä»£çé¡åç¯é»åè³æé¡åç¯é»ï¼ä¸¦æ ¹æä»åçåä½éä¿é²è¡é£æ¥ãæåéä»ç´¹äº TextGNNï¼ä¸ååºæ¼æå­çæ¨è«æ¶æ§ï¼å®å°åç¨®ç ç©¶æ´»åï¼ä¾å¦ï¼é±è®è«æãæ°å¯«è«æåæ°å¯«è©è«ï¼å»ºæ¨¡çºä»£çè³æåä¸çµ±ä¸è¨æ¯å³ééç¨çç¹æ®å½¢å¼ãçºäºè©ä¼°ç ç©¶æ¨¡æ¬çåè³ªï¼æåæåºäº ResearchBenchï¼ä¸åä½¿ç¨ç¯é»é®ç½©é æ¸¬ä»»åé²è¡åºæ¼ç¸ä¼¼æ§çå¯æ´åä¸å®¢è§è©ä¼°çåºæºãæåçå¯¦é©æ­ç¤ºäºä¸åééµç¼ç¾ï¼(1) ResearchTown å¯ä»¥æä¾åä½ç ç©¶æ´»åçé¼çæ¨¡æ¬ï¼åæ¬æ°å¯«è«æåæ°å¯«è©è«ï¼(2) ResearchTown å¯ä»¥ç¶­æå¤ä½ç ç©¶äººå¡åä¸åè«æçç©©å¥æ¨¡æ¬ï¼(3) ResearchTown å¯ä»¥ç¢çè·¨å­¸ç§ç ç©¶æ§æ³ï¼æ½å¨æ¿ç¼æ°çç ç©¶æ¹åã

##### **RAGONITE: Iterative Retrieval on Induced Databases and Verbalized RDF for Conversational QA over KGs with RAG**
2412.17690v3 by Rishiraj Saha Roy, Chris Hinze, Joel Schlotthauer, Farzad Naderi, Viktor Hangya, Andreas Foltyn, Luzian Hahn, Fabian Kuech

Conversational question answering (ConvQA) is a convenient means of searching
over RDF knowledge graphs (KGs), where a prevalent approach is to translate
natural language questions to SPARQL queries. However, SPARQL has certain
shortcomings: (i) it is brittle for complex intents and conversational
questions, and (ii) it is not suitable for more abstract needs. Instead, we
propose a novel two-pronged system where we fuse: (i) SQL-query results over a
database automatically derived from the KG, and (ii) text-search results over
verbalizations of KG facts. Our pipeline supports iterative retrieval: when the
results of any branch are found to be unsatisfactory, the system can
automatically opt for further rounds. We put everything together in a retrieval
augmented generation (RAG) setup, where an LLM generates a coherent response
from accumulated search results. We demonstrate the superiority of our proposed
system over several baselines on a knowledge graph of BMW automobiles.

æè¦ï¼å°è©±å¼åç­ï¼ConvQAï¼æ¯ä¸ç¨®æå° RDF ç¥è­åè­ï¼KGï¼çä¾¿å©æ¹æ³ï¼å¶ä¸­ä¸ç¨®æ®éçæ¹æ³æ¯å°èªç¶èªè¨åé¡è½æçº SPARQL æ¥è©¢ãç¶èï¼SPARQL ææäºç¼ºé»ï¼(i) å°æ¼è¤éçæååå°è©±å¼åé¡èè¨ï¼å®å¾èå¼±ï¼(ii) å®ä¸é©åæ´æ½è±¡çéæ±ãç¸åï¼æåæåºäºä¸åæ°ç©çéç®¡é½ä¸çç³»çµ±ï¼å¶ä¸­æåèåï¼(i) å¾èªåå¾ KG ä¸­æ´¾ççè³æåº«ä¸ç SQL æ¥è©¢çµæï¼ä»¥å (ii) KG äºå¯¦çè¨èªåä¸çæå­æå°çµæãæåçç®¡ç·æ¯æ´åè¦æª¢ç´¢ï¼ç¶ç¼ç¾ä»»ä½åæ¯ççµæä¸ä»¤äººæ»¿ææï¼ç³»çµ±å¯ä»¥èªåé¸æé²ä¸æ­¥çååãæåå°ææå§å®¹æ´åå°æª¢ç´¢æ´åçæï¼RAGï¼è¨­å®ä¸­ï¼å¶ä¸­ LLM å¾ç´¯ç©çæå°çµæä¸­ç¢çé£è²«çåæãæåå¨ BMW æ±½è»çç¥è­åè­ä¸å±ç¤ºäºæåæåºçç³»çµ±åªæ¼å¹¾ååºç·çåªè¶æ§ã

##### **A Dual-Perspective Metaphor Detection Framework Using Large Language Models**
2412.17332v2 by Yujie Lin, Jingyao Liu, Yan Gao, Ante Wang, Jinsong Su

Metaphor detection, a critical task in natural language processing, involves
identifying whether a particular word in a sentence is used metaphorically.
Traditional approaches often rely on supervised learning models that implicitly
encode semantic relationships based on metaphor theories. However, these
methods often suffer from a lack of transparency in their decision-making
processes, which undermines the reliability of their predictions. Recent
research indicates that LLMs (large language models) exhibit significant
potential in metaphor detection. Nevertheless, their reasoning capabilities are
constrained by predefined knowledge graphs. To overcome these limitations, we
propose DMD, a novel dual-perspective framework that harnesses both implicit
and explicit applications of metaphor theories to guide LLMs in metaphor
detection and adopts a self-judgment mechanism to validate the responses from
the aforementioned forms of guidance. In comparison to previous methods, our
framework offers more transparent reasoning processes and delivers more
reliable predictions. Experimental results prove the effectiveness of DMD,
demonstrating state-of-the-art performance across widely-used datasets.

æè¦ï¼é±å»åµæ¸¬æ¯èªç¶èªè¨èçä¸­çä¸é éè¦ä»»åï¼æ¶åè­å¥å¥å­ä¸­ç¹å®å®å­æ¯å¦ä»¥é±å»æ¹å¼ä½¿ç¨ãå³çµ±æ¹æ³éå¸¸ä¾è³´ç£ç£å¼å­¸ç¿æ¨¡åï¼éäºæ¨¡åæ ¹æé±å»çè«é±å«ç·¨ç¢¼èªç¾©éä¿ãç¶èï¼éäºæ¹æ³éå¸¸å¨æ±ºç­éç¨ä¸­ç¼ºä¹éæåº¦ï¼éææå®³å¶é æ¸¬çå¯é æ§ãæè¿çç ç©¶è¡¨æï¼LLMï¼å¤§åèªè¨æ¨¡åï¼å¨é±å»åµæ¸¬ä¸­å±ç¾åºé¡¯èçæ½åãåç®¡å¦æ­¤ï¼å®åçæ¨çè½ååå°é å®ç¾©ç¥è­åè¡¨çéå¶ãçºäºåæéäºéå¶ï¼æåæåºäº DMDï¼éæ¯ä¸ç¨®æ°ç©çééè§é»æ¶æ§ï¼å®å©ç¨é±å»çè«çé±å«åæç¢ºæç¨ä¾å¼å° LLM é²è¡é±å»åµæ¸¬ï¼ä¸¦æ¡ç¨èªæå¤æ·æ©å¶ä¾é©è­ä¸è¿°æå°å½¢å¼çåæãèååçæ¨¡åç¸æ¯ï¼æåçæ¶æ§æä¾äºæ´éæçæ¨çéç¨ï¼ä¸¦æä¾äºæ´å¯é çé æ¸¬ãå¯¦é©çµæè­æäº DMD çæææ§ï¼è­æäºå¨å»£æ³ä½¿ç¨çè³æéä¸­çæåé²æè½ã

##### **GraphAgent: Agentic Graph Language Assistant**
2412.17029v1 by Yuhao Yang, Jiabin Tang, Lianghao Xia, Xingchen Zou, Yuxuan Liang, Chao Huang

Real-world data is represented in both structured (e.g., graph connections)
and unstructured (e.g., textual, visual information) formats, encompassing
complex relationships that include explicit links (such as social connections
and user behaviors) and implicit interdependencies among semantic entities,
often illustrated through knowledge graphs. In this work, we propose
GraphAgent, an automated agent pipeline that addresses both explicit graph
dependencies and implicit graph-enhanced semantic inter-dependencies, aligning
with practical data scenarios for predictive tasks (e.g., node classification)
and generative tasks (e.g., text generation). GraphAgent comprises three key
components: (i) a Graph Generator Agent that builds knowledge graphs to reflect
complex semantic dependencies; (ii) a Task Planning Agent that interprets
diverse user queries and formulates corresponding tasks through agentic
self-planning; and (iii) a Task Execution Agent that efficiently executes
planned tasks while automating tool matching and invocation in response to user
queries. These agents collaborate seamlessly, integrating language models with
graph language models to uncover intricate relational information and data
semantic dependencies. Through extensive experiments on various graph-related
predictive and text generative tasks on diverse datasets, we demonstrate the
effectiveness of our GraphAgent across various settings. We have made our
proposed GraphAgent open-source at: https://github.com/HKUDS/GraphAgent.

æè¦ï¼çå¯¦ä¸ççè³æä»¥çµæ§åï¼ä¾å¦åå½¢é£æ¥ï¼åéçµæ§åï¼ä¾å¦æå­ãè¦è¦ºè³è¨ï¼æ ¼å¼åç¾ï¼åå«è¤éçéä¿ï¼åæ¬æç¢ºçé£çµï¼ä¾å¦ç¤¾äº¤é£çµåä½¿ç¨èè¡çºï¼åèªæå¯¦é«ä¹éçé±å«ç¸äºä¾è³´ï¼éå¸¸ééç¥è­åè¡¨ä¾èªªæãå¨éé å·¥ä½ä¸­ï¼æåæåº GraphAgentï¼ä¸åèªååä»£çç¨å¼ç®¡éï¼å®èçæç¢ºçåå½¢ä¾è³´éä¿åé±å«çåå½¢å¢å¼·èªæç¸äºä¾è³´éä¿ï¼èé æ¸¬ä»»åï¼ä¾å¦ç¯é»åé¡ï¼åçæä»»åï¼ä¾å¦æå­çæï¼çå¯¦éè³ææå¢ä¿æä¸è´ãGraphAgent åå«ä¸åééµçµæé¨åï¼(i) ä¸ååå½¢ç¢çå¨ä»£çç¨å¼ï¼ç¨ä¾å»ºæ§ç¥è­åè¡¨ä»¥åæ è¤éçèªæä¾è³´éä¿ï¼(ii) ä¸åä»»åè¦åä»£çç¨å¼ï¼ç¨ä¾è©®éä¸åçä½¿ç¨èæ¥è©¢ï¼ä¸¦ééä»£çèªè¦åå¶å®ç¸æçä»»åï¼ä»¥å (iii) ä¸åä»»åå·è¡ä»£çç¨å¼ï¼ç¨ä¾å¨åæä½¿ç¨èæ¥è©¢æï¼ææçå°å·è¡å·²è¦åçä»»åï¼åæèªååå·¥å·éå°åå¼å«ãéäºä»£çç¨å¼ç¡ç¸«å°åä½ï¼å°èªè¨æ¨¡åèåå½¢èªè¨æ¨¡åæ´åå¨ä¸èµ·ï¼ä»¥æ­é²è¤éçéä¿è³è¨åè³æèªæä¾è³´éä¿ãééå¨ä¸åè³æéä¸é²è¡åç¨®èåå½¢ç¸éçé æ¸¬åæå­çæä»»åçå»£æ³å¯¦é©ï¼æåè­æäº GraphAgent å¨åç¨®è¨­å®ä¸­çæææ§ãæåå·²å°æåæåºç GraphAgent éæºï¼https://github.com/HKUDS/GraphAgentã

##### **Enhancing Supply Chain Transparency in Emerging Economies Using Online Contents and LLMs**
2412.16922v1 by Bohan Jin, Qianyou Sun, Lihua Chen

In the current global economy, supply chain transparency plays a pivotal role
in ensuring this security by enabling companies to monitor supplier performance
and fostering accountability and responsibility. Despite the advancements in
supply chain relationship datasets like Bloomberg and FactSet, supply chain
transparency remains a significant challenge in emerging economies due to
issues such as information asymmetry and institutional gaps in regulation. This
study proposes a novel approach to enhance supply chain transparency in
emerging economies by leveraging online content and large language models
(LLMs). We develop a Supply Chain Knowledge Graph Mining System that integrates
advanced LLMs with web crawler technology to automatically collect and analyze
supply chain information. The system's effectiveness is validated through a
case study focusing on the semiconductor supply chain, a domain that has
recently gained significant attention due to supply chain risks. Our results
demonstrate that the proposed system provides greater applicability for
emerging economies, such as mainland China, complementing the data gaps in
existing datasets. However, challenges including the accurate estimation of
monetary and material flows, the handling of time series data, synonyms
disambiguation, and mitigating biases from online contents still remains.
Future research should focus on addressing these issues to further enhance the
system's capabilities and broaden its application to other emerging economies
and industries.

æè¦ï¼å¨ç¶ä»å¨çç¶æ¿ä¸­ï¼ä¾æééæåº¦å¨ç¢ºä¿æ­¤å®å¨æ§æ¹é¢ç¼æ®èééµä½ç¨ï¼è®å¬å¸è½å¤ ç£æ§ä¾æåç¸¾æä¸¦ä¿é²åè²¬å¶åè²¬ä»»æãåç®¡å½­åç¤¾å FactSet ç­ä¾æééä¿æ¸æéåå¾é²å±ï¼ä½ç±æ¼è³è¨ä¸å°ç¨±åæ³è¦å¶åº¦å·®è·ç­åé¡ï¼ä¾æééæåº¦å¨éç¼ä¸­åå®¶ä»æ¯ä¸é éå¤§ææ°ãæ¬ç ç©¶æåºäºä¸ç¨®æ°æ¹æ³ï¼å©ç¨ç·ä¸å§å®¹åå¤§åèªè¨æ¨¡å (LLM) ä¾å å¼·éç¼ä¸­åå®¶çä¾æééæåº¦ãæåéç¼äºä¸åä¾æéç¥è­åè­ææç³»çµ±ï¼å°åé²ç LLM èç¶²è·¯ç¬è²æè¡æ´åå¨ä¸èµ·ï¼ä»¥èªåæ¶éååæä¾æéè³è¨ãè©²ç³»çµ±çæææ§å·²éééå°åå°é«ä¾æéçæ¡ä¾ç ç©¶å¾å°é©è­ï¼åå°é«ä¾æéæ¯ä¸åç±æ¼ä¾æéé¢¨éªèæè¿åå°æ¥µå¤§éæ³¨çé åãæåççµæè¡¨æï¼ææåºçç³»çµ±çºéç¼ä¸­åå®¶ï¼ä¾å¦ä¸­åå¤§é¸ï¼æä¾äºæ´å¤§çé©ç¨æ§ï¼è£åäºç¾ææ¸æéä¸­çæ¸æå·®è·ãç¶èï¼åæ¬æºç¢ºä¼°è¨è²¨å¹£åç©ææµãèçæéåºåæ¸æãæ¶é¤åç¾©è©æ­§ç¾©åæ¸è¼ç·ä¸å§å®¹åè¦å¨å§çææ°ä»ç¶å­å¨ãæªä¾çç ç©¶æå°æ³¨æ¼è§£æ±ºéäºåé¡ï¼ä»¥é²ä¸æ­¥å¢å¼·ç³»çµ±çè½åä¸¦æ´å¤§å¶å¨å¶ä»éç¼ä¸­åå®¶åç¢æ¥­çæç¨ã

##### **KG4Diagnosis: A Hierarchical Multi-Agent LLM Framework with Knowledge Graph Enhancement for Medical Diagnosis**
2412.16833v2 by Kaiwen Zuo, Yirui Jiang, Fan Mo, Pietro Lio

Integrating Large Language Models (LLMs) in healthcare diagnosis demands
systematic frameworks that can handle complex medical scenarios while
maintaining specialized expertise. We present KG4Diagnosis, a novel
hierarchical multi-agent framework that combines LLMs with automated knowledge
graph construction, encompassing 362 common diseases across medical
specialties. Our framework mirrors real-world medical systems through a
two-tier architecture: a general practitioner (GP) agent for initial assessment
and triage, coordinating with specialized agents for in-depth diagnosis in
specific domains. The core innovation lies in our end-to-end knowledge graph
generation methodology, incorporating: (1) semantic-driven entity and relation
extraction optimized for medical terminology, (2) multi-dimensional decision
relationship reconstruction from unstructured medical texts, and (3)
human-guided reasoning for knowledge expansion. KG4Diagnosis serves as an
extensible foundation for specialized medical diagnosis systems, with
capabilities to incorporate new diseases and medical knowledge. The framework's
modular design enables seamless integration of domain-specific enhancements,
making it valuable for developing targeted medical diagnosis systems. We
provide architectural guidelines and protocols to facilitate adoption across
medical contexts.

æè¦ï¼æ´åå¤§åèªè¨æ¨¡å (LLM) æ¼é«çè¨ºæ·ä¸­éè¦ç³»çµ±æ§æ¶æ§ï¼æ­¤æ¶æ§å¿é è½èçè¤éçé«çæå¢ï¼åæä¿æå°æ¥­ç¥è­ãæåæåº KG4Diagnosisï¼ä¸åçµå LLM èèªååç¥è­åè¡¨å»ºæ§çæ°åéå±¤å¼å¤éä»£çæ¶æ§ï¼æ¶µè 362 ç¨®å¸¸è¦ç¾çï¼æ©«è·¨ååé«çå°ç§ãæåçæ¶æ§éééå±¤æ¶æ§åæ çå¯¦ä¸ççé«çç³»çµ±ï¼ä¸ä½è² è²¬åæ­¥è©ä¼°ååæµçå®¶åº­é«å¸« (GP) ä»£çï¼åèª¿ååå°ç§ä»£çé²è¡æ·±å¥è¨ºæ·ãæ ¸å¿åµæ°å¨æ¼æåçç«¯å°ç«¯ç¥è­åè¡¨ç¢çæ¹æ³ï¼çµåï¼(1) èªæé©åçå¯¦é«èéä¿èåï¼éå°é«çè¡èªé²è¡æä½³åï¼(2) å¾éçµæ§åé«çææ¬éå»ºå¤ç¶­åº¦æ±ºç­éä¿ï¼ä»¥å (3) äººé¡å¼å°çæ¨çï¼ç¨æ¼ç¥è­æ´åãKG4Diagnosis å¯ä½çºå°éé«çè¨ºæ·ç³»çµ±çå¯å»¶ä¼¸åºç¤ï¼æè½åæ´åæ°çç¾çåé«çç¥è­ãæ­¤æ¶æ§çæ¨¡çµåè¨­è¨è½ç¡ç¸«æ´åç¹å®é åçå¼·ååè½ï¼ä½¿å¶å°æ¼éç¼ç®æ¨å°åçé«çè¨ºæ·ç³»çµ±æ¥µå·å¹å¼ãæåæä¾æ¶æ§æå¼ååå®ï¼ä»¥ä¿é²å¨åç¨®é«çæå¢ä¸­çæ¡ç¨ã

##### **Apples to Apples: Establishing Comparability in Knowledge Generation Tasks Involving Users**
2412.16766v1 by Christophe Debruyne, Ademar Crotti Junior

Knowledge graph construction (KGC) from (semi-)structured data is
challenging, and facilitating user involvement is an issue frequently brought
up within this community. We cannot deny the progress we have made with respect
to (declarative) knowledge generation languages and tools to help build such
mappings. However, it is surprising that no two studies report on similar
protocols. This heterogeneity does not allow for a comparison of KGC languages,
techniques, and tools. This paper first analyses the various studies that
report on studies involving users to identify the points of comparison. These
gaps include a lack of systematic consistency in task design, participant
selection, and evaluation metrics. Moreover, there needs to be a systematic way
of analyzing the data and reporting the findings, which is also lacking. We
thus propose and introduce a user protocol for KGC designed to address this
challenge. Where possible, we draw and take elements from the literature we
deem fit for such a protocol. The protocol, as such, allows for the comparison
of languages and techniques for the RDF Mapping Languages core functionality,
which is covered by most of the other state-of-the-art techniques and tools. We
also propose how the protocol can be amended to compare extensions (of RML).
This protocol provides an important step towards a more comparable evaluation
of KGC user studies.

æè¦ï¼ç¥è­åè­å»ºæ§ (KGC) å¾ (å) çµæ§åè³æä¸­é²è¡éå¸¸å·æææ°æ§ï¼èä¿é²ä½¿ç¨èåèæ¯éåç¤¾ç¾¤ä¸­ç¶å¸¸æåºçè­°é¡ãæåç¡æ³å¦èªæåå¨åå©å»ºæ§æ­¤é¡å°æç (å®£åå¼) ç¥è­ç¢çèªè¨åå·¥å·æ¹é¢æåçé²å±ãç¶èï¼ä»¤äººé©è¨çæ¯ï¼æ²æå©é ç ç©¶å ±åé¡ä¼¼çåå®ãéç¨®ç°è³ªæ§ä¸åè¨±æ¯è¼ KGC èªè¨ãæè¡åå·¥å·ãæ¬æé¦ååæåç¨®ç ç©¶ï¼éäºç ç©¶å ±åæ¶åä½¿ç¨èçç ç©¶ï¼ä»¥æ¾åºæ¯è¼é»ãéäºå·®è·åæ¬ä»»åè¨­è¨ãåèèé¸æåè©éææ¨ç¼ºä¹ç³»çµ±æ§çä¸è´æ§ãæ­¤å¤ï¼éè¦æç³»çµ±çæ¹æ³ä¾åæè³æåå ±åçµæï¼éä¹æ¯æç¼ºä¹çãå æ­¤ï¼æåæåºä¸¦ä»ç´¹ä¸åä½¿ç¨èåå®ï¼ç¨æ¼ KGCï¼æ¨å¨è§£æ±ºéåææ°ãå¨å¯è½çç¯åå§ï¼æåå¾æåèªçºé©åæ­¤é¡åå®çæç»ä¸­æ±²åä¸¦æ¡ç¨åç´ ãå æ­¤ï¼è©²åå®åè¨±æ¯è¼ RDF å°æèªè¨æ ¸å¿åè½çèªè¨åæè¡ï¼èå¤§å¤æ¸å¶ä»æåé²çæè¡åå·¥å·é½æ¶µèäºéä¸é»ãæåéæåºå¦ä½ä¿®æ¹åå®ä»¥æ¯è¼å»¶ä¼¸ (RML)ãæ­¤åå®æä¾äºä¸åéè¦çæ­¥é©ï¼æåæ´å·å¯æ¯è¼æ§ç KGC ä½¿ç¨èç ç©¶è©ééé²ã

##### **Self-guided Knowledgeable Network of Thoughts: Amplifying Reasoning with Large Language Models**
2412.16533v1 by Chao-Chi Chen, Chin-Yuan Yeh, Hsi-Wen Chen, De-Nian Yang, Ming-Syan Chen

We introduce Knowledgeable Network of Thoughts (kNoT): a prompt scheme that
advances the capabilities of large language models (LLMs) beyond existing
paradigms like Chain-of-Thought (CoT), Tree of Thoughts (ToT), and Graph of
Thoughts (GoT). The key innovation of kNoT is the LLM Workflow Template (LWT),
which allows for an executable plan to be specified by LLMs for LLMs. LWT
allows these plans to be arbitrary networks, where single-step LLM operations
are nodes, and edges correspond to message passing between these steps.
Furthermore, LWT supports selection of individual elements through indexing,
facilitating kNoT to produce intricate plans where each LLM operation can be
limited to elementary operations, greatly enhancing reliability over extended
task sequences. We demonstrate that kNoT significantly outperforms the state of
the art on six use cases, while reducing the need for extensive prompt
engineering. For instance, kNoT finds 92% accuracy for sorting 32 numbers over
12% and 31% for ToT and GoT, while utilizing up to 84.4% and 87.3% less
task-specific prompts, respectively.

æè¦ï¼æåå¼å¥äºææ³ç¥è­ç¶²è·¯ (kNoT)ï¼ä¸ç¨®æç¤ºæ¶æ§ï¼å®å°å¤§åèªè¨æ¨¡å (LLM) çè½åæåå°äºè¶è¶ç¾æç¯ä¾çå¢çï¼ä¾å¦ææ³é (CoT)ãææ³æ¨¹ (ToT) åææ³å (GoT)ãkNoT çééµåµæ°æ¯ LLM å·¥ä½æµç¨ç¯æ¬ (LWT)ï¼å®åè¨± LLM çº LLM æå®ä¸åå¯å·è¡çè¨ç«ãLWT åè¨±éäºè¨ç«æçºä»»æç¶²è·¯ï¼å¶ä¸­å®æ­¥ LLM æä½çºç¯é»ï¼èéç·£å°ææ¼éäºæ­¥é©ä¹éçè¨æ¯å³éãæ­¤å¤ï¼LWT æ¯æ´ééç´¢å¼é¸ååå¥åç´ ï¼é²èè® kNoT è½å¤ å¶å®è¤éçè¨ç«ï¼å¶ä¸­æ¯å LLM æä½é½å¯ä»¥éå¶çºåºæ¬æä½ï¼å¤§å¹æåå»¶ä¼¸ä»»ååºåçå¯é æ§ãæåè­æ kNoT å¨å­åç¨ä¾ä¸é¡¯èåªæ¼ç¾ææè¡ï¼åææ¸å°äºå°å»£æ³æç¤ºå·¥ç¨çéæ±ãä¾å¦ï¼kNoT å¨å° 32 åæ¸å­é²è¡æåºæç¼ç¾ 92% çæºç¢ºçï¼è ToT å GoT çº 12% å 31%ï¼åæåå¥å©ç¨äºå°é 84.4% å 87.3% çç¹å®ä»»åæç¤ºã

##### **Beyond End-to-End VLMs: Leveraging Intermediate Text Representations for Superior Flowchart Understanding**
2412.16420v1 by Junyi Ye, Ankan Dash, Wenpeng Yin, Guiling Wang

Flowcharts are typically presented as images, driving the trend of using
vision-language models (VLMs) for end-to-end flowchart understanding. However,
two key challenges arise: (i) Limited controllability--users have minimal
influence over the downstream task, as they can only modify input images, while
the training of VLMs is often out of reach for most researchers. (ii) Lack of
explainability--it is difficult to trace VLM errors to specific causes, such as
failures in visual encoding or reasoning. We propose TextFlow, addressing
aforementioned issues with two stages: (i) Vision Textualizer--which generates
textual representations from flowchart images; and (ii) Textual Reasoner--which
performs question-answering based on the text representations. TextFlow offers
three key advantages: (i) users can select the type of text representations
(e.g., Graphviz, Mermaid, PlantUML), or further convert them into executable
graph object to call tools, enhancing performance and controllability; (ii) it
improves explainability by helping to attribute errors more clearly to visual
or textual processing components; and (iii) it promotes the modularization of
the solution, such as allowing advanced LLMs to be used in the Reasoner stage
when VLMs underperform in end-to-end fashion. Experiments on the FlowVQA and
FlowLearn benchmarks demonstrate TextFlow's state-of-the-art performance as
well as its robustness. All code is publicly available.

æè¦ï¼æµç¨åéå¸¸ä»¥å½±ååç¾ï¼æ¨åäºä½¿ç¨è¦è¦ºèªè¨æ¨¡å (VLM) é²è¡ç«¯å°ç«¯æµç¨åçè§£çè¶¨å¢ãç¶èï¼åºç¾äºå©åééµææ°ï¼(i) å¯æ§æ§æéââä½¿ç¨èå°ä¸æ¸¸ä»»åçå½±é¿å¾å°ï¼å çºä»ååªè½ä¿®æ¹è¼¸å¥å½±åï¼èå¤§å¤æ¸ç ç©¶äººå¡å¾å¾ç¡æ³è¨ç·´ VLMã(ii) ç¼ºä¹å¯è§£éæ§ââé£ä»¥è¿½æº¯ VLM é¯èª¤å°å·é«åå ï¼ä¾å¦è¦è¦ºç·¨ç¢¼ææ¨çå¤±æãæåæåº TextFlowï¼ééå©åéæ®µä¾è§£æ±ºä¸è¿°åé¡ï¼(i) è¦è¦ºæå­åå¨ââå¾æµç¨åå½±åç¢çæå­è¡¨ç¤ºï¼(ii) æå­æ¨çå¨ââæ ¹ææå­è¡¨ç¤ºå·è¡åç­ãTextFlow æä¾äºä¸åä¸»è¦åªé»ï¼(i) ä½¿ç¨èå¯ä»¥é¸ææå­è¡¨ç¤ºçé¡åï¼ä¾å¦ GraphvizãMermaidãPlantUMLï¼ï¼æé²ä¸æ­¥å°å®åè½æçºå¯å·è¡çåå½¢ç©ä»¶ä¾å¼å«å·¥å·ï¼å¢å¼·æè½åå¯æ§æ§ï¼(ii) å®ééå¹«å©æ´æ¸æ¥å°å°é¯èª¤æ­¸å æ¼è¦è¦ºææå­èçåä»¶ä¾æ¹åå¯è§£éæ§ï¼(iii) å®ä¿é²äºè§£æ±ºæ¹æ¡çæ¨¡çµåï¼ä¾å¦åè¨±å¨ VLM å¨ç«¯å°ç«¯æ¨¡å¼ä¸è¡¨ç¾ä¸ä½³æï¼å¨æ¨çå¨éæ®µä½¿ç¨é²é LLMãå¨ FlowVQA å FlowLearn åºæºä¸çå¯¦é©è­æäº TextFlow çæåé²æè½ä»¥åå¶ç©©å¥æ§ãææç¨å¼ç¢¼é½å¬éå¯ç¨ã

##### **HybGRAG: Hybrid Retrieval-Augmented Generation on Textual and Relational Knowledge Bases**
2412.16311v1 by Meng-Chieh Lee, Qi Zhu, Costas Mavromatis, Zhen Han, Soji Adeshina, Vassilis N. Ioannidis, Huzefa Rangwala, Christos Faloutsos

Given a semi-structured knowledge base (SKB), where text documents are
interconnected by relations, how can we effectively retrieve relevant
information to answer user questions? Retrieval-Augmented Generation (RAG)
retrieves documents to assist large language models (LLMs) in question
answering; while Graph RAG (GRAG) uses structured knowledge bases as its
knowledge source. However, many questions require both textual and relational
information from SKB - referred to as "hybrid" questions - which complicates
the retrieval process and underscores the need for a hybrid retrieval method
that leverages both information. In this paper, through our empirical analysis,
we identify key insights that show why existing methods may struggle with
hybrid question answering (HQA) over SKB. Based on these insights, we propose
HybGRAG for HQA consisting of a retriever bank and a critic module, with the
following advantages: (1) Agentic, it automatically refines the output by
incorporating feedback from the critic module, (2) Adaptive, it solves hybrid
questions requiring both textual and relational information with the retriever
bank, (3) Interpretable, it justifies decision making with intuitive refinement
path, and (4) Effective, it surpasses all baselines on HQA benchmarks. In
experiments on the STaRK benchmark, HybGRAG achieves significant performance
gains, with an average relative improvement in Hit@1 of 51%.

æè¦ï¼<paragraph>çµ¦å®ä¸ååçµæ§åç¥è­åº« (SKB)ï¼å¶ä¸­ææ¬æä»¶ç±éä¿ç¸äºé£æ¥ï¼æåå¦ä½ææå°æ·åç¸éè³è¨ä¾åç­ä½¿ç¨èçåé¡ï¼æ·åå¢å¼·çæ (RAG) æ·åæä»¶ä»¥åå©å¤§åèªè¨æ¨¡å (LLM) åç­åé¡ï¼èåå½¢ RAG (GRAG) ä½¿ç¨çµæ§åç¥è­åº«ä½çºå¶ç¥è­ä¾æºãç¶èï¼è¨±å¤åé¡éè¦ä¾èª SKB çæå­åéä¿è³è¨ï¼ç¨±çºãæ··åãåé¡ï¼éä½¿å¾æ·åéç¨è¤éåï¼ä¸¦å¼·èª¿éè¦ä¸ç¨®å©ç¨éå©ç¨®è³è¨çæ··åæ·åæ¹æ³ãå¨æ¬æä¸­ï¼ééæåçå¯¦è­åæï¼æåæ¾åºé¡¯ç¤ºç¾ææ¹æ³å¯è½é£ä»¥å¨ SKB ä¸é²è¡æ··ååé¡è§£ç­ (HQA) çééµè¦è§£ãæ ¹æéäºè¦è§£ï¼æåæåºç±æ·åå¨åº«åæ¹è©æ¨¡çµçµæãå·æä»¥ä¸åªé»ç HQA HybGRAGï¼(1) ä»£çï¼å®ééç´å¥æ¹è©æ¨¡çµçåé¥èªåç²¾çè¼¸åºï¼(2) é©æï¼å®ä½¿ç¨æ·åå¨åº«è§£æ±ºéè¦æå­åéä¿è³è¨çæ··ååé¡ï¼(3) å¯è§£éï¼å®ä»¥ç´è¦ºçç²¾çè·¯å¾è­ææ±ºç­ï¼ä»¥å (4) ææï¼å®è¶è¶äº HQA åºæºçææåºæºãå¨ STaRK åºæºçå¯¦é©ä¸­ï¼HybGRAG éå°äºé¡¯èçæè½æåï¼Hit@1 çå¹³åç¸å°æ¹åçº 51%ã</paragraph>


### Medical
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2025-01-24**|**Do LLMs Provide Consistent Answers to Health-Related Questions across Languages?**|Ipek Baris Schlicht et.al.|[2501.14719v1](http://arxiv.org/abs/2501.14719v1)|null|
|**2025-01-24**|**Rethinking Table Instruction Tuning**|Naihao Deng et.al.|[2501.14693v1](http://arxiv.org/abs/2501.14693v1)|null|
|**2025-01-24**|**Approach to Designing CV Systems for Medical Applications: Data, Architecture and AI**|Dmitry Ryabtsev et.al.|[2501.14689v1](http://arxiv.org/abs/2501.14689v1)|null|
|**2025-01-24**|**Rethinking Foundation Models for Medical Image Classification through a Benchmark Study on MedMNIST**|Fuping Wu et.al.|[2501.14685v1](http://arxiv.org/abs/2501.14685v1)|null|
|**2025-01-24**|**MedAgentBench: Dataset for Benchmarking LLMs as Agents in Medical Applications**|Yixing Jiang et.al.|[2501.14654v1](http://arxiv.org/abs/2501.14654v1)|[link](https://github.com/stanfordmlgroup/medagentbench)|
|**2025-01-24**|**Registration of Longitudinal Liver Examinations for Tumor Progress Assessment**|Walid Yassine et.al.|[2501.14483v1](http://arxiv.org/abs/2501.14483v1)|null|
|**2025-01-24**|**Pesti-Gen: Unleashing a Generative Molecule Approach for Toxicity Aware Pesticide Design**|Taehan Kim et.al.|[2501.14469v1](http://arxiv.org/abs/2501.14469v1)|null|
|**2025-01-24**|**ECTIL: Label-efficient Computational Tumour Infiltrating Lymphocyte (TIL) assessment in breast cancer: Multicentre validation in 2,340 patients with breast cancer**|Yoni Schirris et.al.|[2501.14379v1](http://arxiv.org/abs/2501.14379v1)|null|
|**2025-01-24**|**Enhancing Multimodal Entity Linking with Jaccard Distance-based Conditional Contrastive Learning and Contextual Visual Augmentation**|Cong-Duy Nguyen et.al.|[2501.14166v1](http://arxiv.org/abs/2501.14166v1)|null|
|**2025-01-24**|**Advancing MRI Reconstruction: A Systematic Review of Deep Learning and Compressed Sensing Integration**|Mojtaba Safari et.al.|[2501.14158v1](http://arxiv.org/abs/2501.14158v1)|[link](https://github.com/mosaf/awesome-dl-based-cs-mri)|
|**2025-01-23**|**MedSlice: Fine-Tuned Large Language Models for Secure Clinical Note Sectioning**|Joshua Davis et.al.|[2501.14105v1](http://arxiv.org/abs/2501.14105v1)|[link](https://github.com/lindvalllab/medslice)|
|**2025-01-23**|**Revisiting CLIP: Efficient Alignment of 3D MRI and Tabular Data using Domain-Specific Foundation Models**|Jakob Krogh Petersen et.al.|[2501.14051v1](http://arxiv.org/abs/2501.14051v1)|[link](https://github.com/jakekrogh/3d-clip-for-brain-mri)|
|**2025-01-23**|**Leveraging Multiphase CT for Quality Enhancement of Portal Venous CT: Utility for Pancreas Segmentation**|Xinya Wang et.al.|[2501.14013v1](http://arxiv.org/abs/2501.14013v1)|null|
|**2025-01-23**|**Ensuring Medical AI Safety: Explainable AI-Driven Detection and Mitigation of Spurious Model Behavior and Associated Data**|Frederik Pahde et.al.|[2501.13818v1](http://arxiv.org/abs/2501.13818v1)|[link](https://github.com/frederikpahde/medical-ai-safety)|
|**2025-01-23**|**Question Answering on Patient Medical Records with Private Fine-Tuned LLMs**|Sara Kothari et.al.|[2501.13687v1](http://arxiv.org/abs/2501.13687v1)|null|
|**2025-01-23**|**How to Complete Domain Tuning while Keeping General Ability in LLM: Adaptive Layer-wise and Element-wise Regularization**|Shezheng Song et.al.|[2501.13669v1](http://arxiv.org/abs/2501.13669v1)|null|
|**2025-01-23**|**Contrastive Representation Learning Helps Cross-institutional Knowledge Transfer: A Study in Pediatric Ventilation Management**|Yuxuan et.al.|[2501.13587v1](http://arxiv.org/abs/2501.13587v1)|null|
|**2025-01-23**|**LLMs Can Plan Only If We Tell Them**|Bilgehan Sel et.al.|[2501.13545v1](http://arxiv.org/abs/2501.13545v1)|null|
|**2025-01-23**|**Comprehensive Modeling and Question Answering of Cancer Clinical Practice Guidelines using LLMs**|Bhumika Gupta et.al.|[2501.13984v1](http://arxiv.org/abs/2501.13984v1)|null|
|**2025-01-23**|**A review on development of eco-friendly filters in Nepal for use in cigarettes and masks and Air Pollution Analysis with Machine Learning and SHAP Interpretability**|Bishwash Paneru et.al.|[2501.13369v1](http://arxiv.org/abs/2501.13369v1)|null|
|**2025-01-22**|**QuFeX: Quantum feature extraction module for hybrid quantum-classical deep neural networks**|Naman Jain et.al.|[2501.13165v1](http://arxiv.org/abs/2501.13165v1)|null|
|**2025-01-22**|**AirRadar: Inferring Nationwide Air Quality in China with Deep Neural Networks**|Qiongyan Wang et.al.|[2501.13141v1](http://arxiv.org/abs/2501.13141v1)|null|
|**2025-01-22**|**Estimating the Conformal Prediction Threshold from Noisy Labels**|Coby Penso et.al.|[2501.12749v1](http://arxiv.org/abs/2501.12749v1)|[link](https://github.com/cobypenso/noise-aware-conformal-prediction)|
|**2025-01-22**|**Applications and Challenges of AI and Microscopy in Life Science Research: A Review**|Himanshu Buckchash et.al.|[2501.13135v1](http://arxiv.org/abs/2501.13135v1)|null|
|**2025-01-22**|**FedDAG: Federated Domain Adversarial Generation Towards Generalizable Medical Image Analysis**|Haoxuan Che et.al.|[2501.13967v1](http://arxiv.org/abs/2501.13967v1)|null|
|**2025-01-21**|**Academic Case Reports Lack Diversity: Assessing the Presence and Diversity of Sociodemographic and Behavioral Factors related to Post COVID-19 Condition**|Juan Andres Medina Florez et.al.|[2501.12538v2](http://arxiv.org/abs/2501.12538v2)|null|
|**2025-01-21**|**Efficient Lung Ultrasound Severity Scoring Using Dedicated Feature Extractor**|Jiaqi Guo et.al.|[2501.12524v1](http://arxiv.org/abs/2501.12524v1)|[link](https://github.com/guojiaqi-1020/medivlad)|
|**2025-01-21**|**FuocChuVIP123 at CoMeDi Shared Task: Disagreement Ranking with XLM-Roberta Sentence Embeddings and Deep Neural Regression**|Phuoc Duong Huy Chu et.al.|[2501.12336v1](http://arxiv.org/abs/2501.12336v1)|null|
|**2025-01-21**|**CBVLM: Training-free Explainable Concept-based Large Vision Language Models for Medical Image Classification**|Cristiano PatrÃ­cio et.al.|[2501.12266v1](http://arxiv.org/abs/2501.12266v1)|null|
|**2025-01-21**|**Can open source large language models be used for tumor documentation in Germany? -- An evaluation on urological doctors' notes**|Stefan Lenz et.al.|[2501.12106v1](http://arxiv.org/abs/2501.12106v1)|[link](https://github.com/stefan-m-lenz/urollmeval)|
|**2025-01-21**|**Multi-stage intermediate fusion for multimodal learning to classify non-small cell lung cancer subtypes from CT and PET**|Fatih Aksu et.al.|[2501.12425v1](http://arxiv.org/abs/2501.12425v1)|null|
|**2025-01-21**|**Adaptive Class Learning to Screen Diabetic Disorders in Fundus Images of Eye**|Shramana Dey et.al.|[2501.12048v1](http://arxiv.org/abs/2501.12048v1)|null|
|**2025-01-21**|**Tackling Small Sample Survival Analysis via Transfer Learning: A Study of Colorectal Cancer Prognosis**|Yonghao Zhao et.al.|[2501.12421v1](http://arxiv.org/abs/2501.12421v1)|[link](https://github.com/yonghaozhao722/tsf)|
|**2025-01-21**|**Benchmarking Generative AI for Scoring Medical Student Interviews in Objective Structured Clinical Examinations (OSCEs)**|Jadon Geathers et.al.|[2501.13957v1](http://arxiv.org/abs/2501.13957v1)|null|
|**2025-01-21**|**Data-driven Detection and Evaluation of Damages in Concrete Structures: Using Deep Learning and Computer Vision**|Saeid Ataei et.al.|[2501.11836v1](http://arxiv.org/abs/2501.11836v1)|null|
|**2025-01-20**|**GL-ICNN: An End-To-End Interpretable Convolutional Neural Network for the Diagnosis and Prediction of Alzheimer's Disease**|Wenjie Kang et.al.|[2501.11715v1](http://arxiv.org/abs/2501.11715v1)|null|
|**2025-01-20**|**Human services organizations and the responsible integration of AI: Considering ethics and contextualizing risk(s)**|Brian E. Perron et.al.|[2501.11705v1](http://arxiv.org/abs/2501.11705v1)|null|
|**2025-01-20**|**Spatially-Delineated Domain-Adapted AI Classification: An Application for Oncology Data**|Majid Farhadloo et.al.|[2501.11695v1](http://arxiv.org/abs/2501.11695v1)|null|
|**2025-01-20**|**Multilinguality in LLM-Designed Reward Functions for Restless Bandits: Effects on Task Performance and Fairness**|Ambreesh Parthasarathy et.al.|[2501.13120v1](http://arxiv.org/abs/2501.13120v1)|null|
|**2025-01-20**|**Biomedical Knowledge Graph: A Survey of Domains, Tasks, and Real-World Applications**|Yuxing Lu et.al.|[2501.11632v2](http://arxiv.org/abs/2501.11632v2)|null|
|**2025-01-20**|**Training-free Ultra Small Model for Universal Sparse Reconstruction in Compressed Sensing**|Chaoqing Tang et.al.|[2501.11592v2](http://arxiv.org/abs/2501.11592v2)|[link](https://github.com/billttzqgbt/cscoefficientslearning)|
|**2025-01-20**|**Enhancing Coronary Artery Calcium Scoring via Multi-Organ Segmentation on Non-Contrast Cardiac Computed Tomography**|Jakub Nalepa et.al.|[2501.11428v1](http://arxiv.org/abs/2501.11428v1)|null|
|**2025-01-20**|**RedStar: Does Scaling Long-CoT Data Unlock Better Slow-Reasoning Systems?**|Haotian Xu et.al.|[2501.11284v1](http://arxiv.org/abs/2501.11284v1)|null|
|**2025-01-20**|**Spatiotemporal Air Quality Mapping in Urban Areas Using Sparse Sensor Data, Satellite Imagery, Meteorological Factors, and Spatial Features**|Osama Ahmad et.al.|[2501.11270v1](http://arxiv.org/abs/2501.11270v1)|null|
|**2025-01-20**|**A Layered Multi-Expert Framework for Long-Context Mental Health Assessments**|Jinwen Tang et.al.|[2501.13951v1](http://arxiv.org/abs/2501.13951v1)|null|
|**2025-01-19**|**Clinical trial cohort selection using Large Language Models on n2c2 Challenges**|Chi-en Amy Tai et.al.|[2501.11114v1](http://arxiv.org/abs/2501.11114v1)|null|
|**2025-01-19**|**Enhanced Suicidal Ideation Detection from Social Media Using a CNN-BiLSTM Hybrid Model**|Mohaiminul Islam Bhuiyan et.al.|[2501.11094v1](http://arxiv.org/abs/2501.11094v1)|null|
|**2025-01-18**|**No More Sliding Window: Efficient 3D Medical Image Segmentation with Differentiable Top-k Patch Sampling**|Young Seok Jeon et.al.|[2501.10814v1](http://arxiv.org/abs/2501.10814v1)|null|
|**2025-01-18**|**Efficient Auto-Labeling of Large-Scale Poultry Datasets (ALPD) Using Semi-Supervised Models, Active Learning, and Prompt-then-Detect Approach**|Ramesh Bahadur Bist et.al.|[2501.10809v1](http://arxiv.org/abs/2501.10809v1)|null|
|**2025-01-18**|**MedFILIP: Medical Fine-grained Language-Image Pre-training**|Xinjie Liang et.al.|[2501.10775v1](http://arxiv.org/abs/2501.10775v1)|[link](https://github.com/perceptioncomputinglab/medfilip)|
|**2025-01-18**|**Enhancing Diagnostic in 3D COVID-19 Pneumonia CT-scans through Explainable Uncertainty Bayesian Quantification**|Juan Manuel Liscano Fierro et.al.|[2501.10770v1](http://arxiv.org/abs/2501.10770v1)|null|
|**2025-01-18**|**In the Picture: Medical Imaging Datasets, Artifacts, and their Living Review**|Amelia JimÃ©nez-SÃ¡nchez et.al.|[2501.10727v1](http://arxiv.org/abs/2501.10727v1)|null|
|**2025-01-17**|**An Ontology for Social Determinants of Education (SDoEd) based on Human-AI Collaborative Approach**|Navya Martin Kollapally et.al.|[2501.10300v1](http://arxiv.org/abs/2501.10300v1)|null|
|**2025-01-17**|**SEANN: A Domain-Informed Neural Network for Epidemiological Insights**|Jean-Baptiste Guimbaud et.al.|[2501.10273v1](http://arxiv.org/abs/2501.10273v1)|null|
|**2025-01-17**|**Challenges and recommendations for Electronic Health Records data extraction and preparation for dynamic prediction modelling in hospitalized patients -- a practical guide**|Elena Albu et.al.|[2501.10240v1](http://arxiv.org/abs/2501.10240v1)|null|
|**2025-01-17**|**Generative Artificial Intelligence: Implications for Biomedical and Health Professions Education**|William Hersh et.al.|[2501.10186v1](http://arxiv.org/abs/2501.10186v1)|null|
|**2025-01-17**|**CSSDM Ontology to Enable Continuity of Care Data Interoperability**|Subhashis Das et.al.|[2501.10160v1](http://arxiv.org/abs/2501.10160v1)|null|
|**2025-01-17**|**landmarker: a Toolkit for Anatomical Landmark Localization in 2D/3D Images**|Jef Jonkers et.al.|[2501.10098v1](http://arxiv.org/abs/2501.10098v1)|[link](https://github.com/predict-idlab/landmarker)|
|**2025-01-17**|**Deep Learning for Early Alzheimer Disease Detection with MRI Scans**|Mohammad Rafsan et.al.|[2501.09999v1](http://arxiv.org/abs/2501.09999v1)|[link](https://github.com/rafusan/dl-alzheimer)|
|**2025-01-17**|**Aneumo: A Large-Scale Comprehensive Synthetic Dataset of Aneurysm Hemodynamics**|Xigui Li et.al.|[2501.09980v1](http://arxiv.org/abs/2501.09980v1)|[link](https://github.com/xigui-li/aneumo)|
|**2025-01-17**|**Bias in Decision-Making for AI's Ethical Dilemmas: A Comparative Study of ChatGPT and Claude**|Yile Yan et.al.|[2501.10484v1](http://arxiv.org/abs/2501.10484v1)|null|
|**2025-01-16**|**Bridging Language Barriers in Healthcare: A Study on Arabic LLMs**|Nada Saadi et.al.|[2501.09825v1](http://arxiv.org/abs/2501.09825v1)|null|
|**2025-01-16**|**KU AIGEN ICL EDI@BC8 Track 3: Advancing Phenotype Named Entity Recognition and Normalization for Dysmorphology Physical Examination Reports**|Hajung Kim et.al.|[2501.09744v1](http://arxiv.org/abs/2501.09744v1)|null|
|**2025-01-16**|**Electronic Health Records: Towards Digital Twins in Healthcare**|Muhammet Alkan et.al.|[2501.09640v1](http://arxiv.org/abs/2501.09640v1)|null|
|**2025-01-16**|**Artificial Intelligence-Driven Clinical Decision Support Systems**|Muhammet Alkan et.al.|[2501.09628v1](http://arxiv.org/abs/2501.09628v1)|null|
|**2025-01-16**|**IFRA: a machine learning-based Instrumented Fall Risk Assessment Scale derived from Instrumented Timed Up and Go test in stroke patients**|Simone MacciÃ² et.al.|[2501.09595v1](http://arxiv.org/abs/2501.09595v1)|null|
|**2025-01-16**|**Understanding Mental Health Content on Social Media and Its Effect Towards Suicidal Ideation**|Mohaiminul Islam Bhuiyan et.al.|[2501.09309v1](http://arxiv.org/abs/2501.09309v1)|null|
|**2025-01-16**|**Interpretable Droplet Digital PCR Assay for Trustworthy Molecular Diagnostics**|Yuanyuan Wei et.al.|[2501.09218v1](http://arxiv.org/abs/2501.09218v1)|null|
|**2025-01-15**|**AutoLoop: Fast Visual SLAM Fine-tuning through Agentic Curriculum Learning**|Assaf Lahiany et.al.|[2501.09160v1](http://arxiv.org/abs/2501.09160v1)|null|
|**2025-01-15**|**Benchmarking Robustness of Contrastive Learning Models for Medical Image-Report Retrieval**|Demetrio Deanda et.al.|[2501.09134v1](http://arxiv.org/abs/2501.09134v1)|null|
|**2025-01-15**|**Generative Medical Image Anonymization Based on Latent Code Projection and Optimization**|Huiyu Li et.al.|[2501.09114v1](http://arxiv.org/abs/2501.09114v1)|[link](https://github.com/huiyu-li/gmia)|
|**2025-01-15**|**Development and Validation of the Provider Documentation Summarization Quality Instrument for Large Language Models**|Emma Croxford et.al.|[2501.08977v2](http://arxiv.org/abs/2501.08977v2)|null|
|**2025-01-15**|**An analysis of data variation and bias in image-based dermatological datasets for machine learning classification**|Francisco Mauro et.al.|[2501.08962v1](http://arxiv.org/abs/2501.08962v1)|null|
|**2025-01-15**|**Improving the Efficiency of Self-Supervised Adversarial Training through Latent Clustering-Based Selection**|Somrita Ghosh et.al.|[2501.10466v1](http://arxiv.org/abs/2501.10466v1)|null|
|**2025-01-15**|**Digital Phenotyping for Adolescent Mental Health: A Feasibility Study Employing Machine Learning to Predict Mental Health Risk From Active and Passive Smartphone Data**|Balasundaram Kadirvelu et.al.|[2501.08851v1](http://arxiv.org/abs/2501.08851v1)|null|
|**2025-01-15**|**Spatio-Temporal Foundation Models: Vision, Challenges, and Opportunities**|Adam Goodge et.al.|[2501.09045v1](http://arxiv.org/abs/2501.09045v1)|null|
|**2025-01-14**|**ADAM-1: AI and Bioinformatics for Alzheimer's Detection and Microbiome-Clinical Data Integrations**|Ziyuan Huang et.al.|[2501.08324v1](http://arxiv.org/abs/2501.08324v1)|null|
|**2025-01-14**|**A Feature-Level Ensemble Model for COVID-19 Identification in CXR Images using Choquet Integral and Differential Evolution Optimization**|Amir Reza Takhsha et.al.|[2501.08241v1](http://arxiv.org/abs/2501.08241v1)|null|
|**2025-01-14**|**ASTRID -- An Automated and Scalable TRIaD for the Evaluation of RAG-based Clinical Question Answering Systems**|Mohita Chowdhury et.al.|[2501.08208v1](http://arxiv.org/abs/2501.08208v1)|null|
|**2025-01-14**|**Potential and Perils of Large Language Models as Judges of Unstructured Textual Data**|Rewina Bedemariam et.al.|[2501.08167v2](http://arxiv.org/abs/2501.08167v2)|null|
|**2025-01-14**|**FairTTTS: A Tree Test Time Simulation Method for Fairness-Aware Classification**|Nurit Cohen-Inger et.al.|[2501.08155v1](http://arxiv.org/abs/2501.08155v1)|[link](https://github.com/nuritci/fairttts)|
|**2025-01-14**|**Guiding the classification of hepatocellular carcinoma on 3D CT-scans using deep and handcrafted radiological features**|E. Sarfati et.al.|[2501.08097v1](http://arxiv.org/abs/2501.08097v1)|null|
|**2025-01-14**|**Exploring visual language models as a powerful tool in the diagnosis of Ewing Sarcoma**|Alvaro Pastor-Naranjo et.al.|[2501.08042v1](http://arxiv.org/abs/2501.08042v1)|null|
|**2025-01-14**|**Comprehensive Metapath-based Heterogeneous Graph Transformer for Gene-Disease Association Prediction**|Wentao Cui et.al.|[2501.07970v1](http://arxiv.org/abs/2501.07970v1)|null|
|**2025-01-14**|**Advice for Diabetes Self-Management by ChatGPT Models: Challenges and Recommendations**|Waqar Hussain et.al.|[2501.07931v1](http://arxiv.org/abs/2501.07931v1)|null|
|**2025-01-14**|**Evaluating Computational Accuracy of Large Language Models in Numerical Reasoning Tasks for Healthcare Applications**|Arjun R. Malghan et.al.|[2501.13936v1](http://arxiv.org/abs/2501.13936v1)|null|
|**2025-01-13**|**Large Language Models for Interpretable Mental Health Diagnosis**|Brian Hyeongseok Kim et.al.|[2501.07653v1](http://arxiv.org/abs/2501.07653v1)|null|
|**2025-01-13**|**RadAlign: Advancing Radiology Report Generation with Vision-Language Concept Alignment**|Difei Gu et.al.|[2501.07525v1](http://arxiv.org/abs/2501.07525v1)|[link](https://github.com/difeigu/radalign)|
|**2025-01-13**|**A Survey of Embodied AI in Healthcare: Techniques, Applications, and Opportunities**|Yihao Liu et.al.|[2501.07468v1](http://arxiv.org/abs/2501.07468v1)|null|
|**2025-01-13**|**Diff-Ensembler: Learning to Ensemble 2D Diffusion Models for Volume-to-Volume Medical Image Translation**|Xiyue Zhu et.al.|[2501.07430v1](http://arxiv.org/abs/2501.07430v1)|null|
|**2025-01-13**|**Synthetic Data and Health Privacy**|GwÃ©nolÃ© Abgrall et.al.|[2501.09031v1](http://arxiv.org/abs/2501.09031v1)|null|
|**2025-01-13**|**Natural Language-Assisted Multi-modal Medication Recommendation**|Jie Tan et.al.|[2501.07166v1](http://arxiv.org/abs/2501.07166v1)|[link](https://github.com/jtan1102/nla-mmr_cikm_2024)|
|**2025-01-13**|**CureGraph: Contrastive Multi-Modal Graph Representation Learning for Urban Living Circle Health Profiling and Prediction**|Jinlin Li et.al.|[2501.07157v1](http://arxiv.org/abs/2501.07157v1)|[link](https://github.com/jinlin2021/curegraph)|
|**2025-01-13**|**UNetVL: Enhancing 3D Medical Image Segmentation with Chebyshev KAN Powered Vision-LSTM**|Xuhui Guo et.al.|[2501.07017v2](http://arxiv.org/abs/2501.07017v2)|null|
|**2025-01-13**|**Combining LLM decision and RL action selection to improve RL policy for adaptive interventions**|Karine Karine et.al.|[2501.06980v1](http://arxiv.org/abs/2501.06980v1)|null|
|**2025-01-12**|**Enhancing Patient-Centric Communication: Leveraging LLMs to Simulate Patient Perspectives**|Xinyao Ma et.al.|[2501.06964v1](http://arxiv.org/abs/2501.06964v1)|null|
|**2025-01-12**|**MedGrad E-CLIP: Enhancing Trust and Transparency in AI-Driven Skin Lesion Diagnosis**|Sadia Kamal et.al.|[2501.06887v1](http://arxiv.org/abs/2501.06887v1)|null|
|**2025-01-12**|**A Foundational Generative Model for Breast Ultrasound Image Analysis**|Haojun Yu et.al.|[2501.06869v1](http://arxiv.org/abs/2501.06869v1)|null|
|**2025-01-12**|**A Comprehensive Evaluation of Large Language Models on Mental Illnesses in Arabic Context**|Noureldin Zahran et.al.|[2501.06859v1](http://arxiv.org/abs/2501.06859v1)|null|
|**2025-01-12**|**MEXA-CTP: Mode Experts Cross-Attention for Clinical Trial Outcome Prediction**|Yiqing Zhang et.al.|[2501.06823v1](http://arxiv.org/abs/2501.06823v1)|null|

#### Abstracts
##### **Do LLMs Provide Consistent Answers to Health-Related Questions across Languages?**
2501.14719v1 by Ipek Baris Schlicht, Zhixue Zhao, Burcu Sayin, Lucie Flek, Paolo Rosso

Equitable access to reliable health information is vital for public health,
but the quality of online health resources varies by language, raising concerns
about inconsistencies in Large Language Models (LLMs) for healthcare. In this
study, we examine the consistency of responses provided by LLMs to
health-related questions across English, German, Turkish, and Chinese. We
largely expand the HealthFC dataset by categorizing health-related questions by
disease type and broadening its multilingual scope with Turkish and Chinese
translations. We reveal significant inconsistencies in responses that could
spread healthcare misinformation. Our main contributions are 1) a multilingual
health-related inquiry dataset with meta-information on disease categories, and
2) a novel prompt-based evaluation workflow that enables sub-dimensional
comparisons between two languages through parsing. Our findings highlight key
challenges in deploying LLM-based tools in multilingual contexts and emphasize
the need for improved cross-lingual alignment to ensure accurate and equitable
healthcare information.

æè¦ï¼å¯é çå¥åº·è³è¨çå¬å¹³åå¾å°å¬å±è¡çè³ééè¦ï¼
ä½ç¶²è·¯å¥åº·è³æºçåè³ªå èªè¨èç°ï¼éå¼ç¼äºå°å¤§åèªè¨æ¨¡å (LLM) å¨é«çä¿å¥æ¹é¢çä¸ä¸è´æ§çææãå¨éé ç ç©¶ä¸­ï¼æåæ¢è¨äº LLM å°è±èªãå¾·èªãåè³å¶èªåä¸­æçå¥åº·ç¸éåé¡ææä¾åæçä¸è´æ§ãæåééä¾ç¾çé¡ååé¡å¥åº·ç¸éåé¡ï¼ä¸¦ééåè³å¶èªåä¸­æç¿»è­¯æ´å±å¶å¤èªè¨ç¯åï¼å¤§å¹æ´å±äº HealthFC è³æéãæåæ­é²äºåæä¸­å­å¨é¡¯èçä¸ä¸è´æ§ï¼éå¯è½ææ£å¸é«çä¿å¥é¯èª¤è³è¨ãæåçè²¢ç»ä¸»è¦æ 1) ä¸ååå«ç¾çé¡å¥åè³è¨çå¤èªè¨å¥åº·ç¸éæ¥è©¢è³æéï¼ä»¥å 2) ä¸åæ°ç©çæç¤ºå¼è©ä¼°å·¥ä½æµç¨ï¼å®è½ééè§£æå¨å©ç¨®èªè¨ä¹éé²è¡æ¬¡ç¶­åº¦æ¯è¼ãæåçç ç©¶çµæçªé¡¯äºå¨å¤èªè¨ç°å¢ä¸­é¨ç½²åºæ¼ LLM çå·¥å·çä¸»è¦ææ°ï¼ä¸¦å¼·èª¿éè¦æ¹åè·¨èªè¨å°é½ä»¥ç¢ºä¿æºç¢ºä¸å¬å¹³çé«çä¿å¥è³è¨ã

##### **Rethinking Table Instruction Tuning**
2501.14693v1 by Naihao Deng, Rada Mihalcea

Recent advances in table understanding have focused on instruction-tuning
large language models (LLMs) for table-related tasks. However, existing
research has overlooked the impact of hyperparameter choices and lacks a
comprehensive evaluation of the out-of-domain table understanding ability and
the general capabilities of these table LLMs. In this paper, we evaluate these
abilities in existing table LLMs, and reveal significant declines in both
out-of-domain table understanding and general capabilities compared to their
base models. Through systematic analysis, we show that hyperparameters, such as
learning rate, can significantly influence both table-specific and general
capabilities. Contrary to the existing table instruction-tuning works, we
demonstrate that smaller learning rates and fewer training instances can
enhance table understanding while preserving general capabilities. Based on our
findings, we introduce TAMA, a TAble LLM instruction-tuned from LLaMA 3.1 8B
Instruct, which achieves performance on par with, or surpassing GPT-3.5 and
GPT-4 on table tasks, while maintaining strong out-of-domain generalization and
general capabilities. Our findings highlight the potential for reduced data
annotation costs and more efficient model development through careful
hyperparameter selection.

æè¦ï¼æè¿è¡¨çè§£çé²å±éä¸­å¨æä»¤èª¿æ ¡å¤§åèªè¨æ¨¡å (LLM) ä»¥å·è¡èè¡¨æ ¼ç¸éçä»»åãç¶èï¼ç¾æçç ç©¶å¿½ç¥äºè¶åæ¸é¸æçå½±é¿ï¼ä¸¦ä¸ç¼ºä¹å°é åå¤è¡¨æ ¼çè§£è½ååéäºè¡¨æ ¼ LLM çä¸è¬è½åçå¨é¢è©ä¼°ãå¨æ¬æä¸­ï¼æåè©ä¼°äºç¾æè¡¨æ ¼ LLM ä¸­çéäºè½åï¼ä¸¦æ­ç¤ºäºèå¶åºç¤æ¨¡åç¸æ¯ï¼é åå¤è¡¨æ ¼çè§£åä¸è¬è½åé½æé¡¯èä¸éãééç³»çµ±åæï¼æåè¡¨æè¶åæ¸ï¼ä¾å¦å­¸ç¿çï¼å¯ä»¥é¡¯èå½±é¿ç¹å®è¡¨æ ¼åä¸è¬è½åãèç¾æè¡¨æ ¼æä»¤èª¿æ ¡å·¥ä½ç¸åï¼æåè­æè¼å°çå­¸ç¿çåè¼å°çè¨ç·´å¯¦ä¾å¯ä»¥å¨ä¿çä¸è¬è½åçåæå¢å¼·è¡¨æ ¼çè§£ãæ ¹ææåçç¼ç¾ï¼æåå¼å¥äº TAMAï¼éæ¯ä¸åå¾ LLaMA 3.1 8B Instruct èª¿æ ¡çè¡¨æ ¼ LLMï¼å®å¨è¡¨æ ¼ä»»åä¸å¯¦ç¾äºè GPT-3.5 å GPT-4 ç¸ç¶æè¶è¶çæè½ï¼åæä¿æå¼·å¤§çé åå¤æ¦ååä¸è¬è½åãæåçç¼ç¾å¼·èª¿äºééä»ç´°é¸æè¶åæ¸ï¼éä½è³ææ¨è¨»ææ¬åæ´ææççæ¨¡åéç¼çå¯è½æ§ã

##### **Approach to Designing CV Systems for Medical Applications: Data, Architecture and AI**
2501.14689v1 by Dmitry Ryabtsev, Boris Vasilyev, Sergey Shershakov

This paper introduces an innovative software system for fundus image analysis
that deliberately diverges from the conventional screening approach, opting not
to predict specific diagnoses. Instead, our methodology mimics the diagnostic
process by thoroughly analyzing both normal and pathological features of fundus
structures, leaving the ultimate decision-making authority in the hands of
healthcare professionals. Our initiative addresses the need for objective
clinical analysis and seeks to automate and enhance the clinical workflow of
fundus image examination. The system, from its overarching architecture to the
modular analysis design powered by artificial intelligence (AI) models, aligns
seamlessly with ophthalmological practices. Our unique approach utilizes a
combination of state-of-the-art deep learning methods and traditional computer
vision algorithms to provide a comprehensive and nuanced analysis of fundus
structures. We present a distinctive methodology for designing medical
applications, using our system as an illustrative example. Comprehensive
verification and validation results demonstrate the efficacy of our approach in
revolutionizing fundus image analysis, with potential applications across
various medical domains.

æè¦ï¼æ¬è«æä»ç´¹äºä¸ç¨®åµæ°çè»é«ç³»çµ±ï¼ç¨æ¼ç¼åºå½±ååæï¼å®å»æåé¢å³çµ±çç¯©æª¢æ¹æ³ï¼é¸æä¸é æ¸¬å·é«çè¨ºæ·ãç¸åå°ï¼æåçåææ¹æ³æ¨¡æ¬è¨ºæ·éç¨ï¼å¾¹åºåæç¼åºçµæ§çæ­£å¸¸åççç¹å¾µï¼å°æçµçæ±ºç­æ¬äº¤å°é«çä¿å¥å°æ¥­äººå¡æä¸­ãæåçè¨ç«æ¨å¨æ»¿è¶³å®¢è§è¨åºåæçéæ±ï¼ä¸¦å°æ±èªåååå¼·åç¼åºå½±åæª¢æ¥çè¨åºå·¥ä½æµç¨ãè©²ç³»çµ±å¾å¶æ´é«æ¶æ§å°ç±äººå·¥æºæ§ (AI) æ¨¡åé©åçæ¨¡çµååæè¨­è¨ï¼é½èç¼ç§å¯¦åç¡ç¸«å°é½ãæåç¨ç¹çæ¹æ³çµåäºæåé²çæ·±åº¦å­¸ç¿æ¹æ³åå³çµ±çé»è¦è¦è¦ºæ¼ç®æ³ï¼æä¾ç¼åºçµæ§çå¨é¢ä¸ç´°ç·»çåæãæåæåºäºä¸ç¨®ç¨ç¹çè¨­è¨é«çæç¨æ¹æ³ï¼ä¸¦ä»¥æåçç³»çµ±ä½çºèªªæç¯ä¾ãå¨é¢çé©è­åé©è­çµæè­æäºæåçæ¹æ³å¨é©æ°ç¼åºå½±ååææ¹é¢çæåï¼ä¸¦å·æå¨åç¨®é«çé åçæ½å¨æç¨ã

##### **Rethinking Foundation Models for Medical Image Classification through a Benchmark Study on MedMNIST**
2501.14685v1 by Fuping Wu, Bartlomiej W. Papiez

Foundation models are widely employed in medical image analysis, due to their
high adaptability and generalizability for downstream tasks. With the
increasing number of foundation models being released, model selection has
become an important issue. In this work, we study the capabilities of
foundation models in medical image classification tasks by conducting a
benchmark study on the MedMNIST dataset. Specifically, we adopt various
foundation models ranging from convolutional to Transformer-based models and
implement both end-to-end training and linear probing for all classification
tasks. The results demonstrate the significant potential of these pre-trained
models when transferred for medical image classification. We further conduct
experiments with different image sizes and various sizes of training data. By
analyzing all the results, we provide preliminary, yet useful insights and
conclusions on this topic.

æè¦ï¼åºç¤æ¨¡åå»£æ³ç¨æ¼é«å­¸å½±ååæï¼å çºå®åå°ä¸æ¸¸ä»»åå·æé«åº¦çé©ææ§åæ¦æ¬æ§ãé¨èç¼å¸çåºç¤æ¨¡åæ¸éè¶ä¾è¶å¤ï¼æ¨¡åé¸æå·²æçºä¸åéè¦åé¡ãå¨éé å·¥ä½ä¸­ï¼æåééå° MedMNIST è³æéé²è¡åºæºç ç©¶ä¾ç ç©¶åºç¤æ¨¡åå¨é«å­¸å½±ååé¡ä»»åä¸­çè½åãå·é«ä¾èªªï¼æåæ¡ç¨äºå¾å·ç©å°åºæ¼ Transformer çæ¨¡åç­åç¨®åºç¤æ¨¡åï¼ä¸¦å°ææåé¡ä»»åå¯¦æ½ç«¯å°ç«¯è¨ç·´åç·æ§æ¢æ¸¬ãçµæè­æäºéäºé è¨ç·´æ¨¡åå¨è½ç§»å°é«å­¸å½±ååé¡æå·æé¡¯èçæ½åãæåé²ä¸æ­¥é²è¡äºä¸åå½±åå¤§å°ååç¨®è¨ç·´è³æå¤§å°çå¯¦é©ãééåæææçµæï¼æåå°æ­¤ä¸»é¡æä¾äºåæ­¥ä½æç¨çè¦è§£åçµè«ã

##### **MedAgentBench: Dataset for Benchmarking LLMs as Agents in Medical Applications**
2501.14654v1 by Yixing Jiang, Kameron C. Black, Gloria Geng, Danny Park, Andrew Y. Ng, Jonathan H. Chen

Recent large language models (LLMs) have demonstrated significant
advancements, particularly in their ability to serve as agents thereby
surpassing their traditional role as chatbots. These agents can leverage their
planning and tool utilization capabilities to address tasks specified at a high
level. However, a standardized dataset to benchmark the agent capabilities of
LLMs in medical applications is currently lacking, making the evaluation of
LLMs on complex tasks in interactive healthcare environments challenging. To
address this gap, we introduce MedAgentBench, a broad evaluation suite designed
to assess the agent capabilities of large language models within medical
records contexts. MedAgentBench encompasses 100 patient-specific
clinically-derived tasks from 10 categories written by human physicians,
realistic profiles of 100 patients with over 700,000 data elements, a
FHIR-compliant interactive environment, and an accompanying codebase. The
environment uses the standard APIs and communication infrastructure used in
modern EMR systems, so it can be easily migrated into live EMR systems.
MedAgentBench presents an unsaturated agent-oriented benchmark that current
state-of-the-art LLMs exhibit some ability to succeed at. The best model
(GPT-4o) achieves a success rate of 72%. However, there is still substantial
space for improvement to give the community a next direction to optimize.
Furthermore, there is significant variation in performance across task
categories. MedAgentBench establishes this and is publicly available at
https://github.com/stanfordmlgroup/MedAgentBench , offering a valuable
framework for model developers to track progress and drive continuous
improvements in the agent capabilities of large language models within the
medical domain.

æè¦ï¼<paragraph>æè¿çå¤§åè¯­è¨æ¨¡å (LLM) å·²å±ç¤ºåºæ¾èçè¿æ­¥ï¼ç¹å«æ¯å¨å¶ä½ä¸ºä»£ççè½åæ¹é¢ï¼ä»èè¶è¶äºå¶ä½ä¸ºèå¤©æºå¨äººçä¼ ç»è§è²ãè¿äºä»£çå¯ä»¥å©ç¨å¶è§ååå·¥å·å©ç¨è½åæ¥è§£å³å¨é«å±æå®çä»»å¡ãç¶èï¼ç®åç¼ºä¹ç¨äºå¯¹å»çåºç¨ä¸­ LLM çä»£çè½åè¿è¡åºåæµè¯çæ ååæ°æ®éï¼è¿ä½¿å¾å¨äº¤äºå¼å»çä¿å¥ç¯å¢ä¸­å¯¹ LLM å¨å¤æä»»å¡ä¸çè¯ä¼°å·ææææ§ãä¸ºäºè§£å³è¿ä¸å·®è·ï¼æä»¬å¼å¥äº MedAgentBenchï¼è¿æ¯ä¸ä¸ªå¹¿æ³çè¯ä¼°å¥ä»¶ï¼æ¨å¨è¯ä¼°å¤§åè¯­è¨æ¨¡åå¨å»çè®°å½èæ¯ä¸çä»£çè½åãMedAgentBench åå« 100 ä¸ªç±äººç±»å»çç¼åçæ¥èª 10 ä¸ªç±»å«çç¹å®äºæ£èçä¸´åºä»»å¡ã100 ä¸ªæ£èççå®ä¸ªäººèµæï¼åå«è¶è¿ 700,000 ä¸ªæ°æ®åç´ ï¼ãä¸ä¸ªç¬¦å FHIR çäº¤äºå¼ç¯å¢ä»¥åä¸ä¸ªéå¥çä»£ç åºãè¯¥ç¯å¢ä½¿ç¨ç°ä»£ EMR ç³»ç»ä¸­ä½¿ç¨çæ å API åéä¿¡åºç¡è®¾æ½ï¼å æ­¤å¯ä»¥è½»æ¾å°è¿ç§»å°å®æ¶ EMR ç³»ç»ä¸­ãMedAgentBench åç°äºä¸ä¸ªæªé¥±åçä»¥ä»£çä¸ºå¯¼åçåºåï¼å½åæåè¿ç LLM è¡¨ç°åºä¸å®ç¨åº¦çæåè½åãæå¥½çæ¨¡å (GPT-4o) çæåçè¾¾å° 72%ãç¶èï¼ä»ç¶æå¾å¤§çæ¹è¿ç©ºé´ï¼å¯ä»¥ä¸ºç¤¾åºæä¾ä¼åæ¹åãæ­¤å¤ï¼ä¸åä»»å¡ç±»å«ä¹é´çæ§è½å·®å¼å¾å¤§ãMedAgentBench å»ºç«äºè¿ä¸ç¹ï¼å¹¶å¨ https://github.com/stanfordmlgroup/MedAgentBench å¬å¼æä¾ï¼ä¸ºæ¨¡åå¼åèæä¾äºä¸ä¸ªæä»·å¼çæ¡æ¶ï¼ç¨äºè·è¸ªè¿åº¦å¹¶æ¨å¨å¤§åè¯­è¨æ¨¡åå¨å»çé¢åçä»£çè½åçæç»­æ¹è¿ã</paragraph>

##### **Registration of Longitudinal Liver Examinations for Tumor Progress Assessment**
2501.14483v1 by Walid Yassine, Martin Charachon, CÃ©line Hudelot, Roberto Ardon

Assessing cancer progression in liver CT scans is a clinical challenge,
requiring a comparison of scans at different times for the same patient.
Practitioners must identify existing tumors, compare them with prior exams,
identify new tumors, and evaluate overall disease evolution. This process is
particularly complex in liver examinations due to misalignment between exams
caused by several factors. Indeed, longitudinal liver examinations can undergo
different non-pathological and pathological changes due to non-rigid
deformations, the appearance or disappearance of pathologies, and other
variations. In such cases, existing registration approaches, mainly based on
intrinsic features may distort tumor regions, biasing the tumor progress
evaluation step and the corresponding diagnosis. This work proposes a
registration method based only on geometrical and anatomical information from
liver segmentation, aimed at aligning longitudinal liver images for aided
diagnosis. The proposed method is trained and tested on longitudinal liver CT
scans, with 317 patients for training and 53 for testing. Our experimental
results support our claims by showing that our method is better than other
registration techniques by providing a smoother deformation while preserving
the tumor burden (total volume of tissues considered as tumor) within the
volume. Qualitative results emphasize the importance of smooth deformations in
preserving tumor appearance.

æè¦ï¼è©ä¼°èèé»è¦æ·å±¤ææä¸­çççé²ç¨æ¯ä¸é è¨åºä¸çææ°ï¼
éè¦æ¯è¼åä¸çæ£å¨ä¸åæéé»çææçµæã
å¾æ¥­äººå¡å¿é è¾¨è­ç¾æçè«ç¤ï¼å°å¶èååçæª¢æ¥çµæé²è¡æ¯è¼ï¼
è¾¨è­æ°çè«ç¤ï¼ä¸¦è©ä¼°æ´é«ç¾ççæ¼è®ãç±æ¼ç¨®ç¨®å ç´ é ææª¢æ¥çµæä¹éçé¯ä½ï¼éåéç¨å¨èèæª¢æ¥ä¸­ç¹å¥è¤éãäºå¯¦ä¸ï¼ç¸±åçèèæª¢æ¥å¯è½æå çºéåæ§è®å½¢ãçççåºç¾ææ¶å¤±ï¼ä»¥åå¶ä»è®åèç¢çä¸åçéççæ§åççæ§çè®åãå¨éç¨®ææ³ä¸ï¼ç¾æçéæºæ¹æ³ï¼ä¸»è¦åºæ¼å§å¨ç¹å¾µï¼å¯è½ææ­æ²è«ç¤ååï¼é æè«ç¤é²ç¨è©ä¼°æ­¥é©åç¸æè¨ºæ·çåå·®ãæ¬ç ç©¶æåºäºä¸ç¨®ååºæ¼èèåå²çå¹¾ä½åè§£åè³è¨çéæºæ¹æ³ï¼æ¨å¨å°ç¸±åèèå½±åé²è¡éæºï¼ä»¥åå©è¨ºæ·ãææåºçæ¹æ³å¨ç¸±åèèé»è¦æ·å±¤ææä¸é²è¡è¨ç·´åæ¸¬è©¦ï¼è¨ç·´è³ææ 317 ä½çæ£ï¼æ¸¬è©¦è³ææ 53 ä½ãæåçå¯¦é©çµææ¯ææåçèªªæ³ï¼è­ææåçéæºæ¹æ³æ¯å¶ä»éæºæè¡æ´å¥½ï¼å çºå®å¨ä¿çè«ç¤è² æï¼è¢«è¦çºè«ç¤ççµç¹ç¸½é«ç©ï¼çåæï¼æä¾äºæ´å¹³æ»çè®å½¢ãå®æ§çµæå¼·èª¿äºå¹³æ»è®å½¢å¨ä¿çè«ç¤å¤è§æ¹é¢çéè¦æ§ã

##### **Pesti-Gen: Unleashing a Generative Molecule Approach for Toxicity Aware Pesticide Design**
2501.14469v1 by Taehan Kim, Wonduk Seo

Global climate change has reduced crop resilience and pesticide efficacy,
making reliance on synthetic pesticides inevitable, even though their
widespread use poses significant health and environmental risks. While these
pesticides remain a key tool in pest management, previous machine-learning
applications in pesticide and agriculture have focused on classification or
regression, leaving the fundamental challenge of generating new molecular
structures or designing novel candidates unaddressed. In this paper, we propose
Pesti-Gen, a novel generative model based on variational auto-encoders,
designed to create pesticide candidates with optimized properties for the first
time. Specifically, Pesti-Gen leverages a two-stage learning process: an
initial pre-training phase that captures a generalized chemical structure
representation, followed by a fine-tuning stage that incorporates
toxicity-specific information. The model simultaneously optimizes over multiple
toxicity metrics, such as (1) livestock toxicity and (2) aqua toxicity to
generate environmentally friendly pesticide candidates. Notably, Pesti-Gen
achieves approximately 68\% structural validity in generating new molecular
structures, demonstrating the model's effectiveness in producing optimized and
feasible pesticide candidates, thereby providing a new way for safer and more
sustainable pest management solutions.

æè¦ï¼å¨çæ°£åè®é·éä½äºä½ç©çå¾©ååèæ®ºè²åçæåï¼
ä½¿å¾ä»°è³´åææ®ºè²åæçºç¡å¯é¿åçè¶¨å¢ï¼åç®¡å®åçå»£æ³ä½¿ç¨æå¸¶ä¾éå¤§çå¥åº·åç°å¢é¢¨éªãåç®¡éäºæ®ºè²åä»ç¶æ¯è²å®³ç®¡çä¸­çééµå·¥å·ï¼éå»å¨æ®ºè²ååè¾²æ¥­æ¹é¢çæ©å¨å­¸ç¿æç¨é½èéæ¼åé¡æè¿´æ­¸ï¼èæªè§£æ±ºç¢çæ°çåå­çµæ§æè¨­è¨æ°åé¸è¥åçåºæ¬ææ°ãå¨æ¬æä¸­ï¼æåæåº Pesti-Genï¼ä¸ç¨®åºæ¼è®ç°èªåç·¨ç¢¼å¨çåµæ°çææ¨¡åï¼æ¨å¨é¦æ¬¡å»ºç«å·ææä½³åç¹æ§çæ®ºè²ååé¸è¥åãå·é«ä¾èªªï¼Pesti-Gen æ¡ç¨å©éæ®µå­¸ç¿æµç¨ï¼ä¸åæ·åå»£ç¾©åå­¸çµæ§è¡¨ç¤ºçåå§é è¨ç·´éæ®µï¼æ¥èæ¯ä¸åç´å¥æ¯æ§ç¹å®è³è¨çå¾®èª¿éæ®µãæ­¤æ¨¡ååæéå°å¤ç¨®æ¯æ§ææ¨é²è¡æä½³åï¼ä¾å¦ (1) ç²çæ¯æ§å (2) æ°´çæ¯æ§ï¼ä»¥ç¢çå°ç°å¢ååçæ®ºè²ååé¸è¥åãå¼å¾æ³¨æçæ¯ï¼Pesti-Gen å¨ç¢çæ°çåå­çµæ§æ¹é¢éå°äºç´ 68% ççµæ§æåº¦ï¼è­æäºæ­¤æ¨¡åå¨ç¢çæä½³åä¸å¯è¡çæ®ºè²ååé¸è¥åæ¹é¢çæè½ï¼é²èçºæ´å®å¨ä¸æ´æ°¸çºçè²å®³ç®¡çè§£æ±ºæ¹æ¡æä¾äºä¸ç¨®æ°æ¹æ³ã

##### **ECTIL: Label-efficient Computational Tumour Infiltrating Lymphocyte (TIL) assessment in breast cancer: Multicentre validation in 2,340 patients with breast cancer**
2501.14379v1 by Yoni Schirris, Rosie Voorthuis, Mark Opdam, Marte Liefaard, Gabe S Sonke, Gwen Dackus, Vincent de Jong, Yuwei Wang, Annelot Van Rossum, Tessa G Steenbruggen, Lars C Steggink, Liesbeth G. E. de Vries, Marc van de Vijver, Roberto Salgado, Efstratios Gavves, Paul J van Diest, Sabine C Linn, Jonas Teuwen, Renee Menezes, Marleen Kok, Hugo Horlings

The level of tumour-infiltrating lymphocytes (TILs) is a prognostic factor
for patients with (triple-negative) breast cancer (BC). Computational TIL
assessment (CTA) has the potential to assist pathologists in this
labour-intensive task, but current CTA models rely heavily on many detailed
annotations. We propose and validate a fundamentally simpler deep learning
based CTA that can be trained in only ten minutes on hundredfold fewer
pathologist annotations. We collected whole slide images (WSIs) with TILs
scores and clinical data of 2,340 patients with BC from six cohorts including
three randomised clinical trials. Morphological features were extracted from
whole slide images (WSIs) using a pathology foundation model. Our
label-efficient Computational stromal TIL assessment model (ECTIL) directly
regresses the TILs score from these features. ECTIL trained on only a few
hundred samples (ECTIL-TCGA) showed concordance with the pathologist over five
heterogeneous external cohorts (r=0.54-0.74, AUROC=0.80-0.94). Training on all
slides of five cohorts (ECTIL-combined) improved results on a held-out test set
(r=0.69, AUROC=0.85). Multivariable Cox regression analyses indicated that
every 10% increase of ECTIL scores was associated with improved overall
survival independent of clinicopathological variables (HR 0.86, p<0.01),
similar to the pathologist score (HR 0.87, p<0.001). We demonstrate that ECTIL
is highly concordant with an expert pathologist and obtains a similar hazard
ratio. ECTIL has a fundamentally simpler design than existing methods and can
be trained on orders of magnitude fewer annotations. Such a CTA may be used to
pre-screen patients for, e.g., immunotherapy clinical trial inclusion, or as a
tool to assist clinicians in the diagnostic work-up of patients with BC. Our
model is available under an open source licence
(https://github.com/nki-ai/ectil).

æè¦ï¼è¿ç¤æµ¸æ¶¦æ·å·´ç»è (TIL) çæ°´å¹³æ¯ (ä¸é´æ§) ä¹³èºç (BC) æ£èçé¢åå ç´ ãè®¡ç® TIL è¯ä¼° (CTA) æå¯è½åå©ççå­¦å®¶å®æè¿é¡¹å³å¨å¯éåä»»å¡ï¼ä½ç®åç CTA æ¨¡åä¸¥éä¾èµäºè®¸å¤è¯¦ç»çæ³¨éãæä»¬æåºå¹¶éªè¯äºä¸ä¸ªåºäºæ·±åº¦å­¦ä¹ ç CTAï¼å®å¯ä»¥å¨å ç¾åæ´å°çççå­¦å®¶æ³¨éä¸ä»å¨ååéåè¿è¡è®­ç»ãæä»¬ä»å­ä¸ªéåä¸­æ¶éäº 2,340 å BC æ£èç TILs è¯ååä¸´åºæ°æ®çå¨ç»çå¾å (WSI)ï¼å¶ä¸­åæ¬ä¸é¡¹éæºä¸´åºè¯éªãä½¿ç¨ççåºç¡æ¨¡åä»å¨ç»çå¾å (WSI) ä¸­æåå½¢æå­¦ç¹å¾ãæä»¬çæ ç­¾é«æè®¡ç®åºè´¨ TIL è¯ä¼°æ¨¡å (ECTIL) ç´æ¥ä»è¿äºç¹å¾ä¸­åå½ TILs è¯åãä»å¨å ç¾ä¸ªæ ·æ¬ä¸è¿è¡è®­ç»ç ECTILï¼ECTIL-TCGAï¼æ¾ç¤ºåºä¸ççå­¦å®¶å¨äºä¸ªå¼è´¨å¤é¨éåä¸­çä¸è´æ§ï¼r=0.54-0.74ï¼AUROC=0.80-0.94ï¼ãå¨äºä¸ªéåçææç»çä¸è¿è¡è®­ç»ï¼ECTIL-combinedï¼æ¹åäºä¿çæµè¯éä¸çç»æï¼r=0.69ï¼AUROC=0.85ï¼ãå¤åé Cox åå½åæè¡¨æï¼ECTIL è¯åæ¯å¢å  10%ï¼ä¸ä¸´åºççå­¦åéæ å³çæ»ä½çå­çå°±ä¼æé«ï¼HR 0.86ï¼p<0.01ï¼ï¼ç±»ä¼¼äºççå­¦å®¶è¯åï¼HR 0.87ï¼p<0.001ï¼ãæä»¬è¯æ ECTIL ä¸ä¸å®¶ççå­¦å®¶é«åº¦ä¸è´ï¼å¹¶è·å¾äºç±»ä¼¼çé£é©æ¯ãECTIL çè®¾è®¡æ¯ç°ææ¹æ³ä»æ ¹æ¬ä¸æ´ç®åï¼å¹¶ä¸å¯ä»¥å¨æ°éçº§æ´å°çæ³¨éä¸è¿è¡è®­ç»ãè¿ç§ CTA å¯ç¨äºå¯¹æ£èè¿è¡é¢ç­éï¼ä¾å¦åç«æ²»çä¸´åºè¯éªçº³å¥ï¼æä½ä¸ºä¸ç§å·¥å·æ¥å¸®å©ä¸´åºå»çå¯¹ BC æ£èè¿è¡è¯æ­æ£æ¥ãæä»¬çæ¨¡åå¯å¨å¼æ¾æºä»£ç è®¸å¯ä¸è·å¾ (https://github.com/nki-ai/ectil)ã

##### **Enhancing Multimodal Entity Linking with Jaccard Distance-based Conditional Contrastive Learning and Contextual Visual Augmentation**
2501.14166v1 by Cong-Duy Nguyen, Xiaobao Wu, Thong Nguyen, Shuai Zhao, Khoi Le, Viet-Anh Nguyen, Feng Yichao, Anh Tuan Luu

Previous research on multimodal entity linking (MEL) has primarily employed
contrastive learning as the primary objective. However, using the rest of the
batch as negative samples without careful consideration, these studies risk
leveraging easy features and potentially overlook essential details that make
entities unique. In this work, we propose JD-CCL (Jaccard Distance-based
Conditional Contrastive Learning), a novel approach designed to enhance the
ability to match multimodal entity linking models. JD-CCL leverages
meta-information to select negative samples with similar attributes, making the
linking task more challenging and robust. Additionally, to address the
limitations caused by the variations within the visual modality among mentions
and entities, we introduce a novel method, CVaCPT (Contextual Visual-aid
Controllable Patch Transform). It enhances visual representations by
incorporating multi-view synthetic images and contextual textual
representations to scale and shift patch representations. Experimental results
on benchmark MEL datasets demonstrate the strong effectiveness of our approach.

æè¦ï¼ååéå°å¤æ¨¡æå¯¦é«é£çµ (MEL) çç ç©¶ä¸»è¦æ¡ç¨å°æ¯å­¸ç¿ä½çºä¸»è¦ç®æ¨ãç¶èï¼éäºç ç©¶å¨æªç¶ä»ç´°èéçææ³ä¸å°æ¹æ¬¡å¶é¤é¨åç¨ä½è² æ¨£æ¬ï¼å æ­¤æé¢¨éªæå©ç¨å®¹æè¾¨è­çç¹å¾µï¼ä¸¦å¯è½å¿½ç¥ä½¿å¯¦é«ç¨ä¸ç¡äºçéè¦ç´°ç¯ãå¨æ¬æä¸­ï¼æåæåº JD-CCLï¼Jaccard è·é¢åºç¤æ¢ä»¶å°æ¯å­¸ç¿ï¼ï¼éæ¯ä¸ç¨®æ°ç©çæ¹æ³ï¼æ¨å¨å¢å¼·å¤æ¨¡æå¯¦é«é£çµæ¨¡åçå¹éè½åãJD-CCL å©ç¨åè³è¨ä¾é¸æå·æé¡ä¼¼å±¬æ§çè² æ¨£æ¬ï¼ä½¿é£çµä»»åæ´å·ææ°æ§åç©©å¥æ§ãæ­¤å¤ï¼çºäºè§£æ±ºå¨æååå¯¦é«ä¹éçè¦è¦ºæ¨¡å¼ä¸­è®ç°æé æçéå¶ï¼æåå¼å¥äºä¸ç¨®æ°æ¹æ³ï¼ç¨±çº CVaCPTï¼èçµ¡è¦è¦ºè¼å©å¯æ§åå¡è½æï¼ãå®ééçµåå¤è¦è§åæå½±ååèçµ¡æå­è¡¨å¾µä¾å¢å¼·è¦è¦ºè¡¨å¾µï¼ä»¥ç¸®æ¾åè½ç§»åå¡è¡¨å¾µãå¨åºæº MEL è³æéä¸çå¯¦é©çµæè­æäºæåæ¹æ³çå¼·å¤§æè½ã

##### **Advancing MRI Reconstruction: A Systematic Review of Deep Learning and Compressed Sensing Integration**
2501.14158v1 by Mojtaba Safari, Zach Eidex, Chih-Wei Chang, Richard L. J. Qiu, Xiaofeng Yang

Magnetic resonance imaging (MRI) is a non-invasive imaging modality and
provides comprehensive anatomical and functional insights into the human body.
However, its long acquisition times can lead to patient discomfort, motion
artifacts, and limiting real-time applications. To address these challenges,
strategies such as parallel imaging have been applied, which utilize multiple
receiver coils to speed up the data acquisition process. Additionally,
compressed sensing (CS) is a method that facilitates image reconstruction from
sparse data, significantly reducing image acquisition time by minimizing the
amount of data collection needed. Recently, deep learning (DL) has emerged as a
powerful tool for improving MRI reconstruction. It has been integrated with
parallel imaging and CS principles to achieve faster and more accurate MRI
reconstructions. This review comprehensively examines DL-based techniques for
MRI reconstruction. We categorize and discuss various DL-based methods,
including end-to-end approaches, unrolled optimization, and federated learning,
highlighting their potential benefits. Our systematic review highlights
significant contributions and underscores the potential of DL in MRI
reconstruction. Additionally, we summarize key results and trends in DL-based
MRI reconstruction, including quantitative metrics, the dataset, acceleration
factors, and the progress of and research interest in DL techniques over time.
Finally, we discuss potential future directions and the importance of DL-based
MRI reconstruction in advancing medical imaging. To facilitate further research
in this area, we provide a GitHub repository that includes up-to-date DL-based
MRI reconstruction publications and public
datasets-https://github.com/mosaf/Awesome-DL-based-CS-MRI.

æè¦ï¼ç£å±æ¯æå (MRI) æ¯ä¸ç¨®éä¾µå¥æ§çå½±åæ¨¡å¼ï¼å¯æä¾äººé«å¨é¢çè§£åååè½è¦è§£ãç¶èï¼å¶æ¼«é·çæ·åæéå¯è½æå°è´æ£èä¸é©ãåä½å½å½±ï¼ä¸¦éå¶å¯¦ææç¨ãçºäºæå°éäºææ°ï¼å·²æç¨å¹³è¡å½±åç­ç­ç¥ï¼å©ç¨å¤åæ¥æ¶å¨ç·åä¾å éè³ææ·åéç¨ãæ­¤å¤ï¼å£ç¸®ææ¸¬ (CS) æ¯ä¸ç¨®ä¿é²å¾ç¨çè³æä¸­éå»ºå½±åçæ¹æ³ï¼ééå°æéçè³ææ¶ééæ¸è³æå°ï¼å¤§å¹ç¸®ç­å½±åæ·åæéãæè¿ï¼æ·±åº¦å­¸ç¿ (DL) å·²æçºæ¹é² MRI éå»ºçå¼·å¤§å·¥å·ãå®å·²èå¹³è¡å½±åå CS åçæ´åï¼ä»¥å¯¦ç¾æ´å¿«ãæ´æºç¢ºç MRI éå»ºãæ¬ç¯è©è«å¨é¢æ¢è¨äºåºæ¼ DL ç MRI éå»ºæè¡ãæåå°åç¨®åºæ¼ DL çæ¹æ³é²è¡åé¡åè¨è«ï¼åæ¬ç«¯å°ç«¯æ¹æ³ãå±éæä½³ååè¯åå­¸ç¿ï¼ä¸¦å¼·èª¿å¶æ½å¨åªé»ãæåçç³»çµ±æ§è©è«çªåºäºéè¦çè²¢ç»ï¼ä¸¦å¼·èª¿äº DL å¨ MRI éå»ºä¸­çæ½åãæ­¤å¤ï¼æåç¸½çµäºåºæ¼ DL ç MRI éå»ºä¸­çééµçµæåè¶¨å¢ï¼åæ¬éåææ¨ãè³æéãå éå å­ï¼ä»¥å DL æè¡é¨æéçé²å±åç ç©¶èè¶£ãæå¾ï¼æåè¨è«äºæ½å¨çæªä¾æ¹åï¼ä»¥ååºæ¼ DL ç MRI éå»ºå¨æ¨é²é«å­¸å½±åä¸­çéè¦æ§ãçºäºä¿é²éæ¹é¢çé²ä¸æ­¥ç ç©¶ï¼æåæä¾äºä¸å GitHub å²å­åº«ï¼å¶ä¸­åæ¬ææ°çåºæ¼ DL ç MRI éå»ºåºçç©åå¬éè³æé - https://github.com/mosaf/Awesome-DL-based-CS-MRIã

##### **MedSlice: Fine-Tuned Large Language Models for Secure Clinical Note Sectioning**
2501.14105v1 by Joshua Davis, Thomas Sounack, Kate Sciacca, Jessie M Brain, Brigitte N Durieux, Nicole D Agaronnik, Charlotta Lindvall

Extracting sections from clinical notes is crucial for downstream analysis
but is challenging due to variability in formatting and labor-intensive nature
of manual sectioning. While proprietary large language models (LLMs) have shown
promise, privacy concerns limit their accessibility. This study develops a
pipeline for automated note sectioning using open-source LLMs, focusing on
three sections: History of Present Illness, Interval History, and Assessment
and Plan. We fine-tuned three open-source LLMs to extract sections using a
curated dataset of 487 progress notes, comparing results relative to
proprietary models (GPT-4o, GPT-4o mini). Internal and external validity were
assessed via precision, recall and F1 score. Fine-tuned Llama 3.1 8B
outperformed GPT-4o (F1=0.92). On the external validity test set, performance
remained high (F1= 0.85). Fine-tuned open-source LLMs can surpass proprietary
models in clinical note sectioning, offering advantages in cost, performance,
and accessibility.

æè¦ï¼å¾è¨åºè¨éä¸­èååå¡å°æ¼ä¸æ¸¸åæè³ééè¦ï¼ä½ç±æ¼æ ¼å¼è®ç°åæåååçååå¯éæ§è³ªï¼éæ¯ä¸é ææ°ãå°æå¤§åèªè¨æ¨¡å (LLM) å·²å±ç¾æ½åï¼ä½é±ç§åé¡éå¶äºå¶å¯åæ§ãæ¬ç ç©¶éç¼äºä¸åä½¿ç¨éæ¾åå§ç¢¼ LLM çèªååè¨éååç®¡ç·ï¼å°æ³¨æ¼ä¸ååå¡ï¼ç¾çå²ãééçå²ä»¥åè©ä¼°åè¨ç«ãæåå¾®èª¿äºä¸åéæ¾åå§ç¢¼ LLM ä»¥ä½¿ç¨ 487 åé²åº¦è¨éçç²¾é¸è³æéèååå¡ï¼ä¸¦å°çµæèå°ææ¨¡å (GPT-4oãGPT-4o mini) é²è¡æ¯è¼ãå§é¨åå¤é¨æåº¦ééæºç¢ºåº¦ãå¬åçå F1 åæ¸é²è¡è©ä¼°ãå¾®èª¿å¾ç Llama 3.1 8B åªæ¼ GPT-4o (F1=0.92)ãå¨å¤é¨æåº¦æ¸¬è©¦éä¸­ï¼æè½ä»ç¶å¾é« (F1= 0.85)ãå¾®èª¿å¾çéæ¾åå§ç¢¼ LLM è½å¨è¨åºè¨éååä¸­è¶è¶å°ææ¨¡åï¼å¨ææ¬ãæè½åå¯åæ§æ¹é¢æä¾åªå¢ã

##### **Revisiting CLIP: Efficient Alignment of 3D MRI and Tabular Data using Domain-Specific Foundation Models**
2501.14051v1 by Jakob Krogh Petersen, Valdemar Licht, Mads Nielsen, AsbjÃ¸rn Munk

Multi-modal models require aligned, shared embedding spaces. However, common
CLIP-based approaches need large amounts of samples and do not natively support
3D or tabular data, both of which are crucial in the medical domain. To address
these issues, we revisit CLIP-style alignment by training a domain-specific 3D
foundation model as an image encoder and demonstrate that modality alignment is
feasible with only 62 MRI scans. Our approach is enabled by a simple embedding
accumulation strategy required for training in 3D, which scales the amount of
negative pairs across batches in order to stabilize training. We perform a
thorough evaluation of various design choices, including the choice of backbone
and loss functions, and evaluate the proposed methodology on zero-shot
classification and image-retrieval tasks. While zero-shot image-retrieval
remains challenging, zero-shot classification results demonstrate that the
proposed approach can meaningfully align the representations of 3D MRI with
tabular data.

æè¦ï¼å¤æ¨¡ææ¨¡åéè¦å°é½çå±ç¨åµå¥ç©ºéãç¶èï¼å¸¸è¦çåºæ¼ CLIP çæ¹æ³éè¦å¤§éçæ¨£æ¬ï¼ä¸¦ä¸åçä¸æ¯æ´ 3D æè¡¨æ ¼è³æï¼èéå©èå¨é«çé åä¸­é½è³ééè¦ãçºäºè§£æ±ºéäºåé¡ï¼æåééè¨ç·´ä¸åé åç¹å®ç 3D åºç¤æ¨¡åä½çºå½±åç·¨ç¢¼å¨ï¼éæ°æª¢è¦ CLIP é¢¨æ ¼çå°é½ï¼ä¸¦è­æåªè¦ 62 å MRI ææå³å¯éææ¨¡æå°é½ãæåçåæ³å¾çæ¼ä¸åç°¡å®çåµå¥ç´¯ç©ç­ç¥ï¼éæ¯ 3D è¨ç·´æå¿éçï¼å®æèª¿æ´æ¹æ¬¡ä¸­çè² å°æ¸éä»¥ç©©å®è¨ç·´ãæåå°åç¨®è¨­è¨é¸æé²è¡äºå¾¹åºçè©ä¼°ï¼åæ¬ä¸»å¹¹åæå¤±å½æ¸çé¸æï¼ä¸¦å¨é¶æ¨£æ¬åé¡åå½±åæª¢ç´¢ä»»åä¸è©ä¼°ææåºçæ¹æ³ãåç®¡é¶æ¨£æ¬å½±åæª¢ç´¢ä»ç¶å·æææ°æ§ï¼ä½é¶æ¨£æ¬åé¡çµæè­æï¼ææåºçæ¹æ³å¯ä»¥ææç¾©å°å° 3D MRI çè¡¨ç¤ºèè¡¨æ ¼è³æå°é½ã

##### **Leveraging Multiphase CT for Quality Enhancement of Portal Venous CT: Utility for Pancreas Segmentation**
2501.14013v1 by Xinya Wang, Tejas Sudharshan Mathai, Boah Kim, Ronald M. Summers

Multiphase CT studies are routinely obtained in clinical practice for
diagnosis and management of various diseases, such as cancer. However, the CT
studies can be acquired with low radiation doses, different scanners, and are
frequently affected by motion and metal artifacts. Prior approaches have
targeted the quality improvement of one specific CT phase (e.g., non-contrast
CT). In this work, we hypothesized that leveraging multiple CT phases for the
quality enhancement of one phase may prove advantageous for downstream tasks,
such as segmentation. A 3D progressive fusion and non-local (PFNL) network was
developed. It was trained with three degraded (low-quality) phases
(non-contrast, arterial, and portal venous) to enhance the quality of the
portal venous phase. Then, the effect of scan quality enhancement was evaluated
using a proxy task of pancreas segmentation, which is useful for tracking
pancreatic cancer. The proposed approach improved the pancreas segmentation by
3% over the corresponding low-quality CT scan. To the best of our knowledge, we
are the first to harness multiphase CT for scan quality enhancement and
improved pancreas segmentation.

æè¦ï¼å¤ç¸é»è¦æ·å±¤ææç ç©¶å¨è¨åºå¯¦åä¸­å¸¸è¦åå¾ï¼ç¨æ¼è¨ºæ·åç®¡çåç¨®ç¾çï¼ä¾å¦ççãç¶èï¼é»è¦æ·å±¤ææç ç©¶å¯ä»¥ç¨ä½è¼»å°åéãä¸åçææååå¾ï¼ä¸ç¶å¸¸åå°éååéå±¬è£½åå½±é¿ãååçåæ³å·²éå°ç¹å®é»è¦æ·å±¤ææç¸ä½ï¼ä¾å¦éå°æ¯é»è¦æ·å±¤ææï¼çåè³ªæ¹åãå¨éé å·¥ä½ä¸­ï¼æååè¨­å©ç¨å¤åé»è¦æ·å±¤ææç¸ä½ä¾æ¹åä¸åç¸ä½çåè³ªï¼å¯è½æå°ä¸æ¸¸ä»»åï¼ä¾å¦åå²ï¼æå©ãéç¼äºä¸å 3D æ¼¸é²èååéå±é¨ (PFNL) ç¶²è·¯ãå®ä½¿ç¨ä¸åéåçï¼ä½åè³ªï¼ç¸ä½ï¼éå°æ¯ãåèåééèï¼é²è¡è¨ç·´ï¼ä»¥å¢å¼·ééèç¸ä½çåè³ªãç¶å¾ï¼ä½¿ç¨è°èåå²çä»£çä»»åè©ä¼°ææåè³ªæ¹åçææï¼éå°æ¼è¿½è¹¤è°èçå¾æç¨ãææåºçæ¹æ³å°è°èåå²æ¹åäº 3%ï¼é«æ¼å°æçä½åè³ªé»è¦æ·å±¤ææãææåæç¥ï¼æåæ¯ç¬¬ä¸åå©ç¨å¤ç¸é»è¦æ·å±¤ææé²è¡ææåè³ªæ¹ååæ¹åè°èåå²çäººã

##### **Ensuring Medical AI Safety: Explainable AI-Driven Detection and Mitigation of Spurious Model Behavior and Associated Data**
2501.13818v1 by Frederik Pahde, Thomas Wiegand, Sebastian Lapuschkin, Wojciech Samek

Deep neural networks are increasingly employed in high-stakes medical
applications, despite their tendency for shortcut learning in the presence of
spurious correlations, which can have potentially fatal consequences in
practice. Detecting and mitigating shortcut behavior is a challenging task that
often requires significant labeling efforts from domain experts. To alleviate
this problem, we introduce a semi-automated framework for the identification of
spurious behavior from both data and model perspective by leveraging insights
from eXplainable Artificial Intelligence (XAI). This allows the retrieval of
spurious data points and the detection of model circuits that encode the
associated prediction rules. Moreover, we demonstrate how these shortcut
encodings can be used for XAI-based sample- and pixel-level data annotation,
providing valuable information for bias mitigation methods to unlearn the
undesired shortcut behavior. We show the applicability of our framework using
four medical datasets across two modalities, featuring controlled and
real-world spurious correlations caused by data artifacts. We successfully
identify and mitigate these biases in VGG16, ResNet50, and contemporary Vision
Transformer models, ultimately increasing their robustness and applicability
for real-world medical tasks.

æè¦ï¼æ·±åº¦ç¥ç»ç½ç»è¶æ¥è¶å¤å°ç¨äºé«é£é©å»çåºç¨ä¸­ï¼å°½ç®¡å®ä»¬å¨å­å¨èåç¸å³æ§çæåµä¸å¾åäºæ·å¾å­¦ä¹ ï¼è¿å¨å®è·µä¸­å¯è½äº§çè´å½çåæãæ£æµåç¼è§£æ·å¾è¡ä¸ºæ¯ä¸é¡¹è°å·¨çä»»å¡ï¼éå¸¸éè¦é¢åä¸å®¶çå¤§éæ è®°å·¥ä½ãä¸ºäºç¼è§£è¿ä¸ªé®é¢ï¼æä»¬å¼å¥äºä¸ä¸ªåèªå¨æ¡æ¶ï¼ç¨äºä»æ°æ®åæ¨¡åçè§åº¦è¯å«èåè¡ä¸ºï¼æ¹æ³æ¯å©ç¨å¯è§£éäººå·¥æºè½ (XAI) çè§è§£ãè¿åè®¸æ£ç´¢èåæ°æ®ç¹å¹¶æ£æµå¯¹å³èé¢æµè§åè¿è¡ç¼ç çæ¨¡åçµè·¯ãæ­¤å¤ï¼æä»¬æ¼ç¤ºäºå¦ä½ä½¿ç¨è¿äºæ·å¾ç¼ç è¿è¡åºäº XAI çæ ·æ¬ååç´ çº§æ°æ®æ³¨éï¼ä¸ºåå·®ç¼è§£æ¹æ³æä¾æä»·å¼çä¿¡æ¯ï¼ä»¥æ¶é¤ä¸éè¦çæ·å¾è¡ä¸ºãæä»¬ä½¿ç¨è·¨è¶ä¸¤ç§æ¹å¼çåä¸ªå»å­¦æ°æ®éå±ç¤ºäºæä»¬æ¡æ¶çéç¨æ§ï¼è¿äºæ°æ®éå·æç±æ°æ®ä¼ªåå¼èµ·çåæ§åçå®ä¸çèåç¸å³æ§ãæä»¬æåå°è¯å«å¹¶åè½»äº VGG16ãResNet50 åå½ä»£ Vision Transformer æ¨¡åä¸­çè¿äºåå·®ï¼æç»æé«äºå®ä»¬çé²æ£æ§åå¨çå®ä¸çå»çä»»å¡ä¸­çéç¨æ§ã

##### **Question Answering on Patient Medical Records with Private Fine-Tuned LLMs**
2501.13687v1 by Sara Kothari, Ayush Gupta

Healthcare systems continuously generate vast amounts of electronic health
records (EHRs), commonly stored in the Fast Healthcare Interoperability
Resources (FHIR) standard. Despite the wealth of information in these records,
their complexity and volume make it difficult for users to retrieve and
interpret crucial health insights. Recent advances in Large Language Models
(LLMs) offer a solution, enabling semantic question answering (QA) over medical
data, allowing users to interact with their health records more effectively.
However, ensuring privacy and compliance requires edge and private deployments
of LLMs.
  This paper proposes a novel approach to semantic QA over EHRs by first
identifying the most relevant FHIR resources for a user query (Task1) and
subsequently answering the query based on these resources (Task2). We explore
the performance of privately hosted, fine-tuned LLMs, evaluating them against
benchmark models such as GPT-4 and GPT-4o. Our results demonstrate that
fine-tuned LLMs, while 250x smaller in size, outperform GPT-4 family models by
0.55% in F1 score on Task1 and 42% on Meteor Task in Task2. Additionally, we
examine advanced aspects of LLM usage, including sequential fine-tuning, model
self-evaluation (narcissistic evaluation), and the impact of training data size
on performance. The models and datasets are available here:
https://huggingface.co/genloop

æè¦ï¼é«çä¿å¥ç³»çµ±æçºç¢çå¤§éçé»å­å¥åº·ç´é (EHR)ï¼éå¸¸å²å­å¨å¿«éé«çäºéæ§è³æº (FHIR) æ¨æºä¸­ãåç®¡éäºç´éä¸­åå«è±å¯çè³è¨ï¼ä½å¶è¤éæ§åé¾å¤§æ¸éè®ä½¿ç¨èé£ä»¥æ·ååè©®ééè¦çå¥åº·è¦è§£ãå¤§åèªè¨æ¨¡å (LLM) çææ°é²å±æä¾äºè§£æ±ºæ¹æ¡ï¼è½å°é«çè³æé²è¡èªç¾©åç­ (QA)ï¼è®ä½¿ç¨èè½æ´ææå°èå¶å¥åº·ç´éäºåãç¶èï¼ç¢ºä¿é±ç§åç¸å®¹æ§éè¦ LLM çéç·£åç§äººé¨ç½²ãæ¬ææåºäºèªç¾©åç­çæ°æ¹æ³ï¼åæ¾åºèä½¿ç¨èæ¥è©¢æç¸éç FHIR è³æº (ä»»å 1)ï¼ç¶å¾æ ¹æéäºè³æºåç­æ¥è©¢ (ä»»å 2)ãæåæ¢è¨äºç§äººä¸»æ©ãå¾®èª¿ LLM çæè½ï¼ä¸¦æ ¹æ GPT-4 å GPT-4o ç­åºæºæ¨¡åè©ä¼°å®åãæåççµæé¡¯ç¤ºï¼å¾®èª¿ LLM çå¤§å°éç¶å° 250 åï¼ä½å¨ä»»å 1 ç F1 åæ¸ä¸åªæ¼ GPT-4 ç³»åæ¨¡å 0.55%ï¼å¨ä»»å 2 ç Meteor ä»»åä¸­åªæ¼ 42%ãæ­¤å¤ï¼æåæ¢è¨äº LLM ä½¿ç¨çé«éé¢åï¼åæ¬å¾ªåºå¾®èª¿ãæ¨¡åèªæè©ä¼°ï¼èªæå¼è©ä¼°ï¼åè¨ç·´è³æå¤§å°å°æè½çå½±é¿ãæ¨¡ååè³æéå¨æ­¤èæä¾ï¼https://huggingface.co/genloop

##### **How to Complete Domain Tuning while Keeping General Ability in LLM: Adaptive Layer-wise and Element-wise Regularization**
2501.13669v1 by Shezheng Song, Hao Xu, Jun Ma, Shasha Li, Long Peng, Qian Wan, Xiaodong Liu, Jie Yu

Large Language Models (LLMs) exhibit strong general-purpose language
capabilities. However, fine-tuning these models on domain-specific tasks often
leads to catastrophic forgetting, where the model overwrites or loses essential
knowledge acquired during pretraining. This phenomenon significantly limits the
broader applicability of LLMs. To address this challenge, we propose a novel
approach to compute the element-wise importance of model parameters crucial for
preserving general knowledge during fine-tuning. Our method utilizes a
dual-objective optimization strategy: (1) regularization loss to retain the
parameter crucial for general knowledge; (2) cross-entropy loss to adapt to
domain-specific tasks. Additionally, we introduce layer-wise coefficients to
account for the varying contributions of different layers, dynamically
balancing the dual-objective optimization. Extensive experiments on scientific,
medical, and physical tasks using GPT-J and LLaMA-3 demonstrate that our
approach mitigates catastrophic forgetting while enhancing model adaptability.
Compared to previous methods, our solution is approximately 20 times faster and
requires only 10%-15% of the storage, highlighting the practical efficiency.
The code will be released.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å±ç¾å¼·å¤§çéç¨èªè¨è½åãç¶èï¼éå°ç¹å®é åä»»åå¾®èª¿éäºæ¨¡åæï¼å¸¸å¸¸æå°è´ç½é£æ§éºå¿ï¼æ¨¡åæè¦å¯«æéºå¤±é è¨ç·´æéç¿å¾çåºæ¬ç¥è­ãéç¨®ç¾è±¡å¤§å¹éå¶äº LLM çå»£æ³é©ç¨æ§ãçºäºæå°éé ææ°ï¼æåæåºäºä¸ç¨®æ°ç©æ¹æ³ï¼ç¨æ¼è¨ç®æ¨¡ååæ¸çåç´ ç´éè¦æ§ï¼éäºåæ¸å°æ¼å¨å¾®èª¿æéä¿çä¸è¬ç¥è­è³ééè¦ãæåçåæ³æ¡ç¨éç®æ¨åªåç­ç¥ï¼(1) æ­£ååæå¤±ï¼ç¨æ¼ä¿çå°ä¸è¬ç¥è­è³ééè¦çåæ¸ï¼(2) äº¤åçµæå¤±ï¼ç¨æ¼é©æç¹å®é åçä»»åãæ­¤å¤ï¼æåå¼å¥äºå±¤ç´ä¿æ¸ï¼ç¨æ¼èéä¸åå±¤çè®ç°è²¢ç»ï¼ä¸¦åæå¹³è¡¡éç®æ¨åªåãä½¿ç¨ GPT-J å LLaMA-3 å¨ç§å­¸ãé«çåç©çä»»åä¸é²è¡çå»£æ³å¯¦é©è­æï¼æåçåæ³æ¸è¼äºç½é£æ§éºå¿ï¼åæå¢å¼·äºæ¨¡åé©ææ§ãèä¹åçåæ³ç¸æ¯ï¼æåçè§£æ±ºæ¹æ¡éåº¦å¿«äºç´ 20 åï¼èä¸åªéè¦ 10%-15% çå²å­ç©ºéï¼çªé¡¯äºå¶å¯¦ç¨çæçãç¨å¼ç¢¼å°æéåºã

##### **Contrastive Representation Learning Helps Cross-institutional Knowledge Transfer: A Study in Pediatric Ventilation Management**
2501.13587v1 by Yuxuan, Liu, Jinpei Han, Padmanabhan Ramnarayan, A. Aldo Faisal

Clinical machine learning deployment across institutions faces significant
challenges when patient populations and clinical practices differ
substantially. We present a systematic framework for cross-institutional
knowledge transfer in clinical time series, demonstrated through pediatric
ventilation management between a general pediatric intensive care unit (PICU)
and a cardiac-focused unit. Using contrastive predictive coding (CPC) for
representation learning, we investigate how different data regimes and
fine-tuning strategies affect knowledge transfer across institutional
boundaries. Our results show that while direct model transfer performs poorly,
CPC with appropriate fine-tuning enables effective knowledge sharing between
institutions, with benefits particularly evident in limited data scenarios.
Analysis of transfer patterns reveals an important asymmetry: temporal
progression patterns transfer more readily than point-of-care decisions,
suggesting practical pathways for cross-institutional deployment. Through a
systematic evaluation of fine-tuning approaches and transfer patterns, our work
provides insights for developing more generalizable clinical decision support
systems while enabling smaller specialized units to leverage knowledge from
larger centers.

æè¦ï¼è¨åºæ©å¨å­¸ç¿é¨ç½²å¨æ©æ§éé¢è¨éå¤§ææ°ï¼ç¶æ£èæç¾¤åè¨åºå¯¦åæé¡¯èå·®ç°æãæåæåºä¸åç¨æ¼è¨åºæéåºåçè·¨æ©æ§ç¥è­è½ç§»çç³»çµ±åæ¶æ§ï¼ééä¸è¬å°åå è­·çæ¿ (PICU) åå¿èå°ç§çæ¿ä¹éçåç§å¼å¸å¨ç®¡çå ä»¥è­æãä½¿ç¨å°æ¯é æ¸¬ç·¨ç¢¼ (CPC) é²è¡è¡¨å¾µå­¸ç¿ï¼æåæ¢è¨ä¸åçè³æå¶åº¦åå¾®èª¿ç­ç¥å¦ä½å½±é¿è·¨æ©æ§éççç¥è­è½ç§»ãæåççµæé¡¯ç¤ºï¼åç®¡ç´æ¥æ¨¡åè½ç§»å·è¡ä¸ä½³ï¼ä½ä½¿ç¨é©ç¶å¾®èª¿ç CPC è½å¤ å¨æ©æ§éé²è¡ææçç¥è­åäº«ï¼å¶å¥½èå¨æéè³ææå¢ä¸­ç¹å¥æé¡¯ãè½ç§»æ¨¡å¼åææ­é²äºä¸åéè¦çä¸å°ç¨±æ§ï¼æéé²ç¨æ¨¡å¼æ¯ç§è­·é»æ±ºç­æ´å®¹æè½ç§»ï¼éè¡¨ç¤ºè·¨æ©æ§é¨ç½²çå¯¦åéå¾ãééå¾®èª¿æ¹æ³åè½ç§»æ¨¡å¼çç³»çµ±æ§è©ä¼°ï¼æåçç ç©¶æä¾è¦è§£ï¼ç¨æ¼éç¼æ´å·æ¦æ¬æ§çè¨åºæ±ºç­æ¯æ´ç³»çµ±ï¼åæè®è¼å°çå°ç§å®ä½è½å¤ å©ç¨ä¾èªè¼å¤§ä¸­å¿çç¥è­ã

##### **LLMs Can Plan Only If We Tell Them**
2501.13545v1 by Bilgehan Sel, Ruoxi Jia, Ming Jin

Large language models (LLMs) have demonstrated significant capabilities in
natural language processing and reasoning, yet their effectiveness in
autonomous planning has been under debate. While existing studies have utilized
LLMs with external feedback mechanisms or in controlled environments for
planning, these approaches often involve substantial computational and
development resources due to the requirement for careful design and iterative
backprompting. Moreover, even the most advanced LLMs like GPT-4 struggle to
match human performance on standard planning benchmarks, such as the
Blocksworld, without additional support. This paper investigates whether LLMs
can independently generate long-horizon plans that rival human baselines. Our
novel enhancements to Algorithm-of-Thoughts (AoT), which we dub AoT+, help
achieve state-of-the-art results in planning benchmarks out-competing prior
methods and human baselines all autonomously.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å¨èªç¶èªè¨èçåæ¨çæ¹é¢å±ç¤ºäºé¡¯èçè½åï¼ä½å®åå¨èªä¸»è¦åä¸­çæææ§ä¸ç´å­å¨ç­è­°ãåç®¡ç¾æç ç©¶å·²å° LLM èå¤é¨åé¥æ©å¶çµåä½¿ç¨ï¼æå¨åæ§ç°å¢ä¸­é²è¡è¦åï¼ä½ç±æ¼éè¦ä»ç´°è¨­è¨ååè¦æç¤ºï¼éäºæ¹æ³éå¸¸æ¶åå¤§éçè¨ç®åéç¼è³æºãæ­¤å¤ï¼å³ä½¿æ¯æåé²ç LLMï¼ä¾å¦ GPT-4ï¼å¨æ²æé¡å¤æ¯æ´çææ³ä¸ï¼ä¹å¾é£å¨æ¨æºè¦ååºæºï¼ä¾å¦ Blocksworldï¼ä¸éå°äººé¡çè¡¨ç¾ãæ¬ææ¢è¨ LLM æ¯å¦è½ç¨ç«çæèäººé¡åºæºç¸åª²ç¾çé·é è¨ç«ãæåå°ææ³æ¼ç®æ³ (AoT) çåµæ°å¼·åï¼æåç¨±ä¹çº AoT+ï¼æå©æ¼å¨è¦ååºæºä¸­åå¾æåé²çææï¼å¨å®å¨èªä¸»çææ³ä¸åéååçåç¨®æ¹æ³åäººé¡åºæºã

##### **Comprehensive Modeling and Question Answering of Cancer Clinical Practice Guidelines using LLMs**
2501.13984v1 by Bhumika Gupta, Pralaypati Ta, Keerthi Ram, Mohanasankar Sivaprakasam

The updated recommendations on diagnostic procedures and treatment pathways
for a medical condition are documented as graphical flows in Clinical Practice
Guidelines (CPGs). For effective use of the CPGs in helping medical
professionals in the treatment decision process, it is necessary to fully
capture the guideline knowledge, particularly the contexts and their
relationships in the graph. While several existing works have utilized these
guidelines to create rule bases for Clinical Decision Support Systems, limited
work has been done toward directly capturing the full medical knowledge
contained in CPGs. This work proposes an approach to create a contextually
enriched, faithful digital representation of National Comprehensive Cancer
Network (NCCN) Cancer CPGs in the form of graphs using automated extraction and
node & relationship classification. We also implement semantic enrichment of
the model by using Large Language Models (LLMs) for node classification,
achieving an accuracy of 80.86% and 88.47% with zero-shot learning and few-shot
learning, respectively. Additionally, we introduce a methodology for answering
natural language questions with constraints to guideline text by leveraging
LLMs to extract the relevant subgraph from the guideline knowledge base. By
generating natural language answers based on subgraph paths and semantic
information, we mitigate the risk of incorrect answers and hallucination
associated with LLMs, ensuring factual accuracy in medical domain Question
Answering.

æè¦ï¼å·²æ´æ°çé«ççæ³è¨ºæ·ç¨åºåæ²»çéå¾å»ºè­°ï¼ä»¥è¨åºå¯¦åæå (CPG) ä¸­çåå½¢æµç¨è¨éãçºäºææä½¿ç¨ CPG åå©é«çå°æ¥­äººå¡é²è¡æ²»çæ±ºç­ï¼å¿é å®æ´æ·åæåç¥è­ï¼ç¹å¥æ¯åè¡¨ä¸­çèçµ¡åå¶éä¿ãéç¶ç¾æè¨±å¤ç ç©¶å·²å©ç¨éäºæåçºè¨åºæ±ºç­æ¯æ´ç³»çµ±å»ºç«è¦ååºç¤ï¼ä½ç´æ¥æ·å CPG ä¸­åå«çå®æ´é«çç¥è­çå·¥ä½å»æéãéé ç ç©¶æåºäºä¸ç¨®æ¹æ³ï¼ä»¥èªååæ·ååç¯é»èéä¿åé¡çæ¹å¼ï¼å»ºç«èçµ¡è±å¯ãå¿ å¯¦çåå®¶ç¶åççç¶²è·¯ (NCCN) çç CPG åå½¢æ¸ä½è¡¨ç¤ºãæåä¹ééä½¿ç¨å¤§åèªè¨æ¨¡å (LLM) é²è¡ç¯é»åé¡ï¼å¯¦ä½æ¨¡åçèªæè±å¯åï¼åå¥å¨é¶æ¬¡å­¸ç¿åå°æ¬¡å­¸ç¿ä¸­éå° 80.86% å 88.47% çæºç¢ºåº¦ãæ­¤å¤ï¼æåå¼é²äºä¸ç¨®æ¹æ³ï¼éééç¨ LLM å¾æåç¥è­åº«ä¸­æ·åç¸éå­åï¼ä¾åç­å·ææåæå­éå¶çèªç¶èªè¨åé¡ãééæ ¹æå­åè·¯å¾åèªæè³è¨ç¢çèªç¶èªè¨ç­æ¡ï¼æåéä½äºè LLM ç¸éçé¯èª¤ç­æ¡åå¹»è¦ºé¢¨éªï¼ç¢ºä¿äºé«çé ååé¡è§£ç­ä¸­çäºå¯¦æºç¢ºæ§ã

##### **A review on development of eco-friendly filters in Nepal for use in cigarettes and masks and Air Pollution Analysis with Machine Learning and SHAP Interpretability**
2501.13369v1 by Bishwash Paneru, Biplov Paneru, Tanka Mukhiya, Khem Narayan Poudyal

In Nepal, air pollution is a serious public health concern, especially in
cities like Kathmandu where particulate matter (PM2.5 and PM10) has a major
influence on respiratory health and air quality. The Air Quality Index (AQI) is
predicted in this work using a Random Forest Regressor, and the model's
predictions are interpreted using SHAP (SHapley Additive exPlanations)
analysis. With the lowest Testing RMSE (0.23) and flawless R2 scores (1.00),
CatBoost performs better than other models, demonstrating its greater accuracy
and generalization which is cross validated using a nested cross validation
approach. NowCast Concentration and Raw Concentration are the most important
elements influencing AQI values, according to SHAP research, which shows that
the machine learning results are highly accurate. Their significance as major
contributors to air pollution is highlighted by the fact that high values of
these characteristics significantly raise the AQI. This study investigates the
Hydrogen-Alpha (HA) biodegradable filter as a novel way to reduce the related
health hazards. With removal efficiency of more than 98% for PM2.5 and 99.24%
for PM10, the HA filter offers exceptional defense against dangerous airborne
particles. These devices, which are biodegradable face masks and cigarette
filters, address the environmental issues associated with traditional filters'
non-biodegradable trash while also lowering exposure to air contaminants.

æè¦ï¼å¨å°¼æ³ç¾ï¼ç©ºæ°£æ±¡ææ¯ä¸åå´éçå¬å±è¡çåé¡ï¼ç¹å¥æ¯å¨å å¾·æ»¿é½ç­åå¸ï¼é£è£¡çæ¸æµ®å¾®ç²ï¼PM2.5 å PM10ï¼å°å¼å¸ç³»çµ±å¥åº·åç©ºæ°£åè³ªæéå¤§å½±é¿ãéé å·¥ä½ä½¿ç¨é¨æ©æ£®æåæ­¸å¨é æ¸¬ç©ºæ°£åè³ªææ¸ (AQI)ï¼ä¸¦ä½¿ç¨ SHAPï¼SHapley å æ³è§£éï¼åæä¾è§£éæ¨¡åçé æ¸¬ãCatBoost çæ¸¬è©¦ RMSE æä½ï¼0.23ï¼ï¼R2 åæ¸å®ç¾ï¼1.00ï¼ï¼è¡¨ç¾åªæ¼å¶ä»æ¨¡åï¼è­æå¶å·ææ´é«çæºç¢ºæ§åæ³åæ§ï¼ä¸¦ä½¿ç¨åµå¥äº¤åé©è­æ¹æ³é²è¡äº¤åé©è­ãæ ¹æ SHAP ç ç©¶ï¼ç¾å¨æ¿åº¦ååå§æ¿åº¦æ¯å½±é¿ AQI å¼æéè¦çåç´ ï¼éè¡¨ææ©å¨å­¸ç¿çµæéå¸¸æºç¢ºãå®åä½çºç©ºæ°£æ±¡æçä¸»è¦è²¢ç»èçéè¦æ§å¨æ¼ï¼éäºç¹å¾µçé«å¼æé¡¯èæé« AQIãæ¬ç ç©¶æ¢è¨äºæ°«-Î±ï¼HAï¼å¯çç©éè§£éæ¿¾å¨ä½çºæ¸å°ç¸éå¥åº·å±å®³çä¸ç¨®æ°æ¹æ³ãHA éæ¿¾å¨å° PM2.5 çå»é¤æçè¶é 98%ï¼å° PM10 çå»é¤æçè¶é 99.24%ï¼å¯æä¾é²ç¯å±éªç©ºæ°£æ¸æµ®å¾®ç²çåºè²é²è­·ãéäºå¯çç©éè§£å£ç½©åé¦è¸éæ¿¾å¨çè£ç½®è§£æ±ºäºå³çµ±éæ¿¾å¨ä¸å¯çç©éè§£åå¾ç¸éçç°å¢åé¡ï¼åæä¹éä½äºæ¥è§¸ç©ºæ°£æ±¡æç©çé¢¨éªã

##### **QuFeX: Quantum feature extraction module for hybrid quantum-classical deep neural networks**
2501.13165v1 by Naman Jain, Amir Kalev

We introduce Quantum Feature Extraction (QuFeX), a novel quantum machine
learning module. The proposed module enables feature extraction in a
reduced-dimensional space, significantly decreasing the number of parallel
evaluations required in typical quantum convolutional neural network
architectures. Its design allows seamless integration into deep classical
neural networks, making it particularly suitable for hybrid quantum-classical
models. As an application of QuFeX, we propose Qu-Net -- a hybrid architecture
which integrates QuFeX at the bottleneck of a U-Net architecture. The latter is
widely used for image segmentation tasks such as medical imaging and autonomous
driving. Our numerical analysis indicates that the Qu-Net can achieve superior
segmentation performance compared to a U-Net baseline. These results highlight
the potential of QuFeX to enhance deep neural networks by leveraging hybrid
computational paradigms, providing a path towards a robust framework for
real-world applications requiring precise feature extraction.

æè¦ï¼æåå¼å¥äºéå­ç¹å¾µèå (QuFeX)ï¼éæ¯ä¸ååµæ°çéå­æ©å¨å­¸ç¿æ¨¡çµãææåºçæ¨¡çµå¯ä»¥å¨éç¶­ç©ºéä¸­é²è¡ç¹å¾µèåï¼å¤§å¹æ¸å°å¸åéå­å·ç©ç¥ç¶ç¶²è·¯æ¶æ§ä¸­æéçä¸¦è¡è©ä¼°æ¸éãå¶è¨­è¨åè¨±ç¡ç¸«æ´åå°æ·±åº¦å¤å¸ç¥ç¶ç¶²è·¯ä¸­ï¼ä½¿å¶ç¹å¥é©åæ¼æ··åéå­å¤å¸æ¨¡åãä½çº QuFeX çæç¨ï¼æåæåºäº Qu-Netï¼éæ¯ä¸ç¨®æ··åæ¶æ§ï¼å®å¨ U-Net æ¶æ§çç¶é ¸èæ´åäº QuFeXãå¾èå»£æ³ç¨æ¼å½±ååå²ä»»åï¼ä¾å¦é«å­¸å½±ååèªåé§é§ãæåçæ¸å¼åæè¡¨æï¼è U-Net åºæºç¸æ¯ï¼Qu-Net å¯ä»¥å¯¦ç¾åªç°çåå²æè½ãéäºçµæçªé¡¯äº QuFeX ééå©ç¨æ··åéç®ç¯ä¾ä¾å¢å¼·æ·±åº¦ç¥ç¶ç¶²è·¯çæ½åï¼çºéè¦ç²¾ç¢ºç¹å¾µèåççå¯¦ä¸çæç¨ç¨å¼æä¾äºä¸åéåç©©å¥æ¶æ§çéå¾ã

##### **AirRadar: Inferring Nationwide Air Quality in China with Deep Neural Networks**
2501.13141v1 by Qiongyan Wang, Yutong Xia, Siru ZHong, Weichuang Li, Yuankai Wu, Shifen Cheng, Junbo Zhang, Yu Zheng, Yuxuan Liang

Monitoring real-time air quality is essential for safeguarding public health
and fostering social progress. However, the widespread deployment of air
quality monitoring stations is constrained by their significant costs. To
address this limitation, we introduce \emph{AirRadar}, a deep neural network
designed to accurately infer real-time air quality in locations lacking
monitoring stations by utilizing data from existing ones. By leveraging
learnable mask tokens, AirRadar reconstructs air quality features in
unmonitored regions. Specifically, it operates in two stages: first capturing
spatial correlations and then adjusting for distribution shifts. We validate
AirRadar's efficacy using a year-long dataset from 1,085 monitoring stations
across China, demonstrating its superiority over multiple baselines, even with
varying degrees of unobserved data. The source code can be accessed at
https://github.com/CityMind-Lab/AirRadar.

æè¦ï¼ç£æ§å³æç©ºæ°£åè³ªå°æ¼ä¿éå¬å±å¥åº·åä¿é²ç¤¾æé²æ­¥è³ééè¦ãç¶èï¼ç©ºæ°£åè³ªç£æ¸¬ç«çå»£æ³é¨ç½²åå°å¶é«æææ¬çéå¶ãçºäºè§£æ±ºéåéå¶ï¼æåå¼å¥äº \emph{AirRadar}ï¼éæ¯ä¸åæ·±åº¦ç¥ç¶ç¶²è·¯ï¼æ¨å¨å©ç¨ç¾æç£æ¸¬ç«çè³æï¼ç²¾æºæ¨è«æ²æç£æ¸¬ç«çå°åçå³æç©ºæ°£åè³ªãééå©ç¨å¯å­¸ç¿çé®ç½©ç¬¦èï¼AirRadar éå»ºæªç£æ§ååçç©ºæ°£åè³ªç¹å¾µãå·é«ä¾èªªï¼å®åå©åéæ®µéä½ï¼é¦åæ·åç©ºééè¯æ§ï¼ç¶å¾èª¿æ´åä½è½ç§»ãæåä½¿ç¨ä¾èªä¸­å 1,085 åç£æ¸¬ç«ä¸æ´å¹´çè³æéé©è­äº AirRadar çåæï¼è­æäºå®åªæ¼å¤ååºæºï¼å³ä½¿å¨ä¸åç¨åº¦çæªè§å¯è³æä¸­ä¹æ¯å¦æ­¤ãå¯ä»¥å¨ https://github.com/CityMind-Lab/AirRadar åå¾åå§ç¨å¼ç¢¼ã

##### **Estimating the Conformal Prediction Threshold from Noisy Labels**
2501.12749v1 by Coby Penso, Jacob Goldberger, Ethan Fetaya

Conformal Prediction (CP) is a method to control prediction uncertainty by
producing a small prediction set, ensuring a predetermined probability that the
true class lies within this set. This is commonly done by defining a score,
based on the model predictions, and setting a threshold on this score using a
validation set. In this study, we address the problem of CP calibration when we
only have access to a validation set with noisy labels. We show how we can
estimate the noise-free conformal threshold based on the noisy labeled data.
Our solution is flexible and can accommodate various modeling assumptions
regarding the label contamination process, without needing any information
about the underlying data distribution or the internal mechanisms of the
machine learning classifier. We develop a coverage guarantee for uniform noise
that is effective even in tasks with a large number of classes. We dub our
approach Noise-Aware Conformal Prediction (NACP) and show on several natural
and medical image classification datasets, including ImageNet, that it
significantly outperforms current noisy label methods and achieves results
comparable to those obtained with a clean validation set.

æè¦ï¼å±å½¢é¢æµ (CP) æ¯ä¸ç¨®ééç¢çä¸åå°åé æ¸¬éåä¾æ§å¶é æ¸¬ä¸ç¢ºå®æ§çæ¹æ³ï¼ç¢ºä¿çæ­£çé¡å¥è½å¨éåéåå§çé åç¢ºå®çæ©çãééå¸¸æ¯ééå®ç¾©ä¸ååºæ¼æ¨¡åé æ¸¬çåæ¸ä¾å®æï¼ä¸¦ä½¿ç¨é©è­éåå°éååæ¸è¨­å®ä¸åé¾å¼ãå¨æ¬ç ç©¶ä¸­ï¼æåæ¢è¨äºç¶æååªè½å­åå·æéè¨æ¨ç±¤çé©è­éåæï¼CP æ ¡æ­£çåé¡ãæåå±ç¤ºäºå¦ä½æ ¹æéè¨æ¨ç±¤è³æä¼°è¨ç¡éè¨çå±å½¢é¾å¼ãæåçè§£æ±ºæ¹æ¡å·æå½æ§ï¼ä¸¦ä¸å¯ä»¥é©æéæ¼æ¨ç±¤æ±¡æéç¨çåç¨®å»ºæ¨¡åè¨­ï¼èä¸éè¦ä»»ä½éæ¼åºå±¤è³æåä½ææ©å¨å­¸ç¿åé¡å¨å§é¨æ©å¶çè³è¨ãæåéç¼äºä¸åå°æ¼åå»éè¨çè¦èä¿è­ï¼å³ä½¿å¨å·æå¤§éé¡å¥çä»»åä¸­ä¹å¾ææãæåå°æåçåæ³ç¨±çºéè¨æç¥å±å½¢é æ¸¬ (NACP)ï¼ä¸¦å¨å¹¾åèªç¶åé«å­¸å½±ååé¡è³æéï¼åæ¬ ImageNetï¼ä¸å±ç¤ºäºå®é¡¯èåªæ¼ç®åçéè¨æ¨ç±¤æ¹æ³ï¼ä¸¦ä¸éå°äºèä½¿ç¨ä¹¾æ·¨é©è­éåç²å¾ççµæç¸ç¶ççµæã

##### **Applications and Challenges of AI and Microscopy in Life Science Research: A Review**
2501.13135v1 by Himanshu Buckchash, Gyanendra Kumar Verma, Dilip K. Prasad

The complexity of human biology and its intricate systems holds immense
potential for advancing human health, disease treatment, and scientific
discovery. However, traditional manual methods for studying biological
interactions are often constrained by the sheer volume and complexity of
biological data. Artificial Intelligence (AI), with its proven ability to
analyze vast datasets, offers a transformative approach to addressing these
challenges. This paper explores the intersection of AI and microscopy in life
sciences, emphasizing their potential applications and associated challenges.
We provide a detailed review of how various biological systems can benefit from
AI, highlighting the types of data and labeling requirements unique to this
domain. Particular attention is given to microscopy data, exploring the
specific AI techniques required to process and interpret this information. By
addressing challenges such as data heterogeneity and annotation scarcity, we
outline potential solutions and emerging trends in the field. Written primarily
from an AI perspective, this paper aims to serve as a valuable resource for
researchers working at the intersection of AI, microscopy, and biology. It
summarizes current advancements, key insights, and open problems, fostering an
understanding that encourages interdisciplinary collaborations. By offering a
comprehensive yet concise synthesis of the field, this paper aspires to
catalyze innovation, promote cross-disciplinary engagement, and accelerate the
adoption of AI in life science research.

æè¦ï¼äººé¡çç©å­¸åå¶è¤éç³»çµ±çè¤éæ§èèèä¿é²äººé¡å¥åº·ãç¾çæ²»çåç§å­¸ç¼ç¾çå·¨å¤§æ½åãç¶èï¼å³çµ±çäººå·¥çç©äº¤äºç ç©¶æ¹æ³éå¸¸åå°çç©æ¸æé¾å¤§çæ¸éåè¤éæ§çéå¶ãäººå·¥æºæ§ (AI) å·²è¢«è­å¯¦å·æåæé¾å¤§æ¸æéçè½åï¼å®æä¾äºä¸ç¨®è®é©æ§çæ¹æ³ä¾æå°éäºææ°ãæ¬ææ¢è¨äº AI åé¡¯å¾®é¡å¨çå½ç§å­¸ä¸­çäº¤éï¼å¼·èª¿äºå®åçæ½å¨æç¨åç¸éææ°ãæåè©³ç´°åé¡§äºåç¨®çç©ç³»çµ±å¦ä½å¾ AI ä¸­åçï¼éé»ä»ç´¹äºæ­¤é åç¨æçæ¸æé¡ååæ¨è¨è¦æ±ãç¹å¥éæ³¨é¡¯å¾®é¡æ¸æï¼æ¢è¨èçåè§£éæ­¤ä¿¡æ¯çç¹å® AI æè¡ãééæå°æ¸æç°è³ªæ§åè¨»éç¨ç¼ºæ§ç­ææ°ï¼æåæ¦è¿°äºè©²é åçæ½å¨è§£æ±ºæ¹æ¡åæ°è¶¨å¢ãæ¬æä¸»è¦å¾ AI çè§åº¦æ°å¯«ï¼æ¨å¨çºå¨ AIãé¡¯å¾®é¡åçç©å­¸äº¤åé åå·¥ä½çç ç©¶äººå¡æä¾å¯¶è²´çè³æºãå®ç¸½çµäºç¶åçé²å±ãééµè¦è§£åæªè§£æ±ºçåé¡ï¼å¹é¤äºé¼åµè·¨å­¸ç§åä½ççè§£ãééæä¾è©²é åå¨é¢èç°¡æ½çç¶åï¼æ¬ææ¨å¨å¬ååµæ°ãä¿é²è·¨å­¸ç§åèï¼ä¸¦å é AI å¨çå½ç§å­¸ç ç©¶ä¸­çæ¡ç¨ã

##### **FedDAG: Federated Domain Adversarial Generation Towards Generalizable Medical Image Analysis**
2501.13967v1 by Haoxuan Che, Yifei Wu, Haibo Jin, Yong Xia, Hao Chen

Federated domain generalization aims to train a global model from multiple
source domains and ensure its generalization ability to unseen target domains.
{Due to the target domain being with unknown domain shifts, attempting to
approximate these gaps by source domains may be the key to improving model
generalization capability.} Existing works mainly focus on sharing and
recombining local domain-specific attributes to increase data diversity and
simulate potential domain shifts. {However, these methods may be insufficient
since only the local attribute recombination can be hard to touch the
out-of-distribution of global data.} In this paper, we propose a
simple-yet-efficient framework named Federated Domain Adversarial Generation
(FedDAG). {It aims to simulate the domain shift and improve the model
generalization by adversarially generating novel domains different from local
and global source domains.} Specifically, it generates novel-style images by
maximizing the instance-level feature discrepancy between original and
generated images and trains a generalizable task model by minimizing their
feature discrepancy. {Further, we observed that FedDAG could cause different
performance improvements for local models. It may be due to inherent data
isolation and heterogeneity among clients, exacerbating the imbalance in their
generalization contributions to the global model.} {Ignoring this imbalance can
lead the global model's generalization ability to be sub-optimal, further
limiting the novel domain generation procedure. } Thus, to mitigate this
imbalance, FedDAG hierarchically aggregates local models at the within-client
and across-client levels by using the sharpness concept to evaluate client
model generalization contributions. {Extensive experiments across four medical
benchmarks demonstrate FedDAG's ability to enhance generalization in federated
medical scenarios.}

æè¦ï¼<paragraph>è¯é¦é åæ³åæ¨å¨å¾å¤åä¾æºé åè¨ç·´ä¸åå¨å±æ¨¡åï¼ä¸¦ç¢ºä¿å¶å°æªè¦ç®æ¨é åçæ³åè½åã
{ç±æ¼ç®æ¨é åå­å¨æªç¥çé åè½ç§»ï¼åè©¦ééä¾æºé åä¾è¿ä¼¼éäºå·®è·å¯è½æ¯æé«æ¨¡åæ³åè½åçééµã} ç¾æå·¥ä½ä¸»è¦éä¸­å¨å±äº«åéæ°çµåå±é¨é åç¹å®å±¬æ§ï¼ä»¥å¢å æ¸æå¤æ¨£æ§åæ¨¡æ¬æ½å¨çé åè½ç§»ã {ç¶èï¼éäºæ¹æ³å¯è½ä¸è¶³ï¼å çºåªæå±é¨å±¬æ§éçµé£ä»¥è§¸åå¨å±æ¸æçåå¸å¤ã} å¨æ¬æä¸­ï¼æåæåºäºä¸åç°¡å®èé«æçæ¡æ¶ï¼åçºè¯é¦é åå°æçæï¼FedDAGï¼ã {å®æ¨å¨æ¨¡æ¬é åè½ç§»ï¼ä¸¦ééå°æçæä¸åæ¼å±é¨åå¨å±ä¾æºé åçæ°ç©é åä¾æé«æ¨¡åæ³åã} å·é«ä¾èªªï¼å®ééæå¤§ååå§åååçæååä¹éçå¯¦ä¾ç´å¥ç¹å¾µå·®ç°ä¾çææ°æ¨£å¼çååï¼ä¸¦ééæå°åå®åçç¹å¾µå·®ç°ä¾è¨ç·´ä¸åå¯æ³åçä»»åæ¨¡åã {æ­¤å¤ï¼æåè§å¯å° FedDAG å¯ä»¥å°å±é¨æ¨¡åé æä¸åçæ§è½æåãéå¯è½æ¯ç±æ¼å®¢æ¶ç«¯ä¹éåºæçæ¸æéé¢åç°è³ªæ§ï¼å åäºå®åå°å¨å±æ¨¡åæ³åè²¢ç»çä¸å¹³è¡¡ã} {å¿½ç¥éç¨®ä¸å¹³è¡¡æå°è´å¨å±æ¨¡åçæ³åè½åæ¬¡åªï¼é²ä¸æ­¥éå¶æ°ç©é åçæéç¨ã} å æ­¤ï¼çºäºæ¸è¼éç¨®ä¸å¹³è¡¡ï¼FedDAG ä½¿ç¨æ¸æ°åº¦æ¦å¿µä¾è©ä¼°å®¢æ¶ç«¯æ¨¡åæ³åè²¢ç»ï¼å¨å®¢æ¶ç«¯å§åå®¢æ¶ç«¯ä¹éåå±¤èåå±é¨æ¨¡åã {å¨ååé«çåºæºä¸çå»£æ³å¯¦é©è­æäº FedDAG å¢å¼·è¯é¦é«çå ´æ¯ä¸­æ³åçè½åã}</paragraph>

##### **Academic Case Reports Lack Diversity: Assessing the Presence and Diversity of Sociodemographic and Behavioral Factors related to Post COVID-19 Condition**
2501.12538v2 by Juan Andres Medina Florez, Shaina Raza, Rashida Lynn, Zahra Shakeri, Brendan T. Smith, Elham Dolatabadi

Understanding the prevalence, disparities, and symptom variations of Post
COVID-19 Condition (PCC) for vulnerable populations is crucial to improving
care and addressing intersecting inequities. This study aims to develop a
comprehensive framework for integrating social determinants of health (SDOH)
into PCC research by leveraging NLP techniques to analyze disparities and
variations in SDOH representation within PCC case reports. Following
construction of a PCC Case Report Corpus, comprising over 7,000 case reports
from the LitCOVID repository, a subset of 709 reports were annotated with 26
core SDOH-related entity types using pre-trained named entity recognition (NER)
models, human review, and data augmentation to improve quality, diversity and
representation of entity types. An NLP pipeline integrating NER, natural
language inference (NLI), trigram and frequency analyses was developed to
extract and analyze these entities. Both encoder-only transformer models and
RNN-based models were assessed for the NER objective.
  Fine-tuned encoder-only BERT models outperformed traditional RNN-based models
in generalizability to distinct sentence structures and greater class sparsity.
Exploratory analysis revealed variability in entity richness, with prevalent
entities like condition, age, and access to care, and underrepresentation of
sensitive categories like race and housing status. Trigram analysis highlighted
frequent co-occurrences among entities, including age, gender, and condition.
The NLI objective (entailment and contradiction analysis) showed attributes
like "Experienced violence or abuse" and "Has medical insurance" had high
entailment rates (82.4%-80.3%), while attributes such as "Is
female-identifying," "Is married," and "Has a terminal condition" exhibited
high contradiction rates (70.8%-98.5%).

æè¦ï¼äºè§£èå¼±äººç¾¤ç COVID-19 å¾éºç (PCC) çæµè¡çæ³ãå·®ç°åççè®åå°æ¼æ¹åç§è­·åè§£æ±ºäº¤ç¹çä¸å¹³ç­è³ééè¦ãæ¬ç ç©¶æ¨å¨ééå©ç¨èªç¶èªè¨èçæè¡åæ PCC çä¾å ±åä¸­ SDOH çä»£è¡¨æ§å·®ç°åè®åï¼çºå°ç¤¾æå¥åº·æ±ºå®å ç´  (SDOH) æ´åå° PCC ç ç©¶ä¸­å»ºç«ä¸åå¨é¢çæ¶æ§ãå¨å»ºæ§åå«ä¾èª LitCOVID å²å­åº«ç 7,000 å¤ä»½çä¾å ±åç PCC çä¾å ±åèªæåº«å¾ï¼ä½¿ç¨é åè¨ç·´çåç¨±å¯¦é«è­å¥ (NER) æ¨¡åãäººå·¥å¯©æ¥åè³ææ´åå° 709 ä»½å ±åç 26 åæ ¸å¿ SDOH ç¸éå¯¦é«é¡åé²è¡è¨»è§£ï¼ä»¥æé«å¯¦é«é¡åçåè³ªãå¤æ¨£æ§åä»£è¡¨æ§ãéç¼äºä¸åæ´å NERãèªç¶èªè¨æ¨ç (NLI)ãä¸åçµåé »çåæç NLP ç®¡ç·ä¾èåååæéäºå¯¦é«ãè©ä¼°äºåç·¨ç¢¼å¨è½æå¨æ¨¡åååºæ¼ RNN çæ¨¡åç NER ç®æ¨ãç¶éå¾®èª¿çåç·¨ç¢¼å¨ BERT æ¨¡åå¨å°ä¸åå¥å­çµæ§åæ´å¤§çé¡å¥ç¨çæ§çæ¦æ¬æ§æ¹é¢åªæ¼å³çµ±çåºæ¼ RNN çæ¨¡åãæ¢ç´¢æ§åææ­ç¤ºäºå¯¦é«è±å¯åº¦çè®ç°æ§ï¼å¶ä¸­çè¡çå¯¦é«åæ¬çæ³ãå¹´é½¡åç²å¾ç§è­·çæ©æï¼èç¨®æåä½æ¿çæ³ç­ææé¡å¥çä»£è¡¨æ§ä¸è¶³ãä¸åçµåæçªåºäºå¯¦é«ä¹éçé »ç¹å±ç¾ï¼åæ¬å¹´é½¡ãæ§å¥åçæ³ãNLI ç®æ¨ï¼èæ¶µåçç¾åæï¼é¡¯ç¤ºãç¶æ­·éæ´åæèå¾ãåãæé«çä¿éªãç­å±¬æ§å·æå¾é«çèæ¶µçï¼82.4%-80.3%ï¼ï¼èãèªåèªå·±æ¯å¥³æ§ãããå·²å©ãåãææ«æç¾çãç­å±¬æ§åè¡¨ç¾åºå¾é«ççç¾çï¼70.8%-98.5%ï¼ã

##### **Efficient Lung Ultrasound Severity Scoring Using Dedicated Feature Extractor**
2501.12524v1 by Jiaqi Guo, Yunnan Wu, Evangelos Kaimakamis, Georgios Petmezas, Vasileios E. Papageorgiou, Nicos Maglaveras, Aggelos K. Katsaggelos

With the advent of the COVID-19 pandemic, ultrasound imaging has emerged as a
promising technique for COVID-19 detection, due to its non-invasive nature,
affordability, and portability. In response, researchers have focused on
developing AI-based scoring systems to provide real-time diagnostic support.
However, the limited size and lack of proper annotation in publicly available
ultrasound datasets pose significant challenges for training a robust AI model.
This paper proposes MeDiVLAD, a novel pipeline to address the above issue for
multi-level lung-ultrasound (LUS) severity scoring. In particular, we leverage
self-knowledge distillation to pretrain a vision transformer (ViT) without
label and aggregate frame-level features via dual-level VLAD aggregation. We
show that with minimal finetuning, MeDiVLAD outperforms conventional
fully-supervised methods in both frame- and video-level scoring, while offering
classification reasoning with exceptional quality. This superior performance
enables key applications such as the automatic identification of critical lung
pathology areas and provides a robust solution for broader medical video
classification tasks.

æè¦ï¼é¨è COVID-19 å¤§æµè¡çå°ä¾ï¼è¶é³æ³¢å½±åå·²æçºä¸ç¨®æåéç COVID-19 æª¢æ¸¬æè¡ï¼å çºå®å·æéä¾µå¥æ§ãå¹æ ¼å¯¦æ ä¸å¯æå¸¶ç­ç¹æ§ãæéæ¼æ­¤ï¼ç ç©¶äººå¡å°æ³¨æ¼éç¼åºæ¼ AI çè©åç³»çµ±ï¼ä»¥æä¾å³æçè¨ºæ·æ¯æ´ãç¶èï¼å¬éå¯ç¨çè¶é³æ³¢è³æéè¦æ¨¡æéä¸ç¼ºä¹é©ç¶çè¨»è§£ï¼éå°è¨ç·´ç©©å¥ç AI æ¨¡åæ§æéå¤§ææ°ãæ¬ææåº MeDiVLADï¼éæ¯ä¸ç¨®æ°ç©çç®¡éï¼ç¨æ¼è§£æ±ºä¸è¿°å¤å±¤ç´èºé¨è¶é³æ³¢ (LUS) å´éåº¦è©åçè­°é¡ãå·é«ä¾èªªï¼æåå©ç¨èªæç¥è­è¸é¤¾æè¡ï¼å¨æ²ææ¨ç±¤çææ³ä¸é è¨ç·´è¦è¦ºè½æå¨ (ViT)ï¼ä¸¦éééå±¤ç´ VLAD èåä¾å½ç¸½å¹ç´ç¹å¾µãæåè­æï¼ééæå°çå¾®èª¿ï¼MeDiVLAD å¨å¹ç´åå½±çç´è©åä¸­é½åªæ¼å³çµ±çå¨ç£ç£å¼æ¹æ³ï¼åææä¾åè³ªæ¥µä½³çåé¡æ¨çãéç¨®åªç°çæè½æ¯æ´äºééµæç¨ï¼ä¾å¦èªåè­å¥èºé¨çç¶ååï¼ä¸¦çºæ´å»£æ³çé«å­¸å½±çåé¡ä»»åæä¾ç©©å¥çè§£æ±ºæ¹æ¡ã

##### **FuocChuVIP123 at CoMeDi Shared Task: Disagreement Ranking with XLM-Roberta Sentence Embeddings and Deep Neural Regression**
2501.12336v1 by Phuoc Duong Huy Chu

This paper presents results of our system for CoMeDi Shared Task, focusing on
Subtask 2: Disagreement Ranking. Our system leverages sentence embeddings
generated by the paraphrase-xlm-r-multilingual-v1 model, combined with a deep
neural regression model incorporating batch normalization and dropout for
improved generalization. By predicting the mean of pairwise judgment
differences between annotators, our method explicitly targets disagreement
ranking, diverging from traditional "gold label" aggregation approaches. We
optimized our system with a customized architecture and training procedure,
achieving competitive performance in Spearman correlation against mean
disagreement labels. Our results highlight the importance of robust embeddings,
effective model architecture, and careful handling of judgment differences for
ranking disagreement in multilingual contexts. These findings provide insights
into the use of contextualized representations for ordinal judgment tasks and
open avenues for further refinement of disagreement prediction models.

æè¦ï¼æ¬æå±ç¤ºäºæåå¨ CoMeDi å±äº«ä»»åç³»çµ±ä¸­ççµæï¼éé»å¨
å­ä»»å 2ï¼åæ­§æåãæåçç³»çµ±å©ç¨ paraphrase-xlm-r-multilingual-v1 æ¨¡åç¢ççå¥å­åµå¥ï¼çµåæ·±åº¦
ç¥ç¶è¿´æ­¸æ¨¡åï¼ä¸¦å å¥æ¹æ¬¡æ­£è¦ååä¸­æ·ä»¥æ¹åæ¦åãééé æ¸¬è¨»è§£èä¹éæå°å¤æ·å·®ç°çå¹³åå¼ï¼æåç
æ¹æ³æç¢ºéå°åæ­§æåï¼åé¢å³çµ±çãé»éæ¨ç±¤ãèåæ¹æ³ãæåä½¿ç¨èªè¨æ¶æ§åè¨ç·´ç¨åºåªåç³»çµ±ï¼
å¨èå¹³ååæ­§æ¨ç±¤ç Spearman ç¸éæ§ä¸­ç²å¾ç«¶ç­åè¡¨ç¾ãæåççµæå¼·èª¿äºç©©å¥åµå¥ãæææ¨¡åæ¶æ§å
è¬¹æèçå¤æ·å·®ç°å°æ¼å¨å¤èªè¨ç°å¢ä¸­å°åæ­§é²è¡æåçéè¦æ§ãéäºç¼ç¾æä¾äºä½¿ç¨æå¢åè¡¨å¾µé²è¡åºæ¸å¤æ·ä»»åçè¦è§£ï¼ä¸¦çºé²ä¸æ­¥åªååæ­§é æ¸¬æ¨¡åéé¢äºéè·¯ã

##### **CBVLM: Training-free Explainable Concept-based Large Vision Language Models for Medical Image Classification**
2501.12266v1 by Cristiano PatrÃ­cio, Isabel Rio-Torto, Jaime S. Cardoso, LuÃ­s F. Teixeira, JoÃ£o C. Neves

The main challenges limiting the adoption of deep learning-based solutions in
medical workflows are the availability of annotated data and the lack of
interpretability of such systems. Concept Bottleneck Models (CBMs) tackle the
latter by constraining the final disease prediction on a set of predefined and
human-interpretable concepts. However, the increased interpretability achieved
through these concept-based explanations implies a higher annotation burden.
Moreover, if a new concept needs to be added, the whole system needs to be
retrained. Inspired by the remarkable performance shown by Large
Vision-Language Models (LVLMs) in few-shot settings, we propose a simple, yet
effective, methodology, CBVLM, which tackles both of the aforementioned
challenges. First, for each concept, we prompt the LVLM to answer if the
concept is present in the input image. Then, we ask the LVLM to classify the
image based on the previous concept predictions. Moreover, in both stages, we
incorporate a retrieval module responsible for selecting the best examples for
in-context learning. By grounding the final diagnosis on the predicted
concepts, we ensure explainability, and by leveraging the few-shot capabilities
of LVLMs, we drastically lower the annotation cost. We validate our approach
with extensive experiments across four medical datasets and twelve LVLMs (both
generic and medical) and show that CBVLM consistently outperforms CBMs and
task-specific supervised methods without requiring any training and using just
a few annotated examples. More information on our project page:
https://cristianopatricio.github.io/CBVLM/.

æè¦ï¼éå¶å¨é«çå·¥ä½æµç¨ä¸­æ¡ç¨åºæ¼æ·±åº¦å­¸ç¿çè§£æ±ºæ¹æ¡çä¸»è¦ææ°æ¯æ¨è¨è³æçå¯ç¨æ§ä»¥åæ­¤é¡ç³»çµ±çå¯è§£éæ§ä¸è¶³ãæ¦å¿µç¶é ¸æ¨¡å (CBM) éééå¶ä¸çµé å®ç¾©ä¸äººé¡å¯è§£éçæ¦å¿µå°æçµç¾çé æ¸¬ï¼ä¾è§£æ±ºå¾èãç¶èï¼éééäºåºæ¼æ¦å¿µçè§£éæå¯¦ç¾çå¯è§£éæ§æåï¼æå³èæ´é«çæ¨è¨è² æãæ­¤å¤ï¼å¦æéè¦æ°å¢ä¸åæ°æ¦å¿µï¼åéè¦éæ°è¨ç·´æ´åç³»çµ±ãåå°å¤§åè¦è¦ºèªè¨æ¨¡å (LVLMs) å¨å°æ¨£æ¬è¨­å®ä¸­å±ç¾çåè¶æè½åç¼ï¼æåæåºäºä¸åç°¡å®ä½ææç CBVLM æ¹æ³ï¼ä¾è§£æ±ºä¸è¿°å©åææ°ãé¦åï¼å°æ¼æ¯åæ¦å¿µï¼æåæç¤º LVLM åç­è¼¸å¥å½±åä¸­æ¯å¦åå«è©²æ¦å¿µãç¶å¾ï¼æåè¦æ± LVLM æ ¹æååçæ¦å¿µé æ¸¬å°å½±åé²è¡åé¡ãæ­¤å¤ï¼å¨å©åéæ®µä¸­ï¼æåé½ç´å¥ä¸åæª¢ç´¢æ¨¡çµï¼è² è²¬é¸åºæé©åæ¼æå¢å­¸ç¿çç¯ä¾ãééå°æçµè¨ºæ·å»ºç«å¨é æ¸¬æ¦å¿µä¹ä¸ï¼æåç¢ºä¿äºå¯è§£éæ§ï¼ä¸¦ééå©ç¨ LVLMs çå°æ¨£æ¬è½åï¼æåå¤§å¹éä½äºæ¨è¨ææ¬ãæåééååé«çè³æéååäºå LVLMï¼éç¨åé«çï¼çå»£æ³å¯¦é©é©è­äºæåçä½æ³ï¼ä¸¦é¡¯ç¤º CBVLM å¨ç¡éä»»ä½è¨ç·´ä¸åä½¿ç¨å°æ¸æ¨è¨ç¯ä¾çææ³ä¸ï¼å§çµåªæ¼ CBM åç¹å®æ¼ä»»åçç£ç£å¼æ¹æ³ãæ´å¤è³è¨è«è¦æåçå°æ¡é é¢ï¼https://cristianopatricio.github.io/CBVLM/ã

##### **Can open source large language models be used for tumor documentation in Germany? -- An evaluation on urological doctors' notes**
2501.12106v1 by Stefan Lenz, Arsenij Ustjanzew, Marco Jeray, Torsten Panholzer

Tumor documentation in Germany is largely done manually, requiring reading
patient records and entering data into structured databases. Large language
models (LLMs) could potentially enhance this process by improving efficiency
and reliability. This evaluation tests eleven different open source LLMs with
sizes ranging from 1-70 billion model parameters on three basic tasks of the
tumor documentation process: identifying tumor diagnoses, assigning ICD-10
codes, and extracting the date of first diagnosis. For evaluating the LLMs on
these tasks, a dataset of annotated text snippets based on anonymized doctors'
notes from urology was prepared. Different prompting strategies were used to
investigate the effect of the number of examples in few-shot prompting and to
explore the capabilities of the LLMs in general. The models Llama 3.1 8B,
Mistral 7B, and Mistral NeMo 12 B performed comparably well in the tasks.
Models with less extensive training data or having fewer than 7 billion
parameters showed notably lower performance, while larger models did not
display performance gains. Examples from a different medical domain than
urology could also improve the outcome in few-shot prompting, which
demonstrates the ability of LLMs to handle tasks needed for tumor
documentation. Open source LLMs show a strong potential for automating tumor
documentation. Models from 7-12 billion parameters could offer an optimal
balance between performance and resource efficiency. With tailored fine-tuning
and well-designed prompting, these models might become important tools for
clinical documentation in the future. The code for the evaluation is available
from https://github.com/stefan-m-lenz/UroLlmEval. We also release the dataset
as a new valuable resource that addresses the shortage of authentic and easily
accessible benchmarks in German-language medical NLP.

æè¦ï¼å¾·åçè«ç¤æä»¶è¨éå¤§é¨åæ¯æåå®æï¼éè¦é±è®çæ­·ä¸¦å°è³æè¼¸å¥çµæ§åçè³æåº«ä¸­ãå¤§åèªè¨æ¨¡å (LLM) å¯è½ééæåæçåå¯é æ§ä¾å¢å¼·æ­¤ç¨åºãæ­¤è©éæ¸¬è©¦äº 11 åä¸åçéæº LLMï¼æ¨¡ååæ¸å¤§å°å¾ 10 åå° 700 åä¸ç­ï¼éå°è«ç¤æä»¶è¨éç¨åºçä¸é åºæ¬ä»»åï¼è­å¥è«ç¤è¨ºæ·ãæå® ICD-10 ä»£ç¢¼ï¼ä»¥åæ·åé¦æ¬¡è¨ºæ·æ¥æãçºäºéå°éäºä»»åè©ä¼° LLMï¼æºåäºä¸ååºæ¼æ³å°¿ç§é«çå¿åç­è¨çè¨»è§£æå­çæ®µè³æéãä½¿ç¨ä¸åçæç¤ºç­ç¥ä¾èª¿æ¥å°éæç¤ºä¸­ç¯ä¾æ¸éçå½±é¿ï¼ä¸¦æ¢ç´¢ LLM çä¸è¬è½åãLlama 3.1 8BãMistral 7B å Mistral NeMo 12 B ç­æ¨¡åå¨éäºä»»åä¸­è¡¨ç¾ç¸ç¶å¥½ãè¨ç·´è³æè¼å°æåæ¸å°æ¼ 70 åçæ¨¡åè¡¨ç¾æé¡¯è¼å·®ï¼èè¼å¤§çæ¨¡åä¸¦æªå±ç¾æè½æåãèæ³å°¿ç§ä¸åçé«çé åçç¯ä¾ä¹å¯ä»¥æ¹åå°éæç¤ºççµæï¼éè­æäº LLM èçè«ç¤æä»¶è¨éæéä»»åçè½åãéæº LLM å¨èªååè«ç¤æä»¶è¨éæ¹é¢é¡¯ç¤ºåºå¼·å¤§çæ½åãåæ¸ä»æ¼ 70 åå° 120 åçæ¨¡åå¯ä»¥å¨æè½åè³æºæçä¹éæä¾æä½³å¹³è¡¡ãéééèº«æé å¾®èª¿åç²¾å¿è¨­è¨çæç¤ºï¼éäºæ¨¡åæªä¾å¯è½ææçºè¨åºæä»¶è¨éçéè¦å·¥å·ãè©ä¼°ç¨å¼ç¢¼å¯å¾ https://github.com/stefan-m-lenz/UroLlmEval åå¾ãæåä¹éåºè³æéä½çºä¸åæ°çæå¹å¼è³æºï¼ç¨æ¼è§£æ±ºå¾·èªé«çèªç¶èªè¨èçä¸­çå¯¦ä¸ææ¼åå¾çåºæºç­ç¼ºåé¡ã

##### **Multi-stage intermediate fusion for multimodal learning to classify non-small cell lung cancer subtypes from CT and PET**
2501.12425v1 by Fatih Aksu, Fabrizia Gelardi, Arturo Chiti, Paolo Soda

Accurate classification of histological subtypes of non-small cell lung
cancer (NSCLC) is essential in the era of precision medicine, yet current
invasive techniques are not always feasible and may lead to clinical
complications. This study presents a multi-stage intermediate fusion approach
to classify NSCLC subtypes from CT and PET images. Our method integrates the
two modalities at different stages of feature extraction, using voxel-wise
fusion to exploit complementary information across varying abstraction levels
while preserving spatial correlations. We compare our method against unimodal
approaches using only CT or PET images to demonstrate the benefits of modality
fusion, and further benchmark it against early and late fusion techniques to
highlight the advantages of intermediate fusion during feature extraction.
Additionally, we compare our model with the only existing intermediate fusion
method for histological subtype classification using PET/CT images. Our results
demonstrate that the proposed method outperforms all alternatives across key
metrics, with an accuracy and AUC equal to 0.724 and 0.681, respectively. This
non-invasive approach has the potential to significantly improve diagnostic
accuracy, facilitate more informed treatment decisions, and advance
personalized care in lung cancer management.

æè¦ï¼å¨ç²¾æºé«ççæä»£ï¼æºç¢ºåé¡éå°ç´°èèºç (NSCLC) ççµç¹å­¸äºåè³ééè¦ï¼ä½ç®åçä¾µå¥æ§æè¡ä¸¦ä¸ç¸½æ¯å¯è¡ï¼ä¸å¯è½æå°è´è¨åºä½µç¼çãæ¬ç ç©¶æåºäºä¸ç¨®å¤éæ®µä¸­éèåæ¹æ³ï¼å¾é»è¦æ·å±¤ (CT) åæ­£å­æ·å±¤ææ (PET) å½±åä¸­åé¡ NSCLC äºåãæåçæè¡å¨ç¹å¾µèåçä¸åéæ®µæ´åéå©ç¨®æ¹å¼ï¼å©ç¨éé«ç´ èåä¾å©ç¨ä¸åæ½è±¡å±¤ç´çäºè£è³è¨ï¼åæä¿çç©ºéç¸éæ§ãæåå°æåçæè¡èåä½¿ç¨é»è¦æ·å±¤ææ­£å­æ·å±¤ææå½±åçå®ä¸æ¨¡å¼æ¹æ³é²è¡æ¯è¼ï¼ä»¥è­ææ¨¡å¼èåçåªé»ï¼ä¸¦é²ä¸æ­¥å°å¶èæ©æåææèåæè¡é²è¡æ¯è¼ï¼ä»¥å¼·èª¿ç¹å¾µèåæéä¸­éèåçåªé»ãæ­¤å¤ï¼æåå°æåçæ¨¡åèå¯ä¸ç¾æçä¸­éèåæ¹æ³é²è¡æ¯è¼ï¼è©²æ¹æ³ä½¿ç¨æ­£å­æ·å±¤ææ/é»è¦æ·å±¤ææå½±åé²è¡çµç¹å­¸äºååé¡ãæåççµæè¡¨æï¼ææåºçæ¹æ³å¨æææ¿ä»£æ¹æ¡ä¸­è¡¨ç¾åªç°ï¼æºç¢ºçå AUC åå¥ç­æ¼ 0.724 å 0.681ãéç¨®éä¾µå¥æ§æ¹æ³æå¯è½é¡¯èæé«è¨ºæ·æºç¢ºçï¼ä¿é²æ´ææºçæ²»çæ±ºç­ï¼ä¸¦æ¨é²èºçç®¡çä¸­çåäººåç§è­·ã

##### **Adaptive Class Learning to Screen Diabetic Disorders in Fundus Images of Eye**
2501.12048v1 by Shramana Dey, Pallabi Dutta, Riddhasree Bhattacharyya, Surochita Pal, Sushmita Mitra, Rajiv Raman

The prevalence of ocular illnesses is growing globally, presenting a
substantial public health challenge. Early detection and timely intervention
are crucial for averting visual impairment and enhancing patient prognosis.
This research introduces a new framework called Class Extension with Limited
Data (CELD) to train a classifier to categorize retinal fundus images. The
classifier is initially trained to identify relevant features concerning
Healthy and Diabetic Retinopathy (DR) classes and later fine-tuned to adapt to
the task of classifying the input images into three classes: Healthy, DR, and
Glaucoma. This strategy allows the model to gradually enhance its
classification capabilities, which is beneficial in situations where there are
only a limited number of labeled datasets available. Perturbation methods are
also used to identify the input image characteristics responsible for
influencing the models decision-making process. We achieve an overall accuracy
of 91% on publicly available datasets.

æè¦ï¼å¨çç¼ç¾æ£ççæçºä¸åï¼å°å¬å±è¡çé æéå¤§ææ°ãæ©æç¼ç¾ååæå¹²é å°æ¼é é²è¦åéç¤åæ¹åæ£èé å¾è³ééè¦ãæ¬ç ç©¶æåºäºä¸ååçºæéæ¸æé¡å¥æ´å± (CELD) çæ°æ¡æ¶ï¼ç¨æ¼è¨ç·´åé¡å¨å°è¦ç¶²èç¼åºååé²è¡åé¡ãè©²åé¡å¨æåæ¥åè¨ç·´ä»¥è­å¥èå¥åº·åç³å°¿çè¦ç¶²èçè® (DR) é¡å¥ç¸éçç¹å¾µï¼ç¶å¾é²è¡å¾®èª¿ä»¥é©æå°è¼¸å¥åååé¡çºä¸é¡çä»»åï¼å¥åº·ãDR åéåç¼ãæ­¤ç­ç¥åè¨±æ¨¡åéæ­¥å¢å¼·å¶åé¡è½åï¼éå¨æ¨è¨æ¸æéæ¸éæéçææ³ä¸æ¯æççãæ¾åæ¹æ³ä¹ç¨æ¼è­å¥è² è²¬å½±é¿æ¨¡åæ±ºç­éç¨çè¼¸å¥ååç¹å¾µãæåå¨å¬éæ¸æéä¸å¯¦ç¾äº 91% çæ´é«æºç¢ºåº¦ã

##### **Tackling Small Sample Survival Analysis via Transfer Learning: A Study of Colorectal Cancer Prognosis**
2501.12421v1 by Yonghao Zhao, Changtao Li, Chi Shu, Qingbin Wu, Hong Li, Chuan Xu, Tianrui Li, Ziqiang Wang, Zhipeng Luo, Yazhou He

Survival prognosis is crucial for medical informatics. Practitioners often
confront small-sized clinical data, especially cancer patient cases, which can
be insufficient to induce useful patterns for survival predictions. This study
deals with small sample survival analysis by leveraging transfer learning, a
useful machine learning technique that can enhance the target analysis with
related knowledge pre-learned from other data. We propose and develop various
transfer learning methods designed for common survival models. For parametric
models such as DeepSurv, Cox-CC (Cox-based neural networks), and DeepHit
(end-to-end deep learning model), we apply standard transfer learning
techniques like pretraining and fine-tuning. For non-parametric models such as
Random Survival Forest, we propose a new transfer survival forest (TSF) model
that transfers tree structures from source tasks and fine-tunes them with
target data. We evaluated the transfer learning methods on colorectal cancer
(CRC) prognosis. The source data are 27,379 SEER CRC stage I patients, and the
target data are 728 CRC stage I patients from the West China Hospital. When
enhanced by transfer learning, Cox-CC's $C^{td}$ value was boosted from 0.7868
to 0.8111, DeepHit's from 0.8085 to 0.8135, DeepSurv's from 0.7722 to 0.8043,
and RSF's from 0.7940 to 0.8297 (the highest performance). All models trained
with data as small as 50 demonstrated even more significant improvement.
Conclusions: Therefore, the current survival models used for cancer prognosis
can be enhanced and improved by properly designed transfer learning techniques.
The source code used in this study is available at
https://github.com/YonghaoZhao722/TSF.

æè¦ï¼<paragraph>å­æ´»é æ¸¬å°é«çè³è¨å­¸è³ééè¦ãå¯¦åå·¥ä½èç¶å¸¸é¢å°å°è¦æ¨¡çè¨åºè³æï¼ç¹å¥æ¯çççæ£åæ¡ï¼éäºè³æå¯è½ä¸è¶³ä»¥èªç¼æç¨çæ¨¡å¼ä¾é²è¡å­æ´»é æ¸¬ãæ­¤ç ç©¶ééå©ç¨è½ç§»å­¸ç¿ä¾èçå°æ¨£æ¬å­æ´»åæï¼éæ¯ä¸ç¨®æç¨çæ©å¨å­¸ç¿æè¡ï¼å¯ä»¥ééå¾å¶ä»è³æé åå­¸ç¿å°çç¸éç¥è­ä¾å¢å¼·ç®æ¨åæãæåæåºä¸¦éç¼åç¨®å°çºå¸¸è¦å­æ´»æ¨¡åè¨­è¨çè½ç§»å­¸ç¿æ¹æ³ãå°æ¼åæ¸åæ¨¡åï¼ä¾å¦ DeepSurvãCox-CCï¼åºæ¼ Cox çç¥ç¶ç¶²è·¯ï¼å DeepHitï¼ç«¯å°ç«¯æ·±åº¦å­¸ç¿æ¨¡åï¼ï¼æåæç¨æ¨æºè½ç§»å­¸ç¿æè¡ï¼ä¾å¦é è¨ç·´åå¾®èª¿ãå°æ¼éåæ¸åæ¨¡åï¼ä¾å¦é¨æ©å­æ´»æ£®æï¼æåæåºä¸åæ°çè½ç§»å­æ´»æ£®æï¼TSFï¼æ¨¡åï¼å®å¾ä¾æºä»»åå³è¼¸æ¨¹ççµæ§ï¼ä¸¦ä½¿ç¨ç®æ¨è³æå¾®èª¿å®åãæåå¨çµç´è¸çï¼CRCï¼é å¾ä¸è©ä¼°äºè½ç§»å­¸ç¿æ¹æ³ãä¾æºè³æçº 27,379 å SEER CRC ç¬¬ä¸ææ£èï¼ç®æ¨è³æçºä¾èªä¸­åè¥¿é¨é«é¢ç 728 å CRC ç¬¬ä¸ææ£èãå¨ééè½ç§»å­¸ç¿å¢å¼·å¾ï¼Cox-CC ç $C^{td}$ å¼å¾ 0.7868 æåå° 0.8111ï¼DeepHit çå¾ 0.8085 æåå° 0.8135ï¼DeepSurv çå¾ 0.7722 æåå° 0.8043ï¼RSF çå¾ 0.7940 æåå° 0.8297ï¼æé«æè½ï¼ãææä»¥å°è³ 50 çè³æè¨ç·´çæ¨¡åé½å±ç¤ºåºæ´é¡¯èçé²æ­¥ãçµè«ï¼å æ­¤ï¼ç®åç¨æ¼ççé å¾çå­æ´»æ¨¡åå¯ä»¥ééé©ç¶è¨­è¨çè½ç§»å­¸ç¿æè¡ä¾å¢å¼·åæ¹åãæ¬ç ç©¶ä¸­ä½¿ç¨çåå§ç¢¼å¯å¨ https://github.com/YonghaoZhao722/TSF åå¾ã</paragraph>

##### **Benchmarking Generative AI for Scoring Medical Student Interviews in Objective Structured Clinical Examinations (OSCEs)**
2501.13957v1 by Jadon Geathers, Yann Hicke, Colleen Chan, Niroop Rajashekar, Justin Sewell, Susannah Cornes, Rene Kizilcec, Dennis Shung

Introduction. Objective Structured Clinical Examinations (OSCEs) are widely
used to assess medical students' communication skills, but scoring
interview-based assessments is time-consuming and potentially subject to human
bias. This study explored the potential of large language models (LLMs) to
automate OSCE evaluations using the Master Interview Rating Scale (MIRS).
  Methods. We compared the performance of four state-of-the-art LLMs (GPT-4o,
Claude 3.5, Llama 3.1, and Gemini 1.5 Pro) in evaluating OSCE transcripts
across all 28 items of the MIRS under the conditions of zero-shot,
chain-of-thought (CoT), few-shot, and multi-step prompting. The models were
benchmarked against a dataset of 10 OSCE cases with 174 expert consensus scores
available. Model performance was measured using three accuracy metrics (exact,
off-by-one, thresholded).
  Results. Averaging across all MIRS items and OSCE cases, LLMs performed with
low exact accuracy (0.27 to 0.44), and moderate to high off-by-one accuracy
(0.67 to 0.87) and thresholded accuracy (0.75 to 0.88). A zero temperature
parameter ensured high intra-rater reliability ($\alpha = 0.98$ for GPT-4o).
CoT, few-shot, and multi-step techniques proved valuable when tailored to
specific assessment items. The performance was consistent across MIRS items
independent of encounter phases and communication domains.
  Conclusion. We demonstrated the feasibility of AI-assisted OSCE evaluation
and provided benchmarking of multiple LLMs across multiple prompt techniques.
Our work provides a baseline performance assessment for LLMs that lays a
foundation for future research in automated assessment of clinical
communication skills.

æè¦ï¼<paragraph>ç·è«ãå®¢è§çµæ§åè¨åºèè©¦ (OSCE) å»£æ³ç¨æ¼è©éé«å­¸ççæºéæå·§ï¼ä½è©ååºæ¼è¨ªè«çè©ééå¸¸èæï¼ä¸æ½å¨åå°äººé¡åè¦çå½±é¿ãæ¬ç ç©¶æ¢è¨å¤§åèªè¨æ¨¡å (LLM) ä½¿ç¨å¤§å¸«è¨ªè«è©åéè¡¨ (MIRS) èªåå OSCE è©éçå¯è½æ§ã
æ¹æ³ãæåæ¯è¼äºåç¨®æåé²ç LLMï¼GPT-4oãClaude 3.5ãLlama 3.1 å Gemini 1.5 Proï¼å¨è©é OSCE æç¸¾å®çè¡¨ç¾ï¼ç¯åæ¶µè MIRS çææ 28 åé ç®ï¼æ¢ä»¶çºé¶æ¬¡å­¸ç¿ãæèé (CoT)ãå°æ¬¡å­¸ç¿åå¤æ­¥é©æç¤ºãéäºæ¨¡åä»¥ 10 å OSCE æ¡ä¾çè³æéçºåºæºï¼å¶ä¸­æ 174 åå°å®¶å±è­åæ¸å¯ç¨ãæ¨¡åè¡¨ç¾ä½¿ç¨ä¸åæºç¢ºæ§ææ¨ï¼å®å¨ãåé¢ä¸ãé¾å¼ï¼é²è¡è¡¡éã
çµæãå¹³åææ MIRS é ç®å OSCE æ¡ä¾ï¼LLM çå®å¨æºç¢ºæ§ä½ï¼0.27 å° 0.44ï¼ï¼åé¢ä¸æºç¢ºæ§ä¸­ç­è³é«ï¼0.67 å° 0.87ï¼ï¼é¾å¼æºç¢ºæ§é«ï¼0.75 å° 0.88ï¼ãé¶æº«åº¦åæ¸ç¢ºä¿äºå¾é«çè©åèå§é¨ä¿¡åº¦ï¼GPT-4o ç Î± = 0.98ï¼ãç¶éå°ç¹å®è©éé ç®é²è¡èª¿æ´æï¼CoTãå°æ¬¡å­¸ç¿åå¤æ­¥é©æè¡è¢«è­ææ¯æå¹å¼çãè¡¨ç¾è MIRS é ç®ä¸è´ï¼èé­ééæ®µåæºéé åç¡éã
çµè«ãæåå±ç¤ºäº AI è¼å© OSCE è©éçå¯è¡æ§ï¼ä¸¦æä¾äºå¤ç¨®æç¤ºæè¡ç LLM åºæºæ¸¬è©¦ãæåçç ç©¶çº LLM æä¾äºåºæºè¡¨ç¾è©éï¼çºè¨åºæºéæå·§èªååè©éçæªä¾ç ç©¶å¥ å®äºåºç¤ã</paragraph>

##### **Data-driven Detection and Evaluation of Damages in Concrete Structures: Using Deep Learning and Computer Vision**
2501.11836v1 by Saeid Ataei, Saeed Adibnazari, Seyyed Taghi Ataei

Structural integrity is vital for maintaining the safety and longevity of
concrete infrastructures such as bridges, tunnels, and walls. Traditional
methods for detecting damages like cracks and spalls are labor-intensive,
time-consuming, and prone to human error. To address these challenges, this
study explores advanced data-driven techniques using deep learning for
automated damage detection and analysis. Two state-of-the-art instance
segmentation models, YOLO-v7 instance segmentation and Mask R-CNN, were
evaluated using a dataset comprising 400 images, augmented to 10,995 images
through geometric and color-based transformations to enhance robustness. The
models were trained and validated using a dataset split into 90% training set,
validation and test set 10%. Performance metrics such as precision, recall,
mean average precision (mAP@0.5), and frames per second (FPS) were used for
evaluation. YOLO-v7 achieved a superior mAP@0.5 of 96.1% and processed 40 FPS,
outperforming Mask R-CNN, which achieved a mAP@0.5 of 92.1% with a slower
processing speed of 18 FPS. The findings recommend YOLO-v7 instance
segmentation model for real-time, high-speed structural health monitoring,
while Mask R-CNN is better suited for detailed offline assessments. This study
demonstrates the potential of deep learning to revolutionize infrastructure
maintenance, offering a scalable and efficient solution for automated damage
detection.

æè¦ï¼çµæ§å®æ´æ§å°æ¼ç¶­è­·æ©æ¨ãé§éåçå£ç­æ··åååºç¤è¨­æ½çå®å¨æ§åä½¿ç¨å£½å½è³ééè¦ãå³çµ±çæå£æª¢æ¸¬æ¹æ³ï¼ä¾å¦è£ç¸«ååè½ï¼éè¦å¤§éäººå·¥ï¼èæä¸å®¹æåºç¾äººçºé¯èª¤ãçºäºæå°éäºææ°ï¼æ¬ç ç©¶æ¢è¨äºä½¿ç¨æ·±åº¦å­¸ç¿çåé²æ¸æé©åæè¡ï¼ç¨æ¼èªåæå£æª¢æ¸¬ååæãä½¿ç¨åå« 400 å¼µååçæ¸æéè©ä¼°äºå©åæåé²çå¯¦ä¾åå²æ¨¡åï¼YOLO-v7 å¯¦ä¾åå²å Mask R-CNNï¼ééå¹¾ä½ååºæ¼é¡è²çè½ææ´å±å° 10,995 å¼µååï¼ä»¥å¢å¼·é­¯æ£æ§ãä½¿ç¨åçº 90% è¨ç·´éãé©è­åæ¸¬è©¦é 10% çæ¸æéè¨ç·´åé©è­æ¨¡åãä½¿ç¨ç²¾ç¢ºåº¦ãå¬åçãå¹³åå¹³åç²¾ç¢ºåº¦ (mAP@0.5) åæ¯ç§å¹æ¸ (FPS) ç­æ§è½ææ¨é²è¡è©ä¼°ãYOLO-v7 éå°äº 96.1% çåªç° mAP@0.5ï¼ä¸¦èçäº 40 FPSï¼åªæ¼ Mask R-CNNï¼å¾èä»¥ 18 FPS çè¼æ¢èçéåº¦éå°äº 92.1% ç mAP@0.5ãç ç©¶çµææ¨è¦ä½¿ç¨ YOLO-v7 å¯¦ä¾åå²æ¨¡åé²è¡å¯¦æãé«éçµæ§å¥åº·ç£æ¸¬ï¼è Mask R-CNN æ´é©åè©³ç´°çé¢ç·è©ä¼°ãæ¬ç ç©¶å±ç¤ºäºæ·±åº¦å­¸ç¿å¨åºç¤è¨­æ½ç¶­è­·æ¹é¢å·æé©å½æ§çæ½åï¼çºèªåæå£æª¢æ¸¬æä¾äºä¸åå¯æ´å±ä¸é«æçè§£æ±ºæ¹æ¡ã

##### **GL-ICNN: An End-To-End Interpretable Convolutional Neural Network for the Diagnosis and Prediction of Alzheimer's Disease**
2501.11715v1 by Wenjie Kang, Lize Jiskoot, Peter De Deyn, Geert Biessels, Huiberdina Koek, Jurgen Claassen, Huub Middelkoop, Wiesje Flier, Willemijn J. Jansen, Stefan Klein, Esther Bron

Deep learning methods based on Convolutional Neural Networks (CNNs) have
shown great potential to improve early and accurate diagnosis of Alzheimer's
disease (AD) dementia based on imaging data. However, these methods have yet to
be widely adopted in clinical practice, possibly due to the limited
interpretability of deep learning models. The Explainable Boosting Machine
(EBM) is a glass-box model but cannot learn features directly from input
imaging data. In this study, we propose a novel interpretable model that
combines CNNs and EBMs for the diagnosis and prediction of AD. We develop an
innovative training strategy that alternatingly trains the CNN component as a
feature extractor and the EBM component as the output block to form an
end-to-end model. The model takes imaging data as input and provides both
predictions and interpretable feature importance measures. We validated the
proposed model on the Alzheimer's Disease Neuroimaging Initiative (ADNI)
dataset and the Health-RI Parelsnoer Neurodegenerative Diseases Biobank (PND)
as an external testing set. The proposed model achieved an area-under-the-curve
(AUC) of 0.956 for AD and control classification, and 0.694 for the prediction
of conversion of mild cognitive impairment (MCI) to AD on the ADNI cohort. The
proposed model is a glass-box model that achieves a comparable performance with
other state-of-the-art black-box models. Our code is publicly available at:
https://anonymous.4open.science/r/GL-ICNN.

æè¦ï¼<paragraph>åºæ¼å·ç©ç¥ç¶ç¶²è·¯ (CNN) çæ·±åº¦å­¸ç¿æ¹æ³å·²é¡¯ç¤ºåºæ¥µå¤§çæ½åï¼å¯æ ¹æå½±åè³ææ¹åé¿è²æµ·é»ç (AD) å¤±æºççæ©ææºç¢ºè¨ºæ·ãç¶èï¼éäºæ¹æ³å°æªå»£æ³æç¨æ¼è¨åºå¯¦åä¸­ï¼éå¯è½æ¯ç±æ¼æ·±åº¦å­¸ç¿æ¨¡åçå¯è§£éæ§æéãå¯è§£éæåæ© (EBM) æ¯åç»ççæ¨¡åï¼ä½ç¡æ³ç´æ¥å¾è¼¸å¥å½±åè³æä¸­å­¸ç¿ç¹å¾µãå¨éé ç ç©¶ä¸­ï¼æåæåºä¸åçµå CNN å EBM çæ°å¯è§£éæ¨¡åï¼ç¨æ¼è¨ºæ·åé æ¸¬ ADãæåéç¼äºä¸ç¨®åµæ°çè¨ç·´ç­ç¥ï¼äº¤æ¿è¨ç·´ CNN çµä»¶ä½çºç¹å¾µèåå¨ï¼ä¸¦è¨ç·´ EBM çµä»¶ä½çºè¼¸åºåå¡ï¼ä»¥å½¢æç«¯å°ç«¯æ¨¡åãæ­¤æ¨¡åå°å½±åè³æä½çºè¼¸å¥ï¼ä¸¦æä¾é æ¸¬åå¯è§£éçç¹å¾µéè¦æ§æ¸¬éãæåå¨é¿è²æµ·é»çç¥ç¶å½±åå¡è­° (ADNI) è³æéå Health-RI Parelsnoer ç¥ç¶éåç¾ççç©è³æåº« (PND) ä¸é©è­äºææåºçæ¨¡åï¼ä½çºå¤é¨æ¸¬è©¦éãææåºçæ¨¡åå¨ AD åå°ç§åé¡ä¸­éå°äº 0.956 çæ²ç·ä¸é¢ç© (AUC)ï¼ä¸¦å¨ ADNI éåä¸­é æ¸¬è¼åº¦èªç¥éç¤ (MCI) è½åçº AD æéå°äº 0.694ãææåºçæ¨¡åæ¯ä¸åç»ççæ¨¡åï¼å¶æè½èå¶ä»æåé²çé»çæ¨¡åç¸ç¶ãæåçç¨å¼ç¢¼å¯å¨ä»¥ä¸ç¶²åå¬éåå¾ï¼https://anonymous.4open.science/r/GL-ICNNã</paragraph>

##### **Human services organizations and the responsible integration of AI: Considering ethics and contextualizing risk(s)**
2501.11705v1 by Brian E. Perron, Lauri Goldkind, Zia Qi, Bryan G. Victor

This paper examines the responsible integration of artificial intelligence
(AI) in human services organizations (HSOs), proposing a nuanced framework for
evaluating AI applications across multiple dimensions of risk. The authors
argue that ethical concerns about AI deployment -- including professional
judgment displacement, environmental impact, model bias, and data laborer
exploitation -- vary significantly based on implementation context and specific
use cases. They challenge the binary view of AI adoption, demonstrating how
different applications present varying levels of risk that can often be
effectively managed through careful implementation strategies. The paper
highlights promising solutions, such as local large language models, that can
facilitate responsible AI integration while addressing common ethical concerns.
The authors propose a dimensional risk assessment approach that considers
factors like data sensitivity, professional oversight requirements, and
potential impact on client wellbeing. They conclude by outlining a path forward
that emphasizes empirical evaluation, starting with lower-risk applications and
building evidence-based understanding through careful experimentation. This
approach enables organizations to maintain high ethical standards while
thoughtfully exploring how AI might enhance their capacity to serve clients and
communities effectively.

æè¦ï¼æ¬ææ¢è¨äºäººå·¥æºæ§ (AI) å¨äººé¡æåçµç¹ (HSO) ä¸­è² è²¬ä»»çæ´åï¼æåºäºä¸åç´°ç·»çæ¡æ¶ï¼ç¨æ¼è©ä¼° AI æç¨å¨å¤åé¢¨éªç¶­åº¦ãä½èèªçºï¼å° AI é¨ç½²çéå¾·èéââåæ¬å°æ¥­å¤æ·çåä»£ãç°å¢å½±é¿ãæ¨¡ååå·®åè³æå·¥ä½èçååââææ ¹æå¯¦æ½èæ¯åå·é«ä½¿ç¨æ¡ä¾èæé¡¯èçä¸åãä»åææ°äº AI æ¡ç¨äºåè«çè§é»ï¼èªªæäºä¸åçæç¨å¦ä½åç¾ä¸åç¨åº¦çé¢¨éªï¼èéäºé¢¨éªéå¸¸å¯ä»¥ééä»ç´°çå¯¦æ½ç­ç¥ä¾ææç®¡çãæ¬æéé»ä»ç´¹äºæåæ¯çè§£æ±ºæ¹æ¡ï¼ä¾å¦æ¬å°å¤§åèªè¨æ¨¡åï¼å®å¯ä»¥å¨è§£æ±ºå¸¸è¦çéå¾·åé¡çåæï¼ä¿é²è² è²¬ä»»ç AI æ´åãä½èæåºäºä¸ç¨®ç¶­åº¦é¢¨éªè©ä¼°æ¹æ³ï¼è©²æ¹æ³èæ®äºè³æææåº¦ãå°æ¥­ç£ç£éæ±åå°å®¢æ¶ç¦ç¥çæ½å¨å½±é¿ç­å ç´ ãä»åæå¾æ¦è¿°äºä¸æ¢åé²çéè·¯ï¼å¼·èª¿å¯¦è­è©ä¼°ï¼å¾ä½é¢¨éªæç¨éå§ï¼ä¸¦ééä»ç´°çå¯¦é©å»ºç«åºæ¼è­æççè§£ãéç¨®æ¹æ³ä½¿çµç¹è½å¤ å¨æ·±æçæ®å°æ¢è¨ AI å¦ä½å¢å¼·å¶æææåå®¢æ¶åç¤¾ç¾¤çè½åçåæï¼ç¶­æé«éå¾·æ¨æºã

##### **Spatially-Delineated Domain-Adapted AI Classification: An Application for Oncology Data**
2501.11695v1 by Majid Farhadloo, Arun Sharma, Alexey Leontovich, Svetomir N. Markovic, Shashi Shekhar

Given multi-type point maps from different place-types (e.g., tumor regions),
our objective is to develop a classifier trained on the source place-type to
accurately distinguish between two classes of the target place-type based on
their point arrangements. This problem is societally important for many
applications, such as generating clinical hypotheses for designing new
immunotherapies for cancer treatment. The challenge lies in the spatial
variability, the inherent heterogeneity and variation observed in spatial
properties or arrangements across different locations (i.e., place-types).
Previous techniques focus on self-supervised tasks to learn domain-invariant
features and mitigate domain differences; however, they often neglect the
underlying spatial arrangements among data points, leading to significant
discrepancies across different place-types. We explore a novel multi-task
self-learning framework that targets spatial arrangements, such as spatial
mix-up masking and spatial contrastive predictive coding, for
spatially-delineated domain-adapted AI classification. Experimental results on
real-world datasets (e.g., oncology data) show that the proposed framework
provides higher prediction accuracy than baseline methods.

æè¦ï¼å¾ä¸åé¡åçé»åï¼ä¾å¦ï¼è«ç¤ååï¼ä¸­çµ¦å®å¤é¡åé»åï¼
æåçç®æ¨æ¯éç¼ä¸åå¨ä¾æºé¡åä¸è¨ç·´çåé¡å¨ï¼ä»¥
æ ¹æå¶é»æåæºç¢ºååç®æ¨é¡åä¸­çå©é¡ãéååé¡å°æ¼è¨±å¤
æç¨ä¾èªªå·æç¤¾æéè¦æ§ï¼ä¾å¦çºççæ²»çè¨­è¨æ°çåç«çæ³èçæè¨åºåè¨­ãææ°å¨æ¼ç©ºé
è®ç°æ§ãåºæçç°è³ªæ§åå¨ä¸åä½ç½®ï¼å³é¡åï¼ä¸­è§å¯å°çç©ºé
å±¬æ§ææåçè®åãååçæè¡å°æ³¨æ¼èªç£ç£ä»»åä»¥å­¸ç¿ä¸è®é å
ç¹å¾µä¸¦æ¸è¼é åå·®ç°ï¼ç¶èï¼å®åéå¸¸å¿½è¦æ¸æé»ä¹éç
åºå±¤ç©ºéæåï¼å°è´ä¸åé¡åä¹éå­å¨é¡¯èå·®ç°ãæåæ¢ç´¢äºä¸ç¨®æ°ç©çå¤ä»»å
èªå­¸ç¿æ¡æ¶ï¼ä»¥éå°ç©ºéæåï¼ä¾å¦ç©ºéæ··åæ©è½åç©ºéå°æ¯é æ¸¬ç·¨ç¢¼ï¼ç¨æ¼
ç©ºéååçé åé©æ AI åé¡ãå¨
çå¯¦ä¸çæ¸æéï¼ä¾å¦ï¼è«ç¤å­¸æ¸æï¼ä¸çå¯¦é©çµæè¡¨æï¼ææåºçæ¡æ¶
æä¾çé æ¸¬æºç¢ºåº¦é«æ¼åºç·æ¹æ³ã

##### **Multilinguality in LLM-Designed Reward Functions for Restless Bandits: Effects on Task Performance and Fairness**
2501.13120v1 by Ambreesh Parthasarathy, Chandrasekar Subramanian, Ganesh Senrayan, Shreyash Adappanavar, Aparna Taneja, Balaraman Ravindran, Milind Tambe

Restless Multi-Armed Bandits (RMABs) have been successfully applied to
resource allocation problems in a variety of settings, including public health.
With the rapid development of powerful large language models (LLMs), they are
increasingly used to design reward functions to better match human preferences.
Recent work has shown that LLMs can be used to tailor automated allocation
decisions to community needs using language prompts. However, this has been
studied primarily for English prompts and with a focus on task performance
only. This can be an issue since grassroots workers, especially in developing
countries like India, prefer to work in local languages, some of which are
low-resource. Further, given the nature of the problem, biases along population
groups unintended by the user are also undesirable. In this work, we study the
effects on both task performance and fairness when the DLM algorithm, a recent
work on using LLMs to design reward functions for RMABs, is prompted with
non-English language commands. Specifically, we run the model on a synthetic
environment for various prompts translated into multiple languages. The prompts
themselves vary in complexity. Our results show that the LLM-proposed reward
functions are significantly better when prompted in English compared to other
languages. We also find that the exact phrasing of the prompt impacts task
performance. Further, as prompt complexity increases, performance worsens for
all languages; however, it is more robust with English prompts than with
lower-resource languages. On the fairness side, we find that low-resource
languages and more complex prompts are both highly likely to create unfairness
along unintended dimensions.

æè¦ï¼<paragraph>ä¸å®åçå¤èè³­å¾ (RMAB) å·²æåæç¨æ¼åç¨®ç°å¢ä¸­çè³æºåéåé¡ï¼åæ¬å¬å±è¡çãé¨èå¼·å¤§å¤§åèªè¨æ¨¡å (LLM) çå¿«éç¼å±ï¼å®åæ­£è¶ä¾è¶å¤å°ç¨æ¼è¨­è¨çåµå½æ¸ï¼ä»¥æ´å¥½å°å¹éäººé¡åå¥½ãæè¿çç ç©¶è¡¨æï¼LLM å¯ç¨æ¼ä½¿ç¨èªè¨æç¤ºæ ¹æç¤¾åéæ±èª¿æ´èªååéæ±ºç­ãç¶èï¼éä¸»è¦éå°è±èªæç¤ºé²è¡äºç ç©¶ï¼ä¸¦ä¸åéæ³¨ä»»åç¸¾æãéå¯è½æ¯ä¸ååé¡ï¼å çºåºå±¤å·¥ä½èï¼ç¹å¥æ¯åå°åº¦éæ¨£çç¼å±ä¸­åå®¶çå·¥ä½èï¼æ´é¡æä½¿ç¨ç¶å°èªè¨ï¼å¶ä¸­ä¸äºèªè¨æ¯ä½è³æºçãæ­¤å¤ï¼éæ¼åé¡çæ§è³ªï¼ç¨æ¶ç¡æä¸­å°äººå£ç¾¤é«ç¢ççåè¦ä¹æ¯ä¸åæ­¡è¿çãå¨éé å·¥ä½ä¸­ï¼æåç ç©¶äºç¶ DLM æ¼ç®æ³ï¼æè¿ä½¿ç¨ LLM çº RMAB è¨­è¨çåµå½æ¸çå·¥ä½ï¼æ¶å°éè±èªèªè¨å½ä»¤æï¼å°ä»»åç¸¾æåå¬å¹³æ§çå½±é¿ãå·é«ä¾èªªï¼æåå¨åæç°å¢ä¸­éè¡æ¨¡åï¼å°ç¿»è­¯æå¤ç¨®èªè¨çåç¨®æç¤ºé²è¡éè¡ãæç¤ºæ¬èº«çè¤éæ§åä¸ç¸åãæåççµæè¡¨æï¼èå¶ä»èªè¨ç¸æ¯ï¼ç¨è±èªæç¤ºæï¼LLM æåºççåµå½æ¸é¡¯èæ´å¥½ãæåéç¼ç¾æç¤ºçç¢ºåæªè¾­æå½±é¿ä»»åç¸¾æãæ­¤å¤ï¼é¨èæç¤ºè¤éæ§çå¢å ï¼ææèªè¨çæ§è½é½æä¸éï¼ç¶èï¼å®æ¯ä½è³æºèªè¨æ´å¥å£¯ãå¨å¬å¹³æ§æ¹é¢ï¼æåç¼ç¾ä½è³æºèªè¨åæ´è¤éçæç¤ºé½æ¥µæå¯è½å¨æå¤çç¶­åº¦ä¸é æä¸å¬å¹³ã</paragraph>

##### **Biomedical Knowledge Graph: A Survey of Domains, Tasks, and Real-World Applications**
2501.11632v2 by Yuxing Lu, Sin Yee Goi, Xukai Zhao, Jinzhuo Wang

Biomedical knowledge graphs (BKGs) have emerged as powerful tools for
organizing and leveraging the vast and complex data found across the biomedical
field. Yet, current reviews of BKGs often limit their scope to specific domains
or methods, overlooking the broader landscape and the rapid technological
progress reshaping it. In this survey, we address this gap by offering a
systematic review of BKGs from three core perspectives: domains, tasks, and
applications. We begin by examining how BKGs are constructed from diverse data
sources, including molecular interactions, pharmacological datasets, and
clinical records. Next, we discuss the essential tasks enabled by BKGs,
focusing on knowledge management, retrieval, reasoning, and interpretation.
Finally, we highlight real-world applications in precision medicine, drug
discovery, and scientific research, illustrating the translational impact of
BKGs across multiple sectors. By synthesizing these perspectives into a unified
framework, this survey not only clarifies the current state of BKG research but
also establishes a foundation for future exploration, enabling both innovative
methodological advances and practical implementations.

æè¦ï¼çç©å»å­¦ç¥è¯å¾è°±ï¼BKGï¼å·²æä¸ºç»ç»åå©ç¨çç©å»å­¦é¢åä¸­åç°çåºå¤§ä¸å¤ææ°æ®çå¼ºå¤§å·¥å·ãç¶èï¼å½åå¯¹ BKG çå®¡æ¥éå¸¸å°å¶èå´éå¶å¨ç¹å®é¢åææ¹æ³ï¼å¿½è§äºæ´å¹¿æ³çæ ¼å±åæ­£å¨éå¡å®çå¿«éææ¯è¿æ­¥ãå¨è¿é¡¹è°æ¥ä¸­ï¼æä»¬éè¿ä»ä¸ä¸ªæ ¸å¿è§åº¦ï¼é¢åãä»»å¡ååºç¨ï¼å¯¹ BKG è¿è¡ç³»ç»å®¡æ¥æ¥è§£å³è¿ä¸å·®è·ãæä»¬é¦åæ£æ¥å¦ä½ä»åæ¬åå­ç¸äºä½ç¨ãè¯çæ°æ®éåä¸´åºè®°å½å¨åçåç§æ°æ®æºæå»º BKGãæ¥ä¸æ¥ï¼æä»¬è®¨è®º BKG å¯ç¨çåºæ¬ä»»å¡ï¼éç¹å³æ³¨ç¥è¯ç®¡çãæ£ç´¢ãæ¨çåè§£éãæåï¼æä»¬éç¹ä»ç»äºç²¾åå»çãè¯ç©åç°åç§å­¦ç ç©¶ä¸­çå®éåºç¨ï¼è¯´æäº BKG å¨å¤ä¸ªé¢åçè½¬åå½±åãéè¿å°è¿äºè§ç¹ç»¼åå°ä¸ä¸ªç»ä¸çæ¡æ¶ä¸­ï¼æ¬è°æ¥ä¸ä»éæäº BKG ç ç©¶çç°ç¶ï¼è¿ä¸ºæªæ¥çæ¢ç´¢å¥ å®äºåºç¡ï¼æ¢ä¿è¿äºåæ°æ¹æ³çè¿æ­¥ï¼ä¹ä¿è¿äºå®éå®æ½ã

##### **Training-free Ultra Small Model for Universal Sparse Reconstruction in Compressed Sensing**
2501.11592v2 by Chaoqing Tang, Huanze Zhuang, Guiyun Tian, Zhenli Zeng, Yi Ding, Wenzhong Liu, Xiang Bai

Pre-trained large models attract widespread attention in recent years, but
they face challenges in applications that require high interpretability or have
limited resources, such as physical sensing, medical imaging, and
bioinformatics. Compressed Sensing (CS) is a well-proved theory that drives
many recent breakthroughs in these applications. However, as a typical
under-determined linear system, CS suffers from excessively long sparse
reconstruction times when using traditional iterative methods, particularly
with large-scale data. Current AI methods like deep unfolding fail to
substitute them because pre-trained models exhibit poor generality beyond their
training conditions and dataset distributions, or lack interpretability.
Instead of following the big model fervor, this paper proposes ultra-small
artificial neural models called coefficients learning (CL), enabling
training-free and rapid sparse reconstruction while perfectly inheriting the
generality and interpretability of traditional iterative methods, bringing new
feature of incorporating prior knowledges. In CL, a signal of length $n$ only
needs a minimal of $n$ trainable parameters. A case study model called CLOMP is
implemented for evaluation. Experiments are conducted on both synthetic and
real one-dimensional and two-dimensional signals, demonstrating significant
improvements in efficiency and accuracy. Compared to representative iterative
methods, CLOMP improves efficiency by 100 to 1000 folds for large-scale data.
Test results on eight diverse image datasets indicate that CLOMP improves
structural similarity index by 292%, 98%, 45% for sampling rates of 0.1, 0.3,
0.5, respectively. We believe this method can truly usher CS reconstruction
into the AI era, benefiting countless under-determined linear systems that rely
on sparse solution.

æè¦ï¼<paragraph>é è¨ç·´å¤§åæ¨¡åè¿å¹´ä¾å»£åéæ³¨ï¼ä½å®åå¨éè¦é«å¯è§£éæ§æè³æºåéçæç¨ä¸­é¢è¨ææ°ï¼ä¾å¦ç©çææ¸¬ãé«å­¸å½±ååçç©è³è¨å­¸ãå£ç¸®ææ¸¬ (CS) æ¯ä¸åç¶éé©è­ççè«ï¼æ¨åäºéäºæç¨ä¸­çè¨±å¤è¿æçªç ´ãç¶èï¼ä½çºä¸åå¸åçæ¬ å®ç·æ§ç³»çµ±ï¼CS å¨ä½¿ç¨å³çµ±è¿­ä»£æ¹æ³ææå°è´éé·çç¨çéå»ºæéï¼ç¹å¥æ¯å¨å¤§è¦æ¨¡è³æçææ³ä¸ãåæ·±åº¦å±éç­ç¶å AI æ¹æ³ç¡æ³åä»£å®åï¼å çºé è¨ç·´æ¨¡åå¨è¨ç·´æ¢ä»¶åè³æéåä½ä¹å¤è¡¨ç¾åºè¼å·®çæ¦æ¬æ§ï¼æç¼ºä¹å¯è§£éæ§ãæ¬è«ææ²æè¿½é¨å¤§åæ¨¡åç±æ½®ï¼èæ¯æåºäºç¨±çºä¿æ¸å­¸ç¿ (CL) çè¶å°åäººå·¥ç¥ç¶ç¶²è·¯æ¨¡åï¼å¯¦ç¾ç¡è¨ç·´ä¸å¿«éçç¨çéå»ºï¼åæå®ç¾ç¹¼æ¿å³çµ±è¿­ä»£æ¹æ³çæ¦æ¬æ§åå¯è§£éæ§ï¼å¸¶ä¾çµååé©ç¥è­çæ°ç¹é»ãå¨ CL ä¸­ï¼é·åº¦çº $n$ çä¿¡èåªéè¦æå° $n$ åå¯è¨ç·´åæ¸ãå¯¦ä½äºä¸åç¨±çº CLOMP çæ¡ä¾ç ç©¶æ¨¡åé²è¡è©ä¼°ãå¨åæåçå¯¦çä¸ç¶­åäºç¶­ä¿¡èä¸é²è¡äºå¯¦é©ï¼è­æäºæçåæºç¢ºæ§çé¡¯èæåãèå·ä»£è¡¨æ§çè¿­ä»£æ¹æ³ç¸æ¯ï¼CLOMP å°å¤§åè³æçæçæåäº 100 å° 1000 åãå¨å«åä¸åçå½±åè³æéä¸çæ¸¬è©¦çµæè¡¨æï¼CLOMP åå¥å°æ¡æ¨£ççº 0.1ã0.3ã0.5 ççµæ§ç¸ä¼¼æ§ææ¨æåäº 292%ã98%ã45%ãæåç¸ä¿¡éç¨®æ¹æ³å¯ä»¥çæ­£å° CS éå»ºå¸¶å¥ AI æä»£ï¼ä½¿ä¾è³´ç¨çè§£çç¡æ¸æ¬ å®ç·æ§ç³»çµ±åçã</paragraph>

##### **Enhancing Coronary Artery Calcium Scoring via Multi-Organ Segmentation on Non-Contrast Cardiac Computed Tomography**
2501.11428v1 by Jakub Nalepa, Tomasz Bartczak, Mariusz Bujny, JarosÅaw GoÅliÅski, Katarzyna Jesionek, Wojciech Malara, Filip Malawski, Karol Miszalski-Jamka, Patrycja Rewa, Marcin Kostur

Despite coronary artery calcium scoring being considered a largely solved
problem within the realm of medical artificial intelligence, this paper argues
that significant improvements can still be made. By shifting the focus from
pathology detection to a deeper understanding of anatomy, the novel algorithm
proposed in the paper both achieves high accuracy in coronary artery calcium
scoring and offers enhanced interpretability of the results. This approach not
only aids in the precise quantification of calcifications in coronary arteries,
but also provides valuable insights into the underlying anatomical structures.
Through this anatomically-informed methodology, the paper shows how a nuanced
understanding of the heart's anatomy can lead to more accurate and
interpretable results in the field of cardiovascular health. We demonstrate the
superior accuracy of the proposed method by evaluating it on an open-source
multi-vendor dataset, where we obtain results at the inter-observer level,
surpassing the current state of the art. Finally, the qualitative analyses show
the practical value of the algorithm in such tasks as labeling coronary artery
calcifications, identifying aortic calcifications, and filtering out false
positive detections due to noise.

æè¦ï¼åç®¡å çåèé£åè©åå¨é«å­¸äººå·¥æºæ§é åè¢«èªçºæ¯ä¸åå·²è§£æ±ºçåé¡ï¼ä½æ¬æè«è­ä»æé¡¯èé²æ­¥çç©ºéãééå°ç¦é»å¾ççæª¢æ¸¬è½ç§»å°å°è§£åçµæ§çæ´æ·±å¥çè§£ï¼æ¬ææåºçæ°æ¼ç®æ³å¨å çåèé£åè©åä¸­ç²å¾é«æºç¢ºåº¦ï¼ä¸¦æä¾äºå¢å¼·ççµæå¯è§£éæ§ãéç¨®æ¹æ³ä¸åæå©æ¼ç²¾ç¢ºéåå çåèçé£åï¼éæä¾äºå°åºå±¤è§£åçµæ§çå¯¶è²´è¦è§£ãéééç¨®è§£åå­¸æ¹æ³ï¼æ¬æå±ç¤ºäºå°å¿èè§£åçµæ§çç´°ç·»çè§£å¦ä½è½å°è´å¿è¡ç®¡å¥åº·é åæ´æºç¢ºä¸å¯è§£éççµæãæåééå¨éæ¾åå§ç¢¼çå¤å» åè³æéä¸è©ä¼°ææåºçæ¹æ³ï¼è­æäºå¶åªè¶çæºç¢ºåº¦ï¼æåå¨è§å¯èéå±¤ç´ç²å¾ççµæè¶è¶äºç®åçæè¡æ°´æºãæå¾ï¼å®æ§åæé¡¯ç¤ºäºè©²æ¼ç®æ³å¨æ¨è¨å çåèé£åãè­å¥ä¸»åèé£åä»¥åéæ¿¾æå éè¨èç¢ççåé½æ§åµæ¸¬ç­ä»»åä¸­çå¯¦ç¨å¹å¼ã

##### **RedStar: Does Scaling Long-CoT Data Unlock Better Slow-Reasoning Systems?**
2501.11284v1 by Haotian Xu, Xing Wu, Weinong Wang, Zhongzhi Li, Da Zheng, Boyuan Chen, Yi Hu, Shijia Kang, Jiaming Ji, Yingying Zhang, Zhijiang Guo, Yaodong Yang, Muhan Zhang, Debing Zhang

Can scaling transform reasoning? In this work, we explore the untapped
potential of scaling Long Chain-of-Thought (Long-CoT) data to 1000k samples,
pioneering the development of a slow-thinking model, RedStar. Through extensive
experiments with various LLMs and different sizes, we uncover the ingredients
for specialization and scale for Long-CoT training. Surprisingly, even smaller
models show significant performance gains with limited data, revealing the
sample efficiency of Long-CoT and the critical role of sample difficulty in the
learning process. Our findings demonstrate that Long-CoT reasoning can be
effectively triggered with just a few thousand examples, while larger models
achieve unparalleled improvements. We also introduce reinforcement learning
(RL)-scale training as a promising direction for advancing slow-thinking
systems. RedStar shines across domains: on the MATH-Hard benchmark,
RedStar-code-math boosts performance from 66.2\% to 81.6\%, and on the USA Math
Olympiad (AIME), it solves 46.7\% of problems using only 21k mixed-code-math
datasets. In multimodal tasks like GeoQA and MathVista-GEO, RedStar-Geo
achieves competitive results with minimal Long-CoT data, outperforming other
slow-thinking systems like QvQ-Preview. Compared to QwQ, RedStar strikes the
perfect balance between reasoning and generalizability. Our work highlights
that, with careful tuning, scaling Long-CoT can unlock extraordinary reasoning
capabilities-even with limited dataset and set a new standard for slow-thinking
models across diverse challenges. Our data and models are released at
https://huggingface.co/RedStar-Reasoning.

æè¦ï¼<paragraph>ç¸®æ¾å¯ä»¥è½ææ¨çåï¼å¨éé å·¥ä½ä¸­ï¼æåæ¢ç´¢å°é·éæèï¼Long-CoTï¼è³æç¸®æ¾å° 1000k ç¯ä¾çæªéç¼æ½åï¼çåéç¼æ¢æèæ¨¡å RedStarãééä½¿ç¨åç¨® LLM åä¸åå¤§å°é²è¡å»£æ³å¯¦é©ï¼æåæ­ç¤ºäº Long-CoT è¨ç·´çå°æ¥­ååè¦æ¨¡è¦ç´ ãä»¤äººé©è¨çæ¯ï¼å³ä½¿è¼å°çæ¨¡åå¨è³ææéçææ³ä¸ä¹å±ç¾åºé¡¯èçæè½æåï¼æ­ç¤ºäº Long-CoT çç¯ä¾æçåç¯ä¾é£åº¦å¨å­¸ç¿éç¨ä¸­æ®æ¼çééµè§è²ãæåçç¼ç¾è­æï¼åªè¦ææ¸ååç¯ä¾ï¼å°±å¯ä»¥ææè§¸ç¼ Long-CoT æ¨çï¼èè¼å¤§çæ¨¡ååå¯ç²å¾ç¡èå«æ¯çæ¹é²ãæåéå°å¥å¼·åå­¸ç¿ (RL) è¦æ¨¡è¨ç·´ï¼ä½çºæ¨é²æ¢æèç³»çµ±çä¸åæåéçæ¹åãRedStar å¨ååé åä¸­è¡¨ç¾åºè²ï¼å¨ MATH-Hard åºæºæ¸¬è©¦ä¸­ï¼RedStar-code-math å°æè½å¾ 66.2% æåè³ 81.6%ï¼èå¨ç¾åæ¸å­¸å¥§æå¹åï¼AIMEï¼ä¸­ï¼å®åä½¿ç¨ 21k åæ··åç¨å¼ç¢¼æ¸å­¸è³æéå°±è§£æ±ºäº 46.7% çåé¡ãå¨ GeoQA å MathVista-GEO ç­å¤æ¨¡æä»»åä¸­ï¼RedStar-Geo å¨ Long-CoT è³ææå°çææ³ä¸åå¾ç«¶ç­åççµæï¼åªæ¼å¶ä»æ¢æèç³»çµ±ï¼ä¾å¦ QvQ-Previewãè QwQ ç¸æ¯ï¼RedStar å¨æ¨çåæ¦æ¬æ§ä¹éåå¾äºå®ç¾çå¹³è¡¡ãæåçç ç©¶éé»å¨æ¼ï¼ééä»ç´°èª¿æ´ï¼ç¸®æ¾ Long-CoT å¯ä»¥è§£ééå¡çæ¨çè½åï¼å³ä½¿å¨è³æéæéçææ³ä¸ï¼ä¹è½çºåç¨®ææ°è¨­å®æ¢æèæ¨¡åçæ°æ¨æºãæåçè³æåæ¨¡åå·²æ¼ https://huggingface.co/RedStar-Reasoning ç¼å¸ã</paragraph>

##### **Spatiotemporal Air Quality Mapping in Urban Areas Using Sparse Sensor Data, Satellite Imagery, Meteorological Factors, and Spatial Features**
2501.11270v1 by Osama Ahmad, Zubair Khalid, Muhammad Tahir, Momin Uppal

Monitoring air pollution is crucial for protecting human health from exposure
to harmful substances. Traditional methods of air quality monitoring, such as
ground-based sensors and satellite-based remote sensing, face limitations due
to high deployment costs, sparse sensor coverage, and environmental
interferences. To address these challenges, this paper proposes a framework for
high-resolution spatiotemporal Air Quality Index (AQI) mapping using sparse
sensor data, satellite imagery, and various spatiotemporal factors. By
leveraging Graph Neural Networks (GNNs), we estimate AQI values at unmonitored
locations based on both spatial and temporal dependencies. The framework
incorporates a wide range of environmental features, including meteorological
data, road networks, points of interest (PoIs), population density, and urban
green spaces, which enhance prediction accuracy. We illustrate the use of our
approach through a case study in Lahore, Pakistan, where multi-resolution data
is used to generate the air quality index map at a fine spatiotemporal scale.

æè¦ï¼ç£æ§ç©ºæ°£æ±¡æå°æ¼ä¿è­·äººé¡å¥åº·åæ¼æ¥è§¸æå®³ç©è³ªè³ééè¦ãå³çµ±çç©ºæ°£åè³ªç£æ¸¬æ¹æ³ï¼ä¾å¦å°é¢ææ¸¬å¨åè¡æéæ¸¬ï¼ç±æ¼é¨ç½²ææ¬é«ãææ¸¬å¨è¦èç¯åç¨çä»¥åç°å¢å¹²æ¾èé¢è¨éå¶ãçºäºæå°éäºææ°ï¼æ¬ææåºäºä¸åä½¿ç¨ç¨çææ¸¬å¨è³æãè¡æå½±åååç¨®æç©ºå å­ä¾ç¹ªè£½é«è§£æåº¦æç©ºç©ºæ°£åè³ªææ¸ (AQI) çæ¶æ§ãééå©ç¨åå½¢ç¥ç¶ç¶²è·¯ (GNN)ï¼æåæ ¹æç©ºéåæéä¾è³´æ§ä¾ä¼°è¨æªç£æ§å°é»ç AQI å¼ãè©²æ¶æ§çµåäºå»£æ³çç°å¢ç¹å¾µï¼åæ¬æ°£è±¡è³æãéè·¯ç¶²è·¯ãèè¶£é» (PoI)ãäººå£å¯åº¦ååå¸ç¶ å°ï¼éäºç¹å¾µå¢å¼·äºé æ¸¬æºç¢ºåº¦ãæåééå·´åºæ¯å¦æåç¾çä¸åæ¡ä¾ç ç©¶ä¾èªªææåæ¹æ³çä½¿ç¨ï¼å¶ä¸­ä½¿ç¨å¤è§£æåº¦è³æä¾çæç²¾ç´°æç©ºå°ºåº¦çç©ºæ°£åè³ªææ¸å°åã

##### **A Layered Multi-Expert Framework for Long-Context Mental Health Assessments**
2501.13951v1 by Jinwen Tang, Qiming Guo, Wenbo Sun, Yi Shang

Long-form mental health assessments pose unique challenges for large language
models (LLMs), which often exhibit hallucinations or inconsistent reasoning
when handling extended, domain-specific contexts. We introduce Stacked
Multi-Model Reasoning (SMMR), a layered framework that leverages multiple LLMs
and specialized smaller models as coequal 'experts'. Early layers isolate
short, discrete subtasks, while later layers integrate and refine these partial
outputs through more advanced long-context models. We evaluate SMMR on the
DAIC-WOZ depression-screening dataset and 48 curated case studies with
psychiatric diagnoses, demonstrating consistent improvements over single-model
baselines in terms of accuracy, F1-score, and PHQ-8 error reduction. By
harnessing diverse 'second opinions', SMMR mitigates hallucinations, captures
subtle clinical nuances, and enhances reliability in high-stakes mental health
assessments. Our findings underscore the value of multi-expert frameworks for
more trustworthy AI-driven screening.

æè¦ï¼é·ç¯å¿çå¥åº·è©ä¼°å°å¤§åèªè¨æ¨¡å (LLM) æ§æç¨ç¹ææ°ï¼å¨èçå»¶ä¼¸çç¹å®é åèçµ¡æï¼LLM ç¶å¸¸åºç¾å¹»è¦ºæä¸ä¸è´çæ¨çãæåå¼å¥äºå çå¤æ¨¡åæ¨ç (SMMR)ï¼éæ¯ä¸ååå±¤æ¶æ§ï¼å©ç¨å¤å LLM åå°æ¥­çå°åæ¨¡åä½çºå°ç­çãå°å®¶ããæ©æå±¤éé¢ç­å°ãé¢æ£çå­ä»»åï¼èå¾çºå±¤åééæ´åé²çé·èçµ¡æ¨¡åæ´åä¸¦ç²¾çéäºé¨åè¼¸åºãæåå¨ DAIC-WOZ æé¬±çç¯©é¸è³æéå 48 åç¶éæ´ççæ¡ä¾ç ç©¶ä¸­è©ä¼° SMMRï¼å¶ä¸­åå«ç²¾ç¥ç¾çè¨ºæ·ï¼è­æå¶å¨æºç¢ºæ§ãF1 åæ¸å PHQ-8 é¯èª¤æ¸å°æ¹é¢æçºåªæ¼å®ä¸æ¨¡ååºæºãééå©ç¨ä¸åçãç¬¬äºæè¦ãï¼SMMR æ¸è¼äºå¹»è¦ºï¼ææå°ç´°å¾®çè¨åºå·®ç°ï¼ä¸¦æé«äºé«é¢¨éªå¿çå¥åº·è©ä¼°çå¯é æ§ãæåçç¼ç¾å¼·èª¿äºå¤å°å®¶æ¶æ§å¨æ´å¼å¾ä¿¡è³´ç AI é©åç¯©é¸ä¸­çå¹å¼ã

##### **Clinical trial cohort selection using Large Language Models on n2c2 Challenges**
2501.11114v1 by Chi-en Amy Tai, Xavier Tannier

Clinical trials are a critical process in the medical field for introducing
new treatments and innovations. However, cohort selection for clinical trials
is a time-consuming process that often requires manual review of patient text
records for specific keywords. Though there have been studies on standardizing
the information across the various platforms, Natural Language Processing (NLP)
tools remain crucial for spotting eligibility criteria in textual reports.
Recently, pre-trained large language models (LLMs) have gained popularity for
various NLP tasks due to their ability to acquire a nuanced understanding of
text. In this paper, we study the performance of large language models on
clinical trial cohort selection and leverage the n2c2 challenges to benchmark
their performance. Our results are promising with regard to the incorporation
of LLMs for simple cohort selection tasks, but also highlight the difficulties
encountered by these models as soon as fine-grained knowledge and reasoning are
required.

æè¦ï¼è¨åºè©¦é©æ¯é«å­¸é åä¸­å¼å¥æ°çæ³ååµæ°çééµéç¨ãç¶èï¼è¨åºè©¦é©çæ£èç¾¤é«é¸ææ¯ä¸åèæçéç¨ï¼éå¸¸éè¦äººå·¥å¯©æ¥çæ£çæå­è¨éï¼ä»¥å°æ¾ç¹å®çééµå­ãåç®¡æç ç©¶éå°ä¸åå¹³å°ä¸çè³è¨é²è¡æ¨æºåï¼èªç¶èªè¨èç (NLP) å·¥å·å°æ¼å¨æå­å ±åä¸­æ¾åºç¬¦åè³æ ¼çæ¨æºä»ç¶è³ééè¦ãæè¿ï¼é åè¨ç·´çå¤§åèªè¨æ¨¡å (LLM) å å¶ç²åç´°ç·»ææ¬çè§£çè½åèå»£ååç¨® NLP ä»»åæ­¡è¿ãå¨æ¬æä¸­ï¼æåç ç©¶å¤§åèªè¨æ¨¡åå¨è¨åºè©¦é©æ£èç¾¤é«é¸æä¸çè¡¨ç¾ï¼ä¸¦å©ç¨ n2c2 ææ°ä¾è©éå¶è¡¨ç¾ãæåççµæå°æ¼å° LLM ç´å¥ç°¡å®çæ£èç¾¤é«é¸æä»»åèè¨æ¯å¾æå¸æçï¼ä½ä¹å¼·èª¿äºéäºæ¨¡åå¨éè¦å·åç´°ç·»ç¥è­åæ¨çè½åææéå°çå°é£ã

##### **Enhanced Suicidal Ideation Detection from Social Media Using a CNN-BiLSTM Hybrid Model**
2501.11094v1 by Mohaiminul Islam Bhuiyan, Nur Shazwani Kamarudin, Nur Hafieza Ismail

Suicidal ideation detection is crucial for preventing suicides, a leading
cause of death worldwide. Many individuals express suicidal thoughts on social
media, offering a vital opportunity for early detection through advanced
machine learning techniques. The identification of suicidal ideation in social
media text is improved by utilising a hybrid framework that integrates
Convolutional Neural Networks (CNN) and Bidirectional Long Short-Term Memory
(BiLSTM), enhanced with an attention mechanism. To enhance the interpretability
of the model's predictions, Explainable AI (XAI) methods are applied, with a
particular focus on SHapley Additive exPlanations (SHAP), are incorporated. At
first, the model managed to reach an accuracy of 92.81%. By applying
fine-tuning and early stopping techniques, the accuracy improved to 94.29%. The
SHAP analysis revealed key features influencing the model's predictions, such
as terms related to mental health struggles. This level of transparency boosts
the model's credibility while helping mental health professionals understand
and trust the predictions. This work highlights the potential for improving the
accuracy and interpretability of detecting suicidal tendencies, making a
valuable contribution to the progress of mental health monitoring systems. It
emphasizes the significance of blending powerful machine learning methods with
explainability to develop reliable and impactful mental health solutions.

æè¦ï¼èªæ®ºæå¿µåµæ¸¬å°æ¼é é²èªæ®ºè³ééè¦ï¼èèªæ®ºæ¯å¨çä¸»è¦çæ­»äº¡åå ãè¨±å¤äººå¨ç¤¾ç¾¤åªé«ä¸è¡¨éèªæ®ºå¿µé ­ï¼éæä¾äºééé²éæ©å¨å­¸ç¿æè¡é²è¡æ©æåµæ¸¬çéè¦æ©æãééæ´åå·ç©ç¥ç¶ç¶²è·¯ (CNN) åéåé·ç­æè¨æ¶ (BiLSTM) çæ··åæ¶æ§ï¼ä¸¦å å¥æ³¨æåæ©å¶ï¼å¯ä»¥æåå¨ç¤¾ç¾¤åªé«æå­ä¸­è¾¨è­èªæ®ºæå¿µçè½åãçºäºå å¼·æ¨¡åé æ¸¬çå¯è§£éæ§ï¼æåæ¡ç¨å¯è§£éäººå·¥æºæ§ (XAI) æ¹æ³ï¼ç¹å¥èéæ¼ SHapley å æ³è§£é (SHAP)ãä¸éå§ï¼æ¨¡åæåéå° 92.81% çæºç¢ºåº¦ãééå¥ç¨å¾®èª¿åæ©æåæ­¢æè¡ï¼æºç¢ºåº¦æåè³ 94.29%ãSHAP åææ­é²äºå½±é¿æ¨¡åé æ¸¬çééµç¹å¾µï¼ä¾å¦èå¿çå¥åº·å°å¢ç¸éçè©å½ãéç¨®éæåº¦æåäºæ¨¡åçå¯ä¿¡åº¦ï¼åæåå©å¿çå¥åº·å°æ¥­äººå¡çè§£åä¿¡è³´é æ¸¬çµæãéé å·¥ä½çªé¡¯äºæååµæ¸¬èªæ®ºå¾åçæºç¢ºåº¦åå¯è§£éæ§çæ½åï¼çºå¿çå¥åº·ç£æ§ç³»çµ±çé²å±ååºå¯¶è²´çè²¢ç»ãå®å¼·èª¿äºå°å¼·å¤§çæ©å¨å­¸ç¿æ¹æ³èå¯è§£éæ§ç¸çµåä»¥éç¼å¯é ä¸æå½±é¿åçå¿çå¥åº·è§£æ±ºæ¹æ¡çéè¦æ§ã

##### **No More Sliding Window: Efficient 3D Medical Image Segmentation with Differentiable Top-k Patch Sampling**
2501.10814v1 by Young Seok Jeon, Hongfei Yang, Huazhu Fu, Mengling Feng

3D models are favored over 2D for 3D medical image segmentation tasks due to
their ability to leverage inter-slice relationship, yielding higher
segmentation accuracy. However, 3D models demand significantly more GPU memory
with increased model size and intermediate tensors. A common solution is to use
patch-based training and make whole-volume predictions with sliding window (SW)
inference. SW inference reduces memory usage but is slower due to equal
resource allocation across patches and less accurate as it overlooks global
features beyond patches.
  We propose NMSW-Net (No-More-Sliding-Window-Net), a novel framework that
enhances efficiency and accuracy of any given 3D segmentation model by
eliminating SW inference and incorporating global predictions when necessary.
NMSW-Net incorporates a differentiable Top-k module to sample only the relevant
patches that enhance segmentation accuracy, thereby minimizing redundant
computations. Additionally, it learns to leverage coarse global predictions
when patch prediction alone is insufficient. NMSW-Net is model-agnostic, making
it compatible with any 3D segmentation model that previously relied on SW
inference.
  Evaluated across 3 tasks with 3 segmentation backbones, NMSW-Net achieves
competitive or sometimes superior accuracy compared to SW, while reducing
computational complexity by 90% (87.5 to 7.95 TFLOPS), delivering 4x faster
inference on the H100 GPU (19.0 to 4.3 sec), and 7x faster inference on the
Intel Xeon Gold CPU (1710 to 230 seconds).

æè¦ï¼<paragraph>3D æ¨¡åå¨ 3D å»å­¦å½±ååå²ä»»å¡ä¸­ä¼äº 2Dï¼å ä¸º
å®ä»¬è½å¤å©ç¨åçé´å³ç³»ï¼ä»èäº§çæ´é«ç
åå²ç²¾åº¦ãç¶èï¼3D æ¨¡åéè¦å¤§é GPU åå­
éçæ¨¡åå¤§å°åä¸­é´å¼ éçå¢å ãä¸ç§å¸¸è§çè§£å³æ¹æ¡æ¯ä½¿ç¨
åºäº patch çè®­ç»å¹¶ä½¿ç¨æ»å¨çªå£ (SW)
æ¨çè¿è¡å¨å·é¢æµãSW æ¨çåå°äºåå­ä½¿ç¨éï¼ä½ç±äº
å¨ patch ä¹é´å¹³ååéèµæºå¹¶ä¸ç±äºå¿½ç¥äº patch ä¹å¤çå¨å±
ç¹å¾èå¯¼è´éåº¦è¾æ¢ä¸åç¡®åº¦è¾ä½ã
æä»¬æåºäº NMSW-Netï¼æ æ»å¨çªå£ç½ç»ï¼ï¼è¿æ¯ä¸ç§æ°é¢çæ¡æ¶ï¼å®
éè¿æ¶é¤ SW æ¨çå¹¶å¨å¿è¦æ¶åå¹¶å¨å±é¢æµæ¥æé«ä»»ä½ç»å® 3D åå²æ¨¡åçæçååç¡®æ§ã
NMSW-Net ç»åäºä¸ä¸ªå¯å¾®åç Top-k æ¨¡åæ¥ä»éæ ·ç¸å³
patchï¼ä»¥æé«åå²ç²¾åº¦ï¼ä»èæå¤§éåº¦å°åå°åä½
è®¡ç®ãæ­¤å¤ï¼å®å­¦ä¼äºå¨ä» patch é¢æµä¸è¶³æ¶å©ç¨ç²ç¥çå¨å±é¢æµãNMSW-Net ä¸æ¨¡åæ å³ï¼ä½¿å¶
ä¸ä»¥åä¾èµ SW çä»»ä½ 3D åå²æ¨¡åå¼å®¹
æ¨çã
å¨ 3 ä¸ªå¸¦æ 3 ä¸ªåå²ä¸»å¹²çä»»å¡ä¸­è¿è¡è¯ä¼°ï¼NMSW-Net å®ç°äº
ä¸ SW ç¸æ¯å·æç«äºåæææ¶æ´é«çåç¡®æ§ï¼åæ¶åå°
è®¡ç®å¤æåº¦éä½äº 90%ï¼87.5 å° 7.95 TFLOPSï¼ï¼å¨ H100 GPU ä¸æä¾ 4 åæ´å¿«ç
æ¨çï¼19.0 å° 4.3 ç§ï¼ï¼ä»¥åå¨
è±ç¹å°è³å¼ºé CPU ä¸æ¨çéåº¦æé« 7 åï¼1710 å° 230 ç§ï¼ã</paragraph>

##### **Efficient Auto-Labeling of Large-Scale Poultry Datasets (ALPD) Using Semi-Supervised Models, Active Learning, and Prompt-then-Detect Approach**
2501.10809v1 by Ramesh Bahadur Bist, Lilong Chai, Shawna Weimer, Hannah Atungulua, Chantel Pennicott, Xiao Yang, Sachin Subedi, Chaitanya Pallerla, Yang Tian, Dongyi Wang

The rapid growth of AI in poultry farming has highlighted the challenge of
efficiently labeling large, diverse datasets. Manual annotation is
time-consuming, making it impractical for modern systems that continuously
generate data. This study explores semi-supervised auto-labeling methods,
integrating active learning, and prompt-then-detect paradigm to develop an
efficient framework for auto-labeling of large poultry datasets aimed at
advancing AI-driven behavior and health monitoring. Viideo data were collected
from broilers and laying hens housed at the University of Arkansas and the
University of Georgia. The collected videos were converted into images,
pre-processed, augmented, and labeled. Various machine learning models,
including zero-shot models like Grounding DINO, YOLO-World, and CLIP, and
supervised models like YOLO and Faster-RCNN, were utilized for broilers, hens,
and behavior detection. The results showed that YOLOv8s-World and YOLOv9s
performed better when compared performance metrics for broiler and hen
detection under supervised learning, while among the semi-supervised model,
YOLOv8s-ALPD achieved the highest precision (96.1%) and recall (99.0%) with an
RMSE of 1.9. The hybrid YOLO-World model, incorporating the optimal YOLOv8s
backbone, demonstrated the highest overall performance. It achieved a precision
of 99.2%, recall of 99.4%, and an F1 score of 98.7% for breed detection,
alongside a precision of 88.4%, recall of 83.1%, and an F1 score of 84.5% for
individual behavior detection. Additionally, semi-supervised models showed
significant improvements in behavior detection, achieving up to 31% improvement
in precision and 16% in F1-score. The semi-supervised models with minimal
active learning reduced annotation time by over 80% compared to full manual
labeling. Moreover, integrating zero-shot models enhanced detection and
behavior identification.

æè¦ï¼<paragraph>å®¶ç¦½å»æ®ä¸­äººå·¥æºè½çå¿«éå¢é¿å¸æ¾äºé«ææ æ³¨å¤§åãå¤æ ·åæ°æ®éçææãæå¨æ æ³¨éå¸¸èæ¶ï¼å¯¹äºæç»­çææ°æ®çç°ä»£ç³»ç»èè¨ä¸åå®éãæ¬ç ç©¶æ¢ç´¢äºåçç£èªå¨æ æ³¨æ¹æ³ï¼éæäºä¸»å¨å­¦ä¹ åæç¤ºåæ£æµèå¼ï¼ä»¥å¼åä¸ä¸ªé«æçæ¡æ¶ï¼ç¨äºèªå¨æ æ³¨å¤§åå®¶ç¦½æ°æ®éï¼æ¨å¨æ¨è¿äººå·¥æºè½é©±å¨çè¡ä¸ºåå¥åº·çæµãè§é¢æ°æ®æ¯ä»é¿è¯è²å¤§å­¦åä½æ²»äºå¤§å­¦é¥²å»çèé¸¡åèé¸¡ä¸­æ¶éçãæ¶éçè§é¢è¢«è½¬æ¢æå¾åï¼ç»è¿é¢å¤çãå¢å¼ºåæ æ³¨ãåç§æºå¨å­¦ä¹ æ¨¡åï¼åæ¬ Grounding DINOãYOLO-World å CLIP ç­é¶æ ·æ¬å­¦ä¹ æ¨¡åï¼ä»¥å YOLO å Faster-RCNN ç­çç£æ¨¡åï¼è¢«ç¨äºèé¸¡ãæ¯é¸¡åè¡ä¸ºæ£æµãç»æè¡¨æï¼å¨çç£å­¦ä¹ ä¸ï¼YOLOv8s-World å YOLOv9s å¨èé¸¡åæ¯é¸¡æ£æµçæ§è½ææ æ¯è¾ä¸­è¡¨ç°å¾æ´å¥½ï¼èå¨åçç£æ¨¡åä¸­ï¼YOLOv8s-ALPD ä»¥ 1.9 ç RMSE å®ç°äºæé«çç²¾åº¦ (96.1%) åå¬åç (99.0%)ãç»åäºæä½³ YOLOv8s ä¸»å¹²ç½ç»çæ··å YOLO-World æ¨¡åå±ç¤ºäºæé«çæ´ä½æ§è½ãå®å¨åç§æ£æµä¸­å®ç°äº 99.2% çç²¾åº¦ã99.4% çå¬åçå 98.7% ç F1 åæ°ï¼å¨ä¸ªä½è¡ä¸ºæ£æµä¸­å®ç°äº 88.4% çç²¾åº¦ã83.1% çå¬åçå 84.5% ç F1 åæ°ãæ­¤å¤ï¼åçç£æ¨¡åå¨è¡ä¸ºæ£æµä¸­æ¾ç¤ºåºæ¾èçæ¹è¿ï¼å¨ç²¾åº¦ä¸æé«äº 31%ï¼å¨ F1 åæ°ä¸æé«äº 16%ãä¸å®å¨æå¨æ æ³¨ç¸æ¯ï¼å·ææå°ä¸»å¨å­¦ä¹ çåçç£æ¨¡åå°æ æ³¨æ¶é´åå°äº 80% ä»¥ä¸ãæ­¤å¤ï¼éæé¶æ ·æ¬å­¦ä¹ æ¨¡åå¢å¼ºäºæ£æµåè¡ä¸ºè¯å«ã</paragraph>

##### **MedFILIP: Medical Fine-grained Language-Image Pre-training**
2501.10775v1 by Xinjie Liang, Xiangyu Li, Fanding Li, Jie Jiang, Qing Dong, Wei Wang, Kuanquan Wang, Suyu Dong, Gongning Luo, Shuo Li

Medical vision-language pretraining (VLP) that leverages naturally-paired
medical image-report data is crucial for medical image analysis. However,
existing methods struggle to accurately characterize associations between
images and diseases, leading to inaccurate or incomplete diagnostic results. In
this work, we propose MedFILIP, a fine-grained VLP model, introduces medical
image-specific knowledge through contrastive learning, specifically: 1) An
information extractor based on a large language model is proposed to decouple
comprehensive disease details from reports, which excels in extracting disease
deals through flexible prompt engineering, thereby effectively reducing text
complexity while retaining rich information at a tiny cost. 2) A knowledge
injector is proposed to construct relationships between categories and visual
attributes, which help the model to make judgments based on image features, and
fosters knowledge extrapolation to unfamiliar disease categories. 3) A semantic
similarity matrix based on fine-grained annotations is proposed, providing
smoother, information-richer labels, thus allowing fine-grained image-text
alignment. 4) We validate MedFILIP on numerous datasets, e.g., RSNA-Pneumonia,
NIH ChestX-ray14, VinBigData, and COVID-19. For single-label, multi-label, and
fine-grained classification, our model achieves state-of-the-art performance,
the classification accuracy has increased by a maximum of 6.69\%. The code is
available in https://github.com/PerceptionComputingLab/MedFILIP.

æè¦ï¼é«å­¸å½±åèªè¨é è¨ç·´ï¼VLPï¼å©ç¨èªç¶éå°çé«å­¸å½±åå ±åæ¸æï¼å°æ¼é«å­¸å½±ååæè³ééè¦ãç¶èï¼ç¾ææ¹æ³é£ä»¥æºç¢ºæè¿°å½±åèç¾çä¹éçéè¯æ§ï¼å°è´è¨ºæ·çµæä¸æºç¢ºæä¸å®æ´ãå¨éé å·¥ä½ä¸­ï¼æåæåº MedFILIPï¼ä¸åç´°ç²åº¦ç VLP æ¨¡åï¼ééå°æ¯å­¸ç¿å¼å¥é«å­¸å½±åç¹å®ç¥è­ï¼å·é«ä¾èªªï¼1) æåºä¸ååºæ¼å¤§åèªè¨æ¨¡åçè³è¨èåå¨ï¼å¾å ±åä¸­è§£è¦å¨é¢çç¾çç´°ç¯ï¼éééæ´»çæç¤ºå·¥ç¨ï¼å¨æåç¾çäº¤ææ¹é¢è¡¨ç¾åºè²ï¼å¾èææéä½æå­è¤éæ§ï¼åæä»¥æ¥µå°çä»£å¹ä¿çè±å¯çè³è¨ã2) æåºä¸åç¥è­æ³¨å¥å¨ï¼ç¨æ¼å»ºæ§é¡å¥èè¦è¦ºå±¬æ§ä¹éçéä¿ï¼éæå©æ¼æ¨¡åæ ¹æå½±åç¹å¾µé²è¡å¤æ·ï¼ä¸¦ä¿é²ç¥è­å¤æ¨å°ä¸çæçç¾çé¡å¥ã3) æåºä¸ååºæ¼ç´°ç²åº¦è¨»è§£çèªç¾©ç¸ä¼¼ç©é£ï¼æä¾æ´å¹³æ»ãè³è¨æ´è±å¯çæ¨ç±¤ï¼å¾èåè¨±é²è¡ç´°ç²åº¦çå½±åæå­å°é½ã4) æåå¨è¨±å¤è³æéä¸é©è­ MedFILIPï¼ä¾å¦ RSNA-PneumoniaãNIH ChestX-ray14ãVinBigData å COVID-19ãå°æ¼å®æ¨ç±¤ãå¤æ¨ç±¤åç´°ç²åº¦åé¡ï¼æåçæ¨¡åéå°äºæåé²çæè½ï¼åé¡æºç¢ºçæé«æé«äº 6.69%ãç¨å¼ç¢¼å¯å¨ https://github.com/PerceptionComputingLab/MedFILIP ä¸­åå¾ã

##### **Enhancing Diagnostic in 3D COVID-19 Pneumonia CT-scans through Explainable Uncertainty Bayesian Quantification**
2501.10770v1 by Juan Manuel Liscano Fierro, Hector J. Hortua

Accurately classifying COVID-19 pneumonia in 3D CT scans remains a
significant challenge in the field of medical image analysis. Although
deterministic neural networks have shown promising results in this area, they
provide only point estimates outputs yielding poor diagnostic in clinical
decision-making. In this paper, we explore the use of Bayesian neural networks
for classifying COVID-19 pneumonia in 3D CT scans providing uncertainties in
their predictions. We compare deterministic networks and their Bayesian
counterpart, enhancing the decision-making accuracy under uncertainty
information. Remarkably, our findings reveal that lightweight architectures
achieve the highest accuracy of 96\% after developing extensive hyperparameter
tuning. Furthermore, the Bayesian counterpart of these architectures via
Multiplied Normalizing Flow technique kept a similar performance along with
calibrated uncertainty estimates. Finally, we have developed a 3D-visualization
approach to explain the neural network outcomes based on SHAP values. We
conclude that explainability along with uncertainty quantification will offer
better clinical decisions in medical image analysis, contributing to ongoing
efforts for improving the diagnosis and treatment of COVID-19 pneumonia.

æè¦ï¼æºç¢ºåé¡ 3D é»è¦æ·å±¤ææä¸­ç COVID-19 èºçå¨é«å­¸å½±ååæé åä¸­ä»æ¯ä¸é éå¤§ææ°ãåç®¡ç¢ºå®æ§ç¥ç¶ç¶²è·¯å·²å¨æ­¤é åä¸­å±ç¾åºä»¤äººæ»¿æççµæï¼ä½å®ååæä¾é»ä¼°è¨è¼¸åºï¼å¨è¨åºæ±ºç­ä¸­ç¢çä¸è¯çè¨ºæ·ãå¨æ¬æä¸­ï¼æåæ¢è¨ä½¿ç¨è²æ°ç¥ç¶ç¶²è·¯ä¾åé¡ 3D é»è¦æ·å±¤ææä¸­ç COVID-19 èºçï¼ä¸¦å¨é æ¸¬ä¸­æä¾ä¸ç¢ºå®æ§ãæåæ¯è¼ç¢ºå®æ§ç¶²è·¯åå¶è²æ°å°æç¶²è·¯ï¼å¨ä¸ç¢ºå®æ§è³è¨ä¸æåæ±ºç­çæºç¢ºæ§ãå¼å¾æ³¨æçæ¯ï¼æåçç¼ç¾é¡¯ç¤ºï¼å¨ç¶éå»£æ³çè¶åæ¸èª¿æ´å¾ï¼è¼éç´æ¶æ§å¯éå° 96% çæé«æºç¢ºåº¦ãæ­¤å¤ï¼éäºæ¶æ§çè²æ°å°æç¶²è·¯ééä¹æ³æ­£è¦åæµæè¡ï¼å¨æ ¡æºä¸ç¢ºå®æ§ä¼°è¨çåæï¼ç¶­æé¡ä¼¼çæè½ãæå¾ï¼æåå·²éç¼åº 3D è¦è¦ºåæ¹æ³ï¼ä»¥æ ¹æ SHAP å¼ä¾è§£éç¥ç¶ç¶²è·¯ççµæãæåå¾åºçµè«ï¼å¯è§£éæ§èä¸ç¢ºå®æ§éåå°å¨é«å­¸å½±ååæä¸­æä¾æ´å¥½çè¨åºæ±ºç­ï¼æå©æ¼æçºæ¹å COVID-19 èºççè¨ºæ·åæ²»çã

##### **In the Picture: Medical Imaging Datasets, Artifacts, and their Living Review**
2501.10727v1 by Amelia JimÃ©nez-SÃ¡nchez, Natalia-Rozalia Avlona, Sarah de Boer, VÃ­ctor M. Campello, Aasa Feragen, Enzo Ferrante, Melanie Ganz, Judy Wawira Gichoya, Camila GonzÃ¡lez, Steff Groefsema, Alessa Hering, Adam Hulman, Leo Joskowicz, Dovile Juodelyte, Melih Kandemir, Thijs Kooi, Jorge del Pozo LÃ©rida, Livie Yumeng Li, Andre Pacheco, Tim RÃ¤dsch, Mauricio Reyes, ThÃ©o Sourget, Bram van Ginneken, David Wen, Nina Weng, Jack Junchi Xu, Hubert Dariusz ZajÄc, Maria A. Zuluaga, Veronika Cheplygina

Datasets play a critical role in medical imaging research, yet issues such as
label quality, shortcuts, and metadata are often overlooked. This lack of
attention may harm the generalizability of algorithms and, consequently,
negatively impact patient outcomes. While existing medical imaging literature
reviews mostly focus on machine learning (ML) methods, with only a few focusing
on datasets for specific applications, these reviews remain static -- they are
published once and not updated thereafter. This fails to account for emerging
evidence, such as biases, shortcuts, and additional annotations that other
researchers may contribute after the dataset is published. We refer to these
newly discovered findings of datasets as research artifacts. To address this
gap, we propose a living review that continuously tracks public datasets and
their associated research artifacts across multiple medical imaging
applications. Our approach includes a framework for the living review to
monitor data documentation artifacts, and an SQL database to visualize the
citation relationships between research artifact and dataset. Lastly, we
discuss key considerations for creating medical imaging datasets, review best
practices for data annotation, discuss the significance of shortcuts and
demographic diversity, and emphasize the importance of managing datasets
throughout their entire lifecycle. Our demo is publicly available at
http://130.226.140.142.

æè¦ï¼<paragraph>è³æéå¨é«å­¸å½±åç ç©¶ä¸­æ®æ¼èè³ééè¦çè§è²ï¼ç¶èæ¨ç±¤åè³ªãæ·å¾ååè³æç­åé¡å»å¸¸å¸¸è¢«å¿½ç¥ãéç¨®ç¼ºä¹éæ³¨çç¾è±¡å¯è½ææå®³æ¼ç®æ³çæ¦æ¬æ§ï¼é²èå°çæ£çæ²»ççµæé æè² é¢å½±é¿ãéç¶ç¾æçé«å­¸å½±åæç»åé¡§å¤§å¤éä¸­æ¼æ©å¨å­¸ç¿ (ML) æ¹æ³ï¼åªæå°æ¸åé¡§èéæ¼ç¹å®æç¨ç¨å¼çè³æéï¼ä½éäºåé¡§ä»ç¶æ¯éæçââå®ååªæç¼è¡¨ä¸æ¬¡ï¼ä¹å¾ä¸æåæ´æ°ãéç¡æ³èéæ°åºç¾çè­æï¼ä¾å¦åèª¤ãæ·å¾åè³æéå¨ç¼è¡¨å¾å¶ä»ç ç©¶äººå¡å¯è½æä¾çé¡å¤è¨»è§£ãæåå°éäºæ°ç¼ç¾çè³æéç¼ç¾ç¨±çºç ç©¶ææãçºäºè§£æ±ºéååé¡ï¼æåæåºä¸åæçºè¿½è¹¤å¬éè³æéåå¶èå¤åé«å­¸å½±åæç¨ç¨å¼ç¸éçç ç©¶ææçåæåé¡§ãæåçåæ³åæ¬ä¸åç¨æ¼ç£æ§è³ææä»¶ææçåæåé¡§æ¶æ§ï¼ä»¥åä¸åç¨æ¼è¦è¦ºåç ç©¶ææèè³æéä¹éå¼ç¨éä¿ç SQL è³æåº«ãæå¾ï¼æåè¨è«å»ºç«é«å­¸å½±åè³æéæçä¸»è¦èéå ç´ ï¼åé¡§è³æè¨»è§£çæä½³å¯¦åï¼æ¢è¨æ·å¾åäººå£çµ±è¨å¤æ¨£æ§çéè¦æ§ï¼ä¸¦å¼·èª¿å¨è³æéçæ´åçå½é±æä¸­ç®¡çè³æéçéè¦æ§ãæåçç¤ºç¯å¯æ¼ http://130.226.140.142 å¬éåå¾ã</paragraph>

##### **An Ontology for Social Determinants of Education (SDoEd) based on Human-AI Collaborative Approach**
2501.10300v1 by Navya Martin Kollapally, James Geller, Patricia Morreale, Daehan Kwak

The use of computational ontologies is well-established in the field of
Medical Informatics. The topic of Social Determinants of Health (SDoH) has also
received extensive attention. Work at the intersection of ontologies and SDoH
has been published. However, a standardized framework for Social Determinants
of Education (SDoEd) is lacking. In this paper, we are closing the gap by
introducing an SDoEd ontology for creating a precise conceptualization of the
interplay between life circumstances of students and their possible educational
achievements. The ontology was developed utilizing suggestions from
ChatGPT-3.5-010422 and validated using peer-reviewed research articles. The
first version of developed ontology was evaluated by human experts in the field
of education and validated using standard ontology evaluation software. This
version of the SDoEd ontology contains 231 domain concepts, 10 object
properties, and 24 data properties

æè¦ï¼å¨é«å­¸è³è¨å­¸é åä¸­ï¼è¨ç®æ¬é«çä½¿ç¨å·²ç¶ç¸ç¶æ®éãç¤¾æå¥åº·æ±ºå®å ç´ ï¼SDoHï¼çä¸»é¡ä¹åå°å»£æ³çéæ³¨ãæ¬é«è SDoH äº¤éèçå·¥ä½å·²ç¶ç¼è¡¨ãç¶èï¼ç¤¾ææè²æ±ºå®å ç´ ï¼SDoEdï¼çæ¨æºåæ¶æ§å»ä»ä¹éå¦ãå¨æ¬æä¸­ï¼æåééå¼å¥ SDoEd æ¬é«ä¾å¡«è£éåç¼ºå£ï¼ä»¥å»ºç«å­¸ççæ´»ç°å¢èå¶å¯è½æè²æå°±ä¹éç¸äºä½ç¨çç²¾ç¢ºæ¦å¿µåãæ¬é«æ¯å©ç¨ ChatGPT-3.5-010422 çå»ºè­°éç¼çï¼ä¸¦ä½¿ç¨åè¡è©å¯©çç ç©¶æç« é²è¡é©è­ãéç¼æ¬é«çç¬¬ä¸åçæ¬ç±æè²é åçäººé¡å°å®¶è©ä¼°ï¼ä¸¦ä½¿ç¨æ¨æºæ¬é«è©ä¼°è»é«é²è¡é©è­ãæ­¤çæ¬ç SDoEd æ¬é«åå« 231 åç¶²åæ¦å¿µã10 åç©ä»¶å±¬æ§å 24 åè³æå±¬æ§

##### **SEANN: A Domain-Informed Neural Network for Epidemiological Insights**
2501.10273v1 by Jean-Baptiste Guimbaud, Marc Plantevit, LÃ©a MaÃ®tre, RÃ©my Cazabet

In epidemiology, traditional statistical methods such as logistic regression,
linear regression, and other parametric models are commonly employed to
investigate associations between predictors and health outcomes. However,
non-parametric machine learning techniques, such as deep neural networks
(DNNs), coupled with explainable AI (XAI) tools, offer new opportunities for
this task. Despite their potential, these methods face challenges due to the
limited availability of high-quality, high-quantity data in this field. To
address these challenges, we introduce SEANN, a novel approach for informed
DNNs that leverages a prevalent form of domain-specific knowledge: Pooled
Effect Sizes (PES). PESs are commonly found in published Meta-Analysis studies,
in different forms, and represent a quantitative form of a scientific
consensus. By direct integration within the learning procedure using a custom
loss, we experimentally demonstrate significant improvements in the
generalizability of predictive performances and the scientific plausibility of
extracted relationships compared to a domain-knowledge agnostic neural network
in a scarce and noisy data setting.

æè¦ï¼å¨æµè¡çå­¸ä¸­ï¼å³çµ±ççµ±è¨æ¹æ³ï¼ä¾å¦éè¼¯è¿´æ­¸ãç·æ§è¿´æ­¸åå¶ä»åæ¸æ¨¡åéå¸¸ç¨æ¼èª¿æ¥é æ¸¬å å­èå¥åº·çµæä¹éçéè¯ãç¶èï¼éåæ¸æ©å¨å­¸ç¿æè¡ï¼ä¾å¦æ·±åº¦ç¥ç¶ç¶²è·¯ (DNN)ï¼çµåå¯è§£éç AI (XAI) å·¥å·ï¼çºéé ä»»åæä¾äºæ°çæ©æãåç®¡éäºæ¹æ³å·ææ½åï¼ä½ç±æ¼è©²é åç¼ºä¹é«åè³ªãé«æ¸éè³æï¼å æ­¤éäºæ¹æ³é¢è¨ææ°ãçºäºæå°éäºææ°ï¼æåå¼å¥äº SEANNï¼éæ¯ä¸ç¨®æ°ç©çæ¹æ³ï¼ç¨æ¼ç²åç¥è­ç DNNï¼å®å©ç¨äºä¸ç¨®æµè¡çé åç¹å®ç¥è­å½¢å¼ï¼å½ç¸½ææé (PES)ãPES éå¸¸ä»¥ä¸åçå½¢å¼åºç¾å¨å·²ç¼è¡¨ç Meta åæç ç©¶ä¸­ï¼ä¸¦ä»£è¡¨ç§å­¸å±è­çéåå½¢å¼ãééä½¿ç¨èªè¨æå¤±å½æ¸ç´æ¥æ´åå¨å­¸ç¿ç¨åºä¸­ï¼æåä»¥å¯¦é©æ¹å¼è­æäºé æ¸¬æè½çæ¦æ¬æ§ä»¥åèå¾ç¼ºä¹é åç¥è­çç¥ç¶ç¶²è·¯ä¸­æåçéä¿ç¸æ¯ï¼ç§å­¸åçæ§çé¡¯èæåï¼ä¸æ¯å¨ç¨å°ä¸æéè¨çè³æè¨­å®ä¸­ã

##### **Challenges and recommendations for Electronic Health Records data extraction and preparation for dynamic prediction modelling in hospitalized patients -- a practical guide**
2501.10240v1 by Elena Albu, Shan Gao, Pieter Stijnen, Frank E. Rademakers, Bas C T van Bussel, Taya Collyer, Tina Hernandez-Boussard, Laure Wynants, Ben Van Calster

Dynamic predictive modeling using electronic health record (EHR) data has
gained significant attention in recent years. The reliability and
trustworthiness of such models depend heavily on the quality of the underlying
data, which is largely determined by the stages preceding the model
development: data extraction from EHR systems and data preparation. We list
over forty challenges encountered during these stages and provide actionable
recommendations for addressing them. These challenges are organized into four
categories: cohort definition, outcome definition, feature engineering, and
data cleaning. This list is designed to serve as a practical guide for data
extraction engineers and researchers, supporting better practices and improving
the quality and real-world applicability of dynamic prediction models in
clinical settings.

æè¦ï¼è¿å¹´ä¾ï¼ä½¿ç¨é»å­å¥åº·è¨é (EHR) è³æçåæé æ¸¬æ¨¡åç²å¾äºæ¥µå¤§çéæ³¨ãæ­¤é¡æ¨¡åçå¯é æ§åå¯ä¿¡åº¦å¨å¾å¤§ç¨åº¦ä¸åæ±ºæ¼åºç¤è³æçåè³ªï¼èéå¨å¾å¤§ç¨åº¦ä¸åæ±ºæ¼æ¨¡åéç¼ä¹åçéæ®µï¼å¾ EHR ç³»çµ±ä¸­æåè³æåè³ææºåãæåååºäºéäºéæ®µä¸­éå°çååå¤é ææ°ï¼ä¸¦æä¾äºå·é«å¯è¡çå»ºè­°ä¾è§£æ±ºéäºææ°ãéäºææ°åçºåé¡ï¼ç¾¤çµå®ç¾©ãçµæå®ç¾©ãç¹å¾µå·¥ç¨åè³ææ¸çãæ­¤æ¸å®æ¨å¨ä½çºè³ææåå·¥ç¨å¸«åç ç©¶äººå¡çå¯¦ç¨æåï¼æ¯æ´æ´å¥½çå¯¦åï¼ä¸¦æ¹ååæé æ¸¬æ¨¡åå¨è¨åºç°å¢ä¸­çåè³ªåå¯¦éæç¨æ§ã

##### **Generative Artificial Intelligence: Implications for Biomedical and Health Professions Education**
2501.10186v1 by William Hersh

Generative AI has had a profound impact on biomedicine and health, both in
professional work and in education. Based on large language models (LLMs),
generative AI has been found to perform as well as humans in simulated
situations taking medical board exams, answering clinical questions, solving
clinical cases, applying clinical reasoning, and summarizing information.
Generative AI is also being used widely in education, performing well in
academic courses and their assessments. This review summarizes the successes of
LLMs and highlights some of their challenges in the context of education, most
notably aspects that may undermines the acquisition of knowledge and skills for
professional work. It then provides recommendations for best practices
overcoming shortcomings for LLM use in education. Although there are challenges
for use of generative AI in education, all students and faculty, in biomedicine
and health and beyond, must have understanding and be competent in its use.

æè¦ï¼çæå¼ AI å°çç©é«å­¸åå¥åº·é åç¢çäºæ·±é çå½±é¿ï¼ç¡è«æ¯å¨å°æ¥­å·¥ä½éæ¯æè²æ¹é¢ãåºæ¼å¤§åèªè¨æ¨¡å (LLM)ï¼ç¼ç¾çæå¼ AI å¨æ¨¡æ¬é«çå§å¡æèè©¦ãåç­è¨åºåé¡ãè§£æ±ºè¨åºæ¡ä¾ãæç¨è¨åºæ¨çåç¸½çµè³è¨ç­ææ³ä¸ï¼è¡¨ç¾å¾èäººé¡ä¸æ¨£å¥½ãçæå¼ AI ä¹å»£æ³æç¨æ¼æè²ä¸­ï¼å¨å­¸è¡èª²ç¨åå¶è©ä¼°ä¸­è¡¨ç¾è¯å¥½ãæ¬ç¯è©è«ç¸½çµäº LLM çæåï¼ä¸¦å¼·èª¿äºå®åå¨æè²èæ¯ä¸çä¸äºææ°ï¼æå¼å¾æ³¨æçæ¯å¯è½æå®³å°æ¥­å·¥ä½ç¥è­åæè½ç¿å¾çæ¹é¢ãç¶å¾ï¼å®éå°åæ LLM å¨æè²ä¸­ä½¿ç¨çç¼ºé»æä¾äºæä½³å¯¦åå»ºè­°ãåç®¡çæå¼ AI å¨æè²ä¸­ä½¿ç¨å­å¨ææ°ï¼ä½çç©é«å­¸åå¥åº·é åä»¥åå¶ä»é åçææå­¸çåæè·å¡å·¥é½å¿é äºè§£ä¸¦çç·´ä½¿ç¨å®ã

##### **CSSDM Ontology to Enable Continuity of Care Data Interoperability**
2501.10160v1 by Subhashis Das, Debashis Naskar, Sara Rodriguez Gonzalez, Pamela Hussey

The rapid advancement of digital technologies and recent global pandemic
scenarios have led to a growing focus on how these technologies can enhance
healthcare service delivery and workflow to address crises. Action plans that
consolidate existing digital transformation programs are being reviewed to
establish core infrastructure and foundations for sustainable healthcare
solutions. Reforming health and social care to personalize home care, for
example, can help avoid treatment in overcrowded acute hospital settings and
improve the experiences and outcomes for both healthcare professionals and
service users. In this information-intensive domain, addressing the
interoperability challenge through standards-based roadmaps is crucial for
enabling effective connections between health and social care services. This
approach facilitates safe and trustworthy data workflows between different
healthcare system providers. In this paper, we present a methodology for
extracting, transforming, and loading data through a semi-automated process
using a Common Semantic Standardized Data Model (CSSDM) to create personalized
healthcare knowledge graph (KG). The CSSDM is grounded in the formal ontology
of ISO 13940 ContSys and incorporates FHIR-based specifications to support
structural attributes for generating KGs. We propose that the CSSDM facilitates
data harmonization and linking, offering an alternative approach to
interoperability. This approach promotes a novel form of collaboration between
companies developing health information systems and cloud-enabled health
services. Consequently, it provides multiple stakeholders with access to
high-quality data and information sharing.

æè¦ï¼æ¸ä½ç§æå¿«éé²æ­¥åæè¿çå¨çå¤§æµè¡çæå¢å·²å°è´è¶ä¾è¶å¤äººå°æ³¨æ¼éäºç§æå¦ä½å¢å¼·é«çä¿å¥æåæä¾åå·¥ä½æµç¨ä»¥æå°å±æ©ãæ´åç¾ææ¸ä½è½åè¨ç«çè¡åè¨ç«æ­£è¢«æª¢è¦ï¼ä»¥å»ºç«æ°¸çºé«çä¿å¥è§£æ±ºæ¹æ¡çæ ¸å¿åºç¤æ¶æ§ååºç¤ãä¾å¦ï¼æ¹é©é«çåç¤¾æç§è­·ä»¥åäººåå±å®¶ç§è­·ï¼æå©æ¼é¿åå¨äººæ»¿çºæ£çæ¥æ§é«é¢ç°å¢ä¸­æ¥åæ²»çï¼ä¸¦æ¹åé«çä¿å¥å°æ¥­äººå¡åæåä½¿ç¨èçç¶é©åçµæãå¨éåè³è¨å¯éçé åï¼ééåºæ¼æ¨æºçè·¯å¾åä¾è§£æ±ºäºéæ§ææ°ï¼å°æ¼ä¿æé«çä¿å¥æååç¤¾æç§è­·æåä¹éçææé£çµè³ééè¦ãæ­¤æ¹æ³ä¿æä¸åé«çä¿å¥ç³»çµ±ä¾æåä¹éå®å¨ä¸å¼å¾ä¿¡è³´çè³æå·¥ä½æµç¨ãå¨æ¬æä¸­ï¼æåæåºä¸åæ¹æ³ï¼ééåèªååæµç¨ä½¿ç¨éç¨èªææ¨æºåè³ææ¨¡å (CSSDM) ä¾èåãè½æåè¼å¥è³æï¼ä»¥å»ºç«åäººåçé«çä¿å¥ç¥è­åè­ (KG)ãCSSDM ä»¥ ISO 13940 ContSys çæ­£å¼æ¬ä½è«çºåºç¤ï¼ä¸¦çµååºæ¼ FHIR çè¦æ ¼ä¾æ¯æ´ç¨æ¼ç¢ç KG ççµæ§å±¬æ§ãæåæåº CSSDM ä¿é²è³æèª¿ååé£çµï¼æä¾ä¸ç¨®äºéæ§çæ¿ä»£æ¹æ³ãæ­¤æ¹æ³ä¿æéç¼é«çè³è¨ç³»çµ±åé²ç«¯é«çæåçå¬å¸ä¹éçä¸ç¨®æ°ååä½å½¢å¼ãå æ­¤ï¼å®æä¾å¤åå©å®³éä¿äººå­åé«åè³ªè³æåè³è¨å±äº«ã

##### **landmarker: a Toolkit for Anatomical Landmark Localization in 2D/3D Images**
2501.10098v1 by Jef Jonkers, Luc Duchateau, Glenn Van Wallendael, Sofie Van Hoecke

Anatomical landmark localization in 2D/3D images is a critical task in
medical imaging. Although many general-purpose tools exist for landmark
localization in classical computer vision tasks, such as pose estimation, they
lack the specialized features and modularity necessary for anatomical landmark
localization applications in the medical domain. Therefore, we introduce
landmarker, a Python package built on PyTorch. The package provides a
comprehensive, flexible toolkit for developing and evaluating landmark
localization algorithms, supporting a range of methodologies, including static
and adaptive heatmap regression. landmarker enhances the accuracy of landmark
identification, streamlines research and development processes, and supports
various image formats and preprocessing pipelines. Its modular design allows
users to customize and extend the toolkit for specific datasets and
applications, accelerating innovation in medical imaging. landmarker addresses
a critical need for precision and customization in landmark localization tasks
not adequately met by existing general-purpose pose estimation tools.

æè¦ï¼å¨ 2D/3D å½±åä¸­é²è¡è§£åæ¨èªå®ä½æ¯é«å­¸å½±åä¸­çä¸é ééµä»»åãåç®¡æè¨±å¤éç¨å·¥å·å¯ç¨æ¼ç¶å¸é»è¦è¦è¦ºä»»åä¸­çæ¨èªå®ä½ï¼ä¾å¦å§¿å¢ä¼°è¨ï¼ä½å®åç¼ºä¹è§£åæ¨èªå®ä½æç¨å¨é«å­¸é åä¸­æéçå°æ¥­åè½åæ¨¡çµåãå æ­¤ï¼æåå¼å¥äº landmarkerï¼ä¸åå»ºç«å¨ PyTorch ä¸ç Python å¥ä»¶ãè©²å¥ä»¶æä¾äºä¸åå¨é¢ä¸éæ´»çå·¥å·åï¼ç¨æ¼éç¼åè©ä¼°æ¨èªå®ä½æ¼ç®æ³ï¼æ¯æ´åç¨®æ¹æ³ï¼åæ¬éæåèªé©æç±ååæ­¸ãlandmarker æåäºæ¨èªè­å¥çæºç¢ºæ§ï¼ç°¡åäºç ç©¶åéç¼æµç¨ï¼ä¸¦æ¯æ´åç¨®å½±åæ ¼å¼ååèçç®¡éãå¶æ¨¡çµåè¨­è¨ä½¿ç¨æ¶è½å¤ èªè¨åå»¶ä¼¸å·¥å·åï¼ä»¥é©ç¨æ¼ç¹å®è³æéåæç¨ï¼å éé«å­¸å½±åçåµæ°ãlandmarker æ»¿è¶³äºç¾æéç¨å§¿å¢ä¼°è¨å·¥å·ç¡æ³ååæ»¿è¶³çæ¨èªå®ä½ä»»åä¸­å°æ¼ç²¾ç¢ºåº¦åèªè¨åçééµéæ±ã

##### **Deep Learning for Early Alzheimer Disease Detection with MRI Scans**
2501.09999v1 by Mohammad Rafsan, Tamer Oraby, Upal Roy, Sanjeev Kumar, Hansapani Rodrigo

Alzheimer's Disease is a neurodegenerative condition characterized by
dementia and impairment in neurological function. The study primarily focuses
on the individuals above age 40, affecting their memory, behavior, and
cognitive processes of the brain. Alzheimer's disease requires diagnosis by a
detailed assessment of MRI scans and neuropsychological tests of the patients.
This project compares existing deep learning models in the pursuit of enhancing
the accuracy and efficiency of AD diagnosis, specifically focusing on the
Convolutional Neural Network, Bayesian Convolutional Neural Network, and the
U-net model with the Open Access Series of Imaging Studies brain MRI dataset.
Besides, to ensure robustness and reliability in the model evaluations, we
address the challenge of imbalance in data. We then perform rigorous evaluation
to determine strengths and weaknesses for each model by considering
sensitivity, specificity, and computational efficiency. This comparative
analysis would shed light on the future role of AI in revolutionizing AD
diagnostics but also paved ways for future innovation in medical imaging and
the management of neurodegenerative diseases.

æè¦ï¼é¿è²æµ·é»çæ¯ä¸ç¨®ç¥ç¶éåæ§ç¾çï¼ç¹å¾µçºå¤±æºåç¥ç¶åè½åæãæ¬ç ç©¶ä¸»è¦éå° 40 æ­²ä»¥ä¸çåäººï¼å½±é¿ä»åçè¨æ¶åãè¡çºåèªç¥éç¨ãé¿è²æµ·é»çéè¦ééè©³ç´°è©ä¼°çæ£ç MRI ææåç¥ç¶å¿çæ¸¬è©¦ä¾è¨ºæ·ãæ¬å°æ¡æ¯è¼ç¾æçæ·±åº¦å­¸ç¿æ¨¡åï¼ä»¥å°æ±æå AD è¨ºæ·çæºç¢ºæ§åæçï¼ç¹å¥èéæ¼å·ç©ç¥ç¶ç¶²è·¯ãè²æ°å·ç©ç¥ç¶ç¶²è·¯å U-net æ¨¡åï¼ä»¥åéæ¾åç¨å½±åç ç©¶ç³»åçè¦é¨ MRI è³æéãæ­¤å¤ï¼çºäºç¢ºä¿æ¨¡åè©ä¼°çç©©å¥æ§åå¯é æ§ï¼æåè§£æ±ºäºè³æä¸å¹³è¡¡çææ°ãæ¥èæåå·è¡å´è¬¹çè©ä¼°ï¼ééèéææåº¦ãç¹ç°åº¦åè¨ç®æçä¾ç¢ºå®æ¯åæ¨¡åçåªç¼ºé»ãæ­¤æ¯è¼åæå°é¡æ AI å¨é©æ° AD è¨ºæ·æ¹é¢çæªä¾è§è²ï¼ä¹çºé«å­¸å½±ååç¥ç¶éåæ§ç¾çç®¡ççæªä¾åµæ°éªè·¯ã

##### **Aneumo: A Large-Scale Comprehensive Synthetic Dataset of Aneurysm Hemodynamics**
2501.09980v1 by Xigui Li, Yuanye Zhou, Feiyang Xiao, Xin Guo, Yichi Zhang, Chen Jiang, Jianchao Ge, Xiansheng Wang, Qimeng Wang, Taiwei Zhang, Chensen Lin, Yuan Cheng, Yuan Qi

Intracranial aneurysm (IA) is a common cerebrovascular disease that is
usually asymptomatic but may cause severe subarachnoid hemorrhage (SAH) if
ruptured. Although clinical practice is usually based on individual factors and
morphological features of the aneurysm, its pathophysiology and hemodynamic
mechanisms remain controversial. To address the limitations of current
research, this study constructed a comprehensive hemodynamic dataset of
intracranial aneurysms. The dataset is based on 466 real aneurysm models, and
10,000 synthetic models were generated by resection and deformation operations,
including 466 aneurysm-free models and 9,534 deformed aneurysm models. The
dataset also provides medical image-like segmentation mask files to support
insightful analysis. In addition, the dataset contains hemodynamic data
measured at eight steady-state flow rates (0.001 to 0.004 kg/s), including
critical parameters such as flow velocity, pressure, and wall shear stress,
providing a valuable resource for investigating aneurysm pathogenesis and
clinical prediction. This dataset will help advance the understanding of the
pathologic features and hemodynamic mechanisms of intracranial aneurysms and
support in-depth research in related fields. Dataset hosted at
https://github.com/Xigui-Li/Aneumo.

æè¦ï¼é¡±å§åèç¤ï¼IAï¼æ¯ä¸ç¨®å¸¸è¦çè¦è¡ç®¡ç¾çï¼éå¸¸ç¡ççï¼ä½å¦æç ´è£å¯è½æå°è´å´éçèç¶²èä¸èåºè¡ï¼SAHï¼ãåç®¡è¨åºå¯¦åéå¸¸åºæ¼åé«å ç´ ååèç¤çå½¢æç¹å¾µï¼ä½å¶ççççå­¸åè¡æµååå­¸æ©å¶ä»å­å¨ç­è­°ãçºäºè§£æ±ºç¶åç ç©¶çéå¶ï¼æ¬ç ç©¶æ§å»ºäºä¸åé¡±å§åèç¤çå¨é¢è¡æµååå­¸æ¸æéãè©²æ¸æéåºæ¼ 466 åçå¯¦åèç¤æ¨¡åï¼ä¸¦ééåé¤åè®å½¢æä½çæäº 10,000 ååææ¨¡åï¼åæ¬ 466 åç¡åèç¤æ¨¡åå 9,534 åè®å½¢åèç¤æ¨¡åãè©²æ¸æééæä¾äºé¡é«å­¸å½±åçåå²é®ç½©æªæ¡ï¼ä»¥æ¯ææ·±å¥åæãæ­¤å¤ï¼è©²æ¸æéåå«å¨å«åç©©ææµéï¼0.001 è³ 0.004 kg/sï¼ä¸æ¸¬éçè¡æµååå­¸æ¸æï¼åæ¬æµéãå£ååå£é¢åªæåç­ééµåæ¸ï¼çºç ç©¶åèç¤ç¼çæ©å¶åè¨åºé æ¸¬æä¾äºå¯¶è²´çè³æºãæ­¤æ¸æéå°æå©æ¼å¢é²å°é¡±å§åèç¤ççç¹å¾µåè¡æµååå­¸æ©å¶çäºè§£ï¼ä¸¦æ¯æç¸éé åçæ·±å¥ç ç©¶ãæ¸æéè¨ç®¡æ¼ https://github.com/Xigui-Li/Aneumoã

##### **Bias in Decision-Making for AI's Ethical Dilemmas: A Comparative Study of ChatGPT and Claude**
2501.10484v1 by Yile Yan, Yuqi Zhu, Wentao Xu

Recent advances in Large Language Models (LLMs) have enabled human-like
responses across various tasks, raising questions about their ethical
decision-making capabilities and potential biases. This study investigates
protected attributes in LLMs through systematic evaluation of their responses
to ethical dilemmas. Using two prominent models - GPT-3.5 Turbo and Claude 3.5
Sonnet - we analyzed their decision-making patterns across multiple protected
attributes including age, gender, race, appearance, and disability status.
Through 11,200 experimental trials involving both single-factor and two-factor
protected attribute combinations, we evaluated the models' ethical preferences,
sensitivity, stability, and clustering of preferences. Our findings reveal
significant protected attributeses in both models, with consistent preferences
for certain features (e.g., "good-looking") and systematic neglect of others.
Notably, while GPT-3.5 Turbo showed stronger preferences aligned with
traditional power structures, Claude 3.5 Sonnet demonstrated more diverse
protected attribute choices. We also found that ethical sensitivity
significantly decreases in more complex scenarios involving multiple protected
attributes. Additionally, linguistic referents heavily influence the models'
ethical evaluations, as demonstrated by differing responses to racial
descriptors (e.g., "Yellow" versus "Asian"). These findings highlight critical
concerns about the potential impact of LLM biases in autonomous decision-making
systems and emphasize the need for careful consideration of protected
attributes in AI development. Our study contributes to the growing body of
research on AI ethics by providing a systematic framework for evaluating
protected attributes in LLMs' ethical decision-making capabilities.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) è¿æçé²å±ï¼è®äººåå¨åç¨®ä»»åä¸­é½è½ååºé¡ä¼¼äººé¡çåæï¼éä¹å¼ç¼äºäººåå°å¶éå¾·æ±ºç­è½ååæ½å¨åè¦çè³ªçãæ¬ç ç©¶ééç³»çµ±æ§å°è©ä¼° LLM å°éå¾·å°å¢çåæï¼ä¾æ¢è¨åä¿è­·å±¬æ§å¨ LLM ä¸­çè¡¨ç¾ãæåä½¿ç¨å©åèåçæ¨¡å - GPT-3.5 Turbo å Claude 3.5 Sonnet - åæäºå®åå¨å¤ååä¿è­·å±¬æ§ï¼åæ¬å¹´é½¡ãæ§å¥ãç¨®æãå¤è²åæ®ç¾çæï¼ä¸çæ±ºç­æ¨¡å¼ãéé 11,200 æ¬¡å¯¦é©è©¦é©ï¼åæ¬å®å ç´ åéå ç´ åä¿è­·å±¬æ§çµåï¼ï¼æåè©ä¼°äºæ¨¡åçéå¾·åå¥½ãææåº¦ãç©©å®æ§ååå¥½ç¾¤éãæåçç ç©¶çµææ­ç¤ºäºéå©åæ¨¡åä¸­é¡¯èçåä¿è­·å±¬æ§ï¼å®åå°æäºç¹å¾µï¼ä¾å¦ãå¥½çãï¼ææçºçåå¥½ï¼ä¸¦ä¸ç³»çµ±æ§å°å¿½ç¥å¶ä»ç¹å¾µãå¼å¾æ³¨æçæ¯ï¼éç¶ GPT-3.5 Turbo è¡¨ç¾åºèå³çµ±æ¬åçµæ§ä¸è´çå¼·çåå¥½ï¼ä½ Claude 3.5 Sonnet åè¡¨ç¾åºæ´å¤æ¨£åçåä¿è­·å±¬æ§é¸æãæåéç¼ç¾ï¼å¨æ¶åå¤ååä¿è­·å±¬æ§çæ´è¤éå ´æ¯ä¸­ï¼éå¾·ææåº¦æé¡¯èéä½ãæ­¤å¤ï¼èªè¨æç¨±æå´éå½±é¿æ¨¡åçéå¾·è©ä¼°ï¼éå¾å°ç¨®ææè¿°ç¬¦ï¼ä¾å¦ãé»è²ãèãäºæ´²äººãï¼çä¸ååæä¸­å¯ä»¥çåºãéäºç¼ç¾çªé¡¯äº LLM åè¦å¨èªä¸»æ±ºç­ç³»çµ±ä¸­æ½å¨å½±é¿çééµåé¡ï¼ä¸¦å¼·èª¿å¨ AI éç¼ä¸­ä»ç´°èæ®åä¿è­·å±¬æ§çå¿è¦æ§ãæåçç ç©¶ééæä¾ä¸åç³»çµ±æ§çæ¶æ§ä¾è©ä¼° LLM éå¾·æ±ºç­è½åä¸­çåä¿è­·å±¬æ§ï¼çº AI å«çé åçç ç©¶ååºäºè²¢ç»ã

##### **Bridging Language Barriers in Healthcare: A Study on Arabic LLMs**
2501.09825v1 by Nada Saadi, Tathagata Raha, ClÃ©ment Christophe, Marco AF Pimentel, Ronnie Rajan, Praveen K Kanithi

This paper investigates the challenges of developing large language models
(LLMs) proficient in both multilingual understanding and medical knowledge. We
demonstrate that simply translating medical data does not guarantee strong
performance on clinical tasks in the target language. Our experiments reveal
that the optimal language mix in training data varies significantly across
different medical tasks. We find that larger models with carefully calibrated
language ratios achieve superior performance on native-language clinical tasks.
Furthermore, our results suggest that relying solely on fine-tuning may not be
the most effective approach for incorporating new language knowledge into LLMs.
Instead, data and computationally intensive pretraining methods may still be
necessary to achieve optimal performance in multilingual medical settings.
These findings provide valuable guidance for building effective and inclusive
medical AI systems for diverse linguistic communities.

æè¦ï¼æ¬ææ¢è¨äºéç¼æ¢ç²¾éå¤èªè¨çè§£åç²¾éé«çç¥è­çå¤§åèªè¨æ¨¡å (LLM) çææ°ãæåè­æï¼åç¿»è­¯é«çè³æä¸¦ä¸è½ä¿è­å¨ç®æ¨èªè¨çè¨åºä»»åä¸­è¡¨ç¾åºè²ãæåçå¯¦é©æ­ç¤ºï¼è¨ç·´è³æä¸­çæä½³èªè¨çµåå ä¸åçé«çä»»åèç°ãæåç¼ç¾ï¼å·æä»ç´°æ ¡æºèªè¨æ¯ä¾çè¼å¤§æ¨¡åå¨æ¯èªè¨åºä»»åä¸­è¡¨ç¾æ´ä½³ãæ­¤å¤ï¼æåççµæè¡¨æï¼åä¾è³´å¾®èª¿å¯è½ä¸æ¯å°æ°çèªè¨ç¥è­ç´å¥ LLM çææææ¹æ³ãç¸åï¼è³æåè¨ç®å¯éåé è¨ç·´æ¹æ³å°æ¼å¨å¤èªè¨é«çç°å¢ä¸­å¯¦ç¾æä½³æè½å¯è½ä»ç¶å¿è¦ãéäºç¼ç¾çºå»ºç«ææä¸åå®¹æ§çé«ç AI ç³»çµ±ï¼ä»¥æåæ¼ä¸åçèªè¨ç¤¾ç¾¤ï¼æä¾äºæå¹å¼çæå°æ¹éã

##### **KU AIGEN ICL EDI@BC8 Track 3: Advancing Phenotype Named Entity Recognition and Normalization for Dysmorphology Physical Examination Reports**
2501.09744v1 by Hajung Kim, Chanhwi Kim, Jiwoong Sohn, Tim Beck, Marek Rei, Sunkyu Kim, T Ian Simpson, Joram M Posma, Antoine Lain, Mujeen Sung, Jaewoo Kang

The objective of BioCreative8 Track 3 is to extract phenotypic key medical
findings embedded within EHR texts and subsequently normalize these findings to
their Human Phenotype Ontology (HPO) terms. However, the presence of diverse
surface forms in phenotypic findings makes it challenging to accurately
normalize them to the correct HPO terms. To address this challenge, we explored
various models for named entity recognition and implemented data augmentation
techniques such as synonym marginalization to enhance the normalization step.
Our pipeline resulted in an exact extraction and normalization F1 score 2.6\%
higher than the mean score of all submissions received in response to the
challenge. Furthermore, in terms of the normalization F1 score, our approach
surpassed the average performance by 1.9\%. These findings contribute to the
advancement of automated medical data extraction and normalization techniques,
showcasing potential pathways for future research and application in the
biomedical domain.

æè¦ï¼BioCreative8 è»é 3 çç®æ¨æ¯å¾é»å­çæ­·ææ¬ä¸­èåè¡¨åééµé«çç¼ç¾ï¼ä¸¦å°éäºç¼ç¾æ¨æºåçºäººé¡è¡¨åæ¬ä½ (HPO) æ¢æ¬¾ãç¶èï¼è¡¨åç¼ç¾ä¸­å­å¨å¤æ¨£åçè¡¨é¢å½¢å¼ï¼éä½¿å¾å°å¶æºç¢ºæ¨æºåçºæ­£ç¢ºç HPO æ¢æ¬¾å·æææ°æ§ãçºäºæå°éä¸ææ°ï¼æåæ¢è¨äºå½åå¯¦é«è­å¥çåç¨®æ¨¡åï¼ä¸¦å¯¦ä½äºè³ææ´åæè¡ï¼ä¾å¦åç¾©è©éç·£åï¼ä»¥å¢å¼·æ¨æºåæ­¥é©ãæåçç®¡éç¢çäºç²¾ç¢ºçèååæ¨æºå F1 åæ¸ï¼æ¯åæææ°ææ¶å°çæææäº¤çå¹³ååæ¸é« 2.6%ãæ­¤å¤ï¼å¨æ¨æºå F1 åæ¸æ¹é¢ï¼æåçåæ³æ¯å¹³åè¡¨ç¾é«åº 1.9%ãéäºç¼ç¾æå©æ¼èªååé«çè³æèååæ¨æºåæè¡çé²å±ï¼å±ç¤ºäºçç©é«å­¸é åæªä¾ç ç©¶åæç¨çæ½å¨éå¾ã

##### **Electronic Health Records: Towards Digital Twins in Healthcare**
2501.09640v1 by Muhammet Alkan, Hester Huijsdens, Yola Jones, Fani Deligianni

The pivotal shift from traditional paper-based records to sophisticated
Electronic Health Records (EHR), enabled systematic collection and analysis of
patient data through descriptive statistics, providing insight into patterns
and trends across patient populations. This evolution continued toward
predictive analytics, allowing healthcare providers to anticipate patient
outcomes and potential complications before they occur. This progression from
basic digital record-keeping to sophisticated predictive modelling and digital
twins reflects healthcare's broader evolution toward more integrated,
patient-centred approaches that combine data-driven insights with personalized
care delivery. This chapter explores the evolution and significance of
healthcare information systems, beginning with an examination of the
implementation of EHR in the UK and the USA. It provides a comprehensive
overview of the International Classification of Diseases (ICD) system, tracing
its development from ICD-9 to ICD-10. Central to this discussion is the
MIMIC-III database, a landmark achievement in healthcare data sharing and
arguably the most comprehensive critical care database freely available to
researchers worldwide. MIMIC-III has democratized access to high-quality
healthcare data, enabling unprecedented opportunities for research and
analysis. The chapter examines its structure, clinical outcome analysis
capabilities, and practical applications through case studies, with a
particular focus on mortality and length of stay metrics, vital signs
extraction, and ICD coding. Through detailed entity-relationship diagrams and
practical examples, the text illustrates MIMIC's complex data structure and
demonstrates how different querying approaches can lead to subtly different
results, emphasizing the critical importance of understanding the database's
architecture for accurate data extraction.

æè¦ï¼å¾å³çµ±ç´æ¬è¨éè½è®çºåé²çé»å­å¥åº·è¨éï¼EHRï¼ï¼ä¿ä½¿ééæè¿°æ§çµ±è¨ç³»çµ±æ§å°æ¶éååæçæ£è³æï¼é²èæ·±å¥äºè§£çæ£æç¾¤çæ¨¡å¼åè¶¨å¢ãéé æ¼é²æçºæåé æ¸¬åæç¼å±ï¼è®é«çä¿å¥æä¾èè½å¤ å¨çæ£åºç¾çµæåæ½å¨ä½µç¼çä¹åé æ¸¬éäºçæ³ãå¾åºæ¬çæ¸ä½è¨éä¿å­é²å±å°åé²çé æ¸¬æ¨¡ååæ¸ä½éèèï¼åæ äºé«çä¿å¥æåæ´æ´åãä»¥çæ£çºä¸­å¿çåæ³æåçæ´å»£æ³æ¼é²ï¼éäºåæ³çµåäºè³æé©åçè¦è§£èåäººåç§è­·æåãæ¬ç« æ¢è¨é«çä¿å¥è³è¨ç³»çµ±çæ¼é²åéè¦æ§ï¼å¾å¯©æ¥è±ååç¾åå¯¦æ½ EHR éå§ãå®æä¾äºç¾çåéåé¡ï¼ICDï¼ç³»çµ±çå¨é¢æ¦è¿°ï¼è¿½æº¯å¶å¾ ICD-9 ç¼å±å° ICD-10 çéç¨ãæ­¤è¨è«çæ ¸å¿æ¯ MIMIC-III è³æåº«ï¼éæ¯é«çä¿å¥è³æå±äº«çä¸é éç¨ç¢å¼æå°±ï¼å¯ä»¥èªªæ¯å¨çç ç©¶äººå¡å¯ä»¥åè²»åå¾çæå¨é¢çéçç§è­·è³æåº«ãMIMIC-III æ°ä¸»åäºå°é«åè³ªé«çä¿å¥è³æçå­åï¼çºç ç©¶ååæåµé äºåææªæçæ©æãæ¬ç« ééæ¡ä¾ç ç©¶æ¢è¨å¶çµæ§ãè¨åºçµæåæè½ååå¯¦éæç¨ï¼ç¹å¥éæ³¨æ­»äº¡çåä½é¢æéææ¨ãçå½å¾µè±¡èåå ICD ç·¨ç¢¼ãééè©³ç´°çå¯¦é«éä¿ååå¯¦åç¯ä¾ï¼æ¬æèªªæäº MIMIC è¤éçè³æçµæ§ï¼ä¸¦å±ç¤ºäºä¸åçæ¥è©¢æ¹æ³å¦ä½å°è´ç´°å¾®ä¸åççµæï¼å¼·èª¿äºäºè§£è³æåº«æ¶æ§å°æ¼æºç¢ºèåè³æè³ééè¦çéè¦æ§ã

##### **Artificial Intelligence-Driven Clinical Decision Support Systems**
2501.09628v1 by Muhammet Alkan, Idris Zakariyya, Samuel Leighton, Kaushik Bhargav Sivangi, Christos Anagnostopoulos, Fani Deligianni

As artificial intelligence (AI) becomes increasingly embedded in healthcare
delivery, this chapter explores the critical aspects of developing reliable and
ethical Clinical Decision Support Systems (CDSS). Beginning with the
fundamental transition from traditional statistical models to sophisticated
machine learning approaches, this work examines rigorous validation strategies
and performance assessment methods, including the crucial role of model
calibration and decision curve analysis. The chapter emphasizes that creating
trustworthy AI systems in healthcare requires more than just technical
accuracy; it demands careful consideration of fairness, explainability, and
privacy. The challenge of ensuring equitable healthcare delivery through AI is
stressed, discussing methods to identify and mitigate bias in clinical
predictive models. The chapter then delves into explainability as a cornerstone
of human-centered CDSS. This focus reflects the understanding that healthcare
professionals must not only trust AI recommendations but also comprehend their
underlying reasoning. The discussion advances in an analysis of privacy
vulnerabilities in medical AI systems, from data leakage in deep learning
models to sophisticated attacks against model explanations. The text explores
privacy-preservation strategies such as differential privacy and federated
learning, while acknowledging the inherent trade-offs between privacy
protection and model performance. This progression, from technical validation
to ethical considerations, reflects the multifaceted challenges of developing
AI systems that can be seamlessly and reliably integrated into daily clinical
practice while maintaining the highest standards of patient care and data
protection.

æè¦ï¼é¨èäººå·¥æºæ§ (AI) å¨é«çä¿å¥ä¸­çæç¨æ¥çæ®åï¼æ¬ç« æ¢è¨äºéç¼å¯é ä¸ç¬¦åéå¾·æ¨æºçè¨åºæ±ºç­æ¯æ´ç³»çµ± (CDSS) çééµé¢åãå¾å³çµ±çµ±è¨æ¨¡åå°è¤éæ©å¨å­¸ç¿æ¹æ³çåºæ¬è½è®éå§ï¼éé å·¥ä½å¯©æ¥äºå´è¬¹çé©è­ç­ç¥åæè½è©ä¼°æ¹æ³ï¼åæ¬æ¨¡åæ ¡æºåæ±ºç­æ²ç·åæçééµè§è²ãæ¬ç« å¼·èª¿ï¼å¨é«çä¿å¥ä¸­å»ºç«å¼å¾ä¿¡è³´ç AI ç³»çµ±ä¸åªæ¯æè¡ä¸çæºç¢ºæ§ï¼å®éè¦ä»ç´°èéå¬å¹³æ§ãå¯è§£éæ§åé±ç§æ¬ãæ¬ç« å¼·èª¿äºéé AI ç¢ºä¿å¬å¹³çé«çä¿å¥æåçææ°ï¼ä¸¦è¨è«äºè­å¥åæ¸è¼è¨åºé æ¸¬æ¨¡åä¸­åå·®çæ¹æ³ãæ¥èï¼æ¬ç« æ·±å¥æ¢è¨å¯è§£éæ§ï¼ä½çºä»¥äººçºä¸­å¿ç CDSS çåºç³ãéç¨®éæ³¨åæ äºé«çä¿å¥å°æ¥­äººå¡ä¸åå¿é ä¿¡ä»» AI å»ºè­°ï¼éå¿é çè§£å¶èå¾çæ¨çãè¨è«é²ä¸æ­¥åæäºé«ç AI ç³»çµ±ä¸­çé±ç§æ¼æ´ï¼å¾æ·±åº¦å­¸ç¿æ¨¡åä¸­çè³æå¤æ´©å°éå°æ¨¡åè§£éçè¤éæ»æãæ¬ææ¢è¨äºé±ç§ä¿è­·ç­ç¥ï¼ä¾å¦å·®åé±ç§åè¯åå­¸ç¿ï¼åææ¿èªé±ç§ä¿è­·åæ¨¡åæè½ä¹éçåºæåæ¨ãéç¨®å¾æè¡é©è­å°éå¾·èéçé²å±ï¼åæ äºéç¼ AI ç³»çµ±çå¤é¢åææ°ï¼éäºç³»çµ±å¯ä»¥ç¡ç¸«ä¸å¯é å°æ´åå°æ¥å¸¸è¨åºå¯¦åä¸­ï¼åæç¶­ææé«ççæ£ç§è­·åè³æä¿è­·æ¨æºã

##### **IFRA: a machine learning-based Instrumented Fall Risk Assessment Scale derived from Instrumented Timed Up and Go test in stroke patients**
2501.09595v1 by Simone MacciÃ², Alessandro CarfÃ¬, Alessio Capitanelli, Peppino Tropea, Massimo Corbo, Fulvio Mastrogiovanni, Michela Picardi

Effective fall risk assessment is critical for post-stroke patients. The
present study proposes a novel, data-informed fall risk assessment method based
on the instrumented Timed Up and Go (ITUG) test data, bringing in many mobility
measures that traditional clinical scales fail to capture. IFRA, which stands
for Instrumented Fall Risk Assessment, has been developed using a two-step
process: first, features with the highest predictive power among those
collected in a ITUG test have been identified using machine learning
techniques; then, a strategy is proposed to stratify patients into low, medium,
or high-risk strata. The dataset used in our analysis consists of 142
participants, out of which 93 were used for training (15 synthetically
generated), 17 for validation and 32 to test the resulting IFRA scale (22
non-fallers and 10 fallers). Features considered in the IFRA scale include gait
speed, vertical acceleration during sit-to-walk transition, and turning angular
velocity, which align well with established literature on the risk of fall in
neurological patients. In a comparison with traditional clinical scales such as
the traditional Timed Up & Go and the Mini-BESTest, IFRA demonstrates
competitive performance, being the only scale to correctly assign more than
half of the fallers to the high-risk stratum (Fischer's Exact test p = 0.004).
Despite the dataset's limited size, this is the first proof-of-concept study to
pave the way for future evidence regarding the use of IFRA tool for continuous
patient monitoring and fall prevention both in clinical stroke rehabilitation
and at home post-discharge.

æè¦ï¼<paragraph>å°ä¸­é¢¨å¾æ£èèè¨ï¼ææçè·åé¢¨éªè©ä¼°è³ééè¦ãæ¬ç ç©¶æåºä¸ååµæ°çãåºæ¼è³æçè·åé¢¨éªè©ä¼°æ¹æ³ï¼è©²æ¹æ³åºæ¼åå¨åçè¨æèµ·èº«åè¡èµ° (ITUG) æ¸¬è©¦è³æï¼ç´å¥äºè¨±å¤å³çµ±è¨åºéè¡¨æªè½ææå°çæ´»åè½åæ¸¬éææ¨ãIFRAï¼ä»£è¡¨åå¨åè·åé¢¨éªè©ä¼°ï¼å·²ä½¿ç¨å©æ­¥é©æµç¨éç¼ï¼é¦åï¼å·²ä½¿ç¨æ©å¨å­¸ç¿æè¡è­å¥åºå¨ ITUG æ¸¬è©¦ä¸­æ¶éçé£äºå·ææé«é æ¸¬è½åçç¹å¾µï¼ç¶å¾ï¼æåºäºä¸é ç­ç¥å°æ£èåå±¤çºä½é¢¨éªãä¸­é¢¨éªæé«é¢¨éªç­ç´ãæåçåæä¸­ä½¿ç¨çè³æéåå« 142 ååèèï¼å¶ä¸­ 93 åç¨æ¼è¨ç·´ï¼15 ååæç¢çï¼ï¼17 åç¨æ¼é©è­ï¼32 åç¨æ¼æ¸¬è©¦ç¢çç IFRA éè¡¨ï¼22 åéè·åèå 10 åè·åèï¼ãIFRA éè¡¨ä¸­èæ®çç¹å¾µåæ¬æ­¥æéåº¦ãåå°èµ°éæ¸¡æéçåç´å éåº¦åè½å½è§éåº¦ï¼éäºç¹å¾µèå·²å»ºç«çç¥ç¶çæ£è·åé¢¨éªæç»éå¸¸å»åãèå³çµ±è¨åºéè¡¨ï¼ä¾å¦å³çµ±çè¨æèµ·èº«åè¡èµ°åè¿·ä½  BESTestï¼ç¸æ¯ï¼IFRA è¡¨ç¾åºç«¶ç­åªå¢ï¼æ¯å¯ä¸å°è¶éä¸åçè·åèæ­£ç¢ºåéå°é«é¢¨éªéå±¤çéè¡¨ï¼Fisher ç²¾ç¢ºæª¢å® p = 0.004ï¼ãåç®¡è³æéè¦æ¨¡æéï¼ä½éæ¯ç¬¬ä¸åæ¦å¿µé©è­ç ç©¶ï¼çºæªä¾éæ¼å¨è¨åºä¸­é¢¨åº·å¾©ååºé¢å¾å±å®¶è·åé é²ä¸­ä½¿ç¨ IFRA å·¥å·çè­æéªè·¯ã</paragraph>

##### **Understanding Mental Health Content on Social Media and Its Effect Towards Suicidal Ideation**
2501.09309v1 by Mohaiminul Islam Bhuiyan, Nur Shazwani Kamarudin, Nur Hafieza Ismail

This review underscores the critical need for effective strategies to
identify and support individuals with suicidal ideation, exploiting
technological innovations in ML and DL to further suicide prevention efforts.
The study details the application of these technologies in analyzing vast
amounts of unstructured social media data to detect linguistic patterns,
keywords, phrases, tones, and contextual cues associated with suicidal
thoughts. It explores various ML and DL models like SVMs, CNNs, LSTM, neural
networks, and their effectiveness in interpreting complex data patterns and
emotional nuances within text data. The review discusses the potential of these
technologies to serve as a life-saving tool by identifying at-risk individuals
through their digital traces. Furthermore, it evaluates the real-world
effectiveness, limitations, and ethical considerations of employing these
technologies for suicide prevention, stressing the importance of responsible
development and usage. The study aims to fill critical knowledge gaps by
analyzing recent studies, methodologies, tools, and techniques in this field.
It highlights the importance of synthesizing current literature to inform
practical tools and suicide prevention efforts, guiding innovation in reliable,
ethical systems for early intervention. This research synthesis evaluates the
intersection of technology and mental health, advocating for the ethical and
responsible application of ML, DL, and NLP to offer life-saving potential
worldwide while addressing challenges like generalizability, biases, privacy,
and the need for further research to ensure these technologies do not
exacerbate existing inequities and harms.

æè¦ï¼éç¯è©è«å¼·èª¿äºææç­ç¥çéè¦éæ±ï¼ä»¥ééå©ç¨æ©å¨å­¸ç¿åæ·±åº¦å­¸ç¿çæè¡åµæ°ä¾è­å¥åæ¯ææèªæ®ºæå¿µçäººï¼é²ä¸æ­¥ä¿é²èªæ®ºé²æ²»å·¥ä½ãéé ç ç©¶è©³ç´°èªªæäºéäºæè¡å¨åæå¤§ééçµæ§åç¤¾ç¾¤åªé«è³æä¸­çæç¨ï¼ä»¥åµæ¸¬èèªæ®ºå¿µé ­ç¸éçèªè¨æ¨¡å¼ãééµå­ãè©çµãèªæ°£åèçµ¡ç·ç´¢ãå®æ¢è¨äºåç¨®æ©å¨å­¸ç¿åæ·±åº¦å­¸ç¿æ¨¡åï¼ä¾å¦æ¯æ´åéæ©ãå·ç©ç¥ç¶ç¶²è·¯ãé·ç­æè¨æ¶ç¶²è·¯ãç¥ç¶ç¶²è·¯ï¼ä»¥åå®åå¨è§£è®æå­è³æä¸­çè¤éè³ææ¨¡å¼åæç·ç´°å¾®å·®å¥æ¹é¢çæè½ãéç¯è©è«è¨è«äºéäºæè¡ä½çºæå½å·¥å·çæ½åï¼ééæ¸ä½è¶³è·¡ä¾è­å¥æé¢¨éªçåäººãæ­¤å¤ï¼å®è©ä¼°äºæ¡ç¨éäºæè¡é²è¡èªæ®ºé²æ²»çå¯¦éæè½ãéå¶åéå¾·èéï¼å¼·èª¿è² è²¬ä»»çéç¼åä½¿ç¨çéè¦æ§ãéé ç ç©¶æ¨å¨ééåæéåé åçè¿æç ç©¶ãæ¹æ³ãå·¥å·åæè¡ï¼å¡«è£éè¦çç¥è­å·®è·ãå®å¼·èª¿äºç¶åç¾ææç»å°æ¼æä¾å¯¦ç¨å·¥å·åèªæ®ºé²æ²»å·¥ä½çéè¦æ§ï¼å¼å°å¨æ©æä»å¥ä¸­å»ºç«å¯é çãç¬¦åéå¾·çç³»çµ±çåµæ°ãéé ç ç©¶ç¶åè©ä¼°äºæè¡åå¿çå¥åº·ä¹éçäº¤éï¼å¡å°éå¾·ä¸è² è²¬ä»»å°æç¨æ©å¨å­¸ç¿ãæ·±åº¦å­¸ç¿åèªç¶èªè¨èçï¼ä»¥æä¾å¨çæ§çæå½æ½åï¼åæè§£æ±ºæ¦æ¬æ§ãåèª¤ãé±ç§ç­ææ°ï¼ä¸¦éè¦é²ä¸æ­¥ç ç©¶ä»¥ç¢ºä¿éäºæè¡ä¸æå åç¾æçä¸å¹³ç­åå·å®³ã

##### **Interpretable Droplet Digital PCR Assay for Trustworthy Molecular Diagnostics**
2501.09218v1 by Yuanyuan Wei, Yucheng Wu, Fuyang Qu, Yao Mu, Yi-Ping Ho, Ho-Pui Ho, Wu Yuan, Mingkun Xu

Accurate molecular quantification is essential for advancing research and
diagnostics in fields such as infectious diseases, cancer biology, and genetic
disorders. Droplet digital PCR (ddPCR) has emerged as a gold standard for
achieving absolute quantification. While computational ddPCR technologies have
advanced significantly, achieving automatic interpretation and consistent
adaptability across diverse operational environments remains a challenge. To
address these limitations, we introduce the intelligent interpretable droplet
digital PCR (I2ddPCR) assay, a comprehensive framework integrating front-end
predictive models (for droplet segmentation and classification) with GPT-4o
multimodal large language model (MLLM, for context-aware explanations and
recommendations) to automate and enhance ddPCR image analysis. This approach
surpasses the state-of-the-art models, affording 99.05% accuracy in processing
complex ddPCR images containing over 300 droplets per image with varying
signal-to-noise ratios (SNRs). By combining specialized neural networks and
large language models, the I2ddPCR assay offers a robust and adaptable solution
for absolute molecular quantification, achieving a sensitivity capable of
detecting low-abundance targets as low as 90.32 copies/{\mu}L. Furthermore, it
improves model's transparency through detailed explanation and troubleshooting
guidance, empowering users to make informed decisions. This innovative
framework has the potential to benefit molecular diagnostics, disease research,
and clinical applications, especially in resource-constrained settings.

æè¦ï¼æºç¢ºçåå­éåå°æ¼æ¨é²å³æçãçççç©å­¸åéºå³ç¾çç­é åçç ç©¶åè¨ºæ·è³ééè¦ãé£æ²«æ¸ä½ PCR (ddPCR) å·²æçºå¯¦ç¾çµå°éåçé»éæ¨æºãåç®¡éç®å¼ ddPCR æè¡å·²å¤§å¹é²æ­¥ï¼ä½å¨ä¸åæä½ç°å¢ä¸­å¯¦ç¾èªååè§£è®åä¸è´çé©ææ§ä»ç¶æ¯ä¸é ææ°ãçºäºè§£æ±ºéäºéå¶ï¼æåå¼å¥äºæºæ§å¯è§£è®é£æ²«æ¸ä½ PCR (I2ddPCR) åæï¼ä¸åæ´ååç»æ§é æ¸¬æ¨¡åï¼ç¨æ¼é£æ²«åå²ååé¡ï¼è GPT-4o å¤æ¨¡æå¤§åèªè¨æ¨¡åï¼MLLMï¼ç¨æ¼æå¢æç¥è§£éåå»ºè­°ï¼çç¶åæ¶æ§ï¼ä»¥èªååä¸¦å¢å¼· ddPCR å½±ååæãæ­¤æ¹æ³è¶è¶äºæåé²çæ¨¡åï¼å¨èçæ¯å¼µå½±åå«æè¶é 300 åé£æ²«ä¸ä¿¡åªæ¯ (SNR) ä¸åçè¤é ddPCR å½±åæï¼æºç¢ºåº¦é«é 99.05%ãééçµåå°éçç¥ç¶ç¶²è·¯åå¤§åèªè¨æ¨¡åï¼I2ddPCR åææä¾äºä¸åå¼·å¥ä¸é©ææ§é«ççµå°åå­éåè§£æ±ºæ¹æ¡ï¼éæåº¦é«ï¼è½åµæ¸¬ä½è³ 90.32 åæ·è²æ¸/{\mu}L çä½è±åº¦ç®æ¨ãæ­¤å¤ï¼å®ééè©³ç´°çèªªæåæéæé¤æåä¾æåæ¨¡åçéæåº¦ï¼ä½¿ç¨æ¶è½å¤ ååºææºçæ±ºç­ãéååµæ°çæ¶æ§ææ½åé ç¦åå­è¨ºæ·ãç¾çç ç©¶åè¨åºæç¨ï¼ç¹å¥æ¯å¨è³æºåéçç°å¢ä¸­ã

##### **AutoLoop: Fast Visual SLAM Fine-tuning through Agentic Curriculum Learning**
2501.09160v1 by Assaf Lahiany, Oren Gal

Current visual SLAM systems face significant challenges in balancing
computational efficiency with robust loop closure handling. Traditional
approaches require careful manual tuning and incur substantial computational
overhead, while learning-based methods either lack explicit loop closure
capabilities or implement them through computationally expensive methods. We
present AutoLoop, a novel approach that combines automated curriculum learning
with efficient fine-tuning for visual SLAM systems. Our method employs a DDPG
(Deep Deterministic Policy Gradient) agent to dynamically adjust loop closure
weights during training, eliminating the need for manual hyperparameter search
while significantly reducing the required training steps. The approach
pre-computes potential loop closure pairs offline and leverages them through an
agent-guided curriculum, allowing the model to adapt efficiently to new
scenarios. Experiments conducted on TartanAir for training and validated across
multiple benchmarks including KITTI, EuRoC, ICL-NUIM and TUM RGB-D demonstrate
that AutoLoop achieves comparable or superior performance while reducing
training time by an order of magnitude compared to traditional approaches.
AutoLoop provides a practical solution for rapid adaptation of visual SLAM
systems, automating the weight tuning process that traditionally requires
multiple manual iterations. Our results show that this automated curriculum
strategy not only accelerates training but also maintains or improves the
model's performance across diverse environmental conditions.

æè¦ï¼ç¶åçè¦è¦º SLAM ç³»çµ±å¨å¹³è¡¡éç®æçèç©©å¥çè¿´è·¯éåèçä¸ï¼é¢è¨éå¤§ææ°ãå³çµ±æ¹æ³éè¦ä»ç´°çæåèª¿æ´ï¼ä¸¦æç¢çå¤§éçéç®è² æï¼èåºæ¼å­¸ç¿çæ¹æ³åç¼ºä¹æç¢ºçè¿´è·¯éååè½ï¼æéééç®ææ¬é«æçæ¹æ³ä¾å¯¦ä½ãæåæåº AutoLoopï¼éæ¯ä¸ç¨®æ°ç©çæ¹æ³ï¼å®çµåäºèªååçèª²ç¨å­¸ç¿èè¦è¦º SLAM ç³»çµ±çææå¾®èª¿ãæåçæ¹æ³æ¡ç¨ DDPGï¼æ·±åº¦ç¢ºå®æ§ç­ç¥æ¢¯åº¦ï¼ä»£çï¼å¨è¨ç·´éç¨ä¸­åæèª¿æ´è¿´è·¯éåæ¬éï¼æ¶é¤äºäººå·¥è¶åæ¸æå°çéè¦ï¼åæå¤§å¹æ¸å°äºæéçè¨ç·´æ­¥é©ãæ­¤æ¹æ³æé¢ç·é åè¨ç®æ½å¨çè¿´è·¯éåå°ï¼ä¸¦ééä»£çå°åçèª²ç¨ä¾å©ç¨å®åï¼è®æ¨¡åè½å¤ ææå°é©ææ°çå ´æ¯ãå¨ TartanAir ä¸é²è¡çå¯¦é©ï¼ç¨æ¼è¨ç·´ä¸¦é©è­è·¨å¤ååºæºï¼åæ¬ KITTIãEuRoCãICL-NUIM å TUM RGB-Dï¼è­æ AutoLoop éå°ç¸ç¶ææ´ä½³çæè½ï¼åæå°è¨ç·´æéæ¸å°äºä¸åæ¸éç´ï¼èå³çµ±æ¹æ³ç¸æ¯ãAutoLoop æä¾äºä¸åå¯¦ç¨çè§£æ±ºæ¹æ¡ï¼ç¨æ¼å¿«éé©æè¦è¦º SLAM ç³»çµ±ï¼èªååå³çµ±ä¸éè¦å¤æ¬¡äººå·¥åè¦éç®çæ¬éèª¿æ´éç¨ãæåççµæè¡¨æï¼éç¨®èªååçèª²ç¨ç­ç¥ä¸åå éäºè¨ç·´ï¼éç¶­æææ¹åäºæ¨¡åå¨åç¨®ç°å¢æ¢ä»¶ä¸çæè½ã

##### **Benchmarking Robustness of Contrastive Learning Models for Medical Image-Report Retrieval**
2501.09134v1 by Demetrio Deanda, Yuktha Priya Masupalli, Jeong Yang, Young Lee, Zechun Cao, Gongbo Liang

Medical images and reports offer invaluable insights into patient health. The
heterogeneity and complexity of these data hinder effective analysis. To bridge
this gap, we investigate contrastive learning models for cross-domain
retrieval, which associates medical images with their corresponding clinical
reports. This study benchmarks the robustness of four state-of-the-art
contrastive learning models: CLIP, CXR-RePaiR, MedCLIP, and CXR-CLIP. We
introduce an occlusion retrieval task to evaluate model performance under
varying levels of image corruption. Our findings reveal that all evaluated
models are highly sensitive to out-of-distribution data, as evidenced by the
proportional decrease in performance with increasing occlusion levels. While
MedCLIP exhibits slightly more robustness, its overall performance remains
significantly behind CXR-CLIP and CXR-RePaiR. CLIP, trained on a
general-purpose dataset, struggles with medical image-report retrieval,
highlighting the importance of domain-specific training data. The evaluation of
this work suggests that more effort needs to be spent on improving the
robustness of these models. By addressing these limitations, we can develop
more reliable cross-domain retrieval models for medical applications.

æè¦ï¼é«çå½±ååå ±åæä¾å¯¶è²´çè¦è§£ï¼æ·±å¥äºè§£æ£èå¥åº·ãéäºæ¸æçç°è³ªæ§åè¤éæ§é»ç¤äºææçåæãçºäºå½è£éåå·®è·ï¼æåç ç©¶å°æ¯å­¸ç¿æ¨¡åé²è¡è·¨é åæª¢ç´¢ï¼å°é«å­¸å½±åèå¶å°æçè¨åºå ±åè¯ç¹«èµ·ä¾ãæ¬ç ç©¶å°åç¨®æåé²çå°æ¯å­¸ç¿æ¨¡åçå¥å£¯æ§é²è¡äºåºæºæ¸¬è©¦ï¼CLIPãCXR-RePaiRãMedCLIP å CXR-CLIPãæåå¼å¥é®ææª¢ç´¢ä»»åï¼ä»¥è©ä¼°æ¨¡åå¨ä¸åç¨åº¦çå½±åæå£ä¸çæ§è½ãæåçç ç©¶çµæè¡¨æï¼ææè©ä¼°çæ¨¡åå°åä½å¤æ¸æé½é«åº¦ææï¼éå¾é¨èé®æç¨åº¦çå¢å èå°è´çæ§è½ææ¯ä¾ä¸éå°±å¯ä»¥è­æãéç¶ MedCLIP è¡¨ç¾åºç¨é«çå¥å£¯æ§ï¼ä½å¶æ´é«æ§è½ä»é é è½å¾æ¼ CXR-CLIP å CXR-RePaiRãCLIP å¨éç¨æ¸æéä¸é²è¡è¨ç·´ï¼å¨é«å­¸å½±åå ±åæª¢ç´¢ä¸­éå°å°é£ï¼çªé¡¯äºç¹å®é åè¨ç·´æ¸æçéè¦æ§ãéé å·¥ä½çè©ä¼°è¡¨æï¼éè¦è±è²»æ´å¤ç²¾åä¾æé«éäºæ¨¡åçå¥å£¯æ§ãééè§£æ±ºéäºéå¶ï¼æåå¯ä»¥çºé«çæç¨éç¼æ´å¯é çè·¨é åæª¢ç´¢æ¨¡åã

##### **Generative Medical Image Anonymization Based on Latent Code Projection and Optimization**
2501.09114v1 by Huiyu Li, Nicholas Ayache, HervÃ© Delingette

Medical image anonymization aims to protect patient privacy by removing
identifying information, while preserving the data utility to solve downstream
tasks. In this paper, we address the medical image anonymization problem with a
two-stage solution: latent code projection and optimization. In the projection
stage, we design a streamlined encoder to project input images into a latent
space and propose a co-training scheme to enhance the projection process. In
the optimization stage, we refine the latent code using two deep loss functions
designed to address the trade-off between identity protection and data utility
dedicated to medical images. Through a comprehensive set of qualitative and
quantitative experiments, we showcase the effectiveness of our approach on the
MIMIC-CXR chest X-ray dataset by generating anonymized synthetic images that
can serve as training set for detecting lung pathologies. Source codes are
available at https://github.com/Huiyu-Li/GMIA.

æè¦ï¼é«å­¸å½±åå¿ååæ¨å¨ééç§»é¤è­å¥è³è¨ä¾ä¿è­·çæ£é±ç§ï¼åæä¿çè³ææç¨ä»¥è§£æ±ºä¸æ¸¸ä»»åãå¨æ¬æä¸­ï¼æåééå©éæ®µè§£æ±ºæ¹æ¡ä¾è§£æ±ºé«å­¸å½±åå¿åååé¡ï¼æ½å¨ç¢¼æå½±åæä½³åãå¨æå½±éæ®µï¼æåè¨­è¨ä¸åç°¡åçç·¨ç¢¼å¨ï¼å°è¼¸å¥å½±åæå½±å°æ½å¨ç©ºéï¼ä¸¦æåºä¸åå±åè¨ç·´æ¶æ§ä¾æåæå½±ç¨åºãå¨æä½³åéæ®µï¼æåä½¿ç¨å©åæ·±åº¦æå¤±å½æ¸ä¾èª¿æ´æ½å¨ç¢¼ï¼éäºå½æ¸æ¨å¨è§£æ±ºèº«åä¿è­·èå°éç¨æ¼é«å­¸å½±åçè³ææç¨ä¹éçæ¬è¡¡ãééä¸çµå¨é¢çå®æ§åå®éå¯¦é©ï¼æåå±ç¤ºäºæåæ¹æ³å¨ MIMIC-CXR è¸é¨ X åå½±åè³æéä¸çæææ§ï¼æ¹æ³æ¯ç¢çå¯ä½çºè¨ç·´éä¾åµæ¸¬èºé¨çççå¿ååæå½±åãåå§ç¢¼å¯æ¼ https://github.com/Huiyu-Li/GMIA åå¾ã

##### **Development and Validation of the Provider Documentation Summarization Quality Instrument for Large Language Models**
2501.08977v2 by Emma Croxford, Yanjun Gao, Nicholas Pellegrino, Karen K. Wong, Graham Wills, Elliot First, Miranda Schnier, Kyle Burton, Cris G. Ebby, Jillian Gorskic, Matthew Kalscheur, Samy Khalil, Marie Pisani, Tyler Rubeor, Peter Stetson, Frank Liao, Cherodeep Goswami, Brian Patterson, Majid Afshar

As Large Language Models (LLMs) are integrated into electronic health record
(EHR) workflows, validated instruments are essential to evaluate their
performance before implementation. Existing instruments for provider
documentation quality are often unsuitable for the complexities of
LLM-generated text and lack validation on real-world data. The Provider
Documentation Summarization Quality Instrument (PDSQI-9) was developed to
evaluate LLM-generated clinical summaries. Multi-document summaries were
generated from real-world EHR data across multiple specialties using several
LLMs (GPT-4o, Mixtral 8x7b, and Llama 3-8b). Validation included Pearson
correlation for substantive validity, factor analysis and Cronbach's alpha for
structural validity, inter-rater reliability (ICC and Krippendorff's alpha) for
generalizability, a semi-Delphi process for content validity, and comparisons
of high-versus low-quality summaries for discriminant validity. Seven physician
raters evaluated 779 summaries and answered 8,329 questions, achieving over 80%
power for inter-rater reliability. The PDSQI-9 demonstrated strong internal
consistency (Cronbach's alpha = 0.879; 95% CI: 0.867-0.891) and high
inter-rater reliability (ICC = 0.867; 95% CI: 0.867-0.868), supporting
structural validity and generalizability. Factor analysis identified a 4-factor
model explaining 58% of the variance, representing organization, clarity,
accuracy, and utility. Substantive validity was supported by correlations
between note length and scores for Succinct (rho = -0.200, p = 0.029) and
Organized ($\rho = -0.190$, $p = 0.037$). Discriminant validity distinguished
high- from low-quality summaries ($p < 0.001$). The PDSQI-9 demonstrates robust
construct validity, supporting its use in clinical practice to evaluate
LLM-generated summaries and facilitate safer integration of LLMs into
healthcare workflows.

æè¦ï¼<paragraph>é¨èå¤§åèªè¨æ¨¡å (LLM) æ´åå°é»å­çæ­·
(EHR) å·¥ä½æµç¨ä¸­ï¼å¨å¯¦æ½ä¹åï¼ç¶éé©è­çåå¨å°æ¼è©ä¼°å¶
æè½è³ééè¦ãç¾æçæä¾èæä»¶åè³ªåå¨éå¸¸ä¸é©å
LLM çæçæå­çè¤éæ§ï¼ä¸ç¼ºä¹å°çå¯¦ä¸çè³æçé©è­ãæä¾è
æä»¶æè¦åè³ªåå¨ (PDSQI-9) æ¯çºäºè©ä¼° LLM çæçè¨åºæè¦è
éç¼çãä½¿ç¨å¤å LLMï¼GPT-4oãMixtral 8x7b å Llama 3-8bï¼ï¼
å¾è·¨å¤åå°ç§ççå¯¦ä¸ç EHR è³æä¸­ç¢çäºå¤æä»¶æè¦ãé©è­åæ¬
ç®ç¾æ£®ç¸éæ§ï¼å¯¦è³ªæåº¦ï¼ãå å­åæååæå·´èµ« Î±ï¼çµæ§æåº¦ï¼ã
è©åèéä¿¡åº¦ï¼ICC å Krippendorff Î±ï¼ï¼æ¦åæ§ï¼ãå§å®¹æåº¦çåå¾·ç¾
è²ç¨åºï¼ä»¥åæ¯è¼é«åè³ªåä½åè³ªæè¦ï¼å¤å¥æåº¦ï¼ãä¸ä½é«å¸«
è©åèè©ä¼°äº 779 ä»½æè¦ä¸¦åç­äº 8,329 ååé¡ï¼è©åèéä¿¡åº¦é
å°äº 80% ä»¥ä¸ãPDSQI-9 è¡¨ç¾åºå¼·å¤§çå§é¨ä¸è´æ§ï¼åæå·´èµ« Î± =
0.879ï¼95% CIï¼0.867-0.891ï¼åé«è©åèéä¿¡åº¦ï¼ICC = 0.867ï¼95%
CIï¼0.867-0.868ï¼ï¼æ¯æçµæ§æåº¦åæ¦åæ§ãå å­åæè­å¥åºä¸å
4 å å­æ¨¡åï¼è§£éäº 58% çè®ç°ï¼ä»£è¡¨çµç¹ãæ¸æ°åº¦ãæºç¢ºæ§åå¯¦ç¨
æ§ãå¯¦è³ªæåº¦åå°åå¿éé·åº¦èç°¡æ½ï¼rho = -0.200ï¼p = 0.029ï¼å
æ¢çï¼$\rho = -0.190$ï¼$p = 0.037$ï¼çåæ¸ä¹éç¸éæ§çæ¯æãå¤å¥
æåº¦ååäºé«åè³ªåä½åè³ªæè¦ï¼$p < 0.001$ï¼ãPDSQI-9 å±ç¤ºäºå¼·å¥
çå»ºæ§æåº¦ï¼æ¯æå¨è¨åºå¯¦åä¸­ä½¿ç¨å®ä¾è©ä¼° LLM çæçæè¦ï¼ä¸¦
ä¿é² LLM æ´å®å¨çæ´åå°é«çä¿å¥å·¥ä½æµç¨ä¸­ã</paragraph>

##### **An analysis of data variation and bias in image-based dermatological datasets for machine learning classification**
2501.08962v1 by Francisco Mauro, Emanoel Thyago, Othon Vinicius, Rodrigo Abreu, Kelvin Cunha, JosÃ© Gabriel, Rafael Barros, Thales Bezerra, Manoel Henriques, Natalia Lopes, Ãrico Moutinho, JÃ©ssica Guido, Tsang Ing Ren, Paulo Borba

AI algorithms have become valuable in aiding professionals in healthcare. The
increasing confidence obtained by these models is helpful in critical decision
demands. In clinical dermatology, classification models can detect malignant
lesions on patients' skin using only RGB images as input. However, most
learning-based methods employ data acquired from dermoscopic datasets on
training, which are large and validated by a gold standard. Clinical models aim
to deal with classification on users' smartphone cameras that do not contain
the corresponding resolution provided by dermoscopy. Also, clinical
applications bring new challenges. It can contain captures from uncontrolled
environments, skin tone variations, viewpoint changes, noises in data and
labels, and unbalanced classes. A possible alternative would be to use transfer
learning to deal with the clinical images. However, as the number of samples is
low, it can cause degradations on the model's performance; the source
distribution used in training differs from the test set. This work aims to
evaluate the gap between dermoscopic and clinical samples and understand how
the dataset variations impact training. It assesses the main differences
between distributions that disturb the model's prediction. Finally, from
experiments on different architectures, we argue how to combine the data from
divergent distributions, decreasing the impact on the model's final accuracy.

æè¦ï¼AI æ¼ç®æ³å·²æçºåå©é«çä¿å¥å°æ¥­äººå¡çå¯¶è²´å·¥å·ãéäºæ¨¡åç²å¾çä¿¡å¿æ¥çæåï¼æå©æ¼ééµæ±ºç­éæ±ãå¨è¨åºç®èç§ï¼åé¡æ¨¡ååä½¿ç¨ RGB å½±åä½çºè¼¸å¥ï¼å³å¯åµæ¸¬æ£èç®èä¸çæ¡æ§çç¶ãç¶èï¼å¤§å¤æ¸åºæ¼å­¸ç¿çæ¹æ³æ¡ç¨å¾ç®èé¡è³æéåå¾çè³æé²è¡è¨ç·´ï¼éäºè³æéé¾å¤§ä¸å·²éééæ¨æºé©è­ãè¨åºæ¨¡åæ¨å¨èçä½¿ç¨èæºæ§åææ©ç¸æ©ä¸çåé¡ï¼éäºç¸æ©ä¸åå«ç®èé¡æä¾çå°æè§£æåº¦ãæ­¤å¤ï¼è¨åºæç¨ç¨å¼å¸¶ä¾æ°çææ°ãå®å¯è½åå«ä¾èªä¸åæ§ç°å¢çæ·åãèè²è®åãè¦é»è®æ´ãè³æåæ¨ç±¤ä¸­çéè¨ï¼ä»¥åä¸å¹³è¡¡çé¡å¥ãä¸ç¨®å¯è½çæ¿ä»£æ¹æ¡æ¯ä½¿ç¨é·ç§»å­¸ç¿ä¾èçè¨åºå½±åãç¶èï¼ç±æ¼æ¨£æ¬æ¸éå°ï¼å¯è½æå°è´æ¨¡åæè½ä¸éï¼è¨ç·´ä¸­ä½¿ç¨çä¾æºåä½èæ¸¬è©¦éä¸åãéé å·¥ä½æ¨å¨è©ä¼°ç®èé¡åè¨åºæ¨£æ¬ä¹éçå·®è·ï¼ä¸¦äºè§£è³æéè®åå¦ä½å½±é¿è¨ç·´ãå®è©ä¼°æå¹²æ¾æ¨¡åé æ¸¬çä¸»è¦åä½å·®ç°ãæå¾ï¼å¾ä¸åæ¶æ§çå¯¦é©ä¸­ï¼æåè«è­å¦ä½çµåä¾èªä¸ååä½çè³æï¼éä½å°æ¨¡åæçµæºç¢ºåº¦çå½±é¿ã

##### **Improving the Efficiency of Self-Supervised Adversarial Training through Latent Clustering-Based Selection**
2501.10466v1 by Somrita Ghosh, Yuelin Xu, Xiao Zhang

Compared with standard learning, adversarially robust learning is widely
recognized to demand significantly more training examples. Recent works propose
the use of self-supervised adversarial training (SSAT) with external or
synthetically generated unlabeled data to enhance model robustness. However,
SSAT requires a substantial amount of extra unlabeled data, significantly
increasing memory usage and model training times. To address these challenges,
we propose novel methods to strategically select a small subset of unlabeled
data essential for SSAT and robustness improvement. Our selection prioritizes
data points near the model's decision boundary based on latent clustering-based
techniques, efficiently identifying a critical subset of unlabeled data with a
higher concentration of boundary-adjacent points. While focusing on
near-boundary data, our methods are designed to maintain a balanced ratio
between boundary and non-boundary data points to avoid overfitting. Our
experiments on image benchmarks show that integrating our selection strategies
into self-supervised adversarial training can largely reduce memory and
computational requirements while achieving high model robustness. In
particular, our latent clustering-based selection method with k-means is the
most effective, achieving nearly identical test-time robust accuracies with 5
to 10 times less external or generated unlabeled data when applied to image
benchmarks. Additionally, we validate the generalizability of our approach
across various application scenarios, including a real-world medical dataset
for COVID-19 chest X-ray classification.

æè¦ï¼èæ¨æºå­¸ç¿ç¸æ¯ï¼å°ææ§ç©©å¥å­¸ç¿å»£æ³è¢«èªçºéè¦æ´å¤è¨ç·´ç¯ä¾ãè¿æç ç©¶æåºä½¿ç¨å·æå¤é¨æåæç¢çæ¨ç±¤è³æçèªç£ç£å°æè¨ç·´ (SSAT) ä¾å¢å¼·æ¨¡åç©©å¥æ§ãç¶èï¼SSAT éè¦å¤§éçé¡å¤æªæ¨ç±¤è³æï¼é¡¯èå¢å è¨æ¶é«ä½¿ç¨éåæ¨¡åè¨ç·´æéãçºäºæå°éäºææ°ï¼æåæåºæ°ç©çæ¹æ³ä¾ç­ç¥æ§å°é¸æä¸å°é¨åæªæ¨ç±¤è³æï¼éå° SSAT åç©©å¥æ§æ¹é²è³ééè¦ãæåçé¸æåºæ¼æ½å¨ç¾¤éæè¡ï¼åªåèæ®æ¨¡åæ±ºç­éçéè¿çè³æé»ï¼ææå°è­å¥åºä¸çµééµçæªæ¨ç±¤è³æå­éï¼å¶ä¸­åå«è¼é«æ¿åº¦çéçç¸é°é»ãéç¶å°æ³¨æ¼è¿éçè³æï¼ä½æåçæ¨¡åæ¨å¨ä¿æéçåééçè³æé»ä¹éçå¹³è¡¡æ¯çï¼ä»¥é¿åéåº¦æ¬åãæåå¨å½±ååºæºä¸çå¯¦é©è¡¨æï¼å°æåçé¸æç­ç¥æ´åå°èªç£ç£å°æè¨ç·´ä¸­ï¼å¯ä»¥å¨å¯¦ç¾é«æ¨¡åç©©å¥æ§çåæï¼å¤§å¹æ¸å°è¨æ¶é«åè¨ç®éæ±ãç¹å¥æ¯ï¼æååºæ¼ k å¹³åå¼çæ½å¨ç¾¤éé¸ææ¹æ³æææï¼å¨æç¨æ¼å½±ååºæºæï¼ä»¥å° 5 å° 10 åçå¤é¨æçææªæ¨ç±¤è³æï¼éå°å¹¾ä¹ç¸åçæ¸¬è©¦æéç©©å¥æºç¢ºåº¦ãæ­¤å¤ï¼æåé©è­äºæåçæ¹æ³å¨åç¨®æç¨å ´æ¯ä¸­çéç¨æ§ï¼åæ¬ç¨æ¼ COVID-19 è¸é¨ X ååé¡ççå¯¦ä¸çé«çè³æéã

##### **Digital Phenotyping for Adolescent Mental Health: A Feasibility Study Employing Machine Learning to Predict Mental Health Risk From Active and Passive Smartphone Data**
2501.08851v1 by Balasundaram Kadirvelu, Teresa Bellido Bel, Aglaia Freccero, Martina Di Simplicio, Dasha Nicholls, A Aldo Faisal

Background: Adolescents are particularly vulnerable to mental disorders, with
over 75% of cases manifesting before the age of 25. Research indicates that
only 18 to 34% of young people experiencing high levels of depression or
anxiety symptoms seek support. Digital tools leveraging smartphones offer
scalable and early intervention opportunities. Objective: Using a novel machine
learning framework, this study evaluated the feasibility of integrating active
and passive smartphone data to predict mental disorders in non-clinical
adolescents. Specifically, we investigated the utility of the Mindcraft app in
predicting risks for internalising and externalising disorders, eating
disorders, insomnia and suicidal ideation. Methods: Participants (N=103; mean
age 16.1 years) were recruited from three London schools. Participants
completed the Strengths and Difficulties Questionnaire, the Eating Disorders-15
Questionnaire, Sleep Condition Indicator Questionnaire and indicated the
presence/absence of suicidal ideation. They used the Mindcraft app for 14 days,
contributing active data via self-reports and passive data from smartphone
sensors. A contrastive pretraining phase was applied to enhance user-specific
feature stability, followed by supervised fine-tuning. The model evaluation
employed leave-one-subject-out cross-validation using balanced accuracy as the
primary metric. Results: The integration of active and passive data achieved
superior performance compared to individual data sources, with mean balanced
accuracies of 0.71 for SDQ-High risk, 0.67 for insomnia, 0.77 for suicidal
ideation and 0.70 for eating disorders. The contrastive learning framework
stabilised daily behavioural representations, enhancing predictive robustness.
This study demonstrates the potential of integrating active and passive
smartphone data with advanced machine-learning techniques for predicting mental
health risks.

æè¦ï¼<paragraph>èæ¯ï¼éå°å¹´ç¹å«å®¹æç½¹æ£ç²¾ç¥ç¾çï¼75% ä»¥ä¸ççä¾å¨ 25 å²ä¹åæ¾ç°ãç ç©¶è¡¨æï¼åªæ 18% å° 34% ç»åé«åº¦æéæç¦èçç¶çå¹´è½»äººå¯»æ±æ¯æãå©ç¨æºè½ææºçæ°ä½å·¥å·æä¾å¯æ©å±çæ©æä»å¥æºä¼ãç®æ ï¼æ¬ç ç©¶ä½¿ç¨æ°é¢çæºå¨å­¦ä¹ æ¡æ¶ï¼è¯ä¼°å°ä¸»å¨åè¢«å¨æºè½ææºæ°æ®æ´åæ¥é¢æµéä¸´åºéå°å¹´ç²¾ç¥ç¾ççå¯è¡æ§ãå·ä½æ¥è¯´ï¼æä»¬è°æ¥äº Mindcraft åºç¨ç¨åºå¨é¢æµåååå¤åéç¢ãé¥®é£å¤±è°ãå¤±ç åèªææå¿µæ¹é¢çæç¨ãæ¹æ³ï¼åä¸èï¼N=103ï¼å¹³åå¹´é¾ 16.1 å²ï¼æ¥èªä¼¦æ¦çä¸æå­¦æ ¡ãåä¸èå®æäºä¼å¿åå°é¾é®å·ãè¿é£éç¢-15 é®å·ãç¡ç ç¶åµææ é®å·ï¼å¹¶æåºäºæ¯å¦å­å¨èªææå¿µãä»ä»¬ä½¿ç¨ Mindcraft åºç¨ç¨åº 14 å¤©ï¼éè¿èªææ¥åæä¾ä¸»å¨æ°æ®ï¼å¹¶ä»æºè½ææºä¼ æå¨æä¾è¢«å¨æ°æ®ãåºç¨å¯¹æ¯é¢è®­ç»é¶æ®µæ¥å¢å¼ºç¹å®ç¨æ·çç¹å¾ç¨³å®æ§ï¼ç¶åè¿è¡çç£å¾®è°ãæ¨¡åè¯ä¼°éç¨çä¸æ³äº¤åéªè¯ï¼ä½¿ç¨å¹³è¡¡åç¡®åº¦ä½ä¸ºä¸»è¦ææ ãç»æï¼ä¸ä¸ªå«æ°æ®æºç¸æ¯ï¼ä¸»å¨åè¢«å¨æ°æ®çæ´åå®ç°äºæ´å¥½çæ§è½ï¼SDQ é«é£é©çå¹³åå¹³è¡¡åç¡®åº¦ä¸º 0.71ï¼å¤±ç ä¸º 0.67ï¼èªææå¿µä¸º 0.77ï¼é¥®é£å¤±è°ä¸º 0.70ãå¯¹æ¯å­¦ä¹ æ¡æ¶ç¨³å®äºæ¯æ¥è¡ä¸ºè¡¨å¾ï¼å¢å¼ºäºé¢æµé²æ£æ§ãæ¬ç ç©¶å±ç¤ºäºå°ä¸»å¨åè¢«å¨æºè½ææºæ°æ®ä¸åè¿æºå¨å­¦ä¹ ææ¯ç¸ç»åä»¥é¢æµå¿çå¥åº·é£é©çæ½åã</paragraph>

##### **Spatio-Temporal Foundation Models: Vision, Challenges, and Opportunities**
2501.09045v1 by Adam Goodge, Wee Siong Ng, Bryan Hooi, See Kiong Ng

Foundation models have revolutionized artificial intelligence, setting new
benchmarks in performance and enabling transformative capabilities across a
wide range of vision and language tasks. However, despite the prevalence of
spatio-temporal data in critical domains such as transportation, public health,
and environmental monitoring, spatio-temporal foundation models (STFMs) have
not yet achieved comparable success. In this paper, we articulate a vision for
the future of STFMs, outlining their essential characteristics and the
generalization capabilities necessary for broad applicability. We critically
assess the current state of research, identifying gaps relative to these ideal
traits, and highlight key challenges that impede their progress. Finally, we
explore potential opportunities and directions to advance research towards the
aim of effective and broadly applicable STFMs.

æè¦ï¼åºç¤æ¨¡åå¾¹åºæ¹è®äºäººå·¥æºæ§ï¼å¨æè½ä¸æ¨¹ç«æ°çåºæºï¼ä¸¦å¨å»£æ³çè¦è¦ºåèªè¨ä»»åä¸­å¯¦ç¾è½åè½åãç¶èï¼åç®¡æç©ºè³ææ®éå­å¨æ¼éè¼¸ãå¬å±è¡çåç°å¢ç£æ§ç­ééµé åï¼ä½æç©ºåºç¤æ¨¡å (STFM) å°æªåå¾åç­æå°±ãå¨æ¬æä¸­ï¼æåé¡è¿°äºå° STFM æªä¾çé¡æ¯ï¼æ¦è¿°äºå¶åºæ¬ç¹å¾µåå»£æ³é©ç¨çå¿è¦æ¦æ¬è½åãæåæ¹å¤æ§å°è©ä¼°äºç¶åç ç©¶ççæï¼æ¾åºç¸å°æ¼éäºçæ³ç¹è³ªçå·®è·ï¼ä¸¦å¼·èª¿é»ç¤å¶é²å±çééµææ°ãæå¾ï¼æåæ¢è¨äºæ¨é²ç ç©¶çæ½å¨æ©æåæ¹åï¼ä»¥å¯¦ç¾ææä¸å»£æ³é©ç¨ç STFMã

##### **ADAM-1: AI and Bioinformatics for Alzheimer's Detection and Microbiome-Clinical Data Integrations**
2501.08324v1 by Ziyuan Huang, Vishaldeep Kaur Sekhon, Ouyang Guo, Mark Newman, Roozbeh Sadeghian, Maria L. Vaida, Cynthia Jo, Doyle Ward, Vanni Bucci, John P. Haran

The Alzheimer's Disease Analysis Model Generation 1 (ADAM) is a multi-agent
large language model (LLM) framework designed to integrate and analyze
multi-modal data, including microbiome profiles, clinical datasets, and
external knowledge bases, to enhance the understanding and detection of
Alzheimer's disease (AD). By leveraging retrieval-augmented generation (RAG)
techniques along with its multi-agent architecture, ADAM-1 synthesizes insights
from diverse data sources and contextualizes findings using literature-driven
evidence. Comparative evaluation against XGBoost revealed similar mean F1
scores but significantly reduced variance for ADAM-1, highlighting its
robustness and consistency, particularly in small laboratory datasets. While
currently tailored for binary classification tasks, future iterations aim to
incorporate additional data modalities, such as neuroimaging and biomarkers, to
broaden the scalability and applicability for Alzheimer's research and
diagnostics.

æè¦ï¼é¿è²æµ·é»çåææ¨¡åçæ 1 (ADAM) æ¯ä¸åå¤ä»£çå¤§åèªè¨æ¨¡å (LLM) æ¶æ§ï¼æ¨å¨æ´åååæå¤æ¨¡å¼æ¸æï¼åæ¬å¾®çç©çµç¹å¾µãè¨åºæ¸æéåå¤é¨ç¥è­åº«ï¼ä»¥å¢é²å°é¿è²æµ·é»ç (AD) ççè§£ååµæ¸¬ãééå©ç¨æ·åå¢å¼·çæ (RAG) æè¡ä»¥åå¶å¤ä»£çæ¶æ§ï¼ADAM-1 å¾ä¸åçæ¸æä¾æºä¸­ç¶åè¦è§£ï¼ä¸¦ä½¿ç¨æç»é©åçè­æå°ç¼ç¾é²è¡æå¢åãè XGBoost çæ¯è¼è©ä¼°é¡¯ç¤ºé¡ä¼¼çå¹³å F1 åæ¸ï¼ä½ ADAM-1 çè®ç°é¡¯èéä½ï¼çªé¡¯å¶ç©©å¥æ§åä¸è´æ§ï¼ç¹å¥æ¯å¨å°åå¯¦é©å®¤æ¸æéä¸­ãéç¶ç®åéå°äºååé¡ä»»åé²è¡èª¿æ´ï¼ä½æªä¾çè¿­ä»£æ¨å¨ç´å¥å¶ä»æ¸ææ¨¡å¼ï¼ä¾å¦ç¥ç¶å½±ååçç©æ¨è¨ï¼ä»¥æ´å¤§é¿è²æµ·é»çç ç©¶åè¨ºæ·çå¯æ´åæ§åé©ç¨æ§ã

##### **A Feature-Level Ensemble Model for COVID-19 Identification in CXR Images using Choquet Integral and Differential Evolution Optimization**
2501.08241v1 by Amir Reza Takhsha, Maryam Rastgarpour, Mozhgan Naderi

The COVID-19 pandemic has profoundly impacted billions globally. It
challenges public health and healthcare systems due to its rapid spread and
severe respiratory effects. An effective strategy to mitigate the COVID-19
pandemic involves integrating testing to identify infected individuals. While
RT-PCR is considered the gold standard for diagnosing COVID-19, it has some
limitations such as the risk of false negatives. To address this problem, this
paper introduces a novel Deep Learning Diagnosis System that integrates
pre-trained Deep Convolutional Neural Networks (DCNNs) within an ensemble
learning framework to achieve precise identification of COVID-19 cases from
Chest X-ray (CXR) images. We combine feature vectors from the final hidden
layers of pre-trained DCNNs using the Choquet integral to capture interactions
between different DCNNs that a linear approach cannot. We employed
Sugeno-$\lambda$ measure theory to derive fuzzy measures for subsets of
networks to enable aggregation. We utilized Differential Evolution to estimate
fuzzy densities. We developed a TensorFlow-based layer for Choquet operation to
facilitate efficient aggregation, due to the intricacies involved in
aggregating feature vectors. Experimental results on the COVIDx dataset show
that our ensemble model achieved 98\% accuracy in three-class classification
and 99.50\% in binary classification, outperforming its components-DenseNet-201
(97\% for three-class, 98.75\% for binary), Inception-v3 (96.25\% for
three-class, 98.50\% for binary), and Xception (94.50\% for three-class, 98\%
for binary)-and surpassing many previous methods.

æè¦ï¼æ°å èºçç«æå·²å¯¹å¨çæ°åäº¿äººäº§çæ·±è¿å½±åãç±äºå¶ä¼ æ­è¿éä¸å¼å¸éçç¶ä¸¥éï¼å®å¯¹å¬å±å«çåå»çä¿å¥ç³»ç»ææææãåè½»æ°å èºçç«æçææç­ç¥åæ¬æ´åæ£æµä»¥è¯å«åææèãè½ç¶ RT-PCR è¢«è®¤ä¸ºæ¯è¯æ­æ°å èºççé»éæ åï¼ä½å®ä¹æä¸äºéå¶ï¼ä¾å¦åé´æ§çé£é©ãä¸ºäºè§£å³è¿ä¸ªé®é¢ï¼æ¬æä»ç»äºä¸ç§æ°é¢çæ·±åº¦å­¦ä¹ è¯æ­ç³»ç»ï¼è¯¥ç³»ç»å°é¢è®­ç»çæ·±åº¦å·ç§¯ç¥ç»ç½ç» (DCNN) éæå°éæå­¦ä¹ æ¡æ¶ä¸­ï¼ä»¥ä»è¸é¨ X å°çº¿ (CXR) å¾åä¸­ç²¾ç¡®è¯å«æ°å èºççä¾ãæä»¬ä½¿ç¨ Choquet ç§¯åç»åæ¥èªé¢è®­ç» DCNN çæåä¸ä¸ªéèå±çç¹å¾åéï¼ä»¥æè·çº¿æ§æ¹æ³æ æ³å®ç°çä¸å DCNN ä¹é´çäº¤äºãæä»¬éç¨ Sugeno-$\lambda$ æµåº¦çè®ºæ¥å¯¼åºç½ç»å­éçæ¨¡ç³æµåº¦ä»¥å®ç°èåãæä»¬å©ç¨å·®åè¿åæ¥ä¼°è®¡æ¨¡ç³å¯åº¦ãç±äºèåç¹å¾åéçå¤ææ§ï¼æä»¬å¼åäºä¸ä¸ªåºäº TensorFlow ç Choquet æä½å±ä»¥ä¿è¿é«æèåãCOVIDx æ°æ®éä¸çå®éªç»æè¡¨æï¼æä»¬çéææ¨¡åå¨ä¸ç±»åç±»ä¸­è¾¾å° 98% çåç¡®çï¼å¨äºååç±»ä¸­è¾¾å° 99.50%ï¼ä¼äºå¶ç»ä»¶ DenseNet-201ï¼ä¸ç±»ä¸º 97%ï¼äºåä¸º 98.75%ï¼ãInception-v3ï¼ä¸ç±»ä¸º 96.25%ï¼äºåä¸º 98.50%ï¼å Xceptionï¼ä¸ç±»ä¸º 94.50%ï¼äºåä¸º 98%ï¼ï¼å¹¶è¶è¶äºè®¸å¤ä»¥åçæ¹æ³ã

##### **ASTRID -- An Automated and Scalable TRIaD for the Evaluation of RAG-based Clinical Question Answering Systems**
2501.08208v1 by Mohita Chowdhury, Yajie Vera He, Aisling Higham, Ernest Lim

Large Language Models (LLMs) have shown impressive potential in clinical
question answering (QA), with Retrieval Augmented Generation (RAG) emerging as
a leading approach for ensuring the factual accuracy of model responses.
However, current automated RAG metrics perform poorly in clinical and
conversational use cases. Using clinical human evaluations of responses is
expensive, unscalable, and not conducive to the continuous iterative
development of RAG systems. To address these challenges, we introduce ASTRID -
an Automated and Scalable TRIaD for evaluating clinical QA systems leveraging
RAG - consisting of three metrics: Context Relevance (CR), Refusal Accuracy
(RA), and Conversational Faithfulness (CF). Our novel evaluation metric, CF, is
designed to better capture the faithfulness of a model's response to the
knowledge base without penalising conversational elements. To validate our
triad, we curate a dataset of over 200 real-world patient questions posed to an
LLM-based QA agent during surgical follow-up for cataract surgery - the highest
volume operation in the world - augmented with clinician-selected questions for
emergency, clinical, and non-clinical out-of-domain scenarios. We demonstrate
that CF can predict human ratings of faithfulness better than existing
definitions for conversational use cases. Furthermore, we show that evaluation
using our triad consisting of CF, RA, and CR exhibits alignment with clinician
assessment for inappropriate, harmful, or unhelpful responses. Finally, using
nine different LLMs, we demonstrate that the three metrics can closely agree
with human evaluations, highlighting the potential of these metrics for use in
LLM-driven automated evaluation pipelines. We also publish the prompts and
datasets for these experiments, providing valuable resources for further
research and development.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å¨è¨åºåç­ (QA) ä¸­å±ç¾äºä»¤äººå°è±¡æ·±å»çæ½åï¼å¶ä¸­æª¢ç´¢å¢å¼·çæ (RAG) æçºç¢ºä¿æ¨¡ååæäºå¯¦æºç¢ºæ§çé åæ¹æ³ãç¶èï¼ç®åçèªåå RAG ææ¨å¨è¨åºåå°è©±å¼ç¨ä¾ä¸­è¡¨ç¾ä¸ä½³ãä½¿ç¨è¨åºäººé¡å°åæçè©ä¼°æ¢æè²´åä¸å·å¯æ´åæ§ï¼ä¹ä¸å©æ¼ RAG ç³»çµ±çæçºè¿­ä»£éç¼ãçºäºæå°éäºææ°ï¼æåå¼å¥äº ASTRID - ä¸ç¨®ç¨æ¼è©ä¼°å©ç¨ RAG çè¨åº QA ç³»çµ±çèªååä¸å¯æ´åç TRIaD - åå«ä¸åææ¨ï¼èçµ¡ç¸éæ§ (CR)ãæçµæºç¢ºæ§ (RA) åå°è©±å¿ å¯¦åº¦ (CF)ãæåæ°ç©çè©ä¼°ææ¨ CF æ¨å¨æ´å¥½å°æææ¨¡åå°ç¥è­åº«çåæçå¿ å¯¦åº¦ï¼åæä¸æ²ç½°å°è©±åç´ ãçºäºé©è­æåçä¸åçµï¼æåç­åäºä¸åæ¸æéï¼å¶ä¸­åå«å¨ç½å§éæè¡è¡å¾é¨è¨ªæéå LLM åºæ¼ QA çä»£çæåºç 200 å¤åçå¯¦ä¸ççæ£èåé¡ - ä¸çä¸æè¡éæå¤§çæè¡ - ä¸¦å¢å äºè¨åºé«çé¸æçåé¡ï¼ç¨æ¼ç·æ¥ãè¨åºåéè¨åºé åå¤æå¢ãæåè­æï¼èå°è©±å¼ç¨ä¾ç¾æå®ç¾©ç¸æ¯ï¼CF å¯ä»¥æ´å¥½å°é æ¸¬äººé¡å°å¿ å¯¦åº¦çè©åãæ­¤å¤ï¼æåè¡¨æä½¿ç¨ç± CFãRA å CR çµæçä¸åçµé²è¡è©ä¼°èè¨åºé«çå°ä¸é©ç¶ãæå®³æç¡ççåæçè©ä¼°ä¿æä¸è´ãæå¾ï¼ä½¿ç¨ä¹ç¨®ä¸åç LLMï¼æåè­æéä¸åææ¨å¯ä»¥èäººé¡è©ä¼°ç·å¯ä¸è´ï¼çªé¡¯äºéäºææ¨å¨ LLM é©åçèªååè©ä¼°ç®¡éä¸­ä½¿ç¨çæ½åãæåéå¬ä½äºéäºå¯¦é©çæç¤ºåæ¸æéï¼çºé²ä¸æ­¥çç ç©¶åéç¼æä¾äºå¯¶è²´çè³æºã

##### **Potential and Perils of Large Language Models as Judges of Unstructured Textual Data**
2501.08167v2 by Rewina Bedemariam, Natalie Perez, Sreyoshi Bhaduri, Satya Kapoor, Alex Gil, Elizabeth Conjar, Ikkei Itoku, David Theil, Aman Chadha, Naumaan Nayyar

Rapid advancements in large language models have unlocked remarkable
capabilities when it comes to processing and summarizing unstructured text
data. This has implications for the analysis of rich, open-ended datasets, such
as survey responses, where LLMs hold the promise of efficiently distilling key
themes and sentiments. However, as organizations increasingly turn to these
powerful AI systems to make sense of textual feedback, a critical question
arises, can we trust LLMs to accurately represent the perspectives contained
within these text based datasets? While LLMs excel at generating human-like
summaries, there is a risk that their outputs may inadvertently diverge from
the true substance of the original responses. Discrepancies between the
LLM-generated outputs and the actual themes present in the data could lead to
flawed decision-making, with far-reaching consequences for organizations. This
research investigates the effectiveness of LLM-as-judge models to evaluate the
thematic alignment of summaries generated by other LLMs. We utilized an
Anthropic Claude model to generate thematic summaries from open-ended survey
responses, with Amazon's Titan Express, Nova Pro, and Meta's Llama serving as
judges. This LLM-as-judge approach was compared to human evaluations using
Cohen's kappa, Spearman's rho, and Krippendorff's alpha, validating a scalable
alternative to traditional human centric evaluation methods. Our findings
reveal that while LLM-as-judge offer a scalable solution comparable to human
raters, humans may still excel at detecting subtle, context-specific nuances.
Our research contributes to the growing body of knowledge on AI assisted text
analysis. Further, we provide recommendations for future research, emphasizing
the need for careful consideration when generalizing LLM-as-judge models across
various contexts and use cases.

æè¦ï¼å¤§åèªè¨æ¨¡åçå¿«éé²æ­¥ï¼å¨èçåç¸½çµéçµæ§åæå­è³ææ¹é¢ï¼è§£éäºéå¡çè½åãéå°è±å¯ãéæ¾å¼è³æéçåææå½±é¿ï¼ä¾å¦èª¿æ¥åæï¼å¶ä¸­ LLM æ¿è«¾ææå°æçåºééµä¸»é¡åæç·ãç¶èï¼é¨èçµç¹è¶ä¾è¶ä¾è³´éäºå¼·å¤§ç AI ç³»çµ±ä¾çè§£æå­åé¥ï¼ä¸åééµåé¡åºç¾äºï¼æåè½ç¸ä¿¡ LLM è½æºç¢ºå°ä»£è¡¨éäºåºæ¼æå­çè³æéæåå«çè§é»åï¼éç¶ LLM å¨çæé¡ä¼¼äººé¡çæè¦æ¹é¢è¡¨ç¾åºè²ï¼ä½å­å¨å¶è¼¸åºå¯è½ç¡æéåé¢åå§åæççå¯¦å§å®¹çé¢¨éªãLLM çæçè¼¸åºèè³æä¸­å­å¨çå¯¦éä¸»é¡ä¹éçå·®ç°å¯è½å°è´æç¼ºé·çæ±ºç­å¶å®ï¼å°çµç¹ç¢çæ·±é å½±é¿ãæ¬ç ç©¶èª¿æ¥äº LLM ä½çºè©å¯©æ¨¡åè©ä¼°å¶ä» LLM çæçæè¦çä¸»é¡å°é½æ§çæææ§ãæåå©ç¨ Anthropic Claude æ¨¡åå¾éæ¾å¼èª¿æ¥åæä¸­çæä¸»é¡æè¦ï¼è Amazon ç Titan ExpressãNova Pro å Meta ç Llama åä½çºè©å¯©ãéç¨® LLM ä½çºè©å¯©çæ¹æ³ä½¿ç¨ Cohen's kappaãSpearman's rho å Krippendorff's alpha èäººé¡è©ä¼°é²è¡æ¯è¼ï¼é©è­äºå³çµ±ä»¥äººé¡çºä¸­å¿çè©ä¼°æ¹æ³çå¯æ´åæ¿ä»£æ¹æ¡ãæåçç ç©¶çµæè¡¨æï¼éç¶ LLM ä½çºè©å¯©æä¾äºèäººé¡è©åèç¸ç¶çå¯æ´åè§£æ±ºæ¹æ¡ï¼ä½äººé¡å¨æª¢æ¸¬å¾®å¦çãç¹å®æ¼ä¸ä¸æçç´°å¾®å·®å¥æ¹é¢ä»ç¶å¯è½è¡¨ç¾åºè²ãæåçç ç©¶æå©æ¼æ´åéæ¼ AI è¼å©æå­åæçç¥è­é«ç³»ãæ­¤å¤ï¼æåæä¾äºå°æªä¾ç ç©¶çå»ºè­°ï¼å¼·èª¿å¨åç¨®èæ¯åä½¿ç¨æ¡ä¾ä¸­æ¦æ¬ LLM ä½çºè©å¯©æ¨¡åæéè¦ä»ç´°èéã

##### **FairTTTS: A Tree Test Time Simulation Method for Fairness-Aware Classification**
2501.08155v1 by Nurit Cohen-Inger, Lior Rokach, Bracha Shapira, Seffi Cohen

Algorithmic decision-making has become deeply ingrained in many domains, yet
biases in machine learning models can still produce discriminatory outcomes,
often harming unprivileged groups. Achieving fair classification is inherently
challenging, requiring a careful balance between predictive performance and
ethical considerations. We present FairTTTS, a novel post-processing bias
mitigation method inspired by the Tree Test Time Simulation (TTTS) method.
Originally developed to enhance accuracy and robustness against adversarial
inputs through probabilistic decision-path adjustments, TTTS serves as the
foundation for FairTTTS. By building on this accuracy-enhancing technique,
FairTTTS mitigates bias and improves predictive performance. FairTTTS uses a
distance-based heuristic to adjust decisions at protected attribute nodes,
ensuring fairness for unprivileged samples. This fairness-oriented adjustment
occurs as a post-processing step, allowing FairTTTS to be applied to
pre-trained models, diverse datasets, and various fairness metrics without
retraining. Extensive evaluation on seven benchmark datasets shows that
FairTTTS outperforms traditional methods in fairness improvement, achieving a
20.96% average increase over the baseline compared to 18.78% for related work,
and further enhances accuracy by 0.55%. In contrast, competing methods
typically reduce accuracy by 0.42%. These results confirm that FairTTTS
effectively promotes more equitable decision-making while simultaneously
improving predictive performance.

æè¦ï¼æ¼ç®æ³æ±ºç­å¶å®å·²æ·±æ¤æ¼è¨±å¤é åä¸­ï¼ç¶èæ©å¨å­¸ç¿æ¨¡åä¸­çåè¦ä»å¯è½ç¢çæ­§è¦æ§ççµæï¼éå¸¸æå·å®³æªåä¿éçç¾¤é«ãéæå¬å¹³åé¡æ¬è³ªä¸å·æææ°æ§ï¼éè¦å¨é æ¸¬æè½èéå¾·èéä¹éåå¾ä»ç´°çå¹³è¡¡ãæåæåº FairTTTSï¼éæ¯ä¸ç¨®æ°ç©çå¾èçåèª¤ç·©è§£æ¹æ³ï¼å¶éæä¾èªæ¨¹æ¸¬è©¦æéæ¨¡æ¬ (TTTS) æ¹æ³ãTTTS æåæ¯çºäºééæ©çæ±ºç­è·¯å¾èª¿æ´ä¾å¢å¼·éå°å°æè¼¸å¥çæºç¢ºåº¦åç©©å¥æ§èéç¼ï¼ä¸¦ä½çº FairTTTS çåºç¤ãééå»ºç«å¨éç¨®å¢å¼·æºç¢ºåº¦çæè¡ä¹ä¸ï¼FairTTTS å¯ä»¥æ¸è¼åèª¤ä¸¦æ¹åé æ¸¬æè½ãFairTTTS ä½¿ç¨åºæ¼è·é¢çåç¼æ³ä¾èª¿æ´åä¿è­·å±¬æ§ç¯é»çæ±ºç­ï¼ç¢ºä¿æªåä¿éæ¨£æ¬çå¬å¹³æ§ãéç¨®ä»¥å¬å¹³æ§çºå°åçèª¿æ´æå¨å¾èçæ­¥é©ä¸­ç¼çï¼åè¨± FairTTTS å¥ç¨è³é åè¨ç·´çæ¨¡åãå¤æ¨£åçè³æéååç¨®å¬å¹³æ§ææ¨ï¼èç¡ééæ°è¨ç·´ãå¨ä¸ååºæºè³æéä¸çå»£æ³è©ä¼°é¡¯ç¤ºï¼FairTTTS å¨å¬å¹³æ§æ¹åæ¹é¢åªæ¼å³çµ±æ¹æ³ï¼èç¸éå·¥ä½ç 18.78% ç¸æ¯ï¼å¹³åæåäº 20.96%ï¼ä¸¦é²ä¸æ­¥å°æºç¢ºåº¦æåäº 0.55%ãç¸åå°ï¼ç«¶ç­æ¹æ³éå¸¸æå°æºç¢ºåº¦éä½ 0.42%ãéäºçµæè­å¯¦ï¼FairTTTS ææå°ä¿é²äºæ´å¬å¹³çæ±ºç­å¶å®ï¼åæä¹æ¹åäºé æ¸¬æè½ã

##### **Guiding the classification of hepatocellular carcinoma on 3D CT-scans using deep and handcrafted radiological features**
2501.08097v1 by E. Sarfati, A. BÃ´ne, M-M. RohÃ©, C. AubÃ©, M. Ronot, P. Gori, I. Bloch

Hepatocellular carcinoma is the most spread primary liver cancer across the
world ($\sim$80\% of the liver tumors). The gold standard for HCC diagnosis is
liver biopsy. However, in the clinical routine, expert radiologists provide a
visual diagnosis by interpreting hepatic CT-scans according to a standardized
protocol, the LI-RADS, which uses five radiological criteria with an associated
decision tree. In this paper, we propose an automatic approach to predict
histology-proven HCC from CT images in order to reduce radiologists'
inter-variability. We first show that standard deep learning methods fail to
accurately predict HCC from CT-scans on a challenging database, and propose a
two-step approach inspired by the LI-RADS system to improve the performance. We
achieve improvements from 6 to 18 points of AUC with respect to deep learning
baselines trained with different architectures. We also provide clinical
validation of our method, achieving results that outperform non-expert
radiologists and are on par with expert ones.

æè¦ï¼èç´°èçæ¯æå¸¸è¦çåç¼æ§èçï¼éå¸å¨çï¼ç´ä½èèè«ç¤ç 80%ï¼ãHCC è¨ºæ·çé»éæ¨æºæ¯èèæ´»æª¢ãç¶èï¼å¨è¨åºå¸¸è¦ä¸­ï¼å°å®¶æ¾å°ç§é«å¸«ææ ¹ææ¨æºååå® LI-RADS ä¾è§£è®èèé»è¦æ·å±¤ææï¼æä¾è¦è¦ºè¨ºæ·ï¼æ­¤åå®ä½¿ç¨äºé æ¾å°å­¸æ¨æºï¼ä¸¦éæç¸éæ±ºç­æ¨¹ãå¨æ¬æä¸­ï¼æåæåºäºä¸ç¨®èªååæ¹æ³ï¼ç¨æ¼å¾é»è¦æ·å±¤å½±åé æ¸¬çµç¹ççå­¸è­å¯¦ç HCCï¼ä»¥æ¸å°æ¾å°ç§é«å¸«çè®ç°æ§ãæåé¦åè¡¨æï¼æ¨æºæ·±åº¦å­¸ç¿æ¹æ³ç¡æ³æºç¢ºå°å¾å·æææ°æ§çè³æåº«ä¸­çé»è¦æ·å±¤ææé æ¸¬ HCCï¼ä¸¦æåºäºä¸åå LI-RADS ç³»çµ±åç¼çå©æ­¥é©æ¹æ³ä¾æ¹åæè½ãç¸è¼æ¼ä½¿ç¨ä¸åæ¶æ§è¨ç·´çæ·±åº¦å­¸ç¿åºæºï¼æåå¨ AUC ä¸­ç²å¾äº 6 å° 18 åé»çé²æ­¥ãæåä¹æä¾äºæåæ¹æ³çè¨åºé©è­ï¼æç²å¾ççµæåªæ¼éå°å®¶æ¾å°ç§é«å¸«ï¼ä¸èå°å®¶ç¸ç¶ã

##### **Exploring visual language models as a powerful tool in the diagnosis of Ewing Sarcoma**
2501.08042v1 by Alvaro Pastor-Naranjo, Pablo Meseguer, RocÃ­o del Amor, Jose Antonio Lopez-Guerrero, Samuel Navarro, Katia Scotlandi, Antonio Llombart-Bosch, Isidro Machado, Valery Naranjo

Ewing's sarcoma (ES), characterized by a high density of small round blue
cells without structural organization, presents a significant health concern,
particularly among adolescents aged 10 to 19. Artificial intelligence-based
systems for automated analysis of histopathological images are promising to
contribute to an accurate diagnosis of ES. In this context, this study explores
the feature extraction ability of different pre-training strategies for
distinguishing ES from other soft tissue or bone sarcomas with similar
morphology in digitized tissue microarrays for the first time, as far as we
know. Vision-language supervision (VLS) is compared to fully-supervised
ImageNet pre-training within a multiple instance learning paradigm. Our
findings indicate a substantial improvement in diagnostic accuracy with the
adaption of VLS using an in-domain dataset. Notably, these models not only
enhance the accuracy of predicted classes but also drastically reduce the
number of trainable parameters and computational costs.

æè¦ï¼å°¤å æ°èç¤ (ES) çç¹å¾æ¯é«å¯åº¦çæ ç»æç»ç»çå°åå½¢èè²ç»èï¼å¯¹å¥åº·ææéå¤§å¨èï¼å°¤å¶æ¯å¨ 10 è³ 19 å²çéå°å¹´ä¸­ãåºäºäººå·¥æºè½çç»ç»ççå­¦å¾åèªå¨åæç³»ç»æææå©äº ES çåç¡®è¯æ­ãå¨æ­¤èæ¯ä¸ï¼æ¬ç ç©¶é¦æ¬¡æ¢è®¨äºä¸åé¢è®­ç»ç­ç¥çç¹å¾æåè½åï¼ä»¥åºå ES ä¸æ°å­åç»ç»å¾®éµåä¸­å½¢æç¸ä¼¼çå¶ä»è½¯ç»ç»æéª¨èç¤ï¼æ®æä»¬æç¥ãè§è§è¯­è¨çç£ (VLS) ä¸å¤å®ä¾å­¦ä¹ èå¼ä¸­çå®å¨çç£ ImageNet é¢è®­ç»è¿è¡äºæ¯è¾ãæä»¬çç ç©¶ç»æè¡¨æï¼ä½¿ç¨ååæ°æ®éè°æ´ VLS å¯å¤§å¹æé«è¯æ­åç¡®æ§ãå¼å¾æ³¨æçæ¯ï¼è¿äºæ¨¡åä¸ä»æé«äºé¢æµç±»å«çåç¡®æ§ï¼è¿å¤§å¹åå°äºå¯è®­ç»åæ°åè®¡ç®ææ¬ã

##### **Comprehensive Metapath-based Heterogeneous Graph Transformer for Gene-Disease Association Prediction**
2501.07970v1 by Wentao Cui, Shoubo Li, Chen Fang, Qingqing Long, Chengrui Wang, Xuezhi Wang, Yuanchun Zhou

Discovering gene-disease associations is crucial for understanding disease
mechanisms, yet identifying these associations remains challenging due to the
time and cost of biological experiments. Computational methods are increasingly
vital for efficient and scalable gene-disease association prediction.
Graph-based learning models, which leverage node features and network
relationships, are commonly employed for biomolecular predictions. However,
existing methods often struggle to effectively integrate node features,
heterogeneous structures, and semantic information. To address these
challenges, we propose COmprehensive MEtapath-based heterogeneous graph
Transformer(COMET) for predicting gene-disease associations. COMET integrates
diverse datasets to construct comprehensive heterogeneous networks,
initializing node features with BioGPT. We define seven Metapaths and utilize a
transformer framework to aggregate Metapath instances, capturing global
contexts and long-distance dependencies. Through intra- and inter-metapath
aggregation using attention mechanisms, COMET fuses latent vectors from
multiple Metapaths to enhance GDA prediction accuracy. Our method demonstrates
superior robustness compared to state-of-the-art approaches. Ablation studies
and visualizations validate COMET's effectiveness, providing valuable insights
for advancing human health research.

æè¦ï¼ç¼ç¾åºå ç¾çéè¯å°æ¼çè§£ç¾çæ©å¶è³ééè¦ï¼ä½ç±æ¼çç©å¯¦é©çæéåææ¬ï¼è­å¥éäºéè¯ä»ç¶å·æææ°æ§ãè¨ç®æ¹æ³å°æ¼é«æä¸å¯æ´åçåºå ç¾çéè¯é æ¸¬è¶ä¾è¶éè¦ãåºæ¼åçå­¸ç¿æ¨¡åå©ç¨ç¯é»ç¹å¾µåç¶²è·¯éä¿ï¼éå¸¸ç¨æ¼çç©åå­é æ¸¬ãç¶èï¼ç¾ææ¹æ³éå¸¸é£ä»¥æææ´åç¯é»ç¹å¾µãç°è³ªçµæ§åèªç¾©è³è¨ãçºäºæå°éäºææ°ï¼æåæåºäºåºæ¼ç¶ååè·¯å¾çç°è³ªåè½æå¨ (COMET)ï¼ç¨æ¼é æ¸¬åºå ç¾çéè¯ãCOMET æ´åäºä¸åçè³æéä¾æ§å»ºå¨é¢çç°è³ªç¶²è·¯ï¼ä½¿ç¨ BioGPT åå§åç¯é»ç¹å¾µãæåå®ç¾©äºä¸ååè·¯å¾ï¼ä¸¦å©ç¨è½æå¨æ¡æ¶ä¾èååè·¯å¾å¯¦ä¾ï¼æ·åå¨å±ä¸ä¸æåé·è·é¢ä¾è³´éä¿ãééä½¿ç¨æ³¨ææ©å¶é²è¡åè·¯å¾å§é¨ååè·¯å¾éèåï¼COMET èåäºä¾èªå¤ååè·¯å¾çæ½å¨åéï¼ä»¥å¢å¼· GDA é æ¸¬æºç¢ºæ§ãèæåé²çæ¹æ³ç¸æ¯ï¼æåçæ¨¡åå±ç¤ºäºåè¶çç©©å¥æ§ãæ¶èç ç©¶åè¦è¦ºåé©è­äº COMET çæææ§ï¼çºæ¨é²äººé¡å¥åº·ç ç©¶æä¾äºæå¹å¼çè¦è§£ã

##### **Advice for Diabetes Self-Management by ChatGPT Models: Challenges and Recommendations**
2501.07931v1 by Waqar Hussain, John Grundy

Given their ability for advanced reasoning, extensive contextual
understanding, and robust question-answering abilities, large language models
have become prominent in healthcare management research. Despite adeptly
handling a broad spectrum of healthcare inquiries, these models face
significant challenges in delivering accurate and practical advice for chronic
conditions such as diabetes. We evaluate the responses of ChatGPT versions 3.5
and 4 to diabetes patient queries, assessing their depth of medical knowledge
and their capacity to deliver personalized, context-specific advice for
diabetes self-management. Our findings reveal discrepancies in accuracy and
embedded biases, emphasizing the models' limitations in providing tailored
advice unless activated by sophisticated prompting techniques. Additionally, we
observe that both models often provide advice without seeking necessary
clarification, a practice that can result in potentially dangerous advice. This
underscores the limited practical effectiveness of these models without human
oversight in clinical settings. To address these issues, we propose a
commonsense evaluation layer for prompt evaluation and incorporating
disease-specific external memory using an advanced Retrieval Augmented
Generation technique. This approach aims to improve information quality and
reduce misinformation risks, contributing to more reliable AI applications in
healthcare settings. Our findings seek to influence the future direction of AI
in healthcare, enhancing both the scope and quality of its integration.

æè¦ï¼ç±æ¼å¤§åèªè¨æ¨¡åå·æåé²æ¨çè½åãå»£æ³çèæ¯çè§£è½ååå¼·å¤§çåé¡åç­è½åï¼å æ­¤å¨é«çä¿å¥ç®¡çç ç©¶ä¸­è®å¾çªåºãåç®¡éäºæ¨¡åè½çç·´å°èçå»£æ³çé«çä¿å¥æ¥è©¢ï¼ä½å¨æä¾æ¢æ§ç¾çï¼ä¾å¦ç³å°¿çï¼çæºç¢ºä¸å¯¦ç¨çå»ºè­°æ¹é¢ï¼éäºæ¨¡åé¢è¨èéå¤§çææ°ãæåè©ä¼°äº ChatGPT çæ¬ 3.5 å 4 å°ç³å°¿çæ£èæ¥è©¢çåæï¼è©ä¼°äºä»åçé«å­¸ç¥è­æ·±åº¦ä»¥åæä¾éå°ç³å°¿çèªæç®¡ççåæ§åãç¹å®æ¼èæ¯çå»ºè­°çè½åãæåçç ç©¶çµææ­ç¤ºäºæºç¢ºæ§åå§åµåå·®çå·®ç°ï¼å¼·èª¿äºéäºæ¨¡åå¨æªç¶è¤éæç¤ºæè¡åç¨ææä¾å®å¶å»ºè­°çå±éæ§ãæ­¤å¤ï¼æåè§å¯å°éå©åæ¨¡åéå¸¸å¨ä¸å°æ±å¿è¦çæ¾æ¸çææ³ä¸æä¾å»ºè­°ï¼éç¨®åæ³å¯è½æå°è´æ½å¨çå±éªå»ºè­°ãéå¸é¡¯äºéäºæ¨¡åå¨æ²æè¨åºç°å¢ä¸­çäººå·¥ç£ç£çææ³ä¸å¯¦ç¨æææ§æéãçºäºè§£æ±ºéäºåé¡ï¼æåæåºäºä¸åå¸¸è­è©ä¼°å±¤ï¼ç¨æ¼æç¤ºè©ä¼°åä½¿ç¨åé²çæª¢ç´¢å¢å¼·çææè¡æ´åç¹å®ç¾ççå¤é¨è¨æ¶é«ãéç¨®æ¹æ³æ¨å¨æé«è³è¨åè³ªä¸¦éä½é¯èª¤è³è¨é¢¨éªï¼æå©æ¼å¨é«çä¿å¥ç°å¢ä¸­å»ºç«æ´å¯é çäººå·¥æºæ§æç¨ç¨å¼ãæåçç ç©¶çµææ¨å¨å½±é¿äººå·¥æºæ§å¨é«çä¿å¥ä¸­çæªä¾æ¹åï¼åææåå¶æ´åçç¯åååè³ªã

##### **Evaluating Computational Accuracy of Large Language Models in Numerical Reasoning Tasks for Healthcare Applications**
2501.13936v1 by Arjun R. Malghan

Large Language Models (LLMs) have emerged as transformative tools in the
healthcare sector, demonstrating remarkable capabilities in natural language
understanding and generation. However, their proficiency in numerical
reasoning, particularly in high-stakes domains like in clinical applications,
remains underexplored. Numerical reasoning is critical in healthcare
applications, influencing patient outcomes, treatment planning, and resource
allocation. This study investigates the computational accuracy of LLMs in
numerical reasoning tasks within healthcare contexts. Using a curated dataset
of 1,000 numerical problems, encompassing real-world scenarios such as dosage
calculations and lab result interpretations, the performance of a refined LLM
based on the GPT-3 architecture was evaluated. The methodology includes prompt
engineering, integration of fact-checking pipelines, and application of
regularization techniques to enhance model accuracy and generalization. Key
metrics such as precision, recall, and F1-score were utilized to assess the
model's efficacy. The results indicate an overall accuracy of 84.10%, with
improved performance in straightforward numerical tasks and challenges in
multi-step reasoning. The integration of a fact-checking pipeline improved
accuracy by 11%, underscoring the importance of validation mechanisms. This
research highlights the potential of LLMs in healthcare numerical reasoning and
identifies avenues for further refinement to support critical decision-making
in clinical environments. The findings aim to contribute to the development of
reliable, interpretable, and contextually relevant AI tools for healthcare.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å·²æçºé«çä¿å¥é åçè®é©æ§å·¥å·ï¼å¨èªç¶èªè¨çè§£åçææ¹é¢å±ç¾åºéå¡çè½åãç¶èï¼å®åå¨æ¸å­æ¨çæ¹é¢çè½åï¼ç¹å¥æ¯å¨è¨åºæç¨ç­é«é¢¨éªé åï¼ä»æªå¾å°ååæ¢ç´¢ãæ¸å­æ¨çå¨é«çä¿å¥æç¨ä¸­è³ééè¦ï¼å®å½±é¿æ£èçæ²»ççµæãæ²»çè¨ç«åè³æºåéãæ¬ç ç©¶æ¢è¨äº LLM å¨é«çä¿å¥èæ¯ä¸çæ¸å­æ¨çä»»åä¸­çè¨ç®æºç¢ºæ§ãä½¿ç¨ä¸åç²¾å¿æ´ççåå« 1,000 åæ¸å­åé¡çæ¸æéï¼æ¶µèåéè¨ç®åå¯¦é©å®¤çµæè§£éç­çå¯¦å ´æ¯ï¼è©ä¼°äºåºæ¼ GPT-3 æ¶æ§çç²¾ç LLM çæ§è½ãæ¹æ³åæ¬æç¤ºå·¥ç¨ãæ´åäºå¯¦æ¥æ ¸ç®¡éï¼ä»¥åæç¨æ­£ååæè¡ä»¥å¢å¼·æ¨¡åæºç¢ºæ§åæ³åè½åãå©ç¨ç²¾ç¢ºåº¦ãå¬åçå F1 åæ¸ç­ééµææ¨ä¾è©ä¼°æ¨¡åçæè½ãçµæè¡¨ææ´é«æºç¢ºåº¦çº 84.10%ï¼å¨ç´æ¥æ¸å­ä»»åä¸­è¡¨ç¾è¼å¥½ï¼èå¨å¤æ­¥é©æ¨çä¸­å­å¨ææ°ãæ´åäºå¯¦æ¥æ ¸ç®¡éå°æºç¢ºåº¦æé«äº 11%ï¼å¼·èª¿äºé©è­æ©å¶ç Ð²Ð°Ð¶Ð½Ð¾ÑÑÑãæ¬ç ç©¶å¼·èª¿äº LLM å¨é«çä¿å¥æ¸å­æ¨çä¸­çæ½åï¼ä¸¦æ¾åºé²ä¸æ­¥æ¹é²çéå¾ï¼ä»¥æ¯æè¨åºç°å¢ä¸­çééµæ±ºç­å¶å®ãç ç©¶çµææ¨å¨çºé«çä¿å¥é åçå¯é ãå¯è§£éä¸èèªå¢ç¸éçäººå·¥æºæ§å·¥å·çéç¼ååºè²¢ç»ã

##### **Large Language Models for Interpretable Mental Health Diagnosis**
2501.07653v1 by Brian Hyeongseok Kim, Chao Wang

We propose a clinical decision support system (CDSS) for mental health
diagnosis that combines the strengths of large language models (LLMs) and
constraint logic programming (CLP). Having a CDSS is important because of the
high complexity of diagnostic manuals used by mental health professionals and
the danger of diagnostic errors. Our CDSS is a software tool that uses an LLM
to translate diagnostic manuals to a logic program and solves the program using
an off-the-shelf CLP engine to query a patient's diagnosis based on the encoded
rules and provided data. By giving domain experts the opportunity to inspect
the LLM-generated logic program, and making modifications when needed, our CDSS
ensures that the diagnosis is not only accurate but also interpretable. We
experimentally compare it with two baseline approaches of using LLMs:
diagnosing patients using the LLM-only approach, and using the LLM-generated
logic program but without expert inspection. The results show that, while LLMs
are extremely useful in generating candidate logic programs, these programs
still require expert inspection and modification to guarantee faithfulness to
the official diagnostic manuals. Additionally, ethical concerns arise from the
direct use of patient data in LLMs, underscoring the need for a safer hybrid
approach like our proposed method.

æè¦ï¼<paragraph>æåæåºä¸åç¨æ¼å¿çå¥åº·è¨ºæ·çè¨åºæ±ºç­æ¯æ´ç³»çµ± (CDSS)ï¼å®çµåäºå¤§åèªè¨æ¨¡å (LLM) åç´æéè¼¯ç¨å¼è¨­è¨ (CLP) çåªé»ãææ CDSS å¾éè¦ï¼å çºå¿çå¥åº·å°æ¥­äººå£«ä½¿ç¨çè¨ºæ·æåéå¸¸è¤éï¼èä¸è¨ºæ·é¯èª¤å¾å±éªãæåç CDSS æ¯ä¸åè»é«å·¥å·ï¼å®ä½¿ç¨ LLM å°è¨ºæ·æåè½ææéè¼¯ç¨å¼ï¼ä¸¦ä½¿ç¨ç¾æç CLP å¼æè§£æ±ºç¨å¼ï¼ä»¥æ ¹æç·¨ç¢¼è¦ååæä¾çè³ææ¥è©¢çäººçè¨ºæ·ãééè®é åå°å®¶ææ©ææª¢æ¥ LLM çæçéè¼¯ç¨å¼ï¼ä¸¦å¨éè¦æé²è¡ä¿®æ¹ï¼æåç CDSS å¯ç¢ºä¿è¨ºæ·ä¸åæºç¢ºï¼èä¸å¯è§£è®ãæåä»¥å¯¦é©çæ¹å¼å°å¶èå©ç¨®ä½¿ç¨ LLM çåºç·æ¹æ³é²è¡æ¯è¼ï¼åä½¿ç¨ LLM æ¹æ³è¨ºæ·çäººï¼ä»¥åä½¿ç¨ LLM çæçéè¼¯ç¨å¼ï¼ä½æ²æå°å®¶æª¢æ¥ãçµæé¡¯ç¤ºï¼éç¶ LLM å¨ç¢çåé¸éè¼¯ç¨å¼æ¹é¢éå¸¸æç¨ï¼ä½éäºç¨å¼ä»ç¶éè¦å°å®¶æª¢æ¥åä¿®æ¹ï¼ä»¥ç¢ºä¿å°å®æ¹è¨ºæ·æåçå¿ å¯¦åº¦ãæ­¤å¤ï¼ç´æ¥å¨ LLM ä¸­ä½¿ç¨çäººè³ææå¼ç¼å«çåé¡ï¼éå¼·èª¿äºéè¦ä¸ç¨®æ´å®å¨çæ··åæ¹æ³ï¼ä¾å¦æåæåºçæ¹æ³ã</paragraph>

##### **RadAlign: Advancing Radiology Report Generation with Vision-Language Concept Alignment**
2501.07525v1 by Difei Gu, Yunhe Gao, Yang Zhou, Mu Zhou, Dimitris Metaxas

Automated chest radiographs interpretation requires both accurate disease
classification and detailed radiology report generation, presenting a
significant challenge in the clinical workflow. Current approaches either focus
on classification accuracy at the expense of interpretability or generate
detailed but potentially unreliable reports through image captioning
techniques. In this study, we present RadAlign, a novel framework that combines
the predictive accuracy of vision-language models (VLMs) with the reasoning
capabilities of large language models (LLMs). Inspired by the radiologist's
workflow, RadAlign first employs a specialized VLM to align visual features
with key medical concepts, achieving superior disease classification with an
average AUC of 0.885 across multiple diseases. These recognized medical
conditions, represented as text-based concepts in the aligned visual-language
space, are then used to prompt LLM-based report generation. Enhanced by a
retrieval-augmented generation mechanism that grounds outputs in similar
historical cases, RadAlign delivers superior report quality with a GREEN score
of 0.678, outperforming state-of-the-art methods' 0.634. Our framework
maintains strong clinical interpretability while reducing hallucinations,
advancing automated medical imaging and report analysis through integrated
predictive and generative AI. Code is available at
https://github.com/difeigu/RadAlign.

æè¦ï¼èªååè¸é¨ X åçè§£è®éè¦ç²¾æºçç¾çåé¡åè©³ç´°çæ¾å°ç§å ±åçæï¼éå°è¨åºå·¥ä½æµç¨æ§æéå¤§ææ°ãç®åçåæ³è¦ä¸å°±æ¯ä»¥ç§ç²å¯è§£è®æ§çºä»£å¹å°æ³¨æ¼åé¡æºç¢ºæ§ï¼è¦ä¸å°±æ¯ééå½±åæ¨é¡æè¡ç¢çè©³ç´°ä½å¯è½ä¸å¯é çå ±åãå¨éé ç ç©¶ä¸­ï¼æåæåº RadAlignï¼ä¸åçµåäºè¦è¦ºèªè¨æ¨¡å (VLM) çé æ¸¬æºç¢ºæ§åå¤§åèªè¨æ¨¡å (LLM) çæ¨çè½åçæ°ç©æ¶æ§ãåå°æ¾å°ç§é«å¸«å·¥ä½æµç¨çåç¼ï¼RadAlign é¦åæ¡ç¨å°éç VLM å°è¦è¦ºç¹å¾µèééµé«çæ¦å¿µå°é½ï¼å¨å¤ç¨®ç¾çä¸­éæåªç°çç¾çåé¡ï¼å¹³å AUC çº 0.885ãéäºè­å¥åºçé«ççæ³æå¨å°é½çè¦è¦ºèªè¨ç©ºéä¸­è¡¨ç¤ºçºåºæ¼æå­çæ¦å¿µï¼ç¶å¾ç¨ä¾æç¤ºåºæ¼ LLM çå ±åçæãééä¸ç¨®å°è¼¸åºçµæå»ºç«å¨é¡ä¼¼éå¾æ¡ä¾ä¸­çæª¢ç´¢å¢å¼·çææ©å¶ï¼RadAlign æä¾åªç°çå ±ååè³ªï¼GREEN åæ¸çº 0.678ï¼åªæ¼æåé²æ¹æ³ç 0.634ãæåçæ¶æ§ç¶­æå¼·å¤§çè¨åºå¯è§£è®æ§ï¼åææ¸å°å¹»è¦ºï¼ééæ´åé æ¸¬åçæå¼ AIï¼æ¨é²èªååé«å­¸å½±ååå ±ååæãç¨å¼ç¢¼å¯æ¼ https://github.com/difeigu/RadAlign åå¾ã

##### **A Survey of Embodied AI in Healthcare: Techniques, Applications, and Opportunities**
2501.07468v1 by Yihao Liu, Xu Cao, Tingting Chen, Yankai Jiang, Junjie You, Minghua Wu, Xiaosong Wang, Mengling Feng, Yaochu Jin, Jintai Chen

Healthcare systems worldwide face persistent challenges in efficiency,
accessibility, and personalization. Powered by modern AI technologies such as
multimodal large language models and world models, Embodied AI (EmAI)
represents a transformative frontier, offering enhanced autonomy and the
ability to interact with the physical world to address these challenges. As an
interdisciplinary and rapidly evolving research domain, "EmAI in healthcare"
spans diverse fields such as algorithms, robotics, and biomedicine. This
complexity underscores the importance of timely reviews and analyses to track
advancements, address challenges, and foster cross-disciplinary collaboration.
In this paper, we provide a comprehensive overview of the "brain" of EmAI for
healthcare, wherein we introduce foundational AI algorithms for perception,
actuation, planning, and memory, and focus on presenting the healthcare
applications spanning clinical interventions, daily care & companionship,
infrastructure support, and biomedical research. Despite its promise, the
development of EmAI for healthcare is hindered by critical challenges such as
safety concerns, gaps between simulation platforms and real-world applications,
the absence of standardized benchmarks, and uneven progress across
interdisciplinary domains. We discuss the technical barriers and explore
ethical considerations, offering a forward-looking perspective on the future of
EmAI in healthcare. A hierarchical framework of intelligent levels for EmAI
systems is also introduced to guide further development. By providing
systematic insights, this work aims to inspire innovation and practical
applications, paving the way for a new era of intelligent, patient-centered
healthcare.

æè¦ï¼<paragraph>å¨çé«çä¿å¥ç³»çµ±å¨æçãå¯åæ§ååäººåæ¹é¢æçºé¢è¨ææ°ãé«ç¾å¼ AI (EmAI) ç±å¤æ¨¡æå¤§åèªè¨æ¨¡ååä¸çæ¨¡åç­ç¾ä»£ AI æè¡æä¾æ¯æï¼ä»£è¡¨äºä¸åè½ååæ²¿ï¼æä¾å¢å¼·çèªä¸»æ§ï¼ä»¥åèç©çä¸çäºåä»¥æå°éäºææ°çè½åãä½çºä¸åè·¨å­¸ç§ä¸å¿«éç¼å±çç ç©¶é åï¼ãé«çä¿å¥ä¸­ç EmAIãæ¶µèäºæ¼ç®æ³ãæ©å¨äººåçç©é«å­¸ç­å¤åé åãéç¨®è¤éæ§çªé¡¯äºåæå¯©æ¥ååæçéè¦æ§ï¼ä»¥è¿½è¹¤é²å±ãæå°ææ°ä¸¦ä¿é²è·¨å­¸ç§åä½ãå¨æ¬æä¸­ï¼æåæä¾äº EmAI å¨é«çä¿å¥ä¸­çãå¤§è¦ãçå¨é¢æ¦è¿°ï¼æåå¨å¶ä¸­ä»ç´¹äºæç¥ãå·è¡ãè¦ååè¨æ¶çåºæ¬ AI æ¼ç®æ³ï¼ä¸¦å°æ³¨æ¼åç¾æ¶µèè¨åºå¹²é ãæ¥å¸¸ç§è­·åéªä¼´ãåºç¤è¨­æ½æ¯æ´åçç©é«å­¸ç ç©¶çé«çä¿å¥æç¨ãåç®¡åæ¯çå¥½ï¼ä½ EmAI å¨é«çä¿å¥ä¸­çç¼å±åå°ééµææ°çé»ç¤ï¼ä¾å¦å®å¨åé¡ãæ¨¡æ¬å¹³å°åå¯¦éæç¨ä¹éçå·®è·ãç¼ºä¹æ¨æºååºæºï¼ä»¥åè·¨å­¸ç§é åé²å±ä¸åãæåè¨è«äºæè¡éç¤ä¸¦æ¢è¨äºéå¾·èéï¼å° EmAI å¨é«çä¿å¥ä¸­çæªä¾æä¾äºåç»æ§çè§é»ãéå¼å¥äº EmAI ç³»çµ±çæºæ§å±¤ç´æ¶æ§ï¼ä»¥æå°é²ä¸æ­¥çç¼å±ãééæä¾ç³»çµ±æ§çè¦è§£ï¼éé å·¥ä½æ¨å¨æ¿ç¼åµæ°åå¯¦ç¨æç¨ï¼çºæºæ§ä¸ä»¥æ£èçºä¸­å¿çé«çä¿å¥æ°æä»£éªè·¯ã</paragraph>

##### **Diff-Ensembler: Learning to Ensemble 2D Diffusion Models for Volume-to-Volume Medical Image Translation**
2501.07430v1 by Xiyue Zhu, Dou Hoon Kwark, Ruike Zhu, Kaiwen Hong, Yiqi Tao, Shirui Luo, Yudu Li, Zhi-Pei Liang, Volodymyr Kindratenko

Despite success in volume-to-volume translations in medical images, most
existing models struggle to effectively capture the inherent volumetric
distribution using 3D representations. The current state-of-the-art approach
combines multiple 2D-based networks through weighted averaging, thereby
neglecting the 3D spatial structures. Directly training 3D models in medical
imaging presents significant challenges due to high computational demands and
the need for large-scale datasets. To address these challenges, we introduce
Diff-Ensembler, a novel hybrid 2D-3D model for efficient and effective
volumetric translations by ensembling perpendicularly trained 2D diffusion
models with a 3D network in each diffusion step. Moreover, our model can
naturally be used to ensemble diffusion models conditioned on different
modalities, allowing flexible and accurate fusion of input conditions.
Extensive experiments demonstrate that Diff-Ensembler attains superior accuracy
and volumetric realism in 3D medical image super-resolution and modality
translation. We further demonstrate the strength of our model's volumetric
realism using tumor segmentation as a downstream task.

æè¦ï¼åç®¡å¨é«å­¸å½±åä¸­é«ç©å°é«ç©çç¿»è­¯åå¾æåï¼ä½ç¾æçæ¨¡åå¤§å¤é£ä»¥ææå°ä½¿ç¨ 3D åç¾ä¾æ·ååºæçé«ç©åä½ãç®åæåé²çæ¹æ³æ¯ééå æ¬å¹³åä¾çµåå¤ååºæ¼ 2D çç¶²è·¯ï¼å æ­¤å¿½ç¥äº 3D ç©ºéçµæ§ãå¨é«å­¸å½±åä¸­ç´æ¥è¨ç·´ 3D æ¨¡åæç¢çé¡¯èçææ°ï¼åå å¨æ¼é«éç®éæ±åå¤§è¦æ¨¡è³æéçéæ±ãçºäºæå°éäºææ°ï¼æåå¼å¥äº Diff-Ensemblerï¼éæ¯ä¸åæ°ç©çæ··å 2D-3D æ¨¡åï¼å¯ééå¨æ¯åæ´æ£æ­¥é©ä¸­å°åç´è¨ç·´ç 2D æ´æ£æ¨¡åè 3D ç¶²è·¯çµåï¼ä¾ææçä¸ææå°é²è¡é«ç©è½æãæ­¤å¤ï¼æåçæ¨¡åå¯ä»¥èªç¶å°ç¨æ¼çµååºæ¼ä¸åå½¢å¼çæ´æ£æ¨¡åï¼å¾èéæ´»ä¸æºç¢ºå°èåè¼¸å¥æ¢ä»¶ãå»£æ³çå¯¦é©è­æï¼Diff-Ensembler å¨ 3D é«å­¸å½±åè¶è§£æåº¦åå½¢å¼è½æä¸­éå°äºæ´é«çæºç¢ºåº¦åé«ç©çå¯¦æãæåé²ä¸æ­¥ä½¿ç¨è«ç¤åå²ä½çºä¸æ¸¸ä»»åï¼ä¾è­ææåæ¨¡åçé«ç©çå¯¦æã

##### **Synthetic Data and Health Privacy**
2501.09031v1 by GwÃ©nolÃ© Abgrall, Xavier Monnet, Anmol Arora

This Viewpoint discusses generative artificial intelligence and safeguarding
privacy by using synthetic data as a substitute for private health data.

æè¦ï¼æ­¤è§é»æ¢è¨çæå¼äººå·¥æºæ§ä»¥åä½¿ç¨åæè³æåä»£ç§äººå¥åº·è³æä»¥ä¿è­·é±ç§ã

##### **Natural Language-Assisted Multi-modal Medication Recommendation**
2501.07166v1 by Jie Tan, Yu Rong, Kangfei Zhao, Tian Bian, Tingyang Xu, Junzhou Huang, Hong Cheng, Helen Meng

Combinatorial medication recommendation(CMR) is a fundamental task of
healthcare, which offers opportunities for clinical physicians to provide more
precise prescriptions for patients with intricate health conditions,
particularly in the scenarios of long-term medical care. Previous research
efforts have sought to extract meaningful information from electronic health
records (EHRs) to facilitate combinatorial medication recommendations. Existing
learning-based approaches further consider the chemical structures of
medications, but ignore the textual medication descriptions in which the
functionalities are clearly described. Furthermore, the textual knowledge
derived from the EHRs of patients remains largely underutilized. To address
these issues, we introduce the Natural Language-Assisted Multi-modal Medication
Recommendation(NLA-MMR), a multi-modal alignment framework designed to learn
knowledge from the patient view and medication view jointly. Specifically,
NLA-MMR formulates CMR as an alignment problem from patient and medication
modalities. In this vein, we employ pretrained language models(PLMs) to extract
in-domain knowledge regarding patients and medications, serving as the
foundational representation for both modalities. In the medication modality, we
exploit both chemical structures and textual descriptions to create medication
representations. In the patient modality, we generate the patient
representations based on textual descriptions of diagnosis, procedure, and
symptom. Extensive experiments conducted on three publicly accessible datasets
demonstrate that NLA-MMR achieves new state-of-the-art performance, with a
notable average improvement of 4.72% in Jaccard score. Our source code is
publicly available on https://github.com/jtan1102/NLA-MMR_CIKM_2024.

æè¦ï¼çµåå¼è¥ç©æ¨è¦ (CMR) æ¯é«çä¿å¥çä¸é åºæ¬ä»»åï¼å®çºè¨åºé«çæä¾äºéå°å·æè¤éå¥åº·çæ³çæ£èæä¾æ´ç²¾ç¢ºèæ¹çæ©æï¼ç¹å¥æ¯å¨é·æé«çä¿å¥çææ³ä¸ãååçç ç©¶å·¥ä½è©¦åå¾é»å­å¥åº·è¨é (EHR) ä¸­æåææç¾©çè³è¨ï¼ä»¥ä¿é²çµåå¼è¥ç©æ¨è¦ãç¾æçåºæ¼å­¸ç¿çæ¹æ³é²ä¸æ­¥èæ®äºè¥ç©çåå­¸çµæ§ï¼ä½å¿½ç¥äºåè½æ¸æ¥æè¿°æ¼å¶ä¸­çææ¬è¥ç©èªªæãæ­¤å¤ï¼å¾æ£èç EHR ä¸­è¡ççææ¬ç¥è­å¨å¾å¤§ç¨åº¦ä¸ä»æªå¾å°ååå©ç¨ãçºäºè§£æ±ºéäºåé¡ï¼æåå¼å¥äºèªç¶èªè¨è¼å©å¤æ¨¡å¼è¥ç©æ¨è¦ (NLA-MMR)ï¼éæ¯ä¸åå¤æ¨¡å¼å°é½æ¡æ¶ï¼æ¨å¨å¾æ£èè¦è§åè¥ç©è¦è§å±åå­¸ç¿ç¥è­ãå·é«ä¾èªªï¼NLA-MMR å° CMR æ§å»ºçºæ£èåè¥ç©æ¨¡å¼çå°é½åé¡ãå¨æ­¤èçµ¡ä¸­ï¼æåæ¡ç¨é è¨ç·´èªè¨æ¨¡å (PLM) ä¾æåæéæ£èåè¥ç©çé åå§ç¥è­ï¼ä½çºéå©ç¨®æ¨¡å¼çåºæ¬è¡¨ç¤ºãå¨è¥ç©æ¨¡å¼ä¸­ï¼æåå©ç¨åå­¸çµæ§åææ¬èªªæä¾å»ºç«è¥ç©è¡¨ç¤ºãå¨æ£èæ¨¡å¼ä¸­ï¼æåæ ¹æè¨ºæ·ãç¨åºåçççæå­èªªæä¾çææ£èè¡¨ç¤ºãå¨ä¸åå¬éå­åçè³æéä¸é²è¡çå»£æ³å¯¦é©è¡¨æï¼NLA-MMR éå°äºæ°çæåé²æè½ï¼åå¡å¾·ææ¸å¹³åæ¹é²äº 4.72%ãæåçåå§ç¢¼å¬éæ¼ https://github.com/jtan1102/NLA-MMR_CIKM_2024ã

##### **CureGraph: Contrastive Multi-Modal Graph Representation Learning for Urban Living Circle Health Profiling and Prediction**
2501.07157v1 by Jinlin Li, Xiao Zhou

The early detection and prediction of health status decline among the elderly
at the neighborhood level are of great significance for urban planning and
public health policymaking. While existing studies affirm the connection
between living environments and health outcomes, most rely on single data
modalities or simplistic feature concatenation of multi-modal information,
limiting their ability to comprehensively profile the health-oriented urban
environments. To fill this gap, we propose CureGraph, a contrastive multi-modal
representation learning framework for urban health prediction that employs
graph-based techniques to infer the prevalence of common chronic diseases among
the elderly within the urban living circles of each neighborhood. CureGraph
leverages rich multi-modal information, including photos and textual reviews of
residential areas and their surrounding points of interest, to generate urban
neighborhood embeddings. By integrating pre-trained visual and textual encoders
with graph modeling techniques, CureGraph captures cross-modal spatial
dependencies, offering a comprehensive understanding of urban environments
tailored to elderly health considerations. Extensive experiments on real-world
datasets demonstrate that CureGraph improves the best baseline by $28\%$ on
average in terms of $R^2$ across elderly disease risk prediction tasks.
Moreover, the model enables the identification of stage-wise chronic disease
progression and supports comparative public health analysis across
neighborhoods, offering actionable insights for sustainable urban development
and enhanced quality of life. The code is publicly available at
https://github.com/jinlin2021/CureGraph.

æè¦ï¼å¨é°éå±¤ç´æ©æåµæ¸¬åé æ¸¬èå¹´äººçå¥åº·çæ³ä¸éå°åå¸è¦ååå¬å±è¡çæ¿ç­å¶å®å·æéå¤§æç¾©ãåç®¡ç¾æç ç©¶è¯å®äºçæ´»ç°å¢èå¥åº·çµæä¹éçéè¯æ§ï¼ä½å¤§å¤ä¾è³´å®ä¸è³ææ¨¡å¼æå¤æ¨¡å¼è³è¨çç°¡åç¹å¾µä¸²æ¥ï¼éå¶äºä»åå¨é¢æç¹ªä»¥å¥åº·çºå°åçåå¸ç°å¢çè½åãçºäºå¡«è£éåå·®è·ï¼æåæåºäº CureGraphï¼ä¸åç¨æ¼åå¸å¥åº·é æ¸¬çå°æ¯å¼å¤æ¨¡å¼è¡¨ç¤ºå­¸ç¿æ¶æ§ï¼å®æ¡ç¨åºæ¼åå½¢æè¡ä¾æ¨è«æ¯åé°éåå¸çæ´»åä¸­èå¹´äººå¸¸è¦æ¢æ§ç¾ççæµè¡çãCureGraph å©ç¨è±å¯çå¤æ¨¡å¼è³è¨ï¼åæ¬ä½å®ååå¶å¨åæ¯é»çç§çåæå­è©è«ï¼ä¾ç¢çåå¸é°éåµå¥ãééæ´åé åè¨ç·´çè¦è¦ºåæå­ç·¨ç¢¼å¨èåå½¢å»ºæ¨¡æè¡ï¼CureGraph ææè·¨æ¨¡å¼ç©ºéä¾è³´æ§ï¼æä¾å°åå¸ç°å¢çå¨é¢çè§£ï¼å°ééå°èå¹´äººçå¥åº·èéãå¨çå¯¦ä¸çè³æéä¸çå»£æ³å¯¦é©è­æï¼CureGraph å¨èå¹´äººç¾çé¢¨éªé æ¸¬ä»»åä¸­ï¼å¹³åå¨ R2 æ¹é¢å°æä½³åºæºç·æé«äº 28%ãæ­¤å¤ï¼è©²æ¨¡åè½å¤ è­å¥éæ®µæ§çæ¢æ§ç¾çé²ç¨ï¼ä¸¦æ¯æ´è·¨é°éçæ¯è¼å¬å±è¡çåæï¼çºæ°¸çºçåå¸ç¼å±åæåçæ´»åè³ªæä¾å¯è¡çè¦è§£ãç¨å¼ç¢¼å·²å¬éæ¼ https://github.com/jinlin2021/CureGraphã

##### **UNetVL: Enhancing 3D Medical Image Segmentation with Chebyshev KAN Powered Vision-LSTM**
2501.07017v2 by Xuhui Guo, Tanmoy Dam, Rohan Dhamdhere, Gourav Modanwal, Anant Madabhushi

3D medical image segmentation has progressed considerably due to
Convolutional Neural Networks (CNNs) and Vision Transformers (ViTs), yet these
methods struggle to balance long-range dependency acquisition with
computational efficiency. To address this challenge, we propose UNETVL (U-Net
Vision-LSTM), a novel architecture that leverages recent advancements in
temporal information processing. UNETVL incorporates Vision-LSTM (ViL) for
improved scalability and memory functions, alongside an efficient Chebyshev
Kolmogorov-Arnold Networks (KAN) to handle complex and long-range dependency
patterns more effectively. We validated our method on the ACDC and AMOS2022
(post challenge Task 2) benchmark datasets, showing a significant improvement
in mean Dice score compared to recent state-of-the-art approaches, especially
over its predecessor, UNETR, with increases of 7.3% on ACDC and 15.6% on AMOS,
respectively. Extensive ablation studies were conducted to demonstrate the
impact of each component in UNETVL, providing a comprehensive understanding of
its architecture. Our code is available at https://github.com/tgrex6/UNETVL,
facilitating further research and applications in this domain.

æè¦ï¼3D é«å­¸å½±ååå²ç±æ¼å·ç©ç¥ç¶ç¶²è·¯ (CNN) åè¦è¦ºTransformer (ViT) èé²æ­¥è¨±å¤ï¼ç¶èéäºæ¹æ³é£ä»¥å¹³è¡¡é·ç¨ä¾è³´éä¿æ·åèéç®æçãçºäºæå°éåææ°ï¼æåæåº UNETVL (U-Net è¦è¦º LSTM)ï¼éæ¯ä¸ç¨®æ°ç©çæ¶æ§ï¼å®å©ç¨æéè³è¨èççææ°é²å±ãUNETVL çµåè¦è¦º LSTM (ViL) ä»¥æåå¯æ´åæ§åè¨æ¶åè½ï¼ä¸¦çµåé«æçåæ¯éªå¤« Kolmogorov-Arnold ç¶²è·¯ (KAN) ä»¥æ´ææçå°èçè¤éä¸é·ç¨çä¾è³´éä¿æ¨¡å¼ãæåå¨ ACDC å AMOS2022ï¼ææ°ä»»å 2 ä¹å¾ï¼åºæºè³æéé©è­äºæåçæ¹æ³ï¼èæè¿çææ°æè¡æ¹æ³ç¸æ¯ï¼å¹³å Dice åæ¸æé¡¯èæåï¼ç¹å¥æ¯èå¶åèº« UNETR ç¸æ¯ï¼å¨ ACDC ä¸æåäº 7.3%ï¼å¨ AMOS ä¸æåäº 15.6%ãæåé²è¡äºå»£æ³çæ¶èç ç©¶ï¼ä»¥å±ç¤º UNETVL ä¸­æ¯ååä»¶çå½±é¿ï¼æä¾å°å¶æ¶æ§çå¨é¢çè§£ãæåçç¨å¼ç¢¼å¯å¨ https://github.com/tgrex6/UNETVL åå¾ï¼ä¿é²é²ä¸æ­¥çå¨éæ¹é¢çç ç©¶åæç¨ã

##### **Combining LLM decision and RL action selection to improve RL policy for adaptive interventions**
2501.06980v1 by Karine Karine, Benjamin M. Marlin

Reinforcement learning (RL) is increasingly being used in the healthcare
domain, particularly for the development of personalized health adaptive
interventions. Inspired by the success of Large Language Models (LLMs), we are
interested in using LLMs to update the RL policy in real time, with the goal of
accelerating personalization. We use the text-based user preference to
influence the action selection on the fly, in order to immediately incorporate
the user preference. We use the term "user preference" as a broad term to refer
to a user personal preference, constraint, health status, or a statement
expressing like or dislike, etc. Our novel approach is a hybrid method that
combines the LLM response and the RL action selection to improve the RL policy.
Given an LLM prompt that incorporates the user preference, the LLM acts as a
filter in the typical RL action selection. We investigate different prompting
strategies and action selection strategies. To evaluate our approach, we
implement a simulation environment that generates the text-based user
preferences and models the constraints that impact behavioral dynamics. We show
that our approach is able to take into account the text-based user preferences,
while improving the RL policy, thus improving personalization in adaptive
intervention.

æè¦ï¼å¼·åå­¸ç¿ï¼RLï¼å¨é«çé åçæç¨æ¥çå»£æ³ï¼ç¹å¥æ¯ç¨æ¼éç¼åäººåå¥åº·é©ææ§å¹²é æªæ½ãåå°å¤§åèªè¨æ¨¡åï¼LLMï¼æåçåç¼ï¼æåæèè¶£ä½¿ç¨ LLM å³ææ´æ° RL æ¿ç­ï¼ç®æ¨æ¯å éåäººåãæåä½¿ç¨åºæ¼æå­çä½¿ç¨èåå¥½ä¾å½±é¿è¡åé¸æï¼ä»¥ä¾¿ç«å³ç´å¥ä½¿ç¨èåå¥½ãæåä½¿ç¨ãä½¿ç¨èåå¥½ãä¸è©ä½çºå»£ç¾©è©ï¼ç¨ä¾æä½¿ç¨èçåäººåå¥½ãéå¶ãå¥åº·çæ³æè¡¨éå¥½æ¡çé³è¿°ç­ãæåçæ°ç©æ¹æ³æ¯ä¸ç¨®æ··åæ¹æ³ï¼çµåäº LLM åæå RL è¡åé¸æä»¥æ¹å RL æ¿ç­ãçµ¦å®åå«ä½¿ç¨èåå¥½ç LLM æç¤ºï¼LLM å¨å¸åç RL è¡åé¸æä¸­åç¶éæ¿¾å¨ãæåç ç©¶äºä¸åçæç¤ºç­ç¥åè¡åé¸æç­ç¥ãçºäºè©ä¼°æåçåæ³ï¼æåå¯¦ä½äºä¸åæ¨¡æ¬ç°å¢ï¼ç¨æ¼ç¢çåºæ¼æå­çä½¿ç¨èåå¥½ï¼ä¸¦å°å½±é¿è¡çºåæçéå¶é²è¡å»ºæ¨¡ãæåå±ç¤ºäºæåçåæ³è½å¤ èéåºæ¼æå­çä½¿ç¨èåå¥½ï¼åææ¹å RL æ¿ç­ï¼å¾èæ¹åé©ææ§å¹²é ä¸­çåäººåã

##### **Enhancing Patient-Centric Communication: Leveraging LLMs to Simulate Patient Perspectives**
2501.06964v1 by Xinyao Ma, Rui Zhu, Zihao Wang, Jingwei Xiong, Qingyu Chen, Haixu Tang, L. Jean Camp, Lucila Ohno-Machado

Large Language Models (LLMs) have demonstrated impressive capabilities in
role-playing scenarios, particularly in simulating domain-specific experts
using tailored prompts. This ability enables LLMs to adopt the persona of
individuals with specific backgrounds, offering a cost-effective and efficient
alternative to traditional, resource-intensive user studies. By mimicking human
behavior, LLMs can anticipate responses based on concrete demographic or
professional profiles. In this paper, we evaluate the effectiveness of LLMs in
simulating individuals with diverse backgrounds and analyze the consistency of
these simulated behaviors compared to real-world outcomes. In particular, we
explore the potential of LLMs to interpret and respond to discharge summaries
provided to patients leaving the Intensive Care Unit (ICU). We evaluate and
compare with human responses the comprehensibility of discharge summaries among
individuals with varying educational backgrounds, using this analysis to assess
the strengths and limitations of LLM-driven simulations. Notably, when LLMs are
primed with educational background information, they deliver accurate and
actionable medical guidance 88% of the time. However, when other information is
provided, performance significantly drops, falling below random chance levels.
This preliminary study shows the potential benefits and pitfalls of
automatically generating patient-specific health information from diverse
populations. While LLMs show promise in simulating health personas, our results
highlight critical gaps that must be addressed before they can be reliably used
in clinical settings. Our findings suggest that a straightforward
query-response model could outperform a more tailored approach in delivering
health information. This is a crucial first step in understanding how LLMs can
be optimized for personalized health communication while maintaining accuracy.

æè¦ï¼å¤§åèªè¨æ¨¡åï¼LLMï¼å¨è§è²æ®æ¼å ´æ¯ä¸­å±ç¾äºä»¤äººå°è±¡æ·±å»çè½åï¼ç¹å¥æ¯å¨æ¨¡æ¬ç¹å®é åçå°å®¶æï¼æä½¿ç¨éèº«æé çæç¤ºãéç¨®è½åä½¿ LLM è½å¤ æ¡ç¨å·æç¹å®èæ¯çåäººè§è²ï¼æä¾ä¸ç¨®ç¶æ¿å¯¦æ ä¸ææççæ¿ä»£æ¹æ¡ï¼ç¨æ¼å³çµ±ä¸è³æºå¯éçä½¿ç¨èç ç©¶ãééæ¨¡æ¬äººé¡è¡çºï¼LLM è½å¤ æ ¹æå·é«çäººå£çµ±è¨æå°æ¥­ç¹å¾µé æ¸¬åæãå¨æ¬æä¸­ï¼æåè©ä¼°äº LLM å¨æ¨¡æ¬å·æä¸åèæ¯çåäººæ¹é¢çæææ§ï¼ä¸¦åæäºéäºæ¨¡æ¬è¡çºèå¯¦éçµæç¸æ¯çä¸è´æ§ãç¹å¥æ¯ï¼æåæ¢è¨äº LLM è§£éååææä¾çµ¦é¢éå è­·çæ¿ (ICU) æ£èçåºé¢æè¦çæ½åãæåè©ä¼°ä¸¦èäººé¡çåææ¯è¼äºä¸åæè²èæ¯çåäººå°åºé¢æè¦çå¯çè§£æ§ï¼ä¸¦ä½¿ç¨æ­¤åæä¾è©ä¼° LLM é©åæ¨¡æ¬çåªé»åéå¶ãå¼å¾æ³¨æçæ¯ï¼ç¶ LLM è¢«æ¤å¥æè²èæ¯è³è¨æï¼ä»åå¨ 88% çæéå§é½è½æä¾æºç¢ºä¸å¯è¡çé«çæå°ãä½æ¯ï¼ç¶æä¾å¶ä»è³è¨æï¼æè½æé¡¯èä¸éï¼ä½æ¼é¨æ©æ©æçç­ç´ãéé åæ­¥ç ç©¶é¡¯ç¤ºäºèªåç¢çä¾èªä¸åç¾¤é«çç¹å®æ¼æ£èçå¥åº·è³è¨çæ½å¨å¥½èåç¼ºé»ãåç®¡ LLM å¨æ¨¡æ¬å¥åº·è§è²æ¹é¢é¡¯ç¤ºåºåæ¯ï¼ä½æåççµæçªåºäºå¨è¨åºç°å¢ä¸­å¯é ä½¿ç¨ä¹åå¿é è§£æ±ºçééµå·®è·ãæåçç ç©¶çµæè¡¨æï¼å¨æä¾å¥åº·è³è¨æ¹é¢ï¼ä¸åç´æ¥çæ¥è©¢åææ¨¡åå¯ä»¥åªæ¼ä¸åæ´éèº«æé çæ¹æ³ãéæ¯äºè§£å¦ä½éå°åäººåå¥åº·æºéåªå LLM åæç¶­ææºç¢ºæ§çç¬¬ä¸æ­¥ã

##### **MedGrad E-CLIP: Enhancing Trust and Transparency in AI-Driven Skin Lesion Diagnosis**
2501.06887v1 by Sadia Kamal, Tim Oates

As deep learning models gain attraction in medical data, ensuring transparent
and trustworthy decision-making is essential. In skin cancer diagnosis, while
advancements in lesion detection and classification have improved accuracy, the
black-box nature of these methods poses challenges in understanding their
decision processes, leading to trust issues among physicians. This study
leverages the CLIP (Contrastive Language-Image Pretraining) model, trained on
different skin lesion datasets, to capture meaningful relationships between
visual features and diagnostic criteria terms. To further enhance transparency,
we propose a method called MedGrad E-CLIP, which builds on gradient-based
E-CLIP by incorporating a weighted entropy mechanism designed for complex
medical imaging like skin lesions. This approach highlights critical image
regions linked to specific diagnostic descriptions. The developed integrated
pipeline not only classifies skin lesions by matching corresponding
descriptions but also adds an essential layer of explainability developed
especially for medical data. By visually explaining how different features in
an image relates to diagnostic criteria, this approach demonstrates the
potential of advanced vision-language models in medical image analysis,
ultimately improving transparency, robustness, and trust in AI-driven
diagnostic systems.

æè¦ï¼éçæ·±åº¦å­¦ä¹ æ¨¡åå¨å»å­¦æ°æ®ä¸­è·å¾å³æ³¨ï¼ç¡®ä¿éæä¸å¼å¾ä¿¡èµçå³ç­è³å³éè¦ãå¨ç®è¤çè¯æ­ä¸­ï¼è½ç¶çç¶æ£æµååç±»çè¿æ­¥æé«äºåç¡®æ§ï¼ä½è¿äºæ¹æ³çé»çæ§è´¨å¯¹çè§£å¶å³ç­è¿ç¨ææäºææï¼å¯¼è´å»çä¹é´çä¿¡ä»»é®é¢ãæ¬ç ç©¶å©ç¨å¨ä¸åç®è¤çåæ°æ®éä¸è®­ç»ç CLIPï¼å¯¹æ¯è¯­è¨å¾åé¢è®­ç»ï¼æ¨¡åï¼ä»¥ææè§è§ç¹å¾åè¯æ­æ åæ¯è¯­ä¹é´çææä¹å³ç³»ãä¸ºäºè¿ä¸æ­¥æé«éæåº¦ï¼æä»¬æåºäºä¸ç§åä¸º MedGrad E-CLIP çæ¹æ³ï¼è¯¥æ¹æ³éè¿ç»åä¸ä¸ºç®è¤çåç­å¤æå»å­¦å½±åè®¾è®¡çå æçµæºå¶ï¼å»ºç«å¨åºäºæ¢¯åº¦ç E-CLIP ä¹ä¸ãæ­¤æ¹æ³çªåºäºä¸ç¹å®è¯æ­æè¿°ç¸å³èçå³é®å¾ååºåãå¼åçéæç®¡éä¸ä»éè¿å¹éç¸åºçæè¿°å¯¹ç®è¤çåè¿è¡åç±»ï¼è¿æ·»å äºä¸å±ä¸é¨ä¸ºå»å­¦æ°æ®å¼åçåºæ¬å¯è§£éæ§ãéè¿ç´è§å°è§£éå¾åä¸­ä¸åç¹å¾ä¸è¯æ­æ åçå³ç³»ï¼è¿ç§æ¹æ³å±ç¤ºäºé«çº§è§è§è¯­è¨æ¨¡åå¨å»å­¦å¾ååæä¸­çæ½åï¼æç»æé«äºéæåº¦ãç¨³å¥æ§åå¯¹äººå·¥æºè½é©±å¨çè¯æ­ç³»ç»çä¿¡ä»»ã

##### **A Foundational Generative Model for Breast Ultrasound Image Analysis**
2501.06869v1 by Haojun Yu, Youcheng Li, Nan Zhang, Zihan Niu, Xuantong Gong, Yanwen Luo, Haotian Ye, Siyu He, Quanlin Wu, Wangyan Qin, Mengyuan Zhou, Jie Han, Jia Tao, Ziwei Zhao, Di Dai, Di He, Dong Wang, Binghui Tang, Ling Huo, James Zou, Qingli Zhu, Yong Wang, Liwei Wang

Foundational models have emerged as powerful tools for addressing various
tasks in clinical settings. However, their potential development to breast
ultrasound analysis remains untapped. In this paper, we present BUSGen, the
first foundational generative model specifically designed for breast ultrasound
image analysis. Pretrained on over 3.5 million breast ultrasound images, BUSGen
has acquired extensive knowledge of breast structures, pathological features,
and clinical variations. With few-shot adaptation, BUSGen can generate
repositories of realistic and informative task-specific data, facilitating the
development of models for a wide range of downstream tasks. Extensive
experiments highlight BUSGen's exceptional adaptability, significantly
exceeding real-data-trained foundational models in breast cancer screening,
diagnosis, and prognosis. In breast cancer early diagnosis, our approach
outperformed all board-certified radiologists (n=9), achieving an average
sensitivity improvement of 16.5% (P-value<0.0001). Additionally, we
characterized the scaling effect of using generated data which was as effective
as the collected real-world data for training diagnostic models. Moreover,
extensive experiments demonstrated that our approach improved the
generalization ability of downstream models. Importantly, BUSGen protected
patient privacy by enabling fully de-identified data sharing, making progress
forward in secure medical data utilization. An online demo of BUSGen is
available at https://aibus.bio.

æè¦ï¼åºç¤æ¨¡åå·²æçºè§£æ±ºè¨åºç°å¢ä¸­åç¨®ä»»åçå¼·å¤§å·¥å·ãç¶èï¼å®åå¨ä¹³æ¿è¶é³æ³¢åæçæ½å¨ç¼å±ä»æªéç¼ãå¨æ¬æä¸­ï¼æåæåº BUSGenï¼éæ¯ç¬¬ä¸åå°éè¨­è¨ç¨æ¼ä¹³æ¿è¶é³æ³¢å½±ååæçåºç¤çææ¨¡åãBUSGen å¨è¶é 350 è¬å¼µä¹³æ¿è¶é³æ³¢å½±åä¸é²è¡é è¨ç·´ï¼å·²ç²å¾ä¹³æ¿çµæ§ãççç¹å¾µåè¨åºè®ç°çå»£æ³ç¥è­ãééå°éé©æï¼BUSGen å¯ä»¥ç¢çé¼çä¸å·æè³è¨æ§çç¹å®ä»»åè³æå²å­åº«ï¼ä¿é²éç¼å»£æ³çä¸æ¸¸ä»»åæ¨¡åãå»£æ³çå¯¦é©çªé¡¯äº BUSGen çåºè²é©ææ§ï¼å¨ä¹³çç¯©æª¢ãè¨ºæ·åé å¾æ¹é¢é¡¯èè¶è¶ä»¥çå¯¦è³æè¨ç·´çåºç¤æ¨¡åãå¨ä¹³çæ©æè¨ºæ·ä¸­ï¼æåçåæ³åªæ¼ææééèªè­çæ¾å°ç§é«å¸« (n=9)ï¼å¹³åææåº¦æé«äº 16.5%ï¼P å¼ <0.0001ï¼ãæ­¤å¤ï¼æåæè¿°äºä½¿ç¨çæè³æçè¦æ¨¡ææï¼å¶èæ¶éççå¯¦ä¸çè³æä¸æ¨£ææï¼å¯ç¨æ¼è¨ç·´è¨ºæ·æ¨¡åãæ­¤å¤ï¼å»£æ³çå¯¦é©è­æï¼æåçåæ³æ¹åäºä¸æ¸¸æ¨¡åçæ³åè½åãéè¦çæ¯ï¼BUSGen ä¿è­·äºæ£èé±ç§ï¼å çºå®è½å¤ å®å¨å»è­å¥è³æå±äº«ï¼å¨å®å¨é«çè³æå©ç¨æ¹é¢åå¾é²å±ãBUSGen çç·ä¸ç¤ºç¯å¯å¨ https://aibus.bio åå¾ã

##### **A Comprehensive Evaluation of Large Language Models on Mental Illnesses in Arabic Context**
2501.06859v1 by Noureldin Zahran, Aya E. Fouda, Radwa J. Hanafy, Mohammed E. Fouda

Mental health disorders pose a growing public health concern in the Arab
world, emphasizing the need for accessible diagnostic and intervention tools.
Large language models (LLMs) offer a promising approach, but their application
in Arabic contexts faces challenges including limited labeled datasets,
linguistic complexity, and translation biases. This study comprehensively
evaluates 8 LLMs, including general multi-lingual models, as well as bi-lingual
ones, on diverse mental health datasets (such as AraDepSu, Dreaddit, MedMCQA),
investigating the impact of prompt design, language configuration (native
Arabic vs. translated English, and vice versa), and few-shot prompting on
diagnostic performance. We find that prompt engineering significantly
influences LLM scores mainly due to reduced instruction following, with our
structured prompt outperforming a less structured variant on multi-class
datasets, with an average difference of 14.5\%. While language influence on
performance was modest, model selection proved crucial: Phi-3.5 MoE excelled in
balanced accuracy, particularly for binary classification, while Mistral NeMo
showed superior performance in mean absolute error for severity prediction
tasks. Few-shot prompting consistently improved performance, with particularly
substantial gains observed for GPT-4o Mini on multi-class classification,
boosting accuracy by an average factor of 1.58. These findings underscore the
importance of prompt optimization, multilingual analysis, and few-shot learning
for developing culturally sensitive and effective LLM-based mental health tools
for Arabic-speaking populations.

æè¦ï¼<paragraph>å¿çå¥åº·éç¤å¨é¿æä¼¯ä¸çä¸­æ§ææ¥çå´éçå¬å±è¡çåé¡ï¼å¼·èª¿äºå°å¯åçè¨ºæ·åå¹²é å·¥å·çéæ±ãå¤§åèªè¨æ¨¡å (LLM) æä¾äºä¸ç¨®æåéçæ¹æ³ï¼ä½å®åå¨é¿æä¼¯èªç°å¢ä¸­çæç¨é¢è¨èææ°ï¼åæ¬æ¨è¨è³æéæéãèªè¨è¤éæ§åç¿»è­¯åå·®ãæ¬ç ç©¶å¨é¢è©ä¼°äº 8 å LLMï¼åæ¬ä¸è¬å¤èªè¨æ¨¡ååéèªæ¨¡åï¼å¨ä¸åçå¿çå¥åº·è³æéï¼ä¾å¦ AraDepSuãDreadditãMedMCQAï¼ä¸ï¼æ¢è¨æç¤ºè¨­è¨ãèªè¨éç½®ï¼é¿æä¼¯èªåæèç¿»è­¯å¾çè±èªï¼åä¹äº¦ç¶ï¼åå°æ¬¡æç¤ºå°è¨ºæ·è¡¨ç¾çå½±é¿ãæåç¼ç¾æç¤ºå·¥ç¨é¡¯èå½±é¿ LLM åæ¸ï¼ä¸»è¦æ¯ç±æ¼æ¸å°äºèªªæéµå¾ªï¼æåççµæ§åæç¤ºå¨å¤é¡è³æéä¸åªæ¼çµæ§è¼ä¸å´è¬¹çè®é«ï¼å¹³åå·®ç°çº 14.5%ãéç¶èªè¨å°è¡¨ç¾çå½±é¿ä¸å¤§ï¼ä½æ¨¡åé¸æè¢«è­æè³ééè¦ï¼Phi-3.5 MoE å¨å¹³è¡¡æºç¢ºåº¦æ¹é¢è¡¨ç¾åºè²ï¼ç¹å¥æ¯å¨äºååé¡æ¹é¢ï¼è Mistral NeMo å¨å´éæ§é æ¸¬ä»»åçå¹³åçµå°èª¤å·®æ¹é¢è¡¨ç¾åºåªç°çè¡¨ç¾ãå°æ¬¡æç¤ºå§çµæ¹åè¡¨ç¾ï¼ç¹å¥æ¯å¨ GPT-4o Mini ä¸è§å¯å°å¤é¡åé¡çé¡¯èå¢çï¼å°æºç¢ºåº¦æé«äºå¹³å 1.58 åãéäºç¼ç¾å¼·èª¿äºæç¤ºæä½³åãå¤èªè¨åæåå°æ¬¡å­¸ç¿å°æ¼éç¼é©åæåä¸ææçåºæ¼ LLM çå¿çå¥åº·å·¥å·ä»¥æåé¿æä¼¯èªäººå£çéè¦æ§ã</paragraph>

##### **MEXA-CTP: Mode Experts Cross-Attention for Clinical Trial Outcome Prediction**
2501.06823v1 by Yiqing Zhang, Xiaozhong Liu, Fabricio Murai

Clinical trials are the gold standard for assessing the effectiveness and
safety of drugs for treating diseases. Given the vast design space of drug
molecules, elevated financial cost, and multi-year timeline of these trials,
research on clinical trial outcome prediction has gained immense traction.
Accurate predictions must leverage data of diverse modes such as drug
molecules, target diseases, and eligibility criteria to infer successes and
failures. Previous Deep Learning approaches for this task, such as HINT, often
require wet lab data from synthesized molecules and/or rely on prior knowledge
to encode interactions as part of the model architecture. To address these
limitations, we propose a light-weight attention-based model, MEXA-CTP, to
integrate readily-available multi-modal data and generate effective
representations via specialized modules dubbed "mode experts", while avoiding
human biases in model design. We optimize MEXA-CTP with the Cauchy loss to
capture relevant interactions across modes. Our experiments on the Trial
Outcome Prediction (TOP) benchmark demonstrate that MEXA-CTP improves upon
existing approaches by, respectively, up to 11.3% in F1 score, 12.2% in PR-AUC,
and 2.5% in ROC-AUC, compared to HINT. Ablation studies are provided to
quantify the effectiveness of each component in our proposed method.

æè¦ï¼è¨åºè©¦é©æ¯è©ä¼°æ²»çç¾ççè¥ç©æææ§åå®å¨æ§çé»éæ¨æºãéæ¼è¥ç©åå­çå»£æ³è¨­è¨ç©ºéãé«æçè²¡åææ¬åéäºè©¦é©å¤å¹´çæéè¡¨ï¼è¨åºè©¦é©çµæé æ¸¬çç ç©¶ç²å¾äºå·¨å¤§çéæ³¨ãæºç¢ºçé æ¸¬å¿é å©ç¨è¥ç©åå­ãç®æ¨ç¾çåç¬¦åè³æ ¼æ¨æºç­å¤ç¨®æ¨¡å¼çæ¸æä¾æ¨æ·æååå¤±æãæ­¤ä»»åçååæ·±åº¦å­¸ç¿æ¹æ³ï¼ä¾å¦ HINTï¼éå¸¸éè¦åæåå­çæ¿å¯¦é©å®¤æ¸æå/æä¾è³´æ¼åé©ç¥è­å°äº¤äºç·¨ç¢¼çºæ¨¡åæ¶æ§çä¸é¨åãçºäºè§£æ±ºéäºéå¶ï¼æåæåºäºä¸åè¼éç´çåºæ¼æ³¨æåçæ¨¡å MEXA-CTPï¼ä»¥æ´åç¾æçå¤æ¨¡å¼æ¸æä¸¦ééç¨±çºãæ¨¡å¼å°å®¶ãçå°ç¨æ¨¡çµç¢çææçè¡¨ç¤ºï¼åæé¿åæ¨¡åè¨­è¨ä¸­çäººçºåå·®ãæåä½¿ç¨æ¯è¥¿æå¤±å½æ¸æä½³å MEXA-CTPï¼ä»¥ææè·¨æ¨¡å¼ç¸éçäº¤äºãæåå¨è©¦é©çµæé æ¸¬ (TOP) åºæºä¸çå¯¦é©è¡¨æï¼è HINT ç¸æ¯ï¼MEXA-CTP åå¥å¨ F1 åæ¸ä¸æé«äº 11.3%ãPR-AUC ä¸æé«äº 12.2%ãROC-AUC ä¸æé«äº 2.5%ãæä¾äºæ¶èç ç©¶ä¾éåæåæåºçæ¹æ³ä¸­æ¯åçµä»¶çæææ§ã


### LLM
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2025-01-24**|**Mitigating GenAI-powered Evidence Pollution for Out-of-Context Multimodal Misinformation Detection**|Zehong Yan et.al.|[2501.14728v1](http://arxiv.org/abs/2501.14728v1)|null|
|**2025-01-24**|**Do LLMs Provide Consistent Answers to Health-Related Questions across Languages?**|Ipek Baris Schlicht et.al.|[2501.14719v1](http://arxiv.org/abs/2501.14719v1)|null|
|**2025-01-24**|**Towards Better Understanding Table Instruction Tuning: Decoupling the Effects from Data versus Models**|Naihao Deng et.al.|[2501.14717v1](http://arxiv.org/abs/2501.14717v1)|null|
|**2025-01-24**|**FlexiGPT: Pruning and Extending Large Language Models with Low-Rank Weight Sharing**|James Seale Smith et.al.|[2501.14713v1](http://arxiv.org/abs/2501.14713v1)|null|
|**2025-01-24**|**The Karp Dataset**|Mason DiCicco et.al.|[2501.14705v1](http://arxiv.org/abs/2501.14705v1)|null|
|**2025-01-24**|**NLP-based assessment of prescription appropriateness from Italian referrals**|Vittorio Torri et.al.|[2501.14701v1](http://arxiv.org/abs/2501.14701v1)|null|
|**2025-01-24**|**Rethinking Table Instruction Tuning**|Naihao Deng et.al.|[2501.14693v1](http://arxiv.org/abs/2501.14693v1)|null|
|**2025-01-24**|**Approach to Designing CV Systems for Medical Applications: Data, Architecture and AI**|Dmitry Ryabtsev et.al.|[2501.14689v1](http://arxiv.org/abs/2501.14689v1)|null|
|**2025-01-24**|**Decoding Generalization from Memorization in Deep Neural Networks**|Simran Ketha et.al.|[2501.14687v1](http://arxiv.org/abs/2501.14687v1)|null|
|**2025-01-24**|**Rethinking Foundation Models for Medical Image Classification through a Benchmark Study on MedMNIST**|Fuping Wu et.al.|[2501.14685v1](http://arxiv.org/abs/2501.14685v1)|null|
|**2025-01-24**|**Surface Vision Mamba: Leveraging Bidirectional State Space Model for Efficient Spherical Manifold Representation**|Rongzhao He et.al.|[2501.14679v1](http://arxiv.org/abs/2501.14679v1)|null|
|**2025-01-24**|**A Predictive Approach for Enhancing Accuracy in Remote Robotic Surgery Using Informer Model**|Muhammad Hanif Lashari et.al.|[2501.14678v1](http://arxiv.org/abs/2501.14678v1)|null|
|**2025-01-24**|**State Space Models for Extractive Summarization in Low Resource Scenarios**|Nisrine Ait Khayi et.al.|[2501.14673v1](http://arxiv.org/abs/2501.14673v1)|null|
|**2025-01-24**|**MedAgentBench: Dataset for Benchmarking LLMs as Agents in Medical Applications**|Yixing Jiang et.al.|[2501.14654v1](http://arxiv.org/abs/2501.14654v1)|[link](https://github.com/stanfordmlgroup/medagentbench)|
|**2025-01-24**|**Federated Domain Generalization with Data-free On-server Gradient Matching**|Trong-Binh Nguyen et.al.|[2501.14653v1](http://arxiv.org/abs/2501.14653v1)|null|
|**2025-01-24**|**Investigating the (De)Composition Capabilities of Large Language Models in Natural-to-Formal Language Conversion**|Ziyao Xu et.al.|[2501.14649v1](http://arxiv.org/abs/2501.14649v1)|[link](https://github.com/xzy-xzy/dedc)|
|**2025-01-24**|**Whisper D-SGD: Correlated Noise Across Agents for Differentially Private Decentralized Learning**|Angelo Rodio et.al.|[2501.14644v1](http://arxiv.org/abs/2501.14644v1)|[link](https://github.com/arodio/whisperdsgd)|
|**2025-01-24**|**Recommending Actionable Strategies: A Semantic Approach to Integrating Analytical Frameworks with Decision Heuristics**|Renato Ghisellini et.al.|[2501.14634v1](http://arxiv.org/abs/2501.14634v1)|null|
|**2025-01-24**|**Extracting Problem Structure with LLMs for Optimized SAT Local Search**|AndrÃ© Schilder et.al.|[2501.14630v1](http://arxiv.org/abs/2501.14630v1)|null|
|**2025-01-24**|**ACT-JEPA: Joint-Embedding Predictive Architecture Improves Policy Representation Learning**|Aleksandar Vujinovic et.al.|[2501.14622v1](http://arxiv.org/abs/2501.14622v1)|null|
|**2025-01-24**|**Funzac at CoMeDi Shared Task: Modeling Annotator Disagreement from Word-In-Context Perspectives**|Olufunke O. Sarumi et.al.|[2501.14617v1](http://arxiv.org/abs/2501.14617v1)|[link](https://github.com/funzac/comedi)|
|**2025-01-24**|**Leveraging Spatial Cues from Cochlear Implant Microphones to Efficiently Enhance Speech Separation in Real-World Listening Scenes**|Feyisayo Olalere et.al.|[2501.14610v1](http://arxiv.org/abs/2501.14610v1)|null|
|**2025-01-24**|**Age and Power Minimization via Meta-Deep Reinforcement Learning in UAV Networks**|Sankani Sarathchandra et.al.|[2501.14603v1](http://arxiv.org/abs/2501.14603v1)|null|
|**2025-01-24**|**ZETA: Leveraging Z-order Curves for Efficient Top-k Attention**|Qiuhao Zeng et.al.|[2501.14577v1](http://arxiv.org/abs/2501.14577v1)|null|
|**2025-01-24**|**Leveraging ChatGPT's Multimodal Vision Capabilities to Rank Satellite Images by Poverty Level: Advancing Tools for Social Science Research**|Hamid Sarmadi et.al.|[2501.14546v1](http://arxiv.org/abs/2501.14546v1)|null|
|**2025-01-24**|**Distributed Conformal Prediction via Message Passing**|Haifeng Wen et.al.|[2501.14544v1](http://arxiv.org/abs/2501.14544v1)|null|
|**2025-01-24**|**VERUS-LM: a Versatile Framework for Combining LLMs with Symbolic Reasoning**|Benjamin Callewaert et.al.|[2501.14540v1](http://arxiv.org/abs/2501.14540v1)|null|
|**2025-01-24**|**Idiom Detection in Sorani Kurdish Texts**|Skala Kamaran Omer et.al.|[2501.14528v1](http://arxiv.org/abs/2501.14528v1)|null|
|**2025-01-24**|**WanJuanSiLu: A High-Quality Open-Source Webtext Dataset for Low-Resource Languages**|Jia Yu et.al.|[2501.14506v1](http://arxiv.org/abs/2501.14506v1)|null|
|**2025-01-24**|**Evaluating and Improving Graph to Text Generation with Large Language Models**|Jie He et.al.|[2501.14497v1](http://arxiv.org/abs/2501.14497v1)|[link](https://github.com/probe2/kg_text)|
|**2025-01-24**|**Analyzing the Effect of Linguistic Similarity on Cross-Lingual Transfer: Tasks and Experimental Setups Matter**|Verena Blaschke et.al.|[2501.14491v1](http://arxiv.org/abs/2501.14491v1)|null|
|**2025-01-24**|**RealCritic: Towards Effectiveness-Driven Evaluation of Language Model Critiques**|Zhengyang Tang et.al.|[2501.14492v1](http://arxiv.org/abs/2501.14492v1)|[link](https://github.com/tangzhy/realcritic)|
|**2025-01-24**|**The Pseudo-Dimension of Contracts**|Paul Duetting et.al.|[2501.14474v1](http://arxiv.org/abs/2501.14474v1)|null|
|**2025-01-24**|**Pesti-Gen: Unleashing a Generative Molecule Approach for Toxicity Aware Pesticide Design**|Taehan Kim et.al.|[2501.14469v1](http://arxiv.org/abs/2501.14469v1)|null|
|**2025-01-24**|**Interpretability Analysis of Domain Adapted Dense Retrievers**|Goksenin Yuksel et.al.|[2501.14459v1](http://arxiv.org/abs/2501.14459v1)|null|
|**2025-01-24**|**Understanding and Mitigating Gender Bias in LLMs via Interpretable Neuron Editing**|Zeping Yu et.al.|[2501.14457v1](http://arxiv.org/abs/2501.14457v1)|null|
|**2025-01-24**|**Learning more with the same effort: how randomization improves the robustness of a robotic deep reinforcement learning agent**|LucÃ­a GÃ¼itta-LÃ³pez et.al.|[2501.14443v1](http://arxiv.org/abs/2501.14443v1)|null|
|**2025-01-24**|**Domaino1s: Guiding LLM Reasoning for Explainable Answers in High-Stakes Domains**|Xu Chu et.al.|[2501.14431v1](http://arxiv.org/abs/2501.14431v1)|null|
|**2025-01-24**|**Adaptive Rank Allocation for Federated Parameter-Efficient Fine-Tuning of Language Models**|Fei Wu et.al.|[2501.14406v1](http://arxiv.org/abs/2501.14406v1)|null|
|**2025-01-24**|**SKIL: Semantic Keypoint Imitation Learning for Generalizable Data-efficient Manipulation**|Shengjie Wang et.al.|[2501.14400v1](http://arxiv.org/abs/2501.14400v1)|null|
|**2025-01-24**|**Handling Heterophily in Recommender Systems with Wavelet Hypergraph Diffusion**|Darnbi Sakong et.al.|[2501.14399v1](http://arxiv.org/abs/2501.14399v1)|null|
|**2025-01-24**|**ECTIL: Label-efficient Computational Tumour Infiltrating Lymphocyte (TIL) assessment in breast cancer: Multicentre validation in 2,340 patients with breast cancer**|Yoni Schirris et.al.|[2501.14379v1](http://arxiv.org/abs/2501.14379v1)|null|
|**2025-01-24**|**DRESSing Up LLM: Efficient Stylized Question-Answering via Style Subspace Editing**|Xinyu Ma et.al.|[2501.14371v1](http://arxiv.org/abs/2501.14371v1)|[link](https://github.com/arthurleom/dress-llm)|
|**2025-01-24**|**In System Alignments we Trust! Explainable Alignments via Projections**|Dominique Sommers et.al.|[2501.14360v1](http://arxiv.org/abs/2501.14360v1)|null|
|**2025-01-24**|**HorNets: Learning from Discrete and Continuous Signals with Routing Neural Networks**|Boshko koloski et.al.|[2501.14346v1](http://arxiv.org/abs/2501.14346v1)|[link](https://github.com/bkolosk1/hornets)|
|**2025-01-24**|**Chain-of-Retrieval Augmented Generation**|Liang Wang et.al.|[2501.14342v1](http://arxiv.org/abs/2501.14342v1)|null|
|**2025-01-24**|**Exploring the sustainable scaling of AI dilemma: A projective study of corporations' AI environmental impacts**|ClÃ©ment Desroches et.al.|[2501.14334v1](http://arxiv.org/abs/2501.14334v1)|null|
|**2025-01-24**|**Clear Minds Think Alike: What Makes LLM Fine-tuning Robust? A Study of Token Perplexity**|Chao-Chung Wu et.al.|[2501.14315v1](http://arxiv.org/abs/2501.14315v1)|null|
|**2025-01-24**|**Permutation-based multi-objective evolutionary feature selection for high-dimensional data**|Raquel Espinosa et.al.|[2501.14310v1](http://arxiv.org/abs/2501.14310v1)|null|
|**2025-01-24**|**Learning Primitive Relations for Compositional Zero-Shot Learning**|Insu Lee et.al.|[2501.14308v1](http://arxiv.org/abs/2501.14308v1)|null|
|**2025-01-24**|**A Zero-Shot LLM Framework for Automatic Assignment Grading in Higher Education**|Calvin Yeung et.al.|[2501.14305v1](http://arxiv.org/abs/2501.14305v1)|[link](https://github.com/calvinyeungck/automated_assignment_grading)|
|**2025-01-24**|**MASTER: A Multi-Agent System with LLM Specialized MCTS**|Bingzheng Gan et.al.|[2501.14304v1](http://arxiv.org/abs/2501.14304v1)|null|
|**2025-01-24**|**Fast Think-on-Graph: Wider, Deeper and Faster Reasoning of Large Language Model on Knowledge Graph**|Xujian Liang et.al.|[2501.14300v1](http://arxiv.org/abs/2501.14300v1)|[link](https://github.com/dosonleung/fasttog)|
|**2025-01-24**|**Examining Alignment of Large Language Models through Representative Heuristics: The Case of Political Stereotypes**|Sullam Jeoung et.al.|[2501.14294v1](http://arxiv.org/abs/2501.14294v1)|null|
|**2025-01-24**|**A Comprehensive Framework for Semantic Similarity Detection Using Transformer Architectures and Enhanced Ensemble Techniques**|Lifu Gao et.al.|[2501.14288v1](http://arxiv.org/abs/2501.14288v1)|null|
|**2025-01-24**|**Global Semantic-Guided Sub-image Feature Weight Allocation in High-Resolution Large Vision-Language Models**|Yuxuan Liang et.al.|[2501.14276v1](http://arxiv.org/abs/2501.14276v1)|null|
|**2025-01-24**|**Leveraging Online Olympiad-Level Math Problems for LLMs Training and Contamination-Resistant Evaluation**|Sadegh Mahdavi et.al.|[2501.14275v1](http://arxiv.org/abs/2501.14275v1)|[link](https://github.com/dsl-lab/aops)|
|**2025-01-24**|**Hierarchical Time-Aware Mixture of Experts for Multi-Modal Sequential Recommendation**|Shengzhe Zhang et.al.|[2501.14269v1](http://arxiv.org/abs/2501.14269v1)|[link](https://github.com/SStarCCat/HM4SR)|
|**2025-01-24**|**Pre-train and Fine-tune: Recommenders as Large Models**|Zhenhao Jiang et.al.|[2501.14268v1](http://arxiv.org/abs/2501.14268v1)|null|
|**2025-01-24**|**Siren: A Learning-Based Multi-Turn Attack Framework for Simulating Real-World Human Jailbreak Behaviors**|Yi Zhao et.al.|[2501.14250v1](http://arxiv.org/abs/2501.14250v1)|[link](https://github.com/yiyiyizhao/siren)|
|**2025-01-24**|**Humanity's Last Exam**|Long Phan et.al.|[2501.14249v1](http://arxiv.org/abs/2501.14249v1)|null|
|**2025-01-24**|**Detection and Classification of Acute Lymphoblastic Leukemia Utilizing Deep Transfer Learning**|Md. Abu Ahnaf Mollick et.al.|[2501.14228v1](http://arxiv.org/abs/2501.14228v1)|null|
|**2025-01-24**|**Multi-agent KTO: Reinforcing Strategic Interactions of Large Language Model in Language Game**|Rong Ye et.al.|[2501.14225v1](http://arxiv.org/abs/2501.14225v1)|null|
|**2025-01-24**|**Top Ten Challenges Towards Agentic Neural Graph Databases**|Jiaxin Bai et.al.|[2501.14224v1](http://arxiv.org/abs/2501.14224v1)|null|
|**2025-01-24**|**TFG-Flow: Training-free Guidance in Multimodal Generative Flow**|Haowei Lin et.al.|[2501.14216v1](http://arxiv.org/abs/2501.14216v1)|null|
|**2025-01-24**|**PuzzleGPT: Emulating Human Puzzle-Solving Ability for Time and Location Prediction**|Hammad Ayyubi et.al.|[2501.14210v1](http://arxiv.org/abs/2501.14210v1)|null|
|**2025-01-24**|**Dynamic Token Reduction during Generation for Vision Language Models**|Xiaoyu Liang et.al.|[2501.14204v1](http://arxiv.org/abs/2501.14204v1)|null|
|**2025-01-24**|**Coordinating Ride-Pooling with Public Transit using Reward-Guided Conservative Q-Learning: An Offline Training and Online Fine-Tuning Reinforcement Learning Framework**|Yulong Hu et.al.|[2501.14199v1](http://arxiv.org/abs/2501.14199v1)|null|
|**2025-01-24**|**Distributed Multi-Agent Coordination Using Multi-Modal Foundation Models**|Saaduddin Mahmud et.al.|[2501.14189v1](http://arxiv.org/abs/2501.14189v1)|null|
|**2025-01-24**|**Dreamweaver: Learning Compositional World Representations from Pixels**|Junyeob Baek et.al.|[2501.14174v1](http://arxiv.org/abs/2501.14174v1)|null|
|**2025-01-24**|**UltraLightSqueezeNet: A Deep Learning Architecture for Malaria Classification with up to 54x fewer trainable parameters for resource constrained devices**|Suresh Babu Nettur et.al.|[2501.14172v1](http://arxiv.org/abs/2501.14172v1)|null|
|**2025-01-24**|**Enhancing Multimodal Entity Linking with Jaccard Distance-based Conditional Contrastive Learning and Contextual Visual Augmentation**|Cong-Duy Nguyen et.al.|[2501.14166v1](http://arxiv.org/abs/2501.14166v1)|null|
|**2025-01-24**|**LoCoML: A Framework for Real-World ML Inference Pipelines**|Kritin Maddireddy et.al.|[2501.14165v1](http://arxiv.org/abs/2501.14165v1)|null|
|**2025-01-24**|**Test-Time Code-Switching for Cross-lingual Aspect Sentiment Triplet Extraction**|Dongming Sheng et.al.|[2501.14144v1](http://arxiv.org/abs/2501.14144v1)|null|
|**2025-01-23**|**Reinforcement Learning Platform for Adversarial Black-box Attacks with Custom Distortion Filters**|Soumyendu Sarkar et.al.|[2501.14122v1](http://arxiv.org/abs/2501.14122v1)|null|
|**2025-01-23**|**On the Transfer of Knowledge in Quantum Algorithms**|Esther Villar-Rodriguez et.al.|[2501.14120v1](http://arxiv.org/abs/2501.14120v1)|null|
|**2025-01-23**|**Autonomous Structural Memory Manipulation for Large Language Models Using Hierarchical Embedding Augmentation**|Derek Yotheringhay et.al.|[2501.14119v1](http://arxiv.org/abs/2501.14119v1)|null|
|**2025-01-23**|**LeCoPCR: Legal Concept-guided Prior Case Retrieval for European Court of Human Rights cases**|T. Y. S. S. Santosh et.al.|[2501.14114v1](http://arxiv.org/abs/2501.14114v1)|null|
|**2025-01-23**|**RELexED: Retrieval-Enhanced Legal Summarization with Exemplar Diversity**|T. Y. S. S. Santosh et.al.|[2501.14113v1](http://arxiv.org/abs/2501.14113v1)|null|
|**2025-01-23**|**CoPERLex: Content Planning with Event-based Representations for Legal Case Summarization**|T. Y. S. S. Santosh et.al.|[2501.14112v1](http://arxiv.org/abs/2501.14112v1)|null|
|**2025-01-23**|**MedSlice: Fine-Tuned Large Language Models for Secure Clinical Note Sectioning**|Joshua Davis et.al.|[2501.14105v1](http://arxiv.org/abs/2501.14105v1)|[link](https://github.com/lindvalllab/medslice)|
|**2025-01-23**|**Communicating Activations Between Language Model Agents**|Vignav Ramesh et.al.|[2501.14082v1](http://arxiv.org/abs/2501.14082v1)|null|
|**2025-01-23**|**Enhancing Biomedical Relation Extraction with Directionality**|Po-Ting Lai et.al.|[2501.14079v1](http://arxiv.org/abs/2501.14079v1)|[link](https://github.com/ncbi-nlp/bioredirect)|
|**2025-01-23**|**LLMs are Vulnerable to Malicious Prompts Disguised as Scientific Language**|Yubin Ge et.al.|[2501.14073v1](http://arxiv.org/abs/2501.14073v1)|null|
|**2025-01-23**|**Revisiting CLIP: Efficient Alignment of 3D MRI and Tabular Data using Domain-Specific Foundation Models**|Jakob Krogh Petersen et.al.|[2501.14051v1](http://arxiv.org/abs/2501.14051v1)|[link](https://github.com/jakekrogh/3d-clip-for-brain-mri)|
|**2025-01-23**|**GraphRAG under Fire**|Jiacheng Liang et.al.|[2501.14050v1](http://arxiv.org/abs/2501.14050v1)|null|
|**2025-01-23**|**SIDDA: SInkhorn Dynamic Domain Adaptation for Image Classification with Equivariant Neural Networks**|Sneh Pandya et.al.|[2501.14048v1](http://arxiv.org/abs/2501.14048v1)|[link](https://github.com/deepskies/gcnn_da)|
|**2025-01-23**|**Leveraging Large Language Models to Analyze Emotional and Contextual Drivers of Teen Substance Use in Online Discussions**|Jianfeng Zhu et.al.|[2501.14037v1](http://arxiv.org/abs/2501.14037v1)|null|
|**2025-01-23**|**Human-Alignment Influences the Utility of AI-assisted Decision Making**|Nina L. Corvelo Benz et.al.|[2501.14035v1](http://arxiv.org/abs/2501.14035v1)|[link](https://github.com/networks-learning/human-alignment-study)|
|**2025-01-23**|**CRPO: Confidence-Reward Driven Preference Optimization for Machine Translation**|Guofeng Cui et.al.|[2501.13927v1](http://arxiv.org/abs/2501.13927v1)|null|
|**2025-01-23**|**Can We Generate Images with CoT? Let's Verify and Reinforce Image Generation Step by Step**|Ziyu Guo et.al.|[2501.13926v1](http://arxiv.org/abs/2501.13926v1)|[link](https://github.com/ziyuguo99/image-generation-cot)|
|**2025-01-23**|**Towards Robust Multimodal Open-set Test-time Adaptation via Adaptive Entropy-aware Optimization**|Hao Dong et.al.|[2501.13924v1](http://arxiv.org/abs/2501.13924v1)|[link](https://github.com/donghao51/aeo)|
|**2025-01-23**|**The Breeze 2 Herd of Models: Traditional Chinese LLMs Based on Llama with Vision-Aware and Function-Calling Capabilities**|Chan-Jan Hsu et.al.|[2501.13921v1](http://arxiv.org/abs/2501.13921v1)|null|
|**2025-01-23**|**IMAGINE-E: Image Generation Intelligence Evaluation of State-of-the-art Text-to-Image Models**|Jiayi Lei et.al.|[2501.13920v1](http://arxiv.org/abs/2501.13920v1)|null|
|**2025-01-23**|**Temporal Preference Optimization for Long-Form Video Understanding**|Rui Li et.al.|[2501.13919v1](http://arxiv.org/abs/2501.13919v1)|null|
|**2025-01-23**|**Improving Video Generation with Human Feedback**|Jie Liu et.al.|[2501.13918v1](http://arxiv.org/abs/2501.13918v1)|null|
|**2025-01-23**|**Analysis of Indic Language Capabilities in LLMs**|Aatman Vaidya et.al.|[2501.13912v1](http://arxiv.org/abs/2501.13912v1)|null|
|**2025-01-23**|**Transfer Learning of Surrogate Models via Domain Affine Transformation Across Synthetic and Real-World Benchmarks**|Shuaiqun Pan et.al.|[2501.14012v1](http://arxiv.org/abs/2501.14012v1)|null|
|**2025-01-23**|**QuanTaxo: A Quantum Approach to Self-Supervised Taxonomy Expansion**|Sahil Mishra et.al.|[2501.14011v1](http://arxiv.org/abs/2501.14011v1)|[link](https://github.com/sahilmishra0012/quantaxo)|
|**2025-01-23**|**PointOBB-v3: Expanding Performance Boundaries of Single Point-Supervised Oriented Object Detection**|Peiyuan Zhang et.al.|[2501.13898v1](http://arxiv.org/abs/2501.13898v1)|[link](https://github.com/zpywhu/pointobb-v3)|

#### Abstracts
##### **Mitigating GenAI-powered Evidence Pollution for Out-of-Context Multimodal Misinformation Detection**
2501.14728v1 by Zehong Yan, Peng Qi, Wynne Hsu, Mong Li Lee

While large generative artificial intelligence (GenAI) models have achieved
significant success, they also raise growing concerns about online information
security due to their potential misuse for generating deceptive content.
Out-of-context (OOC) multimodal misinformation detection, which often retrieves
Web evidence to identify the repurposing of images in false contexts, faces the
issue of reasoning over GenAI-polluted evidence to derive accurate predictions.
Existing works simulate GenAI-powered pollution at the claim level with
stylistic rewriting to conceal linguistic cues, and ignore evidence-level
pollution for such information-seeking applications. In this work, we
investigate how polluted evidence affects the performance of existing OOC
detectors, revealing a performance degradation of more than 9 percentage
points. We propose two strategies, cross-modal evidence reranking and
cross-modal claim-evidence reasoning, to address the challenges posed by
polluted evidence. Extensive experiments on two benchmark datasets show that
these strategies can effectively enhance the robustness of existing
out-of-context detectors amidst polluted evidence.

æè¦ï¼åç®¡å¤§åçæå¼äººå·¥æºè½ (GenAI) æ¨¡åå·²åå¾é¡¯èçæåï¼ä½ç±æ¼å®åå¯è½è¢«èª¤ç¨ä¾ç¢çå·ææ¬ºé¨æ§çå§å®¹ï¼å æ­¤ä¹å¼ç¼äºäººåå°ç·ä¸è³è¨å®å¨çææã
èªå¢å¤ (OOC) å¤æ¨¡æé¯èª¤è³è¨åµæ¸¬éå¸¸ææ·åç¶²è·¯è­æä¾è­å¥é¯èª¤èªå¢ä¸­å½±åçåå©ç¨ï¼å®é¢è¨èå¿é å°åå° GenAI æ±æçè­æé²è¡æ¨çæè½å¾åºæºç¢ºé æ¸¬çåé¡ã
ç¾æä½åæä»¥é¢¨æ ¼åæ¹å¯«çæ¹å¼å¨å®£ç¨±å±¤ç´æ¨¡æ¬ç± GenAI é©åçæ±æï¼ä»¥é±èèªè¨ç·ç´¢ï¼ä¸¦å¿½ç¥æ­¤é¡è³è¨æå°æç¨ç¨å¼çè­æå±¤ç´æ±æãå¨éé å·¥ä½ä¸­ï¼æåæ¢è¨åå°æ±æçè­æå¦ä½å½±é¿ç¾æ OOC åµæ¸¬å¨çæè½ï¼æ­é²äºè¶é 9 åç¾åé»çæè½ä¸éãæåæåºäºå©ç¨®ç­ç¥ï¼äº¤åæ¨¡æè­æéæ°æåºåäº¤åæ¨¡æå®£ç¨±-è­ææ¨çï¼ä¾è§£æ±ºåå°æ±æçè­ææå¸¶ä¾çææ°ãå¨å©ååºæºè³æéä¸é²è¡çå»£æ³å¯¦é©é¡¯ç¤ºï¼éäºç­ç¥å¯ä»¥å¨åå°æ±æçè­æä¸­æææåç¾æèªå¢å¤åµæ¸¬å¨çç©©å¥æ§ã

##### **Do LLMs Provide Consistent Answers to Health-Related Questions across Languages?**
2501.14719v1 by Ipek Baris Schlicht, Zhixue Zhao, Burcu Sayin, Lucie Flek, Paolo Rosso

Equitable access to reliable health information is vital for public health,
but the quality of online health resources varies by language, raising concerns
about inconsistencies in Large Language Models (LLMs) for healthcare. In this
study, we examine the consistency of responses provided by LLMs to
health-related questions across English, German, Turkish, and Chinese. We
largely expand the HealthFC dataset by categorizing health-related questions by
disease type and broadening its multilingual scope with Turkish and Chinese
translations. We reveal significant inconsistencies in responses that could
spread healthcare misinformation. Our main contributions are 1) a multilingual
health-related inquiry dataset with meta-information on disease categories, and
2) a novel prompt-based evaluation workflow that enables sub-dimensional
comparisons between two languages through parsing. Our findings highlight key
challenges in deploying LLM-based tools in multilingual contexts and emphasize
the need for improved cross-lingual alignment to ensure accurate and equitable
healthcare information.

æè¦ï¼å¯é çå¥åº·è³è¨çå¬å¹³åå¾å°å¬å±è¡çè³ééè¦ï¼
ä½ç¶²è·¯å¥åº·è³æºçåè³ªå èªè¨èç°ï¼éå¼ç¼äºå°å¤§åèªè¨æ¨¡å (LLM) å¨é«çä¿å¥æ¹é¢çä¸ä¸è´æ§çææãå¨éé ç ç©¶ä¸­ï¼æåæ¢è¨äº LLM å°è±èªãå¾·èªãåè³å¶èªåä¸­æçå¥åº·ç¸éåé¡ææä¾åæçä¸è´æ§ãæåééä¾ç¾çé¡ååé¡å¥åº·ç¸éåé¡ï¼ä¸¦ééåè³å¶èªåä¸­æç¿»è­¯æ´å±å¶å¤èªè¨ç¯åï¼å¤§å¹æ´å±äº HealthFC è³æéãæåæ­é²äºåæä¸­å­å¨é¡¯èçä¸ä¸è´æ§ï¼éå¯è½ææ£å¸é«çä¿å¥é¯èª¤è³è¨ãæåçè²¢ç»ä¸»è¦æ 1) ä¸ååå«ç¾çé¡å¥åè³è¨çå¤èªè¨å¥åº·ç¸éæ¥è©¢è³æéï¼ä»¥å 2) ä¸åæ°ç©çæç¤ºå¼è©ä¼°å·¥ä½æµç¨ï¼å®è½ééè§£æå¨å©ç¨®èªè¨ä¹éé²è¡æ¬¡ç¶­åº¦æ¯è¼ãæåçç ç©¶çµæçªé¡¯äºå¨å¤èªè¨ç°å¢ä¸­é¨ç½²åºæ¼ LLM çå·¥å·çä¸»è¦ææ°ï¼ä¸¦å¼·èª¿éè¦æ¹åè·¨èªè¨å°é½ä»¥ç¢ºä¿æºç¢ºä¸å¬å¹³çé«çä¿å¥è³è¨ã

##### **Towards Better Understanding Table Instruction Tuning: Decoupling the Effects from Data versus Models**
2501.14717v1 by Naihao Deng, Sheng Zhang, Henghui Zhu, Shuaichen Chang, Jiani Zhang, Alexander Hanbo Li, Chung-Wei Hang, Hideo Kobayashi, Yiqun Hu, Patrick Ng

Recent advances in natural language processing have leveraged instruction
tuning to enhance Large Language Models (LLMs) for table-related tasks.
However, previous works train different base models with different training
data, lacking an apples-to-apples comparison across the result table LLMs. To
address this, we fine-tune base models from the Mistral, OLMo, and Phi families
on existing public training datasets. Our replication achieves performance on
par with or surpassing existing table LLMs, establishing new state-of-the-art
performance on Hitab, a table question-answering dataset. More importantly,
through systematic out-of-domain evaluation, we decouple the contributions of
training data and the base model, providing insight into their individual
impacts. In addition, we assess the effects of table-specific instruction
tuning on general-purpose benchmarks, revealing trade-offs between
specialization and generalization.

æè¦ï¼èªç¶èªè¨èççææ°é²å±å©ç¨æä»¤èª¿æ´ä¾å¢å¼·å¤§åèªè¨æ¨¡å (LLM) ä»¥å·è¡èè¡¨æ ¼ç¸éçä»»åãç¶èï¼ååçç ç©¶ä½¿ç¨ä¸åçè¨ç·´è³æè¨ç·´ä¸åçåºç¤æ¨¡åï¼ç¼ºä¹å°çµæè¡¨æ ¼ LLM çèæå°èææ¯è¼ãçºäºè§£æ±ºéååé¡ï¼æåå¾®èª¿äº MistralãOLMo å Phi å®¶æä¸­çåºç¤æ¨¡åï¼ä½¿ç¨ç¾æçå¬éè¨ç·´è³æéãæåçè¤è£½å¨èç¾æè¡¨æ ¼ LLM ç¸ç¶æè¶è¶çæè½ä¸åå¾æå°±ï¼å¨è¡¨æ ¼åç­è³æé Hitab ä¸å»ºç«äºæ°çæåé²æè½ãæ´éè¦çæ¯ï¼ééç³»çµ±æ§çé åå¤è©ä¼°ï¼æåè§£è¦äºè¨ç·´è³æååºç¤æ¨¡åçè²¢ç»ï¼æä¾äºå°å¶åå¥å½±é¿çè¦è§£ãæ­¤å¤ï¼æåè©ä¼°äºç¹å®è¡¨æ ¼æä»¤èª¿æ´å°ä¸è¬ç¨éåºæºçå½±é¿ï¼æ­ç¤ºäºå°æ¥­ååæ¦æ¬åä¹éçæ¬è¡¡ã

##### **FlexiGPT: Pruning and Extending Large Language Models with Low-Rank Weight Sharing**
2501.14713v1 by James Seale Smith, Chi-Heng Lin, Shikhar Tuli, Haris Jeelani, Shangqian Gao, Yilin Shen, Hongxia Jin, Yen-Chang Hsu

The rapid proliferation of large language models (LLMs) in natural language
processing (NLP) has created a critical need for techniques that enable
efficient deployment on memory-constrained devices without compromising
performance. We present a method to prune LLMs that selectively prunes model
blocks based on an importance score and replaces them with a low-parameter
replacement strategy. Specifically, we propose a principled metric to replace
each pruned block using a weight-sharing mechanism that leverages unpruned
counterparts from the model and block-specific low-rank adapters. Furthermore,
we facilitate the learning of these replacement blocks with output feature
normalization and an adapter initialization scheme built on low-rank SVD
reconstructions. Empirical evaluations demonstrate substantial performance
gains over existing methods, achieving state-of-the-art performance on 5/6
benchmarks for a compression rate of 30% and 6/6 benchmarks for a compression
rate of 40%. We also demonstrate that our approach can extend smaller models,
boosting performance on 6/6 benchmarks using only ~0.3% tokens of extended
training with minimal additional parameter costs.

æè¦ï¼å¤§åèªè¨æ¨¡åï¼LLMï¼å¨èªç¶èªè¨èçï¼NLPï¼ä¸­çå¿«éæ´æ£ï¼å·²åµé åºå°æè¡çééµéæ±ï¼éäºæè¡å¯ä»¥å¨ä¸å½±é¿æè½çææ³ä¸ï¼å¨åè¨æ¶é«éå¶çè£ç½®ä¸é²è¡ææççé¨ç½²ãæåæåºäºä¸ç¨®ä¿®åª LLM çæ¹æ³ï¼è©²æ¹æ³æ ¹æéè¦æ§åæ¸é¸ææ§å°ä¿®åªæ¨¡ååå¡ï¼ä¸¦ç¨ä½åæ¸æ¿æç­ç¥åä»£å®åãå·é«ä¾èªªï¼æåæåºä¸åæååçææ¨ï¼ä½¿ç¨æ¬éå±äº«æ©å¶æ¿ææ¯åä¿®åªåå¡ï¼è©²æ©å¶å©ç¨æ¨¡åä¸­æªä¿®åªçå°æé¨ååç¹å®åå¡çä½éé©éå¨ãæ­¤å¤ï¼æåä½¿ç¨è¼¸åºç¹å¾µæ­£è¦ååå»ºç«å¨ä½é SVD éå»ºä¸çé©éå¨åå§åæ¹æ¡ï¼ä¿é²éäºæ¿æåå¡çå­¸ç¿ãç¶é©è©ä¼°é¡¯ç¤ºï¼èç¾ææ¹æ³ç¸æ¯ï¼æè½å¤§å¹æåï¼å¨å£ç¸®ççº 30% çææ³ä¸ï¼å¨ 5/6 ååºæºæ¸¬è©¦ä¸­éå°æåé²çæè½ï¼å¨å£ç¸®ççº 40% çææ³ä¸ï¼å¨ 6/6 ååºæºæ¸¬è©¦ä¸­éå°æåé²çæè½ãæåéè­æï¼æåçåæ³å¯ä»¥æ´åè¼å°çæ¨¡åï¼åä½¿ç¨ç´ 0.3% çå»¶ä¼¸è¨ç·´æ¬æ¨ï¼å°±è½å¨ 6/6 ååºæºæ¸¬è©¦ä¸­æåæè½ï¼èé¡å¤çåæ¸ææ¬æ¥µå°ã

##### **The Karp Dataset**
2501.14705v1 by Mason DiCicco, Eamon Worden, Conner Olsen, Nikhil Gangaram, Daniel Reichman, Neil Heffernan

Understanding the mathematical reasoning capabilities of Large Language
Models (LLMs) is a central topic in the study of artificial intelligence. This
new domain necessitates the creation of datasets of reasoning tasks for both
training and benchmarking the performance of LLMs. To this end, we introduce
the Karp dataset: The first dataset composed of detailed proofs of
NP-completeness reductions. The reductions vary in difficulty, ranging from
simple exercises of undergraduate courses to more challenging reductions from
academic papers. We compare the performance of state-of-the-art models on this
task and demonstrate the effect of fine-tuning with the Karp dataset on
reasoning capacity.

æè¦ï¼çè§£å¤§åèªè¨æ¨¡å (LLM) çæ¸å­¸æ¨çè½åæ¯äººå·¥æºæ§ç ç©¶ä¸­çæ ¸å¿ä¸»é¡ãéåæ°é åéè¦å»ºç«æ¨çä»»åçè³æéï¼ä»¥è¨ç·´åè©é LLM çæè½ãçºæ­¤ï¼æåå¼å¥äº Karp è³æéï¼ç¬¬ä¸åç± NP å®å¨æ§ç°¡ç´çè©³ç´°è­æçµæçè³æéãç°¡ç´é£åº¦ä¸ä¸ï¼å¾å¤§å­¸é¨èª²ç¨çç°¡å®ç·´ç¿å°å­¸è¡è«æä¸­æ´å·ææ°æ§çç°¡ç´ãæåæ¯è¼äºæåé²æ¨¡åå¨æ­¤ä»»åä¸çæè½ï¼ä¸¦å±ç¤ºäºä½¿ç¨ Karp è³æéé²è¡å¾®èª¿å°æ¨çè½åçå½±é¿ã

##### **NLP-based assessment of prescription appropriateness from Italian referrals**
2501.14701v1 by Vittorio Torri, Annamaria Bottelli, Michele Ercolanoni, Olivia Leoni, Francesca Ieva

Objective: This study proposes a Natural Language Processing pipeline to
evaluate prescription appropriateness in Italian referrals, where reasons for
prescriptions are recorded only as free text, complicating automated
comparisons with guidelines. The pipeline aims to derive, for the first time, a
comprehensive summary of the reasons behind these referrals and a
quantification of their appropriateness. While demonstrated in a specific case
study, the approach is designed to generalize to other types of examinations.
  Methods: Leveraging embeddings from a transformer-based model, the proposed
approach clusters referral texts, maps clusters to labels, and aligns these
labels with existing guidelines. We present a case study on a dataset of
496,971 referrals, consisting of all referrals for venous echocolordopplers of
the lower limbs between 2019 and 2021 in the Lombardy Region. A sample of 1,000
referrals was manually annotated to validate the results.
  Results: The pipeline exhibited high performance for referrals' reasons
(Prec=92.43%, Rec=83.28%) and excellent results for referrals' appropriateness
(Prec=93.58%, Rec=91.52%) on the annotated subset. Analysis of the entire
dataset identified clusters matching guideline-defined reasons - both
appropriate and inappropriate - as well as clusters not addressed in the
guidelines. Overall, 34.32% of referrals were marked as appropriate, 34.07%
inappropriate, 14.37% likely inappropriate, and 17.24% could not be mapped to
guidelines.
  Conclusions: The proposed pipeline effectively assessed prescription
appropriateness across a large dataset, serving as a valuable tool for health
authorities. Findings have informed the Lombardy Region's efforts to strengthen
recommendations and reduce the burden of inappropriate referrals.

æè¦ï¼<paragraph>ç®çï¼æ¬ç ç©¶æåºä¸åèªç¶èªè¨èçç®¡éï¼ä»¥è©ä¼°ç¾©å¤§å©è½ä»èæ¹çé©ç¶æ§ï¼å çºèæ¹åå åä»¥èªç±æå­è¨éï¼éä½¿å¾èæåçèªååæ¯è¼è®å¾è¤éãè©²ç®¡éæ¨å¨é¦æ¬¡å¾åºéäºè½ä»èå¾åå çå¨é¢æè¦ï¼ä¸¦éåå¶é©ç¶æ§ãéç¶å¨å·é«æ¡ä¾ç ç©¶ä¸­å¾å°è­æï¼ä½è©²æ¹æ³æ¨å¨æ¨å»£å°å¶ä»é¡åçæª¢æ¥ã
æ¹æ³ï¼å©ç¨åºæ¼Transformerçæ¨¡åä¸­çåµå¥ï¼ææåºçæ¹æ³å°è½ä»ææ¬é²è¡åç¾¤ï¼å°åç¾¤å°æå°æ¨ç±¤ï¼ä¸¦å°éäºæ¨ç±¤èç¾ææåå°é½ãæåå° 496,971 åè½ä»çµæçè³æéé²è¡æ¡ä¾ç ç©¶ï¼å¶ä¸­åæ¬ 2019 å¹´è³ 2021 å¹´å«å·´åºå¤§åææä¸è¢éèè¶è²å¤æ®åè½ä»ãæåè¨»éäº 1,000 åè½ä»æ¨£æ¬ä»¥é©è­çµæã
çµæï¼è©²ç®¡éå°è½ä»åå è¡¨ç¾åºé«æ§è½ï¼Prec=92.43%ï¼Rec=83.28%ï¼ï¼ä¸¦ä¸å¨è¨»éå­éä¸­å°è½ä»é©ç¶æ§è¡¨ç¾åºæ¥µå¥½ççµæï¼Prec=93.58%ï¼Rec=91.52%ï¼ãå°æ´åè³æéçåæè­å¥åºèæåå®ç¾©çåå ç¸å¹éçåç¾¤ - é©ç¶åä¸é©ç¶ - ä»¥åæåä¸­æªæ¶åçåç¾¤ãç¸½é«èè¨ï¼34.32% çè½ä»è¢«æ¨è¨çºé©ç¶ï¼34.07% ä¸é©ç¶ï¼14.37% å¯è½ä¸é©ç¶ï¼17.24% ç¡æ³å°æå°æåã
çµè«ï¼ææåºçç®¡éææå°è©ä¼°äºå¤§åè³æéä¸­çèæ¹é©ç¶æ§ï¼æçºè¡çä¸»ç®¡é¨éçå¯¶è²´å·¥å·ãç ç©¶çµæçºå«å·´åºå¤§åå å¼·å»ºè­°åæ¸å°ä¸é©ç¶è½ä»è² æçåªåæä¾äºä¾æã</paragraph>

##### **Rethinking Table Instruction Tuning**
2501.14693v1 by Naihao Deng, Rada Mihalcea

Recent advances in table understanding have focused on instruction-tuning
large language models (LLMs) for table-related tasks. However, existing
research has overlooked the impact of hyperparameter choices and lacks a
comprehensive evaluation of the out-of-domain table understanding ability and
the general capabilities of these table LLMs. In this paper, we evaluate these
abilities in existing table LLMs, and reveal significant declines in both
out-of-domain table understanding and general capabilities compared to their
base models. Through systematic analysis, we show that hyperparameters, such as
learning rate, can significantly influence both table-specific and general
capabilities. Contrary to the existing table instruction-tuning works, we
demonstrate that smaller learning rates and fewer training instances can
enhance table understanding while preserving general capabilities. Based on our
findings, we introduce TAMA, a TAble LLM instruction-tuned from LLaMA 3.1 8B
Instruct, which achieves performance on par with, or surpassing GPT-3.5 and
GPT-4 on table tasks, while maintaining strong out-of-domain generalization and
general capabilities. Our findings highlight the potential for reduced data
annotation costs and more efficient model development through careful
hyperparameter selection.

æè¦ï¼æè¿è¡¨çè§£çé²å±éä¸­å¨æä»¤èª¿æ ¡å¤§åèªè¨æ¨¡å (LLM) ä»¥å·è¡èè¡¨æ ¼ç¸éçä»»åãç¶èï¼ç¾æçç ç©¶å¿½ç¥äºè¶åæ¸é¸æçå½±é¿ï¼ä¸¦ä¸ç¼ºä¹å°é åå¤è¡¨æ ¼çè§£è½ååéäºè¡¨æ ¼ LLM çä¸è¬è½åçå¨é¢è©ä¼°ãå¨æ¬æä¸­ï¼æåè©ä¼°äºç¾æè¡¨æ ¼ LLM ä¸­çéäºè½åï¼ä¸¦æ­ç¤ºäºèå¶åºç¤æ¨¡åç¸æ¯ï¼é åå¤è¡¨æ ¼çè§£åä¸è¬è½åé½æé¡¯èä¸éãééç³»çµ±åæï¼æåè¡¨æè¶åæ¸ï¼ä¾å¦å­¸ç¿çï¼å¯ä»¥é¡¯èå½±é¿ç¹å®è¡¨æ ¼åä¸è¬è½åãèç¾æè¡¨æ ¼æä»¤èª¿æ ¡å·¥ä½ç¸åï¼æåè­æè¼å°çå­¸ç¿çåè¼å°çè¨ç·´å¯¦ä¾å¯ä»¥å¨ä¿çä¸è¬è½åçåæå¢å¼·è¡¨æ ¼çè§£ãæ ¹ææåçç¼ç¾ï¼æåå¼å¥äº TAMAï¼éæ¯ä¸åå¾ LLaMA 3.1 8B Instruct èª¿æ ¡çè¡¨æ ¼ LLMï¼å®å¨è¡¨æ ¼ä»»åä¸å¯¦ç¾äºè GPT-3.5 å GPT-4 ç¸ç¶æè¶è¶çæè½ï¼åæä¿æå¼·å¤§çé åå¤æ¦ååä¸è¬è½åãæåçç¼ç¾å¼·èª¿äºééä»ç´°é¸æè¶åæ¸ï¼éä½è³ææ¨è¨»ææ¬åæ´ææççæ¨¡åéç¼çå¯è½æ§ã

##### **Approach to Designing CV Systems for Medical Applications: Data, Architecture and AI**
2501.14689v1 by Dmitry Ryabtsev, Boris Vasilyev, Sergey Shershakov

This paper introduces an innovative software system for fundus image analysis
that deliberately diverges from the conventional screening approach, opting not
to predict specific diagnoses. Instead, our methodology mimics the diagnostic
process by thoroughly analyzing both normal and pathological features of fundus
structures, leaving the ultimate decision-making authority in the hands of
healthcare professionals. Our initiative addresses the need for objective
clinical analysis and seeks to automate and enhance the clinical workflow of
fundus image examination. The system, from its overarching architecture to the
modular analysis design powered by artificial intelligence (AI) models, aligns
seamlessly with ophthalmological practices. Our unique approach utilizes a
combination of state-of-the-art deep learning methods and traditional computer
vision algorithms to provide a comprehensive and nuanced analysis of fundus
structures. We present a distinctive methodology for designing medical
applications, using our system as an illustrative example. Comprehensive
verification and validation results demonstrate the efficacy of our approach in
revolutionizing fundus image analysis, with potential applications across
various medical domains.

æè¦ï¼æ¬è«æä»ç´¹äºä¸ç¨®åµæ°çè»é«ç³»çµ±ï¼ç¨æ¼ç¼åºå½±ååæï¼å®å»æåé¢å³çµ±çç¯©æª¢æ¹æ³ï¼é¸æä¸é æ¸¬å·é«çè¨ºæ·ãç¸åå°ï¼æåçåææ¹æ³æ¨¡æ¬è¨ºæ·éç¨ï¼å¾¹åºåæç¼åºçµæ§çæ­£å¸¸åççç¹å¾µï¼å°æçµçæ±ºç­æ¬äº¤å°é«çä¿å¥å°æ¥­äººå¡æä¸­ãæåçè¨ç«æ¨å¨æ»¿è¶³å®¢è§è¨åºåæçéæ±ï¼ä¸¦å°æ±èªåååå¼·åç¼åºå½±åæª¢æ¥çè¨åºå·¥ä½æµç¨ãè©²ç³»çµ±å¾å¶æ´é«æ¶æ§å°ç±äººå·¥æºæ§ (AI) æ¨¡åé©åçæ¨¡çµååæè¨­è¨ï¼é½èç¼ç§å¯¦åç¡ç¸«å°é½ãæåç¨ç¹çæ¹æ³çµåäºæåé²çæ·±åº¦å­¸ç¿æ¹æ³åå³çµ±çé»è¦è¦è¦ºæ¼ç®æ³ï¼æä¾ç¼åºçµæ§çå¨é¢ä¸ç´°ç·»çåæãæåæåºäºä¸ç¨®ç¨ç¹çè¨­è¨é«çæç¨æ¹æ³ï¼ä¸¦ä»¥æåçç³»çµ±ä½çºèªªæç¯ä¾ãå¨é¢çé©è­åé©è­çµæè­æäºæåçæ¹æ³å¨é©æ°ç¼åºå½±ååææ¹é¢çæåï¼ä¸¦å·æå¨åç¨®é«çé åçæ½å¨æç¨ã

##### **Decoding Generalization from Memorization in Deep Neural Networks**
2501.14687v1 by Simran Ketha, Venkatakrishnan Ramaswamy

Overparameterized Deep Neural Networks that generalize well have been key to
the dramatic success of Deep Learning in recent years. The reasons for their
remarkable ability to generalize are not well understood yet. It has also been
known that deep networks possess the ability to memorize training data, as
evidenced by perfect or high training accuracies on models trained with
corrupted data that have class labels shuffled to varying degrees.
Concomitantly, such models are known to generalize poorly, i.e. they suffer
from poor test accuracies, due to which it is thought that the act of
memorizing substantially degrades the ability to generalize. It has, however,
been unclear why the poor generalization that accompanies such memorization,
comes about. One possibility is that in the process of training with corrupted
data, the layers of the network irretrievably reorganize their representations
in a manner that makes generalization difficult. The other possibility is that
the network retains significant ability to generalize, but the trained network
somehow chooses to readout in a manner that is detrimental to generalization.
Here, we provide evidence for the latter possibility by demonstrating,
empirically, that such models possess information in their representations for
substantially improved generalization, even in the face of memorization.
Furthermore, such generalization abilities can be easily decoded from the
internals of the trained model, and we build a technique to do so from the
outputs of specific layers of the network. We demonstrate results on multiple
models trained with a number of standard datasets.

æè¦ï¼<paragraph>éåº¦åæ¸åçæ·±åº¦ç¥ç¶ç¶²è·¯å·æè¯å¥½çæ³åæ§ï¼æ¯è¿å¹´ä¾æ·±åº¦å­¸ç¿ç²å¾å·¨å¤§æåçééµãå®åå·æéå¡æ³åè½åçåå å°æªå¾å°å¾å¥½ççè§£ãç¾æå¨ç¥ï¼æ·±åº¦ç¶²è·¯å·æè¨æ¶è¨ç·´è³æçè½åï¼éä¸é»å¾å¨è³ææ¨ç±¤é¨æ©æ´çå°ä¸åç¨åº¦çå·²ææ¯è³æè¨ç·´æ¨¡åä¸­å®ç¾çæé«è¨ç·´æºç¢ºåº¦å°±å¯ä»¥è­æãèæ­¤åæï¼å·²ç¥æ­¤é¡æ¨¡åçæ³åæ§è¼å·®ï¼å³å®åçæ¸¬è©¦æºç¢ºåº¦è¼å·®ï¼å æ­¤äººåèªçºè¨æ¶è¡çºæå¤§å¹éä½æ³åè½åãç¶èï¼ä¸ç´ä¸æ¸æ¥ä¼´é¨æ­¤é¡è¨æ¶èä¾çæ³åæ§è¼å·®çåå ãä¸ç¨®å¯è½æ§æ¯å¨ä½¿ç¨å·²ææ¯è³æè¨ç·´çéç¨ä¸­ï¼ç¶²è·¯çåå±¤æä¸å¯æ½åå°ä»¥ä¸ç¨®é£ä»¥æ³åçæ¹å¼éæ°çµç¹å®åçè¡¨ç¤ºãå¦ä¸ç¨®å¯è½æ§æ¯ç¶²è·¯ä¿çäºé¡¯èçæ³åè½åï¼ä½è¨ç·´å¾çç¶²è·¯å¨æç¨®ç¨åº¦ä¸é¸æä»¥ä¸å©æ¼æ³åçæ¹å¼è®åºãå¨éè£¡ï¼æåééå¯¦è­è­æå¾ä¸ç¨®å¯è½æ§ï¼è­ææ­¤é¡æ¨¡åå¨å¶è¡¨ç¤ºä¸­å·æé¡¯èæ¹åæ³åçè³è¨ï¼å³ä½¿å¨è¨æ¶çææ³ä¸ä¹æ¯å¦æ­¤ãæ­¤å¤ï¼æ­¤é¡æ³åè½åå¯ä»¥è¼é¬å°å¾è¨ç·´æ¨¡åçå§é¨è§£ç¢¼ï¼æåå»ºç«äºä¸ç¨®å¾ç¶²è·¯ç¹å®å±¤çè¼¸åºä¸­é²è¡è§£ç¢¼çæè¡ãæåå±ç¤ºäºä½¿ç¨å¤åæ¨æºè³æéè¨ç·´çæ¨¡åççµæã</paragraph>

##### **Rethinking Foundation Models for Medical Image Classification through a Benchmark Study on MedMNIST**
2501.14685v1 by Fuping Wu, Bartlomiej W. Papiez

Foundation models are widely employed in medical image analysis, due to their
high adaptability and generalizability for downstream tasks. With the
increasing number of foundation models being released, model selection has
become an important issue. In this work, we study the capabilities of
foundation models in medical image classification tasks by conducting a
benchmark study on the MedMNIST dataset. Specifically, we adopt various
foundation models ranging from convolutional to Transformer-based models and
implement both end-to-end training and linear probing for all classification
tasks. The results demonstrate the significant potential of these pre-trained
models when transferred for medical image classification. We further conduct
experiments with different image sizes and various sizes of training data. By
analyzing all the results, we provide preliminary, yet useful insights and
conclusions on this topic.

æè¦ï¼åºç¤æ¨¡åå»£æ³ç¨æ¼é«å­¸å½±ååæï¼å çºå®åå°ä¸æ¸¸ä»»åå·æé«åº¦çé©ææ§åæ¦æ¬æ§ãé¨èç¼å¸çåºç¤æ¨¡åæ¸éè¶ä¾è¶å¤ï¼æ¨¡åé¸æå·²æçºä¸åéè¦åé¡ãå¨éé å·¥ä½ä¸­ï¼æåééå° MedMNIST è³æéé²è¡åºæºç ç©¶ä¾ç ç©¶åºç¤æ¨¡åå¨é«å­¸å½±ååé¡ä»»åä¸­çè½åãå·é«ä¾èªªï¼æåæ¡ç¨äºå¾å·ç©å°åºæ¼ Transformer çæ¨¡åç­åç¨®åºç¤æ¨¡åï¼ä¸¦å°ææåé¡ä»»åå¯¦æ½ç«¯å°ç«¯è¨ç·´åç·æ§æ¢æ¸¬ãçµæè­æäºéäºé è¨ç·´æ¨¡åå¨è½ç§»å°é«å­¸å½±ååé¡æå·æé¡¯èçæ½åãæåé²ä¸æ­¥é²è¡äºä¸åå½±åå¤§å°ååç¨®è¨ç·´è³æå¤§å°çå¯¦é©ãééåæææçµæï¼æåå°æ­¤ä¸»é¡æä¾äºåæ­¥ä½æç¨çè¦è§£åçµè«ã

##### **Surface Vision Mamba: Leveraging Bidirectional State Space Model for Efficient Spherical Manifold Representation**
2501.14679v1 by Rongzhao He, Weihao Zheng

Attention-based methods have demonstrated exceptional performance in
modelling long-range dependencies on spherical cortical surfaces, surpassing
traditional Geometric Deep Learning (GDL) models. However, their extensive
inference time and high memory demands pose challenges for application to large
datasets with limited computing resources. Inspired by the state space model in
computer vision, we introduce the attention-free Vision Mamba (Vim) to
spherical surfaces, presenting a domain-agnostic architecture for analyzing
data on spherical manifolds. Our method achieves surface patching by
representing spherical data as a sequence of triangular patches derived from a
subdivided icosphere. The proposed Surface Vision Mamba (SiM) is evaluated on
multiple neurodevelopmental phenotype regression tasks using cortical surface
metrics from neonatal brains. Experimental results demonstrate that SiM
outperforms both attention- and GDL-based methods, delivering 4.8 times faster
inference and achieving 91.7% lower memory consumption compared to the Surface
Vision Transformer (SiT) under the Ico-4 grid partitioning. Sensitivity
analysis further underscores the potential of SiM to identify subtle cognitive
developmental patterns. The code is available at
https://github.com/Rongzhao-He/surface-vision-mamba.

æè¦ï¼<paragraph>åºæ¼æ³¨æåçæ¹æ³å·²è­æå¨çå½¢ç®è³ªè¡¨é¢ä¸å»ºæ¨¡é·ç¨ä¾è³´æ§æ¹é¢è¡¨ç¾åºè²ï¼è¶è¶äºå³çµ±çå¹¾ä½æ·±åº¦å­¸ç¿ (GDL) æ¨¡åãç¶èï¼å®åå»£æ³çæ¨è«æéåé«è¨æ¶é«éæ±å°æç¨æ¼å·ææééç®è³æºçå¤§åè³æéæ§æææ°ãåé»è¦è¦è¦ºä¸­ççæç©ºéæ¨¡ååç¼ï¼æåå°ç¡æ³¨æåç Vision Mamba (Vim) å¼å¥çå½¢è¡¨é¢ï¼æåºäºä¸åèé åç¡éçæ¶æ§ï¼ç¨æ¼åæçå½¢æµå½¢ä¸çè³æãæåçééå°çå½¢è³æè¡¨ç¤ºçºå¾ç´°åç­è§çé«è¡ççä¸è§å½¢è£ä¸åºåï¼ä¾å¯¦ç¾è¡¨é¢è²¼çãææåºç Surface Vision Mamba (SiM) ä½¿ç¨ä¾èªæ°çåå¤§è¦çç®è³ªè¡¨é¢ææ¨ï¼å¨å¤åç¥ç¶ç¼è²è¡¨ååæ­¸ä»»åä¸é²è¡è©ä¼°ãå¯¦é©çµæè¡¨æï¼èåºæ¼æ³¨æåå GDL çæ¹æ³ç¸æ¯ï¼SiM è¡¨ç¾åºè²ï¼å¨ Ico-4 ç¶²æ ¼åå²ä¸æä¾å¿« 4.8 åçæ¨è«éåº¦ï¼ä¸¦å¯¦ç¾ä½ 91.7% çè¨æ¶é«æ¶èï¼ä½æ¼ Surface Vision Transformer (SiT)ãæææ§åæé²ä¸æ­¥å¼·èª¿äº SiM è­å¥å¾®å¦èªç¥ç¼è²æ¨¡å¼çæ½åãç¨å¼ç¢¼å¯å¨ https://github.com/Rongzhao-He/surface-vision-mamba åå¾ã</paragraph>

##### **A Predictive Approach for Enhancing Accuracy in Remote Robotic Surgery Using Informer Model**
2501.14678v1 by Muhammad Hanif Lashari, Shakil Ahmed, Wafa Batayneh, Ashfaq Khokhar

Precise and real-time estimation of the robotic arm's position on the
patient's side is essential for the success of remote robotic surgery in
Tactile Internet (TI) environments. This paper presents a prediction model
based on the Transformer-based Informer framework for accurate and efficient
position estimation. Additionally, it combines a Four-State Hidden Markov Model
(4-State HMM) to simulate realistic packet loss scenarios. The proposed
approach addresses challenges such as network delays, jitter, and packet loss
to ensure reliable and precise operation in remote surgical applications. The
method integrates the optimization problem into the Informer model by embedding
constraints such as energy efficiency, smoothness, and robustness into its
training process using a differentiable optimization layer. The Informer
framework uses features such as ProbSparse attention, attention distilling, and
a generative-style decoder to focus on position-critical features while
maintaining a low computational complexity of O(L log L). The method is
evaluated using the JIGSAWS dataset, achieving a prediction accuracy of over 90
percent under various network scenarios. A comparison with models such as TCN,
RNN, and LSTM demonstrates the Informer framework's superior performance in
handling position prediction and meeting real-time requirements, making it
suitable for Tactile Internet-enabled robotic surgery.

æè¦ï¼æ©å¨æèå¨çæ£ç«¯çç²¾ç¢ºå³æä½ç½®ä¼°è¨ï¼å°æ¼è§¸è¦ºç¶²è·¯ (TI) ç°å¢ä¸­çé è·æ©å¨äººæè¡æåè³ééè¦ãæ¬ææåºä¸ååºæ¼ Transformer Informer æ¶æ§çé æ¸¬æ¨¡åï¼ä»¥é²è¡æºç¢ºä¸ææççä½ç½®ä¼°è¨ãæ­¤å¤ï¼å®çµåäºä¸ååæé±èé¦¬å¯å¤«æ¨¡å (4-State HMM) ä¾æ¨¡æ¬çå¯¦çå°åéºå¤±æå¢ãææåºçæ¹æ³å¯ä»¥è§£æ±ºç¶²è·¯å»¶é²ãæååå°åéºå¤±ç­ææ°ï¼ä»¥ç¢ºä¿é è·æè¡æç¨ä¸­çå¯é ä¸ç²¾ç¢ºæä½ãæ­¤æ¹æ³ééå°è½éæçãå¹³æ»åº¦åç©©å¥æ§ç­ç´æåµå¥å¶è¨ç·´éç¨ä¸­ï¼å°æä½³ååé¡æ´åå° Informer æ¨¡åä¸­ï¼ä¸¦ä½¿ç¨å¯å¾®åæä½³åå±¤ãInformer æ¶æ§ä½¿ç¨ ProbSparse æ³¨æåãæ³¨æåèååçæå¼è§£ç¢¼å¨ç­åè½ï¼å°æ³¨æ¼ä½ç½®ééµç¹å¾µï¼åæç¶­æ O(L log L) çä½è¨ç®è¤éåº¦ãæ­¤æ¹æ³ä½¿ç¨ JIGSAWS è³æéé²è¡è©ä¼°ï¼å¨åç¨®ç¶²è·¯æå¢ä¸éæè¶é 90% çé æ¸¬æºç¢ºåº¦ãè TCNãRNN å LSTM ç­æ¨¡åçæ¯è¼ï¼è­æäº Informer æ¶æ§å¨èçä½ç½®é æ¸¬åæ»¿è¶³å³æéæ±æ¹é¢çåªç°æè½ï¼ä½¿å¶é©ç¨æ¼è§¸è¦ºç¶²è·¯åç¨çæ©å¨äººæè¡ã

##### **State Space Models for Extractive Summarization in Low Resource Scenarios**
2501.14673v1 by Nisrine Ait Khayi

Extractive summarization involves selecting the most relevant sentences from
a text. Recently, researchers have focused on advancing methods to improve
state-of-the-art results in low-resource settings. Motivated by these
advancements, we propose the MPoincareSum method. This method applies the Mamba
state space model to generate the semantics of reviews and sentences, which are
then concatenated. A Poincare compression is used to select the most meaningful
features, followed by the application of a linear layer to predict sentence
relevance based on the corresponding review. Finally, we paraphrase the
relevant sentences to create the final summary. To evaluate the effectiveness
of MPoincareSum, we conducted extensive experiments using the Amazon review
dataset. The performance of the method was assessed using ROUGE scores. The
experimental results demonstrate that MPoincareSum outperforms several existing
approaches in the literature

æè¦ï¼èåå¼æè¦æ¶åå¾ææ¬ä¸­é¸åæç¸éçå¥å­ãæè¿ï¼ç ç©¶äººå¡å°æ³¨æ¼é²æ­¥çæ¹æ³ï¼ä»¥æ¹åä½è³æºè¨­å®ä¸­çæåé²çµæãåå°éäºé²å±çæ¿åµï¼æåæåº MPoincareSum æ¹æ³ãæ­¤æ¹æ³æç¨ Mamba çæç©ºéæ¨¡åä¾ç¢çè©è«åå¥å­çèªç¾©ï¼ç¶å¾å°å¶ä¸²æ¥ãä½¿ç¨ Poincare å£ç¸®ä¾é¸ææææç¾©çç¹å¾µï¼ç¶å¾æç¨ç·æ§å±¤æ ¹æå°æçè©è«é æ¸¬å¥å­ç¸éæ§ãæå¾ï¼æåå°ç¸éå¥å­é²è¡æ¹å¯«ï¼ä»¥å»ºç«æçµæè¦ãçºäºè©ä¼° MPoincareSum çæææ§ï¼æåä½¿ç¨ Amazon è©è«è³æéé²è¡äºå»£æ³çå¯¦é©ãä½¿ç¨ ROUGE åæ¸è©ä¼°æ¹æ³çæè½ãå¯¦é©çµæè¡¨æï¼MPoincareSum åªæ¼æç»ä¸­ç¾æçå¹¾ç¨®æ¹æ³

##### **MedAgentBench: Dataset for Benchmarking LLMs as Agents in Medical Applications**
2501.14654v1 by Yixing Jiang, Kameron C. Black, Gloria Geng, Danny Park, Andrew Y. Ng, Jonathan H. Chen

Recent large language models (LLMs) have demonstrated significant
advancements, particularly in their ability to serve as agents thereby
surpassing their traditional role as chatbots. These agents can leverage their
planning and tool utilization capabilities to address tasks specified at a high
level. However, a standardized dataset to benchmark the agent capabilities of
LLMs in medical applications is currently lacking, making the evaluation of
LLMs on complex tasks in interactive healthcare environments challenging. To
address this gap, we introduce MedAgentBench, a broad evaluation suite designed
to assess the agent capabilities of large language models within medical
records contexts. MedAgentBench encompasses 100 patient-specific
clinically-derived tasks from 10 categories written by human physicians,
realistic profiles of 100 patients with over 700,000 data elements, a
FHIR-compliant interactive environment, and an accompanying codebase. The
environment uses the standard APIs and communication infrastructure used in
modern EMR systems, so it can be easily migrated into live EMR systems.
MedAgentBench presents an unsaturated agent-oriented benchmark that current
state-of-the-art LLMs exhibit some ability to succeed at. The best model
(GPT-4o) achieves a success rate of 72%. However, there is still substantial
space for improvement to give the community a next direction to optimize.
Furthermore, there is significant variation in performance across task
categories. MedAgentBench establishes this and is publicly available at
https://github.com/stanfordmlgroup/MedAgentBench , offering a valuable
framework for model developers to track progress and drive continuous
improvements in the agent capabilities of large language models within the
medical domain.

æè¦ï¼<paragraph>æè¿çå¤§åè¯­è¨æ¨¡å (LLM) å·²å±ç¤ºåºæ¾èçè¿æ­¥ï¼ç¹å«æ¯å¨å¶ä½ä¸ºä»£ççè½åæ¹é¢ï¼ä»èè¶è¶äºå¶ä½ä¸ºèå¤©æºå¨äººçä¼ ç»è§è²ãè¿äºä»£çå¯ä»¥å©ç¨å¶è§ååå·¥å·å©ç¨è½åæ¥è§£å³å¨é«å±æå®çä»»å¡ãç¶èï¼ç®åç¼ºä¹ç¨äºå¯¹å»çåºç¨ä¸­ LLM çä»£çè½åè¿è¡åºåæµè¯çæ ååæ°æ®éï¼è¿ä½¿å¾å¨äº¤äºå¼å»çä¿å¥ç¯å¢ä¸­å¯¹ LLM å¨å¤æä»»å¡ä¸çè¯ä¼°å·ææææ§ãä¸ºäºè§£å³è¿ä¸å·®è·ï¼æä»¬å¼å¥äº MedAgentBenchï¼è¿æ¯ä¸ä¸ªå¹¿æ³çè¯ä¼°å¥ä»¶ï¼æ¨å¨è¯ä¼°å¤§åè¯­è¨æ¨¡åå¨å»çè®°å½èæ¯ä¸çä»£çè½åãMedAgentBench åå« 100 ä¸ªç±äººç±»å»çç¼åçæ¥èª 10 ä¸ªç±»å«çç¹å®äºæ£èçä¸´åºä»»å¡ã100 ä¸ªæ£èççå®ä¸ªäººèµæï¼åå«è¶è¿ 700,000 ä¸ªæ°æ®åç´ ï¼ãä¸ä¸ªç¬¦å FHIR çäº¤äºå¼ç¯å¢ä»¥åä¸ä¸ªéå¥çä»£ç åºãè¯¥ç¯å¢ä½¿ç¨ç°ä»£ EMR ç³»ç»ä¸­ä½¿ç¨çæ å API åéä¿¡åºç¡è®¾æ½ï¼å æ­¤å¯ä»¥è½»æ¾å°è¿ç§»å°å®æ¶ EMR ç³»ç»ä¸­ãMedAgentBench åç°äºä¸ä¸ªæªé¥±åçä»¥ä»£çä¸ºå¯¼åçåºåï¼å½åæåè¿ç LLM è¡¨ç°åºä¸å®ç¨åº¦çæåè½åãæå¥½çæ¨¡å (GPT-4o) çæåçè¾¾å° 72%ãç¶èï¼ä»ç¶æå¾å¤§çæ¹è¿ç©ºé´ï¼å¯ä»¥ä¸ºç¤¾åºæä¾ä¼åæ¹åãæ­¤å¤ï¼ä¸åä»»å¡ç±»å«ä¹é´çæ§è½å·®å¼å¾å¤§ãMedAgentBench å»ºç«äºè¿ä¸ç¹ï¼å¹¶å¨ https://github.com/stanfordmlgroup/MedAgentBench å¬å¼æä¾ï¼ä¸ºæ¨¡åå¼åèæä¾äºä¸ä¸ªæä»·å¼çæ¡æ¶ï¼ç¨äºè·è¸ªè¿åº¦å¹¶æ¨å¨å¤§åè¯­è¨æ¨¡åå¨å»çé¢åçä»£çè½åçæç»­æ¹è¿ã</paragraph>

##### **Federated Domain Generalization with Data-free On-server Gradient Matching**
2501.14653v1 by Trong-Binh Nguyen, Minh-Duong Nguyen, Jinsun Park, Quoc-Viet Pham, Won Joo Hwang

Domain Generalization (DG) aims to learn from multiple known source domains a
model that can generalize well to unknown target domains. One of the key
approaches in DG is training an encoder which generates domain-invariant
representations. However, this approach is not applicable in Federated Domain
Generalization (FDG), where data from various domains are distributed across
different clients. In this paper, we introduce a novel approach, dubbed
Federated Learning via On-server Matching Gradient (FedOMG), which can
\emph{efficiently leverage domain information from distributed domains}.
Specifically, we utilize the local gradients as information about the
distributed models to find an invariant gradient direction across all domains
through gradient inner product maximization. The advantages are two-fold: 1)
FedOMG can aggregate the characteristics of distributed models on the
centralized server without incurring any additional communication cost, and 2)
FedOMG is orthogonal to many existing FL/FDG methods, allowing for additional
performance improvements by being seamlessly integrated with them. Extensive
experimental evaluations on various settings to demonstrate the robustness of
FedOMG compared to other FL/FDG baselines. Our method outperforms recent SOTA
baselines on four FL benchmark datasets (MNIST, EMNIST, CIFAR-10, and
CIFAR-100), and three FDG benchmark datasets (PACS, VLCS, and OfficeHome).

æè¦ï¼é åæ³åï¼DGï¼æ¨å¨å¾å¤åå·²ç¥çä¾æºé åå­¸ç¿ä¸åæ¨¡åï¼è©²æ¨¡åå¯ä»¥å¾å¥½å°æ³åå°æªç¥çç®æ¨é åãDG ä¸­çä¸åééµæ¹æ³æ¯è¨ç·´ä¸åç·¨ç¢¼å¨ï¼å®çæèé åä¸è®çè¡¨ç¤ºãç¶èï¼éç¨®æ¹æ³ä¸é©ç¨æ¼è¯åé åæ³å (FDG)ï¼å¶ä¸­ä¾èªä¸åé åçæ¸æåä½å¨ä¸åçå®¢æ¶ç«¯ä¸ãå¨æ¬æä¸­ï¼æåä»ç´¹äºä¸ç¨®æ°æ¹æ³ï¼ç¨±çºééä¼ºæå¨ä¸å¹éæ¢¯åº¦é²è¡è¯åå­¸ç¿ (FedOMG)ï¼å®å¯ä»¥\emph{ææå°å©ç¨ä¾èªåä½å¼é åçé åä¿¡æ¯}ãå·é«ä¾èªªï¼æåå©ç¨å±é¨æ¢¯åº¦ä½çºåä½å¼æ¨¡åçä¿¡æ¯ï¼ééæ¢¯åº¦å§ç©æå¤§åä¾æ¾å°ææé åä¸­ä¸è®çæ¢¯åº¦æ¹åãåªé»æå©åï¼1) FedOMG å¯ä»¥èåä¸­å¿åä¼ºæå¨ä¸åä½å¼æ¨¡åçç¹å¾µï¼èä¸æç¢çä»»ä½é¡å¤çéä¿¡ææ¬ï¼ä»¥å 2) FedOMG èè¨±å¤ç¾æç FL/FDG æ¹æ³æ­£äº¤ï¼åè¨±ééèå®åç¡ç¸«éæä¾é²ä¸æ­¥æé«æ§è½ãå¨åç¨®è¨­ç½®ä¸é²è¡äºå»£æ³çå¯¦é©è©ä¼°ï¼ä»¥è­æ FedOMG èå¶ä» FL/FDG åºæºç¸æ¯çé­¯æ£æ§ãæåçæ¨¡åå¨åå FL åºæºæ¸æéï¼MNISTãEMNISTãCIFAR-10 å CIFAR-100ï¼åä¸å FDG åºæºæ¸æéï¼PACSãVLCS å OfficeHomeï¼ä¸åªæ¼æè¿ç SOTA åºæºã

##### **Investigating the (De)Composition Capabilities of Large Language Models in Natural-to-Formal Language Conversion**
2501.14649v1 by Ziyao Xu, Houfeng Wang

To achieve generalized and robust natural-to-formal language conversion
(N2F), large language models (LLMs) need to have strong capabilities of
decomposition and composition in N2F when faced with an unfamiliar formal
language and be able to cope with compositional gaps and counter-intuitive
symbolic names. To investigate whether LLMs have this set of basic capabilities
in N2F, we propose the DEDC framework. This framework semi-automatically
performs sample and task construction, allowing decoupled evaluation of the set
of decomposition and composition capabilities of LLMs in N2F. Based on this
framework, we evaluate and analyze the most advanced LLMs, and the main
findings include that: (1) the LLMs are deficient in both decomposition and
composition; (2) the LLMs show a wide coverage of error types that can be
attributed to deficiencies in natural language understanding and the learning
and use of symbolic systems; (3) compositional gaps and counter-intuitive
symbolic names both affect the decomposition and composition of the LLMs. Our
work provides a new perspective for investigating the basic capabilities of
decomposition and composition of LLMs in N2F. The detailed analysis of
deficiencies and attributions can help subsequent improvements of LLMs.

æè¦ï¼<paragraph>çºäºéæå»£æ³ä¸ç©©å¥çèªç¶èªè¨è½æçºå½¢å¼èªè¨ï¼N2Fï¼ï¼å¤§åèªè¨æ¨¡åï¼LLMï¼éè¦å¨é¢å°ä¸çæçå½¢å¼èªè¨æææå¼·å¤§ç N2F åè§£åçµåè½åï¼ä¸¦è½å¤ æå°çµåééååç´è¦ºçç¬¦èåç¨±ãçºäºæ¢ç©¶ LLM æ¯å¦å·åéçµ N2F åºæ¬è½åï¼æåæåºäº DEDC æ¶æ§ãæ­¤æ¶æ§åèªåå·è¡ç¯ä¾åä»»åå»ºæ§ï¼åè¨±å° LLM å¨ N2F ä¸­çåè§£åçµåè½åçµé²è¡è§£è¦è©ä¼°ãæ ¹ææ­¤æ¶æ§ï¼æåè©ä¼°ååææåé²ç LLMï¼ä¸»è¦ç¼ç¾åæ¬ï¼(1) LLM å¨åè§£åçµåæ¹é¢åæç¼ºé·ï¼(2) LLM é¡¯ç¤ºåºå»£æ³çé¯èª¤é¡åï¼å¯æ­¸å æ¼èªç¶èªè¨çè§£ä»¥åç¬¦èç³»çµ±çå­¸ç¿åä½¿ç¨æ¹é¢çç¼ºé·ï¼(3) çµåééååç´è¦ºçç¬¦èåç¨±é½æå½±é¿ LLM çåè§£åçµåãæåçç ç©¶çºæ¢ç©¶ LLM å¨ N2F ä¸­çåè§£åçµååºæ¬è½åæä¾äºæ°çè§é»ãå°ç¼ºé·åæ­¸å çè©³ç´°åææå©æ¼å¾çºæ¹é² LLMã</paragraph>

##### **Whisper D-SGD: Correlated Noise Across Agents for Differentially Private Decentralized Learning**
2501.14644v1 by Angelo Rodio, Zheng Chen, Erik G. Larsson

Decentralized learning enables distributed agents to train a shared machine
learning model through local computation and peer-to-peer communication.
Although each agent retains its dataset locally, the communication of local
models can still expose private information to adversaries. To mitigate these
threats, local differential privacy (LDP) injects independent noise per agent,
but it suffers a larger utility gap than central differential privacy (CDP). We
introduce Whisper D-SGD, a novel covariance-based approach that generates
correlated privacy noise across agents, unifying several state-of-the-art
methods as special cases. By leveraging network topology and mixing weights,
Whisper D-SGD optimizes the noise covariance to achieve network-wide noise
cancellation. Experimental results show that Whisper D-SGD cancels more noise
than existing pairwise-correlation schemes, substantially narrowing the CDP-LDP
gap and improving model performance under the same privacy guarantees.

æè¦ï¼åæ£å¼å­¸ç¿ä½¿åæ£å¼ä»£çè½å¤ ééæ¬å°éç®åé»å°é»éè¨è¨ç·´å±äº«æ©å¨å­¸ç¿æ¨¡åãåç®¡æ¯åä»£çå¨æ¬å°ä¿çå¶è³æéï¼ä½æ¬å°æ¨¡åçéè¨ä»å¯è½åå°ææ­é²ç§äººè³è¨ãçºäºæ¸è¼éäºå¨èï¼æ¬å°å·®ç°é±ç§ (LDP) æéå°æ¯åä»£çæ³¨å¥ç¨ç«éè¨ï¼ä½å®æé ææ¯ä¸­å¤®å·®ç°é±ç§ (CDP) æ´å¤§çæç¨å·®è·ãæåå¼å¥äº Whisper D-SGDï¼ä¸ç¨®æ°çåºæ¼åæ¹å·®çæ¹æ³ï¼å®æç¢çä»£çä¹éç¸éçé±ç§éè¨ï¼å°æ¸ç¨®æåé²çæ¹æ³çµ±ä¸çºç¹ä¾ãééå©ç¨ç¶²è·¯ææ²åæ··åæ¬éï¼Whisper D-SGD ææä½³åéè¨åæ¹å·®ï¼ä»¥éæç¶²è·¯ç¯åçéè¨æ¶é¤ãå¯¦é©çµæé¡¯ç¤ºï¼Whisper D-SGD æ¶é¤äºæ¯ç¾æçæå°ç¸éæ§æ¹æ¡æ´å¤çéè¨ï¼å¤§å¹ç¸®å°äº CDP-LDP å·®è·ï¼ä¸¦å¨ç¸åçé±ç§ä¿è­ä¸æåäºæ¨¡åæè½ã

##### **Recommending Actionable Strategies: A Semantic Approach to Integrating Analytical Frameworks with Decision Heuristics**
2501.14634v1 by Renato Ghisellini, Remo Pareschi, Marco Pedroni, Giovanni Battista Raggi

We present a novel approach for recommending actionable strategies by
integrating strategic frameworks with decision heuristics through semantic
analysis. While strategy frameworks provide systematic models for assessment
and planning, and decision heuristics encode experiential knowledge,these
traditions have historically remained separate. Our methodology bridges this
gap using advanced natural language processing (NLP), demonstrated through
integrating frameworks like the 6C model with the Thirty-Six Stratagems. The
approach employs vector space representations and semantic similarity
calculations to map framework parameters to heuristic patterns, supported by a
computational architecture that combines deep semantic processing with
constrained use of Large Language Models. By processing both primary content
and secondary elements (diagrams, matrices) as complementary linguistic
representations, we demonstrate effectiveness through corporate strategy case
studies. The methodology generalizes to various analytical frameworks and
heuristic sets, culminating in a plug-and-play architecture for generating
recommender systems that enable cohesive integration of strategic frameworks
and decision heuristics into actionable guidance.

æè¦ï¼æåæåºäºä¸ç¨®æ°ç©çæ¹æ³ï¼ééèªæåæï¼å°ç­ç¥æ¶æ§èæ±ºç­åç¼æ³æ´åå¨ä¸èµ·ï¼ä¾æ¨è¦å¯è¡çç­ç¥ãéç¶ç­ç¥æ¶æ§æä¾äºç³»çµ±åçè©ä¼°åè¦åæ¨¡åï¼èæ±ºç­åç¼æ³ç·¨ç¢¼äºç¶é©ç¥è­ï¼ä½éäºå³çµ±å¨æ­·å²ä¸ä¸ç´æ¯åéçãæåçåæ³ä½¿ç¨åé²çèªç¶èªè¨èç (NLP) ä¾å½åéåå·®è·ï¼ä¸¦ééå° 6C æ¨¡åç­æ¶æ§èä¸åå­è¨æ´åå¨ä¸èµ·ä¾å ä»¥è­æãè©²æ¹æ³æ¡ç¨åéç©ºéè¡¨ç¤ºåèªæç¸ä¼¼æ§è¨ç®ï¼å°æ¶æ§åæ¸æ å°å°åç¼æ¨¡å¼ï¼ä¸¦ç±çµåæ·±åº¦èªæèçåç´æå¼ä½¿ç¨å¤§åèªè¨æ¨¡åçè¨ç®æ¶æ§æä¾æ¯æ´ãééå°ä¸»è¦å§å®¹åæ¬¡è¦åç´ ï¼åè¡¨ãç©é£ï¼ä½çºäºè£çèªè¨è¡¨ç¤ºé²è¡èçï¼æåééå¬å¸ç­ç¥æ¡ä¾ç ç©¶è­æäºå¶æææ§ãè©²æ¹æ³å¯ä»¥æ¦æ¬å°åç¨®åææ¶æ§ååç¼å¼éåï¼æçµå½¢æä¸åå³æå³ç¨çæ¶æ§ï¼ç¨æ¼ç¢çæ¨è¦ç³»çµ±ï¼ä½¿ç­ç¥æ¶æ§åæ±ºç­åç¼æ³è½å¤ ç·å¯æ´åå°å¯è¡çæå°ä¸­ã

##### **Extracting Problem Structure with LLMs for Optimized SAT Local Search**
2501.14630v1 by AndrÃ© Schilder, Stefan Szeider

Local search preprocessing makes Conflict-Driven Clause Learning (CDCL)
solvers faster by providing high-quality starting points and modern SAT solvers
have incorporated this technique into their preprocessing steps. However, these
tools rely on basic strategies that miss the structural patterns in problems.
We present a method that applies Large Language Models (LLMs) to analyze
Python-based encoding code. This reveals hidden structural patterns in how
problems convert into SAT. Our method automatically generates specialized local
search algorithms that find these patterns and use them to create strong
initial assignments. This works for any problem instance from the same encoding
type. Our tests show encouraging results, achieving faster solving times
compared to baseline preprocessing systems.

æè¦ï¼ååæå°é èçä½¿è¡çªé©åå­å¥å­¸ç¿ (CDCL) è§£ç®å¨è½æä¾é«åè³ªçèµ·é»ï¼èç¾ä»£ SAT è§£ç®å¨å·²å°æ­¤æè¡ç´å¥å¶é èçæ­¥é©ä¸­ï¼è®è§£ç®å¨è½éä½å¾æ´å¿«ãç¶èï¼éäºå·¥å·ä¾è³´æ¼åºæ¬ç­ç¥ï¼èé¯å¤±äºåé¡ä¸­ççµæ§æ¨¡å¼ãæåæåºäºä¸åæ¹æ³ï¼å°å¤§åèªè¨æ¨¡å (LLM) æç¨æ¼åæåºæ¼ Python çç·¨ç¢¼ç¢¼ãéæ­é²äºåé¡è½æçº SAT æé±èççµæ§æ¨¡å¼ãæåçèªåç¢çç¹æ®ååæå°æ¼ç®æ³ï¼æ¾åºéäºæ¨¡å¼ä¸¦ä½¿ç¨å®åä¾å»ºç«å¼·èæåçåå§ææ´¾ãéé©ç¨æ¼ç¸åç·¨ç¢¼é¡åçä»»ä½åé¡å¯¦ä¾ãæåçæ¸¬è©¦é¡¯ç¤ºä»¤äººæ¯å¥®ççµæï¼èåºæºé èçç³»çµ±ç¸æ¯ï¼è½éææ´å¿«çè§£ç®æéã

##### **ACT-JEPA: Joint-Embedding Predictive Architecture Improves Policy Representation Learning**
2501.14622v1 by Aleksandar Vujinovic, Aleksandar Kovacevic

Learning efficient representations for decision-making policies is a
challenge in imitation learning (IL). Current IL methods require expert
demonstrations, which are expensive to collect. Consequently, they often have
underdeveloped world models. Self-supervised learning (SSL) offers an
alternative by allowing models to learn from diverse, unlabeled data, including
failures. However, SSL methods often operate in raw input space, making them
inefficient. In this work, we propose ACT-JEPA, a novel architecture that
integrates IL and SSL to enhance policy representations. We train a policy to
predict (1) action sequences and (2) abstract observation sequences. The first
objective uses action chunking to improve action prediction and reduce
compounding errors. The second objective extends this idea of chunking by
predicting abstract observation sequences. We utilize Joint-Embedding
Predictive Architecture to predict in abstract representation space, allowing
the model to filter out irrelevant details, improve efficiency, and develop a
robust world model. Our experiments show that ACT-JEPA improves the quality of
representations by learning temporal environment dynamics. Additionally, the
model's ability to predict abstract observation sequences results in
representations that effectively generalize to action sequence prediction.
ACT-JEPA performs on par with established baselines across a range of
decision-making tasks.

æè¦ï¼å¨æ¨¡ä»¿å­¸ç¿ï¼ILï¼ä¸­ï¼å­¸ç¿æ±ºç­å¶å®ç­ç¥çææè¡¨ç¤ºæ¯ä¸é ææ°ãç¶åç IL æ¹æ³éè¦å°å®¶ç¤ºç¯ï¼èæ¶ééäºç¤ºç¯çææ¬å¾é«ãå æ­¤ï¼å®åéå¸¸ææ¬ ç¼å±çä¸çæ¨¡åãèªæç£ç£å­¸ç¿ï¼SSLï¼æä¾äºä¸ç¨®æ¿ä»£æ¹æ¡ï¼åè¨±æ¨¡åå¾å¤æ¨£åçãæªæ¨è¨çæ¸æï¼åæ¬å¤±æï¼ä¸­å­¸ç¿ãç¶èï¼SSL æ¹æ³éå¸¸å¨åå§è¼¸å¥ç©ºéä¸­éä½ï¼éä½¿å¾å®åæçä½ä¸ãå¨éé å·¥ä½ä¸­ï¼æåæåºäº ACT-JEPAï¼éæ¯ä¸ç¨®å° IL å SSL éæå¨ä¸èµ·ä»¥å¢å¼·ç­ç¥è¡¨ç¤ºçæ°æ¶æ§ãæåè¨ç·´ä¸åç­ç¥ä¾é æ¸¬ï¼1ï¼åä½åºååï¼2ï¼æ½è±¡è§å¯åºåãç¬¬ä¸åç®æ¨ä½¿ç¨åä½åå¡ä¾æ¹é²åä½é æ¸¬ä¸¦æ¸å°ç´¯ç©èª¤å·®ãç¬¬äºåç®æ¨ééé æ¸¬æ½è±¡è§å¯åºåä¾æ´å±éååå¡çæ³æ³ãæåå©ç¨è¯ååµå¥é æ¸¬æ¶æ§å¨æ½è±¡è¡¨ç¤ºç©ºéä¸­é²è¡é æ¸¬ï¼åè¨±æ¨¡åéæ¿¾æç¡éçç´°ç¯ãæé«æçä¸¦éç¼ä¸åå¼·å¥çä¸çæ¨¡åãæåçå¯¦é©è¡¨æï¼ACT-JEPA ééå­¸ç¿æéç°å¢åæä¾æé«è¡¨ç¤ºçè³ªéãæ­¤å¤ï¼æ¨¡åé æ¸¬æ½è±¡è§å¯åºåçè½åç¢çäºæææ¦æ¬å°åä½åºåé æ¸¬çè¡¨ç¤ºãACT-JEPA å¨ä¸ç³»åæ±ºç­å¶å®ä»»åä¸­èå·²å»ºç«çåºæºè¡¨ç¾ç¸ç¶ã

##### **Funzac at CoMeDi Shared Task: Modeling Annotator Disagreement from Word-In-Context Perspectives**
2501.14617v1 by Olufunke O. Sarumi, Charles Welch, Lucie Flek, JÃ¶rg SchlÃ¶tterer

In this work, we evaluate annotator disagreement in Word-in-Context (WiC)
tasks exploring the relationship between contextual meaning and disagreement as
part of the CoMeDi shared task competition. While prior studies have modeled
disagreement by analyzing annotator attributes with single-sentence inputs,
this shared task incorporates WiC to bridge the gap between sentence-level
semantic representation and annotator judgment variability. We describe three
different methods that we developed for the shared task, including a feature
enrichment approach that combines concatenation, element-wise differences,
products, and cosine similarity, Euclidean and Manhattan distances to extend
contextual embedding representations, a transformation by Adapter blocks to
obtain task-specific representations of contextual embeddings, and classifiers
of varying complexities, including ensembles. The comparison of our methods
demonstrates improved performance for methods that include enriched and
task-specfic features. While the performance of our method falls short in
comparison to the best system in subtask 1 (OGWiC), it is competitive to the
official evaluation results in subtask 2 (DisWiC).

æè¦ï¼å¨éé å·¥ä½ä¸­ï¼æåè©ä¼°äºèªå¢ä¸­çå®å­ (WiC) ä»»åä¸­çè¨»è§£èåæ­§ï¼æ¢ç´¢äºèªå¢æç¾©ååæ­§ä¹éçéä¿ï¼ä½çº CoMeDi å±äº«ä»»åç«¶è³½çä¸é¨åãéç¶ååçç ç©¶å·²ééåæå®ä¸å¥å­è¼¸å¥çè¨»è§£èå±¬æ§å°åæ­§é²è¡å»ºæ¨¡ï¼ä½æ­¤å±äº«ä»»åç´å¥äº WiCï¼ä»¥å½åå¥å­å±¤ç´èªç¾©è¡¨ç¤ºåè¨»è§£èå¤æ·è®ç°ä¹éçå·®è·ãæåæè¿°äºæåçºå±äº«ä»»åéç¼çä¸ç¨®ä¸åæ¹æ³ï¼åæ¬ä¸ç¨®ç¹å¾µè±å¯åæ¹æ³ï¼å®çµåäºä¸²è¯ãåç´ å·®ç°ãä¹ç©åé¤å¼¦ç¸ä¼¼æ§ãæ­å¹¾éå¾åæ¼åé è·é¢ä¾æ´åèªå¢åµå¥è¡¨ç¤ºï¼ééé©éå¨å¡é²è¡è½æä»¥ç²å¾èªå¢åµå¥çç¹å®æ¼ä»»åçè¡¨ç¤ºï¼ä»¥ååæ¬éåå¨å§çä¸åè¤éç¨åº¦çåé¡å¨ãæåçæ¹æ³çæ¯è¼è­æäºåå«è±å¯åç¹å®æ¼ä»»åçç¹å¾µçæ¹æ³çæè½æææåãéç¶æåçæ¹æ³çæè½èå­ä»»å 1 (OGWiC) ä¸­çæä½³ç³»çµ±ç¸æ¯ææä¸è¶³ï¼ä½å®èå­ä»»å 2 (DisWiC) ä¸­çå®æ¹è©ä¼°çµæå·æç«¶ç­åã

##### **Leveraging Spatial Cues from Cochlear Implant Microphones to Efficiently Enhance Speech Separation in Real-World Listening Scenes**
2501.14610v1 by Feyisayo Olalere, Kiki van der Heijden, Christiaan H. Stronks, Jeroen Briaire, Johan HM Frijns, Marcel van Gerven

Speech separation approaches for single-channel, dry speech mixtures have
significantly improved. However, real-world spatial and reverberant acoustic
environments remain challenging, limiting the effectiveness of these approaches
for assistive hearing devices like cochlear implants (CIs). To address this, we
quantify the impact of real-world acoustic scenes on speech separation and
explore how spatial cues can enhance separation quality efficiently. We analyze
performance based on implicit spatial cues (inherent in the acoustic input and
learned by the model) and explicit spatial cues (manually calculated spatial
features added as auxiliary inputs). Our findings show that spatial cues (both
implicit and explicit) improve separation for mixtures with spatially separated
and nearby talkers. Furthermore, spatial cues enhance separation when spectral
cues are ambiguous, such as when voices are similar. Explicit spatial cues are
particularly beneficial when implicit spatial cues are weak. For instance,
single CI microphone recordings provide weaker implicit spatial cues than
bilateral CIs, but even single CIs benefit from explicit cues. These results
emphasize the importance of training models on real-world data to improve
generalizability in everyday listening scenarios. Additionally, our statistical
analyses offer insights into how data properties influence model performance,
supporting the development of efficient speech separation approaches for CIs
and other assistive devices in real-world settings.

æè¦ï¼å®ééãä¹¾å¼èªé³æ··åçèªé³åé¢æ¹æ³å·²é¡¯èæ¹åãç¶èï¼çå¯¦ä¸ççç©ºéåæ··é¿è²å­¸ç°å¢ä»ç¶å·æææ°æ§ï¼ééå¶äºéäºæ¹æ³å°å©è½è£ç½®ï¼ä¾å¦äººå·¥è³è¸ (CI)ï¼çæææ§ãçºäºè§£æ±ºéååé¡ï¼æåéåäºçå¯¦ä¸çè²å­¸å ´æ¯å°èªé³åé¢çå½±é¿ï¼ä¸¦æ¢è¨äºç©ºéç·ç´¢å¦ä½ææå°å¢å¼·åé¢åè³ªãæåæ ¹æé±å«ç©ºéç·ç´¢ï¼è²å­¸è¼¸å¥ä¸­åºæçï¼ä¸ç±æ¨¡åå­¸ç¿çï¼åé¡¯å¼ç©ºéç·ç´¢ï¼æåè¨ç®çç©ºéç¹å¾µï¼ä½çºè¼å©è¼¸å¥æ°å¢ï¼åææè½ãæåçç ç©¶çµæé¡¯ç¤ºï¼ç©ºéç·ç´¢ï¼é±å«åé¡¯å¼ï¼å¯æ¹åç©ºéåé¢åéè¿èªªè©±èçæ··ååé¢ãæ­¤å¤ï¼ç¶é »è­ç·ç´¢æ¨¡ç¨å©å¯æï¼ä¾å¦è²é³ç¸ä¼¼æï¼ï¼ç©ºéç·ç´¢æå¢å¼·åé¢ãç¶é±å«ç©ºéç·ç´¢è¼å¼±æï¼é¡¯å¼ç©ºéç·ç´¢ç¹å¥æçãä¾å¦ï¼å®ä¸ CI éº¥åé¢¨éé³æä¾çé±å«ç©ºéç·ç´¢æ¯éé CI å¼±ï¼ä½å³ä½¿å®ä¸ CI ä¹è½å¾é¡¯å¼ç·ç´¢ä¸­åçãéäºçµæå¼·èª¿äºå¨çå¯¦ä¸çè³æä¸è¨ç·´æ¨¡åä»¥æ¹åæ¥å¸¸èè½å ´æ¯ä¸­æ¦æ¬æ§çéè¦æ§ãæ­¤å¤ï¼æåççµ±è¨åææä¾äºè³æå±¬æ§å¦ä½å½±é¿æ¨¡åæè½çè¦è§£ï¼æ¯æ´å¨çå¯¦ä¸çè¨­å®ä¸­éç¼ CI åå¶ä»è¼å©è£ç½®çææèªé³åé¢æ¹æ³ã

##### **Age and Power Minimization via Meta-Deep Reinforcement Learning in UAV Networks**
2501.14603v1 by Sankani Sarathchandra, Eslam Eldeeb, Mohammad Shehab, Hirley Alves, Konstantin Mikhaylov, Mohamed-Slim Alouini

Age-of-information (AoI) and transmission power are crucial performance
metrics in low energy wireless networks, where information freshness is of
paramount importance. This study examines a power-limited internet of things
(IoT) network supported by a flying unmanned aerial vehicle(UAV) that collects
data. Our aim is to optimize the UAV flight trajectory and scheduling policy to
minimize a varying AoI and transmission power combination. To tackle this
variation, this paper proposes a meta-deep reinforcement learning (RL) approach
that integrates deep Q-networks (DQNs) with model-agnostic meta-learning
(MAML). DQNs determine optimal UAV decisions, while MAML enables scalability
across varying objective functions. Numerical results indicate that the
proposed algorithm converges faster and adapts to new objectives more
effectively than traditional deep RL methods, achieving minimal AoI and
transmission power overall.

æè¦ï¼è³è¨å¹´é½¡ (AoI) åå³è¼¸åçæ¯ä½è½èç¡ç·ç¶²è·¯ä¸­è³ééè¦çæè½ææ¨ï¼å¶ä¸­è³è¨æ°é®®åº¦è³ééè¦ãæ¬ç ç©¶æ¢è¨ç±é£è¡ç¡äººæ© (UAV) æ¯æ´çé»ååéç©è¯ç¶² (IoT) ç¶²è·¯ï¼è©²ç¡äººæ©è² è²¬æ¶éè³æãæåçç®æ¨æ¯æä½³åç¡äººæ©é£è¡è»è·¡åæç¨æ¿ç­ï¼ä»¥æå°åè®åç AoI åå³è¼¸åççµåãçºäºæå°éç¨®è®åï¼æ¬ææåºäºä¸ç¨®åæ·±åº¦å¼·åå­¸ç¿ (RL) æ¹æ³ï¼å®å°æ·±åº¦ Q ç¶²è·¯ (DQN) èæ¨¡åä¸å¯ç¥çåå­¸ç¿ (MAML) æ´åå¨ä¸èµ·ãDQN æ±ºå®æä½³ç¡äººæ©æ±ºç­ï¼è MAML åæ¯æ´å¨ä¸åçç®æ¨å½æ¸ä¹éé²è¡æ´åãæ¸å¼çµæè¡¨æï¼èå³çµ±çæ·±åº¦ RL æ¹æ³ç¸æ¯ï¼ææåºçæ¼ç®æ³æ¶æå¾æ´å¿«ï¼ä¸¦ä¸æ´ææå°é©ææ°çç®æ¨ï¼æ´é«ä¸å¯¦ç¾äºæå°ç AoI åå³è¼¸åçã

##### **ZETA: Leveraging Z-order Curves for Efficient Top-k Attention**
2501.14577v1 by Qiuhao Zeng, Jerry Huang, Peng Lu, Gezheng Xu, Boxing Chen, Charles Ling, Boyu Wang

Over recent years, the Transformer has become a fundamental building block
for sequence modeling architectures. Yet at its core is the use of
self-attention, whose memory and computational cost grow quadratically with the
sequence length $N$, rendering it prohibitively expensive for long sequences. A
promising approach is top-$k$ attention, which selects only the $k$ most
relevant tokens and achieves performance comparable to vanilla self-attention
while significantly reducing space and computational demands. However, causal
masks require the current query token to only attend to past tokens, preventing
the existing top-$k$ attention method from efficiently searching for the most
relevant tokens in parallel, thereby limiting training efficiency. In this
work, we propose ZETA, leveraging \textbf{Z}-Order Curves for
\textbf{E}fficient \textbf{T}op-$k$ \textbf{A}ttention, to enable parallel
querying of past tokens for entire sequences. % in both space and time
complexity of $\mathcal{O}(N \log N)$. We first theoretically show that the
choice of key and query dimensions involves a trade-off between the curse of
dimensionality and the preservation of relative distances after projection. In
light of this insight, we propose reducing the dimensionality of keys and
queries in contrast to values and further leverage $Z$-order curves to map
low-dimensional keys and queries into \emph{one}-dimensional space, which
permits parallel sorting, thereby largely improving the efficiency for top-$k$
token selection. Experimental results demonstrate that ZETA matches the
performance of standard attention on the synthetic \textsc{Multi-Query
Associative Recall} task and outperforms attention and its variants on
\textsc{Long Range Arena} and \textsc{WikiText-103} language modeling.

æè¦ï¼<paragraph>è¿å¹´æ¥ï¼Transformer å·²æä¸ºåºåå»ºæ¨¡æ¶æçåºæ¬æå»ºæ¨¡åãç¶èï¼å¶æ ¸å¿æ¯ä½¿ç¨èªæ³¨æåï¼å¶åå­åè®¡ç®ææ¬éåºåé¿åº¦ $N$ äºæ¬¡å¢é¿ï¼ä½¿å¾å¶å¯¹äºé¿åºåçå¼éè¿å¤§ãä¸ç§æåæ¯çæ¹æ³æ¯ top-$k$ æ³¨æåï¼å®ä»éæ© $k$ ä¸ªæç¸å³çæ è®°ï¼å¹¶å®ç°ä¸é¦èèªæ³¨æåç¸å½çæ§è½ï¼åæ¶æ¾èéä½ç©ºé´åè®¡ç®éæ±ãç¶èï¼å ææ©ç è¦æ±å½åæ¥è¯¢æ è®°ä»å³æ³¨è¿å»æ è®°ï¼ä»èé»æ­¢ç°æç top-$k$ æ³¨æåæ¹æ³å¹¶è¡ææå°æç´¢æç¸å³çæ è®°ï¼ä»èéå¶äºè®­ç»æçãå¨è¿é¡¹å·¥ä½ä¸­ï¼æä»¬æåºäº ZETAï¼å©ç¨ \textbf{Z} é¶æ²çº¿å®ç° \textbf{E}fficient \textbf{T}op-$k$ \textbf{A}ttentionï¼ä»¥å®ç°å¯¹æ´ä¸ªåºåä¸­è¿å»æ è®°çå¹¶è¡æ¥è¯¢ã% å¨ç©ºé´åæ¶é´å¤æåº¦ä¸åä¸º $\mathcal{O}(N \log N)$ãæä»¬é¦åä»çè®ºä¸è¡¨æï¼é®åæ¥è¯¢ç»´åº¦çéæ©æ¶åç»´åº¦ç¾é¾åæå½±åç¸å¯¹è·ç¦»çä¿çä¹é´çæè¡¡ãæ ¹æ®è¿ä¸è§è§£ï¼æä»¬æåºéä½é®åæ¥è¯¢çç»´åº¦ï¼ä¸å¼å½¢æå¯¹æ¯ï¼å¹¶è¿ä¸æ­¥å©ç¨ $Z$ é¶æ²çº¿å°ä½ç»´é®åæ¥è¯¢æ å°å°\emph{ä¸}ç»´ç©ºé´ï¼è¿åè®¸å¹¶è¡æåºï¼ä»èæå¤§å°æé«äº top-$k$ æ è®°éæ©çæçãå®éªç»æè¡¨æï¼ZETA å¨åæ \textsc{å¤æ¥è¯¢å³èå¬å} ä»»å¡ä¸ä¸æ åæ³¨æåçæ§è½ç¸å¹éï¼å¹¶å¨ \textsc{é¿ç¨ç«æåº} å \textsc{WikiText-103} è¯­è¨å»ºæ¨¡ä¸ä¼äºæ³¨æååå¶åä½ã</paragraph>

##### **Leveraging ChatGPT's Multimodal Vision Capabilities to Rank Satellite Images by Poverty Level: Advancing Tools for Social Science Research**
2501.14546v1 by Hamid Sarmadi, Ola Hall, Thorsteinn RÃ¶gnvaldsson, Mattias Ohlsson

This paper investigates the novel application of Large Language Models (LLMs)
with vision capabilities to analyze satellite imagery for village-level poverty
prediction. Although LLMs were originally designed for natural language
understanding, their adaptability to multimodal tasks, including geospatial
analysis, has opened new frontiers in data-driven research. By leveraging
advancements in vision-enabled LLMs, we assess their ability to provide
interpretable, scalable, and reliable insights into human poverty from
satellite images. Using a pairwise comparison approach, we demonstrate that
ChatGPT can rank satellite images based on poverty levels with accuracy
comparable to domain experts. These findings highlight both the promise and the
limitations of LLMs in socioeconomic research, providing a foundation for their
integration into poverty assessment workflows. This study contributes to the
ongoing exploration of unconventional data sources for welfare analysis and
opens pathways for cost-effective, large-scale poverty monitoring.

æè¦ï¼æ¬ææ¢è¨å¤§åèªè¨æ¨¡åï¼LLMï¼çæ°ç©æç¨ï¼çµåè¦è¦ºè½åä¾åæè¡æå½±åï¼ç¨æ¼æèå±¤ç´çè²§çª®é æ¸¬ãåç®¡ LLM æåæ¯çºèªç¶èªè¨çè§£èè¨­è¨ï¼ä½å¶å°å¤æ¨¡æä»»åï¼åæ¬å°çç©ºéåæï¼çé©ææ§ï¼éåäºè³æé©åç ç©¶çæ°é åãééå©ç¨å·åè¦è¦ºåè½ç LLM çé²æ­¥ï¼æåè©ä¼°å¶å¾è¡æå½±åä¸­æä¾å¯è§£éãå¯æ´åä¸å¯é çäººé¡è²§çª®æ´å¯çè½åãä½¿ç¨æå°æ¯è¼æ¹æ³ï¼æåè­æ ChatGPT å¯ä»¥æ ¹æè²§çª®ç¨åº¦å°è¡æå½±åé²è¡æåï¼å¶æºç¢ºåº¦èé åå°å®¶ç¸ç¶ãéäºç¼ç¾çªé¡¯äº LLM å¨ç¤¾æç¶æ¿ç ç©¶ä¸­çåªé»åéå¶ï¼çºå¶æ´åå°è²§çª®è©ä¼°å·¥ä½æµç¨ä¸­å¥ å®äºåºç¤ãæ¬ç ç©¶æå©æ¼æçºæ¢ç´¢éå³çµ±è³æä¾æºä»¥é²è¡ç¦å©åæï¼ä¸¦çºå·ææ¬æççå¤§è¦æ¨¡è²§çª®ç£æ¸¬éåäºéå¾ã

##### **Distributed Conformal Prediction via Message Passing**
2501.14544v1 by Haifeng Wen, Hong Xing, Osvaldo Simeone

Post-hoc calibration of pre-trained models is critical for ensuring reliable
inference, especially in safety-critical domains such as healthcare. Conformal
Prediction (CP) offers a robust post-hoc calibration framework, providing
distribution-free statistical coverage guarantees for prediction sets by
leveraging held-out datasets. In this work, we address a decentralized setting
where each device has limited calibration data and can communicate only with
its neighbors over an arbitrary graph topology. We propose two
message-passing-based approaches for achieving reliable inference via CP:
quantile-based distributed conformal prediction (Q-DCP) and histogram-based
distributed conformal prediction (H-DCP). Q-DCP employs distributed quantile
regression enhanced with tailored smoothing and regularization terms to
accelerate convergence, while H-DCP uses a consensus-based histogram estimation
approach. Through extensive experiments, we investigate the trade-offs between
hyperparameter tuning requirements, communication overhead, coverage
guarantees, and prediction set sizes across different network topologies.

æè¦ï¼é åè¨ç·´æ¨¡åçäºå¾æ ¡æ­£å°æ¼ç¢ºä¿å¯é çæ¨è«è³ééè¦ï¼å°¤å¶æ¯å¨é«çä¿å¥ç­å®å¨æ§è³ä¸çé åãä¸è´æ§é æ¸¬ (CP) æä¾äºä¸åå¼·å¥çäºå¾æ ¡æ­£æ¶æ§ï¼ééå©ç¨ä¿ççè³æéï¼çºé æ¸¬éåæä¾ä¸ä¾è³´åéççµ±è¨è¦èçä¿è­ãå¨éé ç ç©¶ä¸­ï¼æåæ¢è¨äºä¸ååæ£å¼è¨­å®ï¼å¶ä¸­æ¯åè£ç½®é½åªææéçæ ¡æ­£è³æï¼èä¸åªè½ééä»»æåå½¢ææ²èå¶é°è¿è£ç½®é²è¡éè¨ãæåæåºäºå©ç¨®åºæ¼è¨æ¯å³éçæ¹æ³ï¼éé CP éå°å¯é çæ¨è«ï¼åºæ¼åä½æ¸çåæ£å¼ä¸è´æ§é æ¸¬ (Q-DCP) ååºæ¼ç´æ¹åçåæ£å¼ä¸è´æ§é æ¸¬ (H-DCP)ãQ-DCP æ¡ç¨çåæ£å¼åä½æ¸åæ­¸ç¶ééèº«æé çå¹³æ»åæ­£ååé å¼·åï¼ä»¥å éæ¶æï¼è H-DCP åä½¿ç¨åºæ¼å±è­çç´æ¹åä¼°è¨æ¹æ³ãééå»£æ³çå¯¦é©ï¼æåæ¢è¨äºå¨ä¸åçç¶²è·¯ææ²ä¸­ï¼è¶åæ¸èª¿æ´éæ±ãéè¨è² æãè¦èçä¿è­åé æ¸¬éåå¤§å°ä¹éçåæ¨ã

##### **VERUS-LM: a Versatile Framework for Combining LLMs with Symbolic Reasoning**
2501.14540v1 by Benjamin Callewaert, Simon Vandevelde, Joost Vennekens

A recent approach to neurosymbolic reasoning is to explicitly combine the
strengths of large language models (LLMs) and symbolic solvers to tackle
complex reasoning tasks. However, current approaches face significant
limitations, including poor generalizability due to task-specific prompts,
inefficiencies caused by the lack of separation between knowledge and queries,
and restricted inferential capabilities. These shortcomings hinder their
scalability and applicability across diverse domains. In this paper, we
introduce VERUS-LM, a novel framework designed to address these challenges.
VERUS-LM employs a generic prompting mechanism, clearly separates domain
knowledge from queries, and supports a wide range of different logical
reasoning tasks. This framework enhances adaptability, reduces computational
cost, and allows for richer forms of reasoning, such as optimization and
constraint satisfaction. We show that our approach succeeds in diverse
reasoning on a novel dataset, markedly outperforming LLMs. Additionally, our
system achieves competitive results on common reasoning benchmarks when
compared to other state-of-the-art approaches, and significantly surpasses them
on the difficult AR-LSAT dataset. By pushing the boundaries of hybrid
reasoning, VERUS-LM represents a significant step towards more versatile
neurosymbolic AI systems

æè¦ï¼æè¿ç¥ç»ç¬¦å·æ¨ççä¸ç§æ¹æ³æ¯æç¡®ç»åå¤§åè¯­è¨æ¨¡å (LLM) åç¬¦å·æ±è§£å¨çä¼å¿æ¥è§£å³å¤æçæ¨çä»»å¡ãç¶èï¼ç®åçæ¹æ³é¢ä¸´çéå¤§çå±éæ§ï¼åæ¬ç±äºç¹å®ä»»å¡æç¤ºå¯¼è´çæ³åè½åå·®ãç±äºç¼ºä¹ç¥è¯åæ¥è¯¢ä¹é´çåç¦»èå¯¼è´çæçä½ä¸ä»¥ååéçæ¨çè½åãè¿äºç¼ºç¹é»ç¢äºå®ä»¬å¨ä¸åé¢åçå¯æ©å±æ§åéç¨æ§ãå¨æ¬æä¸­ï¼æä»¬ä»ç»äº VERUS-LMï¼è¿æ¯ä¸ä¸ªæ¨å¨è§£å³è¿äºææçæ°æ¡æ¶ãVERUS-LM éç¨éç¨æç¤ºæºå¶ï¼å°é¢åç¥è¯ä¸æ¥è¯¢æç¡®åå¼ï¼å¹¶æ¯æåç§ä¸åçé»è¾æ¨çä»»å¡ãè¯¥æ¡æ¶å¢å¼ºäºéåºæ§ï¼éä½äºè®¡ç®ææ¬ï¼å¹¶åè®¸è¿è¡æ´ä¸°å¯çæ¨çå½¢å¼ï¼ä¾å¦ä¼ååçº¦ææ»¡è¶³ãæä»¬è¡¨æï¼æä»¬çæ¹æ³å¨æ°çæ°æ®éä¸åå¾äºä¸åçæ¨çæåï¼ææ¾ä¼äº LLMãæ­¤å¤ï¼ä¸å¶ä»æåè¿çæ¹æ³ç¸æ¯ï¼æä»¬çç³»ç»å¨å¸¸è§çæ¨çåºåä¸åå¾äºæç«äºåçç»æï¼å¹¶ä¸å¨å°é¾ç AR-LSAT æ°æ®éä¸ææ¾è¶è¶äºå®ä»¬ãéè¿çªç ´æ··åæ¨çççéï¼VERUS-LM ä»£è¡¨äºæçæ´éç¨çç¥ç»ç¬¦å· AI ç³»ç»è¿åºçéè¦ä¸æ­¥

##### **Idiom Detection in Sorani Kurdish Texts**
2501.14528v1 by Skala Kamaran Omer, Hossein Hassani

Idiom detection using Natural Language Processing (NLP) is the computerized
process of recognizing figurative expressions within a text that convey
meanings beyond the literal interpretation of the words. While idiom detection
has seen significant progress across various languages, the Kurdish language
faces a considerable research gap in this area despite the importance of idioms
in tasks like machine translation and sentiment analysis. This study addresses
idiom detection in Sorani Kurdish by approaching it as a text classification
task using deep learning techniques. To tackle this, we developed a dataset
containing 10,580 sentences embedding 101 Sorani Kurdish idioms across diverse
contexts. Using this dataset, we developed and evaluated three deep learning
models: KuBERT-based transformer sequence classification, a Recurrent
Convolutional Neural Network (RCNN), and a BiLSTM model with an attention
mechanism. The evaluations revealed that the transformer model, the fine-tuned
BERT, consistently outperformed the others, achieving nearly 99% accuracy while
the RCNN achieved 96.5% and the BiLSTM 80%. These results highlight the
effectiveness of Transformer-based architectures in low-resource languages like
Kurdish. This research provides a dataset, three optimized models, and insights
into idiom detection, laying a foundation for advancing Kurdish NLP.

æè¦ï¼æ£ç¨èªåµæ¸¬ä½¿ç¨èªç¶èªè¨èç (NLP)ï¼æ¯ä¸ç¨®é»è¦åçç¨åºï¼ç¨æ¼è¾¨è­æå­ä¸­çæ¯å»è¡¨éæ¹å¼ï¼å³éåºè¶åºå­é¢ææçæç¾©ãéç¶æ£ç¨èªåµæ¸¬å¨åç¨®èªè¨ä¸­é½æé¡¯èçé²å±ï¼ä½åº«å¾·èªå¨éåé åå»é¢è¨ç¸ç¶å¤§çç ç©¶å·®è·ï¼åç®¡æ£ç¨èªå¨æ©å¨ç¿»è­¯åæç·åæç­ä»»åä¸­å¾éè¦ãæ¬ç ç©¶ééå°æ£ç¨èªåµæ¸¬è¦çºä¸ç¨®ä½¿ç¨æ·±åº¦å­¸ç¿æè¡çæå­åé¡ä»»åï¼ä¾æ¢è¨ç´¢æå°¼åº«å¾·èªä¸­çæ£ç¨èªåµæ¸¬ãçºäºè§£æ±ºéååé¡ï¼æåéç¼äºä¸ååå« 10,580 åå¥å­çè³æéï¼å¶ä¸­åµå¥äº 101 åç´¢æå°¼åº«å¾·èªæ£ç¨èªï¼æ¶µèäºåç¨®ä¸åçèçµ¡ãä½¿ç¨éåè³æéï¼æåéç¼ä¸¦è©ä¼°äºä¸åæ·±åº¦å­¸ç¿æ¨¡åï¼åºæ¼ KuBERT ç Transformer åºååé¡ãéè¿´å·ç©ç¥ç¶ç¶²è·¯ (RCNN) åå¸¶ææ³¨æåæ©å¶ç BiLSTM æ¨¡åãè©ä¼°çµæé¡¯ç¤ºï¼Transformer æ¨¡åãå¾®èª¿å¾ç BERTï¼å§çµåªæ¼å¶ä»æ¨¡åï¼æºç¢ºçæ¥è¿ 99%ï¼è RCNN éå° 96.5%ï¼BiLSTM éå° 80%ãéäºçµæçªé¡¯äº Transformer-based æ¶æ§å¨ä½è³æºèªè¨ï¼å¦åº«å¾·èªï¼ä¸­çæææ§ãæ¬ç ç©¶æä¾äºä¸åè³æéãä¸åæä½³åæ¨¡ååå°æ£ç¨èªåµæ¸¬çè¦è§£ï¼çºæ¨é²åº«å¾·èª NLP å¥ å®äºåºç¤ã

##### **WanJuanSiLu: A High-Quality Open-Source Webtext Dataset for Low-Resource Languages**
2501.14506v1 by Jia Yu, Fei Yuan, Rui Min, Jing Yu, Pei Chu, Jiayang Li, Wei Li, Ruijie Zhang, Zhenxiang Li, Zhifei Ren, Dong Zheng, Wenjian Zhang, Yan Teng, Lingyu Meng, ZhenJiang Jin, Jiantao Qiu, ShaSha Wang, Zhongying Tu, Dahua Lin, Yu Wang, Yu Qiao, Yanfeng Wang, Conghui He

This paper introduces the open-source dataset WanJuanSiLu, designed to
provide high-quality training corpora for low-resource languages, thereby
advancing the research and development of multilingual models. To achieve this,
we have developed a systematic data processing framework tailored for
low-resource languages. This framework encompasses key stages such as data
extraction, corpus cleaning, content deduplication, security filtering, quality
evaluation, and theme classification. Through the implementation of this
framework, we have significantly improved both the quality and security of the
dataset, while maintaining its linguistic diversity. As of now, data for all
five languages have been fully open-sourced. The dataset can be accessed at
https://opendatalab.com/applyMultilingualCorpus, and GitHub repository is
available at https://github.com/opendatalab/WanJuan3.0

æè¦ï¼æ¬æä»ç´¹äºéæºè³æé WanJuanSiLuï¼å¶è¨­è¨ç®çæ¯çºä½è³æºèªè¨æä¾é«åè³ªçè¨ç·´èªæåº«ï¼é²èæ¨åå¤èªè¨æ¨¡åçç ç©¶èéç¼ãçºæ­¤ï¼æåéç¼äºä¸åç³»çµ±æ§çè³æèçæ¶æ§ï¼å°ééå°ä½è³æºèªè¨ãæ­¤æ¶æ§åå«è³æèåãèªæåº«æ¸çãå§å®¹å»éãå®å¨æ§éæ¿¾ãåè³ªè©ä¼°åä¸»é¡åé¡ç­ä¸»è¦éæ®µãééå¯¦ä½æ­¤æ¶æ§ï¼æåå¤§å¹æåäºè³æéçåè³ªåå®å¨æ§ï¼åæç¶­æå¶èªè¨çå¤æ¨£æ§ãç®åï¼ææäºç¨®èªè¨çè³æé½å·²å®å¨éæºãå¯å¨ https://opendatalab.com/applyMultilingualCorpus å­åè³æéï¼GitHub å²å­åº«å¯æ¼ https://github.com/opendatalab/WanJuan3.0 åå¾

##### **Evaluating and Improving Graph to Text Generation with Large Language Models**
2501.14497v1 by Jie He, Yijun Yang, Wanqiu Long, Deyi Xiong, Victor Gutierrez Basulto, Jeff Z. Pan

Large language models (LLMs) have demonstrated immense potential across
various tasks. However, research for exploring and improving the capabilities
of LLMs in interpreting graph structures remains limited. To address this gap,
we conduct a comprehensive evaluation of prompting current open-source LLMs on
graph-to-text generation tasks. Although we explored the optimal prompting
strategies and proposed a novel and effective diversity-difficulty-based
few-shot sample selection method, we found that the improvements from
tuning-free approaches were incremental, as LLMs struggle with planning on
complex graphs, particularly those with a larger number of triplets. To further
improve LLMs in planning with graph sequences and grounding in truth, we
introduce a new graph-to-text dataset, PlanGTG, annotated with two sub-tasks:
reordering and attribution. Through extensive automatic and human evaluations,
we demonstrate significant improvements in the quality of generated text from
both few-shot learning and fine-tuning perspectives using the PlanGTG dataset.
Our study paves the way for new research directions in graph-to-text
generation. PlanGTG datasets can be found in https://github.com/probe2/kg_text.

æè¦ï¼å¤§åèªè¨æ¨¡åï¼LLMï¼å·²å¨åç¨®ä»»åä¸­å±ç¾åºå·¨å¤§çæ½åãç¶èï¼æ¢ç´¢åæå LLM å¨è©®éåå½¢çµæ§æ¹é¢çè½åçç ç©¶ä»ç¶æéãçºäºè§£æ±ºéåå·®è·ï¼æåå°æç¤ºç®åéæºç LLM å·è¡åå½¢è½æå­çæä»»åé²è¡å¨é¢è©ä¼°ãåç®¡æåæ¢ç´¢äºæä½³æç¤ºç­ç¥ä¸¦æåºäºä¸ç¨®æ°ç©ä¸ææçåºæ¼å¤æ¨£æ§é£åº¦çå°æ¨£æ¬é¸ææ¹æ³ï¼ä½æåç¼ç¾ç¡èª¿æ ¡æ¹æ³çæ¹é²æ¯æ¼¸é²çï¼å çº LLM é£ä»¥è¦åè¤éçåå½¢ï¼ç¹å¥æ¯é£äºå·æè¼å¤ä¸åçµçåå½¢ãçºäºé²ä¸æ­¥æå LLM å¨åå½¢åºåè¦ååçå¯¦ä¾ææ¹é¢çè½åï¼æåå¼å¥äºä¸åæ°çåå½¢è½æå­è³æé PlanGTGï¼ä¸¦è¨»è§£äºå©åå­ä»»åï¼éæ°æåºåæ­¸å ãééå»£æ³çèªåååäººå·¥è©ä¼°ï¼æåè­æäºä½¿ç¨ PlanGTG è³æéå¾å°æ¨£æ¬å­¸ç¿åå¾®èª¿è§åº¦ç¢çæå­çåè³ªæé¡¯èæåãæåçç ç©¶çºåå½¢è½æå­çæä¸­çæ°ç ç©¶æ¹åéªè·¯ãPlanGTG è³æéå¯ä»¥å¨ https://github.com/probe2/kg_text ä¸­æ¾å°ã

##### **Analyzing the Effect of Linguistic Similarity on Cross-Lingual Transfer: Tasks and Experimental Setups Matter**
2501.14491v1 by Verena Blaschke, Masha Fedzechkina, Maartje ter Hoeve

Cross-lingual transfer is a popular approach to increase the amount of
training data for NLP tasks in a low-resource context. However, the best
strategy to decide which cross-lingual data to include is unclear. Prior
research often focuses on a small set of languages from a few language families
and/or a single task. It is still an open question how these findings extend to
a wider variety of languages and tasks. In this work, we analyze cross-lingual
transfer for 266 languages from a wide variety of language families. Moreover,
we include three popular NLP tasks: POS tagging, dependency parsing, and topic
classification. Our findings indicate that the effect of linguistic similarity
on transfer performance depends on a range of factors: the NLP task, the (mono-
or multilingual) input representations, and the definition of linguistic
similarity.

æè¦ï¼è·¨èªè¨è½ç§»æ¯ä¸ç¨®æµè¡çä½æ³ï¼ç¨æ¼å¢å ä½è³æºç°å¢ä¸ NLP ä»»åçè¨ç·´è³æéãç¶èï¼è¦æ±ºå®ç´å¥åªäºè·¨èªè¨è³æçæä½³ç­ç¥ä»ä¸æç¢ºãååçç ç©¶éå¸¸å°æ³¨æ¼å°æ¸èªè¨å®¶æä¸­çä¸å°çµèªè¨å/æå®ä¸ä»»åãéäºç¼ç¾å¦ä½æ´å±å°æ´å¤ååçèªè¨åä»»åï¼éä»æ¯ä¸åéæ¾æ§çåé¡ãå¨éé å·¥ä½ä¸­ï¼æååæäºä¾èªåç¨®èªè¨å®¶æç 266 ç¨®èªè¨çè·¨èªè¨è½ç§»ãæ­¤å¤ï¼æåç´å¥äºä¸é æµè¡ç NLP ä»»åï¼è©æ§æ¨è¨ãä¾å­å¥æ³åæåä¸»é¡åé¡ãæåçç ç©¶çµæè¡¨æï¼èªè¨ç¸ä¼¼æ§å°è½ç§»æè½çå½±é¿åæ±ºæ¼ä¸ç³»åå ç´ ï¼NLP ä»»åãï¼å®èªæå¤èªï¼è¼¸å¥è¡¨ç¤ºï¼ä»¥åèªè¨ç¸ä¼¼æ§çå®ç¾©ã

##### **RealCritic: Towards Effectiveness-Driven Evaluation of Language Model Critiques**
2501.14492v1 by Zhengyang Tang, Ziniu Li, Zhenyang Xiao, Tian Ding, Ruoyu Sun, Benyou Wang, Dayiheng Liu, Fei Huang, Tianyu Liu, Bowen Yu, Junyang Lin

Critiques are important for enhancing the performance of Large Language
Models (LLMs), enabling both self-improvement and constructive feedback for
others by identifying flaws and suggesting improvements. However, evaluating
the critique capabilities of LLMs presents a significant challenge due to the
open-ended nature of the task. In this work, we introduce a new benchmark
designed to assess the critique capabilities of LLMs. Unlike existing
benchmarks, which typically function in an open-loop fashion, our approach
employs a closed-loop methodology that evaluates the quality of corrections
generated from critiques. Moreover, the benchmark incorporates features such as
self-critique, cross-critique, and iterative critique, which are crucial for
distinguishing the abilities of advanced reasoning models from more classical
ones. We implement this benchmark using eight challenging reasoning tasks. We
have several interesting findings. First, despite demonstrating comparable
performance in direct chain-of-thought generation, classical LLMs significantly
lag behind the advanced reasoning-based model o1-mini across all critique
scenarios. Second, in self-critique and iterative critique settings, classical
LLMs may even underperform relative to their baseline capabilities. We hope
that this benchmark will serve as a valuable resource to guide future
advancements. The code and data are available at
\url{https://github.com/tangzhy/RealCritic}.

æè¦ï¼æ¹è©å°æ¼å¤§åèªè¨æ¨¡å (LLM) çæè½æåéå¸¸éè¦ï¼å®è½ééæ¾åºç¼ºé»ä¸¦å»ºè­°æ¹é²æ¹å¼ï¼éå°èªææååå°ä»äººæä¾å»ºè¨­æ§åé¥çç®çãç¶èï¼è©ä¼° LLM çæ¹è©è½åæ¯ä¸é éå¤§ææ°ï¼å çºéé ä»»åçæ¬è³ªæ¯éæ¾å¼çãå¨éé ç ç©¶ä¸­ï¼æåæåºäºä¸åæ°çåºæºï¼ç¨ä¾è©ä¼° LLM çæ¹è©è½åãèç¾æçåºæºï¼éå¸¸ä»¥éæ¾è¿´è·¯çæ¹å¼éä½ï¼ä¸åï¼æåçåæ³æ¡ç¨éè¿´è·¯æ¹æ³ï¼ç¨ä¾è©ä¼°å¾æ¹è©ä¸­ç¢ççä¿®æ­£åè³ªãæ­¤å¤ï¼éååºæºéåå«èªè©ãäº¤åæ¹è©ååè¦æ¹è©ç­åè½ï¼éäºåè½å°æ¼ååé²éæ¨çæ¨¡ååè¼å³çµ±æ¨¡åçè½åè³ééè¦ãæåä½¿ç¨å«é å·æææ°æ§çæ¨çä»»åä¾å¯¦ä½éååºæºãæåæå¹¾åæè¶£çç¼ç¾ãé¦åï¼åç®¡å¨ç´æ¥çæç¶­éçæä¸­è¡¨ç¾åºç¸ç¶çæè½ï¼ä½å³çµ±ç LLM å¨æææ¹è©æå¢ä¸­é½é é è½å¾æ¼åºæ¼é²éæ¨ççæ¨¡å o1-miniãå¶æ¬¡ï¼å¨èªè©ååè¦æ¹è©çè¨­å®ä¸­ï¼å³çµ±ç LLM çè³å¯è½è¡¨ç¾ä¸å¦å¶åºæºè½åãæåå¸æéååºæºè½æçºå¼å°æªä¾é²å±çå¯¶è²´è³æºãç¨å¼ç¢¼åè³æå¯å¨ \url{https://github.com/tangzhy/RealCritic} åå¾ã

##### **The Pseudo-Dimension of Contracts**
2501.14474v1 by Paul Duetting, Michal Feldman, Tomasz Ponitka, Ermis Soumalias

Algorithmic contract design studies scenarios where a principal incentivizes
an agent to exert effort on her behalf. In this work, we focus on settings
where the agent's type is drawn from an unknown distribution, and formalize an
offline learning framework for learning near-optimal contracts from sample
agent types. A central tool in our analysis is the notion of pseudo-dimension
from statistical learning theory. Beyond its role in establishing upper bounds
on the sample complexity, pseudo-dimension measures the intrinsic complexity of
a class of contracts, offering a new perspective on the tradeoffs between
simplicity and optimality in contract design. Our main results provide
essentially optimal tradeoffs between pseudo-dimension and representation error
(defined as the loss in principal's utility) with respect to linear and bounded
contracts. Using these tradeoffs, we derive sample- and time-efficient learning
algorithms, and demonstrate their near-optimality by providing almost matching
lower bounds on the sample complexity. Conversely, for unbounded contracts, we
prove an impossibility result showing that no learning algorithm exists.
  Finally, we extend our techniques in three important ways. First, we provide
refined pseudo-dimension and sample complexity guarantees for the combinatorial
actions model, revealing a novel connection between the number of critical
values and sample complexity. Second, we extend our results to menus of
contracts, showing that their pseudo-dimension scales linearly with the menu
size. Third, we adapt our algorithms to the online learning setting, where we
show that, a polynomial number of type samples suffice to learn near-optimal
bounded contracts. Combined with prior work, this establishes a formal
separation between expert advice and bandit feedback for this setting.

æè¦ï¼<paragraph>æ¼ç®æ³åç´è¨­è¨ç ç©¶å ´æ¯ï¼å¶ä¸­å§è¨äººæ¿åµä»£çäººçºå¶ä»åºåªåãå¨éé å·¥ä½ä¸­ï¼æåå°æ³¨æ¼ä»£çäººçé¡åå¾æªç¥åä½ä¸­æ½åºçè¨­å®ï¼ä¸¦å½¢å¼åä¸åé¢ç·å­¸ç¿æ¶æ§ï¼ä»¥å¾æ¨£æ¬ä»£çäººé¡åä¸­å­¸ç¿è¿ä¹æä½³çåç´ãæååæä¸­çæ ¸å¿å·¥å·æ¯çµ±è¨å­¸ç¿çè«ä¸­çå½ç¶­åº¦æ¦å¿µãé¤äºå¨å»ºç«æ¨£æ¬è¤éåº¦ä¸éä¸­çä½ç¨å¤ï¼å½ç¶­åº¦éæ¸¬éäºä¸é¡åç´çå§å¨è¤éåº¦ï¼çºåç´è¨­è¨ä¸­ç°¡æ½æ§åæä½³æ§ä¹éçæ¬è¡¡æä¾äºæ°çè§é»ãæåçææå¨å½ç¶­åº¦åè¡¨ç¤ºèª¤å·®ï¼å®ç¾©çºå§è¨äººæç¨çæå¤±ï¼ä¹éæä¾äºæ¬è³ªä¸æä½³çæ¬è¡¡ï¼ç¸å°æ¼ç·æ§åæçåç´ãå©ç¨éäºæ¬è¡¡ï¼æåæ¨å°åºæ¨£æ¬åæéæççå­¸ç¿æ¼ç®æ³ï¼ä¸¦ééæä¾å¹¾ä¹å¹éæ¨£æ¬è¤éåº¦ä¸éä¾è­æå®åçè¿ä¹æä½³æ§ãç¸åå°ï¼å°æ¼ç¡çåç´ï¼æåè­æäºä¸åä¸å¯è½ççµæï¼è¡¨æä¸å­å¨å­¸ç¿æ¼ç®æ³ãæå¾ï¼æåä»¥ä¸ç¨®éè¦æ¹å¼æ´å±äºæåçæè¡ãé¦åï¼æåçºçµååä½æ¨¡åæä¾äºç²¾ç¢ºçå½ç¶­åº¦åæ¨£æ¬è¤éåº¦ä¿è­ï¼æ­ç¤ºäºè¨çå¼æ¸éåæ¨£æ¬è¤éåº¦ä¹éçæ°ç©éè¯ãå¶æ¬¡ï¼æåå°æåççµææ´å±å°åç´é¸å®ï¼è¡¨æå®åçå½ç¶­åº¦èé¸å®å¤§å°æç·æ§æ¯ä¾ãç¬¬ä¸ï¼æåå°æåçæ¼ç®æ³èª¿æ´å°ç·ä¸å­¸ç¿è¨­å®ï¼å¨å¶ä¸­æåè¡¨æï¼å¤é å¼çé¡åæ¨£æ¬æ¸éè¶³ä»¥å­¸ç¿è¿ä¹æä½³çæçåç´ãçµåååçç ç©¶ï¼éçºæ­¤è¨­å®çå°å®¶å»ºè­°åå¤èèèæ©åé¥å»ºç«äºä¸åæ­£å¼çåé¢ã</paragraph>

##### **Pesti-Gen: Unleashing a Generative Molecule Approach for Toxicity Aware Pesticide Design**
2501.14469v1 by Taehan Kim, Wonduk Seo

Global climate change has reduced crop resilience and pesticide efficacy,
making reliance on synthetic pesticides inevitable, even though their
widespread use poses significant health and environmental risks. While these
pesticides remain a key tool in pest management, previous machine-learning
applications in pesticide and agriculture have focused on classification or
regression, leaving the fundamental challenge of generating new molecular
structures or designing novel candidates unaddressed. In this paper, we propose
Pesti-Gen, a novel generative model based on variational auto-encoders,
designed to create pesticide candidates with optimized properties for the first
time. Specifically, Pesti-Gen leverages a two-stage learning process: an
initial pre-training phase that captures a generalized chemical structure
representation, followed by a fine-tuning stage that incorporates
toxicity-specific information. The model simultaneously optimizes over multiple
toxicity metrics, such as (1) livestock toxicity and (2) aqua toxicity to
generate environmentally friendly pesticide candidates. Notably, Pesti-Gen
achieves approximately 68\% structural validity in generating new molecular
structures, demonstrating the model's effectiveness in producing optimized and
feasible pesticide candidates, thereby providing a new way for safer and more
sustainable pest management solutions.

æè¦ï¼å¨çæ°£åè®é·éä½äºä½ç©çå¾©ååèæ®ºè²åçæåï¼
ä½¿å¾ä»°è³´åææ®ºè²åæçºç¡å¯é¿åçè¶¨å¢ï¼åç®¡å®åçå»£æ³ä½¿ç¨æå¸¶ä¾éå¤§çå¥åº·åç°å¢é¢¨éªãåç®¡éäºæ®ºè²åä»ç¶æ¯è²å®³ç®¡çä¸­çééµå·¥å·ï¼éå»å¨æ®ºè²ååè¾²æ¥­æ¹é¢çæ©å¨å­¸ç¿æç¨é½èéæ¼åé¡æè¿´æ­¸ï¼èæªè§£æ±ºç¢çæ°çåå­çµæ§æè¨­è¨æ°åé¸è¥åçåºæ¬ææ°ãå¨æ¬æä¸­ï¼æåæåº Pesti-Genï¼ä¸ç¨®åºæ¼è®ç°èªåç·¨ç¢¼å¨çåµæ°çææ¨¡åï¼æ¨å¨é¦æ¬¡å»ºç«å·ææä½³åç¹æ§çæ®ºè²ååé¸è¥åãå·é«ä¾èªªï¼Pesti-Gen æ¡ç¨å©éæ®µå­¸ç¿æµç¨ï¼ä¸åæ·åå»£ç¾©åå­¸çµæ§è¡¨ç¤ºçåå§é è¨ç·´éæ®µï¼æ¥èæ¯ä¸åç´å¥æ¯æ§ç¹å®è³è¨çå¾®èª¿éæ®µãæ­¤æ¨¡ååæéå°å¤ç¨®æ¯æ§ææ¨é²è¡æä½³åï¼ä¾å¦ (1) ç²çæ¯æ§å (2) æ°´çæ¯æ§ï¼ä»¥ç¢çå°ç°å¢ååçæ®ºè²ååé¸è¥åãå¼å¾æ³¨æçæ¯ï¼Pesti-Gen å¨ç¢çæ°çåå­çµæ§æ¹é¢éå°äºç´ 68% ççµæ§æåº¦ï¼è­æäºæ­¤æ¨¡åå¨ç¢çæä½³åä¸å¯è¡çæ®ºè²ååé¸è¥åæ¹é¢çæè½ï¼é²èçºæ´å®å¨ä¸æ´æ°¸çºçè²å®³ç®¡çè§£æ±ºæ¹æ¡æä¾äºä¸ç¨®æ°æ¹æ³ã

##### **Interpretability Analysis of Domain Adapted Dense Retrievers**
2501.14459v1 by Goksenin Yuksel, Jaap Kamps

Dense retrievers have demonstrated significant potential for neural
information retrieval; however, they exhibit a lack of robustness to domain
shifts, thereby limiting their efficacy in zero-shot settings across diverse
domains. Previous research has investigated unsupervised domain adaptation
techniques to adapt dense retrievers to target domains. However, these studies
have not focused on explainability analysis to understand how such adaptations
alter the model's behavior. In this paper, we propose utilizing the integrated
gradients framework to develop an interpretability method that provides both
instance-based and ranking-based explanations for dense retrievers. To generate
these explanations, we introduce a novel baseline that reveals both query and
document attributions. This method is used to analyze the effects of domain
adaptation on input attributions for query and document tokens across two
datasets: the financial question answering dataset (FIQA) and the biomedical
information retrieval dataset (TREC-COVID). Our visualizations reveal that
domain-adapted models focus more on in-domain terminology compared to
non-adapted models, exemplified by terms such as "hedge," "gold," "corona," and
"disease." This research addresses how unsupervised domain adaptation
techniques influence the behavior of dense retrievers when adapted to new
domains. Additionally, we demonstrate that integrated gradients are a viable
choice for explaining and analyzing the internal mechanisms of these opaque
neural models.

æè¦ï¼å¯éæª¢ç´¢å¨å·²è­æå¨ç¥ç¶è³è¨æª¢ç´¢æ¹é¢å·æé¡¯èçæ½åï¼ç¶èï¼å®åç¼ºä¹å°é åè½ç§»çå¥å£¯æ§ï¼å¾èéå¶äºå®åå¨ä¸åé åçé¶æ¬¡å­¸ç¿è¨­ç½®ä¸­çæè½ãååçç ç©¶èª¿æ¥äºç¡ç£ç£é åé©ææè¡ï¼ä»¥é©æå¯éæª¢ç´¢å¨ä»¥éå®é åãç¶èï¼éäºç ç©¶ä¸¦æªå°æ³¨æ¼å¯è§£éæ§åæï¼ä»¥äºè§£æ­¤é¡é©æå¦ä½æ¹è®æ¨¡åçè¡çºãå¨æ¬æä¸­ï¼æåå»ºè­°å©ç¨æ´åæ¢¯åº¦æ¡æ¶ä¾éç¼ä¸ç¨®å¯è§£éæ§æ¹æ³ï¼è©²æ¹æ³åæçºå¯éæª¢ç´¢å¨æä¾åºæ¼å¯¦ä¾ååºæ¼æåçè§£éãçºäºç¢çéäºè§£éï¼æåå¼å¥äºä¸åæ°ç©çåºæºï¼æ­ç¤ºäºæ¥è©¢åæä»¶æ­¸å ãæ­¤æ¹æ³ç¨æ¼åæé åé©æå°å©åæ¸æéä¸­æ¥è©¢åæä»¶ä»£ç¢¼è¼¸å¥æ­¸å çå½±é¿ï¼è²¡ååé¡åç­æ¸æé (FIQA) åçç©é«å­¸è³è¨æª¢ç´¢æ¸æé (TREC-COVID)ãæåçè¦è¦ºåé¡¯ç¤ºï¼èæªé©ææ¨¡åç¸æ¯ï¼é åé©ææ¨¡åæ´éæ³¨æ¼é åå§è¡èªï¼ä¾å¦ãé¿éªãããé»éãããå ççæ¯ãåãç¾çããéé ç ç©¶æ¢è¨äºç¡ç£ç£é åé©ææè¡å¦ä½å½±é¿å¯éæª¢ç´¢å¨å¨é©ææ°é åæçè¡çºãæ­¤å¤ï¼æåè­ææ´åæ¢¯åº¦æ¯è§£éååæéäºä¸éæç¥ç¶æ¨¡åçå§é¨æ©å¶çå¯è¡é¸æã

##### **Understanding and Mitigating Gender Bias in LLMs via Interpretable Neuron Editing**
2501.14457v1 by Zeping Yu, Sophia Ananiadou

Large language models (LLMs) often exhibit gender bias, posing challenges for
their safe deployment. Existing methods to mitigate bias lack a comprehensive
understanding of its mechanisms or compromise the model's core capabilities. To
address these issues, we propose the CommonWords dataset, to systematically
evaluate gender bias in LLMs. Our analysis reveals pervasive bias across models
and identifies specific neuron circuits, including gender neurons and general
neurons, responsible for this behavior. Notably, editing even a small number of
general neurons can disrupt the model's overall capabilities due to
hierarchical neuron interactions. Based on these insights, we propose an
interpretable neuron editing method that combines logit-based and causal-based
strategies to selectively target biased neurons. Experiments on five LLMs
demonstrate that our method effectively reduces gender bias while preserving
the model's original capabilities, outperforming existing fine-tuning and
editing approaches. Our findings contribute a novel dataset, a detailed
analysis of bias mechanisms, and a practical solution for mitigating gender
bias in LLMs.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) ç¶å¸¸è¡¨ç¾åºæ§å¥åè¦ï¼å°å¶å®å¨é¨ç½²æ§æææ°ãç¾æçæ¸è¼åè¦çæ¹æ³ç¼ºä¹å°å¶æ©å¶çå¨é¢çè§£ï¼ææå®³æ¨¡åçæ ¸å¿è½åãçºäºè§£æ±ºéäºåé¡ï¼æåæåº CommonWords è³æéï¼ä»¥ç³»çµ±æ§å°è©ä¼° LLM ä¸­çæ§å¥åè¦ãæåçåææ­ç¤ºäºè·¨æ¨¡åçæ®éåè¦ï¼ä¸¦è­å¥åºç¹å®ç¥ç¶åé»è·¯ï¼åæ¬æ§å¥ç¥ç¶ååä¸è¬ç¥ç¶åï¼éäºç¥ç¶åå°éç¨®è¡çºè² è²¬ãå¼å¾æ³¨æçæ¯ï¼ç±æ¼åå±¤ç¥ç¶åäº¤äºä½ç¨ï¼å³ä½¿ç·¨è¼¯å°æ¸ä¸è¬ç¥ç¶åä¹æç ´å£æ¨¡åçæ´é«è½åãåºæ¼éäºè¦è§£ï¼æåæåºäºä¸ç¨®å¯è§£éçç¥ç¶åç·¨è¼¯æ¹æ³ï¼è©²æ¹æ³çµåäºåºæ¼éè¼¯ååºæ¼å æçç­ç¥ä¾é¸ææ§å°éå°æåè¦çç¥ç¶åãå°äºå LLM çå¯¦é©è¡¨æï¼æåçæ¨¡åææå°æ¸å°äºæ§å¥åè¦ï¼åæä¿çäºæ¨¡åçåå§è½åï¼åªæ¼ç¾æçå¾®èª¿åç·¨è¼¯æ¹æ³ãæåçç ç©¶çµææä¾äºä¸åæ°çè³æéãå°åè¦æ©å¶çè©³ç´°åæï¼ä»¥åä¸ç¨®æ¸è¼ LLM ä¸­æ§å¥åè¦çå¯¦ç¨è§£æ±ºæ¹æ¡ã

##### **Learning more with the same effort: how randomization improves the robustness of a robotic deep reinforcement learning agent**
2501.14443v1 by LucÃ­a GÃ¼itta-LÃ³pez, Jaime Boal, Ãlvaro J. LÃ³pez-LÃ³pez

The industrial application of Deep Reinforcement Learning (DRL) is frequently
slowed down because of the inability to generate the experience required to
train the models. Collecting data often involves considerable time and economic
effort that is unaffordable in most cases. Fortunately, devices like robots can
be trained with synthetic experience thanks to virtual environments. With this
approach, the sample efficiency problems of artificial agents are mitigated,
but another issue arises: the need for efficiently transferring the synthetic
experience into the real world (sim-to-real).
  This paper analyzes the robustness of a state-of-the-art sim-to-real
technique known as progressive neural networks (PNNs) and studies how adding
diversity to the synthetic experience can complement it. To better understand
the drivers that lead to a lack of robustness, the robotic agent is still
tested in a virtual environment to ensure total control on the divergence
between the simulated and real models.
  The results show that a PNN-like agent exhibits a substantial decrease in its
robustness at the beginning of the real training phase. Randomizing certain
variables during simulation-based training significantly mitigates this issue.
On average, the increase in the model's accuracy is around 25% when diversity
is introduced in the training process. This improvement can be translated into
a decrease in the required real experience for the same final robustness
performance. Notwithstanding, adding real experience to agents should still be
beneficial regardless of the quality of the virtual experience fed into the
agent.

æè¦ï¼æ·±åº¦å¼·åå­¸ç¿ (DRL) çç¢æ¥­æç¨ç¶å¸¸å çºç¡æ³ç¢çè¨ç·´æ¨¡åæéçç¶é©èé²åº¦ç·©æ¢ãæ¶éè³æéå¸¸éè¦å¤§éæéåéé¢ï¼å¨è¨±å¤ææ³ä¸è² æä¸èµ·ãå¹¸éçæ¯ï¼æ©å¨äººç­è£ç½®å¯ä»¥ééèæ¬ç°å¢å©ç¨åæç¶é©é²è¡è¨ç·´ãéç¨®æ¹æ³ç·©è§£äºäººå·¥ä»£ççæ¨£æ¬æçåé¡ï¼ä½ç¢çäºå¦ä¸ååé¡ï¼éè¦ææå°å°åæç¶é©è½ç§»å°ç¾å¯¦ä¸çï¼æ¨¡æ¬å°çå¯¦ï¼ã
æ¬æåæäºæåé²çæ¨¡æ¬å°çå¯¦æè¡ï¼ç¨±çºæ¼¸é²å¼ç¥ç¶ç¶²è·¯ (PNN)ï¼çç©©å¥æ§ï¼ä¸¦ç ç©¶å¦ä½ééå¢å åæç¶é©çå¤æ¨£æ§ä¾è£åå®ãçºäºæ´æ·±å¥äºè§£å°è´ç¼ºä¹ç©©å¥æ§çé©åå ç´ ï¼æ©å¨äººä»£çä»æå¨èæ¬ç°å¢ä¸­é²è¡æ¸¬è©¦ï¼ä»¥ç¢ºä¿å°æ¨¡æ¬æ¨¡ååçå¯¦æ¨¡åä¹éçå·®ç°é²è¡å®å¨æ§å¶ã
çµæé¡¯ç¤ºï¼é¡ PNN ä»£çå¨çå¯¦è¨ç·´éæ®µéå§æï¼å¶ç©©å¥æ§å¤§å¹ä¸éãå¨åºæ¼æ¨¡æ¬çè¨ç·´æéå°æäºè®æ¸é¨æ©åï¼å¯é¡¯èç·©è§£æ­¤åé¡ãç¶å¨è¨ç·´éç¨ä¸­å¼å¥å¤æ¨£æ§æï¼æ¨¡åç²¾ç¢ºåº¦çå¹³åå¢å å¹åº¦ç´çº 25%ãæ­¤æ¹é²å¯ä»¥è½æçºå¨ç¸åçæçµç©©å¥æ§è¡¨ç¾ä¸æ¸å°æéççå¯¦ç¶é©ãåç®¡å¦æ­¤ï¼ç¡è«æä¾çµ¦ä»£ççèæ¬ç¶é©åè³ªå¦ä½ï¼çºä»£çå¢å çå¯¦ç¶é©ä»ææ¯æççã

##### **Domaino1s: Guiding LLM Reasoning for Explainable Answers in High-Stakes Domains**
2501.14431v1 by Xu Chu, Zhijie Tan, Hanlin Xue, Guanyu Wang, Tong Mo, Weiping Li

Large Language Models (LLMs) are widely applied to downstream domains.
However, current LLMs for high-stakes domain tasks, such as financial
investment and legal QA, typically generate brief answers without reasoning
processes and explanations. This limits users' confidence in making decisions
based on their responses. While original CoT shows promise, it lacks
self-correction mechanisms during reasoning. This work introduces Domain$o1$s,
which enhances LLMs' reasoning capabilities on domain tasks through supervised
fine-tuning and tree search. We construct CoT-stock-2k and CoT-legal-2k
datasets for fine-tuning models that activate domain-specific reasoning steps
based on their judgment. Additionally, we propose Selective Tree Exploration to
spontaneously explore solution spaces and sample optimal reasoning paths to
improve performance. We also introduce PROOF-Score, a new metric for evaluating
domain models' explainability, complementing traditional accuracy metrics with
richer assessment dimensions. Extensive experiments on stock investment
recommendation and legal reasoning QA tasks demonstrate Domaino1s's leading
performance and explainability. Our code is available at
https://anonymous.4open.science/r/Domaino1s-006F/.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å»£æ³æç¨æ¼ä¸æ¸¸é åã
ç¶èï¼ç®åç¨æ¼é«é¢¨éªé åä»»åç LLMï¼ä¾å¦éèæè³åæ³å¾ QAï¼éå¸¸æç¢çç°¡ç­çç­æ¡ï¼èæ²ææ¨çéç¨åè§£éãééå¶äºä½¿ç¨èæ ¹æå¶åæååºæ±ºç­çä¿¡å¿ãåç®¡åå§ç CoT é¡¯ç¤ºåºåæ¯ï¼ä½å®å¨æ¨çéç¨ä¸­ç¼ºä¹èªæä¿®æ­£æ©å¶ãéé å·¥ä½ä»ç´¹äº Domain$o1$sï¼å®ééç£ç£å¾®èª¿åæ¨¹çæå°å¢å¼·äº LLM å¨é åä»»åä¸çæ¨çè½åãæåæ§å»ºäº CoT-stock-2k å CoT-legal-2k è³æéï¼ç¨æ¼å¾®èª¿æ¨¡åï¼éäºæ¨¡åææ ¹æå¤æ·ååç¹å®é åçæ¨çæ­¥é©ãæ­¤å¤ï¼æåæåºäºé¸ææ§æ¨¹çæ¢ç´¢ï¼ä»¥èªç¼æ¢ç´¢è§£ç©ºéä¸¦æ¡æ¨£æä½³æ¨çè·¯å¾ä»¥æé«æ§è½ãæåéå¼å¥äº PROOF-Scoreï¼éæ¯ä¸åç¨æ¼è©ä¼°é åæ¨¡åå¯è§£éæ§çæ°ææ¨ï¼å®ä½¿ç¨æ´è±å¯çè©ä¼°ç¶­åº¦ä¾è£åå³çµ±çæºç¢ºæ§ææ¨ãå¨è¡ç¥¨æè³æ¨è¦åæ³å¾æ¨ç QA ä»»åä¸çå»£æ³å¯¦é©è­æäº Domaino1s çé åæ§è½åå¯è§£éæ§ãæåçç¨å¼ç¢¼å¯å¨ https://anonymous.4open.science/r/Domaino1s-006F/ åå¾ã

##### **Adaptive Rank Allocation for Federated Parameter-Efficient Fine-Tuning of Language Models**
2501.14406v1 by Fei Wu, Jia Hu, Geyong Min, Shiqiang Wang

Pre-trained Language Models (PLMs) have demonstrated their superiority and
versatility in modern Natural Language Processing (NLP), effectively adapting
to various downstream tasks through further fine-tuning. Federated
Parameter-Efficient Fine-Tuning (FedPEFT) has emerged as a promising solution
to address privacy and efficiency challenges in distributed training for PLMs
on mobile devices. However, our measurements reveal two key limitations of
FedPEFT: heterogeneous data leads to significant performance degradation, and a
fixed parameter configuration results in communication inefficiency. To
overcome these limitations, we propose FedARA, a novel Federated Adaptive Rank
Allocation for parameter-efficient fine-tuning of language models.
Specifically, FedARA employs truncated singular value decomposition (SVD)
adaptation to enhance flexibility and expressiveness, significantly mitigating
the adverse effects of data heterogeneity. Subsequently, it utilizes dynamic
rank allocation to progressively identify critical ranks, effectively improving
communication efficiency. Lastly, it leverages rank-based module pruning to
remove inactive modules, steadily reducing local training time and peak memory
usage in each round. Extensive experiments show that FedARA consistently
outperforms weak baselines by an average of 8.49\% and strong baselines by
6.95\% across various datasets under data heterogeneity while significantly
improving communication efficiency by 2.40\(\times\). Moreover, experiments on
AGX Orin, Orin Nano and Raspberry Pi 5 devices demonstrate substantial
decreases in total training time and energy consumption by up to 48.90\% and
46.95\%, respectively.

æè¦ï¼<paragraph>é è¨ç·´èªè¨æ¨¡å (PLM) å·²å±ç¾å¶å¨ç¾ä»£èªç¶èªè¨èç (NLP) ä¸­çåªè¶æ§åå¤åè½æ§ï¼ééé²ä¸æ­¥çå¾®èª¿ï¼ææå°é©æåç¨®ä¸æ¸¸ä»»åãè¯é¦åæ¸é«æå¾®èª¿ (FedPEFT) å·²æçºä¸ç¨®æåæ¯çè§£æ±ºæ¹æ¡ï¼ç¨æ¼è§£æ±ºè¡åè£ç½®ä¸ PLM åæ£å¼è¨ç·´çé±ç§åæçææ°ãç¶èï¼æåçæ¸¬éçµææ­ç¤ºäº FedPEFT çå©åä¸»è¦éå¶ï¼ç°è³ªè³ææå°è´æè½é¡¯èä¸éï¼èåºå®çåæ¸çµææå°è´éè¨æçä½ä¸ãçºäºåæéäºéå¶ï¼æåæåº FedARAï¼ä¸ç¨®ç¨æ¼èªè¨æ¨¡ååæ¸é«æå¾®èª¿çæ°åè¯é¦èªé©æç§©åéãå·é«ä¾èªªï¼FedARA æ¡ç¨æªæ·å¥ç°å¼åè§£ (SVD) é©æä¾å¢å¼·éæ´»æ§èè¡¨éåï¼å¤§å¹æ¸è¼è³æç°è³ªæ§çè² é¢å½±é¿ãé¨å¾ï¼å®å©ç¨åæç§©åéä¾éæ­¥è­å¥ééµç§©ï¼æææ¹åéè¨æçãæå¾ï¼å®å©ç¨åºæ¼ç§©çæ¨¡çµåªæä¾ç§»é¤éæ´»åæ¨¡çµï¼å¨æ¯ä¸è¼ªä¸­ç©©å®çæ¸å°ååè¨ç·´æéåå³°å¼è¨æ¶é«ä½¿ç¨éãå»£æ³çå¯¦é©é¡¯ç¤ºï¼FedARA å¨è³æç°è³ªæ§ä¸ï¼å¨åç¨®è³æéä¸ï¼å¹³ååªæ¼å¼±åºç· 8.49%ï¼åªæ¼å¼·åºç· 6.95%ï¼åæå°éè¨æçé¡¯èæé«äº 2.40 åãæ­¤å¤ï¼å¨ AGX OrinãOrin Nano å Raspberry Pi 5 è£ç½®ä¸é²è¡çå¯¦é©è­æï¼ç¸½è¨ç·´æéåè½æºæ¶èåå¥å¤§å¹æ¸å°äº 48.90% å 46.95%ã</paragraph>

##### **SKIL: Semantic Keypoint Imitation Learning for Generalizable Data-efficient Manipulation**
2501.14400v1 by Shengjie Wang, Jiacheng You, Yihang Hu, Jiongye Li, Yang Gao

Real-world tasks such as garment manipulation and table rearrangement demand
robots to perform generalizable, highly precise, and long-horizon actions.
Although imitation learning has proven to be an effective approach for teaching
robots new skills, large amounts of expert demonstration data are still
indispensible for these complex tasks, resulting in high sample complexity and
costly data collection. To address this, we propose Semantic Keypoint Imitation
Learning (SKIL), a framework which automatically obtain semantic keypoints with
help of vision foundation models, and forms the descriptor of semantic
keypoints that enables effecient imitation learning of complex robotic tasks
with significantly lower sample complexity. In real world experiments, SKIL
doubles the performance of baseline methods in tasks such as picking a cup or
mouse, while demonstrating exceptional robustness to variations in objects,
environmental changes, and distractors. For long-horizon tasks like hanging a
towel on a rack where previous methods fail completely, SKIL achieves a mean
success rate of 70\% with as few as 30 demonstrations. Furthermore, SKIL
naturally supports cross-embodiment learning due to its semantic keypoints
abstraction, our experiments demonstrate that even human videos bring
considerable improvement to the learning performance. All these results
demonstrate the great success of SKIL in achieving data-efficint generalizable
robotic learning. Visualizations and code are available at:
https://skil-robotics.github.io/SKIL-robotics/.

æè¦ï¼ç¾å¯¦ä¸ççä»»åï¼ä¾å¦æè£æä½åæ¡å­éæ°æåï¼è¦æ±æ©å¨äººå·è¡å¯æ¦æ¬ãé«åº¦ç²¾ç¢ºä¸é·æåçåä½ãåç®¡æ¨¡ä»¿å­¸ç¿å·²è¢«è­ææ¯æå°æ©å¨äººæ°æè½çæææ¹æ³ï¼ä½å°æ¼éäºè¤éä»»åä¾èªªï¼å¤§éçå°å®¶ç¤ºç¯æ¸æä»ç¶ä¸å¯æç¼ºï¼å°è´é«æ¨£æ¬è¤éåº¦åæè²´çæ¸ææ¶éãçºäºè§£æ±ºéååé¡ï¼æåæåºäºèªç¾©ééµé»æ¨¡ä»¿å­¸ç¿ (SKIL)ï¼ä¸åèªåç²åèªç¾©ééµé»çæ¡æ¶ï¼åå©è¦è¦ºåºç¤æ¨¡åï¼ä¸¦å½¢æèªç¾©ééµé»çæè¿°ç¬¦ï¼ä½¿è¤éæ©å¨äººä»»åçæææ¨¡ä»¿å­¸ç¿æçºå¯è½ï¼ä¸æ¨£æ¬è¤éåº¦é¡¯èéä½ãå¨çå¯¦ä¸ççå¯¦é©ä¸­ï¼SKIL å¨æ¾åæ¯å­ææ»é¼ ç­ä»»åä¸­å°åºç·æ¹æ³çæ§è½æé«äºä¸åï¼åæå±ç¤ºäºå°ç©é«è®åãç°å¢è®ååå¹²æ¾å ç´ çéå¡é­¯æ£æ§ãå°æ¼é·æåä»»åï¼ä¾å¦å°æ¯å·¾æå¨æ¶å­ä¸ï¼ä»¥åçè¾¦æ³å®å¨å¤±æï¼SKIL ä»¥ä½è³ 30 æ¬¡ç¤ºç¯å¯¦ç¾äº 70% çå¹³åæåçãæ­¤å¤ï¼ç±æ¼å¶èªç¾©ééµé»æ½è±¡ï¼SKIL èªç¶æ¯æ´è·¨å·é«åå­¸ç¿ï¼æåçå¯¦é©è¡¨æï¼å³ä½¿æ¯äººé¡è¦é »ä¹è½é¡¯èæé«å­¸ç¿æ§è½ãææéäºçµæé½è­æäº SKIL å¨å¯¦ç¾è³æææççå¯æ¦æ¬æ©å¨äººå­¸ç¿æ¹é¢åå¾äºå·¨å¤§æåãè¦è¦ºååç¨å¼ç¢¼å¯å¨ä»¥ä¸ä½ç½®åå¾ï¼https://skil-robotics.github.io/SKIL-robotics/ã

##### **Handling Heterophily in Recommender Systems with Wavelet Hypergraph Diffusion**
2501.14399v1 by Darnbi Sakong, Thanh Tam Nguyen

Recommender systems are pivotal in delivering personalised user experiences
across various domains. However, capturing the heterophily patterns and the
multi-dimensional nature of user-item interactions poses significant
challenges. To address this, we introduce FWHDNN (Fusion-based Wavelet
Hypergraph Diffusion Neural Networks), an innovative framework aimed at
advancing representation learning in hypergraph-based recommendation tasks. The
model incorporates three key components: (1) a cross-difference relation
encoder leveraging heterophily-aware hypergraph diffusion to adapt
message-passing for diverse class labels, (2) a multi-level cluster-wise
encoder employing wavelet transform-based hypergraph neural network layers to
capture multi-scale topological relationships, and (3) an integrated
multi-modal fusion mechanism that combines structural and textual information
through intermediate and late-fusion strategies. Extensive experiments on
real-world datasets demonstrate that FWHDNN surpasses state-of-the-art methods
in accuracy, robustness, and scalability in capturing high-order
interconnections between users and items.

æè¦ï¼æ¨è¦ç³»çµ±å¨æä¾åäººåä½¿ç¨èé«é©æ¹é¢è³ééè¦ï¼æ©«è·¨åç¨®é åãç¶èï¼ææç°è³ªæ§æ¨¡å¼åä½¿ç¨èèé ç®äºåçå¤ç¶­æ¬è³ªæé æéå¤§çææ°ãçºäºè§£æ±ºéååé¡ï¼æåå¼é²äº FWHDNNï¼åºæ¼èåçæ³¢å½¢è¶åæ´æ£ç¥ç¶ç¶²è·¯ï¼ï¼éæ¯ä¸ååµæ°çæ¶æ§ï¼æ¨å¨æ¨åè¶åæ¨è¦ä»»åä¸­çè¡¨å¾µå­¸ç¿ãéåæ¨¡ååå«äºä¸åééµçµæé¨åï¼(1) è·¨å·®ç°éä¿ç·¨ç¢¼å¨ï¼å©ç¨ç°è³ªæ§æç¥è¶åæ´æ£ä¾èª¿æ´è¨æ¯å³éä»¥é©æä¸åçé¡å¥æ¨ç±¤ï¼(2) å¤å±¤ç´å¢éç·¨ç¢¼å¨ï¼æ¡ç¨åºæ¼å°æ³¢è½æçè¶åç¥ç¶ç¶²è·¯å±¤ï¼ä»¥ææå¤å°ºåº¦ææ²éä¿ï¼ä»¥å (3) æ´åå¤æ¨¡å¼èåæ©å¶ï¼ééä¸­éèååå¾æèåç­ç¥ï¼çµåçµæ§ååæå­è³è¨ãå¨çå¯¦ä¸çè³æéä¸é²è¡çå»£æ³å¯¦é©è­æï¼FWHDNN å¨ææä½¿ç¨èåé ç®ä¹éçé«éäºé£æ¹é¢ï¼è¶è¶äºæåé²çæ¹æ³ï¼å¨æºç¢ºæ§ãç©©å¥æ§åå¯æ´åæ§ä¸é½æææåã

##### **ECTIL: Label-efficient Computational Tumour Infiltrating Lymphocyte (TIL) assessment in breast cancer: Multicentre validation in 2,340 patients with breast cancer**
2501.14379v1 by Yoni Schirris, Rosie Voorthuis, Mark Opdam, Marte Liefaard, Gabe S Sonke, Gwen Dackus, Vincent de Jong, Yuwei Wang, Annelot Van Rossum, Tessa G Steenbruggen, Lars C Steggink, Liesbeth G. E. de Vries, Marc van de Vijver, Roberto Salgado, Efstratios Gavves, Paul J van Diest, Sabine C Linn, Jonas Teuwen, Renee Menezes, Marleen Kok, Hugo Horlings

The level of tumour-infiltrating lymphocytes (TILs) is a prognostic factor
for patients with (triple-negative) breast cancer (BC). Computational TIL
assessment (CTA) has the potential to assist pathologists in this
labour-intensive task, but current CTA models rely heavily on many detailed
annotations. We propose and validate a fundamentally simpler deep learning
based CTA that can be trained in only ten minutes on hundredfold fewer
pathologist annotations. We collected whole slide images (WSIs) with TILs
scores and clinical data of 2,340 patients with BC from six cohorts including
three randomised clinical trials. Morphological features were extracted from
whole slide images (WSIs) using a pathology foundation model. Our
label-efficient Computational stromal TIL assessment model (ECTIL) directly
regresses the TILs score from these features. ECTIL trained on only a few
hundred samples (ECTIL-TCGA) showed concordance with the pathologist over five
heterogeneous external cohorts (r=0.54-0.74, AUROC=0.80-0.94). Training on all
slides of five cohorts (ECTIL-combined) improved results on a held-out test set
(r=0.69, AUROC=0.85). Multivariable Cox regression analyses indicated that
every 10% increase of ECTIL scores was associated with improved overall
survival independent of clinicopathological variables (HR 0.86, p<0.01),
similar to the pathologist score (HR 0.87, p<0.001). We demonstrate that ECTIL
is highly concordant with an expert pathologist and obtains a similar hazard
ratio. ECTIL has a fundamentally simpler design than existing methods and can
be trained on orders of magnitude fewer annotations. Such a CTA may be used to
pre-screen patients for, e.g., immunotherapy clinical trial inclusion, or as a
tool to assist clinicians in the diagnostic work-up of patients with BC. Our
model is available under an open source licence
(https://github.com/nki-ai/ectil).

æè¦ï¼è¿ç¤æµ¸æ¶¦æ·å·´ç»è (TIL) çæ°´å¹³æ¯ (ä¸é´æ§) ä¹³èºç (BC) æ£èçé¢åå ç´ ãè®¡ç® TIL è¯ä¼° (CTA) æå¯è½åå©ççå­¦å®¶å®æè¿é¡¹å³å¨å¯éåä»»å¡ï¼ä½ç®åç CTA æ¨¡åä¸¥éä¾èµäºè®¸å¤è¯¦ç»çæ³¨éãæä»¬æåºå¹¶éªè¯äºä¸ä¸ªåºäºæ·±åº¦å­¦ä¹ ç CTAï¼å®å¯ä»¥å¨å ç¾åæ´å°çççå­¦å®¶æ³¨éä¸ä»å¨ååéåè¿è¡è®­ç»ãæä»¬ä»å­ä¸ªéåä¸­æ¶éäº 2,340 å BC æ£èç TILs è¯ååä¸´åºæ°æ®çå¨ç»çå¾å (WSI)ï¼å¶ä¸­åæ¬ä¸é¡¹éæºä¸´åºè¯éªãä½¿ç¨ççåºç¡æ¨¡åä»å¨ç»çå¾å (WSI) ä¸­æåå½¢æå­¦ç¹å¾ãæä»¬çæ ç­¾é«æè®¡ç®åºè´¨ TIL è¯ä¼°æ¨¡å (ECTIL) ç´æ¥ä»è¿äºç¹å¾ä¸­åå½ TILs è¯åãä»å¨å ç¾ä¸ªæ ·æ¬ä¸è¿è¡è®­ç»ç ECTILï¼ECTIL-TCGAï¼æ¾ç¤ºåºä¸ççå­¦å®¶å¨äºä¸ªå¼è´¨å¤é¨éåä¸­çä¸è´æ§ï¼r=0.54-0.74ï¼AUROC=0.80-0.94ï¼ãå¨äºä¸ªéåçææç»çä¸è¿è¡è®­ç»ï¼ECTIL-combinedï¼æ¹åäºä¿çæµè¯éä¸çç»æï¼r=0.69ï¼AUROC=0.85ï¼ãå¤åé Cox åå½åæè¡¨æï¼ECTIL è¯åæ¯å¢å  10%ï¼ä¸ä¸´åºççå­¦åéæ å³çæ»ä½çå­çå°±ä¼æé«ï¼HR 0.86ï¼p<0.01ï¼ï¼ç±»ä¼¼äºççå­¦å®¶è¯åï¼HR 0.87ï¼p<0.001ï¼ãæä»¬è¯æ ECTIL ä¸ä¸å®¶ççå­¦å®¶é«åº¦ä¸è´ï¼å¹¶è·å¾äºç±»ä¼¼çé£é©æ¯ãECTIL çè®¾è®¡æ¯ç°ææ¹æ³ä»æ ¹æ¬ä¸æ´ç®åï¼å¹¶ä¸å¯ä»¥å¨æ°éçº§æ´å°çæ³¨éä¸è¿è¡è®­ç»ãè¿ç§ CTA å¯ç¨äºå¯¹æ£èè¿è¡é¢ç­éï¼ä¾å¦åç«æ²»çä¸´åºè¯éªçº³å¥ï¼æä½ä¸ºä¸ç§å·¥å·æ¥å¸®å©ä¸´åºå»çå¯¹ BC æ£èè¿è¡è¯æ­æ£æ¥ãæä»¬çæ¨¡åå¯å¨å¼æ¾æºä»£ç è®¸å¯ä¸è·å¾ (https://github.com/nki-ai/ectil)ã

##### **DRESSing Up LLM: Efficient Stylized Question-Answering via Style Subspace Editing**
2501.14371v1 by Xinyu Ma, Yifeng Xu, Yang Lin, Tianlong Wang, Xu Chu, Xin Gao, Junfeng Zhao, Yasha Wang

We introduce DRESS, a novel approach for generating stylized large language
model (LLM) responses through representation editing. Existing methods like
prompting and fine-tuning are either insufficient for complex style adaptation
or computationally expensive, particularly in tasks like NPC creation or
character role-playing. Our approach leverages the over-parameterized nature of
LLMs to disentangle a style-relevant subspace within the model's representation
space to conduct representation editing, ensuring a minimal impact on the
original semantics. By applying adaptive editing strengths, we dynamically
adjust the steering vectors in the style subspace to maintain both stylistic
fidelity and semantic integrity. We develop two stylized QA benchmark datasets
to validate the effectiveness of DRESS, and the results demonstrate significant
improvements compared to baseline methods such as prompting and ITI. In short,
DRESS is a lightweight, train-free solution for enhancing LLMs with flexible
and effective style control, making it particularly useful for developing
stylized conversational agents. Codes and benchmark datasets are available at
https://github.com/ArthurLeoM/DRESS-LLM.

æè¦ï¼æåä»ç´¹ DRESSï¼éæ¯ä¸ç¨®ééè¡¨å¾µç·¨è¼¯ä¾ç¢çé¢¨æ ¼åå¤§åèªè¨æ¨¡å (LLM) åæçæ°ç©æ¹æ³ãæç¤ºåå¾®èª¿ç­ç¾ææ¹æ³å°æ¼è¤éçé¢¨æ ¼é©æèè¨è¦åä¸è¶³ï¼è¦åè¨ç®ææ¬é«æï¼å°¤å¶æ¯å¨ NPC å»ºç«æè§è²æ®æ¼ç­ä»»åä¸­ãæåçåæ³å©ç¨ LLM çéåº¦åæ¸åæ§è³ªï¼å¨æ¨¡åçè¡¨å¾µç©ºéä¸­è§£éä¸åèé¢¨æ ¼ç¸éçå­ç©ºéï¼ä»¥é²è¡è¡¨å¾µç·¨è¼¯ï¼ç¢ºä¿å°åå§èªç¾©çå½±é¿æå°ãééæç¨èªé©æç·¨è¼¯å¼·åº¦ï¼æååæèª¿æ´é¢¨æ ¼å­ç©ºéä¸­çå¼å°åéï¼ä»¥ç¶­æé¢¨æ ¼ä¿çåº¦åèªç¾©å®æ´æ§ãæåéç¼äºå©åé¢¨æ ¼åçåç­åºæºè³æéï¼ä»¥é©è­ DRESS çæææ§ï¼çµæé¡¯ç¤ºèæç¤ºå ITI ç­åºæºæ¹æ³ç¸æ¯æé¡¯èçæ¹é²ãç°¡èè¨ä¹ï¼DRESS æ¯ä¸ç¨®è¼éç´ãåè¨ç·´çè§£æ±ºæ¹æ¡ï¼å¯ç¨æ¼å¢å¼· LLMï¼å·åéæ´»ä¸ææçé¢¨æ ¼æ§å¶ï¼ä½¿å¶ç¹å¥é©ç¨æ¼éç¼é¢¨æ ¼åçå°è©±ä»£çãç¨å¼ç¢¼ååºæºè³æéå¯å¨ https://github.com/ArthurLeoM/DRESS-LLM åå¾ã

##### **In System Alignments we Trust! Explainable Alignments via Projections**
2501.14360v1 by Dominique Sommers, Natalia Sidorova, Boudewijn van Dongen

Alignments are a well-known process mining technique for reconciling system
logs and normative process models. Evidence of certain behaviors in a real
system may only be present in one representation - either a log or a model -
but not in the other. Since for processes in which multiple entities, like
objects and resources, are involved in the activities, their interactions
affect the behavior and are therefore essential to take into account in the
alignments.
  Additionally, both logged and modeled representations of reality may be
imprecise and only partially represent some of these entities, but not all. In
this paper, we introduce the concept of "relaxations" through projections for
alignments to deal with partially correct models and logs. Relaxed alignments
help to distinguish between trustworthy and untrustworthy content of the two
representations (the log and the model) to achieve a better understanding of
the underlying process and expose quality issues.

æè¦ï¼å°é½æ¯èª¿åç³»çµ±ç´éåè¦ç¯æµç¨æ¨¡åçç¥åæµç¨æ¢åæè¡ãå¨çå¯¦ç³»çµ±ä¸­ç¹å®è¡çºçè­æå¯è½åªå­å¨æ¼ä¸åè¡¨ç¤ºæ³ï¼å¯è½æ¯ç´éææ¨¡åï¼ï¼èä¸å¨å¦ä¸åè¡¨ç¤ºæ³ä¸­ãç±æ¼å¨æµç¨ä¸­ï¼å¤åå¯¦é«ï¼ä¾å¦ç©ä»¶åè³æºï¼æåèæ´»åï¼å æ­¤å®åçäºåæå½±é¿è¡çºï¼å æ­¤å¨å°é½æå¿é å°å®åç´å¥èéã
æ­¤å¤ï¼ç¾å¯¦çè¨éåæ¨¡åè¡¨ç¤ºæ³é½å¯è½ä¸ç²¾ç¢ºï¼èä¸å¯è½åªé¨åè¡¨ç¤ºéäºå¯¦é«ä¸­çä¸äºï¼èä¸æ¯å¨é¨ãå¨æ¬æä¸­ï¼æåééæå½±å¼å¥äºãæ¾é¬ãçæ¦å¿µï¼ä»¥èçé¨åæ­£ç¢ºçæ¨¡ååç´éçå°é½ãæ¾é¬å°é½æå©æ¼ååå©åè¡¨ç¤ºæ³ï¼ç´éåæ¨¡åï¼ä¸­å¼å¾ä¿¡è³´åä¸å¯ä¿¡è³´çå§å®¹ï¼ä»¥æ´å¥½å°çè§£åºç¤æµç¨ä¸¦æ­é²åè³ªåé¡ã

##### **HorNets: Learning from Discrete and Continuous Signals with Routing Neural Networks**
2501.14346v1 by Boshko koloski, Nada LavraÄ, BlaÅ¾ Å krlj

Construction of neural network architectures suitable for learning from both
continuous and discrete tabular data is a challenging research endeavor.
Contemporary high-dimensional tabular data sets are often characterized by a
relatively small instance count, requiring data-efficient learning. We propose
HorNets (Horn Networks), a neural network architecture with state-of-the-art
performance on synthetic and real-life data sets from scarce-data tabular
domains. HorNets are based on a clipped polynomial-like activation function,
extended by a custom discrete-continuous routing mechanism that decides which
part of the neural network to optimize based on the input's cardinality. By
explicitly modeling parts of the feature combination space or combining whole
space in a linear attention-like manner, HorNets dynamically decide which mode
of operation is the most suitable for a given piece of data with no explicit
supervision. This architecture is one of the few approaches that reliably
retrieves logical clauses (including noisy XNOR) and achieves state-of-the-art
classification performance on 14 real-life biomedical high-dimensional data
sets. HorNets are made freely available under a permissive license alongside a
synthetic generator of categorical benchmarks.

æè¦ï¼æ§å»ºé©åå¾é£çºåé¢æ£è¡¨æ ¼è³æå­¸ç¿çç¥ç¶ç¶²è·¯æ¶æ§æ¯ä¸é å·æææ°æ§çç ç©¶å·¥ä½ã
ç¶ä»£é«ç¶­åº¦è¡¨æ ¼è³æééå¸¸çç¹å¾µæ¯å¯¦ä¾æ¸éç¸å°è¼å°ï¼éè¦è³æææå­¸ç¿ãæåæåº HorNetsï¼éæ©ç¶²è·¯ï¼ï¼ä¸ç¨®å¨ç¨çè³æè¡¨æ ¼é åçåæåçå¯¦è³æéä¸å·ææåé²æè½çç¥ç¶ç¶²è·¯æ¶æ§ãHorNets åºæ¼ä¸åè£åªçå¤é å¼é¡æ¿æ´»å½æ¸ï¼ä¸¦ç±ä¸åèªè¨é¢æ£é£çºè·¯ç±æ©å¶æ´åï¼è©²æ©å¶æ ¹æè¼¸å¥çåºæ¸ä¾æ±ºå®è¦åªåç¥ç¶ç¶²è·¯çåªä¸é¨åãééæç¢ºå»ºæ¨¡ç¹å¾µçµåç©ºéçä¸é¨åæä»¥ç·æ§æ³¨æåé¡çæ¹å¼çµåæ´åç©ºéï¼HorNets åææ±ºå®åªç¨®éä½æ¨¡å¼æé©åçµ¦å®çè³æé¨åï¼èä¸éè¦æç¢ºç£ç£ãéç¨®æ¶æ§æ¯å°æ¸å¯é æ·åéè¼¯å­å¥ï¼åæ¬éè¨ XNORï¼çæ¹æ³ä¹ä¸ï¼ä¸¦å¨ 14 åçå¯¦çç©é«å­¸é«ç¶­åº¦è³æéä¸éææåé²çåé¡æè½ãHorNets å¨å¯¬é¬è¨±å¯è­ä¸åè²»æä¾ï¼ä¸¦éæä¸åé¡å¥åºæºçåæç¢çå¨ã

##### **Chain-of-Retrieval Augmented Generation**
2501.14342v1 by Liang Wang, Haonan Chen, Nan Yang, Xiaolong Huang, Zhicheng Dou, Furu Wei

This paper introduces an approach for training o1-like RAG models that
retrieve and reason over relevant information step by step before generating
the final answer. Conventional RAG methods usually perform a single retrieval
step before the generation process, which limits their effectiveness in
addressing complex queries due to imperfect retrieval results. In contrast, our
proposed method, CoRAG (Chain-of-Retrieval Augmented Generation), allows the
model to dynamically reformulate the query based on the evolving state. To
train CoRAG effectively, we utilize rejection sampling to automatically
generate intermediate retrieval chains, thereby augmenting existing RAG
datasets that only provide the correct final answer. At test time, we propose
various decoding strategies to scale the model's test-time compute by
controlling the length and number of sampled retrieval chains. Experimental
results across multiple benchmarks validate the efficacy of CoRAG, particularly
in multi-hop question answering tasks, where we observe more than 10 points
improvement in EM score compared to strong baselines. On the KILT benchmark,
CoRAG establishes a new state-of-the-art performance across a diverse range of
knowledge-intensive tasks. Furthermore, we offer comprehensive analyses to
understand the scaling behavior of CoRAG, laying the groundwork for future
research aimed at developing factual and grounded foundation models.

æè¦ï¼æ¬æä»ç´¹ä¸ç¨®è¨ç·´é¡ä¼¼ o1 ç RAG æ¨¡åçæ¹æ³ï¼è©²æ¨¡åå¨ç¢çæçµç­æ¡ä¹åï¼æéæ­¥æ·åä¸¦æ¨çç¸éè³è¨ãå³çµ±ç RAG æ¹æ³éå¸¸å¨ç¢çéç¨ä¹åå·è¡å®ä¸æ·åæ­¥é©ï¼éæéå¶å®åå¨èçè¤éæ¥è©¢æçæææ§ï¼å çºæ·åçµæä¸å®ç¾ãç¸åï¼æåæåºçæ¹æ³ CoRAGï¼æ·åå¢å¼·çæéï¼åè¨±æ¨¡åæ ¹ææ¼åçæåæéæ°è¡¨è¿°æ¥è©¢ãçºäºææè¨ç·´ CoRAGï¼æåå©ç¨æçµæ½æ¨£èªåç¢çä¸­éæ·åéï¼å¾èæ´åç¾æç RAG è³æéï¼éäºè³æéåªæä¾æ­£ç¢ºçæçµç­æ¡ãå¨æ¸¬è©¦æï¼æåæåºåç¨®è§£ç¢¼ç­ç¥ï¼ééæ§å¶æ½æ¨£æ·åéçé·åº¦åæ¸éä¾æ´åæ¨¡åçæ¸¬è©¦æééç®ãå¨å¤ååºæºæ¸¬è©¦ä¸­çå¯¦é©çµæé©è­äº CoRAG çæè½ï¼ç¹å¥æ¯å¨å¤è·³å¼åç­ä»»åä¸­ï¼æåè§å¯å° EM åæ¸æ¯å¼·å¤§çåºç·æ¹é²äº 10 åä»¥ä¸ãå¨ KILT åºæºæ¸¬è©¦ä¸­ï¼CoRAG å¨åç¨®ç¥è­å¯éåä»»åä¸­å»ºç«äºæ°çæåé²æè½ãæ­¤å¤ï¼æåæä¾å¨é¢çåæä¾äºè§£ CoRAG çæ´åè¡çºï¼çºæªä¾æ¨å¨éç¼äºå¯¦ååºç¤åºç¤æ¨¡åçç ç©¶å¥ å®åºç¤ã

##### **Exploring the sustainable scaling of AI dilemma: A projective study of corporations' AI environmental impacts**
2501.14334v1 by ClÃ©ment Desroches, Martin Chauvin, Louis Ladan, Caroline Vateau, Simon Gosset, Philippe Cordier

The rapid growth of artificial intelligence (AI), particularly Large Language
Models (LLMs), has raised concerns regarding its global environmental impact
that extends beyond greenhouse gas emissions to include consideration of
hardware fabrication and end-of-life processes. The opacity from major
providers hinders companies' abilities to evaluate their AI-related
environmental impacts and achieve net-zero targets.In this paper, we propose a
methodology to estimate the environmental impact of a company's AI portfolio,
providing actionable insights without necessitating extensive AI and Life-Cycle
Assessment (LCA) expertise. Results confirm that large generative AI models
consume up to 4600x more energy than traditional models. Our modelling
approach, which accounts for increased AI usage, hardware computing efficiency,
and changes in electricity mix in line with IPCC scenarios, forecasts AI
electricity use up to 2030. Under a high adoption scenario, driven by
widespread Generative AI and agents adoption associated to increasingly complex
models and frameworks, AI electricity use is projected to rise by a factor of
24.4.Mitigating the environmental impact of Generative AI by 2030 requires
coordinated efforts across the AI value chain. Isolated measures in hardware
efficiency, model efficiency, or grid improvements alone are insufficient. We
advocate for standardized environmental assessment frameworks, greater
transparency from the all actors of the value chain and the introduction of a
"Return on Environment" metric to align AI development with net-zero goals.

æè¦ï¼äººå·¥æºæ§ï¼AIï¼ï¼ç¹å¥æ¯å¤§åèªè¨æ¨¡åï¼LLMï¼çå¿«éç¼å±ï¼å¼ç¼äºå°å¶å¨çç°å¢å½±é¿çææï¼å¶å½±é¿ç¯åä¸åéæ¼æº«å®¤æ°£é«ææ¾ï¼éåæ¬å°ç¡¬é«è£½é åå ±å»¢æµç¨çèéãä¸»è¦ä¾æåçä¸éææ§é»ç¤äºå¬å¸è©ä¼°å¶ AI ç¸éç°å¢å½±é¿ä¸¦å¯¦ç¾æ·¨é¶ç®æ¨çè½åãå¨æ¬æä¸­ï¼æåæåºäºä¸ç¨®æ¹æ³ï¼ç¨æ¼ä¼°è¨å¬å¸ AI çµåçç°å¢å½±é¿ï¼æä¾å¯è¡çè¦è§£ï¼èç¡éå¤§éç AI åçå½é±æè©ä¼° (LCA) å°æ¥­ç¥è­ãçµæè­å¯¦ï¼å¤§åçæå¼ AI æ¨¡åæ¶èçè½æºæ¯å³çµ±æ¨¡åå¤é 4600 åãæåçå»ºæ¨¡æ¹æ³èæ®äº AI ä½¿ç¨éçå¢å ãç¡¬é«éç®æçä»¥åè IPCC æå¢ä¸è´çé»åçµæ§è®åï¼é æ¸¬äº AI çé»åä½¿ç¨éè³ 2030 å¹´ãå¨é«æ¡ç¨çæå¢ä¸ï¼åå»£æ³æ¡ç¨ççæå¼ AI åä»£çäººæ¡ç¨æé©åï¼éäºä»£çäººèæ¥çè¤éçæ¨¡ååæ¶æ§ç¸éï¼é è¨ AI é»åä½¿ç¨éå°å¢å  24.4 åãå° 2030 å¹´æ¸è¼çæå¼ AI çç°å¢å½±é¿éè¦å¨æ´å AI å¹å¼éä¸­åèª¿åªåãå®é ç¡¬é«æçãæ¨¡åæçæé»ç¶²æ¹åç­å­¤ç«æªæ½æ¯ä¸å¤ çãæåæå¡æ¨æºåçç°å¢è©ä¼°æ¡æ¶ãå¹å¼éä¸­ææåèèçæ´å¤§éæåº¦ï¼ä»¥åå¼å¥ãç°å¢æè³å ±é¬çãææ¨ï¼ä»¥ä½¿ AI éç¼èæ·¨é¶ç®æ¨ä¿æä¸è´ã

##### **Clear Minds Think Alike: What Makes LLM Fine-tuning Robust? A Study of Token Perplexity**
2501.14315v1 by Chao-Chung Wu, Zhi Rui Tam, Chieh-Yen Lin, Hung-yi Lee, Yun-Nung Chen

Maintaining consistent model performance across domains is a fundamental
challenge in machine learning. While recent work has explored using
LLM-generated data for fine-tuning, its impact on cross-domain generalization
remains poorly understood. In this paper, we present a systematic analysis
revealing that fine-tuning with LLM-generated data not only improves target
task performance but also reduces out-of-domain (OOD) degradation compared to
fine-tuning with ground truth data. Through analyzing the data sequence in
tasks of various domains, we demonstrate that this enhanced OOD robustness
stems from a reduced prevalence of high perplexity tokens in LLM-generated
sequences. Following this hypothesis we showed that masking high perplexity
tokens in ground truth training data also achieves similar OOD preservation
comparable to using LLM-generated data. Extensive experiments across diverse
model architectures and scales, including Gemma2-2B, Mistral-7B and Llama3-8B,
corroborate the consistency of our findings. To the best of our knowledge, this
work provides the first mechanistic explanation for the superior OOD robustness
conferred by LLM-generated training data, offering valuable insights for
developing more robust fine-tuning strategies.

æè¦ï¼å¨æ©å¨å­¸ç¿ä¸­ï¼ç¶­ææ¨¡åå¨ä¸åé åä¸­çä¸è´æè½æ¯ä¸é åºæ¬çææ°ãéç¶æè¿çç ç©¶æ¢è¨äºä½¿ç¨ LLM çæçè³æé²è¡å¾®èª¿ï¼ä½å®å°è·¨é åæ³åçå½±é¿ä»ç¶ç¥ä¹çå°ãå¨æ¬æä¸­ï¼æåæåºä¸åç³»çµ±æ§çåæï¼æ­ç¤ºä½¿ç¨ LLM çæçè³æé²è¡å¾®èª¿ä¸åå¯ä»¥æ¹åç®æ¨ä»»åçæè½ï¼èä¸èä½¿ç¨çå¯¦è³æé²è¡å¾®èª¿ç¸æ¯ï¼éè½æ¸å°é åå¤ (OOD) çéåãééåæä¸åé åä»»åä¸­çè³æåºåï¼æåè­æäºéç¨®å¢å¼·ç OOD ç©©å¥æ§æºæ¼ LLM çæçåºåä¸­é«å°æåº¦æ¨è¨çç¼ççéä½ãæ ¹æéååè¨­ï¼æåè¡¨æå¨çå¯¦è¨ç·´è³æä¸­é®è½é«å°æåº¦æ¨è¨ä¹å¯ä»¥å¯¦ç¾èä½¿ç¨ LLM çæçè³æç¸ä¼¼ç OOD ä¿çãå¨åæ¬ Gemma2-2BãMistral-7B å Llama3-8B å¨å§çåç¨®æ¨¡åæ¶æ§åè¦æ¨¡ä¸­é²è¡çå»£æ³å¯¦é©ï¼è­å¯¦äºæåç¼ç¾çä¸è´æ§ãææåæç¥ï¼éé å·¥ä½é¦æ¬¡æä¾äº LLM çæçè¨ç·´è³æè³¦äºçåªç° OOD ç©©å¥æ§çæ©å¶è§£éï¼çºéç¼æ´ç©©å¥çå¾®èª¿ç­ç¥æä¾äºå¯¶è²´çè¦è§£ã

##### **Permutation-based multi-objective evolutionary feature selection for high-dimensional data**
2501.14310v1 by Raquel Espinosa, Gracia SÃ¡nchez, JosÃ© Palma, Fernando JimÃ©nez

Feature selection is a critical step in the analysis of high-dimensional
data, where the number of features often vastly exceeds the number of samples.
Effective feature selection not only improves model performance and
interpretability but also reduces computational costs and mitigates the risk of
overfitting. In this context, we propose a novel feature selection method for
high-dimensional data, based on the well-known permutation feature importance
approach, but extending it to evaluate subsets of attributes rather than
individual features. This extension more effectively captures how interactions
among features influence model performance. The proposed method employs a
multi-objective evolutionary algorithm to search for candidate feature subsets,
with the objectives of maximizing the degradation in model performance when the
selected features are shuffled, and minimizing the cardinality of the feature
subset. The effectiveness of our method has been validated on a set of 24
publicly available high-dimensional datasets for classification and regression
tasks, and compared against 9 well-established feature selection methods
designed for high-dimensional problems, including the conventional permutation
feature importance method. The results demonstrate the ability of our approach
in balancing accuracy and computational efficiency, providing a powerful tool
for feature selection in complex, high-dimensional datasets.

æè¦ï¼ç¹å¾µé¸ææ¯é«ç¶­åº¦è³æåæä¸­çä¸åééµæ­¥é©ï¼å¶ä¸­ç¹å¾µæ¸ç®éå¸¸é é è¶éæ¨£æ¬æ¸ç®ãææçç¹å¾µé¸æä¸åå¯ä»¥æåæ¨¡åæè½åå¯è§£éæ§ï¼éè½éä½éç®ææ¬ä¸¦æ¸è¼éåº¦æ¬åçé¢¨éªãå¨æ­¤èçµ¡ä¸­ï¼æåæåºä¸åéå°é«ç¶­åº¦è³æçæ°ç©ç¹å¾µé¸ææ¹æ³ï¼å®åºæ¼èåçç½®æç¹å¾µéè¦æ§æ¹æ³ï¼ä½å°å¶æ´å±çºè©ä¼°å±¬æ§å­éï¼èéåå¥ç¹å¾µãæ­¤æ´å±æ´ææå°ææç¹å¾µä¹éçäºåå¦ä½å½±é¿æ¨¡åæè½ãææåºçæ¹æ³æ¡ç¨å¤ç®æ¨æ¼åæ¼ç®æ³ä¾æå°åé¸ç¹å¾µå­éï¼ç®æ¨çºæå¤§åæ¨¡åæè½çä¸éç¨åº¦ï¼ç¶æé¸ç¹å¾µè¢«æ´çæï¼ï¼ä¸¦æå°åç¹å¾µå­éçåºæ¸ãæåçæ¹æ³çæææ§å·²å¨ 24 åå¬éçé«ç¶­åº¦è³æéä¸ç²å¾é©è­ï¼éäºè³æéé©ç¨æ¼åé¡ååæ­¸ä»»åï¼ä¸¦è 9 ç¨®éå°é«ç¶­åº¦åé¡è¨­è¨çãå®åçç¹å¾µé¸ææ¹æ³é²è¡æ¯è¼ï¼åæ¬å³çµ±çç½®æç¹å¾µéè¦æ§æ¹æ³ãçµæè­æäºæåçæ¹æ³å¨å¹³è¡¡æºç¢ºæ§åéç®æçæ¹é¢çè½åï¼çºè¤éãé«ç¶­åº¦è³æéä¸­çç¹å¾µé¸ææä¾äºä¸åå¼·å¤§çå·¥å·ã

##### **Learning Primitive Relations for Compositional Zero-Shot Learning**
2501.14308v1 by Insu Lee, Jiseob Kim, Kyuhong Shim, Byonghyo Shim

Compositional Zero-Shot Learning (CZSL) aims to identify unseen state-object
compositions by leveraging knowledge learned from seen compositions. Existing
approaches often independently predict states and objects, overlooking their
relationships. In this paper, we propose a novel framework, learning primitive
relations (LPR), designed to probabilistically capture the relationships
between states and objects. By employing the cross-attention mechanism, LPR
considers the dependencies between states and objects, enabling the model to
infer the likelihood of unseen compositions. Experimental results demonstrate
that LPR outperforms state-of-the-art methods on all three CZSL benchmark
datasets in both closed-world and open-world settings. Through qualitative
analysis, we show that LPR leverages state-object relationships for unseen
composition prediction.

æè¦ï¼çµåé¶æ¨£æ¬å­¸ç¿ (CZSL) æ¨å¨éééç¨å¾å·²è¦çµåä¸­å­¸ç¿å°çç¥è­ä¾è­å¥æªè¦ççæ-ç©ä»¶çµåãç¾ææ¹æ³éå¸¸ç¨ç«é æ¸¬çæåç©ä»¶ï¼å¿½ç¥å®åä¹éçéä¿ãå¨æ¬æä¸­ï¼æåæåºä¸åæ°ç©çæ¶æ§ï¼å­¸ç¿åå§éä¿ (LPR)ï¼æ¨å¨ä»¥æ©çæ¹å¼ææçæåç©ä»¶ä¹éçéä¿ãééæ¡ç¨äº¤åæ³¨æåæ©å¶ï¼LPR èæ®çæåç©ä»¶ä¹éçä¾è³´éä¿ï¼ä½¿æ¨¡åè½å¤ æ¨è«æªè¦çµåçå¯è½æ§ãå¯¦é©çµæè­æï¼å¨å°éä¸çåéæ¾ä¸çè¨­å®ä¸­ï¼LPR å¨ææä¸å CZSL åºæºè³æéä¸é½åªæ¼æåé²çæ¹æ³ãééå®æ§åæï¼æåå±ç¤º LPR å©ç¨çæ-ç©ä»¶éä¿é²è¡æªè¦çµåé æ¸¬ã

##### **A Zero-Shot LLM Framework for Automatic Assignment Grading in Higher Education**
2501.14305v1 by Calvin Yeung, Jeff Yu, King Chau Cheung, Tat Wing Wong, Chun Man Chan, Kin Chi Wong, Keisuke Fujii

Automated grading has become an essential tool in education technology due to
its ability to efficiently assess large volumes of student work, provide
consistent and unbiased evaluations, and deliver immediate feedback to enhance
learning. However, current systems face significant limitations, including the
need for large datasets in few-shot learning methods, a lack of personalized
and actionable feedback, and an overemphasis on benchmark performance rather
than student experience. To address these challenges, we propose a Zero-Shot
Large Language Model (LLM)-Based Automated Assignment Grading (AAG) system.
This framework leverages prompt engineering to evaluate both computational and
explanatory student responses without requiring additional training or
fine-tuning. The AAG system delivers tailored feedback that highlights
individual strengths and areas for improvement, thereby enhancing student
learning outcomes. Our study demonstrates the system's effectiveness through
comprehensive evaluations, including survey responses from higher education
students that indicate significant improvements in motivation, understanding,
and preparedness compared to traditional grading methods. The results validate
the AAG system's potential to transform educational assessment by prioritizing
learning experiences and providing scalable, high-quality feedback.

æè¦ï¼èªåè©åå·²æçºæè²æè¡ä¸­ä¸å¯æç¼ºçå·¥å·ï¼å çºå®è½ææè©éå¤§éçå­¸çä½æ¥­ãæä¾ä¸è´ä¸å¬æ­£çè©éï¼ä¸¦æä¾ç«å³åé¥ä»¥å¢é²å­¸ç¿ãç¶èï¼ç®åçç³»çµ±é¢è¨å´éçéå¶ï¼åæ¬å°æ¨£æ¬å­¸ç¿æ¹æ³ä¸­éè¦å¤§éçè³æéãç¼ºä¹åäººåä¸å¯è¡çåé¥ï¼ä»¥åéåº¦éè¦åºæºè¡¨ç¾èéå­¸çé«é©ãçºäºæå°éäºææ°ï¼æåæåºäºä¸ååºæ¼é¶æ¨£æ¬å¤§åèªè¨æ¨¡å (LLM) çèªåä½æ¥­è©å (AAG) ç³»çµ±ãæ­¤æ¶æ§å©ç¨æç¤ºå·¥ç¨ä¾è©éè¨ç®åèªªææ§çå­¸çåæï¼èä¸éè¦é¡å¤çè¨ç·´æå¾®èª¿ãAAG ç³»çµ±æä¾å®¢è£½åçåé¥ï¼å¼·èª¿åäººçåªå¢åéè¦æ¹é²çå°æ¹ï¼å¾èå¢é²å­¸ççå­¸ç¿ææãæåçç ç©¶ééå¨é¢çè©éä¾å±ç¤ºç³»çµ±çæææ§ï¼åæ¬ä¾èªé«ç­æè²å­¸ççåå·èª¿æ¥åæï¼éäºåæé¡¯ç¤ºèå³çµ±è©åæ¹æ³ç¸æ¯ï¼åæ©ãçè§£ååæºååº¦é½æé¡¯èçé²æ­¥ãçµæé©è­äº AAG ç³»çµ±ééåªåèæ®å­¸ç¿é«é©åæä¾å¯æ´åãé«åè³ªçåé¥ï¼è½åæè²è©éçæ½åã

##### **MASTER: A Multi-Agent System with LLM Specialized MCTS**
2501.14304v1 by Bingzheng Gan, Yufan Zhao, Tianyi Zhang, Jing Huang, Yusu Li, Shu Xian Teo, Changwang Zhang, Wei Shi

Large Language Models (LLM) are increasingly being explored for
problem-solving tasks. However, their strategic planning capability is often
viewed with skepticism. Recent studies have incorporated the Monte Carlo Tree
Search (MCTS) algorithm to augment the planning capacity of LLM. Despite its
potential, MCTS relies on extensive sampling simulations to approximate the
true reward distribution, leading to two primary issues. Firstly, MCTS is
effective for tasks like the Game of Go, where simulation results can yield
objective rewards (e.g., 1 for a win and 0 for a loss). However, for tasks such
as question answering, the result of a simulation is the answer to the
question, which cannot obtain an objective reward without the ground truth.
Secondly, obtaining statistically significant reward estimations typically
requires a sample size exceeding 30 simulations, resulting in excessive token
usage and time consumption. To address these challenges, we present Multi-Agent
System with Tactical Execution and Reasoning using LLM Specialized MCTS
(MASTER), a novel framework that coordinates agent recruitment and
communication using LLM specialized MCTS. This system autonomously adjusts the
number of agents based on task complexity and ensures focused communication
among them. Comprehensive experiments across various tasks demonstrate the
effectiveness of our proposed framework. It achieves 76% accuracy on HotpotQA
and 80% on WebShop, setting new state-of-the-art performance on these datasets.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) æ­£è¶ä¾è¶å¸¸è¢«ç¨æ¼è§£æ±ºåé¡çä»»åä¸­ãç¶èï¼å®åçç­ç¥è¦åè½åå¸¸å¸¸åå°è³ªçãæè¿çç ç©¶å·²æ´åèå°å¡ç¾æ¨¹æå° (MCTS) æ¼ç®æ³ä¾æ´å¢ LLM çè¦åè½åãåç®¡æå¶æ½åï¼MCTS ä¾è³´å¤§éçæ½æ¨£æ¨¡æ¬ä¾è¿ä¼¼çå¯¦çåé¥åä½ï¼å°è´å©åä¸»è¦åé¡ãé¦åï¼MCTS é©ç¨æ¼åæ£ç­ä»»åï¼å¶ä¸­æ¨¡æ¬çµæå¯ä»¥ç¢çå®¢è§çåé¥ï¼ä¾å¦ï¼è´å¾æ¯è³½çº 1ï¼è¼¸ææ¯è³½çº 0ï¼ãç¶èï¼å°æ¼åç­ç­ä»»åï¼æ¨¡æ¬ççµææ¯åé¡çç­æ¡ï¼èç­æ¡å¨æ²ææ­£è§£çææ³ä¸ç¡æ³ç²å¾å®¢è§çåé¥ãå¶æ¬¡ï¼è¦ç²å¾å·æçµ±è¨æç¾©çåé¥ä¼°è¨å¼ï¼éå¸¸éè¦è¶é 30 æ¬¡æ¨¡æ¬çæ¨£æ¬å¤§å°ï¼éæå°è´éåº¦ä½¿ç¨æ¬æåæµªè²»æéãçºäºæå°éäºææ°ï¼æåæåºä½¿ç¨ LLM å°ç¨ MCTS çå¤ä»£çç³»çµ±ï¼å·åæ°è¡å·è¡åæ¨ç (MASTER)ï¼éæ¯ä¸ååèª¿ä»£çæååä½¿ç¨ LLM å°ç¨ MCTS é²è¡æºéçæ°æ¶æ§ãéåç³»çµ±ææ ¹æä»»åçè¤éæ§èªåèª¿æ´ä»£çæ¸éï¼ä¸¦ç¢ºä¿å®åä¹éçæºéå°æ³¨ãè·¨åç¨®ä»»åçç¶åå¯¦é©è­æäºæåæåºçæ¶æ§çæææ§ãå®å¨ HotpotQA ä¸éå°äº 76% çæºç¢ºåº¦ï¼å¨ WebShop ä¸éå°äº 80%ï¼å¨éäºè³æéä¸åµä¸äºæ°çæåé²æè½ã

##### **Fast Think-on-Graph: Wider, Deeper and Faster Reasoning of Large Language Model on Knowledge Graph**
2501.14300v1 by Xujian Liang, Zhaoquan Gu

Graph Retrieval Augmented Generation (GRAG) is a novel paradigm that takes
the naive RAG system a step further by integrating graph information, such as
knowledge graph (KGs), into large-scale language models (LLMs) to mitigate
hallucination. However, existing GRAG still encounter limitations: 1) simple
paradigms usually fail with the complex problems due to the narrow and shallow
correlations capture from KGs 2) methods of strong coupling with KGs tend to be
high computation cost and time consuming if the graph is dense. In this paper,
we propose the Fast Think-on-Graph (FastToG), an innovative paradigm for
enabling LLMs to think ``community by community" within KGs. To do this,
FastToG employs community detection for deeper correlation capture and two
stages community pruning - coarse and fine pruning for faster retrieval.
Furthermore, we also develop two Community-to-Text methods to convert the graph
structure of communities into textual form for better understanding by LLMs.
Experimental results demonstrate the effectiveness of FastToG, showcasing
higher accuracy, faster reasoning, and better explainability compared to the
previous works.

æè¦ï¼åè¡¨æª¢ç´¢å¢å¼·çæ (GRAG) æ¯ä¸ç¨®æ°ç©çç¯ä¾ï¼å®ééå°åè¡¨è³è¨ï¼ä¾å¦ç¥è­åè¡¨ (KG)) æ´åå°å¤§åèªè¨æ¨¡å (LLM) ä¸­ï¼é²ä¸æ­¥æåäºæ¨¸ç´ ç RAG ç³»çµ±ä»¥æ¸è¼å¹»è¦ºãç¶èï¼ç¾æç GRAG ä»æéå°éå¶ï¼1) ç°¡å®çç¯ä¾éå¸¸æå å¾ KG ä¸­æ·åçéè¯æ§ç¹éä¸æ·ºèèç¡æ³è§£æ±ºè¤éçåé¡ 2) å¦æåè¡¨å¾å¯éï¼è KG å¼·è¦åçæ¹æ³å¾å¾æå°è´é«éç®ææ¬åèæãå¨æ¬æä¸­ï¼æåæåºäº Fast Think-on-Graph (FastToG)ï¼éæ¯ä¸ç¨®åµæ°çç¯ä¾ï¼å¯è® LLM å¨ KG ä¸­ãéåç¤¾ç¾¤ãé²è¡æèãçºæ­¤ï¼FastToG ä½¿ç¨ç¤¾ç¾¤åµæ¸¬ä¾æ·åæ´æ·±å¥çéè¯æ§ï¼ä¸¦ä½¿ç¨å©åéæ®µçç¤¾ç¾¤ä¿®åªï¼ç²ç¥ä¿®åªåç²¾ç´°ä¿®åªï¼ä¾å å¿«æª¢ç´¢éåº¦ãæ­¤å¤ï¼æåééç¼äºå©ç¨®ç¤¾ç¾¤å°æå­çæ¹æ³ï¼å°ç¤¾ç¾¤çåè¡¨çµæ§è½æçºæå­å½¢å¼ï¼ä»¥ä¾¿ LLM æ´å®¹æçè§£ãå¯¦é©çµæè­æäº FastToG çæææ§ï¼èååçç ç©¶ç¸æ¯ï¼å±ç¤ºåºæ´é«çæºç¢ºæ§ãæ´å¿«çæ¨çéåº¦åæ´å¥½çå¯è§£éæ§ã

##### **Examining Alignment of Large Language Models through Representative Heuristics: The Case of Political Stereotypes**
2501.14294v1 by Sullam Jeoung, Yubin Ge, Haohan Wang, Jana Diesner

Examining the alignment of large language models (LLMs) has become
increasingly important, particularly when these systems fail to operate as
intended. This study explores the challenge of aligning LLMs with human
intentions and values, with specific focus on their political inclinations.
Previous research has highlighted LLMs' propensity to display political
leanings, and their ability to mimic certain political parties' stances on
various issues. However, the extent and conditions under which LLMs deviate
from empirical positions have not been thoroughly examined. To address this
gap, our study systematically investigates the factors contributing to LLMs'
deviations from empirical positions on political issues, aiming to quantify
these deviations and identify the conditions that cause them.
  Drawing on cognitive science findings related to representativeness
heuristics -- where individuals readily recall the representative attribute of
a target group in a way that leads to exaggerated beliefs -- we scrutinize LLM
responses through this heuristics lens. We conduct experiments to determine how
LLMs exhibit stereotypes by inflating judgments in favor of specific political
parties. Our results indicate that while LLMs can mimic certain political
parties' positions, they often exaggerate these positions more than human
respondents do. Notably, LLMs tend to overemphasize representativeness to a
greater extent than humans. This study highlights the susceptibility of LLMs to
representativeness heuristics, suggeseting potential vulnerabilities to
political stereotypes. We propose prompt-based mitigation strategies that
demonstrate effectiveness in reducing the influence of representativeness in
LLM responses.

æè¦ï¼<paragraph>æª¢è¦å¤§åèªè¨æ¨¡åï¼LLMï¼çå°é½æ¹å¼è®å¾è¶ä¾è¶éè¦ï¼ç¹å¥æ¯å¨éäºç³»çµ±ç¡æ³æé æéä½æãæ¬ç ç©¶æ¢è¨äºå° LLM èäººé¡æååå¹å¼è§å°é½çææ°ï¼ç¹å¥éæ³¨å¶æ¿æ²»å¾åãååçç ç©¶å¼·èª¿äº LLM é¡¯ç¤ºæ¿æ²»å¾åçå¾åï¼ä»¥åå®åæ¨¡æ¬æäºæ¿é»¨å°åç¨®åé¡çç«å ´çè½åãç¶èï¼LLM åé¢ç¶é©ç«å ´çç¨åº¦åæ¢ä»¶å°æªå¾å°å¾¹åºæª¢é©ãçºäºè§£æ±ºéåå·®è·ï¼æåçç ç©¶ç³»çµ±å°èª¿æ¥äºå°è´ LLM å¨æ¿æ²»åé¡ä¸åé¢ç¶é©ç«å ´çå ç´ ï¼æ¨å¨éåéäºåå·®ä¸¦æ¾åºå°è´å®åçæ¢ä»¶ã
æ ¹æèä»£è¡¨æ§åç¼æ³ç¸éçèªç¥ç§å­¸ç¼ç¾ââåäººå®¹æä»¥å°è´èªå¤§ä¿¡å¿µçæ¹å¼åæ¶ç®æ¨ç¾¤é«çä»£è¡¨æ§å±¬æ§ââæåééæ­¤åç¼æ³éé¡ä»ç´°å¯©æ¥ LLM åæãæåé²è¡å¯¦é©ä»¥ç¢ºå® LLM å¦ä½ééèªå¤§å°ç¹å®æ¿é»¨æå©çå¤æ·ä¾è¡¨ç¾å»æ¿å°è±¡ãæåççµæè¡¨æï¼éç¶ LLM å¯ä»¥æ¨¡æ¬æäºæ¿é»¨çç«å ´ï¼ä½å®åéå¸¸æ¯äººé¡åè¨ªèæ´èªå¤§éäºç«å ´ãå¼å¾æ³¨æçæ¯ï¼LLM å¾å¾æ¯äººé¡æ´å¼·èª¿ä»£è¡¨æ§ãæ¬ç ç©¶å¼·èª¿äº LLM å°ä»£è¡¨æ§åç¼æ³çæææ§ï¼è¡¨æå°æ¿æ²»å»æ¿å°è±¡çæ½å¨èå¼±æ§ãæåæåºäºåºæ¼æç¤ºçç·©è§£ç­ç¥ï¼è­æäºå¨æ¸å°ä»£è¡¨æ§å° LLM åæçå½±é¿æ¹é¢ææã</paragraph>

##### **A Comprehensive Framework for Semantic Similarity Detection Using Transformer Architectures and Enhanced Ensemble Techniques**
2501.14288v1 by Lifu Gao, Qi Zhang, Ziwei Liu

Detecting AI-generated text, especially in short-context documents, is
difficult because there is not enough context for accurate classification. This
paper presents a new teacher-student model that uses domain adaptation and data
augmentation to solve these problems. The teacher model, which combines
DeBERTa-v3-large and Mamba-790m, learns semantic knowledge through
domain-specific fine-tuning. The student model handles short-context text more
efficiently. The system uses a Mean Squared Error (MSE) loss function to guide
the student's learning, improving both accuracy and efficiency. Also, data
augmentation methods like spelling correction and error injection make the
model more robust. Experimental results show that this approach works better
than baseline methods, proving its usefulness for real-time AI-generated text
detection and other text classification tasks.

æè¦ï¼åµæ¸¬ AI çæçæå­ï¼ç¹å¥æ¯å¨ç­èªå¢æä»¶ä¸­ï¼å¾å°é£ï¼å çºæ²æè¶³å¤ çèªå¢å¯ä»¥é²è¡ç²¾ç¢ºçåé¡ãéç¯è«ææåºäºä¸åæ°çå¸«çæ¨¡åï¼å®ä½¿ç¨é åé©æåè³ææ´åä¾è§£æ±ºéäºåé¡ãæå¸«æ¨¡åçµåäº DeBERTa-v3-large å Mamba-790mï¼ééç¹å®é åçå¾®èª¿ä¾å­¸ç¿èªç¾©ç¥è­ãå­¸çæ¨¡åæ´ææçå°èçç­èªå¢æå­ãç³»çµ±ä½¿ç¨åæ¹èª¤å·® (MSE) æå¤±å½æ¸ä¾å¼å°å­¸ççå­¸ç¿ï¼åææåæºç¢ºæ§åæçãæ­¤å¤ï¼æ¼å¯«æ ¡æ­£åé¯èª¤æ³¨å¥ç­è³ææ´åæ¹æ³è®æ¨¡åæ´å¼·å¥ãå¯¦é©çµæé¡¯ç¤ºï¼æ­¤æ¹æ³æ¯åºæºæ¹æ³è¡¨ç¾å¾æ´å¥½ï¼è­æäºå®å¨å³æ AI çæçæå­åµæ¸¬åå¶ä»æå­åé¡ä»»åä¸­çæç¨ã

##### **Global Semantic-Guided Sub-image Feature Weight Allocation in High-Resolution Large Vision-Language Models**
2501.14276v1 by Yuxuan Liang, Xu Li, Xiaolei Chen, Haotian Chen, Yi Zheng, Chenghang Lai, Bin Li, Xiangyang Xue

As the demand for high-resolution image processing in Large Vision-Language
Models (LVLMs) grows, sub-image partitioning has become a popular approach for
mitigating visual information loss associated with fixed-resolution processing.
However, existing partitioning methods uniformly process sub-images, resulting
in suboptimal image understanding. In this work, we reveal that the sub-images
with higher semantic relevance to the entire image encapsulate richer visual
information for preserving the model's visual understanding ability. Therefore,
we propose the Global Semantic-guided Weight Allocator (GSWA) module, which
dynamically allocates weights to sub-images based on their relative information
density, emulating human visual attention mechanisms. This approach enables the
model to focus on more informative regions, overcoming the limitations of
uniform treatment. We integrate GSWA into the InternVL2-2B framework to create
SleighVL, a lightweight yet high-performing model. Extensive experiments
demonstrate that SleighVL outperforms models with comparable parameters and
remains competitive with larger models. Our work provides a promising direction
for more efficient and contextually aware high-resolution image processing in
LVLMs, advancing multimodal system development.

æè¦ï¼éçå¤§åè§è§è¯­è¨æ¨¡å (LVLMs) ä¸­å¯¹é«åè¾¨çå¾åå¤ççéæ±ä¸æ­å¢é¿ï¼å­å¾åååºå·²æä¸ºç¼è§£ä¸åºå®åè¾¨çå¤çç¸å³çè§è§ä¿¡æ¯ä¸¢å¤±çæµè¡æ¹æ³ãç¶èï¼ç°æçååºæ¹æ³ç»ä¸å¤çå­å¾åï¼å¯¼è´å­å¾åçè§£ä¸ä½³ãå¨è¿é¡¹å·¥ä½ä¸­ï¼æä»¬æ­ç¤ºäºä¸æ´ä¸ªå¾åå·æè¾é«è¯­ä¹ç¸å³æ§çå­å¾åå°è£äºæ´ä¸°å¯çè§è§ä¿¡æ¯ï¼ä»¥ä¿çæ¨¡åçè§è§çè§£è½åãå æ­¤ï¼æä»¬æåºäºå¨å±è¯­ä¹å¼å¯¼æéåéå¨ (GSWA) æ¨¡åï¼è¯¥æ¨¡åæ ¹æ®å­å¾åçç¸å¯¹ä¿¡æ¯å¯åº¦å¨æåéæéï¼æ¨¡æäººç±»è§è§æ³¨æåæºå¶ãè¿ç§æ¹æ³ä½¿æ¨¡åè½å¤ä¸æ³¨äºæ´å¤ä¿¡æ¯ä¸°å¯çåºåï¼åæäºç»ä¸å¤ççå±éæ§ãæä»¬å° GSWA éæå° InternVL2-2B æ¡æ¶ä¸­ä»¥åå»º SleighVLï¼è¿æ¯ä¸ç§è½»éçº§ä½é«æ§è½çæ¨¡åãå¤§éå®éªè¡¨æï¼SleighVL ä¼äºå·æå¯æ¯åæ°çæ¨¡åï¼å¹¶ä¸ä¸æ´å¤§æ¨¡åä¿æç«äºåãæä»¬çå·¥ä½ä¸º LVLMs ä¸­æ´é«æä¸å·æä¸ä¸ææç¥è½åçé«åè¾¨çå¾åå¤çæä¾äºä¸ä¸ªæå¸æçæ¹åï¼ä»èä¿è¿äºå¤æ¨¡æç³»ç»å¼åã

##### **Leveraging Online Olympiad-Level Math Problems for LLMs Training and Contamination-Resistant Evaluation**
2501.14275v1 by Sadegh Mahdavi, Muchen Li, Kaiwen Liu, Christos Thrampoulidis, Leonid Sigal, Renjie Liao

Advances in Large Language Models (LLMs) have sparked interest in their
ability to solve Olympiad-level math problems. However, the training and
evaluation of these models are constrained by the limited size and quality of
available datasets, as creating large-scale data for such advanced problems
requires extensive effort from human experts. In addition, current benchmarks
are prone to contamination, leading to unreliable evaluations. In this paper,
we present an automated pipeline that leverages the rich resources of the Art
of Problem Solving (AoPS) forum, which predominantly features Olympiad-level
problems and community-driven solutions. Using open-source LLMs, we develop a
method to extract question-answer pairs from the forum, resulting in
AoPS-Instruct, a dataset of more than 600,000 high-quality QA pairs. Our
experiments demonstrate that fine-tuning LLMs on AoPS-Instruct improves their
reasoning abilities across various benchmarks. Moreover, we build an automatic
pipeline that introduces LiveAoPSBench, an evolving evaluation set with
timestamps, derived from the latest forum data, providing a
contamination-resistant benchmark for assessing LLM performance. Notably, we
observe a significant decline in LLM performance over time, suggesting their
success on older examples may stem from pre-training exposure rather than true
reasoning ability. Our work presents a scalable approach to creating and
maintaining large-scale, high-quality datasets for advanced math reasoning,
offering valuable insights into the capabilities and limitations of LLMs in
this domain. Our benchmark and code is available at
https://github.com/DSL-Lab/aops

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) çé²æ­¥æ¿ç¼äºäººåå°å¶è§£æ±ºå¥§æå¹åæ¸å­¸åé¡è½åçèè¶£ãç¶èï¼éäºæ¨¡åçè¨ç·´åè©ä¼°åå°å¯ç¨æ¸æéè¦æ¨¡ååè³ªçéå¶ï¼å çºçºéé¡é²éåé¡å»ºç«å¤§è¦æ¨¡æ¸æéè¦äººé¡å°å®¶çå»£æ³åªåãæ­¤å¤ï¼ç®åçåºæºå®¹æåå°æ±æï¼å°è´è©ä¼°ä¸å¯é ãå¨æ¬æä¸­ï¼æåæåºäºä¸åèªååç®¡éï¼å©ç¨äºåé¡è§£æ±ºçèè¡ (AoPS) è«å£çè±å¯è³æºï¼è©²è«å£ä¸»è¦ä»¥å¥§æå¹åç¨åº¦çåé¡åç¤¾ç¾¤é©åçè§£æ±ºæ¹æ¡çºç¹è²ãä½¿ç¨éæº LLMï¼æåéç¼äºä¸ç¨®å¾è«å£ä¸­èååç­éå°çæ¹æ³ï¼ç¢çäº AoPS-Instructï¼ä¸ååå«è¶é 600,000 åé«åè³ª QA éå°çæ¸æéãæåçå¯¦é©è­æï¼å¨ AoPS-Instruct ä¸å¾®èª¿ LLM è½å¤ æåå¶å¨åç¨®åºæºä¸çæ¨çè½åãæ­¤å¤ï¼æåå»ºç«äºä¸åèªååç®¡éï¼å¼å¥äº LiveAoPSBenchï¼ä¸åå¾ææ°è«å£æ¸æè¡ççãå¸¶ææéæ³è¨çæ¼åè©ä¼°éï¼æä¾äºä¸åææ±æçåºæºä¾è©ä¼° LLM æè½ãå¼å¾æ³¨æçæ¯ï¼æåè§å¯å° LLM æè½é¨èæéæ¨ç§»èé¡¯èä¸éï¼éè¡¨æå®åå¨è¼èç¯ä¾ä¸çæåå¯è½æºæ¼é è¨ç·´æåï¼èä¸æ¯çæ­£çæ¨çè½åãæåçç ç©¶æåºäºä¸åå¯æ´å±çæ¹æ³ä¾å»ºç«åç¶­è­·ç¨æ¼é²éæ¸å­¸æ¨ççå¤§è¦æ¨¡ãé«åè³ªæ¸æéï¼æä¾äºéæ¼ LLM å¨æ­¤é åä¸­è½ååéå¶çå¯¶è²´è¦è§£ãæåçåºæºåç¨å¼ç¢¼å¯ä»¥å¨ https://github.com/DSL-Lab/aops åå¾

##### **Hierarchical Time-Aware Mixture of Experts for Multi-Modal Sequential Recommendation**
2501.14269v1 by Shengzhe Zhang, Liyi Chen, Dazhong Shen, Chao Wang, Hui Xiong

Multi-modal sequential recommendation (SR) leverages multi-modal data to
learn more comprehensive item features and user preferences than traditional SR
methods, which has become a critical topic in both academia and industry.
Existing methods typically focus on enhancing multi-modal information utility
through adaptive modality fusion to capture the evolving of user preference
from user-item interaction sequences. However, most of them overlook the
interference caused by redundant interest-irrelevant information contained in
rich multi-modal data. Additionally, they primarily rely on implicit temporal
information based solely on chronological ordering, neglecting explicit
temporal signals that could more effectively represent dynamic user interest
over time. To address these limitations, we propose a Hierarchical time-aware
Mixture of experts for multi-modal Sequential Recommendation (HM4SR) with a
two-level Mixture of Experts (MoE) and a multi-task learning strategy.
Specifically, the first MoE, named Interactive MoE, extracts essential user
interest-related information from the multi-modal data of each item. Then, the
second MoE, termed Temporal MoE, captures user dynamic interests by introducing
explicit temporal embeddings from timestamps in modality encoding. To further
address data sparsity, we propose three auxiliary supervision tasks:
sequence-level category prediction (CP) for item feature understanding,
contrastive learning on ID (IDCL) to align sequence context with user
interests, and placeholder contrastive learning (PCL) to integrate temporal
information with modalities for dynamic interest modeling. Extensive
experiments on four public datasets verify the effectiveness of HM4SR compared
to several state-of-the-art approaches.

æè¦ï¼å¤æ¨¡æé¡ºåºæ¨èï¼SRï¼å©ç¨å¤æ¨¡ææ°æ®æ¥å­¦ä¹ æ¯ä¼ ç» SR æ¹æ³æ´å¨é¢çé¡¹ç®ç¹å¾åç¨æ·åå¥½ï¼è¿å·²æä¸ºå­¦æ¯çåå·¥ä¸ççå³é®è¯¾é¢ãç°ææ¹æ³éå¸¸ä¸æ³¨äºéè¿èªéåºæ¨¡æèåæ¥å¢å¼ºå¤æ¨¡æä¿¡æ¯æç¨ï¼ä»¥ä»ç¨æ·-é¡¹ç®äº¤äºåºåä¸­ææç¨æ·åå¥½çæ¼åãç¶èï¼å¤§å¤æ°æ¹æ³å¿½ç¥äºä¸°å¯å¤æ¨¡ææ°æ®ä¸­åå«çåä½ä¸å´è¶£æ å³çä¿¡æ¯æé æçå¹²æ°ãæ­¤å¤ï¼å®ä»¬ä¸»è¦ä¾èµäºä»åºäºæ¶é´é¡ºåºçéå¼æ¶é´ä¿¡æ¯ï¼èå¿½ç¥äºå¯ä»¥æ´ææå°è¡¨ç¤ºå¨æç¨æ·å´è¶£çæ¾å¼æ¶é´ä¿¡å·ãä¸ºäºè§£å³è¿äºéå¶ï¼æä»¬æåºäºä¸ç§å·æä¸¤çº§ä¸å®¶æ··åï¼MoEï¼åå¤ä»»å¡å­¦ä¹ ç­ç¥çåå±æ¶é´æç¥ä¸å®¶æ··åç¨äºå¤æ¨¡æé¡ºåºæ¨èï¼HM4SRï¼ãå·ä½æ¥è¯´ï¼ç¬¬ä¸ä¸ª MoEï¼ç§°ä¸ºäº¤äºå¼ MoEï¼ä»æ¯ä¸ªé¡¹ç®çæ¨¡ææ°æ®ä¸­æååºæ¬çä¸ç¨æ·å´è¶£ç¸å³çä¿¡æ¯ãç¶åï¼ç¬¬äºä¸ª MoEï¼ç§°ä¸ºæ¶é´ MoEï¼éè¿å¨æ¨¡æç¼ç ä¸­å¼å¥æ¶é´æ³çæ¾å¼æ¶é´åµå¥æ¥ææç¨æ·å¨æå´è¶£ãä¸ºäºè¿ä¸æ­¥è§£å³æ°æ®ç¨çæ§ï¼æä»¬æåºäºä¸ä¸ªè¾å©çç£ä»»å¡ï¼ç¨äºé¡¹ç®ç¹å¾çè§£çåºåçº§ç±»å«é¢æµï¼CPï¼ãç¨äºå°åºåä¸ä¸æä¸ç¨æ·å´è¶£å¯¹é½ç ID å¯¹æ¯å­¦ä¹ ï¼IDCLï¼ï¼ä»¥åç¨äºå°æ¶é´ä¿¡æ¯ä¸æ¨¡ææ´åä»¥è¿è¡å¨æå´è¶£å»ºæ¨¡çå ä½ç¬¦å¯¹æ¯å­¦ä¹ ï¼PCLï¼ãå¨åä¸ªå¬å¼æ°æ®éä¸çå¹¿æ³å®éªéªè¯äº HM4SR ä¸å ç§æåè¿æ¹æ³ç¸æ¯çæææ§ã

##### **Pre-train and Fine-tune: Recommenders as Large Models**
2501.14268v1 by Zhenhao Jiang, Chenghao Chen, Hao Feng, Yu Yang, Jin Liu, Jie Zhang, Jia Jia, Ning Hu

In reality, users have different interests in different periods, regions,
scenes, etc. Such changes in interest are so drastic that they are difficult to
be captured by recommenders. Existing multi-domain learning can alleviate this
problem. However, the structure of the industrial recommendation system is
complex, the amount of data is huge, and the training cost is extremely high,
so it is difficult to modify the structure of the industrial recommender and
re-train it. To fill this gap, we consider recommenders as large pre-trained
models and fine-tune them. We first propose the theory of the information
bottleneck for fine-tuning and present an explanation for the fine-tuning
technique in recommenders. To tailor for recommendation, we design an
information-aware adaptive kernel (IAK) technique to fine-tune the pre-trained
recommender. Specifically, we define fine-tuning as two phases: knowledge
compression and knowledge matching and let the training stage of IAK explicitly
approximate these two phases. Our proposed approach designed from the essence
of fine-tuning is well interpretable. Extensive online and offline experiments
show the superiority of our proposed method. Besides, we also share unique and
important lessons we learned when deploying the method in a large-scale online
platform. We also present the potential issues of fine-tuning techniques in
recommendation systems and the corresponding solutions. The recommender with
IAK technique has been deployed on the homepage of a billion-scale online food
platform for several months and has yielded considerable profits in our
business.

æè¦ï¼<paragraph>å¨ç¾å¯¦ä¸­ï¼ä½¿ç¨èå¨ä¸åçææ®µãååãå ´æ¯ç­ï¼ææä¸åçèè¶£ãèéæ¨£çèè¶£è®ååçï¼é£ä»¥è¢«æ¨è¦ç³»çµ±ææå°ãç¾æçå¤é åå­¸ç¿å¯ä»¥ç·©è§£éååé¡ãç¶èï¼ç¢æ¥­æ¨è¦ç³»çµ±çæ¶æ§è¤éãè³æéé¾å¤§ãè¨ç·´ææ¬æ¥µé«ï¼å æ­¤é£ä»¥ä¿®æ¹ç¢æ¥­æ¨è¦ç³»çµ±çæ¶æ§ä¸¦éæ°è¨ç·´ãçºäºå¡«è£éåç¼ºå£ï¼æåå°æ¨è¦ç³»çµ±è¦çºå¤§åé è¨ç·´æ¨¡åï¼ä¸¦å°å¶é²è¡å¾®èª¿ãæåé¦åæåºå¾®èª¿çè³è¨ç¶é ¸çè«ï¼ä¸¦å°æ¨è¦ç³»çµ±ä¸­çå¾®èª¿æè¡æåºè§£éãçºäºå®¢è£½åæ¨è¦ï¼æåè¨­è¨äºä¸ç¨®è³è¨æç¥èªé©ææ ¸ (IAK) æè¡ä¾å¾®èª¿é è¨ç·´çæ¨è¦ç³»çµ±ãå·é«ä¾èªªï¼æåå°å¾®èª¿å®ç¾©çºå©åéæ®µï¼ç¥è­å£ç¸®åç¥è­å¹éï¼ä¸¦è® IAK çè¨ç·´éæ®µæç¢ºé¼è¿éå©åéæ®µãæåæåºçæ¹æ³å¾å¾®èª¿çæ¬è³ªè¨­è¨ï¼å·æè¯å¥½çå¯è§£éæ§ãå»£æ³çç·ä¸åé¢ç·å¯¦é©é¡¯ç¤ºäºæåæåºçæ¹æ³çåªè¶æ§ãæ­¤å¤ï¼æåéåäº«äºå¨å¤§åç·ä¸å¹³å°é¨ç½²è©²æ¹æ³æå­¸å°çç¨ç¹ä¸éè¦çç¶é©ãæåä¹æåºäºå¾®èª¿æè¡å¨æ¨è¦ç³»çµ±ä¸­çæ½å¨åé¡åå°æçè§£æ±ºæ¹æ¡ãçµå IAK æè¡çæ¨è¦ç³»çµ±å·²å¨ååè¦æ¨¡çç·ä¸ç¾é£å¹³å°é¦é é¨ç½²æ¸æï¼ä¸¦å¨æåçæ¥­åä¸­ç¢çäºå¯è§çå©æ½¤ã</paragraph>

##### **Siren: A Learning-Based Multi-Turn Attack Framework for Simulating Real-World Human Jailbreak Behaviors**
2501.14250v1 by Yi Zhao, Youzhi Zhang

Large language models (LLMs) are widely used in real-world applications,
raising concerns about their safety and trustworthiness. While red-teaming with
jailbreak prompts exposes the vulnerabilities of LLMs, current efforts focus
primarily on single-turn attacks, overlooking the multi-turn strategies used by
real-world adversaries. Existing multi-turn methods rely on static patterns or
predefined logical chains, failing to account for the dynamic strategies during
attacks. We propose Siren, a learning-based multi-turn attack framework
designed to simulate real-world human jailbreak behaviors. Siren consists of
three stages: (1) training set construction utilizing Turn-Level LLM feedback
(Turn-MF), (2) post-training attackers with supervised fine-tuning (SFT) and
direct preference optimization (DPO), and (3) interactions between the
attacking and target LLMs. Experiments demonstrate that Siren achieves an
attack success rate (ASR) of 90% with LLaMA-3-8B as the attacker against
Gemini-1.5-Pro as the target model, and 70% with Mistral-7B against GPT-4o,
significantly outperforming single-turn baselines. Moreover, Siren with a
7B-scale model achieves performance comparable to a multi-turn baseline that
leverages GPT-4o as the attacker, while requiring fewer turns and employing
decomposition strategies that are better semantically aligned with attack
goals. We hope Siren inspires the development of stronger defenses against
advanced multi-turn jailbreak attacks under realistic scenarios. Code is
available at https://github.com/YiyiyiZhao/siren. Warning: This paper contains
potentially harmful text.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å»£æ³ç¨æ¼å¯¦éæç¨ä¸­ï¼å¼ç¼äºäººåå°å¶å®å¨æ§åå¯ä¿¡åº¦çææãéç¶ä½¿ç¨è¶çæç¤ºé²è¡ç´éæ¸¬è©¦æ­é²äº LLM çæ¼æ´ï¼ä½ç®åçåªåä¸»è¦éä¸­å¨å®ååæ»æä¸ï¼å¿½è¦äºç¾å¯¦ä¸çä¸­çå°ææä½¿ç¨çå¤ååç­ç¥ãç¾æçå¤ååæ¹æ³ä¾è³´æ¼éææ¨¡å¼æé å®ç¾©çéè¼¯éï¼ç¡æ³èªªææ»æéç¨ä¸­çåæç­ç¥ãæåæåºäº Sirenï¼ä¸ååºæ¼å­¸ç¿çå¤ååæ»ææ¡æ¶ï¼æ¨å¨æ¨¡æ¬ç¾å¯¦ä¸çä¸­äººé¡è¶çè¡çºãSiren åå«ä¸åéæ®µï¼(1) å©ç¨ååç´ LLM åé¥ (Turn-MF) è¨ç·´éåå»ºæ§ï¼(2) å·æç£ç£å¾®èª¿ (SFT) åç´æ¥åå¥½æä½³å (DPO) çè¨ç·´å¾æ»æèï¼ä»¥å (3) æ»æåç®æ¨ LLM ä¹éçäºåãå¯¦é©è¡¨æï¼Siren ä»¥ LLaMA-3-8B ä½çºæ»æèå°æ Gemini-1.5-Pro ä½çºç®æ¨æ¨¡åæï¼æ»ææåç (ASR) éå° 90%ï¼è Mistral-7B å°æ GPT-4o æéå° 70%ï¼é¡¯èåªæ¼å®åååºæºãæ­¤å¤ï¼Siren ä½¿ç¨ 7B ç´å¥æ¨¡åéå°çæ§è½èä½¿ç¨ GPT-4o ä½çºæ»æèçå¤åååºæºç¸ç¶ï¼åæéè¦çååæ´å°ï¼ä¸¦æ¡ç¨äºèæ»æç®æ¨å¨èªç¾©ä¸æ´ä¸è´çåè§£ç­ç¥ãæåå¸æ Siren è½æ¿åµäººåå¨ç¾å¯¦å ´æ¯ä¸­éç¼åºéå°é«ç´å¤ååè¶çæ»æçæ´å¼·å¤§çé²ç¦¦æªæ½ãç¨å¼ç¢¼å¯å¨ https://github.com/YiyiyiZhao/siren åå¾ãè­¦åï¼æ¬æåå«æ½å¨æå®³çæå­ã

##### **Humanity's Last Exam**
2501.14249v1 by Long Phan, Alice Gatti, Ziwen Han, Nathaniel Li, Josephina Hu, Hugh Zhang, Sean Shi, Michael Choi, Anish Agrawal, Arnav Chopra, Adam Khoja, Ryan Kim, Jason Hausenloy, Oliver Zhang, Mantas Mazeika, Daron Anderson, Tung Nguyen, Mobeen Mahmood, Fiona Feng, Steven Y. Feng, Haoran Zhao, Michael Yu, Varun Gangal, Chelsea Zou, Zihan Wang, Jessica P. Wang, Pawan Kumar, Oleksandr Pokutnyi, Robert Gerbicz, Serguei Popov, John-Clark Levin, Mstyslav Kazakov, Johannes Schmitt, Geoff Galgon, Alvaro Sanchez, Yongki Lee, Will Yeadon, Scott Sauers, Marc Roth, Chidozie Agu, SÃ¸ren Riis, Fabian Giska, Saiteja Utpala, Zachary Giboney, Gashaw M. Goshu, Joan of Arc Xavier, Sarah-Jane Crowson, Mohinder Maheshbhai Naiya, Noah Burns, Lennart Finke, Zerui Cheng, Hyunwoo Park, Francesco Fournier-Facio, John Wydallis, Mark Nandor, Ankit Singh, Tim Gehrunger, Jiaqi Cai, Ben McCarty, Darling Duclosel, Jungbae Nam, Jennifer Zampese, Ryan G. Hoerr, Aras Bacho, Gautier Abou Loume, Abdallah Galal, Hangrui Cao, Alexis C Garretson, Damien Sileo, Qiuyu Ren, Doru Cojoc, Pavel Arkhipov, Usman Qazi, Lianghui Li, Sumeet Motwani, Christian Schroeder de Witt, Edwin Taylor, Johannes Veith, Eric Singer, Taylor D. Hartman, Paolo Rissone, Jaehyeok Jin, Jack Wei Lun Shi, Chris G. Willcocks, Joshua Robinson, Aleksandar Mikov, Ameya Prabhu, Longke Tang, Xavier Alapont, Justine Leon Uro, Kevin Zhou, Emily de Oliveira Santos, Andrey Pupasov Maksimov, Edward Vendrow, Kengo Zenitani, Julien Guillod, Yuqi Li, Joshua Vendrow, Vladyslav Kuchkin, Ng Ze-An, Pierre Marion, Denis Efremov, Jayson Lynch, Kaiqu Liang, Andrew Gritsevskiy, Dakotah Martinez, Ben Pageler, Nick Crispino, Dimitri Zvonkine, Natanael Wildner Fraga, Saeed Soori, Ori Press, Henry Tang, Julian Salazar, Sean R. Green, Lina BrÃ¼ssel, Moon Twayana, Aymeric Dieuleveut, T. Ryan Rogers, Wenjin Zhang, Bikun Li, Jinzhou Yang, Arun Rao, Gabriel Loiseau, Mikhail Kalinin, Marco Lukas, Ciprian Manolescu, Subrata Mishra, Ariel Ghislain Kemogne Kamdoum, Tobias Kreiman, Tad Hogg, Alvin Jin, Carlo Bosio, Gongbo Sun, Brian P Coppola, Tim Tarver, Haline Heidinger, Rafael Sayous, Stefan Ivanov, Joseph M Cavanagh, Jiawei Shen, Joseph Marvin Imperial, Philippe Schwaller, Shaipranesh Senthilkuma, Andres M Bran, Ali Dehghan, Andres Algaba, Brecht Verbeken, David Noever, Ragavendran P V, Lisa Schut, Ilia Sucholutsky, Evgenii Zheltonozhskii, Derek Lim, Richard Stanley, Shankar Sivarajan, Tong Yang, John Maar, Julian Wykowski, MartÃ­ Oller, Jennifer Sandlin, Anmol Sahu, Yuzheng Hu, Sara Fish, Nasser Heydari, Archimedes Apronti, Kaivalya Rawal, Tobias Garcia Vilchis, Yuexuan Zu, Martin Lackner, James Koppel, Jeremy Nguyen, Daniil S. Antonenko, Steffi Chern, Bingchen Zhao, Pierrot Arsene, Alan Goldfarb, Sergey Ivanov, RafaÅ PoÅwiata, Chenguang Wang, Daofeng Li, Donato Crisostomi, Andrea Achilleos, Benjamin Myklebust, Archan Sen, David Perrella, Nurdin Kaparov, Mark H Inlow, Allen Zang, Elliott Thornley, Daniil Orel, Vladislav Poritski, Shalev Ben-David, Zachary Berger, Parker Whitfill, Michael Foster, Daniel Munro, Linh Ho, Dan Bar Hava, Aleksey Kuchkin, Robert Lauff, David Holmes, Frank Sommerhage, Keith Schneider, Zakayo Kazibwe, Nate Stambaugh, Mukhwinder Singh, Ilias Magoulas, Don Clarke, Dae Hyun Kim, Felipe Meneguitti Dias, Veit Elser, Kanu Priya Agarwal, Victor Efren Guadarrama Vilchis, Immo Klose, Christoph Demian, Ujjwala Anantheswaran, Adam Zweiger, Guglielmo Albani, Jeffery Li, Nicolas Daans, Maksim Radionov, VÃ¡clav RozhoÅ, Ziqiao Ma, Christian Stump, Mohammed Berkani, Jacob Platnick, Volodymyr Nevirkovets, Luke Basler, Marco Piccardo, Ferenc Jeanplong, Niv Cohen, Josef Tkadlec, Paul Rosu, Piotr Padlewski, Stanislaw Barzowski, Kyle Montgomery, Aline Menezes, Arkil Patel, Zixuan Wang, Jamie Tucker-Foltz, Jack Stade, Tom Goertzen, Fereshteh Kazemi, Jeremiah Milbauer, John Arnold Ambay, Abhishek Shukla, Yan Carlos Leyva Labrador, Alan GivrÃ©, Hew Wolff, Vivien Rossbach, Muhammad Fayez Aziz, Younesse Kaddar, Yanxu Chen, Robin Zhang, Jiayi Pan, Antonio Terpin, Niklas Muennighoff, Hailey Schoelkopf, Eric Zheng, Avishy Carmi, Adam Jones, Jainam Shah, Ethan D. L. Brown, Kelin Zhu, Max Bartolo, Richard Wheeler, Andrew Ho, Shaul Barkan, Jiaqi Wang, Martin Stehberger, Egor Kretov, Kaustubh Sridhar, Zienab EL-Wasif, Anji Zhang, Daniel Pyda, Joanna Tam, David M. Cunningham, Vladimir Goryachev, Demosthenes Patramanis, Michael Krause, Andrew Redenti, Daniel Bugas, David Aldous, Jesyin Lai, Shannon Coleman, Mohsen Bahaloo, Jiangnan Xu, Sangwon Lee, Sandy Zhao, Ning Tang, Michael K. Cohen, Micah Carroll, Orr Paradise, Jan Hendrik Kirchner, Stefan Steinerberger, Maksym Ovchynnikov, Jason O. Matos, Adithya Shenoy, Benedito Alves de Oliveira Junior, Michael Wang, Yuzhou Nie, Paolo Giordano, Philipp Petersen, Anna Sztyber-Betley, Priti Shukla, Jonathan Crozier, Antonella Pinto, Shreyas Verma, Prashant Joshi, Zheng-Xin Yong, Allison Tee, JÃ©rÃ©my AndrÃ©oletti, Orion Weller, Raghav Singhal, Gang Zhang, Alexander Ivanov, Seri Khoury, Hamid Mostaghimi, Kunvar Thaman, Qijia Chen, Tran Quoc KhÃ¡nh, Jacob Loader, Stefano Cavalleri, Hannah Szlyk, Zachary Brown, Jonathan Roberts, William Alley, Kunyang Sun, Ryan Stendall, Max Lamparth, Anka Reuel, Ting Wang, Hanmeng Xu, Sreenivas Goud Raparthi, Pablo HernÃ¡ndez-CÃ¡mara, Freddie Martin, Dmitry Malishev, Thomas Preu, Tomek Korbak, Marcus Abramovitch, Dominic Williamson, Ziye Chen, BirÃ³ BÃ¡lint, M Saiful Bari, Peyman Kassani, Zihao Wang, Behzad Ansarinejad, Laxman Prasad Goswami, Yewen Sun, Hossam Elgnainy, Daniel Tordera, George Balabanian, Earth Anderson, Lynna Kvistad, Alejandro JosÃ© Moyano, Rajat Maheshwari, Ahmad Sakor, Murat Eron, Isaac C. McAlister, Javier Gimenez, Innocent Enyekwe, Andrew Favre D. O., Shailesh Shah, Xiaoxiang Zhou, Firuz Kamalov, Ronald Clark, Sherwin Abdoli, Tim Santens, Khalida Meer, Harrison K Wang, Kalyan Ramakrishnan, Evan Chen, Alessandro Tomasiello, G. Bruno De Luca, Shi-Zhuo Looi, Vinh-Kha Le, Noam Kolt, Niels MÃ¼ndler, Avi Semler, Emma Rodman, Jacob Drori, Carl J Fossum, Milind Jagota, Ronak Pradeep, Honglu Fan, Tej Shah, Jonathan Eicher, Michael Chen, Kushal Thaman, William Merrill, Carter Harris, Jason Gross, Ilya Gusev, Asankhaya Sharma, Shashank Agnihotri, Pavel Zhelnov, Siranut Usawasutsakorn, Mohammadreza Mofayezi, Sergei Bogdanov, Alexander Piperski, Marc Carauleanu, David K. Zhang, Dylan Ler, Roman Leventov, Ignat Soroko, Thorben Jansen, Pascal Lauer, Joshua Duersch, Vage Taamazyan, Wiktor Morak, Wenjie Ma, William Held, Tran Äuc Huy, Ruicheng Xian, Armel Randy Zebaze, Mohanad Mohamed, Julian Noah Leser, Michelle X Yuan, Laila Yacar, Johannes Lengler, Hossein Shahrtash, Edson Oliveira, Joseph W. Jackson, Daniel Espinosa Gonzalez, Andy Zou, Muthu Chidambaram, Timothy Manik, Hector Haffenden, Dashiell Stander, Ali Dasouqi, Alexander Shen, Emilien Duc, Bita Golshani, David Stap, Mikalai Uzhou, Alina Borisovna Zhidkovskaya, Lukas Lewark, MÃ¡tyÃ¡s Vincze, Dustin Wehr, Colin Tang, Zaki Hossain, Shaun Phillips, Jiang Muzhen, Fredrik EkstrÃ¶m, Angela Hammon, Oam Patel, Nicolas Remy, Faraz Farhidi, George Medley, Forough Mohammadzadeh, Madellene PeÃ±aflor, Haile Kassahun, Alena Friedrich, Claire Sparrow, Taom Sakal, Omkar Dhamane, Ali Khajegili Mirabadi, Eric Hallman, Mike Battaglia, Mohammad Maghsoudimehrabani, Hieu Hoang, Alon Amit, Dave Hulbert, Roberto Pereira, Simon Weber, Stephen Mensah, Nathan Andre, Anton Peristyy, Chris Harjadi, Himanshu Gupta, Stephen Malina, Samuel Albanie, Will Cai, Mustafa Mehkary, Frank Reidegeld, Anna-Katharina Dick, Cary Friday, Jasdeep Sidhu, Wanyoung Kim, Mariana Costa, Hubeyb Gurdogan, Brian Weber, Harsh Kumar, Tong Jiang, Arunim Agarwal, Chiara Ceconello, Warren S. Vaz, Chao Zhuang, Haon Park, Andrew R. Tawfeek, Daattavya Aggarwal, Michael Kirchhof, Linjie Dai, Evan Kim, Johan Ferret, Yuzhou Wang, Minghao Yan, Krzysztof Burdzy, Lixin Zhang, Antonio Franca, Diana T. Pham, Kang Yong Loh, Joshua Robinson, Shreen Gul, Gunjan Chhablani, Zhehang Du, Adrian Cosma, Colin White, Robin Riblet, Prajvi Saxena, Jacob Votava, Vladimir Vinnikov, Ethan Delaney, Shiv Halasyamani, Syed M. Shahid, Jean-Christophe Mourrat, Lavr Vetoshkin, Renas Bacho, Vincent Ginis, Aleksandr Maksapetyan, Florencia de la Rosa, Xiuyu Li, Guillaume Malod, Leon Lang, Julien Laurendeau, Fatimah Adesanya, Julien Portier, Lawrence Hollom, Victor Souza, Yuchen Anna Zhou, YiÄit YalÄ±n, Gbenga Daniel Obikoya, Luca Arnaboldi, Rai, Filippo Bigi, Kaniuar Bacho, Pierre Clavier, Gabriel Recchia, Mara Popescu, Nikita Shulga, Ngefor Mildred Tanwie, Thomas C. H. Lux, Ben Rank, Colin Ni, Alesia Yakimchyk, Huanxu, Liu, Olle HÃ¤ggstrÃ¶m, Emil Verkama, Himanshu Narayan, Hans Gundlach, Leonor Brito-Santana, Brian Amaro, Vivek Vajipey, Rynaa Grover, Yiyang Fan, Gabriel Poesia Reis e Silva, Linwei Xin, Yosi Kratish, Jakub Åucki, Wen-Ding Li, Justin Xu, Kevin Joseph Scaria, Freddie Vargus, Farzad Habibi, Long, Lian, Emanuele RodolÃ , Jules Robins, Vincent Cheng, Declan Grabb, Ida Bosio, Tony Fruhauff, Ido Akov, Eve J. Y. Lo, Hao Qi, Xi Jiang, Ben Segev, Jingxuan Fan, Sarah Martinson, Erik Y. Wang, Kaylie Hausknecht, Michael P. Brenner, Mao Mao, Yibo Jiang, Xinyu Zhang, David Avagian, Eshawn Jessica Scipio, Muhammad Rehan Siddiqi, Alon Ragoler, Justin Tan, Deepakkumar Patil, Rebeka Plecnik, Aaron Kirtland, Roselynn Grace Montecillo, Stephane Durand, Omer Faruk Bodur, Zahra Adoul, Mohamed Zekry, Guillaume Douville, Ali Karakoc, Tania C. B. Santos, Samir Shamseldeen, Loukmane Karim, Anna Liakhovitskaia, Nate Resman, Nicholas Farina, Juan Carlos Gonzalez, Gabe Maayan, Sarah Hoback, Rodrigo De Oliveira Pena, Glen Sherman, Hodjat Mariji, Rasoul Pouriamanesh, Wentao Wu, GÃ¶zdenur Demir, Sandra Mendoza, Ismail Alarab, Joshua Cole, Danyelle Ferreira, Bryan Johnson, Hsiaoyun Milliron, Mohammad Safdari, Liangti Dai, Siriphan Arthornthurasuk, Alexey Pronin, Jing Fan, Angel Ramirez-Trinidad, Ashley Cartwright, Daphiny Pottmaier, Omid Taheri, David Outevsky, Stanley Stepanic, Samuel Perry, Luke Askew, RaÃºl AdriÃ¡n Huerta RodrÃ­guez, Abdelkader Dendane, Sam Ali, Ricardo Lorena, Krishnamurthy Iyer, Sk Md Salauddin, Murat Islam, Juan Gonzalez, Josh Ducey, Russell Campbell, Maja Somrak, Vasilios Mavroudis, Eric Vergo, Juehang Qin, BenjÃ¡min BorbÃ¡s, Eric Chu, Jack Lindsey, Anil Radhakrishnan, Antoine Jallon, I. M. J. McInnis, Alex Hoover, SÃ¶ren MÃ¶ller, Song Bian, John Lai, Tejal Patwardhan, Summer Yue, Alexandr Wang, Dan Hendrycks

Benchmarks are important tools for tracking the rapid advancements in large
language model (LLM) capabilities. However, benchmarks are not keeping pace in
difficulty: LLMs now achieve over 90\% accuracy on popular benchmarks like
MMLU, limiting informed measurement of state-of-the-art LLM capabilities. In
response, we introduce Humanity's Last Exam (HLE), a multi-modal benchmark at
the frontier of human knowledge, designed to be the final closed-ended academic
benchmark of its kind with broad subject coverage. HLE consists of 3,000
questions across dozens of subjects, including mathematics, humanities, and the
natural sciences. HLE is developed globally by subject-matter experts and
consists of multiple-choice and short-answer questions suitable for automated
grading. Each question has a known solution that is unambiguous and easily
verifiable, but cannot be quickly answered via internet retrieval.
State-of-the-art LLMs demonstrate low accuracy and calibration on HLE,
highlighting a significant gap between current LLM capabilities and the expert
human frontier on closed-ended academic questions. To inform research and
policymaking upon a clear understanding of model capabilities, we publicly
release HLE at https://lastexam.ai.

æè¦ï¼åºæºæ¸¬è©¦æ¯è¿½è¹¤å¤§åèªè¨æ¨¡å (LLM) è½åå¿«éé²å±çéè¦å·¥å·ãç¶èï¼åºæºæ¸¬è©¦çé£åº¦ä¸¦æªè·ä¸è³æ­¥ï¼LLM ç¾å¨å¨ MMLU ç­ç±éåºæºæ¸¬è©¦ä¸­éå° 90% ä»¥ä¸çæºç¢ºåº¦ï¼éå¶äºå°æåé² LLM è½åçææè¡¡éãçºäºè§£æ±ºéååé¡ï¼æåå¼å¥äºäººé¡æå¾èè©¦ (HLE)ï¼éæ¯ä¸åè·¨é ååºæºæ¸¬è©¦ï¼èæ¼äººé¡ç¥è­çåæ²¿ï¼æ¨å¨æçºæå¾ä¸åå°éå¼å­¸è¡åºæºæ¸¬è©¦ï¼æ¶µèå»£æ³çä¸»é¡ãHLE åå« 3,000 ååé¡ï¼æ¶µèæ¸ååç§ç®ï¼åæ¬æ¸å­¸ãäººæå­¸ç§åèªç¶ç§å­¸ãHLE ç±å¨ççå°å®¶å±åéç¼ï¼åå«é©åèªåè©åçé¸æé¡åç°¡ç­é¡ãæ¯ååé¡é½æå·²ç¥çè§£æ³ï¼æç¢ºä¸ææ¼é©è­ï¼ä½ç¡æ³ééç¶²è·¯æª¢ç´¢å¿«éåç­ãæåé²ç LLM å¨ HLE ä¸å±ç¾åºä½æºç¢ºåº¦åæ ¡æºï¼çªé¡¯äºç¶å LLM è½åèå°éå¼å­¸è¡åé¡çå°å®¶äººé¡åæ²¿ä¹éçé¡¯èå·®è·ãçºäºå¨æ¸æ¥äºè§£æ¨¡åè½åçææ³ä¸çºç ç©¶åæ¿ç­å¶å®æä¾è³è¨ï¼æåå¨ https://lastexam.ai å¬éç¼å¸ HLEã

##### **Detection and Classification of Acute Lymphoblastic Leukemia Utilizing Deep Transfer Learning**
2501.14228v1 by Md. Abu Ahnaf Mollick, Md. Mahfujur Rahman, D. M. Asadujjaman, Abdullah Tamim, Nosin Anjum Dristi, Md. Takbir Hossen

A mutation in the DNA of a single cell that compromises its function
initiates leukemia,leading to the overproduction of immature white blood cells
that encroach upon the space required for the generation of healthy blood
cells.Leukemia is treatable if identified in its initial stages. However,its
diagnosis is both arduous and time consuming. This study proposes a novel
approach for diagnosing leukemia across four stages Benign,Early,Pre,and Pro
using deep learning techniques.We employed two Convolutional Neural Network
(CNN) models as MobileNetV2 with an altered head and a custom model. The custom
model consists of multiple convolutional layers,each paired with corresponding
max pooling layers.We utilized MobileNetV2 with ImageNet weights,adjusting the
head to integrate the final results.The dataset used is the publicly available
"Acute Lymphoblastic Leukemia (ALL) Image Dataset", and we applied the
Synthetic Minority Oversampling Technique (SMOTE) to augment and balance the
training dataset.The custom model achieved an accuracy of 98.6%, while
MobileNetV2 attained a superior accuracy of 99.69%. The pretrained model showed
promising results,indicating an increased likelihood of real-world application.

æè¦ï¼å®ä¸ç´°è DNA ä¸­ææå®³å¶åè½ççªè®æå¼ç¼ç½è¡çï¼å°è´æªæçç½è¡çéåº¦å¢çï¼ä¾µä½å¥åº·è¡ççæçç©ºéãç½è¡çè¥å¨åæéæ®µå°±è½è­å¥ï¼æ¯å¯ä»¥æ²»ççãç¶èï¼å®çè¨ºæ·æ¢è±é£åèæãæ¬ç ç©¶æåºäºä¸ç¨®ä½¿ç¨æ·±åº¦å­¸ç¿æè¡è¨ºæ·ååç½è¡çéæ®µï¼è¯æ§ãæ©æãåæåé²å±æï¼çæ°æ¹æ³ãæåä½¿ç¨äºå©åå·ç©ç¥ç¶ç¶²è·¯ (CNN) æ¨¡åï¼åå¥æ¯å·æä¿®æ¹é ­é¨ç MobileNetV2 åä¸åèªè¨æ¨¡åãèªè¨æ¨¡ååå«å¤åå·ç©å±¤ï¼æ¯åå·ç©å±¤é½èå°æçæå¤§æ± åå±¤éå°ãæåå©ç¨å·æ ImageNet æ¬éç MobileNetV2ï¼èª¿æ´é ­é¨ä»¥æ´åæçµçµæãæä½¿ç¨çè³æéæ¯å¬éçãæ¥æ§æ·å·´æ§ç½è¡ç (ALL) å½±åè³æéãï¼æåæç¨åæå°æ¸éæ¡æ¨£æè¡ (SMOTE) ä¾æ´ååå¹³è¡¡è¨ç·´è³æéãèªè¨æ¨¡åéå°äº 98.6% çæºç¢ºçï¼è MobileNetV2 åéå°äº 99.69% çåªç°æºç¢ºçãé è¨ç·´æ¨¡åé¡¯ç¤ºåºæå¸æççµæï¼è¡¨ç¤ºå¨ç¾å¯¦ä¸çä¸­æç¨çå¯è½æ§æé«ã

##### **Multi-agent KTO: Reinforcing Strategic Interactions of Large Language Model in Language Game**
2501.14225v1 by Rong Ye, Yongxin Zhang, Yikai Zhang, Haoyu Kuang, Zhongyu Wei, Peng Sun

Achieving Artificial General Intelligence (AGI) requires AI agents that can
not only make stratigic decisions but also engage in flexible and meaningful
communication. Inspired by Wittgenstein's language game theory in Philosophical
Investigations, we propose that language agents can learn through in-context
interaction rather than traditional multi-stage frameworks that separate
decision-making from language expression. Using Werewolf, a social deduction
game that tests language understanding, strategic interaction, and
adaptability, we develop the Multi-agent Kahneman & Tversky's Optimization
(MaKTO). MaKTO engages diverse models in extensive gameplay to generate
unpaired desirable and unacceptable responses, then employs KTO to refine the
model's decision-making process. In 9-player Werewolf games, MaKTO achieves a
61% average win rate across various models, outperforming GPT-4o and two-stage
RL agents by relative improvements of 23.0% and 10.9%, respectively. Notably,
MaKTO also demonstrates human-like performance, winning 60% against expert
players and showing only 49% detectability in Turing-style blind tests. These
results showcase MaKTO's superior decision-making, strategic adaptation, and
natural language generation in complex social deduction games.

æè¦ï¼è¦å®ç°äººå·¥æºè½éç¨æºè½ï¼AGIï¼ï¼éè¦ AI ä»£çä¸ä»è½ååºæç¥å³ç­ï¼è¿è½è¿è¡çµæ´»ä¸ææä¹çæ²éãåç»´ç¹æ ¹æ¯å¦å¨ãå²å­¦ç ç©¶ãä¸­æåºçè¯­è¨æ¸¸æçè®ºçå¯åï¼æä»¬æåºè¯­è¨ä»£çå¯ä»¥éè¿æå¢äºå¨å­¦ä¹ ï¼èä¸æ¯éè¿å°å³ç­ä¸è¯­è¨è¡¨è¾¾åå¼çä¼ ç»å¤é¶æ®µæ¡æ¶ãæä»¬ä½¿ç¨ç¼äººæ¸¸æï¼ä¸ç§æµè¯è¯­è¨çè§£ãæç¥äºå¨åéåºæ§çç¤¾äº¤æ¨çæ¸¸æï¼å¼åäºå¤ä»£çå¡å°¼æ¼åç¹æ²æ¯åºä¼åï¼MaKTOï¼ãMaKTO è®©ä¸åçæ¨¡ååä¸å¹¿æ³çæ¸¸æï¼ä»¥çæä¸æå¯¹ççæ³åä¸å¯æ¥åçååºï¼ç¶åä½¿ç¨ KTO ä¼åæ¨¡åçå³ç­è¿ç¨ãå¨ 9 äººç¼äººæ¸¸æä¸­ï¼MaKTO å¨åç§æ¨¡åä¸­å®ç°äº 61% çå¹³åè·èçï¼åå«æ¯ GPT-4o åä¸¤é¶æ®µ RL ä»£ççç¸å¯¹æ¹è¿çé«åº 23.0% å 10.9%ãå¼å¾æ³¨æçæ¯ï¼MaKTO è¿å±ç¤ºäºç±»äººçè¡¨ç°ï¼å¨å¯¹æä¸å®¶ç©å®¶æ¶è·èçä¸º 60%ï¼å¨å¾çµé£æ ¼çç²æµä¸­ä»æ¾ç¤º 49% çå¯æ£æµæ§ãè¿äºç»æå±ç¤ºäº MaKTO å¨å¤æçç¤¾äº¤æ¨çæ¸¸æä¸­åºè²çå³ç­ãæç¥éåºåèªç¶è¯­è¨çæè½åã

##### **Top Ten Challenges Towards Agentic Neural Graph Databases**
2501.14224v1 by Jiaxin Bai, Zihao Wang, Yukun Zhou, Hang Yin, Weizhi Fei, Qi Hu, Zheye Deng, Jiayang Cheng, Tianshi Zheng, Hong Ting Tsang, Yisen Gao, Zhongwei Xie, Yufei Li, Lixin Fan, Binhang Yuan, Wei Wang, Lei Chen, Xiaofang Zhou, Yangqiu Song

Graph databases (GDBs) like Neo4j and TigerGraph excel at handling
interconnected data but lack advanced inference capabilities. Neural Graph
Databases (NGDBs) address this by integrating Graph Neural Networks (GNNs) for
predictive analysis and reasoning over incomplete or noisy data. However, NGDBs
rely on predefined queries and lack autonomy and adaptability. This paper
introduces Agentic Neural Graph Databases (Agentic NGDBs), which extend NGDBs
with three core functionalities: autonomous query construction, neural query
execution, and continuous learning. We identify ten key challenges in realizing
Agentic NGDBs: semantic unit representation, abductive reasoning, scalable
query execution, and integration with foundation models like large language
models (LLMs). By addressing these challenges, Agentic NGDBs can enable
intelligent, self-improving systems for modern data-driven applications, paving
the way for adaptable and autonomous data management solutions.

æè¦ï¼åå½¢è³æåº«ï¼GDBï¼ï¼ä¾å¦ Neo4j å TigerGraphï¼æé·èçç¸äºé£æ¥çè³æï¼ä½ç¼ºä¹é²éçæ¨è«è½åãç¥ç¶åå½¢è³æåº«ï¼NGDBï¼ééæ´ååå½¢ç¥ç¶ç¶²è·¯ï¼GNNï¼ä¾è§£æ±ºéååé¡ï¼ä»¥é²è¡é æ¸¬åæåå°ä¸å®æ´ææéè¨çè³æé²è¡æ¨çãç¶èï¼NGDB ä¾è³´æ¼é åå®ç¾©çæ¥è©¢ï¼ä¸¦ä¸ç¼ºä¹èªä¸»æ§åé©ææ§ãæ¬æä»ç´¹äºä»£çç¥ç¶åå½¢è³æåº«ï¼Agentic NGDBï¼ï¼å®ä»¥ä¸é æ ¸å¿åè½æ´åäº NGDBï¼èªåæ¥è©¢å»ºæ§ãç¥ç¶æ¥è©¢å·è¡åæçºå­¸ç¿ãæåæ¾åºå¯¦ç¾ Agentic NGDB çåå¤§ééµææ°ï¼èªç¾©å®åè¡¨ç¤ºãæ¼ç¹¹æ¨çãå¯æ´åæ¥è©¢å·è¡ï¼ä»¥åèåºç¤æ¨¡åï¼ä¾å¦å¤§åèªè¨æ¨¡å (LLM)ï¼æ´åãééè§£æ±ºéäºææ°ï¼Agentic NGDB å¯ä»¥çºç¾ä»£è³æé©åæç¨æé æºæ§ä¸èªææ¹åçç³»çµ±ï¼çºé©ææ§åèªä¸»è³æç®¡çè§£æ±ºæ¹æ¡éªè·¯ã

##### **TFG-Flow: Training-free Guidance in Multimodal Generative Flow**
2501.14216v1 by Haowei Lin, Shanda Li, Haotian Ye, Yiming Yang, Stefano Ermon, Yitao Liang, Jianzhu Ma

Given an unconditional generative model and a predictor for a target property
(e.g., a classifier), the goal of training-free guidance is to generate samples
with desirable target properties without additional training. As a highly
efficient technique for steering generative models toward flexible outcomes,
training-free guidance has gained increasing attention in diffusion models.
However, existing methods only handle data in continuous spaces, while many
scientific applications involve both continuous and discrete data (referred to
as multimodality). Another emerging trend is the growing use of the simple and
general flow matching framework in building generative foundation models, where
guided generation remains under-explored. To address this, we introduce
TFG-Flow, a novel training-free guidance method for multimodal generative flow.
TFG-Flow addresses the curse-of-dimensionality while maintaining the property
of unbiased sampling in guiding discrete variables. We validate TFG-Flow on
four molecular design tasks and show that TFG-Flow has great potential in drug
design by generating molecules with desired properties.

æè¦ï¼åè¨­æåæä¸åç¡æ¢ä»¶çææ¨¡ååä¸åç®æ¨å±¬æ§çé æ¸¬å¨ï¼ä¾å¦åé¡å¨ï¼ï¼ç¡è¨ç·´å¼å°çç®æ¨æ¯çæå·æçæ³ç®æ¨å±¬æ§çæ¨£æ¬ï¼èç¡éé¡å¤è¨ç·´ãä½çºä¸ç¨®å¼å°çææ¨¡åæåéæ´»çµæçé«ææè¡ï¼ç¡è¨ç·´å¼å°å¨æ´æ£æ¨¡åä¸­ç²å¾äºè¶ä¾è¶å¤çéæ³¨ãç¶èï¼ç¾ææ¹æ³åèçé£çºç©ºéä¸­çæ¸æï¼èè¨±å¤ç§å­¸æç¨æ¶åé£çºåé¢æ£æ¸æï¼ç¨±çºå¤æ¨¡æï¼ãå¦ä¸åæ°èè¶¨å¢æ¯è¶ä¾è¶å¤å°ä½¿ç¨ç°¡å®ä¸éç¨çæµå¹éæ¡æ¶ä¾æ§å»ºçæåºç¤æ¨¡åï¼å¶ä¸­å¼å°çæä»æªå¾å°ååæ¢ç´¢ãçºäºè§£æ±ºéååé¡ï¼æåå¼å¥äº TFG-Flowï¼éæ¯ä¸ç¨®éå°å¤æ¨¡æçææµçæ°åç¡è¨ç·´å¼å°æ¹æ³ãTFG-Flow å¨ä¿æç¡åæ¡æ¨£çå±¬æ§çåæè§£æ±ºäºç¶­åº¦ç½é£ï¼å¾èå¼å°é¢æ£è®éãæåå¨åååå­è¨­è¨ä»»åä¸é©è­äº TFG-Flowï¼ä¸¦è¡¨æ TFG-Flow å¨è¥ç©è¨­è¨ä¸­å·æå·¨å¤§çæ½åï¼å çºå®å¯ä»¥çæå·ææéå±¬æ§çåå­ã

##### **PuzzleGPT: Emulating Human Puzzle-Solving Ability for Time and Location Prediction**
2501.14210v1 by Hammad Ayyubi, Xuande Feng, Junzhang Liu, Xudong Lin, Zhecan Wang, Shih-Fu Chang

The task of predicting time and location from images is challenging and
requires complex human-like puzzle-solving ability over different clues. In
this work, we formalize this ability into core skills and implement them using
different modules in an expert pipeline called PuzzleGPT. PuzzleGPT consists of
a perceiver to identify visual clues, a reasoner to deduce prediction
candidates, a combiner to combinatorially combine information from different
clues, a web retriever to get external knowledge if the task can't be solved
locally, and a noise filter for robustness. This results in a zero-shot,
interpretable, and robust approach that records state-of-the-art performance on
two datasets -- TARA and WikiTilo. PuzzleGPT outperforms large VLMs such as
BLIP-2, InstructBLIP, LLaVA, and even GPT-4V, as well as automatically
generated reasoning pipelines like VisProg, by at least 32% and 38%,
respectively. It even rivals or surpasses finetuned models.

æè¦ï¼å¾å½±åé æ¸¬æéåä½ç½®çä»»åå·æææ°æ§ï¼éè¦å·åäººé¡è¬çè¤éè§£è¬è½åï¼æè½å¾ä¸åçç·ç´¢ä¸­è§£è¬ãå¨æ­¤ç ç©¶ä¸­ï¼æåå°éç¨®è½åå½¢å¼åçºæ ¸å¿æè½ï¼ä¸¦ä½¿ç¨å°å®¶ç®¡é PuzzleGPT ä¸­çä¸åæ¨¡çµä¾å¯¦ä½éäºæè½ãPuzzleGPT åå«ä¸åæç¥å¨ï¼ç¨æ¼è­å¥è¦è¦ºç·ç´¢ï¼ä¸åæ¨çå¨ï¼ç¨æ¼æ¨è«é æ¸¬åé¸é ï¼ä¸åçµåå¨ï¼ç¨æ¼çµåä¾èªä¸åç·ç´¢çè³è¨ï¼ä¸åç¶²è·¯æª¢ç´¢å¨ï¼ç¨æ¼å¨ç¡æ³å¨æ¬å°è§£æ±ºä»»åæåå¾å¤é¨ç¥è­ï¼ä»¥åä¸åéè¨æ¿¾æ³¢å¨ï¼ç¨æ¼å¢å¼·ç©©å¥æ§ãéç¢çäºä¸ç¨®é¶æ¬¡å­¸ç¿ãå¯è§£éä¸ç©©å¥çæ¹æ³ï¼å¨å©åè³æéï¼TARA å WikiTiloï¼ä¸åµä¸æåé²çæè½ãPuzzleGPT çè¡¨ç¾åªæ¼å¤§å VLMï¼ä¾å¦ BLIP-2ãInstructBLIPãLLaVAï¼çè³ GPT-4Vï¼ä»¥åèªåç¢ççæ¨çç®¡éï¼ä¾å¦ VisProgï¼ï¼åå¥è³å°é«åº 32% å 38%ãå®çè³èå¾®èª¿æ¨¡åç¸æè¡¡æè¶è¶å¾®èª¿æ¨¡åã

##### **Dynamic Token Reduction during Generation for Vision Language Models**
2501.14204v1 by Xiaoyu Liang, Chaofeng Guan, Jiaying Lu, Huiyao Chen, Huan Wang, Haoji Hu

Vision-Language Models (VLMs) have achieved notable success in multimodal
tasks but face practical limitations due to the quadratic complexity of decoder
attention mechanisms and autoregressive generation. Existing methods like FASTV
and VTW have achieved notable results in reducing redundant visual tokens, but
these approaches focus on pruning tokens in a single forward pass without
systematically analyzing the redundancy of visual tokens throughout the entire
generation process. In this paper, we introduce a dynamic pruning strategy
tailored for VLMs, namedDynamic Rate (DyRate), which progressively adjusts the
compression rate during generation. Our analysis of the distribution of
attention reveals that the importance of visual tokens decreases throughout the
generation process, inspiring us to adopt a more aggressive compression rate.
By integrating a lightweight predictor based on attention distribution, our
approach enables flexible adjustment of pruning rates based on the attention
distribution. Our experimental results demonstrate that our method not only
reduces computational demands but also maintains the quality of responses.

æè¦ï¼è¦è¦ºèªè¨æ¨¡å (VLM) å·²å¨å¤æ¨¡æä»»åä¸­åå¾é¡¯èæåï¼ä½ç±æ¼è§£ç¢¼å¨æ³¨æåæ©å¶åèªè¿´æ­¸çæçäºæ¬¡è¤éæ§èé¢è¨å¯¦ééå¶ãFASTV å VTW ç­ç¾ææ¹æ³å·²å¨æ¸å°å¤é¤è¦è¦ºç¬¦èæ¹é¢åå¾é¡¯èææï¼ä½éäºæ¹æ³å°æ³¨æ¼å¨å®æ¬¡ååå³éä¸­ä¿®åªç¬¦èï¼èæ²æç³»çµ±å°åææ´åçæéç¨ä¸­è¦è¦ºç¬¦èçåé¤ãå¨æ¬æä¸­ï¼æåå¼å¥äºä¸ç¨®å°çº VLM è¨­è¨çåæä¿®åªç­ç¥ï¼ç¨±çºåæéç (DyRate)ï¼å®æå¨çæéç¨ä¸­éæ­¥èª¿æ´å£ç¸®çãæåå°æ³¨æååä½çåæè¡¨æï¼è¦è¦ºç¬¦èçéè¦æ§æå¨æ´åçæéç¨ä¸­éä½ï¼éåç¼æåæ¡ç¨æ´æ¿é²çå£ç¸®çãééæ´ååºæ¼æ³¨æååä½çè¼éç´é æ¸¬å¨ï¼æåçæè¡å¯ä»¥æ ¹ææ³¨æååä½éæ´»èª¿æ´ä¿®åªçãæåçå¯¦é©çµæè¡¨æï¼æåçæè¡ä¸åæ¸å°äºéç®éæ±ï¼èä¸éç¶­æäºåæçåè³ªã

##### **Coordinating Ride-Pooling with Public Transit using Reward-Guided Conservative Q-Learning: An Offline Training and Online Fine-Tuning Reinforcement Learning Framework**
2501.14199v1 by Yulong Hu, Tingting Dong, Sen Li

This paper introduces a novel reinforcement learning (RL) framework, termed
Reward-Guided Conservative Q-learning (RG-CQL), to enhance coordination between
ride-pooling and public transit within a multimodal transportation network. We
model each ride-pooling vehicle as an agent governed by a Markov Decision
Process (MDP) and propose an offline training and online fine-tuning RL
framework to learn the optimal operational decisions of the multimodal
transportation systems, including rider-vehicle matching, selection of drop-off
locations for passengers, and vehicle routing decisions, with improved data
efficiency. During the offline training phase, we develop a Conservative Double
Deep Q Network (CDDQN) as the action executor and a supervised learning-based
reward estimator, termed the Guider Network, to extract valuable insights into
action-reward relationships from data batches. In the online fine-tuning phase,
the Guider Network serves as an exploration guide, aiding CDDQN in effectively
and conservatively exploring unknown state-action pairs. The efficacy of our
algorithm is demonstrated through a realistic case study using real-world data
from Manhattan. We show that integrating ride-pooling with public transit
outperforms two benchmark cases solo rides coordinated with transit and
ride-pooling without transit coordination by 17% and 22% in the achieved system
rewards, respectively. Furthermore, our innovative offline training and online
fine-tuning framework offers a remarkable 81.3% improvement in data efficiency
compared to traditional online RL methods with adequate exploration budgets,
with a 4.3% increase in total rewards and a 5.6% reduction in overestimation
errors. Experimental results further demonstrate that RG-CQL effectively
addresses the challenges of transitioning from offline to online RL in
large-scale ride-pooling systems integrated with transit.

æè¦ï¼<paragraph>æ¬æä»ç´¹äºä¸ç¨®åµæ°çå¼·åå­¸ç¿ (RL) æ¶æ§ï¼ç¨±çºçåµå¼å°ä¿å® Q å­¸ç¿ (RG-CQL)ï¼ä»¥å¢å¼·å¤å¼è¯éç¶²è·¯ä¸­ä¹è»å±ä¹èå¤§ç¾éè¼¸ä¹éçåèª¿ãæåå°æ¯åä¹è»å±ä¹è»è¼å»ºæ¨¡çºåé¦¬å¯å¤«æ±ºç­éç¨ (MDP) æ§å¶çä»£çï¼ä¸¦æåºä¸åé¢ç·è¨ç·´åç·ä¸å¾®èª¿ RL æ¶æ§ï¼ä»¥å­¸ç¿å¤å¼è¯éç³»çµ±çæä½³çéæ±ºç­ï¼åæ¬ä¹å®¢èè»è¼éå°ãä¹å®¢ä¸è»å°é»çé¸æï¼ä»¥åè»è¼è·¯ç·æ±ºç­ï¼ä¸¦æé«è³ææçãå¨é¢ç·è¨ç·´éæ®µï¼æåéç¼äºä¸åä¿å®éæ·±åº¦ Q ç¶²è·¯ (CDDQN) ä½çºåä½å·è¡å¨ï¼ä»¥åä¸ååºæ¼ç£ç£å­¸ç¿ççåµä¼°è¨å¨ï¼ç¨±çºå¼å°ç¶²è·¯ï¼å¾è³ææ¹æ¬¡ä¸­æåå°åä½çåµéä¿çå¯¶è²´è¦è§£ãå¨ç·ä¸å¾®èª¿éæ®µï¼å¼å°ç¶²è·¯ä½çºæ¢ç´¢æåï¼åå© CDDQN ææä¸ä¿å®å°æ¢ç´¢æªç¥ççæåä½å°ãæåä½¿ç¨ä¾èªæ¼åé ççå¯¦ä¸çè³æï¼ééä¸åå¯¦éæ¡ä¾ç ç©¶ä¾è­ææåæ¼ç®æ³çåæãæåå±ç¤ºäºå°ä¹è»å±ä¹èå¤§ç¾éè¼¸æ´åèµ·ä¾ï¼å¨éæçç³»çµ±çåµæ¹é¢åå¥æ¯èéè¼¸åèª¿çå®äººä¹è»åæ²æéè¼¸åèª¿çä¹è»å±ä¹é«åº 17% å 22%ãæ­¤å¤ï¼æååµæ°çé¢ç·è¨ç·´åç·ä¸å¾®èª¿æ¶æ§ï¼èå·æè¶³å¤ æ¢ç´¢é ç®çå³çµ±ç·ä¸ RL æ¹æ³ç¸æ¯ï¼å¨è³ææçæ¹é¢æä¾äºé¡¯èç 81.3% æåï¼ç¸½çåµå¢å äº 4.3%ï¼é«ä¼°èª¤å·®æ¸å°äº 5.6%ãå¯¦é©çµæé²ä¸æ­¥è­æï¼RG-CQL ææå°æå°äºå¾é¢ç·å°ç·ä¸ RL è½æå¨èéè¼¸æ´åçå¤§è¦æ¨¡ä¹è»å±ä¹ç³»çµ±ä¸­çææ°ã</paragraph>

##### **Distributed Multi-Agent Coordination Using Multi-Modal Foundation Models**
2501.14189v1 by Saaduddin Mahmud, Dorian Benhamou Goldfajn, Shlomo Zilberstein

Distributed Constraint Optimization Problems (DCOPs) offer a powerful
framework for multi-agent coordination but often rely on labor-intensive,
manual problem construction. To address this, we introduce VL-DCOPs, a
framework that takes advantage of large multimodal foundation models (LFMs) to
automatically generate constraints from both visual and linguistic
instructions. We then introduce a spectrum of agent archetypes for solving
VL-DCOPs: from a neuro-symbolic agent that delegates some of the algorithmic
decisions to an LFM, to a fully neural agent that depends entirely on an LFM
for coordination. We evaluate these agent archetypes using state-of-the-art
LLMs (large language models) and VLMs (vision language models) on three novel
VL-DCOP tasks and compare their respective advantages and drawbacks. Lastly, we
discuss how this work extends to broader frontier challenges in the DCOP
literature.

æè¦ï¼åæ£å¼ç´ææä½³ååé¡ (DCOP) æä¾äºä¸åå¼·å¤§çå¤ä»£çåèª¿æ¶æ§ï¼ä½éå¸¸ä¾è³´æ¼ååå¯éçæååé¡å»ºæ§ãçºäºè§£æ±ºéååé¡ï¼æåå¼å¥äº VL-DCOPï¼ä¸åå©ç¨å¤§åå¤æ¨¡æåºç¤æ¨¡å (LFM) å¾è¦è¦ºåèªè¨æä»¤èªåç¢çç´æçæ¶æ§ãæ¥èæåå¼å¥äºç¨æ¼è§£æ±º VL-DCOP çä¸çµä»£çååï¼å¾å°é¨åæ¼ç®æ³æ±ºç­å§æ´¾çµ¦ LFM çç¥ç¶ç¬¦èä»£çï¼å°å®å¨ä¾è³´ LFM é²è¡åèª¿çå¨ç¥ç¶ç¶²è·¯ä»£çãæåä½¿ç¨æåé²ç LLM (å¤§åèªè¨æ¨¡å) å VLM (è¦è¦ºèªè¨æ¨¡å) å¨ä¸åæ°ç©ç VL-DCOP ä»»åä¸è©ä¼°éäºä»£çååï¼ä¸¦æ¯è¼å®ååèªçåªç¼ºé»ãæå¾ï¼æåè¨è«äºéé å·¥ä½å¦ä½æ´å±å° DCOP æç»ä¸­æ´å»£æ³çåæ²¿ææ°ã

##### **Dreamweaver: Learning Compositional World Representations from Pixels**
2501.14174v1 by Junyeob Baek, Yi-Fu Wu, Gautam Singh, Sungjin Ahn

Humans have an innate ability to decompose their perceptions of the world
into objects and their attributes, such as colors, shapes, and movement
patterns. This cognitive process enables us to imagine novel futures by
recombining familiar concepts. However, replicating this ability in artificial
intelligence systems has proven challenging, particularly when it comes to
modeling videos into compositional concepts and generating unseen, recomposed
futures without relying on auxiliary data, such as text, masks, or bounding
boxes. In this paper, we propose Dreamweaver, a neural architecture designed to
discover hierarchical and compositional representations from raw videos and
generate compositional future simulations. Our approach leverages a novel
Recurrent Block-Slot Unit (RBSU) to decompose videos into their constituent
objects and attributes. In addition, Dreamweaver uses a multi-future-frame
prediction objective to capture disentangled representations for dynamic
concepts more effectively as well as static concepts. In experiments, we
demonstrate our model outperforms current state-of-the-art baselines for world
modeling when evaluated under the DCI framework across multiple datasets.
Furthermore, we show how the modularized concept representations of our model
enable compositional imagination, allowing the generation of novel videos by
recombining attributes from different objects.

æè¦ï¼äººé¡å·æå°ä»åå°ä¸ççæç¥åè§£æç©ä»¶åå¶å±¬æ§ï¼ä¾å¦é¡è²ãå½¢çåéåæ¨¡å¼ï¼çåå¤©è½åãéåèªç¥éç¨è®æåè½å¤ éééæ°çµåçæçæ¦å¿µä¾æ³åæ°ç©çæªä¾ãç¶èï¼å¨äººå·¥æºæ§ç³»çµ±ä¸­è¤è£½éç¨®è½åå·²è¢«è­æå·æææ°æ§ï¼ç¹å¥æ¯å¨å°å½±çå»ºæ¨¡æçµåæ¦å¿µä¸¦ç¢çæªè¦éçãéæ°çµåçæªä¾æï¼ä¸ä¸ä¾è³´è¼å©è³æï¼ä¾å¦æå­ãé®ç½©æéçæ¡ãå¨æ¬æä¸­ï¼æåæåºäº Dreamweaverï¼ä¸ç¨®ç¥ç¶æ¶æ§ï¼æ¨å¨å¾åå§å½±çä¸­ç¼ç¾éå±¤å¼åçµåå¼è¡¨ç¤ºï¼ä¸¦ç¢ççµåå¼æªä¾æ¨¡æ¬ãæåçåæ³å©ç¨ä¸ç¨®æ°ç©çéè¿´åå¡æ§½å®å (RBSU) å°å½±çåè§£æå¶çµæç©ä»¶åå±¬æ§ãæ­¤å¤ï¼Dreamweaver ä½¿ç¨å¤æªä¾å¹é æ¸¬ç®æ¨ï¼ä»¥æ´ææå°æ·ååææ¦å¿µåéææ¦å¿µçè§£ç³¾çºè¡¨ç¤ºãå¨å¯¦é©ä¸­ï¼æåè­æäºæåçæ¨¡åå¨å¤åè³æéä¸æ ¹æ DCI æ¶æ§è©ä¼°æï¼åªæ¼ç¶åä¸çå»ºæ¨¡æè¡çææ°åºæºãæ­¤å¤ï¼æåå±ç¤ºäºæåæ¨¡åçæ¨¡çµåæ¦å¿µè¡¨ç¤ºå¦ä½åç¨çµåå¼æ³ååï¼åè¨±éééæ°çµåä¾èªä¸åç©ä»¶çå±¬æ§ä¾ç¢çæ°ç©çå½±çã

##### **UltraLightSqueezeNet: A Deep Learning Architecture for Malaria Classification with up to 54x fewer trainable parameters for resource constrained devices**
2501.14172v1 by Suresh Babu Nettur, Shanthi Karpurapu, Unnati Nettur, Likhit Sagar Gajja, Sravanthy Myneni, Akhil Dusi, Lalithya Posham

Lightweight deep learning approaches for malaria detection have gained
attention for their potential to enhance diagnostics in resource constrained
environments. For our study, we selected SqueezeNet1.1 as it is one of the most
popular lightweight architectures. SqueezeNet1.1 is a later version of
SqueezeNet1.0 and is 2.4 times more computationally efficient than the original
model. We proposed and implemented three ultra-lightweight architecture
variants to SqueezeNet1.1 architecture, namely Variant 1 (one fire module),
Variant 2 (two fire modules), and Variant 3 (four fire modules), which are even
more compact than SqueezeNetV1.1 (eight fire modules). These models were
implemented to evaluate the best performing variant that achieves superior
computational efficiency without sacrificing accuracy in malaria blood cell
classification. The models were trained and evaluated using the NIH Malaria
dataset. We assessed each model's performance based on metrics including
accuracy, recall, precision, F1-score, and Area Under the Curve (AUC). The
results show that the SqueezeNet1.1 model achieves the highest performance
across all metrics, with a classification accuracy of 97.12%. Variant 3 (four
fire modules) offers a competitive alternative, delivering almost identical
results (accuracy 96.55%) with a 6x reduction in computational overhead
compared to SqueezeNet1.1. Variant 2 and Variant 1 perform slightly lower than
Variant 3, with Variant 2 (two fire modules) reducing computational overhead by
28x, and Variant 1 (one fire module) achieving a 54x reduction in trainable
parameters compared to SqueezeNet1.1. These findings demonstrate that our
SqueezeNet1.1 architecture variants provide a flexible approach to malaria
detection, enabling the selection of a variant that balances resource
constraints and performance.

æè¦ï¼è¼éç´æ·±åº¦å­¸ç¿ç¨æ¼ç§ç¾æª¢æ¸¬çæ¹æ³å å¶å¢å¼·è³æºåéç°å¢ä¸­è¨ºæ·çæ½åèååéæ³¨ãå¨æåçç ç©¶ä¸­ï¼æåé¸æäº SqueezeNet1.1ï¼å çºå®æ¯æåæ­¡è¿çè¼éç´æ¶æ§ä¹ä¸ãSqueezeNet1.1 æ¯ SqueezeNet1.0 çå¾çºçæ¬ï¼å¶è¨ç®æçæ¯åå§æ¨¡åé«åº 2.4 åãæåæåºä¸¦å¯¦ä½äºä¸åè¶è¼éç´æ¶æ§è®é«ï¼åå¥æ¯ SqueezeNet1.1 æ¶æ§çè®é« 1ï¼ä¸å fire æ¨¡çµï¼ãè®é« 2ï¼å©å fire æ¨¡çµï¼åè®é« 3ï¼åå fire æ¨¡çµï¼ï¼å®åçè³æ¯ SqueezeNetV1.1ï¼å«å fire æ¨¡çµï¼æ´ç²¾ç°¡ãéäºæ¨¡åçå¯¦ä½ç®çæ¯è©ä¼°å¨ä¸ç§ç²ç§ç¾è¡çåé¡æºç¢ºæ§çææ³ä¸ï¼è½éæåè¶éç®æççæä½³æè½è®é«ãéäºæ¨¡åä½¿ç¨ NIH ç§ç¾è³æéé²è¡è¨ç·´åè©ä¼°ãæåæ ¹ææºç¢ºåº¦ãå¬åçãç²¾ç¢ºåº¦ãF1 åæ¸åæ²ç·ä¸é¢ç© (AUC) ç­ææ¨è©ä¼°æ¯åæ¨¡åçæè½ãçµæé¡¯ç¤ºï¼SqueezeNet1.1 æ¨¡åå¨ææææ¨ä¸é½éå°æé«æè½ï¼åé¡æºç¢ºåº¦çº 97.12%ãè®é« 3ï¼åå fire æ¨¡çµï¼æä¾äºæç«¶ç­åçæ¿ä»£æ¹æ¡ï¼æä¾äºå¹¾ä¹ç¸åççµæï¼æºç¢ºåº¦ 96.55%ï¼ï¼åæè SqueezeNet1.1 ç¸æ¯ï¼éç®è² ææ¸å°äº 6 åãè®é« 2 åè®é« 1 çæè½ç¥ä½æ¼è®é« 3ï¼å¶ä¸­è®é« 2ï¼å©å fire æ¨¡çµï¼å°éç®è² ææ¸å°äº 28 åï¼èè®é« 1ï¼ä¸å fire æ¨¡çµï¼è SqueezeNet1.1 ç¸æ¯ï¼å¯è¨ç·´åæ¸æ¸å°äº 54 åãéäºç¼ç¾è­æäºæåç SqueezeNet1.1 æ¶æ§è®é«æä¾äºç§ç¾æª¢æ¸¬çå½æ§æ¹æ³ï¼è½å¤ é¸æå¹³è¡¡è³æºéå¶åæè½çè®é«ã

##### **Enhancing Multimodal Entity Linking with Jaccard Distance-based Conditional Contrastive Learning and Contextual Visual Augmentation**
2501.14166v1 by Cong-Duy Nguyen, Xiaobao Wu, Thong Nguyen, Shuai Zhao, Khoi Le, Viet-Anh Nguyen, Feng Yichao, Anh Tuan Luu

Previous research on multimodal entity linking (MEL) has primarily employed
contrastive learning as the primary objective. However, using the rest of the
batch as negative samples without careful consideration, these studies risk
leveraging easy features and potentially overlook essential details that make
entities unique. In this work, we propose JD-CCL (Jaccard Distance-based
Conditional Contrastive Learning), a novel approach designed to enhance the
ability to match multimodal entity linking models. JD-CCL leverages
meta-information to select negative samples with similar attributes, making the
linking task more challenging and robust. Additionally, to address the
limitations caused by the variations within the visual modality among mentions
and entities, we introduce a novel method, CVaCPT (Contextual Visual-aid
Controllable Patch Transform). It enhances visual representations by
incorporating multi-view synthetic images and contextual textual
representations to scale and shift patch representations. Experimental results
on benchmark MEL datasets demonstrate the strong effectiveness of our approach.

æè¦ï¼ååéå°å¤æ¨¡æå¯¦é«é£çµ (MEL) çç ç©¶ä¸»è¦æ¡ç¨å°æ¯å­¸ç¿ä½çºä¸»è¦ç®æ¨ãç¶èï¼éäºç ç©¶å¨æªç¶ä»ç´°èéçææ³ä¸å°æ¹æ¬¡å¶é¤é¨åç¨ä½è² æ¨£æ¬ï¼å æ­¤æé¢¨éªæå©ç¨å®¹æè¾¨è­çç¹å¾µï¼ä¸¦å¯è½å¿½ç¥ä½¿å¯¦é«ç¨ä¸ç¡äºçéè¦ç´°ç¯ãå¨æ¬æä¸­ï¼æåæåº JD-CCLï¼Jaccard è·é¢åºç¤æ¢ä»¶å°æ¯å­¸ç¿ï¼ï¼éæ¯ä¸ç¨®æ°ç©çæ¹æ³ï¼æ¨å¨å¢å¼·å¤æ¨¡æå¯¦é«é£çµæ¨¡åçå¹éè½åãJD-CCL å©ç¨åè³è¨ä¾é¸æå·æé¡ä¼¼å±¬æ§çè² æ¨£æ¬ï¼ä½¿é£çµä»»åæ´å·ææ°æ§åç©©å¥æ§ãæ­¤å¤ï¼çºäºè§£æ±ºå¨æååå¯¦é«ä¹éçè¦è¦ºæ¨¡å¼ä¸­è®ç°æé æçéå¶ï¼æåå¼å¥äºä¸ç¨®æ°æ¹æ³ï¼ç¨±çº CVaCPTï¼èçµ¡è¦è¦ºè¼å©å¯æ§åå¡è½æï¼ãå®ééçµåå¤è¦è§åæå½±ååèçµ¡æå­è¡¨å¾µä¾å¢å¼·è¦è¦ºè¡¨å¾µï¼ä»¥ç¸®æ¾åè½ç§»åå¡è¡¨å¾µãå¨åºæº MEL è³æéä¸çå¯¦é©çµæè­æäºæåæ¹æ³çå¼·å¤§æè½ã

##### **LoCoML: A Framework for Real-World ML Inference Pipelines**
2501.14165v1 by Kritin Maddireddy, Santhosh Kotekal Methukula, Chandrasekar Sridhar, Karthik Vaidhyanathan

The widespread adoption of machine learning (ML) has brought forth diverse
models with varying architectures, and data requirements, introducing new
challenges in integrating these systems into real-world applications.
Traditional solutions often struggle to manage the complexities of connecting
heterogeneous models, especially when dealing with varied technical
specifications. These limitations are amplified in large-scale, collaborative
projects where stakeholders contribute models with different technical
specifications. To address these challenges, we developed LoCoML, a low-code
framework designed to simplify the integration of diverse ML models within the
context of the \textit{Bhashini Project} - a large-scale initiative aimed at
integrating AI-driven language technologies such as automatic speech
recognition, machine translation, text-to-speech, and optical character
recognition to support seamless communication across more than 20 languages.
Initial evaluations show that LoCoML adds only a small amount of computational
load, making it efficient and effective for large-scale ML integration. Our
practical insights show that a low-code approach can be a practical solution
for connecting multiple ML models in a collaborative environment.

æè¦ï¼æ©å¨å­¸ç¿ (ML) çå»£æ³æ¡ç¨å¸¶ä¾äºæ¶æ§åè³æéæ±åä¸ç¸åçåç¨®æ¨¡åï¼å¨å°éäºç³»çµ±æ´åå°å¯¦éæç¨ä¸­æå¼å¥äºæ°çææ°ã
å³çµ±çè§£æ±ºæ¹æ¡å¸¸å¸¸é£ä»¥ç®¡çé£æ¥ç°è³ªæ¨¡åçè¤éæ§ï¼ç¹å¥æ¯å¨èçåç¨®æè¡è¦æ ¼æãéäºéå¶å¨å¤§ååä½å°æ¡ä¸­æè¢«æ¾å¤§ï¼å¨éäºå°æ¡ä¸­ï¼å©å®³éä¿äººæè²¢ç»å·æä¸åæè¡è¦æ ¼çæ¨¡åãçºäºæå°éäºææ°ï¼æåéç¼äº LoCoMLï¼éæ¯ä¸åä½ç¨å¼ç¢¼æ¡æ¶ï¼æ¨å¨ç°¡åå¨ãBhashini å°æ¡ãä¸­æ´ååç¨® ML æ¨¡åï¼éæ¯ä¸åå¤§åè¨ç«ï¼æ¨å¨æ´å AI é©åçèªè¨æè¡ï¼ä¾å¦èªåèªé³è¾¨è­ãæ©å¨ç¿»è­¯ãæå­è½èªé³ååå­¸å­åè¾¨è­ï¼ä»¥æ¯æ´è¶é 20 ç¨®èªè¨çç¡ç¸«æºéã
åæ­¥è©ä¼°é¡¯ç¤ºï¼LoCoML åªå¢å äºå°ééç®è² è¼ï¼ä½¿å¶å°æ¼å¤§è¦æ¨¡ ML æ´åä¾èªªæ¢ææçåææãæåçå¯¦åè¦è§£é¡¯ç¤ºï¼ä½ç¨å¼ç¢¼æ¹æ³å¯ä»¥æçºå¨åä½ç°å¢ä¸­é£æ¥å¤å ML æ¨¡åçå¯¦ç¨è§£æ±ºæ¹æ¡ã

##### **Test-Time Code-Switching for Cross-lingual Aspect Sentiment Triplet Extraction**
2501.14144v1 by Dongming Sheng, Kexin Han, Hao Li, Yan Zhang, Yucheng Huang, Jun Lang, Wenqiang Liu

Aspect Sentiment Triplet Extraction (ASTE) is a thriving research area with
impressive outcomes being achieved on high-resource languages. However, the
application of cross-lingual transfer to the ASTE task has been relatively
unexplored, and current code-switching methods still suffer from term boundary
detection issues and out-of-dictionary problems. In this study, we introduce a
novel Test-Time Code-SWitching (TT-CSW) framework, which bridges the gap
between the bilingual training phase and the monolingual test-time prediction.
During training, a generative model is developed based on bilingual
code-switched training data and can produce bilingual ASTE triplets for
bilingual inputs. In the testing stage, we employ an alignment-based
code-switching technique for test-time augmentation. Extensive experiments on
cross-lingual ASTE datasets validate the effectiveness of our proposed method.
We achieve an average improvement of 3.7% in terms of weighted-averaged F1 in
four datasets with different languages. Additionally, we set a benchmark using
ChatGPT and GPT-4, and demonstrate that even smaller generative models
fine-tuned with our proposed TT-CSW framework surpass ChatGPT and GPT-4 by
14.2% and 5.0% respectively.

æè¦ï¼é¢åæ¹é¢çææä¸åçµæ½å (ASTE) æ¯åè¬åç¼å±çç ç©¶é åï¼å¨é«è³æºèªè¨ä¸­åå¾ä»¤äººå°è±¡æ·±å»çææãç¶èï¼è·¨èªè¨è½ç§»æç¨æ¼ ASTE ä»»åçç ç©¶ç¸å°è¼å°ï¼ç®åçä»£ç¢¼è½ææ¹æ³ä»ç¶å­å¨è¡èªéçåµæ¸¬åé¡åå­å¸å¤åé¡ãå¨æ¬ç ç©¶ä¸­ï¼æåå¼å¥äºä¸åæ°ç©çæ¸¬è©¦æä»£ç¢¼è½æ (TT-CSW) æ¡æ¶ï¼å®å½åäºéèªè¨ç·´éæ®µèå®èªæ¸¬è©¦æé æ¸¬ä¹éçå·®è·ãå¨è¨ç·´æéï¼åºæ¼éèªä»£ç¢¼è½æè¨ç·´æ¸æéç¼äºä¸åçææ¨¡åï¼ä¸¦ä¸å¯ä»¥çºéèªè¼¸å¥ç¢çéèª ASTE ä¸åçµãå¨æ¸¬è©¦éæ®µï¼æåæ¡ç¨åºæ¼å°é½çä»£ç¢¼è½ææè¡é²è¡æ¸¬è©¦ææ´åãè·¨èªè¨ ASTE è³æéä¸çå¤§éå¯¦é©é©è­äºæåæåºçæ¹æ³çæææ§ãæåå¨ååä¸åèªè¨çè³æéä¸­ï¼å¨å æ¬å¹³å F1 æ¹é¢å¯¦ç¾äºå¹³å 3.7% çæåãæ­¤å¤ï¼æåä½¿ç¨ ChatGPT å GPT-4 è¨­å®äºä¸ååºæºï¼ä¸¦è­æå³ä½¿æ¯è¼å°ççææ¨¡åä½¿ç¨æåæåºç TT-CSW æ¡æ¶é²è¡å¾®èª¿ï¼ä¹åå¥æ¯ ChatGPT å GPT-4 é«åº 14.2% å 5.0%ã

##### **Reinforcement Learning Platform for Adversarial Black-box Attacks with Custom Distortion Filters**
2501.14122v1 by Soumyendu Sarkar, Ashwin Ramesh Babu, Sajad Mousavi, Vineet Gundecha, Sahand Ghorbanpour, Avisek Naug, Ricardo Luna Gutierrez, Antonio Guillen

We present a Reinforcement Learning Platform for Adversarial Black-box
untargeted and targeted attacks, RLAB, that allows users to select from various
distortion filters to create adversarial examples. The platform uses a
Reinforcement Learning agent to add minimum distortion to input images while
still causing misclassification by the target model. The agent uses a novel
dual-action method to explore the input image at each step to identify
sensitive regions for adding distortions while removing noises that have less
impact on the target model. This dual action leads to faster and more efficient
convergence of the attack. The platform can also be used to measure the
robustness of image classification models against specific distortion types.
Also, retraining the model with adversarial samples significantly improved
robustness when evaluated on benchmark datasets. The proposed platform
outperforms state-of-the-art methods in terms of the average number of queries
required to cause misclassification. This advances trustworthiness with a
positive social impact.

æè¦ï¼æåæåºä¸åéå°å°ææ§é»çç¡ç®æ¨åç®æ¨æ»æçå¼·åå­¸ç¿å¹³å° RLABï¼å®åè¨±ä½¿ç¨èå¾åç¨®å¤±çæ¿¾é¡ä¸­é¸æï¼ä»¥å»ºç«å°ææ§ç¯ä¾ãè©²å¹³å°ä½¿ç¨å¼·åå­¸ç¿ä»£çï¼å¨ä¸é æç®æ¨æ¨¡åèª¤åé¡çææ³ä¸ï¼å°è¼¸å¥å½±åçå¤±çéè³æä½ãè©²ä»£çä½¿ç¨ä¸ç¨®æ°ç©çééåä½æ¹æ³ï¼å¨æ¯åæ­¥é©ä¸­æ¢ç´¢è¼¸å¥å½±åï¼ä»¥æ¾åºå¯å å¥å¤±ççææååï¼åæç§»é¤å°ç®æ¨æ¨¡åå½±é¿è¼å°çéè¨ãéç¨®ééåä½å°è´æ»æçæ¶æéåº¦æ´å¿«ãæçæ´é«ãè©²å¹³å°éå¯ç¨æ¥è¡¡éå½±ååé¡æ¨¡åå°ç¹å®å¤±çé¡åçç©©å¥æ§ãæ­¤å¤ï¼ä½¿ç¨å°ææ§ç¯ä¾éæ°è¨ç·´æ¨¡åï¼å¨åºæºè³æéä¸è©ä¼°æï¼é¡¯èæ¹åäºç©©å¥æ§ãææåºçå¹³å°å¨é æèª¤åé¡æéçå¹³åæ¥è©¢æ¬¡æ¸æ¹é¢ï¼åªæ¼æåé²çæ¹æ³ãéééæ­£åçç¤¾æå½±é¿ï¼æåäºå¯ä¿¡åº¦ã

##### **On the Transfer of Knowledge in Quantum Algorithms**
2501.14120v1 by Esther Villar-Rodriguez, Eneko Osaba, Izaskun Oregi, SebastiÃ¡n V. Romero, JuliÃ¡n Ferreiro-VÃ©lez

The field of quantum computing is generating significant anticipation within
the scientific and industrial communities due to its potential to revolutionize
computing paradigms. Recognizing this potential, this paper explores the
integration of transfer of knowledge techniques, traditionally used in
classical artificial intelligence, into quantum computing. We present a
comprehensive classification of the transfer models, focusing on Transfer
Learning and Transfer Optimization. Additionally, we analyze relevant schemes
in quantum computing that can benefit from knowledge sharing, and we delve into
the potential synergies, supported by theoretical insights and initial
experimental results. Our findings suggest that leveraging the transfer of
knowledge can enhance the efficiency and effectiveness of quantum algorithms,
particularly in the context of hybrid solvers. This approach not only
accelerates the optimization process but also reduces the computational burden
on quantum processors, making it a valuable tool for advancing quantum
computing technologies.

æè¦ï¼éå­éç®é åå¨ç§å­¸åç¢æ¥­çä¸­ç¢çäºéå¤§çæå¾ï¼å çºå®ææ½åé©æ°éç®æ¨¡å¼ãçºäºäºè§£éç¨®æ½åï¼æ¬ææ¢è¨äºå°ç¥è­å³è¼¸æè¡ï¼å³çµ±ä¸ç¨æ¼å¤å¸äººå·¥æºæ§ï¼æ´åå°éå­éç®ä¸­çæ¹æ³ãæåæåºäºå³è¼¸æ¨¡åçå¨é¢åé¡ï¼éé»å¨æ¼é·ç§»å­¸ç¿åé·ç§»æä½³åãæ­¤å¤ï¼æååæäºéå­éç®ä¸­å¯ä»¥å¾ç¥è­å±äº«ä¸­åççç¸å³æ¹æ¡ï¼ä¸¦æ·±å¥æ¢è¨äºç±çè«è¦è§£ååæ­¥å¯¦é©çµææ¯æçæ½å¨ååææãæåçç ç©¶çµæè¡¨æï¼å©ç¨ç¥è­å³è¼¸å¯ä»¥æé«éå­æ¼ç®æ³çæçåæè½ï¼ç¹å¥æ¯å¨æ··åæ±è§£å¨çèæ¯ä¸ãéç¨®æ¹æ³ä¸åå éäºæä½³åæµç¨ï¼éæ¸è¼äºéå­èçå¨çéç®è² æï¼ä½¿å¶æçºæ¨é²éå­éç®æè¡çå¯¶è²´å·¥å·ã

##### **Autonomous Structural Memory Manipulation for Large Language Models Using Hierarchical Embedding Augmentation**
2501.14119v1 by Derek Yotheringhay, Alistair Kirkland, Humphrey Kirkbride, Josiah Whitesteeple

Transformative innovations in model architectures have introduced
hierarchical embedding augmentation as a means to redefine the representation
of tokens through multi-level semantic structures, offering enhanced
adaptability to complex linguistic inputs. Autonomous structural memory
manipulation further advances this paradigm through dynamic memory reallocation
mechanisms that prioritize critical contextual features while suppressing less
relevant information, enabling scalable and efficient performance across
diverse tasks. Experimental results reveal substantial improvements in
computational efficiency, with marked reductions in processing overhead for
longer input sequences, achieved through memory reorganization strategies that
adapt to evolving contextual requirements. Hierarchical embeddings not only
improved contextual alignment but also facilitated task generalization by
capturing relationships at varying semantic granularities, ensuring coherence
across layers without introducing significant computational redundancies.
Comparative analysis against baseline models demonstrated unique advantages in
accuracy, efficiency, and interpretability, particularly in tasks requiring
complex contextual understanding or domain-specific adaptability. The ability
to dynamically adjust token representations and memory configurations
contributed to the model's robustness under varied and unpredictable input
conditions. Applications benefiting from these advancements include
multi-domain generalization, interactive systems, and scenarios involving
real-time decision-making, where traditional static memory architectures often
face limitations. The proposed methodology combines advanced embedding and
memory management strategies into a cohesive framework that addresses
scalability challenges while preserving task-specific relevance.

æè¦ï¼æ¨¡åæ¶æ§çè½ååµæ°å¼å¥äºåå±¤åµå¥æ´åï¼ä½çºééå¤å±¤èªç¾©çµæ§éæ°å®ç¾©ç¬¦èè¡¨å¾µçæ¹æ³ï¼æä¾å¢å¼·çè¤éèªè¨è¼¸å¥é©ææ§ãèªé«çµæ§è¨æ¶æä½é²ä¸æ­¥ééåæè¨æ¶éæ°éç½®æ©å¶æ¨é²æ­¤ç¯ä¾ï¼æ­¤æ©å¶åªåèçééµçèçµ¡ç¹å¾µï¼åææå¶è¼ä¸ç¸éçè³è¨ï¼è®è·¨ä¸åä»»åçæè½å·åå¯æ´åæ§åæçãå¯¦é©çµæé¡¯ç¤ºå¨éç®æçæ¹é¢æå¤§å¹é²æ­¥ï¼ééé©æä¸æ·è®åçèçµ¡éæ±çè¨æ¶éçµç­ç¥ï¼å¤§å¹æ¸å°è¼é·è¼¸å¥åºåçèçè² æãåå±¤åµå¥ä¸åæ¹åèçµ¡å°é½ï¼ä¹ééæ·åä¸åèªç¾©ç²åº¦çéä¿ä¾ä¿é²ä»»åæ¦åï¼ç¢ºä¿è·¨å±¤æ¬¡çä¸è´æ§ï¼åæä¸æå¼å¥é¡¯èçéç®åé¤ãèåºæºæ¨¡åçæ¯è¼åæè­æäºå¨æºç¢ºåº¦ãæçåå¯è§£éæ§æ¹é¢æç¨ç¹çåªå¢ï¼ç¹å¥æ¯å¨éè¦è¤éèçµ¡çè§£æç¹å®é åé©ææ§çä»»åä¸­ãåæèª¿æ´ç¬¦èè¡¨å¾µåè¨æ¶çµæçè½åæå©æ¼æ¨¡åå¨è®åå¤ç«¯ä¸ç¡æ³é æ¸¬çè¼¸å¥æ¢ä»¶ä¸å±ç¾ç©©å¥æ§ãå¾éäºé²å±ä¸­åççæç¨åæ¬å¤é åæ¦åãäºåå¼ç³»çµ±ï¼ä»¥åæ¶åå³ææ±ºç­çå ´æ¯ï¼å¨éäºå ´æ¯ä¸­ï¼å³çµ±çéæè¨æ¶æ¶æ§ç¶å¸¸æé¢è¨éå¶ãææåºçæ¹æ³å°é²éåµå¥åè¨æ¶ç®¡çç­ç¥çµåå°ä¸åç·å¯çæ¶æ§ä¸­ï¼æ­¤æ¶æ§è§£æ±ºäºå¯æ´åæ§ææ°ï¼åæä¿çäºç¹å®ä»»åç¸éæ§ã

##### **LeCoPCR: Legal Concept-guided Prior Case Retrieval for European Court of Human Rights cases**
2501.14114v1 by T. Y. S. S. Santosh, Isaac Misael OlguÃ­n Nolasco, Matthias Grabmair

Prior case retrieval (PCR) is crucial for legal practitioners to find
relevant precedent cases given the facts of a query case. Existing approaches
often overlook the underlying semantic intent in determining relevance with
respect to the query case. In this work, we propose LeCoPCR, a novel approach
that explicitly generate intents in the form of legal concepts from a given
query case facts and then augments the query with these concepts to enhance
models understanding of semantic intent that dictates relavance. To overcome
the unavailability of annotated legal concepts, we employ a weak supervision
approach to extract key legal concepts from the reasoning section using
Determinantal Point Process (DPP) to balance quality and diversity.
Experimental results on the ECtHR-PCR dataset demonstrate the effectiveness of
leveraging legal concepts and DPP-based key concept extraction.

æè¦ï¼åä¾æª¢ç´¢ (PCR) å°æ³å¾å¾æ¥­äººå¡èè¨è³ééè¦ï¼è½æ ¹ææ¥è©¢æ¡ä¾çäºå¯¦æ¾å°ç¸éçå¤ä¾ãç¾ææ¹æ³å¨ç¢ºå®èæ¥è©¢æ¡ä¾ç¸éæ§æï¼ç¶å¸¸å¿½ç¥åºç¤èªææåãå¨éé å·¥ä½ä¸­ï¼æåæåº LeCoPCRï¼ä¸ç¨®åµæ°çæ¹æ³ï¼è½å¾çµ¦å®çæ¥è©¢æ¡ä¾äºå¯¦ä¸­ä»¥æ³å¾æ¦å¿µçå½¢å¼æç¢ºç¢çæåï¼ç¶å¾ä½¿ç¨éäºæ¦å¿µæ´åæ¥è©¢ï¼ä»¥å¢å¼·æ¨¡åå°èªææåççè§£ï¼èèªææåæ±ºå®äºç¸éæ§ãçºäºåææ¨è¨»æ³å¾æ¦å¿µçä¸å¯ç¨æ§ï¼æåæ¡ç¨å¼±ç£ç£æ¹æ³ï¼ä½¿ç¨è¡åå¼é»éç¨ (DPP) å¾æ¨çé¨åä¸­èåééµæ³å¾æ¦å¿µï¼ä»¥å¹³è¡¡åè³ªåå¤æ¨£æ§ãå¨ ECtHR-PCR è³æéä¸çå¯¦é©çµæè­æäºå©ç¨æ³å¾æ¦å¿µååºæ¼ DPP çééµæ¦å¿µèåçæææ§ã

##### **RELexED: Retrieval-Enhanced Legal Summarization with Exemplar Diversity**
2501.14113v1 by T. Y. S. S. Santosh, Chen Jia, Patrick Goroncy, Matthias Grabmair

This paper addresses the task of legal summarization, which involves
distilling complex legal documents into concise, coherent summaries. Current
approaches often struggle with content theme deviation and inconsistent writing
styles due to their reliance solely on source documents. We propose RELexED, a
retrieval-augmented framework that utilizes exemplar summaries along with the
source document to guide the model. RELexED employs a two-stage exemplar
selection strategy, leveraging a determinantal point process to balance the
trade-off between similarity of exemplars to the query and diversity among
exemplars, with scores computed via influence functions. Experimental results
on two legal summarization datasets demonstrate that RELexED significantly
outperforms models that do not utilize exemplars and those that rely solely on
similarity-based exemplar selection.

æè¦ï¼æ¬ææ¢è¨æ³å¾æè¦ä»»åï¼éæ¶åå°è¤éçæ³å¾æä»¶ç°¡åçºç°¡æ½ãé£è²«çæè¦ãç®åçåæ³éå¸¸æå éåº¦ä¾è³´åå§æä»¶èå°è´å§å®¹ä¸»é¡åé¢åå¯«ä½é¢¨æ ¼ä¸ä¸è´ãæåæåº RELexEDï¼ä¸åæª¢ç´¢å¢å¼·æ¡æ¶ï¼å®å©ç¨ç¯ä¾æè¦ååå§æä»¶ä¾æå°æ¨¡åãRELexED ä½¿ç¨å©éæ®µç¯ä¾é¸æç­ç¥ï¼å©ç¨è¡åå¼é»éç¨ä¾å¹³è¡¡ç¯ä¾èæ¥è©¢çç¸ä¼¼æ§èç¯ä¾ä¹éçå¤æ¨£æ§ï¼ä¸¦ééå½±é¿å½æ¸è¨ç®åæ¸ãå¨å©åæ³å¾æè¦è³æéä¸çå¯¦é©çµæè¡¨æï¼RELexED æé¡¯åªæ¼ä¸ä½¿ç¨ç¯ä¾çæ¨¡åååä¾è³´åºæ¼ç¸ä¼¼æ§çç¯ä¾é¸æçæ¨¡åã

##### **CoPERLex: Content Planning with Event-based Representations for Legal Case Summarization**
2501.14112v1 by T. Y. S. S. Santosh, Youssef Farag, Matthias Grabmair

Legal professionals often struggle with lengthy judgments and require
efficient summarization for quick comprehension. To address this challenge, we
investigate the need for structured planning in legal case summarization,
particularly through event-centric representations that reflect the narrative
nature of legal case documents. We propose our framework, CoPERLex, which
operates in three stages: first, it performs content selection to identify
crucial information from the judgment; second, the selected content is utilized
to generate intermediate plans through event-centric representations modeled as
Subject-Verb-Object tuples; and finally, it generates coherent summaries based
on both the content and the structured plan. Our experiments on four legal
summarization datasets demonstrate the effectiveness of integrating content
selection and planning components, highlighting the advantages of event-centric
plans over traditional entity-centric approaches in the context of legal
judgements.

æè¦ï¼æ³å¾å°æ¥­äººå£«å¸¸å¸¸çºåé·çå¤æ±ºæ¸æè¦ï¼éè¦ææççæè¦ä»¥å¿«éçè§£ãçºäºæå°éåææ°ï¼æåæ¢è¨æ³å¾æ¡ä¾æè¦ä¸­çµæ§åè¦åçå¿è¦æ§ï¼ç¹å¥æ¯ééä»¥äºä»¶çºä¸­å¿çè¡¨è¿°ï¼åæ æ³å¾æ¡ä¾æä»¶çæäºæ§è³ªãæåæåºæåçæ¶æ§ CoPERLexï¼å®åä¸åéæ®µéä½ï¼é¦åï¼å®å·è¡å§å®¹é¸æä»¥è­å¥å¤æ±ºæ¸ä¸­çééµè³è¨ï¼å¶æ¬¡ï¼é¸å®çå§å®¹ç¨æ¼ééå»ºæ¨¡çºãä¸»è©-åè©-åè©ãçµçä»¥äºä»¶çºä¸­å¿çè¡¨è¿°ä¾ç¢çä¸­éè¨ç«ï¼æå¾ï¼å®æ ¹æå§å®¹åçµæ§åè¨ç«ç¢çé£è²«çæè¦ãæåå°ååæ³å¾æè¦è³æéçå¯¦é©è­æäºæ´åå§å®¹é¸æåè¦åçµä»¶çæææ§ï¼çªé¡¯äºä»¥äºä»¶çºä¸­å¿çè¨ç«å¨æ³å¾å¤æ±ºçèæ¯ä¸åªæ¼å³çµ±ä»¥å¯¦é«çºä¸­å¿çéå¾ã

##### **MedSlice: Fine-Tuned Large Language Models for Secure Clinical Note Sectioning**
2501.14105v1 by Joshua Davis, Thomas Sounack, Kate Sciacca, Jessie M Brain, Brigitte N Durieux, Nicole D Agaronnik, Charlotta Lindvall

Extracting sections from clinical notes is crucial for downstream analysis
but is challenging due to variability in formatting and labor-intensive nature
of manual sectioning. While proprietary large language models (LLMs) have shown
promise, privacy concerns limit their accessibility. This study develops a
pipeline for automated note sectioning using open-source LLMs, focusing on
three sections: History of Present Illness, Interval History, and Assessment
and Plan. We fine-tuned three open-source LLMs to extract sections using a
curated dataset of 487 progress notes, comparing results relative to
proprietary models (GPT-4o, GPT-4o mini). Internal and external validity were
assessed via precision, recall and F1 score. Fine-tuned Llama 3.1 8B
outperformed GPT-4o (F1=0.92). On the external validity test set, performance
remained high (F1= 0.85). Fine-tuned open-source LLMs can surpass proprietary
models in clinical note sectioning, offering advantages in cost, performance,
and accessibility.

æè¦ï¼å¾è¨åºè¨éä¸­èååå¡å°æ¼ä¸æ¸¸åæè³ééè¦ï¼ä½ç±æ¼æ ¼å¼è®ç°åæåååçååå¯éæ§è³ªï¼éæ¯ä¸é ææ°ãå°æå¤§åèªè¨æ¨¡å (LLM) å·²å±ç¾æ½åï¼ä½é±ç§åé¡éå¶äºå¶å¯åæ§ãæ¬ç ç©¶éç¼äºä¸åä½¿ç¨éæ¾åå§ç¢¼ LLM çèªååè¨éååç®¡ç·ï¼å°æ³¨æ¼ä¸ååå¡ï¼ç¾çå²ãééçå²ä»¥åè©ä¼°åè¨ç«ãæåå¾®èª¿äºä¸åéæ¾åå§ç¢¼ LLM ä»¥ä½¿ç¨ 487 åé²åº¦è¨éçç²¾é¸è³æéèååå¡ï¼ä¸¦å°çµæèå°ææ¨¡å (GPT-4oãGPT-4o mini) é²è¡æ¯è¼ãå§é¨åå¤é¨æåº¦ééæºç¢ºåº¦ãå¬åçå F1 åæ¸é²è¡è©ä¼°ãå¾®èª¿å¾ç Llama 3.1 8B åªæ¼ GPT-4o (F1=0.92)ãå¨å¤é¨æåº¦æ¸¬è©¦éä¸­ï¼æè½ä»ç¶å¾é« (F1= 0.85)ãå¾®èª¿å¾çéæ¾åå§ç¢¼ LLM è½å¨è¨åºè¨éååä¸­è¶è¶å°ææ¨¡åï¼å¨ææ¬ãæè½åå¯åæ§æ¹é¢æä¾åªå¢ã

##### **Communicating Activations Between Language Model Agents**
2501.14082v1 by Vignav Ramesh, Kenneth Li

Communication between multiple language model (LM) agents has been shown to
scale up the reasoning ability of LMs. While natural language has been the
dominant medium for inter-LM communication, it is not obvious this should be
the standard: not only does natural language communication incur high inference
costs that scale quickly with the number of both agents and messages, but also
the decoding process abstracts away too much rich information that could be
otherwise accessed from the internal activations. In this work, we propose a
simple technique whereby LMs communicate via activations; concretely, we pause
an LM $\textit{B}$'s computation at an intermediate layer, combine its current
activation with another LM $\textit{A}$'s intermediate activation via some
function $\textit{f}$, then pass $\textit{f}$'s output into the next layer of
$\textit{B}$ and continue the forward pass till decoding is complete. This
approach scales up LMs on new tasks with zero additional parameters and data,
and saves a substantial amount of compute over natural language communication.
We test our method with various functional forms $\textit{f}$ on two
experimental setups--multi-player coordination games and reasoning
benchmarks--and find that it achieves up to $27.0\%$ improvement over natural
language communication across datasets with $<$$1/4$ the compute, illustrating
the superiority and robustness of activations as an alternative "language" for
communication between LMs.

æè¦ï¼å¤èªç³»èªè¨æ¨¡å (LM) ä»£çä¹éçæºéå·²è¢«è­å¯¦è½æå LM çæ¨çè½åãåç®¡èªç¶èªè¨ä¸ç´æ¯ LM éæºéçä¸»è¦åªä»ï¼ä½éä¸¦ä¸è¡¨ç¤ºèªç¶èªè¨çææçºæ¨æºï¼èªç¶èªè¨æºéä¸åæç¢çé«æçæ¨çææ¬ï¼ä¸ææ¬æé¨èä»£çåè¨æ¯æ¸éå¿«éå¢å ï¼èä¸è§£ç¢¼ç¨åºææ½è±¡åå¤ªå¤è±å¯çè³è¨ï¼å¦åéäºè³è¨å¯å¾å§é¨åç¨å­åãå¨éé ç ç©¶ä¸­ï¼æåæåºäºä¸ç¨®ç°¡å®çæè¡ï¼è® LM è½ééåç¨é²è¡æºéï¼å·é«ä¾èªªï¼æåæ«å LM $\textit{B}$ å¨ä¸­éå±¤çéç®ï¼ééå½æ¸ $\textit{f}$ å°å¶ç®åçåç¨èå¦ä¸å LM $\textit{A}$ çä¸­éåç¨çµåï¼ç¶å¾å° $\textit{f}$ çè¼¸åºå³éå° $\textit{B}$ çä¸ä¸å±¤ï¼ä¸¦ç¹¼çºé²è¡ååå³éï¼ç´å°è§£ç¢¼å®æãéç¨®æ¹æ³è½è® LM å¨æ°çä»»åä¸­æ´åï¼èç¡éé¡å¤çåæ¸åè³æï¼éè½æ¯èªç¶èªè¨æºéç¯çå¤§éçéç®éãæåå¨å©åå¯¦é©è¨­ç½®ï¼å¤ç©å®¶åèª¿éæ²åæ¨çåºæºï¼ä¸æ¸¬è©¦äºæåçåç¨®å½æ¸å½¢å¼ $\textit{f}$ï¼ç¼ç¾å®å¨è³æéä¸å¯¦ç¾äºæ¯èªç¶èªè¨æºéé«é $27.0\%$ çé²æ­¥ï¼éç®éå»ä¸å° $1/4$ï¼éèªªæäºåç¨ä½çº LM éæºéçå¦ä¸ç¨®ãèªè¨ãçåªè¶æ§åç©©å¥æ§ã

##### **Enhancing Biomedical Relation Extraction with Directionality**
2501.14079v1 by Po-Ting Lai, Chih-Hsuan Wei, Shubo Tian, Robert Leaman, Zhiyong Lu

Biological relation networks contain rich information for understanding the
biological mechanisms behind the relationship of entities such as genes,
proteins, diseases, and chemicals. The vast growth of biomedical literature
poses significant challenges updating the network knowledge. The recent
Biomedical Relation Extraction Dataset (BioRED) provides valuable manual
annotations, facilitating the develop-ment of machine-learning and pre-trained
language model approaches for automatically identifying novel document-level
(inter-sentence context) relationships. Nonetheless, its annotations lack
directionality (subject/object) for the entity roles, essential for studying
complex biological networks. Herein we annotate the entity roles of the
relationships in the BioRED corpus and subsequently propose a novel multi-task
language model with soft-prompt learning to jointly identify the relationship,
novel findings, and entity roles. Our results in-clude an enriched BioRED
corpus with 10,864 directionality annotations. Moreover, our proposed method
outperforms existing large language models such as the state-of-the-art GPT-4
and Llama-3 on two benchmarking tasks. Our source code and dataset are
available at https://github.com/ncbi-nlp/BioREDirect.

æè¦ï¼çç©éä¿ç¶²è·¯åå«è±å¯çè³è¨ï¼ç¨æ¼äºè§£åºå ãèç½è³ªãç¾çååå­¸ç©è³ªç­å¯¦é«éä¿èå¾ççç©æ©å¶ãçç©é«å­¸æç»çå¿«éæé·å°æ´æ°ç¶²è·¯ç¥è­æ§æéå¤§ææ°ãæè¿ççç©é«å­¸éä¿èåè³æé (BioRED) æä¾äºæå¹å¼çæåè¨»è§£ï¼ä¿é²äºæ©å¨å­¸ç¿åé åè¨ç·´èªè¨æ¨¡åæ¹æ³çç¼å±ï¼ç¨æ¼èªåè­å¥æ°çæä»¶å±¤ç´ï¼å¥å­éèçµ¡ï¼éä¿ãåç®¡å¦æ­¤ï¼å¶è¨»è§£ç¼ºä¹å¯¦é«è§è²çæ¹åæ§ï¼ä¸»è©/åè©ï¼ï¼éå°æ¼ç ç©¶è¤éççç©ç¶²è·¯è³ééè¦ãå¨æ­¤ï¼æåè¨»è§£äº BioRED èªæåº«ä¸­éä¿çå¯¦é«è§è²ï¼ä¸¦é¨å¾æåºäºä¸åæ°ç©çå¤ä»»åèªè¨æ¨¡åï¼æ¡ç¨è»æç¤ºå­¸ç¿ä¾è¯åè­å¥éä¿ãæ°ç¼ç¾åå¯¦é«è§è²ãæåççµæåæ¬ä¸åè±å¯ç BioRED èªæåº«ï¼å¶ä¸­åå« 10,864 åæ¹åæ§è¨»è§£ãæ­¤å¤ï¼æåæåºçæ¹æ³åªæ¼ç¾æçå¤§åèªè¨æ¨¡åï¼ä¾å¦æåé²ç GPT-4 å Llama-3ï¼å¨å©ååºæºä»»åä¸ãæåçåå§ç¢¼åè³æéå¯å¨ https://github.com/ncbi-nlp/BioREDirect åå¾ã

##### **LLMs are Vulnerable to Malicious Prompts Disguised as Scientific Language**
2501.14073v1 by Yubin Ge, Neeraja Kirtane, Hao Peng, Dilek Hakkani-TÃ¼r

As large language models (LLMs) have been deployed in various real-world
settings, concerns about the harm they may propagate have grown. Various
jailbreaking techniques have been developed to expose the vulnerabilities of
these models and improve their safety. This work reveals that many
state-of-the-art proprietary and open-source LLMs are vulnerable to malicious
requests hidden behind scientific language. Specifically, our experiments with
GPT4o, GPT4o-mini, GPT-4, LLama3-405B-Instruct, Llama3-70B-Instruct, Cohere,
Gemini models on the StereoSet data demonstrate that, the models' biases and
toxicity substantially increase when prompted with requests that deliberately
misinterpret social science and psychological studies as evidence supporting
the benefits of stereotypical biases. Alarmingly, these models can also be
manipulated to generate fabricated scientific arguments claiming that biases
are beneficial, which can be used by ill-intended actors to systematically
jailbreak even the strongest models like GPT. Our analysis studies various
factors that contribute to the models' vulnerabilities to malicious requests in
academic language. Mentioning author names and venues enhances the
persuasiveness of some models, and the bias scores can increase as dialogues
progress. Our findings call for a more careful investigation on the use of
scientific data in the training of LLMs.

æè¦ï¼é¨èå¤§åèªè¨æ¨¡å (LLM) å¨åç¨®çå¯¦ä¸çå ´æ¯ä¸­é¨ç½²ï¼äººåå°å¶å¯è½å³æ­çå±å®³çææä¹é¨ä¹å¢å ãå·²ç¶éç¼äºåç¨®è¶çæè¡ä¾æ­é²éäºæ¨¡åçæ¼æ´ä¸¦æé«å¶å®å¨æ§ãéé å·¥ä½æ­ç¤ºäºè¨±å¤æåé²çå°æåéæº LLM å®¹æåå°é±èå¨ç§å­¸èªè¨èå¾çæ¡æè«æ±çæ»æãå·é«ä¾èªªï¼æåå° StereoSet æ¸æä¸ç GPT4oãGPT4o-miniãGPT-4ãLLama3-405B-InstructãLlama3-70B-InstructãCohereãGemini æ¨¡åçå¯¦é©è¡¨æï¼ç¶ä½¿ç¨ææå°ç¤¾æç§å­¸åå¿çå­¸ç ç©¶èª¤è§£çºæ¯æå»æ¿å°è±¡åè¦å¥½èçè­æçè«æ±æï¼æ¨¡åçåè¦åæ¯æ§æå¤§å¹å¢å ãä»¤äººææçæ¯ï¼éäºæ¨¡åéå¯ä»¥è¢«æç¸±ä»¥ç¢çèåçç§å­¸è«æï¼è²ç¨±åè¦æ¯æççï¼éå¯ä»¥è¢«å¿æ·ä¸è»çäººç¨ä¾ç³»çµ±æ§å°è¶ççè³å GPT éæ¨£çæå¼·å¤§çæ¨¡åãæåçåæç ç©¶äºå°è´æ¨¡åå®¹æåå°å­¸è¡èªè¨ä¸­çæ¡æè«æ±æ»æçåç¨®å ç´ ãæåä½èå§ååå ´æ¯æå¢å¼·æäºæ¨¡åçèªªæåï¼ä¸¦ä¸é¨èå°è©±çé²è¡ï¼åè¦åæ¸å¯è½æå¢å ãæåçç ç©¶çµæè¦æ±å° LLM è¨ç·´ä¸­ç§å­¸æ¸æçä½¿ç¨é²è¡æ´ä»ç´°çèª¿æ¥ã

##### **Revisiting CLIP: Efficient Alignment of 3D MRI and Tabular Data using Domain-Specific Foundation Models**
2501.14051v1 by Jakob Krogh Petersen, Valdemar Licht, Mads Nielsen, AsbjÃ¸rn Munk

Multi-modal models require aligned, shared embedding spaces. However, common
CLIP-based approaches need large amounts of samples and do not natively support
3D or tabular data, both of which are crucial in the medical domain. To address
these issues, we revisit CLIP-style alignment by training a domain-specific 3D
foundation model as an image encoder and demonstrate that modality alignment is
feasible with only 62 MRI scans. Our approach is enabled by a simple embedding
accumulation strategy required for training in 3D, which scales the amount of
negative pairs across batches in order to stabilize training. We perform a
thorough evaluation of various design choices, including the choice of backbone
and loss functions, and evaluate the proposed methodology on zero-shot
classification and image-retrieval tasks. While zero-shot image-retrieval
remains challenging, zero-shot classification results demonstrate that the
proposed approach can meaningfully align the representations of 3D MRI with
tabular data.

æè¦ï¼å¤æ¨¡ææ¨¡åéè¦å°é½çå±ç¨åµå¥ç©ºéãç¶èï¼å¸¸è¦çåºæ¼ CLIP çæ¹æ³éè¦å¤§éçæ¨£æ¬ï¼ä¸¦ä¸åçä¸æ¯æ´ 3D æè¡¨æ ¼è³æï¼èéå©èå¨é«çé åä¸­é½è³ééè¦ãçºäºè§£æ±ºéäºåé¡ï¼æåééè¨ç·´ä¸åé åç¹å®ç 3D åºç¤æ¨¡åä½çºå½±åç·¨ç¢¼å¨ï¼éæ°æª¢è¦ CLIP é¢¨æ ¼çå°é½ï¼ä¸¦è­æåªè¦ 62 å MRI ææå³å¯éææ¨¡æå°é½ãæåçåæ³å¾çæ¼ä¸åç°¡å®çåµå¥ç´¯ç©ç­ç¥ï¼éæ¯ 3D è¨ç·´æå¿éçï¼å®æèª¿æ´æ¹æ¬¡ä¸­çè² å°æ¸éä»¥ç©©å®è¨ç·´ãæåå°åç¨®è¨­è¨é¸æé²è¡äºå¾¹åºçè©ä¼°ï¼åæ¬ä¸»å¹¹åæå¤±å½æ¸çé¸æï¼ä¸¦å¨é¶æ¨£æ¬åé¡åå½±åæª¢ç´¢ä»»åä¸è©ä¼°ææåºçæ¹æ³ãåç®¡é¶æ¨£æ¬å½±åæª¢ç´¢ä»ç¶å·æææ°æ§ï¼ä½é¶æ¨£æ¬åé¡çµæè­æï¼ææåºçæ¹æ³å¯ä»¥ææç¾©å°å° 3D MRI çè¡¨ç¤ºèè¡¨æ ¼è³æå°é½ã

##### **GraphRAG under Fire**
2501.14050v1 by Jiacheng Liang, Yuhui Wang, Changjiang Li, Rongyi Zhu, Tanqiu Jiang, Neil Gong, Ting Wang

GraphRAG advances retrieval-augmented generation (RAG) by structuring
external knowledge as multi-scale knowledge graphs, enabling language models to
integrate both broad context and granular details in their reasoning. While
GraphRAG has demonstrated success across domains, its security implications
remain largely unexplored. To bridge this gap, this work examines GraphRAG's
vulnerability to poisoning attacks, uncovering an intriguing security paradox:
compared to conventional RAG, GraphRAG's graph-based indexing and retrieval
enhance resilience against simple poisoning attacks; meanwhile, the same
features also create new attack surfaces. We present GRAGPoison, a novel attack
that exploits shared relations in the knowledge graph to craft poisoning text
capable of compromising multiple queries simultaneously. GRAGPoison employs
three key strategies: i) relation injection to introduce false knowledge, ii)
relation enhancement to amplify poisoning influence, and iii) narrative
generation to embed malicious content within coherent text. Empirical
evaluation across diverse datasets and models shows that GRAGPoison
substantially outperforms existing attacks in terms of effectiveness (up to 98%
success rate) and scalability (using less than 68% poisoning text). We also
explore potential defensive measures and their limitations, identifying
promising directions for future research.

æè¦ï¼GraphRAG ééå°å¤é¨ç¥è­çµæ§åçºå¤å°ºåº¦ç¥è­åè­ï¼æ¨åäºæª¢ç´¢å¢å¼·çæ (RAG)ï¼ä½¿èªè¨æ¨¡åè½å¤ å¨å¶æ¨çä¸­æ´åå»£æ³çèæ¯åç´°å¾®çç´°ç¯ãåç®¡ GraphRAG å¨ååé åé½å·²å±ç¾åºæåï¼ä½å¶å®å¨æ§å½±é¿å¨å¾å¤§ç¨åº¦ä¸ä»æªè¢«æ¢ç´¢ãçºäºå½è£éä¸å·®è·ï¼æ¬ç ç©¶æ¢è¨äº GraphRAG å°ææ¯æ»æçèå¼±æ§ï¼æ­ç¤ºäºä¸åæè¶£çå®å¨æè«ï¼èå³çµ±ç RAG ç¸æ¯ï¼GraphRAG åºæ¼åè¡¨çç´¢å¼åæª¢ç´¢å¢å¼·äºå°ç°¡å®ææ¯æ»æçéæ§ï¼åæï¼ç¸åçç¹å¾µä¹åµé äºæ°çæ»æé¢ãæåæåºäº GRAGPoisonï¼éæ¯ä¸ç¨®æ°ç©çæ»æï¼å®å©ç¨ç¥è­åè­ä¸­çå±äº«éä¿ä¾è£½ä½ä¸­æ¯ææ¬ï¼è½å¤ åæå±å®³å¤åæ¥è©¢ãGRAGPoison æ¡ç¨äºä¸é ééµç­ç¥ï¼i) éä¿æ³¨å¥ä»¥å¼å¥é¯èª¤çç¥è­ï¼ii) éä¿å¢å¼·ä»¥æ´å¤§ææ¯å½±é¿ï¼ä»¥å iii) æäºçæä»¥å°æ¡æå§å®¹åµå¥é£è²«çææ¬ä¸­ãå¨åç¨®æ¸æéåæ¨¡åä¸çç¶é©è©ä¼°è¡¨æï¼GRAGPoison å¨æææ§ï¼æåçé«é 98%ï¼åå¯æ´å±æ§ï¼ä½¿ç¨ä¸å° 68% çææ¯ææ¬ï¼æ¹é¢é½æé¡¯åªæ¼ç¾æçæ»æãæåéæ¢è¨äºæ½å¨çé²ç¦¦æªæ½åå¶å±éæ§ï¼ç¢ºå®äºæªä¾ç ç©¶çæå¸æçæ¹åã

##### **SIDDA: SInkhorn Dynamic Domain Adaptation for Image Classification with Equivariant Neural Networks**
2501.14048v1 by Sneh Pandya, Purvik Patel, Brian D. Nord, Mike Walmsley, Aleksandra ÄiprijanoviÄ

Modern neural networks (NNs) often do not generalize well in the presence of
a "covariate shift"; that is, in situations where the training and test data
distributions differ, but the conditional distribution of classification labels
remains unchanged. In such cases, NN generalization can be reduced to a problem
of learning more domain-invariant features. Domain adaptation (DA) methods
include a range of techniques aimed at achieving this; however, these methods
have struggled with the need for extensive hyperparameter tuning, which then
incurs significant computational costs. In this work, we introduce SIDDA, an
out-of-the-box DA training algorithm built upon the Sinkhorn divergence, that
can achieve effective domain alignment with minimal hyperparameter tuning and
computational overhead. We demonstrate the efficacy of our method on multiple
simulated and real datasets of varying complexity, including simple shapes,
handwritten digits, and real astronomical observations. SIDDA is compatible
with a variety of NN architectures, and it works particularly well in improving
classification accuracy and model calibration when paired with equivariant
neural networks (ENNs). We find that SIDDA enhances the generalization
capabilities of NNs, achieving up to a $\approx40\%$ improvement in
classification accuracy on unlabeled target data. We also study the efficacy of
DA on ENNs with respect to the varying group orders of the dihedral group
$D_N$, and find that the model performance improves as the degree of
equivariance increases. Finally, we find that SIDDA enhances model calibration
on both source and target data--achieving over an order of magnitude
improvement in the ECE and Brier score. SIDDA's versatility, combined with its
automated approach to domain alignment, has the potential to advance
multi-dataset studies by enabling the development of highly generalizable
models.

æè¦ï¼<paragraph>ç¾ä»£ç¥ç¶ç¶²è·¯ (NN) å¨åºç¾ãåè®ä½ç§»ãæéå¸¸ç¡æ³å¾å¥½å°æ¦åï¼ä¹å°±æ¯èªªï¼å¨è¨ç·´åæ¸¬è©¦è³æåä½ä¸åï¼ä½åé¡æ¨ç±¤çæ¢ä»¶åä½ä¿æä¸è®çææ³ä¸ãå¨éç¨®ææ³ä¸ï¼NN æ¦åå¯ä»¥ç°¡åçºå­¸ç¿æ´å¤é åä¸è®ç¹å¾µçåé¡ãé åé©æ (DA) æ¹æ³åæ¬ä¸ç³»åæ¨å¨å¯¦ç¾æ­¤ç®ççæè¡ï¼ç¶èï¼éäºæ¹æ³ä¸ç´é£ä»¥æ»¿è¶³å»£æ³çè¶åæ¸èª¿æ´éæ±ï¼éæç¢çå¤§éçéç®ææ¬ãå¨éé å·¥ä½ä¸­ï¼æåä»ç´¹äº SIDDAï¼ä¸ç¨®å»ºç«å¨è¾éæ©æ£åº¦ä¸çéç®±å³ç¨ DA è¨ç·´æ¼ç®æ³ï¼å®å¯ä»¥å¨æå°çè¶åæ¸èª¿æ´åéç®éé·ä¸å¯¦ç¾ææçé åå°é½ãæåå¨å¤åä¸åè¤éç¨åº¦çæ¨¡æ¬åçå¯¦è³æéä¸å±ç¤ºäºæåæ¹æ³çåæï¼åæ¬ç°¡å®å½¢çãæå¯«æ¸å­åçå¯¦çå¤©æè§æ¸¬ãSIDDA èåç¨® NN æ¶æ§ç¸å®¹ï¼ä¸¦ä¸å¨èç­è®ç¥ç¶ç¶²è·¯ (ENN) éå°æï¼ç¹å¥è½æ¹ååé¡æºç¢ºåº¦åæ¨¡åæ ¡æºãæåç¼ç¾ SIDDA å¢å¼·äº NN çæ¦åè½åï¼å¨æªæ¨è¨ç®æ¨è³æä¸çåé¡æºç¢ºåº¦æåäºç´ 40%ãæåéç ç©¶äº DA å° ENN çåæï¼ç¸å°æ¼äºé¢é«ç¾¤ $D_N$ çä¸åç¾¤éï¼æåç¼ç¾é¨èç­è®ç¨åº¦çå¢å ï¼æ¨¡åæè½ä¹ææåãæå¾ï¼æåç¼ç¾ SIDDA å¢å¼·äºä¾æºåç®æ¨è³æçæ¨¡åæ ¡æºï¼å¨ ECE åå¸è³´ç¾åæ¸ä¸ç²å¾äºæ¸éç´çæ¹é²ãSIDDA çå¤åè½æ§ï¼å ä¸å¶èªååçé åå°é½æ¹æ³ï¼ææ½åééä¿é²é«åº¦å¯æ¦åçæ¨¡åéç¼ï¼ä¾æ¨åå¤è³æéç ç©¶ã</paragraph>

##### **Leveraging Large Language Models to Analyze Emotional and Contextual Drivers of Teen Substance Use in Online Discussions**
2501.14037v1 by Jianfeng Zhu, Ruoming Jin, Hailong Jiang, Yulan Wang, Xinyu Zhang, Karin G. Coifman

Adolescence is a critical stage often linked to risky behaviors, including
substance use, with significant developmental and public health implications.
Social media provides a lens into adolescent self-expression, but interpreting
emotional and contextual signals remains complex. This study applies Large
Language Models (LLMs) to analyze adolescents' social media posts, uncovering
emotional patterns (e.g., sadness, guilt, fear, joy) and contextual factors
(e.g., family, peers, school) related to substance use. Heatmap and machine
learning analyses identified key predictors of substance use-related posts.
Negative emotions like sadness and guilt were significantly more frequent in
substance use contexts, with guilt acting as a protective factor, while shame
and peer influence heightened substance use risk. Joy was more common in
non-substance use discussions. Peer influence correlated strongly with sadness,
fear, and disgust, while family and school environments aligned with
non-substance use. Findings underscore the importance of addressing emotional
vulnerabilities and contextual influences, suggesting that collaborative
interventions involving families, schools, and communities can reduce risk
factors and foster healthier adolescent development.

æè¦ï¼éæ¥ææ¯èé¢¨éªè¡çºï¼åæ¬ç©è³ªä½¿ç¨ï¼å¸¸æéè¯çééµéæ®µï¼å°ç¼å±åå¬å±è¡çå·æéå¤§å½±é¿ã
ç¤¾ç¾¤åªé«æä¾äºä¸åè§å¯éå°å¹´èªæè¡¨éçè¦è§ï¼ä½è§£è®æç·åèçµ¡ä¿¡èä»ç¶å¾è¤éãæ¬ç ç©¶æ¡ç¨å¤§åèªè¨æ¨¡åï¼LLMï¼ä¾åæéå°å¹´çç¤¾ç¾¤åªé«è²¼æï¼æ­é²èç©è³ªä½¿ç¨ç¸éçæç·æ¨¡å¼ï¼ä¾å¦ï¼æ²å·ãç½ªæ¡æãææ¼ãå¿«æ¨ï¼åèçµ¡å ç´ ï¼ä¾å¦ï¼å®¶åº­ãååãå­¸æ ¡ï¼ãç±é»ååæ©å¨å­¸ç¿åææ¾åºç©è³ªä½¿ç¨ç¸éè²¼æçééµé æ¸¬å å­ãå¨ç©è³ªä½¿ç¨èçµ¡ä¸­ï¼æ²å·åç½ªæ¡æç­è² é¢æç·é¡¯èæ´é »ç¹ï¼ç½ªæ¡æå·æä¿è­·ä½ç¨ï¼èç¾æ¥æåååå½±é¿åæå¢å ç©è³ªä½¿ç¨é¢¨éªãå¨éç©è³ªä½¿ç¨è¨è«ä¸­ï¼å¿«æ¨æ´çºå¸¸è¦ãååå½±é¿èæ²å·ãææ¼åå­æ¡å¯åç¸éï¼èå®¶åº­åå­¸æ ¡ç°å¢åèéç©è³ªä½¿ç¨ä¸è´ãç ç©¶çµæå¼·èª¿äºèçæç·èå¼±æ§åèçµ¡å½±é¿çéè¦æ§ï¼ä¸¦è¡¨ææ¶åå®¶åº­ãå­¸æ ¡åç¤¾åçåä½å¹²é å¯ä»¥éä½é¢¨éªå ç´ ï¼ä¸¦ä¿é²æ´å¥åº·çéå°å¹´ç¼å±ã

##### **Human-Alignment Influences the Utility of AI-assisted Decision Making**
2501.14035v1 by Nina L. Corvelo Benz, Manuel Gomez Rodriguez

Whenever an AI model is used to predict a relevant (binary) outcome in
AI-assisted decision making, it is widely agreed that, together with each
prediction, the model should provide an AI confidence value. However, it has
been unclear why decision makers have often difficulties to develop a good
sense on when to trust a prediction using AI confidence values. Very recently,
Corvelo Benz and Gomez Rodriguez have argued that, for rational decision
makers, the utility of AI-assisted decision making is inherently bounded by the
degree of alignment between the AI confidence values and the decision maker's
confidence on their own predictions. In this work, we empirically investigate
to what extent the degree of alignment actually influences the utility of
AI-assisted decision making. To this end, we design and run a large-scale human
subject study (n=703) where participants solve a simple decision making task -
an online card game - assisted by an AI model with a steerable degree of
alignment. Our results show a positive association between the degree of
alignment and the utility of AI-assisted decision making. In addition, our
results also show that post-processing the AI confidence values to achieve
multicalibration with respect to the participants' confidence on their own
predictions increases both the degree of alignment and the utility of
AI-assisted decision making.

æè¦ï¼æ¯ç¶ AI æ¨¡åç¨æ¼é æ¸¬ AI è¼å©æ±ºç­ä¸­çç¸éï¼äºåï¼çµææï¼äººåæ®éåæï¼é¤äºæ¯åé æ¸¬å¤ï¼æ¨¡åéææä¾ AI ä¿¡å¿å¼ãç¶èï¼ä¸ç´ä¸æ¸æ¥çºä½æ±ºç­èç¶å¸¸é£ä»¥å¹é¤å¨ä½æä½¿ç¨ AI ä¿¡å¿å¼ä¾ä¿¡ä»»é æ¸¬çè¯å¥½æè­ãæè¿ï¼Corvelo Benz å Gomez Rodriguez æåºï¼å°æ¼çæ§æ±ºç­èèè¨ï¼AI è¼å©æ±ºç­çæç¨æ¬è³ªä¸åéæ¼ AI ä¿¡å¿å¼èæ±ºç­èå°èªå·±é æ¸¬çä¿¡å¿ä¹éçä¸è´æ§ç¨åº¦ãå¨éé å·¥ä½ä¸­ï¼æåå¯¦è­ç ç©¶äºä¸è´æ§ç¨åº¦å¯¦éä¸å¨å¤å¤§ç¨åº¦ä¸å½±é¿ AI è¼å©æ±ºç­çæç¨ãçºæ­¤ï¼æåè¨­è¨ä¸¦å·è¡äºä¸é å¤§è¦æ¨¡çäººé¡åè©¦èç ç©¶ï¼n=703ï¼ï¼åèèå¨ AI æ¨¡åçåå©ä¸è§£æ±ºä¸åç°¡å®çæ±ºç­ä»»åââä¸æ¬¾ç·ä¸ç´çéæ²ï¼å¶ä¸­ AI æ¨¡åçä¸è´æ§ç¨åº¦å¯æ§ãæåççµæé¡¯ç¤ºä¸è´æ§ç¨åº¦è AI è¼å©æ±ºç­çæç¨ä¹éå­å¨æ­£ç¸éãæ­¤å¤ï¼æåççµæéé¡¯ç¤ºï¼å° AI ä¿¡å¿å¼é²è¡å¾èçä»¥å¯¦ç¾ç¸å°æ¼åèèå°èªå·±é æ¸¬çä¿¡å¿çå¤æ ¡æºï¼æ¢è½æé«ä¸è´æ§ç¨åº¦ï¼åè½æé« AI è¼å©æ±ºç­çæç¨ã

##### **CRPO: Confidence-Reward Driven Preference Optimization for Machine Translation**
2501.13927v1 by Guofeng Cui, Pichao Wang, Yang Liu, Zemian Ke, Zhu Liu, Vimal Bhat

Large language models (LLMs) have shown great potential in natural language
processing tasks, but their application to machine translation (MT) remains
challenging due to pretraining on English-centric data and the complexity of
reinforcement learning from human feedback (RLHF). Direct Preference
Optimization (DPO) has emerged as a simpler and more efficient alternative, but
its performance depends heavily on the quality of preference data. To address
this, we propose Confidence-Reward driven Preference Optimization (CRPO), a
novel method that combines reward scores with model confidence to improve data
selection for fine-tuning. CRPO selects challenging sentence pairs where the
model is uncertain or underperforms, leading to more effective learning. While
primarily designed for LLMs, CRPO also generalizes to encoder-decoder models
like NLLB, demonstrating its versatility. Empirical results show that CRPO
outperforms existing methods such as RS-DPO, RSO and MBR score in both
translation accuracy and data efficiency.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å¨èªç¶èªè¨èçä»»åä¸­å±ç¾åºæ¥µå¤§çæ½åï¼ä½ç±æ¼é è¨ç·´æä»¥è±èªçºä¸­å¿è³æï¼ä»¥åå¾äººé¡åé¥ä¸­é²è¡å¼·åå­¸ç¿çè¤éæ§ï¼å¶å¨æ©å¨ç¿»è­¯ (MT) ä¸­çæç¨ä»ç¶å·æææ°æ§ãç´æ¥åå¥½æä½³å (DPO) å·²æçºä¸ç¨®æ´ç°¡å®ä¸æ´ææççæ¿ä»£æ¹æ¡ï¼ä½å¶æè½é«åº¦ä¾è³´æ¼åå¥½è³æçåè³ªãçºäºè§£æ±ºæ­¤åé¡ï¼æåæåºä»¥ä¿¡å¿çåµçºé©ååçåå¥½æä½³å (CRPO)ï¼éæ¯ä¸ç¨®çµåçåµåæ¸èæ¨¡åä¿¡å¿çæ°æ¹æ³ï¼ä»¥æ¹åå¾®èª¿çè³æé¸åãCRPO é¸ææ¨¡åä¸ç¢ºå®æè¡¨ç¾ä¸ä½³çå·ææ°æ§å¥å­å°ï¼é²èå¸¶ä¾æ´ææçå­¸ç¿ãåç®¡ CRPO ä¸»è¦è¨­è¨ç¨æ¼ LLMï¼ä½å®ä¹é©ç¨æ¼ç·¨ç¢¼å¨-è§£ç¢¼å¨æ¨¡åï¼ä¾å¦ NLLBï¼è­æäºå¶å¤åè½æ§ãå¯¦è­çµæé¡¯ç¤ºï¼CRPO å¨ç¿»è­¯æºç¢ºåº¦åè³ææçæ¹é¢ååªæ¼ç¾ææ¹æ³ï¼ä¾å¦ RS-DPOãRSO å MBR åæ¸ã

##### **Can We Generate Images with CoT? Let's Verify and Reinforce Image Generation Step by Step**
2501.13926v1 by Ziyu Guo, Renrui Zhang, Chengzhuo Tong, Zhizheng Zhao, Peng Gao, Hongsheng Li, Pheng-Ann Heng

Chain-of-Thought (CoT) reasoning has been extensively explored in large
models to tackle complex understanding tasks. However, it still remains an open
question whether such strategies can be applied to verifying and reinforcing
image generation scenarios. In this paper, we provide the first comprehensive
investigation of the potential of CoT reasoning to enhance autoregressive image
generation. We focus on three techniques: scaling test-time computation for
verification, aligning model preferences with Direct Preference Optimization
(DPO), and integrating these techniques for complementary effects. Our results
demonstrate that these approaches can be effectively adapted and combined to
significantly improve image generation performance. Furthermore, given the
pivotal role of reward models in our findings, we propose the Potential
Assessment Reward Model (PARM) and PARM++, specialized for autoregressive image
generation. PARM adaptively assesses each generation step through a potential
assessment approach, merging the strengths of existing reward models, and
PARM++ further introduces a reflection mechanism to self-correct the generated
unsatisfactory image. Using our investigated reasoning strategies, we enhance a
baseline model, Show-o, to achieve superior results, with a significant +24%
improvement on the GenEval benchmark, surpassing Stable Diffusion 3 by +15%. We
hope our study provides unique insights and paves a new path for integrating
CoT reasoning with autoregressive image generation. Code and models are
released at https://github.com/ZiyuGuo99/Image-Generation-CoT

æè¦ï¼<paragraph>éå¼æè (CoT) æ¨çå·²è¢«å»£æ³å°æ¢ç´¢æ¼å¤§åæ¨¡åä¸­ï¼ä»¥è§£æ±ºè¤éççè§£ä»»åãç¶èï¼æ­¤é¡ç­ç¥æ¯å¦è½æç¨æ¼é©è­åå¼·åå½±åçæå ´æ¯ï¼ä»æ¯ä¸åéæ¾æ§çåé¡ãå¨æ¬æä¸­ï¼æåæä¾äºç¬¬ä¸åéæ¼ CoT æ¨çæ½åç¨æ¼å¢å¼·èªè¿´æ­¸å½±åçæçå¨é¢èª¿æ¥ãæåå°æ³¨æ¼ä¸ç¨®æè¡ï¼æ´å±æ¸¬è©¦æééç®ä»¥é²è¡é©è­ãå°æ¨¡ååå¥½èç´æ¥åå¥½æä½³å (DPO) å°é½ï¼ä»¥åæ´åéäºæè¡ä»¥ç¢çäºè£ææãæåççµæè­æï¼éäºæ¹æ³å¯ä»¥ææå°é©æä¸¦çµåï¼ä»¥é¡¯èæ¹åå½±åçææè½ãæ­¤å¤ï¼éæ¼çåµæ¨¡åå¨æåçç¼ç¾ä¸­æ®æ¼èééµè§è²ï¼æåæåºäºæ½åè©ä¼°çåµæ¨¡å (PARM) å PARM++ï¼å°éç¨æ¼èªè¿´æ­¸å½±åçæãPARM ééæ½åè©ä¼°æ¹æ³èªé©æå°è©ä¼°æ¯åçææ­¥é©ï¼åä½µç¾æçåµæ¨¡åçåªé»ï¼è PARM++ é²ä¸æ­¥å¼å¥åå°æ©å¶ä¾èªæä¿®æ­£çæçä»¤äººä¸æ»¿æçå½±åãä½¿ç¨æåèª¿æ¥çæ¨çç­ç¥ï¼æåå¢å¼·äºä¸ååºæºæ¨¡å Show-oï¼ä»¥åå¾åªç°ççµæï¼å¨ GenEval åºæºä¸é¡¯èæå +24%ï¼è¶è¶ Stable Diffusion 3 +15%ãæåå¸ææåçç ç©¶æä¾ç¨ç¹çè¦è§£ï¼ä¸¦çºå° CoT æ¨çèèªè¿´æ­¸å½±åçææ´åéé¢ä¸æ¢æ°éå¾ãç¨å¼ç¢¼åæ¨¡åå·²æ¼ https://github.com/ZiyuGuo99/Image-Generation-CoT ç¼å¸</paragraph>

##### **Towards Robust Multimodal Open-set Test-time Adaptation via Adaptive Entropy-aware Optimization**
2501.13924v1 by Hao Dong, Eleni Chatzi, Olga Fink

Test-time adaptation (TTA) has demonstrated significant potential in
addressing distribution shifts between training and testing data. Open-set
test-time adaptation (OSTTA) aims to adapt a source pre-trained model online to
an unlabeled target domain that contains unknown classes. This task becomes
more challenging when multiple modalities are involved. Existing methods have
primarily focused on unimodal OSTTA, often filtering out low-confidence samples
without addressing the complexities of multimodal data. In this work, we
present Adaptive Entropy-aware Optimization (AEO), a novel framework
specifically designed to tackle Multimodal Open-set Test-time Adaptation
(MM-OSTTA) for the first time. Our analysis shows that the entropy difference
between known and unknown samples in the target domain strongly correlates with
MM-OSTTA performance. To leverage this, we propose two key components:
Unknown-aware Adaptive Entropy Optimization (UAE) and Adaptive Modality
Prediction Discrepancy Optimization (AMP). These components enhance the ability
of model to distinguish unknown class samples during online adaptation by
amplifying the entropy difference between known and unknown samples. To
thoroughly evaluate our proposed methods in the MM-OSTTA setting, we establish
a new benchmark derived from existing datasets. This benchmark includes two
downstream tasks and incorporates five modalities. Extensive experiments across
various domain shift situations demonstrate the efficacy and versatility of the
AEO framework. Additionally, we highlight the strong performance of AEO in
long-term and continual MM-OSTTA settings, both of which are challenging and
highly relevant to real-world applications. Our source code is available at
https://github.com/donghao51/AEO.

æè¦ï¼<paragraph>æ¸¬è©¦æéé©æ (TTA) å·²å±ç¾åºå¨è§£æ±ºè¨ç·´è³æèæ¸¬è©¦è³æä¹éçåéè½ç§»ä¸å·æé¡¯èæ½åãéæ¾éæ¸¬è©¦æéé©æ (OSTTA) æ¨å¨å°ä¾æºé åè¨ç·´çæ¨¡åç·ä¸é©æå°åå«æªç¥é¡å¥çæªæ¨è¨ç®æ¨ç¶²åãç¶æ¶åå¤ç¨®æ¨¡å¼æï¼éé ä»»åå°è®å¾æ´å·ææ°æ§ãç¾ææ¹æ³ä¸»è¦éæ³¨æ¼å®æ¨¡æ OSTTAï¼éå¸¸æéæ¿¾æä½ä¿¡å¿æ¨£æ¬ï¼èä¸æè§£æ±ºå¤æ¨¡æè³æçè¤éæ§ãå¨éé å·¥ä½ä¸­ï¼æåæåºèªé©æçµæç¥æä½³å (AEO)ï¼éæ¯ä¸åæ°ç©çæ¶æ§ï¼å°éè¨­è¨ä¾é¦æ¬¡èçå¤æ¨¡æéæ¾éæ¸¬è©¦æéé©æ (MM-OSTTA)ãæåçåæé¡¯ç¤ºï¼ç®æ¨ç¶²åä¸­å·²ç¥åæªç¥æ¨£æ¬ä¹éççµå·®ç°è MM-OSTTA æè½å¯åç¸éãçºäºå©ç¨éä¸é»ï¼æåæåºäºå©åééµçµæé¨åï¼æªç¥æç¥èªé©æçµæä½³å (UAE) åèªé©ææ¨¡å¼é æ¸¬å·®ç°æä½³å (AMP)ãéäºçµæé¨åå¢å¼·äºæ¨¡åå¨ç·ä¸é©ææéååæªç¥é¡å¥æ¨£æ¬çè½åï¼æ¹æ³æ¯æ´å¤§å·²ç¥åæªç¥æ¨£æ¬ä¹éççµå·®ç°ãçºäºå¨ MM-OSTTA è¨­å®ä¸­å¾¹åºè©ä¼°æåæåºçæ¹æ³ï¼æåå»ºç«äºä¸åæºèªç¾æè³æéçæ°åºæºãæ­¤åºæºåå«å©åä¸æ¸¸ä»»åä¸¦ç´å¥äºäºç¨®æ¨¡å¼ãå¨åç¨®é åè½ç§»ææ³ä¸çå»£æ³å¯¦é©è­æäº AEO æ¶æ§çæè½åå¤åè½æ§ãæ­¤å¤ï¼æåå¼·èª¿äº AEO å¨é·æåæçºç MM-OSTTA è¨­å®ä¸­çå¼·åæè½ï¼éå©èé½å·æææ°æ§ï¼ä¸¦ä¸èå¯¦éæç¨é«åº¦ç¸éãæåçåå§ç¢¼å¯å¨ https://github.com/donghao51/AEO åå¾ã</paragraph>

##### **The Breeze 2 Herd of Models: Traditional Chinese LLMs Based on Llama with Vision-Aware and Function-Calling Capabilities**
2501.13921v1 by Chan-Jan Hsu, Chia-Sheng Liu, Meng-Hsi Chen, Muxi Chen, Po-Chun Hsu, Yi-Chang Chen, Da-Shan Shiu

Breeze 2 is a suite of advanced multi-modal language models, available in 3B
and 8B parameter configurations, specifically designed to enhance Traditional
Chinese language representation. Building upon the Llama 3, Breeze 2 continues
pretraining on an extensive corpus to enhance the linguistic and cultural
heritage of Traditional Chinese. It incorporates vision-aware capabilities
through a visual encoder and a bridge module, and supports function-calling via
prompt templates and post-training on function-calling data. The effectiveness
of Breeze 2 is benchmarked across various tasks, including Taiwan general
knowledge, instruction-following, long context, function calling, and vision
understanding. Furthermore, we showcase the capabilities of the its 3B model in
a mobile application. We are publicly releasing all Breeze 2 models under the
Llama 3 Community License.

æè¦ï¼Breeze 2 æ¯ä¸å¥é²éçå¤æ¨¡æèªè¨æ¨¡åï¼æä¾ 3B å 8B åæ¸éç½®ï¼å°éè¨­è¨ç¨æ¼å¢å¼·ç¹é«ä¸­æèªè¨è¡¨ç¤ºãBreeze 2 å»ºç«å¨ Llama 3 çåºç¤ä¸ï¼æçºå¨å»£æ³çèªæåº«ä¸é²è¡é è¨ç·´ï¼ä»¥å¢å¼·ç¹é«ä¸­æçèªè¨åæåéºç¢ãå®ééè¦è¦ºç·¨ç¢¼å¨åæ©æ¥æ¨¡çµæ´åäºè¦è¦ºæç¥è½åï¼ä¸¦ééæç¤ºç¯æ¬ååè½å¼å«è³æçå¾çºè¨ç·´æ¯æ´åè½å¼å«ãBreeze 2 çæææ§å·²éå°åç¨®ä»»åé²è¡åºæºæ¸¬è©¦ï¼åæ¬å°ç£ä¸è¬ç¥è­ãéµå¾ªæç¤ºãé·ç¯èªå¢ãåè½å¼å«åè¦è¦ºçè§£ãæ­¤å¤ï¼æåå¨è¡åæç¨ç¨å¼ä¸­å±ç¤ºå¶ 3B æ¨¡åçåè½ãæåå¨ Llama 3 ç¤¾ç¾¤ææ¬ä¸å¬éç¼å¸ææ Breeze 2 æ¨¡åã

##### **IMAGINE-E: Image Generation Intelligence Evaluation of State-of-the-art Text-to-Image Models**
2501.13920v1 by Jiayi Lei, Renrui Zhang, Xiangfei Hu, Weifeng Lin, Zhen Li, Wenjian Sun, Ruoyi Du, Le Zhuo, Zhongyu Li, Xinyue Li, Shitian Zhao, Ziyu Guo, Yiting Lu, Peng Gao, Hongsheng Li

With the rapid development of diffusion models, text-to-image(T2I) models
have made significant progress, showcasing impressive abilities in prompt
following and image generation. Recently launched models such as FLUX.1 and
Ideogram2.0, along with others like Dall-E3 and Stable Diffusion 3, have
demonstrated exceptional performance across various complex tasks, raising
questions about whether T2I models are moving towards general-purpose
applicability. Beyond traditional image generation, these models exhibit
capabilities across a range of fields, including controllable generation, image
editing, video, audio, 3D, and motion generation, as well as computer vision
tasks like semantic segmentation and depth estimation. However, current
evaluation frameworks are insufficient to comprehensively assess these models'
performance across expanding domains. To thoroughly evaluate these models, we
developed the IMAGINE-E and tested six prominent models: FLUX.1, Ideogram2.0,
Midjourney, Dall-E3, Stable Diffusion 3, and Jimeng. Our evaluation is divided
into five key domains: structured output generation, realism, and physical
consistency, specific domain generation, challenging scenario generation, and
multi-style creation tasks. This comprehensive assessment highlights each
model's strengths and limitations, particularly the outstanding performance of
FLUX.1 and Ideogram2.0 in structured and specific domain tasks, underscoring
the expanding applications and potential of T2I models as foundational AI
tools. This study provides valuable insights into the current state and future
trajectory of T2I models as they evolve towards general-purpose usability.
Evaluation scripts will be released at https://github.com/jylei16/Imagine-e.

æè¦ï¼<paragraph>é¨èæ´æ£æ¨¡åçå¿«éç¼å±ï¼æå­è½åå (T2I) æ¨¡åå·²åå¾é¡¯èé²å±ï¼å¨æç¤ºè¿½è¹¤åå½±åçææ¹é¢å±ç¾ä»¤äººå°è±¡æ·±å»çè½åãæè¿æ¨åºçæ¨¡åï¼å¦ FLUX.1 å Ideogram2.0ï¼ä»¥å Dall-E3 å Stable Diffusion 3 ç­å¶ä»æ¨¡åï¼å·²å¨åç¨®è¤éä»»åä¸­å±ç¾åºè²çæè½ï¼å¼ç¼ T2I æ¨¡åæ¯å¦æ­£æåéç¨é©ç¨æ§éé²ççåãé¤äºå³çµ±çå½±åçæå¤ï¼éäºæ¨¡åå¨å¯æ§çæãå½±åç·¨è¼¯ãå½±çãé³è¨ã3D ååä½çæï¼ä»¥åèªæåå²åæ·±åº¦ä¼°è¨ç­é»è¦è¦è¦ºä»»åä¸­å±ç¾åºè·¨é åçè½åãç¶èï¼ç®åçè©ä¼°æ¶æ§ä¸è¶³ä»¥å¨é¢è©ä¼°éäºæ¨¡åå¨æ´å±é åä¸­çæè½ãçºäºå¾¹åºè©ä¼°éäºæ¨¡åï¼æåéç¼äº IMAGINE-Eï¼ä¸¦æ¸¬è©¦äºå­åååºçæ¨¡åï¼FLUX.1ãIdeogram2.0ãMidjourneyãDall-E3ãStable Diffusion 3 å Jimengãæåçè©ä¼°åçºäºåééµé åï¼çµæ§åè¼¸åºçæãçå¯¦æåç©çä¸è´æ§ãç¹å®é åçæãå·ææ°æ§çå ´æ¯çæåå¤æ¨£å¼åµä½ä»»åãæ­¤ç¶åè©ä¼°çªé¡¯äºæ¯åæ¨¡åçåªå¢åéå¶ï¼ç¹å¥æ¯ FLUX.1 å Ideogram2.0 å¨çµæ§ååç¹å®é åä»»åä¸­çåºè²æè½ï¼å¼·èª¿äº T2I æ¨¡åä½çºåºç¤ AI å·¥å·çæ´å±æç¨åæ½åãæ¬ç ç©¶æä¾äºå° T2I æ¨¡åç¶åçæåæªä¾è»è·¡çå¯¶è²´è¦è§£ï¼å çºå®åæåéç¨å¯ç¨æ§æ¼é²ãè©ä¼°è³æ¬å°å¨ https://github.com/jylei16/Imagine-e ç¼å¸ã</paragraph>

##### **Temporal Preference Optimization for Long-Form Video Understanding**
2501.13919v1 by Rui Li, Xiaohan Wang, Yuhui Zhang, Zeyu Wang, Serena Yeung-Levy

Despite significant advancements in video large multimodal models
(video-LMMs), achieving effective temporal grounding in long-form videos
remains a challenge for existing models. To address this limitation, we propose
Temporal Preference Optimization (TPO), a novel post-training framework
designed to enhance the temporal grounding capabilities of video-LMMs through
preference learning. TPO adopts a self-training approach that enables models to
differentiate between well-grounded and less accurate temporal responses by
leveraging curated preference datasets at two granularities: localized temporal
grounding, which focuses on specific video segments, and comprehensive temporal
grounding, which captures extended temporal dependencies across entire video
sequences. By optimizing on these preference datasets, TPO significantly
enhances temporal understanding while reducing reliance on manually annotated
data. Extensive experiments on three long-form video understanding
benchmarks--LongVideoBench, MLVU, and Video-MME--demonstrate the effectiveness
of TPO across two state-of-the-art video-LMMs. Notably, LLaVA-Video-TPO
establishes itself as the leading 7B model on the Video-MME benchmark,
underscoring the potential of TPO as a scalable and efficient solution for
advancing temporal reasoning in long-form video understanding. Project page:
https://ruili33.github.io/tpo_website.

æè¦ï¼åç®¡å¨è¦è¨å¤§åå¤æ¨¡ææ¨¡åï¼video-LMMsï¼ä¸­åå¾é¡¯èé²å±ï¼ä½å¨é·ç¯å½±çä¸­å¯¦ç¾ææçæéåºç¤ä»æ¯ç¾ææ¨¡åçææ°ãçºäºè§£æ±ºæ­¤éå¶ï¼æåæåºæéåå¥½æä½³åï¼TPOï¼ï¼éæ¯ä¸åæ°ç©çå¾è¨ç·´æ¶æ§ï¼æ¨å¨ééåå¥½å­¸ç¿å¢å¼· video-LMMs çæéåºç¤è½åãTPO æ¡ç¨èªè¨ç·´æ¹æ³ï¼ä½¿æ¨¡åè½å¤ ééå©ç¨å©åç²åº¦å±¤ç´çç²¾é¸åå¥½è³æéä¾åååºç¤è¯å¥½çæéåæèè¼ä¸æºç¢ºçæéåæï¼å±é¨æéåºç¤ï¼å°æ³¨æ¼ç¹å®å½±ççæ®µï¼ä»¥åå¨é¢æéåºç¤ï¼æ·åæ´åå½±çåºåä¸­å»¶ä¼¸çæéä¾è³´æ§ãééæä½³åéäºåå¥½è³æéï¼TPO å¤§å¹å¢å¼·æéçè§£ï¼åææ¸å°å°æåè¨»è§£è³æçä¾è³´ãå¨ä¸åé·ç¯å½±ççè§£åºæºæ¸¬è©¦ï¼LongVideoBenchãMLVU å Video-MMEï¼ä¸é²è¡çå¤§éå¯¦é©è­æäº TPO å¨å©åæåé²ç video-LMMs ä¸­çæææ§ãå¼å¾æ³¨æçæ¯ï¼LLaVA-Video-TPO å¨ Video-MME åºæºæ¸¬è©¦ä¸­ç¢ºç«äºèªå·±ä½çºé åç 7B æ¨¡åï¼çªé¡¯äº TPO ä½çºå¯æ´åä¸ææè§£æ±ºæ¹æ¡çæ½åï¼å¯ä¿é²é·ç¯å½±ççè§£ä¸­çæéæ¨çãå°æ¡é é¢ï¼https://ruili33.github.io/tpo_websiteã

##### **Improving Video Generation with Human Feedback**
2501.13918v1 by Jie Liu, Gongye Liu, Jiajun Liang, Ziyang Yuan, Xiaokun Liu, Mingwu Zheng, Xiele Wu, Qiulin Wang, Wenyu Qin, Menghan Xia, Xintao Wang, Xiaohong Liu, Fei Yang, Pengfei Wan, Di Zhang, Kun Gai, Yujiu Yang, Wanli Ouyang

Video generation has achieved significant advances through rectified flow
techniques, but issues like unsmooth motion and misalignment between videos and
prompts persist. In this work, we develop a systematic pipeline that harnesses
human feedback to mitigate these problems and refine the video generation
model. Specifically, we begin by constructing a large-scale human preference
dataset focused on modern video generation models, incorporating pairwise
annotations across multi-dimensions. We then introduce VideoReward, a
multi-dimensional video reward model, and examine how annotations and various
design choices impact its rewarding efficacy. From a unified reinforcement
learning perspective aimed at maximizing reward with KL regularization, we
introduce three alignment algorithms for flow-based models by extending those
from diffusion models. These include two training-time strategies: direct
preference optimization for flow (Flow-DPO) and reward weighted regression for
flow (Flow-RWR), and an inference-time technique, Flow-NRG, which applies
reward guidance directly to noisy videos. Experimental results indicate that
VideoReward significantly outperforms existing reward models, and Flow-DPO
demonstrates superior performance compared to both Flow-RWR and standard
supervised fine-tuning methods. Additionally, Flow-NRG lets users assign custom
weights to multiple objectives during inference, meeting personalized video
quality needs. Project page: https://gongyeliu.github.io/videoalign.

æè¦ï¼å½±ççæééä¿®æ­£æµæè¡å·²ç²å¾éå¤§é²å±ï¼ä½å½±çèæç¤ºä¹éçä¸æµæ¢åæåæªå°é½ç­åé¡ä»ç¶å­å¨ãå¨æ¬æä¸­ï¼æåéç¼äºä¸åç³»çµ±åç®¡éï¼å©ç¨äººé¡åé¥ä¾æ¸è¼éäºåé¡ä¸¦æ¹åå½±ççææ¨¡åãå·é«ä¾èªªï¼æåé¦åå»ºç«ä¸åå¤§åäººé¡åå¥½è³æéï¼å°æ³¨æ¼ç¾ä»£å½±ççææ¨¡åï¼ä¸¦çµåè·¨å¤ç¶­åº¦çæå°è¨»è§£ãæ¥èæåä»ç´¹ VideoRewardï¼ä¸åå¤ç¶­å½±ççåµæ¨¡åï¼ä¸¦æ¢è¨è¨»è§£ååç¨®è¨­è¨é¸æå¦ä½å½±é¿å¶çåµæè½ãå¾çµ±ä¸çå¼·åå­¸ç¿è§é»ï¼æ¨å¨æå¤§åå·æ KL æ­£è¦åççåµï¼æåééæ´åæ´æ£æ¨¡åçæ¼ç®æ³ï¼çºåºæ¼æµçæ¨¡åå¼å¥äºä¸ç¨®å°é½æ¼ç®æ³ãéäºæ¼ç®æ³åæ¬å©åè¨ç·´æéç­ç¥ï¼æµçç´æ¥åå¥½æä½³å (Flow-DPO) åæµççåµå æ¬è¿´æ­¸ (Flow-RWR)ï¼ä»¥åä¸åæ¨è«æéæè¡ Flow-NRGï¼å®å°çåµå¼å°ç´æ¥æç¨æ¼æéè¨çå½±çãå¯¦é©çµæé¡¯ç¤ºï¼VideoReward æé¡¯åªæ¼ç¾æççåµæ¨¡åï¼è Flow-DPO è Flow-RWR åæ¨æºç£ç£å¾®èª¿æ¹æ³ç¸æ¯ï¼è¡¨ç¾åºåªç°çæè½ãæ­¤å¤ï¼Flow-NRG è®ä½¿ç¨èå¨æ¨è«æéçºå¤åç®æ¨åéèªè¨æ¬éï¼æ»¿è¶³åäººåçå½±çåè³ªéæ±ãå°æ¡é é¢ï¼https://gongyeliu.github.io/videoalignã

##### **Analysis of Indic Language Capabilities in LLMs**
2501.13912v1 by Aatman Vaidya, Tarunima Prabhakar, Denny George, Swair Shah

This report evaluates the performance of text-in text-out Large Language
Models (LLMs) to understand and generate Indic languages. This evaluation is
used to identify and prioritize Indic languages suited for inclusion in safety
benchmarks. We conduct this study by reviewing existing evaluation studies and
datasets; and a set of twenty-eight LLMs that support Indic languages. We
analyze the LLMs on the basis of the training data, license for model and data,
type of access and model developers. We also compare Indic language performance
across evaluation datasets and find that significant performance disparities in
performance across Indic languages. Hindi is the most widely represented
language in models. While model performance roughly correlates with number of
speakers for the top five languages, the assessment after that varies.

æè¦ï¼éä»½å ±åè©ä¼°ææ¬è¼¸å¥ææ¬è¼¸åºçå¤§åèªè¨æ¨¡å (LLM) äºè§£åç¢çå°åº¦èªè¨çæè½ãæ­¤è©ä¼°ç¨æ¼æ¾åºä¸¦åªåèçé©åç´å¥å®å¨åºæºçå°åº¦èªè¨ãæåééæª¢é±ç¾æçè©ä¼°ç ç©¶åè³æéä¾é²è¡éé ç ç©¶ï¼ä»¥åæ¯æ´å°åº¦èªè¨çäºåå«å LLMãæåæ ¹æè¨ç·´è³æãæ¨¡ååè³æçææ¬ãå­åé¡ååæ¨¡åéç¼èä¾åæ LLMãæåä¹æ¯è¼äºä¸åè©ä¼°è³æéçå°åº¦èªè¨æè½ï¼ä¸¦ç¼ç¾å°åº¦èªè¨çæè½æé¡¯èçå·®ç°ãå°å°èªæ¯æ¨¡åä¸­æå»£æ³ä»£è¡¨çèªè¨ãåç®¡æ¨¡åæè½å¤§è´èåäºåèªè¨çä½¿ç¨èäººæ¸ç¸éï¼ä½æ­¤å¾çè©ä¼°åææä¸åã

##### **Transfer Learning of Surrogate Models via Domain Affine Transformation Across Synthetic and Real-World Benchmarks**
2501.14012v1 by Shuaiqun Pan, Diederick Vermetten, Manuel LÃ³pez-IbÃ¡Ã±ez, Thomas BÃ¤ck, Hao Wang

Surrogate models are frequently employed as efficient substitutes for the
costly execution of real-world processes. However, constructing a high-quality
surrogate model often demands extensive data acquisition. A solution to this
issue is to transfer pre-trained surrogate models for new tasks, provided that
certain invariances exist between tasks. This study focuses on transferring
non-differentiable surrogate models (e.g., random forest) from a source
function to a target function, where we assume their domains are related by an
unknown affine transformation, using only a limited amount of transfer data
points evaluated on the target. Previous research attempts to tackle this
challenge for differentiable models, e.g., Gaussian process regression, which
minimizes the empirical loss on the transfer data by tuning the affine
transformations. In this paper, we extend the previous work to the random
forest model and assess its effectiveness on a widely-used artificial problem
set - Black-Box Optimization Benchmark (BBOB) testbed, and on four real-world
transfer learning problems. The results highlight the significant practical
advantages of the proposed method, particularly in reducing both the data
requirements and computational costs of training surrogate models for complex
real-world scenarios.

æè¦ï¼ä»£çæ¨¡åç¶å¸¸è¢«ç¨ä½çå¯¦ä¸çéç¨ä¸­æè²´å·è¡çé«ææ¿ä»£åãç¶èï¼æ§å»ºä¸åé«åè³ªçä»£çæ¨¡åéå¸¸éè¦å»£æ³çæ¸ææ¡éãéååé¡çè§£æ±ºæ¹æ¡æ¯è½ç§»é åè¨ç·´å¥½çä»£çæ¨¡åä»¥å·è¡æ°ä»»åï¼åææ¯ä»»åä¹éå­å¨æäºä¸è®æ§ãæ¬ç ç©¶éé»å¨æ¼å¾æºå½æ¸è½ç§»ä¸å¯å¾®åçä»£çæ¨¡åï¼ä¾å¦ï¼é¨æ©æ£®æï¼å°ç®æ¨å½æ¸ï¼å¶ä¸­æååè¨­å®åçåç±æªç¥çä»¿å°è½æç¸éè¯ï¼åä½¿ç¨å¨ç®æ¨ä¸è©ä¼°çæéæ¸éçè½ç§»æ¸æé»ãååçç ç©¶åè©¦è§£æ±ºå¯å¾®åæ¨¡åçéåææ°ï¼ä¾å¦ï¼é«æ¯éç¨åæ­¸ï¼å®ééèª¿æ´ä»¿å°è½æä¾æå°åè½ç§»æ¸æçç¶é©æå¤±ãå¨æ¬æä¸­ï¼æåå°ååçç ç©¶å»¶ä¼¸å°é¨æ©æ£®ææ¨¡åï¼ä¸¦è©ä¼°å¶å¨å»£æ³ä½¿ç¨çäººå·¥åé¡é - é»çæä½³ååºæº (BBOB) æ¸¬è©¦å¹³å°ä»¥åååçå¯¦ä¸ççè½ç§»å­¸ç¿åé¡ä¸çæææ§ãçµæçªåºäºææåºæ¹æ³çé¡¯èå¯¦ç¨åªå¢ï¼ç¹å¥æ¯å¨æ¸å°è¤éç¾å¯¦ä¸çå ´æ¯ä¸­è¨ç·´ä»£çæ¨¡åçæ¸æéæ±åè¨ç®ææ¬æ¹é¢ã

##### **QuanTaxo: A Quantum Approach to Self-Supervised Taxonomy Expansion**
2501.14011v1 by Sahil Mishra, Avi Patni, Niladri Chatterjee, Tanmoy Chakraborty

A taxonomy is a hierarchical graph containing knowledge to provide valuable
insights for various web applications. Online retail organizations like
Microsoft and Amazon utilize taxonomies to improve product recommendations and
optimize advertisement by enhancing query interpretation. However, the manual
construction of taxonomies requires significant human effort. As web content
continues to expand at an unprecedented pace, existing taxonomies risk becoming
outdated, struggling to incorporate new and emerging information effectively.
As a consequence, there is a growing need for dynamic taxonomy expansion to
keep them relevant and up-to-date. Existing taxonomy expansion methods often
rely on classical word embeddings to represent entities. However, these
embeddings fall short in capturing hierarchical polysemy, where an entity's
meaning can vary based on its position in the hierarchy and its surrounding
context. To address this challenge, we introduce QuanTaxo, an innovative
quantum-inspired framework for taxonomy expansion. QuanTaxo encodes entity
representations in quantum space, effectively modeling hierarchical polysemy by
leveraging the principles of Hilbert space to capture interference effects
between entities, yielding richer and more nuanced representations.
Comprehensive experiments on four real-world benchmark datasets show that
QuanTaxo significantly outperforms classical embedding models, achieving
substantial improvements of 18.45% in accuracy, 20.5% in Mean Reciprocal Rank,
and 17.87% in Wu & Palmer metrics across eight classical embedding-based
baselines. We further highlight the superiority of QuanTaxo through extensive
ablation and case studies.

æè¦ï¼<paragraph>åé¡æ³æ¯ä¸åéå±¤åï¼åå«ç¥è­ï¼å¯çºåç¨®ç¶²è·¯æç¨ç¨å¼æä¾æå¹å¼çè¦è§£ãå¾®è»åäºé¦¬éç­ç·ä¸é¶å®çµç¹å©ç¨åé¡æ³ä¾æ¹åç¢åæ¨è¦ï¼ä¸¦ééå å¼·æ¥è©¢è©®éä¾æä½³åå»£åãç¶èï¼åé¡æ³çå»ºç½®éè¦å¤§éäººåãé¨èç¶²è·¯å§å®¹æçºä»¥ç©ºåçéåº¦æ´åï¼ç¾æçåé¡æ³æéæçé¢¨éªï¼é£ä»¥ææç´å¥æ°èè³è¨ãå æ­¤ï¼å°æ¼åæåé¡æ³æ´åçéæ±æ¥çå¢å ï¼ä»¥ä¿æå¶ç¸éæ§åæææ§ãç¾æçåé¡æ³æ´åæ¹æ³éå¸¸ä¾è³´å³çµ±çè©å½åµå¥ä¾è¡¨ç¤ºå¯¦é«ãç¶èï¼éäºåµå¥ç¡æ³ææéå±¤å¤ç¾©æ§ï¼å¶ä¸­å¯¦é«çæç¾©ææ ¹æå¶å¨éå±¤ä¸­çä½ç½®åå¶å¨é­èçµ¡èææä¸åãçºäºæå°éé ææ°ï¼æåå¼å¥äº QuanTaxoï¼ä¸ååµæ°çéå­åç¼å¼åé¡æ³æ´åæ¶æ§ãQuanTaxo å¨éå­ç©ºéä¸­ç·¨ç¢¼å¯¦é«è¡¨ç¤ºï¼ééå©ç¨å¸ç¾ä¼¯ç¹ç©ºéçåçä¾ææå¯¦é«ä¹éçå¹²æ¾ææï¼ææå°å»ºæ¨¡éå±¤å¤ç¾©æ§ï¼ç¢çæ´è±å¯ä¸æ´ç´°ç·»çè¡¨ç¤ºãå¨ååçå¯¦ä¸ççåºæºè³æéä¸çå¨é¢å¯¦é©é¡¯ç¤ºï¼QuanTaxo æé¡¯åªæ¼å³çµ±åµå¥æ¨¡åï¼å¨æºç¢ºåº¦æ¹é¢æåäº 18.45%ï¼å¨å¹³ååæ¸æåæ¹é¢æåäº 20.5%ï¼å¨ Wu & Palmer ææ¨æ¹é¢æåäº 17.87%ï¼è¶è¶äºå«ååºæ¼å³çµ±åµå¥çåºæºãæåé²ä¸æ­¥ééå»£æ³çæ¶èååæ¡ç ç©¶ä¾å¼·èª¿ QuanTaxo çåªè¶æ§ã</paragraph>

##### **PointOBB-v3: Expanding Performance Boundaries of Single Point-Supervised Oriented Object Detection**
2501.13898v1 by Peiyuan Zhang, Junwei Luo, Xue Yang, Yi Yu, Qingyun Li, Yue Zhou, Xiaosong Jia, Xudong Lu, Jingdong Chen, Xiang Li, Junchi Yan, Yansheng Li

With the growing demand for oriented object detection (OOD), recent studies
on point-supervised OOD have attracted significant interest. In this paper, we
propose PointOBB-v3, a stronger single point-supervised OOD framework. Compared
to existing methods, it generates pseudo rotated boxes without additional
priors and incorporates support for the end-to-end paradigm. PointOBB-v3
functions by integrating three unique image views: the original view, a resized
view, and a rotated/flipped (rot/flp) view. Based on the views, a scale
augmentation module and an angle acquisition module are constructed. In the
first module, a Scale-Sensitive Consistency (SSC) loss and a Scale-Sensitive
Feature Fusion (SSFF) module are introduced to improve the model's ability to
estimate object scale. To achieve precise angle predictions, the second module
employs symmetry-based self-supervised learning. Additionally, we introduce an
end-to-end version that eliminates the pseudo-label generation process by
integrating a detector branch and introduces an Instance-Aware Weighting (IAW)
strategy to focus on high-quality predictions. We conducted extensive
experiments on the DIOR-R, DOTA-v1.0/v1.5/v2.0, FAIR1M, STAR, and RSAR
datasets. Across all these datasets, our method achieves an average improvement
in accuracy of 3.56% in comparison to previous state-of-the-art methods. The
code will be available at https://github.com/ZpyWHU/PointOBB-v3.

æè¦ï¼é¨èé¢åç®æ¨åµæ¸¬ (OOD) éæ±çå¢é·ï¼æè¿å°é»ç£ç£ OOD çç ç©¶å¼èµ·äºæ¥µå¤§çèè¶£ãå¨æ¬æä¸­ï¼æåæåºäº PointOBB-v3ï¼ä¸åæ´å¼·å¤§çå®é»ç£ç£ OOD æ¡æ¶ãèç¾ææ¹æ³ç¸æ¯ï¼å®å¨æ²æé¡å¤åé©ç¥è­çææ³ä¸çæäºå½æè½æ¡ï¼ä¸¦çµåäºå°ç«¯å°ç«¯ç¯ä¾çæ¯æãPointOBB-v3 çåè½æ¯ééæ´åä¸åç¨ç¹çå½±åæª¢è¦ï¼åå§æª¢è¦ãç¸®æ¾æª¢è¦åæè½/ç¿»è½ (rot/flp) æª¢è¦ãæ ¹æéäºæª¢è¦ï¼æ§å»ºäºä¸åæ¯ä¾æ´åæ¨¡çµåä¸åè§åº¦æ·åæ¨¡çµãå¨ç¬¬ä¸åæ¨¡çµä¸­ï¼å¼å¥äºæ¯ä¾ææä¸è´æ§ (SSC) æå¤±åæ¯ä¾ææç¹å¾µèå (SSFF) æ¨¡çµï¼ä»¥æé«æ¨¡åä¼°è¨ç©ä»¶æ¯ä¾çè½åãçºäºå¯¦ç¾ç²¾ç¢ºçè§åº¦é æ¸¬ï¼ç¬¬äºåæ¨¡çµæ¡ç¨äºåºæ¼å°ç¨±çèªç£ç£å­¸ç¿ãæ­¤å¤ï¼æåå¼å¥äºç«¯å°ç«¯çæ¬ï¼ééæ´ååµæ¸¬å¨åæ¯ä¸¦å¼å¥å¯¦ä¾æç¥å æ¬ (IAW) ç­ç¥ä¾æ¶é¤å½æ¨ç±¤çæéç¨ï¼ä»¥å°æ³¨æ¼é«åè³ªé æ¸¬ãæåå° DIOR-RãDOTA-v1.0/v1.5/v2.0ãFAIR1MãSTAR å RSAR è³æéé²è¡äºå»£æ³çå¯¦é©ãå¨ææéäºè³æéä¸­ï¼èååçæåé²æ¹æ³ç¸æ¯ï¼æåçæ¨¡åå¨æºç¢ºåº¦æ¹é¢å¹³åæåäº 3.56%ãç¨å¼ç¢¼å°å¯å¨ https://github.com/ZpyWHU/PointOBB-v3 åå¾ã

