{"2407.16831": {"publish_time": "2024-07-23", "title": "Networks of Networks: Complexity Class Principles Applied to Compound AI Systems Design", "paper_summary": "As practitioners seek to surpass the current reliability and quality frontier\nof monolithic models, Compound AI Systems consisting of many language model\ninference calls are increasingly employed. In this work, we construct systems,\nwhich we call Networks of Networks (NoNs) organized around the distinction\nbetween generating a proposed answer and verifying its correctness, a\nfundamental concept in complexity theory that we show empirically extends to\nLanguage Models (LMs). We introduce a verifier-based judge NoN with K\ngenerators, an instantiation of \"best-of-K\" or \"judge-based\" compound AI\nsystems. Through experiments on synthetic tasks such as prime factorization,\nand core benchmarks such as the MMLU, we demonstrate notable performance gains.\nFor instance, in factoring products of two 3-digit primes, a simple NoN\nimproves accuracy from 3.7\\% to 36.6\\%. On MMLU, a verifier-based judge\nconstruction with only 3 generators boosts accuracy over individual GPT-4-Turbo\ncalls by 2.8\\%. Our analysis reveals that these gains are most pronounced in\ndomains where verification is notably easier than generation--a\ncharacterization which we believe subsumes many reasoning and procedural\nknowledge tasks, but doesn't often hold for factual and declarative\nknowledge-based settings. For mathematical and formal logic reasoning-based\nsubjects of MMLU, we observe a 5-8\\% or higher gain, whilst no gain on others\nsuch as geography and religion. We provide key takeaways for ML practitioners,\nincluding the importance of considering verification complexity, the impact of\nwitness format on verifiability, and a simple test to determine the potential\nbenefit of this NoN approach for a given problem distribution. This work aims\nto inform future research and practice in the design of compound AI systems.", "paper_summary_zh": "<paragraph>\u96a8\u8457\u5f9e\u696d\u4eba\u54e1\u5c0b\u6c42\u8d85\u8d8a\u7576\u524d\u55ae\u4e00\u6a21\u578b\u7684\u53ef\u9760\u6027\u548c\u54c1\u8cea\u524d\u6cbf\uff0c\u7531\u8a31\u591a\u8a9e\u8a00\u6a21\u578b\u63a8\u7406\u547c\u53eb\u7d44\u6210\u7684\u8907\u5408\u5f0f AI \u7cfb\u7d71\u6b63\u65e5\u76ca\u88ab\u63a1\u7528\u3002\u5728\u9019\u9805\u5de5\u4f5c\u4e2d\uff0c\u6211\u5011\u5efa\u69cb\u4e86\u7cfb\u7d71\uff0c\u6211\u5011\u7a31\u4e4b\u70ba\u7db2\u8def\u4e4b\u7db2\uff08NoN\uff09\uff0c\u5176\u7d44\u7e54\u65b9\u5f0f\u570d\u7e5e\u8457\u63d0\u51fa\u5efa\u8b70\u7b54\u6848\u548c\u9a57\u8b49\u5176\u6b63\u78ba\u6027\u4e4b\u9593\u7684\u5340\u5225\uff0c\u9019\u662f\u4e00\u500b\u8907\u96dc\u6027\u7406\u8ad6\u4e2d\u7684\u57fa\u672c\u6982\u5ff5\uff0c\u6211\u5011\u4ee5\u5be6\u8b49\u65b9\u5f0f\u5c55\u793a\u5176\u5ef6\u4f38\u81f3\u8a9e\u8a00\u6a21\u578b\uff08LM\uff09\u3002\u6211\u5011\u5f15\u5165\u4e86\u5177\u6709 K \u500b\u7522\u751f\u5668\u7684\u9a57\u8b49\u8005\u70ba\u57fa\u790e\u7684\u8a55\u5be9 NoN\uff0c\u9019\u662f\u300cK \u4e2d\u6700\u4f73\u300d\u6216\u300c\u57fa\u65bc\u8a55\u5be9\u300d\u8907\u5408\u5f0f AI \u7cfb\u7d71\u7684\u5be6\u4f8b\u5316\u3002\u900f\u904e\u5c0d\u5408\u6210\u4efb\u52d9\uff08\u4f8b\u5982\u8cea\u56e0\u6578\u5206\u89e3\uff09\u548c\u6838\u5fc3\u57fa\u6e96\uff08\u4f8b\u5982 MMLU\uff09\u7684\u5be6\u9a57\uff0c\u6211\u5011\u5c55\u793a\u4e86\u986f\u8457\u7684\u6548\u80fd\u63d0\u5347\u3002\u4f8b\u5982\uff0c\u5728\u5206\u89e3\u5169\u500b 3 \u4f4d\u6578\u8cea\u6578\u7684\u4e58\u7a4d\u6642\uff0c\u4e00\u500b\u7c21\u55ae\u7684 NoN \u5c07\u6e96\u78ba\u5ea6\u5f9e 3.7% \u63d0\u5347\u81f3 36.6%\u3002\u5728 MMLU \u4e0a\uff0c\u4e00\u500b\u50c5\u6709 3 \u500b\u7522\u751f\u5668\u7684\u57fa\u65bc\u9a57\u8b49\u8005\u7684\u8a55\u5be9\u5efa\u69cb\uff0c\u5c07\u6e96\u78ba\u5ea6\u63d0\u5347\u4e86 2.8%\uff0c\u8d85\u8d8a\u4e86\u500b\u5225\u7684 GPT-4-Turbo \u547c\u53eb\u3002\u6211\u5011\u7684\u5206\u6790\u986f\u793a\uff0c\u9019\u4e9b\u63d0\u5347\u5728\u9a57\u8b49\u986f\u8457\u6bd4\u7522\u751f\u5bb9\u6613\u7684\u9818\u57df\u4e2d\u6700\u4e3a\u660e\u986f\u2014\u2014\u6211\u5011\u76f8\u4fe1\u6b64\u7279\u6027\u6db5\u84cb\u4e86\u8a31\u591a\u63a8\u7406\u548c\u7a0b\u5e8f\u77e5\u8b58\u4efb\u52d9\uff0c\u4f46\u5c0d\u65bc\u57fa\u65bc\u4e8b\u5be6\u548c\u5ba3\u544a\u5f0f\u77e5\u8b58\u7684\u8a2d\u5b9a\u4e26\u4e0d\u5e38\u898b\u3002\u5c0d\u65bc MMLU \u4e2d\u57fa\u65bc\u6578\u5b78\u548c\u5f62\u5f0f\u908f\u8f2f\u63a8\u7406\u7684\u4e3b\u984c\uff0c\u6211\u5011\u89c0\u5bdf\u5230 5-8% \u6216\u66f4\u9ad8\u7684\u63d0\u5347\uff0c\u800c\u5176\u4ed6\u4e3b\u984c\uff08\u4f8b\u5982\u5730\u7406\u548c\u5b97\u6559\uff09\u5247\u6c92\u6709\u63d0\u5347\u3002\u6211\u5011\u70ba ML \u5f9e\u696d\u4eba\u54e1\u63d0\u4f9b\u4e86\u95dc\u9375\u7684\u91cd\u9ede\uff0c\u5305\u62ec\u8003\u91cf\u9a57\u8b49\u8907\u96dc\u6027\u7684\u91cd\u8981\u6027\u3001\u898b\u8b49\u683c\u5f0f\u5c0d\u53ef\u9a57\u8b49\u6027\u7684\u5f71\u97ff\uff0c\u4ee5\u53ca\u4e00\u500b\u7c21\u55ae\u7684\u6e2c\u8a66\uff0c\u7528\u65bc\u78ba\u5b9a\u6b64 NoN \u65b9\u6cd5\u5c0d\u7d66\u5b9a\u554f\u984c\u5206\u5e03\u7684\u6f5b\u5728\u6548\u76ca\u3002\u9019\u9805\u5de5\u4f5c\u65e8\u5728\u70ba\u8907\u5408\u5f0f AI \u7cfb\u7d71\u8a2d\u8a08\u4e2d\u7684\u672a\u4f86\u7814\u7a76\u548c\u5be6\u52d9\u63d0\u4f9b\u8cc7\u8a0a\u3002</paragraph>", "author": "Jared Quincy Davis et.al.", "authors": "Jared Quincy Davis, Boris Hanin, Lingjiao Chen, Peter Bailis, Ion Stoica, Matei Zaharia", "id": "2407.16831v1", "paper_url": "http://arxiv.org/abs/2407.16831v1", "repo": "null"}}