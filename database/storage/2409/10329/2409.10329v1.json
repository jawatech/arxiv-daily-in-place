{"2409.10329": {"publish_time": "2024-09-16", "title": "InfoDisent: Explainability of Image Classification Models by Information Disentanglement", "paper_summary": "Understanding the decisions made by image classification networks is a\ncritical area of research in deep learning. This task is traditionally divided\ninto two distinct approaches: post-hoc methods and intrinsic methods. Post-hoc\nmethods, such as GradCam, aim to interpret the decisions of pre-trained models\nby identifying regions of the image where the network focuses its attention.\nHowever, these methods provide only a high-level overview, making it difficult\nto fully understand the network's decision-making process. Conversely,\nintrinsic methods, like prototypical parts models, offer a more detailed\nunderstanding of network predictions but are constrained by specific\narchitectures, training methods, and datasets.\n  In this paper, we introduce InfoDisent, a hybrid model that combines the\nadvantages of both approaches. By utilizing an information bottleneck,\nInfoDisent disentangles the information in the final layer of a pre-trained\ndeep network, enabling the breakdown of classification decisions into basic,\nunderstandable atomic components. Unlike standard prototypical parts\napproaches, InfoDisent can interpret the decisions of pre-trained\nclassification networks and be used for making classification decisions,\nsimilar to intrinsic models. We validate the effectiveness of InfoDisent on\nbenchmark datasets such as ImageNet, CUB-200-2011, Stanford Cars, and Stanford\nDogs for both convolutional and transformer backbones.", "paper_summary_zh": "\u7406\u89e3\u56fe\u50cf\u5206\u7c7b\u7f51\u7edc\u505a\u51fa\u7684\u51b3\u7b56\u662f\u6df1\u5ea6\u5b66\u4e60\u4e2d\u4e00\u4e2a\u5173\u952e\u7684\u7814\u7a76\u9886\u57df\u3002\u8fd9\u9879\u4efb\u52a1\u4f20\u7edf\u4e0a\u5206\u4e3a\u4e24\u79cd\u4e0d\u540c\u7684\u65b9\u6cd5\uff1a\u4e8b\u540e\u65b9\u6cd5\u548c\u5185\u5728\u65b9\u6cd5\u3002\u4e8b\u540e\u65b9\u6cd5\uff0c\u4f8b\u5982 GradCam\uff0c\u65e8\u5728\u901a\u8fc7\u8bc6\u522b\u7f51\u7edc\u5173\u6ce8\u56fe\u50cf\u533a\u57df\u6765\u89e3\u91ca\u9884\u8bad\u7ec3\u6a21\u578b\u7684\u51b3\u7b56\u3002\u7136\u800c\uff0c\u8fd9\u4e9b\u65b9\u6cd5\u4ec5\u63d0\u4f9b\u9ad8\u7ea7\u6982\u8ff0\uff0c\u96be\u4ee5\u5b8c\u5168\u7406\u89e3\u7f51\u7edc\u7684\u51b3\u7b56\u8fc7\u7a0b\u3002\u76f8\u53cd\uff0c\u539f\u578b\u90e8\u5206\u6a21\u578b\u7b49\u5185\u5728\u65b9\u6cd5\u63d0\u4f9b\u4e86\u5bf9\u7f51\u7edc\u9884\u6d4b\u7684\u66f4\u8be6\u7ec6\u7406\u89e3\uff0c\u4f46\u53d7\u5230\u7279\u5b9a\u67b6\u6784\u3001\u8bad\u7ec3\u65b9\u6cd5\u548c\u6570\u636e\u96c6\u7684\u9650\u5236\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u4eec\u4ecb\u7ecd\u4e86 InfoDisent\uff0c\u8fd9\u662f\u4e00\u4e2a\u7ed3\u5408\u4e86\u4e24\u79cd\u65b9\u6cd5\u4f18\u52bf\u7684\u6df7\u5408\u6a21\u578b\u3002\u901a\u8fc7\u5229\u7528\u4fe1\u606f\u74f6\u9888\uff0cInfoDisent \u89e3\u5f00\u4e86\u9884\u8bad\u7ec3\u6df1\u5ea6\u7f51\u7edc\u6700\u540e\u4e00\u5c42\u4e2d\u7684\u4fe1\u606f\uff0c\u4ece\u800c\u5c06\u5206\u7c7b\u51b3\u7b56\u5206\u89e3\u4e3a\u57fa\u672c\u7684\u3001\u53ef\u7406\u89e3\u7684\u539f\u5b50\u7ec4\u4ef6\u3002\u4e0e\u6807\u51c6\u539f\u578b\u90e8\u5206\u65b9\u6cd5\u4e0d\u540c\uff0cInfoDisent \u53ef\u4ee5\u89e3\u91ca\u9884\u8bad\u7ec3\u5206\u7c7b\u7f51\u7edc\u7684\u51b3\u7b56\uff0c\u5e76\u7528\u4e8e\u505a\u51fa\u5206\u7c7b\u51b3\u7b56\uff0c\u7c7b\u4f3c\u4e8e\u5185\u5728\u6a21\u578b\u3002\u6211\u4eec\u5728 ImageNet\u3001CUB-200-2011\u3001Stanford Cars \u548c Stanford Dogs \u7b49\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u4e86 InfoDisent \u7684\u6709\u6548\u6027\uff0c\u7528\u4e8e\u5377\u79ef\u548c\u8f6c\u6362\u5668\u9aa8\u5e72\u3002", "author": "\u0141ukasz Struski et.al.", "authors": "\u0141ukasz Struski, Jacek Tabor", "id": "2409.10329v1", "paper_url": "http://arxiv.org/abs/2409.10329v1", "repo": "null"}}