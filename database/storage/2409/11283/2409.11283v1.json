{"2409.11283": {"publish_time": "2024-09-17", "title": "Zero-resource Hallucination Detection for Text Generation via Graph-based Contextual Knowledge Triples Modeling", "paper_summary": "LLMs obtain remarkable performance but suffer from hallucinations. Most\nresearch on detecting hallucination focuses on the questions with short and\nconcrete correct answers that are easy to check the faithfulness. Hallucination\ndetections for text generation with open-ended answers are more challenging.\nSome researchers use external knowledge to detect hallucinations in generated\ntexts, but external resources for specific scenarios are hard to access. Recent\nstudies on detecting hallucinations in long text without external resources\nconduct consistency comparison among multiple sampled outputs. To handle long\ntexts, researchers split long texts into multiple facts and individually\ncompare the consistency of each pairs of facts. However, these methods (1)\nhardly achieve alignment among multiple facts; (2) overlook dependencies\nbetween multiple contextual facts. In this paper, we propose a graph-based\ncontext-aware (GCA) hallucination detection for text generations, which aligns\nknowledge facts and considers the dependencies between contextual knowledge\ntriples in consistency comparison. Particularly, to align multiple facts, we\nconduct a triple-oriented response segmentation to extract multiple knowledge\ntriples. To model dependencies among contextual knowledge triple (facts), we\nconstruct contextual triple into a graph and enhance triples' interactions via\nmessage passing and aggregating via RGCN. To avoid the omission of knowledge\ntriples in long text, we conduct a LLM-based reverse verification via\nreconstructing the knowledge triples. Experiments show that our model enhances\nhallucination detection and excels all baselines.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b\u53d6\u5f97\u4e86\u986f\u8457\u7684\u8868\u73fe\uff0c\u4f46\u6703\u7522\u751f\u5e7b\u89ba\u3002\u5927\u591a\u6578\u95dc\u65bc\u5075\u6e2c\u5e7b\u89ba\u7684\u7814\u7a76\u90fd\u5c08\u6ce8\u65bc\u554f\u984c\u7684\u7b54\u6848\u7c21\u77ed\u4e14\u5177\u9ad4\uff0c\u4e14\u6613\u65bc\u6aa2\u67e5\u5176\u771f\u5be6\u6027\u3002\u5c0d\u65bc\u958b\u653e\u5f0f\u7b54\u6848\u7684\u6587\u5b57\u751f\u6210\uff0c\u5e7b\u89ba\u5075\u6e2c\u66f4\u5177\u6311\u6230\u6027\u3002\u4e00\u4e9b\u7814\u7a76\u4eba\u54e1\u4f7f\u7528\u5916\u90e8\u77e5\u8b58\u4f86\u5075\u6e2c\u751f\u6210\u7684\u6587\u5b57\u4e2d\u7684\u5e7b\u89ba\uff0c\u4f46\u7279\u5b9a\u60c5\u5883\u7684\u5916\u90e8\u8cc7\u6e90\u96e3\u4ee5\u53d6\u5f97\u3002\u6700\u8fd1\u95dc\u65bc\u5728\u6c92\u6709\u5916\u90e8\u8cc7\u6e90\u7684\u60c5\u6cc1\u4e0b\u5075\u6e2c\u9577\u7bc7\u6587\u5b57\u4e2d\u7684\u5e7b\u89ba\u7684\u7814\u7a76\uff0c\u6703\u5728\u591a\u500b\u53d6\u6a23\u8f38\u51fa\u4e4b\u9593\u9032\u884c\u4e00\u81f4\u6027\u6bd4\u8f03\u3002\u70ba\u4e86\u8655\u7406\u9577\u7bc7\u6587\u5b57\uff0c\u7814\u7a76\u4eba\u54e1\u5c07\u9577\u7bc7\u6587\u5b57\u62c6\u5206\u6210\u591a\u500b\u4e8b\u5be6\uff0c\u4e26\u500b\u5225\u6bd4\u8f03\u6bcf\u5c0d\u4e8b\u5be6\u7684\u4e00\u81f4\u6027\u3002\u7136\u800c\uff0c\u9019\u4e9b\u65b9\u6cd5\uff081\uff09\u96e3\u4ee5\u5728\u591a\u500b\u4e8b\u5be6\u4e4b\u9593\u9054\u6210\u4e00\u81f4\u6027\uff1b\uff082\uff09\u5ffd\u7565\u4e86\u591a\u500b\u4e0a\u4e0b\u6587\u4e8b\u5be6\u4e4b\u9593\u7684\u4f9d\u8cf4\u6027\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u4e00\u500b\u57fa\u65bc\u5716\u5f62\u7684\u4e0a\u4e0b\u6587\u611f\u77e5\uff08GCA\uff09\u5e7b\u89ba\u5075\u6e2c\uff0c\u7528\u65bc\u6587\u5b57\u751f\u6210\uff0c\u5b83\u6703\u5c0d\u9f4a\u77e5\u8b58\u4e8b\u5be6\uff0c\u4e26\u8003\u616e\u4e0a\u4e0b\u6587\u77e5\u8b58\u4e09\u5143\u7d44\u4e4b\u9593\u7684\u4f9d\u8cf4\u6027\uff0c\u4ee5\u9032\u884c\u4e00\u81f4\u6027\u6bd4\u8f03\u3002\u7279\u5225\u662f\uff0c\u70ba\u4e86\u5c0d\u9f4a\u591a\u500b\u4e8b\u5be6\uff0c\u6211\u5011\u9032\u884c\u4e86\u4e09\u5143\u5c0e\u5411\u7684\u56de\u61c9\u5340\u584a\uff0c\u4ee5\u63d0\u53d6\u591a\u500b\u77e5\u8b58\u4e09\u5143\u7d44\u3002\u70ba\u4e86\u6a21\u64ec\u4e0a\u4e0b\u6587\u77e5\u8b58\u4e09\u5143\u7d44\uff08\u4e8b\u5be6\uff09\u4e4b\u9593\u7684\u4f9d\u8cf4\u6027\uff0c\u6211\u5011\u5c07\u4e0a\u4e0b\u6587\u4e09\u5143\u7d44\u5efa\u69cb\u70ba\u4e00\u500b\u5716\u5f62\uff0c\u4e26\u900f\u904e\u8a0a\u606f\u50b3\u905e\u548c\u900f\u904e RGCN \u9032\u884c\u805a\u5408\u4f86\u589e\u5f37\u4e09\u5143\u7d44\u7684\u4e92\u52d5\u3002\u70ba\u4e86\u907f\u514d\u907a\u6f0f\u9577\u7bc7\u6587\u5b57\u4e2d\u7684\u77e5\u8b58\u4e09\u5143\u7d44\uff0c\u6211\u5011\u900f\u904e\u91cd\u5efa\u77e5\u8b58\u4e09\u5143\u7d44\u9032\u884c\u57fa\u65bc LLM \u7684\u53cd\u5411\u9a57\u8b49\u3002\u5be6\u9a57\u8868\u660e\uff0c\u6211\u5011\u7684\u6a21\u578b\u589e\u5f37\u4e86\u5e7b\u89ba\u5075\u6e2c\uff0c\u4e26\u512a\u65bc\u6240\u6709\u57fa\u7dda\u3002", "author": "Xinyue Fang et.al.", "authors": "Xinyue Fang, Zhen Huang, Zhiliang Tian, Minghui Fang, Ziyi Pan, Quntian Fang, Zhihua Wen, Hengyue Pan, Dongsheng Li", "id": "2409.11283v1", "paper_url": "http://arxiv.org/abs/2409.11283v1", "repo": "null"}}