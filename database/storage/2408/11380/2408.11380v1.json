{"2408.11380": {"publish_time": "2024-08-21", "title": "Reflex-Based Open-Vocabulary Navigation without Prior Knowledge Using Omnidirectional Camera and Multiple Vision-Language Models", "paper_summary": "Various robot navigation methods have been developed, but they are mainly\nbased on Simultaneous Localization and Mapping (SLAM), reinforcement learning,\netc., which require prior map construction or learning. In this study, we\nconsider the simplest method that does not require any map construction or\nlearning, and execute open-vocabulary navigation of robots without any prior\nknowledge to do this. We applied an omnidirectional camera and pre-trained\nvision-language models to the robot. The omnidirectional camera provides a\nuniform view of the surroundings, thus eliminating the need for complicated\nexploratory behaviors including trajectory generation. By applying multiple\npre-trained vision-language models to this omnidirectional image and\nincorporating reflective behaviors, we show that navigation becomes simple and\ndoes not require any prior setup. Interesting properties and limitations of our\nmethod are discussed based on experiments with the mobile robot Fetch.", "paper_summary_zh": "\u5df2\u958b\u767c\u51fa\u5404\u7a2e\u6a5f\u5668\u4eba\u5c0e\u822a\u65b9\u6cd5\uff0c\u4f46\u5b83\u5011\u4e3b\u8981\u57fa\u65bc\u540c\u6642\u5b9a\u4f4d\u8207\u5efa\u5716 (SLAM)\u3001\u5f37\u5316\u5b78\u7fd2\u7b49\uff0c\u9700\u8981\u4e8b\u5148\u5efa\u69cb\u5730\u5716\u6216\u5b78\u7fd2\u3002\u5728\u672c\u7814\u7a76\u4e2d\uff0c\u6211\u5011\u8003\u616e\u6700\u7c21\u55ae\u7684\u65b9\u6cd5\uff0c\u4e0d\u9700\u8981\u4efb\u4f55\u5730\u5716\u5efa\u69cb\u6216\u5b78\u7fd2\uff0c\u4e26\u57f7\u884c\u6a5f\u5668\u4eba\u7684\u958b\u653e\u5f0f\u8a5e\u5f59\u5c0e\u822a\uff0c\u7121\u9700\u4efb\u4f55\u5148\u9a57\u77e5\u8b58\u5373\u53ef\u57f7\u884c\u6b64\u64cd\u4f5c\u3002\u6211\u5011\u5c07\u5168\u666f\u76f8\u6a5f\u548c\u9810\u5148\u8a13\u7df4\u7684\u8996\u89ba\u8a9e\u8a00\u6a21\u578b\u61c9\u7528\u65bc\u6a5f\u5668\u4eba\u3002\u5168\u666f\u76f8\u6a5f\u63d0\u4f9b\u5468\u570d\u74b0\u5883\u7684\u7d71\u4e00\u8996\u5716\uff0c\u56e0\u6b64\u7121\u9700\u8907\u96dc\u7684\u63a2\u7d22\u884c\u70ba\uff0c\u5305\u62ec\u8ecc\u8de1\u751f\u6210\u3002\u901a\u904e\u5c07\u591a\u500b\u9810\u5148\u8a13\u7df4\u7684\u8996\u89ba\u8a9e\u8a00\u6a21\u578b\u61c9\u7528\u65bc\u6b64\u5168\u666f\u5716\u50cf\u4e26\u7d50\u5408\u53cd\u5c04\u884c\u70ba\uff0c\u6211\u5011\u8868\u660e\u5c0e\u822a\u8b8a\u5f97\u7c21\u55ae\uff0c\u4e26\u4e14\u4e0d\u9700\u8981\u4efb\u4f55\u5148\u524d\u7684\u8a2d\u7f6e\u3002\u6839\u64da\u4f7f\u7528\u79fb\u52d5\u6a5f\u5668\u4eba Fetch \u9032\u884c\u7684\u5be6\u9a57\uff0c\u8a0e\u8ad6\u4e86\u6211\u5011\u65b9\u6cd5\u7684\u6709\u8da3\u7279\u6027\u548c\u9650\u5236\u3002", "author": "Kento Kawaharazuka et.al.", "authors": "Kento Kawaharazuka, Yoshiki Obinata, Naoaki Kanazawa, Naoto Tsukamoto, Kei Okada, Masayuki Inaba", "id": "2408.11380v1", "paper_url": "http://arxiv.org/abs/2408.11380v1", "repo": "null"}}