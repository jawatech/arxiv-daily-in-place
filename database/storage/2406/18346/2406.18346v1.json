{"2406.18346": {"publish_time": "2024-06-26", "title": "AI Alignment through Reinforcement Learning from Human Feedback? Contradictions and Limitations", "paper_summary": "This paper critically evaluates the attempts to align Artificial Intelligence\n(AI) systems, especially Large Language Models (LLMs), with human values and\nintentions through Reinforcement Learning from Feedback (RLxF) methods,\ninvolving either human feedback (RLHF) or AI feedback (RLAIF). Specifically, we\nshow the shortcomings of the broadly pursued alignment goals of honesty,\nharmlessness, and helpfulness. Through a multidisciplinary sociotechnical\ncritique, we examine both the theoretical underpinnings and practical\nimplementations of RLxF techniques, revealing significant limitations in their\napproach to capturing the complexities of human ethics and contributing to AI\nsafety. We highlight tensions and contradictions inherent in the goals of RLxF.\nIn addition, we discuss ethically-relevant issues that tend to be neglected in\ndiscussions about alignment and RLxF, among which the trade-offs between\nuser-friendliness and deception, flexibility and interpretability, and system\nsafety. We conclude by urging researchers and practitioners alike to critically\nassess the sociotechnical ramifications of RLxF, advocating for a more nuanced\nand reflective approach to its application in AI development.", "paper_summary_zh": "\u9019\u7bc7\u8ad6\u6587\u6279\u5224\u6027\u5730\u8a55\u4f30\u4e86\u5c07\u4eba\u5de5\u667a\u6167 (AI) \u7cfb\u7d71\uff0c\u7279\u5225\u662f\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM)\uff0c\u8207\u4eba\u985e\u50f9\u503c\u89c0\u548c\u610f\u5716\u76f8\u7b26\u7684\u5617\u8a66\uff0c\u9019\u4e9b\u5617\u8a66\u900f\u904e\u56de\u994b\u5f37\u5316\u5b78\u7fd2 (RLxF) \u65b9\u6cd5\u9032\u884c\uff0c\u5305\u62ec\u4eba\u985e\u56de\u994b (RLHF) \u6216 AI \u56de\u994b (RLAIF)\u3002\u5177\u9ad4\u4f86\u8aaa\uff0c\u6211\u5011\u5c55\u793a\u4e86\u8aa0\u5be6\u3001\u7121\u5bb3\u548c\u6709\u5e6b\u52a9\u7b49\u5ee3\u6cdb\u8ffd\u6c42\u7684\u5c0d\u9f4a\u76ee\u6a19\u7684\u7f3a\u9ede\u3002\u900f\u904e\u591a\u5b78\u79d1\u793e\u6703\u6280\u8853\u6279\u5224\uff0c\u6211\u5011\u6aa2\u8996\u4e86 RLxF \u6280\u8853\u7684\u7406\u8ad6\u57fa\u790e\u548c\u5be6\u969b\u5be6\u4f5c\uff0c\u63ed\u793a\u4e86\u5b83\u5011\u5728\u6355\u6349\u4eba\u985e\u502b\u7406\u8907\u96dc\u6027\u548c\u4fc3\u6210 AI \u5b89\u5168\u65b9\u9762\u7684\u91cd\u5927\u9650\u5236\u3002\u6211\u5011\u5f37\u8abf\u4e86 RLxF \u76ee\u6a19\u4e2d\u56fa\u6709\u7684\u7dca\u5f35\u548c\u77db\u76fe\u3002\u6b64\u5916\uff0c\u6211\u5011\u8a0e\u8ad6\u4e86\u5728\u95dc\u65bc\u5c0d\u9f4a\u548c RLxF \u7684\u8a0e\u8ad6\u4e2d\u5f80\u5f80\u88ab\u5ffd\u7565\u7684\u8207\u502b\u7406\u76f8\u95dc\u7684\u554f\u984c\uff0c\u5176\u4e2d\u5305\u62ec\u4f7f\u7528\u8005\u53cb\u5584\u6027\u548c\u6b3a\u9a19\u6027\u3001\u9748\u6d3b\u6027\u8207\u53ef\u89e3\u91cb\u6027\uff0c\u4ee5\u53ca\u7cfb\u7d71\u5b89\u5168\u6027\u4e4b\u9593\u7684\u6b0a\u8861\u3002\u6211\u5011\u6700\u5f8c\u6566\u4fc3\u7814\u7a76\u4eba\u54e1\u548c\u5f9e\u696d\u4eba\u54e1\u6279\u5224\u6027\u5730\u8a55\u4f30 RLxF \u7684\u793e\u6703\u6280\u8853\u5f71\u97ff\uff0c\u4e26\u5021\u5c0e\u5728 AI \u958b\u767c\u4e2d\u63a1\u7528\u66f4\u7d30\u7dfb\u4e14\u5177\u53cd\u7701\u6027\u7684\u61c9\u7528\u65b9\u6cd5\u3002", "author": "Adam Dahlgren Lindstr\u00f6m et.al.", "authors": "Adam Dahlgren Lindstr\u00f6m, Leila Methnani, Lea Krause, Petter Ericson, \u00cd\u00f1igo Mart\u00ednez de Rituerto de Troya, Dimitri Coelho Mollo, Roel Dobbe", "id": "2406.18346v1", "paper_url": "http://arxiv.org/abs/2406.18346v1", "repo": "null"}}