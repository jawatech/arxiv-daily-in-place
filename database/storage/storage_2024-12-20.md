# arxiv-daily
 Automated deployment @ 2024-12-20 20:36:12 Asia/Taipei
> Welcome to contribute! Add your topics and keywords in [`topic.yml`](https://github.com/jawatech/arxiv-daily-in-place/blob/main/database/topic.yml).
> You can also view historical data through the [storage](https://github.com/jawatech/arxiv-daily-in-place/blob/main/database/storage).

## AI

### Medical explainable AI
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-12-18**|**Cognition Chain for Explainable Psychological Stress Detection on Social Media**|Xin Wang et.al.|[2412.14009v1](http://arxiv.org/abs/2412.14009v1)|null|
|**2024-11-30**|**2-Factor Retrieval for Improved Human-AI Decision Making in Radiology**|Jim Solomon et.al.|[2412.00372v1](http://arxiv.org/abs/2412.00372v1)|null|
|**2024-11-28**|**Mapping Public Perception of Artificial Intelligence: Expectations, Risk-Benefit Tradeoffs, and Value As Determinants for Societal Acceptance**|Philipp Brauner et.al.|[2411.19356v1](http://arxiv.org/abs/2411.19356v1)|null|
|**2024-11-26**|**Explainable AI for Classifying UTI Risk Groups Using a Real-World Linked EHR and Pathology Lab Dataset**|Yujie Dai et.al.|[2411.17645v1](http://arxiv.org/abs/2411.17645v1)|null|
|**2024-11-18**|**Exploring the Requirements of Clinicians for Explainable AI Decision Support Systems in Intensive Care**|Jeffrey N. Clark et.al.|[2411.11774v1](http://arxiv.org/abs/2411.11774v1)|null|
|**2024-11-15**|**Artificial Intelligence in Pediatric Echocardiography: Exploring Challenges, Opportunities, and Clinical Applications with Explainable AI and Federated Learning**|Mohammed Yaseen Jabarulla et.al.|[2411.10255v1](http://arxiv.org/abs/2411.10255v1)|null|
|**2024-11-01**|**Enhancing Osteoporosis Detection: An Explainable Multi-Modal Learning Framework with Feature Fusion and Variable Clustering**|Mehdi Hosseini Chagahi et.al.|[2411.00916v2](http://arxiv.org/abs/2411.00916v2)|null|
|**2024-10-25**|**A Review of Deep Learning Approaches for Non-Invasive Cognitive Impairment Detection**|Muath Alsuhaibani et.al.|[2410.19898v1](http://arxiv.org/abs/2410.19898v1)|null|
|**2024-10-23**|**An Ontology-Enabled Approach For User-Centered and Knowledge-Enabled Explanations of AI Systems**|Shruthi Chari et.al.|[2410.17504v1](http://arxiv.org/abs/2410.17504v1)|[link](https://github.com/tetherless-world/metaexplainer)|
|**2024-10-22**|**Contrasting Attitudes Towards Current and Future AI Applications for Computerised Interpretation of ECG: A Clinical Stakeholder Interview Study**|Lukas Hughes-Noehrer et.al.|[2410.16879v1](http://arxiv.org/abs/2410.16879v1)|null|
|**2024-10-19**|**Pathologist-like explainable AI for interpretable Gleason grading in prostate cancer**|Gesa Mittmann et.al.|[2410.15012v1](http://arxiv.org/abs/2410.15012v1)|null|
|**2024-10-15**|**Explainable AI Methods for Multi-Omics Analysis: A Survey**|Ahmad Hussein et.al.|[2410.11910v1](http://arxiv.org/abs/2410.11910v1)|null|
|**2024-10-14**|**Study on the Helpfulness of Explainable Artificial Intelligence**|Tobias Labarta et.al.|[2410.11896v1](http://arxiv.org/abs/2410.11896v1)|[link](https://github.com/tlabarta/helpfulnessofxai)|
|**2024-10-12**|**Use of What-if Scenarios to Help Explain Artificial Intelligence Models for Neonatal Health**|Abdullah Mamun et.al.|[2410.09635v1](http://arxiv.org/abs/2410.09635v1)|[link](https://github.com/ab9mamun/aimen)|
|**2024-10-10**|**Artificial intelligence techniques in inherited retinal diseases: A review**|Han Trinh et.al.|[2410.09105v1](http://arxiv.org/abs/2410.09105v1)|null|
|**2024-10-07**|**CasiMedicos-Arg: A Medical Question Answering Dataset Annotated with Explanatory Argumentative Structures**|Ekaterina Sviridova et.al.|[2410.05235v2](http://arxiv.org/abs/2410.05235v2)|[link](https://github.com/ixa-ehu/antidote-casimedicos)|
|**2024-10-01**|**Explainable Diagnosis Prediction through Neuro-Symbolic Integration**|Qiuhao Lu et.al.|[2410.01855v1](http://arxiv.org/abs/2410.01855v1)|null|
|**2024-10-01**|**Easydiagnos: a framework for accurate feature selection for automatic diagnosis in smart healthcare**|Prasenjit Maji et.al.|[2410.00366v1](http://arxiv.org/abs/2410.00366v1)|null|
|**2024-09-20**|**Dermatologist-like explainable AI enhances melanoma diagnosis accuracy: eye-tracking study**|Tirtha Chanda et.al.|[2409.13476v1](http://arxiv.org/abs/2409.13476v1)|null|
|**2024-09-19**|**Explainable AI for Autism Diagnosis: Identifying Critical Brain Regions Using fMRI Data**|Suryansh Vidya et.al.|[2409.15374v1](http://arxiv.org/abs/2409.15374v1)|null|
|**2024-09-19**|**Improving Prototypical Parts Abstraction for Case-Based Reasoning Explanations Designed for the Kidney Stone Type Recognition**|Daniel Flores-Araiza et.al.|[2409.12883v1](http://arxiv.org/abs/2409.12883v1)|null|
|**2024-09-18**|**Towards Interpretable End-Stage Renal Disease (ESRD) Prediction: Utilizing Administrative Claims Data with Explainable AI Techniques**|Yubo Li et.al.|[2409.12087v3](http://arxiv.org/abs/2409.12087v3)|null|
|**2024-09-09**|**Explainable AI: Definition and attributes of a good explanation for health AI**|Evangelia Kyrimi et.al.|[2409.15338v1](http://arxiv.org/abs/2409.15338v1)|null|
|**2024-08-30**|**Exploring the Effect of Explanation Content and Format on User Comprehension and Trust**|Antonio Rago et.al.|[2408.17401v1](http://arxiv.org/abs/2408.17401v1)|null|
|**2024-08-29**|**A Survey for Large Language Models in Biomedicine**|Chong Wang et.al.|[2409.00133v1](http://arxiv.org/abs/2409.00133v1)|null|
|**2024-08-27**|**Aligning XAI with EU Regulations for Smart Biomedical Devices: A Methodology for Compliance Analysis**|Francesco Sovrano et.al.|[2408.15121v1](http://arxiv.org/abs/2408.15121v1)|null|
|**2024-08-24**|**Towards Case-based Interpretability for Medical Federated Learning**|Laura Latorre et.al.|[2408.13626v1](http://arxiv.org/abs/2408.13626v1)|null|
|**2024-08-22**|**AI in radiological imaging of soft-tissue and bone tumours: a systematic review evaluating against CLAIM and FUTURE-AI guidelines**|Douwe J. Spaanderman et.al.|[2408.12491v1](http://arxiv.org/abs/2408.12491v1)|null|
|**2024-08-14**|**Evaluating Explainable AI Methods in Deep Learning Models for Early Detection of Cerebral Palsy**|Kimji N. Pellano et.al.|[2409.00001v1](http://arxiv.org/abs/2409.00001v1)|null|
|**2024-08-06**|**MicroXercise: A Micro-Level Comparative and Explainable System for Remote Physical Therapy**|Hanchen David Wang et.al.|[2408.11837v1](http://arxiv.org/abs/2408.11837v1)|null|
|**2024-08-05**|**The Literature Review Network: An Explainable Artificial Intelligence for Systematic Literature Reviews, Meta-analyses, and Method Development**|Joshua Morriss et.al.|[2408.05239v1](http://arxiv.org/abs/2408.05239v1)|null|
|**2024-08-05**|**Enhancing Medical Learning and Reasoning Systems: A Boxology-Based Comparative Analysis of Design Patterns**|Chi Him Ng et.al.|[2408.02709v1](http://arxiv.org/abs/2408.02709v1)|null|
|**2024-08-05**|**Bayesian Kolmogorov Arnold Networks (Bayesian_KANs): A Probabilistic Approach to Enhance Accuracy and Interpretability**|Masoud Muhammed Hassan et.al.|[2408.02706v1](http://arxiv.org/abs/2408.02706v1)|null|
|**2024-07-26**|**MLtoGAI: Semantic Web based with Machine Learning for Enhanced Disease Prediction and Personalized Recommendations using Generative AI**|Shyam Dongre et.al.|[2407.20284v1](http://arxiv.org/abs/2407.20284v1)|null|
|**2024-07-25**|**Introducing Î´-XAI: a novel sensitivity-based method for local AI explanations**|Alessandro De Carlo et.al.|[2407.18343v2](http://arxiv.org/abs/2407.18343v2)|null|
|**2024-07-24**|**Enhanced Deep Learning Methodologies and MRI Selection Techniques for Dementia Diagnosis in the Elderly Population**|Nikolaos Ntampakis et.al.|[2407.17324v2](http://arxiv.org/abs/2407.17324v2)|null|
|**2024-07-24**|**Using Large Language Models to Compare Explainable Models for Smart Home Human Activity Recognition**|Michele Fiori et.al.|[2408.06352v1](http://arxiv.org/abs/2408.06352v1)|null|
|**2024-07-21**|**Explainable AI-based Intrusion Detection System for Industry 5.0: An Overview of the Literature, associated Challenges, the existing Solutions, and Potential Research Directions**|Naseem Khan et.al.|[2408.03335v1](http://arxiv.org/abs/2408.03335v1)|null|
|**2024-07-18**|**A Comparative Study on Automatic Coding of Medical Letters with Explainability**|Jamie Glen et.al.|[2407.13638v1](http://arxiv.org/abs/2407.13638v1)|[link](https://github.com/Glenj01/Medical-Coding)|
|**2024-07-09**|**Explainable AI for Enhancing Efficiency of DL-based Channel Estimation**|Abdul Karim Gizzini et.al.|[2407.07009v1](http://arxiv.org/abs/2407.07009v1)|null|
|**2024-07-07**|**Explainable AI: Comparative Analysis of Normal and Dilated ResNet Models for Fundus Disease Classification**|P. N. Karthikayan et.al.|[2407.05440v2](http://arxiv.org/abs/2407.05440v2)|null|
|**2024-07-03**|**A Survey on Trustworthiness in Foundation Models for Medical Image Analysis**|Congzhen Shi et.al.|[2407.15851v2](http://arxiv.org/abs/2407.15851v2)|null|
|**2024-07-01**|**The Impact of an XAI-Augmented Approach on Binary Classification with Scarce Data**|Ximing Wen et.al.|[2407.06206v1](http://arxiv.org/abs/2407.06206v1)|null|
|**2024-06-28**|**Can GPT-4 Help Detect Quit Vaping Intentions? An Exploration of Automatic Data Annotation Approach**|Sai Krishna Revanth Vuruma et.al.|[2407.00167v1](http://arxiv.org/abs/2407.00167v1)|null|
|**2024-06-25**|**Towards Compositional Interpretability for XAI**|Sean Tull et.al.|[2406.17583v1](http://arxiv.org/abs/2406.17583v1)|null|
|**2024-06-17**|**Slicing Through Bias: Explaining Performance Gaps in Medical Image Analysis using Slice Discovery Methods**|Vincent Olesen et.al.|[2406.12142v2](http://arxiv.org/abs/2406.12142v2)|[link](https://github.com/volesen/slicing-through-bias)|
|**2024-06-11**|**Unlocking the Potential of Metaverse in Innovative and Immersive Digital Health**|Fatemeh Ebrahimzadeh et.al.|[2406.07114v2](http://arxiv.org/abs/2406.07114v2)|null|
|**2024-06-10**|**AI-Driven Predictive Analytics Approach for Early Prognosis of Chronic Kidney Disease Using Ensemble Learning and Explainable AI**|K M Tawsik Jawad et.al.|[2406.06728v1](http://arxiv.org/abs/2406.06728v1)|null|
|**2024-06-10**|**Explainable AI for Mental Disorder Detection via Social Media: A survey and outlook**|Yusif Ibrahimov et.al.|[2406.05984v1](http://arxiv.org/abs/2406.05984v1)|null|
|**2024-06-09**|**Methodology and Real-World Applications of Dynamic Uncertain Causality Graph for Clinical Diagnosis with Explainability and Invariance**|Zhan Zhang et.al.|[2406.05746v1](http://arxiv.org/abs/2406.05746v1)|null|
|**2024-06-07**|**Advancing Histopathology-Based Breast Cancer Diagnosis: Insights into Multi-Modality and Explainability**|Faseela Abdullakutty et.al.|[2406.12897v1](http://arxiv.org/abs/2406.12897v1)|null|
|**2024-06-07**|**Revisiting Attention Weights as Interpretations of Message-Passing Neural Networks**|Yong-Min Shin et.al.|[2406.04612v1](http://arxiv.org/abs/2406.04612v1)|[link](https://github.com/jordan7186/gatt)|
|**2024-06-04**|**Using Explainable AI for EEG-based Reduced Montage Neonatal Seizure Detection**|Dinuka Sandun Udayantha et.al.|[2406.16908v3](http://arxiv.org/abs/2406.16908v3)|[link](https://github.com/dinuka-1999/braineocare)|
|**2024-06-01**|**Breast Cancer Diagnosis: A Comprehensive Exploration of Explainable Artificial Intelligence (XAI) Techniques**|Samita Bai et.al.|[2406.00532v1](http://arxiv.org/abs/2406.00532v1)|null|
|**2024-06-01**|**Unveiling Hidden Factors: Explainable AI for Feature Boosting in Speech Emotion Recognition**|Alaa Nfissi et.al.|[2406.01624v2](http://arxiv.org/abs/2406.01624v2)|[link](https://github.com/alaanfissi/unveiling-hidden-factors-explainable-ai-for-feature-boosting-in-speech-emotion-recognition)|
|**2024-05-31**|**The Explanation Necessity for Healthcare AI**|Michail Mamalakis et.al.|[2406.00216v1](http://arxiv.org/abs/2406.00216v1)|null|
|**2024-05-29**|**Interdisciplinary Expertise to Advance Equitable Explainable AI**|Chloe R. Bennett et.al.|[2406.18563v1](http://arxiv.org/abs/2406.18563v1)|null|
|**2024-05-27**|**"It depends": Configuring AI to Improve Clinical Usefulness Across Contexts**|Hubert D. ZajÄc et.al.|[2407.11978v1](http://arxiv.org/abs/2407.11978v1)|null|
|**2024-05-26**|**Improving Health Professionals' Onboarding with AI and XAI for Trustworthy Human-AI Collaborative Decision Making**|Min Hun Lee et.al.|[2405.16424v1](http://arxiv.org/abs/2405.16424v1)|null|
|**2024-05-26**|**Exploring Nutritional Impact on Alzheimer's Mortality: An Explainable AI Approach**|Ziming Liu et.al.|[2405.17502v1](http://arxiv.org/abs/2405.17502v1)|null|
|**2024-05-24**|**Explainable AI Enhances Glaucoma Referrals, Yet the Human-AI Team Still Falls Short of the AI Alone**|Catalina Gomez et.al.|[2407.11974v1](http://arxiv.org/abs/2407.11974v1)|null|
|**2024-05-23**|**Decoding Decision Reasoning: A Counterfactual-Powered Model for Knowledge Discovery**|Yingying Fang et.al.|[2406.18552v1](http://arxiv.org/abs/2406.18552v1)|null|
|**2024-05-21**|**The Role of Emotions in Informational Support Question-Response Pairs in Online Health Communities: A Multimodal Deep Learning Approach**|Mohsen Jozani et.al.|[2405.13099v1](http://arxiv.org/abs/2405.13099v1)|null|
|**2024-05-17**|**ChatGPT in Classrooms: Transforming Challenges into Opportunities in Education**|Harris Bin Munawar et.al.|[2405.10645v1](http://arxiv.org/abs/2405.10645v1)|null|
|**2024-05-13**|**Evaluating the Explainable AI Method Grad-CAM for Breath Classification on Newborn Time Series Data**|Camelia Oprea et.al.|[2405.07590v1](http://arxiv.org/abs/2405.07590v1)|null|
|**2024-05-10**|**XAI4LLM. Let Machine Learning Models and LLMs Collaborate for Enhanced In-Context Learning in Healthcare**|Fatemeh Nazary et.al.|[2405.06270v3](http://arxiv.org/abs/2405.06270v3)|null|
|**2024-05-09**|**To Trust or Not to Trust: Towards a novel approach to measure trust for XAI systems**|Miquel MirÃ³-Nicolau et.al.|[2405.05766v1](http://arxiv.org/abs/2405.05766v1)|null|
|**2024-05-05**|**Region-specific Risk Quantification for Interpretable Prognosis of COVID-19**|Zhusi Zhong et.al.|[2405.02815v1](http://arxiv.org/abs/2405.02815v1)|[link](https://github.com/zzs95/RSP_COVID)|
|**2024-04-26**|**Rad4XCNN: a new agnostic method for post-hoc global explanation of CNN-derived features by means of radiomics**|Francesco Prinzi et.al.|[2405.02334v1](http://arxiv.org/abs/2405.02334v1)|null|
|**2024-04-25**|**Attributing Responsibility in AI-Induced Incidents: A Computational Reflective Equilibrium Framework for Accountability**|Yunfei Ge et.al.|[2404.16957v1](http://arxiv.org/abs/2404.16957v1)|null|
|**2024-04-19**|**Explainable AI for Fair Sepsis Mortality Predictive Model**|Chia-Hsuan Chang et.al.|[2404.13139v1](http://arxiv.org/abs/2404.13139v1)|null|
|**2024-04-19**|**Multi Class Depression Detection Through Tweets using Artificial Intelligence**|Muhammad Osama Nusrat et.al.|[2404.13104v1](http://arxiv.org/abs/2404.13104v1)|[link](https://github.com/mnusrat786/masters-thesis)|
|**2024-04-19**|**COIN: Counterfactual inpainting for weakly supervised semantic segmentation for medical images**|Dmytro Shvetsov et.al.|[2404.12832v2](http://arxiv.org/abs/2404.12832v2)|[link](https://github.com/dmytro-shvetsov/counterfactual-search)|
|**2024-04-15**|**Hybrid Intelligence for Digital Humanities**|Victor de Boer et.al.|[2406.15374v1](http://arxiv.org/abs/2406.15374v1)|null|
|**2024-04-14**|**Ethical Framework for Responsible Foundational Models in Medical Imaging**|Abhijit Das et.al.|[2406.11868v1](http://arxiv.org/abs/2406.11868v1)|null|
|**2024-04-09**|**Advancements in Radiomics and Artificial Intelligence for Thyroid Cancer Diagnosis**|Milad Yousefi et.al.|[2404.07239v1](http://arxiv.org/abs/2404.07239v1)|null|
|**2024-04-06**|**Predictive Modeling for Breast Cancer Classification in the Context of Bangladeshi Patients: A Supervised Machine Learning Approach with Explainable AI**|Taminul Islam et.al.|[2404.04686v1](http://arxiv.org/abs/2404.04686v1)|null|
|**2024-04-05**|**Enhancing Breast Cancer Diagnosis in Mammography: Evaluation and Integration of Convolutional Neural Networks and Explainable AI**|Maryam Ahmed et.al.|[2404.03892v3](http://arxiv.org/abs/2404.03892v3)|null|
|**2024-03-30**|**Advancing Multimodal Data Fusion in Pain Recognition: A Strategy Leveraging Statistical Correlation and Human-Centered Perspectives**|Xingrui Gu et.al.|[2404.00320v2](http://arxiv.org/abs/2404.00320v2)|null|
|**2024-03-26**|**Addressing Social Misattributions of Large Language Models: An HCXAI-based Approach**|Andrea Ferrario et.al.|[2403.17873v1](http://arxiv.org/abs/2403.17873v1)|null|
|**2024-03-26**|**Clinical Domain Knowledge-Derived Template Improves Post Hoc AI Explanations in Pneumothorax Classification**|Han Yuan et.al.|[2403.18871v1](http://arxiv.org/abs/2403.18871v1)|[link](https://github.com/han-yuan-med/template-explanation)|
|**2024-03-03**|**Enhancing Neural Machine Translation of Low-Resource Languages: Corpus Development, Human Evaluation and Explainable AI Architectures**|SÃ©amus Lankford et.al.|[2403.01580v1](http://arxiv.org/abs/2403.01580v1)|null|
|**2024-02-28**|**Cause and Effect: Can Large Language Models Truly Understand Causality?**|Swagata Ashwani et.al.|[2402.18139v3](http://arxiv.org/abs/2402.18139v3)|null|
|**2024-02-28**|**Artificial Intelligence and Diabetes Mellitus: An Inside Look Through the Retina**|Yasin Sadeghi Bazargani et.al.|[2402.18600v1](http://arxiv.org/abs/2402.18600v1)|null|
|**2024-02-22**|**Multi-stakeholder Perspective on Responsible Artificial Intelligence and Acceptability in Education**|A. J. Karran et.al.|[2402.15027v2](http://arxiv.org/abs/2402.15027v2)|null|
|**2024-02-12**|**Deciphering Heartbeat Signatures: A Vision Transformer Approach to Explainable Atrial Fibrillation Detection from ECG Signals**|Aruna Mohan et.al.|[2402.09474v2](http://arxiv.org/abs/2402.09474v2)|null|
|**2024-02-05**|**Illuminate: A novel approach for depression detection with explainable analysis and proactive therapy using prompt engineering**|Aryan Agrawal et.al.|[2402.05127v1](http://arxiv.org/abs/2402.05127v1)|null|
|**2024-01-24**|**Information That Matters: Exploring Information Needs of People Affected by Algorithmic Decisions**|TimothÃ©e Schmude et.al.|[2401.13324v6](http://arxiv.org/abs/2401.13324v6)|null|
|**2024-01-02**|**Evaluating Large Language Models on the GMAT: Implications for the Future of Business Education**|Vahid Ashrafimoghari et.al.|[2401.02985v1](http://arxiv.org/abs/2401.02985v1)|null|
|**2023-12-29**|**XAI for In-hospital Mortality Prediction via Multimodal ICU Data**|Xingqiao Li et.al.|[2312.17624v1](http://arxiv.org/abs/2312.17624v1)|[link](https://github.com/lixingqiao/xai-icu)|
|**2023-12-22**|**Joining Forces for Pathology Diagnostics with AI Assistance: The EMPAIA Initiative**|Norman Zerbe et.al.|[2401.09450v2](http://arxiv.org/abs/2401.09450v2)|null|
|**2023-12-18**|**Robust Stochastic Graph Generator for Counterfactual Explanations**|Mario Alfonso Prado-Romero et.al.|[2312.11747v2](http://arxiv.org/abs/2312.11747v2)|null|
|**2023-12-10**|**Evaluating the Utility of Model Explanations for Model Development**|Shawn Im et.al.|[2312.06032v1](http://arxiv.org/abs/2312.06032v1)|null|
|**2023-12-05**|**Building Trustworthy NeuroSymbolic AI Systems: Consistency, Reliability, Explainability, and Safety**|Manas Gaur et.al.|[2312.06798v1](http://arxiv.org/abs/2312.06798v1)|null|
|**2023-12-04**|**Class-Discriminative Attention Maps for Vision Transformers**|Lennart Brocki et.al.|[2312.02364v3](http://arxiv.org/abs/2312.02364v3)|null|
|**2023-11-28**|**Deployment of a Robust and Explainable Mortality Prediction Model: The COVID-19 Pandemic and Beyond**|Jacob R. Epifano et.al.|[2311.17133v1](http://arxiv.org/abs/2311.17133v1)|null|
|**2023-11-27**|**Variational Autoencoders for Feature Exploration and Malignancy Prediction of Lung Lesions**|Benjamin Keel et.al.|[2311.15719v1](http://arxiv.org/abs/2311.15719v1)|[link](https://github.com/benkeel/vae_lung_lesion_bmvc)|
|**2023-11-24**|**MRxaI: Black-Box Explainability for Image Classifiers in a Medical Setting**|Nathan Blake et.al.|[2311.14471v1](http://arxiv.org/abs/2311.14471v1)|null|
|**2023-11-21**|**Moderating Model Marketplaces: Platform Governance Puzzles for AI Intermediaries**|Robert Gorwa et.al.|[2311.12573v3](http://arxiv.org/abs/2311.12573v3)|null|
|**2023-11-20**|**Ovarian Cancer Data Analysis using Deep Learning: A Systematic Review from the Perspectives of Key Features of Data Analysis and AI Assurance**|Muta Tah Hira et.al.|[2311.11932v1](http://arxiv.org/abs/2311.11932v1)|null|

#### Abstracts
##### **Cognition Chain for Explainable Psychological Stress Detection on Social Media**
2412.14009v1 by Xin Wang, Boyan Gao, Yi Dai, Lei Cao, Liang Zhao, Yibo Yang, David Clifton

Stress is a pervasive global health issue that can lead to severe mental
health problems. Early detection offers timely intervention and prevention of
stress-related disorders. The current early detection models perform "black
box" inference suffering from limited explainability and trust which blocks the
real-world clinical application. Thanks to the generative properties introduced
by the Large Language Models (LLMs), the decision and the prediction from such
models are semi-interpretable through the corresponding description. However,
the existing LLMs are mostly trained for general purposes without the guidance
of psychological cognitive theory. To this end, we first highlight the
importance of prior theory with the observation of performance boosted by the
chain-of-thoughts tailored for stress detection. This method termed Cognition
Chain explicates the generation of stress through a step-by-step cognitive
perspective based on cognitive appraisal theory with a progress pipeline:
Stimulus $\rightarrow$ Evaluation $\rightarrow$ Reaction $\rightarrow$ Stress
State, guiding LLMs to provide comprehensive reasoning explanations. We further
study the benefits brought by the proposed Cognition Chain format by utilising
it as a synthetic dataset generation template for LLMs instruction-tuning and
introduce CogInstruct, an instruction-tuning dataset for stress detection. This
dataset is developed using a three-stage self-reflective annotation pipeline
that enables LLMs to autonomously generate and refine instructional data. By
instruction-tuning Llama3 with CogInstruct, we develop CogLLM, an explainable
stress detection model. Evaluations demonstrate that CogLLM achieves
outstanding performance while enhancing explainability. Our work contributes a
novel approach by integrating cognitive theories into LLM reasoning processes,
offering a promising direction for future explainable AI research.

æè¦ï¼å£åæ¯ä¸åæ®éçå¨çæ§å¥åº·åé¡ï¼å¯è½æå°è´å´éçç²¾ç¥
å¥åº·åé¡ãæ©æç¼ç¾æä¾åæçå¹²é åé é²
å£åç¸éç¾çãç®åçæ©æç¼ç¾æ¨¡åå·è¡ãé»
çå­ãæ¨è«ï¼å­å¨å¯è§£éæ§åä¿¡ä»»åº¦æéçåé¡ï¼é»ç¤äº
ç¾å¯¦ä¸ççè¨åºæç¨ãå¤è§äºå¤§åèªè¨æ¨¡å (LLM) å¼å¥ççæå±¬æ§ï¼æ­¤é¡
æ¨¡åçæ±ºç­åé æ¸¬ééå°ææè¿°å·æåå¯è§£éæ§ãç¶èï¼
ç¾æç LLM ä¸»è¦éå°ä¸è¬ç¨éé²è¡è¨ç·´ï¼æ²æå¿çèªç¥çè«çæå°ãçºæ­¤ï¼æåé¦åå¼·èª¿
åé©çè«çéè¦æ§ï¼ä¸¦è§å¯å°éå°å£åæª¢æ¸¬éèº«å®å¶çææ³éæåäºæ§è½ãéç¨®æ¹æ³ç¨±çºèªç¥
éééåºæ¼èªç¥è©ä¼°çè«çå¾ªåºæ¼¸é²çèªç¥è¦è§é¡æäºå£åçç¢çï¼ä¸¦å·æé²åº¦ç®¡éï¼
åºæ¿ $\rightarrow$ è©ä¼° $\rightarrow$ åæ $\rightarrow$ å£å
çæï¼æå° LLM æä¾å¨é¢çæ¨çè§£éãæåé²ä¸æ­¥
ééå°å¶ç¨ä½ LLM æä»¤èª¿æ´çåææ¸æéçææ¨¡æ¿ä¾ç ç©¶ææåºçèªç¥éæ ¼å¼å¸¶ä¾çåªé»ï¼ä¸¦ä»ç´¹ CogInstructï¼éæ¯ä¸åéå°å£åæª¢æ¸¬çæä»¤èª¿æ´æ¸æéãéå
æ¸æéæ¯ä½¿ç¨ä¸åä¸éæ®µçèªçæ¨è¨»ç®¡ééç¼çï¼ä½¿ LLM è½å¤ èªä¸»çæååªåæä»¤æ¸æãéé
ä½¿ç¨ CogInstruct å° Llama3 é²è¡æä»¤èª¿æ´ï¼æåéç¼äº CogLLMï¼éæ¯ä¸åå¯è§£éç
å£åæª¢æ¸¬æ¨¡åãè©ä¼°è¡¨æï¼CogLLM å¨æé«å¯è§£éæ§çåæå¯¦ç¾äºåºè²çæ§è½ãæåçç ç©¶ééå°èªç¥çè«æ´åå° LLM æ¨çéç¨ä¸­ï¼æåºäºä¸ç¨®æ°ç©çæ¹æ³ï¼
çºæªä¾çå¯è§£éäººå·¥æºè½ç ç©¶æä¾äºä¸åæå¸æçæ¹åã

##### **2-Factor Retrieval for Improved Human-AI Decision Making in Radiology**
2412.00372v1 by Jim Solomon, Laleh Jalilian, Alexander Vilesov, Meryl Mathew, Tristan Grogan, Arash Bedayat, Achuta Kadambi

Human-machine teaming in medical AI requires us to understand to what degree
a trained clinician should weigh AI predictions. While previous work has shown
the potential of AI assistance at improving clinical predictions, existing
clinical decision support systems either provide no explainability of their
predictions or use techniques like saliency and Shapley values, which do not
allow for physician-based verification. To address this gap, this study
compares previously used explainable AI techniques with a newly proposed
technique termed '2-factor retrieval (2FR)', which is a combination of
interface design and search retrieval that returns similarly labeled data
without processing this data. This results in a 2-factor security blanket
where: (a) correct images need to be retrieved by the AI; and (b) humans should
associate the retrieved images with the current pathology under test. We find
that when tested on chest X-ray diagnoses, 2FR leads to increases in clinician
accuracy, with particular improvements when clinicians are radiologists and
have low confidence in their decision. Our results highlight the importance of
understanding how different modes of human-AI decision making may impact
clinician accuracy in clinical decision support systems.

æè¦ï¼äººæ©åä½å¨é«ç AI ä¸­ï¼éè¦æåçè§£åéè¨ç·´çè¨åºé«çå¨å¤å¤§ç¨åº¦ä¸æéè¦ AI é æ¸¬ãéç¶ååçç ç©¶é¡¯ç¤º AI è¼å©å¨æ¹åè¨åºé æ¸¬æ¹é¢çæ½åï¼ä½ç¾æçè¨åºæ±ºç­æ¯æ´ç³»çµ±ï¼è¦ä¸å°±æ²ææä¾é æ¸¬çå¯è§£éæ§ï¼è¦ä¸å°±æ¯ä½¿ç¨åé¡¯èæ§å Shapley å¼ä¹é¡çæè¡ï¼éäºæè¡ä¸åè¨±åºæ¼é«ççé©è­ãçºäºè§£æ±ºéåå·®è·ï¼æ¬ç ç©¶å°ååä½¿ç¨çå¯è§£é AI æè¡èä¸ç¨®æ°æåºçç¨±çºã2 å å­æª¢ç´¢ (2FR)ãçæè¡é²è¡æ¯è¼ï¼å¾èæ¯ä¸ç¨®ä»é¢è¨­è¨åæå°æª¢ç´¢ççµåï¼å®æå³åæ¨ç±¤ç¸ä¼¼çè³æï¼èä¸æèçéäºè³æãéæç¢çä¸å 2 å å­å®å¨æ©å¶ï¼å¶ä¸­ï¼(a) æ­£ç¢ºçå½±åéè¦ç± AI æª¢ç´¢ï¼(b) äººé¡æå°æª¢ç´¢çå½±åèæ­£å¨æ¸¬è©¦ä¸­çççè¯æ³èµ·ä¾ãæåç¼ç¾ï¼ç¶å¨è¸é¨ X åè¨ºæ·ä¸é²è¡æ¸¬è©¦æï¼2FR ææé«è¨åºé«ççæºç¢ºåº¦ï¼ç¹å¥æ¯å¨è¨åºé«çæ¯æ¾å°ç§é«çä¸å°å¶æ±ºç­ä¿¡å¿ä¸è¶³æï¼ææé¡¯èçæ¹åãæåççµæå¼·èª¿äºçè§£äººæ©æ±ºç­çä¸åæ¨¡å¼å¦ä½å½±é¿è¨åºé«çå¨è¨åºæ±ºç­æ¯æ´ç³»çµ±ä¸­çæºç¢ºæ§çéè¦æ§ã

##### **Mapping Public Perception of Artificial Intelligence: Expectations, Risk-Benefit Tradeoffs, and Value As Determinants for Societal Acceptance**
2411.19356v1 by Philipp Brauner, Felix Glawe, Gian Luca Liehner, Luisa Vervier, Martina Ziefle

Understanding public perception of artificial intelligence (AI) and the
tradeoffs between potential risks and benefits is crucial, as these perceptions
might shape policy decisions, influence innovation trajectories for successful
market strategies, and determine individual and societal acceptance of AI
technologies. Using a representative sample of 1100 participants from Germany,
this study examines mental models of AI. Participants quantitatively evaluated
71 statements about AI's future capabilities (e.g., autonomous driving, medical
care, art, politics, warfare, and societal divides), assessing the expected
likelihood of occurrence, perceived risks, benefits, and overall value. We
present rankings of these projections alongside visual mappings illustrating
public risk-benefit tradeoffs. While many scenarios were deemed likely,
participants often associated them with high risks, limited benefits, and low
overall value. Across all scenarios, 96.4% ($r^2=96.4\%$) of the variance in
value assessment can be explained by perceived risks ($\beta=-.504$) and
perceived benefits ($\beta=+.710$), with no significant relation to expected
likelihood. Demographics and personality traits influenced perceptions of
risks, benefits, and overall evaluations, underscoring the importance of
increasing AI literacy and tailoring public information to diverse user needs.
These findings provide actionable insights for researchers, developers, and
policymakers by highlighting critical public concerns and individual factors
essential to align AI development with individual values.

æè¦ï¼<paragraph>äºè§£å¬ç¾å°äººå·¥æºæ§ (AI) çèªç¥ä»¥åæ½å¨é¢¨éªèå¥½èä¹éçæ¬è¡¡è³ééè¦ï¼å çºéäºèªç¥å¯è½æå½±é¿æ¿ç­æ±ºç­ãå½±é¿æåå¸å ´ç­ç¥çåµæ°è»è·¡ï¼ä¸¦æ±ºå®åäººåç¤¾æå° AI æè¡çæ¥ååº¦ãæ¬ç ç©¶ä½¿ç¨ä¾èªå¾·åç 1100 ååèèçä»£è¡¨æ§æ¨£æ¬ï¼æ¢è¨äº AI çå¿æºæ¨¡åãåèèå° 71 é éæ¼ AI æªä¾è½åçé³è¿°ï¼ä¾å¦ï¼èªåé§é§ãé«çä¿å¥ãèè¡ãæ¿æ²»ãæ°ç­åç¤¾æåæ­§ï¼é²è¡äºå®éè©ä¼°ï¼è©ä¼°é æçç¼çå¯è½æ§ãæç¥é¢¨éªãå¥½èåæ´é«å¹å¼ãæåå±ç¤ºäºéäºé æ¸¬çæåï¼ä¸¦éä¸è¦è¦ºåæ å°ï¼èªªæäºå¬ç¾çé¢¨éªæ¶çæ¬è¡¡ãåç®¡è¨±å¤å ´æ¯è¢«èªçºæ¯å¯è½çï¼ä½åèèéå¸¸å°å®åèé«é¢¨éªãæéçå¥½èåä½æ´é«å¹å¼è¯ç¹«èµ·ä¾ãå¨ææå ´æ¯ä¸­ï¼96.4% ($r^2=96.4\%$) çå¹å¼è©ä¼°å·®ç°å¯ä»¥ç¨æç¥é¢¨éª ($\beta=-.504$) åæç¥å¥½è ($\beta=+.710$) ä¾è§£éï¼èé æçå¯è½æ§æ²æé¡¯èéä¿ãäººå£çµ±è¨åäººæ ¼ç¹è³ªå½±é¿äºå°é¢¨éªãå¥½èåæ´é«è©ä¼°ççæ³ï¼éå¸é¡¯äºæé« AI ç´ é¤åæ ¹æä¸åçä½¿ç¨èéæ±èª¿æ´å¬å±è³è¨çéè¦æ§ãéäºç¼ç¾ééå¼·èª¿ééµçå¬å±éæ³¨åèåäººå¹å¼è§ä¸è´ç AI éç¼å¿ä¸å¯å°çåäººå ç´ ï¼çºç ç©¶äººå¡ãéç¼äººå¡åæ¿ç­å¶å®èæä¾äºå¯è¡çè¦è§£ã</paragraph>

##### **Explainable AI for Classifying UTI Risk Groups Using a Real-World Linked EHR and Pathology Lab Dataset**
2411.17645v1 by Yujie Dai, Brian Sullivan, Axel Montout, Amy Dillon, Chris Waller, Peter Acs, Rachel Denholm, Philip Williams, Alastair D Hay, Raul Santos-Rodriguez, Andrew Dowsey

The use of machine learning and AI on electronic health records (EHRs) holds
substantial potential for clinical insight. However, this approach faces
significant challenges due to data heterogeneity, sparsity, temporal
misalignment, and limited labeled outcomes. In this context, we leverage a
linked EHR dataset of approximately one million de-identified individuals from
Bristol, North Somerset, and South Gloucestershire, UK, to characterize urinary
tract infections (UTIs) and develop predictive models focused on data quality,
fairness and transparency. A comprehensive data pre-processing and curation
pipeline transforms the raw EHR data into a structured format suitable for AI
modeling. Given the limited availability and biases of ground truth UTI
outcomes, we introduce a UTI risk estimation framework informed by clinical
expertise to estimate UTI risk across individual patient timelines. Using this
framework, we built pairwise XGBoost models to differentiate UTI risk
categories with explainable AI techniques to identify key predictors while
ensuring interpretability. Our findings reveal differences in clinical and
demographic factors across risk groups, offering insights into UTI risk
stratification and progression. This study demonstrates the added value of
AI-driven insights into UTI clinical decision-making while prioritizing
interpretability, transparency, and fairness, underscoring the importance of
sound data practices in advancing health outcomes.

æè¦ï¼æ©å¨å­¸ç¿åäººå·¥æºæ§å¨é»å­å¥åº·ç´é (EHR) ä¸çæç¨å·æ
è¨åºè¦è§£çå·¨å¤§æ½åãç¶èï¼éç¨®æ¹æ³ç±æ¼è³æç°è³ªæ§ãç¨çæ§ãæéé¯ä½åæ¨è¨çµææéï¼å æ­¤é¢è¨éå¤§ææ°ãå¨æ­¤èæ¯ä¸ï¼æåå©ç¨ä¾èªè±åå¸éæ¯æãåè©é»å¡ç¹é¡ååæ ¼æ´æ¯ç¹é¡çå¤§ç´ä¸ç¾è¬åå»è­å¥ååäººçé£çµå¼ EHR è³æéï¼ä»¥æè¿°æ³å°¿éææ (UTI) ä¸¦éç¼å°æ³¨æ¼è³æåè³ªãå¬å¹³æ§åéæåº¦çé æ¸¬æ¨¡åãå¨é¢çè³æåèçåæ´çç®¡éå°åå§ EHR è³æè½æçºé©å AI å»ºæ¨¡ççµæ§åæ ¼å¼ãéæ¼å¯¦é UTI çµæçå¯ç¨æ§æéååè¦ï¼æåå¼å¥äºä¸åç±è¨åºå°æ¥­ç¥è­æä¾è³è¨ç UTI é¢¨éªè©ä¼°æ¶æ§ï¼ä»¥ä¼°è¨åäººæ£èæéç·ä¸ç UTI é¢¨éªãä½¿ç¨æ­¤æ¶æ§ï¼æåå»ºç«äºæå°ç XGBoost æ¨¡åï¼ä»¥åå UTI é¢¨éªé¡å¥ï¼ä¸¦ä½¿ç¨å¯è§£éç AI æè¡ä¾è­å¥ééµé æ¸¬å å­ï¼åæç¢ºä¿å¯è§£éæ§ãæåçç ç©¶çµææ­ç¤ºäºä¸åé¢¨éªç¾¤çµçè¨åºåäººå£çµ±è¨å ç´ çå·®ç°ï¼æä¾äºå° UTI é¢¨éªåå±¤åé²å±çè¦è§£ãæ¬ç ç©¶å±ç¤ºäº AI é©åçè¦è§£å¨ UTI è¨åºæ±ºç­ä¸­çéå å¹å¼ï¼åæåªåèæ®å¯è§£éæ§ãéæåº¦åå¬å¹³æ§ï¼å¼·èª¿äºå¥å¨è³æå¯¦åå¨ä¿é²å¥åº·çµæä¸­çéè¦æ§ã

##### **Exploring the Requirements of Clinicians for Explainable AI Decision Support Systems in Intensive Care**
2411.11774v1 by Jeffrey N. Clark, Matthew Wragg, Emily Nielsen, Miquel Perello-Nieto, Nawid Keshtmand, Michael Ambler, Shiv Sharma, Christopher P. Bourdeaux, Amberly Brigden, Raul Santos-Rodriguez

There is a growing need to understand how digital systems can support
clinical decision-making, particularly as artificial intelligence (AI) models
become increasingly complex and less human-interpretable. This complexity
raises concerns about trustworthiness, impacting safe and effective adoption of
such technologies. Improved understanding of decision-making processes and
requirements for explanations coming from decision support tools is a vital
component in providing effective explainable solutions. This is particularly
relevant in the data-intensive, fast-paced environments of intensive care units
(ICUs). To explore these issues, group interviews were conducted with seven ICU
clinicians, representing various roles and experience levels. Thematic analysis
revealed three core themes: (T1) ICU decision-making relies on a wide range of
factors, (T2) the complexity of patient state is challenging for shared
decision-making, and (T3) requirements and capabilities of AI decision support
systems. We include design recommendations from clinical input, providing
insights to inform future AI systems for intensive care.

æè¦ï¼é¨èäººå·¥æºæ§ (AI) æ¨¡åè®å¾è¶ä¾è¶è¤éï¼ä¸è¶ä¾è¶é£ä»¥è¢«äººçè§£ï¼äºè§£æ¸ä½ç³»çµ±å¦ä½æ¯æ´è¨åºæ±ºç­çéæ±ä¹æ¥çå¢å ãéç¨®è¤éæ§å¼ç¼äºå°å¯ä¿¡åº¦ççæ®ï¼å½±é¿äºæ­¤é¡æè¡çå®å¨ä¸æææ¡ç¨ãæ¹åå°æ±ºç­å¶å®æµç¨ççè§£ï¼ä»¥åå°æ±ºç­æ¯æ´å·¥å·ææä¾èªªæçè¦æ±ï¼æ¯æä¾ææå¯è§£éè§£æ±ºæ¹æ¡çéè¦çµæé¨åãéå¨è³æå¯éãå¿«ç¯å¥çå è­·çæ¿ (ICU) ç°å¢ä¸­ç¹å¥ç¸éãçºäºæ¢è¨éäºåé¡ï¼å°ä¸ä½ ICU è¨åºé«å¸«é²è¡äºå°çµè¨ªè«ï¼éäºé«å¸«ä»£è¡¨äºä¸åçè§è²åç¶é©å±¤ç´ãä¸»é¡åææ­é²äºä¸åæ ¸å¿ä¸»é¡ï¼(T1) ICU æ±ºç­å¶å®ä¾è³´æ¼å»£æ³çå ç´ ï¼(T2) çæ£çæçè¤éæ§å°å±åæ±ºç­å¶å®æ§æææ°ï¼ä»¥å (T3) AI æ±ºç­æ¯æ´ç³»çµ±çè¦æ±åè½åãæåç´å¥äºè¨åºè¼¸å¥çè¨­è¨å»ºè­°ï¼æä¾è¦è§£ä»¥æä¾è³è¨çµ¦æªä¾ç¨æ¼å è­·ç AI ç³»çµ±ã

##### **Artificial Intelligence in Pediatric Echocardiography: Exploring Challenges, Opportunities, and Clinical Applications with Explainable AI and Federated Learning**
2411.10255v1 by Mohammed Yaseen Jabarulla, Theodor Uden, Thomas Jack, Philipp Beerbaum, Steffen Oeltze-Jafra

Pediatric heart diseases present a broad spectrum of congenital and acquired
diseases. More complex congenital malformations require a differentiated and
multimodal decision-making process, usually including echocardiography as a
central imaging method. Artificial intelligence (AI) offers considerable
promise for clinicians by facilitating automated interpretation of pediatric
echocardiography data. However, adapting AI technologies for pediatric
echocardiography analysis has challenges such as limited public data
availability, data privacy, and AI model transparency. Recently, researchers
have focused on disruptive technologies, such as federated learning (FL) and
explainable AI (XAI), to improve automatic diagnostic and decision support
workflows. This study offers a comprehensive overview of the limitations and
opportunities of AI in pediatric echocardiography, emphasizing the synergistic
workflow and role of XAI and FL, identifying research gaps, and exploring
potential future developments. Additionally, three relevant clinical use cases
demonstrate the functionality of XAI and FL with a focus on (i) view
recognition, (ii) disease classification, (iii) segmentation of cardiac
structures, and (iv) quantitative assessment of cardiac function.

æè¦ï¼å°åå¿èç¾çåç¾åå¤©æ§èå¾å¤©æ§ç¾ççå»£æ³åè­ãè¼è¤éçåå¤©æ§ç¸å½¢éè¦ä¸åå·®ç°åä¸å¤æ¨¡å¼çæ±ºç­éç¨ï¼éå¸¸åæ¬è¶é³æ³¢æª¢æ¥ä½çºä¸»è¦çå½±åæ¹æ³ãäººå·¥æºæ§ (AI) çºè¨åºé«çæä¾äºç¸ç¶å¤§çå¸æï¼å çºå®å¯ä»¥ä¿é²å°åè¶é³æ³¢æª¢æ¥è³æçèªååè§£è®ãç¶èï¼å°äººå·¥æºæ§æè¡æç¨æ¼å°åè¶é³æ³¢æª¢æ¥åææè¨±å¤ææ°ï¼ä¾å¦æéçå¬éè³æå¯ç¨æ§ãè³æé±ç§åäººå·¥æºæ§æ¨¡åéæåº¦ãæè¿ï¼ç ç©¶äººå¡å°æ³¨æ¼ç ´å£æ§æè¡ï¼ä¾å¦è¯åå­¸ç¿ (FL) åå¯è§£éäººå·¥æºæ§ (XAI)ï¼ä»¥æ¹åèªåè¨ºæ·åæ±ºç­æ¯æ´å·¥ä½æµç¨ãæ¬ç ç©¶æä¾äºäººå·¥æºæ§å¨å°åè¶é³æ³¢æª¢æ¥ä¸­çéå¶åæ©æçå¨é¢æ¦è¿°ï¼å¼·èª¿äº XAI å FL çååå·¥ä½æµç¨åè§è²ï¼æ¾åºç ç©¶å·®è·ä¸¦æ¢è¨æ½å¨çæªä¾ç¼å±ãæ­¤å¤ï¼ä¸åç¸éçè¨åºä½¿ç¨æ¡ä¾å±ç¤ºäº XAI å FL çåè½ï¼éé»å¨æ¼ (i) æª¢è¦è¾¨è­ã(ii) ç¾çåé¡ã(iii) å¿èçµæ§åå²å (iv) å¿èåè½çéåè©ä¼°ã

##### **Enhancing Osteoporosis Detection: An Explainable Multi-Modal Learning Framework with Feature Fusion and Variable Clustering**
2411.00916v2 by Mehdi Hosseini Chagahi, Saeed Mohammadi Dashtaki, Niloufar Delfan, Nadia Mohammadi, Alireza Samari, Behzad Moshiri, Md. Jalil Piran, Oliver Faust

Osteoporosis is a common condition that increases fracture risk, especially
in older adults. Early diagnosis is vital for preventing fractures, reducing
treatment costs, and preserving mobility. However, healthcare providers face
challenges like limited labeled data and difficulties in processing medical
images. This study presents a novel multi-modal learning framework that
integrates clinical and imaging data to improve diagnostic accuracy and model
interpretability. The model utilizes three pre-trained networks-VGG19,
InceptionV3, and ResNet50-to extract deep features from X-ray images. These
features are transformed using PCA to reduce dimensionality and focus on the
most relevant components. A clustering-based selection process identifies the
most representative components, which are then combined with preprocessed
clinical data and processed through a fully connected network (FCN) for final
classification. A feature importance plot highlights key variables, showing
that Medical History, BMI, and Height were the main contributors, emphasizing
the significance of patient-specific data. While imaging features were
valuable, they had lower importance, indicating that clinical data are crucial
for accurate predictions. This framework promotes precise and interpretable
predictions, enhancing transparency and building trust in AI-driven diagnoses
for clinical integration.

æè¦ï¼éª¨è³ªçé¬çæ¯ä¸ç¨®å¸¸è¦çç¾çï¼æå¢å éª¨æçé¢¨éªï¼ç¹å¥æ¯èå¹´äººãæ©æè¨ºæ·å°æ¼é é²éª¨æãéä½æ²»çææ¬åç¶­æè¡åè½åè³ééè¦ãç¶èï¼é«çä¿å¥æä¾èé¢è¨èæ¨è¨æ¸ææéåèçé«å­¸å½±åå°é£ç­ææ°ãæ¬ç ç©¶æåºäºä¸åæ°ç©çå¤æ¨¡å¼å­¸ç¿æ¡æ¶ï¼è©²æ¡æ¶æ´åäºè¨åºåå½±åæ¸æï¼ä»¥æé«è¨ºæ·æºç¢ºæ§åæ¨¡åå¯è§£éæ§ãè©²æ¨¡åå©ç¨ä¸åé è¨ç·´çç¶²è·¯ï¼VGG19ãInceptionV3 å ResNet50ï¼å¾ X å°ç·å½±åä¸­æåæ·±åº¦ç¹å¾µãéäºç¹å¾µä½¿ç¨ PCA è½æä»¥éä½ç¶­åº¦ä¸¦å°æ³¨æ¼æç¸éççµæé¨åãåºæ¼èé¡çé¸æéç¨è­å¥åºæå·ä»£è¡¨æ§ççµæé¨åï¼ç¶å¾å°éäºçµæé¨åèé èççè¨åºæ¸æçµåï¼ä¸¦ééå¨é£æ¥ç¶²è·¯ (FCN) é²è¡æçµåé¡ãç¹å¾µéè¦æ§åçªåºäºééµè®æ¸ï¼è¡¨æçå²ãBMI åèº«é«æ¯ä¸»è¦è²¢ç»å ç´ ï¼å¼·èª¿äºæ£èç¹å®æ¸æçéè¦æ§ãéç¶å½±åç¹å¾µå¾æå¹å¼ï¼ä½å®åçéè¦æ§è¼ä½ï¼éè¡¨æè¨åºæ¸æå°æ¼æºç¢ºé æ¸¬è³ééè¦ãæ­¤æ¡æ¶ä¿è¿äºæºç¢ºä¸å¯è§£éçé æ¸¬ï¼æé«äºéæåº¦ï¼ä¸¦å»ºç«äºå° AI é©åè¨ºæ·å¨è¨åºæ´åä¸­çä¿¡ä»»ã

##### **A Review of Deep Learning Approaches for Non-Invasive Cognitive Impairment Detection**
2410.19898v1 by Muath Alsuhaibani, Ali Pourramezan Fard, Jian Sun, Farida Far Poor, Peter S. Pressman, Mohammad H. Mahoor

This review paper explores recent advances in deep learning approaches for
non-invasive cognitive impairment detection. We examine various non-invasive
indicators of cognitive decline, including speech and language, facial, and
motoric mobility. The paper provides an overview of relevant datasets,
feature-extracting techniques, and deep-learning architectures applied to this
domain. We have analyzed the performance of different methods across modalities
and observed that speech and language-based methods generally achieved the
highest detection performance. Studies combining acoustic and linguistic
features tended to outperform those using a single modality. Facial analysis
methods showed promise for visual modalities but were less extensively studied.
Most papers focused on binary classification (impaired vs. non-impaired), with
fewer addressing multi-class or regression tasks. Transfer learning and
pre-trained language models emerged as popular and effective techniques,
especially for linguistic analysis. Despite significant progress, several
challenges remain, including data standardization and accessibility, model
explainability, longitudinal analysis limitations, and clinical adaptation.
Lastly, we propose future research directions, such as investigating
language-agnostic speech analysis methods, developing multi-modal diagnostic
systems, and addressing ethical considerations in AI-assisted healthcare. By
synthesizing current trends and identifying key obstacles, this review aims to
guide further development of deep learning-based cognitive impairment detection
systems to improve early diagnosis and ultimately patient outcomes.

æè¦ï¼æ¬ç¯è©è«æ¢è¨äºæ·±åº¦å­¸ç¿æ¹æ³å¨éä¾µå¥å¼èªç¥åè½éç¤æª¢æ¸¬ä¸çææ°é²å±ãæåæª¢è¦äºåç¨®éä¾µå¥å¼çèªç¥è¡°éææ¨ï¼åæ¬èªè¨åèªè¨ãé¢é¨åéåæ©è½ãæ¬ææ¦è¿°äºèæ­¤é åç¸éçè³æéãç¹å¾µæåæè¡åæ·±åº¦å­¸ç¿æ¶æ§ãæååæäºä¸åæ¹æ³å¨ä¸åæ¹å¼ä¸çè¡¨ç¾ï¼ä¸¦è§å¯å°åºæ¼èªè¨åèªè¨çæ¹æ³éå¸¸è½éå°æé«çæª¢æ¸¬è¡¨ç¾ãçµåè²å­¸åèªè¨ç¹å¾µçç ç©¶å¾å¾åªæ¼ä½¿ç¨å®ä¸æ¹å¼çç ç©¶ãé¢é¨åææ¹æ³é¡¯ç¤ºåºè¦è¦ºæ¹å¼çæ½åï¼ä½ç ç©¶è¼å°ãå¤§å¤æ¸è«æå°æ³¨æ¼äºååé¡ï¼åæèæªåæï¼ï¼è¼å°æ¢è¨å¤é¡æåæ­¸ä»»åãé·ç§»å­¸ç¿åé è¨ç·´èªè¨æ¨¡åå·²æçºæµè¡ä¸ææçæè¡ï¼ç¹å¥æ¯å°æ¼èªè¨åæãåç®¡åå¾äºéå¤§é²å±ï¼ä½ä»å­å¨ä¸äºææ°ï¼åæ¬è³ææ¨æºååå¯åæ§ãæ¨¡åå¯è§£éæ§ãç¸±ååæéå¶åè¨åºé©ææ§ãæå¾ï¼æåæåºäºæªä¾çç ç©¶æ¹åï¼ä¾å¦èª¿æ¥èèªè¨ç¡éçèªé³åææ¹æ³ãéç¼å¤æ¨¡å¼è¨ºæ·ç³»çµ±ï¼ä»¥åè§£æ±ºäººå·¥æºæ§è¼å©é«çä¿å¥ä¸­çå«çèéãééç¶åç®åçè¶¨å¢åæ¾åºééµéç¤ï¼æ¬ç¯è©è«æ¨å¨å¼å°æ·±åº¦å­¸ç¿çºåºç¤çèªç¥åè½éç¤æª¢æ¸¬ç³»çµ±çé²ä¸æ­¥ç¼å±ï¼ä»¥æ¹åæ©æè¨ºæ·ï¼ä¸¦æçµæ¹åæ£èçæ²»ççµæã

##### **An Ontology-Enabled Approach For User-Centered and Knowledge-Enabled Explanations of AI Systems**
2410.17504v1 by Shruthi Chari

Explainable Artificial Intelligence (AI) focuses on helping humans understand
the working of AI systems or their decisions and has been a cornerstone of AI
for decades. Recent research in explainability has focused on explaining the
workings of AI models or model explainability. There have also been several
position statements and review papers detailing the needs of end-users for
user-centered explainability but fewer implementations. Hence, this thesis
seeks to bridge some gaps between model and user-centered explainability. We
create an explanation ontology (EO) to represent literature-derived explanation
types via their supporting components. We implement a knowledge-augmented
question-answering (QA) pipeline to support contextual explanations in a
clinical setting. Finally, we are implementing a system to combine explanations
from different AI methods and data modalities. Within the EO, we can represent
fifteen different explanation types, and we have tested these representations
in six exemplar use cases. We find that knowledge augmentations improve the
performance of base large language models in the contextualized QA, and the
performance is variable across disease groups. In the same setting, clinicians
also indicated that they prefer to see actionability as one of the main foci in
explanations. In our explanations combination method, we plan to use similarity
metrics to determine the similarity of explanations in a chronic disease
detection setting. Overall, through this thesis, we design methods that can
support knowledge-enabled explanations across different use cases, accounting
for the methods in today's AI era that can generate the supporting components
of these explanations and domain knowledge sources that can enhance them.

æè¦ï¼å¯è§£éäººå·¥æºæ§ï¼AIï¼å°æ³¨æ¼åå©äººé¡äºè§£ AI ç³»çµ±éä½æå¶æ±ºç­ï¼æ¸åå¹´ä¾ä¸ç´æ¯ AI çåºç³ãæè¿çå¯è§£éæ§ç ç©¶å°æ³¨æ¼è§£é AI æ¨¡åææ¨¡åå¯è§£éæ§çéä½ãä¹æå¹¾ä»½ç«å ´è²æåè©è«è«æè©³ç´°èªªæäºæçµä½¿ç¨èå°ä»¥ä½¿ç¨èçºä¸­å¿çå¯è§£éæ§çéæ±ï¼ä½å¯¦ä½è¼å°ãå æ­¤ï¼æ¬è«ææ¨å¨å½è£æ¨¡ååä»¥ä½¿ç¨èçºä¸­å¿çå¯è§£éæ§ä¹éçä¸äºå·®è·ãæåå»ºç«ä¸åè§£éæ¬é«ï¼EOï¼ä»¥ééå¶æ¯æ´åä»¶ä¾è¡¨ç¤ºå¾æç»ä¸­è¡ççè§£éé¡åãæåå¯¦ä½ä¸åç¥è­å¢å¼·çåç­ï¼QAï¼ç®¡ç·ï¼ä»¥å¨è¨åºç°å¢ä¸­æ¯æ´æå¢è§£éãæå¾ï¼æåæ­£å¨å¯¦ä½ä¸åç³»çµ±ï¼ä»¥çµåä¾èªä¸å AI æ¹æ³åè³ææ¨¡å¼çè§£éãå¨ EO ä¸­ï¼æåå¯ä»¥è¡¨ç¤º 15 ç¨®ä¸åçè§£éé¡åï¼ä¸¦ä¸æåå·²å¨å­åç¯ä¾ä½¿ç¨æ¡ä¾ä¸­æ¸¬è©¦éäºè¡¨ç¤ºãæåç¼ç¾ï¼ç¥è­å¢å¼·æ¹åäºåºç¤å¤§åèªè¨æ¨¡åå¨æå¢å QA ä¸­çæè½ï¼ä¸¦ä¸æè½å ç¾çç¾¤çµèç°ãå¨ç¸åçç°å¢ä¸­ï¼è¨åºé«çä¹è¡¨ç¤ºä»åå¸æå°å¯æä½æ§è¦çºè§£éä¸­çä¸»è¦ç¦é»ä¹ä¸ãå¨æåçè§£éçµåæ¹æ³ä¸­ï¼æåè¨ç«ä½¿ç¨ç¸ä¼¼æ§ææ¨ä¾ç¢ºå®æ¢æ§çåµæ¸¬ç°å¢ä¸­è§£éçç¸ä¼¼æ§ãç¸½é«èè¨ï¼ééæ¬è«æï¼æåè¨­è¨äºå¯ä»¥å¨ä¸åä½¿ç¨æ¡ä¾ä¸­æ¯æ´ç¥è­åç¨è§£éçæ¹æ³ï¼èéå°ç¶ä» AI æä»£ä¸­å¯ä»¥ç¢çéäºè§£éçæ¯æ´åä»¶åå¯ä»¥å¢å¼·éäºè§£éçé åç¥è­ä¾æºçæ¹æ³ã

##### **Contrasting Attitudes Towards Current and Future AI Applications for Computerised Interpretation of ECG: A Clinical Stakeholder Interview Study**
2410.16879v1 by Lukas Hughes-Noehrer, Leda Channer, Gabriel Strain, Gregory Yates, Richard Body, Caroline Jay

Objectives: To investigate clinicians' attitudes towards current automated
interpretation of ECG and novel AI technologies and their perception of
computer-assisted interpretation. Materials and Methods: We conducted a series
of interviews with clinicians in the UK. Our study: (i) explores the potential
for AI, specifically future 'human-like' computing approaches, to facilitate
ECG interpretation and support clinical decision making, and (ii) elicits their
opinions about the importance of explainability and trustworthiness of AI
algorithms. Results: We performed inductive thematic analysis on interview
transcriptions from 23 clinicians and identified the following themes: (i) a
lack of trust in current systems, (ii) positive attitudes towards future AI
applications and requirements for these, (iii) the relationship between the
accuracy and explainability of algorithms, and (iv) opinions on education,
possible deskilling, and the impact of AI on clinical competencies. Discussion:
Clinicians do not trust current computerised methods, but welcome future 'AI'
technologies. Where clinicians trust future AI interpretation to be accurate,
they are less concerned that it is explainable. They also preferred ECG
interpretation that demonstrated the results of the algorithm visually. Whilst
clinicians do not fear job losses, they are concerned about deskilling and the
need to educate the workforce to use AI responsibly. Conclusion: Clinicians are
positive about the future application of AI in clinical decision-making.
Accuracy is a key factor of uptake and visualisations are preferred over
current computerised methods. This is viewed as a potential means of training
and upskilling, in contrast to the deskilling that automation might be
perceived to bring.

æè¦ï¼<paragraph>ç®çï¼èª¿æ¥è¨åºé«çå°ç®åèªååå¿é»åè§£è®åæ°çäººå·¥æºæ§æè¡çæåº¦ï¼ä»¥åä»åå°é»è¦è¼å©è§£è®ççæ³ãææåæ¹æ³ï¼æåå°è±åçè¨åºé«çé²è¡äºä¸ç³»åè¨ªè«ãæåçç ç©¶ï¼(i) æ¢è¨äººå·¥æºæ§çæ½åï¼ç¹å¥æ¯æªä¾çãé¡äººé¡ãéç®æ¹æ³ï¼ä»¥ä¿é²å¿é»åè§£è®ä¸¦æ¯æè¨åºæ±ºç­å¶å®ï¼ä»¥å (ii) å¾µæ±ä»åå°äººå·¥æºæ§æ¼ç®æ³çå¯è§£éæ§åå¯ä¿¡åº¦ççæ³ãçµæï¼æåå° 23 ä½è¨åºé«ççè¨ªè«è¨éé²è¡äºæ­¸ç´ä¸»é¡åæï¼ä¸¦æ¾åºä»¥ä¸ä¸»é¡ï¼(i) å°ç®åç³»çµ±ç¼ºä¹ä¿¡ä»»ï¼(ii) å°æªä¾äººå·¥æºæ§æç¨åå°éäºæç¨çè¦æ±ææ­£é¢æåº¦ï¼(iii) æ¼ç®æ³çæºç¢ºæ§åå¯è§£éæ§ä¹éçéä¿ï¼ä»¥å (iv) å°æè²ãå¯è½çæè½éåï¼ä»¥åäººå·¥æºæ§å°è¨åºè½åçå½±é¿ççæ³ãè¨è«ï¼è¨åºé«çä¸ä¿¡ä»»ç®åçé»è¦åæ¹æ³ï¼ä½æ­¡è¿æªä¾çãäººå·¥æºæ§ãæè¡ãå¨è¨åºé«çç¸ä¿¡æªä¾ç AI è§£è®æºç¢ºçææ³ä¸ï¼ä»åä¸å¤ªæå¿å®æ¯å¦å¯è§£éãä»åä¹æ¯è¼åæ­¡è½ä»¥è¦è¦ºæ¹å¼åç¾æ¼ç®æ³çµæçå¿é»åè§£è®ãéç¶è¨åºé«çä¸å®³æå¤±æ¥­ï¼ä½ä»åæå¿æè½éåï¼ä»¥åéè¦æè²å¡å·¥è² è²¬ä»»å°ä½¿ç¨äººå·¥æºæ§ãçµè«ï¼è¨åºé«çå°äººå·¥æºæ§å¨è¨åºæ±ºç­å¶å®ä¸­çæªä¾æç¨ææ­£é¢æåº¦ãæºç¢ºæ§æ¯æ¡ç¨äººå·¥æºæ§çä¸åééµå ç´ ï¼èè¦è¦ºåæ¯ç®åçé»è¦åæ¹æ³æ´åéçãéè¢«è¦çºä¸ç¨®æ½å¨çå¹è¨åæåæè½çæ¹æ³ï¼èèªååå¯è½å¸¶ä¾çæè½éåå½¢æå°æ¯ã</paragraph>

##### **Pathologist-like explainable AI for interpretable Gleason grading in prostate cancer**
2410.15012v1 by Gesa Mittmann, Sara Laiouar-Pedari, Hendrik A. Mehrtens, Sarah HaggenmÃ¼ller, Tabea-Clara Bucher, Tirtha Chanda, Nadine T. Gaisa, Mathias Wagner, Gilbert Georg Klamminger, Tilman T. Rau, Christina Neppl, Eva Maria CompÃ©rat, Andreas Gocht, Monika HÃ¤mmerle, Niels J. Rupp, Jula Westhoff, Irene KrÃ¼cken, Maximillian Seidl, Christian M. SchÃ¼rch, Marcus Bauer, Wiebke Solass, Yu Chun Tam, Florian Weber, Rainer Grobholz, Jaroslaw Augustyniak, Thomas Kalinski, Christian HÃ¶rner, Kirsten D. Mertz, Constanze DÃ¶ring, Andreas Erbersdobler, Gabriele Deubler, Felix Bremmer, Ulrich Sommer, Michael Brodhun, Jon Griffin, Maria Sarah L. Lenon, Kiril Trpkov, Liang Cheng, Fei Chen, Angelique Levi, Guoping Cai, Tri Q. Nguyen, Ali Amin, Alessia Cimadamore, Ahmed Shabaik, Varsha Manucha, Nazeel Ahmad, Nidia Messias, Francesca Sanguedolce, Diana Taheri, Ezra Baraban, Liwei Jia, Rajal B. Shah, Farshid Siadat, Nicole Swarbrick, Kyung Park, Oudai Hassan, Siamak Sakhaie, Michelle R. Downes, Hiroshi Miyamoto, Sean R. Williamson, Tim Holland-Letz, Carolin V. Schneider, Jakob Nikolas Kather, Yuri Tolkach, Titus J. Brinker

The aggressiveness of prostate cancer, the most common cancer in men
worldwide, is primarily assessed based on histopathological data using the
Gleason scoring system. While artificial intelligence (AI) has shown promise in
accurately predicting Gleason scores, these predictions often lack inherent
explainability, potentially leading to distrust in human-machine interactions.
To address this issue, we introduce a novel dataset of 1,015 tissue microarray
core images, annotated by an international group of 54 pathologists. The
annotations provide detailed localized pattern descriptions for Gleason grading
in line with international guidelines. Utilizing this dataset, we develop an
inherently explainable AI system based on a U-Net architecture that provides
predictions leveraging pathologists' terminology. This approach circumvents
post-hoc explainability methods while maintaining or exceeding the performance
of methods trained directly for Gleason pattern segmentation (Dice score: 0.713
$\pm$ 0.003 trained on explanations vs. 0.691 $\pm$ 0.010 trained on Gleason
patterns). By employing soft labels during training, we capture the intrinsic
uncertainty in the data, yielding strong results in Gleason pattern
segmentation even in the context of high interobserver variability. With the
release of this dataset, we aim to encourage further research into segmentation
in medical tasks with high levels of subjectivity and to advance the
understanding of pathologists' reasoning processes.

æè¦ï¼ååèºçæ¯å¨çç·æ§æå¸¸è¦çççï¼å¶æ¡æ§ç¨åº¦ä¸»è¦æ ¹æ Gleason è©åç³»çµ±ä½¿ç¨çµç¹ççå­¸æ¸æé²è¡è©ä¼°ãéç¶äººå·¥æºæ§ (AI) å¨æºç¢ºé æ¸¬ Gleason è©åæ¹é¢å·²å±ç¾æ½åï¼ä½éäºé æ¸¬éå¸¸ç¼ºä¹å§å¨çå¯è§£éæ§ï¼å¯è½æå°è´å°äººæ©äºåçä¸ä¿¡ä»»ãçºäºè§£æ±ºéååé¡ï¼æåå¼é²äºä¸åç± 54 ä½ççå­¸å®¶çµæçåéåéè¨»è§£ç 1,015 åçµç¹å¾®é£åæ ¸å¿å½±åçæ°ç©è³æéãéäºè¨»è§£æä¾äºè©³ç´°çå±é¨æ¨¡å¼æè¿°ï¼ç¨æ¼ç¬¦ååéæºåç Gleason åç´ãå©ç¨éåè³æéï¼æåéç¼äºä¸ååºæ¼ U-Net æ¶æ§çå§å¨å¯è§£é AI ç³»çµ±ï¼è©²ç³»çµ±æä¾äºå©ç¨ççå­¸å®¶è¡èªé²è¡é æ¸¬ãéç¨®æ¹æ³è¦é¿äºäºå¾å¯è§£éæ§æ¹æ³ï¼åæç¶­ææè¶è¶äºç´æ¥è¨ç·´ç¨æ¼ Gleason æ¨¡å¼åå²çæ¹æ³çæè½ï¼Dice åæ¸ï¼0.713 Â± 0.003ï¼è¨ç·´æ¼è§£éï¼ç¸å°æ¼ 0.691 Â± 0.010ï¼è¨ç·´æ¼ Gleason æ¨¡å¼ï¼ãééå¨è¨ç·´æéæ¡ç¨è»æ¨ç±¤ï¼æåææäºè³æä¸­çå§å¨ä¸ç¢ºå®æ§ï¼å³ä½¿å¨è§å¯èéè®ç°æ§é«çææ³ä¸ï¼ä¹è½å¨ Gleason æ¨¡å¼åå²ä¸­ç¢çå¼·å¤§ççµæãéééåºéåè³æéï¼æåæ¨å¨é¼åµé²ä¸æ­¥ç ç©¶ä¸»è§æ§é«çé«çä»»åä¸­çåå²ï¼ä¸¦å¢é²å°ççå­¸å®¶æ¨çéç¨ççè§£ã

##### **Explainable AI Methods for Multi-Omics Analysis: A Survey**
2410.11910v1 by Ahmad Hussein, Mukesh Prasad, Ali Braytee

Advancements in high-throughput technologies have led to a shift from
traditional hypothesis-driven methodologies to data-driven approaches.
Multi-omics refers to the integrative analysis of data derived from multiple
'omes', such as genomics, proteomics, transcriptomics, metabolomics, and
microbiomics. This approach enables a comprehensive understanding of biological
systems by capturing different layers of biological information. Deep learning
methods are increasingly utilized to integrate multi-omics data, offering
insights into molecular interactions and enhancing research into complex
diseases. However, these models, with their numerous interconnected layers and
nonlinear relationships, often function as black boxes, lacking transparency in
decision-making processes. To overcome this challenge, explainable artificial
intelligence (xAI) methods are crucial for creating transparent models that
allow clinicians to interpret and work with complex data more effectively. This
review explores how xAI can improve the interpretability of deep learning
models in multi-omics research, highlighting its potential to provide
clinicians with clear insights, thereby facilitating the effective application
of such models in clinical settings.

æè¦ï¼é«ééæè¡çé²æ­¥å°è´å¾å³çµ±çåè¨­é©åæ¹æ³è½è®çºè³æé©åçæ¹æ³ãå¤çµå­¸æ¯ææ´ååæä¾èªå¤åãçµå­¸ãçè³æï¼ä¾å¦åºå çµå­¸ãèç½è³ªçµå­¸ãè½éçµå­¸ãä»£è¬çµå­¸åå¾®çç©çµå­¸ãæ­¤æ¹æ³ééæ·åçç©è³è¨çä¸åå±¤é¢ï¼è½å¨é¢äºè§£çç©ç³»çµ±ãæ·±åº¦å­¸ç¿æ¹æ³æä¾æå¸¸è¢«ç¨æ¼æ´åå¤çµå­¸è³æï¼æä¾åå­äº¤äºä½ç¨çæ´å¯åï¼ä¸¦å å¼·å°è¤éç¾ççç ç©¶ãç¶èï¼éäºæ¨¡åå·æè¨±å¤ç¸äºé£æ¥çå±¤ç´åéç·æ§éä¿ï¼éå¸¸æåé»çå­ä¸æ¨£éä½ï¼ç¼ºä¹æ±ºç­éç¨çéæåº¦ãçºäºåææ­¤ææ°ï¼å¯è§£éäººå·¥æºæ§ (xAI) æ¹æ³å°æ¼å»ºç«éææ¨¡åè³ééè¦ï¼è®è¨åºé«çå¯ä»¥æ´ææå°è§£éåèçè¤éè³æãæ­¤è©è«æ¢è¨ xAI å¦ä½è½æ¹åå¤çµå­¸ç ç©¶ä¸­æ·±åº¦å­¸ç¿æ¨¡åçå¯è§£éæ§ï¼å¼·èª¿å¶æä¾è¨åºé«çæç¢ºè¦è§£çæ½åï¼é²èä¿é²æ­¤é¡æ¨¡åå¨è¨åºç°å¢ä¸­çæææç¨ã

##### **Study on the Helpfulness of Explainable Artificial Intelligence**
2410.11896v1 by Tobias Labarta, Elizaveta Kulicheva, Ronja Froelian, Christian GeiÃler, Xenia Melman, Julian von Klitzing

Explainable Artificial Intelligence (XAI) is essential for building advanced
machine learning-powered applications, especially in critical domains such as
medical diagnostics or autonomous driving. Legal, business, and ethical
requirements motivate using effective XAI, but the increasing number of
different methods makes it challenging to pick the right ones. Further, as
explanations are highly context-dependent, measuring the effectiveness of XAI
methods without users can only reveal a limited amount of information,
excluding human factors such as the ability to understand it. We propose to
evaluate XAI methods via the user's ability to successfully perform a proxy
task, designed such that a good performance is an indicator for the explanation
to provide helpful information. In other words, we address the helpfulness of
XAI for human decision-making. Further, a user study on state-of-the-art
methods was conducted, showing differences in their ability to generate trust
and skepticism and the ability to judge the rightfulness of an AI decision
correctly. Based on the results, we highly recommend using and extending this
approach for more objective-based human-centered user studies to measure XAI
performance in an end-to-end fashion.

æè¦ï¼å¯è§£éäººå·¥æºæ§ (XAI) å°æ¼å»ºæ§åé²çæ©å¨å­¸ç¿é©åæç¨ç¨å¼è³ééè¦ï¼ç¹å¥æ¯å¨é«çè¨ºæ·æèªåé§é§ç­ééµé åãæ³å¾ãåæ¥­åå«çè¦æ±ä¿ä½¿ä½¿ç¨ææç XAIï¼ä½æ¸éæ¥çå¢å çä¸åæ¹æ³ä½¿å¾æé¸æ­£ç¢ºçæ¹æ³å·æææ°æ§ãæ­¤å¤ï¼ç±æ¼è§£éé«åº¦ä¾è³´æ¼èæ¯ï¼å¨æ²æä½¿ç¨èçææ³ä¸è¡¡é XAI æ¹æ³çæææ§åªè½æ­ç¤ºæéçè³è¨ï¼æé¤äººé¡å ç´ ï¼ä¾å¦çè§£å®çè½åãæåå»ºè­°ééä½¿ç¨èæåå·è¡ä»£çä»»åçè½åä¾è©ä¼° XAI æ¹æ³ï¼è¨­è¨ä½¿å¾è¯å¥½çå·è¡è¡¨ç¾æ¯è§£éæä¾æç¨è³è¨çææ¨ãæå¥è©±èªªï¼æåæ¢è¨ XAI å°äººé¡æ±ºç­å¶å®çå¹«å©ãæ­¤å¤ï¼å°æåé²çæ¹æ³é²è¡ä½¿ç¨èç ç©¶ï¼é¡¯ç¤ºåºå®åå¨ç¢çä¿¡ä»»åæ·ççè½åä»¥åæ­£ç¢ºå¤æ· AI æ±ºç­æ¯å¦æ­£ç¢ºçè½åæ¹é¢å­å¨å·®ç°ãæ ¹æçµæï¼æåå¼·çå»ºè­°ä½¿ç¨åæ´åéç¨®æ¹æ³ï¼ä»¥é²è¡æ´å¤ä»¥ç®æ¨çºåºç¤çäººçºä¸­å¿ä½¿ç¨èç ç©¶ï¼ä»¥çµç«¯å°çµç«¯çæ¹å¼è¡¡é XAI æè½ã

##### **Use of What-if Scenarios to Help Explain Artificial Intelligence Models for Neonatal Health**
2410.09635v1 by Abdullah Mamun, Lawrence D. Devoe, Mark I. Evans, David W. Britt, Judith Klein-Seetharaman, Hassan Ghasemzadeh

Early detection of intrapartum risk enables interventions to potentially
prevent or mitigate adverse labor outcomes such as cerebral palsy. Currently,
there is no accurate automated system to predict such events to assist with
clinical decision-making. To fill this gap, we propose "Artificial Intelligence
(AI) for Modeling and Explaining Neonatal Health" (AIMEN), a deep learning
framework that not only predicts adverse labor outcomes from maternal, fetal,
obstetrical, and intrapartum risk factors but also provides the model's
reasoning behind the predictions made. The latter can provide insights into
what modifications in the input variables of the model could have changed the
predicted outcome. We address the challenges of imbalance and small datasets by
synthesizing additional training data using Adaptive Synthetic Sampling
(ADASYN) and Conditional Tabular Generative Adversarial Networks (CTGAN). AIMEN
uses an ensemble of fully-connected neural networks as the backbone for its
classification with the data augmentation supported by either ADASYN or CTGAN.
AIMEN, supported by CTGAN, outperforms AIMEN supported by ADASYN in
classification. AIMEN can predict a high risk for adverse labor outcomes with
an average F1 score of 0.784. It also provides counterfactual explanations that
can be achieved by changing 2 to 3 attributes on average. Resources available:
https://github.com/ab9mamun/AIMEN.

æè¦ï¼ç¢ç¨ä¸­é¢¨éªçæ©æåµæ¸¬æå©æ¼é²è¡å¹²é æªæ½ï¼ä»¥é é²ææ¸è¼ä¸å©ççç¢çµæï¼ä¾å¦è¦æ§éº»çºãç®åï¼æ²ææºç¢ºçèªååç³»çµ±å¯ä»¥é æ¸¬æ­¤é¡äºä»¶ï¼ä»¥åå©è¨åºæ±ºç­ãçºäºå¡«è£éä¸ç©ºç½ï¼æåæåºãç¨æ¼å»ºæ¨¡åè§£éæ°çåå¥åº·çäººå·¥æºæ§ã(AIMEN)ï¼éæ¯ä¸åæ·±åº¦å­¸ç¿æ¶æ§ï¼å®ä¸åå¯ä»¥æ ¹æå­ç¢å©¦ãèåãç¢ç§åç¢ç¨é¢¨éªå ç´ é æ¸¬ä¸å©ççç¢çµæï¼éè½æä¾æ¨¡åååºé æ¸¬èå¾çåå ãå¾èå¯ä»¥æä¾è¦è§£ï¼èªªææ¨¡åè¼¸å¥è®æ¸ä¸­çåªäºä¿®æ¹å¯è½ææ¹è®é æ¸¬çµæãæåééä½¿ç¨é©ææ§åææ½æ¨£ (ADASYN) åæ¢ä»¶è¡¨æ ¼çæå°æç¶²è·¯ (CTGAN) ä¾åæé¡å¤çè¨ç·´è³æï¼ä»¥è§£æ±ºä¸å¹³è¡¡åå°åè³æéçææ°ãAIMEN ä½¿ç¨å¨é£æ¥ç¥ç¶ç¶²è·¯çéåä½çºå¶åé¡çéª¨å¹¹ï¼ä¸¦éé ADASYN æ CTGAN æ¯æ´è³ææ´åãç± CTGAN æ¯æ´ç AIMEN å¨åé¡æ¹é¢åªæ¼ç± ADASYN æ¯æ´ç AIMENãAIMEN å¯ä»¥é æ¸¬ä¸å©ççç¢çµæçé«é¢¨éªï¼å¹³å F1 åæ¸çº 0.784ãå®éæä¾åäºå¯¦è§£éï¼å¯ééå¹³åè®æ´ 2 è³ 3 åå±¬æ§ä¾éæãå¯ç¨è³æºï¼https://github.com/ab9mamun/AIMENã

##### **Artificial intelligence techniques in inherited retinal diseases: A review**
2410.09105v1 by Han Trinh, Jordan Vice, Jason Charng, Zahra Tajbakhsh, Khyber Alam, Fred K. Chen, Ajmal Mian

Inherited retinal diseases (IRDs) are a diverse group of genetic disorders
that lead to progressive vision loss and are a major cause of blindness in
working-age adults. The complexity and heterogeneity of IRDs pose significant
challenges in diagnosis, prognosis, and management. Recent advancements in
artificial intelligence (AI) offer promising solutions to these challenges.
However, the rapid development of AI techniques and their varied applications
have led to fragmented knowledge in this field. This review consolidates
existing studies, identifies gaps, and provides an overview of AI's potential
in diagnosing and managing IRDs. It aims to structure pathways for advancing
clinical applications by exploring AI techniques like machine learning and deep
learning, particularly in disease detection, progression prediction, and
personalized treatment planning. Special focus is placed on the effectiveness
of convolutional neural networks in these areas. Additionally, the integration
of explainable AI is discussed, emphasizing its importance in clinical settings
to improve transparency and trust in AI-based systems. The review addresses the
need to bridge existing gaps in focused studies on AI's role in IRDs, offering
a structured analysis of current AI techniques and outlining future research
directions. It concludes with an overview of the challenges and opportunities
in deploying AI for IRDs, highlighting the need for interdisciplinary
collaboration and the continuous development of robust, interpretable AI models
to advance clinical applications.

æè¦ï¼éºå³æ§è¦ç¶²èç¾ç (IRD) æ¯ä¸çµå¤æ¨£åçéºå³ç¾çï¼
æå°è´è¦åéæ¼¸åªå¤±ï¼æ¯å·¥ä½å¹´é½¡æäººå¤±æçä¸»è¦åå ãIRD çè¤éæ§åç°è³ªæ§å°è¨ºæ·ãé å¾åç®¡çæåºäºéå¤§ææ°ãæè¿äººå·¥æºè½ (AI) çé²æ­¥çºéäºææ°æä¾äºæå¸æçè§£æ±ºæ¹æ¡ã
ç¶èï¼AI æè¡çå¿«éç¼å±åå¶å¤ç¨®æç¨å°è´äºè©²é åçç¥è­åæ£ãæ¬ç¶è¿°æ´åäºç¾æç ç©¶ï¼æ¾åºå·®è·ï¼ä¸¦æ¦è¿°äº AI å¨è¨ºæ·åç®¡ç IRD ä¸­çæ½åãå®æ¨å¨ééæ¢ç´¢æ©å¨å­¸ç¿åæ·±åº¦å­¸ç¿ç­ AI æè¡ï¼ç¹å¥æ¯å¨ç¾çæª¢æ¸¬ãé²ç¨é æ¸¬ååæ§åæ²»çè¨åä¸­ï¼çºæ¨é²è¨åºæç¨æ§å»ºéå¾ãç¹å¥éæ³¨éäºé åä¸­å·ç©ç¥ç¶ç¶²è·¯çæææ§ãæ­¤å¤ï¼è¨è«äºå¯è§£é AI çæ´åï¼å¼·èª¿äºå¶å¨è¨åºç°å¢ä¸­æé«éæåº¦åå°åºæ¼ AI çç³»çµ±çä¿¡ä»»çéè¦æ§ãè©²ç¶è¿°è§£æ±ºäºå½å AI å¨ IRD ä¸­ä½ç¨çéé»ç ç©¶ä¸­ç¾æå·®è·çå¿è¦æ§ï¼æä¾äºå°ç¶å AI æè¡ççµæ§ååæï¼ä¸¦æ¦è¿°äºæªä¾çç ç©¶æ¹åãæå¾æ¦è¿°äºå¨ IRD ä¸­é¨ç½² AI çææ°åæ©éï¼å¼·èª¿äºè·¨å­¸ç§åä½åæçºéç¼å¼·å¤§ãå¯è§£éç AI æ¨¡åä»¥æ¨é²è¨åºæç¨çå¿è¦æ§ã

##### **CasiMedicos-Arg: A Medical Question Answering Dataset Annotated with Explanatory Argumentative Structures**
2410.05235v2 by Ekaterina Sviridova, Anar Yeginbergen, Ainara Estarrona, Elena Cabrio, Serena Villata, Rodrigo Agerri

Explaining Artificial Intelligence (AI) decisions is a major challenge
nowadays in AI, in particular when applied to sensitive scenarios like medicine
and law. However, the need to explain the rationale behind decisions is a main
issue also for human-based deliberation as it is important to justify
\textit{why} a certain decision has been taken. Resident medical doctors for
instance are required not only to provide a (possibly correct) diagnosis, but
also to explain how they reached a certain conclusion. Developing new tools to
aid residents to train their explanation skills is therefore a central
objective of AI in education. In this paper, we follow this direction, and we
present, to the best of our knowledge, the first multilingual dataset for
Medical Question Answering where correct and incorrect diagnoses for a clinical
case are enriched with a natural language explanation written by doctors. These
explanations have been manually annotated with argument components (i.e.,
premise, claim) and argument relations (i.e., attack, support), resulting in
the Multilingual CasiMedicos-Arg dataset which consists of 558 clinical cases
in four languages (English, Spanish, French, Italian) with explanations, where
we annotated 5021 claims, 2313 premises, 2431 support relations, and 1106
attack relations. We conclude by showing how competitive baselines perform over
this challenging dataset for the argument mining task.

æè¦ï¼è§£éäººå·¥æºæ§ (AI) çæ±ºç­æ¯ç¾å¨ AI çä¸é éå¤§ææ°ï¼ç¹å¥æ¯æç¨æ¼åé«å­¸åæ³å¾ç­æææå¢æãç¶èï¼è§£éæ±ºç­èå¾çç±çéæ±ä¹æ¯åºæ¼äººé¡çèéçä¸åä¸»è¦åé¡ï¼å çºæå¿è¦è­æçºä»éº¼ååºæåæ±ºç­ãä¾å¦ï¼ä½é¢é«å¸«ä¸åéè¦æä¾ï¼å¯è½æ¯æ­£ç¢ºçï¼è¨ºæ·ï¼ééè¦è§£éä»åå¦ä½éææåçµè«ãå æ­¤ï¼éç¼æ°çå·¥å·ä¾å¹«å©ä½é¢é«å¸«è¨ç·´ä»åçè§£éæå·§æ¯æè²ä¸­ AI çä¸é æ ¸å¿ç®æ¨ãå¨æ¬æä¸­ï¼æåéµå¾ªéåæ¹åï¼ä¸¦ä¸æ ¹ææåçäºè§£ï¼æåºç¬¬ä¸åå¤èªè¨é«å­¸åç­è³æéï¼å¶ä¸­è¨åºçä¾çæ­£ç¢ºåä¸æ­£ç¢ºè¨ºæ·é½éæç±é«çæ°å¯«çèªç¶èªè¨è§£éãéäºè§£éå·²ä½¿ç¨è«è­çµæï¼å³åæãä¸»å¼µï¼åè«è­éä¿ï¼å³æ»æãæ¯æï¼é²è¡æåè¨»è§£ï¼ç¢çå¤èªè¨ CasiMedicos-Arg è³æéï¼å¶ä¸­åå« 558 åå·æè§£éçåç¨®èªè¨ï¼è±èªãè¥¿ç­çèªãæ³èªãç¾©å¤§å©èªï¼çè¨åºçä¾ï¼æåè¨»è§£äº 5021 åä¸»å¼µã2313 ååæã2431 åæ¯æéä¿å 1106 åæ»æéä¿ãæåæå¾å±ç¤ºäºç«¶ç­åºæºå¦ä½éå°è«è­æ¢åä»»åå·è¡æ­¤å·ææ°æ§çè³æéã

##### **Explainable Diagnosis Prediction through Neuro-Symbolic Integration**
2410.01855v1 by Qiuhao Lu, Rui Li, Elham Sagheb, Andrew Wen, Jinlian Wang, Liwei Wang, Jungwei W. Fan, Hongfang Liu

Diagnosis prediction is a critical task in healthcare, where timely and
accurate identification of medical conditions can significantly impact patient
outcomes. Traditional machine learning and deep learning models have achieved
notable success in this domain but often lack interpretability which is a
crucial requirement in clinical settings. In this study, we explore the use of
neuro-symbolic methods, specifically Logical Neural Networks (LNNs), to develop
explainable models for diagnosis prediction. Essentially, we design and
implement LNN-based models that integrate domain-specific knowledge through
logical rules with learnable thresholds. Our models, particularly
$M_{\text{multi-pathway}}$ and $M_{\text{comprehensive}}$, demonstrate superior
performance over traditional models such as Logistic Regression, SVM, and
Random Forest, achieving higher accuracy (up to 80.52\%) and AUROC scores (up
to 0.8457) in the case study of diabetes prediction. The learned weights and
thresholds within the LNN models provide direct insights into feature
contributions, enhancing interpretability without compromising predictive
power. These findings highlight the potential of neuro-symbolic approaches in
bridging the gap between accuracy and explainability in healthcare AI
applications. By offering transparent and adaptable diagnostic models, our work
contributes to the advancement of precision medicine and supports the
development of equitable healthcare solutions. Future research will focus on
extending these methods to larger and more diverse datasets to further validate
their applicability across different medical conditions and populations.

æè¦ï¼è¨ºæ·é æ¸¬æ¯é«çä¿å¥ä¸­çä¸é ééµä»»åï¼åæä¸æºç¢ºå°è­å¥é«ççæ³æå°æ£èççµæç¢çéå¤§å½±é¿ãå³çµ±æ©å¨å­¸ç¿åæ·±åº¦å­¸ç¿æ¨¡åå·²å¨æ­¤é ååå¾é¡¯èæåï¼ä½éå¸¸ç¼ºä¹å¯è§£éæ§ï¼éæ¯è¨åºç°å¢ä¸­çééµè¦æ±ãå¨æ¬ç ç©¶ä¸­ï¼æåæ¢è¨äºç¥ç¶ç¬¦èæ¹æ³ï¼ç¹å¥æ¯éè¼¯ç¥ç¶ç¶²è·¯ (LNN)ï¼ä»¥éç¼å¯è§£éçè¨ºæ·é æ¸¬æ¨¡åãåºæ¬ä¸ï¼æåè¨­è¨ä¸¦å¯¦ä½äºåºæ¼ LNN çæ¨¡åï¼è©²æ¨¡åéééè¼¯è¦ååå¯å­¸ç¿çé¾å¼æ´åé åç¹å®çç¥è­ãæåçæ¨¡åï¼ç¹å¥æ¯ $M_{\text{multi-pathway}}$ å $M_{\text{comprehensive}}$ï¼è¡¨ç¾åºåªæ¼å³çµ±æ¨¡åï¼å¦éè¼¯è¿´æ­¸ãSVM åé¨æ©æ£®æï¼çåè¶æè½ï¼å¨ç³å°¿çé æ¸¬çæ¡ä¾ç ç©¶ä¸­ï¼éå°äºæ´é«çæºç¢ºåº¦ï¼é«é 80.52%ï¼å AUROC åæ¸ï¼é«é 0.8457ï¼ãLNN æ¨¡åä¸­å­¸ç¿çæ¬éåé¾å¼æä¾äºå°ç¹å¾µè²¢ç»çç´æ¥è¦è§£ï¼å¢å¼·äºå¯è§£éæ§ï¼åæä¸æå®³é æ¸¬è½åãéäºç¼ç¾çªé¡¯äºç¥ç¶ç¬¦èæ¹æ³å¨å½åé«çä¿å¥ AI æç¨ä¸­æºç¢ºæ§åå¯è§£éæ§å·®è·æ¹é¢çæ½åãééæä¾éæä¸é©ææ§å¼·çè¨ºæ·æ¨¡åï¼æåçç ç©¶æå©æ¼ç²¾æºé«ççé²æ­¥ï¼ä¸¦æ¯æ´å¬å¹³é«çä¿å¥è§£æ±ºæ¹æ¡çéç¼ãæªä¾çç ç©¶å°å°æ³¨æ¼å°éäºæ¹æ³æ´å±å°æ´å¤§ä¸æ´å¤æ¨£åçè³æéï¼ä»¥é²ä¸æ­¥é©è­å¶å¨ä¸åé«ççæ³åäººç¾¤ä¸­çé©ç¨æ§ã

##### **Easydiagnos: a framework for accurate feature selection for automatic diagnosis in smart healthcare**
2410.00366v1 by Prasenjit Maji, Amit Kumar Mondal, Hemanta Kumar Mondal, Saraju P. Mohanty

The rapid advancements in artificial intelligence (AI) have revolutionized
smart healthcare, driving innovations in wearable technologies, continuous
monitoring devices, and intelligent diagnostic systems. However, security,
explainability, robustness, and performance optimization challenges remain
critical barriers to widespread adoption in clinical environments. This
research presents an innovative algorithmic method using the Adaptive Feature
Evaluator (AFE) algorithm to improve feature selection in healthcare datasets
and overcome problems. AFE integrating Genetic Algorithms (GA), Explainable
Artificial Intelligence (XAI), and Permutation Combination Techniques (PCT),
the algorithm optimizes Clinical Decision Support Systems (CDSS), thereby
enhancing predictive accuracy and interpretability. The proposed method is
validated across three diverse healthcare datasets using six distinct machine
learning algorithms, demonstrating its robustness and superiority over
conventional feature selection techniques. The results underscore the
transformative potential of AFE in smart healthcare, enabling personalized and
transparent patient care. Notably, the AFE algorithm, when combined with a
Multi-layer Perceptron (MLP), achieved an accuracy of up to 98.5%, highlighting
its capability to improve clinical decision-making processes in real-world
healthcare applications.

æè¦ï¼äººå·¥æºæ§ (AI) çå¿«éé²å±å¾¹åºæ¹è®äºæºæ§é«çä¿å¥ï¼æ¨åäºå¯ç©¿æ´æè¡ãæçºç£æ§è£ç½®åæºæ§è¨ºæ·ç³»çµ±çåµæ°ãç¶èï¼å®å¨æ§ãå¯è§£éæ§ãç©©å¥æ§åæè½æä½³åææ°ä»ç¶æ¯è¨åºç°å¢ä¸­å»£æ³æ¡ç¨çééµéç¤ãæ¬ç ç©¶æåºä¸ååµæ°çæ¼ç®æ³æ¹æ³ï¼ä½¿ç¨èªé©æç¹å¾µè©ä¼°å¨ (AFE) æ¼ç®æ³ä¾æ¹åé«çä¿å¥è³æéä¸­çç¹å¾µé¸åä¸¦åæåé¡ãAFE æ´åäºéºå³æ¼ç®æ³ (GA)ãå¯è§£éäººå·¥æºæ§ (XAI) åæåçµåæè¡ (PCT)ï¼è©²æ¼ç®æ³æä½³åäºè¨åºæ±ºç­æ¯æ´ç³»çµ± (CDSS)ï¼å¾èæé«äºé æ¸¬æºç¢ºæ§åå¯è§£éæ§ãææåºçæ¹æ³ä½¿ç¨å­ç¨®ä¸åçæ©å¨å­¸ç¿æ¼ç®æ³é©è­äºä¸åä¸åçé«çä¿å¥è³æéï¼è­æäºå¶ç©©å¥æ§ååªæ¼å³çµ±ç¹å¾µé¸åæè¡ãçµæå¼·èª¿äº AFE å¨æºæ§é«çä¿å¥ä¸­çè½è®æ½åï¼å¯¦ç¾äºåäººååéæçæ£èç§è­·ãå¼å¾æ³¨æçæ¯ï¼AFE æ¼ç®æ³èå¤å±¤æç¥å¨ (MLP) çµåä½¿ç¨æï¼æºç¢ºåº¦é«é 98.5%ï¼çªé¡¯äºå¶æ¹åå¯¦éé«çä¿å¥æç¨ä¸­è¨åºæ±ºç­å¶å®æµç¨çè½åã

##### **Dermatologist-like explainable AI enhances melanoma diagnosis accuracy: eye-tracking study**
2409.13476v1 by Tirtha Chanda, Sarah Haggenmueller, Tabea-Clara Bucher, Tim Holland-Letz, Harald Kittler, Philipp Tschandl, Markus V. Heppt, Carola Berking, Jochen S. Utikal, Bastian Schilling, Claudia Buerger, Cristian Navarrete-Dechent, Matthias Goebeler, Jakob Nikolas Kather, Carolin V. Schneider, Benjamin Durani, Hendrike Durani, Martin Jansen, Juliane Wacker, Joerg Wacker, Reader Study Consortium, Titus J. Brinker

Artificial intelligence (AI) systems have substantially improved
dermatologists' diagnostic accuracy for melanoma, with explainable AI (XAI)
systems further enhancing clinicians' confidence and trust in AI-driven
decisions. Despite these advancements, there remains a critical need for
objective evaluation of how dermatologists engage with both AI and XAI tools.
In this study, 76 dermatologists participated in a reader study, diagnosing 16
dermoscopic images of melanomas and nevi using an XAI system that provides
detailed, domain-specific explanations. Eye-tracking technology was employed to
assess their interactions. Diagnostic performance was compared with that of a
standard AI system lacking explanatory features. Our findings reveal that XAI
systems improved balanced diagnostic accuracy by 2.8 percentage points relative
to standard AI. Moreover, diagnostic disagreements with AI/XAI systems and
complex lesions were associated with elevated cognitive load, as evidenced by
increased ocular fixations. These insights have significant implications for
clinical practice, the design of AI tools for visual tasks, and the broader
development of XAI in medical diagnostics.

æè¦ï¼äººå·¥æºæ§ (AI) ç³»çµ±å·²å¤§å¹æ¹åç®èç§é«å¸«å°é»è²ç´ ç¤çè¨ºæ·æºç¢ºåº¦ï¼èå¯è§£é AI (XAI) ç³»çµ±é²ä¸æ­¥æåè¨åºé«å¸«å° AI é©åæ±ºç­çä¿¡å¿èä¿¡è³´ãåç®¡æéäºé²å±ï¼å°æ¼ç®èç§é«å¸«å¦ä½ä½¿ç¨ AI å XAI å·¥å·ï¼ä»æå®¢è§è©ä¼°çè¿«åéæ±ãå¨éé ç ç©¶ä¸­ï¼76 ä½ç®èç§é«å¸«åèäºä¸é è®èç ç©¶ï¼ä½¿ç¨ XAI ç³»çµ±è¨ºæ· 16 å¼µé»è²ç´ ç¤åç£çç®èé¡å½±åï¼è©²ç³»çµ±æä¾è©³ç´°çé åç¹å®èªªæãæ¡ç¨ç¼çè¿½è¹¤æè¡ä¾è©ä¼°ä»åçäºåãå°è¨ºæ·è¡¨ç¾èç¼ºä¹èªªæåè½çæ¨æº AI ç³»çµ±é²è¡æ¯è¼ãæåçç ç©¶çµæé¡¯ç¤ºï¼XAI ç³»çµ±ç¸è¼æ¼æ¨æº AIï¼å°å¹³è¡¡è¨ºæ·æºç¢ºåº¦æåäº 2.8 åç¾åé»ãæ­¤å¤ï¼è AI/XAI ç³»çµ±çè¨ºæ·åæ­§åè¤éççç¶èèªç¥è² æåé«æéï¼éç±å¢å çç¼çæ³¨è¦æ¬¡æ¸æè­å¯¦ãéäºè¦è§£å°è¨åºå¯¦åãè¦è¦ºä»»å AI å·¥å·çè¨­è¨åé«å­¸è¨ºæ·ä¸­ XAI çå»£æ³ç¼å±å·æéå¤§æç¾©ã

##### **Explainable AI for Autism Diagnosis: Identifying Critical Brain Regions Using fMRI Data**
2409.15374v1 by Suryansh Vidya, Kush Gupta, Amir Aly, Andy Wills, Emmanuel Ifeachor, Rohit Shankar

Early diagnosis and intervention for Autism Spectrum Disorder (ASD) has been
shown to significantly improve the quality of life of autistic individuals.
However, diagnostics methods for ASD rely on assessments based on clinical
presentation that are prone to bias and can be challenging to arrive at an
early diagnosis. There is a need for objective biomarkers of ASD which can help
improve diagnostic accuracy. Deep learning (DL) has achieved outstanding
performance in diagnosing diseases and conditions from medical imaging data.
Extensive research has been conducted on creating models that classify ASD
using resting-state functional Magnetic Resonance Imaging (fMRI) data. However,
existing models lack interpretability. This research aims to improve the
accuracy and interpretability of ASD diagnosis by creating a DL model that can
not only accurately classify ASD but also provide explainable insights into its
working. The dataset used is a preprocessed version of the Autism Brain Imaging
Data Exchange (ABIDE) with 884 samples. Our findings show a model that can
accurately classify ASD and highlight critical brain regions differing between
ASD and typical controls, with potential implications for early diagnosis and
understanding of the neural basis of ASD. These findings are validated by
studies in the literature that use different datasets and modalities,
confirming that the model actually learned characteristics of ASD and not just
the dataset. This study advances the field of explainable AI in medical imaging
by providing a robust and interpretable model, thereby contributing to a future
with objective and reliable ASD diagnostics.

æè¦ï¼èªéçè­ç³»éç¤ (ASD) çæ©æè¨ºæ·åä»å¥å·²è¢«è­å¯¦è½é¡¯èæ¹åèªéçæ£èççæ´»åè³ªãç¶èï¼ASD çè¨ºæ·æ¹æ³ä¾è³´æ¼åºæ¼è¨åºè¡¨ç¾çè©ä¼°ï¼å®¹æç¢çåè¦ï¼ä¸å¯è½é£ä»¥ååºæ©æè¨ºæ·ãæå¿è¦æ¾åº ASD çå®¢è§çç©æ¨è¨ï¼ä»¥å¹«å©æé«è¨ºæ·æºç¢ºæ§ãæ·±åº¦å­¸ç¿ (DL) å¨å¾é«å­¸å½±åè³æè¨ºæ·ç¾çåççæ¹é¢åå¾ååºçè¡¨ç¾ãå·²ç¶éå°å»ºç«ä½¿ç¨éæåè½æ§ç£æ¯é å½± (fMRI) è³æå° ASD é²è¡åé¡çæ¨¡åé²è¡å»£æ³çç ç©¶ãç¶èï¼ç¾æçæ¨¡åç¼ºä¹å¯è§£éæ§ãæ¬ç ç©¶æ¨å¨ééå»ºç«ä¸åä¸åè½æºç¢ºåé¡ ASDï¼éè½æä¾å¯è§£éè¦è§£èªªæå¶éä½åçç DL æ¨¡åï¼ä¾æ¹å ASD è¨ºæ·çæºç¢ºæ§åå¯è§£éæ§ãæä½¿ç¨çè³æéæ¯èªéçå¤§è¦å½±åè³æäº¤æ (ABIDE) çé èççæ¬ï¼åå« 884 åæ¨£æ¬ãæåçç ç©¶çµæé¡¯ç¤ºï¼è©²æ¨¡åè½æºç¢ºåé¡ ASDï¼ä¸¦å¼·èª¿ ASD èå¸åå°ç§çµä¹éå­å¨å·®ç°çééµè¦åï¼å°æ¼ ASD çæ©æè¨ºæ·åç¥ç¶åºç¤ççè§£å·ææ½å¨çæç¾©ãéäºç ç©¶çµæå·²ç±ä½¿ç¨ä¸åè³æéåæ¹å¼çæç»ç ç©¶é©è­ï¼è­å¯¦è©²æ¨¡åå¯¦éä¸å­¸ç¿äº ASD çç¹å¾µï¼èä¸ååæ¯è³æéãæ¬ç ç©¶ééæä¾ä¸åå¼·å¥ä¸å¯è§£éçæ¨¡åï¼æ¨åäºé«å­¸å½±åä¸­å¯è§£é AI çé åï¼å¾èçºæªä¾æä¾å®¢è§ä¸å¯é ç ASD è¨ºæ·ååºè²¢ç»ã

##### **Improving Prototypical Parts Abstraction for Case-Based Reasoning Explanations Designed for the Kidney Stone Type Recognition**
2409.12883v1 by Daniel Flores-Araiza, Francisco Lopez-Tiro, ClÃ©ment Larose, Salvador Hinojosa, Andres Mendez-Vazquez, Miguel Gonzalez-Mendoza, Gilberto Ochoa-Ruiz, Christian Daul

The in-vivo identification of the kidney stone types during an ureteroscopy
would be a major medical advance in urology, as it could reduce the time of the
tedious renal calculi extraction process, while diminishing infection risks.
Furthermore, such an automated procedure would make possible to prescribe
anti-recurrence treatments immediately. Nowadays, only few experienced
urologists are able to recognize the kidney stone types in the images of the
videos displayed on a screen during the endoscopy. Thus, several deep learning
(DL) models have recently been proposed to automatically recognize the kidney
stone types using ureteroscopic images. However, these DL models are of black
box nature whicl limits their applicability in clinical settings. This
contribution proposes a case-based reasoning DL model which uses prototypical
parts (PPs) and generates local and global descriptors. The PPs encode for each
class (i.e., kidney stone type) visual feature information (hue, saturation,
intensity and textures) similar to that used by biologists. The PPs are
optimally generated due a new loss function used during the model training.
Moreover, the local and global descriptors of PPs allow to explain the
decisions ("what" information, "where in the images") in an understandable way
for biologists and urologists. The proposed DL model has been tested on a
database including images of the six most widespread kidney stone types. The
overall average classification accuracy was 90.37. When comparing this results
with that of the eight other DL models of the kidney stone state-of-the-art, it
can be seen that the valuable gain in explanability was not reached at the
expense of accuracy which was even slightly increased with respect to that
(88.2) of the best method of the literature. These promising and interpretable
results also encourage urologists to put their trust in AI-based solutions.

æè¦ï¼å°¿è·¯é¡æª¢æ¥ä¸­èçµç³é¡åçé«å§è­å¥å°æ¯æ³å°¿ç§çä¸é éå¤§é²å±ï¼å çºå®å¯ä»¥æ¸å°ç¹ç£çèçµç³ååºéç¨çæéï¼åæéä½ææé¢¨éªãæ­¤å¤ï¼éç¨®èªååç¨åºå°ä½¿ç«å³éç«æå¾©ç¼æ²»çæçºå¯è½ãå¦ä»ï¼åªæå°æ¸ç¶é©è±å¯çæ³å°¿ç§é«çè½å¤ å¨å§è¦é¡æª¢æ¥æéå±å¹ä¸é¡¯ç¤ºçè¦é »ååä¸­è­å¥èçµç³é¡åãå æ­¤ï¼æè¿å·²æåºå¤ç¨®æ·±åº¦å­¸ç¿ (DL) æ¨¡åï¼ä»¥ä½¿ç¨è¼¸å°¿ç®¡é¡ååèªåè­å¥èçµç³é¡åãç¶èï¼éäº DL æ¨¡åæ¬è³ªä¸æ¯é»çå­ï¼ééå¶äºå®åå¨è¨åºç°å¢ä¸­çæç¨æ§ãæ¬ææåºäºä¸ååºæ¼æ¡ä¾æ¨çç DL æ¨¡åï¼å®ä½¿ç¨ååé¨å (PP) ä¸¦çæå±é¨åå¨å±æè¿°ç¬¦ãPP çºæ¯ç¨®é¡åï¼å³èçµç³é¡åï¼ç·¨ç¢¼è¦è¦ºç¹å¾µä¿¡æ¯ï¼è²èª¿ãé£½ååº¦ãå¼·åº¦åç´çï¼ï¼é¡ä¼¼æ¼çç©å­¸å®¶ä½¿ç¨çä¿¡æ¯ãç±æ¼å¨æ¨¡åè¨ç·´æéä½¿ç¨çæ°æå¤±å½æ¸ï¼PP å¾å°äºæä½³çæãæ­¤å¤ï¼PP çå±é¨åå¨å±æè¿°ç¬¦åè¨±ä»¥çç©å­¸å®¶åæ³å°¿ç§é«çå¯ä»¥çè§£çæ¹å¼è§£éæ±ºç­ï¼âä»éº¼âä¿¡æ¯ï¼âååä¸­çä»éº¼ä½ç½®âï¼ãææåºç DL æ¨¡åå·²å¨ä¸ååå«å­ç¨®æå»£æ³çèçµç³é¡åååçæ¸æåº«ä¸é²è¡äºæ¸¬è©¦ãç¸½é«å¹³ååé¡æºç¢ºççº 90.37ãå°æ­¤çµæèèçµç³æåé²çå«åå¶ä» DL æ¨¡åççµæé²è¡æ¯è¼æï¼å¯ä»¥çåºï¼å¯è§£éæ§çå¯¶è²´å¢çä¸¦æªä»¥æºç¢ºæ§çºä»£å¹ï¼çè³ç¥æå¢å èæç»ä¸­æå¥½çæ¹æ³ (88.2) ç¸æ¯ãéäºæå¸æä¸å¯è§£éççµæä¹é¼åµæ³å°¿ç§é«çç¸ä¿¡åºæ¼äººå·¥æºè½çè§£æ±ºæ¹æ¡ã

##### **Towards Interpretable End-Stage Renal Disease (ESRD) Prediction: Utilizing Administrative Claims Data with Explainable AI Techniques**
2409.12087v3 by Yubo Li, Saba Al-Sayouri, Rema Padman

This study explores the potential of utilizing administrative claims data,
combined with advanced machine learning and deep learning techniques, to
predict the progression of Chronic Kidney Disease (CKD) to End-Stage Renal
Disease (ESRD). We analyze a comprehensive, 10-year dataset provided by a major
health insurance organization to develop prediction models for multiple
observation windows using traditional machine learning methods such as Random
Forest and XGBoost as well as deep learning approaches such as Long Short-Term
Memory (LSTM) networks. Our findings demonstrate that the LSTM model,
particularly with a 24-month observation window, exhibits superior performance
in predicting ESRD progression, outperforming existing models in the
literature. We further apply SHapley Additive exPlanations (SHAP) analysis to
enhance interpretability, providing insights into the impact of individual
features on predictions at the individual patient level. This study underscores
the value of leveraging administrative claims data for CKD management and
predicting ESRD progression.

æè¦ï¼æ¬ç ç©¶æ¢è¨å©ç¨è¡æ¿ç³å ±è³æï¼çµååé²æ©å¨å­¸ç¿èæ·±åº¦å­¸ç¿æè¡ï¼é æ¸¬æ¢æ§èèç (CKD) é²å±è³æ«æèèç¾ç (ESRD) çå¯è½æ§ãæååæä¸å®¶å¤§åå¥åº·ä¿éªçµç¹æä¾ç 10 å¹´ç¶åè³æéï¼ä½¿ç¨å³çµ±æ©å¨å­¸ç¿æ¹æ³ï¼ä¾å¦é¨æ©æ£®æå XGBoostï¼ä»¥åæ·±åº¦å­¸ç¿æ¹æ³ï¼ä¾å¦é·æç­æè¨æ¶ (LSTM) ç¶²è·¯ï¼éç¼å¤åè§å¯è¦çªçé æ¸¬æ¨¡åãæåçç ç©¶çµæé¡¯ç¤ºï¼LSTM æ¨¡åï¼å°¤å¶æ¯ 24 åæè§å¯è¦çªï¼å¨é æ¸¬ ESRD é²å±æ¹é¢è¡¨ç¾åªç°ï¼åªæ¼æç»ä¸­çç¾ææ¨¡åãæåé²ä¸æ­¥æç¨ SHapley å¯å æ§è§£é (SHAP) åæä»¥å¢å¼·å¯è§£éæ§ï¼æ·±å¥äºè§£åå¥ç¹å¾µå°åå¥æ£èå±¤ç´é æ¸¬çå½±é¿ãæ¬ç ç©¶å¼·èª¿äºå©ç¨è¡æ¿ç³å ±è³æé²è¡ CKD ç®¡çåé æ¸¬ ESRD é²å±çå¹å¼ã

##### **Explainable AI: Definition and attributes of a good explanation for health AI**
2409.15338v1 by Evangelia Kyrimi, Scott McLachlan, Jared M Wohlgemut, Zane B Perkins, David A. Lagnado, William Marsh, the ExAIDSS Expert Group

Proposals of artificial intelligence (AI) solutions based on increasingly
complex and accurate predictive models are becoming ubiquitous across many
disciplines. As the complexity of these models grows, transparency and users'
understanding often diminish. This suggests that accurate prediction alone is
insufficient for making an AI-based solution truly useful. In the development
of healthcare systems, this introduces new issues related to accountability and
safety. Understanding how and why an AI system makes a recommendation may
require complex explanations of its inner workings and reasoning processes.
Although research on explainable AI (XAI) has significantly increased in recent
years and there is high demand for XAI in medicine, defining what constitutes a
good explanation remains ad hoc, and providing adequate explanations continues
to be challenging. To fully realize the potential of AI, it is critical to
address two fundamental questions about explanations for safety-critical AI
applications, such as health-AI: (1) What is an explanation in health-AI? and
(2) What are the attributes of a good explanation in health-AI? In this study,
we examined published literature and gathered expert opinions through a
two-round Delphi study. The research outputs include (1) a definition of what
constitutes an explanation in health-AI and (2) a comprehensive list of
attributes that characterize a good explanation in health-AI.

æè¦ï¼é¨èè¶ä¾è¶è¤éä¸æºç¢ºçé æ¸¬æ¨¡åï¼åºæ¼äººå·¥æºæ§ (AI) è§£æ±ºæ¹æ¡çææ¡å¨è¨±å¤é åä¸­è®å¾ç¡èä¸å¨ãé¨èéäºæ¨¡åè¤éæ§çå¢å ï¼éæåº¦åä½¿ç¨èççè§£åå¾å¾æéä½ãéè¡¨ç¤ºåææºç¢ºçé æ¸¬ä¸¦ä¸è¶³ä»¥è® AI è§£æ±ºæ¹æ¡çæ­£æç¨ãå¨é«çä¿å¥ç³»çµ±çéç¼ä¸­ï¼éå¼å¥äºèåè²¬å¶åå®å¨æ§ç¸éçæ°åé¡ãç­è§£ AI ç³»çµ±å¦ä½ä»¥åçºä½æåºå»ºè­°å¯è½éè¦å°å¶å§é¨éä½åæ¨çéç¨é²è¡è¤éçèªªæãåç®¡è¿å¹´ä¾å°å¯è§£é AI (XAI) çç ç©¶å·²å¤§å¹å¢å ï¼ä¸é«å­¸é åå° XAI æå¾é«çéæ±ï¼ä½å®ç¾©ä»éº¼æ§æä¸åå¥½çè§£éä»æ¯è¨ææ§çï¼èæä¾é©ç¶çè§£éä»ç¶å·æææ°æ§ãçºäºååç¼æ® AI çæ½åï¼å°æ¼å®å¨ééµå AI æç¨ï¼ä¾å¦å¥åº· AIï¼çè§£éï¼æ¢è¨å©ååºæ¬åé¡è³ééè¦ï¼(1) ä»éº¼æ¯å¥åº· AI ä¸­çè§£éï¼ä»¥å (2) å¥åº· AI ä¸­ä¸åå¥½çè§£éæåªäºå±¬æ§ï¼å¨æ¬ç ç©¶ä¸­ï¼æåæª¢è¦äºå·²ç¼è¡¨çæç»ï¼ä¸¦ééå©è¼ªå¾·ç¾è²ç ç©¶æ¶éäºå°å®¶æè¦ãç ç©¶ææåæ¬ï¼(1) å¥åº· AI ä¸­ä»éº¼æ§æè§£éçå®ç¾©ï¼ä»¥å (2) å¥åº· AI ä¸­ä¸åå¥½è§£éçå±¬æ§æ¸å®ã

##### **Exploring the Effect of Explanation Content and Format on User Comprehension and Trust**
2408.17401v1 by Antonio Rago, Bence Palfi, Purin Sukpanichnant, Hannibal Nabli, Kavyesh Vivek, Olga Kostopoulou, James Kinross, Francesca Toni

In recent years, various methods have been introduced for explaining the
outputs of "black-box" AI models. However, it is not well understood whether
users actually comprehend and trust these explanations. In this paper, we focus
on explanations for a regression tool for assessing cancer risk and examine the
effect of the explanations' content and format on the user-centric metrics of
comprehension and trust. Regarding content, we experiment with two explanation
methods: the popular SHAP, based on game-theoretic notions and thus potentially
complex for everyday users to comprehend, and occlusion-1, based on feature
occlusion which may be more comprehensible. Regarding format, we present SHAP
explanations as charts (SC), as is conventional, and occlusion-1 explanations
as charts (OC) as well as text (OT), to which their simpler nature also lends
itself. The experiments amount to user studies questioning participants, with
two different levels of expertise (the general population and those with some
medical training), on their subjective and objective comprehension of and trust
in explanations for the outputs of the regression tool. In both studies we
found a clear preference in terms of subjective comprehension and trust for
occlusion-1 over SHAP explanations in general, when comparing based on content.
However, direct comparisons of explanations when controlling for format only
revealed evidence for OT over SC explanations in most cases, suggesting that
the dominance of occlusion-1 over SHAP explanations may be driven by a
preference for text over charts as explanations. Finally, we found no evidence
of a difference between the explanation types in terms of objective
comprehension. Thus overall, the choice of the content and format of
explanations needs careful attention, since in some contexts format, rather
than content, may play the critical role in improving user experience.

æè¦ï¼<paragraph>è¿å¹´ä¾ï¼å·²ç¶å¼é²åç¨®æ¹æ³ä¾è§£éãé»ç®±ãAI æ¨¡åçè¼¸åºãç¶èï¼ç®åä¸¦ä¸æ¸æ¥ä½¿ç¨èæ¯å¦å¯¦éçè§£åä¿¡ä»»éäºè§£éãå¨æ¬æä¸­ï¼æåå°æ³¨æ¼è©ä¼°ççé¢¨éªçåæ­¸å·¥å·çè§£éï¼ä¸¦æ¢è¨è§£éçå§å®¹åæ ¼å¼å°ä»¥ä½¿ç¨èçºä¸­å¿ççè§£åä¿¡ä»»ææ¨çå½±é¿ãéæ¼å§å®¹ï¼æåå¯¦é©äºå©ç¨®è§£éæ¹æ³ï¼æµè¡ç SHAPï¼åºæ¼åå¼è«æ¦å¿µï¼å æ­¤å°æ¼æ¥å¸¸ä½¿ç¨èä¾èªªå¯è½å¾è¤éï¼ä»¥ååºæ¼ç¹å¾µé®è½ç occlusion-1ï¼å¯è½æ´ææ¼çè§£ãéæ¼æ ¼å¼ï¼æåå° SHAP è§£éåç¾çºåè¡¨ (SC)ï¼éæ¯æ£ä¾ï¼èå° occlusion-1 è§£éåç¾çºåè¡¨ (OC) ä»¥åæå­ (OT)ï¼å¶è¼çºç°¡å®çæ§è³ªä¹é©ç¨æ¼æ­¤ãéäºå¯¦é©ç­åæ¼ä½¿ç¨èç ç©¶ï¼è©¢ååèèï¼å·æå©ç¨®ä¸åç¨åº¦çå°æ¥­ç¥è­ï¼ä¸è¬æ°ç¾åå·åä¸äºé«å­¸è¨ç·´çäººï¼ï¼ä»åå°åæ­¸å·¥å·è¼¸åºè§£éçä¸»è§åå®¢è§çè§£åä¿¡ä»»ãå¨å©é ç ç©¶ä¸­ï¼æåç¼ç¾ï¼å¨åºæ¼å§å®¹é²è¡æ¯è¼æï¼ä¸è¬ä¾èªªï¼occlusion-1 åªæ¼ SHAP è§£éï¼å¨ä¸»è§çè§£åä¿¡ä»»æ¹é¢ææé¡¯çåå¥½ãç¶èï¼å¨åæ§å¶æ ¼å¼çææ³ä¸ç´æ¥æ¯è¼è§£éï¼å¨å¤§å¤æ¸ææ³ä¸åªé¡¯ç¤º OT åªæ¼ SC è§£éçè­æï¼éè¡¨æ occlusion-1 åªæ¼ SHAP è§£éçä¸»å°å°ä½å¯è½æ¯ç±åå¥½æå­èéåè¡¨ä½çºè§£éæé©åçãæå¾ï¼æåæ²æç¼ç¾è§£éé¡åå¨å®¢è§çè§£æ¹é¢çå·®ç°è­æãå æ­¤ï¼ç¸½é«èè¨ï¼å°è§£éçå§å®¹åæ ¼å¼çé¸æéè¦ä»ç´°æ³¨æï¼å çºå¨æäºææ³ä¸ï¼æ ¼å¼èéå§å®¹ï¼å¯è½å¨æ¹åä½¿ç¨èé«é©æ¹é¢ç¼æ®ééµä½ç¨ã</paragraph>

##### **A Survey for Large Language Models in Biomedicine**
2409.00133v1 by Chong Wang, Mengyao Li, Junjun He, Zhongruo Wang, Erfan Darzi, Zan Chen, Jin Ye, Tianbin Li, Yanzhou Su, Jing Ke, Kaili Qu, Shuxin Li, Yi Yu, Pietro LiÃ², Tianyun Wang, Yu Guang Wang, Yiqing Shen

Recent breakthroughs in large language models (LLMs) offer unprecedented
natural language understanding and generation capabilities. However, existing
surveys on LLMs in biomedicine often focus on specific applications or model
architectures, lacking a comprehensive analysis that integrates the latest
advancements across various biomedical domains. This review, based on an
analysis of 484 publications sourced from databases including PubMed, Web of
Science, and arXiv, provides an in-depth examination of the current landscape,
applications, challenges, and prospects of LLMs in biomedicine, distinguishing
itself by focusing on the practical implications of these models in real-world
biomedical contexts. Firstly, we explore the capabilities of LLMs in zero-shot
learning across a broad spectrum of biomedical tasks, including diagnostic
assistance, drug discovery, and personalized medicine, among others, with
insights drawn from 137 key studies. Then, we discuss adaptation strategies of
LLMs, including fine-tuning methods for both uni-modal and multi-modal LLMs to
enhance their performance in specialized biomedical contexts where zero-shot
fails to achieve, such as medical question answering and efficient processing
of biomedical literature. Finally, we discuss the challenges that LLMs face in
the biomedicine domain including data privacy concerns, limited model
interpretability, issues with dataset quality, and ethics due to the sensitive
nature of biomedical data, the need for highly reliable model outputs, and the
ethical implications of deploying AI in healthcare. To address these
challenges, we also identify future research directions of LLM in biomedicine
including federated learning methods to preserve data privacy and integrating
explainable AI methodologies to enhance the transparency of LLMs.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) çææ°çªç ´æä¾äºåææªæçèªç¶èªè¨çè§£åçæè½åãç¶èï¼ç¾æéæ¼çç©é«å­¸ä¸­ LLM çèª¿æ¥éå¸¸å°æ³¨æ¼ç¹å®æç¨ææ¨¡åæ¶æ§ï¼ç¼ºä¹æ´ååç¨®çç©é«å­¸é åææ°é²å±çå¨é¢åæãæ¬ç¶è¿°åºæ¼å°ä¾èª PubMedãWeb of Science å arXiv ç­æ¸æåº«ç 484 ç¯åºçç©çåæï¼æ·±å¥æ¢è¨äºçç©é«å­¸ä¸­ LLM çç¶åç¾æ³ãæç¨ãææ°ååæ¯ï¼å¶ç¹é»æ¯éæ³¨éäºæ¨¡åå¨ç¾å¯¦ä¸ççç©é«å­¸èæ¯ä¸­çå¯¦éæç¨ãé¦åï¼æåæ¢è¨äº LLM å¨å»£æ³ççç©é«å­¸ä»»åä¸­çé¶æ¬¡å­¸ç¿è½åï¼åæ¬è¨ºæ·è¼å©ãè¥ç©ç¼ç¾ååæ§åé«çç­ï¼ä¸¦å¾ 137 é ééµç ç©¶ä¸­æ±²åè¦è§£ãç¶å¾ï¼æåè¨è«äº LLM çé©æç­ç¥ï¼åæ¬å®æ¨¡æåå¤æ¨¡æ LLM çå¾®èª¿æ¹æ³ï¼ä»¥å¢å¼·å®åå¨é¶æ¬¡å­¸ç¿ç¡æ³å¯¦ç¾çå°æ¥­çç©é«å­¸èæ¯ä¸­çæ§è½ï¼ä¾å¦é«çåé¡è§£ç­åçç©é«å­¸æç»çææèçãæå¾ï¼æåè¨è«äº LLM å¨çç©é«å­¸é åé¢è¨çææ°ï¼åæ¬æ¸æé±ç§åé¡ãæ¨¡åå¯è§£éæ§æéãæ¸æéè³ªéåé¡ä»¥åç±æ¼çç©é«å­¸æ¸æçæææ§ãå°é«åº¦å¯é æ¨¡åè¼¸åºçéæ±ä»¥åå¨é«çä¿å¥ä¸­é¨ç½² AI çå«çå½±é¿èç¢ççå«çåé¡ãçºäºæå°éäºææ°ï¼æåéç¢ºå®äºçç©é«å­¸ä¸­ LLM æªä¾çç ç©¶æ¹åï¼åæ¬ç¨æ¼ä¿è­·æ¸æé±ç§çè¯åå­¸ç¿æ¹æ³ä»¥åæ´åå¯è§£é AI æ¹æ³ä»¥å¢å¼· LLM çéæåº¦ã

##### **Aligning XAI with EU Regulations for Smart Biomedical Devices: A Methodology for Compliance Analysis**
2408.15121v1 by Francesco Sovrano, Michael Lognoul, Giulia Vilone

Significant investment and development have gone into integrating Artificial
Intelligence (AI) in medical and healthcare applications, leading to advanced
control systems in medical technology. However, the opacity of AI systems
raises concerns about essential characteristics needed in such sensitive
applications, like transparency and trustworthiness. Our study addresses these
concerns by investigating a process for selecting the most adequate Explainable
AI (XAI) methods to comply with the explanation requirements of key EU
regulations in the context of smart bioelectronics for medical devices. The
adopted methodology starts with categorising smart devices by their control
mechanisms (open-loop, closed-loop, and semi-closed-loop systems) and delving
into their technology. Then, we analyse these regulations to define their
explainability requirements for the various devices and related goals.
Simultaneously, we classify XAI methods by their explanatory objectives. This
allows for matching legal explainability requirements with XAI explanatory
goals and determining the suitable XAI algorithms for achieving them. Our
findings provide a nuanced understanding of which XAI algorithms align better
with EU regulations for different types of medical devices. We demonstrate this
through practical case studies on different neural implants, from chronic
disease management to advanced prosthetics. This study fills a crucial gap in
aligning XAI applications in bioelectronics with stringent provisions of EU
regulations. It provides a practical framework for developers and researchers,
ensuring their AI innovations advance healthcare technology and adhere to legal
and ethical standards.

æè¦ï¼äººå·¥æºæ§ï¼AIï¼å¨é«çåä¿å¥æç¨ä¸­æå¥äºå¤§éçæè³åéç¼ï¼é²èå°è´é«çæè¡ä¸­çåé²æ§å¶ç³»çµ±ãç¶èï¼AI ç³»çµ±çä¸éææ§å¼ç¼äºå°æ­¤é¡æææç¨ä¸­æéåºæ¬ç¹æ§çææï¼ä¾å¦éæåº¦åå¯ä¿¡åº¦ãæåçç ç©¶ééèª¿æ¥ä¸åç¨åºä¾è§£æ±ºéäºåé¡ï¼ç¨æ¼é¸ææååçå¯è§£é AIï¼XAIï¼æ¹æ³ï¼ä»¥ç¬¦åæ­çæ³è¦å¨é«çå¨æçæºæ§åçç©é»å­å­¸ä¸­çèªªæè¦æ±ãæ¡ç¨çæ¹æ³å¾ééå¶æ§å¶æ©å¶ï¼éè¿´è·¯ãéè¿´è·¯ååéè¿´è·¯ç³»çµ±ï¼å°æºæ§åè£ç½®é²è¡åé¡ï¼ä¸¦æ·±å¥æ¢è¨å¶æè¡éå§ãç¶å¾ï¼æååæéäºæ³è¦ä»¥å®ç¾©å¶å°åç¨®è£ç½®åç¸éç®æ¨çå¯è§£éæ§è¦æ±ãåæï¼æåééå¶èªªæç®æ¨å° XAI æ¹æ³é²è¡åé¡ãéåè¨±å°æ³å¾å¯è§£éæ§è¦æ±è XAI èªªæç®æ¨ç¸å¹éï¼ä¸¦ç¢ºå®é©ç¶ç XAI æ¼ç®æ³ä¾éæå®åãæåçç ç©¶çµææä¾äºå°åªäº XAI æ¼ç®æ³æ´ç¬¦åæ­çæ³è¦ä»¥é©ç¨æ¼ä¸åé¡åçé«çå¨æçç´°ç·»çè§£ãæåééä¸åç¥ç¶æ¤å¥ç©çå¯¦éæ¡ä¾ç ç©¶ä¾è­æéä¸é»ï¼å¾æ¢æ§ç¾çç®¡çå°åé²çç¾©è¢ãéé ç ç©¶å¡«è£äºå°çç©é»å­å­¸ä¸­ç XAI æç¨èæ­çæ³è¦çå´æ ¼è¦å®ç¸ç¬¦çéè¦ç©ºç½ãå®çºéç¼äººå¡åç ç©¶äººå¡æä¾äºä¸åå¯¦ç¨çæ¶æ§ï¼ç¢ºä¿å¶ AI åµæ°è½ä¿é²é«çæè¡ä¸¦éµå®æ³å¾åéå¾·æ¨æºã

##### **Towards Case-based Interpretability for Medical Federated Learning**
2408.13626v1 by Laura Latorre, Liliana Petrychenko, Regina Beets-Tan, Taisiya Kopytova, Wilson Silva

We explore deep generative models to generate case-based explanations in a
medical federated learning setting. Explaining AI model decisions through
case-based interpretability is paramount to increasing trust and allowing
widespread adoption of AI in clinical practice. However, medical AI training
paradigms are shifting towards federated learning settings in order to comply
with data protection regulations. In a federated scenario, past data is
inaccessible to the current user. Thus, we use a deep generative model to
generate synthetic examples that protect privacy and explain decisions. Our
proof-of-concept focuses on pleural effusion diagnosis and uses publicly
available Chest X-ray data.

æè¦ï¼æåæ¢ç´¢æ·±åº¦çææ¨¡åï¼å¨é«çè¯é¦å­¸ç¿è¨­ç½®ä¸­çæåºæ¼æ¡ä¾çèªªæãééåºæ¼æ¡ä¾çå¯è§£éæ§ä¾è§£é AI æ¨¡åæ±ºç­ï¼å°æ¼å¢å ä¿¡ä»»ä¸¦åè¨± AI å¨è¨åºå¯¦åä¸­å»£æ³æ¡ç¨è³ééè¦ãç¶èï¼é«ç AI è¨ç·´ç¯ä¾æ­£è½åè¯é¦å­¸ç¿è¨­ç½®ï¼ä»¥ç¬¦åè³æä¿è­·æ³è¦ãå¨è¯é¦æå¢ä¸­ï¼éå»çè³æå°ç®åçä½¿ç¨èèè¨æ¯ç¡æ³åå¾çãå æ­¤ï¼æåä½¿ç¨æ·±åº¦çææ¨¡åä¾ç¢çä¿è­·é±ç§åè§£éæ±ºç­çåæç¯ä¾ãæåçæ¦å¿µé©è­èéæ¼è¸èç©æ¶²è¨ºæ·ï¼ä¸¦ä½¿ç¨å¬éå¯åå¾çè¸é¨ X åè³æã

##### **AI in radiological imaging of soft-tissue and bone tumours: a systematic review evaluating against CLAIM and FUTURE-AI guidelines**
2408.12491v1 by Douwe J. Spaanderman, Matthew Marzetti, Xinyi Wan, Andrew F. Scarsbrook, Philip Robinson, Edwin H. G. Oei, Jacob J. Visser, Robert Hemke, Kirsten van Langevelde, David F. Hanff, Geert J. L. H. van Leenders, Cornelis Verhoef, Dirk J. GruÃ¼hagen, Wiro J. Niessen, Stefan Klein, Martijn P. A. Starmans

Soft-tissue and bone tumours (STBT) are rare, diagnostically challenging
lesions with variable clinical behaviours and treatment approaches. This
systematic review provides an overview of Artificial Intelligence (AI) methods
using radiological imaging for diagnosis and prognosis of these tumours,
highlighting challenges in clinical translation, and evaluating study alignment
with the Checklist for AI in Medical Imaging (CLAIM) and the FUTURE-AI
international consensus guidelines for trustworthy and deployable AI to promote
the clinical translation of AI methods. The review covered literature from
several bibliographic databases, including papers published before 17/07/2024.
Original research in peer-reviewed journals focused on radiology-based AI for
diagnosing or prognosing primary STBT was included. Exclusion criteria were
animal, cadaveric, or laboratory studies, and non-English papers. Abstracts
were screened by two of three independent reviewers for eligibility. Eligible
papers were assessed against guidelines by one of three independent reviewers.
The search identified 15,015 abstracts, from which 325 articles were included
for evaluation. Most studies performed moderately on CLAIM, averaging a score
of 28.9$\pm$7.5 out of 53, but poorly on FUTURE-AI, averaging 5.1$\pm$2.1 out
of 30. Imaging-AI tools for STBT remain at the proof-of-concept stage,
indicating significant room for improvement. Future efforts by AI developers
should focus on design (e.g. define unmet clinical need, intended clinical
setting and how AI would be integrated in clinical workflow), development (e.g.
build on previous work, explainability), evaluation (e.g. evaluating and
addressing biases, evaluating AI against best practices), and data
reproducibility and availability (making documented code and data publicly
available). Following these recommendations could improve clinical translation
of AI methods.

æè¦ï¼è»çµç¹åéª¨éª¼è«ç¤ï¼STBTï¼æ¯ç½è¦ãè¨ºæ·å·æææ°æ§ççç¶ï¼å¶è¨åºè¡çºåæ²»çæ¹æ³åä¸ç¸åãéç¯ç³»çµ±æ§åé¡§æä¾äºä½¿ç¨æ¾å°å½±åé²è¡è¨ºæ·åé å¾çäººå·¥æºæ§ (AI) æ¹æ³çæ¦è§ï¼éé»èªªæäºè¨åºè½è­¯çææ°ï¼ä¸¦è©ä¼°ç ç©¶èé«çå½±å AI æ ¸æ¥è¡¨ (CLAIM) å FUTURE-AI å¯ä¿¡è³´ä¸å¯é¨ç½² AI çåéå±è­æºåçä¸è´æ§ï¼ä»¥ä¿é² AI æ¹æ³çè¨åºè½è­¯ãéç¯åé¡§æ¶µèäºå¹¾åæ¸ç®è³æåº«ä¸­çæç»ï¼åæ¬å¨ 2024 å¹´ 7 æ 17 æ¥ä¹åç¼è¡¨çè«æãç´å¥äºä»¥æ¾å°çºåºç¤ç AI è¨ºæ·æé å¾åç¼æ§ STBT çåè¡è©å¯©æåä¸­çåå§ç ç©¶ãæé¤æ¨æºæ¯åç©ãå±é«æå¯¦é©å®¤ç ç©¶ï¼ä»¥åéè±æè«æãæè¦ç±ä¸ä½ç¨ç«å¯©æ¥å¡ä¸­çå©ä½ç¯©é¸è³æ ¼ãåæ ¼çè«æç±ä¸ä½ç¨ç«å¯©æ¥å¡ä¸­çä¸ä½æ ¹ææºåé²è¡è©ä¼°ãæç´¢è­å¥åº 15,015 ç¯æè¦ï¼å¶ä¸­ 325 ç¯æç« è¢«ç´å¥è©ä¼°ãå¤§å¤æ¸ç ç©¶å¨ CLAIM ä¸­è¡¨ç¾ä¸­ç­ï¼å¹³åå¾åçº 53 åä¸­ç 28.9Â±7.5 åï¼ä½å¨ FUTURE-AI ä¸­è¡¨ç¾ä¸ä½³ï¼å¹³åå¾åçº 30 åä¸­ç 5.1Â±2.1 åãSTBT çå½±å AI å·¥å·ä»èæ¼æ¦å¿µé©è­éæ®µï¼è¡¨ææé¡¯èçæ¹é²ç©ºéãAI éç¼äººå¡æªä¾çåªåæéä¸­å¨è¨­è¨ï¼ä¾å¦å®ç¾©æªæ»¿è¶³çè¨åºéæ±ãé æçè¨åºç°å¢ä»¥å AI å¦ä½æ´åå°è¨åºå·¥ä½æµç¨ä¸­ï¼ãéç¼ï¼ä¾å¦å»ºç«å¨ååçå·¥ä½ãå¯è§£éæ§ï¼ãè©ä¼°ï¼ä¾å¦è©ä¼°åè§£æ±ºåå·®ãè©ä¼° AI èæä½³å¯¦åï¼ãä»¥åæ¸æå¯è¤è£½æ§åå¯ç¨æ§ï¼å¬éæä¾æä»¶åçä»£ç¢¼åæ¸æï¼ãéµå¾ªéäºå»ºè­°å¯ä»¥æ¹å AI æ¹æ³çè¨åºè½è­¯ã

##### **Evaluating Explainable AI Methods in Deep Learning Models for Early Detection of Cerebral Palsy**
2409.00001v1 by Kimji N. Pellano, Inga StrÃ¼mke, Daniel Groos, Lars Adde, Espen Alexander F. Ihlen

Early detection of Cerebral Palsy (CP) is crucial for effective intervention
and monitoring. This paper tests the reliability and applicability of
Explainable AI (XAI) methods using a deep learning method that predicts CP by
analyzing skeletal data extracted from video recordings of infant movements.
Specifically, we use XAI evaluation metrics -- namely faithfulness and
stability -- to quantitatively assess the reliability of Class Activation
Mapping (CAM) and Gradient-weighted Class Activation Mapping (Grad-CAM) in this
specific medical application. We utilize a unique dataset of infant movements
and apply skeleton data perturbations without distorting the original dynamics
of the infant movements. Our CP prediction model utilizes an ensemble approach,
so we evaluate the XAI metrics performances for both the overall ensemble and
the individual models. Our findings indicate that both XAI methods effectively
identify key body points influencing CP predictions and that the explanations
are robust against minor data perturbations. Grad-CAM significantly outperforms
CAM in the RISv metric, which measures stability in terms of velocity. In
contrast, CAM performs better in the RISb metric, which relates to bone
stability, and the RRS metric, which assesses internal representation
robustness. Individual models within the ensemble show varied results, and
neither CAM nor Grad-CAM consistently outperform the other, with the ensemble
approach providing a representation of outcomes from its constituent models.

æè¦ï¼è¦æ§éº»çº (CP) çæ©æåµæ¸¬å°æ¼ææçä»å¥åç£æ¸¬è³ééè¦ãæ¬ææ¸¬è©¦äºå¯è§£é AI (XAI) æ¹æ³çå¯é æ§åé©ç¨æ§ï¼ä½¿ç¨æ·±åº¦å­¸ç¿æ¹æ³ï¼ééåæå¾å¬°ååä½å½±çè¨éä¸­æåçéª¨éª¼è³æä¾é æ¸¬ CPãå·é«ä¾èªªï¼æåä½¿ç¨ XAI è©ä¼°ææ¨ï¼å³å¿ å¯¦åº¦åç©©å®æ§ï¼ä¾éåè©ä¼°é¡å¥æ¿æ´»æ å° (CAM) åæ¢¯åº¦å æ¬é¡å¥æ¿æ´»æ å° (Grad-CAM) å¨éåç¹å®é«çæç¨ä¸­çå¯é æ§ãæåå©ç¨ä¸åç¨ç¹çå¬°ååä½è³æéï¼ä¸¦æç¨éª¨éª¼è³ææ¾åï¼èä¸ææ­æ²å¬°ååä½çåå§ååãæåç CP é æ¸¬æ¨¡åå©ç¨æ´é«æ¹æ³ï¼å æ­¤æåè©ä¼°äºæ´é«æ´é«ååå¥æ¨¡åç XAI ææ¨è¡¨ç¾ãæåçç ç©¶çµæè¡¨æï¼å©ç¨® XAI æ¹æ³é½è½ææè­å¥å½±é¿ CP é æ¸¬çééµèº«é«é¨ä½ï¼ä¸¦ä¸éäºè§£éå°æ¼å¾®å°çè³ææ¾åå·æé­¯æ£æ§ãGrad-CAM å¨ RISv ææ¨ä¸­é¡¯èåªæ¼ CAMï¼è©²ææ¨è¡¡ééåº¦æ¹é¢çç©©å®æ§ãç¸æ¯ä¹ä¸ï¼CAM å¨ RISb ææ¨ä¸­è¡¨ç¾å¾æ´å¥½ï¼è©²ææ¨èéª¨éª¼ç©©å®æ§æéï¼è RRS ææ¨åè©ä¼°å§é¨è¡¨ç¤ºçé­¯æ£æ§ãæ´é«ä¸­çåå¥æ¨¡åé¡¯ç¤ºåºä¸åççµæï¼CAM å Grad-CAM é½ä¸ä¸è´å°åªæ¼å¦ä¸ç¨®ï¼æ´é«æ¹æ³æä¾äºå¶çµææ¨¡åçµæçè¡¨ç¤ºã

##### **MicroXercise: A Micro-Level Comparative and Explainable System for Remote Physical Therapy**
2408.11837v1 by Hanchen David Wang, Nibraas Khan, Anna Chen, Nilanjan Sarkar, Pamela Wisniewski, Meiyi Ma

Recent global estimates suggest that as many as 2.41 billion individuals have
health conditions that would benefit from rehabilitation services. Home-based
Physical Therapy (PT) faces significant challenges in providing interactive
feedback and meaningful observation for therapists and patients. To fill this
gap, we present MicroXercise, which integrates micro-motion analysis with
wearable sensors, providing therapists and patients with a comprehensive
feedback interface, including video, text, and scores. Crucially, it employs
multi-dimensional Dynamic Time Warping (DTW) and attribution-based explainable
methods to analyze the existing deep learning neural networks in monitoring
exercises, focusing on a high granularity of exercise. This synergistic
approach is pivotal, providing output matching the input size to precisely
highlight critical subtleties and movements in PT, thus transforming complex AI
analysis into clear, actionable feedback. By highlighting these micro-motions
in different metrics, such as stability and range of motion, MicroXercise
significantly enhances the understanding and relevance of feedback for
end-users. Comparative performance metrics underscore its effectiveness over
traditional methods, such as a 39% and 42% improvement in Feature Mutual
Information (FMI) and Continuity. MicroXercise is a step ahead in home-based
physical therapy, providing a technologically advanced and intuitively helpful
solution to enhance patient care and outcomes.

æè¦ï¼æè¿çå¨çä¼°è¨è¡¨æï¼å¤é 24.1 åäººæ
å¥åº·çæ³å¯å¾å¾©å¥æåä¸­åçãå±å®¶
ç©çæ²»ç (PT) å¨æä¾äºåå¼
åé¥åææç¾©çè§å¯æ¹é¢é¢è¨éå¤§ææ°ï¼ä¾æ²»çå¸«åæ£èä½¿ç¨ãçºäºå¡«è£é
åç¼ºå£ï¼æåæåº MicroXerciseï¼å®å°å¾®åä½åæè
å¯ç©¿æ´å¼ææ¸¬å¨æ´åå¨ä¸èµ·ï¼çºæ²»çå¸«åæ£èæä¾ä¸åå¨é¢ç
åé¥ä»é¢ï¼åæ¬å½±çãæå­ååæ¸ãè³ééè¦çæ¯ï¼å®æ¡ç¨
å¤ç¶­åææéè¦æ´ (DTW) ååºæ¼æ­¸å çå¯è§£é
æ¹æ³ä¾åæç£æ§éåä¸­ç¾æçæ·±åº¦å­¸ç¿ç¥ç¶ç¶²è·¯ï¼å°æ³¨æ¼éåçé«ç²åº¦ãéç¨®åå
æ¹æ³è³ééè¦ï¼æä¾èè¼¸å¥å¤§å°å¹éçè¼¸åºï¼ä»¥ç²¾ç¢ºå°
çªåº PT ä¸­ééµçç´°å¾®å·®å¥ååä½ï¼å¾èå°è¤éç AI
åæè½æçºæ¸æ°ãå¯æä½çåé¥ãééå¨ä¸åææ¨ä¸­çªé¡¯éäºå¾®åä½ï¼ä¾å¦ç©©å®æ§ååä½ç¯åï¼MicroXercise
é¡¯èæåæçµä½¿ç¨èå°åé¥ççè§£åç¸éæ§ãæ¯è¼æè½ææ¨å¼·èª¿å¶åªæ¼
å³çµ±æ¹æ³çæææ§ï¼ä¾å¦ç¹å¾µäºæ è³è¨ (FMI) åé£çºæ§åå¥æåäº 39% å 42%ãMicroXercise å¨å±å®¶
ç©çæ²»çæ¹é¢æ´é²ä¸æ­¥ï¼æä¾æè¡åé²ä¸ç´è¦ºæç¨ç
è§£æ±ºæ¹æ¡ï¼ä»¥æåæ£èç§è­·åçµæã

##### **The Literature Review Network: An Explainable Artificial Intelligence for Systematic Literature Reviews, Meta-analyses, and Method Development**
2408.05239v1 by Joshua Morriss, Tod Brindle, Jessica Bah RÃ¶sman, Daniel Reibsamen, Andreas Enz

Systematic literature reviews are the highest quality of evidence in
research. However, the review process is hindered by significant resource and
data constraints. The Literature Review Network (LRN) is the first of its kind
explainable AI platform adhering to PRISMA 2020 standards, designed to automate
the entire literature review process. LRN was evaluated in the domain of
surgical glove practices using 3 search strings developed by experts to query
PubMed. A non-expert trained all LRN models. Performance was benchmarked
against an expert manual review. Explainability and performance metrics
assessed LRN's ability to replicate the experts' review. Concordance was
measured with the Jaccard index and confusion matrices. Researchers were
blinded to the other's results until study completion. Overlapping studies were
integrated into an LRN-generated systematic review. LRN models demonstrated
superior classification accuracy without expert training, achieving 84.78% and
85.71% accuracy. The highest performance model achieved high interrater
reliability (k = 0.4953) and explainability metrics, linking 'reduce',
'accident', and 'sharp' with 'double-gloving'. Another LRN model covered 91.51%
of the relevant literature despite diverging from the non-expert's judgments (k
= 0.2174), with the terms 'latex', 'double' (gloves), and 'indication'. LRN
outperformed the manual review (19,920 minutes over 11 months), reducing the
entire process to 288.6 minutes over 5 days. This study demonstrates that
explainable AI does not require expert training to successfully conduct
PRISMA-compliant systematic literature reviews like an expert. LRN summarized
the results of surgical glove studies and identified themes that were nearly
identical to the clinical researchers' findings. Explainable AI can accurately
expedite our understanding of clinical practices, potentially revolutionizing
healthcare research.

æè¦ï¼ç³»çµ±æ§æç»åé¡§æ¯ç ç©¶ä¸­è­æåè³ªæé«çãç¶èï¼åé¡§éç¨åå°é¡¯èè³æºåè³æéå¶çé»ç¤ãæç»åé¡§ç¶²è·¯ (LRN) æ¯ç¬¬ä¸åéµå¾ª PRISMA 2020 æ¨æºçå¯è§£é AI å¹³å°ï¼æ¨å¨èªååæ´åæç»åé¡§éç¨ãLRN å¨å¤ç§æå¥å¯¦åé åä¸­é²è¡è©ä¼°ï¼ä½¿ç¨å°å®¶éç¼ç 3 åæå°å­ä¸²ä¾æ¥è©¢ PubMedãéå°å®¶è¨ç·´ææ LRN æ¨¡åãæè½ä»¥å°å®¶æååé¡§ä½çºåºæºãå¯è§£éæ§åæè½ææ¨è©ä¼° LRN è¤è£½å°å®¶åé¡§çè½åãä¸è´æ§ä»¥ Jaccard ææ¸åæ··æ·ç©é£æ¸¬éãç ç©¶äººå¡å¨ç ç©¶å®æåå°å½¼æ­¤ççµæä¿å¯ãéççç ç©¶æ´åå° LRN çæçç³»çµ±æ§åé¡§ä¸­ãLRN æ¨¡åå¨æ²æå°å®¶è¨ç·´çææ³ä¸å±ç¾åºåªç°çåé¡æºç¢ºçï¼éå° 84.78% å 85.71% çæºç¢ºçãæè½æé«çæ¨¡åéå°äºé«è©åèéä¿¡è³´åº¦ (k = 0.4953) åå¯è§£éæ§ææ¨ï¼å°ãæ¸å°ãããæå¤ãåãé³å©ãèãééæ´æå¥ãé£çµå¨ä¸èµ·ãå¦ä¸å LRN æ¨¡åæ¶µèäº 91.51% çç¸éæç»ï¼åç®¡èéå°å®¶çå¤æ·ä¸å (k = 0.2174)ï¼ä½åå«äºãä¹³è ãããééãï¼æå¥ï¼åãé©æçãç­è©å½ãLRN åªæ¼æååé¡§ï¼11 åæè¶é 19,920 åéï¼ï¼å°æ´åéç¨ç¸®ç­çº 5 å¤©è¶é 288.6 åéãéé ç ç©¶é¡¯ç¤ºï¼å¯è§£éç AI ä¸éè¦å°å®¶è¨ç·´å³å¯æåé²è¡å°å®¶ç­ç´ç PRISMA ç¸å®¹ç³»çµ±æ§æç»åé¡§ãLRN ç¸½çµäºå¤ç§æå¥ç ç©¶ççµæï¼ä¸¦æ¾åºèè¨åºç ç©¶äººå¡ç¼ç¾å¹¾ä¹ç¸åçä¸»é¢ãå¯è§£éç AI å¯ä»¥æºç¢ºå°å å¿«æåå°è¨åºå¯¦åççè§£ï¼ææ½åé©æ°é«çä¿å¥ç ç©¶ã

##### **Enhancing Medical Learning and Reasoning Systems: A Boxology-Based Comparative Analysis of Design Patterns**
2408.02709v1 by Chi Him Ng

This study analyzes hybrid AI systems' design patterns and their
effectiveness in clinical decision-making using the boxology framework. It
categorizes and copares various architectures combining machine learning and
rule-based reasoning to provide insights into their structural foundations and
healthcare applications. Addressing two main questions, how to categorize these
systems againts established design patterns and how to extract insights through
comparative analysis, the study uses design patterns from software engineering
to understand and optimize healthcare AI systems. Boxology helps identify
commonalities and create reusable solutions, enhancing these systems'
scalability, reliability, and performance. Five primary architectures are
examined: REML, MLRB, RBML, RMLT, and PERML. Each has unique strengths and
weaknesses, highlighting the need for tailored approaches in clinical tasks.
REML excels in high-accuracy prediction for datasets with limited data; MLRB in
handling large datasets and complex data integration; RBML in explainability
and trustworthiness; RMLT in managing high-dimensional data; and PERML, though
limited in analysis, shows promise in urgent care scenarios. The study
introduces four new patterns, creates five abstract categorization patterns,
and refines those five further to specific systems. These contributions enhance
Boxlogy's taxonomical organization and offer novel approaches to integrating
expert knowledge with machine learning. Boxology's structured, modular apporach
offers significant advantages in developing and analyzing hybrid AI systems,
revealing commonalities, and promoting reusable solutions. In conclusion, this
study underscores hybrid AI systems' crucial role in advancing healthcare and
Boxology's potential to drive further innovation in AI integration, ultimately
improving clinical decision support and patient outcomes.

æè¦ï¼æ¬ç ç©¶ä½¿ç¨çå­å­¸æ¡æ¶åææ··åäººå·¥æºæ§ç³»çµ±çè¨­è¨æ¨¡å¼åå¶å¨è¨åºæ±ºç­ä¸­çæææ§ãå®åé¡ä¸¦æ¯è¼çµåæ©å¨å­¸ç¿ååºæ¼è¦åçæ¨ççåç¨®æ¶æ§ï¼ä»¥æ·±å¥äºè§£å¶çµæ§åºç¤åé«çä¿å¥æç¨ãéå°å©åä¸»è¦åé¡ï¼å¦ä½æ ¹ææ¢å®çè¨­è¨æ¨¡å¼å°éäºç³»çµ±é²è¡åé¡ï¼ä»¥åå¦ä½ééæ¯è¼åææåè¦è§£ï¼æ¬ç ç©¶ä½¿ç¨è»é«å·¥ç¨ä¸­çè¨­è¨æ¨¡å¼ä¾äºè§£ååªåé«çä¿å¥äººå·¥æºæ§ç³»çµ±ãçå­å­¸æå©æ¼è­å¥å±æ§ä¸¦å»ºç«å¯éè¤ä½¿ç¨çè§£æ±ºæ¹æ¡ï¼å¾èå¢å¼·éäºç³»çµ±çå¯æ´åæ§ãå¯é æ§åæè½ãæª¢æ¥äºäºç¨®ä¸»è¦çæ¶æ§ï¼REMLãMLRBãRBMLãRMLT å PERMLãæ¯ç¨®æ¶æ§é½æç¨ç¹çåªç¼ºé»ï¼å¼·èª¿äºå¨è¨åºä»»åä¸­éè¦éèº«æé çæ¹æ³ãREML å¨è³ææéçè³æéä¸­è¡¨ç¾åºé«ç²¾åº¦çé æ¸¬ï¼MLRB å¨èçå¤§åè³æéåè¤éè³ææ´åæ¹é¢è¡¨ç¾åºè²ï¼RBML å¨å¯è§£éæ§åå¯ä¿¡åº¦æ¹é¢è¡¨ç¾åºè²ï¼RMLT å¨ç®¡çé«ç¶­è³ææ¹é¢è¡¨ç¾åºè²ï¼è PERML åç®¡å¨åææ¹é¢æéï¼ä½å¨ç·æ¥ç§è­·å ´æ¯ä¸­è¡¨ç¾åºæ½åãæ¬ç ç©¶å¼å¥äºåç¨®æ°æ¨¡å¼ï¼å»ºç«äºäºç¨®æ½è±¡åé¡æ¨¡å¼ï¼ä¸¦é²ä¸æ­¥å°éäºç¨®æ¨¡å¼ç´°åçºå·é«çç³»çµ±ãéäºè²¢ç»å¢å¼·äºçå­å­¸çåé¡çµç¹ï¼ä¸¦æä¾äºå°å°å®¶ç¥è­èæ©å¨å­¸ç¿æ´åçæ°æ¹æ³ãçå­å­¸ççµæ§åãæ¨¡çµåæ¹æ³å¨éç¼ååææ··åäººå·¥æºæ§ç³»çµ±ãæ­ç¤ºå±æ§ä»¥åæ¨å»£å¯éè¤ä½¿ç¨çè§£æ±ºæ¹æ¡æ¹é¢å·æé¡¯èåªå¢ãç¸½ä¹ï¼æ¬ç ç©¶å¼·èª¿äºæ··åäººå·¥æºæ§ç³»çµ±å¨æ¨é²é«çä¿å¥ä¸­çééµä½ç¨ï¼ä»¥åçå­å­¸å¨æ¨åäººå·¥æºæ§æ´åé²ä¸æ­¥åµæ°æ¹é¢çæ½åï¼æçµæ¹åè¨åºæ±ºç­æ¯æ´åæ£èçæ²»çææã

##### **Bayesian Kolmogorov Arnold Networks (Bayesian_KANs): A Probabilistic Approach to Enhance Accuracy and Interpretability**
2408.02706v1 by Masoud Muhammed Hassan

Because of its strong predictive skills, deep learning has emerged as an
essential tool in many industries, including healthcare. Traditional deep
learning models, on the other hand, frequently lack interpretability and omit
to take prediction uncertainty into account two crucial components of clinical
decision making. In order to produce explainable and uncertainty aware
predictions, this study presents a novel framework called Bayesian Kolmogorov
Arnold Networks (BKANs), which combines the expressive capacity of Kolmogorov
Arnold Networks with Bayesian inference. We employ BKANs on two medical
datasets, which are widely used benchmarks for assessing machine learning
models in medical diagnostics: the Pima Indians Diabetes dataset and the
Cleveland Heart Disease dataset. Our method provides useful insights into
prediction confidence and decision boundaries and outperforms traditional deep
learning models in terms of prediction accuracy. Moreover, BKANs' capacity to
represent aleatoric and epistemic uncertainty guarantees doctors receive more
solid and trustworthy decision support. Our Bayesian strategy improves the
interpretability of the model and considerably minimises overfitting, which is
important for tiny and imbalanced medical datasets, according to experimental
results. We present possible expansions to further use BKANs in more
complicated multimodal datasets and address the significance of these
discoveries for future research in building reliable AI systems for healthcare.
This work paves the way for a new paradigm in deep learning model deployment in
vital sectors where transparency and reliability are crucial.

æè¦ï¼ç±æ¼å¶å¼·å¤§çé æ¸¬è½åï¼æ·±åº¦å­¸ç¿å·²æçºè¨±å¤ç¢æ¥­ä¸­ä¸å¯æç¼ºçå·¥å·ï¼åæ¬é«çä¿å¥ãç¶èï¼å³çµ±çæ·±åº¦å­¸ç¿æ¨¡åéå¸¸ç¼ºä¹å¯è§£éæ§ï¼ä¸¦ä¸å¿½ç¥äºå°é æ¸¬ä¸ç¢ºå®æ§ç´å¥èéï¼èéå©åå ç´ æ¯è¨åºæ±ºç­å¶å®çééµçµæé¨åãçºäºç¢çå¯è§£éä¸å·æä¸ç¢ºå®æ§æè­çé æ¸¬ï¼æ¬ç ç©¶æåºäºä¸ååçºè²æ°æ¯ç¾è«å¥æ´å¤«é¿è«¾å¾·ç¶²è·¯ (BKAN) çæ°æ¶æ§ï¼å®çµåäºæ¯ç¾è«å¥æ´å¤«é¿è«¾å¾·ç¶²è·¯çè¡¨éè½åèè²æ°æ¨è«ãæåå¨å©åé«å­¸è³æéä¸ä½¿ç¨ BKANï¼éäºè³æéæ¯è©ä¼°æ©å¨å­¸ç¿æ¨¡åå¨é«å­¸è¨ºæ·ä¸­çå»£æ³ä½¿ç¨åºæºï¼ç®é¦¬å°ç¬¬å®äººç³å°¿çè³æéååéå¤«è­å¿èçè³æéãæåçæ¨¡åæä¾äºå°é æ¸¬ä¿¡å¿åæ±ºç­éççæçè¦è§£ï¼ä¸¦ä¸å¨é æ¸¬æºç¢ºåº¦æ¹é¢åªæ¼å³çµ±çæ·±åº¦å­¸ç¿æ¨¡åãæ­¤å¤ï¼BKAN è¡¨ç¾é¨æ©åèªè­ä¸ç¢ºå®æ§çè½åï¼å¯ç¢ºä¿é«çç²å¾æ´å¯é ä¸å¼å¾ä¿¡è³´çæ±ºç­æ¯æ´ãæ ¹æå¯¦é©çµæï¼æåçè²æ°ç­ç¥æé«äºæ¨¡åçå¯è§£éæ§ï¼ä¸¦å¤§å¹æ¸å°äºéåº¦æ¬åï¼éå°æ¼å°åä¸ä¸å¹³è¡¡çé«å­¸è³æééå¸¸éè¦ãæåæåºäºå¯è½çæ´ååè½ï¼ä»¥é²ä¸æ­¥å° BKAN ç¨æ¼æ´è¤éçå¤æ¨¡å¼è³æéï¼ä¸¦æ¢è¨éäºç¼ç¾å°æ¼æªä¾å»ºç«å¯é çé«çä¿å¥ AI ç³»çµ±ç ç©¶çéè¦æ§ãéé å·¥ä½çºæ·±åº¦å­¸ç¿æ¨¡åé¨ç½²å¨éæåº¦åå¯é æ§è³ééè¦çéè¦é åä¸­éåäºä¸åæ°çå¸ç¯ã

##### **MLtoGAI: Semantic Web based with Machine Learning for Enhanced Disease Prediction and Personalized Recommendations using Generative AI**
2407.20284v1 by Shyam Dongre, Ritesh Chandra, Sonali Agarwal

In modern healthcare, addressing the complexities of accurate disease
prediction and personalized recommendations is both crucial and challenging.
This research introduces MLtoGAI, which integrates Semantic Web technology with
Machine Learning (ML) to enhance disease prediction and offer user-friendly
explanations through ChatGPT. The system comprises three key components: a
reusable disease ontology that incorporates detailed knowledge about various
diseases, a diagnostic classification model that uses patient symptoms to
detect specific diseases accurately, and the integration of Semantic Web Rule
Language (SWRL) with ontology and ChatGPT to generate clear, personalized
health advice. This approach significantly improves prediction accuracy and
ensures results that are easy to understand, addressing the complexity of
diseases and diverse symptoms. The MLtoGAI system demonstrates substantial
advancements in accuracy and user satisfaction, contributing to developing more
intelligent and accessible healthcare solutions. This innovative approach
combines the strengths of ML algorithms with the ability to provide
transparent, human-understandable explanations through ChatGPT, achieving
significant improvements in prediction accuracy and user comprehension. By
leveraging semantic technology and explainable AI, the system enhances the
accuracy of disease prediction and ensures that the recommendations are
relevant and easily understood by individual patients. Our research highlights
the potential of integrating advanced technologies to overcome existing
challenges in medical diagnostics, paving the way for future developments in
intelligent healthcare systems. Additionally, the system is validated using 200
synthetic patient data records, ensuring robust performance and reliability.

æè¦ï¼å¨ç¾ä»£é«çä¿å¥ä¸­ï¼è§£æ±ºæºç¢ºç¾çé æ¸¬ååæ§åå»ºè­°çè¤éæ§æ¢è³ééè¦åå·æææ°æ§ãæ¬ç ç©¶å¼å¥äº MLtoGAIï¼å®å°èªç¾©ç¶²è·¯æè¡èæ©å¨å­¸ç¿ (ML) ç¸çµåï¼ä»¥å¢å¼·ç¾çé æ¸¬ä¸¦éé ChatGPT æä¾ä½¿ç¨èååçèªªæãè©²ç³»çµ±åå«ä¸åééµçµæé¨åï¼ä¸åå¯éè¤ä½¿ç¨çç¾çæ¬ä½ï¼å¶ä¸­åå«æéåç¨®ç¾ççè©³ç´°ç¥è­ï¼ä¸åè¨ºæ·åé¡æ¨¡åï¼å®ä½¿ç¨æ£èççä¾æºç¢ºæª¢æ¸¬ç¹å®ç¾çï¼ä»¥åèªç¾©ç¶²è·¯è¦åèªè¨ (SWRL) èæ¬ä½å ChatGPT çæ´åï¼ä»¥ç¢çæ¸æ°ãåæ§åçå¥åº·å»ºè­°ãéç¨®æ¹æ³é¡¯èæé«äºé æ¸¬æºç¢ºæ§ï¼ä¸¦ç¢ºä¿äºææ¼çè§£ççµæï¼è§£æ±ºäºç¾çåä¸åçççè¤éæ§ãMLtoGAI ç³»çµ±å±ç¤ºäºæºç¢ºæ§åä½¿ç¨èæ»¿æåº¦çå¯¦è³ªæ§é²æ­¥ï¼æå©æ¼éç¼æ´æºæ§ä¸æ´ææ¼åå¾çé«çä¿å¥è§£æ±ºæ¹æ¡ãéç¨®åµæ°çæ¹æ³çµåäº ML æ¼ç®æ³çåªé»ï¼ä»¥åéé ChatGPT æä¾éæä¸äººé¡å¯ä»¥çè§£çèªªæçè½åï¼å¨é æ¸¬æºç¢ºæ§åä½¿ç¨èçè§£æ¹é¢åå¾äºé¡¯èçé²æ­¥ãééå©ç¨èªç¾©æè¡åå¯è§£éç AIï¼è©²ç³»çµ±æé«äºç¾çé æ¸¬çæºç¢ºæ§ï¼ä¸¦ç¢ºä¿äºå»ºè­°èåå¥æ£èç¸éä¸ææ¼çè§£ãæåçç ç©¶å¼·èª¿äºæ´ååé²æè¡ä»¥åæé«çè¨ºæ·ä¸­ç¾æææ°çæ½åï¼çºæºæ§é«çä¿å¥ç³»çµ±çæªä¾ç¼å±éªè·¯ãæ­¤å¤ï¼è©²ç³»çµ±ä½¿ç¨ 200 ååææ£èè³æè¨éé²è¡é©è­ï¼ç¢ºä¿äºç©©å¥çæè½åå¯é æ§ã

##### **Introducing Î´-XAI: a novel sensitivity-based method for local AI explanations**
2407.18343v2 by Alessandro De Carlo, Enea Parimbelli, Nicola Melillo, Giovanna Nicora

Explainable Artificial Intelligence (XAI) is central to the debate on
integrating Artificial Intelligence (AI) and Machine Learning (ML) algorithms
into clinical practice. High-performing AI/ML models, such as ensemble learners
and deep neural networks, often lack interpretability, hampering clinicians'
trust in their predictions. To address this, XAI techniques are being developed
to describe AI/ML predictions in human-understandable terms. One promising
direction is the adaptation of sensitivity analysis (SA) and global sensitivity
analysis (GSA), which inherently rank model inputs by their impact on
predictions. Here, we introduce a novel delta-XAI method that provides local
explanations of ML model predictions by extending the delta index, a GSA
metric. The delta-XAI index assesses the impact of each feature's value on the
predicted output for individual instances in both regression and classification
problems. We formalize the delta-XAI index and provide code for its
implementation. The delta-XAI method was evaluated on simulated scenarios using
linear regression models, with Shapley values serving as a benchmark. Results
showed that the delta-XAI index is generally consistent with Shapley values,
with notable discrepancies in models with highly impactful or extreme feature
values. The delta-XAI index demonstrated higher sensitivity in detecting
dominant features and handling extreme feature values. Qualitatively, the
delta-XAI provides intuitive explanations by leveraging probability density
functions, making feature rankings clearer and more explainable for
practitioners. Overall, the delta-XAI method appears promising for robustly
obtaining local explanations of ML model predictions. Further investigations in
real-world clinical settings will be conducted to evaluate its impact on
AI-assisted clinical workflows.

æè¦ï¼å¯è§£éäººå·¥æºæ§ (XAI) æ¯å°äººå·¥æºæ§ (AI) åæ©å¨å­¸ç¿ (ML) æ¼ç®æ³æ´åå°è¨åºå¯¦åä¸­çè¾¯è«æ ¸å¿ãé«å·è¡æè½ç AI/ML æ¨¡åï¼ä¾å¦æ´é«å­¸ç¿å¨åæ·±åº¦ç¥ç¶ç¶²è·¯ï¼éå¸¸ç¼ºä¹å¯è§£éæ§ï¼é»ç¤è¨åºé«çå°å¶é æ¸¬çä¿¡ä»»ãçºäºè§£æ±ºéååé¡ï¼æ­£å¨éç¼ XAI æè¡ï¼ä»¥äººé¡å¯ä»¥çè§£çè¡èªæè¿° AI/ML é æ¸¬ãä¸åæå¸æçæ¹åæ¯æ¡ç¨ææåº¦åæ (SA) åå¨çææåº¦åæ (GSA)ï¼å®åæ¬è³ªä¸æä¾ææ¨¡åè¼¸å¥å°é æ¸¬çå½±é¿ä¾å°å¶é²è¡æåãå¨æ­¤ï¼æåä»ç´¹ä¸ç¨®æ°ç delta-XAI æ¹æ³ï¼ééæ´å GSA ææ¨ delta ææ¸ä¾æä¾ ML æ¨¡åé æ¸¬çå±é¨è§£éãdelta-XAI ææ¸è©ä¼°æ¯åç¹å¾µå¼å°åæ­¸ååé¡åé¡ä¸­åå¥ä¾é çé æ¸¬è¼¸åºä¹å½±é¿ãæåå° delta-XAI ææ¸å½¢å¼åï¼ä¸¦æä¾å¶å¯¦ä½çç¨å¼ç¢¼ãä½¿ç¨ç·æ§åæ­¸æ¨¡åå°æ¨¡æ¬æå¢è©ä¼° delta-XAI æ¹æ³ï¼ä¸¦ä»¥ Shapley å¼ä½çºåºæºãçµæé¡¯ç¤º delta-XAI ææ¸éå¸¸è Shapley å¼ä¸è´ï¼ä½å¨å·æé«åº¦å½±é¿åææ¥µç«¯ç¹å¾µå¼çæ¨¡åä¸­å­å¨é¡¯èå·®ç°ãdelta-XAI ææ¸å¨åµæ¸¬ä¸»è¦ç¹å¾µåèçæ¥µç«¯ç¹å¾µå¼æ¹é¢è¡¨ç¾åºæ´é«çææåº¦ãå®æ§å°ä¾èªªï¼delta-XAI ééå©ç¨æ©çå¯åº¦å½æ¸æä¾ç´è§çè§£éï¼ä½¿ç¹å¾µæåæ´æ¸æ°ä¸å°å¾æ¥­äººå¡ä¾èªªæ´å·å¯è§£éæ§ãç¸½é«èè¨ï¼delta-XAI æ¹æ³å°æ¼ç©©å¥å°åå¾ ML æ¨¡åé æ¸¬çå±é¨è§£éä¼¼ä¹å¾æå¸æãå°å¨çå¯¦ä¸ççè¨åºç°å¢ä¸­é²è¡é²ä¸æ­¥èª¿æ¥ï¼ä»¥è©ä¼°å¶å° AI è¼å©è¨åºå·¥ä½æµç¨çå½±é¿ã

##### **Enhanced Deep Learning Methodologies and MRI Selection Techniques for Dementia Diagnosis in the Elderly Population**
2407.17324v2 by Nikolaos Ntampakis, Konstantinos Diamantaras, Ioanna Chouvarda, Vasileios Argyriou, Panagiotis Sarigianndis

Dementia, a debilitating neurological condition affecting millions worldwide,
presents significant diagnostic challenges. In this work, we introduce a novel
methodology for the classification of demented and non-demented elderly
patients using 3D brain Magnetic Resonance Imaging (MRI) scans. Our approach
features a unique technique for selectively processing MRI slices, focusing on
the most relevant brain regions and excluding less informative sections. This
methodology is complemented by a confidence-based classification committee
composed of three custom deep learning models: Dem3D ResNet, Dem3D CNN, and
Dem3D EfficientNet. These models work synergistically to enhance
decision-making accuracy, leveraging their collective strengths. Tested on the
Open Access Series of Imaging Studies(OASIS) dataset, our method achieved an
impressive accuracy of 94.12%, surpassing existing methodologies. Furthermore,
validation on the Alzheimer's Disease Neuroimaging Initiative (ADNI) dataset
confirmed the robustness and generalizability of our approach. The use of
explainable AI (XAI) techniques and comprehensive ablation studies further
substantiate the effectiveness of our techniques, providing insights into the
decision-making process and the importance of our methodology. This research
offers a significant advancement in dementia diagnosis, providing a highly
accurate and efficient tool for clinical applications.

æè¦ï¼å¤±æºçæ¯ä¸ç¨®å½±é¿å¨çæ¸ç¾è¬äººçè¡°å¼±æ§ç¥ç¶ç¾çï¼å¨è¨ºæ·ä¸å·æéå¤§ææ°ãå¨éé å·¥ä½ä¸­ï¼æåæåºäºä¸ç¨®æ°çæ¹æ³ï¼ç¨æ¼å°å¤±æºåéå¤±æºèå¹´æ£èé²è¡åé¡ï¼ä½¿ç¨ 3D å¤§è¦ç£æ¯é å½± (MRI) ææãæåçåæ³æ¡ç¨äºä¸ç¨®ç¨ç¹æè¡ï¼ç¨æ¼é¸ææ§èç MRI åçï¼éé»éæ³¨æç¸éçå¤§è¦ååï¼ä¸¦æé¤ä¿¡æ¯éè¼å°çé¨åãéç¨®æ¹æ³ç±ä¸ååºæ¼ä¿¡å¿çåé¡å§å¡æè£åï¼è©²å§å¡æç±ä¸åèªå®ç¾©æ·±åº¦å­¸ç¿æ¨¡åçµæï¼Dem3D ResNetãDem3D CNN å Dem3D EfficientNetãéäºæ¨¡åååå·¥ä½ä»¥å¢å¼·æ±ºç­çæºç¢ºæ§ï¼å©ç¨å®åçéé«åªå¢ãå¨å½±åç ç©¶éæ¾å­åç³»å (OASIS) è³æéä¸é²è¡æ¸¬è©¦ï¼æåçæ¨¡åéå°äº 94.12% çé©äººæºç¢ºåº¦ï¼è¶éäºç¾ææ¹æ³ãæ­¤å¤ï¼å¨é¿è²æµ·é»çç¥ç¶å½±åå¡è­° (ADNI) è³æéä¸çé©è­è­å¯¦äºæåæ¹æ³çç©©å¥æ§åæ®éæ§ãå¯è§£é AI (XAI) æè¡åå¨é¢çæ¶èç ç©¶é²ä¸æ­¥è­å¯¦äºæåæè¡çæææ§ï¼æä¾äºå°æ±ºç­éç¨åæåæ¹æ³éè¦æ§çè¦è§£ãéé ç ç©¶çºå¤±æºçè¨ºæ·æä¾äºéå¤§é²å±ï¼çºè¨åºæç¨æä¾äºä¸åé«åº¦æºç¢ºä¸é«æçå·¥å·ã

##### **Using Large Language Models to Compare Explainable Models for Smart Home Human Activity Recognition**
2408.06352v1 by Michele Fiori, Gabriele Civitarese, Claudio Bettini

Recognizing daily activities with unobtrusive sensors in smart environments
enables various healthcare applications. Monitoring how subjects perform
activities at home and their changes over time can reveal early symptoms of
health issues, such as cognitive decline. Most approaches in this field use
deep learning models, which are often seen as black boxes mapping sensor data
to activities. However, non-expert users like clinicians need to trust and
understand these models' outputs. Thus, eXplainable AI (XAI) methods for Human
Activity Recognition have emerged to provide intuitive natural language
explanations from these models. Different XAI methods generate different
explanations, and their effectiveness is typically evaluated through user
surveys, that are often challenging in terms of costs and fairness. This paper
proposes an automatic evaluation method using Large Language Models (LLMs) to
identify, in a pool of candidates, the best XAI approach for non-expert users.
Our preliminary results suggest that LLM evaluation aligns with user surveys.

æè¦ï¼èç±æºæ§ç°å¢ä¸­ä¸å¼äººæ³¨ç®çææ¸¬å¨è¾¨è­æ¥å¸¸æ´»åï¼è½åç¨åç¨®é«çä¿å¥æç¨ãç£æ§åè©¦èå¨å®¶ä¸­å¦ä½å·è¡æ´»åï¼ä»¥åå¶é¨èæéçè®åï¼å¯ä»¥æ­ç¤ºå¥åº·åé¡çæ©æççï¼ä¾å¦èªç¥è½åä¸éãæ­¤é åä¸­çå¤§å¤æ¸æ¹æ³é½ä½¿ç¨æ·±åº¦å­¸ç¿æ¨¡åï¼éäºæ¨¡åéå¸¸è¢«è¦çºå°ææ¸¬å¨è³æå°æè³æ´»åçé»çå­ãç¶èï¼éå°å®¶ä½¿ç¨èï¼ä¾å¦è¨åºé«å¸«ï¼éè¦ä¿¡ä»»ä¸¦äºè§£éäºæ¨¡åçè¼¸åºãå æ­¤ï¼äººé¡æ´»åè¾¨è­çå¯è§£é AI (XAI) æ¹æ³æéèçï¼ä»¥æä¾ä¾èªéäºæ¨¡åçç´è¦ºèªç¶èªè¨èªªæãä¸åç XAI æ¹æ³æç¢çä¸åçèªªæï¼èå¶æææ§éå¸¸ééä½¿ç¨èèª¿æ¥ä¾è©ä¼°ï¼éå¨ææ¬åå¬å¹³æ§æ¹é¢éå¸¸å·æææ°æ§ãæ¬ææåºä½¿ç¨å¤§åèªè¨æ¨¡å (LLM) çèªåè©ä¼°æ¹æ³ï¼ä»¥å¨åé¸èä¸­æ¾åºæé©åéå°å®¶ä½¿ç¨èç XAI æ¹æ³ãæåçåæ­¥çµæè¡¨æï¼LLM è©ä¼°èä½¿ç¨èèª¿æ¥ä¸è´ã

##### **Explainable AI-based Intrusion Detection System for Industry 5.0: An Overview of the Literature, associated Challenges, the existing Solutions, and Potential Research Directions**
2408.03335v1 by Naseem Khan, Kashif Ahmad, Aref Al Tamimi, Mohammed M. Alani, Amine Bermak, Issa Khalil

Industry 5.0, which focuses on human and Artificial Intelligence (AI)
collaboration for performing different tasks in manufacturing, involves a
higher number of robots, Internet of Things (IoTs) devices and
interconnections, Augmented/Virtual Reality (AR), and other smart devices. The
huge involvement of these devices and interconnection in various critical
areas, such as economy, health, education and defense systems, poses several
types of potential security flaws. AI itself has been proven a very effective
and powerful tool in different areas of cybersecurity, such as intrusion
detection, malware detection, and phishing detection, among others. Just as in
many application areas, cybersecurity professionals were reluctant to accept
black-box ML solutions for cybersecurity applications. This reluctance pushed
forward the adoption of eXplainable Artificial Intelligence (XAI) as a tool
that helps explain how decisions are made in ML-based systems. In this survey,
we present a comprehensive study of different XAI-based intrusion detection
systems for industry 5.0, and we also examine the impact of explainability and
interpretability on Cybersecurity practices through the lens of Adversarial
XIDS (Adv-XIDS) approaches. Furthermore, we analyze the possible opportunities
and challenges in XAI cybersecurity systems for industry 5.0 that elicit future
research toward XAI-based solutions to be adopted by high-stakes industry 5.0
applications. We believe this rigorous analysis will establish a foundational
framework for subsequent research endeavors within the specified domain.

æè¦ï¼å·¥æ¥­ 5.0 èéæ¼äººé¡èäººå·¥æºæ§ (AI) åä½å·è¡è£½é ä¸­çä¸åä»»åï¼æ¶åæ´å¤æ©å¨äººãç©è¯ç¶² (IoT) è£ç½®åäºé£ãæ´å¢/èæ¬å¯¦å¢ (AR) åå¶ä»æºæ§è£ç½®ãéäºè£ç½®åäºé£å¨ç¶æ¿ãé«çä¿å¥ãæè²ååé²ç³»çµ±ç­åç¨®ééµé åçå»£æ³åèï¼å¼ç¼äºå¤ç¨®é¡åçæ½å¨å®å¨æ¼æ´ãAI æ¬èº«å·²è¢«è­ææ¯ç¶²è·¯å®å¨ä¸åé åä¸­éå¸¸ææä¸å¼·å¤§çå·¥å·ï¼ä¾å¦å¥ä¾µåµæ¸¬ãæ¡æè»é«åµæ¸¬åç¶²è·¯é£é­åµæ¸¬ç­ãå°±åå¨è¨±å¤æç¨é åä¸æ¨£ï¼ç¶²è·¯å®å¨å°æ¥­äººå¡ä¸é¡ææ¥åé»ç ML è§£æ±ºæ¹æ¡ä¾æç¨æ¼ç¶²è·¯å®å¨ãéç¨®ä¸é¡æä¿ä½¿å¯è§£éäººå·¥æºæ§ (XAI) ä½çºä¸ç¨®å·¥å·è¢«æ¡ç¨ï¼æå©æ¼èªªæå¨åºæ¼ ML çç³»çµ±ä¸­å¦ä½ååºæ±ºç­ãå¨éé èª¿æ¥ä¸­ï¼æåå°å·¥æ¥­ 5.0 çä¸ååºæ¼ XAI çå¥ä¾µåµæ¸¬ç³»çµ±é²è¡äºå¨é¢çç ç©¶ï¼ä¸¦ä¸æåä¹ééå°æå¼ XIDS (Adv-XIDS) æ¹æ³çè§é»ä¾æ¢è¨å¯è§£éæ§åå¯è©®éæ§å°ç¶²è·¯å®å¨å¯¦åçå½±é¿ãæ­¤å¤ï¼æååæäºå·¥æ¥­ 5.0 ç XAI ç¶²è·¯å®å¨ç³»çµ±ä¸­å¯è½å­å¨çæ©æåææ°ï¼å¼ç¼äºæªä¾éå° XAI åºç¤è§£æ±ºæ¹æ¡çç ç©¶ï¼ä»¥ä¾é«é¢¨éªçå·¥æ¥­ 5.0 æç¨æ¡ç¨ãæåç¸ä¿¡éé å´è¬¹çåæå°çºæå®é åå§çå¾çºç ç©¶å·¥ä½å»ºç«åºç¤æ¶æ§ã

##### **A Comparative Study on Automatic Coding of Medical Letters with Explainability**
2407.13638v1 by Jamie Glen, Lifeng Han, Paul Rayson, Goran Nenadic

This study aims to explore the implementation of Natural Language Processing
(NLP) and machine learning (ML) techniques to automate the coding of medical
letters with visualised explainability and light-weighted local computer
settings. Currently in clinical settings, coding is a manual process that
involves assigning codes to each condition, procedure, and medication in a
patient's paperwork (e.g., 56265001 heart disease using SNOMED CT code). There
are preliminary research on automatic coding in this field using
state-of-the-art ML models; however, due to the complexity and size of the
models, the real-world deployment is not achieved. To further facilitate the
possibility of automatic coding practice, we explore some solutions in a local
computer setting; in addition, we explore the function of explainability for
transparency of AI models. We used the publicly available MIMIC-III database
and the HAN/HLAN network models for ICD code prediction purposes. We also
experimented with the mapping between ICD and SNOMED CT knowledge bases. In our
experiments, the models provided useful information for 97.98\% of codes. The
result of this investigation can shed some light on implementing automatic
clinical coding in practice, such as in hospital settings, on the local
computers used by clinicians , project page
\url{https://github.com/Glenj01/Medical-Coding}.

æè¦ï¼æ¬ç ç©¶æ¨å¨æ¢è¨å°èªç¶èªè¨èç (NLP) åæ©å¨å­¸ç¿ (ML) æè¡å¯¦ä½æ¼é«çä¿¡å½ç·¨ç¢¼èªååï¼ä¸¦å·åè¦è¦ºåèªªæè½ååè¼éåçæ¬å°é»è¦è¨­å®ãç®åå¨è¨åºç°å¢ä¸­ï¼ç·¨ç¢¼æ¯ä¸ç¨®æåæµç¨ï¼æ¶åçºçæ£æä»¶ä¸­çæ¯é ççãç¨åºåè¥ç©ææ´¾ä»£ç¢¼ (ä¾å¦ï¼ä½¿ç¨ SNOMED CT ä»£ç¢¼ 56265001 è¡¨ç¤ºå¿èç)ãæ­¤é åæä½¿ç¨ææ° ML æ¨¡åé²è¡èªåç·¨ç¢¼çåæ­¥ç ç©¶ï¼ç¶èï¼ç±æ¼æ¨¡åçè¤éæ§åå¤§å°ï¼ä¸¦æªå¯¦ç¾å¯¦éé¨ç½²ãçºäºé²ä¸æ­¥ä¿é²èªåç·¨ç¢¼å¯¦åçå¯è½æ§ï¼æåå¨æ¬å°é»è¦è¨­å®ä¸­æ¢è¨äºä¸äºè§£æ±ºæ¹æ¡ï¼æ­¤å¤ï¼æåæ¢è¨äºèªªæåè½å¨ AI æ¨¡åéæåº¦ä¸­çåè½ãæåä½¿ç¨å¬éç MIMIC-III è³æåº«å HAN/HLAN ç¶²è·¯æ¨¡åé²è¡ ICD ä»£ç¢¼é æ¸¬ãæåéè©¦é©äº ICD å SNOMED CT ç¥è­åº«ä¹éçå°æãå¨æåçå¯¦é©ä¸­ï¼éäºæ¨¡åæä¾äº 97.98% ä»£ç¢¼çæç¨è³è¨ãéé èª¿æ¥çµæå¯ä»¥çºå¯¦åä¸­çèªåè¨åºç·¨ç¢¼å¯¦ä½æä¾ä¸äºè¦è§£ï¼ä¾å¦å¨é«é¢ç°å¢ä¸­ï¼ç±è¨åºé«çä½¿ç¨çæ¬å°é»è¦ï¼å°æ¡é é¢ \url{https://github.com/Glenj01/Medical-Coding}ã

##### **Explainable AI for Enhancing Efficiency of DL-based Channel Estimation**
2407.07009v1 by Abdul Karim Gizzini, Yahia Medjahdi, Ali J. Ghandour, Laurent Clavier

The support of artificial intelligence (AI) based decision-making is a key
element in future 6G networks, where the concept of native AI will be
introduced. Moreover, AI is widely employed in different critical applications
such as autonomous driving and medical diagnosis. In such applications, using
AI as black-box models is risky and challenging. Hence, it is crucial to
understand and trust the decisions taken by these models. Tackling this issue
can be achieved by developing explainable AI (XAI) schemes that aim to explain
the logic behind the black-box model behavior, and thus, ensure its efficient
and safe deployment. Recently, we proposed a novel perturbation-based XAI-CHEST
framework that is oriented toward channel estimation in wireless
communications. The core idea of the XAI-CHEST framework is to identify the
relevant model inputs by inducing high noise on the irrelevant ones. This
manuscript provides the detailed theoretical foundations of the XAI-CHEST
framework. In particular, we derive the analytical expressions of the XAI-CHEST
loss functions and the noise threshold fine-tuning optimization problem. Hence
the designed XAI-CHEST delivers a smart input feature selection methodology
that can further improve the overall performance while optimizing the
architecture of the employed model. Simulation results show that the XAI-CHEST
framework provides valid interpretations, where it offers an improved bit error
rate performance while reducing the required computational complexity in
comparison to the classical DL-based channel estimation.

æè¦ï¼äººå·¥æºè½ (AI) æ¯æçæ±ºç­å¶å®æ¯æªä¾ 6G ç¶²è·¯ä¸­çééµåç´ ï¼å¶ä¸­å°å¼å¥åç AI çæ¦å¿µãæ­¤å¤ï¼AI å»£æ³ç¨æ¼ä¸åçééµæç¨ä¸­ï¼ä¾å¦èªåé§é§åé«çè¨ºæ·ãå¨éäºæç¨ä¸­ï¼ä½¿ç¨ AI ä½çºé»çæ¨¡åæ¯æé¢¨éªä¸å·æææ°æ§çãå æ­¤ï¼çè§£åä¿¡ä»»éäºæ¨¡åååºçæ±ºç­è³ééè¦ãè§£æ±ºæ­¤åé¡çæ¹æ³æ¯éç¼å¯è§£é AI (XAI) æ¶æ§ï¼æ¨å¨è§£éé»çæ¨¡åè¡çºèå¾çéè¼¯ï¼å¾èç¢ºä¿å¶ææä¸å®å¨çé¨ç½²ãæè¿ï¼æåæåºäºä¸åæ°çåºæ¼æ¾åç XAI-CHEST æ¡æ¶ï¼è©²æ¡æ¶é¢åç¡ç·éä¿¡ä¸­çä¿¡éä¼°è¨ãXAI-CHEST æ¡æ¶çæ ¸å¿ææ³æ¯ééå¨ç¡éè¼¸å¥ä¸å¼å¥é«åªè²ä¾è­å¥ç¸éæ¨¡åè¼¸å¥ãéä»½æç¨¿æä¾äº XAI-CHEST æ¡æ¶çè©³ç´°çè«åºç¤ãç¹å¥æ¯ï¼æåæ¨å°äº XAI-CHEST æå¤±å½æ¸ååªè²é¾å¼å¾®èª¿åªååé¡çè§£æè¡¨éå¼ãå æ­¤ï¼è¨­è¨ç XAI-CHEST æä¾äºä¸ç¨®æºè½è¼¸å¥ç¹å¾µé¸ææ¹æ³ï¼å¯ä»¥å¨åªåæç¨æ¨¡åçæ¶æ§çåæé²ä¸æ­¥æé«æ´é«æ§è½ãæ¨¡æ¬çµæè¡¨æï¼XAI-CHEST æ¡æ¶æä¾äºææçè§£éï¼å¨éä½æéçè¨ç®è¤éåº¦çåæï¼æä¾äºæ¹é²çæ¯ç¹é¯èª¤çæ§è½ï¼èéèåºæ¼å³çµ± DL çä¿¡éä¼°è¨ç¸æ¯ã

##### **Explainable AI: Comparative Analysis of Normal and Dilated ResNet Models for Fundus Disease Classification**
2407.05440v2 by P. N. Karthikayan, Yoga Sri Varshan V, Hitesh Gupta Kattamuri, Umarani Jayaraman

This paper presents dilated Residual Network (ResNet) models for disease
classification from retinal fundus images. Dilated convolution filters are used
to replace normal convolution filters in the higher layers of the ResNet model
(dilated ResNet) in order to improve the receptive field compared to the normal
ResNet model for disease classification. This study introduces
computer-assisted diagnostic tools that employ deep learning, enhanced with
explainable AI techniques. These techniques aim to make the tool's
decision-making process transparent, thereby enabling medical professionals to
understand and trust the AI's diagnostic decision. They are particularly
relevant in today's healthcare landscape, where there is a growing demand for
transparency in AI applications to ensure their reliability and ethical use.
The dilated ResNet is used as a replacement for the normal ResNet to enhance
the classification accuracy of retinal eye diseases and reduce the required
computing time. The dataset used in this work is the Ocular Disease Intelligent
Recognition (ODIR) dataset which is a structured ophthalmic database with eight
classes covering most of the common retinal eye diseases. The evaluation
metrics used in this work include precision, recall, accuracy, and F1 score. In
this work, a comparative study has been made between normal ResNet models and
dilated ResNet models on five variants namely ResNet-18, ResNet-34, ResNet-50,
ResNet-101, and ResNet-152. The dilated ResNet model shows promising results as
compared to normal ResNet with an average F1 score of 0.71, 0.70, 0.69, 0.67,
and 0.70 respectively for the above respective variants in ODIR multiclass
disease classification.

æè¦ï¼è¿ç¯è®ºææåºäºç¨äºä»è§ç½èç¼åºå¾åè¿è¡ç¾çåç±»çæ©å¼ æ®å·®ç½ç» (ResNet) æ¨¡åãæ©å¼ å·ç§¯æ»¤æ³¢å¨ç¨äºæ¿æ¢ ResNet æ¨¡åè¾é«å±ä¸­çæ­£å¸¸å·ç§¯æ»¤æ³¢å¨ï¼æ©å¼  ResNetï¼ï¼ä»¥æ¹åæç¥åºï¼ä»èéå¯¹ç¾çåç±»å¯¹æ­£å¸¸ ResNet æ¨¡åè¿è¡æ¹è¿ãæ¬ç ç©¶å¼å¥äºéç¨æ·±åº¦å­¦ä¹ çè®¡ç®æºè¾å©è¯æ­å·¥å·ï¼å¹¶éè¿å¯è§£éç AI ææ¯è¿è¡äºå¢å¼ºãè¿äºææ¯æ¨å¨ä½¿è¯¥å·¥å·çå³ç­è¿ç¨éæåï¼ä»èä½¿å»å­¦ä¸ä¸äººå£«è½å¤çè§£åä¿¡ä»» AI çè¯æ­å³ç­ãå®ä»¬ä¸å½ä»çå»çä¿å¥é¢åå°¤ä¸ºç¸å³ï¼å¨è¯¥é¢åï¼å¯¹ AI åºç¨çéæåº¦éæ±ä¸æ­å¢é¿ï¼ä»¥ç¡®ä¿å¶å¯é æ§ååä¹éå¾·çä½¿ç¨ãæ©å¼  ResNet ç¨ä½æ­£å¸¸ ResNet çæ¿ä»£åï¼ä»¥æé«è§ç½èç¼é¨ç¾ççåç±»åç¡®æ§å¹¶åå°æéçè®¡ç®æ¶é´ãæ¬å·¥ä½ä¸­ä½¿ç¨çæ°æ®éæ¯ç¼ç§ç¾çæºè½è¯å« (ODIR) æ°æ®éï¼è¿æ¯ä¸ä¸ªç»æåçç¼ç§æ°æ®åºï¼åå«å«ç±»æ¶µçå¤§å¤æ°å¸¸è§è§ç½èç¼é¨ç¾çãæ¬å·¥ä½ä¸­ä½¿ç¨çè¯ä¼°ææ åæ¬ç²¾ç¡®åº¦ãå¬åçãåç¡®åº¦å F1 å¾åãå¨è¿é¡¹å·¥ä½ä¸­ï¼å¯¹ ResNet-18ãResNet-34ãResNet-50ãResNet-101 å ResNet-152 äºä¸ªåä½çæ­£å¸¸ ResNet æ¨¡ååæ©å¼  ResNet æ¨¡åè¿è¡äºæ¯è¾ç ç©¶ãä¸æ­£å¸¸ ResNet ç¸æ¯ï¼æ©å¼  ResNet æ¨¡åæ¾ç¤ºåºæå¸æçç»æï¼å¨ ODIR å¤ç±»ç¾çåç±»ä¸­ï¼ä¸è¿°åä¸ªåä½çå¹³å F1 å¾åä¸º 0.71ã0.70ã0.69ã0.67 å 0.70ã

##### **A Survey on Trustworthiness in Foundation Models for Medical Image Analysis**
2407.15851v2 by Congzhen Shi, Ryan Rezai, Jiaxi Yang, Qi Dou, Xiaoxiao Li

The rapid advancement of foundation models in medical imaging represents a
significant leap toward enhancing diagnostic accuracy and personalized
treatment. However, the deployment of foundation models in healthcare
necessitates a rigorous examination of their trustworthiness, encompassing
privacy, robustness, reliability, explainability, and fairness. The current
body of survey literature on foundation models in medical imaging reveals
considerable gaps, particularly in the area of trustworthiness. Additionally,
existing surveys on the trustworthiness of foundation models do not adequately
address their specific variations and applications within the medical imaging
domain. This survey aims to fill that gap by presenting a novel taxonomy of
foundation models used in medical imaging and analyzing the key motivations for
ensuring their trustworthiness. We review current research on foundation models
in major medical imaging applications, focusing on segmentation, medical report
generation, medical question and answering (Q\&A), and disease diagnosis. These
areas are highlighted because they have seen a relatively mature and
substantial number of foundation models compared to other applications. We
focus on literature that discusses trustworthiness in medical image analysis
manuscripts. We explore the complex challenges of building trustworthy
foundation models for each application, summarizing current concerns and
strategies for enhancing trustworthiness. Furthermore, we examine the potential
of these models to revolutionize patient care. Our analysis underscores the
imperative for advancing towards trustworthy AI in medical image analysis,
advocating for a balanced approach that fosters innovation while ensuring
ethical and equitable healthcare delivery.

æè¦ï¼åºç¤æ¨¡åå¨é«å­¸å½±åæ¹é¢çå¿«éé²å±ï¼ä»£è¡¨èå¨å å¼·è¨ºæ·æºç¢ºæ§ååäººåæ²»çæ¹é¢éåºä¸å¤§æ­¥ãç¶èï¼åºç¤æ¨¡åå¨é«çä¿å¥ä¸­çé¨ç½²éè¦å°å¶å¯ä¿¡åº¦é²è¡å´æ ¼çå¯©æ¥ï¼åæ¬é±ç§ãç©©å¥æ§ãå¯é æ§ãå¯è§£éæ§åå¬å¹³æ§ãç®åéæ¼é«å­¸å½±åä¸­åºç¤æ¨¡åçèª¿æ¥æç»ä¸­é¡¯ç¤ºåºç¸ç¶å¤§çå·®è·ï¼ç¹å¥æ¯å¨å¯ä¿¡åº¦æ¹é¢ãæ­¤å¤ï¼ç¾æéæ¼åºç¤æ¨¡åå¯ä¿¡åº¦çèª¿æ¥ä¸¦æªååè§£æ±ºå¶å¨é«å­¸å½±åé åä¸­çç¹å®è®ååæç¨ãæ¬èª¿æ¥æ¨å¨ééæåºé«å­¸å½±åä¸­ä½¿ç¨çåºç¤æ¨¡åçæ°åé¡æ³ä¸¦åæç¢ºä¿å¶å¯ä¿¡åº¦çééµåæ©ï¼ä¾å¡«è£éä¸ç©ºç½ãæååé¡§äºåºç¤æ¨¡åå¨ä¸»è¦é«å­¸å½±åæç¨ä¸­çç¶åç ç©¶ï¼éé»éæ³¨åå²ãé«çå ±åçæãé«çåé¡ååç­ (Q&A) ä»¥åç¾çè¨ºæ·ãéäºé åä¹æä»¥è¢«å¼·èª¿ï¼æ¯å çºèå¶ä»æç¨ç¸æ¯ï¼å®åå·²ç¶çå°ç¸å°æçä¸å¤§éçåºç¤æ¨¡åãæåå°æ³¨æ¼æ¢è¨é«å­¸å½±ååææç¨¿ä¸­å¯ä¿¡åº¦çæç»ãæåæ¢è¨äºçºæ¯åæç¨æ§å»ºå¯ä¿¡åºç¤æ¨¡åçè¤éææ°ï¼ç¸½çµäºç¶åéæ³¨é»åå¢å¼·å¯ä¿¡åº¦çç­ç¥ãæ­¤å¤ï¼æåæ¢è¨äºéäºæ¨¡åå¨é©æ°æ£èè­·çæ¹é¢çæ½åãæåçåæå¼·èª¿äºå¨é«å­¸å½±ååæä¸­æèå¯ä¿¡è³´çäººå·¥æºæ§éé²çå¿è¦æ§ï¼ä¸¦å¡å°ä¸ç¨®å¹³è¡¡çæ¹æ³ï¼æ¢è½ä¿é²åµæ°ï¼åè½ç¢ºä¿éå¾·åå¬å¹³çé«çä¿å¥æåã

##### **The Impact of an XAI-Augmented Approach on Binary Classification with Scarce Data**
2407.06206v1 by Ximing Wen, Rosina O. Weber, Anik Sen, Darryl Hannan, Steven C. Nesbit, Vincent Chan, Alberto Goffi, Michael Morris, John C. Hunninghake, Nicholas E. Villalobos, Edward Kim, Christopher J. MacLellan

Point-of-Care Ultrasound (POCUS) is the practice of clinicians conducting and
interpreting ultrasound scans right at the patient's bedside. However, the
expertise needed to interpret these images is considerable and may not always
be present in emergency situations. This reality makes algorithms such as
machine learning classifiers extremely valuable to augment human decisions.
POCUS devices are becoming available at a reasonable cost in the size of a
mobile phone. The challenge of turning POCUS devices into life-saving tools is
that interpretation of ultrasound images requires specialist training and
experience. Unfortunately, the difficulty to obtain positive training images
represents an important obstacle to building efficient and accurate
classifiers. Hence, the problem we try to investigate is how to explore
strategies to increase accuracy of classifiers trained with scarce data. We
hypothesize that training with a few data instances may not suffice for
classifiers to generalize causing them to overfit. Our approach uses an
Explainable AI-Augmented approach to help the algorithm learn more from less
and potentially help the classifier better generalize.

æè¦ï¼åºéè¶é³æ³¢ (POCUS) æ¯è¨åºé«å¸«å¨æ£èåºéé²è¡åè§£è®è¶é³æ³¢ææçå¯¦åãç¶èï¼è§£è®éäºå½±åæéçå°æ¥­ç¥è­ç¸ç¶å¯è§ï¼èä¸å¨ç·æ¥ææ³ä¸å¯è½ä¸¦éé¨æå·åãéç¨®ç¾å¯¦ææ³ä½¿å¾æ©å¨å­¸ç¿åé¡å¨ç­æ¼ç®æ³å°æ¼å å¼·äººé¡æ±ºç­è®å¾æ¥µçºæå¹å¼ãPOCUS è£ç½®æ­£ä»¥åçææ¬æ¨åºï¼å°ºå¯¸çºææ©å¤§å°ãå° POCUS è£ç½®è½è®çºæçå·¥å·çææ°å¨æ¼ï¼è§£è®è¶é³æ³¢å½±åéè¦å°éè¨ç·´åç¶é©ãä¸å¹¸çæ¯ï¼åå¾æ­£åè¨ç·´å½±åçå°é£åº¦ä»£è¡¨èå»ºç½®ææçä¸æºç¢ºçåé¡å¨çä¸å¤§éç¤ãå æ­¤ï¼æååè©¦æ¢è¨çåé¡æ¯å¦ä½æ¢ç´¢ç­ç¥ï¼ä»¥æé«ä½¿ç¨ç¨çè³æè¨ç·´çåé¡å¨çæºç¢ºåº¦ãæååè¨­ä½¿ç¨å°æ¸è³æå¯¦ä¾é²è¡è¨ç·´å¯è½ä¸è¶³ä»¥è®åé¡å¨æ¦æ¬ï¼å°è´å®åéåº¦æ¬åãæåçåæ³ä½¿ç¨å¯è§£é AI å¢å¼·æ¹æ³ï¼ä»¥åå©æ¼ç®æ³å¾è¼å°çè³æä¸­å­¸ç¿æ´å¤ï¼ä¸¦æ½å¨åå©åé¡å¨æ´å¥½å°æ¦æ¬ã

##### **Can GPT-4 Help Detect Quit Vaping Intentions? An Exploration of Automatic Data Annotation Approach**
2407.00167v1 by Sai Krishna Revanth Vuruma, Dezhi Wu, Saborny Sen Gupta, Lucas Aust, Valerie Lookingbill, Wyatt Bellamy, Yang Ren, Erin Kasson, Li-Shiun Chen, Patricia Cavazos-Rehg, Dian Hu, Ming Huang

In recent years, the United States has witnessed a significant surge in the
popularity of vaping or e-cigarette use, leading to a notable rise in cases of
e-cigarette and vaping use-associated lung injury (EVALI) that caused
hospitalizations and fatalities during the EVALI outbreak in 2019, highlighting
the urgency to comprehend vaping behaviors and develop effective strategies for
cessation. Due to the ubiquity of social media platforms, over 4.7 billion
users worldwide use them for connectivity, communications, news, and
entertainment with a significant portion of the discourse related to health,
thereby establishing social media data as an invaluable organic data resource
for public health research. In this study, we extracted a sample dataset from
one vaping sub-community on Reddit to analyze users' quit-vaping intentions.
Leveraging OpenAI's latest large language model GPT-4 for sentence-level quit
vaping intention detection, this study compares the outcomes of this model
against layman and clinical expert annotations. Using different prompting
strategies such as zero-shot, one-shot, few-shot and chain-of-thought
prompting, we developed 8 prompts with varying levels of detail to explain the
task to GPT-4 and also evaluated the performance of the strategies against each
other. These preliminary findings emphasize the potential of GPT-4 in social
media data analysis, especially in identifying users' subtle intentions that
may elude human detection.

æè¦ï¼è¿å¹´ä¾ï¼ç¾åè¦è­äºé»å­çæé»å­é¦è¸ä½¿ç¨çå¤§å¹æ¿å¢ï¼å°è´é»å­çåé»å­çä½¿ç¨ç¸éèºæå· (EVALI) çä¾é¡¯èå¢å ï¼å¨ 2019 å¹´ EVALI çç¼æéé æä½é¢åæ­»äº¡ï¼å¸é¡¯äºçè§£é»å­çè¡çºåå¶å®æææè¸ç­ç¥çè¿«åæ§ãç±æ¼ç¤¾ç¾¤åªé«å¹³å°çæ®åï¼å¨çè¶é 47 åä½¿ç¨èä½¿ç¨å®åé²è¡é£çµãæºéãæ°èåå¨æ¨ï¼å¶ä¸­å¾å¤§ä¸é¨åèå¥åº·ç¸éï¼å æ­¤å°ç¤¾ç¾¤åªé«è³æå»ºç«çºå¬å±è¡çç ç©¶ä¸­ç¡å¹çææ©è³æè³æºãå¨æ¬ç ç©¶ä¸­ï¼æåå¾ Reddit ä¸ä¸åé»å­çå­ç¤¾ç¾¤ä¸­æåä¸åç¯ä¾è³æéï¼ä»¥åæä½¿ç¨èçæé»å­çæåãå©ç¨ OpenAI ææ°çå¤§åèªè¨æ¨¡å GPT-4 é²è¡å¥å­å±¤ç´çæé»å­çæååµæ¸¬ï¼æ¬ç ç©¶æ¯è¼äºæ­¤æ¨¡åççµæèå¤è¡äººåè¨åºå°å®¶è¨»è§£ãä½¿ç¨ä¸åçæç¤ºç­ç¥ï¼ä¾å¦é¶æ¬¡å­¸ç¿ãä¸æ¬¡å­¸ç¿ãå°æ¬¡å­¸ç¿åæèéæç¤ºï¼æåéç¼äº 8 åæç¤ºï¼è©³ç´°ç¨åº¦ä¸åï¼å GPT-4 è§£éä»»åï¼ä¸¦è©ä¼°éäºç­ç¥å½¼æ­¤ä¹éçæè½ãéäºåæ­¥ç¼ç¾å¼·èª¿äº GPT-4 å¨ç¤¾ç¾¤åªé«è³æåæä¸­çæ½åï¼ç¹å¥æ¯å¨è­å¥äººé¡åµæ¸¬å¯è½ç¡æ³å¯è¦ºçä½¿ç¨èå¾®å¦æåæ¹é¢ã

##### **Towards Compositional Interpretability for XAI**
2406.17583v1 by Sean Tull, Robin Lorenz, Stephen Clark, Ilyas Khan, Bob Coecke

Artificial intelligence (AI) is currently based largely on black-box machine
learning models which lack interpretability. The field of eXplainable AI (XAI)
strives to address this major concern, being critical in high-stakes areas such
as the finance, legal and health sectors.
  We present an approach to defining AI models and their interpretability based
on category theory. For this we employ the notion of a compositional model,
which sees a model in terms of formal string diagrams which capture its
abstract structure together with its concrete implementation. This
comprehensive view incorporates deterministic, probabilistic and quantum
models. We compare a wide range of AI models as compositional models, including
linear and rule-based models, (recurrent) neural networks, transformers, VAEs,
and causal and DisCoCirc models.
  Next we give a definition of interpretation of a model in terms of its
compositional structure, demonstrating how to analyse the interpretability of a
model, and using this to clarify common themes in XAI. We find that what makes
the standard 'intrinsically interpretable' models so transparent is brought out
most clearly diagrammatically. This leads us to the more general notion of
compositionally-interpretable (CI) models, which additionally include, for
instance, causal, conceptual space, and DisCoCirc models.
  We next demonstrate the explainability benefits of CI models. Firstly, their
compositional structure may allow the computation of other quantities of
interest, and may facilitate inference from the model to the modelled
phenomenon by matching its structure. Secondly, they allow for diagrammatic
explanations for their behaviour, based on influence constraints, diagram
surgery and rewrite explanations. Finally, we discuss many future directions
for the approach, raising the question of how to learn such meaningfully
structured models in practice.

æè¦ï¼<paragraph>äººå·¥æºæ§ï¼AIï¼ç®åå¨å¾å¤§ç¨åº¦ä¸ä¾è³´æ¼ç¼ºä¹å¯è§£éæ§çé»çæ©å¨å­¸ç¿æ¨¡åãå¯è§£éæ§äººå·¥æºæ§ï¼XAIï¼é åè´åæ¼è§£æ±ºéåä¸»è¦åé¡ï¼éå¨éèãæ³å¾åå¥åº·ç­é«é¢¨éªé åè³ééè¦ã
æåæåºäºä¸ç¨®åºæ¼ç¯çè«å®ç¾© AI æ¨¡ååå¶å¯è§£éæ§çæ¹æ³ãçºæ­¤ï¼æåæ¡ç¨çµåæ¨¡åçæ¦å¿µï¼å®ä»¥å½¢å¼å¼¦åçå½¢å¼çå¾æ¨¡åï¼éäºå¼¦åæç²äºæ¨¡åçæ½è±¡çµæ§åå¶å·é«å¯¦ç¾ãéç¨®ç¶åè§é»åå«äºç¢ºå®æ§ãæ¦çæ§åéå­æ¨¡åãæåå°åç¨® AI æ¨¡åä½çºçµåæ¨¡åé²è¡æ¯è¼ï¼åæ¬ç·æ§ååºæ¼è¦åçæ¨¡åãï¼éè¿´ï¼ç¥ç¶ç¶²è·¯ãTransformerãVAEï¼ä»¥åå æå DisCoCirc æ¨¡åã
æ¥ä¸ä¾ï¼æåæ ¹ææ¨¡åççµåçµæ§çµ¦åºæ¨¡åè§£éçå®ç¾©ï¼å±ç¤ºå¦ä½åææ¨¡åçå¯è§£éæ§ï¼ä¸¦ä½¿ç¨å®ä¾æ¾æ¸ XAI ä¸­çå¸¸è¦ä¸»é¡ãæåç¼ç¾ï¼è®æ¨æºçãå§å¨å¯è§£éãæ¨¡åå¦æ­¤éæçåå å¨åè¡¨ä¸­è¡¨ç¾å¾æçºæ¸æ¥ãéå¼å°æåå¾åºæ´ä¸è¬ççµåå¯è§£éï¼CIï¼æ¨¡åæ¦å¿µï¼å®å¦å¤éåæ¬å æãæ¦å¿µç©ºéå DisCoCirc æ¨¡åã
æ¥ä¸ä¾ï¼æåå±ç¤ºäº CI æ¨¡åçå¯è§£éæ§åªå¢ãé¦åï¼å®åççµåçµæ§åè¨±è¨ç®å¶ä»æèè¶£çéï¼ä¸¦å¯è½ééå¹éæ¨¡åççµæ§ä¾ä¿é²å¾æ¨¡åå°è¢«å»ºæ¨¡ç¾è±¡çæ¨çãå¶æ¬¡ï¼å®ååè¨±å°å¶è¡çºé²è¡åè§£èªªæï¼éäºèªªæåºæ¼å½±é¿ç´æãåè§£æè¡åéå¯«èªªæãæå¾ï¼æåè¨è«äºéç¨®æ¹æ³çè¨±å¤æªä¾æ¹åï¼æåºäºå¦ä½å¨å¯¦è¸ä¸­å­¸ç¿éç¨®ææç¾©ççµæ§åæ¨¡åçåé¡ã</paragraph>

##### **Slicing Through Bias: Explaining Performance Gaps in Medical Image Analysis using Slice Discovery Methods**
2406.12142v2 by Vincent Olesen, Nina Weng, Aasa Feragen, Eike Petersen

Machine learning models have achieved high overall accuracy in medical image
analysis. However, performance disparities on specific patient groups pose
challenges to their clinical utility, safety, and fairness. This can affect
known patient groups - such as those based on sex, age, or disease subtype - as
well as previously unknown and unlabeled groups. Furthermore, the root cause of
such observed performance disparities is often challenging to uncover,
hindering mitigation efforts. In this paper, to address these issues, we
leverage Slice Discovery Methods (SDMs) to identify interpretable
underperforming subsets of data and formulate hypotheses regarding the cause of
observed performance disparities. We introduce a novel SDM and apply it in a
case study on the classification of pneumothorax and atelectasis from chest
x-rays. Our study demonstrates the effectiveness of SDMs in hypothesis
formulation and yields an explanation of previously observed but unexplained
performance disparities between male and female patients in widely used chest
X-ray datasets and models. Our findings indicate shortcut learning in both
classification tasks, through the presence of chest drains and ECG wires,
respectively. Sex-based differences in the prevalence of these shortcut
features appear to cause the observed classification performance gap,
representing a previously underappreciated interaction between shortcut
learning and model fairness analyses.

æè¦ï¼æ©å¨å­¸ç¿æ¨¡åå¨é«å­¸å½±ååæä¸­å·²éå°æ´é«é«æºç¢ºåº¦ãç¶èï¼ç¹å®æ£èç¾¤é«çæè½å·®ç°å°å¶è¨åºæç¨ãå®å¨æ§èå¬å¹³æ§æ§æææ°ãéå¯è½æå½±é¿å·²ç¥çæ£èç¾¤é«ï¼ä¾å¦åºæ¼æ§å¥ãå¹´é½¡æç¾çäºåï¼ä»¥åååæªç¥ä¸æªæ¨ç±¤çç¾¤é«ãæ­¤å¤ï¼æ­¤é¡è§å¯å°çæè½å·®ç°çæ ¹æ¬åå éå¸¸é£ä»¥ç¼ç¾ï¼é»ç¤äºç·©è§£æªæ½ãå¨æ¬æä¸­ï¼çºäºè§£æ±ºéäºåé¡ï¼æåå©ç¨åçç¼ç¾æ¹æ³ (SDM) ä¾è­å¥å¯è§£éçè³ææè½ä¸ä½³å­éï¼ä¸¦éå°è§å¯å°çæè½å·®ç°åå å¶å®åè¨­ãæåå¼å¥ä¸ç¨®æ°ç SDMï¼ä¸¦å¨è¸é¨ X åçä¸­èºçåèºä¸å¼µåé¡çæ¡ä¾ç ç©¶ä¸­æç¨å®ãæåçç ç©¶è­æäº SDM å¨åè¨­å¶å®ä¸­çæææ§ï¼ä¸¦å°å»£æ³ä½¿ç¨çè¸é¨ X åçè³æéåæ¨¡åä¸­ååè§å¯å°ä½ç¡æ³è§£éçç·æ§åå¥³æ§æ£èä¹éçæè½å·®ç°æä¾äºè§£éãæåçç¼ç¾è¡¨æï¼å¨åé¡ä»»åä¸­ï¼ééè¸èå¼æµç®¡åå¿é»åå°ç·çå­å¨ï¼å­å¨æ·å¾å­¸ç¿ãéäºæ·å¾ç¹å¾µççè¡çå­å¨åºæ¼æ§å¥çå·®ç°ï¼ä¼¼ä¹æå°è´è§å¯å°çåé¡æè½å·®è·ï¼éä»£è¡¨æ·å¾å­¸ç¿åæ¨¡åå¬å¹³æ§åæä¹éååæªåå°éè¦çäº¤äºä½ç¨ã

##### **Unlocking the Potential of Metaverse in Innovative and Immersive Digital Health**
2406.07114v2 by Fatemeh Ebrahimzadeh, Ramin Safa

The concept of Metaverse has attracted a lot of attention in various fields
and one of its important applications is health and treatment. The Metaverse
has enormous potential to transform healthcare by changing patient care,
medical education, and the way teaching/learning and research are done. The
purpose of this research is to provide an introduction to the basic concepts
and fundamental technologies of the Metaverse. This paper examines the pros and
cons of the Metaverse in healthcare context and analyzes its potential from the
technology and AI perspective. In particular, the role of machine learning
methods is discussed; We will explain how machine learning algorithms can be
applied to the Metaverse generated data to gain better insights in healthcare
applications. Additionally, we examine the future visions of the Metaverse in
health delivery, by examining emerging technologies such as blockchain and also
addressing privacy concerns. The findings of this study contribute to a deeper
understanding of the applications of Metaverse in healthcare and its potential
to revolutionize the delivery of medical services.

æè¦ï¼åå®å®çæ¦å¿µå¨ååé åé½ååéæ³¨ï¼å¶éè¦æç¨ä¹ä¸ä¾¿æ¯é«çä¿å¥ãåå®å®æå·¨å¤§çæ½åééæ¹è®çæ£ç§è­·ãé«å­¸æè²ï¼ä»¥åæå­¸/å­¸ç¿åç ç©¶çæ¹å¼ä¾è½åé«çä¿å¥ãæ¬ç ç©¶çç®çæ¯æä¾åå®å®åºæ¬æ¦å¿µååºç¤æè¡çä»ç´¹ãæ¬ææ¢è¨äºåå®å®å¨é«çä¿å¥èæ¯ä¸çåªç¼ºé»ï¼ä¸¦å¾æè¡å AI çè§åº¦åæå¶æ½åãç¹å¥æ¯ï¼è¨è«äºæ©å¨å­¸ç¿æ¹æ³çè§è²ï¼æåå°èªªæå¦ä½å°æ©å¨å­¸ç¿æ¼ç®æ³æç¨æ¼åå®å®ç¢ççè³æï¼ä»¥ç²å¾é«çä¿å¥æç¨æ¹é¢çæ´ä½³è¦è§£ãæ­¤å¤ï¼æåééæ¢è¨åå¡éç­æ°èæè¡ï¼ä¸¦è§£æ±ºé±ç§åé¡ï¼ä¾æ¢è¨åå®å®å¨é«çä¿å¥æ¹é¢çæªä¾é¡æ¯ãæ¬ç ç©¶çç¼ç¾æå©æ¼æ´æ·±å¥å°äºè§£åå®å®å¨é«çä¿å¥ä¸­çæç¨ï¼ä»¥åå¶å¨é«çæåæä¾æ¹é¢ç¼æ®é©å½æ§è®é©çæ½åã

##### **AI-Driven Predictive Analytics Approach for Early Prognosis of Chronic Kidney Disease Using Ensemble Learning and Explainable AI**
2406.06728v1 by K M Tawsik Jawad, Anusha Verma, Fathi Amsaad

Chronic Kidney Disease (CKD) is one of the widespread Chronic diseases with
no known ultimo cure and high morbidity. Research demonstrates that progressive
Chronic Kidney Disease (CKD) is a heterogeneous disorder that significantly
impacts kidney structure and functions, eventually leading to kidney failure.
With the progression of time, chronic kidney disease has moved from a
life-threatening disease affecting few people to a common disorder of varying
severity. The goal of this research is to visualize dominating features,
feature scores, and values exhibited for early prognosis and detection of CKD
using ensemble learning and explainable AI. For that, an AI-driven predictive
analytics approach is proposed to aid clinical practitioners in prescribing
lifestyle modifications for individual patients to reduce the rate of
progression of this disease. Our dataset is collected on body vitals from
individuals with CKD and healthy subjects to develop our proposed AI-driven
solution accurately. In this regard, blood and urine test results are provided,
and ensemble tree-based machine-learning models are applied to predict unseen
cases of CKD. Our research findings are validated after lengthy consultations
with nephrologists. Our experiments and interpretation results are compared
with existing explainable AI applications in various healthcare domains,
including CKD. The comparison shows that our developed AI models, particularly
the Random Forest model, have identified more features as significant
contributors than XgBoost. Interpretability (I), which measures the ratio of
important to masked features, indicates that our XgBoost model achieved a
higher score, specifically a Fidelity of 98\%, in this metric and naturally in
the FII index compared to competing models.

æè¦ï¼æ¢æ§èèçï¼CKDï¼æ¯ä¸ç¨®å»£æ³çæ¢æ§ç¾çï¼æ²æå·²ç¥çæçµçæ³ä¸ç¼ççå¾é«ãç ç©¶è¡¨æï¼é²è¡æ§æ¢æ§èèçï¼CKDï¼æ¯ä¸ç¨®ç°è³ªæ§ç¾çï¼æé¡¯èå½±é¿èèçµæ§ååè½ï¼æçµå°è´èè¡°ç«­ãé¨èæéçæ¨ç§»ï¼æ¢æ§èèçå·²å¾å½±é¿å°æ¸äººçè´å½ç¾çè½è®çºä¸ç¨®å´éç¨åº¦ä¸åçå¸¸è¦ç¾çãæ¬ç ç©¶çç®æ¨æ¯ä½¿ç¨éæå­¸ç¿åå¯è§£éç AI é²è¡æ©æé å¾å CKD æª¢æ¸¬ï¼ä¸¦è¦è¦ºåä¸»å°ç¹å¾µãç¹å¾µåæ¸åè¡¨ç¾åºçå¼ãçºæ­¤ï¼æåºäºä¸ç¨® AI é©åçé æ¸¬åææ¹æ³ï¼ä»¥å¹«å©è¨åºé«ççºåå¥æ£èéå·çæ´»æ¹å¼ä¿®æ¹å»ºè­°ï¼ä»¥éä½éç¨®ç¾ççé²å±éåº¦ãæåçæ¸æéæ¯å¾ CKD æ£èåå¥åº·åè©¦èçèº«é«çå½é«å¾µä¸­æ¶éçï¼ä»¥æºç¢ºéç¼æåæåºç AI é©åçè§£æ±ºæ¹æ¡ãå¨éæ¹é¢ï¼æä¾äºè¡æ¶²åå°¿æ¶²æª¢æ¸¬çµæï¼ä¸¦æç¨åºæ¼éææ¨¹çæ©å¨å­¸ç¿æ¨¡åä¾é æ¸¬æªç¼ç¾ç CKD çä¾ãæåçç ç©¶çµæç¶éèèèç§é«ççé·æè«®è©¢å¾å¾å°é©è­ãæåçå¯¦é©åè§£éçµæèåç¨®é«çä¿å¥é åä¸­ç¾æçå¯è§£é AI æç¨é²è¡äºæ¯è¼ï¼åæ¬ CKDãæ¯è¼è¡¨æï¼æåéç¼ç AI æ¨¡åï¼ç¹å¥æ¯é¨æ©æ£®ææ¨¡åï¼å·²ç¶ç¢ºå®äºæ¯ XgBoost æ´å¤ä½çºéè¦è²¢ç»èçç¹å¾µãå¯è§£éæ§ (I) è¡¡ééè¦ç¹å¾µèæ©èç¹å¾µçæ¯çï¼è¡¨ææåç XgBoost æ¨¡åå¨éåææ¨ä¸­ç²å¾äºæ´é«çåæ¸ï¼ç¹å¥æ¯ 98% çä¿çåº¦ï¼ä¸¦ä¸å¨ FII ææ¸ä¸­èªç¶é«æ¼ç«¶ç­æ¨¡åã

##### **Explainable AI for Mental Disorder Detection via Social Media: A survey and outlook**
2406.05984v1 by Yusif Ibrahimov, Tarique Anwar, Tommy Yuan

Mental health constitutes a complex and pervasive global challenge, affecting
millions of lives and often leading to severe consequences. In this paper, we
conduct a thorough survey to explore the intersection of data science,
artificial intelligence, and mental healthcare, focusing on the recent
developments of mental disorder detection through online social media (OSM). A
significant portion of the population actively engages in OSM platforms,
creating a vast repository of personal data that holds immense potential for
mental health analytics. The paper navigates through traditional diagnostic
methods, state-of-the-art data- and AI-driven research studies, and the
emergence of explainable AI (XAI) models for mental healthcare. We review
state-of-the-art machine learning methods, particularly those based on modern
deep learning, while emphasising the need for explainability in healthcare AI
models. The experimental design section provides insights into prevalent
practices, including available datasets and evaluation approaches. We also
identify key issues and challenges in the field and propose promising future
research directions. As mental health decisions demand transparency,
interpretability, and ethical considerations, this paper contributes to the
ongoing discourse on advancing XAI in mental healthcare through social media.
The comprehensive overview presented here aims to guide researchers,
practitioners, and policymakers in developing the area of mental disorder
detection.

æè¦ï¼å¿çå¥åº·æ§æäºä¸é è¤éä¸æ®éçå¨çææ°ï¼å½±é¿äºæ¸ç¾è¬äººççæ´»ï¼ä¸¦ç¶å¸¸å°è´å´éçå¾æãå¨æ¬æä¸­ï¼æåé²è¡äºä¸é å¾¹åºçèª¿æ¥ï¼ä»¥æ¢ç´¢æ¸æç§å­¸ãäººå·¥æºæ§åå¿çä¿å¥çäº¤éï¼éé»éæ³¨ééç·ä¸ç¤¾äº¤åªé« (OSM) é²è¡å¿çç¾çæª¢æ¸¬çææ°ç¼å±ãå¾å¤§ä¸é¨åäººå£ç©æ¥µåè OSM å¹³å°ï¼åµé äºä¸åé¾å¤§çäººå¡è³æåº«ï¼å°å¿çå¥åº·åæå·æå·¨å¤§çæ½åãæ¬ææ¢è¨äºå³çµ±çè¨ºæ·æ¹æ³ãæåé²çè³æå AI é©åçç ç©¶ï¼ä»¥åå¿çä¿å¥ä¸­å¯è§£é AI (XAI) æ¨¡åçåºç¾ãæååé¡§äºæåé²çæ©å¨å­¸ç¿æ¹æ³ï¼ç¹å¥æ¯é£äºåºæ¼ç¾ä»£æ·±åº¦å­¸ç¿çæ¹æ³ï¼åæå¼·èª¿äºé«çä¿å¥ AI æ¨¡åä¸­å¯è§£éæ§çå¿è¦æ§ãå¯¦é©è¨­è¨é¨åæä¾äºå°æ®éåæ³çè¦è§£ï¼åæ¬å¯ç¨çè³æéåè©ä¼°æ¹æ³ãæåéæ¾åºè©²é åçä¸»è¦åé¡åææ°ï¼ä¸¦æåºäºæå¸æçæªä¾ç ç©¶æ¹åãç±æ¼å¿çå¥åº·æ±ºç­éè¦éæåº¦ãå¯è§£éæ§åéå¾·èéï¼æ¬ææå©æ¼æ¨é²å¿çä¿å¥ä¸­ééç¤¾äº¤åªé«æ¨é² XAI çæçºè¨è«ãéè£¡æåºçå¨é¢æ¦è¿°æ¨å¨å¼å°ç ç©¶äººå¡ãå¾æ¥­äººå¡åæ¿ç­å¶å®èç¼å±å¿çç¾çæª¢æ¸¬é åã

##### **Methodology and Real-World Applications of Dynamic Uncertain Causality Graph for Clinical Diagnosis with Explainability and Invariance**
2406.05746v1 by Zhan Zhang, Qin Zhang, Yang Jiao, Lin Lu, Lin Ma, Aihua Liu, Xiao Liu, Juan Zhao, Yajun Xue, Bing Wei, Mingxia Zhang, Ru Gao, Hong Zhao, Jie Lu, Fan Li, Yang Zhang, Yiming Wang, Lei Zhang, Fengwei Tian, Jie Hu, Xin Gou

AI-aided clinical diagnosis is desired in medical care. Existing deep
learning models lack explainability and mainly focus on image analysis. The
recently developed Dynamic Uncertain Causality Graph (DUCG) approach is
causality-driven, explainable, and invariant across different application
scenarios, without problems of data collection, labeling, fitting, privacy,
bias, generalization, high cost and high energy consumption. Through close
collaboration between clinical experts and DUCG technicians, 46 DUCG models
covering 54 chief complaints were constructed. Over 1,000 diseases can be
diagnosed without triage. Before being applied in real-world, the 46 DUCG
models were retrospectively verified by third-party hospitals. The verified
diagnostic precisions were no less than 95%, in which the diagnostic precision
for every disease including uncommon ones was no less than 80%. After
verifications, the 46 DUCG models were applied in the real-world in China. Over
one million real diagnosis cases have been performed, with only 17 incorrect
diagnoses identified. Due to DUCG's transparency, the mistakes causing the
incorrect diagnoses were found and corrected. The diagnostic abilities of the
clinicians who applied DUCG frequently were improved significantly. Following
the introduction to the earlier presented DUCG methodology, the recommendation
algorithm for potential medical checks is presented and the key idea of DUCG is
extracted.

æè¦ï¼<paragraph>é«çç§è­·ä¸­éè¦ AI è¼å©çè¨åºè¨ºæ·ãç¾æçæ·±åº¦å­¸ç¿æ¨¡åç¼ºä¹å¯è§£éæ§ï¼ä¸¦ä¸ä¸»è¦å°æ³¨æ¼å½±ååæãæè¿éç¼çåæä¸ç¢ºå®å æéä¿å (DUCG) æ¹æ³æ¯å æé©åçãå¯è§£éçï¼ä¸¦ä¸å¨ä¸åçæç¨å ´æ¯ä¸­æ¯ä¸è®çï¼æ²æè³ææ¶éãæ¨è¨ãæ¬åãé±ç§ãåè¦ãæ¦åãé«ææ¬åé«è½èçåé¡ãééè¨åºå°å®¶å DUCG æè¡äººå¡ä¹éçå¯ååä½ï¼æ§å»ºäºæ¶µè 54 åä¸»è¨´ç 46 å DUCG æ¨¡åãå¯ä»¥å¨æ²æåæµçææ³ä¸è¨ºæ·åº 1,000 å¤ç¨®ç¾çãå¨æç¨æ¼å¯¦éä¸çä¹åï¼46 å DUCG æ¨¡åå·²ç±ç¬¬ä¸æ¹é«é¢åæº¯æ§é©è­ãé©è­çè¨ºæ·ç²¾åº¦ä¸ä½æ¼ 95%ï¼å¶ä¸­åæ¬ç½è¦ç¾çå¨å§çæ¯ç¨®ç¾ççè¨ºæ·ç²¾åº¦ä¸ä½æ¼ 80%ãé©è­å¾ï¼46 å DUCG æ¨¡åå·²å¨ä¸­åå¯¦éæç¨ãå·²ç¶å·è¡äºè¶éä¸ç¾è¬åçå¯¦è¨ºæ·æ¡ä¾ï¼åç¼ç¾ 17 åä¸æ­£ç¢ºçè¨ºæ·ãç±æ¼ DUCG çéææ§ï¼ç¼ç¾ä¸¦ç³¾æ­£äºå°è´ä¸æ­£ç¢ºè¨ºæ·çé¯èª¤ãé »ç¹æç¨ DUCG çè¨åºé«ççè¨ºæ·è½åå¾å°äºé¡¯èæé«ãå¨ä»ç´¹äºåé¢æåºç DUCG æ¹æ³è«ä¹å¾ï¼æåºäºæ½å¨å¥åº·æª¢æ¥çæ¨è¦æ¼ç®æ³ï¼ä¸¦æåäº DUCG çééµææ³ã</paragraph>

##### **Advancing Histopathology-Based Breast Cancer Diagnosis: Insights into Multi-Modality and Explainability**
2406.12897v1 by Faseela Abdullakutty, Younes Akbari, Somaya Al-Maadeed, Ahmed Bouridane, Rifat Hamoudi

It is imperative that breast cancer is detected precisely and timely to
improve patient outcomes. Diagnostic methodologies have traditionally relied on
unimodal approaches; however, medical data analytics is integrating diverse
data sources beyond conventional imaging. Using multi-modal techniques,
integrating both image and non-image data, marks a transformative advancement
in breast cancer diagnosis. The purpose of this review is to explore the
burgeoning field of multimodal techniques, particularly the fusion of
histopathology images with non-image data. Further, Explainable AI (XAI) will
be used to elucidate the decision-making processes of complex algorithms,
emphasizing the necessity of explainability in diagnostic processes. This
review utilizes multi-modal data and emphasizes explainability to enhance
diagnostic accuracy, clinician confidence, and patient engagement, ultimately
fostering more personalized treatment strategies for breast cancer, while also
identifying research gaps in multi-modality and explainability, guiding future
studies, and contributing to the strategic direction of the field.

æè¦ï¼ç²¾ç¢ºä¸åæå°åµæ¸¬ä¹³çå°æ¼æ¹åæ£èé å¾è³ééè¦ãè¨ºæ·æ¹æ³å³çµ±ä¸ä¾è³´æ¼å®ä¸æ¨¡å¼æ¹æ³ï¼ç¶èï¼é«çè³æåææ­£å¨æ´åè¶è¶å³çµ±å½±åçåç¨®è³æä¾æºãä½¿ç¨æ´åå½±ååéå½±åè³æçå¤æ¨¡å¼æè¡ï¼æ¨èªèä¹³çè¨ºæ·çè®é©æ§é²å±ãæ¬ç¯ç¶è¿°çç®çæ¯æ¢è¨å¤æ¨¡å¼æè¡çæ°èé åï¼ç¹å¥æ¯å°çµç¹ççå­¸å½±åèéå½±åè³æèåãæ­¤å¤ï¼å¯è§£éäººå·¥æºæ§ (XAI) å°ç¨æ¼é¡æè¤éæ¼ç®æ³çæ±ºç­éç¨ï¼å¼·èª¿è¨ºæ·éç¨ä¸­å¯è§£éæ§çå¿è¦æ§ãæ¬ç¶è¿°å©ç¨å¤æ¨¡å¼è³æä¸¦å¼·èª¿å¯è§£éæ§ï¼ä»¥æé«è¨ºæ·æºç¢ºæ§ãè¨åºé«å¸«çä¿¡å¿åæ£èåèåº¦ï¼æçµä¿é²ä¹³çæ´åäººåçæ²»çç­ç¥ï¼åæä¹æ¾åºå¤æ¨¡å¼åå¯è§£éæ§çç ç©¶å·®è·ï¼å¼å°æªä¾çç ç©¶ï¼ä¸¦çºè©²é åçç­ç¥æ¹åååºè²¢ç»ã

##### **Revisiting Attention Weights as Interpretations of Message-Passing Neural Networks**
2406.04612v1 by Yong-Min Shin, Siqing Li, Xin Cao, Won-Yong Shin

The self-attention mechanism has been adopted in several widely-used
message-passing neural networks (MPNNs) (e.g., GATs), which adaptively controls
the amount of information that flows along the edges of the underlying graph.
This usage of attention has made such models a baseline for studies on
explainable AI (XAI) since interpretations via attention have been popularized
in various domains (e.g., natural language processing and computer vision).
However, existing studies often use naive calculations to derive attribution
scores from attention, and do not take the precise and careful calculation of
edge attribution into consideration. In our study, we aim to fill the gap
between the widespread usage of attention-enabled MPNNs and their potential in
largely under-explored explainability, a topic that has been actively
investigated in other areas. To this end, as the first attempt, we formalize
the problem of edge attribution from attention weights in GNNs. Then, we
propose GATT, an edge attribution calculation method built upon the computation
tree. Through comprehensive experiments, we demonstrate the effectiveness of
our proposed method when evaluating attributions from GATs. Conversely, we
empirically validate that simply averaging attention weights over graph
attention layers is insufficient to interpret the GAT model's behavior. Code is
publicly available at https://github.com/jordan7186/GAtt/tree/main.

æè¦ï¼èªæ³¨æåæ©å¶å·²è¢«æ¡ç¨æ¼å¤åå»£æ³ä½¿ç¨çè¨æ¯å³éç¥ç¶ç¶²è·¯ (MPNN)ï¼ä¾å¦ GATï¼ï¼å®å¯ä»¥èªé©æå°æ§å¶æ²¿èåºå±¤åå½¢éç·£æµåçè³è¨éãéç¨®æ³¨æåçä½¿ç¨ä½¿å¾æ­¤é¡æ¨¡åæçºå¯è§£é AI (XAI) ç ç©¶çåºç·ï¼å çºééæ³¨æåçè©®éå·²å¨åç¨®é åï¼ä¾å¦èªç¶èªè¨èçåé»è¦è¦è¦ºï¼ä¸­æ®åãç¶èï¼ç¾æçç ç©¶éå¸¸ä½¿ç¨å¤©ççè¨ç®æ¹æ³å¾æ³¨æåä¸­æ¨å°åºæ­¸å åæ¸ï¼ä¸¦ä¸æ²æèæ®å°éç·£æ­¸å çç²¾ç¢ºä¸ä»ç´°çè¨ç®ãå¨æåçç ç©¶ä¸­ï¼æåæ¨å¨å¡«è£æ³¨æååç¨ MPNN çå»£æ³ä½¿ç¨èå®åå¨å¾å¤§ç¨åº¦ä¸æªè¢«ååæ¢ç´¢çå¯è§£éæ§ä¹éçå·®è·ï¼éåä¸»é¡å·²å¨å¶ä»é åç©æ¥µç ç©¶ãçºæ­¤ï¼ä½çºç¬¬ä¸æ¬¡åè©¦ï¼æåå° GNN ä¸­æ³¨æåæ¬éçéç·£æ­¸å åé¡å½¢å¼åãç¶å¾ï¼æåæåº GATTï¼ä¸ç¨®å»ºç«å¨è¨ç®æ¨¹ä¸çéç·£æ­¸å è¨ç®æ¹æ³ãééå¨é¢çå¯¦é©ï¼æåå±ç¤ºäºæåæåºçæ¹æ³å¨è©ä¼° GAT çæ­¸å ææå·æçææãç¸åå°ï¼æåæç¶é©é©è­äºåå°åæ³¨æåå±¤ä¸çæ³¨æåæ¬éåå¹³åå¼ä¸è¶³ä»¥è©®é GAT æ¨¡åçè¡çºãç¨å¼ç¢¼å·²å¬éæ¼ https://github.com/jordan7186/GAtt/tree/mainã

##### **Using Explainable AI for EEG-based Reduced Montage Neonatal Seizure Detection**
2406.16908v3 by Dinuka Sandun Udayantha, Kavindu Weerasinghe, Nima Wickramasinghe, Akila Abeyratne, Kithmin Wickremasinghe, Jithangi Wanigasinghe, Anjula De Silva, Chamira U. S. Edussooriya

The neonatal period is the most vulnerable time for the development of
seizures. Seizures in the immature brain lead to detrimental consequences,
therefore require early diagnosis. The gold-standard for neonatal seizure
detection currently relies on continuous video-EEG monitoring; which involves
recording multi-channel electroencephalogram (EEG) alongside real-time video
monitoring within a neonatal intensive care unit (NICU). However, video-EEG
monitoring technology requires clinical expertise and is often limited to
technologically advanced and resourceful settings. Cost-effective new
techniques could help the medical fraternity make an accurate diagnosis and
advocate treatment without delay. In this work, a novel explainable deep
learning model to automate the neonatal seizure detection process with a
reduced EEG montage is proposed, which employs convolutional nets, graph
attention layers, and fully connected layers. Beyond its ability to detect
seizures in real-time with a reduced montage, this model offers the unique
advantage of real-time interpretability. By evaluating the performance on the
Zenodo dataset with 10-fold cross-validation, the presented model achieves an
absolute improvement of 8.31% and 42.86% in area under curve (AUC) and recall,
respectively.

æè¦ï¼æ°çåææ¯å¤§è¦ç¼è²æèå¼±çææï¼å®¹æåºç¾ç²çç¼ä½ãå¤§è¦ç¼è²ä¸æçæåºç¾ç²çç¼ä½æé æä¸è¯å¾æï¼å æ­¤éè¦åæ©è¨ºæ·ãç®åæ°çåç²çç¼ä½çé»éæ¨æºä¾è³´æ¼é£çºçè¦è¨è¦é»å (EEG) ç£æ¸¬ï¼å¶ä¸­åæ¬å¨æ°çåå è­·çæ¿ (NICU) å§åæé²è¡å¤é »éè¦é»å (EEG) è¨éåå³æè¦è¨ç£æ§ãç¶èï¼è¦è¨è¦é»åç£æ§æè¡éè¦è¨åºå°æ¥­ç¥è­ï¼èä¸éå¸¸åéæ¼æè¡åé²ä¸è³æºè±å¯çç°å¢ãå·ææ¬æççæ°æè¡å¯ä»¥å¹«å©é«ççæºç¢ºè¨ºæ·ä¸¦ç«å³æå¡æ²»çãå¨éé å·¥ä½ä¸­ï¼æåºäºä¸åæ°ç©çå¯è§£éæ·±åº¦å­¸ç¿æ¨¡åï¼ä»¥èªååæ°çåç²çç¼ä½åµæ¸¬éç¨ï¼ä¸¦æ¡ç¨æ¸å°çè¦é»åè£ç½®ï¼å¶ä¸­æ¡ç¨äºå·ç©ç¥ç¶ç¶²è·¯ãåå½¢æ³¨æåå±¤åå¨é£æ¥å±¤ãé¤äºè½å¤ ä½¿ç¨æ¸å°çè£ç½®å³æåµæ¸¬ç²çç¼ä½å¤ï¼æ­¤æ¨¡åéæä¾äºå³æå¯è§£éæ§çç¨ç¹åªå¢ãééå¨ Zenodo è³æéä¸ä½¿ç¨ 10 åäº¤åé©è­è©ä¼°æè½ï¼ææåºçæ¨¡åå¨æ²ç·ä¸é¢ç© (AUC) åå¬åçæ¹é¢åå¥éå°äº 8.31% å 42.86% ççµå°æ¹åã

##### **Breast Cancer Diagnosis: A Comprehensive Exploration of Explainable Artificial Intelligence (XAI) Techniques**
2406.00532v1 by Samita Bai, Sidra Nasir, Rizwan Ahmed Khan, Sheeraz Arif, Alexandre Meyer, Hubert Konik

Breast cancer (BC) stands as one of the most common malignancies affecting
women worldwide, necessitating advancements in diagnostic methodologies for
better clinical outcomes. This article provides a comprehensive exploration of
the application of Explainable Artificial Intelligence (XAI) techniques in the
detection and diagnosis of breast cancer. As Artificial Intelligence (AI)
technologies continue to permeate the healthcare sector, particularly in
oncology, the need for transparent and interpretable models becomes imperative
to enhance clinical decision-making and patient care. This review discusses the
integration of various XAI approaches, such as SHAP, LIME, Grad-CAM, and
others, with machine learning and deep learning models utilized in breast
cancer detection and classification. By investigating the modalities of breast
cancer datasets, including mammograms, ultrasounds and their processing with
AI, the paper highlights how XAI can lead to more accurate diagnoses and
personalized treatment plans. It also examines the challenges in implementing
these techniques and the importance of developing standardized metrics for
evaluating XAI's effectiveness in clinical settings. Through detailed analysis
and discussion, this article aims to highlight the potential of XAI in bridging
the gap between complex AI models and practical healthcare applications,
thereby fostering trust and understanding among medical professionals and
improving patient outcomes.

æè¦ï¼ä¹³ç (BC) æ¯å½±é¿å¨çå¥³æ§æå¸¸è¦çæ¡æ§è«ç¤ä¹ä¸ï¼å æ­¤éè¦é²æ­¥çè¨ºæ·æ¹æ³ï¼ä»¥æ¹åè¨åºçµæãæ¬æå¨é¢æ¢è¨äºå¯è§£éäººå·¥æºæ§ (XAI) æè¡å¨ä¹³çåµæ¸¬åè¨ºæ·ä¸­çæç¨ãé¨èäººå·¥æºæ§ (AI) æè¡æçºæ»²éé«çä¿å¥é åï¼ç¹å¥æ¯å¨è«ç¤å­¸ä¸­ï¼éæä¸å¯è§£éçæ¨¡åéæ±è®å¾å¢å¨å¿è¡ï¼ä»¥å¢å¼·è¨åºæ±ºç­å¶å®åæ£èç§è­·ãæ­¤ç¯è©è«æ¢è¨äºåç¨® XAI æ¹æ³çæ´åï¼ä¾å¦ SHAPãLIMEãGrad-CAM ç­ï¼ä»¥åç¨æ¼ä¹³çåµæ¸¬ååé¡çæ©å¨å­¸ç¿åæ·±åº¦å­¸ç¿æ¨¡åãééæ¢è¨ä¹³çè³æéçæ¨¡å¼ï¼åæ¬ä¹³æ¿æå½±ãè¶é³æ³¢åå¶å¨ AI ä¸­çèçï¼æ¬æéé»èªªæ XAI å¦ä½è½å°è´æ´æºç¢ºçè¨ºæ·ååäººåæ²»çè¨ç«ãå®ä¹æ¢è¨äºå¯¦æ½éäºæè¡çææ°ï¼ä»¥åå¶å®æ¨æºåè©éææ¨ä»¥è©ä¼° XAI å¨è¨åºç°å¢ä¸­çæææ§çéè¦æ§ãééè©³ç´°çåæåè¨è«ï¼æ¬ææ¨å¨å¼·èª¿ XAI å¨ç¸®å°è¤é AI æ¨¡åèå¯¦åé«çä¿å¥æç¨ä¹éå·®è·çæ½åï¼é²èä¿é²é«çå°æ¥­äººå¡ä¹éçä¿¡ä»»èçè§£ï¼ä¸¦æ¹åæ£èççµæã

##### **Unveiling Hidden Factors: Explainable AI for Feature Boosting in Speech Emotion Recognition**
2406.01624v2 by Alaa Nfissi, Wassim Bouachir, Nizar Bouguila, Brian Mishara

Speech emotion recognition (SER) has gained significant attention due to its
several application fields, such as mental health, education, and
human-computer interaction. However, the accuracy of SER systems is hindered by
high-dimensional feature sets that may contain irrelevant and redundant
information. To overcome this challenge, this study proposes an iterative
feature boosting approach for SER that emphasizes feature relevance and
explainability to enhance machine learning model performance. Our approach
involves meticulous feature selection and analysis to build efficient SER
systems. In addressing our main problem through model explainability, we employ
a feature evaluation loop with Shapley values to iteratively refine feature
sets. This process strikes a balance between model performance and
transparency, which enables a comprehensive understanding of the model's
predictions. The proposed approach offers several advantages, including the
identification and removal of irrelevant and redundant features, leading to a
more effective model. Additionally, it promotes explainability, facilitating
comprehension of the model's predictions and the identification of crucial
features for emotion determination. The effectiveness of the proposed method is
validated on the SER benchmarks of the Toronto emotional speech set (TESS),
Berlin Database of Emotional Speech (EMO-DB), Ryerson Audio-Visual Database of
Emotional Speech and Song (RAVDESS), and Surrey Audio-Visual Expressed Emotion
(SAVEE) datasets, outperforming state-of-the-art methods. To the best of our
knowledge, this is the first work to incorporate model explainability into an
SER framework. The source code of this paper is publicly available via this
https://github.com/alaaNfissi/Unveiling-Hidden-Factors-Explainable-AI-for-Feature-Boosting-in-Speech-Emotion-Recognition.

æè¦ï¼èªé³æç·è¾¨è­ (SER) ç±æ¼å¶å¨å¿çå¥åº·ãæè²åäººæ©äºåç­å¤åæç¨é åèååéæ³¨ãç¶èï¼SER ç³»çµ±çæºç¢ºæ§åå°é«ç¶­ç¹å¾µéçé»ç¤ï¼éäºç¹å¾µéå¯è½åå«ä¸ç¸éååé¤çè³è¨ãçºäºåæéåææ°ï¼æ¬ç ç©¶æåºäºä¸ç¨®ç¨æ¼ SER çè¿­ä»£ç¹å¾µæåæ¹æ³ï¼è©²æ¹æ³å¼·èª¿ç¹å¾µç¸éæ§åå¯è§£éæ§ï¼ä»¥å¢å¼·æ©å¨å­¸ç¿æ¨¡åçæè½ãæåçåæ³æ¶åä»ç´°çç¹å¾µé¸æååæï¼ä»¥å»ºç«é«æç SER ç³»çµ±ãçºäºééæ¨¡åå¯è§£éæ§è§£æ±ºæåçæ ¸å¿åé¡ï¼æåæ¡ç¨äºå·æ Shapley å¼çç¹å¾µè©ä¼°è¿´åï¼ä»¥åè¦æ¹åç¹å¾µéãéåéç¨å¨æ¨¡åæè½åéæåº¦ä¹éåå¾å¹³è¡¡ï¼éä½¿å¾æåè½å¤ å¨é¢äºè§£æ¨¡åçé æ¸¬ãææåºçæ¹æ³æä¾äºå¤é åªé»ï¼åæ¬è­å¥åç§»é¤ä¸ç¸éååé¤çç¹å¾µï¼å¾èå»ºç«æ´ææçæ¨¡åãæ­¤å¤ï¼å®ä¿é²äºå¯è§£éæ§ï¼æå©æ¼çè§£æ¨¡åçé æ¸¬ä»¥åè­å¥æç·æ±ºå®çééµç¹å¾µãææåºçæ¹æ³çæææ§å·²å¨å¤å«å¤æç·èªé³é (TESS)ãæææç·èªé³è³æåº« (EMO-DB)ãè³´ç¾æ£®é³è¨è¦è¦ºæç·èªé³åæ­æ²è³æåº« (RAVDESS) åè©éé³è¨è¦è¦ºè¡¨éæç· (SAVEE) è³æéç SER åºæºä¸å¾å°é©è­ï¼å¶æè½åªæ¼ç¾ææ¹æ³ãææåæç¥ï¼éæ¯ç¬¬ä¸åå°æ¨¡åå¯è§£éæ§ç´å¥ SER æ¶æ§çç ç©¶ãæ¬æçåå§ç¢¼å¯ééæ­¤é£çµå¬éåå¾ï¼https://github.com/alaaNfissi/Unveiling-Hidden-Factors-Explainable-AI-for-Feature-Boosting-in-Speech-Emotion-Recognitionã

##### **The Explanation Necessity for Healthcare AI**
2406.00216v1 by Michail Mamalakis, HÃ©loÃ¯se de Vareilles, Graham Murray, Pietro Lio, John Suckling

Explainability is often critical to the acceptable implementation of
artificial intelligence (AI). Nowhere is this more important than healthcare
where decision-making directly impacts patients and trust in AI systems is
essential. This trust is often built on the explanations and interpretations
the AI provides. Despite significant advancements in AI interpretability, there
remains the need for clear guidelines on when and to what extent explanations
are necessary in the medical context. We propose a novel categorization system
with four distinct classes of explanation necessity, guiding the level of
explanation required: patient or sample (local) level, cohort or dataset
(global) level, or both levels. We introduce a mathematical formulation that
distinguishes these categories and offers a practical framework for researchers
to determine the necessity and depth of explanations required in medical AI
applications. Three key factors are considered: the robustness of the
evaluation protocol, the variability of expert observations, and the
representation dimensionality of the application. In this perspective, we
address the question: When does an AI medical application need to be explained,
and at what level of detail?

æè¦ï¼å¯è§£éæ§éå¸¸å¯¹äºäººå·¥æºè½ (AI) çå¯æ¥åå®æ½è³å³éè¦ãå¨å»çä¿å¥é¢åï¼è¿ä¸ç¹å°¤ä¸ºéè¦ï¼å ä¸ºå³ç­ç´æ¥å½±åæ£èï¼å¹¶ä¸å¯¹ AI ç³»ç»çä¿¡ä»»è³å³éè¦ãè¿ç§ä¿¡ä»»éå¸¸å»ºç«å¨ AI æä¾çè§£éåè¯ éä¹ä¸ãå°½ç®¡ AI å¯è§£éæ§åå¾äºéå¤§è¿å±ï¼ä½ä»ç¶éè¦æç¡®çæå¯¼æ¹éï¼è¯´æå¨å»çç¯å¢ä¸­ä½æ¶ä»¥åå¨å¤å¤§ç¨åº¦ä¸éè¦è§£éãæä»¬æåºäºä¸ç§æ°é¢çåç±»ç³»ç»ï¼è¯¥ç³»ç»å·æåç§ä¸åçè§£éå¿è¦æ§ç±»å«ï¼æå¯¼æéçè§£éçº§å«ï¼æ£èææ ·æ¬ï¼å±é¨ï¼çº§å«ãéåææ°æ®éï¼å¨å±ï¼çº§å«ï¼æä¸¤ä¸ªçº§å«ãæä»¬å¼å¥äºä¸ä¸ªæ°å­¦å¬å¼ï¼è¯¥å¬å¼åºåäºè¿äºç±»å«ï¼å¹¶ä¸ºç ç©¶äººåæä¾äºä¸ä¸ªå®ç¨æ¡æ¶ï¼ä»¥ç¡®å®å»ç AI åºç¨ä¸­æéçè§£éçå¿è¦æ§åæ·±åº¦ãèèäºä¸ä¸ªå³é®å ç´ ï¼è¯ä¼°åè®®çç¨³å¥æ§ãä¸å®¶è§å¯çå¯åæ§ä»¥ååºç¨ç¨åºçè¡¨ç¤ºç»´æ°ãä»è¿ä¸ªè§åº¦æ¥çï¼æä»¬è§£å³äºè¿ä¸ªé®é¢ï¼AI å»çåºç¨ä½æ¶éè¦è§£éï¼ä»¥åéè¦è§£éå°ä½ç§ç¨åº¦ï¼

##### **Interdisciplinary Expertise to Advance Equitable Explainable AI**
2406.18563v1 by Chloe R. Bennett, Heather Cole-Lewis, Stephanie Farquhar, Naama Haamel, Boris Babenko, Oran Lang, Mat Fleck, Ilana Traynis, Charles Lau, Ivor Horn, Courtney Lyles

The field of artificial intelligence (AI) is rapidly influencing health and
healthcare, but bias and poor performance persists for populations who face
widespread structural oppression. Previous work has clearly outlined the need
for more rigorous attention to data representativeness and model performance to
advance equity and reduce bias. However, there is an opportunity to also
improve the explainability of AI by leveraging best practices of social
epidemiology and health equity to help us develop hypotheses for associations
found. In this paper, we focus on explainable AI (XAI) and describe a framework
for interdisciplinary expert panel review to discuss and critically assess AI
model explanations from multiple perspectives and identify areas of bias and
directions for future research. We emphasize the importance of the
interdisciplinary expert panel to produce more accurate, equitable
interpretations which are historically and contextually informed.
Interdisciplinary panel discussions can help reduce bias, identify potential
confounders, and identify opportunities for additional research where there are
gaps in the literature. In turn, these insights can suggest opportunities for
AI model improvement.

æè¦ï¼äººå·¥æºæ§ (AI) é åæ­£å¿«éå½±é¿èå¥åº·èé«çä¿å¥ï¼ä½å°æ¼é¢è¨å»£æ³çµæ§æ§å£è¿«çäººç¾¤ä¾èªªï¼åè¦åä¸è¯è¡¨ç¾ä¾ç¶å­å¨ãååçç ç©¶å·²æ¸æ¥èªªæï¼éè¦æ´å´æ ¼å°æ³¨æè³æä»£è¡¨æ§åæ¨¡åæè½ï¼ä»¥ä¿é²å¬å¹³æ§ä¸¦æ¸å°åè¦ãç¶èï¼æåææ©æéééç¨ç¤¾ææµè¡çå­¸åå¥åº·å¬å¹³çæä½³å¯¦åï¼ä¾æ¹å AI çå¯è§£éæ§ï¼ä»¥å¹«å©æåéå°ç¼ç¾çéè¯æ§ï¼ç¼å±åè¨­ãå¨æ¬æä¸­ï¼æåå°æ³¨æ¼å¯è§£é AI (XAI)ï¼ä¸¦æè¿°ä¸åè·¨é åå°å®¶å°çµå¯©æ¥æ¶æ§ï¼ä»¥å¾å¤éè§é»è¨è«åæ¹å¤æ§è©ä¼° AI æ¨¡åçè§£éï¼ä¸¦æ¾åºåè¦é ååæªä¾ç ç©¶çæ¹åãæåå¼·èª¿è·¨é åå°å®¶å°çµå°æ¼ç¢çæ´æºç¢ºãå¬å¹³çè©®éè³ééè¦ï¼èéäºè©®éæ¯æ ¹ææ­·å²åèçµ¡èä¾çãè·¨é åå°çµè¨è«æå©æ¼æ¸å°åè¦ãæ¾åºæ½å¨çæ··æ·å ç´ ï¼ä¸¦å¨æç»ä¸­æç¼ºå£ææ¾åºé¡å¤ç ç©¶çæ©æãåéä¾ï¼éäºè¦è§£å¯ä»¥å»ºè­° AI æ¨¡åæ¹é²çæ©æã

##### **"It depends": Configuring AI to Improve Clinical Usefulness Across Contexts**
2407.11978v1 by Hubert D. ZajÄc, Jorge M. N. Ribeiro, Silvia Ingala, Simona Gentile, Ruth Wanjohi, Samuel N. Gitau, Jonathan F. Carlsen, Michael B. Nielsen, Tariq O. Andersen

Artificial Intelligence (AI) repeatedly match or outperform radiologists in
lab experiments. However, real-world implementations of radiological AI-based
systems are found to provide little to no clinical value. This paper explores
how to design AI for clinical usefulness in different contexts. We conducted 19
design sessions and design interventions with 13 radiologists from 7 clinical
sites in Denmark and Kenya, based on three iterations of a functional AI-based
prototype. Ten sociotechnical dependencies were identified as crucial for the
design of AI in radiology. We conceptualised four technical dimensions that
must be configured to the intended clinical context of use: AI functionality,
AI medical focus, AI decision threshold, and AI Explainability. We present four
design recommendations on how to address dependencies pertaining to the medical
knowledge, clinic type, user expertise level, patient context, and user
situation that condition the configuration of these technical dimensions.

æè¦ï¼äººå·¥æºæ§ï¼AIï¼å¨å¯¦é©å®¤å¯¦é©ä¸­ä¸æ·å°èæ¾å°ç§é«å¸«å¹æµæè¡¨ç¾å¾æ´åºè²ãç¶èï¼ç¼ç¾æ¾å°ç§ AI çºåºç¤ç³»çµ±çå¯¦éå·è¡å¹¾ä¹æ²ææä¾è¨åºå¹å¼ãæ¬ææ¢è¨å¦ä½çº AI è¨­è¨å¨ä¸åæå¢ä¸­è¨åºä¸çæç¨ãæåæ ¹æåè½æ§ AI çºåºç¤ååçä¸æ¬¡è¿­ä»£ï¼å¨ä¸¹éº¥åè¯äºç 7 åè¨åºå ´åè 13 ä½æ¾å°ç§é«å¸«é²è¡äº 19 æ¬¡è¨­è¨æè­°åè¨­è¨ä»å¥ãååç¤¾ææè¡ä¾è³´éä¿è¢«èªçºå°æ¼æ¾å°ç§ä¸­ AI çè¨­è¨è³ééè¦ãæåæ¦å¿µåäºååæè¡é¢åï¼å¿é æ ¹æé æçè¨åºä½¿ç¨æå¢é²è¡è¨­å®ï¼AI åè½ãAI é«çéé»ãAI æ±ºç­éæª»ï¼ä»¥å AI å¯è§£éæ§ãæåæåºåé è¨­è¨å»ºè­°ï¼èªªæå¦ä½èçèé«çç¥è­ãè¨ºæé¡åãä½¿ç¨èå°æ¥­ç¥è­ç­ç´ãæ£èæå¢ï¼ä»¥åå½±é¿éäºæè¡é¢åè¨­å®çä½¿ç¨èæå¢ç¸éçä¾è³´éä¿ã

##### **Improving Health Professionals' Onboarding with AI and XAI for Trustworthy Human-AI Collaborative Decision Making**
2405.16424v1 by Min Hun Lee, Silvana Xin Yi Choo, Shamala D/O Thilarajah

With advanced AI/ML, there has been growing research on explainable AI (XAI)
and studies on how humans interact with AI and XAI for effective human-AI
collaborative decision-making. However, we still have a lack of understanding
of how AI systems and XAI should be first presented to users without technical
backgrounds. In this paper, we present the findings of semi-structured
interviews with health professionals (n=12) and students (n=4) majoring in
medicine and health to study how to improve onboarding with AI and XAI. For the
interviews, we built upon human-AI interaction guidelines to create onboarding
materials of an AI system for stroke rehabilitation assessment and AI
explanations and introduce them to the participants. Our findings reveal that
beyond presenting traditional performance metrics on AI, participants desired
benchmark information, the practical benefits of AI, and interaction trials to
better contextualize AI performance, and refine the objectives and performance
of AI. Based on these findings, we highlight directions for improving
onboarding with AI and XAI and human-AI collaborative decision-making.

æè¦ï¼é¨èåé²ç AI/MLï¼å°å¯è§£é AI (XAI) çç ç©¶ä¸æ·å¢å ï¼ä»¥åéæ¼äººé¡å¦ä½è AI å XAI äºåä»¥é²è¡ææçäººå·¥æºæ§åä½æ±ºç­å¶å®ãç¶èï¼æåä»ç¶ç¼ºä¹å° AI ç³»çµ±å XAI æå¦ä½é¦ååç¾çµ¦æ²ææè¡èæ¯çç¨æ¶çäºè§£ãå¨æ¬æä¸­ï¼æåå±ç¤ºäºèé«çå°æ¥­äººå¡ (n=12) åä¸»ä¿®é«å­¸åå¥åº·çå­¸ç (n=4) é²è¡åçµæ§åè¨ªè«ççµæï¼ä»¥ç ç©¶å¦ä½æ¹å AI å XAI çå¥éãå°æ¼è¨ªè«ï¼æåå»ºç«å¨äººæ©äºåæºåä¹ä¸ï¼çºä¸­é¢¨åº·å¾©è©ä¼°å AI è§£éç AI ç³»çµ±åµå»ºå¥éææï¼ä¸¦å°å®åä»ç´¹çµ¦åèèãæåçç ç©¶çµæè¡¨æï¼é¤äºåç¾å³çµ±ç AI æ§è½ææ¨å¤ï¼åèèéå¸æåºåä¿¡æ¯ãAI çå¯¦éå¥½èä»¥åäº¤äºè©¦é©ï¼ä»¥æ´å¥½å°å° AI æ§è½æå¢åï¼ä¸¦å®å AI çç®æ¨åæ§è½ãæ ¹æéäºç¼ç¾ï¼æåå¼·èª¿äºæ¹é² AI å XAI ä»¥åäººæ©åä½æ±ºç­å¶å®çå¥éæ¹åã

##### **Exploring Nutritional Impact on Alzheimer's Mortality: An Explainable AI Approach**
2405.17502v1 by Ziming Liu, Longjian Liu, Robert E. Heidel, Xiaopeng Zhao

This article uses machine learning (ML) and explainable artificial
intelligence (XAI) techniques to investigate the relationship between
nutritional status and mortality rates associated with Alzheimers disease (AD).
The Third National Health and Nutrition Examination Survey (NHANES III)
database is employed for analysis. The random forest model is selected as the
base model for XAI analysis, and the Shapley Additive Explanations (SHAP)
method is used to assess feature importance. The results highlight significant
nutritional factors such as serum vitamin B12 and glycated hemoglobin. The
study demonstrates the effectiveness of random forests in predicting AD
mortality compared to other diseases. This research provides insights into the
impact of nutrition on AD and contributes to a deeper understanding of disease
progression.

æè¦ï¼æ¬æä½¿ç¨æ©å¨å­¸ç¿ (ML) åå¯è§£éäººå·¥æºæ§ (XAI) æè¡ä¾æ¢è¨çé¤çæ³èé¿è²æµ·é»ç (AD) ç¸éçæ­»äº¡çä¹éçéä¿ãæ¡ç¨ç¬¬ä¸æ¬¡å¨åå¥åº·èçé¤æª¢æ¥èª¿æ¥ (NHANES III) è³æåº«é²è¡åæãé¸æé¨æ©æ£®ææ¨¡åä½çº XAI åæçåºç¤æ¨¡åï¼ä¸¦ä½¿ç¨ Shapley Additive Explanations (SHAP) æ¹æ³ä¾è©ä¼°ç¹å¾µéè¦æ§ãçµæçªé¡¯äºéè¦ççé¤å ç´ ï¼ä¾å¦è¡æ¸ç¶­çç´  B12 åç³åè¡ç´èç½ãè©²ç ç©¶è­æäºé¨æ©æ£®æå¨é æ¸¬ AD æ­»äº¡çæ¹é¢ç¸è¼æ¼å¶ä»ç¾ççæææ§ãæ¬ç ç©¶æä¾äºçé¤å° AD çå½±é¿çè¦è§£ï¼ä¸¦æå©æ¼æ´æ·±å¥å°äºè§£ç¾ççé²å±ã

##### **Explainable AI Enhances Glaucoma Referrals, Yet the Human-AI Team Still Falls Short of the AI Alone**
2407.11974v1 by Catalina Gomez, Ruolin Wang, Katharina Breininger, Corinne Casey, Chris Bradley, Mitchell Pavlak, Alex Pham, Jithin Yohannan, Mathias Unberath

Primary care providers are vital for initial triage and referrals to
specialty care. In glaucoma, asymptomatic and fast progression can lead to
vision loss, necessitating timely referrals to specialists. However, primary
eye care providers may not identify urgent cases, potentially delaying care.
Artificial Intelligence (AI) offering explanations could enhance their referral
decisions. We investigate how various AI explanations help providers
distinguish between patients needing immediate or non-urgent specialist
referrals. We built explainable AI algorithms to predict glaucoma surgery needs
from routine eyecare data as a proxy for identifying high-risk patients. We
incorporated intrinsic and post-hoc explainability and conducted an online
study with optometrists to assess human-AI team performance, measuring referral
accuracy and analyzing interactions with AI, including agreement rates, task
time, and user experience perceptions. AI support enhanced referral accuracy
among 87 participants (59.9%/50.8% with/without AI), though Human-AI teams
underperformed compared to AI alone. Participants believed they included AI
advice more when using the intrinsic model, and perceived it more useful and
promising. Without explanations, deviations from AI recommendations increased.
AI support did not increase workload, confidence, and trust, but reduced
challenges. On a separate test set, our black-box and intrinsic models achieved
an accuracy of 77% and 71%, respectively, in predicting surgical outcomes. We
identify opportunities of human-AI teaming for glaucoma management in primary
eye care, noting that while AI enhances referral accuracy, it also shows a
performance gap compared to AI alone, even with explanations. Human involvement
remains essential in medical decision making, underscoring the need for future
research to optimize collaboration, ensuring positive experiences and safe AI
use.

æè¦ï¼<paragraph>åç´ä¿å¥æä¾èå°æ¼æåçåæµåè½è¨ºå°å°ç§ç§è­·è³ééè¦ãå¨éåç¼çææ³ä¸ï¼ç¡ççä¸å¿«éæ¡åå¯è½å°è´è¦ååªå¤±ï¼å æ­¤éè¦åæè½è¨ºçµ¦å°å®¶ãç¶èï¼åç´ç¼ç§ä¿å¥æä¾èå¯è½ç¡æ³è­å¥ç·æ¥ææ³ï¼å¯è½æå»¶èª¤ç§è­·ãæä¾è§£éçäººå·¥æºæ§ (AI) å¯ä»¥å å¼·ä»åçè½è¨ºæ±ºç­ãæåç ç©¶åç¨® AI è§£éå¦ä½å¹«å©æä¾èååéè¦ç«å³æéç·æ¥å°ç§è½è¨ºçæ£èãæåå»ºç«äºè§£éæ§ AI æ¼ç®æ³ï¼ä»¥å¾ä¾è¡ç¼ç§è­·çè³æé æ¸¬éåç¼æè¡éæ±ï¼ä½çºè­å¥é«é¢¨éªæ£èçä»£çãæåç´å¥äºå§å¨åäºå¾è§£éæ§ï¼ä¸¦èé©åå¸«é²è¡äºä¸é ç·ä¸ç ç©¶ï¼ä»¥è©ä¼°äººæ©åéçè¡¨ç¾ï¼è¡¡éè½è¨ºæºç¢ºåº¦ä¸¦åæè AI çäºåï¼åæ¬åæçãä»»åæéåä½¿ç¨èé«é©æç¥ãå¨ 87 ååèèä¸­ï¼AI æ¯æ´æé«äºè½è¨ºæºç¢ºåº¦ï¼ä½¿ç¨ AI/æªä½¿ç¨çæ¯ä¾çº 59.9%/50.8%ï¼ï¼åç®¡äººæ©åéçè¡¨ç¾ä¸å¦å®ç¨ä½¿ç¨ AIãåèèèªçºä»åå¨ä½¿ç¨å§å¨æ¨¡åææ´å¤å°ç´å¥äº AI å»ºè­°ï¼ä¸¦èªçºå®æ´æç¨ä¸æ´æå¸æãæ²æè§£éï¼AI å»ºè­°çåå·®æå¢å ãAI æ¯æ´ä¸¦æªå¢å å·¥ä½éãä¿¡å¿åä¿¡ä»»ï¼ä½æ¸å°äºææ°ãå¨ä¸åå®ç¨çæ¸¬è©¦éä¸­ï¼æåçé»çå­åå§å¨æ¨¡åå¨é æ¸¬æè¡çµææ¹é¢åå¥éå°äº 77% å 71% çæºç¢ºåº¦ãæåæ¾åºå¨åç´ç¼ç§ä¿å¥ä¸­ï¼äººæ©åéåä½ç®¡çéåç¼çæ©æï¼ä¸¦æ³¨æå°éç¶ AI æé«äºè½è¨ºæºç¢ºåº¦ï¼ä½å³ä½¿æè§£éï¼å®ä¹é¡¯ç¤ºåºèå®ç¨ä½¿ç¨ AI ç¸æ¯çæè½å·®è·ãäººé¡åèå¨é«çæ±ºç­ä¸­ä»ç¶è³ééè¦ï¼éå¼·èª¿äºæªä¾ç ç©¶åªååä½ãç¢ºä¿æ­£é¢ç¶é©åå®å¨ä½¿ç¨ AI çå¿è¦æ§ã</paragraph>

##### **Decoding Decision Reasoning: A Counterfactual-Powered Model for Knowledge Discovery**
2406.18552v1 by Yingying Fang, Zihao Jin, Xiaodan Xing, Simon Walsh, Guang Yang

In medical imaging, particularly in early disease detection and prognosis
tasks, discerning the rationale behind an AI model's predictions is crucial for
evaluating the reliability of its decisions. Conventional explanation methods
face challenges in identifying discernible decisive features in medical image
classifications, where discriminative features are subtle or not immediately
apparent. To bridge this gap, we propose an explainable model that is equipped
with both decision reasoning and feature identification capabilities. Our
approach not only detects influential image patterns but also uncovers the
decisive features that drive the model's final predictions. By implementing our
method, we can efficiently identify and visualise class-specific features
leveraged by the data-driven model, providing insights into the decision-making
processes of deep learning models. We validated our model in the demanding
realm of medical prognosis task, demonstrating its efficacy and potential in
enhancing the reliability of AI in healthcare and in discovering new knowledge
in diseases where prognostic understanding is limited.

æè¦ï¼å¨é«å­¸å½±åä¸­ï¼ç¹å¥æ¯å¨æ©æç¾çæª¢æ¸¬åé å¾ä»»åä¸­ï¼è¾¨å¥ AI æ¨¡åé æ¸¬èå¾çåçå°æ¼è©ä¼°å¶æ±ºç­çå¯é æ§è³ééè¦ãå³çµ±çè§£éæ¹æ³å¨è­å¥é«å­¸å½±ååé¡ä¸­å¯è­å¥çæ±ºå®æ§ç¹å¾µæé¢è¨ææ°ï¼å¶ä¸­åå¥æ§ç¹å¾µå¾å¾®å¦æä¸¦ä¸æé¡¯ãçºäºå½åéä¸å·®è·ï¼æåæåºäºä¸åå¯è§£éçæ¨¡åï¼è©²æ¨¡åå·åæ±ºç­æ¨çåç¹å¾µè­å¥è½åãæåçåæ³ä¸åæª¢æ¸¬æå½±é¿åçå½±åæ¨¡å¼ï¼éæ­ç¤ºäºæ¨åæ¨¡åæçµé æ¸¬çæ±ºå®æ§ç¹å¾µãééå¯¦æ½æåçæ¨¡åï¼æåå¯ä»¥ææè­å¥åè¦è¦ºåç±æ¸æé©åæ¨¡åå©ç¨çé¡ç¹å®ç¹å¾µï¼å¾èæ·±å¥äºè§£æ·±åº¦å­¸ç¿æ¨¡åçæ±ºç­éç¨ãæåå¨è¦æ±å´æ ¼çé«å­¸é å¾ä»»åé åé©è­äºæåçæ¨¡åï¼å±ç¤ºäºå¶å¨æé« AI å¨é«çä¿å¥ä¸­çå¯é æ§åç¼ç¾é å¾çè§£åéç¾ççæ°ç¥è­æ¹é¢çåæåæ½åã

##### **The Role of Emotions in Informational Support Question-Response Pairs in Online Health Communities: A Multimodal Deep Learning Approach**
2405.13099v1 by Mohsen Jozani, Jason A. Williams, Ahmed Aleroud, Sarbottam Bhagat

This study explores the relationship between informational support seeking
questions, responses, and helpfulness ratings in online health communities. We
created a labeled data set of question-response pairs and developed multimodal
machine learning and deep learning models to reliably predict informational
support questions and responses. We employed explainable AI to reveal the
emotions embedded in informational support exchanges, demonstrating the
importance of emotion in providing informational support. This complex
interplay between emotional and informational support has not been previously
researched. The study refines social support theory and lays the groundwork for
the development of user decision aids. Further implications are discussed.

æè¦ï¼æ¬ç ç©¶æ¢è¨ç·ä¸å¥åº·ç¤¾ç¾¤ä¸­å°æ±è³è¨æ¯æçåé¡ãåæï¼ä»¥åæå¹«å©çè©åä¹éçéä¿ãæåå»ºç«äºä¸çµæ¨è¨çåç­éå°è³æéï¼ä¸¦éç¼äºå¤æ¨¡ææ©å¨å­¸ç¿åæ·±åº¦å­¸ç¿æ¨¡åï¼ä»¥å¯é å°é æ¸¬è³è¨æ¯æåé¡ååæãæåæ¡ç¨å¯è§£éç AI ä¾æ­ç¤ºè³è¨æ¯æäº¤æµä¸­èå«çæç·ï¼è­ææç·å¨æä¾è³è¨æ¯æä¸­çéè¦æ§ãéç¨®æç·æ¯æåè³è¨æ¯æä¹éçè¤éäº¤äºä½ç¨ä»¥åä¸¦æªè¢«ç ç©¶éãæ¬ç ç©¶æ¹é²äºç¤¾ææ¯æçè«ï¼ä¸¦çºä½¿ç¨èæ±ºç­è¼å©å·¥å·çéç¼å¥ å®äºåºç¤ãè¨è«äºé²ä¸æ­¥çå½±é¿ã

##### **ChatGPT in Classrooms: Transforming Challenges into Opportunities in Education**
2405.10645v1 by Harris Bin Munawar, Nikolaos Misirlis

In the era of exponential technology growth, one unexpected guest has claimed
a seat in classrooms worldwide, Artificial Intelligence. Generative AI, such as
ChatGPT, promises a revolution in education, yet it arrives with a double-edged
sword. Its potential for personalized learning is offset by issues of cheating,
inaccuracies, and educators struggling to incorporate it effectively into their
lesson design. We are standing on the brink of this educational frontier, and
it is clear that we need to navigate this terrain with a lot of care. This is a
major challenge that could undermine the integrity and value of our educational
process. So, how can we turn these challenges into opportunities? When used
inappropriately, AI tools can become the perfect tool for the cut copy paste
mentality, and quickly begin to corrode critical thinking, creativity, and deep
understanding, the most important skills in our rapidly changing world.
Teachers feel that they are not equipped to leverage this technology, widening
the digital divide among educators and institutions. Addressing these concerns
calls for an in depth research approach. We will employ empirical research,
drawing on the Technology Acceptance Model, to assess the attitudes toward
generative AI among educators and students. Understanding their perceptions,
usage patterns, and hurdles is the first crucial step in creating an effective
solution. The present study will be used as a process manual for future
researchers to apply, running their own data, based on the steps explained here

æè¦ï¼å¨ç§æé£éç¼å±çæä»£ï¼ä¸ä½æå¤çè¨ªå®¢å·²å¨å¨çæå®¤ä¸­ä½æä¸å¸­ä¹å°ï¼é£å°±æ¯äººå·¥æºæ§ãçæå¼ AIï¼ä¾å¦ ChatGPTï¼æ¿è«¾å¨æè²é åæèµ·ä¸å ´é©å½ï¼ä½å®å»æ¯ä¸æéé¢åãå®å¨åäººåå­¸ç¿æ¹é¢çæ½åï¼å»å ä½å¼ãä¸æºç¢ºä»¥åæè²å·¥ä½èé£ä»¥å°å¶ææèå¥æå­¸è¨­è¨ç­åé¡èæµé·ãæåæ­£ç«å¨éæè²åæ²¿çéç·£ï¼é¡¯ç¶æåéè¦éå¸¸å°å¿å°æ¢ç´¢éçé åãéæ¯ä¸åéå¤§çææ°ï¼å¯è½ææå®³æåæè²éç¨çå®æ´æ§åå¹å¼ãé£éº¼ï¼æåå¦ä½å°éäºææ°è½åçºæ©éï¼ç¶ä¸é©ç¶å°ä½¿ç¨æï¼AI å·¥å·å¯è½ææçºè¤è£½è²¼ä¸å¿æçå®ç¾å·¥å·ï¼ä¸¦è¿éèèæ¹å¤æ§æç¶­ãåµé ååæ·±å¥çè§£ï¼éäºé½æ¯æåå¿«éè®åçä¸çä¸­æéè¦çæè½ãæå¸«åè¦ºå¾ä»åæ²æè½åå©ç¨éé æè¡ï¼éæ´å¤§äºæè²å·¥ä½èåæ©æ§ä¹éçæ¸ä½é´»æºãè§£æ±ºéäºåé¡éè¦æ·±å¥çç ç©¶æ¹æ³ãæåå°æ¡ç¨å¯¦è­ç ç©¶ï¼åéæè¡æ¥åæ¨¡åï¼ä¾è©ä¼°æè²å·¥ä½èåå­¸çå°çæå¼ AI çæåº¦ãäºè§£ä»åççæ³ãä½¿ç¨æ¨¡å¼åéç¤æ¯åµé ææè§£æ±ºæ¹æ¡çç¬¬ä¸åééµæ­¥é©ãæ¬ç ç©¶å°ä½çºæªä¾ç ç©¶äººå¡æç¨çæµç¨æåï¼æ ¹ææ­¤èèªªæçæ­¥é©éè¡ä»åèªå·±çæ¸æ

##### **Evaluating the Explainable AI Method Grad-CAM for Breath Classification on Newborn Time Series Data**
2405.07590v1 by Camelia Oprea, Mike GrÃ¼ne, Mateusz Buglowski, Lena Olivier, Thorsten Orlikowsky, Stefan Kowalewski, Mark Schoberer, AndrÃ© Stollenwerk

With the digitalization of health care systems, artificial intelligence
becomes more present in medicine. Especially machine learning shows great
potential for complex tasks such as time series classification, usually at the
cost of transparency and comprehensibility. This leads to a lack of trust by
humans and thus hinders its active usage. Explainable artificial intelligence
tries to close this gap by providing insight into the decision-making process,
the actual usefulness of its different methods is however unclear. This paper
proposes a user study based evaluation of the explanation method Grad-CAM with
application to a neural network for the classification of breaths in time
series neonatal ventilation data. We present the perceived usefulness of the
explainability method by different stakeholders, exposing the difficulty to
achieve actual transparency and the wish for more in-depth explanations by many
of the participants.

æè¦ï¼é¨èé«çä¿å¥ç³»çµ±çæ¸ä½åï¼äººå·¥æºæ§å¨é«å­¸é åä¸­è®å¾æ´å æ®åãç¹å¥æ¯æ©å¨å­¸ç¿å¨æéåºååé¡ç­è¤éä»»åä¸­å±ç¾åºæ¥µå¤§çæ½åï¼ä½éå¸¸æ¯ä»¥éæåº¦åå¯çè§£æ§çºä»£å¹ãéå°è´äººé¡ç¼ºä¹ä¿¡ä»»ï¼å¾èé»ç¤äºå¶ç©æ¥µä½¿ç¨ãå¯è§£éçäººå·¥æºæ§è©¦åééæä¾å°æ±ºç­éç¨çæ´å¯ä¾å½è£éä¸å·®è·ï¼ä½å¶ä¸åæ¹æ³çå¯¦éæç¨å°ä¸æ¸æ¥ãæ¬ææåºäºä¸ååºæ¼ä½¿ç¨èç ç©¶çè©ä¼°ï¼å¶ä¸­åå«äº Grad-CAM è§£éæ¹æ³ï¼ä¸¦å°å¶æç¨æ¼ç¥ç¶ç¶²è·¯ä»¥åé¡æéåºåæ°çåå¼å¸æ¸æä¸­çå¼å¸ãæåå±ç¤ºäºä¸åå©çç¸éèå°å¯è§£éæ§æ¹æ³çæç¥æç¨ï¼æ­ç¤ºäºå¯¦ç¾å¯¦ééæåº¦çé£åº¦ï¼ä»¥åè¨±å¤åèèå¸æç²å¾æ´æ·±å¥çè§£éã

##### **XAI4LLM. Let Machine Learning Models and LLMs Collaborate for Enhanced In-Context Learning in Healthcare**
2405.06270v3 by Fatemeh Nazary, Yashar Deldjoo, Tommaso Di Noia, Eugenio di Sciascio

The integration of Large Language Models (LLMs) into healthcare diagnostics
offers a promising avenue for clinical decision-making. This study outlines the
development of a novel method for zero-shot/few-shot in-context learning (ICL)
by integrating medical domain knowledge using a multi-layered structured
prompt. We also explore the efficacy of two communication styles between the
user and LLMs: the Numerical Conversational (NC) style, which processes data
incrementally, and the Natural Language Single-Turn (NL-ST) style, which
employs long narrative prompts.
  Our study systematically evaluates the diagnostic accuracy and risk factors,
including gender bias and false negative rates, using a dataset of 920 patient
records in various few-shot scenarios. Results indicate that traditional
clinical machine learning (ML) models generally outperform LLMs in zero-shot
and few-shot settings. However, the performance gap narrows significantly when
employing few-shot examples alongside effective explainable AI (XAI) methods as
sources of domain knowledge. Moreover, with sufficient time and an increased
number of examples, the conversational style (NC) nearly matches the
performance of ML models. Most notably, LLMs demonstrate comparable or superior
cost-sensitive accuracy relative to ML models.
  This research confirms that, with appropriate domain knowledge and tailored
communication strategies, LLMs can significantly enhance diagnostic processes.
The findings highlight the importance of optimizing the number of training
examples and communication styles to improve accuracy and reduce biases in LLM
applications.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) èé«çè¨ºæ·æ´å
çºè¨åºæ±ºç­æä¾äºä¸åæåæ¯çéå¾ãæ¬ç ç©¶æ¦è¿°äºä¸ç¨®æ°ç©æ¹æ³çéç¼ï¼ç¨æ¼é¶æ¬¡å­¸ç¿/å°éå­¸ç¿æå¢å­¸ç¿ (ICL)ï¼æ¹æ³æ¯ä½¿ç¨å¤å±¤çµæ§åæç¤ºæ´åé«çé åç¥è­ãæåéæ¢è¨äºä½¿ç¨èè LLM ä¹éå©ç¨®æºéæ¹å¼çåæï¼æ¸å¼å°è©± (NC) æ¹å¼ï¼å®æéæ­¥èçè³æï¼ä»¥åèªç¶èªè¨å®åå (NL-ST) æ¹å¼ï¼å®æä½¿ç¨é·ç¯æäºæç¤ºã
æåçç ç©¶ç³»çµ±æ§å°è©ä¼°äºè¨ºæ·æºç¢ºæ§åé¢¨éªå å­ï¼åæ¬æ§å¥åè¦ååé°æ§çï¼ä½¿ç¨äºä¸ååå« 920 åæ£èè¨éçè³æéï¼æ¡ç¨åç¨®å°éå­¸ç¿æå¢ãçµæè¡¨æï¼å³çµ±çè¨åºæ©å¨å­¸ç¿ (ML) æ¨¡åéå¸¸å¨é¶æ¬¡å­¸ç¿åå°éå­¸ç¿è¨­å®ä¸­è¡¨ç¾åªæ¼ LLMãç¶èï¼ç¶ä½¿ç¨å°éå­¸ç¿ç¯ä¾ä»¥åææçå¯è§£é AI (XAI) æ¹æ³ä½çºé åç¥è­ä¾æºæï¼æè½å·®è·æé¡¯èç¸®å°ãæ­¤å¤ï¼é¨èæéåè¶³åç¯ä¾æ¸éå¢å ï¼å°è©±æ¹å¼ (NC) å¹¾ä¹å¯ä»¥åª²ç¾ ML æ¨¡åçæè½ãæå¼å¾æ³¨æçæ¯ï¼LLM ç¸å°æ¼ ML æ¨¡åå±ç¾åºç¸ç¶ææ´ä½³çææ¬æææºç¢ºåº¦ã
æ¬ç ç©¶è­å¯¦ï¼ééé©ç¶çé åç¥è­åéèº«æé çæºéç­ç¥ï¼LLM å¯ä»¥é¡¯èå¢å¼·è¨ºæ·ç¨åºãéäºç¼ç¾çªé¡¯äºæä½³åè¨ç·´ç¯ä¾æ¸éåæºéæ¹å¼çéè¦æ§ï¼ä»¥æé«æºç¢ºåº¦ä¸¦æ¸å° LLM æç¨ä¸­çåå·®ã

##### **To Trust or Not to Trust: Towards a novel approach to measure trust for XAI systems**
2405.05766v1 by Miquel MirÃ³-Nicolau, Gabriel MoyÃ -Alcover, Antoni Jaume-i-CapÃ³, Manuel GonzÃ¡lez-Hidalgo, Maria Gemma Sempere Campello, Juan Antonio Palmer Sancho

The increasing reliance on Deep Learning models, combined with their inherent
lack of transparency, has spurred the development of a novel field of study
known as eXplainable AI (XAI) methods. These methods seek to enhance the trust
of end-users in automated systems by providing insights into the rationale
behind their decisions. This paper presents a novel approach for measuring user
trust in XAI systems, allowing their refinement. Our proposed metric combines
both performance metrics and trust indicators from an objective perspective. To
validate this novel methodology, we conducted a case study in a realistic
medical scenario: the usage of XAI system for the detection of pneumonia from
x-ray images.

æè¦ï¼é¨èå°æ·±åº¦å­¸ç¿æ¨¡åä¾è³´æ§çå¢å ï¼å ä¸å¶åºæçéæåº¦ä¸è¶³ï¼ä¿ä½¿ä¸åæ°çç ç©¶é åç¼å±ï¼ç¨±çºå¯è§£é AI (XAI) æ¹æ³ãéäºæ¹æ³æ¨å¨ééæ·±å¥äºè§£æ±ºç­èå¾çåçï¼ä¾æåæçµä½¿ç¨èå°èªååç³»çµ±çä¿¡è³´ãæ¬ææåºäºä¸ç¨®è¡¡éä½¿ç¨èå° XAI ç³»çµ±ä¿¡è³´åº¦çæ°ç©æ¹æ³ï¼åè¨±å°å¶é²è¡æ¹é²ãæåæåºçææ¨çµåäºå®¢è§è§é»ä¸çæè½ææ¨åä¿¡è³´ææ¨ãçºäºé©è­éåæ°ç©çæ¹æ³ï¼æåå¨ä¸åçå¯¦çé«çå ´æ¯ä¸­é²è¡äºä¸åæ¡ä¾ç ç©¶ï¼ä½¿ç¨ XAI ç³»çµ±å¾ X åå½±åä¸­åµæ¸¬èºçã

##### **Region-specific Risk Quantification for Interpretable Prognosis of COVID-19**
2405.02815v1 by Zhusi Zhong, Jie Li, Zhuoqi Ma, Scott Collins, Harrison Bai, Paul Zhang, Terrance Healey, Xinbo Gao, Michael K. Atalay, Zhicheng Jiao

The COVID-19 pandemic has strained global public health, necessitating
accurate diagnosis and intervention to control disease spread and reduce
mortality rates. This paper introduces an interpretable deep survival
prediction model designed specifically for improved understanding and trust in
COVID-19 prognosis using chest X-ray (CXR) images. By integrating a large-scale
pretrained image encoder, Risk-specific Grad-CAM, and anatomical region
detection techniques, our approach produces regional interpretable outcomes
that effectively capture essential disease features while focusing on rare but
critical abnormal regions. Our model's predictive results provide enhanced
clarity and transparency through risk area localization, enabling clinicians to
make informed decisions regarding COVID-19 diagnosis with better understanding
of prognostic insights. We evaluate the proposed method on a multi-center
survival dataset and demonstrate its effectiveness via quantitative and
qualitative assessments, achieving superior C-indexes (0.764 and 0.727) and
time-dependent AUCs (0.799 and 0.691). These results suggest that our
explainable deep survival prediction model surpasses traditional survival
analysis methods in risk prediction, improving interpretability for clinical
decision making and enhancing AI system trustworthiness.

æè¦ï¼COVID-19 ç«æå°å¨çå¬å±è¡çé æå£åï¼å¿é é²è¡æºç¢ºçè¨ºæ·åå¹²é ï¼ä»¥æ§å¶ç¾çå³æ­ä¸¦éä½æ­»äº¡çãæ¬æä»ç´¹äºä¸åå¯è§£éçæ·±åº¦çå­é æ¸¬æ¨¡åï¼å°éè¨­è¨ç¨æ¼ééè¸é¨ X å (CXR) å½±åæ¹åå° COVID-19 é å¾ççè§£åä¿¡è³´ãééæ´åå¤§è¦æ¨¡é è¨ç·´å½±åç·¨ç¢¼å¨ãé¢¨éªç¹å® Grad-CAM åè§£ååååµæ¸¬æè¡ï¼æåçåæ³ç¢çååå¯è§£éççµæï¼ææææå¿è¦çç¾çç¹å¾µï¼åæå°æ³¨æ¼ç½è¦ä½ééµçç°å¸¸ååãæåçæ¨¡åé æ¸¬çµæééé¢¨éªååå®ä½æä¾å¢å¼·çæ¸æ°åº¦åéæåº¦ï¼è®è¨åºé«çè½å¤ å¨æ´äºè§£é å¾è¦è§£çææ³ä¸ï¼å°± COVID-19 è¨ºæ·ååºææºçæ±ºç­ãæåå¨å¤ä¸­å¿çå­è³æéä¸è©ä¼°ææåºçæ¹æ³ï¼ä¸¦éééååè³ªåè©ä¼°è­æå¶æææ§ï¼éå°åªç°ç C ææ¸ï¼0.764 å 0.727ï¼åæéç¸é AUCï¼0.799 å 0.691ï¼ãéäºçµæè¡¨æï¼æåå¯è§£éçæ·±åº¦çå­é æ¸¬æ¨¡åå¨é¢¨éªé æ¸¬æ¹é¢è¶è¶å³çµ±ççå­åææ¹æ³ï¼æåè¨åºæ±ºç­çè§£éæ§ï¼ä¸¦å¢å¼· AI ç³»çµ±çä¿¡è³´åº¦ã

##### **Rad4XCNN: a new agnostic method for post-hoc global explanation of CNN-derived features by means of radiomics**
2405.02334v1 by Francesco Prinzi, Carmelo Militello, Calogero Zarcaro, Tommaso Vincenzo Bartolotta, Salvatore Gaglio, Salvatore Vitabile

In the last years, artificial intelligence (AI) in clinical decision support
systems (CDSS) played a key role in harnessing machine learning and deep
learning architectures. Despite their promising capabilities, the lack of
transparency and explainability of AI models poses significant challenges,
particularly in medical contexts where reliability is a mandatory aspect.
Achieving transparency without compromising predictive accuracy remains a key
challenge. This paper presents a novel method, namely Rad4XCNN, to enhance the
predictive power of CNN-derived features with the interpretability inherent in
radiomic features. Rad4XCNN diverges from conventional methods based on
saliency map, by associating intelligible meaning to CNN-derived features by
means of Radiomics, offering new perspectives on explanation methods beyond
visualization maps. Using a breast cancer classification task as a case study,
we evaluated Rad4XCNN on ultrasound imaging datasets, including an online
dataset and two in-house datasets for internal and external validation. Some
key results are: i) CNN-derived features guarantee more robust accuracy when
compared against ViT-derived and radiomic features; ii) conventional
visualization map methods for explanation present several pitfalls; iii)
Rad4XCNN does not sacrifice model accuracy for their explainability; iv)
Rad4XCNN provides global explanation insights enabling the physician to analyze
the model outputs and findings. In addition, we highlight the importance of
integrating interpretability into AI models for enhanced trust and adoption in
clinical practice, emphasizing how our method can mitigate some concerns
related to explainable AI methods.

æè¦ï¼<paragraph>å¨éå»å¹¾å¹´ï¼è¨åºæ±ºç­æ¯æ´ç³»çµ± (CDSS) ä¸­çäººå·¥æºæ§ (AI) å¨å©ç¨æ©å¨å­¸ç¿åæ·±åº¦å­¸ç¿æ¶æ§æ¹é¢ç¼æ®äºééµä½ç¨ãåç®¡ AI æ¨¡åå·æä»¤äººæ»¿æçè½åï¼ä½ç¼ºä¹éæåº¦åå¯è§£éæ§ï¼ç¹å¥æ¯å¨å¯é æ§çºå¿è¦èéçé«çèæ¯ä¸ï¼éå¸¶ä¾äºéå¤§çææ°ãå¨ä¸å½±é¿é æ¸¬ç²¾æºåº¦çææ³ä¸å¯¦ç¾éæåº¦ä»ç¶æ¯ä¸é ééµææ°ãæ¬ææåºäºä¸ç¨®æ°æ¹æ³ï¼å³ Rad4XCNNï¼ä»¥å¢å¼· CNN è¡çç¹å¾µçé æ¸¬è½åï¼åæå·åæ¾å°ç¹å¾µåºæçå¯è§£éæ§ãRad4XCNN ä¸åæ¼åºæ¼é¡¯èæ§åçå³çµ±æ¹æ³ï¼å®ééæ¾å°çµå­¸å°å¯çè§£çå«ç¾©è CNN è¡çç¹å¾µéè¯èµ·ä¾ï¼çºè¶è¶è¦è¦ºååè¡¨çè§£éæ¹æ³æä¾äºæ°çè§é»ãæåä»¥ä¹³çåé¡ä»»åä½çºæ¡ä¾ç ç©¶ï¼å¨è¶é³æ³¢å½±åè³æéä¸è©ä¼° Rad4XCNNï¼åæ¬ä¸åç·ä¸è³æéåå©åç¨æ¼å§é¨åå¤é¨é©è­çå§é¨è³æéãä¸äºééµçµæå¦ä¸ï¼i) è ViT è¡çç¹å¾µåæ¾å°ç¹å¾µç¸æ¯ï¼CNN è¡çç¹å¾µä¿è­äºæ´ç©©å¥çæºç¢ºåº¦ï¼ii) å³çµ±çè¦è¦ºååè§£éæ¹æ³å­å¨ä¸äºç¼ºé·ï¼iii) Rad4XCNN æ²æç§ç²æ¨¡åæºç¢ºåº¦ä¾æåå¶å¯è§£éæ§ï¼iv) Rad4XCNN æä¾äºå¨å±è§£éè¦è§£ï¼ä½¿é«å¸«è½å¤ åææ¨¡åè¼¸åºåç¼ç¾ãæ­¤å¤ï¼æåå¼·èª¿å°å¯è§£éæ§æ´åå° AI æ¨¡åä¸­å°æ¼å¢å¼·è¨åºå¯¦åä¸­çä¿¡ä»»åæ¡ç¨è³ééè¦ï¼ä¸¦å¼·èª¿äºæåçæ¹æ³å¦ä½è½ç·©è§£èå¯è§£é AI æ¹æ³ç¸éçä¸äºçæ®ã</paragraph>

##### **Attributing Responsibility in AI-Induced Incidents: A Computational Reflective Equilibrium Framework for Accountability**
2404.16957v1 by Yunfei Ge, Quanyan Zhu

The pervasive integration of Artificial Intelligence (AI) has introduced
complex challenges in the responsibility and accountability in the event of
incidents involving AI-enabled systems. The interconnectivity of these systems,
ethical concerns of AI-induced incidents, coupled with uncertainties in AI
technology and the absence of corresponding regulations, have made traditional
responsibility attribution challenging. To this end, this work proposes a
Computational Reflective Equilibrium (CRE) approach to establish a coherent and
ethically acceptable responsibility attribution framework for all stakeholders.
The computational approach provides a structured analysis that overcomes the
limitations of conceptual approaches in dealing with dynamic and multifaceted
scenarios, showcasing the framework's explainability, coherence, and adaptivity
properties in the responsibility attribution process. We examine the pivotal
role of the initial activation level associated with claims in equilibrium
computation. Using an AI-assisted medical decision-support system as a case
study, we illustrate how different initializations lead to diverse
responsibility distributions. The framework offers valuable insights into
accountability in AI-induced incidents, facilitating the development of a
sustainable and resilient system through continuous monitoring, revision, and
reflection.

æè¦ï¼é¨èäººå·¥æºæ§ (AI) çæ®åæ´åï¼å¨æ¶å AI é©åç³»çµ±çäºæä¸­ï¼è²¬ä»»åç¾©åæ­¸å±¬ç¢çäºè¤éçææ°ãéäºç³»çµ±çäºé£æ§ãAI å¼ç¼äºæçå«çåé¡ï¼å ä¸ AI æè¡çä¸ç¢ºå®æ§åç¼ºä¹ç¸ææ³è¦ï¼ä½¿å¾å³çµ±è²¬ä»»æ­¸å±¬é¢è¨ææ°ãçºæ­¤ï¼æ¬ç ç©¶æåºäºä¸ç¨®è¨ç®åæåè¡¡ (CRE) æ¹æ³ï¼ä»¥å»ºç«ä¸åé£è²«ä¸å¨å«çä¸å¯æ¥åçè²¬ä»»æ­¸å±¬æ¶æ§ï¼é©ç¨æ¼ææå©å®³éä¿äººãè¨ç®æ¹æ³æä¾äºçµæ§åçåæï¼åæäºæ¦å¿µæ¹æ³å¨èçåæä¸å¤é¢åæå¢æçéå¶ï¼å±ç¤ºäºè©²æ¶æ§å¨è²¬ä»»æ­¸å±¬éç¨ä¸­å·åçå¯è§£éæ§ãé£è²«æ§åé©ææ§ãæåæ¢è¨äºèåè¡¡è¨ç®ä¸­ç´¢è³ ç¸éçåå§ååå±¤ç´çééµä½ç¨ãæåä»¥ AI è¼å©é«çæ±ºç­æ¯æ´ç³»çµ±çºæ¡ä¾ç ç©¶ï¼èªªæä¸åçåå§åå¦ä½å°è´ä¸åçè²¬ä»»åéãè©²æ¶æ§æä¾äºå° AI å¼ç¼äºæä¸­åè²¬å¶çå¯¶è²´è¦è§£ï¼ééæçºç£æ§ãä¿®è¨ååæï¼ä¿é²äºæ°¸çºä¸æéæ§çç³»çµ±ç¼å±ã

##### **Explainable AI for Fair Sepsis Mortality Predictive Model**
2404.13139v1 by Chia-Hsuan Chang, Xiaoyang Wang, Christopher C. Yang

Artificial intelligence supports healthcare professionals with predictive
modeling, greatly transforming clinical decision-making. This study addresses
the crucial need for fairness and explainability in AI applications within
healthcare to ensure equitable outcomes across diverse patient demographics. By
focusing on the predictive modeling of sepsis-related mortality, we propose a
method that learns a performance-optimized predictive model and then employs
the transfer learning process to produce a model with better fairness. Our
method also introduces a novel permutation-based feature importance algorithm
aiming at elucidating the contribution of each feature in enhancing fairness on
predictions. Unlike existing explainability methods concentrating on explaining
feature contribution to predictive performance, our proposed method uniquely
bridges the gap in understanding how each feature contributes to fairness. This
advancement is pivotal, given sepsis's significant mortality rate and its role
in one-third of hospital deaths. Our method not only aids in identifying and
mitigating biases within the predictive model but also fosters trust among
healthcare stakeholders by improving the transparency and fairness of model
predictions, thereby contributing to more equitable and trustworthy healthcare
delivery.

æè¦ï¼äººå·¥æºæ§ééé æ¸¬æ¨¡ååå©é«çå°æ¥­äººå¡ï¼å¤§å¹è½è®äºè¨åºæ±ºç­å¶å®ãæ¬ç ç©¶æ¢è¨äºå¨é«çä¿å¥ä¸­ä½¿ç¨äººå·¥æºæ§æç¨ç¨å¼æå¬å¹³æ§åå¯è§£éæ§çééµéæ±ï¼ä»¥ç¢ºä¿å¨ä¸åçæ£èäººå£çµ±è¨è³æä¸­ç²å¾å¬å¹³ççµæãééå°æ³¨æ¼æè¡çç¸éæ­»äº¡ççé æ¸¬æ¨¡åï¼æåæåºäºä¸ç¨®æ¹æ³ï¼è©²æ¹æ³æå­¸ç¿ä¸åæè½æä½³åçé æ¸¬æ¨¡åï¼ç¶å¾æ¡ç¨è½ç§»å­¸ç¿éç¨ä¾ç¢çä¸åå·ææ´å¥½å¬å¹³æ§çæ¨¡åãæåçæ¨¡åéå¼å¥äºä¸ç¨®æ°ç©çåºæ¼æåçç¹å¾µéè¦æ§æ¼ç®æ³ï¼æ¨å¨é¡ææ¯åç¹å¾µå¨å¢å¼·é æ¸¬å¬å¹³æ§æ¹é¢çè²¢ç»ãèç¾æçå¯è§£éæ§æ¹æ³å°æ³¨æ¼è§£éç¹å¾µå°é æ¸¬æè½çè²¢ç»ä¸åï¼æåæåºçæ¹æ³ç¨ç¹å°å½è£äºçè§£æ¯åç¹å¾µå¦ä½æå©æ¼å¬å¹³æ§çå·®è·ãéé é²å±è³ééè¦ï¼å çºæè¡ççæ­»äº¡çå¾é«ï¼ä¸å¨ä¸åä¹ä¸çé«é¢æ­»äº¡ä¸­æ®æ¼èè§è²ãæåçæ¨¡åä¸åæå©æ¼è­å¥åæ¸è¼é æ¸¬æ¨¡åä¸­çåå·®ï¼éè½ééæé«æ¨¡åé æ¸¬çéæåº¦åå¬å¹³æ§ä¾å¹é¤é«çä¿å¥å©çç¸éèä¹éçä¿¡ä»»ï¼é²èæå©æ¼æä¾æ´å¬å¹³ä¸å¼å¾ä¿¡è³´çé«çä¿å¥æåã

##### **Multi Class Depression Detection Through Tweets using Artificial Intelligence**
2404.13104v1 by Muhammad Osama Nusrat, Waseem Shahzad, Saad Ahmed Jamal

Depression is a significant issue nowadays. As per the World Health
Organization (WHO), in 2023, over 280 million individuals are grappling with
depression. This is a huge number; if not taken seriously, these numbers will
increase rapidly. About 4.89 billion individuals are social media users. People
express their feelings and emotions on platforms like Twitter, Facebook,
Reddit, Instagram, etc. These platforms contain valuable information which can
be used for research purposes. Considerable research has been conducted across
various social media platforms. However, certain limitations persist in these
endeavors. Particularly, previous studies were only focused on detecting
depression and the intensity of depression in tweets. Also, there existed
inaccuracies in dataset labeling. In this research work, five types of
depression (Bipolar, major, psychotic, atypical, and postpartum) were predicted
using tweets from the Twitter database based on lexicon labeling. Explainable
AI was used to provide reasoning by highlighting the parts of tweets that
represent type of depression. Bidirectional Encoder Representations from
Transformers (BERT) was used for feature extraction and training. Machine
learning and deep learning methodologies were used to train the model. The BERT
model presented the most promising results, achieving an overall accuracy of
0.96.

æè¦ï¼ç¾ä»ï¼æé¬±çæ¯ä¸åéè¦çè­°é¡ãæ ¹æä¸çè¡ççµç¹ (WHO) çè³æï¼å¨ 2023 å¹´ï¼è¶é 2.8 åäººæ­£å¨èæé¬±çæé¬¥ãéæ¯ä¸åé¾å¤§çæ¸å­ï¼å¦æä¸èªççå¾ï¼éäºæ¸å­å°æå¿«éå¢å ãå¤§ç´æ 48.9 åäººæ¯ç¤¾ç¾¤åªé«ä½¿ç¨èãäººåå¨ TwitterãFacebookãRedditãInstagram ç­å¹³å°ä¸è¡¨éèªå·±çæååæç·ãéäºå¹³å°åå«æå¹å¼çè³è¨ï¼å¯ç¨æ¼ç ç©¶ç®çãå·²ç¶å¨åç¨®ç¤¾ç¾¤åªé«å¹³å°ä¸é²è¡äºå¤§éçç ç©¶ãç¶èï¼éäºåªåä»å­å¨æäºéå¶ãç¹å¥æ¯ï¼ååçç ç©¶åå°æ³¨æ¼åµæ¸¬æ¨æä¸­çæé¬±çåæé¬±ççå¼·åº¦ãæ­¤å¤ï¼è³æéæ¨ç±¤ä¸­å­å¨ä¸æºç¢ºçææ³ãå¨éé ç ç©¶å·¥ä½ä¸­ï¼ä½¿ç¨åºæ¼è©å½æ¨ç±¤ç Twitter è³æåº«ä¸­çæ¨æé æ¸¬äºäºç¨®é¡åçæé¬±çï¼éæ¥µåãéåº¦ãç²¾ç¥çåãéå¸ååç¢å¾ï¼ãå¯è§£éç AI ç¨æ¼ééå¼·èª¿ä»£è¡¨æé¬±çé¡åçæ¨æé¨åä¾æä¾æ¨çãå¾ Transformersï¼BERTï¼ä¸­æåçéåç·¨ç¢¼å¨è¡¨ç¤ºç¨æ¼ç¹å¾µæååè¨ç·´ãæ©å¨å­¸ç¿åæ·±åº¦å­¸ç¿æ¹æ³ç¨æ¼è¨ç·´æ¨¡åãBERT æ¨¡ååç¾åºææå¸æççµæï¼éå° 0.96 çæ´é«æºç¢ºåº¦ã

##### **COIN: Counterfactual inpainting for weakly supervised semantic segmentation for medical images**
2404.12832v2 by Dmytro Shvetsov, Joonas Ariva, Marharyta Domnich, Raul Vicente, Dmytro Fishman

Deep learning is dramatically transforming the field of medical imaging and
radiology, enabling the identification of pathologies in medical images,
including computed tomography (CT) and X-ray scans. However, the performance of
deep learning models, particularly in segmentation tasks, is often limited by
the need for extensive annotated datasets. To address this challenge, the
capabilities of weakly supervised semantic segmentation are explored through
the lens of Explainable AI and the generation of counterfactual explanations.
The scope of this research is development of a novel counterfactual inpainting
approach (COIN) that flips the predicted classification label from abnormal to
normal by using a generative model. For instance, if the classifier deems an
input medical image X as abnormal, indicating the presence of a pathology, the
generative model aims to inpaint the abnormal region, thus reversing the
classifier's original prediction label. The approach enables us to produce
precise segmentations for pathologies without depending on pre-existing
segmentation masks. Crucially, image-level labels are utilized, which are
substantially easier to acquire than creating detailed segmentation masks. The
effectiveness of the method is demonstrated by segmenting synthetic targets and
actual kidney tumors from CT images acquired from Tartu University Hospital in
Estonia. The findings indicate that COIN greatly surpasses established
attribution methods, such as RISE, ScoreCAM, and LayerCAM, as well as an
alternative counterfactual explanation method introduced by Singla et al. This
evidence suggests that COIN is a promising approach for semantic segmentation
of tumors in CT images, and presents a step forward in making deep learning
applications more accessible and effective in healthcare, where annotated data
is scarce.

æè¦ï¼æ·±åº¦å­¦ä¹ æ­£å¤§å¹è½è®é«å­¸å½±ååæ¾å°ç·å­¸é åï¼è½è¾¨è­é«å­¸å½±åä¸­çççï¼åæ¬é»è¦æ·å±¤ææ (CT) å X åææãç¶èï¼æ·±åº¦å­¸ç¿æ¨¡åçæè½ï¼ç¹å¥æ¯å¨åå²ä»»åä¸­ï¼å¸¸å¸¸åå°å»£æ³è¨»è§£è³æééæ±çéå¶ãçºäºæå°æ­¤ææ°ï¼ééå¯è§£é AI ååäºå¯¦è§£éçç¢çï¼æ¢ç´¢å¼±ç£ç£èªæåå²çè½åãæ¬ç ç©¶çç¯åæ¯éç¼ä¸ç¨®æ°çåäºå¯¦å§ææ¹æ³ (COIN)ï¼è©²æ¹æ³ä½¿ç¨çææ¨¡åå°é æ¸¬çåé¡æ¨ç±¤å¾ç°å¸¸ç¿»è½çºæ­£å¸¸ãä¾å¦ï¼å¦æåé¡å¨å°è¼¸å¥çé«å­¸å½±å X è¦çºç°å¸¸ï¼è¡¨ç¤ºå­å¨ççï¼åçææ¨¡åæ¨å¨å§æç°å¸¸ååï¼å¾èéè½åé¡å¨çåå§é æ¸¬æ¨ç±¤ãæ­¤æ¹æ³ä½¿æåè½å¤ ç¢ççççç²¾ç¢ºåå²ï¼èç¡éä¾è³´æ¼é åå­å¨çåå²é®ç½©ãè³ééè¦çæ¯ï¼å©ç¨å½±åå±¤ç´æ¨ç±¤ï¼éæ¯å»ºç«è©³ç´°çåå²é®ç½©å®¹æåå¾ãè©²æ¹æ³çæææ§ééåå²åæç®æ¨åå¾ææ²å°¼äºå¡ç¾åå¤§å­¸é«é¢åå¾ç CT å½±åä¸­çå¯¦éèèè«ç¤ä¾è­æãç ç©¶çµæè¡¨æï¼COIN é é è¶éå·²å»ºç«çæ­¸å æ¹æ³ï¼ä¾å¦ RISEãScoreCAM å LayerCAMï¼ä»¥å Singla ç­äººæåºçå¦ä¸ç¨®åäºå¯¦è§£éæ¹æ³ãæ­¤è­æè¡¨æï¼COIN æ¯ä¸ç¨®å¾æåéç CT å½±åä¸­è«ç¤èªæåå²æ¹æ³ï¼ä¸¦å¨é«çä¿å¥ä¸­è®æ·±åº¦å­¸ç¿æç¨æ´ææ¼åå¾åæ´ææçéé²ä¸æ­¥ï¼å¶ä¸­è¨»è§£è³æå¾ç¨å°ã

##### **Hybrid Intelligence for Digital Humanities**
2406.15374v1 by Victor de Boer, Lise Stork

In this paper, we explore the synergies between Digital Humanities (DH) as a
discipline and Hybrid Intelligence (HI) as a research paradigm. In DH research,
the use of digital methods and specifically that of Artificial Intelligence is
subject to a set of requirements and constraints. We argue that these are
well-supported by the capabilities and goals of HI. Our contribution includes
the identification of five such DH requirements: Successful AI systems need to
be able to 1) collaborate with the (human) scholar; 2) support data criticism;
3) support tool criticism; 4) be aware of and cater to various perspectives and
5) support distant and close reading. We take the CARE principles of Hybrid
Intelligence (collaborative, adaptive, responsible and explainable) as
theoretical framework and map these to the DH requirements. In this mapping, we
include example research projects. We finally address how insights from DH can
be applied to HI and discuss open challenges for the combination of the two
disciplines.

æè¦ï¼å¨æ¬æä¸­ï¼æåæ¢è¨æ¸ä½äººæå­¸ç§ (DH) ä½çºä¸éå­¸ç§èæ··åæºè½ (HI) ä½çºä¸åç ç©¶å¸ç¯ä¹éçååä½ç¨ãå¨ DH ç ç©¶ä¸­ï¼æ¸ä½æ¹æ³çä½¿ç¨ï¼ç¹å¥æ¯äººå·¥æºæ§çä½¿ç¨ï¼åå°ä¸ç³»åè¦æ±åéå¶ãæåèªçºéäºè¦æ±åéå¶ç²å¾ HI çè½ååç®æ¨çååæ¯æãæåçè²¢ç»åæ¬æ¾åºäºåéæ¨£ç DH è¦æ±ï¼æåç AI ç³»çµ±éè¦è½å¤  1) èï¼äººé¡ï¼å­¸èåä½ï¼2) æ¯æ´è³ææ¹è©ï¼3) æ¯æ´å·¥å·æ¹è©ï¼4) å¯è¦ºä¸¦è¿ååç¨®è§é»ï¼5) æ¯æ´é è·åè¿è·é¢é±è®ãæåå°æ··åæºè½ç CARE ååï¼åä½ãé©æãè² è²¬åå¯è§£éï¼ä½çºçè«æ¶æ§ï¼ä¸¦å°éäºååå°æå° DH è¦æ±ãå¨æ­¤å°æä¸­ï¼æåç´å¥ç¯ä¾ç ç©¶å°æ¡ãæå¾ï¼æåæ¢è¨å¦ä½å° DH çè¦è§£æç¨æ¼ HIï¼ä¸¦è¨è«çµåéå©åå­¸ç§çéæ¾ææ°ã

##### **Ethical Framework for Responsible Foundational Models in Medical Imaging**
2406.11868v1 by Abhijit Das, Debesh Jha, Jasmer Sanjotra, Onkar Susladkar, Suramyaa Sarkar, Ashish Rauniyar, Nikhil Tomar, Vanshali Sharma, Ulas Bagci

Foundational models (FMs) have tremendous potential to revolutionize medical
imaging. However, their deployment in real-world clinical settings demands
extensive ethical considerations. This paper aims to highlight the ethical
concerns related to FMs and propose a framework to guide their responsible
development and implementation within medicine. We meticulously examine ethical
issues such as privacy of patient data, bias mitigation, algorithmic
transparency, explainability and accountability. The proposed framework is
designed to prioritize patient welfare, mitigate potential risks, and foster
trust in AI-assisted healthcare.

æè¦ï¼åºç¤æ¨¡å (FM) å·æå¾¹åºæ¹è®é«å­¸å½±åçå·¨å¤§æ½åãç¶èï¼å®åå¨ç¾å¯¦ä¸çè¨åºç°å¢ä¸­çé¨ç½²éè¦å»£æ³çå«çèéãæ¬ææ¨å¨å¼·èª¿è FM ç¸éçå«çåé¡ï¼ä¸¦æåºä¸åæ¡æ¶ä¾æå°å®åå¨é«å­¸ä¸­çè² è²¬ä»»éç¼åå¯¦æ½ãæåä»ç´°å¯©æ¥äºå«çåé¡ï¼ä¾å¦æ£èæ¸æé±ç§ãåå·®ç·©è§£ãæ¼ç®æ³éæåº¦ãå¯è§£éæ§ååè²¬å¶ãææåºçæ¡æ¶æ¨å¨åªåèæ®æ£èç¦å©ãæ¸è¼æ½å¨é¢¨éªï¼ä¸¦å¹é¤å° AI è¼å©é«çä¿å¥çä¿¡ä»»ã

##### **Advancements in Radiomics and Artificial Intelligence for Thyroid Cancer Diagnosis**
2404.07239v1 by Milad Yousefi, Shadi Farabi Maleki, Ali Jafarizadeh, Mahya Ahmadpour Youshanlui, Aida Jafari, Siamak Pedrammehr, Roohallah Alizadehsani, Ryszard Tadeusiewicz, Pawel Plawiak

Thyroid cancer is an increasing global health concern that requires advanced
diagnostic methods. The application of AI and radiomics to thyroid cancer
diagnosis is examined in this review. A review of multiple databases was
conducted in compliance with PRISMA guidelines until October 2023. A
combination of keywords led to the discovery of an English academic publication
on thyroid cancer and related subjects. 267 papers were returned from the
original search after 109 duplicates were removed. Relevant studies were
selected according to predetermined criteria after 124 articles were eliminated
based on an examination of their abstract and title. After the comprehensive
analysis, an additional six studies were excluded. Among the 28 included
studies, radiomics analysis, which incorporates ultrasound (US) images,
demonstrated its effectiveness in diagnosing thyroid cancer. Various results
were noted, some of the studies presenting new strategies that outperformed the
status quo. The literature has emphasized various challenges faced by AI
models, including interpretability issues, dataset constraints, and operator
dependence. The synthesized findings of the 28 included studies mentioned the
need for standardization efforts and prospective multicenter studies to address
these concerns. Furthermore, approaches to overcome these obstacles were
identified, such as advances in explainable AI technology and personalized
medicine techniques. The review focuses on how AI and radiomics could transform
the diagnosis and treatment of thyroid cancer. Despite challenges, future
research on multidisciplinary cooperation, clinical applicability validation,
and algorithm improvement holds the potential to improve patient outcomes and
diagnostic precision in the treatment of thyroid cancer.

æè¦ï¼ç²çèºçæ¯ä¸ç¨®æ¥çå´éçå¨çå¥åº·åé¡ï¼éè¦åé²çè¨ºæ·æ¹æ³ãæ¬ç¯è©è«æ¢è¨äºäººå·¥æºè½èæ¾å°ç¹å¾µåæå¨ç²çèºçè¨ºæ·ä¸­çæç¨ãå¨ç¬¦å PRISMA æåçææ³ä¸ï¼å°å¤åè³æåº«é²è¡äºåé¡§ï¼ç´å° 2023 å¹´ 10 æãééçµåééµå­ï¼ç¼ç¾äºä¸ç¯éæ¼ç²çèºçåç¸éä¸»é¡çè±æå­¸è¡åºçç©ãå¨ç§»é¤ 109 ç¯éè¤æç»å¾ï¼åå§æå°å±åå³ 267 ç¯è«æãå¨æ ¹æé åç¢ºå®çæ¨æºï¼æ·æ±°äº 124 ç¯æç« çæè¦åæ¨é¡å¾ï¼é¸åºäºç¸éç ç©¶ãå¨é²è¡å¨é¢åæå¾ï¼é¡å¤æé¤äºå­é ç ç©¶ãå¨ç´å¥ç 28 é ç ç©¶ä¸­ï¼çµåè¶é³æ³¢ (US) å½±åçæ¾å°ç¹å¾µåæï¼è­æäºå¶å¨è¨ºæ·ç²çèºçæ¹é¢çæææ§ãç ç©¶çµæä¸ä¸ï¼æäºç ç©¶æåºäºåªæ¼ç¾ççæ°ç­ç¥ãæç»å¼·èª¿äºäººå·¥æºè½æ¨¡åé¢è¨çåç¨®ææ°ï¼åæ¬å¯è§£éæ§åé¡ãè³æééå¶åæä½å¡ä¾è³´æ§ã28 é ç´å¥ç ç©¶çç¶åç¼ç¾æå°ï¼éè¦æ¨æºåå·¥ä½ååç»æ§å¤ä¸­å¿ç ç©¶ä¾è§£æ±ºéäºåé¡ãæ­¤å¤ï¼éç¢ºå®äºåæéäºéç¤çæ¹æ³ï¼ä¾å¦å¯è§£éäººå·¥æºè½æè¡ååäººåé«çæè¡çé²æ­¥ãæ¬ç¯è©è«éé»æ¢è¨äºäººå·¥æºè½åæ¾å°ç¹å¾µåæå¦ä½è½è®ç²çèºççè¨ºæ·åæ²»çãåç®¡å­å¨ææ°ï¼ä½æªä¾å°å¤å­¸ç§åä½ãè¨åºé©ç¨æ§é©è­åæ¼ç®æ³æ¹é²çç ç©¶ï¼ä»ææ½åæ¹åç²çèºçæ²»çä¸­çæ£èé å¾åè¨ºæ·ç²¾æºåº¦ã

##### **Predictive Modeling for Breast Cancer Classification in the Context of Bangladeshi Patients: A Supervised Machine Learning Approach with Explainable AI**
2404.04686v1 by Taminul Islam, Md. Alif Sheakh, Mst. Sazia Tahosin, Most. Hasna Hena, Shopnil Akash, Yousef A. Bin Jardan, Gezahign Fentahun Wondmie, Hiba-Allah Nafidi, Mohammed Bourhia

Breast cancer has rapidly increased in prevalence in recent years, making it
one of the leading causes of mortality worldwide. Among all cancers, it is by
far the most common. Diagnosing this illness manually requires significant time
and expertise. Since detecting breast cancer is a time-consuming process,
preventing its further spread can be aided by creating machine-based forecasts.
Machine learning and Explainable AI are crucial in classification as they not
only provide accurate predictions but also offer insights into how the model
arrives at its decisions, aiding in the understanding and trustworthiness of
the classification results. In this study, we evaluate and compare the
classification accuracy, precision, recall, and F-1 scores of five different
machine learning methods using a primary dataset (500 patients from Dhaka
Medical College Hospital). Five different supervised machine learning
techniques, including decision tree, random forest, logistic regression, naive
bayes, and XGBoost, have been used to achieve optimal results on our dataset.
Additionally, this study applied SHAP analysis to the XGBoost model to
interpret the model's predictions and understand the impact of each feature on
the model's output. We compared the accuracy with which several algorithms
classified the data, as well as contrasted with other literature in this field.
After final evaluation, this study found that XGBoost achieved the best model
accuracy, which is 97%.

æè¦ï¼<paragraph>è¿å¹´ä¾ï¼ä¹³çççè¡çè¿éå¢å ï¼ä½¿å¶æçºå¨çä¸»è¦çæ­»äº¡åå ä¹ä¸ãå¨ææççä¸­ï¼ä¹³çè¿ä»çºæ­¢æ¯æå¸¸è¦çãæåè¨ºæ·æ­¤ç¾çéè¦å¤§éçæéåå°æ¥­ç¥è­ãç±æ¼ä¹³ççæª¢æ¸¬éç¨èæï¼å æ­¤ééå»ºç«æ©å¨å­¸ç¿æ¨¡åä¾é æ¸¬ï¼æå©æ¼é²æ­¢å¶é²ä¸æ­¥æ´æ£ãæ©å¨å­¸ç¿åå¯è§£é AI å¨åé¡ä¸­è³ééè¦ï¼å çºå®åä¸åå¯ä»¥æä¾æºç¢ºçé æ¸¬ï¼éå¯ä»¥æ·±å¥äºè§£æ¨¡åå¦ä½ååºæ±ºç­ï¼æå©æ¼çè§£åä¿¡è³´åé¡çµæãå¨æ­¤ç ç©¶ä¸­ï¼æåè©ä¼°ä¸¦æ¯è¼äºäºç¨®ä¸åçæ©å¨å­¸ç¿æ¹æ³çåé¡æºç¢ºåº¦ãç²¾ç¢ºåº¦ãå¬åçå F1 åæ¸ï¼ä½¿ç¨äºä¸åä¸»è¦çè³æéï¼éå¡é«å­¸é¢é«é¢ç 500 åæ£èï¼ãäºç¨®ä¸åçç£ç£å¼æ©å¨å­¸ç¿æè¡ï¼åæ¬æ±ºç­æ¨¹ãé¨æ©æ£®æãéè¼¯è¿´æ­¸ãæ´ç´ è²æ°å XGBoostï¼å·²ç¨æ¼å¨æåçè³æéä¸åå¾æä½³çµæãæ­¤å¤ï¼æ¬ç ç©¶å° SHAP åææç¨æ¼ XGBoost æ¨¡åï¼ä»¥è§£éæ¨¡åçé æ¸¬ä¸¦äºè§£æ¯åç¹å¾µå°æ¨¡åè¼¸åºçå½±é¿ãæåæ¯è¼äºå¹¾ç¨®æ¼ç®æ³å°è³æé²è¡åé¡çæºç¢ºåº¦ï¼ä¸¦èè©²é åçå¶ä»æç»é²è¡å°æ¯ãå¨æå¾è©ä¼°å¾ï¼æ¬ç ç©¶ç¼ç¾ XGBoost éå°äºæä½³çæ¨¡åæºç¢ºåº¦ï¼çº 97%ã</paragraph>

##### **Enhancing Breast Cancer Diagnosis in Mammography: Evaluation and Integration of Convolutional Neural Networks and Explainable AI**
2404.03892v3 by Maryam Ahmed, Tooba Bibi, Rizwan Ahmed Khan, Sidra Nasir

The Deep learning (DL) models for diagnosing breast cancer from mammographic
images often operate as "black boxes", making it difficult for healthcare
professionals to trust and understand their decision-making processes. The
study presents an integrated framework combining Convolutional Neural Networks
(CNNs) and Explainable Artificial Intelligence (XAI) for the enhanced diagnosis
of breast cancer using the CBIS-DDSM dataset. The methodology encompasses an
elaborate data preprocessing pipeline and advanced data augmentation techniques
to counteract dataset limitations and transfer learning using pre-trained
networks such as VGG-16, Inception-V3 and ResNet was employed. A focal point of
our study is the evaluation of XAI's effectiveness in interpreting model
predictions, highlighted by utilizing the Hausdorff measure to assess the
alignment between AI-generated explanations and expert annotations
quantitatively. This approach is critical for XAI in promoting trustworthiness
and ethical fairness in AI-assisted diagnostics. The findings from our research
illustrate the effective collaboration between CNNs and XAI in advancing
diagnostic methods for breast cancer, thereby facilitating a more seamless
integration of advanced AI technologies within clinical settings. By enhancing
the interpretability of AI driven decisions, this work lays the groundwork for
improved collaboration between AI systems and medical practitioners, ultimately
enriching patient care. Furthermore, the implications of our research extended
well beyond the current methodologies. It encourages further research into how
to combine multimodal data and improve AI explanations to meet the needs of
clinical practice.

æè¦ï¼æ·±åº¦å­¸ç¿ (DL) ç¨æ¼å¾ä¹³æ¿æå½±è¡å½±åè¨ºæ·ä¹³ççæ¨¡åéå¸¸ä»¥ãé»çå­ãæ¹å¼éä½ï¼éä½¿å¾é«çä¿å¥å°æ¥­äººå¡é£ä»¥ä¿¡ä»»åçè§£å¶æ±ºç­éç¨ãæ¬ç ç©¶æåºä¸åæ´åæ¶æ§ï¼çµåå·ç©ç¥ç¶ç¶²è·¯ (CNN) åå¯è§£éäººå·¥æºæ§ (XAI)ï¼ä»¥ä½¿ç¨ CBIS-DDSM è³æéå¢å¼·ä¹³ççè¨ºæ·ãæ¹æ³åå«ä¸åç²¾ç´°çè³æåèçç®¡ç·åé²éè³ææ´åæè¡ï¼ä»¥å°æè³æééå¶ï¼ä¸¦æ¡ç¨é åè¨ç·´çç¶²è·¯ï¼ä¾å¦ VGG-16ãInception-V3 å ResNetï¼é²è¡é·ç§»å­¸ç¿ãæåç ç©¶çéé»æ¯è©ä¼° XAI å¨è§£éæ¨¡åé æ¸¬ä¸­çæææ§ï¼éé»å©ç¨è±ªæ¯å¤å¤«æ¸¬åº¦éåè©ä¼° AI çæçè§£éåå°å®¶è¨»è§£ä¹éçä¸è´æ§ãéç¨®æ¹æ³å°æ¼ XAI å¨ä¿é² AI è¼å©è¨ºæ·ä¸­çå¯ä¿¡åº¦åå«çå¬å¹³æ§è³ééè¦ãæåç ç©¶çç¼ç¾èªªæäº CNN å XAI å¨æ¨é²ä¹³çè¨ºæ·æ¹æ³ä¸­çææåä½ï¼å¾èä¿é²äºåé² AI æè¡å¨è¨åºç°å¢ä¸­çæ´é æ¢æ´åãééå¢å¼· AI é©åæ±ºç­çå¯è§£éæ§ï¼éé å·¥ä½çº AI ç³»çµ±åé«çå¾æ¥­äººå¡ä¹éçæ¹ååä½å¥ å®äºåºç¤ï¼æçµè±å¯äºæ£èç§è­·ãæ­¤å¤ï¼æåç ç©¶çå½±é¿é é è¶åºäºç®åçæè¡ãå®é¼åµé²ä¸æ­¥ç ç©¶å¦ä½çµåå¤æ¨¡å¼è³æä¸¦æ¹å AI è§£éï¼ä»¥æ»¿è¶³è¨åºå¯¦åçéæ±ã

##### **Advancing Multimodal Data Fusion in Pain Recognition: A Strategy Leveraging Statistical Correlation and Human-Centered Perspectives**
2404.00320v2 by Xingrui Gu, Zhixuan Wang, Irisa Jin, Zekun Wu

This research presents a novel multimodal data fusion methodology for pain
behavior recognition, integrating statistical correlation analysis with
human-centered insights. Our approach introduces two key innovations: 1)
integrating data-driven statistical relevance weights into the fusion strategy
to effectively utilize complementary information from heterogeneous modalities,
and 2) incorporating human-centric movement characteristics into multimodal
representation learning for detailed modeling of pain behaviors. Validated
across various deep learning architectures, our method demonstrates superior
performance and broad applicability. We propose a customizable framework that
aligns each modality with a suitable classifier based on statistical
significance, advancing personalized and effective multimodal fusion.
Furthermore, our methodology provides explainable analysis of multimodal data,
contributing to interpretable and explainable AI in healthcare. By highlighting
the importance of data diversity and modality-specific representations, we
enhance traditional fusion techniques and set new standards for recognizing
complex pain behaviors. Our findings have significant implications for
promoting patient-centered healthcare interventions and supporting explainable
clinical decision-making.

æè¦ï¼æ¬ç ç©¶æåºäºä¸ç¨®åµæ°çå¤æ¨¡ææ¸æèåæ¹æ³ï¼ç¨æ¼ç¼çè¡çºè­å¥ï¼å°çµ±è¨ç¸éåæèä»¥äººçºä¸­å¿çè¦è§£ç¸çµåãæåçåæ³å¼å¥äºå©é ééµåµæ°ï¼1) å°æ¸æé©åççµ±è¨ç¸éæ¬éæ´åå°èåç­ç¥ä¸­ï¼ä»¥ææå©ç¨ä¾èªç°è³ªæ¨¡æçè£åä¿¡æ¯ï¼ä»¥å 2) å°ä»¥äººçºä¸­å¿çéåç¹å¾µç´å¥å¤æ¨¡æè¡¨ç¤ºå­¸ç¿ä¸­ï¼ä»¥è©³ç´°å»ºæ¨¡ç¼çè¡çºãæåçæ¨¡åå¨åç¨®æ·±åº¦å­¸ç¿æ¶æ§ä¸­å¾å°é©è­ï¼å±ç¤ºäºåè¶çæ§è½åå»£æ³çé©ç¨æ§ãæåæåºäºä¸åå¯èªå®ç¾©çæ¡æ¶ï¼æ ¹æçµ±è¨é¡¯èæ§å°æ¯åæ¨¡æèåé©çåé¡å¨å°é½ï¼æ¨é²åæ§ååææçå¤æ¨¡æèåãæ­¤å¤ï¼æåçæ¨¡åæä¾å°å¤æ¨¡ææ¸æçå¯è§£éåæï¼æå©æ¼é«çä¿å¥ä¸­çå¯è§£éåå¯è§£é AIãééå¼·èª¿æ¸æå¤æ¨£æ§åæ¨¡æç¹å®è¡¨ç¤ºçéè¦æ§ï¼æåå¢å¼·äºå³çµ±çèåæè¡ï¼ä¸¦çºè­å¥è¤éçç¼çè¡çºè¨­å®äºæ°çæ¨æºãæåçç¼ç¾å°ä¿é²ä»¥æ£èçºä¸­å¿çé«çä¿å¥å¹²é åæ¯æå¯è§£éçè¨åºæ±ºç­å¶å®å·æéè¦æç¾©ã

##### **Addressing Social Misattributions of Large Language Models: An HCXAI-based Approach**
2403.17873v1 by Andrea Ferrario, Alberto Termine, Alessandro Facchini

Human-centered explainable AI (HCXAI) advocates for the integration of social
aspects into AI explanations. Central to the HCXAI discourse is the Social
Transparency (ST) framework, which aims to make the socio-organizational
context of AI systems accessible to their users. In this work, we suggest
extending the ST framework to address the risks of social misattributions in
Large Language Models (LLMs), particularly in sensitive areas like mental
health. In fact LLMs, which are remarkably capable of simulating roles and
personas, may lead to mismatches between designers' intentions and users'
perceptions of social attributes, risking to promote emotional manipulation and
dangerous behaviors, cases of epistemic injustice, and unwarranted trust. To
address these issues, we propose enhancing the ST framework with a fifth
'W-question' to clarify the specific social attributions assigned to LLMs by
its designers and users. This addition aims to bridge the gap between LLM
capabilities and user perceptions, promoting the ethically responsible
development and use of LLM-based technology.

æè¦ï¼ä»¥äººä¸ºæ¬çå¯è§£é AI (HCXAI) å¡å¯¼å°ç¤¾ä¼å±é¢æ´åå° AI è§£éä¸­ãHCXAI è¯è¯­çæ ¸å¿æ¯ç¤¾ä¼éæåº¦ (ST) æ¡æ¶ï¼å¶ç®æ æ¯è®© AI ç³»ç»çç¤¾ä¼ç»ç»èæ¯å¯¹ç¨æ·æ¥è¯´æ¯å¯çè§£çãå¨è¿é¡¹å·¥ä½ä¸­ï¼æä»¬å»ºè®®æ©å± ST æ¡æ¶ä»¥è§£å³å¤§åè¯­è¨æ¨¡å (LLM) ä¸­ç¤¾ä¼éè¯¯å½å çé£é©ï¼å°¤å¶æ¯å¨å¿çå¥åº·ç­ææé¢åãäºå®ä¸ï¼LLM è½å¤åºè²å°æ¨¡æè§è²åäººæ ¼ï¼è¿å¯è½å¯¼è´è®¾è®¡èçæå¾åç¨æ·å¯¹ç¤¾ä¼å±æ§çè®¤ç¥ä¹é´åºç°ééï¼ä»èæé£é©ä¿è¿æç»ªæçºµåå±é©è¡ä¸ºãè®¤ç¥ä¸å¬æ­£åä¸åççä¿¡ä»»ãä¸ºäºè§£å³è¿äºé®é¢ï¼æä»¬å»ºè®®ç¨ç¬¬äºä¸ªâW é®é¢âæ¥å¢å¼º ST æ¡æ¶ï¼ä»¥æç¡®è®¾è®¡èåç¨æ·èµäº LLM çå·ä½ç¤¾ä¼å±æ§ãæ­¤è¡¥åæ¨å¨å¼¥å LLM è½ååç¨æ·è®¤ç¥ä¹é´çå·®è·ï¼ä¿è¿åºäº LLM çææ¯å¨éå¾·ä¸è´è´£ä»»å°å¼ååä½¿ç¨ã

##### **Clinical Domain Knowledge-Derived Template Improves Post Hoc AI Explanations in Pneumothorax Classification**
2403.18871v1 by Han Yuan, Chuan Hong, Pengtao Jiang, Gangming Zhao, Nguyen Tuan Anh Tran, Xinxing Xu, Yet Yen Yan, Nan Liu

Background: Pneumothorax is an acute thoracic disease caused by abnormal air
collection between the lungs and chest wall. To address the opaqueness often
associated with deep learning (DL) models, explainable artificial intelligence
(XAI) methods have been introduced to outline regions related to pneumothorax
diagnoses made by DL models. However, these explanations sometimes diverge from
actual lesion areas, highlighting the need for further improvement. Method: We
propose a template-guided approach to incorporate the clinical knowledge of
pneumothorax into model explanations generated by XAI methods, thereby
enhancing the quality of these explanations. Utilizing one lesion delineation
created by radiologists, our approach first generates a template that
represents potential areas of pneumothorax occurrence. This template is then
superimposed on model explanations to filter out extraneous explanations that
fall outside the template's boundaries. To validate its efficacy, we carried
out a comparative analysis of three XAI methods with and without our template
guidance when explaining two DL models in two real-world datasets. Results: The
proposed approach consistently improved baseline XAI methods across twelve
benchmark scenarios built on three XAI methods, two DL models, and two
datasets. The average incremental percentages, calculated by the performance
improvements over the baseline performance, were 97.8% in Intersection over
Union (IoU) and 94.1% in Dice Similarity Coefficient (DSC) when comparing model
explanations and ground-truth lesion areas. Conclusions: In the context of
pneumothorax diagnoses, we proposed a template-guided approach for improving AI
explanations. We anticipate that our template guidance will forge a fresh
approach to elucidating AI models by integrating clinical domain expertise.

æè¦ï¼<paragraph>èæ¯ï¼æ°£è¸æ¯ä¸ç¨®å èºé¨èè¸å£ä¹éç°å¸¸éæ°£æå¼èµ·çæ¥æ§è¸èç¾çãçºäºè§£æ±ºæ·±åº¦å­¸ç¿ï¼DLï¼æ¨¡åç¶å¸¸ä¼´é¨çä¸éææ§ï¼å¯è§£éäººå·¥æºæ§ï¼XAIï¼æ¹æ³å·²è¢«å¼å¥ï¼ç¨æ¼æ¦è¿°è DL æ¨¡åååºçæ°£è¸è¨ºæ·ç¸éçååãç¶èï¼éäºè§£éæææèå¯¦éçç¶ååææåºå¥ï¼çªé¡¯åºé²ä¸æ­¥æ¹é²çå¿è¦æ§ãæ¹æ³ï¼æåæåºäºä¸ç¨®æ¨¡æ¿å¼å°å¼æ¹æ³ï¼å°æ°£è¸çè¨åºç¥è­ç´å¥ XAI æ¹æ³ç¢ççæ¨¡åè§£éä¸­ï¼å¾èæåéäºè§£éçåè³ªãå©ç¨æ¾å°ç§é«å¸«å»ºç«ççç¶æç¹ªï¼æåçåæ³é¦åç¢çä¸åæ¨¡æ¿ï¼ç¨æ¼è¡¨ç¤ºæ°£è¸å¯è½ç¼ççååãç¶å¾å°æ­¤æ¨¡æ¿çå å¨æ¨¡åè§£éä¸ï¼ä»¥ç¯©é¸åºè¶åºæ¨¡æ¿éççç¡éè§£éãçºäºé©è­å¶æåï¼æåå°ä¸ç¨® XAI æ¹æ³é²è¡äºæ¯è¼åæï¼å¨å©åçå¯¦ä¸çè³æéä¸­è§£éå©å DL æ¨¡åæï¼åå¥æ¡ç¨åä¸æ¡ç¨æåçæ¨¡æ¿å¼å°ãçµæï¼ææåºçæ¹æ³å¨å»ºç«æ¼ä¸ç¨® XAI æ¹æ³ãå©å DL æ¨¡ååå©åè³æéçåäºç¨®åºæºæå¢ä¸­ï¼å§çµæ¹åäºåºæº XAI æ¹æ³ãå¨æ¯è¼æ¨¡åè§£éåçå¯¦çç¶ååæï¼ééåºæºæè½çæè½æ¹é²è¨ç®åºçå¹³åå¢éç¾åæ¯çºäº¤éæ¯ï¼IoUï¼ç 97.8% åéª°å­ç¸ä¼¼æ§ä¿æ¸ï¼DSCï¼ç 94.1%ãçµè«ï¼å¨æ°£è¸è¨ºæ·çèæ¯ä¸ï¼æåæåºäºä¸ç¨®æ¨¡æ¿å¼å°å¼æ¹æ³ï¼ç¨æ¼æ¹å AI è§£éãæåé ææåçæ¨¡æ¿å¼å°å°ééæ´åè¨åºé åå°æ¥­ç¥è­ï¼çºé¡æ AI æ¨¡åå»ºç«ä¸ç¨®æ°æ¹æ³ã</paragraph>

##### **Enhancing Neural Machine Translation of Low-Resource Languages: Corpus Development, Human Evaluation and Explainable AI Architectures**
2403.01580v1 by SÃ©amus Lankford

In the current machine translation (MT) landscape, the Transformer
architecture stands out as the gold standard, especially for high-resource
language pairs. This research delves into its efficacy for low-resource
language pairs including both the English$\leftrightarrow$Irish and
English$\leftrightarrow$Marathi language pairs. Notably, the study identifies
the optimal hyperparameters and subword model type to significantly improve the
translation quality of Transformer models for low-resource language pairs.
  The scarcity of parallel datasets for low-resource languages can hinder MT
development. To address this, gaHealth was developed, the first bilingual
corpus of health data for the Irish language. Focusing on the health domain,
models developed using this in-domain dataset exhibited very significant
improvements in BLEU score when compared with models from the LoResMT2021
Shared Task. A subsequent human evaluation using the multidimensional quality
metrics error taxonomy showcased the superior performance of the Transformer
system in reducing both accuracy and fluency errors compared to an RNN-based
counterpart.
  Furthermore, this thesis introduces adaptNMT and adaptMLLM, two open-source
applications streamlined for the development, fine-tuning, and deployment of
neural machine translation models. These tools considerably simplify the setup
and evaluation process, making MT more accessible to both developers and
translators. Notably, adaptNMT, grounded in the OpenNMT ecosystem, promotes
eco-friendly natural language processing research by highlighting the
environmental footprint of model development. Fine-tuning of MLLMs by adaptMLLM
demonstrated advancements in translation performance for two low-resource
language pairs: English$\leftrightarrow$Irish and
English$\leftrightarrow$Marathi, compared to baselines from the LoResMT2021
Shared Task.

æè¦ï¼<paragraph>å¨ç¶åæ©å¨ç¿»è­¯ (MT) é åä¸­ï¼Transformer æ¶æ§è«ç©èåºï¼æçºé»éæ¨æºï¼ç¹å¥æ¯å°æ¼é«è³æºèªè¨å°ãæ¬ç ç©¶æ¢è¨å¶å°ä½è³æºèªè¨å°çæè½ï¼åæ¬è±èªâæç¾è­èªåè±èªâé¦¬æå°èªèªè¨å°ãå¼å¾æ³¨æçæ¯ï¼æ¬ç ç©¶è­å¥åºæä½³è¶åæ¸åå­è©æ¨¡åé¡åï¼ä»¥é¡¯èæé« Transformer æ¨¡åå°ä½è³æºèªè¨å°çç¿»è­¯åè³ªã
ä½è³æºèªè¨çå¹³è¡è³æéçç¨ç¼ºæé»ç¤ MT çç¼å±ãçºäºè§£æ±ºéååé¡ï¼éç¼äº gaHealthï¼éæ¯æç¾è­èªçç¬¬ä¸åéèªå¥åº·è³æèªæåº«ãå°æ³¨æ¼å¥åº·é åï¼ä½¿ç¨æ­¤åå§è³æééç¼çæ¨¡åå¨ BLEU å¾åæ¹é¢è¡¨ç¾åºéå¸¸é¡¯èçé²æ­¥ï¼è LoResMT2021 å±äº«ä»»åä¸­çæ¨¡åç¸æ¯ãé¨å¾ä½¿ç¨å¤ç¶­åè³ªææ¨é¯èª¤åé¡æ³é²è¡çäººå·¥è©ä¼°é¡¯ç¤ºï¼èåºæ¼ RNN çå°ææ¨¡åç¸æ¯ï¼Transformer ç³»çµ±å¨æ¸å°æºç¢ºæ§åæµæ¢æ§é¯èª¤æ¹é¢è¡¨ç¾åºåªç°çæ§è½ã
æ­¤å¤ï¼æ¬è«æä»ç´¹äº adaptNMT å adaptMLLMï¼éå©åéæºæç¨ç¨å¼ç°¡åäºç¥ç¶æ©å¨ç¿»è­¯æ¨¡åçéç¼ãå¾®èª¿åé¨ç½²ãéäºå·¥å·å¤§å¹ç°¡åäºè¨­å®åè©ä¼°æµç¨ï¼è® MT æ´å®¹æè®éç¼äººå¡åç¿»è­¯äººå¡ä½¿ç¨ãå¼å¾æ³¨æçæ¯ï¼adaptNMT ä»¥ OpenNMT çæç³»çµ±çºåºç¤ï¼ééå¼·èª¿æ¨¡åéç¼çç°å¢è¶³è·¡ä¾ä¿é²çæåå¥½çèªç¶èªè¨èçç ç©¶ãè LoResMT2021 å±äº«ä»»åä¸­çåºæºç¸æ¯ï¼adaptMLLM å° MLLM çå¾®èª¿è­æäºè±èªâæç¾è­èªåè±èªâé¦¬æå°èªéå©åä½è³æºèªè¨å°çç¿»è­¯æ§è½é²æ­¥ã</paragraph>

##### **Cause and Effect: Can Large Language Models Truly Understand Causality?**
2402.18139v3 by Swagata Ashwani, Kshiteesh Hegde, Nishith Reddy Mannuru, Mayank Jindal, Dushyant Singh Sengar, Krishna Chaitanya Rao Kathala, Dishant Banga, Vinija Jain, Aman Chadha

With the rise of Large Language Models(LLMs), it has become crucial to
understand their capabilities and limitations in deciphering and explaining the
complex web of causal relationships that language entails. Current methods use
either explicit or implicit causal reasoning, yet there is a strong need for a
unified approach combining both to tackle a wide array of causal relationships
more effectively. This research proposes a novel architecture called Context
Aware Reasoning Enhancement with Counterfactual Analysis(CARE CA) framework to
enhance causal reasoning and explainability. The proposed framework
incorporates an explicit causal detection module with ConceptNet and
counterfactual statements, as well as implicit causal detection through LLMs.
Our framework goes one step further with a layer of counterfactual explanations
to accentuate LLMs understanding of causality. The knowledge from ConceptNet
enhances the performance of multiple causal reasoning tasks such as causal
discovery, causal identification and counterfactual reasoning. The
counterfactual sentences add explicit knowledge of the not caused by scenarios.
By combining these powerful modules, our model aims to provide a deeper
understanding of causal relationships, enabling enhanced interpretability.
Evaluation of benchmark datasets shows improved performance across all metrics,
such as accuracy, precision, recall, and F1 scores. We also introduce
CausalNet, a new dataset accompanied by our code, to facilitate further
research in this domain.

æè¦ï¼é¨èå¤§åèªè¨æ¨¡å (LLM) çèèµ·ï¼äºè§£å®åå¨è§£ç¢¼åè§£éèªè¨æèå«çè¤éå æéä¿ç¶²è·¯ä¸­çè½ååéå¶è®å¾è³ééè¦ãç®åçæè¡ä½¿ç¨æç¢ºæé±å«çå ææ¨çï¼ä½å¼·çéè¦ä¸ç¨®çµ±ä¸çæ¹æ³ï¼çµåå©èä»¥æ´ææå°èçå»£æ³çå æéä¿ãæ¬ç ç©¶æåºäºä¸ç¨®ç¨±çºæå¢æç¥æ¨çå¢å¼·èåäºå¯¦åæ (CARE CA) æ¡æ¶çæ°æ¶æ§ï¼ä»¥å¢å¼·å ææ¨çåå¯è§£éæ§ãæåºçæ¡æ¶çµåäºä½¿ç¨ ConceptNet ååäºå¯¦é³è¿°çæç¢ºå ææª¢æ¸¬æ¨¡çµï¼ä»¥åéé LLM é²è¡çé±å«å ææª¢æ¸¬ãæåçæ¡æ¶æ´é²ä¸æ­¥ï¼å å¥ä¸å±¤åäºå¯¦è§£éï¼ä»¥å¼·èª¿ LLM å°å æéä¿ççè§£ãä¾èª ConceptNet çç¥è­å¢å¼·äºå¤é å ææ¨çä»»åçå·è¡ï¼ä¾å¦å æç¼ç¾ãå æè­å¥ååäºå¯¦æ¨çãåäºå¯¦å¥å å¥äºæªç±æå¢é æçæç¢ºç¥è­ãééçµåéäºå¼·å¤§çæ¨¡çµï¼æåçæ¨¡åæ¨å¨æä¾å°å æéä¿æ´æ·±å¥ççè§£ï¼å¯¦ç¾å¢å¼·çå¯è§£éæ§ãåºæºè³æéçè©ä¼°é¡¯ç¤ºå¨ææææ¨ï¼ä¾å¦æºç¢ºåº¦ãç²¾ç¢ºåº¦ãå¬åçå F1 åæ¸ï¼ä¸é½æææåãæåéå¼å¥äº CausalNetï¼ä¸åæ°çè³æéï¼ä¸¦éä¸äºæåçç¨å¼ç¢¼ï¼ä»¥ä¿é²å¨éåé åçé²ä¸æ­¥ç ç©¶ã

##### **Artificial Intelligence and Diabetes Mellitus: An Inside Look Through the Retina**
2402.18600v1 by Yasin Sadeghi Bazargani, Majid Mirzaei, Navid Sobhi, Mirsaeed Abdollahi, Ali Jafarizadeh, Siamak Pedrammehr, Roohallah Alizadehsani, Ru San Tan, Sheikh Mohammed Shariful Islam, U. Rajendra Acharya

Diabetes mellitus (DM) predisposes patients to vascular complications.
Retinal images and vasculature reflect the body's micro- and macrovascular
health. They can be used to diagnose DM complications, including diabetic
retinopathy (DR), neuropathy, nephropathy, and atherosclerotic cardiovascular
disease, as well as forecast the risk of cardiovascular events. Artificial
intelligence (AI)-enabled systems developed for high-throughput detection of DR
using digitized retinal images have become clinically adopted. Beyond DR
screening, AI integration also holds immense potential to address challenges
associated with the holistic care of the patient with DM. In this work, we aim
to comprehensively review the literature for studies on AI applications based
on retinal images related to DM diagnosis, prognostication, and management. We
will describe the findings of holistic AI-assisted diabetes care, including but
not limited to DR screening, and discuss barriers to implementing such systems,
including issues concerning ethics, data privacy, equitable access, and
explainability. With the ability to evaluate the patient's health status vis a
vis DM complication as well as risk prognostication of future cardiovascular
complications, AI-assisted retinal image analysis has the potential to become a
central tool for modern personalized medicine in patients with DM.

æè¦ï¼ç³å°¿çï¼DMï¼ä½¿æ£èå®¹æåºç¾è¡ç®¡ä½µç¼çã
è¦ç¶²èå½±ååè¡ç®¡åæ èº«é«çå¾®è¡ç®¡åå·¨è¡ç®¡å¥åº·çæ³ãå®åå¯ç¨æ¼è¨ºæ·ç³å°¿çä½µç¼çï¼åæ¬ç³å°¿çè¦ç¶²èçè®ï¼DRï¼ãç¥ç¶çè®ãèçååèç²¥æ¨£ç¡¬åæ§å¿è¡ç®¡ç¾çï¼ä»¥åé æ¸¬å¿è¡ç®¡äºä»¶çé¢¨éªãçºä½¿ç¨æ¸ä½åè¦ç¶²èå½±åé²è¡é«éé DR æª¢æ¸¬èéç¼çäººå·¥æºæ§ï¼AIï¼åç¨ç³»çµ±å·²å¨è¨åºæ¡ç¨ãé¤äº DR ç¯©æª¢å¤ï¼AI æ´åä¹å·æå·¨å¤§çæ½åä¾æå°èç³å°¿çæ£èæ´é«ç§è­·ç¸éçææ°ãå¨éé å·¥ä½ä¸­ï¼æåæ¨å¨å¨é¢åé¡§åºæ¼è¦ç¶²èå½±åç AI æç¨ç¸éç ç©¶çæç»ï¼éäºç ç©¶èç³å°¿ççè¨ºæ·ãé å¾åç®¡çæéãæåå°æè¿°æ´é« AI è¼å©ç³å°¿çç§è­·çç¼ç¾ï¼åæ¬ä½ä¸éæ¼ DR ç¯©æª¢ï¼ä¸¦è¨è«å¯¦æ½æ­¤é¡ç³»çµ±çéç¤ï¼åæ¬èå«çãè³æé±ç§ãå¬å¹³å­ååå¯è§£éæ§æéçåé¡ãééè©ä¼°æ£èçå¥åº·çæ³ï¼åæèéç³å°¿çä½µç¼çä»¥åæªä¾å¿è¡ç®¡ä½µç¼ççé¢¨éªé å¾ï¼AI è¼å©è¦ç¶²èå½±ååæææ½åæçºç³å°¿çæ£èç¾ä»£ååäººåé«ççä¸­å¿å·¥å·ã

##### **Multi-stakeholder Perspective on Responsible Artificial Intelligence and Acceptability in Education**
2402.15027v2 by A. J. Karran, P. Charland, J-T. Martineau, A. Ortiz de Guinea Lopez de Arana, AM. Lesage, S. Senecal, P-M. Leger

This study investigates the acceptability of different artificial
intelligence (AI) applications in education from a multi-stakeholder
perspective, including students, teachers, and parents. Acknowledging the
transformative potential of AI in education, it addresses concerns related to
data privacy, AI agency, transparency, explainability and the ethical
deployment of AI. Through a vignette methodology, participants were presented
with four scenarios where AI's agency, transparency, explainability, and
privacy were manipulated. After each scenario, participants completed a survey
that captured their perceptions of AI's global utility, individual usefulness,
justice, confidence, risk, and intention to use each scenario's AI if
available. The data collection comprising a final sample of 1198
multi-stakeholder participants was distributed through a partner institution
and social media campaigns and focused on individual responses to four AI use
cases. A mediation analysis of the data indicated that acceptance and trust in
AI varies significantly across stakeholder groups. We found that the key
mediators between high and low levels of AI's agency, transparency, and
explainability, as well as the intention to use the different educational AI,
included perceived global utility, justice, and confidence. The study
highlights that the acceptance of AI in education is a nuanced and multifaceted
issue that requires careful consideration of specific AI applications and their
characteristics, in addition to the diverse stakeholders' perceptions.

æè¦ï¼éé ç ç©¶å¾å¤åå©å®³éä¿äººçè§åº¦æ¢è¨ä¸åçäººå·¥æºæ§ (AI) æç¨å¨æè²ä¸çå¯æ¥åæ§ï¼åæ¬å­¸çãèå¸«åå®¶é·ãæ¿èª AI å¨æè²ä¸çè½åæ½åï¼å®è§£æ±ºäºèè³æé±ç§ãAI ä»£çãéæåº¦ãå¯è§£éæ§å AI çéå¾·é¨ç½²ç¸éççæ®ãééå°ææ²æ¹æ³ï¼åèèè¢«åç¾äºåç¨®æå¢ï¼å¶ä¸­ AI çä»£çãéæåº¦ãå¯è§£éæ§åé±ç§åå°æç¸±ãå¨æ¯åæå¢å¾ï¼åèèå®æäºä¸é èª¿æ¥ï¼è©²èª¿æ¥ææäºä»åå° AI çæ´é«æç¨ãåäººæç¨ãæ­£ç¾©ãä¿¡å¿ãé¢¨éªåå¦æå¯ç¨ï¼ä½¿ç¨æ¯åæå¢ç AI çæåççæ³ãè³æèéåå«ä¾èªåä½æ©æ§åç¤¾ç¾¤åªé«æ´»åç 1198 ä½å¤å©å®³éä¿äººåèèçæçµæ¨£æ¬ï¼ä¸¦å°æ³¨æ¼å°åå AI ä½¿ç¨æ¡ä¾çåå¥åæãå°è³æçèª¿è§£åæè¡¨æï¼å° AI çæ¥ååº¦åä¿¡ä»»å¨å©å®³éä¿äººåé«ä¹éæé¡¯èå·®ç°ãæåç¼ç¾ï¼AI çä»£çãéæåº¦åå¯è§£éæ§é«ä½ç¨åº¦ä¹éçééµèª¿è§£èï¼ä»¥åä½¿ç¨ä¸åæè² AI çæåï¼åæ¬æç¥å°çæ´é«æç¨ãæ­£ç¾©åä¿¡å¿ãéé ç ç©¶å¼·èª¿ï¼æ¥å AI å¨æè²ä¸çæç¨æ¯ä¸åå¾®å¦ä¸å¤é¢åçåé¡ï¼é¤äºä¸åçå©å®³éä¿äººççæ³å¤ï¼ééè¦ä»ç´°èæ®å·é«ç AI æç¨åå¶ç¹å¾µã

##### **Deciphering Heartbeat Signatures: A Vision Transformer Approach to Explainable Atrial Fibrillation Detection from ECG Signals**
2402.09474v2 by Aruna Mohan, Danne Elbers, Or Zilbershot, Fatemeh Afghah, David Vorchheimer

Remote patient monitoring based on wearable single-lead electrocardiogram
(ECG) devices has significant potential for enabling the early detection of
heart disease, especially in combination with artificial intelligence (AI)
approaches for automated heart disease detection. There have been prior studies
applying AI approaches based on deep learning for heart disease detection.
However, these models are yet to be widely accepted as a reliable aid for
clinical diagnostics, in part due to the current black-box perception
surrounding many AI algorithms. In particular, there is a need to identify the
key features of the ECG signal that contribute toward making an accurate
diagnosis, thereby enhancing the interpretability of the model. In the present
study, we develop a vision transformer approach to identify atrial fibrillation
based on single-lead ECG data. A residual network (ResNet) approach is also
developed for comparison with the vision transformer approach. These models are
applied to the Chapman-Shaoxing dataset to classify atrial fibrillation, as
well as another common arrhythmia, sinus bradycardia, and normal sinus rhythm
heartbeats. The models enable the identification of the key regions of the
heartbeat that determine the resulting classification, and highlight the
importance of P-waves and T-waves, as well as heartbeat duration and signal
amplitude, in distinguishing normal sinus rhythm from atrial fibrillation and
sinus bradycardia.

æè¦ï¼<paragraph>åºæ¼å¯ç©¿æ´å¼å®å°ç¨å¿é»å (ECG) è£ç½®çé ç«¯çæ£ç£æ¸¬å¨æ©æåµæ¸¬å¿èç¾çæ¹é¢å·æé¡¯èçæ½åï¼ç¹å¥æ¯èç¨æ¼èªååå¿èç¾çåµæ¸¬çäººå·¥æºæ§ (AI) æ¹æ³çµåä½¿ç¨æãååå·²æç ç©¶æç¨åºæ¼æ·±åº¦å­¸ç¿ç AI æ¹æ³é²è¡å¿èç¾çåµæ¸¬ãç¶èï¼éäºæ¨¡åå°æªè¢«å»£æ³æ¥åçºè¨åºè¨ºæ·çå¯é è¼å©å·¥å·ï¼é¨ååå å¨æ¼åç¹è¨±å¤ AI æ¼ç®æ³çç¶åé»ç®±æç¥ãç¹å¥æ¯ï¼æå¿è¦æ¾åºæå©æ¼ååºæºç¢ºè¨ºæ·ç ECG è¨èééµç¹å¾µï¼å¾èå¢å¼·æ¨¡åçå¯è§£éæ§ãå¨æ¬ç ç©¶ä¸­ï¼æåéç¼äºä¸ç¨®è¦è¦ºè½æå¨æ¹æ³ï¼ä»¥æ ¹æå®å°ç¨ ECG è³ææ¾åºå¿æ¿é¡«åãæ®å·®ç¶²è·¯ (ResNet) æ¹æ³ä¹å·²éç¼åºä¾ï¼ä»¥ä¾¿èè¦è¦ºè½æå¨æ¹æ³é²è¡æ¯è¼ãéäºæ¨¡åæç¨æ¼ Chapman-Shaoxing è³æéï¼ä»¥åé¡å¿æ¿é¡«åï¼ä»¥åå¦ä¸ç¨®å¸¸è¦çå¿å¾ä¸æ´ï¼ç«æ§å¿åéç·©ï¼åæ­£å¸¸ç«æ§å¿å¾çå¿è·³ãéäºæ¨¡åè½å¤ æ¾åºæ±ºå®æçµåé¡çå¿è·³ééµååï¼ä¸¦å¼·èª¿ P æ³¢å T æ³¢ï¼ä»¥åå¿è·³æçºæéåè¨èæ¯å¹å¨ååæ­£å¸¸ç«æ§å¿å¾èå¿æ¿é¡«ååç«æ§å¿åéç·©æ¹é¢çéè¦æ§ã</paragraph>

##### **Illuminate: A novel approach for depression detection with explainable analysis and proactive therapy using prompt engineering**
2402.05127v1 by Aryan Agrawal

This paper introduces a novel paradigm for depression detection and treatment
using advanced Large Language Models (LLMs): Generative Pre-trained Transformer
4 (GPT-4), Llama 2 chat, and Gemini. These LLMs are fine-tuned with specialized
prompts to diagnose, explain, and suggest therapeutic interventions for
depression. A unique few-shot prompting method enhances the models' ability to
analyze and explain depressive symptoms based on the DSM-5 criteria. In the
interaction phase, the models engage in empathetic dialogue management, drawing
from resources like PsychDB and a Cognitive Behavioral Therapy (CBT) Guide,
fostering supportive interactions with individuals experiencing major
depressive disorders. Additionally, the research introduces the Illuminate
Database, enriched with various CBT modules, aiding in personalized therapy
recommendations. The study evaluates LLM performance using metrics such as F1
scores, Precision, Recall, Cosine similarity, and Recall-Oriented Understudy
for Gisting Evaluation (ROUGE) across different test sets, demonstrating their
effectiveness. This comprehensive approach blends cutting-edge AI with
established psychological methods, offering new possibilities in mental health
care and showcasing the potential of LLMs in revolutionizing depression
diagnosis and treatment strategies.

æè¦ï¼æ¬æä»ç´¹äºä¸ç¨®ä½¿ç¨åé²å¤§åèªè¨æ¨¡å (LLM) é²è¡æé¬±çåµæ¸¬åæ²»ççæ°æ¨¡å¼ï¼çæå¼é è¨ç·´Transformer 4 (GPT-4)ãLlama 2 èå¤©æ©å¨äººå Geminiãéäº LLM ç¶éå¾®èª¿ï¼å·åå°æ¥­æç¤ºï¼å¯è¨ºæ·ãè§£éä¸¦å»ºè­°æé¬±ççæ²»çä»å¥æ¹æ³ãä¸ç¨®ç¨ç¹çå°æ¬¡æç¤ºæ¹æ³å¢å¼·äºæ¨¡åæ ¹æ DSM-5 æ¨æºåæåè§£éæé¬±çççè½åãå¨äºåéæ®µï¼éäºæ¨¡åæåèåçå¿å°è©±ç®¡çï¼å¾ PsychDB åèªç¥è¡çºçæ³ (CBT) æåç­è³æºä¸­æ±²åï¼ä¿é²èç¶æ­·éåº¦æé¬±ççäººåçæ¯ææ§äºåãæ­¤å¤ï¼éé ç ç©¶éä»ç´¹äº Illuminate è³æåº«ï¼å¶ä¸­åå«åç¨® CBT æ¨¡çµï¼æå©æ¼åæ§åæ²»çå»ºè­°ãéé ç ç©¶ä½¿ç¨ F1 åæ¸ãæºç¢ºçãå¬åçãé¤å¼¦ç¸ä¼¼åº¦åé¢åå¬åçç Gisting è©ä¼°æ¿èº« (ROUGE) ç­ææ¨ï¼å¨ä¸åçæ¸¬è©¦éä¸­è©ä¼° LLM çè¡¨ç¾ï¼è­æäºå®åçæææ§ãéç¨®ç¶åæ¹æ³çµåäºå°ç«¯ç AI èæ¢å®çå¿çæ¹æ³ï¼çºå¿çä¿å¥æä¾äºæ°çå¯è½æ§ï¼ä¸¦å±ç¤ºäº LLM å¨é©æ°æé¬±çè¨ºæ·åæ²»çç­ç¥æ¹é¢çæ½åã

##### **Information That Matters: Exploring Information Needs of People Affected by Algorithmic Decisions**
2401.13324v6 by TimothÃ©e Schmude, Laura Koesten, Torsten MÃ¶ller, Sebastian Tschiatschek

Every AI system that makes decisions about people has a group of stakeholders
that are personally affected by these decisions. However, explanations of AI
systems rarely address the information needs of this stakeholder group, who
often are AI novices. This creates a gap between conveyed information and
information that matters to those who are impacted by the system's decisions,
such as domain experts and decision subjects. To address this, we present the
"XAI Novice Question Bank," an extension of the XAI Question Bank containing a
catalog of information needs from AI novices in two use cases: employment
prediction and health monitoring. The catalog covers the categories of data,
system context, system usage, and system specifications. We gathered
information needs through task-based interviews where participants asked
questions about two AI systems to decide on their adoption and received verbal
explanations in response. Our analysis showed that participants' confidence
increased after receiving explanations but that their understanding faced
challenges. These included difficulties in locating information and in
assessing their own understanding, as well as attempts to outsource
understanding. Additionally, participants' prior perceptions of the systems'
risks and benefits influenced their information needs. Participants who
perceived high risks sought explanations about the intentions behind a system's
deployment, while those who perceived low risks rather asked about the system's
operation. Our work aims to support the inclusion of AI novices in
explainability efforts by highlighting their information needs, aims, and
challenges. We summarize our findings as five key implications that can inform
the design of future explanations for lay stakeholder audiences.

æè¦ï¼<paragraph>æ¯åå°äººååºæ±ºå®ç AI ç³»çµ±é½æä¸ç¾¤å©å®³éä¿äºº
åå°éäºæ±ºå®çè¦ªèº«å½±é¿ãç¶èï¼AI
ç³»çµ±çè§£éå¾å°è½æ»¿è¶³éç¾¤å©å®³éä¿äººçè³è¨éæ±ï¼èä»å
éå¸¸é½æ¯ AI æ°æãéé æäºå³éè³è¨è
åå°ç³»çµ±æ±ºç­å½±é¿çäººå£«ï¼ä¾å¦é åå°å®¶åæ±ºç­ä¸»é«ï¼éè¦çè³è¨ä¹éçè½å·®ãçºäºè§£æ±ºéååé¡ï¼æåæåºäº
ãXAI æ°æåé¡åº«ãï¼å®æ¯ XAI åé¡åº«çå»¶ä¼¸ï¼åå«ä¾èª AI æ°æå¨å©åä½¿ç¨æ¡ä¾ä¸­çè³è¨éæ±ç®éï¼å°±æ¥­
é æ¸¬åå¥åº·ç£æ¸¬ãç®éæ¶µèäºè³æã
ç³»çµ±èæ¯ãç³»çµ±ä½¿ç¨åç³»çµ±è¦æ ¼ç­é¡å¥ãæåééä»»ååè¨ªè«æ¶éè³è¨éæ±ï¼åèèå¨è¨ªè«ä¸­è©¢åäºå©å AI ç³»çµ±çåé¡ï¼ä»¥æ±ºå®æ¯å¦æ¡ç¨å®åï¼ä¸¦æ¶å°å£é ­
è§£éä½çºåæãæåçåæé¡¯ç¤ºï¼åèèå¨æ¶å°è§£éå¾ä¿¡å¿æææåï¼ä½ä»åççè§£å»é¢è¨ææ°ãéäºææ°åæ¬é£ä»¥æ¾å°è³è¨åè©ä¼°èªå·±ççè§£ï¼ä»¥åè©¦åå¤å
çè§£ãæ­¤å¤ï¼åèèå°ç³»çµ±é¢¨éªåå¥½èçåååé¥å½±é¿äºä»åçè³è¨éæ±ãèªçºé¢¨éªé«çåèèå°æ±è§£éç³»çµ±é¨ç½²èå¾çæåï¼èèªçºé¢¨éªä½çäººåè©¢åç³»çµ±ç
æä½ãæåçç ç©¶æ¨å¨ééå¼·èª¿ AI æ°æçè³è¨éæ±ãç®æ¨å
ææ°ï¼ä¾æ¯æå° AI æ°æç´å¥å¯è§£éæ§å·¥ä½ä¸­ãæåå°æåçç ç©¶çµæç¸½çµçºäºåééµåç¤ºï¼éäºåç¤ºå¯ä»¥çºæªä¾éå°éå°æ¥­å©å®³éä¿äººåç¾çè§£éè¨­è¨æä¾åèã</paragraph>

##### **Evaluating Large Language Models on the GMAT: Implications for the Future of Business Education**
2401.02985v1 by Vahid Ashrafimoghari, Necdet GÃ¼rkan, Jordan W. Suchow

The rapid evolution of artificial intelligence (AI), especially in the domain
of Large Language Models (LLMs) and generative AI, has opened new avenues for
application across various fields, yet its role in business education remains
underexplored. This study introduces the first benchmark to assess the
performance of seven major LLMs, OpenAI's models (GPT-3.5 Turbo, GPT-4, and
GPT-4 Turbo), Google's models (PaLM 2, Gemini 1.0 Pro), and Anthropic's models
(Claude 2 and Claude 2.1), on the GMAT, which is a key exam in the admission
process for graduate business programs. Our analysis shows that most LLMs
outperform human candidates, with GPT-4 Turbo not only outperforming the other
models but also surpassing the average scores of graduate students at top
business schools. Through a case study, this research examines GPT-4 Turbo's
ability to explain answers, evaluate responses, identify errors, tailor
instructions, and generate alternative scenarios. The latest LLM versions,
GPT-4 Turbo, Claude 2.1, and Gemini 1.0 Pro, show marked improvements in
reasoning tasks compared to their predecessors, underscoring their potential
for complex problem-solving. While AI's promise in education, assessment, and
tutoring is clear, challenges remain. Our study not only sheds light on LLMs'
academic potential but also emphasizes the need for careful development and
application of AI in education. As AI technology advances, it is imperative to
establish frameworks and protocols for AI interaction, verify the accuracy of
AI-generated content, ensure worldwide access for diverse learners, and create
an educational environment where AI supports human expertise. This research
sets the stage for further exploration into the responsible use of AI to enrich
educational experiences and improve exam preparation and assessment methods.

æè¦ï¼äººå·¥æºæ§ (AI) çå¿«éæ¼é²ï¼å°¤å¶æ¯å¨å¤§åèªè¨æ¨¡å (LLM) åçæå¼ AI çé åï¼çºååé åçæç¨éåäºæ°éå¾ï¼ä½å¶å¨åæ¥­æè²ä¸­çè§è²ä»æªè¢«ååæ¢è¨ãæ¬ç ç©¶é¦æ¬¡å¼å¥äºåºæºï¼ç¨ä»¥è©ä¼°ä¸åä¸»è¦ LLM çæè½ï¼åæ¬ OpenAI çæ¨¡å (GPT-3.5 TurboãGPT-4 å GPT-4 Turbo)ãGoogle çæ¨¡å (PaLM 2ãGemini 1.0 Pro) å Anthropic çæ¨¡å (Claude 2 å Claude 2.1)ï¼éäºæ¨¡åå°ç¨æ¼ç ç©¶çåæ¥­èª²ç¨å¥å­¸ç¨åºä¸­çééµèè©¦ GMATãæåçåæé¡¯ç¤ºï¼å¤§å¤æ¸ LLM çè¡¨ç¾é½åªæ¼äººé¡èçï¼å¶ä¸­ GPT-4 Turbo ä¸ååªæ¼å¶ä»æ¨¡åï¼æ´è¶è¶äºé å°åå­¸é¢çç ç©¶çå¹³ååæ¸ãééæ¡ä¾ç ç©¶ï¼æ¬ç ç©¶æ¢è¨äº GPT-4 Turbo å¨è§£éç­æ¡ãè©ä¼°åæãè¾¨è­é¯èª¤ãèª¿æ´èªªæåç¢çæ¿ä»£æå¢æ¹é¢çè½åãèåä¸ä»£çæ¬ç¸æ¯ï¼ææ°ç LLM çæ¬ GPT-4 TurboãClaude 2.1 å Gemini 1.0 Pro å¨æ¨çä»»åæ¹é¢æé¡¯èçé²æ­¥ï¼å¸é¡¯äºå¶å¨è§£æ±ºè¤éåé¡æ¹é¢çæ½åãåç®¡ AI å¨æè²ãè©éåè¼å°æ¹é¢çæ¿è«¾å¾æç¢ºï¼ä½ä»æææ°å­å¨ãæåçç ç©¶ä¸åé¡æäº LLM çå­¸è¡æ½åï¼ä¹å¼·èª¿äºå¨æè²ä¸­å¯©æéç¼åæç¨ AI çå¿è¦æ§ãé¨è AI æè¡çé²æ­¥ï¼å»ºç« AI äºåçæ¶æ§ååå®ãé©è­ AI çæçå§å®¹çæºç¢ºæ§ãç¢ºä¿å¨çåå°å¤åå­¸ç¿èçå­åæ¬ï¼ä»¥ååµé ä¸å AI æ¯æäººé¡å°æ¥­ç¥è­çæè²ç°å¢è³ééè¦ãæ¬ç ç©¶çºé²ä¸æ­¥æ¢ç´¢è² è²¬ä»»å°ä½¿ç¨ AI ä¾è±å¯æè²é«é©ä¸¦æ¹åèè©¦æºååè©éæ¹æ³å¥ å®äºåºç¤ã

##### **XAI for In-hospital Mortality Prediction via Multimodal ICU Data**
2312.17624v1 by Xingqiao Li, Jindong Gu, Zhiyong Wang, Yancheng Yuan, Bo Du, Fengxiang He

Predicting in-hospital mortality for intensive care unit (ICU) patients is
key to final clinical outcomes. AI has shown advantaged accuracy but suffers
from the lack of explainability. To address this issue, this paper proposes an
eXplainable Multimodal Mortality Predictor (X-MMP) approaching an efficient,
explainable AI solution for predicting in-hospital mortality via multimodal ICU
data. We employ multimodal learning in our framework, which can receive
heterogeneous inputs from clinical data and make decisions. Furthermore, we
introduce an explainable method, namely Layer-Wise Propagation to Transformer,
as a proper extension of the LRP method to Transformers, producing explanations
over multimodal inputs and revealing the salient features attributed to
prediction. Moreover, the contribution of each modality to clinical outcomes
can be visualized, assisting clinicians in understanding the reasoning behind
decision-making. We construct a multimodal dataset based on MIMIC-III and
MIMIC-III Waveform Database Matched Subset. Comprehensive experiments on
benchmark datasets demonstrate that our proposed framework can achieve
reasonable interpretation with competitive prediction accuracy. In particular,
our framework can be easily transferred to other clinical tasks, which
facilitates the discovery of crucial factors in healthcare research.

æè¦ï¼é æ¸¬å è­·çæ¿ (ICU) çæ£çé¢å§æ­»äº¡çæ¯æçµè¨åºçµæçééµãAI å·²å±ç¾åºåªç°çæºç¢ºåº¦ï¼ä½å»ç¼ºä¹å¯è§£éæ§ãçºäºè§£æ±ºéååé¡ï¼æ¬ææåºäºä¸åå¯è§£éçå¤æ¨¡å¼æ­»äº¡çé æ¸¬å¨ (X-MMP)ï¼æ¡ç¨ææä¸å¯è§£éç AI æ¹å¼ï¼èç±å¤æ¨¡å¼ ICU è³æä¾é æ¸¬é¢å§æ­»äº¡çãæåå¨æ¶æ§ä¸­æ¡ç¨å¤æ¨¡å¼å­¸ç¿ï¼å¯ä»¥æ¥æ¶ä¾èªè¨åºè³æçç°è³ªè¼¸å¥ä¸¦ååºæ±ºç­ãæ­¤å¤ï¼æåå¼å¥äºä¸åå¯è§£éçæ¹æ³ï¼ä¹å°±æ¯åå±¤å³æ­è³ Transformerï¼ä½çº LRP æ¹æ³é©ç¶å°å»¶ä¼¸è³ Transformerï¼å°å¤æ¨¡å¼è¼¸å¥ç¢çè§£éï¼ä¸¦æ­é²æ­¸å æ¼é æ¸¬çé¡¯èç¹å¾µãæ­¤å¤ï¼æ¯åæ¨¡å¼å°è¨åºçµæçè²¢ç»å¯ä»¥è¦è¦ºåï¼åå©è¨åºé«å¸«äºè§£æ±ºç­èå¾ççç±ãæåæ ¹æ MIMIC-III å MIMIC-III æ³¢å½¢è³æåº«æ¯å°å­éå»ºæ§äºä¸åå¤æ¨¡å¼è³æéãå¨åºæºè³æéä¸çå¨é¢å¯¦é©è­æï¼æåæåºçæ¶æ§å¯ä»¥éæåççè©®éï¼ä¸¦å·åç«¶ç­åçé æ¸¬æºç¢ºåº¦ãç¹å¥æ¯ï¼æåçæ¶æ§å¯ä»¥è¼é¬å°è½ç§»å°å¶ä»è¨åºä»»åï¼éæå©æ¼å¨é«çä¿å¥ç ç©¶ä¸­ç¼ç¾ééµå ç´ ã

##### **Joining Forces for Pathology Diagnostics with AI Assistance: The EMPAIA Initiative**
2401.09450v2 by Norman Zerbe, Lars Ole Schwen, Christian GeiÃler, Katja Wiesemann, Tom Bisson, Peter Boor, Rita Carvalho, Michael Franz, Christoph Jansen, Tim-Rasmus Kiehl, BjÃ¶rn Lindequist, Nora Charlotte Pohlan, Sarah Schmell, Klaus Strohmenger, Falk Zakrzewski, Markus Plass, Michael Takla, Tobias KÃ¼ster, AndrÃ© Homeyer, Peter Hufnagl

Over the past decade, artificial intelligence (AI) methods in pathology have
advanced substantially. However, integration into routine clinical practice has
been slow due to numerous challenges, including technical and regulatory
hurdles in translating research results into clinical diagnostic products and
the lack of standardized interfaces. The open and vendor-neutral EMPAIA
initiative addresses these challenges. Here, we provide an overview of EMPAIA's
achievements and lessons learned. EMPAIA integrates various stakeholders of the
pathology AI ecosystem, i.e., pathologists, computer scientists, and industry.
In close collaboration, we developed technical interoperability standards,
recommendations for AI testing and product development, and explainability
methods. We implemented the modular and open-source EMPAIA platform and
successfully integrated 14 AI-based image analysis apps from 8 different
vendors, demonstrating how different apps can use a single standardized
interface. We prioritized requirements and evaluated the use of AI in real
clinical settings with 14 different pathology laboratories in Europe and Asia.
In addition to technical developments, we created a forum for all stakeholders
to share information and experiences on digital pathology and AI. Commercial,
clinical, and academic stakeholders can now adopt EMPAIA's common open-source
interfaces, providing a unique opportunity for large-scale standardization and
streamlining of processes. Further efforts are needed to effectively and
broadly establish AI assistance in routine laboratory use. To this end, a
sustainable infrastructure, the non-profit association EMPAIA International,
has been established to continue standardization and support broad
implementation and advocacy for an AI-assisted digital pathology future.

æè¦ï¼å¨éå»çåå¹´ä¸­ï¼ççå­¸ä¸­çäººå·¥æºæ§ (AI) æ¹æ³å·²å¤§å¹é²æ­¥ãç¶èï¼ç±æ¼è¨±å¤ææ°ï¼åæ¬å°ç ç©¶çµæè½åçºè¨åºè¨ºæ·ç¢åå¨æè¡åæ³è¦æ¹é¢çéç¤ï¼ä»¥åç¼ºä¹æ¨æºåä»é¢ï¼å°è´æ´åå°å¸¸è¦è¨åºå¯¦åä¸­é²å±ç·©æ¢ãéæ¾ä¸èä¾æåç¡éç EMPAIA è¨ç«æå°äºéäºææ°ãå¨æ­¤ï¼æåæä¾ EMPAIA çæå°±åç¶é©æè¨çæ¦è¿°ãEMPAIA æ´åäºççå­¸ AI çæç³»çµ±çååå©å®³éä¿äººï¼å³ççå­¸å®¶ãé»è¦ç§å­¸å®¶åç¢æ¥­ãå¨å¯ååä½ä¸ï¼æåå¶å®äºæè¡äºéæ§æ¨æºãAI æ¸¬è©¦åç¢åéç¼å»ºè­°ï¼ä»¥åå¯è§£éæ§æ¹æ³ãæåå¯¦ä½äºæ¨¡çµåä¸éæ¾åå§ç¢¼ç EMPAIA å¹³èºï¼ä¸¦æåæ´åäºä¾èª 8 åä¸åä¾æåç 14 ååºæ¼ AI çå½±ååææç¨ç¨å¼ï¼å±ç¤ºäºä¸åçæç¨ç¨å¼å¦ä½ä½¿ç¨å®ä¸çæ¨æºåä»é¢ãæååªåèæ®éæ±ï¼ä¸¦è©ä¼°äº AI å¨æ­æ´²åäºæ´²ç 14 åä¸åççå¯¦é©å®¤ä¸­çå¯¦éè¨åºæç¨ãé¤äºæè¡éç¼å¤ï¼æåéçºææå©å®³éä¿äººå»ºç«äºä¸åè«å£ï¼ä»¥åäº«æ¸ä½ççå­¸å AI çè³è¨åç¶é©ãåæ¥­ãè¨åºåå­¸è¡å©å®³éä¿äººç¾å¨å¯ä»¥æ¡ç¨ EMPAIA çå¸¸è¦éæ¾åå§ç¢¼ä»é¢ï¼éçºå¤§è¦æ¨¡æ¨æºååç°¡åæµç¨æä¾äºç¨ç¹çæ©æãéè¦é²ä¸æ­¥çåªåæè½ææä¸å»£æ³å°å»ºç«ä¾è¡å¯¦é©å®¤ä½¿ç¨ä¸­ç AI è¼å©ãçºæ­¤ï¼å·²æç«éçå©åæ EMPAIA Internationalï¼ä»¥ä½çºæ°¸çºåºç¤æ¶æ§ï¼ç¹¼çºé²è¡æ¨æºåï¼ä¸¦æ¯æ´å»£æ³å¯¦ä½åå¡å° AI è¼å©æ¸ä½ççå­¸çæªä¾ã

##### **Robust Stochastic Graph Generator for Counterfactual Explanations**
2312.11747v2 by Mario Alfonso Prado-Romero, Bardh Prenkaj, Giovanni Stilo

Counterfactual Explanation (CE) techniques have garnered attention as a means
to provide insights to the users engaging with AI systems. While extensively
researched in domains such as medical imaging and autonomous vehicles, Graph
Counterfactual Explanation (GCE) methods have been comparatively
under-explored. GCEs generate a new graph similar to the original one, with a
different outcome grounded on the underlying predictive model. Among these GCE
techniques, those rooted in generative mechanisms have received relatively
limited investigation despite demonstrating impressive accomplishments in other
domains, such as artistic styles and natural language modelling. The preference
for generative explainers stems from their capacity to generate counterfactual
instances during inference, leveraging autonomously acquired perturbations of
the input graph. Motivated by the rationales above, our study introduces
RSGG-CE, a novel Robust Stochastic Graph Generator for Counterfactual
Explanations able to produce counterfactual examples from the learned latent
space considering a partially ordered generation sequence. Furthermore, we
undertake quantitative and qualitative analyses to compare RSGG-CE's
performance against SoA generative explainers, highlighting its increased
ability to engendering plausible counterfactual candidates.

æè¦ï¼åäºå¯¦è§£é (CE) æè¡å·²å¼èµ·éæ³¨ï¼ä½çºä¸ç¨®çºè AI ç³»çµ±äºåçä½¿ç¨èæä¾è¦è§£çæ¹æ³ãéç¶å¨é«å­¸å½±ååèªåé§é§æ±½è»ç­é åå»£æ³ç ç©¶ï¼åå½¢åäºå¯¦è§£é (GCE) æ¹æ³ç¸å°è¼å°è¢«æ¢ç´¢ãGCE æç¢çä¸åé¡ä¼¼æ¼åå§åå½¢çæ°åå½¢ï¼ä¸¦æ ¹æåºç¤é æ¸¬æ¨¡åç¢çä¸åççµæãå¨éäº GCE æè¡ä¸­ï¼åç®¡å¨å¶ä»é åï¼ä¾å¦èè¡é¢¨æ ¼åèªç¶èªè¨å»ºæ¨¡ï¼ä¸­å±ç¾åºä»¤äººå°è±¡æ·±å»çæå°±ï¼ä½æ¤åºæ¼çææ©å¶çæè¡ç²å¾çéæ³¨ç¸å°æéãå°çæå¼è§£éå¨çåå¥½æºæ¼å®åå¨æ¨çæéç¢çåäºå¯¦å¯¦ä¾çè½åï¼å©ç¨è¼¸å¥åå½¢çèªä¸»ç²åæ¾åãåºæ¼ä¸è¿°çç±ï¼æåçç ç©¶å¼å¥äº RSGG-CEï¼ä¸ç¨®ç¨æ¼åäºå¯¦è§£éçæ°åç©©å¥é¨æ©åå½¢çæå¨ï¼è½å¤ å¾å­¸ç¿å°çæ½å¨ç©ºéä¸­ç¢çåäºå¯¦ç¯ä¾ï¼èæ®é¨åæåºççæåºåãæ­¤å¤ï¼æåé²è¡å®éåå®æ§åæï¼ä»¥æ¯è¼ RSGG-CE çæè½è SoA çæå¼è§£éå¨ï¼å¼·èª¿å¶å¢å¼·äºç¢çåçè§£éåé¸çè½åã

##### **Evaluating the Utility of Model Explanations for Model Development**
2312.06032v1 by Shawn Im, Jacob Andreas, Yilun Zhou

One of the motivations for explainable AI is to allow humans to make better
and more informed decisions regarding the use and deployment of AI models. But
careful evaluations are needed to assess whether this expectation has been
fulfilled. Current evaluations mainly focus on algorithmic properties of
explanations, and those that involve human subjects often employ subjective
questions to test human's perception of explanation usefulness, without being
grounded in objective metrics and measurements. In this work, we evaluate
whether explanations can improve human decision-making in practical scenarios
of machine learning model development. We conduct a mixed-methods user study
involving image data to evaluate saliency maps generated by SmoothGrad,
GradCAM, and an oracle explanation on two tasks: model selection and
counterfactual simulation. To our surprise, we did not find evidence of
significant improvement on these tasks when users were provided with any of the
saliency maps, even the synthetic oracle explanation designed to be simple to
understand and highly indicative of the answer. Nonetheless, explanations did
help users more accurately describe the models. These findings suggest caution
regarding the usefulness and potential for misunderstanding in saliency-based
explanations.

æè¦ï¼å¯è§£é AI çåæ©ä¹ä¸æ¯è®äººåå¨ä½¿ç¨åé¨ç½² AI æ¨¡åæååºæ´å¥½ãæ´ææºçæ±ºç­ãä½éè¦ä»ç´°è©ä¼°ä»¥è©ä¼°æ¯å¦å·²éå°æ­¤é æãç®åçè©ä¼°ä¸»è¦éä¸­å¨è§£éçæ¼ç®æ³ç¹æ§ï¼èæ¶åäººé¡åè©¦èçè©ä¼°éå¸¸æ¡ç¨ä¸»è§åé¡ä¾æ¸¬è©¦äººé¡å°è§£éæç¨æ§ççæ³ï¼èæ²æåºæ¼å®¢è§ææ¨åæ¸¬éãå¨éé å·¥ä½ä¸­ï¼æåè©ä¼°è§£éæ¯å¦å¯ä»¥å¨æ©å¨å­¸ç¿æ¨¡åéç¼çå¯¦éå ´æ¯ä¸­æ¹åäººé¡æ±ºç­å¶å®ãæåé²è¡äºä¸é æ¶åå½±åè³æçæ··åæ¹æ³ä½¿ç¨èç ç©¶ï¼ä»¥è©ä¼° SmoothGradãGradCAM åé è¨è§£éå¨å©åä»»åä¸­ç¢ççé¡¯èæ§åï¼æ¨¡åé¸æååäºå¯¦æ¨¡æ¬ãä»¤äººé©è¨çæ¯ï¼æåæ²æç¼ç¾ä»»ä½é¡¯èæ§åï¼å³ä½¿æ¯è¨­è¨çºææ¼çè§£ä¸é«åº¦æç¤ºç­æ¡çåæé è¨è§£éï¼è½è®ä½¿ç¨èå¨éäºä»»åä¸é¡¯èæ¹åçè­æãåç®¡å¦æ­¤ï¼è§£éç¢ºå¯¦æå©æ¼ä½¿ç¨èæ´æºç¢ºå°æè¿°æ¨¡åãéäºç¼ç¾æç¤ºæåè¦å°åºæ¼é¡¯èæ§çè§£éä¸­å¯è½å­å¨èª¤è§£çæç¨æ§ä¿æè¬¹æã

##### **Building Trustworthy NeuroSymbolic AI Systems: Consistency, Reliability, Explainability, and Safety**
2312.06798v1 by Manas Gaur, Amit Sheth

Explainability and Safety engender Trust. These require a model to exhibit
consistency and reliability. To achieve these, it is necessary to use and
analyze data and knowledge with statistical and symbolic AI methods relevant to
the AI application - neither alone will do. Consequently, we argue and seek to
demonstrate that the NeuroSymbolic AI approach is better suited for making AI a
trusted AI system. We present the CREST framework that shows how Consistency,
Reliability, user-level Explainability, and Safety are built on NeuroSymbolic
methods that use data and knowledge to support requirements for critical
applications such as health and well-being. This article focuses on Large
Language Models (LLMs) as the chosen AI system within the CREST framework. LLMs
have garnered substantial attention from researchers due to their versatility
in handling a broad array of natural language processing (NLP) scenarios. For
example, ChatGPT and Google's MedPaLM have emerged as highly promising
platforms for providing information in general and health-related queries,
respectively. Nevertheless, these models remain black boxes despite
incorporating human feedback and instruction-guided tuning. For instance,
ChatGPT can generate unsafe responses despite instituting safety guardrails.
CREST presents a plausible approach harnessing procedural and graph-based
knowledge within a NeuroSymbolic framework to shed light on the challenges
associated with LLMs.

æè¦ï¼å¯è§£éæ§åå®å¨æ§å»ºç«ä¿¡ä»»ãéäºéè¦ä¸åæ¨¡åä¾å±ç¤ºä¸è´æ§åå¯é æ§ãçºäºå¯¦ç¾éäºï¼æå¿è¦ä½¿ç¨ååææ¸æåç¥è­ï¼ä¸¦ä½¿ç¨è AI æç¨ç¸éççµ±è¨åç¬¦è AI æ¹æ³ - å®ç¨ä½¿ç¨ä»»ä½ä¸ç¨®æ¹æ³é½ä¸æå¥æãå æ­¤ï¼æåä¸»å¼µä¸¦è©¦åè­æ NeuroSymbolic AI æ¹æ³æ´é©åæ¼ä½¿ AI æçºåä¿¡ä»»ç AI ç³»çµ±ãæåæåºäº CREST æ¡æ¶ï¼å±ç¤ºäºä¸è´æ§ãå¯é æ§ãä½¿ç¨èå±¤ç´çå¯è§£éæ§åå®å¨æ§æ¯å¦ä½å»ºç«å¨ NeuroSymbolic æ¹æ³ä¸çï¼è©²æ¹æ³ä½¿ç¨æ¸æåç¥è­ä¾æ¯æééµæç¨ï¼ä¾å¦å¥åº·åç¦ç¥ï¼çè¦æ±ãæ¬æéé»éæ³¨å¤§åèªè¨æ¨¡å (LLM)ï¼å çºå®æ¯ CREST æ¡æ¶ä¸­é¸æç AI ç³»çµ±ãLLM å å¶å¨èçå»£æ³çèªç¶èªè¨èç (NLP) å ´æ¯æ¹é¢çå¤åè½æ§èååç ç©¶äººå¡çéæ³¨ãä¾å¦ï¼ChatGPT å Google ç MedPaLM å·²æçºæä¾ä¸è¬åå¥åº·ç¸éæ¥è©¢ä¿¡æ¯çæ¥µæå¸æçå¹³å°ãåç®¡å¦æ­¤ï¼éäºæ¨¡åä»ç¶æ¯é»çå­ï¼åç®¡ç´å¥äºäººé¡åé¥åæä»¤å¼å°çèª¿æ´ãä¾å¦ï¼åç®¡å¶å®äºå®å¨é²è­·æªæ½ï¼ChatGPT ä»å¯è½ç¢çä¸å®å¨çåæãCREST æåºäºä¸ç¨®åççæ¹æ³ï¼å¨ NeuroSymbolic æ¡æ¶ä¸­å©ç¨ç¨åºååºæ¼åè¡¨çç¥è­ï¼ä»¥é¡æè LLM ç¸éçææ°ã

##### **Class-Discriminative Attention Maps for Vision Transformers**
2312.02364v3 by Lennart Brocki, Jakub Binda, Neo Christopher Chung

Importance estimators are explainability methods that quantify feature
importance for deep neural networks (DNN). In vision transformers (ViT), the
self-attention mechanism naturally leads to attention maps, which are sometimes
interpreted as importance scores that indicate which input features ViT models
are focusing on. However, attention maps do not account for signals from
downstream tasks. To generate explanations that are sensitive to downstream
tasks, we have developed class-discriminative attention maps (CDAM), a
gradient-based extension that estimates feature importance with respect to a
known class or a latent concept. CDAM scales attention scores by how relevant
the corresponding tokens are for the predictions of a classifier head. In
addition to targeting the supervised classifier, CDAM can explain an arbitrary
concept shared by selected samples by measuring similarity in the latent space
of ViT. Additionally, we introduce Smooth CDAM and Integrated CDAM, which
average a series of CDAMs with slightly altered tokens. Our quantitative
benchmarks include correctness, compactness, and class sensitivity, in
comparison to 7 other importance estimators. Vanilla, Smooth, and Integrated
CDAM excel across all three benchmarks. In particular, our results suggest that
existing importance estimators may not provide sufficient class-sensitivity. We
demonstrate the utility of CDAM in medical images by training and explaining
malignancy and biomarker prediction models based on lung Computed Tomography
(CT) scans. Overall, CDAM is shown to be highly class-discriminative and
semantically relevant, while providing compact explanations.

æè¦ï¼<paragraph>éè¦æ§ä¼°è¨å¨æ¯ä¸ç¨®å¯è§£éæ§æ¹æ³ï¼ç¨æ¼éåæ·±åº¦ç¥ç¶ç¶²è·¯ (DNN) çç¹å¾µéè¦æ§ãå¨è¦è¦ºTransformer (ViT) ä¸­ï¼èªææ³¨ææ©å¶èªç¶æå°è´æ³¨æååï¼æææå°å¶è§£éçºéè¦æ§åæ¸ï¼è¡¨ç¤º ViT æ¨¡åéæ³¨åªäºè¼¸å¥ç¹å¾µãç¶èï¼æ³¨æååä¸¦æªèæ®ä¾èªä¸æ¸¸ä»»åçä¿¡èãçºäºç¢çå°ä¸æ¸¸ä»»åææçè§£éï¼æåéç¼äºé¡å¥ååæ³¨æåå (CDAM)ï¼éæ¯ä¸ç¨®åºæ¼æ¢¯åº¦çæ´åï¼ç¨æ¼ä¼°è¨ç¸å°æ¼å·²ç¥é¡å¥ææ½å¨æ¦å¿µçç¹å¾µéè¦æ§ãCDAM æ ¹æå°æçç¬¦èèåé¡å¨é ­çé æ¸¬ç¸éç¨åº¦ï¼èª¿æ´æ³¨æååæ¸ãé¤äºéå°ç£ç£åé¡å¨å¤ï¼CDAM éå¯ä»¥ééæ¸¬é ViT çæ½å¨ç©ºéä¸­çç¸ä¼¼æ§ä¾è§£éé¸å®æ¨£æ¬å±æçä»»ææ¦å¿µãæ­¤å¤ï¼æåå¼å¥äºå¹³æ» CDAM åç©å CDAMï¼å®åå°ä¸ç³»åå·æç¥å¾®æ¹è®çç¬¦èç CDAM é²è¡å¹³åãæåçéååºæºåæ¬æ­£ç¢ºæ§ãç·æ¹æ§åé¡å¥æææ§ï¼èå¶ä» 7 åéè¦æ§ä¼°è¨å¨ç¸æ¯ãé¦èãå¹³æ»åç©å CDAM å¨ææä¸ååºæºä¸­è¡¨ç¾åºè²ãç¹å¥æ¯ï¼æåççµæè¡¨æç¾æçéè¦æ§ä¼°è¨å¨å¯è½ç¡æ³æä¾è¶³å¤ çé¡å¥æææ§ãæåééåºæ¼èºé¨é»è¦æ·å±¤ææ (CT) ææè¨ç·´åè§£éæ¡æ§è«ç¤åçç©æ¨è¨é æ¸¬æ¨¡åï¼è­æäº CDAM å¨é«å­¸å½±åä¸­çæç¨ãç¸½çä¾èªªï¼CDAM è¢«è­æå·æé«åº¦é¡å¥ååæ§åèªç¾©ç¸éæ§ï¼åææä¾ç°¡æ½çè§£éã</paragraph>

##### **Deployment of a Robust and Explainable Mortality Prediction Model: The COVID-19 Pandemic and Beyond**
2311.17133v1 by Jacob R. Epifano, Stephen Glass, Ravi P. Ramachandran, Sharad Patel, Aaron J. Masino, Ghulam Rasool

This study investigated the performance, explainability, and robustness of
deployed artificial intelligence (AI) models in predicting mortality during the
COVID-19 pandemic and beyond. The first study of its kind, we found that
Bayesian Neural Networks (BNNs) and intelligent training techniques allowed our
models to maintain performance amidst significant data shifts. Our results
emphasize the importance of developing robust AI models capable of matching or
surpassing clinician predictions, even under challenging conditions. Our
exploration of model explainability revealed that stochastic models generate
more diverse and personalized explanations thereby highlighting the need for AI
models that provide detailed and individualized insights in real-world clinical
settings. Furthermore, we underscored the importance of quantifying uncertainty
in AI models which enables clinicians to make better-informed decisions based
on reliable predictions. Our study advocates for prioritizing implementation
science in AI research for healthcare and ensuring that AI solutions are
practical, beneficial, and sustainable in real-world clinical environments. By
addressing unique challenges and complexities in healthcare settings,
researchers can develop AI models that effectively improve clinical practice
and patient outcomes.

æè¦ï¼æ¬ç ç©¶è°æ¥äºå¨ COVID-19 ç«ææé´åä»¥åé¢æµæ­»äº¡çæ¶ï¼å·²é¨ç½²äººå·¥æºè½ (AI) æ¨¡åçæ§è½ãå¯è§£éæ§åç¨³å¥æ§ãä½ä¸ºåç±»ç ç©¶ä¸­çé¦ä¾ï¼æä»¬åç°è´å¶æ¯ç¥ç»ç½ç» (BNN) åæºè½è®­ç»ææ¯è®©æä»¬çæ¨¡åå¨æ°æ®åçéå¤§ååæ¶ä»è½ä¿ææ§è½ãæä»¬çç»æå¼ºè°äºå¼åç¨³å¥ç AI æ¨¡åçéè¦æ§ï¼å³ä½¿å¨å·ææææ§çæ¡ä»¶ä¸ï¼è¿äºæ¨¡åä¹è½å¹éæè¶è¶ä¸´åºå»ççé¢æµãæä»¬å¯¹æ¨¡åå¯è§£éæ§çæ¢ç´¢è¡¨æï¼éæºæ¨¡åä¼äº§çæ´å¤æ ·åä¸ä¸ªæ§åçè§£éï¼ä»èçªåºäºå¨ç°å®ä¸ççä¸´åºç¯å¢ä¸­æä¾è¯¦ç»ä¸ä¸ªæ§åè§è§£ç AI æ¨¡åçå¿è¦æ§ãæ­¤å¤ï¼æä»¬å¼ºè°äºéå AI æ¨¡åä¸­ä¸ç¡®å®æ§çéè¦æ§ï¼è¿ä½¿ä¸´åºå»çè½å¤æ ¹æ®å¯é çé¢æµååºæ´ææºçå³ç­ãæä»¬çç ç©¶æå¡å¨å»çä¿å¥ç AI ç ç©¶ä¸­ä¼åèèå®æ½ç§å­¦ï¼å¹¶ç¡®ä¿ AI è§£å³æ¹æ¡å¨ç°å®ä¸ççä¸´åºç¯å¢ä¸­å®ç¨ãæçä¸å¯æç»­ãéè¿è§£å³å»çä¿å¥ç¯å¢ä¸­çç¬ç¹ææåå¤ææ§ï¼ç ç©¶äººåå¯ä»¥å¼ååºæææ¹åä¸´åºå®è·µåæ£èé¢åç AI æ¨¡åã

##### **Variational Autoencoders for Feature Exploration and Malignancy Prediction of Lung Lesions**
2311.15719v1 by Benjamin Keel, Aaron Quyn, David Jayne, Samuel D. Relton

Lung cancer is responsible for 21% of cancer deaths in the UK and five-year
survival rates are heavily influenced by the stage the cancer was identified
at. Recent studies have demonstrated the capability of AI methods for accurate
and early diagnosis of lung cancer from routine scans. However, this evidence
has not translated into clinical practice with one barrier being a lack of
interpretable models. This study investigates the application Variational
Autoencoders (VAEs), a type of generative AI model, to lung cancer lesions.
Proposed models were trained on lesions extracted from 3D CT scans in the
LIDC-IDRI public dataset. Latent vector representations of 2D slices produced
by the VAEs were explored through clustering to justify their quality and used
in an MLP classifier model for lung cancer diagnosis, the best model achieved
state-of-the-art metrics of AUC 0.98 and 93.1% accuracy. Cluster analysis shows
the VAE latent space separates the dataset of malignant and benign lesions
based on meaningful feature components including tumour size, shape, patient
and malignancy class. We also include a comparative analysis of the standard
Gaussian VAE (GVAE) and the more recent Dirichlet VAE (DirVAE), which replaces
the prior with a Dirichlet distribution to encourage a more explainable latent
space with disentangled feature representation. Finally, we demonstrate the
potential for latent space traversals corresponding to clinically meaningful
feature changes.

æè¦ï¼èºçå è±åççæ­»äº¡äººæ¸ç 21%ï¼äºå¹´å­æ´»çå¾å¤§ç¨åº¦åæ±ºæ¼ççè¢«ç¼ç¾çéæ®µãæè¿çç ç©¶å·²è­æäººå·¥æºè½æ¹æ³å·æå¾ä¾è¡ææä¸­æºç¢ºåæ©è¨ºæ·èºççè½åãç¶èï¼æ­¤è­æå°æªè½åçºè¨åºå¯¦åï¼å¶ä¸­ä¸åéç¤æ¯ç¼ºä¹å¯è§£éçæ¨¡åãæ¬ç ç©¶æ¢è¨äºæç¨è®åèªåç·¨ç¢¼å¨ (VAE)ï¼ä¸ç¨®çæå¼äººå·¥æºè½æ¨¡åï¼æ¼èºççç¶ãå°æåºçæ¨¡åè¨ç·´æ¼å¾ LIDC-IDRI å¬å±æ¸æéä¸­æåç 3D é»è¦æ·å±¤ææçç¶ãééèé¡æ¢ç´¢äº VAE çæç 2D åççæ½å¨åéè¡¨ç¤ºï¼ä»¥è­æå¶åè³ªï¼ä¸¦ç¨æ¼èºçè¨ºæ·ç MLP åé¡å¨æ¨¡åï¼æä½³æ¨¡åéå°äº AUC 0.98 å 93.1% æºç¢ºåº¦çæåé²ææ¨ãèé¡åæé¡¯ç¤ºï¼VAE æ½å¨ç©ºéæ ¹æææç¾©çç¹å¾µçµæï¼åæ¬è«ç¤å¤§å°ãå½¢çãæ£èåæ¡æ§é¡å¥ï¼å°æ¡æ§åè¯æ§çç¶çæ¸æéåéãæåéåæ¬æ¨æºé«æ¯ VAE (GVAE) åæ´æ°ççå©åé· VAE (DirVAE) çæ¯è¼åæï¼å¾èç¨çå©åé·åä½åä»£åé©ï¼ä»¥ä¿é²å·æè§£éç¹å¾µè¡¨ç¤ºçæ´å·å¯è§£éæ§çæ½å¨ç©ºéãæå¾ï¼æåå±ç¤ºäºèè¨åºææç¾©çç¹å¾µè®åç¸æçæ½å¨ç©ºéæ©«è¶çæ½åã

##### **MRxaI: Black-Box Explainability for Image Classifiers in a Medical Setting**
2311.14471v1 by Nathan Blake, Hana Chockler, David A. Kelly, Santiago Calderon Pena, Akchunya Chanchal

Existing tools for explaining the output of image classifiers can be divided
into white-box, which rely on access to the model internals, and black-box,
agnostic to the model. As the usage of AI in the medical domain grows, so too
does the usage of explainability tools. Existing work on medical image
explanations focuses on white-box tools, such as gradcam. However, there are
clear advantages to switching to a black-box tool, including the ability to use
it with any classifier and the wide selection of black-box tools available. On
standard images, black-box tools are as precise as white-box. In this paper we
compare the performance of several black-box methods against gradcam on a brain
cancer MRI dataset. We demonstrate that most black-box tools are not suitable
for explaining medical image classifications and present a detailed analysis of
the reasons for their shortcomings. We also show that one black-box tool, a
causal explainability-based rex, performs as well as \gradcam.

æè¦ï¼ç¾æçåååé¡å¨è¼¸åºè§£éå·¥å·å¯åçºä¾è³´æ¼æ¨¡åå§é¨å­åæ¬éçç½çï¼ä»¥åèæ¨¡åç¡éçé»çãé¨è AI å¨é«çé åçä½¿ç¨å¢å ï¼å¯è§£éæ§å·¥å·çä½¿ç¨ä¹é¨ä¹å¢å ãç¾æé«å­¸å½±åè§£éçå·¥ä½éé»å¨æ¼ç½çå·¥å·ï¼ä¾å¦ gradcamãç¶èï¼åæå°é»çå·¥å·ææé¡¯çåªé»ï¼åæ¬è½å¤ èä»»ä½åé¡å¨ä¸èµ·ä½¿ç¨ï¼ä»¥åå»£æ³çé»çå·¥å·å¯ä¾é¸æãå¨æ¨æºå½±åä¸ï¼é»çå·¥å·èç½çä¸æ¨£ç²¾ç¢ºãå¨æ¬æä¸­ï¼æåæ¯è¼äºå¤ç¨®é»çæ¹æ³å¨è¦ç MRI è³æéä¸è gradcam çæè½ãæåè­æå¤§å¤æ¸é»çå·¥å·ä¸é©åè§£éé«å­¸å½±ååé¡ï¼ä¸¦è©³ç´°åæå¶ç¼ºé»çåå ãæåéè¡¨æä¸ç¨®é»çå·¥å·ï¼åºæ¼å æå¯è§£éæ§ç rexï¼è¡¨ç¾è \gradcam ä¸æ¨£å¥½ã

##### **Moderating Model Marketplaces: Platform Governance Puzzles for AI Intermediaries**
2311.12573v3 by Robert Gorwa, Michael Veale

The AI development community is increasingly making use of hosting
intermediaries such as Hugging Face provide easy access to user-uploaded models
and training data. These model marketplaces lower technical deployment barriers
for hundreds of thousands of users, yet can be used in numerous potentially
harmful and illegal ways. In this article, we explain ways in which AI systems,
which can both `contain' content and be open-ended tools, present one of the
trickiest platform governance challenges seen to date. We provide case studies
of several incidents across three illustrative platforms -- Hugging Face,
GitHub and Civitai -- to examine how model marketplaces moderate models.
Building on this analysis, we outline important (and yet nevertheless limited)
practices that industry has been developing to respond to moderation demands:
licensing, access and use restrictions, automated content moderation, and open
policy development. While the policy challenge at hand is a considerable one,
we conclude with some ideas as to how platforms could better mobilize resources
to act as a careful, fair, and proportionate regulatory access point.

æè¦ï¼AI éç¼ç¤¾ç¾¤æ¥çå©ç¨ Hugging Face ç­è¨ç®¡ä¸­ä»æ©æ§æä¾ç¨æ¶ä¸å³çæ¨¡ååè¨ç·´è³æçç°¡æå­åæ¬éãéäºæ¨¡åå¸ééä½äºæ¸åè¬åç¨æ¶çæè¡é¨ç½²éç¤ï¼ä½å¯è½æè¢«ç¨æ¼è¨±å¤æ½å¨æå®³åéæ³çæ¹å¼ãå¨æ¬æä¸­ï¼æåèªªæ AI ç³»çµ±æ¢å¯ä»¥ãåå«ãå§å®¹ï¼åå¯ä»¥ä½çºéæ¾å¼å·¥å·ï¼éæåºäºè¿ä»çºæ­¢ææ£æçå¹³å°æ²»çææ°ä¹ä¸ãæåæä¾ Hugging FaceãGitHub å Civitai ç­ä¸åèªªææ§å¹³å°ä¸æ¸èµ·äºä»¶çæ¡ä¾ç ç©¶ï¼ä»¥æª¢è¦æ¨¡åå¸éå¦ä½å¯©æ ¸æ¨¡åãæ ¹ææ­¤åæï¼æåæ¦è¿°ç¢æ¥­çºåæå¯©æ ¸éæ±èéç¼çéè¦ï¼ä½ä»æéï¼å¯¦åï¼ææ¬ãå­ååä½¿ç¨éå¶ãèªååå§å®¹å¯©æ ¸åéæ¾æ¿ç­å¶å®ãéç¶ç¶åæ¿ç­ææ°ç¸ç¶å¯è§ï¼æåæå¾æåºä¸äºæ§æ³ï¼èªªæå¹³å°å¦ä½è½æ´å¥½å°åå¡è³æºï¼ä½çºè¬¹æãå¬å¹³ä¸é©åº¦çæ³è¦å­åé»ã

##### **Ovarian Cancer Data Analysis using Deep Learning: A Systematic Review from the Perspectives of Key Features of Data Analysis and AI Assurance**
2311.11932v1 by Muta Tah Hira, Mohammad A. Razzaque, Mosharraf Sarker

Background and objectives: By extracting this information, Machine or Deep
Learning (ML/DL)-based autonomous data analysis tools can assist clinicians and
cancer researchers in discovering patterns and relationships from complex data
sets. Many DL-based analyses on ovarian cancer (OC) data have recently been
published. These analyses are highly diverse in various aspects of cancer
(e.g., subdomain(s) and cancer type they address) and data analysis features.
However, a comprehensive understanding of these analyses in terms of these
features and AI assurance (AIA) is currently lacking. This systematic review
aims to fill this gap by examining the existing literature and identifying
important aspects of OC data analysis using DL, explicitly focusing on the key
features and AI assurance perspectives. Methods: The PRISMA framework was used
to conduct comprehensive searches in three journal databases. Only studies
published between 2015 and 2023 in peer-reviewed journals were included in the
analysis. Results: In the review, a total of 96 DL-driven analyses were
examined. The findings reveal several important insights regarding DL-driven
ovarian cancer data analysis: - Most studies 71% (68 out of 96) focused on
detection and diagnosis, while no study addressed the prediction and prevention
of OC. - The analyses were predominantly based on samples from a non-diverse
population (75% (72/96 studies)), limited to a geographic location or country.
- Only a small proportion of studies (only 33% (32/96)) performed integrated
analyses, most of which used homogeneous data (clinical or omics). - Notably, a
mere 8.3% (8/96) of the studies validated their models using external and
diverse data sets, highlighting the need for enhanced model validation, and -
The inclusion of AIA in cancer data analysis is in a very early stage; only
2.1% (2/96) explicitly addressed AIA through explainability.

æè¦ï¼<paragraph>èæ¯åç®æ¨ï¼ééæåéäºè³è¨ï¼æ©å¨ææ·±åº¦å­¸ç¿ (ML/DL) åºæ¼èªä¸»æ¸æåæå·¥å·å¯ä»¥åå©è¨åºé«çåççç ç©¶äººå¡å¾è¤éçæ¸æéä¸­ç¼ç¾æ¨¡å¼åéä¿ãæè¿å·²ç¼è¡¨è¨±å¤åºæ¼ DL çåµå·¢ç (OC) æ¸æåæãéäºåæå¨çççååæ¹é¢ï¼ä¾å¦ï¼å®åæ¶åçå­é ååççé¡åï¼åæ¸æåæåè½æ¹é¢é«åº¦å¤æ¨£åãç¶èï¼ç®åç¼ºä¹å°éäºåæå¨éäºç¹å¾µå AI ä¿è­ (AIA) æ¹é¢çå¨é¢çè§£ãéç¯ç³»çµ±æ§åé¡§æ¨å¨ééæª¢è¦ç¾ææç»ä¸¦æç¢ºéæ³¨ééµç¹å¾µå AI ä¿è­è§é»ï¼ä¾å¡«è£éåç©ºç½ãæ¹æ³ï¼ä½¿ç¨ PRISMA æ¶æ§å¨ä¸åæåè³æåº«ä¸­é²è¡å¨é¢æå°ãåæååæ¬ 2015 å¹´è³ 2023 å¹´éç¼è¡¨æ¼åè¡è©å¯©æåçç ç©¶ãçµæï¼å¨åé¡§ä¸­ï¼ç¸½å±æª¢è¦äº 96 é ç± DL é©åçåæãç ç©¶çµææ­ç¤ºäºå¹¾åéæ¼ç± DL é©åçåµå·¢çæ¸æåæçéè¦è¦è§£ï¼- å¤§å¤æ¸ç ç©¶ 71%ï¼96 é ä¸­æ 68 é ï¼å°æ³¨æ¼æª¢æ¸¬åè¨ºæ·ï¼èæ²æç ç©¶æ¢è¨ OC çé æ¸¬åé é²ã- éäºåæä¸»è¦åºæ¼ä¾èªéå¤åæç¾¤çæ¨£æ¬ï¼75%ï¼96 é ç ç©¶ä¸­ç 72 é ï¼ï¼ï¼åéæ¼æåå°çä½ç½®æåå®¶ã- åªæå°é¨åç ç©¶ï¼å 33%ï¼96 é ç ç©¶ä¸­ç 32 é ï¼å·è¡æ´ååæï¼å¶ä¸­å¤§å¤æ¸ä½¿ç¨åè³ªæ¸æï¼è¨åºæçµå­¸ï¼ã- å¼å¾æ³¨æçæ¯ï¼åªæ 8.3%ï¼96 é ç ç©¶ä¸­ç 8 é ï¼ä½¿ç¨å¤é¨åå¤åæ¸æéé©è­äºå¶æ¨¡åï¼å¼·èª¿äºå å¼·æ¨¡åé©è­çå¿è¦æ§ï¼ä»¥å- å° AIA ç´å¥ççæ¸æåæä»èæ¼éå¸¸æ©æçéæ®µï¼åªæ 2.1%ï¼96 é ç ç©¶ä¸­ç 2 é ï¼ééå¯è§£éæ§æç¢ºæ¢è¨äº AIAã</paragraph>


### Knowledge Graphs
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-12-19**|**Graph-Convolutional Networks: Named Entity Recognition and Large Language Model Embedding in Document Clustering**|Imed Keraghel et.al.|[2412.14867v1](http://arxiv.org/abs/2412.14867v1)|null|
|**2024-12-19**|**Answer Set Networks: Casting Answer Set Programming into Deep Learning**|Arseny Skryagin et.al.|[2412.14814v1](http://arxiv.org/abs/2412.14814v1)|null|
|**2024-12-19**|**IOHunter: Graph Foundation Model to Uncover Online Information Operations**|Marco Minici et.al.|[2412.14663v1](http://arxiv.org/abs/2412.14663v1)|null|
|**2024-12-19**|**GraphEQA: Using 3D Semantic Scene Graphs for Real-time Embodied Question Answering**|Saumya Saxena et.al.|[2412.14480v1](http://arxiv.org/abs/2412.14480v1)|null|
|**2024-12-18**|**Discovering maximally consistent distribution of causal tournaments with Large Language Models**|Federico Baldo et.al.|[2412.14019v1](http://arxiv.org/abs/2412.14019v1)|null|
|**2024-12-18**|**DODGE: Ontology-Aware Risk Assessment via Object-Oriented Disruption Graphs**|Stefano M. Nicoletti et.al.|[2412.13964v1](http://arxiv.org/abs/2412.13964v1)|null|
|**2024-12-18**|**Knowledge Editing with Dynamic Knowledge Graphs for Multi-hop Question Answering**|Yifan Lu et.al.|[2412.13782v1](http://arxiv.org/abs/2412.13782v1)|null|
|**2024-12-18**|**Bridging the User-side Knowledge Gap in Knowledge-aware Recommendations with Large Language Models**|Zheng Hu et.al.|[2412.13544v1](http://arxiv.org/abs/2412.13544v1)|[link](https://github.com/laowangzi/cikgrec)|
|**2024-12-18**|**Benchmarking and Improving Large Vision-Language Models for Fundamental Visual Graph Understanding and Reasoning**|Yingjie Zhu et.al.|[2412.13540v1](http://arxiv.org/abs/2412.13540v1)|[link](https://github.com/aaandy-zhu/vgcure)|
|**2024-12-18**|**Transducer Tuning: Efficient Model Adaptation for Software Tasks Using Code Property Graphs**|Imam Nur Bani Yusuf et.al.|[2412.13467v1](http://arxiv.org/abs/2412.13467v1)|[link](https://github.com/imamnurby/transducer-tuning)|
|**2024-12-17**|**Enhancing Persona Classification in Dialogue Systems: A Graph Neural Network Approach**|Konstantin Zaitsev et.al.|[2412.13283v1](http://arxiv.org/abs/2412.13283v1)|null|
|**2024-12-17**|**Detecting Emotional Incongruity of Sarcasm by Commonsense Reasoning**|Ziqi Qiu et.al.|[2412.12808v1](http://arxiv.org/abs/2412.12808v1)|null|
|**2024-12-17**|**LLM-based Discriminative Reasoning for Knowledge Graph Question Answering**|Mufan Xu et.al.|[2412.12643v1](http://arxiv.org/abs/2412.12643v1)|null|
|**2024-12-17**|**SynthCypher: A Fully Synthetic Data Generation Framework for Text-to-Cypher Querying in Knowledge Graphs**|Aman Tiwari et.al.|[2412.12612v1](http://arxiv.org/abs/2412.12612v1)|null|
|**2024-12-17**|**Graph Learning in the Era of LLMs: A Survey from the Perspective of Data, Models, and Tasks**|Xunkai Li et.al.|[2412.12456v1](http://arxiv.org/abs/2412.12456v1)|null|
|**2024-12-16**|**Graph-Guided Textual Explanation Generation Framework**|Shuzhou Yuan et.al.|[2412.12318v1](http://arxiv.org/abs/2412.12318v1)|null|
|**2024-12-16**|**Cost-Effective Label-free Node Classification with LLMs**|Taiyan Zhang et.al.|[2412.11983v1](http://arxiv.org/abs/2412.11983v1)|null|
|**2024-12-16**|**SE-GCL: An Event-Based Simple and Effective Graph Contrastive Learning for Text Representation**|Tao Meng et.al.|[2412.11652v1](http://arxiv.org/abs/2412.11652v1)|null|
|**2024-12-16**|**EvoLlama: Enhancing LLMs' Understanding of Proteins via Multimodal Structure and Sequence Representations**|Nuowei Liu et.al.|[2412.11618v1](http://arxiv.org/abs/2412.11618v1)|null|
|**2024-12-16**|**Embodied CoT Distillation From LLM To Off-the-shelf Agents**|Wonje Choi et.al.|[2412.11499v1](http://arxiv.org/abs/2412.11499v1)|null|
|**2024-12-16**|**How Can LLMs and Knowledge Graphs Contribute to Robot Safety? A Few-Shot Learning Approach**|Abdulrahman Althobaiti et.al.|[2412.11387v1](http://arxiv.org/abs/2412.11387v1)|null|
|**2024-12-15**|**Embracing Large Language Models in Traffic Flow Forecasting**|Yusheng Zhao et.al.|[2412.12201v1](http://arxiv.org/abs/2412.12201v1)|null|
|**2024-12-15**|**SceneLLM: Implicit Language Reasoning in LLM for Dynamic Scene Graph Generation**|Hang Zhang et.al.|[2412.11026v1](http://arxiv.org/abs/2412.11026v1)|null|
|**2024-12-14**|**MedG-KRP: Medical Graph Knowledge Representation Probing**|Gabriel R. Rosenbaum et.al.|[2412.10982v2](http://arxiv.org/abs/2412.10982v2)|null|
|**2024-12-14**|**Thinking with Knowledge Graphs: Enhancing LLM Reasoning Through Structured Data**|Xue Wu et.al.|[2412.10654v1](http://arxiv.org/abs/2412.10654v1)|null|
|**2024-12-13**|**WHAT-IF: Exploring Branching Narratives by Meta-Prompting Large Language Models**|Runsheng "Anson" Huang et.al.|[2412.10582v2](http://arxiv.org/abs/2412.10582v2)|null|
|**2024-12-13**|**Can LLMs Convert Graphs to Text-Attributed Graphs?**|Zehong Wang et.al.|[2412.10136v1](http://arxiv.org/abs/2412.10136v1)|[link](https://github.com/zehong-wang/tans)|
|**2024-12-13**|**Lost in the Middle, and In-Between: Enhancing Language Models' Ability to Reason Over Long Contexts in Multi-Hop QA**|George Arthur Baker et.al.|[2412.10079v1](http://arxiv.org/abs/2412.10079v1)|[link](https://github.com/spongeorge/long-context-multihop)|
|**2024-12-13**|**Low-Resource Fast Text Classification Based on Intra-Class and Inter-Class Distance Calculation**|Yanxu Mao et.al.|[2412.09922v1](http://arxiv.org/abs/2412.09922v1)|null|
|**2024-12-12**|**MGM: Global Understanding of Audience Overlap Graphs for Predicting the Factuality and the Bias of News Media**|Muhammad Arslan Manzoor et.al.|[2412.10467v1](http://arxiv.org/abs/2412.10467v1)|[link](https://github.com/marslanm/mgm_code)|
|**2024-12-12**|**Uncommon Belief in Rationality**|Qi Shi et.al.|[2412.09407v1](http://arxiv.org/abs/2412.09407v1)|null|
|**2024-12-12**|**Foundation Models and Adaptive Feature Selection: A Synergistic Approach to Video Question Answering**|Sai Bhargav Rongali et.al.|[2412.09230v1](http://arxiv.org/abs/2412.09230v1)|null|
|**2024-12-12**|**Filter-then-Generate: Large Language Models with Structure-Text Adapter for Knowledge Graph Completion**|Ben Liu et.al.|[2412.09094v1](http://arxiv.org/abs/2412.09094v1)|[link](https://github.com/lb0828/ftg)|
|**2024-12-12**|**Neural Interactive Proofs**|Lewis Hammond et.al.|[2412.08897v1](http://arxiv.org/abs/2412.08897v1)|null|
|**2024-12-12**|**A Graph-Based Synthetic Data Pipeline for Scaling High-Quality Reasoning Instructions**|Jiankang Wang et.al.|[2412.08864v1](http://arxiv.org/abs/2412.08864v1)|null|
|**2024-12-11**|**In-Context Learning with Topological Information for Knowledge Graph Completion**|Udari Madhushani Sehwag et.al.|[2412.08742v1](http://arxiv.org/abs/2412.08742v1)|null|
|**2024-12-11**|**VEL: A Formally Verified Reasoner for OWL2 EL Profile**|Atalay Mert Ileri et.al.|[2412.08739v1](http://arxiv.org/abs/2412.08739v1)|null|
|**2024-12-11**|**From communities to interpretable network and word embedding: an unified approach**|Thibault Prouteau et.al.|[2412.08187v1](http://arxiv.org/abs/2412.08187v1)|null|
|**2024-12-11**|**Can Graph Neural Networks Learn Language with Extremely Weak Text Supervision?**|Zihao Li et.al.|[2412.08174v2](http://arxiv.org/abs/2412.08174v2)|null|
|**2024-12-11**|**GraphTool-Instruction: Revolutionizing Graph Reasoning in LLMs through Decomposed Subtask Instruction**|Rongzheng Wang et.al.|[2412.12152v1](http://arxiv.org/abs/2412.12152v1)|null|
|**2024-12-11**|**NAT-NL2GQL: A Novel Multi-Agent Framework for Translating Natural Language to Graph Query Language**|Yuanyuan Liang et.al.|[2412.10434v1](http://arxiv.org/abs/2412.10434v1)|[link](https://github.com/leonyuancode/stockgql)|
|**2024-12-11**|**Repository-Level Graph Representation Learning for Enhanced Security Patch Detection**|Xin-Cheng Wen et.al.|[2412.08068v1](http://arxiv.org/abs/2412.08068v1)|[link](https://github.com/Xin-Cheng-Wen/RepoSPD)|
|**2024-12-11**|**Bootstrapping Heterogeneous Graph Representation Learning via Large Language Models: A Generalized Approach**|Hang Gao et.al.|[2412.08038v2](http://arxiv.org/abs/2412.08038v2)|null|
|**2024-12-10**|**Ontology-Aware RAG for Improved Question-Answering in Cybersecurity Education**|Chengshuai Zhao et.al.|[2412.14191v1](http://arxiv.org/abs/2412.14191v1)|null|
|**2024-12-10**|**Combining knowledge graphs and LLMs for hazardous chemical information management and reuse**|Marcos Da Silveira et.al.|[2412.09644v1](http://arxiv.org/abs/2412.09644v1)|null|
|**2024-12-10**|**Adapting to Non-Stationary Environments: Multi-Armed Bandit Enhanced Retrieval-Augmented Generation on Knowledge Graphs**|Xiaqiang Tang et.al.|[2412.07618v1](http://arxiv.org/abs/2412.07618v1)|[link](https://github.com/futureeeeee/dynamic-rag)|
|**2024-12-10**|**Knowledge Graph Guided Evaluation of Abstention Techniques**|Kinshuk Vasisht et.al.|[2412.07430v1](http://arxiv.org/abs/2412.07430v1)|null|
|**2024-12-10**|**RAG-based Question Answering over Heterogeneous Data and Text**|Philipp Christmann et.al.|[2412.07420v1](http://arxiv.org/abs/2412.07420v1)|null|
|**2024-12-10**|**Generating Knowledge Graphs from Large Language Models: A Comparative Study of GPT-4, LLaMA 2, and BERT**|Ahan Bhatt et.al.|[2412.07412v1](http://arxiv.org/abs/2412.07412v1)|null|
|**2024-12-10**|**My Words Imply Your Opinion: Reader Agent-Based Propagation Enhancement for Personalized Implicit Emotion Analysis**|Jian Liao et.al.|[2412.07367v1](http://arxiv.org/abs/2412.07367v1)|null|
|**2024-12-09**|**ProVision: Programmatically Scaling Vision-centric Instruction Data for Multimodal Language Models**|Jieyu Zhang et.al.|[2412.07012v2](http://arxiv.org/abs/2412.07012v2)|[link](https://github.com/jieyuz2/provision)|
|**2024-12-09**|**Generative Adversarial Reviews: When LLMs Become the Critic**|Nicolas Bougie et.al.|[2412.10415v1](http://arxiv.org/abs/2412.10415v1)|null|
|**2024-12-09**|**A Self-guided Multimodal Approach to Enhancing Graph Representation Learning for Alzheimer's Diseases**|Zhepeng Wang et.al.|[2412.06212v1](http://arxiv.org/abs/2412.06212v1)|null|
|**2024-12-08**|**Automated Extraction and Creation of FBS Design Reasoning Knowledge Graphs from Structured Data in Product Catalogues Lacking Contextual Information**|Vijayalaxmi Sahadevan et.al.|[2412.05868v1](http://arxiv.org/abs/2412.05868v1)|null|
|**2024-12-08**|**A Collaborative Multi-Agent Approach to Retrieval-Augmented Generation Across Diverse Data**|Aniruddha Salve et.al.|[2412.05838v1](http://arxiv.org/abs/2412.05838v1)|null|
|**2024-12-08**|**Large Language Models Merging for Enhancing the Link Stealing Attack on Graph Neural Networks**|Faqian Guan et.al.|[2412.05830v1](http://arxiv.org/abs/2412.05830v1)|null|
|**2024-12-08**|**GL-Fusion: Rethinking the Combination of Graph Neural Network and Large Language model**|Haotong Yang et.al.|[2412.06849v1](http://arxiv.org/abs/2412.06849v1)|null|
|**2024-12-08**|**M$^{3}$-20M: A Large-Scale Multi-Modal Molecule Dataset for AI-driven Drug Design and Discovery**|Siyuan Guo et.al.|[2412.06847v1](http://arxiv.org/abs/2412.06847v1)|[link](https://github.com/bz99bz/m-3)|
|**2024-12-07**|**HMGIE: Hierarchical and Multi-Grained Inconsistency Evaluation for Vision-Language Data Cleansing**|Zihao Zhu et.al.|[2412.05685v1](http://arxiv.org/abs/2412.05685v1)|null|
|**2024-12-07**|**KG-Retriever: Efficient Knowledge Indexing for Retrieval-Augmented Large Language Models**|Weijie Chen et.al.|[2412.05547v1](http://arxiv.org/abs/2412.05547v1)|null|
|**2024-12-06**|**Knowledge Graphs are all you need: Leveraging KGs in Physics Question Answering**|Krishnasai Addala et.al.|[2412.05453v1](http://arxiv.org/abs/2412.05453v1)|null|
|**2024-12-06**|**A Graph-Based Approach for Conversational AI-Driven Personal Memory Capture and Retrieval in a Real-world Application**|Savini Kashmira et.al.|[2412.05447v1](http://arxiv.org/abs/2412.05447v1)|null|
|**2024-12-06**|**KaLM: Knowledge-aligned Autoregressive Language Modeling via Dual-view Knowledge Graph Contrastive Learning**|Peng Yu et.al.|[2412.04948v1](http://arxiv.org/abs/2412.04948v1)|null|
|**2024-12-06**|**HyperGraphOS: A Meta Operating System for Science and Engineering**|Antonello Ceravola et.al.|[2412.04923v1](http://arxiv.org/abs/2412.04923v1)|null|
|**2024-12-06**|**Transformers Struggle to Learn to Search**|Abulhair Saparov et.al.|[2412.04703v1](http://arxiv.org/abs/2412.04703v1)|null|
|**2024-12-06**|**LLM-Align: Utilizing Large Language Models for Entity Alignment in Knowledge Graphs**|Xuan Chen et.al.|[2412.04690v1](http://arxiv.org/abs/2412.04690v1)|null|
|**2024-12-05**|**Retrieval-Augmented Machine Translation with Unstructured Knowledge**|Jiaan Wang et.al.|[2412.04342v1](http://arxiv.org/abs/2412.04342v1)|[link](https://github.com/krystalan/RAGtrans)|
|**2024-12-05**|**GRAF: Graph Retrieval Augmented by Facts for Legal Question Answering**|Cristian-George CrÄciun et.al.|[2412.04119v1](http://arxiv.org/abs/2412.04119v1)|null|
|**2024-12-05**|**MIND: Effective Incorrect Assignment Detection through a Multi-Modal Structure-Enhanced Language Model**|Yunhe Pang et.al.|[2412.03930v1](http://arxiv.org/abs/2412.03930v1)|[link](https://github.com/thudm/whoiswho)|
|**2024-12-05**|**How Good is ChatGPT in Giving Adaptive Guidance Using Knowledge Graphs in E-Learning Environments?**|Patrick Ocheja et.al.|[2412.03856v1](http://arxiv.org/abs/2412.03856v1)|null|
|**2024-12-05**|**Synergizing LLMs and Knowledge Graphs: A Novel Approach to Software Repository-Related Question Answering**|Samuel Abedu et.al.|[2412.03815v1](http://arxiv.org/abs/2412.03815v1)|null|
|**2024-12-05**|**Agent AI with LangGraph: A Modular Framework for Enhancing Machine Translation Using Large Language Models**|Jialin Wang et.al.|[2412.03801v1](http://arxiv.org/abs/2412.03801v1)|null|
|**2024-12-04**|**Language Model Meets Prototypes: Towards Interpretable Text Classification Models through Prototypical Networks**|Ximing Wen et.al.|[2412.03761v1](http://arxiv.org/abs/2412.03761v1)|null|
|**2024-12-04**|**How to Correctly do Semantic Backpropagation on Language-based Agentic Systems**|Wenyi Wang et.al.|[2412.03624v1](http://arxiv.org/abs/2412.03624v1)|[link](https://github.com/hishamalyahya/semantic_backprop)|
|**2024-12-04**|**Enhancing Supply Chain Visibility with Generative AI: An Exploratory Case Study on Relationship Prediction in Knowledge Graphs**|Ge Zheng et.al.|[2412.03390v1](http://arxiv.org/abs/2412.03390v1)|null|
|**2024-12-04**|**CBEval: A framework for evaluating and interpreting cognitive biases in LLMs**|Ammar Shaikh et.al.|[2412.03605v1](http://arxiv.org/abs/2412.03605v1)|null|
|**2024-12-03**|**Hybrid-SQuAD: Hybrid Scholarly Question Answering Dataset**|Tilahun Abedissa Taffa et.al.|[2412.02788v2](http://arxiv.org/abs/2412.02788v2)|[link](https://github.com/semantic-systems/hybrid-squad)|
|**2024-12-03**|**Characterizing Information Shared by Participants to Coding Challenges: The Case of Advent of Code**|Francesco Cauteruccio et.al.|[2412.02290v1](http://arxiv.org/abs/2412.02290v1)|null|
|**2024-12-02**|**A Neurosymbolic Fast and Slow Architecture for Graph Coloring**|Vedant Khandelwal et.al.|[2412.01752v1](http://arxiv.org/abs/2412.01752v1)|null|
|**2024-12-02**|**Intelligent Spark Agents: A Modular LangGraph Framework for Scalable, Visualized, and Enhanced Big Data Machine Learning Workflows**|Jialin Wang et.al.|[2412.01490v4](http://arxiv.org/abs/2412.01490v4)|null|
|**2024-12-01**|**SelfPrompt: Autonomously Evaluating LLM Robustness via Domain-Constrained Knowledge Guidelines and Refined Adversarial Prompts**|Aihua Pei et.al.|[2412.00765v1](http://arxiv.org/abs/2412.00765v1)|null|
|**2024-11-30**|**Leveraging LLM for Automated Ontology Extraction and Knowledge Graph Generation**|Mohammad Sadeq Abolhasani et.al.|[2412.00608v3](http://arxiv.org/abs/2412.00608v3)|null|
|**2024-11-30**|**Opus: A Large Work Model for Complex Workflow Generation**|ThÃ©o Fagnoni et.al.|[2412.00573v2](http://arxiv.org/abs/2412.00573v2)|null|
|**2024-11-30**|**Neural-Symbolic Reasoning over Knowledge Graphs: A Survey from a Query Perspective**|Lihui Liu et.al.|[2412.10390v1](http://arxiv.org/abs/2412.10390v1)|null|
|**2024-11-30**|**Node Importance Estimation Leveraging LLMs for Semantic Augmentation in Knowledge Graphs**|Xinyu Lin et.al.|[2412.00478v1](http://arxiv.org/abs/2412.00478v1)|[link](https://github.com/xinyulin-fz/lenie)|
|**2024-11-29**|**An AI-Driven Data Mesh Architecture Enhancing Decision-Making in Infrastructure Construction and Public Procurement**|Saurabh Mishra et.al.|[2412.00224v1](http://arxiv.org/abs/2412.00224v1)|null|
|**2024-11-29**|**PerLA: Perceptive 3D Language Assistant**|Guofeng Mei et.al.|[2411.19774v1](http://arxiv.org/abs/2411.19774v1)|null|
|**2024-11-29**|**Knowledge Management for Automobile Failure Analysis Using Graph RAG**|Yuta Ojima et.al.|[2411.19539v1](http://arxiv.org/abs/2411.19539v1)|null|
|**2024-11-28**|**Way to Specialist: Closing Loop Between Specialized LLM and Evolving Domain Knowledge Graph**|Yutong Zhang et.al.|[2411.19064v1](http://arxiv.org/abs/2411.19064v1)|null|
|**2024-11-28**|**EzSQL: An SQL intermediate representation for improving SQL-to-text Generation**|Meher Bhardwaj et.al.|[2411.18923v1](http://arxiv.org/abs/2411.18923v1)|null|
|**2024-11-27**|**MLLM-Search: A Zero-Shot Approach to Finding People using Multimodal Large Language Models**|Angus Fung et.al.|[2412.00103v1](http://arxiv.org/abs/2412.00103v1)|null|
|**2024-11-27**|**Human Evaluation of Procedural Knowledge Graph Extraction from Text with Large Language Models**|Valentina Anita Carriero et.al.|[2412.03589v1](http://arxiv.org/abs/2412.03589v1)|null|
|**2024-11-27**|**Regularized Multi-LLMs Collaboration for Enhanced Score-based Causal Discovery**|Xiaoxuan Li et.al.|[2411.17989v1](http://arxiv.org/abs/2411.17989v1)|null|
|**2024-11-26**|**ShowUI: One Vision-Language-Action Model for GUI Visual Agent**|Kevin Qinghong Lin et.al.|[2411.17465v1](http://arxiv.org/abs/2411.17465v1)|[link](https://github.com/showlab/showui)|
|**2024-11-26**|**Can LLMs be Good Graph Judger for Knowledge Graph Construction?**|Haoyu Huang et.al.|[2411.17388v1](http://arxiv.org/abs/2411.17388v1)|[link](https://github.com/hhy-huang/graphjudger)|
|**2024-11-26**|**Interleaved Scene Graph for Interleaved Text-and-Image Generation Assessment**|Dongping Chen et.al.|[2411.17188v1](http://arxiv.org/abs/2411.17188v1)|null|
|**2024-11-25**|**AtomR: Atomic Operator-Empowered Large Language Models for Heterogeneous Knowledge Reasoning**|Amy Xin et.al.|[2411.16495v2](http://arxiv.org/abs/2411.16495v2)|[link](https://github.com/THU-KEG/AtomR)|
|**2024-11-25**|**Learning by Analogy: Enhancing Few-Shot Prompting for Math Word Problem Solving with Computational Graph-Based Retrieval**|Xiaocong Yang et.al.|[2411.16454v1](http://arxiv.org/abs/2411.16454v1)|null|
|**2024-11-25**|**Adapter-based Approaches to Knowledge-enhanced Language Models -- A Survey**|Alexander Fichtl et.al.|[2411.16403v1](http://arxiv.org/abs/2411.16403v1)|null|
|**2024-11-24**|**Decoding Urban Industrial Complexity: Enhancing Knowledge-Driven Insights via IndustryScopeGPT**|Siqi Wang et.al.|[2411.15758v1](http://arxiv.org/abs/2411.15758v1)|[link](https://github.com/tongji-kgllm/industryscope)|

#### Abstracts
##### **Graph-Convolutional Networks: Named Entity Recognition and Large Language Model Embedding in Document Clustering**
2412.14867v1 by Imed Keraghel, Mohamed Nadif

Recent advances in machine learning, particularly Large Language Models
(LLMs) such as BERT and GPT, provide rich contextual embeddings that improve
text representation. However, current document clustering approaches often
ignore the deeper relationships between named entities (NEs) and the potential
of LLM embeddings. This paper proposes a novel approach that integrates Named
Entity Recognition (NER) and LLM embeddings within a graph-based framework for
document clustering. The method builds a graph with nodes representing
documents and edges weighted by named entity similarity, optimized using a
graph-convolutional network (GCN). This ensures a more effective grouping of
semantically related documents. Experimental results indicate that our approach
outperforms conventional co-occurrence-based methods in clustering, notably for
documents rich in named entities.

æè¦ï¼è¿ææ©å¨å­¸ç¿çé²å±ï¼ç¹å¥æ¯å¤§åèªè¨æ¨¡å (LLM)ï¼ä¾å¦ BERT å GPTï¼æä¾äºè±å¯çä¸ä¸æåµå¥ï¼æ¹é²äºææ¬è¡¨å¾µãç¶èï¼ç¶åçæä»¶åç¾¤æ¹æ³éå¸¸å¿½ç¥å½åå¯¦é« (NE) ä¹éæ´æ·±å±¤çéä¿å LLM åµå¥çæ½åãæ¬ææåºäºä¸ç¨®åµæ°çæ¹æ³ï¼å°å½åå¯¦é«è¾¨è­ (NER) å LLM åµå¥æ´åå°åºæ¼åå½¢çæ¶æ§ä¸­ï¼ä»¥é²è¡æä»¶åç¾¤ãè©²æ¹æ³å»ºç«äºä¸ååå½¢ï¼å¶ä¸­ç¯é»ä»£è¡¨æä»¶ï¼éç·£åç±å½åå¯¦é«ç¸ä¼¼æ§å æ¬ï¼ä¸¦ä½¿ç¨åå½¢å·ç©ç¶²è·¯ (GCN) é²è¡æä½³åãéç¢ºä¿äºèªç¾©ç¸éæä»¶æ´ææçåçµãå¯¦é©çµæè¡¨æï¼æåçåæ³åªæ¼å³çµ±çå±ç¾æ¹æ³å¨åç¾¤ä¸­çè¡¨ç¾ï¼ç¹å¥æ¯å°æ¼å¯å«å½åå¯¦é«çæä»¶ã

##### **Answer Set Networks: Casting Answer Set Programming into Deep Learning**
2412.14814v1 by Arseny Skryagin, Daniel Ochs, Phillip Deibert, Simon Kohaut, Devendra Singh Dhami, Kristian Kersting

Although Answer Set Programming (ASP) allows constraining neural-symbolic
(NeSy) systems, its employment is hindered by the prohibitive costs of
computing stable models and the CPU-bound nature of state-of-the-art solvers.
To this end, we propose Answer Set Networks (ASN), a NeSy solver. Based on
Graph Neural Networks (GNN), ASNs are a scalable approach to ASP-based Deep
Probabilistic Logic Programming (DPPL). Specifically, we show how to translate
ASPs into ASNs and demonstrate how ASNs can efficiently solve the encoded
problem by leveraging GPU's batching and parallelization capabilities. Our
experimental evaluations demonstrate that ASNs outperform state-of-the-art
CPU-bound NeSy systems on multiple tasks. Simultaneously, we make the following
two contributions based on the strengths of ASNs. Namely, we are the first to
show the finetuning of Large Language Models (LLM) with DPPLs, employing ASNs
to guide the training with logic. Further, we show the "constitutional
navigation" of drones, i.e., encoding public aviation laws in an ASN for
routing Unmanned Aerial Vehicles in uncertain environments.

æè¦ï¼åç®¡ç­æ¡éç¨å¼è¨­è¨ï¼ASPï¼åè¨±ç´æç¥ç¶ç¬¦èï¼NeSyï¼ç³»çµ±ï¼ä½å¶æç¨åå°è¨ç®ç©©å®æ¨¡åçéé«ææ¬åç¾ææ±è§£å¨å CPU éå¶çæ¬è³ªæé»ç¤ãçºæ­¤ï¼æåæåºç­æ¡éç¶²è·¯ï¼ASNï¼ï¼ä¸å NeSy æ±è§£å¨ãASN åºæ¼åç¥ç¶ç¶²è·¯ï¼GNNï¼ï¼æ¯ä¸ç¨®åºæ¼ ASP çæ·±åº¦æ©çéè¼¯ç¨å¼è¨­è¨ï¼DPPLï¼çå¯æ´åæ¹æ³ãå·é«ä¾èªªï¼æåå±ç¤ºå¦ä½å° ASP è½æçº ASNï¼ä¸¦å±ç¤º ASN å¦ä½ééå©ç¨ GPU çæ¹æ¬¡èçåä¸¦è¡ååè½ææå°è§£æ±ºç·¨ç¢¼åé¡ãæåçå¯¦é©è©ä¼°è¡¨æï¼ASN å¨å¤é ä»»åä¸åªæ¼ç¾æçå CPU éå¶ç NeSy ç³»çµ±ãåæï¼æåæ ¹æ ASN çåªå¢ååºäºä»¥ä¸å©é è²¢ç»ãä¹å°±æ¯èªªï¼æåé¦æ¬¡å±ç¤ºä½¿ç¨ DPPL å°å¤§åèªè¨æ¨¡åï¼LLMï¼é²è¡å¾®èª¿ï¼ä½¿ç¨ ASN ä»¥éè¼¯å¼å°è¨ç·´ãæ­¤å¤ï¼æåå±ç¤ºäºç¡äººæ©çãæ²æ³å°èªãï¼å³å¨ ASN ä¸­ç·¨ç¢¼å¬å±èªç©ºæ³ï¼ä»¥ä¾¿å¨ä¸ç¢ºå®çç°å¢ä¸­å°ç¡äººæ©é²è¡è·¯ç±ã

##### **IOHunter: Graph Foundation Model to Uncover Online Information Operations**
2412.14663v1 by Marco Minici, Luca Luceri, Francesco Fabbri, Emilio Ferrara

Social media platforms have become vital spaces for public discourse, serving
as modern agor\'as where a wide range of voices influence societal narratives.
However, their open nature also makes them vulnerable to exploitation by
malicious actors, including state-sponsored entities, who can conduct
information operations (IOs) to manipulate public opinion. The spread of
misinformation, false news, and misleading claims threatens democratic
processes and societal cohesion, making it crucial to develop methods for the
timely detection of inauthentic activity to protect the integrity of online
discourse. In this work, we introduce a methodology designed to identify users
orchestrating information operations, a.k.a. \textit{IO drivers}, across
various influence campaigns. Our framework, named \texttt{IOHunter}, leverages
the combined strengths of Language Models and Graph Neural Networks to improve
generalization in \emph{supervised}, \emph{scarcely-supervised}, and
\emph{cross-IO} contexts. Our approach achieves state-of-the-art performance
across multiple sets of IOs originating from six countries, significantly
surpassing existing approaches. This research marks a step toward developing
Graph Foundation Models specifically tailored for the task of IO detection on
social media platforms.

æè¦ï¼ç¤¾äº¤åªé«å¹³å°å·²æçºå¬å±è«è¿°çéè¦ç©ºéï¼ä½çºç¾ä»£å»£å ´ï¼åç¨®è²é³å½±é¿èç¤¾ææäºãç¶èï¼å®åçéæ¾æ§ä¹ä½¿å¾å®åå®¹æåå°æ¡æè¡çºèçå©ç¨ï¼åæ¬åå®¶è³å©çå¯¦é«ï¼ä»åå¯ä»¥é²è¡ä¿¡æ¯æä½ (IO) ä»¥æç¸±è¼¿è«ãé¯èª¤ä¿¡æ¯çå³æ­ãèåæ°èåèª¤å°æ§èªªæ³å¨èèæ°ä¸»é²ç¨åç¤¾æåèåï¼å æ­¤å¶å®åææª¢æ¸¬èåæ´»åä»¥ä¿è­·å¨ç·è«è¿°çå®æ´æ§çæ¹æ³è³ééè¦ãå¨éé å·¥ä½ä¸­ï¼æåä»ç´¹äºä¸ç¨®æ¹æ³ï¼æ¨å¨è­å¥å¨åç¨®å½±é¿åéåä¸­ç­åä¿¡æ¯è¡åçç¨æ¶ï¼å³æè¬çãIO é©åç¨åºããæåçæ¡æ¶åçº \texttt{IOHunter}ï¼å®å©ç¨èªè¨æ¨¡åååç¥ç¶ç¶²è·¯çç¶ååªå¢ä¾æ¹åãç£ç£ãããç¨çç£ç£ãåãè·¨ IOãæå¢ä¸­çæ³åè½åãæåçåæ³å¨ä¾èªå­ååå®¶çå¤çµ IO ä¸­å¯¦ç¾äºæåé²çæ§è½ï¼é¡¯èè¶è¶äºç¾ææ¹æ³ãéé ç ç©¶æ¨èªèå°ééå°ç¤¾äº¤åªé«å¹³å°ä¸ç IO æª¢æ¸¬ä»»åéç¼ååºç¤æ¨¡åéåºäºä¸æ­¥ã

##### **GraphEQA: Using 3D Semantic Scene Graphs for Real-time Embodied Question Answering**
2412.14480v1 by Saumya Saxena, Blake Buchanan, Chris Paxton, Bingqing Chen, Narunas Vaskevicius, Luigi Palmieri, Jonathan Francis, Oliver Kroemer

In Embodied Question Answering (EQA), agents must explore and develop a
semantic understanding of an unseen environment in order to answer a situated
question with confidence. This remains a challenging problem in robotics, due
to the difficulties in obtaining useful semantic representations, updating
these representations online, and leveraging prior world knowledge for
efficient exploration and planning. Aiming to address these limitations, we
propose GraphEQA, a novel approach that utilizes real-time 3D metric-semantic
scene graphs (3DSGs) and task relevant images as multi-modal memory for
grounding Vision-Language Models (VLMs) to perform EQA tasks in unseen
environments. We employ a hierarchical planning approach that exploits the
hierarchical nature of 3DSGs for structured planning and semantic-guided
exploration. Through experiments in simulation on the HM-EQA dataset and in the
real world in home and office environments, we demonstrate that our method
outperforms key baselines by completing EQA tasks with higher success rates and
fewer planning steps.

æè¦ï¼å¨å·èº«åç­ (EQA) ä¸­ï¼ä»£çå¿é æ¢ç´¢ä¸¦ç¼å±å°æªè¦éç°å¢çèªç¾©çè§£ï¼æè½æä¿¡å¿å°åç­æå¢åé¡ãç±æ¼é£ä»¥åå¾æç¨çèªç¾©è¡¨ç¤ºãç·ä¸æ´æ°éäºè¡¨ç¤ºï¼ä»¥åå©ç¨ååçä¸çç¥è­é²è¡ææççæ¢ç´¢åè¦åï¼éå¨æ©å¨äººå­¸ä¸­ä»ç¶æ¯ä¸åå·æææ°æ§çåé¡ãçºäºè§£æ±ºéäºéå¶ï¼æåæåº GraphEQAï¼ä¸ç¨®å©ç¨å³æ 3D åº¦éèªç¾©å ´æ¯å (3DSG) åèä»»åç¸éçå½±åä½çºå¤æ¨¡å¼è¨æ¶é«çæ°ç©æ¹æ³ï¼ä»¥æ¥å°è¦è¦ºèªè¨æ¨¡å (VLM) ä¾å·è¡æªè¦éç°å¢ä¸­ç EQA ä»»åãæåæ¡ç¨åå±¤è¦åæ¹æ³ï¼å©ç¨ 3DSG çåå±¤æ§è³ªé²è¡çµæ§åè¦ååèªç¾©å¼å°æ¢ç´¢ãééå¨ HM-EQA è³æéä¸çæ¨¡æ¬å¯¦é©ï¼ä»¥åå¨å®¶åº­åè¾¦å¬å®¤ç°å¢ä¸­ççå¯¦ä¸çä¸­ï¼æåè­ææåçæ¨¡åééä»¥è¼é«çæåçåè¼å°çè¦åæ­¥é©å®æ EQA ä»»åï¼åªæ¼ä¸»è¦çåºç·ã

##### **Discovering maximally consistent distribution of causal tournaments with Large Language Models**
2412.14019v1 by Federico Baldo, Simon Ferreira, Charles K. Assaad

Causal discovery is essential for understanding complex systems, yet
traditional methods often depend on strong, untestable assumptions, making the
process challenging. Large Language Models (LLMs) present a promising
alternative for extracting causal insights from text-based metadata, which
consolidates domain expertise. However, LLMs are prone to unreliability and
hallucinations, necessitating strategies that account for their limitations.
One such strategy involves leveraging a consistency measure to evaluate
reliability. Additionally, most text metadata does not clearly distinguish
direct causal relationships from indirect ones, further complicating the
inference of causal graphs. As a result, focusing on causal orderings, rather
than causal graphs, emerges as a more practical and robust approach. We propose
a novel method to derive a distribution of acyclic tournaments (representing
plausible causal orders) that maximizes a consistency score. Our approach
begins by computing pairwise consistency scores between variables, yielding a
cyclic tournament that aggregates these scores. From this structure, we
identify optimal acyclic tournaments compatible with the original tournament,
prioritizing those that maximize consistency across all configurations. We
tested our method on both classical and well-established bechmarks, as well as
real-world datasets from epidemiology and public health. Our results
demonstrate the effectiveness of our approach in recovering distributions
causal orders with minimal error.

æè¦ï¼å æç¼ç¾å°æ¼çè§£è¤éç³»çµ±è³ééè¦ï¼ä½å³çµ±æ¹æ³éå¸¸ä¾è³´æ¼å¼·èä¸å¯æ¸¬è©¦çåè¨­ï¼éä½¿å¾éåéç¨åæ»¿ææ°ãå¤§åèªè¨æ¨¡å (LLM) æä¾äºä¸åå¾åºæ¼ææ¬çåæ¸æä¸­æåå æè¦è§£çæå¸æçæ¿ä»£æ¹æ¡ï¼å®æ´åäºé åå°æ¥­ç¥è­ãç¶èï¼LLM å®¹æåºç¾ä¸å¯é æ§åå¹»è¦ºï¼ééè¦èæ®å¶éå¶çç­ç¥ãä¸ç¨®éæ¨£çç­ç¥æ¶åå©ç¨ä¸è´æ§åº¦éä¾è©ä¼°å¯é æ§ãæ­¤å¤ï¼å¤§å¤æ¸ææ¬åæ¸æä¸¦æªæ¸æ¥å°ååç´æ¥å æéä¿åéæ¥å æéä¿ï¼éé²ä¸æ­¥è¤éåäºå æåçæ¨è«ãå æ­¤ï¼å°æ³¨æ¼å æé åºï¼èä¸æ¯å æåï¼æçºä¸ç¨®æ´å¯¦ç¨ãæ´ç©©å¥çæ¹æ³ãæåæåºäºä¸ç¨®æ°æ¹æ³ä¾æ¨å°ç¡ç°é¦æ¨è³½çåå¸ï¼è¡¨ç¤ºåççå æé åºï¼ï¼éæå¤§åäºä¸è´æ§åæ¸ãæåçåæ³é¦åè¨ç®è®éä¹éæå°çä¸è´æ§åæ¸ï¼ç¢çä¸åå½ç¸½éäºåæ¸çå¾ªç°é¦æ¨è³½ãå¾éåçµæ§ä¸­ï¼æåè­å¥åºèåå§é¦æ¨è³½ç¸å®¹çæä½³ç¡ç°é¦æ¨è³½ï¼åªåèæ®é£äºå¨ææéç½®ä¸­æå¤§åä¸è´æ§çé¦æ¨è³½ãæåå¨ç¶å¸ä¸å®åçåºæºä»¥åä¾èªæµè¡çå­¸åå¬å±è¡çççå¯¦ä¸çæ¸æéä¸æ¸¬è©¦äºæåçæ¨¡åãæåççµæè­æäºæåçæ¹æ³å¨ä»¥æå°èª¤å·®æ¢å¾©å æé åºåå¸æ¹é¢çæææ§ã

##### **DODGE: Ontology-Aware Risk Assessment via Object-Oriented Disruption Graphs**
2412.13964v1 by Stefano M. Nicoletti, E. Moritz Hahn, Mattia Fumagalli, Giancarlo Guizzardi, MariÃ«lle Stoelinga

When considering risky events or actions, we must not downplay the role of
involved objects: a charged battery in our phone averts the risk of being
stranded in the desert after a flat tyre, and a functional firewall mitigates
the risk of a hacker intruding the network. The Common Ontology of Value and
Risk (COVER) highlights how the role of objects and their relationships remains
pivotal to performing transparent, complete and accountable risk assessment. In
this paper, we operationalize some of the notions proposed by COVER -- such as
parthood between objects and participation of objects in events/actions -- by
presenting a new framework for risk assessment: DODGE. DODGE enriches the
expressivity of vetted formal models for risk -- i.e., fault trees and attack
trees -- by bridging the disciplines of ontology and formal methods into an
ontology-aware formal framework composed by a more expressive modelling
formalism, Object-Oriented Disruption Graphs (ODGs), logic (ODGLog) and an
intermediate query language (ODGLang). With these, DODGE allows risk assessors
to pose questions about disruption propagation, disruption likelihood and risk
levels, keeping the fundamental role of objects at risk always in sight.

æè¦ï¼å¨èéé«é¢¨éªäºä»¶æè¡åæï¼æåä¸è½ä½ä¼°ææ¶ç©ä»¶çè§è²ï¼ææ©ä¸­çåé»é»æ± å¯é¿åå¨çèå¾åå°æ²æ¼ çé¢¨éªï¼èåè½æ­£å¸¸çé²ç«çåå¯éä½é§­å®¢å¥ä¾µç¶²è·¯çé¢¨éªãå¹å¼èé¢¨éªçå±ç¨æ¬ä½è« (COVER) å¼·èª¿ç©ä»¶åå¶éä¿çè§è²ï¼å°æ¼å·è¡éæãå®æ´ä¸è² è²¬ä»»çé¢¨éªè©ä¼°ä»ç¶è³ééè¦ãå¨æ¬æä¸­ï¼æåå° COVER ææåºçé¨åæ¦å¿µï¼ä¾å¦ç©ä»¶ä¹éççµæé¨åéä¿ï¼ä»¥åç©ä»¶åèäºä»¶/è¡åï¼å·é«åï¼èç±æåºä¸åæ°çé¢¨éªè©ä¼°æ¶æ§ï¼DODGEãDODGE ééå°æ¬ä½è«èå½¢å¼åæ¹æ³æ©æ¥è³ä¸åæ¬ä½è«æç¥å½¢å¼åæ¶æ§ä¸­ï¼è±å¯äºé¢¨éªé©è­å½¢å¼åæ¨¡åï¼ä¾å¦æéæ¨¹åæ»ææ¨¹ï¼çè¡¨éåï¼è©²æ¶æ§ç±æ´å·è¡¨éåçå»ºæ¨¡å½¢å¼ä¸»ç¾©ãç©ä»¶å°åä¸­æ·å (ODG)ãéè¼¯ (ODGLog) åä¸åä¸­éæ¥è©¢èªè¨ (ODGLang) çµæãéééäºï¼DODGE è®é¢¨éªè©ä¼°èè½å¤ æåºæéä¸­æ·å³æ­ãä¸­æ·å¯è½æ§åé¢¨éªå±¤ç´çåé¡ï¼åæå§çµä¿æå°é¢¨éªç©ä»¶çåºæ¬è§è²çéæ³¨ã

##### **Knowledge Editing with Dynamic Knowledge Graphs for Multi-hop Question Answering**
2412.13782v1 by Yifan Lu, Yigeng Zhou, Jing Li, Yequan Wang, Xuebo Liu, Daojing He, Fangming Liu, Min Zhang

Multi-hop question answering (MHQA) poses a significant challenge for large
language models (LLMs) due to the extensive knowledge demands involved.
Knowledge editing, which aims to precisely modify the LLMs to incorporate
specific knowledge without negatively impacting other unrelated knowledge,
offers a potential solution for addressing MHQA challenges with LLMs. However,
current solutions struggle to effectively resolve issues of knowledge
conflicts. Most parameter-preserving editing methods are hindered by inaccurate
retrieval and overlook secondary editing issues, which can introduce noise into
the reasoning process of LLMs. In this paper, we introduce KEDKG, a novel
knowledge editing method that leverages a dynamic knowledge graph for MHQA,
designed to ensure the reliability of answers. KEDKG involves two primary
steps: dynamic knowledge graph construction and knowledge graph augmented
generation. Initially, KEDKG autonomously constructs a dynamic knowledge graph
to store revised information while resolving potential knowledge conflicts.
Subsequently, it employs a fine-grained retrieval strategy coupled with an
entity and relation detector to enhance the accuracy of graph retrieval for LLM
generation. Experimental results on benchmarks show that KEDKG surpasses
previous state-of-the-art models, delivering more accurate and reliable answers
in environments with dynamic information.

æè¦ï¼å¤è·³åé¡åç­ (MHQA) ç±æ¼æ¶åå»£æ³çç¥è­éæ±ï¼å°å¤§åèªè¨æ¨¡å (LLM) æ§æéå¤§ææ°ãç¥è­ç·¨è¼¯æ¨å¨ç²¾ç¢ºä¿®æ¹ LLM ä»¥ç´å¥ç¹å®ç¥è­ï¼èä¸æå°å¶ä»ä¸ç¸éçç¥è­ç¢çè² é¢å½±é¿ï¼çºäºè§£æ±º LLM ç MHQA ææ°æä¾äºæ½å¨çè§£æ±ºæ¹æ¡ãç¶èï¼ç®åçè§£æ±ºæ¹æ¡é£ä»¥ææè§£æ±ºç¥è­è¡çªçåé¡ãå¤§å¤æ¸åæ¸ä¿çç·¨è¼¯æ¹æ³åå°ä¸æºç¢ºæª¢ç´¢çé»ç¤ï¼ä¸¦ä¸å¿½è¦äºæ¬¡è¦ç·¨è¼¯åé¡ï¼éå¯è½æå¨ LLM çæ¨çéç¨ä¸­å¼å¥éè¨ãå¨æ¬æä¸­ï¼æåä»ç´¹äº KEDKGï¼éæ¯ä¸ç¨®æ°ç©çç¥è­ç·¨è¼¯æ¹æ³ï¼å®å©ç¨åæç¥è­åè­é²è¡ MHQAï¼æ¨å¨ç¢ºä¿ç­æ¡çå¯é æ§ãKEDKG æ¶åå©åä¸»è¦æ­¥é©ï¼åæç¥è­åè­æ§å»ºåç¥è­åè­å¢å¼·çæãæåï¼KEDKG èªä¸»æ§å»ºåæç¥è­åè­ä»¥å²å­ä¿®æ¹å¾çè³è¨ï¼åæè§£æ±ºæ½å¨çç¥è­è¡çªãé¨å¾ï¼å®æ¡ç¨ç²¾ç´°çæª¢ç´¢ç­ç¥ï¼çµåå¯¦é«åéä¿æª¢æ¸¬å¨ï¼ä»¥å¢å¼· LLM çæçåè­æª¢ç´¢çæºç¢ºæ§ãåºæºä¸çå¯¦é©çµæè¡¨æï¼KEDKG è¶è¶äºä»¥åæåé²çæ¨¡åï¼å¨åæè³è¨ç°å¢ä¸­æä¾äºæ´æºç¢ºåå¯é çç­æ¡ã

##### **Bridging the User-side Knowledge Gap in Knowledge-aware Recommendations with Large Language Models**
2412.13544v1 by Zheng Hu, Zhe Li, Ziyun Jiao, Satoshi Nakagawa, Jiawen Deng, Shimin Cai, Tao Zhou, Fuji Ren

In recent years, knowledge graphs have been integrated into recommender
systems as item-side auxiliary information, enhancing recommendation accuracy.
However, constructing and integrating structural user-side knowledge remains a
significant challenge due to the improper granularity and inherent scarcity of
user-side features. Recent advancements in Large Language Models (LLMs) offer
the potential to bridge this gap by leveraging their human behavior
understanding and extensive real-world knowledge. Nevertheless, integrating
LLM-generated information into recommender systems presents challenges,
including the risk of noisy information and the need for additional knowledge
transfer. In this paper, we propose an LLM-based user-side knowledge inference
method alongside a carefully designed recommendation framework to address these
challenges. Our approach employs LLMs to infer user interests based on
historical behaviors, integrating this user-side information with item-side and
collaborative data to construct a hybrid structure: the Collaborative Interest
Knowledge Graph (CIKG). Furthermore, we propose a CIKG-based recommendation
framework that includes a user interest reconstruction module and a
cross-domain contrastive learning module to mitigate potential noise and
facilitate knowledge transfer. We conduct extensive experiments on three
real-world datasets to validate the effectiveness of our method. Our approach
achieves state-of-the-art performance compared to competitive baselines,
particularly for users with sparse interactions.

æè¦ï¼è¿å¹´ä¾ï¼ç¥è­åè­å·²æ´åå°æ¨è¦ç³»çµ±ä¸­ï¼ä½çºé ç®å´è¼å©è³è¨ï¼æåæ¨è¦æºç¢ºåº¦ã
ç¶èï¼ç±æ¼ä½¿ç¨èå´ç¹å¾µçç²åº¦ä¸ç¶åå§å¨ç¨å°æ§ï¼å»ºæ§åæ´åçµæ§åä½¿ç¨èå´ç¥è­ä»ç¶æ¯ä¸é éå¤§ææ°ã
å¤§åèªè¨æ¨¡å (LLM) çææ°é²å±æä¾äºå½åæ­¤å·®è·çæ½åï¼æ¹æ³æ¯å©ç¨å®åå°äººé¡è¡çºççè§£åå»£æ³ççå¯¦ä¸çç¥è­ã
åç®¡å¦æ­¤ï¼å° LLM çæçè³è¨æ´åå°æ¨è¦ç³»çµ±ä¸­æå¸¶ä¾ææ°ï¼åæ¬éè¨è³è¨çé¢¨éªåéè¦é¡å¤çç¥è­è½ç§»ã
å¨æ¬æä¸­ï¼æåæåºäºä¸ç¨®åºæ¼ LLM çä½¿ç¨èå´ç¥è­æ¨è«æ¹æ³ï¼ä»¥åä¸åç²¾å¿è¨­è¨çæ¨è¦æ¶æ§ï¼ä»¥æå°éäºææ°ã
æåçåæ³æ¡ç¨ LLM ä¾æ¨è«åºæ¼æ­·å²è¡çºçä½¿ç¨èèè¶£ï¼å°æ­¤ä½¿ç¨èå´è³è¨èé ç®å´ååä½è³ææ´åèµ·ä¾ï¼ä»¥å»ºæ§ä¸åæ··åçµæ§ï¼åä½èè¶£ç¥è­åè­ (CIKG)ã
æ­¤å¤ï¼æåæåºäºä¸ååºæ¼ CIKG çæ¨è¦æ¶æ§ï¼å¶ä¸­åæ¬ä½¿ç¨èèè¶£éå»ºæ¨¡çµåè·¨ç¶²åå°æ¯å­¸ç¿æ¨¡çµï¼ä»¥æ¸è¼æ½å¨éè¨ä¸¦ä¿é²ç¥è­è½ç§»ã
æåå°ä¸åçå¯¦ä¸çè³æéé²è¡äºå»£æ³çå¯¦é©ï¼ä»¥é©è­æåæ¹æ³çæææ§ã
èç«¶ç­åºæºç¸æ¯ï¼æåçåæ³éå°äºæåé²çæè½ï¼ç¹å¥æ¯å°æ¼äºåç¨ççä½¿ç¨èã

##### **Benchmarking and Improving Large Vision-Language Models for Fundamental Visual Graph Understanding and Reasoning**
2412.13540v1 by Yingjie Zhu, Xuefeng Bai, Kehai Chen, Yang Xiang, Min Zhang

Large Vision-Language Models (LVLMs) have demonstrated remarkable performance
across diverse tasks. Despite great success, recent studies show that LVLMs
encounter substantial limitations when engaging with visual graphs. To study
the reason behind these limitations, we propose VGCure, a comprehensive
benchmark covering 22 tasks for examining the fundamental graph understanding
and reasoning capacities of LVLMs. Extensive evaluations conducted on 14 LVLMs
reveal that LVLMs are weak in basic graph understanding and reasoning tasks,
particularly those concerning relational or structurally complex information.
Based on this observation, we propose a structure-aware fine-tuning framework
to enhance LVLMs with structure learning abilities through 3 self-supervised
learning tasks. Experiments validate the effectiveness of our method in
improving LVLMs' zero-shot performance on fundamental graph learning tasks, as
well as enhancing the robustness of LVLMs against complex visual graphs.

æè¦ï¼å¤§åè¦è¦ºèªè¨æ¨¡å (LVLMs) å·²å¨åç¨®ä»»åä¸­å±ç¾åºéå¡çè¡¨ç¾ãåç®¡ç²å¾å·¨å¤§çæåï¼æè¿çç ç©¶é¡¯ç¤ºï¼LVLMs å¨èçè¦è¦ºåå½¢ææéå°éå¤§çéå¶ãçºäºç ç©¶éäºéå¶èå¾çåå ï¼æåæåºäº VGCureï¼éæ¯ä¸åæ¶µè 22 é ä»»åçç¶ååºæºï¼ç¨æ¼æª¢æ¥ LVLMs çåºæ¬åå½¢çè§£åæ¨çè½åãå° 14 å LVLMs é²è¡çå»£æ³è©ä¼°é¡¯ç¤ºï¼LVLMs å¨åºæ¬çåå½¢çè§£åæ¨çä»»åä¸­è¼å¼±ï¼ç¹å¥æ¯é£äºæ¶åéä¿æçµæ§è¤éè³è¨çä»»åãåºæ¼æ­¤è§å¯ï¼æåæåºäºä¸åçµæ§æç¥å¾®èª¿æ¡æ¶ï¼ä»¥éé 3 åèªæç£ç£å­¸ç¿ä»»åä¾å¢å¼· LVLMs ççµæ§å­¸ç¿è½åãå¯¦é©é©è­äºæåçæ¹æ³å¨æå LVLMs å¨åºæ¬åå½¢å­¸ç¿ä»»åä¸çé¶æ¬¡å­¸ç¿è¡¨ç¾çæææ§ï¼ä»¥åå¢å¼· LVLMs å°è¤éè¦è¦ºåå½¢çé­¯æ£æ§ã

##### **Transducer Tuning: Efficient Model Adaptation for Software Tasks Using Code Property Graphs**
2412.13467v1 by Imam Nur Bani Yusuf, Lingxiao Jiang

Large language models have demonstrated promising performance across various
software engineering tasks. While fine-tuning is a common practice to adapt
these models for downstream tasks, it becomes challenging in
resource-constrained environments due to increased memory requirements from
growing trainable parameters in increasingly large language models. We
introduce \approach, a technique to adapt large models for downstream code
tasks using Code Property Graphs (CPGs). Our approach introduces a modular
component called \transducer that enriches code embeddings with structural and
dependency information from CPGs. The Transducer comprises two key components:
Graph Vectorization Engine (GVE) and Attention-Based Fusion Layer (ABFL). GVE
extracts CPGs from input source code and transforms them into graph feature
vectors. ABFL then fuses those graphs feature vectors with initial code
embeddings from a large language model. By optimizing these transducers for
different downstream tasks, our approach enhances the models without the need
to fine-tune them for specific tasks. We have evaluated \approach on three
downstream tasks: code summarization, assert generation, and code translation.
Our results demonstrate competitive performance compared to full parameter
fine-tuning while reducing up to 99\% trainable parameters to save memory.
\approach also remains competitive against other fine-tuning approaches (e.g.,
LoRA, Prompt-Tuning, Prefix-Tuning) while using only 1.5\%-80\% of their
trainable parameters. Our findings show that integrating structural and
dependency information through Transducer Tuning enables more efficient model
adaptation, making it easier for users to adapt large models in
resource-constrained settings.

æè¦ï¼å¤§åèªè¨æ¨¡åå·²å¨åç¨®è»é«å·¥ç¨ä»»åä¸­å±ç¾åºä»¤äººæ»¿æçæè½ãéç¶å¾®èª¿æ¯èª¿æ´éäºæ¨¡åä»¥å·è¡ä¸æ¸¸ä»»åçå¸¸è¦åæ³ï¼ä½ç±æ¼å¤§åèªè¨æ¨¡åä¸­å¯è¨ç·´åæ¸ä¸æ·å¢å ï¼å°è´è¨æ¶é«éæ±å¢å ï¼å æ­¤å¨è³æºåéçç°å¢ä¸­è®å¾å·æææ°æ§ãæåå¼å¥äº \approachï¼éæ¯ä¸ç¨®ä½¿ç¨ç¨å¼ç¢¼å±¬æ§å (CPG) ä¾èª¿æ´å¤§åæ¨¡åä»¥å·è¡ä¸æ¸¸ç¨å¼ç¢¼ä»»åçæè¡ãæåçåæ³å¼å¥äºç¨±çº \transducer çæ¨¡çµååä»¶ï¼å®ä½¿ç¨ä¾èª CPG ççµæ§åä¾è³´éä¿è³è¨ä¾è±å¯ç¨å¼ç¢¼åµå¥ãTransducer åå«å©åééµåä»¶ï¼ååéåå¼æ (GVE) ååºæ¼æ³¨æåçèåå±¤ (ABFL)ãGVE å¾è¼¸å¥åå§ç¢¼ä¸­èå CPGï¼ä¸¦å°å®åè½æçºåå½¢ç¹å¾µåéãABFL æ¥èå°éäºåå½¢ç¹å¾µåéèä¾èªå¤§åèªè¨æ¨¡åçåå§ç¨å¼ç¢¼åµå¥èåãéééå°ä¸åçä¸æ¸¸ä»»åæä½³åéäºè½æå¨ï¼æåçåæ³å¢å¼·äºæ¨¡åï¼èç¡ééå°ç¹å®ä»»åé²è¡å¾®èª¿ãæåå·²å¨ä¸åä¸æ¸¸ä»»åä¸­è©ä¼° \approachï¼ç¨å¼ç¢¼æè¦ãæ·è¨ç¢çåç¨å¼ç¢¼ç¿»è­¯ãæåççµæé¡¯ç¤ºï¼èå®å¨åæ¸å¾®èª¿ç¸æ¯ï¼å·æç«¶ç­åçæè½ï¼åææ¸å°äºå¤é 99% çå¯è¨ç·´åæ¸ä»¥ç¯çè¨æ¶é«ã\approach å¨åä½¿ç¨ 1.5% - 80% å¯è¨ç·´åæ¸çææ³ä¸ï¼ä»ç¶å¨èå¶ä»å¾®èª¿æ¹æ³ï¼ä¾å¦ LoRAãPrompt-TuningãPrefix-Tuningï¼çç«¶ç­ä¸­ä¿æç«¶ç­åãæåçç¼ç¾è¡¨æï¼éé Transducer Tuning æ´åçµæ§åä¾è³´éä¿è³è¨å¯ä»¥å¯¦ç¾æ´ææççæ¨¡åèª¿æ´ï¼ä½¿ç¨æ¶æ´å®¹æå¨è³æºåéçè¨­å®ä¸­èª¿æ´å¤§åæ¨¡åã

##### **Enhancing Persona Classification in Dialogue Systems: A Graph Neural Network Approach**
2412.13283v1 by Konstantin Zaitsev

In recent years, Large Language Models (LLMs) gain considerable attention for
their potential to enhance personalized experiences in virtual assistants and
chatbots. A key area of interest is the integration of personas into LLMs to
improve dialogue naturalness and user engagement. This study addresses the
challenge of persona classification, a crucial component in dialogue
understanding, by proposing a framework that combines text embeddings with
Graph Neural Networks (GNNs) for effective persona classification. Given the
absence of dedicated persona classification datasets, we create a manually
annotated dataset to facilitate model training and evaluation. Our method
involves extracting semantic features from persona statements using text
embeddings and constructing a graph where nodes represent personas and edges
capture their similarities. The GNN component uses this graph structure to
propagate relevant information, thereby improving classification performance.
Experimental results show that our approach, in particular the integration of
GNNs, significantly improves classification performance, especially with
limited data. Our contributions include the development of a persona
classification framework and the creation of a dataset.

æè¦ï¼è¿å¹´ä¾ï¼å¤§åèªè¨æ¨¡å (LLM) å å¶å¢å¼·èæ¬å©çåèå¤©æ©å¨äººä¸­åäººåé«é©çæ½åèååéæ³¨ãä¸åééµçèè¶£é åæ¯å°è§è²èå¥ LLMï¼ä»¥æ¹åå°è©±çèªç¶æ§åä½¿ç¨èåèåº¦ãæ¬ç ç©¶æ¢è¨è§è²åé¡çææ°ï¼éæ¯å°è©±çè§£ä¸­çééµçµæé¨åï¼æåºä¸åçµåææ¬åµå¥èåç¥ç¶ç¶²è·¯ (GNN) çæ¶æ§ï¼ä»¥é²è¡ææçè§è²åé¡ãéæ¼ç¼ºä¹å°ç¨çè§è²åé¡è³æéï¼æåå»ºç«äºä¸åæåæ¨è¨»çè³æéï¼ä»¥å©æ¼æ¨¡åè¨ç·´åè©ä¼°ãæåçæ¹æ³åæ¬ä½¿ç¨ææ¬åµå¥å¾è§è²é³è¿°ä¸­æåèªç¾©ç¹å¾µï¼ä¸¦å»ºæ§ä¸ååï¼å¶ä¸­ç¯é»è¡¨ç¤ºè§è²ï¼èéç·£ææå®åçç¸ä¼¼æ§ãGNN çµä»¶ä½¿ç¨éååçµæ§ä¾å³æ­ç¸éè³è¨ï¼å¾èæ¹ååé¡æè½ãå¯¦é©çµæé¡¯ç¤ºï¼æåçæ¹æ³ï¼ç¹å¥æ¯ GNN çæ´åï¼é¡¯èæ¹åäºåé¡æè½ï¼ç¹å¥æ¯å¨è³ææéçææ³ä¸ãæåçè²¢ç»åæ¬éç¼è§è²åé¡æ¶æ§åå»ºç«è³æéã

##### **Detecting Emotional Incongruity of Sarcasm by Commonsense Reasoning**
2412.12808v1 by Ziqi Qiu, Jianxing Yu, Yufeng Zhang, Hanjiang Lai, Yanghui Rao, Qinliang Su, Jian Yin

This paper focuses on sarcasm detection, which aims to identify whether given
statements convey criticism, mockery, or other negative sentiment opposite to
the literal meaning. To detect sarcasm, humans often require a comprehensive
understanding of the semantics in the statement and even resort to external
commonsense to infer the fine-grained incongruity. However, existing methods
lack commonsense inferential ability when they face complex real-world
scenarios, leading to unsatisfactory performance. To address this problem, we
propose a novel framework for sarcasm detection, which conducts incongruity
reasoning based on commonsense augmentation, called EICR. Concretely, we first
employ retrieval-augmented large language models to supplement the missing but
indispensable commonsense background knowledge. To capture complex contextual
associations, we construct a dependency graph and obtain the optimized topology
via graph refinement. We further introduce an adaptive reasoning skeleton that
integrates prior rules to extract sentiment-inconsistent subgraphs explicitly.
To eliminate the possible spurious relations between words and labels, we
employ adversarial contrastive learning to enhance the robustness of the
detector. Experiments conducted on five datasets demonstrate the effectiveness
of EICR.

æè¦ï¼æ¬æéé»æ¢è¨è«·åºåµæ¸¬ï¼æ¨å¨è¾¨è­çµ¦å®çé³è¿°æ¯å¦å³éæ¹è©ãå²è«·æå¶ä»èå­é¢ææç¸åçè² é¢æç·ãçºäºåµæ¸¬è«·åºï¼äººé¡éå¸¸éè¦å¨é¢äºè§£é³è¿°ä¸­çèªç¾©ï¼çè³è¨´è«¸å¤é¨å¸¸è­ä¾æ¨è«ç´°å¾®çä¸ä¸è´ãç¶èï¼ç¾ææ¹æ³å¨é¢å°è¤éçç¾å¯¦ä¸çå ´æ¯æç¼ºä¹å¸¸è­æ¨çè½åï¼å°è´è¡¨ç¾ä¸ä½³ãçºäºè§£æ±ºéååé¡ï¼æåæåºäºä¸åæ°çè«·åºåµæ¸¬æ¶æ§ï¼è©²æ¶æ§åºæ¼å¸¸è­æ´åé²è¡ä¸ä¸è´æ¨çï¼ç¨±çº EICRãå·é«ä¾èªªï¼æåé¦åæ¡ç¨æª¢ç´¢æ´åå¤§åèªè¨æ¨¡åä¾è£åéºå¤±ä½ä¸å¯æç¼ºçå¸¸è­èæ¯ç¥è­ãçºäºææè¤éçä¸ä¸æéè¯ï¼æåæ§é äºä¸åä¾è³´åï¼ä¸¦ééåå½¢åªåç²å¾æä½³ææ²ãæåé²ä¸æ­¥å¼å¥ä¸åèªé©ææ¨çæ¶æ§ï¼æ´ååé©è¦åä¾æç¢ºæåæç·ä¸ä¸è´çå­åãçºäºæ¶é¤è©å½åæ¨ç±¤ä¹éå¯è½çèåéä¿ï¼æåæ¡ç¨å°æå°æ¯å­¸ç¿ä¾å¢å¼·æª¢æ¸¬å¨çé­¯æ£æ§ãå¨äºåè³æéä¸é²è¡çå¯¦é©è­æäº EICR çæææ§ã

##### **LLM-based Discriminative Reasoning for Knowledge Graph Question Answering**
2412.12643v1 by Mufan Xu, Kehai Chen, Xuefeng Bai, Muyun Yang, Tiejun Zhao, Min Zhang

Large language models (LLMs) based on generative pre-trained Transformer have
achieved remarkable performance on knowledge graph question-answering (KGQA)
tasks. However, LLMs often produce ungrounded subgraph planning or reasoning
results in KGQA due to the hallucinatory behavior brought by the generative
paradigm, which may hinder the advancement of the LLM-based KGQA model. To deal
with the issue, we propose a novel LLM-based Discriminative Reasoning (LDR)
method to explicitly model the subgraph retrieval and answer inference process.
By adopting discriminative strategies, the proposed LDR method not only
enhances the capability of LLMs to retrieve question-related subgraphs but also
alleviates the issue of ungrounded reasoning brought by the generative paradigm
of LLMs. Experimental results show that the proposed approach outperforms
multiple strong comparison methods, along with achieving state-of-the-art
performance on two widely used WebQSP and CWQ benchmarks.

æè¦ï¼å¤§åèªè¨æ¨¡åï¼LLMï¼åºæ¼çæå¼é è¨ç·´ Transformerï¼å¨ç¥è­åè­åç­ï¼KGQAï¼ä»»åä¸å·²åå¾é¡¯èçææãç¶èï¼ç±æ¼çæå¼ç¯ä¾å¸¶ä¾çå¹»è¦ºè¡çºï¼LLM å¨ KGQA ä¸­ç¶å¸¸ç¢çç¡æ ¹æçå­åè¦åææ¨ççµæï¼éå¯è½æé»ç¤åºæ¼ LLM ç KGQA æ¨¡åçé²å±ãçºäºè§£æ±ºéååé¡ï¼æåæåºäºä¸ç¨®æ°ç©çåºæ¼ LLM çå¤å¥æ¨çï¼LDRï¼æ¹æ³ï¼ä»¥æç¢ºå»ºæ¨¡å­åæª¢ç´¢åç­æ¡æ¨è«éç¨ãééæ¡ç¨å¤å¥ç­ç¥ï¼ææåºç LLM æ¹æ³ä¸åå¢å¼·äº LLM æª¢ç´¢èåé¡ç¸éçå­åçè½åï¼èä¸éç·©è§£äº LLM ççæå¼ç¯ä¾å¸¶ä¾çç¡æ ¹ææ¨çåé¡ãå¯¦é©çµæè¡¨æï¼ææåºçæ¹æ³åªæ¼å¤ç¨®å¼·å¤§çæ¯è¼æ¹æ³ï¼åæå¨å©åå»£æ³ä½¿ç¨ç WebQSP å CWQ åºæºæ¸¬è©¦ä¸­åå¾äºæåé²çæè½ã

##### **SynthCypher: A Fully Synthetic Data Generation Framework for Text-to-Cypher Querying in Knowledge Graphs**
2412.12612v1 by Aman Tiwari, Shiva Krishna Reddy Malay, Vikas Yadav, Masoud Hashemi, Sathwik Tejaswi Madhusudhan

Cypher, the query language for Neo4j graph databases, plays a critical role
in enabling graph-based analytics and data exploration. While substantial
research has been dedicated to natural language to SQL query generation
(Text2SQL), the analogous problem for graph databases referred to as
Text2Cypher remains underexplored. In this work, we introduce SynthCypher, a
fully synthetic and automated data generation pipeline designed to address this
gap. SynthCypher employs a novel LLMSupervised Generation-Verification
framework, ensuring syntactically and semantically correct Cypher queries
across diverse domains and query complexities. Using this pipeline, we create
SynthCypher Dataset, a large-scale benchmark containing 29.8k Text2Cypher
instances. Fine-tuning open-source large language models (LLMs), including
LLaMa-3.1- 8B, Mistral-7B, and QWEN-7B, on SynthCypher yields significant
performance improvements of up to 40% on the Text2Cypher test set and 30% on
the SPIDER benchmark adapted for graph databases. This work demonstrates that
high-quality synthetic data can effectively advance the state-of-the-art in
Text2Cypher tasks.

æè¦ï¼Cypher æ¯ Neo4j åå½¢è³æåº«çæ¥è©¢èªè¨ï¼å¨åç¨ä»¥åå½¢çºåºç¤çåæåè³ææ¢ç´¢æ¹é¢ç¼æ®èè³ééè¦çä½ç¨ãåç®¡å·²ç¶æå¥å¤§éç ç©¶å°èªç¶èªè¨è½æçº SQL æ¥è©¢çæ (Text2SQL)ï¼ä½ç¨±çº Text2Cypher çåå½¢è³æåº«é¡æ¯åé¡ä»æªå¾å°ååæ¢è¨ãå¨éé å·¥ä½ä¸­ï¼æåä»ç´¹äº SynthCypherï¼éæ¯ä¸åå®å¨åæä¸èªååçè³æçæç®¡éï¼æ¨å¨è§£æ±ºéåå·®è·ãSynthCypher æ¡ç¨äºä¸ç¨®æ°ç©ç LLMSupervised çæé©è­æ¡æ¶ï¼ç¢ºä¿äºè·¨è¶ä¸åé ååæ¥è©¢è¤éæ§ç Cypher æ¥è©¢å¨èªæ³åèªç¾©ä¸æ­£ç¢ºãä½¿ç¨éåç®¡éï¼æååµå»ºäº SynthCypher è³æéï¼éæ¯ä¸ååå« 29.8k Text2Cypher å¯¦ä¾çå¤§è¦æ¨¡åºæºãå¾®èª¿éæºå¤§åèªè¨æ¨¡å (LLM)ï¼åæ¬ SynthCypher ä¸ç LLaMa-3.1- 8BãMistral-7B å QWEN-7Bï¼å¨ Text2Cypher æ¸¬è©¦éä¸­ç¢çäºé«é 40% çé¡¯èæ§è½æåï¼å¨é©ç¨æ¼åå½¢è³æåº«ç SPIDER åºæºä¸æåäº 30%ãéé å·¥ä½è­æäºé«åè³ªçåæè³æå¯ä»¥ææå°æ¨å Text2Cypher ä»»åçææ°æè¡ã

##### **Graph Learning in the Era of LLMs: A Survey from the Perspective of Data, Models, and Tasks**
2412.12456v1 by Xunkai Li, Zhengyu Wu, Jiayi Wu, Hanwen Cui, Jishuo Jia, Rong-Hua Li, Guoren Wang

With the increasing prevalence of cross-domain Text-Attributed Graph (TAG)
Data (e.g., citation networks, recommendation systems, social networks, and
ai4science), the integration of Graph Neural Networks (GNNs) and Large Language
Models (LLMs) into a unified Model architecture (e.g., LLM as enhancer, LLM as
collaborators, LLM as predictor) has emerged as a promising technological
paradigm. The core of this new graph learning paradigm lies in the synergistic
combination of GNNs' ability to capture complex structural relationships and
LLMs' proficiency in understanding informative contexts from the rich textual
descriptions of graphs. Therefore, we can leverage graph description texts with
rich semantic context to fundamentally enhance Data quality, thereby improving
the representational capacity of model-centric approaches in line with
data-centric machine learning principles. By leveraging the strengths of these
distinct neural network architectures, this integrated approach addresses a
wide range of TAG-based Task (e.g., graph learning, graph reasoning, and graph
question answering), particularly in complex industrial scenarios (e.g.,
supervised, few-shot, and zero-shot settings). In other words, we can treat
text as a medium to enable cross-domain generalization of graph learning Model,
allowing a single graph model to effectively handle the diversity of downstream
graph-based Task across different data domains. This work serves as a
foundational reference for researchers and practitioners looking to advance
graph learning methodologies in the rapidly evolving landscape of LLM. We
consistently maintain the related open-source materials at
\url{https://github.com/xkLi-Allen/Awesome-GNN-in-LLMs-Papers}.

æè¦ï¼<paragraph>é¨èè·¨é åææ¬å±¬æ§å (TAG) è³æï¼ä¾å¦å¼æç¶²è·¯ãæ¨è¦ç³»çµ±ãç¤¾äº¤ç¶²è·¯å ai4scienceï¼çæ¥çæ®åï¼å°åç¥ç¶ç¶²è·¯ (GNN) åå¤§åèªè¨æ¨¡å (LLM) æ´åå°çµ±ä¸çæ¨¡åæ¶æ§ï¼ä¾å¦ï¼LLM ä½çºå¢å¼·å¨ãLLM ä½çºåä½èãLLM ä½çºé æ¸¬å¨ï¼ä¸­å·²æçºä¸ç¨®æåéçæè¡å¸ç¯ãéç¨®æ°çåå½¢å­¸ç¿å¸ç¯çæ ¸å¿å¨æ¼ GNN ææè¤éçµæ§éä¿çè½åè LLM å¾åå½¢çè±å¯æå­æè¿°ä¸­çè§£è³è¨è±å¯èæ¯ççç·´åº¦çååçµåãå æ­¤ï¼æåå¯ä»¥å©ç¨å·æè±å¯èªç¾©èæ¯çåå½¢æè¿°æå­ï¼å¾æ ¹æ¬ä¸æåè³æåè³ªï¼å¾èæ¹åä»¥æ¨¡åçºä¸­å¿çéå¾çè¡¨ç¤ºè½åï¼ä¸¦ç¬¦åä»¥è³æçºä¸­å¿çæ©å¨å­¸ç¿ååãééå©ç¨éäºä¸åçç¥ç¶ç¶²è·¯æ¶æ§çåªé»ï¼éç¨®æ´åæ¹æ³è§£æ±ºäºå»£æ³çåºæ¼ TAG çä»»åï¼ä¾å¦ï¼åå½¢å­¸ç¿ãåå½¢æ¨çååå½¢åç­ï¼ï¼ç¹å¥æ¯å¨è¤éçç¢æ¥­å ´æ¯ï¼ä¾å¦ï¼ç£ç£å¼ãå°æ¨£æ¬åé¶æ¨£æ¬è¨­å®ï¼ä¸­ãæå¥è©±èªªï¼æåå¯ä»¥å°æå­è¦çºä¸ç¨®åªä»ï¼ä»¥å¯¦ç¾åå½¢å­¸ç¿æ¨¡åçè·¨é åæ³åï¼è®å®ä¸åå½¢æ¨¡åè½å¤ ææå°èçä¸åè³æé åä¸­ä¸æ¸¸åºæ¼åå½¢çä»»åçå¤æ¨£æ§ãéé å·¥ä½ä½çºç ç©¶äººå¡åå¯¦åå·¥ä½èçåºç¤åèï¼ä»åå¸æå¨ LLM å¿«éæ¼è®çç°å¢ä¸­æ¨é²åå½¢å­¸ç¿æ¹æ³ãæåæçºå¨ \url{https://github.com/xkLi-Allen/Awesome-GNN-in-LLMs-Papers} ç¶­è­·ç¸éçéæ¾åå§ç¢¼è³æã</paragraph>

##### **Graph-Guided Textual Explanation Generation Framework**
2412.12318v1 by Shuzhou Yuan, Jingyi Sun, Ran Zhang, Michael FÃ¤rber, Steffen Eger, Pepa Atanasova, Isabelle Augenstein

Natural language explanations (NLEs) are commonly used to provide plausible
free-text explanations of a model's reasoning about its predictions. However,
recent work has questioned the faithfulness of NLEs, as they may not accurately
reflect the model's internal reasoning process regarding its predicted answer.
In contrast, highlight explanations -- input fragments identified as critical
for the model's predictions -- exhibit measurable faithfulness, which has been
incrementally improved through existing research. Building on this foundation,
we propose G-Tex, a Graph-Guided Textual Explanation Generation framework
designed to enhance the faithfulness of NLEs by leveraging highlight
explanations. Specifically, highlight explanations are extracted as highly
faithful cues representing the model's reasoning and are subsequently encoded
through a graph neural network layer, which explicitly guides the NLE
generation process. This alignment ensures that the generated explanations
closely reflect the model's underlying reasoning. Experiments on T5 and BART
using three reasoning datasets show that G-Tex improves NLE faithfulness by up
to 17.59% compared to baseline methods. Additionally, G-Tex generates NLEs with
greater semantic and lexical similarity to human-written ones. Human
evaluations show that G-Tex can decrease redundant content and enhance the
overall quality of NLEs. As our work introduces a novel method for explicitly
guiding NLE generation to improve faithfulness, we hope it will serve as a
stepping stone for addressing additional criteria for NLE and generated text
overall.

æè¦ï¼èªç¶èªè¨è§£é (NLE) å¸¸ç¨æ¼æä¾æ¨¡åå°å¶é æ¸¬çåçè§£éãç¶èï¼æè¿çç ç©¶è³ªç NLE çå¿ å¯¦åº¦ï¼å çºå®åå¯è½ç¡æ³æºç¢ºåæ æ¨¡åå¨å¶é æ¸¬ç­æ¡ä¸çå§é¨æ¨çéç¨ãç¸åï¼éé»è§£éââè¢«è­å¥çºå°æ¨¡åé æ¸¬è³ééè¦çè¼¸å¥çæ®µââè¡¨ç¾åºå¯è¡¡éçå¿ å¯¦åº¦ï¼éå·²ééç¾æç ç©¶éæ­¥å¾å°æ¹é²ãå¨æ­¤åºç¤ä¸ï¼æåæåºäº G-Texï¼ä¸ååå½¢å¼å°ææ¬è§£éçææ¡æ¶ï¼æ¨å¨ééå©ç¨éé»è§£éä¾å¢å¼· NLE çå¿ å¯¦åº¦ãå·é«ä¾èªªï¼éé»è§£éè¢«æåçºä»£è¡¨æ¨¡åæ¨ççé«åº¦å¿ å¯¦ç·ç´¢ï¼ç¶å¾ééåç¥ç¶ç¶²è·¯å±¤é²è¡ç·¨ç¢¼ï¼éæç¢ºæå°äº NLE çæéç¨ãéç¨®å°é½ç¢ºä¿çæçè§£éç·å¯åæ æ¨¡åçåºå±¤æ¨çãä½¿ç¨ä¸åæ¨çæ¸æéå° T5 å BART é²è¡çå¯¦é©è¡¨æï¼èåºç·æ¹æ³ç¸æ¯ï¼G-Tex å° NLE çå¿ å¯¦åº¦æé«äº 17.59%ãæ­¤å¤ï¼G-Tex çæç NLE èäººé¡ç·¨å¯«ç NLE å¨èªç¾©åè©å½ä¸å·ææ´é«çç¸ä¼¼æ§ãäººé¡è©ä¼°è¡¨æï¼G-Tex å¯ä»¥æ¸å°åé¤å§å®¹ä¸¦æé« NLE çæ´é«åè³ªãç±æ¼æåçç ç©¶å¼å¥äºä¸ç¨®æç¢ºæå° NLE çæçåµæ°æ¹æ³ä¾æé«å¿ å¯¦åº¦ï¼æåå¸æå®å°ä½çºè§£æ±º NLE åæ´é«çæææ¬çéå æ¨æºçå¢è³ç³ã

##### **Cost-Effective Label-free Node Classification with LLMs**
2412.11983v1 by Taiyan Zhang, Renchi Yang, Mingyu Yan, Xiaochun Ye, Dongrui Fan, Yurui Lai

Graph neural networks (GNNs) have emerged as go-to models for node
classification in graph data due to their powerful abilities in fusing graph
structures and attributes. However, such models strongly rely on adequate
high-quality labeled data for training, which are expensive to acquire in
practice. With the advent of large language models (LLMs), a promising way is
to leverage their superb zero-shot capabilities and massive knowledge for node
labeling. Despite promising results reported, this methodology either demands
considerable queries to LLMs, or suffers from compromised performance caused by
noisy labels produced by LLMs.
  To remedy these issues, this work presents Cella, an active self-training
framework that integrates LLMs into GNNs in a cost-effective manner. The design
recipe of Cella is to iteratively identify small sets of "critical" samples
using GNNs and extract informative pseudo-labels for them with both LLMs and
GNNs as additional supervision signals to enhance model training. Particularly,
Cella includes three major components: (i) an effective active node selection
strategy for initial annotations; (ii) a judicious sample selection scheme to
sift out the "critical" nodes based on label disharmonicity and entropy; and
(iii) a label refinement module combining LLMs and GNNs with rewired topology.
Our extensive experiments over five benchmark text-attributed graph datasets
demonstrate that Cella significantly outperforms the state of the arts under
the same query budget to LLMs in terms of label-free node classification. In
particular, on the DBLP dataset with 14.3k nodes, Cella is able to achieve an
8.08% conspicuous improvement in accuracy over the state-of-the-art at a cost
of less than one cent.

æè¦ï¼åå½¢ç¥ç¶ç¶²è·¯ (GNN) å·²æçºåå½¢è³æä¸­ç¯é»åé¡çç±éæ¨¡åï¼å çºå®åå¨èååå½¢çµæ§åå±¬æ§æ¹é¢å·æå¼·å¤§çè½åãç¶èï¼æ­¤é¡æ¨¡åå¨è¨ç·´æé«åº¦ä¾è³´è¶³å¤ çé«åè³ªæ¨ç±¤è³æï¼èéäºè³æå¨å¯¦åä¸åå¾çææ¬å¾é«ãé¨èå¤§åèªè¨æ¨¡å (LLM) çåºç¾ï¼ä¸åæåéçæ¹æ³æ¯å©ç¨å¶åè¶çé¶æ¬¡å­¸ç¿è½ååæµ·éç¥è­é²è¡ç¯é»æ¨ç±¤ãåç®¡å ±åäºæå¸æççµæï¼ä½æ­¤æ¹æ³ä¸æ¯éè¦å¤§éæ¥è©¢ LLMï¼å°±æ¯æå çº LLM ç¢ççæ¨ç±¤æéè¨èå°è´æè½åæã
çºäºè§£æ±ºéäºåé¡ï¼æ¬ç ç©¶æåº Cellaï¼ä¸åä¸»åèªè¨ç·´æ¶æ§ï¼ä»¥å·æææ¬æççæ¹å¼å° LLM æ´åå° GNN ä¸­ãCella çè¨­è¨ç§è¨£æ¯ä½¿ç¨ GNN è¿­ä»£è­å¥å°çµãééµãæ¨£æ¬ï¼ä¸¦ä½¿ç¨ LLM å GNN ä½çºé¡å¤çç£ç£è¨èï¼çºéäºæ¨£æ¬èåææç¾©çå½æ¨ç±¤ï¼ä»¥å¢å¼·æ¨¡åè¨ç·´ãç¹å¥æ¯ï¼Cella åå«ä¸åä¸»è¦çµæé¨åï¼(i) ä¸åææçç¯é»ä¸»åé¸æç­ç¥ï¼ç¨æ¼åå§è¨»è§£ï¼(ii) ä¸åææºçæ¨£æ¬é¸ææ¹æ¡ï¼æ ¹ææ¨ç±¤ä¸åèª¿æ§åçµç¯©é¸åºãééµãç¯é»ï¼ä»¥å (iii) ä¸åçµå LLM å GNN ä»¥åéæ°é£ç·ææ²çæ¨ç±¤ç²¾ç·»æ¨¡çµãæåå¨äºååºæºæå­å±¬æ§åå½¢è³æéä¸é²è¡çå»£æ³å¯¦é©è¡¨æï¼å¨ç¸åç LLM æ¥è©¢é ç®ä¸ï¼Cella å¨ç¡æ¨ç±¤ç¯é»åé¡æ¹é¢é¡¯èåªæ¼ç¾ææè¡ãç¹å¥æ¯å¨å·æ 14.3k åç¯é»ç DBLP è³æéä¸ï¼Cella è½å¤ ä»¥ä½æ¼ä¸ç¾åçææ¬ï¼å¨æºç¢ºåº¦ä¸æ¯ç¾ææè¡é¡¯èæå 8.08%ã

##### **SE-GCL: An Event-Based Simple and Effective Graph Contrastive Learning for Text Representation**
2412.11652v1 by Tao Meng, Wei Ai, Jianbin Li, Ze Wang, Yuntao Shou, Keqin Li

Text representation learning is significant as the cornerstone of natural
language processing. In recent years, graph contrastive learning (GCL) has been
widely used in text representation learning due to its ability to represent and
capture complex text information in a self-supervised setting. However, current
mainstream graph contrastive learning methods often require the incorporation
of domain knowledge or cumbersome computations to guide the data augmentation
process, which significantly limits the application efficiency and scope of
GCL. Additionally, many methods learn text representations only by constructing
word-document relationships, which overlooks the rich contextual semantic
information in the text. To address these issues and exploit representative
textual semantics, we present an event-based, simple, and effective graph
contrastive learning (SE-GCL) for text representation. Precisely, we extract
event blocks from text and construct internal relation graphs to represent
inter-semantic interconnections, which can ensure that the most critical
semantic information is preserved. Then, we devise a streamlined, unsupervised
graph contrastive learning framework to leverage the complementary nature of
the event semantic and structural information for intricate feature data
capture. In particular, we introduce the concept of an event skeleton for core
representation semantics and simplify the typically complex data augmentation
techniques found in existing graph contrastive learning to boost algorithmic
efficiency. We employ multiple loss functions to prompt diverse embeddings to
converge or diverge within a confined distance in the vector space, ultimately
achieving a harmonious equilibrium. We conducted experiments on the proposed
SE-GCL on four standard data sets (AG News, 20NG, SougouNews, and THUCNews) to
verify its effectiveness in text representation learning.

æè¦ï¼ææ¬è¡¨å¾µå­¸ç¿ä½çºèªç¶èªè¨èççåºç³ï¼å·æéè¦çæç¾©ãè¿å¹´ä¾ï¼åå½¢å°æ¯å­¸ç¿ (GCL) å å¶å¨èªæç£ç£è¨­å®ä¸­è¡¨å¾µåæ·åè¤éææ¬è³è¨çè½åï¼èè¢«å»£æ³ç¨æ¼ææ¬è¡¨å¾µå­¸ç¿ãç¶èï¼ç¶åçä¸»æµåå½¢å°æ¯å­¸ç¿æ¹æ³éå¸¸éè¦å å¥é åç¥è­æç¹ç£çéç®ä¾å¼å°è³ææ´åç¨åºï¼éé¡¯èå°éå¶äº GCL çæç¨æçåç¯åãæ­¤å¤ï¼è¨±å¤æ¹æ³åééå»ºæ§å­è©æä»¶éä¿ä¾å­¸ç¿ææ¬è¡¨å¾µï¼éå¿½ç¥äºææ¬ä¸­è±å¯çèçµ¡èªç¾©è³è¨ãçºäºè§£æ±ºéäºåé¡ä¸¦éç¨å·ä»£è¡¨æ§çææ¬èªç¾©ï¼æåæåºäºä¸ç¨®åºæ¼äºä»¶ãç°¡å®ä¸ææçåå½¢å°æ¯å­¸ç¿ (SE-GCL) ä¾é²è¡ææ¬è¡¨å¾µãå·é«ä¾èªªï¼æåå¾ææ¬ä¸­èåäºä»¶åå¡ä¸¦å»ºæ§å§é¨éä¿åå½¢ä¾è¡¨å¾µèªç¾©éçç¸äºé£çµï¼éè½ç¢ºä¿ä¿çæééµçèªç¾©è³è¨ãæ¥èï¼æåè¨­è¨äºä¸åç°¡åçç¡ç£ç£åå½¢å°æ¯å­¸ç¿æ¶æ§ï¼ä»¥å©ç¨äºä»¶èªç¾©åçµæ§è³è¨çäºè£ç¹æ§ä¾æ·åè¤éçç¹å¾µè³æãç¹å¥å°ï¼æåå¼å¥äºäºä»¶éª¨æ¶çæ¦å¿µï¼ç¨æ¼æ ¸å¿è¡¨å¾µèªç¾©ï¼ä¸¦ç°¡åç¾æåå½¢å°æ¯å­¸ç¿ä¸­éå¸¸è¤éçè³ææ´åæè¡ï¼ä»¥æåæ¼ç®æ³æçãæåæ¡ç¨å¤éæå¤±å½æ¸ä¾ä¿ä½¿ä¸åçåµå¥å¨åéç©ºéä¸­åéè·é¢å§æ¶ææç¼æ£ï¼æçµéæåè«§çå¹³è¡¡ãæåå¨ååæ¨æºè³æé (AG Newsã20NGãSougouNews å THUCNews) ä¸å°ææåºç SE-GCL é²è¡äºå¯¦é©ï¼ä»¥é©è­å¶å¨ææ¬è¡¨å¾µå­¸ç¿ä¸­çæææ§ã

##### **EvoLlama: Enhancing LLMs' Understanding of Proteins via Multimodal Structure and Sequence Representations**
2412.11618v1 by Nuowei Liu, Changzhi Sun, Tao Ji, Junfeng Tian, Jianxin Tang, Yuanbin Wu, Man Lan

Current Large Language Models (LLMs) for understanding proteins primarily
treats amino acid sequences as a text modality. Meanwhile, Protein Language
Models (PLMs), such as ESM-2, have learned massive sequential evolutionary
knowledge from the universe of natural protein sequences. Furthermore,
structure-based encoders like ProteinMPNN learn the structural information of
proteins through Graph Neural Networks. However, whether the incorporation of
protein encoders can enhance the protein understanding of LLMs has not been
explored. To bridge this gap, we propose EvoLlama, a multimodal framework that
connects a structure-based encoder, a sequence-based protein encoder and an LLM
for protein understanding. EvoLlama consists of a ProteinMPNN structure
encoder, an ESM-2 protein sequence encoder, a multimodal projector to align
protein and text representations and a Llama-3 text decoder. To train EvoLlama,
we fine-tune it on protein-oriented instructions and protein property
prediction datasets verbalized via natural language instruction templates. Our
experiments show that EvoLlama's protein understanding capabilities have been
significantly enhanced, outperforming other fine-tuned protein-oriented LLMs in
zero-shot settings by an average of 1%-8% and surpassing the state-of-the-art
baseline with supervised fine-tuning by an average of 6%. On protein property
prediction datasets, our approach achieves promising results that are
competitive with state-of-the-art task-specific baselines. We will release our
code in a future version.

æè¦ï¼ç®åç¨æ¼çè§£èç½è³ªçå¤§åèªè¨æ¨¡å (LLM) ä¸»è¦å°èºåºé¸åºåè¦çºæå­å½¢å¼ãåæï¼èç½è³ªèªè¨æ¨¡å (PLM)ï¼ä¾å¦ ESM-2ï¼å·²å¾èªç¶èç½è³ªåºåçå®å®ä¸­å­¸ç¿å°å¤§éçé åºé²åç¥è­ãæ­¤å¤ï¼å ProteinMPNN ç­åºæ¼çµæ§çç·¨ç¢¼å¨ééåå½¢ç¥ç¶ç¶²è·¯å­¸ç¿èç½è³ªççµæ§è³è¨ãç¶èï¼å°æªæ¢è¨çµåèç½è³ªç·¨ç¢¼å¨æ¯å¦è½å¢å¼· LLM å°èç½è³ªççè§£ãçºäºå½åéåå·®è·ï¼æåæåº EvoLlamaï¼ä¸åå¤æ¨¡ææ¶æ§ï¼å®çµåä¸ååºæ¼çµæ§çç·¨ç¢¼å¨ãä¸ååºæ¼åºåçèç½è³ªç·¨ç¢¼å¨åä¸åç¨æ¼çè§£èç½è³ªç LLMãEvoLlama åå«ä¸å ProteinMPNN çµæ§ç·¨ç¢¼å¨ãä¸å ESM-2 èç½è³ªåºåç·¨ç¢¼å¨ãä¸åå¤æ¨¡ææå½±å¨ï¼ç¨æ¼å°é½èç½è³ªåæå­è¡¨å¾µï¼ä»¥åä¸å Llama-3 æå­è§£ç¢¼å¨ãçºäºè¨ç·´ EvoLlamaï¼æåéå°èç½è³ªå°åçæä»¤åééèªç¶èªè¨æä»¤ç¯æ¬è¡¨éçèç½è³ªå±¬æ§é æ¸¬è³æéå¾®èª¿å®ãæåçå¯¦é©é¡¯ç¤ºï¼EvoLlama çèç½è³ªçè§£è½åå·²ç²å¾é¡¯èæåï¼å¨é¶æ¬¡å­¸ç¿è¨­å®ä¸­ï¼å¹³ååªæ¼å¶ä»å¾®èª¿çèç½è³ªå°å LLM 1%-8%ï¼ä¸¦å¨æç£ç£çå¾®èª¿ä¸­å¹³ååªæ¼æåé²çåºæº 6%ãå¨èç½è³ªå±¬æ§é æ¸¬è³æéä¸ï¼æåçåæ³éå°äºæå¸æççµæï¼èæåé²çç¹å®ä»»ååºæºç¸ç¶ãæåå°å¨æªä¾çæ¬ä¸­éåºæåçç¨å¼ç¢¼ã

##### **Embodied CoT Distillation From LLM To Off-the-shelf Agents**
2412.11499v1 by Wonje Choi, Woo Kyung Kim, Minjong Yoo, Honguk Woo

We address the challenge of utilizing large language models (LLMs) for
complex embodied tasks, in the environment where decision-making systems
operate timely on capacity-limited, off-the-shelf devices. We present DeDer, a
framework for decomposing and distilling the embodied reasoning capabilities
from LLMs to efficient, small language model (sLM)-based policies. In DeDer,
the decision-making process of LLM-based strategies is restructured into a
hierarchy with a reasoning-policy and planning-policy. The reasoning-policy is
distilled from the data that is generated through the embodied in-context
learning and self-verification of an LLM, so it can produce effective
rationales. The planning-policy, guided by the rationales, can render optimized
plans efficiently. In turn, DeDer allows for adopting sLMs for both policies,
deployed on off-the-shelf devices. Furthermore, to enhance the quality of
intermediate rationales, specific to embodied tasks, we devise the embodied
knowledge graph, and to generate multiple rationales timely through a single
inference, we also use the contrastively prompted attention model. Our
experiments with the ALFRED benchmark demonstrate that DeDer surpasses leading
language planning and distillation approaches, indicating the applicability and
efficiency of sLM-based embodied policies derived through DeDer.

æè¦ï¼æåè§£æ±ºäºå¨æ±ºç­ç³»çµ±æ¼å®¹éæéçç¾æè¨­åä¸å³æéä½çç°å¢ä¸­ï¼å©ç¨å¤§åèªè¨æ¨¡å (LLM) å·è¡è¤éå·èº«ä»»åçææ°ãæåæåº DeDerï¼ä¸åç¨æ¼å°å·èº«æ¨çè½åå¾ LLM åè§£ä¸¦èååºé«æè½ãå°åèªè¨æ¨¡å (sLM) çºåºç¤çæ¿ç­çæ¡æ¶ãå¨ DeDer ä¸­ï¼åºæ¼ LLM çç­ç¥çæ±ºç­æµç¨è¢«éæ°çµæ§çºä¸åå·ææ¨çæ¿ç­åè¦åæ¿ç­çéå±¤ãæ¨çæ¿ç­å¾éé LLM çå·èº«æå¢å­¸ç¿åèªæé©è­æç¢ççè³æä¸­èååºï¼å æ­¤å®å¯ä»¥ç¢çææçä¾æãè¦åæ¿ç­å¨ä¾æçå¼å°ä¸ï¼å¯ä»¥ææçå°åç¾æä½³åçè¨ç«ãåéä¾ï¼DeDer åè¨±æ¡ç¨ sLM ä¾å·è¡éå©åæ¿ç­ï¼ä¸¦é¨ç½²å¨ç¾æè¨­åä¸ãæ­¤å¤ï¼çºäºæåä¸­éä¾æçåè³ªï¼ç¹å¥æ¯éå°å·èº«ä»»åï¼æåè¨­è¨äºå·èº«ç¥è­åè­ï¼ä¸¦ééå®ä¸æ¨è«å³æç¢çå¤åä¾æï¼æåä¹ä½¿ç¨äºå°æ¯æç¤ºæ³¨æåæ¨¡åãæåä½¿ç¨ ALFRED åºæºé²è¡çå¯¦é©è­æï¼DeDer è¶è¶äºé åçèªè¨è¦ååèåæ¹æ³ï¼éè¡¨ç¤ºéé DeDer è¡ççåºæ¼ sLM çå·èº«æ¿ç­å·æé©ç¨æ§åæçã

##### **How Can LLMs and Knowledge Graphs Contribute to Robot Safety? A Few-Shot Learning Approach**
2412.11387v1 by Abdulrahman Althobaiti, Angel Ayala, JingYing Gao, Ali Almutairi, Mohammad Deghat, Imran Razzak, Francisco Cruz

Large Language Models (LLMs) are transforming the robotics domain by enabling
robots to comprehend and execute natural language instructions. The cornerstone
benefits of LLM include processing textual data from technical manuals,
instructions, academic papers, and user queries based on the knowledge
provided. However, deploying LLM-generated code in robotic systems without
safety verification poses significant risks. This paper outlines a safety layer
that verifies the code generated by ChatGPT before executing it to control a
drone in a simulated environment. The safety layer consists of a fine-tuned
GPT-4o model using Few-Shot learning, supported by knowledge graph prompting
(KGP). Our approach improves the safety and compliance of robotic actions,
ensuring that they adhere to the regulations of drone operations.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) ééè®æ©å¨äººçè§£ä¸¦å·è¡èªç¶èªè¨æä»¤ï¼è½è®äºæ©å¨äººé åãLLM çåºç³åªé»åæ¬èçåºæ¼ææä¾ç¥è­çæè¡æåãèªªæãå­¸è¡è«æåä½¿ç¨èæ¥è©¢ä¸­çæå­è³æãç¶èï¼å¨æ²æå®å¨é©è­çææ³ä¸ï¼å¨æ©å¨äººç³»çµ±ä¸­é¨ç½² LLM çæçç¨å¼ç¢¼æå¸¶ä¾é¡¯èçé¢¨éªãæ¬ææ¦è¿°äºä¸åå®å¨å±¤ï¼å¨å·è¡å®ä»¥æ§å¶æ¨¡æ¬ç°å¢ä¸­çç¡äººæ©ä¹åï¼é©è­ ChatGPT çæçç¨å¼ç¢¼ãå®å¨å±¤ç±ä¸åä½¿ç¨å°æ¬¡å­¸ç¿é²è¡å¾®èª¿ç GPT-4o æ¨¡åçµæï¼ä¸¦ç±ç¥è­åè¡¨æç¤º (KGP) æ¯æ´ãæåçåæ³æ¹åäºæ©å¨äººåä½çå®å¨æ§èåè¦æ§ï¼ç¢ºä¿å®åç¬¦åç¡äººæ©æä½æ³è¦ã

##### **Embracing Large Language Models in Traffic Flow Forecasting**
2412.12201v1 by Yusheng Zhao, Xiao Luo, Haomin Wen, Zhiping Xiao, Wei Ju, Ming Zhang

Traffic flow forecasting aims to predict future traffic flows based on the
historical traffic conditions and the road network. It is an important problem
in intelligent transportation systems, with a plethora of methods been
proposed. Existing efforts mainly focus on capturing and utilizing
spatio-temporal dependencies to predict future traffic flows. Though promising,
they fall short in adapting to test-time environmental changes of traffic
conditions. To tackle this challenge, we propose to introduce large language
models (LLMs) to help traffic flow forecasting and design a novel method named
Large Language Model Enhanced Traffic Flow Predictor (LEAF). LEAF adopts two
branches, capturing different spatio-temporal relations using graph and
hypergraph structures respectively. The two branches are first pre-trained
individually, and during test-time, they yield different predictions. Based on
these predictions, a large language model is used to select the most likely
result. Then, a ranking loss is applied as the learning objective to enhance
the prediction ability of the two branches. Extensive experiments on several
datasets demonstrate the effectiveness of the proposed LEAF.

æè¦ï¼äº¤éæµéé æ¸¬æ¨å¨æ ¹ææ­·å²äº¤éçæ³åéè·¯ç¶²è·¯é æ¸¬æªä¾çäº¤éæµéãéæ¯æºæ§éè¼¸ç³»çµ±ä¸­ä¸åéè¦çåé¡ï¼å·²ç¶æåºäºè¨±å¤æ¹æ³ãç¾æåªåä¸»è¦éä¸­å¨æ·ååå©ç¨æç©ºä¾è³´æ§ä¾é æ¸¬æªä¾çäº¤éæµéãåç®¡æåæ¯ï¼ä½å®åå¨é©æäº¤éçæ³çæ¸¬è©¦æéç°å¢è®åæ¹é¢ä»æä¸è¶³ãçºäºæå°éä¸ææ°ï¼æåå»ºè­°å¼å¥å¤§åèªè¨æ¨¡å (LLM) ä¾å¹«å©äº¤éæµéé æ¸¬ï¼ä¸¦è¨­è¨ä¸ç¨®åçºå¤§åèªè¨æ¨¡åå¢å¼·äº¤éæµéé æ¸¬å¨ (LEAF) çæ°æ¹æ³ãLEAF æ¡ç¨å©ååæ¯ï¼åå¥ä½¿ç¨åå½¢åè¶åå½¢çµæ§æ·åä¸åçæç©ºéä¿ãéå©ååæ¯é¦ååå¥é²è¡é è¨ç·´ï¼å¨æ¸¬è©¦æï¼å®åç¢çä¸åçé æ¸¬ãåºæ¼éäºé æ¸¬ï¼ä½¿ç¨å¤§åèªè¨æ¨¡åé¸æææå¯è½ççµæãç¶å¾ï¼å°æåæå¤±æç¨çºå­¸ç¿ç®æ¨ï¼ä»¥å¢å¼·å©ååæ¯çé æ¸¬è½åãå¨å¹¾åæ¸æéä¸é²è¡çå»£æ³å¯¦é©è­æäºææåºç LEAF çæææ§ã

##### **SceneLLM: Implicit Language Reasoning in LLM for Dynamic Scene Graph Generation**
2412.11026v1 by Hang Zhang, Zhuoling Li, Jun Liu

Dynamic scenes contain intricate spatio-temporal information, crucial for
mobile robots, UAVs, and autonomous driving systems to make informed decisions.
Parsing these scenes into semantic triplets <Subject-Predicate-Object> for
accurate Scene Graph Generation (SGG) is highly challenging due to the
fluctuating spatio-temporal complexity. Inspired by the reasoning capabilities
of Large Language Models (LLMs), we propose SceneLLM, a novel framework that
leverages LLMs as powerful scene analyzers for dynamic SGG. Our framework
introduces a Video-to-Language (V2L) mapping module that transforms video
frames into linguistic signals (scene tokens), making the input more
comprehensible for LLMs. To better encode spatial information, we devise a
Spatial Information Aggregation (SIA) scheme, inspired by the structure of
Chinese characters, which encodes spatial data into tokens. Using Optimal
Transport (OT), we generate an implicit language signal from the frame-level
token sequence that captures the video's spatio-temporal information. To
further improve the LLM's ability to process this implicit linguistic input, we
apply Low-Rank Adaptation (LoRA) to fine-tune the model. Finally, we use a
transformer-based SGG predictor to decode the LLM's reasoning and predict
semantic triplets. Our method achieves state-of-the-art results on the Action
Genome (AG) benchmark, and extensive experiments show the effectiveness of
SceneLLM in understanding and generating accurate dynamic scene graphs.

æè¦ï¼åæå ´æ¯åå«è¤éçæç©ºè³è¨ï¼å°æ¼è¡åæ©å¨äººãç¡äººæ©åèªåé§é§ç³»çµ±ååºææºçæ±ºç­è³ééè¦ã
ç±æ¼æç©ºè¤éæ§æ³¢åï¼å°éäºå ´æ¯è§£ææèªç¾©ä¸åçµ <ä¸»è©-è¬è©-åè©> ä»¥é²è¡æºç¢ºçå ´æ¯åçæ (SGG) æ¯ä¸é æ¥µå·ææ°æ§çä»»åã
åå°å¤§åèªè¨æ¨¡å (LLM) çæ¨çè½ååç¼ï¼æåæåºäº SceneLLMï¼éæ¯ä¸åæ°ç©çæ¡æ¶ï¼å©ç¨ LLM ä½çºå¼·å¤§çå ´æ¯åæå¨ï¼ç¨æ¼åæ SGGã
æåçæ¡æ¶å¼å¥äºä¸åå½±çè½èªè¨ (V2L) æ å°æ¨¡çµï¼å°å½±çæ ¼è½ææèªè¨è¨è (å ´æ¯ä»£å¹£)ï¼è® LLM æ´å®¹æçè§£è¼¸å¥ã
çºäºæ´å¥½å°ç·¨ç¢¼ç©ºéè³è¨ï¼æåè¨­è¨äºä¸åç©ºéè³è¨èå (SIA) æ¶æ§ï¼å¶éæä¾èªæ¼¢å­ççµæ§ï¼å°ç©ºéè³æç·¨ç¢¼æä»£å¹£ã
ä½¿ç¨æä½³å³è¼¸ (OT)ï¼æåå¾å¹ç´ä»£å¹£åºåç¢çä¸åé±å«çèªè¨è¨èï¼ææå½±ççæç©ºè³è¨ã
çºäºé²ä¸æ­¥æé« LLM èçæ­¤é±å«èªè¨è¼¸å¥çè½åï¼æåæç¨ä½ç§©é©æ (LoRA) ä¾å¾®èª¿æ¨¡åã
æå¾ï¼æåä½¿ç¨ä¸ååºæ¼è½æå¨ç SGG é æ¸¬å¨ä¾è§£ç¢¼ LLM çæ¨çä¸¦é æ¸¬èªç¾©ä¸åçµã
æåçæ¨¡åå¨åä½åºå çµ (AG) åºæºä¸åå¾äºæåé²ççµæï¼å»£æ³çå¯¦é©é¡¯ç¤ºäº SceneLLM å¨çè§£åçææºç¢ºçåæå ´æ¯åæ¹é¢çæææ§ã

##### **MedG-KRP: Medical Graph Knowledge Representation Probing**
2412.10982v2 by Gabriel R. Rosenbaum, Lavender Yao Jiang, Ivaxi Sheth, Jaden Stryker, Anton Alyakin, Daniel Alexander Alber, Nicolas K. Goff, Young Joon Fred Kwon, John Markert, Mustafa Nasir-Moin, Jan Moritz Niehues, Karl L. Sangwon, Eunice Yang, Eric Karl Oermann

Large language models (LLMs) have recently emerged as powerful tools, finding
many medical applications. LLMs' ability to coalesce vast amounts of
information from many sources to generate a response-a process similar to that
of a human expert-has led many to see potential in deploying LLMs for clinical
use. However, medicine is a setting where accurate reasoning is paramount. Many
researchers are questioning the effectiveness of multiple choice question
answering (MCQA) benchmarks, frequently used to test LLMs. Researchers and
clinicians alike must have complete confidence in LLMs' abilities for them to
be deployed in a medical setting. To address this need for understanding, we
introduce a knowledge graph (KG)-based method to evaluate the biomedical
reasoning abilities of LLMs. Essentially, we map how LLMs link medical concepts
in order to better understand how they reason. We test GPT-4, Llama3-70b, and
PalmyraMed-70b, a specialized medical model. We enlist a panel of medical
students to review a total of 60 LLM-generated graphs and compare these graphs
to BIOS, a large biomedical KG. We observe GPT-4 to perform best in our human
review but worst in our ground truth comparison; vice-versa with PalmyraMed,
the medical model. Our work provides a means of visualizing the medical
reasoning pathways of LLMs so they can be implemented in clinical settings
safely and effectively.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) è¿æå·²æçºå¼·å¤§çå·¥å·ï¼å¨é«çé åä¸­ç¼ç¾è¨±å¤æç¨ãLLM å¾è¨±å¤ä¾æºå¯éå¤§éè³è¨ä»¥ç¢çåæçè½åï¼æ­¤éç¨é¡ä¼¼æ¼äººé¡å°å®¶çéç¨ï¼ï¼å·²è®è¨±å¤äººçå°å° LLM é¨ç½²æ¼è¨åºç¨éçæ½åãç¶èï¼é«å­¸æ¯ä¸åæºç¢ºæ¨çè³ééè¦çé åãè¨±å¤ç ç©¶äººå¡è³ªçå¤é¸é¡åç­ (MCQA) åºæºçæææ§ï¼èéç¶å¸¸è¢«ç¨æ¼æ¸¬è©¦ LLMãç ç©¶äººå¡åè¨åºé«çé½å¿é å° LLM çè½åæå®å¨çä¿¡å¿ï¼æè½å°å¶é¨ç½²æ¼é«çç°å¢ä¸­ãçºäºæ»¿è¶³éç¨®çè§£éæ±ï¼æåå¼å¥ä¸ååºæ¼ç¥è­åè­ (KG) çæ¹æ³ä¾è©ä¼° LLM ççç©é«å­¸æ¨çè½åãåºæ¬ä¸ï¼æåç¹ªè£½ LLM å¦ä½é£çµé«çæ¦å¿µï¼ä»¥æ´å¥½å°çè§£å®åçæ¨çæ¹å¼ãæåæ¸¬è©¦äº GPT-4ãLlama3-70b å PalmyraMed-70bï¼éæ¯ä¸åå°éçé«çæ¨¡åãæåå¾µéäºä¸çµé«å­¸çä¾æª¢é±ç¸½å± 60 å LLM çæçåè¡¨ï¼ä¸¦å°éäºåè¡¨è BIOSï¼ä¸åå¤§åçç©é«å­¸ KGï¼é²è¡æ¯è¼ãæåè§å¯å° GPT-4 å¨æåçäººå·¥å¯©æ¥ä¸­è¡¨ç¾æä½³ï¼ä½å¨æåçåºæ¬äºå¯¦æ¯è¼ä¸­è¡¨ç¾æå·®ï¼èå°éçé«çæ¨¡å PalmyraMed åç¸åãæåçç ç©¶æä¾äºä¸ç¨®å¯è¦å LLM é«çæ¨çè·¯å¾çæ¹æ³ï¼ä»¥ä¾¿å®åè½å¤ å®å¨ææå°å¯¦ä½æ¼è¨åºç°å¢ä¸­ã

##### **Thinking with Knowledge Graphs: Enhancing LLM Reasoning Through Structured Data**
2412.10654v1 by Xue Wu, Kostas Tsioutsiouliklis

Large Language Models (LLMs) have demonstrated remarkable capabilities in
natural language understanding and generation. However, they often struggle
with complex reasoning tasks and are prone to hallucination. Recent research
has shown promising results in leveraging knowledge graphs (KGs) to enhance LLM
performance. KGs provide a structured representation of entities and their
relationships, offering a rich source of information that can enhance the
reasoning capabilities of LLMs. For this work, we have developed different
techniques that tightly integrate KG structures and semantics into LLM
representations. Our results show that we are able to significantly improve the
performance of LLMs in complex reasoning scenarios, and ground the reasoning
process with KGs. We are the first to represent KGs with programming language
and fine-tune pretrained LLMs with KGs. This integration facilitates more
accurate and interpretable reasoning processes, paving the way for more
advanced reasoning capabilities of LLMs.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å¨èªç¶èªè¨çè§£åçææ¹é¢å±ç¾äºéå¡çè½åãç¶èï¼å®åç¶å¸¸å¨è¤éçæ¨çä»»åä¸­ææï¼ä¸¦ä¸å®¹æåºç¾å¹»è¦ºãæè¿çç ç©¶é¡¯ç¤ºåºå©ç¨ç¥è­åè­ (KG) ä¾å¢å¼· LLM æè½çè¯å¥½çµæãKG æä¾å¯¦é«åå¶éä¿ççµæ§åè¡¨ç¤ºï¼æä¾äºè±å¯çè³è¨ä¾æºï¼å¯ä»¥å¢å¼· LLM çæ¨çè½åãå°æ¼éé å·¥ä½ï¼æåéç¼äºä¸åçæè¡ï¼å° KG çµæ§åèªç¾©ç·å¯æ´åå° LLM è¡¨ç¤ºä¸­ãæåççµæè¡¨æï¼æåè½å¤ é¡¯èæå LLM å¨è¤éæ¨çå ´æ¯ä¸­çæè½ï¼ä¸¦ä»¥ KG çºåºç¤é²è¡æ¨çéç¨ãæåæ¯ç¬¬ä¸åä½¿ç¨ç¨å¼èªè¨è¡¨ç¤º KGï¼ä¸¦ä½¿ç¨ KG å¾®èª¿é è¨ç·´ LLM çäººãéç¨®æ´åæå©æ¼æ´æºç¢ºä¸å¯è§£éçæ¨çéç¨ï¼çº LLM æ´åé²çæ¨çè½åéªè·¯ã

##### **WHAT-IF: Exploring Branching Narratives by Meta-Prompting Large Language Models**
2412.10582v2 by Runsheng "Anson" Huang, Lara J. Martin, Chris Callison-Burch

WHAT-IF -- Writing a Hero's Alternate Timeline through Interactive Fiction --
is a system that uses zero-shot meta-prompting to create branching narratives
from a prewritten story. Played as an interactive fiction (IF) game, WHAT-IF
lets the player choose between decisions that the large language model (LLM)
GPT-4 generates as possible branches in the story. Starting with an existing
linear plot as input, a branch is created at each key decision taken by the
main character. By meta-prompting the LLM to consider the major plot points
from the story, the system produces coherent and well-structured alternate
storylines. WHAT-IF stores the branching plot tree in a graph which helps it to
both keep track of the story for prompting and maintain the structure for the
final IF system. A video demo of our system can be found here:
https://youtu.be/8vBqjqtupcc.

æè¦ï¼WHAT-IFââééäºåå°èªªæ°å¯«è±éçå¦é¡æéç·ââ
æ¯ä¸åä½¿ç¨é¶æ¬¡æç¤ºä¾å»ºç«å¾é åæ°å¯«çæäºåæ­§æäºçç³»çµ±ãä»¥äºåå°èªª (IF) éæ²çæ¹å¼éç©ï¼WHAT-IF
è®ç©å®¶å¨å¤§åèªè¨æ¨¡å (LLM)
GPT-4 ç¢ççæäºä¸­å¯è½çæ¯ç·ä¸­é¸ææ±ºå®ãå¾ç¾æçç·æ§æç¯ä½çºè¼¸å¥éå§ï¼å¨ä¸»è¦è§è²ååºçæ¯åééµæ±ºå®ä¸­ç¢çä¸åæ¯ç·ãééåæç¤º LLM èéæäºä¸­çä¸»è¦æç¯ï¼ç³»çµ±ç¢çé£è²«ä¸çµæ§è¯å¥½çå¦é¡æäºç·ãWHAT-IF å°åæ­§æç¯æ¨¹å²å­å¨åå½¢ä¸­ï¼éæå©æ¼å®åæè¿½è¹¤æäºä»¥æç¤ºåç¶­è­·æçµ IF ç³»çµ±ççµæ§ãæåç³»çµ±çå½±çç¤ºç¯å¯ä»¥å¨éè£¡æ¾å°ï¼
https://youtu.be/8vBqjqtupccã

##### **Can LLMs Convert Graphs to Text-Attributed Graphs?**
2412.10136v1 by Zehong Wang, Sidney Liu, Zheyuan Zhang, Tianyi Ma, Chuxu Zhang, Yanfang Ye

Graphs are ubiquitous data structures found in numerous real-world
applications, such as drug discovery, recommender systems, and social network
analysis. Graph neural networks (GNNs) have become a popular tool to learn node
embeddings through message passing on these structures. However, a significant
challenge arises when applying GNNs to multiple graphs with different feature
spaces, as existing GNN architectures are not designed for cross-graph feature
alignment. To address this, recent approaches introduce text-attributed graphs,
where each node is associated with a textual description, enabling the use of a
shared textual encoder to project nodes from different graphs into a unified
feature space. While promising, this method relies heavily on the availability
of text-attributed data, which can be difficult to obtain in practice. To
bridge this gap, we propose a novel method named Topology-Aware Node
description Synthesis (TANS), which leverages large language models (LLMs) to
automatically convert existing graphs into text-attributed graphs. The key idea
is to integrate topological information with each node's properties, enhancing
the LLMs' ability to explain how graph topology influences node semantics. We
evaluate our TANS on text-rich, text-limited, and text-free graphs,
demonstrating that it enables a single GNN to operate across diverse graphs.
Notably, on text-free graphs, our method significantly outperforms existing
approaches that manually design node features, showcasing the potential of LLMs
for preprocessing graph-structured data, even in the absence of textual
information. The code and data are available at
https://github.com/Zehong-Wang/TANS.

æè¦ï¼åå½¢æ¯æ®éå­å¨æ¼è¨±å¤çå¯¦ä¸çæç¨ä¸­çè³æçµæ§ï¼ä¾å¦è¥ç©ç¼ç¾ãæ¨è¦ç³»çµ±åç¤¾äº¤ç¶²è·¯åæãåå½¢ç¥ç¶ç¶²è·¯ (GNN) å·²æçºä¸ç¨®æµè¡çå·¥å·ï¼å¯ééå¨éäºçµæ§ä¸å³éè¨æ¯ä¾å­¸ç¿ç¯é»åµå¥ãç¶èï¼ç¶å° GNN æç¨æ¼å·æä¸åç¹å¾µç©ºéçå¤ååå½¢æï¼æåºç¾ä¸åéå¤§çææ°ï¼å çºç¾æç GNN æ¶æ§ä¸¦éè¨­è¨ç¨æ¼è·¨åå½¢ç¹å¾µå°é½ãçºäºè§£æ±ºéååé¡ï¼æè¿çæ¹æ³å¼å¥äºæå­å±¬æ§åå½¢ï¼å¶ä¸­æ¯åç¯é»é½èæå­æè¿°ç¸éè¯ï¼å¾èå¯ä»¥ä½¿ç¨å±ç¨æå­ç·¨ç¢¼å¨å°ä¾èªä¸ååå½¢çç¯é»æå½±å°çµ±ä¸çç¹å¾µç©ºéä¸­ãåç®¡æå¸æï¼ä½æ­¤æ¹æ³å¨å¾å¤§ç¨åº¦ä¸ä¾è³´æ¼æå­å±¬æ§è³æçå¯ç¨æ§ï¼éå¨å¯¦åä¸å¯è½é£ä»¥åå¾ãçºäºå½è£éåå·®è·ï¼æåæåºäºä¸ç¨®åçºææ²æç¥ç¯é»æè¿°åæ (TANS) çæ°æ¹æ³ï¼è©²æ¹æ³å©ç¨å¤§åèªè¨æ¨¡å (LLM) å°ç¾æåå½¢èªåè½æçºæå­å±¬æ§åå½¢ãå¶ééµææ³æ¯å°ææ²è³è¨èæ¯åç¯é»çå±¬æ§æ´åå¨ä¸èµ·ï¼å¢å¼· LLM è§£éåå½¢ææ²å¦ä½å½±é¿ç¯é»èªç¾©çè½åãæåå¨æå­è±å¯ãæå­åéåç¡æå­åå½¢ä¸è©ä¼°æåç TANSï¼è­æå®è½è®å®ä¸ GNN å¨ä¸åçåå½¢ä¸­éä½ãå¼å¾æ³¨æçæ¯ï¼å¨ç¡æå­åå½¢ä¸ï¼æåçæ¨¡åé¡¯èåªæ¼æåè¨­è¨ç¯é»ç¹å¾µçç¾ææ¹æ³ï¼å±ç¤ºäº LLM å¨é èçåå½¢çµæ§è³ææ¹é¢çæ½åï¼å³ä½¿å¨æ²ææå­è³è¨çææ³ä¸ä¹æ¯å¦æ­¤ãç¨å¼ç¢¼åè³æå¯å¨ https://github.com/Zehong-Wang/TANS åå¾ã

##### **Lost in the Middle, and In-Between: Enhancing Language Models' Ability to Reason Over Long Contexts in Multi-Hop QA**
2412.10079v1 by George Arthur Baker, Ankush Raut, Sagi Shaier, Lawrence E Hunter, Katharina von der Wense

Previous work finds that recent long-context language models fail to make
equal use of information in the middle of their inputs, preferring pieces of
information located at the tail ends which creates an undue bias in situations
where we would like models to be equally capable of using different parts of
the input. Thus far, the problem has mainly only been considered in settings
with single pieces of critical information, leading us to question what happens
when multiple necessary pieces of information are spread out over the inputs.
Here, we demonstrate the effects of the "lost in the middle" problem in the
multi-hop question answering setting -- in which multiple reasoning "hops" over
disconnected documents are required -- and show that performance degrades not
only with respect to the distance of information from the edges of the context,
but also between pieces of information. Additionally, we experiment with means
of alleviating the problem by reducing superfluous document contents through
knowledge graph triple extraction and summarization, and prompting models to
reason more thoroughly using chain-of-thought prompting.

æè¦ï¼ååçç ç©¶ç¼ç¾ï¼æè¿çé·èªå¢èªè¨æ¨¡åç¡æ³å¹³åå©ç¨å¶è¼¸å¥ä¸­æ®µçè³è¨ï¼åå¥½ä½æ¼å°¾ç«¯çè³è¨çæ®µï¼éæé æä¸ç¶çåå·®ï¼å¨æåå¸ææ¨¡åè½å¹³åä½¿ç¨è¼¸å¥ä¸åé¨åçææ³ä¸ãå°ç®åçºæ­¢ï¼éååé¡ä¸»è¦åªå¨å·æå®ä¸ééµè³è¨çæ®µçè¨­å®ä¸­è¢«èæ®ï¼å°è´æåè³ªçç¶å¤åå¿è¦çè³è¨çæ®µæ£ä½å¨è¼¸å¥ä¸­ææç¼çä»éº¼ææ³ãå¨æ­¤ï¼æåç¤ºç¯äºãéºå¤±å¨ä¸­éãåé¡å¨å¤è·³åç­è¨­å®ä¸­çå½±é¿ï¼å¶ä¸­éè¦è·¨è¶æªé£æ¥æä»¶çå¤æ¬¡æ¨çãè·³èºãï¼ä¸¦é¡¯ç¤ºæè½ä¸åæé¨èè³è¨èèªå¢éç·£çè·é¢èä¸éï¼ä¹æé¨èè³è¨çæ®µä¹éçè·é¢èä¸éãæ­¤å¤ï¼æåå¯¦é©äºééç¥è­åè­ä¸åçµèååæè¦ä¾æ¸å°å¤é¤æä»¶å§å®¹ï¼ä¸¦æç¤ºæ¨¡åä½¿ç¨æèéæç¤ºä¾æ´å¾¹åºå°æ¨çï¼ä»¥æ¸è¼åé¡çæ¹æ³ã

##### **Low-Resource Fast Text Classification Based on Intra-Class and Inter-Class Distance Calculation**
2412.09922v1 by Yanxu Mao, Peipei Liu, Tiehan Cui, Congying Liu, Datao You

In recent years, text classification methods based on neural networks and
pre-trained models have gained increasing attention and demonstrated excellent
performance. However, these methods still have some limitations in practical
applications: (1) They typically focus only on the matching similarity between
sentences. However, there exists implicit high-value information both within
sentences of the same class and across different classes, which is very crucial
for classification tasks. (2) Existing methods such as pre-trained language
models and graph-based approaches often consume substantial memory for training
and text-graph construction. (3) Although some low-resource methods can achieve
good performance, they often suffer from excessively long processing times. To
address these challenges, we propose a low-resource and fast text
classification model called LFTC. Our approach begins by constructing a
compressor list for each class to fully mine the regularity information within
intra-class data. We then remove redundant information irrelevant to the target
classification to reduce processing time. Finally, we compute the similarity
distance between text pairs for classification. We evaluate LFTC on 9 publicly
available benchmark datasets, and the results demonstrate significant
improvements in performance and processing time, especially under limited
computational and data resources, highlighting its superior advantages.

æè¦ï¼è¿å¹´æ¥ï¼åºäºç¥ç»ç½ç»åé¢è®­ç»æ¨¡åçææ¬åç±»æ¹æ³è¶æ¥è¶åå°å³æ³¨ï¼å¹¶è¡¨ç°åºä¼å¼çæ§è½ãç¶èï¼è¿äºæ¹æ³å¨å®éåºç¨ä¸­ä»ç¶å­å¨ä¸äºå±éæ§ï¼(1) å®ä»¬éå¸¸åªå³æ³¨å¥å­ä¹é´çå¹éç¸ä¼¼æ§ãç¶èï¼åç±»å¥å­åé¨åä¸åç±»å¥å­ä¹é´é½å­å¨éå«çé«ä»·å¼ä¿¡æ¯ï¼è¿å¯¹åç±»ä»»å¡è³å³éè¦ã(2) é¢è®­ç»è¯­è¨æ¨¡åååºäºå¾çæ¹æ³ç­ç°ææ¹æ³éå¸¸éè¦å¤§éçåå­ç¨äºè®­ç»åææ¬å¾æå»ºã(3) è½ç¶ä¸äºä½èµæºæ¹æ³å¯ä»¥è¾¾å°è¯å¥½çæ§è½ï¼ä½å®ä»¬éå¸¸å¤çæ¶é´è¿é¿ãä¸ºäºåºå¯¹è¿äºææï¼æä»¬æåºäºä¸ç§ä½èµæºä¸å¿«éçææ¬åç±»æ¨¡åï¼ç§°ä¸º LFTCãæä»¬çæ¹æ³é¦åä¸ºæ¯ä¸ªç±»å«æå»ºä¸ä¸ªåç¼©å¨åè¡¨ï¼ä»¥ååææç±»åæ°æ®ä¸­çè§å¾æ§ä¿¡æ¯ãç¶åï¼æä»¬å é¤ä¸ç®æ åç±»æ å³çåä½ä¿¡æ¯ï¼ä»¥åå°å¤çæ¶é´ãæåï¼æä»¬è®¡ç®ææ¬å¯¹ä¹é´çç¸ä¼¼æ§è·ç¦»è¿è¡åç±»ãæä»¬å¨ 9 ä¸ªå¬å¼çåºåæ°æ®éä¸è¯ä¼°äº LFTCï¼ç»æè¡¨æå¨æéçè®¡ç®åæ°æ®èµæºä¸ï¼å¶æ§è½åå¤çæ¶é´é½ææ¾èæåï¼çªåºäºå¶ä¼è¶çä¼å¿ã

##### **MGM: Global Understanding of Audience Overlap Graphs for Predicting the Factuality and the Bias of News Media**
2412.10467v1 by Muhammad Arslan Manzoor, Ruihong Zeng, Dilshod Azizov, Preslav Nakov, Shangsong Liang

In the current era of rapidly growing digital data, evaluating the political
bias and factuality of news outlets has become more important for seeking
reliable information online. In this work, we study the classification problem
of profiling news media from the lens of political bias and factuality.
Traditional profiling methods, such as Pre-trained Language Models (PLMs) and
Graph Neural Networks (GNNs) have shown promising results, but they face
notable challenges. PLMs focus solely on textual features, causing them to
overlook the complex relationships between entities, while GNNs often struggle
with media graphs containing disconnected components and insufficient labels.
To address these limitations, we propose MediaGraphMind (MGM), an effective
solution within a variational Expectation-Maximization (EM) framework. Instead
of relying on limited neighboring nodes, MGM leverages features, structural
patterns, and label information from globally similar nodes. Such a framework
not only enables GNNs to capture long-range dependencies for learning
expressive node representations but also enhances PLMs by integrating
structural information and therefore improving the performance of both models.
The extensive experiments demonstrate the effectiveness of the proposed
framework and achieve new state-of-the-art results. Further, we share our
repository1 which contains the dataset, code, and documentation

æè¦ï¼<paragraph>å¨æ¸ä½è³æå¿«éæé·çæä»£ï¼è©ä¼°æ°èåªé«çæ¿æ²»åè¦åäºå¯¦æ§ï¼å°æ¼å¨ç¶²è·¯ä¸å°æ¾å¯é çè³è¨è®å¾æ´å éè¦ãå¨éé å·¥ä½ä¸­ï¼æåå¾æ¿æ²»åè¦åäºå¯¦æ§çè§åº¦ç ç©¶æ°èåªé«çåé¡åé¡ãå³çµ±çåé¡æ¹æ³ï¼ä¾å¦é åè¨ç·´çèªè¨æ¨¡å (PLM) ååç¥ç¶ç¶²è·¯ (GNN)ï¼å·²ç¶å±ç¾åºæåéçææï¼ä½å®åé¢è¨èé¡¯èçææ°ãPLM åå°æ³¨æ¼æå­ç¹å¾µï¼å°è´å®åå¿½ç¥äºå¯¦é«ä¹éçè¤ééä¿ï¼è GNN åç¶å¸¸é£ä»¥èçåå«ä¸é£éåä»¶åæ¨ç±¤ä¸è¶³çåªé«åãçºäºè§£æ±ºéäºéå¶ï¼æåæåºäº MediaGraphMind (MGM)ï¼éæ¯ä¸ç¨®å¨è®ç°æææå¤§å (EM) æ¡æ¶å§ææçè§£æ±ºæ¹æ¡ãMGM ä¸ä¾è³´æ¼æéçé°è¿ç¯é»ï¼èæ¯å©ç¨ç¹å¾µãçµæ§æ¨¡å¼åä¾èªå¨çç¸ä¼¼ç¯é»çæ¨ç±¤è³è¨ãéç¨®æ¡æ¶ä¸åä½¿ GNN è½å¤ æ·åé·ç¨ä¾è³´æ§ä»¥å­¸ç¿è¡¨éå¼ç¯é»è¡¨ç¤ºï¼èä¸éééæ´åçµæ§è³è¨ä¾å¢å¼· PLMï¼å¾èæ¹åéå©ç¨®æ¨¡åçæè½ãå»£æ³çå¯¦é©è­æäºææåºçæ¡æ¶çæææ§ï¼ä¸¦éå°äºæ°çæåé²ææãæ­¤å¤ï¼æååäº«äºæåçå²å­åº« 1ï¼å¶ä¸­åå«è³æéãç¨å¼ç¢¼åæä»¶</paragraph>

##### **Uncommon Belief in Rationality**
2412.09407v1 by Qi Shi, Pavel Naumov

Common knowledge/belief in rationality is the traditional standard assumption
in analysing interaction among agents. This paper proposes a graph-based
language for capturing significantly more complicated structures of
higher-order beliefs that agents might have about the rationality of the other
agents. The two main contributions are a solution concept that captures the
reasoning process based on a given belief structure and an efficient algorithm
for compressing any belief structure into a unique minimal form.

æè¦ï¼å¨åæä»£çä¹éçäºåæï¼çæ§ä¸­çå¸¸è­/ä¿¡å¿µæ¯å³çµ±çæ¨æºåè¨­ãæ¬ææåºäºä¸ç¨®åºæ¼åå½¢çèªè¨ï¼ç¨æ¼ææä»£çäººå¯è½å°å¶ä»ä»£çäººççæ§å·æé¡¯èæ´è¤éçé«éä¿¡å¿µçµæ§ãå©é ä¸»è¦è²¢ç»æ¯ææåºæ¼çµ¦å®ä¿¡å¿µçµæ§çæ¨çéç¨çè§£æ±ºæ¹æ¡æ¦å¿µï¼ä»¥åå°ä»»ä½ä¿¡å¿µçµæ§å£ç¸®æå¯ä¸æå°å½¢å¼çæææ¼ç®æ³ã

##### **Foundation Models and Adaptive Feature Selection: A Synergistic Approach to Video Question Answering**
2412.09230v1 by Sai Bhargav Rongali, Mohamad Hassan N C, Ankit Jha, Neha Bhargava, Saurabh Prasad, Biplab Banerjee

This paper tackles the intricate challenge of video question-answering
(VideoQA). Despite notable progress, current methods fall short of effectively
integrating questions with video frames and semantic object-level abstractions
to create question-aware video representations. We introduce Local-Global
Question Aware Video Embedding (LGQAVE), which incorporates three major
innovations to integrate multi-modal knowledge better and emphasize semantic
visual concepts relevant to specific questions. LGQAVE moves beyond traditional
ad-hoc frame sampling by utilizing a cross-attention mechanism that precisely
identifies the most relevant frames concerning the questions. It captures the
dynamics of objects within these frames using distinct graphs, grounding them
in question semantics with the miniGPT model. These graphs are processed by a
question-aware dynamic graph transformer (Q-DGT), which refines the outputs to
develop nuanced global and local video representations. An additional
cross-attention module integrates these local and global embeddings to generate
the final video embeddings, which a language model uses to generate answers.
Extensive evaluations across multiple benchmarks demonstrate that LGQAVE
significantly outperforms existing models in delivering accurate multi-choice
and open-ended answers.

æè¦ï¼æ¬ææ¢è¨äºå½±çåç­ (VideoQA) çè¤éææ°ãåç®¡åå¾é¡¯èé²å±ï¼ä½ç®åçæè¡ä»ç¡æ³ææçµååé¡ãå½±çç«é¢åèªç¾©ç©ä»¶å±¤ç´æ½è±¡ï¼ä»¥å»ºç«åé¡æç¥çå½±çè¡¨å¾µãæåå¼é²äºå±é¨-å¨ååé¡æç¥å½±çåµå¥ (LGQAVE)ï¼å®åå«ä¸é éå¤§åµæ°ï¼ä»¥æ´å¥½å°æ´åå¤æ¨¡å¼ç¥è­ï¼ä¸¦å¼·èª¿èç¹å®åé¡ç¸éçèªç¾©è¦è¦ºæ¦å¿µãLGQAVE è¶è¶äºå³çµ±çè¨æç«é¢åæ¨£ï¼å©ç¨è·¨æ³¨æåæ©å¶ç²¾ç¢ºæ¾åºèåé¡æç¸éçç«é¢ãå®ä½¿ç¨ä¸åçåå½¢ææéäºç«é¢ä¸­ç©ä»¶çåæï¼ä¸¦éé miniGPT æ¨¡åå°å®åå¥ åºæ¼åé¡èªç¾©ä¸­ãéäºåå½¢ç±åé¡æç¥åæåå½¢è½æå¨ (Q-DGT) èçï¼å®ææ¹åè¼¸åºï¼ä»¥éç¼ç´°ç·»çå¨å±åå±é¨å½±çè¡¨å¾µãé¡å¤çè·¨æ³¨æåæ¨¡çµæ´åéäºå±é¨åå¨å±åµå¥ï¼ä»¥ç¢çæçµçå½±çåµå¥ï¼èªè¨æ¨¡åä½¿ç¨éäºåµå¥ä¾ç¢çç­æ¡ãè·¨å¤ååºæºçå»£æ³è©ä¼°è­æï¼LGQAVE å¨æä¾æºç¢ºçå¤é¸åéæ¾å¼ç­æ¡æ¹é¢ï¼æé¡¯åªæ¼ç¾ææ¨¡åã

##### **Filter-then-Generate: Large Language Models with Structure-Text Adapter for Knowledge Graph Completion**
2412.09094v1 by Ben Liu, Jihai Zhang, Fangquan Lin, Cheng Yang, Min Peng

Large Language Models (LLMs) present massive inherent knowledge and superior
semantic comprehension capability, which have revolutionized various tasks in
natural language processing. Despite their success, a critical gap remains in
enabling LLMs to perform knowledge graph completion (KGC). Empirical evidence
suggests that LLMs consistently perform worse than conventional KGC approaches,
even through sophisticated prompt design or tailored instruction-tuning.
Fundamentally, applying LLMs on KGC introduces several critical challenges,
including a vast set of entity candidates, hallucination issue of LLMs, and
under-exploitation of the graph structure. To address these challenges, we
propose a novel instruction-tuning-based method, namely FtG. Specifically, we
present a \textit{filter-then-generate} paradigm and formulate the KGC task
into a multiple-choice question format. In this way, we can harness the
capability of LLMs while mitigating the issue casused by hallucinations.
Moreover, we devise a flexible ego-graph serialization prompt and employ a
structure-text adapter to couple structure and text information in a
contextualized manner. Experimental results demonstrate that FtG achieves
substantial performance gain compared to existing state-of-the-art methods. The
instruction dataset and code are available at
\url{https://github.com/LB0828/FtG}.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å·æé¾å¤§çå§é¨ç¥è­ååè¶çèªç¾©çè§£è½åï¼éå¾¹åºæ¹è®äºèªç¶èªè¨èçä¸­çåç¨®ä»»åãåç®¡å®åæåï¼ä½å¨ä½¿ LLM è½å·è¡ç¥è­åè­å®æ (KGC) æ¹é¢ä»å­å¨ä¸åééµå·®è·ãç¶é©è­æè¡¨æï¼å³ä½¿ééç²¾å¯çæç¤ºè¨­è¨æéèº«æé çæä»¤èª¿æ´ï¼LLM çè¡¨ç¾ä¹å§çµä¸å¦å³çµ±ç KGC æ¹æ³ãå¾æ ¹æ¬ä¸ä¾èªªï¼å¨ KGC ä¸æç¨ LLM æå¸¶ä¾å¹¾åééµææ°ï¼åæ¬å¤§éçå¯¦é«åé¸ãLLM çå¹»è¦ºåé¡ä»¥ååå½¢çµæ§çå©ç¨ä¸è¶³ãçºäºæå°éäºææ°ï¼æåæåºäºä¸ç¨®æ°çåºæ¼æä»¤èª¿æ´çæ¹æ³ï¼å³ FtGãå·é«ä¾èªªï¼æåæåºäºãåéæ¿¾åçæãçç¯ä¾ï¼ä¸¦å° KGC ä»»åå¶å®çºå¤é¸é¡æ ¼å¼ãéæ¨£ï¼æåå°±è½å©ç¨ LLM çè½åï¼åææ¸è¼å¹»è¦ºæé æçåé¡ãæ­¤å¤ï¼æåè¨­è¨äºä¸åéæ´»çèªååºååæç¤ºï¼ä¸¦æ¡ç¨çµæ§ææ¬é©éå¨ï¼ä»¥æå¢åçæ¹å¼çµåçµæ§åææ¬è³è¨ãå¯¦é©çµæè¡¨æï¼èç¾æçæåé²æ¹æ³ç¸æ¯ï¼FtG ç²å¾äºé¡¯èçæè½æåãæä»¤è³æéåç¨å¼ç¢¼å¯å¨
\url{https://github.com/LB0828/FtG} åå¾ã

##### **Neural Interactive Proofs**
2412.08897v1 by Lewis Hammond, Sam Adam-Day

We consider the problem of how a trusted, but computationally bounded agent
(a 'verifier') can learn to interact with one or more powerful but untrusted
agents ('provers') in order to solve a given task. More specifically, we study
the case in which agents are represented using neural networks and refer to
solutions of this problem as neural interactive proofs. First we introduce a
unifying framework based on prover-verifier games, which generalises previously
proposed interaction protocols. We then describe several new protocols for
generating neural interactive proofs, and provide a theoretical comparison of
both new and existing approaches. Finally, we support this theory with
experiments in two domains: a toy graph isomorphism problem that illustrates
the key ideas, and a code validation task using large language models. In so
doing, we aim to create a foundation for future work on neural interactive
proofs and their application in building safer AI systems.

æè¦ï¼<paragraph>æåèæ®ä¸ååé¡ï¼èªªæä¸ååä¿¡ä»»ä½è¨ç®åéçä»£çï¼ãé©è­èãï¼å¦ä½å­¸æèä¸åæå¤åå¼·å¤§ä½ä¸å¯ä¿¡çä»£çï¼ãè­æèãï¼äºåï¼ä»¥è§£æ±ºçµ¦å®çä»»åãæ´å·é«å°èªªï¼æåç ç©¶ä»£çä½¿ç¨ç¥ç¶ç¶²è·¯è¡¨ç¤ºçææ³ï¼ä¸¦å°æ­¤åé¡çè§£æ±ºæ¹æ¡ç¨±çºç¥ç¶äºåè­æãé¦åï¼æåå¼å¥ä¸ååºæ¼è­æèé©è­èéæ²ççµ±ä¸æ¡æ¶ï¼å®æ¦æ¬äºååæåºçäºååè­°ãç¶å¾ï¼æåæè¿°äºå¹¾åçæç¥ç¶äºåè­æçæ°åè­°ï¼ä¸¦å°æ°èæ¹æ³é²è¡äºçè«æ¯è¼ãæå¾ï¼æåå¨å©åé åä¸­ç¨å¯¦é©æ¯æäºéåçè«ï¼ä¸åç©å·ååæ§åé¡ï¼èªªæäºééµææ³ï¼ä»¥åä½¿ç¨å¤§åèªè¨æ¨¡åçä»£ç¢¼é©è­ä»»åãéæ¨£åï¼æåæ¨å¨çºç¥ç¶äºåè­æåå¶å¨æ§å»ºæ´å®å¨ç AI ç³»çµ±ä¸­çæç¨å¥ å®åºç¤ã</paragraph>

##### **A Graph-Based Synthetic Data Pipeline for Scaling High-Quality Reasoning Instructions**
2412.08864v1 by Jiankang Wang, Jianjun Xu, Xiaorui Wang, Yuxin Wang, Mengting Xing, Shancheng Fang, Zhineng Chen, Hongtao Xie, Yongdong Zhang

Synthesizing high-quality reasoning data for continual training has been
proven to be effective in enhancing the performance of Large Language Models
(LLMs). However, previous synthetic approaches struggle to easily scale up data
and incur high costs in the pursuit of high quality. In this paper, we propose
the Graph-based Synthetic Data Pipeline (GSDP), an economical and scalable
framework for high-quality reasoning data synthesis. Inspired by knowledge
graphs, we extracted knowledge points from seed data and constructed a
knowledge point relationships graph to explore their interconnections. By
exploring the implicit relationships among knowledge, our method achieves
$\times$255 data expansion. Furthermore, GSDP led by open-source models,
achieves synthesis quality comparable to GPT-4-0613 while maintaining
$\times$100 lower costs. To tackle the most challenging mathematical reasoning
task, we present the GSDP-MATH dataset comprising over 1.91 million pairs of
math problems and answers. After fine-tuning on GSDP-MATH, GSDP-7B based on
Mistral-7B achieves 37.7% accuracy on MATH and 78.4% on GSM8K, demonstrating
the effectiveness of our method. The dataset and models trained in this paper
will be available.

æè¦ï¼<paragraph>åæé«åè³ªæ¨çè³æä»¥é²è¡æçºè¨ç·´å·²è¢«è­å¯¦è½æææåå¤§åèªè¨æ¨¡å (LLM) çæè½ãç¶èï¼ååçåææ¹æ³é£ä»¥è¼ææ´åè³æï¼ä¸å¨è¿½æ±é«åè³ªçéç¨ä¸­æç¢çé«ææ¬ãå¨æ¬æä¸­ï¼æåæåºåºæ¼åè¡¨çåæè³æç®¡ç· (GSDP)ï¼ä¸åç¶æ¿ä¸å¯æ´åçé«åè³ªæ¨çè³æåææ¶æ§ãåç¥è­åè¡¨åç¼ï¼æåå¾ç¨®å­è³æä¸­èåç¥è­é»ï¼ä¸¦å»ºæ§ä¸åç¥è­é»éä¿åè¡¨ä»¥æ¢ç´¢å®åçç¸äºéè¯æ§ãééæ¢ç´¢ç¥è­ä¸­çé±å«éä¿ï¼æåçåæ³éå°äº $\times$255 è³ææ´åãæ­¤å¤ï¼ç±éæºæ¨¡åé å°ç GSDPï¼éå°äºè GPT-4-0613 ç¸ç¶çåæåè³ªï¼åæå°ææ¬éä½äº $\times$100ãçºäºæå°æå·ææ°æ§çæ¸å­¸æ¨çä»»åï¼æåæåºäº GSDP-MATH è³æéï¼å¶ä¸­åå«è¶é 191 è¬å°æ¸å­¸åé¡åç­æ¡ãå¨ GSDP-MATH ä¸é²è¡å¾®èª¿å¾ï¼åºæ¼ Mistral-7B ç GSDP-7B å¨ MATH ä¸éå°äº 37.7% çæºç¢ºåº¦ï¼å¨ GSM8K ä¸éå°äº 78.4%ï¼è­æäºæåæ¹æ³çæææ§ãæ¬æä¸­è¨ç·´çè³æéåæ¨¡åå°æå¬éã</paragraph>

##### **In-Context Learning with Topological Information for Knowledge Graph Completion**
2412.08742v1 by Udari Madhushani Sehwag, Kassiani Papasotiriou, Jared Vann, Sumitra Ganesh

Knowledge graphs (KGs) are crucial for representing and reasoning over
structured information, supporting a wide range of applications such as
information retrieval, question answering, and decision-making. However, their
effectiveness is often hindered by incompleteness, limiting their potential for
real-world impact. While knowledge graph completion (KGC) has been extensively
studied in the literature, recent advances in generative AI models,
particularly large language models (LLMs), have introduced new opportunities
for innovation. In-context learning has recently emerged as a promising
approach for leveraging pretrained knowledge of LLMs across a range of natural
language processing tasks and has been widely adopted in both academia and
industry. However, how to utilize in-context learning for effective KGC remains
relatively underexplored. We develop a novel method that incorporates
topological information through in-context learning to enhance KGC performance.
By integrating ontological knowledge and graph structure into the context of
LLMs, our approach achieves strong performance in the transductive setting
i.e., nodes in the test graph dataset are present in the training graph
dataset. Furthermore, we apply our approach to KGC in the more challenging
inductive setting, i.e., nodes in the training graph dataset and test graph
dataset are disjoint, leveraging the ontology to infer useful information about
missing nodes which serve as contextual cues for the LLM during inference. Our
method demonstrates superior performance compared to baselines on the
ILPC-small and ILPC-large datasets.

æè¦ï¼ç¥è­åè­ (KG) å°æ¼è¡¨ç¤ºåæ¨ççµæ§åè³è¨è³ééè¦ï¼æ¯æ´å»£æ³çæç¨ç¨å¼ï¼ä¾å¦è³è¨æª¢ç´¢ãåé¡è§£ç­åæ±ºç­å¶å®ãç¶èï¼å®åçæè½ç¶å¸¸åå°ä¸å®æ´æ§çé»ç¤ï¼éå¶äºå®åå°ç¾å¯¦ä¸çå½±é¿çæ½åãéç¶ç¥è­åè­å®æ (KGC) å·²å¨æç»ä¸­å»£æ³ç ç©¶ï¼ä½çæå¼ AI æ¨¡åçææ°é²å±ï¼ç¹å¥æ¯å¤§åèªè¨æ¨¡å (LLM)ï¼çºåµæ°å¸¶ä¾äºæ°çæ©æãæå¢å­¸ç¿æè¿å·²æçºä¸ç¨®æåéçæ¹æ³ï¼ç¨æ¼è·¨è¶ä¸ç³»åèªç¶èªè¨èçä»»åå©ç¨ LLM çé è¨ç·´ç¥è­ï¼ä¸¦å·²å»£æ³æç¨æ¼å­¸è¡çåç¢æ¥­ãç¶èï¼å¦ä½å©ç¨æå¢å­¸ç¿é²è¡ææç KGC ä»ç¶ç¸å°æªè¢«æ¢è¨ãæåéç¼äºä¸ç¨®æ°æ¹æ³ï¼ééæå¢å­¸ç¿ç´å¥ææ²è³è¨ä¾å¢å¼· KGC æè½ãééå°æ¬é«ç¥è­ååå½¢çµæ§æ´åå° LLM çæå¢ä¸­ï¼æåçåæ³å¨è½å°å¼è¨­å®ä¸­åå¾å¼·åçæè½ï¼å³æ¸¬è©¦åå½¢è³æéä¸­çç¯é»å­å¨æ¼è¨ç·´åå½¢è³æéä¸­ãæ­¤å¤ï¼æåå°æåçåæ³æç¨æ¼æ´å·ææ°æ§çæ­¸ç´å¼è¨­å®ä¸­ç KGCï¼å³è¨ç·´åå½¢è³æéåæ¸¬è©¦åå½¢è³æéä¸­çç¯é»æ¯ä¸ç¸äº¤çï¼å©ç¨æ¬é«ä¾æ¨æ·æééºå¤±ç¯é»çæç¨è³è¨ï¼éäºç¯é»å¨æ¨çéç¨ä¸­ä½çº LLM çæå¢æç¤ºãè ILPC-small å ILPC-large è³æéä¸çåºæºç¸æ¯ï¼æåçåæ³å±ç¾åºåªç°çæè½ã

##### **VEL: A Formally Verified Reasoner for OWL2 EL Profile**
2412.08739v1 by Atalay Mert Ileri, Nalen Rangarajan, Jack Cannell, Hande McGinty

Over the past two decades, the Web Ontology Language (OWL) has been
instrumental in advancing the development of ontologies and knowledge graphs,
providing a structured framework that enhances the semantic integration of
data. However, the reliability of deductive reasoning within these systems
remains challenging, as evidenced by inconsistencies among popular reasoners in
recent competitions. This evidence underscores the limitations of current
testing-based methodologies, particularly in high-stakes domains such as
healthcare. To mitigate these issues, in this paper, we have developed VEL, a
formally verified EL++ reasoner equipped with machine-checkable correctness
proofs that ensure the validity of outputs across all possible inputs. This
formalization, based on the algorithm of Baader et al., has been transformed
into executable OCaml code using the Coq proof assistant's extraction
capabilities. Our formalization revealed several errors in the original
completeness proofs, which led to changes to the algorithm to ensure its
completeness. Our work demonstrates the necessity of mechanization of reasoning
algorithms to ensure their correctness at theoretical and implementation
levels.

æè¦ï¼å¨éå»äºåå¹´ï¼Web Ontology Language (OWL) å·²å¨æ¨åæ¬ä½åç¥è­åè­çç¼å±ä¸­ç¼æ®ééµä½ç¨ï¼æä¾ä¸åå¢å¼·è³æèªææ´åççµæ§åæ¶æ§ãç¶èï¼éäºç³»çµ±ä¸­æ¼ç¹¹æ¨ççå¯é æ§ä»ç¶å·æææ°æ§ï¼æ­£å¦æè¿æ¯è³½ä¸­æµè¡çæ¨çæ©ä¹éçä¸ä¸è´æ§æè­æçé£æ¨£ãéåè­æçªé¡¯äºç¶ååºæ¼æ¸¬è©¦çæ¹æ³çå±éæ§ï¼ç¹å¥æ¯å¨é«çä¿å¥ç­é«é¢¨éªé åãçºäºæ¸è¼éäºåé¡ï¼æåå¨æ¬æä¸­éç¼äº VELï¼ä¸åæ­£å¼é©è­ç EL++ æ¨çæ©ï¼éåäºæ©å¨å¯æª¢æ¥çæ­£ç¢ºæ§è­æï¼ä»¥ç¢ºä¿å¨ææå¯è½çè¼¸å¥ä¸­è¼¸åºçæææ§ãéåå½¢å¼åï¼åºæ¼ Baader ç­äººçæ¼ç®æ³ï¼å·²ä½¿ç¨ Coq è­æå©æçæååè½è½æçºå¯å·è¡ç OCaml ç¨å¼ç¢¼ãæåçå½¢å¼åæ­ç¤ºäºåå§å®æ´æ§è­æä¸­çå¹¾åé¯èª¤ï¼éå°è´äºæ¼ç®æ³çæ¹è®ä»¥ç¢ºä¿å¶å®æ´æ§ãæåçä½åè­æäºæ¨çæ¼ç®æ³æ©æ¢°åçå¿è¦æ§ï¼ä»¥ç¢ºä¿å®åå¨çè«åå¯¦ä½å±¤é¢çæ­£ç¢ºæ§ã

##### **From communities to interpretable network and word embedding: an unified approach**
2412.08187v1 by Thibault Prouteau, Nicolas DuguÃ©, Simon Guillot

Modelling information from complex systems such as humans social interaction
or words co-occurrences in our languages can help to understand how these
systems are organized and function. Such systems can be modelled by networks,
and network theory provides a useful set of methods to analyze them. Among
these methods, graph embedding is a powerful tool to summarize the interactions
and topology of a network in a vectorized feature space. When used in input of
machine learning algorithms, embedding vectors help with common graph problems
such as link prediction, graph matching, etc. Word embedding has the goal of
representing the sense of words, extracting it from large text corpora. Despite
differences in the structure of information in input of embedding algorithms,
many graph embedding approaches are adapted and inspired from methods in NLP.
Limits of these methods are observed in both domains. Most of these methods
require long and resource greedy training. Another downside to most methods is
that they are black-box, from which understanding how the information is
structured is rather complex. Interpretability of a model allows understanding
how the vector space is structured without the need for external information,
and thus can be audited more easily. With both these limitations in mind, we
propose a novel framework to efficiently embed network vertices in an
interpretable vector space. Our Lower Dimension Bipartite Framework (LDBGF)
leverages the bipartite projection of a network using cliques to reduce
dimensionality. Along with LDBGF, we introduce two implementations of this
framework that rely on communities instead of cliques: SINr-NR and SINr-MF. We
show that SINr-MF can perform well on classical graphs and SINr-NR can produce
high-quality graph and word embeddings that are interpretable and stable across
runs.

æè¦ï¼<paragraph>ééæ¨¡æ¬äººé¡ç¤¾äº¤äºåæèªè¨ä¸­è©å½å±ç¾ç­è¤éç³»çµ±ä¸­çè³è¨ï¼æå©æ¼äºè§£éäºç³»çµ±ççµç¹åéä½æ¹å¼ãéäºç³»çµ±å¯ä»¥ç¨ç¶²è·¯ä¾å»ºæ¨¡ï¼èç¶²è·¯çè«æä¾äºæç¨çæ¹æ³éä¾åæå®åãå¨éäºæ¹æ³ä¸­ï¼åå½¢åµå¥æ¯ä¸ç¨®å¼·å¤§çå·¥å·ï¼å¯ç¨æ¼å¨åéåç¹å¾µç©ºéä¸­ç¸½çµç¶²è·¯çäº¤äºåææ²ãç¶ç¨æ¼æ©å¨å­¸ç¿æ¼ç®æ³çè¼¸å¥æï¼åµå¥åéæå©æ¼å¸¸è¦çåå½¢åé¡ï¼ä¾å¦é£çµé æ¸¬ãåå½¢éå°ç­ãè©åµå¥çç®æ¨æ¯è¡¨ç¤ºè©å½çæç¾©ï¼å¾å¤§åæå­èªæåº«ä¸­èåå®ãåç®¡åµå¥æ¼ç®æ³è¼¸å¥è³è¨ççµæ§ä¸åï¼ä½è¨±å¤åå½¢åµå¥æ¹æ³é½æ¯æ ¹æèªç¶èªè¨èçä¸­çæ¹æ³æ¹ç·¨ååç¼çãå¨å©åé åä¸­é½è§å¯å°éäºæ¹æ³çéå¶ãå¤§å¤æ¸éäºæ¹æ³éè¦æ¼«é·ä¸èè²»è³æºçè¨ç·´ãå¤§å¤æ¸æ¹æ³çå¦ä¸åç¼ºé»æ¯å®åæ¯é»çå­ï¼å¾ä¸­çè§£è³è¨å¦ä½è¢«çµæ§åç¸ç¶è¤éãæ¨¡åçå¯è§£éæ§åè¨±å¨ä¸éè¦å¤é¨è³è¨çææ³ä¸äºè§£åéç©ºéæ¯å¦ä½è¢«çµæ§åçï¼å æ­¤å¯ä»¥æ´å®¹æå°é²è¡ç¨½æ ¸ãç¢è¨éå©åéå¶ï¼æåæåºäºä¸åæ°ç©çæ¡æ¶ï¼ä»¥ææçæ¹å¼å°ç¶²è·¯é é»åµå¥å¯è§£éçåéç©ºéä¸­ãæåçä½ç¶­äºé¨åæ¡æ¶ (LDBGF) å©ç¨ç¶²è·¯çäºé¨åæå½±ä½¿ç¨æ´¾ç³»ä¾éä½ç¶­åº¦ãé¤äº LDBGF ä¹å¤ï¼æåéä»ç´¹äºå©åä¾è³´ç¤¾ç¾¤èéæ´¾ç³»çæ­¤æ¡æ¶å¯¦ä½ï¼SINr-NR å SINr-MFãæåå±ç¤ºäº SINr-MF å¨ç¶å¸åå½¢ä¸å¯ä»¥å·è¡è¯å¥½ï¼è SINr-NR å¯ä»¥ç¢çé«åè³ªçåå½¢åè©åµå¥ï¼éäºåµå¥å¨åæ¬¡å·è¡ä¸­é½æ¯å¯è§£éä¸ç©©å®çã</paragraph>

##### **Can Graph Neural Networks Learn Language with Extremely Weak Text Supervision?**
2412.08174v2 by Zihao Li, Lecheng Zheng, Bowen Jin, Dongqi Fu, Baoyu Jing, Yikun Ban, Jingrui He, Jiawei Han

While great success has been achieved in building vision models with
Contrastive Language-Image Pre-training (CLIP) over Internet-scale image-text
pairs, building transferable Graph Neural Networks (GNNs) with CLIP pipeline is
challenging because of three fundamental issues: the scarcity of labeled data
and text supervision, different levels of downstream tasks, and the conceptual
gaps between domains. In this work, to address these issues, we leverage
multi-modal prompt learning to effectively adapt pre-trained GNN to downstream
tasks and data, given only a few semantically labeled samples, each with
extremely weak text supervision. Our new paradigm embeds the graphs directly in
the same space as the Large Language Models (LLMs) by learning both graph
prompts and text prompts simultaneously. To accomplish this, we improve
state-of-the-art graph prompt method, and then propose the first graph-language
multi-modal prompt learning approach for exploiting the knowledge in
pre-trained models. Notably, due to the insufficient supervision for
fine-tuning, in our paradigm, the pre-trained GNN and the LLM are kept frozen,
so the learnable parameters are much fewer than fine-tuning any pre-trained
model. Through extensive experiments on real-world datasets, we demonstrate the
superior performance of our paradigm in few-shot, multi-task-level, and
cross-domain settings. Moreover, we build the first CLIP-style zero-shot
classification prototype that can generalize GNNs to unseen classes with
extremely weak text supervision.

æè¦ï¼<paragraph>åç®¡å¨ä½¿ç¨ç¶²éç¶²è·¯è¦æ¨¡çå½±åæå­éå°é²è¡å°æ¯èªè¨å½±åé è¨ç·´ (CLIP) ä¾å»ºç«è¦è¦ºæ¨¡åæ¹é¢åå¾äºå·¨å¤§çæåï¼ä½ä½¿ç¨ CLIP ç®¡ç·å»ºç«å¯è½ç§»åå½¢ç¥ç¶ç¶²è·¯ (GNN) å»å¾å·ææ°æ§ï¼åå å¨æ¼ä¸åæ ¹æ¬åé¡ï¼æ¨è¨è³æåæå­ç£ç£çç¨å°æ§ãä¸åå±¤ç´çä¸æ¸¸ä»»åï¼ä»¥åä¸åé åä¹éçæ¦å¿µå·®è·ãå¨éé å·¥ä½ä¸­ï¼çºäºè§£æ±ºéäºåé¡ï¼æåå©ç¨å¤æ¨¡ææç¤ºå­¸ç¿ï¼å¨åæå°æ¸èªç¾©æ¨è¨ç¯ä¾çææ³ä¸ï¼ææå°èª¿æ´é è¨ç·´ç GNN ä»¥é©ç¨æ¼ä¸æ¸¸ä»»ååè³æï¼æ¯åç¯ä¾é½å·ææ¥µå¶èå¼±çæå­ç£ç£ãæåçæ°ç¯ä¾å°åå½¢ç´æ¥åµå¥èå¤§åèªè¨æ¨¡å (LLM) ç¸åçç©ºéä¸­ï¼æ¹æ³æ¯åæå­¸ç¿åå½¢æç¤ºåæå­æç¤ºãçºäºéæéåç®æ¨ï¼æåæ¹é²äºæåé²çåå½¢æç¤ºæ¹æ³ï¼ç¶å¾æåºç¬¬ä¸ååå½¢èªè¨å¤æ¨¡ææç¤ºå­¸ç¿æ¹æ³ï¼ä»¥å©ç¨é è¨ç·´æ¨¡åä¸­çç¥è­ãå¼å¾æ³¨æçæ¯ï¼ç±æ¼å¾®èª¿çç£ç£ä¸è¶³ï¼å¨æåçç¯ä¾ä¸­ï¼é è¨ç·´ç GNN å LLM ä¿æåçµçæï¼å æ­¤å¯å­¸ç¿åæ¸é å°æ¼å¾®èª¿ä»»ä½é è¨ç·´æ¨¡åãééå°çå¯¦ä¸çè³æéé²è¡å»£æ³çå¯¦é©ï¼æåè­æäºæåçç¯ä¾å¨å°æ¨£æ¬ãå¤ä»»åå±¤ç´åè·¨é åè¨­å®ä¸­çåè¶æè½ãæ­¤å¤ï¼æåå»ºç«äºç¬¬ä¸å CLIP é¢¨æ ¼çé¶æ¨£æ¬åé¡ååï¼å®å¯ä»¥å° GNN æ¨å»£å°å·ææ¥µå¶èå¼±æå­ç£ç£çæªè¦é¡å¥ã</paragraph>

##### **GraphTool-Instruction: Revolutionizing Graph Reasoning in LLMs through Decomposed Subtask Instruction**
2412.12152v1 by Rongzheng Wang, Shuang Liang, Qizhi Chen, Jiasheng Zhang, Ke Qin

Large language models (LLMs) have been demonstrated to possess the
capabilities to understand fundamental graph properties and address various
graph reasoning tasks. Existing methods fine-tune LLMs to understand and
execute graph reasoning tasks by specially designed task instructions. However,
these Text-Instruction methods generally exhibit poor performance. Inspired by
tool learning, researchers propose Tool-Instruction methods to solve various
graph problems by special tool calling (e.g., function, API and model),
achieving significant improvements in graph reasoning tasks. Nevertheless,
current Tool-Instruction approaches focus on the tool information and ignore
the graph structure information, which leads to significantly inferior
performance on small-scale LLMs (less than 13B). To tackle this issue, we
propose GraphTool-Instruction, an innovative Instruction-tuning approach that
decomposes the graph reasoning task into three distinct subtasks (i.e., graph
extraction, tool name identification and tool parameter extraction), and design
specialized instructions for each subtask. Our GraphTool-Instruction can be
used as a plug-and-play prompt for different LLMs without fine-tuning.
Moreover, building on GraphTool-Instruction, we develop GTools, a dataset that
includes twenty graph reasoning tasks, and create a graph reasoning LLM called
GraphForge based on Llama3-8B. We conduct extensive experiments on twenty graph
reasoning tasks with different graph types (e.g., graph size or graph
direction), and we find that GraphTool-Instruction achieves SOTA compared to
Text-Instruction and Tool-Instruction methods. Fine-tuned on GTools, GraphForge
gets further improvement of over 30% compared to the Tool-Instruction enhanced
GPT-3.5-turbo, and it performs comparably to the high-cost GPT-4o. Our codes
and data are available at
https://anonymous.4open.science/r/GraphTool-Instruction.

æè¦ï¼<paragraph>å¤§åèªè¨æ¨¡å (LLM) å·²è¢«è­æå·æçè§£åºæ¬åå½¢å±¬æ§åèçåç¨®åå½¢æ¨çä»»åçè½åãç¾ææ¹æ³å¾®èª¿ LLM ä»¥ééå°éè¨­è¨çä»»åæä»¤ä¾çè§£åå·è¡åå½¢æ¨çä»»åãç¶èï¼éäºææ¬æä»¤æ¹æ³éå¸¸è¡¨ç¾åºè¼å·®çæ§è½ãåå·¥å·å­¸ç¿çåç¼ï¼ç ç©¶äººå¡æåºå·¥å·æä»¤æ¹æ³ï¼ééç¹æ®å·¥å·å¼å«ï¼ä¾å¦å½æ¸ãAPI åæ¨¡åï¼ä¾è§£æ±ºåç¨®åå½¢åé¡ï¼å¾èé¡¯èæ¹é²äºåå½¢æ¨çä»»åãåç®¡å¦æ­¤ï¼ç¶åçå·¥å·æä»¤æ¹æ³å´éæ¼å·¥å·è³è¨ï¼èå¿½ç¥äºåå½¢çµæ§è³è¨ï¼éå°è´å¨å°è¦æ¨¡ LLMï¼å°æ¼ 13Bï¼ä¸æ§è½é¡¯èä¸éãçºäºè§£æ±ºéååé¡ï¼æåæåºäº GraphTool-Instructionï¼éæ¯ä¸ç¨®åµæ°çæä»¤èª¿æ´æ¹æ³ï¼å®å°åå½¢æ¨çä»»ååè§£çºä¸åä¸åçå­ä»»åï¼å³åå½¢æåãå·¥å·åç¨±è­å¥åå·¥å·åæ¸æåï¼ï¼ä¸¦çºæ¯åå­ä»»åè¨­è¨å°éçæä»¤ãæåç GraphTool-Instruction å¯ç¨ä½ä¸å LLM çå³æå³ç¨æç¤ºï¼èç¡éå¾®èª¿ãæ­¤å¤ï¼åºæ¼ GraphTool-Instructionï¼æåéç¼äº GToolsï¼éæ¯ä¸ååå« 20 ååå½¢æ¨çä»»åçè³æéï¼ä¸¦åºæ¼ Llama3-8B åµå»ºäºä¸ååçº GraphForge çåå½¢æ¨ç LLMãæåå° 20 åå·æä¸ååå½¢é¡åï¼ä¾å¦åå½¢å¤§å°æåå½¢æ¹åï¼çåå½¢æ¨çä»»åé²è¡äºå»£æ³çå¯¦é©ï¼æåç¼ç¾èææ¬æä»¤åå·¥å·æä»¤æ¹æ³ç¸æ¯ï¼GraphTool-Instruction éå°äº SOTAãå¨ GTools ä¸é²è¡å¾®èª¿å¾ï¼èå·¥å·æä»¤å¢å¼·ç GPT-3.5-turbo ç¸æ¯ï¼GraphForge é²ä¸æ­¥æ¹é²äº 30% ä»¥ä¸ï¼ä¸¦ä¸å¶æ§è½èé«ææ¬ç GPT-4o ç¸ç¶ãæåçç¨å¼ç¢¼åè³æå¯å¨ https://anonymous.4open.science/r/GraphTool-Instruction ç²å¾ã</paragraph>

##### **NAT-NL2GQL: A Novel Multi-Agent Framework for Translating Natural Language to Graph Query Language**
2412.10434v1 by Yuanyuan Liang, Tingyu Xie, Gan Peng, Zihao Huang, Yunshi Lan, Weining Qian

The emergence of Large Language Models (LLMs) has revolutionized many fields,
not only traditional natural language processing (NLP) tasks. Recently,
research on applying LLMs to the database field has been booming, and as a
typical non-relational database, the use of LLMs in graph database research has
naturally gained significant attention. Recent efforts have increasingly
focused on leveraging LLMs to translate natural language into graph query
language (NL2GQL). Although some progress has been made, these methods have
clear limitations, such as their reliance on streamlined processes that often
overlook the potential of LLMs to autonomously plan and collaborate with other
LLMs in tackling complex NL2GQL challenges. To address this gap, we propose
NAT-NL2GQL, a novel multi-agent framework for translating natural language to
graph query language. Specifically, our framework consists of three synergistic
agents: the Preprocessor agent, the Generator agent, and the Refiner agent. The
Preprocessor agent manages data processing as context, including tasks such as
name entity recognition, query rewriting, path linking, and the extraction of
query-related schemas. The Generator agent is a fine-tuned LLM trained on
NL-GQL data, responsible for generating corresponding GQL statements based on
queries and their related schemas. The Refiner agent is tasked with refining
the GQL or context using error information obtained from the GQL execution
results. Given the scarcity of high-quality open-source NL2GQL datasets based
on nGQL syntax, we developed StockGQL, a dataset constructed from a financial
market graph database. It is available at:
https://github.com/leonyuancode/StockGQL. Experimental results on the StockGQL
and SpCQL datasets reveal that our method significantly outperforms baseline
approaches, highlighting its potential for advancing NL2GQL research.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) çåºç¾ï¼ä¸åå¾¹åºæ¹è®äºå³çµ±çèªç¶èªè¨èç (NLP) ä»»åï¼æ´å°è¨±å¤é åé æé©å½æ§çå½±é¿ãæè¿ï¼å° LLM æç¨æ¼è³æåº«é åçç ç©¶è¬åç¼å±ï¼èä½çºå¸åçééè¯å¼è³æåº«ï¼LLM å¨åå½¢è³æåº«ç ç©¶ä¸­çæç¨èªç¶ååéæ³¨ãæè¿çç ç©¶å·¥ä½è¶ä¾è¶èéæ¼å©ç¨ LLM å°èªç¶èªè¨è½ææåå½¢æ¥è©¢èªè¨ (NL2GQL)ãåç®¡å·²åå¾ä¸äºé²å±ï¼ä½éäºæ¹æ³ä»ææé¡¯çéå¶ï¼ä¾å¦å®åä¾è³´ç°¡åçæµç¨ï¼èéäºæµç¨å¾å¾å¿½ç¥äº LLM èå¶ä» LLM èªä¸»è¦åååä½ä»¥æå°è¤é NL2GQL ææ°çæ½åãçºäºè§£æ±ºéåå·®è·ï¼æåæåºäº NAT-NL2GQLï¼éæ¯ä¸åç¨æ¼å°èªç¶èªè¨è½ææåå½¢æ¥è©¢èªè¨çæ°ç©å¤éä»£çæ¶æ§ãå·é«ä¾èªªï¼æåçæ¶æ§åå«ä¸åååéä½çä»£çï¼é èçå¨ä»£çãç¢çå¨ä»£çåç²¾çå¨ä»£çãé èçå¨ä»£çç®¡çè³æèçä½çºèæ¯ï¼åæ¬å½åå¯¦é«è¾¨è­ãæ¥è©¢éå¯«ãè·¯å¾é£çµåæåèæ¥è©¢ç¸éçæ¶æ§ç­ä»»åãç¢çå¨ä»£çæ¯ä¸åéå° NL-GQL è³æå¾®èª¿éç LLMï¼è² è²¬æ ¹ææ¥è©¢åå¶ç¸éæ¶æ§ç¢çå°æç GQL é³è¿°ãç²¾çå¨ä»£çè² è²¬ä½¿ç¨å¾ GQL å·è¡çµæåå¾çé¯èª¤è³è¨ä¾ç²¾ç GQL æèæ¯ãéæ¼åºæ¼ nGQL èªæ³çåªè³ªéæº NL2GQL è³æéç¨å°ï¼æåéç¼äº StockGQLï¼éæ¯ä¸åå¾éèå¸å ´åå½¢è³æåº«å»ºæ§çè³æéãå®å¯æ¼ä»¥ä¸ä½ç½®åå¾ï¼https://github.com/leonyuancode/StockGQLãå¨ StockGQL å SpCQL è³æéä¸çå¯¦é©çµæé¡¯ç¤ºï¼æåçæ¨¡åæé¡¯åªæ¼åºæºæ¹æ³ï¼çªé¡¯äºå¶å¨æ¨å NL2GQL ç ç©¶æ¹é¢çæ½åã

##### **Repository-Level Graph Representation Learning for Enhanced Security Patch Detection**
2412.08068v1 by Xin-Cheng Wen, Zirui Lin, Cuiyun Gao, Hongyu Zhang, Yong Wang, Qing Liao

Software vendors often silently release security patches without providing
sufficient advisories (e.g., Common Vulnerabilities and Exposures) or delayed
updates via resources (e.g., National Vulnerability Database). Therefore, it
has become crucial to detect these security patches to ensure secure software
maintenance. However, existing methods face the following challenges: (1) They
primarily focus on the information within the patches themselves, overlooking
the complex dependencies in the repository. (2) Security patches typically
involve multiple functions and files, increasing the difficulty in well
learning the representations. To alleviate the above challenges, this paper
proposes a Repository-level Security Patch Detection framework named RepoSPD,
which comprises three key components: 1) a repository-level graph construction,
RepoCPG, which represents software patches by merging pre-patch and post-patch
source code at the repository level; 2) a structure-aware patch representation,
which fuses the graph and sequence branch and aims at comprehending the
relationship among multiple code changes; 3) progressive learning, which
facilitates the model in balancing semantic and structural information. To
evaluate RepoSPD, we employ two widely-used datasets in security patch
detection: SPI-DB and PatchDB. We further extend these datasets to the
repository level, incorporating a total of 20,238 and 28,781 versions of
repository in C/C++ programming languages, respectively, denoted as SPI-DB* and
PatchDB*. We compare RepoSPD with six existing security patch detection methods
and five static tools. Our experimental results demonstrate that RepoSPD
outperforms the state-of-the-art baseline, with improvements of 11.90%, and
3.10% in terms of accuracy on the two datasets, respectively.

æè¦ï¼<paragraph>è»é«ä¾æåéå¸¸æå¨æ²ææä¾è¶³å¤ çè«®è©¢ï¼ä¾å¦å¸¸è¦æ¼æ´åæéªï¼æå»¶é²ééè³æºï¼ä¾å¦åå®¶æ¼æ´è³æåº«ï¼æ´æ°çææ³ä¸ï¼ç¡è²å°ç¼å¸å®å¨æ§ä¿®è£ç¨å¼ãå æ­¤ï¼åµæ¸¬éäºå®å¨æ§ä¿®è£ç¨å¼ä»¥ç¢ºä¿è»é«ç¶­è­·å®å¨è³ééè¦ãç¶èï¼ç¾ææ¹æ³é¢è¨ä»¥ä¸ææ°ï¼(1) å®åä¸»è¦éæ³¨ä¿®è£ç¨å¼æ¬èº«çè³è¨ï¼å¿½ç¥äºå²å­åº«ä¸­è¤éçç¸ä¾æ§ã(2) å®å¨æ§ä¿®è£ç¨å¼éå¸¸æ¶åå¤åå½å¼åæªæ¡ï¼å¢å äºè¯å¥½å­¸ç¿è¡¨ç¤ºå½¢å¼çé£åº¦ãçºäºç·©è§£ä¸è¿°ææ°ï¼æ¬ææåºäºä¸ååçº RepoSPD çå²å­åº«å±¤ç´å®å¨æ§ä¿®è£ç¨å¼åµæ¸¬æ¶æ§ï¼å®åå«ä¸åééµåä»¶ï¼1) å²å­åº«å±¤ç´åå½¢å»ºæ§ï¼RepoCPGï¼å®ééåä½µå²å­åº«å±¤ç´çåä¿®è£ç¨å¼åå¾ä¿®è£ç¨å¼åå§ç¢¼ä¾è¡¨ç¤ºè»é«ä¿®è£ç¨å¼ï¼2) çµæ§æç¥ä¿®è£ç¨å¼è¡¨ç¤ºå½¢å¼ï¼å®èåäºåå½¢ååºååæ¯ï¼æ¨å¨çè§£å¤åç¨å¼ç¢¼è®æ´ä¹éçéä¿ï¼3) æ¼¸é²å¼å­¸ç¿ï¼å®æå©æ¼æ¨¡åå¹³è¡¡èªæåçµæ§è³è¨ãçºäºè©ä¼° RepoSPDï¼æåå¨å®å¨æ§ä¿®è£ç¨å¼åµæ¸¬ä¸­æ¡ç¨äºå©åå»£æ³ä½¿ç¨çè³æéï¼SPI-DB å PatchDBãæåé²ä¸æ­¥å°éäºè³æéæ´åå¥ä»¶å°å²å­åº«å±¤ç´ï¼åå¥ç´å¥äº C/C++ ç¨å¼èªè¨ä¸­ç¸½è¨ 20,238 å 28,781 åçæ¬çå²å­åº«ï¼è¡¨ç¤ºçº SPI-DB* å PatchDB*ãæåå° RepoSPD èå­ç¨®ç¾æçå®å¨æ§ä¿®è£ç¨å¼åµæ¸¬æ¹æ³åäºç¨®éæå·¥å·é²è¡æ¯è¼ãæåçå¯¦é©çµæè¡¨æï¼RepoSPD åªæ¼æåé²çåºæºï¼å¨å©åè³æéä¸çæºç¢ºæ§åå¥æé«äº 11.90% å 3.10%ã</paragraph>

##### **Bootstrapping Heterogeneous Graph Representation Learning via Large Language Models: A Generalized Approach**
2412.08038v2 by Hang Gao, Chenhao Zhang, Fengge Wu, Junsuo Zhao, Changwen Zheng, Huaping Liu

Graph representation learning methods are highly effective in handling
complex non-Euclidean data by capturing intricate relationships and features
within graph structures. However, traditional methods face challenges when
dealing with heterogeneous graphs that contain various types of nodes and edges
due to the diverse sources and complex nature of the data. Existing
Heterogeneous Graph Neural Networks (HGNNs) have shown promising results but
require prior knowledge of node and edge types and unified node feature
formats, which limits their applicability. Recent advancements in graph
representation learning using Large Language Models (LLMs) offer new solutions
by integrating LLMs' data processing capabilities, enabling the alignment of
various graph representations. Nevertheless, these methods often overlook
heterogeneous graph data and require extensive preprocessing. To address these
limitations, we propose a novel method that leverages the strengths of both LLM
and GNN, allowing for the processing of graph data with any format and type of
nodes and edges without the need for type information or special preprocessing.
Our method employs LLM to automatically summarize and classify different data
formats and types, aligns node features, and uses a specialized GNN for
targeted learning, thus obtaining effective graph representations for
downstream tasks. Theoretical analysis and experimental validation have
demonstrated the effectiveness of our method.

æè¦ï¼åè¡¨è¡¨å¾µå­¸ç¿æ¹æ³å¨èçè¤ééæ­å¹¾éå¾è³ææéå¸¸ææï¼å®è½ææåè¡¨çµæ§ä¸­çè¤ééä¿åç¹å¾µãç¶èï¼å³çµ±æ¹æ³å¨èçç°è³ªåè¡¨ææé¢è¨ææ°ï¼å çºç°è³ªåè¡¨åå«åç¨®ç¯é»åéç·£é¡åï¼éæ¯ç±æ¼è³æä¾æºå¤æ¨£ä¸æ§è³ªè¤éãç¾æçç°è³ªåç¥ç¶ç¶²è·¯ (HGNN) å·²å±ç¾åºæåæ¯çææï¼ä½éè¦äºåç¥éç¯é»åéç·£é¡åï¼ä»¥åçµ±ä¸çç¯é»ç¹å¾µæ ¼å¼ï¼ééå¶äºå®åçé©ç¨æ§ãæè¿å¨ä½¿ç¨å¤§åèªè¨æ¨¡å (LLM) é²è¡åè¡¨è¡¨å¾µå­¸ç¿æ¹é¢åå¾çé²å±æä¾äºæ°çè§£æ±ºæ¹æ¡ï¼æ¹æ³æ¯æ´å LLM çè³æèçåè½ï¼è®åç¨®åè¡¨è¡¨å¾µå¾ä»¥å°é½ãåç®¡å¦æ­¤ï¼éäºæ¹æ³ç¶å¸¸å¿½ç¥ç°è³ªåè¡¨è³æï¼èä¸éè¦å»£æ³çé èçãçºäºè§£æ±ºéäºéå¶ï¼æåæåºäºä¸ç¨®æ°æ¹æ³ï¼å®åæå©ç¨äº LLM å GNN çåªé»ï¼åè¨±èçä»»ä½æ ¼å¼åé¡åç¯é»åéç·£çåè¡¨è³æï¼èä¸éè¦é¡åè³è¨æç¹æ®é èçãæåçéåæ¹æ³æ¡ç¨ LLM èªåæè¦ååé¡ä¸åçè³ææ ¼å¼åé¡åï¼å°é½ç¯é»ç¹å¾µï¼ä¸¦ä½¿ç¨å°éç GNN é²è¡ç®æ¨å­¸ç¿ï¼å¾èçºä¸æ¸¸ä»»ååå¾ææçåè¡¨è¡¨å¾µãçè«åæåå¯¦é©é©è­å·²è­ææåéåæ¹æ³çæææ§ã

##### **Ontology-Aware RAG for Improved Question-Answering in Cybersecurity Education**
2412.14191v1 by Chengshuai Zhao, Garima Agrawal, Tharindu Kumarage, Zhen Tan, Yuli Deng, Ying-Chih Chen, Huan Liu

Integrating AI into education has the potential to transform the teaching of
science and technology courses, particularly in the field of cybersecurity.
AI-driven question-answering (QA) systems can actively manage uncertainty in
cybersecurity problem-solving, offering interactive, inquiry-based learning
experiences. Large language models (LLMs) have gained prominence in AI-driven
QA systems, offering advanced language understanding and user engagement.
However, they face challenges like hallucinations and limited domain-specific
knowledge, which reduce their reliability in educational settings. To address
these challenges, we propose CyberRAG, an ontology-aware retrieval-augmented
generation (RAG) approach for developing a reliable and safe QA system in
cybersecurity education. CyberRAG employs a two-step approach: first, it
augments the domain-specific knowledge by retrieving validated cybersecurity
documents from a knowledge base to enhance the relevance and accuracy of the
response. Second, it mitigates hallucinations and misuse by integrating a
knowledge graph ontology to validate the final answer. Experiments on publicly
available cybersecurity datasets show that CyberRAG delivers accurate, reliable
responses aligned with domain knowledge, demonstrating the potential of AI
tools to enhance education.

æè¦ï¼å° AI æ´åå°æè²ä¸­ï¼ææ½åè½åç§å­¸åæè¡èª²ç¨çæå­¸ï¼ç¹å¥æ¯å¨ç¶²è·¯å®å¨é åãAI é©åçåé¡è§£ç­ (QA) ç³»çµ±å¯ä»¥ç©æ¥µç®¡çç¶²è·¯å®å¨åé¡è§£æ±ºä¸­çä¸ç¢ºå®æ§ï¼æä¾äºåå¼ãåºæ¼æ¢ç©¶çå­¸ç¿é«é©ãå¤§åèªè¨æ¨¡å (LLM) å¨ AI é©åç QA ç³»çµ±ä¸­ç²å¾é¡¯èå°ä½ï¼æä¾é²éçèªè¨çè§£åä½¿ç¨èåèãç¶èï¼å®åé¢è¨å¹»è¦ºåç¹å®é åç¥è­æéçææ°ï¼éæéä½å®åå¨æè²ç°å¢ä¸­çå¯é æ§ãçºäºæå°éäºææ°ï¼æåæåº CyberRAGï¼ä¸ç¨®æè­å°æ¬é«è«çæª¢ç´¢å¢å¼·çæ (RAG) æ¹æ³ï¼ç¨æ¼å¨ç¶²è·¯å®å¨æè²ä¸­éç¼å¯é ä¸å®å¨ç QA ç³»çµ±ãCyberRAG æ¡ç¨å©æ­¥é©æ¹æ³ï¼é¦åï¼å®ééå¾ç¥è­åº«ä¸­æª¢ç´¢å·²é©è­çç¶²è·¯å®å¨æä»¶ä¾æ´åç¹å®é åçç¥è­ï¼ä»¥å¢å¼·åæçç¸éæ§åæºç¢ºæ§ãå¶æ¬¡ï¼å®ééæ´åç¥è­åè­æ¬é«è«ä¾é©è­æçµç­æ¡ï¼ä»¥æ¸è¼å¹»è¦ºåèª¤ç¨ãå¨å¬éçç¶²è·¯å®å¨è³æéä¸é²è¡çå¯¦é©é¡¯ç¤ºï¼CyberRAG æä¾æºç¢ºãå¯é çåæï¼ç¬¦åé åç¥è­ï¼è­æäº AI å·¥å·å¢å¼·æè²çæ½åã

##### **Combining knowledge graphs and LLMs for hazardous chemical information management and reuse**
2412.09644v1 by Marcos Da Silveira, Louis Deladiennee, Kheira Acem, Oona Freudenthal

Human health is increasingly threatened by exposure to hazardous substances,
particularly persistent and toxic chemicals. The link between these substances,
often encountered in complex mixtures, and various diseases are demonstrated in
scientific studies. However, this information is scattered across several
sources and hardly accessible by humans and machines. This paper evaluates
current practices for publishing/accessing information on hazardous chemicals
and proposes a novel platform designed to facilitate retrieval of critical
chemical data in urgent situations. The platform aggregates information from
multiple sources and organizes it into a structured knowledge graph. Users can
access this information through a visual interface such as Neo4J Bloom and
dashboards, or via natural language queries using a Chatbot. Our findings
demonstrate a significant reduction in the time and effort required to access
vital chemical information when datasets follow FAIR principles. Furthermore,
we discuss the lessons learned from the development and implementation of this
platform and provide recommendations for data owners and publishers to enhance
data reuse and interoperability. This work aims to improve the accessibility
and usability of chemical information by healthcare professionals, thereby
supporting better health outcomes and informed decision-making in the face of
patients exposed to chemical intoxication risks.

æè¦ï¼äººé¡å¥åº·è¶ä¾è¶åå°æ¥è§¸æå®³ç©è³ªçå¨èï¼å°¤å¶æ¯æä¹æ§åææ¯çåå­¸ç©è³ªãç§å­¸ç ç©¶å·²è­æéäºç©è³ªï¼éå¸¸å­å¨æ¼è¤éçæ··åç©ä¸­ï¼èåç¨®ç¾çä¹éçéè¯ãç¶èï¼éäºè³è¨åæ£å¨å¤åä¾æºä¸­ï¼äººé¡åæ©å¨é½å¾é£åå¾ãæ¬æè©ä¼°äºç¶åç¼å¸/åå¾æéæå®³åå­¸ç©è³ªè³è¨çæ£ä¾ï¼ä¸¦æåºä¸åæ°ç©çå¹³å°ï¼æ¨å¨ä¿é²å¨ç·æ¥ææ³ä¸åå¾ééµåå­¸è³æãæ­¤å¹³å°å¯éä¾èªå¤åä¾æºçè³è¨ï¼ä¸¦å°å¶çµç¹æçµæ§åçç¥è­åè­ãä½¿ç¨èå¯ä»¥ééè¦è¦ºåä»é¢ï¼ä¾å¦ Neo4J Bloom ååè¡¨æ¿ï¼æä½¿ç¨èå¤©æ©å¨äººçèªç¶èªè¨æ¥è©¢ä¾åå¾éäºè³è¨ãæåçç ç©¶çµæè¡¨æï¼ç¶è³æééµå¾ª FAIR ååæï¼åå¾éè¦åå­¸è³è¨æéçæéåç²¾åæå¤§å¹æ¸å°ãæ­¤å¤ï¼æåè¨è«å¾æ­¤å¹³å°çéç¼åå¯¦ä½ä¸­å­¸å°çç¶é©æè¨ï¼ä¸¦çºè³æææèåç¼å¸èæä¾å»ºè­°ï¼ä»¥å¢å¼·è³æåå©ç¨åäºæä½æ§ãéé å·¥ä½æ¨å¨æ¹åé«çä¿å¥å°æ¥­äººå¡åå¾åä½¿ç¨åå­¸è³è¨çæ¹å¼ï¼å¾èæ¯ææ´å¥½çå¥åº·çµæï¼ä¸¦å¨é¢å°æ¥è§¸åå­¸ä¸­æ¯é¢¨éªçæ£èæååºææºçæ±ºç­ã

##### **Adapting to Non-Stationary Environments: Multi-Armed Bandit Enhanced Retrieval-Augmented Generation on Knowledge Graphs**
2412.07618v1 by Xiaqiang Tang, Jian Li, Nan Du, Sihong Xie

Despite the superior performance of Large language models on many NLP tasks,
they still face significant limitations in memorizing extensive world
knowledge. Recent studies have demonstrated that leveraging the
Retrieval-Augmented Generation (RAG) framework, combined with Knowledge Graphs
that encapsulate extensive factual data in a structured format, robustly
enhances the reasoning capabilities of LLMs. However, deploying such systems in
real-world scenarios presents challenges: the continuous evolution of
non-stationary environments may lead to performance degradation and user
satisfaction requires a careful balance of performance and responsiveness. To
address these challenges, we introduce a Multi-objective Multi-Armed Bandit
enhanced RAG framework, supported by multiple retrieval methods with diverse
capabilities under rich and evolving retrieval contexts in practice. Within
this framework, each retrieval method is treated as a distinct ``arm''. The
system utilizes real-time user feedback to adapt to dynamic environments, by
selecting the appropriate retrieval method based on input queries and the
historical multi-objective performance of each arm. Extensive experiments
conducted on two benchmark KGQA datasets demonstrate that our method
significantly outperforms baseline methods in non-stationary settings while
achieving state-of-the-art performance in stationary environments. Code and
data are available at https://github.com/FUTUREEEEEE/Dynamic-RAG.git

æè¦ï¼åç®¡å¤§åèªè¨æ¨¡åå¨è¨±å¤ NLP ä»»åä¸è¡¨ç¾åªç°ï¼
å®åå¨è¨æ¶å»£æ³çä¸çç¥è­æ¹é¢ä»é¢è¨éå¤§éå¶ãæè¿çç ç©¶è¡¨æï¼
å©ç¨æª¢ç´¢å¢å¼·çæ (RAG) æ¡æ¶ï¼çµåä»¥çµæ§åæ ¼å¼å°è£å»£æ³äºå¯¦è³æçç¥è­åè­ï¼
è½ç©©å¥å°å¢å¼· LLM çæ¨çè½åãç¶èï¼å¨ç¾å¯¦ä¸çå ´æ¯ä¸­é¨ç½²æ­¤é¡ç³»çµ±æç¢çææ°ï¼
éå¹³ç©©ç°å¢çæçºæ¼è®å¯è½å°è´æè½ä¸éï¼èä½¿ç¨èçæ»¿æåº¦éè¦å¨æè½ååææ§ä¹éåå¾ä»ç´°çå¹³è¡¡ã
çºäºæå°éäºææ°ï¼æåå¼å¥äºå¤ç®æ¨å¤èèèæ©å¢å¼·ç RAG æ¡æ¶ï¼
ä¸¦å¨å¯¦åä¸­æ¡ç¨å·åå¤åè½åçåç¨®æª¢ç´¢æ¹æ³ï¼ä»¥æå°è±å¯ä¸ä¸æ·æ¼è®çæª¢ç´¢æå¢ã
å¨æ­¤æ¡æ¶ä¸­ï¼æ¯åæª¢ç´¢æ¹æ³é½è¢«è¦çºä¸åä¸åçãæèãã
è©²ç³»çµ±å©ç¨å³æä½¿ç¨èåé¥ä¾é©æåæç°å¢ï¼
æ ¹æè¼¸å¥æ¥è©¢åæ¯åæèçæ­·å²å¤ç®æ¨æè½ä¾é¸æé©ç¶çæª¢ç´¢æ¹æ³ã
å¨å©ååºæº KGQA è³æéä¸é²è¡çå»£æ³å¯¦é©è¡¨æï¼
æåçæ¨¡åå¨éå¹³ç©©è¨­å®ä¸­é¡¯èåªæ¼åºç·æ¨¡åï¼åæå¨å¹³ç©©ç°å¢ä¸­éå°æåé²çæè½ã
ç¨å¼ç¢¼åè³æå¯æ¼ https://github.com/FUTUREEEEEE/Dynamic-RAG.git åå¾

##### **Knowledge Graph Guided Evaluation of Abstention Techniques**
2412.07430v1 by Kinshuk Vasisht, Navreet Kaur, Danish Pruthi

To deploy language models safely, it is crucial that they abstain from
responding to inappropriate requests. Several prior studies test the safety
promises of models based on their effectiveness in blocking malicious requests.
In this work, we focus on evaluating the underlying techniques that cause
models to abstain. We create SELECT, a benchmark derived from a set of benign
concepts (e.g., "rivers") from a knowledge graph. The nature of SELECT enables
us to isolate the effects of abstention techniques from other safety training
procedures, as well as evaluate their generalization and specificity. Using
SELECT, we benchmark different abstention techniques over six open-weight and
closed-source models. We find that the examined techniques indeed cause models
to abstain with over $80\%$ abstention rates. However, these techniques are not
as effective for descendants of the target concepts, with refusal rates
declining by $19\%$. We also characterize the generalization-vs-specificity
trade-offs for different techniques. Overall, no single technique is invariably
better than the others. Our findings call for a careful evaluation of different
aspects of abstention, and hopefully inform practitioners of various trade-offs
involved.

æè¦ï¼çºäºå®å¨å°é¨ç½²èªè¨æ¨¡åï¼è³ééè¦çæ¯ï¼å®åå¿é é¿ååæä¸é©ç¶çè«æ±ãååææ¸é ç ç©¶æ¸¬è©¦æ¨¡åçå®å¨æ§ï¼ä¾æå®åå°éæ¡æè«æ±çæææ§çºåºç¤ãå¨éé å·¥ä½ä¸­ï¼æåå°æ³¨æ¼è©ä¼°å°è´æ¨¡åé¿ååæçåºå±¤æè¡ãæåå»ºç«äº SELECTï¼ä¸åå¾ç¥è­åè­ä¸­ä¸çµè¯æ§æ¦å¿µï¼ä¾å¦ãæ²³æµãï¼è¡ççåºæºãSELECT çæ§è³ªä½¿æåè½å¤ å°é¿ååææè¡çå½±é¿èå¶ä»å®å¨è¨ç·´ç¨åºéé¢ï¼ä¸¦è©ä¼°å®åçæ¦æ¬æ§åç¹ç°æ§ãä½¿ç¨ SELECTï¼æåå°å­åéæ¾æ¬éåå°éåå§ç¢¼æ¨¡åé²è¡äºä¸åé¿ååææè¡çåºæºæ¸¬è©¦ãæåç¼ç¾ï¼ææª¢æ¥çæè¡ç¢ºå¯¦å°è´æ¨¡åé¿ååæï¼é¿ååæçè¶é 80%ãç¶èï¼éäºæè¡å°æ¼ç®æ¨æ¦å¿µçå¾ä»£ä¸¦ä¸é£éº¼ææï¼æçµçä¸éäº 19%ãæåéæè¿°äºä¸åæè¡çæ¦æ¬æ§èç¹ç°æ§æ¬è¡¡ãç¸½é«èè¨ï¼æ²æä»»ä½å®ä¸æè¡å§çµåªæ¼å¶ä»æè¡ãæåçç¼ç¾è¦æ±ä»ç´°è©ä¼°é¿ååæçä¸åé¢åï¼ä¸¦å¸æè®å¾æ¥­äººå¡äºè§£ææ¶åçåç¨®æ¬è¡¡ã

##### **RAG-based Question Answering over Heterogeneous Data and Text**
2412.07420v1 by Philipp Christmann, Gerhard Weikum

This article presents the QUASAR system for question answering over
unstructured text, structured tables, and knowledge graphs, with unified
treatment of all sources. The system adopts a RAG-based architecture, with a
pipeline of evidence retrieval followed by answer generation, with the latter
powered by a moderate-sized language model. Additionally and uniquely, QUASAR
has components for question understanding, to derive crisper input for evidence
retrieval, and for re-ranking and filtering the retrieved evidence before
feeding the most informative pieces into the answer generation. Experiments
with three different benchmarks demonstrate the high answering quality of our
approach, being on par with or better than large GPT models, while keeping the
computational cost and energy consumption orders of magnitude lower.

æè¦ï¼æ¬æä»ç´¹ QUASAR ç³»çµ±ï¼ç¨æ¼åç­éçµæ§åæå­ãçµæ§åè¡¨æ ¼åç¥è­åè¡¨ä¸­çåé¡ï¼ä¸¦çµ±ä¸èçææä¾æºãè©²ç³»çµ±æ¡ç¨åºæ¼ RAG çæ¶æ§ï¼ç®¡éåæ¬è­ææª¢ç´¢å¾æ¥ç­æ¡çæï¼å¾èç±ä¸­ç­è¦æ¨¡çèªè¨æ¨¡åæä¾æ¯æ´ãæ­¤å¤ï¼QUASAR ç¨ç¹å°åå«åé¡çè§£åä»¶ï¼ä»¥è¡çæ´æ¸æ°çè¼¸å¥é²è¡è­ææª¢ç´¢ï¼ä»¥åå¨å°ææè³è¨ççæ®µè¼¸å¥ç­æ¡çæä¹åéæ°æåºåéæ¿¾æª¢ç´¢å°çè­æãä½¿ç¨ä¸åä¸åçåºæºé²è¡çå¯¦é©è­æäºæåæ¹æ³çé«åç­åè³ªï¼èå¤§å GPT æ¨¡åç¸ç¶ææ´å¥½ï¼åæå°éç®ææ¬åè½æºæ¶èéä½äºå¹¾åæ¸éç´ã

##### **Generating Knowledge Graphs from Large Language Models: A Comparative Study of GPT-4, LLaMA 2, and BERT**
2412.07412v1 by Ahan Bhatt, Nandan Vaghela, Kush Dudhia

Knowledge Graphs (KGs) are essential for the functionality of GraphRAGs, a
form of Retrieval-Augmented Generative Systems (RAGs) that excel in tasks
requiring structured reasoning and semantic understanding. However, creating
KGs for GraphRAGs remains a significant challenge due to accuracy and
scalability limitations of traditional methods. This paper introduces a novel
approach leveraging large language models (LLMs) like GPT-4, LLaMA 2 (13B), and
BERT to generate KGs directly from unstructured data, bypassing traditional
pipelines. Using metrics such as Precision, Recall, F1-Score, Graph Edit
Distance, and Semantic Similarity, we evaluate the models' ability to generate
high-quality KGs. Results demonstrate that GPT-4 achieves superior semantic
fidelity and structural accuracy, LLaMA 2 excels in lightweight,
domain-specific graphs, and BERT provides insights into challenges in
entity-relationship modeling. This study underscores the potential of LLMs to
streamline KG creation and enhance GraphRAG accessibility for real-world
applications, while setting a foundation for future advancements.

æè¦ï¼ç¥è­åè­ (KG) å°æ¼ GraphRAG çåè½è³ééè¦ï¼GraphRAG æ¯ä¸ç¨®æª¢ç´¢å¢å¼·å¼çæç³»çµ± (RAG)ï¼å¨éè¦çµæ§åæ¨çåèªç¾©çè§£çä»»åä¸­è¡¨ç¾åºè²ãç¶èï¼ç±æ¼å³çµ±æ¹æ³çæºç¢ºæ§åå¯æ´åæ§éå¶ï¼çº GraphRAG å»ºç« KG ä»ç¶æ¯ä¸é éå¤§ææ°ãæ¬æä»ç´¹äºä¸ç¨®åµæ°æ¹æ³ï¼å©ç¨å¤§åèªè¨æ¨¡å (LLM)ï¼ä¾å¦ GPT-4ãLLaMA 2 (13B) å BERTï¼ç´æ¥å¾éçµæ§åæ¸æçæ KGï¼ç¹éå³çµ±ç®¡éãæåä½¿ç¨æºç¢ºåº¦ãå¬åçãF1 åæ¸ãåå½¢ç·¨è¼¯è·é¢åèªç¾©ç¸ä¼¼æ§ç­ææ¨ï¼è©ä¼°æ¨¡åçæé«åè³ª KG çè½åãçµæè¡¨æï¼GPT-4 éå°äºåè¶çèªç¾©ä¿çåº¦åçµæ§æºç¢ºæ§ï¼LLaMA 2 å¨è¼éç´ãç¹å®é åçåå½¢ä¸­è¡¨ç¾åºè²ï¼è BERT åæä¾äºå°å¯¦é«éä¿å»ºæ¨¡ææ°çè¦è§£ãéé ç ç©¶å¼·èª¿äº LLM ç°¡å KG å»ºç«åå¢å¼· GraphRAG å¨ç¾å¯¦ä¸çæç¨ä¸­å¯åæ§çæ½åï¼åæçºæªä¾çé²å±å¥ å®äºåºç¤ã

##### **My Words Imply Your Opinion: Reader Agent-Based Propagation Enhancement for Personalized Implicit Emotion Analysis**
2412.07367v1 by Jian Liao, Yu Feng, Xiaoyu Wang, Suge Wang, Jianxing Zheng, Deyu Li

In implicit emotion analysis (IEA), the subtlety of emotional expressions
makes it particularly sensitive to user-specific characteristics. Existing
studies often inject personalization into the analysis by focusing on the
authorial dimension of the emotional text. However, these methods overlook the
potential influence of the intended reader on the reaction of implicit
emotions. In this paper, we refine the IEA task to Personalized Implicit
Emotion Analysis (PIEA) and introduce the RAPPIE model, a novel framework
designed to address the issue of missing user information within this task. In
particular, 1) we create reader agents based on the Large Language Model to
simulate reader reactions, to address challenges of the spiral of silence and
data incompleteness encountered when acquiring reader feedback information. 2)
We establish a reader propagation role system and develop a role-aware emotion
propagation multi-view graph learning model, which effectively deals with the
sparsity of reader information by utilizing the distribution of propagation
roles. 3) We annotate two Chinese PIEA datasets with detailed user metadata,
thereby addressing the limitation of prior datasets that primarily focus on
textual content annotation. Extensive experiments on these datasets indicate
that the RAPPIE model outperforms current state-of-the-art baselines,
highlighting the significance and efficacy of incorporating reader feedback
into the PIEA process.

æè¦ï¼å¨éå¼ææåæ (IEA) ä¸­ï¼ææè¡¨è¾¾çå¾®å¦æ§ä½¿å¶å¯¹ç¹å®äºç¨æ·çç¹å¾ç¹å«ææãç°æçç ç©¶éå¸¸éè¿å³æ³¨ææææ¬çä½èç»´åº¦æ¥å°ä¸ªæ§åæ³¨å¥å°åæä¸­ãç¶èï¼è¿äºæ¹æ³å¿½ç¥äºé¢æè¯»èå¯¹éå¼ææååºçæ½å¨å½±åãå¨æ¬æä¸­ï¼æä»¬å° IEA ä»»å¡ç»åä¸ºä¸ªæ§åéå¼ææåæ (PIEA)ï¼å¹¶å¼å¥ RAPPIE æ¨¡åï¼è¿æ¯ä¸ä¸ªæ°é¢çæ¡æ¶ï¼æ¨å¨è§£å³æ­¤ä»»å¡ä¸­ç¼ºå°ç¨æ·ä¿¡æ¯çé®é¢ãç¹å«æ¯ï¼1) æä»¬åºäºå¤§åè¯­è¨æ¨¡ååå»ºè¯»èä»£çæ¥æ¨¡æè¯»èååºï¼ä»¥è§£å³å¨è·åè¯»èåé¦ä¿¡æ¯æ¶éå°çæ²é»èºæåæ°æ®ä¸å®æ´æ§çææã2) æä»¬å»ºç«äºä¸ä¸ªè¯»èä¼ æ­è§è²ç³»ç»ï¼å¹¶å¼åäºä¸ä¸ªè§è²æç¥æç»ªä¼ æ­å¤è§å¾å¾å­¦ä¹ æ¨¡åï¼è¯¥æ¨¡åéè¿å©ç¨ä¼ æ­è§è²çåå¸ææå°å¤çè¯»èä¿¡æ¯çç¨çæ§ã3) æä»¬ä½¿ç¨è¯¦ç»çç¨æ·åæ°æ®æ³¨éäºä¸¤ä¸ªä¸­æ PIEA æ°æ®éï¼ä»èè§£å³äºååä¸»è¦ä¸æ³¨äºææ¬åå®¹æ³¨éçæ°æ®éçå±éæ§ãå¨è¿äºæ°æ®éä¸è¿è¡çå¹¿æ³å®éªè¡¨æï¼RAPPIE æ¨¡åä¼äºå½åæåè¿çåºçº¿ï¼çªåºäºå°è¯»èåé¦çº³å¥ PIEA è¿ç¨çéè¦æ§åæææ§ã

##### **ProVision: Programmatically Scaling Vision-centric Instruction Data for Multimodal Language Models**
2412.07012v2 by Jieyu Zhang, Le Xue, Linxin Song, Jun Wang, Weikai Huang, Manli Shu, An Yan, Zixian Ma, Juan Carlos Niebles, silvio savarese, Caiming Xiong, Zeyuan Chen, Ranjay Krishna, Ran Xu

With the rise of multimodal applications, instruction data has become
critical for training multimodal language models capable of understanding
complex image-based queries. Existing practices rely on powerful but costly
large language models (LLMs) or multimodal language models (MLMs) to produce
instruction data. These are often prone to hallucinations, licensing issues and
the generation process is often hard to scale and interpret. In this work, we
present a programmatic approach that employs scene graphs as symbolic
representations of images and human-written programs to systematically
synthesize vision-centric instruction data. Our approach ensures the
interpretability and controllability of the data generation process and scales
efficiently while maintaining factual accuracy. By implementing a suite of 24
single-image, 14 multi-image instruction generators, and a scene graph
generation pipeline, we build a scalable, cost-effective system: ProVision
which produces diverse question-answer pairs concerning objects, attributes,
relations, depth, etc., for any given image. Applied to Visual Genome and
DataComp datasets, we generate over 10 million instruction data points,
ProVision-10M, and leverage them in both pretraining and instruction tuning
stages of MLMs. When adopted in the instruction tuning stage, our single-image
instruction data yields up to a 7% improvement on the 2D split and 8% on the 3D
split of CVBench, along with a 3% increase in performance on QBench2,
RealWorldQA, and MMMU. Our multi-image instruction data leads to an 8%
improvement on Mantis-Eval. Incorporation of our data in both pre-training and
fine-tuning stages of xGen-MM-4B leads to an averaged improvement of 1.6%
across 11 benchmarks.

æè¦ï¼<paragraph>é¨èå¤æ¨¡ææç¨ç¨å¼èèµ·ï¼æä»¤è³æå·²æçºè¨ç·´å¤æ¨¡æèªè¨æ¨¡åçééµï¼è©²æ¨¡åè½å¤ çè§£åºæ¼è¤éå½±åçæ¥è©¢ãç¾æåæ³ä¾è³´æ¼å¼·å¤§ä½æè²´çå¤§åèªè¨æ¨¡å (LLM) æå¤æ¨¡æèªè¨æ¨¡å (MLM) ä¾ç¢çæä»¤è³æãéäºæ¹æ³ç¶å¸¸å®¹æåºç¾å¹»è¦ºãææ¬åé¡ï¼ä¸çæéç¨éå¸¸é£ä»¥æ´ååè©®éãå¨éé å·¥ä½ä¸­ï¼æåæåºäºä¸ç¨®ç¨å¼åæ¹æ³ï¼ä½¿ç¨å ´æ¯åå½¢ä½çºå½±åçç¬¦èè¡¨ç¤ºï¼ä¸¦ä½¿ç¨äººæ°å¯«çç¨å¼ç³»çµ±æ§å°åæä»¥è¦è¦ºçºä¸­å¿çæä»¤è³æãæåçåæ³ç¢ºä¿äºè³æçæéç¨çå¯è©®éæ§åå¯æ§æ§ï¼ä¸¦å¨ç¶­æäºå¯¦æºç¢ºæ§çåæææå°æ´åãééå¯¦ä½ä¸çµ 24 åå®ä¸å½±åã14 åå¤éå½±åæä»¤ç¢çå¨ï¼ä»¥åä¸åå ´æ¯åå½¢ç¢çç®¡ç·ï¼æåå»ºç«äºä¸åå¯æ´åãå·æææ¬æççç³»çµ±ï¼ProVisionï¼å®éå°ä»»ä½çµ¦å®çå½±åç¢çéæ¼ç©ä»¶ãå±¬æ§ãéä¿ãæ·±åº¦ç­çåç¨®åç­éå°ãæç¨æ¼ Visual Genome å DataComp è³æéï¼æåç¢çäºè¶é 1000 è¬åæä»¤è³æé»ï¼ProVision-10Mï¼ä¸¦å¨ MLM çé è¨ç·´åæä»¤å¾®èª¿éæ®µä¸­å ä»¥å©ç¨ãç¶å¨æä»¤å¾®èª¿éæ®µæ¡ç¨æï¼æåçå®ä¸å½±åæä»¤è³æå¨ CVBench ç 2D åå²ä¸­æåäº 7%ï¼å¨ 3D åå²ä¸­æåäº 8%ï¼å¨ QBench2ãRealWorldQA å MMMU ä¸çæè½ä¹æåäº 3%ãæåçå¤éå½±åæä»¤è³æå¨ Mantis-Eval ä¸æåäº 8%ãå¨ xGen-MM-4B çé è¨ç·´åå¾®èª¿éæ®µä¸­ç´å¥æåçè³æï¼å¨ 11 ååºæºæ¸¬è©¦ä¸­å¹³åæåäº 1.6%ã</paragraph>

##### **Generative Adversarial Reviews: When LLMs Become the Critic**
2412.10415v1 by Nicolas Bougie, Narimasa Watanabe

The peer review process is fundamental to scientific progress, determining
which papers meet the quality standards for publication. Yet, the rapid growth
of scholarly production and increasing specialization in knowledge areas strain
traditional scientific feedback mechanisms. In light of this, we introduce
Generative Agent Reviewers (GAR), leveraging LLM-empowered agents to simulate
faithful peer reviewers. To enable generative reviewers, we design an
architecture that extends a large language model with memory capabilities and
equips agents with reviewer personas derived from historical data. Central to
this approach is a graph-based representation of manuscripts, condensing
content and logically organizing information - linking ideas with evidence and
technical details. GAR's review process leverages external knowledge to
evaluate paper novelty, followed by detailed assessment using the graph
representation and multi-round assessment. Finally, a meta-reviewer aggregates
individual reviews to predict the acceptance decision. Our experiments
demonstrate that GAR performs comparably to human reviewers in providing
detailed feedback and predicting paper outcomes. Beyond mere performance
comparison, we conduct insightful experiments, such as evaluating the impact of
reviewer expertise and examining fairness in reviews. By offering early
expert-level feedback, typically restricted to a limited group of researchers,
GAR democratizes access to transparent and in-depth evaluation.

æè¦ï¼åè¡è©å¯©ç¨åºå°æ¼ç§å­¸é²å±è³ééè¦ï¼å®æ±ºå®äºåªäºè«æç¬¦ååºççåè³ªæ¨æºãç¶èï¼å­¸è¡èä½çå¿«éå¢é·ä»¥åç¥è­é åçæ¥çå°æ¥­åï¼å°å³çµ±çç§å­¸åé¥æ©å¶é æå£åãæéæ¼æ­¤ï¼æåå¼å¥äºçæå¼ä»£çå¯©æ¥å¡ (GAR)ï¼å©ç¨ LLM è³¦è½çä»£çä¾æ¨¡æ¬å¿ å¯¦çåè¡å¯©æ¥å¡ãçºäºåç¨çæå¼å¯©æ¥å¡ï¼æåè¨­è¨äºä¸ç¨®æ¶æ§ï¼å°å¤§åèªè¨æ¨¡åæ´å±å°å·åè¨æ¶è½åï¼ä¸¦ä½¿ç¨å¾æ­·å²æ¸æä¸­è¡ççå¯©æ¥å¡è§è²ä¾è£åä»£çãéç¨®æ¹æ³çæ ¸å¿æ¯æç¨¿çåå½¢åè¡¨ç¤ºï¼æ¿ç¸®å§å®¹ä¸¦éè¼¯å°çµç¹è³è¨ï¼å°æ³æ³èè­æåæè¡ç´°ç¯è¯ç¹«èµ·ä¾ãGAR çå¯©æ¥éç¨å©ç¨å¤é¨ç¥è­ä¾è©ä¼°è«æçæ°ç©æ§ï¼ç¶å¾ä½¿ç¨åå½¢è¡¨ç¤ºåå¤è¼ªè©ä¼°é²è¡è©³ç´°è©ä¼°ãæå¾ï¼ä¸ä½åå¯©æ¥å¡å½ç¸½åå¥å¯©æ¥æè¦ï¼ä»¥é æ¸¬æ¥åæ±ºå®ãæåçå¯¦é©è¡¨æï¼GAR å¨æä¾è©³ç´°åé¥åé æ¸¬è«æçµææ¹é¢ï¼è¡¨ç¾èäººé¡å¯©æ¥å¡ç¸ç¶ãé¤äºå®ç´çæ§è½æ¯è¼ä¹å¤ï¼æåéé²è¡äºæè¦å°çå¯¦é©ï¼ä¾å¦è©ä¼°å¯©æ¥å¡å°æ¥­ç¥è­çå½±é¿ï¼ä»¥åå¯©æ¥å¬å¹³æ§çæª¢è¦ãééæä¾æ©æå°å®¶ç´åé¥ï¼éå¸¸åéæ¼å°æ¸ç ç©¶äººå¡ï¼GAR æ°ä¸»åäºå°éæä¸æ·±å¥è©ä¼°çå­åã

##### **A Self-guided Multimodal Approach to Enhancing Graph Representation Learning for Alzheimer's Diseases**
2412.06212v1 by Zhepeng Wang, Runxue Bao, Yawen Wu, Guodong Liu, Lei Yang, Liang Zhan, Feng Zheng, Weiwen Jiang, Yanfu Zhang

Graph neural networks (GNNs) are powerful machine learning models designed to
handle irregularly structured data. However, their generic design often proves
inadequate for analyzing brain connectomes in Alzheimer's Disease (AD),
highlighting the need to incorporate domain knowledge for optimal performance.
Infusing AD-related knowledge into GNNs is a complicated task. Existing methods
typically rely on collaboration between computer scientists and domain experts,
which can be both time-intensive and resource-demanding. To address these
limitations, this paper presents a novel self-guided, knowledge-infused
multimodal GNN that autonomously incorporates domain knowledge into the model
development process. Our approach conceptualizes domain knowledge as natural
language and introduces a specialized multimodal GNN capable of leveraging this
uncurated knowledge to guide the learning process of the GNN, such that it can
improve the model performance and strengthen the interpretability of the
predictions. To evaluate our framework, we curated a comprehensive dataset of
recent peer-reviewed papers on AD and integrated it with multiple real-world AD
datasets. Experimental results demonstrate the ability of our method to extract
relevant domain knowledge, provide graph-based explanations for AD diagnosis,
and improve the overall performance of the GNN. This approach provides a more
scalable and efficient alternative to inject domain knowledge for AD compared
with the manual design from the domain expert, advancing both prediction
accuracy and interpretability in AD diagnosis.

æè¦ï¼åå½¢ç¥ç¶ç¶²è·¯ (GNN) æ¯ä¸æ¬¾å¼·å¤§çæ©å¨å­¸ç¿æ¨¡åï¼å°éç¨æ¼èççµæ§ä¸è¦åçè³æãç¶èï¼å®åçéç¨è¨­è¨éå¸¸ç¡æ³åååæé¿è²æµ·é»ç (AD) ä¸­çè¦é£æ¥é«ï¼çªé¡¯äºå å¥é åç¥è­ä»¥åªåæè½çéæ±ãå° AD ç¸éç¥è­èå¥ GNN æ¯ä¸é è¤éçä»»åãç¾ææ¹æ³éå¸¸ä»°è³´é»è¦ç§å­¸å®¶åé åå°å®¶ä¹éçåä½ï¼éå¯è½æèè²»å¤§éæéåè³æºãçºäºè§£æ±ºéäºéå¶ï¼æ¬ææåºäºä¸ç¨®æ°ç©çèªå°å¼ãç¥è­æ³¨å¥å¤æ¨¡å¼ GNNï¼å®è½èªä¸»å°å°é åç¥è­ç´å¥æ¨¡åéç¼éç¨ä¸­ãæåçåæ³å°é åç¥è­æ¦å¿µåçºèªç¶èªè¨ï¼ä¸¦å¼å¥ä¸åå°éçå¤æ¨¡å¼ GNNï¼å®è½å©ç¨éç¨®æªç¶æ´ççç¥è­ä¾æå° GNN çå­¸ç¿éç¨ï¼ä»¥ä¾¿å®è½æ¹åæ¨¡åæè½ä¸¦å å¼·é æ¸¬çå¯è§£éæ§ãçºäºè©ä¼°æåçæ¶æ§ï¼æåæ´çäºä¸ä»½éæ¼ AD çè¿æåè¡è©å¯©è«æçå¨é¢è³æéï¼ä¸¦å°å¶èå¤åçå¯¦ä¸çç AD è³æéæ´åãå¯¦é©çµæè­æäºæåçæ¹æ³è½å¤ èåç¸éçé åç¥è­ãæä¾ AD è¨ºæ·çåå½¢åèªªæï¼ä¸¦æ¹å GNN çæ´é«æè½ãèé åå°å®¶çæåè¨­è¨ç¸æ¯ï¼éç¨®æ¹æ³æä¾äºä¸åæ´å·å¯æ´åæ§åæçæ§çæ¿ä»£æ¹æ¡ï¼ç¨æ¼æ³¨å¥ AD çé åç¥è­ï¼é²èæå AD è¨ºæ·ä¸­çé æ¸¬æºç¢ºæ§åå¯è§£éæ§ã

##### **Automated Extraction and Creation of FBS Design Reasoning Knowledge Graphs from Structured Data in Product Catalogues Lacking Contextual Information**
2412.05868v1 by Vijayalaxmi Sahadevan, Sushil Mario, Yash Jaiswal, Divyanshu Bajpai, Vishal Singh, Hiralal Aggarwal, Suhas Suresh, Manjunath Maigur

Ontology-based knowledge graphs (KG) are desirable for effective knowledge
management and reuse in various decision making scenarios, including design.
Creating and populating extensive KG based on specific ontological models can
be highly labour and time-intensive unless automated processes are developed
for knowledge extraction and graph creation. Most research and development on
automated extraction and creation of KG is based on extensive unstructured data
sets that provide contextual information. However, some of the most useful
information about the products and services of a company has traditionally been
recorded as structured data. Such structured data sets rarely follow a standard
ontology, do not capture explicit mapping of relationships between the
entities, and provide no contextual information. Therefore, this research
reports a method and digital workflow developed to address this gap. The
developed method and workflow employ rule-based techniques to extract and
create a Function Behaviour-Structure (FBS) ontology-based KG from legacy
structured data, especially specification sheets and product catalogues. The
solution approach consists of two main components: a process for deriving
context and context-based classification rules for FBS ontology concepts and a
workflow for populating and retrieving the FBS ontology-based KG. KG and
Natural Language Processing (NLP) are used to automate knowledge extraction,
representation, and retrieval. The workflow's effectiveness is demonstrated via
pilot implementation in an industrial context. Insights gained from the pilot
study are reported regarding the challenges and opportunities, including
discussing the FBS ontology and concepts.

æè¦ï¼<paragraph>åºæ¼æ¬ä½è«çç¥è­åè­ (KG) å°æ¼å¨åç¨®æ±ºç­å¶å®æå¢ï¼åæ¬è¨­è¨ï¼ä¸­ææç®¡çåéç¨ç¥è­æ¯çæ³çãå»ºç«ä¸¦å¡«å¥åºæ¼ç¹å®æ¬é«æ¨¡åçå»£æ³ KG å¯è½éå¸¸èè²»äººååæéï¼é¤ééç¼åºç¨æ¼ç¥è­èåååè­å»ºç«çèªååæµç¨ãå¤§å¤æ¸éæ¼ KG èªååèååå»ºç«çç ç©¶åéç¼é½åºæ¼æä¾èçµ¡è³è¨çå»£æ³éçµæ§åè³æéãç¶èï¼éæ¼å¬å¸ç¢ååæåçä¸äºææç¨çè³è¨å³çµ±ä¸é½æ¯ä»¥çµæ§åè³æè¨éçãæ­¤é¡çµæ§åè³æéå¾å°éµå¾ªæ¨æºæ¬é«è«ï¼ä¸ææ·åå¯¦é«ä¹ééä¿çæç¢ºå°æï¼ä¹ä¸ææä¾èçµ¡è³è¨ãå æ­¤ï¼æ¬ç ç©¶å ±åäºä¸ç¨®æ¹æ³åæ¸ä½å·¥ä½æµç¨ï¼ç¨æ¼è§£æ±ºæ­¤å·®è·ãéç¼çæ¹æ³åå·¥ä½æµç¨æ¡ç¨åºæ¼è¦åçæè¡ï¼å¾å³çµ±çµæ§åè³æï¼ç¹å¥æ¯è¦æ ¼è¡¨åç¢åç®éï¼ä¸­èåä¸¦å»ºç«åè½è¡çºçµæ§ (FBS) æ¬é«è«åºç¤ç KGãè§£æ±ºæ¹æ¡æ¹æ³åå«å©åä¸»è¦çµæé¨åï¼ä¸åç¨æ¼æ¨å° FBS æ¬é«è«æ¦å¿µçèçµ¡ååºæ¼èçµ¡çåé¡è¦åçæµç¨ï¼ä»¥åä¸åç¨æ¼å¡«å¥åæª¢ç´¢ FBS æ¬é«è«åºç¤ç KG çå·¥ä½æµç¨ãKG åèªç¶èªè¨èç (NLP) ç¨æ¼èªååç¥è­èåãè¡¨ç¤ºåæª¢ç´¢ãå·¥ä½æµç¨çæææ§ééå¨å·¥æ¥­èçµ¡ä¸­çè©¦é»å¯¦ä½å¾å°è­æãå ±åäºå¾è©¦é»ç ç©¶ä¸­ç²å¾çè¦è§£ï¼åæ¬è¨è« FBS æ¬é«è«åæ¦å¿µå¨å§çææ°åæ©æã</paragraph>

##### **A Collaborative Multi-Agent Approach to Retrieval-Augmented Generation Across Diverse Data**
2412.05838v1 by Aniruddha Salve, Saba Attar, Mahesh Deshmukh, Sayali Shivpuje, Arnab Mitra Utsab

Retrieval-Augmented Generation (RAG) enhances Large Language Models (LLMs) by
incorporating external, domain-specific data into the generative process. While
LLMs are highly capable, they often rely on static, pre-trained datasets,
limiting their ability to integrate dynamic or private data. Traditional RAG
systems typically use a single-agent architecture to handle query generation,
data retrieval, and response synthesis. However, this approach becomes
inefficient when dealing with diverse data sources, such as relational
databases, document stores, and graph databases, often leading to performance
bottlenecks and reduced accuracy. This paper proposes a multi-agent RAG system
to address these limitations. Specialized agents, each optimized for a specific
data source, handle query generation for relational, NoSQL, and document-based
systems. These agents collaborate within a modular framework, with query
execution delegated to an environment designed for compatibility across various
database types. This distributed approach enhances query efficiency, reduces
token overhead, and improves response accuracy by ensuring that each agent
focuses on its specialized task. The proposed system is scalable and adaptable,
making it ideal for generative AI workflows that require integration with
diverse, dynamic, or private data sources. By leveraging specialized agents and
a modular execution environment, the system provides an efficient and robust
solution for handling complex, heterogeneous data environments in generative AI
applications.

æè¦ï¼æª¢ç´¢å¢å¼·çæ (RAG) ééå°å¤é¨é åç¹å®è³æç´å¥çææµç¨ï¼å¢å¼·å¤§åèªè¨æ¨¡å (LLM)ãéç¶ LLM å·æé«åº¦è½åï¼ä½å®åéå¸¸ä¾è³´æ¼éæçé è¨ç·´è³æéï¼éå¶äºå®åæ´ååææç§äººè³æçè½åãå³çµ±ç RAG ç³»çµ±éå¸¸ä½¿ç¨å®ä¸ä»£çæ¶æ§ä¾èçæ¥è©¢çæãè³ææª¢ç´¢ååæåæãç¶èï¼ç¶èçå¤æ¨£åçè³æä¾æºæï¼éç¨®æ¹æ³æè®å¾æ²ææçï¼ä¾å¦éä¿è³æåº«ãæä»¶å²å­ååå½¢è³æåº«ï¼éå¸¸æå°è´æè½ç¶é ¸åéä½æºç¢ºæ§ãæ¬ææåºä¸åå¤ä»£ç RAG ç³»çµ±ä¾è§£æ±ºéäºéå¶ãéå°ç¹å®è³æä¾æºæä½³åçå°éä»£çï¼è² è²¬éä¿ãNoSQL ååºæ¼æä»¶ç³»çµ±çæ¥è©¢çæãéäºä»£çå¨ä¸åæ¨¡çµåæ¶æ§å§åä½ï¼æ¥è©¢å·è¡å§æ´¾çµ¦ä¸åç°å¢ï¼è©²ç°å¢è¨­è¨çºèåç¨®è³æåº«é¡åç¸å®¹ãéç¨®åæ£å¼æ¹æ³å¢å¼·äºæ¥è©¢æçï¼æ¸å°äºæ¨è¨éé·ï¼ä¸¦ééç¢ºä¿æ¯åä»£çå°æ³¨æ¼å¶å°éä»»åï¼ä¾æ¹ååææºç¢ºæ§ãææåºçç³»çµ±å·æå¯æ´åæ§åé©ææ§ï¼ä½¿å¶æçºéè¦èå¤æ¨£åãåææç§äººè³æä¾æºæ´åççæå¼ AI å·¥ä½æµç¨ççæ³é¸æãééå©ç¨å°éä»£çåæ¨¡çµåå·è¡ç°å¢ï¼è©²ç³»çµ±çºèççæå¼ AI æç¨ç¨å¼ä¸­è¤éãç°è³ªçè³æç°å¢ï¼æä¾äºä¸åææä¸ç©©å¥çè§£æ±ºæ¹æ¡ã

##### **Large Language Models Merging for Enhancing the Link Stealing Attack on Graph Neural Networks**
2412.05830v1 by Faqian Guan, Tianqing Zhu, Wenhan Chang, Wei Ren, Wanlei Zhou

Graph Neural Networks (GNNs), specifically designed to process the graph
data, have achieved remarkable success in various applications. Link stealing
attacks on graph data pose a significant privacy threat, as attackers aim to
extract sensitive relationships between nodes (entities), potentially leading
to academic misconduct, fraudulent transactions, or other malicious activities.
Previous studies have primarily focused on single datasets and did not explore
cross-dataset attacks, let alone attacks that leverage the combined knowledge
of multiple attackers. However, we find that an attacker can combine the data
knowledge of multiple attackers to create a more effective attack model, which
can be referred to cross-dataset attacks. Moreover, if knowledge can be
extracted with the help of Large Language Models (LLMs), the attack capability
will be more significant. In this paper, we propose a novel link stealing
attack method that takes advantage of cross-dataset and Large Language Models
(LLMs). The LLM is applied to process datasets with different data structures
in cross-dataset attacks. Each attacker fine-tunes the LLM on their specific
dataset to generate a tailored attack model. We then introduce a novel model
merging method to integrate the parameters of these attacker-specific models
effectively. The result is a merged attack model with superior generalization
capabilities, enabling effective attacks not only on the attackers' datasets
but also on previously unseen (out-of-domain) datasets. We conducted extensive
experiments in four datasets to demonstrate the effectiveness of our method.
Additional experiments with three different GNN and LLM architectures further
illustrate the generality of our approach.

æè¦ï¼åç¥ç¶ç¶²è·¯ (GNN) å°éç¨æ¼èçåå½¢è³æï¼å¨åç¨®æç¨ä¸­é½åå¾äºé¡¯èçæåãé£çµç«åæ»æå°åå½¢è³ææ§æéå¤§çé±ç§å¨èï¼å çºæ»æèæ¨å¨æåç¯é»ï¼å¯¦é«ï¼ä¹éçææéä¿ï¼å¯è½å°è´å­¸è¡ä¸ç¶è¡çºãæ¬ºè©äº¤ææå¶ä»æ¡ææ´»åãååçç ç©¶ä¸»è¦éä¸­æ¼å®ä¸è³æéï¼ä¸¦ä¸æ²ææ¢è¨è·¨è³æéæ»æï¼æ´ä¸ç¨èªªå©ç¨å¤åæ»æèçç¶åç¥è­çæ»æãç¶èï¼æåç¼ç¾æ»æèå¯ä»¥çµåå¤åæ»æèçè³æç¥è­ä¾å»ºç«æ´ææçæ»ææ¨¡åï¼éå¯ä»¥ç¨±çºè·¨è³æéæ»æãæ­¤å¤ï¼å¦æå¯ä»¥å¨å¤§åèªè¨æ¨¡å (LLM) çå¹«å©ä¸æåç¥è­ï¼åæ»æè½åå°ææ´é¡¯èãå¨æ¬æä¸­ï¼æåæåºäºä¸ç¨®æ°ç©çé£çµç«åæ»ææ¹æ³ï¼è©²æ¹æ³å©ç¨è·¨è³æéåå¤§åèªè¨æ¨¡å (LLM)ãLLM ç¨æ¼å¨è·¨è³æéæ»æä¸­èçå·æä¸åè³æçµæ§çè³æéãæ¯åæ»æèéå°å¶ç¹å®è³æéå¾®èª¿ LLM ä»¥ç¢çéèº«æé çæ»ææ¨¡åãç¶å¾ï¼æåå¼å¥ä¸ç¨®æ°ç©çæ¨¡ååä½µæ¹æ³ï¼ä»¥æææ´åéäºç¹å®æ¼æ»æèçæ¨¡åçåæ¸ãçµææ¯ä¸ååä½µçæ»ææ¨¡åï¼å·æåªç°çæ³åè½åï¼ä¸åå¯ä»¥å¨æ»æèçè³æéä¸é²è¡æææ»æï¼éå¯ä»¥å¨ä»¥åæªè¦çï¼åå¤ï¼è³æéä¸é²è¡æææ»æãæåå¨ååè³æéä¸­é²è¡äºå»£æ³çå¯¦é©ï¼ä»¥è­ææåæ¹æ³çæææ§ãä½¿ç¨ä¸ç¨®ä¸åç GNN å LLM æ¶æ§é²è¡çé¡å¤å¯¦é©é²ä¸æ­¥èªªæäºæåæ¹æ³çæ®éæ§ã

##### **GL-Fusion: Rethinking the Combination of Graph Neural Network and Large Language model**
2412.06849v1 by Haotong Yang, Xiyuan Wang, Qian Tao, Shuxian Hu, Zhouchen Lin, Muhan Zhang

Recent research on integrating Large Language Models (LLMs) with Graph Neural
Networks (GNNs) typically follows two approaches: LLM-centered models, which
convert graph data into tokens for LLM processing, and GNN-centered models,
which use LLMs to encode text features into node and edge representations for
GNN input. LLM-centered models often struggle to capture graph structures
effectively, while GNN-centered models compress variable-length textual data
into fixed-size vectors, limiting their ability to understand complex
semantics. Additionally, GNN-centered approaches require converting tasks into
a uniform, manually-designed format, restricting them to classification tasks
and preventing language output. To address these limitations, we introduce a
new architecture that deeply integrates GNN with LLM, featuring three key
innovations: (1) Structure-Aware Transformers, which incorporate GNN's
message-passing capabilities directly into LLM's transformer layers, allowing
simultaneous processing of textual and structural information and generating
outputs from both GNN and LLM; (2) Graph-Text Cross-Attention, which processes
full, uncompressed text from graph nodes and edges, ensuring complete semantic
integration; and (3) GNN-LLM Twin Predictor, enabling LLM's flexible
autoregressive generation alongside GNN's scalable one-pass prediction.
GL-Fusion achieves outstand performance on various tasks. Notably, it achieves
state-of-the-art performance on OGBN-Arxiv and OGBG-Code2.

æè¦ï¼<paragraph>å°å¤§åèªè¨æ¨¡å (LLM) èåç¥ç¶ç¶²è·¯ (GNN) æ´åçææ°ç ç©¶éå¸¸éµå¾ªå©ç¨®æ¹æ³ï¼ä»¥ LLM çºä¸­å¿çæ¨¡åï¼å°åå½¢è³æè½æçº LLM èççç¬¦èï¼ä»¥åä»¥ GNN çºä¸­å¿çæ¨¡åï¼ä½¿ç¨ LLM å°æå­ç¹å¾µç·¨ç¢¼æç¯é»åéç·£è¡¨ç¤ºï¼ä½çº GNN è¼¸å¥ãä»¥ LLM çºä¸­å¿çæ¨¡åéå¸¸é£ä»¥æææ·ååå½¢çµæ§ï¼èä»¥ GNN çºä¸­å¿çæ¨¡åæå°è®é·æå­è³æå£ç¸®æåºå®å¤§å°çåéï¼éå¶å®åçè§£è¤éèªæçè½åãæ­¤å¤ï¼ä»¥ GNN çºä¸­å¿çæ¨¡åéè¦å°ä»»åè½ææçµ±ä¸çæåè¨­è¨æ ¼å¼ï¼éå¶å®ååªè½é²è¡åé¡ä»»åï¼ä¸ç¡æ³ç¢çèªè¨è¼¸åºãçºäºè§£æ±ºéäºéå¶ï¼æåå¼å¥ä¸ç¨®æ°çæ¶æ§ï¼å° GNN è LLM æ·±åº¦æ´åï¼å·åä¸å¤§ééµåµæ°ï¼(1) çµæ§æç¥Transformerï¼å° GNN çè¨æ¯å³éåè½ç´æ¥æ´åå° LLM çTransformerå±¤ä¸­ï¼åè¨±åæèçæå­åçµæ§è³è¨ï¼ä¸¦å¾ GNN å LLM ç¢çè¼¸åºï¼(2) åå½¢æå­äº¤åæ³¨æåï¼èçä¾èªåå½¢ç¯é»åéç·£çå®æ´æªå£ç¸®æå­ï¼ç¢ºä¿å®æ´çèªç¾©æ´åï¼(3) GNN-LLM ééé æ¸¬å¨ï¼åç¨ LLM çå½æ§èªè¿´æ­¸ç¢çï¼ä»¥å GNN çå¯æ´åå®æ¬¡é æ¸¬ãGL-Fusion å¨åç¨®ä»»åä¸­éæååºçæè½ãå¼å¾æ³¨æçæ¯ï¼å®å¨ OGBN-Arxiv å OGBG-Code2 ä¸éå°äºæåé²çæè½ã</paragraph>

##### **M$^{3}$-20M: A Large-Scale Multi-Modal Molecule Dataset for AI-driven Drug Design and Discovery**
2412.06847v1 by Siyuan Guo, Lexuan Wang, Chang Jin, Jinxian Wang, Han Peng, Huayang Shi, Wengen Li, Jihong Guan, Shuigeng Zhou

This paper introduces M$^{3}$-20M, a large-scale Multi-Modal Molecular
dataset that contains over 20 million molecules. Designed to support AI-driven
drug design and discovery, M$^{3}$-20M is 71 times more in the number of
molecules than the largest existing dataset, providing an unprecedented scale
that can highly benefit training or fine-tuning large (language) models with
superior performance for drug design and discovery. This dataset integrates
one-dimensional SMILES, two-dimensional molecular graphs, three-dimensional
molecular structures, physicochemical properties, and textual descriptions
collected through web crawling and generated by using GPT-3.5, offering a
comprehensive view of each molecule. To demonstrate the power of M$^{3}$-20M in
drug design and discovery, we conduct extensive experiments on two key tasks:
molecule generation and molecular property prediction, using large language
models including GLM4, GPT-3.5, and GPT-4. Our experimental results show that
M$^{3}$-20M can significantly boost model performance in both tasks.
Specifically, it enables the models to generate more diverse and valid
molecular structures and achieve higher property prediction accuracy than the
existing single-modal datasets, which validates the value and potential of
M$^{3}$-20M in supporting AI-driven drug design and discovery. The dataset is
available at \url{https://github.com/bz99bz/M-3}.

æè¦ï¼éç¯è«æä»ç´¹äº M$^{3}$-20Mï¼ä¸ååå«è¶é 2000 è¬ååå­çå¤§åå¤æ¨¡æåå­è³æéãM$^{3}$-20M æ¨å¨æ¯æ´ AI é©åçè¥ç©è¨­è¨åç¼ç¾ï¼å¶åå­æ¸éæ¯ç¾ææå¤§è³æéç 71 åï¼æä¾äºåææªæçè¦æ¨¡ï¼å¯ä»¥æ¥µå¤§å°åçæ¼è¨ç·´æå¾®èª¿å¤§åï¼èªè¨ï¼æ¨¡åï¼ä»¥å¨è¥ç©è¨­è¨åç¼ç¾æ¹é¢ç²å¾åè¶çæè½ãæ­¤è³æéæ´åäºééç¶²è·¯ç¬åæ¶éåä½¿ç¨ GPT-3.5 çæçå®ç¶­ SMILESãäºç¶­åå­åãä¸ç¶­åå­çµæ§ãç©çåå­¸æ§è³ªåæå­æè¿°ï¼æä¾äºæ¯ååå­çå¨é¢æª¢è¦ãçºäºå±ç¤º M$^{3}$-20M å¨è¥ç©è¨­è¨åç¼ç¾ä¸­çå¼·å¤§åè½ï¼æåå°å©åééµä»»åé²è¡äºå»£æ³çå¯¦é©ï¼åå­çæååå­æ§è³ªé æ¸¬ï¼ä½¿ç¨åæ¬ GLM4ãGPT-3.5 å GPT-4 å¨å§çå¤§åèªè¨æ¨¡åãæåçå¯¦é©çµæè¡¨æï¼M$^{3}$-20M å¯ä»¥é¡¯èæåæ¨¡åå¨å©åä»»åä¸­çæè½ãå·é«ä¾èªªï¼å®ä½¿æ¨¡åè½å¤ ç¢çæ´å¤æ¨£ååææçåå­çµæ§ï¼ä¸¦æ¯ç¾æçå®æ¨¡æè³æéç²å¾æ´é«çæ§è³ªé æ¸¬æºç¢ºåº¦ï¼éé©è­äº M$^{3}$-20M å¨æ¯æ´ AI é©åçè¥ç©è¨­è¨åç¼ç¾ä¸­çå¹å¼åæ½åãè³æéå¯å¨ \url{https://github.com/bz99bz/M-3} åå¾ã

##### **HMGIE: Hierarchical and Multi-Grained Inconsistency Evaluation for Vision-Language Data Cleansing**
2412.05685v1 by Zihao Zhu, Hongbao Zhang, Guanzong Wu, Siwei Lyu, Baoyuan Wu

Visual-textual inconsistency (VTI) evaluation plays a crucial role in
cleansing vision-language data. Its main challenges stem from the high variety
of image captioning datasets, where differences in content can create a range
of inconsistencies (\eg, inconsistencies in scene, entities, entity attributes,
entity numbers, entity interactions). Moreover, variations in caption length
can introduce inconsistencies at different levels of granularity as well. To
tackle these challenges, we design an adaptive evaluation framework, called
Hierarchical and Multi-Grained Inconsistency Evaluation (HMGIE), which can
provide multi-grained evaluations covering both accuracy and completeness for
various image-caption pairs. Specifically, the HMGIE framework is implemented
by three consecutive modules. Firstly, the semantic graph generation module
converts the image caption to a semantic graph for building a structural
representation of all involved semantic items. Then, the hierarchical
inconsistency evaluation module provides a progressive evaluation procedure
with a dynamic question-answer generation and evaluation strategy guided by the
semantic graph, producing a hierarchical inconsistency evaluation graph (HIEG).
Finally, the quantitative evaluation module calculates the accuracy and
completeness scores based on the HIEG, followed by a natural language
explanation about the detection results. Moreover, to verify the efficacy and
flexibility of the proposed framework on handling different image captioning
datasets, we construct MVTID, an image-caption dataset with diverse types and
granularities of inconsistencies. Extensive experiments on MVTID and other
benchmark datasets demonstrate the superior performance of the proposed HMGIE
to current state-of-the-art methods.

æè¦ï¼è¦è¦ºææ¬ä¸ä¸è´æ§ (VTI) è©ä¼°å¨æ¸çè¦è¦ºèªè¨è³æä¸­æ®æ¼èè³ééè¦çè§è²ãå¶ä¸»è¦ææ°æºèªæ¼ååæ¨é¡è³æéçç¨®é¡ç¹å¤ï¼å¶ä¸­å§å®¹çå·®ç°å¯è½æé æåç¨®ä¸ä¸è´æ§ï¼ä¾å¦å ´æ¯ãå¯¦é«ãå¯¦é«å±¬æ§ãå¯¦é«æ¸éãå¯¦é«äºåçä¸ä¸è´æ§ï¼ãæ­¤å¤ï¼æ¨é¡é·åº¦çè®åä¹æå¨ä¸åç²åº¦å±¤ç´å¼ç¼ä¸ä¸è´æ§ãçºäºæå°éäºææ°ï¼æåè¨­è¨äºä¸åèªé©æè©ä¼°æ¶æ§ï¼ç¨±çºéå±¤å¼å¤ç²åº¦ä¸ä¸è´æ§è©ä¼° (HMGIE)ï¼å®å¯ä»¥æä¾å¤ç²åº¦è©ä¼°ï¼æ¶µèåç¨®ååæ¨é¡å°çæºç¢ºæ§åå®æ´æ§ãå·é«ä¾èªªï¼HMGIE æ¶æ§æ¯ç±ä¸åé£çºæ¨¡çµå¯¦ä½çãé¦åï¼èªæåå½¢ç¢çæ¨¡çµå°ååæ¨é¡è½æçºèªæåå½¢ï¼ä»¥å»ºç«ææç¸éèªæé ç®ççµæ§åè¡¨ç¤ºãç¶å¾ï¼éå±¤å¼ä¸ä¸è´æ§è©ä¼°æ¨¡çµæä¾æ¼¸é²å¼è©ä¼°ç¨åºï¼ä¸¦æ¡ç¨ç±èªæåå½¢å¼å°çåæåé¡è§£ç­ç¢çåè©ä¼°ç­ç¥ï¼ç¢çéå±¤å¼ä¸ä¸è´æ§è©ä¼°åå½¢ (HIEG)ãæå¾ï¼éåè©ä¼°æ¨¡çµæ ¹æ HIEG è¨ç®æºç¢ºæ§åå®æ´æ§åæ¸ï¼æ¥èå°åµæ¸¬çµæé²è¡èªç¶èªè¨èªªæãæ­¤å¤ï¼çºäºé©è­ææåºçæ¶æ§å¨èçä¸åååæ¨é¡è³æéä¸çæè½åéæ´»æ§ï¼æåå»ºæ§äº MVTIDï¼ä¸åå·æä¸åé¡ååä¸ä¸è´æ§ç²åº¦çååæ¨é¡è³æéãå¨ MVTID åå¶ä»åºæºè³æéä¸çå¤§éå¯¦é©è­æäºææåºç HMGIE åªæ¼ç¶åæåé²çæ¹æ³ã

##### **KG-Retriever: Efficient Knowledge Indexing for Retrieval-Augmented Large Language Models**
2412.05547v1 by Weijie Chen, Ting Bai, Jinbo Su, Jian Luan, Wei Liu, Chuan Shi

Large language models with retrieval-augmented generation encounter a pivotal
challenge in intricate retrieval tasks, e.g., multi-hop question answering,
which requires the model to navigate across multiple documents and generate
comprehensive responses based on fragmented information. To tackle this
challenge, we introduce a novel Knowledge Graph-based RAG framework with a
hierarchical knowledge retriever, termed KG-Retriever. The retrieval indexing
in KG-Retriever is constructed on a hierarchical index graph that consists of a
knowledge graph layer and a collaborative document layer. The associative
nature of graph structures is fully utilized to strengthen intra-document and
inter-document connectivity, thereby fundamentally alleviating the information
fragmentation problem and meanwhile improving the retrieval efficiency in
cross-document retrieval of LLMs. With the coarse-grained collaborative
information from neighboring documents and concise information from the
knowledge graph, KG-Retriever achieves marked improvements on five public QA
datasets, showing the effectiveness and efficiency of our proposed RAG
framework.

æè¦ï¼å¤§åè¯­è¨æ¨¡åä½¿ç¨æ£ç´¢å¢å¼ºçæå¨å¤æçæ£ç´¢ä»»å¡ä¸­ä¼éå°å³é®ææï¼ä¾å¦å¤è·³é®é¢è§£ç­ï¼è¿è¦æ±æ¨¡åè·¨å¤ä¸ªææ¡£å¯¼èªå¹¶æ ¹æ®çæ®µä¿¡æ¯çæç»¼åååºãä¸ºäºåºå¯¹è¿ä¸ææï¼æä»¬å¼å¥äºä¸ä¸ªåºäºç¥è¯å¾è°±çæ°å RAG æ¡æ¶ï¼è¯¥æ¡æ¶å·æåå±ç¥è¯æ£ç´¢å¨ï¼ç§°ä¸º KG-RetrieverãKG-Retriever ä¸­çæ£ç´¢ç´¢å¼æå»ºå¨åå±ç´¢å¼å¾ä¸ï¼è¯¥å¾ç±ç¥è¯å¾è°±å±ååä½ææ¡£å±ç»æãå¾ç»æçå³èæ§è´¨è¢«ååå©ç¨ä»¥å å¼ºææ¡£ååææ¡£é´è¿æ¥æ§ï¼ä»èä»æ ¹æ¬ä¸ç¼è§£ä¿¡æ¯ç¢çåé®é¢ï¼åæ¶æé« LLM è·¨ææ¡£æ£ç´¢ä¸­çæ£ç´¢æçãéè¿æ¥èªç¸é»ææ¡£çç²ç²åº¦åä½ä¿¡æ¯åæ¥èªç¥è¯å¾è°±çç®æ´ä¿¡æ¯ï¼KG-Retriever å¨äºä¸ªå¬å±é®ç­æ°æ®éä¸åå¾äºæ¾çæ¹è¿ï¼æ¾ç¤ºäºæä»¬æåºç RAG æ¡æ¶çæææ§åæçã

##### **Knowledge Graphs are all you need: Leveraging KGs in Physics Question Answering**
2412.05453v1 by Krishnasai Addala, Kabir Dev Paul Baghel, Dhruv Jain, Chhavi Kirtani, Avinash Anand, Rajiv Ratn Shah

This study explores the effectiveness of using knowledge graphs generated by
large language models to decompose high school-level physics questions into
sub-questions. We introduce a pipeline aimed at enhancing model response
quality for Question Answering tasks. By employing LLMs to construct knowledge
graphs that capture the internal logic of the questions, these graphs then
guide the generation of subquestions. We hypothesize that this method yields
sub-questions that are more logically consistent with the original questions
compared to traditional decomposition techniques. Our results show that
sub-questions derived from knowledge graphs exhibit significantly improved
fidelity to the original question's logic. This approach not only enhances the
learning experience by providing clearer and more contextually appropriate
sub-questions but also highlights the potential of LLMs to transform
educational methodologies. The findings indicate a promising direction for
applying AI to improve the quality and effectiveness of educational content.

æè¦ï¼æ¬ç ç©¶æ¢è¨ä½¿ç¨å¤§åèªè¨æ¨¡åç¢ççç¥è­åè­å°é«ä¸­ç©çé¡ç®åè§£æå­åé¡çæææ§ãæåå¼é²ä¸åæ¨å¨å¢å¼·æ¨¡ååæåè³ªçç®¡éï¼ç¨æ¼åç­ä»»åãééä½¿ç¨å¤§åèªè¨æ¨¡åå»ºç«ç¥è­åè­ä»¥ææåé¡çå§é¨éè¼¯ï¼éäºåè­æ¥èå¼å°å­åé¡çç¢çãæååè¨­èå³çµ±åè§£æè¡ç¸æ¯ï¼æ­¤æ¹æ³ç¢ççå­åé¡èåå§åé¡å¨éè¼¯ä¸æ´ä¸è´ãæåççµæé¡¯ç¤ºï¼å¾ç¥è­åè­è¡ççå­åé¡å±ç¾åºé¡¯èæ¹åçä¿çåº¦ï¼ç¬¦ååå§åé¡çéè¼¯ãæ­¤æ¹æ³ä¸åééæä¾æ´æ¸æ°ä¸æ´ç¬¦åèçµ¡çå­åé¡ä¾å¢å¼·å­¸ç¿é«é©ï¼ä¹çªé¡¯å¤§åèªè¨æ¨¡åè½åæè²æ¹æ³çæ½åãéäºç¼ç¾æåºäºä¸åæåéçæ¹åï¼å¯å°äººå·¥æºæ§æç¨æ¼æåæè²å§å®¹çåè³ªèæææ§ã

##### **A Graph-Based Approach for Conversational AI-Driven Personal Memory Capture and Retrieval in a Real-world Application**
2412.05447v1 by Savini Kashmira, Jayanaka L. Dantanarayana, Joshua Brodsky, Ashish Mahendra, Yiping Kang, Krisztian Flautner, Lingjia Tang, Jason Mars

TOBU is a novel mobile application that captures and retrieves `personal
memories' (pictures/videos together with stories and context around those
moments) in a user-engaging AI-guided conversational approach. Our initial
prototype showed that existing retrieval techniques such as retrieval-augmented
generation (RAG) systems fall short due to their limitations in understanding
memory relationships, causing low recall, hallucination, and unsatisfactory
user experience. We design TOBUGraph, a novel graph-based retrieval approach.
During capturing, TOBUGraph leverages large language models (LLMs) to
automatically create a dynamic knowledge graph of memories, establishing
context and relationships of those memories. During retrieval, TOBUGraph
combines LLMs with the memory graph to achieve comprehensive recall through
graph traversal. Our evaluation using real user data demonstrates that
TOBUGraph outperforms multiple RAG implementations in both precision and
recall, significantly improving user experience through improved retrieval
accuracy and reduced hallucination.

æè¦ï¼TOBU æ¯ä¸æ¬¾æ°é¢çç§»å¨åºç¨ç¨åºï¼å®ä»¥ç¨æ·åä¸å¼ AI å¼å¯¼å¯¹è¯æ¹å¼ææåæ£ç´¢âä¸ªäººè®°å¿âï¼å¾ç/è§é¢ä»¥åè¿äºæ¶å»å¨å´çæäºåèæ¯ï¼ãæä»¬çåå§ååè¡¨æï¼ç°æçæ£ç´¢ææ¯ï¼ä¾å¦æ£ç´¢å¢å¼ºçæ (RAG) ç³»ç»ï¼ç±äºå®ä»¬å¨çè§£è®°å¿å³ç³»æ¹é¢çå±éæ§èè¡¨ç°ä¸ä½³ï¼ä»èå¯¼è´å¬åçä½ãåºç°å¹»è§åç¨æ·ä½éªä¸ä½³ãæä»¬è®¾è®¡äº TOBUGraphï¼ä¸ç§æ°é¢çåºäºå¾çæ£ç´¢æ¹æ³ãå¨æè·æé´ï¼TOBUGraph å©ç¨å¤§åè¯­è¨æ¨¡å (LLM) èªå¨åå»ºå¨æç¥è¯å¾è°±ï¼å»ºç«è¿äºè®°å¿çèæ¯åå³ç³»ãå¨æ£ç´¢æé´ï¼TOBUGraph å° LLM ä¸è®°å¿å¾è°±ç»åèµ·æ¥ï¼éè¿å¾éåå®ç°å¨é¢å¬åãæä»¬ä½¿ç¨çå®ç¨æ·æ°æ®è¿è¡çè¯ä¼°è¡¨æï¼TOBUGraph å¨ç²¾ç¡®åº¦åå¬åçæ¹é¢é½ä¼äºå¤ä¸ª RAG å®ç°ï¼éè¿æé«æ£ç´¢åç¡®åº¦ååå°å¹»è§ï¼æ¾èæ¹åäºç¨æ·ä½éªã

##### **KaLM: Knowledge-aligned Autoregressive Language Modeling via Dual-view Knowledge Graph Contrastive Learning**
2412.04948v1 by Peng Yu, Cheng Deng, Beiya Dai, Xinbing Wang, Ying Wen

Autoregressive large language models (LLMs) pre-trained by next token
prediction are inherently proficient in generative tasks. However, their
performance on knowledge-driven tasks such as factual knowledge querying
remains unsatisfactory. Knowledge graphs (KGs), as high-quality structured
knowledge bases, can provide reliable knowledge for LLMs, potentially
compensating for their knowledge deficiencies. Aligning LLMs with explicit,
structured knowledge from KGs has been a challenge; previous attempts either
failed to effectively align knowledge representations or compromised the
generative capabilities of LLMs, leading to less-than-optimal outcomes. This
paper proposes \textbf{KaLM}, a \textit{Knowledge-aligned Language Modeling}
approach, which fine-tunes autoregressive LLMs to align with KG knowledge via
the joint objective of explicit knowledge alignment and implicit knowledge
alignment. The explicit knowledge alignment objective aims to directly optimize
the knowledge representation of LLMs through dual-view knowledge graph
contrastive learning. The implicit knowledge alignment objective focuses on
incorporating textual patterns of knowledge into LLMs through triple completion
language modeling. Notably, our method achieves a significant performance boost
in evaluations of knowledge-driven tasks, specifically embedding-based
knowledge graph completion and generation-based knowledge graph question
answering.

æè¦ï¼<paragraph>èªååæ­¸å¤§åèªè¨æ¨¡å (LLM) ç¶ç±ä¸ä¸åç¬¦èé æ¸¬é åè¨ç·´ï¼æ¬è³ªä¸æé·çæå¼ä»»åãç¶èï¼å®åå¨ç¥è­é©åä»»åï¼ä¾å¦äºå¯¦ç¥è­æ¥è©¢ï¼ä¸çè¡¨ç¾ä»ä¸ç¡äººæãç¥è­åè­ (KG) ä½çºé«åè³ªççµæ§åç¥è­åº«ï¼å¯ä»¥çº LLM æä¾å¯é çç¥è­ï¼æ½å¨å°å½è£å¶ç¥è­ä¸è¶³ãå° LLM èä¾èª KG çæç¢ºçµæ§åç¥è­å°é½ä¸ç´æ¯ä¸é ææ°ï¼ååçåè©¦è¦ä¹ç¡æ³ææå°é½ç¥è­è¡¨ç¤ºï¼è¦ä¹æå®³ LLM ççæè½åï¼å°è´çµæä¸ç¡çæ³ãæ¬ææåºäºä¸å**KaLM**ï¼ä¸ç¨®**ç¥è­å°é½èªè¨å»ºæ¨¡**æ¹æ³ï¼å®å¾®èª¿èªååæ­¸ LLM ä»¥ééæç¢ºç¥è­å°é½åé±å¼ç¥è­å°é½çè¯åç®æ¨è KG ç¥è­å°é½ãæç¢ºç¥è­å°é½ç®æ¨æ¨å¨éééè¦åç¥è­åè­å°æ¯å­¸ç¿ç´æ¥æä½³å LLM çç¥è­è¡¨ç¤ºãé±å¼ç¥è­å°é½ç®æ¨å°æ³¨æ¼ééä¸åçµå®æèªè¨å»ºæ¨¡å°ç¥è­çæå­æ¨¡å¼ç´å¥ LLMãå¼å¾æ³¨æçæ¯ï¼æåçæ¨¡åå¨ç¥è­é©åä»»åçè©ä¼°ä¸­ç²å¾é¡¯èçæè½æåï¼ç¹å¥æ¯åºæ¼åµå¥çç¥è­åè­å®æååºæ¼çæçç¥è­åè­åé¡è§£ç­ã</paragraph>

##### **HyperGraphOS: A Meta Operating System for Science and Engineering**
2412.04923v1 by Antonello Ceravola, Frank Joublin, Ahmed R. Sadik, Bram Bolder, Juha-Pekka Tolvanen

This paper presents HyperGraphOS, an innovative Operating System designed for
the scientific and engineering domains. It combines model based engineering,
graph modeling, data containers, and computational tools, offering users a
dynamic workspace for creating and managing complex models represented as
customizable graphs. Using a web based architecture, HyperGraphOS requires only
a modern browser to organize knowledge, documents, and content into
interconnected models. Domain Specific Languages drive workspace navigation,
code generation, AI integration, and process organization.The platform models
function as both visual drawings and data structures, enabling dynamic
modifications and inspection, both interactively and programmatically.
HyperGraphOS was evaluated across various domains, including virtual avatars,
robotic task planning using Large Language Models, and meta modeling for
feature based code development. Results show significant improvements in
flexibility, data management, computation, and document handling.

æè¦ï¼æ¬ææåº HyperGraphOSï¼éæ¯ä¸ååµæ°çä½æ¥­ç³»çµ±ï¼å°çºç§å­¸åå·¥ç¨é åè¨­è¨ãå®çµåäºåºæ¼æ¨¡åçå·¥ç¨ãåå½¢å»ºæ¨¡ãè³æå®¹å¨åè¨ç®å·¥å·ï¼çºä½¿ç¨èæä¾ä¸ååæå·¥ä½ç©ºéï¼ç¨æ¼å»ºç«åç®¡çè¡¨ç¤ºçºå¯èªè¨åå½¢çè¤éæ¨¡åãHyperGraphOS ä½¿ç¨åºæ¼ Web çæ¶æ§ï¼åªéè¦ä¸åç¾ä»£çè¦½å¨å³å¯å°ç¥è­ãæä»¶åå§å®¹çµç¹æäºé£æ¨¡åãç¹å®é åèªè¨é©åå·¥ä½ç©ºéå°è¦½ãç¨å¼ç¢¼ç¢çãAI æ´ååæµç¨çµç¹ãå¹³å°æ¨¡ååæä½çºè¦è¦ºç¹ªååè³æçµæ§ï¼æ¯æ´åæä¿®æ¹åæª¢æ¥ï¼ç¡è«æ¯äºåå¼éæ¯ä»¥ç¨å¼æ¹å¼é²è¡ãHyperGraphOS å·²å¨åç¨®é åä¸­é²è¡è©ä¼°ï¼åæ¬èæ¬åèº«ãä½¿ç¨å¤§åèªè¨æ¨¡åçæ©å¨äººä»»åè¦åï¼ä»¥åç¨æ¼åºæ¼ç¹å¾µçç¨å¼ç¢¼éç¼çåå»ºæ¨¡ãçµæé¡¯ç¤ºåºéæ´»æ§ãè³æç®¡çãéç®åæä»¶èçæ¹é¢çé¡¯èæ¹é²ã

##### **Transformers Struggle to Learn to Search**
2412.04703v1 by Abulhair Saparov, Srushti Pawar, Shreyas Pimpalgaonkar, Nitish Joshi, Richard Yuanzhe Pang, Vishakh Padmakumar, Seyed Mehran Kazemi, Najoung Kim, He He

Search is an ability foundational in many important tasks, and recent studies
have shown that large language models (LLMs) struggle to perform search
robustly. It is unknown whether this inability is due to a lack of data,
insufficient model parameters, or fundamental limitations of the transformer
architecture. In this work, we use the foundational graph connectivity problem
as a testbed to generate effectively limitless high-coverage data to train
small transformers and test whether they can learn to perform search. We find
that, when given the right training distribution, the transformer is able to
learn to search.
  We analyze the algorithm that the transformer has learned through a novel
mechanistic interpretability technique that enables us to extract the
computation graph from the trained model. We find that for each vertex in the
input graph, transformers compute the set of vertices reachable from that
vertex. Each layer then progressively expands these sets, allowing the model to
search over a number of vertices exponential in the number of layers.
  However, we find that as the input graph size increases, the transformer has
greater difficulty in learning the task. This difficulty is not resolved even
as the number of parameters is increased, suggesting that increasing model
scale will not lead to robust search abilities. We also find that performing
search in-context (i.e., chain-of-thought) does not resolve this inability to
learn to search on larger graphs.

æè¦ï¼æå°æ¯è¨±å¤éè¦ä»»åä¸­çä¸é åºç¤è½åï¼æè¿çç ç©¶è¡¨æï¼å¤§åèªè¨æ¨¡å (LLM) é£ä»¥ç©©å¥å°å·è¡æå°ãç®åå°ä¸æ¸æ¥éç¨®ç¡è½æ¯æºæ¼è³æä¸è¶³ãæ¨¡ååæ¸ä¸è¶³ï¼éæ¯ Transformer æ¶æ§çåºæ¬éå¶ãå¨éé å·¥ä½ä¸­ï¼æåä½¿ç¨åºç¤åå½¢é£éæ§åé¡ä½çºæ¸¬è©¦å¹³å°ï¼çæææç¡éçé«è¦èçè³æï¼ä»¥è¨ç·´å°å Transformer ä¸¦æ¸¬è©¦å®åæ¯å¦è½å­¸æå·è¡æå°ãæåç¼ç¾ï¼ç¶çµ¦äºæ­£ç¢ºçè¨ç·´åä½æï¼Transformer è½å¤ å­¸ææå°ã
æåééä¸ç¨®æ°ç©çæ©å¶å¯è§£éæ§æè¡åæ Transformer å­¸å°çæ¼ç®æ³ï¼éè®æåè½å¤ å¾è¨ç·´å¥½çæ¨¡åä¸­æåéç®åå½¢ãæåç¼ç¾ï¼å°æ¼è¼¸å¥åå½¢ä¸­çæ¯åé é»ï¼Transformer æè¨ç®å¾è©²é é»å¯å°éçé é»éåãç¶å¾ï¼æ¯ä¸å±¤é½æéæ­¥æ´åéäºéåï¼è®æ¨¡åè½å¤ å¨èå±¤æ¸åææ¸éä¿çé é»æ¸ç®ä¸é²è¡æå°ã
ç¶èï¼æåç¼ç¾ï¼é¨èè¼¸å¥åå½¢å¤§å°çå¢å ï¼Transformer å¨å­¸ç¿ä»»åææéå°æ´å¤§çå°é£ãå³ä½¿å¢å åæ¸æ¸éï¼éç¨®å°é£ä¹ä¸æå¾å°è§£æ±ºï¼éè¡¨æå¢å æ¨¡åè¦æ¨¡ä¸æå¸¶ä¾ç©©å¥çæå°è½åãæåéç¼ç¾ï¼å¨ä¸ä¸æä¸­å·è¡æå°ï¼å³æèéï¼ç¡æ³è§£æ±ºéç¨®ç¡æ³å­¸ç¿å¨è¼å¤§åå½¢ä¸æå°çåé¡ã

##### **LLM-Align: Utilizing Large Language Models for Entity Alignment in Knowledge Graphs**
2412.04690v1 by Xuan Chen, Tong Lu, Zhichun Wang

Entity Alignment (EA) seeks to identify and match corresponding entities
across different Knowledge Graphs (KGs), playing a crucial role in knowledge
fusion and integration. Embedding-based entity alignment (EA) has recently
gained considerable attention, resulting in the emergence of many innovative
approaches. Initially, these approaches concentrated on learning entity
embeddings based on the structural features of knowledge graphs (KGs) as
defined by relation triples. Subsequent methods have integrated entities' names
and attributes as supplementary information to improve the embeddings used for
EA. However, existing methods lack a deep semantic understanding of entity
attributes and relations. In this paper, we propose a Large Language Model
(LLM) based Entity Alignment method, LLM-Align, which explores the
instruction-following and zero-shot capabilities of Large Language Models to
infer alignments of entities. LLM-Align uses heuristic methods to select
important attributes and relations of entities, and then feeds the selected
triples of entities to an LLM to infer the alignment results. To guarantee the
quality of alignment results, we design a multi-round voting mechanism to
mitigate the hallucination and positional bias issues that occur with LLMs.
Experiments on three EA datasets, demonstrating that our approach achieves
state-of-the-art performance compared to existing EA methods.

æè¦ï¼å¯¦é«å°é½ (EA) æ¨å¨è­å¥åå¹éä¸åç¥è­åè­ (KG) ä¸­å°æçå¯¦é«ï¼å¨ç¥è­èååæ´åä¸­æ®æ¼èè³ééè¦çè§è²ãåºæ¼åµå¥çå¯¦é«å°é½ (EA) è¿ä¾ååéæ³¨ï¼é²èå¬çåºè¨±å¤åµæ°çæ¹æ³ãæåï¼éäºæ¹æ³å°æ³¨æ¼æ ¹æç¥è­åè­ (KG) ççµæ§ç¹å¾µä¾å­¸ç¿å¯¦é«åµå¥ï¼éäºç¹å¾µç±éä¿ä¸åçµå®ç¾©ãå¾çºæ¹æ³å°å¯¦é«åç¨±åå±¬æ§æ´åçºè£åè³è¨ï¼ä»¥æ¹åç¨æ¼ EA çåµå¥ãç¶èï¼ç¾ææ¹æ³ç¼ºä¹å°å¯¦é«å±¬æ§åéä¿çæ·±å¥èªç¾©çè§£ãå¨æ¬æä¸­ï¼æåæåºäºä¸ç¨®åºæ¼å¤§åèªè¨æ¨¡å (LLM) çå¯¦é«å°é½æ¹æ³ LLM-Alignï¼è©²æ¹æ³æ¢ç´¢äºå¤§åèªè¨æ¨¡åçéµå¾ªæä»¤åé¶æ¬¡å­¸ç¿è½åï¼ä»¥æ¨è«å¯¦é«å°é½ãLLM-Align ä½¿ç¨åç¼å¼æ¹æ³ä¾é¸æå¯¦é«çéè¦å±¬æ§åéä¿ï¼ç¶å¾å°å¯¦é«çé¸å®ä¸åçµé¥å¥ LLM ä»¥æ¨è«å°é½çµæãçºäºä¿è­å°é½çµæçåè³ªï¼æåè¨­è¨äºä¸åå¤è¼ªæç¥¨æ©å¶ï¼ä»¥æ¸è¼ LLM ä¸­åºç¾çå¹»è¦ºåä½ç½®åå·®åé¡ãå¨ä¸å EA è³æéä¸çå¯¦é©è¡¨æï¼èç¾æç EA æ¹æ³ç¸æ¯ï¼æåçåæ³éå°äºæåé²çæè½ã

##### **Retrieval-Augmented Machine Translation with Unstructured Knowledge**
2412.04342v1 by Jiaan Wang, Fandong Meng, Yingxue Zhang, Jie Zhou

Retrieval-augmented generation (RAG) introduces additional information to
enhance large language models (LLMs). In machine translation (MT), previous
work typically retrieves in-context examples from paired MT corpora, or
domain-specific knowledge from knowledge graphs, to enhance models' MT ability.
However, a large amount of world knowledge is organized in unstructured
documents, and might not be fully paired across different languages. In this
paper, we study retrieval-augmented MT using unstructured documents.
Specifically, we build RAGtrans, the first benchmark to train and evaluate
LLMs' retrieval-augmented MT ability. RAGtrans contains 79K MT samples
collected via GPT-4o and human translators. Besides, documents from different
languages are also provided to supply the knowledge to these samples. Based on
RAGtrans, we further propose a multi-task training method to teach LLMs how to
use information from multilingual documents during their translation. The
method uses existing multilingual corpora to create auxiliary training
objectives without additional labeling requirements. Extensive experiments show
that the method improves LLMs by 1.58-3.09 BLEU and 1.00-2.03 COMET scores.

æè¦ï¼æª¢ç´¢å¢å¼·ç¢ç (RAG) æå¼å¥é¡å¤è³è¨ï¼ä»¥å¢å¼·å¤§åèªè¨æ¨¡å (LLM)ãå¨æ©å¨ç¿»è­¯ (MT) ä¸­ï¼ååçä½æ¥­éå¸¸æå¾éå°ç MT èªæåº«ä¸­æª¢ç´¢æå¢ç¯ä¾ï¼æå¾ç¥è­åè¡¨ä¸­æª¢ç´¢ç¹å®é åçç¥è­ï¼ä»¥å¢å¼·æ¨¡åç MT è½åãç¶èï¼å¤§éçä¸çç¥è­é½æ¯ä»¥éçµæ§åæä»¶çµç¹ï¼èä¸å¯è½ç¡æ³å®å¨éå°å°ä¸åçèªè¨ä¸­ãå¨æ¬æä¸­ï¼æåç ç©¶ä½¿ç¨éçµæ§åæä»¶é²è¡æª¢ç´¢å¢å¼· MTãå·é«ä¾èªªï¼æåå»ºç«äº RAGtransï¼éæ¯ç¬¬ä¸åç¨æ¼è¨ç·´åè©ä¼° LLM çæª¢ç´¢å¢å¼· MT è½åçåºæºãRAGtrans åå«éé GPT-4o åäººå·¥ç¿»è­¯äººå¡æ¶éç 79K å MT ç¯ä¾ãæ­¤å¤ï¼ä¹æä¾äºä¸åèªè¨çæä»¶ï¼ä»¥æä¾éäºç¯ä¾çç¥è­ãæ ¹æ RAGtransï¼æåé²ä¸æ­¥æåºäºä¸åå¤ä»»åè¨ç·´æ¹æ³ï¼ä»¥æå° LLM å¦ä½å¨ç¿»è­¯éç¨ä¸­ä½¿ç¨å¤èªè¨æä»¶çè³è¨ãè©²æ¹æ³ä½¿ç¨ç¾æçå¤èªè¨èªæåº«å»ºç«è¼å©è¨ç·´ç®æ¨ï¼èç¡éé¡å¤çæ¨è¨éæ±ãå»£æ³çå¯¦é©é¡¯ç¤ºï¼è©²æ¹æ³å° LLM ç BLEU åæ¸æé«äº 1.58-3.09ï¼COMET åæ¸æé«äº 1.00-2.03ã

##### **GRAF: Graph Retrieval Augmented by Facts for Legal Question Answering**
2412.04119v1 by Cristian-George CrÄciun, RÄzvan-Alexandru SmÄdu, Dumitru-Clementin Cercel, Mihaela-Claudia Cercel

Pre-trained Language Models (PLMs) have shown remarkable performances in
recent years, setting a new paradigm for NLP research and industry. The legal
domain has received some attention from the NLP community partly due to its
textual nature. Some tasks from this domain are represented by
question-answering (QA) tasks. This work explores the legal domain
Multiple-Choice QA (MCQA) for a low-resource language. The contribution of this
work is multi-fold. We first introduce JuRO, the first openly available
Romanian legal MCQA dataset, comprising three different examinations and a
number of 10,836 total questions. Along with this dataset, we introduce CROL,
an organized corpus of laws that has a total of 93 distinct documents with
their modifications from 763 time spans, that we leveraged in this work for
Information Retrieval (IR) techniques. Moreover, we are the first to propose
Law-RoG, a Knowledge Graph (KG) for the Romanian language, and this KG is
derived from the aforementioned corpus. Lastly, we propose a novel approach for
MCQA, Graph Retrieval Augmented by Facts (GRAF), which achieves competitive
results with generally accepted SOTA methods and even exceeds them in most
settings.

æè¦ï¼<paragraph>é è¨ç·´èªè¨æ¨¡å (PLM) å¨è¿å¹´ä¾å±ç¾åºåè¶çæè½ï¼çºèªç¶èªè¨èççç ç©¶åç¢æ¥­æ¨¹ç«äºæ°çå¸ç¯ãæ³å¾é åå çºå¶ææ¬æ§è³ªèåå°èªç¶èªè¨èçç¤¾ç¾¤çé¨åéæ³¨ãæ­¤é åä¸­çä¸äºä»»åç±åç­ (QA) ä»»åè¡¨ç¤ºãéé å·¥ä½æ¢ç´¢äºä½è³æºèªè¨çæ³å¾é åå¤éé¸æåç­ (MCQA)ãéé å·¥ä½çè²¢ç»æ¯å¤æ¹é¢çãæåé¦åä»ç´¹ JuROï¼éæ¯ç¬¬ä¸åå¬éçç¾é¦¬å°¼äºæ³å¾ MCQA è³æéï¼åå«ä¸æ¬¡ä¸åçèè©¦åç¸½å± 10,836 ååé¡ãé¤äºéåè³æéä¹å¤ï¼æåéä»ç´¹äº CROLï¼éæ¯ä¸åæçµç¹çæ³å¾èªæåº«ï¼ç¸½å±æ 93 åä¸åçæä»¶ï¼åå«äºä¾èª 763 åæéåéçä¿®æ¹ï¼æåå¨éåå·¥ä½ä¸­å©ç¨å®ä¾é²è¡è³è¨æª¢ç´¢ (IR) æè¡ãæ­¤å¤ï¼æåæ¯ç¬¬ä¸åæåº Law-RoG çäººï¼éæ¯ä¸åç¾é¦¬å°¼äºèªçç¥è­åè­ (KG)ï¼èéå KG æ¯å¾ä¸è¿°èªæåº«è¡ççãæå¾ï¼æåæåºäºä¸åæ°çå¤éé¸æåç­æ¹æ³ï¼ç±äºå¯¦å¢å¼·çåå½¢æª¢ç´¢ (GRAF)ï¼å®å¨ä¸è¬å¬èªç SOTA æ¹æ³ä¸­ç²å¾äºæç«¶ç­åççµæï¼çè³å¨å¤§å¤æ¸è¨­å®ä¸­é½è¶è¶äºå®åã</paragraph>

##### **MIND: Effective Incorrect Assignment Detection through a Multi-Modal Structure-Enhanced Language Model**
2412.03930v1 by Yunhe Pang, Bo Chen, Fanjin Zhang, Yanghui Rao, Jie Tang

The rapid growth of academic publications has exacerbated the issue of author
name ambiguity in online digital libraries. Despite advances in name
disambiguation algorithms, cumulative errors continue to undermine the
reliability of academic systems. It is estimated that over 10% paper-author
assignments are rectified when constructing the million-scale WhoIsWho
benchmark. Existing endeavors to detect incorrect assignments are either
semantic-based or graph-based approaches, which fall short of making full use
of the rich text attributes of papers and implicit structural features defined
via the co-occurrence of paper attributes. To this end, this paper introduces a
structure-enhanced language model that combines key structural features from
graph-based methods with fine-grained semantic features from rich paper
attributes to detect incorrect assignments. The proposed model is trained with
a highly effective multi-modal multi-turn instruction tuning framework, which
incorporates task-guided instruction tuning, text-attribute modality, and
structural modality. Experimental results demonstrate that our model
outperforms previous approaches, achieving top performance on the leaderboard
of KDD Cup 2024. Our code has been publicly available.

æè¦ï¼å­¸è¡åºçåçå¿«éæé·ï¼å åäºç·ä¸æ¸ä½åæ¸é¤¨ä¸­ä½èå§åæ­§ç¾©çåé¡ãåç®¡å§åæ¶æ­§æ¼ç®æ³æé²å±ï¼ç´¯ç©çé¯èª¤ä»æçºç ´å£å­¸è¡ç³»çµ±çå¯é æ§ãæä¼°è¨ï¼å¨å»ºæ§ç¾è¬è¦æ¨¡ç WhoIsWho åºæºæï¼è¶é 10% çè«æä½èææ´¾è¢«ä¿®æ­£ãç¾æçåµæ¸¬ä¸æ­£ç¢ºææ´¾çåªåï¼ä¸æ¯åºæ¼èªæçï¼å°±æ¯åºæ¼åçï¼ç¡æ³ååå©ç¨è«æè±å¯çæå­å±¬æ§åééè«æå±¬æ§å±ç¾å®ç¾©çé±å«çµæ§ç¹å¾µãçºæ­¤ï¼æ¬æä»ç´¹äºä¸åçµæ§å¢å¼·èªè¨æ¨¡åï¼å°åºæ¼åçæ¹æ³ä¸­çééµçµæ§ç¹å¾µèè±å¯è«æå±¬æ§ä¸­çç´°ç²åº¦èªç¾©ç¹å¾µç¸çµåï¼ä»¥åµæ¸¬ä¸æ­£ç¢ºçææ´¾ãææåºçæ¨¡åä½¿ç¨ä¸åé«æçå¤æ¨¡æå¤è¼ªæä»¤å¾®èª¿æ¶æ§é²è¡è¨ç·´ï¼å¶ä¸­åå«ä»»åå°åçæä»¤å¾®èª¿ãæå­å±¬æ§æ¨¡æåçµæ§æ¨¡æãå¯¦é©çµæè­æï¼æåçæ¨¡ååªæ¼ååçæ¨¡åï¼å¨ KDD Cup 2024 çæè¡æ¦ä¸åå¾æä½³æè½ãæåçç¨å¼ç¢¼å·²å¬éã

##### **How Good is ChatGPT in Giving Adaptive Guidance Using Knowledge Graphs in E-Learning Environments?**
2412.03856v1 by Patrick Ocheja, Brendan Flanagan, Yiling Dai, Hiroaki Ogata

E-learning environments are increasingly harnessing large language models
(LLMs) like GPT-3.5 and GPT-4 for tailored educational support. This study
introduces an approach that integrates dynamic knowledge graphs with LLMs to
offer nuanced student assistance. By evaluating past and ongoing student
interactions, the system identifies and appends the most salient learning
context to prompts directed at the LLM. Central to this method is the knowledge
graph's role in assessing a student's comprehension of topic prerequisites.
Depending on the categorized understanding (good, average, or poor), the LLM
adjusts its guidance, offering advanced assistance, foundational reviews, or
in-depth prerequisite explanations, respectively. Preliminary findings suggest
students could benefit from this tiered support, achieving enhanced
comprehension and improved task outcomes. However, several issues related to
potential errors arising from LLMs were identified, which can potentially
mislead students. This highlights the need for human intervention to mitigate
these risks. This research aims to advance AI-driven personalized learning
while acknowledging the limitations and potential pitfalls, thus guiding future
research in technology and data-driven education.

æè¦ï¼é»å­å­¸ç¿ç°å¢æ­£æ¥çå©ç¨å¤§åèªè¨æ¨¡å (LLM)ï¼ä¾å¦ GPT-3.5 å GPT-4ï¼æä¾éèº«æé çæè²æ¯æ´ãæ¬ç ç©¶æåºäºä¸ç¨®æ¹æ³ï¼å°åæç¥è­åè LLM æ´åï¼æä¾ç´°ç·»å¥å¾®çå­¸çåå©ãç³»çµ±æè©ä¼°éå»åæ­£å¨é²è¡çå­¸çäºåï¼æ¾åºä¸¦éå æé¡¯èçå­¸ç¿èçµ¡ï¼ä»¥æç¤º LLMãæ­¤æ¹æ³çæ ¸å¿å¨æ¼ç¥è­åå¨è©ä¼°å­¸çå°ä¸»é¡ååç¥è­ççè§£ç¨åº¦æ¹é¢ææ®æ¼çè§è²ãLLM ææ ¹æåé¡å¾ççè§£ç¨åº¦ï¼è¯å¥½ãæ®éæå·®ï¼èª¿æ´å¶æå°ï¼åå¥æä¾é²éåå©ãåºç¤åé¡§ææ·±å¥çååç¥è­èªªæãåæ­¥ç¼ç¾è¡¨æï¼å­¸çå¯ä»¥åçæ¼éç¨®åå±¤æ¯æ´ï¼éå°å¢å¼·ççè§£ååæ¹åçä»»åææãç¶èï¼å·²æ¾åºè LLM ç¢ççæ½å¨é¯èª¤ç¸éçå¹¾ååé¡ï¼éäºé¯èª¤å¯è½æèª¤å°å­¸çãéçªé¡¯äºäººé¡ä»å¥ä»¥éä½éäºé¢¨éªçå¿è¦æ§ãæ¬ç ç©¶æ¨å¨æ¨é² AI é©åçåäººåå­¸ç¿ï¼åææ¿èªéå¶åæ½å¨çé·é±ï¼å¾èæå°æªä¾å¨æè¡åè³æé©åæè²æ¹é¢çç ç©¶ã

##### **Synergizing LLMs and Knowledge Graphs: A Novel Approach to Software Repository-Related Question Answering**
2412.03815v1 by Samuel Abedu, SayedHassan Khatoonabadi, Emad Shihab

Software repositories contain valuable information for gaining insights into
their development process. However, extracting insights from these repository
data is time-consuming and requires technical expertise. While software
engineering chatbots have been developed to facilitate natural language
interactions with repositories, they struggle with understanding natural
language and accurately retrieving relevant data. This study aims to improve
the accuracy of LLM-based chatbots in answering repository-related questions by
augmenting them with knowledge graphs. We achieve this in a two-step approach;
(1) constructing a knowledge graph from the repository data and (2) synergizing
the knowledge graph with LLM to allow for the natural language questions and
answers. We curated a set of 20 questions with different complexities and
evaluated our approach on five popular open-source projects. Our approach
achieved an accuracy of 65%. We further investigated the limitations and
identified six key issues, with the majority relating to the reasoning
capability of the LLM. We experimented with a few-shot chain-of-thought
prompting to determine if it could enhance our approach. This technique
improved the overall accuracy to 84%. Our findings demonstrate the synergy
between LLMs and knowledge graphs as a viable solution for making repository
data accessible to both technical and non-technical stakeholders.

æè¦ï¼è»é«å²å­åº«åå«æå¹å¼çè³è¨ï¼å¯æ·±å¥äºè§£å¶éç¼æµç¨ãç¶èï¼å¾éäºå²å­åº«è³æä¸­æ·åè¦è§£æ¢èæåéè¦æè¡å°æ¥­ç¥è­ãåç®¡å·²éç¼åºè»é«å·¥ç¨èå¤©æ©å¨äººä¾ä¿é²èå²å­åº«çèªç¶èªè¨äºåï¼ä½å®åå¨çè§£èªç¶èªè¨åæºç¢ºæ·åç¸éè³ææ¹é¢ä»æå°é£ãæ¬ç ç©¶æ¨å¨ééç¥è­åè­æ´å LLM åºç¤èå¤©æ©å¨äººï¼ä»¥æé«å¶åç­å²å­åº«ç¸éåé¡çæºç¢ºæ§ãæåæ¡ç¨å©æ­¥é©æ¹æ³ä¾éææ­¤ç®æ¨ï¼(1) å¾å²å­åº«è³æå»ºæ§ç¥è­åè­ï¼ä»¥å (2) å°ç¥è­åè­è LLM çµåï¼ä»¥åè¨±èªç¶èªè¨åé¡åç­æ¡ãæåç­åäºä¸çµ 20 åå·æä¸åè¤éåº¦çåé¡ï¼ä¸¦éå°äºåç±éçéæºå°æ¡è©ä¼°æåçåæ³ãæåçåæ³éå°äº 65% çæºç¢ºåº¦ãæåé²ä¸æ­¥æ¢è¨äºéå¶ï¼ä¸¦æ¾åºå­åééµåé¡ï¼å¶ä¸­å¤§é¨åè LLM çæ¨çè½åæéãæåå¯¦é©äºå°æ¬¡æ¸çæèéæç¤ºï¼ä»¥ç¢ºå®å®æ¯å¦å¯ä»¥å¢å¼·æåçåæ³ãæ­¤æè¡å°æ´é«æºç¢ºåº¦æé«å° 84%ãæåçç ç©¶çµæè­æäº LLM åç¥è­åè­ä¹éçååææï¼ä½çºè®æè¡åéæè¡å©å®³éä¿äººè½å¤ å­åå²å­åº«è³æçå¯è¡è§£æ±ºæ¹æ¡ã

##### **Agent AI with LangGraph: A Modular Framework for Enhancing Machine Translation Using Large Language Models**
2412.03801v1 by Jialin Wang, Zhihua Duan

This paper explores the transformative role of Agent AI and LangGraph in
advancing the automation and effectiveness of machine translation (MT). Agents
are modular components designed to perform specific tasks, such as translating
between particular languages, with specializations like TranslateEnAgent,
TranslateFrenchAgent, and TranslateJpAgent for English, French, and Japanese
translations, respectively. These agents leverage the powerful semantic
capabilities of large language models (LLMs), such as GPT-4o, to ensure
accurate, contextually relevant translations while maintaining modularity,
scalability, and context retention.
  LangGraph, a graph-based framework built on LangChain, simplifies the
creation and management of these agents and their workflows. It supports
dynamic state management, enabling agents to maintain dialogue context and
automates complex workflows by linking agents and facilitating their
collaboration. With flexibility, open-source community support, and seamless
integration with LLMs, LangGraph empowers agents to deliver high-quality
translations.
  Together, Agent AI and LangGraph create a cohesive system where LangGraph
orchestrates agent interactions, ensuring that user inputs are analyzed,
routed, and processed efficiently. Experimental results demonstrate the
potential of this system to enhance multilingual translation accuracy and
scalability. By highlighting modular design and automated workflows, this paper
sets the stage for further innovations in intelligent machine translation
services.

æè¦ï¼æ¬ææ¢è¨äº Agent AI å LangGraph å¨æ¨åæ©å¨ç¿»è­¯ (MT) çèªåååæçæ¹é¢çè®é©æ§ä½ç¨ãAgent æ¯æ¨¡çµååä»¶ï¼æ¨å¨å·è¡ç¹å®ä»»åï¼ä¾å¦å¨ç¹å®èªè¨ä¹éç¿»è­¯ï¼ä¸¦å·æå°éé åï¼ä¾å¦ TranslateEnAgentãTranslateFrenchAgent å TranslateJpAgent åå¥ç¨æ¼è±æãæ³æåæ¥æçç¿»è­¯ãéäº Agent éç¨å¤§åèªè¨æ¨¡å (LLM) çå¼·å¤§èªç¾©åè½ï¼ä¾å¦ GPT-4oï¼ä»¥ç¢ºä¿æºç¢ºãèä¸ä¸æç¸éçç¿»è­¯ï¼åæä¿ææ¨¡çµåãå¯æ´åæ§åä¸ä¸æä¿çã
LangGraph æ¯å»ºæ§æ¼ LangChain ä¸çåå½¢åæ¡æ¶ï¼ç°¡åäºéäº Agent åå¶å·¥ä½æµç¨çå»ºç«åç®¡çãå®æ¯æ´åæçæç®¡çï¼è® Agent è½å¤ ç¶­è­·å°è©±å§å®¹ï¼ä¸¦ééé£çµ Agent åä¿é²å¶åä½ï¼èªååè¤éçå·¥ä½æµç¨ãLangGraph å·æéæ´»æ§ãéæ¾åå§ç¢¼ç¤¾ç¾¤æ¯æ´åè LLM ç¡ç¸«æ´åç­åªé»ï¼è® Agent è½å¤ æä¾é«åè³ªçç¿»è­¯ã
Agent AI å LangGraph å±åå»ºç«äºä¸åç·å¯çç³»çµ±ï¼å¶ä¸­ LangGraph ç·¨æ Agent äºåï¼ç¢ºä¿ä½¿ç¨èè¼¸å¥è¢«ææå°åæãè·¯ç±åèçãå¯¦é©çµæè­æäºéåç³»çµ±å¨æåå¤èªè¨ç¿»è­¯æºç¢ºæ§åå¯æ´åæ§æ¹é¢çæ½åãééå¼·èª¿æ¨¡çµåè¨­è¨åèªååå·¥ä½æµç¨ï¼æ¬æçºæºæ§åæ©å¨ç¿»è­¯æåçé²ä¸æ­¥åµæ°å¥ å®äºåºç¤ã

##### **Language Model Meets Prototypes: Towards Interpretable Text Classification Models through Prototypical Networks**
2412.03761v1 by Ximing Wen

Pretrained transformer-based Language Models (LMs) are well-known for their
ability to achieve significant improvement on NLP tasks, but their black-box
nature, which leads to a lack of interpretability, has been a major concern. My
dissertation focuses on developing intrinsically interpretable models when
using LMs as encoders while maintaining their superior performance via
prototypical networks. I initiated my research by investigating enhancements in
performance for interpretable models of sarcasm detection. My proposed approach
focuses on capturing sentiment incongruity to enhance accuracy while offering
instance-based explanations for the classification decisions. Later, I
developed a novel white-box multi-head graph attention-based prototype network
designed to explain the decisions of text classification models without
sacrificing the accuracy of the original black-box LMs. In addition, I am
working on extending the attention-based prototype network with contrastive
learning to redesign an interpretable graph neural network, aiming to enhance
both the interpretability and performance of the model in document
classification.

æè¦ï¼é åè¨ç·´å¥½çåºæ¼ Transformer çèªè¨æ¨¡å (LM) ä»¥å¶å¨ NLP ä»»åä¸­åå¾é¡¯èé²æ­¥çè½åèèåï¼ä½å®åçé»çæ§è³ªå°è´ç¼ºä¹å¯è§£éæ§ï¼ä¸ç´æ¯ä¸åä¸»è¦åé¡ãæçè«æéé»å¨æ¼å¨ä½¿ç¨ LM ä½çºç·¨ç¢¼å¨æéç¼å§å¨å¯è§£éçæ¨¡åï¼åæééååç¶²è·¯ç¶­æå¶åªç°çæè½ãæééç ç©¶è«·åºåµæ¸¬çå¯è§£éæ¨¡åçæè½æåä¾ååæçç ç©¶ãææåºçæ¹æ³å°æ³¨æ¼æææç·ä¸ä¸è´æ§ï¼ä»¥æé«æºç¢ºåº¦ï¼åæçºåé¡æ±ºç­æä¾åºæ¼å¯¦ä¾çè§£éãå¾ä¾ï¼æéç¼äºä¸åæ°ç©çç½çå¤é ­åå½¢æ³¨æåååç¶²è·¯ï¼æ¨å¨è§£éæå­åé¡æ¨¡åçæ±ºç­ï¼èä¸æç§ç²åå§é»ç LM çæºç¢ºåº¦ãæ­¤å¤ï¼ææ­£å¨åªåå°åºæ¼æ³¨æåçååç¶²è·¯èå°æ¯å­¸ç¿æ´å±ï¼ä»¥éæ°è¨­è¨ä¸åå¯è§£éçåå½¢ç¥ç¶ç¶²è·¯ï¼æ¨å¨å¢å¼·æ¨¡åå¨æä»¶åé¡ä¸­çå¯è§£éæ§åæè½ã

##### **How to Correctly do Semantic Backpropagation on Language-based Agentic Systems**
2412.03624v1 by Wenyi Wang, Hisham A. Alyahya, Dylan R. Ashley, Oleg Serikov, Dmitrii Khizbullin, Francesco Faccio, JÃ¼rgen Schmidhuber

Language-based agentic systems have shown great promise in recent years,
transitioning from solving small-scale research problems to being deployed in
challenging real-world tasks. However, optimizing these systems often requires
substantial manual labor. Recent studies have demonstrated that these systems
can be represented as computational graphs, enabling automatic optimization.
Despite these advancements, most current efforts in Graph-based Agentic System
Optimization (GASO) fail to properly assign feedback to the system's components
given feedback on the system's output. To address this challenge, we formalize
the concept of semantic backpropagation with semantic gradients -- a
generalization that aligns several key optimization techniques, including
reverse-mode automatic differentiation and the more recent TextGrad by
exploiting the relationship among nodes with a common successor. This serves as
a method for computing directional information about how changes to each
component of an agentic system might improve the system's output. To use these
gradients, we propose a method called semantic gradient descent which enables
us to solve GASO effectively. Our results on both BIG-Bench Hard and GSM8K show
that our approach outperforms existing state-of-the-art methods for solving
GASO problems. A detailed ablation study on the LIAR dataset demonstrates the
parsimonious nature of our method. A full copy of our implementation is
publicly available at https://github.com/HishamAlyahya/semantic_backprop

æè¦ï¼<paragraph>è¿å¹´ä¾ï¼åºæ¼èªè¨çä»£çç³»çµ±å±ç¾äºæ¥µå¤§çåæ¯ï¼
å¾è§£æ±ºå°è¦æ¨¡çç ç©¶åé¡ï¼è½è®çºé¨ç½²å¨
å·æææ°æ§ççå¯¦ä¸çä»»åä¸­ãç¶èï¼æä½³åéäºç³»çµ±éå¸¸éè¦
å¤§éçäººå·¥ååãæè¿çç ç©¶è¡¨æï¼éäºç³»çµ±
å¯ä»¥è¡¨ç¤ºçºè¨ç®åï¼å¯¦ç¾èªåæä½³åã
åç®¡æéäºé²å±ï¼ä½ç®åå¤§å¤æ¸åºæ¼åå½¢çä»£çç³»çµ±
æä½³å (GASO) çåªåï¼é½ç¡æ³é©ç¶å°å°åé¥åéçµ¦ç³»çµ±ççµæé¨å
çµ¦äºç³»çµ±è¼¸åºçåé¥ãçºäºæå°éä¸ææ°ï¼æåæ­£å¼åäº
èªç¾©ååå³æ­çæ¦å¿µï¼ä¸¦å¸¶æèªç¾©æ¢¯åº¦ââä¸ç¨®
æ¦æ¬ï¼å®çµåäºå¹¾ç¨®ééµçæä½³åæè¡ï¼åæ¬
ååæ¨¡å¼èªåå¾®ååæè¿ç TextGradï¼å©ç¨å·æå±åå¾ç¹¼èçç¯é»ä¹éçéä¿ãéå¯ä»¥ç¨ä½
ä¸ç¨®è¨ç®æ¹åè³è¨çæ¹æ³ï¼èªªæå¦ä½æ¹è®ä»£çç³»çµ±çæ¯å
çµæé¨åå¯è½ææ¹åç³»çµ±çè¼¸åºãçºäºä½¿ç¨éäº
æ¢¯åº¦ï¼æåæåºäºä¸ç¨®ç¨±çºèªç¾©æ¢¯åº¦ä¸éçæ¹æ³ï¼ä½¿æåè½å¤ 
ææå°è§£æ±º GASOãæåå¨ BIG-Bench Hard å GSM8K ä¸ççµæè¡¨æ
æåçåæ³åªæ¼è§£æ±º
GASO åé¡çç¾ææåé²æ¹æ³ãå¨ LIAR è³æéä¸é²è¡çè©³ç´°æ¶èç ç©¶è­æäº
æåæ¹æ³çç°¡ç´æ§ãæåçå¯¦ä½çå®æ´å¯æ¬å¬éæ¼ https://github.com/HishamAlyahya/semantic_backprop</paragraph>

##### **Enhancing Supply Chain Visibility with Generative AI: An Exploratory Case Study on Relationship Prediction in Knowledge Graphs**
2412.03390v1 by Ge Zheng, Alexandra Brintrup

A key stumbling block in effective supply chain risk management for companies
and policymakers is a lack of visibility on interdependent supply network
relationships. Relationship prediction, also called link prediction is an
emergent area of supply chain surveillance research that aims to increase the
visibility of supply chains using data-driven techniques. Existing methods have
been successful for predicting relationships but struggle to extract the
context in which these relationships are embedded - such as the products being
supplied or locations they are supplied from. Lack of context prevents
practitioners from distinguishing transactional relations from established
supply chain relations, hindering accurate estimations of risk. In this work,
we develop a new Generative Artificial Intelligence (Gen AI) enhanced machine
learning framework that leverages pre-trained language models as embedding
models combined with machine learning models to predict supply chain
relationships within knowledge graphs. By integrating Generative AI techniques,
our approach captures the nuanced semantic relationships between entities,
thereby improving supply chain visibility and facilitating more precise risk
management. Using data from a real case study, we show that GenAI-enhanced link
prediction surpasses all benchmarks, and demonstrate how GenAI models can be
explored and effectively used in supply chain risk management.

æè¦ï¼ä¾æéé¢¨éªç®¡çä¸­çä¸åééµéç¤å¨æ¼ä¼æ¥­åæ¿ç­å¶å®èç¼ºä¹å°ç¸äºä¾å­ä¾æç¶²è·¯éä¿çè½è¦åº¦ãéä¿é æ¸¬ï¼ä¹ç¨±çºé£çµé æ¸¬ï¼æ¯ä¾æéç£æ§ç ç©¶ä¸­ä¸åæ°èé åï¼æ¨å¨ä½¿ç¨è³æé©åæè¡æé«ä¾æéçè½è¦åº¦ãç¾ææ¹æ³å·²æåé æ¸¬éä¿ï¼ä½é£ä»¥æåéäºéä¿æåµå¥çèæ¯ï¼ä¾å¦æä¾æçç¢åæä¾æå°é»ãç¼ºä¹èæ¯æå¦¨ç¤å¾æ¥­èååäº¤æéä¿åæ¢å®çä¾æééä¿ï¼é²èé»ç¤é¢¨éªçæºç¢ºè©ä¼°ãå¨éé å·¥ä½ä¸­ï¼æåéç¼äºä¸åæ°ççæå¼äººå·¥æºæ§ (Gen AI) å¢å¼·æ©å¨å­¸ç¿æ¶æ§ï¼å®å©ç¨é åè¨ç·´çèªè¨æ¨¡åä½çºåµå¥æ¨¡åï¼ä¸¦çµåæ©å¨å­¸ç¿æ¨¡åä¾é æ¸¬ç¥è­åè­ä¸­çä¾æééä¿ãééæ´åçæå¼ AI æè¡ï¼æåçåæ³ææå°å¯¦é«ä¹éç´°å¾®çèªç¾©éä¿ï¼å¾èæé«ä¾æéè½è¦åº¦ä¸¦ä¿é²æ´ç²¾ç¢ºçé¢¨éªç®¡çãä½¿ç¨ä¾èªçå¯¦æ¡ä¾ç ç©¶çè³æï¼æåè­æ GenAI å¢å¼·é£çµé æ¸¬åªæ¼ææåºæºï¼ä¸¦å±ç¤ºå¦ä½æ¢ç´¢åææå°å¨ä¾æéé¢¨éªç®¡çä¸­ä½¿ç¨ GenAI æ¨¡åã

##### **CBEval: A framework for evaluating and interpreting cognitive biases in LLMs**
2412.03605v1 by Ammar Shaikh, Raj Abhijit Dandekar, Sreedath Panat, Rajat Dandekar

Rapid advancements in Large Language models (LLMs) has significantly enhanced
their reasoning capabilities. Despite improved performance on benchmarks, LLMs
exhibit notable gaps in their cognitive processes. Additionally, as reflections
of human-generated data, these models have the potential to inherit cognitive
biases, raising concerns about their reasoning and decision making
capabilities. In this paper we present a framework to interpret, understand and
provide insights into a host of cognitive biases in LLMs. Conducting our
research on frontier language models we're able to elucidate reasoning
limitations and biases, and provide reasoning behind these biases by
constructing influence graphs that identify phrases and words most responsible
for biases manifested in LLMs. We further investigate biases such as round
number bias and cognitive bias barrier revealed when noting framing effect in
language models.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) çå¿«éé²æ­¥é¡¯èå¢å¼·äºå®åçæ¨çè½åãåç®¡å¨åºæºæ¸¬è©¦ä¸­çè¡¨ç¾æææåï¼ä½ LLM å¨å¶èªç¥éç¨ä¸­ä»å­å¨é¡¯èçå·®è·ãæ­¤å¤ï¼ä½çºäººé¡çææ¸æçåæ ï¼éäºæ¨¡åæå¯è½ç¹¼æ¿èªç¥åå·®ï¼å¼ç¼äººåå°å¶æ¨çåæ±ºç­è½åçææãå¨æ¬æä¸­ï¼æåæåºäºä¸åæ¡æ¶ä¾è§£éãçè§£åæ´å¯ LLM ä¸­çä¸ç³»åèªç¥åå·®ãééå°åæ²¿èªè¨æ¨¡åé²è¡ç ç©¶ï¼æåè½å¤ é¡ææ¨çéå¶ååå·®ï¼ä¸¦ééæ§å»ºå½±é¿åä¾æä¾éäºåå·®èå¾çæ¨çï¼éäºå½±é¿åè­å¥åºå° LLM ä¸­è¡¨ç¾åºçåå·®è² ææå¤§è²¬ä»»çç­èªåè©å½ãæåé²ä¸æ­¥ç ç©¶äºå¨èªè¨æ¨¡åä¸­è¨»ææ¡æ¶ææææ­ç¤ºçåå·®ï¼ä¾å¦åæ¨äºå¥åå·®åèªç¥åå·®éç¤ã

##### **Hybrid-SQuAD: Hybrid Scholarly Question Answering Dataset**
2412.02788v2 by Tilahun Abedissa Taffa, Debayan Banerjee, Yaregal Assabie, Ricardo Usbeck

Existing Scholarly Question Answering (QA) methods typically target
homogeneous data sources, relying solely on either text or Knowledge Graphs
(KGs). However, scholarly information often spans heterogeneous sources,
necessitating the development of QA systems that integrate information from
multiple heterogeneous data sources. To address this challenge, we introduce
Hybrid-SQuAD (Hybrid Scholarly Question Answering Dataset), a novel large-scale
QA dataset designed to facilitate answering questions incorporating both text
and KG facts. The dataset consists of 10.5K question-answer pairs generated by
a large language model, leveraging the KGs DBLP and SemOpenAlex alongside
corresponding text from Wikipedia. In addition, we propose a RAG-based baseline
hybrid QA model, achieving an exact match score of 69.65 on the Hybrid-SQuAD
test set.

æè¦ï¼ç¾æçå­¸è¡åé¡è§£ç­ (QA) æ¹æ³éå¸¸éå°åè³ªè³æä¾æºï¼åä¾è³´ææ¬æç¥è­åè­ (KG)ãç¶èï¼å­¸è¡è³è¨éå¸¸æ©«è·¨ç°è³ªä¾æºï¼å æ­¤æå¿è¦éç¼æ´åä¾èªå¤åç°è³ªè³æä¾æºè³è¨ç QA ç³»çµ±ãçºäºæå°æ­¤ææ°ï¼æåå¼å¥äº Hybrid-SQuADï¼æ··åå­¸è¡åé¡è§£ç­è³æéï¼ï¼éæ¯ä¸åæ°ç©çå¤§è¦æ¨¡ QA è³æéï¼æ¨å¨ä¿é²åç­åå«ææ¬å KG äºå¯¦çåé¡ãè©²è³æéåå« 10.5K ååé¡ç­æ¡å°ï¼ç±å¤§åèªè¨æ¨¡åçæï¼å©ç¨ KGs DBLP å SemOpenAlex ä»¥åä¾èªç¶­åºç¾ç§çå°æææ¬ãæ­¤å¤ï¼æåæåºäºåºæ¼ RAG çåºç·æ··å QA æ¨¡åï¼å¨ Hybrid-SQuAD æ¸¬è©¦éä¸­å¯¦ç¾äº 69.65 çå®å¨å¹éåæ¸ã

##### **Characterizing Information Shared by Participants to Coding Challenges: The Case of Advent of Code**
2412.02290v1 by Francesco Cauteruccio, Enrico Corradini, Luca Virgili

Advent of Code (AoC from now on) is a popular coding challenge requiring to
solve programming puzzles for a variety of skill sets and levels. AoC follows
the advent calendar, therefore it is an annual challenge that lasts for 25
days. AoC participants usually post their solutions on social networks and
discuss them online. These challenges are interesting to study since they could
highlight the adoption of new tools, the evolution of the developer community,
or the technological requirements of well-known companies. For these reasons,
we first create a dataset of the 2019-2021 AoC editions containing the
discussion threads made on the subreddit {\tt /r/adventofcode}. Then, we
propose a model based on stream graphs to best study this context, where we
represent its most important actors through time: participants, comments, and
programming languages. Thanks to our model, we investigate user participation,
adoption of new programming languages during a challenge and between two of
them, and resiliency of programming languages based on a Stack Overflow survey.
We find that the top-used programming languages are almost the same in the
three years, pointing out their importance. Moreover, participants tend to keep
the same programming language for the whole challenge, while the ones attending
two AoCs usually change it in the next one. Finally, we observe interesting
results about the programming languages that are ``Popular'' or ``Loved''
according to the Stack Overflow survey. Firstly, these are the ones adopted for
the longest time in an AoC edition, thanks to which users have a high chance of
reaching the end of the challenge. Secondly, they are the most chosen when a
participant decides to change programming language during the same challenge.

æè¦ï¼éè¨ç¯å¯ç¢¼ï¼ä»¥ä¸ç°¡ç¨± AoCï¼æ¯ä¸é æµè¡çç·¨ç¢¼ææ°ï¼éè¦è§£æ±ºåç¨®æè½çµåç­ç´çç¨å¼è¨­è¨è¬é¡ãAoC éµå¾ªéè¨æï¼å æ­¤æ¯ä¸é çºæ 25 å¤©çå¹´åº¦ææ°ãAoC åèèéå¸¸å¨ç¤¾ç¾¤ç¶²è·¯ä¸ç¼å¸ä»åçè§£æ±ºæ¹æ¡ï¼ä¸¦å¨ç¶²è·¯ä¸è¨è«å®åãéäºææ°å¾æè¶£ï¼å çºå®åå¯ä»¥çªé¡¯æ°å·¥å·çæ¡ç¨ãéç¼äººå¡ç¤¾ç¾¤çæ¼é²ï¼æç¥åå¬å¸çæè¡éæ±ãåºæ¼éäºåå ï¼æåé¦åå»ºç«ä¸ååå«å¨ subreddit {\tt /r/adventofcode} ä¸é²è¡è¨è«ä¸²ç 2019-2021 å¹´ AoC çæ¬è³æéãç¶å¾ï¼æåæåºä¸ååºæ¼ä¸²æµåçæ¨¡åä¾æä½³ç ç©¶æ­¤èæ¯ï¼å¶ä¸­æåé¨èæéåç¾å¶æéè¦çåèèï¼åèèãçè¨åç¨å¼èªè¨ãééæåçæ¨¡åï¼æåèª¿æ¥ä½¿ç¨èåèåº¦ãå¨ææ°æéåå©èä¹éæ¡ç¨æ°ç¨å¼èªè¨çææ³ï¼ä»¥åæ ¹æ Stack Overflow èª¿æ¥å°ç¨å¼èªè¨çå¾©ååãæåç¼ç¾ä¸å¹´ä¾æå¸¸ç¨çç¨å¼èªè¨å¹¾ä¹ç¸åï¼æåºäºå®åçéè¦æ§ãæ­¤å¤ï¼åèèå¾åæ¼å¨æ´åææ°ä¸­ä½¿ç¨ç¸åçç¨å¼èªè¨ï¼èåå å©å AoC çåèèéå¸¸æå¨ä¸ä¸å ´æ¯è³½ä¸­æ´æç¨å¼èªè¨ãæå¾ï¼æåè§å¯å°éæ¼æ ¹æ Stack Overflow èª¿æ¥è¢«æ­¸é¡çºãç±éãæãåæãçç¨å¼èªè¨çä¸äºæè¶£çµæãé¦åï¼éäºç¨å¼èªè¨æ¯ AoC çæ¬ä¸­æ¡ç¨æä¹çç¨å¼èªè¨ï¼å æ­¤ä½¿ç¨èæå¾é«çæ©æå®æææ°ãå¶æ¬¡ï¼ç¶åèèæ±ºå®å¨åä¸åææ°ä¸­æ´æ¹ç¨å¼èªè¨æï¼å®åæ¯æå¸¸è¢«é¸ç¨çç¨å¼èªè¨ã

##### **A Neurosymbolic Fast and Slow Architecture for Graph Coloring**
2412.01752v1 by Vedant Khandelwal, Vishal Pallagani, Biplav Srivastava, Francesca Rossi

Constraint Satisfaction Problems (CSPs) present significant challenges to
artificial intelligence due to their intricate constraints and the necessity
for precise solutions. Existing symbolic solvers are often slow, and prior
research has shown that Large Language Models (LLMs) alone struggle with CSPs
because of their complexity. To bridge this gap, we build upon the existing
SOFAI architecture (or SOFAI-v1), which adapts Daniel Kahneman's ''Thinking,
Fast and Slow'' cognitive model to AI. Our enhanced architecture, SOFAI-v2,
integrates refined metacognitive governance mechanisms to improve adaptability
across complex domains, specifically tailored for solving CSPs like graph
coloring. SOFAI-v2 combines a fast System 1 (S1) based on LLMs with a
deliberative System 2 (S2) governed by a metacognition module. S1's initial
solutions, often limited by non-adherence to constraints, are enhanced through
metacognitive governance, which provides targeted feedback and examples to
adapt S1 to CSP requirements. If S1 fails to solve the problem, metacognition
strategically invokes S2, ensuring accurate and reliable solutions. With
empirical results, we show that SOFAI-v2 for graph coloring problems achieves a
16.98% increased success rate and is 32.42% faster than symbolic solvers.

æè¦ï¼ç´ææ»¿è¶³åé¡ (CSP) å çºå¶è¤éçç´æåå°ç²¾ç¢ºè§£çå¿è¦æ§ï¼å°äººå·¥æºæ§æåºäºéå¤§çææ°ãç¾æçç¬¦èæ±è§£å¨éå¸¸å¾æ¢ï¼èååçç ç©¶è¡¨æï¼å¤§åèªè¨æ¨¡å (LLM) å çºå¶è¤éæ§èç¡æ³å®ç¨èç CSPãçºäºå½è£éåå·®è·ï¼æåå»ºç«å¨ç¾æç SOFAI æ¶æ§ï¼æ SOFAI-v1ï¼ä¹ä¸ï¼å®å° Daniel Kahneman çãå¿«ææ¢æ³ãèªç¥æ¨¡åèª¿æ´çº AIãæåå¢å¼·çæ¶æ§ SOFAI-v2 æ´åäºç²¾ç·»çåèªç¥æ²»çæ©å¶ï¼ä»¥æé«è·¨è¤éé åçé©ææ§ï¼ç¹å¥æ¯éå°è§£æ±ºåå½¢èè²ç­ CSP èéèº«æé ãSOFAI-v2 çµåäºåºæ¼ LLM çå¿«éç³»çµ± 1 (S1) åç±åèªç¥æ¨¡çµç®¡æ§çå¯©æç³»çµ± 2 (S2)ãS1 çåå§è§£æ³éå¸¸åå°ä¸éµå®ç´æçéå¶ï¼ééåèªç¥æ²»çå¾ä»¥å¢å¼·ï¼æä¾æéå°æ§çåé¥åç¯ä¾ï¼ä»¥é©æ S1 ç CSP éæ±ãå¦æ S1 ç¡æ³è§£æ±ºåé¡ï¼åèªç¥æç­ç¥æ§å°å¼å« S2ï¼ç¢ºä¿æºç¢ºä¸å¯é çè§£æ³ãééç¶é©çµæï¼æåå±ç¤ºäºç¨æ¼åå½¢èè²åé¡ç SOFAI-v2 éå°äºæåçæé« 16.98%ï¼ä¸¦ä¸æ¯ç¬¦èæ±è§£å¨å¿« 32.42%ã

##### **Intelligent Spark Agents: A Modular LangGraph Framework for Scalable, Visualized, and Enhanced Big Data Machine Learning Workflows**
2412.01490v4 by Jialin Wang, Zhihua Duan

This paper presents a Spark-based modular LangGraph framework, designed to
enhance machine learning workflows through scalability, visualization, and
intelligent process optimization. At its core, the framework introduces Agent
AI, a pivotal innovation that leverages Spark's distributed computing
capabilities and integrates with LangGraph for workflow orchestration.
  Agent AI facilitates the automation of data preprocessing, feature
engineering, and model evaluation while dynamically interacting with data
through Spark SQL and DataFrame agents. Through LangGraph's graph-structured
workflows, the agents execute complex tasks, adapt to new inputs, and provide
real-time feedback, ensuring seamless decision-making and execution in
distributed environments. This system simplifies machine learning processes by
allowing users to visually design workflows, which are then converted into
Spark-compatible code for high-performance execution.
  The framework also incorporates large language models through the LangChain
ecosystem, enhancing interaction with unstructured data and enabling advanced
data analysis. Experimental evaluations demonstrate significant improvements in
process efficiency and scalability, as well as accurate data-driven
decision-making in diverse application scenarios.
  This paper emphasizes the integration of Spark with intelligent agents and
graph-based workflows to redefine the development and execution of machine
learning tasks in big data environments, paving the way for scalable and
user-friendly AI solutions.

æè¦ï¼<paragraph>æ¬ææåºäºä¸ååºæ¼ Spark çæ¨¡çµå LangGraph æ¡æ¶ï¼æ¨å¨ééå¯æ´åæ§ãå¯è¦ååæºæ§æµç¨æä½³åä¾æåæ©å¨å­¸ç¿å·¥ä½æµç¨ãå¨æ ¸å¿é¨åï¼æ­¤æ¡æ¶å¼å¥äº Agent AIï¼éé ééµåµæ°å©ç¨äº Spark çåæ£å¼éç®è½åï¼ä¸¦è LangGraph æ´åä»¥é²è¡å·¥ä½æµç¨ç·¨æã
  Agent AI ä¿é²äºè³æåèçãç¹å¾µå·¥ç¨åæ¨¡åè©ä¼°çèªååï¼åæéé Spark SQL å DataFrame ä»£çèè³æåæäºåãéé LangGraph çåå½¢çµæ§å·¥ä½æµç¨ï¼éäºä»£çå·è¡è¤éçä»»åãé©ææ°çè¼¸å¥ï¼ä¸¦æä¾å³æåé¥ï¼ç¢ºä¿å¨åæ£å¼ç°å¢ä¸­é²è¡ç¡ç¸«æ±ºç­å¶å®åå·è¡ãæ­¤ç³»çµ±ééåè¨±ä½¿ç¨èè¦è¦ºåè¨­è¨å·¥ä½æµç¨ï¼å¶å¾è½æçºç¸å®¹æ¼ Spark çç¨å¼ç¢¼ä»¥é²è¡é«æ§è½å·è¡ï¼ä¾ç°¡åæ©å¨å­¸ç¿æµç¨ã
  æ­¤æ¡æ¶ä¹éé LangChain çæç³»æ´åäºå¤§åèªè¨æ¨¡åï¼å¢å¼·äºèéçµæ§åè³æçäºåï¼ä¸¦åç¨äºé²éè³æåæãå¯¦é©è©ä¼°é¡¯ç¤ºï¼æµç¨æçåå¯æ´åæ§æé¡¯èæ¹åï¼èä¸å¨ä¸åçæç¨æå¢ä¸­é²è¡äºç²¾ç¢ºçè³æé©åæ±ºç­å¶å®ã
  æ¬æå¼·èª¿äº Spark èæºæ§ä»£çååºæ¼åå½¢çå·¥ä½æµç¨çæ´åï¼ä»¥éæ°å®ç¾©å¤§è³æç°å¢ä¸­æ©å¨å­¸ç¿ä»»åçéç¼åå·è¡ï¼çºå¯æ´åä¸ä½¿ç¨èååç AI è§£å³æ¹æ¡éªè·¯ã</paragraph>

##### **SelfPrompt: Autonomously Evaluating LLM Robustness via Domain-Constrained Knowledge Guidelines and Refined Adversarial Prompts**
2412.00765v1 by Aihua Pei, Zehua Yang, Shunan Zhu, Ruoxi Cheng, Ju Jia

Traditional methods for evaluating the robustness of large language models
(LLMs) often rely on standardized benchmarks, which can escalate costs and
limit evaluations across varied domains. This paper introduces a novel
framework designed to autonomously evaluate the robustness of LLMs by
incorporating refined adversarial prompts and domain-constrained knowledge
guidelines in the form of knowledge graphs. Our method systematically generates
descriptive sentences from domain-constrained knowledge graph triplets to
formulate adversarial prompts, enhancing the relevance and challenge of the
evaluation. These prompts, generated by the LLM itself and tailored to evaluate
its own robustness, undergo a rigorous filtering and refinement process,
ensuring that only those with high textual fluency and semantic fidelity are
used. This self-evaluation mechanism allows the LLM to evaluate its robustness
without the need for external benchmarks. We assess the effectiveness of our
framework through extensive testing on both proprietary models like ChatGPT and
open-source models such as Llama-3.1, Phi-3, and Mistral. Results confirm that
our approach not only reduces dependency on conventional data but also provides
a targeted and efficient means of evaluating LLM robustness in constrained
domains.

æè¦ï¼å³çµ±ç¨æ¼è©ä¼°å¤§åèªè¨æ¨¡å (LLM) ç©©å¥æ§çæ¹æ³éå¸¸ä¾è³´æ¨æºååºæºï¼éå¯è½æå¢å ææ¬ä¸¦éå¶è·¨ä¸åé åçè©ä¼°ãæ¬æä»ç´¹äºä¸åæ°ç©çæ¡æ¶ï¼æ¨å¨ééå¨ç¥è­åè­çå½¢å¼ä¸­ç´å¥ç²¾ç·»çå°ææç¤ºåé åç´æç¥è­æºåï¼ä¾èªä¸»è©ä¼° LLM çç©©å¥æ§ãæåçåæ³æ¯ç³»çµ±æ§å°å¾é åç´æç¥è­åè­ä¸åçµä¸­ç¢çæè¿°æ§å¥å­ï¼ä»¥å¶å®å°ææç¤ºï¼å¢å¼·è©ä¼°çç¸éæ§åææ°æ§ãéäºæç¤ºæ¯ç± LLM æ¬èº«ç¢çï¼ä¸¦éå°è©ä¼°å¶èªèº«çç©©å¥æ§èéèº«æé ï¼å®åæç¶æ­·å´æ ¼çéæ¿¾åç²¾çéç¨ï¼ç¢ºä¿åªæé£äºå·æé«åº¦ææ¬æµæ¢æ§åèªç¾©ä¿çæ§çæç¤ºææè¢«ä½¿ç¨ãéç¨®èªæè©ä¼°æ©å¶åè¨± LLM å¨ä¸éè¦å¤é¨åºæºçææ³ä¸è©ä¼°å¶ç©©å¥æ§ãæåééå°å°ææ¨¡åï¼ä¾å¦ ChatGPTï¼åéæºæ¨¡åï¼ä¾å¦ Llama-3.1ãPhi-3 å Mistralï¼é²è¡å»£æ³æ¸¬è©¦ï¼è©ä¼°æåæ¡æ¶çæææ§ãçµæè­å¯¦ï¼æåçåæ³ä¸åæ¸å°äºå°å³çµ±è³æçä¾è³´æ§ï¼éæä¾äºä¸ç¨®æéå°æ§åææçæ¹æ³ï¼å¯ä»¥å¨åéé åä¸­è©ä¼° LLM çç©©å¥æ§ã

##### **Leveraging LLM for Automated Ontology Extraction and Knowledge Graph Generation**
2412.00608v3 by Mohammad Sadeq Abolhasani, Rong Pan

Extracting relevant and structured knowledge from large, complex technical
documents within the Reliability and Maintainability (RAM) domain is
labor-intensive and prone to errors. Our work addresses this challenge by
presenting OntoKGen, a genuine pipeline for ontology extraction and Knowledge
Graph (KG) generation. OntoKGen leverages Large Language Models (LLMs) through
an interactive user interface guided by our adaptive iterative Chain of Thought
(CoT) algorithm to ensure that the ontology extraction process and, thus, KG
generation align with user-specific requirements. Although KG generation
follows a clear, structured path based on the confirmed ontology, there is no
universally correct ontology as it is inherently based on the user's
preferences. OntoKGen recommends an ontology grounded in best practices,
minimizing user effort and providing valuable insights that may have been
overlooked, all while giving the user complete control over the final ontology.
Having generated the KG based on the confirmed ontology, OntoKGen enables
seamless integration into schemeless, non-relational databases like Neo4j. This
integration allows for flexible storage and retrieval of knowledge from
diverse, unstructured sources, facilitating advanced querying, analysis, and
decision-making. Moreover, the generated KG serves as a robust foundation for
future integration into Retrieval Augmented Generation (RAG) systems, offering
enhanced capabilities for developing domain-specific intelligent applications.

æè¦ï¼å¾å¯é æ§åå¯ç¶­è­·æ§ (RAM) é åä¸­é¾å¤§ä¸è¤éçæè¡æä»¶ä¸­èåç¸éä¸çµæ§åçç¥è­ï¼æ¯ä¸é ååå¯éä¸å®¹æåºé¯çå·¥ä½ãæåçç ç©¶ééæåº OntoKGen ä¾è§£æ±ºéåææ°ï¼éæ¯ä¸åçæ­£çæ¬ä½èååç¥è­åè­ (KG) ç¢ççç®¡éãOntoKGen ééå¤§åèªè¨æ¨¡å (LLM) ä»¥åç±æåèªé©æçè¿­ä»£æèé (CoT) æ¼ç®æ³å¼å°çäºåå¼ä½¿ç¨èä»é¢ï¼ä¾ç¢ºä¿æ¬ä½èåçæµç¨ä»¥åç¥è­åè­çç¢çç¬¦åä½¿ç¨èç¹å®çéæ±ãéç¶ç¥è­åè­çç¢çæéµå¾ªä¸åæç¢ºä¸çµæ§åçè·¯å¾ï¼æ ¹æå·²ç¢ºèªçæ¬ä½ï¼ä½ä¸¦æ²æä¸åæ®éæ­£ç¢ºçæ¬ä½ï¼å çºå®æ¬è³ªä¸æ¯åºæ¼ä½¿ç¨èçåå¥½ãOntoKGen ææ¨è¦ä¸ååºæ¼æä½³å¯¦åçæ¬ä½ï¼å°ä½¿ç¨èçå·¥ä½ééå°æä½ï¼ä¸¦æä¾å¯è½è¢«å¿½ç¥çå¯¶è²´è¦è§£ï¼åæè®ä½¿ç¨èå®å¨æ§å¶æçµçæ¬ä½ãå¨æ ¹æå·²ç¢ºèªçæ¬ä½ç¢çç¥è­åè­å¾ï¼OntoKGen è½å¤ ç¡ç¸«æ´åå°å Neo4j éæ¨£çç¡æ¨¡å¼ãééä¿å¼è³æåº«ä¸­ãéç¨®æ´ååè¨±å¾å¤æ¨£ä¸éçµæ§åçä¾æºä¸­éæ´»å°å²å­åæ·åç¥è­ï¼ä¿é²é²éçæ¥è©¢ãåæåæ±ºç­å¶å®ãæ­¤å¤ï¼ç¢ççç¥è­åè­å¯ä½çºæªä¾æ´åå°æª¢ç´¢æ´å¢çæ (RAG) ç³»çµ±ä¸­çç©©åºåºç¤ï¼æä¾éç¼ç¹å®é åæºæ§åæç¨ç¨å¼çé²éåè½ã

##### **Opus: A Large Work Model for Complex Workflow Generation**
2412.00573v2 by ThÃ©o Fagnoni, Bellinda Mesbah, Mahsun Altin, Phillip Kingston

This paper introduces Opus, a novel framework for generating and optimizing
Workflows tailored to complex Business Process Outsourcing (BPO) use cases,
focusing on cost reduction and quality enhancement while adhering to
established industry processes and operational constraints. Our approach
generates executable Workflows from Intention, defined as the alignment of
Client Input, Client Output, and Process Context. These Workflows are
represented as Directed Acyclic Graphs (DAGs), with nodes as Tasks consisting
of sequences of executable Instructions, including tools and human expert
reviews. We adopt a two-phase methodology: Workflow Generation and Workflow
Optimization. In the Generation phase, Workflows are generated using a Large
Work Model (LWM) informed by a Work Knowledge Graph (WKG) that encodes
domain-specific procedural and operational knowledge. In the Optimization
phase, Workflows are transformed into Workflow Graphs (WFGs), where optimal
Workflows are determined through path optimization. Our experiments demonstrate
that state-of-the-art Large Language Models (LLMs) face challenges in reliably
retrieving detailed process data as well as generating industry-compliant
workflows. The key contributions of this paper include integrating a Work
Knowledge Graph (WKG) into a Large Work Model (LWM) to enable the generation of
context-aware, semantically aligned, structured and auditable Workflows. It
further introduces a two-phase approach that combines Workflow Generation from
Intention with graph-based Workflow Optimization. Finally, we present Opus
Alpha 1 Large and Opus Alpha 1 Small that outperform state-of-the-art LLMs by
38% and 29% respectively in Workflow Generation for a Medical Coding use case.

æè¦ï¼éç¯è«æä»ç´¹äº Opusï¼ä¸åç¨æ¼ç¢çåæä½³åå·¥ä½æµç¨çæ°ç©æ¶æ§ï¼å°çºè¤éçæ¥­åæµç¨å¤å (BPO) ä½¿ç¨æ¡ä¾éèº«æé ï¼éé»å¨æ¼éä½ææ¬åæååè³ªï¼åæéµå®æ¢å®çç¢æ¥­æµç¨åçééå¶ãæåçåæ³æ ¹ææåç¢çå¯å·è¡çå·¥ä½æµç¨ï¼æåå®ç¾©çºå®¢æ¶è¼¸å¥ãå®¢æ¶è¼¸åºåæµç¨èæ¯çå°é½ãéäºå·¥ä½æµç¨è¡¨ç¤ºçºæåç¡ç°å (DAG)ï¼ç¯é»çºåå«å¯å·è¡æä»¤åºåçä»»åï¼åæ¬å·¥å·åäººé¡å°å®¶çå¯©æ¥ãæåæ¡ç¨å©éæ®µæ¹æ³ï¼å·¥ä½æµç¨ç¢çåå·¥ä½æµç¨æä½³åãå¨ç¢çéæ®µï¼å·¥ä½æµç¨ä½¿ç¨å¤§åå·¥ä½æ¨¡å (LWM) ç¢çï¼è©²æ¨¡åç±ç·¨ç¢¼ç¹å®é åç¨åºåéä½ç¥è­çå·¥ä½ç¥è­å (WKG) æä¾è³è¨ãå¨æä½³åéæ®µï¼å·¥ä½æµç¨è½æçºå·¥ä½æµç¨å (WFG)ï¼å¶ä¸­ééè·¯å¾æä½³åä¾ç¢ºå®æä½³å·¥ä½æµç¨ãæåçå¯¦é©è¡¨æï¼æåé²çå¤§åèªè¨æ¨¡å (LLM) å¨å¯é å°æ·åè©³ç´°çæµç¨è³æä»¥åç¢çç¬¦åç¢æ¥­è¦ç¯çå·¥ä½æµç¨æ¹é¢é¢è¨ææ°ãéç¯è«æçä¸»è¦è²¢ç»åæ¬å°å·¥ä½ç¥è­å (WKG) æ´åå°å¤§åå·¥ä½æ¨¡å (LWM) ä¸­ï¼ä»¥ç¢çå·åæå¢æç¥ãèªç¾©å°é½ãçµæ§ååå¯ç¨½æ ¸çå·¥ä½æµç¨ãå®é²ä¸æ­¥ä»ç´¹äºä¸ç¨®å©éæ®µæ¹æ³ï¼å°åºæ¼æåçå·¥ä½æµç¨ç¢çèåºæ¼åå½¢çå·¥ä½æµç¨æä½³åç¸çµåãæå¾ï¼æåå±ç¤ºäº Opus Alpha 1 Large å Opus Alpha 1 Smallï¼å®åå¨é«çç·¨ç¢¼ä½¿ç¨æ¡ä¾ä¸­åå¥æ¯æåé²ç LLM å¨å·¥ä½æµç¨ç¢çæ¹é¢é«åº 38% å 29%ã

##### **Neural-Symbolic Reasoning over Knowledge Graphs: A Survey from a Query Perspective**
2412.10390v1 by Lihui Liu, Zihao Wang, Hanghang Tong

Knowledge graph reasoning is pivotal in various domains such as data mining,
artificial intelligence, the Web, and social sciences. These knowledge graphs
function as comprehensive repositories of human knowledge, facilitating the
inference of new information. Traditional symbolic reasoning, despite its
strengths, struggles with the challenges posed by incomplete and noisy data
within these graphs. In contrast, the rise of Neural Symbolic AI marks a
significant advancement, merging the robustness of deep learning with the
precision of symbolic reasoning. This integration aims to develop AI systems
that are not only highly interpretable and explainable but also versatile,
effectively bridging the gap between symbolic and neural methodologies.
Additionally, the advent of large language models (LLMs) has opened new
frontiers in knowledge graph reasoning, enabling the extraction and synthesis
of knowledge in unprecedented ways. This survey offers a thorough review of
knowledge graph reasoning, focusing on various query types and the
classification of neural symbolic reasoning. Furthermore, it explores the
innovative integration of knowledge graph reasoning with large language models,
highlighting the potential for groundbreaking advancements. This comprehensive
overview is designed to support researchers and practitioners across multiple
fields, including data mining, AI, the Web, and social sciences, by providing a
detailed understanding of the current landscape and future directions in
knowledge graph reasoning.

æè¦ï¼ç¥è­åè­æ¨çå¨è³ææ¢åãäººå·¥æºæ§ãç¶²è·¯åç¤¾æç§å­¸ç­é åè³ééè¦ãéäºç¥è­åè­ä½çºäººé¡ç¥è­çç¶åå²å­åº«ï¼ä¿é²æ°è³è¨çæ¨è«ãå³çµ±çç¬¦èæ¨çåç®¡æå¶åªé»ï¼ä½ä»é£ä»¥æå°éäºåè­ä¸­ä¸å®æ´ä¸æéè¨çè³ææå¸¶ä¾çææ°ãç¸æ¯ä¹ä¸ï¼ç¥ç¶ç¬¦è AI çèèµ·æ¨èªèä¸åéå¤§é²å±ï¼å®å°æ·±åº¦å­¸ç¿çç©©å¥æ§èç¬¦èæ¨ççç²¾ç¢ºæ§çµåèµ·ä¾ãéç¨®æ´åæ¨å¨éç¼ä¸åé«åº¦å¯è§£éä¸å¯èªªæï¼èä¸ç¨éå»£æ³ç AI ç³»çµ±ï¼ææå°ç¸®å°ç¬¦èåç¥ç¶æ¹æ³ä¹éçå·®è·ãæ­¤å¤ï¼å¤§åèªè¨æ¨¡å (LLM) çåºç¾çºç¥è­åè­æ¨çéé¢äºæ°é åï¼ä»¥åææªæçæ¹å¼å¯¦ç¾ç¥è­çæååç¶åãæ¬èª¿æ¥å°ç¥è­åè­æ¨çé²è¡äºå¨é¢åé¡§ï¼éé»éæ³¨åç¨®æ¥è©¢é¡ååç¥ç¶ç¬¦èæ¨ççåé¡ãæ­¤å¤ï¼å®éæ¢è¨äºç¥è­åè­æ¨çèå¤§åèªè¨æ¨¡åçåµæ°æ´åï¼å¼·èª¿äºçªç ´æ§é²å±çæ½åãéä»½å¨é¢çæ¦è¿°æ¨å¨ééæä¾å°ç¥è­åè­æ¨çä¸­ç¶åæ¦æ³åæªä¾æ¹åçè©³ç´°äºè§£ï¼ä¾æ¯æ´è³ææ¢åãAIãç¶²è·¯åç¤¾æç§å­¸ç­å¤åé åçç ç©¶äººå¡åå¯¦åå·¥ä½èã

##### **Node Importance Estimation Leveraging LLMs for Semantic Augmentation in Knowledge Graphs**
2412.00478v1 by Xinyu Lin, Tianyu Zhang, Chengbin Hou, Jinbao Wang, Jianye Xue, Hairong Lv

Node Importance Estimation (NIE) is a task that quantifies the importance of
node in a graph. Recent research has investigated to exploit various
information from Knowledge Graphs (KGs) to estimate node importance scores.
However, the semantic information in KGs could be insufficient, missing, and
inaccurate, which would limit the performance of existing NIE models. To
address these issues, we leverage Large Language Models (LLMs) for semantic
augmentation thanks to the LLMs' extra knowledge and ability of integrating
knowledge from both LLMs and KGs. To this end, we propose the LLMs Empowered
Node Importance Estimation (LENIE) method to enhance the semantic information
in KGs for better supporting NIE tasks. To our best knowledge, this is the
first work incorporating LLMs into NIE. Specifically, LENIE employs a novel
clustering-based triplet sampling strategy to extract diverse knowledge of a
node sampled from the given KG. After that, LENIE adopts the node-specific
adaptive prompts to integrate the sampled triplets and the original node
descriptions, which are then fed into LLMs for generating richer and more
precise augmented node descriptions. These augmented descriptions finally
initialize node embeddings for boosting the downstream NIE model performance.
Extensive experiments demonstrate LENIE's effectiveness in addressing semantic
deficiencies in KGs, enabling more informative semantic augmentation and
enhancing existing NIE models to achieve the state-of-the-art performance. The
source code of LENIE is freely available at
\url{https://github.com/XinyuLin-FZ/LENIE}.

æè¦ï¼ç¯é»éè¦æ§ä¼°è¨ (NIE) æ¯ä¸é éååä¸­ç¯é»éè¦æ§çä»»åãæè¿çç ç©¶å·²èª¿æ¥å©ç¨ç¥è­åè­ (KG) ä¸­çåç¨®è³è¨ä¾ä¼°è¨ç¯é»éè¦æ§åæ¸ãç¶èï¼KG ä¸­çèªç¾©è³è¨å¯è½ä¸è¶³ãéºå¤±ä¸ä¸æºç¢ºï¼éå°éå¶ç¾æ NIE æ¨¡åçæè½ãçºäºè§£æ±ºéäºåé¡ï¼æåå©ç¨å¤§åèªè¨æ¨¡å (LLM) é²è¡èªç¾©å¢å¼·ï¼éè¦æ­¸åæ¼ LLM çé¡å¤ç¥è­åæ´å LLM å KG ä¸­ç¥è­çè½åãçºæ­¤ï¼æåæåº LLM å¼·åç¯é»éè¦æ§ä¼°è¨ (LENIE) æ¹æ³ï¼ä»¥å¢å¼· KG ä¸­çèªç¾©è³è¨ï¼ä»¥ä¾¿æ´å¥½å°æ¯æ´ NIE ä»»åãææåæç¥ï¼éæ¯å° LLM ç´å¥ NIE çç¬¬ä¸é å·¥ä½ãå·é«ä¾èªªï¼LENIE æ¡ç¨æ°ç©çåºæ¼ç¾¤éçä¸åçµåæ¨£ç­ç¥ï¼ä»¥èåå¾çµ¦å® KG åæ¨£çç¯é»çå¤åç¥è­ãå¨é£ä¹å¾ï¼LENIE æ¡ç¨ç¹å®æ¼ç¯é»çèªé©ææç¤ºï¼ä»¥æ´ååæ¨£çä¸åçµååå§ç¯é»æè¿°ï¼ç¶å¾å°å®åè¼¸å¥ LLM ä»¥ç¢çæ´è±å¯ä¸æ´ç²¾ç¢ºçå¢å¼·ç¯é»æè¿°ãéäºå¢å¼·çæè¿°æçµåå§åç¯é»åµå¥ï¼ä»¥æåä¸æ¸¸ NIE æ¨¡åæè½ãå»£æ³çå¯¦é©è­æäº LENIE å¨è§£æ±º KG ä¸­çèªç¾©ç¼ºé·æ¹é¢çæææ§ï¼å¯¦ç¾æ´å¤è³è¨æ§çèªç¾©å¢å¼·ï¼ä¸¦å¢å¼·ç¾æç NIE æ¨¡åä»¥éææåé²çæè½ãLENIE çåå§ç¨å¼ç¢¼å¯æ¼\url{https://github.com/XinyuLin-FZ/LENIE} åè²»åå¾ã

##### **An AI-Driven Data Mesh Architecture Enhancing Decision-Making in Infrastructure Construction and Public Procurement**
2412.00224v1 by Saurabh Mishra, Mahendra Shinde, Aniket Yadav, Bilal Ayyub, Anand Rao

Infrastructure construction, often dubbed an "industry of industries," is
closely linked with government spending and public procurement, offering
significant opportunities for improved efficiency and productivity through
better transparency and information access. By leveraging these opportunities,
we can achieve notable gains in productivity, cost savings, and broader
economic benefits. Our approach introduces an integrated software ecosystem
utilizing Data Mesh and Service Mesh architectures. This system includes the
largest training dataset for infrastructure and procurement, encompassing over
100 billion tokens, scientific publications, activities, and risk data, all
structured by a systematic AI framework. Supported by a Knowledge Graph linked
to domain-specific multi-agent tasks and Q&A capabilities, our platform
standardizes and ingests diverse data sources, transforming them into
structured knowledge. Leveraging large language models (LLMs) and automation,
our system revolutionizes data structuring and knowledge creation, aiding
decision-making in early-stage project planning, detailed research, market
trend analysis, and qualitative assessments. Its web-scalable architecture
delivers domain-curated information, enabling AI agents to facilitate reasoning
and manage uncertainties, while preparing for future expansions with
specialized agents targeting particular challenges. This integration of AI with
domain expertise not only boosts efficiency and decision-making in construction
and infrastructure but also establishes a framework for enhancing government
efficiency and accelerating the transition of traditional industries to digital
workflows. This work is poised to significantly influence AI-driven initiatives
in this sector and guide best practices in AI Operations.

æè¦ï¼åºç¤å»ºè¨­å»ºè¨­ï¼å¸¸è¢«ç¨±çºãç¢æ¥­ä¸­çç¢æ¥­ãï¼èæ¿åºæ¯åºåå¬å±æ¡è³¼æ¯æ¯ç¸éï¼ééæåéæåº¦åè³è¨åå¾ï¼è½å¤§å¹æåæçåçç¢åãééåç¨éäºæ©æï¼æåè½å¨çç¢åãææ¬ç¯çåæ´å»£æ³çç¶æ¿æçä¸ç²å¾é¡¯èçæ¶çãæåçåæ³å¼é²ä¸åæ´åå¼è»é«çæç³»ï¼å©ç¨è³æç¶²æ ¼åæåç¶²æ ¼æ¶æ§ãéåç³»çµ±åå«åºç¤å»ºè¨­åæ¡è³¼æå¤§çè¨ç·´è³æéï¼æ¶µèè¶é 1000 ååç¬¦èãç§å­¸åºçåãæ´»ååé¢¨éªè³æï¼ææè³æé½ä»¥ç³»çµ±åç AI æ¶æ§é²è¡çµæ§åãæåçå¹³å°ç±é£çµå°ç¹å®é åçå¤éä»£çäººä»»åååç­åè½çç¥è­åè­æä¾æ¯æ´ï¼æ¨æºåä¸¦å¯å¥ä¸åçè³æä¾æºï¼å°å¶è½æçºçµæ§åçç¥è­ãæåçç³»çµ±å©ç¨å¤§èªè¨æ¨¡å (LLM) åèªååï¼å¾¹åºæ¹é©è³æçµæ§ååç¥è­å»ºç«ï¼åå©å¨æ©æéæ®µçå°æ¡è¦åãè©³ç´°ç ç©¶ãå¸å ´è¶¨å¢åæåå®æ§è©ä¼°ä¸­é²è¡æ±ºç­å¶å®ãå¶å¯æ´åè³ç¶²è·¯è¦æ¨¡çæ¶æ§æä¾é åç­å±çè³è¨ï¼è® AI ä»£çäººè½å¤ ä¿é²æ¨çåç®¡çä¸ç¢ºå®æ§ï¼åææºåå¥½ä»¥å°éä»£çäººå æç¹å®ææ°ï¼é²è¡æªä¾çæ´åãéç¨®å° AI èé åå°æ¥­ç¥è­æ´åçæ¹å¼ï¼ä¸åæåå»ºè¨­ååºç¤å»ºè¨­çæçåæ±ºç­å¶å®ï¼ä¹å»ºç«äºä¸åæ¶æ§ï¼ä»¥æåæ¿åºæçä¸¦å éå³çµ±ç¢æ¥­è½åè³æ¸ä½å·¥ä½æµç¨ãéé å·¥ä½æºåå°éåé¨éç AI é©åè¨ç«ç¢çéå¤§å½±é¿ï¼ä¸¦å¼å° AI ä½æ¥­çæä½³å¯¦åã

##### **PerLA: Perceptive 3D Language Assistant**
2411.19774v1 by Guofeng Mei, Wei Lin, Luigi Riz, Yujiao Wu, Fabio Poiesi, Yiming Wang

Enabling Large Language Models (LLMs) to understand the 3D physical world is
an emerging yet challenging research direction. Current strategies for
processing point clouds typically downsample the scene or divide it into
smaller parts for separate analysis. However, both approaches risk losing key
local details or global contextual information. In this paper, we introduce
PerLA, a 3D language assistant designed to be more perceptive to both details
and context, making visual representations more informative for the LLM. PerLA
captures high-resolution (local) details in parallel from different point cloud
areas and integrates them with (global) context obtained from a
lower-resolution whole point cloud. We present a novel algorithm that preserves
point cloud locality through the Hilbert curve and effectively aggregates
local-to-global information via cross-attention and a graph neural network.
Lastly, we introduce a novel loss for local representation consensus to promote
training stability. PerLA outperforms state-of-the-art 3D language assistants,
with gains of up to +1.34 CiDEr on ScanQA for question answering, and +4.22 on
ScanRefer and +3.88 on Nr3D for dense
captioning.\url{https://gfmei.github.io/PerLA/}

æè¦ï¼è®å¤§åèªè¨æ¨¡å (LLM) çè§£ 3D ç©çä¸çæ¯ä¸åæ°èä½å·æææ°æ§çç ç©¶æ¹åãç¶åèçé»é²çç­ç¥éå¸¸æå°å ´æ¯é²è¡éæ¡æ¨£æå°å¶åçºæ´å°çé¨åä»¥é²è¡å®ç¨åæãç¶èï¼éå©ç¨®æ¹æ³é½æå¯è½éºå¤±ééµçå±é¨ç´°ç¯æå¨å±èæ¯è³è¨ãå¨æ¬æä¸­ï¼æåä»ç´¹äº PerLAï¼éæ¯ä¸å 3D èªè¨å©çï¼æ¨å¨æ´æé³å°æç¥ç´°ç¯åèæ¯ï¼è®è¦è¦ºè¡¨ç¾å° LLM æ´æè³è¨æ§ãPerLA å¾ä¸åçé»é²ååä¸¦è¡æ·åé«è§£æåº¦ï¼å±é¨ï¼ç´°ç¯ï¼ä¸¦å°å¶èå¾ä½è§£æåº¦å¨é»é²ä¸­ç²å¾çï¼å¨å±ï¼èæ¯æ´åå¨ä¸èµ·ãæåæåºäºä¸ç¨®æ°æ¼ç®æ³ï¼ééå¸ç¾ä¼¯ç¹æ²ç·ä¿çé»é²å±é¨æ§ï¼ä¸¦ééäº¤åæ³¨æåååå½¢ç¥ç¶ç¶²è·¯ææå°å¯ç¸½å±é¨å°å¨å±è³è¨ãæå¾ï¼æåå¼å¥äºä¸åæ°çæå¤±å½æ¸ï¼ç¨æ¼å±é¨è¡¨ç¤ºå±è­ï¼ä»¥ä¿é²è¨ç·´ç©©å®æ§ãPerLA åªæ¼æåé²ç 3D èªè¨å©çï¼å¨ ScanQA ä¸åç­ç²å¾é«é +1.34 CiDEr çå¢çï¼å¨ ScanRefer ä¸ç²å¾ +4.22ï¼å¨ Nr3D ä¸ç²å¾ +3.88 çå¯éæ¨é¡ã\url{https://gfmei.github.io/PerLA/}

##### **Knowledge Management for Automobile Failure Analysis Using Graph RAG**
2411.19539v1 by Yuta Ojima, Hiroki Sakaji, Tadashi Nakamura, Hiroaki Sakata, Kazuya Seki, Yuu Teshigawara, Masami Yamashita, Kazuhiro Aoyama

This paper presents a knowledge management system for automobile failure
analysis using retrieval-augmented generation (RAG) with large language models
(LLMs) and knowledge graphs (KGs). In the automotive industry, there is a
growing demand for knowledge transfer of failure analysis from experienced
engineers to young engineers. However, failure events are phenomena that occur
in a chain reaction, making them difficult for beginners to analyze them. While
knowledge graphs, which can describe semantic relationships and structure
information is effective in representing failure events, due to their
capability of representing the relationships between components, there is much
information in KGs, so it is challenging for young engineers to extract and
understand sub-graphs from the KG. On the other hand, there is increasing
interest in the use of Graph RAG, a type of RAG that combines LLMs and KGs for
knowledge management. However, when using the current Graph RAG framework with
an existing knowledge graph for automobile failures, several issues arise
because it is difficult to generate executable queries for a knowledge graph
database which is not constructed by LLMs. To address this, we focused on
optimizing the Graph RAG pipeline for existing knowledge graphs. Using an
original Q&A dataset, the ROUGE F1 score of the sentences generated by the
proposed method showed an average improvement of 157.6% compared to the current
method. This highlights the effectiveness of the proposed method for automobile
failure analysis.

æè¦ï¼æ¬ææåºäºä¸åä½¿ç¨æª¢ç´¢å¢å¼·çæï¼RAGï¼åå¤§åèªè¨æ¨¡åï¼LLMï¼åç¥è­åè­ï¼KGï¼çæ±½è»æéåæç¥è­ç®¡çç³»çµ±ãå¨æ±½è»ç¢æ¥­ä¸­ï¼æè¶ä¾è¶å¤çéæ±ï¼å°æéåæç¥è­å¾ç¶é©è±å¯çå·¥ç¨å¸«å³æçµ¦å¹´è¼çå·¥ç¨å¸«ãç¶èï¼æéäºä»¶æ¯ä¸ç¨®é£éåæä¸­ç¼ççç¾è±¡ï¼éä½¿å¾åå­¸èé£ä»¥åæå®åãåç®¡ç¥è­åè­å¯ä»¥æè¿°èªç¾©éä¿åçµæ§åè³è¨ï¼ä¸¦ææå°è¡¨ç¤ºæéäºä»¶ï¼ç±æ¼å®åæè¡¨ç¤ºåä»¶ä¹ééä¿çè½åï¼KG ä¸­æè¨±å¤è³è¨ï¼å æ­¤å¹´è¼çå·¥ç¨å¸«å¾é£å¾ KG ä¸­æååçè§£å­åãå¦ä¸æ¹é¢ï¼äººåè¶ä¾è¶æèè¶£ä½¿ç¨ Graph RAGï¼éæ¯ä¸ç¨®çµå LLM å KG é²è¡ç¥è­ç®¡çç RAGãç¶èï¼ç¶å°ç®åç Graph RAG æ¡æ¶èç¾æçæ±½è»æéç¥è­åè­ä¸èµ·ä½¿ç¨æï¼æåºç¾å¹¾ååé¡ï¼å çºé£ä»¥çæéå°é LLM æ§å»ºçç¥è­åè­è³æåº«çå¯å·è¡æ¥è©¢ãçºäºè§£æ±ºéååé¡ï¼æåå°æ³¨æ¼éå°ç¾æç¥è­åè­æä½³å Graph RAG ç®¡éãä½¿ç¨åå§åç­è³æéï¼ææåºæ¹æ³çæçå¥å­ç ROUGE F1 åæ¸èç®åæ¹æ³ç¸æ¯ï¼å¹³åæåäº 157.6%ãéçªé¡¯äºææåºæ¹æ³å°æ¼æ±½è»æéåæçæææ§ã

##### **Way to Specialist: Closing Loop Between Specialized LLM and Evolving Domain Knowledge Graph**
2411.19064v1 by Yutong Zhang, Lixing Chen, Shenghong Li, Nan Cao, Yang Shi, Jiaxin Ding, Zhe Qu, Pan Zhou, Yang Bai

Large language models (LLMs) have demonstrated exceptional performance across
a wide variety of domains. Nonetheless, generalist LLMs continue to fall short
in reasoning tasks necessitating specialized knowledge. Prior investigations
into specialized LLMs focused on domain-specific training, which entails
substantial efforts in domain data acquisition and model parameter fine-tuning.
To address these challenges, this paper proposes the Way-to-Specialist (WTS)
framework, which synergizes retrieval-augmented generation with knowledge
graphs (KGs) to enhance the specialized capability of LLMs in the absence of
specialized training. In distinction to existing paradigms that merely utilize
external knowledge from general KGs or static domain KGs to prompt LLM for
enhanced domain-specific reasoning, WTS proposes an innovative
"LLM$\circlearrowright$KG" paradigm, which achieves bidirectional enhancement
between specialized LLM and domain knowledge graph (DKG). The proposed paradigm
encompasses two closely coupled components: the DKG-Augmented LLM and the
LLM-Assisted DKG Evolution. The former retrieves question-relevant domain
knowledge from DKG and uses it to prompt LLM to enhance the reasoning
capability for domain-specific tasks; the latter leverages LLM to generate new
domain knowledge from processed tasks and use it to evolve DKG. WTS closes the
loop between DKG-Augmented LLM and LLM-Assisted DKG Evolution, enabling
continuous improvement in the domain specialization as it progressively answers
and learns from domain-specific questions. We validate the performance of WTS
on 6 datasets spanning 5 domains. The experimental results show that WTS
surpasses the previous SOTA in 4 specialized domains and achieves a maximum
performance improvement of 11.3%.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å·²å¨ååé åå±ç¾åºåªç°çè¡¨ç¾ãç¶èï¼éæ LLM å¨éè¦å°æ¥­ç¥è­çæ¨çä»»åä¸­ä»è¡¨ç¾ä¸ä½³ãååå°å°æ¥­ LLM çç ç©¶éä¸­å¨ç¹å®é åè¨ç·´ï¼ééè¦å¤§éé åè³æåå¾åæ¨¡ååæ¸å¾®èª¿ãçºäºæå°éäºææ°ï¼æ¬ææåº Way-to-Specialist (WTS) æ¶æ§ï¼å®å°æª¢ç´¢å¢å¼·çæèç¥è­åè­ (KG) çµåèµ·ä¾ï¼ä»¥æå LLM å¨æ²æå°æ¥­è¨ç·´ææ³ä¸çå°æ¥­è½åãèåå©ç¨ä¾èªä¸è¬ KG æéæé å KG çå¤é¨ç¥è­æç¤º LLM ä»¥å¢å¼·ç¹å®é åæ¨ççæ¢æç¯ä¾ä¸åï¼WTS æåºä¸ååµæ°çãLLM$\circlearrowright$KGãç¯ä¾ï¼å®å¨å°æ¥­ LLM åé åç¥è­åè­ (DKG) ä¹éå¯¦ç¾éåå¢å¼·ãææåºçç¯ä¾åå«å©åç·å¯çµåççµæé¨åï¼DKG å¢å¼· LLM å LLM è¼å© DKG æ¼åãåèå¾ DKG ä¸­æª¢ç´¢èåé¡ç¸éçé åç¥è­ï¼ä¸¦ä½¿ç¨å®æç¤º LLM ä»¥å¢å¼·ç¹å®é åä»»åçæ¨çè½åï¼å¾èå©ç¨ LLM å¾èçéçä»»åä¸­ç¢çæ°çé åç¥è­ï¼ä¸¦ä½¿ç¨å®ä¾æ¼å DKGãWTS éåäº DKG å¢å¼· LLM å LLM è¼å© DKG æ¼åä¹éçè¿´è·¯ï¼é¨èå®éæ¼¸åç­åå­¸ç¿ç¹å®é ååé¡ï¼è½å¤ æçºæ¹åé åå°æ¥­åãæåå¨æ©«è·¨ 5 åé åç 6 åè³æéä¸é©è­ WTS çæè½ãå¯¦é©çµæé¡¯ç¤ºï¼WTS å¨ 4 åå°æ¥­é åä¸­è¶è¶ååç SOTAï¼ä¸¦éå° 11.3% çæå¤§æè½æåã

##### **EzSQL: An SQL intermediate representation for improving SQL-to-text Generation**
2411.18923v1 by Meher Bhardwaj, Hrishikesh Ethari, Dennis Singh Moirangthem

The SQL-to-text generation task traditionally uses template base, Seq2Seq,
tree-to-sequence, and graph-to-sequence models. Recent models take advantage of
pre-trained generative language models for this task in the Seq2Seq framework.
However, treating SQL as a sequence of inputs to the pre-trained models is not
optimal. In this work, we put forward a new SQL intermediate representation
called EzSQL to align SQL with the natural language text sequence. EzSQL
simplifies the SQL queries and brings them closer to natural language text by
modifying operators and keywords, which can usually be described in natural
language. EzSQL also removes the need for set operators. Our proposed
SQL-to-text generation model uses EzSQL as the input to a pre-trained
generative language model for generating the text descriptions. We demonstrate
that our model is an effective state-of-the-art method to generate text
narrations from SQL queries on the WikiSQL and Spider datasets. We also show
that by generating pretraining data using our SQL-to-text generation model, we
can enhance the performance of Text-to-SQL parsers.

æè¦ï¼SQL è½æå­çæä»»åå³çµ±ä¸ä½¿ç¨ç¯æ¬åºç¤ãSeq2Seqãæ¨¹å°åºåååå°åºåæ¨¡åãæè¿çæ¨¡åå©ç¨é è¨ç·´çæå¼èªè¨æ¨¡åä¾å·è¡ Seq2Seq æ¶æ§ä¸­çæ­¤é ä»»åãç¶èï¼å° SQL è¦çºé è¨ç·´æ¨¡åè¼¸å¥åºåä¸¦éæä½³è§£ãå¨æ­¤é å·¥ä½ä¸­ï¼æåæåºä¸ååçº EzSQL çæ°å¼ SQL ä¸­éè¡¨ç¤ºï¼ä»¥å° SQL èèªç¶èªè¨æå­åºåå°é½ãEzSQL ç°¡å SQL æ¥è©¢ï¼ä¸¦ééä¿®æ¹éç®å­èééµå­ï¼éå¸¸å¯ä»¥ç¨èªç¶èªè¨æè¿°ï¼ï¼è®å®åæ´æ¥è¿èªç¶èªè¨æå­ãEzSQL ä¹æ¶é¤äºå°éåéç®å­çéæ±ãæåæåºç SQL è½æå­çææ¨¡åä½¿ç¨ EzSQL ä½çºè¼¸å¥ï¼è¼¸å¥é è¨ç·´çæå¼èªè¨æ¨¡åä»¥ç¢çæå­æè¿°ãæåç¤ºç¯æåçæ¨¡åæ¯ä¸ç¨®ææçææ°æ¹æ³ï¼å¯ä»¥ç¨æ¼å¾ WikiSQL è Spider è³æéä¸­ç SQL æ¥è©¢ç¢çæå­æè¿°ãæåä¹å±ç¤ºééä½¿ç¨æåç SQL è½æå­çææ¨¡åç¢çé è¨ç·´è³æï¼æåå¯ä»¥æåæå­è½ SQL è§£æå¨çæè½ã

##### **MLLM-Search: A Zero-Shot Approach to Finding People using Multimodal Large Language Models**
2412.00103v1 by Angus Fung, Aaron Hao Tan, Haitong Wang, Beno Benhabib, Goldie Nejat

Robotic search of people in human-centered environments, including healthcare
settings, is challenging as autonomous robots need to locate people without
complete or any prior knowledge of their schedules, plans or locations.
Furthermore, robots need to be able to adapt to real-time events that can
influence a person's plan in an environment. In this paper, we present
MLLM-Search, a novel zero-shot person search architecture that leverages
multimodal large language models (MLLM) to address the mobile robot problem of
searching for a person under event-driven scenarios with varying user
schedules. Our approach introduces a novel visual prompting method to provide
robots with spatial understanding of the environment by generating a spatially
grounded waypoint map, representing navigable waypoints by a topological graph
and regions by semantic labels. This is incorporated into a MLLM with a region
planner that selects the next search region based on the semantic relevance to
the search scenario, and a waypoint planner which generates a search path by
considering the semantically relevant objects and the local spatial context
through our unique spatial chain-of-thought prompting approach. Extensive 3D
photorealistic experiments were conducted to validate the performance of
MLLM-Search in searching for a person with a changing schedule in different
environments. An ablation study was also conducted to validate the main design
choices of MLLM-Search. Furthermore, a comparison study with state-of-the art
search methods demonstrated that MLLM-Search outperforms existing methods with
respect to search efficiency. Real-world experiments with a mobile robot in a
multi-room floor of a building showed that MLLM-Search was able to generalize
to finding a person in a new unseen environment.

æè¦ï¼æ©å¨äººå¨ä»¥äººçºä¸­å¿çç°å¢ä¸­æå°äººï¼åæ¬é«çä¿å¥ç°å¢ï¼éæ¯ä¸åææ°ï¼å çºèªä¸»æ©å¨äººéè¦å¨å®å¨ææ²æäºåç¥éä»åçæéè¡¨ãè¨ç«æä½ç½®çææ³ä¸æ¾å°äººãæ­¤å¤ï¼æ©å¨äººéè¦è½å¤ é©æå¯è½å½±é¿ç°å¢ä¸­æäººè¨ç«çå³æäºä»¶ãå¨æ¬æä¸­ï¼æåæåº MLLM-Searchï¼ä¸ç¨®æ°ç©çé¶æ¬¡äººæå°æ¶æ§ï¼å®å©ç¨å¤æ¨¡æå¤§åèªè¨æ¨¡å (MLLM) ä¾è§£æ±ºå¨äºä»¶é©åå ´æ¯ä¸­æå°å·æä¸åä½¿ç¨èæéè¡¨çæäººçè¡åæ©å¨äººåé¡ãæåçåæ³å¼å¥äºä¸ç¨®æ°ç©çè¦è¦ºæç¤ºæ¹æ³ï¼ééçæä¸åç©ºéæ¥å°çèªé»åï¼ä»¥ææ²åè¡¨ç¤ºå¯å°èªèªé»ï¼ä¸¦ééèªç¾©æ¨ç±¤è¡¨ç¤ºååï¼çºæ©å¨äººæä¾ç°å¢çç©ºéçè§£ãéè¢«æ´åå°ä¸åå·æååè¦åå¨ç MLLM ä¸­ï¼è©²ååè¦åå¨æ ¹æèæå°å ´æ¯çèªç¾©ç¸éæ§é¸æä¸ä¸åæå°ååï¼ä»¥åä¸åèªé»è¦åå¨ï¼è©²è¦åå¨ééèæ®èªç¾©ç¸éç©ä»¶åå±é¨ç©ºéèæ¯ééæåç¨ç¹çç©ºéæç¶­æç¤ºæ¹æ³çææå°è·¯å¾ãé²è¡äºå»£æ³ç 3D çå¯¦æå¯¦é©ï¼ä»¥é©è­ MLLM-Search å¨ä¸åç°å¢ä¸­æå°å·æè®æ´æéè¡¨çäººçæè½ãéé²è¡äºä¸é æ¶èç ç©¶ï¼ä»¥é©è­ MLLM-Search çä¸»è¦è¨­è¨é¸æãæ­¤å¤ï¼èæåé²çæå°æ¹æ³çæ¯è¼ç ç©¶è¡¨æï¼MLLM-Search å¨æå°æçæ¹é¢åªæ¼ç¾ææ¹æ³ãå¨å»ºç¯ç©å¤æ¿éæ¨å±¤ä¸­ä½¿ç¨è¡åæ©å¨äººé²è¡ççå¯¦ä¸çå¯¦é©è¡¨æï¼MLLM-Search è½å¤ æ¦æ¬å°å¨ä¸åæ°çæªè¦ç°å¢ä¸­æ¾å°æäººã

##### **Human Evaluation of Procedural Knowledge Graph Extraction from Text with Large Language Models**
2412.03589v1 by Valentina Anita Carriero, Antonia Azzini, Ilaria Baroni, Mario Scrocca, Irene Celino

Procedural Knowledge is the know-how expressed in the form of sequences of
steps needed to perform some tasks. Procedures are usually described by means
of natural language texts, such as recipes or maintenance manuals, possibly
spread across different documents and systems, and their interpretation and
subsequent execution is often left to the reader. Representing such procedures
in a Knowledge Graph (KG) can be the basis to build digital tools to support
those users who need to apply or execute them. In this paper, we leverage Large
Language Model (LLM) capabilities and propose a prompt engineering approach to
extract steps, actions, objects, equipment and temporal information from a
textual procedure, in order to populate a Procedural KG according to a
pre-defined ontology. We evaluate the KG extraction results by means of a user
study, in order to qualitatively and quantitatively assess the perceived
quality and usefulness of the LLM-extracted procedural knowledge. We show that
LLMs can produce outputs of acceptable quality and we assess the subjective
perception of AI by human evaluators.

æè¦ï¼ç¨åºæ§ç¥è­æ¯ä»¥å·è¡æäºä»»åæéçæ­¥é©åºåå½¢å¼è¡¨éçæè¡ç¥è­ãç¨åºéå¸¸ç±èªç¶èªè¨ææ¬æè¿°ï¼ä¾å¦é£è­æç¶­è­·æåï¼å¯è½åæ£å¨ä¸åçæä»¶åç³»çµ±ä¸­ï¼å¶è§£éåå¾çºå·è¡éå¸¸ççµ¦è®èãå¨ç¥è­åè­ (KG) ä¸­è¡¨ç¤ºæ­¤é¡ç¨åºå¯ä»¥æçºæ§å»ºæ¸ä½å·¥å·çåºç¤ï¼ä»¥æ¯æ´éè¦æç¨æå·è¡éäºç¨åºçä½¿ç¨èãå¨æ¬æä¸­ï¼æåå©ç¨å¤§åèªè¨æ¨¡å (LLM) åè½ä¸¦æåºæç¤ºå·¥ç¨æ¹æ³ï¼å¾æå­ç¨åºä¸­æåæ­¥é©ãåä½ãç©ä»¶ãè¨­ååæéè³è¨ï¼ä»¥ä¾¿æ ¹æé å®ç¾©çæ¬ä½å¡«åç¨åº KGãæåééä½¿ç¨èç ç©¶è©ä¼° KG æåçµæï¼ä»¥å®æ§åå®éè©ä¼° LLM æåçç¨åºç¥è­çæç¥åè³ªåå¯¦ç¨æ§ãæåè¡¨æ LLM å¯ä»¥ç¢çå¯æ¥ååè³ªçè¼¸åºï¼ä¸¦ä¸æåè©ä¼°äºäººé¡è©ä¼°èå° AI çä¸»è§æç¥ã

##### **Regularized Multi-LLMs Collaboration for Enhanced Score-based Causal Discovery**
2411.17989v1 by Xiaoxuan Li, Yao Liu, Ruoyu Wang, Lina Yao

As the significance of understanding the cause-and-effect relationships among
variables increases in the development of modern systems and algorithms,
learning causality from observational data has become a preferred and efficient
approach over conducting randomized control trials. However, purely
observational data could be insufficient to reconstruct the true causal graph.
Consequently, many researchers tried to utilise some form of prior knowledge to
improve causal discovery process. In this context, the impressive capabilities
of large language models (LLMs) have emerged as a promising alternative to the
costly acquisition of prior expert knowledge. In this work, we further explore
the potential of using LLMs to enhance causal discovery approaches,
particularly focusing on score-based methods, and we propose a general
framework to utilise the capacity of not only one but multiple LLMs to augment
the discovery process.

æè¦ï¼é¨èçè§£ç¾ä»£ç³»çµ±åæ¼ç®æ³ä¸­è®æ¸ä¹éçå æéä¿çéè¦æ§æ¥çå¢å ï¼å¾è§æ¸¬è³æä¸­å­¸ç¿å æéä¿å·²æçºä¸ç¨®æ¯é²è¡é¨æ©å°ç§è©¦é©æ´åéçä¸æ´ææççæ¹æ³ãç¶èï¼ç´ç²¹çè§æ¸¬è³æå¯è½ä¸è¶³ä»¥éå»ºçæ­£çå æåãå æ­¤ï¼è¨±å¤ç ç©¶äººå¡åè©¦å©ç¨æç¨®å½¢å¼çåé©ç¥è­ä¾æ¹åå æç¼ç¾éç¨ãå¨æ­¤èæ¯ä¸ï¼å¤§åèªè¨æ¨¡å (LLM) çå¼·å¤§åè½å·²æçºæè²´çåé©å°å®¶ç¥è­ç²åçæ¿ä»£æ¹æ¡ãå¨éé å·¥ä½ä¸­ï¼æåé²ä¸æ­¥æ¢è¨äºä½¿ç¨ LLM ä¾å¢å¼·å æç¼ç¾æ¹æ³çå¯è½æ§ï¼ç¹å¥éæ³¨åºæ¼è©åçæ¨¡åï¼ä¸¦ä¸æåæåºäºä¸åéç¨æ¡æ¶ï¼ä¸åå¯ä»¥å©ç¨ä¸å LLMï¼éå¯ä»¥å©ç¨å¤å LLM ä¾æ´åç¼ç¾éç¨ã

##### **ShowUI: One Vision-Language-Action Model for GUI Visual Agent**
2411.17465v1 by Kevin Qinghong Lin, Linjie Li, Difei Gao, Zhengyuan Yang, Shiwei Wu, Zechen Bai, Weixian Lei, Lijuan Wang, Mike Zheng Shou

Building Graphical User Interface (GUI) assistants holds significant promise
for enhancing human workflow productivity. While most agents are
language-based, relying on closed-source API with text-rich meta-information
(e.g., HTML or accessibility tree), they show limitations in perceiving UI
visuals as humans do, highlighting the need for GUI visual agents. In this
work, we develop a vision-language-action model in digital world, namely
ShowUI, which features the following innovations: (i) UI-Guided Visual Token
Selection to reduce computational costs by formulating screenshots as an UI
connected graph, adaptively identifying their redundant relationship and serve
as the criteria for token selection during self-attention blocks; (ii)
Interleaved Vision-Language-Action Streaming that flexibly unifies diverse
needs within GUI tasks, enabling effective management of visual-action history
in navigation or pairing multi-turn query-action sequences per screenshot to
enhance training efficiency; (iii) Small-scale High-quality GUI
Instruction-following Datasets by careful data curation and employing a
resampling strategy to address significant data type imbalances. With above
components, ShowUI, a lightweight 2B model using 256K data, achieves a strong
75.1% accuracy in zero-shot screenshot grounding. Its UI-guided token selection
further reduces 33% of redundant visual tokens during training and speeds up
the performance by 1.4x. Navigation experiments across web Mind2Web, mobile
AITW, and online MiniWob environments further underscore the effectiveness and
potential of our model in advancing GUI visual agents. The models are available
at https://github.com/showlab/ShowUI.

æè¦ï¼<paragraph>å»ºæ§åå½¢ä½¿ç¨èä»é¢ (GUI) å©çæ¥µæææåäººé¡å·¥ä½æµç¨ççç¢åãéç¶å¤§å¤æ¸ä»£çé½æ¯åºæ¼èªè¨ï¼ä»°è³´å·æè±å¯æå­åè³è¨å°éåå§ç¢¼ APIï¼ä¾å¦ HTML æç¡éç¤æ¨¹ï¼ï¼ä½å®åå¨æç¥ä½¿ç¨èä»é¢è¦è¦ºæææ¹é¢é¡¯ç¤ºåºéå¶ï¼éå¸é¡¯äºå° GUI è¦è¦ºä»£ççéæ±ãå¨éé å·¥ä½ä¸­ï¼æåå¨æ¸ä½ä¸çä¸­éç¼äºä¸åè¦è¦ºèªè¨åä½æ¨¡åï¼å³ ShowUIï¼å¶å·æä»¥ä¸åµæ°åè½ï¼(i) UI å¼å°è¦è¦ºä»£å¹£é¸æï¼ééå°è¢å¹æªåè¡¨è¿°çº UI é£æ¥åï¼èªé©æå°è­å¥å¶åé¤éä¿ï¼ä¸¦ä½çºèªæ³¨æååå¡ä¸­ä»£å¹£é¸æçæºåï¼ä»¥éä½éç®ææ¬ï¼(ii) äº¤é¯è¦è¦ºèªè¨åä½ä¸²æµï¼éæ´»å°çµ±ä¸ GUI ä»»åä¸­çåç¨®éæ±ï¼å¨å°è¦½ä¸­ææç®¡çè¦è¦ºåä½æ­·ç¨ï¼æéå°æ¯åè¢å¹æªåçå¤è¼ªæ¥è©¢åä½åºåï¼ä»¥æåè¨ç·´æçï¼(iii) å°è¦æ¨¡é«åè³ª GUI æä»¤éµå¾ªè³æéï¼ééä»ç´°çè³ææ´çåæ¡ç¨åæ½æ¨£ç­ç¥ï¼ä¾è§£æ±ºé¡¯èçè³æé¡åä¸å¹³è¡¡ãShowUI æ¯ä¸åä½¿ç¨ 256K è³æçè¼éç´ 2B æ¨¡åï¼å·åä¸è¿°çµæé¨åï¼å¨é¶æ¬¡æ¹è¢å¹æªåæ¥å°ä¸­éå°å¼·åç 75.1% ç²¾ç¢ºåº¦ãå¶ UI å¼å°ä»£å¹£é¸æé²ä¸æ­¥æ¸å°äºè¨ç·´æé 33% çåé¤è¦è¦ºä»£å¹£ï¼ä¸¦å°æè½æåäº 1.4 åãè·¨ç¶²è·¯ Mind2Webãè¡å AITW åç·ä¸ MiniWob ç°å¢çå°è¦½å¯¦é©é²ä¸æ­¥å¼·èª¿äºæåçæ¨¡åå¨æ¨é² GUI è¦è¦ºä»£çæ¹é¢çæææ§åæ½åãéäºæ¨¡åå¯å¨ https://github.com/showlab/ShowUI åå¾ã</paragraph>

##### **Can LLMs be Good Graph Judger for Knowledge Graph Construction?**
2411.17388v1 by Haoyu Huang, Chong Chen, Conghui He, Yang Li, Jiawei Jiang, Wentao Zhang

In real-world scenarios, most of the data obtained from information retrieval
(IR) system is unstructured. Converting natural language sentences into
structured Knowledge Graphs (KGs) remains a critical challenge. The quality of
constructed KGs may also impact the performance of some KG-dependent domains
like GraphRAG systems and recommendation systems. Recently, Large Language
Models (LLMs) have demonstrated impressive capabilities in addressing a wide
range of natural language processing tasks. However, there are still challenges
when utilizing LLMs to address the task of generating structured KGs. And we
have identified three limitations with respect to existing KG construction
methods. (1)There is a large amount of information and excessive noise in
real-world documents, which could result in extracting messy information.
(2)Native LLMs struggle to effectively extract accuracy knowledge from some
domain-specific documents. (3)Hallucinations phenomenon cannot be overlooked
when utilizing LLMs directly as an unsupervised method for constructing KGs.
  In this paper, we propose GraphJudger, a knowledge graph construction
framework to address the aforementioned challenges. We introduce three
innovative modules in our method, which are entity-centric iterative text
denoising, knowledge aware instruction tuning and graph judgement,
respectively. We seek to utilize the capacity of LLMs to function as a graph
judger, a capability superior to their role only as a predictor for KG
construction problems. Experiments conducted on two general text-graph pair
datasets and one domain-specific text-graph pair dataset show superior
performances compared to baseline methods. The code of our proposed method is
available at https://github.com/hhy-huang/GraphJudger.

æè¦ï¼<paragraph>å¨ç¾å¯¦ä¸ççå ´æ¯ä¸­ï¼å¾è³è¨æª¢ç´¢ (IR) ç³»çµ±åå¾çå¤§é¨åè³æé½æ¯éçµæ§åçãå°èªç¶èªè¨å¥å­è½æçºçµæ§åçç¥è­åè­ (KG) ä»ç¶æ¯ä¸é éå¤§çææ°ãå·²å»ºæ§ç KG åè³ªä¹å¯è½å½±é¿æäºä¾è³´ KG çé åï¼ä¾å¦ GraphRAG ç³»çµ±åæ¨è¦ç³»çµ±çæè½ãæè¿ï¼å¤§åèªè¨æ¨¡å (LLM) å·²å±ç¾åºä»¤äººå°è±¡æ·±å»çè½åï¼è½èçå»£æ³çèªç¶èªè¨èçä»»åãç¶èï¼ç¶å©ç¨ LLM ä¾èçç¢ççµæ§å KG çä»»åæï¼ä»ç¶å­å¨ææ°ãæåå·²éå°ç¾æç KG å»ºæ§æ¹æ³æ¾åºä¸åéå¶ã(1) å¨ç¾å¯¦ä¸ççæä»¶ä¸­æå¤§éçè³è¨åéå¤çéè¨ï¼éå¯è½æå°è´èåéäºçè³è¨ã(2) åç LLM é£ä»¥å¾æäºç¹å®é åçæä»¶ä¸­ææèåç²¾ç¢ºçç¥è­ã(3) å¨å° LLM ç´æ¥ç¨ä½å»ºæ§ KG çéç£ç£å¼æ¹æ³æï¼ç¡æ³å¿½ç¥å¹»è¦ºç¾è±¡ãå¨æ¬æä¸­ï¼æåæåº GraphJudgerï¼éæ¯ä¸åç¥è­åè­å»ºæ§æ¶æ§ï¼ç¨æ¼è§£æ±ºä¸è¿°ææ°ãæåå¨æ¹æ³ä¸­å¼å¥äºä¸ååµæ°çæ¨¡çµï¼åå¥æ¯å¯¦é«çºä¸­å¿çåè¦æå­å»éè¨ãç¥è­æç¥æä»¤å¾®èª¿ååå½¢å¤æ·ãæåå°æ±å©ç¨ LLM çè½åï¼ä½¿å¶ç¼æ®åå½¢å¤æ·èçåè½ï¼éé è½ååªæ¼å¶åä½çº KG å»ºæ§åé¡é æ¸¬èçè§è²ãå¨å©åä¸è¬æå­åå½¢éå°è³æéåä¸åç¹å®é åæå­åå½¢éå°è³æéä¸é²è¡çå¯¦é©é¡¯ç¤ºï¼èåºç·æ¹æ³ç¸æ¯ï¼å¶æè½åªç°ãæåæåºçæ¹æ³çç¨å¼ç¢¼å¯æ¼ https://github.com/hhy-huang/GraphJudger åå¾ã</paragraph>

##### **Interleaved Scene Graph for Interleaved Text-and-Image Generation Assessment**
2411.17188v1 by Dongping Chen, Ruoxi Chen, Shu Pu, Zhaoyi Liu, Yanru Wu, Caixi Chen, Benlin Liu, Yue Huang, Yao Wan, Pan Zhou, Ranjay Krishna

Many real-world user queries (e.g. "How do to make egg fried rice?") could
benefit from systems capable of generating responses with both textual steps
with accompanying images, similar to a cookbook. Models designed to generate
interleaved text and images face challenges in ensuring consistency within and
across these modalities. To address these challenges, we present ISG, a
comprehensive evaluation framework for interleaved text-and-image generation.
ISG leverages a scene graph structure to capture relationships between text and
image blocks, evaluating responses on four levels of granularity: holistic,
structural, block-level, and image-specific. This multi-tiered evaluation
allows for a nuanced assessment of consistency, coherence, and accuracy, and
provides interpretable question-answer feedback. In conjunction with ISG, we
introduce a benchmark, ISG-Bench, encompassing 1,150 samples across 8
categories and 21 subcategories. This benchmark dataset includes complex
language-vision dependencies and golden answers to evaluate models effectively
on vision-centric tasks such as style transfer, a challenging area for current
models. Using ISG-Bench, we demonstrate that recent unified vision-language
models perform poorly on generating interleaved content. While compositional
approaches that combine separate language and image models show a 111%
improvement over unified models at the holistic level, their performance
remains suboptimal at both block and image levels. To facilitate future work,
we develop ISG-Agent, a baseline agent employing a "plan-execute-refine"
pipeline to invoke tools, achieving a 122% performance improvement.

æè¦ï¼è¨±å¤çå¯¦ä¸ççä½¿ç¨èæ¥è©¢ï¼ä¾å¦ãå¦ä½è£½ä½èçé£¯ï¼ãï¼å¯ä»¥åçæ¼è½å¤ ç¢çåå«æå­æ­¥é©åéå¸¶åççåæçç³»çµ±ï¼é¡ä¼¼æ¼é£è­ãå°éç¨æ¼ç¢çäº¤é¯ææ¬ååççæ¨¡åé¢è¨ç¢ºä¿éäºæ¹å¼å§é¨åä¹éçä¸è´æ§çææ°ãçºäºæå°éäºææ°ï¼æåæåºäº ISGï¼ä¸åç¨æ¼äº¤é¯ææ¬ååçç¢ççç¶åè©ä¼°æ¶æ§ãISG å©ç¨å ´æ¯åçµæ§ä¾ææææ¬ååçåå¡ä¹éçéä¿ï¼å¨ååå±¤ç´çç²åº¦ä¸è©ä¼°åæï¼æ´é«ãçµæ§ãåå¡å±¤ç´ååçç¹å®ãéç¨®å¤å±¤è©ä¼°åè¨±å°ä¸è´æ§ãé£è²«æ§åæºç¢ºæ§é²è¡ç´°ç·»çè©ä¼°ï¼ä¸¦æä¾å¯è§£éçåé¡è§£ç­åé¥ãçµå ISGï¼æåå¼å¥äºåºæº ISG-Benchï¼æ¶µè 8 åé¡å¥å 21 åå­é¡å¥ä¸­ç 1,150 åç¯ä¾ãéååºæºè³æéåå«è¤éçèªè¨è¦è¦ºä¾è³´éä¿åé»éç­æ¡ï¼ä»¥ææè©ä¼°æ¨¡åå¨ä»¥è¦è¦ºçºä¸­å¿çä»»åï¼ä¾å¦é¢¨æ ¼è½ç§»ï¼ä¸çè¡¨ç¾ï¼éæ¯ç¶åæ¨¡åé¢è¨çææ°é åãä½¿ç¨ ISG-Benchï¼æåè­æäºæè¿ççµ±ä¸è¦è¦ºèªè¨æ¨¡åå¨ç¢çäº¤é¯å§å®¹ä¸çè¡¨ç¾ä¸ä½³ãéç¶çµåå®ç¨èªè¨ååçæ¨¡åççµåæ¹æ³å¨æ´é«å±¤ç´ä¸æ¯çµ±ä¸æ¨¡åæåäº 111%ï¼ä½å®åå¨åå¡ååçå±¤ç´ä¸çè¡¨ç¾ä»ç¶ä¸ä½³ãçºäºä¿é²å¾çºå·¥ä½ï¼æåéç¼äº ISG-Agentï¼ä¸åæ¡ç¨ãè¨ç«å·è¡ä¿®æ­£ãç®¡ç·çåºæºä»£çï¼ç¨æ¼å¼å«å·¥å·ï¼å¯¦ç¾äº 122% çæè½æåã

##### **AtomR: Atomic Operator-Empowered Large Language Models for Heterogeneous Knowledge Reasoning**
2411.16495v2 by Amy Xin, Jinxin Liu, Zijun Yao, Zhicheng Lee, Shulin Cao, Lei Hou, Juanzi Li

Recent advancements in large language models (LLMs) have led to significant
improvements in various natural language processing tasks, but it is still
challenging for LLMs to perform knowledge-intensive complex question answering
due to LLMs' inefficacy in reasoning planning and the hallucination problem. A
typical solution is to employ retrieval-augmented generation (RAG) coupled with
chain-of-thought (CoT) reasoning, which decomposes complex questions into
chain-like sub-questions and applies iterative RAG at each sub-question.
However, prior works exhibit sub-optimal reasoning planning and overlook
dynamic knowledge retrieval from heterogeneous sources. In this paper, we
propose AtomR, a novel heterogeneous knowledge reasoning framework that
conducts multi-source reasoning at the atomic level. Drawing inspiration from
the graph modeling of knowledge, AtomR leverages large language models (LLMs)
to decompose complex questions into combinations of three atomic knowledge
operators, significantly enhancing the reasoning process at both the planning
and execution stages. We also introduce BlendQA, a novel evaluation benchmark
tailored to assess complex heterogeneous knowledge reasoning. Experiments show
that AtomR significantly outperforms state-of-the-art baselines across three
single-source and two multi-source reasoning benchmarks, with notable
performance gains of 9.4% on 2WikiMultihop and 9.5% on BlendQA.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) çææ°é²å±å·²å¤§å¹æååç¨®èªç¶èªè¨èçä»»åçè¡¨ç¾ï¼ä½ LLM ä»é£ä»¥å·è¡ç¥è­å¯éåè¤éåé¡è§£ç­ï¼åå å¨æ¼ LLM å¨æ¨çè¦ååå¹»è¦ºåé¡æ¹é¢æçä¸å½°ãå¸åçè§£æ±ºæ¹æ¡æ¯æ¡ç¨æª¢ç´¢å¢å¼·çæ (RAG) æ­éæç¶­é (CoT) æ¨çï¼å°è¤éåé¡åè§£æéçå­åé¡ï¼ä¸¦å¨æ¯åå­åé¡å¥ç¨åè¦ RAGãç¶èï¼ååçç ç©¶å±ç¾åºæ¬¡ä½³æ¨çè¦åï¼ä¸¦å¿½ç¥å¾ç°è³ªä¾æºé²è¡åæç¥è­æª¢ç´¢ãå¨æ¬æä¸­ï¼æåæåº AtomRï¼ä¸åæ°ç©çç°è³ªç¥è­æ¨çæ¶æ§ï¼å¨åå­å±¤ç´é²è¡å¤ä¾æºæ¨çãAtomR å¾ç¥è­çåå½¢å»ºæ¨¡ä¸­æ±²åéæï¼å©ç¨å¤§åèªè¨æ¨¡å (LLM) å°è¤éåé¡åè§£æä¸ç¨®åå­ç¥è­éç®å­ççµåï¼å¤§å¹æåè¦ååå·è¡éæ®µçæ¨çç¨åºãæåä¹å¼é² BlendQAï¼ä¸åæ°ç©çè©éåºæºï¼å°éç¨æ¼è©ä¼°è¤éç°è³ªç¥è­æ¨çãå¯¦é©é¡¯ç¤ºï¼AtomR å¨ä¸åå®ä¸ä¾æºåå©åå¤ä¾æºæ¨çåºæºä¸­ï¼è¡¨ç¾é¡¯èåªæ¼ç¾ææè¡åºç·ï¼å¨ 2WikiMultihop ä¸ç²å¾ 9.4% çé¡¯èæè½æåï¼å¨ BlendQA ä¸ç²å¾ 9.5% çæåã

##### **Learning by Analogy: Enhancing Few-Shot Prompting for Math Word Problem Solving with Computational Graph-Based Retrieval**
2411.16454v1 by Xiaocong Yang, Jiacheng Lin, Ziqi Wang, Chengxiang Zhai

Large language models (LLMs) are known to struggle with complicated reasoning
tasks such as math word problems (MWPs). In this paper, we present how analogy
from similarly structured questions can improve LLMs' problem-solving
capabilities for MWPs. Specifically, we rely on the retrieval of problems with
similar computational graphs to the given question to serve as exemplars in the
prompt, providing the correct reasoning path for the generation model to refer
to. Empirical results across six math word problem datasets demonstrate the
effectiveness of our proposed method, which achieves a significant improvement
of up to 6.7 percent on average in absolute value, compared to baseline
methods. These results highlight our method's potential in addressing the
reasoning challenges in current LLMs.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å·²ç¥å¨è¤éæ¨çä»»åï¼ä¾å¦æ¸å­¸æå­é¡ (MWP)ï¼ä¸­æéå°å°é£ãå¨æ¬æä¸­ï¼æåå±ç¤ºäºä¾èªçµæ§ç¸ä¼¼çåé¡çé¡æ¯å¦ä½è½æ¹å LLM å° MWP çåé¡è§£æ±ºè½åãå·é«ä¾èªªï¼æåä¾è³´æ¼æ·åèçµ¦å®åé¡å·æé¡ä¼¼éç®åå½¢çåé¡ï¼ä½çºæç¤ºä¸­çç¯ä¾ï¼çºçææ¨¡åæä¾æ­£ç¢ºçæ¨çè·¯å¾ä»¥ä¾åèãå­åæ¸å­¸æå­é¡æ¸æéçå¯¦è­çµæè­æäºæåæåºçæ¹æ³çæææ§ï¼èåºç·æ¹æ³ç¸æ¯ï¼å¹³åçµå°å¼æé«äº 6.7 åç¾åé»ãéäºçµæçªåºäºæåçæ¹æ³å¨è§£æ±ºç¶å LLM ä¸­çæ¨çææ°æ¹é¢çæ½åã

##### **Adapter-based Approaches to Knowledge-enhanced Language Models -- A Survey**
2411.16403v1 by Alexander Fichtl, Juraj Vladika, Georg Groh

Knowledge-enhanced language models (KELMs) have emerged as promising tools to
bridge the gap between large-scale language models and domain-specific
knowledge. KELMs can achieve higher factual accuracy and mitigate
hallucinations by leveraging knowledge graphs (KGs). They are frequently
combined with adapter modules to reduce the computational load and risk of
catastrophic forgetting. In this paper, we conduct a systematic literature
review (SLR) on adapter-based approaches to KELMs. We provide a structured
overview of existing methodologies in the field through quantitative and
qualitative analysis and explore the strengths and potential shortcomings of
individual approaches. We show that general knowledge and domain-specific
approaches have been frequently explored along with various adapter
architectures and downstream tasks. We particularly focused on the popular
biomedical domain, where we provided an insightful performance comparison of
existing KELMs. We outline the main trends and propose promising future
directions.

æè¦ï¼ç¥è­å¢å¼·èªè¨æ¨¡åï¼KELMï¼å·²æçºå½åå¤§è¦æ¨¡èªè¨æ¨¡åèç¹å®é åç¥è­å·®è·çæåéçå·¥å·ãKELM å¯ä»¥ééå©ç¨ç¥è­åè­ï¼KGï¼ä¾æé«äºå¯¦æºç¢ºæ§ä¸¦æ¸å°å¹»è¦ºãå®åç¶å¸¸èé©éå¨æ¨¡çµçµåä½¿ç¨ï¼ä»¥éä½éç®è² è¼åç½é£æ§éºå¿çé¢¨éªãå¨æ¬æä¸­ï¼æåå°åºæ¼é©éå¨ç KELM æ¹æ³é²è¡ç³»çµ±æ§çæç»åé¡§ï¼SLRï¼ãæåééå®éåå®æ§åææä¾è©²é åæ¢ææ¹æ³è«ççµæ§åæ¦è§ï¼ä¸¦æ¢è¨åå¥æ¹æ³çåªé»åæ½å¨ç¼ºé»ãæåè¡¨æï¼ä¸è¬ç¥è­åç¹å®é åçæ¹æ³å·²èåç¨®é©éå¨æ¶æ§åä¸æ¸¸ä»»åä¸èµ·è¢«é »ç¹æ¢ç´¢ãæåç¹å¥éæ³¨ç±éççç©é«å­¸é åï¼å¨è©²é åä¸­ï¼æåæä¾äºç¾æ KELM çæè¦å°æè½æ¯è¼ãæåæ¦è¿°äºä¸»è¦è¶¨å¢ï¼ä¸¦æåºäºæåéçæªä¾æ¹åã

##### **Decoding Urban Industrial Complexity: Enhancing Knowledge-Driven Insights via IndustryScopeGPT**
2411.15758v1 by Siqi Wang, Chao Liang, Yunfan Gao, Yang Liu, Jing Li, Haofen Wang

Industrial parks are critical to urban economic growth. Yet, their
development often encounters challenges stemming from imbalances between
industrial requirements and urban services, underscoring the need for strategic
planning and operations. This paper introduces IndustryScopeKG, a pioneering
large-scale multi-modal, multi-level industrial park knowledge graph, which
integrates diverse urban data including street views, corporate,
socio-economic, and geospatial information, capturing the complex relationships
and semantics within industrial parks. Alongside this, we present the
IndustryScopeGPT framework, which leverages Large Language Models (LLMs) with
Monte Carlo Tree Search to enhance tool-augmented reasoning and decision-making
in Industrial Park Planning and Operation (IPPO). Our work significantly
improves site recommendation and functional planning, demonstrating the
potential of combining LLMs with structured datasets to advance industrial park
management. This approach sets a new benchmark for intelligent IPPO research
and lays a robust foundation for advancing urban industrial development. The
dataset and related code are available at
https://github.com/Tongji-KGLLM/IndustryScope.

æè¦ï¼å·¥æ¥­ååå°æ¼é½å¸ç¶æ¿æé·è³ééè¦ãç¶èï¼å¶ç¼å±ç¶å¸¸æéå°å·¥æ¥­éæ±èé½å¸æåä¹éä¸å¹³è¡¡æç¢ççææ°ï¼éå¸é¡¯äºç­ç¥æ§è¦åèçéçéæ±ãæ¬æä»ç´¹äº IndustryScopeKGï¼ä¸ååé©æ§çãå¤§è¦æ¨¡ãå¤æ¨¡å¼ãå¤å±¤ç´çå·¥æ¥­ååç¥è­åè­ï¼å®æ´åäºåå«è¡æ¯ãå¬å¸ãç¤¾æç¶æ¿åå°çç©ºéè³è¨å¨å§çåç¨®é½å¸è³æï¼ææå·¥æ¥­ååå§è¤éçéä¿åèªæãé¤æ­¤ä¹å¤ï¼æåæåºäº IndustryScopeGPT æ¶æ§ï¼å®å©ç¨å¤§åèªè¨æ¨¡å (LLM) èèå°å¡ç¾æ¨¹çæå°ï¼ä»¥å¢å¼·å·¥å·è¼å©æ¨çåå¨å·¥æ¥­ååè¦ååçé (IPPO) ä¸­çæ±ºç­å¶å®ãæåçç ç©¶å¤§å¹æ¹åäºå ´å°æ¨è¦ååè½è¦åï¼å±ç¤ºäºçµå LLM åçµæ§åè³æéä»¥æ¨é²å·¥æ¥­ååç®¡ççæ½åãéåæ¹æ³çºæºæ§ IPPO ç ç©¶è¨­å®äºæ°çåºæºï¼ä¸¦çºæ¨é²é½å¸ç¢æ¥­ç¼å±å¥ å®äºç©©åºçåºç¤ãè³æéåç¸éç¨å¼ç¢¼å¯å¨ https://github.com/Tongji-KGLLM/IndustryScope åå¾ã


### Medical
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-12-19**|**GIRAFE: Glottal Imaging Dataset for Advanced Segmentation, Analysis, and Facilitative Playbacks Evaluation**|G. Andrade-Miranda et.al.|[2412.15054v1](http://arxiv.org/abs/2412.15054v1)|null|
|**2024-12-19**|**RobustFT: Robust Supervised Fine-tuning for Large Language Models under Noisy Response**|Junyu Luo et.al.|[2412.14922v1](http://arxiv.org/abs/2412.14922v1)|[link](https://github.com/luo-junyu/robustft)|
|**2024-12-19**|**Advances in Artificial Intelligence forDiabetes Prediction: Insights from a Systematic Literature Review**|Pir Bakhsh Khokhar et.al.|[2412.14736v1](http://arxiv.org/abs/2412.14736v1)|null|
|**2024-12-19**|**Pitfalls of topology-aware image segmentation**|Alexander H. Berger et.al.|[2412.14619v1](http://arxiv.org/abs/2412.14619v1)|[link](https://github.com/alexanderhberger/topo-pitfalls)|
|**2024-12-19**|**CAE-T: A Channelwise AutoEncoder with Transformer for EEG Abnormality Detection**|Youshen Zhao et.al.|[2412.14522v1](http://arxiv.org/abs/2412.14522v1)|[link](https://github.com/yossizhao/cae-t)|
|**2024-12-19**|**GenHMR: Generative Human Mesh Recovery**|Muhammad Usama Saleem et.al.|[2412.14444v1](http://arxiv.org/abs/2412.14444v1)|null|
|**2024-12-19**|**FedPIA -- Permuting and Integrating Adapters leveraging Wasserstein Barycenters for Finetuning Foundation Models in Multi-Modal Federated Learning**|Pramit Saha et.al.|[2412.14424v1](http://arxiv.org/abs/2412.14424v1)|null|
|**2024-12-18**|**Clinical Trials Ontology Engineering with Large Language Models**|Berkan ÃakÄ±r et.al.|[2412.14387v1](http://arxiv.org/abs/2412.14387v1)|null|
|**2024-12-18**|**Multi-OphthaLingua: A Multilingual Benchmark for Assessing and Debiasing LLM Ophthalmological QA in LMICs**|David Restrepo et.al.|[2412.14304v1](http://arxiv.org/abs/2412.14304v1)|null|
|**2024-12-18**|**Discovering maximally consistent distribution of causal tournaments with Large Language Models**|Federico Baldo et.al.|[2412.14019v1](http://arxiv.org/abs/2412.14019v1)|null|
|**2024-12-18**|**SurgSora: Decoupled RGBD-Flow Diffusion Model for Controllable Surgical Video Generation**|Tong Chen et.al.|[2412.14018v1](http://arxiv.org/abs/2412.14018v1)|null|
|**2024-12-18**|**Cognition Chain for Explainable Psychological Stress Detection on Social Media**|Xin Wang et.al.|[2412.14009v1](http://arxiv.org/abs/2412.14009v1)|null|
|**2024-12-18**|**Federated Learning and RAG Integration: A Scalable Approach for Medical Large Language Models**|Jincheol Jung et.al.|[2412.13720v1](http://arxiv.org/abs/2412.13720v1)|null|
|**2024-12-18**|**Clio: Privacy-Preserving Insights into Real-World AI Use**|Alex Tamkin et.al.|[2412.13678v1](http://arxiv.org/abs/2412.13678v1)|null|
|**2024-12-18**|**Exploring Multi-Modal Integration with Tool-Augmented LLM Agents for Precise Causal Discovery**|ChengAo Shen et.al.|[2412.13667v1](http://arxiv.org/abs/2412.13667v1)|null|
|**2024-12-17**|**BadSAD: Clean-Label Backdoor Attacks against Deep Semi-Supervised Anomaly Detection**|He Cheng et.al.|[2412.13324v1](http://arxiv.org/abs/2412.13324v1)|null|
|**2024-12-17**|**In-context learning for medical image segmentation**|Eichi Takaya et.al.|[2412.13299v1](http://arxiv.org/abs/2412.13299v1)|null|
|**2024-12-17**|**Continuous Patient Monitoring with AI: Real-Time Analysis of Video in Hospital Care Settings**|Paolo Gabriel et.al.|[2412.13152v1](http://arxiv.org/abs/2412.13152v1)|null|
|**2024-12-17**|**Boosting Fine-Grained Visual Anomaly Detection with Coarse-Knowledge-Aware Adversarial Learning**|Qingqing Fang et.al.|[2412.12850v1](http://arxiv.org/abs/2412.12850v1)|[link](https://github.com/Faustinaqq/CKAAD)|
|**2024-12-17**|**Rethinking Diffusion-Based Image Generators for Fundus Fluorescein Angiography Synthesis on Limited Data**|Chengzhou Yu et.al.|[2412.12778v1](http://arxiv.org/abs/2412.12778v1)|null|
|**2024-12-17**|**MedMax: Mixed-Modal Instruction Tuning for Training Biomedical Assistants**|Hritik Bansal et.al.|[2412.12661v1](http://arxiv.org/abs/2412.12661v1)|[link](https://github.com/Hritikbansal/medmax)|
|**2024-12-17**|**a2z-1 for Multi-Disease Detection in Abdomen-Pelvis CT: External Validation and Performance Analysis Across 21 Conditions**|Pranav Rajpurkar et.al.|[2412.12629v1](http://arxiv.org/abs/2412.12629v1)|null|
|**2024-12-17**|**A Scalable Approach to Benchmarking the In-Conversation Differential Diagnostic Accuracy of a Health AI**|Deep Bhatt et.al.|[2412.12538v1](http://arxiv.org/abs/2412.12538v1)|null|
|**2024-12-17**|**Addressing Small and Imbalanced Medical Image Datasets Using Generative Models: A Comparative Study of DDPM and PGGANs with Random and Greedy K Sampling**|Iman Khazrak et.al.|[2412.12532v1](http://arxiv.org/abs/2412.12532v1)|[link](https://github.com/imankhazrak/DDPM_X-Ray)|
|**2024-12-17**|**RareAgents: Autonomous Multi-disciplinary Team for Rare Disease Diagnosis and Treatment**|Xuanzhong Chen et.al.|[2412.12475v1](http://arxiv.org/abs/2412.12475v1)|null|
|**2024-12-16**|**Bridging the Gap: Enhancing LLM Performance for Low-Resource African Languages with New Benchmarks, Fine-Tuning, and Cultural Adjustments**|Tuka Alhanai et.al.|[2412.12417v1](http://arxiv.org/abs/2412.12417v1)|[link](https://github.com/InstituteforDiseaseModeling/Bridging-the-Gap-Low-Resource-African-Languages)|
|**2024-12-16**|**The Impact of AI Assistance on Radiology Reporting: A Pilot Study Using Simulated AI Draft Reports**|JuliÃ¡n N. Acosta et.al.|[2412.12042v1](http://arxiv.org/abs/2412.12042v1)|null|
|**2024-12-16**|**Combining Large Language Models with Tutoring System Intelligence: A Case Study in Caregiver Homework Support**|Devika Venugopalan et.al.|[2412.11995v1](http://arxiv.org/abs/2412.11995v1)|[link](https://github.com/devika-prog/caregiver-conversational-support-tool)|
|**2024-12-16**|**LLMs Can Simulate Standardized Patients via Agent Coevolution**|Zhuoyun Du et.al.|[2412.11716v1](http://arxiv.org/abs/2412.11716v1)|null|
|**2024-12-16**|**Fast-staged CNN Model for Accurate pulmonary diseases and Lung cancer detection**|Abdelbaki Souid et.al.|[2412.11681v1](http://arxiv.org/abs/2412.11681v1)|null|
|**2024-12-16**|**BioBridge: Unified Bio-Embedding with Bridging Modality in Code-Switched EMR**|Jangyeong Jeon et.al.|[2412.11671v1](http://arxiv.org/abs/2412.11671v1)|[link](https://github.com/jjy961228/biobridge)|
|**2024-12-16**|**Leveraging Foundation Language Models (FLMs) for Automated Cohort Extraction from Large EHR Databases**|Purity Mugambi et.al.|[2412.11472v1](http://arxiv.org/abs/2412.11472v1)|null|
|**2024-12-16**|**FedCAR: Cross-client Adaptive Re-weighting for Generative Models in Federated Learning**|Minjun Kim et.al.|[2412.11463v1](http://arxiv.org/abs/2412.11463v1)|[link](https://github.com/danny0628/fedcar)|
|**2024-12-16**|**ACE-$M^3$: Automatic Capability Evaluator for Multimodal Medical Models**|Xiechi Zhang et.al.|[2412.11453v1](http://arxiv.org/abs/2412.11453v1)|null|
|**2024-12-15**|**Detecting Daily Living Gait Amid Huntington's Disease Chorea using a Foundation Deep Learning Model**|Dafna Schwartz et.al.|[2412.11286v1](http://arxiv.org/abs/2412.11286v1)|[link](https://github.com/dafnaschwartz/hd_gait_detection_with_ssl)|
|**2024-12-15**|**Wearable Accelerometer Foundation Models for Health via Knowledge Distillation**|Salar Abbaspourazad et.al.|[2412.11276v1](http://arxiv.org/abs/2412.11276v1)|null|
|**2024-12-15**|**TrimLLM: Progressive Layer Dropping for Domain-Specific LLMs**|Lanxiang Hu et.al.|[2412.11242v2](http://arxiv.org/abs/2412.11242v2)|null|
|**2024-12-15**|**Efficient Quantization-Aware Training on Segment Anything Model in Medical Images and Its Deployment**|Haisheng Lu et.al.|[2412.11186v1](http://arxiv.org/abs/2412.11186v1)|[link](https://github.com/avc2-uestc/qmedsam)|
|**2024-12-15**|**AD-LLM: Benchmarking Large Language Models for Anomaly Detection**|Tiankai Yang et.al.|[2412.11142v1](http://arxiv.org/abs/2412.11142v1)|[link](https://github.com/usc-fortis/ad-llm)|
|**2024-12-15**|**Decoding Drug Discovery: Exploring A-to-Z In silico Methods for Beginners**|Hezha O. Rasul et.al.|[2412.11137v1](http://arxiv.org/abs/2412.11137v1)|null|
|**2024-12-14**|**MedG-KRP: Medical Graph Knowledge Representation Probing**|Gabriel R. Rosenbaum et.al.|[2412.10982v2](http://arxiv.org/abs/2412.10982v2)|null|
|**2024-12-14**|**LLMs-in-the-Loop Part 2: Expert Small AI Models for Anonymization and De-identification of PHI Across Multiple Languages**|Murat Gunay et.al.|[2412.10918v1](http://arxiv.org/abs/2412.10918v1)|null|
|**2024-12-14**|**Superhuman performance of a large language model on the reasoning tasks of a physician**|Peter G. Brodeur et.al.|[2412.10849v1](http://arxiv.org/abs/2412.10849v1)|null|
|**2024-12-14**|**Large Language Models for Medical Forecasting -- Foresight 2**|Zeljko Kraljevic et.al.|[2412.10848v1](http://arxiv.org/abs/2412.10848v1)|null|
|**2024-12-14**|**Generative AI: A Pix2pix-GAN-Based Machine Learning Approach for Robust and Efficient Lung Segmentation**|Sharmin Akter et.al.|[2412.10826v1](http://arxiv.org/abs/2412.10826v1)|null|
|**2024-12-14**|**Medical Manifestation-Aware De-Identification**|Yuan Tian et.al.|[2412.10804v1](http://arxiv.org/abs/2412.10804v1)|[link](https://github.com/tianyuan168326/mema-pytorch)|
|**2024-12-14**|**Rapid Reconstruction of Extremely Accelerated Liver 4D MRI via Chained Iterative Refinement**|Di Xu et.al.|[2412.10629v1](http://arxiv.org/abs/2412.10629v1)|null|
|**2024-12-14**|**A recent evaluation on the performance of LLMs on radiation oncology physics using questions of randomly shuffled options**|Peilong Wang et.al.|[2412.10622v1](http://arxiv.org/abs/2412.10622v1)|null|
|**2024-12-13**|**Generative AI in Medicine**|Divya Shanmugam et.al.|[2412.10337v2](http://arxiv.org/abs/2412.10337v2)|null|
|**2024-12-13**|**A Cascaded Dilated Convolution Approach for Mpox Lesion Classification**|Ayush Deshmukh et.al.|[2412.10106v1](http://arxiv.org/abs/2412.10106v1)|null|
|**2024-12-13**|**Cycle-Consistent Bridge Diffusion Model for Accelerated MRI Reconstruction**|Tao Song et.al.|[2412.09998v1](http://arxiv.org/abs/2412.09998v1)|null|
|**2024-12-13**|**Enhancing Nursing and Elderly Care with Large Language Models: An AI-Driven Framework**|Qiao Sun et.al.|[2412.09946v1](http://arxiv.org/abs/2412.09946v1)|null|
|**2024-12-12**|**Detecting Cognitive Impairment and Psychological Well-being among Older Adults Using Facial, Acoustic, Linguistic, and Cardiovascular Patterns Derived from Remote Conversations**|Xiaofan Mu et.al.|[2412.14194v1](http://arxiv.org/abs/2412.14194v1)|null|
|**2024-12-12**|**Efficient and Comprehensive Feature Extraction in Large Vision-Language Model for Clinical Pathology Analysis**|Shengxuming Zhang et.al.|[2412.09521v1](http://arxiv.org/abs/2412.09521v1)|null|
|**2024-12-12**|**Towards a Multimodal Large Language Model with Pixel-Level Insight for Biomedicine**|Xiaoshuang Huang et.al.|[2412.09278v1](http://arxiv.org/abs/2412.09278v1)|[link](https://github.com/shawnhuang497/medplib)|
|**2024-12-12**|**CSSDH: An Ontology for Social Determinants of Health to Operational Continuity of Care Data Interoperability**|Subhashis Das et.al.|[2412.09223v1](http://arxiv.org/abs/2412.09223v1)|null|
|**2024-12-12**|**Understanding Opportunities and Risks of Synthetic Relationships: Leveraging the Power of Longitudinal Research with Customised AI Tools**|Alfio Ventura et.al.|[2412.09086v1](http://arxiv.org/abs/2412.09086v1)|null|
|**2024-12-12**|**An Interoperable Machine Learning Pipeline for Pediatric Obesity Risk Estimation**|Hamed Fayyaz et.al.|[2412.10454v1](http://arxiv.org/abs/2412.10454v1)|[link](https://github.com/healthylaife/fhir)|
|**2024-12-12**|**Structurally Consistent MRI Colorization using Cross-modal Fusion Learning**|Mayuri Mathur et.al.|[2412.10452v1](http://arxiv.org/abs/2412.10452v1)|null|
|**2024-12-12**|**Radiology Report Generation via Multi-objective Preference Optimization**|Ting Xiao et.al.|[2412.08901v2](http://arxiv.org/abs/2412.08901v2)|null|
|**2024-12-12**|**AI-assisted Knowledge Discovery in Biomedical Literature to Support Decision-making in Precision Oncology**|Ting He et.al.|[2412.08900v1](http://arxiv.org/abs/2412.08900v1)|null|
|**2024-12-12**|**Towards modeling evolving longitudinal health trajectories with a transformer-based deep learning model**|Hans Moen et.al.|[2412.08873v1](http://arxiv.org/abs/2412.08873v1)|null|
|**2024-12-11**|**Performance of a large language model-Artificial Intelligence based chatbot for counseling patients with sexually transmitted infections and genital diseases**|Nikhil Mehta et.al.|[2412.12166v1](http://arxiv.org/abs/2412.12166v1)|null|
|**2024-12-11**|**Multimodal Approaches to Fair Image Classification: An Ethical Perspective**|Javon Hickmon et.al.|[2412.12165v1](http://arxiv.org/abs/2412.12165v1)|null|
|**2024-12-11**|**Euclid: Supercharging Multimodal LLMs with Synthetic High-Fidelity Visual Descriptions**|Jiarui Zhang et.al.|[2412.08737v1](http://arxiv.org/abs/2412.08737v1)|null|
|**2024-12-11**|**Assisted morbidity coding: the SISCO.web use case for identifying the main diagnosis in Hospital Discharge Records**|Elena Cardillo et.al.|[2412.09651v1](http://arxiv.org/abs/2412.09651v1)|null|
|**2024-12-11**|**IRL for Restless Multi-Armed Bandits with Applications in Maternal and Child Health**|Gauri Jain et.al.|[2412.08463v1](http://arxiv.org/abs/2412.08463v1)|[link](https://github.com/gjain234/whirl)|
|**2024-12-11**|**Personalized Sleep Staging Leveraging Source-free Unsupervised Domain Adaptation**|Yangxuan Zhou et.al.|[2412.12159v1](http://arxiv.org/abs/2412.12159v1)|null|
|**2024-12-11**|**SmolTulu: Higher Learning Rate to Batch Size Ratios Can Lead to Better Reasoning in SLMs**|Sultan Alrashed et.al.|[2412.08347v1](http://arxiv.org/abs/2412.08347v1)|null|
|**2024-12-11**|**Novel 3D Binary Indexed Tree for Volume Computation of 3D Reconstructed Models from Volumetric Data**|Quoc-Bao Nguyen-Le et.al.|[2412.10441v1](http://arxiv.org/abs/2412.10441v1)|null|
|**2024-12-11**|**Hierarchical Classification for Automated Image Annotation of Coral Reef Benthic Structures**|CÃ©lia Blondin et.al.|[2412.08228v1](http://arxiv.org/abs/2412.08228v1)|[link](https://github.com/celia-bl/hierarchical_classifying_corals_dataset)|
|**2024-12-11**|**How to select slices for annotation to train best-performing deep learning segmentation models for cross-sectional medical images?**|Yixin Zhang et.al.|[2412.08081v1](http://arxiv.org/abs/2412.08081v1)|null|
|**2024-12-11**|**Can a MISL Fly? Analysis and Ingredients for Mutual Information Skill Learning**|Chongyi Zheng et.al.|[2412.08021v1](http://arxiv.org/abs/2412.08021v1)|[link](https://github.com/Princeton-RL/contrastive-successor-features)|
|**2024-12-10**|**From Lived Experience to Insight: Unpacking the Psychological Risks of Using AI Conversational Agents**|Mohit Chandra et.al.|[2412.07951v2](http://arxiv.org/abs/2412.07951v2)|null|
|**2024-12-10**|**How Should We Represent History in Interpretable Models of Clinical Policies?**|Anton Matsson et.al.|[2412.07895v1](http://arxiv.org/abs/2412.07895v1)|[link](https://github.com/Healthy-AI/inpole)|
|**2024-12-10**|**Towards Foundation-model-based Multiagent System to Accelerate AI for Social Impact**|Yunfan Zhao et.al.|[2412.07880v2](http://arxiv.org/abs/2412.07880v2)|null|
|**2024-12-10**|**Comparative Analysis of Deep Learning Approaches for Harmful Brain Activity Detection Using EEG**|Shivraj Singh Bhatti et.al.|[2412.07878v1](http://arxiv.org/abs/2412.07878v1)|null|
|**2024-12-10**|**Combining knowledge graphs and LLMs for hazardous chemical information management and reuse**|Marcos Da Silveira et.al.|[2412.09644v1](http://arxiv.org/abs/2412.09644v1)|null|
|**2024-12-10**|**Adapting to Non-Stationary Environments: Multi-Armed Bandit Enhanced Retrieval-Augmented Generation on Knowledge Graphs**|Xiaqiang Tang et.al.|[2412.07618v1](http://arxiv.org/abs/2412.07618v1)|[link](https://github.com/futureeeeee/dynamic-rag)|
|**2024-12-10**|**Scaling Sequential Recommendation Models with Transformers**|Pablo Zivic et.al.|[2412.07585v1](http://arxiv.org/abs/2412.07585v1)|[link](https://github.com/mercadolibre/srt)|
|**2024-12-10**|**Knowledge Graph Guided Evaluation of Abstention Techniques**|Kinshuk Vasisht et.al.|[2412.07430v1](http://arxiv.org/abs/2412.07430v1)|null|
|**2024-12-10**|**AutoPrep: Natural Language Question-Aware Data Preparation with a Multi-Agent Framework**|Meihao Fan et.al.|[2412.10422v1](http://arxiv.org/abs/2412.10422v1)|null|
|**2024-12-10**|**A Review of Challenges in Speech-based Conversational AI for Elderly Care**|Willemijn Klaassen et.al.|[2412.07388v1](http://arxiv.org/abs/2412.07388v1)|null|
|**2024-12-10**|**Enhanced MRI Representation via Cross-series Masking**|Churan Wang et.al.|[2412.07387v1](http://arxiv.org/abs/2412.07387v1)|null|
|**2024-12-10**|**On Evaluating the Durability of Safeguards for Open-Weight LLMs**|Xiangyu Qi et.al.|[2412.07097v1](http://arxiv.org/abs/2412.07097v1)|[link](https://github.com/ai-law-society-lab/evaluating-durable-safeguards)|
|**2024-12-09**|**Toward AI-Driven Digital Organism: Multiscale Foundation Models for Predicting, Simulating and Programming Biology at All Levels**|Le Song et.al.|[2412.06993v1](http://arxiv.org/abs/2412.06993v1)|[link](https://github.com/genbio-ai/aido)|
|**2024-12-09**|**Leveraging Audio and Text Modalities in Mental Health: A Study of LLMs Performance**|Abdelrahman A. Ali et.al.|[2412.10417v1](http://arxiv.org/abs/2412.10417v1)|null|
|**2024-12-09**|**Diagnosis and Severity Assessment of Ulcerative Colitis using Self Supervised Learning**|Venkat Margapuri et.al.|[2412.07806v1](http://arxiv.org/abs/2412.07806v1)|null|
|**2024-12-09**|**Toward Non-Invasive Diagnosis of Bankart Lesions with Deep Learning**|Sahil Sethi et.al.|[2412.06717v1](http://arxiv.org/abs/2412.06717v1)|null|
|**2024-12-09**|**Parkinson's Disease Diagnosis Through Deep Learning: A Novel LSTM-Based Approach for Freezing of Gait Detection**|Aqib Nazir Mir et.al.|[2412.06709v1](http://arxiv.org/abs/2412.06709v1)|null|
|**2024-12-09**|**Fundus Image-based Visual Acuity Assessment with PAC-Guarantees**|Sooyong Jang et.al.|[2412.06624v1](http://arxiv.org/abs/2412.06624v1)|[link](https://github.com/precise-ai4oph/va_pred_pac)|
|**2024-12-09**|**Real-Time Performance Optimization of Travel Reservation Systems Using AI and Microservices**|Biman Barua et.al.|[2412.06874v1](http://arxiv.org/abs/2412.06874v1)|null|
|**2024-12-09**|**Advancing Music Therapy: Integrating Eastern Five-Element Music Theory and Western Techniques with AI in the Novel Five-Element Harmony System**|Yubo Zhou et.al.|[2412.06600v2](http://arxiv.org/abs/2412.06600v2)|[link](https://github.com/everydaylucky/wu_xing_harmony_system)|
|**2024-12-09**|**HES-UNet: A U-Net for Hepatic Echinococcosis Lesion Segmentation**|Jiayan Chen et.al.|[2412.06530v1](http://arxiv.org/abs/2412.06530v1)|null|
|**2024-12-09**|**Simulating Human-like Daily Activities with Desire-driven Autonomy**|Yiding Wang et.al.|[2412.06435v1](http://arxiv.org/abs/2412.06435v1)|null|
|**2024-12-09**|**CAD-Unet: A Capsule Network-Enhanced Unet Architecture for Accurate Segmentation of COVID-19 Lung Infections from CT Images**|Yijie Dang et.al.|[2412.06314v1](http://arxiv.org/abs/2412.06314v1)|null|
|**2024-12-09**|**A Lightweight U-like Network Utilizing Neural Memory Ordinary Differential Equations for Slimming the Decoder**|Quansong He et.al.|[2412.06262v1](http://arxiv.org/abs/2412.06262v1)|[link](https://github.com/nayutayuki/lightweight-nmode-decoders-for-u-like-networks)|
|**2024-12-09**|**MSCrackMamba: Leveraging Vision Mamba for Crack Detection in Fused Multispectral Imagery**|Qinfeng Zhu et.al.|[2412.06211v1](http://arxiv.org/abs/2412.06211v1)|null|
|**2024-12-09**|**Balancing Efficiency and Effectiveness: An LLM-Infused Approach for Optimized CTR Prediction**|Guoxiao Zhang et.al.|[2412.06860v1](http://arxiv.org/abs/2412.06860v1)|null|
|**2024-12-09**|**MMedPO: Aligning Medical Vision-Language Models with Clinical-Aware Multimodal Preference Optimization**|Kangyu Zhu et.al.|[2412.06141v1](http://arxiv.org/abs/2412.06141v1)|[link](https://github.com/aiming-lab/mmedpo)|

#### Abstracts
##### **GIRAFE: Glottal Imaging Dataset for Advanced Segmentation, Analysis, and Facilitative Playbacks Evaluation**
2412.15054v1 by G. Andrade-Miranda, K. Chatzipapas, J. D. Arias-LondoÃ±o, J. I. Godino-Llorente

The advances in the development of Facilitative Playbacks extracted from
High-Speed videoendoscopic sequences of the vocal folds are hindered by a
notable lack of publicly available datasets annotated with the semantic
segmentations corresponding to the area of the glottal gap. This fact also
limits the reproducibility and further exploration of existing research in this
field.
  To address this gap, GIRAFE is a data repository designed to facilitate the
development of advanced techniques for the semantic segmentation, analysis, and
fast evaluation of High-Speed videoendoscopic sequences of the vocal folds. The
repository includes 65 high-speed videoendoscopic recordings from a cohort of
50 patients (30 female, 20 male). The dataset comprises 15 recordings from
healthy controls, 26 from patients with diagnosed voice disorders, and 24 with
an unknown health condition. All of them were manually annotated by an expert,
including the masks corresponding to the semantic segmentation of the glottal
gap. The repository is also complemented with the automatic segmentation of the
glottal area using different state-of-the-art approaches.
  This data set has already supported several studies, which demonstrates its
usefulness for the development of new glottal gap segmentation algorithms from
High-Speed-Videoendoscopic sequences to improve or create new Facilitative
Playbacks. Despite these advances and others in the field, the broader
challenge of performing an accurate and completely automatic semantic
segmentation method of the glottal area remains open.

æè¦ï¼<paragraph>å¾é«éè²éå§è¦é¡åºåä¸­æåçä¿é²æ§åæ¾çç¼å±é²å±åå°æé¡¯ç¼ºä¹å¬éå¯ç¨è³æéçé»ç¤ï¼éäºè³æéå¸¶æèè²éééååç¸æçèªç¾©åå²è¨»è§£ãéåäºå¯¦ä¹éå¶äºç¾æç ç©¶å¨æ­¤é åçå¯éç¾æ§åé²ä¸æ­¥æ¢ç´¢ã
  çºäºè§£æ±ºéåå·®è·ï¼GIRAFE æ¯æ¨å¨ä¿é²èªç¾©åå²ãåæåé«éè²éå§è¦é¡åºåå¿«éè©ä¼°çåé²æè¡éç¼çè³æåº«ãéåè³æåº«åå«ä¾èª 50 ä½æ£èï¼30 ä½å¥³æ§ï¼20 ä½ç·æ§ï¼ç 65 ä»½é«éè²éå§è¦é¡éé³ãè©²è³æéåå« 15 ä»½ä¾èªå¥åº·å°ç§çµçéé³ã26 ä»½ä¾èªè¢«è¨ºæ·åºæ£æè²é³éç¤çæ£èçéé³ï¼ä»¥å 24 ä»½ä¾èªå¥åº·çæ³ä¸æçæ£èçéé³ãææéäºéé³é½ç±å°å®¶æåè¨»è§£ï¼åæ¬èè²éééèªç¾©åå²ç¸æçé®ç½©ãè©²è³æåº«éä½¿ç¨ä¸åçæåé²æ¹æ³è£åäºè²éååçèªååå²ã
  æ­¤è³æéå·²ç¶æ¯æ´å¤é ç ç©¶ï¼éè­æäºå®å°æ¼å¾é«éè¦é »å§è¦é¡åºåéç¼æ°çè²éééåå²æ¼ç®æ³ä»¥æ¹åæå»ºç«æ°çä¿é²æ§åæ¾å¾æç¨ãåç®¡å¨è©²é ååå¾äºéäºé²å±åå¶ä»é²å±ï¼ä½å·è¡æºç¢ºä¸å®å¨èªååçè²éååèªç¾©åå²æ¹æ³çæ´å»£æ³ææ°ä»ç¶å­å¨ã</paragraph>

##### **RobustFT: Robust Supervised Fine-tuning for Large Language Models under Noisy Response**
2412.14922v1 by Junyu Luo, Xiao Luo, Kaize Ding, Jingyang Yuan, Zhiping Xiao, Ming Zhang

Supervised fine-tuning (SFT) plays a crucial role in adapting large language
models (LLMs) to specific domains or tasks. However, as demonstrated by
empirical experiments, the collected data inevitably contains noise in
practical applications, which poses significant challenges to model performance
on downstream tasks. Therefore, there is an urgent need for a noise-robust SFT
framework to enhance model capabilities in downstream tasks. To address this
challenge, we introduce a robust SFT framework (RobustFT) that performs noise
detection and relabeling on downstream task data. For noise identification, our
approach employs a multi-expert collaborative system with inference-enhanced
models to achieve superior noise detection. In the denoising phase, we utilize
a context-enhanced strategy, which incorporates the most relevant and confident
knowledge followed by careful assessment to generate reliable annotations.
Additionally, we introduce an effective data selection mechanism based on
response entropy, ensuring only high-quality samples are retained for
fine-tuning. Extensive experiments conducted on multiple LLMs across five
datasets demonstrate RobustFT's exceptional performance in noisy scenarios.

æè¦ï¼ç£ç£å¼å¾®èª¿ï¼SFTï¼å¨å°å¤§åèªè¨æ¨¡åï¼LLMï¼é©æå°ç¹å®é åæä»»åä¸­æ®æ¼èè³ééè¦çè§è²ãç¶èï¼æ­£å¦ç¶é©å¯¦é©æè­æï¼å¨å¯¦éæç¨ä¸­æ¶éå°çè³æä¸å¯é¿åå°åå«éè¨ï¼éå°ä¸æ¸¸ä»»åçæ¨¡åæè½æ§æäºéå¤§ææ°ãå æ­¤ï¼è¿«åéè¦ä¸åæéè¨ç SFT æ¡æ¶ï¼ä»¥å¢å¼·æ¨¡åå¨ä¸æ¸¸ä»»åä¸­çè½åãçºäºæå°éä¸ææ°ï¼æåå¼å¥äºç©©å¥ç SFT æ¡æ¶ï¼RobustFTï¼ï¼å®å°ä¸æ¸¸ä»»åè³æå·è¡éè¨åµæ¸¬åéæ°æ¨è¨ãå°æ¼éè¨è­å¥ï¼æåçæ¹æ³æ¡ç¨å¤å°å®¶åä½ç³»çµ±ï¼ä¸¦ä½¿ç¨å¢å¼·æ¨è«çæ¨¡åä¾å¯¦ç¾åªç°çéè¨åµæ¸¬ãå¨å»éè¨éæ®µï¼æåå©ç¨ä¸ç¨®æå¢å¢å¼·ç­ç¥ï¼å®çµåäºæç¸éåæç¢ºä¿¡çç¥è­ï¼ç¶å¾é²è¡ä»ç´°è©ä¼°ä»¥ç¢çå¯é çè¨»è§£ãæ­¤å¤ï¼æåéå¼å¥äºä¸ç¨®åºæ¼åæçµçææè³æé¸åæ©å¶ï¼ç¢ºä¿åä¿çé«åè³ªçæ¨£æ¬é²è¡å¾®èª¿ãå¨äºåè³æéä¸å°å¤å LLM é²è¡çå»£æ³å¯¦é©è­æäº RobustFT å¨éè¨æå¢ä¸­çåºè²æè½ã

##### **Advances in Artificial Intelligence forDiabetes Prediction: Insights from a Systematic Literature Review**
2412.14736v1 by Pir Bakhsh Khokhar, Carmine Gravino, Fabio Palomba

This systematic review explores the use of machine learning (ML) in
predicting diabetes, focusing on datasets, algorithms, training methods, and
evaluation metrics. It examines datasets like the Singapore National Diabetic
Retinopathy Screening program, REPLACE-BG, National Health and Nutrition
Examination Survey, and Pima Indians Diabetes Database. The review assesses the
performance of ML algorithms like CNN, SVM, Logistic Regression, and XGBoost in
predicting diabetes outcomes. The study emphasizes the importance of
interdisciplinary collaboration and ethical considerations in ML-based diabetes
prediction models.

æè¦ï¼éé ç³»çµ±æ§åé¡§æ¢è¨äºæ©å¨å­¸ç¿ (ML) å¨ç³å°¿çé æ¸¬ä¸­çæç¨ï¼éé»å¨æ¼è³æéãæ¼ç®æ³ãè¨ç·´æ¹æ³åè©ä¼°ææ¨ãå®æª¢é©äºè³æéï¼ä¾å¦æ°å å¡åå®¶ç³å°¿çè¦ç¶²èçè®ç¯©æª¢è¨ç«ãREPLACE-BGãåå®¶å¥åº·èçé¤æª¢æ¥èª¿æ¥åç®é¦¬å°ç¬¬å®äººç³å°¿çè³æåº«ãè©²åé¡§è©ä¼°äº ML æ¼ç®æ³ï¼ä¾å¦ CNNãSVMãéè¼¯è¿´æ­¸å XGBoostï¼å¨é æ¸¬ç³å°¿ççµææ¹é¢çè¡¨ç¾ãéé ç ç©¶å¼·èª¿äºè·¨é ååä½åå¨åºæ¼ ML çç³å°¿çé æ¸¬æ¨¡åä¸­é²è¡éå¾·èéçéè¦æ§ã

##### **Pitfalls of topology-aware image segmentation**
2412.14619v1 by Alexander H. Berger, Laurin Lux, Alexander Weers, Martin Menten, Daniel Rueckert, Johannes C. Paetzold

Topological correctness, i.e., the preservation of structural integrity and
specific characteristics of shape, is a fundamental requirement for medical
imaging tasks, such as neuron or vessel segmentation. Despite the recent surge
in topology-aware methods addressing this challenge, their real-world
applicability is hindered by flawed benchmarking practices. In this paper, we
identify critical pitfalls in model evaluation that include inadequate
connectivity choices, overlooked topological artifacts in ground truth
annotations, and inappropriate use of evaluation metrics. Through detailed
empirical analysis, we uncover these issues' profound impact on the evaluation
and ranking of segmentation methods. Drawing from our findings, we propose a
set of actionable recommendations to establish fair and robust evaluation
standards for topology-aware medical image segmentation methods.

æè¦ï¼ææ²æ­£ç¢ºæ§ï¼å³å½¢ççµæ§å®æ´æ§åç¹å®ç¹å¾µçä¿çï¼æ¯é«å­¸å½±åä»»åï¼ä¾å¦ç¥ç¶åæè¡ç®¡åå²ï¼çåºæ¬è¦æ±ãåç®¡æè¿è§£æ±ºæ­¤ææ°çææ²æç¥æ¹æ³æ¿å¢ï¼ä½å¶çå¯¦ä¸ççé©ç¨æ§åå°æç¼ºé·çåºæºæ¸¬è©¦å¯¦åçé»ç¤ãå¨æ¬æä¸­ï¼æåç¢ºå®äºæ¨¡åè©ä¼°ä¸­çééµç¼ºé·ï¼åæ¬ä¸é©ç¶çé£æ¥é¸æãåºæ¬äºå¯¦æ¨è¨»ä¸­è¢«å¿½ç¥çææ²äººå·¥è£½åï¼ä»¥åè©ä¼°ææ¨çä¸é©ç¶ä½¿ç¨ãééè©³ç´°çç¶é©åæï¼æåæ­ç¤ºäºéäºåé¡å°åå²æ¹æ³çè©ä¼°åæåç¢ççæ·±é å½±é¿ãæ ¹ææåçç ç©¶çµæï¼æåæåºäºä¸çµå¯è¡çå»ºè­°ï¼ä»¥å»ºç«å¬å¹³ä¸ç©©å¥çè©ä¼°æ¨æºï¼ç¨æ¼ææ²æç¥é«å­¸å½±ååå²æ¹æ³ã

##### **CAE-T: A Channelwise AutoEncoder with Transformer for EEG Abnormality Detection**
2412.14522v1 by Youshen Zhao, Keiji Iramina

Electroencephalogram (EEG) signals are critical for detecting abnormal brain
activity, but their high dimensionality and complexity pose significant
challenges for effective analysis. In this paper, we propose CAE-T, a novel
framework that combines a channelwise CNN-based autoencoder with a single-head
transformer classifier for efficient EEG abnormality detection. The channelwise
autoencoder compresses raw EEG signals while preserving channel independence,
reducing computational costs and retaining biologically meaningful features.
The compressed representations are then fed into the transformer-based
classifier, which efficiently models long-term dependencies to distinguish
between normal and abnormal signals. Evaluated on the TUH Abnormal EEG Corpus,
the proposed model achieves 85.0% accuracy, 76.2% sensitivity, and 91.2%
specificity at the per-case level, outperforming baseline models such as
EEGNet, Deep4Conv, and FusionCNN. Furthermore, CAE-T requires only 202M FLOPs
and 2.9M parameters, making it significantly more efficient than
transformer-based alternatives. The framework retains interpretability through
its channelwise design, demonstrating great potential for future applications
in neuroscience research and clinical practice. The source code is available at
https://github.com/YossiZhao/CAE-T.

æè¦ï¼è¦é»å (EEG) è¨èå°æ¼åµæ¸¬ç°å¸¸è¦é¨æ´»åè³ééè¦ï¼ä½å¶é«ç¶­åº¦åè¤éæ§å°ææåææ§æéå¤§ææ°ãå¨æ¬æä¸­ï¼æåæåº CAE-Tï¼ä¸åçµååºæ¼ééç CNN èªåç·¨ç¢¼å¨åå®é ­Transformeråé¡å¨çå¨æ°æ¶æ§ï¼ç¨æ¼é«æç EEG ç°å¸¸åµæ¸¬ãåºæ¼ééçèªåç·¨ç¢¼å¨å£ç¸®åå§ EEG è¨èï¼åæä¿çééç¨ç«æ§ï¼éä½è¨ç®ææ¬ä¸¦ä¿ççç©å­¸ä¸ææç¾©çç¹å¾µãå£ç¸®å¾çè¡¨ç¤ºæ¥èè¢«è¼¸å¥å°åºæ¼Transformerçåé¡å¨ä¸­ï¼è©²åé¡å¨ææå°å»ºæ¨¡é·æä¾è³´éä¿ä»¥ååæ­£å¸¸åç°å¸¸è¨èãå¨ TUH ç°å¸¸ EEG èªæåº«ä¸é²è¡è©ä¼°ï¼ææåºçæ¨¡åå¨åæ¡å±¤ç´éå° 85.0% çæºç¢ºåº¦ã76.2% çææåº¦å 91.2% çç¹ç°æ§ï¼åªæ¼ EEGNetãDeep4Conv å FusionCNN ç­åºç·æ¨¡åãæ­¤å¤ï¼CAE-T åéè¦ 202M FLOP å 2.9M åæ¸ï¼ä½¿å¶æ¯åºæ¼Transformerçæ¿ä»£æ¹æ¡é¡¯èæ´ææçãè©²æ¶æ§ééå¶åºæ¼ééçè¨­è¨ä¿çäºè§£éæ§ï¼å±ç¾åºå¨ç¥ç¶ç§å­¸ç ç©¶åè¨åºå¯¦åä¸­æªä¾æç¨æ¥µå¤§çæ½åãåå§ç¨å¼ç¢¼å¯å¨ https://github.com/YossiZhao/CAE-T åå¾ã

##### **GenHMR: Generative Human Mesh Recovery**
2412.14444v1 by Muhammad Usama Saleem, Ekkasit Pinyoanuntapong, Pu Wang, Hongfei Xue, Srijan Das, Chen Chen

Human mesh recovery (HMR) is crucial in many computer vision applications;
from health to arts and entertainment. HMR from monocular images has
predominantly been addressed by deterministic methods that output a single
prediction for a given 2D image. However, HMR from a single image is an
ill-posed problem due to depth ambiguity and occlusions. Probabilistic methods
have attempted to address this by generating and fusing multiple plausible 3D
reconstructions, but their performance has often lagged behind deterministic
approaches. In this paper, we introduce GenHMR, a novel generative framework
that reformulates monocular HMR as an image-conditioned generative task,
explicitly modeling and mitigating uncertainties in the 2D-to-3D mapping
process. GenHMR comprises two key components: (1) a pose tokenizer to convert
3D human poses into a sequence of discrete tokens in a latent space, and (2) an
image-conditional masked transformer to learn the probabilistic distributions
of the pose tokens, conditioned on the input image prompt along with randomly
masked token sequence. During inference, the model samples from the learned
conditional distribution to iteratively decode high-confidence pose tokens,
thereby reducing 3D reconstruction uncertainties. To further refine the
reconstruction, a 2D pose-guided refinement technique is proposed to directly
fine-tune the decoded pose tokens in the latent space, which forces the
projected 3D body mesh to align with the 2D pose clues. Experiments on
benchmark datasets demonstrate that GenHMR significantly outperforms
state-of-the-art methods. Project website can be found at
https://m-usamasaleem.github.io/publication/GenHMR/GenHMR.html

æè¦ï¼äººé«ç¶²æ ¼éå»ºï¼HMRï¼å¨è¨±å¤é»è¦è¦è¦ºæç¨ä¸­è³ééè¦ï¼
å¾å¥åº·å°èè¡åå¨æ¨ãå®ç®å½±åç HMR ä¸»è¦ç±ç¢ºå®æ§æ¹æ³è§£æ±ºï¼
è©²æ¹æ³éå°çµ¦å®ç 2D å½±åè¼¸åºå®ä¸é æ¸¬ãç¶èï¼ç±æ¼æ·±åº¦æ¨¡ç³åé®æï¼
å®ä¸å½±åç HMR æ¯åçæåé¡ãæ©çæ¹æ³åè©¦ééç¢çåèåå¤ååçç 3D
éå»ºä¾è§£æ±ºæ­¤åé¡ï¼ä½å¶æè½éå¸¸è½å¾æ¼ç¢ºå®æ§æ¹æ³ãå¨æ¬æä¸­ï¼æåä»ç´¹
GenHMRï¼éæ¯ä¸åæ°ç©ççæå¼æ¶æ§ï¼å°å®ç® HMR éæ°è¡¨è¿°çºä¸åå½±åæ¢ä»¶çæä»»åï¼
æç¢ºå»ºæ¨¡åæ¸è¼ 2D å° 3D å°æéç¨ä¸­çä¸ç¢ºå®æ§ãGenHMR åå«å©åééµçµæé¨åï¼
ï¼1ï¼å§¿å¢æ¨è¨åå¨ï¼å° 3D äººé«å§¿å¢è½æçºæ½å¨ç©ºéä¸­çé¢æ£æ¨è¨åºåï¼ä»¥å
ï¼2ï¼å½±åæ¢ä»¶é®ç½©è½æå¨ï¼ä»¥è¼¸å¥å½±åæç¤ºä»¥åé¨æ©é®ç½©æ¨è¨åºåçºæ¢ä»¶ï¼
å­¸ç¿å§¿å¢æ¨è¨çæ©çåä½ãå¨æ¨è«æéï¼æ¨¡åå¾å­¸ç¿å°çæ¢ä»¶åä½ä¸­åæ¨£ï¼
ä»¥åè¦è§£ç¢¼é«ç½®ä¿¡åº¦å§¿å¢æ¨è¨ï¼å¾èæ¸å° 3D éå»ºçä¸ç¢ºå®æ§ãçºäºé²ä¸æ­¥åªå
éå»ºï¼æåºäºä¸ç¨® 2D å§¿å¢å¼å°çåªåæè¡ï¼ä»¥ç´æ¥å¾®èª¿æ½å¨ç©ºéä¸­è§£ç¢¼çå§¿å¢æ¨è¨ï¼
éè¿«ä½¿æå½±ç 3D èº«é«ç¶²æ ¼è 2D å§¿å¢ç·ç´¢å°é½ãåºæºè³æéä¸çå¯¦é©è­æï¼
GenHMR æé¡¯åªæ¼æåé²çæ¹æ³ãå°æ¡ç¶²ç«å¯ä»¥å¨
https://m-usamasaleem.github.io/publication/GenHMR/GenHMR.html æ¾å°

##### **FedPIA -- Permuting and Integrating Adapters leveraging Wasserstein Barycenters for Finetuning Foundation Models in Multi-Modal Federated Learning**
2412.14424v1 by Pramit Saha, Divyanshu Mishra, Felix Wagner, Konstantinos Kamnitsas, J. Alison Noble

Large Vision-Language Models typically require large text and image datasets
for effective fine-tuning. However, collecting data from various sites,
especially in healthcare, is challenging due to strict privacy regulations. An
alternative is to fine-tune these models on end-user devices, such as in
medical clinics, without sending data to a server. These local clients
typically have limited computing power and small datasets, which are not enough
for fully fine-tuning large VLMs on their own. A naive solution to these
scenarios is to leverage parameter-efficient fine-tuning (PEFT) strategies and
apply federated learning (FL) algorithms to combine the learned adapter
weights, thereby respecting the resource limitations and data privacy. However,
this approach does not fully leverage the knowledge from multiple adapters
trained on diverse data distributions and for diverse tasks. The adapters are
adversely impacted by data heterogeneity and task heterogeneity across clients
resulting in suboptimal convergence. To this end, we propose a novel framework
called FedPIA that improves upon the naive combinations of FL and PEFT by
introducing Permutation and Integration of the local Adapters in the server and
global Adapters in the clients exploiting Wasserstein barycenters for improved
blending of client-specific and client-agnostic knowledge. This layerwise
permutation helps to bridge the gap in the parameter space of local and global
adapters before integration. We conduct over 2000 client-level experiments
utilizing 48 medical image datasets across five different medical
vision-language FL task settings encompassing visual question answering as well
as image and report-based multi-label disease detection. Our experiments
involving diverse client settings, ten different modalities, and two VLM
backbones demonstrate that FedPIA consistently outperforms the state-of-the-art
PEFT-FL baselines.

æè¦ï¼å¤§åè¦è¦ºèªè¨æ¨¡åéå¸¸éè¦å¤§åæå­åå½±åè³æéæè½é²è¡ææçå¾®èª¿ãç¶èï¼ç±æ¼å´æ ¼çé±ç§æ³è¦ï¼å¾åç¨®ç¶²ç«æ¶éè³æï¼ç¹å¥æ¯å¨é«çä¿å¥æ¹é¢ï¼æ¯ä¸é ææ°ãå¦ä¸ç¨®æ¹æ³æ¯å¨çµç«¯ä½¿ç¨èè£ç½®ä¸å¾®èª¿éäºæ¨¡åï¼ä¾å¦å¨é«çè¨ºæï¼èä¸å°è³æå³éè³ä¼ºæå¨ãéäºæ¬æ©ç¨æ¶ç«¯éå¸¸å·æåéçéç®è½ååå°åè³æéï¼ä¸è¶³ä»¥èªè¡å°å¤§å VLM é²è¡å®å¨å¾®èª¿ãéå°éäºå ´æ¯çä¸åå¤©çè§£æ±ºæ¹æ¡æ¯å©ç¨åæ¸ææå¾®èª¿ (PEFT) ç­ç¥ï¼ä¸¦å¥ç¨è¯é¦å­¸ç¿ (FL) æ¼ç®æ³ä¾çµåå­¸ç¿å°çé©éå¨æ¬éï¼å¾èå°éè³æºéå¶åè³æé±ç§ãç¶èï¼æ­¤æ¹æ³ä¸¦æªååå©ç¨å¾è¨ç·´æ¼ä¸åè³æåä½åä¸åä»»åçå¤åé©éå¨ä¸­ç²å¾çç¥è­ãé©éå¨åå°å®¢æ¶ç«¯éè³æç°è³ªæ§åä»»åç°è³ªæ§çä¸å©å½±é¿ï¼å°è´æ¬¡ä½³æ¶æãçºæ­¤ï¼æåæåºäºä¸ååçº FedPIA çæ°æ¶æ§ï¼ééå¨ä¼ºæå¨ä¸­å¼å¥å±é¨é©éå¨çæååæ´åï¼ä»¥åå¨å®¢æ¶ç«¯ä¸­å¼å¥å¨çé©éå¨ï¼ä¸¦å©ç¨ Wasserstein éå¿ä¾æ¹åå®¢æ¶ç«¯ç¹å®åå®¢æ¶ç«¯ä¸å¯ç¥ç¥è­çæ··åï¼å¾èæ¹é² FL å PEFT çå¤©ççµåãéç¨®éå±¤æåæå©æ¼å¨æ´åä¹åå½åå±é¨åå¨çé©éå¨åæ¸ç©ºéçå·®è·ãæåå©ç¨ 48 åé«å­¸å½±åè³æéå¨äºåä¸åçé«å­¸è¦è¦ºèªè¨ FL ä»»åè¨­å®ä¸­é²è¡äº 2000 å¤åå®¢æ¶ç«¯å±¤ç´å¯¦é©ï¼åæ¬è¦è¦ºåé¡è§£ç­ä»¥ååºæ¼å½±ååå ±åçå¤æ¨ç±¤ç¾çæª¢æ¸¬ãæåæ¶åä¸åå®¢æ¶ç«¯è¨­å®ãåç¨®ä¸åæ¨¡å¼åå©å VLM ä¸»å¹¹çå¯¦é©è¡¨æï¼FedPIA æçºåªæ¼æåé²ç PEFT-FL åºæºã

##### **Clinical Trials Ontology Engineering with Large Language Models**
2412.14387v1 by Berkan ÃakÄ±r

Managing clinical trial information is currently a significant challenge for
the medical industry, as traditional methods are both time-consuming and
costly. This paper proposes a simple yet effective methodology to extract and
integrate clinical trial data in a cost-effective and time-efficient manner.
Allowing the medical industry to stay up-to-date with medical developments.
Comparing time, cost, and quality of the ontologies created by humans, GPT3.5,
GPT4, and Llama3 (8b & 70b). Findings suggest that large language models (LLM)
are a viable option to automate this process both from a cost and time
perspective. This study underscores significant implications for medical
research where real-time data integration from clinical trials could become the
norm.

æè¦ï¼ç®¡çè¨åºè©¦é©è³è¨ç®åæ¯é«çç¢æ¥­çä¸é éå¤§ææ°ï¼å çºå³çµ±æ¹æ³æ¢èæåæè²´ãæ¬ææåºä¸åç°¡å®ä½ææçæ¹æ³ï¼ä»¥ç¶æ¿ææä¸çæçæ¹å¼æååæ´åè¨åºè©¦é©è³æãè®é«çç¢æ¥­è½é¨æææ¡é«çç¼å±ãæ¯è¼äººé¡ãGPT3.5ãGPT4 å Llama3ï¼8b å 70bï¼å»ºç«çæ¬ä½çæéãææ¬ååè³ªãç ç©¶çµæè¡¨æï¼å¤§åèªè¨æ¨¡å (LLM) æ¯å¾ææ¬åæéè§åº¦èªååæ­¤æµç¨çå¯è¡é¸é ãéé ç ç©¶å¼·èª¿äºå°é«çç ç©¶çéè¦å½±é¿ï¼å¶ä¸­è¨åºè©¦é©çå³æè³ææ´åå¯è½ææçºå¸¸æã

##### **Multi-OphthaLingua: A Multilingual Benchmark for Assessing and Debiasing LLM Ophthalmological QA in LMICs**
2412.14304v1 by David Restrepo, Chenwei Wu, Zhengxu Tang, Zitao Shuai, Thao Nguyen Minh Phan, Jun-En Ding, Cong-Tinh Dao, Jack Gallifant, Robyn Gayle Dychiao, Jose Carlo Artiaga, AndrÃ© Hiroshi Bando, Carolina Pelegrini Barbosa Gracitelli, Vincenz Ferrer, Leo Anthony Celi, Danielle Bitterman, Michael G Morley, Luis Filipe Nakayama

Current ophthalmology clinical workflows are plagued by over-referrals, long
waits, and complex and heterogeneous medical records. Large language models
(LLMs) present a promising solution to automate various procedures such as
triaging, preliminary tests like visual acuity assessment, and report
summaries. However, LLMs have demonstrated significantly varied performance
across different languages in natural language question-answering tasks,
potentially exacerbating healthcare disparities in Low and Middle-Income
Countries (LMICs). This study introduces the first multilingual
ophthalmological question-answering benchmark with manually curated questions
parallel across languages, allowing for direct cross-lingual comparisons. Our
evaluation of 6 popular LLMs across 7 different languages reveals substantial
bias across different languages, highlighting risks for clinical deployment of
LLMs in LMICs. Existing debiasing methods such as Translation Chain-of-Thought
or Retrieval-augmented generation (RAG) by themselves fall short of closing
this performance gap, often failing to improve performance across all languages
and lacking specificity for the medical domain. To address this issue, We
propose CLARA (Cross-Lingual Reflective Agentic system), a novel inference time
de-biasing method leveraging retrieval augmented generation and
self-verification. Our approach not only improves performance across all
languages but also significantly reduces the multilingual bias gap,
facilitating equitable LLM application across the globe.

æè¦ï¼<paragraph>ç¶åç¼ç§è¨åºå·¥ä½æµç¨é£½åéåº¦è½è¨ºãæ¼«é·ç­å¾æéä»¥åè¤éä¸ç°è³ªçé«çè¨éæè¦ãå¤§åèªè¨æ¨¡å (LLM) æä¾äºä¸åæåæ¯çè§£æ±ºæ¹æ¡ï¼å¯èªåååç¨®ç¨åºï¼ä¾å¦åæµãè¦åè©ä¼°ç­åæ­¥æ¸¬è©¦åå ±åæè¦ãç¶èï¼LLM å·²å¨èªç¶èªè¨åç­ä»»åä¸­å±ç¾åºè·¨ä¸åèªè¨çé¡¯èå·®ç°æè½ï¼éå¯è½æå åä½æ¶å¥åä¸­ç­æ¶å¥åå®¶ (LMIC) çé«çä¿å¥å·®ç°ãæ¬ç ç©¶å¼å¥äºé¦åå¤èªè¨ç¼ç§åç­åºæºï¼å¶ä¸­åå«æåç­åä¸è·¨èªè¨å¹³è¡çåé¡ï¼åè¨±ç´æ¥é²è¡è·¨èªè¨æ¯è¼ãæåå° 7 ç¨®ä¸åèªè¨ä¸­ç 6 åç±é LLM é²è¡è©ä¼°ï¼çµæé¡¯ç¤ºä¸åèªè¨ä¹éå­å¨é¡¯èåå·®ï¼çªé¡¯åºå¨ LMIC ä¸­é¨ç½² LLM çè¨åºé¢¨éªãç¾æçå»åæ¹æ³ï¼ä¾å¦ç¿»è­¯æç¶­éææª¢ç´¢å¢å¼·çæ (RAG)ï¼æ¬èº«ç¡æ³ç¸®å°æ­¤æè½å·®è·ï¼éå¸¸ç¡æ³æ¹åææèªè¨çæè½ï¼ä¸ç¼ºä¹éå°é«çé åçå°ä¸æ§ãçºäºè§£æ±ºæ­¤åé¡ï¼æåæåº CLARA (è·¨èªè¨åå°ä»£çç³»çµ±)ï¼éæ¯ä¸ç¨®æ°ç©çæ¨çæéå»åæ¹æ³ï¼å©ç¨æª¢ç´¢å¢å¼·çæåèªæé©è­ãæåçåæ³ä¸åæ¹åäºææèªè¨çæè½ï¼éé¡¯èç¸®å°äºå¤èªè¨åè¦å·®è·ï¼ä¿é²äº LLM å¨å¨çç¯åå§çå¬å¹³æç¨ã</paragraph>

##### **Discovering maximally consistent distribution of causal tournaments with Large Language Models**
2412.14019v1 by Federico Baldo, Simon Ferreira, Charles K. Assaad

Causal discovery is essential for understanding complex systems, yet
traditional methods often depend on strong, untestable assumptions, making the
process challenging. Large Language Models (LLMs) present a promising
alternative for extracting causal insights from text-based metadata, which
consolidates domain expertise. However, LLMs are prone to unreliability and
hallucinations, necessitating strategies that account for their limitations.
One such strategy involves leveraging a consistency measure to evaluate
reliability. Additionally, most text metadata does not clearly distinguish
direct causal relationships from indirect ones, further complicating the
inference of causal graphs. As a result, focusing on causal orderings, rather
than causal graphs, emerges as a more practical and robust approach. We propose
a novel method to derive a distribution of acyclic tournaments (representing
plausible causal orders) that maximizes a consistency score. Our approach
begins by computing pairwise consistency scores between variables, yielding a
cyclic tournament that aggregates these scores. From this structure, we
identify optimal acyclic tournaments compatible with the original tournament,
prioritizing those that maximize consistency across all configurations. We
tested our method on both classical and well-established bechmarks, as well as
real-world datasets from epidemiology and public health. Our results
demonstrate the effectiveness of our approach in recovering distributions
causal orders with minimal error.

æè¦ï¼å æç¼ç¾å°æ¼çè§£è¤éç³»çµ±è³ééè¦ï¼ä½å³çµ±æ¹æ³éå¸¸ä¾è³´æ¼å¼·èä¸å¯æ¸¬è©¦çåè¨­ï¼éä½¿å¾éåéç¨åæ»¿ææ°ãå¤§åèªè¨æ¨¡å (LLM) æä¾äºä¸åå¾åºæ¼ææ¬çåæ¸æä¸­æåå æè¦è§£çæå¸æçæ¿ä»£æ¹æ¡ï¼å®æ´åäºé åå°æ¥­ç¥è­ãç¶èï¼LLM å®¹æåºç¾ä¸å¯é æ§åå¹»è¦ºï¼ééè¦èæ®å¶éå¶çç­ç¥ãä¸ç¨®éæ¨£çç­ç¥æ¶åå©ç¨ä¸è´æ§åº¦éä¾è©ä¼°å¯é æ§ãæ­¤å¤ï¼å¤§å¤æ¸ææ¬åæ¸æä¸¦æªæ¸æ¥å°ååç´æ¥å æéä¿åéæ¥å æéä¿ï¼éé²ä¸æ­¥è¤éåäºå æåçæ¨è«ãå æ­¤ï¼å°æ³¨æ¼å æé åºï¼èä¸æ¯å æåï¼æçºä¸ç¨®æ´å¯¦ç¨ãæ´ç©©å¥çæ¹æ³ãæåæåºäºä¸ç¨®æ°æ¹æ³ä¾æ¨å°ç¡ç°é¦æ¨è³½çåå¸ï¼è¡¨ç¤ºåççå æé åºï¼ï¼éæå¤§åäºä¸è´æ§åæ¸ãæåçåæ³é¦åè¨ç®è®éä¹éæå°çä¸è´æ§åæ¸ï¼ç¢çä¸åå½ç¸½éäºåæ¸çå¾ªç°é¦æ¨è³½ãå¾éåçµæ§ä¸­ï¼æåè­å¥åºèåå§é¦æ¨è³½ç¸å®¹çæä½³ç¡ç°é¦æ¨è³½ï¼åªåèæ®é£äºå¨ææéç½®ä¸­æå¤§åä¸è´æ§çé¦æ¨è³½ãæåå¨ç¶å¸ä¸å®åçåºæºä»¥åä¾èªæµè¡çå­¸åå¬å±è¡çççå¯¦ä¸çæ¸æéä¸æ¸¬è©¦äºæåçæ¨¡åãæåççµæè­æäºæåçæ¹æ³å¨ä»¥æå°èª¤å·®æ¢å¾©å æé åºåå¸æ¹é¢çæææ§ã

##### **SurgSora: Decoupled RGBD-Flow Diffusion Model for Controllable Surgical Video Generation**
2412.14018v1 by Tong Chen, Shuya Yang, Junyi Wang, Long Bai, Hongliang Ren, Luping Zhou

Medical video generation has transformative potential for enhancing surgical
understanding and pathology insights through precise and controllable visual
representations. However, current models face limitations in controllability
and authenticity. To bridge this gap, we propose SurgSora, a
motion-controllable surgical video generation framework that uses a single
input frame and user-controllable motion cues. SurgSora consists of three key
modules: the Dual Semantic Injector (DSI), which extracts object-relevant RGB
and depth features from the input frame and integrates them with segmentation
cues to capture detailed spatial features of complex anatomical structures; the
Decoupled Flow Mapper (DFM), which fuses optical flow with semantic-RGB-D
features at multiple scales to enhance temporal understanding and object
spatial dynamics; and the Trajectory Controller (TC), which allows users to
specify motion directions and estimates sparse optical flow, guiding the video
generation process. The fused features are used as conditions for a frozen
Stable Diffusion model to produce realistic, temporally coherent surgical
videos. Extensive evaluations demonstrate that SurgSora outperforms
state-of-the-art methods in controllability and authenticity, showing its
potential to advance surgical video generation for medical education, training,
and research.

æè¦ï¼é«çå½±ççæå·æè®é©æ§çæ½åï¼å¯ééç²¾ç¢ºä¸å¯æ§çè¦è¦ºè¡¨ç¾ä¾å¢å¼·æè¡çè§£åççè¦è§£ãç¶èï¼ç®åçæ¨¡åå¨å¯æ§æ§åçå¯¦æ§æ¹é¢é¢è¨éå¶ãçºäºå½åéåå·®è·ï¼æåæåºäº SurgSoraï¼ä¸ååä½å¯æ§çæè¡å½±ççææ¡æ¶ï¼ä½¿ç¨å®ä¸è¼¸å¥å¹åä½¿ç¨èå¯æ§çåä½æç¤ºãSurgSora åå«ä¸åééµæ¨¡çµï¼éèªææ³¨å¥å¨ (DSI)ï¼å®å¾è¼¸å¥å¹ä¸­æåèç©ä»¶ç¸éç RGB åæ·±åº¦ç¹å¾µï¼ä¸¦å°å¶èåå²æç¤ºæ´åï¼ä»¥æ·åè¤éè§£åçµæ§çè©³ç´°ç©ºéç¹å¾µï¼è§£è¦æµå°æå¨ (DFM)ï¼å®å¨å¤åå°ºåº¦ä¸å°åæµèèªæ RGB-D ç¹å¾µèåï¼ä»¥å¢å¼·æéçè§£åç©ä»¶ç©ºéåæï¼ä»¥åè»è·¡æ§å¶å¨ (TC)ï¼å®åè¨±ä½¿ç¨èæå®åä½æ¹åä¸¦ä¼°è¨ç¨çåæµï¼å¼å°å½±ççæéç¨ãèåçç¹å¾µç¨ä½åçµç Stable Diffusion æ¨¡åçæ¢ä»¶ï¼ä»¥ç¢çé¼çãæéé£è²«çæè¡å½±çãå»£æ³çè©ä¼°è¡¨æï¼SurgSora å¨å¯æ§æ§åçå¯¦æ§æ¹é¢åªæ¼æåé²çæ¹æ³ï¼é¡¯ç¤ºå¶å¨æ¨é²æè¡å½±ççæä»¥ç¨æ¼é«å­¸æè²ãå¹è¨åç ç©¶æ¹é¢çæ½åã

##### **Cognition Chain for Explainable Psychological Stress Detection on Social Media**
2412.14009v1 by Xin Wang, Boyan Gao, Yi Dai, Lei Cao, Liang Zhao, Yibo Yang, David Clifton

Stress is a pervasive global health issue that can lead to severe mental
health problems. Early detection offers timely intervention and prevention of
stress-related disorders. The current early detection models perform "black
box" inference suffering from limited explainability and trust which blocks the
real-world clinical application. Thanks to the generative properties introduced
by the Large Language Models (LLMs), the decision and the prediction from such
models are semi-interpretable through the corresponding description. However,
the existing LLMs are mostly trained for general purposes without the guidance
of psychological cognitive theory. To this end, we first highlight the
importance of prior theory with the observation of performance boosted by the
chain-of-thoughts tailored for stress detection. This method termed Cognition
Chain explicates the generation of stress through a step-by-step cognitive
perspective based on cognitive appraisal theory with a progress pipeline:
Stimulus $\rightarrow$ Evaluation $\rightarrow$ Reaction $\rightarrow$ Stress
State, guiding LLMs to provide comprehensive reasoning explanations. We further
study the benefits brought by the proposed Cognition Chain format by utilising
it as a synthetic dataset generation template for LLMs instruction-tuning and
introduce CogInstruct, an instruction-tuning dataset for stress detection. This
dataset is developed using a three-stage self-reflective annotation pipeline
that enables LLMs to autonomously generate and refine instructional data. By
instruction-tuning Llama3 with CogInstruct, we develop CogLLM, an explainable
stress detection model. Evaluations demonstrate that CogLLM achieves
outstanding performance while enhancing explainability. Our work contributes a
novel approach by integrating cognitive theories into LLM reasoning processes,
offering a promising direction for future explainable AI research.

æè¦ï¼å£åæ¯ä¸åæ®éçå¨çæ§å¥åº·åé¡ï¼å¯è½æå°è´å´éçç²¾ç¥
å¥åº·åé¡ãæ©æç¼ç¾æä¾åæçå¹²é åé é²
å£åç¸éç¾çãç®åçæ©æç¼ç¾æ¨¡åå·è¡ãé»
çå­ãæ¨è«ï¼å­å¨å¯è§£éæ§åä¿¡ä»»åº¦æéçåé¡ï¼é»ç¤äº
ç¾å¯¦ä¸ççè¨åºæç¨ãå¤è§äºå¤§åèªè¨æ¨¡å (LLM) å¼å¥ççæå±¬æ§ï¼æ­¤é¡
æ¨¡åçæ±ºç­åé æ¸¬ééå°ææè¿°å·æåå¯è§£éæ§ãç¶èï¼
ç¾æç LLM ä¸»è¦éå°ä¸è¬ç¨éé²è¡è¨ç·´ï¼æ²æå¿çèªç¥çè«çæå°ãçºæ­¤ï¼æåé¦åå¼·èª¿
åé©çè«çéè¦æ§ï¼ä¸¦è§å¯å°éå°å£åæª¢æ¸¬éèº«å®å¶çææ³éæåäºæ§è½ãéç¨®æ¹æ³ç¨±çºèªç¥
éééåºæ¼èªç¥è©ä¼°çè«çå¾ªåºæ¼¸é²çèªç¥è¦è§é¡æäºå£åçç¢çï¼ä¸¦å·æé²åº¦ç®¡éï¼
åºæ¿ $\rightarrow$ è©ä¼° $\rightarrow$ åæ $\rightarrow$ å£å
çæï¼æå° LLM æä¾å¨é¢çæ¨çè§£éãæåé²ä¸æ­¥
ééå°å¶ç¨ä½ LLM æä»¤èª¿æ´çåææ¸æéçææ¨¡æ¿ä¾ç ç©¶ææåºçèªç¥éæ ¼å¼å¸¶ä¾çåªé»ï¼ä¸¦ä»ç´¹ CogInstructï¼éæ¯ä¸åéå°å£åæª¢æ¸¬çæä»¤èª¿æ´æ¸æéãéå
æ¸æéæ¯ä½¿ç¨ä¸åä¸éæ®µçèªçæ¨è¨»ç®¡ééç¼çï¼ä½¿ LLM è½å¤ èªä¸»çæååªåæä»¤æ¸æãéé
ä½¿ç¨ CogInstruct å° Llama3 é²è¡æä»¤èª¿æ´ï¼æåéç¼äº CogLLMï¼éæ¯ä¸åå¯è§£éç
å£åæª¢æ¸¬æ¨¡åãè©ä¼°è¡¨æï¼CogLLM å¨æé«å¯è§£éæ§çåæå¯¦ç¾äºåºè²çæ§è½ãæåçç ç©¶ééå°èªç¥çè«æ´åå° LLM æ¨çéç¨ä¸­ï¼æåºäºä¸ç¨®æ°ç©çæ¹æ³ï¼
çºæªä¾çå¯è§£éäººå·¥æºè½ç ç©¶æä¾äºä¸åæå¸æçæ¹åã

##### **Federated Learning and RAG Integration: A Scalable Approach for Medical Large Language Models**
2412.13720v1 by Jincheol Jung, Hongju Jeong, Eui-Nam Huh

This study analyzes the performance of domain-specific Large Language Models
(LLMs) for the medical field by integrating Retrieval-Augmented Generation
(RAG) systems within a federated learning framework. Leveraging the inherent
advantages of federated learning, such as preserving data privacy and enabling
distributed computation, this research explores the integration of RAG systems
with models trained under varying client configurations to optimize
performance. Experimental results demonstrate that the federated learning-based
models integrated with RAG systems consistently outperform their non-integrated
counterparts across all evaluation metrics. This study highlights the potential
of combining federated learning and RAG systems for developing domain-specific
LLMs in the medical field, providing a scalable and privacy-preserving solution
for enhancing text generation capabilities.

æè¦ï¼æ¬ç ç©¶ééå¨è¯é¦å­¸ç¿æ¶æ§ä¸­æ´åæª¢ç´¢æ´å¢çæ (RAG) ç³»çµ±ï¼åæç¹å®é åçå¤§èªè¨æ¨¡å (LLM) å¨é«çé åçè¡¨ç¾ãå©ç¨è¯é¦å­¸ç¿çå§å¨åªå¢ï¼ä¾å¦ç¶­è­·è³æé±ç§ååç¨åæ£å¼éç®ï¼æ¬ç ç©¶æ¢è¨å° RAG ç³»çµ±èå¨ä¸åå®¢æ¶ç«¯çµæä¸è¨ç·´çæ¨¡åæ´åï¼ä»¥æä½³åæè½ãå¯¦é©çµæé¡¯ç¤ºï¼è RAG ç³»çµ±æ´åçåºæ¼è¯é¦å­¸ç¿çæ¨¡åå¨ææè©ä¼°ææ¨ä¸é½æçºåªæ¼æªæ´åçå°ææ¨¡åãæ¬ç ç©¶å¼·èª¿å¨é«çé åçµåè¯é¦å­¸ç¿å RAG ç³»çµ±ä»¥éç¼ç¹å®é å LLM çæ½åï¼æä¾å¯æ´åä¸ç¶­è­·é±ç§çè§£æ±ºæ¹æ¡ï¼ä»¥å¢å¼·æå­çæè½åã

##### **Clio: Privacy-Preserving Insights into Real-World AI Use**
2412.13678v1 by Alex Tamkin, Miles McCain, Kunal Handa, Esin Durmus, Liane Lovitt, Ankur Rathi, Saffron Huang, Alfred Mountfield, Jerry Hong, Stuart Ritchie, Michael Stern, Brian Clarke, Landon Goldberg, Theodore R. Sumers, Jared Mueller, William McEachen, Wes Mitchell, Shan Carter, Jack Clark, Jared Kaplan, Deep Ganguli

How are AI assistants being used in the real world? While model providers in
theory have a window into this impact via their users' data, both privacy
concerns and practical challenges have made analyzing this data difficult. To
address these issues, we present Clio (Claude insights and observations), a
privacy-preserving platform that uses AI assistants themselves to analyze and
surface aggregated usage patterns across millions of conversations, without the
need for human reviewers to read raw conversations. We validate this can be
done with a high degree of accuracy and privacy by conducting extensive
evaluations. We demonstrate Clio's usefulness in two broad ways. First, we
share insights about how models are being used in the real world from one
million Claude.ai Free and Pro conversations, ranging from providing advice on
hairstyles to providing guidance on Git operations and concepts. We also
identify the most common high-level use cases on Claude.ai (coding, writing,
and research tasks) as well as patterns that differ across languages (e.g.,
conversations in Japanese discuss elder care and aging populations at
higher-than-typical rates). Second, we use Clio to make our systems safer by
identifying coordinated attempts to abuse our systems, monitoring for unknown
unknowns during critical periods like launches of new capabilities or major
world events, and improving our existing monitoring systems. We also discuss
the limitations of our approach, as well as risks and ethical concerns. By
enabling analysis of real-world AI usage, Clio provides a scalable platform for
empirically grounded AI safety and governance.

æè¦ï¼äººå·¥æºè½å©çå¨ç¾å¯¦ä¸çä¸­å¦ä½ä½¿ç¨ï¼éç¶çè«ä¸æ¨¡åä¾æåå¯ä»¥ééä½¿ç¨èçè³æäºè§£éç¨®å½±é¿ï¼ä½é±ç§åé¡åå¯¦éææ°é½è®åæéäºè³æè®å¾å°é£ãçºäºè§£æ±ºéäºåé¡ï¼æåæåºäº Clioï¼Claude è¦è§£èè§å¯ï¼ï¼ä¸åé±ç§ä¿è­·å¹³å°ï¼å®ä½¿ç¨äººå·¥æºè½å©çæ¬èº«ä¾åæä¸¦æµ®åºæ¸ç¾è¬æ¬¡å°è©±ä¸­çå½æ´ä½¿ç¨æ¨¡å¼ï¼èä¸éè¦äººé¡å¯©æ¥å¡é±è®åå§å°è©±ãæåééé²è¡å»£æ³çè©ä¼°ï¼é©è­éå¯ä»¥ç¨é«åº¦æºç¢ºåé±ç§ä¾å®æãæåä»¥å©ç¨®å»£æ³çæ¹å¼å±ç¤º Clio çç¨éãé¦åï¼æååäº«éæ¼æ¨¡åå¨ç¾å¯¦ä¸çä¸­å¦ä½ä½¿ç¨çä¸ç¾è¬å Claude.ai åè²»åå°æ¥­å°è©±çè¦è§£ï¼ç¯åå¾æä¾é«®åå»ºè­°å°æä¾æé Git æä½åæ¦å¿µçæå°ãæåéæ¾åº Claude.ai ä¸æå¸¸è¦çé«éä½¿ç¨æ¡ä¾ï¼ç·¨ç¢¼ãå¯«ä½åç ç©¶ä»»åï¼ï¼ä»¥åä¸åèªè¨ä¹éçæ¨¡å¼å·®ç°ï¼ä¾å¦ï¼æ¥èªå°è©±è¨è«èå¹´ç§è­·åèé½¡åäººå£çæ¯çé«æ¼ä¸è¬ï¼ãå¶æ¬¡ï¼æåä½¿ç¨ Clio ééæ¾åºåèª¿æ¿«ç¨æåç³»çµ±çåè©¦ãå¨ååæ°åè½æéå¤§ä¸çäºä»¶ç­ééµææç£æ§æªç¥çæªç¥æ¸ï¼ä»¥åæ¹åæåç¾æçç£æ§ç³»çµ±ï¼è®æåçç³»çµ±æ´å®å¨ãæåä¹è¨è«æåæ¹æ³çéå¶ï¼ä»¥åé¢¨éªåéå¾·åé¡ãééåç¨å°ç¾å¯¦ä¸çäººå·¥æºè½ä½¿ç¨çåæï¼Clio æä¾äºä¸åå¯æ´åçå¹³å°ï¼ç¨æ¼ä»¥ç¶é©çºåºç¤çäººå·¥æºè½å®å¨åæ²»çã

##### **Exploring Multi-Modal Integration with Tool-Augmented LLM Agents for Precise Causal Discovery**
2412.13667v1 by ChengAo Shen, Zhengzhang Chen, Dongsheng Luo, Dongkuan Xu, Haifeng Chen, Jingchao Ni

Causal inference is an imperative foundation for decision-making across
domains, such as smart health, AI for drug discovery and AIOps. Traditional
statistical causal discovery methods, while well-established, predominantly
rely on observational data and often overlook the semantic cues inherent in
cause-and-effect relationships. The advent of Large Language Models (LLMs) has
ushered in an affordable way of leveraging the semantic cues for
knowledge-driven causal discovery, but the development of LLMs for causal
discovery lags behind other areas, particularly in the exploration of
multi-modality data. To bridge the gap, we introduce MATMCD, a multi-agent
system powered by tool-augmented LLMs. MATMCD has two key agents: a Data
Augmentation agent that retrieves and processes modality-augmented data, and a
Causal Constraint agent that integrates multi-modal data for knowledge-driven
inference. Delicate design of the inner-workings ensures successful cooperation
of the agents. Our empirical study across seven datasets suggests the
significant potential of multi-modality enhanced causal discovery.

æè¦ï¼å ææ¨è«æ¯è·¨é åæ±ºç­å¶å®ä¸­çå¿è¦åºç¤ï¼ä¾å¦æºæ§é«çãç¨æ¼è¥ç©ç¼ç¾çäººå·¥æºæ§å AIOpsãå³çµ±ççµ±è¨å æç¼ç¾æ¹æ³éç¶å·²ç¶ç¢ºç«ï¼ä½ä¸»è¦ä¾è³´æ¼è§å¯è³æï¼ä¸å¸¸å¸¸å¿½ç¥å æéä¿ä¸­åºæçèªæç·ç´¢ãå¤§åèªè¨æ¨¡å (LLM) çåºç¾ï¼éåäºä¸ç¨®å©ç¨èªæç·ç´¢é²è¡ç¥è­é©åå æç¼ç¾çæ¹æ³ï¼ä½ç¨æ¼å æç¼ç¾ç LLM ç¼å±è½å¾æ¼å¶ä»é åï¼ç¹å¥æ¯å¨å¤æ¨¡æè³æçæ¢ç´¢æ¹é¢ãçºäºå½è£å·®è·ï¼æåå¼å¥äº MATMCDï¼éæ¯ä¸åç±å·¥å·å¢å¼·ç LLM é©åçå¤ä¸»é«ç³»çµ±ãMATMCD æå©åééµä¸»é«ï¼ä¸åè³ææ´åä¸»é«ï¼ç¨æ¼æ·ååèçæ¨¡ææ´åè³æï¼ä»¥åä¸åå æç´æä¸»é«ï¼ç¨æ¼æ´åå¤æ¨¡æè³æé²è¡ç¥è­é©åæ¨è«ãå§é¨éä½çç²¾ç´°è¨­è¨ç¢ºä¿äºä¸»é«ä¹éçæååä½ãæåå°ä¸åè³æéçå¯¦è­ç ç©¶è¡¨æï¼å¤æ¨¡æå¢å¼·å æç¼ç¾å·æé¡¯èçæ½åã

##### **BadSAD: Clean-Label Backdoor Attacks against Deep Semi-Supervised Anomaly Detection**
2412.13324v1 by He Cheng, Depeng Xu, Shuhan Yuan

Image anomaly detection (IAD) is essential in applications such as industrial
inspection, medical imaging, and security. Despite the progress achieved with
deep learning models like Deep Semi-Supervised Anomaly Detection (DeepSAD),
these models remain susceptible to backdoor attacks, presenting significant
security challenges. In this paper, we introduce BadSAD, a novel backdoor
attack framework specifically designed to target DeepSAD models. Our approach
involves two key phases: trigger injection, where subtle triggers are embedded
into normal images, and latent space manipulation, which positions and clusters
the poisoned images near normal images to make the triggers appear benign.
Extensive experiments on benchmark datasets validate the effectiveness of our
attack strategy, highlighting the severe risks that backdoor attacks pose to
deep learning-based anomaly detection systems.

æè¦ï¼å½±åç°å¸¸åµæ¸¬ï¼IADï¼å¨å·¥æ¥­æª¢æ¥ãé«çå½±ååå®å¨ç­æç¨ä¸­è³ééè¦ãåç®¡æ·±åº¦å­¸ç¿æ¨¡åï¼å¦æ·±åº¦åç£ç£ç°å¸¸åµæ¸¬ï¼DeepSADï¼ï¼å·²åå¾é²å±ï¼ä½éäºæ¨¡åä»ç¶å®¹æåå°å¾éæ»æï¼é æéå¤§çå®å¨ææ°ãå¨æ¬æä¸­ï¼æåä»ç´¹ BadSADï¼ä¸åå°ééå° DeepSAD æ¨¡åè¨­è¨çæ°åå¾éæ»ææ¶æ§ãæåçåæ³åå«å©åééµéæ®µï¼è§¸ç¼æ³¨å¥ï¼å¶ä¸­å°ç´°å¾®è§¸ç¼åµå¥å°æ­£å¸¸å½±åä¸­ï¼ä»¥åæ½å¨ç©ºéæä½ï¼å°ä¸­æ¯å½±åå®ä½ä¸¦ç¾¤éå¨æ­£å¸¸å½±åéè¿ï¼ä»¥ä½¿è§¸ç¼çèµ·ä¾æ¯è¯æ§çãå¨åºæºè³æéä¸é²è¡çå»£æ³å¯¦é©é©è­äºæåæ»æç­ç¥çæææ§ï¼çªé¡¯äºå¾éæ»æå°åºæ¼æ·±åº¦å­¸ç¿çç°å¸¸åµæ¸¬ç³»çµ±é æçå´éé¢¨éªã

##### **In-context learning for medical image segmentation**
2412.13299v1 by Eichi Takaya, Shinnosuke Yamamoto

Annotation of medical images, such as MRI and CT scans, is crucial for
evaluating treatment efficacy and planning radiotherapy. However, the extensive
workload of medical professionals limits their ability to annotate large image
datasets, posing a bottleneck for AI applications in medical imaging. To
address this, we propose In-context Cascade Segmentation (ICS), a novel method
that minimizes annotation requirements while achieving high segmentation
accuracy for sequential medical images. ICS builds on the UniverSeg framework,
which performs few-shot segmentation using support images without additional
training. By iteratively adding the inference results of each slice to the
support set, ICS propagates information forward and backward through the
sequence, ensuring inter-slice consistency. We evaluate the proposed method on
the HVSMR dataset, which includes segmentation tasks for eight cardiac regions.
Experimental results demonstrate that ICS significantly improves segmentation
performance in complex anatomical regions, particularly in maintaining boundary
consistency across slices, compared to baseline methods. The study also
highlights the impact of the number and position of initial support slices on
segmentation accuracy. ICS offers a promising solution for reducing annotation
burdens while delivering robust segmentation results, paving the way for its
broader adoption in clinical and research applications.

æè¦ï¼é«å­¸å½±åçè¨»è§£ï¼ä¾å¦ MRI å CT ææï¼å°æ¼è©ä¼°æ²»çææåè¦åæ¾å°æ²»çè³ééè¦ãç¶èï¼é«è­·äººå¡é¾å¤§çå·¥ä½ééå¶äºä»åè¨»è§£å¤§åå½±åè³æéçè½åï¼å°é«å­¸å½±åä¸­ç AI æç¨æ§æç¶é ¸ãçºäºè§£æ±ºéååé¡ï¼æåæåºæå¢ä¸²è¯åå² (ICS)ï¼éæ¯ä¸ç¨®æ°æ¹æ³ï¼å¯æå¤§ç¨åº¦æ¸å°è¨»è§£éæ±ï¼åæçºé åºé«å­¸å½±åå¯¦ç¾é«åå²æºç¢ºåº¦ãICS å»ºç«å¨ UniverSeg æ¶æ§ä¹ä¸ï¼è©²æ¶æ§ä½¿ç¨æ¯æ´å½±åå·è¡å°éåå²ï¼èç¡éé¡å¤è¨ç·´ãééåè¦å°æ¯ååççæ¨è«çµææ°å¢å°æ¯æ´éï¼ICS ééåºåååååå¾å³æ­è³è¨ï¼ç¢ºä¿åçéçä¸è´æ§ãæåå¨ HVSMR è³æéä¸è©ä¼°ææåºçæ¹æ³ï¼å¶ä¸­åæ¬å«åå¿èååçåå²ä»»åãå¯¦é©çµæè¡¨æï¼èåºæºæ¹æ³ç¸æ¯ï¼ICS å¨è¤éçè§£åååé¡¯èæ¹åäºåå²æè½ï¼ç¹å¥æ¯å¨ç¶­è­·åçéçéçä¸è´æ§æ¹é¢ãè©²ç ç©¶éå¼·èª¿äºåå§æ¯æ´åççæ¸éåä½ç½®å°åå²æºç¢ºåº¦çå½±é¿ãICS æä¾äºä¸åæå¸æçè§£æ±ºæ¹æ¡ï¼å¯ä»¥å¨æä¾ç©©å¥çåå²çµæçåææ¸å°è¨»è§£è² æï¼çºå¶å¨è¨åºåç ç©¶æç¨ä¸­çæ´å»£æ³æ¡ç¨éªå¹³éè·¯ã

##### **Continuous Patient Monitoring with AI: Real-Time Analysis of Video in Hospital Care Settings**
2412.13152v1 by Paolo Gabriel, Peter Rehani, Tyler Troy, Tiffany Wyatt, Michael Choma, Narinder Singh

This study introduces an AI-driven platform for continuous and passive
patient monitoring in hospital settings, developed by LookDeep Health.
Leveraging advanced computer vision, the platform provides real-time insights
into patient behavior and interactions through video analysis, securely storing
inference results in the cloud for retrospective evaluation. The dataset,
compiled in collaboration with 11 hospital partners, encompasses over 300
high-risk fall patients and over 1,000 days of inference, enabling applications
such as fall detection and safety monitoring for vulnerable patient
populations. To foster innovation and reproducibility, an anonymized subset of
this dataset is publicly available. The AI system detects key components in
hospital rooms, including individual presence and role, furniture location,
motion magnitude, and boundary crossings. Performance evaluation demonstrates
strong accuracy in object detection (macro F1-score = 0.92) and patient-role
classification (F1-score = 0.98), as well as reliable trend analysis for the
"patient alone" metric (mean logistic regression accuracy = 0.82 \pm 0.15).
These capabilities enable automated detection of patient isolation, wandering,
or unsupervised movement-key indicators for fall risk and other adverse events.
This work establishes benchmarks for validating AI-driven patient monitoring
systems, highlighting the platform's potential to enhance patient safety and
care by providing continuous, data-driven insights into patient behavior and
interactions.

æè¦ï¼æ¬ç ç©¶ä»ç´¹äºä¸åç± LookDeep Health éç¼ç AI é©åå¹³å°ï¼ç¨æ¼å¨é«é¢ç°å¢ä¸­æçºä¸è¢«åå°ç£æ§æ£èãè©²å¹³å°å©ç¨åé²çé»è¦è¦è¦ºæè¡ï¼ééå½±çåææä¾æ£èè¡çºåäºåçå³æè¦è§£ï¼ä¸¦å°æ¨è«çµæå®å¨å°å²å­å¨é²ç«¯ä»¥ä¾åé¡§æ§è©ä¼°ãè©²è³æéè 11 å®¶åä½é«é¢å±åç·¨å¶ï¼åå« 300 å¤åé«é¢¨éªè·åæ£èå 1,000 å¤å¤©çæ¨è«ï¼é©ç¨æ¼è·ååµæ¸¬åèå¼±æ£èæç¾¤çå®å¨ç£æ§ç­æç¨ãçºäºä¿é²åµæ°åå¯è¤è£½æ§ï¼éä»½è³æéçå¿åå­éå·²å¬éæä¾ãAI ç³»çµ±æåµæ¸¬é«é¢æ¿éä¸­çééµçµæé¨åï¼åæ¬åäººå­å¨åè§è²ãå®¶å·ä½ç½®ãåä½å¹åº¦åéçç©¿è¶ãæè½è©ä¼°é¡¯ç¤ºç©ä»¶åµæ¸¬ï¼å·¨è§ F1 åæ¸ = 0.92ï¼åæ£èè§è²åé¡ï¼F1 åæ¸ = 0.98ï¼å·æå¾é«çæºç¢ºæ§ï¼ä»¥åãæ£èç¨èªä¸äººãææ¨çå¯é è¶¨å¢åæï¼å¹³åéè¼¯è¿´æ­¸æºç¢ºæ§ = 0.82 Â± 0.15ï¼ãéäºåè½å¯èªååµæ¸¬æ£èéé¢ãéèµ°æç¡ç£ç£çç§»åï¼éäºé½æ¯è·åé¢¨éªåå¶ä»ä¸è¯äºä»¶çééµææ¨ãéé å·¥ä½çºé©è­ AI é©åçæ£èç£æ§ç³»çµ±å»ºç«äºåºæºï¼çªé¡¯äºè©²å¹³å°ééæä¾æçºä¸è³æé©åçæ£èè¡çºåäºåè¦è§£ï¼å¢å¼·æ£èå®å¨åç§è­·çæ½åã

##### **Boosting Fine-Grained Visual Anomaly Detection with Coarse-Knowledge-Aware Adversarial Learning**
2412.12850v1 by Qingqing Fang, Qinliang Su, Wenxi Lv, Wenchao Xu, Jianxing Yu

Many unsupervised visual anomaly detection methods train an auto-encoder to
reconstruct normal samples and then leverage the reconstruction error map to
detect and localize the anomalies. However, due to the powerful modeling and
generalization ability of neural networks, some anomalies can also be well
reconstructed, resulting in unsatisfactory detection and localization accuracy.
In this paper, a small coarsely-labeled anomaly dataset is first collected.
Then, a coarse-knowledge-aware adversarial learning method is developed to
align the distribution of reconstructed features with that of normal features.
The alignment can effectively suppress the auto-encoder's reconstruction
ability on anomalies and thus improve the detection accuracy. Considering that
anomalies often only occupy very small areas in anomalous images, a patch-level
adversarial learning strategy is further developed. Although no patch-level
anomalous information is available, we rigorously prove that by simply viewing
any patch features from anomalous images as anomalies, the proposed
knowledge-aware method can also align the distribution of reconstructed patch
features with the normal ones. Experimental results on four medical datasets
and two industrial datasets demonstrate the effectiveness of our method in
improving the detection and localization performance.

æè¦ï¼è¨±å¤ç¡ç£ç£è¦è¦ºç°å¸¸åµæ¸¬æ¹æ³æè¨ç·´èªåç·¨ç¢¼å¨ä¾éå»ºæ­£å¸¸æ¨£æ¬ï¼ç¶å¾å©ç¨éå»ºèª¤å·®åä¾åµæ¸¬åå®ä½ç°å¸¸ãç¶èï¼ç±æ¼ç¥ç¶ç¶²è·¯å¼·å¤§çå»ºæ¨¡åæ¦åè½åï¼ä¸äºç°å¸¸ä¹å¯ä»¥è¢«è¯å¥½å°éå»ºï¼å°è´ä¸ä»¤äººæ»¿æçåµæ¸¬åå®ä½æºç¢ºåº¦ãå¨æ¬æä¸­ï¼é¦åæ¶éäºä¸åå°åç²ç¥æ¨è¨çç°å¸¸è³æéãç¶å¾ï¼éç¼äºä¸åç²ç¥ç¥è­æç¥å°æå­¸ç¿æ¹æ³ï¼ä»¥å°éå»ºç¹å¾µçåå¸èæ­£å¸¸ç¹å¾µçåå¸å°é½ãå°é½å¯ä»¥ææå°æå¶èªåç·¨ç¢¼å¨å°ç°å¸¸çéå»ºè½åï¼å¾èæé«åµæ¸¬æºç¢ºåº¦ãèæ®å°ç°å¸¸éå¸¸åªä½ç°å¸¸å½±åä¸­å¾å°çååï¼é²ä¸æ­¥éç¼äºåå¡ç´å°æå­¸ç¿ç­ç¥ãåç®¡æ²æåå¡ç´ç°å¸¸è³è¨å¯ç¨ï¼ä½æåå´æ ¼è­æï¼åªéå°ç°å¸¸å½±åä¸­çä»»ä½åå¡ç¹å¾µè¦çºç°å¸¸ï¼ææåºçç¥è­æç¥æ¹æ³ä¹å¯ä»¥å°éå»ºåå¡ç¹å¾µçåå¸èæ­£å¸¸ç¹å¾µå°é½ãå¨ååé«å­¸è³æéåå©åå·¥æ¥­è³æéä¸çå¯¦é©çµæè­æäºæåçæ¹æ³å¨æ¹ååµæ¸¬åå®ä½æè½æ¹é¢çæææ§ã

##### **Rethinking Diffusion-Based Image Generators for Fundus Fluorescein Angiography Synthesis on Limited Data**
2412.12778v1 by Chengzhou Yu, Huihui Fang, Hongqiu Wang, Ting Deng, Qing Du, Yanwu Xu, Weihua Yang

Fundus imaging is a critical tool in ophthalmology, with different imaging
modalities offering unique advantages. For instance, fundus fluorescein
angiography (FFA) can accurately identify eye diseases. However, traditional
invasive FFA involves the injection of sodium fluorescein, which can cause
discomfort and risks. Generating corresponding FFA images from non-invasive
fundus images holds significant practical value but also presents challenges.
First, limited datasets constrain the performance and effectiveness of models.
Second, previous studies have primarily focused on generating FFA for single
diseases or single modalities, often resulting in poor performance for patients
with various ophthalmic conditions. To address these issues, we propose a novel
latent diffusion model-based framework, Diffusion, which introduces a
fine-tuning protocol to overcome the challenge of limited medical data and
unleash the generative capabilities of diffusion models. Furthermore, we
designed a new approach to tackle the challenges of generating across different
modalities and disease types. On limited datasets, our framework achieves
state-of-the-art results compared to existing methods, offering significant
potential to enhance ophthalmic diagnostics and patient care. Our code will be
released soon to support further research in this field.

æè¦ï¼ç¼åºæåæè¡æ¯ç¼ç§ä¸­çä¸é éè¦å·¥å·ï¼ä¸åçæåæ¹å¼åæåªå¢ãä¾å¦ï¼ç¼åºè¢åç´ è¡ç®¡æå½± (FFA) å¯ç²¾æºè¾¨è­ç¼é¨ç¾çãç¶èï¼å³çµ±ä¾µå¥å¼ç FFA ææ³¨å°è¢åç´ éï¼å¯è½æé æä¸é©åé¢¨éªãå¾éä¾µå¥å¼ç¼åºå½±åä¸­ç¢çç¸å°æç FFA å½±åå·æéè¦çå¯¦ç¨å¹å¼ï¼ä½ä¹å­å¨ææ°ãé¦åï¼æéçè³æéæéå¶æ¨¡åçæè½åææãå¶æ¬¡ï¼ååçç ç©¶ä¸»è¦éä¸­å¨çºå®ä¸ç¾çæå®ä¸æ¹å¼ç¢ç FFAï¼å°æ¼æ£æå¤ç¨®ç¼ç§ç¾ççæ£èï¼æè½éå¸¸ä¸ä½³ãçºäºè§£æ±ºéäºåé¡ï¼æåæåºä¸åæ°ç©çæ½å¨æ´æ£æ¨¡åæ¶æ§ï¼ç¨±çº Diffusionï¼å®å¼å¥ä¸åå¾®èª¿åå®ï¼ä»¥åæé«çè³ææéçææ°ï¼ä¸¦éæ¾æ´æ£æ¨¡åççæè½åãæ­¤å¤ï¼æåè¨­è¨äºä¸ç¨®æ°æ¹æ³ä¾æå°è·¨ä¸åæ¹å¼åç¾çé¡åçæå½±åçææ°ãå¨æéçè³æéä¸ï¼èç¾ææ¹æ³ç¸æ¯ï¼æåçæ¶æ§éå°äºæåé²ççµæï¼çºå¢å¼·ç¼ç§è¨ºæ·åæ£èç§è­·æä¾äºé¡¯èçæ½åãæåçç¨å¼ç¢¼å°å¾å¿«éåºï¼ä»¥æ¯ææ­¤é åçé²ä¸æ­¥ç ç©¶ã

##### **MedMax: Mixed-Modal Instruction Tuning for Training Biomedical Assistants**
2412.12661v1 by Hritik Bansal, Daniel Israel, Siyan Zhao, Shufan Li, Tung Nguyen, Aditya Grover

Recent advancements in mixed-modal generative models have enabled flexible
integration of information across image-text content. These models have opened
new avenues for developing unified biomedical assistants capable of analyzing
biomedical images, answering complex questions about them, and predicting the
impact of medical procedures on a patient's health. However, existing resources
face challenges such as limited data availability, narrow domain coverage, and
restricted sources (e.g., medical papers). To address these gaps, we present
MedMax, the first large-scale multimodal biomedical instruction-tuning dataset
for mixed-modal foundation models. With 1.47 million instances, MedMax
encompasses a diverse range of tasks, including multimodal content generation
(interleaved image-text data), biomedical image captioning and generation,
visual chatting, and report understanding. These tasks span diverse medical
domains such as radiology and histopathology. Subsequently, we fine-tune a
mixed-modal foundation model on the MedMax dataset, achieving significant
performance improvements: a 26% gain over the Chameleon model and an 18.3%
improvement over GPT-4o across 12 downstream biomedical visual
question-answering tasks. Additionally, we introduce a unified evaluation suite
for biomedical tasks, providing a robust framework to guide the development of
next-generation mixed-modal biomedical AI assistants.

æè¦ï¼æ··åæ¨¡å¼çææ¨¡åçææ°è¿å±ä½¿å¾è·¨å¾åææ¬åå®¹çµæ´»æ´åä¿¡æ¯æä¸ºå¯è½ãè¿äºæ¨¡åä¸ºå¼åç»ä¸ççç©å»å­¦å©æå¼è¾äºæ°éå¾ï¼è¿äºå©æè½å¤åæçç©å»å­¦å¾åãåç­æå³å¾åçå¤æé®é¢ï¼å¹¶é¢æµå»çç¨åºå¯¹æ£èå¥åº·çå½±åãç¶èï¼ç°æèµæºé¢ä¸´çæ°æ®å¯ç¨æ§æéãé¢åè¦çèå´ç­çªåæ¥æºåéï¼ä¾å¦å»å­¦è®ºæï¼ç­ææãä¸ºäºè§£å³è¿äºå·®è·ï¼æä»¬æåºäº MedMaxï¼è¿æ¯ç¬¬ä¸ä¸ªç¨äºæ··åæ¨¡å¼åºç¡æ¨¡åçå¤§è§æ¨¡å¤æ¨¡æçç©å»å­¦æä»¤å¾®è°æ°æ®éãMedMax æ¥æ 147 ä¸ä¸ªå®ä¾ï¼æ¶µçäºåç§ä»»å¡ï¼åæ¬å¤æ¨¡æåå®¹çæï¼äº¤éå¾åææ¬æ°æ®ï¼ãçç©å»å­¦å¾åæ é¢åçæãå¯è§åèå¤©åæ¥åçè§£ãè¿äºä»»å¡è·¨è¶äºæ¾å°å­¦åç»ç»ççå­¦ç­ä¸åçå»å­¦é¢åãéåï¼æä»¬å¨ MedMax æ°æ®éä¸å¯¹æ··åæ¨¡å¼åºç¡æ¨¡åè¿è¡å¾®è°ï¼åå¾äºæ¾èçæ§è½æåï¼å¨ 12 ä¸ªä¸æ¸¸çç©å»å­¦è§è§é®ç­ä»»å¡ä¸­ï¼æ¯ Chameleon æ¨¡åæåäº 26%ï¼æ¯ GPT-4o æåäº 18.3%ãæ­¤å¤ï¼æä»¬è¿å¼å¥äºç¨äºçç©å»å­¦ä»»å¡çç»ä¸è¯ä¼°å¥ä»¶ï¼ä¸ºæå¯¼ä¸ä¸ä»£æ··åæ¨¡å¼çç©å»å­¦ AI å©æçåå±æä¾äºç¨³å¥çæ¡æ¶ã

##### **a2z-1 for Multi-Disease Detection in Abdomen-Pelvis CT: External Validation and Performance Analysis Across 21 Conditions**
2412.12629v1 by Pranav Rajpurkar, Julian N. Acosta, Siddhant Dogra, Jaehwan Jeong, Deepanshu Jindal, Michael Moritz, Samir Rajpurkar

We present a comprehensive evaluation of a2z-1, an artificial intelligence
(AI) model designed to analyze abdomen-pelvis CT scans for 21 time-sensitive
and actionable findings. Our study focuses on rigorous assessment of the
model's performance and generalizability. Large-scale retrospective analysis
demonstrates an average AUC of 0.931 across 21 conditions. External validation
across two distinct health systems confirms consistent performance (AUC 0.923),
establishing generalizability to different evaluation scenarios, with notable
performance in critical findings such as small bowel obstruction (AUC 0.958)
and acute pancreatitis (AUC 0.961). Subgroup analysis shows consistent accuracy
across patient sex, age groups, and varied imaging protocols, including
different slice thicknesses and contrast administration types. Comparison of
high-confidence model outputs to radiologist reports reveals instances where
a2z-1 identified overlooked findings, suggesting potential for quality
assurance applications.

æè¦ï¼æåæåº a2z-1 çå¨é¢è©ä¼°ï¼éæ¯ä¸åäººå·¥æºæ§ (AI) æ¨¡åï¼æ¨å¨åæè¹é¨éª¨çé»è¦æ·å±¤ææï¼ä»¥æ¾åº 21 é æéææä¸å¯æ¡åè¡åçç¼ç¾ãæåçç ç©¶éé»å¨æ¼å´æ ¼è©ä¼°æ¨¡åçæè½åæ¦æ¬æ§ãå¤§è¦æ¨¡åé¡§æ§åæé¡¯ç¤ºï¼21 ç¨®ç¾ççå¹³å AUC çº 0.931ãå©åä¸åé«çç³»çµ±çå¤é¨é©è­ç¢ºèªæè½ä¸è´ï¼AUC 0.923ï¼ï¼å»ºç«äºå°ä¸åè©ä¼°æå¢çæ¦æ¬æ§ï¼å¨å°è¸é»å¡ï¼AUC 0.958ï¼åæ¥æ§è°èçï¼AUC 0.961ï¼ç­ééµç¼ç¾ä¸­è¡¨ç¾åºè²ãæ¬¡ç¾¤é«åæé¡¯ç¤ºï¼å¨æ£èæ§å¥ãå¹´é½¡çµåä¸åçå½±ååè­°ï¼åæ¬ä¸åçåçååº¦åå°æ¯åæ½ç¨é¡åï¼ä¸­ï¼æºç¢ºåº¦ä¸è´ãå°é«ä¿¡è³´åº¦æ¨¡åè¼¸åºèæ¾å°ç§é«å¸«å ±åé²è¡æ¯è¼ï¼æ­ç¤ºäº a2z-1 æ¾åºè¢«å¿½ç¥ç¼ç¾çç¯ä¾ï¼è¡¨ç¤ºææ½åç¨æ¼åè³ªä¿è­æç¨ã

##### **A Scalable Approach to Benchmarking the In-Conversation Differential Diagnostic Accuracy of a Health AI**
2412.12538v1 by Deep Bhatt, Surya Ayyagari, Anuruddh Mishra

Diagnostic errors in healthcare persist as a critical challenge, with
increasing numbers of patients turning to online resources for health
information. While AI-powered healthcare chatbots show promise, there exists no
standardized and scalable framework for evaluating their diagnostic
capabilities. This study introduces a scalable benchmarking methodology for
assessing health AI systems and demonstrates its application through August, an
AI-driven conversational chatbot. Our methodology employs 400 validated
clinical vignettes across 14 medical specialties, using AI-powered patient
actors to simulate realistic clinical interactions. In systematic testing,
August achieved a top-one diagnostic accuracy of 81.8% (327/400 cases) and a
top-two accuracy of 85.0% (340/400 cases), significantly outperforming
traditional symptom checkers. The system demonstrated 95.8% accuracy in
specialist referrals and required 47% fewer questions compared to conventional
symptom checkers (mean 16 vs 29 questions), while maintaining empathetic
dialogue throughout consultations. These findings demonstrate the potential of
AI chatbots to enhance healthcare delivery, though implementation challenges
remain regarding real-world validation and integration of objective clinical
data. This research provides a reproducible framework for evaluating healthcare
AI systems, contributing to the responsible development and deployment of AI in
clinical settings.

æè¦ï¼é«çä¿å¥ä¸­çè¨ºæ·é¯èª¤æçºæçºä¸é éå¤§ææ°ï¼è¶ä¾è¶å¤çæ£èæ±å©æ¼ç·ä¸è³æºä¾åå¾å¥åº·è³è¨ãåç®¡ç±äººå·¥æºæ§é©åçé«çä¿å¥èå¤©æ©å¨äººå±ç¾åºåæ¯ï¼ä½ç®åéæ²ææ¨æºåä¸å¯æ´åçæ¶æ§ä¾è©ä¼°å¶è¨ºæ·è½åãæ¬ç ç©¶ä»ç´¹äºä¸ç¨®å¯æ´åçåºæºæ¸¬è©¦æ¹æ³ï¼ç¨æ¼è©ä¼°å¥åº·äººå·¥æºæ§ç³»çµ±ï¼ä¸¦ééç±äººå·¥æºæ§é©åçå°è©±å¼èå¤©æ©å¨äºº Augustï¼å±ç¤ºå¶æç¨ãæåçåæ³æ¡ç¨äº 14 åé«çå°ç§ç 400 åå·²é©è­è¨åºå°æäºï¼ä¸¦ä½¿ç¨ç±äººå·¥æºæ§é©åçæ£èè§è²æ¨¡æ¬å¯¦éçè¨åºäºåãå¨ç³»çµ±æ§æ¸¬è©¦ä¸­ï¼August éå°äº 81.8% çåä¸é è¨ºæ·æºç¢ºåº¦ï¼327/400 åæ¡ä¾ï¼å 85.0% çåå©é æºç¢ºåº¦ï¼340/400 åæ¡ä¾ï¼ï¼é¡¯èåªæ¼å³çµ±çççæª¢æ¥å¨ãè©²ç³»çµ±å¨å°ç§è½è¨ºæ¹é¢è¡¨ç¾åº 95.8% çæºç¢ºåº¦ï¼ä¸¦ä¸èå³çµ±ççæª¢æ¥å¨ç¸æ¯ï¼æéçæåæ¸éæ¸å°äº 47%ï¼å¹³å 16 ååé¡ï¼ç¸è¼æ¼ 29 ååé¡ï¼ï¼åæå¨è«®è©¢éç¨ä¸­ç¶­æåççå°è©±ãéäºç¼ç¾è­æäºäººå·¥æºæ§èå¤©æ©å¨äººå¢å¼·é«çä¿å¥æåçæ½åï¼åç®¡å¨å¯¦éé©è­åæ´åå®¢è§è¨åºæ¸ææ¹é¢ä»å­å¨å¯¦ä½ææ°ãæ¬ç ç©¶æä¾äºä¸åå¯è¤è£½çæ¶æ§ï¼ç¨æ¼è©ä¼°é«çä¿å¥äººå·¥æºæ§ç³»çµ±ï¼æå©æ¼å¨è¨åºç°å¢ä¸­è² è²¬ä»»å°éç¼åé¨ç½²äººå·¥æºæ§ã

##### **Addressing Small and Imbalanced Medical Image Datasets Using Generative Models: A Comparative Study of DDPM and PGGANs with Random and Greedy K Sampling**
2412.12532v1 by Iman Khazrak, Shakhnoza Takhirova, Mostafa M. Rezaee, Mehrdad Yadollahi, Robert C. Green II, Shuteng Niu

The development of accurate medical image classification models is often
constrained by privacy concerns and data scarcity for certain conditions,
leading to small and imbalanced datasets. To address these limitations, this
study explores the use of generative models, such as Denoising Diffusion
Probabilistic Models (DDPM) and Progressive Growing Generative Adversarial
Networks (PGGANs), for dataset augmentation. The research introduces a
framework to assess the impact of synthetic images generated by DDPM and PGGANs
on the performance of four models: a custom CNN, Untrained VGG16, Pretrained
VGG16, and Pretrained ResNet50. Experiments were conducted using Random
Sampling and Greedy K Sampling to create small, imbalanced datasets. The
synthetic images were evaluated using Frechet Inception Distance (FID) and
compared to original datasets through classification metrics. The results show
that DDPM consistently generated more realistic images with lower FID scores
and significantly outperformed PGGANs in improving classification metrics
across all models and datasets. Incorporating DDPM-generated images into the
original datasets increased accuracy by up to 6%, enhancing model robustness
and stability, particularly in imbalanced scenarios. Random Sampling
demonstrated superior stability, while Greedy K Sampling offered diversity at
the cost of higher FID scores. This study highlights the efficacy of DDPM in
augmenting small, imbalanced medical image datasets, improving model
performance by balancing the dataset and expanding its size.

æè¦ï¼<paragraph>æºç¢ºé«çå½±ååé¡æ¨¡åçéç¼å¸¸åéæ¼é±ç§çæ®åç¹å®çæ³è³æçç¨ç¼ºï¼éå°è´è³æéè¦æ¨¡å°ä¸ä¸å¹³è¡¡ãçºäºè§£æ±ºéäºéå¶ï¼æ¬ç ç©¶æ¢è¨çææ¨¡åï¼ä¾å¦å»åªæ´æ£æ©çæ¨¡å (DDPM) åæ¼¸é²å¼çæå°æç¶²è·¯ (PGGAN)ï¼ç¨æ¼è³æéæ´åãæ¬ç ç©¶å¼é²ä¸åæ¶æ§ï¼è©ä¼°ç± DDPM å PGGAN çæçåæå½±åå°ååæ¨¡åæè½çå½±é¿ï¼èªè¨ CNNãUntrained VGG16ãPretrained VGG16 å Pretrained ResNet50ãå¯¦é©ä½¿ç¨é¨æ©åæ¨£åè²ªå©ª K åæ¨£é²è¡ï¼ä»¥å»ºç«å°è¦æ¨¡çä¸å¹³è¡¡è³æéãåæå½±åä½¿ç¨ FrÃ©chet èµ·å§è·é¢ (FID) é²è¡è©ä¼°ï¼ä¸¦ééåé¡ææ¨èåå§è³æéé²è¡æ¯è¼ãçµæé¡¯ç¤ºï¼DDPM æçºç¢çè¼é¼ççå½±åï¼FID åæ¸è¼ä½ï¼ä¸å¨æ¹åæææ¨¡ååè³æéçåé¡ææ¨æ¹é¢ï¼è¡¨ç¾æé¡¯åªæ¼ PGGANãå° DDPM çæçå½±åç´å¥åå§è³æéï¼å¯å°æºç¢ºåº¦æåå¤é 6%ï¼å¢å¼·æ¨¡åçç©©å¥æ§åç©©å®æ§ï¼ç¹å¥æ¯å¨ä¸å¹³è¡¡çææ³ä¸ãé¨æ©åæ¨£å±ç¾åºåªç°çç©©å®æ§ï¼èè²ªå©ª K åæ¨£åä»¥è¼é«ç FID åæ¸çºä»£å¹ï¼æä¾äºå¤æ¨£æ§ãæ¬ç ç©¶å¼·èª¿ DDPM å¨æ´åå°è¦æ¨¡ãä¸å¹³è¡¡é«çå½±åè³æéæ¹é¢çæè½ï¼ééå¹³è¡¡è³æéåæ´åå¶è¦æ¨¡ï¼æ¹åæ¨¡åæè½ã</paragraph>

##### **RareAgents: Autonomous Multi-disciplinary Team for Rare Disease Diagnosis and Treatment**
2412.12475v1 by Xuanzhong Chen, Ye Jin, Xiaohao Mao, Lun Wang, Shuyang Zhang, Ting Chen

Rare diseases, despite their low individual incidence, collectively impact
around 300 million people worldwide due to the huge number of diseases. The
complexity of symptoms and the shortage of specialized doctors with relevant
experience make diagnosing and treating rare diseases more challenging than
common diseases. Recently, agents powered by large language models (LLMs) have
demonstrated notable improvements across various domains. In the medical field,
some agent methods have outperformed direct prompts in question-answering tasks
from medical exams. However, current agent frameworks lack adaptation for
real-world clinical scenarios, especially those involving the intricate demands
of rare diseases. To address these challenges, we present RareAgents, the first
multi-disciplinary team of LLM-based agents tailored to the complex clinical
context of rare diseases. RareAgents integrates advanced planning capabilities,
memory mechanisms, and medical tools utilization, leveraging Llama-3.1-8B/70B
as the base model. Experimental results show that RareAgents surpasses
state-of-the-art domain-specific models, GPT-4o, and existing agent frameworks
in both differential diagnosis and medication recommendation for rare diseases.
Furthermore, we contribute a novel dataset, MIMIC-IV-Ext-Rare, derived from
MIMIC-IV, to support further advancements in this field.

æè¦ï¼åç®¡ç½è¦ç¾ççåå¥ç¼ççå¾ä½ï¼ä½ç±æ¼ç¾çæ¸éé¾å¤§ï¼å¨å¨çå½±é¿äºç´ 3 åäººãçççè¤éæ§åç¸éç¶é©çå°ç§é«çç­ç¼ºï¼ä½¿å¾è¨ºæ·åæ²»çç½è¦ç¾çæ¯å¸¸è¦ç¾çæ´å·ææ°æ§ãæè¿ï¼ç±å¤§åèªè¨æ¨¡å (LLM) é©åçä»£çå·²å¨ååé åå±ç¤ºåºé¡¯èçæ¹é²ãå¨é«å­¸é åï¼ä¸äºä»£çæ¹æ³å¨é«å­¸èè©¦çåç­ä»»åä¸­åªæ¼ç´æ¥æç¤ºãç¶èï¼ç¶åçä»£çæ¶æ§ç¼ºä¹é©æç¾å¯¦ä¸ççè¨åºå ´æ¯ï¼ç¹å¥æ¯é£äºæ¶åç½è¦ç¾çè¤ééæ±çå ´æ¯ãçºäºæå°éäºææ°ï¼æåæåºäº RareAgentsï¼éæ¯ç¬¬ä¸åéå°ç½è¦ç¾çè¤éè¨åºèæ¯éèº«æé ç LLM çºåºç¤çå¤å­¸ç§ä»£çåéãRareAgents æ´åäºåé²çè¦åè½åãè¨æ¶æ©å¶åé«çå·¥å·å©ç¨ï¼å©ç¨ Llama-3.1-8B/70B ä½çºåºç¤æ¨¡åãå¯¦é©çµæè¡¨æï¼RareAgents å¨ç½è¦ç¾ççéå¥è¨ºæ·åè¥ç©æ¨è¦æ¹é¢é½è¶è¶äºæåé²çç¹å®é åæ¨¡å GPT-4o åç¾æçä»£çæ¶æ§ãæ­¤å¤ï¼æåè²¢ç»äºä¸åæ°çæ¸æé MIMIC-IV-Ext-Rareï¼å®ä¾èª MIMIC-IVï¼ä»¥æ¯æè©²é åçé²ä¸æ­¥ç¼å±ã

##### **Bridging the Gap: Enhancing LLM Performance for Low-Resource African Languages with New Benchmarks, Fine-Tuning, and Cultural Adjustments**
2412.12417v1 by Tuka Alhanai, Adam Kasumovic, Mohammad Ghassemi, Aven Zitzelberger, Jessica Lundin, Guillaume Chabot-Couture

Large Language Models (LLMs) have shown remarkable performance across various
tasks, yet significant disparities remain for non-English languages, and
especially native African languages. This paper addresses these disparities by
creating approximately 1 million human-translated words of new benchmark data
in 8 low-resource African languages, covering a population of over 160 million
speakers of: Amharic, Bambara, Igbo, Sepedi (Northern Sotho), Shona, Sesotho
(Southern Sotho), Setswana, and Tsonga. Our benchmarks are translations of
Winogrande and three sections of MMLU: college medicine, clinical knowledge,
and virology. Using the translated benchmarks, we report previously unknown
performance gaps between state-of-the-art (SOTA) LLMs in English and African
languages. Finally, using results from over 400 fine-tuned models, we explore
several methods to reduce the LLM performance gap, including high-quality
dataset fine-tuning (using an LLM-as-an-Annotator), cross-lingual transfer, and
cultural appropriateness adjustments. Key findings include average mono-lingual
improvements of 5.6% with fine-tuning (with 5.4% average mono-lingual
improvements when using high-quality data over low-quality data), 2.9% average
gains from cross-lingual transfer, and a 3.0% out-of-the-box performance boost
on culturally appropriate questions. The publicly available benchmarks,
translations, and code from this study support further research and development
aimed at creating more inclusive and effective language technologies.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å¨åç¨®ä»»åä¸­å±ç¾åºåè¶çè¡¨ç¾ï¼ä½éè±èªèªè¨ï¼å°¤å¶æ¯åçéæ´²èªè¨ï¼ä»å­å¨é¡¯èçå·®ç°ãæ¬æééå¨ 8 ç¨®è³æºå±ä¹çéæ´²èªè¨ä¸­å»ºç«ç´ 100 è¬åäººé¡ç¿»è­¯çå®å­ä½çºæ°çåºæºè³æï¼ä¾è§£æ±ºéäºå·®ç°ï¼æ¶µèè¶é 1.6 åäººå£çä½¿ç¨èï¼é¿å§åæèªãç­å·´æèªãä¼åèªãåç´¢æèªãç´¹ç´èªãåç´¢æèªãè¨ç¦ç´èªåè°å èªãæåçåºæºæ¯å° Winogrande å MMLU çä¸åé¨åé²è¡ç¿»è­¯ï¼å¤§å­¸é«å­¸ãè¨åºç¥è­åçæ¯å­¸ãééç¿»è­¯çåºæºï¼æåå ±åäºååæªç¥çæè½å·®è·ï¼å¨è±èªåéæ´²èªè¨çææ° (SOTA) LLM ä¹éãæå¾ï¼ä½¿ç¨ä¾èª 400 å¤åå¾®èª¿æ¨¡åççµæï¼æåæ¢è¨äºå¹¾ç¨®æ¹æ³ä¾ç¸®å° LLM æè½å·®è·ï¼åæ¬é«åè³ªè³æéå¾®èª¿ï¼ä½¿ç¨ LLM ä½çºè¨»è§£èï¼ãè·¨èªè¨è½ç§»åæåé©å®æ§èª¿æ´ãä¸»è¦ç¼ç¾åæ¬å¾®èª¿å¾å¹³åå®èªæ¹å 5.6%ï¼ä½¿ç¨é«åè³ªè³ææ¯ä½åè³ªè³ææï¼å¹³åå®èªæ¹å 5.4%ï¼ãè·¨èªè¨è½ç§»å¹³åæå 2.9%ï¼ä»¥åå¨æåé©å®åé¡ä¸å³ææè½æå 3.0%ãæ¬ç ç©¶ä¸­å¬éæä¾çåºæºãç¿»è­¯åç¨å¼ç¢¼æ¯æ´é²ä¸æ­¥çç ç©¶åéç¼ï¼æ¨å¨å»ºç«æ´å·åå®¹æ§åæææ§çèªè¨æè¡ã

##### **The Impact of AI Assistance on Radiology Reporting: A Pilot Study Using Simulated AI Draft Reports**
2412.12042v1 by JuliÃ¡n N. Acosta, Siddhant Dogra, Subathra Adithan, Kay Wu, Michael Moritz, Stephen Kwak, Pranav Rajpurkar

Radiologists face increasing workload pressures amid growing imaging volumes,
creating risks of burnout and delayed reporting times. While artificial
intelligence (AI) based automated radiology report generation shows promise for
reporting workflow optimization, evidence of its real-world impact on clinical
accuracy and efficiency remains limited. This study evaluated the effect of
draft reports on radiology reporting workflows by conducting a three reader
multi-case study comparing standard versus AI-assisted reporting workflows. In
both workflows, radiologists reviewed the cases and modified either a standard
template (standard workflow) or an AI-generated draft report (AI-assisted
workflow) to create the final report. For controlled evaluation, we used GPT-4
to generate simulated AI drafts and deliberately introduced 1-3 errors in half
the cases to mimic real AI system performance. The AI-assisted workflow
significantly reduced average reporting time from 573 to 435 seconds (p=0.003),
without a statistically significant difference in clinically significant errors
between workflows. These findings suggest that AI-generated drafts can
meaningfully accelerate radiology reporting while maintaining diagnostic
accuracy, offering a practical solution to address mounting workload challenges
in clinical practice.

æè¦ï¼æ¾å°ç§é«å¸«å¨å½±åéä¸æ·å¢å çææ³ä¸ï¼é¢è¨å·¥ä½éå£åå¢å ï¼
é æå¦æ åå ±åæéå»¶èª¤çé¢¨éªãéç¶åºæ¼äººå·¥æºæ§ (AI) çèªååæ¾å°ç§å ±åçæé¡¯ç¤ºåºåªåå ±åå·¥ä½æµç¨çå¸æï¼ä½å¶å°è¨åºæºç¢ºæ§åæççå¯¦éå½±é¿è­æä»ç¶æéãæ¬ç ç©¶ééé²è¡ä¸åè®èå¤æ¡ä¾ç ç©¶ï¼æ¯è¼æ¨æºè AI è¼å©å ±åå·¥ä½æµç¨ï¼è©ä¼°èç¨¿å ±åå°æ¾å°ç§å ±åå·¥ä½æµç¨çå½±é¿ãå¨å©ç¨®å·¥ä½æµç¨ä¸­ï¼æ¾å°ç§é«å¸«æª¢é±çä¾ä¸¦ä¿®æ¹æ¨æºç¯æ¬ (æ¨æºå·¥ä½æµç¨) æ AI çæçèç¨¿å ±å (AI è¼å©å·¥ä½æµç¨) ä»¥å»ºç«æçµå ±åãçºäºé²è¡åæ§è©ä¼°ï¼æåä½¿ç¨ GPT-4 ç¢çæ¨¡æ¬ç AI èç¨¿ï¼ä¸¦ææå¨åæ¸çä¾ä¸­å¼å¥ 1-3 åé¯èª¤ï¼ä»¥æ¨¡æ¬çå¯¦ç AI ç³»çµ±æè½ãAI è¼å©å·¥ä½æµç¨å°å¹³åå ±åæéå¾ 573 ç§é¡¯èæ¸å°å° 435 ç§ (p=0.003)ï¼èå·¥ä½æµç¨ä¹éå¨è¨åºé¡¯èé¯èª¤æ¹é¢æ²æçµ±è¨ä¸çé¡¯èå·®ç°ãéäºç¼ç¾è¡¨æï¼AI çæçèç¨¿å¯ä»¥å¨ç¶­æè¨ºæ·æºç¢ºæ§çåæï¼ææç¾©å°å éæ¾å°ç§å ±åï¼çºè§£æ±ºè¨åºå¯¦åä¸­ä¸æ·å¢å çå·¥ä½éææ°æä¾å¯¦éçè§£æ±ºæ¹æ¡ã

##### **Combining Large Language Models with Tutoring System Intelligence: A Case Study in Caregiver Homework Support**
2412.11995v1 by Devika Venugopalan, Ziwen Yan, Conrad Borchers, Jionghao Lin, Vincent Aleven

Caregivers (i.e., parents and members of a child's caring community) are
underappreciated stakeholders in learning analytics. Although caregiver
involvement can enhance student academic outcomes, many obstacles hinder
involvement, most notably knowledge gaps with respect to modern school
curricula. An emerging topic of interest in learning analytics is hybrid
tutoring, which includes instructional and motivational support. Caregivers
assert similar roles in homework, yet it is unknown how learning analytics can
support them. Our past work with caregivers suggested that conversational
support is a promising method of providing caregivers with the guidance needed
to effectively support student learning. We developed a system that provides
instructional support to caregivers through conversational recommendations
generated by a Large Language Model (LLM). Addressing known instructional
limitations of LLMs, we use instructional intelligence from tutoring systems
while conducting prompt engineering experiments with the open-source Llama 3
LLM. This LLM generated message recommendations for caregivers supporting their
child's math practice via chat. Few-shot prompting and combining real-time
problem-solving context from tutoring systems with examples of tutoring
practices yielded desirable message recommendations. These recommendations were
evaluated with ten middle school caregivers, who valued recommendations
facilitating content-level support and student metacognition through
self-explanation. We contribute insights into how tutoring systems can best be
merged with LLMs to support hybrid tutoring settings through conversational
assistance, facilitating effective caregiver involvement in tutoring systems.

æè¦ï¼ç§é¡§èï¼å³ç¶æ¯ååç«¥ç§é¡§ç¤¾ç¾¤çæå¡ï¼æ¯å­¸ç¿åæä¸­æªç²ååéè¦çå©å®³éä¿äººãåç®¡ç§é¡§èçåèå¯ä»¥æåå­¸ççå­¸æ¥­æç¸¾ï¼ä½è¨±å¤éç¤é»ç¤äºåèï¼æé¡¯èçæ¯éæ¼ç¾ä»£å­¸æ ¡èª²ç¨çç¥è­å·®è·ãå­¸ç¿åæä¸­ä¸åæ°èçéæ³¨ä¸»é¡æ¯æ··åå¼è¼å°ï¼å¶ä¸­åæ¬æå­¸ååæ©æ¯æãç§é¡§èå¨å®¶åº­ä½æ¥­ä¸­æ®æ¼é¡ä¼¼çè§è²ï¼ä½ç®åå°ä¸æ¸æ¥å­¸ç¿åæå¦ä½è½æ¯æä»åãæåéå»èç§é¡§èçåä½è¡¨æï¼å°è©±å¼æ¯ææ¯æä¾ç§é¡§èæææ¯æå­¸çå­¸ç¿æéçæå°çä¸ç¨®æåéçæ¹æ³ãæåéç¼äºä¸åç³»çµ±ï¼ééå¤§åèªè¨æ¨¡å (LLM) ç¢ççå°è©±å¼å»ºè­°ï¼çºç§é¡§èæä¾æå­¸æ¯æ´ãçºäºè§£æ±º LLM å·²ç¥çæå­¸éå¶ï¼æåå¨å°éæº Llama 3 LLM é²è¡æç¤ºå·¥ç¨å¯¦é©æï¼ä½¿ç¨äºä¾èªè¼å°ç³»çµ±çæå­¸æºæ§ãæ­¤ LLM çºç§é¡§èééèå¤©æ¯æ´å¶å­å¥³çæ¸å­¸ç·´ç¿çæäºè¨æ¯å»ºè­°ãå°éæç¤ºä¸¦çµåä¾èªè¼å°ç³»çµ±çå³æåé¡è§£æ±ºèæ¯èè¼å°å¯¦åç¯ä¾ï¼ç¢çäºçæ³çè¨æ¯å»ºè­°ãéäºå»ºè­°ç¶éåä½åä¸­ç§é¡§èçè©ä¼°ï¼ä»åéè¦ä¿é²å§å®¹å±¤ç´æ¯æ´åå­¸çééèªæè§£éé²è¡åèªç¥çå»ºè­°ãæåæä¾è¦è§£ï¼èªªæè¼å°ç³»çµ±å¦ä½è½ééå°è©±å¼åå©è LLM æä½³æ´åï¼ä»¥æ¯æ´æ··åå¼è¼å°è¨­å®ï¼ä¿é²ç§é¡§èææåèè¼å°ç³»çµ±ã

##### **LLMs Can Simulate Standardized Patients via Agent Coevolution**
2412.11716v1 by Zhuoyun Du, Lujie Zheng, Renjun Hu, Yuyang Xu, Xiawei Li, Ying Sun, Wei Chen, Jian Wu, Haolei Cai, Haohao Ying

Training medical personnel using standardized patients (SPs) remains a
complex challenge, requiring extensive domain expertise and role-specific
practice. Most research on Large Language Model (LLM)-based simulated patients
focuses on improving data retrieval accuracy or adjusting prompts through human
feedback. However, this focus has overlooked the critical need for patient
agents to learn a standardized presentation pattern that transforms data into
human-like patient responses through unsupervised simulations. To address this
gap, we propose EvoPatient, a novel simulated patient framework in which a
patient agent and doctor agents simulate the diagnostic process through
multi-turn dialogues, simultaneously gathering experience to improve the
quality of both questions and answers, ultimately enabling human doctor
training. Extensive experiments on various cases demonstrate that, by providing
only overall SP requirements, our framework improves over existing reasoning
methods by more than 10% in requirement alignment and better human preference,
while achieving an optimal balance of resource consumption after evolving over
200 cases for 10 hours, with excellent generalizability. The code will be
available at https://github.com/ZJUMAI/EvoPatient.

æè¦ï¼ä½¿ç¨æ ååæ£è (SP) å¹è®­å»çäººåä»ç¶æ¯ä¸é¡¹å¤æçææï¼éè¦å¹¿æ³çé¢åä¸ä¸ç¥è¯åéå¯¹ç¹å®è§è²çå®è·µãå¤§å¤æ°å³äºåºäºå¤§è¯­è¨æ¨¡å (LLM) çæ¨¡ææ£èçç ç©¶é½éä¸­å¨æé«æ°æ®æ£ç´¢åç¡®æ§æéè¿äººå·¥åé¦è°æ´æç¤ºä¸ãç¶èï¼è¿ç§å³æ³¨å¿½è§äºæ£èä»£çå­¦ä¹ æ ååéè¿°æ¨¡å¼çå³é®éæ±ï¼è¯¥æ¨¡å¼éè¿æ çç£æ¨¡æå°æ°æ®è½¬æ¢ä¸ºç±»äººçæ£èååºãä¸ºäºè§£å³è¿ä¸å·®è·ï¼æä»¬æåºäº EvoPatientï¼è¿æ¯ä¸ä¸ªæ°é¢çæ¨¡ææ£èæ¡æ¶ï¼å¶ä¸­æ£èä»£çåå»çä»£çéè¿å¤è½®å¯¹è¯æ¨¡æè¯æ­è¿ç¨ï¼åæ¶æ¶éç»éªä»¥æé«é®é¢åç­æ¡çè´¨éï¼æç»å®ç°äººç±»å»çå¹è®­ãå¯¹åç§æ¡ä¾è¿è¡çå¹¿æ³å®éªè¡¨æï¼éè¿ä»æä¾æ´ä½ SP è¦æ±ï¼æä»¬çæ¡æ¶å¨éæ±å¯¹é½åæ´å¥½çäººç±»åå¥½æ¹é¢æ¯ç°æçæ¨çæ¹æ³æé«äº 10% ä»¥ä¸ï¼åæ¶å¨ç»è¿ 200 ä¸ªæ¡ä¾æ¼å 10 å°æ¶åå®ç°äºèµæºæ¶èçæä½³å¹³è¡¡ï¼å·æåºè²çå¯æ¦æ¬æ§ãä»£ç å¯å¨ https://github.com/ZJUMAI/EvoPatient è·å¾ã

##### **Fast-staged CNN Model for Accurate pulmonary diseases and Lung cancer detection**
2412.11681v1 by Abdelbaki Souid, Mohamed Hamroun, Soufiene Ben Othman, Hedi Sakli, Naceur Abdelkarim

Pulmonary pathologies are a significant global health concern, often leading
to fatal outcomes if not diagnosed and treated promptly. Chest radiography
serves as a primary diagnostic tool, but the availability of experienced
radiologists remains limited. Advances in Artificial Intelligence (AI) and
machine learning, particularly in computer vision, offer promising solutions to
address this challenge.
  This research evaluates a deep learning model designed to detect lung cancer,
specifically pulmonary nodules, along with eight other lung pathologies, using
chest radiographs. The study leverages diverse datasets comprising over 135,120
frontal chest radiographs to train a Convolutional Neural Network (CNN). A
two-stage classification system, utilizing ensemble methods and transfer
learning, is employed to first triage images into Normal or Abnormal categories
and then identify specific pathologies, including lung nodules.
  The deep learning model achieves notable results in nodule classification,
with a top-performing accuracy of 77%, a sensitivity of 0.713, a specificity of
0.776 during external validation, and an AUC score of 0.888. Despite these
successes, some misclassifications were observed, primarily false negatives.
  In conclusion, the model demonstrates robust potential for generalization
across diverse patient populations, attributed to the geographic diversity of
the training dataset. Future work could focus on integrating ETL data
distribution strategies and expanding the dataset with additional nodule-type
samples to further enhance diagnostic accuracy.

æè¦ï¼èºé¨çè®æ¯å¨çéè¦çå¥åº·åé¡ï¼è¥æªåæè¨ºæ·åæ²»çï¼å¸¸æå°è´è´å½å¾æãè¸é¨ X åæå½±å¯ç¨ä½ä¸»è¦çè¨ºæ·å·¥å·ï¼ä½ç¶é©è±å¯çæ¾å°ç§é«å¸«æ¸éæéãäººå·¥æºæ§ (AI) åæ©å¨å­¸ç¿çé²å±ï¼ç¹å¥æ¯å¨é»è¦è¦è¦ºæ¹é¢ï¼æä¾äºææè§£æ±ºæ­¤ææ°çæ¹æ¡ã
æ¬ç ç©¶è©ä¼°äºä¸åæ·±åº¦å­¸ç¿æ¨¡åï¼è©²æ¨¡åæ¨å¨ä½¿ç¨è¸é¨ X åçæª¢æ¸¬èºçï¼ç¹å¥æ¯èºçµç¯ï¼ä»¥åå¶ä»å«ç¨®èºé¨çè®ãæ­¤ç ç©¶å©ç¨åå«è¶é 135,120 å¼µæ­£é¢è¸é¨ X åççä¸åè³æéä¾è¨ç·´å·ç©ç¥ç¶ç¶²è·¯ (CNN)ãæ¡ç¨å©éæ®µåé¡ç³»çµ±ï¼å©ç¨æ´é«æ¹æ³åé·ç§»å­¸ç¿ï¼é¦åå°å½±ååé¡çºæ­£å¸¸æç°å¸¸é¡å¥ï¼ç¶å¾è­å¥ç¹å®çè®ï¼åæ¬èºçµç¯ã
æ·±åº¦å­¸ç¿æ¨¡åå¨çµç¯åé¡æ¹é¢åå¾é¡¯èææï¼å¨å¤é¨é©è­æéï¼å¶æºç¢ºçæé«éå° 77%ï¼éæåº¦çº 0.713ï¼ç¹ç°åº¦çº 0.776ï¼AUC åæ¸çº 0.888ãåç®¡æéäºæåï¼ä½ä»è§å¯å°ä¸äºé¯èª¤åé¡ï¼ä¸»è¦æ¯åé°æ§ã
ç¸½ä¹ï¼è©²æ¨¡åå±ç¤ºäºå¨ä¸åæ£èæç¾¤ä¸­æ¦æ¬çå¼·å¤§æ½åï¼éæ­¸åæ¼è¨ç·´è³æéçå°çå¤æ¨£æ§ãæªä¾çç ç©¶å¯ä»¥å°æ³¨æ¼æ´å ETL è³æåä½ç­ç¥ï¼ä¸¦ä½¿ç¨é¡å¤ççµç¯é¡åæ¨£æ¬æ´åè³æéï¼ä»¥é²ä¸æ­¥æé«è¨ºæ·æºç¢ºæ§ã

##### **BioBridge: Unified Bio-Embedding with Bridging Modality in Code-Switched EMR**
2412.11671v1 by Jangyeong Jeon, Sangyeon Cho, Dongjoon Lee, Changhee Lee, Junyeong Kim

Pediatric Emergency Department (PED) overcrowding presents a significant
global challenge, prompting the need for efficient solutions. This paper
introduces the BioBridge framework, a novel approach that applies Natural
Language Processing (NLP) to Electronic Medical Records (EMRs) in written
free-text form to enhance decision-making in PED. In non-English speaking
countries, such as South Korea, EMR data is often written in a Code-Switching
(CS) format that mixes the native language with English, with most
code-switched English words having clinical significance. The BioBridge
framework consists of two core modules: "bridging modality in context" and
"unified bio-embedding." The "bridging modality in context" module improves the
contextual understanding of bilingual and code-switched EMRs. In the "unified
bio-embedding" module, the knowledge of the model trained in the medical domain
is injected into the encoder-based model to bridge the gap between the medical
and general domains. Experimental results demonstrate that the proposed
BioBridge significantly performance traditional machine learning and
pre-trained encoder-based models on several metrics, including F1 score, area
under the receiver operating characteristic curve (AUROC), area under the
precision-recall curve (AUPRC), and Brier score. Specifically, BioBridge-XLM
achieved enhancements of 0.85% in F1 score, 0.75% in AUROC, and 0.76% in AUPRC,
along with a notable 3.04% decrease in the Brier score, demonstrating marked
improvements in accuracy, reliability, and prediction calibration over the
baseline XLM model. The source code will be made publicly available.

æè¦ï¼<paragraph>å°åæ¥è¨ºé¨ï¼PEDï¼äººæ»¿çºæ£æ¯ä¸åéå¤§çå¨çæ§ææ°ï¼ä¿ä½¿æåéè¦æ¾åºææççè§£æ±ºæ¹æ¡ãæ¬æä»ç´¹ BioBridge æ¶æ§ï¼éæ¯ä¸ç¨®åµæ°çæ¹æ³ï¼å°èªç¶èªè¨èçï¼NLPï¼æç¨æ¼ä»¥èªç±æå­å½¢å¼æ°å¯«çé»å­çæ­·ï¼EMRï¼ï¼ä»¥å¢å¼·å¨ PED ä¸­çæ±ºç­å¶å®ãå¨éè±èªç³»åå®¶/å°åï¼ä¾å¦åéï¼ï¼EMR è³æéå¸¸ä»¥ä»£ç¢¼è½æï¼CSï¼æ ¼å¼æ°å¯«ï¼å°æ¯èªèè±èªæ··åï¼èå¤§å¤æ¸ä»£ç¢¼è½æçè±èªå®å­å·æè¨åºæç¾©ãBioBridge æ¶æ§åå«å©åæ ¸å¿æ¨¡çµï¼ãèªå¢ä¸­çæ©æ¥æ¹å¼ãåãçµ±ä¸çç©åµå¥ãããèªå¢ä¸­çæ©æ¥æ¹å¼ãæ¨¡çµæ¹åäºéèªåä»£ç¢¼è½æ EMR çèªå¢çè§£ãå¨ãçµ±ä¸çç©åµå¥ãæ¨¡çµä¸­ï¼å°å¨é«çé åè¨ç·´çæ¨¡åç¥è­æ³¨å¥å°åºæ¼ç·¨ç¢¼å¨çæ¨¡åä¸­ï¼ä»¥å½åé«çåä¸è¬é åä¹éçå·®è·ãå¯¦é©çµæè­æï¼ææåºç BioBridge å¨å¤é ææ¨ï¼åæ¬ F1 åæ¸ãåè©¦èæä½ç¹å¾µæ²ç·ä¸é¢ç©ï¼AUROCï¼ãç²¾ç¢ºåº¦å¬åçæ²ç·ä¸é¢ç©ï¼AUPRCï¼åå¸è³´ç¾åæ¸ï¼ä¸é¡¯èåªæ¼å³çµ±æ©å¨å­¸ç¿åé åè¨ç·´çåºæ¼ç·¨ç¢¼å¨çæ¨¡åãå·é«ä¾èªªï¼BioBridge-XLM å¨ F1 åæ¸ä¸æåäº 0.85%ï¼å¨ AUROC ä¸æåäº 0.75%ï¼å¨ AUPRC ä¸æåäº 0.76%ï¼åæå¸è³´ç¾åæ¸é¡¯èä¸éäº 3.04%ï¼è­æå¨æºç¢ºåº¦ãå¯é æ§åé æ¸¬æ ¡æºæ¹é¢ï¼èåºæº XLM æ¨¡åç¸æ¯é½æé¡¯èçæ¹åãåå§ç¢¼å°å¬éæä¾ã</paragraph>

##### **Leveraging Foundation Language Models (FLMs) for Automated Cohort Extraction from Large EHR Databases**
2412.11472v1 by Purity Mugambi, Alexandra Meliou, Madalina Fiterau

A crucial step in cohort studies is to extract the required cohort from one
or more study datasets. This step is time-consuming, especially when a
researcher is presented with a dataset that they have not previously worked
with. When the cohort has to be extracted from multiple datasets, cohort
extraction can be extremely laborious. In this study, we present an approach
for partially automating cohort extraction from multiple electronic health
record (EHR) databases. We formulate the guided multi-dataset cohort extraction
problem in which selection criteria are first converted into queries,
translating them from natural language text to language that maps to database
entities. Then, using FLMs, columns of interest identified from the queries are
automatically matched between the study databases. Finally, the generated
queries are run across all databases to extract the study cohort. We propose
and evaluate an algorithm for automating column matching on two large, popular
and publicly-accessible EHR databases -- MIMIC-III and eICU. Our approach
achieves a high top-three accuracy of $92\%$, correctly matching $12$ out of
the $13$ columns of interest, when using a small, pre-trained general purpose
language model. Furthermore, this accuracy is maintained even as the search
space (i.e., size of the database) increases.

æè¦ï¼å¨éåç ç©¶ä¸­ï¼ä»ä¸ä¸ªæå¤ä¸ªç ç©¶æ°æ®éæåæéçéåæ¯è³å³éè¦çä¸æ­¥ãæ­¤æ­¥éª¤éå¸¸èæ¶ï¼ç¹å«æ¯å½ç ç©¶äººåä½¿ç¨ä¹åæªå¤çè¿çæ°æ®éæ¶ãå½å¿é¡»ä»å¤ä¸ªæ°æ®éæåéåæ¶ï¼éåæåå¯è½ä¼éå¸¸è´¹åãå¨æ¬ç ç©¶ä¸­ï¼æä»¬æåºäºä¸ç§ä»å¤ä¸ªçµå­å¥åº·è®°å½ (EHR) æ°æ®åºä¸­é¨åèªå¨åéåæåçæ¹æ³ãæä»¬å¶å®äºå¼å¯¼å¼å¤æ°æ®ééåæåé®é¢ï¼å¶ä¸­éæ©æ åé¦åè½¬æ¢ä¸ºæ¥è¯¢ï¼å°å®ä»¬ä»èªç¶è¯­è¨ææ¬è½¬æ¢ä¸ºæ å°å°æ°æ®åºå®ä½çè¯­è¨ãç¶åï¼ä½¿ç¨ FLMï¼ä»æ¥è¯¢ä¸­è¯å«åºçç®æ åå¨ç ç©¶æ°æ®åºä¹é´èªå¨å¹éãæåï¼å¨æææ°æ®åºä¸­è¿è¡çæçæ¥è¯¢ä»¥æåç ç©¶éåãæä»¬æåºå¹¶è¯ä¼°äºä¸ç§ç®æ³ï¼ç¨äºå¨ä¸¤ä¸ªå¤§åãæµè¡ä¸å¯å¬å¼è®¿é®ç EHR æ°æ®åºï¼MIMIC-III å eICUï¼ä¸èªå¨æ§è¡åå¹éãæä»¬çæ¹æ³å®ç°äº 92% çé«åä¸åç¡®åº¦ï¼å¨ä½¿ç¨å°åãé¢åè®­ç»çéç¨è¯­è¨æ¨¡åæ¶ï¼æ­£ç¡®å¹éäº 13 ä¸ªç®æ åä¸­ç 12 ä¸ªãæ­¤å¤ï¼å³ä½¿æç´¢ç©ºé´ï¼å³æ°æ®åºå¤§å°ï¼å¢å ï¼ä¹è½ä¿æè¿ç§åç¡®æ§ã

##### **FedCAR: Cross-client Adaptive Re-weighting for Generative Models in Federated Learning**
2412.11463v1 by Minjun Kim, Minjee Kim, Jinhoon Jeong

Generative models trained on multi-institutional datasets can provide an
enriched understanding through diverse data distributions. However, training
the models on medical images is often challenging due to hospitals' reluctance
to share data for privacy reasons. Federated learning(FL) has emerged as a
privacy-preserving solution for training distributed datasets across data
centers by aggregating model weights from multiple clients instead of sharing
raw data. Previous research has explored the adaptation of FL to generative
models, yet effective aggregation algorithms specifically tailored for
generative models remain unexplored. We hereby propose a novel algorithm aimed
at improving the performance of generative models within FL. Our approach
adaptively re-weights the contribution of each client, resulting in
well-trained shared parameters. In each round, the server side measures the
distribution distance between fake images generated by clients instead of
directly comparing the Fr\'echet Inception Distance per client, thereby
enhancing efficiency of the learning. Experimental results on three public
chest X-ray datasets show superior performance in medical image generation,
outperforming both centralized learning and conventional FL algorithms. Our
code is available at https://github.com/danny0628/FedCAR.

æè¦ï¼å¨å¤æ©æ§è³æéä¸è¨ç·´ççææ¨¡åè½ééå¤æ¨£åçè³æåä½æä¾è±å¯ççè§£ãç¶èï¼ç±æ¼é«é¢åºæ¼é±ç§åå ä¸é¡æåäº«è³æï¼å æ­¤å¨é«å­¸å½±åä¸è¨ç·´æ¨¡åéå¸¸å·æææ°æ§ãè¯åå­¸ç¿ (FL) å·²æçºä¸ç¨®é±ç§ä¿è­·è§£æ±ºæ¹æ¡ï¼ééå½ç¸½å¤åç¨æ¶ç«¯çæ¨¡åæ¬éï¼èéåäº«åå§è³æï¼å°±è½å¨è³æä¸­å¿éè¨ç·´åæ£å¼è³æéãååçç ç©¶å·²æ¢è¨å° FL æ¹ç·¨å°çææ¨¡åï¼ä½å°éçºçææ¨¡åéèº«æé çææå½ç¸½æ¼ç®æ³ä»æªè¢«æ¢è¨ãæåå¨æ­¤æåºä¸åæ°æ¼ç®æ³ï¼æ¨å¨æ¹å FL å§çææ¨¡åçæè½ãæåçåæ³æ¯èªé©æå°éæ°å æ¬æ¯åç¨æ¶ç«¯çè²¢ç»ï¼é²èç¢çè¨ç·´è¯å¥½çå±ç¨åæ¸ãå¨æ¯ä¸ååä¸­ï¼ä¼ºæå¨ç«¯æ¸¬éç¨æ¶ç«¯ç¢ççåå½±åä¹éçåéè·é¢ï¼èéç´æ¥æ¯è¼æ¯åç¨æ¶ç«¯ç Fr\'echet Inception Distanceï¼å¾èæåå­¸ç¿æçãå¨ä¸åå¬éè¸é¨ X åè³æéä¸çå¯¦é©çµæé¡¯ç¤ºï¼å¨é«å­¸å½±åçææ¹é¢æåªç°çæè½ï¼åªæ¼éä¸­å¼å­¸ç¿åå³çµ±ç FL æ¼ç®æ³ãæåçç¨å¼ç¢¼å¯ä»¥å¨ https://github.com/danny0628/FedCAR åå¾ã

##### **ACE-$M^3$: Automatic Capability Evaluator for Multimodal Medical Models**
2412.11453v1 by Xiechi Zhang, Shunfan Zheng, Linlin Wang, Gerard de Melo, Zhu Cao, Xiaoling Wang, Liang He

As multimodal large language models (MLLMs) gain prominence in the medical
field, the need for precise evaluation methods to assess their effectiveness
has become critical. While benchmarks provide a reliable means to evaluate the
capabilities of MLLMs, traditional metrics like ROUGE and BLEU employed for
open domain evaluation only focus on token overlap and may not align with human
judgment. Although human evaluation is more reliable, it is labor-intensive,
costly, and not scalable. LLM-based evaluation methods have proven promising,
but to date, there is still an urgent need for open-source multimodal LLM-based
evaluators in the medical field. To address this issue, we introduce ACE-$M^3$,
an open-sourced \textbf{A}utomatic \textbf{C}apability \textbf{E}valuator for
\textbf{M}ultimodal \textbf{M}edical \textbf{M}odels specifically designed to
assess the question answering abilities of medical MLLMs. It first utilizes a
branch-merge architecture to provide both detailed analysis and a concise final
score based on standard medical evaluation criteria. Subsequently, a reward
token-based direct preference optimization (RTDPO) strategy is incorporated to
save training time without compromising performance of our model. Extensive
experiments have demonstrated the effectiveness of our ACE-$M^3$
model\footnote{\url{https://huggingface.co/collections/AIUSRTMP/ace-m3-67593297ff391b93e3e5d068}}
in evaluating the capabilities of medical MLLMs.

æè¦ï¼<paragraph>é¨èå¤æ¨¡æå¤§åèªè¨æ¨¡å (MLLM) å¨é«çé åçéè¦æ§æ¥çæåï¼è©ä¼°å¶æè½çç²¾æºè©éæ¹æ³çéæ±ä¹è®å¾è³ééè¦ãéç¶åºæºæ¸¬è©¦æä¾äºè©ä¼° MLLM è½åçå¯é æ¹æ³ï¼ä½ç¨æ¼éæ¾é åè©éçå³çµ±ææ¨ï¼ä¾å¦ ROUGE å BLEUï¼åèéæ¼æ¬æ¨éçï¼å¯è½èäººé¡å¤æ·ä¸ç¬¦ãåç®¡äººé¡è©éè¼çºå¯é ï¼ä½å®å»ååå¯éãææ¬é«æä¸ç¡æ³æ´åãåºæ¼ LLM çè©éæ¹æ³å·²è¢«è­å¯¦å·æåæ¯ï¼ä½è¿ä»çºæ­¢ï¼é«çé åä»è¿«åéè¦éæ¾åå§ç¢¼çå¤æ¨¡æåºæ¼ LLM çè©éå¨ãçºäºè§£æ±ºéååé¡ï¼æåå¼å¥äº ACE-$M^3$ï¼ä¸åéæ¾åå§ç¢¼ç**A**utomatic **C**apability **E**valuator for **M**ultimodal **M**edical **M**odelsï¼å°éè¨­è¨ç¨æ¼è©ä¼°é«ç MLLM çåç­è½åãå®é¦åå©ç¨åæ¯åä½µæ¶æ§æä¾è©³ç´°åæååºæ¼æ¨æºé«çè©éæ¨æºçç°¡æ½æçµè©åãé¨å¾ï¼ç´å¥äºåºæ¼çåµæ¬æ¨çç´æ¥åå¥½æä½³å (RTDPO) ç­ç¥ï¼ä»¥ç¯çè¨ç·´æéï¼åæä¸å½±é¿æåæ¨¡åçæè½ãå»£æ³çå¯¦é©è­æäºæåç ACE-$M^3$ æ¨¡å\footnote{\url{https://huggingface.co/collections/AIUSRTMP/ace-m3-67593297ff391b93e3e5d068}} å¨è©ä¼°é«ç MLLM è½åæ¹é¢çæè½ã</paragraph>

##### **Detecting Daily Living Gait Amid Huntington's Disease Chorea using a Foundation Deep Learning Model**
2412.11286v1 by Dafna Schwartz, Lori Quinn, Nora E. Fritz, Lisa M. Muratori, Jeffery M. Hausdorff, Ran Gilad Bachrach

Wearable sensors offer a non-invasive way to collect physical activity (PA)
data, with walking as a key component. Existing models often struggle to detect
gait bouts in individuals with neurodegenerative diseases (NDDs) involving
involuntary movements. We developed J-Net, a deep learning model inspired by
U-Net, which uses a pre-trained self-supervised foundation model fine-tuned
with Huntington`s disease (HD) in-lab data and paired with a segmentation head
for gait detection. J-Net processes wrist-worn accelerometer data to detect
gait during daily living. We evaluated J-Net on in-lab and daily-living data
from HD, Parkinson`s disease (PD), and controls. J-Net achieved a 10-percentage
point improvement in ROC-AUC for HD over existing methods, reaching 0.97 for
in-lab data. In daily-living environments, J-Net estimates showed no
significant differences in median daily walking time between HD and controls (p
= 0.23), in contrast to other models, which indicated counterintuitive results
(p < 0.005). Walking time measured by J-Net correlated with the UHDRS-TMS
clinical severity score (r=-0.52; p=0.02), confirming its clinical relevance.
Fine-tuning J-Net on PD data also improved gait detection over current methods.
J-Net`s architecture effectively addresses the challenges of gait detection in
severe chorea and offers robust performance in daily living. The dataset and
J-Net model are publicly available, providing a resource for further research
into NDD-related gait impairments.

æè¦ï¼<paragraph>ç©¿æ´å¼ææ¸¬å¨æä¾æ¶éèº«é«æ´»å (PA) è³æçéä¾µå¥å¼æ¹æ³ï¼å¶ä¸­æ­¥è¡çºééµçµæé¨åãç¾ææ¨¡åéå¸¸é£ä»¥åµæ¸¬æ£æç¥ç¶éåæ§ç¾ç (NDD) ä¸¦ä¼´é¨éèªä¸»éåçåé«çæ­¥æç¼ä½ãæåéç¼äº J-Netï¼ä¸ç¨®å U-Net åç¼çæ·±åº¦å­¸ç¿æ¨¡åï¼å®ä½¿ç¨ç¶éé åè¨ç·´çèªç£ç£åºç¤æ¨¡åï¼ä¸¦ä½¿ç¨äº¨ä¸é èè¹ç (HD) å¯¦é©å®¤è³æé²è¡å¾®èª¿ï¼ä¸¦èç¨æ¼æ­¥æåµæ¸¬çåæ®µé ­é¨éå°ãJ-Net èçæèéæ´çå éåº¦è¨è³æï¼ä»¥åµæ¸¬æ¥å¸¸çæ´»ä¸­çæ­¥æãæåå¨ HDãå¸éæ£®æ°ç (PD) åå°ç§çµçå¯¦é©å®¤åæ¥å¸¸çæ´»è³æä¸è©ä¼° J-NetãJ-Net å¨ HD ç ROC-AUC ä¸æ¯ç¾ææ¹æ³æé«äº 10 åç¾åé»ï¼å°æ¼å¯¦é©å®¤è³æéå° 0.97ãå¨æ¥å¸¸çæ´»ç°å¢ä¸­ï¼J-Net ä¼°è¨å¼é¡¯ç¤º HD åå°ç§çµä¹éçæ¯æ¥å¹³åæ­¥è¡æéæ²æé¡¯èå·®ç° (p = 0.23)ï¼éèå¶ä»æ¨¡åå½¢æå°æ¯ï¼å¾èé¡¯ç¤ºåºéèç´è¦ºççµæ (p < 0.005)ãJ-Net æ¸¬éçæ­¥è¡æéè UHDRS-TMS è¨åºå´éç¨åº¦è©åç¸é (r=-0.52ï¼p=0.02)ï¼è­å¯¦å¶è¨åºç¸éæ§ãå¨ PD è³æä¸å¾®èª¿ J-Net ä¹æ¹åäºå°ç¾ææ¹æ³çæ­¥æåµæ¸¬ãJ-Net çæ¶æ§ææè§£æ±ºäºå´éèè¹çä¸­æ­¥æåµæ¸¬çææ°ï¼ä¸¦å¨æ¥å¸¸çæ´»ä¸­æä¾ç©©å¥çæè½ãè©²è³æéå J-Net æ¨¡åå¬éæä¾ï¼çºé²ä¸æ­¥ç ç©¶ NDD ç¸éæ­¥æéç¤æä¾è³æºã</paragraph>

##### **Wearable Accelerometer Foundation Models for Health via Knowledge Distillation**
2412.11276v1 by Salar Abbaspourazad, Anshuman Mishra, Joseph Futoma, Andrew C. Miller, Ian Shapiro

Modern wearable devices can conveniently and continuously record various
biosignals in the many different environments of daily living, ultimately
enabling a rich view of individual health. However, not all biosignals are the
same: high-fidelity measurements, such as photoplethysmography (PPG), contain
more physiological information, but require optical sensors with a high power
footprint. In a resource-constrained setting, such biosignals may be
unavailable. Alternatively, a lower-fidelity biosignal, such as accelerometry
that captures minute cardiovascular information during low-motion periods, has
a significantly smaller power footprint and is available in almost any wearable
device. Here, we demonstrate that we can distill representational knowledge
across biosignals, i.e., from PPG to accelerometry, using 20 million minutes of
unlabeled data, collected from ~172K participants in the Apple Heart and
Movement Study under informed consent. We first pre-train PPG encoders via
self-supervised learning, and then distill their representational knowledge to
accelerometry encoders. We demonstrate strong cross-modal alignment on unseen
data, e.g., 99.2% top-1 accuracy for retrieving PPG embeddings from
accelerometry embeddings. We show that distilled accelerometry encoders have
significantly more informative representations compared to self-supervised or
supervised encoders trained directly on accelerometry data, observed by at
least 23%-49% improved performance for predicting heart rate and heart rate
variability. We also show that distilled accelerometry encoders are readily
predictive of a wide array of downstream health targets, i.e., they are
generalist foundation models. We believe accelerometry foundation models for
health may unlock new opportunities for developing digital biomarkers from any
wearable device, and help individuals track their health more frequently and
conveniently.

æè¦ï¼<paragraph>ç¾ä»£çå¯ç©¿æ´è£ç½®å¯ä»¥å¨æ¥å¸¸çæ´»çè¨±å¤ä¸åç°å¢ä¸­æ¹ä¾¿ä¸æçºå°è¨éåç¨®çç©è¨èï¼æçµè½å¨é¢äºè§£åäººçå¥åº·çæ³ãç¶èï¼ä¸¦éææçç©è¨èé½ç¸åï¼é«ä¿çæ¸¬éå¼ï¼ä¾å¦åé»å®¹ç©æè¨æ³ (PPG)ï¼åå«æ´å¤ççè³è¨ï¼ä½éè¦å·æé«åçä½ç¨çåå­¸ææ¸¬å¨ãå¨è³æºåéçç°å¢ä¸­ï¼éäºçç©è¨èå¯è½ç¡æ³åå¾ãæèï¼ä½ä¿ççç©è¨èï¼ä¾å¦å éåº¦è¨ï¼å¯å¨ä½åä½æéæ·åç´°å¾®çå¿è¡ç®¡è³è¨ï¼å·ææé¡¯æ´å°çåçä½ç¨ï¼ä¸å¹¾ä¹å¯ä»¥å¨ä»»ä½å¯ç©¿æ´è£ç½®ä¸­åå¾ãå¨éè£¡ï¼æåè­ææåå¯ä»¥è·¨çç©è¨èï¼å³å¾ PPG å°å éåº¦è¨ï¼èååºè¡¨å¾µç¥è­ï¼ä½¿ç¨å¾ Apple å¿èåéåç ç©¶ä¸­ç´ 172K ååèèæ¶éç 2000 è¬åéæªæ¨è¨è³æï¼å¨ç¥æåæä¸é²è¡ãæååééèªæç£ç£å¼å­¸ç¿é åè¨ç·´ PPG ç·¨ç¢¼å¨ï¼ç¶å¾å°å¶è¡¨å¾µç¥è­èåå°å éåº¦è¨ç·¨ç¢¼å¨ãæåå¨æªè¦éçè³æä¸å±ç¤ºäºå¼·å¤§çè·¨æ¨¡æå°é½ï¼ä¾å¦å¾å éåº¦è¨åµå¥ä¸­æ·å PPG åµå¥ç 99.2% æé« 1 ç²¾ç¢ºåº¦ãæåè¡¨æï¼èç´æ¥å¨å éåº¦è¨è³æä¸è¨ç·´çèªæç£ç£å¼æç£ç£å¼ç·¨ç¢¼å¨ç¸æ¯ï¼èåçå éåº¦è¨ç·¨ç¢¼å¨å·ææ´å¤è³è¨è±å¯çè¡¨å¾µï¼å¾é æ¸¬å¿çåå¿çè®ç°æ§çè¡¨ç¾æ¹åè³å° 23%-49% å¯è¦ãæåéè¡¨æï¼èåçå éåº¦è¨ç·¨ç¢¼å¨å¾å®¹æé æ¸¬å»£æ³çä¸æ¸¸å¥åº·ç®æ¨ï¼å³å®åæ¯ä¸è¬åçåºç¤æ¨¡åãæåç¸ä¿¡ï¼ç¨æ¼å¥åº·çå éåº¦è¨åºç¤æ¨¡åå¯è½æéåå¾ä»»ä½å¯ç©¿æ´è£ç½®éç¼æ¸ä½çç©æ¨è¨çæ°æ©æï¼ä¸¦å¹«å©åäººæ´é »ç¹ä¸æ´æ¹ä¾¿å°è¿½è¹¤ä»åçå¥åº·çæ³ã</paragraph>

##### **TrimLLM: Progressive Layer Dropping for Domain-Specific LLMs**
2412.11242v2 by Lanxiang Hu, Tajana Rosing, Hao Zhang

Specializing large language models (LLMs) for local deployment in
domain-specific use cases is necessary for strong performance while meeting
latency and privacy constraints. However, conventional task-specific adaptation
approaches do not show simultaneous memory saving and inference speedup at
deployment time. Practical compression techniques like quantization and pruning
require dedicated hardware or kernel support to achieve measured inference
speedup. We develop TrimLLM based on the layer-wise specialization phenomenon
we empirically observed and verified on contemporary LLMs. TrimLLM reduces the
depth of LLMs via progressive layer dropping. We show it retains LLMs' capacity
in specific domains and achieves inference speedup irrespective of hardware and
deep learning frameworks. We evaluated TrimLLM on LLMs of various sizes for
inference; models adapted on medical, legal, and financial datasets all
demonstrate $2.1-5.7\times$ inference speedup on consumer GPUs and up to
$3.1\times$ speedup on A100 when compared to state-of-the-art model compression
algorithms, with no loss in accuracy at 50$\sim$60\% model compression ratio.

æè¦ï¼éå°ç¹å®é åçä½¿ç¨æ¡ä¾ï¼å°å¤§åèªè¨æ¨¡å (LLM) å°éåçºæ¬å°é¨ç½²å°æ¼å¨æ»¿è¶³å»¶é²åé±ç§éå¶çåæï¼å¯¦ç¾å¼·å¤§çæè½ååå¿è¦ãç¶èï¼å³çµ±çç¹å®ä»»åé©ææ¹æ³ä¸¦æªå¨é¨ç½²æåæå±ç¾è¨æ¶é«ç¯çåæ¨è«å éãéåååªæç­å¯¦ç¨çå£ç¸®æè¡éè¦å°ç¨çç¡¬é«ææ ¸å¿æ¯æ´ï¼æè½å¯¦ç¾å·²æ¸¬éçæ¨è«å éãæåæ ¹æå¨ç¶ä»£ LLM ä¸ç¶é©è§å¯ä¸¦é©è­çåå±¤å°éåç¾è±¡ï¼éç¼äº TrimLLMãTrimLLM ééæ¼¸é²å¼å±¤ç´æ¨æ£ä¾æ¸å° LLM çæ·±åº¦ãæåå±ç¤ºå®ä¿çäº LLM å¨ç¹å®é åä¸­çå®¹éï¼ä¸¦å¨ä¸èæ®ç¡¬é«åæ·±åº¦å­¸ç¿æ¶æ§çææ³ä¸å¯¦ç¾äºæ¨è«å éãæåéå°ä¸åå¤§å°ç LLM è©ä¼°äº TrimLLM çæ¨è«ï¼å¨é«çãæ³å¾åè²¡åè³æéä¸é©æçæ¨¡åï¼èæåé²çæ¨¡åå£ç¸®æ¼ç®æ³ç¸æ¯ï¼å¨æ¶è²»ç´ GPU ä¸é½å±ç¾äº $2.1-5.7\times$ çæ¨è«å éï¼è A100 ä¸çå éåé«é $3.1\times$ï¼ä¸å¨ 50$\sim$60% çæ¨¡åå£ç¸®çä¸ï¼æºç¢ºåº¦æ²ææå¤±ã

##### **Efficient Quantization-Aware Training on Segment Anything Model in Medical Images and Its Deployment**
2412.11186v1 by Haisheng Lu, Yujie Fu, Fan Zhang, Le Zhang

Medical image segmentation is a critical component of clinical practice, and
the state-of-the-art MedSAM model has significantly advanced this field.
Nevertheless, critiques highlight that MedSAM demands substantial computational
resources during inference. To address this issue, the CVPR 2024 MedSAM on
Laptop Challenge was established to find an optimal balance between accuracy
and processing speed. In this paper, we introduce a quantization-aware training
pipeline designed to efficiently quantize the Segment Anything Model for
medical images and deploy it using the OpenVINO inference engine. This pipeline
optimizes both training time and disk storage. Our experimental results confirm
that this approach considerably enhances processing speed over the baseline,
while still achieving an acceptable accuracy level. The training script,
inference script, and quantized model are publicly accessible at
https://github.com/AVC2-UESTC/QMedSAM.

æè¦ï¼é«å­¸å½±ååå²æ¯è¨åºå¯¦åä¸­è³ééè¦ççµæé¨åï¼èæåé²ç MedSAM æ¨¡åå·²å¤§å¹æåæ­¤é åãåç®¡å¦æ­¤ï¼æ¹è©èå¼·èª¿ MedSAM å¨æ¨è«æééè¦å¤§éçè¨ç®è³æºãçºäºè§£æ±ºéååé¡ï¼CVPR 2024 MedSAM on Laptop ææ°è³½å èæç«ï¼ä»¥æå¨æºç¢ºåº¦èèçéåº¦ä¹éåå¾æä½³å¹³è¡¡ãå¨æ¬æä¸­ï¼æåä»ç´¹äºä¸ç¨®éåæç¥è¨ç·´ç®¡éï¼ç¨æ¼ææéå Segment Anything Model ä»¥èçé«å­¸å½±åï¼ä¸¦ä½¿ç¨ OpenVINO æ¨è«å¼æé²è¡é¨ç½²ãæ­¤ç®¡éåææä½³åäºè¨ç·´æéèç£ç¢å²å­ç©ºéãæåçå¯¦é©çµæè­å¯¦ï¼æ­¤æ¹æ³å¤§å¹æåäºèçéåº¦ï¼åæä»éå°å¯æ¥åçæºç¢ºåº¦ç­ç´ãè¨ç·´è³æ¬ãæ¨è«è³æ¬åéåæ¨¡åå·²å¬éæ¼ https://github.com/AVC2-UESTC/QMedSAMã

##### **AD-LLM: Benchmarking Large Language Models for Anomaly Detection**
2412.11142v1 by Tiankai Yang, Yi Nian, Shawn Li, Ruiyao Xu, Yuangang Li, Jiaqi Li, Zhuo Xiao, Xiyang Hu, Ryan Rossi, Kaize Ding, Xia Hu, Yue Zhao

Anomaly detection (AD) is an important machine learning task with many
real-world uses, including fraud detection, medical diagnosis, and industrial
monitoring. Within natural language processing (NLP), AD helps detect issues
like spam, misinformation, and unusual user activity. Although large language
models (LLMs) have had a strong impact on tasks such as text generation and
summarization, their potential in AD has not been studied enough. This paper
introduces AD-LLM, the first benchmark that evaluates how LLMs can help with
NLP anomaly detection. We examine three key tasks: (i) zero-shot detection,
using LLMs' pre-trained knowledge to perform AD without tasks-specific
training; (ii) data augmentation, generating synthetic data and category
descriptions to improve AD models; and (iii) model selection, using LLMs to
suggest unsupervised AD models. Through experiments with different datasets, we
find that LLMs can work well in zero-shot AD, that carefully designed
augmentation methods are useful, and that explaining model selection for
specific datasets remains challenging. Based on these results, we outline six
future research directions on LLMs for AD.

æè¦ï¼ç°å¸¸åµæ¸¬ (AD) æ¯ä¸é éè¦çæ©å¨å­¸ç¿ä»»åï¼å¨ç¾å¯¦ä¸çä¸­æè¨±å¤ç¨éï¼åæ¬è©æ¬ºåµæ¸¬ãé«çè¨ºæ·åå·¥æ¥­ç£æ§ãå¨èªç¶èªè¨èç (NLP) ä¸­ï¼AD æå©æ¼åµæ¸¬åå¾éµä»¶ãé¯èª¤è¨æ¯åç°å¸¸ä½¿ç¨èæ´»åç­åé¡ãåç®¡å¤§åèªè¨æ¨¡å (LLM) å°æå­çæåæè¦ç­ä»»åç¢çäºéå¤§å½±é¿ï¼ä½å®åå¨ AD ä¸­çæ½åå°æªå¾å°ååç ç©¶ãæ¬æä»ç´¹äº AD-LLMï¼éæ¯ç¬¬ä¸åè©ä¼° LLM å¦ä½åå© NLP ç°å¸¸åµæ¸¬çåºæºãæåæ¢è¨äºä¸åééµä»»åï¼(i) é¶æ¬¡å­¸ç¿åµæ¸¬ï¼ä½¿ç¨ LLM çé è¨ç·´ç¥è­å¨æ²æç¹å®ä»»åè¨ç·´çææ³ä¸å·è¡ ADï¼(ii) è³ææ´åï¼çæåæè³æåé¡å¥æè¿°ä»¥æ¹å AD æ¨¡åï¼ä»¥å (iii) æ¨¡åé¸æï¼ä½¿ç¨ LLM ä¾å»ºè­°ç¡ç£ç£ AD æ¨¡åãééä½¿ç¨ä¸åè³æéé²è¡çå¯¦é©ï¼æåç¼ç¾ LLM å¯ä»¥å¾å¥½å°ç¨æ¼é¶æ¬¡å­¸ç¿ ADï¼ç²¾å¿è¨­è¨çæ´åæ¹æ³å¾æç¨ï¼ä¸¦ä¸éå°ç¹å®è³æéè§£éæ¨¡åé¸æä»ç¶å·æææ°æ§ãæ ¹æéäºçµæï¼æåæ¦è¿°äºæé AD ç LLM æªä¾å­åç ç©¶æ¹åã

##### **Decoding Drug Discovery: Exploring A-to-Z In silico Methods for Beginners**
2412.11137v1 by Hezha O. Rasul, Dlzar D. Ghafour, Bakhtyar K. Aziz, Bryar A. Hassan, Tarik A. Rashid, Arif Kivrak

The drug development process is a critical challenge in the pharmaceutical
industry due to its time-consuming nature and the need to discover new drug
potentials to address various ailments. The initial step in drug development,
drug target identification, often consumes considerable time. While valid,
traditional methods such as in vivo and in vitro approaches are limited in
their ability to analyze vast amounts of data efficiently, leading to wasteful
outcomes. To expedite and streamline drug development, an increasing reliance
on computer-aided drug design (CADD) approaches has merged. These sophisticated
in silico methods offer a promising avenue for efficiently identifying viable
drug candidates, thus providing pharmaceutical firms with significant
opportunities to uncover new prospective drug targets. The main goal of this
work is to review in silico methods used in the drug development process with a
focus on identifying therapeutic targets linked to specific diseases at the
genetic or protein level. This article thoroughly discusses A-to-Z in silico
techniques, which are essential for identifying the targets of bioactive
compounds and their potential therapeutic effects. This review intends to
improve drug discovery processes by illuminating the state of these
cutting-edge approaches, thereby maximizing the effectiveness and duration of
clinical trials for novel drug target investigation.

æè¦ï¼è¥ç©éç¼éç¨æ¯è£½è¥ç¢æ¥­çä¸é ééµææ°ï¼å çºå®èæä¸éè¦æ¾åºæ°çè¥ç©æ½åä¾è§£æ±ºåç¨®ç¾çãè¥ç©éç¼çç¬¬ä¸æ­¥ï¼è¥ç©ç®æ¨è­å¥ï¼éå¸¸æè±è²»å¤§éæéãéç¶ææï¼ä½å³çµ±æ¹æ³ï¼ä¾å¦é«å§åé«å¤æ¹æ³ï¼å¨ææåæå¤§éè³æçè½åä¸åå°éå¶ï¼å°è´æµªè²»çµæãçºäºå å¿«åç°¡åè¥ç©éç¼ï¼è¶ä¾è¶ä¾è³´é»è¦è¼å©è¥ç©è¨­è¨ (CADD) æ¹æ³ãéäºåé²ç in silico æ¹æ³æä¾äºä¸åæåéçéå¾ï¼å¯ä»¥ææå°è­å¥å¯è¡çåé¸è¥ç©ï¼å¾èçºè£½è¥å¬å¸æä¾é¡¯èçæ©æä¾ç¼ç¾æ°çæ½å¨è¥ç©ç®æ¨ãéé å·¥ä½çç®æ¨æ¯åé¡§è¥ç©éç¼éç¨ä¸­ä½¿ç¨ç in silico æ¹æ³ï¼éé»æ¯æ¾åºèç¹å®ç¾çå¨åºå æèç½è³ªå±¤é¢ç¸éçæ²»çç®æ¨ãæ¬æå¾¹åºè¨è«äº A-to-Z in silico æè¡ï¼éäºæè¡å°æ¼è­å¥çç©æ´»æ§ååç©çç®æ¨åå¶æ½å¨æ²»çææè³ééè¦ãéç¯è©è«æ¨å¨ééé¡æéäºå°ç«¯æ¹æ³ççæä¾æ¹é²è¥ç©ç¼ç¾éç¨ï¼å¾èæå¤§åæ°è¥ç©ç®æ¨ç ç©¶çæææ§åæçºæéã

##### **MedG-KRP: Medical Graph Knowledge Representation Probing**
2412.10982v2 by Gabriel R. Rosenbaum, Lavender Yao Jiang, Ivaxi Sheth, Jaden Stryker, Anton Alyakin, Daniel Alexander Alber, Nicolas K. Goff, Young Joon Fred Kwon, John Markert, Mustafa Nasir-Moin, Jan Moritz Niehues, Karl L. Sangwon, Eunice Yang, Eric Karl Oermann

Large language models (LLMs) have recently emerged as powerful tools, finding
many medical applications. LLMs' ability to coalesce vast amounts of
information from many sources to generate a response-a process similar to that
of a human expert-has led many to see potential in deploying LLMs for clinical
use. However, medicine is a setting where accurate reasoning is paramount. Many
researchers are questioning the effectiveness of multiple choice question
answering (MCQA) benchmarks, frequently used to test LLMs. Researchers and
clinicians alike must have complete confidence in LLMs' abilities for them to
be deployed in a medical setting. To address this need for understanding, we
introduce a knowledge graph (KG)-based method to evaluate the biomedical
reasoning abilities of LLMs. Essentially, we map how LLMs link medical concepts
in order to better understand how they reason. We test GPT-4, Llama3-70b, and
PalmyraMed-70b, a specialized medical model. We enlist a panel of medical
students to review a total of 60 LLM-generated graphs and compare these graphs
to BIOS, a large biomedical KG. We observe GPT-4 to perform best in our human
review but worst in our ground truth comparison; vice-versa with PalmyraMed,
the medical model. Our work provides a means of visualizing the medical
reasoning pathways of LLMs so they can be implemented in clinical settings
safely and effectively.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) è¿æå·²æçºå¼·å¤§çå·¥å·ï¼å¨é«çé åä¸­ç¼ç¾è¨±å¤æç¨ãLLM å¾è¨±å¤ä¾æºå¯éå¤§éè³è¨ä»¥ç¢çåæçè½åï¼æ­¤éç¨é¡ä¼¼æ¼äººé¡å°å®¶çéç¨ï¼ï¼å·²è®è¨±å¤äººçå°å° LLM é¨ç½²æ¼è¨åºç¨éçæ½åãç¶èï¼é«å­¸æ¯ä¸åæºç¢ºæ¨çè³ééè¦çé åãè¨±å¤ç ç©¶äººå¡è³ªçå¤é¸é¡åç­ (MCQA) åºæºçæææ§ï¼èéç¶å¸¸è¢«ç¨æ¼æ¸¬è©¦ LLMãç ç©¶äººå¡åè¨åºé«çé½å¿é å° LLM çè½åæå®å¨çä¿¡å¿ï¼æè½å°å¶é¨ç½²æ¼é«çç°å¢ä¸­ãçºäºæ»¿è¶³éç¨®çè§£éæ±ï¼æåå¼å¥ä¸ååºæ¼ç¥è­åè­ (KG) çæ¹æ³ä¾è©ä¼° LLM ççç©é«å­¸æ¨çè½åãåºæ¬ä¸ï¼æåç¹ªè£½ LLM å¦ä½é£çµé«çæ¦å¿µï¼ä»¥æ´å¥½å°çè§£å®åçæ¨çæ¹å¼ãæåæ¸¬è©¦äº GPT-4ãLlama3-70b å PalmyraMed-70bï¼éæ¯ä¸åå°éçé«çæ¨¡åãæåå¾µéäºä¸çµé«å­¸çä¾æª¢é±ç¸½å± 60 å LLM çæçåè¡¨ï¼ä¸¦å°éäºåè¡¨è BIOSï¼ä¸åå¤§åçç©é«å­¸ KGï¼é²è¡æ¯è¼ãæåè§å¯å° GPT-4 å¨æåçäººå·¥å¯©æ¥ä¸­è¡¨ç¾æä½³ï¼ä½å¨æåçåºæ¬äºå¯¦æ¯è¼ä¸­è¡¨ç¾æå·®ï¼èå°éçé«çæ¨¡å PalmyraMed åç¸åãæåçç ç©¶æä¾äºä¸ç¨®å¯è¦å LLM é«çæ¨çè·¯å¾çæ¹æ³ï¼ä»¥ä¾¿å®åè½å¤ å®å¨ææå°å¯¦ä½æ¼è¨åºç°å¢ä¸­ã

##### **LLMs-in-the-Loop Part 2: Expert Small AI Models for Anonymization and De-identification of PHI Across Multiple Languages**
2412.10918v1 by Murat Gunay, Bunyamin Keles, Raife Hizlan

The rise of chronic diseases and pandemics like COVID-19 has emphasized the
need for effective patient data processing while ensuring privacy through
anonymization and de-identification of protected health information (PHI).
Anonymized data facilitates research without compromising patient
confidentiality. This paper introduces expert small AI models developed using
the LLM-in-the-loop methodology to meet the demand for domain-specific
de-identification NER models. These models overcome the privacy risks
associated with large language models (LLMs) used via APIs by eliminating the
need to transmit or store sensitive data. More importantly, they consistently
outperform LLMs in de-identification tasks, offering superior performance and
reliability. Our de-identification NER models, developed in eight languages
(English, German, Italian, French, Romanian, Turkish, Spanish, and Arabic)
achieved f1-micro score averages of 0.966, 0.975, 0.976, 0.970, 0.964, 0.974,
0.978, and 0.953 respectively. These results establish them as the most
accurate healthcare anonymization solutions, surpassing existing small models
and even general-purpose LLMs such as GPT-4o. While Part-1 of this series
introduced the LLM-in-the-loop methodology for bio-medical document
translation, this second paper showcases its success in developing
cost-effective expert small NER models in de-identification tasks. Our findings
lay the groundwork for future healthcare AI innovations, including biomedical
entity and relation extraction, demonstrating the value of specialized models
for domain-specific challenges.

æè¦ï¼æ¢æ§ç¾çå COVID-19 ç­æµè¡ççèèµ·å¼·èª¿äºææèçæ£èè³æçå¿è¦æ§ï¼åæééå¿åååç§»é¤åä¿è­·å¥åº·è³è¨ (PHI) çè­å¥è³è¨ä¾ç¢ºä¿é±ç§ãå¿ååè³ææå©æ¼ç ç©¶ï¼èä¸ææå®³æ£èçæ©å¯æ§ãæ¬æä»ç´¹ä½¿ç¨ LLM-in-the-loop æ¹æ³éç¼çå°å®¶å°å AI æ¨¡åï¼ä»¥æ»¿è¶³ç¹å®é åå»è­å¥å NER æ¨¡åçéæ±ãéäºæ¨¡ååæäºéé API ä½¿ç¨å¤§åèªè¨æ¨¡å (LLM) æå¸¶ä¾çé±ç§é¢¨éªï¼æ¶é¤äºå³è¼¸æå²å­ææè³æçéè¦ãæ´éè¦çæ¯ï¼å®åå¨å»è­å¥åä»»åä¸­å§çµåªæ¼ LLMï¼æä¾åè¶çæè½åå¯é æ§ãæåä»¥å«ç¨®èªè¨ï¼è±èªãå¾·èªãç¾©å¤§å©èªãæ³èªãç¾é¦¬å°¼äºèªãåè³å¶èªãè¥¿ç­çèªåé¿æä¼¯èªï¼éç¼çå»è­å¥å NER æ¨¡ååå¥éå° f1-micro åæ¸å¹³åå¼ 0.966ã0.975ã0.976ã0.970ã0.964ã0.974ã0.978 å 0.953ãéäºçµæç¢ºç«äºå®åä½çºææºç¢ºçé«çä¿å¥å¿ååè§£æ±ºæ¹æ¡ï¼è¶è¶äºç¾æçå°æ¨¡åï¼çè³è¶è¶äº GPT-4o ç­éç¨ LLMãéç¶æ¬ç³»åçç¬¬ä¸é¨åä»ç´¹äºç¨æ¼çç©é«å­¸æä»¶ç¿»è­¯ç LLM-in-the-loop æ¹æ³ï¼ä½ç¬¬äºç¯è«æå±ç¤ºäºå¶å¨å»è­å¥åä»»åä¸­éç¼å·æææ¬æççå°å®¶å°å NER æ¨¡åçæåãæåçç ç©¶çµæçºæªä¾çé«çä¿å¥ AI åµæ°å¥ å®äºåºç¤ï¼åæ¬çç©é«å­¸å¯¦é«åéä¿èåï¼è­æäºå°éåæ¨¡åå¨ç¹å®é åææ°ä¸­çå¹å¼ã

##### **Superhuman performance of a large language model on the reasoning tasks of a physician**
2412.10849v1 by Peter G. Brodeur, Thomas A. Buckley, Zahir Kanjee, Ethan Goh, Evelyn Bin Ling, Priyank Jain, Stephanie Cabral, Raja-Elie Abdulnour, Adrian Haimovich, Jason A. Freed, Andrew Olson, Daniel J. Morgan, Jason Hom, Robert Gallo, Eric Horvitz, Jonathan Chen, Arjun K. Manrai, Adam Rodman

Performance of large language models (LLMs) on medical tasks has
traditionally been evaluated using multiple choice question benchmarks.
However, such benchmarks are highly constrained, saturated with repeated
impressive performance by LLMs, and have an unclear relationship to performance
in real clinical scenarios. Clinical reasoning, the process by which physicians
employ critical thinking to gather and synthesize clinical data to diagnose and
manage medical problems, remains an attractive benchmark for model performance.
Prior LLMs have shown promise in outperforming clinicians in routine and
complex diagnostic scenarios. We sought to evaluate OpenAI's o1-preview model,
a model developed to increase run-time via chain of thought processes prior to
generating a response. We characterize the performance of o1-preview with five
experiments including differential diagnosis generation, display of diagnostic
reasoning, triage differential diagnosis, probabilistic reasoning, and
management reasoning, adjudicated by physician experts with validated
psychometrics. Our primary outcome was comparison of the o1-preview output to
identical prior experiments that have historical human controls and benchmarks
of previous LLMs. Significant improvements were observed with differential
diagnosis generation and quality of diagnostic and management reasoning. No
improvements were observed with probabilistic reasoning or triage differential
diagnosis. This study highlights o1-preview's ability to perform strongly on
tasks that require complex critical thinking such as diagnosis and management
while its performance on probabilistic reasoning tasks was similar to past
models. New robust benchmarks and scalable evaluation of LLM capabilities
compared to human physicians are needed along with trials evaluating AI in real
clinical settings.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å¨é«çä»»åä¸­çè¡¨ç¾éå¸¸ä½¿ç¨å¤é¸é¡åºæºé²è¡è©ä¼°ãç¶èï¼æ­¤é¡åºæºåå°é«åº¦éå¶ï¼åæ¥è LLM éè¤ä¸ä»¤äººå°è±¡æ·±å»çè¡¨ç¾ï¼ä¸èå¯¦éè¨åºå ´æ¯ä¸­çè¡¨ç¾éä¿ä¸æç¢ºãè¨åºæ¨çï¼å³é«å¸«éç¨æ¹å¤æ§æèæ¶éåç¶åè¨åºè³æä»¥è¨ºæ·åç®¡çé«çåé¡çéç¨ï¼ä»ç¶æ¯æ¨¡åè¡¨ç¾çèªäººåºæºãååç LLM å·²å±ç¾åºå¨å¸¸è¦åè¤éè¨ºæ·å ´æ¯ä¸­åªæ¼è¨åºé«å¸«çæ½åãæåè©¦åè©ä¼° OpenAI ç o1-preview æ¨¡åï¼éæ¯ä¸åå¨ç¢çåæä¹åééæèéç¨éä¾å¢å å·è¡æéçæ¨¡åãæåééäºé å¯¦é©ä¾æè¿° o1-preview çè¡¨ç¾ï¼åæ¬éå¥è¨ºæ·ç¢çãè¨ºæ·æ¨çé¡¯ç¤ºãåæµéå¥è¨ºæ·ãæ©çæ¨çåç®¡çæ¨çï¼ä¸¦ç±ç¶éé©è­çå¿çæ¸¬éå­¸çé«å¸«å°å®¶é²è¡å¤å®ãæåçä¸»è¦çµææ¯å° o1-preview è¼¸åºèå·ææ­·å²äººé¡æ§å¶ååå LLM åºæºçç¸åååå¯¦é©é²è¡æ¯è¼ãå¨éå¥è¨ºæ·ç¢çåè¨ºæ·åç®¡çæ¨çåè³ªæ¹é¢è§å¯å°é¡¯èçé²æ­¥ãå¨æ©çæ¨çæåæµéå¥è¨ºæ·æ¹é¢æ²æè§å¯å°é²æ­¥ãéé ç ç©¶çªé¡¯äº o1-preview å¨å·è¡éè¦è¤éæ¹å¤æ§æèçä»»åï¼ä¾å¦è¨ºæ·åç®¡çï¼æ¹é¢çå¼·å¤§è½åï¼èå®å¨æ©çæ¨çä»»åä¸­çè¡¨ç¾åèéå»çæ¨¡åé¡ä¼¼ãéè¦æ°çç©©å¥åºæºå LLM è½åçå¯æ´åè©ä¼°ï¼èäººé¡é«å¸«é²è¡æ¯è¼ï¼ä»¥åè©ä¼° AI å¨å¯¦éè¨åºç°å¢ä¸­çè©¦é©ã

##### **Large Language Models for Medical Forecasting -- Foresight 2**
2412.10848v1 by Zeljko Kraljevic, Joshua Au Yeung, Daniel Bean, James Teo, Richard J. Dobson

Foresight 2 (FS2) is a large language model fine-tuned on hospital data for
modelling patient timelines (GitHub 'removed for anon'). It can understand
patients' clinical notes and predict SNOMED codes for a wide range of
biomedical use cases, including diagnosis suggestions, risk forecasting, and
procedure and medication recommendations. FS2 is trained on the free text
portion of the MIMIC-III dataset, firstly through extracting biomedical
concepts and then creating contextualised patient timelines, upon which the
model is then fine-tuned. The results show significant improvement over the
previous state-of-the-art for the next new biomedical concept prediction (P/R -
0.73/0.66 vs 0.52/0.32) and a similar improvement specifically for the next new
disorder prediction (P/R - 0.69/0.62 vs 0.46/0.25). Finally, on the task of
risk forecast, we compare our model to GPT-4-turbo (and a range of open-source
biomedical LLMs) and show that FS2 performs significantly better on such tasks
(P@5 - 0.90 vs 0.65). This highlights the need to incorporate hospital data
into LLMs and shows that small models outperform much larger ones when
fine-tuned on high-quality, specialised data.

æè¦ï¼Foresight 2 (FS2) æ¯ä¸åå¤§åèªè¨æ¨¡åï¼éå°é«é¢æ¸æé²è¡å¾®èª¿ï¼ç¨æ¼å»ºæ¨¡æ£èæéè»¸ï¼GitHubãå·²ç§»é¤å¿åãï¼ãå®å¯ä»¥äºè§£æ£èçè¨åºè¨éï¼ä¸¦é æ¸¬åç¨®çç©é«å­¸ç¨ä¾ç SNOMED ä»£ç¢¼ï¼åæ¬è¨ºæ·å»ºè­°ãé¢¨éªé æ¸¬ä»¥åç¨åºåè¥ç©å»ºè­°ãFS2 å¨ MIMIC-III æ¸æéçèªç±ææ¬é¨åä¸é²è¡è¨ç·´ï¼é¦åééæåçç©é«å­¸æ¦å¿µï¼ç¶å¾åµå»ºæå¢åçæ£èæéè»¸ï¼ç¶å¾å°æ¨¡åé²è¡å¾®èª¿ãçµæè¡¨æï¼èååæåé²çä¸ä¸æ°çç©é«å­¸æ¦å¿µé æ¸¬ï¼P/R - 0.73/0.66 å° 0.52/0.32ï¼ç¸æ¯ï¼æé¡¯èæ¹é²ï¼ä¸¦ä¸ç¹å¥æ¯å°æ¼ä¸ä¸æ°ç¾çé æ¸¬ï¼P/R - 0.69/0.62 å° 0.46/0.25ï¼ä¹æé¡ä¼¼çæ¹é²ãæå¾ï¼å¨é¢¨éªé æ¸¬ä»»åä¸ï¼æåå°æåçæ¨¡åè GPT-4-turboï¼åä¸ç³»åéæºçç©é«å­¸ LLMï¼é²è¡æ¯è¼ï¼ä¸¦è¡¨æ FS2 å¨æ­¤é¡ä»»åä¸è¡¨ç¾é¡¯èåªæ¼ï¼P@5 - 0.90 å° 0.65ï¼ãéçªé¡¯äºå°é«é¢æ¸æç´å¥ LLM çå¿è¦æ§ï¼ä¸¦è¡¨æå¨éå°é«åè³ªå°éæ¸æé²è¡å¾®èª¿æï¼å°åæ¨¡åçè¡¨ç¾åªæ¼å¤§åæ¨¡åã

##### **Generative AI: A Pix2pix-GAN-Based Machine Learning Approach for Robust and Efficient Lung Segmentation**
2412.10826v1 by Sharmin Akter

Chest radiography is climacteric in identifying different pulmonary diseases,
yet radiologist workload and inefficiency can lead to misdiagnoses. Automatic,
accurate, and efficient segmentation of lung from X-ray images of chest is
paramount for early disease detection. This study develops a deep learning
framework using a Pix2pix Generative Adversarial Network (GAN) to segment
pulmonary abnormalities from CXR images. This framework's image preprocessing
and augmentation techniques were properly incorporated with a U-Net-inspired
generator-discriminator architecture. Initially, it loaded the CXR images and
manual masks from the Montgomery and Shenzhen datasets, after which
preprocessing and resizing were performed. A U-Net generator is applied to the
processed CXR images that yield segmented masks; then, a Discriminator Network
differentiates between the generated and real masks. Montgomery dataset served
as the model's training set in the study, and the Shenzhen dataset was used to
test its robustness, which was used here for the first time. An adversarial
loss and an L1 distance were used to optimize the model in training. All
metrics, which assess precision, recall, F1 score, and Dice coefficient, prove
the effectiveness of this framework in pulmonary abnormality segmentation. It,
therefore, sets the basis for future studies to be performed shortly using
diverse datasets that could further confirm its clinical applicability in
medical imaging.

æè¦ï¼è¸é¨ X åæå½±å¨è¾¨è­ä¸åçèºé¨ç¾çä¸­å·ææ±ºå®æ§ï¼ç¶èæ¾å°ç§é«å¸«çå·¥ä½è² æåæçä¸å½°å¯è½æå°è´èª¤è¨ºãèªåãæºç¢ºä¸ææçå°å¾è¸é¨ X åå½±åä¸­åå²åºèºé¨ï¼å°æ¼æ©æç¾çåµæ¸¬è³ééè¦ãæ¬ç ç©¶éç¼ä¸åæ·±åº¦å­¸ç¿æ¶æ§ï¼ä½¿ç¨ Pix2pix çæå°æç¶²è·¯ (GAN) å¾ CXR å½±åä¸­åå²åºèºé¨ç°å¸¸ãæ­¤æ¶æ§çå½±ååèçåæ´åæè¡èä¸åå U-Net åç¼ççæå¨-å¤å¥å¨æ¶æ§é©ç¶å°æ´åãæåï¼å®è¼å¥ CXR å½±åå Montgomery åæ·±å³è³æéçæåé®ç½©ï¼ä¹å¾å·è¡åèçåèª¿æ´å¤§å°ãå° U-Net çæå¨æç¨æ¼å·²èçç CXR å½±åï¼ç¢çåå²é®ç½©ï¼ç¶å¾ï¼å¤å¥å¨ç¶²è·¯ååçæçé®ç½©åçå¯¦é®ç½©ãMontgomery è³æéä½çºæ¬ç ç©¶æ¨¡åçè¨ç·´éï¼èæ·±å³è³æéç¨æ¼æ¸¬è©¦å¶ç©©å¥æ§ï¼éæ¯é¦æ¬¡ä½¿ç¨æ¼æ­¤ãå°ææå¤±å L1 è·é¢ç¨æ¼å¨è¨ç·´ä¸­æä½³åæ¨¡åãææè©ä¼°ç²¾æºåº¦ãå¬åçãF1 åæ¸å Dice ä¿æ¸çææ¨é½è­ææ­¤æ¶æ§å¨èºé¨ç°å¸¸åå²ä¸­çæææ§ãå æ­¤ï¼å®çºä¸ä¹å¾ä½¿ç¨æ´å¤åè³æéé²è¡çæªä¾ç ç©¶å¥ å®åºç¤ï¼éäºç ç©¶é²ä¸æ­¥ç¢ºèªå¶å¨é«å­¸å½±åä¸­çè¨åºé©ç¨æ§ã

##### **Medical Manifestation-Aware De-Identification**
2412.10804v1 by Yuan Tian, Shuo Wang, Guangtao Zhai

Face de-identification (DeID) has been widely studied for common scenes, but
remains under-researched for medical scenes, mostly due to the lack of
large-scale patient face datasets. In this paper, we release MeMa, consisting
of over 40,000 photo-realistic patient faces. MeMa is re-generated from massive
real patient photos. By carefully modulating the generation and data-filtering
procedures, MeMa avoids breaching real patient privacy, while ensuring rich and
plausible medical manifestations. We recruit expert clinicians to annotate MeMa
with both coarse- and fine-grained labels, building the first medical-scene
DeID benchmark. Additionally, we propose a baseline approach for this new
medical-aware DeID task, by integrating data-driven medical semantic priors
into the DeID procedure. Despite its conciseness and simplicity, our approach
substantially outperforms previous ones. Dataset is available at
https://github.com/tianyuan168326/MeMa-Pytorch.

æè¦ï¼äººè¸å»è­å¥ (DeID) å·²è¢«å»£æ³ç ç©¶ç¨æ¼å¸¸è¦å ´æ¯ï¼ä½
å°æ¼é«çå ´æ¯çç ç©¶ä»ç¶ä¸è¶³ï¼ä¸»è¦æ¯ç±æ¼ç¼ºä¹
å¤§è¦æ¨¡çæ£èäººèæ¸æéãå¨æ¬æä¸­ï¼æåç¼å¸äº MeMaï¼å¶ä¸­
åå«è¶é 40,000 å¼µé¼ççæ£èäººèãMeMa æ¯å¾å¤§éç
çå¯¦æ£èç§çä¸­éæ°çæçãééä»ç´°èª¿ç¯çæåæ¸æéæ¿¾
ç¨åºï¼MeMa é¿åä¾µç¯çå¯¦æ£èçé±ç§ï¼åæç¢ºä¿è±å¯ä¸
åççé«çè¡¨ç¾ãæåæåå°å®¶è¨åºé«ççº MeMa æ·»å ç²ç¥åç²¾ç´°æ¨ç±¤ï¼å»ºç«ç¬¬ä¸åé«çå ´æ¯
DeID åºæºãæ­¤å¤ï¼æåæåºäºä¸ç¨®éå°æ­¤æ°ç
é«çæç¥ DeID ä»»åçåºç·æ¹æ³ï¼ééå°æ¸æé©åçé«çèªç¾©åé©
æ´åå° DeID ç¨åºä¸­ãåç®¡ç°¡æ½ä¸ç°¡å®ï¼ä½æåçåæ³
å¤§å¹åªæ¼ååçåæ³ãæ¸æéå¯å¨
https://github.com/tianyuan168326/MeMa-Pytorch ä¸­ç²å¾ã

##### **Rapid Reconstruction of Extremely Accelerated Liver 4D MRI via Chained Iterative Refinement**
2412.10629v1 by Di Xu, Xin Miao, Hengjie Liu, Jessica E. Scholey, Wensha Yang, Mary Feng, Michael Ohliger, Hui Lin, Yi Lao, Yang Yang, Ke Sheng

Abstract Purpose: High-quality 4D MRI requires an impractically long scanning
time for dense k-space signal acquisition covering all respiratory phases.
Accelerated sparse sampling followed by reconstruction enhancement is desired
but often results in degraded image quality and long reconstruction time. We
hereby propose the chained iterative reconstruction network (CIRNet) for
efficient sparse-sampling reconstruction while maintaining clinically
deployable quality. Methods: CIRNet adopts the denoising diffusion
probabilistic framework to condition the image reconstruction through a
stochastic iterative denoising process. During training, a forward Markovian
diffusion process is designed to gradually add Gaussian noise to the densely
sampled ground truth (GT), while CIRNet is optimized to iteratively reverse the
Markovian process from the forward outputs. At the inference stage, CIRNet
performs the reverse process solely to recover signals from noise, conditioned
upon the undersampled input. CIRNet processed the 4D data (3D+t) as temporal
slices (2D+t). The proposed framework is evaluated on a data cohort consisting
of 48 patients (12332 temporal slices) who underwent free-breathing liver 4D
MRI. 3-, 6-, 10-, 20- and 30-times acceleration were examined with a
retrospective random undersampling scheme. Compressed sensing (CS)
reconstruction with a spatiotemporal constraint and a recently proposed deep
network, Re-Con-GAN, are selected as baselines. Results: CIRNet consistently
achieved superior performance compared to CS and Re-Con-GAN. The inference time
of CIRNet, CS, and Re-Con-GAN are 11s, 120s, and 0.15s. Conclusion: A novel
framework, CIRNet, is presented. CIRNet maintains useable image quality for
acceleration up to 30 times, significantly reducing the burden of 4DMRI.

æè¦ï¼<paragraph>æè¦ç®çï¼é«åè³ª 4D MRI éè¦æ¥µä¸åå¯¦éçé·æéææï¼æè½ç²å¾æ¶µèææå¼å¸éæ®µçå¯é k ç©ºéè¨èãå éç¨çåæ¨£å¾åé²è¡éå»ºå¢å¼·åºç¶çæ³ï¼ä½éå¸¸æå°è´å½±ååè³ªä¸éï¼ä¸éå»ºæééé·ãå¨æ­¤ï¼æåæåºéå¼åè¦éå»ºç¶²è·¯ (CIRNet)ï¼ä»¥å¨ç¶­æè¨åºå¯é¨ç½²åè³ªçåæï¼é²è¡ææççç¨çåæ¨£éå»ºãæ¹æ³ï¼CIRNet æ¡ç¨å»åªæ´æ£æ©çæ¶æ§ï¼ééé¨æ©åè¦å»åªç¨åºï¼å°å½±åéå»ºé²è¡æ¢ä»¶åãå¨è¨ç·´æéï¼æ­£åé¦¬å¯å¤«æ´æ£ç¨åºæéæ¼¸å°é«æ¯éè¨å å¥å¯éåæ¨£ççå¯¦å¼ (GT) ä¸­ï¼è CIRNet åæä½³åï¼ä»¥åè¦éè½æ­£åè¼¸åºçé¦¬å¯å¤«ç¨åºãå¨æ¨è«éæ®µï¼CIRNet åå·è¡éåç¨åºï¼ä»¥å¾éè¨ä¸­å¾©åè¨èï¼ä¸¦ä»¥æ¬ åæ¨£è¼¸å¥çºæ¢ä»¶ãCIRNet å° 4D è³æ (3D+t) èççºæéåç (2D+t)ãææåºçæ¶æ§å¨ä¸åè³æç¾¤çµä¸­é²è¡è©ä¼°ï¼è©²ç¾¤çµåå« 48 ä½æ¥åèªç±å¼å¸èè 4D MRI çæ£è (12332 åæéåç)ãä½¿ç¨åæº¯é¨æ©æ¬ åæ¨£æ¹æ¡ï¼æª¢æ¥ 3ã6ã10ã20 å 30 åå éãé¸æå·ææç©ºç´æçå£ç¸®ææ¸¬ (CS) éå»ºåæè¿æåºçæ·±åº¦ç¶²è·¯ Re-Con-GAN ä½çºåºæºãçµæï¼è CS å Re-Con-GAN ç¸æ¯ï¼CIRNet æçºç²å¾è¼ä½³çæè½ãCIRNetãCS å Re-Con-GAN çæ¨è«æéåå¥çº 11 ç§ã120 ç§å 0.15 ç§ãçµè«ï¼æåºäºä¸åæ°ç©çæ¶æ§ CIRNetãCIRNet å¯ç¶­æå¯ç¨å½±ååè³ªï¼å éçæé«é 30 åï¼å¤§å¹éä½ 4DMRI çè² æã</paragraph>

##### **A recent evaluation on the performance of LLMs on radiation oncology physics using questions of randomly shuffled options**
2412.10622v1 by Peilong Wang, Jason Holmes, Zhengliang Liu, Dequan Chen, Tianming Liu, Jiajian Shen, Wei Liu

Purpose: We present an updated study evaluating the performance of large
language models (LLMs) in answering radiation oncology physics questions,
focusing on the latest released models.
  Methods: A set of 100 multiple-choice radiation oncology physics questions,
previously created by us, was used for this study. The answer options of the
questions were randomly shuffled to create "new" exam sets. Five LLMs -- OpenAI
o1-preview, GPT-4o, LLaMA 3.1 (405B), Gemini 1.5 Pro, and Claude 3.5 Sonnet --
with the versions released before September 30, 2024, were queried using these
new exams. To evaluate their deductive reasoning abilities, the correct answer
options in the questions were replaced with "None of the above." Then, the
explain-first and step-by-step instruction prompt was used to test if it
improved their reasoning abilities. The performance of the LLMs was compared to
medical physicists in majority-vote scenarios.
  Results: All models demonstrated expert-level performance on these questions,
with o1-preview even surpassing medical physicists in majority-vote scenarios.
When substituting the correct answer options with "None of the above," all
models exhibited a considerable decline in performance, suggesting room for
improvement. The explain-first and step-by-step instruction prompt helped
enhance the reasoning abilities of LLaMA 3.1 (405B), Gemini 1.5 Pro, and Claude
3.5 Sonnet models.
  Conclusion: These latest LLMs demonstrated expert-level performance in
answering radiation oncology physics questions, exhibiting great potential for
assisting in radiation oncology physics education.

æè¦ï¼<paragraph>ç®çï¼æä»¬æåºäºä¸é¡¹æ´æ°çç ç©¶ï¼è¯ä¼°å¤§åè¯­è¨æ¨¡å (LLM) å¨åç­æ¾å°è¿ç¤ç©çå­¦é®é¢æ¹é¢çæ§è½ï¼éç¹å³æ³¨ææ°åå¸çæ¨¡åã
æ¹æ³ï¼æä»¬ä¹ååå»ºçä¸ç» 100 éå¤é¡¹éæ©æ¾å°è¿ç¤ç©çå­¦é®é¢ç¨äºè¿é¡¹ç ç©¶ãé®é¢çç­æ¡éé¡¹è¢«éæºæä¹±ä»¥åå»ºâæ°âçèè¯éãäºä¸ª LLMââOpenAI o1-previewãGPT-4oãLLaMA 3.1 (405B)ãGemini 1.5 Pro å Claude 3.5 Sonnetââå¨ 2024 å¹´ 9 æ 30 æ¥ä¹ååå¸ççæ¬ä¸­ï¼ä½¿ç¨è¿äºæ°èè¯è¿è¡äºæ¥è¯¢ãä¸ºäºè¯ä¼°å®ä»¬çæ¼ç»æ¨çè½åï¼é®é¢ä¸­çæ­£ç¡®ç­æ¡éé¡¹è¢«æ¿æ¢ä¸ºâä»¥ä¸çéâãç¶åï¼ä½¿ç¨åè§£éåéæ­¥è¯´æçæç¤ºæ¥æµè¯å®æ¯å¦æé«äºå®ä»¬çæ¨çè½åãLLM çæ§è½ä¸å¤§å¤æ°æç¥¨åºæ¯ä¸­çå»å­¦ç©çå­¦å®¶è¿è¡äºæ¯è¾ã
ç»æï¼æææ¨¡åå¨è¿äºé®é¢ä¸é½è¡¨ç°åºä¸å®¶çº§æ§è½ï¼o1-preview çè³å¨å¤§å¤æ°æç¥¨åºæ¯ä¸­è¶è¿äºå»å­¦ç©çå­¦å®¶ãå½ç¨âä»¥ä¸çéâæ¿æ¢æ­£ç¡®çç­æ¡éé¡¹æ¶ï¼æææ¨¡åçæ§è½é½å¤§å¹ä¸éï¼è¿è¡¨æææ¹è¿çç©ºé´ãåè§£éåéæ­¥è¯´æçæç¤ºæå©äºå¢å¼º LLaMA 3.1 (405B)ãGemini 1.5 Pro å Claude 3.5 Sonnet æ¨¡åçæ¨çè½åã
ç»è®ºï¼è¿äºææ°ç LLM å¨åç­æ¾å°è¿ç¤ç©çå­¦é®é¢æ¹é¢è¡¨ç°åºä¸å®¶çº§æ§è½ï¼å±ç¤ºäºå¨æ¾å°è¿ç¤ç©çå­¦æè²ä¸­æä¾å¸®å©çå·¨å¤§æ½åã</paragraph>

##### **Generative AI in Medicine**
2412.10337v2 by Divya Shanmugam, Monica Agrawal, Rajiv Movva, Irene Y. Chen, Marzyeh Ghassemi, Maia Jacobs, Emma Pierson

The increased capabilities of generative AI have dramatically expanded its
possible use cases in medicine. We provide a comprehensive overview of
generative AI use cases for clinicians, patients, clinical trial organizers,
researchers, and trainees. We then discuss the many challenges -- including
maintaining privacy and security, improving transparency and interpretability,
upholding equity, and rigorously evaluating models -- which must be overcome to
realize this potential, and the open research directions they give rise to.

æè¦ï¼çæå¼ AI åè½çæåå¤§å¹æ´å±äºå¶å¨é«å­¸ä¸çæ½å¨ç¨éãæåæä¾çæå¼ AI ä½¿ç¨æ¡ä¾çå¨é¢æ¦è¿°ï¼é©ç¨æ¼è¨åºé«çãæ£èãè¨åºè©¦é©çµç¹èãç ç©¶äººå¡ååè¨èãæ¥èï¼æåè¨è«è¨±å¤ææ°ï¼åæ¬ç¶­è­·é±ç§åå®å¨æ§ãæåéæåº¦åå¯è§£éæ§ãç¶­è­·å¬å¹³æ§ï¼ä»¥åå´æ ¼è©ä¼°æ¨¡åï¼éäºææ°å¿é åææè½å¯¦ç¾æ­¤æ½åï¼ä»¥åå®åå¼ç¼çéæ¾å¼ç ç©¶æ¹åã

##### **A Cascaded Dilated Convolution Approach for Mpox Lesion Classification**
2412.10106v1 by Ayush Deshmukh

The global outbreak of Mpox virus, classified as a Public Health Emergency of
International Concern by WHO, presents significant diagnostic challenges due to
its visual similarity to other skin lesion diseases. Current clinical detection
techniques face limitations in accuracy and efficiency, necessitating improved
automated diagnostic solutions. This study introduces a novel Cascaded Atrous
Group Attention (CAGA) module, specifically designed to enhance multi-scale
feature representation while optimizing computational efficiency. By
integrating CAGA with EfficientViT-L1 as the backbone architecture, our
approach achieves state-of-the-art performance with a score of 0.98% on the
MCSI dataset, while reducing model parameters by 37.5% compared to the original
EfficientViT-L1. This reduction in computational complexity maintains
diagnostic accuracy while enabling broader deployment across
resource-constrained healthcare settings. Extensive validation across two other
benchmark datasets, including MSID and MSLD, demonstrate the model's
robustness, consistently outperforming existing approaches. Our findings
suggest that CAGA's efficient feature extraction mechanism could be adapted for
other medical imaging tasks requiring fine-grained visual discrimination.

æè¦ï¼ç±æ¼ä¸çè¡ççµç¹å°ç´ççæ¯å¨ççç¼å®çºåééæ³¨çå¬å±è¡çç·æ¥äºä»¶ï¼å æ­¤ç´ççæ¯èå¶ä»ç®èçè®ç¾çå¨è¦è¦ºä¸çç¸ä¼¼æ§ï¼å°è¨ºæ·å¸¶ä¾éå¤§ææ°ãç®åçè¨åºæª¢æ¸¬æè¡å¨æºç¢ºæ§åæçæ¹é¢é¢è¨éå¶ï¼å æ­¤éè¦æ¹é²çèªååè¨ºæ·è§£æ±ºæ¹æ¡ãæ¬ç ç©¶å¼å¥äºä¸åæ°ç©çä¸²è¯ç©ºæ´çµæ³¨æå (CAGA) æ¨¡çµï¼å°éè¨­è¨ç¨æ¼å¢å¼·å¤å°ºåº¦ç¹å¾µè¡¨ç¤ºï¼åææä½³åéç®æçãééå° CAGA è EfficientViT-L1 æ´åä½çºä¸»å¹¹æ¶æ§ï¼æåçåæ³å¨ MCSI è³æéä¸ä»¥ 0.98% çåæ¸éå°äºæåé²çæè½ï¼åæèåå§ EfficientViT-L1 ç¸æ¯ï¼æ¨¡ååæ¸æ¸å°äº 37.5%ãéç¨®éç®è¤éåº¦çéä½ç¶­æäºè¨ºæ·æºç¢ºæ§ï¼åææ¯æ´å¨è³æºåéçé«çä¿å¥ç°å¢ä¸­æ´å»£æ³å°é¨ç½²ãå¨åæ¬ MSID å MSLD å¨å§çå¦å¤å©ååºæºè³æéä¸çå»£æ³é©è­è­æäºæ¨¡åçç©©å¥æ§ï¼å§çµåªæ¼ç¾ææ¹æ³ãæåçç ç©¶çµæè¡¨æï¼CAGA çé«æç¹å¾µæåæ©å¶å¯ä»¥èª¿æ´çºå¶ä»éè¦ç´°ç·»è¦è¦ºè¾¨å¥çé«å­¸å½±åä»»åã

##### **Cycle-Consistent Bridge Diffusion Model for Accelerated MRI Reconstruction**
2412.09998v1 by Tao Song, Yicheng Wu, Minhao Hu, Xiangde Luo, Guoting Luo, Guotai Wang, Yi Guo, Feng Xu, Shaoting Zhang

Accelerated MRI reconstruction techniques aim to reduce examination time
while maintaining high image fidelity, which is highly desirable in clinical
settings for improving patient comfort and hospital efficiency. Existing deep
learning methods typically reconstruct images from under-sampled data with
traditional reconstruction approaches, but they still struggle to provide
high-fidelity results. Diffusion models show great potential to improve
fidelity of generated images in recent years. However, their inference process
starting with a random Gaussian noise introduces instability into the results
and usually requires thousands of sampling steps, resulting in sub-optimal
reconstruction quality and low efficiency. To address these challenges, we
propose Cycle-Consistent Bridge Diffusion Model (CBDM). CBDM employs two bridge
diffusion models to construct a cycle-consistent diffusion process with a
consistency loss, enhancing the fine-grained details of reconstructed images
and reducing the number of diffusion steps. Moreover, CBDM incorporates a
Contourlet Decomposition Embedding Module (CDEM) which captures multi-scale
structural texture knowledge in images through frequency domain decomposition
pyramids and directional filter banks to improve structural fidelity. Extensive
experiments demonstrate the superiority of our model by higher reconstruction
quality and fewer training iterations, achieving a new state of the art for
accelerated MRI reconstruction in both fastMRI and IXI datasets.

æè¦ï¼å éå¼ MRI éå»ºæè¡æ¨å¨ç¸®ç­æª¢æ¥æéï¼åæç¶­æé«å½±åä¿çåº¦ï¼éå¨è¨åºç°å¢ä¸­éå¸¸çæ³ï¼å¯æåçæ£èé©åº¦åé«é¢æçãç¾æçæ·±åº¦å­¸ç¿æ¹æ³éå¸¸ä½¿ç¨å³çµ±éå»ºæ¹æ³å¾æ¬ æ¡æ¨£æ¸æéå»ºå½±åï¼ä½ä»é£ä»¥æä¾é«ä¿çåº¦çµæãæ´æ£æ¨¡åå¨è¿å¹´å±ç¾åºæåçæå½±åä¿çåº¦ççµä½³æ½åãç¶èï¼å¶å¾é¨æ©é«æ¯éè¨éå§çæ¨è«éç¨æçºçµæå¸¶ä¾ä¸ç©©å®æ§ï¼ä¸éå¸¸éè¦æ¸ååæ¡æ¨£æ­¥é©ï¼å°è´æ¬¡æä½³éå»ºåè³ªåä½æçãçºäºæå°éäºææ°ï¼æåæåºå¾ªç°ä¸è´æ©æ¥æ´æ£æ¨¡å (CBDM)ãCBDM ä½¿ç¨å©åæ©æ¥æ´æ£æ¨¡åï¼å»ºæ§ä¸åå·æç¸å®¹æ§æå¤±çå¾ªç°ä¸è´æ´æ£éç¨ï¼å¢å¼·éå»ºå½±åçç²¾ç´°ç´°ç¯ä¸¦æ¸å°æ´æ£æ­¥é©çæ¸éãæ­¤å¤ï¼CBDM æ´åäºä¸åè¼ªå»åè§£åµå¥æ¨¡çµ (CDEM)ï¼ééé »ååè§£éå­å¡åæ¹åæ¿¾æ³¢å¨çµå¨å½±åä¸­æ·åå¤å°ºåº¦çµæ§ç´çç¥è­ï¼ä»¥æåçµæ§ä¿çåº¦ãå»£æ³çå¯¦é©è­æäºæåæ¨¡åçåªç°æ§ï¼å·ææ´é«çéå»ºåè³ªåæ´å°çè¨ç·´åè¦éç®ï¼å¨ fastMRI å IXI è³æéçå éå¼ MRI éå»ºä¸­éææ°çæè¡æ°´æºã

##### **Enhancing Nursing and Elderly Care with Large Language Models: An AI-Driven Framework**
2412.09946v1 by Qiao Sun, Jiexin Xie, Nanyang Ye, Qinying Gu, Shijie Guo

This paper explores the application of large language models (LLMs) in
nursing and elderly care, focusing on AI-driven patient monitoring and
interaction. We introduce a novel Chinese nursing dataset and implement
incremental pre-training (IPT) and supervised fine-tuning (SFT) techniques to
enhance LLM performance in specialized tasks. Using LangChain, we develop a
dynamic nursing assistant capable of real-time care and personalized
interventions. Experimental results demonstrate significant improvements,
paving the way for AI-driven solutions to meet the growing demands of
healthcare in aging populations.

æè¦ï¼æ¬ææ¢è¨å¤§åèªè¨æ¨¡å (LLM) å¨è­·çåèå¹´ç§è­·ä¸­çæç¨ï¼éé»å¨æ¼ AI é©åççäººç£æ§åäºåãæåå¼å¥äºä¸åæ°ç©çä¸­æè­·çè³æéï¼ä¸¦å¯¦æ½å¢éé è¨ç·´ (IPT) åç£ç£å¾®èª¿ (SFT) æè¡ï¼ä»¥å¢å¼· LLM å¨å°æ¥­ä»»åä¸­çè¡¨ç¾ãä½¿ç¨ LangChainï¼æåéç¼äºä¸ååæè­·çå©çï¼è½å¤ æä¾å³æç§è­·ååäººåå¹²é æªæ½ãå¯¦é©çµæè­æäºé¡¯èçæ¹é²ï¼çº AI é©åçè§£æ±ºæ¹æ¡éªå¹³äºéè·¯ï¼ä»¥æ»¿è¶³èé½¡åäººå£å°é«çä¿å¥æ¥çå¢é·çéæ±ã

##### **Detecting Cognitive Impairment and Psychological Well-being among Older Adults Using Facial, Acoustic, Linguistic, and Cardiovascular Patterns Derived from Remote Conversations**
2412.14194v1 by Xiaofan Mu, Salman Seyedi, Iris Zheng, Zifan Jiang, Liu Chen, Bolaji Omofojoye, Rachel Hershenberg, Allan I. Levey, Gari D. Clifford, Hiroko H. Dodge, Hyeokhyen Kwon

INTRODUCTION: The aging society urgently requires scalable methods to monitor
cognitive decline and identify social and psychological factors indicative of
dementia risk in older adults. METHODS: Our machine learning models captured
facial, acoustic, linguistic, and cardiovascular features from 39 individuals
with normal cognition or Mild Cognitive Impairment derived from remote video
conversations and classified cognitive status, social isolation, neuroticism,
and psychological well-being. RESULTS: Our model could distinguish Clinical
Dementia Rating Scale of 0.5 (vs. 0) with 0.78 area under the receiver
operating characteristic curve (AUC), social isolation with 0.75 AUC,
neuroticism with 0.71 AUC, and negative affect scales with 0.79 AUC.
DISCUSSION: Our findings demonstrate the feasibility of remotely monitoring
cognitive status, social isolation, neuroticism, and psychological well-being.
Speech and language patterns were more useful for quantifying cognitive
impairment, whereas facial expression and cardiovascular patterns using remote
photoplethysmography were more useful for quantifying personality and
psychological well-being.

æè¦ï¼å¼è¨ï¼èé½¡åç¤¾æè¿«åéè¦å¯æ´åçæ¹æ³ä¾ç£æ§èªç¥è½åä¸éï¼ä¸¦æ¾åºå¹´é·èä¸­é¡¯ç¤ºåºå¤±æºçé¢¨éªçç¤¾æåå¿çå ç´ ãæ¹æ³ï¼æåçæ©å¨å­¸ç¿æ¨¡åå¾ 39 ä½èªç¥æ­£å¸¸æè¼åº¦èªç¥éç¤çåäººä¸­æ·åäºé¢é¨ãè²é³ãèªè¨åå¿è¡ç®¡ç¹å¾µï¼éäºç¹å¾µä¾èªé ç«¯è¦è¨å°è©±ï¼ä¸¦åé¡äºèªç¥çæãç¤¾äº¤å­¤ç«ãç¥ç¶è³ªåå¿çå¥åº·ãçµæï¼æåçæ¨¡åå¯ä»¥ååè¨åºå¤±æºè©åéè¡¨ 0.5ï¼ç¸å°æ¼ 0ï¼ï¼æ¥æ¶èæä½ç¹å¾µæ²ç·ï¼AUCï¼ä¸çé¢ç©çº 0.78ï¼ç¤¾äº¤å­¤ç«ç AUC çº 0.75ï¼ç¥ç¶è³ªç AUC çº 0.71ï¼è² é¢å½±é¿éè¡¨ç AUC çº 0.79ãè¨è«ï¼æåçç ç©¶çµæè­æäºé ç«¯ç£æ§èªç¥çæãç¤¾äº¤å­¤ç«ãç¥ç¶è³ªåå¿çå¥åº·çå¯è¡æ§ãèªè¨åèªè¨æ¨¡å¼å°æ¼éåèªç¥éç¤æ´æç¨ï¼èä½¿ç¨é ç«¯åé»å®¹ç©æè¨è¡çé¢é¨è¡¨æåå¿è¡ç®¡æ¨¡å¼å°æ¼éåäººæ ¼åå¿çå¥åº·æ´æç¨ã

##### **Efficient and Comprehensive Feature Extraction in Large Vision-Language Model for Clinical Pathology Analysis**
2412.09521v1 by Shengxuming Zhang, Weihan Li, Tianhong Gao, Jiacong Hu, Haoming Luo, Mingli Song, Xiuming Zhang, Zunlei Feng

Pathological diagnosis is vital for determining disease characteristics,
guiding treatment, and assessing prognosis, relying heavily on detailed,
multi-scale analysis of high-resolution whole slide images (WSI). However,
traditional pure vision models face challenges of redundant feature extraction,
whereas existing large vision-language models (LVLMs) are limited by input
resolution constraints, hindering their efficiency and accuracy. To overcome
these issues, we propose two innovative strategies: the mixed task-guided
feature enhancement, which directs feature extraction toward lesion-related
details across scales, and the prompt-guided detail feature completion, which
integrates coarse- and fine-grained features from WSI based on specific prompts
without compromising inference speed. Leveraging a comprehensive dataset of
490,000 samples from diverse pathology tasks-including cancer detection,
grading, vascular and neural invasion identification, and so on-we trained the
pathology-specialized LVLM, OmniPath. Extensive experiments demonstrate that
this model significantly outperforms existing methods in diagnostic accuracy
and efficiency, offering an interactive, clinically aligned approach for
auxiliary diagnosis in a wide range of pathology applications.

æè¦ï¼ççè¯æ­å¯¹äºç¡®å®ç¾çç¹å¾ãæå¯¼æ²»çåè¯ä¼°é¢åè³å³éè¦ï¼å®ä¸¥éä¾èµäºå¯¹é«åè¾¨çå¨ç»çå¾å (WSI) çè¯¦ç»ãå¤å°ºåº¦åæãç¶èï¼ä¼ ç»ççº¯è§è§æ¨¡åé¢ä¸´åä½ç¹å¾æåçææï¼èç°æçå¤§åè§è§è¯­è¨æ¨¡å (LVLMs) åå°è¾å¥åè¾¨ççº¦æçéå¶ï¼é»ç¢äºå®ä»¬çæçååç¡®æ§ãä¸ºäºåæè¿äºé®é¢ï¼æä»¬æåºäºä¸¤ç§åæ°ç­ç¥ï¼æ··åä»»å¡å¼å¯¼çç¹å¾å¢å¼ºï¼å®å°ç¹å¾æåå¼å¯¼å°è·¨å°ºåº¦ççåç¸å³ç»èä¸ï¼ä»¥åæç¤ºå¼å¯¼çç»èç¹å¾å®æï¼å®åºäºç¹å®æç¤ºå° WSI ä¸­çç²ç²åº¦åç»ç²åº¦ç¹å¾éæå¨ä¸èµ·ï¼èä¸ä¼å½±åæ¨çéåº¦ãå©ç¨æ¥èªä¸åççä»»å¡ç 490,000 ä¸ªæ ·æ¬çç»¼åæ°æ®éï¼åæ¬ççæ£æµãåçº§ãè¡ç®¡åç¥ç»ä¾µè¢­è¯å«ç­ï¼æä»¬è®­ç»äºççå­¦ä¸ä¸ LVLMï¼å³ OmniPathãå¤§éçå®éªè¡¨æï¼è¯¥æ¨¡åå¨è¯æ­åç¡®æ§åæçæ¹é¢ææ¾ä¼äºç°ææ¹æ³ï¼ä¸ºå¹¿æ³çççå­¦åºç¨ä¸­çè¾å©è¯æ­æä¾äºä¸ç§äº¤äºå¼ãä¸´åºä¸ä¸è´çæ¹æ³ã

##### **Towards a Multimodal Large Language Model with Pixel-Level Insight for Biomedicine**
2412.09278v1 by Xiaoshuang Huang, Lingdong Shen, Jia Liu, Fangxin Shang, Hongxiang Li, Haifeng Huang, Yehui Yang

In recent years, Multimodal Large Language Models (MLLM) have achieved
notable advancements, demonstrating the feasibility of developing an
intelligent biomedical assistant. However, current biomedical MLLMs
predominantly focus on image-level understanding and restrict interactions to
textual commands, thus limiting their capability boundaries and the flexibility
of usage. In this paper, we introduce a novel end-to-end multimodal large
language model for the biomedical domain, named MedPLIB, which possesses
pixel-level understanding. Excitingly, it supports visual question answering
(VQA), arbitrary pixel-level prompts (points, bounding boxes, and free-form
shapes), and pixel-level grounding. We propose a novel Mixture-of-Experts (MoE)
multi-stage training strategy, which divides MoE into separate training phases
for a visual-language expert model and a pixel-grounding expert model, followed
by fine-tuning using MoE. This strategy effectively coordinates multitask
learning while maintaining the computational cost at inference equivalent to
that of a single expert model. To advance the research of biomedical MLLMs, we
introduce the Medical Complex Vision Question Answering Dataset (MeCoVQA),
which comprises an array of 8 modalities for complex medical imaging question
answering and image region understanding. Experimental results indicate that
MedPLIB has achieved state-of-the-art outcomes across multiple medical visual
language tasks. More importantly, in zero-shot evaluations for the pixel
grounding task, MedPLIB leads the best small and large models by margins of
19.7 and 15.6 respectively on the mDice metric. The codes, data, and model
checkpoints will be made publicly available at
https://github.com/ShawnHuang497/MedPLIB.

æè¦ï¼<paragraph>è¿å¹´æ¥ï¼å¤æ¨¡æå¤§åè¯­è¨æ¨¡å (MLLM) å·²åå¾æ¾èè¿å±ï¼è¯æäºå¼åæºè½çç©å»å­¦å©ççå¯è¡æ§ãç¶èï¼å½åççç©å»å­¦ MLLM ä¸»è¦ä¸æ³¨äºå¾åçº§çè§£ï¼å¹¶å°äº¤äºéå¶å¨ææ¬å½ä»¤ä¸­ï¼ä»èéå¶äºå®ä»¬çè½åè¾¹çåä½¿ç¨çµæ´»æ§ãå¨æ¬æä¸­ï¼æä»¬ä»ç»äºä¸ä¸ªç¨äºçç©å»å­¦é¢åçå¨æ°ç«¯å°ç«¯å¤æ¨¡æå¤§åè¯­è¨æ¨¡åï¼åä¸º MedPLIBï¼å®å·æåç´ çº§çè§£è½åãä»¤äººå´å¥çæ¯ï¼å®æ¯æè§è§é®ç­ (VQA)ãä»»æåç´ çº§æç¤ºï¼ç¹ãè¾¹çæ¡åèªç±å½¢å¼å½¢ç¶ï¼ä»¥ååç´ çº§æ¥å°ãæä»¬æåºäºä¸ç§æ°é¢çä¸å®¶æ··å (MoE) å¤é¶æ®µè®­ç»ç­ç¥ï¼è¯¥ç­ç¥å° MoE åä¸ºè§è§è¯­è¨ä¸å®¶æ¨¡åååç´ æ¥å°ä¸å®¶æ¨¡åçåç¬è®­ç»é¶æ®µï¼ç¶åä½¿ç¨ MoE è¿è¡å¾®è°ãè¯¥ç­ç¥ææå°åè°äºå¤ä»»å¡å­¦ä¹ ï¼åæ¶å°æ¨çæ¶çè®¡ç®ææ¬ä¿æå¨ä¸åä¸ªä¸å®¶æ¨¡åç¸å½çæ°´å¹³ãä¸ºäºæ¨è¿çç©å»å­¦ MLLM çç ç©¶ï¼æä»¬å¼å¥äºå»å­¦å¤æè§è§é®ç­æ°æ®é (MeCoVQA)ï¼å®åå«ä¸ç³»å 8 ç§ç¨äºå¤æå»å­¦å½±åé®ç­åå¾ååºåçè§£çæ¨¡æãå®éªç»æè¡¨æï¼MedPLIB å¨å¤ä¸ªå»å­¦è§è§è¯­è¨ä»»å¡ä¸­åå¾äºæåè¿çææãæ´éè¦çæ¯ï¼å¨åç´ æ¥å°ä»»å¡çé¶æ ·æ¬è¯ä¼°ä¸­ï¼MedPLIB å¨ mDice ææ ä¸åå«ä»¥ 19.7 å 15.6 çä¼å¿é¢åäºæå¥½çå°ååå¤§åæ¨¡åãä»£ç ãæ°æ®åæ¨¡åæ£æ¥ç¹å°å¨ https://github.com/ShawnHuang497/MedPLIB ä¸å¬å¼ã
</paragraph>

##### **CSSDH: An Ontology for Social Determinants of Health to Operational Continuity of Care Data Interoperability**
2412.09223v1 by Subhashis Das, Debashis Naskar, Sara Rodriguez Gonzalez

The rise of digital platforms has led to an increasing reliance on
technology-driven, home-based healthcare solutions, enabling individuals to
monitor their health and share information with healthcare professionals as
needed. However, creating an efficient care plan management system requires
more than just analyzing hospital summaries and Electronic Health Records
(EHRs). Factors such as individual user needs and social determinants of
health, including living conditions and the flow of healthcare information
between different settings, must also be considered. Challenges in this complex
healthcare network involve schema diversity (in EHRs, personal health records,
etc.) and terminology diversity (e.g., ICD, SNOMED-CT) across ancillary
healthcare operations. Establishing interoperability among various systems and
applications is crucial, with the European Interoperability Framework (EIF)
emphasizing the need for patient-centric access and control of healthcare data.
In this paper, we propose an integrated ontological model, the Common Semantic
Data Model for Social Determinants of Health (CSSDH), by combining ISO/DIS
13940:2024 ContSys with WHO Social Determinants of Health. CSSDH aims to
achieve interoperability within the Continuity of Care Network.

æè¦ï¼æ¸ä½å¹³å°çèèµ·å°è´æä¾æä¾è³´ç§æé©åãå±å®¶é«çä¿å¥è§£æ±ºæ¹æ¡ï¼è®åäººå¾ä»¥ç£æ¸¬èªå·±çå¥åº·ï¼ä¸¦è¦éè¦èé«çä¿å¥å°æ¥­äººå¡åäº«è³è¨ãç¶èï¼å»ºç«ä¸åææçç§è­·è¨ç«ç®¡çç³»çµ±ï¼éè¦çå¯ä¸ååæ¯åæé«é¢æè¦åé»å­å¥åº·ç´é (EHR) èå·²ãéå¿é èéåäººä½¿ç¨èéæ±åå¥åº·çç¤¾ææ±ºå®å ç´ ï¼åæ¬çæ´»æ¢ä»¶åä¸åç°å¢ä¹éçé«çä¿å¥è³è¨æµåãéåè¤éçé«çä¿å¥ç¶²è·¯ä¸­çææ°ï¼åæ¬æ¶æ§å¤æ¨£æ§ (å¨ EHRãåäººå¥åº·ç´éç­) åè¡èªå¤æ¨£æ§ (ä¾å¦ ICDãSNOMED-CT) ç­è¼å©é«çä¿å¥ä½æ¥­ãå¨åç¨®ç³»çµ±åæç¨ç¨å¼ä¹éå»ºç«äºéæ§è³ééè¦ï¼æ­æ´²äºéæ§æ¶æ§ (EIF) å¼·èª¿éè¦ä»¥çäººçºä¸­å¿å­ååæ§å¶é«çä¿å¥è³æãå¨æ¬æä¸­ï¼æåæåºä¸åæ´åçæ¬é«è«æ¨¡åï¼å³çµå ISO/DIS 13940:2024 ContSys è WHO å¥åº·ç¤¾ææ±ºå®å ç´ çç¤¾ææ±ºå®å ç´ å¥åº·å±åèªç¾©è³ææ¨¡å (CSSDH)ãCSSDH æ¨å¨å¨ç§è­·é£çºæ§ç¶²è·¯ä¸­éæäºéæ§ã

##### **Understanding Opportunities and Risks of Synthetic Relationships: Leveraging the Power of Longitudinal Research with Customised AI Tools**
2412.09086v1 by Alfio Ventura, Nils KÃ¶bis

This position paper discusses the benefits of longitudinal behavioural
research with customised AI tools for exploring the opportunities and risks of
synthetic relationships. Synthetic relationships are defined as "continuing
associations between humans and AI tools that interact with one another wherein
the AI tool(s) influence(s) humans' thoughts, feelings, and/or actions."
(Starke et al., 2024). These relationships can potentially improve health,
education, and the workplace, but they also bring the risk of subtle
manipulation and privacy and autonomy concerns. To harness the opportunities of
synthetic relationships and mitigate their risks, we outline a methodological
approach that complements existing findings. We propose longitudinal research
designs with self-assembled AI agents that enable the integration of detailed
behavioural and self-reported data.

æè¦ï¼æ¬ç«å ´æä»¶æ¢è¨ç¸±åè¡çºç ç©¶èå®¢è£½å AI å·¥å·çåªé»ï¼ç¨æ¼æ¢è¨åæéä¿çæ©æèé¢¨éªãåæéä¿å®ç¾©çºãäººé¡è AI å·¥å·ä¹éæçºçéè¯ï¼å½¼æ­¤äºåï¼å¶ä¸­ AI å·¥å·æå½±é¿äººé¡çæ³æ³ãæåå/æè¡çºããï¼Starke ç­äººï¼2024 å¹´ï¼ãéäºéä¿æå¯è½æ¹åå¥åº·ãæè²åè·å ´ï¼ä½å®åä¹å¸¶ä¾å¾®å¦çæç¸±ä»¥åé±ç§åèªä¸»æ¬çé±æãçºäºå©ç¨åæéä¿çæ©æä¸¦éä½å¶é¢¨éªï¼æåæ¦è¿°äºä¸ç¨®æ¹æ³è«æ¹æ³ï¼è£åç¾æçç¼ç¾ãæåæåºä½¿ç¨èªçµè£ AI ä»£ççç¸±åç ç©¶è¨­è¨ï¼ä½¿æåè½å¤ æ´åè©³ç´°çè¡çºåèªæå ±åè³æã

##### **An Interoperable Machine Learning Pipeline for Pediatric Obesity Risk Estimation**
2412.10454v1 by Hamed Fayyaz, Mehak Gupta, Alejandra Perez Ramirez, Claudine Jurkovitz, H. Timothy Bunnell, Thao-Ly T. Phan, Rahmatollah Beheshti

Reliable prediction of pediatric obesity can offer a valuable resource to
providers, helping them engage in timely preventive interventions before the
disease is established. Many efforts have been made to develop ML-based
predictive models of obesity, and some studies have reported high predictive
performances. However, no commonly used clinical decision support tool based on
existing ML models currently exists. This study presents a novel end-to-end
pipeline specifically designed for pediatric obesity prediction, which supports
the entire process of data extraction, inference, and communication via an API
or a user interface. While focusing only on routinely recorded data in
pediatric electronic health records (EHRs), our pipeline uses a diverse
expert-curated list of medical concepts to predict the 1-3 years risk of
developing obesity. Furthermore, by using the Fast Healthcare Interoperability
Resources (FHIR) standard in our design procedure, we specifically target
facilitating low-effort integration of our pipeline with different EHR systems.
In our experiments, we report the effectiveness of the predictive model as well
as its alignment with the feedback from various stakeholders, including ML
scientists, providers, health IT personnel, health administration
representatives, and patient group representatives.

æè¦ï¼å¯é çå¿ç«¥è¥èé¢æµå¯ä»¥ä¸ºæä¾èæä¾å®è´µçèµæºï¼å¸®å©ä»ä»¬å¨ç¾çç¡®ç«ä¹ååæ¶è¿è¡é¢é²æ§å¹²é¢ãå·²ç»ä¸ºå¼ååºäº ML çè¥èé¢æµæ¨¡åååºäºè®¸å¤åªåï¼ä¸äºç ç©¶æ¥åäºè¾é«çé¢æµæ§è½ãç¶èï¼ç®åå°ä¸å­å¨åºäºç°æ ML æ¨¡åçå¸¸ç¨ä¸´åºå³ç­æ¯æå·¥å·ãæ¬ç ç©¶æåºäºä¸ç§ä¸é¨è®¾è®¡ç¨äºå¿ç«¥è¥èé¢æµçæ°åç«¯å°ç«¯ç®¡éï¼å®æ¯æéè¿ API æç¨æ·çé¢è¿è¡æ°æ®æåãæ¨çåéä¿¡çæ´ä¸ªè¿ç¨ãè½ç¶ä»å³æ³¨å¿ç§çµå­å¥åº·è®°å½ (EHR) ä¸­å¸¸è§è®°å½çæ°æ®ï¼ä½æä»¬çç®¡éä½¿ç¨ç±ä¸å®¶ç­åçåç§å»å­¦æ¦å¿µåè¡¨æ¥é¢æµ 1-3 å¹´ååçè¥èçé£é©ãæ­¤å¤ï¼éè¿å¨æä»¬çè®¾è®¡ç¨åºä¸­ä½¿ç¨å¿«éå»çäºæä½æ§èµæº (FHIR) æ åï¼æä»¬ä¸é¨éå¯¹ä¿è¿æä»¬çç®¡éä¸ä¸å EHR ç³»ç»çä½ææ¬éæãå¨æä»¬çå®éªä¸­ï¼æä»¬æ¥åäºé¢æµæ¨¡åçæææ§ä»¥åå®ä¸åæ¬ ML ç§å­¦å®¶ãæä¾èãå¥åº· IT äººåãå¥åº·ç®¡çä»£è¡¨åæ£èç¾¤ä½ä»£è¡¨å¨åçåç§å©çç¸å³èçåé¦çä¸è´æ§ã

##### **Structurally Consistent MRI Colorization using Cross-modal Fusion Learning**
2412.10452v1 by Mayuri Mathur, Anav Chaudhary, Saurabh Kumar Gupta, Ojaswa Sharma

Medical image colorization can greatly enhance the interpretability of the
underlying imaging modality and provide insights into human anatomy. The
objective of medical image colorization is to transfer a diverse spectrum of
colors distributed across human anatomy from Cryosection data to source MRI
data while retaining the structures of the MRI. To achieve this, we propose a
novel architecture for structurally consistent color transfer to the source MRI
data. Our architecture fuses segmentation semantics of Cryosection images for
stable contextual colorization of various organs in MRI images. For
colorization, we neither require precise registration between MRI and
Cryosection images, nor segmentation of MRI images. Additionally, our
architecture incorporates a feature compression-and-activation mechanism to
capture organ-level global information and suppress noise, enabling the
distinction of organ-specific data in MRI scans for more accurate and realistic
organ-specific colorization. Our experiments demonstrate that our architecture
surpasses the existing methods and yields better quantitative and qualitative
results.

æè¦ï¼é«å­¸å½±åèè²è½å¤§å¹æååºç¤å½±åæ¨¡å¼çå¯è§£è®æ§ï¼ä¸¦æä¾äººé¡è§£åå­¸çè¦è§£ãé«å­¸å½±åèè²çç®æ¨æ¯å°åå¸å¨äººé¡è§£åå­¸ä¸­ãä¾èªå·ååçè³æçåç¨®è²å½©åè­è½ç§»å°åå§ MRI è³æï¼åæä¿ç MRI ççµæ§ãçºéææ­¤ç®æ¨ï¼æåæåºä¸åçµæ§ä¸è´è²å½©è½ç§»å°åå§ MRI è³æçæ°ç©æ¶æ§ãæåçæ¶æ§èåå·ååçå½±åçåå²èªç¾©ï¼ä»¥ç©©å®èè² MRI å½±åä¸­åç¨®å¨å®çè²å½©ãå¨èè²æï¼æåæ¢ä¸éè¦ MRI èå·ååçå½±åä¹éç²¾ç¢ºçéæºï¼ä¹ä¸éè¦ MRI å½±åçåå²ãæ­¤å¤ï¼æåçæ¶æ§ç´å¥ä¸åç¹å¾µå£ç¸®åååæ©å¶ï¼ä»¥æ·åå¨å®å±¤ç´çæ´é«è³è¨ä¸¦æå¶éè¨ï¼è® MRI ææä¸­å¨å®ç¹å®è³æçåå¥æ´ç²¾ç¢ºä¸é¼çï¼é²èé²è¡å¨å®ç¹å®èè²ãæåçå¯¦é©è­æï¼æåçæ¶æ§åªæ¼ç¾ææ¹æ³ï¼ä¸¦ç¢çæ´å¥½çéååè³ªåçµæã

##### **Radiology Report Generation via Multi-objective Preference Optimization**
2412.08901v2 by Ting Xiao, Lei Shi, Peng Liu, Zhe Wang, Chenjia Bai

Automatic Radiology Report Generation (RRG) is an important topic for
alleviating the substantial workload of radiologists. Existing RRG approaches
rely on supervised regression based on different architectures or additional
knowledge injection,while the generated report may not align optimally with
radiologists' preferences. Especially, since the preferences of radiologists
are inherently heterogeneous and multidimensional, e.g., some may prioritize
report fluency, while others emphasize clinical accuracy. To address this
problem,we propose a new RRG method via Multi-objective Preference Optimization
(MPO) to align the pre-trained RRG model with multiple human preferences, which
can be formulated by multi-dimensional reward functions and optimized by
multi-objective reinforcement learning (RL). Specifically, we use a preference
vector to represent the weight of preferences and use it as a condition for the
RRG model. Then, a linearly weighed reward is obtained via a dot product
between the preference vector and multi-dimensional reward. Next,the RRG model
is optimized to align with the preference vector by optimizing such a reward
via RL. In the training stage,we randomly sample diverse preference vectors
from the preference space and align the model by optimizing the weighted
multi-objective rewards, which leads to an optimal policy on the entire
preference space. When inference,our model can generate reports aligned with
specific preferences without further fine-tuning. Extensive experiments on two
public datasets show the proposed method can generate reports that cater to
different preferences in a single model and achieve state-of-the-art
performance.

æè¦ï¼èªåæ¾å°å ±åçæ (RRG) æ¯æ¸è¼æ¾å°ç§é«å¸«å¤§éå·¥ä½è² æçéè¦è­°é¡ãç¾æç RRG æ¹æ³ä»°è³´åºæ¼ä¸åæ¶æ§æé¡å¤ç¥è­æ³¨å¥çç£ç£å¼åæ­¸ï¼èç¢ççå ±åå¯è½ç¡æ³æä½³å°ç¬¦åæ¾å°ç§é«å¸«çåå¥½ãç¹å¥æ¯ï¼ç±æ¼æ¾å°ç§é«å¸«çåå¥½æ¬è³ªä¸æ¯ç°è³ªä¸å¤é¢åçï¼ä¾å¦ï¼æäºäººå¯è½åªåèæ®å ±åçæµæ¢åº¦ï¼èå¦ä¸äºäººåå¼·èª¿è¨åºæºç¢ºæ§ãçºäºè§£æ±ºéååé¡ï¼æåééå¤ç®æ¨åå¥½æä½³å (MPO) æåºä¸åæ°ç RRG æ¹æ³ï¼ä»¥å°é åè¨ç·´ç RRG æ¨¡åèå¤åäººé¡åå¥½å°é½ï¼éå¯ä»¥ç¨å¤ç¶­çåµå½æ¸ä¾å¶å®ï¼ä¸¦ééå¤ç®æ¨å¼·åå­¸ç¿ (RL) ä¾æä½³åãå·é«ä¾èªªï¼æåä½¿ç¨åå¥½åéä¾è¡¨ç¤ºåå¥½çæ¬éï¼ä¸¦å°å¶ç¨ä½ RRG æ¨¡åçæ¢ä»¶ãç¶å¾ï¼ééåå¥½åéåå¤ç¶­çåµä¹éçé»ç©ï¼ç²å¾ç·æ§å æ¬çåµãæ¥ä¸ä¾ï¼éé RL æä½³åæ­¤é¡çåµï¼æä½³å RRG æ¨¡åä»¥èåå¥½åéå°é½ãå¨è¨ç·´éæ®µï¼æåå¾åå¥½ç©ºéä¸­é¨æ©åæ¨£ä¸åçåå¥½åéï¼ä¸¦ééæä½³åå æ¬çå¤ç®æ¨çåµä¾å°é½æ¨¡åï¼éæç¢çæ´ååå¥½ç©ºéçæä½³ç­ç¥ãå¨æ¨è«æï¼æåçæ¨¡åå¯ä»¥çæèç¹å®åå¥½å°é½çå ±åï¼èç¡éé²ä¸æ­¥å¾®èª¿ãå¨å©åå¬éè³æéä¸çå»£æ³å¯¦é©é¡¯ç¤ºï¼ææåºçæ¹æ³å¯ä»¥å¨å®ä¸æ¨¡åä¸­çæè¿åä¸ååå¥½çå ±åï¼ä¸¦éå°æåé²çæè½ã

##### **AI-assisted Knowledge Discovery in Biomedical Literature to Support Decision-making in Precision Oncology**
2412.08900v1 by Ting He, Kory Kreimeyer, Mimi Najjar, Jonathan Spiker, Maria Fatteh, Valsamo Anagnostou, Taxiarchis Botsis

The delivery of appropriate targeted therapies to cancer patients requires
the complete analysis of the molecular profiling of tumors and the patient's
clinical characteristics in the context of existing knowledge and recent
findings described in biomedical literature and several other sources. We
evaluated the potential contributions of specific natural language processing
solutions to support knowledge discovery from biomedical literature. Two models
from the Bidirectional Encoder Representations from Transformers (BERT) family,
two Large Language Models, and PubTator 3.0 were tested for their ability to
support the named entity recognition (NER) and the relation extraction (RE)
tasks. PubTator 3.0 and the BioBERT model performed best in the NER task (best
F1-score equal to 0.93 and 0.89, respectively), while BioBERT outperformed all
other solutions in the RE task (best F1-score 0.79) and a specific use case it
was applied to by recognizing nearly all entity mentions and most of the
relations.

æè¦ï¼é©ç¶æ¨é¶çæ³å¨çççæ£çæç¨ï¼éè¦å¨ç¾æç¥è­åçç©é«å­¸æç»ä¸­ææè¿°çææ°ç¼ç¾çèçµ¡ä¸ï¼å®æ´åæè«ç¤çåå­ç¹å¾µåçæ£çè¨åºç¹å¾µãæåè©ä¼°äºç¹å®èªç¶èªè¨èçè§£æ±ºæ¹æ¡å¨æ¯æ´å¾çç©é«å­¸æç»ä¸­ç¼ç¾ç¥è­çæ½å¨è²¢ç»ãæåæ¸¬è©¦äºä¾èª Transformer éåç·¨ç¢¼å¨è¡¨ç¤ºæ³ (BERT) å®¶æçå©åæ¨¡åãå©åå¤§åèªè¨æ¨¡åå PubTator 3.0ï¼ä»¥è©ä¼°å®åæ¯æ´å½åå¯¦é«è¾¨è­ (NER) åéä¿èå (RE) ä»»åçè½åãPubTator 3.0 å BioBERT æ¨¡åå¨ NER ä»»åä¸­è¡¨ç¾æä½³ï¼æä½³ F1 åæ¸åå¥çº 0.93 å 0.89ï¼ï¼è BioBERT å¨ RE ä»»åä¸­åªæ¼ææå¶ä»è§£æ±ºæ¹æ¡ï¼æä½³ F1 åæ¸çº 0.79ï¼ï¼ä¸¦ä¸å¨ä¸åç¹å®çæç¨æ¡ä¾ä¸­ï¼å®å¹¾ä¹è¾¨è­åºææå¯¦é«æååå¤§é¨åéä¿ã

##### **Towards modeling evolving longitudinal health trajectories with a transformer-based deep learning model**
2412.08873v1 by Hans Moen, Vishnu Raj, Andrius Vabalas, Markus Perola, Samuel Kaski, Andrea Ganna, Pekka Marttinen

Health registers contain rich information about individuals' health
histories. Here our interest lies in understanding how individuals' health
trajectories evolve in a nationwide longitudinal dataset with coded features,
such as clinical codes, procedures, and drug purchases. We introduce a
straightforward approach for training a Transformer-based deep learning model
in a way that lets us analyze how individuals' trajectories change over time.
This is achieved by modifying the training objective and by applying a causal
attention mask. We focus here on a general task of predicting the onset of a
range of common diseases in a given future forecast interval. However, instead
of providing a single prediction about diagnoses that could occur in this
forecast interval, our approach enable the model to provide continuous
predictions at every time point up until, and conditioned on, the time of the
forecast period. We find that this model performs comparably to other models,
including a bi-directional transformer model, in terms of basic prediction
performance while at the same time offering promising trajectory modeling
properties. We explore a couple of ways to use this model for analyzing health
trajectories and aiding in early detection of events that forecast possible
later disease onsets. We hypothesize that this method may be helpful in
continuous monitoring of peoples' health trajectories and enabling
interventions in ongoing health trajectories, as well as being useful in
retrospective analyses.

æè¦ï¼å¥åº·ç»è¨åå«åäººå¥åº·å²çè±å¯è³è¨ãæåå¨æ­¤æèè¶£äºè§£åäººå¥åº·è»è·¡å¦ä½é¨èç·¨ç¢¼åè½ï¼ä¾å¦è¨åºä»£ç¢¼ãç¨åºåè¥ç©è³¼è²·ï¼å¨å¨åç¸±åè³æéä¸­æ¼è®ãæåå¼å¥ä¸ç¨®ç´æ¥çæ¹æ³ï¼ç¨æ¼è¨ç·´ Transformer çºåºç¤çæ·±åº¦å­¸ç¿æ¨¡åï¼è®æååæåäººè»è·¡å¦ä½é¨èæéæ¨ç§»èæ¹è®ãéæ¯ééä¿®æ¹è¨ç·´ç®æ¨ä¸¦æç¨å ææ³¨æåé®ç½©ä¾å¯¦ç¾çãæåå¨æ­¤å°æ³¨æ¼é æ¸¬å¨çµ¦å®æªä¾é æ¸¬åéå§ä¸ç³»åå¸¸è¦ç¾çç¼ççä¸è¬ä»»åãç¶èï¼æåçåæ³ä¸¦éæä¾éæ¼å¯è½å¨æ­¤é æ¸¬åéå§ç¼ççè¨ºæ·çå®ä¸é æ¸¬ï¼èæ¯è®æ¨¡åè½å¤ å¨æ¯åæéé»æä¾é£çºé æ¸¬ï¼ç´å°é æ¸¬æéçæéï¼ä¸¦ä»¥å¶çºæ¢ä»¶ãæåç¼ç¾æ­¤æ¨¡åçè¡¨ç¾èå¶ä»æ¨¡åï¼åæ¬éå Transformer æ¨¡åï¼ç¸ç¶ï¼å¨åºæ¬é æ¸¬æè½æ¹é¢å¦æ­¤ï¼åææä¾æå¸æçè»è·¡å»ºæ¨¡å±¬æ§ãæåæ¢ç´¢äºå¹¾ç¨®ä½¿ç¨æ­¤æ¨¡ååæå¥åº·è»è·¡ä¸¦åå©æ©æåµæ¸¬é æ¸¬å¯è½å¾çºç¼çäºä»¶çæ¹æ³ãæååè¨­æ­¤æ¹æ³å¯è½æå©æ¼æçºç£æ¸¬åäººå¥åº·è»è·¡ï¼ä¸¦è®å¹²é æªæ½å¾ä»¥å¨æçºçå¥åº·è»è·¡ä¸­é²è¡ï¼ä¸å¨åé¡§æ§åæä¸­ä¹å¾æç¨ã

##### **Performance of a large language model-Artificial Intelligence based chatbot for counseling patients with sexually transmitted infections and genital diseases**
2412.12166v1 by Nikhil Mehta, Sithira Ambepitiya, Thanveer Ahamad, Dinuka Wijesundara, Yudara Kularathne

Introduction: Global burden of sexually transmitted infections (STIs) is
rising out of proportion to specialists. Current chatbots like ChatGPT are not
tailored for handling STI-related concerns out of the box. We developed Otiz,
an Artificial Intelligence-based (AI-based) chatbot platform designed
specifically for STI detection and counseling, and assessed its performance.
Methods: Otiz employs a multi-agent system architecture based on GPT4-0613,
leveraging large language model (LLM) and Deterministic Finite Automaton
principles to provide contextually relevant, medically accurate, and empathetic
responses. Its components include modules for general STI information,
emotional recognition, Acute Stress Disorder detection, and psychotherapy. A
question suggestion agent operates in parallel. Four STIs (anogenital warts,
herpes, syphilis, urethritis/cervicitis) and 2 non-STIs (candidiasis, penile
cancer) were evaluated using prompts mimicking patient language. Each prompt
was independently graded by two venereologists conversing with Otiz as patient
actors on 6 criteria using Numerical Rating Scale ranging from 0 (poor) to 5
(excellent). Results: Twenty-three venereologists did 60 evaluations of 30
prompts. Across STIs, Otiz scored highly on diagnostic accuracy (4.1-4.7),
overall accuracy (4.3-4.6), correctness of information (5.0), comprehensibility
(4.2-4.4), and empathy (4.5-4.8). However, relevance scores were lower
(2.9-3.6), suggesting some redundancy. Diagnostic scores for non-STIs were
lower (p=0.038). Inter-observer agreement was strong, with differences greater
than 1 point occurring in only 12.7% of paired evaluations. Conclusions: AI
conversational agents like Otiz can provide accurate, correct, discrete,
non-judgmental, readily accessible and easily understandable STI-related
information in an empathetic manner, and can alleviate the burden on healthcare
systems.

æè¦ï¼<paragraph>å¼è¨ï¼å¨çæ§å³æææï¼STIï¼çè² æèå°å®¶ä¸ææ¯ä¾å°å¢å ãç¾æçèå¤©æ©å¨äººï¼ä¾å¦ ChatGPTï¼ä¸¦éçºäºèçè STI ç¸éççæ®èéèº«æé ãæåéç¼äº Otizï¼ä¸ååºæ¼äººå·¥æºæ§ï¼AIï¼çèå¤©æ©å¨äººå¹³å°ï¼å°éè¨­è¨ç¨æ¼ STI æª¢æ¸¬åè«®è©¢ï¼ä¸¦è©ä¼°å¶æè½ã
æ¹æ³ï¼Otiz æ¡ç¨åºæ¼ GPT4-0613 çå¤ä»£çç³»çµ±æ¶æ§ï¼å©ç¨å¤§åèªè¨æ¨¡åï¼LLMï¼åç¢ºå®æéèªåæ©ååï¼æä¾èèçµ¡ç¸éãé«å­¸ä¸æºç¢ºä¸å¯æåçå¿çåæãå¶åä»¶åæ¬ä¸è¬ STI è³è¨ãæç·è¾¨è­ãæ¥æ§å£åç¾æ£æª¢æ¸¬åå¿çæ²»çæ¨¡çµãä¸ååé¡å»ºè­°ä»£çæä¸¦è¡éä½ãä½¿ç¨æ¨¡æ¬æ£èèªè¨çæç¤ºï¼è©ä¼°äºåç¨® STIï¼èéçæ®å¨ç£ãç±ç¹ãæ¢æ¯ãå°¿éç/å­å®®é ¸çï¼åå©ç¨®é STIï¼å¿µç èçãé°èçï¼ãæ¯åæç¤ºç±å©ä½æ³å°¿ç§é«å¸«ç¨ç«è©åï¼ä»åä»¥æ£èè§è²è Otiz å°è©±ï¼æ ¹æ 0ï¼å·®ï¼å° 5ï¼æ¥µä½³ï¼çæ¸å¼è©åéè¡¨ï¼éå°å­é æ¨æºé²è¡è©åãçµæï¼23 ä½æ³å°¿ç§é«å¸«å° 30 åæç¤ºé²è¡äº 60 æ¬¡è©ä¼°ãå¨ STI ä¸­ï¼Otiz å¨è¨ºæ·æºç¢ºæ§ï¼4.1-4.7ï¼ãæ´é«æºç¢ºæ§ï¼4.3-4.6ï¼ãè³è¨æ­£ç¢ºæ§ï¼5.0ï¼ãå¯çè§£æ§ï¼4.2-4.4ï¼ååçå¿ï¼4.5-4.8ï¼æ¹é¢å¾åå¾é«ãç¶èï¼ç¸éæ§å¾åè¼ä½ï¼2.9-3.6ï¼ï¼è¡¨ç¤ºæäºåé¤ãé STI çè¨ºæ·å¾åè¼ä½ï¼p=0.038ï¼ãè§å¯èéçä¸è´æ§å¾å¼·ï¼åªæ 12.7% çéå°è©ä¼°ä¸­åºç¾å¤§æ¼ 1 åçå·®ç°ãçµè«ï¼å Otiz éæ¨£ç AI å°è©±ä»£çç¨å¼å¯ä»¥æä¾æºç¢ºãæ­£ç¢ºãé¢æ£ãä¸å¸¶è©å¤ãææ¼åå¾ä¸ææ¼çè§£ç STI ç¸éè³è¨ï¼ä¸¦ä»¥åçå¿çæ¹å¼ï¼æ¸è¼é«çç³»çµ±çè² æã</paragraph>

##### **Multimodal Approaches to Fair Image Classification: An Ethical Perspective**
2412.12165v1 by Javon Hickmon

In the rapidly advancing field of artificial intelligence, machine perception
is becoming paramount to achieving increased performance. Image classification
systems are becoming increasingly integral to various applications, ranging
from medical diagnostics to image generation; however, these systems often
exhibit harmful biases that can lead to unfair and discriminatory outcomes.
Machine Learning systems that depend on a single data modality, i.e. only
images or only text, can exaggerate hidden biases present in the training data,
if the data is not carefully balanced and filtered. Even so, these models can
still harm underrepresented populations when used in improper contexts, such as
when government agencies reinforce racial bias using predictive policing. This
thesis explores the intersection of technology and ethics in the development of
fair image classification models. Specifically, I focus on improving fairness
and methods of using multiple modalities to combat harmful demographic bias.
Integrating multimodal approaches, which combine visual data with additional
modalities such as text and metadata, allows this work to enhance the fairness
and accuracy of image classification systems. The study critically examines
existing biases in image datasets and classification algorithms, proposes
innovative methods for mitigating these biases, and evaluates the ethical
implications of deploying such systems in real-world scenarios. Through
comprehensive experimentation and analysis, the thesis demonstrates how
multimodal techniques can contribute to more equitable and ethical AI
solutions, ultimately advocating for responsible AI practices that prioritize
fairness.

æè¦ï¼å¨å¿«éåå±ç AI é åä¸­ï¼æ©å¨æç¥æ­£æçºæåæè½çééµãå½±ååé¡ç³»çµ±æ­£éæ¼¸æçºåç¨®æç¨ç¨å¼ä¸­ä¸å¯æç¼ºçä¸é¨åï¼å¾é«çè¨ºæ·å°å½±åç¢ççææ¶µèï¼ç¶èï¼éäºç³»çµ±ç¶å¸¸å±ç¾åºæå®³çåè¦ï¼å¯è½å°è´ä¸å¬å¹³ä¸ææ­§è¦æ§ççµæãæ©å¨å­¸ç¿ç³»çµ±ä¾è³´å®ä¸è³æåæï¼ä¾å¦åæå½±åæåææå­ï¼å¯è½æèªå¤§è¨ç·´è³æä¸­é±èçåè¦ï¼å¦æè³ææªç¶éä»ç´°å¹³è¡¡åç¯©é¸çè©±ãå³ä½¿å¦æ­¤ï¼ç¶éäºæ¨¡åç¨æ¼ä¸é©ç¶çæå¢ä¸­æï¼ä¾å¦æ¿åºæ©æ§ä½¿ç¨é æ¸¬è­¦åä¾å å¼·ç¨®æåè¦ï¼ä»ç¶å¯è½å·å®³å°å°æ¸æç¾¤ãæ¬è«ææ¢è¨æè¡èå«çå¨éç¼å¬å¹³å½±ååé¡æ¨¡åä¸­çäº¤éãå·é«ä¾èªªï¼æå°æ³¨æ¼æ¹åå¬å¹³æ§ï¼ä»¥åä½¿ç¨å¤ç¨®åæä¾å°ææå®³çäººå£çµ±è¨åè¦çæ¹æ³ãæ´åå¤æ¨¡ææ¹æ³ï¼å°è¦è¦ºè³æèå¶ä»åæï¼ä¾å¦æå­ååè³æï¼çµåï¼è®éé å·¥ä½å¾ä»¥æåå½±ååé¡ç³»çµ±çå¬å¹³æ§åæºç¢ºæ§ãæ¬ç ç©¶æ¹å¤æ§å°æª¢è¦å½±åè³æéååé¡æ¼ç®æ³ä¸­ç¾æçåè¦ï¼æåºæ¸è¼éäºåè¦çåµæ°æ¹æ³ï¼ä¸¦è©ä¼°å¨ç¾å¯¦ä¸çå ´æ¯ä¸­é¨ç½²æ­¤é¡ç³»çµ±çå«çææ¶µãééå¨é¢çå¯¦é©ååæï¼æ¬è«æå±ç¤ºå¤æ¨¡ææè¡å¦ä½è½ä¿ææ´å¬å¹³ä¸åä¹å«çç AI è§£æ±ºæ¹æ¡ï¼æçµå¡å°ä»¥å¬å¹³æ§çºåªåçè² è²¬ä»» AI å¯¦åã

##### **Euclid: Supercharging Multimodal LLMs with Synthetic High-Fidelity Visual Descriptions**
2412.08737v1 by Jiarui Zhang, Ollie Liu, Tianyu Yu, Jinyi Hu, Willie Neiswanger

Multimodal large language models (MLLMs) have made rapid progress in recent
years, yet continue to struggle with low-level visual perception (LLVP) --
particularly the ability to accurately describe the geometric details of an
image. This capability is crucial for applications in areas such as robotics,
medical image analysis, and manufacturing. In this paper, we first introduce
Geoperception, a benchmark designed to evaluate an MLLM's ability to accurately
transcribe 2D geometric information from an image. Using this benchmark, we
demonstrate the limitations of leading MLLMs, and then conduct a comprehensive
empirical study to explore strategies for improving their performance on
geometric tasks. Our findings highlight the benefits of certain model
architectures, training techniques, and data strategies, including the use of
high-fidelity synthetic data and multi-stage training with a data curriculum.
Notably, we find that a data curriculum enables models to learn challenging
geometry understanding tasks which they fail to learn from scratch. Leveraging
these insights, we develop Euclid, a family of models specifically optimized
for strong low-level geometric perception. Although purely trained on synthetic
multimodal data, Euclid shows strong generalization ability to novel geometry
shapes. For instance, Euclid outperforms the best closed-source model,
Gemini-1.5-Pro, by up to 58.56% on certain Geoperception benchmark tasks and
10.65% on average across all tasks.

æè¦ï¼è¿å¹¾å¹´ï¼å¤æ¨¡æå¤§åèªè¨æ¨¡å (MLLM) è¿éé²å±ï¼ä½ä»æçºèä½éè¦è¦ºæç¥ (LLVP) å¥®æ°ï¼å°¤å¶æ¯æºç¢ºæè¿°å½±åå¹¾ä½ç´°ç¯çè½åãæ­¤åè½å°æ¼æ©å¨äººãé«å­¸å½±ååæåè£½é ç­é åçæç¨è³ééè¦ãå¨æ¬æä¸­ï¼æåé¦åä»ç´¹ Geoperceptionï¼ä¸ååºæºï¼æ¨å¨è©ä¼° MLLM å¾å½±åæºç¢ºè½é 2D å¹¾ä½è³è¨çè½åãä½¿ç¨æ­¤åºæºï¼æåå±ç¤ºäºé å MLLM çéå¶ï¼ç¶å¾é²è¡å¨é¢çå¯¦è­ç ç©¶ï¼æ¢è¨æ¹åå¶å¨å¹¾ä½ä»»åä¸è¡¨ç¾çç­ç¥ãæåçç ç©¶çµæçªåºäºç¹å®æ¨¡åæ¶æ§ãè¨ç·´æè¡åè³æç­ç¥çåªé»ï¼åæ¬ä½¿ç¨é«ä¿çåæè³æåå·æè³æèª²ç¨çå¤éæ®µè¨ç·´ãå¼å¾æ³¨æçæ¯ï¼æåç¼ç¾è³æèª²ç¨è½è®æ¨¡åå­¸ç¿ä»åç¡æ³å¾é ­éå§å­¸ç¿çå·æææ°æ§çå¹¾ä½çè§£ä»»åãå©ç¨éäºè¦è§£ï¼æåéç¼äº Euclidï¼ä¸åå°ééå°å¼·ä½éå¹¾ä½æç¥èæä½³åçæ¨¡åå®¶æãåç®¡ç´ç²¹å¨åæå¤æ¨¡æè³æä¸è¨ç·´ï¼ä½ Euclid å°æ°å¹¾ä½å½¢çå±ç¾åºå¼·å¤§çæ³åè½åãä¾å¦ï¼Euclid å¨æäº Geoperception åºæºä»»åä¸æ¯æä½³éæºæ¨¡å Gemini-1.5-Pro é«åº 58.56%ï¼å¨ææä»»åä¸çå¹³åè¡¨ç¾é«åº 10.65%ã

##### **Assisted morbidity coding: the SISCO.web use case for identifying the main diagnosis in Hospital Discharge Records**
2412.09651v1 by Elena Cardillo, Lucilla Frattura

Coding morbidity data using international standard diagnostic classifications
is increasingly important and still challenging. Clinical coders and physicians
assign codes to patient episodes based on their interpretation of case notes or
electronic patient records. Therefore, accurate coding relies on the legibility
of case notes and the coders' understanding of medical terminology. During the
last ten years, many studies have shown poor reproducibility of clinical
coding, even recently, with the application of Artificial Intelligence-based
models. Given this context, the paper aims to present the SISCO.web approach
designed to support physicians in filling in Hospital Discharge Records with
proper diagnoses and procedures codes using the International Classification of
Diseases (9th and 10th), and, above all, in identifying the main pathological
condition. The web service leverages NLP algorithms, specific coding rules, as
well as ad hoc decision trees to identify the main condition, showing promising
results in providing accurate ICD coding suggestions.

æè¦ï¼ä½¿ç¨åéæ¨æºè¨ºæ·åé¡å°çæè³æé²è¡ç·¨ç¢¼è¶ä¾è¶éè¦ï¼ä½ä»å·æææ°æ§ãè¨åºç·¨ç¢¼å¡åé«å¸«æ ¹æä»åå°çä¾è¨éæé»å­çæ­·çè§£è®ï¼çºæ£èå°±è¨ºææ³åéä»£ç¢¼ãå æ­¤ï¼æºç¢ºç·¨ç¢¼ä¾è³´æ¼çä¾è¨éçå¯è®æ§åç·¨ç¢¼å¡å°é«å­¸è¡èªççè§£ãå¨éå»åå¹´ä¸­ï¼è¨±å¤ç ç©¶è¡¨æè¨åºç·¨ç¢¼çå¯åç¾æ§å¾å·®ï¼å³ä½¿å¨æè¿ï¼äººå·¥æºè½æ¨¡åçæç¨ä¹æ¯å¦æ­¤ãéæ¼éç¨®ææ³ï¼æ¬ææ¨å¨ä»ç´¹ SISCO.web æ¹æ³ï¼è©²æ¹æ³æ¨å¨æ¯æ´é«å¸«ä½¿ç¨åéç¾çåé¡ (ç¬¬ 9 çåç¬¬ 10 ç) å¡«å¯«åºé¢è¨éï¼ä¸¦æ­£ç¢ºè¨ºæ·åç·¨ç¢¼ç¨åºï¼æéè¦çæ¯ï¼æ¾åºä¸»è¦ççççæ³ãç¶²è·¯æåå©ç¨ NLP æ¼ç®æ³ãç¹å®çç·¨ç¢¼è¦åä»¥åç¹å¥æ±ºç­æ¨¹ä¾æ¾åºä¸»è¦çæ³ï¼å¨æä¾æºç¢ºç ICD ç·¨ç¢¼å»ºè­°æ¹é¢é¡¯ç¤ºåºæå¸æççµæã

##### **IRL for Restless Multi-Armed Bandits with Applications in Maternal and Child Health**
2412.08463v1 by Gauri Jain, Pradeep Varakantham, Haifeng Xu, Aparna Taneja, Prashant Doshi, Milind Tambe

Public health practitioners often have the goal of monitoring patients and
maximizing patients' time spent in "favorable" or healthy states while being
constrained to using limited resources. Restless multi-armed bandits (RMAB) are
an effective model to solve this problem as they are helpful to allocate
limited resources among many agents under resource constraints, where patients
behave differently depending on whether they are intervened on or not. However,
RMABs assume the reward function is known. This is unrealistic in many public
health settings because patients face unique challenges and it is impossible
for a human to know who is most deserving of any intervention at such a large
scale. To address this shortcoming, this paper is the first to present the use
of inverse reinforcement learning (IRL) to learn desired rewards for RMABs, and
we demonstrate improved outcomes in a maternal and child health telehealth
program. First we allow public health experts to specify their goals at an
aggregate or population level and propose an algorithm to design expert
trajectories at scale based on those goals. Second, our algorithm WHIRL uses
gradient updates to optimize the objective, allowing for efficient and accurate
learning of RMAB rewards. Third, we compare with existing baselines and
outperform those in terms of run-time and accuracy. Finally, we evaluate and
show the usefulness of WHIRL on thousands on beneficiaries from a real-world
maternal and child health setting in India. We publicly release our code here:
https://github.com/Gjain234/WHIRL.

æè¦ï¼<paragraph>å¬å±è¡çå¾æ¥­äººå¡éå¸¸æç£æ§æ£èåæå¤§åæ£èèæ¼ãæå©ãæå¥åº·çæçæéçç®æ¨ï¼åæåå°æéè³æºçéå¶ãä¸å®åçå¤èå¼·ç (RMAB) æ¯è§£æ±ºæ­¤åé¡çæææ¨¡åï¼å çºå®åæå©æ¼å¨è³æºéå¶ä¸ï¼å¨è¨±å¤ä»£çä¹éåéæéçè³æºï¼å¶ä¸­æ£èçè¡çºåæ±ºæ¼æ¯å¦å°å¶é²è¡å¹²é ãç¶èï¼RMAB åè¨­å·²ç¥åå ±å½æ¸ãéå¨è¨±å¤å¬å±è¡çç°å¢ä¸­æ¯ä¸åå¯¦éçï¼å çºæ£èé¢è¨ç¨ç¹çææ°ï¼èä¸å°æ¼å¦æ­¤å¤§è¦æ¨¡çå¹²é ï¼äººé¡ä¸å¯è½ç¥éèª°æéè¦å¹²é ãçºäºè§£æ±ºéåç¼ºé»ï¼æ¬æé¦æ¬¡æåºä½¿ç¨éåå¼·åå­¸ç¿ (IRL) ä¾å­¸ç¿ RMAB çææåå ±ï¼ä¸¦ä¸æåå¨æ¯å¬°å¥åº·é è·é«çè¨ç«ä¸­å±ç¤ºäºæ¹åççµæãé¦åï¼æååè¨±å¬å±è¡çå°å®¶å¨ç¸½é«æäººå£å±¤ç´æå®ä»åçç®æ¨ï¼ä¸¦æåºä¸åæ¼ç®æ³ä¾æ ¹æéäºç®æ¨å¤§è¦æ¨¡è¨­è¨å°å®¶è»è·¡ãå¶æ¬¡ï¼æåçæ¼ç®æ³ WHIRL ä½¿ç¨æ¢¯åº¦æ´æ°ä¾æä½³åç®æ¨ï¼åè¨±ææä¸æºç¢ºå°å­¸ç¿ RMAB åå ±ãç¬¬ä¸ï¼æåèç¾æçåºæºé²è¡æ¯è¼ï¼ä¸¦å¨å·è¡æéåæºç¢ºæ§æ¹é¢åªæ¼éäºåºæºãæå¾ï¼æåè©ä¼°ä¸¦å±ç¤ºäº WHIRL å¨å°åº¦å¯¦éæ¯å¬°å¥åº·ç°å¢ä¸­å°æ¸åååçèçæç¨æ§ãæåå¨æ­¤å¬éç¼å¸æåçç¨å¼ç¢¼ï¼https://github.com/Gjain234/WHIRLã</paragraph>

##### **Personalized Sleep Staging Leveraging Source-free Unsupervised Domain Adaptation**
2412.12159v1 by Yangxuan Zhou, Sha Zhao, Jiquan Wang, Haiteng Jiang, hijian Li, Benyan Luo, Tao Li, Gang Pan

Sleep staging is crucial for assessing sleep quality and diagnosing related
disorders. Recent deep learning models for automatic sleep staging using
polysomnography often suffer from poor generalization to new subjects because
they are trained and tested on the same labeled datasets, overlooking
individual differences. To tackle this issue, we propose a novel Source-Free
Unsupervised Individual Domain Adaptation (SF-UIDA) framework. This two-step
adaptation scheme allows the model to effectively adjust to new unlabeled
individuals without needing source data, facilitating personalized
customization in clinical settings. Our framework has been applied to three
established sleep staging models and tested on three public datasets, achieving
state-of-the-art performance.

æè¦ï¼ç¡ç åæå°æ¼è©ä¼°ç¡ç åè³ªåè¨ºæ·ç¸éç¾çè³ééè¦ãæè¿ä½¿ç¨å¤éççç¡ç æª¢æ¥çèªåç¡ç åææ·±åº¦å­¸ç¿æ¨¡åï¼ç±æ¼å¨åä¸åæ¨ç±¤è³æéä¸è¨ç·´åæ¸¬è©¦ï¼å æ­¤ç¶å¸¸æåºç¾ç¡æ³å»£æ³éç¨å°æ°åè©¦èçåé¡ï¼å¿½ç¥äºåé«å·®ç°ãçºäºè§£æ±ºéååé¡ï¼æåæåºäºä¸åæ°ç©çç¡ç£ç£åé«é åé©æ (SF-UIDA) æ¡æ¶ï¼éç¨®å©æ­¥é©é©ææ©å¶åè¨±æ¨¡åææå°èª¿æ´å°æ°çæªæ¨ç±¤åé«ï¼èä¸éè¦åå§è³æï¼æå©æ¼å¨è¨åºç°å¢ä¸­é²è¡åäººåå®¢è£½åãæåçæ¡æ¶å·²æç¨æ¼ä¸åæ¢å®çç¡ç åææ¨¡åï¼ä¸¦å¨ä¸åå¬éè³æéä¸é²è¡æ¸¬è©¦ï¼éå°äºæåé²çæè½ã

##### **SmolTulu: Higher Learning Rate to Batch Size Ratios Can Lead to Better Reasoning in SLMs**
2412.08347v1 by Sultan Alrashed

We present SmolTulu-1.7b-Instruct, referenced in this report as
SmolTulu-DPO-1130, an instruction-tuned language model that adapts AllenAI's
Tulu 3 post-training pipeline to enhance Huggingface's SmolLM2-1.7B base model.
Through comprehensive empirical analysis using a 135M parameter model, we
demonstrate that the relationship between learning rate and batch size
significantly impacts model performance in a task-dependent manner. Our
findings reveal a clear split: reasoning tasks like ARC and GSM8K benefit from
higher learning rate to batch size ratios, while pattern recognition tasks such
as HellaSwag and IFEval show optimal performance with lower ratios. These
insights informed the development of SmolTulu, which achieves state-of-the-art
performance among sub-2B parameter models on instruction following, scoring
67.7% on IFEval ($\Delta$11%), and mathematical reasoning with 51.6% on GSM8K
($\Delta$3.4%), with an alternate version achieving scoring 57.1% on ARC
($\Delta5.4%$). We release our model, training recipes, and ablation studies to
facilitate further research in efficient model alignment, demonstrating that
careful adaptation of optimization dynamics can help bridge the capability gap
between small and large language models.

æè¦ï¼æåæåº SmolTulu-1.7b-Instructï¼æ¬å ±åä¸­ç¨±çº SmolTulu-DPO-1130ï¼éæ¯ä¸ç¨®æä»¤èª¿æ´èªè¨æ¨¡åï¼æ¡ç¨ AllenAI ç Tulu 3 å¾è¨ç·´ç®¡éä¾å¢å¼· Huggingface ç SmolLM2-1.7B åºç¤æ¨¡åãééä½¿ç¨ 135M åæ¸æ¨¡åçå¨é¢ç¶é©åæï¼æåè­æå­¸ç¿çèæ¹æ¬¡å¤§å°ä¹éçéä¿æä»¥ä»»åç¸éçæ¹å¼é¡¯èå½±é¿æ¨¡åæè½ãæåçç¼ç¾æ­ç¤ºäºä¸åæç¢ºçåæ­§ï¼å ARC å GSM8K ç­æ¨çä»»ååçæ¼è¼é«çå­¸ç¿çå°æ¹æ¬¡å¤§å°çæ¯çï¼èå HellaSwag å IFEval ç­æ¨¡å¼è¾¨è­ä»»ååé¡¯ç¤ºåºè¼ä½æ¯ççæä½³æè½ãéäºè¦è§£çº SmolTulu çéç¼æä¾äºè³è¨ï¼å¨å°æ¼ 2B åæ¸æ¨¡åä¸­ï¼å¨æä»¤éµå¾ªæ¹é¢åå¾äºæåé²çè¡¨ç¾ï¼å¨ IFEval ä¸å¾å 67.7%ï¼Î11%ï¼ï¼å¨ GSM8K ä¸çæ¸å­¸æ¨çå¾åçº 51.6%ï¼Î3.4%ï¼ï¼èå¦ä¸åçæ¬å¨ ARC ä¸å¾å 57.1%ï¼Î5.4%ï¼ãæåç¼å¸æåçæ¨¡åãè¨ç·´ç¯ä¾åæ¶èç ç©¶ï¼ä»¥ä¿é²é«ææ¨¡åå°é½çé²ä¸æ­¥ç ç©¶ï¼è­æä»ç´°èª¿æ´æä½³ååæå¯ä»¥å¹«å©ç¸®å°å°ååå¤§åèªè¨æ¨¡åä¹éçè½åå·®è·ã

##### **Novel 3D Binary Indexed Tree for Volume Computation of 3D Reconstructed Models from Volumetric Data**
2412.10441v1 by Quoc-Bao Nguyen-Le, Tuan-Hy Le, Anh-Triet Do

In the burgeoning field of medical imaging, precise computation of 3D volume
holds a significant importance for subsequent qualitative analysis of 3D
reconstructed objects. Combining multivariate calculus, marching cube
algorithm, and binary indexed tree data structure, we developed an algorithm
for efficient computation of intrinsic volume of any volumetric data recovered
from computed tomography (CT) or magnetic resonance (MR). We proposed the 30
configurations of volume values based on the polygonal mesh generation method.
Our algorithm processes the data in scan-line order simultaneously with
reconstruction algorithm to create a Fenwick tree, ensuring query time much
faster and assisting users' edition of slicing or transforming model. We tested
the algorithm's accuracy on simple 3D objects (e.g., sphere, cylinder) to
complicated structures (e.g., lungs, cardiac chambers). The result deviated
within $\pm 0.004 \text{cm}^3$ and there is still room for further improvement.

æè¦ï¼å¨è¬åç¼å±çé«å­¸å½±åé åä¸­ï¼3D é«ç©çç²¾ç¢ºè¨ç®å°æ¼å¾çº 3D éå»ºç©é«çå®æ§åæå·æéè¦æç¾©ãçµåå¤åå¾®ç©åãè¡é²ç«æ¹é«æ¼ç®æ³åäºåç´¢å¼æ¨¹è³æçµæ§ï¼æåéç¼äºä¸ç¨®æ¼ç®æ³ï¼ç¨æ¼ææè¨ç®å¾é»è¦æ·å±¤ææ (CT) æç£æ¯é å½± (MR) ä¸­æ¢å¾©çä»»ä½é«ç©è³æçå§å¨é«ç©ãæåæ ¹æå¤éå½¢ç¶²æ ¼çææ¹æ³æåºäº 30 ç¨®é«ç©å¼çéç½®ãæåçæ¼ç®æ³èéå»ºæ¼ç®æ³åæä»¥ææç·é åºèçè³æï¼ä»¥å»ºç«è¬å¨åæ¨¹ï¼ç¢ºä¿æ¥è©¢æéæ´å¿«ï¼ä¸¦åå©ä½¿ç¨èç·¨è¼¯åçæè½ææ¨¡åãæåå¨ç°¡å®ç 3D ç©é«ï¼ä¾å¦çé«ãåæ±é«ï¼ä¸æ¸¬è©¦äºæ¼ç®æ³çæºç¢ºæ§ï¼ä¸¦å°è¤éççµæ§ï¼ä¾å¦èºãå¿èï¼é²è¡äºæ¸¬è©¦ãçµæåé¢å¨ $\pm 0.004 \text{cm}^3$ å§ï¼ä¸¦ä¸ä»æé²ä¸æ­¥æ¹é²çç©ºéã

##### **Hierarchical Classification for Automated Image Annotation of Coral Reef Benthic Structures**
2412.08228v1 by CÃ©lia Blondin, Joris GuÃ©rin, Kelly Inagaki, Guilherme Longo, Laure Berti-Ãquille

Automated benthic image annotation is crucial to efficiently monitor and
protect coral reefs against climate change. Current machine learning approaches
fail to capture the hierarchical nature of benthic organisms covering reef
substrata, i.e., coral taxonomic levels and health condition. To address this
limitation, we propose to annotate benthic images using hierarchical
classification. Experiments on a custom dataset from a Northeast Brazilian
coral reef show that our approach outperforms flat classifiers, improving both
F1 and hierarchical F1 scores by approximately 2\% across varying amounts of
training data. In addition, this hierarchical method aligns more closely with
ecological objectives.

æè¦ï¼èªåååºæ£²å½±åè¨»è§£å°æ¼ææç£æ¸¬åä¿è­·ççç¤ååæ°£åè®é·å½±é¿è³ééè¦ãç®åçæ©å¨å­¸ç¿æ¹æ³ç¡æ³ææè¦èç¤ç³åºè³ªçåºæ£²çç©çéå±¤æ§è³ªï¼ä¾å¦ççåé¡ç­ç´åå¥åº·çæ³ãçºäºè§£æ±ºæ­¤éå¶ï¼æåå»ºè­°ä½¿ç¨éå±¤åé¡è¨»è§£åºæ£²å½±åãå°ä¾èªå·´è¥¿æ±åé¨ççç¤çèªè¨è³æéé²è¡çå¯¦é©é¡¯ç¤ºï¼æåçåæ³åªæ¼å¹³é¢åé¡å¨ï¼å¨ä¸åæ¸éçè¨ç·´è³æä¸­å° F1 åéå±¤ F1 åæ¸é½æé«äºå¤§ç´ 2%ãæ­¤å¤ï¼éç¨®éå±¤å¼æ¹æ³èçæç®æ¨æ´çºä¸è´ã

##### **How to select slices for annotation to train best-performing deep learning segmentation models for cross-sectional medical images?**
2412.08081v1 by Yixin Zhang, Kevin Kramer, Maciej A. Mazurowski

Automated segmentation of medical images highly depends on the availability
of accurate manual image annotations. Such annotations are very time-consuming
and costly to generate, and often require specialized expertise, particularly
for cross-sectional images which contain many slices for each patient. It is
crucial to ensure the best use of annotation resources. In this paper, we
systematically answer the question of how to select slices of cross-sectional
medical images in order to maximize performance of the resulting deep learning
segmentation models. We conducted experiments on 4 medical imaging segmentation
tasks with varying annotation budgets, numbers of annotated cases, numbers of
annotated slices per volume, slice selection techniques, and mask
interpolations. We found that:
  1) It is almost always preferable to annotate fewer slices per volume and
more volumes given an annotation budget. 2) Selecting slices for annotation by
unsupervised active learning (UAL) is not superior to selecting slices randomly
or at fixed intervals, provided that each volume is allocated the same number
of annotated slices. 3) Interpolating masks between annotated slices rarely
enhances model performance, with exceptions of some specific configuration for
3D models.

æè¦ï¼é«å­¸å½±åçèªåååå²é«åº¦ä¾è³´æ¼æºç¢ºçæåå½±åæ¨è¨»ãæ­¤é¡æ¨è¨»éå¸¸èæä¸çæææ¬é«æï¼ä¸éå¸¸éè¦å°æ¥­ç¥è­ï¼ç¹å¥æ¯å°æ¼æ¯åæ£èåå«è¨±å¤åççæ©«æ·é¢å½±åãç¢ºä¿æä½³å©ç¨æ¨è¨»è³æºè³ééè¦ãå¨æ¬æä¸­ï¼æåç³»çµ±æ§å°åç­äºå¦ä½é¸ææ©«æ·é¢é«å­¸å½±ååçä»¥æå¤§åæ·±åº¦å­¸ç¿åå²æ¨¡åæè½çåé¡ãæåéå° 4 é é«å­¸å½±ååå²ä»»åé²è¡äºå¯¦é©ï¼éäºä»»åå·æä¸åçæ¨è¨»é ç®ãæ¨è¨»æ¡ä¾æ¸ãæ¯åé«ç©çæ¨è¨»åçæ¸ãåçé¸ææè¡åé®ç½©å§æãæåç¼ç¾ï¼
1) å¨çµ¦å®æ¨è¨»é ç®çææ³ä¸ï¼å¹¾ä¹ç¸½æ¯åªåæ¨è¨»æ¯åé«ç©è¼å°åçåæ´å¤é«ç©ã2) éééç£ç£ä¸»åå­¸ç¿ (UAL) é¸æåçé²è¡æ¨è¨»ä¸¦ä¸åªæ¼é¨æ©æåºå®ééé¸æåçï¼åææ¯æ¯åé«ç©åéçæ¨è¨»åçæ¸ç¸åã3) å¨æ¨è¨»åçä¹éå§æé®ç½©å¾å°è½æåæ¨¡åæè½ï¼ä½æäº 3D æ¨¡åçç¹å®çµæé¤å¤ã

##### **Can a MISL Fly? Analysis and Ingredients for Mutual Information Skill Learning**
2412.08021v1 by Chongyi Zheng, Jens Tuyls, Joanne Peng, Benjamin Eysenbach

Self-supervised learning has the potential of lifting several of the key
challenges in reinforcement learning today, such as exploration, representation
learning, and reward design. Recent work (METRA) has effectively argued that
moving away from mutual information and instead optimizing a certain
Wasserstein distance is important for good performance. In this paper, we argue
that the benefits seen in that paper can largely be explained within the
existing framework of mutual information skill learning (MISL). Our analysis
suggests a new MISL method (contrastive successor features) that retains the
excellent performance of METRA with fewer moving parts, and highlights
connections between skill learning, contrastive representation learning, and
successor features. Finally, through careful ablation studies, we provide
further insight into some of the key ingredients for both our method and METRA.

æè¦ï¼èªæç£ç£å­¸ç¿ææ½åè§£æ±ºç¶ä»å¼·åå­¸ç¿ä¸­çå¹¾åééµææ°ï¼ä¾å¦æ¢ç´¢ãè¡¨å¾µå­¸ç¿åçåµè¨­è¨ãæè¿çç ç©¶ï¼METRAï¼ææå°è«è­äºé é¢äºä¿¡æ¯ä¸¦æ¹çºåªåæå Wasserstein è·é¢å°æ¼è¯å¥½çæ§è½å¾éè¦ãå¨æ¬æä¸­ï¼æåè«è­è©²è«æä¸­çå°çåªé»å¯ä»¥å¨äºä¿¡æ¯æè½å­¸ç¿ï¼MISLï¼çç¾ææ¡æ¶å§å¾å°å¾å¤§ç¨åº¦çè§£éãæåçåææåºäºä¸ç¨®æ°ç MISL æ¹æ³ï¼å°æ¯å¾ç¹¼ç¹å¾µï¼ï¼å®ä¿çäº METRA çåºè²æ§è½ï¼åææ¸å°äºæ´»åé¨ä»¶ï¼ä¸¦çªåºäºæè½å­¸ç¿ãå°æ¯è¡¨å¾µå­¸ç¿åå¾ç¹¼ç¹å¾µä¹éçè¯ç¹«ãæå¾ï¼ééä»ç´°çæ¶èç ç©¶ï¼æåé²ä¸æ­¥æ·±å¥äºè§£äºæåçæ¹æ³å METRA çä¸äºééµè¦ç´ ã

##### **From Lived Experience to Insight: Unpacking the Psychological Risks of Using AI Conversational Agents**
2412.07951v2 by Mohit Chandra, Suchismita Naik, Denae Ford, Ebele Okoli, Munmun De Choudhury, Mahsa Ershadi, Gonzalo Ramos, Javier Hernandez, Ananya Bhattacharjee, Shahed Warreth, Jina Suh

Recent gain in popularity of AI conversational agents has led to their
increased use for improving productivity and supporting well-being. While
previous research has aimed to understand the risks associated with
interactions with AI conversational agents, these studies often fall short in
capturing the lived experiences. Additionally, psychological risks have often
been presented as a sub-category within broader AI-related risks in past
taxonomy works, leading to under-representation of the impact of psychological
risks of AI use. To address these challenges, our work presents a novel risk
taxonomy focusing on psychological risks of using AI gathered through lived
experience of individuals. We employed a mixed-method approach, involving a
comprehensive survey with 283 individuals with lived mental health experience
and workshops involving lived experience experts to develop a psychological
risk taxonomy. Our taxonomy features 19 AI behaviors, 21 negative psychological
impacts, and 15 contexts related to individuals. Additionally, we propose a
novel multi-path vignette based framework for understanding the complex
interplay between AI behaviors, psychological impacts, and individual user
contexts. Finally, based on the feedback obtained from the workshop sessions,
we present design recommendations for developing safer and more robust AI
agents. Our work offers an in-depth understanding of the psychological risks
associated with AI conversational agents and provides actionable
recommendations for policymakers, researchers, and developers.

æè¦ï¼è¿æ AI å°è©±ä»£ççæ®åæåï¼å°è´å¶å¨æåçç¢ååæ¯æå¹¸ç¦ææ¹é¢çæç¨æ¥çå¢å ãéç¶ååçç ç©¶æ¨å¨äºè§£è AI å°è©±ä»£çäºåç¸éçé¢¨éªï¼ä½éäºç ç©¶å¾å¾ç¡æ³ææå°çæ´»é«é©ãæ­¤å¤ï¼å¨éå»çåé¡å·¥ä½ä¸­ï¼å¿çé¢¨éªéå¸¸è¢«è¦çºæ´å»£æ³ç AI ç¸éé¢¨éªä¸­çå­é¡å¥ï¼å°è´ AI ä½¿ç¨å¿çé¢¨éªçå½±é¿è¢«ä½ä¼°ãçºäºæå°éäºææ°ï¼æåçç ç©¶æåºäºæ°ç©çé¢¨éªåé¡æ³ï¼éé»éæ³¨ééåäººçæ´»ç¶é©æ¶éç AI ä½¿ç¨å¿çé¢¨éªãæåæ¡ç¨æ··åæ¹æ³ï¼åæ¬å° 283 ä½å·æçæ´»å¿çå¥åº·ç¶é©çåäººé²è¡å¨é¢èª¿æ¥ï¼ä»¥åèçæ´»ç¶é©å°å®¶åä½çç è¨æï¼ä»¥å¶å®å¿çé¢¨éªåé¡æ³ãæåçåé¡æ³åå« 19 ç¨® AI è¡çºã21 ç¨®è² é¢å¿çå½±é¿å 15 ç¨®èåäººç¸éçèæ¯ãæ­¤å¤ï¼æåæåºäºä¸åæ°ç©çå¤è·¯å¾å°æåæ¡æ¶ï¼ç¨æ¼äºè§£ AI è¡çºãå¿çå½±é¿ååäººä½¿ç¨èèæ¯ä¹éçè¤éäº¤äºä½ç¨ãæå¾ï¼æ ¹æå¾ç è¨æä¸­ç²å¾çåé¥ï¼æåæåºäºè¨­è¨å»ºè­°ï¼ä»¥éç¼æ´å®å¨ãæ´å¼·å¤§ç AI ä»£çãæåçç ç©¶æ·±å¥äºè§£äºè AI å°è©±ä»£çç¸éçå¿çé¢¨éªï¼ä¸¦çºæ¿ç­å¶å®èãç ç©¶äººå¡åéç¼äººå¡æä¾äºå¯è¡çå»ºè­°ã

##### **How Should We Represent History in Interpretable Models of Clinical Policies?**
2412.07895v1 by Anton Matsson, Lena Stempfle, Yaochen Rao, Zachary R. Margolin, Heather J. Litman, Fredrik D. Johansson

Modeling policies for sequential clinical decision-making based on
observational data is useful for describing treatment practices, standardizing
frequent patterns in treatment, and evaluating alternative policies. For each
task, it is essential that the policy model is interpretable. Learning accurate
models requires effectively capturing the state of a patient, either through
sequence representation learning or carefully crafted summaries of their
medical history. While recent work has favored the former, it remains a
question as to how histories should best be represented for interpretable
policy modeling. Focused on model fit, we systematically compare diverse
approaches to summarizing patient history for interpretable modeling of
clinical policies across four sequential decision-making tasks. We illustrate
differences in the policies learned using various representations by breaking
down evaluations by patient subgroups, critical states, and stages of
treatment, highlighting challenges specific to common use cases. We find that
interpretable sequence models using learned representations perform on par with
black-box models across all tasks. Interpretable models using hand-crafted
representations perform substantially worse when ignoring history entirely, but
are made competitive by incorporating only a few aggregated and recent elements
of patient history. The added benefits of using a richer representation are
pronounced for subgroups and in specific use cases. This underscores the
importance of evaluating policy models in the context of their intended use.

æè¦ï¼åºæ¼è§å¯è³æå°åºè²«è¨åºæ±ºç­å¶å®å»ºæ¨¡æ¿ç­ï¼æå©æ¼æè¿°æ²»çå¯¦åãæ¨æºåæ²»çä¸­çå¸¸è¦æ¨¡å¼ï¼ä»¥åè©ä¼°æ¿ä»£æ¿ç­ãå°æ¼æ¯é ä»»åï¼æ¿ç­æ¨¡åçå¯è§£éæ§è³ééè¦ãå­¸ç¿ç²¾ç¢ºçæ¨¡åéè¦æææ·åæ£èççæï¼ç¡è«æ¯ééåºåè¡¨å¾µå­¸ç¿æç²¾å¿è£½ä½ççå²æè¦ãéç¶è¿æç ç©¶åå¥½åèï¼ä½å¦ä½ä»¥æä½³æ¹å¼è¡¨å¾µçå²ä»¥é²è¡å¯è§£éçæ¿ç­å»ºæ¨¡ï¼ä»æ¯ä¸ååé¡ãæåå°æ³¨æ¼æ¨¡åæ¬ååº¦ï¼ç³»çµ±æ§å°æ¯è¼åç¨®æè¦æ£èçå²çæ¹æ³ï¼ä»¥éå°åé åºè²«æ±ºç­å¶å®ä»»åé²è¡å¯è§£éçè¨åºæ¿ç­å»ºæ¨¡ãæåééææ£èå­ç¾¤ãå±æ¥çæåæ²»çéæ®µç´°åè©ä¼°ï¼ä¾èªªæä½¿ç¨åç¨®è¡¨å¾µæå­¸ç¿å°çæ¿ç­ä¹éçå·®ç°ï¼ä¸¦å¼·èª¿ç¹å®æ¼å¸¸è¦ä½¿ç¨æ¡ä¾çææ°ãæåç¼ç¾ï¼ä½¿ç¨å­¸ç¿è¡¨å¾µçå¯è§£éåºåæ¨¡åå¨ææä»»åä¸­è¡¨ç¾èé»ç®±æ¨¡åä¸ç¸ä¸ä¸ãä½¿ç¨æå·¥è£½ä½è¡¨å¾µçå¯è§£éæ¨¡åå¨å®å¨å¿½ç¥çå²æè¡¨ç¾æé¡¯è¼å·®ï¼ä½ééåç´å¥å°æ¸æ£èçå²çå½æ´åè¿æåç´ ï¼ä¾¿è½ä½¿å¶å·æç«¶ç­åãä½¿ç¨æ´è±å¯è¡¨å¾µçé¡å¤å¥½èå¨å­ç¾¤åç¹å®ä½¿ç¨æ¡ä¾ä¸­é¡¯èãéå¼·èª¿äºå¨é æç¨éçèçµ¡ä¸­è©ä¼°æ¿ç­æ¨¡åçéè¦æ§ã

##### **Towards Foundation-model-based Multiagent System to Accelerate AI for Social Impact**
2412.07880v2 by Yunfan Zhao, Niclas Boehmer, Aparna Taneja, Milind Tambe

AI for social impact (AI4SI) offers significant potential for addressing
complex societal challenges in areas such as public health, agriculture,
education, conservation, and public safety. However, existing AI4SI research is
often labor-intensive and resource-demanding, limiting its accessibility and
scalability; the standard approach is to design a (base-level) system tailored
to a specific AI4SI problem. We propose the development of a novel meta-level
multi-agent system designed to accelerate the development of such base-level
systems, thereby reducing the computational cost and the burden on social
impact domain experts and AI researchers. Leveraging advancements in foundation
models and large language models, our proposed approach focuses on resource
allocation problems providing help across the full AI4SI pipeline from problem
formulation over solution design to impact evaluation. We highlight the ethical
considerations and challenges inherent in deploying such systems and emphasize
the importance of a human-in-the-loop approach to ensure the responsible and
effective application of AI systems.

æè¦ï¼äººå·¥æºæ§å°ç¤¾æå½±é¿ï¼AI4SIï¼æä¾äºå·¨å¤§çæ½åï¼ç¨æ¼è§£æ±ºè¤éçç¤¾æææ°ï¼ä¾å¦å¬å±è¡çãè¾²æ¥­ãæè²ãä¿è²åå¬å±å®å¨ãç¶èï¼ç¾æç AI4SI ç ç©¶éå¸¸éè¦å¤§éäººååè³æºï¼ééå¶äºå¶å¯åæ§åå¯æ´å±æ§ï¼æ¨æºæ¹æ³æ¯è¨­è¨ä¸åéå°ç¹å® AI4SI åé¡éèº«æé çï¼åºç¤å±¤ç´ï¼ç³»çµ±ãæåå»ºè­°éç¼ä¸åæ°ç©çåå±¤ç´å¤ä»£çç³»çµ±ï¼æ¨å¨å éæ­¤é¡åºç¤å±¤ç´ç³»çµ±çéç¼ï¼å¾èéä½éç®ææ¬åç¤¾æå½±é¿é åå°å®¶è AI ç ç©¶äººå¡çè² æãéééç¨åºç¤æ¨¡ååå¤§åèªè¨æ¨¡åçé²å±ï¼æåå»ºè­°çæ¹æ³å°æ³¨æ¼è³æºéç½®åé¡ï¼æä¾å¾åé¡å»ºæ§ãè§£æ±ºæ¹æ¡è¨­è¨å°å½±é¿è©ä¼°çå®æ´ AI4SI ç®¡ç·çåå©ãæåå¼·èª¿é¨ç½²æ­¤é¡ç³»çµ±æåºæçéå¾·èéåææ°ï¼ä¸¦å¼·èª¿äººæ©åä½æ¹æ³çéè¦æ§ï¼ä»¥ç¢ºä¿è² è²¬ä»»ä¸ææå°æç¨ AI ç³»çµ±ã

##### **Comparative Analysis of Deep Learning Approaches for Harmful Brain Activity Detection Using EEG**
2412.07878v1 by Shivraj Singh Bhatti, Aryan Yadav, Mitali Monga, Neeraj Kumar

The classification of harmful brain activities, such as seizures and periodic
discharges, play a vital role in neurocritical care, enabling timely diagnosis
and intervention. Electroencephalography (EEG) provides a non-invasive method
for monitoring brain activity, but the manual interpretation of EEG signals are
time-consuming and rely heavily on expert judgment. This study presents a
comparative analysis of deep learning architectures, including Convolutional
Neural Networks (CNNs), Vision Transformers (ViTs), and EEGNet, applied to the
classification of harmful brain activities using both raw EEG data and
time-frequency representations generated through Continuous Wavelet Transform
(CWT). We evaluate the performance of these models use multimodal data
representations, including high-resolution spectrograms and waveform data, and
introduce a multi-stage training strategy to improve model robustness. Our
results show that training strategies, data preprocessing, and augmentation
techniques are as critical to model success as architecture choice, with
multi-stage TinyViT and EfficientNet demonstrating superior performance. The
findings underscore the importance of robust training regimes in achieving
accurate and efficient EEG classification, providing valuable insights for
deploying AI models in clinical practice.

æè¦ï¼æå®³è¦é¨æ´»åçåé¡ï¼ä¾å¦ç²çç¼ä½åé±ææ§æ¾é»ï¼å¨ç¥ç¶éçç§è­·ä¸­æ®æ¼èè³ééè¦çè§è²ï¼è½åæè¨ºæ·åä»å¥ãè¦é»å (EEG) æä¾äºä¸ç¨®éä¾µå¥å¼çæ¹æ³ä¾ç£æ¸¬è¦é¨æ´»åï¼ä½ EEG è¨èçæåå¤è®èæä¸é«åº¦ä¾è³´å°å®¶çå¤æ·ãæ¬ç ç©¶éå°æ·±åº¦å­¸ç¿æ¶æ§é²è¡æ¯è¼åæï¼åæ¬å·ç©ç¥ç¶ç¶²è·¯ (CNN)ãè¦è¦ºTransformer (ViT) å EEGNetï¼éç¨æ¼æå®³è¦é¨æ´»åçåé¡ï¼åæä½¿ç¨åå§ EEG è³æåééé£çºå°æ³¢è½æ (CWT) çæçæé »è¡¨ç¤ºãæåè©ä¼°éäºæ¨¡åä½¿ç¨å¤æ¨¡å¼è³æè¡¨ç¤ºçæè½ï¼åæ¬é«è§£æåº¦é »è­ååæ³¢å½¢è³æï¼ä¸¦å¼å¥å¤éæ®µè¨ç·´ç­ç¥ä¾æ¹åæ¨¡åçç©©å¥æ§ãæåççµæé¡¯ç¤ºï¼è¨ç·´ç­ç¥ãè³æåèçåæ´åæè¡å°æ¼æ¨¡åçæåèæ¶æ§é¸æä¸æ¨£éè¦ï¼å¶ä¸­å¤éæ®µ TinyViT å EfficientNet è¡¨ç¾åºåªç°çæè½ãéäºç¼ç¾å¼·èª¿äºç©©å¥è¨ç·´æ©å¶å°æ¼éææºç¢ºä¸ææçç EEG åé¡çéè¦æ§ï¼çºå¨è¨åºå¯¦åä¸­é¨ç½² AI æ¨¡åæä¾äºå¯¶è²´çè¦è§£ã

##### **Combining knowledge graphs and LLMs for hazardous chemical information management and reuse**
2412.09644v1 by Marcos Da Silveira, Louis Deladiennee, Kheira Acem, Oona Freudenthal

Human health is increasingly threatened by exposure to hazardous substances,
particularly persistent and toxic chemicals. The link between these substances,
often encountered in complex mixtures, and various diseases are demonstrated in
scientific studies. However, this information is scattered across several
sources and hardly accessible by humans and machines. This paper evaluates
current practices for publishing/accessing information on hazardous chemicals
and proposes a novel platform designed to facilitate retrieval of critical
chemical data in urgent situations. The platform aggregates information from
multiple sources and organizes it into a structured knowledge graph. Users can
access this information through a visual interface such as Neo4J Bloom and
dashboards, or via natural language queries using a Chatbot. Our findings
demonstrate a significant reduction in the time and effort required to access
vital chemical information when datasets follow FAIR principles. Furthermore,
we discuss the lessons learned from the development and implementation of this
platform and provide recommendations for data owners and publishers to enhance
data reuse and interoperability. This work aims to improve the accessibility
and usability of chemical information by healthcare professionals, thereby
supporting better health outcomes and informed decision-making in the face of
patients exposed to chemical intoxication risks.

æè¦ï¼äººé¡å¥åº·è¶ä¾è¶åå°æ¥è§¸æå®³ç©è³ªçå¨èï¼å°¤å¶æ¯æä¹æ§åææ¯çåå­¸ç©è³ªãç§å­¸ç ç©¶å·²è­æéäºç©è³ªï¼éå¸¸å­å¨æ¼è¤éçæ··åç©ä¸­ï¼èåç¨®ç¾çä¹éçéè¯ãç¶èï¼éäºè³è¨åæ£å¨å¤åä¾æºä¸­ï¼äººé¡åæ©å¨é½å¾é£åå¾ãæ¬æè©ä¼°äºç¶åç¼å¸/åå¾æéæå®³åå­¸ç©è³ªè³è¨çæ£ä¾ï¼ä¸¦æåºä¸åæ°ç©çå¹³å°ï¼æ¨å¨ä¿é²å¨ç·æ¥ææ³ä¸åå¾ééµåå­¸è³æãæ­¤å¹³å°å¯éä¾èªå¤åä¾æºçè³è¨ï¼ä¸¦å°å¶çµç¹æçµæ§åçç¥è­åè­ãä½¿ç¨èå¯ä»¥ééè¦è¦ºåä»é¢ï¼ä¾å¦ Neo4J Bloom ååè¡¨æ¿ï¼æä½¿ç¨èå¤©æ©å¨äººçèªç¶èªè¨æ¥è©¢ä¾åå¾éäºè³è¨ãæåçç ç©¶çµæè¡¨æï¼ç¶è³æééµå¾ª FAIR ååæï¼åå¾éè¦åå­¸è³è¨æéçæéåç²¾åæå¤§å¹æ¸å°ãæ­¤å¤ï¼æåè¨è«å¾æ­¤å¹³å°çéç¼åå¯¦ä½ä¸­å­¸å°çç¶é©æè¨ï¼ä¸¦çºè³æææèåç¼å¸èæä¾å»ºè­°ï¼ä»¥å¢å¼·è³æåå©ç¨åäºæä½æ§ãéé å·¥ä½æ¨å¨æ¹åé«çä¿å¥å°æ¥­äººå¡åå¾åä½¿ç¨åå­¸è³è¨çæ¹å¼ï¼å¾èæ¯ææ´å¥½çå¥åº·çµæï¼ä¸¦å¨é¢å°æ¥è§¸åå­¸ä¸­æ¯é¢¨éªçæ£èæååºææºçæ±ºç­ã

##### **Adapting to Non-Stationary Environments: Multi-Armed Bandit Enhanced Retrieval-Augmented Generation on Knowledge Graphs**
2412.07618v1 by Xiaqiang Tang, Jian Li, Nan Du, Sihong Xie

Despite the superior performance of Large language models on many NLP tasks,
they still face significant limitations in memorizing extensive world
knowledge. Recent studies have demonstrated that leveraging the
Retrieval-Augmented Generation (RAG) framework, combined with Knowledge Graphs
that encapsulate extensive factual data in a structured format, robustly
enhances the reasoning capabilities of LLMs. However, deploying such systems in
real-world scenarios presents challenges: the continuous evolution of
non-stationary environments may lead to performance degradation and user
satisfaction requires a careful balance of performance and responsiveness. To
address these challenges, we introduce a Multi-objective Multi-Armed Bandit
enhanced RAG framework, supported by multiple retrieval methods with diverse
capabilities under rich and evolving retrieval contexts in practice. Within
this framework, each retrieval method is treated as a distinct ``arm''. The
system utilizes real-time user feedback to adapt to dynamic environments, by
selecting the appropriate retrieval method based on input queries and the
historical multi-objective performance of each arm. Extensive experiments
conducted on two benchmark KGQA datasets demonstrate that our method
significantly outperforms baseline methods in non-stationary settings while
achieving state-of-the-art performance in stationary environments. Code and
data are available at https://github.com/FUTUREEEEEE/Dynamic-RAG.git

æè¦ï¼åç®¡å¤§åèªè¨æ¨¡åå¨è¨±å¤ NLP ä»»åä¸è¡¨ç¾åªç°ï¼
å®åå¨è¨æ¶å»£æ³çä¸çç¥è­æ¹é¢ä»é¢è¨éå¤§éå¶ãæè¿çç ç©¶è¡¨æï¼
å©ç¨æª¢ç´¢å¢å¼·çæ (RAG) æ¡æ¶ï¼çµåä»¥çµæ§åæ ¼å¼å°è£å»£æ³äºå¯¦è³æçç¥è­åè­ï¼
è½ç©©å¥å°å¢å¼· LLM çæ¨çè½åãç¶èï¼å¨ç¾å¯¦ä¸çå ´æ¯ä¸­é¨ç½²æ­¤é¡ç³»çµ±æç¢çææ°ï¼
éå¹³ç©©ç°å¢çæçºæ¼è®å¯è½å°è´æè½ä¸éï¼èä½¿ç¨èçæ»¿æåº¦éè¦å¨æè½ååææ§ä¹éåå¾ä»ç´°çå¹³è¡¡ã
çºäºæå°éäºææ°ï¼æåå¼å¥äºå¤ç®æ¨å¤èèèæ©å¢å¼·ç RAG æ¡æ¶ï¼
ä¸¦å¨å¯¦åä¸­æ¡ç¨å·åå¤åè½åçåç¨®æª¢ç´¢æ¹æ³ï¼ä»¥æå°è±å¯ä¸ä¸æ·æ¼è®çæª¢ç´¢æå¢ã
å¨æ­¤æ¡æ¶ä¸­ï¼æ¯åæª¢ç´¢æ¹æ³é½è¢«è¦çºä¸åä¸åçãæèãã
è©²ç³»çµ±å©ç¨å³æä½¿ç¨èåé¥ä¾é©æåæç°å¢ï¼
æ ¹æè¼¸å¥æ¥è©¢åæ¯åæèçæ­·å²å¤ç®æ¨æè½ä¾é¸æé©ç¶çæª¢ç´¢æ¹æ³ã
å¨å©ååºæº KGQA è³æéä¸é²è¡çå»£æ³å¯¦é©è¡¨æï¼
æåçæ¨¡åå¨éå¹³ç©©è¨­å®ä¸­é¡¯èåªæ¼åºç·æ¨¡åï¼åæå¨å¹³ç©©ç°å¢ä¸­éå°æåé²çæè½ã
ç¨å¼ç¢¼åè³æå¯æ¼ https://github.com/FUTUREEEEEE/Dynamic-RAG.git åå¾

##### **Scaling Sequential Recommendation Models with Transformers**
2412.07585v1 by Pablo Zivic, Hernan Vazquez, Jorge Sanchez

Modeling user preferences has been mainly addressed by looking at users'
interaction history with the different elements available in the system.
Tailoring content to individual preferences based on historical data is the
main goal of sequential recommendation.
  The nature of the problem, as well as the good performance observed across
various domains, has motivated the use of the transformer architecture, which
has proven effective in leveraging increasingly larger amounts of training data
when accompanied by an increase in the number of model parameters. This scaling
behavior has brought a great deal of attention, as it provides valuable
guidance in the design and training of even larger models.
  Taking inspiration from the scaling laws observed in training large language
models, we explore similar principles for sequential recommendation.
  We use the full Amazon Product Data dataset, which has only been partially
explored in other studies, and reveal scaling behaviors similar to those found
in language models. Compute-optimal training is possible but requires a careful
analysis of the compute-performance trade-offs specific to the application.
  We also show that performance scaling translates to downstream tasks by
fine-tuning larger pre-trained models on smaller task-specific domains. Our
approach and findings provide a strategic roadmap for model training and
deployment in real high-dimensional preference spaces, facilitating better
training and inference efficiency.
  We hope this paper bridges the gap between the potential of transformers and
the intrinsic complexities of high-dimensional sequential recommendation in
real-world recommender systems.
  Code and models can be found at https://github.com/mercadolibre/srt

æè¦ï¼<paragraph>å»ºæ¨¡ä½¿ç¨èåå¥½ä¸»è¦ééè§å¯ä½¿ç¨èèç³»çµ±ä¸­ä¸ååç´ çäºåè¨éã
æ ¹ææ­·å²è³æèª¿æ´åäººåå¥½çå§å®¹æ¯é£çºæ¨è¦çä¸»è¦ç®æ¨ã
åé¡çæ¬è³ªï¼ä»¥åå¨ååé åè§å¯å°çè¯å¥½æè½ï¼æ¿åµäºTransformeræ¶æ§çä½¿ç¨ï¼å¨å¢å æ¨¡ååæ¸æ¸éæï¼å·²è­æè½ææå©ç¨è¶ä¾è¶å¤è¨ç·´è³æãéç¨®è¦æ¨¡è¡çºå¼èµ·äºæ¥µå¤§çéæ³¨ï¼å çºå®å¨è¨­è¨åè¨ç·´æ´å¤§æ¨¡åææä¾äºæå¹å¼çæå°ã
å¾è¨ç·´å¤§åèªè¨æ¨¡åä¸­è§å¯å°çè¦æ¨¡æ³åä¸­æ±²åéæï¼æåæ¢è¨äºé£çºæ¨è¦çé¡ä¼¼ååã
æåä½¿ç¨äºå®æ´ç Amazon ç¢åè³æéï¼å¶ä»ç ç©¶åé¨åæ¢è¨éï¼ä¸¦æ­ç¤ºäºèå¨èªè¨æ¨¡åä¸­ç¼ç¾çé¡ä¼¼çè¦æ¨¡è¡çºãè¨ç®æä½³è¨ç·´æ¯å¯è½çï¼ä½éè¦ä»ç´°åæç¹å®æ¼æç¨ç¨å¼çè¨ç®æè½æè¡·ã
æåéå±ç¤ºäºæè½è¦æ¨¡è½åçºä¸æ¸¸ä»»åï¼ééå°è¼å°çç¹å®ä»»åé åå¾®èª¿è¼å¤§çé è¨ç·´æ¨¡åãæåçåæ³åç¼ç¾çºæ¨¡åè¨ç·´åå¨å¯¦éé«ç¶­åº¦åå¥½ç©ºéä¸­é¨ç½²æä¾äºç­ç¥æ§è·¯ç·åï¼ä¿é²æ´å¥½çè¨ç·´åæ¨çæçã
æåå¸æéç¯è«æè½å½åTransformeræ½åèå¯¦éæ¨è¦ç³»çµ±ä¸­é«ç¶­åº¦é£çºæ¨è¦çå§å¨è¤éæ§ä¹éçå·®è·ã
ç¨å¼ç¢¼åæ¨¡åå¯ä»¥å¨ https://github.com/mercadolibre/srt æ¾å°</paragraph>

##### **Knowledge Graph Guided Evaluation of Abstention Techniques**
2412.07430v1 by Kinshuk Vasisht, Navreet Kaur, Danish Pruthi

To deploy language models safely, it is crucial that they abstain from
responding to inappropriate requests. Several prior studies test the safety
promises of models based on their effectiveness in blocking malicious requests.
In this work, we focus on evaluating the underlying techniques that cause
models to abstain. We create SELECT, a benchmark derived from a set of benign
concepts (e.g., "rivers") from a knowledge graph. The nature of SELECT enables
us to isolate the effects of abstention techniques from other safety training
procedures, as well as evaluate their generalization and specificity. Using
SELECT, we benchmark different abstention techniques over six open-weight and
closed-source models. We find that the examined techniques indeed cause models
to abstain with over $80\%$ abstention rates. However, these techniques are not
as effective for descendants of the target concepts, with refusal rates
declining by $19\%$. We also characterize the generalization-vs-specificity
trade-offs for different techniques. Overall, no single technique is invariably
better than the others. Our findings call for a careful evaluation of different
aspects of abstention, and hopefully inform practitioners of various trade-offs
involved.

æè¦ï¼çºäºå®å¨å°é¨ç½²èªè¨æ¨¡åï¼è³ééè¦çæ¯ï¼å®åå¿é é¿ååæä¸é©ç¶çè«æ±ãååææ¸é ç ç©¶æ¸¬è©¦æ¨¡åçå®å¨æ§ï¼ä¾æå®åå°éæ¡æè«æ±çæææ§çºåºç¤ãå¨éé å·¥ä½ä¸­ï¼æåå°æ³¨æ¼è©ä¼°å°è´æ¨¡åé¿ååæçåºå±¤æè¡ãæåå»ºç«äº SELECTï¼ä¸åå¾ç¥è­åè­ä¸­ä¸çµè¯æ§æ¦å¿µï¼ä¾å¦ãæ²³æµãï¼è¡ççåºæºãSELECT çæ§è³ªä½¿æåè½å¤ å°é¿ååææè¡çå½±é¿èå¶ä»å®å¨è¨ç·´ç¨åºéé¢ï¼ä¸¦è©ä¼°å®åçæ¦æ¬æ§åç¹ç°æ§ãä½¿ç¨ SELECTï¼æåå°å­åéæ¾æ¬éåå°éåå§ç¢¼æ¨¡åé²è¡äºä¸åé¿ååææè¡çåºæºæ¸¬è©¦ãæåç¼ç¾ï¼ææª¢æ¥çæè¡ç¢ºå¯¦å°è´æ¨¡åé¿ååæï¼é¿ååæçè¶é 80%ãç¶èï¼éäºæè¡å°æ¼ç®æ¨æ¦å¿µçå¾ä»£ä¸¦ä¸é£éº¼ææï¼æçµçä¸éäº 19%ãæåéæè¿°äºä¸åæè¡çæ¦æ¬æ§èç¹ç°æ§æ¬è¡¡ãç¸½é«èè¨ï¼æ²æä»»ä½å®ä¸æè¡å§çµåªæ¼å¶ä»æè¡ãæåçç¼ç¾è¦æ±ä»ç´°è©ä¼°é¿ååæçä¸åé¢åï¼ä¸¦å¸æè®å¾æ¥­äººå¡äºè§£ææ¶åçåç¨®æ¬è¡¡ã

##### **AutoPrep: Natural Language Question-Aware Data Preparation with a Multi-Agent Framework**
2412.10422v1 by Meihao Fan, Ju Fan, Nan Tang, Lei Cao, Xiaoyong Du

Answering natural language (NL) questions about tables, which is referred to
as Tabular Question Answering (TQA), is important because it enables users to
extract meaningful insights quickly and efficiently from structured data,
bridging the gap between human language and machine-readable formats. Many of
these tables originate from web sources or real-world scenarios, necessitating
careful data preparation (or data prep for short) to ensure accurate answers.
However, unlike traditional data prep, question-aware data prep introduces new
requirements, which include tasks such as column augmentation and filtering for
given questions, and question-aware value normalization or conversion. Because
each of the above tasks is unique, a single model (or agent) may not perform
effectively across all scenarios. In this paper, we propose AUTOPREP, a large
language model (LLM)-based multi-agent framework that leverages the strengths
of multiple agents, each specialized in a certain type of data prep, ensuring
more accurate and contextually relevant responses. Given an NL question over a
table, AUTOPREP performs data prep through three key components. Planner:
Determines a logical plan, outlining a sequence of high-level operations.
Programmer: Translates this logical plan into a physical plan by generating the
corresponding low-level code. Executor: Iteratively executes and debugs the
generated code to ensure correct outcomes. To support this multi-agent
framework, we design a novel chain-of-thought reasoning mechanism for
high-level operation suggestion, and a tool-augmented method for low-level code
generation. Extensive experiments on real-world TQA datasets demonstrate that
AUTOPREP can significantly improve the SOTA TQA solutions through
question-aware data prep.

æè¦ï¼åç­æå³è¡¨æ ¼çèªç¶è¯­è¨ (NL) é®é¢ï¼ç§°ä¸ºè¡¨æ ¼é®é¢è§£ç­ (TQA)ï¼éå¸¸éè¦ï¼å ä¸ºå®ä½¿ç¨æ·è½å¤ä»ç»æåæ°æ®ä¸­å¿«éææå°æåææä¹çè§è§£ï¼ä»èå¼¥åäºäººç±»è¯­è¨åæºå¨å¯è¯»æ ¼å¼ä¹é´çå·®è·ãå¶ä¸­è®¸å¤è¡¨æ ¼æºèªç½ç»æ¥æºæç°å®ä¸çåºæ¯ï¼å æ­¤éè¦ä»ç»åå¤æ°æ®ï¼æç®ç§°ä¸ºæ°æ®åå¤ï¼ä»¥ç¡®ä¿ç­æ¡åç¡®ãç¶èï¼ä¸ä¼ ç»æ°æ®åå¤ä¸åï¼èèé®é¢çæ°æ®åå¤å¼å¥äºæ°è¦æ±ï¼å¶ä¸­åæ¬éå¯¹ç»å®é®é¢è¿è¡åå¢å¼ºåè¿æ»¤ï¼ä»¥åèèé®é¢çä»·å¼è§èåæè½¬æ¢ç­ä»»å¡ãç±äºä¸è¿°æ¯é¡¹ä»»å¡é½æ¯å¯ä¸çï¼å æ­¤åä¸ªæ¨¡åï¼æä»£çï¼å¯è½æ æ³å¨ææåºæ¯ä¸­æææ§è¡ãå¨æ¬æä¸­ï¼æä»¬æåºäº AUTOPREPï¼è¿æ¯ä¸ä¸ªåºäºå¤§åè¯­è¨æ¨¡å (LLM) çå¤ä»£çæ¡æ¶ï¼å®å©ç¨äºå¤ä¸ªä»£ççä¼å¿ï¼æ¯ä¸ªä»£çé½ä¸é¨ä»äºæç§ç±»åçæ°æ®åå¤ï¼ä»èç¡®ä¿äºæ´åç¡®åä¸ä¸ä¸æç¸å³çååºãç»å®ä¸ä¸ªå³äºè¡¨æ ¼ç NL é®é¢ï¼AUTOPREP éè¿ä¸ä¸ªå³é®ç»ä»¶æ§è¡æ°æ®åå¤ãè®¡åç¨åºï¼ç¡®å®ä¸ä¸ªé»è¾è®¡åï¼æ¦è¿°ä¸ç³»åé«çº§æä½ãç¨åºåï¼éè¿çæç¸åºçä½çº§ä»£ç å°æ­¤é»è¾è®¡åè½¬æ¢ä¸ºç©çè®¡åãæ§è¡å¨ï¼è¿­ä»£æ§è¡å¹¶è°è¯çæçä»£ç ä»¥ç¡®ä¿æ­£ç¡®çç»æãä¸ºäºæ¯ææ­¤å¤ä»£çæ¡æ¶ï¼æä»¬è®¾è®¡äºä¸ç§æ°é¢çææ³é¾æ¨çæºå¶ï¼ç¨äºé«çº§æä½å»ºè®®ï¼ä»¥åä¸ç§ç¨äºä½çº§ä»£ç çæââçå·¥å·å¢å¼ºæ¹æ³ãå¨çå®ä¸ç TQA æ°æ®éä¸è¿è¡çå¹¿æ³å®éªè¡¨æï¼AUTOPREP å¯ä»¥éè¿èèé®é¢çââæ°æ®åå¤æ¾çæ¹è¿ SOTA TQA è§£å³æ¹æ¡ã

##### **A Review of Challenges in Speech-based Conversational AI for Elderly Care**
2412.07388v1 by Willemijn Klaassen, Bram van Dijk, Marco Spruit

Artificially intelligent systems optimized for speech conversation are
appearing at a fast pace. Such models are interesting from a healthcare
perspective, as these voice-controlled assistants may support the elderly and
enable remote health monitoring. The bottleneck for efficacy, however, is how
well these devices work in practice and how the elderly experience them, but
research on this topic is scant. We review elderly use of voice-controlled AI
and highlight various user- and technology-centered issues, that need to be
considered before effective speech-controlled AI for elderly care can be
realized.

æè¦ï¼ä»¥èªé³å°è©±çºæä½³åçäººå·¥æºæ§ç³»çµ±æ­£å¿«éåºç¾ãæ­¤é¡æ¨¡åå¨é«çä¿å¥æ¹é¢å¾æè¶£ï¼å çºéäºè²æ§å©çå¯ä»¥æ¯æ´é·èä¸¦è½é²è¡é è·å¥åº·ç£æ§ãç¶èï¼æè½çç¶é ¸å¨æ¼éäºè£ç½®å¨å¯¦ééä½ä¸çè¡¨ç¾å¦ä½ï¼ä»¥åé·èå¦ä½é«é©å®åï¼ä½éæ¹é¢çç ç©¶å»å¾ç¨å°ãæååé¡§äºé·èä½¿ç¨è²æ§äººå·¥æºæ§ççæ³ï¼ä¸¦éé»èªªæåç¨®ä»¥ä½¿ç¨èåæè¡çºä¸­å¿çè­°é¡ï¼å¨è½å¯¦ç¾ææçè²æ§äººå·¥æºæ§ä»¥é²è¡é·èç§è­·ä¹åï¼éäºè­°é¡é½éè¦å ä»¥èéã

##### **Enhanced MRI Representation via Cross-series Masking**
2412.07387v1 by Churan Wang, Fei Gao, Lijun Yan, Siwen Wang, Yizhou Yu, Yizhou Wang

Magnetic resonance imaging (MRI) is indispensable for diagnosing and planning
treatment in various medical conditions due to its ability to produce
multi-series images that reveal different tissue characteristics. However,
integrating these diverse series to form a coherent analysis presents
significant challenges, such as differing spatial resolutions and contrast
patterns meanwhile requiring extensive annotated data, which is scarce in
clinical practice. Due to these issues, we introduce a novel Cross-Series
Masking (CSM) Strategy for effectively learning MRI representation in a
self-supervised manner. Specifically, CSM commences by randomly sampling a
subset of regions and series, which are then strategically masked. In the
training process, the cross-series representation is learned by utilizing the
unmasked data to reconstruct the masked portions. This process not only
integrates information across different series but also facilitates the ability
to model both intra-series and inter-series correlations and complementarities.
With the learned representation, the downstream tasks like segmentation and
classification are also enhanced. Taking brain tissue segmentation, breast
tumor benign/malignant classification, and prostate cancer diagnosis as
examples, our method achieves state-of-the-art performance on both public and
in-house datasets.

æè¦ï¼ç£æ¯é å½± (MRI) å°æ¼è¨ºæ·åè¦ååç¨®é«ççæ³çæ²»çè³ééè¦ï¼å çºå®è½å¤ ç¢çæ­ç¤ºä¸åçµç¹ç¹å¾µçå¤ç³»åå½±åãç¶èï¼æ´åéäºä¸åçç³»åä»¥å½¢æé£è²«çåææå¸¶ä¾éå¤§çææ°ï¼ä¾å¦ä¸åçç©ºéè§£æåº¦åå°æ¯æ¨¡å¼ï¼åæéè¦å¤§éçè¨»è§£è³æï¼ä½å¨è¨åºå¯¦åä¸­å»å¾ç¨å°ãç±æ¼éäºåé¡ï¼æåå¼å¥äºä¸ç¨®æ°ç©çè·¨ç³»åé®ç½© (CSM) ç­ç¥ï¼ä»¥ä¾¿ä»¥èªæç£ç£çæ¹å¼ææå°å­¸ç¿ MRI è¡¨å¾µãå·é«ä¾èªªï¼CSM å¾é¨æ©æ½æ¨£åååç³»åçå­ééå§ï¼ç¶å¾å°å¶é²è¡ç­ç¥æ§é®ç½©ãå¨è¨ç·´éç¨ä¸­ï¼è·¨ç³»åè¡¨å¾µæ¯ééå©ç¨æªé®ç½©çè³æä¾éå»ºé®ç½©é¨åèå­¸ç¿çãéåéç¨ä¸åæ´åäºä¸åç³»åçè³è¨ï¼éä¿é²äºå°ç³»åå§åç³»åééè¯æ§åäºè£æ§çå»ºæ¨¡è½åãééå­¸ç¿å°çè¡¨å¾µï¼ä¸æ¸¸ä»»åï¼ä¾å¦åå²ååé¡ï¼ä¹æå¾å°å¢å¼·ãä»¥è¦çµç¹åå²ãä¹³æ¿è«ç¤è¯æ§/æ¡æ§åé¡åååèºçè¨ºæ·çºä¾ï¼æåçæ¨¡åå¨å¬éè³æéåå§é¨è³æéä¸é½éå°äºæåé²çæè½ã

##### **On Evaluating the Durability of Safeguards for Open-Weight LLMs**
2412.07097v1 by Xiangyu Qi, Boyi Wei, Nicholas Carlini, Yangsibo Huang, Tinghao Xie, Luxi He, Matthew Jagielski, Milad Nasr, Prateek Mittal, Peter Henderson

Stakeholders -- from model developers to policymakers -- seek to minimize the
dual-use risks of large language models (LLMs). An open challenge to this goal
is whether technical safeguards can impede the misuse of LLMs, even when models
are customizable via fine-tuning or when model weights are fully open. In
response, several recent studies have proposed methods to produce durable LLM
safeguards for open-weight LLMs that can withstand adversarial modifications of
the model's weights via fine-tuning. This holds the promise of raising
adversaries' costs even under strong threat models where adversaries can
directly fine-tune model weights. However, in this paper, we urge for more
careful characterization of the limits of these approaches. Through several
case studies, we demonstrate that even evaluating these defenses is exceedingly
difficult and can easily mislead audiences into thinking that safeguards are
more durable than they really are. We draw lessons from the evaluation pitfalls
that we identify and suggest future research carefully cabin claims to more
constrained, well-defined, and rigorously examined threat models, which can
provide more useful and candid assessments to stakeholders.

æè¦ï¼å©å®³éä¿äººï¼å¾æ¨¡åéç¼äººå¡å°æ¿ç­å¶å®èï¼å°æ±å°å¤§åèªè¨æ¨¡å (LLM) çééä½¿ç¨é¢¨éªéè³æä½ãå°æ­¤ç®æ¨çå¬éææ°å¨æ¼ï¼æè¡ä¿éæªæ½æ¯å¦è½é»æ­¢ LLM çæ¿«ç¨ï¼å³ä½¿æ¨¡åå¯ééå¾®èª¿é²è¡èªè¨ï¼ææ¨¡åæ¬éå®å¨éæ¾æäº¦ç¶ãçºäºè§£æ±ºæ­¤åé¡ï¼æè¿æå¹¾é ç ç©¶æåºæ¹æ³ï¼ä»¥ç¢çé©ç¨æ¼éæ¾æ¬é LLM çèç¨ LLM ä¿éæªæ½ï¼éäºä¿éæªæ½è½æ¿åééå¾®èª¿å°æ¨¡åæ¬éé²è¡çå°ææ§ä¿®æ¹ãéæææé«å°æçææ¬ï¼å³ä½¿å¨å°æå¯ä»¥ç´æ¥å¾®èª¿æ¨¡åæ¬éçå¼·å¨èæ¨¡åä¸äº¦ç¶ãç¶èï¼å¨æ¬æä¸­ï¼æåæ¦ä¿æ´ä»ç´°å°æè¿°éäºæ¹æ³çéå¶ãééå¤é æ¡ä¾ç ç©¶ï¼æåè­æå³ä½¿è©ä¼°éäºé²ç¦¦æªæ½ä¹æ¥µå¶å°é£ï¼ä¸¦ä¸å¾å®¹æèª¤å°åç¾ï¼è®ä»åèªçºä¿éæªæ½æ¯å¯¦éä¸æ´èç¨ãæåå¾æåè¾¨è­åºçè©ä¼°é·é±ä¸­æ±²åæè¨ï¼ä¸¦å»ºè­°æªä¾çç ç©¶è¬¹æå°å°ä¸»å¼µéå¶å¨æ´åéãå®ç¾©æç¢ºä¸ç¶éå´æ ¼å¯©æ¥çå¨èæ¨¡åä¸­ï¼éå¯ä»¥çºå©å®³éä¿äººæä¾æ´æç¨ä¸å¦ççè©ä¼°ã

##### **Toward AI-Driven Digital Organism: Multiscale Foundation Models for Predicting, Simulating and Programming Biology at All Levels**
2412.06993v1 by Le Song, Eran Segal, Eric Xing

We present an approach of using AI to model and simulate biology and life.
Why is it important? Because at the core of medicine, pharmacy, public health,
longevity, agriculture and food security, environmental protection, and clean
energy, it is biology at work. Biology in the physical world is too complex to
manipulate and always expensive and risky to tamper with. In this perspective,
we layout an engineering viable approach to address this challenge by
constructing an AI-Driven Digital Organism (AIDO), a system of integrated
multiscale foundation models, in a modular, connectable, and holistic fashion
to reflect biological scales, connectedness, and complexities. An AIDO opens up
a safe, affordable and high-throughput alternative platform for predicting,
simulating and programming biology at all levels from molecules to cells to
individuals. We envision that an AIDO is poised to trigger a new wave of
better-guided wet-lab experimentation and better-informed first-principle
reasoning, which can eventually help us better decode and improve life.

æè¦ï¼æåæåºäºä¸ç¨®ä½¿ç¨ AI ä¾å»ºæ¨¡åæ¨¡æ¬çç©å­¸åçå½çæ¹æ³ã
çºä»éº¼éå¾éè¦ï¼å çºå¨é«å­¸ãè¥å­¸ãå¬å±è¡çã
é·å£½ãè¾²æ¥­åé£åå®å¨ãç°å¢ä¿è­·åæ¸æ½
è½æºçæ ¸å¿ï¼é½æ¯çç©å­¸å¨éä½ãç©çä¸çä¸­ççç©å­¸å¤ªéè¤éï¼
é£ä»¥æä½ï¼èä¸ç¸½æ¯æè²´ä¸æé¢¨éªãå¾éåè§åº¦ä¾çï¼
æåå¶å®äºä¸ç¨®å¯è¡çå·¥ç¨æ¹æ³ä¾è§£æ±ºéåææ°ï¼æ¹æ³æ¯
æ§å»ºä¸å AI é©åçæ¸ä½çç©é« (AIDO)ï¼ä¸åæ´åç
å¤å°ºåº¦åºç¤æ¨¡åç³»çµ±ï¼ä»¥æ¨¡çµåãå¯é£æ¥åæ´é«çæ¹å¼
ä¾åæ çç©å°ºåº¦ãé£éæ§åè¤éæ§ãAIDO éåäºä¸åå®å¨ã
è² æå¾èµ·ä¸é«ééçæ¿ä»£å¹³å°ï¼ç¨æ¼é æ¸¬ã
æ¨¡æ¬åç·¨ç¨å¾åå­å°ç´°èå°åé«çææå±¤ç´ççç©å­¸ãæåé è¨ AIDO å°å¼ç¼ä¸æ³¢
ç±æ´ä½³æå°çæ¿å¼å¯¦é©åæ´å®åçç¬¬ä¸åç
æ¨ççæ°æµªæ½®ï¼æçµå¯ä»¥å¹«å©æåæ´å¥½å°è§£ç¢¼åæ¹åçå½ã

##### **Leveraging Audio and Text Modalities in Mental Health: A Study of LLMs Performance**
2412.10417v1 by Abdelrahman A. Ali, Aya E. Fouda, Radwa J. Hanafy, Mohammed E. Fouda

Mental health disorders are increasingly prevalent worldwide, creating an
urgent need for innovative tools to support early diagnosis and intervention.
This study explores the potential of Large Language Models (LLMs) in multimodal
mental health diagnostics, specifically for detecting depression and Post
Traumatic Stress Disorder through text and audio modalities. Using the E-DAIC
dataset, we compare text and audio modalities to investigate whether LLMs can
perform equally well or better with audio inputs. We further examine the
integration of both modalities to determine if this can enhance diagnostic
accuracy, which generally results in improved performance metrics. Our analysis
specifically utilizes custom-formulated metrics; Modal Superiority Score and
Disagreement Resolvement Score to evaluate how combined modalities influence
model performance. The Gemini 1.5 Pro model achieves the highest scores in
binary depression classification when using the combined modality, with an F1
score of 0.67 and a Balanced Accuracy (BA) of 77.4%, assessed across the full
dataset. These results represent an increase of 3.1% over its performance with
the text modality and 2.7% over the audio modality, highlighting the
effectiveness of integrating modalities to enhance diagnostic accuracy.
Notably, all results are obtained in zero-shot inferring, highlighting the
robustness of the models without requiring task-specific fine-tuning. To
explore the impact of different configurations on model performance, we conduct
binary, severity, and multiclass tasks using both zero-shot and few-shot
prompts, examining the effects of prompt variations on performance. The results
reveal that models such as Gemini 1.5 Pro in text and audio modalities, and
GPT-4o mini in the text modality, often surpass other models in balanced
accuracy and F1 scores across multiple tasks.

æè¦ï¼<paragraph>å¿çå¥åº·ç¾çå¨å¨çèå´åæ¥çæ®éï¼è¿«åéè¦åæ°å·¥å·æ¥æ¯ææ©æè¯æ­åå¹²é¢ãæ¬ç ç©¶æ¢è®¨äºå¤§è¯­è¨æ¨¡å (LLM) å¨å¤æ¨¡æå¿çå¥åº·è¯æ­ä¸­çæ½åï¼ç¹å«æ¯éè¿ææ¬åé³é¢æ¨¡å¼æ£æµæéçååä¼¤ååºæ¿éç¢ãä½¿ç¨ E-DAIC æ°æ®éï¼æä»¬æ¯è¾ææ¬åé³é¢æ¨¡å¼ä»¥è°æ¥ LLM æ¯å¦å¯ä»¥ä½¿ç¨é³é¢è¾å¥è¡¨ç°å¾åæ ·å¥½ææ´å¥½ãæä»¬è¿ä¸æ­¥æ£æ¥äºä¸¤ç§æ¨¡å¼çéæï¼ä»¥ç¡®å®è¿æ¯å¦å¯ä»¥æé«è¯æ­åç¡®æ§ï¼è¿éå¸¸ä¼å¯¼è´æ§è½ææ çæé«ãæä»¬çåæä¸é¨ä½¿ç¨å®å¶å¬å¼çææ ï¼æ¨¡å¼ä¼å¿åæ°ååæ­§è§£å³åæ°æ¥è¯ä¼°ç»åæ¨¡å¼å¦ä½å½±åæ¨¡åæ§è½ãGemini 1.5 Pro æ¨¡åå¨ä½¿ç¨ç»åæ¨¡å¼æ¶å¨äºåæéçåç±»ä¸­è·å¾æé«åï¼F1 å¾åä¸º 0.67ï¼å¹³è¡¡åç¡®åº¦ (BA) ä¸º 77.4%ï¼å¨æ´ä¸ªæ°æ®éä¸è¿è¡è¯ä¼°ãè¿äºç»ææ¯å¶å¨ææ¬æ¨¡å¼ä¸çè¡¨ç°æé«äº 3.1%ï¼æ¯é³é¢æ¨¡å¼æé«äº 2.7%ï¼çªæ¾äºéææ¨¡å¼ä»¥æé«è¯æ­åç¡®æ§çæææ§ãå¼å¾æ³¨æçæ¯ï¼ææç»æé½æ¯å¨é¶æ¬¡æ¨æ­ä¸­è·å¾çï¼çªåºäºæ¨¡åçç¨³å¥æ§ï¼èä¸éè¦ç¹å®äºä»»å¡çå¾®è°ãä¸ºäºæ¢ç´¢ä¸åéç½®å¯¹æ¨¡åæ§è½çå½±åï¼æä»¬ä½¿ç¨é¶æ¬¡åå°æ¬¡æç¤ºæ§è¡äºåãä¸¥éæ§åå¤ç±»ä»»å¡ï¼æ£æ¥æç¤ºååå¯¹æ§è½çå½±åãç»æè¡¨æï¼ææ¬åé³é¢æ¨¡å¼ä¸­ç Gemini 1.5 Pro ç­æ¨¡åä»¥åææ¬æ¨¡å¼ä¸­ç GPT-4o mini å¨å¤ä¸ªä»»å¡ä¸­çå¹³è¡¡åç¡®æ§å F1 åæ°éå¸¸ä¼äºå¶ä»æ¨¡åã</paragraph>

##### **Diagnosis and Severity Assessment of Ulcerative Colitis using Self Supervised Learning**
2412.07806v1 by Venkat Margapuri

Ulcerative Colitis (UC) is an incurable inflammatory bowel disease that leads
to ulcers along the large intestine and rectum. The increase in the prevalence
of UC coupled with gastrointestinal physician shortages stresses the healthcare
system and limits the care UC patients receive. A colonoscopy is performed to
diagnose UC and assess its severity based on the Mayo Endoscopic Score (MES).
The MES ranges between zero and three, wherein zero indicates no inflammation
and three indicates that the inflammation is markedly high. Artificial
Intelligence (AI)-based neural network models, such as convolutional neural
networks (CNNs) are capable of analyzing colonoscopies to diagnose and
determine the severity of UC by modeling colonoscopy analysis as a multi-class
classification problem. Prior research for AI-based UC diagnosis relies on
supervised learning approaches that require large annotated datasets to train
the CNNs. However, creating such datasets necessitates that domain experts
invest a significant amount of time, rendering the process expensive and
challenging. To address the challenge, this research employs self-supervised
learning (SSL) frameworks that can efficiently train on unannotated datasets to
analyze colonoscopies and, aid in diagnosing UC and its severity. A comparative
analysis with supervised learning models shows that SSL frameworks, such as
SwAV and SparK outperform supervised learning models on the LIMUC dataset, the
largest publicly available annotated dataset of colonoscopy images for UC.

æè¦ï¼æ½°çæ§çµè¸ç (UC) æ¯ä¸ç¨®ç¡æ³æ²»ççç¼çæ§è¸éç¾çï¼æå°è´å¤§è¸åç´è¸æ½°çãUC çæ£ççå¢å ï¼å ä¸è¸èç§é«å¸«ç­ç¼ºï¼å°é«çä¿å¥ç³»çµ±é æå£åï¼ä¸¦éå¶ UC æ£èæ¥åçç§è­·ãé²è¡å¤§è¸é¡æª¢æ¥ä»¥è¨ºæ· UC ä¸¦æ ¹æ Mayo å§è¦é¡è©å (MES) è©ä¼°å¶å´éç¨åº¦ãMES çç¯åå¨ 0 å° 3 ä¹éï¼å¶ä¸­ 0 è¡¨ç¤ºæ²æç¼çï¼è 3 è¡¨ç¤ºç¼çç¨åº¦é¡¯èãåºæ¼äººå·¥æºæ§ (AI) çç¥ç¶ç¶²è·¯æ¨¡åï¼ä¾å¦å·ç©ç¥ç¶ç¶²è·¯ (CNN)ï¼è½å¤ åæå¤§è¸é¡æª¢æ¥ä»¥è¨ºæ·åç¢ºå® UC çå´éç¨åº¦ï¼æ¹æ³æ¯å°å¤§è¸é¡æª¢æ¥åæå»ºæ¨¡çºå¤é¡å¥åé¡åé¡ãååéå°åºæ¼ AI ç UC è¨ºæ·çç ç©¶ä¾è³´æ¼ç£ç£å¼å­¸ç¿æ¹æ³ï¼éè¦å¤§éæ¨è¨»çè³æéä¾è¨ç·´ CNNãç¶èï¼å»ºç«æ­¤é¡è³æééè¦é åå°å®¶æå¥å¤§éæéï¼ä½¿éåéç¨æ¢æè²´åå·æææ°æ§ãçºäºæå°éåææ°ï¼æ¬ç ç©¶æ¡ç¨èªæç£ç£å­¸ç¿ (SSL) æ¡æ¶ï¼å¯ä»¥å¨æªæ¨è¨»çè³æéä¸é²è¡ææççè¨ç·´ï¼ä»¥åæå¤§è¸é¡æª¢æ¥ä¸¦åå©è¨ºæ· UC åå¶å´éç¨åº¦ãèç£ç£å¼å­¸ç¿æ¨¡åçæ¯è¼åæé¡¯ç¤ºï¼SSL æ¡æ¶ï¼ä¾å¦ SwAV å SparKï¼å¨ LIMUC è³æéï¼æå¤§çå¬é UC å¤§è¸é¡æª¢æ¥å½±åæ¨è¨»è³æéï¼ä¸åªæ¼ç£ç£å¼å­¸ç¿æ¨¡åã

##### **Toward Non-Invasive Diagnosis of Bankart Lesions with Deep Learning**
2412.06717v1 by Sahil Sethi, Sai Reddy, Mansi Sakarvadia, Jordan Serotte, Darlington Nwaudo, Nicholas Maassen, Lewis Shi

Bankart lesions, or anterior-inferior glenoid labral tears, are
diagnostically challenging on standard MRIs due to their subtle imaging
features-often necessitating invasive MRI arthrograms (MRAs). This study
develops deep learning (DL) models to detect Bankart lesions on both standard
MRIs and MRAs, aiming to improve diagnostic accuracy and reduce reliance on
MRAs. We curated a dataset of 586 shoulder MRIs (335 standard, 251 MRAs) from
558 patients who underwent arthroscopy. Ground truth labels were derived from
intraoperative findings, the gold standard for Bankart lesion diagnosis.
Separate DL models for MRAs and standard MRIs were trained using the Swin
Transformer architecture, pre-trained on a public knee MRI dataset. Predictions
from sagittal, axial, and coronal views were ensembled to optimize performance.
The models were evaluated on a 20% hold-out test set (117 MRIs: 46 MRAs, 71
standard MRIs). Bankart lesions were identified in 31.9% of MRAs and 8.6% of
standard MRIs. The models achieved AUCs of 0.87 (86% accuracy, 83% sensitivity,
86% specificity) and 0.90 (85% accuracy, 82% sensitivity, 86% specificity) on
standard MRIs and MRAs, respectively. These results match or surpass
radiologist performance on our dataset and reported literature metrics.
Notably, our model's performance on non-invasive standard MRIs matched or
surpassed the radiologists interpreting MRAs. This study demonstrates the
feasibility of using DL to address the diagnostic challenges posed by subtle
pathologies like Bankart lesions. Our models demonstrate potential to improve
diagnostic confidence, reduce reliance on invasive imaging, and enhance
accessibility to care.

æè¦ï¼Bankart çç¶ï¼æåä¸çåæè£ï¼ç±æ¼å¶å½±åç¹å¾µå¾®å¦ï¼å¨æ¨æºæ ¸ç£å±æ¯æåä¸­è¨ºæ·å·æææ°æ§ï¼éå¸¸éè¦ä¾µå¥æ§æ ¸ç£å±æ¯è¡ç®¡é å½± (MRA)ãæ¬ç ç©¶éç¼æ·±åº¦å­¸ç¿ (DL) æ¨¡åï¼ç¨æ¼å¨æ¨æºæ ¸ç£å±æ¯æååæ ¸ç£å±æ¯è¡ç®¡é å½±ä¸­æª¢æ¸¬ Bankart çç¶ï¼æ¨å¨æé«è¨ºæ·æºç¢ºæ§ä¸¦æ¸å°å°æ ¸ç£å±æ¯è¡ç®¡é å½±çä¾è³´ãæåå¾ 558 åæ¥åéç¯é¡æª¢æ¥çæ£èä¸­ç­åäºä¸çµ 586 ä¾è©é¨æ ¸ç£å±æ¯æå (335 ä¾æ¨æºï¼251 ä¾æ ¸ç£å±æ¯è¡ç®¡é å½±) çæ¸æéãåºæ¬äºå¯¦æ¨ç±¤ä¾èªè¡ä¸­ç¼ç¾ï¼éæ¯ Bankart çç¶è¨ºæ·çé»éæ¨æºãä½¿ç¨ Swin Transformer æ¶æ§è¨ç·´äºæ ¸ç£å±æ¯è¡ç®¡é å½±åæ¨æºæ ¸ç£å±æ¯æåçå®ç¨æ·±åº¦å­¸ç¿æ¨¡åï¼ä¸¦å¨å¬éçèé¨æ ¸ç£å±æ¯æåæ¸æéä¸é²è¡é è¨ç·´ãç¢çé¢ãè»¸é¢åå çé¢çé æ¸¬çµæè¢«çµåèµ·ä¾ä»¥åªåæ§è½ãéäºæ¨¡åå¨ 20% çä¿çæ¸¬è©¦éï¼117 ä¾æ ¸ç£å±æ¯æåï¼46 ä¾æ ¸ç£å±æ¯è¡ç®¡é å½±ï¼71 ä¾æ¨æºæ ¸ç£å±æ¯æåï¼ä¸é²è¡äºè©ä¼°ãå¨ 31.9% çæ ¸ç£å±æ¯è¡ç®¡é å½±å 8.6% çæ¨æºæ ¸ç£å±æ¯æåä¸­ç¼ç¾äº Bankart çç¶ãéäºæ¨¡åå¨æ¨æºæ ¸ç£å±æ¯æååæ ¸ç£å±æ¯è¡ç®¡é å½±ä¸­ç AUC åå¥éå° 0.87ï¼86% æºç¢ºåº¦ï¼83% éæåº¦ï¼86% ç¹ç°åº¦ï¼å 0.90ï¼85% æºç¢ºåº¦ï¼82% éæåº¦ï¼86% ç¹ç°åº¦ï¼ãéäºçµæèæ¾å°ç§é«çå°æåæ¸æéçè¡¨ç¾ç¸å¹éæè¶éï¼ä¸¦è¶éäºå ±åçæç»ææ¨ãå¼å¾æ³¨æçæ¯ï¼æåçæ¨¡åå¨éä¾µå¥æ§æ¨æºæ ¸ç£å±æ¯æåä¸­çè¡¨ç¾èæ¾å°ç§é«çå°æ ¸ç£å±æ¯è¡ç®¡é å½±çè§£éç¸å¹éæè¶éãæ¬ç ç©¶è­æäºä½¿ç¨æ·±åº¦å­¸ç¿ä¾è§£æ±º Bankart çç¶ç­å¾®å¦ççè¨ºæ·ææ°çå¯è¡æ§ãæåçæ¨¡åå±ç¤ºäºæé«è¨ºæ·ä¿¡å¿ãæ¸å°å°ä¾µå¥æ§å½±åæª¢æ¥çä¾è³´ä»¥åå¢å¼·ç²å¾ç§è­·çæ©æçæ½åã

##### **Parkinson's Disease Diagnosis Through Deep Learning: A Novel LSTM-Based Approach for Freezing of Gait Detection**
2412.06709v1 by Aqib Nazir Mir, Iqra Nissar, Mumtaz Ahmed, Sarfaraz Masood, Danish Raza Rizvi

Deep learning holds tremendous potential in healthcare for uncovering hidden
patterns within extensive clinical datasets, aiding in the diagnosis of various
diseases. Parkinson's disease (PD) is a neurodegenerative condition
characterized by the deterioration of brain function. In the initial stages of
PD, automatic diagnosis poses a challenge due to the similarity in behavior
between individuals with PD and those who are healthy. Our objective is to
propose an effective model that can aid in the early detection of Parkinson's
disease. We employed the VGRF gait signal dataset sourced from Physionet for
distinguishing between healthy individuals and those diagnosed with Parkinson's
disease. This paper introduces a novel deep learning architecture based on the
LSTM network for automatically detecting freezing of gait episodes in
Parkinson's disease patients. In contrast to conventional machine learning
algorithms, this method eliminates manual feature engineering and proficiently
captures prolonged temporal dependencies in gait patterns, thereby improving
the diagnosis of Parkinson's disease. The LSTM network resolves the issue of
vanishing gradients by employing memory blocks in place of self-connected
hidden units, allowing for optimal information assimilation. To prevent
overfitting, dropout and L2 regularization techniques have been employed.
Additionally, the stochastic gradient-based optimizer Adam is used for the
optimization process. The results indicate that our proposed approach surpasses
current state-of-the-art models in FOG episode detection, achieving an accuracy
of 97.71%, sensitivity of 99%, precision of 98%, and specificity of 96%. This
demonstrates its potential as a superior classification method for Parkinson's
disease detection.

æè¦ï¼æ·±åº¦å­¸ç¿å¨é«çä¿å¥é åææå·¨å¤§çæ½åï¼å¯ç¨æ¼ç¼æå»£æ³è¨åºè³æéä¸­çé±èæ¨¡å¼ï¼åå©è¨ºæ·åç¨®ç¾çãå¸éæ£®æ°ç (PD) æ¯ä¸ç¨®ç¥ç¶éåæ§ç¾çï¼å¶ç¹å¾µæ¯å¤§è¦åè½æ¡åãå¨ PD çåæéæ®µï¼ç±æ¼ PD æ£èèå¥åº·èçè¡çºç¸ä¼¼ï¼å æ­¤èªåè¨ºæ·å·æææ°æ§ãæåçç®æ¨æ¯æåºä¸åææçæ¨¡åï¼å¯ä»¥å¹«å©æ©ææª¢æ¸¬å¸éæ£®æ°çãæåæ¡ç¨äºä¾èª Physionet ç VGRF æ­¥æä¿¡èè³æéï¼ç¨æ¼ååå¥åº·åé«åè¢«è¨ºæ·åºæ£æå¸éæ£®æ°ççåé«ãæ¬æä»ç´¹äºä¸ç¨®åºæ¼ LSTM ç¶²è·¯çæ·±åº¦å­¸ç¿æ°æ¶æ§ï¼ç¨æ¼èªåæª¢æ¸¬å¸éæ£®æ°çæ£èçæ­¥æåçµç¼ä½ãèå³çµ±æ©å¨å­¸ç¿æ¼ç®æ³ç¸æ¯ï¼æ­¤æ¹æ³æ¶é¤äºæåç¹å¾µå·¥ç¨ï¼ä¸¦çç·´å°æææ­¥ææ¨¡å¼ä¸­çé·æéä¾è³´æ§ï¼å¾èæ¹é²äºå¸éæ£®æ°ççè¨ºæ·ãLSTM ç¶²è·¯ééä½¿ç¨è¨æ¶åå¡ä»£æ¿èªé£æ¥é±èå®åä¾è§£æ±ºæ¢¯åº¦æ¶å¤±åé¡ï¼å¾èå¯¦ç¾æä½³è³è¨ååãçºäºé²æ­¢éåº¦æ¬åï¼å·²æ¡ç¨ä¸­æ·å L2 æ­£ååæè¡ãæ­¤å¤ï¼é¨æ©æ¢¯åº¦åªåå¨ Adam ç¨æ¼åªåéç¨ãçµæè¡¨æï¼æåæåºçæ¹æ³å¨ FOG ç¼ä½æª¢æ¸¬æ¹é¢è¶è¶äºç¶åæåé²çæ¨¡åï¼éå°äº 97.71% çæºç¢ºçã99% çéæåº¦ã98% çç²¾ç¢ºåº¦å 96% çç¹ç°æ§ãéè­æäºå¶ä½çºå¸éæ£®æ°çæª¢æ¸¬çåªè¶åé¡æ¹æ³çæ½åã

##### **Fundus Image-based Visual Acuity Assessment with PAC-Guarantees**
2412.06624v1 by Sooyong Jang, Kuk Jin Jang, Hyonyoung Choi, Yong-Seop Han, Seongjin Lee, Jin-hyun Kim, Insup Lee

Timely detection and treatment are essential for maintaining eye health.
Visual acuity (VA), which measures the clarity of vision at a distance, is a
crucial metric for managing eye health. Machine learning (ML) techniques have
been introduced to assist in VA measurement, potentially alleviating
clinicians' workloads. However, the inherent uncertainties in ML models make
relying solely on them for VA prediction less than ideal. The VA prediction
task involves multiple sources of uncertainty, requiring more robust
approaches. A promising method is to build prediction sets or intervals rather
than point estimates, offering coverage guarantees through techniques like
conformal prediction and Probably Approximately Correct (PAC) prediction sets.
Despite the potential, to date, these approaches have not been applied to the
VA prediction task.To address this, we propose a method for deriving prediction
intervals for estimating visual acuity from fundus images with a PAC guarantee.
Our experimental results demonstrate that the PAC guarantees are upheld, with
performance comparable to or better than that of two prior works that do not
provide such guarantees.

æè¦ï¼åæå°åµæ¸¬åæ²»çå°æ¼ç¶­æç¼çå¥åº·è³ééè¦ã
è¦åï¼VAï¼ï¼ç¨æ¼æ¸¬éé è·é¢è¦è¦ºçæ¸æ°åº¦ï¼æ¯ç¶­æç¼çå¥åº·çééµææ¨ãæ©å¨å­¸ç¿ï¼MLï¼æè¡å·²è¢«å¼å¥ä»¥åå© VA æ¸¬éï¼æ½å¨å°æ¸è¼è¨åºé«å¸«çå·¥ä½è² æãç¶èï¼ML æ¨¡åä¸­åºæçä¸ç¢ºå®æ§ä½¿å¾åä¾è³´å®åé²è¡ VA é æ¸¬ä¸¦éçæ³ãVA é æ¸¬ä»»åæ¶åå¤ç¨®ä¸ç¢ºå®æ§ä¾æºï¼éè¦æ´å¼·å¤§çæ¹æ³ãä¸ç¨®æåéçæ¹æ³æ¯å»ºç«é æ¸¬éåæåéï¼èä¸æ¯é»ä¼°è¨ï¼ééåå±å½¢é æ¸¬åå¤§æ¦æ­£ç¢ºï¼PACï¼é æ¸¬éåéæ¨£çæè¡æä¾è¦èçä¿è­ãåç®¡ææ½åï¼ä½è¿ä»çºæ­¢ï¼éäºæ¹æ³å°æªæç¨æ¼ VA é æ¸¬ä»»åãçºäºè§£æ±ºéååé¡ï¼æåæåºäºä¸ç¨®å¾ç¼åºååä¼°è¨è¦åçé æ¸¬åéçæ¹æ³ï¼ä¸¦æä¾ PAC ä¿è­ãæåçå¯¦é©çµæè¡¨æï¼PAC ä¿è­å¾å°ç¶­æï¼å¶æ§è½èä¸æä¾æ­¤é¡ä¿è­çå©é ååå·¥ä½çæ§è½ç¸ç¶ææ´å¥½ã

##### **Real-Time Performance Optimization of Travel Reservation Systems Using AI and Microservices**
2412.06874v1 by Biman Barua, M. Shamim Kaiser

The rapid growth of the travel industry has increased the need for real-time
optimization in reservation systems that could take care of huge data and
transaction volumes. This study proposes a hybrid framework that ut folds an
Artificial Intelligence and a Microservices approach for the performance
optimization of the system. The AI algorithms forecast demand patterns,
optimize the allocation of resources, and enhance decision-making driven by
Microservices architecture, hence decentralizing system components for
scalability, fault tolerance, and reduced downtime. The model provided focuses
on major problems associated with the travel reservation systems such as
latency of systems, load balancing and data consistency. It endows the systems
with predictive models based on AI improved ability to forecast user demands.
Microservices would also take care of different scales during uneven traffic
patterns. Hence, both aspects ensure better handling of peak loads and spikes
while minimizing delays and ensuring high service quality. A comparison was
made between traditional reservation models, which are monolithic and the new
model of AI-Microservices. Comparatively, the analysis results state that there
is a drastic improvement in processing times where the system uptime and
resource utilization proved the capability of AI and the microservices in
transforming the travel industry in terms of reservation. This research work
focused on AI and Microservices towards real-time optimization, providing
critical insight into how to move forward with practical recommendations for
upgrading travel reservation systems with this technology.

æè¦ï¼æéç¢æ¥­å¿«éæé·ï¼æåäºé è¨ç³»çµ±ä¸­å³ææä½³åçéæ±ï¼éåç³»çµ±å¯ä»¥èçé¾å¤§çè³æåäº¤æéãæ¬ç ç©¶æåºä¸åæ··åæ¶æ§ï¼å®çµåäººå·¥æºæ§åå¾®æåæ¹æ³ä¾æä½³åç³»çµ±æè½ãäººå·¥æºæ§æ¼ç®æ³é æ¸¬éæ±æ¨¡å¼ï¼æä½³åè³æºéç½®ï¼ä¸¦å å¼·ç±å¾®æåæ¶æ§é©åçæ±ºç­å¶å®ï¼å æ­¤åæ£ç³»çµ±åä»¶ä»¥å©æ¼æ´åæ§ãå®¹é¯è½ååæ¸å°åæ©æéãææä¾çæ¨¡åå°æ³¨æ¼èæéé è¨ç³»çµ±ç¸éçä¸»è¦åé¡ï¼ä¾å¦ç³»çµ±å»¶é²ãè² è¼å¹³è¡¡åè³æä¸è´æ§ãå®è³¦äºç³»çµ±é æ¸¬æ¨¡åï¼åºæ¼äººå·¥æºæ§æåé æ¸¬ä½¿ç¨èéæ±çè½åãå¾®æåä¹æå¨æµéæ¨¡å¼ä¸åæèçä¸åçè¦æ¨¡ãå æ­¤ï¼éå©åé¢åç¢ºä¿è½æ´å¥½å°èçå°å³°è² è¼åæµéæ¿å¢ï¼åæå°å»¶é²éå°æä½ä¸¦ç¢ºä¿é«æååè³ªãæ¯è¼å³çµ±çé è¨æ¨¡åï¼å®é«å¼ï¼åæ°ç AI-å¾®æåæ¨¡åãæ¯è¼ä¹ä¸ï¼åæçµææåºèçæéæé¡¯èæ¹åï¼å¶ä¸­ç³»çµ±æ­£å¸¸éè¡æéåè³æºä½¿ç¨çè­æäºäººå·¥æºæ§åå¾®æåå¨é è¨æ¹é¢è½åæéç¢æ¥­çè½åãéé ç ç©¶å·¥ä½å°æ³¨æ¼äººå·¥æºæ§åå¾®æåï¼ä»¥å¯¦ç¾å³ææä½³åï¼æä¾ééµè¦è§£ï¼èªªæå¦ä½ééå¯¦ç¨å»ºè­°ï¼ä½¿ç¨éé æè¡åç´æéé è¨ç³»çµ±ã

##### **Advancing Music Therapy: Integrating Eastern Five-Element Music Theory and Western Techniques with AI in the Novel Five-Element Harmony System**
2412.06600v2 by Yubo Zhou, Weizhen Bian, Kaitai Zhang, Xiaohan Gu

In traditional medical practices, music therapy has proven effective in
treating various psychological and physiological ailments. Particularly in
Eastern traditions, the Five Elements Music Therapy (FEMT), rooted in
traditional Chinese medicine, possesses profound cultural significance and
unique therapeutic philosophies. With the rapid advancement of Information
Technology and Artificial Intelligence, applying these modern technologies to
FEMT could enhance the personalization and cultural relevance of the therapy
and potentially improve therapeutic outcomes. In this article, we developed a
music therapy system for the first time by applying the theory of the five
elements in music therapy to practice. This innovative approach integrates
advanced Information Technology and Artificial Intelligence with Five-Element
Music Therapy (FEMT) to enhance personalized music therapy practices. As
traditional music therapy predominantly follows Western methodologies, the
unique aspects of Eastern practices, specifically the Five-Element theory from
traditional Chinese medicine, should be considered. This system aims to bridge
this gap by utilizing computational technologies to provide a more
personalized, culturally relevant, and therapeutically effective music therapy
experience.

æè¦ï¼å¨å³çµ±é«å­¸ä¸­ï¼é³æ¨çæ³å·²è¢«è­å¯¦è½æææ²»çåç¨®å¿çåççç¾çãç¹å¥æ¯å¨æ±æ¹å³çµ±ä¸­ï¼æ ¹æ¤æ¼ä¸­é«çäºè¡é³æ¨çæ³ (FEMT) å·ææ·±é çæåæç¾©åç¨ç¹çæ²»ççå¿µãé¨èè³è¨ç§æåäººå·¥æºæ§çå¿«éç¼å±ï¼å°éäºç¾ä»£æè¡æç¨æ¼ FEMT å¯ä»¥å¢å¼·çæ³çåäººååæåç¸éæ§ï¼ä¸¦æå¯è½æ¹åæ²»çææãå¨æ¬æä¸­ï¼æåé¦æ¬¡ééå°é³æ¨çæ³ä¸­çäºè¡çè«æç¨æ¼å¯¦è¸ï¼éç¼äºä¸åé³æ¨çæ³ç³»çµ±ãéç¨®åµæ°æ¹æ³å°åé²çè³è¨ç§æåäººå·¥æºæ§èäºè¡é³æ¨çæ³ (FEMT) ç¸çµåï¼ä»¥å¢å¼·åæ§åçé³æ¨çæ³å¯¦åãç±æ¼å³çµ±é³æ¨çæ³ä¸»è¦éµå¾ªè¥¿æ¹æ¹æ³ï¼å æ­¤æèæ®æ±æ¹å¯¦åçç¨ç¹æ¹é¢ï¼ç¹å¥æ¯ä¸­é«çäºè¡çè«ãæ­¤ç³»çµ±æ¨å¨å©ç¨è¨ç®æè¡å½åéä¸å·®è·ï¼ä»¥æä¾æ´åäººåãæåç¸éä¸æ²»çæææ´å¥½çé³æ¨çæ³é«é©ã

##### **HES-UNet: A U-Net for Hepatic Echinococcosis Lesion Segmentation**
2412.06530v1 by Jiayan Chen, Kai Li, Zhanjin Wang, Zhan Wang, Jianqiang Huang

Hepatic echinococcosis (HE) is a prevalent disease in economically
underdeveloped pastoral areas, where adequate medical resources are usually
lacking. Existing methods often ignore multi-scale feature fusion or focus only
on feature fusion between adjacent levels, which may lead to insufficient
feature fusion. To address these issues, we propose HES-UNet, an efficient and
accurate model for HE lesion segmentation. This model combines convolutional
layers and attention modules to capture local and global features. During
downsampling, the multi-directional downsampling block (MDB) is employed to
integrate high-frequency and low-frequency features, effectively extracting
image details. The multi-scale aggregation block (MAB) aggregates multi-scale
feature information. In contrast, the multi-scale upsampling Block (MUB) learns
highly abstract features and supplies this information to the skip connection
module to fuse multi-scale features. Due to the distinct regional
characteristics of HE, there is currently no publicly available high-quality
dataset for training our model. We collected CT slice data from 268 patients at
a certain hospital to train and evaluate the model. The experimental results
show that HES-UNet achieves state-of-the-art performance on our dataset,
achieving an overall Dice Similarity Coefficient (DSC) of 89.21%, which is
1.09% higher than that of TransUNet. The project page is available at
https://chenjiayan-qhu.github.io/HES-UNet-page.

æè¦ï¼èåè²çï¼HEï¼å¨ç¶æ¿è½å¾ççç§å°åçè¡ï¼é£è£¡éå¸¸ç¼ºä¹è¶³å¤ çé«çè³æºãç¾ææ¹æ³éå¸¸å¿½ç¥å¤å°ºåº¦ç¹å¾µèåï¼æåéæ³¨ç¸é°å±¤ä¹éçç¹å¾µèåï¼éå¯è½å°è´ç¹å¾µèåä¸è¶³ãçºäºè§£æ±ºéäºåé¡ï¼æåæåºäº HES-UNetï¼éæ¯ä¸ç¨®ç¨æ¼ HE çç¶åå²çé«æä¸æºç¢ºçæ¨¡åãæ­¤æ¨¡åçµåäºå·ç©å±¤åæ³¨æåæ¨¡çµï¼ä»¥æ·åå±é¨åå¨å±ç¹å¾µãå¨éæ¡æ¨£éç¨ä¸­ï¼æ¡ç¨å¤åéæ¡æ¨£åå¡ (MDB) ä¾æ´åé«é »åä½é »ç¹å¾µï¼æææåå½±åç´°ç¯ãå¤å°ºåº¦èååå¡ (MAB) èåå¤å°ºåº¦ç¹å¾µè³è¨ãç¸åï¼å¤å°ºåº¦ä¸æ¡æ¨£åå¡ (MUB) æå­¸ç¿é«åº¦æ½è±¡çç¹å¾µï¼ä¸¦å°æ­¤è³è¨æä¾çµ¦è·³èºé£æ¥æ¨¡çµï¼ä»¥èåå¤å°ºåº¦ç¹å¾µãç±æ¼ HE çååç¹å¾µä¸åï¼ç®åæ²æå¬éå¯ç¨çé«åè³ªè³æéå¯ä¾è¨ç·´æåçæ¨¡åãæåå¾æå®¶é«é¢æ¶éäº 268 ä½æ£èç CT åçè³æï¼ä»¥è¨ç·´åè©ä¼°æ¨¡åãå¯¦é©çµæè¡¨æï¼HES-UNet å¨æåçè³æéä¸éå°äºæåé²çæè½ï¼æ´é« Dice ç¸ä¼¼æ§ä¿æ¸ (DSC) éå° 89.21%ï¼æ¯ TransUNet é« 1.09%ãå°æ¡é é¢å¯æ¼ https://chenjiayan-qhu.github.io/HES-UNet-page åå¾ã

##### **Simulating Human-like Daily Activities with Desire-driven Autonomy**
2412.06435v1 by Yiding Wang, Yuxuan Chen, Fangwei Zhong, Long Ma, Yizhou Wang

Existing task-oriented AI agents often depend on explicit instructions or
external rewards, limiting their ability to be driven by intrinsic motivations
like humans. In this paper, we present a desire-driven autonomy framework to
guide a Large Language Model-based (LLM-based) agent to simulate human-like
daily activities. In contrast to previous agents, our Desire-driven Autonomous
Agent (D2A) operates on the principle of intrinsic desire, allowing it to
propose and select tasks that fulfill its motivational framework autonomously.
Inspired by the Theory of Needs, the motivational framework incorporates an
understanding of human-like desires, such as the need for social interaction,
personal fulfillment, and self-care. Utilizing a desire-driven task generation
mechanism, the agent evaluates its current state and takes a sequence of
activities aligned with its intrinsic motivations. Through simulations, we
demonstrate that our Desire-driven Autonomous Agent (D2A) generates coherent,
contextually relevant daily activities while exhibiting variability and
adaptability similar to human behavior. A comparative analysis with other
LLM-based frameworks demonstrates that our approach significantly enhances the
rationality of the simulated activities.

æè¦ï¼ç¾æçä»»åå°å AI ä»£çéå¸¸ä¾è³´æç¢ºçæç¤ºæå¤é¨çåµï¼ééå¶äºå®ååäººé¡ä¸æ¨£ç±å§å¨åæ©é©åçè½åãå¨æ¬æä¸­ï¼æåæåºäºä¸åæ¾æé©åçèªä¸»æ¡æ¶ï¼ä»¥æå°åºæ¼å¤§åèªè¨æ¨¡å (LLM) çä»£çæ¨¡æ¬é¡äººçæ¥å¸¸æ´»åãèä¹åçä»£çä¸åï¼æåçæ¾æé©åèªä¸»ä»£ç (D2A) éµå¾ªå§å¨æ¾æçååï¼åè¨±å®èªä¸»æåºåé¸æç¬¦åå¶åæ©æ¡æ¶çä»»åãåéæ±çè«çåç¼ï¼åæ©æ¡æ¶åå«å°é¡äººæ¾æççè§£ï¼ä¾å¦ç¤¾æäºåãåäººæ»¿è¶³åèªæä¿å¥çéè¦ãå©ç¨æ¾æé©åä»»åçææ©å¶ï¼ä»£çè©ä¼°å¶ç¶åçæä¸¦æ¡åä¸ç³»åèå¶å§å¨åæ©ä¸è´çæ´»åãééæ¨¡æ¬ï¼æåè­æäºæåçæ¾æé©åèªä¸»ä»£ç (D2A) ç¢çäºé£è²«ãèä¸ä¸æç¸éçæ¥å¸¸æ´»åï¼åæè¡¨ç¾åºèäººé¡è¡çºç¸ä¼¼çå¯è®æ§åé©ææ§ãèå¶ä»åºæ¼ LLM çæ¡æ¶é²è¡æ¯è¼åæè¡¨æï¼æåçåæ³é¡¯èæé«äºæ¨¡æ¬æ´»åçåçæ§ã

##### **CAD-Unet: A Capsule Network-Enhanced Unet Architecture for Accurate Segmentation of COVID-19 Lung Infections from CT Images**
2412.06314v1 by Yijie Dang, Weijun Ma, Xiaohu Luo

Since the outbreak of the COVID-19 pandemic in 2019, medical imaging has
emerged as a primary modality for diagnosing COVID-19 pneumonia. In clinical
settings, the segmentation of lung infections from computed tomography images
enables rapid and accurate quantification and diagnosis of COVID-19.
Segmentation of COVID-19 infections in the lungs poses a formidable challenge,
primarily due to the indistinct boundaries and limited contrast presented by
ground glass opacity manifestations. Moreover, the confounding similarity
between infiltrates, lung tissues, and lung walls further complicates this
segmentation task. To address these challenges, this paper introduces a novel
deep network architecture, called CAD-Unet, for segmenting COVID-19 lung
infections. In this architecture, capsule networks are incorporated into the
existing Unet framework. Capsule networks represent a novel network
architecture that differs from traditional convolutional neural networks. They
utilize vectors for information transfer among capsules, facilitating the
extraction of intricate lesion spatial information. Additionally, we design a
capsule encoder path and establish a coupling path between the unet encoder and
the capsule encoder. This design maximizes the complementary advantages of both
network structures while achieving efficient information fusion. \noindent
Finally, extensive experiments are conducted on four publicly available
datasets, encompassing binary segmentation tasks and multi-class segmentation
tasks. The experimental results demonstrate the superior segmentation
performance of the proposed model. The code has been released at:
https://github.com/AmanoTooko-jie/CAD-Unet.

æè¦ï¼èª 2019 å¹´ COVID-19 å¤§æµè¡çåä»¥æ¥ï¼å»å­¦å½±åå·²æä¸ºè¯æ­ COVID-19 èºççä¸»è¦æ¹å¼ãå¨ä¸´åºç¯å¢ä¸­ï¼ä»è®¡ç®æºæ­å±æ«æå¾åä¸­åå²èºé¨ææï¼å¯ä»¥å¿«éãåç¡®å°éååè¯æ­ COVID-19ãåå²èºé¨ä¸­ç COVID-19 æææ¯ä¸ä¸ªè°å·¨çææï¼è¿ä¸»è¦æ¯ç±äºæ¯ç»çæ ·åç°åºçè¾¹çä¸æ¸æ°ä¸å¯¹æ¯åº¦æéãæ­¤å¤ï¼æµ¸æ¶¦ãèºç»ç»åèºå£ä¹é´çæ··æ·ç¸ä¼¼æ§è¿ä¸æ­¥å¤æåäºè¿é¡¹åå²ä»»å¡ãä¸ºäºåºå¯¹è¿äºææï¼æ¬æä»ç»äºä¸ç§æ°é¢çæ·±åº¦ç½ç»æ¶æï¼ç§°ä¸º CAD-Unetï¼ç¨äºåå² COVID-19 èºé¨ææãå¨æ­¤æ¶æä¸­ï¼è¶åç½ç»è¢«çº³å¥ç°æç Unet æ¡æ¶ä¸­ãè¶åç½ç»ä»£è¡¨äºä¸ç§æ°é¢çç½ç»æ¶æï¼å®ä¸åäºä¼ ç»çå·ç§¯ç¥ç»ç½ç»ãå®ä»¬å©ç¨åéå¨è¶åä¹é´è¿è¡ä¿¡æ¯ä¼ è¾ï¼ä¿è¿äºå¤æçåç©ºé´ä¿¡æ¯çæåãæ­¤å¤ï¼æä»¬è®¾è®¡äºä¸ä¸ªè¶åç¼ç å¨è·¯å¾ï¼å¹¶å¨ unet ç¼ç å¨åè¶åç¼ç å¨ä¹é´å»ºç«äºä¸ä¸ªè¦åè·¯å¾ãè¿ç§è®¾è®¡æå¤§éåº¦å°åæ¥äºä¸¤ç§ç½ç»ç»æçäºè¡¥ä¼å¿ï¼åæ¶å®ç°äºé«æçä¿¡æ¯èåã\noindent
æåï¼å¨åä¸ªå¬å¼å¯ç¨çæ°æ®éä¸è¿è¡äºå¹¿æ³çå®éªï¼åæ¬äºè¿å¶åå²ä»»å¡åå¤ç±»åå²ä»»å¡ãå®éªç»æè¯æäºææåºæ¨¡åçåè¶åå²æ§è½ãè¯¥ä»£ç å·²åå¸å¨ï¼
https://github.com/AmanoTooko-jie/CAD-Unetã

##### **A Lightweight U-like Network Utilizing Neural Memory Ordinary Differential Equations for Slimming the Decoder**
2412.06262v1 by Quansong He, Xiaojun Yao, Jun Wu, Zhang Yi, Tao He

In recent years, advanced U-like networks have demonstrated remarkable
performance in medical image segmentation tasks. However, their drawbacks,
including excessive parameters, high computational complexity, and slow
inference speed, pose challenges for practical implementation in scenarios with
limited computational resources. Existing lightweight U-like networks have
alleviated some of these problems, but they often have pre-designed structures
and consist of inseparable modules, limiting their application scenarios. In
this paper, we propose three plug-and-play decoders by employing different
discretization methods of the neural memory Ordinary Differential Equations
(nmODEs). These decoders integrate features at various levels of abstraction by
processing information from skip connections and performing numerical
operations on upward path. Through experiments on the PH2, ISIC2017, and
ISIC2018 datasets, we embed these decoders into different U-like networks,
demonstrating their effectiveness in significantly reducing the number of
parameters and FLOPs while maintaining performance. In summary, the proposed
discretized nmODEs decoders are capable of reducing the number of parameters by
about 20% ~ 50% and FLOPs by up to 74%, while possessing the potential to adapt
to all U-like networks. Our code is available at
https://github.com/nayutayuki/Lightweight-nmODE-Decoders-For-U-like-networks.

æè¦ï¼è¿å¹´ä¾ï¼åé²ç U åç¶²è·¯å¨é«å­¸å½±ååå²ä»»åä¸­å±ç¾åºåè¶çè¡¨ç¾ãç¶èï¼å®åçç¼ºé»åæ¬éå¤çåæ¸ãé«éç®è¤éåº¦åç·©æ¢çæ¨è«éåº¦ï¼å°å¨éç®è³æºæéçææ³ä¸å¯¦éå·è¡æ§æææ°ãç¾æçè¼éç´ U åç¶²è·¯å·²ç¶æ¸è¼äºéäºåé¡ï¼ä½å®åéå¸¸æé åè¨­è¨ççµæ§ï¼ä¸¦åå«ä¸å¯åé¢çæ¨¡çµï¼éå¶äºå®åçæç¨å ´æ¯ãå¨æ¬æä¸­ï¼æåééæ¡ç¨ç¥ç¶è¨æ¶å¸¸å¾®åæ¹ç¨å¼ (nmODE) çä¸åé¢æ£åæ¹æ³ï¼æåºäºä¸åå³æå³ç¨çè§£ç¢¼å¨ãéäºè§£ç¢¼å¨ééèçä¾èªè·³èºé£æ¥çè³è¨ï¼ä¸¦å¨åä¸è·¯å¾ä¸å·è¡æ¸å¼éç®ï¼æ´åäºä¸åæ½è±¡å±¤ç´çç¹å¾µãééå¨ PH2ãISIC2017 å ISIC2018 è³æéä¸çå¯¦é©ï¼æåå°éäºè§£ç¢¼å¨åµå¥å°ä¸åç U åç¶²è·¯ä¸­ï¼è­æå®åå¨é¡¯èæ¸å°åæ¸å FLOP çåæï¼éè½ç¶­ææè½ãç¸½ä¹ï¼ææåºçé¢æ£ nmODE è§£ç¢¼å¨è½å¤ å°åæ¸æ¸éæ¸å°ç´ 20% ~ 50%ï¼FLOP æå¤æ¸å° 74%ï¼åæå·åé©æææ U åç¶²è·¯çæ½åãæåçç¨å¼ç¢¼å¯ä»¥å¨ https://github.com/nayutayuki/Lightweight-nmODE-Decoders-For-U-like-networks åå¾ã

##### **MSCrackMamba: Leveraging Vision Mamba for Crack Detection in Fused Multispectral Imagery**
2412.06211v1 by Qinfeng Zhu, Yuan Fang, Lei Fan

Crack detection is a critical task in structural health monitoring, aimed at
assessing the structural integrity of bridges, buildings, and roads to prevent
potential failures. Vision-based crack detection has become the mainstream
approach due to its ease of implementation and effectiveness. Fusing infrared
(IR) channels with red, green and blue (RGB) channels can enhance feature
representation and thus improve crack detection. However, IR and RGB channels
often differ in resolution. To align them, higher-resolution RGB images
typically need to be downsampled to match the IR image resolution, which leads
to the loss of fine details. Moreover, crack detection performance is
restricted by the limited receptive fields and high computational complexity of
traditional image segmentation networks. Inspired by the recently proposed
Mamba neural architecture, this study introduces a two-stage paradigm called
MSCrackMamba, which leverages Vision Mamba along with a super-resolution
network to address these challenges. Specifically, to align IR and RGB
channels, we first apply super-resolution to IR channels to match the
resolution of RGB channels for data fusion. Vision Mamba is then adopted as the
backbone network, while UperNet is employed as the decoder for crack detection.
Our approach is validated on the large-scale Crack Detection dataset Crack900,
demonstrating an improvement of 3.55% in mIoU compared to the best-performing
baseline methods.

æè¦ï¼è£ç¸«åµæ¸¬å¨çµæ§å¥åº·ç£æ¸¬ä¸­æ¯ä¸é éè¦çä»»åï¼æ¨å¨è©ä¼°æ©æ¨ãå»ºç¯ç©åéè·¯ççµæ§å®æ´æ§ï¼ä»¥é²æ­¢æ½å¨çæéãåºæ¼è¦è¦ºçè£ç¸«åµæ¸¬ç±æ¼å¶ææ¼å¯¦ä½åæææ§ï¼å·²æçºä¸»æµæ¹æ³ãå°ç´å¤ç· (IR) ééèç´è²ãç¶ è²åèè² (RGB) ééèåå¯ä»¥å¢å¼·ç¹å¾µè¡¨ç¤ºï¼é²èæ¹åè£ç¸«åµæ¸¬ãç¶èï¼IR å RGB éééå¸¸è§£æåº¦ä¸åãçºäºå°é½å®åï¼éå¸¸éè¦å°è¼é«è§£æåº¦ç RGB å½±åé²è¡éæ¡æ¨£ä»¥å¹é IR å½±åè§£æåº¦ï¼éæå°è´ç²¾ç´°ç´°ç¯çéºå¤±ãæ­¤å¤ï¼è£ç¸«åµæ¸¬æè½åå°å³çµ±å½±ååå²ç¶²è·¯æéçæåéåé«éç®è¤éåº¦çéå¶ãåè¿ææåºç Mamba ç¥ç¶æ¶æ§åç¼ï¼æ¬ç ç©¶å¼å¥äºä¸åç¨±çº MSCrackMamba çå©éæ®µç¯ä¾ï¼å®å©ç¨ Vision Mamba åè¶è§£æåº¦ç¶²è·¯ä¾æå°éäºææ°ãå·é«ä¾èªªï¼çºäºå°é½ IR å RGB ééï¼æåé¦åå° IR ééæç¨è¶è§£æåº¦ï¼ä»¥å¹é RGB ééçè§£æåº¦ï¼ä»¥é²è¡è³æèåãç¶å¾æ¡ç¨ Vision Mamba ä½çºéª¨å¹¹ç¶²è·¯ï¼åææ¡ç¨ UperNet ä½çºè£ç¸«åµæ¸¬çè§£ç¢¼å¨ãæåçåæ³å·²å¨å¤§åè£ç¸«åµæ¸¬è³æé Crack900 ä¸­å¾å°é©è­ï¼èæè½æä½³çåºæºæ¹æ³ç¸æ¯ï¼mIoU æåäº 3.55%ã

##### **Balancing Efficiency and Effectiveness: An LLM-Infused Approach for Optimized CTR Prediction**
2412.06860v1 by Guoxiao Zhang, Yi Wei, Yadong Zhang, Huajian Feng, Qiang Liu

Click-Through Rate (CTR) prediction is essential in online advertising, where
semantic information plays a pivotal role in shaping user decisions and
enhancing CTR effectiveness. Capturing and modeling deep semantic information,
such as a user's preference for "H\"aagen-Dazs' HEAVEN strawberry light ice
cream" due to its health-conscious and premium attributes, is challenging.
Traditional semantic modeling often overlooks these intricate details at the
user and item levels. To bridge this gap, we introduce a novel approach that
models deep semantic information end-to-end, leveraging the comprehensive world
knowledge capabilities of Large Language Models (LLMs). Our proposed
LLM-infused CTR prediction framework(Multi-level Deep Semantic Information
Infused CTR model via Distillation, MSD) is designed to uncover deep semantic
insights by utilizing LLMs to extract and distill critical information into a
smaller, more efficient model, enabling seamless end-to-end training and
inference. Importantly, our framework is carefully designed to balance
efficiency and effectiveness, ensuring that the model not only achieves high
performance but also operates with optimal resource utilization. Online A/B
tests conducted on the Meituan sponsored-search system demonstrate that our
method significantly outperforms baseline models in terms of Cost Per Mile
(CPM) and CTR, validating its effectiveness, scalability, and balanced approach
in real-world applications.

æè¦ï¼é»æç (CTR) é æ¸¬å¨ç·ä¸å»£åä¸­è³ééè¦ï¼å¶ä¸­èªæè³è¨å¨å¡é ä½¿ç¨èæ±ºç­åæå CTR æçæ¹é¢æ®æ¼èééµè§è²ãæ·ååå»ºæ¨¡æ·±å¥çèªæè³è¨ï¼ä¾å¦ä½¿ç¨èåå¥½ãH\"aagen-Dazs' HEAVEN èèè¼çå°æ·æ·ãï¼å çºå®å·ææ³¨éå¥åº·åé«ç´çå±¬æ§ï¼æ¯ä¸é ææ°ãå³çµ±çèªæå»ºæ¨¡éå¸¸æå¿½ç¥ä½¿ç¨èåé ç®å±¤ç´çéäºè¤éç´°ç¯ãçºäºå½è£æ­¤å·®è·ï¼æåæåºäºä¸ç¨®åµæ°çæ¹æ³ï¼è©²æ¹æ³å¯ä»¥ç«¯å°ç«¯å°å»ºæ¨¡æ·±å¥èªæè³è¨ï¼ä¸¦å©ç¨å¤§åèªè¨æ¨¡å (LLM) çå¨é¢ä¸çç¥è­è½åãæåæåºç LLM æ³¨å¥ CTR é æ¸¬æ¶æ§ï¼ééç¥è­èåçå¤å±¤ç´æ·±å¥èªæè³è¨æ³¨å¥ CTR æ¨¡åï¼MSDï¼æ¨å¨ééå©ç¨ LLM èååæçééµè³è¨å°ä¸åæ´å°ãæ´ææççæ¨¡åä¸­ï¼ä¾ç¼ææ·±å¥çèªææ´å¯ï¼å¯¦ç¾ç¡ç¸«ç«¯å°ç«¯è¨ç·´åæ¨è«ãéè¦çæ¯ï¼æåçæ¶æ§ç¶éä»ç´°è¨­è¨ï¼ä»¥å¹³è¡¡æçåæè½ï¼ç¢ºä¿æ¨¡åä¸åè½éæé«æ§è½ï¼éè½ä»¥æä½³è³æºå©ç¨çéä½ãå¨ç¾åè´å©æå°ç³»çµ±ä¸é²è¡çç·ä¸ A/B æ¸¬è©¦è­æï¼æåçæ¨¡åå¨æ¯åæ¬¡ææ¬ (CPM) å CTR æ¹é¢é¡¯èåªæ¼åºç·æ¨¡åï¼é©è­äºå¶å¨å¯¦éæç¨ä¸­çæææ§ãå¯æ´åæ§åå¹³è¡¡æ¹æ³ã

##### **MMedPO: Aligning Medical Vision-Language Models with Clinical-Aware Multimodal Preference Optimization**
2412.06141v1 by Kangyu Zhu, Peng Xia, Yun Li, Hongtu Zhu, Sheng Wang, Huaxiu Yao

The advancement of Large Vision-Language Models (LVLMs) has propelled their
application in the medical field. However, Medical LVLMs (Med-LVLMs) encounter
factuality challenges due to modality misalignment, where the models prioritize
textual knowledge over visual input, leading to hallucinations that contradict
information in medical images. Previous attempts to enhance modality alignment
in Med-LVLMs through preference optimization have inadequately mitigated
clinical relevance in preference data, making these samples easily
distinguishable and reducing alignment effectiveness. To address this
challenge, we propose MMedPO, a novel multimodal medical preference
optimization approach that considers the clinical relevance of preference
samples to enhance Med-LVLM alignment. MMedPO curates multimodal preference
data by introducing two types of dispreference: (1) plausible hallucinations
injected through target Med-LVLMs or GPT-4o to produce medically inaccurate
responses, and (2) lesion region neglect achieved through local lesion-noising,
disrupting visual understanding of critical areas. We then calculate clinical
relevance for each sample based on scores from multiple Med-LLMs and visual
tools, and integrate these scores into the preference optimization process as
weights, enabling effective alignment. Our experiments demonstrate that MMedPO
significantly enhances factual accuracy in Med-LVLMs, achieving substantial
improvements over existing preference optimization methods by averaging 14.2%
and 51.7% across the Med-VQA and report generation tasks. Our code are
available in https://github.com/aiming-lab/MMedPO.

æè¦ï¼å¤§åè¦è¦ºèªè¨æ¨¡å (LVLMs) çé²æ­¥æ¨åäºå®åå¨é«çé åçæç¨ãç¶èï¼é«å­¸ LVLMs (Med-LVLMs) ç±æ¼æ¨¡æé¯ä½èéå°äºå¯¦ææ°ï¼å¶ä¸­æ¨¡ååªåèæ®æå­ç¥è­èéè¦è¦ºè¼¸å¥ï¼å°è´å¹»è¦ºèé«å­¸å½±åä¸­çè³è¨ç¸çç¾ãåååè©¦ééåå¥½æä½³åä¾å¢å¼· Med-LVLMs ä¸­çæ¨¡æå°é½ï¼å¨åå¥½è³æä¸­ä¸è¶³ä»¥æ¸è¼è¨åºç¸éæ§ï¼ä½¿å¾éäºç¯ä¾å®¹æååï¼ä¸¦éä½å°é½ææãçºäºæå°éé ææ°ï¼æåæåº MMedPOï¼ä¸ç¨®æ°çå¤æ¨¡æé«å­¸åå¥½æä½³åæ¹æ³ï¼å®èæ®åå¥½ç¯ä¾çè¨åºç¸éæ§ï¼ä»¥å¢å¼· Med-LVLM å°é½ãMMedPO ééå¼å¥å©ç¨®é¡åçååå¥½ä¾ç®¡çå¤æ¨¡æåå¥½è³æï¼(1) åççå¹»è¦ºééç®æ¨ Med-LVLMs æ GPT-4o æ³¨å¥ï¼ä»¥ç¢çé«å­¸ä¸ä¸æºç¢ºçåæï¼ä»¥å (2) ééå±é¨çç¶éè¨å¯¦ç¾çç¶ååå¿½ç¥ï¼ç ´å£å°ééµååçè¦è¦ºçè§£ãç¶å¾ï¼æåæ ¹æä¾èªå¤å Med-LLMs åè¦è¦ºå·¥å·çåæ¸è¨ç®æ¯åç¯ä¾çè¨åºç¸éæ§ï¼ä¸¦å°éäºåæ¸ä½çºæ¬éæ´åå°åå¥½æä½³åéç¨ä¸­ï¼ä»¥å¯¦ç¾ææå°é½ãæåçå¯¦é©è­æï¼MMedPO æé¡¯å¢å¼·äº Med-LVLMs ä¸­çäºå¯¦æºç¢ºæ§ï¼å¨ Med-VQA åå ±åçæä»»åä¸­ï¼å¹³ååå¥æ¯ç¾æçåå¥½æä½³åæ¹æ³æé«äº 14.2% å 51.7%ãæåçç¨å¼ç¢¼å¯ä»¥å¨ https://github.com/aiming-lab/MMedPO ä¸­åå¾ã


### LLM
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-12-19**|**Scaling 4D Representations**|JoÃ£o Carreira et.al.|[2412.15212v1](http://arxiv.org/abs/2412.15212v1)|null|
|**2024-12-19**|**PRIMA: Multi-Image Vision-Language Models for Reasoning Segmentation**|Muntasir Wahed et.al.|[2412.15209v1](http://arxiv.org/abs/2412.15209v1)|null|
|**2024-12-19**|**LongBench v2: Towards Deeper Understanding and Reasoning on Realistic Long-context Multitasks**|Yushi Bai et.al.|[2412.15204v1](http://arxiv.org/abs/2412.15204v1)|null|
|**2024-12-19**|**DI-PCG: Diffusion-based Efficient Inverse Procedural Content Generation for High-quality 3D Asset Creation**|Wang Zhao et.al.|[2412.15200v1](http://arxiv.org/abs/2412.15200v1)|null|
|**2024-12-19**|**MMLU-CF: A Contamination-free Multi-task Language Understanding Benchmark**|Qihao Zhao et.al.|[2412.15194v1](http://arxiv.org/abs/2412.15194v1)|null|
|**2024-12-19**|**Face the Facts! Evaluating RAG-based Fact-checking Pipelines in Realistic Settings**|Daniel Russo et.al.|[2412.15189v1](http://arxiv.org/abs/2412.15189v1)|[link](https://github.com/drusso98/face-the-facts)|
|**2024-12-19**|**LlamaFusion: Adapting Pretrained Language Models for Multimodal Generation**|Weijia Shi et.al.|[2412.15188v1](http://arxiv.org/abs/2412.15188v1)|null|
|**2024-12-19**|**Critical-Questions-of-Thought: Steering LLM reasoning with Argumentative Querying**|Federico Castagna et.al.|[2412.15177v1](http://arxiv.org/abs/2412.15177v1)|null|
|**2024-12-19**|**Human-Humanoid Robots Cross-Embodiment Behavior-Skill Transfer Using Decomposed Adversarial Learning from Demonstration**|Junjia Liu et.al.|[2412.15166v1](http://arxiv.org/abs/2412.15166v1)|null|
|**2024-12-19**|**Prompt-A-Video: Prompt Your Video Diffusion Model via Preference-Aligned LLM**|Yatai Ji et.al.|[2412.15156v1](http://arxiv.org/abs/2412.15156v1)|[link](https://github.com/jiyt17/prompt-a-video)|
|**2024-12-19**|**Language Models as Continuous Self-Evolving Data Engineers**|Peidong Wang et.al.|[2412.15151v1](http://arxiv.org/abs/2412.15151v1)|null|
|**2024-12-19**|**Leveraging Color Channel Independence for Improved Unsupervised Object Detection**|Bastian JÃ¤ckl et.al.|[2412.15150v1](http://arxiv.org/abs/2412.15150v1)|null|
|**2024-12-19**|**Probabilistic Strategy Logic with Degrees of Observability**|Chunyan Mu et.al.|[2412.15135v1](http://arxiv.org/abs/2412.15135v1)|null|
|**2024-12-19**|**Jet: A Modern Transformer-Based Normalizing Flow**|Alexander Kolesnikov et.al.|[2412.15129v1](http://arxiv.org/abs/2412.15129v1)|null|
|**2024-12-19**|**Adaptive Pruning for Large Language Models with Structural Importance Awareness**|Haotian Zheng et.al.|[2412.15127v1](http://arxiv.org/abs/2412.15127v1)|null|
|**2024-12-19**|**Outcome-Refining Process Supervision for Code Generation**|Zhuohao Yu et.al.|[2412.15118v1](http://arxiv.org/abs/2412.15118v1)|null|
|**2024-12-19**|**Qwen2.5 Technical Report**|Qwen et.al.|[2412.15115v1](http://arxiv.org/abs/2412.15115v1)|null|
|**2024-12-19**|**Associative memory inspires improvements for in-context learning using a novel attention residual stream architecture**|Thomas F Burns et.al.|[2412.15113v1](http://arxiv.org/abs/2412.15113v1)|[link](https://github.com/tfburns/amicl-and-residual-attention-streams)|
|**2024-12-19**|**Exploiting sparse structures and synergy designs to advance situational awareness of electrical power grid**|Shimiao Li et.al.|[2412.15105v1](http://arxiv.org/abs/2412.15105v1)|null|
|**2024-12-19**|**Review-Then-Refine: A Dynamic Framework for Multi-Hop Question Answering with Temporal Adaptability**|Xiangsen Chen et.al.|[2412.15101v1](http://arxiv.org/abs/2412.15101v1)|null|
|**2024-12-19**|**A Cross-Domain Study of the Use of Persuasion Techniques in Online Disinformation**|JoÃ£o A. Leite et.al.|[2412.15098v1](http://arxiv.org/abs/2412.15098v1)|null|
|**2024-12-19**|**A Full Transformer-based Framework for Automatic Pain Estimation using Videos**|Stefanos Gkikas et.al.|[2412.15095v1](http://arxiv.org/abs/2412.15095v1)|null|
|**2024-12-19**|**Learning Disentangled Equivariant Representation for Explicitly Controllable 3D Molecule Generation**|Haoran Liu et.al.|[2412.15086v1](http://arxiv.org/abs/2412.15086v1)|null|
|**2024-12-19**|**AceMath: Advancing Frontier Math Reasoning with Post-Training and Reward Modeling**|Zihan Liu et.al.|[2412.15084v1](http://arxiv.org/abs/2412.15084v1)|null|
|**2024-12-19**|**Till the Layers Collapse: Compressing a Deep Neural Network through the Lenses of Batch Normalization Layers**|Zhu Liao et.al.|[2412.15077v1](http://arxiv.org/abs/2412.15077v1)|null|
|**2024-12-19**|**ConfliBERT: A Language Model for Political Conflict**|Patrick T. Brandt et.al.|[2412.15060v1](http://arxiv.org/abs/2412.15060v1)|[link](https://github.com/eventdata/conflibert)|
|**2024-12-19**|**Measuring, Modeling, and Helping People Account for Privacy Risks in Online Self-Disclosures with AI**|Isadora Krsek et.al.|[2412.15047v1](http://arxiv.org/abs/2412.15047v1)|null|
|**2024-12-19**|**LLMs Lost in Translation: M-ALERT uncovers Cross-Linguistic Safety Gaps**|Felix Friedrich et.al.|[2412.15035v1](http://arxiv.org/abs/2412.15035v1)|null|
|**2024-12-19**|**Large Language Models and Code Security: A Systematic Literature Review**|Enna Basic et.al.|[2412.15004v1](http://arxiv.org/abs/2412.15004v1)|null|
|**2024-12-19**|**HSEvo: Elevating Automatic Heuristic Design with Diversity-Driven Harmony Search and Genetic Algorithm Using LLMs**|Pham Vu Tuan Dat et.al.|[2412.14995v1](http://arxiv.org/abs/2412.14995v1)|null|
|**2024-12-19**|**Chain-of-MetaWriting: Linguistic and Textual Analysis of How Small Language Models Write Young Students Texts**|Ioana Buhnila et.al.|[2412.14986v1](http://arxiv.org/abs/2412.14986v1)|null|
|**2024-12-19**|**Movie2Story: A framework for understanding videos and telling stories in the form of novel text**|Kangning Li et.al.|[2412.14965v1](http://arxiv.org/abs/2412.14965v1)|null|
|**2024-12-19**|**Knowledge Injection via Prompt Distillation**|Kalle KujanpÃ¤Ã¤ et.al.|[2412.14964v1](http://arxiv.org/abs/2412.14964v1)|null|
|**2024-12-19**|**Understanding the Dark Side of LLMs' Intrinsic Self-Correction**|Qingjie Zhang et.al.|[2412.14959v1](http://arxiv.org/abs/2412.14959v1)|null|
|**2024-12-19**|**Generalizing Constraint Models in Constraint Acquisition**|Dimos Tsouros et.al.|[2412.14950v1](http://arxiv.org/abs/2412.14950v1)|[link](https://github.com/dimosts/genconmodels)|
|**2024-12-19**|**RobustFT: Robust Supervised Fine-tuning for Large Language Models under Noisy Response**|Junyu Luo et.al.|[2412.14922v1](http://arxiv.org/abs/2412.14922v1)|[link](https://github.com/luo-junyu/robustft)|
|**2024-12-19**|**Dehallucinating Parallel Context Extension for Retrieval-Augmented Generation**|Zexiong Ma et.al.|[2412.14905v1](http://arxiv.org/abs/2412.14905v1)|null|
|**2024-12-19**|**Why language models collapse when trained on recursively generated text**|Lecheng Wang et.al.|[2412.14872v1](http://arxiv.org/abs/2412.14872v1)|null|
|**2024-12-19**|**AI-Powered Intracranial Hemorrhage Detection: A Co-Scale Convolutional Attention Model with Uncertainty-Based Fuzzy Integral Operator and Feature Screening**|Mehdi Hosseini Chagahi et.al.|[2412.14869v1](http://arxiv.org/abs/2412.14869v1)|null|
|**2024-12-19**|**Graph-Convolutional Networks: Named Entity Recognition and Large Language Model Embedding in Document Clustering**|Imed Keraghel et.al.|[2412.14867v1](http://arxiv.org/abs/2412.14867v1)|null|
|**2024-12-19**|**Think&Cite: Improving Attributed Text Generation with Self-Guided Tree Search and Progress Reward Modeling**|Junyi Li et.al.|[2412.14860v1](http://arxiv.org/abs/2412.14860v1)|null|
|**2024-12-19**|**DS$^2$-ABSA: Dual-Stream Data Synthesis with Label Refinement for Few-Shot Aspect-Based Sentiment Analysis**|Hongling Xu et.al.|[2412.14849v1](http://arxiv.org/abs/2412.14849v1)|[link](https://github.com/behappyplz/ds2-absa)|
|**2024-12-19**|**A Survey of RWKV**|Zhiyuan Li et.al.|[2412.14847v1](http://arxiv.org/abs/2412.14847v1)|null|
|**2024-12-19**|**Head and Neck Tumor Segmentation of MRI from Pre- and Mid-radiotherapy with Pre-training, Data Augmentation and Dual Flow UNet**|Litingyu Wang et.al.|[2412.14846v1](http://arxiv.org/abs/2412.14846v1)|[link](https://github.com/wltyby/hnts-mrg2024_train_code)|
|**2024-12-19**|**Mapping and Influencing the Political Ideology of Large Language Models using Synthetic Personas**|Pietro Bernardelle et.al.|[2412.14843v1](http://arxiv.org/abs/2412.14843v1)|null|
|**2024-12-19**|**Helping LLMs Improve Code Generation Using Feedback from Testing and Static Analysis**|Greta Dolcetti et.al.|[2412.14841v1](http://arxiv.org/abs/2412.14841v1)|null|
|**2024-12-19**|**DynamicKV: Task-Aware Adaptive KV Cache Compression for Long Context LLMs**|Xiabin Zhou et.al.|[2412.14838v1](http://arxiv.org/abs/2412.14838v1)|null|
|**2024-12-19**|**Progressive Multimodal Reasoning via Active Retrieval**|Guanting Dong et.al.|[2412.14835v1](http://arxiv.org/abs/2412.14835v1)|null|
|**2024-12-19**|**Mention Attention for Pronoun Translation**|Gongbo Tang et.al.|[2412.14829v1](http://arxiv.org/abs/2412.14829v1)|null|
|**2024-12-19**|**Answer Set Networks: Casting Answer Set Programming into Deep Learning**|Arseny Skryagin et.al.|[2412.14814v1](http://arxiv.org/abs/2412.14814v1)|null|
|**2024-12-19**|**MARIA: a Multimodal Transformer Model for Incomplete Healthcare Data**|Camillo Maria Caruso et.al.|[2412.14810v1](http://arxiv.org/abs/2412.14810v1)|null|
|**2024-12-19**|**ResoFilter: Rine-grained Synthetic Data Filtering for Large Language Models through Data-Parameter Resonance Analysis**|Zeao Tu et.al.|[2412.14809v1](http://arxiv.org/abs/2412.14809v1)|[link](https://github.com/tal-aurorax/resofilter)|
|**2024-12-19**|**Stack Trace Deduplication: Faster, More Accurately, and in More Realistic Scenarios**|Egor Shibaev et.al.|[2412.14802v1](http://arxiv.org/abs/2412.14802v1)|[link](https://github.com/jetbrains-research/stack-trace-deduplication)|
|**2024-12-19**|**Disentangling Reasoning Tokens and Boilerplate Tokens For Language Model Fine-tuning**|Ziang Ye et.al.|[2412.14780v1](http://arxiv.org/abs/2412.14780v1)|null|
|**2024-12-19**|**ALKAFI-LLAMA3: Fine-Tuning LLMs for Precise Legal Understanding in Palestine**|Rabee Qasem et.al.|[2412.14771v1](http://arxiv.org/abs/2412.14771v1)|null|
|**2024-12-19**|**PsyDraw: A Multi-Agent Multimodal System for Mental Health Screening in Left-Behind Children**|Yiqun Zhang et.al.|[2412.14769v1](http://arxiv.org/abs/2412.14769v1)|[link](https://github.com/LYiHub/psydraw)|
|**2024-12-19**|**CodeRepoQA: A Large-scale Benchmark for Software Engineering Question Answering**|Ruida Hu et.al.|[2412.14764v1](http://arxiv.org/abs/2412.14764v1)|null|
|**2024-12-19**|**Query pipeline optimization for cancer patient question answering systems**|Maolin He et.al.|[2412.14751v1](http://arxiv.org/abs/2412.14751v1)|null|
|**2024-12-19**|**On Verbalized Confidence Scores for LLMs**|Daniel Yang et.al.|[2412.14737v1](http://arxiv.org/abs/2412.14737v1)|null|
|**2024-12-19**|**Advances in Artificial Intelligence forDiabetes Prediction: Insights from a Systematic Literature Review**|Pir Bakhsh Khokhar et.al.|[2412.14736v1](http://arxiv.org/abs/2412.14736v1)|null|
|**2024-12-19**|**Creation of AI-driven Smart Spaces for Enhanced Indoor Environments -- A Survey**|AygÃ¼n Varol et.al.|[2412.14708v1](http://arxiv.org/abs/2412.14708v1)|null|
|**2024-12-19**|**How to Synthesize Text Data without Model Collapse?**|Xuekai Zhu et.al.|[2412.14689v1](http://arxiv.org/abs/2412.14689v1)|null|
|**2024-12-19**|**Each Fake News is Fake in its Own Way: An Attribution Multi-Granularity Benchmark for Multimodal Fake News Detection**|Hao Guo et.al.|[2412.14686v1](http://arxiv.org/abs/2412.14686v1)|null|
|**2024-12-19**|**Bel Esprit: Multi-Agent Framework for Building AI Model Pipelines**|Yunsu Kim et.al.|[2412.14684v1](http://arxiv.org/abs/2412.14684v1)|null|
|**2024-12-19**|**A Light-Weight Framework for Open-Set Object Detection with Decoupled Feature Alignment in Joint Space**|Yonghao He et.al.|[2412.14680v1](http://arxiv.org/abs/2412.14680v1)|null|
|**2024-12-19**|**LLMs as mediators: Can they diagnose conflicts accurately?**|Ãzgecan KoÃ§ak et.al.|[2412.14675v1](http://arxiv.org/abs/2412.14675v1)|null|
|**2024-12-19**|**FiVL: A Framework for Improved Vision-Language Alignment**|Estelle Aflalo et.al.|[2412.14672v1](http://arxiv.org/abs/2412.14672v1)|null|
|**2024-12-19**|**Analysis and Visualization of Linguistic Structures in Large Language Models: Neural Representations of Verb-Particle Constructions in BERT**|Hassane Kissane et.al.|[2412.14670v1](http://arxiv.org/abs/2412.14670v1)|null|
|**2024-12-19**|**LoLaFL: Low-Latency Federated Learning via Forward-only Propagation**|Jierui Zhang et.al.|[2412.14668v1](http://arxiv.org/abs/2412.14668v1)|null|
|**2024-12-19**|**IOHunter: Graph Foundation Model to Uncover Online Information Operations**|Marco Minici et.al.|[2412.14663v1](http://arxiv.org/abs/2412.14663v1)|null|
|**2024-12-19**|**Unveiling Uncertainty: A Deep Dive into Calibration and Performance of Multimodal Large Language Models**|Zijun Chen et.al.|[2412.14660v1](http://arxiv.org/abs/2412.14660v1)|[link](https://github.com/hfutml/calibration-mllm)|
|**2024-12-19**|**Length Controlled Generation for Black-box LLMs**|Yuxuan Gu et.al.|[2412.14656v1](http://arxiv.org/abs/2412.14656v1)|null|
|**2024-12-19**|**TOMG-Bench: Evaluating LLMs on Text-based Open Molecule Generation**|Jiatong Li et.al.|[2412.14642v1](http://arxiv.org/abs/2412.14642v1)|[link](https://github.com/phenixace/tomg-bench)|
|**2024-12-19**|**Adaptive Prompt Tuning: Vision Guided Prompt Tuning with Cross-Attention for Fine-Grained Few-Shot Learning**|Eric Brouwer et.al.|[2412.14640v1](http://arxiv.org/abs/2412.14640v1)|null|
|**2024-12-19**|**Progressive Fine-to-Coarse Reconstruction for Accurate Low-Bit Post-Training Quantization in Vision Transformers**|Rui Ding et.al.|[2412.14633v1](http://arxiv.org/abs/2412.14633v1)|null|
|**2024-12-19**|**Learning to Generate Research Idea with Dynamic Control**|Ruochen Li et.al.|[2412.14626v1](http://arxiv.org/abs/2412.14626v1)|null|
|**2024-12-19**|**Pitfalls of topology-aware image segmentation**|Alexander H. Berger et.al.|[2412.14619v1](http://arxiv.org/abs/2412.14619v1)|[link](https://github.com/alexanderhberger/topo-pitfalls)|
|**2024-12-19**|**How good is GPT at writing political speeches for the White House?**|Jacques Savoy et.al.|[2412.14617v1](http://arxiv.org/abs/2412.14617v1)|null|
|**2024-12-19**|**HarmonicEval: Multi-modal, Multi-task, Multi-criteria Automatic Evaluation Using a Vision Language Model**|Masanari Ohi et.al.|[2412.14613v1](http://arxiv.org/abs/2412.14613v1)|null|
|**2024-12-19**|**KARRIEREWEGE: A Large Scale Career Path Prediction Dataset**|Elena Senger et.al.|[2412.14612v1](http://arxiv.org/abs/2412.14612v1)|null|
|**2024-12-19**|**Towards Scalable and Deep Graph Neural Networks via Noise Masking**|Yuxuan Liang et.al.|[2412.14602v1](http://arxiv.org/abs/2412.14602v1)|null|
|**2024-12-19**|**LDP: Generalizing to Multilingual Visual Information Extraction by Language Decoupled Pretraining**|Huawen Shen et.al.|[2412.14596v1](http://arxiv.org/abs/2412.14596v1)|null|
|**2024-12-19**|**Beyond Guilt: Legal Judgment Prediction with Trichotomous Reasoning**|Kepu Zhang et.al.|[2412.14588v1](http://arxiv.org/abs/2412.14588v1)|null|
|**2024-12-19**|**Simulation-Free Hierarchical Latent Policy Planning for Proactive Dialogues**|Tao He et.al.|[2412.14584v1](http://arxiv.org/abs/2412.14584v1)|null|
|**2024-12-19**|**CORD: Balancing COnsistency and Rank Distillation for Robust Retrieval-Augmented Generation**|Youngwon Lee et.al.|[2412.14581v1](http://arxiv.org/abs/2412.14581v1)|null|
|**2024-12-19**|**Sliding Windows Are Not the End: Exploring Full Ranking with Long-Context Large Language Models**|Wenhan Liu et.al.|[2412.14574v1](http://arxiv.org/abs/2412.14574v1)|[link](https://github.com/8421bcd/fullrank)|
|**2024-12-19**|**Characterising Simulation-Based Program Equilibria**|Emery Cooper et.al.|[2412.14570v1](http://arxiv.org/abs/2412.14570v1)|null|
|**2024-12-19**|**AIArena: A Blockchain-Based Decentralized AI Training Platform**|Zhipeng Wang et.al.|[2412.14566v1](http://arxiv.org/abs/2412.14566v1)|null|
|**2024-12-19**|**CitaLaw: Enhancing LLM with Citations in Legal Domain**|Kepu Zhang et.al.|[2412.14556v1](http://arxiv.org/abs/2412.14556v1)|null|
|**2024-12-19**|**Overview of AI and Communication for 6G Network: Fundamentals, Challenges, and Future Research Opportunities**|Qimei Cui et.al.|[2412.14538v1](http://arxiv.org/abs/2412.14538v1)|null|
|**2024-12-19**|**Multi-Level Optimal Transport for Universal Cross-Tokenizer Knowledge Distillation on Language Models**|Xiao Cui et.al.|[2412.14528v1](http://arxiv.org/abs/2412.14528v1)|null|
|**2024-12-19**|**CAE-T: A Channelwise AutoEncoder with Transformer for EEG Abnormality Detection**|Youshen Zhao et.al.|[2412.14522v1](http://arxiv.org/abs/2412.14522v1)|[link](https://github.com/yossizhao/cae-t)|
|**2024-12-19**|**Cal-DPO: Calibrated Direct Preference Optimization for Language Model Alignment**|Teng Xiao et.al.|[2412.14516v1](http://arxiv.org/abs/2412.14516v1)|[link](https://github.com/tengxiao1/cal-dpo)|
|**2024-12-19**|**Relational Programming with Foundation Models**|Ziyang Li et.al.|[2412.14515v1](http://arxiv.org/abs/2412.14515v1)|null|
|**2024-12-19**|**PA-RAG: RAG Alignment via Multi-Perspective Preference Optimization**|Jiayi Wu et.al.|[2412.14510v1](http://arxiv.org/abs/2412.14510v1)|[link](https://github.com/wujwyi/pa-rag)|
|**2024-12-19**|**Do Large Language Models Defend Inferentialist Semantics?: On the Logical Expressivism and Anti-Representationalism of LLMs**|Yuzuki Arai et.al.|[2412.14501v1](http://arxiv.org/abs/2412.14501v1)|null|
|**2024-12-19**|**The Digital Ecosystem of Beliefs: does evolution favour AI over humans?**|David M. Bossens et.al.|[2412.14500v1](http://arxiv.org/abs/2412.14500v1)|null|
|**2024-12-19**|**FaultExplainer: Leveraging Large Language Models for Interpretable Fault Detection and Diagnosis**|Abdullah Khan et.al.|[2412.14492v1](http://arxiv.org/abs/2412.14492v1)|null|
|**2024-12-19**|**Towards Projected and Incremental Pseudo-Boolean Model Counting**|Suwei Yang et.al.|[2412.14485v1](http://arxiv.org/abs/2412.14485v1)|null|
|**2024-12-19**|**GraphEQA: Using 3D Semantic Scene Graphs for Real-time Embodied Question Answering**|Saumya Saxena et.al.|[2412.14480v1](http://arxiv.org/abs/2412.14480v1)|null|

#### Abstracts
##### **Scaling 4D Representations**
2412.15212v1 by JoÃ£o Carreira, Dilara Gokay, Michael King, Chuhan Zhang, Ignacio Rocco, Aravindh Mahendran, Thomas Albert Keck, Joseph Heyward, Skanda Koppula, Etienne Pot, Goker Erdogan, Yana Hasson, Yi Yang, Klaus Greff, Guillaume Le Moing, Sjoerd van Steenkiste, Daniel Zoran, Drew A. Hudson, Pedro VÃ©lez, Luisa PolanÃ­a, Luke Friedman, Chris Duvarney, Ross Goroshin, Kelsey Allen, Jacob Walker, Rishabh Kabra, Eric Aboussouan, Jennifer Sun, Thomas Kipf, Carl Doersch, Viorica PÄtrÄucean, Dima Damen, Pauline Luc, Mehdi S. M. Sajjadi, Andrew Zisserman

Scaling has not yet been convincingly demonstrated for pure self-supervised
learning from video. However, prior work has focused evaluations on
semantic-related tasks $\unicode{x2013}$ action classification, ImageNet
classification, etc. In this paper we focus on evaluating self-supervised
learning on non-semantic vision tasks that are more spatial (3D) and temporal
(+1D = 4D), such as camera pose estimation, point and object tracking, and
depth estimation. We show that by learning from very large video datasets,
masked auto-encoding (MAE) with transformer video models actually scales,
consistently improving performance on these 4D tasks, as model size increases
from 20M all the way to the largest by far reported self-supervised video model
$\unicode{x2013}$ 22B parameters. Rigorous apples-to-apples comparison with
many recent image and video models demonstrates the benefits of scaling 4D
representations.

æè¦ï¼ç´ç²¹çå½±çèªç£ç£å­¸ç¿å°æªä»¤äººä¿¡æå°å±ç¾åºæ´åæ§ãç¶èï¼ååçç ç©¶å°è©ä¼°éé»æ¾å¨èªæç¸éä»»åä¸ï¼ä¾å¦åä½åé¡ãImageNet åé¡ç­ãå¨æ¬æä¸­ï¼æåå°æ³¨æ¼è©ä¼°èªç£ç£å­¸ç¿å¨éèªæè¦è¦ºä»»åä¸çè¡¨ç¾ï¼éäºä»»åæ´å·ç©ºéæ§ (3D) åæéæ§ (+1D = 4D)ï¼ä¾å¦ç¸æ©ä½å§¿ä¼°è¨ãé»åç©é«è¿½è¹¤ï¼ä»¥åæ·±åº¦ä¼°è¨ãæåå±ç¤ºäºééå¾éå¸¸å¤§çå½±çè³æéä¸­å­¸ç¿ï¼ä½¿ç¨Transformerå½±çæ¨¡åçé®ç½©èªåç·¨ç¢¼ (MAE) ç¢ºå¯¦å·ææ´åæ§ï¼é¨èæ¨¡åå¤§å°å¾ 20M ä¸è·¯å¢å å°ç®åçºæ­¢æå¤§çèªç£ç£å½±çæ¨¡åï¼å¨éäº 4D ä»»åä¸çè¡¨ç¾æçºæåï¼éå° 22B åæ¸ãèè¨±å¤æè¿çå½±ååå½±çæ¨¡åé²è¡å´è¬¹çèæå°èææ¯è¼ï¼è­æäºæ´å 4D è¡¨å¾µçå¥½èã

##### **PRIMA: Multi-Image Vision-Language Models for Reasoning Segmentation**
2412.15209v1 by Muntasir Wahed, Kiet A. Nguyen, Adheesh Sunil Juvekar, Xinzhuo Li, Xiaona Zhou, Vedant Shah, Tianjiao Yu, Pinar Yanardag, Ismini Lourentzou

Despite significant advancements in Large Vision-Language Models (LVLMs),
existing pixel-grounding models operate on single-image settings, limiting
their ability to perform detailed, fine-grained comparisons across multiple
images. Conversely, current multi-image understanding models lack pixel-level
grounding. Our work addresses this gap by introducing the task of multi-image
pixel-grounded reasoning segmentation, and PRIMA, a novel LVLM that integrates
pixel-level grounding with robust multi-image reasoning capabilities to produce
contextually rich, pixel-grounded explanations. Central to PRIMA is an
efficient vision module that queries fine-grained visual representations across
multiple images, reducing TFLOPs by $25.3\%$. To support training and
evaluation, we curate $M^4Seg$, a new reasoning segmentation benchmark
consisting of $\sim$224K question-answer pairs that require fine-grained visual
understanding across multiple images. Experimental results demonstrate PRIMA
outperforms state-of-the-art baselines.

æè¦ï¼åç®¡å¤§åè¦è¦ºèªè¨æ¨¡å (LVLMs) æé¡¯èçé²å±ï¼ç¾æçåç´ åºç¤æ¨¡åå¨å®ä¸å½±åè¨­å®ä¸­éä½ï¼éå¶äºå®åè·¨å¤åå½±åå·è¡è©³ç´°ãç´°å¾®çæ¯è¼çè½åãç¸åå°ï¼ç®åçè¨±å¤å½±åçè§£æ¨¡åç¼ºä¹åç´ å±¤ç´çåºç¤ãæåçç ç©¶ééå¼å¥å¤å½±ååç´ åºç¤æ¨çåå²çä»»åï¼ä»¥å PRIMAï¼ä¸åæ´ååç´ å±¤ç´åºç¤èå¼·å¥çå¤å½±åæ¨çè½åçæ°ç© LVLMï¼ä¾è§£æ±ºéåå·®è·ï¼ä»¥ç¢çèçµ¡è±å¯ãåç´ åºç¤çè§£éãPRIMA çæ ¸å¿æ¯ä¸åé«æçè¦è¦ºæ¨¡çµï¼å®æ¥è©¢è·¨å¤åå½±åçç´°å¾®è¦è¦ºè¡¨ç¤ºï¼å° TFLOP æ¸å°äº 25.3%ãçºäºæ¯æ´è¨ç·´åè©ä¼°ï¼æåç­åäº M4Segï¼ä¸åæ°çæ¨çåå²åºæºï¼åå«ç´ 22.4 è¬ååé¡åç­å°ï¼éäºå°éè¦è·¨å¤åå½±åçç´°å¾®è¦è¦ºçè§£ãå¯¦é©çµæè­æ PRIMA åªæ¼æåé²çåºæºã

##### **LongBench v2: Towards Deeper Understanding and Reasoning on Realistic Long-context Multitasks**
2412.15204v1 by Yushi Bai, Shangqing Tu, Jiajie Zhang, Hao Peng, Xiaozhi Wang, Xin Lv, Shulin Cao, Jiazheng Xu, Lei Hou, Yuxiao Dong, Jie Tang, Juanzi Li

This paper introduces LongBench v2, a benchmark designed to assess the
ability of LLMs to handle long-context problems requiring deep understanding
and reasoning across real-world multitasks. LongBench v2 consists of 503
challenging multiple-choice questions, with contexts ranging from 8k to 2M
words, across six major task categories: single-document QA, multi-document QA,
long in-context learning, long-dialogue history understanding, code repository
understanding, and long structured data understanding. To ensure the breadth
and the practicality, we collect data from nearly 100 highly educated
individuals with diverse professional backgrounds. We employ both automated and
manual review processes to maintain high quality and difficulty, resulting in
human experts achieving only 53.7% accuracy under a 15-minute time constraint.
Our evaluation reveals that the best-performing model, when directly answers
the questions, achieves only 50.1% accuracy. In contrast, the o1-preview model,
which includes longer reasoning, achieves 57.7%, surpassing the human baseline
by 4%. These results highlight the importance of enhanced reasoning ability and
scaling inference-time compute to tackle the long-context challenges in
LongBench v2. The project is available at https://longbench2.github.io.

æè¦ï¼æ¬æä»ç´¹ LongBench v2ï¼éæ¯ä¸ååºæºæ¸¬è©¦ï¼ç¨ä¾è©ä¼° LLM èçéè¦è·¨è¶çå¯¦ä¸çå¤ä»»åé²è¡æ·±å¥çè§£åæ¨ççé·èçµ¡åé¡çè½åãLongBench v2 åå« 503 åå·æææ°æ§çå¤é¸é¡ï¼èçµ¡ç¯åå¾ 8k å° 2M åå­ï¼æ¶µèå­åä¸»è¦çä»»åé¡å¥ï¼å®ä¸æä»¶åç­ãå¤æä»¶åç­ãé·èçµ¡å­¸ç¿ãé·å°è©±æ­·ç¨çè§£ãç¨å¼ç¢¼å²å­åº«çè§£ï¼ä»¥åé·çµæ§åè³æçè§£ãçºäºç¢ºä¿å»£åº¦åå¯¦ç¨æ§ï¼æåå¾è¿ 100 ä½åéé«ç­æè²ãå·æä¸åå°æ¥­èæ¯çäººå¡æ¶éè³æãæåæ¡ç¨èªåååæåæª¢é±æµç¨ä¾ç¶­æé«åè³ªåé£åº¦ï¼å°è´äººé¡å°å®¶å¨ 15 åéçæééå¶ä¸åªè½éå° 53.7% çæºç¢ºåº¦ãæåçè©ä¼°é¡¯ç¤ºï¼å¨ç´æ¥åç­åé¡æï¼è¡¨ç¾æä½³çæ¨¡ååªè½éå° 50.1% çæºç¢ºåº¦ãç¸æ¯ä¹ä¸ï¼åå«è¼é·æ¨çç o1-preview æ¨¡åéå° 57.7%ï¼æ¯äººé¡åºæºé«åº 4%ãéäºçµæçªé¡¯äºå¢å¼·æ¨çè½ååæ´åæ¨è«æééç®çéè¦æ§ï¼ä»¥æå° LongBench v2 ä¸­çé·èçµ¡ææ°ãæ­¤å°æ¡å¯å¨ https://longbench2.github.io/ åå¾ã

##### **DI-PCG: Diffusion-based Efficient Inverse Procedural Content Generation for High-quality 3D Asset Creation**
2412.15200v1 by Wang Zhao, Yan-Pei Cao, Jiale Xu, Yuejiang Dong, Ying Shan

Procedural Content Generation (PCG) is powerful in creating high-quality 3D
contents, yet controlling it to produce desired shapes is difficult and often
requires extensive parameter tuning. Inverse Procedural Content Generation aims
to automatically find the best parameters under the input condition. However,
existing sampling-based and neural network-based methods still suffer from
numerous sample iterations or limited controllability. In this work, we present
DI-PCG, a novel and efficient method for Inverse PCG from general image
conditions. At its core is a lightweight diffusion transformer model, where PCG
parameters are directly treated as the denoising target and the observed images
as conditions to control parameter generation. DI-PCG is efficient and
effective. With only 7.6M network parameters and 30 GPU hours to train, it
demonstrates superior performance in recovering parameters accurately, and
generalizing well to in-the-wild images. Quantitative and qualitative
experiment results validate the effectiveness of DI-PCG in inverse PCG and
image-to-3D generation tasks. DI-PCG offers a promising approach for efficient
inverse PCG and represents a valuable exploration step towards a 3D generation
path that models how to construct a 3D asset using parametric models.

æè¦ï¼ç¨åºå§å®¹ç¢çï¼PCGï¼å¨å»ºç«é«åè³ª 3D å§å®¹æ¹é¢å¾å¼·å¤§ï¼ä½è¦æ§å¶å®ä¾ç¢çæéçå½¢çå¾å°é£ï¼èä¸éå¸¸éè¦å»£æ³çåæ¸èª¿æ´ãååç¨åºå§å®¹ç¢çæ¨å¨èªåæ¾åºè¼¸å¥æ¢ä»¶ä¸çæä½³åæ¸ãç¶èï¼ç¾æçåºæ¼æ¡æ¨£ååºæ¼ç¥ç¶ç¶²è·¯çæ¹æ³ä»ç¶æè¨±å¤æ¨£æ¬è¿­ä»£ææ§å¶è½åæéçåé¡ãå¨éé å·¥ä½ä¸­ï¼æåæåº DI-PCGï¼éæ¯ä¸ç¨®å¾ä¸è¬å½±åæ¢ä»¶ä¸­é²è¡åå PCG çæ°ç©ä¸ææçæ¹æ³ãå¶æ ¸å¿æ¯ä¸åè¼éç´çæ´æ£è®æå¨æ¨¡åï¼å¶ä¸­ PCG åæ¸è¢«ç´æ¥è¦çºå»åªç®æ¨ï¼èè§å¯å°çå½±ååä½çºæ§å¶åæ¸çæçæ¢ä»¶ãDI-PCG æ¯ææçä¸ææçãå®åªæ 7.6M ç¶²è·¯åæ¸å 30 å GPU å°æé²è¡è¨ç·´ï¼å¨æºç¢ºæ¢å¾©åæ¸æ¹é¢è¡¨ç¾åºåªç°çæ§è½ï¼ä¸¦ä¸è½å¾å¥½å°æ¨å»£å°éå¤å½±åãå®éåå®æ§å¯¦é©çµæé©è­äº DI-PCG å¨åå PCG åå½±åå° 3D çæä»»åä¸­çæææ§ãDI-PCG çºææççåå PCG æä¾äºä¸åæåéçæ¹æ³ï¼ä¸¦ä»£è¡¨äºä¸åæå¹å¼çæ¢ç´¢æ­¥é©ï¼æèä¸åä½¿ç¨åæ¸æ¨¡åä¾å»ºæ§ 3D è³ç¢ç 3D çæè·¯å¾éé²ã

##### **MMLU-CF: A Contamination-free Multi-task Language Understanding Benchmark**
2412.15194v1 by Qihao Zhao, Yangyu Huang, Tengchao Lv, Lei Cui, Qinzheng Sun, Shaoguang Mao, Xin Zhang, Ying Xin, Qiufeng Yin, Scarlett Li, Furu Wei

Multiple-choice question (MCQ) datasets like Massive Multitask Language
Understanding (MMLU) are widely used to evaluate the commonsense,
understanding, and problem-solving abilities of large language models (LLMs).
However, the open-source nature of these benchmarks and the broad sources of
training data for LLMs have inevitably led to benchmark contamination,
resulting in unreliable evaluation results. To alleviate this issue, we propose
a contamination-free and more challenging MCQ benchmark called MMLU-CF. This
benchmark reassesses LLMs' understanding of world knowledge by averting both
unintentional and malicious data leakage. To avoid unintentional data leakage,
we source data from a broader domain and design three decontamination rules. To
prevent malicious data leakage, we divide the benchmark into validation and
test sets with similar difficulty and subject distributions. The test set
remains closed-source to ensure reliable results, while the validation set is
publicly available to promote transparency and facilitate independent
verification. Our evaluation of mainstream LLMs reveals that the powerful
GPT-4o achieves merely a 5-shot score of 73.4% and a 0-shot score of 71.9% on
the test set, which indicates the effectiveness of our approach in creating a
more rigorous and contamination-free evaluation standard. The GitHub repository
is available at https://github.com/microsoft/MMLU-CF and the dataset refers to
https://huggingface.co/datasets/microsoft/MMLU-CF.

æè¦ï¼<paragraph>å¤éé¸æé¡ (MCQ) è³æéï¼ä¾å¦ Massive Multitask Language Understanding (MMLU)ï¼è¢«å»£æ³ç¨æ¼è©ä¼°å¤§åèªè¨æ¨¡å (LLM) çå¸¸è­ãçè§£ååé¡è§£æ±ºè½åãç¶èï¼éäºåºæºçéæ¾åå§ç¢¼æ§è³ªå LLM çè¨ç·´è³æå»£æ³ä¾æºä¸å¯é¿åå°å°è´åºæºæ±¡æï¼å°è´è©ä¼°çµæä¸å¯é ãçºäºç·©è§£éååé¡ï¼æåæåºäºä¸åç¡æ±¡æä¸æ´å·ææ°æ§ç MCQ åºæºï¼ç¨±çº MMLU-CFãæ­¤åºæºééé¿åç¡æåæ¡æçè³æå¤æ´©ï¼éæ°è©ä¼° LLM å°ä¸çç¥è­ççè§£ãçºäºé¿åç¡æçè³æå¤æ´©ï¼æåå¾æ´å»£æ³çç¶²åä¸­åå¾è³æï¼ä¸¦è¨­è¨äºä¸æ¢å»æ±è¦åãçºäºé²æ­¢æ¡æçè³æå¤æ´©ï¼æåå°åºæºååçºé©è­åæ¸¬è©¦éï¼å·æç¸ä¼¼çé£åº¦åä¸»é¡åä½ãæ¸¬è©¦éä¿æå°éåå§ç¢¼ä»¥ç¢ºä¿çµæå¯é ï¼èé©è­éå¬éå¯ç¨ä»¥ä¿é²éæåº¦ååå©ç¨ç«é©è­ãæåå°ä¸»æµ LLM çè©ä¼°é¡¯ç¤ºï¼å¼·å¤§ç GPT-4o å¨æ¸¬è©¦éä¸åç²å¾ 5 æ¬¡åè©¦å¾å 73.4% å 0 æ¬¡åè©¦å¾å 71.9%ï¼éè¡¨ç¤ºæåçæ¹æ³å¨å»ºç«æ´å´è¬¹ä¸ç¡æ±¡æçè©ä¼°æ¨æºä¸æ¯ææçãGitHub å­æ¾åº«å¯å¨ https://github.com/microsoft/MMLU-CF åå¾ï¼èè³æéè«åé± https://huggingface.co/datasets/microsoft/MMLU-CFã</paragraph>

##### **Face the Facts! Evaluating RAG-based Fact-checking Pipelines in Realistic Settings**
2412.15189v1 by Daniel Russo, Stefano Menini, Jacopo Staiano, Marco Guerini

Natural Language Processing and Generation systems have recently shown the
potential to complement and streamline the costly and time-consuming job of
professional fact-checkers. In this work, we lift several constraints of
current state-of-the-art pipelines for automated fact-checking based on the
Retrieval-Augmented Generation (RAG) paradigm. Our goal is to benchmark, under
more realistic scenarios, RAG-based methods for the generation of verdicts -
i.e., short texts discussing the veracity of a claim - evaluating them on
stylistically complex claims and heterogeneous, yet reliable, knowledge bases.
Our findings show a complex landscape, where, for example, LLM-based retrievers
outperform other retrieval techniques, though they still struggle with
heterogeneous knowledge bases; larger models excel in verdict faithfulness,
while smaller models provide better context adherence, with human evaluations
favouring zero-shot and one-shot approaches for informativeness, and fine-tuned
models for emotional alignment.

æè¦ï¼èªç¶èªè¨èçåçæç³»çµ±æè¿å·²å±ç¾åºè£ååç°¡åå°æ¥­äºå¯¦æ¥æ ¸å¡æè²´ä¸èæçä»»åçæ½åãå¨éé å·¥ä½ä¸­ï¼æåè§£é¤äºåºæ¼æª¢ç´¢å¢å¼·çæ (RAG) å¸ç¯çç¶åæåé²èªåäºå¯¦æ¥æ ¸ç®¡ç·çè¥å¹²éå¶ãæåçç®æ¨æ¯å¨æ´å¯¦éçå ´æ¯ä¸ï¼å°åºæ¼ RAG çæ¹æ³é²è¡åºæºæ¸¬è©¦ï¼ä»¥çæå¤æ±º - å³è¨è«èªªæ³çå¯¦æ§çç°¡ç­æå­ - å¨é¢¨æ ¼è¤éçèªªæ³åç°è³ªä½å¯é çç¥è­åº«ä¸å°å¶é²è¡è©ä¼°ãæåçç ç©¶çµæé¡¯ç¤ºäºä¸åè¤éçç°å¢ï¼ä¾å¦ï¼åºæ¼ LLM çæª¢ç´¢å¨åªæ¼å¶ä»æª¢ç´¢æè¡ï¼åç®¡å®åä»é£ä»¥æå°ç°è³ªç¥è­åº«ï¼è¼å¤§çæ¨¡åå¨å¤æ±ºå¿ å¯¦åº¦æ¹é¢è¡¨ç¾åºè²ï¼èè¼å°çæ¨¡ååæä¾æ´å¥½çä¸ä¸æä¾éæ§ï¼äººé¡è©ä¼°åå¥½é¶æ¬¡å­¸ç¿åä¸æ¬¡å­¸ç¿æ¹æ³ä»¥ç²åä¿¡æ¯ï¼ä¸¦å¾®èª¿æ¨¡åä»¥é²è¡æç·å°é½ã

##### **LlamaFusion: Adapting Pretrained Language Models for Multimodal Generation**
2412.15188v1 by Weijia Shi, Xiaochuang Han, Chunting Zhou, Weixin Liang, Xi Victoria Lin, Luke Zettlemoyer, Lili Yu

We present LlamaFusion, a framework for empowering pretrained text-only large
language models (LLMs) with multimodal generative capabilities, enabling them
to understand and generate both text and images in arbitrary sequences.
LlamaFusion leverages existing Llama-3's weights for processing texts
autoregressively while introducing additional and parallel transformer modules
for processing images with diffusion. During training, the data from each
modality is routed to its dedicated modules: modality-specific feedforward
layers, query-key-value projections, and normalization layers process each
modality independently, while the shared self-attention layers allow
interactions across text and image features. By freezing the text-specific
modules and only training the image-specific modules, LlamaFusion preserves the
language capabilities of text-only LLMs while developing strong visual
understanding and generation abilities. Compared to methods that pretrain
multimodal generative models from scratch, our experiments demonstrate that,
LlamaFusion improves image understanding by 20% and image generation by 3.6%
using only 50% of the FLOPs while maintaining Llama-3's language capabilities.
We also demonstrate that this framework can adapt existing vision-language
models with multimodal generation ability. Overall, this framework not only
leverages existing computational investments in text-only LLMs but also enables
the parallel development of language and vision capabilities, presenting a
promising direction for efficient multimodal model development.

æè¦ï¼<paragraph>æåæåºäº LlamaFusionï¼ä¸åç¨æ¼è³¦äºé è¨ç·´ç´æå­å¤§åèªè¨æ¨¡å (LLM) å¤æ¨¡æçæåè½çæ¡æ¶ï¼ä½¿å®åè½å¤ çè§£ä¸¦çæä»»æåºåä¸­çæå­åå½±åã
LlamaFusion ååå©ç¨äºç¾æ Llama-3 çæ¬éä¾èªåè¿´æ­¸å°èçæå­ï¼åæå¼å¥äºé¡å¤çå¹³è¡Transformeræ¨¡çµä¾èçå½±åæ´æ£ãå¨è¨ç·´æéï¼æ¯åæ¨¡æçè³æé½æè·¯ç±å°å¶å°å±¬æ¨¡çµï¼æ¨¡æç¹å®çåé¥å±¤ãæ¥è©¢éµå¼æå½±åæ­£è¦åå±¤æç¨ç«èçæ¯åæ¨¡æï¼èå±äº«çèªææ³¨æå±¤ååè¨±æå­åå½±åç¹å¾µä¹éçäºåãééåçµæå­ç¹å®æ¨¡çµä¸¦åªè¨ç·´å½±åç¹å®æ¨¡çµï¼LlamaFusion ä¿çäºç´æå­ LLM çèªè¨è½åï¼åæç¼å±åºå¼·å¤§çè¦è¦ºçè§£åçæè½åãèå¾é ­éå§é è¨ç·´å¤æ¨¡æçææ¨¡åçæ¹æ³ç¸æ¯ï¼æåçå¯¦é©è­æï¼LlamaFusion å¨åä½¿ç¨ 50% ç FLOP çææ³ä¸ï¼å°å½±åçè§£åæåäº 20%ï¼å½±åçæè½åæåäº 3.6%ï¼åæç¶­æäº Llama-3 çèªè¨è½åãæåä¹è­æäºéåæ¡æ¶å¯ä»¥è®ç¾æçè¦è¦ºèªè¨æ¨¡åé©æå¤æ¨¡æçæè½åãç¸½çä¾èªªï¼éåæ¡æ¶ä¸åå©ç¨äºå¨ç´æå­ LLM ä¸æ¢æçéç®æè³ï¼ä¹è®èªè¨åè¦è¦ºè½åå¯ä»¥å¹³è¡ç¼å±ï¼çºé«æçå¤æ¨¡ææ¨¡åéç¼å±ç¤ºäºä¸åæåæ¯çæ¹åã</paragraph>

##### **Critical-Questions-of-Thought: Steering LLM reasoning with Argumentative Querying**
2412.15177v1 by Federico Castagna, Isabel Sassoon, Simon Parsons

Studies have underscored how, regardless of the recent breakthrough and swift
advances in AI research, even state-of-the-art Large Language models (LLMs)
continue to struggle when performing logical and mathematical reasoning. The
results seem to suggest that LLMs still work as (highly advanced) data pattern
identifiers, scoring poorly when attempting to generalise and solve reasoning
problems the models have never previously seen or that are not close to samples
presented in their training data. To address this compelling concern, this
paper makes use of the notion of critical questions from the literature on
argumentation theory, focusing in particular on Toulmin's model of
argumentation. We show that employing these critical questions can improve the
reasoning capabilities of LLMs. By probing the rationale behind the models'
reasoning process, the LLM can assess whether some logical mistake is occurring
and correct it before providing the final reply to the user prompt. The
underlying idea is drawn from the gold standard of any valid argumentative
procedure: the conclusion is valid if it is entailed by accepted premises. Or,
to paraphrase such Aristotelian principle in a real-world approximation,
characterised by incomplete information and presumptive logic, the conclusion
is valid if not proved otherwise. This approach successfully steers the models'
output through a reasoning pipeline, resulting in better performance against
the baseline and its Chain-of-Thought (CoT) implementation. To this end, an
extensive evaluation of the proposed approach on the MT-Bench Reasoning and
Math tasks across a range of LLMs is provided.

æè¦ï¼ç ç©¶å¼·èª¿ï¼åç®¡ AI ç ç©¶æè¿åå¾çªç ´åå¿«éé²å±ï¼ä½å³ä½¿æåé²çå¤§èªè¨æ¨¡å (LLM) å¨å·è¡éè¼¯åæ¸å­¸æ¨çæä»æéå°å°é£ãçµæä¼¼ä¹è¡¨æï¼LLM ä»ä½çºï¼é«åº¦åé²çï¼è³ææ¨¡å¼è­å¥å¨ï¼å¨åè©¦æ¦æ¬åè§£æ±ºæ¨¡åä»¥åå¾æªè¦éæèå¶è¨ç·´è³æä¸­åç¾çæ¨£æ¬ä¸æ¥è¿çæ¨çåé¡æå¾åå¾å·®ãçºäºè§£æ±ºéåä»¤äººä¿¡æçåé¡ï¼æ¬æå©ç¨è«è­çè«æç»ä¸­çæ¹å¤æ§åé¡æ¦å¿µï¼ç¹å¥éæ³¨ Toulmin çè«è­æ¨¡åãæåè¡¨æï¼æ¡ç¨éäºæ¹å¤æ§åé¡å¯ä»¥æé« LLM çæ¨çè½åãééæ¢è¨æ¨¡åæ¨çéç¨èå¾çåçï¼LLM å¯ä»¥è©ä¼°æ¯å¦ç¼çäºéè¼¯é¯èª¤ï¼ä¸¦å¨åä½¿ç¨èæç¤ºæä¾æçµç­è¦ä¹åäºä»¥ç³¾æ­£ãå¶åºæ¬ææ³æºèªä»»ä½ææè«è­ç¨åºçé»éæ¨æºï¼å¦æçµè«æ¯ç±å¬èªçåææèå«ï¼åè©²çµè«ææãæèï¼ç¨äºéæ¯å¤å¾·ååå¨ç¾å¯¦ä¸ççè¿ä¼¼ä¸­é²è¡æ¹å¯«ï¼å¶ç¹å¾µæ¯ä¸å®å¨çè³è¨åæ¨å®çéè¼¯ï¼å¦ææ²æè¢«è­ææ¯é¯èª¤çï¼åçµè«æ¯ææçãéç¨®æ¹æ³æåå°å¼å°æ¨¡åçè¼¸åºééæ¨çç®¡éï¼å¾èç¸å°æ¼åºç·åå¶ææ³é (CoT) å¯¦ä½ç¢çæ´å¥½çæè½ãçºæ­¤ï¼æä¾äºå°è·¨è¶ä¸ç³»å LLM ç MT-Bench æ¨çåæ¸å­¸ä»»åçæ¬è­°æ¹æ³çå»£æ³è©ä¼°ã

##### **Human-Humanoid Robots Cross-Embodiment Behavior-Skill Transfer Using Decomposed Adversarial Learning from Demonstration**
2412.15166v1 by Junjia Liu, Zhuo Li, Minghao Yu, Zhipeng Dong, Sylvain Calinon, Darwin Caldwell, Fei Chen

Humanoid robots are envisioned as embodied intelligent agents capable of
performing a wide range of human-level loco-manipulation tasks, particularly in
scenarios requiring strenuous and repetitive labor. However, learning these
skills is challenging due to the high degrees of freedom of humanoid robots,
and collecting sufficient training data for humanoid is a laborious process.
Given the rapid introduction of new humanoid platforms, a cross-embodiment
framework that allows generalizable skill transfer is becoming increasingly
critical. To address this, we propose a transferable framework that reduces the
data bottleneck by using a unified digital human model as a common prototype
and bypassing the need for re-training on every new robot platform. The model
learns behavior primitives from human demonstrations through adversarial
imitation, and the complex robot structures are decomposed into functional
components, each trained independently and dynamically coordinated. Task
generalization is achieved through a human-object interaction graph, and skills
are transferred to different robots via embodiment-specific kinematic motion
retargeting and dynamic fine-tuning. Our framework is validated on five
humanoid robots with diverse configurations, demonstrating stable
loco-manipulation and highlighting its effectiveness in reducing data
requirements and increasing the efficiency of skill transfer across platforms.

æè¦ï¼é¡äººæ©å¨äººè¢«è¦çºå·åé«ç¾æºè½çä»£çäººï¼è½å¤ å·è¡å»£æ³çäººé¡å±¤ç´çéåæç¸±ä»»åï¼ç¹å¥æ¯å¨éè¦åçä¸éè¤ååçå ´æ¯ä¸­ãç¶èï¼å­¸ç¿éäºæè½å·æææ°æ§ï¼å çºé¡äººæ©å¨äººçèªç±åº¦å¾é«ï¼èä¸çºé¡äººæ©å¨äººæ¶éè¶³å¤ çè¨ç·´è³ææ¯ä¸åè²»åçéç¨ãç±æ¼æ°é¡äººæ©å¨äººå¹³å°çå¿«éå°å¥ï¼ä¸ååè¨±éç¨æè½è½ç§»çè·¨é«ç¾æ¡æ¶æ­£è®å¾è¶ä¾è¶éè¦ãçºäºè§£æ±ºéååé¡ï¼æåæåºä¸åå¯è½ç§»çæ¡æ¶ï¼å®ééä½¿ç¨ä¸åçµ±ä¸çæ¸ä½äººé¡æ¨¡åä½çºä¸åå±åçååä¾æ¸å°è³æç¶é ¸ï¼ä¸¦ç¹éå¨æ¯åæ°æ©å¨äººå¹³å°ä¸éæ°è¨ç·´çéè¦ãéåæ¨¡åééå°æå¼æ¨¡ä»¿å¾äººé¡ç¤ºç¯ä¸­å­¸ç¿è¡çºåèªï¼èè¤éçæ©å¨äººçµæ§è¢«åè§£æåè½åä»¶ï¼æ¯ååä»¶ç¨ç«è¨ç·´ä¸¦åæåèª¿ãä»»åæ¦æ¬åæ¯ééäººé¡ç©ä»¶äºååè¡¨ä¾å¯¦ç¾ï¼èæè½åééé«ç¾ç¹å®çéåéåéæ°å®ä½ååæå¾®èª¿å³è¼¸å°ä¸åçæ©å¨äººãæåçæ¡æ¶å¨äºåäººå½¢æ©å¨äººä¸é²è¡é©è­ï¼éäºæ©å¨äººå·æå¤æ¨£åççµæï¼å±ç¤ºäºç©©å®çéåæç¸±ï¼ä¸¦çªé¡¯äºå¶å¨æ¸å°è³æéæ±åæé«è·¨å¹³å°æè½è½ç§»æçæ¹é¢çæè½ã

##### **Prompt-A-Video: Prompt Your Video Diffusion Model via Preference-Aligned LLM**
2412.15156v1 by Yatai Ji, Jiacheng Zhang, Jie Wu, Shilong Zhang, Shoufa Chen, Chongjian GE, Peize Sun, Weifeng Chen, Wenqi Shao, Xuefeng Xiao, Weilin Huang, Ping Luo

Text-to-video models have made remarkable advancements through optimization
on high-quality text-video pairs, where the textual prompts play a pivotal role
in determining quality of output videos. However, achieving the desired output
often entails multiple revisions and iterative inference to refine
user-provided prompts. Current automatic methods for refining prompts encounter
challenges such as Modality-Inconsistency, Cost-Discrepancy, and Model-Unaware
when applied to text-to-video diffusion models. To address these problem, we
introduce an LLM-based prompt adaptation framework, termed as Prompt-A-Video,
which excels in crafting Video-Centric, Labor-Free and Preference-Aligned
prompts tailored to specific video diffusion model. Our approach involves a
meticulously crafted two-stage optimization and alignment system. Initially, we
conduct a reward-guided prompt evolution pipeline to automatically create
optimal prompts pool and leverage them for supervised fine-tuning (SFT) of the
LLM. Then multi-dimensional rewards are employed to generate pairwise data for
the SFT model, followed by the direct preference optimization (DPO) algorithm
to further facilitate preference alignment. Through extensive experimentation
and comparative analyses, we validate the effectiveness of Prompt-A-Video
across diverse generation models, highlighting its potential to push the
boundaries of video generation.

æè¦ï¼ææ¬å°å½±çæ¨¡åééæä½³åé«åè³ªææ¬å½±çéå°ï¼åå¾äºé¡¯èçé²æ­¥ï¼å¶ä¸­æå­æç¤ºå¨æ±ºå®å½±çè¼¸åºåè³ªæ¹é¢æ®æ¼äºééµè§è²ãç¶èï¼è¦éå°çæ³çè¼¸åºï¼éå¸¸éè¦å¤æ¬¡ä¿®æ¹ååè¦æ¨è«ä¾æ¹åä½¿ç¨èæä¾çæç¤ºãç®åç¨æ¼æ¹åæç¤ºçèªååæ¹æ³ï¼å¨æç¨æ¼ææ¬å°å½±çæ´æ£æ¨¡åæï¼æéå°æ¨¡æä¸ä¸è´ãææ¬å·®ç°åæ¨¡åä¸ç¥æç­ææ°ãçºäºè§£æ±ºéäºåé¡ï¼æåå¼å¥äºä¸ååºæ¼ LLM çæç¤ºé©ææ¶æ§ï¼ç¨±çº Prompt-A-Videoï¼å®æé·è£½ä½éå°ç¹å®å½±çæ´æ£æ¨¡åéèº«æé çä»¥å½±ççºä¸­å¿ãåäººå·¥ååå¥½å°é½çæç¤ºãæåçåæ³åå«ç²¾å¿è¨­è¨çå©éæ®µæä½³ååå°é½ç³»çµ±ãæåï¼æåå·è¡ä¸åçåµå¼å°æç¤ºæ¼åç®¡éï¼ä»¥èªåå»ºç«æä½³æç¤ºæ± ï¼ä¸¦å©ç¨å®åå° LLM é²è¡ç£ç£å¾®èª¿ (SFT)ãç¶å¾æ¡ç¨å¤ç¶­åº¦çåµçº SFT æ¨¡åç¢çæå°è³æï¼æ¥èä½¿ç¨ç´æ¥åå¥½æä½³å (DPO) æ¼ç®æ³é²ä¸æ­¥ä¿é²åå¥½å°é½ãééå»£æ³çå¯¦é©åæ¯è¼åæï¼æåé©è­äº Prompt-A-Video å¨åç¨®çææ¨¡åä¸­çæææ§ï¼çªé¡¯äºå®å¨æ¨åå½±ççæéççæ½åã

##### **Language Models as Continuous Self-Evolving Data Engineers**
2412.15151v1 by Peidong Wang, Ming Wang, Zhiming Ma, Xiaocui Yang, Shi Feng, Daling Wang, Yifei Zhang

Large Language Models (LLMs) have demonstrated remarkable capabilities on
various tasks, while the further evolvement is limited to the lack of
high-quality training data. In addition, traditional training approaches rely
too much on expert-labeled data, setting an upper limit on the performance of
LLMs. To address this issue, we propose a novel paradigm that enables LLMs to
train itself by autonomously generating, cleaning, reviewing, and annotating
data with preference information, named LANCE. Our approach demonstrates that
LLMs can serve as continuous self-evolving data engineers, significantly
reducing the time and cost of the post-training data construction process.
Through iterative fine-tuning on different variants of the Qwen2, we validate
the effectiveness of LANCE across various tasks, showing that it can
continuously improve model performance and maintain high-quality data
generation. Across eight benchmark dimensions, LANCE resulted in an average
score enhancement of 3.36 for Qwen2-7B and 2.70 for Qwen2-7B-Instruct. This
training paradigm with autonomous data construction not only reduces the
reliance on human experts or external models but also ensures that the data
aligns with human values and preferences, paving the way for the development of
future superintelligent systems that can exceed human capabilities.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å·²å¨åç¨®ä»»åä¸­å±ç¾åºåè¶çè½åï¼èé²ä¸æ­¥çæ¼é²ååå°ç¼ºä¹é«åè³ªè¨ç·´è³æçéå¶ãæ­¤å¤ï¼å³çµ±çè¨ç·´æ¹æ³éåº¦ä¾è³´å°å®¶æ¨è¨çè³æï¼çº LLM çæè½è¨­å®äºä¸éãçºäºè§£æ±ºéååé¡ï¼æåæåºäºä¸ååµæ°çç¯ä¾ï¼è® LLM è½å¤ ééèªä¸»ç¢çãæ¸çãå¯©é±åè¨»è§£å¸¶æåå¥½è³è¨çè³æä¾è¨ç·´èªå·±ï¼ç¨±çº LANCEãæåçåæ³è­æäº LLM å¯ä»¥ä½çºæçºèªææ¼é²çè³æå·¥ç¨å¸«ï¼å¤§å¹æ¸å°è¨ç·´å¾è³æå»ºæ§ç¨åºçæéåææ¬ãééå¨ Qwen2 çä¸åè®é«ä¸é²è¡åè¦å¾®èª¿ï¼æåé©è­äº LANCE å¨åç¨®ä»»åä¸­çæææ§ï¼é¡¯ç¤ºå®å¯ä»¥æçºæ¹åæ¨¡åæè½ä¸¦ç¶­æé«åè³ªçè³æç¢çãå¨å«ååºæºç¶­åº¦ä¸­ï¼LANCE è® Qwen2-7B çå¹³ååæ¸æåäº 3.36ï¼è Qwen2-7B-Instruct åæåäº 2.70ãéç¨®å·æèªä¸»è³æå»ºæ§çè¨ç·´ç¯ä¾ä¸åæ¸å°äºå°äººé¡å°å®¶æå¤é¨æ¨¡åçä¾è³´ï¼éè½ç¢ºä¿è³æç¬¦åäººé¡çå¹å¼è§ååå¥½ï¼çºéç¼æªä¾è½å¤ è¶è¶äººé¡è½åçè¶ç´æºæ§ç³»çµ±éªè·¯ã

##### **Leveraging Color Channel Independence for Improved Unsupervised Object Detection**
2412.15150v1 by Bastian JÃ¤ckl, Yannick Metz, Udo Schlegel, Daniel A. Keim, Maximilian T. Fischer

Object-centric architectures can learn to extract distinct object
representations from visual scenes, enabling downstream applications on the
object level. Similarly to autoencoder-based image models, object-centric
approaches have been trained on the unsupervised reconstruction loss of images
encoded by RGB color spaces. In our work, we challenge the common assumption
that RGB images are the optimal color space for unsupervised learning in
computer vision. We discuss conceptually and empirically that other color
spaces, such as HSV, bear essential characteristics for object-centric
representation learning, like robustness to lighting conditions. We further
show that models improve when requiring them to predict additional color
channels. Specifically, we propose to transform the predicted targets to the
RGB-S space, which extends RGB with HSV's saturation component and leads to
markedly better reconstruction and disentanglement for five common evaluation
datasets. The use of composite color spaces can be implemented with basically
no computational overhead, is agnostic of the models' architecture, and is
universally applicable across a wide range of visual computing tasks and
training types. The findings of our approach encourage additional
investigations in computer vision tasks beyond object-centric learning.

æè¦ï¼ç©ä»¶ä¸­å¿æ¶æå¯ä»¥å­¦ä¹ ä»è§è§åºæ¯ä¸­èååºä¸åçç©ä»¶è¡¨å¾ï¼è®©ä¸æ¸¸åºç¨è½å¤å¨ç©ä»¶å±çº§ä¸è¿è¡ãç±»ä¼¼äºåºäºèªå¨ç¼ç å¨çå¾åæ¨¡åï¼ç©ä»¶ä¸­å¿æ¹æ³å·²ç»è¿è®­ç»ï¼å¯ä»¥æ çç£å°éå»ºç± RGB è²å½©ç©ºé´ç¼ç çå¾åçæå¤±ãå¨æä»¬çå·¥ä½ä¸­ï¼æä»¬ææäº RGB å¾åæ¯è®¡ç®æºè§è§ä¸­æ çç£å­¦ä¹ çæä½³è²å½©ç©ºé´çæ®éåè®¾ãæä»¬ä»æ¦å¿µä¸åç»éªä¸è®¨è®ºäºå¶ä»è²å½©ç©ºé´ï¼ä¾å¦ HSVï¼å·æç©ä»¶ä¸­å¿è¡¨å¾å­¦ä¹ çåºæ¬ç¹æ§ï¼ä¾å¦å¯¹åç§æ¡ä»¶çé²æ£æ§ãæä»¬è¿ä¸æ­¥è¡¨æï¼å½è¦æ±æ¨¡åé¢æµé¢å¤çè²å½©ééæ¶ï¼æ¨¡åä¼å¾å°æ¹åãå·ä½æ¥è¯´ï¼æä»¬å»ºè®®å°é¢æµç®æ è½¬æ¢ä¸º RGB-S ç©ºé´ï¼è¯¥ç©ºé´ä½¿ç¨ HSV çé¥±ååº¦åéæ©å±äº RGBï¼å¹¶å¯¼è´äºä¸ªå¸¸è§è¯ä¼°æ°æ®éçéå»ºåè§£ç¼ ææ¾æ´å¥½ãå¤åè²å½©ç©ºé´çä½¿ç¨åºæ¬ä¸å¯ä»¥ä¸å¢å è®¡ç®å¼éæ¥å®ç°ï¼ä¸æ¨¡åçæ¶ææ å³ï¼å¹¶ä¸æ®ééç¨äºå¹¿æ³çè§è§è®¡ç®ä»»å¡åè®­ç»ç±»åãæä»¬æ¹æ³çåç°é¼å±å¨è¶è¶ç©ä»¶ä¸­å¿å­¦ä¹ çè®¡ç®æºè§è§ä»»å¡ä¸­è¿è¡é¢å¤çè°æ¥ã

##### **Probabilistic Strategy Logic with Degrees of Observability**
2412.15135v1 by Chunyan Mu, Nima Motamed, Natasha Alechina, Brian Logan

There has been considerable work on reasoning about the strategic ability of
agents under imperfect information. However, existing logics such as
Probabilistic Strategy Logic are unable to express properties relating to
information transparency. Information transparency concerns the extent to which
agents' actions and behaviours are observable by other agents. Reasoning about
information transparency is useful in many domains including security, privacy,
and decision-making. In this paper, we present a formal framework for reasoning
about information transparency properties in stochastic multi-agent systems. We
extend Probabilistic Strategy Logic with new observability operators that
capture the degree of observability of temporal properties by agents. We show
that the model checking problem for the resulting logic is decidable.

æè¦ï¼å°æ¼ä¸å®ç¾è³è¨ä¸ä¸»é«çç­ç¥è½åé²è¡æ¨ççå·¥ä½å·²ç¶ç¸ç¶å¤ãç¶èï¼ç¾æçéè¼¯ä¾å¦æ©çç­ç¥éè¼¯ç¡æ³è¡¨éèè³è¨éæåº¦æéçå±¬æ§ãè³è¨éæåº¦æ¶åä¸»é«çåä½åè¡çºå¨ä½ç¨®ç¨åº¦ä¸å¯ä»¥è¢«å¶ä»ä¸»é«è§å¯å°ãå°æ¼è³è¨éæåº¦é²è¡æ¨çå¨è¨±å¤é åä¸­å¾æç¨ï¼åæ¬å®å¨æ§ãé±ç§åæ±ºç­å¶å®ãå¨æ¬æä¸­ï¼æåæåºä¸åç¨æ¼å°é¨æ©å¤ä¸»é«ç³»çµ±ä¸­è³è¨éæåº¦å±¬æ§é²è¡æ¨ççå½¢å¼æ¶æ§ãæåä½¿ç¨æ°çå¯è§å¯æ§éç®å­æ´åæ©çç­ç¥éè¼¯ï¼è©²éç®å­ææä¸»é«å°æéå±¬æ§çå¯è§å¯ç¨åº¦ãæåè­æäºå°æ¼æå¾éè¼¯çæ¨¡åæª¢æ¥åé¡æ¯å¯å¤å®çã

##### **Jet: A Modern Transformer-Based Normalizing Flow**
2412.15129v1 by Alexander Kolesnikov, AndrÃ© Susano Pinto, Michael Tschannen

In the past, normalizing generative flows have emerged as a promising class
of generative models for natural images. This type of model has many modeling
advantages: the ability to efficiently compute log-likelihood of the input
data, fast generation and simple overall structure. Normalizing flows remained
a topic of active research but later fell out of favor, as visual quality of
the samples was not competitive with other model classes, such as GANs,
VQ-VAE-based approaches or diffusion models. In this paper we revisit the
design of the coupling-based normalizing flow models by carefully ablating
prior design choices and using computational blocks based on the Vision
Transformer architecture, not convolutional neural networks. As a result, we
achieve state-of-the-art quantitative and qualitative performance with a much
simpler architecture. While the overall visual quality is still behind the
current state-of-the-art models, we argue that strong normalizing flow models
can help advancing research frontier by serving as building components of more
powerful generative models.

æè¦ï¼å¨éå»ï¼æ­£è¦åçææµå·²æçºèªç¶ååçææ¨¡åä¸­ä¸åå¾æåæ¯çé¡å¥ãéç¨®é¡åçæ¨¡åæè¨±å¤å»ºæ¨¡åªå¢ï¼ææè¨ç®è¼¸å¥è³æçå°æ¸ä¼¼ç¶ãå¿«éçæåç°¡å®çæ´é«çµæ§ãæ­£è¦åæµä»ç¶æ¯ç©æ¥µç ç©¶çä¸»é¡ï¼ä½å¾ä¾ä¸åéçï¼å çºæ¨£æ¬çè¦è¦ºåè³ªç¡æ³èå¶ä»æ¨¡åé¡å¥ç«¶ç­ï¼ä¾å¦ GANãåºæ¼ VQ-VAE çæ¹æ³ææ´æ£æ¨¡åãå¨æ¬æä¸­ï¼æåéæ°æª¢è¦åºæ¼è¦åçæ­£è¦åæµæ¨¡åçè¨­è¨ï¼ééä»ç´°æ¶èååçè¨­è¨é¸æï¼ä¸¦ä½¿ç¨åºæ¼ Vision Transformer æ¶æ§ï¼èéå·ç©ç¥ç¶ç¶²è·¯ï¼çè¨ç®åå¡ãå æ­¤ï¼æåä»¥æ´ç°¡å®çæ¶æ§å¯¦ç¾äºæåé²çéååè³ªåæè½ãéç¶æ´é«è¦è¦ºåè³ªä»è½å¾æ¼ç®åçææ°æ¨¡åï¼ä½æåèªçºå¼·å¤§çæ­£è¦åæµæ¨¡åå¯ä»¥ééä½çºæ´å¼·å¤§çææ¨¡åçå»ºæ§åä»¶ï¼ä¾å¹«å©æ¨é²ç ç©¶åæ²¿ã

##### **Adaptive Pruning for Large Language Models with Structural Importance Awareness**
2412.15127v1 by Haotian Zheng, Jinke Ren, Yushan Sun, Ruichen Zhang, Wenbo Zhang, Zhen Li, Dusit Niyato, Shuguang Cui, Yatong Han

The recent advancements in large language models (LLMs) have significantly
improved language understanding and generation capabilities. However, it is
difficult to deploy LLMs on resource-constrained edge devices due to their high
computational and storage resource demands. To address this issue, we propose a
novel LLM model pruning method, namely structurally-aware adaptive pruning
(SAAP), to significantly reduce the computational and memory costs while
maintaining model performance. We first define an adaptive importance fusion
metric to evaluate the importance of all coupled structures in LLMs by
considering their homoscedastic uncertainty. Then, we rank the importance of
all modules to determine the specific layers that should be pruned to meet
particular performance requirements. Furthermore, we develop a new group
fine-tuning strategy to improve the inference efficiency of LLMs. Finally, we
evaluate the proposed SAAP method on multiple LLMs across two common tasks,
i.e., zero-shot classification and text generation. Experimental results show
that our SAAP method outperforms several state-of-the-art baseline methods,
achieving 2.17%, 2.37%, and 2.39% accuracy gains on LLaMA-7B, Vicuna-7B, and
LLaMA-13B. Additionally, SAAP improves the token generation speed by 5%,
showcasing its practical advantages in resource-constrained scenarios.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) çææ°é²å±é¡¯èå°
æ¹é²äºèªè¨çè§£åçæè½åãç¶èï¼ç±æ¼ LLM å°è¨ç®åå²å­è³æºéæ±é«ï¼å æ­¤é£ä»¥å°å¶é¨ç½²å¨è³æºåéçéç·£è£ç½®ä¸ãçºäºè§£æ±ºæ­¤åé¡ï¼æåæåºäºä¸ç¨®æ°ç©ç LLM æ¨¡ååªææ¹æ³ï¼å³çµæ§æç¥èªé©æåªæ (SAAP)ï¼ä»¥å¨ç¶­ææ¨¡åæè½çåæé¡¯èéä½è¨ç®åè¨æ¶é«ææ¬ãæåé¦åå®ç¾©ä¸åèªé©æéè¦æ§èåææ¨ï¼ééèæ® LLM ä¸­ææè¦åçµæ§çåè³ªç°æ¹å·®ä¸ç¢ºå®æ§ä¾è©ä¼°å¶éè¦æ§ãç¶å¾ï¼æåå°æææ¨¡çµçéè¦æ§é²è¡æåºï¼ä»¥ç¢ºå®æåªæçç¹å®å±¤ï¼ä»¥æ»¿è¶³ç¹å®çæè½éæ±ãæ­¤å¤ï¼æåéç¼äºä¸ç¨®æ°çç¾¤çµå¾®èª¿ç­ç¥ï¼ä»¥æ¹å LLM çæ¨è«æçãæå¾ï¼æåå¨å©åå¸¸è¦ä»»åä¸­å°å¤å LLM è©ä¼°ææåºç SAAP æ¹æ³ï¼å³é¶æ¬¡åé¡åæå­çæãå¯¦é©çµæé¡¯ç¤ºï¼æåç SAAP æ¹æ³åªæ¼å¤ç¨®æåé²çåºç·æ¹æ³ï¼å¨ LLaMA-7BãVicuna-7B å LLaMA-13B ä¸åå¥ç²å¾ 2.17%ã2.37% å 2.39% çæºç¢ºåº¦æåãæ­¤å¤ï¼SAAP å°ä»£ç¢¼çæéåº¦æé«äº 5%ï¼å±ç¤ºäºå¶å¨è³æºåéå ´æ¯ä¸­çå¯¦éåªå¢ã

##### **Outcome-Refining Process Supervision for Code Generation**
2412.15118v1 by Zhuohao Yu, Weizheng Gu, Yidong Wang, Zhengran Zeng, Jindong Wang, Wei Ye, Shikun Zhang

Large Language Models have demonstrated remarkable capabilities in code
generation, yet they often struggle with complex programming tasks that require
deep algorithmic reasoning. While process supervision through learned reward
models shows promise in guiding reasoning steps, it requires expensive training
data and suffers from unreliable evaluation. We propose Outcome-Refining
Process Supervision, a novel paradigm that treats outcome refinement itself as
the process to be supervised. Our framework leverages concrete execution
signals to ground the supervision of reasoning steps, while using
tree-structured exploration to maintain multiple solution trajectories
simultaneously. Experiments demonstrate that our approach enables even smaller
models to achieve high success accuracy and performance metrics on competitive
programming tasks, creates more reliable verification than traditional reward
models without requiring training PRMs. Our approach achieves significant
improvements across 5 models and 3 datasets: an average of 26.9% increase in
correctness and 42.2% in efficiency. The results suggest that providing
structured reasoning space with concrete verification signals is crucial for
solving complex programming tasks. We open-source all our code and data at:
https://github.com/zhuohaoyu/ORPS

æè¦ï¼å¤§åèªè¨æ¨¡åå¨ç¨å¼ç¢¼çææ¹é¢å±ç¾äºåè¶çè½åï¼ä½å®åç¶å¸¸å¨éè¦æ·±å¥æ¼ç®æ³æ¨ççè¤éç¨å¼è¨­è¨ä»»åä¸­éå°å°é£ãéç¶ééå­¸ç¿åé¥æ¨¡åé²è¡ç¨åºç£ç£é¡¯ç¤ºåºå¼å°æ¨çæ­¥é©çæ½åï¼ä½å®éè¦æè²´çè¨ç·´è³æï¼ä¸è©ä¼°çµæä¸å¯é ãæåæåºçµæç²¾çç¨åºç£ç£ï¼éæ¯ä¸ç¨®æ°ç©çç¯ä¾ï¼å°çµæç²¾çæ¬èº«è¦çºè¦ç£ç£çç¨åºãæåçæ¶æ§å©ç¨å·é«çå·è¡è¨èä¾å¥ å®æ¨çæ­¥é©çç£ç£åºç¤ï¼åæä½¿ç¨æ¨¹ççµæ§æ¢ç´¢ä¾åæç¶­è­·å¤åè§£æ±ºæ¹æ¡è»è·¡ãå¯¦é©è­æï¼æåçåæ³ä½¿æ´å°çæ¨¡åä¹è½å¨ç«¶ç­æ§ç¨å¼è¨­è¨ä»»åä¸­éæé«æåæºç¢ºåº¦åæè½ææ¨ï¼ä¸¦å»ºç«æ¯å³çµ±åé¥æ¨¡åæ´å¯é çé©è­ï¼èä¸éè¦è¨ç·´ PRMãæåçåæ³å¨ 5 åæ¨¡åå 3 åè³æéä¸ç²å¾é¡¯èé²æ­¥ï¼æ­£ç¢ºçå¹³åæå 26.9%ï¼æçæå 42.2%ãçµæè¡¨æï¼æä¾å·æå·é«é©è­è¨èççµæ§åæ¨çç©ºéå°æ¼è§£æ±ºè¤éçç¨å¼è¨­è¨ä»»åè³ééè¦ãæåå¨ä»¥ä¸ç¶²åéæ¾åå§ç¢¼åææè³æï¼https://github.com/zhuohaoyu/ORPS

##### **Qwen2.5 Technical Report**
2412.15115v1 by Qwen, :, An Yang, Baosong Yang, Beichen Zhang, Binyuan Hui, Bo Zheng, Bowen Yu, Chengyuan Li, Dayiheng Liu, Fei Huang, Haoran Wei, Huan Lin, Jian Yang, Jianhong Tu, Jianwei Zhang, Jianxin Yang, Jiaxi Yang, Jingren Zhou, Junyang Lin, Kai Dang, Keming Lu, Keqin Bao, Kexin Yang, Le Yu, Mei Li, Mingfeng Xue, Pei Zhang, Qin Zhu, Rui Men, Runji Lin, Tianhao Li, Tingyu Xia, Xingzhang Ren, Xuancheng Ren, Yang Fan, Yang Su, Yichang Zhang, Yu Wan, Yuqiong Liu, Zeyu Cui, Zhenru Zhang, Zihan Qiu

In this report, we introduce Qwen2.5, a comprehensive series of large
language models (LLMs) designed to meet diverse needs. Compared to previous
iterations, Qwen 2.5 has been significantly improved during both the
pre-training and post-training stages. In terms of pre-training, we have scaled
the high-quality pre-training datasets from the previous 7 trillion tokens to
18 trillion tokens. This provides a strong foundation for common sense, expert
knowledge, and reasoning capabilities. In terms of post-training, we implement
intricate supervised finetuning with over 1 million samples, as well as
multistage reinforcement learning. Post-training techniques enhance human
preference, and notably improve long text generation, structural data analysis,
and instruction following. To handle diverse and varied use cases effectively,
we present Qwen2.5 LLM series in rich sizes. Open-weight offerings include base
and instruction-tuned models, with quantized versions available. In addition,
for hosted solutions, the proprietary models currently include two
mixture-of-experts (MoE) variants: Qwen2.5-Turbo and Qwen2.5-Plus, both
available from Alibaba Cloud Model Studio. Qwen2.5 has demonstrated top-tier
performance on a wide range of benchmarks evaluating language understanding,
reasoning, mathematics, coding, human preference alignment, etc. Specifically,
the open-weight flagship Qwen2.5-72B-Instruct outperforms a number of open and
proprietary models and demonstrates competitive performance to the
state-of-the-art open-weight model, Llama-3-405B-Instruct, which is around 5
times larger. Qwen2.5-Turbo and Qwen2.5-Plus offer superior cost-effectiveness
while performing competitively against GPT-4o-mini and GPT-4o respectively.
Additionally, as the foundation, Qwen2.5 models have been instrumental in
training specialized models such as Qwen2.5-Math, Qwen2.5-Coder, QwQ, and
multimodal models.

æè¦ï¼<paragraph>å¨éä»½å ±åä¸­ï¼æåä»ç´¹äº Qwen2.5ï¼éæ¯ä¸åå¨é¢çå¤§èªè¨æ¨¡å (LLM) ç³»åï¼æ¨å¨æ»¿è¶³ä¸åçéæ±ãèä¹åçè¿­ä»£ç¸æ¯ï¼Qwen 2.5 å¨é è¨ç·´åå¾è¨ç·´éæ®µé½å¾å°äºé¡¯èæ¹é²ãå¨é è¨ç·´æ¹é¢ï¼æåå°é«åè³ªçé è¨ç·´æ¸æéå¾ä¹åç 7 ååç¬¦èæ´å±å°äº 18 ååç¬¦èãéçºå¸¸è­ãå°æ¥­ç¥è­åæ¨çè½åæä¾äºå å¯¦çåºç¤ãå¨å¾è¨ç·´æ¹é¢ï¼æåå¯¦æ½äºè¤éçç£ç£å¾®èª¿ï¼æ¨£æ¬éè¶é 100 è¬ï¼ä»¥åå¤éæ®µå¼·åå­¸ç¿ãå¾è¨ç·´æè¡å¢å¼·äºäººé¡åå¥½ï¼ä¸¦é¡¯èæ¹é²äºé·ææ¬çæãçµæ§åæ¸æåæåæä»¤éµå¾ªãçºäºææå°èçå¤æ¨£åçç¨ä¾ï¼æåæä¾äºè±å¯å°ºå¯¸ç Qwen2.5 LLM ç³»åãéæ¾æ¬éç¢ååæ¬åºç¤æ¨¡ååæä»¤èª¿æ´æ¨¡åï¼ä¸¦æä¾éåçæ¬ãæ­¤å¤ï¼å°æ¼è¨ç®¡è§£æ±ºæ¹æ¡ï¼å°ææ¨¡åç®ååæ¬å©åæ··åå°å®¶ (MoE) è®é«ï¼Qwen2.5-Turbo å Qwen2.5-Plusï¼åå¯å¨é¿éé²æ¨¡åå·¥ä½å®¤ç²å¾ãQwen2.5 å¨è©ä¼°èªè¨çè§£ãæ¨çãæ¸å­¸ãç·¨ç¢¼ãäººé¡åå¥½å°é½ç­æ¹é¢çä¸ç³»ååºæºæ¸¬è©¦ä¸­å±ç¤ºäºä¸æµçæ§è½ãå·é«ä¾èªªï¼éæ¾æ¬éæè¦ Qwen2.5-72B-Instruct åªæ¼è¨±å¤éæ¾åå°ææ¨¡åï¼ä¸¦å±ç¤ºäºèæåé²çéæ¾æ¬éæ¨¡å Llama-3-405B-Instruct çç«¶ç­æ§è½ï¼å¾èå¤§ç´å¤§ 5 åãQwen2.5-Turbo å Qwen2.5-Plus åå¥æä¾åªè¶çææ¬æçï¼åæè GPT-4o-mini å GPT-4o ç«¶ç­ãæ­¤å¤ï¼ä½çºåºç¤ï¼Qwen2.5 æ¨¡åå¨è¨ç·´ Qwen2.5-MathãQwen2.5-CoderãQwQ åå¤æ¨¡ææ¨¡åç­å°æ¥­æ¨¡åæ¹é¢ç¼æ®äºéè¦ä½ç¨ã</paragraph>

##### **Associative memory inspires improvements for in-context learning using a novel attention residual stream architecture**
2412.15113v1 by Thomas F Burns, Tomoki Fukai, Christopher J Earls

Large language models (LLMs) demonstrate an impressive ability to utilise
information within the context of their input sequences to appropriately
respond to data unseen by the LLM during its training procedure. This ability
is known as in-context learning (ICL). Humans and non-human animals demonstrate
similar abilities, however their neural architectures differ substantially from
LLMs. Despite this, a critical component within LLMs, the attention mechanism,
resembles modern associative memory models, widely used in and influenced by
the computational neuroscience community to model biological memory systems.
Using this connection, we introduce an associative memory model capable of
performing ICL. We use this as inspiration for a novel residual stream
architecture which allows information to directly flow between attention heads.
We test this architecture during training within a two-layer Transformer and
show its ICL abilities manifest more quickly than without this modification. We
then apply our architecture in small language models with 8 million parameters,
focusing on attention head values, with results also indicating improved ICL
performance at this larger and more naturalistic scale.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) è¡¨ç¾åºä»¤äººå°è±¡æ·±å»çè½åï¼è½å¤ å©ç¨å¶è¼¸å¥åºåä¸­çè³è¨ï¼é©ç¶å°åæ LLM å¨è¨ç·´éç¨ä¸­æªè¦éçè³æãéç¨®è½åç¨±çºèªå¢ä¸­å­¸ç¿ (ICL)ãäººé¡åéäººé¡åç©è¡¨ç¾åºé¡ä¼¼çè½åï¼ä½ä»åçç¥ç¶æ¶æ§è LLM æå¾å¤§ä¸åãåç®¡å¦æ­¤ï¼LLM ä¸­çä¸åééµçµæé¨åï¼æ³¨ææ©å¶ï¼é¡ä¼¼æ¼ç¾ä»£è¯æ³è¨æ¶æ¨¡åï¼å¨è¨ç®ç¥ç¶ç§å­¸ç¤¾ç¾¤ä¸­å»£æ³ä½¿ç¨ä¸¦åå°å¶å½±é¿ï¼ç¨æ¼å»ºæ¨¡çç©è¨æ¶ç³»çµ±ãå©ç¨éç¨®è¯ç¹«ï¼æåå¼å¥äºä¸åè½å¤ å·è¡ ICL çè¯æ³è¨æ¶æ¨¡åãæåä»¥æ­¤çºéæï¼æé äºä¸åæ°ç©çæ®å·®ä¸²æµæ¶æ§ï¼è®è³è¨è½å¤ ç´æ¥å¨æ³¨ææ¬éä¹éæµåãæåå¨ä¸åå©å±¤ Transformer ä¸­è¨ç·´æéæ¸¬è©¦éåæ¶æ§ï¼ä¸¦å±ç¤ºå¶ ICL è½åæ¯æ²æéåä¿®æ¹æè¡¨ç¾å¾æ´å¿«ãç¶å¾ï¼æåå°æåçæ¶æ§æç¨æ¼å·æ 800 è¬ååæ¸çå°èªè¨æ¨¡åï¼å°æ³¨æ¼æ³¨ææ¬éå¼ï¼çµæä¹è¡¨æå¨éåæ´å¤§ä¸æ´èªç¶çè¦æ¨¡ä¸ï¼ICL æè½æææåã

##### **Exploiting sparse structures and synergy designs to advance situational awareness of electrical power grid**
2412.15105v1 by Shimiao Li

The growing threats of uncertainties, anomalies, and cyberattacks on power
grids are driving a critical need to advance situational awareness which allows
system operators to form a complete and accurate picture of the present and
future state. Simulation and estimation are foundational tools in this process.
However, existing tools lack the robustness and efficiency required to achieve
the level of situational awareness needed for the ever-evolving threat
landscape. Industry-standard (steady-state) simulators are not robust to
blackouts, often leading to non-converging or non-actionable results.
Estimation tools lack robustness to anomalous data, returning erroneous system
states. Efficiency is the other major concern as nonlinearities and scalability
issues make large systems slow to converge.
  This thesis addresses robustness and efficiency gaps through a dual-fold
contribution. We first address the inherent limitations in the existing
physics-based and data-driven worlds; and then transcend the boundaries of
conventional algorithmic design in the direction of a new paradigm --
Physics-ML Synergy -- which integrates the strengths of the two worlds. Our
approaches are built on circuit formulation which provides a unified framework
that applies to both transmission and distribution. Sparse optimization acts as
the key enabler to make these tools intrinsically robust and immune to random
threats, pinpointing dominant sources of (random) blackouts and data errors.
Further, we explore sparsity-exploiting optimizations to develop lightweight ML
models whose prediction and detection capabilities are a complement to
physics-based tools; and whose lightweight designs advance generalization and
scalability. Finally, Physics-ML Synergy brings robustness and efficiency
further against targeted cyberthreats, by interconnecting our physics-based
tools with lightweight ML.

æè¦ï¼<paragraph>é»ç¶²ä¸­ä¸ç¢ºå®æ§ãç°å¸¸åç¶²è·¯æ»æçå¨èæ¥çå¢å ï¼éä¿ä½¿æåæ¥éæåæå¢æç¥ï¼è®ç³»çµ±æä½å¡è½å¤ å°ç¶ååæªä¾çæå½¢æå®æ´ä¸æºç¢ºçååãæ¨¡æ¬åä¼°è¨æ¯æ­¤éç¨ä¸­å¿åçå·¥å·ã
ä½æ¯ï¼ç¾æçå·¥å·ç¼ºä¹å¯¦ç¾æå¢æç¥æéçç©©å¥æ§åæçï¼èæå¢æç¥æ¯å æä¸æ·è®åçå¨èç°å¢æå¿éçãç¢æ¥­æ¨æºï¼ç©©æï¼æ¨¡æ¬å¨å°åé»ä¸¦ä¸ç©©å¥ï¼éå¸¸æå°è´ç¡æ³æ¶ææç¡æ³æ¡åè¡åççµæãä¼°è¨å·¥å·ç¼ºä¹å°ç°å¸¸è³æçç©©å¥æ§ï¼æåå ±é¯èª¤çç³»çµ±çæãæçæ¯å¦ä¸åä¸»è¦åé¡ï¼å çºéç·æ§åå¯æ´åæ§åé¡æä½¿å¾å¤§åç³»çµ±æ¶æéåº¦è®æ¢ã
æ¬è«æééééçè²¢ç»ä¾è§£æ±ºç©©å¥æ§åæççå·®è·ãæåé¦åè§£æ±ºç¾æåºæ¼ç©çåè³æé©åçä¸çä¸­åºæçéå¶ï¼ç¶å¾è¶è¶å³çµ±æ¼ç®æ³è¨­è¨ççéï¼æåä¸åæ°çå¸ç¯ââç©çæ©å¨å­¸ç¿ååææââéé²ï¼å®æ´åäºéå©åä¸ççåªå¢ãæåçåæ³å»ºç«å¨é»è·¯å¬å¼ä¹ä¸ï¼å®æä¾äºä¸åçµ±ä¸çæ¶æ§ï¼é©ç¨æ¼å³è¼¸åéé»ãç¨çæä½³åä½çºééµçæ¨æï¼è®éäºå·¥å·å¨å§é¨è®å¾ç©©å¥ï¼ä¸¦ä¸å°é¨æ©å¨èåç«ï¼ç²¾ç¢ºæ¾åºï¼é¨æ©ï¼åé»åè³æé¯èª¤çä¸»è¦ä¾æºã
æ­¤å¤ï¼æåæ¢ç´¢å©ç¨ç¨çæ§çæä½³åä¾éç¼è¼éç´æ©å¨å­¸ç¿æ¨¡åï¼å¶é æ¸¬ååµæ¸¬è½åå¯ä»¥è£ååºæ¼ç©ççå·¥å·ï¼èå¶è¼éç´çè¨­è¨åå¯ä»¥ä¿é²æ³ååå¯æ´åæ§ãæå¾ï¼ç©çæ©å¨å­¸ç¿ååææééå°æåçåºæ¼ç©ççå·¥å·èè¼éç´æ©å¨å­¸ç¿äºé£ï¼é²ä¸æ­¥æåå°éå°æ§ç¶²è·¯å¨èçç©©å¥æ§åæçã</paragraph>

##### **Review-Then-Refine: A Dynamic Framework for Multi-Hop Question Answering with Temporal Adaptability**
2412.15101v1 by Xiangsen Chen, Xuming Hu, Nan Tang

Retrieve-augmented generation (RAG) frameworks have emerged as a promising
solution to multi-hop question answering(QA) tasks since it enables large
language models (LLMs) to incorporate external knowledge and mitigate their
inherent knowledge deficiencies. Despite this progress, existing RAG
frameworks, which usually follows the retrieve-then-read paradigm, often
struggle with multi-hop QA with temporal information since it has difficulty
retrieving and synthesizing accurate time-related information. To address the
challenge, this paper proposes a novel framework called review-then-refine,
which aims to enhance LLM performance in multi-hop QA scenarios with temporal
information. Our approach begins with a review phase, where decomposed
sub-queries are dynamically rewritten with temporal information, allowing for
subsequent adaptive retrieval and reasoning process. In addition, we implement
adaptive retrieval mechanism to minimize unnecessary retrievals, thus reducing
the potential for hallucinations. In the subsequent refine phase, the LLM
synthesizes the retrieved information from each sub-query along with its
internal knowledge to formulate a coherent answer. Extensive experimental
results across multiple datasets demonstrate the effectiveness of our proposed
framework, highlighting its potential to significantly improve multi-hop QA
capabilities in LLMs.

æè¦ï¼æª¢ç´¢å¢å¼·çæ (RAG) æ¡æ¶å·²æçºå¤è·³å¼åç­ (QA) ä»»åçä¸ç¨®æåéçè§£æ±ºæ¹æ¡ï¼å çºå®ä½¿å¤§åèªè¨æ¨¡å (LLM) è½å¤ ç´å¥å¤é¨ç¥è­ä¸¦æ¸è¼å¶åºæçç¥è­ç¼ºé·ãåç®¡æéäºé²å±ï¼ç¾æç RAG æ¡æ¶éå¸¸éµå¾ªåæª¢ç´¢å¾é±è®çç¯ä¾ï¼ç±æ¼é£ä»¥æª¢ç´¢åç¶åæºç¢ºçæéç¸éè³è¨ï¼å æ­¤å¨å·ææéè³è¨çå¤è·³å¼åç­ä¸­ç¶å¸¸éå°å°é£ãçºäºæå°éä¸ææ°ï¼æ¬ææåºäºä¸ç¨®ç¨±çºåæª¢é±å¾ä¿®æ­£çæ°æ¡æ¶ï¼æ¨å¨å¢å¼· LLM å¨å·ææéè³è¨çå¤è·³å¼åç­å ´æ¯ä¸­çæ§è½ãæåçåæ³å¾æª¢é±éæ®µéå§ï¼å¨è©²éæ®µï¼åè§£çå­æ¥è©¢æä½¿ç¨æéè³è¨åææ¹å¯«ï¼åè¨±å¾çºçé©ææ§æª¢ç´¢åæ¨çéç¨ãæ­¤å¤ï¼æåå¯¦ä½äºé©ææ§æª¢ç´¢æ©å¶ä»¥æå¤§ç¨åº¦æ¸å°ä¸å¿è¦çæª¢ç´¢ï¼å¾èéä½ç¢çå¹»è¦ºçå¯è½æ§ãå¨å¾çºçä¿®æ­£éæ®µï¼LLM å°å¾æ¯åå­æ¥è©¢ä¸­æª¢ç´¢çè³è¨èå¶å§é¨ç¥è­ä¸èµ·ç¶åï¼ä»¥å½¢æä¸åé£è²«çç­æ¡ãè·¨å¤åè³æéçå»£æ³å¯¦é©çµæè­æäºæåæåºçæ¡æ¶çæææ§ï¼çªåºäºå¶é¡¯èæ¹å LLM ä¸­å¤è·³å¼åç­è½åçæ½åã

##### **A Cross-Domain Study of the Use of Persuasion Techniques in Online Disinformation**
2412.15098v1 by JoÃ£o A. Leite, Olesya Razuvayevskaya, Carolina Scarton, Kalina Bontcheva

Disinformation, irrespective of domain or language, aims to deceive or
manipulate public opinion, typically through employing advanced persuasion
techniques. Qualitative and quantitative research on the weaponisation of
persuasion techniques in disinformation has been mostly topic-specific (e.g.,
COVID-19) with limited cross-domain studies, resulting in a lack of
comprehensive understanding of these strategies. This study employs a
state-of-the-art persuasion technique classifier to conduct a large-scale,
multi-domain analysis of the role of 16 persuasion techniques in disinformation
narratives. It shows how different persuasion techniques are employed
disproportionately in different disinformation domains. We also include a
detailed case study on climate change disinformation, highlighting how
linguistic, psychological, and cultural factors shape the adaptation of
persuasion strategies to fit unique thematic contexts.

æè¦ï¼ä¸è«é åæèªè¨ï¼é¯èª¤è¨æ¯çç®çæ¯æ¬ºé¨ææå¼å¬ç¾è¼¿è«ï¼éå¸¸ééä½¿ç¨é²éèªªææå·§ãéæ¼å¨é¯èª¤è¨æ¯ä¸­å°èªªææå·§æ­¦å¨åçå®æ§åéåç ç©¶å¤§å¤æ¯éå°ç¹å®ä¸»é¡ï¼ä¾å¦ COVID-19ï¼ï¼è·¨é åç ç©¶æéï¼å°è´ç¡æ³å¨é¢äºè§£éäºç­ç¥ãæ¬ç ç©¶æ¡ç¨æåé²çèªªææå·§åé¡å¨ï¼å° 16 ç¨®èªªææå·§å¨é¯èª¤è¨æ¯æè¿°ä¸­çè§è²é²è¡å¤§è¦æ¨¡ãå¤é ååæãå®é¡¯ç¤ºä¸åçèªªææå·§å¦ä½å¨ä¸åçé¯èª¤è¨æ¯é åä¸­ä¸ææ¯ä¾å°ä½¿ç¨ãæåéåæ¬ä¸åéæ¼æ°£åè®é·é¯èª¤è¨æ¯çè©³ç´°æ¡ä¾ç ç©¶ï¼å¼·èª¿èªè¨ãå¿çåæåå ç´ å¦ä½å½±é¿èªªæç­ç¥ä»¥é©æç¨ç¹çè­°é¡èçµ¡ã

##### **A Full Transformer-based Framework for Automatic Pain Estimation using Videos**
2412.15095v1 by Stefanos Gkikas, Manolis Tsiknakis

The automatic estimation of pain is essential in designing an optimal pain
management system offering reliable assessment and reducing the suffering of
patients. In this study, we present a novel full transformer-based framework
consisting of a Transformer in Transformer (TNT) model and a Transformer
leveraging cross-attention and self-attention blocks. Elaborating on videos
from the BioVid database, we demonstrate state-of-the-art performances, showing
the efficacy, efficiency, and generalization capability across all the primary
pain estimation tasks.

æè¦ï¼ç¼ççèªåè©ä¼°å°æ¼è¨­è¨ä¸åæä½³çç¼çç®¡çç³»çµ±è³ééè¦ï¼è©²ç³»çµ±æä¾å¯é çè©ä¼°ä¸¦æ¸è¼æ£èççè¦ãå¨æ¬ç ç©¶ä¸­ï¼æåæåºäºä¸åæ°ç©çåºæ¼å®å¨Transformerçæ¡æ¶ï¼å®ç±Transformerä¸­çTransformer (TNT) æ¨¡ååä¸åå©ç¨äº¤åæ³¨æååèªæ³¨æåå¡çTransformerçµæãééé¡è¿° BioVid æ¸æåº«ä¸­çè¦é »ï¼æåå±ç¤ºäºæåé²çæ§è½ï¼å±ç¤ºäºå¨ææä¸»è¦çç¼çè©ä¼°ä»»åä¸­çåæãæçåæ³åè½åã

##### **Learning Disentangled Equivariant Representation for Explicitly Controllable 3D Molecule Generation**
2412.15086v1 by Haoran Liu, Youzhi Luo, Tianxiao Li, James Caverlee, Martin Renqiang Min

We consider the conditional generation of 3D drug-like molecules with
\textit{explicit control} over molecular properties such as drug-like
properties (e.g., Quantitative Estimate of Druglikeness or Synthetic
Accessibility score) and effectively binding to specific protein sites. To
tackle this problem, we propose an E(3)-equivariant Wasserstein autoencoder and
factorize the latent space of our generative model into two disentangled
aspects: molecular properties and the remaining structural context of 3D
molecules. Our model ensures explicit control over these molecular attributes
while maintaining equivariance of coordinate representation and invariance of
data likelihood. Furthermore, we introduce a novel alignment-based coordinate
loss to adapt equivariant networks for auto-regressive de-novo 3D molecule
generation from scratch. Extensive experiments validate our model's
effectiveness on property-guided and context-guided molecule generation, both
for de-novo 3D molecule design and structure-based drug discovery against
protein targets.

æè¦ï¼æåèæ®å·æå°åå­ç¹æ§ï¼ä¾å¦è¥ç©ç¹æ§ï¼ä¾å¦è¥ç©ç¸ä¼¼æ§æåæå¯åæ§è©åï¼çæç¢ºæ§å¶ï¼ç 3D è¥ç©æ¨£åå­çæ¢ä»¶çæï¼ä¸¦ææå°èç¹å®èç½è³ªä½é»çµåãçºäºè§£æ±ºéååé¡ï¼æåæåºä¸å E(3)-ç­è® Wasserstein èªåç·¨ç¢¼å¨ï¼ä¸¦å°æåçææ¨¡åçæ½å¨ç©ºéåè§£çºå©åè§£éçæ¹é¢ï¼åå­ç¹æ§å 3D åå­çå©é¤çµæ§èæ¯ãæåçæ¨¡åç¢ºä¿å°éäºåå­å±¬æ§é²è¡æç¢ºæ§å¶ï¼åæä¿æåº§æ¨è¡¨ç¤ºçç­è®æ§åæ¸æä¼¼ç¶çæå®æ§ãæ­¤å¤ï¼æåå¼å¥äºä¸ååºæ¼å°é½çæ°çåº§æ¨æå¤±ï¼ä»¥é©æç­è®ç¶²è·¯ï¼å¾é ­éå§é²è¡èªåæ­¸å¾é ­ 3D åå­çæãå¤§éçå¯¦é©é©è­äºæåæ¨¡åå¨å±¬æ§å¼å°åèæ¯å¼å°åå­çææ¹é¢çæææ§ï¼æ¢é©ç¨æ¼å¾é ­ 3D åå­è¨­è¨ï¼ä¹é©ç¨æ¼éå°èç½è³ªé¶æ¨çåºæ¼çµæ§çè¥ç©ç¼ç¾ã

##### **AceMath: Advancing Frontier Math Reasoning with Post-Training and Reward Modeling**
2412.15084v1 by Zihan Liu, Yang Chen, Mohammad Shoeybi, Bryan Catanzaro, Wei Ping

In this paper, we introduce AceMath, a suite of frontier math models that
excel in solving complex math problems, along with highly effective reward
models capable of evaluating generated solutions and reliably identifying the
correct ones. To develop the instruction-tuned math models, we propose a
supervised fine-tuning (SFT) process that first achieves competitive
performance across general domains, followed by targeted fine-tuning for the
math domain using a carefully curated set of prompts and synthetically
generated responses. The resulting model, AceMath-72B-Instruct greatly
outperforms Qwen2.5-Math-72B-Instruct, GPT-4o and Claude-3.5 Sonnet. To develop
math-specialized reward model, we first construct AceMath-RewardBench, a
comprehensive and robust benchmark for evaluating math reward models across
diverse problems and difficulty levels. After that, we present a systematic
approach to build our math reward models. The resulting model, AceMath-72B-RM,
consistently outperforms state-of-the-art reward models. Furthermore, when
combining AceMath-72B-Instruct with AceMath-72B-RM, we achieve the highest
average rm@8 score across the math reasoning benchmarks. We will release model
weights, training data, and evaluation benchmarks at:
https://research.nvidia.com/labs/adlr/acemath

æè¦ï¼<paragraph>å¨æ¬æä¸­ï¼æåä»ç´¹ AceMathï¼éæ¯ä¸å¥åæ²¿æ¸å­¸æ¨¡åï¼æé·è§£æ±ºè¤éçæ¸å­¸åé¡ï¼ä¸¦å·åé«æççåµæ¨¡åï¼è½å¤ è©ä¼°çæçè§£ä¸¦å¯é å°æ¾åºæ­£ç¢ºçè§£ãçºäºéç¼æä»¤èª¿æ´çæ¸å­¸æ¨¡åï¼æåæåºäºä¸åç£ç£å¾®èª¿ (SFT) éç¨ï¼é¦åå¨ä¸è¬é åä¸­å¯¦ç¾ç«¶ç­åï¼ç¶å¾ä½¿ç¨ç²¾å¿ç­åçæç¤ºååæçæçåæï¼éå°æ¸å­¸é åé²è¡ç®æ¨å¾®èª¿ãç±æ­¤ç¢ççæ¨¡å AceMath-72B-Instruct å¤§å¤§åªæ¼ Qwen2.5-Math-72B-InstructãGPT-4o å Claude-3.5 Sonnetãçºäºéç¼æ¸å­¸å°æ¥­çåµæ¨¡åï¼æåé¦åæ§å»º AceMath-RewardBenchï¼ä¸åå¨é¢ä¸ç©©å¥çåºæºï¼ç¨æ¼è©ä¼°æ¸å­¸çåµæ¨¡åå¨ä¸ååé¡åé£åº¦ç´å¥ä¸çè¡¨ç¾ãä¹å¾ï¼æåæåºäºä¸åç³»çµ±æ§çæ¹æ³ä¾æ§å»ºæåçæ¸å­¸çåµæ¨¡åãç±æ­¤ç¢ççæ¨¡å AceMath-72B-RMï¼å§çµåªæ¼æåé²ççåµæ¨¡åãæ­¤å¤ï¼ç¶å° AceMath-72B-Instruct è AceMath-72B-RM çµåä½¿ç¨æï¼æåå¨æ¸å­¸æ¨çåºæºä¸­ç²å¾äºæé«çå¹³å rm@8 åæ¸ãæåå°å¨ä»¥ä¸ç¶²åç¼å¸æ¨¡åæ¬éãè¨ç·´æ¸æåè©ä¼°åºæºï¼
https://research.nvidia.com/labs/adlr/acemath</paragraph>

##### **Till the Layers Collapse: Compressing a Deep Neural Network through the Lenses of Batch Normalization Layers**
2412.15077v1 by Zhu Liao, Nour Hezbri, Victor QuÃ©tu, Van-Tam Nguyen, Enzo Tartaglione

Today, deep neural networks are widely used since they can handle a variety
of complex tasks. Their generality makes them very powerful tools in modern
technology. However, deep neural networks are often overparameterized. The
usage of these large models consumes a lot of computation resources. In this
paper, we introduce a method called \textbf{T}ill the \textbf{L}ayers
\textbf{C}ollapse (TLC), which compresses deep neural networks through the
lenses of batch normalization layers. By reducing the depth of these networks,
our method decreases deep neural networks' computational requirements and
overall latency. We validate our method on popular models such as Swin-T,
MobileNet-V2, and RoBERTa, across both image classification and natural
language processing (NLP) tasks.

æè¦ï¼<paragraph>å¦ä»ï¼æ·±åº¦ç¥ç»ç½ç»è¢«å¹¿æ³ä½¿ç¨ï¼å ä¸ºå®ä»¬å¯ä»¥å¤çåç§å¤æçä»»å¡ãå®ä»¬çæ®éæ§ä½¿å®ä»¬æä¸ºç°ä»£ææ¯ä¸­éå¸¸å¼ºå¤§çå·¥å·ãç¶èï¼æ·±åº¦ç¥ç»ç½ç»éå¸¸æ¯è¿åæ°åçãä½¿ç¨è¿äºå¤§åæ¨¡åä¼æ¶èå¤§éè®¡ç®èµæºãå¨æ¬æä¸­ï¼æä»¬ä»ç»äºä¸ç§ç§°ä¸º\textbf{T}ill the \textbf{L}ayers \textbf{C}ollapse (TLC) çæ¹æ³ï¼è¯¥æ¹æ³éè¿æ¹å½ä¸åå±çééåç¼©æ·±åº¦ç¥ç»ç½ç»ãéè¿åå°è¿äºç½ç»çæ·±åº¦ï¼æä»¬çæ¹æ³éä½äºæ·±åº¦ç¥ç»ç½ç»çè®¡ç®éæ±åæ´ä½å»¶è¿ãæä»¬å¨æµè¡çæ¨¡åï¼ä¾å¦ Swin-TãMobileNet-V2 å RoBERTaï¼ä¸éªè¯äºæä»¬çæ¹æ³ï¼æ¶µçå¾ååç±»åèªç¶è¯­è¨å¤ç (NLP) ä»»å¡ã</paragraph>

##### **ConfliBERT: A Language Model for Political Conflict**
2412.15060v1 by Patrick T. Brandt, Sultan Alsarra, Vito J. D`Orazio, Dagmar Heintze, Latifur Khan, Shreyas Meher, Javier Osorio, Marcus Sianan

Conflict scholars have used rule-based approaches to extract information
about political violence from news reports and texts. Recent Natural Language
Processing developments move beyond rigid rule-based approaches. We review our
recent ConfliBERT language model (Hu et al. 2022) to process political and
violence related texts. The model can be used to extract actor and action
classifications from texts about political conflict. When fine-tuned, results
show that ConfliBERT has superior performance in accuracy, precision and recall
over other large language models (LLM) like Google's Gemma 2 (9B), Meta's Llama
3.1 (7B), and Alibaba's Qwen 2.5 (14B) within its relevant domains. It is also
hundreds of times faster than these more generalist LLMs. These results are
illustrated using texts from the BBC, re3d, and the Global Terrorism Dataset
(GTD).

æè¦ï¼è¡çªå­¸èå·²ä½¿ç¨åºæ¼è¦åçæ¹æ³å¾æ°èå ±å°åæå­ä¸­æ·åæéæ¿æ²»æ´åçè³è¨ãæè¿çèªç¶èªè¨èçç¼å±å·²è¶è¶åµåçåºæ¼è¦åçæ¹æ³ãæåæª¢è¦æåæè¿ç ConfliBERT èªè¨æ¨¡å (Hu et al. 2022) ä»¥èçæ¿æ²»åæ´åç¸éæå­ãè©²æ¨¡åå¯ used to extract actor and action classifications from texts about political conflict.å¾®èª¿å¾ï¼çµæé¡¯ç¤º ConfliBERT å¨å¶ç¸éé åä¸­ï¼å¨æºç¢ºåº¦ãç²¾ç¢ºåº¦åå¬åçæ¹é¢é½åªæ¼å¶ä»å¤§åèªè¨æ¨¡å (LLM)ï¼ä¾å¦ Google ç Gemma 2 (9B)ãMeta ç Llama 3.1 (7B) åé¿éå·´å·´ç Qwen 2.5 (14B)ãå®ä¹æ¯éäºæ´éç¨ç LLM å¿«ä¸æ¸ç¾åãéäºçµæä½¿ç¨ä¾èª BBCãre3d åå¨çææä¸»ç¾©è³æé (GTD) çæå­èªªæã

##### **Measuring, Modeling, and Helping People Account for Privacy Risks in Online Self-Disclosures with AI**
2412.15047v1 by Isadora Krsek, Anubha Kabra, Yao Dou, Tarek Naous, Laura A. Dabbish, Alan Ritter, Wei Xu, Sauvik Das

In pseudonymous online fora like Reddit, the benefits of self-disclosure are
often apparent to users (e.g., I can vent about my in-laws to understanding
strangers), but the privacy risks are more abstract (e.g., will my partner be
able to tell that this is me?). Prior work has sought to develop natural
language processing (NLP) tools that help users identify potentially risky
self-disclosures in their text, but none have been designed for or evaluated
with the users they hope to protect. Absent this assessment, these tools will
be limited by the social-technical gap: users need assistive tools that help
them make informed decisions, not paternalistic tools that tell them to avoid
self-disclosure altogether. To bridge this gap, we conducted a study with N =
21 Reddit users; we had them use a state-of-the-art NLP disclosure detection
model on two of their authored posts and asked them questions to understand if
and how the model helped, where it fell short, and how it could be improved to
help them make more informed decisions. Despite its imperfections, users
responded positively to the model and highlighted its use as a tool that can
help them catch mistakes, inform them of risks they were unaware of, and
encourage self-reflection. However, our work also shows how, to be useful and
usable, AI for supporting privacy decision-making must account for posting
context, disclosure norms, and users' lived threat models, and provide
explanations that help contextualize detected risks.

æè¦ï¼å¨ Reddit ç­å¿åç¶²è·¯è«å£ä¸­ï¼èªææ­é²çåªé»å°ä½¿ç¨èä¾èªªéå¸¸å¾æé¡¯ï¼ä¾å¦ï¼æå¯ä»¥åçè§£æçéçäººç¼æ´©å°å§»è¦ªçä¸æ»¿ï¼ï¼ä½é±ç§é¢¨éªåè¼çºæ½è±¡ï¼ä¾å¦ï¼æçä¼´ä¾¶æ¯å¦æç¥ééæ¯æï¼ï¼ãååçç ç©¶è©¦åéç¼èªç¶èªè¨èç (NLP) å·¥å·ï¼åå©ä½¿ç¨èè¾¨è­å¶æå­ä¸­æ½å¨æé¢¨éªçèªææ­é²ï¼ä½æ²æä¸é æ¯å°éçºä»åå¸æä¿è­·çä½¿ç¨èæè¨­è¨æè©ä¼°çãå¨æ²æéé è©ä¼°çææ³ä¸ï¼éäºå·¥å·å°åå°ç¤¾ææè¡å·®è·çéå¶ï¼ä½¿ç¨èéè¦è¼å©å·¥å·ä¾å¹«å©ä»åååºææºçæ±ºå®ï¼èä¸æ¯åè¨´ä»åå®å¨é¿åèªææ­é²çç¶æ¬å¼å·¥å·ãçºäºå½åçè«èå¯¦åçå·®è·ï¼æåå° N = 21 ä½ Reddit ä½¿ç¨èé²è¡äºä¸é ç ç©¶ï¼æåè«ä»åä½¿ç¨æåé²ç NLP æ­é²åµæ¸¬æ¨¡åï¼éå°ä»åæ°å¯«çå©ç¯æç« é²è¡åæï¼ä¸¦åä»åæåï¼ä»¥äºè§£è©²æ¨¡åæ¯å¦æå¹«å©ãå¦ä½å¹«å©ãä¸è¶³ä¹èï¼ä»¥åå¦ä½æ¹é²ä»¥å¹«å©ä»åååºæ´ææºçæ±ºå®ãåç®¡æå¶ç¼ºé·ï¼ä½¿ç¨èå°è©²æ¨¡åçåæä»æ¯æ­£é¢çï¼ä¸¦å¼·èª¿å¶å¯ç¨ä½ä¸ç¨®å·¥å·ï¼å¹«å©ä»åæ¾åºé¯èª¤ãåç¥ä»åä¸ç¥éçé¢¨éªï¼ä¸¦é¼åµèªæåçãç¶èï¼æåçç ç©¶ä¹é¡¯ç¤ºï¼çºäºå¯¦ç¨ä¸å¯ç¨ï¼æ¯æ´é±ç§æ±ºç­ç AI å¿é èæ®ç¼æèæ¯ãæ­é²è¦ç¯åä½¿ç¨èçæ¢æå¨èæ¨¡åï¼ä¸¦æä¾èªªæä»¥å¹«å©å°åµæ¸¬å°çé¢¨éªèçµ¡åã

##### **LLMs Lost in Translation: M-ALERT uncovers Cross-Linguistic Safety Gaps**
2412.15035v1 by Felix Friedrich, Simone Tedeschi, Patrick Schramowski, Manuel Brack, Roberto Navigli, Huu Nguyen, Bo Li, Kristian Kersting

Building safe Large Language Models (LLMs) across multiple languages is
essential in ensuring both safe access and linguistic diversity. To this end,
we introduce M-ALERT, a multilingual benchmark that evaluates the safety of
LLMs in five languages: English, French, German, Italian, and Spanish. M-ALERT
includes 15k high-quality prompts per language, totaling 75k, following the
detailed ALERT taxonomy. Our extensive experiments on 10 state-of-the-art LLMs
highlight the importance of language-specific safety analysis, revealing that
models often exhibit significant inconsistencies in safety across languages and
categories. For instance, Llama3.2 shows high unsafety in the category
crime_tax for Italian but remains safe in other languages. Similar differences
can be observed across all models. In contrast, certain categories, such as
substance_cannabis and crime_propaganda, consistently trigger unsafe responses
across models and languages. These findings underscore the need for robust
multilingual safety practices in LLMs to ensure safe and responsible usage
across diverse user communities.

æè¦ï¼å»ºç«è·¨å¤ç¨®èªè¨çå®å¨å¤§åèªè¨æ¨¡å (LLM) å°æ¼ç¢ºä¿å®å¨å­ååèªè¨å¤æ¨£æ§è³ééè¦ãçºæ­¤ï¼æåå¼å¥äº M-ALERTï¼éæ¯ä¸åå¤èªè¨åºæºï¼ç¨æ¼è©ä¼°äºç¨®èªè¨ï¼è±èªãæ³èªãå¾·èªãç¾©å¤§å©èªåè¥¿ç­çèªï¼ä¸­ LLM çå®å¨æ§ãM-ALERT åå«æ¯ç¨®èªè¨ 15k åé«åè³ªæç¤ºï¼ç¸½è¨ 75kï¼éµå¾ªè©³ç´°ç ALERT åé¡æ³ãæåå° 10 åæåé²ç LLM é²è¡çå»£æ³å¯¦é©çªé¡¯äºç¹å®èªè¨å®å¨åæçéè¦æ§ï¼æ­ç¤ºäºæ¨¡åå¨ä¸åèªè¨åé¡å¥ä¸­çå®å¨æ§å¾å¾å­å¨é¡¯èä¸ä¸è´ãä¾å¦ï¼Llama3.2 å¨ç¾©å¤§å©èªç crime_tax é¡å¥ä¸­è¡¨ç¾åºé«åº¦ä¸å®å¨æ§ï¼ä½å¨å¶ä»èªè¨ä¸­ä»ç¶å®å¨ãå¨æææ¨¡åä¸­é½å¯ä»¥è§å¯å°é¡ä¼¼çå·®ç°ãç¸æ¯ä¹ä¸ï¼æäºé¡å¥ï¼ä¾å¦ substance_cannabis å crime_propagandaï¼ææçºè§¸ç¼ä¸åæ¨¡ååèªè¨çä¸å®å¨åæãéäºç¼ç¾å¼·èª¿äºå¨ LLM ä¸­æ¡ç¨å¼·å¥çå¤èªè¨å®å¨å¯¦åï¼ä»¥ç¢ºä¿å¨ä¸åçä½¿ç¨èç¤¾ç¾¤ä¸­å®å¨ä¸è² è²¬ä»»å°ä½¿ç¨ã

##### **Large Language Models and Code Security: A Systematic Literature Review**
2412.15004v1 by Enna Basic, Alberto Giaretta

Large Language Models (LLMs) have emerged as powerful tools for automating
various programming tasks, including security-related ones, such as detecting
and fixing vulnerabilities. Despite their promising capabilities, when required
to produce or modify pre-existing code, LLMs could introduce vulnerabilities
unbeknown to the programmer. When analyzing code, they could miss clear
vulnerabilities or signal nonexistent ones. In this Systematic Literature
Review (SLR), we aim to investigate both the security benefits and potential
drawbacks of using LLMs for a variety of code-related tasks. In particular,
first we focus on the types of vulnerabilities that could be introduced by
LLMs, when used for producing code. Second, we analyze the capabilities of LLMs
to detect and fix vulnerabilities, in any given code, and how the prompting
strategy of choice impacts their performance in these two tasks. Last, we
provide an in-depth analysis on how data poisoning attacks on LLMs can impact
performance in the aforementioned tasks.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å·²æçºèªåååç¨®ç¨å¼è¨­è¨ä»»åçå¼·å¤§å·¥å·ï¼åæ¬èå®å¨æ§ç¸éçä»»åï¼ä¾å¦åµæ¸¬åä¿®å¾©æ¼æ´ãåç®¡å®åå·æä»¤äººæå¾çè½åï¼ä½å¨éè¦ç¢çæä¿®æ¹ç¾æç¨å¼ç¢¼æï¼LLM å¯è½æå¨ç¨å¼è¨­è¨äººå¡ä¸ç¥æçææ³ä¸å¼å¥æ¼æ´ãå¨åæç¨å¼ç¢¼æï¼å®åå¯è½æéºæ¼æé¡¯çæ¼æ´æç¼åºä¸å­å¨çæ¼æ´è¨èãå¨æ­¤ç³»çµ±æ§æç»åé¡§ (SLR) ä¸­ï¼æåæ¨å¨æ¢è¨ä½¿ç¨ LLM å·è¡åç¨®ç¨å¼ç¢¼ç¸éä»»åçå®å¨æ§å¥½èåæ½å¨ç¼ºé»ãç¹å¥æ¯ï¼æåé¦åéæ³¨ LLM å¨ç¨æ¼ç¢çç¨å¼ç¢¼æå¯è½å¼å¥çæ¼æ´é¡åãå¶æ¬¡ï¼æååæ LLM å¨ä»»ä½çµ¦å®ç¨å¼ç¢¼ä¸­åµæ¸¬åä¿®å¾©æ¼æ´çè½åï¼ä»¥åæç¤ºç­ç¥å¦ä½å½±é¿å®åå¨éäºä»»åä¸­çæè½ãæå¾ï¼æåæ·±å¥åæè³æä¸­æ¯æ»æå¦ä½å½±é¿ LLM å¨ä¸è¿°ä»»åä¸­çæè½ã

##### **HSEvo: Elevating Automatic Heuristic Design with Diversity-Driven Harmony Search and Genetic Algorithm Using LLMs**
2412.14995v1 by Pham Vu Tuan Dat, Long Doan, Huynh Thi Thanh Binh

Automatic Heuristic Design (AHD) is an active research area due to its
utility in solving complex search and NP-hard combinatorial optimization
problems in the real world. The recent advancements in Large Language Models
(LLMs) introduce new possibilities by coupling LLMs with evolutionary
computation to automatically generate heuristics, known as LLM-based
Evolutionary Program Search (LLM-EPS). While previous LLM-EPS studies obtained
great performance on various tasks, there is still a gap in understanding the
properties of heuristic search spaces and achieving a balance between
exploration and exploitation, which is a critical factor in large heuristic
search spaces. In this study, we address this gap by proposing two diversity
measurement metrics and perform an analysis on previous LLM-EPS approaches,
including FunSearch, EoH, and ReEvo. Results on black-box AHD problems reveal
that while EoH demonstrates higher diversity than FunSearch and ReEvo, its
objective score is unstable. Conversely, ReEvo's reflection mechanism yields
good objective scores but fails to optimize diversity effectively. With this
finding in mind, we introduce HSEvo, an adaptive LLM-EPS framework that
maintains a balance between diversity and convergence with a harmony search
algorithm. Through experimentation, we find that HSEvo achieved high diversity
indices and good objective scores while remaining cost-effective. These results
underscore the importance of balancing exploration and exploitation and
understanding heuristic search spaces in designing frameworks in LLM-EPS.

æè¦ï¼èªååç¼å¼è¨­è¨ (AHD) å å¶å¨è§£æ±ºç¾å¯¦ä¸çä¸­è¤éçæå°å NP é£çµåæä½³ååé¡ä¸­çæç¨èæçºä¸åæ´»èºçç ç©¶é åãå¤§åèªè¨æ¨¡å (LLM) çææ°é²å±å¼å¥äºæ°çå¯è½æ§ï¼å° LLM èæ¼åè¨ç®çµåèµ·ä¾èªåçæåç¼å¼ï¼ç¨±çºåºæ¼ LLM çæ¼åç¨å¼æå° (LLM-EPS)ãéç¶ååç LLM-EPS ç ç©¶å¨åç¨®ä»»åä¸ç²å¾äºå¾å¥½çæè½ï¼ä½å¨çè§£åç¼å¼æå°ç©ºéçå±¬æ§åå¨æ¢ç´¢åå©ç¨ä¹éåå¾å¹³è¡¡æ¹é¢ä»ç¶å­å¨å·®è·ï¼éæ¯å¤§ååç¼å¼æå°ç©ºéä¸­çééµå ç´ ãå¨æ¬ç ç©¶ä¸­ï¼æåééæåºå©åå¤æ¨£æ§æ¸¬éææ¨ä¾è§£æ±ºéåå·®è·ï¼ä¸¦å°ååç LLM-EPS æ¹æ³é²è¡åæï¼åæ¬ FunSearchãEoH å ReEvoãé»ç®± AHD åé¡ççµæé¡¯ç¤ºï¼éç¶ EoH å±ç¾åºæ¯ FunSearch å ReEvo æ´é«çå¤æ¨£æ§ï¼ä½å¶ç®æ¨åæ¸ä¸ç©©å®ãç¸åå°ï¼ReEvo çåå°æ©å¶ç¢çäºè¯å¥½çç®æ¨åæ¸ï¼ä½æªè½æææä½³åå¤æ¨£æ§ãæäºéåç¼ç¾ï¼æåå¼å¥äº HSEvoï¼ä¸åèªé©æ LLM-EPS æ¡æ¶ï¼ééåè«§æå°æ¼ç®æ³å¨å¤æ¨£æ§åæ¶æä¹éåå¾å¹³è¡¡ãééå¯¦é©ï¼æåç¼ç¾ HSEvo éå°äºé«å¤æ¨£æ§ææ¨åè¯å¥½çç®æ¨åæ¸ï¼åæä»ç¶å·æææ¬æçãéäºçµæå¼·èª¿äºå¨è¨­è¨ LLM-EPS ä¸­çæ¡æ¶æï¼å¹³è¡¡æ¢ç´¢åå©ç¨ä»¥åçè§£åç¼å¼æå°ç©ºéçéè¦æ§ã

##### **Chain-of-MetaWriting: Linguistic and Textual Analysis of How Small Language Models Write Young Students Texts**
2412.14986v1 by Ioana Buhnila, Georgeta Cislaru, Amalia Todirascu

Large Language Models (LLMs) have been used to generate texts in response to
different writing tasks: reports, essays, story telling. However, language
models do not have a meta-representation of the text writing process, nor
inherent communication learning needs, comparable to those of young human
students. This paper introduces a fine-grained linguistic and textual analysis
of multilingual Small Language Models' (SLMs) writing. With our method,
Chain-of-MetaWriting, SLMs can imitate some steps of the human writing process,
such as planning and evaluation. We mainly focused on short story and essay
writing tasks in French for schoolchildren and undergraduate students
respectively. Our results show that SLMs encounter difficulties in assisting
young students on sensitive topics such as violence in the schoolyard, and they
sometimes use words too complex for the target audience. In particular, the
output is quite different from the human produced texts in term of text
cohesion and coherence regarding temporal connectors, topic progression,
reference.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å·²ç¨æ¼ç¢çæå­ä»¥åæä¸åçå¯«ä½ä»»åï¼å ±åãè«æãæäºæè¿°ãç¶èï¼èªè¨æ¨¡åæ²ææå­å¯«ä½éç¨çåè¡¨ç¤ºï¼ä¹æ²æèå¹´è¼äººé¡å­¸çç¸ç¶çå§å¨æºéå­¸ç¿éæ±ãæ¬æä»ç´¹äºå¤èªè¨å°åèªè¨æ¨¡å (SLM) å¯«ä½çç´°ç·»èªè¨åææ¬åæãééæåçæ¹æ³ï¼åå¯«ä½éï¼SLM å¯ä»¥æ¨¡ä»¿äººé¡å¯«ä½éç¨çæäºæ­¥é©ï¼ä¾å¦è¦ååè©ä¼°ãæåä¸»è¦å°æ³¨æ¼æ³èªçç­ç¯æäºåè«æå¯«ä½ä»»åï¼åå¥éå°å­¸ç«¥åå¤§å­¸çãæåççµæé¡¯ç¤ºï¼SLM å¨åå©å¹´è¼å­¸çèçææä¸»é¡ï¼ä¾å¦æ ¡åæ´åï¼æéå°å°é£ï¼èä¸æææä½¿ç¨å°ç®æ¨åç¾ä¾èªªéæ¼è¤éçè©å½ãç¹å¥æ¯ï¼å¨ææ¬é£è²«æ§åéæ¼æéé£æ¥è©ãä¸»é¡é²å±ãå¼ç¨çç¸å¹²æ§æ¹é¢ï¼è¼¸åºèäººé¡ç¢ççææ¬æå¾å¤§ä¸åã

##### **Movie2Story: A framework for understanding videos and telling stories in the form of novel text**
2412.14965v1 by Kangning Li, Zheyang Jia, Anyu Ying

Multimodal video-to-text models have made considerable progress, primarily in
generating brief descriptions of video content. However, there is still a
deficiency in generating rich long-form text descriptions that integrate both
video and audio. In this paper, we introduce a framework called M2S, designed
to generate novel-length text by combining audio, video, and character
recognition. M2S includes modules for video long-form text description and
comprehension, audio-based analysis of emotion, speech rate, and character
alignment, and visual-based character recognition alignment. By integrating
multimodal information using the large language model GPT4o, M2S stands out in
the field of multimodal text generation. We demonstrate the effectiveness and
accuracy of M2S through comparative experiments and human evaluation.
Additionally, the model framework has good scalability and significant
potential for future research.

æè¦ï¼å¤æ¨¡æå½±çè½æå­æ¨¡åå·²åå¾é¡¯èé²å±ï¼ä¸»è¦å¨æ¼ç¢çå½±çå§å®¹çç°¡ç­æè¿°ãç¶èï¼å¨ç¢çæ´åè¦è¨åé³è¨çè±å¯é·ç¯æå­æè¿°æ¹é¢ï¼ä»æä¸è¶³ä¹èãå¨æ¬æä¸­ï¼æåä»ç´¹äºä¸ååçº M2S çæ¶æ§ï¼æ¨å¨ééçµåé³è¨ãè¦è¨åè§è²è­å¥ä¾ç¢çå°èªªé·åº¦çæå­ãM2S åå«è¦è¨é·ç¯æå­æè¿°åçè§£ãåºæ¼é³è¨çæç·åæãèªéåè§è²å°é½ï¼ä»¥ååºæ¼è¦è¦ºçè§è²è­å¥å°é½ç­æ¨¡çµãééä½¿ç¨å¤§åèªè¨æ¨¡å GPT4o æ´åå¤æ¨¡æè³è¨ï¼M2S å¨å¤æ¨¡ææå­ç¢ççé åä¸­è«ç©èåºãæåééæ¯è¼å¯¦é©åäººå·¥è©ä¼°ï¼è­æäº M2S çæææ§åæºç¢ºæ§ãæ­¤å¤ï¼è©²æ¨¡åæ¶æ§å·æè¯å¥½çå¯æ´åæ§ï¼ä¸¦å°æªä¾çç ç©¶å·æé¡¯èçæ½åã

##### **Knowledge Injection via Prompt Distillation**
2412.14964v1 by Kalle KujanpÃ¤Ã¤, Harri Valpola, Alexander Ilin

In many practical applications, large language models (LLMs) need to
incorporate new knowledge not present in their pre-training data. The primary
methods for this are fine-tuning and retrieval-augmented generation (RAG).
Although RAG has emerged as the industry standard for knowledge injection,
fine-tuning has not yet achieved comparable success. In this paper, we propose
a new fine-tuning technique for learning new knowledge and show that it can
reach the performance of RAG. The proposed method is based on the
self-distillation approach, which we call prompt distillation. First, we
generate question-answer pairs about the new knowledge. Then, we fine-tune a
student model on the question-answer pairs to imitate the output distributions
of a teacher model, which additionally receives the new knowledge in its
prompt. The student model is identical to the teacher, except it is equipped
with a LoRA adapter. This training procedure facilitates distilling the new
knowledge from the teacher's prompt into the student's weights.

æè¦ï¼å¨è¨±å¤å¯¦åæç¨ä¸­ï¼å¤§åèªè¨æ¨¡å (LLM) éè¦æ´åé è¨ç·´è³æä¸­æ²æçæ°ç¥è­ãä¸»è¦æ¹æ³æ¯å¾®èª¿åæª¢ç´¢å¢å¼·ç¢ç (RAG)ãåç®¡ RAG å·²æçºç¥è­æ³¨å¥çç¢æ¥­æ¨æºï¼ä½å¾®èª¿å°æªç²å¾å¯æ¯è¼çæåãå¨æ¬æä¸­ï¼æåæåºäºä¸ç¨®æ°çå¾®èª¿æè¡ï¼ç¨æ¼å­¸ç¿æ°ç¥è­ï¼ä¸¦å±ç¤ºå®å¯ä»¥éå° RAG çæè½ãææåºçæ¹æ³åºæ¼èªè¸é¤¾æ¹æ³ï¼æåç¨±ä¹çºæç¤ºè¸é¤¾ãé¦åï¼æåç¢çæéæ°ç¥è­çåé¡è§£ç­å°ãç¶å¾ï¼æåå¾®èª¿ä¸åå­¸çæ¨¡åï¼å¨åé¡è§£ç­å°ä¸æ¨¡ä»¿æå¸«æ¨¡åçè¼¸åºåä½ï¼èæå¸«æ¨¡åå¨æç¤ºä¸­å¦å¤æ¥æ¶æ°ç¥è­ãå­¸çæ¨¡åèæå¸«æ¨¡åç¸åï¼é¤äºå®éåäº LoRA é©éå¨ãæ­¤è¨ç·´ç¨åºæå©æ¼å°æå¸«æç¤ºä¸­çæ°ç¥è­è¸é¤¾å°å­¸ççæ¬éä¸­ã

##### **Understanding the Dark Side of LLMs' Intrinsic Self-Correction**
2412.14959v1 by Qingjie Zhang, Han Qiu, Di Wang, Haoting Qian, Yiming Li, Tianwei Zhang, Minlie Huang

Intrinsic self-correction was proposed to improve LLMs' responses via
feedback prompts solely based on their inherent capability. However, recent
works show that LLMs' intrinsic self-correction fails without oracle labels as
feedback prompts. In this paper, we aim to interpret LLMs' intrinsic
self-correction for different tasks, especially for those failure cases. By
including one simple task and three complex tasks with state-of-the-art (SOTA)
LLMs like ChatGPT families (o1, 4o, 3.5-turbo) and Llama families (2-7B, 3-8B,
and 3.1-8B), we design three interpretation methods to reveal the dark side of
LLMs' intrinsic self-correction. We identify intrinsic self-correction can (1)
cause LLMs to waver both intermedia and final answers and lead to prompt bias
on simple factual questions; (2) introduce human-like cognitive bias on complex
tasks. In light of our findings, we also provide two simple yet effective
strategies for alleviation: question repeating and supervised fine-tuning with
a few samples. We open-source our work at https://x-isc.info/.

æè¦ï¼å§å¨èªæä¿®æ­£è¢«æåºä¾ééåé¥æç¤ºä¾æ¹å LLM çåæï¼éäºæç¤ºååºæ¼å¶åºæè½åãç¶èï¼æè¿çç ç©¶é¡¯ç¤ºï¼LLM çå§å¨èªæä¿®æ­£æå¨æ²æç¥è«­æ¨ç±¤ä½çºåé¥æç¤ºçææ³ä¸å¤±æãå¨æ¬æä¸­ï¼æåæ¨å¨è§£é LLM çå§å¨èªæä¿®æ­£å°æ¼ä¸åä»»åï¼ç¹å¥æ¯é£äºå¤±ææ¡ä¾ãééåå«ä¸åç°¡å®ä»»ååä¸åè¤éä»»åï¼ä½¿ç¨æåé² (SOTA) ç LLMï¼ä¾å¦ ChatGPT å®¶æ (o1ã4oã3.5-turbo) å Llama å®¶æ (2-7Bã3-8B å 3.1-8B)ï¼æåè¨­è¨äºä¸ç¨®è§£éæ¹æ³ä¾æ­ç¤º LLM å§å¨èªæä¿®æ­£çé»æé¢ãæåç¼ç¾å§å¨èªæä¿®æ­£å¯è½ (1) å°è´ LLM å¨ä¸­éç­æ¡åæçµç­æ¡ä¹éææºä¸å®ï¼ä¸¦å°è´ç°¡å®äºå¯¦åé¡çæç¤ºåå·®ï¼(2) å¨è¤éä»»åä¸­å¼å¥é¡ä¼¼äººé¡çèªç¥åå·®ãæ ¹ææåçç¼ç¾ï¼æåéæä¾äºå©ç¨®ç°¡å®ä½ææçç·©è§£ç­ç¥ï¼åé¡éè¤åä½¿ç¨å°æ¸æ¨£æ¬é²è¡ç£ç£å¾®èª¿ãæåå¨ https://x-isc.info/ ä¸éæ¾æåçåå§ç¢¼ã

##### **Generalizing Constraint Models in Constraint Acquisition**
2412.14950v1 by Dimos Tsouros, Senne Berden, Steven Prestwich, Tias Guns

Constraint Acquisition (CA) aims to widen the use of constraint programming
by assisting users in the modeling process. However, most CA methods suffer
from a significant drawback: they learn a single set of individual constraints
for a specific problem instance, but cannot generalize these constraints to the
parameterized constraint specifications of the problem. In this paper, we
address this limitation by proposing GenCon, a novel approach to learn
parameterized constraint models capable of modeling varying instances of the
same problem. To achieve this generalization, we make use of statistical
learning techniques at the level of individual constraints. Specifically, we
propose to train a classifier to predict, for any possible constraint and
parameterization, whether the constraint belongs to the problem. We then show
how, for some classes of classifiers, we can extract decision rules to
construct interpretable constraint specifications. This enables the generation
of ground constraints for any parameter instantiation. Additionally, we present
a generate-and-test approach that can be used with any classifier, to generate
the ground constraints on the fly. Our empirical results demonstrate that our
approach achieves high accuracy and is robust to noise in the input instances.

æè¦ï¼ç´æåå¾ (CA) çç®çæ¯ééåå©ä½¿ç¨èé²è¡å»ºæ¨¡æµç¨ï¼æ´å¤§ç´æç¨å¼è¨­è¨çä½¿ç¨ãç¶èï¼å¤§å¤æ¸ CA æ¹æ³é½æåéå¤§çç¼ºé»ï¼å®åæçºç¹å®åé¡å¯¦ä¾å­¸ç¿ä¸çµå®ç¨çç´æï¼ä½ç¡æ³å°éäºç´ææ¦æ¬çºåé¡çåæ¸åç´æè¦ç¯ãå¨æ¬æä¸­ï¼æåééæåº GenCon ä¾è§£æ±ºéåéå¶ï¼éæ¯ä¸ç¨®æ°ç©çæ¹æ³ï¼ç¨æ¼å­¸ç¿åæ¸åç´ææ¨¡åï¼è½å¤ å»ºæ¨¡ç¸ååé¡çä¸åå¯¦ä¾ãçºäºéæéåæ¦æ¬ï¼æåå¨åå¥ç´æçå±¤ç´ä¸ä½¿ç¨çµ±è¨å­¸ç¿æè¡ãå·é«ä¾èªªï¼æåå»ºè­°è¨ç·´åé¡å¨ä¾é æ¸¬ä»»ä½å¯è½çç´æååæ¸åï¼è©²ç´ææ¯å¦å±¬æ¼åé¡ãç¶å¾ï¼æåå±ç¤ºå°æ¼æäºé¡å¥çåé¡å¨ï¼æåå¯ä»¥æåæ±ºç­è¦åä¾å»ºæ§å¯è©®éçç´æè¦ç¯ãéä½¿å¾è½å¤ çºä»»ä½åæ¸å¯¦ä¾ç¢çåºç¤ç´æãæ­¤å¤ï¼æåæåºä¸åçæåæ¸¬è©¦æ¹æ³ï¼å¯ä»¥ç¨æ¼ä»»ä½åé¡å¨ï¼ä»¥å³æç¢çåºç¤ç´æãæåçç¶é©çµæè­æï¼æåçåæ³è½éæé«æºç¢ºåº¦ï¼ä¸å°æ¼è¼¸å¥å¯¦ä¾ä¸­çéè¨å·æç©©å¥æ§ã

##### **RobustFT: Robust Supervised Fine-tuning for Large Language Models under Noisy Response**
2412.14922v1 by Junyu Luo, Xiao Luo, Kaize Ding, Jingyang Yuan, Zhiping Xiao, Ming Zhang

Supervised fine-tuning (SFT) plays a crucial role in adapting large language
models (LLMs) to specific domains or tasks. However, as demonstrated by
empirical experiments, the collected data inevitably contains noise in
practical applications, which poses significant challenges to model performance
on downstream tasks. Therefore, there is an urgent need for a noise-robust SFT
framework to enhance model capabilities in downstream tasks. To address this
challenge, we introduce a robust SFT framework (RobustFT) that performs noise
detection and relabeling on downstream task data. For noise identification, our
approach employs a multi-expert collaborative system with inference-enhanced
models to achieve superior noise detection. In the denoising phase, we utilize
a context-enhanced strategy, which incorporates the most relevant and confident
knowledge followed by careful assessment to generate reliable annotations.
Additionally, we introduce an effective data selection mechanism based on
response entropy, ensuring only high-quality samples are retained for
fine-tuning. Extensive experiments conducted on multiple LLMs across five
datasets demonstrate RobustFT's exceptional performance in noisy scenarios.

æè¦ï¼ç£ç£å¼å¾®èª¿ï¼SFTï¼å¨å°å¤§åèªè¨æ¨¡åï¼LLMï¼é©æå°ç¹å®é åæä»»åä¸­æ®æ¼èè³ééè¦çè§è²ãç¶èï¼æ­£å¦ç¶é©å¯¦é©æè­æï¼å¨å¯¦éæç¨ä¸­æ¶éå°çè³æä¸å¯é¿åå°åå«éè¨ï¼éå°ä¸æ¸¸ä»»åçæ¨¡åæè½æ§æäºéå¤§ææ°ãå æ­¤ï¼è¿«åéè¦ä¸åæéè¨ç SFT æ¡æ¶ï¼ä»¥å¢å¼·æ¨¡åå¨ä¸æ¸¸ä»»åä¸­çè½åãçºäºæå°éä¸ææ°ï¼æåå¼å¥äºç©©å¥ç SFT æ¡æ¶ï¼RobustFTï¼ï¼å®å°ä¸æ¸¸ä»»åè³æå·è¡éè¨åµæ¸¬åéæ°æ¨è¨ãå°æ¼éè¨è­å¥ï¼æåçæ¹æ³æ¡ç¨å¤å°å®¶åä½ç³»çµ±ï¼ä¸¦ä½¿ç¨å¢å¼·æ¨è«çæ¨¡åä¾å¯¦ç¾åªç°çéè¨åµæ¸¬ãå¨å»éè¨éæ®µï¼æåå©ç¨ä¸ç¨®æå¢å¢å¼·ç­ç¥ï¼å®çµåäºæç¸éåæç¢ºä¿¡çç¥è­ï¼ç¶å¾é²è¡ä»ç´°è©ä¼°ä»¥ç¢çå¯é çè¨»è§£ãæ­¤å¤ï¼æåéå¼å¥äºä¸ç¨®åºæ¼åæçµçææè³æé¸åæ©å¶ï¼ç¢ºä¿åä¿çé«åè³ªçæ¨£æ¬é²è¡å¾®èª¿ãå¨äºåè³æéä¸å°å¤å LLM é²è¡çå»£æ³å¯¦é©è­æäº RobustFT å¨éè¨æå¢ä¸­çåºè²æè½ã

##### **Dehallucinating Parallel Context Extension for Retrieval-Augmented Generation**
2412.14905v1 by Zexiong Ma, Shengnan An, Zeqi Lin, Yanzhen Zou, Jian-Guang Lou, Bing Xie

Large language models (LLMs) are susceptible to generating hallucinated
information, despite the integration of retrieval-augmented generation (RAG).
Parallel context extension (PCE) is a line of research attempting to
effectively integrating parallel (unordered) contexts, while it still suffers
from hallucinations when adapted to RAG scenarios. In this paper, we propose
DePaC (Dehallucinating Parallel Context Extension), which alleviates the
hallucination problem with context-aware negative training and
information-calibrated aggregation. DePaC is designed to alleviate two types of
in-context hallucination: fact fabrication (i.e., LLMs present claims that are
not supported by the contexts) and fact omission (i.e., LLMs fail to present
claims that can be supported by the contexts). Specifically, (1) for fact
fabrication, we apply the context-aware negative training that fine-tunes the
LLMs with negative supervisions, thus explicitly guiding the LLMs to refuse to
answer when contexts are not related to questions; (2) for fact omission, we
propose the information-calibrated aggregation which prioritizes context
windows with higher information increment from their contexts. The experimental
results on nine RAG tasks demonstrate that DePaC significantly alleviates the
two types of hallucination and consistently achieves better performances on
these tasks.

æè¦ï¼å¤§åè¯­è¨æ¨¡å (LLM) å®¹æäº§çå¹»è§ä¿¡æ¯ï¼å°½ç®¡éæäºæ£ç´¢å¢å¼ºçæ (RAG)ã
å¹³è¡ä¸ä¸ææ©å± (PCE) æ¯ä¸æ¡å°è¯ææéæå¹³è¡ï¼æ åºï¼ä¸ä¸æççç ç©¶çº¿ï¼ä½å½å®éåº RAG åºæ¯æ¶ï¼å®ä»ç¶ä¼äº§çå¹»è§ãå¨æ¬æä¸­ï¼æä»¬æåºäº DePaCï¼å»å¹»è§å¹³è¡ä¸ä¸ææ©å±ï¼ï¼å®éè¿ä¸ä¸ææç¥çè´è®­ç»åä¿¡æ¯æ ¡åèåæ¥ç¼è§£å¹»è§é®é¢ãDePaC æ¨å¨ç¼è§£ä¸¤ç§ç±»åçä¸ä¸æå¹»è§ï¼äºå®æé ï¼å³ï¼LLM æåºä¸åä¸ä¸ææ¯æçä¸»å¼ ï¼åäºå®éæ¼ï¼å³ï¼LLM æ æ³æåºå¯ä»¥ç±ä¸ä¸ææ¯æçä¸»å¼ ï¼ãå·ä½æ¥è¯´ï¼ï¼1ï¼å¯¹äºäºå®æé ï¼æä»¬åºç¨äºä¸ä¸ææç¥çè´è®­ç»ï¼è¯¥è®­ç»ä½¿ç¨è´çç£å¯¹ LLM è¿è¡å¾®è°ï¼ä»èæç¡®æå¯¼ LLM å¨ä¸ä¸æä¸é®é¢æ å³æ¶æç»åç­ï¼ï¼2ï¼å¯¹äºäºå®éæ¼ï¼æä»¬æåºäºä¿¡æ¯æ ¡åèåï¼è¯¥èåä¼åèèä»å¶ä¸ä¸æä¸­å·æè¾é«ä¿¡æ¯å¢éçä¸ä¸æçªå£ãå¨ä¹ä¸ª RAG ä»»å¡ä¸çå®éªç»æè¡¨æï¼DePaC æ¾çç¼è§£äºè¿ä¸¤ç§ç±»åçå¹»è§ï¼å¹¶å¨è¿äºä»»å¡ä¸æç»­åå¾äºæ´å¥½çæ§è½ã

##### **Why language models collapse when trained on recursively generated text**
2412.14872v1 by Lecheng Wang, Xianjie Shi, Ge Li, Jia Li, Yihong Dong, Xuanming Zhang, Wenpin Jiao, Hong Mei

Language models (LMs) have been widely used to generate text on the Internet.
The generated text is often collected into the training corpus of the next
generations of LMs. Previous work has experimentally found that LMs collapse
when trained on recursively generated text. This paper contributes to existing
knowledge from two aspects. We present a theoretical proof of LM collapse. Our
proof reveals the cause of LM collapse and proves that all auto-regressive LMs
will definitely collapse. We present a new finding: the performance of LMs
gradually declines when trained on recursively generated text until they
perform no better than a randomly initialized LM. The trained LMs produce large
amounts of repetitive text and perform poorly across a wide range of natural
language tasks. The above proof and new findings deepen our understanding of LM
collapse and offer valuable insights that may inspire new training techniques
to mitigate this threat.

æè¦ï¼èªè¨æ¨¡å (LM) å·²å»£æ³ç¨æ¼å¨ç¶²éç¶²è·¯ä¸ç¢çæå­ã
ç¢ççæå­éå¸¸ææ¶éå°ä¸ä¸ä»£ LM çè¨ç·´èªæåº«ä¸­ãååçç ç©¶å·²ééå¯¦é©ç¼ç¾ï¼ç¶ LM å¨éè¿´ç¢ççæå­ä¸è¨ç·´ææå´©æ½°ãæ¬æå¾å©åé¢åæ¢è¨ç¾æç¥è­ãæåæåº LM å´©æ½°ççè«è­æãæåçè­ææ­é²äº LM å´©æ½°çåå ï¼ä¸¦è­æææèªè¿´æ­¸ LM è¯å®æå´©æ½°ãæåæåºä¸åæ°ç¼ç¾ï¼å¨éè¿´ç¢ççæå­ä¸è¨ç·´æï¼LM çæè½æéæ¼¸ä¸éï¼ç´å°å¶æè½è¡¨ç¾ä¸æ¯é¨æ©åå§åç LM çºæ­¢ãè¨ç·´å¾ç LM æç¢çå¤§éçéè¤æå­ï¼ä¸¦ä¸å¨åç¨®èªç¶èªè¨ä»»åä¸­çè¡¨ç¾é½å¾å·®ãä¸è¿°è­æåæ°ç¼ç¾å æ·±äºæåå° LM å´©æ½°çäºè§£ï¼ä¸¦æä¾äºå¯¶è²´çè¦è§£ï¼å¯è½æ¿åµæ°çè¨ç·´æè¡ä¾æ¸è¼éåå¨èã

##### **AI-Powered Intracranial Hemorrhage Detection: A Co-Scale Convolutional Attention Model with Uncertainty-Based Fuzzy Integral Operator and Feature Screening**
2412.14869v1 by Mehdi Hosseini Chagahi, Md. Jalil Piran, Niloufar Delfan, Behzad Moshiri, Jaber Hatam Parikhan

Intracranial hemorrhage (ICH) refers to the leakage or accumulation of blood
within the skull, which occurs due to the rupture of blood vessels in or around
the brain. If this condition is not diagnosed in a timely manner and
appropriately treated, it can lead to serious complications such as decreased
consciousness, permanent neurological disabilities, or even death.The primary
aim of this study is to detect the occurrence or non-occurrence of ICH,
followed by determining the type of subdural hemorrhage (SDH). These tasks are
framed as two separate binary classification problems. By adding two layers to
the co-scale convolutional attention (CCA) classifier architecture, we
introduce a novel approach for ICH detection. In the first layer, after
extracting features from different slices of computed tomography (CT) scan
images, we combine these features and select the 50 components that capture the
highest variance in the data, considering them as informative features. We then
assess the discriminative power of these features using the bootstrap forest
algorithm, discarding those that lack sufficient discriminative ability between
different classes. This algorithm explicitly determines the contribution of
each feature to the final prediction, assisting us in developing an explainable
AI model. The features feed into a boosting neural network as a latent feature
space. In the second layer, we introduce a novel uncertainty-based fuzzy
integral operator to fuse information from different CT scan slices. This
operator, by accounting for the dependencies between consecutive slices,
significantly improves detection accuracy.

æè¦ï¼é¡±å§åºè¡ (ICH) æ¯æé¡±éª¨å§è¡æ¶²æ»²æ¼æç©èï¼éæ¯ç±æ¼è¦é¨æè¦é¨å¨åçè¡ç®¡ç ´è£æè´ãå¦æéç¨®ææ³æªè½åæè¨ºæ·ä¸¦é©ç¶æ²»çï¼å¯è½æå°è´å´éçä½µç¼çï¼ä¾å¦æè­ä¸éãæ°¸ä¹æ§ç¥ç¶åè½éç¤ï¼çè³æ­»äº¡ãæ¬ç ç©¶çä¸»è¦ç®çæ¯æª¢æ¸¬ ICH çç¼çææªç¼çï¼ç¶å¾ç¢ºå®ç¡¬è¦èä¸åºè¡ (SDH) çé¡åãéäºä»»åè¢«è¨­å®çºå©åç¨ç«çäºååé¡åé¡ãééå¨åå°ºåº¦å·ç©æ³¨æå (CCA) åé¡å¨æ¶æ§ä¸­æ°å¢å©å±¤ï¼æåæåºäºä¸ç¨®ç¨æ¼ ICH æª¢æ¸¬çæ°æ¹æ³ãå¨ç¬¬ä¸å±¤ä¸­ï¼å¾é»è¦æ·å±¤æå½± (CT) ææå½±åçä¸ååçä¸­èåç¹å¾µå¾ï¼æåæçµåéäºç¹å¾µä¸¦é¸å 50 åå¨è³æä¸­æ·åæé«è®ç°æ¸ççµæé¨åï¼å°å®åè¦çºææç¾©çç¹å¾µãç¶å¾ï¼æåä½¿ç¨ bootstrap forest æ¼ç®æ³è©ä¼°éäºç¹å¾µçå¤å¥åï¼ä¸¦æ¨æ£å¨ä¸åé¡å¥ä¹éç¼ºä¹è¶³å¤ å¤å¥è½åçç¹å¾µãæ­¤æ¼ç®æ³ææç¢ºå°ç¢ºå®æ¯åç¹å¾µå°æçµé æ¸¬çè²¢ç»ï¼åå©æåéç¼å¯è§£éç AI æ¨¡åãéäºç¹å¾µæä½çºæ½å¨ç¹å¾µç©ºéæä¾çµ¦æåç¥ç¶ç¶²è·¯ãå¨ç¬¬äºå±¤ä¸­ï¼æåå¼å¥äºä¸ç¨®æ°çåºæ¼ä¸ç¢ºå®æ§çæ¨¡ç³ç©åç®å­ï¼ä»¥èåä¾èªä¸å CT ææåççè³è¨ãæ­¤ç®å­ééèéé£çºåçä¹éçä¾è³´æ§ï¼å¤§å¹æåäºæª¢æ¸¬æºç¢ºåº¦ã

##### **Graph-Convolutional Networks: Named Entity Recognition and Large Language Model Embedding in Document Clustering**
2412.14867v1 by Imed Keraghel, Mohamed Nadif

Recent advances in machine learning, particularly Large Language Models
(LLMs) such as BERT and GPT, provide rich contextual embeddings that improve
text representation. However, current document clustering approaches often
ignore the deeper relationships between named entities (NEs) and the potential
of LLM embeddings. This paper proposes a novel approach that integrates Named
Entity Recognition (NER) and LLM embeddings within a graph-based framework for
document clustering. The method builds a graph with nodes representing
documents and edges weighted by named entity similarity, optimized using a
graph-convolutional network (GCN). This ensures a more effective grouping of
semantically related documents. Experimental results indicate that our approach
outperforms conventional co-occurrence-based methods in clustering, notably for
documents rich in named entities.

æè¦ï¼è¿ææ©å¨å­¸ç¿çé²å±ï¼ç¹å¥æ¯å¤§åèªè¨æ¨¡å (LLM)ï¼ä¾å¦ BERT å GPTï¼æä¾äºè±å¯çä¸ä¸æåµå¥ï¼æ¹é²äºææ¬è¡¨å¾µãç¶èï¼ç¶åçæä»¶åç¾¤æ¹æ³éå¸¸å¿½ç¥å½åå¯¦é« (NE) ä¹éæ´æ·±å±¤çéä¿å LLM åµå¥çæ½åãæ¬ææåºäºä¸ç¨®åµæ°çæ¹æ³ï¼å°å½åå¯¦é«è¾¨è­ (NER) å LLM åµå¥æ´åå°åºæ¼åå½¢çæ¶æ§ä¸­ï¼ä»¥é²è¡æä»¶åç¾¤ãè©²æ¹æ³å»ºç«äºä¸ååå½¢ï¼å¶ä¸­ç¯é»ä»£è¡¨æä»¶ï¼éç·£åç±å½åå¯¦é«ç¸ä¼¼æ§å æ¬ï¼ä¸¦ä½¿ç¨åå½¢å·ç©ç¶²è·¯ (GCN) é²è¡æä½³åãéç¢ºä¿äºèªç¾©ç¸éæä»¶æ´ææçåçµãå¯¦é©çµæè¡¨æï¼æåçåæ³åªæ¼å³çµ±çå±ç¾æ¹æ³å¨åç¾¤ä¸­çè¡¨ç¾ï¼ç¹å¥æ¯å°æ¼å¯å«å½åå¯¦é«çæä»¶ã

##### **Think&Cite: Improving Attributed Text Generation with Self-Guided Tree Search and Progress Reward Modeling**
2412.14860v1 by Junyi Li, Hwee Tou Ng

Despite their outstanding capabilities, large language models (LLMs) are
prone to hallucination and producing factually incorrect information. This
challenge has spurred efforts in attributed text generation, which prompts LLMs
to generate content with supporting evidence. In this paper, we propose a novel
framework, called Think&Cite, and formulate attributed text generation as a
multi-step reasoning problem integrated with search. Specifically, we propose
Self-Guided Monte Carlo Tree Search (SG-MCTS), which capitalizes on the
self-reflection capability of LLMs to reflect on the intermediate states of
MCTS for guiding the tree expansion process. To provide reliable and
comprehensive feedback, we introduce Progress Reward Models to measure the
progress of tree search from the root to the current state from two aspects,
i.e., generation and attribution progress. We conduct extensive experiments on
three datasets and the results show that our approach significantly outperforms
baseline approaches.

æè¦ï¼åç®¡å¤§åèªè¨æ¨¡å (LLM) å·æååºçè½åï¼ä½å®åå®¹æåºç¾å¹»è¦ºä¸¦ç¢çäºå¯¦ä¸ä¸æ­£ç¢ºçè³è¨ãéåææ°ä¿ä½¿æåè´åæ¼æ­¸å æå­çæï¼éææç¤º LLM ç¢çå·æä½è­è­æçå§å®¹ãå¨æ¬æä¸­ï¼æåæåºä¸åç¨±çº Think&Cite çæ°æ¶æ§ï¼ä¸¦å°æ­¸å æå­çæè¡¨è¿°çºä¸åæ´åæå°çå¤æ­¥é©æ¨çåé¡ãå·é«ä¾èªªï¼æåæåºèªå°èå°å¡ç¾æ¨¹çæå° (SG-MCTS)ï¼å®å©ç¨ LLM çèªæåçè½åä¾åç MCTS çä¸­éçæï¼ä»¥å¼å°æ¨¹çæ´åç¨åºãçºäºæä¾å¯é ä¸å¨é¢çåé¥ï¼æåå¼å¥é²åº¦çåµæ¨¡åä¾è¡¡éæ¨¹çæå°å¾æ ¹ç¯é»å°ç®åçæçé²åº¦ï¼å¾å©åæ¹é¢èæï¼å³çæé²åº¦åæ­¸å é²åº¦ãæåå¨ä¸åè³æéä¸é²è¡å»£æ³çå¯¦é©ï¼çµæé¡¯ç¤ºæåçåæ³é¡¯èåªæ¼åºæºåæ³ã

##### **DS$^2$-ABSA: Dual-Stream Data Synthesis with Label Refinement for Few-Shot Aspect-Based Sentiment Analysis**
2412.14849v1 by Hongling Xu, Yice Zhang, Qianlong Wang, Ruifeng Xu

Recently developed large language models (LLMs) have presented promising new
avenues to address data scarcity in low-resource scenarios. In few-shot
aspect-based sentiment analysis (ABSA), previous efforts have explored data
augmentation techniques, which prompt LLMs to generate new samples by modifying
existing ones. However, these methods fail to produce adequately diverse data,
impairing their effectiveness. Besides, some studies apply in-context learning
for ABSA by using specific instructions and a few selected examples as prompts.
Though promising, LLMs often yield labels that deviate from task requirements.
To overcome these limitations, we propose DS$^2$-ABSA, a dual-stream data
synthesis framework targeted for few-shot ABSA. It leverages LLMs to synthesize
data from two complementary perspectives: \textit{key-point-driven} and
\textit{instance-driven}, which effectively generate diverse and high-quality
ABSA samples in low-resource settings. Furthermore, a \textit{label refinement}
module is integrated to improve the synthetic labels. Extensive experiments
demonstrate that DS$^2$-ABSA significantly outperforms previous few-shot ABSA
solutions and other LLM-oriented data generation methods.

æè¦ï¼æè¿éç¼çå¤§åèªè¨æ¨¡å (LLM) æåºäºä¸åæåéçæ°éå¾ä¾è§£æ±ºä½è³æºå ´æ¯ä¸­çè³æç¨å°æ§ãå¨å°æ¨£æ¬æ¹é¢è§é»åºç¤æç·åæ (ABSA) ä¸­ï¼ååçåªåå·²ç¶æ¢ç´¢äºè³ææ´åæè¡ï¼å®æç¤º LLM èç±ä¿®æ¹ç¾ææ¨£æ¬ä¾ç¢çæ°æ¨£æ¬ãç¶èï¼éäºæ¹æ³ç¡æ³ç¢çè¶³å¤ å¤æ¨£åçè³æï¼æå®³å¶æææ§ãæ­¤å¤ï¼ä¸äºç ç©¶ä½¿ç¨ç¹å®èªªæåä¸äºé¸å®çç¯ä¾ä½çºæç¤ºï¼ä¾æç¨æå¢å­¸ç¿æ¼ ABSAãåç®¡æåéï¼LLM ç¶å¸¸ç¢çåé¢ä»»åéæ±çæ¨ç±¤ãçºäºåæéäºéå¶ï¼æåæåº DS$^2$-ABSAï¼ä¸åéå°å°æ¨£æ¬ ABSA çéæµè³æåææ¶æ§ãå®å©ç¨ LLM å¾å©åäºè£çè§é»ä¾åæè³æï¼\textit{ééµé»é©å} å \textit{å¯¦ä¾é©å}ï¼éå¨ä½è³æºè¨­å®ä¸­ææå°ç¢çå¤æ¨£åä¸é«åè³ªç ABSA æ¨£æ¬ãæ­¤å¤ï¼æ´åäºä¸å \textit{æ¨ç±¤ç²¾ç·»å} æ¨¡çµä¾æ¹ååææ¨ç±¤ãå»£æ³çå¯¦é©è­æï¼DS$^2$-ABSA æé¡¯åªæ¼ååçå¹¾åå°æ¨£æ¬ ABSA è§£æ±ºæ¹æ¡åå¶ä»ä»¥ LLM çºå°åçè³æç¢çæ¹æ³ã

##### **A Survey of RWKV**
2412.14847v1 by Zhiyuan Li, Tingyu Xia, Yi Chang, Yuan Wu

The Receptance Weighted Key Value (RWKV) model offers a novel alternative to
the Transformer architecture, merging the benefits of recurrent and
attention-based systems. Unlike conventional Transformers, which depend heavily
on self-attention, RWKV adeptly captures long-range dependencies with minimal
computational demands. By utilizing a recurrent framework, RWKV addresses some
computational inefficiencies found in Transformers, particularly in tasks with
long sequences. RWKV has recently drawn considerable attention for its robust
performance across multiple domains. Despite its growing popularity, no
systematic review of the RWKV model exists. This paper seeks to fill this gap
as the first comprehensive review of the RWKV architecture, its core
principles, and its varied applications, such as natural language generation,
natural language understanding, and computer vision. We assess how RWKV
compares to traditional Transformer models, highlighting its capability to
manage long sequences efficiently and lower computational costs. Furthermore,
we explore the challenges RWKV encounters and propose potential directions for
future research and advancement. We consistently maintain the related
open-source materials at: https://github.com/MLGroupJLU/RWKV-Survey.

æè¦ï¼å¯æ¥æ¶å æ¬ééµå¼ (RWKV) æ¨¡åæä¾äºä¸åæ°ç©çæ¿ä»£æ¹æ¡ä¾è½ææ¶æ§ï¼åä½µäºéè¿´ååºæ¼æ³¨æåçç³»çµ±çåªé»ãèé«åº¦ä¾è³´èªææ³¨æåçå³çµ±è½æå¨ä¸åï¼RWKV è½å¤ ä»¥æå°çéç®éæ±éæ´»å°ææé·è·é¢ä¾è³´æ§ãééå©ç¨éè¿´æ¶æ§ï¼RWKV è§£æ±ºäºå¨è½æå¨ä¸­ç¼ç¾çä¸äºéç®ä½æçï¼ç¹å¥æ¯å¨å·æé·åºåçä»»åä¸­ãRWKV æè¿å å¶å¨å¤åé åçå¼·å¤§æè½èååéæ³¨ãåç®¡å¶åæ­¡è¿ç¨åº¦æ¥çæé«ï¼ä½ RWKV æ¨¡åä¸¦æªé²è¡ç³»çµ±æ§åé¡§ãæ¬ææ¨å¨å¡«è£éä¸ç©ºç½ï¼ä½çº RWKV æ¶æ§ãå¶æ ¸å¿åçåå¶åç¨®æç¨ï¼ä¾å¦èªç¶èªè¨çæãèªç¶èªè¨çè§£åé»è¦è¦è¦ºï¼çç¬¬ä¸åå¨é¢åé¡§ãæåè©ä¼° RWKV å¦ä½èå³çµ±è½æå¨æ¨¡åé²è¡æ¯è¼ï¼å¼·èª¿å¶ææç®¡çé·åºååéä½éç®ææ¬çè½åãæ­¤å¤ï¼æåæ¢è¨äº RWKV éè¦çææ°ï¼ä¸¦æåºäºæªä¾ç ç©¶åé²å±çæ½å¨æ¹åãæåæçºå¨ä»¥ä¸ä½ç½®ç¶­è­·ç¸éçéæºææï¼https://github.com/MLGroupJLU/RWKV-Surveyã

##### **Head and Neck Tumor Segmentation of MRI from Pre- and Mid-radiotherapy with Pre-training, Data Augmentation and Dual Flow UNet**
2412.14846v1 by Litingyu Wang, Wenjun Liao, Shichuan Zhang, Guotai Wang

Head and neck tumors and metastatic lymph nodes are crucial for treatment
planning and prognostic analysis. Accurate segmentation and quantitative
analysis of these structures require pixel-level annotation, making automated
segmentation techniques essential for the diagnosis and treatment of head and
neck cancer. In this study, we investigated the effects of multiple strategies
on the segmentation of pre-radiotherapy (pre-RT) and mid-radiotherapy (mid-RT)
images. For the segmentation of pre-RT images, we utilized: 1) a fully
supervised learning approach, and 2) the same approach enhanced with
pre-trained weights and the MixUp data augmentation technique. For mid-RT
images, we introduced a novel computational-friendly network architecture that
features separate encoders for mid-RT images and registered pre-RT images with
their labels. The mid-RT encoder branch integrates information from pre-RT
images and labels progressively during the forward propagation. We selected the
highest-performing model from each fold and used their predictions to create an
ensemble average for inference. In the final test, our models achieved a
segmentation performance of 82.38% for pre-RT and 72.53% for mid-RT on
aggregated Dice Similarity Coefficient (DSC) as HiLab. Our code is available at
https://github.com/WltyBY/HNTS-MRG2024_train_code.

æè¦ï¼é ­é ¸é¨è«ç¤åè½ç§»æ·å·´çµå°æ¼æ²»çè¨ç«åé å¾åæè³ééè¦ãéäºçµæ§çæºç¢ºåå²åå®éåæéè¦åç´ ç´è¨»è§£ï¼ä½¿èªååå²æè¡å°æ¼é ­é ¸ççè¨ºæ·åæ²»çè³ééè¦ãå¨æ¬ç ç©¶ä¸­ï¼æåæ¢è¨äºå¤ç¨®ç­ç¥å°æ¾å°æ²»çå (pre-RT) åæ¾å°æ²»çä¸­æ (mid-RT) å½±ååå²çå½±é¿ãå°æ¼æ¾å°æ²»çåå½±åçåå²ï¼æåå©ç¨ï¼1ï¼å®å¨ç£ç£å¼å­¸ç¿æ¹æ³ï¼ä»¥å 2ï¼ä½¿ç¨é è¨ç·´æ¬éå MixUp è³ææ´åæè¡å¢å¼·çç¸åæ¹æ³ãå°æ¼æ¾å°æ²»çä¸­æå½±åï¼æåå¼å¥äºä¸åæ°ç©çè¨ç®åå¥½åç¶²è·¯æ¶æ§ï¼å¶ç¹é»æ¯çºæ¾å°æ²»çä¸­æå½±ååè¨»åçæ¾å°æ²»çåå½±ååå¶æ¨ç±¤æä¾äºå®ç¨çç·¨ç¢¼å¨ãæ¾å°æ²»çä¸­æç·¨ç¢¼å¨åæ¯å¨æ­£åå³æ­éç¨ä¸­éæ­¥æ´åä¾èªæ¾å°æ²»çåå½±ååæ¨ç±¤çè³è¨ãæåå¾æ¯ååå¡ä¸­é¸åºæè½æé«çæ¨¡åï¼ä¸¦ä½¿ç¨å¶é æ¸¬å¼å»ºç«ä¸åéåå¹³åå¼ä»¥é²è¡æ¨è«ãå¨æå¾çæ¸¬è©¦ä¸­ï¼æåçæ¨¡åå¨ HiLab ä¸çé æ¸¬è¡¨ç¾å°æ¼æ¾å°æ²»çåå½±åçº 82.38%ï¼å°æ¼æ¾å°æ²»çä¸­æå½±åçº 72.53%ï¼ä»¥èåç Dice ç¸ä¼¼æ§ä¿æ¸ (DSC) çºæºãæåçç¨å¼ç¢¼å¯ä»¥å¨ https://github.com/WltyBY/HNTS-MRG2024_train_code åå¾ã

##### **Mapping and Influencing the Political Ideology of Large Language Models using Synthetic Personas**
2412.14843v1 by Pietro Bernardelle, Leon FrÃ¶hling, Stefano Civelli, Riccardo Lunardi, Kevin Roiter, Gianluca Demartini

The analysis of political biases in large language models (LLMs) has
primarily examined these systems as single entities with fixed viewpoints.
While various methods exist for measuring such biases, the impact of
persona-based prompting on LLMs' political orientation remains unexplored. In
this work we leverage PersonaHub, a collection of synthetic persona
descriptions, to map the political distribution of persona-based prompted LLMs
using the Political Compass Test (PCT). We then examine whether these initial
compass distributions can be manipulated through explicit ideological prompting
towards diametrically opposed political orientations: right-authoritarian and
left-libertarian. Our experiments reveal that synthetic personas predominantly
cluster in the left-libertarian quadrant, with models demonstrating varying
degrees of responsiveness when prompted with explicit ideological descriptors.
While all models demonstrate significant shifts towards right-authoritarian
positions, they exhibit more limited shifts towards left-libertarian positions,
suggesting an asymmetric response to ideological manipulation that may reflect
inherent biases in model training.

æè¦ï¼æ¿æ²»åèª¤å¨å¤§åèªè¨æ¨¡å (LLM) ä¸­çåæï¼ä¸»è¦å°éäºç³»çµ±è¦çºå·æåºå®è§é»çå®ä¸å¯¦é«ãéç¶å­å¨åç¨®æ¸¬éæ­¤é¡åèª¤çæ¹æ³ï¼ä½åºæ¼è§è²çæç¤ºå° LLM çæ¿æ²»å¾åçå½±é¿ä»æªå¾å°æ¢è¨ãå¨éé å·¥ä½ä¸­ï¼æåå©ç¨ PersonaHubï¼ä¸ååæè§è²æè¿°çéåï¼ä¾ç¹ªè£½åºæ¼è§è²æç¤ºç LLM çæ¿æ²»åä½ï¼ä½¿ç¨æ¿æ²»ç¾ç¤æ¸¬è©¦ (PCT)ãç¶å¾ï¼æåæ¢è¨æ¯å¦å¯ä»¥ééæç¢ºçæè­å½¢ææç¤ºä¾æç¸±éäºåå§ç¾ç¤åä½ï¼æåæªç¶ç¸åçæ¿æ²»å¾åï¼å³ç¿¼å¨æ¬ä¸»ç¾©åå·¦ç¿¼èªç±ä¸»ç¾©ãæåçå¯¦é©è¡¨æï¼åæè§è²ä¸»è¦èéå¨å·¦ç¿¼èªç±ä¸»ç¾©è±¡éï¼èæ¨¡åå¨ä½¿ç¨æç¢ºçæè­å½¢ææè¿°ç¬¦æç¤ºæè¡¨ç¾åºä¸åç¨åº¦çåæè½åãéç¶æææ¨¡åé½è¡¨ç¾åºé¡¯èçåå³ç¿¼å¨æ¬ä¸»ç¾©ç«å ´çè½è®ï¼ä½å®ååå·¦ç¿¼èªç±ä¸»ç¾©ç«å ´çè½è®è¼çºæéï¼éè¡¨æå°æè­å½¢ææç¸±çä¸å°ç¨±åæå¯è½åæ äºæ¨¡åè¨ç·´ä¸­çåºæåèª¤ã

##### **Helping LLMs Improve Code Generation Using Feedback from Testing and Static Analysis**
2412.14841v1 by Greta Dolcetti, Vincenzo Arceri, Eleonora Iotti, Sergio Maffeis, Agostino Cortesi, Enea Zaffanella

Large Language Models (LLMs) are one of the most promising developments in
the field of artificial intelligence, and the software engineering community
has readily noticed their potential role in the software development
life-cycle. Developers routinely ask LLMs to generate code snippets, increasing
productivity but also potentially introducing ownership, privacy, correctness,
and security issues. Previous work highlighted how code generated by mainstream
commercial LLMs is often not safe, containing vulnerabilities, bugs, and code
smells. In this paper, we present a framework that leverages testing and static
analysis to assess the quality, and guide the self-improvement, of code
generated by general-purpose, open-source LLMs.
  First, we ask LLMs to generate C code to solve a number of programming tasks.
Then we employ ground-truth tests to assess the (in)correctness of the
generated code, and a static analysis tool to detect potential safety
vulnerabilities. Next, we assess the models ability to evaluate the generated
code, by asking them to detect errors and vulnerabilities. Finally, we test the
models ability to fix the generated code, providing the reports produced during
the static analysis and incorrectness evaluation phases as feedback.
  Our results show that models often produce incorrect code, and that the
generated code can include safety issues. Moreover, they perform very poorly at
detecting either issue. On the positive side, we observe a substantial ability
to fix flawed code when provided with information about failed tests or
potential vulnerabilities, indicating a promising avenue for improving the
safety of LLM-based code generation tools.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) æ¯äººå·¥æºè½é åä¸­ææåéçç¼å±ä¹ä¸ï¼è»é«å·¥ç¨ç¤¾ç¾¤ä¹è¿éæ³¨æå°å®åå¨è»é«éç¼çå½é±æä¸­çæ½å¨è§è²ãéç¼äººå¡ä¾è¡å¬äºå°è¦æ± LLM ç¢çç¨å¼ç¢¼çæ®µï¼éæé«äºçç¢åï¼ä½ä¹å¯è½å¼ç¼æææ¬ãé±ç§ãæ­£ç¢ºæ§åå®å¨æ§åé¡ãååçç ç©¶å¼·èª¿ï¼ä¸»æµåæ¥­ LLM ç¢ççç¨å¼ç¢¼éå¸¸ä¸å®å¨ï¼åå«æ¼æ´ãé¯èª¤åç¨å¼ç¢¼åé¡ãå¨æ¬æä¸­ï¼æåæåºäºä¸åæ¡æ¶ï¼å©ç¨æ¸¬è©¦åéæåæä¾è©ä¼°åè³ªï¼ä¸¦æå°ç±éç¨éæº LLM ç¢ççç¨å¼ç¢¼èªææ¹åã
é¦åï¼æåè¦æ± LLM ç¢ç C ç¨å¼ç¢¼ä¾è§£æ±ºè¨±å¤ç¨å¼è¨­è¨ä»»åãç¶å¾ï¼æåæ¡ç¨åºæ¬äºå¯¦æ¸¬è©¦ä¾è©ä¼°ç¢ççç¨å¼ç¢¼çï¼ä¸ï¼æ­£ç¢ºæ§ï¼ä¸¦ä½¿ç¨éæåæå·¥å·ä¾åµæ¸¬æ½å¨çå®å¨æ¼æ´ãæ¥ä¸ä¾ï¼æåè©ä¼°æ¨¡åè©ä¼°ç¢ççç¨å¼ç¢¼çè½åï¼æ¹æ³æ¯è¦æ±å®ååµæ¸¬é¯èª¤åæ¼æ´ãæå¾ï¼æåæ¸¬è©¦æ¨¡åä¿®æ­£ç¢ççç¨å¼ç¢¼çè½åï¼æä¾å¨éæåæåä¸æ­£ç¢ºæ§è©ä¼°éæ®µç¢ççå ±åä½çºåé¥ã
æåççµæé¡¯ç¤ºï¼æ¨¡åéå¸¸æç¢çä¸æ­£ç¢ºçç¨å¼ç¢¼ï¼èä¸ç¢ççç¨å¼ç¢¼å¯è½åå«å®å¨åé¡ãæ­¤å¤ï¼å®åå¨åµæ¸¬éå©ååé¡æ¹é¢çè¡¨ç¾éå¸¸å·®ãå¨æ­£é¢æ¹é¢ï¼æåè§å¯å°å¨æä¾æéå¤±ææ¸¬è©¦ææ½å¨æ¼æ´çè³è¨æï¼å®åå·æä¿®æ­£æç¼ºé·ç¨å¼ç¢¼çé¡¯èè½åï¼éè¡¨ç¤ºæ¹ååºæ¼ LLM çç¨å¼ç¢¼ç¢çå·¥å·çå®å¨æ§æ¯ä¸åæåéçéå¾ã

##### **DynamicKV: Task-Aware Adaptive KV Cache Compression for Long Context LLMs**
2412.14838v1 by Xiabin Zhou, Wenbin Wang, Minyan Zeng, Jiaxian Guo, Xuebo Liu, Li Shen, Min Zhang, Liang Ding

Efficient KV cache management in LLMs is crucial for long-context tasks like
RAG and summarization. Existing KV cache compression methods enforce a fixed
pattern, neglecting task-specific characteristics and reducing the retention of
essential information. However, we observe distinct activation patterns across
layers in various tasks, highlighting the need for adaptive strategies tailored
to each task's unique demands. Based on this insight, we propose DynamicKV, a
method that dynamically optimizes token retention by adjusting the number of
tokens retained at each layer to adapt to the specific task. DynamicKV
establishes global and per-layer maximum KV cache budgets, temporarily
retaining the maximum budget for the current layer, and periodically updating
the KV cache sizes of all preceding layers during inference. Our method retains
only 1.7% of the KV cache size while achieving ~85% of the Full KV cache
performance on LongBench. Notably, even under extreme compression (0.9%),
DynamicKV surpasses state-of-the-art (SOTA) methods by 11% in the
Needle-in-a-Haystack test using Mistral-7B-Instruct-v0.2. The code will be
released.

æè¦ï¼å¨ LLMs ä¸­é²è¡é«æç KV å¿«åç®¡çå°æ¼ RAG åæè¦ç­é·èæ¯ä»»åè³ééè¦ãç¾æç KV å¿«åå£ç¸®æ¹æ³å¼·å¶å·è¡ä¸ååºå®çæ¨¡å¼ï¼å¿½ç¥ç¹å®ä»»åçç¹å¾µä¸¦æ¸å°ä¿çéè¦è³è¨ãç¶èï¼æåè§å¯å°ä¸åä»»åä¸­çååå±¤ç´éæä¸åçååæ¨¡å¼ï¼éçªé¡¯äºéè¦éå°æ¯åä»»åçç¨ç¹éæ±éèº«æé èªé©æç­ç¥ãåºæ¼æ­¤è¦è§£ï¼æåæåºäº DynamicKVï¼éæ¯ä¸ç¨®ééèª¿æ´æ¯åå±¤ç´ä¿ççä»£æ¸éä¾åææä½³åä»£ä¿ççæ¹æ³ï¼ä»¥é©æç¹å®ä»»åãDynamicKV å»ºç«äºå¨ååæ¯åå±¤ç´çæå¤§ KV å¿«åé ç®ï¼æ«æä¿çç¶åå±¤ç´çæå¤§é ç®ï¼ä¸¦å¨æ¨è«æéå®ææ´æ°ææåç½®å±¤ç´ç KV å¿«åå¤§å°ãæåçéåæ¹æ³åä¿ç 1.7% ç KV å¿«åå¤§å°ï¼åæå¨ LongBench ä¸éå°äºç´ 85% çå®æ´ KV å¿«åæè½ãå¼å¾æ³¨æçæ¯ï¼å³ä½¿å¨æ¥µç«¯å£ç¸® (0.9%) ä¸ï¼DynamicKV å¨ä½¿ç¨ Mistral-7B-Instruct-v0.2 çå¤§æµ·æéæ¸¬è©¦ä¸­ä¹æ¯æåé² (SOTA) çæ¹æ³é«åº 11%ãç¨å¼ç¢¼å°æéåºã

##### **Progressive Multimodal Reasoning via Active Retrieval**
2412.14835v1 by Guanting Dong, Chenghao Zhang, Mengjie Deng, Yutao Zhu, Zhicheng Dou, Ji-Rong Wen

Multi-step multimodal reasoning tasks pose significant challenges for
multimodal large language models (MLLMs), and finding effective ways to enhance
their performance in such scenarios remains an unresolved issue. In this paper,
we propose AR-MCTS, a universal framework designed to progressively improve the
reasoning capabilities of MLLMs through Active Retrieval (AR) and Monte Carlo
Tree Search (MCTS). Our approach begins with the development of a unified
retrieval module that retrieves key supporting insights for solving complex
reasoning problems from a hybrid-modal retrieval corpus. To bridge the gap in
automated multimodal reasoning verification, we employ the MCTS algorithm
combined with an active retrieval mechanism, which enables the automatic
generation of step-wise annotations. This strategy dynamically retrieves key
insights for each reasoning step, moving beyond traditional beam search
sampling to improve the diversity and reliability of the reasoning space.
Additionally, we introduce a process reward model that aligns progressively to
support the automatic verification of multimodal reasoning tasks. Experimental
results across three complex multimodal reasoning benchmarks confirm the
effectiveness of the AR-MCTS framework in enhancing the performance of various
multimodal models. Further analysis demonstrates that AR-MCTS can optimize
sampling diversity and accuracy, yielding reliable multimodal reasoning.

æè¦ï¼å¤æ­¥é©å¤æ¨¡ææ¨çä»»åå°å¤æ¨¡æå¤§åèªè¨æ¨¡å (MLLM) æ§æéå¤§ææ°ï¼èå°æ¾æææ¹æ³ä¾æåå®åå¨éç¨®ææ³ä¸çæè½ä»ç¶æ¯ä¸åæªè§£æ±ºçåé¡ãå¨æ¬æä¸­ï¼æåæåº AR-MCTSï¼ä¸åéç¨æ¡æ¶ï¼æ¨å¨ééä¸»åæª¢ç´¢ (AR) åèå°å¡ç¾æ¨¹çæå° (MCTS) éæ­¥æå MLLM çæ¨çè½åãæåçåæ³å¾éç¼ä¸åçµ±ä¸çæª¢ç´¢æ¨¡çµéå§ï¼è©²æ¨¡çµå¾æ··åæ¨¡å¼æª¢ç´¢èªæåº«ä¸­æª¢ç´¢è§£æ±ºè¤éæ¨çåé¡çä¸»è¦æ¯æè¦è§£ãçºäºå½åèªååå¤æ¨¡ææ¨çé©è­çå·®è·ï¼æåæ¡ç¨ MCTS æ¼ç®æ³çµåä¸»åæª¢ç´¢æ©å¶ï¼éä½¿å¾è½å¤ èªåç¢çéæ­¥è¨»è§£ãæ­¤ç­ç¥åææª¢ç´¢æ¯åæ¨çæ­¥é©çä¸»è¦è¦è§£ï¼è¶è¶å³çµ±çæ³¢ææå°åæ¨£ï¼ä»¥æåæ¨çç©ºéçå¤æ¨£æ§åå¯é æ§ãæ­¤å¤ï¼æåå¼å¥ä¸åéç¨åé¥æ¨¡åï¼éæ­¥èª¿æ´ä»¥æ¯æ´å¤æ¨¡ææ¨çä»»åçèªåé©è­ãå¨ä¸åè¤éçå¤æ¨¡ææ¨çåºæºä¸çå¯¦é©çµæè­å¯¦äº AR-MCTS æ¡æ¶å¨æååç¨®å¤æ¨¡ææ¨¡åæè½æ¹é¢çæææ§ãé²ä¸æ­¥çåæè­æ AR-MCTS è½å¤ æä½³ååæ¨£å¤æ¨£æ§åæºç¢ºåº¦ï¼ç¢çå¯é çå¤æ¨¡ææ¨çã

##### **Mention Attention for Pronoun Translation**
2412.14829v1 by Gongbo Tang, Christian Hardmeier

Most pronouns are referring expressions, computers need to resolve what do
the pronouns refer to, and there are divergences on pronoun usage across
languages. Thus, dealing with these divergences and translating pronouns is a
challenge in machine translation. Mentions are referring candidates of pronouns
and have closer relations with pronouns compared to general tokens. We assume
that extracting additional mention features can help pronoun translation.
Therefore, we introduce an additional mention attention module in the decoder
to pay extra attention to source mentions but not non-mention tokens. Our
mention attention module not only extracts features from source mentions, but
also considers target-side context which benefits pronoun translation. In
addition, we also introduce two mention classifiers to train models to
recognize mentions, whose outputs guide the mention attention. We conduct
experiments on the WMT17 English-German translation task, and evaluate our
models on general translation and pronoun translation, using BLEU, APT, and
contrastive evaluation metrics. Our proposed model outperforms the baseline
Transformer model in terms of APT and BLEU scores, this confirms our hypothesis
that we can improve pronoun translation by paying additional attention to
source mentions, and shows that our introduced additional modules do not have
negative effect on the general translation quality.

æè¦ï¼å¤§é¨åä»£åè©é½æ¯ææ¶è¡¨éï¼é»è¦éè¦è§£æä»£åè©æææ¶çå§å®¹ï¼èä¸åèªè¨å¨ä»£åè©çä½¿ç¨ä¸å­å¨å·®ç°ãå æ­¤ï¼èçéäºå·®ç°ä¸¦ç¿»è­¯ä»£åè©æ¯æ©å¨ç¿»è­¯ä¸­çä¸é ææ°ãæåæ¯ä»£åè©çææ¶åé¸ï¼èä¸è¬ç¬¦èç¸æ¯ï¼èä»£åè©ææ´ç·å¯çéä¿ãæååè¨­èåé¡å¤çæåç¹å¾µæå©æ¼ä»£åè©ç¿»è­¯ãå æ­¤ï¼æåå¨è§£ç¢¼å¨ä¸­å¼å¥ä¸åé¡å¤çæåæ³¨æåæ¨¡çµï¼ä»¥ç¹å¥æ³¨æä¾æºæåï¼ä½ä¸æ³¨æéæåç¬¦èãæåçæåæ³¨æåæ¨¡çµä¸åå¾ä¾æºæåä¸­èåç¹å¾µï¼éèæ®äºå°ä»£åè©ç¿»è­¯æççç®æ¨å´æå¢ãæ­¤å¤ï¼æåéå¼å¥äºå©åæååé¡å¨ï¼ä»¥è¨ç·´æ¨¡åè­å¥æåï¼å¶è¼¸åºæå°æåæ³¨æåãæåå° WMT17 è±å¾·ç¿»è­¯ä»»åé²è¡äºå¯¦é©ï¼ä¸¦ä½¿ç¨ BLEUãAPT åå°æ¯è©ä¼°ææ¨å°æåçæ¨¡åé²è¡äºéç¨ç¿»è­¯åä»£åè©ç¿»è­¯è©ä¼°ãæåæåºçæ¨¡åå¨ APT å BLEU åæ¸æ¹é¢åªæ¼åºæº Transformer æ¨¡åï¼éè­å¯¦äºæåçåè¨­ï¼å³æåå¯ä»¥ééç¹å¥æ³¨æä¾æºæåä¾æ¹é²ä»£åè©ç¿»è­¯ï¼ä¸¦è¡¨ææåå¼å¥çé¡å¤æ¨¡çµå°ä¸è¬ç¿»è­¯åè³ªæ²æè² é¢å½±é¿ã

##### **Answer Set Networks: Casting Answer Set Programming into Deep Learning**
2412.14814v1 by Arseny Skryagin, Daniel Ochs, Phillip Deibert, Simon Kohaut, Devendra Singh Dhami, Kristian Kersting

Although Answer Set Programming (ASP) allows constraining neural-symbolic
(NeSy) systems, its employment is hindered by the prohibitive costs of
computing stable models and the CPU-bound nature of state-of-the-art solvers.
To this end, we propose Answer Set Networks (ASN), a NeSy solver. Based on
Graph Neural Networks (GNN), ASNs are a scalable approach to ASP-based Deep
Probabilistic Logic Programming (DPPL). Specifically, we show how to translate
ASPs into ASNs and demonstrate how ASNs can efficiently solve the encoded
problem by leveraging GPU's batching and parallelization capabilities. Our
experimental evaluations demonstrate that ASNs outperform state-of-the-art
CPU-bound NeSy systems on multiple tasks. Simultaneously, we make the following
two contributions based on the strengths of ASNs. Namely, we are the first to
show the finetuning of Large Language Models (LLM) with DPPLs, employing ASNs
to guide the training with logic. Further, we show the "constitutional
navigation" of drones, i.e., encoding public aviation laws in an ASN for
routing Unmanned Aerial Vehicles in uncertain environments.

æè¦ï¼åç®¡ç­æ¡éç¨å¼è¨­è¨ï¼ASPï¼åè¨±ç´æç¥ç¶ç¬¦èï¼NeSyï¼ç³»çµ±ï¼ä½å¶æç¨åå°è¨ç®ç©©å®æ¨¡åçéé«ææ¬åç¾ææ±è§£å¨å CPU éå¶çæ¬è³ªæé»ç¤ãçºæ­¤ï¼æåæåºç­æ¡éç¶²è·¯ï¼ASNï¼ï¼ä¸å NeSy æ±è§£å¨ãASN åºæ¼åç¥ç¶ç¶²è·¯ï¼GNNï¼ï¼æ¯ä¸ç¨®åºæ¼ ASP çæ·±åº¦æ©çéè¼¯ç¨å¼è¨­è¨ï¼DPPLï¼çå¯æ´åæ¹æ³ãå·é«ä¾èªªï¼æåå±ç¤ºå¦ä½å° ASP è½æçº ASNï¼ä¸¦å±ç¤º ASN å¦ä½ééå©ç¨ GPU çæ¹æ¬¡èçåä¸¦è¡ååè½ææå°è§£æ±ºç·¨ç¢¼åé¡ãæåçå¯¦é©è©ä¼°è¡¨æï¼ASN å¨å¤é ä»»åä¸åªæ¼ç¾æçå CPU éå¶ç NeSy ç³»çµ±ãåæï¼æåæ ¹æ ASN çåªå¢ååºäºä»¥ä¸å©é è²¢ç»ãä¹å°±æ¯èªªï¼æåé¦æ¬¡å±ç¤ºä½¿ç¨ DPPL å°å¤§åèªè¨æ¨¡åï¼LLMï¼é²è¡å¾®èª¿ï¼ä½¿ç¨ ASN ä»¥éè¼¯å¼å°è¨ç·´ãæ­¤å¤ï¼æåå±ç¤ºäºç¡äººæ©çãæ²æ³å°èªãï¼å³å¨ ASN ä¸­ç·¨ç¢¼å¬å±èªç©ºæ³ï¼ä»¥ä¾¿å¨ä¸ç¢ºå®çç°å¢ä¸­å°ç¡äººæ©é²è¡è·¯ç±ã

##### **MARIA: a Multimodal Transformer Model for Incomplete Healthcare Data**
2412.14810v1 by Camillo Maria Caruso, Paolo Soda, Valerio Guarrasi

In healthcare, the integration of multimodal data is pivotal for developing
comprehensive diagnostic and predictive models. However, managing missing data
remains a significant challenge in real-world applications. We introduce MARIA
(Multimodal Attention Resilient to Incomplete datA), a novel transformer-based
deep learning model designed to address these challenges through an
intermediate fusion strategy. Unlike conventional approaches that depend on
imputation, MARIA utilizes a masked self-attention mechanism, which processes
only the available data without generating synthetic values. This approach
enables it to effectively handle incomplete datasets, enhancing robustness and
minimizing biases introduced by imputation methods. We evaluated MARIA against
10 state-of-the-art machine learning and deep learning models across 8
diagnostic and prognostic tasks. The results demonstrate that MARIA outperforms
existing methods in terms of performance and resilience to varying levels of
data incompleteness, underscoring its potential for critical healthcare
applications.

æè¦ï¼å¨é«çä¿å¥ä¸­ï¼å¤æ¨¡æè³æçæ´åå°æ¼éç¼å¨é¢çè¨ºæ·åé æ¸¬æ¨¡åè³ééè¦ãç¶èï¼å¨å¯¦éæç¨ä¸­ï¼ç®¡çéºå¤±çè³æä»ç¶æ¯ä¸é éå¤§çææ°ãæåä»ç´¹äº MARIAï¼å°ä¸å®æ´è³æå·æå½æ§çå¤æ¨¡ææ³¨æåï¼ï¼éæ¯ä¸ç¨®æ°ç©çåºæ¼Transformerçæ·±åº¦å­¸ç¿æ¨¡åï¼æ¨å¨ééä¸­éèåç­ç¥ä¾æå°éäºææ°ãèä¾è³´æ¼æè£çå³çµ±æ¹æ³ä¸åï¼MARIA å©ç¨äºé®ç½©èªæ³¨æåæ©å¶ï¼å®åªèçå¯ç¨è³æèä¸çæåæå¼ãéç¨®æ¹æ³ä½¿å¶è½å¤ ææå°èçä¸å®æ´çè³æéï¼å¢å¼·äºå¥å£¯æ§ä¸¦æå¤§éåº¦å°æ¸å°äºæè£æ¹æ³å¼å¥çåå·®ãæåå¨ 8 é è¨ºæ·åé å¾ä»»åä¸­ï¼å° MARIA è 10 ç¨®æåé²çæ©å¨å­¸ç¿åæ·±åº¦å­¸ç¿æ¨¡åé²è¡äºè©ä¼°ãçµæè¡¨æï¼MARIA å¨æ§è½åå°ä¸åç¨åº¦è³æä¸å®æ´æ§çå½æ§æ¹é¢åªæ¼ç¾ææ¹æ³ï¼éçªé¡¯äºå¶å¨ééµé«çä¿å¥æç¨ä¸­çæ½åã

##### **ResoFilter: Rine-grained Synthetic Data Filtering for Large Language Models through Data-Parameter Resonance Analysis**
2412.14809v1 by Zeao Tu, Xiangdi Meng, Yu He, Zihan Yao, Tianyu Qi, Jun Liu, Ming Li

Large language models (LLMs) have shown remarkable effectiveness across
various domains, with data augmentation methods utilizing GPT for synthetic
data generation becoming prevalent. However, the quality and utility of
augmented data remain questionable, and current methods lack clear metrics for
evaluating data characteristics. To address these challenges, we propose
ResoFilter, a novel method that integrates models, data, and tasks to refine
datasets. ResoFilter leverages the fine-tuning process to obtain Data-Parameter
features for data selection, offering improved interpretability by representing
data characteristics through model weights. Our experiments demonstrate that
ResoFilter achieves comparable results to full-scale fine-tuning using only
half the data in mathematical tasks and exhibits strong generalization across
different models and domains. This method provides valuable insights for
constructing synthetic datasets and evaluating high-quality data, offering a
promising solution for enhancing data augmentation techniques and improving
training dataset quality for LLMs. For reproducibility, we will release our
code and data upon acceptance.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å·²å¨åç¨®é åå±ç¾åºé¡¯èçæè½ï¼èå©ç¨ GPT é²è¡åæè³æçæçè³ææ´åæ¹æ³ä¹æ¥çæ®éãç¶èï¼æ´åè³æçåè³ªåæç¨ä»æå¾åæ¦·ï¼èç¾è¡æ¹æ³ä¹ç¼ºä¹æç¢ºçææ¨ä¾è©ä¼°è³æç¹æ§ãçºäºæå°éäºææ°ï¼æåæåº ResoFilterï¼éæ¯ä¸ç¨®å°æ¨¡åãè³æåä»»åæ´åå¨ä¸èµ·ï¼ç¨æ¼ç²¾çè³æéçåµæ°æ¹æ³ãResoFilter ééå¾®èª¿ç¨åºä¾åå¾è³æåæ¸ç¹å¾µï¼ç¨æ¼è³æé¸åï¼ä¸¦ééæ¨¡åæ¬éä¾åç¾è³æç¹æ§ï¼é²èæåå¯è§£éæ§ãæåçå¯¦é©è­æï¼ResoFilter åªä½¿ç¨æ¸å­¸ä»»åä¸­ä¸åçè³æï¼å°±è½éæèå¨é¢å¾®èª¿ç¸ç¶ççµæï¼ä¸¦å¨ä¸åçæ¨¡ååé åä¸­å±ç¾å¼·å¤§çæ³åè½åãæ­¤æ¹æ³å¯çºå»ºæ§åæè³æéåè©ä¼°é«åè³ªè³ææä¾æå¹å¼çè¦è§£ï¼ä¸¦çºå å¼·è³ææ´åæè¡åæå LLM è¨ç·´è³æéåè³ªæä¾ä¸åæåæ¯çè§£æ±ºæ¹æ¡ãçºäºå¯éç¾æ§ï¼æåå°å¨ç²å¾æ¥åå¾éåºæåçç¨å¼ç¢¼åè³æã

##### **Stack Trace Deduplication: Faster, More Accurately, and in More Realistic Scenarios**
2412.14802v1 by Egor Shibaev, Denis Sushentsev, Yaroslav Golubev, Aleksandr Khvorov

In large-scale software systems, there are often no fully-fledged bug reports
with human-written descriptions when an error occurs. In this case, developers
rely on stack traces, i.e., series of function calls that led to the error.
Since there can be tens and hundreds of thousands of them describing the same
issue from different users, automatic deduplication into categories is
necessary to allow for processing. Recent works have proposed powerful deep
learning-based approaches for this, but they are evaluated and compared in
isolation from real-life workflows, and it is not clear whether they will
actually work well at scale.
  To overcome this gap, this work presents three main contributions: a novel
model, an industry-based dataset, and a multi-faceted evaluation. Our model
consists of two parts - (1) an embedding model with byte-pair encoding and
approximate nearest neighbor search to quickly find the most relevant stack
traces to the incoming one, and (2) a reranker that re-ranks the most fitting
stack traces, taking into account the repeated frames between them. To
complement the existing datasets collected from open-source projects, we share
with the community SlowOps - a dataset of stack traces from IntelliJ-based
products developed by JetBrains, which has an order of magnitude more stack
traces per category. Finally, we carry out an evaluation that strives to be
realistic: measuring not only the accuracy of categorization, but also the
operation time and the ability to create new categories. The evaluation shows
that our model strikes a good balance - it outperforms other models on both
open-source datasets and SlowOps, while also being faster on time than most. We
release all of our code and data, and hope that our work can pave the way to
further practice-oriented research in the area.

æè¦ï¼<paragraph>å¨å¤§è¦æ¨¡è»é«ç³»çµ±ä¸­ï¼ç¶é¯èª¤ç¼çæï¼éå¸¸æ²æå®æ´çäººå·¥æ°å¯«æè¿°çé¯èª¤å ±åãå¨éç¨®ææ³ä¸ï¼éç¼äººå¡ä¾è³´å çè¿½è¹¤ï¼ä¹å°±æ¯å°è´é¯èª¤çä¸ç³»åå½å¼å¼å«ãç±æ¼å¯è½ææåä¸è¬åå çè¿½è¹¤æè¿°ä¾èªä¸åä½¿ç¨èçç¸ååé¡ï¼å æ­¤å¿é èªåå°å¶åé¡å»éï¼æè½é²è¡èçãæè¿çç ç©¶æåºå¼·å¤§çæ·±åº¦å­¸ç¿æ¹æ³ä¾è§£æ±ºéååé¡ï¼ä½éäºæ¹æ³æ¯å¨èå¯¦éå·¥ä½æµç¨éé¢ççæä¸é²è¡è©ä¼°åæ¯è¼ï¼å æ­¤ä¸æ¸æ¥å®åæ¯å¦ççè½å¨å¤§è¦æ¨¡ææ³ä¸é å©éä½ã
çºäºåæéåå·®è·ï¼æ¬ç ç©¶æåºäºä¸é ä¸»è¦è²¢ç»ï¼ä¸åæ°æ¨¡åãä¸åç¢æ¥­è³æéåä¸åå¤é¢åè©ä¼°ãæåçæ¨¡ååå«å©åé¨åï¼(1) ä¸åä½¿ç¨ä½åçµå°ç·¨ç¢¼çåµå¥æ¨¡ååè¿ä¼¼æè¿é°æå°ï¼ç¨æ¼å¿«éæ¾åºèè¼¸å¥å çè¿½è¹¤æç¸éçå çè¿½è¹¤ï¼ä»¥å (2) ä¸åéæ°æåºå¨ï¼ç¨æ¼éæ°æåºæåé©çå çè¿½è¹¤ï¼ä¸¦èéå®åä¹ééè¤çæ¡æ¶ãçºäºè£åå¾éæºå°æ¡æ¶éçç¾æè³æéï¼æåèç¤¾ç¾¤åäº« SlowOpsï¼éæ¯ä¸åä¾èª JetBrains éç¼ç IntelliJ çºåºç¤ç¢åçå çè¿½è¹¤è³æéï¼æ¯åé¡å¥çå çè¿½è¹¤æ¸éå¤äºä¸åæ¸éç´ãæå¾ï¼æåé²è¡äºä¸é åæ±åå¯¦çè©ä¼°ï¼ä¸åè¡¡éåé¡çæºç¢ºæ§ï¼éè¡¡ééä½æéåå»ºç«æ°é¡å¥çè½åãè©ä¼°çµæé¡¯ç¤ºæåçæ¨¡ååå¾äºè¯å¥½çå¹³è¡¡ï¼å®å¨éæºè³æéå SlowOps ä¸é½åªæ¼å¶ä»æ¨¡åï¼åæéåº¦ä¹æ¯å¤§å¤æ¸æ¨¡åå¿«ãæåéåºäºææç¨å¼ç¢¼åè³æï¼ä¸¦å¸ææåçç ç©¶è½çºéåé åçå¯¦åå°åç ç©¶éªè·¯ã</paragraph>

##### **Disentangling Reasoning Tokens and Boilerplate Tokens For Language Model Fine-tuning**
2412.14780v1 by Ziang Ye, Zhenru Zhang, Yang Zhang, Jianxin Ma, Junyang Lin, Fuli Feng

When using agent-task datasets to enhance agent capabilities for Large
Language Models (LLMs), current methodologies often treat all tokens within a
sample equally. However, we argue that tokens serving different roles -
specifically, reasoning tokens versus boilerplate tokens (e.g., those governing
output format) - differ significantly in importance and learning complexity,
necessitating their disentanglement and distinct treatment. To address this, we
propose a novel Shuffle-Aware Discriminator (SHAD) for adaptive token
discrimination. SHAD classifies tokens by exploiting predictability differences
observed after shuffling input-output combinations across samples: boilerplate
tokens, due to their repetitive nature among samples, maintain predictability,
whereas reasoning tokens do not. Using SHAD, we propose the
Reasoning-highlighted Fine-Tuning (RFT) method, which adaptively emphasizes
reasoning tokens during fine-tuning, yielding notable performance gains over
common Supervised Fine-Tuning (SFT).

æè¦ï¼å¨ä½¿ç¨ä»£çä»»åè³æéä¾å¢å¼·å¤§åèªè¨æ¨¡å (LLM) çä»£çè½åæï¼ç®åçæè¡éå¸¸å°ç¯ä¾ä¸­çææç¬¦èè¦çºåç­éè¦ãç¶èï¼æåèªçºæ®æ¼ä¸åè§è²çç¬¦èï¼ç¹å¥æ¯æ¨çç¬¦èèæ¨£æ¿ç¬¦èï¼ä¾å¦ï¼æ§å¶è¼¸åºæ ¼å¼çç¬¦èï¼ï¼å¨éè¦æ§åå­¸ç¿è¤éæ§ä¸å­å¨é¡¯èå·®ç°ï¼éè¦å°å®åååéä¾ä¸¦åå¥èçãçºäºè§£æ±ºéååé¡ï¼æåæåºäºä¸ç¨®æ°ç©çé¨æ©æç¥è¾¨è­å¨ (SHAD)ï¼ç¨æ¼èªé©æç¬¦èè¾¨è­ãSHAD ééå©ç¨å¨ç¯ä¾ä¸­æ··æ´è¼¸å¥è¼¸åºçµåå¾è§å¯å°çå¯é æ¸¬æ§å·®ç°ä¾å°ç¬¦èé²è¡åé¡ï¼æ¨£æ¿ç¬¦èç±æ¼å¨ç¯ä¾ä¸­çéè¤æ§èä¿æå¯é æ¸¬æ§ï¼èæ¨çç¬¦èåä¸ç¶ãä½¿ç¨ SHADï¼æåæåºäºå¼·èª¿æ¨çå¾®èª¿ (RFT) æ¹æ³ï¼å®å¨å¾®èª¿éç¨ä¸­èªé©æå°å¼·èª¿æ¨çç¬¦èï¼èå¸¸è¦çç£ç£å¾®èª¿ (SFT) ç¸æ¯ï¼ç¢çé¡¯èçæè½æåã

##### **ALKAFI-LLAMA3: Fine-Tuning LLMs for Precise Legal Understanding in Palestine**
2412.14771v1 by Rabee Qasem, Mohannad Hendi, Banan Tantour

Large Language Models (LLMs) have demonstrated remarkable potential in
diverse domains, yet their application in the legal sector, particularly in
low-resource contexts, remains limited. This study addresses the challenges of
adapting LLMs to the Palestinian legal domain, where political instability,
fragmented legal frameworks, and limited AI resources hinder effective
machine-learning applications. We present a fine-tuned model based on a
quantized version of Llama-3.2-1B-Instruct, trained on a synthetic data set
derived from Palestinian legal texts. Using smaller-scale models and
strategically generated question-answer pairs, we achieve a cost-effective,
locally sustainable solution that provides accurate and contextually relevant
legal guidance. Our experiments demonstrate promising performance on various
query types, ranging from yes/no questions and narrative explanations to
complex legal differentiations, while highlighting areas for improvement, such
as handling calculation-based inquiries and structured list formatting. This
work provides a pathway for the deployment of AI-driven legal assistance tools
tailored to the needs of resource-constrained environments.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å·²å¨ä¸åé åå±ç¾åºé¡¯èçæ½åï¼ä½å®åå¨æ³å¾é åçæç¨ï¼ç¹å¥æ¯å¨è³æºä¸è¶³çç°å¢ä¸­ï¼ä»ç¶æéãæ¬ç ç©¶æ¢è¨äºå° LLM é©æå°å·´åæ¯å¦æ³å¾é åçææ°ï¼å¨è©²é åä¸­ï¼æ¿æ²»ä¸ç©©å®ãæ³å¾æ¡æ¶æ¯é¢ç ´ç¢ä»¥å AI è³æºæéï¼é»ç¤äºææçæ©å¨å­¸ç¿æç¨ãæåæä¾äºä¸åç¶éå¾®èª¿çæ¨¡åï¼è©²æ¨¡ååºæ¼ Llama-3.2-1B-Instruct çéåçæ¬ï¼ä¸¦æ ¹æå¾å·´åæ¯å¦æ³å¾ææ¬ä¸­è¡ççåææ¸æéé²è¡è¨ç·´ãä½¿ç¨è¼å°è¦æ¨¡çæ¨¡ååç­ç¥æ§çæçåç­å°ï¼æåå¯¦ç¾äºä¸åå·æææ¬æçãå¨ç¶å°å¯æçºçè§£æ±ºæ¹æ¡ï¼è©²è§£æ±ºæ¹æ¡æä¾äºæºç¢ºä¸èä¸ä¸æç¸éçæ³å¾æå°ãæåçå¯¦é©è­æäºå¨åç¨®æ¥è©¢é¡åä¸çè¯å¥½è¡¨ç¾ï¼åæ¬å¾æ¯éé¡åæè¿°æ§è§£éå°è¤éçæ³å¾åå¥ï¼åæå¼·èª¿äºæ¹é²é åï¼ä¾å¦èçåºæ¼è¨ç®çæ¥è©¢åçµæ§ååè¡¨æ ¼å¼ãéé å·¥ä½çºé¨ç½² AI é©åçæ³å¾æ´å©å·¥å·æä¾äºä¸æ¢éå¾ï¼è©²å·¥å·å°çºè³æºåéç°å¢çéæ±èéèº«æé ã

##### **PsyDraw: A Multi-Agent Multimodal System for Mental Health Screening in Left-Behind Children**
2412.14769v1 by Yiqun Zhang, Xiaocui Yang, Xiaobai Li, Siyuan Yu, Yi Luan, Shi Feng, Daling Wang, Yifei Zhang

Left-behind children (LBCs), numbering over 66 million in China, face severe
mental health challenges due to parental migration for work. Early screening
and identification of at-risk LBCs is crucial, yet challenging due to the
severe shortage of mental health professionals, especially in rural areas.
While the House-Tree-Person (HTP) test shows higher child participation rates,
its requirement for expert interpretation limits its application in
resource-scarce regions. To address this challenge, we propose PsyDraw, a
multi-agent system based on Multimodal Large Language Models that assists
mental health professionals in analyzing HTP drawings. The system employs
specialized agents for feature extraction and psychological interpretation,
operating in two stages: comprehensive feature analysis and professional report
generation. Evaluation of HTP drawings from 290 primary school students reveals
that 71.03% of the analyzes achieved High Consistency with professional
evaluations, 26.21% Moderate Consistency and only 2.41% Low Consistency. The
system identified 31.03% of cases requiring professional attention,
demonstrating its effectiveness as a preliminary screening tool. Currently
deployed in pilot schools, \method shows promise in supporting mental health
professionals, particularly in resource-limited areas, while maintaining high
professional standards in psychological assessment.

æè¦ï¼çå®å¿ç«¥ï¼LBCï¼å¨ä¸­å½è¶è¿ 6600 ä¸ï¼ç±äºç¶æ¯å¤åºå¡å·¥ï¼ä»ä»¬é¢ä¸´çä¸¥éçå¿çå¥åº·ææãå¯¹é«å± LBC è¿è¡æ©æç­æ¥åè¯å«è³å³éè¦ï¼ä½ç±äºå¿çå¥åº·ä¸ä¸äººåä¸¥éç­ç¼ºï¼å°¤å¶æ¯å¨åæå°åºï¼è¿å´æ¯ä¸é¡¹ææãè½ç¶æ¿æ äººï¼HTPï¼æµè¯æ¾ç¤ºå¿ç«¥åä¸çè¾é«ï¼ä½å¶å¯¹ä¸å®¶è§£è¯»çè¦æ±éå¶äºå¶å¨èµæºå®ä¹å°åºçåºç¨ãä¸ºäºåºå¯¹è¿ä¸ææï¼æä»¬æåºäº PsyDrawï¼è¿æ¯ä¸ä¸ªåºäºå¤æ¨¡æå¤§è¯­è¨æ¨¡åçå¤ä¸»ä½ç³»ç»ï¼å®å¯ä»¥åå©å¿çå¥åº·ä¸ä¸äººååæ HTP å¾ç»ãè¯¥ç³»ç»éç¨ä¸é¨çä¸»ä½è¿è¡ç¹å¾æååå¿çè§£è¯»ï¼åä¸¤ä¸ªé¶æ®µè¿è¡ï¼ç»¼åç¹å¾åæåä¸ä¸æ¥åçæãå¯¹ 290 åå°å­¦çç HTP å¾ç»è¿è¡è¯ä¼°ååç°ï¼71.03% çåæä¸ä¸ä¸è¯ä¼°é«åº¦ä¸è´ï¼26.21% ä¸è´æ§ä¸­ç­ï¼ä» 2.41% ä¸è´æ§ä½ãè¯¥ç³»ç»è¯å«åº 31.03% éè¦ä¸ä¸å³æ³¨ççä¾ï¼è¯æäºå¶ä½ä¸ºåæ­¥ç­æ¥å·¥å·çæææ§ãç®åå·²å¨è¯ç¹å­¦æ ¡é¨ç½²ï¼è¯¥æ¹æ³ææä¸ºå¿çå¥åº·ä¸ä¸äººåæä¾æ¯æï¼å°¤å¶æ¯å¨èµæºæéçå°åºï¼åæ¶å¨å¿çè¯ä¼°ä¸­ä¿æè¾é«çä¸ä¸æ åã

##### **CodeRepoQA: A Large-scale Benchmark for Software Engineering Question Answering**
2412.14764v1 by Ruida Hu, Chao Peng, Jingyi Ren, Bo Jiang, Xiangxin Meng, Qinyun Wu, Pengfei Gao, Xinchen Wang, Cuiyun Gao

In this work, we introduce CodeRepoQA, a large-scale benchmark specifically
designed for evaluating repository-level question-answering capabilities in the
field of software engineering. CodeRepoQA encompasses five programming
languages and covers a wide range of scenarios, enabling comprehensive
evaluation of language models. To construct this dataset, we crawl data from 30
well-known repositories in GitHub, the largest platform for hosting and
collaborating on code, and carefully filter raw data. In total, CodeRepoQA is a
multi-turn question-answering benchmark with 585,687 entries, covering a
diverse array of software engineering scenarios, with an average of 6.62
dialogue turns per entry.
  We evaluate ten popular large language models on our dataset and provide
in-depth analysis. We find that LLMs still have limitations in
question-answering capabilities in the field of software engineering, and
medium-length contexts are more conducive to LLMs' performance. The entire
benchmark is publicly available at
https://github.com/kinesiatricssxilm14/CodeRepoQA.

æè¦ï¼å¨éé å·¥ä½ä¸­ï¼æåä»ç´¹ CodeRepoQAï¼ä¸åå°éè¨­è¨ç¨æ¼è©ä¼°è»é«å·¥ç¨é åä¸­å²å­åº«å±¤ç´åç­è½åçå¤§è¦æ¨¡åºæºãCodeRepoQA æ¶µèäºäºç¨®ç¨å¼èªè¨ä¸¦æ¶µèäºå»£æ³çå ´æ¯ï¼è®èªè¨æ¨¡åè½å¤ é²è¡å¨é¢çè©ä¼°ãçºäºå»ºæ§æ­¤è³æéï¼æåå¾ GitHubï¼ä¸åæå¤§çç¨å¼ç¢¼è¨ç®¡ååä½å¹³å°ï¼ä¸­ç¬åäº 30 åç¥åå²å­åº«çè³æï¼ä¸¦ä»ç´°éæ¿¾åå§è³æãç¸½èè¨ä¹ï¼CodeRepoQA æ¯åå¤è¼ªåç­åºæºï¼åå« 585,687 åæ¢ç®ï¼æ¶µèäºåç¨®è»é«å·¥ç¨å ´æ¯ï¼æ¯åæ¢ç®çå¹³åå°è©±è¼ªæ¸çº 6.62ã
æåå¨è³æéä¸è©ä¼°äºååç±éçå¤§åèªè¨æ¨¡åï¼ä¸¦æä¾äºæ·±å¥çåæãæåç¼ç¾å¤§åèªè¨æ¨¡åå¨è»é«å·¥ç¨é åçåç­è½åä»æå¶éå¶ï¼èä¸­ç­é·åº¦çèçµ¡æ´å©æ¼å¤§åèªè¨æ¨¡åçè¡¨ç¾ãæ´ååºæºå¯å¨ https://github.com/kinesiatricssxilm14/CodeRepoQA å¬éåå¾ã

##### **Query pipeline optimization for cancer patient question answering systems**
2412.14751v1 by Maolin He, Rena Gao, Mike Conway, Brian E. Chapman

Retrieval-augmented generation (RAG) mitigates hallucination in Large
Language Models (LLMs) by using query pipelines to retrieve relevant external
information and grounding responses in retrieved knowledge. However, query
pipeline optimization for cancer patient question-answering (CPQA) systems
requires separately optimizing multiple components with domain-specific
considerations. We propose a novel three-aspect optimization approach for the
RAG query pipeline in CPQA systems, utilizing public biomedical databases like
PubMed and PubMed Central. Our optimization includes: (1) document retrieval,
utilizing a comparative analysis of NCBI resources and introducing Hybrid
Semantic Real-time Document Retrieval (HSRDR); (2) passage retrieval,
identifying optimal pairings of dense retrievers and rerankers; and (3)
semantic representation, introducing Semantic Enhanced Overlap Segmentation
(SEOS) for improved contextual understanding. On a custom-developed dataset
tailored for cancer-related inquiries, our optimized RAG approach improved the
answer accuracy of Claude-3-haiku by 5.24% over chain-of-thought prompting and
about 3% over a naive RAG setup. This study highlights the importance of
domain-specific query optimization in realizing the full potential of RAG and
provides a robust framework for building more accurate and reliable CPQA
systems, advancing the development of RAG-based biomedical systems.

æè¦ï¼æª¢ç´¢å¢å¼·çæ (RAG) ééä½¿ç¨æ¥è©¢ç®¡ç·ä¾æ·åç¸éå¤é¨è³è¨ï¼ä¸¦å°åæå»ºç«å¨æ·åçç¥è­ä¸­ï¼ä»¥æ¸è¼å¤§åèªè¨æ¨¡å (LLM) ä¸­çå¹»è¦ºãç¶èï¼ççæ£èåç­ (CPQA) ç³»çµ±çæ¥è©¢ç®¡ç·æä½³åéè¦ä½¿ç¨ç¹å®æ¼é åçèéï¼åå¥æä½³åå¤ååä»¶ãæåæåºä¸ååµæ°çä¸é¢åæä½³åæ¹æ³ï¼ç¨æ¼ CPQA ç³»çµ±ä¸­ç RAG æ¥è©¢ç®¡ç·ï¼å©ç¨ PubMed å PubMed Central ç­å¬éçç©é«å­¸è³æåº«ãæåçæä½³ååæ¬ï¼(1) æä»¶æ·åï¼å©ç¨ NCBI è³æºçæ¯è¼åæï¼ä¸¦å¼å¥æ··åèªç¾©å³ææä»¶æ·å (HSRDR)ï¼(2) æ®µè½æ·åï¼æ¾åºç¨ å¯æ·åå¨åéæ°æåºå¨çæä½³éå°ï¼ä»¥å (3) èªæè¡¨ç¤ºï¼å¼å¥èªæå¢å¼·éçåæ®µ (SEOS) ä»¥æ¹åèçµ¡çè§£ãå¨éå°ççç¸éæ¥è©¢éèº«æé çå®¢è£½åéç¼è³æéä¸ï¼æåæä½³åç RAG æ¹æ³å° Claude-3-haiku çç­æ¡æºç¢ºåº¦æåäº 5.24%ï¼åªæ¼æèéæç¤ºï¼ä¸æ¯æ¨¸ç´ ç RAG è¨­å®æåäºç´ 3%ãéé ç ç©¶å¼·èª¿äºç¹å®æ¼é åçæ¥è©¢æä½³åå¨å¯¦ç¾ RAG ååæ½åçéè¦æ§ï¼ä¸¦æä¾äºä¸åç©©å¥çæ¶æ§ä¾å»ºæ§æ´æºç¢ºä¸å¯é ç CPQA ç³»çµ±ï¼ä¿é²åºæ¼ RAG ççç©é«å­¸ç³»çµ±çç¼å±ã

##### **On Verbalized Confidence Scores for LLMs**
2412.14737v1 by Daniel Yang, Yao-Hung Hubert Tsai, Makoto Yamada

The rise of large language models (LLMs) and their tight integration into our
daily life make it essential to dedicate efforts towards their trustworthiness.
Uncertainty quantification for LLMs can establish more human trust into their
responses, but also allows LLM agents to make more informed decisions based on
each other's uncertainty. To estimate the uncertainty in a response, internal
token logits, task-specific proxy models, or sampling of multiple responses are
commonly used. This work focuses on asking the LLM itself to verbalize its
uncertainty with a confidence score as part of its output tokens, which is a
promising way for prompt- and model-agnostic uncertainty quantification with
low overhead. Using an extensive benchmark, we assess the reliability of
verbalized confidence scores with respect to different datasets, models, and
prompt methods. Our results reveal that the reliability of these scores
strongly depends on how the model is asked, but also that it is possible to
extract well-calibrated confidence scores with certain prompt methods. We argue
that verbalized confidence scores can become a simple but effective and
versatile uncertainty quantification method in the future. Our code is
available at https://github.com/danielyxyang/llm-verbalized-uq .

æè¦ï¼é¨èå¤§åèªè¨æ¨¡å (LLM) çèèµ·åå¶èæåæ¥å¸¸çæ´»ç·å¯çæ´åï¼è´åæ¼æåå¶å¯ä¿¡åº¦è³ééè¦ãLLM çä¸ç¢ºå®æ§éåå¯ä»¥å»ºç«äººé¡å°å¶åæçæ´å¤ä¿¡ä»»ï¼ä½ä¹åè¨± LLM ä»£çæ ¹æå½¼æ­¤çä¸ç¢ºå®æ§ååºæ´ææºçæ±ºç­ãçºäºä¼°è¨åæä¸­çä¸ç¢ºå®æ§ï¼éå¸¸æä½¿ç¨å§é¨æ¬éãç¹å®æ¼ä»»åçä»£çæ¨¡åæå¤éåæåæ¨£ãéé å·¥ä½éé»å¨æ¼è¦æ± LLM æ¬èº«ä»¥ä¿¡å¿åæ¸çå½¢å¼å°å¶ä¸ç¢ºå®æ§é²è¡è¨èªåï¼ä½çºå¶è¼¸åºæ¬éçä¸é¨åï¼éæ¯ä¸ç¨®å¾æåæ¯çæç¤ºåæ¨¡åä¸å¯ç¥çä¸ç¢ºå®æ§éåæ¹å¼ï¼ä¸éé·ä½ãä½¿ç¨å»£æ³çåºæºï¼æåè©ä¼°äºè¨èªåä¿¡å¿åæ¸ç¸å°æ¼ä¸åè³æéãæ¨¡ååæç¤ºæ¹æ³çå¯ä¿¡åº¦ãæåççµæé¡¯ç¤ºï¼éäºåæ¸çå¯ä¿¡åº¦å¨å¾å¤§ç¨åº¦ä¸åæ±ºæ¼å¦ä½è©¢åæ¨¡åï¼ä½ä¹é¡¯ç¤ºåºä½¿ç¨ç¹å®æç¤ºæ¹æ³æåæ ¡æºè¯å¥½çä¿¡å¿åæ¸æ¯å¯è¡çãæåèªçºï¼è¨èªåä¿¡å¿åæ¸æªä¾å¯ä»¥æçºä¸ç¨®ç°¡å®ä½ææä¸éç¨çä¸ç¢ºå®æ§éåæ¹æ³ãæåçç¨å¼ç¢¼å¯å¨ https://github.com/danielyxyang/llm-verbalized-uq åå¾ã

##### **Advances in Artificial Intelligence forDiabetes Prediction: Insights from a Systematic Literature Review**
2412.14736v1 by Pir Bakhsh Khokhar, Carmine Gravino, Fabio Palomba

This systematic review explores the use of machine learning (ML) in
predicting diabetes, focusing on datasets, algorithms, training methods, and
evaluation metrics. It examines datasets like the Singapore National Diabetic
Retinopathy Screening program, REPLACE-BG, National Health and Nutrition
Examination Survey, and Pima Indians Diabetes Database. The review assesses the
performance of ML algorithms like CNN, SVM, Logistic Regression, and XGBoost in
predicting diabetes outcomes. The study emphasizes the importance of
interdisciplinary collaboration and ethical considerations in ML-based diabetes
prediction models.

æè¦ï¼éé ç³»çµ±æ§åé¡§æ¢è¨äºæ©å¨å­¸ç¿ (ML) å¨ç³å°¿çé æ¸¬ä¸­çæç¨ï¼éé»å¨æ¼è³æéãæ¼ç®æ³ãè¨ç·´æ¹æ³åè©ä¼°ææ¨ãå®æª¢é©äºè³æéï¼ä¾å¦æ°å å¡åå®¶ç³å°¿çè¦ç¶²èçè®ç¯©æª¢è¨ç«ãREPLACE-BGãåå®¶å¥åº·èçé¤æª¢æ¥èª¿æ¥åç®é¦¬å°ç¬¬å®äººç³å°¿çè³æåº«ãè©²åé¡§è©ä¼°äº ML æ¼ç®æ³ï¼ä¾å¦ CNNãSVMãéè¼¯è¿´æ­¸å XGBoostï¼å¨é æ¸¬ç³å°¿ççµææ¹é¢çè¡¨ç¾ãéé ç ç©¶å¼·èª¿äºè·¨é ååä½åå¨åºæ¼ ML çç³å°¿çé æ¸¬æ¨¡åä¸­é²è¡éå¾·èéçéè¦æ§ã

##### **Creation of AI-driven Smart Spaces for Enhanced Indoor Environments -- A Survey**
2412.14708v1 by AygÃ¼n Varol, Naser Hossein Motlagh, Mirka Leino, Sasu Tarkoma, Johanna Virkki

Smart spaces are ubiquitous computing environments that integrate diverse
sensing and communication technologies to enhance space functionality, optimize
energy utilization, and improve user comfort and well-being. The integration of
emerging AI methodologies into these environments facilitates the formation of
AI-driven smart spaces, which further enhance functionalities of the spaces by
enabling advanced applications such as personalized comfort settings,
interactive living spaces, and automatization of the space systems, all
resulting in enhanced indoor experiences of the users. In this paper, we
present a systematic survey of existing research on the foundational components
of AI-driven smart spaces, including sensor technologies, data communication
protocols, sensor network management and maintenance strategies, as well as the
data collection, processing and analytics. Given the pivotal role of AI in
establishing AI-powered smart spaces, we explore the opportunities and
challenges associated with traditional machine learning (ML) approaches, such
as deep learning (DL), and emerging methodologies including large language
models (LLMs). Finally, we provide key insights necessary for the development
of AI-driven smart spaces, propose future research directions, and sheds light
on the path forward.

æè¦ï¼æºæ§ç©ºéæ¯ä¸ç¨®æ®ééç®ç°å¢ï¼æ´åäºå¤æ¨£åçææ¸¬åéè¨æè¡ä»¥æåç©ºéåè½ãåªåè½æºå©ç¨ï¼ä¸¦æ¹åä½¿ç¨èçèé©åº¦åå¹¸ç¦æãå°æ°èçäººå·¥æºæ§æ¹æ³æ´åå°éäºç°å¢ä¸­ï¼æå©æ¼å½¢æäººå·¥æºæ§é©åçæºæ§ç©ºéï¼é²ä¸æ­¥æåç©ºéåè½ï¼å¯¦ç¾åäººåèé©è¨­å®ãäºåå¼çæ´»ç©ºéåç©ºéç³»çµ±èªååç­é²éæç¨ï¼ææéäºé½è½æåä½¿ç¨èçå®¤å§é«é©ãå¨æ¬æä¸­ï¼æåå°äººå·¥æºæ§é©åæºæ§ç©ºéçåºç¤çµæé²è¡ç³»çµ±æ§æ¢è¨ï¼åæ¬ææ¸¬å¨æè¡ãè³æéè¨åå®ãææ¸¬å¨ç¶²è·¯ç®¡çåç¶­è­·ç­ç¥ï¼ä»¥åè³ææ¶éãèçååæãéæ¼äººå·¥æºæ§å¨å»ºç«äººå·¥æºæ§é©åæºæ§ç©ºéä¸­æ®æ¼ééµè§è²ï¼æåæ¢è¨äºå³çµ±æ©å¨å­¸ç¿ (ML) æ¹æ³ï¼ä¾å¦æ·±åº¦å­¸ç¿ (DL)ï¼ç¸éçæ©éåææ°ï¼ä»¥åæ°èæ¹æ³ï¼åæ¬å¤§åèªè¨æ¨¡å (LLM)ï¼ãæå¾ï¼æåæä¾äºäººå·¥æºæ§é©åæºæ§ç©ºééç¼å¿è¦çééµè¦è§£ï¼æåºæªä¾çç ç©¶æ¹åï¼ä¸¦é¡æåé²çéè·¯ã

##### **How to Synthesize Text Data without Model Collapse?**
2412.14689v1 by Xuekai Zhu, Daixuan Cheng, Hengli Li, Kaiyan Zhang, Ermo Hua, Xingtai Lv, Ning Ding, Zhouhan Lin, Zilong Zheng, Bowen Zhou

Model collapse in synthetic data indicates that iterative training on
self-generated data leads to a gradual decline in performance. With the
proliferation of AI models, synthetic data will fundamentally reshape the web
data ecosystem. Future GPT-$\{n\}$ models will inevitably be trained on a blend
of synthetic and human-produced data. In this paper, we focus on two questions:
what is the impact of synthetic data on language model training, and how to
synthesize data without model collapse? We first pre-train language models
across different proportions of synthetic data, revealing a negative
correlation between the proportion of synthetic data and model performance. We
further conduct statistical analysis on synthetic data to uncover
distributional shift phenomenon and over-concentration of n-gram features.
Inspired by the above findings, we propose token editing on human-produced data
to obtain semi-synthetic data. As a proof of concept, we theoretically
demonstrate that token-level editing can prevent model collapse, as the test
error is constrained by a finite upper bound. We conduct extensive experiments
on pre-training from scratch, continual pre-training, and supervised
fine-tuning. The results validate our theoretical proof that token-level
editing improves data quality and enhances model performance.

æè¦ï¼åæè³æä¸­çæ¨¡åå´©æ½°è¡¨æï¼å°èªæç¢ççè³æé²è¡åè¦è¨ç·´æå°è´æè½éæ¼¸ä¸éãé¨è AI æ¨¡åçæ®åï¼åæè³æå°å¾æ ¹æ¬ä¸éå¡ç¶²è·¯è³æçæç³»çµ±ãæªä¾ç GPT-$\{n\}$ æ¨¡åå°ä¸å¯é¿åå°è¨ç·´æ¼åæè³æåäººé¡ç¢çè³æçæ··åè³æä¸­ãå¨æ¬æä¸­ï¼æåå°æ³¨æ¼å©ååé¡ï¼åæè³æå°èªè¨æ¨¡åè¨ç·´çå½±é¿æ¯ä»éº¼ï¼ä»¥åå¦ä½å¨ä¸ç¼çæ¨¡åå´©æ½°çææ³ä¸åæè³æï¼æåé¦åå¨ä¸åæ¯ä¾çåæè³æä¸­é è¨ç·´èªè¨æ¨¡åï¼æ­ç¤ºäºåæè³æçæ¯ä¾èæ¨¡åæè½ä¹éçè² ç¸éãæåé²ä¸æ­¥å°åæè³æé²è¡çµ±è¨åæï¼ä»¥ç¼ç¾åä½è½ç§»ç¾è±¡å n-gram ç¹å¾µçéåº¦éä¸­ãæ ¹æä¸è¿°ç¼ç¾ï¼æåæåºå°äººé¡ç¢ççè³æé²è¡æ¨è¨ç·¨è¼¯ä»¥åå¾ååæè³æãä½çºæ¦å¿µè­æï¼æåå¨çè«ä¸è­æäºæ¨è¨å±¤ç´ç·¨è¼¯å¯ä»¥é²æ­¢æ¨¡åå´©æ½°ï¼å çºæ¸¬è©¦èª¤å·®åå°æéçä¸éç´æãæåå°å¾é ­éå§çé è¨ç·´ãæçºé è¨ç·´åç£ç£å¾®èª¿é²è¡äºå»£æ³çå¯¦é©ãçµæé©è­äºæåççè«è­æï¼å³æ¨è¨å±¤ç´ç·¨è¼¯å¯ä»¥æ¹åè³æåè³ªä¸¦å¢å¼·æ¨¡åæè½ã

##### **Each Fake News is Fake in its Own Way: An Attribution Multi-Granularity Benchmark for Multimodal Fake News Detection**
2412.14686v1 by Hao Guo, Zihan Ma, Zhi Zeng, Minnan Luo, Weixin Zeng, Jiuyang Tang, Xiang Zhao

Social platforms, while facilitating access to information, have also become
saturated with a plethora of fake news, resulting in negative consequences.
Automatic multimodal fake news detection is a worthwhile pursuit. Existing
multimodal fake news datasets only provide binary labels of real or fake.
However, real news is alike, while each fake news is fake in its own way. These
datasets fail to reflect the mixed nature of various types of multimodal fake
news. To bridge the gap, we construct an attributing multi-granularity
multimodal fake news detection dataset \amg, revealing the inherent fake
pattern. Furthermore, we propose a multi-granularity clue alignment model \our
to achieve multimodal fake news detection and attribution. Experimental results
demonstrate that \amg is a challenging dataset, and its attribution setting
opens up new avenues for future research.

æè¦ï¼ç¤¾äº¤å¹³å°å¨ä¿é²è³è¨åå¾çåæï¼ä¹åæ¥èå¤§éçåæ°èï¼é æè² é¢å½±é¿ãèªåå¤æ¨¡æåæ°èåµæ¸¬æ¯ä¸é æå¹å¼çè¿½æ±ãç¾æçå¤æ¨¡æåæ°èè³æéåæä¾çå¯¦æåçäºåæ¨ç±¤ãç¶èï¼çå¯¦æ°èæ¯ç¸ä¼¼çï¼èæ¯ååæ°èé½æå¶ç¨ç¹çèåæ¹å¼ãéäºè³æéç¡æ³åæ åç¨®é¡åå¤æ¨¡æåæ°èçæ··åæ§è³ªãçºäºå½åå·®è·ï¼æåæ§å»ºäºä¸åæ­¸å çå¤ç²åº¦å¤æ¨¡æåæ°èåµæ¸¬è³æé \amgï¼æ­ç¤ºäºå§å¨çåæ°èæ¨¡å¼ãæ­¤å¤ï¼æåæåºäºä¸åå¤ç²åº¦ç·ç´¢å°é½æ¨¡å \ourï¼ä»¥å¯¦ç¾å¤æ¨¡æåæ°èåµæ¸¬åæ­¸å ãå¯¦é©çµæè¡¨æï¼\amg æ¯ä¸åå·æææ°æ§çè³æéï¼å¶æ­¸å è¨­å®çºæªä¾çç ç©¶éé¢äºæ°çéå¾ã

##### **Bel Esprit: Multi-Agent Framework for Building AI Model Pipelines**
2412.14684v1 by Yunsu Kim, AhmedElmogtaba Abdelaziz, Thiago Castro Ferreira, Mohamed Al-Badrashiny, Hassan Sawaf

As the demand for artificial intelligence (AI) grows to address complex
real-world tasks, single models are often insufficient, requiring the
integration of multiple models into pipelines. This paper introduces Bel
Esprit, a conversational agent designed to construct AI model pipelines based
on user-defined requirements. Bel Esprit employs a multi-agent framework where
subagents collaborate to clarify requirements, build, validate, and populate
pipelines with appropriate models. We demonstrate the effectiveness of this
framework in generating pipelines from ambiguous user queries, using both
human-curated and synthetic data. A detailed error analysis highlights ongoing
challenges in pipeline construction. Bel Esprit is available for a free trial
at https://belesprit.aixplain.com.

æè¦ï¼é¨èäººå·¥æºæ§ï¼AIï¼å°æè¤éçç¾å¯¦ä¸çä»»åçéæ±ä¸æ·å¢é·ï¼å®ä¸æ¨¡åå¾å¾ä¸è¶³ä»¥æä»ï¼éè¦å°å¤åæ¨¡åæ´åå°ç®¡éä¸­ãæ¬æä»ç´¹äº Bel Espritï¼éæ¯ä¸åå°è©±ä»£çï¼æ¨å¨æ ¹æä½¿ç¨èå®ç¾©çéæ±å»ºç« AI æ¨¡åç®¡éãBel Esprit æ¡ç¨å¤ä»£çæ¶æ§ï¼å¶ä¸­å­ä»£çæåä½éæ¸éæ±ãå»ºç«ãé©è­åä½¿ç¨é©ç¶çæ¨¡åä¾å¡«åç®¡éãæåä½¿ç¨äººå·¥ç­åååæè³æï¼å±ç¤ºäºæ­¤æ¶æ§å¨å¾æ¨¡ç¨å©å¯çä½¿ç¨èæ¥è©¢ä¸­ç¢çç®¡éçæææ§ãè©³ç´°çé¯èª¤åæçªé¡¯äºç®¡éå»ºæ§ä¸­æçºå­å¨çææ°ãBel Esprit å¯å¨ https://belesprit.aixplain.com/ åè²»è©¦ç¨ã

##### **A Light-Weight Framework for Open-Set Object Detection with Decoupled Feature Alignment in Joint Space**
2412.14680v1 by Yonghao He, Hu Su, Haiyong Yu, Cong Yang, Wei Sui, Cong Wang, Song Liu

Open-set object detection (OSOD) is highly desirable for robotic manipulation
in unstructured environments. However, existing OSOD methods often fail to meet
the requirements of robotic applications due to their high computational burden
and complex deployment. To address this issue, this paper proposes a
light-weight framework called Decoupled OSOD (DOSOD), which is a practical and
highly efficient solution to support real-time OSOD tasks in robotic systems.
Specifically, DOSOD builds upon the YOLO-World pipeline by integrating a
vision-language model (VLM) with a detector. A Multilayer Perceptron (MLP)
adaptor is developed to transform text embeddings extracted by the VLM into a
joint space, within which the detector learns the region representations of
class-agnostic proposals. Cross-modality features are directly aligned in the
joint space, avoiding the complex feature interactions and thereby improving
computational efficiency. DOSOD operates like a traditional closed-set detector
during the testing phase, effectively bridging the gap between closed-set and
open-set detection. Compared to the baseline YOLO-World, the proposed DOSOD
significantly enhances real-time performance while maintaining comparable
accuracy. The slight DOSOD-S model achieves a Fixed AP of $26.7\%$, compared to
$26.2\%$ for YOLO-World-v1-S and $22.7\%$ for YOLO-World-v2-S, using similar
backbones on the LVIS minival dataset. Meanwhile, the FPS of DOSOD-S is
$57.1\%$ higher than YOLO-World-v1-S and $29.6\%$ higher than YOLO-World-v2-S.
Meanwhile, we demonstrate that the DOSOD model facilitates the deployment of
edge devices. The codes and models are publicly available at
https://github.com/D-Robotics-AI-Lab/DOSOD.

æè¦ï¼<paragraph>éæ¾å¼ç©ä»¶åµæ¸¬ (OSOD) å°æ¼éçµæ§åç°å¢ä¸­çæ©å¨äººæä½éå¸¸éè¦ãç¶èï¼ç¾æç OSOD æ¹æ³ç±æ¼å¶é«éç®è² æåè¤éçé¨ç½²ï¼éå¸¸ç¡æ³æ»¿è¶³æ©å¨äººæç¨ç¨å¼çéæ±ãçºäºè§£æ±ºéååé¡ï¼æ¬ææåºäºä¸åç¨±çºè§£è¦ OSOD (DOSOD) çè¼éç´æ¡æ¶ï¼éæ¯ä¸åå¯¦ç¨ä¸é«æçè§£æ±ºæ¹æ¡ï¼ç¨æ¼æ¯æ´æ©å¨äººç³»çµ±ä¸­çå³æ OSOD ä»»åãå·é«ä¾èªªï¼DOSOD å»ºç«å¨ YOLO-World ç®¡ç·ä¸ï¼ééå°è¦è¦ºèªè¨æ¨¡å (VLM) èåµæ¸¬å¨æ´åå¨ä¸èµ·ãéç¼äºä¸åå¤å±¤æç¥å¨ (MLP) é©éå¨ï¼å° VLM æåçæå­åµå¥è½ææä¸åè¯åç©ºéï¼åµæ¸¬å¨å¨å¶ä¸­å­¸ç¿é¡å¥ä¸å¯ç¥ææ¡çååè¡¨ç¤ºãè·¨æ¨¡æç¹å¾µç´æ¥å¨è¯åç©ºéä¸­å°é½ï¼é¿åäºè¤éçç¹å¾µäº¤äºï¼å¾èæé«äºéç®æçãDOSOD å¨æ¸¬è©¦éæ®µå°±åå³çµ±çå°éå¼åµæ¸¬å¨ä¸æ¨£éä½ï¼ææå°ç¸®å°äºå°éå¼åéæ¾å¼åµæ¸¬ä¹éçå·®è·ãèåºæº YOLO-World ç¸æ¯ï¼æåºç DOSOD å¨ä¿æå¯æ¯ç²¾ç¢ºåº¦çåæï¼é¡¯èæåäºå³ææè½ãè¼éç DOSOD-S æ¨¡åå¨ LVIS minival è³æéä¸ä½¿ç¨é¡ä¼¼çéª¨å¹¹ç¶²è·¯ï¼éå°äº 26.7% çåºå® APï¼è YOLO-World-v1-S çº 26.2%ï¼YOLO-World-v2-S çº 22.7%ãåæï¼DOSOD-S ç FPS æ¯ YOLO-World-v1-S é« 57.1%ï¼æ¯ YOLO-World-v2-S é« 29.6%ãåæï¼æåè­æäº DOSOD æ¨¡åæå©æ¼éç·£è£ç½®çé¨ç½²ãç¨å¼ç¢¼åæ¨¡åå·²å¬éå¨ https://github.com/D-Robotics-AI-Lab/DOSODã</paragraph>

##### **LLMs as mediators: Can they diagnose conflicts accurately?**
2412.14675v1 by Ãzgecan KoÃ§ak, Phanish Puranam, AfÅar Yegin

Prior research indicates that to be able to mediate conflict, observers of
disagreements between parties must be able to reliably distinguish the sources
of their disagreement as stemming from differences in beliefs about what is
true (causality) vs. differences in what they value (morality). In this paper,
we test if OpenAI's Large Language Models GPT 3.5 and GPT 4 can perform this
task and whether one or other type of disagreement proves particularly
challenging for LLM's to diagnose. We replicate study 1 in Ko\c{c}ak et al.
(2003), which employes a vignette design, with OpenAI's GPT 3.5 and GPT 4. We
find that both LLMs have similar semantic understanding of the distinction
between causal and moral codes as humans and can reliably distinguish between
them. When asked to diagnose the source of disagreement in a conversation, both
LLMs, compared to humans, exhibit a tendency to overestimate the extent of
causal disagreement and underestimate the extent of moral disagreement in the
moral misalignment condition. This tendency is especially pronounced for GPT 4
when using a proximate scale that relies on concrete language specific to an
issue. GPT 3.5 does not perform as well as GPT4 or humans when using either the
proximate or the distal scale. The study provides a first test of the potential
for using LLMs to mediate conflict by diagnosing the root of disagreements in
causal and evaluative codes.

æè¦ï¼<paragraph>ååçç ç©¶è¡¨æï¼ä¸ºäºè½å¤è°è§£å²çªï¼åæ¹äºç«¯çè§å¯èå¿é¡»è½å¤å¯é å°åºåå¶äºç«¯çæ ¹æºï¼æ¯æºäºå¯¹ä½ä¸ºçå®ï¼å æå³ç³»ï¼çä¿¡å¿µå·®å¼ï¼è¿æ¯æºäºå¯¹ä»ä»¬æéè§äºç©çå·®å¼ï¼éå¾·ï¼ãå¨æ¬æä¸­ï¼æä»¬æµè¯äº OpenAI çå¤§åè¯­è¨æ¨¡å GPT 3.5 å GPT 4 æ¯å¦å¯ä»¥æ§è¡æ­¤ä»»å¡ï¼ä»¥ååªç§ç±»åçäºç«¯è¢«è¯æå¯¹ LLM çè¯æ­ç¹å«å·ææææ§ãæä»¬å¨ Ko\c{c}ak ç­äººçç ç©¶ 1 ä¸­å¤å¶äºç ç©¶ 1ã(2003)ï¼å®éç¨å°æå¾è®¾è®¡ï¼ä½¿ç¨ OpenAI ç GPT 3.5 å GPT 4ãæä»¬åç°ï¼è¿ä¸¤ç§ LLM å¯¹å æåéå¾·è§èä¹é´çåºå«å·æä¸äººç±»ç¸ä¼¼çè¯­ä¹çè§£ï¼å¹¶ä¸å¯ä»¥å¯é å°åºåå®ä»¬ãå½è¢«è¦æ±è¯æ­å¯¹è¯ä¸­åæ­§çæ ¹æºæ¶ï¼ä¸äººç±»ç¸æ¯ï¼è¿ä¸¤ç§ LLM é½è¡¨ç°åºé«ä¼°å æåæ­§ç¨åº¦åä½ä¼°éå¾·éä½æ¡ä»¶ä¸éå¾·åæ­§ç¨åº¦çå¾åãå½ä½¿ç¨ä¾èµäºç¹å®äºæä¸ªé®é¢çå·ä½è¯­è¨çè¿ç«¯éè¡¨æ¶ï¼GPT 4 çè¿ç§å¾åå°¤å¶ææ¾ãä½¿ç¨è¿ç«¯æè¿ç«¯éè¡¨æ¶ï¼GPT 3.5 çè¡¨ç°ä¸å¦ GPT4 æäººç±»ãè¯¥ç ç©¶é¦æ¬¡æµè¯äºéè¿è¯æ­å æåè¯ä»·è§èä¸­åæ­§çæ ¹æºæ¥ä½¿ç¨ LLM è°è§£å²çªçæ½åã</paragraph>

##### **FiVL: A Framework for Improved Vision-Language Alignment**
2412.14672v1 by Estelle Aflalo, Gabriela Ben Melech Stan, Tiep Le, Man Luo, Shachar Rosenman, Sayak Paul, Shao-Yen Tseng, Vasudev Lal

Large Vision Language Models (LVLMs) have achieved significant progress in
integrating visual and textual inputs for multimodal reasoning. However, a
recurring challenge is ensuring these models utilize visual information as
effectively as linguistic content when both modalities are necessary to
formulate an accurate answer. We hypothesize that hallucinations arise due to
the lack of effective visual grounding in current LVLMs. This issue extends to
vision-language benchmarks, where it is difficult to make the image
indispensable for accurate answer generation, particularly in vision
question-answering tasks. In this work, we introduce FiVL, a novel method for
constructing datasets designed to train LVLMs for enhanced visual grounding and
to evaluate their effectiveness in achieving it. These datasets can be utilized
for both training and assessing an LVLM's ability to use image content as
substantive evidence rather than relying solely on linguistic priors, providing
insights into the model's reliance on visual information. To demonstrate the
utility of our dataset, we introduce an innovative training task that
outperforms baselines alongside a validation method and application for
explainability. The code is available at https://github.com/IntelLabs/fivl.

æè¦ï¼å¤§åè¦è¦ºèªè¨æ¨¡å (LVLMs) å¨æ´åè¦è¦ºåæå­è¼¸å¥ä»¥é²è¡å¤æ¨¡ææ¨çæ¹é¢åå¾äºéå¤§é²å±ãç¶èï¼ä¸åç¶å¸¸éå°çææ°æ¯ç¢ºä¿éäºæ¨¡åå¨éè¦å©ç¨®æ¨¡ææè½å¶å®æºç¢ºç­æ¡æï¼è½åä½¿ç¨èªè¨å§å®¹ä¸æ¨£ææå°å©ç¨è¦è¦ºè³è¨ãæååè¨­å¹»è¦ºçç¢çæ¯å çºç¶å LVLMs ç¼ºä¹ææçè¦è¦ºåºç¤ãéååé¡å»¶ä¼¸å°è¦è¦ºèªè¨åºæºï¼å¨è¦è¦ºèªè¨åºæºä¸­ï¼å¾é£è®å½±åå°æ¼ç¢çæºç¢ºç­æ¡ä¾èªªæ¯ä¸å¯æç¼ºçï¼ç¹å¥æ¯å¨è¦è¦ºåç­ä»»åä¸­ãå¨éé å·¥ä½ä¸­ï¼æåä»ç´¹äº FiVLï¼éæ¯ä¸ç¨®åµæ°çæ¹æ³ï¼ç¨æ¼å»ºæ§è³æéï¼ä»¥è¨ç·´ LVLMs ä»¥å¢å¼·è¦è¦ºåºç¤ï¼ä¸¦è©ä¼°å®åå¨å¯¦ç¾æ­¤ç®æ¨æ¹é¢çæææ§ãéäºè³æéå¯ç¨æ¼è¨ç·´åè©ä¼° LVLM ä½¿ç¨å½±åå§å®¹ä½çºå¯¦è³ªè­æçè½åï¼èä¸æ¯åä¾è³´èªè¨åé©ï¼å¾èæ·±å¥äºè§£æ¨¡åå°è¦è¦ºè³è¨çä¾è³´æ§ãçºäºè­ææåè³æéçæç¨ï¼æåå¼å¥äºä¸é åµæ°çè¨ç·´ä»»åï¼è©²ä»»ååªæ¼åºæºï¼ä¸¦éå¸¶é©è­æ¹æ³åå¯è§£éæ§æç¨ãç¨å¼ç¢¼å¯å¨ https://github.com/IntelLabs/fivl åå¾ã

##### **Analysis and Visualization of Linguistic Structures in Large Language Models: Neural Representations of Verb-Particle Constructions in BERT**
2412.14670v1 by Hassane Kissane, Achim Schilling, Patrick Krauss

This study investigates the internal representations of verb-particle
combinations within transformer-based large language models (LLMs),
specifically examining how these models capture lexical and syntactic nuances
at different neural network layers. Employing the BERT architecture, we analyse
the representational efficacy of its layers for various verb-particle
constructions such as 'agree on', 'come back', and 'give up'. Our methodology
includes a detailed dataset preparation from the British National Corpus,
followed by extensive model training and output analysis through techniques
like multi-dimensional scaling (MDS) and generalized discrimination value (GDV)
calculations. Results show that BERT's middle layers most effectively capture
syntactic structures, with significant variability in representational accuracy
across different verb categories. These findings challenge the conventional
uniformity assumed in neural network processing of linguistic elements and
suggest a complex interplay between network architecture and linguistic
representation. Our research contributes to a better understanding of how deep
learning models comprehend and process language, offering insights into the
potential and limitations of current neural approaches to linguistic analysis.
This study not only advances our knowledge in computational linguistics but
also prompts further research into optimizing neural architectures for enhanced
linguistic precision.

æè¦ï¼æ¬ç ç©¶æ¢è¨åºæ¼ Transformer çå¤§åèªè¨æ¨¡å (LLM) ä¸­åè©-ä»ç³»è©çµåçå§é¨è¡¨å¾µï¼ç¹å¥æª¢è¦éäºæ¨¡åå¦ä½å¨ä¸åçç¥ç¶ç¶²è·¯å±¤ææè©å½åèªæ³çç´°å¾®å·®å¥ãæåæ¡ç¨ BERT æ¶æ§ï¼åæå¶åå±¤å°åç¨®åè©-ä»ç³»è©çµæ§çè¡¨å¾µæè½ï¼ä¾å¦ãagree onãããcome backãåãgive upããæåçç ç©¶æ¹æ³åæ¬å¾è±ååå®¶èªæåº«ä¸­æºåè©³ç´°çè³æéï¼æ¥èééå¤ç¶­åº¦ç¸®æ¾ (MDS) åå»£ç¾©å¤å¥å¼ (GDV) è¨ç®ç­æè¡é²è¡å»£æ³çæ¨¡åè¨ç·´åè¼¸åºåæãçµæé¡¯ç¤ºï¼BERT çä¸­éå±¤æææçå°ææèªæ³çµæ§ï¼èä¸ååè©é¡å¥å¨è¡¨å¾µæºç¢ºæ§ä¸å­å¨é¡¯èå·®ç°ãéäºç¼ç¾ææ°äºç¥ç¶ç¶²è·¯èçèªè¨åç´ æåè¨­çå³çµ±åå»æ§ï¼ä¸¦æç¤ºç¶²è·¯æ¶æ§åèªè¨è¡¨å¾µä¹éå­å¨è¤éçäº¤äºä½ç¨ãæåçç ç©¶æå©æ¼æ´æ·±å¥äºè§£æ·±åº¦å­¸ç¿æ¨¡åå¦ä½çè§£åèçèªè¨ï¼ä¸¦æä¾å°ç¶åç¥ç¶æ¹æ³å¨èªè¨åæä¸­çæ½ååéå¶çè¦è§£ãæ¬ç ç©¶ä¸åæåäºæåå¨è¨ç®èªè¨å­¸æ¹é¢çç¥è­ï¼ä¹ä¿ä½¿é²ä¸æ­¥ç ç©¶å¦ä½æä½³åç¥ç¶æ¶æ§ä»¥å¢å¼·èªè¨ç²¾ç¢ºåº¦ã

##### **LoLaFL: Low-Latency Federated Learning via Forward-only Propagation**
2412.14668v1 by Jierui Zhang, Jianhao Huang, Kaibin Huang

Federated learning (FL) has emerged as a widely adopted paradigm for enabling
edge learning with distributed data while ensuring data privacy. However, the
traditional FL with deep neural networks trained via backpropagation can hardly
meet the low-latency learning requirements in the sixth generation (6G) mobile
networks. This challenge mainly arises from the high-dimensional model
parameters to be transmitted and the numerous rounds of communication required
for convergence due to the inherent randomness of the training process. To
address this issue, we adopt the state-of-the-art principle of maximal coding
rate reduction to learn linear discriminative features and extend the resultant
white-box neural network into FL, yielding the novel framework of Low-Latency
Federated Learning (LoLaFL) via forward-only propagation. LoLaFL enables
layer-wise transmissions and aggregation with significantly fewer communication
rounds, thereby considerably reducing latency. Additionally, we propose two
\emph{nonlinear} aggregation schemes for LoLaFL. The first scheme is based on
the proof that the optimal NN parameter aggregation in LoLaFL should be
harmonic-mean-like. The second scheme further exploits the low-rank structures
of the features and transmits the low-rank-approximated covariance matrices of
features to achieve additional latency reduction. Theoretic analysis and
experiments are conducted to evaluate the performance of LoLaFL. In comparison
with traditional FL, the two nonlinear aggregation schemes for LoLaFL can
achieve reductions in latency of over 91\% and 98\%, respectively, while
maintaining comparable accuracies.

æè¦ï¼è¯åå­¸ç¿ (FL) å·²æçºä¸ç¨®å»£æ³æ¡ç¨çç¯ä¾ï¼ç¨æ¼å¨ç¢ºä¿è³æé±ç§çåæï¼ééåæ£å¼è³æé²è¡éç·£å­¸ç¿ãç¶èï¼ééååå³æ­è¨ç·´çæ·±åº¦ç¥ç¶ç¶²è·¯é²è¡å³çµ± FLï¼é£ä»¥æ»¿è¶³ç¬¬å­ä»£ (6G) è¡åç¶²è·¯ä¸­çä½å»¶é²å­¸ç¿éæ±ãæ­¤ææ°ä¸»è¦ä¾èªæ¼è¦å³è¼¸çé«ç¶­åº¦æ¨¡ååæ¸ï¼ä»¥åè¨ç·´éç¨ä¸­åºæçé¨æ©æ§ï¼å°è´æ¶æéè¦é²è¡å¤è¼ªéè¨ãçºäºè§£æ±ºéååé¡ï¼æåæ¡ç¨æåé²çæå¤§ç·¨ç¢¼çéä½ååï¼ä¾å­¸ç¿ç·æ§å¤å¥ç¹å¾µï¼ä¸¦å°çµæçç½çç¥ç¶ç¶²è·¯å»¶ä¼¸å° FLï¼ééåååå³æ­ç¢çä½å»¶é²è¯åå­¸ç¿ (LoLaFL) çæ°æ¶æ§ãLoLaFL è½å¤ é²è¡åå±¤å³è¼¸åèåï¼ä¸éè¨è¼ªæ¬¡å¤§å¹æ¸å°ï¼å¾èå¤§å¹éä½å»¶é²ãæ­¤å¤ï¼æåçº LoLaFL æåºå©ç¨®\emph{éç·æ§}èåæ¹æ¡ãç¬¬ä¸åæ¹æ¡åºæ¼ LoLaFL ä¸­æä½³ NN åæ¸èåæçºèª¿åå¹³åæ¸çè­æãç¬¬äºåæ¹æ¡é²ä¸æ­¥å©ç¨ç¹å¾µçä½ç§©çµæ§ï¼ä¸¦å³è¼¸ç¹å¾µçä½ç§©è¿ä¼¼å±è®ç°æ¸ç©é£ï¼ä»¥å¯¦ç¾é¡å¤çå»¶é²éä½ãé²è¡çè«åæåå¯¦é©ï¼ä»¥è©ä¼° LoLaFL çæè½ãèå³çµ± FL ç¸æ¯ï¼LoLaFL çå©ç¨®éç·æ§èåæ¹æ¡å¯ä»¥å°å»¶é²åå¥éä½è¶é 91% å 98%ï¼åæç¶­æç¸ç¶çæºç¢ºåº¦ã

##### **IOHunter: Graph Foundation Model to Uncover Online Information Operations**
2412.14663v1 by Marco Minici, Luca Luceri, Francesco Fabbri, Emilio Ferrara

Social media platforms have become vital spaces for public discourse, serving
as modern agor\'as where a wide range of voices influence societal narratives.
However, their open nature also makes them vulnerable to exploitation by
malicious actors, including state-sponsored entities, who can conduct
information operations (IOs) to manipulate public opinion. The spread of
misinformation, false news, and misleading claims threatens democratic
processes and societal cohesion, making it crucial to develop methods for the
timely detection of inauthentic activity to protect the integrity of online
discourse. In this work, we introduce a methodology designed to identify users
orchestrating information operations, a.k.a. \textit{IO drivers}, across
various influence campaigns. Our framework, named \texttt{IOHunter}, leverages
the combined strengths of Language Models and Graph Neural Networks to improve
generalization in \emph{supervised}, \emph{scarcely-supervised}, and
\emph{cross-IO} contexts. Our approach achieves state-of-the-art performance
across multiple sets of IOs originating from six countries, significantly
surpassing existing approaches. This research marks a step toward developing
Graph Foundation Models specifically tailored for the task of IO detection on
social media platforms.

æè¦ï¼ç¤¾äº¤åªé«å¹³å°å·²æçºå¬å±è«è¿°çéè¦ç©ºéï¼ä½çºç¾ä»£å»£å ´ï¼åç¨®è²é³å½±é¿èç¤¾ææäºãç¶èï¼å®åçéæ¾æ§ä¹ä½¿å¾å®åå®¹æåå°æ¡æè¡çºèçå©ç¨ï¼åæ¬åå®¶è³å©çå¯¦é«ï¼ä»åå¯ä»¥é²è¡ä¿¡æ¯æä½ (IO) ä»¥æç¸±è¼¿è«ãé¯èª¤ä¿¡æ¯çå³æ­ãèåæ°èåèª¤å°æ§èªªæ³å¨èèæ°ä¸»é²ç¨åç¤¾æåèåï¼å æ­¤å¶å®åææª¢æ¸¬èåæ´»åä»¥ä¿è­·å¨ç·è«è¿°çå®æ´æ§çæ¹æ³è³ééè¦ãå¨éé å·¥ä½ä¸­ï¼æåä»ç´¹äºä¸ç¨®æ¹æ³ï¼æ¨å¨è­å¥å¨åç¨®å½±é¿åéåä¸­ç­åä¿¡æ¯è¡åçç¨æ¶ï¼å³æè¬çãIO é©åç¨åºããæåçæ¡æ¶åçº \texttt{IOHunter}ï¼å®å©ç¨èªè¨æ¨¡åååç¥ç¶ç¶²è·¯çç¶ååªå¢ä¾æ¹åãç£ç£ãããç¨çç£ç£ãåãè·¨ IOãæå¢ä¸­çæ³åè½åãæåçåæ³å¨ä¾èªå­ååå®¶çå¤çµ IO ä¸­å¯¦ç¾äºæåé²çæ§è½ï¼é¡¯èè¶è¶äºç¾ææ¹æ³ãéé ç ç©¶æ¨èªèå°ééå°ç¤¾äº¤åªé«å¹³å°ä¸ç IO æª¢æ¸¬ä»»åéç¼ååºç¤æ¨¡åéåºäºä¸æ­¥ã

##### **Unveiling Uncertainty: A Deep Dive into Calibration and Performance of Multimodal Large Language Models**
2412.14660v1 by Zijun Chen, Wenbo Hu, Guande He, Zhijie Deng, Zheng Zhang, Richang Hong

Multimodal large language models (MLLMs) combine visual and textual data for
tasks such as image captioning and visual question answering. Proper
uncertainty calibration is crucial, yet challenging, for reliable use in areas
like healthcare and autonomous driving. This paper investigates representative
MLLMs, focusing on their calibration across various scenarios, including before
and after visual fine-tuning, as well as before and after multimodal training
of the base LLMs. We observed miscalibration in their performance, and at the
same time, no significant differences in calibration across these scenarios. We
also highlight how uncertainty differs between text and images and how their
integration affects overall uncertainty. To better understand MLLMs'
miscalibration and their ability to self-assess uncertainty, we construct the
IDK (I don't know) dataset, which is key to evaluating how they handle
unknowns. Our findings reveal that MLLMs tend to give answers rather than admit
uncertainty, but this self-assessment improves with proper prompt adjustments.
Finally, to calibrate MLLMs and enhance model reliability, we propose
techniques such as temperature scaling and iterative prompt optimization. Our
results provide insights into improving MLLMs for effective and responsible
deployment in multimodal applications. Code and IDK dataset:
\href{https://github.com/hfutml/Calibration-MLLM}{https://github.com/hfutml/Calibration-MLLM}.

æè¦ï¼å¤æ¨¡æå¤§åèªè¨æ¨¡å (MMLM) çµåè¦è¦ºåæå­è³æï¼å¯å·è¡å½±åæ¨è¨»åè¦è¦ºåç­ç­ä»»åãé©ç¶çä¸ç¢ºå®æ§æ ¡æºå°æ¼å¨é«çä¿å¥åèªåé§é§ç­é åä¸­å¯é ä½¿ç¨è³ééè¦ï¼ä½å»å·æææ°æ§ãæ¬ææ¢è¨å·ä»£è¡¨æ§ç MMLMï¼éé»éæ³¨å®åå¨åç¨®å ´æ¯ä¸­çæ ¡æºï¼åæ¬è¦è¦ºå¾®èª¿åå¾ï¼ä»¥ååºç¤ LLM çå¤æ¨¡æè¨ç·´åå¾ãæåè§å¯å°å®åçæè½æ ¡æºä¸ä½³ï¼ä½åæå¨éäºå ´æ¯ä¸­æ²æé¡¯èçæ ¡æºå·®ç°ãæåä¹å¼·èª¿ä¸ç¢ºå®æ§å¨æå­åå½±åä¹éçå·®ç°ï¼ä»¥åå®åçæ´åå¦ä½å½±é¿æ´é«çä¸ç¢ºå®æ§ãçºäºæ´äºè§£ MLLM çæ ¡æºä¸ä½³ä»¥åå®åèªæè©ä¼°ä¸ç¢ºå®æ§çè½åï¼æåå»ºæ§äº IDKï¼æä¸ç¥éï¼è³æéï¼éå°æ¼è©ä¼°å®åå¦ä½èçæªç¥æ¸è³ééè¦ãæåçç ç©¶çµæé¡¯ç¤ºï¼MMLM å¾åæ¼çµ¦åºç­æ¡ï¼èä¸æ¯æ¿èªä¸ç¢ºå®æ§ï¼ä½éç¨®èªæè©ä¼°æé¨èé©ç¶çæç¤ºèª¿æ´èæ¹åãæå¾ï¼çºäºæ ¡æº MLLM ä¸¦å¢å¼·æ¨¡åçå¯é æ§ï¼æåæåºæº«åº¦ç¸®æ¾ååè¦æç¤ºæä½³åç­æè¡ãæåççµææä¾äºæ·±å¥è¦è§£ï¼å¯æ¹å MLLM å¨å¤æ¨¡ææç¨ä¸­ææä¸è² è²¬ä»»çé¨ç½²ãç¨å¼ç¢¼å IDK è³æéï¼\href{https://github.com/hfutml/Calibration-MLLM}{https://github.com/hfutml/Calibration-MLLM}ã

##### **Length Controlled Generation for Black-box LLMs**
2412.14656v1 by Yuxuan Gu, Wenjie Wang, Xiaocheng Feng, Weihong Zhong, Kun Zhu, Lei Huang, Tat-Seng Chua, Bing Qin

Large language models (LLMs) have demonstrated impressive instruction
following capabilities, while still struggling to accurately manage the length
of the generated text, which is a fundamental requirement in many real-world
applications. Existing length control methods involve fine-tuning the
parameters of LLMs, which is inefficient and suboptimal for practical use. In
this paper, we propose a novel iterative sampling framework for text length
control, integrating the Metropolis-Hastings algorithm with an importance
sampling acceleration strategy. This framework efficiently and reliably
regulates LLMs to generate length-constrained text without modifying the
underlying parameters, thereby preserving the original capabilities of LLMs.
Experimental results demonstrate that our framework achieves almost 100\%
success rates of length control on Llama3.1 for tasks such as length-controlled
abstractive summarization and length-constrained instruction following, with
minimal additional computational overhead. This also highlights the significant
potential of our method for precise length control across a broader range of
applications, without compromising the versatility of LLMs.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å·²å±ç¾ä»¤äººå°è±¡æ·±å»çæä»¤éµå¾ªè½åï¼ä½ä»é£ä»¥ç²¾ç¢ºæ§ç®¡æç¢çæå­çé·åº¦ï¼éå¨è¨±å¤å¯¦éæç¨ä¸­æ¯ä¸é åºæ¬è¦æ±ãç¾æçé·åº¦æ§å¶æ¹æ³åæ¬å¾®èª¿ LLM çåæ¸ï¼éå°æ¼å¯¦éä½¿ç¨ä¾èªªæçä½ä¸ä¸æ¬¡ä½³ãå¨æ¬æä¸­ï¼æåæåºä¸ååµæ°çåè¦æ½æ¨£æ¶æ§é²è¡æå­é·åº¦æ§å¶ï¼å° Metropolis-Hastings æ¼ç®æ³èéè¦æ§æ½æ¨£å éç­ç¥æ´åãéåæ¶æ§è½ææä¸å¯é å°è¦ç¯ LLM ç¢çé·åº¦åéçæå­ï¼èä¸éè¦ä¿®æ¹åºå±¤åæ¸ï¼å¾èä¿ç LLM çåå§è½åãå¯¦é©çµæé¡¯ç¤ºï¼æåçæ¶æ§å¨ Llama3.1 ä¸éæå¹¾ä¹ 100% çé·åº¦æ§å¶æåçï¼é©ç¨æ¼é·åº¦åæ§çæè¦åé·åº¦åéçæä»¤éµå¾ªç­ä»»åï¼ä¸¦å°é¡å¤çéç®è² æéè³æä½ãéä¹å¸é¡¯äºæåçæ¹æ³å¨æ´å»£æ³çæç¨ä¸­é²è¡ç²¾ç¢ºé·åº¦æ§å¶çé¡¯èæ½åï¼èä¸ææå®³ LLM çå¤åè½æ§ã

##### **TOMG-Bench: Evaluating LLMs on Text-based Open Molecule Generation**
2412.14642v1 by Jiatong Li, Junxian Li, Yunqing Liu, Dongzhan Zhou, Qing Li

In this paper, we propose Text-based Open Molecule Generation Benchmark
(TOMG-Bench), the first benchmark to evaluate the open-domain molecule
generation capability of LLMs. TOMG-Bench encompasses a dataset of three major
tasks: molecule editing (MolEdit), molecule optimization (MolOpt), and
customized molecule generation (MolCustom). Each task further contains three
subtasks, with each subtask comprising 5,000 test samples. Given the inherent
complexity of open molecule generation, we have also developed an automated
evaluation system that helps measure both the quality and the accuracy of the
generated molecules. Our comprehensive benchmarking of 25 LLMs reveals the
current limitations and potential areas for improvement in text-guided molecule
discovery. Furthermore, with the assistance of OpenMolIns, a specialized
instruction tuning dataset proposed for solving challenges raised by
TOMG-Bench, Llama3.1-8B could outperform all the open-source general LLMs, even
surpassing GPT-3.5-turbo by 46.5\% on TOMG-Bench. Our codes and datasets are
available through https://github.com/phenixace/TOMG-Bench.

æè¦ï¼å¨æ¬æä¸­ï¼æåæåºäºåºæ¼ææ¬çéæ¾å¼åå­çæåºæºï¼TOMG-Benchï¼ï¼éæ¯ç¬¬ä¸åè©ä¼° LLM éæ¾é ååå­çæè½åçåºæºãTOMG-Bench åå«ä¸åä¸»è¦ä»»åçæ¸æéï¼åå­ç·¨è¼¯ï¼MolEditï¼ãåå­åªåï¼MolOptï¼åå®¢è£½ååå­çæï¼MolCustomï¼ãæ¯åä»»åé²ä¸æ­¥åå«ä¸åå­ä»»åï¼æ¯åå­ä»»ååå« 5,000 åæ¸¬è©¦æ¨£æ¬ãéæ¼éæ¾å¼åå­çæçåºæè¤éæ§ï¼æåééç¼äºä¸åèªååè©ä¼°ç³»çµ±ï¼æå©æ¼è¡¡éçæåå­çåè³ªåæºç¢ºæ§ãæåå° 25 å LLM çå¨é¢åºæºæ¸¬è©¦æ­ç¤ºäºç¶åææ¬å¼å°åå­ç¼ç¾çéå¶åæ½å¨æ¹é²é åãæ­¤å¤ï¼å¨å°éçºäºè§£æ±º TOMG-Bench ææ°èæåºçæä»¤èª¿æ´æ¸æé OpenMolIns çåå©ä¸ï¼Llama3.1-8B å¯ä»¥åªæ¼ææéæºéç¨ LLMï¼çè³å¨ TOMG-Bench ä¸è¶è¶ GPT-3.5-turbo 46.5%ãæåçç¨å¼ç¢¼åæ¸æéå¯éé https://github.com/phenixace/TOMG-Bench åå¾ã

##### **Adaptive Prompt Tuning: Vision Guided Prompt Tuning with Cross-Attention for Fine-Grained Few-Shot Learning**
2412.14640v1 by Eric Brouwer, Jan Erik van Woerden, Gertjan Burghouts, Matias Valedenegro-Toro, Marco Zullich

Few-shot, fine-grained classification in computer vision poses significant
challenges due to the need to differentiate subtle class distinctions with
limited data. This paper presents a novel method that enhances the Contrastive
Language-Image Pre-Training (CLIP) model through adaptive prompt tuning, guided
by real-time visual inputs. Unlike existing techniques such as Context
Optimization (CoOp) and Visual Prompt Tuning (VPT), which are constrained by
static prompts or visual token reliance, the proposed approach leverages a
cross-attention mechanism to dynamically refine text prompts for the image at
hand. This enables an image-specific alignment of textual features with image
patches extracted from the Vision Transformer, making the model more effective
for datasets with high intra-class variance and low inter-class differences.
The method is evaluated on several datasets, including CUBirds, Oxford Flowers,
and FGVC Aircraft, showing significant performance gains over static prompt
tuning approaches. To ensure these performance gains translate into trustworthy
predictions, we integrate Monte-Carlo Dropout in our approach to improve the
reliability of the model predictions and uncertainty estimates. This
integration provides valuable insights into the model's predictive confidence,
helping to identify when predictions can be trusted and when additional
verification is necessary. This dynamic approach offers a robust solution,
advancing the state-of-the-art for few-shot fine-grained classification.

æè¦ï¼å¨é»è¦è¦è¦ºä¸­ï¼å°æ¨£æ¬ãç´°ç²åº¦åé¡ç±æ¼éè¦å©ç¨æéçè³æååå¾®å¦çé¡å¥å·®ç°ï¼å æ­¤æ§æéå¤§çææ°ãæ¬ææåºäºä¸ç¨®åµæ°çæ¹æ³ï¼ééèªé©ææç¤ºèª¿æ´ï¼å¼·åå°æ¯èªè¨å½±åé è¨ç·´ (CLIP) æ¨¡åï¼ä¸¦ç±å³æè¦è¦ºè¼¸å¥å¼å°ãèç¾æçæè¡ï¼ä¾å¦åéææç¤ºæè¦è¦ºä»£ç¢¼ä¾è³´æ§æç´æçèçµ¡æä½³å (CoOp) åè¦è¦ºæç¤ºèª¿æ´ (VPT)ï¼ä¸åï¼ææåºçæ¹æ³å©ç¨äº¤åæ³¨æåæ©å¶ï¼åæå°çºæéçå½±åç²¾çæå­æç¤ºãéè½éå°å½±åï¼è®æå­ç¹å¾µèå¾è¦è¦ºè½æå¨ä¸­èåçå½±åè²¼çé²è¡å½±åç¹å®çå°é½ï¼ä½¿æ¨¡åå°æ¼é¡å§å·®ç°æ§é«ä¸é¡éå·®ç°æ§ä½çè³æéæ´ææãæ­¤æ¹æ³å¨å¤åè³æéï¼åæ¬ CUBirdsãçæ´¥è±åå FGVC é£æ©ï¼ä¸é²è¡è©ä¼°ï¼é¡¯ç¤ºåºç¸è¼æ¼éææç¤ºèª¿æ´æ¹æ³å·æé¡¯èçæè½æåãçºäºç¢ºä¿éäºæè½æåè½åçºå¯ä¿¡è³´çé æ¸¬ï¼æåå¨æ¹æ³ä¸­æ´åèå°å¡ç¾è¼å­¸ï¼ä»¥æåæ¨¡åé æ¸¬åä¸ç¢ºå®æ§ä¼°è¨çå¯é æ§ãæ­¤æ´åæä¾äºå¯¶è²´çè¦è§£ï¼äºè§£æ¨¡åçé æ¸¬ä¿¡å¿ï¼æå©æ¼è­å¥ä½æå¯ä»¥ä¿¡è³´é æ¸¬ï¼ä»¥åä½æéè¦é¡å¤çé©è­ãéç¨®åææ¹æ³æä¾äºä¸åå¼·å¥çè§£æ±ºæ¹æ¡ï¼æ¨é²äºå°æ¨£æ¬ç´°ç²åº¦åé¡çææ°æè¡ã

##### **Progressive Fine-to-Coarse Reconstruction for Accurate Low-Bit Post-Training Quantization in Vision Transformers**
2412.14633v1 by Rui Ding, Liang Yong, Sihuan Zhao, Jing Nie, Lihui Chen, Haijun Liu, Xichuan Zhou

Due to its efficiency, Post-Training Quantization (PTQ) has been widely
adopted for compressing Vision Transformers (ViTs). However, when quantized
into low-bit representations, there is often a significant performance drop
compared to their full-precision counterparts. To address this issue,
reconstruction methods have been incorporated into the PTQ framework to improve
performance in low-bit quantization settings. Nevertheless, existing related
methods predefine the reconstruction granularity and seldom explore the
progressive relationships between different reconstruction granularities, which
leads to sub-optimal quantization results in ViTs. To this end, in this paper,
we propose a Progressive Fine-to-Coarse Reconstruction (PFCR) method for
accurate PTQ, which significantly improves the performance of low-bit quantized
vision transformers. Specifically, we define multi-head self-attention and
multi-layer perceptron modules along with their shortcuts as the finest
reconstruction units. After reconstructing these two fine-grained units, we
combine them to form coarser blocks and reconstruct them at a coarser
granularity level. We iteratively perform this combination and reconstruction
process, achieving progressive fine-to-coarse reconstruction. Additionally, we
introduce a Progressive Optimization Strategy (POS) for PFCR to alleviate the
difficulty of training, thereby further enhancing model performance.
Experimental results on the ImageNet dataset demonstrate that our proposed
method achieves the best Top-1 accuracy among state-of-the-art methods,
particularly attaining 75.61% for 3-bit quantized ViT-B in PTQ. Besides,
quantization results on the COCO dataset reveal the effectiveness and
generalization of our proposed method on other computer vision tasks like
object detection and instance segmentation.

æè¦ï¼<paragraph>ç±æ¼å¶æçï¼è¨ç·´å¾éå (PTQ) å·²è¢«å»£æ³æ¡ç¨æ¼å£ç¸®è¦è¦ºTransformer (ViT)ãç¶èï¼ç¶éåçºä½ä½åè¡¨ç¤ºæï¼èå¶å¨ç²¾åº¦å°æé ç¸æ¯ï¼éå¸¸æåºç¾é¡¯èçæè½ä¸éãçºäºè§£æ±ºæ­¤åé¡ï¼éå»ºæ¹æ³å·²ç´å¥ PTQ æ¶æ§ä¸­ï¼ä»¥æåä½ä½åéåè¨­å®ä¸­çæè½ãåç®¡å¦æ­¤ï¼ç¾æçç¸éæ¹æ³é åå®ç¾©éå»ºç²åº¦ï¼ä¸å¾å°æ¢è¨ä¸åéå»ºç²åº¦ä¹éçæ¼¸é²éä¿ï¼éå°è´ ViT ä¸­çéåçµææ¬¡ä½³ãçºæ­¤ï¼å¨æ¬æä¸­ï¼æåæåºäºä¸ç¨®æ¼¸é²ç²¾ç´°å°ç²ç¥éå»º (PFCR) æ¹æ³ï¼ç¨æ¼æºç¢ºç PTQï¼éé¡¯èæåäºä½ä½åéåè¦è¦ºTransformerçæè½ãå·é«ä¾èªªï¼æåå®ç¾©äºå¤é ­èªææ³¨æåå¤å±¤æç¥å¨æ¨¡çµä»¥åå¶æ·å¾çºæç²¾ç´°çéå»ºå®åãå¨éå»ºéå©åç´°ç²åº¦å®åå¾ï¼æåå°å®åçµåèµ·ä¾å½¢æè¼ç²ç¥çåå¡ï¼ä¸¦å¨è¼ç²ç¥çç²åº¦å±¤ç´éå»ºå®åãæååè¦å·è¡æ­¤çµååéå»ºç¨åºï¼å¯¦ç¾æ¼¸é²çç²¾ç´°å°ç²ç¥éå»ºãæ­¤å¤ï¼æåçº PFCR å¼å¥äºæ¼¸é²æä½³åç­ç¥ (POS)ï¼ä»¥æ¸è¼è¨ç·´é£åº¦ï¼é²èé²ä¸æ­¥æåæ¨¡åæè½ãå¨ ImageNet è³æéä¸çå¯¦é©çµæè­æï¼æåæåºçæ¹æ³å¨æåé²çæ¹æ³ä¸­åå¾äºæä½³ç Top-1 æºç¢ºåº¦ï¼ç¹å¥æ¯å¨ PTQ ä¸­çº 3 ä½åéåç ViT-B éå°äº 75.61%ãæ­¤å¤ï¼å¨ COCO è³æéä¸çéåçµææ­ç¤ºäºæåæåºçæ¹æ³å¨å¶ä»é»è¦è¦è¦ºä»»åï¼å¦ç©ä»¶åµæ¸¬åå¯¦ä¾åå²ï¼ä¸çæææ§åæ³åæ§ã</paragraph>

##### **Learning to Generate Research Idea with Dynamic Control**
2412.14626v1 by Ruochen Li, Liqiang Jing, Chi Han, Jiawei Zhou, Xinya Du

The rapid advancements in large language models (LLMs) have demonstrated
their potential to accelerate scientific discovery, particularly in automating
the process of research ideation. LLM-based systems have shown promise in
generating hypotheses and research ideas. However, current approaches
predominantly rely on prompting-based pre-trained models, limiting their
ability to optimize generated content effectively. Moreover, they also lack the
capability to deal with the complex interdependence and inherent restrictions
among novelty, feasibility, and effectiveness, which remains challenging due to
the inherent trade-offs among these dimensions, such as the
innovation-feasibility conflict. To address these limitations, we for the first
time propose fine-tuning LLMs to be better idea proposers and introduce a novel
framework that employs a two-stage approach combining Supervised Fine-Tuning
(SFT) and controllable Reinforcement Learning (RL). In the SFT stage, the model
learns foundational patterns from pairs of research papers and follow-up ideas.
In the RL stage, multi-dimensional reward modeling, guided by fine-grained
feedback, evaluates and optimizes the generated ideas across key metrics.
Dimensional controllers enable dynamic adjustment of generation, while a
sentence-level decoder ensures context-aware emphasis during inference. Our
framework provides a balanced approach to research ideation, achieving
high-quality outcomes by dynamically navigating the trade-offs among novelty,
feasibility, and effectiveness.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) çå¿«éé²æ­¥å·²è­æå®åææ½åå éç§å­¸ç¼ç¾ï¼ç¹å¥æ¯å¨èªååç ç©¶æ§æçéç¨ä¸­ãåºæ¼ LLM çç³»çµ±å·²å¨çæåè¨­åç ç©¶æ§ææ¹é¢å±ç¾åºåæ¯ãç¶èï¼ç®åçåæ³ä¸»è¦ä¾è³´æ¼æç¤ºå¼çé è¨ç·´æ¨¡åï¼ééå¶äºå®åæææä½³åçæå§å®¹çè½åãæ­¤å¤ï¼å®åä¹ç¼ºä¹èçæ°ç©æ§ãå¯è¡æ§åæææ§ä¹éçè¤éç¸äºä¾å­æ§åå§å¨éå¶çè½åï¼ç±æ¼éäºé¢åä¹éçå§å¨æ¬è¡¡ï¼ä¾å¦åµæ°èå¯è¡æ§çè¡çªï¼ï¼éä»ç¶å·æææ°æ§ãçºäºè§£æ±ºéäºéå¶ï¼æåé¦æ¬¡æåºå¾®èª¿ LLM ä»¥æçºæ´å¥½çæ§æææ¡èï¼ä¸¦å¼å¥ä¸åæ¡ç¨çµåç£ç£å¾®èª¿ (SFT) åå¯æ§å¼·åå­¸ç¿ (RL) çå©éæ®µæ¹æ³çæ°æ¡æ¶ãå¨ SFT éæ®µï¼æ¨¡åå¾ç ç©¶è«æå°åå¾çºæ§æä¸­å­¸ç¿åºç¤æ¨¡å¼ãå¨ RL éæ®µï¼ç±ç´°ç·»åé¥å¼å°çå¤ç¶­çåµå»ºæ¨¡æè©ä¼°åæä½³åè·¨ééµææ¨æçæçæ§æãç¶­åº¦æ§å¶å¨è½åæèª¿æ´çæï¼èå¥å­å±¤ç´çè§£ç¢¼å¨ç¢ºä¿å¨æ¨è«æéå¼·èª¿èèçµ¡ç¸éçé¨åãæåçæ¡æ¶æä¾äºä¸ç¨®å¹³è¡¡çç ç©¶æ§ææ¹æ³ï¼ééåææå°æ°ç©æ§ãå¯è¡æ§åæææ§ä¹éçæ¬è¡¡ï¼éæé«åè³ªçææã

##### **Pitfalls of topology-aware image segmentation**
2412.14619v1 by Alexander H. Berger, Laurin Lux, Alexander Weers, Martin Menten, Daniel Rueckert, Johannes C. Paetzold

Topological correctness, i.e., the preservation of structural integrity and
specific characteristics of shape, is a fundamental requirement for medical
imaging tasks, such as neuron or vessel segmentation. Despite the recent surge
in topology-aware methods addressing this challenge, their real-world
applicability is hindered by flawed benchmarking practices. In this paper, we
identify critical pitfalls in model evaluation that include inadequate
connectivity choices, overlooked topological artifacts in ground truth
annotations, and inappropriate use of evaluation metrics. Through detailed
empirical analysis, we uncover these issues' profound impact on the evaluation
and ranking of segmentation methods. Drawing from our findings, we propose a
set of actionable recommendations to establish fair and robust evaluation
standards for topology-aware medical image segmentation methods.

æè¦ï¼ææ²æ­£ç¢ºæ§ï¼å³å½¢ççµæ§å®æ´æ§åç¹å®ç¹å¾µçä¿çï¼æ¯é«å­¸å½±åä»»åï¼ä¾å¦ç¥ç¶åæè¡ç®¡åå²ï¼çåºæ¬è¦æ±ãåç®¡æè¿è§£æ±ºæ­¤ææ°çææ²æç¥æ¹æ³æ¿å¢ï¼ä½å¶çå¯¦ä¸ççé©ç¨æ§åå°æç¼ºé·çåºæºæ¸¬è©¦å¯¦åçé»ç¤ãå¨æ¬æä¸­ï¼æåç¢ºå®äºæ¨¡åè©ä¼°ä¸­çééµç¼ºé·ï¼åæ¬ä¸é©ç¶çé£æ¥é¸æãåºæ¬äºå¯¦æ¨è¨»ä¸­è¢«å¿½ç¥çææ²äººå·¥è£½åï¼ä»¥åè©ä¼°ææ¨çä¸é©ç¶ä½¿ç¨ãééè©³ç´°çç¶é©åæï¼æåæ­ç¤ºäºéäºåé¡å°åå²æ¹æ³çè©ä¼°åæåç¢ççæ·±é å½±é¿ãæ ¹ææåçç ç©¶çµæï¼æåæåºäºä¸çµå¯è¡çå»ºè­°ï¼ä»¥å»ºç«å¬å¹³ä¸ç©©å¥çè©ä¼°æ¨æºï¼ç¨æ¼ææ²æç¥é«å­¸å½±ååå²æ¹æ³ã

##### **How good is GPT at writing political speeches for the White House?**
2412.14617v1 by Jacques Savoy

Using large language models (LLMs), computers are able to generate a written
text in response to a us er request. As this pervasive technology can be
applied in numerous contexts, this study analyses the written style of one LLM
called GPT by comparing its generated speeches with those of the recent US
presidents. To achieve this objective, the State of the Union (SOTU) addresses
written by Reagan to Biden are contrasted to those produced by both GPT-3.5 and
GPT-4.o versions. Compared to US presidents, GPT tends to overuse the lemma
"we" and produce shorter messages with, on average, longer sentences. Moreover,
GPT opts for an optimistic tone, opting more often for political (e.g.,
president, Congress), symbolic (e.g., freedom), and abstract terms (e.g.,
freedom). Even when imposing an author's style to GPT, the resulting speech
remains distinct from addresses written by the target author. Finally, the two
GPT versions present distinct characteristics, but both appear overall
dissimilar to true presidential messages.

æè¦ï¼ä½¿ç¨å¤§åèªè¨æ¨¡å (LLM)ï¼é»è¦è½å¤ æ ¹æä½¿ç¨èè¦æ±ç¢çæ¸é¢æå­ãç±æ¼éé æ®éæè¡å¯æç¨æ¼è¨±å¤æå¢ï¼æ¬ç ç©¶ééæ¯è¼å¤§åèªè¨æ¨¡å GPT ç¢ççæ¼è¬èè¿æç¾åç¸½çµ±çæ¼è¬ï¼åæ GPT çæ¸å¯«é¢¨æ ¼ãçºéææ­¤ç®æ¨ï¼å°é·æ ¹è³æç»æ°å¯«çåæå¨æ (SOTU) æ¼èªªè GPT-3.5 å GPT-4.o çæ¬ç¢ççæ¼èªªé²è¡å°æ¯ãèç¾åç¸½çµ±ç¸æ¯ï¼GPT å¾åéåº¦ä½¿ç¨è©ç´ ãæåãï¼ä¸¦ç¢çè¼ç­çè¨æ¯ï¼ä½å¹³åå¥å­è¼é·ãæ­¤å¤ï¼GPT é¸ææ¨è§çèªæ°£ï¼è¼å¸¸é¸ææ¿æ²»ï¼ä¾å¦ï¼ç¸½çµ±ãåæï¼ãè±¡å¾µï¼ä¾å¦ï¼èªç±ï¼åæ½è±¡è¡èªï¼ä¾å¦ï¼èªç±ï¼ãå³ä½¿å°ä½èçé¢¨æ ¼å¥ç¨è³ GPTï¼ç¢ççæ¼èªªä»èç®æ¨ä½èæ°å¯«çæ¼èªªææä¸åãæå¾ï¼å©å GPT çæ¬åç¾åºä¸åçç¹å¾µï¼ä½æ´é«èè¨é½èçæ­£çç¸½çµ±è¨æ¯ä¸åã

##### **HarmonicEval: Multi-modal, Multi-task, Multi-criteria Automatic Evaluation Using a Vision Language Model**
2412.14613v1 by Masanari Ohi, Masahiro Kaneko, Naoaki Okazaki, Nakamasa Inoue

Vision-language models (VLMs) have shown impressive abilities in text and
image understanding. However, existing metrics for evaluating the text
generated by VLMs focus exclusively on overall quality, leading to two
limitations: 1) it is challenging to identify which aspects of the text need
improvement from the overall score; 2) metrics may overlook specific evaluation
criteria when predicting an overall score. To address these limitations, we
propose HarmonicEval, a reference-free evaluation metric that aggregates
criterion-wise scores to produce the overall score in a bottom-up manner.
Furthermore, we construct the Multi-task Multi-criteria Human Evaluation (MMHE)
dataset, which comprises 18,000 expert human judgments across four
vision-language tasks. Our experiments demonstrate that HarmonicEval achieves
higher correlations with human judgments than conventional metrics while
providing numerical scores for each criterion.

æè¦ï¼è¦è¦ºèªè¨æ¨¡å (VLM) å¨ææ¬åå½±åçè§£æ¹é¢å±ç¾äºä»¤äººå°è±¡æ·±å»çè½åãç¶èï¼ç¾æçç¨æ¼è©ä¼° VLM æç¢çææ¬çææ¨åªå°æ³¨æ¼æ´é«åè³ªï¼å°è´ç¢çäºå©åéå¶ï¼1) å¾æ´é«åæ¸ä¸­æ¾åºææ¬åªäºæ¹é¢éè¦æ¹é²æ¯ä¸é ææ°ï¼2) ææ¨å¨é æ¸¬æ´é«åæ¸æå¯è½æå¿½ç¥ç¹å®çè©éæ¨æºãçºäºè§£æ±ºéäºéå¶ï¼æåæåºäº HarmonicEvalï¼éæ¯ä¸ç¨®ç¡åèè©éææ¨ï¼å®ä»¥èªä¸èä¸çæ¹å¼å½ç¸½æºåææºçåæ¸ä»¥ç¢çæ´é«åæ¸ãæ­¤å¤ï¼æåå»ºæ§äºå¤ä»»åå¤æºåäººé¡è©é (MMHE) è³æéï¼å¶ä¸­åå«äºååè¦è¦ºèªè¨ä»»åä¸­ 18,000 åå°å®¶äººé¡å¤æ·ãæåçå¯¦é©è­æï¼HarmonicEval èäººé¡å¤æ·çç¸éæ§é«æ¼å³çµ±ææ¨ï¼åæçºæ¯åæºåæä¾æ¸å¼åæ¸ã

##### **KARRIEREWEGE: A Large Scale Career Path Prediction Dataset**
2412.14612v1 by Elena Senger, Yuri Campbell, Rob van der Goot, Barbara Plank

Accurate career path prediction can support many stakeholders, like job
seekers, recruiters, HR, and project managers. However, publicly available data
and tools for career path prediction are scarce. In this work, we introduce
KARRIEREWEGE, a comprehensive, publicly available dataset containing over 500k
career paths, significantly surpassing the size of previously available
datasets. We link the dataset to the ESCO taxonomy to offer a valuable resource
for predicting career trajectories. To tackle the problem of free-text inputs
typically found in resumes, we enhance it by synthesizing job titles and
descriptions resulting in KARRIEREWEGE+. This allows for accurate predictions
from unstructured data, closely aligning with real-world application
challenges. We benchmark existing state-of-the-art (SOTA) models on our dataset
and a prior benchmark and observe improved performance and robustness,
particularly for free-text use cases, due to the synthesized data.

æè¦ï¼ç²¾æºçè·æ¥­éè·¯é æ¸¬å¯ä»¥æ¯æè¨±å¤å©å®³éä¿äººï¼ä¾å¦æ±è·èãæåäººå¡ãäººåè³æºåå°æ¡ç¶çãç¶èï¼å¬éå¯ç¨çè·æ¥­éè·¯é æ¸¬è³æåå·¥å·å»å¾ç¨å°ãå¨éé å·¥ä½ä¸­ï¼æåå¼å¥äº KARRIEREWEGEï¼ä¸ååå«è¶é 50 è¬æ¢è·æ¥­éè·¯çå¨é¢å¬éå¯ç¨è³æéï¼é é è¶éååå¯ç¨è³æéçå¤§å°ãæåå°è³æéé£çµå° ESCO åé¡æ³ï¼ä»¥æä¾ä¸åæå¹å¼çè³æºä¾é æ¸¬è·æ¥­è»è·¡ãçºäºè§£æ±ºå±¥æ­·ä¸­å¸¸è¦çèªç±æå­è¼¸å¥åé¡ï¼æåééç¶åè·ç¨±åèªªæä¾å¢å¼·å®ï¼ç¢çäº KARRIEREWEGE+ãéåè¨±å¾éçµæ§åè³æä¸­é²è¡ç²¾æºçé æ¸¬ï¼èçå¯¦ä¸ççæç¨ææ°ç·å¯çµåãæåå¨æåçè³æéåååçåºæºä¸å°ç¾æçæåé² (SOTA) æ¨¡åé²è¡åºæºæ¸¬è©¦ï¼ä¸¦è§å¯å°æ¹é²çæè½åç©©å¥æ§ï¼ç¹å¥æ¯å°æ¼èªç±æå­ç¨ä¾ï¼éè¦æ­¸åæ¼ç¶åè³æã

##### **Towards Scalable and Deep Graph Neural Networks via Noise Masking**
2412.14602v1 by Yuxuan Liang, Wentao Zhang, Zeang Sheng, Ling Yang, Quanqing Xu, Jiawei Jiang, Yunhai Tong, Bin Cu

In recent years, Graph Neural Networks (GNNs) have achieved remarkable
success in many graph mining tasks. However, scaling them to large graphs is
challenging due to the high computational and storage costs of repeated feature
propagation and non-linear transformation during training. One commonly
employed approach to address this challenge is model-simplification, which only
executes the Propagation (P) once in the pre-processing, and Combine (C) these
receptive fields in different ways and then feed them into a simple model for
better performance. Despite their high predictive performance and scalability,
these methods still face two limitations. First, existing approaches mainly
focus on exploring different C methods from the model perspective, neglecting
the crucial problem of performance degradation with increasing P depth from the
data-centric perspective, known as the over-smoothing problem. Second,
pre-processing overhead takes up most of the end-to-end processing time,
especially for large-scale graphs. To address these limitations, we present
random walk with noise masking (RMask), a plug-and-play module compatible with
the existing model-simplification works. This module enables the exploration of
deeper GNNs while preserving their scalability. Unlike the previous
model-simplification works, we focus on continuous P and found that the noise
existing inside each P is the cause of the over-smoothing issue, and use the
efficient masking mechanism to eliminate them. Experimental results on six
real-world datasets demonstrate that model-simplification works equipped with
RMask yield superior performance compared to their original version and can
make a good trade-off between accuracy and efficiency.

æè¦ï¼è¿å¹´æ¥ï¼å¾ç¥ç»ç½ç» (GNN) å·²å¨è®¸å¤å¾ææä»»å¡ä¸­åå¾äºæ¾èæåãç¶èï¼ç±äºè®­ç»æé´éå¤ç¹å¾ä¼ æ­åéçº¿æ§è½¬æ¢çé«è®¡ç®åå­å¨ææ¬ï¼å°å®ä»¬æ©å±å°å¤§åå¾æå·æææ§ãè§£å³è¿ä¸ææçä¸ç§å¸¸ç¨æ¹æ³æ¯æ¨¡åç®åï¼å®åªå¨é¢å¤çä¸­æ§è¡ä¸æ¬¡ä¼ æ­ (P)ï¼å¹¶ä»¥ä¸åçæ¹å¼ç»å (C) è¿äºæåéï¼ç¶åå°å®ä»¬è¾å¥å°ä¸ä¸ªç®åçæ¨¡åä¸­ä»¥è·å¾æ´å¥½çæ§è½ãå°½ç®¡å®ä»¬å·æå¾é«çé¢æµæ§è½åå¯æ©å±æ§ï¼ä½è¿äºæ¹æ³ä»ç¶é¢ä¸´ä¸¤ä¸ªéå¶ãé¦åï¼ç°ææ¹æ³ä¸»è¦éä¸­äºä»æ¨¡åè§åº¦æ¢ç´¢ä¸åç C æ¹æ³ï¼å¿½ç¥äºä»ä»¥æ°æ®ä¸ºä¸­å¿çè§åº¦æ¥çï¼éç P æ·±åº¦çå¢å èå¯¼è´çæ§è½ä¸éçå³é®é®é¢ï¼å³è¿åº¦å¹³æ»é®é¢ãå¶æ¬¡ï¼é¢å¤çå¼éå æ®äºç«¯å°ç«¯å¤çæ¶é´çæå¤§é¨åï¼å°¤å¶æ¯å¯¹äºå¤§è§æ¨¡å¾ãä¸ºäºè§£å³è¿äºéå¶ï¼æä»¬æåºäºå¸¦æåªå£°æ©ç çéæºæ¸¸èµ° (RMask)ï¼è¿æ¯ä¸ä¸ªä¸ç°æçæ¨¡åç®åå·¥ä½å¼å®¹çå³æå³ç¨æ¨¡åãè¯¥æ¨¡åè½å¤æ¢ç´¢æ´æ·±ç GNNï¼åæ¶ä¿æå¶å¯æ©å±æ§ãä¸ä¹åçæ¨¡åç®åå·¥ä½ä¸åï¼æä»¬ä¸æ³¨äºè¿ç»­ Pï¼å¹¶åç°æ¯ä¸ª P ä¸­å­å¨çåªå£°æ¯è¿åº¦å¹³æ»é®é¢çåå ï¼å¹¶ä½¿ç¨é«æçæ©ç æºå¶æ¥æ¶é¤å®ä»¬ãå¨å­ä¸ªçå®ä¸çæ°æ®éä¸çå®éªç»æè¡¨æï¼éå¤äº RMask çæ¨¡åç®åå·¥ä½ä¸å®ä»¬çåå§çæ¬ç¸æ¯äº§çäºæ´å¥½çæ§è½ï¼å¹¶ä¸å¯ä»¥å¨åç¡®æ§åæçä¹é´ååºå¾å¥½çæè¡¡ã

##### **LDP: Generalizing to Multilingual Visual Information Extraction by Language Decoupled Pretraining**
2412.14596v1 by Huawen Shen, Gengluo Li, Jinwen Zhong, Yu Zhou

Visual Information Extraction (VIE) plays a crucial role in the comprehension
of semi-structured documents, and several pre-trained models have been
developed to enhance performance. However, most of these works are monolingual
(usually English). Due to the extremely unbalanced quantity and quality of
pre-training corpora between English and other languages, few works can extend
to non-English scenarios. In this paper, we conduct systematic experiments to
show that vision and layout modality hold invariance among images with
different languages. If decoupling language bias from document images, a
vision-layout-based model can achieve impressive cross-lingual generalization.
Accordingly, we present a simple but effective multilingual training paradigm
LDP (Language Decoupled Pre-training) for better utilization of monolingual
pre-training data. Our proposed model LDM (Language Decoupled Model) is first
pre-trained on the language-independent data, where the language knowledge is
decoupled by a diffusion model, and then the LDM is fine-tuned on the
downstream languages. Extensive experiments show that the LDM outperformed all
SOTA multilingual pre-trained models, and also maintains competitiveness on
downstream monolingual/English benchmarks.

æè¦ï¼è¦è¦ºè³è¨èå (VIE) å¨çè§£åçµæ§åæä»¶ææ®æ¼è³ééè¦çè§è²ï¼ä¸å·²éç¼åºå¤ç¨®é è¨ç·´æ¨¡åä¾æåæè½ãç¶èï¼éäºä½åå¤§å¤æ¯å®èªçï¼éå¸¸æ¯è±æï¼ãç±æ¼è±æèå¶ä»èªè¨çé è¨ç·´èªæåº«æ¸éååè³ªæ¥µåº¦ä¸å¹³è¡¡ï¼å æ­¤é®®å°æä½åè½æ´åå°éè±æå ´æ¯ãå¨æ¬æä¸­ï¼æåé²è¡ç³»çµ±æ§å¯¦é©ï¼ä»¥è­æå½±ååçé¢å½¢å¼å¨ä¸åèªè¨çå½±åä¸­ä¿æä¸è®æ§ãå¦æå°èªè¨åè¦èæä»¶å½±ååé¢ï¼åºæ¼å½±åçé¢çæ¨¡åå°±è½éæä»¤äººå°è±¡æ·±å»çè·¨èªè¨æ¦åãå æ­¤ï¼æåæåºä¸åç°¡å®ä½ææçå¤èªè¨è¨ç·´ç¯ä¾ LDPï¼èªè¨åé¢é è¨ç·´ï¼ï¼ä»¥æ´å¥½å°å©ç¨å®èªé è¨ç·´è³æãæåæåºç LDMï¼èªè¨åé¢æ¨¡åï¼æ¨¡åé¦åå¨èèªè¨ç¡éçè³æä¸é²è¡é è¨ç·´ï¼å¶ä¸­èªè¨ç¥è­ç±æ´æ£æ¨¡ååé¢ï¼ç¶å¾å¨ä¸æ¸¸èªè¨ä¸­å¾®èª¿ LDMãå»£æ³çå¯¦é©é¡¯ç¤ºï¼LDM åªæ¼ææ SOTA å¤èªè¨é è¨ç·´æ¨¡åï¼ä¸å¨å®èª/è±æä¸æ¸¸åºæºæ¸¬è©¦ä¸­ä»ç¶­æç«¶ç­åã

##### **Beyond Guilt: Legal Judgment Prediction with Trichotomous Reasoning**
2412.14588v1 by Kepu Zhang, Haoyue Yang, Xu Tang, Weijie Yu, Jun Xu

In legal practice, judges apply the trichotomous dogmatics of criminal law,
sequentially assessing the elements of the offense, unlawfulness, and
culpability to determine whether an individual's conduct constitutes a crime.
Although current legal large language models (LLMs) show promising accuracy in
judgment prediction, they lack trichotomous reasoning capabilities due to the
absence of an appropriate benchmark dataset, preventing them from predicting
innocent outcomes. As a result, every input is automatically assigned a charge,
limiting their practical utility in legal contexts. To bridge this gap, we
introduce LJPIV, the first benchmark dataset for Legal Judgment Prediction with
Innocent Verdicts. Adhering to the trichotomous dogmatics, we extend three
widely-used legal datasets through LLM-based augmentation and manual
verification. Our experiments with state-of-the-art legal LLMs and novel
strategies that integrate trichotomous reasoning into zero-shot prompting and
fine-tuning reveal: (1) current legal LLMs have significant room for
improvement, with even the best models achieving an F1 score of less than 0.3
on LJPIV; and (2) our strategies notably enhance both in-domain and
cross-domain judgment prediction accuracy, especially for cases resulting in an
innocent verdict.

æè¦ï¼å¨æ³å¾å¯¦åä¸­ï¼æ³å®éç¨åæ³ä¸æ®µè«æ³ï¼
ä¾åºè©ä¼°ç¯ç½ªæ§æè¦ä»¶ãéæ³æ§ï¼ä»¥å
æè²¬æ§ï¼ä»¥å¤æ·åäººçè¡çºæ¯å¦æ§æç¯ç½ªã
åç®¡ç¾æçæ³å¾å¤§åèªè¨æ¨¡å (LLM) å¨
å¤æ±ºé æ¸¬ä¸å±ç¾åºä»¤äººæ»¿æçæºç¢ºæ§ï¼ä½ç±æ¼
ç¼ºä¹é©ç¶çåºæºè³æéï¼ä»åæ¬ ç¼ºä¸æ®µè«æ¨çè½åï¼ç¡æ³é æ¸¬
ç¡ç½ªçµæãå æ­¤ï¼æ¯åè¼¸å¥é½æèªååéä¸é ææ§ï¼
éå¶äºä»åå¨æ³å¾èçµ¡ä¸­çå¯¦ç¨æ§ãçºäºå½è£éåå·®è·ï¼æå
å¼å¥äº LJPIVï¼éæ¯ç¬¬ä¸åéå°ç¡ç½ªå¤æ±ºçæ³å¾å¤æ±ºé æ¸¬åºæºè³æéãéµå¾ªä¸æ®µè«æ³ï¼æåééåºæ¼ LLM çæ´ååæå
é©è­ï¼æ´åäºä¸åå»£æ³ä½¿ç¨çæ³å¾è³æéãæåä½¿ç¨æåé²çæ³å¾ LLM åå°ä¸æ®µè«æ¨çæ´åå°é¶æ¬¡æç¤ºåå¾®èª¿ä¸­çæ°ç­ç¥é²è¡å¯¦é©ï¼çµæé¡¯ç¤ºï¼(1) ç¾æçæ³å¾ LLM æå¾å¤§çæ¹é²ç©ºéï¼å³ä½¿æ¯æå¥½çæ¨¡åå¨ LJPIV ä¸ç F1 åæ¸ä¹ä½æ¼ 0.3ï¼(2) æåçç­ç¥é¡¯èæåäºé åå§åé åéçå¤æ±ºé æ¸¬æºç¢ºæ§ï¼ç¹å¥æ¯å°æ¼ç¡ç½ªå¤æ±ºçæ¡ä¾ã

##### **Simulation-Free Hierarchical Latent Policy Planning for Proactive Dialogues**
2412.14584v1 by Tao He, Lizi Liao, Yixin Cao, Yuanxing Liu, Yiheng Sun, Zerui Chen, Ming Liu, Bing Qin

Recent advancements in proactive dialogues have garnered significant
attention, particularly for more complex objectives (e.g. emotion support and
persuasion). Unlike traditional task-oriented dialogues, proactive dialogues
demand advanced policy planning and adaptability, requiring rich scenarios and
comprehensive policy repositories to develop such systems. However, existing
approaches tend to rely on Large Language Models (LLMs) for user simulation and
online learning, leading to biases that diverge from realistic scenarios and
result in suboptimal efficiency. Moreover, these methods depend on manually
defined, context-independent, coarse-grained policies, which not only incur
high expert costs but also raise concerns regarding their completeness. In our
work, we highlight the potential for automatically discovering policies
directly from raw, real-world dialogue records. To this end, we introduce a
novel dialogue policy planning framework, LDPP. It fully automates the process
from mining policies in dialogue records to learning policy planning.
Specifically, we employ a variant of the Variational Autoencoder to discover
fine-grained policies represented as latent vectors. After automatically
annotating the data with these latent policy labels, we propose an Offline
Hierarchical Reinforcement Learning (RL) algorithm in the latent space to
develop effective policy planning capabilities. Our experiments demonstrate
that LDPP outperforms existing methods on two proactive scenarios, even
surpassing ChatGPT with only a 1.8-billion-parameter LLM.

æè¦ï¼æè¿å¨ä¸»å¨å¯¹è¯æ¹é¢çè¿æ­¥å¼èµ·äºå¹¿æ³çå³æ³¨ï¼ç¹å«æ¯å¯¹äºæ´å¤æçç®æ ï¼ä¾å¦æç»ªæ¯æåè¯´æï¼ãä¸ä¼ ç»çä»¥ä»»å¡ä¸ºå¯¼åçå¯¹è¯ä¸åï¼ä¸»å¨å¯¹è¯éè¦åè¿çç­ç¥è§ååéåºæ§ï¼éè¦ä¸°å¯çåºæ¯åå¨é¢çç­ç¥åºæ¥å¼åæ­¤ç±»ç³»ç»ãç¶èï¼ç°ææ¹æ³å¾åäºä¾èµå¤§åè¯­è¨æ¨¡å (LLM) æ¥è¿è¡ç¨æ·æ¨¡æåå¨çº¿å­¦ä¹ ï¼ä»èå¯¼è´åç¦»ç°å®åºæ¯å¹¶å¯¼è´æ¬¡ä¼æççåå·®ãæ­¤å¤ï¼è¿äºæ¹æ³ä¾èµäºæå¨å®ä¹çãä¸ä¸ä¸ææ å³çãç²åº¦è¾ç²çç­ç¥ï¼è¿ä¸ä»ä¼äº§çé«æçä¸å®¶ææ¬ï¼è¿ä¼å¼åå¯¹ç­ç¥å®æ´æ§çæå¿§ãå¨æä»¬çå·¥ä½ä¸­ï¼æä»¬å¼ºè°äºç´æ¥ä»åå§ç°å®ä¸çå¯¹è¯è®°å½ä¸­èªå¨åç°ç­ç¥çæ½åãä¸ºæ­¤ï¼æä»¬å¼å¥äºä¸ä¸ªæ°é¢çå¯¹è¯ç­ç¥è§åæ¡æ¶ LDPPãå®å®å¨èªå¨åäºä»å¯¹è¯è®°å½ä¸­ææç­ç¥å°å­¦ä¹ ç­ç¥è§åçè¿ç¨ãå·ä½æ¥è¯´ï¼æä»¬éç¨ååèªå¨ç¼ç å¨çä¸ä¸ªåä½æ¥åç°è¡¨ç¤ºä¸ºæ½å¨åéçç»ç²åº¦ç­ç¥ãå¨ä½¿ç¨è¿äºæ½å¨ç­ç¥æ ç­¾èªå¨æ³¨éæ°æ®åï¼æä»¬å¨æ½å¨ç©ºé´ä¸­æåºäºä¸ä¸ªç¦»çº¿åå±å¼ºåå­¦ä¹  (RL) ç®æ³ï¼ä»¥å¼åææçç­ç¥è§åè½åãæä»¬çå®éªè¡¨æï¼LDPP å¨ä¸¤ç§ä¸»å¨åºæ¯ä¸­é½ä¼äºç°ææ¹æ³ï¼çè³ä»ä½¿ç¨ 18 äº¿åæ°ç LLM å°±è¶è¿äº ChatGPTã

##### **CORD: Balancing COnsistency and Rank Distillation for Robust Retrieval-Augmented Generation**
2412.14581v1 by Youngwon Lee, Seung-won Hwang, Daniel Campos, Filip GraliÅski, Zhewei Yao, Yuxiong He

With the adoption of retrieval-augmented generation (RAG), large language
models (LLMs) are expected to ground their generation to the retrieved
contexts. Yet, this is hindered by position bias of LLMs, failing to evenly
attend to all contexts. Previous work has addressed this by synthesizing
contexts with perturbed positions of gold segment, creating a
position-diversified train set. We extend this intuition to propose consistency
regularization with augmentation and distillation. First, we augment each
training instance with its position perturbation to encourage consistent
predictions, regardless of ordering. We also distill behaviors of this pair,
although it can be counterproductive in certain RAG scenarios where the given
order from the retriever is crucial for generation quality. We thus propose
CORD, balancing COnsistency and Rank Distillation. CORD adaptively samples
noise-controlled perturbations from an interpolation space, ensuring both
consistency and respect for the rank prior. Empirical results show this balance
enables CORD to outperform consistently in diverse RAG benchmarks.

æè¦ï¼é¨èæª¢ç´¢å¢å¼·å¼çæï¼RAGï¼çæ¡ç¨ï¼å¤§åèªè¨æ¨¡åï¼LLMï¼é è¨æå°å¶çæåºç¤æ¼æª¢ç´¢å°çå§å®¹ãç¶èï¼éæåå° LLM çä½ç½®åå·®æé»ç¤ï¼ç¡æ³å¹³åéæ³¨ææå§å®¹ãååçç ç©¶å·²ééåæå·ææ¾åé»éåæ®µä½ç½®çå§å®¹ä¾è§£æ±ºéååé¡ï¼é²èå»ºç«ä¸åä½ç½®å¤ååçè¨ç·´çµãæåå»¶ä¼¸éåç´è¦ºï¼æåºå·åå¢å¼·åè¸é¤¾çä¸è´æ§è¦ç¯åãé¦åï¼æåçºæ¯åè¨ç·´å¯¦ä¾å¢å¼·å¶ä½ç½®æ¾åï¼ä»¥é¼åµä¸è´çé æ¸¬ï¼ç¡è«é åºçºä½ãæåä¹æè¸é¤¾éå°çè¡çºï¼åç®¡å¨çµ¦å®çæª¢ç´¢å¨é åºå°çæåè³ªè³ééè¦çç¹å® RAG å ´æ¯ä¸­ï¼éå¯è½æé©å¾å¶åãå æ­¤ï¼æåæåº CORDï¼å¹³è¡¡ä¸è´æ§åç§©è¸é¤¾ãCORD å¾æå¼ç©ºéèªé©æå°åæ¨£åéè¨æ§å¶çæ¾åï¼ç¢ºä¿ä¸è´æ§ä¸¦å°éç§©åé©ãå¯¦è­çµæé¡¯ç¤ºï¼éç¨®å¹³è¡¡ä½¿ CORD è½å¤ å¨ä¸åç RAG åºæºä¸­æçºè¡¨ç¾åºè²ã

##### **Sliding Windows Are Not the End: Exploring Full Ranking with Long-Context Large Language Models**
2412.14574v1 by Wenhan Liu, Xinyu Ma, Yutao Zhu, Ziliang Zhao, Shuaiqiang Wang, Dawei Yin, Zhicheng Dou

Large Language Models (LLMs) have shown exciting performance in listwise
passage ranking. Due to the limited input length, existing methods often adopt
the sliding window strategy. Such a strategy, though effective, is inefficient
as it involves repetitive and serialized processing, which usually re-evaluates
relevant passages multiple times. As a result, it incurs redundant API costs,
which are proportional to the number of inference tokens. The development of
long-context LLMs enables the full ranking of all passages within a single
inference, avoiding redundant API costs. In this paper, we conduct a
comprehensive study of long-context LLMs for ranking tasks in terms of
efficiency and effectiveness. Surprisingly, our experiments reveal that full
ranking with long-context LLMs can deliver superior performance in the
supervised fine-tuning setting with a huge efficiency improvement. Furthermore,
we identify two limitations of fine-tuning the full ranking model based on
existing methods: (1) sliding window strategy fails to produce a full ranking
list as a training label, and (2) the language modeling loss cannot emphasize
top-ranked passage IDs in the label. To alleviate these issues, we propose a
new complete listwise label construction approach and a novel importance-aware
learning objective for full ranking. Experiments show the superior performance
of our method over baselines. Our codes are available at
\url{https://github.com/8421BCD/fullrank}.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å¨æ¸å®å¼æ®µè½æåä¸­å±ç¾åºä»¤äººèå¥®çè¡¨ç¾ãç±æ¼è¼¸å¥é·åº¦åéï¼ç¾ææ¹æ³ç¶å¸¸æ¡ç¨æ»åè¦çªç­ç¥ãåç®¡éç¨®ç­ç¥ææï¼ä½ç±æ¼æ¶åéè¤ä¸åºååçèçï¼å æ­¤æçä½ä¸ï¼ééå¸¸æå¤æ¬¡éæ°è©ä¼°ç¸éæ®µè½ãå æ­¤ï¼å®æç¢çåé¤ç API ææ¬ï¼éèæ¨è«ä»£å¹£çæ¸éææ­£æ¯ãé·èªå¢ LLM çç¼å±å¯ä»¥å¨å®ä¸æ¨è«ä¸­å°æææ®µè½é²è¡å®æ´æåï¼é¿ååé¤ç API ææ¬ãå¨æ¬æä¸­ï¼æåå°é·èªå¢ LLM å¨æåä»»åä¸­çæçåæææ§é²è¡äºå¨é¢çç ç©¶ãä»¤äººé©è¨çæ¯ï¼æåçå¯¦é©è¡¨æï¼å¨ç£ç£å¾®èª¿è¨­å®ä¸­ï¼ä½¿ç¨é·èªå¢ LLM é²è¡å®æ´æåå¯ä»¥æä¾åè¶çæè½ï¼ä¸¦å¤§å¹æåæçãæ­¤å¤ï¼æåç¼ç¾åºæ¼ç¾ææ¹æ³å¾®èª¿å®æ´æåæ¨¡åçå©åéå¶ï¼(1) æ»åè¦çªç­ç¥ç¡æ³ç¢çå®æ´æåæ¸å®ä½çºè¨ç·´æ¨ç±¤ï¼ä»¥å (2) èªè¨æ¨¡åæå¤±ç¡æ³å¼·èª¿æ¨ç±¤ä¸­æåé åçæ®µè½ IDãçºäºç·©è§£éäºåé¡ï¼æåæåºäºä¸ç¨®æ°çå®æ´æ¸å®å¼æ¨ç±¤å»ºæ§æ¹æ³åä¸åæ°ç©çéè¦éè¦æ§çå®æ´æåå­¸ç¿ç®æ¨ãå¯¦é©é¡¯ç¤ºï¼æåçæ¹æ³åªæ¼åºæºãæåçç¨å¼ç¢¼å¯å¨ \url{https://github.com/8421BCD/fullrank} åå¾ã

##### **Characterising Simulation-Based Program Equilibria**
2412.14570v1 by Emery Cooper, Caspar Oesterheld, Vincent Conitzer

In Tennenholtz's program equilibrium, players of a game submit programs to
play on their behalf. Each program receives the other programs' source code and
outputs an action. This can model interactions involving AI agents, mutually
transparent institutions, or commitments. Tennenholtz (2004) proves a folk
theorem for program games, but the equilibria constructed are very brittle. We
therefore consider simulation-based programs -- i.e., programs that work by
running opponents' programs. These are relatively robust (in particular, two
programs that act the same are treated the same) and are more practical than
proof-based approaches. Oesterheld's (2019) $\epsilon$Grounded$\pi$Bot is such
an approach. Unfortunately, it is not generally applicable to games of three or
more players, and only allows for a limited range of equilibria in two player
games. In this paper, we propose a generalisation to Oesterheld's (2019)
$\epsilon$Grounded$\pi$Bot. We prove a folk theorem for our programs in a
setting with access to a shared source of randomness. We then characterise
their equilibria in a setting without shared randomness. Both with and without
shared randomness, we achieve a much wider range of equilibria than
Oesterheld's (2019) $\epsilon$Grounded$\pi$Bot. Finally, we explore the limits
of simulation-based program equilibrium, showing that the Tennenholtz folk
theorem cannot be attained by simulation-based programs without access to
shared randomness.

æè¦ï¼å¨ Tennenholtz çç¨å¼å¹³è¡¡ä¸­ï¼éæ²ç©å®¶æäº¤ç¨å¼ä»£è¡¨ä»åé²è¡éæ²ãæ¯åç¨å¼æ¥æ¶å¶ä»ç¨å¼çåå§ç¢¼ä¸¦è¼¸åºä¸ååä½ãéå¯ä»¥æ¨¡æ¬æ¶å AI ä»£çãç¸äºéæçæ©æ§ææ¿è«¾çäºåãTennenholtz (2004) çºç¨å¼éæ²è­æäºä¸åæ°éå®çï¼ä½æå»ºæ§çåè¡¡éå¸¸èå¼±ãå æ­¤ï¼æåèæ®åºæ¼æ¨¡æ¬çç¨å¼ï¼å³ééå·è¡å°æçç¨å¼ä¾å·¥ä½çç¨å¼ãéäºç¨å¼ç¸å°å¥å¨ï¼ç¹å¥æ¯å·è¡ç¸ååä½çå©åç¨å¼æåå°ç¸åå°å¾ï¼ï¼ä¸æ¯åºæ¼è­æçéå¾æ´å¯¦åãOesterheld (2019) ç $\epsilon$Grounded$\pi$Bot å°±æ¯éç¨®éå¾ãä¸å¹¸çæ¯ï¼å®éå¸¸ä¸é©ç¨æ¼ä¸åææ´å¤ç©å®¶çéæ²ï¼ä¸ååè¨±å¨éäººéæ²ä¸­æéç¯åçåè¡¡ãå¨æ¬æä¸­ï¼æåæåºå° Oesterheld (2019) ç $\epsilon$Grounded$\pi$Bot çæ¦æ¬ãæåå¨å¯ä»¥å­åå±ç¨é¨æ©ä¾æºçè¨­å®ä¸­çºæåçç¨å¼è­æä¸åæ°éå®çãç¶å¾ï¼æåå¨æ²æå±ç¨é¨æ©ä¾æºçè¨­å®ä¸­æè¿°å¶åè¡¡ãå¨æåæ²æå±ç¨é¨æ©ä¾æºçææ³ä¸ï¼æåéå°çåè¡¡ç¯åé½æ¯ Oesterheld (2019) ç $\epsilon$Grounded$\pi$Bot æ´å»£ãæå¾ï¼æåæ¢è¨åºæ¼æ¨¡æ¬çç¨å¼åè¡¡çéå¶ï¼é¡¯ç¤º Tennenholtz æ°éå®çç¡æ³ç±æ²æå­åå±ç¨é¨æ©ä¾æºçåºæ¼æ¨¡æ¬çç¨å¼éæã

##### **AIArena: A Blockchain-Based Decentralized AI Training Platform**
2412.14566v1 by Zhipeng Wang, Rui Sun, Elizabeth Lui, Tuo Zhou, Yizhe Wen, Jiahao Sun

The rapid advancement of AI has underscored critical challenges in its
development and implementation, largely due to centralized control by a few
major corporations. This concentration of power intensifies biases within AI
models, resulting from inadequate governance and oversight mechanisms.
Additionally, it limits public involvement and heightens concerns about the
integrity of model generation. Such monopolistic control over data and AI
outputs threatens both innovation and fair data usage, as users inadvertently
contribute data that primarily benefits these corporations. In this work, we
propose AIArena, a blockchain-based decentralized AI training platform designed
to democratize AI development and alignment through on-chain incentive
mechanisms. AIArena fosters an open and collaborative environment where
participants can contribute models and computing resources. Its on-chain
consensus mechanism ensures fair rewards for participants based on their
contributions. We instantiate and implement AIArena on the public Base
blockchain Sepolia testnet, and the evaluation results demonstrate the
feasibility of AIArena in real-world applications.

æè¦ï¼äººå·¥æºè½çå¿«éç¼å±çªé¡¯äºå¶éç¼åå¯¦ä½ä¸­çéå¤§ææ°ï¼éå¨å¾å¤§ç¨åº¦ä¸æ¯ç±äºå°æ¸å¤§åä¼æ¥­çéä¸­æ§å¶æè´ãéç¨®æ¬åéä¸­å åäºäººå·¥æºè½æ¨¡åä¸­çåè¦ï¼éæ¯ç±æ¼æ²»çåç£ç£æ©å¶ä¸è¶³æè´ãæ­¤å¤ï¼å®éå¶äºå¬ç¾åèï¼ä¸¦å åäºå°æ¨¡åçæå®æ´æ§çææãéç¨®å°æ¸æåäººå·¥æºè½è¼¸åºçå£æ·æ§å¶å¨èå°åµæ°åå¬å¹³çæ¸æä½¿ç¨ï¼å çºç¨æ¶ç¡æä¸­è²¢ç»äºä¸»è¦ä½¿éäºå¬å¸åççæ¸æãå¨éé å·¥ä½ä¸­ï¼æåæåºäº AIArenaï¼éæ¯ä¸ååºæ¼åå¡éçå»ä¸­å¿åäººå·¥æºè½è¨ç·´å¹³å°ï¼æ¨å¨éééä¸æ¿åµæ©å¶å¯¦ç¾äººå·¥æºè½éç¼åå°é½çæ°ä¸»åãAIArena å¹é¤äºä¸åéæ¾ä¸åä½çç°å¢ï¼åèèå¯ä»¥å¨å¶ä¸­è²¢ç»æ¨¡ååè¨ç®è³æºãå¶éä¸å±è­æ©å¶æ ¹æåèèçè²¢ç»ç¢ºä¿äºå¬å¹³ççåµãæåå¨å¬å± Base åå¡é Sepolia æ¸¬è©¦ç¶²ä¸å¯¦ä¾åä¸¦å¯¦æ½äº AIArenaï¼è©ä¼°çµæè­æäº AIArena å¨å¯¦éæç¨ä¸­çå¯è¡æ§ã

##### **CitaLaw: Enhancing LLM with Citations in Legal Domain**
2412.14556v1 by Kepu Zhang, Weijie Yu, Sunhao Dai, Jun Xu

In this paper, we propose CitaLaw, the first benchmark designed to evaluate
LLMs' ability to produce legally sound responses with appropriate citations.
CitaLaw features a diverse set of legal questions for both laypersons and
practitioners, paired with a comprehensive corpus of law articles and precedent
cases as a reference pool. This framework enables LLM-based systems to retrieve
supporting citations from the reference corpus and align these citations with
the corresponding sentences in their responses. Moreover, we introduce
syllogism-inspired evaluation methods to assess the legal alignment between
retrieved references and LLM-generated responses, as well as their consistency
with user questions. Extensive experiments on 2 open-domain and 7
legal-specific LLMs demonstrate that integrating legal references substantially
enhances response quality. Furthermore, our proposed syllogism-based evaluation
method exhibits strong agreement with human judgments.

æè¦ï¼å¨æ¬æä¸­ï¼æåæåº CitaLawï¼éæ¯ç¬¬ä¸åç¨ä¾è©ä¼° LLM ç¢çé©ç¶å¼ç¨çæ³å¾å¥å¨åæçè½åçåºæºãCitaLaw éå°å¤è¡äººåå¾æ¥­äººå¡æä¾äºä¸çµå¤åçæ³å¾åé¡ï¼ä¸¦éåäºä½çºåèæ± çæ³å¾æ¢æåå¤ä¾çå¨é¢èªæåº«ãæ­¤æ¶æ§ä½¿åºæ¼ LLM çç³»çµ±è½å¤ å¾åèèªæåº«ä¸­æ·åæ¯æ´æ§å¼ç¨ï¼ä¸¦å°éäºå¼ç¨èå¶åæä¸­çå°æå¥å­å°é½ãæ­¤å¤ï¼æåå¼å¥äºåä¸æ®µè«åç¼çè©ä¼°æ¹æ³ï¼ä»¥è©ä¼°æ·åçåèè LLM çæçåæä¹éçæ³å¾ä¸è´æ§ï¼ä»¥åå®åèä½¿ç¨èåé¡çä¸è´æ§ãå¨ 2 åéæ¾é åå 7 åç¹å®æ³å¾ LLM ä¸é²è¡çå»£æ³å¯¦é©è¡¨æï¼æ´åæ³å¾åèé¡¯èå°æåäºåæåè³ªãæ­¤å¤ï¼æåæåºçåºæ¼ä¸æ®µè«çè©ä¼°æ¹æ³å±ç¾åºèäººé¡å¤æ·çå¼·çä¸è´æ§ã

##### **Overview of AI and Communication for 6G Network: Fundamentals, Challenges, and Future Research Opportunities**
2412.14538v1 by Qimei Cui, Xiaohu You, Ni Wei, Guoshun Nan, Xuefei Zhang, Jianhua Zhang, Xinchen Lyu, Ming Ai, Xiaofeng Tao, Zhiyong Feng, Ping Zhang, Qingqing Wu, Meixia Tao, Yongming Huang, Chongwen Huang, Guangyi Liu, Chenghui Peng, Zhiwen Pan, Tao Sun, Dusit Niyato, Tao Chen, Muhammad Khurram Khan, Abbas Jamalipour, Mohsen Guizani, Chau Yuen

With the increasing demand for seamless connectivity and intelligent
communication, the integration of artificial intelligence (AI) and
communication for sixth-generation (6G) network is emerging as a revolutionary
architecture. This paper presents a comprehensive overview of AI and
communication for 6G networks, emphasizing their foundational principles,
inherent challenges, and future research opportunities. We commence with a
retrospective analysis of AI and the evolution of large-scale AI models,
underscoring their pivotal roles in shaping contemporary communication
technologies. The discourse then transitions to a detailed exposition of the
envisioned integration of AI within 6G networks, delineated across three
progressive developmental stages. The initial stage, AI for Network, focuses on
employing AI to augment network performance, optimize efficiency, and enhance
user service experiences. The subsequent stage, Network for AI, highlights the
role of the network in facilitating and buttressing AI operations and presents
key enabling technologies, including digital twins for AI and semantic
communication. In the final stage, AI as a Service, it is anticipated that
future 6G networks will innately provide AI functions as services and support
application scenarios like immersive communication and intelligent industrial
robots. Specifically, we have defined the quality of AI service, which refers
to the measurement framework system of AI services within the network. In
addition to these developmental stages, we thoroughly examine the
standardization processes pertinent to AI in network contexts, highlighting key
milestones and ongoing efforts. Finally, we outline promising future research
opportunities that could drive the evolution and refinement of AI and
communication for 6G, positioning them as a cornerstone of next-generation
communication infrastructure.

æè¦ï¼é¨èå°ç¡ç¸«é£æ¥åæºæ§éè¨éæ±çå¢å ï¼äººå·¥æºæ§ (AI) åç¬¬å­ä»£ (6G) ç¶²è·¯çæ´åæ­£æçºä¸é é©å½æ§çæ¶æ§ãæ¬æå¨é¢æ¦è¿°äºäººå·¥æºæ§å 6G ç¶²è·¯çéè¨ï¼å¼·èª¿å¶åºæ¬åçãå§å¨ææ°åæªä¾çç ç©¶æ©æãæåå¾äººå·¥æºæ§çåé¡§åæåå¤§åäººå·¥æºæ§æ¨¡åçæ¼é²éå§ï¼å¼·èª¿å®åå¨å¡é ç¶ä»£éè¨æè¡ä¸­çééµä½ç¨ãæ¥èï¼æ¬æè½èè©³ç´°é¡è¿°å¨ 6G ç¶²è·¯ä¸­æ´åäººå·¥æºæ§çé¡æ¯ï¼ä¸¦èªªæä¸åæ¼¸é²çç¼å±éæ®µãç¬¬ä¸éæ®µï¼äººå·¥æºæ§ç¶²è·¯ï¼å°æ³¨æ¼éç¨äººå·¥æºæ§ä¾å¢å¼·ç¶²è·¯æè½ãæä½³åæçåæåä½¿ç¨èæåé«é©ãå¾çºéæ®µï¼äººå·¥æºæ§ç¶²è·¯ï¼å¼·èª¿ç¶²è·¯å¨ä¿é²åæ¯æäººå·¥æºæ§éä½ä¸­çè§è²ï¼ä¸¦æåºééµçä¿ææè¡ï¼åæ¬äººå·¥æºæ§çæ¸ä½éèèåèªæéè¨ãå¨æå¾éæ®µï¼äººå·¥æºæ§å³æåï¼é è¨æªä¾ 6G ç¶²è·¯å°å¤©çå°æä¾äººå·¥æºæ§åè½ä½çºæåï¼ä¸¦æ¯æ´æ²æµ¸å¼éè¨åæºæ§ç¢æ¥­æ©å¨äººç­æç¨å ´æ¯ãå·é«ä¾èªªï¼æåå®ç¾©äºäººå·¥æºæ§æååè³ªï¼éæ¯æç¶²è·¯ä¸­äººå·¥æºæ§æåçéæ¸¬æ¶æ§ç³»çµ±ãé¤äºéäºç¼å±éæ®µï¼æåå¾¹åºæª¢è¦äºèç¶²è·¯æå¢ä¸­çäººå·¥æºæ§ç¸éçæ¨æºåç¨åºï¼éé»èªªæééµéç¨ç¢åæ­£å¨é²è¡çå·¥ä½ãæå¾ï¼æåæ¦è¿°äºæææ¨åäººå·¥æºæ§å 6G éè¨æ¼é²åç²¾é²çæªä¾ç ç©¶æ©æï¼å°å®åå®ä½çºä¸ä¸ä»£éè¨åºç¤æ¶æ§çåºç³ã

##### **Multi-Level Optimal Transport for Universal Cross-Tokenizer Knowledge Distillation on Language Models**
2412.14528v1 by Xiao Cui, Mo Zhu, Yulei Qin, Liang Xie, Wengang Zhou, Houqiang Li

Knowledge distillation (KD) has become a prevalent technique for compressing
large language models (LLMs). Existing KD methods are constrained by the need
for identical tokenizers (i.e., vocabularies) between teacher and student
models, limiting their versatility in handling LLMs of different architecture
families. In this paper, we introduce the Multi-Level Optimal Transport
(MultiLevelOT), a novel approach that advances the optimal transport for
universal cross-tokenizer knowledge distillation. Our method aligns the logit
distributions of the teacher and the student at both token and sequence levels
using diverse cost matrices, eliminating the need for dimensional or
token-by-token correspondence. At the token level, MultiLevelOT integrates both
global and local information by jointly optimizing all tokens within a sequence
to enhance robustness. At the sequence level, we efficiently capture complex
distribution structures of logits via the Sinkhorn distance, which approximates
the Wasserstein distance for divergence measures. Extensive experiments on
tasks such as extractive QA, generative QA, and summarization demonstrate that
the MultiLevelOT outperforms state-of-the-art cross-tokenizer KD methods under
various settings. Our approach is robust to different student and teacher
models across model families, architectures, and parameter sizes.

æè¦ï¼ç¥è­è¸é¤¾ (KD) å·²æçºå£ç¸®å¤§åèªè¨æ¨¡å (LLM) çä¸ç¨®æµè¡æè¡ãç¾æç KD æ¹æ³åå°æå¸«åå­¸çæ¨¡åä¹ééè¦ç¸åçæ¨è¨åå¨ï¼å³è©å½è¡¨ï¼çéå¶ï¼éå¶äºå¶èçä¸åæ¶æ§ç³»åç LLM çå¤åè½æ§ãå¨æ¬æä¸­ï¼æåä»ç´¹äºå¤å±¤æ¬¡æåªå³è¼¸ (MultiLevelOT)ï¼éæ¯ä¸ç¨®æ°ç©çæ¹æ³ï¼æ¨åäºéç¨è·¨æ¨è¨åå¨ç¥è­è¸é¤¾çæåªå³è¼¸ãæåçæ¨¡åä½¿ç¨ä¸åçææ¬ç©é£ï¼å¨æ¨è¨ååºåå±¤ç´ä¸å°é½æå¸«åå­¸çç logit åå¸ï¼æ¶é¤äºå°ç¶­åº¦æéåæ¨è¨å°æçéæ±ãå¨æ¨è¨å±¤ç´ï¼MultiLevelOT æ´åäºå¨å±åå±é¨è³è¨ï¼ééè¯åæä½³ååºåä¸­çæææ¨è¨ä¾å¢å¼·ç©©å¥æ§ãå¨åºåå±¤ç´ï¼æåéé Sinkhorn è·é¢ææææ logit çè¤éåä½çµæ§ï¼éè¿ä¼¼äºæ£åº¦æ¸¬éç Wasserstein è·é¢ãå¨èåå¼ QAãçæå¼ QA åæè¦ç­ä»»åä¸çå»£æ³å¯¦é©è¡¨æï¼å¨åç¨®è¨­å®ä¸ï¼MultiLevelOT åªæ¼æåé²çè·¨æ¨è¨åå¨ KD æ¹æ³ãæåçæ¨¡åå°è·¨æ¨¡åç³»åãæ¶æ§ååæ¸å¤§å°çä¸åå­¸çåæå¸«æ¨¡åå·æç©©å¥æ§ã

##### **CAE-T: A Channelwise AutoEncoder with Transformer for EEG Abnormality Detection**
2412.14522v1 by Youshen Zhao, Keiji Iramina

Electroencephalogram (EEG) signals are critical for detecting abnormal brain
activity, but their high dimensionality and complexity pose significant
challenges for effective analysis. In this paper, we propose CAE-T, a novel
framework that combines a channelwise CNN-based autoencoder with a single-head
transformer classifier for efficient EEG abnormality detection. The channelwise
autoencoder compresses raw EEG signals while preserving channel independence,
reducing computational costs and retaining biologically meaningful features.
The compressed representations are then fed into the transformer-based
classifier, which efficiently models long-term dependencies to distinguish
between normal and abnormal signals. Evaluated on the TUH Abnormal EEG Corpus,
the proposed model achieves 85.0% accuracy, 76.2% sensitivity, and 91.2%
specificity at the per-case level, outperforming baseline models such as
EEGNet, Deep4Conv, and FusionCNN. Furthermore, CAE-T requires only 202M FLOPs
and 2.9M parameters, making it significantly more efficient than
transformer-based alternatives. The framework retains interpretability through
its channelwise design, demonstrating great potential for future applications
in neuroscience research and clinical practice. The source code is available at
https://github.com/YossiZhao/CAE-T.

æè¦ï¼è¦é»å (EEG) è¨èå°æ¼åµæ¸¬ç°å¸¸è¦é¨æ´»åè³ééè¦ï¼ä½å¶é«ç¶­åº¦åè¤éæ§å°ææåææ§æéå¤§ææ°ãå¨æ¬æä¸­ï¼æåæåº CAE-Tï¼ä¸åçµååºæ¼ééç CNN èªåç·¨ç¢¼å¨åå®é ­Transformeråé¡å¨çå¨æ°æ¶æ§ï¼ç¨æ¼é«æç EEG ç°å¸¸åµæ¸¬ãåºæ¼ééçèªåç·¨ç¢¼å¨å£ç¸®åå§ EEG è¨èï¼åæä¿çééç¨ç«æ§ï¼éä½è¨ç®ææ¬ä¸¦ä¿ççç©å­¸ä¸ææç¾©çç¹å¾µãå£ç¸®å¾çè¡¨ç¤ºæ¥èè¢«è¼¸å¥å°åºæ¼Transformerçåé¡å¨ä¸­ï¼è©²åé¡å¨ææå°å»ºæ¨¡é·æä¾è³´éä¿ä»¥ååæ­£å¸¸åç°å¸¸è¨èãå¨ TUH ç°å¸¸ EEG èªæåº«ä¸é²è¡è©ä¼°ï¼ææåºçæ¨¡åå¨åæ¡å±¤ç´éå° 85.0% çæºç¢ºåº¦ã76.2% çææåº¦å 91.2% çç¹ç°æ§ï¼åªæ¼ EEGNetãDeep4Conv å FusionCNN ç­åºç·æ¨¡åãæ­¤å¤ï¼CAE-T åéè¦ 202M FLOP å 2.9M åæ¸ï¼ä½¿å¶æ¯åºæ¼Transformerçæ¿ä»£æ¹æ¡é¡¯èæ´ææçãè©²æ¶æ§ééå¶åºæ¼ééçè¨­è¨ä¿çäºè§£éæ§ï¼å±ç¾åºå¨ç¥ç¶ç§å­¸ç ç©¶åè¨åºå¯¦åä¸­æªä¾æç¨æ¥µå¤§çæ½åãåå§ç¨å¼ç¢¼å¯å¨ https://github.com/YossiZhao/CAE-T åå¾ã

##### **Cal-DPO: Calibrated Direct Preference Optimization for Language Model Alignment**
2412.14516v1 by Teng Xiao, Yige Yuan, Huaisheng Zhu, Mingxiao Li, Vasant G Honavar

We study the problem of aligning large language models (LLMs) with human
preference data. Contrastive preference optimization has shown promising
results in aligning LLMs with available preference data by optimizing the
implicit reward associated with the policy. However, the contrastive objective
focuses mainly on the relative values of implicit rewards associated with two
responses while ignoring their actual values, resulting in suboptimal alignment
with human preferences. To address this limitation, we propose calibrated
direct preference optimization (Cal-DPO), a simple yet effective algorithm. We
show that substantial improvement in alignment with the given preferences can
be achieved simply by calibrating the implicit reward to ensure that the
learned implicit rewards are comparable in scale to the ground-truth rewards.
We demonstrate the theoretical advantages of Cal-DPO over existing approaches.
The results of our experiments on a variety of standard benchmarks show that
Cal-DPO remarkably improves off-the-shelf methods.

æè¦ï¼æåç ç©¶å°å¤§åèªè¨æ¨¡å (LLM) èäººé¡åå¥½æ¸æå°é½çåé¡ãå°æ¯åå¥½æä½³åå·²å¨å°é½ LLM èå¯ç¨çåå¥½æ¸ææ¹é¢é¡¯ç¤ºåºæå¸æççµæï¼æ¹æ³æ¯æä½³åèæ¿ç­ç¸éçé±å«çåµãç¶èï¼å°æ¯ç®æ¨ä¸»è¦éä¸­å¨èå©ååæç¸éçé±å«çåµçç¸å°å¼ï¼èå¿½ç¥å®åçå¯¦éå¼ï¼å°è´èäººé¡åå¥½çå°é½æ¬¡ä½³åãçºäºè§£æ±ºéåéå¶ï¼æåæåºæ ¡æºç´æ¥åå¥½æä½³å (Cal-DPO)ï¼ä¸ç¨®ç°¡å®ä½ææçæ¼ç®æ³ãæåè­æï¼åªéæ ¡æºé±å«çåµä»¥ç¢ºä¿å­¸ç¿å°çé±å«çåµå¨è¦æ¨¡ä¸èçå¯¦çåµç¸ç¶ï¼å°±å¯ä»¥é¡¯èæ¹åèçµ¦å®åå¥½çå°é½ãæåå±ç¤ºäº Cal-DPO ç¸è¼æ¼ç¾ææ¹æ³ççè«åªå¢ãæåå¨åç¨®æ¨æºåºæºä¸é²è¡çå¯¦é©çµæé¡¯ç¤ºï¼Cal-DPO æé¡¯æ¹åäºç¾æçæ¹æ³ã

##### **Relational Programming with Foundation Models**
2412.14515v1 by Ziyang Li, Jiani Huang, Jason Liu, Felix Zhu, Eric Zhao, William Dodds, Neelay Velingker, Rajeev Alur, Mayur Naik

Foundation models have vast potential to enable diverse AI applications. The
powerful yet incomplete nature of these models has spurred a wide range of
mechanisms to augment them with capabilities such as in-context learning,
information retrieval, and code interpreting. We propose Vieira, a declarative
framework that unifies these mechanisms in a general solution for programming
with foundation models. Vieira follows a probabilistic relational paradigm and
treats foundation models as stateless functions with relational inputs and
outputs. It supports neuro-symbolic applications by enabling the seamless
combination of such models with logic programs, as well as complex, multi-modal
applications by streamlining the composition of diverse sub-models. We
implement Vieira by extending the Scallop compiler with a foreign interface
that supports foundation models as plugins. We implement plugins for 12
foundation models including GPT, CLIP, and SAM. We evaluate Vieira on 9
challenging tasks that span language, vision, and structured and vector
databases. Our evaluation shows that programs in Vieira are concise, can
incorporate modern foundation models, and have comparable or better accuracy
than competitive baselines.

æè¦ï¼åºç¤æ¨¡åå·æå¯¦ç¾åç¨® AI æç¨ç¨å¼çå·¨å¤§æ½åãéäºæ¨¡åçåè½å¼·å¤§ä½åä¸å®æ´ï¼å æ­¤ä¿ä½¿åºç¾äºåç¨®æ©å¶ï¼ä»¥æ´åå®åçåè½ï¼ä¾å¦æå¢å­¸ç¿ãè³è¨æª¢ç´¢åç¨å¼ç¢¼è§£è­¯ãæåæåº Vieiraï¼éæ¯ä¸åå®£åå¼æ¶æ§ï¼å®å°éäºæ©å¶çµ±ä¸å¨ä¸åéç¨çè§£æ±ºæ¹æ¡ä¸­ï¼ç¨æ¼ä½¿ç¨åºç¤æ¨¡åé²è¡ç¨å¼è¨­è¨ãVieira éµå¾ªæ©çéä¿ç¯ä¾ï¼ä¸¦å°åºç¤æ¨¡åè¦çºå·æéä¿è¼¸å¥åè¼¸åºçç¡çæå½æ¸ãå®æ¯æ´ç¥ç¶ç¬¦èæç¨ç¨å¼ï¼è®æ­¤é¡æ¨¡åè½èéè¼¯ç¨å¼é æ¢å°çµåï¼ä¸¦ééç°¡ååç¨®å­æ¨¡åççµæï¼æ¯æ´è¤éçå¤æ¨¡å¼æç¨ç¨å¼ãæåééæ´å Scallop ç·¨è­¯å¨ä¾å¯¦ä½ Vieiraï¼å¶ä¸­åå«ä¸åå¤é¨ä»é¢ï¼å¯æ¯æ´åºç¤æ¨¡åä½çºå¤æç¨å¼ãæåå¯¦ä½äº 12 ååºç¤æ¨¡åçå¤æç¨å¼ï¼åæ¬ GPTãCLIP å SAMãæåå¨ 9 é å·æææ°æ§çä»»åä¸è©ä¼° Vieiraï¼éäºä»»åæ¶µèèªè¨ãè¦è¦ºä»¥åçµæ§åååéè³æåº«ãæåçè©ä¼°é¡¯ç¤ºï¼Vieira ä¸­çç¨å¼ç°¡æ½ï¼è½æ´åç¾ä»£åºç¤æ¨¡åï¼ä¸¦ä¸å·æèç«¶ç­åºæºç·ç¸ç¶ææ´å¥½çæºç¢ºåº¦ã

##### **PA-RAG: RAG Alignment via Multi-Perspective Preference Optimization**
2412.14510v1 by Jiayi Wu, Hengyi Cai, Lingyong Yan, Hao Sun, Xiang Li, Shuaiqiang Wang, Dawei Yin, Ming Gao

The emergence of Retrieval-augmented generation (RAG) has alleviated the
issues of outdated and hallucinatory content in the generation of large
language models (LLMs), yet it still reveals numerous limitations. When a
general-purpose LLM serves as the RAG generator, it often suffers from
inadequate response informativeness, response robustness, and citation quality.
Past approaches to tackle these limitations, either by incorporating additional
steps beyond generating responses or optimizing the generator through
supervised fine-tuning (SFT), still failed to align with the RAG requirement
thoroughly. Consequently, optimizing the RAG generator from multiple preference
perspectives while maintaining its end-to-end LLM form remains a challenge. To
bridge this gap, we propose Multiple Perspective Preference Alignment for
Retrieval-Augmented Generation (PA-RAG), a method for optimizing the generator
of RAG systems to align with RAG requirements comprehensively. Specifically, we
construct high-quality instruction fine-tuning data and multi-perspective
preference data by sampling varied quality responses from the generator across
different prompt documents quality scenarios. Subsequently, we optimize the
generator using SFT and Direct Preference Optimization (DPO). Extensive
experiments conducted on four question-answer datasets across three LLMs
demonstrate that PA-RAG can significantly enhance the performance of RAG
generators. Our code and datasets are available at
https://github.com/wujwyi/PA-RAG.

æè¦ï¼æª¢ç´¢å¢å¼·çæï¼RAGï¼çåºç¾ç·©è§£äºå¤§åèªè¨æ¨¡åï¼LLMï¼ä¸­éæåå¹»è¦ºå§å®¹çåé¡ï¼ä½å®ä»ç¶æ´é²åºè¨±å¤éå¶ãç¶éç¨ LLM ä½çº RAG çæå¨æï¼å®éå¸¸æé­ååæè³è¨ä¸è¶³ãåæç©©å¥æ§åå¼æåè³ªçåé¡ãéå»è§£æ±ºéäºéå¶çæ¹æ³ï¼ç¡è«æ¯ééç´å¥çæåæä»¥å¤çé¡å¤æ­¥é©ï¼éæ¯ééç£ç£å¾®èª¿ï¼SFTï¼æä½³åçæå¨ï¼ä»ç¶ç¡æ³å¾¹åºç¬¦å RAG éæ±ãå æ­¤ï¼å¨ç¶­æå¶ç«¯å°ç«¯ LLM å½¢å¼çåæï¼å¾å¤ååå¥½è§é»æä½³å RAG çæå¨ä»ç¶æ¯ä¸é ææ°ãçºäºå½åéåå·®è·ï¼æåæåºäºæª¢ç´¢å¢å¼·çæçãå¤è§é»åå¥½å°é½ãï¼PA-RAGï¼ï¼éæ¯ä¸ç¨®æä½³å RAG ç³»çµ±çæå¨çæ¹æ³ï¼ä»¥å¨é¢ç¬¦å RAG è¦æ±ãå·é«ä¾èªªï¼æåééå¾ä¸åæç¤ºæä»¶åè³ªæå¢ä¸­å°çæå¨çåç¨®åè³ªåæé²è¡æ½æ¨£ï¼ä¾å»ºæ§é«åè³ªçæä»¤å¾®èª¿è³æåå¤è§é»åå¥½è³æãé¨å¾ï¼æåä½¿ç¨ SFT åç´æ¥åå¥½æä½³åï¼DPOï¼ä¾æä½³åçæå¨ãå¨ä¸å LLM ä¸å°åååç­è³æéé²è¡çå»£æ³å¯¦é©è¡¨æï¼PA-RAG å¯ä»¥é¡¯èæå RAG çæå¨çæè½ãæåçç¨å¼ç¢¼åè³æéå¯å¨ https://github.com/wujwyi/PA-RAG åå¾ã

##### **Do Large Language Models Defend Inferentialist Semantics?: On the Logical Expressivism and Anti-Representationalism of LLMs**
2412.14501v1 by Yuzuki Arai, Sho Tsugawa

The philosophy of language, which has historically been developed through an
anthropocentric lens, is now being forced to move towards post-anthropocentrism
due to the advent of large language models (LLMs) like ChatGPT (OpenAI), Claude
(Anthropic), which are considered to possess linguistic abilities comparable to
those of humans. Traditionally, LLMs have been explained through distributional
semantics as their foundational semantics. However, recent research is
exploring alternative foundational semantics beyond distributional semantics.
This paper proposes Robert Brandom's inferentialist semantics as an suitable
foundational semantics for LLMs, specifically focusing on the issue of
linguistic representationalism within this post-anthropocentric trend. Here, we
show that the anti-representationalism and logical expressivism of inferential
semantics, as well as quasi-compositionality, are useful in interpreting the
characteristics and behaviors of LLMs. Further, we propose a \emph{consensus
theory of truths} for LLMs. This paper argues that the characteristics of LLMs
challenge mainstream assumptions in philosophy of language, such as semantic
externalism and compositionality. We believe the argument in this paper leads
to a re-evaluation of anti\hyphen{}representationalist views of language,
potentially leading to new developments in the philosophy of language.

æè¦ï¼èªè¨å²å­¸éå»ä¸ç´ééäººé¡ä¸­å¿ä¸»ç¾©çè§é»ç¼å±ï¼ä½ç¾å¨å çº ChatGPTï¼OpenAIï¼ãClaudeï¼Anthropicï¼ç­å¤§åèªè¨æ¨¡åï¼LLMï¼çåºç¾ï¼èè¢«è¿«æåå¾äººé¡ä¸­å¿ä¸»ç¾©ç¼å±ï¼éäºæ¨¡åè¢«èªçºå·åèäººé¡ç¸ç¶çèªè¨è½åãå³çµ±ä¸ï¼LLM æ¯ééåä½å¼èªæå­¸ä½çºå¶åºç¤èªæå­¸ä¾è§£éçãç¶èï¼æè¿çç ç©¶æ­£å¨æ¢ç´¢è¶è¶åä½å¼èªæå­¸çæ¿ä»£åºç¤èªæå­¸ãæ¬ææåº Robert Brandom çæ¨è«ä¸»ç¾©èªæå­¸ä½çº LLM çåé©åºç¤èªæå­¸ï¼ç¹å¥éæ³¨å¾äººé¡ä¸­å¿ä¸»ç¾©è¶¨å¢ä¸çèªè¨è¡¨å¾µä¸»ç¾©åé¡ãå¨æ­¤ï¼æåå±ç¤ºäºæ¨è«èªæå­¸çåè¡¨å¾µä¸»ç¾©åéè¼¯è¡¨ç¾ä¸»ç¾©ï¼ä»¥åæºçµåæ§ï¼æå©æ¼è©®é LLM çç¹å¾µåè¡çºãæ­¤å¤ï¼æåæåº LLM çãå±è­çççè«ããæ¬æè«è­ LLM çç¹å¾µææ°äºèªè¨å²å­¸ä¸­çä¸»æµåè¨­ï¼ä¾å¦èªæå¤å¨ä¸»ç¾©åçµåæ§ãæåç¸ä¿¡æ¬æä¸­çè«é»å°å°è´éæ°è©ä¼°èªè¨çåè¡¨å¾µä¸»ç¾©è§é»ï¼ä¸¦å¯è½çºèªè¨å²å­¸å¸¶ä¾æ°çç¼å±ã

##### **The Digital Ecosystem of Beliefs: does evolution favour AI over humans?**
2412.14500v1 by David M. Bossens, Shanshan Feng, Yew-Soon Ong

As AI systems are integrated into social networks, there are AI safety
concerns that AI-generated content may dominate the web, e.g. in popularity or
impact on beliefs.To understand such questions, this paper proposes the Digital
Ecosystem of Beliefs (Digico), the first evolutionary framework for controlled
experimentation with multi-population interactions in simulated social
networks. The framework models a population of agents which change their
messaging strategies due to evolutionary updates following a Universal
Darwinism approach, interact via messages, influence each other's beliefs
through dynamics based on a contagion model, and maintain their beliefs through
cognitive Lamarckian inheritance. Initial experiments with an abstract
implementation of Digico show that: a) when AIs have faster messaging,
evolution, and more influence in the recommendation algorithm, they get 80% to
95% of the views, depending on the size of the influence benefit; b) AIs
designed for propaganda can typically convince 50% of humans to adopt extreme
beliefs, and up to 85% when agents believe only a limited number of channels;
c) a penalty for content that violates agents' beliefs reduces propaganda
effectiveness by up to 8%. We further discuss implications for control (e.g.
legislation) and Digico as a means of studying evolutionary principles.

æè¦ï¼é¨è AI ç³»çµ±æ´åå°ç¤¾ç¾¤ç¶²è·¯ä¸­ï¼æ AI å®å¨æ¹é¢ççæ®ï¼å³ AI çæçå§å®¹å¯è½ä¸»å°ç¶²è·¯ï¼ä¾å¦å¨äººæ°£æå°ä¿¡å¿µçå½±é¿ä¸ãçºäºäºè§£æ­¤é¡åé¡ï¼æ¬ææåºäºä¿¡å¿µçæ¸ä½çæç³»çµ± (Digico)ï¼éæ¯ç¬¬ä¸åç¨æ¼å¨æ¨¡æ¬ç¤¾ç¾¤ç¶²è·¯ä¸­é²è¡å¤æç¾¤äºåçåæ§å¯¦é©çæ¼åæ¶æ§ãæ­¤æ¶æ§æ¨¡æ¬äºä¸ç¾¤æå æ¼åæ´æ°èæ¹è®å¶è¨æ¯ç­ç¥çä»£çï¼ééè¨æ¯äºåï¼ééåºæ¼å³ææ¨¡åçåæå½±é¿å½¼æ­¤çä¿¡å¿µï¼ä¸¦ééèªç¥æé¦¬åéºå³ç¶­æå¶ä¿¡å¿µãå° Digico çæ½è±¡å¯¦ä½é²è¡çåæ­¥å¯¦é©é¡¯ç¤ºï¼a) ç¶ AI å·ææ´å¿«çè¨æ¯å³éãæ¼ååå¨æ¨è¦æ¼ç®æ³ä¸­å·ææ´å¤å½±é¿åæï¼ä»åæç²å¾ 80% å° 95% çè§çæ¬¡æ¸ï¼å·é«åæ±ºæ¼å½±é¿æççå¤§å°ï¼b) å°éç¨æ¼å®£å³ç AI éå¸¸å¯ä»¥èªªæ 50% çäººé¡æ¥åæ¥µç«¯çä¿¡å¿µï¼ç¶ä»£çåªç¸ä¿¡æéæ¸éçé »éæï¼æ­¤æ¯ä¾æé«å¯é 85%ï¼c) å°éåä»£çä¿¡å¿µçå§å®¹é²è¡æ²ç½°å¯å°å®£å³ææéä½å¤é 8%ãæåé²ä¸æ­¥è¨è«äºå°æ§å¶ï¼ä¾å¦ç«æ³ï¼çå½±é¿ï¼ä»¥å Digico ä½çºç ç©¶æ¼ååççä¸ç¨®ææ®µã

##### **FaultExplainer: Leveraging Large Language Models for Interpretable Fault Detection and Diagnosis**
2412.14492v1 by Abdullah Khan, Rahul Nahar, Hao Chen, Gonzalo E. Constante Flores, Can Li

Machine learning algorithms are increasingly being applied to fault detection
and diagnosis (FDD) in chemical processes. However, existing data-driven FDD
platforms often lack interpretability for process operators and struggle to
identify root causes of previously unseen faults. This paper presents
FaultExplainer, an interactive tool designed to improve fault detection,
diagnosis, and explanation in the Tennessee Eastman Process (TEP).
FaultExplainer integrates real-time sensor data visualization, Principal
Component Analysis (PCA)-based fault detection, and identification of top
contributing variables within an interactive user interface powered by large
language models (LLMs). We evaluate the LLMs' reasoning capabilities in two
scenarios: one where historical root causes are provided, and one where they
are not to mimic the challenge of previously unseen faults. Experimental
results using GPT-4o and o1-preview models demonstrate the system's strengths
in generating plausible and actionable explanations, while also highlighting
its limitations, including reliance on PCA-selected features and occasional
hallucinations.

æè¦ï¼æ©å¨å­¸ç¿æ¼ç®æ³æ­£è¶ä¾è¶å»£æ³å°æç¨æ¼åå­¸è£½ç¨ä¸­çæéåµæ¸¬èè¨ºæ· (FDD)ãç¶èï¼ç¾æçè³æå°å FDD å¹³å°éå¸¸ç¼ºä¹è£½ç¨æä½å¡çå¯è§£éæ§ï¼ä¸é£ä»¥æ¾åºåææªè¦çæéæ ¹æ¬åå ãæ¬ææåº FaultExplainerï¼éæ¯ä¸åäºåå¼å·¥å·ï¼æ¨å¨æ¹åç°ç´è¥¿ Eastman è£½ç¨ (TEP) ä¸­çæéåµæ¸¬ãè¨ºæ·åèªªæãFaultExplainer æ´åäºå³æææ¸¬å¨è³æè¦è¦ºåãåºæ¼ä¸»æååæ (PCA) çæéåµæ¸¬ï¼ä»¥åå¨ç±å¤§åèªè¨æ¨¡å (LLM) æä¾ååçäºåå¼ä½¿ç¨èä»é¢ä¸­æ¾åºæéè¦çè²¢ç»è®æ¸ãæåå¨å©ç¨®æå¢ä¸­è©ä¼° LLM çæ¨çè½åï¼ä¸ç¨®æ¯ææä¾æ­·å²æ ¹æºï¼å¦ä¸ç¨®åæ²æï¼ç¨ä»¥æ¨¡æ¬åææªè¦æéçææ°ãä½¿ç¨ GPT-4o å o1-preview æ¨¡åçå¯¦é©çµæè­æäºç³»çµ±å¨ç¢çåçä¸å¯è¡çèªªææ¹é¢çåªå¢ï¼åæä¹çªé¡¯äºå¶éå¶ï¼åæ¬ä¾è³´ PCA é¸æçç¹å¾µåå¶ç¾ç¢ççå¹»è¦ºã

##### **Towards Projected and Incremental Pseudo-Boolean Model Counting**
2412.14485v1 by Suwei Yang, Kuldeep S. Meel

Model counting is a fundamental task that involves determining the number of
satisfying assignments to a logical formula, typically in conjunctive normal
form (CNF). While CNF model counting has received extensive attention over
recent decades, interest in Pseudo-Boolean (PB) model counting is just emerging
partly due to the greater flexibility of PB formulas. As such, we observed
feature gaps in existing PB counters such as a lack of support for projected
and incremental settings, which could hinder adoption.
  In this work, our main contribution is the introduction of the PB model
counter PBCount2, the first exact PB model counter with support for projected
and incremental model counting. Our counter, PBCount2, uses our Least
Occurrence Weighted Min Degree (LOW-MD) computation ordering heuristic to
support projected model counting and a cache mechanism to enable incremental
model counting. In our evaluations, PBCount2 completed at least 1.40x the
number of benchmarks of competing methods for projected model counting and at
least 1.18x of competing methods in incremental model counting.

æè¦ï¼æ¨¡åè¨æ¸æ¯ä¸é åºæ¬ä»»åï¼æ¶åç¢ºå®æ»¿è¶³éè¼¯å¬å¼çææ´¾æ¸éï¼éå¸¸ä»¥ååç¯å¼ (CNF) å½¢å¼è¡¨ç¤ºãéç¶ CNF æ¨¡åè¨æ¸å¨æè¿å¹¾åå¹´åå°å»£æ³éæ³¨ï¼ä½å°å½å¸æ (PB) æ¨¡åè¨æ¸çèè¶£æåéå§æµ®ç¾ï¼é¨ååå æ¯ PB å¬å¼å·ææ´å¤§çéæ´»æ§ãå æ­¤ï¼æåè§å¯å°ç¾æ PB è¨æ¸å¨ä¸­çåè½å·®è·ï¼ä¾å¦ç¼ºä¹å°æå½±åéå¢è¨­å®çæ¯æï¼éå¯è½æé»ç¤æ¡ç¨ã
å¨éé å·¥ä½ä¸­ï¼æåçè²¢ç»å¨æ¼å¼å¥äº PB æ¨¡åè¨æ¸å¨ PBCount2ï¼éæ¯ç¬¬ä¸åæ¯æ´æå½±åéå¢æ¨¡åè¨æ¸çç²¾ç¢º PB æ¨¡åè¨æ¸å¨ãæåçè¨æ¸å¨ PBCount2 ä½¿ç¨æåçæå°åºç¾å æ¬æå°åº¦æ¸ (LOW-MD) è¨ç®æåºåç¼æ³ä¾æ¯æ´æå½±æ¨¡åè¨æ¸ï¼ä¸¦ä½¿ç¨å¿«åæ©å¶ä¾åç¨éå¢æ¨¡åè¨æ¸ãå¨æåçè©ä¼°ä¸­ï¼PBCount2 å®æçåºæºæ¸éè³å°æ¯æå½±æ¨¡åè¨æ¸ç«¶ç­æ¹æ³ç 1.40 åï¼ä¸¦ä¸è³å°æ¯éå¢æ¨¡åè¨æ¸ç«¶ç­æ¹æ³ç 1.18 åã

##### **GraphEQA: Using 3D Semantic Scene Graphs for Real-time Embodied Question Answering**
2412.14480v1 by Saumya Saxena, Blake Buchanan, Chris Paxton, Bingqing Chen, Narunas Vaskevicius, Luigi Palmieri, Jonathan Francis, Oliver Kroemer

In Embodied Question Answering (EQA), agents must explore and develop a
semantic understanding of an unseen environment in order to answer a situated
question with confidence. This remains a challenging problem in robotics, due
to the difficulties in obtaining useful semantic representations, updating
these representations online, and leveraging prior world knowledge for
efficient exploration and planning. Aiming to address these limitations, we
propose GraphEQA, a novel approach that utilizes real-time 3D metric-semantic
scene graphs (3DSGs) and task relevant images as multi-modal memory for
grounding Vision-Language Models (VLMs) to perform EQA tasks in unseen
environments. We employ a hierarchical planning approach that exploits the
hierarchical nature of 3DSGs for structured planning and semantic-guided
exploration. Through experiments in simulation on the HM-EQA dataset and in the
real world in home and office environments, we demonstrate that our method
outperforms key baselines by completing EQA tasks with higher success rates and
fewer planning steps.

æè¦ï¼å¨å·èº«åç­ (EQA) ä¸­ï¼ä»£çå¿é æ¢ç´¢ä¸¦ç¼å±å°æªè¦éç°å¢çèªç¾©çè§£ï¼æè½æä¿¡å¿å°åç­æå¢åé¡ãç±æ¼é£ä»¥åå¾æç¨çèªç¾©è¡¨ç¤ºãç·ä¸æ´æ°éäºè¡¨ç¤ºï¼ä»¥åå©ç¨ååçä¸çç¥è­é²è¡ææççæ¢ç´¢åè¦åï¼éå¨æ©å¨äººå­¸ä¸­ä»ç¶æ¯ä¸åå·æææ°æ§çåé¡ãçºäºè§£æ±ºéäºéå¶ï¼æåæåº GraphEQAï¼ä¸ç¨®å©ç¨å³æ 3D åº¦éèªç¾©å ´æ¯å (3DSG) åèä»»åç¸éçå½±åä½çºå¤æ¨¡å¼è¨æ¶é«çæ°ç©æ¹æ³ï¼ä»¥æ¥å°è¦è¦ºèªè¨æ¨¡å (VLM) ä¾å·è¡æªè¦éç°å¢ä¸­ç EQA ä»»åãæåæ¡ç¨åå±¤è¦åæ¹æ³ï¼å©ç¨ 3DSG çåå±¤æ§è³ªé²è¡çµæ§åè¦ååèªç¾©å¼å°æ¢ç´¢ãééå¨ HM-EQA è³æéä¸çæ¨¡æ¬å¯¦é©ï¼ä»¥åå¨å®¶åº­åè¾¦å¬å®¤ç°å¢ä¸­ççå¯¦ä¸çä¸­ï¼æåè­ææåçæ¨¡åééä»¥è¼é«çæåçåè¼å°çè¦åæ­¥é©å®æ EQA ä»»åï¼åªæ¼ä¸»è¦çåºç·ã

