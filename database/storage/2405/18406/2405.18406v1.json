{"2405.18406": {"publish_time": "2024-05-28", "title": "RACCooN: Remove, Add, and Change Video Content with Auto-Generated Narratives", "paper_summary": "Recent video generative models primarily rely on carefully written text\nprompts for specific tasks, like inpainting or style editing. They require\nlabor-intensive textual descriptions for input videos, hindering their\nflexibility to adapt personal/raw videos to user specifications. This paper\nproposes RACCooN, a versatile and user-friendly video-to-paragraph-to-video\ngenerative framework that supports multiple video editing capabilities such as\nremoval, addition, and modification, through a unified pipeline. RACCooN\nconsists of two principal stages: Video-to-Paragraph (V2P) and\nParagraph-to-Video (P2V). In the V2P stage, we automatically describe video\nscenes in well-structured natural language, capturing both the holistic context\nand focused object details. Subsequently, in the P2V stage, users can\noptionally refine these descriptions to guide the video diffusion model,\nenabling various modifications to the input video, such as removing, changing\nsubjects, and/or adding new objects. The proposed approach stands out from\nother methods through several significant contributions: (1) RACCooN suggests a\nmulti-granular spatiotemporal pooling strategy to generate well-structured\nvideo descriptions, capturing both the broad context and object details without\nrequiring complex human annotations, simplifying precise video content editing\nbased on text for users. (2) Our video generative model incorporates\nauto-generated narratives or instructions to enhance the quality and accuracy\nof the generated content. It supports the addition of video objects,\ninpainting, and attribute modification within a unified framework, surpassing\nexisting video editing and inpainting benchmarks. The proposed framework\ndemonstrates impressive versatile capabilities in video-to-paragraph\ngeneration, video content editing, and can be incorporated into other SoTA\nvideo generative models for further enhancement.", "paper_summary_zh": "<paragraph>\u6700\u8fd1\u7684\u5f71\u7247\u751f\u6210\u6a21\u578b\u4e3b\u8981\u4ef0\u8cf4\u4ed4\u7d30\u64b0\u5beb\u7684\u6587\u5b57\u63d0\u793a\uff0c\u4ee5\u57f7\u884c\u7279\u5b9a\u4efb\u52d9\uff0c\u4f8b\u5982\u4fee\u5fa9\u6216\u98a8\u683c\u7de8\u8f2f\u3002\u5b83\u5011\u9700\u8981\u5927\u91cf\u6587\u5b57\u63cf\u8ff0\u4f5c\u70ba\u8f38\u5165\u5f71\u7247\uff0c\u9019\u6703\u59a8\u7919\u5b83\u5011\u9748\u6d3b\u5730\u8abf\u6574\u500b\u4eba/\u539f\u59cb\u5f71\u7247\u4ee5\u7b26\u5408\u4f7f\u7528\u8005\u898f\u683c\u3002\u672c\u6587\u63d0\u51fa RACCooN\uff0c\u4e00\u500b\u591a\u529f\u80fd\u4e14\u53cb\u5584\u7684\u5f71\u7247\u8f49\u6bb5\u843d\u8f49\u5f71\u7247\u751f\u6210\u67b6\u69cb\uff0c\u900f\u904e\u7d71\u4e00\u7684\u7ba1\u9053\u652f\u63f4\u591a\u7a2e\u5f71\u7247\u7de8\u8f2f\u529f\u80fd\uff0c\u4f8b\u5982\u79fb\u9664\u3001\u65b0\u589e\u548c\u4fee\u6539\u3002RACCooN \u5305\u542b\u5169\u500b\u4e3b\u8981\u968e\u6bb5\uff1a\u5f71\u7247\u8f49\u6bb5\u843d (V2P) \u548c\u6bb5\u843d\u8f49\u5f71\u7247 (P2V)\u3002\u5728 V2P \u968e\u6bb5\uff0c\u6211\u5011\u6703\u81ea\u52d5\u4ee5\u7d50\u69cb\u826f\u597d\u7684\u81ea\u7136\u8a9e\u8a00\u63cf\u8ff0\u5f71\u7247\u5834\u666f\uff0c\u540c\u6642\u64f7\u53d6\u6574\u9ad4\u8108\u7d61\u548c\u805a\u7126\u7684\u7269\u4ef6\u7d30\u7bc0\u3002\u63a5\u8457\uff0c\u5728 P2V \u968e\u6bb5\uff0c\u4f7f\u7528\u8005\u53ef\u4ee5\u9078\u64c7\u8abf\u6574\u9019\u4e9b\u63cf\u8ff0\uff0c\u4ee5\u5f15\u5c0e\u5f71\u7247\u64f4\u6563\u6a21\u578b\uff0c\u5c0d\u8f38\u5165\u5f71\u7247\u9032\u884c\u5404\u7a2e\u4fee\u6539\uff0c\u4f8b\u5982\u79fb\u9664\u3001\u8b8a\u66f4\u4e3b\u9ad4\u548c/\u6216\u65b0\u589e\u65b0\u7269\u4ef6\u3002\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u900f\u904e\u5e7e\u500b\u91cd\u8981\u7684\u8ca2\u737b\uff0c\u5728\u5176\u4ed6\u65b9\u6cd5\u4e2d\u812b\u7a4e\u800c\u51fa\uff1a(1) RACCooN \u5efa\u8b70\u63a1\u7528\u591a\u9846\u7c92\u6642\u7a7a\u6c60\u5316\u7b56\u7565\u4f86\u7522\u751f\u7d50\u69cb\u826f\u597d\u7684\u5f71\u7247\u63cf\u8ff0\uff0c\u540c\u6642\u64f7\u53d6\u5ee3\u6cdb\u7684\u8108\u7d61\u548c\u7269\u4ef6\u7d30\u7bc0\uff0c\u800c\u7121\u9700\u8907\u96dc\u7684\u4eba\u5de5\u8a3b\u89e3\uff0c\u7c21\u5316\u4e86\u57fa\u65bc\u6587\u5b57\u7684\u7cbe\u78ba\u5f71\u7247\u5167\u5bb9\u7de8\u8f2f\u3002 (2) \u6211\u5011\u7684\u5f71\u7247\u751f\u6210\u6a21\u578b\u7d50\u5408\u81ea\u52d5\u7522\u751f\u7684\u6558\u8ff0\u6216\u8aaa\u660e\uff0c\u4ee5\u63d0\u5347\u751f\u6210\u5167\u5bb9\u7684\u54c1\u8cea\u548c\u6e96\u78ba\u5ea6\u3002\u5b83\u652f\u63f4\u5728\u7d71\u4e00\u67b6\u69cb\u4e2d\u65b0\u589e\u5f71\u7247\u7269\u4ef6\u3001\u4fee\u5fa9\u548c\u5c6c\u6027\u4fee\u6539\uff0c\u8d85\u8d8a\u73fe\u6709\u7684\u5f71\u7247\u7de8\u8f2f\u548c\u4fee\u5fa9\u57fa\u6e96\u3002\u6240\u63d0\u51fa\u7684\u67b6\u69cb\u5c55\u73fe\u51fa\u4ee4\u4eba\u5370\u8c61\u6df1\u523b\u7684\u591a\u529f\u80fd\u80fd\u529b\uff0c\u5728\u5f71\u7247\u8f49\u6bb5\u843d\u751f\u6210\u3001\u5f71\u7247\u5167\u5bb9\u7de8\u8f2f\u65b9\u9762\uff0c\u4e26\u4e14\u53ef\u4ee5\u6574\u5408\u5230\u5176\u4ed6 SoTA \u5f71\u7247\u751f\u6210\u6a21\u578b\u4e2d\u4ee5\u9032\u4e00\u6b65\u63d0\u5347\u3002</paragraph>", "author": "Jaehong Yoon et.al.", "authors": "Jaehong Yoon, Shoubin Yu, Mohit Bansal", "id": "2405.18406v1", "paper_url": "http://arxiv.org/abs/2405.18406v1", "repo": "null"}}