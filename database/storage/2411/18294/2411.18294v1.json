{"2411.18294": {"publish_time": "2024-11-27", "title": "Aligning Pre-trained Models for Spoken Language Translation", "paper_summary": "This paper investigates a novel approach to end-to-end speech translation\n(ST) based on aligning frozen pre-trained automatic speech recognition (ASR)\nand machine translation (MT) models via a small connector module (Q-Former, our\nSubsampler-Transformer Encoder). This connector bridges the gap between the\nspeech and text modalities, transforming ASR encoder embeddings into the latent\nrepresentation space of the MT encoder while being the only part of the system\noptimized during training. Experiments are conducted on the How2\nEnglish-Portuguese dataset as we investigate the alignment approach in a\nsmall-scale scenario focusing on ST. While keeping the size of the connector\nmodule constant and small in comparison ( < 5% of the size of the larger\naligned models), increasing the size and capability of the foundation ASR and\nMT models universally improves translation results. We also find that the\nconnectors can serve as domain adapters for the foundation MT models,\nsignificantly improving translation performance in the aligned ST setting. We\nconclude that this approach represents a viable and scalable approach to\ntraining end-to-end ST systems.", "paper_summary_zh": "\u672c\u6587\u63a2\u8a0e\u4e86\u4e00\u7a2e\u7aef\u5c0d\u7aef\u8a9e\u97f3\u7ffb\u8b6f (ST) \u7684\u65b0\u65b9\u6cd5\uff0c\u6b64\u65b9\u6cd5\u662f\u900f\u904e\u4e00\u500b\u5c0f\u578b\u9023\u63a5\u6a21\u7d44 (Q-Former\uff0c\u6211\u5011\u7684\u5b50\u63a1\u6a23\u5668\u8f49\u63db\u5668\u7de8\u78bc\u5668) \u4f86\u5c0d\u9f4a\u51cd\u7d50\u7684\u9810\u8a13\u7df4\u81ea\u52d5\u8a9e\u97f3\u8fa8\u8b58 (ASR) \u548c\u6a5f\u5668\u7ffb\u8b6f (MT) \u6a21\u578b\u3002\u6b64\u9023\u63a5\u5668\u5f4c\u88dc\u4e86\u8a9e\u97f3\u548c\u6587\u5b57\u6a21\u614b\u4e4b\u9593\u7684\u5dee\u8ddd\uff0c\u5c07 ASR \u7de8\u78bc\u5668\u5d4c\u5165\u8f49\u63db\u6210 MT \u7de8\u78bc\u5668\u7684\u6f5b\u5728\u8868\u793a\u7a7a\u9593\uff0c\u540c\u6642\u6210\u70ba\u8a13\u7df4\u671f\u9593\u7cfb\u7d71\u4e2d\u552f\u4e00\u6700\u4f73\u5316\u7684\u90e8\u5206\u3002\u6211\u5011\u5728 How2 \u82f1\u8461\u8cc7\u6599\u96c6\u4e0a\u9032\u884c\u5be6\u9a57\uff0c\u56e0\u70ba\u6211\u5011\u5728\u5c0f\u898f\u6a21\u5834\u666f\u4e2d\u63a2\u8a0e\u5c0d\u9f4a\u65b9\u6cd5\uff0c\u5c08\u6ce8\u65bc ST\u3002\u5728\u4fdd\u6301\u9023\u63a5\u5668\u6a21\u7d44\u5927\u5c0f\u6046\u5b9a\u4e14\u8f03\u5c0f (\u5c0f\u65bc\u8f03\u5927\u5c0d\u9f4a\u6a21\u578b\u5927\u5c0f\u7684 5%) \u7684\u540c\u6642\uff0c\u589e\u52a0\u57fa\u790e ASR \u548c MT \u6a21\u578b\u7684\u5927\u5c0f\u548c\u529f\u80fd\u666e\u904d\u6539\u5584\u4e86\u7ffb\u8b6f\u7d50\u679c\u3002\u6211\u5011\u9084\u767c\u73fe\u9023\u63a5\u5668\u53ef\u4ee5\u7528\u4f5c\u57fa\u790e MT \u6a21\u578b\u7684\u9818\u57df\u9069\u914d\u5668\uff0c\u5927\u5e45\u6539\u5584\u5c0d\u9f4a ST \u8a2d\u5b9a\u4e2d\u7684\u7ffb\u8b6f\u6548\u80fd\u3002\u6211\u5011\u5f97\u51fa\u7d50\u8ad6\uff0c\u9019\u7a2e\u65b9\u6cd5\u4ee3\u8868\u4e00\u7a2e\u53ef\u884c\u4e14\u53ef\u64f4\u5145\u7684\u65b9\u6cd5\uff0c\u7528\u65bc\u8a13\u7df4\u7aef\u5c0d\u7aef ST \u7cfb\u7d71\u3002", "author": "\u0160imon Sedl\u00e1\u010dek et.al.", "authors": "\u0160imon Sedl\u00e1\u010dek, Santosh Kesiraju, Alexander Polok, Jan \u010cernock\u00fd", "id": "2411.18294v1", "paper_url": "http://arxiv.org/abs/2411.18294v1", "repo": "null"}}