
### LLM
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-11-21**|**Whack-a-Chip: The Futility of Hardware-Centric Export Controls**|Ritwik Gupta et.al.|[2411.14425v1](http://arxiv.org/abs/2411.14425v1)|null|
|**2024-11-21**|**Marco-o1: Towards Open Reasoning Models for Open-Ended Solutions**|Yu Zhao et.al.|[2411.14405v1](http://arxiv.org/abs/2411.14405v1)|null|
|**2024-11-21**|**Resolving Multiple-Dynamic Model Uncertainty in Hypothesis-Driven Belief-MDPs**|Ofer Dagan et.al.|[2411.14404v1](http://arxiv.org/abs/2411.14404v1)|null|
|**2024-11-21**|**Landing Trajectory Prediction for UAS Based on Generative Adversarial Network**|Jun Xiang et.al.|[2411.14403v1](http://arxiv.org/abs/2411.14403v1)|null|
|**2024-11-21**|**Lightweight Safety Guardrails Using Fine-tuned BERT Embeddings**|Aaron Zheng et.al.|[2411.14398v1](http://arxiv.org/abs/2411.14398v1)|null|
|**2024-11-21**|**POS-tagging to highlight the skeletal structure of sentences**|Grigorii Churakov et.al.|[2411.14393v1](http://arxiv.org/abs/2411.14393v1)|[link](https://github.com/disk0Dancer/rubert-finetuned-pos)|
|**2024-11-21**|**Using Formal Models, Safety Shields and Certified Control to Validate AI-Based Train Systems**|Jan Gruteser et.al.|[2411.14374v1](http://arxiv.org/abs/2411.14374v1)|null|
|**2024-11-21**|**Synthesising Robust Controllers for Robot Collectives with Recurrent Tasks: A Case Study**|Till Schnittka et.al.|[2411.14371v1](http://arxiv.org/abs/2411.14371v1)|null|
|**2024-11-21**|**Contrasting local and global modeling with machine learning and satellite data: A case study estimating tree canopy height in African savannas**|Esther Rolf et.al.|[2411.14354v1](http://arxiv.org/abs/2411.14354v1)|null|
|**2024-11-21**|**UnifiedCrawl: Aggregated Common Crawl for Affordable Adaptation of LLMs on Low-Resource Languages**|Bethel Melesse Tessema et.al.|[2411.14343v1](http://arxiv.org/abs/2411.14343v1)|[link](https://github.com/bethelmelesse/unifiedcrawl)|
|**2024-11-21**|**Velocitune: A Velocity-based Dynamic Domain Reweighting Method for Continual Pre-training**|Zheheng Luo et.al.|[2411.14318v1](http://arxiv.org/abs/2411.14318v1)|null|
|**2024-11-21**|**Automated Generation of Code Debugging Exercises**|Victor-Alexandru Pădurean et.al.|[2411.14303v1](http://arxiv.org/abs/2411.14303v1)|null|
|**2024-11-21**|**Looking Beyond Text: Reducing Language bias in Large Vision-Language Models via Multimodal Dual-Attention and Soft-Image Guidance**|Haozhe Zhao et.al.|[2411.14279v1](http://arxiv.org/abs/2411.14279v1)|null|
|**2024-11-21**|**Neuro-Symbolic Query Optimization in Knowledge Graphs**|Maribel Acosta et.al.|[2411.14277v1](http://arxiv.org/abs/2411.14277v1)|null|
|**2024-11-21**|**Efficient Aspect-Based Summarization of Climate Change Reports with Small Language Models**|Iacopo Ghinassi et.al.|[2411.14272v1](http://arxiv.org/abs/2411.14272v1)|[link](https://github.com/ighina/llmclimate2024)|
|**2024-11-21**|**Generating Realistic Adversarial Examples for Business Processes using Variational Autoencoders**|Alexander Stevens et.al.|[2411.14263v1](http://arxiv.org/abs/2411.14263v1)|null|
|**2024-11-21**|**Knowledge Graphs, Large Language Models, and Hallucinations: An NLP Perspective**|Ernests Lavrinovics et.al.|[2411.14258v1](http://arxiv.org/abs/2411.14258v1)|null|
|**2024-11-21**|**Do I Know This Entity? Knowledge Awareness and Hallucinations in Language Models**|Javier Ferrando et.al.|[2411.14257v1](http://arxiv.org/abs/2411.14257v1)|null|
|**2024-11-21**|**BERT-Based Approach for Automating Course Articulation Matrix Construction with Explainable AI**|Natenaile Asmamaw Shiferaw et.al.|[2411.14254v1](http://arxiv.org/abs/2411.14254v1)|[link](https://github.com/natenaile/bert-based-approach-for-automating-course-articulation-matrix-construction-with-explainable-ai)|
|**2024-11-21**|**Intent-Aware Dialogue Generation and Multi-Task Contrastive Learning for Multi-Turn Intent Classification**|Junhua Liu et.al.|[2411.14252v1](http://arxiv.org/abs/2411.14252v1)|null|
|**2024-11-21**|**Natural Language Reinforcement Learning**|Xidong Feng et.al.|[2411.14251v1](http://arxiv.org/abs/2411.14251v1)|null|
|**2024-11-21**|**AnywhereDoor: Multi-Target Backdoor Attacks on Object Detection**|Jialin Lu et.al.|[2411.14243v1](http://arxiv.org/abs/2411.14243v1)|null|
|**2024-11-21**|**Towards Context-Rich Automated Biodiversity Assessments: Deriving AI-Powered Insights from Camera Trap Data**|Paul Fergus et.al.|[2411.14219v1](http://arxiv.org/abs/2411.14219v1)|null|
|**2024-11-21**|**Evaluating the Robustness of Analogical Reasoning in Large Language Models**|Martha Lewis et.al.|[2411.14215v1](http://arxiv.org/abs/2411.14215v1)|[link](https://github.com/marthaflinderslewis/robust-analogy)|
|**2024-11-21**|**Physics-Informed LLM-Agent for Automated Modulation Design in Power Electronics Systems**|Junhua Liu et.al.|[2411.14214v1](http://arxiv.org/abs/2411.14214v1)|null|
|**2024-11-21**|**HARP: A Large-Scale Higher-Order Ambisonic Room Impulse Response Dataset**|Shivam Saini et.al.|[2411.14207v1](http://arxiv.org/abs/2411.14207v1)|[link](https://github.com/whojavumusic/harp)|
|**2024-11-21**|**Is this Generated Person Existed in Real-world? Fine-grained Detecting and Calibrating Abnormal Human-body**|Zeqing Wang et.al.|[2411.14205v1](http://arxiv.org/abs/2411.14205v1)|null|
|**2024-11-21**|**OpenScholar: Synthesizing Scientific Literature with Retrieval-augmented LMs**|Akari Asai et.al.|[2411.14199v1](http://arxiv.org/abs/2411.14199v1)|[link](https://github.com/akariasai/scholarbench)|
|**2024-11-21**|**Why do language models perform worse for morphologically complex languages?**|Catherine Arnett et.al.|[2411.14198v1](http://arxiv.org/abs/2411.14198v1)|[link](https://github.com/catherinearnett/morphscore)|
|**2024-11-21**|**ComfyGI: Automatic Improvement of Image Generation Workflows**|Dominik Sobania et.al.|[2411.14193v1](http://arxiv.org/abs/2411.14193v1)|null|
|**2024-11-21**|**FoPru: Focal Pruning for Efficient Large Vision-Language Models**|Lei Jiang et.al.|[2411.14164v1](http://arxiv.org/abs/2411.14164v1)|null|
|**2024-11-21**|**Visual Contexts Clarify Ambiguous Expressions: A Benchmark Dataset**|Heejeong Nam et.al.|[2411.14137v1](http://arxiv.org/abs/2411.14137v1)|null|
|**2024-11-21**|**GASP: Efficient Black-Box Generation of Adversarial Suffixes for Jailbreaking LLMs**|Advik Raj Basani et.al.|[2411.14133v1](http://arxiv.org/abs/2411.14133v1)|[link](https://github.com/llm-gasp/gasp)|
|**2024-11-21**|**Learning from "Silly" Questions Improves Large Language Models, But Only Slightly**|Tingyuan Zhu et.al.|[2411.14121v1](http://arxiv.org/abs/2411.14121v1)|null|
|**2024-11-21**|**Lost in Inference: Rediscovering the Role of Natural Language Inference for Large Language Models**|Lovish Madaan et.al.|[2411.14103v1](http://arxiv.org/abs/2411.14103v1)|null|
|**2024-11-21**|**BEST-STD: Bidirectional Mamba-Enhanced Speech Tokenization for Spoken Term Detection**|Anup Singh et.al.|[2411.14100v1](http://arxiv.org/abs/2411.14100v1)|null|
|**2024-11-21**|**Meaning at the Planck scale? Contextualized word embeddings for doing history, philosophy, and sociology of science**|Arno Simons et.al.|[2411.14073v1](http://arxiv.org/abs/2411.14073v1)|null|
|**2024-11-21**|**The Master-Slave Encoder Model for Improving Patent Text Summarization: A New Approach to Combining Specifications and Claims**|Shu Zhou et.al.|[2411.14072v1](http://arxiv.org/abs/2411.14072v1)|null|
|**2024-11-21**|**Multi LoRA Meets Vision: Merging multiple adapters to create a multi task model**|Ege Kesim et.al.|[2411.14064v1](http://arxiv.org/abs/2411.14064v1)|null|
|**2024-11-21**|**MMGenBench: Evaluating the Limits of LMMs from the Text-to-Image Generation Perspective**|Hailang Huang et.al.|[2411.14062v1](http://arxiv.org/abs/2411.14062v1)|[link](https://github.com/lerogo/mmgenbench)|
|**2024-11-21**|**DRPruning: Efficient Large Language Model Pruning through Distributionally Robust Optimization**|Hexuan Deng et.al.|[2411.14055v1](http://arxiv.org/abs/2411.14055v1)|[link](https://github.com/hexuandeng/drpruning)|
|**2024-11-21**|**FunctionChat-Bench: Comprehensive Evaluation of Language Models' Generative Capabilities in Korean Tool-use Dialogs**|Shinbok Lee et.al.|[2411.14054v1](http://arxiv.org/abs/2411.14054v1)|[link](https://github.com/kakao/functionchat-bench)|
|**2024-11-21**|**Forecasting Future International Events: A Reliable Dataset for Text-Based Event Modeling**|Daehoon Gwak et.al.|[2411.14042v1](http://arxiv.org/abs/2411.14042v1)|null|
|**2024-11-21**|**Uterine Ultrasound Image Captioning Using Deep Learning Techniques**|Abdennour Boulesnane et.al.|[2411.14039v1](http://arxiv.org/abs/2411.14039v1)|null|
|**2024-11-21**|**Multi-LLM-Agent Systems: Techniques and Business Perspectives**|Yingxuan Yang et.al.|[2411.14033v1](http://arxiv.org/abs/2411.14033v1)|null|
|**2024-11-21**|**Trajectory Representation Learning on Road Networks and Grids with Spatio-Temporal Dynamics**|Stefan Schestakov et.al.|[2411.14014v1](http://arxiv.org/abs/2411.14014v1)|null|
|**2024-11-21**|**Logic Augmented Generation**|Aldo Gangemi et.al.|[2411.14012v1](http://arxiv.org/abs/2411.14012v1)|null|
|**2024-11-21**|**Mirror Target YOLO: An Improved YOLOv8 Method with Indirect Vision for Heritage Buildings Fire Detection**|Jian Liang et.al.|[2411.13997v1](http://arxiv.org/abs/2411.13997v1)|null|
|**2024-11-21**|**Safety Without Semantic Disruptions: Editing-free Safe Image Generation via Context-preserving Dual Latent Reconstruction**|Jordan Vice et.al.|[2411.13982v1](http://arxiv.org/abs/2411.13982v1)|null|
|**2024-11-21**|**On the Fairness, Diversity and Reliability of Text-to-Image Generative Models**|Jordan Vice et.al.|[2411.13981v1](http://arxiv.org/abs/2411.13981v1)|null|
|**2024-11-21**|**FedRAV: Hierarchically Federated Region-Learning for Traffic Object Classification of Autonomous Vehicles**|Yijun Zhai et.al.|[2411.13979v1](http://arxiv.org/abs/2411.13979v1)|[link](https://github.com/yjzhai-cs/fedrav)|
|**2024-11-21**|**Separable Mixture of Low-Rank Adaptation for Continual Visual Instruction Tuning**|Ziqi Wang et.al.|[2411.13949v1](http://arxiv.org/abs/2411.13949v1)|null|
|**2024-11-21**|**LLMs as Continuous Learners: Improving the Reproduction of Defective Code in Software Issues**|Yalan Lin et.al.|[2411.13941v1](http://arxiv.org/abs/2411.13941v1)|null|
|**2024-11-21**|**Learning to Cooperate with Humans using Generative Agents**|Yancheng Liang et.al.|[2411.13934v1](http://arxiv.org/abs/2411.13934v1)|[link](https://github.com/lych1233/gamma-human-ai-collaboration)|
|**2024-11-21**|**XAgents: A Framework for Interpretable Rule-Based Multi-Agents Cooperation**|Hailong Yang et.al.|[2411.13932v1](http://arxiv.org/abs/2411.13932v1)|null|
|**2024-11-21**|**Split Federated Learning Over Heterogeneous Edge Devices: Algorithm and Optimization**|Yunrui Sun et.al.|[2411.13907v1](http://arxiv.org/abs/2411.13907v1)|null|
|**2024-11-21**|**Towards Full Delegation: Designing Ideal Agentic Behaviors for Travel Planning**|Song Jiang et.al.|[2411.13904v1](http://arxiv.org/abs/2411.13904v1)|null|
|**2024-11-21**|**AmpliNetECG12: A lightweight SoftMax-based relativistic amplitude amplification architecture for 12 lead ECG classification**|Shreya Srivastava et.al.|[2411.13903v1](http://arxiv.org/abs/2411.13903v1)|null|
|**2024-11-21**|**PIORS: Personalized Intelligent Outpatient Reception based on Large Language Model with Multi-Agents Medical Scenario Simulation**|Zhijie Bao et.al.|[2411.13902v1](http://arxiv.org/abs/2411.13902v1)|null|
|**2024-11-21**|**When Online Algorithms Influence the Environment: A Dynamical Systems Analysis of the Unintended Consequences**|Prabhat Lankireddy et.al.|[2411.13883v1](http://arxiv.org/abs/2411.13883v1)|null|
|**2024-11-21**|**Next-Generation Phishing: How LLM Agents Empower Cyber Attackers**|Khalifa Afane et.al.|[2411.13874v1](http://arxiv.org/abs/2411.13874v1)|null|
|**2024-11-21**|**Robust Detection of Watermarks for Large Language Models Under Human Edits**|Xiang Li et.al.|[2411.13868v1](http://arxiv.org/abs/2411.13868v1)|[link](https://github.com/lx10077/TrGoF)|
|**2024-11-21**|**Generative Fuzzy System for Sequence Generation**|Hailong Yang et.al.|[2411.13867v1](http://arxiv.org/abs/2411.13867v1)|null|
|**2024-11-21**|**HARec: Hyperbolic Graph-LLM Alignment for Exploration and Exploitation in Recommender Systems**|Qiyao Ma et.al.|[2411.13865v1](http://arxiv.org/abs/2411.13865v1)|null|
|**2024-11-21**|**Exploratory Study Of Human-AI Interaction For Hindustani Music**|Nithya Shikarpur et.al.|[2411.13846v1](http://arxiv.org/abs/2411.13846v1)|null|
|**2024-11-21**|**Interactive and Expressive Code-Augmented Planning with Large Language Models**|Anthony Z. Liu et.al.|[2411.13826v1](http://arxiv.org/abs/2411.13826v1)|null|
|**2024-11-21**|**Heterophilic Graph Neural Networks Optimization with Causal Message-passing**|Botao Wang et.al.|[2411.13821v1](http://arxiv.org/abs/2411.13821v1)|null|
|**2024-11-21**|**InstCache: A Predictive Cache for LLM Serving**|Longwei Zou et.al.|[2411.13820v1](http://arxiv.org/abs/2411.13820v1)|null|
|**2024-11-21**|**AutoMixQ: Self-Adjusting Quantization for High Performance Memory-Efficient Fine-Tuning**|Changhai Zhou et.al.|[2411.13814v1](http://arxiv.org/abs/2411.13814v1)|null|
|**2024-11-21**|**SemiKong: Curating, Training, and Evaluating A Semiconductor Industry-Specific Large Language Model**|Christopher Nguyen et.al.|[2411.13802v1](http://arxiv.org/abs/2411.13802v1)|[link](https://github.com/aitomatic/semikong)|
|**2024-11-21**|**Explaining GPT-4's Schema of Depression Using Machine Behavior Analysis**|Adithya V Ganesan et.al.|[2411.13800v1](http://arxiv.org/abs/2411.13800v1)|null|
|**2024-11-21**|**Adaptable Embeddings Network (AEN)**|Stan Loosmore et.al.|[2411.13786v1](http://arxiv.org/abs/2411.13786v1)|null|
|**2024-11-21**|**NewsInterview: a Dataset and a Playground to Evaluate LLMs' Ground Gap via Informational Interviews**|Michael Lu et.al.|[2411.13779v1](http://arxiv.org/abs/2411.13779v1)|[link](https://github.com/alex2awesome/news-interview-question-generation)|
|**2024-11-21**|**Benchmarking GPT-4 against Human Translators: A Comprehensive Evaluation Across Languages, Domains, and Expertise Levels**|Jianhao Yan et.al.|[2411.13775v1](http://arxiv.org/abs/2411.13775v1)|null|
|**2024-11-21**|**FastRAG: Retrieval Augmented Generation for Semi-structured Data**|Amar Abane et.al.|[2411.13773v1](http://arxiv.org/abs/2411.13773v1)|null|
|**2024-11-21**|**An Evaluation-Driven Approach to Designing LLM Agents: Process and Architecture**|Boming Xia et.al.|[2411.13768v1](http://arxiv.org/abs/2411.13768v1)|null|
|**2024-11-21**|**Tiny-Align: Bridging Automatic Speech Recognition and Large Language Model on the Edge**|Ruiyang Qin et.al.|[2411.13766v1](http://arxiv.org/abs/2411.13766v1)|null|
|**2024-11-21**|**A Framework for Evaluating LLMs Under Task Indeterminacy**|Luke Guerdan et.al.|[2411.13760v1](http://arxiv.org/abs/2411.13760v1)|null|
|**2024-11-21**|**AttentionBreaker: Adaptive Evolutionary Optimization for Unmasking Vulnerabilities in LLMs through Bit-Flip Attacks**|Sanjay Das et.al.|[2411.13757v1](http://arxiv.org/abs/2411.13757v1)|null|
|**2024-11-20**|**Learning to Reason Iteratively and Parallelly for Complex Visual Reasoning Scenarios**|Shantanu Jaiswal et.al.|[2411.13754v1](http://arxiv.org/abs/2411.13754v1)|null|
|**2024-11-20**|**AI-Driven Agents with Prompts Designed for High Agreeableness Increase the Likelihood of Being Mistaken for a Human in the Turing Test**|U. León-Domínguez et.al.|[2411.13749v1](http://arxiv.org/abs/2411.13749v1)|null|
|**2024-11-20**|**Federated Continual Learning for Edge-AI: A Comprehensive Survey**|Zi Wang et.al.|[2411.13740v1](http://arxiv.org/abs/2411.13740v1)|null|
|**2024-11-20**|**Assessing Gender Bias in LLMs: Comparing LLM Outputs with Human Perceptions and Official Statistics**|Tetiana Bas et.al.|[2411.13738v1](http://arxiv.org/abs/2411.13738v1)|[link](https://github.com/tetianabas/llm_biases)|
|**2024-11-20**|**Exploring Large Language Models for Climate Forecasting**|Yang Wang et.al.|[2411.13724v1](http://arxiv.org/abs/2411.13724v1)|null|
|**2024-11-20**|**SimPhony: A Device-Circuit-Architecture Cross-Layer Modeling and Simulation Framework for Heterogeneous Electronic-Photonic AI System**|Ziang Yin et.al.|[2411.13715v1](http://arxiv.org/abs/2411.13715v1)|null|
|**2024-11-20**|**Retrieval-Augmented Generation for Domain-Specific Question Answering: A Case Study on Pittsburgh and CMU**|Haojia Sun et.al.|[2411.13691v1](http://arxiv.org/abs/2411.13691v1)|null|
|**2024-11-20**|**Hierarchical Text Classification (HTC) vs. eXtreme Multilabel Classification (XML): Two Sides of the Same Medal**|Nerijus Bertalis et.al.|[2411.13687v1](http://arxiv.org/abs/2411.13687v1)|[link](https://github.com/flohauss/xmc_htc)|
|**2024-11-20**|**Hymba: A Hybrid-head Architecture for Small Language Models**|Xin Dong et.al.|[2411.13676v1](http://arxiv.org/abs/2411.13676v1)|null|
|**2024-11-20**|**No Free Delivery Service: Epistemic limits of passive data collection in complex social systems**|Maximilian Nickel et.al.|[2411.13653v1](http://arxiv.org/abs/2411.13653v1)|null|
|**2024-11-20**|**SpecTool: A Benchmark for Characterizing Errors in Tool-Use LLMs**|Shirley Kokane et.al.|[2411.13547v1](http://arxiv.org/abs/2411.13547v1)|null|
|**2024-11-20**|**BALROG: Benchmarking Agentic LLM and VLM Reasoning On Games**|Davide Paglieri et.al.|[2411.13543v1](http://arxiv.org/abs/2411.13543v1)|null|
|**2024-11-20**|**Metacognition for Unknown Situations and Environments (MUSE)**|Rodolfo Valiente et.al.|[2411.13537v1](http://arxiv.org/abs/2411.13537v1)|null|
|**2024-11-20**|**Identity Preserving 3D Head Stylization with Multiview Score Distillation**|Bahri Batuhan Bilecen et.al.|[2411.13536v1](http://arxiv.org/abs/2411.13536v1)|null|
|**2024-11-20**|**Predictive Insights into LGBTQ+ Minority Stress: A Transductive Exploration of Social Media Discourse**|S. Chapagain et.al.|[2411.13534v1](http://arxiv.org/abs/2411.13534v1)|[link](https://github.com/chapagaisa/transductive)|
|**2024-11-20**|**Advancing Complex Medical Communication in Arabic with Sporo AraSum: Surpassing Existing Large Language Models**|Chanseo Lee et.al.|[2411.13518v1](http://arxiv.org/abs/2411.13518v1)|null|
|**2024-11-20**|**Disentangling Memory and Reasoning Ability in Large Language Models**|Mingyu Jin et.al.|[2411.13504v2](http://arxiv.org/abs/2411.13504v2)|[link](https://github.com/mingyuj666/disentangling-memory-and-reasoning)|
|**2024-11-20**|**Utilizing Large Language Models to Synthesize Product Desirability Datasets**|John D. Hastings et.al.|[2411.13485v1](http://arxiv.org/abs/2411.13485v1)|null|
|**2024-11-20**|**PatentEdits: Framing Patent Novelty as Textual Entailment**|Ryan Lee et.al.|[2411.13477v1](http://arxiv.org/abs/2411.13477v1)|null|
|**2024-11-20**|**When Precision Meets Position: BFloat16 Breaks Down RoPE in Long-Context Training**|Haonan Wang et.al.|[2411.13476v1](http://arxiv.org/abs/2411.13476v1)|[link](https://github.com/haonan3/anchorcontext)|
|**2024-11-20**|**SoK: A Systems Perspective on Compound AI Threats and Countermeasures**|Sarbartha Banerjee et.al.|[2411.13459v1](http://arxiv.org/abs/2411.13459v1)|null|

#### Abstracts
##### **Whack-a-Chip: The Futility of Hardware-Centric Export Controls**
2411.14425v1 by Ritwik Gupta, Leah Walker, Andrew W. Reddie

U.S. export controls on semiconductors are widely known to be permeable, with
the People's Republic of China (PRC) steadily creating state-of-the-art
artificial intelligence (AI) models with exfiltrated chips. This paper presents
the first concrete, public evidence of how leading PRC AI labs evade and
circumvent U.S. export controls. We examine how Chinese companies, notably
Tencent, are not only using chips that are restricted under U.S. export
controls but are also finding ways to circumvent these regulations by using
software and modeling techniques that maximize less capable hardware.
Specifically, we argue that Tencent's ability to power its Hunyuan-Large model
with non-export controlled NVIDIA H20s exemplifies broader gains in efficiency
in machine learning that have eroded the moat that the United States initially
built via its existing export controls. Finally, we examine the implications of
this finding for the future of the United States' export control strategy.

摘要：美國對半導體的出口管制措施眾所周知是具有滲透性的，而中華人民共和國（PRC）則持續透過外洩的晶片打造最先進的人工智慧（AI）模型。本文提出第一個具體的公開證據，說明中國領先的 AI 實驗室如何規避和繞過美國的出口管制。我們探討中國公司，尤其是騰訊，如何不僅使用美國出口管制限制的晶片，還透過使用軟體和建模技術，最大化功能較弱的硬體，來找出規避這些法規的方法。具體來說，我們認為騰訊能夠使用非出口管制的 NVIDIA H20s 來為其 Hunyuan-Large 模型供電，這說明了機器學習效率的更廣泛提升，而這已侵蝕了美國最初透過其現有出口管制措施所建立的護城河。最後，我們探討這一發現對美國未來出口管制策略的影響。

##### **Marco-o1: Towards Open Reasoning Models for Open-Ended Solutions**
2411.14405v1 by Yu Zhao, Huifeng Yin, Bo Zeng, Hao Wang, Tianqi Shi, Chenyang Lyu, Longyue Wang, Weihua Luo, Kaifu Zhang

Currently OpenAI o1 has sparked a surge of interest in the study of large
reasoning models (LRM). Building on this momentum, Marco-o1 not only focuses on
disciplines with standard answers, such as mathematics, physics, and coding --
which are well-suited for reinforcement learning (RL) -- but also places
greater emphasis on open-ended resolutions. We aim to address the question:
"Can the o1 model effectively generalize to broader domains where clear
standards are absent and rewards are challenging to quantify?" Marco-o1 is
powered by Chain-of-Thought (CoT) fine-tuning, Monte Carlo Tree Search (MCTS),
reflection mechanisms, and innovative reasoning strategies -- optimized for
complex real-world problem-solving tasks.

摘要：目前，OpenAI o1 在大型推理模型 (LRM) 研究領域引起了極大的興趣。馬可 o1 不僅專注於具有標準答案的學科，例如數學、物理和編碼，這些學科非常適合強化學習 (RL)，還更加強調開放式的解決方案。我們的目標是解決這個問題：「o1 模型是否可以有效地概括到缺乏明確標準且獎勵難以量化的更廣泛領域？」馬可 o1 由思想鏈 (CoT) 微調、蒙地卡羅樹搜尋 (MCTS)、反思機制和創新推理策略提供支援，這些策略經過優化，可用於解決複雜的現實世界問題。

##### **Resolving Multiple-Dynamic Model Uncertainty in Hypothesis-Driven Belief-MDPs**
2411.14404v1 by Ofer Dagan, Tyler Becker, Zachary N. Sunberg

When human operators of cyber-physical systems encounter surprising behavior,
they often consider multiple hypotheses that might explain it. In some cases,
taking information-gathering actions such as additional measurements or control
inputs given to the system can help resolve uncertainty and determine the most
accurate hypothesis. The task of optimizing these actions can be formulated as
a belief-space Markov decision process that we call a hypothesis-driven belief
MDP. Unfortunately, this problem suffers from the curse of history similar to a
partially observable Markov decision process (POMDP). To plan in continuous
domains, an agent needs to reason over countlessly many possible
action-observation histories, each resulting in a different belief over the
unknown state. The problem is exacerbated in the hypothesis-driven context
because each action-observation pair spawns a different belief for each
hypothesis, leading to additional branching. This paper considers the case in
which each hypothesis corresponds to a different dynamic model in an underlying
POMDP. We present a new belief MDP formulation that: (i) enables reasoning over
multiple hypotheses, (ii) balances the goals of determining the (most likely)
correct hypothesis and performing well in the underlying POMDP, and (iii) can
be solved with sparse tree search.

摘要：當網路物理系統的人類操作員遇到令人驚訝的行為時，他們通常會考慮多種假設來解釋它。在某些情況下，採取資訊收集動作（例如額外的量測或給予系統的控制輸入）有助於解決不確定性並確定最準確的假設。最佳化這些動作的任務可以表述為一個信念空間馬可夫決策過程，我們稱之為假設驅動信念 MDP。不幸的是，這個問題與部分可觀察馬可夫決策過程 (POMDP) 類似，會受到歷史詛咒的影響。要在連續領域中規劃，代理需要對無數可能的動作觀察歷史進行推理，每個歷史都會導致對未知狀態的不同信念。這個問題在假設驅動的背景下會更加惡化，因為每對動作觀察會為每個假設產生不同的信念，導致額外的分支。本文考慮了每個假設在基礎 POMDP 中對應於不同動態模型的情況。我們提出一個新的信念 MDP 公式，它：(i) 能夠對多個假設進行推理，(ii) 平衡確定（最可能）正確假設和在基礎 POMDP 中表現良好的目標，以及 (iii) 可以透過稀疏樹搜尋來解決。

##### **Landing Trajectory Prediction for UAS Based on Generative Adversarial Network**
2411.14403v1 by Jun Xiang, Drake Essick, Luiz Gonzalez Bautista, Junfei Xie, Jun Chen

Models for trajectory prediction are an essential component of many advanced
air mobility studies. These models help aircraft detect conflict and plan
avoidance maneuvers, which is especially important in Unmanned Aircraft systems
(UAS) landing management due to the congested airspace near vertiports. In this
paper, we propose a landing trajectory prediction model for UAS based on
Generative Adversarial Network (GAN). The GAN is a prestigious neural network
that has been developed for many years. In previous research, GAN has achieved
many state-of-the-art results in many generation tasks. The GAN consists of one
neural network generator and a neural network discriminator. Because of the
learning capacity of the neural networks, the generator is capable to
understand the features of the sample trajectory. The generator takes the
previous trajectory as input and outputs some random status of a flight.
According to the results of the experiences, the proposed model can output more
accurate predictions than the baseline method(GMR) in various datasets. To
evaluate the proposed model, we also create a real UAV landing dataset that
includes more than 2600 trajectories of drone control manually by real pilots.

摘要：航跡預測模型是許多先進空中流動性研究中不可或缺的組成部分。這些模型有助於飛機偵測衝突並規劃避讓動作，這在無人機系統（UAS）著陸管理中尤其重要，這是因為垂直起降機場附近的空域壅塞。在本文中，我們提出一個基於生成對抗網路（GAN）的 UAS 著陸航跡預測模型。GAN 是一個久負盛名的神經網路，已經發展多年。在先前的研究中，GAN 在許多生成任務中取得許多最先進的成果。GAN 包含一個神經網路產生器和一個神經網路判別器。由於神經網路的學習能力，產生器能夠了解樣本航跡的特徵。產生器將先前的航跡作為輸入，並輸出飛行的某些隨機狀態。根據經驗結果，所提出的模型可以在各種資料集中輸出比基線方法（GMR）更準確的預測。為了評估所提出的模型，我們還建立了一個真實的無人機著陸資料集，其中包含超過 2600 條由真實飛行員手動控制的無人機航跡。

##### **Lightweight Safety Guardrails Using Fine-tuned BERT Embeddings**
2411.14398v1 by Aaron Zheng, Mansi Rana, Andreas Stolcke

With the recent proliferation of large language models (LLMs), enterprises
have been able to rapidly develop proof-of-concepts and prototypes. As a
result, there is a growing need to implement robust guardrails that monitor,
quantize and control an LLM's behavior, ensuring that the use is reliable,
safe, accurate and also aligned with the users' expectations. Previous
approaches for filtering out inappropriate user prompts or system outputs, such
as LlamaGuard and OpenAI's MOD API, have achieved significant success by
fine-tuning existing LLMs. However, using fine-tuned LLMs as guardrails
introduces increased latency and higher maintenance costs, which may not be
practical or scalable for cost-efficient deployments. We take a different
approach, focusing on fine-tuning a lightweight architecture: Sentence-BERT.
This method reduces the model size from LlamaGuard's 7 billion parameters to
approximately 67 million, while maintaining comparable performance on the AEGIS
safety benchmark.

摘要：隨著大型語言模型 (LLM) 的快速擴散，企業已能快速開發概念驗證和原型。因此，越來越需要實施強固的防護措施，以監控、量化和控制 LLM 的行為，確保使用可靠、安全、準確，且符合使用者的預期。先前用於過濾不適當使用者提示或系統輸出的方法，例如 LlamaGuard 和 OpenAI 的 MOD API，已透過微調現有的 LLM 而獲得顯著的成功。然而，使用微調的 LLM 作為防護措施會增加延遲和更高的維護成本，這對於經濟高效的部署而言可能不切實際或無法擴展。我們採用不同的方法，專注於微調輕量級架構：Sentence-BERT。此方法將模型大小從 LlamaGuard 的 70 億個參數減少到約 6,700 萬個，同時在 AEGIS 安全基準上維持相當的效能。

##### **POS-tagging to highlight the skeletal structure of sentences**
2411.14393v1 by Grigorii Churakov

This study presents the development of a part-of-speech (POS) tagging model
to extract the skeletal structure of sentences using transfer learning with the
BERT architecture for token classification. The model, fine-tuned on Russian
text, demonstrating its effectiveness. The approach offers potential
applications in enhancing natural language processing tasks, such as improving
machine translation.
  Keywords: part of speech tagging, morphological analysis, natural language
processing, BERT.

摘要：本研究提出了一個詞性標記模型的開發
使用 BERT 架構進行標記分類，以轉移學習來提取句子的骨架結構。該模型針對俄語文本進行微調，證明了其有效性。此方法提供了增強自然語言處理任務的潛在應用，例如改進機器翻譯。
關鍵字：詞性標記、形態分析、自然語言處理、BERT。

##### **Using Formal Models, Safety Shields and Certified Control to Validate AI-Based Train Systems**
2411.14374v1 by Jan Gruteser, Jan Roßbach, Fabian Vu, Michael Leuschel

The certification of autonomous systems is an important concern in science
and industry. The KI-LOK project explores new methods for certifying and safely
integrating AI components into autonomous trains. We pursued a two-layered
approach: (1) ensuring the safety of the steering system by formal analysis
using the B method, and (2) improving the reliability of the perception system
with a runtime certificate checker. This work links both strategies within a
demonstrator that runs simulations on the formal model, controlled by the real
AI output and the real certificate checker. The demonstrator is integrated into
the validation tool ProB. This enables runtime monitoring, runtime
verification, and statistical validation of formal safety properties using a
formal B model. Consequently, one can detect and analyse potential
vulnerabilities and weaknesses of the AI and the certificate checker. We apply
these techniques to a signal detection case study and present our findings.

摘要：自主系統的認證是科學和產業中的重要課題。KI-LOK 計畫探索用於認證和安全地將 AI 元件整合到自動駕駛火車中的新方法。我們採用了雙層方法：(1) 使用 B 方法透過形式化分析確保轉向系統的安全，以及 (2) 使用執行時期證書檢查器來提升感知系統的可靠性。此項工作在一個示範程式中連結了這兩種策略，在形式化模型上執行模擬，由實際的 AI 輸出和實際的證書檢查器控制。此示範程式整合到驗證工具 ProB 中。這能使用形式化 B 模型進行執行時期監控、執行時期驗證和形式化安全屬性的統計驗證。因此，可以偵測和分析 AI 和證書檢查器的潛在漏洞和弱點。我們將這些技術應用於訊號偵測案例研究，並提出我們的發現。

##### **Synthesising Robust Controllers for Robot Collectives with Recurrent Tasks: A Case Study**
2411.14371v1 by Till Schnittka, Mario Gleirscher

When designing correct-by-construction controllers for autonomous
collectives, three key challenges are the task specification, the modelling,
and its use at practical scale. In this paper, we focus on a simple yet useful
abstraction for high-level controller synthesis for robot collectives with
optimisation goals (e.g., maximum cleanliness, minimum energy consumption) and
recurrence (e.g., re-establish contamination and charge thresholds) and safety
(e.g., avoid full discharge, mutually exclusive room occupation) constraints.
Due to technical limitations (related to scalability and using constraints in
the synthesis), we simplify our graph-based setting from a stochastic
two-player game into a single-player game on a partially observable Markov
decision process (POMDP). Robustness against environmental uncertainty is
encoded via partial observability. Linear-time correctness properties are
verified separately after synthesising the POMDP strategy. We contribute
at-scale guidance on POMDP modelling and controller synthesis for tasked robot
collectives exemplified by the scenario of battery-driven robots responsible
for cleaning public buildings with utilisation constraints.

摘要：在為自主集體設計正確的建構控制器時，有三個主要的挑戰：任務規範、建模，以及在實際規模下的使用。在本文中，我們專注於一個簡單但有用的抽象化，用於具有最佳化目標（例如，最大清潔度、最低能源消耗）和遞迴（例如，重新建立污染和充電閾值）以及安全（例如，避免完全放電、相互排斥的房間佔用）約束的機器人集體的高階控制器合成。由於技術限制（與擴充性和在合成中使用約束有關），我們將基於圖表的設定從隨機雙人遊戲簡化為部分可觀察馬可夫決策過程 (POMDP) 中的單人遊戲。對環境不確定性的魯棒性通過部分可觀察性編碼。線性時間正確性屬性在合成 POMDP 策略後單獨驗證。我們為任務機器人集體的 POMDP 建模和控制器合成提供了大規模指導，這些集體以負責在利用約束下清潔公共建築的電池驅動機器人為例。

##### **Contrasting local and global modeling with machine learning and satellite data: A case study estimating tree canopy height in African savannas**
2411.14354v1 by Esther Rolf, Lucia Gordon, Milind Tambe, Andrew Davies

While advances in machine learning with satellite imagery (SatML) are
facilitating environmental monitoring at a global scale, developing SatML
models that are accurate and useful for local regions remains critical to
understanding and acting on an ever-changing planet. As increasing attention
and resources are being devoted to training SatML models with global data, it
is important to understand when improvements in global models will make it
easier to train or fine-tune models that are accurate in specific regions. To
explore this question, we contrast local and global training paradigms for
SatML through a case study of tree canopy height (TCH) mapping in the Karingani
Game Reserve, Mozambique. We find that recent advances in global TCH mapping do
not necessarily translate to better local modeling abilities in our study
region. Specifically, small models trained only with locally-collected data
outperform published global TCH maps, and even outperform globally pretrained
models that we fine-tune using local data. Analyzing these results further, we
identify specific points of conflict and synergy between local and global
modeling paradigms that can inform future research toward aligning local and
global performance objectives in geospatial machine learning.

摘要：雖然機器學習與衛星影像（SatML）的進展促進了全球環境監測，但開發出對局部地區準確且有用的 SatML 模型對於理解和應對不斷變化的地球仍然至關重要。隨著越來越多的關注和資源投入到使用全球數據訓練 SatML 模型，了解何時全球模型的改進將使訓練或微調特定區域準確的模型變得更容易，這一點非常重要。為了探討這個問題，我們通過莫三比克卡林加尼野生動物保護區的樹冠高度（TCH）製圖案例研究，對比了 SatML 的局部和全球訓練範例。我們發現，全球 TCH 製圖的最新進展並非一定能轉化為我們研究區域中更好的局部建模能力。具體來說，僅使用當地收集的數據訓練的小模型優於已發布的全球 TCH 地圖，甚至優於我們使用當地數據微調的全球預訓練模型。進一步分析這些結果，我們找出了局部和全球建模範例之間衝突和協同作用的具體點，這些點可以為未來的研究提供信息，以調整地理空間機器學習中的局部和全球性能目標。

##### **UnifiedCrawl: Aggregated Common Crawl for Affordable Adaptation of LLMs on Low-Resource Languages**
2411.14343v1 by Bethel Melesse Tessema, Akhil Kedia, Tae-Sun Chung

Large language models (LLMs) under-perform on low-resource languages due to
limited training data. We present a method to efficiently collect text data for
low-resource languages from the entire Common Crawl corpus. Our approach,
UnifiedCrawl, filters and extracts common crawl using minimal compute
resources, yielding mono-lingual datasets much larger than previously available
sources. We demonstrate that leveraging this data to fine-tuning multilingual
LLMs via efficient adapter methods (QLoRA) significantly boosts performance on
the low-resource language, while minimizing VRAM usage. Our experiments show
large improvements in language modeling perplexity and an increase in few-shot
prompting scores. Our work and released source code provide an affordable
approach to improve LLMs for low-resource languages using consumer hardware.
Our source code is available here at
https://github.com/bethelmelesse/unifiedcrawl.

摘要：由於訓練資料有限，大型語言模型 (LLM) 在低資源語言上的表現不佳。我們提出了一種方法，可以從整個 Common Crawl 語料庫中有效地收集低資源語言的文字資料。我們的 UnifiedCrawl 方法使用最少的運算資源來過濾和擷取 Common Crawl，產生比先前可用的來源大得多的單一語言資料集。我們證明利用這些資料微調多語言 LLM，透過有效率的適配器方法 (QLoRA)，可以大幅提升低資源語言的效能，同時將 VRAM 使用量降至最低。我們的實驗顯示，語言模型困惑度大幅改善，且少次提示分數增加。我們的研究和釋出的原始碼提供了一種經濟實惠的方法，可以使用消費者硬體改善低資源語言的 LLM。我們的原始碼可在以下位置取得：https://github.com/bethelmelesse/unifiedcrawl。

##### **Velocitune: A Velocity-based Dynamic Domain Reweighting Method for Continual Pre-training**
2411.14318v1 by Zheheng Luo, Xin Zhang, Xiao Liu, Haoling Li, Yeyun Gong, Chen Qi, Peng Cheng

It is well-known that a diverse corpus is critical for training large
language models, which are typically constructed from a mixture of various
domains. In general, previous efforts resort to sampling training data from
different domains with static proportions, as well as adjusting data
proportions during training. However, few methods have addressed the
complexities of domain-adaptive continual pre-training. To fill this gap, we
propose Velocitune, a novel framework dynamically assesses learning velocity
and adjusts data proportions accordingly, favoring slower-learning domains
while shunning faster-learning ones, which is guided by a scaling law to
indicate the desired learning goal for each domain with less associated cost.
To evaluate the effectiveness of Velocitune, we conduct experiments in a
reasoning-focused dataset with CodeLlama, as well as in a corpus specialised
for system command generation with Llama3 and Mistral. Velocitune achieves
performance gains in both math and code reasoning tasks and command-line
generation benchmarks. Further analysis reveals that key factors driving
Velocitune's effectiveness include target loss prediction and data ordering.

摘要：众所周知，多样化的语料库对于训练大型语言模型至关重要，而大型语言模型通常由来自不同领域的数据混合构建而成。一般来说，之前的研究诉诸于以静态比例从不同领域采样训练数据，以及在训练期间调整数据比例。然而，很少有方法解决域自适应持续预训练的复杂性。为了填补这一空白，我们提出了 Velocitune，这是一个新颖的框架，可以动态评估学习速度并相应地调整数据比例，偏爱学习较慢的领域，同时回避学习较快的领域，这由一个比例定律指导，以较低的相关成本为每个领域指示所需的学习目标。为了评估 Velocitune 的有效性，我们在一个以推理为重点的数据集中使用 CodeLlama 进行了实验，以及在一个专门用于使用 Llama3 和 Mistral 生成系统命令的语料库中进行了实验。Velocitune 在数学和代码推理任务以及命令行生成基准测试中都取得了性能提升。进一步的分析表明，推动 Velocitune 有效性的关键因素包括目标损失预测和数据排序。

##### **Automated Generation of Code Debugging Exercises**
2411.14303v1 by Victor-Alexandru Pădurean, Paul Denny, Adish Singla

Debugging is an essential skill when learning to program, yet its instruction
and emphasis often vary widely across introductory courses. In the era of
code-generating large language models (LLMs), the ability for students to
reason about code and identify errors is increasingly important. However,
students frequently resort to trial-and-error methods to resolve bugs without
fully understanding the underlying issues. Developing the ability to identify
and hypothesize the cause of bugs is crucial but can be time-consuming to teach
effectively through traditional means. This paper introduces BugSpotter, an
innovative tool that leverages an LLM to generate buggy code from a problem
description and verify the synthesized bugs via a test suite. Students interact
with BugSpotter by designing failing test cases, where the buggy code's output
differs from the expected result as defined by the problem specification. This
not only provides opportunities for students to enhance their debugging skills,
but also to practice reading and understanding problem specifications. We
deployed BugSpotter in a large classroom setting and compared the debugging
exercises it generated to exercises hand-crafted by an instructor for the same
problems. We found that the LLM-generated exercises produced by BugSpotter
varied in difficulty and were well-matched to the problem specifications.
Importantly, the LLM-generated exercises were comparable to those manually
created by instructors with respect to student performance, suggesting that
BugSpotter could be an effective and efficient aid for learning debugging.

摘要：<paragraph>除錯是學習程式設計時必備的技能，但其教學和重點在各入門課程中往往差異很大。在產生程式碼的大型語言模型（LLM）的時代，學生推理程式碼和找出錯誤的能力越來越重要。然而，學生常常訴諸試錯法來解決錯誤，而沒有完全理解其背後的根本問題。培養找出錯誤並對其成因提出假設的能力至關重要，但透過傳統方式有效地教授這項能力可能很耗時。本文介紹了 BugSpotter，這是一個創新的工具，它利用 LLM 從問題描述中產生有錯誤的程式碼，並透過測試套件驗證合成的錯誤。學生透過設計失敗的測試案例與 BugSpotter 互動，其中有錯誤的程式碼輸出與問題規格所定義的預期結果不同。這不僅能提供學生增進其除錯技能的機會，還能練習閱讀和理解問題規格。我們在一個大型教室環境中部署了 BugSpotter，並將其產生的除錯練習與由教師親自為相同問題設計的練習進行比較。我們發現，BugSpotter 產生的 LLM 練習難度不一，且與問題規格十分相符。重要的是，LLM 產生的練習在學生表現方面與人工產生的練習相當，這表明 BugSpotter 可能是學習除錯的有效且高效的輔助工具。</paragraph>

##### **Looking Beyond Text: Reducing Language bias in Large Vision-Language Models via Multimodal Dual-Attention and Soft-Image Guidance**
2411.14279v1 by Haozhe Zhao, Shuzheng Si, Liang Chen, Yichi Zhang, Maosong Sun, Mingjia Zhang, Baobao Chang

Large vision-language models (LVLMs) have achieved impressive results in
various vision-language tasks. However, despite showing promising performance,
LVLMs suffer from hallucinations caused by language bias, leading to diminished
focus on images and ineffective visual comprehension. We identify two primary
reasons for this bias: 1. Different scales of training data between the
pretraining stage of LLM and multimodal alignment stage. 2. The learned
inference bias due to short-term dependency of text data. Therefore, we propose
LACING, a systemic framework designed to address the language bias of LVLMs
with muLtimodal duAl-attention meChanIsm (MDA) aNd soft-image Guidance (IFG).
Specifically, MDA introduces a parallel dual-attention mechanism that enhances
the integration of visual inputs across the model. IFG introduces a learnable
soft visual prompt during training and inference to replace visual inputs,
designed to compel LVLMs to prioritize text inputs. Then, IFG further proposes
a novel decoding strategy using the soft visual prompt to mitigate the model's
over-reliance on adjacent text inputs. Comprehensive experiments demonstrate
that our method effectively debiases LVLMs from their language bias, enhancing
visual comprehension and reducing hallucinations without requiring additional
training resources or data. The code and model are available at
[lacing-lvlm.github.io](https://lacing-lvlm.github.io).

摘要：大型視覺語言模型 (LVLMs) 已在各種視覺語言任務中取得令人印象深刻的成果。然而，儘管表現出令人滿意的效能，LVLMs 仍會因語言偏誤而產生幻覺，導致對影像的關注度降低和視覺理解力不佳。我們找出造成這種偏誤的兩個主要原因：1. LLM 預訓練階段與多模態對齊階段的訓練資料規模不同。2. 由於文字資料的短期依賴性所產生的學習推論偏誤。因此，我們提出 LACING，一個系統性框架，旨在透過多模態雙注意力機制 (MDA) 和軟影像引導 (IFG) 來解決 LVLMs 的語言偏誤。具體來說，MDA 引入一個平行的雙注意力機制，增強模型中視覺輸入的整合。IFG 在訓練和推論期間引入一個可學習的軟視覺提示，以取代視覺輸入，旨在迫使 LVLMs 優先考慮文字輸入。然後，IFG 進一步提出一個新的解碼策略，使用軟視覺提示來減輕模型對相鄰文字輸入的過度依賴。全面的實驗證明，我們的模型有效地消除了 LVLMs 的語言偏誤，增強了視覺理解力，並減少了幻覺，而不需要額外的訓練資源或資料。程式碼和模型可在 [lacing-lvlm.github.io](https://lacing-lvlm.github.io) 取得。

##### **Neuro-Symbolic Query Optimization in Knowledge Graphs**
2411.14277v1 by Maribel Acosta, Chang Qin, Tim Schwabe

This chapter delves into the emerging field of neuro-symbolic query
optimization for knowledge graphs (KGs), presenting a comprehensive exploration
of how neural and symbolic techniques can be integrated to enhance query
processing. Traditional query optimizers in knowledge graphs rely heavily on
symbolic methods, utilizing dataset summaries, statistics, and cost models to
select efficient execution plans. However, these approaches often suffer from
misestimations and inaccuracies, particularly when dealing with complex queries
or large-scale datasets. Recent advancements have introduced neural models,
which capture non-linear aspects of query optimization, offering promising
alternatives to purely symbolic methods. In this chapter, we introduce
neuro-symbolic query optimizers, a novel approach that combines the strengths
of symbolic reasoning with the adaptability of neural computation. We discuss
the architecture of these hybrid systems, highlighting the interplay between
neural and symbolic components to improve the optimizer's ability to navigate
the search space and produce efficient execution plans. Additionally, the
chapter reviews existing neural components tailored for optimizing queries over
knowledge graphs and examines the limitations and challenges in deploying
neuro-symbolic query optimizers in real-world environments.

摘要：本章深入探討知識圖譜 (KG) 的新興領域神經符號查詢最佳化，全面探討如何整合神經和符號技術以增強查詢處理。知識圖譜中的傳統查詢最佳化器高度依賴符號方法，利用資料集摘要、統計資料和成本模型來選擇有效率的執行計畫。然而，這些方法通常會產生錯誤估計和不準確的結果，特別是在處理複雜查詢或大型資料集時。最近的進展引入了神經模型，它能捕捉查詢最佳化的非線性面向，提供純粹符號方法的有希望的替代方案。在本章中，我們介紹神經符號查詢最佳化器，這是一種新穎的方法，結合符號推理的優點和神經運算的適應性。我們討論這些混合系統的架構，強調神經和符號元件之間的交互作用，以提高最佳化器導航搜尋空間和產生有效率執行計畫的能力。此外，本章回顧了針對最佳化知識圖譜查詢而量身打造的現有神經元件，並探討在現實環境中部署神經符號查詢最佳化器的限制和挑戰。

##### **Efficient Aspect-Based Summarization of Climate Change Reports with Small Language Models**
2411.14272v1 by Iacopo Ghinassi, Leonardo Catalano, Tommaso Colella

The use of Natural Language Processing (NLP) for helping decision-makers with
Climate Change action has recently been highlighted as a use case aligning with
a broader drive towards NLP technologies for social good. In this context,
Aspect-Based Summarization (ABS) systems that extract and summarize relevant
information are particularly useful as they provide stakeholders with a
convenient way of finding relevant information in expert-curated reports. In
this work, we release a new dataset for ABS of Climate Change reports and we
employ different Large Language Models (LLMs) and so-called Small Language
Models (SLMs) to tackle this problem in an unsupervised way. Considering the
problem at hand, we also show how SLMs are not significantly worse for the
problem while leading to reduced carbon footprint; we do so by applying for the
first time an existing framework considering both energy efficiency and task
performance to the evaluation of zero-shot generative models for ABS. Overall,
our results show that modern language models, both big and small, can
effectively tackle ABS for Climate Change reports but more research is needed
when we frame the problem as a Retrieval Augmented Generation (RAG) problem and
our work and dataset will help foster efforts in this direction.

摘要：自然語言處理 (NLP) 用於協助決策者採取氣候變遷行動，最近被強調為與更廣泛推動 NLP 技術用於社會公益的用例一致。在此背景下，擷取和摘要相關資訊的面向面向摘要 (ABS) 系統特別有用，因為它們為利害關係人提供一種便利的方式，可以在專家策劃的報告中找到相關資訊。在這項工作中，我們發布了一個新的 ABS 氣候變遷報告資料集，並且我們使用不同的大型語言模型 (LLM) 和所謂的小型語言模型 (SLM) 以無監督的方式來解決這個問題。考量手邊的問題，我們也展示了 SLM 對於這個問題並未顯著惡化，同時導致碳足跡減少；我們這樣做是首次應用現有架構，考量能源效率和任務效能來評估 ABS 的零次學習生成模型。整體而言，我們的結果顯示，無論大小，現代語言模型都能有效處理氣候變遷報告的 ABS，但當我們將問題設定為檢索擴充生成 (RAG) 問題時，需要更多研究，而我們的研究和資料集將有助於促進朝此方向的努力。

##### **Generating Realistic Adversarial Examples for Business Processes using Variational Autoencoders**
2411.14263v1 by Alexander Stevens, Jari Peeperkorn, Johannes De Smedt, Jochen De Weerdt

In predictive process monitoring, predictive models are vulnerable to
adversarial attacks, where input perturbations can lead to incorrect
predictions. Unlike in computer vision, where these perturbations are designed
to be imperceptible to the human eye, the generation of adversarial examples in
predictive process monitoring poses unique challenges. Minor changes to the
activity sequences can create improbable or even impossible scenarios to occur
due to underlying constraints such as regulatory rules or process constraints.
To address this, we focus on generating realistic adversarial examples tailored
to the business process context, in contrast to the imperceptible, pixel-level
changes commonly seen in computer vision adversarial attacks. This paper
introduces two novel latent space attacks, which generate adversaries by adding
noise to the latent space representation of the input data, rather than
directly modifying the input attributes. These latent space methods are
domain-agnostic and do not rely on process-specific knowledge, as we restrict
the generation of adversarial examples to the learned class-specific data
distributions by directly perturbing the latent space representation of the
business process executions. We evaluate these two latent space methods with
six other adversarial attacking methods on eleven real-life event logs and four
predictive models. The first three attacking methods directly permute the
activities of the historically observed business process executions. The fourth
method constrains the adversarial examples to lie within the same data
distribution as the original instances, by projecting the adversarial examples
to the original data distribution.

摘要：在预测过程监控中，预测模型容易受到对抗性攻击，输入扰动可能导致预测不正确。与计算机视觉中这些扰动被设计为对人眼不可察觉不同，在预测过程监控中生成对抗性示例提出了独特的挑战。由于法规规则或过程约束等基本约束，活动序列的微小变化可能会产生不可能甚至不可能发生的场景。为了解决这个问题，我们专注于生成针对业务流程上下文的现实对抗性示例，这与计算机视觉对抗性攻击中常见的不可察觉的像素级变化形成对比。本文介绍了两种新颖的潜在空间攻击，它们通过向输入数据的潜在空间表示添加噪声来生成对抗者，而不是直接修改输入属性。这些潜在空间方法与域无关，并且不依赖于特定于过程的知识，因为我们将对抗性示例的生成限制在学习的特定于类的分布数据上，通过直接扰动业务流程执行的潜在空间表示。我们使用六种其他对抗性攻击方法在十一个真实事件日志和四个预测模型上评估了这两种潜在空间方法。前三种攻击方法直接排列历史观察到的业务流程执行的活动。第四种方法通过将对抗性示例投影到原始数据分布，将对抗性示例限制在与原始实例相同的分布中。

##### **Knowledge Graphs, Large Language Models, and Hallucinations: An NLP Perspective**
2411.14258v1 by Ernests Lavrinovics, Russa Biswas, Johannes Bjerva, Katja Hose

Large Language Models (LLMs) have revolutionized Natural Language Processing
(NLP) based applications including automated text generation, question
answering, chatbots, and others. However, they face a significant challenge:
hallucinations, where models produce plausible-sounding but factually incorrect
responses. This undermines trust and limits the applicability of LLMs in
different domains. Knowledge Graphs (KGs), on the other hand, provide a
structured collection of interconnected facts represented as entities (nodes)
and their relationships (edges). In recent research, KGs have been leveraged to
provide context that can fill gaps in an LLM understanding of certain topics
offering a promising approach to mitigate hallucinations in LLMs, enhancing
their reliability and accuracy while benefiting from their wide applicability.
Nonetheless, it is still a very active area of research with various unresolved
open problems. In this paper, we discuss these open challenges covering
state-of-the-art datasets and benchmarks as well as methods for knowledge
integration and evaluating hallucinations. In our discussion, we consider the
current use of KGs in LLM systems and identify future directions within each of
these challenges.

摘要：大型語言模型（LLM）徹底改變了基於自然語言處理（NLP）的應用，包括自動文字生成、問題解答、聊天機器人等。然而，它們面臨著一個重大的挑戰：幻覺，模型產生聽起來合理但事實上不正確的回應。這會破壞信任，並限制 LLM 在不同領域的適用性。另一方面，知識圖譜（KG）提供了以實體（節點）及其關係（邊緣）表示的相互連接事實的結構化集合。在最近的研究中，KG 已被用於提供上下文，可以填補 LLM 對某些主題理解的空白，提供了一種有希望的方法來減輕 LLM 中的幻覺，提高它們的可靠性和準確性，同時受益於它們的廣泛適用性。儘管如此，這仍然是一個非常活躍的研究領域，有各種未解決的開放問題。在本文中，我們討論了這些開放挑戰，涵蓋了最先進的數據集和基準，以及知識整合和評估幻覺的方法。在我們的討論中，我們考慮了 LLM 系統中 KG 的當前使用，並確定了這些挑戰中的每一個未來的方向。

##### **Do I Know This Entity? Knowledge Awareness and Hallucinations in Language Models**
2411.14257v1 by Javier Ferrando, Oscar Obeso, Senthooran Rajamanoharan, Neel Nanda

Hallucinations in large language models are a widespread problem, yet the
mechanisms behind whether models will hallucinate are poorly understood,
limiting our ability to solve this problem. Using sparse autoencoders as an
interpretability tool, we discover that a key part of these mechanisms is
entity recognition, where the model detects if an entity is one it can recall
facts about. Sparse autoencoders uncover meaningful directions in the
representation space, these detect whether the model recognizes an entity, e.g.
detecting it doesn't know about an athlete or a movie. This suggests that
models can have self-knowledge: internal representations about their own
capabilities. These directions are causally relevant: capable of steering the
model to refuse to answer questions about known entities, or to hallucinate
attributes of unknown entities when it would otherwise refuse. We demonstrate
that despite the sparse autoencoders being trained on the base model, these
directions have a causal effect on the chat model's refusal behavior,
suggesting that chat finetuning has repurposed this existing mechanism.
Furthermore, we provide an initial exploration into the mechanistic role of
these directions in the model, finding that they disrupt the attention of
downstream heads that typically move entity attributes to the final token.

摘要：大型语言模型中的幻觉是一个普遍的问题，但模型是否会产生幻觉背后的机制却鲜为人知，这限制了我们解决这一问题的能力。使用稀疏自动编码器作为可解释性工具，我们发现这些机制的关键部分是实体识别，其中模型检测实体是否是可以回忆事实的实体。稀疏自动编码器揭示了表示空间中的有意义的方向，这些方向检测模型是否识别实体，例如检测到它不知道运动员或电影。这表明模型可以自我认知：关于自身能力的内部表征。这些方向具有因果相关性：能够引导模型拒绝回答有关已知实体的问题，或在它原本会拒绝的情况下对未知实体的属性产生幻觉。我们证明，尽管稀疏自动编码器是在基础模型上训练的，但这些方向对聊天模型的拒绝行为有因果关系，这表明聊天微调已经重新利用了这种现有机制。此外，我们对这些方向在模型中的机制作用进行了初步探索，发现它们破坏了下游头的注意力，而下游头通常将实体属性移动到最终标记。

##### **BERT-Based Approach for Automating Course Articulation Matrix Construction with Explainable AI**
2411.14254v1 by Natenaile Asmamaw Shiferaw, Simpenzwe Honore Leandre, Aman Sinha, Dillip Rout

Course Outcome (CO) and Program Outcome (PO)/Program-Specific Outcome (PSO)
alignment is a crucial task for ensuring curriculum coherence and assessing
educational effectiveness. The construction of a Course Articulation Matrix
(CAM), which quantifies the relationship between COs and POs/PSOs, typically
involves assigning numerical values (0, 1, 2, 3) to represent the degree of
alignment. In this study, We experiment with four models from the BERT family:
BERT Base, DistilBERT, ALBERT, and RoBERTa, and use multiclass classification
to assess the alignment between CO and PO/PSO pairs. We first evaluate
traditional machine learning classifiers, such as Decision Tree, Random Forest,
and XGBoost, and then apply transfer learning to evaluate the performance of
the pretrained BERT models. To enhance model interpretability, we apply
Explainable AI technique, specifically Local Interpretable Model-agnostic
Explanations (LIME), to provide transparency into the decision-making process.
Our system achieves accuracy, precision, recall, and F1-score values of 98.66%,
98.67%, 98.66%, and 98.66%, respectively. This work demonstrates the potential
of utilizing transfer learning with BERT-based models for the automated
generation of CAMs, offering high performance and interpretability in
educational outcome assessment.

摘要：課程成果 (CO) 與計畫成果 (PO)/計畫特定成果 (PSO)
對齊對於確保課程架構一致性及評量教育成效至關重要。課程關聯矩陣 (CAM) 的建構量化 CO 與 PO/PSO 之間的關係，通常
會指派數值 (0、1、2、3) 來表示對齊程度。在本研究中，我們實驗 BERT 家族中的四個模型：BERT Base、DistilBERT、ALBERT 和 RoBERTa，並使用多類別分類來評估 CO 和 PO/PSO 成對之間的對齊。我們首先評估傳統機器學習分類器，例如決策樹、隨機森林，
以及 XGBoost，然後應用遷移學習來評估預訓練 BERT 模型的效能。為了增強模型可解釋性，我們應用可解釋 AI 技術，特別是局部可解釋模型不可知解釋 (LIME)，以提供決策制定過程的透明度。
我們的系統達到準確率、精準度、召回率和 F1 分數值分別為 98.66%、98.67%、98.66% 和 98.66%。這項工作展示了利用遷移學習與 BERT 為基礎的模型進行 CAM 自動產生的潛力，在教育成果評量中提供高性能和可解釋性。

##### **Intent-Aware Dialogue Generation and Multi-Task Contrastive Learning for Multi-Turn Intent Classification**
2411.14252v1 by Junhua Liu, Yong Keat Tan, Bin Fu, Kwan Hui Lim

Generating large-scale, domain-specific, multilingual multi-turn dialogue
datasets remains a significant hurdle for training effective Multi-Turn Intent
Classification models in chatbot systems. In this paper, we introduce
Chain-of-Intent, a novel mechanism that combines Hidden Markov Models with
Large Language Models (LLMs) to generate contextually aware, intent-driven
conversations through self-play. By extracting domain-specific knowledge from
e-commerce chat logs, we estimate conversation turns and intent transitions,
which guide the generation of coherent dialogues. Leveraging LLMs to enhance
emission probabilities, our approach produces natural and contextually
consistent questions and answers. We also propose MINT-CL, a framework for
multi-turn intent classification using multi-task contrastive learning,
improving classification accuracy without the need for extensive annotated
data. Evaluations show that our methods outperform baselines in dialogue
quality and intent classification accuracy, especially in multilingual
settings, while significantly reducing data generation efforts. Furthermore, we
release MINT-E, a multilingual, intent-aware multi-turn e-commerce dialogue
corpus to support future research in this area.

摘要：生成大规模、特定领域、多语言的多轮对话数据集对于训练聊天机器人系统中的有效多轮意图分类模型仍然是一个重大障碍。在本文中，我们介绍了意图链，这是一种将隐马尔可夫模型与大语言模型 (LLM) 相结合的新机制，通过自博弈生成上下文感知、意图驱动的对话。通过从电子商务聊天记录中提取特定领域的知识，我们估计对话轮次和意图转换，从而指导生成连贯的对话。利用 LLM 来提高发射概率，我们的方法产生了自然且在上下文上一致的问题和答案。我们还提出了 MINT-CL，一个用于多任务对比学习的多轮意图分类框架，提高了分类准确性，而无需大量注释数据。评估表明，我们的方法在对话质量和意图分类准确性方面优于基准，特别是在多语言环境中，同时显着减少了数据生成工作。此外，我们发布了 MINT-E，这是一个多语言、意图感知的多轮电子商务对话语料库，以支持该领域的未来研究。

##### **Natural Language Reinforcement Learning**
2411.14251v1 by Xidong Feng, Ziyu Wan, Haotian Fu, Bo Liu, Mengyue Yang, Girish A. Koushik, Zhiyuan Hu, Ying Wen, Jun Wang

Reinforcement Learning (RL) mathematically formulates decision-making with
Markov Decision Process (MDP). With MDPs, researchers have achieved remarkable
breakthroughs across various domains, including games, robotics, and language
models. This paper seeks a new possibility, Natural Language Reinforcement
Learning (NLRL), by extending traditional MDP to natural language-based
representation space. Specifically, NLRL innovatively redefines RL principles,
including task objectives, policy, value function, Bellman equation, and policy
iteration, into their language counterparts. With recent advancements in large
language models (LLMs), NLRL can be practically implemented to achieve RL-like
policy and value improvement by either pure prompting or gradient-based
training. Experiments over Maze, Breakthrough, and Tic-Tac-Toe games
demonstrate the effectiveness, efficiency, and interpretability of the NLRL
framework among diverse use cases. Our code will be released at
https://github.com/waterhorse1/Natural-language-RL.

摘要：強化學習（RL）以馬可夫決策過程（MDP）數學化制定決策。透過 MDP，研究人員在各種領域（包括遊戲、機器人和語言模型）取得顯著突破。本文探討一種新的可能性，自然語言強化學習（NLRL），方法是將傳統的 MDP 擴展到基於自然語言的表示空間。具體來說，NLRL 創新地將 RL 原理（包括任務目標、策略、價值函數、貝爾曼方程式和策略迭代）重新定義為它們的語言對應物。隨著大型語言模型（LLM）的最新進展，NLRL 可以實際實作，藉由純粹提示或基於梯度的訓練來達成類 RL 的策略和價值改善。在迷宮、突破和井字遊戲的實驗證明了 NLRL 架構在各種使用案例中的有效性、效率和可解釋性。我們的程式碼將在 https://github.com/waterhorse1/Natural-language-RL 發布。

##### **AnywhereDoor: Multi-Target Backdoor Attacks on Object Detection**
2411.14243v1 by Jialin Lu, Junjie Shan, Ziqi Zhao, Ka-Ho Chow

As object detection becomes integral to many safety-critical applications,
understanding its vulnerabilities is essential. Backdoor attacks, in
particular, pose a significant threat by implanting hidden backdoor in a victim
model, which adversaries can later exploit to trigger malicious behaviors
during inference. However, current backdoor techniques are limited to static
scenarios where attackers must define a malicious objective before training,
locking the attack into a predetermined action without inference-time
adaptability. Given the expressive output space in object detection, including
object existence detection, bounding box estimation, and object classification,
the feasibility of implanting a backdoor that provides inference-time control
with a high degree of freedom remains unexplored. This paper introduces
AnywhereDoor, a flexible backdoor attack tailored for object detection. Once
implanted, AnywhereDoor enables adversaries to specify different attack types
(object vanishing, fabrication, or misclassification) and configurations
(untargeted or targeted with specific classes) to dynamically control detection
behavior. This flexibility is achieved through three key innovations: (i)
objective disentanglement to support a broader range of attack combinations
well beyond what existing methods allow; (ii) trigger mosaicking to ensure
backdoor activations are robust, even against those object detectors that
extract localized regions from the input image for recognition; and (iii)
strategic batching to address object-level data imbalances that otherwise
hinders a balanced manipulation. Extensive experiments demonstrate that
AnywhereDoor provides attackers with a high degree of control, achieving an
attack success rate improvement of nearly 80% compared to adaptations of
existing methods for such flexible control.

摘要：隨著目標偵測逐漸成為許多安全關鍵應用程式中不可或缺的一部分，了解其漏洞至關重要。後門攻擊尤其會構成重大威脅，它會在受害者模型中植入隱藏的後門，而對手之後可以利用它在推論期間觸發惡意行為。然而，目前的後門技術僅限於靜態場景，其中攻擊者必須在訓練前定義惡意目標，將攻擊鎖定在預先決定的動作中，而沒有推論時間的適應性。考量到目標偵測中具有表現力的輸出空間，包括目標存在偵測、邊界框估計和目標分類，植入後門以提供推論時間控制並具備高度自由度的可行性仍未被探索。本文介紹了 AnywhereDoor，這是一種針對目標偵測量身打造的靈活後門攻擊。一旦植入，AnywhereDoor 便能讓對手指定不同的攻擊類型（目標消失、偽造或誤分類）和組態（未鎖定目標或鎖定特定類別），以動態控制偵測行為。這種靈活性是透過三項關鍵創新實現的：(i) 目標解開，以支援比現有方法允許的範圍更廣的攻擊組合；(ii) 觸發馬賽克，以確保後門啟動具有穩健性，即使針對那些從輸入影像中擷取局部區域以進行辨識的目標偵測器也是如此；以及 (iii) 策略性批次處理，以解決物件層級資料不平衡的問題，否則會妨礙平衡操作。廣泛的實驗證明，與現有方法的改編相比，AnywhereDoor 為攻擊者提供了高度的控制，實現了近 80% 的攻擊成功率提升，以實現這種靈活控制。

##### **Towards Context-Rich Automated Biodiversity Assessments: Deriving AI-Powered Insights from Camera Trap Data**
2411.14219v1 by Paul Fergus, Carl Chalmers, Naomi Matthews, Stuart Nixon, Andre Burger, Oliver Hartley, Chris Sutherland, Xavier Lambin, Steven Longmore, Serge Wich

Camera traps offer enormous new opportunities in ecological studies, but
current automated image analysis methods often lack the contextual richness
needed to support impactful conservation outcomes. Here we present an
integrated approach that combines deep learning-based vision and language
models to improve ecological reporting using data from camera traps. We
introduce a two-stage system: YOLOv10-X to localise and classify species
(mammals and birds) within images, and a Phi-3.5-vision-instruct model to read
YOLOv10-X binding box labels to identify species, overcoming its limitation
with hard to classify objects in images. Additionally, Phi-3.5 detects broader
variables, such as vegetation type, and time of day, providing rich ecological
and environmental context to YOLO's species detection output. When combined,
this output is processed by the model's natural language system to answer
complex queries, and retrieval-augmented generation (RAG) is employed to enrich
responses with external information, like species weight and IUCN status
(information that cannot be obtained through direct visual analysis). This
information is used to automatically generate structured reports, providing
biodiversity stakeholders with deeper insights into, for example, species
abundance, distribution, animal behaviour, and habitat selection. Our approach
delivers contextually rich narratives that aid in wildlife management
decisions. By providing contextually rich insights, our approach not only
reduces manual effort but also supports timely decision-making in conservation,
potentially shifting efforts from reactive to proactive management.

摘要：相機陷阱在生態研究中提供了新的龐大機會，但目前的自動化影像分析方法通常缺乏支持有影響力的保育成果所需的豐富脈絡。在此，我們提出一個整合方法，結合基於深度學習的視覺和語言模型，以使用相機陷阱的資料改善生態報告。我們引入一個兩階段系統：YOLOv10-X 用於定位和分類影像中的物種（哺乳動物和鳥類），以及 Phi-3.5-vision-instruct 模型用於讀取 YOLOv10-X 繫結框標籤以識別物種，克服其在影像中難以分類物體的限制。此外，Phi-3.5 可偵測更廣泛的變數，例如植被類型和時間，為 YOLO 的物種偵測輸出提供豐富的生態和環境脈絡。結合後，此輸出會由模型的自然語言系統處理以回答複雜的查詢，並採用檢索增強生成（RAG）來使用外部資訊（例如物種重量和 IUCN 狀態，這些資訊無法透過直接視覺分析取得）豐富回應。這些資訊用於自動產生結構化報告，為生物多樣性利益相關者提供更深入的見解，例如物種豐富度、分佈、動物行為和棲息地選擇。我們的做法提供有助於野生動物管理決策的豐富脈絡敘述。透過提供豐富的脈絡見解，我們的做法不僅減少手動工作，還支援保育中的及時決策制定，潛在地將工作從被動管理轉移到主動管理。

##### **Evaluating the Robustness of Analogical Reasoning in Large Language Models**
2411.14215v1 by Martha Lewis, Melanie Mitchell

LLMs have performed well on several reasoning benchmarks, including ones that
test analogical reasoning abilities. However, there is debate on the extent to
which they are performing general abstract reasoning versus employing
non-robust processes, e.g., that overly rely on similarity to pre-training
data. Here we investigate the robustness of analogy-making abilities previously
claimed for LLMs on three of four domains studied by Webb, Holyoak, and Lu
(2023): letter-string analogies, digit matrices, and story analogies. For each
domain we test humans and GPT models on robustness to variants of the original
analogy problems that test the same abstract reasoning abilities but are likely
dissimilar from tasks in the pre-training data. The performance of a system
that uses robust abstract reasoning should not decline substantially on these
variants.
  On simple letter-string analogies, we find that while the performance of
humans remains high for two types of variants we tested, the GPT models'
performance declines sharply. This pattern is less pronounced as the complexity
of these problems is increased, as both humans and GPT models perform poorly on
both the original and variant problems requiring more complex analogies. On
digit-matrix problems, we find a similar pattern but only on one out of the two
types of variants we tested. On story-based analogy problems, we find that,
unlike humans, the performance of GPT models are susceptible to answer-order
effects, and that GPT models also may be more sensitive than humans to
paraphrasing.
  This work provides evidence that LLMs often lack the robustness of zero-shot
human analogy-making, exhibiting brittleness on most of the variations we
tested. More generally, this work points to the importance of carefully
evaluating AI systems not only for accuracy but also robustness when testing
their cognitive capabilities.

摘要：<paragraph>LLM 在許多推理基準上表現良好，包括測試類比推理能力的基準。然而，對於它們執行一般抽象推理的程度，與採用非穩健的程序（例如過度依賴與預訓練資料的相似性）之間的爭論不休。在此，我們探討了 Webb、Holyoak 和 Lu（2023 年）研究的四個領域中，LLM 先前聲稱的類比建構能力的穩健性：字母串類比、數字矩陣和故事類比。對於每個領域，我們針對人類和 GPT 模型測試其對原始類比問題變體的穩健性，這些變體測試了相同的抽象推理能力，但可能與預訓練資料中的任務不同。使用穩健抽象推理的系統，在這些變體上的表現不應大幅下降。
在簡單的字母串類比中，我們發現雖然人類的表現對於我們測試的兩種變體類型仍然很高，但 GPT 模型的表現急劇下降。隨著這些問題的複雜性增加，這種模式不太明顯，因為人類和 GPT 模型在需要更複雜類比的原始問題和變體問題上表現都很差。在數字矩陣問題中，我們發現類似的模式，但僅出現在我們測試的兩種變體類型中的一種。在基於故事的類比問題中，我們發現與人類不同，GPT 模型的表現容易受到答案順序效應的影響，而且 GPT 模型也可能比人類對同義改寫更敏感。
這項工作提供了證據，證明 LLM 通常缺乏零次學習人類類比建構的穩健性，在我們測試的大多數變體上表現出脆弱性。更一般地說，這項工作指出在測試 AI 系統的認知能力時，不僅要仔細評估其準確性，還要評估其穩健性的重要性。</paragraph>

##### **Physics-Informed LLM-Agent for Automated Modulation Design in Power Electronics Systems**
2411.14214v1 by Junhua Liu, Fanfan Lin, Xinze Li, Kwan Hui Lim, Shuai Zhao

LLM-based autonomous agents have demonstrated outstanding performance in
solving complex industrial tasks. However, in the pursuit of carbon neutrality
and high-performance renewable energy systems, existing AI-assisted design
automation faces significant limitations in explainability, scalability, and
usability. To address these challenges, we propose LP-COMDA, an LLM-based,
physics-informed autonomous agent that automates the modulation design of power
converters in Power Electronics Systems with minimal human supervision. Unlike
traditional AI-assisted approaches, LP-COMDA contains an LLM-based planner that
gathers and validates design specifications through a user-friendly chat
interface. The planner then coordinates with physics-informed design and
optimization tools to iteratively generate and refine modulation designs
autonomously. Through the chat interface, LP-COMDA provides an explainable
design process, presenting explanations and charts. Experiments show that
LP-COMDA outperforms all baseline methods, achieving a 63.2% reduction in error
compared to the second-best benchmark method in terms of standard mean absolute
error. Furthermore, empirical studies with 20 experts conclude that design time
with LP-COMDA is over 33 times faster than conventional methods, showing its
significant improvement on design efficiency over the current processes.

摘要：基於 LLM 的自主代理已在解決複雜的產業任務方面展現出色的效能。然而，在追求碳中和和高性能再生能源系統的過程中，現有的 AI 輔助設計自動化在可解釋性、可擴充性和可用性方面面臨重大限制。為了應對這些挑戰，我們提出 LP-COMDA，這是一種基於 LLM、以物理為基礎的自主代理，它自動化了電力電子系統中功率轉換器的調變設計，並將人為監督減至最低。與傳統的 AI 輔助方法不同，LP-COMDA 包含一個基於 LLM 的規劃器，它透過使用者友善的聊天介面收集並驗證設計規範。然後，規劃器與以物理為基礎的設計和最佳化工具協調，以自主方式反覆生成並改善調變設計。透過聊天介面，LP-COMDA 提供可解釋的設計流程，並提供說明和圖表。實驗顯示，LP-COMDA 優於所有基線方法，在標準平均絕對誤差方面，與第二好的基準方法相比，誤差減少了 63.2%。此外，與 20 位專家的實證研究得出，使用 LP-COMDA 的設計時間比傳統方法快了 33 倍以上，顯示出它對當前流程的設計效率有顯著的改善。

##### **HARP: A Large-Scale Higher-Order Ambisonic Room Impulse Response Dataset**
2411.14207v1 by Shivam Saini, Jürgen Peissig

This contribution introduces a dataset of 7th-order Ambisonic Room Impulse
Responses (HOA-RIRs), created using the Image Source Method. By employing
higher-order Ambisonics, our dataset enables precise spatial audio
reproduction, a critical requirement for realistic immersive audio
applications. Leveraging the virtual simulation, we present a unique microphone
configuration, based on the superposition principle, designed to optimize sound
field coverage while addressing the limitations of traditional microphone
arrays. The presented 64-microphone configuration allows us to capture RIRs
directly in the Spherical Harmonics domain. The dataset features a wide range
of room configurations, encompassing variations in room geometry, acoustic
absorption materials, and source-receiver distances. A detailed description of
the simulation setup is provided alongside for an accurate reproduction. The
dataset serves as a vital resource for researchers working on spatial audio,
particularly in applications involving machine learning to improve room
acoustics modeling and sound field synthesis. It further provides a very high
level of spatial resolution and realism crucial for tasks such as source
localization, reverberation prediction, and immersive sound reproduction.

摘要：此貢獻引入了一個使用影像來源方法創建的 7 階 Ambisonic 房間脈衝響應 (HOA-RIR) 資料集。透過採用高階 Ambisonics，我們的資料集能進行精確的空間音訊重現，這是逼真沉浸式音訊應用的一項關鍵需求。利用虛擬模擬，我們根據疊加原理，提出了一種獨特的麥克風配置，旨在最佳化聲音場覆蓋範圍，同時解決傳統麥克風陣列的限制。所提出的 64 麥克風配置讓我們能夠直接在球諧域中擷取 RIR。該資料集具有廣泛的房間配置，包含房間幾何形狀、吸音材料和聲源接收器距離的變化。模擬設定的詳細說明也隨附提供，以進行準確的重現。該資料集可作為從事空間音訊研究人員的重要資源，特別是在涉及機器學習以改善房間聲學建模和聲音場合成的應用中。它進一步提供了非常高的空間解析度和真實感，這對於聲源定位、混響預測和沉浸式聲音重現等任務至關重要。

##### **Is this Generated Person Existed in Real-world? Fine-grained Detecting and Calibrating Abnormal Human-body**
2411.14205v1 by Zeqing Wang, Qingyang Ma, Wentao Wan, Haojie Li, Keze Wang, Yonghong Tian

Recent improvements in visual synthesis have significantly enhanced the
depiction of generated human photos, which are pivotal due to their wide
applicability and demand. Nonetheless, the existing text-to-image or
text-to-video models often generate low-quality human photos that might differ
considerably from real-world body structures, referred to as "abnormal human
bodies". Such abnormalities, typically deemed unacceptable, pose considerable
challenges in the detection and repair of them within human photos. These
challenges require precise abnormality recognition capabilities, which entail
pinpointing both the location and the abnormality type. Intuitively, Visual
Language Models (VLMs) that have obtained remarkable performance on various
visual tasks are quite suitable for this task. However, their performance on
abnormality detection in human photos is quite poor. Hence, it is quite
important to highlight this task for the research community. In this paper, we
first introduce a simple yet challenging task, i.e., \textbf{F}ine-grained
\textbf{H}uman-body \textbf{A}bnormality \textbf{D}etection \textbf{(FHAD)},
and construct two high-quality datasets for evaluation. Then, we propose a
meticulous framework, named HumanCalibrator, which identifies and repairs
abnormalities in human body structures while preserving the other content.
Experiments indicate that our HumanCalibrator achieves high accuracy in
abnormality detection and accomplishes an increase in visual comparisons while
preserving the other visual content.

摘要：<paragraph>最近視覺合成技術的進步，顯著增強了生成的人像照片的描繪，由於其廣泛的適用性和需求，因此至關重要。儘管如此，現有的文字轉圖像或文字轉影片模型通常會產生低品質的人像照片，這些照片可能與真實的身體結構有很大不同，稱為「異常人體」。這種異常通常被認為是不可接受的，在人像照片中檢測和修復它們會帶來相當大的挑戰。這些挑戰需要精確的異常識別能力，這需要精確指出位置和異常類型。直觀地說，在各種視覺任務中獲得顯著表現的視覺語言模型 (VLM) 非常適合這項任務。然而，它們在人像照片中異常檢測的表現非常差。因此，對於研究社群來說，強調這項任務非常重要。在本文中，我們首先介紹一個簡單但具有挑戰性的任務，即\textbf{F}ine-grained \textbf{H}uman-body \textbf{A}bnormality \textbf{D}etection \textbf{(FHAD)}，並建立兩個高品質的資料集進行評估。然後，我們提出一個細緻的框架，稱為 HumanCalibrator，它識別並修復人體結構中的異常，同時保留其他內容。實驗表明，我們的 HumanCalibrator 在異常檢測中實現了高準確度，並在保留其他視覺內容的同時，在視覺比較中取得了進展。</paragraph>

##### **OpenScholar: Synthesizing Scientific Literature with Retrieval-augmented LMs**
2411.14199v1 by Akari Asai, Jacqueline He, Rulin Shao, Weijia Shi, Amanpreet Singh, Joseph Chee Chang, Kyle Lo, Luca Soldaini, Sergey Feldman, Mike D'arcy, David Wadden, Matt Latzke, Minyang Tian, Pan Ji, Shengyan Liu, Hao Tong, Bohao Wu, Yanyu Xiong, Luke Zettlemoyer, Graham Neubig, Dan Weld, Doug Downey, Wen-tau Yih, Pang Wei Koh, Hannaneh Hajishirzi

Scientific progress depends on researchers' ability to synthesize the growing
body of literature. Can large language models (LMs) assist scientists in this
task? We introduce OpenScholar, a specialized retrieval-augmented LM that
answers scientific queries by identifying relevant passages from 45 million
open-access papers and synthesizing citation-backed responses. To evaluate
OpenScholar, we develop ScholarQABench, the first large-scale multi-domain
benchmark for literature search, comprising 2,967 expert-written queries and
208 long-form answers across computer science, physics, neuroscience, and
biomedicine. On ScholarQABench, OpenScholar-8B outperforms GPT-4o by 5% and
PaperQA2 by 7% in correctness, despite being a smaller, open model. While GPT4o
hallucinates citations 78 to 90% of the time, OpenScholar achieves citation
accuracy on par with human experts. OpenScholar's datastore, retriever, and
self-feedback inference loop also improves off-the-shelf LMs: for instance,
OpenScholar-GPT4o improves GPT-4o's correctness by 12%. In human evaluations,
experts preferred OpenScholar-8B and OpenScholar-GPT4o responses over
expert-written ones 51% and 70% of the time, respectively, compared to GPT4o's
32%. We open-source all of our code, models, datastore, data and a public demo.

摘要：<paragraph>科學進步有賴於研究人員綜合日益龐大的文獻資料的能力。大型語言模型 (LM) 能否協助科學家執行這項任務？我們推出 OpenScholar，一種專門的檢索增強型 LM，它透過識別來自 4500 萬篇開放取用論文中的相關段落並綜合引用備註的回應，來回答科學問題。為了評估 OpenScholar，我們開發了 ScholarQABench，這是第一個針對文獻搜尋的大規模多領域基準，包含 2967 個專家撰寫的問題和 208 個長篇答案，涵蓋電腦科學、物理學、神經科學和生物醫學。在 ScholarQABench 上，OpenScholar-8B 在正確性方面比 GPT-4o 高出 5%，比 PaperQA2 高出 7%，儘管它是一個較小的開放模型。雖然 GPT-4o 在 78% 到 90% 的時間內會產生幻覺引文，但 OpenScholar 的引文準確度與人類專家不相上下。OpenScholar 的資料儲存庫、檢索器和自我回饋推理迴圈也改進了現成的 LM：例如，OpenScholar-GPT4o 將 GPT-4o 的正確性提高了 12%。在人類評估中，專家分別有 51% 和 70% 的時間偏好 OpenScholar-8B 和 OpenScholar-GPT4o 回應，而 GPT-4o 為 32%。我們開放原始碼、模型、資料儲存庫、資料和公開示範。</paragraph>

##### **Why do language models perform worse for morphologically complex languages?**
2411.14198v1 by Catherine Arnett, Benjamin K. Bergen

Language models perform differently across languages. It has been previously
suggested that morphological typology may explain some of this variability
(Cotterell et al., 2018). We replicate previous analyses and find additional
new evidence for a performance gap between agglutinative and fusional
languages, where fusional languages, such as English, tend to have better
language modeling performance than morphologically more complex languages like
Turkish. We then propose and test three possible causes for this performance
gap: morphological alignment of tokenizers, tokenization quality, and
disparities in dataset sizes and measurement. To test the morphological
alignment hypothesis, we present MorphScore, a tokenizer evaluation metric, and
supporting datasets for 22 languages. We find some evidence that tokenization
quality explains the performance gap, but none for the role of morphological
alignment. Instead we find that the performance gap is most reduced when
training datasets are of equivalent size across language types, but only when
scaled according to the so-called "byte-premium" -- the different encoding
efficiencies of different languages and orthographies. These results suggest
that no language is harder or easier for a language model to learn on the basis
of its morphological typology. Differences in performance can be attributed to
disparities in dataset size. These results bear on ongoing efforts to improve
performance for low-performing and under-resourced languages.

摘要：語言模型在不同語言中的表現不同。先前曾提出形態類型學可能解釋了這種變異性的一部分（Cotterell 等人，2018 年）。我們複製先前的分析並發現更多證據，證明黏著語和融合語之間存在效能差距，其中融合語，例如英語，往往比形態更複雜的語言（例如土耳其語）有更好的語言建模效能。然後，我們提出並測試了造成這種效能差距的三個可能原因：分詞器的形態對齊、分詞品質，以及資料集大小和測量上的差異。為了測試形態對齊假設，我們提出了 MorphScore，一種分詞器評估指標，以及支援 22 種語言的資料集。我們發現一些證據表明分詞品質解釋了效能差距，但沒有證據支持形態對齊的作用。相反，我們發現當訓練資料集在不同語言類型中具有相同大小時，效能差距會最大程度地縮小，但僅當根據所謂的「位元組溢價」進行縮放時才會發生這種情況——不同語言和正寫法的編碼效率不同。這些結果表明，沒有哪種語言對語言模型來說更難或更容易學習，取決於其形態類型。效能差異可歸因於資料集大小的差異。這些結果與持續進行的改善低效能和資源不足語言效能的努力有關。

##### **ComfyGI: Automatic Improvement of Image Generation Workflows**
2411.14193v1 by Dominik Sobania, Martin Briesch, Franz Rothlauf

Automatic image generation is no longer just of interest to researchers, but
also to practitioners. However, current models are sensitive to the settings
used and automatic optimization methods often require human involvement. To
bridge this gap, we introduce ComfyGI, a novel approach to automatically
improve workflows for image generation without the need for human intervention
driven by techniques from genetic improvement. This enables image generation
with significantly higher quality in terms of the alignment with the given
description and the perceived aesthetics. On the performance side, we find that
overall, the images generated with an optimized workflow are about 50% better
compared to the initial workflow in terms of the median ImageReward score.
These already good results are even surpassed in our human evaluation, as the
participants preferred the images improved by ComfyGI in around 90% of the
cases.

摘要：自動影像生成不再僅是研究人員有興趣的領域，
實務工作者也開始關注。然而，目前的模型對所使用的設定很敏感，而自動最佳化方法通常需要人工介入。為了彌補這個差距，我們引入了 ComfyGI，一種新穎的方法，可自動改善影像生成工作流程，無需人工介入，並由遺傳改良技術驅動。這使得影像生成在與給定描述的一致性和感知美學方面具有顯著更高的品質。在效能方面，我們發現整體而言，使用最佳化工作流程生成的影像在 ImageReward 中位數評分方面比初始工作流程高出約 50%。這些已經不錯的結果在我們的人類評估中甚至被超越，因為參與者在約 90% 的情況下更喜歡 ComfyGI 改進的影像。

##### **FoPru: Focal Pruning for Efficient Large Vision-Language Models**
2411.14164v1 by Lei Jiang, Weizhe Huang, Tongxuan Liu, Yuting Zeng, Jing Li, Lechao Cheng, Xiaohua Xu

Large Vision-Language Models (LVLMs) represent a significant advancement
toward achieving superior multimodal capabilities by enabling powerful Large
Language Models (LLMs) to understand visual input. Typically, LVLMs utilize
visual encoders, such as CLIP, to transform images into visual tokens, which
are then aligned with textual tokens through projection layers before being
input into the LLM for inference. Although existing LVLMs have achieved
significant success, their inference efficiency is still limited by the
substantial number of visual tokens and the potential redundancy among them. To
mitigate this issue, we propose Focal Pruning (FoPru), a training-free method
that prunes visual tokens based on the attention-based token significance
derived from the vision encoder. Specifically, we introduce two alternative
pruning strategies: 1) the rank strategy, which leverages all token
significance scores to retain more critical tokens in a global view; 2) the row
strategy, which focuses on preserving continuous key information in images from
a local perspective. Finally, the selected tokens are reordered to maintain
their original positional relationships. Extensive experiments across various
LVLMs and multimodal datasets demonstrate that our method can prune a large
number of redundant tokens while maintaining high accuracy, leading to
significant improvements in inference efficiency.

摘要：大型视觉语言模型 (LVLMs) 藉由让强大的大型语言模型 (LLMs) 理解视觉输入，展现出在达成卓越多模态能力上的一大进步。LVLMs 一般会利用视觉编码器，例如 CLIP，将图像转换为视觉标记，然后在输入 LLM 进行推理之前，透过投影层与文本标记对齐。虽然现有的 LVLMs 已获得显著的成功，但其推理效率仍受到大量视觉标记和标记之间潜在冗余的限制。为了减轻此问题，我们提出了焦点修剪 (FoPru)，这是一种无需训练的方法，它会根据视觉编码器衍生的基于注意力的标记重要性来修剪视觉标记。具体来说，我们引入了两种替代修剪策略：1) 排名策略，它利用所有标记重要性分数来在全局视图中保留更重要的标记；2) 行策略，它专注于从局部角度保留图像中的连续关键信息。最后，选定的标记会重新排序以维持其原始位置关系。在各种 LVLMs 和多模态数据集上的广泛实验表明，我们的方法可以修剪大量冗余标记，同时维持高准确度，从而大幅提升推理效率。

##### **Visual Contexts Clarify Ambiguous Expressions: A Benchmark Dataset**
2411.14137v1 by Heejeong Nam, Jinwoo Ahn

The ability to perform complex reasoning across multimodal inputs is
essential for models to effectively interact with humans in real-world
scenarios. Advancements in vision-language models have significantly improved
performance on tasks that require processing explicit and direct textual
inputs, such as Visual Question Answering (VQA) and Visual Grounding (VG).
However, less attention has been given to improving the model capabilities to
comprehend nuanced and ambiguous forms of communication. This presents a
critical challenge, as human language in real-world interactions often convey
hidden intentions that rely on context for accurate interpretation. To address
this gap, we propose VAGUE, a multimodal benchmark comprising 3.9K indirect
human utterances paired with corresponding scenes. Additionally, we contribute
a model-based pipeline for generating prompt-solution pairs from input images.
Our work aims to delve deeper into the ability of models to understand indirect
communication and seek to contribute to the development of models capable of
more refined and human-like interactions. Extensive evaluation on multiple VLMs
reveals that mainstream models still struggle with indirect communication when
required to perform complex linguistic and visual reasoning. We release our
code and data at https://github.com/Hazel-Heejeong-Nam/VAGUE.git.

摘要：在真實世界的場景中，模型要有效地與人類互動，就必須具備跨多模態輸入進行複雜推理的能力。視覺語言模型的進步顯著提升了需要處理明確且直接的文字輸入的任務的效能，例如視覺問答 (VQA) 和視覺基礎 (VG)。然而，對於提升模型理解細微且模稜兩可的溝通形式的能力，關注較少。這是一個重大的挑戰，因為在真實世界的互動中，人類語言通常會傳達隱藏的意圖，而這些意圖依賴於背景才能準確解讀。為了解決這個差距，我們提出 VAGUE，一個由 3.9K 個間接的人類話語與對應場景配對組成的多模態基準。此外，我們提供了一個基於模型的管道，用於從輸入影像產生提示解決方案對。我們的研究旨在深入探討模型理解間接溝通的能力，並致力於開發能夠進行更精緻且更類似人類互動的模型。對多個 VLM 的廣泛評估顯示，主流模型在需要執行複雜的語言和視覺推理時，仍然難以處理間接溝通。我們在 https://github.com/Hazel-Heejeong-Nam/VAGUE.git/ 釋出我們的程式碼和資料。

##### **GASP: Efficient Black-Box Generation of Adversarial Suffixes for Jailbreaking LLMs**
2411.14133v1 by Advik Raj Basani, Xiao Zhang

Large Language Models (LLMs) have shown impressive proficiency across a range
of natural language processing tasks yet remain vulnerable to adversarial
prompts, known as jailbreak attacks, carefully designed to elicit harmful
responses from LLMs. Traditional methods rely on manual heuristics, which
suffer from limited generalizability. While being automatic, optimization-based
attacks often produce unnatural jailbreak prompts that are easy to detect by
safety filters or require high computational overhead due to discrete token
optimization. Witnessing the limitations of existing jailbreak methods, we
introduce Generative Adversarial Suffix Prompter (GASP), a novel framework that
combines human-readable prompt generation with Latent Bayesian Optimization
(LBO) to improve adversarial suffix creation in a fully black-box setting. GASP
leverages LBO to craft adversarial suffixes by efficiently exploring continuous
embedding spaces, gradually optimizing the model to improve attack efficacy
while balancing prompt coherence through a targeted iterative refinement
procedure. Our experiments show that GASP can generate natural jailbreak
prompts, significantly improving attack success rates, reducing training times,
and accelerating inference speed, thus making it an efficient and scalable
solution for red-teaming LLMs.

摘要：大型語言模型 (LLM) 在各種自然語言處理任務中展現出驚人的能力，但仍然容易受到對抗性提示的攻擊，稱為越獄攻擊，這些提示經過精心設計，可以引發 LLM 產生有害的回應。傳統方法依賴於手動啟發法，這種方法的泛化能力有限。雖然是自動化的，但基於優化的攻擊通常會產生不自然的越獄提示，這些提示很容易被安全過濾器檢測到，或者由於離散令牌優化而需要很高的計算開銷。鑑於現有越獄方法的局限性，我們引入了生成對抗後綴提示器 (GASP)，這是一個新穎的框架，它將人類可讀的提示生成與潛在貝葉斯優化 (LBO) 相結合，以在完全黑盒設置中改進對抗性後綴的創建。GASP 利用 LBO 通過有效探索連續嵌入空間來製作對抗性後綴，逐漸優化模型以提高攻擊效率，同時通過有針對性的迭代改進程序來平衡提示一致性。我們的實驗表明，GASP 可以生成自然的越獄提示，顯著提高攻擊成功率，減少訓練時間，並加快推理速度，從而使其成為一種高效且可擴展的紅隊 LLM 解決方案。

##### **Learning from "Silly" Questions Improves Large Language Models, But Only Slightly**
2411.14121v1 by Tingyuan Zhu, Shudong Liu, Yidong Wang, Derek F. Wong, Han Yu, Takahiro Shinozaki, Jindong Wang

Constructing high-quality Supervised Fine-Tuning (SFT) datasets is critical
for the training of large language models (LLMs). Recent studies have shown
that using data from a specific source, Ruozhiba, a Chinese website where users
ask "silly" questions to better understand certain topics, can lead to better
fine-tuning performance. This paper aims to explore some hidden factors: the
potential interpretations of its success and a large-scale evaluation of the
performance. First, we leverage GPT-4 to analyze the successful cases of
Ruozhiba questions from the perspective of education, psychology, and cognitive
science, deriving a set of explanatory rules. Then, we construct fine-tuning
datasets by applying these rules to the MMLU training set. Surprisingly, our
results indicate that rules can significantly improve model performance in
certain tasks, while potentially diminishing performance on others. For
example, SFT data generated following the "Counterintuitive Thinking" rule can
achieve approximately a 5% improvement on the "Global Facts" task, whereas the
"Blurring the Conceptual Boundaries" rule leads to a performance drop of 6.14%
on the "Econometrics" task. In addition, for specific tasks, different rules
tend to have a consistent impact on model performance. This suggests that the
differences between the extracted rules are not as significant, and the
effectiveness of the rules is relatively consistent across tasks. Our research
highlights the importance of considering task diversity and rule applicability
when constructing SFT datasets to achieve more comprehensive performance
improvements.

摘要：<paragraph>建構高品質的監督式微調 (SFT) 資料集對於訓練大型語言模型 (LLM) 至關重要。最近的研究顯示，使用來自特定來源的資料，例如 Ruozhiba，一個使用者提出「愚蠢」問題以更深入了解特定主題的中文網站，可以提升微調的效能。本文旨在探討一些隱藏的因素：成功背後的潛在詮釋以及效能的大規模評估。首先，我們利用 GPT-4 從教育、心理學和認知科學的角度分析 Ruozhiba 問題的成功案例，推導出一組解釋性規則。接著，我們將這些規則套用至 MMLU 訓練集，建構微調資料集。令人驚訝的是，我們的結果顯示規則可以顯著提升模型在特定任務中的效能，但可能會降低其他任務的效能。例如，遵循「反直覺思考」規則產生的 SFT 資料，在「全球事實」任務中可以提升約 5%，而「模糊概念界線」規則則導致「計量經濟學」任務的效能下降 6.14%。此外，對於特定任務，不同的規則往往對模型效能產生一致的影響。這表示提取出的規則之間的差異並不明顯，而且規則的有效性在各項任務中相對一致。我們的研究強調在建構 SFT 資料集時，考量任務的多樣性和規則的適用性非常重要，才能達成更全面的效能提升。</paragraph>

##### **Lost in Inference: Rediscovering the Role of Natural Language Inference for Large Language Models**
2411.14103v1 by Lovish Madaan, David Esiobu, Pontus Stenetorp, Barbara Plank, Dieuwke Hupkes

In the recent past, a popular way of evaluating natural language
understanding (NLU), was to consider a model's ability to perform natural
language inference (NLI) tasks. In this paper, we investigate if NLI tasks,
that are rarely used for LLM evaluation, can still be informative for
evaluating LLMs. Focusing on five different NLI benchmarks across six models of
different scales, we investigate if they are able to discriminate models of
different size and quality and how their accuracies develop during training.
Furthermore, we investigate the extent to which the softmax distributions of
models align with human distributions in cases where statements are ambiguous
or vague. Overall, our results paint a positive picture for the NLI tasks: we
find that they are able to discriminate well between models at various stages
of training, yet are not (all) saturated. Furthermore, we find that while the
similarity of model distributions with human label distributions increases with
scale, it is still much higher than the similarity between two populations of
humans, making it a potentially interesting statistic to consider.

摘要：在不久的過去，評估自然語言理解 (NLU) 的一種流行方式，是考慮模型執行自然語言推理 (NLI) 任務的能力。在本文中，我們探討了很少用於 LLM 評估的 NLI 任務，是否仍能為評估 LLM 提供資訊。我們專注於六個不同規模模型中的五個不同的 NLI 基準，探討它們是否能夠區分不同大小和品質的模型，以及它們的準確度如何在訓練過程中發展。此外，我們探討了在語句模稜兩可或含糊不清的情況下，模型的 softmax 分布與人類分布一致的程度。總的來說，我們的結果為 NLI 任務描繪了一幅正面的圖像：我們發現它們能夠很好地區分訓練不同階段的模型，但並未（全部）飽和。此外，我們發現雖然模型分布與人類標籤分布的相似性隨著規模而增加，但它仍然遠高於兩個人群之間的相似性，這使其成為一個值得考慮的潛在有趣統計數據。

##### **BEST-STD: Bidirectional Mamba-Enhanced Speech Tokenization for Spoken Term Detection**
2411.14100v1 by Anup Singh, Kris Demuynck, Vipul Arora

Spoken term detection (STD) is often hindered by reliance on frame-level
features and the computationally intensive DTW-based template matching,
limiting its practicality. To address these challenges, we propose a novel
approach that encodes speech into discrete, speaker-agnostic semantic tokens.
This facilitates fast retrieval using text-based search algorithms and
effectively handles out-of-vocabulary terms. Our approach focuses on generating
consistent token sequences across varying utterances of the same term. We also
propose a bidirectional state space modeling within the Mamba encoder, trained
in a self-supervised learning framework, to learn contextual frame-level
features that are further encoded into discrete tokens. Our analysis shows that
our speech tokens exhibit greater speaker invariance than those from existing
tokenizers, making them more suitable for STD tasks. Empirical evaluation on
LibriSpeech and TIMIT databases indicates that our method outperforms existing
STD baselines while being more efficient.

摘要：語音詞彙偵測 (STD) 經常受到依賴於幀層級特徵和計算密集的 DTW 基於範本匹配的阻礙，限制了其實用性。為了應對這些挑戰，我們提出了一種新穎的方法，將語音編碼成離散的、與說話者無關的語義符號。這有助於使用基於文字的搜尋演算法快速檢索，並有效處理詞彙外用語。我們的做法專注於在同一個詞彙的不同語句中產生一致的符號序列。我們還提出在 Mamba 編碼器內部使用雙向狀態空間建模，在自監督式學習架構中訓練，以學習進一步編碼成離散符號的上下文幀層級特徵。我們的分析顯示，我們的語音符號比現有符號化工具的符號表現出更大的說話者不變性，這使得它們更適合於 STD 任務。在 LibriSpeech 和 TIMIT 資料庫上的經驗評估表明，我們的模型優於現有的 STD 基準，同時更有效率。

##### **Meaning at the Planck scale? Contextualized word embeddings for doing history, philosophy, and sociology of science**
2411.14073v1 by Arno Simons

This paper explores the potential of contextualized word embeddings (CWEs) as
a new tool in the history, philosophy, and sociology of science (HPSS) for
studying contextual and evolving meanings of scientific concepts. Using the
term "Planck" as a test case, I evaluate five BERT-based models with varying
degrees of domain-specific pretraining, including my custom model
Astro-HEP-BERT, trained on the Astro-HEP Corpus, a dataset containing 21.84
million paragraphs from 600,000 articles in astrophysics and high-energy
physics. For this analysis, I compiled two labeled datasets: (1) the
Astro-HEP-Planck Corpus, consisting of 2,900 labeled occurrences of "Planck"
sampled from 1,500 paragraphs in the Astro-HEP Corpus, and (2) a
physics-related Wikipedia dataset comprising 1,186 labeled occurrences of
"Planck" across 885 paragraphs. Results demonstrate that the domain-adapted
models outperform the general-purpose ones in disambiguating the target term,
predicting its known meanings, and generating high-quality sense clusters, as
measured by a novel purity indicator I developed. Additionally, this approach
reveals semantic shifts in the target term over three decades in the unlabeled
Astro-HEP Corpus, highlighting the emergence of the Planck space mission as a
dominant sense. The study underscores the importance of domain-specific
pretraining for analyzing scientific language and demonstrates the
cost-effectiveness of adapting pretrained models for HPSS research. By offering
a scalable and transferable method for modeling the meanings of scientific
concepts, CWEs open up new avenues for investigating the socio-historical
dynamics of scientific discourses.

摘要：<paragraph>本文探討了語境化字詞嵌入 (CWE) 作為科學史、哲學和社會學 (HPSS) 中一項新工具的潛力，用於研究科學概念的語境和演化意義。使用「普朗克」一詞作為測試案例，我評估了五個基於 BERT 的模型，它們具有不同程度的特定領域預訓練，包括我在 Astro-HEP 語料庫上訓練的客製化模型 Astro-HEP-BERT，該資料集包含來自天體物理學和高能物理學中 600,000 篇文章的 21.84 百萬段落。對於此分析，我編譯了兩個標記資料集：(1) Astro-HEP-Planck 語料庫，包含從 Astro-HEP 語料庫中 1,500 段落中抽取的 2,900 個標記「普朗克」出現次數，以及 (2) 一個物理相關的維基百科資料集，包含跨越 885 段落的 1,186 個標記「普朗克」出現次數。結果證明，領域適應模型在消除目標術語歧義、預測其已知意義和產生高品質意義叢集方面優於通用模型，這是透過我開發的一項新穎純度指標測量的。此外，這種方法揭示了目標術語在未標記的 Astro-HEP 語料庫中超過三十年的語義轉變，突顯了普朗克太空任務作為主要意義的出現。這項研究強調了特定領域預訓練對於分析科學語言的重要性，並證明了適應預訓練模型對於 HPSS 研究的成本效益。透過提供一種可擴充且可轉移的方法來建模科學概念的意義，CWE 開啟了研究科學論述的社會歷史動態的新途徑。</paragraph>

##### **The Master-Slave Encoder Model for Improving Patent Text Summarization: A New Approach to Combining Specifications and Claims**
2411.14072v1 by Shu Zhou, Xin Wang, Zhengda Zhou, Haohan Yi, Xuhui Zheng, Hao Wan

In order to solve the problem of insufficient generation quality caused by
traditional patent text abstract generation models only originating from patent
specifications, the problem of new terminology OOV caused by rapid patent
updates, and the problem of information redundancy caused by insufficient
consideration of the high professionalism, accuracy, and uniqueness of patent
texts, we proposes a patent text abstract generation model (MSEA) based on a
master-slave encoder architecture; Firstly, the MSEA model designs a
master-slave encoder, which combines the instructions in the patent text with
the claims as input, and fully explores the characteristics and details between
the two through the master-slave encoder; Then, the model enhances the
consideration of new technical terms in the input sequence based on the pointer
network, and further enhances the correlation with the input text by re
weighing the "remembered" and "for-gotten" parts of the input sequence from the
encoder; Finally, an enhanced repetition suppression mechanism for patent text
was introduced to ensure accurate and non redundant abstracts generated. On a
publicly available patent text dataset, compared to the state-of-the-art model,
Improved Multi-Head Attention Mechanism (IMHAM), the MSEA model achieves an
improvement of 0.006, 0.005, and 0.005 in Rouge-1, Rouge-2, and Rouge-L scores,
respectively. MSEA leverages the characteristics of patent texts to effectively
enhance the quality of patent text generation, demonstrating its advancement
and effectiveness in the experiments.

摘要：<paragraph>為了解決傳統專利文本摘要生成模型僅源自專利說明書導致生成品質不足的問題、專利更新快速導致新術語 OOV 的問題，以及對專利文本專業性、準確性、獨特性考量不足導致資訊冗餘的問題，我們提出一個基於主從編碼器架構的專利文本摘要生成模型 (MSEA)；首先，MSEA 模型設計一個主從編碼器，將專利文本中的說明書與權利要求書結合作為輸入，並透過主從編碼器充分探索兩者之間的特性與細節；接著，模型基於 pointer network 增強輸入序列中新技術詞彙的考量，並透過重新加權編碼器中「記住」與「遺忘」的輸入序列部分，進一步提升與輸入文本的關聯性；最後，導入增強的專利文本重複抑制機制，以確保生成摘要的準確性與非冗餘性。在一個公開的專利文本資料集上，與目前最先進的模型 Improved Multi-Head Attention Mechanism (IMHAM) 相比，MSEA 模型在 Rouge-1、Rouge-2、Rouge-L 分數上分別提升了 0.006、0.005、0.005。MSEA 充分利用專利文本的特性，有效提升專利文本生成的品質，在實驗中展現其先進性與有效性。</paragraph>

##### **Multi LoRA Meets Vision: Merging multiple adapters to create a multi task model**
2411.14064v1 by Ege Kesim, Selahattin Serdar Helli

Parameter efficient finetuning (PEFT) methods are widely used in LLMs and
generative models in computer vision. Especially one can use multiple of these
during inference to change the behavior of the base model. In this paper we
investigated whether multiple LoRA adapters trained on computer vision tasks
can be merged together and used during inference without loss in performance.
By achieving this, multitask models can be created just by merging different
LoRAs. Merging these will reduce inference time and it will not require any
additional retraining. We have trained adapters on six different tasks and
evaluated their performance when they are merged together. For comparison we
used a model with a frozen backbone and finetuned its head. Our results show
that even with simple merging techniques creating a multitask model by merging
adapters is achievable by slightly loosing performance in some cases. In our
experiments we merged up to three adapters together. Depending on the task and
the similarity of the data adapters were trained on, merges can outperform head
finetuning. We have observed that LoRAs trained with dissimilar datasets tend
to perform better compared to model trained on similar datasets.

摘要：参数高效微调 (PEFT) 方法广泛用于语言大模型和计算机视觉中的生成模型。特别是在推理期间，可以利用其中多个方法来改变基础模型的行为。在本文中，我们研究了是否可以将针对计算机视觉任务训练的多个 LoRA 适配器合并在一起并在推理期间使用，而不会损失性能。通过实现这一点，只需合并不同的 LoRA 即可创建多任务模型。合并这些模型将减少推理时间，并且不需要任何额外的重新训练。我们在六个不同的任务上训练了适配器，并在合并后评估了它们的性能。为了进行比较，我们使用了一个冻结主干并对其头部进行微调的模型。我们的结果表明，即使使用简单的合并技术，通过合并适配器创建多任务模型也是可行的，在某些情况下会略微降低性能。在我们的实验中，我们将多达三个适配器合并在一起。根据任务和训练适配器的数据的相似性，合并可以优于头部微调。我们观察到，使用不同数据集训练的 LoRA 与在类似数据集上训练的模型相比，往往表现得更好。

##### **MMGenBench: Evaluating the Limits of LMMs from the Text-to-Image Generation Perspective**
2411.14062v1 by Hailang Huang, Yong Wang, Zixuan Huang, Huaqiu Li, Tongwen Huang, Xiangxiang Chu, Richong Zhang

Large Multimodal Models (LMMs) have demonstrated remarkable capabilities.
While existing benchmarks for evaluating LMMs mainly focus on image
comprehension, few works evaluate them from the image generation perspective.
To address this issue, we propose a straightforward automated evaluation
pipeline. Specifically, this pipeline requires LMMs to generate an image-prompt
from a given input image. Subsequently, it employs text-to-image generative
models to create a new image based on these generated prompts. Finally, we
evaluate the performance of LMMs by comparing the original image with the
generated one. Furthermore, we introduce MMGenBench-Test, a comprehensive
benchmark developed to evaluate LMMs across 13 distinct image patterns, and
MMGenBench-Domain, targeting the performance evaluation of LMMs within the
generative image domain. A thorough evaluation involving over 50 popular LMMs
demonstrates the effectiveness and reliability in both the pipeline and
benchmark. Our observations indicate that numerous LMMs excelling in existing
benchmarks fail to adequately complete the basic tasks, related to image
understanding and description. This finding highlights the substantial
potential for performance improvement in current LMMs and suggests avenues for
future model optimization. Concurrently, our pipeline facilitates the efficient
assessment of LMMs performance across diverse domains by using solely image
inputs.

摘要：大型多模态模型 (LMM) 已展示出惊人的能力。
虽然用于评估 LMM 的现有基准主要关注图像理解，但很少有研究从图像生成的角度对其进行评估。
为了解决这个问题，我们提出了一种直接的自动化评估管道。具体来说，此管道要求 LMM 从给定的输入图像生成图像提示。随后，它使用文本到图像生成模型根据这些生成的提示创建新图像。最后，我们通过比较原始图像和生成图像来评估 LMM 的性能。此外，我们引入了 MMGenBench-Test，这是一个综合基准，用于评估 13 种不同图像模式的 LMM，以及 MMGenBench-Domain，针对生成图像域中 LMM 的性能评估。涉及 50 多个流行 LMM 的全面评估证明了管道和基准的有效性和可靠性。我们的观察结果表明，许多在现有基准中表现出色的 LMM 无法充分完成与图像理解和描述相关的基本任务。这一发现突显了当前 LMM 中性能改进的巨大潜力，并为未来的模型优化提供了途径。同时，我们的管道仅使用图像输入即可促进跨不同领域的 LMM 性能的有效评估。

##### **DRPruning: Efficient Large Language Model Pruning through Distributionally Robust Optimization**
2411.14055v1 by Hexuan Deng, Wenxiang Jiao, Xuebo Liu, Min Zhang, Zhaopeng Tu

Large language models (LLMs) deliver impressive results but face challenges
from increasing model sizes and computational costs. Structured pruning reduces
model size and speeds up inference but often causes uneven degradation across
domains, leading to biased performance. To address this, we propose DRPruning,
which incorporates distributionally robust optimization to restore balanced
performance across domains, along with further improvements to enhance
robustness. Experiments in monolingual and multilingual settings show that our
method surpasses similarly sized models in pruning and continued pretraining
over perplexity, downstream tasks, and instruction tuning. We further provide
analysis demonstrating the robustness of our method towards various domains and
distribution shifts. Furthermore, our method automatically determines optimal
reference losses and data ratios, suggesting potential for broader
applications. Our code is available at https://github.com/hexuandeng/DRPruning.

摘要：大型語言模型 (LLM) 提供令人印象深刻的結果，但面臨模型規模和運算成本增加的挑戰。結構化剪枝可減少模型大小並加速推理，但通常會導致不同領域的性能下降不均，進而導致性能偏差。為了解決這個問題，我們提出了 DRPruning，它結合了分布穩健最佳化，以恢復不同領域的平衡性能，同時進一步改進以增強穩健性。單語和多語環境中的實驗表明，我們的模型在剪枝和持續預訓練方面優於大小相似的模型，在困惑度、下游任務和指令調整方面表現出色。我們進一步提供了分析，證明了我們的模型對各種領域和分佈轉移的穩健性。此外，我們的模型自動確定最佳參考損失和數據比率，表明其在更廣泛的應用中具有潛力。我們的程式碼可在 https://github.com/hexuandeng/DRPruning 取得。

##### **FunctionChat-Bench: Comprehensive Evaluation of Language Models' Generative Capabilities in Korean Tool-use Dialogs**
2411.14054v1 by Shinbok Lee, Gaeun Seo, Daniel Lee, Byeongil Ko, Sunghee Jung, Myeongcheol Shin

This study investigates language models' generative capabilities in tool-use
dialogs. We categorize the models' outputs in tool-use dialogs into four
distinct types: Tool Call, Answer Completion, Slot Question, and Relevance
Detection, which serve as aspects for evaluation. We introduce
FunctionChat-Bench, comprising 700 evaluation items and automated assessment
programs. Using this benchmark, we evaluate several language models that
support function calling. Our findings indicate that while language models may
exhibit high accuracy in single-turn Tool Call scenarios, this does not
necessarily translate to superior generative performance in multi-turn
environments. We argue that the capabilities required for function calling
extend beyond generating tool call messages; they must also effectively
generate conversational messages that engage the user.

摘要：本研究探討語言模型在工具使用對話中的生成能力。我們將模型在工具使用對話中的輸出分為四種類型：工具呼叫、答案完成、插槽問題和相關性偵測，作為評估的方面。我們引入了 FunctionChat-Bench，包含 700 個評估項目和自動化評估程式。使用此基準，我們評估了支援函式呼叫的幾個語言模型。我們的研究結果表明，儘管語言模型在單回合工具呼叫場景中可能表現出高準確性，但這並不一定能轉化為多回合環境中的優異生成效能。我們認為，函式呼叫所需的能力不只限於產生工具呼叫訊息；它們還必須有效產生能與使用者互動的對話訊息。

##### **Forecasting Future International Events: A Reliable Dataset for Text-Based Event Modeling**
2411.14042v1 by Daehoon Gwak, Junwoo Park, Minho Park, Chaehun Park, Hyunchan Lee, Edward Choi, Jaegul Choo

Predicting future international events from textual information, such as news
articles, has tremendous potential for applications in global policy, strategic
decision-making, and geopolitics. However, existing datasets available for this
task are often limited in quality, hindering the progress of related research.
In this paper, we introduce WORLDREP (WORLD Relationship and Event Prediction),
a novel dataset designed to address these limitations by leveraging the
advanced reasoning capabilities of large-language models (LLMs). Our dataset
features high-quality scoring labels generated through advanced prompt modeling
and rigorously validated by domain experts in political science. We showcase
the quality and utility of WORLDREP for real-world event prediction tasks,
demonstrating its effectiveness through extensive experiments and analysis.
Furthermore, we publicly release our dataset along with the full automation
source code for data collection, labeling, and benchmarking, aiming to support
and advance research in text-based event prediction.

摘要：從新聞文章等文字資訊預測未來國際事件，在全球政策、策略決策和地緣政治等應用領域具有巨大的潛力。然而，現有可用的資料集品質往往有限，阻礙了相關研究的進展。在本文中，我們介紹了 WORLDREP（世界關係與事件預測），這是一個新穎的資料集，旨在透過利用大型語言模型 (LLM) 的先進推理能力來解決這些限制。我們的資料集的特點是透過先進提示建模產生的高品質評分標籤，並由政治科學領域專家嚴格驗證。我們展示了 WORLDREP 在現實世界事件預測任務中的品質和效用，並透過廣泛的實驗和分析證明了其有效性。此外，我們公開發布我們的資料集，以及用於資料收集、標記和基準測試的完整自動化原始碼，旨在支援和推進基於文字的事件預測研究。

##### **Uterine Ultrasound Image Captioning Using Deep Learning Techniques**
2411.14039v1 by Abdennour Boulesnane, Boutheina Mokhtari, Oumnia Rana Segueni, Slimane Segueni

Medical imaging has significantly revolutionized medical diagnostics and
treatment planning, progressing from early X-ray usage to sophisticated methods
like MRIs, CT scans, and ultrasounds. This paper investigates the use of deep
learning for medical image captioning, with a particular focus on uterine
ultrasound images. These images are vital in obstetrics and gynecology for
diagnosing and monitoring various conditions across different age groups.
However, their interpretation is often challenging due to their complexity and
variability. To address this, a deep learning-based medical image captioning
system was developed, integrating Convolutional Neural Networks with a
Bidirectional Gated Recurrent Unit network. This hybrid model processes both
image and text features to generate descriptive captions for uterine ultrasound
images. Our experimental results demonstrate the effectiveness of this approach
over baseline methods, with the proposed model achieving superior performance
in generating accurate and informative captions, as indicated by higher BLEU
and ROUGE scores. By enhancing the interpretation of uterine ultrasound images,
our research aims to assist medical professionals in making timely and accurate
diagnoses, ultimately contributing to improved patient care.

摘要：醫學影像大幅革新了醫療診斷和治療計畫，從早期的 X 光使用進展到 MRI、電腦斷層掃描和超音波等精密方法。這篇論文探討深度學習在醫學影像標題中的應用，特別著重於子宮超音波影像。這些影像在婦產科中對於診斷和追蹤不同年齡層的各種疾病至關重要。然而，由於其複雜性和變異性，它們的詮釋通常具有挑戰性。為了解決這個問題，開發了一個基於深度學習的醫學影像標題系統，將卷積神經網路與雙向門控循環單元網路整合在一起。這個混合模型處理影像和文字特徵，為子宮超音波影像產生描述性標題。我們的實驗結果證明了此方法優於基線方法的有效性，所提出的模型在產生準確且有意義的標題方面達到了卓越的效能，這由較高的 BLEU 和 ROUGE 分數所證明。透過增強子宮超音波影像的詮釋，我們的研究旨在協助醫療專業人員進行及時且準確的診斷，最終有助於改善病患照護。

##### **Multi-LLM-Agent Systems: Techniques and Business Perspectives**
2411.14033v1 by Yingxuan Yang, Qiuying Peng, Jun Wang, Weinan Zhang

In the era of (multi-modal) large language models, most operational processes
can be reformulated and reproduced using LLM agents. The LLM agents can
perceive, control, and get feedback from the environment so as to accomplish
the given tasks in an autonomous manner. Besides the environment-interaction
property, the LLM agents can call various external tools to ease the task
completion process. The tools can be regarded as a predefined operational
process with private or real-time knowledge that does not exist in the
parameters of LLMs. As a natural trend of development, the tools for calling
are becoming autonomous agents, thus the full intelligent system turns out to
be a multi-LLM-agent system (MLAS). This paper discusses the technical and
business landscapes of MLAS. Compared to the previous single-LLM-agent system,
a MLAS has the advantages of i) higher potential of task-solving performance,
ii) higher flexibility for system changing, iii) proprietary data preserving
for each participating entity, and iv) feasibility of monetization for each
entity. To support the ecosystem of MLAS, we provide a preliminary version of
such MLAS protocol considering technical requirements, data privacy, and
business incentives. As such, MLAS would be a practical solution to achieve
artificial collective intelligence in the near future.

摘要：在（多模态）大语言模型的时代，大多数操作流程
可以使用 LLM 代理重新表述和复制。LLM 代理可以
感知、控制和从环境中获取反馈，以便以自主的方式完成
给定的任务。除了环境交互
属性外，LLM 代理还可以调用各种外部工具来简化任务
完成过程。这些工具可以被视为具有私有或实时知识的预定义操作
流程，这些知识不存在于 LLM 的参数中。作为一种自然的发展趋势，用于调用的工具
正在成为自主代理，因此完整的智能系统变成了
多 LLM 代理系统 (MLAS)。本文讨论了 MLAS 的技术和
商业前景。与之前的单 LLM 代理系统相比，
MLAS 具有以下优势：i) 更高的任务解决性能潜力，
ii) 更高的系统更改灵活性，iii) 每个参与实体的专有数据保留，以及 iv) 每个
实体的货币化可行性。为了支持 MLAS 生态系统，我们提供了一个初步版本
此类 MLAS 协议考虑技术要求、数据隐私和
商业激励。因此，MLAS 将成为在不久的将来实现
人工智能集体智能的实用解决方案。

##### **Trajectory Representation Learning on Road Networks and Grids with Spatio-Temporal Dynamics**
2411.14014v1 by Stefan Schestakov, Simon Gottschalk

Trajectory representation learning is a fundamental task for applications in
fields including smart city, and urban planning, as it facilitates the
utilization of trajectory data (e.g., vehicle movements) for various downstream
applications, such as trajectory similarity computation or travel time
estimation. This is achieved by learning low-dimensional representations from
high-dimensional and raw trajectory data. However, existing methods for
trajectory representation learning either rely on grid-based or road-based
representations, which are inherently different and thus, could lose
information contained in the other modality. Moreover, these methods overlook
the dynamic nature of urban traffic, relying on static road network features
rather than time varying traffic patterns. In this paper, we propose TIGR, a
novel model designed to integrate grid and road network modalities while
incorporating spatio-temporal dynamics to learn rich, general-purpose
representations of trajectories. We evaluate TIGR on two realworld datasets and
demonstrate the effectiveness of combining both modalities by substantially
outperforming state-of-the-art methods, i.e., up to 43.22% for trajectory
similarity, up to 16.65% for travel time estimation, and up to 10.16% for
destination prediction.

摘要：軌跡表示學習是智慧城市和都市規劃等領域應用的一項基本任務，因為它促進了軌跡資料（例如車輛移動）在各種下游應用程式中的使用，例如軌跡相似性計算或旅行時間估計。這是透過從高維度和原始軌跡資料中學習低維度表示來實現的。然而，現有的軌跡表示學習方法依賴於基於網格或基於道路的表示，它們本質上是不同的，因此可能會遺失包含在另一種方式中的資訊。此外，這些方法忽略了城市交通的動態特性，依賴於靜態道路網路特徵，而不是時間變動的交通模式。在本文中，我們提出 TIGR，這是一個新穎的模型，旨在整合網格和道路網路方式，同時納入時空動態以學習軌跡的豐富通用表示。我們在兩個真實世界資料集上評估 TIGR，並透過大幅優於現有方法來證明結合兩種方式的有效性，即軌跡相似性最多 43.22%、旅行時間估計最多 16.65% 和目的地預測最多 10.16%。

##### **Logic Augmented Generation**
2411.14012v1 by Aldo Gangemi, Andrea Giovanni Nuzzolese

Semantic Knowledge Graphs (SKG) face challenges with scalability,
flexibility, contextual understanding, and handling unstructured or ambiguous
information. However, they offer formal and structured knowledge enabling
highly interpretable and reliable results by means of reasoning and querying.
Large Language Models (LLMs) overcome those limitations making them suitable in
open-ended tasks and unstructured environments. Nevertheless, LLMs are neither
interpretable nor reliable. To solve the dichotomy between LLMs and SKGs we
envision Logic Augmented Generation (LAG) that combines the benefits of the two
worlds. LAG uses LLMs as Reactive Continuous Knowledge Graphs that can generate
potentially infinite relations and tacit knowledge on-demand. SKGs are key for
injecting a discrete heuristic dimension with clear logical and factual
boundaries. We exemplify LAG in two tasks of collective intelligence, i.e.,
medical diagnostics and climate projections. Understanding the properties and
limitations of LAG, which are still mostly unknown, is of utmost importance for
enabling a variety of tasks involving tacit knowledge in order to provide
interpretable and effective results.

摘要：語意知識圖（SKG）在可擴充性、靈活性、情境理解以及處理非結構化或含糊資訊方面面臨挑戰。然而，它們提供正式且結構化的知識，能透過推理和查詢提供高度可解釋且可靠的結果。大型語言模型（LLM）克服了這些限制，使其適用於開放式任務和非結構化環境。儘管如此，LLM 既不可解釋也不可靠。為了解決 LLM 和 SKG 之間的二分法，我們設想了邏輯增強生成（LAG），它結合了兩個世界的優點。LAG 使用 LLM 作為反應式連續知識圖，它可以按需產生潛在的無限關係和默會知識。SKG 是注入離散啟發式維度（具有明確邏輯和事實邊界）的關鍵。我們在集體智慧的兩個任務中舉例說明 LAG，即醫療診斷和氣候預測。理解 LAG 的特性和限制（目前仍然大多數未知）對於啟用涉及默會知識的各種任務以提供可解釋且有效的結果至關重要。

##### **Mirror Target YOLO: An Improved YOLOv8 Method with Indirect Vision for Heritage Buildings Fire Detection**
2411.13997v1 by Jian Liang, JunSheng Cheng

Fires can cause severe damage to heritage buildings, making timely fire
detection essential. Traditional dense cabling and drilling can harm these
structures, so reducing the number of cameras to minimize such impact is
challenging. Additionally, avoiding false alarms due to noise sensitivity and
preserving the expertise of managers in fire-prone areas is crucial. To address
these needs, we propose a fire detection method based on indirect vision,
called Mirror Target YOLO (MITA-YOLO). MITA-YOLO integrates indirect vision
deployment and an enhanced detection module. It uses mirror angles to achieve
indirect views, solving issues with limited visibility in irregular spaces and
aligning each indirect view with the target monitoring area. The Target-Mask
module is designed to automatically identify and isolate the indirect vision
areas in each image, filtering out non-target areas. This enables the model to
inherit managers' expertise in assessing fire-risk zones, improving focus and
resistance to interference in fire detection.In our experiments, we created an
800-image fire dataset with indirect vision. Results show that MITA-YOLO
significantly reduces camera requirements while achieving superior detection
performance compared to other mainstream models.

摘要：火災會對古蹟建築造成嚴重損害，因此及時偵測火災至關重要。傳統的密集佈線和鑽孔可能會損害這些結構，因此減少相機數量以將此類影響降至最低具有挑戰性。此外，避免因噪音敏感性而發出錯誤警報並保留火災多發地區管理人員的專業知識至關重要。為了滿足這些需求，我們提出了一種基於間接視覺的火災檢測方法，稱為 Mirror Target YOLO (MITA-YOLO)。MITA-YOLO 整合了間接視覺部署和增強的檢測模組。它使用鏡面角度來獲得間接視角，解決了不規則空間中能見度受限的問題，並將每個間接視角與目標監控區域對齊。Target-Mask 模組旨在自動識別和隔離每個影像中的間接視覺區域，濾除非目標區域。這使模型能夠繼承管理人員在評估火災風險區域方面的專業知識，提高焦點和抗干擾能力，以進行火災檢測。在我們的實驗中，我們創建了一個具有間接視覺的 800 張影像火災資料集。結果表明，與其他主流模型相比，MITA-YOLO 大幅減少了相機需求，同時實現了卓越的檢測效能。

##### **Safety Without Semantic Disruptions: Editing-free Safe Image Generation via Context-preserving Dual Latent Reconstruction**
2411.13982v1 by Jordan Vice, Naveed Akhtar, Richard Hartley, Ajmal Mian

Training multimodal generative models on large, uncurated datasets can result
in users being exposed to harmful, unsafe and controversial or
culturally-inappropriate outputs. While model editing has been proposed to
remove or filter undesirable concepts in embedding and latent spaces, it can
inadvertently damage learned manifolds, distorting concepts in close semantic
proximity. We identify limitations in current model editing techniques, showing
that even benign, proximal concepts may become misaligned. To address the need
for safe content generation, we propose a modular, dynamic solution that
leverages safety-context embeddings and a dual reconstruction process using
tunable weighted summation in the latent space to generate safer images. Our
method preserves global context without compromising the structural integrity
of the learned manifolds. We achieve state-of-the-art results on safe image
generation benchmarks, while offering controllable variation of model safety.
We identify trade-offs between safety and censorship, which presents a
necessary perspective in the development of ethical AI models. We will release
our code.
  Keywords: Text-to-Image Models, Generative AI, Safety, Reliability, Model
Editing

摘要：<paragraph>在大型、未整理的数据集上训练多模态生成模型可能会导致
用户接触到有害、不安全和有争议或
文化上不恰当的输出。虽然已经提出模型编辑来
删除或过滤嵌入和潜在空间中的不良概念，但它可以
无意中损坏学习流形，扭曲语义中紧密的概念
邻近度。我们发现当前模型编辑技术的局限性，表明
即使是良性的、近似的概念也可能变得不一致。为了解决
安全内容生成的需求，我们提出了一种模块化、动态的解决方案，
利用安全上下文嵌入和使用可调加权和的双重重建过程
在潜在空间中生成更安全的图像。我们的
方法保留了全局上下文，同时不损害学习流形的结构完整性。我们在安全图像中取得了最先进的结果
生成基准，同时提供模型安全性的可控变化。
我们确定了安全和审查之间的权衡，这提出了一个
在开发道德人工智能模型中必要的视角。我们将发布
我们的代码。
关键词：文本到图像模型、生成式人工智能、安全、可靠性、模型
编辑</paragraph>

##### **On the Fairness, Diversity and Reliability of Text-to-Image Generative Models**
2411.13981v1 by Jordan Vice, Naveed Akhtar, Richard Hartley, Ajmal Mian

The widespread availability of multimodal generative models has sparked
critical discussions on their fairness, reliability, and potential for misuse.
While text-to-image models can produce high-fidelity, user-guided images, they
also exhibit unpredictable behavior and vulnerabilities, which can be exploited
to manipulate class or concept representations. To address this, we propose an
evaluation framework designed to assess model reliability through their
responses to globally- and locally-applied `semantic' perturbations in the
embedding space, pinpointing inputs that trigger unreliable behavior. Our
approach offers deeper insights into two essential aspects: (i) generative
diversity, evaluating the breadth of visual representations for learned
concepts, and (ii) generative fairness, examining how removing concepts from
input prompts affects semantic guidance. Beyond these evaluations, our method
lays the groundwork for detecting unreliable, bias-injected models and
retrieval of bias provenance. We will release our code.
  Keywords: Fairness, Reliability, AI Ethics, Bias, Text-to-Image Models

摘要：多模态生成模型的广泛可用性引发了对其公平性、可靠性和潜在滥用风险的关键讨论。虽然文本到图像模型可以生成高保真度、用户引导的图像，但它们也表现出不可预测的行为和漏洞，这些行为和漏洞可被利用来操纵类别或概念表征。为了解决这个问题，我们提出了一个评估框架，旨在通过模型对嵌入空间中全局和局部应用的“语义”扰动的响应来评估模型可靠性，从而找出触发不可靠行为的输入。我们的方法对两个基本方面提供了更深入的见解：(i) 生成多样性，评估学习概念的可视化表征的广度，以及 (ii) 生成公平性，检查从输入提示中移除概念如何影响语义指导。除了这些评估之外，我们的方法还为检测不可靠的、注入偏差的模型和检索偏差来源奠定了基础。我们将发布我们的代码。
关键词：公平性、可靠性、人工智能伦理、偏差、文本到图像模型

##### **FedRAV: Hierarchically Federated Region-Learning for Traffic Object Classification of Autonomous Vehicles**
2411.13979v1 by Yijun Zhai, Pengzhan Zhou, Yuepeng He, Fang Qu, Zhida Qin, Xianlong Jiao, Guiyan Liu, Songtao Guo

The emerging federated learning enables distributed autonomous vehicles to
train equipped deep learning models collaboratively without exposing their raw
data, providing great potential for utilizing explosively growing autonomous
driving data. However, considering the complicated traffic environments and
driving scenarios, deploying federated learning for autonomous vehicles is
inevitably challenged by non-independent and identically distributed (Non-IID)
data of vehicles, which may lead to failed convergence and low training
accuracy. In this paper, we propose a novel hierarchically Federated
Region-learning framework of Autonomous Vehicles (FedRAV), a two-stage
framework, which adaptively divides a large area containing vehicles into
sub-regions based on the defined region-wise distance, and achieves
personalized vehicular models and regional models. This approach ensures that
the personalized vehicular model adopts the beneficial models while discarding
the unprofitable ones. We validate our FedRAV framework against existing
federated learning algorithms on three real-world autonomous driving datasets
in various heterogeneous settings. The experiment results demonstrate that our
framework outperforms those known algorithms, and improves the accuracy by at
least 3.69%. The source code of FedRAV is available at:
https://github.com/yjzhai-cs/FedRAV.

摘要：新興的聯邦學習使分散的自動駕駛車輛能夠在不公開其原始數據的情況下協作訓練配備的深度學習模型，為利用爆炸性增長的自動駕駛數據提供了巨大的潛力。然而，考慮到複雜的交通環境和駕駛場景，為自動駕駛車輛部署聯邦學習不可避免地會受到車輛的非獨立同分布 (Non-IID) 數據的挑戰，這可能導致收斂失敗和訓練精度低。在本文中，我們提出了一個新穎的分層聯邦區域學習自動駕駛車輛框架 (FedRAV)，這是一個兩階段框架，它根據定義的區域距離自適應地將包含車輛的大區域劃分為子區域，並實現個性化車輛模型和區域模型。此方法確保個性化車輛模型採用有益模型，同時捨棄無利可圖的模型。我們在各種異構設置下的三個真實世界自動駕駛數據集上驗證了我們的 FedRAV 框架與現有的聯邦學習演算法。實驗結果表明，我們的框架優於那些已知的演算法，並將準確度提高了至少 3.69%。FedRAV 的原始碼可在以下位置取得：
https://github.com/yjzhai-cs/FedRAV。

##### **Separable Mixture of Low-Rank Adaptation for Continual Visual Instruction Tuning**
2411.13949v1 by Ziqi Wang, Chang Che, Qi Wang, Yangyang Li, Zenglin Shi, Meng Wang

Visual instruction tuning (VIT) enables multimodal large language models
(MLLMs) to effectively handle a wide range of vision tasks by framing them as
language-based instructions. Building on this, continual visual instruction
tuning (CVIT) extends the capability of MLLMs to incrementally learn new tasks,
accommodating evolving functionalities. While prior work has advanced CVIT
through the development of new benchmarks and approaches to mitigate
catastrophic forgetting, these efforts largely follow traditional continual
learning paradigms, neglecting the unique challenges specific to CVIT. We
identify a dual form of catastrophic forgetting in CVIT, where MLLMs not only
forget previously learned visual understanding but also experience a decline in
instruction following abilities as they acquire new tasks. To address this, we
introduce the Separable Mixture of Low-Rank Adaptation (SMoLoRA) framework,
which employs separable routing through two distinct modules - one for visual
understanding and another for instruction following. This dual-routing design
enables specialized adaptation in both domains, preventing forgetting while
improving performance. Furthermore, we propose a novel CVIT benchmark that goes
beyond existing benchmarks by additionally evaluating a model's ability to
generalize to unseen tasks and handle diverse instructions across various
tasks. Extensive experiments demonstrate that SMoLoRA outperforms existing
methods in mitigating dual forgetting, improving generalization to unseen
tasks, and ensuring robustness in following diverse instructions.

摘要：視覺指令微調 (VIT) 能讓多模態大型語言模型 (MLLM) 有效處理廣泛的視覺任務，方法是將它們建構為基於語言的指令。在此基礎上，持續視覺指令微調 (CVIT) 擴展了 MLLM 的能力，讓它們能逐步學習新任務，以適應不斷變化的功能。儘管先前的工作已透過開發新的基準和方法來緩解災難性遺忘，進而推動 CVIT 的進步，但這些努力在很大程度上遵循傳統的持續學習範例，忽略了 CVIT 特有的獨特挑戰。我們在 CVIT 中發現了一種災難性遺忘的雙重形式，其中 MLLM 不僅遺忘了先前學習的視覺理解，而且在獲得新任務時，其遵循指令的能力也會下降。為了解決這個問題，我們引入了可分離低秩適應混合 (SMoLoRA) 框架，它採用可分離路由，透過兩個不同的模組來執行，一個模組用於視覺理解，另一個模組用於遵循指令。這種雙重路由設計可以在兩個領域中進行專門適應，防止遺忘，同時提升效能。此外，我們提出了一個新穎的 CVIT 基準，它超越了現有的基準，進一步評估模型在各種任務中概括到未見任務和處理不同指令的能力。廣泛的實驗證明，SMoLoRA 在減輕雙重遺忘、改善對未見任務的概括以及確保遵循不同指令的穩健性方面，都優於現有方法。

##### **LLMs as Continuous Learners: Improving the Reproduction of Defective Code in Software Issues**
2411.13941v1 by Yalan Lin, Yingwei Ma, Rongyu Cao, Binhua Li, Fei Huang, Xiaodong Gu, Yongbin Li

Reproducing buggy code is the first and crucially important step in issue
resolving, as it aids in identifying the underlying problems and validating
that generated patches resolve the problem. While numerous approaches have been
proposed for this task, they primarily address common, widespread errors and
struggle to adapt to unique, evolving errors specific to individual code
repositories. To fill this gap, we propose EvoCoder, a multi-agent continuous
learning framework for issue code reproduction. EvoCoder adopts a reflection
mechanism that allows the LLM to continuously learn from previously resolved
problems and dynamically refine its strategies to new emerging challenges. To
prevent experience bloating, EvoCoder introduces a novel hierarchical
experience pool that enables the model to adaptively update common and
repo-specific experiences. Our experimental results show a 20\% improvement in
issue reproduction rates over existing SOTA methods. Furthermore, integrating
our reproduction mechanism significantly boosts the overall accuracy of the
existing issue-resolving pipeline.

摘要：重现错误代码是解决问题的第一个也是至关重要的一步，因为它有助于识别潜在的问题并验证所生成的补丁是否解决了问题。虽然针对此任务已提出许多方法，但它们主要解决常见、广泛的错误，并且难以适应特定于各个代码存储库的独特、不断发展的错误。为了填补这一空白，我们提出了 EvoCoder，一个用于问题代码重现的多代理连续学习框架。EvoCoder 采用了一种反射机制，允许 LLM 持续从先前解决的问题中学习，并动态地完善其应对新出现的挑战的策略。为了防止经验膨胀，EvoCoder 引入了一个新颖的分层经验池，使模型能够自适应地更新常见和特定于存储库的经验。我们的实验结果表明，与现有的 SOTA 方法相比，问题重现率提高了 20%。此外，集成我们的重现机制显著提高了现有问题解决管道的整体准确性。

##### **Learning to Cooperate with Humans using Generative Agents**
2411.13934v1 by Yancheng Liang, Daphne Chen, Abhishek Gupta, Simon S. Du, Natasha Jaques

Training agents that can coordinate zero-shot with humans is a key mission in
multi-agent reinforcement learning (MARL). Current algorithms focus on training
simulated human partner policies which are then used to train a Cooperator
agent. The simulated human is produced either through behavior cloning over a
dataset of human cooperation behavior, or by using MARL to create a population
of simulated agents. However, these approaches often struggle to produce a
Cooperator that can coordinate well with real humans, since the simulated
humans fail to cover the diverse strategies and styles employed by people in
the real world. We show \emph{learning a generative model of human partners}
can effectively address this issue. Our model learns a latent variable
representation of the human that can be regarded as encoding the human's unique
strategy, intention, experience, or style. This generative model can be
flexibly trained from any (human or neural policy) agent interaction data. By
sampling from the latent space, we can use the generative model to produce
different partners to train Cooperator agents. We evaluate our method --
\textbf{G}enerative \textbf{A}gent \textbf{M}odeling for \textbf{M}ulti-agent
\textbf{A}daptation (GAMMA) -- on Overcooked, a challenging cooperative cooking
game that has become a standard benchmark for zero-shot coordination. We
conduct an evaluation with real human teammates, and the results show that
GAMMA consistently improves performance, whether the generative model is
trained on simulated populations or human datasets. Further, we propose a
method for posterior sampling from the generative model that is biased towards
the human data, enabling us to efficiently improve performance with only a
small amount of expensive human interaction data.

摘要：<paragraph>訓練能與人類零次學習協調的代理程式，是多重代理強化學習 (MARL) 的一項關鍵任務。目前的演算法專注於訓練模擬的人類夥伴政策，然後用於訓練合作代理程式。模擬的人類是透過對人類合作行為資料集進行行為複製產生，或透過使用 MARL 建立模擬代理程式族群。然而，這些方法通常難以產生能與真實人類協調良好的合作代理程式，因為模擬的人類無法涵蓋現實世界中人類所使用的各種策略和風格。我們展示「學習人類夥伴的生成模型」能有效解決這個問題。我們的模型學習人類的潛在變數表示，可視為編碼人類的獨特策略、意圖、經驗或風格。這個生成模型能靈活地從任何（人類或神經網路政策）代理程式互動資料中進行訓練。透過從潛在空間取樣，我們可以使用生成模型產生不同的夥伴來訓練合作代理程式。我們評估我們的模型——多重代理適應的生成代理程式建模 (GAMMA)——在 Overcooked 上，這是一個具有挑戰性的合作烹飪遊戲，已成為零次學習協調的標準基準。我們與真實的人類隊友進行評估，結果顯示無論生成模型是針對模擬族群或人類資料集進行訓練，GAMMA 都能持續改善效能。此外，我們提出一個從生成模型中進行後驗取樣的模型，該模型偏向於人類資料，使我們能夠僅使用少量的昂貴人類互動資料來有效提升效能。</paragraph>

##### **XAgents: A Framework for Interpretable Rule-Based Multi-Agents Cooperation**
2411.13932v1 by Hailong Yang, Mingxian Gu, Renhuo Zhao, Fuping Hu, Zhaohong Deng, Yitang Chen

Extracting implicit knowledge and logical reasoning abilities from large
language models (LLMs) has consistently been a significant challenge. The
advancement of multi-agent systems has further en-hanced the capabilities of
LLMs. Inspired by the structure of multi-polar neurons (MNs), we propose the
XAgents framework, an in-terpretable multi-agent cooperative framework based on
the IF-THEN rule-based system. The IF-Parts of the rules are responsible for
logical reasoning and domain membership calculation, while the THEN-Parts are
comprised of domain expert agents that generate domain-specific contents.
Following the calculation of the member-ship, XAgetns transmits the task to the
disparate domain rules, which subsequently generate the various responses.
These re-sponses are analogous to the answers provided by different experts to
the same question. The final response is reached at by eliminat-ing the
hallucinations and erroneous knowledge of the LLM through membership
computation and semantic adversarial genera-tion of the various domain rules.
The incorporation of rule-based interpretability serves to bolster user
confidence in the XAgents framework. We evaluate the efficacy of XAgents
through a com-parative analysis with the latest AutoAgents, in which XAgents
demonstrated superior performance across three distinct datasets. We perform
post-hoc interpretable studies with SHAP algorithm and case studies, proving
the interpretability of XAgent in terms of input-output feature correlation and
rule-based semantics.

摘要：<paragraph>從大型語言模型 (LLM) 中萃取隱含知識和邏輯推理能力一直都是一項重大挑戰。多主體系統的進展進一步增強了 LLM 的能力。受多極神經元 (MN) 的結構啟發，我們提出 XAgents 框架，一個基於 IF-THEN 規則系統的可解釋多主體合作框架。規則的 IF 部分負責邏輯推理和領域成員計算，而 THEN 部分由產生特定領域內容的領域專家主體組成。在計算成員資格後，XAgetns 將任務傳遞給不同的領域規則，隨後生成各種回應。這些回應類似於不同專家對同一個問題提供的答案。最終的回應是透過消除 LLM 的幻覺和錯誤知識，藉由成員計算和各種領域規則的語義對抗產生而達成的。基於規則的可解釋性的納入有助於提升使用者對 XAgents 框架的信心。我們透過與最新的 AutoAgents 進行比較分析來評估 XAgents 的效能，其中 XAgents 在三個不同的資料集上展現出優異的效能。我們使用 SHAP 演算法和案例研究進行事後可解釋性研究，證明 XAgent 在輸入輸出特徵關聯性和基於規則的語義方面的可解釋性。</paragraph>

##### **Split Federated Learning Over Heterogeneous Edge Devices: Algorithm and Optimization**
2411.13907v1 by Yunrui Sun, Gang Hu, Yinglei Teng, Dunbo Cai

Split Learning (SL) is a promising collaborative machine learning approach,
enabling resource-constrained devices to train models without sharing raw data,
while reducing computational load and preserving privacy simultaneously.
However, current SL algorithms face limitations in training efficiency and
suffer from prolonged latency, particularly in sequential settings, where the
slowest device can bottleneck the entire process due to heterogeneous resources
and frequent data exchanges between clients and servers. To address these
challenges, we propose the Heterogeneous Split Federated Learning (HSFL)
framework, which allows resource-constrained clients to train their
personalized client-side models in parallel, utilizing different cut layers.
Aiming to mitigate the impact of heterogeneous environments and accelerate the
training process, we formulate a latency minimization problem that optimizes
computational and transmission resources jointly. Additionally, we design a
resource allocation algorithm that combines the Sample Average Approximation
(SAA), Genetic Algorithm (GA), Lagrangian relaxation and Branch and Bound
(B\&B) methods to efficiently solve this problem. Simulation results
demonstrate that HSFL outperforms other frameworks in terms of both convergence
rate and model accuracy on heterogeneous devices with non-iid data, while the
optimization algorithm is better than other baseline methods in reducing
latency.

摘要：分離式學習 (SL) 是一種有前景的協作機器學習方法，
讓資源受限的裝置能夠在不共用原始資料的情況下訓練模型，
同時減少運算負載並維護隱私。
然而，目前的 SL 演算法在訓練效率上遇到限制，
並在順序設定中遭受延遲過長的問題，特別是在順序設定中，
由於異質資源和客戶端與伺服器之間頻繁的資料交換，
最慢的裝置會成為整個流程的瓶頸。為了應對這些挑戰，
我們提出異質分離式聯邦學習 (HSFL) 架構，
允許資源受限的客戶端並行訓練其個人化的客戶端模型，
利用不同的切割層。為了減輕異質環境的影響並加速
訓練流程，我們制定了一個延遲最小化問題，
以最佳化運算和傳輸資源。此外，我們設計了一個
資源分配演算法，結合樣本平均近似 (SAA)、遺傳演算法 (GA)、
拉格朗日鬆弛和分支定界 (B&B) 方法來有效解決這個問題。
模擬結果證明，在具有非獨立同分布資料的異質裝置上，
HSFL 在收斂率和模型準確度方面都優於其他架構，
而最佳化演算法在降低延遲方面優於其他基準方法。

##### **Towards Full Delegation: Designing Ideal Agentic Behaviors for Travel Planning**
2411.13904v1 by Song Jiang, Da JU, Andrew Cohen, Sasha Mitts, Aaron Foss, Justine T Kao, Xian Li, Yuandong Tian

How are LLM-based agents used in the future? While many of the existing work
on agents has focused on improving the performance of a specific family of
objective and challenging tasks, in this work, we take a different perspective
by thinking about full delegation: agents take over humans' routine
decision-making processes and are trusted by humans to find solutions that fit
people's personalized needs and are adaptive to ever-changing context. In order
to achieve such a goal, the behavior of the agents, i.e., agentic behaviors,
should be evaluated not only on their achievements (i.e., outcome evaluation),
but also how they achieved that (i.e., procedure evaluation). For this, we
propose APEC Agent Constitution, a list of criteria that an agent should follow
for good agentic behaviors, including Accuracy, Proactivity, Efficiency and
Credibility. To verify whether APEC aligns with human preferences, we develop
APEC-Travel, a travel planning agent that proactively extracts hidden
personalized needs via multi-round dialog with travelers. APEC-Travel is
constructed purely from synthetic data generated by Llama3.1-405B-Instruct with
a diverse set of travelers' persona to simulate rich distribution of dialogs.
Iteratively fine-tuned to follow APEC Agent Constitution, APEC-Travel surpasses
baselines by 20.7% on rule-based metrics and 9.1% on LLM-as-a-Judge scores
across the constitution axes.

摘要：未來 LLM 基礎代理如何使用？儘管許多現有代理工作都專注於改善特定目標和挑戰任務的執行成效，但在此工作中，我們採用不同的觀點，思考全面委派：代理接手人類的例行決策過程，並獲得人類信任，為符合個人化需求且能適應不斷變化的脈絡找出解決方案。為了達成此一目標，代理的行為，亦即代理行為，應不僅根據其成就（亦即結果評估），還應根據其達成目標的方式（亦即程序評估）進行評估。為此，我們提出 APEC 代理憲法，這是一份代理應遵循的準則清單，以展現良好的代理行為，包括準確性、主動性、效率和可信度。為驗證 APEC 是否符合人類偏好，我們開發了 APEC-Travel，這是一個主動透過多輪對話從旅客身上找出隱藏個人化需求的旅遊規劃代理。APEC-Travel 純粹建構自 Llama3.1-405B-Instruct 所產生的合成資料，並具備多元的旅客角色，以模擬對話的豐富分佈。APEC-Travel 經過反覆微調以遵循 APEC 代理憲法，在基於規則的指標上超越基準 20.7%，在 LLM 作為評審分數上超越憲法軸線 9.1%。

##### **AmpliNetECG12: A lightweight SoftMax-based relativistic amplitude amplification architecture for 12 lead ECG classification**
2411.13903v1 by Shreya Srivastava

The urgent need to promptly detect cardiac disorders from 12-lead
Electrocardiograms using limited computations is motivated by the heart's fast
and complex electrical activity and restricted computational power of portable
devices. Timely and precise diagnoses are crucial since delays might
significantly impact patient health outcomes. This research presents a novel
deep-learning architecture that aims to diagnose heart abnormalities quickly
and accurately. We devised a new activation function called aSoftMax, designed
to improve the visibility of ECG deflections. The proposed activation function
is used with Convolutional Neural Network architecture to includes kernel
weight sharing across the ECG's various leads. This innovative method
thoroughly generalizes the global 12-lead ECG features and minimizes the
model's complexity by decreasing the trainable parameters. aSoftMax, combined
with enhanced CNN architecture yielded AmpliNetECG12, we obtain exceptional
accuracy of 84% in diagnosing cardiac disorders. AmpliNetECG12 shows
outstanding prediction ability when used with the CPSC2018 dataset for
arrhythmia classification. The model attains an F1-score of 80.71% and a
ROC-AUC score of 96.00%, with 280,000 trainable parameters which signifies the
lightweight yet efficient nature of AmpliNetECG12. The stochastic
characteristics of aSoftMax, a fundamental element of AmpliNetECG12, improve
prediction accuracy and also increasse the model's interpretability. This
feature enhances comprehension of important ECG segments in different forms of
arrhythmias, establishing a new standard of explainable architecture for
cardiac disorder classification.

摘要：<paragraph>由於心臟的快速且複雜的電氣活動和攜帶式裝置受限的運算能力，因此迫切需要使用 12 導程心電圖來快速偵測心臟疾病。及時且精確的診斷至關重要，因為延誤可能會對患者的健康狀況產生重大影響。本研究提出了一種新穎的深度學習架構，旨在快速且準確地診斷心臟異常。我們設計了一個稱為 aSoftMax 的新激活函數，旨在提高心電圖偏轉的可見度。所提出的激活函數與卷積神經網路架構一起使用，以在心電圖的各種導程之間包含核權重共享。這種創新方法徹底概括了全球 12 導程心電圖特徵，並通過減少可訓練參數來最小化模型的複雜性。aSoftMax 結合增強的 CNN 架構產生了 AmpliNetECG12，我們在診斷心臟疾病方面獲得了 84% 的出色準確度。AmpliNetECG12 在與 CPSC2018 資料集一起用於心律不整分類時顯示出出色的預測能力。該模型以 280,000 個可訓練參數獲得 80.71% 的 F1 分數和 96.00% 的 ROC-AUC 分數，這表明 AmpliNetECG12 的輕量級且高效的本質。aSoftMax 的隨機特徵是 AmpliNetECG12 的基本要素，它提高了預測準確度，也增加了模型的可解釋性。此功能增強了對不同形式心律不整中重要心電圖區段的理解，為心臟疾病分類建立了一個新的可解釋架構標準。</paragraph>

##### **PIORS: Personalized Intelligent Outpatient Reception based on Large Language Model with Multi-Agents Medical Scenario Simulation**
2411.13902v1 by Zhijie Bao, Qingyun Liu, Ying Guo, Zhengqiang Ye, Jun Shen, Shirong Xie, Jiajie Peng, Xuanjing Huang, Zhongyu Wei

In China, receptionist nurses face overwhelming workloads in outpatient
settings, limiting their time and attention for each patient and ultimately
reducing service quality. In this paper, we present the Personalized
Intelligent Outpatient Reception System (PIORS). This system integrates an
LLM-based reception nurse and a collaboration between LLM and hospital
information system (HIS) into real outpatient reception setting, aiming to
deliver personalized, high-quality, and efficient reception services.
Additionally, to enhance the performance of LLMs in real-world healthcare
scenarios, we propose a medical conversational data generation framework named
Service Flow aware Medical Scenario Simulation (SFMSS), aiming to adapt the LLM
to the real-world environments and PIORS settings. We evaluate the
effectiveness of PIORS and SFMSS through automatic and human assessments
involving 15 users and 15 clinical experts. The results demonstrate that
PIORS-Nurse outperforms all baselines, including the current state-of-the-art
model GPT-4o, and aligns with human preferences and clinical needs. Further
details and demo can be found at https://github.com/FudanDISC/PIORS

摘要：<paragraph>在中国，接待护士在门诊环境中面临着繁重的工作量，限制了他们对每位患者的时间和注意力，最终降低了服务质量。在本文中，我们提出了个性化智能门诊接待系统 (PIORS)。该系统将基于 LLM 的接待护士和 LLM 与医院信息系统 (HIS) 之间的协作整合到真实的门诊接待环境中，旨在提供个性化、高质量和高效的接待服务。此外，为了提高 LLM 在真实医疗保健场景中的性能，我们提出了一个名为服务流感知医疗场景模拟 (SFMSS) 的医疗会话数据生成框架，旨在使 LLM 适应真实世界环境和 PIORS 设置。我们通过涉及 15 名用户和 15 名临床专家的自动和人工评估来评估 PIORS 和 SFMSS 的有效性。结果表明，PIORS-Nurse 优于所有基线，包括当前最先进的模型 GPT-4o，并且符合人类偏好和临床需求。更多详细信息和演示可在 https://github.com/FudanDISC/PIORS 中找到</paragraph>

##### **When Online Algorithms Influence the Environment: A Dynamical Systems Analysis of the Unintended Consequences**
2411.13883v1 by Prabhat Lankireddy, Jayakrishnan Nair, D Manjunath

We analyze the effect that online algorithms have on the environment that
they are learning. As a motivation, consider recommendation systems that use
online algorithms to learn optimal product recommendations based on user and
product attributes. It is well known that the sequence of recommendations
affects user preferences. However, typical learning algorithms treat the user
attributes as static and disregard the impact of their recommendations on user
preferences. Our interest is to analyze the effect of this mismatch between the
model assumption of a static environment, and the reality of an evolving
environment affected by the recommendations. To perform this analysis, we first
introduce a model for a generic coupled evolution of the parameters that are
being learned, and the environment that is affected by it. We then frame a
linear bandit recommendation system (RS) into this generic model where the
users are characterized by a state variable that evolves based on the sequence
of recommendations. The learning algorithm of the RS does not explicitly
account for this evolution and assumes that the users are static. A dynamical
system model that captures the coupled evolution of the population state and
the learning algorithm is described, and its equilibrium behavior is analyzed.
We show that when the recommendation algorithm is able to learn the population
preferences in the presence of this mismatch, the algorithm induces similarity
in the preferences of the user population. In particular, we present results on
how different properties of the recommendation algorithm, namely the user
attribute space and the exploration-exploitation tradeoff, effect the
population preferences when they are learned by the algorithm. We demonstrate
these results using model simulations.

摘要：<paragraph>我們分析線上演算法對其學習的環境所產生的影響。作為動機，考慮使用線上演算法來學習最佳產品推薦的推薦系統，該系統是根據使用者和產品屬性。眾所周知，推薦順序會影響使用者的偏好。然而，典型的學習演算法將使用者屬性視為靜態的，並忽略其推薦對使用者偏好的影響。我們的興趣是分析靜態環境的模型假設與受推薦影響的演化環境現實之間的不匹配的影響。為了執行此分析，我們首先為正在學習的參數和受其影響的環境引入一個通用耦合演化的模型。然後，我們將線性賭徒推薦系統 (RS) 構建到這個通用模型中，其中使用者以根據推薦順序演化的狀態變數為特徵。RS 的學習演算法並未明確考慮此演化，並假設使用者是靜態的。描述了一個捕捉族群狀態和學習演算法的耦合演化的動態系統模型，並分析其平衡行為。我們表明，當推薦演算法能夠在這種不匹配的情況下學習族群偏好時，該演算法會誘導使用者族群偏好的相似性。特別是，我們展示了推薦演算法的不同屬性（即使用者屬性空間和探索開發權衡）如何影響演算法學習時族群偏好的結果。我們使用模型模擬來證明這些結果。</paragraph>

##### **Next-Generation Phishing: How LLM Agents Empower Cyber Attackers**
2411.13874v1 by Khalifa Afane, Wenqi Wei, Ying Mao, Junaid Farooq, Juntao Chen

The escalating threat of phishing emails has become increasingly
sophisticated with the rise of Large Language Models (LLMs). As attackers
exploit LLMs to craft more convincing and evasive phishing emails, it is
crucial to assess the resilience of current phishing defenses. In this study we
conduct a comprehensive evaluation of traditional phishing detectors, such as
Gmail Spam Filter, Apache SpamAssassin, and Proofpoint, as well as machine
learning models like SVM, Logistic Regression, and Naive Bayes, in identifying
both traditional and LLM-rephrased phishing emails. We also explore the
emerging role of LLMs as phishing detection tools, a method already adopted by
companies like NTT Security Holdings and JPMorgan Chase. Our results reveal
notable declines in detection accuracy for rephrased emails across all
detectors, highlighting critical weaknesses in current phishing defenses. As
the threat landscape evolves, our findings underscore the need for stronger
security controls and regulatory oversight on LLM-generated content to prevent
its misuse in creating advanced phishing attacks. This study contributes to the
development of more effective Cyber Threat Intelligence (CTI) by leveraging
LLMs to generate diverse phishing variants that can be used for data
augmentation, harnessing the power of LLMs to enhance phishing detection, and
paving the way for more robust and adaptable threat detection systems.

摘要：隨著大型語言模型 (LLM) 的興起，網路釣魚電子郵件的威脅日益嚴重且複雜。由於攻擊者利用 LLM 製作更具說服力和規避性的網路釣魚電子郵件，因此評估當前網路釣魚防禦的韌性至關重要。在這項研究中，我們對傳統的網路釣魚偵測器進行全面評估，例如 Gmail 垃圾郵件過濾器、Apache SpamAssassin 和 Proofpoint，以及機器學習模型（例如 SVM、邏輯迴歸和樸素貝氏），以識別傳統和 LLM 改寫的網路釣魚電子郵件。我們還探討了 LLM 作為網路釣魚偵測工具的新興角色，這是一種 NTT Security Holdings 和 JPMorgan Chase 等公司已採用的方法。我們的結果顯示，所有偵測器對改寫電子郵件的偵測準確度都有顯著下降，突顯出當前網路釣魚防禦的嚴重弱點。隨著威脅環境的演變，我們的研究結果強調需要對 LLM 生成的內容進行更強的安全性控制和法規監督，以防止其被濫用於製造進階網路釣魚攻擊。本研究有助於開發更有效的網路威脅情報 (CTI)，方法是利用 LLM 生成可用于資料擴充的多樣化網路釣魚變體，利用 LLM 的功能來增強網路釣魚偵測，並為更強大且適應性更強的威脅偵測系統鋪路。

##### **Robust Detection of Watermarks for Large Language Models Under Human Edits**
2411.13868v1 by Xiang Li, Feng Ruan, Huiyuan Wang, Qi Long, Weijie J. Su

Watermarking has offered an effective approach to distinguishing text
generated by large language models (LLMs) from human-written text. However, the
pervasive presence of human edits on LLM-generated text dilutes watermark
signals, thereby significantly degrading detection performance of existing
methods. In this paper, by modeling human edits through mixture model
detection, we introduce a new method in the form of a truncated goodness-of-fit
test for detecting watermarked text under human edits, which we refer to as
Tr-GoF. We prove that the Tr-GoF test achieves optimality in robust detection
of the Gumbel-max watermark in a certain asymptotic regime of substantial text
modifications and vanishing watermark signals. Importantly, Tr-GoF achieves
this optimality \textit{adaptively} as it does not require precise knowledge of
human edit levels or probabilistic specifications of the LLMs, in contrast to
the optimal but impractical (Neyman--Pearson) likelihood ratio test. Moreover,
we establish that the Tr-GoF test attains the highest detection efficiency rate
in a certain regime of moderate text modifications. In stark contrast, we show
that sum-based detection rules, as employed by existing methods, fail to
achieve optimal robustness in both regimes because the additive nature of their
statistics is less resilient to edit-induced noise. Finally, we demonstrate the
competitive and sometimes superior empirical performance of the Tr-GoF test on
both synthetic data and open-source LLMs in the OPT and LLaMA families.

摘要：<paragraph>浮水印提供了一種有效的方法來區分大型語言模型 (LLM) 生成的文字和人工撰寫的文字。然而，人工編輯在 LLM 生成的文字中普遍存在，會稀釋浮水印訊號，從而顯著降低現有方法的偵測效能。在本文中，我們透過混合模型偵測來建構人工編輯，並以截斷的優良擬合檢定形式提出一個新方法，用於偵測人工編輯下的浮水印文字，我們稱之為 Tr-GoF。我們證明 Tr-GoF 檢定在大量文字修改和消失的浮水印訊號的特定漸近範圍內，在 Gumbel-max 浮水印的穩健偵測中達到最佳化。重要的是，Tr-GoF 以「自適應」方式達到這個最佳化，因為它不需要人工編輯層級或 LLM 機率規格的精確知識，這與最佳但不可行的 (Neyman--Pearson) 似然比檢定形成對比。此外，我們確立 Tr-GoF 檢定在特定範圍的適度文字修改中達到最高的偵測效率率。形成鮮明對比的是，我們表明現有方法所採用的基於總和的偵測規則無法在兩種範圍內達到最佳穩健性，因為它們統計資料的加法性質較無法抵禦編輯引起的雜訊。最後，我們展示 Tr-GoF 檢定在 OPT 和 LLaMA 家族的合成資料和開源 LLM 上具有競爭力，有時甚至表現優異。</paragraph>

##### **Generative Fuzzy System for Sequence Generation**
2411.13867v1 by Hailong Yang, Zhaohong Deng, Wei Zhang, Zhuangzhuang Zhao, Guanjin Wang, Kup-sze Choi

Generative Models (GMs), particularly Large Language Models (LLMs), have
garnered significant attention in machine learning and artificial intelligence
for their ability to generate new data by learning the statistical properties
of training data and creating data that resemble the original. This capability
offers a wide range of applications across various domains. However, the
complex structures and numerous model parameters of GMs make the input-output
processes opaque, complicating the understanding and control of outputs.
Moreover, the purely data-driven learning mechanism limits GM's ability to
acquire broader knowledge. There remains substantial potential for enhancing
the robustness and generalization capabilities of GMs. In this work, we
introduce the fuzzy system, a classical modeling method that combines data and
knowledge-driven mechanisms, to generative tasks. We propose a novel Generative
Fuzzy System framework, named GenFS, which integrates the deep learning
capabilities of GM with the interpretability and dual-driven mechanisms of
fuzzy systems. Specifically, we propose an end-to-end GenFS-based model for
sequence generation, called FuzzyS2S. A series of experimental studies were
conducted on 12 datasets, covering three distinct categories of generative
tasks: machine translation, code generation, and summary generation. The
results demonstrate that FuzzyS2S outperforms the Transformer in terms of
accuracy and fluency. Furthermore, it exhibits better performance on some
datasets compared to state-of-the-art models T5 and CodeT5.

摘要：生成模型 (GM)，尤其是大語言模型 (LLM)，因其通過學習訓練資料的統計特性並建立類似原始資料的資料來生成新資料的能力，而在機器學習和人工智慧領域備受關注。這種能力在各個領域提供了廣泛的應用。然而，GM 的複雜結構和大量的模型參數使得輸入輸出過程不透明，加劇了對輸出理解和控制的複雜性。此外，純粹由資料驅動的學習機制限制了 GM 獲取更廣泛知識的能力。GM 的穩健性和泛化能力仍有很大的增強潛力。在這項工作中，我們引入了模糊系統，一種結合資料和知識驅動機制的經典建模方法，用於生成任務。我們提出了一個名為 GenFS 的新穎生成模糊系統框架，它將 GM 的深度學習能力與模糊系統的可解釋性和雙重驅動機制相結合。具體來說，我們提出了基於 GenFS 的端到端模型，用於序列生成，稱為 FuzzyS2S。在 12 個資料集上進行了一系列實驗研究，涵蓋了生成任務的三個不同類別：機器翻譯、程式碼生成和摘要生成。結果表明，FuzzyS2S 在準確性和流暢性方面優於 Transformer。此外，與最先進的模型 T5 和 CodeT5 相比，它在某些資料集上表現出更好的效能。

##### **HARec: Hyperbolic Graph-LLM Alignment for Exploration and Exploitation in Recommender Systems**
2411.13865v1 by Qiyao Ma, Menglin Yang, Mingxuan Ju, Tong Zhao, Neil Shah, Rex Ying

Modern recommendation systems often create information cocoons, limiting
users' exposure to diverse content. To enhance user experience, a crucial
challenge is developing systems that can balance content exploration and
exploitation, allowing users to adjust their recommendation preferences.
Intuitively, this balance can be achieved through a tree-structured
representation, where depth search facilitates exploitation and breadth search
enables exploration. However, current works face two challenges to achieve this
target: (1) Euclidean methods fail to fully capture hierarchical structures and
lack flexibility in balancing exploration-exploitation, while (2) hyperbolic
approaches, despite better hierarchical modeling, suffer from insufficient
semantic alignment due to their reliance on Euclidean text encoders. To address
these challenges, we propose HARec, a hyperbolic representation learning
framework that jointly aligns user-item collaborative information with textual
descriptions in hyperbolic space. Our framework introduces two key technique
novelty: (1) a hierarchical-aware graph-llm alignment mechanism that enables
better hierarchical representation, and (2) a hyperbolic hierarchical tree
structure that facilitates user-adjustable exploration-exploitation trade-offs.
Extensive experiments demonstrate that HARec consistently outperforms both
Euclidean and hyperbolic baselines, achieving up to 5.49% improvement in
utility metrics and 11.39% increase in diversity metrics.

摘要：現代推薦系統經常會產生資訊繭房，限制使用者接觸到多元的內容。為了提升使用者體驗，一個重要的挑戰在於開發出能夠平衡內容探索與開發的系統，讓使用者調整他們的推薦偏好。直覺上來說，這個平衡可以透過樹狀結構的表達來達成，其中深度搜尋能促進開發，廣度搜尋則能促進探索。然而，現有的工作在達成這個目標時面臨兩個挑戰：(1) 歐幾里得方法無法完全捕捉階層結構，在平衡探索與開發時也缺乏彈性，而 (2) 雙曲線方法儘管有更好的階層建模，但由於依賴歐幾里得文本編碼器，導致語意對齊不足。為了應對這些挑戰，我們提出 HARec，一個雙曲線表達學習架構，它在雙曲線空間中聯合對齊使用者項目協作資訊和文本描述。我們的架構引入了兩個關鍵技術新穎性：(1) 一個階層感知圖形 llm 對齊機制，它能促進更好的階層表達，以及 (2) 一個雙曲線階層樹狀結構，它能促進使用者可調整的探索開發權衡。廣泛的實驗證明，HARec 持續優於歐幾里得和雙曲線基線，在效用指標上提升了 5.49%，在多樣性指標上提升了 11.39%。

##### **Exploratory Study Of Human-AI Interaction For Hindustani Music**
2411.13846v1 by Nithya Shikarpur, Cheng-Zhi Anna Huang

This paper presents a study of participants interacting with and using
GaMaDHaNi, a novel hierarchical generative model for Hindustani vocal contours.
To explore possible use cases in human-AI interaction, we conducted a user
study with three participants, each engaging with the model through three
predefined interaction modes. Although this study was conducted "in the wild"-
with the model unadapted for the shift from the training data to real-world
interaction - we use it as a pilot to better understand the expectations,
reactions, and preferences of practicing musicians when engaging with such a
model. We note their challenges as (1) the lack of restrictions in model
output, and (2) the incoherence of model output. We situate these challenges in
the context of Hindustani music and aim to suggest future directions for the
model design to address these gaps.

摘要：本文介紹參與者與 GaMaDHaNi 互動和使用情況的研究，GaMaDHaNi 是一種新型的階層式生成模型，用於印度斯坦語聲調輪廓。為了探索人機互動中的可能用例，我們進行了一項使用者研究，共有三名參與者參與，每位參與者透過三種預定義的互動模式與模型互動。儘管這項研究是在「野外」進行的，但模型並未針對從訓練資料轉移到真實世界互動的情況進行調整，我們將其用作試點研究，以便更深入瞭解實務音樂家在與此類模型互動時的期望、反應和偏好。我們注意到他們的挑戰在於：(1) 模型輸出缺乏限制，以及 (2) 模型輸出的不連貫性。我們將這些挑戰置於印度斯坦音樂的背景中，並旨在建議模型設計的未來方向，以解決這些差距。

##### **Interactive and Expressive Code-Augmented Planning with Large Language Models**
2411.13826v1 by Anthony Z. Liu, Xinhe Wang, Jacob Sansom, Yao Fu, Jongwook Choi, Sungryull Sohn, Jaekyeom Kim, Honglak Lee

Large Language Models (LLMs) demonstrate strong abilities in common-sense
reasoning and interactive decision-making, but often struggle with complex,
long-horizon planning tasks. Recent techniques have sought to structure LLM
outputs using control flow and other code-adjacent techniques to improve
planning performance. These techniques include using variables (to track
important information) and functions (to divide complex tasks into smaller
re-usable sub-tasks). However, purely code-based approaches can be error-prone
and insufficient for handling ambiguous or unstructured data. To address these
challenges, we propose REPL-Plan, an LLM planning approach that is fully
code-expressive (it can utilize all the benefits of code) while also being
dynamic (it can flexibly adapt from errors and use the LLM for fuzzy
situations). In REPL-Plan, an LLM solves tasks by interacting with a
Read-Eval-Print Loop (REPL), which iteratively executes and evaluates code,
similar to language shells or interactive code notebooks, allowing the model to
flexibly correct errors and handle tasks dynamically. We demonstrate that
REPL-Plan achieves strong results across various planning domains compared to
previous methods.

摘要：大型語言模型 (LLM) 在常識推理和互動式決策制定方面表現出強大的能力，但通常難以應付複雜、長期的規劃任務。最近的技術已尋求使用控制流程和其他與程式碼相鄰的技術來建構 LLM 輸出，以改善規劃效能。這些技術包括使用變數（追蹤重要資訊）和函式（將複雜任務分為較小的可重複使用子任務）。然而，純粹基於程式碼的方法容易出錯，且不足以處理模稜兩可或非結構化的資料。為了應對這些挑戰，我們提出了 REPL-Plan，這是一種 LLM 規劃方法，它完全具有程式碼表達能力（它可以利用程式碼的所有優點），同時也是動態的（它可以靈活地從錯誤中調整，並使用 LLM 來處理模糊情況）。在 REPL-Plan 中，LLM 透過與讀取-評估-列印迴圈 (REPL) 互動來解決任務，類似於語言殼層或互動式程式碼筆記本，允許模型靈活地更正錯誤並動態地處理任務。我們證明了與先前的各種方法相比，REPL-Plan 在各種規劃領域中都取得了顯著的成果。

##### **Heterophilic Graph Neural Networks Optimization with Causal Message-passing**
2411.13821v1 by Botao Wang, Jia Li, Heng Chang, Keli Zhang, Fugee Tsung

In this work, we discover that causal inference provides a promising approach
to capture heterophilic message-passing in Graph Neural Network (GNN). By
leveraging cause-effect analysis, we can discern heterophilic edges based on
asymmetric node dependency. The learned causal structure offers more accurate
relationships among nodes. To reduce the computational complexity, we introduce
intervention-based causal inference in graph learning. We first simplify causal
analysis on graphs by formulating it as a structural learning model and define
the optimization problem within the Bayesian scheme. We then present an
analysis of decomposing the optimization target into a consistency penalty and
a structure modification based on cause-effect relations. We then estimate this
target by conditional entropy and present insights into how conditional entropy
quantifies the heterophily. Accordingly, we propose CausalMP, a causal
message-passing discovery network for heterophilic graph learning, that
iteratively learns the explicit causal structure of input graphs. We conduct
extensive experiments in both heterophilic and homophilic graph settings. The
result demonstrates that the our model achieves superior link prediction
performance. Training on causal structure can also enhance node representation
in classification task across different base models.

摘要：在这项工作中，我们发现因果推理提供了一种有前途的方法，可以捕捉图神经网络 (GNN) 中的异质信息传递。通过利用因果分析，我们可以根据不对称节点依赖关系来识别异质边。学习到的因果结构提供了节点之间更准确的关系。为了降低计算复杂度，我们在图学习中引入了基于干预的因果推理。我们首先通过将其表述为结构学习模型来简化图上的因果分析，并在贝叶斯方案中定义优化问题。然后，我们提出了将优化目标分解为一致性惩罚和基于因果关系的结构修改的分析。然后，我们通过条件熵估计这个目标，并展示条件熵如何量化异质性。相应地，我们提出了 CausalMP，一个用于异质图学习的因果信息传递发现网络，它迭代学习输入图的显式因果结构。我们在异质和同质图设置中进行了广泛的实验。结果表明，我们的模型实现了卓越的链接预测性能。在因果结构上进行训练还可以增强不同基础模型在分类任务中的节点表示。

##### **InstCache: A Predictive Cache for LLM Serving**
2411.13820v1 by Longwei Zou, Tingfeng Liu, Kai Chen, Jiangang Kong, Yangdong Deng

Large language models are revolutionizing every aspect of human life.
However, the unprecedented power comes at the cost of significant computing
intensity, suggesting long latency and large energy footprint. Key-Value Cache
and Semantic Cache have been proposed as a solution to the above problem, but
both suffer from limited scalability due to significant memory cost for each
token or instruction embeddings. Motivated by the observations that most
instructions are short, repetitive and predictable by LLMs, we propose to
predict user-instructions by an instruction-aligned LLM and store them in a
predictive cache, so-called InstCache. We introduce an instruction
pre-population algorithm based on the negative log likelihood of instructions,
determining the cache size with regard to the hit rate. The proposed InstCache
is efficiently implemented as a hash table with minimal lookup latency for
deployment. Experimental results show that InstCache can achieve up to 51.34%
hit rate on LMSys dataset, which corresponds to a 2x speedup, at a memory cost
of only 4.5GB.

摘要：大型語言模型正在改變人類生活的各個方面。
然而，這種前所未有的能力是以巨大的運算強度為代價的，這意味著延遲時間長和能源消耗大。關鍵值快取和語義快取已被提出作為上述問題的解決方案，但由於每個符號或指令嵌入的記憶體成本巨大，這兩種方法都受到可擴充性有限的困擾。由於大多數指令都是簡短、重複且可由 LLM 預測的，因此我們提出通過指令對齊的 LLM 預測使用者指令，並將它們儲存在一個預測快取中，稱為 InstCache。我們引入了一種基於指令負對數似然的指令預填充演算法，根據命中率確定快取大小。建議的 InstCache 以雜湊表的形式有效實作，具有最小的查詢延遲，以便部署。實驗結果表明，InstCache 可以對 LMSys 資料集實現高達 51.34% 的命中率，這相當於速度提升 2 倍，而記憶體成本僅為 4.5GB。

##### **AutoMixQ: Self-Adjusting Quantization for High Performance Memory-Efficient Fine-Tuning**
2411.13814v1 by Changhai Zhou, Shiyang Zhang, Yuhua Zhou, Zekai Liu, Shichao Weng

Fine-tuning large language models (LLMs) under resource constraints is a
significant challenge in deep learning. Low-Rank Adaptation (LoRA), pruning,
and quantization are all effective methods for improving resource efficiency.
However, combining them directly often results in suboptimal performance,
especially with uniform quantization across all model layers. This is due to
the complex, uneven interlayer relationships introduced by pruning,
necessitating more refined quantization strategies. To address this, we propose
AutoMixQ, an end-to-end optimization framework that selects optimal
quantization configurations for each LLM layer. AutoMixQ leverages lightweight
performance models to guide the selection process, significantly reducing time
and computational resources compared to exhaustive search methods. By
incorporating Pareto optimality, AutoMixQ balances memory usage and
performance, approaching the upper bounds of model capability under strict
resource constraints. Our experiments on widely used benchmarks show that
AutoMixQ reduces memory consumption while achieving superior performance. For
example, at a 30\% pruning rate in LLaMA-7B, AutoMixQ achieved 66.21\% on BoolQ
compared to 62.45\% for LoRA and 58.96\% for LoftQ, while reducing memory
consumption by 35.5\% compared to LoRA and 27.5\% compared to LoftQ.

摘要：在资源受限的情况下微调大型语言模型 (LLM) 是深度学习中的一项重大挑战。低秩自适应 (LoRA)、剪枝和量化都是提高资源效率的有效方法。然而，直接组合它们通常会导致次优性能，尤其是在所有模型层上进行均匀量化时。这是由于剪枝引入的复杂、不均匀的层间关系，需要更精细的量化策略。为了解决这个问题，我们提出了 AutoMixQ，这是一个端到端优化框架，用于为每个 LLM 层选择最佳量化配置。AutoMixQ 利用轻量级性能模型来指导选择过程，与穷举搜索方法相比，显著减少了时间和计算资源。通过结合帕累托最优性，AutoMixQ 平衡了内存使用和性能，在严格的资源限制下接近模型能力的上限。我们在广泛使用的基准测试中的实验表明，AutoMixQ 减少了内存消耗，同时实现了卓越的性能。例如，在 LLaMA-7B 中以 30% 的剪枝率，AutoMixQ 在 BoolQ 上达到 66.21%，而 LoRA 为 62.45%，LoftQ 为 58.96%，同时与 LoRA 相比减少了 35.5% 的内存消耗，与 LoftQ 相比减少了 27.5%。

##### **SemiKong: Curating, Training, and Evaluating A Semiconductor Industry-Specific Large Language Model**
2411.13802v1 by Christopher Nguyen, William Nguyen, Atsushi Suzuki, Daisuke Oku, Hong An Phan, Sang Dinh, Zooey Nguyen, Anh Ha, Shruti Raghavan, Huy Vo, Thang Nguyen, Lan Nguyen, Yoshikuni Hirayama

Large Language Models (LLMs) have demonstrated the potential to address some
issues within the semiconductor industry. However, they are often
general-purpose models that lack the specialized knowledge needed to tackle the
unique challenges of this sector, such as the intricate physics and chemistry
of semiconductor devices and processes. SemiKong, the first industry-specific
LLM for the semiconductor domain, provides a foundation that can be used to
develop tailored proprietary models. With SemiKong 1.0, we aim to develop a
foundational model capable of understanding etching problems at an expert
level. Our key contributions include (a) curating a comprehensive corpus of
semiconductor-related texts, (b) creating a foundational model with in-depth
semiconductor knowledge, and (c) introducing a framework for integrating expert
knowledge, thereby advancing the evaluation process of domain-specific AI
models. Through fine-tuning a pre-trained LLM using our curated dataset, we
have shown that SemiKong outperforms larger, general-purpose LLMs in various
semiconductor manufacturing and design tasks. Our extensive experiments
underscore the importance of developing domain-specific LLMs as a foundation
for company- or tool-specific proprietary models, paving the way for further
research and applications in the semiconductor domain. Code and dataset will be
available at https://github.com/aitomatic/semikong

摘要：大型語言模型 (LLM) 已展現出解決半導體產業內部一些問題的潛力。然而，它們通常是缺乏解決此產業獨特挑戰所需專業知識的通用模型，例如半導體裝置和製程的複雜物理和化學。SemiKong 是半導體領域的第一個產業特定 LLM，它提供了可供用於開發客製化專有模型的基礎。有了 SemiKong 1.0，我們的目標是開發一個基礎模型，能夠在專家層級理解蝕刻問題。我們的關鍵貢獻包括：(a) 策劃一個全面的半導體相關文本語料庫、(b) 建立一個具有深入半導體知識的基礎模型，以及 (c) 介紹一個整合專家知識的架構，藉此推進領域特定 AI 模型的評估程序。透過使用我們策劃的資料集微調一個預先訓練的 LLM，我們已證明 SemiKong 在各種半導體製造和設計任務中優於更大、更通用的 LLM。我們廣泛的實驗強調了開發領域特定 LLM 作為公司或工具特定專有模型基礎的重要性，為半導體領域的進一步研究和應用鋪路。程式碼和資料集將可在 https://github.com/aitomatic/semikong 取得

##### **Explaining GPT-4's Schema of Depression Using Machine Behavior Analysis**
2411.13800v1 by Adithya V Ganesan, Vasudha Varadarajan, Yash Kumar Lal, Veerle C. Eijsbroek, Katarina Kjell, Oscar N. E. Kjell, Tanuja Dhanasekaran, Elizabeth C. Stade, Johannes C. Eichstaedt, Ryan L. Boyd, H. Andrew Schwartz, Lucie Flek

Use of large language models such as ChatGPT (GPT-4) for mental health
support has grown rapidly, emerging as a promising route to assess and help
people with mood disorders, like depression. However, we have a limited
understanding of GPT-4's schema of mental disorders, that is, how it internally
associates and interprets symptoms. In this work, we leveraged contemporary
measurement theory to decode how GPT-4 interrelates depressive symptoms to
inform both clinical utility and theoretical understanding. We found GPT-4's
assessment of depression: (a) had high overall convergent validity (r = .71
with self-report on 955 samples, and r = .81 with experts judgments on 209
samples); (b) had moderately high internal consistency (symptom
inter-correlates r = .23 to .78 ) that largely aligned with literature and
self-report; except that GPT-4 (c) underemphasized suicidality's -- and
overemphasized psychomotor's -- relationship with other symptoms, and (d) had
symptom inference patterns that suggest nuanced hypotheses (e.g. sleep and
fatigue are influenced by most other symptoms while feelings of
worthlessness/guilt is mostly influenced by depressed mood).

摘要：大型語言模型（例如 ChatGPT (GPT-4)）在心理健康方面的使用迅速增長，成為評估和幫助情緒障礙（例如憂鬱症）患者的有前途途徑。然而，我們對 GPT-4 的心理障礙模式了解有限，也就是說，它在內部如何關聯和詮釋症狀。在這項工作中，我們利用當代測量理論來解碼 GPT-4 如何將憂鬱症狀相互關聯，以告知臨床效用和理論理解。我們發現 GPT-4 對憂鬱症的評估：(a) 具有很高的整體收斂效度（r = .71，來自 955 個樣本的自陳，以及 r = .81，來自 209 個樣本的專家判斷）；(b) 具有中等偏高的內部一致性（症狀互相關係 r = .23 至 .78），這在很大程度上與文獻和自陳一致；GPT-4 (c) 除了低估自殺傾向與其他症狀的關係，以及高估精神運動與其他症狀的關係之外，(d) 還有暗示細微假設的症狀推論模式（例如，睡眠和疲勞受大多數其他症狀影響，而無價值感/罪惡感則主要受憂鬱情緒影響）。

##### **Adaptable Embeddings Network (AEN)**
2411.13786v1 by Stan Loosmore, Alexander Titus

Modern day Language Models see extensive use in text classification, yet this
comes at significant computational cost. Compute-effective classification
models are needed for low-resource environments, most notably on edge devices.
We introduce Adaptable Embeddings Networks (AEN), a novel dual-encoder
architecture using Kernel Density Estimation (KDE). This architecture allows
for runtime adaptation of classification criteria without retraining and is
non-autoregressive. Through thorough synthetic data experimentation, we
demonstrate our model outputs comparable and in certain cases superior results
to that of autoregressive models an order of magnitude larger than AEN's size.
The architecture's ability to preprocess and cache condition embeddings makes
it ideal for edge computing applications and real-time monitoring systems.

摘要：現代語言模型在文本分類中廣泛使用，但這需要大量的計算成本。在低資源環境中，特別是在邊緣設備上，需要具有運算效率的分類模型。我們引入了適應性嵌入網路 (AEN)，這是一種使用核密度估計 (KDE) 的新穎雙編碼器架構。此架構允許在不重新訓練的情況下執行時調整分類標準，並且是非自迴歸的。透過徹底的合成數據實驗，我們證明了我們的模型輸出與比 AEN 大一個數量級的自迴歸模型相當，在某些情況下甚至更優異。此架構能夠預處理和快取條件嵌入，使其非常適合邊緣運算應用程式和即時監控系統。

##### **NewsInterview: a Dataset and a Playground to Evaluate LLMs' Ground Gap via Informational Interviews**
2411.13779v1 by Michael Lu, Hyundong Justin Cho, Weiyan Shi, Jonathan May, Alexander Spangher

Large Language Models (LLMs) have demonstrated impressive capabilities in
generating coherent text but often struggle with grounding language and
strategic dialogue. To address this gap, we focus on journalistic interviews, a
domain rich in grounding communication and abundant in data. We curate a
dataset of 40,000 two-person informational interviews from NPR and CNN, and
reveal that LLMs are significantly less likely than human interviewers to use
acknowledgements and to pivot to higher-level questions. Realizing that a
fundamental deficit exists in multi-turn planning and strategic thinking, we
develop a realistic simulated environment, incorporating source personas and
persuasive elements, in order to facilitate the development of agents with
longer-horizon rewards. Our experiments show that while source LLMs mimic human
behavior in information sharing, interviewer LLMs struggle with recognizing
when questions are answered and engaging persuasively, leading to suboptimal
information extraction across model size and capability. These findings
underscore the need for enhancing LLMs' strategic dialogue capabilities.

摘要：大型語言模型 (LLM) 在生成連貫文字方面展現了令人印象深刻的能力，但常常在語言基礎和策略性對話方面遇到困難。為了解決這個差距，我們專注於新聞採訪，這是一個以基礎溝通和豐富數據為主的領域。我們從 NPR 和 CNN 策劃了一個包含 40,000 個雙人資訊性採訪的資料集，並揭示出 LLM 使用確認和轉向更高層次問題的可能性遠低於人類採訪者。意識到多輪規劃和策略性思考中存在根本缺陷，我們開發了一個逼真的模擬環境，結合來源角色和說服元素，以促進具有更長遠回報的代理開發。我們的實驗表明，雖然來源 LLM 在資訊共享方面模仿人類行為，但採訪者 LLM 難以辨識問題何時獲得解答並進行有說服力的互動，導致跨模型大小和能力的資訊提取次佳。這些發現強調了加強 LLM 策略性對話能力的必要性。

##### **Benchmarking GPT-4 against Human Translators: A Comprehensive Evaluation Across Languages, Domains, and Expertise Levels**
2411.13775v1 by Jianhao Yan, Pingchuan Yan, Yulong Chen, Jing Li, Xianchao Zhu, Yue Zhang

This study presents a comprehensive evaluation of GPT-4's translation
capabilities compared to human translators of varying expertise levels. Through
systematic human evaluation using the MQM schema, we assess translations across
three language pairs (Chinese$\longleftrightarrow$English,
Russian$\longleftrightarrow$English, and Chinese$\longleftrightarrow$Hindi) and
three domains (News, Technology, and Biomedical). Our findings reveal that
GPT-4 achieves performance comparable to junior-level translators in terms of
total errors, while still lagging behind senior translators. Unlike traditional
Neural Machine Translation systems, which show significant performance
degradation in resource-poor language directions, GPT-4 maintains consistent
translation quality across all evaluated language pairs. Through qualitative
analysis, we identify distinctive patterns in translation approaches: GPT-4
tends toward overly literal translations and exhibits lexical inconsistency,
while human translators sometimes over-interpret context and introduce
hallucinations. This study represents the first systematic comparison between
LLM and human translators across different proficiency levels, providing
valuable insights into the current capabilities and limitations of LLM-based
translation systems.

摘要：本研究對 GPT-4 的翻譯能力進行了全面評估，並將其與不同專業水準的人類翻譯員進行比較。透過使用 MQM 架構進行系統性的人類評估，我們評估了三組語言對（中文 ↔ 英文、俄文 ↔ 英文和中文 ↔ 印地文）和三個領域（新聞、科技和生物醫學）的翻譯。我們的研究結果顯示，GPT-4 在總錯誤方面達到了與初階翻譯員相當的表現，但仍落後於資深翻譯員。與傳統的神經機器翻譯系統不同，後者在資源匱乏的語言方向上表現出顯著的效能下降，而 GPT-4 在所有評估的語言對中都維持了一致的翻譯品質。透過定性分析，我們在翻譯方法中發現了獨特的模式：GPT-4 傾向於過度直譯，並表現出詞彙不一致，而人類翻譯員有時會過度詮釋上下文並引入幻覺。本研究代表了 LLM 和不同熟練程度的人類翻譯員之間的首次系統性比較，對基於 LLM 的翻譯系統的當前能力和限制提供了有價值的見解。

##### **FastRAG: Retrieval Augmented Generation for Semi-structured Data**
2411.13773v1 by Amar Abane, Anis Bekri, Abdella Battou

Efficiently processing and interpreting network data is critical for the
operation of increasingly complex networks. Recent advances in Large Language
Models (LLM) and Retrieval-Augmented Generation (RAG) techniques have improved
data processing in network management. However, existing RAG methods like
VectorRAG and GraphRAG struggle with the complexity and implicit nature of
semi-structured technical data, leading to inefficiencies in time, cost, and
retrieval. This paper introduces FastRAG, a novel RAG approach designed for
semi-structured data. FastRAG employs schema learning and script learning to
extract and structure data without needing to submit entire data sources to an
LLM. It integrates text search with knowledge graph (KG) querying to improve
accuracy in retrieving context-rich information. Evaluation results demonstrate
that FastRAG provides accurate question answering, while improving up to 90% in
time and 85% in cost compared to GraphRAG.

摘要：有效率地處理和解讀網路資料對於日益複雜的網路操作至關重要。大型語言模型 (LLM) 和檢索增強產生 (RAG) 技術的最新進展已經改善了網路管理中的資料處理。然而，現有的 RAG 方法（例如 VectorRAG 和 GraphRAG）難以應付半結構化技術資料的複雜性和隱含性質，導致時間、成本和檢索效率不彰。本文介紹 FastRAG，一種專為半結構化資料設計的新穎 RAG 方法。FastRAG 使用架構學習和腳本學習來萃取和建構資料，而無需將整個資料來源提交給 LLM。它將文字搜尋與知識圖譜 (KG) 查詢整合，以提高檢索內容豐富資訊的準確性。評估結果證明，FastRAG 提供了準確的問答，同時與 GraphRAG 相比，時間改善了 90%，成本改善了 85%。

##### **An Evaluation-Driven Approach to Designing LLM Agents: Process and Architecture**
2411.13768v1 by Boming Xia, Qinghua Lu, Liming Zhu, Zhenchang Xing, Dehai Zhao, Hao Zhang

The advent of Large Language Models (LLMs) has enabled the development of LLM
agents capable of autonomously achieving under-specified goals and continuously
evolving through post-deployment improvement, sometimes without requiring code
or model updates. Conventional approaches, such as pre-defined test cases and
code/model redevelopment pipelines, are inadequate for addressing the unique
challenges of LLM agent development, particularly in terms of quality and risk
control. This paper introduces an evaluation-driven design approach, inspired
by test-driven development, to address these challenges. Through a multivocal
literature review (MLR), we synthesize existing LLM evaluation methods and
propose a novel process model and reference architecture specifically designed
for LLM agents. The proposed approach integrates online and offline evaluations
to support adaptive runtime adjustments and systematic offline redevelopment,
improving runtime pipelines, artifacts, system architecture, and LLMs by
continuously incorporating evaluation results, including fine-grained feedback
from human and AI evaluators.

摘要：大型語言模型 (LLM) 的出現促成了 LLM 代理的開發，此類代理能夠在未指定目標下自主實現目標，並透過部署後持續改進不斷進化，有時不需要程式碼或模型更新。傳統方法，例如預先定義的測試案例和程式碼/模型重新開發管線，不足以解決 LLM 代理開發的獨特挑戰，特別是在品質和風險控制方面。本文介紹了一種評估驅動設計方法，靈感來自測試驅動開發，以應對這些挑戰。透過多聲道文獻回顧 (MLR)，我們綜合現有的 LLM 評估方法，並提出專門為 LLM 代理設計的新穎流程模型和參考架構。所提出的方法整合線上和離線評估，以支援適應性執行時期調整和系統性離線重新開發，透過持續納入評估結果（包括來自人類和 AI 評估者的細微回饋），改善執行時期管線、人工製品、系統架構和 LLM。

##### **Tiny-Align: Bridging Automatic Speech Recognition and Large Language Model on the Edge**
2411.13766v1 by Ruiyang Qin, Dancheng Liu, Gelei Xu, Zheyu Yan, Chenhui Xu, Yuting Hu, X. Sharon Hu, Jinjun Xiong, Yiyu Shi

The combination of Large Language Models (LLM) and Automatic Speech
Recognition (ASR), when deployed on edge devices (called edge ASR-LLM), can
serve as a powerful personalized assistant to enable audio-based interaction
for users. Compared to text-based interaction, edge ASR-LLM allows accessible
and natural audio interactions. Unfortunately, existing ASR-LLM models are
mainly trained in high-performance computing environments and produce
substantial model weights, making them difficult to deploy on edge devices.
More importantly, to better serve users' personalized needs, the ASR-LLM must
be able to learn from each distinct user, given that audio input often contains
highly personalized characteristics that necessitate personalized on-device
training. Since individually fine-tuning the ASR or LLM often leads to
suboptimal results due to modality-specific limitations, end-to-end training
ensures seamless integration of audio features and language understanding
(cross-modal alignment), ultimately enabling a more personalized and efficient
adaptation on edge devices. However, due to the complex training requirements
and substantial computational demands of existing approaches, cross-modal
alignment between ASR audio and LLM can be challenging on edge devices. In this
work, we propose a resource-efficient cross-modal alignment framework that
bridges ASR and LLMs on edge devices to handle personalized audio input. Our
framework enables efficient ASR-LLM alignment on resource-constrained devices
like NVIDIA Jetson Orin (8GB RAM), achieving 50x training time speedup while
improving the alignment quality by more than 50\%. To the best of our
knowledge, this is the first work to study efficient ASR-LLM alignment on
resource-constrained edge devices.

摘要：大型語言模型 (LLM) 和自動語音辨識 (ASR) 的結合，在部署於邊緣裝置（稱為邊緣 ASR-LLM）時，可用作強大的個人化助理，讓使用者能進行基於音訊的互動。與基於文字的互動相比，邊緣 ASR-LLM 允許無障礙且自然的音訊互動。不幸的是，現有的 ASR-LLM 模型主要是在高性能運算環境中訓練，並產生大量的模型權重，這使得它們難以部署在邊緣裝置上。更重要的是，為了更好地滿足使用者的個人化需求，ASR-LLM 必須能夠從每個不同的使用者學習，因為音訊輸入通常包含高度個人化的特徵，需要進行個人化的裝置上訓練。由於個別微調 ASR 或 LLM 通常會因特定於模式的限制而導致次佳結果，端到端訓練確保音訊特徵和語言理解（跨模式對齊）的無縫整合，最終實現更個人化且更有效率的邊緣裝置適應。然而，由於現有方法複雜的訓練需求和大量的運算需求，ASR 音訊和 LLM 之間的跨模式對齊在邊緣裝置上可能具有挑戰性。在這項工作中，我們提出一個資源有效率的跨模式對齊架構，在邊緣裝置上橋接 ASR 和 LLM 以處理個人化的音訊輸入。我們的架構可以在資源受限的裝置（例如 NVIDIA Jetson Orin（8GB RAM））上實現高效的 ASR-LLM 對齊，將訓練時間加速 50 倍，同時將對齊品質提升 50% 以上。據我們所知，這是第一個研究在資源受限的邊緣裝置上進行高效 ASR-LLM 對齊的工作。

##### **A Framework for Evaluating LLMs Under Task Indeterminacy**
2411.13760v1 by Luke Guerdan, Hanna Wallach, Solon Barocas, Alexandra Chouldechova

Large language model (LLM) evaluations often assume there is a single correct
response -- a gold label -- for each item in the evaluation corpus. However,
some tasks can be ambiguous -- i.e., they provide insufficient information to
identify a unique interpretation -- or vague -- i.e., they do not clearly
indicate where to draw the line when making a determination. Both ambiguity and
vagueness can cause task indeterminacy -- the condition where some items in the
evaluation corpus have more than one correct response. In this paper, we
develop a framework for evaluating LLMs under task indeterminacy. Our framework
disentangles the relationships between task specification, human ratings, and
LLM responses in the LLM evaluation pipeline. Using our framework, we conduct a
synthetic experiment showing that evaluations that use the "gold label"
assumption underestimate the true performance. We also provide a method for
estimating an error-adjusted performance interval given partial knowledge about
indeterminate items in the evaluation corpus. We conclude by outlining
implications of our work for the research community.

摘要：大型語言模型 (LLM) 評估通常假設評估語料庫中的每個項目都有單一的正確
回應——一個黃金標籤。然而，有些任務可能是模稜兩可的——即，它們提供的資訊不足以
識別出一個獨特的詮釋——或含糊不清的——即，它們沒有明確指出在做出判斷時應在哪裡劃清界線。模稜兩可和含糊不清都會導致任務不確定性——評估語料庫中某些項目有多個正確回應的情況。在本文中，我們
開發了一個在任務不確定性下評估 LLM 的框架。我們的框架解開了 LLM 評估管道中任務規範、人類評分和 LLM 回應之間的關係。使用我們的框架，我們進行了一個合成實驗，表明使用「黃金標籤」假設的評估低估了真實效能。我們還提供了一種方法，用於估計評估語料庫中不確定項目的部分知識所給出的誤差調整效能區間。我們最後概述了我們的工作對研究社群的影響。

##### **AttentionBreaker: Adaptive Evolutionary Optimization for Unmasking Vulnerabilities in LLMs through Bit-Flip Attacks**
2411.13757v1 by Sanjay Das, Swastik Bhattacharya, Souvik Kundu, Shamik Kundu, Anand Menon, Arnab Raha, Kanad Basu

Large Language Models (LLMs) have revolutionized natural language processing
(NLP), excelling in tasks like text generation and summarization. However,
their increasing adoption in mission-critical applications raises concerns
about hardware-based threats, particularly bit-flip attacks (BFAs). BFAs,
enabled by fault injection methods such as Rowhammer, target model parameters
in memory, compromising both integrity and performance. Identifying critical
parameters for BFAs in the vast parameter space of LLMs poses significant
challenges. While prior research suggests transformer-based architectures are
inherently more robust to BFAs compared to traditional deep neural networks, we
challenge this assumption. For the first time, we demonstrate that as few as
three bit-flips can cause catastrophic performance degradation in an LLM with
billions of parameters. Current BFA techniques are inadequate for exploiting
this vulnerability due to the difficulty of efficiently identifying critical
parameters within the immense parameter space. To address this, we propose
AttentionBreaker, a novel framework tailored for LLMs that enables efficient
traversal of the parameter space to identify critical parameters. Additionally,
we introduce GenBFA, an evolutionary optimization strategy designed to refine
the search further, isolating the most critical bits for an efficient and
effective attack. Empirical results reveal the profound vulnerability of LLMs
to AttentionBreaker. For example, merely three bit-flips (4.129 x 10^-9% of
total parameters) in the LLaMA3-8B-Instruct 8-bit quantized (W8) model result
in a complete performance collapse: accuracy on MMLU tasks drops from 67.3% to
0%, and Wikitext perplexity skyrockets from 12.6 to 4.72 x 10^5. These findings
underscore the effectiveness of AttentionBreaker in uncovering and exploiting
critical vulnerabilities within LLM architectures.

摘要：大型語言模型 (LLM) 徹底改變了自然語言處理 (NLP)，在文本生成和摘要等任務中表現出色。然而，它們在任務關鍵型應用中的採用越來越多，這引起了對基於硬體的威脅的擔憂，特別是位元翻轉攻擊 (BFA)。BFA 由故障注入方法（例如 Rowhammer）啟用，針對記憶體中的模型參數，損害完整性和效能。在 LLM 巨大參數空間中識別 BFA 的關鍵參數提出了重大挑戰。雖然先前的研究表明，與傳統深度神經網路相比，基於Transformer的架構天生對 BFA 更具魯棒性，但我們挑戰了這一假設。我們首次證明，僅三處位元翻轉即可導致具有數十億個參數的 LLM 發生災難性的效能下降。由於難以在巨大的參數空間中有效識別關鍵參數，目前的 BFA 技術不足以利用此漏洞。為了解決這個問題，我們提出了 AttentionBreaker，這是一個專門針對 LLM 的新框架，它可以有效遍歷參數空間以識別關鍵參數。此外，我們引入了 GenBFA，這是一種進化優化策略，旨在進一步優化搜尋，隔離最關鍵的位元，以進行有效率且有效的攻擊。經驗結果揭示了 LLM 對 AttentionBreaker 的嚴重漏洞。例如，LLaMA3-8B-Instruct 8 位元量化 (W8) 模型中僅三處位元翻轉（總參數的 4.129 x 10^-9%）就會導致效能完全崩潰：MMLU 任務的準確度從 67.3% 降至 0%，而 Wikitext 的困惑度從 12.6 飆升至 4.72 x 10^5。這些發現強調了 AttentionBreaker 在揭露和利用 LLM 架構中的關鍵漏洞方面的有效性。

##### **Learning to Reason Iteratively and Parallelly for Complex Visual Reasoning Scenarios**
2411.13754v1 by Shantanu Jaiswal, Debaditya Roy, Basura Fernando, Cheston Tan

Complex visual reasoning and question answering (VQA) is a challenging task
that requires compositional multi-step processing and higher-level reasoning
capabilities beyond the immediate recognition and localization of objects and
events. Here, we introduce a fully neural Iterative and Parallel Reasoning
Mechanism (IPRM) that combines two distinct forms of computation -- iterative
and parallel -- to better address complex VQA scenarios. Specifically, IPRM's
"iterative" computation facilitates compositional step-by-step reasoning for
scenarios wherein individual operations need to be computed, stored, and
recalled dynamically (e.g. when computing the query "determine the color of pen
to the left of the child in red t-shirt sitting at the white table").
Meanwhile, its "parallel" computation allows for the simultaneous exploration
of different reasoning paths and benefits more robust and efficient execution
of operations that are mutually independent (e.g. when counting individual
colors for the query: "determine the maximum occurring color amongst all
t-shirts"). We design IPRM as a lightweight and fully-differentiable neural
module that can be conveniently applied to both transformer and non-transformer
vision-language backbones. It notably outperforms prior task-specific methods
and transformer-based attention modules across various image and video VQA
benchmarks testing distinct complex reasoning capabilities such as
compositional spatiotemporal reasoning (AGQA), situational reasoning (STAR),
multi-hop reasoning generalization (CLEVR-Humans) and causal event linking
(CLEVRER-Humans). Further, IPRM's internal computations can be visualized
across reasoning steps, aiding interpretability and diagnosis of its errors.

摘要：複雜視覺推理和問題解答 (VQA) 是一項具有挑戰性的任務，需要組合式多步驟處理和超越立即識別和定位物件和事件的高階推理能力。在此，我們引入了一種完全神經元的迭代並行推理機制 (IPRM)，它結合了兩種不同的計算形式——迭代和並行——以更好地應對複雜的 VQA 場景。具體來說，IPRM 的「迭代」計算促進了情境中逐步組合式推理，在該情境中需要動態地計算、儲存和調用個別運算（例如，在計算查詢「判斷坐在白色桌子旁穿紅色 T 恤的小孩左邊的筆的顏色」時）。同時，其「並行」計算允許同時探索不同的推理路徑，並受益於對相互獨立的運算進行更穩健且有效率的執行（例如，在計算查詢的個別顏色時：「判斷所有 T 恤中出現次數最多的顏色」）。我們將 IPRM 設計為一個輕量且完全可微分的類神經元模組，可以方便地應用於Transformer和非Transformer視覺語言主幹。它明顯優於各種影像和影片 VQA 基準測試中先前的特定任務方法和基於Transformer的注意力模組，這些基准測試了不同的複雜推理能力，例如組合式時空推理 (AGQA)、情境推理 (STAR)、多跳推理概化 (CLEVR-Humans) 和因果事件連結 (CLEVRER-Humans)。此外，IPRM 的內部計算可以在推理步驟中視覺化，有助於其錯誤的可解釋性和診斷。

##### **AI-Driven Agents with Prompts Designed for High Agreeableness Increase the Likelihood of Being Mistaken for a Human in the Turing Test**
2411.13749v1 by U. León-Domínguez, E. D. Flores-Flores, A. J. García-Jasso, M. K. Gómez-Cuellar, D. Torres-Sánchez, A. Basora-Marimon

Large Language Models based on transformer algorithms have revolutionized
Artificial Intelligence by enabling verbal interaction with machines akin to
human conversation. These AI agents have surpassed the Turing Test, achieving
confusion rates up to 50%. However, challenges persist, especially with the
advent of robots and the need to humanize machines for improved Human-AI
collaboration. In this experiment, three GPT agents with varying levels of
agreeableness (disagreeable, neutral, agreeable) based on the Big Five
Inventory were tested in a Turing Test. All exceeded a 50% confusion rate, with
the highly agreeable AI agent surpassing 60%. This agent was also recognized as
exhibiting the most human-like traits. Various explanations in the literature
address why these GPT agents were perceived as human, including psychological
frameworks for understanding anthropomorphism. These findings highlight the
importance of personality engineering as an emerging discipline in artificial
intelligence, calling for collaboration with psychology to develop ergonomic
psychological models that enhance system adaptability in collaborative
activities.

摘要：大型語言模型基於轉換器演算法，透過讓機器與人類對話般互動，徹底革新了人工智慧。這些人工智慧代理人已超越圖靈測試，達到高達 50% 的混淆率。然而，挑戰依然存在，特別是隨著機器人的出現以及為了改善人機協作而使機器人性化的需求。在這個實驗中，三個具有不同程度的親和性（令人不快、中立、令人愉快）的 GPT 代理人根據大五人格量表在圖靈測試中受到測試。所有代理人都超過了 50% 的混淆率，高度令人愉快的 AI 代理人更超過了 60%。這個代理人也被認為展現出最像人類的特質。文獻中各種解釋說明了為什麼這些 GPT 代理人被認為是人類，包括用於理解擬人化的心理架構。這些發現突顯了人格工程作為人工智慧中一個新興領域的重要性，呼籲與心理學合作，開發符合人體工學的心理模型，以增強系統在協作活動中的適應性。

##### **Federated Continual Learning for Edge-AI: A Comprehensive Survey**
2411.13740v1 by Zi Wang, Fei Wu, Feng Yu, Yurui Zhou, Jia Hu, Geyong Min

Edge-AI, the convergence of edge computing and artificial intelligence (AI),
has become a promising paradigm that enables the deployment of advanced AI
models at the network edge, close to users. In Edge-AI, federated continual
learning (FCL) has emerged as an imperative framework, which fuses knowledge
from different clients while preserving data privacy and retaining knowledge
from previous tasks as it learns new ones. By so doing, FCL aims to ensure
stable and reliable performance of learning models in dynamic and distributed
environments. In this survey, we thoroughly review the state-of-the-art
research and present the first comprehensive survey of FCL for Edge-AI. We
categorize FCL methods based on three task characteristics: federated class
continual learning, federated domain continual learning, and federated task
continual learning. For each category, an in-depth investigation and review of
the representative methods are provided, covering background, challenges,
problem formalisation, solutions, and limitations. Besides, existing real-world
applications empowered by FCL are reviewed, indicating the current progress and
potential of FCL in diverse application domains. Furthermore, we discuss and
highlight several prospective research directions of FCL such as
algorithm-hardware co-design for FCL and FCL with foundation models, which
could provide insights into the future development and practical deployment of
FCL in the era of Edge-AI.

摘要：邊緣人工智慧（Edge-AI）是邊緣運算和人工智慧（AI）的融合，
已成為一種有前途的範例，可以在靠近使用者的網路邊緣部署進階的人工智慧模型。在 Edge-AI 中，聯邦持續學習（FCL）已成為一個必要的架構，它融合了來自不同用戶的知識，同時在學習新任務時保護資料隱私和保留先前任務的知識。透過這樣做，FCL 旨在確保學習模型在動態且分散的環境中具有穩定且可靠的效能。在本次調查中，我們徹底檢視了最先進的研究，並提出了 FCL 在 Edge-AI 中的第一份全面調查。我們根據三項任務特性對 FCL 方法進行分類：聯邦類別持續學習、聯邦領域持續學習和聯邦任務持續學習。對於每個類別，我們提供了代表性方法的深入調查和回顧，涵蓋背景、挑戰、問題形式化、解決方案和限制。此外，我們回顧了由 FCL 賦能的現有真實世界應用程式，說明了 FCL 在各種應用領域的當前進度和潛力。此外，我們討論並強調了 FCL 的幾個潛在研究方向，例如 FCL 的演算法硬體共同設計和具備基礎模型的 FCL，這些方向可以提供對 FCL 在 Edge-AI 時代的未來發展和實際部署的見解。

##### **Assessing Gender Bias in LLMs: Comparing LLM Outputs with Human Perceptions and Official Statistics**
2411.13738v1 by Tetiana Bas

This study investigates gender bias in large language models (LLMs) by
comparing their gender perception to that of human respondents, U.S. Bureau of
Labor Statistics data, and a 50% no-bias benchmark. We created a new evaluation
set using occupational data and role-specific sentences. Unlike common
benchmarks included in LLM training data, our set is newly developed,
preventing data leakage and test set contamination. Five LLMs were tested to
predict the gender for each role using single-word answers. We used
Kullback-Leibler (KL) divergence to compare model outputs with human
perceptions, statistical data, and the 50% neutrality benchmark. All LLMs
showed significant deviation from gender neutrality and aligned more with
statistical data, still reflecting inherent biases.

摘要：本研究透過將大型語言模型 (LLM) 的性別感知與人類受訪者、美國勞工統計局資料和 50% 無偏見基準進行比較，來調查大型語言模型中的性別偏見。我們使用職業資料和角色特定句子建立了一個新的評量集。與 LLM 訓練資料中常見的基準不同，我們的集合是新開發的，可防止資料外洩和測試集污染。測試了五個 LLM，使用單字答案來預測每個角色的性別。我們使用 Kullback-Leibler (KL) 距離來比較模型輸出與人類感知、統計資料和 50% 中立基準。所有 LLM 都顯示出與性別中立有顯著偏差，並且更符合統計資料，仍然反映出固有的偏見。

##### **Exploring Large Language Models for Climate Forecasting**
2411.13724v1 by Yang Wang, Hassan A. Karimi

With the increasing impacts of climate change, there is a growing demand for
accessible tools that can provide reliable future climate information to
support planning, finance, and other decision-making applications. Large
language models (LLMs), such as GPT-4, present a promising approach to bridging
the gap between complex climate data and the general public, offering a way for
non-specialist users to obtain essential climate insights through natural
language interaction. However, an essential challenge remains under-explored:
evaluating the ability of LLMs to provide accurate and reliable future climate
predictions, which is crucial for applications that rely on anticipating
climate trends. In this study, we investigate the capability of GPT-4 in
predicting rainfall at short-term (15-day) and long-term (12-month) scales. We
designed a series of experiments to assess GPT's performance under different
conditions, including scenarios with and without expert data inputs. Our
results indicate that GPT, when operating independently, tends to generate
conservative forecasts, often reverting to historical averages in the absence
of clear trend signals. This study highlights both the potential and challenges
of applying LLMs for future climate predictions, providing insights into their
integration with climate-related applications and suggesting directions for
enhancing their predictive capabilities in the field.

摘要：隨著氣候變遷的影響日益加劇，對於可提供可靠未來氣候資訊的平易近人工具需求日益殷切，以支援規劃、財務和其他決策制定應用程式。大型語言模型 (LLM)，例如 GPT-4，提供了一種有前景的方法，可以彌合複雜氣候資料與一般大眾之間的鴻溝，提供一種方式讓非專家使用者透過自然語言互動取得必要的氣候見解。然而，有一個重要的挑戰仍然未被充分探討：評估 LLM 提供準確且可靠未來氣候預測的能力，這對於依賴預測氣候趨勢的應用程式至關重要。在本研究中，我們調查了 GPT-4 在短期 (15 天) 和長期 (12 個月) 尺度預測降雨的能力。我們設計了一系列實驗，以評估 GPT 在不同條件下的效能，包括有和沒有專家資料輸入的場景。我們的結果表明，GPT 在獨立運作時，傾向於產生保守的預測，在沒有明確趨勢信號的情況下，通常會恢復到歷史平均值。本研究強調了將 LLM 應用於未來氣候預測的潛力與挑戰，提供了將其整合到與氣候相關的應用程式中的見解，並提出了在該領域增強其預測能力的方向。

##### **SimPhony: A Device-Circuit-Architecture Cross-Layer Modeling and Simulation Framework for Heterogeneous Electronic-Photonic AI System**
2411.13715v1 by Ziang Yin, Meng Zhang, Amir Begovic, Rena Huang, Jeff Zhang, Jiaqi Gu

Electronic-photonic integrated circuits (EPICs) offer transformative
potential for next-generation high-performance AI but require interdisciplinary
advances across devices, circuits, architecture, and design automation. The
complexity of hybrid systems makes it challenging even for domain experts to
understand distinct behaviors and interactions across design stack. The lack of
a flexible, accurate, fast, and easy-to-use EPIC AI system simulation framework
significantly limits the exploration of hardware innovations and system
evaluations on common benchmarks. To address this gap, we propose SimPhony, a
cross-layer modeling and simulation framework for heterogeneous
electronic-photonic AI systems. SimPhony offers a platform that enables (1)
generic, extensible hardware topology representation that supports
heterogeneous multi-core architectures with diverse photonic tensor core
designs; (2) optics-specific dataflow modeling with unique multi-dimensional
parallelism and reuse beyond spatial/temporal dimensions; (3) data-aware energy
modeling with realistic device responses, layout-aware area estimation, link
budget analysis, and bandwidth-adaptive memory modeling; and (4) seamless
integration with model training framework for hardware/software co-simulation.
By providing a unified, versatile, and high-fidelity simulation platform,
SimPhony enables researchers to innovate and evaluate EPIC AI hardware across
multiple domains, facilitating the next leap in emerging AI hardware. We
open-source our codes at https://github.com/ScopeX-ASU/SimPhony

摘要：電子光子整合電路 (EPIC) 為次世代高效能人工智慧帶來轉型潛力，但需要在裝置、電路、架構和設計自動化方面跨領域進展。混合系統的複雜性讓即使是領域專家也很難理解設計堆疊中的不同行為和互動。缺乏一個靈活、精確、快速且易於使用的 EPIC 人工智慧系統模擬架構，大幅限制了對硬體創新和系統評估的探索。為了解決這個差距，我們提出 SimPhony，一個異質電子光子人工智慧系統的跨層建模和模擬架構。SimPhony 提供了一個平台，可以實現 (1) 支援異質多核心架構和多樣光子張量核心設計的通用、可擴充硬體拓撲表示；(2) 具有獨特多維度平行性和空間/時間維度之外的再利用的光學特定資料流建模；(3) 透過實際裝置反應、考量佈局的面積估計、鏈路預算分析和頻寬適應式記憶體建模來進行資料感知的能源建模；以及 (4) 與模型訓練架構無縫整合，以進行硬體/軟體協同模擬。透過提供一個統一、多功能且高保真度的模擬平台，SimPhony 能讓研究人員跨多個領域創新和評估 EPIC 人工智慧硬體，促進新興人工智慧硬體的下一步飛躍。我們的程式碼已在 https://github.com/ScopeX-ASU/SimPhony 開源。

##### **Retrieval-Augmented Generation for Domain-Specific Question Answering: A Case Study on Pittsburgh and CMU**
2411.13691v1 by Haojia Sun, Yaqi Wang, Shuting Zhang

We designed a Retrieval-Augmented Generation (RAG) system to provide large
language models with relevant documents for answering domain-specific questions
about Pittsburgh and Carnegie Mellon University (CMU). We extracted over 1,800
subpages using a greedy scraping strategy and employed a hybrid annotation
process, combining manual and Mistral-generated question-answer pairs,
achieving an inter-annotator agreement (IAA) score of 0.7625. Our RAG framework
integrates BM25 and FAISS retrievers, enhanced with a reranker for improved
document retrieval accuracy. Experimental results show that the RAG system
significantly outperforms a non-RAG baseline, particularly in time-sensitive
and complex queries, with an F1 score improvement from 5.45% to 42.21% and
recall of 56.18%. This study demonstrates the potential of RAG systems in
enhancing answer precision and relevance, while identifying areas for further
optimization in document retrieval and model training.

摘要：我們設計了一個檢索增強生成 (RAG) 系統，為大型語言模型提供相關文件，以回答有關匹茲堡和卡內基美隆大學 (CMU) 的特定領域問題。我們使用貪婪的網路爬取策略提取了超過 1,800 個子頁面，並採用了混合註釋處理程序，結合手動和 Mistral 生成的問答對，達到了 0.7625 的標記間一致性 (IAA) 分數。我們的 RAG 框架整合了 BM25 和 FAISS 檢索器，並增強了重新排序器，以提高文件檢索準確度。實驗結果表明，RAG 系統明顯優於非 RAG 基準，特別是在時間敏感和複雜的查詢中，F1 分數從 5.45% 提高到 42.21%，召回率為 56.18%。本研究展示了 RAG 系統在增強答案精確度和相關性方面的潛力，同時找出文件檢索和模型訓練中進一步最佳化的領域。

##### **Hierarchical Text Classification (HTC) vs. eXtreme Multilabel Classification (XML): Two Sides of the Same Medal**
2411.13687v1 by Nerijus Bertalis, Paul Granse, Ferhat Gül, Florian Hauss, Leon Menkel, David Schüler, Tom Speier, Lukas Galke, Ansgar Scherp

Assigning a subset of labels from a fixed pool of labels to a given input
text is a text classification problem with many real-world applications, such
as in recommender systems. Two separate research streams address this issue.
Hierarchical Text Classification (HTC) focuses on datasets with smaller label
pools of hundreds of entries, accompanied by a semantic label hierarchy. In
contrast, eXtreme Multi-Label Text Classification (XML) considers very large
label pools with up to millions of entries, in which the labels are not
arranged in any particular manner. However, in XML, a common approach is to
construct an artificial hierarchy without any semantic information before or
during the training process. Here, we investigate how state-of-the-art models
from one domain perform when trained and tested on datasets from the other
domain. The HBGL and HGLCR models from the HTC domain are trained and tested on
the datasets Wiki10-31K, AmazonCat-13K, and Amazon-670K from the XML domain. On
the other side, the XML models CascadeXML and XR-Transformer are trained and
tested on the datasets Web of Science, The New York Times Annotated Corpus, and
RCV1-V2 from the HTC domain. HTC models, on the other hand, are not equipped to
handle the size of XML datasets and achieve poor transfer results. The code and
numerous files that are needed to reproduce our results can be obtained from
https://github.com/FloHauss/XMC_HTC

摘要：將固定標籤池中的標籤子集指定給特定輸入文字是文字分類問題，在許多實際應用中會遇到，例如推薦系統。兩個獨立的研究領域探討此議題。階層式文字分類 (HTC) 專注於標籤池較小的資料集，其中包含數百個項目，並附帶語意標籤階層。相反地，極端多標籤文字分類 (XML) 考量包含數百萬個項目的非常大的標籤池，其中標籤並未以任何特定方式排列。然而，在 XML 中，一種常見的方法是在訓練過程中或之前建構一個不含任何語意資訊的人工階層。在此，我們探討來自一個領域的最新模型在針對來自另一個領域的資料集進行訓練和測試時如何執行。HTC 領域的 HBGL 和 HGLCR 模型在 XML 領域的資料集 Wiki10-31K、AmazonCat-13K 和 Amazon-670K 上進行訓練和測試。另一方面，XML 模型 CascadeXML 和 XR-Transformer 在 HTC 領域的資料集 Web of Science、The New York Times Annotated Corpus 和 RCV1-V2 上進行訓練和測試。另一方面，HTC 模型並未具備處理 XML 資料集大小的能力，且轉移結果不佳。可以在 https://github.com/FloHauss/XMC_HTC 取得重現我們結果所需的程式碼和大量檔案。

##### **Hymba: A Hybrid-head Architecture for Small Language Models**
2411.13676v1 by Xin Dong, Yonggan Fu, Shizhe Diao, Wonmin Byeon, Zijia Chen, Ameya Sunil Mahabaleshwarkar, Shih-Yang Liu, Matthijs Van Keirsbilck, Min-Hung Chen, Yoshi Suhara, Yingyan Lin, Jan Kautz, Pavlo Molchanov

We propose Hymba, a family of small language models featuring a hybrid-head
parallel architecture that integrates transformer attention mechanisms with
state space models (SSMs) for enhanced efficiency. Attention heads provide
high-resolution recall, while SSM heads enable efficient context summarization.
Additionally, we introduce learnable meta tokens that are prepended to prompts,
storing critical information and alleviating the "forced-to-attend" burden
associated with attention mechanisms. This model is further optimized by
incorporating cross-layer key-value (KV) sharing and partial sliding window
attention, resulting in a compact cache size. During development, we conducted
a controlled study comparing various architectures under identical settings and
observed significant advantages of our proposed architecture. Notably, Hymba
achieves state-of-the-art results for small LMs: Our Hymba-1.5B-Base model
surpasses all sub-2B public models in performance and even outperforms
Llama-3.2-3B with 1.32% higher average accuracy, an 11.67x cache size
reduction, and 3.49x throughput.

摘要：我們提出 Hymba，一個小型語言模型系列，具有整合Transformer注意力機制與狀態空間模型 (SSM) 的混合頭平行架構，以提高效率。注意力頭提供高解析度召回，而 SSM 頭則能有效地對內容進行摘要。此外，我們引入了可學習的元標記，並將其置於提示之前，儲存關鍵資訊，並減輕與注意力機制相關的「被迫關注」負擔。此模型進一步透過整合跨層鍵值 (KV) 共享和部分滑動視窗注意力進行最佳化，進而縮小快取大小。在開發過程中，我們進行了一項受控研究，在相同的設定下比較各種架構，並觀察到我們提出的架構具有顯著的優點。值得注意的是，Hymba 達到了小型語言模型的最新技術成果：我們的 Hymba-1.5B-Base 模型在效能上超越所有低於 2B 的公開模型，甚至以高出 1.32% 的平均準確度、減少 11.67 倍的快取大小和 3.49 倍的吞吐量，優於 Llama-3.2-3B。

##### **No Free Delivery Service: Epistemic limits of passive data collection in complex social systems**
2411.13653v1 by Maximilian Nickel

Rapid model validation via the train-test paradigm has been a key driver for
the breathtaking progress in machine learning and AI. However, modern AI
systems often depend on a combination of tasks and data collection practices
that violate all assumptions ensuring test validity. Yet, without rigorous
model validation we cannot ensure the intended outcomes of deployed AI systems,
including positive social impact, nor continue to advance AI research in a
scientifically sound way. In this paper, I will show that for widely considered
inference settings in complex social systems the train-test paradigm does not
only lack a justification but is indeed invalid for any risk estimator,
including counterfactual and causal estimators, with high probability. These
formal impossibility results highlight a fundamental epistemic issue, i.e.,
that for key tasks in modern AI we cannot know whether models are valid under
current data collection practices. Importantly, this includes variants of both
recommender systems and reasoning via large language models, and neither
na\"ive scaling nor limited benchmarks are suited to address this issue. I am
illustrating these results via the widely used MovieLens benchmark and conclude
by discussing the implications of these results for AI in social systems,
including possible remedies such as participatory data curation and open
science.

摘要：透過訓練測試典範進行快速模型驗證，一直是機器學習和 AI 令人驚嘆的進展的關鍵驅動力。然而，現代的 AI 系統通常依賴於任務和資料收集實務的組合，這些實務違反了確保測試有效性的所有假設。然而，如果沒有嚴謹的模型驗證，我們無法確保已部署的 AI 系統的預期結果，包括正面的社會影響，也無法以科學健全的方式持續推進 AI 研究。在本文中，我將說明對於複雜社會系統中廣泛考量的推論設定，訓練測試典範不僅缺乏依據，而且對於任何風險估計器（包括反事實和因果估計器）來說，在高機率下都是無效的。這些形式上的不可能結果突顯了一個基本的認識論問題，也就是對於現代 AI 中的關鍵任務，我們無法知道在當前的資料收集實務下，模型是否有效。重要的是，這包括推薦系統和透過大型語言模型進行推理的變體，而且天真的擴充或有限的基準都不適合解決這個問題。我透過廣泛使用的 MovieLens 基準來說明這些結果，並透過討論這些結果對社會系統中 AI 的影響，包括可能的補救措施，例如參與式資料策展和開放科學，來作為結論。

##### **SpecTool: A Benchmark for Characterizing Errors in Tool-Use LLMs**
2411.13547v1 by Shirley Kokane, Ming Zhu, Tulika Awalgaonkar, Jianguo Zhang, Thai Hoang, Akshara Prabhakar, Zuxin Liu, Tian Lan, Liangwei Yang, Juntao Tan, Rithesh Murthy, Weiran Yao, Zhiwei Liu, Juan Carlos Niebles, Huan Wang, Shelby Heinecke, Caiming Xiong, Silivo Savarese

Evaluating the output of Large Language Models (LLMs) is one of the most
critical aspects of building a performant compound AI system. Since the output
from LLMs propagate to downstream steps, identifying LLM errors is crucial to
system performance. A common task for LLMs in AI systems is tool use. While
there are several benchmark environments for evaluating LLMs on this task, they
typically only give a success rate without any explanation of the failure
cases. To solve this problem, we introduce SpecTool, a new benchmark to
identify error patterns in LLM output on tool-use tasks. Our benchmark data set
comprises of queries from diverse environments that can be used to test for the
presence of seven newly characterized error patterns. Using SPECTOOL , we show
that even the most prominent LLMs exhibit these error patterns in their
outputs. Researchers can use the analysis and insights from SPECTOOL to guide
their error mitigation strategies.

摘要：評估大型語言模型 (LLM) 的輸出是建構高效能複合式 AI 系統最重要的面向之一。由於 LLM 的輸出會傳播到下游步驟，因此找出 LLM 錯誤對於系統效能至關重要。在 AI 系統中，LLM 的一項常見任務是使用工具。雖然有幾個用於評估 LLM 執行此項任務的基準環境，但它們通常只提供成功率，而沒有說明失敗案例。為了解決這個問題，我們引進 SpecTool，一個用於找出 LLM 在工具使用任務中輸出錯誤模式的新基準。我們的基準資料集包含來自不同環境的查詢，可據以測試七種新特徵化錯誤模式的存在。使用 SPECTOOL，我們顯示出即使是最傑出的 LLM 也會在其輸出中展現這些錯誤模式。研究人員可以使用 SPECTOOL 的分析和見解來引導他們的錯誤緩解策略。

##### **BALROG: Benchmarking Agentic LLM and VLM Reasoning On Games**
2411.13543v1 by Davide Paglieri, Bartłomiej Cupiał, Samuel Coward, Ulyana Piterbarg, Maciej Wolczyk, Akbir Khan, Eduardo Pignatelli, Łukasz Kuciński, Lerrel Pinto, Rob Fergus, Jakob Nicolaus Foerster, Jack Parker-Holder, Tim Rocktäschel

Large Language Models (LLMs) and Vision Language Models (VLMs) possess
extensive knowledge and exhibit promising reasoning abilities; however, they
still struggle to perform well in complex, dynamic environments. Real-world
tasks require handling intricate interactions, advanced spatial reasoning,
long-term planning, and continuous exploration of new strategies-areas in which
we lack effective methodologies for comprehensively evaluating these
capabilities. To address this gap, we introduce BALROG, a novel benchmark
designed to assess the agentic capabilities of LLMs and VLMs through a diverse
set of challenging games. Our benchmark incorporates a range of existing
reinforcement learning environments with varying levels of difficulty,
including tasks that are solvable by non-expert humans in seconds to extremely
challenging ones that may take years to master (e.g., the NetHack Learning
Environment). We devise fine-grained metrics to measure performance and conduct
an extensive evaluation of several popular open-source and closed-source LLMs
and VLMs. Our findings indicate that while current models achieve partial
success in the easier games, they struggle significantly with more challenging
tasks. Notably, we observe severe deficiencies in vision-based decision-making,
as models perform worse when visual representations of the environments are
provided. We release BALROG as an open and user-friendly benchmark to
facilitate future research and development in the agentic community.

摘要：大型語言模型 (LLM) 和視覺語言模型 (VLM) 擁有
廣泛的知識並展現出有前途的推理能力；然而，它們
在複雜、動態的環境中仍然難以表現良好。現實世界的
任務需要處理複雜的互動、先進的空間推理、
長期規劃和持續探索新的策略，我們缺乏有效的
方法來全面評估這些能力。為了解決這個差距，我們引入了 BALROG，一個新基準
旨在通過一系列具有挑戰性的遊戲來評估 LLM 和 VLM 的代理能力。我們的基準納入了範圍廣泛的現有
強化學習環境，難度各不相同，
包括非專家人類可以在幾秒鐘內解決的任務到可能需要數年才能掌握的極具挑戰性的任務（例如 NetHack 學習
環境）。我們設計了細緻的指標來衡量性能並進行
對幾個流行的開源和閉源 LLM
和 VLM 進行廣泛的評估。我們的研究結果表明，雖然當前模型在較簡單的遊戲中取得了部分成功，但它們在更具挑戰性的
任務中顯著掙扎。值得注意的是，我們觀察到基於視覺的決策制定存在嚴重缺陷，
因為當提供環境的視覺表示時，模型的表現會更差。我們將 BALROG 發布為一個開放且用戶友好的基準，以
促進代理社區未來的研究和開發。

##### **Metacognition for Unknown Situations and Environments (MUSE)**
2411.13537v1 by Rodolfo Valiente, Praveen K. Pilly

Metacognition--the awareness and regulation of one's cognitive processes--is
central to human adaptability in unknown situations. In contrast, current
autonomous agents often struggle in novel environments due to their limited
capacity for adaptation. We hypothesize that metacognition is a critical
missing ingredient in adaptive autonomous systems, equipping them with the
cognitive flexibility needed to tackle unfamiliar challenges. Given the broad
scope of metacognitive abilities, we focus on two key aspects: competence
awareness and strategy selection for novel tasks. To this end, we propose the
Metacognition for Unknown Situations and Environments (MUSE) framework, which
integrates metacognitive processes--specifically self-awareness and
self-regulation--into autonomous agents. We present two initial implementations
of MUSE: one based on world modeling and another leveraging large language
models (LLMs), both instantiating the metacognitive cycle. Our system
continuously learns to assess its competence on a given task and uses this
self-awareness to guide iterative cycles of strategy selection. MUSE agents
show significant improvements in self-awareness and self-regulation, enabling
them to solve novel, out-of-distribution tasks more effectively compared to
Dreamer-v3-based reinforcement learning and purely prompt-based LLM agent
approaches. This work highlights the promise of approaches inspired by
cognitive and neural systems in enabling autonomous systems to adapt to new
environments, overcoming the limitations of current methods that rely heavily
on extensive training data.

摘要：元認知——對自身認知過程的覺察與調節——是人類在未知情境中適應能力的中心。相比之下，當前的自主代理經常在新的環境中掙扎，因為它們的適應能力有限。我們假設元認知是適應性自主系統中一個重要的遺失成分，它為它們提供了應對不熟悉挑戰所需的認知靈活性。鑑於元認知能力的廣泛範圍，我們專注於兩個關鍵方面：能力意識和新任務的策略選擇。為此，我們提出了未知情境和環境的元認知 (MUSE) 框架，它將元認知過程——特別是自我意識和自我調節——整合到自主代理中。我們提出了 MUSE 的兩個初始實現：一個基於世界建模，另一個利用大型語言模型 (LLM)，兩者都實例化了元認知迴圈。我們的系統持續學習評估其在給定任務上的能力，並利用這種自我意識來指導策略選擇的迭代迴圈。與基於 Dreamer-v3 的強化學習和純粹基於提示的 LLM 代理方法相比，MUSE 代理在自我意識和自我調節方面表現出顯著的改進，使它們能夠更有效地解決新穎的、分布外的任務。這項工作突出了受認知和神經系統啟發的方法在使自主系統適應新環境方面的前景，克服了當前方法的局限性，而當前方法過於依賴於大量的訓練資料。

##### **Identity Preserving 3D Head Stylization with Multiview Score Distillation**
2411.13536v1 by Bahri Batuhan Bilecen, Ahmet Berke Gokmen, Furkan Guzelant, Aysegul Dundar

3D head stylization transforms realistic facial features into artistic
representations, enhancing user engagement across gaming and virtual reality
applications. While 3D-aware generators have made significant advancements,
many 3D stylization methods primarily provide near-frontal views and struggle
to preserve the unique identities of original subjects, often resulting in
outputs that lack diversity and individuality. This paper addresses these
challenges by leveraging the PanoHead model, synthesizing images from a
comprehensive 360-degree perspective. We propose a novel framework that employs
negative log-likelihood distillation (LD) to enhance identity preservation and
improve stylization quality. By integrating multi-view grid score and mirror
gradients within the 3D GAN architecture and introducing a score rank weighing
technique, our approach achieves substantial qualitative and quantitative
improvements. Our findings not only advance the state of 3D head stylization
but also provide valuable insights into effective distillation processes
between diffusion models and GANs, focusing on the critical issue of identity
preservation. Please visit the https://three-bee.github.io/head_stylization for
more visuals.

摘要：3D 頭部風格化將逼真的臉部特徵轉換成藝術表現，提升遊戲和虛擬實境應用中的使用者參與度。雖然 3D 感知生成器已取得顯著進展，但許多 3D 風格化方法主要提供近乎正面的視角，且難以保留原始主體的獨特身分，通常導致產出缺乏多樣性和個性。本文透過利用 PanoHead 模型，從全面的 360 度視角合成影像，來解決這些挑戰。我們提出一個新的架構，採用負對數似然蒸餾 (LD) 來增強身分保留並提升風格化品質。透過整合多視角網格評分和鏡像梯度於 3D GAN 架構中，並引入評分等級加權技術，我們的做法在質量和數量上皆取得顯著的進步。我們的發現不僅推進了 3D 頭部風格化的現況，也提供了關於擴散模型和 GAN 之間有效蒸餾程序的寶貴見解，重點關注身分保留的關鍵問題。請造訪 https://three-bee.github.io/head_stylization 以取得更多視覺效果。

##### **Predictive Insights into LGBTQ+ Minority Stress: A Transductive Exploration of Social Media Discourse**
2411.13534v1 by S. Chapagain, Y. Zhao, T. K. Rohleen, S. M. Hamdi, S. F. Boubrahimi, R. E. Flinn, E. M. Lund, D. Klooster, J. R. Scheer, C. J. Cascalheira

Individuals who identify as sexual and gender minorities, including lesbian,
gay, bisexual, transgender, queer, and others (LGBTQ+) are more likely to
experience poorer health than their heterosexual and cisgender counterparts.
One primary source that drives these health disparities is minority stress
(i.e., chronic and social stressors unique to LGBTQ+ communities' experiences
adapting to the dominant culture). This stress is frequently expressed in
LGBTQ+ users' posts on social media platforms. However, these expressions are
not just straightforward manifestations of minority stress. They involve
linguistic complexity (e.g., idiom or lexical diversity), rendering them
challenging for many traditional natural language processing methods to detect.
In this work, we designed a hybrid model using Graph Neural Networks (GNN) and
Bidirectional Encoder Representations from Transformers (BERT), a pre-trained
deep language model to improve the classification performance of minority
stress detection. We experimented with our model on a benchmark social media
dataset for minority stress detection (LGBTQ+ MiSSoM+). The dataset is
comprised of 5,789 human-annotated Reddit posts from LGBTQ+ subreddits. Our
approach enables the extraction of hidden linguistic nuances through
pretraining on a vast amount of raw data, while also engaging in transductive
learning to jointly develop representations for both labeled training data and
unlabeled test data. The RoBERTa-GCN model achieved an accuracy of 0.86 and an
F1 score of 0.86, surpassing the performance of other baseline models in
predicting LGBTQ+ minority stress. Improved prediction of minority stress
expressions on social media could lead to digital health interventions to
improve the wellbeing of LGBTQ+ people-a community with high rates of
stress-sensitive health problems.

摘要：<paragraph>認同自己是性與性別少數族群的人，包括女同性戀、男同性戀、雙性戀、跨性別、酷兒和其他 LGBTQ+ 族群，比異性戀和順性別者更容易有較差的健康狀況。造成這些健康差異的主要來源之一是少數族群壓力（即 LGBTQ+ 社群在適應主流文化時獨有的慢性與社會壓力）。這種壓力經常在 LGBTQ+ 使用者於社群媒體平台上的貼文中表達出來。然而，這些表達並不僅僅是少數族群壓力的直接表現。它們包含了語言複雜性（例如慣用語或詞彙多樣性），讓許多傳統的自然語言處理方法難以辨識。在這項研究中，我們設計了一個混合模型，使用圖神經網路 (GNN) 和來自 Transformer 的雙向編碼器表徵 (BERT)，這是一個經過預先訓練的深度語言模型，以提升少數族群壓力辨識的分類效能。我們在一個用於少數族群壓力辨識的基準社群媒體資料集 (LGBTQ+ MiSSoM+) 上對我們的模型進行實驗。該資料集包含了 5,789 篇由人類註解的 Reddit 貼文，來自於 LGBTQ+ 的 subreddit。我們的做法能夠透過在大量的原始資料上進行預訓練來萃取隱藏的語言差異，同時也參與轉導式學習，以共同開發標籤訓練資料和未標籤測試資料的表徵。RoBERTa-GCN 模型達到了 0.86 的準確率和 0.86 的 F1 分數，在預測 LGBTQ+ 少數族群壓力方面超越了其他基線模型的效能。在社群媒體上對少數族群壓力表達的預測改善，可以導致數位健康介入措施，以改善 LGBTQ+ 族群的福祉，而這個族群有很高的壓力敏感性健康問題發生率。</paragraph>

##### **Advancing Complex Medical Communication in Arabic with Sporo AraSum: Surpassing Existing Large Language Models**
2411.13518v1 by Chanseo Lee, Sonu Kumar, Kimon A. Vogt, Sam Meraj, Antonia Vogt

The increasing demand for multilingual capabilities in healthcare underscores
the need for AI models adept at processing diverse languages, particularly in
clinical documentation and decision-making. Arabic, with its complex
morphology, syntax, and diglossia, poses unique challenges for natural language
processing (NLP) in medical contexts. This case study evaluates Sporo AraSum, a
language model tailored for Arabic clinical documentation, against JAIS, the
leading Arabic NLP model. Using synthetic datasets and modified PDQI-9 metrics
modified ourselves for the purposes of assessing model performances in a
different language. The study assessed the models' performance in summarizing
patient-physician interactions, focusing on accuracy, comprehensiveness,
clinical utility, and linguistic-cultural competence.
  Results indicate that Sporo AraSum significantly outperforms JAIS in
AI-centric quantitative metrics and all qualitative attributes measured in our
modified version of the PDQI-9. AraSum's architecture enables precise and
culturally sensitive documentation, addressing the linguistic nuances of Arabic
while mitigating risks of AI hallucinations. These findings suggest that Sporo
AraSum is better suited to meet the demands of Arabic-speaking healthcare
environments, offering a transformative solution for multilingual clinical
workflows. Future research should incorporate real-world data to further
validate these findings and explore broader integration into healthcare
systems.

摘要：醫療保健領域對多語言能力的需求日益增加，這凸顯了對善於處理各種語言的 AI 模型的需求，特別是在臨床文件和決策制定中。阿拉伯語具有複雜的形態、語法和雙語現象，這對醫療環境中的自然語言處理 (NLP) 構成了獨特的挑戰。本案例研究評估了 Sporo AraSum（一種專為阿拉伯語臨床文件量身打造的語言模型）和阿拉伯語 NLP 模型的領導者 JAIS。我們使用合成資料集和修改後的 PDQI-9 指標（我們自行修改，以評估模型在不同語言中的表現）。本研究評估了模型在總結患者與醫師互動時的表現，重點在於準確性、全面性、臨床效用和語言文化能力。
結果表明，在以 AI 為中心的定量指標和我們修改後的 PDQI-9 版本中測量的所有定性屬性中，Sporo AraSum 明顯優於 JAIS。AraSum 的架構能產生精確且具有文化敏感度的文件，它能處理阿拉伯語的語言差異，同時降低 AI 產生幻覺的風險。這些發現表明，Sporo AraSum 更適合滿足講阿拉伯語的醫療保健環境的需求，為多語言臨床工作流程提供了一個變革性的解決方案。未來的研究應納入真實世界的資料，以進一步驗證這些發現，並探索更廣泛地整合到醫療保健系統中。

##### **Disentangling Memory and Reasoning Ability in Large Language Models**
2411.13504v2 by Mingyu Jin, Weidi Luo, Sitao Cheng, Xinyi Wang, Wenyue Hua, Ruixiang Tang, William Yang Wang, Yongfeng Zhang

Large Language Models (LLMs) have demonstrated strong performance in handling
complex tasks requiring both extensive knowledge and reasoning abilities.
However, the existing LLM inference pipeline operates as an opaque process
without explicit separation between knowledge retrieval and reasoning steps,
making the model's decision-making process unclear and disorganized. This
ambiguity can lead to issues such as hallucinations and knowledge forgetting,
which significantly impact the reliability of LLMs in high-stakes domains. In
this paper, we propose a new inference paradigm that decomposes the complex
inference process into two distinct and clear actions: (1) memory recall: which
retrieves relevant knowledge, and (2) reasoning: which performs logical steps
based on the recalled knowledge. To facilitate this decomposition, we introduce
two special tokens memory and reason, guiding the model to distinguish between
steps that require knowledge retrieval and those that involve reasoning. Our
experiment results show that this decomposition not only improves model
performance but also enhances the interpretability of the inference process,
enabling users to identify sources of error and refine model responses
effectively. The code is available at
https://github.com/MingyuJ666/Disentangling-Memory-and-Reasoning.

摘要：大型語言模型 (LLM) 在處理需要廣泛知識和推理能力的複雜任務方面表現出強勁的效能。然而，現有的 LLM 推論管線以不透明的流程運作，知識擷取和推理步驟之間沒有明確的區分，使得模型的決策過程不清不楚且雜亂無章。這種模稜兩可可能會導致幻覺和知識遺忘等問題，這會顯著影響 LLM 在高風險領域的可靠性。在本文中，我們提出了一種新的推論範例，將複雜的推論過程分解成兩個不同且明確的動作：(1) 記憶回想：擷取相關知識，以及 (2) 推理：根據回想的知識執行邏輯步驟。為了促進這種分解，我們引入了兩個特殊符號記憶和推理，引導模型區分需要知識擷取的步驟和涉及推理的步驟。我們的實驗結果顯示，這種分解不僅改善了模型效能，也增強了推論過程的可解釋性，使用戶能夠找出錯誤來源並有效地改善模型反應。程式碼可在 https://github.com/MingyuJ666/Disentangling-Memory-and-Reasoning 取得。

##### **Utilizing Large Language Models to Synthesize Product Desirability Datasets**
2411.13485v1 by John D. Hastings, Sherri Weitl-Harms, Joseph Doty, Zachary L. Myers, Warren Thompson

This research explores the application of large language models (LLMs) to
generate synthetic datasets for Product Desirability Toolkit (PDT) testing, a
key component in evaluating user sentiment and product experience. Utilizing
gpt-4o-mini, a cost-effective alternative to larger commercial LLMs, three
methods, Word+Review, Review+Word, and Supply-Word, were each used to
synthesize 1000 product reviews. The generated datasets were assessed for
sentiment alignment, textual diversity, and data generation cost. Results
demonstrated high sentiment alignment across all methods, with Pearson
correlations ranging from 0.93 to 0.97. Supply-Word exhibited the highest
diversity and coverage of PDT terms, although with increased generation costs.
Despite minor biases toward positive sentiments, in situations with limited
test data, LLM-generated synthetic data offers significant advantages,
including scalability, cost savings, and flexibility in dataset production.

摘要：本研究探討將大型語言模型 (LLM) 應用於產生產品可欲性工具組 (PDT) 測試的合成資料集，這是評估使用者情緒和產品體驗的關鍵組成部分。利用 gpt-4o-mini，這是一種具備成本效益且可替代大型商業 LLM 的方法，三種方法（Word+Review、Review+Word 和 Supply-Word）各用於合成 1000 個產品評論。對產生的資料集進行情緒對齊、文字多樣性和資料產生成本的評估。結果顯示所有方法的情緒對齊度都很高，皮爾森相關係數介於 0.93 到 0.97 之間。Supply-Word 展現出最高的 PDT 術語多樣性和涵蓋範圍，儘管產生成本也隨之增加。儘管對正面情緒有輕微的偏見，但在測試資料有限的情況下，LLM 產生的合成資料提供了顯著的優勢，包括可擴充性、成本節省和資料集製作的靈活性。

##### **PatentEdits: Framing Patent Novelty as Textual Entailment**
2411.13477v1 by Ryan Lee, Alexander Spangher, Xuezhe Ma

A patent must be deemed novel and non-obvious in order to be granted by the
US Patent Office (USPTO). If it is not, a US patent examiner will cite the
prior work, or prior art, that invalidates the novelty and issue a non-final
rejection. Predicting what claims of the invention should change given the
prior art is an essential and crucial step in securing invention rights, yet
has not been studied before as a learnable task. In this work we introduce the
PatentEdits dataset, which contains 105K examples of successful revisions that
overcome objections to novelty. We design algorithms to label edits sentence by
sentence, then establish how well these edits can be predicted with large
language models (LLMs). We demonstrate that evaluating textual entailment
between cited references and draft sentences is especially effective in
predicting which inventive claims remained unchanged or are novel in relation
to prior art.

摘要：要獲得美國專利商標局 (USPTO) 授予專利，該專利必須被視為新穎且非顯而易見的。如果不是這樣，美國專利審查員將引用先前作品或先前技術，使新穎性失效並發出非最終駁回。預測在先技術下應更改哪些發明權利要求是確保發明權利的必要且關鍵步驟，但尚未作為可學習的任務進行研究。在這項工作中，我們引入了 PatentEdits 資料集，其中包含 105K 個成功修改範例，克服了對新穎性的反對意見。我們設計演算法來逐句標記編輯，然後確定使用大型語言模型 (LLM) 可以預測這些編輯的程度。我們證明評估引用的參考文獻和草稿句子之間的文本蘊涵對於預測哪些發明權利要求保持不變或相對於先前技術而言是新穎的特別有效。

##### **When Precision Meets Position: BFloat16 Breaks Down RoPE in Long-Context Training**
2411.13476v1 by Haonan Wang, Qian Liu, Chao Du, Tongyao Zhu, Cunxiao Du, Kenji Kawaguchi, Tianyu Pang

Extending context window sizes allows large language models (LLMs) to process
longer sequences and handle more complex tasks. Rotary Positional Embedding
(RoPE) has become the de facto standard due to its relative positional encoding
properties that benefit long-context training. However, we observe that using
RoPE with BFloat16 format results in numerical issues, causing it to deviate
from its intended relative positional encoding, especially in long-context
scenarios. This issue arises from BFloat16's limited precision and accumulates
as context length increases, with the first token contributing significantly to
this problem. To address this, we develop AnchorAttention, a plug-and-play
attention method that alleviates numerical issues caused by BFloat16, improves
long-context capabilities, and speeds up training. AnchorAttention reduces
unnecessary attention computations, maintains semantic coherence, and boosts
computational efficiency by treating the first token as a shared anchor with a
consistent position ID, making it visible to all documents within the training
context. Experiments on three types of LLMs demonstrate that AnchorAttention
significantly improves long-context performance and reduces training time by
over 50\% compared to standard full attention mechanisms, while preserving the
original LLM's capabilities on general tasks. Our code is available at
https://github.com/haonan3/AnchorContext.

摘要：擴展上下文視窗大小允許大型語言模型 (LLM) 處理更長的序列並處理更複雜的任務。旋轉位置嵌入 (RoPE) 已成為事實上的標準，因為它具有相對位置編碼特性，有利於長文脈訓練。然而，我們觀察到使用 BFloat16 格式的 RoPE 會導致數值問題，導致它偏離其預期的相對位置編碼，特別是在長文脈場景中。此問題源自 BFloat16 的有限精度，並隨著文脈長度的增加而累積，其中第一個標記對此問題有顯著的影響。為了解決這個問題，我們開發了 AnchorAttention，這是一種即插即用的注意力方法，可以減輕由 BFloat16 引起的數值問題，改善長文脈能力，並加快訓練速度。AnchorAttention 減少了不必要的注意力計算，維持語義一致性，並通過將第一個標記視為具有固定位置 ID 的共享錨點來提升運算效率，使其在訓練文脈中的所有文件都可見。在三種類型的 LLM 上進行的實驗表明，與標準全注意力機制相比，AnchorAttention 大幅提升了長文脈效能，並將訓練時間縮短了 50% 以上，同時保留了 LLM 在一般任務上的原始能力。我們的程式碼可在 https://github.com/haonan3/AnchorContext 取得。

##### **SoK: A Systems Perspective on Compound AI Threats and Countermeasures**
2411.13459v1 by Sarbartha Banerjee, Prateek Sahu, Mulong Luo, Anjo Vahldiek-Oberwagner, Neeraja J. Yadwadkar, Mohit Tiwari

Large language models (LLMs) used across enterprises often use proprietary
models and operate on sensitive inputs and data. The wide range of attack
vectors identified in prior research - targeting various software and hardware
components used in training and inference - makes it extremely challenging to
enforce confidentiality and integrity policies.
  As we advance towards constructing compound AI inference pipelines that
integrate multiple large language models (LLMs), the attack surfaces expand
significantly. Attackers now focus on the AI algorithms as well as the software
and hardware components associated with these systems. While current research
often examines these elements in isolation, we find that combining cross-layer
attack observations can enable powerful end-to-end attacks with minimal
assumptions about the threat model. Given, the sheer number of existing attacks
at each layer, we need a holistic and systemized understanding of different
attack vectors at each layer.
  This SoK discusses different software and hardware attacks applicable to
compound AI systems and demonstrates how combining multiple attack mechanisms
can reduce the threat model assumptions required for an isolated attack. Next,
we systematize the ML attacks in lines with the Mitre Att&ck framework to
better position each attack based on the threat model. Finally, we outline the
existing countermeasures for both software and hardware layers and discuss the
necessity of a comprehensive defense strategy to enable the secure and
high-performance deployment of compound AI systems.

摘要：大型語言模型 (LLM) 在企業中廣泛使用，通常使用專有模型並對敏感輸入和數據進行操作。先前研究中發現的各種攻擊媒介 - 針對訓練和推理中使用的各種軟體和硬體元件 - 使得執行機密性和完整性政策極具挑戰性。
當我們朝著構建整合多個大型語言模型 (LLM) 的複合式 AI 推理管線邁進時，攻擊面會顯著擴大。攻擊者現在專注於 AI 演算法以及與這些系統相關的軟體和硬體元件。雖然目前的研究所調查通常孤立地檢查這些元素，但我們發現結合跨層攻擊觀察可以實現強大的端對端攻擊，對威脅模型的假設最少。由於每一層現有攻擊的數量龐大，我們需要對每一層的不同攻擊媒介有全面且系統化的了解。
本 SoK 討論了適用於複合式 AI 系統的不同軟體和硬體攻擊，並展示了結合多種攻擊機制如何降低孤立攻擊所需的威脅模型假設。接下來，我們系統化 ML 攻擊，並與 Mitre Att&ck 架構保持一致，以便根據威脅模型更好地定位每個攻擊。最後，我們概述了軟體和硬體層的現有對策，並討論了全面防禦策略的必要性，以實現複合式 AI 系統的安全和高性能部署。

