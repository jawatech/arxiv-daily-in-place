{"2406.08391": {"publish_time": "2024-06-12", "title": "Large Language Models Must Be Taught to Know What They Don't Know", "paper_summary": "When using large language models (LLMs) in high-stakes applications, we need\nto know when we can trust their predictions. Some works argue that prompting\nhigh-performance LLMs is sufficient to produce calibrated uncertainties, while\nothers introduce sampling methods that can be prohibitively expensive. In this\nwork, we first argue that prompting on its own is insufficient to achieve good\ncalibration and then show that fine-tuning on a small dataset of correct and\nincorrect answers can create an uncertainty estimate with good generalization\nand small computational overhead. We show that a thousand graded examples are\nsufficient to outperform baseline methods and that training through the\nfeatures of a model is necessary for good performance and tractable for large\nopen-source models when using LoRA. We also investigate the mechanisms that\nenable reliable LLM uncertainty estimation, finding that many models can be\nused as general-purpose uncertainty estimators, applicable not just to their\nown uncertainties but also the uncertainty of other models. Lastly, we show\nthat uncertainty estimates inform human use of LLMs in human-AI collaborative\nsettings through a user study.", "paper_summary_zh": "\u5728\u9ad8\u98a8\u96aa\u61c9\u7528\u4e2d\u4f7f\u7528\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u6642\uff0c\u6211\u5011\u9700\u8981\u77e5\u9053\u4f55\u6642\u53ef\u4ee5\u4fe1\u4efb\u5176\u9810\u6e2c\u3002\u4e00\u4e9b\u7814\u7a76\u8a8d\u70ba\uff0c\u63d0\u793a\u9ad8\u6027\u80fd LLM \u8db3\u4ee5\u7522\u751f\u6821\u6e96\u7684\u4e0d\u78ba\u5b9a\u6027\uff0c\u800c\u53e6\u4e00\u4e9b\u7814\u7a76\u5247\u5f15\u5165\u4e86\u53ef\u80fd\u975e\u5e38\u6602\u8cb4\u7684\u62bd\u6a23\u65b9\u6cd5\u3002\u5728\u9019\u9805\u7814\u7a76\u4e2d\uff0c\u6211\u5011\u9996\u5148\u8ad6\u8b49\u55ae\u7368\u63d0\u793a\u4e0d\u8db3\u4ee5\u5be6\u73fe\u826f\u597d\u7684\u6821\u6e96\uff0c\u7136\u5f8c\u8868\u660e\u5728\u6b63\u78ba\u548c\u4e0d\u6b63\u78ba\u7b54\u6848\u7684\u5c0f\u578b\u6578\u64da\u96c6\u4e0a\u9032\u884c\u5fae\u8abf\u53ef\u4ee5\u5275\u5efa\u5177\u6709\u826f\u597d\u6cdb\u5316\u6027\u548c\u8f03\u5c0f\u8a08\u7b97\u958b\u92b7\u7684\u4e0d\u78ba\u5b9a\u6027\u4f30\u8a08\u3002\u6211\u5011\u8868\u660e\uff0c\u4e00\u5343\u500b\u5206\u7d1a\u793a\u4f8b\u8db3\u4ee5\u512a\u65bc\u57fa\u7dda\u65b9\u6cd5\uff0c\u4e26\u4e14\u901a\u904e\u6a21\u578b\u7684\u7279\u5fb5\u9032\u884c\u8a13\u7df4\u5c0d\u65bc\u826f\u597d\u7684\u6027\u80fd\u662f\u5fc5\u8981\u7684\uff0c\u4e26\u4e14\u5728\u4f7f\u7528 LoRA \u6642\u5c0d\u65bc\u5927\u578b\u958b\u6e90\u6a21\u578b\u4f86\u8aaa\u662f\u53ef\u884c\u7684\u3002\u6211\u5011\u9084\u7814\u7a76\u4e86\u5be6\u73fe\u53ef\u9760 LLM \u4e0d\u78ba\u5b9a\u6027\u4f30\u8a08\u7684\u6a5f\u5236\uff0c\u767c\u73fe\u8a31\u591a\u6a21\u578b\u53ef\u4ee5\u7528\u4f5c\u901a\u7528\u4e0d\u78ba\u5b9a\u6027\u4f30\u8a08\u5668\uff0c\u4e0d\u50c5\u9069\u7528\u65bc\u5b83\u5011\u81ea\u5df1\u7684\u4e0d\u78ba\u5b9a\u6027\uff0c\u4e5f\u9069\u7528\u65bc\u5176\u4ed6\u6a21\u578b\u7684\u4e0d\u78ba\u5b9a\u6027\u3002\u6700\u5f8c\uff0c\u6211\u5011\u901a\u904e\u7528\u6236\u7814\u7a76\u8868\u660e\uff0c\u4e0d\u78ba\u5b9a\u6027\u4f30\u8a08\u901a\u904e\u4eba\u6a5f\u5354\u4f5c\u8a2d\u7f6e\u544a\u77e5\u4eba\u985e\u4f7f\u7528 LLM\u3002", "author": "Sanyam Kapoor et.al.", "authors": "Sanyam Kapoor, Nate Gruver, Manley Roberts, Katherine Collins, Arka Pal, Umang Bhatt, Adrian Weller, Samuel Dooley, Micah Goldblum, Andrew Gordon Wilson", "id": "2406.08391v1", "paper_url": "http://arxiv.org/abs/2406.08391v1", "repo": "https://github.com/activatedgeek/calibration-tuning"}}