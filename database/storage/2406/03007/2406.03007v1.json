{"2406.03007": {"publish_time": "2024-06-05", "title": "BadAgent: Inserting and Activating Backdoor Attacks in LLM Agents", "paper_summary": "With the prosperity of large language models (LLMs), powerful LLM-based\nintelligent agents have been developed to provide customized services with a\nset of user-defined tools. State-of-the-art methods for constructing LLM agents\nadopt trained LLMs and further fine-tune them on data for the agent task.\nHowever, we show that such methods are vulnerable to our proposed backdoor\nattacks named BadAgent on various agent tasks, where a backdoor can be embedded\nby fine-tuning on the backdoor data. At test time, the attacker can manipulate\nthe deployed LLM agents to execute harmful operations by showing the trigger in\nthe agent input or environment. To our surprise, our proposed attack methods\nare extremely robust even after fine-tuning on trustworthy data. Though\nbackdoor attacks have been studied extensively in natural language processing,\nto the best of our knowledge, we could be the first to study them on LLM agents\nthat are more dangerous due to the permission to use external tools. Our work\ndemonstrates the clear risk of constructing LLM agents based on untrusted LLMs\nor data. Our code is public at https://github.com/DPamK/BadAgent", "paper_summary_zh": "\u96a8\u8457\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u7684\u84ec\u52c3\u767c\u5c55\uff0c\u529f\u80fd\u5f37\u5927\u7684\u57fa\u65bc LLM \u7684\u667a\u6167\u4ee3\u7406\u7a0b\u5f0f\u5df2\u88ab\u958b\u767c\u51fa\u4f86\uff0c\u4ee5\u63d0\u4f9b\u5ba2\u88fd\u5316\u670d\u52d9\uff0c\u4e26\u914d\u6709\u4e00\u7d44\u4f7f\u7528\u8005\u5b9a\u7fa9\u7684\u5de5\u5177\u3002\u5efa\u69cb LLM \u4ee3\u7406\u7a0b\u5f0f\u7684\u6700\u65b0\u65b9\u6cd5\u63a1\u7528\u5df2\u8a13\u7df4\u7684 LLM\uff0c\u4e26\u9032\u4e00\u6b65\u91dd\u5c0d\u4ee3\u7406\u7a0b\u5f0f\u4efb\u52d9\u7684\u8cc7\u6599\u9032\u884c\u5fae\u8abf\u3002\u7136\u800c\uff0c\u6211\u5011\u767c\u73fe\u9019\u4e9b\u65b9\u6cd5\u5bb9\u6613\u53d7\u5230\u6211\u5011\u63d0\u51fa\u7684\u5f8c\u9580\u653b\u64ca\uff0c\u6211\u5011\u7a31\u4e4b\u70ba BadAgent\uff0c\u91dd\u5c0d\u5404\u7a2e\u4ee3\u7406\u7a0b\u5f0f\u4efb\u52d9\uff0c\u5f8c\u9580\u53ef\u4ee5\u900f\u904e\u91dd\u5c0d\u5f8c\u9580\u8cc7\u6599\u9032\u884c\u5fae\u8abf\u4f86\u5d4c\u5165\u3002\u5728\u6e2c\u8a66\u6642\uff0c\u653b\u64ca\u8005\u53ef\u4ee5\u900f\u904e\u5728\u4ee3\u7406\u7a0b\u5f0f\u8f38\u5165\u6216\u74b0\u5883\u4e2d\u986f\u793a\u89f8\u767c\u5668\uff0c\u4f86\u64cd\u7e31\u5df2\u90e8\u7f72\u7684 LLM \u4ee3\u7406\u7a0b\u5f0f\u4ee5\u57f7\u884c\u6709\u5bb3\u64cd\u4f5c\u3002\u4ee4\u6211\u5011\u9a5a\u8a1d\u7684\u662f\uff0c\u6211\u5011\u63d0\u51fa\u7684\u653b\u64ca\u65b9\u6cd5\u5373\u4f7f\u5728\u91dd\u5c0d\u53ef\u4fe1\u8cf4\u8cc7\u6599\u9032\u884c\u5fae\u8abf\u5f8c\uff0c\u4ecd\u7136\u6975\u70ba\u5f37\u5927\u3002\u5118\u7ba1\u5f8c\u9580\u653b\u64ca\u5df2\u5728\u81ea\u7136\u8a9e\u8a00\u8655\u7406\u4e2d\u5ee3\u6cdb\u7814\u7a76\uff0c\u4f46\u64da\u6211\u5011\u6240\u77e5\uff0c\u6211\u5011\u53ef\u80fd\u662f\u7b2c\u4e00\u500b\u7814\u7a76 LLM \u4ee3\u7406\u7a0b\u5f0f\u7684\u5f8c\u9580\u653b\u64ca\uff0c\u800c LLM \u4ee3\u7406\u7a0b\u5f0f\u7531\u65bc\u88ab\u5141\u8a31\u4f7f\u7528\u5916\u90e8\u5de5\u5177\uff0c\u56e0\u6b64\u66f4\u52a0\u5371\u96aa\u3002\u6211\u5011\u7684\u7814\u7a76\u6e05\u695a\u5730\u8868\u660e\uff0c\u57fa\u65bc\u4e0d\u53d7\u4fe1\u4efb\u7684 LLM \u6216\u8cc7\u6599\u4f86\u5efa\u69cb LLM \u4ee3\u7406\u7a0b\u5f0f\u5177\u6709\u660e\u986f\u98a8\u96aa\u3002\u6211\u5011\u7684\u7a0b\u5f0f\u78bc\u5df2\u516c\u958b\u65bc https://github.com/DPamK/BadAgent", "author": "Yifei Wang et.al.", "authors": "Yifei Wang, Dizhan Xue, Shengjie Zhang, Shengsheng Qian", "id": "2406.03007v1", "paper_url": "http://arxiv.org/abs/2406.03007v1", "repo": "https://github.com/dpamk/badagent"}}