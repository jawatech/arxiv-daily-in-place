
### LLM
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-09-05**|**Lexicon3D: Probing Visual Foundation Models for Complex 3D Scene Understanding**|Yunze Man et.al.|[2409.03757v1](http://arxiv.org/abs/2409.03757v1)|[link](https://github.com/yunzeman/lexicon3d)|
|**2024-09-05**|**Attention Heads of Large Language Models: A Survey**|Zifan Zheng et.al.|[2409.03752v1](http://arxiv.org/abs/2409.03752v1)|[link](https://github.com/iaar-shanghai/awesome-attention-heads)|
|**2024-09-05**|**LLM-CI: Assessing Contextual Integrity Norms in Language Models**|Yan Shvartzshnaider et.al.|[2409.03735v1](http://arxiv.org/abs/2409.03735v1)|null|
|**2024-09-05**|**Planning In Natural Language Improves LLM Search For Code Generation**|Evan Wang et.al.|[2409.03733v1](http://arxiv.org/abs/2409.03733v1)|null|
|**2024-09-05**|**RAG based Question-Answering for Contextual Response Prediction System**|Sriram Veturi et.al.|[2409.03708v1](http://arxiv.org/abs/2409.03708v1)|null|
|**2024-09-05**|**A Different Level Text Protection Mechanism With Differential Privacy**|Qingwen Fu et.al.|[2409.03707v1](http://arxiv.org/abs/2409.03707v1)|null|
|**2024-09-05**|**LAST: Language Model Aware Speech Tokenization**|Arnon Turetzky et.al.|[2409.03701v1](http://arxiv.org/abs/2409.03701v1)|null|
|**2024-09-05**|**View-Invariant Policy Learning via Zero-Shot Novel View Synthesis**|Stephen Tian et.al.|[2409.03685v1](http://arxiv.org/abs/2409.03685v1)|null|
|**2024-09-05**|**TRACE-cs: Trustworthy Reasoning for Contrastive Explanations in Course Scheduling Problems**|Stylianos Loukas Vasileiou et.al.|[2409.03671v1](http://arxiv.org/abs/2409.03671v1)|null|
|**2024-09-05**|**A method to benchmark high-dimensional process drift detection**|Edgar Wolf et.al.|[2409.03669v1](http://arxiv.org/abs/2409.03669v1)|[link](https://github.com/edgarwolf/driftbench)|
|**2024-09-05**|**A Fused Large Language Model for Predicting Startup Success**|Abdurahman Maarouf et.al.|[2409.03668v1](http://arxiv.org/abs/2409.03668v1)|null|
|**2024-09-05**|**The representation landscape of few-shot learning and fine-tuning in large language models**|Diego Doimo et.al.|[2409.03662v1](http://arxiv.org/abs/2409.03662v1)|[link](https://github.com/diegodoimo/geometry_icl_finetuning)|
|**2024-09-05**|**LLM-based multi-agent poetry generation in non-cooperative environments**|Ran Zhang et.al.|[2409.03659v1](http://arxiv.org/abs/2409.03659v1)|[link](https://github.com/zhangr2021/Multiagent_poetry)|
|**2024-09-05**|**On the Limited Generalization Capability of the Implicit Reward Model Induced by Direct Preference Optimization**|Yong Lin et.al.|[2409.03650v1](http://arxiv.org/abs/2409.03650v1)|null|
|**2024-09-05**|**Limited but consistent gains in adversarial robustness by co-training object recognition models with human EEG**|Manshan Guo et.al.|[2409.03646v1](http://arxiv.org/abs/2409.03646v1)|null|
|**2024-09-05**|**CDM: A Reliable Metric for Fair and Accurate Formula Recognition Evaluation**|Bin Wang et.al.|[2409.03643v1](http://arxiv.org/abs/2409.03643v1)|[link](https://github.com/opendatalab/unimernet)|
|**2024-09-05**|**Attend First, Consolidate Later: On the Importance of Attention in Different LLM Layers**|Amit Ben Artzy et.al.|[2409.03621v1](http://arxiv.org/abs/2409.03621v1)|null|
|**2024-09-05**|**100 instances is all you need: predicting the success of a new LLM on unseen data by testing on a few instances**|Lorenzo Pacchiardi et.al.|[2409.03563v1](http://arxiv.org/abs/2409.03563v1)|null|
|**2024-09-05**|**DKDM: Data-Free Knowledge Distillation for Diffusion Models with Any Architecture**|Qianlong Xiang et.al.|[2409.03550v1](http://arxiv.org/abs/2409.03550v1)|null|
|**2024-09-05**|**Prediction Accuracy & Reliability: Classification and Object Localization under Distribution Shift**|Fabian Diet et.al.|[2409.03543v1](http://arxiv.org/abs/2409.03543v1)|null|
|**2024-09-05**|**LMLT: Low-to-high Multi-Level Vision Transformer for Image Super-Resolution**|Jeongsoo Kim et.al.|[2409.03516v1](http://arxiv.org/abs/2409.03516v1)|[link](https://github.com/jwgdmkj/lmlt)|
|**2024-09-05**|**From MOOC to MAIC: Reshaping Online Teaching and Learning through LLM-driven Agents**|Jifan Yu et.al.|[2409.03512v1](http://arxiv.org/abs/2409.03512v1)|null|
|**2024-09-05**|**Improving Uncertainty-Error Correspondence in Deep Bayesian Medical Image Segmentation**|Prerak Mody et.al.|[2409.03470v1](http://arxiv.org/abs/2409.03470v1)|[link](https://github.com/prerakmody/bayesuncertainty-error-correspondence)|
|**2024-09-05**|**Characterizing Massive Activations of Attention Mechanism in Graph Neural Networks**|Lorenzo Bini et.al.|[2409.03463v1](http://arxiv.org/abs/2409.03463v1)|[link](https://github.com/msorbi/gnn-ma)|
|**2024-09-05**|**How Much Data is Enough Data? Fine-Tuning Large Language Models for In-House Translation: Performance Evaluation Across Multiple Dataset Sizes**|Inacio Vieira et.al.|[2409.03454v1](http://arxiv.org/abs/2409.03454v1)|null|
|**2024-09-05**|**Fine-tuning large language models for domain adaptation: Exploration of training strategies, scaling, model merging and synergistic capabilities**|Wei Lu et.al.|[2409.03444v1](http://arxiv.org/abs/2409.03444v1)|[link](https://github.com/lamm-mit/llm-finetuning)|
|**2024-09-05**|**Rx Strategist: Prescription Verification using LLM Agents System**|Phuc Phan Van et.al.|[2409.03440v1](http://arxiv.org/abs/2409.03440v1)|null|
|**2024-09-05**|**KiloBot: A Programming Language for Deploying Perception-Guided Industrial Manipulators at Scale**|Wei Gao et.al.|[2409.03439v1](http://arxiv.org/abs/2409.03439v1)|null|
|**2024-09-05**|**Reinforcement Learning Approach to Optimizing Profilometric Sensor Trajectories for Surface Inspection**|Sara Roos-Hoefgeest et.al.|[2409.03429v1](http://arxiv.org/abs/2409.03429v1)|null|
|**2024-09-05**|**Game On: Towards Language Models as RL Experimenters**|Jingwei Zhang et.al.|[2409.03402v1](http://arxiv.org/abs/2409.03402v1)|null|
|**2024-09-05**|**Hardware Acceleration of LLMs: A comprehensive survey and comparison**|Nikoletta Koilia et.al.|[2409.03384v1](http://arxiv.org/abs/2409.03384v1)|null|
|**2024-09-05**|**CogniDual Framework: Self-Training Large Language Models within a Dual-System Theoretical Framework for Improving Cognitive Tasks**|Yongxin Deng et.al.|[2409.03381v1](http://arxiv.org/abs/2409.03381v1)|null|
|**2024-09-05**|**Raw Speech Enhancement with Deep State Space Modeling**|Yan Ru Pei et.al.|[2409.03377v1](http://arxiv.org/abs/2409.03377v1)|[link](https://github.com/Brainchip-Inc/aTENNuate)|
|**2024-09-05**|**Leveraging Large Language Models through Natural Language Processing to provide interpretable Machine Learning predictions of mental deterioration in real time**|Francisco de Arriba-Pérez et.al.|[2409.03375v1](http://arxiv.org/abs/2409.03375v1)|null|
|**2024-09-05**|**Con-ReCall: Detecting Pre-training Data in LLMs via Contrastive Decoding**|Cheng Wang et.al.|[2409.03363v1](http://arxiv.org/abs/2409.03363v1)|null|
|**2024-09-05**|**Sketch: A Toolkit for Streamlining LLM Operations**|Xin Jiang et.al.|[2409.03346v1](http://arxiv.org/abs/2409.03346v1)|null|
|**2024-09-05**|**Normal forms in Virus Machines**|A. Ramírez-de-Arellano et.al.|[2409.03327v1](http://arxiv.org/abs/2409.03327v1)|null|
|**2024-09-05**|**N-gram Prediction and Word Difference Representations for Language Modeling**|DongNyeong Heo et.al.|[2409.03295v1](http://arxiv.org/abs/2409.03295v1)|null|
|**2024-09-05**|**LLM Detectors Still Fall Short of Real World: Case of LLM-Generated Short News-Like Posts**|Henrique Da Silva Gameiro et.al.|[2409.03291v1](http://arxiv.org/abs/2409.03291v1)|null|
|**2024-09-05**|**iText2KG: Incremental Knowledge Graphs Construction Using Large Language Models**|Yassir Lairgi et.al.|[2409.03284v1](http://arxiv.org/abs/2409.03284v1)|[link](https://github.com/AuvaLab/itext2kg)|
|**2024-09-05**|**ChartMoE: Mixture of Expert Connector for Advanced Chart Understanding**|Zhengzhuo Xu et.al.|[2409.03277v1](http://arxiv.org/abs/2409.03277v1)|null|
|**2024-09-05**|**Recent Advances in Attack and Defense Approaches of Large Language Models**|Jing Cui et.al.|[2409.03274v1](http://arxiv.org/abs/2409.03274v1)|null|
|**2024-09-05**|**Strategic Chain-of-Thought: Guiding Accurate Reasoning in LLMs through Strategy Elicitation**|Yu Wang et.al.|[2409.03271v1](http://arxiv.org/abs/2409.03271v1)|null|
|**2024-09-05**|**Bones Can't Be Triangles: Accurate and Efficient Vertebrae Keypoint Estimation through Collaborative Error Revision**|Jinhee Kim et.al.|[2409.03261v1](http://arxiv.org/abs/2409.03261v1)|null|
|**2024-09-05**|**In Search of Trees: Decision-Tree Policy Synthesis for Black-Box Systems via Search**|Emir Demirović et.al.|[2409.03260v1](http://arxiv.org/abs/2409.03260v1)|null|
|**2024-09-05**|**GraphInsight: Unlocking Insights in Large Language Models for Graph Structure Understanding**|Yukun Cao et.al.|[2409.03258v1](http://arxiv.org/abs/2409.03258v1)|null|
|**2024-09-05**|**Understanding LLM Development Through Longitudinal Study: Insights from the Open Ko-LLM Leaderboard**|Chanjun Park et.al.|[2409.03257v1](http://arxiv.org/abs/2409.03257v1)|null|
|**2024-09-05**|**E2CL: Exploration-based Error Correction Learning for Embodied Agents**|Hanlin Wang et.al.|[2409.03256v1](http://arxiv.org/abs/2409.03256v1)|null|
|**2024-09-05**|**Granular-ball Representation Learning for Deep CNN on Learning with Label Noise**|Dawei Dai et.al.|[2409.03254v1](http://arxiv.org/abs/2409.03254v1)|null|
|**2024-09-05**|**Preserving Empirical Probabilities in BERT for Small-sample Clinical Entity Recognition**|Abdul Rehman et.al.|[2409.03238v1](http://arxiv.org/abs/2409.03238v1)|null|
|**2024-09-05**|**Enhancing Healthcare LLM Trust with Atypical Presentations Recalibration**|Jeremy Qin et.al.|[2409.03225v1](http://arxiv.org/abs/2409.03225v1)|[link](https://github.com/jeremy-qin/medical_confidence_elicitation)|
|**2024-09-05**|**Content Moderation by LLM: From Accuracy to Legitimacy**|Tao Huang et.al.|[2409.03219v1](http://arxiv.org/abs/2409.03219v1)|null|
|**2024-09-05**|**xLAM: A Family of Large Action Models to Empower AI Agent Systems**|Jianguo Zhang et.al.|[2409.03215v1](http://arxiv.org/abs/2409.03215v1)|null|
|**2024-09-05**|**TC-LLaVA: Rethinking the Transfer from Image to Video Understanding with Temporal Considerations**|Mingze Gao et.al.|[2409.03206v1](http://arxiv.org/abs/2409.03206v1)|null|
|**2024-09-05**|**An Effective Deployment of Diffusion LM for Data Augmentation in Low-Resource Sentiment Classification**|Zhuowei Chen et.al.|[2409.03203v1](http://arxiv.org/abs/2409.03203v1)|null|
|**2024-09-05**|**Bypassing DARCY Defense: Indistinguishable Universal Adversarial Triggers**|Zuquan Peng et.al.|[2409.03183v1](http://arxiv.org/abs/2409.03183v1)|null|
|**2024-09-05**|**MARAGS: A Multi-Adapter System for Multi-Task Retrieval Augmented Generation Question Answering**|Mitchell DeHaven et.al.|[2409.03171v1](http://arxiv.org/abs/2409.03171v1)|null|
|**2024-09-05**|**InfraLib: Enabling Reinforcement Learning and Decision Making for Large Scale Infrastructure Management**|Pranay Thangeda et.al.|[2409.03167v1](http://arxiv.org/abs/2409.03167v1)|null|
|**2024-09-05**|**Continual Skill and Task Learning via Dialogue**|Weiwei Gu et.al.|[2409.03166v1](http://arxiv.org/abs/2409.03166v1)|null|
|**2024-09-05**|**MaterialBENCH: Evaluating College-Level Materials Science Problem-Solving Abilities of Large Language Models**|Michiko Yoshitake et.al.|[2409.03161v1](http://arxiv.org/abs/2409.03161v1)|null|
|**2024-09-05**|**Debate on Graph: a Flexible and Reliable Reasoning Framework for Large Language Models**|Jie Ma et.al.|[2409.03155v1](http://arxiv.org/abs/2409.03155v1)|[link](https://github.com/reml-group/dog)|
|**2024-09-05**|**Addressing the Gaps in Early Dementia Detection: A Path Towards Enhanced Diagnostic Models through Machine Learning**|Juan A. Berrios Moya et.al.|[2409.03147v1](http://arxiv.org/abs/2409.03147v1)|null|
|**2024-09-05**|**GraphEx: A Graph-based Extraction Method for Advertiser Keyphrase Recommendation**|Ashirbad Mishra et.al.|[2409.03140v1](http://arxiv.org/abs/2409.03140v1)|null|
|**2024-09-04**|**Well, that escalated quickly: The Single-Turn Crescendo Attack (STCA)**|Alan Aqrawi et.al.|[2409.03131v1](http://arxiv.org/abs/2409.03131v1)|null|
|**2024-09-04**|**Probing self-attention in self-supervised speech models for cross-linguistic differences**|Sai Gopinath et.al.|[2409.03115v1](http://arxiv.org/abs/2409.03115v1)|null|
|**2024-09-04**|**MobileUNETR: A Lightweight End-To-End Hybrid Vision Transformer For Efficient Medical Image Segmentation**|Shehan Perera et.al.|[2409.03062v1](http://arxiv.org/abs/2409.03062v1)|[link](https://github.com/osupcvlab/mobileunetr)|
|**2024-09-04**|**Better Verified Explanations with Applications to Incorrectness and Out-of-Distribution Detection**|Min Wu et.al.|[2409.03060v1](http://arxiv.org/abs/2409.03060v1)|null|
|**2024-09-04**|**Oddballness: universal anomaly detection with language models**|Filip Graliński et.al.|[2409.03046v1](http://arxiv.org/abs/2409.03046v1)|null|
|**2024-09-04**|**Can Your Generative Model Detect Out-of-Distribution Covariate Shift?**|Christiaan Viviers et.al.|[2409.03043v1](http://arxiv.org/abs/2409.03043v1)|[link](https://github.com/cviviers/covariateflow)|
|**2024-09-04**|**CLUE: Concept-Level Uncertainty Estimation for Large Language Models**|Yu-Hsiang Wang et.al.|[2409.03021v1](http://arxiv.org/abs/2409.03021v1)|null|
|**2024-09-04**|**RoboTwin: Dual-Arm Robot Benchmark with Generative Digital Twins (early version)**|Yao Mu et.al.|[2409.02920v1](http://arxiv.org/abs/2409.02920v1)|null|
|**2024-09-04**|**UC-NeRF: Uncertainty-aware Conditional Neural Radiance Fields from Endoscopic Sparse Views**|Jiaxin Guo et.al.|[2409.02917v1](http://arxiv.org/abs/2409.02917v1)|[link](https://github.com/wrld/uc-nerf)|
|**2024-09-04**|**Masked Diffusion Models are Secretly Time-Agnostic Masked Models and Exploit Inaccurate Categorical Sampling**|Kaiwen Zheng et.al.|[2409.02908v1](http://arxiv.org/abs/2409.02908v1)|null|
|**2024-09-04**|**LongCite: Enabling LLMs to Generate Fine-grained Citations in Long-context QA**|Jiajie Zhang et.al.|[2409.02897v2](http://arxiv.org/abs/2409.02897v2)|[link](https://github.com/THUDM/LongCite)|
|**2024-09-04**|**LongLLaVA: Scaling Multi-modal LLMs to 1000 Images Efficiently via Hybrid Architecture**|Xidong Wang et.al.|[2409.02889v1](http://arxiv.org/abs/2409.02889v1)|[link](https://github.com/freedomintelligence/longllava)|
|**2024-09-04**|**Multi-stream deep learning framework to predict mild cognitive impairment with Rey Complex Figure Test**|Junyoung Park et.al.|[2409.02883v1](http://arxiv.org/abs/2409.02883v1)|null|
|**2024-09-04**|**Configurable Foundation Models: Building LLMs from a Modular Perspective**|Chaojun Xiao et.al.|[2409.02877v1](http://arxiv.org/abs/2409.02877v1)|null|
|**2024-09-04**|**Hybrid Imitation-Learning Motion Planner for Urban Driving**|Cristian Gariboldi et.al.|[2409.02871v1](http://arxiv.org/abs/2409.02871v1)|null|
|**2024-09-04**|**Historical German Text Normalization Using Type- and Token-Based Language Modeling**|Anton Ehrmanntraut et.al.|[2409.02841v1](http://arxiv.org/abs/2409.02841v1)|null|
|**2024-09-04**|**R2GQA: Retriever-Reader-Generator Question Answering System to Support Students Understanding Legal Regulations in Higher Education**|Phuc-Tinh Pham Do et.al.|[2409.02840v1](http://arxiv.org/abs/2409.02840v1)|null|
|**2024-09-04**|**Exploring Sentiment Dynamics and Predictive Behaviors in Cryptocurrency Discussions by Few-Shot Learning with Large Language Models**|Moein Shahiki Tash et.al.|[2409.02836v1](http://arxiv.org/abs/2409.02836v1)|null|
|**2024-09-04**|**CMM-Math: A Chinese Multimodal Math Dataset To Evaluate and Enhance the Mathematics Reasoning of Large Multimodal Models**|Wentao Liu et.al.|[2409.02834v1](http://arxiv.org/abs/2409.02834v1)|null|
|**2024-09-04**|**Large Language Model-Based Agents for Software Engineering: A Survey**|Junwei Liu et.al.|[2409.02977v1](http://arxiv.org/abs/2409.02977v1)|[link](https://github.com/fudanselab/agent4se-paper-list)|
|**2024-09-04**|**MMMU-Pro: A More Robust Multi-discipline Multimodal Understanding Benchmark**|Xiang Yue et.al.|[2409.02813v1](http://arxiv.org/abs/2409.02813v1)|null|
|**2024-09-04**|**A hybrid FEM-PINN method for time-dependent partial differential equations**|Xiaodong Feng et.al.|[2409.02810v1](http://arxiv.org/abs/2409.02810v1)|null|
|**2024-09-04**|**Towards a Unified View of Preference Learning for Large Language Models: A Survey**|Bofei Gao et.al.|[2409.02795v1](http://arxiv.org/abs/2409.02795v1)|null|
|**2024-09-04**|**An incremental preference elicitation-based approach to learning potentially non-monotonic preferences in multi-criteria sorting**|Zhuolin Li et.al.|[2409.02760v1](http://arxiv.org/abs/2409.02760v1)|null|
|**2024-09-04**|**A Comparative Study of Pre-training and Self-training**|Yiheng Wang et.al.|[2409.02751v1](http://arxiv.org/abs/2409.02751v1)|[link](https://github.com/PKUAI-LINGroup/PAS)|
|**2024-09-04**|**Tractable Offline Learning of Regular Decision Processes**|Ahana Deb et.al.|[2409.02747v1](http://arxiv.org/abs/2409.02747v1)|null|
|**2024-09-04**|**Pooling And Attention: What Are Effective Designs For LLM-Based Embedding Models?**|Yixuan Tang et.al.|[2409.02727v2](http://arxiv.org/abs/2409.02727v2)|[link](https://github.com/yixuantt/poolingandattn)|
|**2024-09-04**|**Pre-training data selection for biomedical domain adaptation using journal impact metrics**|Mathieu Laï-king et.al.|[2409.02725v1](http://arxiv.org/abs/2409.02725v1)|null|
|**2024-09-04**|**Hallucination Detection in LLMs: Fast and Memory-Efficient Finetuned Models**|Gabriel Y. Arteaga et.al.|[2409.02976v1](http://arxiv.org/abs/2409.02976v1)|null|
|**2024-09-04**|**Alignment-Aware Model Extraction Attacks on Large Language Models**|Zi Liang et.al.|[2409.02718v1](http://arxiv.org/abs/2409.02718v1)|[link](https://github.com/liangzid/alignmentextraction)|
|**2024-09-04**|**A Data Selection Approach for Enhancing Low Resource Machine Translation Using Cross-Lingual Sentence Representations**|Nidhi Kowtal et.al.|[2409.02712v1](http://arxiv.org/abs/2409.02712v1)|null|
|**2024-09-04**|**Creating a Gen-AI based Track and Trace Assistant MVP (SuperTracy) for PostNL**|Mohammad Reshadati et.al.|[2409.02711v1](http://arxiv.org/abs/2409.02711v1)|null|
|**2024-09-04**|**Incorporating Like-Minded Peers to Overcome Friend Data Sparsity in Session-Based Social Recommendations**|Chunyan An et.al.|[2409.02702v1](http://arxiv.org/abs/2409.02702v1)|null|
|**2024-09-04**|**LLM-Assisted Visual Analytics: Opportunities and Challenges**|Maeve Hutchinson et.al.|[2409.02691v1](http://arxiv.org/abs/2409.02691v1)|null|
|**2024-09-04**|**Detecting Calls to Action in Multimodal Content: Analysis of the 2021 German Federal Election Campaign on Instagram**|Michael Achmann-Denkler et.al.|[2409.02690v1](http://arxiv.org/abs/2409.02690v1)|null|
|**2024-09-04**|**Deconfounded Causality-aware Parameter-Efficient Fine-Tuning for Problem-Solving Improvement of LLMs**|Ruoyu Wang et.al.|[2409.02686v1](http://arxiv.org/abs/2409.02686v1)|null|
|**2024-09-04**|**RouterRetriever: Exploring the Benefits of Routing over Multiple Expert Embedding Models**|Hyunji Lee et.al.|[2409.02685v1](http://arxiv.org/abs/2409.02685v1)|null|

#### Abstracts
##### **Lexicon3D: Probing Visual Foundation Models for Complex 3D Scene Understanding**
2409.03757v1 by Yunze Man, Shuhong Zheng, Zhipeng Bao, Martial Hebert, Liang-Yan Gui, Yu-Xiong Wang

Complex 3D scene understanding has gained increasing attention, with scene
encoding strategies playing a crucial role in this success. However, the
optimal scene encoding strategies for various scenarios remain unclear,
particularly compared to their image-based counterparts. To address this issue,
we present a comprehensive study that probes various visual encoding models for
3D scene understanding, identifying the strengths and limitations of each model
across different scenarios. Our evaluation spans seven vision foundation
encoders, including image-based, video-based, and 3D foundation models. We
evaluate these models in four tasks: Vision-Language Scene Reasoning, Visual
Grounding, Segmentation, and Registration, each focusing on different aspects
of scene understanding. Our evaluations yield key findings: DINOv2 demonstrates
superior performance, video models excel in object-level tasks, diffusion
models benefit geometric tasks, and language-pretrained models show unexpected
limitations in language-related tasks. These insights challenge some
conventional understandings, provide novel perspectives on leveraging visual
foundation models, and highlight the need for more flexible encoder selection
in future vision-language and scene-understanding tasks.

摘要：複雜的 3D 場景理解獲得越來越多的關注，場景編碼策略在這個成功中扮演著至關重要的角色。然而，各種場景的最佳場景編碼策略仍然不明確，特別是與它們基於影像的對應物相比。為了解決這個問題，我們提出了一項全面的研究，探討了各種視覺編碼模型以進行 3D 場景理解，並確定了每個模型在不同場景中的優點和限制。我們的評估涵蓋了七個視覺基礎編碼器，包括基於影像、基於影片和 3D 基礎模型。我們在四項任務中評估了這些模型：視覺語言場景推理、視覺接地、分割和配準，每項任務都專注於場景理解的不同方面。我們的評估產生了關鍵發現：DINOv2 表現出優異的效能，影片模型在物件層級任務中表現出色，擴散模型受益於幾何任務，而語言預訓練模型在語言相關任務中表現出令人意外的限制。這些見解挑戰了一些傳統的理解，提供了利用視覺基礎模型的新觀點，並強調了在未來的視覺語言和場景理解任務中需要更靈活的編碼器選擇。

##### **Attention Heads of Large Language Models: A Survey**
2409.03752v1 by Zifan Zheng, Yezhaohui Wang, Yuxin Huang, Shichao Song, Bo Tang, Feiyu Xiong, Zhiyu Li

Since the advent of ChatGPT, Large Language Models (LLMs) have excelled in
various tasks but remain largely as black-box systems. Consequently, their
development relies heavily on data-driven approaches, limiting performance
enhancement through changes in internal architecture and reasoning pathways. As
a result, many researchers have begun exploring the potential internal
mechanisms of LLMs, aiming to identify the essence of their reasoning
bottlenecks, with most studies focusing on attention heads. Our survey aims to
shed light on the internal reasoning processes of LLMs by concentrating on the
interpretability and underlying mechanisms of attention heads. We first distill
the human thought process into a four-stage framework: Knowledge Recalling,
In-Context Identification, Latent Reasoning, and Expression Preparation. Using
this framework, we systematically review existing research to identify and
categorize the functions of specific attention heads. Furthermore, we summarize
the experimental methodologies used to discover these special heads, dividing
them into two categories: Modeling-Free methods and Modeling-Required methods.
Also, we outline relevant evaluation methods and benchmarks. Finally, we
discuss the limitations of current research and propose several potential
future directions. Our reference list is open-sourced at
\url{https://github.com/IAAR-Shanghai/Awesome-Attention-Heads}.

摘要：自 ChatGPT 問世以來，大型語言模型 (LLM) 在各種任務中表現出色，但仍很大程度上是黑箱系統。因此，它們的發展很大程度上依賴於數據驅動的方法，限制了通過內部架構和推理路徑的改變來提升性能。因此，許多研究人員開始探索 LLM 的潛在內部機制，旨在找出其推理瓶頸的本質，大多數研究都集中在注意力頭部。我們的調查旨在通過專注於注意力頭部的可解釋性和底層機制，闡明 LLM 的內部推理過程。我們首先將人類的思維過程提煉成一個四階段框架：知識回憶、語境識別、潛在推理和表達準備。使用這個框架，我們系統地回顧現有研究，以識別和分類特定注意力頭部的功能。此外，我們總結了用於發現這些特殊頭部的實驗方法，將它們分為兩類：無建模方法和需要建模的方法。此外，我們概述了相關的評估方法和基準。最後，我們討論了當前研究的局限性，並提出了幾個潛在的未來方向。我們的參考清單在 \url{https://github.com/IAAR-Shanghai/Awesome-Attention-Heads} 開源。

##### **LLM-CI: Assessing Contextual Integrity Norms in Language Models**
2409.03735v1 by Yan Shvartzshnaider, Vasisht Duddu, John Lacalamita

Large language models (LLMs), while memorizing parts of their training data
scraped from the Internet, may also inadvertently encode societal preferences
and norms. As these models are integrated into sociotechnical systems, it is
crucial that the norms they encode align with societal expectations. These
norms could vary across models, hyperparameters, optimization techniques, and
datasets. This is especially challenging due to prompt sensitivity$-$small
variations in prompts yield different responses, rendering existing assessment
methodologies unreliable. There is a need for a comprehensive framework
covering various models, optimization, and datasets, along with a reliable
methodology to assess encoded norms.
  We present LLM-CI, the first open-sourced framework to assess privacy norms
encoded in LLMs. LLM-CI uses a Contextual Integrity-based factorial vignette
methodology to assess the encoded norms across different contexts and LLMs. We
propose the multi-prompt assessment methodology to address prompt sensitivity
by assessing the norms from only the prompts that yield consistent responses
across multiple variants. Using LLM-CI and our proposed methodology, we
comprehensively evaluate LLMs using IoT and COPPA vignettes datasets from prior
work, examining the impact of model properties (e.g., hyperparameters,
capacity) and optimization strategies (e.g., alignment, quantization).

摘要：大型語言模型 (LLM) 在記憶從網際網路擷取的部分訓練資料時，也可能無意間編碼社會偏好和規範。隨著這些模型整合到社會技術系統中，它們編碼的規範與社會期望一致至關重要。這些規範可能會因模型、超參數、最佳化技術和資料集而異。由於提示敏感性，這尤其具有挑戰性$-$提示的微小變化會產生不同的回應，使得現有的評估方法論不可靠。需要一個涵蓋各種模型、最佳化和資料集的綜合架構，以及一個可靠的方法論來評估編碼的規範。
我們提出 LLM-CI，這是第一個用於評估 LLM 中編碼的隱私規範的開源架構。LLM-CI 使用基於情境完整性的階乘小插曲方法論來評估不同情境和 LLM 中編碼的規範。我們提出多提示評估方法論來解決提示敏感性，方法是僅從在多個變體中產生一致回應的提示中評估規範。使用 LLM-CI 和我們提出的方法論，我們使用先前工作中的 IoT 和 COPPA 小插曲資料集全面評估 LLM，檢查模型屬性（例如，超參數、容量）和最佳化策略（例如，對齊、量化）的影響。

##### **Planning In Natural Language Improves LLM Search For Code Generation**
2409.03733v1 by Evan Wang, Federico Cassano, Catherine Wu, Yunfeng Bai, Will Song, Vaskar Nath, Ziwen Han, Sean Hendryx, Summer Yue, Hugh Zhang

While scaling training compute has led to remarkable improvements in large
language models (LLMs), scaling inference compute has not yet yielded analogous
gains. We hypothesize that a core missing component is a lack of diverse LLM
outputs, leading to inefficient search due to models repeatedly sampling highly
similar, yet incorrect generations. We empirically demonstrate that this lack
of diversity can be mitigated by searching over candidate plans for solving a
problem in natural language. Based on this insight, we propose PLANSEARCH, a
novel search algorithm which shows strong results across HumanEval+, MBPP+, and
LiveCodeBench (a contamination-free benchmark for competitive coding).
PLANSEARCH generates a diverse set of observations about the problem and then
uses these observations to construct plans for solving the problem. By
searching over plans in natural language rather than directly over code
solutions, PLANSEARCH explores a significantly more diverse range of potential
solutions compared to baseline search methods. Using PLANSEARCH on top of
Claude 3.5 Sonnet achieves a state-of-the-art pass@200 of 77.0% on
LiveCodeBench, outperforming both the best score achieved without search
(pass@1 = 41.4%) and using standard repeated sampling (pass@200 = 60.6%).
Finally, we show that, across all models, search algorithms, and benchmarks
analyzed, we can accurately predict performance gains due to search as a direct
function of the diversity over generated ideas.

摘要：<paragraph>儘管擴展訓練運算已大幅改善大型語言模型 (LLM)，但擴展推論運算尚未產生類似的優勢。我們假設一個核心遺失的組成部分是缺乏多樣化的 LLM 輸出，這會導致模型反覆取樣高度相似但錯誤的生成，進而導致搜尋效率低下。我們實證證明，透過搜尋以自然語言解決問題的候選計畫，可以減輕這種缺乏多樣性的問題。根據這個見解，我們提出了 PLANSEARCH，這是一種新穎的搜尋演算法，在 HumanEval+、MBPP+ 和 LiveCodeBench（一種無污染的競爭編碼基準）中展現強勁的結果。PLANSEARCH 會產生一組關於問題的多樣化觀察，然後使用這些觀察來建構解決問題的計畫。透過以自然語言而非直接以程式碼解決方案搜尋計畫，與基準搜尋方法相比，PLANSEARCH 探索了更多樣化的潛在解決方案範圍。在 Claude 3.5 Sonnet 上使用 PLANSEARCH，在 LiveCodeBench 上達到了 77.0% 的最佳 pass@200，優於未搜尋獲得的最佳分數 (pass@1 = 41.4%) 和使用標準重複取樣 (pass@200 = 60.6%)。最後，我們證明，在分析的所有模型、搜尋演算法和基準中，我們可以準確預測由於搜尋而產生的效能提升，作為生成想法多樣性的直接函數。</paragraph>

##### **RAG based Question-Answering for Contextual Response Prediction System**
2409.03708v1 by Sriram Veturi, Saurabh Vaichal, Nafis Irtiza Tripto, Reshma Lal Jagadheesh, Nian Yan

Large Language Models (LLMs) have shown versatility in various Natural
Language Processing (NLP) tasks, including their potential as effective
question-answering systems. However, to provide precise and relevant
information in response to specific customer queries in industry settings, LLMs
require access to a comprehensive knowledge base to avoid hallucinations.
Retrieval Augmented Generation (RAG) emerges as a promising technique to
address this challenge. Yet, developing an accurate question-answering
framework for real-world applications using RAG entails several challenges: 1)
data availability issues, 2) evaluating the quality of generated content, and
3) the costly nature of human evaluation. In this paper, we introduce an
end-to-end framework that employs LLMs with RAG capabilities for industry use
cases. Given a customer query, the proposed system retrieves relevant knowledge
documents and leverages them, along with previous chat history, to generate
response suggestions for customer service agents in the contact centers of a
major retail company. Through comprehensive automated and human evaluations, we
show that this solution outperforms the current BERT-based algorithms in
accuracy and relevance. Our findings suggest that RAG-based LLMs can be an
excellent support to human customer service representatives by lightening their
workload.

摘要：大型語言模型 (LLM) 已在各種自然語言處理 (NLP) 任務中展現出多功能性，包括其作為有效問答系統的潛力。然而，為了在產業環境中對特定客戶查詢提供精確且相關的資訊，LLM 需要存取全面的知識庫以避免產生幻覺。檢索增強生成 (RAG) 成為了解決此挑戰的一種有前途的技術。然而，使用 RAG 為真實世界的應用程式開發準確的問答架構會帶來若干挑戰：1) 資料可用性問題、2) 評估生成內容的品質，以及 3) 人工評估的昂貴性質。在本文中，我們介紹了一個端對端的架構，它採用具備 RAG 功能的 LLM，以適用於產業用例。針對客戶查詢，所提出的系統會檢索相關的知識文件，並利用它們，連同先前的聊天記錄，為大型零售公司的聯絡中心中的客戶服務代理產生回應建議。透過全面的自動化和人工評估，我們證明此解決方案在準確性和相關性方面優於目前的 BERT 基準演算法。我們的研究結果表明，基於 RAG 的 LLM 可以透過減輕其工作負擔，成為人類客戶服務代表的絕佳支援。

##### **A Different Level Text Protection Mechanism With Differential Privacy**
2409.03707v1 by Qingwen Fu

The article introduces a method for extracting words of different degrees of
importance based on the BERT pre-training model and proves the effectiveness of
this method. The article also discusses the impact of maintaining the same
perturbation results for words of different importance on the overall text
utility. This method can be applied to long text protection.

摘要：本文提出了一种基于BERT预训练模型提取不同重要程度词语的方法，并论证了该方法的有效性。文章还探讨了对不同重要程度的词语保持相同的扰动结果对整体文本效用的影响。该方法可应用于长文本保护。

##### **LAST: Language Model Aware Speech Tokenization**
2409.03701v1 by Arnon Turetzky, Yossi Adi

Speech tokenization serves as the foundation of speech language model (LM),
enabling them to perform various tasks such as spoken language modeling,
text-to-speech, speech-to-text, etc. Most speech tokenizers are trained
independently of the LM training process, relying on separate acoustic models
and quantization methods. Following such an approach may create a mismatch
between the tokenization process and its usage afterward. In this study, we
propose a novel approach to training a speech tokenizer by leveraging
objectives from pre-trained textual LMs. We advocate for the integration of
this objective into the process of learning discrete speech representations.
Our aim is to transform features from a pre-trained speech model into a new
feature space that enables better clustering for speech LMs. We empirically
investigate the impact of various model design choices, including speech
vocabulary size and text LM size. Our results demonstrate the proposed
tokenization method outperforms the evaluated baselines considering both spoken
language modeling and speech-to-text. More importantly, unlike prior work, the
proposed method allows the utilization of a single pre-trained LM for
processing both speech and text inputs, setting it apart from conventional
tokenization approaches.

摘要：語音標記化作為語音語言模型 (LM) 的基礎，
使它們能夠執行各種任務，例如口語語言建模、
文字轉語音、語音轉文字等。大多數語音標記器都是獨立於 LM 訓練過程進行訓練，依賴於單獨的聲學模型
和量化方法。遵循這種方法可能會在標記化過程及其後續使用之間造成不匹配。在本研究中，我們
提出了一種通過利用預訓練文本 LM 的目標來訓練語音標記器的全新方法。我們提倡將
此目標整合到學習離散語音表示的過程中。我們的目標是將預訓練語音模型中的特徵轉換為新的
特徵空間，以便為語音 LM 實現更好的聚類。我們憑經驗
研究了各種模型設計選擇的影響，包括語音詞彙量大小和文本 LM 大小。我們的結果表明，所提出的
標記化方法在口語語言建模和語音轉文字方面都優於評估的基準。更重要的是，與先前的研究不同，
所提出的方法允許利用單個預訓練 LM 來處理語音和文字輸入，這使其有別於傳統的
標記化方法。

##### **View-Invariant Policy Learning via Zero-Shot Novel View Synthesis**
2409.03685v1 by Stephen Tian, Blake Wulfe, Kyle Sargent, Katherine Liu, Sergey Zakharov, Vitor Guizilini, Jiajun Wu

Large-scale visuomotor policy learning is a promising approach toward
developing generalizable manipulation systems. Yet, policies that can be
deployed on diverse embodiments, environments, and observational modalities
remain elusive. In this work, we investigate how knowledge from large-scale
visual data of the world may be used to address one axis of variation for
generalizable manipulation: observational viewpoint. Specifically, we study
single-image novel view synthesis models, which learn 3D-aware scene-level
priors by rendering images of the same scene from alternate camera viewpoints
given a single input image. For practical application to diverse robotic data,
these models must operate zero-shot, performing view synthesis on unseen tasks
and environments. We empirically analyze view synthesis models within a simple
data-augmentation scheme that we call View Synthesis Augmentation (VISTA) to
understand their capabilities for learning viewpoint-invariant policies from
single-viewpoint demonstration data. Upon evaluating the robustness of policies
trained with our method to out-of-distribution camera viewpoints, we find that
they outperform baselines in both simulated and real-world manipulation tasks.
Videos and additional visualizations are available at
https://s-tian.github.io/projects/vista.

摘要：大規模視覺運動策略學習是一種很有前景的方法，用於開發可概括的操縱系統。然而，可以在不同的具體實施、環境和觀察方式中部署的策略仍然難以捉摸。在這項工作中，我們研究了來自世界的大規模視覺數據的知識如何用於解決可概括操縱的一個變異軸：觀察視點。具體來說，我們研究單圖像新視圖合成模型，該模型通過給定單個輸入圖像從備用相機視點渲染同一場景的圖像，學習具有 3D 感知能力的場景級先驗。對於對各種機器人數據的實際應用，這些模型必須進行零次學習，對未見任務和環境執行視圖合成。我們在一個簡單的數據擴充方案中對視圖合成模型進行經驗分析，我們稱之為視圖合成擴充 (VISTA)，以了解它們從單視點演示數據中學習視點不變策略的能力。在評估使用我們的視點外分佈相機視點訓練的策略的穩健性後，我們發現它們在模擬和真實世界操縱任務中都優於基準。視頻和其他視覺化效果可在 https://s-tian.github.io/projects/vista 上獲得。

##### **TRACE-cs: Trustworthy Reasoning for Contrastive Explanations in Course Scheduling Problems**
2409.03671v1 by Stylianos Loukas Vasileiou, William Yeoh

We present TRACE-cs, a novel hybrid system that combines symbolic reasoning
with large language models (LLMs) to address contrastive queries in scheduling
problems. TRACE-cs leverages SAT solving techniques to encode scheduling
constraints and generate explanations for user queries, while utilizing an LLM
to process the user queries into logical clauses as well as refine the
explanations generated by the symbolic solver to natural language sentences. By
integrating these components, our approach demonstrates the potential of
combining symbolic methods with LLMs to create explainable AI agents with
correctness guarantees.

摘要：我們提出 TRACE-cs，這是一個新穎的混合系統，它結合了符號推理和大型語言模型 (LLM)，以解決排程問題中的對比查詢。TRACE-cs 利用 SAT 求解技術來編碼排程約束並為使用者查詢產生解釋，同時利用 LLM 將使用者查詢處理成邏輯子句，並將符號求解器產生的解釋精煉成自然語言句子。透過整合這些元件，我們的做法展示了結合符號方法與 LLM 的潛力，以建立具有正確性保證的可解釋 AI 代理。

##### **A method to benchmark high-dimensional process drift detection**
2409.03669v1 by Edgar Wolf, Tobias Windisch

Process curves are multi-variate finite time series data coming from
manufacturing processes. This paper studies machine learning methods for drifts
of process curves. A theoretic framework to synthetically generate process
curves in a controlled way is introduced in order to benchmark machine learning
algorithms for process drift detection. A evaluation score, called the temporal
area under the curve, is introduced, which allows to quantify how well machine
learning models unveil curves belonging to drift segments. Finally, a benchmark
study comparing popular machine learning approaches on synthetic data generated
with the introduced framework shown.

摘要：製程曲線是來自製造製程的多變量有限時間序列資料。本文探討製程曲線偏移的機器學習方法。引進一個理論架構，以受控方式合成產生製程曲線，以基準機器學習演算法用於製程偏移偵測。引進一個評估分數，稱為曲線下的時間區域，用於量化機器學習模型揭露屬於偏移區段的曲線的程度。最後，一個基準研究比較了在以引進的架構產生的合成資料上流行的機器學習方法。

##### **A Fused Large Language Model for Predicting Startup Success**
2409.03668v1 by Abdurahman Maarouf, Stefan Feuerriegel, Nicolas Pröllochs

Investors are continuously seeking profitable investment opportunities in
startups and, hence, for effective decision-making, need to predict a startup's
probability of success. Nowadays, investors can use not only various
fundamental information about a startup (e.g., the age of the startup, the
number of founders, and the business sector) but also textual description of a
startup's innovation and business model, which is widely available through
online venture capital (VC) platforms such as Crunchbase. To support the
decision-making of investors, we develop a machine learning approach with the
aim of locating successful startups on VC platforms. Specifically, we develop,
train, and evaluate a tailored, fused large language model to predict startup
success. Thereby, we assess to what extent self-descriptions on VC platforms
are predictive of startup success. Using 20,172 online profiles from
Crunchbase, we find that our fused large language model can predict startup
success, with textual self-descriptions being responsible for a significant
part of the predictive power. Our work provides a decision support tool for
investors to find profitable investment opportunities.

摘要：<paragraph>投資者持續尋找新創公司的獲利投資機會，因此，為了做出有效的決策，需要預測新創公司的成功機率。現今，投資者不僅可以使用各種新創公司的基本資訊（例如，新創公司的年齡、創辦人數和產業別），還能使用新創公司創新和商業模式的文字說明，這些說明可透過 Crunchbase 等線上創投平台廣泛取得。為了協助投資者進行決策，我們開發了一種機器學習方法，目的是在創投平台上找出成功的公司。具體來說，我們開發、訓練和評估一個量身打造的融合式大型語言模型，以預測新創公司的成功。藉此，我們評估創投平台上的自我描述在多大程度上可以預測新創公司的成功。我們使用 Crunchbase 中的 20,172 個線上個人資料，發現我們的融合式大型語言模型可以預測新創公司的成功，而文字自我描述在預測能力中扮演了重要的角色。我們的研究為投資者提供了一個決策支援工具，以找出獲利的投資機會。</paragraph>

##### **The representation landscape of few-shot learning and fine-tuning in large language models**
2409.03662v1 by Diego Doimo, Alessandro Serra, Alessio Ansuini, Alberto Cazzaniga

In-context learning (ICL) and supervised fine-tuning (SFT) are two common
strategies for improving the performance of modern large language models (LLMs)
on specific tasks. Despite their different natures, these strategies often lead
to comparable performance gains. However, little is known about whether they
induce similar representations inside LLMs. We approach this problem by
analyzing the probability landscape of their hidden representations in the two
cases. More specifically, we compare how LLMs solve the same question-answering
task, finding that ICL and SFT create very different internal structures, in
both cases undergoing a sharp transition in the middle of the network. In the
first half of the network, ICL shapes interpretable representations
hierarchically organized according to their semantic content. In contrast, the
probability landscape obtained with SFT is fuzzier and semantically mixed. In
the second half of the model, the fine-tuned representations develop
probability modes that better encode the identity of answers, while the
landscape of ICL representations is characterized by less defined peaks. Our
approach reveals the diverse computational strategies developed inside LLMs to
solve the same task across different conditions, allowing us to make a step
towards designing optimal methods to extract information from language models.

摘要：文本内学习 (ICL) 和监督微调 (SFT) 是两种常见的策略，用于提升现代大型语言模型 (LLM) 在特定任务上的性能。尽管其本质不同，但这些策略通常会导致可比的性能提升。然而，对于它们是否会在 LLM 内诱发类似的表征，我们所知甚少。我们通过分析这两种情况下其隐藏表征的概率分布来解决这个问题。更具体地说，我们比较了 LLM 如何解决相同的问答任务，发现 ICL 和 SFT 创建了非常不同的内部结构，在这两种情况下，网络中间都经历了急剧的转变。在网络的前半部分，ICL 根据语义内容分层组织可解释的表征。相比之下，使用 SFT 获得的概率分布则更加模糊且语义混合。在模型的后半部分，微调后的表征发展出概率模式，更好地编码答案的身份，而 ICL 表征的分布则以不太明确的峰值为特征。我们的方法揭示了 LLM 内部开发的不同计算策略，以解决不同条件下的相同任务，使我们能够朝着设计从语言模型中提取信息的最优方法迈出一步。

##### **LLM-based multi-agent poetry generation in non-cooperative environments**
2409.03659v1 by Ran Zhang, Steffen Eger

Despite substantial progress of large language models (LLMs) for automatic
poetry generation, the generated poetry lacks diversity while the training
process differs greatly from human learning. Under the rationale that the
learning process of the poetry generation systems should be more human-like and
their output more diverse and novel, we introduce a framework based on social
learning where we emphasize non-cooperative interactions besides cooperative
interactions to encourage diversity. Our experiments are the first attempt at
LLM-based multi-agent systems in non-cooperative environments for poetry
generation employing both TRAINING-BASED agents (GPT-2) and PROMPTING-BASED
agents (GPT-3 and GPT-4). Our evaluation based on 96k generated poems shows
that our framework benefits the poetry generation process for TRAINING-BASED
agents resulting in 1) a 3.0-3.7 percentage point (pp) increase in diversity
and a 5.6-11.3 pp increase in novelty according to distinct and novel n-grams.
The generated poetry from TRAINING-BASED agents also exhibits group divergence
in terms of lexicons, styles and semantics. PROMPTING-BASED agents in our
framework also benefit from non-cooperative environments and a more diverse
ensemble of models with non-homogeneous agents has the potential to further
enhance diversity, with an increase of 7.0-17.5 pp according to our
experiments. However, PROMPTING-BASED agents show a decrease in lexical
diversity over time and do not exhibit the group-based divergence intended in
the social network. Our paper argues for a paradigm shift in creative tasks
such as automatic poetry generation to include social learning processes (via
LLM-based agent modeling) similar to human interaction.

摘要：<paragraph>儘管大型語言模型 (LLM) 在自動詩歌生成方面取得了顯著進展，但生成的詩歌缺乏多樣性，而訓練過程與人類學習有很大不同。基於詩歌生成系統的學習過程應更像人類，其輸出應更具多樣性和新穎性，我們引入了一個基於社會學習的框架，在其中我們強調非合作互動，除了合作互動以鼓勵多樣性。我們的實驗是 LLM 為基礎的多代理系統在非合作環境中生成詩歌的首次嘗試，採用基於訓練的代理（GPT-2）和基於提示的代理（GPT-3 和 GPT-4）。我們根據 96k 首生成的詩歌進行評估，顯示我們的框架有利於基於訓練的代理的詩歌生成過程，導致 1) 多樣性增加 3.0-3.7 個百分點 (pp)，根據不同的新穎 n-gram，新穎性增加 5.6-11.3 pp。基於訓練的代理所生成的詩歌在詞彙、風格和語義方面也表現出群體差異。我們框架中的基於提示的代理也受益於非合作環境，並且具有非同質代理的多樣化模型集合有可能進一步提高多樣性，根據我們的實驗，增加了 7.0-17.5 pp。然而，基於提示的代理會隨著時間推移而降低詞彙多樣性，並且不會表現出社交網路中預期的基於群體的差異。我們的論文主張在創造性任務（例如自動詩歌生成）中進行典範轉移，以納入類似於人類互動的社會學習過程（通過基於 LLM 的代理建模）。</paragraph>

##### **On the Limited Generalization Capability of the Implicit Reward Model Induced by Direct Preference Optimization**
2409.03650v1 by Yong Lin, Skyler Seto, Maartje ter Hoeve, Katherine Metcalf, Barry-John Theobald, Xuan Wang, Yizhe Zhang, Chen Huang, Tong Zhang

Reinforcement Learning from Human Feedback (RLHF) is an effective approach
for aligning language models to human preferences. Central to RLHF is learning
a reward function for scoring human preferences. Two main approaches for
learning a reward model are 1) training an EXplicit Reward Model (EXRM) as in
RLHF, and 2) using an implicit reward learned from preference data through
methods such as Direct Preference Optimization (DPO). Prior work has shown that
the implicit reward model of DPO (denoted as DPORM) can approximate an EXRM in
the limit. DPORM's effectiveness directly implies the optimality of the learned
policy, and also has practical implication for LLM alignment methods including
iterative DPO. However, it is unclear how well DPORM empirically matches the
performance of EXRM. This work studies the accuracy at distinguishing preferred
and rejected answers for both DPORM and EXRM. Our findings indicate that even
though DPORM fits the training dataset comparably, it generalizes less
effectively than EXRM, especially when the validation datasets contain
distribution shifts. Across five out-of-distribution settings, DPORM has a mean
drop in accuracy of 3% and a maximum drop of 7%. These findings highlight that
DPORM has limited generalization ability and substantiates the integration of
an explicit reward model in iterative DPO approaches.

摘要：人類回饋強化學習 (RLHF) 是一種有效的方法，可以將語言模型調整到人類偏好。RLHF 的核心是學習一個獎勵函數來評分人類偏好。學習獎勵模型的兩種主要方法為 1) 訓練一個明確獎勵模型 (EXRM)，如同 RLHF 中，2) 使用從偏好數據中學習到的隱含獎勵，透過直接偏好最佳化 (DPO) 等方法。先前的研究顯示，DPO 的隱含獎勵模型 (表示為 DPORM) 可在極限中近似 EXRM。DPORM 的效能直接暗示學習到的政策的最佳性，且對 LLM 調整方法（包括反覆 DPO）也有實際的意義。然而，尚不清楚 DPORM 在經驗上有多符合 EXRM 的效能。本研究探討區分 DPORM 和 EXRM 的偏好和拒絕答案的準確性。我們的發現顯示，儘管 DPORM 符合訓練資料集的程度相當，但其泛化效果不如 EXRM，特別是在驗證資料集包含分配轉移時。在五個非分配設定中，DPORM 的準確性平均下降 3%，最大下降 7%。這些發現強調 DPORM 的泛化能力有限，並證實了在反覆 DPO 方法中整合明確獎勵模型。

##### **Limited but consistent gains in adversarial robustness by co-training object recognition models with human EEG**
2409.03646v1 by Manshan Guo, Bhavin Choksi, Sari Sadiya, Alessandro T. Gifford, Martina G. Vilas, Radoslaw M. Cichy, Gemma Roig

In contrast to human vision, artificial neural networks (ANNs) remain
relatively susceptible to adversarial attacks. To address this vulnerability,
efforts have been made to transfer inductive bias from human brains to ANNs,
often by training the ANN representations to match their biological
counterparts. Previous works relied on brain data acquired in rodents or
primates using invasive techniques, from specific regions of the brain, under
non-natural conditions (anesthetized animals), and with stimulus datasets
lacking diversity and naturalness. In this work, we explored whether aligning
model representations to human EEG responses to a rich set of real-world images
increases robustness to ANNs. Specifically, we trained ResNet50-backbone models
on a dual task of classification and EEG prediction; and evaluated their EEG
prediction accuracy and robustness to adversarial attacks. We observed
significant correlation between the networks' EEG prediction accuracy, often
highest around 100 ms post stimulus onset, and their gains in adversarial
robustness. Although effect size was limited, effects were consistent across
different random initializations and robust for architectural variants. We
further teased apart the data from individual EEG channels and observed
strongest contribution from electrodes in the parieto-occipital regions. The
demonstrated utility of human EEG for such tasks opens up avenues for future
efforts that scale to larger datasets under diverse stimuli conditions with the
promise of stronger effects.

摘要：相較於人類視覺，人工神經網路 (ANN) 仍然
容易受到對抗攻擊。為了解決此弱點，
已致力於將歸納偏誤從人腦轉移到 ANN，
通常透過訓練 ANN 表徵以符合其生物
對應物。先前的研究依賴於在特定大腦區域中，使用侵入式技術在齧齒動物或靈長類動物中獲得的大腦資料，在非自然條件（麻醉動物）下，且刺激資料集缺乏多樣性和自然性。在這項研究中，我們探討了將模型表徵與人類 EEG 對應於豐富的真實世界影像集合，是否會增加 ANN 的穩健性。具體來說，我們在分類和 EEG 預測的雙重任務上訓練了 ResNet50 骨幹模型；並評估其 EEG 預測準確度和對抗攻擊的穩健性。我們觀察到網路的 EEG 預測準確度之間存在顯著相關性，通常在刺激開始後約 100 毫秒時最高，以及它們在對抗穩健性方面的增益。儘管效應量有限，但效應在不同的隨機初始化和架構變體中是一致的。我們進一步區分來自個別 EEG 通道的資料，並觀察到來自頂枕區域電極的最強貢獻。人類 EEG 在此類任務中展現的效用，為未來在不同刺激條件下擴展到更大資料集的努力開啟了道路，並有望產生更強大的效應。

##### **CDM: A Reliable Metric for Fair and Accurate Formula Recognition Evaluation**
2409.03643v1 by Bin Wang, Fan Wu, Linke Ouyang, Zhuangcheng Gu, Rui Zhang, Renqiu Xia, Bo Zhang, Conghui He

Formula recognition presents significant challenges due to the complicated
structure and varied notation of mathematical expressions. Despite continuous
advancements in formula recognition models, the evaluation metrics employed by
these models, such as BLEU and Edit Distance, still exhibit notable
limitations. They overlook the fact that the same formula has diverse
representations and is highly sensitive to the distribution of training data,
thereby causing the unfairness in formula recognition evaluation. To this end,
we propose a Character Detection Matching (CDM) metric, ensuring the evaluation
objectivity by designing a image-level rather than LaTex-level metric score.
Specifically, CDM renders both the model-predicted LaTeX and the ground-truth
LaTeX formulas into image-formatted formulas, then employs visual feature
extraction and localization techniques for precise character-level matching,
incorporating spatial position information. Such a spatially-aware and
character-matching method offers a more accurate and equitable evaluation
compared with previous BLEU and Edit Distance metrics that rely solely on
text-based character matching. Experimentally, we evaluated various formula
recognition models using CDM, BLEU, and ExpRate metrics. Their results
demonstrate that the CDM aligns more closely with human evaluation standards
and provides a fairer comparison across different models by eliminating
discrepancies caused by diverse formula representations.

摘要：公式辨識由於數學表達式的複雜結構和多樣符號，因此面臨重大挑戰。儘管公式辨識模型持續進步，這些模型所採用的評估指標，例如 BLEU 和編輯距離，仍存在顯著的限制。它們忽略了同一個公式有多種表示法，且對訓練資料的分配高度敏感，從而導致公式辨識評估的不公平性。為此，我們提出一個字元偵測比對 (CDM) 指標，透過設計一個影像層級而非 LaTex 層級的指標分數，確保評估的客觀性。具體而言，CDM 將模型預測的 LaTeX 和真實的 LaTeX 公式都轉換成影像格式的公式，然後採用視覺特徵萃取和定位技術進行精確的字元層級比對，並納入空間位置資訊。這種具有空間感知和字元比對的方法，與僅依賴於基於文字的字元比對的先前 BLEU 和編輯距離指標相比，提供了更準確和公平的評估。在實驗中，我們使用 CDM、BLEU 和 ExpRate 指標評估了各種公式辨識模型。其結果表明，CDM 與人類評估標準更為一致，並透過消除由不同公式表示法所造成的差異，提供了不同模型之間更公平的比較。

##### **Attend First, Consolidate Later: On the Importance of Attention in Different LLM Layers**
2409.03621v1 by Amit Ben Artzy, Roy Schwartz

In decoder-based LLMs, the representation of a given layer serves two
purposes: as input to the next layer during the computation of the current
token; and as input to the attention mechanism of future tokens. In this work,
we show that the importance of the latter role might be overestimated. To show
that, we start by manipulating the representations of previous tokens; e.g. by
replacing the hidden states at some layer k with random vectors. Our
experimenting with four LLMs and four tasks show that this operation often
leads to small to negligible drop in performance. Importantly, this happens if
the manipulation occurs in the top part of the model-k is in the final 30-50%
of the layers. In contrast, doing the same manipulation in earlier layers might
lead to chance level performance. We continue by switching the hidden state of
certain tokens with hidden states of other tokens from another prompt; e.g.,
replacing the word "Italy" with "France" in "What is the capital of Italy?". We
find that when applying this switch in the top 1/3 of the model, the model
ignores it (answering "Rome"). However if we apply it before, the model
conforms to the switch ("Paris"). Our results hint at a two stage process in
transformer-based LLMs: the first part gathers input from previous tokens,
while the second mainly processes that information internally.

摘要：在基於解碼器的 LLM 中，給定層的表示有兩個目的：作為當前代幣計算期間下一層的輸入；以及作為未來代幣的注意力機制的輸入。在這項工作中，我們表明後者的重要性可能被高估了。為了證明這一點，我們從操縱先前代幣的表示開始；例如，通過用隨機向量替換某些層 k 的隱藏狀態。我們對四個 LLM 和四個任務的實驗表明，此操作通常會導致性能下降很小或可以忽略不計。重要的是，如果操作發生在模型的頂部，則會發生這種情況——k 在最後 30-50% 的層中。相比之下，在較早的層中進行相同的操作可能會導致機會級別的性能。我們繼續將某些代幣的隱藏狀態與來自另一個提示的其他代幣的隱藏狀態進行切換；例如，在「義大利的首都是什麼？」中將「義大利」替換為「法國」。我們發現，當在模型的前 1/3 中應用此切換時，模型會忽略它（回答「羅馬」）。但是，如果我們在之前應用它，模型會符合切換（「巴黎」）。我們的結果暗示了基於Transformer的 LLM 中的兩階段過程：第一部分從先前的代幣收集輸入，而第二部分主要在內部處理該信息。

##### **100 instances is all you need: predicting the success of a new LLM on unseen data by testing on a few instances**
2409.03563v1 by Lorenzo Pacchiardi, Lucy G. Cheke, José Hernández-Orallo

Predicting the performance of LLMs on individual task instances is essential
to ensure their reliability in high-stakes applications. To do so, a
possibility is to evaluate the considered LLM on a set of task instances and
train an assessor to predict its performance based on features of the
instances. However, this approach requires evaluating each new LLM on a
sufficiently large set of task instances to train an assessor specific to it.
In this work, we leverage the evaluation results of previously tested LLMs to
reduce the number of evaluations required to predict the performance of a new
LLM. In practice, we propose to test the new LLM on a small set of reference
instances and train a generic assessor which predicts the performance of the
LLM on an instance based on the performance of the former on the reference set
and features of the instance of interest. We conduct empirical studies on
HELM-Lite and KindsOfReasoning, a collection of existing reasoning datasets
that we introduce, where we evaluate all instruction-fine-tuned OpenAI models
until the January 2024 version of GPT4. When predicting performance on
instances with the same distribution as those used to train the generic
assessor, we find this achieves performance comparable to the LLM-specific
assessors trained on the full set of instances. Additionally, we find that
randomly selecting the reference instances performs as well as some advanced
selection methods we tested. For out of distribution, however, no clear winner
emerges and the overall performance is worse, suggesting that the inherent
predictability of LLMs is low.

摘要：預測 LLM 在個別任務實例中的表現對於確保它們在高風險應用中的可靠性至關重要。為此，一種可能性是在一組任務實例上評估所考慮的 LLM，並訓練評估器根據實例的特徵來預測其表現。然而，這種方法需要在足夠大的任務實例集上評估每個新的 LLM，以訓練專門針對它的評估器。在這項工作中，我們利用先前測試的 LLM 的評估結果來減少預測新 LLM 的表現所需的評估次數。在實務上，我們建議在少量參考實例上測試新的 LLM，並訓練一個通用評估器，該評估器根據前者在參考集上的表現和感興趣實例的特徵來預測 LLM 在實例上的表現。我們對 HELM-Lite 和 KindsOfReasoning 進行實證研究，這是一個我們介紹的現有推理資料集集合，我們在其中評估所有微調 OpenAI 模型，直到 GPT4 的 2024 年 1 月版本。在預測與用於訓練通用評估器的那些具有相同分佈的實例上的表現時，我們發現這達到了與在全組實例上訓練的 LLM 專用評估器相當的表現。此外，我們發現隨機選擇參考實例的表現與我們測試的一些進階選擇方法一樣好。然而，對於分佈外，沒有明確的贏家出現，而且整體表現較差，這表明 LLM 的內在可預測性較低。

##### **DKDM: Data-Free Knowledge Distillation for Diffusion Models with Any Architecture**
2409.03550v1 by Qianlong Xiang, Miao Zhang, Yuzhang Shang, Jianlong Wu, Yan Yan, Liqiang Nie

Diffusion models (DMs) have demonstrated exceptional generative capabilities
across various areas, while they are hindered by slow inference speeds and high
computational demands during deployment. The most common way to accelerate DMs
involves reducing the number of denoising steps during generation, achieved
through faster sampling solvers or knowledge distillation (KD). In contrast to
prior approaches, we propose a novel method that transfers the capability of
large pretrained DMs to faster architectures. Specifically, we employ KD in a
distinct manner to compress DMs by distilling their generative ability into
more rapid variants. Furthermore, considering that the source data is either
unaccessible or too enormous to store for current generative models, we
introduce a new paradigm for their distillation without source data, termed
Data-Free Knowledge Distillation for Diffusion Models (DKDM). Generally, our
established DKDM framework comprises two main components: 1) a DKDM objective
that uses synthetic denoising data produced by pretrained DMs to optimize
faster DMs without source data, and 2) a dynamic iterative distillation method
that flexibly organizes the synthesis of denoising data, preventing it from
slowing down the optimization process as the generation is slow. To our
knowledge, this is the first attempt at using KD to distill DMs into any
architecture in a data-free manner. Importantly, our DKDM is orthogonal to most
existing acceleration methods, such as denoising step reduction, quantization
and pruning. Experiments show that our DKDM is capable of deriving 2x faster
DMs with performance remaining on par with the baseline. Notably, our DKDM
enables pretrained DMs to function as "datasets" for training new DMs.

摘要：擴散模型 (DM) 已在各種領域展現出卓越的生成能力，但它們在部署期間受到推理速度慢和高運算需求的阻礙。加速 DM 最常見的方法包括減少生成期間的去噪步驟數，透過更快速的取樣求解器或知識蒸餾 (KD) 來實現。與先前的做法不同，我們提出了一種新方法，將大型預訓練 DM 的能力轉移到更快的架構中。具體來說，我們以不同方式採用 KD，透過將其生成能力蒸餾到更快速的變體中來壓縮 DM。此外，考慮到原始資料對於當前生成模型來說無法存取或過於龐大，我們引入了在沒有原始資料的情況下進行蒸餾的新範例，稱為擴散模型的無資料知識蒸餾 (DKDM)。一般來說，我們建立的 DKDM 框架包含兩個主要組成部分：1) 一個 DKDM 目標，它使用預訓練 DM 產生的合成去噪資料，在沒有原始資料的情況下最佳化更快速的 DM，以及 2) 一個動態反覆蒸餾方法，它靈活地組織去噪資料的合成，防止它在生成速度慢時拖慢最佳化流程。據我們所知，這是第一次嘗試使用 KD 以無資料的方式將 DM 蒸餾到任何架構中。重要的是，我們的 DKDM 與大多數現有的加速方法正交，例如去噪步驟減少、量化和剪枝。實驗表明，我們的 DKDM 能夠衍生出速度快 2 倍的 DM，其效能仍與基線相當。值得注意的是，我們的 DKDM 使預訓練的 DM 能夠作為「資料集」，用於訓練新的 DM。

##### **Prediction Accuracy & Reliability: Classification and Object Localization under Distribution Shift**
2409.03543v1 by Fabian Diet, Moussa Kassem Sbeyti, Michelle Karg

Natural distribution shift causes a deterioration in the perception
performance of convolutional neural networks (CNNs). This comprehensive
analysis for real-world traffic data addresses: 1) investigating the effect of
natural distribution shift and weather augmentations on both detection quality
and confidence estimation, 2) evaluating model performance for both
classification and object localization, and 3) benchmarking two common
uncertainty quantification methods - Ensembles and different variants of
Monte-Carlo (MC) Dropout - under natural and close-to-natural distribution
shift. For this purpose, a novel dataset has been curated from publicly
available autonomous driving datasets. The in-distribution (ID) data is based
on cutouts of a single object, for which both class and bounding box
annotations are available. The six distribution-shift datasets cover adverse
weather scenarios, simulated rain and fog, corner cases, and
out-of-distribution data. A granular analysis of CNNs under distribution shift
allows to quantize the impact of different types of shifts on both, task
performance and confidence estimation: ConvNeXt-Tiny is more robust than
EfficientNet-B0; heavy rain degrades classification stronger than localization,
contrary to heavy fog; integrating MC-Dropout into selected layers only has the
potential to enhance task performance and confidence estimation, whereby the
identification of these layers depends on the type of distribution shift and
the considered task.

摘要：自然分布轉移會導致卷積神經網路 (CNN) 的感知效能下降。針對真實世界交通數據的這項全面分析探討了：1) 調查自然分布轉移和天氣增強對偵測品質和信心估計的影響，2) 評估模型效能，同時涵蓋分類和物件定位，以及 3) 在自然和接近自然的分布轉移下，對兩種常見的不確定性量化方法進行基準測試，分別為集成法和蒙地卡羅 (MC) Dropout 的不同變體。為此，已經從公開的自動駕駛數據集中策劃了一個新穎的數據集。分佈內 (ID) 資料是根據單一物件的切口建立，而該物件同時有類別和邊界框註解。六個分佈轉移數據集涵蓋了惡劣天氣情境、模擬雨和霧、臨界情況和分佈外資料。在分佈轉移下對 CNN 進行細緻分析，可以量化不同類型轉移對任務效能和信心估計的影響：ConvNeXt-Tiny 比 EfficientNet-B0 更強大；大雨比濃霧更嚴重地降低分類，這與濃霧相反；僅將 MC-Dropout 整合到選定的層中，就有可能提升任務效能和信心估計，而這些層的識別取決於分佈轉移的類型和考量的任務。

##### **LMLT: Low-to-high Multi-Level Vision Transformer for Image Super-Resolution**
2409.03516v1 by Jeongsoo Kim, Jongho Nang, Junsuk Choe

Recent Vision Transformer (ViT)-based methods for Image Super-Resolution have
demonstrated impressive performance. However, they suffer from significant
complexity, resulting in high inference times and memory usage. Additionally,
ViT models using Window Self-Attention (WSA) face challenges in processing
regions outside their windows. To address these issues, we propose the
Low-to-high Multi-Level Transformer (LMLT), which employs attention with
varying feature sizes for each head. LMLT divides image features along the
channel dimension, gradually reduces spatial size for lower heads, and applies
self-attention to each head. This approach effectively captures both local and
global information. By integrating the results from lower heads into higher
heads, LMLT overcomes the window boundary issues in self-attention. Extensive
experiments show that our model significantly reduces inference time and GPU
memory usage while maintaining or even surpassing the performance of
state-of-the-art ViT-based Image Super-Resolution methods. Our codes are
availiable at https://github.com/jwgdmkj/LMLT.

摘要：最近基于视觉转换器 (ViT) 的图像超分辨率方法已经证明了令人印象深刻的性能。然而，它们遭受着巨大的复杂性，导致较高的推理时间和内存使用。此外，使用窗口自注意力 (WSA) 的 ViT 模型在处理窗口外的区域时面临挑战。为了解决这些问题，我们提出了低到高的多级转换器 (LMLT)，它为每个头采用具有不同特征大小的注意力。LMLT 沿通道维度划分图像特征，逐渐减小较低头的空间大小，并对每个头应用自注意力。这种方法有效地捕获了局部和全局信息。通过将较低头的结果整合到较高头中，LMLT 克服了自注意力中的窗口边界问题。大量的实验表明，我们的模型显着减少了推理时间和 GPU 内存使用，同时保持或甚至超越了最先进的基于 ViT 的图像超分辨率方法的性能。我们的代码可在 https://github.com/jwgdmkj/LMLT 获得。

##### **From MOOC to MAIC: Reshaping Online Teaching and Learning through LLM-driven Agents**
2409.03512v1 by Jifan Yu, Zheyuan Zhang, Daniel Zhang-li, Shangqing Tu, Zhanxin Hao, Rui Miao Li, Haoxuan Li, Yuanchun Wang, Hanming Li, Linlu Gong, Jie Cao, Jiayin Lin, Jinchang Zhou, Fei Qin, Haohua Wang, Jianxiao Jiang, Lijun Deng, Yisi Zhan, Chaojun Xiao, Xusheng Dai, Xuan Yan, Nianyi Lin, Nan Zhang, Ruixin Ni, Yang Dang, Lei Hou, Yu Zhang, Xu Han, Manli Li, Juanzi Li, Zhiyuan Liu, Huiqin Liu, Maosong Sun

Since the first instances of online education, where courses were uploaded to
accessible and shared online platforms, this form of scaling the dissemination
of human knowledge to reach a broader audience has sparked extensive discussion
and widespread adoption. Recognizing that personalized learning still holds
significant potential for improvement, new AI technologies have been
continuously integrated into this learning format, resulting in a variety of
educational AI applications such as educational recommendation and intelligent
tutoring. The emergence of intelligence in large language models (LLMs) has
allowed for these educational enhancements to be built upon a unified
foundational model, enabling deeper integration. In this context, we propose
MAIC (Massive AI-empowered Course), a new form of online education that
leverages LLM-driven multi-agent systems to construct an AI-augmented
classroom, balancing scalability with adaptivity. Beyond exploring the
conceptual framework and technical innovations, we conduct preliminary
experiments at Tsinghua University, one of China's leading universities.
Drawing from over 100,000 learning records of more than 500 students, we obtain
a series of valuable observations and initial analyses. This project will
continue to evolve, ultimately aiming to establish a comprehensive open
platform that supports and unifies research, technology, and applications in
exploring the possibilities of online education in the era of large model AI.
We envision this platform as a collaborative hub, bringing together educators,
researchers, and innovators to collectively explore the future of AI-driven
online education.

摘要：<paragraph>自線上教育首次出現，課程上傳至可存取且共用的線上平台以來，這種擴展人類知識傳播以接觸更廣泛受眾的形式，已引發廣泛討論並被廣泛採用。認知到個人化學習仍具有顯著的改善潛力，新的 AI 技術已持續整合到這種學習格式中，產生了各種教育 AI 應用程式，例如教育建議和智慧型家教。大型語言模型 (LLM) 中出現的智慧，已允許這些教育增強功能建立在統一的基礎模型上，實現更深入的整合。在此背景下，我們提出 MAIC（大規模 AI 驅動課程），一種新的線上教育形式，利用 LLM 驅動的多重代理系統來建構 AI 增強型教室，在可擴充性與適應性之間取得平衡。除了探討概念架構和技術創新之外，我們還在中國頂尖大學之一的清華大學進行初步實驗。從 500 多名學生的 10 萬多筆學習記錄中，我們獲得一系列有價值的觀察和初步分析。此專案將持續演進，最終目標是建立一個全面的開放平台，支援並統一研究、技術和應用程式，以探索大型模型 AI 時代線上教育的可能性。我們將這個平台視為一個協作中心，匯集教育工作者、研究人員和創新者，共同探索 AI 驅動線上教育的未來。</paragraph>

##### **Improving Uncertainty-Error Correspondence in Deep Bayesian Medical Image Segmentation**
2409.03470v1 by Prerak Mody, Nicolas F. Chaves-de-Plaza, Chinmay Rao, Eleftheria Astrenidou, Mischa de Ridder, Nienke Hoekstra, Klaus Hildebrandt, Marius Staring

Increased usage of automated tools like deep learning in medical image
segmentation has alleviated the bottleneck of manual contouring. This has
shifted manual labour to quality assessment (QA) of automated contours which
involves detecting errors and correcting them. A potential solution to
semi-automated QA is to use deep Bayesian uncertainty to recommend potentially
erroneous regions, thus reducing time spent on error detection. Previous work
has investigated the correspondence between uncertainty and error, however, no
work has been done on improving the "utility" of Bayesian uncertainty maps such
that it is only present in inaccurate regions and not in the accurate ones. Our
work trains the FlipOut model with the Accuracy-vs-Uncertainty (AvU) loss which
promotes uncertainty to be present only in inaccurate regions. We apply this
method on datasets of two radiotherapy body sites, c.f. head-and-neck CT and
prostate MR scans. Uncertainty heatmaps (i.e. predictive entropy) are evaluated
against voxel inaccuracies using Receiver Operating Characteristic (ROC) and
Precision-Recall (PR) curves. Numerical results show that when compared to the
Bayesian baseline the proposed method successfully suppresses uncertainty for
accurate voxels, with similar presence of uncertainty for inaccurate voxels.
Code to reproduce experiments is available at
https://github.com/prerakmody/bayesuncertainty-error-correspondence

摘要：深度學習等自動化工具在醫學影像分割中使用率提升，減輕了手動輪廓描繪的瓶頸。這已將手動勞動轉移到自動輪廓的品質評估 (QA)，其中包含偵測錯誤並修正它們。半自動化 QA 的潛在解決方案是使用深度貝氏不確定性來建議潛在的錯誤區域，從而減少花費在錯誤偵測上的時間。先前的研究已調查不確定性和錯誤之間的對應關係，然而，尚未對改善貝氏不確定性地圖的「效用」進行研究，以使其僅出現在不準確區域，而不出現在準確區域。我們的研究使用準確度對抗不確定性 (AvU) 損失來訓練 FlipOut 模型，這會促使不確定性僅出現在不準確區域。我們將此方法應用於兩個放射治療部位的資料集，即頭頸部電腦斷層掃描和前列腺核磁共振掃描。使用接收器操作特性 (ROC) 和精確度召回率 (PR) 曲線，針對體素不準確性評估不確定性熱圖（即預測熵）。數值結果顯示，與貝氏基準相比，所提出的方法成功地抑制準確體素的不確定性，對於不準確體素的不確定性存在類似情況。可在 https://github.com/prerakmody/bayesuncertainty-error-correspondence 取得重現實驗的程式碼

##### **Characterizing Massive Activations of Attention Mechanism in Graph Neural Networks**
2409.03463v1 by Lorenzo Bini, Marco Sorbi, Stephane Marchand-Maillet

Graph Neural Networks (GNNs) have become increasingly popular for effectively
modeling data with graph structures. Recently, attention mechanisms have been
integrated into GNNs to improve their ability to capture complex patterns. This
paper presents the first comprehensive study revealing a critical, unexplored
consequence of this integration: the emergence of Massive Activations (MAs)
within attention layers. We introduce a novel method for detecting and
analyzing MAs, focusing on edge features in different graph transformer
architectures. Our study assesses various GNN models using benchmark datasets,
including ZINC, TOX21, and PROTEINS. Key contributions include (1) establishing
the direct link between attention mechanisms and MAs generation in GNNs, (2)
developing a robust definition and detection method for MAs based on activation
ratio distributions, (3) introducing the Explicit Bias Term (EBT) as a
potential countermeasure and exploring it as an adversarial framework to assess
models robustness based on the presence or absence of MAs. Our findings
highlight the prevalence and impact of attention-induced MAs across different
architectures, such as GraphTransformer, GraphiT, and SAN. The study reveals
the complex interplay between attention mechanisms, model architecture, dataset
characteristics, and MAs emergence, providing crucial insights for developing
more robust and reliable graph models.

摘要：圖形神經網路 (GNN) 已變得越來越受歡迎，可有效建模具有圖形結構的資料。最近，注意力機制已被整合到 GNN 中，以提升其擷取複雜模式的能力。本文提出第一個全面的研究，揭示了這種整合的一個關鍵、未探索的後果：注意力層中出現大量活化 (MA)。我們引入一種新的方法來偵測和分析 MA，重點放在不同圖形Transformer架構中的邊緣特徵。我們的研究使用基準資料集評估各種 GNN 模型，包括 ZINC、TOX21 和 PROTEINS。主要貢獻包括：(1) 建立注意力機制和 GNN 中 MA 產生的直接連結，(2) 根據活化率分佈開發一個穩健的定義和偵測 MA 的方法，(3) 引入顯式偏差項 (EBT) 作為一個潛在的對策，並將其作為一個對抗框架來探索模型的穩健性，根據 MA 的存在或不存在。我們的研究結果突顯了注意力誘導的 MA 在不同架構（例如 GraphTransformer、GraphiT 和 SAN）中的普遍性和影響。該研究揭示了注意力機制、模型架構、資料集特徵和 MA 出現之間的複雜交互作用，為開發更穩健、更可靠的圖形模型提供了重要的見解。

##### **How Much Data is Enough Data? Fine-Tuning Large Language Models for In-House Translation: Performance Evaluation Across Multiple Dataset Sizes**
2409.03454v1 by Inacio Vieira, Will Allred, Seamus Lankford, Sheila Castilho Monteiro De Sousa, Andy Way

Decoder-only LLMs have shown impressive performance in MT due to their
ability to learn from extensive datasets and generate high-quality
translations. However, LLMs often struggle with the nuances and style required
for organisation-specific translation. In this study, we explore the
effectiveness of fine-tuning Large Language Models (LLMs), particularly Llama 3
8B Instruct, leveraging translation memories (TMs), as a valuable resource to
enhance accuracy and efficiency. We investigate the impact of fine-tuning the
Llama 3 model using TMs from a specific organisation in the software sector.
Our experiments cover five translation directions across languages of varying
resource levels (English to Brazilian Portuguese, Czech, German, Finnish, and
Korean). We analyse diverse sizes of training datasets (1k to 207k segments) to
evaluate their influence on translation quality. We fine-tune separate models
for each training set and evaluate their performance based on automatic
metrics, BLEU, chrF++, TER, and COMET. Our findings reveal improvement in
translation performance with larger datasets across all metrics. On average,
BLEU and COMET scores increase by 13 and 25 points, respectively, on the
largest training set against the baseline model. Notably, there is a
performance deterioration in comparison with the baseline model when
fine-tuning on only 1k and 2k examples; however, we observe a substantial
improvement as the training dataset size increases. The study highlights the
potential of integrating TMs with LLMs to create bespoke translation models
tailored to the specific needs of businesses, thus enhancing translation
quality and reducing turn-around times. This approach offers a valuable insight
for organisations seeking to leverage TMs and LLMs for optimal translation
outcomes, especially in narrower domains.

摘要：<paragraph>僅解碼的 LLM 在機器翻譯中展現出令人驚豔的效能，因為它們能從廣泛的資料集學習，並產生高品質的翻譯。然而，LLM 通常難以處理組織特定翻譯所需的細微差別和風格。在此研究中，我們探討微調大型語言模型 (LLM) 的有效性，特別是 Llama 3 8B Instruct，利用翻譯記憶體 (TM) 作為有價值的資源，以提升準確度和效率。我們探討使用來自軟體部門特定組織的 TM 微調 Llama 3 模型的影響。我們的實驗涵蓋五種翻譯方向，橫跨不同資源層級的語言（英語到巴西葡萄牙語、捷克語、德語、芬蘭語和韓語）。我們分析不同大小的訓練資料集（1k 到 207k 段落），以評估其對翻譯品質的影響。我們針對每個訓練集微調不同的模型，並根據自動化指標（BLEU、chrF++、TER 和 COMET）評估其效能。我們的研究結果顯示，在所有指標中，隨著資料集的擴大，翻譯效能都有所提升。平均而言，在最大的訓練集上，與基準模型相比，BLEU 和 COMET 分數分別增加了 13 和 25 分。值得注意的是，當僅針對 1k 和 2k 個範例進行微調時，與基準模型相比，效能會下降；然而，我們觀察到隨著訓練資料集大小的增加，效能有顯著的提升。這項研究強調了將 TM 與 LLM 整合以建立客製化翻譯模型的潛力，這些模型專門針對企業的特定需求，從而提升翻譯品質並縮短週轉時間。此方法為尋求利用 TM 和 LLM 以獲得最佳翻譯成果的組織提供了有價值的見解，尤其是在較狹窄的領域中。</paragraph>

##### **Fine-tuning large language models for domain adaptation: Exploration of training strategies, scaling, model merging and synergistic capabilities**
2409.03444v1 by Wei Lu, Rachel K. Luu, Markus J. Buehler

The advancement of Large Language Models (LLMs) for domain applications in
fields such as materials science and engineering depends on the development of
fine-tuning strategies that adapt models for specialized, technical
capabilities. In this work, we explore the effects of Continued Pretraining
(CPT), Supervised Fine-Tuning (SFT), and various preference-based optimization
approaches, including Direct Preference Optimization (DPO) and Odds Ratio
Preference Optimization (ORPO), on fine-tuned LLM performance. Our analysis
shows how these strategies influence model outcomes and reveals that the
merging of multiple fine-tuned models can lead to the emergence of capabilities
that surpass the individual contributions of the parent models. We find that
model merging leads to new functionalities that neither parent model could
achieve alone, leading to improved performance in domain-specific assessments.
Experiments with different model architectures are presented, including Llama
3.1 8B and Mistral 7B models, where similar behaviors are observed. Exploring
whether the results hold also for much smaller models, we use a tiny LLM with
1.7 billion parameters and show that very small LLMs do not necessarily feature
emergent capabilities under model merging, suggesting that model scaling may be
a key component. In open-ended yet consistent chat conversations between a
human and AI models, our assessment reveals detailed insights into how
different model variants perform and show that the smallest model achieves a
high intelligence score across key criteria including reasoning depth,
creativity, clarity, and quantitative precision. Other experiments include the
development of image generation prompts based on disparate biological material
design concepts, to create new microstructures, architectural concepts, and
urban design based on biological materials-inspired construction principles.

摘要：大型語言模型 (LLM) 在材料科學和工程等領域的領域應用進步取決於微調策略的發展，這些策略可調整模型以適應專業的技術能力。在這項工作中，我們探討了持續預訓練 (CPT)、監督微調 (SFT) 和各種基於偏好的最佳化方法（包括直接偏好最佳化 (DPO) 和機率比偏好最佳化 (ORPO)）對微調後的 LLM 效能的影響。我們的分析顯示這些策略如何影響模型結果，並揭示多個微調模型的合併可能導致出現超越父模型個別貢獻的能力。我們發現模型合併導致新的功能，而任何父模型都無法單獨實現，從而提高特定領域評估的效能。我們展示了使用不同模型架構的實驗，包括 Llama 3.1 8B 和 Mistral 7B 模型，其中觀察到類似的行為。為了探討結果是否也適用於更小的模型，我們使用一個只有 17 億個參數的小型 LLM，並顯示非常小的 LLM 在模型合併下不一定具有浮現的能力，這表示模型縮放可能是關鍵組成部分。在人類和 AI 模型之間開放式但一致的聊天對話中，我們的評估揭示了不同模型變體的執行方式的詳細見解，並顯示最小的模型在包括推理深度、創造力、清晰度和定量精確度等關鍵標準中都獲得了很高的智力分數。其他實驗包括基於不同的生物材料設計概念開發圖像生成提示，以根據受生物材料啟發的建築原理建立新的微結構、建築概念和城市設計。

##### **Rx Strategist: Prescription Verification using LLM Agents System**
2409.03440v1 by Phuc Phan Van, Dat Nguyen Minh, An Dinh Ngoc, Huy Phan Thanh

To protect patient safety, modern pharmaceutical complexity demands strict
prescription verification. We offer a new approach - Rx Strategist - that makes
use of knowledge graphs and different search strategies to enhance the power of
Large Language Models (LLMs) inside an agentic framework. This multifaceted
technique allows for a multi-stage LLM pipeline and reliable information
retrieval from a custom-built active ingredient database. Different facets of
prescription verification, such as indication, dose, and possible drug
interactions, are covered in each stage of the pipeline. We alleviate the
drawbacks of monolithic LLM techniques by spreading reasoning over these
stages, improving correctness and reliability while reducing memory demands.
Our findings demonstrate that Rx Strategist surpasses many current LLMs,
achieving performance comparable to that of a highly experienced clinical
pharmacist. In the complicated world of modern medications, this combination of
LLMs with organized knowledge and sophisticated search methods presents a
viable avenue for reducing prescription errors and enhancing patient outcomes.

摘要：為了保護患者安全，現代藥品複雜性要求嚴格的處方驗證。我們提供一種新方法 - Rx Strategist - 它利用知識圖譜和不同的搜尋策略來增強代理架構內大型語言模型 (LLM) 的功能。這種多方面的技術允許多階段的 LLM 管線和從自訂主動成分資料庫中可靠地擷取資訊。處方驗證的不同面向，例如適應症、劑量和可能的藥物交互作用，都在管線的每個階段中涵蓋。我們透過將推理分散在這些階段來減輕單一 LLM 技術的缺點，同時提高正確性和可靠性，並減少記憶體需求。我們的研究結果表明，Rx Strategist 超越許多現有的 LLM，達到與經驗豐富的臨床藥劑師相當的表現。在現代藥物複雜的世界中，這種將 LLM 與有組織的知識和先進搜尋方法相結合，為減少處方錯誤和改善患者預後提供了可行的途徑。

##### **KiloBot: A Programming Language for Deploying Perception-Guided Industrial Manipulators at Scale**
2409.03439v1 by Wei Gao, Jingqiang Wang, Xinv Zhu, Jun Zhong, Yue Shen, Youshuang Ding

We would like industrial robots to handle unstructured environments with
cameras and perception pipelines. In contrast to traditional industrial robots
that replay offline-crafted trajectories, online behavior planning is required
for these perception-guided industrial applications. Aside from perception and
planning algorithms, deploying perception-guided manipulators also requires
substantial effort in integration. One approach is writing scripts in a
traditional language (such as Python) to construct the planning problem and
perform integration with other algorithmic modules & external devices. While
scripting in Python is feasible for a handful of robots and applications,
deploying perception-guided manipulation at scale (e.g., more than 10000 robot
workstations in over 2000 customer sites) becomes intractable. To resolve this
challenge, we propose a Domain-Specific Language (DSL) for perception-guided
manipulation applications. To scale up the deployment,our DSL provides: 1) an
easily accessible interface to construct & solve a sub-class of Task and Motion
Planning (TAMP) problems that are important in practical applications; and 2) a
mechanism to implement flexible control flow to perform integration and address
customized requirements of distinct industrial application. Combined with an
intuitive graphical programming frontend, our DSL is mainly used by machine
operators without coding experience in traditional programming languages.
Within hours of training, operators are capable of orchestrating interesting
sophisticated manipulation behaviors with our DSL. Extensive practical
deployments demonstrate the efficacy of our method.

摘要：我們希望工業機器人能透過相機和感知管道來處理非結構化環境。與傳統工業機器人重播離線製作的軌跡不同，這些感知導向的工業應用需要線上行為規劃。除了感知和規劃演算法外，部署感知導向的機械手還需要大量的整合工作。一種方法是用傳統語言（例如 Python）撰寫腳本，以建構規劃問題並與其他演算法模組和外部裝置進行整合。雖然用 Python 撰寫腳本對少數機器人和應用程式來說是可行的，但要大規模部署感知導向的機械手（例如，超過 2000 個客戶地點的 10000 個機器人工作站）就會變得難以處理。為了解決這個挑戰，我們提出了一個感知導向機械手應用程式的特定領域語言 (DSL)。為了擴大部署規模，我們的 DSL 提供：1) 一個易於存取的介面，用於建構和解決在實際應用中很重要的任務和動作規劃 (TAMP) 問題的子類別；以及 2) 一個實作彈性控制流程的機制，以執行整合並滿足不同工業應用程式的自訂需求。我們的 DSL 結合了一個直覺的圖形化程式設計前端，主要由沒有傳統程式語言編碼經驗的機器操作員使用。經過數小時的訓練，操作員就能用我們的 DSL 編排出有趣且複雜的機械手行為。廣泛的實際部署證明了我們方法的有效性。

##### **Reinforcement Learning Approach to Optimizing Profilometric Sensor Trajectories for Surface Inspection**
2409.03429v1 by Sara Roos-Hoefgeest, Mario Roos-Hoefgeest, Ignacio Alvarez, Rafael C. González

High-precision surface defect detection in manufacturing is essential for
ensuring quality control. Laser triangulation profilometric sensors are key to
this process, providing detailed and accurate surface measurements over a line.
To achieve a complete and precise surface scan, accurate relative motion
between the sensor and the workpiece is required. It is crucial to control the
sensor pose to maintain optimal distance and relative orientation to the
surface. It is also important to ensure uniform profile distribution throughout
the scanning process. This paper presents a novel Reinforcement Learning (RL)
based approach to optimize robot inspection trajectories for profilometric
sensors. Building upon the Boustrophedon scanning method, our technique
dynamically adjusts the sensor position and tilt to maintain optimal
orientation and distance from the surface, while also ensuring a consistent
profile distance for uniform and high-quality scanning. Utilizing a simulated
environment based on the CAD model of the part, we replicate real-world
scanning conditions, including sensor noise and surface irregularities. This
simulation-based approach enables offline trajectory planning based on CAD
models. Key contributions include the modeling of the state space, action
space, and reward function, specifically designed for inspection applications
using profilometric sensors. We use Proximal Policy Optimization (PPO)
algorithm to efficiently train the RL agent, demonstrating its capability to
optimize inspection trajectories with profilometric sensors. To validate our
approach, we conducted several experiments where a model trained on a specific
training piece was tested on various parts in simulation. Also, we conducted a
real-world experiment by executing the optimized trajectory, generated offline
from a CAD model, to inspect a part using a UR3e robotic arm model.

摘要：在製造業中，高精度的表面缺陷偵測對於確保品質管控至關重要。雷射三角測量輪廓儀感測器是此過程中關鍵的元件，能夠提供一條線上詳細且精確的表面測量。為了達成完整且精確的表面掃描，感測器和工件之間需要精確的相對運動。控制感測器姿勢以維持與表面之間最佳距離和相對方位至關重要。在整個掃描過程中確保均勻的輪廓分佈也很重要。本文提出了一種基於強化學習 (RL) 的新穎方法，用於優化輪廓儀感測器的機器人檢測軌跡。我們的技術建立在 Boustrophedon 掃描方法之上，可以動態調整感測器的位置和傾斜度，以維持與表面的最佳方位和距離，同時也確保一致的輪廓距離，以進行均勻且高品質的掃描。利用基於零件 CAD 模型的模擬環境，我們複製了真實世界的掃描條件，包括感測器雜訊和表面不規則性。這種基於模擬的方法能夠根據 CAD 模型進行離線軌跡規劃。主要的貢獻包括狀態空間、動作空間和獎勵函數的建模，這些函數專門設計用於使用輪廓儀感測器的檢測應用。我們使用近端策略最佳化 (PPO) 演算法來有效訓練 RL 代理，展示其優化使用輪廓儀感測器的檢測軌跡的能力。為了驗證我們的做法，我們進行了多項實驗，其中在模擬中對在特定訓練件上訓練的模型進行了各種零件測試。此外，我們還進行了一項真實世界的實驗，通過執行從 CAD 模型離線生成的最佳化軌跡，使用 UR3e 機器人手臂模型來檢測零件。

##### **Game On: Towards Language Models as RL Experimenters**
2409.03402v1 by Jingwei Zhang, Thomas Lampe, Abbas Abdolmaleki, Jost Tobias Springenberg, Martin Riedmiller

We propose an agent architecture that automates parts of the common
reinforcement learning experiment workflow, to enable automated mastery of
control domains for embodied agents. To do so, it leverages a VLM to perform
some of the capabilities normally required of a human experimenter, including
the monitoring and analysis of experiment progress, the proposition of new
tasks based on past successes and failures of the agent, decomposing tasks into
a sequence of subtasks (skills), and retrieval of the skill to execute -
enabling our system to build automated curricula for learning. We believe this
is one of the first proposals for a system that leverages a VLM throughout the
full experiment cycle of reinforcement learning. We provide a first prototype
of this system, and examine the feasibility of current models and techniques
for the desired level of automation. For this, we use a standard Gemini model,
without additional fine-tuning, to provide a curriculum of skills to a
language-conditioned Actor-Critic algorithm, in order to steer data collection
so as to aid learning new skills. Data collected in this way is shown to be
useful for learning and iteratively improving control policies in a robotics
domain. Additional examination of the ability of the system to build a growing
library of skills, and to judge the progress of the training of those skills,
also shows promising results, suggesting that the proposed architecture
provides a potential recipe for fully automated mastery of tasks and domains
for embodied agents.

摘要：我們提出了一種代理架構，該架構自動化了常見的強化學習實驗工作流程的部分，以實現對具身代理的控制領域的自動化掌握。為此，它利用 VLM 來執行通常人類實驗者所需的部分能力，包括監控和分析實驗進度、根據代理過去的成功和失敗提出新任務、將任務分解為一系列子任務（技能），以及檢索要執行的技能 - 使我們的系統能夠建立自動化的學習課程。我們相信這是第一個提出在強化學習的整個實驗週期中利用 VLM 的系統建議之一。我們提供了這個系統的第一個原型，並檢查了當前模型和技術對於所需自動化級別的可行性。為此，我們使用標準的 Gemini 模型，沒有額外的微調，為語言條件的 Actor-Critic 演算法提供技能課程，以便引導數據收集，以幫助學習新技能。以這種方式收集的數據被證明對於學習和反覆改進機器人領域的控制策略很有用。對系統構建不斷增長的技能庫以及判斷這些技能訓練進度的能力的進一步檢查也顯示出有希望的結果，表明所提出的架構為具身代理的任務和領域的完全自動化掌握提供了一個潛在的途徑。

##### **Hardware Acceleration of LLMs: A comprehensive survey and comparison**
2409.03384v1 by Nikoletta Koilia, Christoforos Kachris

Large Language Models (LLMs) have emerged as powerful tools for natural
language processing tasks, revolutionizing the field with their ability to
understand and generate human-like text. In this paper, we present a
comprehensive survey of the several research efforts that have been presented
for the acceleration of transformer networks for Large Language Models using
hardware accelerators.
  The survey presents the frameworks that have been proposed and then performs
a qualitative and quantitative comparison regarding the technology, the
processing platform (FPGA, ASIC, In-Memory, GPU), the speedup, the energy
efficiency, the performance (GOPs), and the energy efficiency (GOPs/W) of each
framework. The main challenge in comparison is that every proposed scheme is
implemented on a different process technology making hard a fair comparison.
The main contribution of this paper is that we extrapolate the results of the
performance and the energy efficiency on the same technology to make a fair
comparison; one theoretical and one more practical. We implement part of the
LLMs on several FPGA chips to extrapolate the results to the same process
technology and then we make a fair comparison of the performance.

摘要：大型語言模型 (LLM) 已成為自然語言處理任務的強大工具，它們能夠理解和生成類似人類的文字，因而徹底改變了這個領域。在本文中，我們對使用硬體加速器來加速大型語言模型的Transformer網路所提出的多項研究工作進行了全面的調查。
調查介紹了已提出的框架，然後對技術、處理平台 (FPGA、ASIC、In-Memory、GPU)、加速、能效、效能 (GOP) 和能效 (GOP/W) 進行定性和定量比較。比較中的主要挑戰在於，每項提出的方案都是在不同的製程技術上實作，這使得公平比較變得困難。本文的主要貢獻在於，我們將效能和能效的結果外推到相同的技術上，以進行公平的比較；一種是理論上的，一種是更實際的。我們在多個 FPGA 晶片上實作部分 LLM，以將結果外推到相同的製程技術，然後公平地比較效能。

##### **CogniDual Framework: Self-Training Large Language Models within a Dual-System Theoretical Framework for Improving Cognitive Tasks**
2409.03381v1 by Yongxin Deng, Xihe Qiu, Xiaoyu Tan, Chao Qu, Jing Pan, Yuan Cheng, Yinghui Xu, Wei Chu

Cognitive psychology investigates perception, attention, memory, language,
problem-solving, decision-making, and reasoning. Kahneman's dual-system theory
elucidates the human decision-making process, distinguishing between the rapid,
intuitive System 1 and the deliberative, rational System 2. Recent advancements
have positioned large language Models (LLMs) as formidable tools nearing
human-level proficiency in various cognitive tasks. Nonetheless, the presence
of a dual-system framework analogous to human cognition in LLMs remains
unexplored. This study introduces the \textbf{CogniDual Framework for LLMs}
(CFLLMs), designed to assess whether LLMs can, through self-training, evolve
from deliberate deduction to intuitive responses, thereby emulating the human
process of acquiring and mastering new information. Our findings reveal the
cognitive mechanisms behind LLMs' response generation, enhancing our
understanding of their capabilities in cognitive psychology. Practically,
self-trained models can provide faster responses to certain queries, reducing
computational demands during inference.

摘要：認知心理學研究知覺、注意力、記憶、語言、問題解決、決策和推理。卡尼曼的雙系統理論闡明了人類決策過程，區分了快速、直覺的系統 1 和深思熟慮、理性的系統 2。最近的進展已將大型語言模型 (LLM) 定位為強大的工具，在各種認知任務中接近人類水平的熟練度。儘管如此，在 LLM 中類似於人類認知的雙系統架構的存在仍未被探索。本研究介紹了 LLM 的 CogniDual 框架 (CFLLM)，旨在評估 LLM 是否能透過自我訓練，從深思熟慮的推論演變為直覺反應，從而模擬人類獲取和掌握新資訊的過程。我們的研究結果揭示了 LLM 回應產生的認知機制，增強了我們對其在認知心理學中的能力的理解。實際上，自我訓練的模型可以對某些查詢提供更快的回應，從而減少推理過程中的運算需求。

##### **Raw Speech Enhancement with Deep State Space Modeling**
2409.03377v1 by Yan Ru Pei, Ritik Shrivastava, FNU Sidharth

We present aTENNuate, a simple deep state-space autoencoder configured for
efficient online raw speech enhancement in an end-to-end fashion. The network's
performance is primarily evaluated on raw speech denoising, with additional
assessments on tasks such as super-resolution and de-quantization. We benchmark
aTENNuate on the VoiceBank + DEMAND and the Microsoft DNS1 synthetic test sets.
The network outperforms previous real-time denoising models in terms of PESQ
score, parameter count, MACs, and latency. Even as a raw waveform processing
model, the model maintains high fidelity to the clean signal with minimal
audible artifacts. In addition, the model remains performant even when the
noisy input is compressed down to 4000Hz and 4 bits, suggesting general speech
enhancement capabilities in low-resource environments.

摘要：我們提出 aTENNuate，一種簡單的深度狀態空間自動編碼器，以端到端的方式配置用於高效的線上原始語音增強。該網路的效能主要評估於原始語音去噪，並對超解析度和去量化等任務進行額外評估。我們在 VoiceBank + DEMAND 和 Microsoft DNS1 合成測試集中對 aTENNuate 進行基準測試。該網路在 PESQ 分數、參數數量、MAC 和延遲方面優於先前的即時去噪模型。即使作為原始波形處理模型，該模型也能以最小的可聽見的人工製品保持對乾淨訊號的高保真度。此外，即使將雜訊輸入壓縮到 4000Hz 和 4 位元，該模型仍保持效能，這表明在低資源環境中具備一般的語音增強能力。

##### **Leveraging Large Language Models through Natural Language Processing to provide interpretable Machine Learning predictions of mental deterioration in real time**
2409.03375v1 by Francisco de Arriba-Pérez, Silvia García-Méndez

Based on official estimates, 50 million people worldwide are affected by
dementia, and this number increases by 10 million new patients every year.
Without a cure, clinical prognostication and early intervention represent the
most effective ways to delay its progression. To this end, Artificial
Intelligence and computational linguistics can be exploited for natural
language analysis, personalized assessment, monitoring, and treatment. However,
traditional approaches need more semantic knowledge management and
explicability capabilities. Moreover, using Large Language Models (LLMs) for
cognitive decline diagnosis is still scarce, even though these models represent
the most advanced way for clinical-patient communication using intelligent
systems. Consequently, we leverage an LLM using the latest Natural Language
Processing (NLP) techniques in a chatbot solution to provide interpretable
Machine Learning prediction of cognitive decline in real-time.
Linguistic-conceptual features are exploited for appropriate natural language
analysis. Through explainability, we aim to fight potential biases of the
models and improve their potential to help clinical workers in their diagnosis
decisions. More in detail, the proposed pipeline is composed of (i) data
extraction employing NLP-based prompt engineering; (ii) stream-based data
processing including feature engineering, analysis, and selection; (iii)
real-time classification; and (iv) the explainability dashboard to provide
visual and natural language descriptions of the prediction outcome.
Classification results exceed 80 % in all evaluation metrics, with a recall
value for the mental deterioration class about 85 %. To sum up, we contribute
with an affordable, flexible, non-invasive, personalized diagnostic system to
this work.

摘要：<paragraph>根據官方的估計，全球約有 5000 萬人罹患失智症，且這個數字每年增加 1000 萬名新患者。在沒有治癒方法的情況下，臨床預後和早期介入是延緩其惡化的最有效方法。為此，人工智慧和計算語言學可被用於自然語言分析、個人化評估、監控和治療。然而，傳統方法需要更多語義知識管理和可解釋性能力。此外，儘管這些模型代表了使用智慧系統進行臨床患者溝通的最先進方式，但將大型語言模型 (LLM) 用於認知能力下降診斷仍然很少見。因此，我們利用聊天機器人解決方案中使用最新自然語言處理 (NLP) 技術的 LLM，以提供對認知能力下降的機器學習預測。語言概念特徵被用於適當的自然語言分析。透過可解釋性，我們旨在消除模型的潛在偏差，並提高其在診斷決策中協助臨床工作者的潛力。更詳細地說，所提出的管道包括：(i) 使用基於 NLP 的提示工程進行資料萃取；(ii) 串流式資料處理，包括特徵工程、分析和選擇；(iii) 即時分類；以及 (iv) 可解釋性儀表板，以提供預測結果的可視化和自然語言描述。分類結果在所有評估指標中都超過 80%，心智退化類別的召回率約為 85%。總而言之，我們為這項工作貢獻了一個經濟實惠、靈活、非侵入性、個人化的診斷系統。</paragraph>

##### **Con-ReCall: Detecting Pre-training Data in LLMs via Contrastive Decoding**
2409.03363v1 by Cheng Wang, Yiwei Wang, Bryan Hooi, Yujun Cai, Nanyun Peng, Kai-Wei Chang

The training data in large language models is key to their success, but it
also presents privacy and security risks, as it may contain sensitive
information. Detecting pre-training data is crucial for mitigating these
concerns. Existing methods typically analyze target text in isolation or solely
with non-member contexts, overlooking potential insights from simultaneously
considering both member and non-member contexts. While previous work suggested
that member contexts provide little information due to the minor distributional
shift they induce, our analysis reveals that these subtle shifts can be
effectively leveraged when contrasted with non-member contexts. In this paper,
we propose Con-ReCall, a novel approach that leverages the asymmetric
distributional shifts induced by member and non-member contexts through
contrastive decoding, amplifying subtle differences to enhance membership
inference. Extensive empirical evaluations demonstrate that Con-ReCall achieves
state-of-the-art performance on the WikiMIA benchmark and is robust against
various text manipulation techniques.

摘要：大型語言模型中的訓練資料是其成功的關鍵，但它也存在隱私和安全風險，因為它可能包含敏感資訊。偵測預訓練資料對於降低這些疑慮至關重要。現有方法通常孤立分析目標文字或僅使用非成員背景，忽略同時考慮成員和非成員背景的潛在見解。雖然先前的研究表明，由於成員背景會導致輕微的分配轉移，因此提供的信息很少，但我們的分析表明，當與非成員背景進行對比時，這些細微的轉移可以被有效利用。在本文中，我們提出 Con-ReCall，一種新穎的方法，它利用對比解碼來利用成員和非成員背景所引發的不對稱分配轉移，放大細微差異以增強成員推論。廣泛的實證評估表明，Con-ReCall 在 WikiMIA 基準上達到了最先進的效能，並且對於各種文字操作技術具有穩健性。

##### **Sketch: A Toolkit for Streamlining LLM Operations**
2409.03346v1 by Xin Jiang, Xiang Li, Wenjia Ma, Xuezhi Fang, Yiqun Yao, Naitong Yu, Xuying Meng, Peng Han, Jing Li, Aixin Sun, Yequan Wang

Large language models (LLMs) represented by GPT family have achieved
remarkable success. The characteristics of LLMs lie in their ability to
accommodate a wide range of tasks through a generative approach. However, the
flexibility of their output format poses challenges in controlling and
harnessing the model's outputs, thereby constraining the application of LLMs in
various domains. In this work, we present Sketch, an innovative toolkit
designed to streamline LLM operations across diverse fields. Sketch comprises
the following components: (1) a suite of task description schemas and prompt
templates encompassing various NLP tasks; (2) a user-friendly, interactive
process for building structured output LLM services tailored to various NLP
tasks; (3) an open-source dataset for output format control, along with tools
for dataset construction; and (4) an open-source model based on
LLaMA3-8B-Instruct that adeptly comprehends and adheres to output formatting
instructions. We anticipate this initiative to bring considerable convenience
to LLM users, achieving the goal of ''plug-and-play'' for various applications.
The components of Sketch will be progressively open-sourced at
https://github.com/cofe-ai/Sketch.

摘要：由 GPT 家族代表的大型語言模型 (LLM) 已取得顯著的成功。LLM 的特點在於它們能夠透過生成式方法來適應廣泛的任務。然而，它們的輸出格式靈活性在控制和利用模型輸出方面構成了挑戰，從而限制了 LLM 在各種領域中的應用。在這項工作中，我們展示了 Sketch，這是一個創新的工具包，旨在簡化 LLM 在不同領域中的操作。Sketch 包含以下組件：(1) 一套任務描述架構和提示範本，涵蓋各種 NLP 任務；(2) 一個友善、互動的流程，用於建立針對各種 NLP 任務量身打造的結構化輸出 LLM 服務；(3) 一個用於輸出格式控制的開源資料集，以及用於資料集建構的工具；(4) 一個基於 LLaMA3-8B-Instruct 的開源模型，它能靈活地理解並遵守輸出格式化指示。我們預期這個計畫將為 LLM 使用者帶來極大的便利性，實現各種應用程式的「即插即用」目標。Sketch 的組件將在 https://github.com/cofe-ai/Sketch 逐步開放原始碼。

##### **Normal forms in Virus Machines**
2409.03327v1 by A. Ramírez-de-Arellano, F. G. C. Cabarle, D. Orellana-Martín, M. J. Pérez-Jiménez

In the present work, we further study the computational power of virus
machines (VMs in short). VMs provide a computing paradigm inspired by the
transmission and replication networks of viruses. VMs consist of process units
(called hosts) structured by a directed graph whose arcs are called channels
and an instruction graph that controls the transmissions of virus objects among
hosts. The present work complements our understanding of the computing power of
VMs by introducing normal forms; these expressions restrict the features in a
given computing model. Some of the features that we restrict in our normal
forms include (a) the number of hosts, (b) the number of instructions, and (c)
the number of virus objects in each host. After we recall some known results on
the computing power of VMs we give our normal forms, such as the size of the
loops in the network, proving new characterisations of family of sets, such as
the finite sets, semilinear sets, or NRE.

摘要：在目前的工作中，我们进一步研究了病毒机器（简称 VM）的计算能力。VM 提供了一种受病毒传输和复制网络启发的计算范例。VM 由进程单元（称为主机）组成，这些进程单元由有向图构成，其弧称为通道，以及一个控制病毒对象在主机之间传输的指令图。本工作通过引入范式来补充我们对 VM 计算能力的理解；这些表达式限制了给定计算模型中的特征。我们在范式中限制的一些特征包括 (a) 主机数量，(b) 指令数量，以及 (c) 每个主机中的病毒对象数量。在我们回顾了有关 VM 计算能力的一些已知结果后，我们给出了我们的范式，例如网络中循环的大小，证明了集合族的新特征，例如有限集、半线性集或 NRE。

##### **N-gram Prediction and Word Difference Representations for Language Modeling**
2409.03295v1 by DongNyeong Heo, Daniela Noemi Rim, Heeyoul Choi

Causal language modeling (CLM) serves as the foundational framework
underpinning remarkable successes of recent large language models (LLMs).
Despite its success, the training approach for next word prediction poses a
potential risk of causing the model to overly focus on local dependencies
within a sentence. While prior studies have been introduced to predict future N
words simultaneously, they were primarily applied to tasks such as masked
language modeling (MLM) and neural machine translation (NMT). In this study, we
introduce a simple N-gram prediction framework for the CLM task. Moreover, we
introduce word difference representation (WDR) as a surrogate and
contextualized target representation during model training on the basis of
N-gram prediction framework. To further enhance the quality of next word
prediction, we propose an ensemble method that incorporates the future N words'
prediction results. Empirical evaluations across multiple benchmark datasets
encompassing CLM and NMT tasks demonstrate the significant advantages of our
proposed methods over the conventional CLM.

摘要：因果語言模型 (CLM) 構成了支撐近期大型語言模型 (LLM) 顯著成功之基礎架構。
儘管獲得成功，但下一個字詞預測的訓練方法存在潛在風險，可能會導致模型過度專注於句子內的局部依賴性。雖然先前研究已引入同時預測未來 N 個字詞，但主要應用於遮罩語言模型 (MLM) 和神經機器翻譯 (NMT) 等任務。在本研究中，我們為 CLM 任務引入了簡單的 N-gram 預測架構。此外，我們在基於 N-gram 預測架構的模型訓練期間，引入了字詞差異表徵 (WDR) 作為替代和脈絡化的目標表徵。為了進一步提升下一個字詞預測的品質，我們提出了一種整體方法，該方法納入了未來 N 個字詞的預測結果。跨越涵蓋 CLM 和 NMT 任務的多個基準資料集的經驗評估，證明了我們提出的方法相較於傳統 CLM 的顯著優勢。

##### **LLM Detectors Still Fall Short of Real World: Case of LLM-Generated Short News-Like Posts**
2409.03291v1 by Henrique Da Silva Gameiro, Andrei Kucharavy, Ljiljana Dolamic

With the emergence of widely available powerful LLMs, disinformation
generated by large Language Models (LLMs) has become a major concern.
Historically, LLM detectors have been touted as a solution, but their
effectiveness in the real world is still to be proven. In this paper, we focus
on an important setting in information operations -- short news-like posts
generated by moderately sophisticated attackers.
  We demonstrate that existing LLM detectors, whether zero-shot or
purpose-trained, are not ready for real-world use in that setting. All tested
zero-shot detectors perform inconsistently with prior benchmarks and are highly
vulnerable to sampling temperature increase, a trivial attack absent from
recent benchmarks. A purpose-trained detector generalizing across LLMs and
unseen attacks can be developed, but it fails to generalize to new
human-written texts.
  We argue that the former indicates domain-specific benchmarking is needed,
while the latter suggests a trade-off between the adversarial evasion
resilience and overfitting to the reference human text, with both needing
evaluation in benchmarks and currently absent. We believe this suggests a
re-consideration of current LLM detector benchmarking approaches and provides a
dynamically extensible benchmark to allow it
(https://github.com/Reliable-Information-Lab-HEVS/dynamic_llm_detector_benchmark).

摘要：隨著廣泛可用的強大 LLM 的出現，大型語言模型 (LLM) 產生的錯誤訊息已成為一個主要問題。
歷史上，LLM 偵測器被吹捧為一種解決方案，但它們在現實世界中的有效性仍有待證明。在本文中，我們專注於信息操作中的一個重要設定——由中等程度老練的攻擊者產生的類似新聞的短篇貼文。
我們證明了現有的 LLM 偵測器，無論是零次學習或專門訓練的，都還不適合在該設定中用於真實世界。所有經過測試的零次學習偵測器與先前的基準測試表現不一致，並且極易受到採樣溫度增加的影響，這是最近基準測試中沒有的微不足道攻擊。可以開發出一個針對 LLM 和未知攻擊進行概括的專門訓練偵測器，但它無法概括到新的由人類撰寫的文本。
我們認為前者表明需要特定領域的基準測試，而後者表明對抗性規避彈性和過度擬合參考人類文本之間存在權衡，兩者都需要在基準測試中進行評估，目前還沒有。我們相信這表明需要重新考慮當前 LLM 偵測器基準測試方法，並提供一個動態可擴充的基準測試來允許它（https://github.com/Reliable-Information-Lab-HEVS/dynamic_llm_detector_benchmark）。

##### **iText2KG: Incremental Knowledge Graphs Construction Using Large Language Models**
2409.03284v1 by Yassir Lairgi, Ludovic Moncla, Rémy Cazabet, Khalid Benabdeslem, Pierre Cléau

Most available data is unstructured, making it challenging to access valuable
information. Automatically building Knowledge Graphs (KGs) is crucial for
structuring data and making it accessible, allowing users to search for
information effectively. KGs also facilitate insights, inference, and
reasoning. Traditional NLP methods, such as named entity recognition and
relation extraction, are key in information retrieval but face limitations,
including the use of predefined entity types and the need for supervised
learning. Current research leverages large language models' capabilities, such
as zero- or few-shot learning. However, unresolved and semantically duplicated
entities and relations still pose challenges, leading to inconsistent graphs
and requiring extensive post-processing. Additionally, most approaches are
topic-dependent. In this paper, we propose iText2KG, a method for incremental,
topic-independent KG construction without post-processing. This plug-and-play,
zero-shot method is applicable across a wide range of KG construction scenarios
and comprises four modules: Document Distiller, Incremental Entity Extractor,
Incremental Relation Extractor, and Graph Integrator and Visualization. Our
method demonstrates superior performance compared to baseline methods across
three scenarios: converting scientific papers to graphs, websites to graphs,
and CVs to graphs.

摘要：大部分可用資料為非結構化，這使得存取有價值的資訊變得具有挑戰性。自動建立知識圖譜 (KG) 對於結構化資料和讓資料易於存取至關重要，讓使用者能夠有效地搜尋資訊。KG 也促進見解、推論和推理。傳統的 NLP 方法，例如命名實體辨識和關係萃取，在資訊檢索中是關鍵，但面臨限制，包括使用預定義的實體類型和需要監督式學習。目前的研究所利用大型語言模型的能力，例如零次或少次學習。然而，未解決和語義重複的實體和關係仍然構成挑戰，導致圖形不一致，需要廣泛的後處理。此外，大多數方法都依賴於主題。在本文中，我們提出 iText2KG，一種用於漸進式、與主題無關的 KG 建構方法，無需後處理。這種即插即用、零次的方法適用於廣泛的 KG 建構場景，並包含四個模組：文件精餾器、漸進式實體萃取器、漸進式關係萃取器，以及圖形整合器和視覺化器。與基線方法相比，我們的模型在三種場景中展現出卓越的效能：將科學論文轉換為圖形、網站轉換為圖形，以及履歷轉換為圖形。

##### **ChartMoE: Mixture of Expert Connector for Advanced Chart Understanding**
2409.03277v1 by Zhengzhuo Xu, Bowen Qu, Yiyan Qi, Sinan Du, Chengjin Xu, Chun Yuan, Jian Guo

Automatic chart understanding is crucial for content comprehension and
document parsing. Multimodal large language models (MLLMs) have demonstrated
remarkable capabilities in chart understanding through domain-specific
alignment and fine-tuning. However, the application of alignment training
within the chart domain is still underexplored. To address this, we propose
ChartMoE, which employs the mixture of expert (MoE) architecture to replace the
traditional linear projector to bridge the modality gap. Specifically, we train
multiple linear connectors through distinct alignment tasks, which are utilized
as the foundational initialization parameters for different experts.
Additionally, we introduce ChartMoE-Align, a dataset with over 900K
chart-table-JSON-code quadruples to conduct three alignment tasks
(chart-table/JSON/code). Combined with the vanilla connector, we initialize
different experts in four distinct ways and adopt high-quality knowledge
learning to further refine the MoE connector and LLM parameters. Extensive
experiments demonstrate the effectiveness of the MoE connector and our
initialization strategy, e.g., ChartMoE improves the accuracy of the previous
state-of-the-art from 80.48% to 84.64% on the ChartQA benchmark.

摘要：自動圖表理解對於內容理解和文件解析至關重要。多模態大型語言模型 (MLLM) 已透過特定領域的對齊和微調，在圖表理解中展現出非凡的能力。然而，對齊訓練在圖表領域的應用仍處於探索不足的階段。為了解決這個問題，我們提出了 ChartMoE，它採用專家混合 (MoE) 架構來取代傳統的線性投影，以彌合模態差距。具體來說，我們透過不同的對齊任務來訓練多個線性連接器，這些連接器被用作不同專家的基礎初始化參數。此外，我們引入了 ChartMoE-Align，這是一個包含超過 90 萬個圖表-表格-JSON-程式碼四元組的資料集，用於執行三項對齊任務（圖表-表格/JSON/程式碼）。結合香草連接器，我們以四種不同的方式初始化不同的專家，並採用高品質的知識學習來進一步優化 MoE 連接器和 LLM 參數。廣泛的實驗證明了 MoE 連接器和我們的初始化策略的有效性，例如，ChartMoE 將 ChartQA 基準上先前最先進的技術的準確度從 80.48% 提升到 84.64%。

##### **Recent Advances in Attack and Defense Approaches of Large Language Models**
2409.03274v1 by Jing Cui, Yishi Xu, Zhewei Huang, Shuchang Zhou, Jianbin Jiao, Junge Zhang

Large Language Models (LLMs) have revolutionized artificial intelligence and
machine learning through their advanced text processing and generating
capabilities. However, their widespread deployment has raised significant
safety and reliability concerns. Established vulnerabilities in deep neural
networks, coupled with emerging threat models, may compromise security
evaluations and create a false sense of security. Given the extensive research
in the field of LLM security, we believe that summarizing the current state of
affairs will help the research community better understand the present
landscape and inform future developments. This paper reviews current research
on LLM vulnerabilities and threats, and evaluates the effectiveness of
contemporary defense mechanisms. We analyze recent studies on attack vectors
and model weaknesses, providing insights into attack mechanisms and the
evolving threat landscape. We also examine current defense strategies,
highlighting their strengths and limitations. By contrasting advancements in
attack and defense methodologies, we identify research gaps and propose future
directions to enhance LLM security. Our goal is to advance the understanding of
LLM safety challenges and guide the development of more robust security
measures.

摘要：大型語言模型 (LLM) 透過其先進的文字處理和生成能力，徹底改變了人工智慧和機器學習。然而，它們的廣泛部署引起了重大的安全性和可靠性問題。深度神經網路中既定的漏洞，加上新興的威脅模型，可能會損害安全性評估並造成虛假的安全感。鑑於 LLM 安全領域的廣泛研究，我們相信總結當前狀態將有助於研究社群更深入了解目前的現況，並為未來的發展提供資訊。本文回顧了 LLM 漏洞和威脅的現有研究，並評估了當代防禦機制的有效性。我們分析了近期針對攻擊媒介和模型弱點的研究，深入探討了攻擊機制和不斷演變的威脅現況。我們也檢視了目前的防禦策略，強調其優點和限制。透過對比攻擊和防禦方法的進展，我們找出研究差距並提出未來的方向，以提升 LLM 的安全性。我們的目標是增進對 LLM 安全挑戰的理解，並引導更強大的安全措施的發展。

##### **Strategic Chain-of-Thought: Guiding Accurate Reasoning in LLMs through Strategy Elicitation**
2409.03271v1 by Yu Wang, Shiwan Zhao, Zhihu Wang, Heyuan Huang, Ming Fan, Yubo Zhang, Zhixing Wang, Haijun Wang, Ting Liu

The Chain-of-Thought (CoT) paradigm has emerged as a critical approach for
enhancing the reasoning capabilities of large language models (LLMs). However,
despite their widespread adoption and success, CoT methods often exhibit
instability due to their inability to consistently ensure the quality of
generated reasoning paths, leading to sub-optimal reasoning performance. To
address this challenge, we propose the \textbf{Strategic Chain-of-Thought}
(SCoT), a novel methodology designed to refine LLM performance by integrating
strategic knowledge prior to generating intermediate reasoning steps. SCoT
employs a two-stage approach within a single prompt: first eliciting an
effective problem-solving strategy, which is then used to guide the generation
of high-quality CoT paths and final answers. Our experiments across eight
challenging reasoning datasets demonstrate significant improvements, including
a 21.05\% increase on the GSM8K dataset and 24.13\% on the Tracking\_Objects
dataset, respectively, using the Llama3-8b model. Additionally, we extend the
SCoT framework to develop a few-shot method with automatically matched
demonstrations, yielding even stronger results. These findings underscore the
efficacy of SCoT, highlighting its potential to substantially enhance LLM
performance in complex reasoning tasks.

摘要：鏈條思考（CoT）範例已成為一種關鍵方法，用於增強大型語言模型（LLM）的推理能力。然而，儘管廣泛採用且成功，但 CoT 方法由於無法持續確保生成推理路徑的品質，因而經常出現不穩定的情況，導致次佳的推理表現。為了應對這個挑戰，我們提出**策略鏈條思考**（SCoT），這是一種新穎的方法，旨在透過在產生中間推理步驟之前整合策略知識來改善 LLM 表現。SCoT 在單一提示中採用兩階段方法：首先引發有效的問題解決策略，然後用於引導產生高品質的 CoT 路徑和最終答案。我們在八個具有挑戰性的推理資料集中的實驗證明了顯著的改善，包括在使用 Llama3-8b 模型的情況下，GSM8K 資料集增加了 21.05%，Tracking_Objects 資料集增加了 24.13%。此外，我們擴充 SCoT 架構來開發一種具備自動匹配示範的少次學習方法，產生更強大的結果。這些發現強調了 SCoT 的效能，突顯其在複雜推理任務中大幅增強 LLM 表現的潛力。

##### **Bones Can't Be Triangles: Accurate and Efficient Vertebrae Keypoint Estimation through Collaborative Error Revision**
2409.03261v1 by Jinhee Kim, Taesung Kim, Jaegul Choo

Recent advances in interactive keypoint estimation methods have enhanced
accuracy while minimizing user intervention. However, these methods require
user input for error correction, which can be costly in vertebrae keypoint
estimation where inaccurate keypoints are densely clustered or overlap. We
introduce a novel approach, KeyBot, specifically designed to identify and
correct significant and typical errors in existing models, akin to user
revision. By characterizing typical error types and using simulated errors for
training, KeyBot effectively corrects these errors and significantly reduces
user workload. Comprehensive quantitative and qualitative evaluations on three
public datasets confirm that KeyBot significantly outperforms existing methods,
achieving state-of-the-art performance in interactive vertebrae keypoint
estimation. The source code and demo video are available at:
https://ts-kim.github.io/KeyBot/

摘要：互動式關鍵點估計方法的最新進展提高了準確度，同時將使用者介入降到最低。然而，這些方法需要使用者輸入以進行錯誤修正，這在椎骨關鍵點估計中可能會很昂貴，其中不準確的關鍵點密集分佈或重疊。我們引入了一種新穎的方法 KeyBot，專門設計用於識別和修正現有模型中的顯著且典型的錯誤，類似於使用者修改。通過表徵典型的錯誤類型並使用模擬錯誤進行訓練，KeyBot 有效地修正了這些錯誤，並顯著減少了使用者的工作負擔。在三個公開數據集上進行的全面定量和定性評估證實，KeyBot 明顯優於現有方法，在互動式椎骨關鍵點估計中實現了最先進的效能。原始碼和示範影片可以在以下位置取得：https://ts-kim.github.io/KeyBot/

##### **In Search of Trees: Decision-Tree Policy Synthesis for Black-Box Systems via Search**
2409.03260v1 by Emir Demirović, Christian Schilling, Anna Lukina

Decision trees, owing to their interpretability, are attractive as control
policies for (dynamical) systems. Unfortunately, constructing, or synthesising,
such policies is a challenging task. Previous approaches do so by imitating a
neural-network policy, approximating a tabular policy obtained via formal
synthesis, employing reinforcement learning, or modelling the problem as a
mixed-integer linear program. However, these works may require access to a
hard-to-obtain accurate policy or a formal model of the environment (within
reach of formal synthesis), and may not provide guarantees on the quality or
size of the final tree policy. In contrast, we present an approach to
synthesise optimal decision-tree policies given a black-box environment and
specification, and a discretisation of the tree predicates, where optimality is
defined with respect to the number of steps to achieve the goal. Our approach
is a specialised search algorithm which systematically explores the
(exponentially large) space of decision trees under the given discretisation.
The key component is a novel pruning mechanism that significantly reduces the
search space. Our approach represents a conceptually novel way of synthesising
small decision-tree policies with optimality guarantees even for black-box
environments with black-box specifications.

摘要：決策樹由於其可解釋性，對於（動態）系統的控制策略而言很有吸引力。不幸的是，構建或綜合此類策略是一項具有挑戰性的任務。先前的做法是通過模仿神經網路策略、近似通過形式綜合獲得的表格策略、採用強化學習或將問題建模為混合整數線性規劃來實現的。然而，這些工作可能需要獲取難以獲得的準確策略或環境的正式模型（在形式綜合的範圍內），並且可能無法保證最終樹策略的質量或大小。相比之下，我們提出了一種在給定黑盒環境和規範以及樹謂詞離散化的情況下綜合最優決策樹策略的方法，其中最優性是根據實現目標的步驟數定義的。我們的做法是一種專門的搜尋演算法，它系統地探索給定離散化下的（指數級大的）決策樹空間。關鍵組成部分是一種新穎的剪枝機制，它顯著地減少了搜尋空間。我們的做法代表了一種概念上新穎的方式，即使對於具有黑盒規範的黑盒環境，也能綜合出具有最優性保證的小型決策樹策略。

##### **GraphInsight: Unlocking Insights in Large Language Models for Graph Structure Understanding**
2409.03258v1 by Yukun Cao, Shuo Han, Zengyi Gao, Zezhong Ding, Xike Xie, S. Kevin Zhou

Although Large Language Models (LLMs) have demonstrated potential in
processing graphs, they struggle with comprehending graphical structure
information through prompts of graph description sequences, especially as the
graph size increases. We attribute this challenge to the uneven memory
performance of LLMs across different positions in graph description sequences,
known as ''positional biases''. To address this, we propose GraphInsight, a
novel framework aimed at improving LLMs' comprehension of both macro- and
micro-level graphical information. GraphInsight is grounded in two key
strategies: 1) placing critical graphical information in positions where LLMs
exhibit stronger memory performance, and 2) investigating a lightweight
external knowledge base for regions with weaker memory performance, inspired by
retrieval-augmented generation (RAG). Moreover, GraphInsight explores
integrating these two strategies into LLM agent processes for composite graph
tasks that require multi-step reasoning. Extensive empirical studies on
benchmarks with a wide range of evaluation tasks show that GraphInsight
significantly outperforms all other graph description methods (e.g., prompting
techniques and reordering strategies) in understanding graph structures of
varying sizes.

摘要：儘管大型語言模型 (LLM) 已展現出處理圖形的能力，但它們在透過圖形描述序列提示理解圖形結構資訊時會遇到困難，特別是在圖形大小增加時。我們將此挑戰歸因於 LLM 在圖形描述序列中不同位置的記憶力表現不均，稱為「位置偏誤」。為了解決這個問題，我們提出了 GraphInsight，一個旨在改善 LLM 對巨觀和微觀層級圖形資訊理解的新框架。GraphInsight 以兩個關鍵策略為基礎：1) 將關鍵圖形資訊放置在 LLM 展現較強記憶力表現的位置，以及 2) 調查一個受到檢索增強生成 (RAG) 啟發的、針對記憶力表現較弱區域的輕量級外部知識庫。此外，GraphInsight 探索將這兩個策略整合到 LLM 代理程序中，以處理需要多步驟推理的複合圖形任務。在具有廣泛評量任務的基準上進行的廣泛實證研究顯示，GraphInsight 在理解各種大小的圖形結構方面，明顯優於所有其他圖形描述方法（例如提示技巧和重新排序策略）。

##### **Understanding LLM Development Through Longitudinal Study: Insights from the Open Ko-LLM Leaderboard**
2409.03257v1 by Chanjun Park, Hyeonwoo Kim

This paper conducts a longitudinal study over eleven months to address the
limitations of prior research on the Open Ko-LLM Leaderboard, which have relied
on empirical studies with restricted observation periods of only five months.
By extending the analysis duration, we aim to provide a more comprehensive
understanding of the progression in developing Korean large language models
(LLMs). Our study is guided by three primary research questions: (1) What are
the specific challenges in improving LLM performance across diverse tasks on
the Open Ko-LLM Leaderboard over time? (2) How does model size impact task
performance correlations across various benchmarks? (3) How have the patterns
in leaderboard rankings shifted over time on the Open Ko-LLM Leaderboard?. By
analyzing 1,769 models over this period, our research offers a comprehensive
examination of the ongoing advancements in LLMs and the evolving nature of
evaluation frameworks.

摘要：本論文進行為期 11 個月的縱向研究，以解決先前對 Open Ko-LLM 排行榜研究的限制，這些研究依賴於僅五個月的受限觀察期的經驗研究。透過延長分析期間，我們旨在提供對開發韓語大型語言模型 (LLM) 進展的更全面了解。我們的研究由三個主要的研究問題引導：(1) 隨著時間推移，在 Open Ko-LLM 排行榜上改善 LLM 在不同任務中的表現有哪些具體挑戰？(2) 模型大小如何影響不同基準測試中的任務表現相關性？(3) Open Ko-LLM 排行榜上的排行榜排名模式如何隨著時間推移而改變？透過在此期間分析 1,769 個模型，我們的研究提供了對 LLM 持續進展和評估架構演變性質的全面檢視。

##### **E2CL: Exploration-based Error Correction Learning for Embodied Agents**
2409.03256v1 by Hanlin Wang, Chak Tou Leong, Jian Wang, Wenjie Li

Language models are exhibiting increasing capability in knowledge utilization
and reasoning. However, when applied as agents in embodied environments, they
often suffer from misalignment between their intrinsic knowledge and
environmental knowledge, leading to infeasible actions. Traditional environment
alignment methods, such as supervised learning on expert trajectories and
reinforcement learning, face limitations in covering environmental knowledge
and achieving efficient convergence, respectively. Inspired by human learning,
we propose Exploration-based Error Correction Learning (E2CL), a novel
framework that leverages exploration-induced errors and environmental feedback
to enhance environment alignment for LM-based agents. E2CL incorporates
teacher-guided and teacher-free exploration to gather environmental feedback
and correct erroneous actions. The agent learns to provide feedback and
self-correct, thereby enhancing its adaptability to target environments.
Evaluations in the Virtualhome environment demonstrate that E2CL-trained agents
outperform those trained by baseline methods and exhibit superior
self-correction capabilities.

摘要：語言模型在知識利用和推理方面表現出越來越強的能力。然而，當它們作為具體環境中的代理時，它們通常會因為內在知識和環境知識之間的不一致而導致無法執行的動作。傳統的環境對齊方法，例如專家軌跡上的監督學習和強化學習，在涵蓋環境知識和實現有效收斂方面分別面臨限制。受人類學習的啟發，我們提出基於探索的錯誤修正學習 (E2CL)，這是一個新穎的框架，利用探索引起的錯誤和環境回饋來增強基於 LM 的代理的環境對齊。E2CL 結合了教師指導和無教師探索來收集環境回饋並修正錯誤動作。代理學習提供回饋並自我修正，從而增強其對目標環境的適應性。在 Virtualhome 環境中的評估表明，E2CL 訓練的代理優於基線方法訓練的代理，並表現出優越的自我修正能力。

##### **Granular-ball Representation Learning for Deep CNN on Learning with Label Noise**
2409.03254v1 by Dawei Dai, Hao Zhu, Shuyin Xia, Guoyin Wang

In actual scenarios, whether manually or automatically annotated, label noise
is inevitably generated in the training data, which can affect the
effectiveness of deep CNN models. The popular solutions require data cleaning
or designing additional optimizations to punish the data with mislabeled data,
thereby enhancing the robustness of models. However, these methods come at the
cost of weakening or even losing some data during the training process. As we
know, content is the inherent attribute of an image that does not change with
changes in annotations. In this study, we propose a general granular-ball
computing (GBC) module that can be embedded into a CNN model, where the
classifier finally predicts the label of granular-ball ($gb$) samples instead
of each individual samples. Specifically, considering the classification task:
(1) in forward process, we split the input samples as $gb$ samples at
feature-level, each of which can correspond to multiple samples with varying
numbers and share one single label; (2) during the backpropagation process, we
modify the gradient allocation strategy of the GBC module to enable it to
propagate normally; and (3) we develop an experience replay policy to ensure
the stability of the training process. Experiments demonstrate that the
proposed method can improve the robustness of CNN models with no additional
data or optimization.

摘要：在實際場景中，無論是手動還是自動標註，標籤雜訊都不可避免地會在訓練資料中產生，這會影響深度 CNN 模型的有效性。流行的解決方案需要資料清理或設計額外的最佳化來懲罰標籤錯誤的資料，從而增強模型的穩健性。然而，這些方法是以在訓練過程中削弱甚至丟失一些資料為代價的。正如我們所知，內容是影像的內在屬性，不會隨著標註的變化而改變。在這項研究中，我們提出了一個可以嵌入 CNN 模型的通用粒狀球計算 (GBC) 模組，其中分類器最終預測粒狀球 ($gb$) 樣本的標籤，而不是每個個別樣本的標籤。具體來說，考慮分類任務：(1) 在前向過程中，我們在特徵層級將輸入樣本分割為 $gb$ 樣本，每個樣本都可以對應到具有不同數量並共用一個標籤的多個樣本；(2) 在反向傳播過程中，我們修改 GBC 模組的梯度分配策略，使其能夠正常傳播；(3) 我們開發了一種經驗重播策略來確保訓練過程的穩定性。實驗表明，所提出的方法可以提高 CNN 模型的穩健性，而無需額外的資料或最佳化。

##### **Preserving Empirical Probabilities in BERT for Small-sample Clinical Entity Recognition**
2409.03238v1 by Abdul Rehman, Jian Jun Zhang, Xiaosong Yang

Named Entity Recognition (NER) encounters the challenge of unbalanced labels,
where certain entity types are overrepresented while others are
underrepresented in real-world datasets. This imbalance can lead to biased
models that perform poorly on minority entity classes, impeding accurate and
equitable entity recognition. This paper explores the effects of unbalanced
entity labels of the BERT-based pre-trained model. We analyze the different
mechanisms of loss calculation and loss propagation for the task of token
classification on randomized datasets. Then we propose ways to improve the
token classification for the highly imbalanced task of clinical entity
recognition.

摘要：命名實體辨識 (NER) 會遭遇標籤不平衡的挑戰，其中某些實體類型在真實世界資料集中被過度表示，而其他實體類型則被低估。這種不平衡可能導致有偏誤的模型，在少數實體類別上的表現不佳，阻礙準確且公平的實體辨識。本文探討 BERT 為基礎的預訓練模型的不平衡實體標籤的影響。我們分析了用於對隨機資料集進行標記分類任務的損失計算和損失傳播的不同機制。然後，我們提出改善臨床實體辨識高度不平衡任務的標記分類的方法。

##### **Enhancing Healthcare LLM Trust with Atypical Presentations Recalibration**
2409.03225v1 by Jeremy Qin, Bang Liu, Quoc Dinh Nguyen

Black-box large language models (LLMs) are increasingly deployed in various
environments, making it essential for these models to effectively convey their
confidence and uncertainty, especially in high-stakes settings. However, these
models often exhibit overconfidence, leading to potential risks and
misjudgments. Existing techniques for eliciting and calibrating LLM confidence
have primarily focused on general reasoning datasets, yielding only modest
improvements. Accurate calibration is crucial for informed decision-making and
preventing adverse outcomes but remains challenging due to the complexity and
variability of tasks these models perform. In this work, we investigate the
miscalibration behavior of black-box LLMs within the healthcare setting. We
propose a novel method, \textit{Atypical Presentations Recalibration}, which
leverages atypical presentations to adjust the model's confidence estimates.
Our approach significantly improves calibration, reducing calibration errors by
approximately 60\% on three medical question answering datasets and
outperforming existing methods such as vanilla verbalized confidence, CoT
verbalized confidence and others. Additionally, we provide an in-depth analysis
of the role of atypicality within the recalibration framework.

摘要：黑盒大型語言模型（LLM）正越來越多地部署在各種環境中，這使得這些模型有效傳達其信心和不確定性變得至關重要，尤其是在高風險環境中。然而，這些模型通常表現出過度自信，導致潛在風險和錯誤判斷。現有的用於引出和校準 LLM 信心的技術主要集中在一般推理數據集上，僅產生了適度的改進。準確的校準對於明智的決策制定和防止不良後果至關重要，但由於這些模型執行任務的複雜性和可變性，這仍然具有挑戰性。在這項工作中，我們研究了黑盒 LLM 在醫療保健環境中的校準錯誤行為。我們提出了一種新方法，“非典型表現重新校準”，它利用非典型表現來調整模型的信心估計。我們的做法顯著改進了校準，在三個醫療問題解答數據集上將校準誤差減少了大約 60%，並且優於現有方法，例如香草言語化信心、CoT 言語化信心等。此外，我們對重新校準框架內非典型性的作用進行了深入分析。

##### **Content Moderation by LLM: From Accuracy to Legitimacy**
2409.03219v1 by Tao Huang

One trending application of LLM (large language model) is to use it for
content moderation in online platforms. Most current studies on this
application have focused on the metric of accuracy - the extent to which LLM
makes correct decisions about content. This article argues that accuracy is
insufficient and misleading, because it fails to grasp the distinction between
easy cases and hard cases as well as the inevitable trade-offs in achieving
higher accuracy. Closer examination reveals that content moderation is a
constitutive part of platform governance, the key of which is to gain and
enhance legitimacy. Instead of making moderation decisions correct, the chief
goal of LLM is to make them legitimate. In this regard, this article proposes a
paradigm shift from the single benchmark of accuracy towards a legitimacy-based
framework of evaluating the performance of LLM moderators. The framework
suggests that for easy cases, the key is to ensure accuracy, speed and
transparency, while for hard cases, what matters is reasoned justification and
user participation. Examined under this framework, LLM's real potential in
moderation is not accuracy improvement. Rather, LLM can better contribute in
four other aspects: to conduct screening of hard cases from easy cases, to
provide quality explanations for moderation decisions, to assist human
reviewers in getting more contextual information, and to facilitate user
participation in a more interactive way. Using normative theories from law and
social sciences to critically assess the new technological application, this
article seeks to redefine LLM's role in content moderation and redirect
relevant research in this field.

摘要：大型語言模型（LLM）的一個熱門應用是將其用於線上平台的內容審核。目前大多數關於此應用的研究都專注於準確度指標，也就是 LLM 對內容做出正確決策的程度。這篇文章認為準確度是不足且具有誤導性的，因為它無法掌握簡單案例與困難案例之間的區別，以及在實現更高準確度時不可避免的權衡取捨。更仔細的檢視顯示，內容審核是平台治理的組成部分，其關鍵在於獲得並提升合法性。LLM 的主要目標並非做出正確的審核決策，而是讓決策合法化。有鑑於此，本文提出了一個典範轉移，從單一的準確度基準轉向以合法性為基礎的 LLM 審核員績效評估架構。該架構建議，對於簡單案例，關鍵在於確保準確度、速度和透明度，而對於困難案例，重要的是有理據的證明和使用者參與。在這個架構下檢視，LLM 在審核中的真正潛力並非準確度提升。相反地，LLM 可以透過以下四個方面做出更好的貢獻：從簡單案例中篩選出困難案例、為審核決策提供品質說明、協助人工審查員取得更多脈絡資訊，以及以更互動的方式促進使用者參與。本文使用法律和社會科學的規範理論來批判性地評估新的技術應用，試圖重新定義 LLM 在內容審核中的角色，並重新導向此領域相關的研究。

##### **xLAM: A Family of Large Action Models to Empower AI Agent Systems**
2409.03215v1 by Jianguo Zhang, Tian Lan, Ming Zhu, Zuxin Liu, Thai Hoang, Shirley Kokane, Weiran Yao, Juntao Tan, Akshara Prabhakar, Haolin Chen, Zhiwei Liu, Yihao Feng, Tulika Awalgaonkar, Rithesh Murthy, Eric Hu, Zeyuan Chen, Ran Xu, Juan Carlos Niebles, Shelby Heinecke, Huan Wang, Silvio Savarese, Caiming Xiong

Autonomous agents powered by large language models (LLMs) have attracted
significant research interest. However, the open-source community faces many
challenges in developing specialized models for agent tasks, driven by the
scarcity of high-quality agent datasets and the absence of standard protocols
in this area. We introduce and publicly release xLAM, a series of large action
models designed for AI agent tasks. The xLAM series includes five models with
both dense and mixture-of-expert architectures, ranging from 1B to 8x22B
parameters, trained using a scalable, flexible pipeline that unifies, augments,
and synthesizes diverse datasets to enhance AI agents' generalizability and
performance across varied environments. Our experimental results demonstrate
that xLAM consistently delivers exceptional performance across multiple agent
ability benchmarks, notably securing the 1st position on the Berkeley
Function-Calling Leaderboard, outperforming GPT-4, Claude-3, and many other
models in terms of tool use. By releasing the xLAM series, we aim to advance
the performance of open-source LLMs for autonomous AI agents, potentially
accelerating progress and democratizing access to high-performance models for
agent tasks. Models are available at
https://huggingface.co/collections/Salesforce/xlam-models-65f00e2a0a63bbcd1c2dade4

摘要：<paragraph>由大型語言模型（LLM）推動的自主代理已吸引了
顯著的研究興趣。然而，開源社群在開發專門用於代理任務的模型時面臨許多
挑戰，這是由於缺乏高品質的代理資料集和該領域缺乏標準協定的驅使。我們介紹並公開發布 xLAM，這是一系列專為 AI 代理任務設計的大型動作模型。xLAM 系列包括五個模型，具有密集和混合專家架構，範圍從 1B 到 8x22B 參數，使用可擴展、靈活的管道進行訓練，該管道統一、擴充和合成不同的資料集，以增強 AI 代理在各種環境中的泛化能力和效能。我們的實驗結果表明，xLAM 在多個代理能力基準中持續提供卓越的效能，特別是在 Berkeley 函式呼叫排行榜上獲得第 1 名，在工具使用方面優於 GPT-4、Claude-3 和許多其他模型。通過發布 xLAM 系列，我們旨在提升開源 LLM 在自主 AI 代理中的效能，這有可能加速進度並使代理任務的高效能模型的取得民主化。模型可於
https://huggingface.co/collections/Salesforce/xlam-models-65f00e2a0a63bbcd1c2dade4 取得</paragraph>

##### **TC-LLaVA: Rethinking the Transfer from Image to Video Understanding with Temporal Considerations**
2409.03206v1 by Mingze Gao, Jingyu Liu, Mingda Li, Jiangtao Xie, Qingbin Liu, Bo Zhao, Xi Chen, Hui Xiong

Multimodal Large Language Models (MLLMs) have significantly improved
performance across various image-language applications. Recently, there has
been a growing interest in adapting image pre-trained MLLMs for video-related
tasks. However, most efforts concentrate on enhancing the vision encoder and
projector components, while the core part, Large Language Models (LLMs),
remains comparatively under-explored. In this paper, we propose two strategies
to enhance the model's capability in video understanding tasks by improving
inter-layer attention computation in LLMs. Specifically, the first approach
focuses on the enhancement of Rotary Position Embedding (RoPE) with
Temporal-Aware Dual RoPE, which introduces temporal position information to
strengthen the MLLM's temporal modeling capabilities while preserving the
relative position relationships of both visual and text tokens. The second
approach involves enhancing the Attention Mask with the Frame-wise Block Causal
Attention Mask, a simple yet effective method that broadens visual token
interactions within and across video frames while maintaining the causal
inference mechanism. Based on these proposed methods, we adapt LLaVA for video
understanding tasks, naming it Temporal-Considered LLaVA (TC-LLaVA). Our
TC-LLaVA achieves new state-of-the-art performance across various video
understanding benchmarks with only supervised fine-tuning (SFT) on
video-related datasets.

摘要：多模态大语言模型 (MLLM) 已显著提升各种图像语言应用程序的性能。最近，人们对将图像预训练 MLLM 调整用于与视频相关的任务越来越感兴趣。然而，大多数工作都集中在增强视觉编码器和投影机组件上，而核心部分大语言模型 (LLM) 仍相对缺乏探索。在本文中，我们提出了两种策略来增强模型在视频理解任务中的能力，方法是改进 LLM 中的层间注意力计算。具体来说，第一种方法专注于使用时间感知双 RoPE 增强旋转位置嵌入 (RoPE)，它引入了时间位置信息来增强 MLLM 的时间建模能力，同时保留视觉标记和文本标记的相对位置关系。第二种方法涉及使用帧级块因果注意力掩码增强注意力掩码，这是一种简单但有效的方法，它拓宽了视频帧内和帧间视觉标记的交互，同时保持因果推理机制。基于这些提出的方法，我们调整 LLaVA 用于视频理解任务，并将其命名为时间考虑 LLaVA (TC-LLaVA)。我们的 TC-LLaVA 在各种视频理解基准上实现了新的最先进性能，仅在与视频相关的数据集上进行监督微调 (SFT)。

##### **An Effective Deployment of Diffusion LM for Data Augmentation in Low-Resource Sentiment Classification**
2409.03203v1 by Zhuowei Chen, Lianxi Wang, Yuben Wu, Xinfeng Liao, Yujia Tian, Junyang Zhong

Sentiment classification (SC) often suffers from low-resource challenges such
as domain-specific contexts, imbalanced label distributions, and few-shot
scenarios. The potential of the diffusion language model (LM) for textual data
augmentation (DA) remains unexplored, moreover, textual DA methods struggle to
balance the diversity and consistency of new samples. Most DA methods either
perform logical modifications or rephrase less important tokens in the original
sequence with the language model. In the context of SC, strong emotional tokens
could act critically on the sentiment of the whole sequence. Therefore,
contrary to rephrasing less important context, we propose DiffusionCLS to
leverage a diffusion LM to capture in-domain knowledge and generate pseudo
samples by reconstructing strong label-related tokens. This approach ensures a
balance between consistency and diversity, avoiding the introduction of noise
and augmenting crucial features of datasets. DiffusionCLS also comprises a
Noise-Resistant Training objective to help the model generalize. Experiments
demonstrate the effectiveness of our method in various low-resource scenarios
including domain-specific and domain-general problems. Ablation studies confirm
the effectiveness of our framework's modules, and visualization studies
highlight optimal deployment conditions, reinforcing our conclusions.

摘要：情緒分類（SC）通常會面臨低資源挑戰，例如特定網域脈絡、標籤分佈不平衡及少樣本情境。擴散語言模型（LM）在文字資料擴充（DA）的潛力仍未被探索，此外，文字 DA 方法難以平衡新樣本的多樣性和一致性。大多數 DA 方法會對原始序列中較不重要的標記進行邏輯修改或重新表述，並使用語言模型。在 SC 的脈絡中，強烈的情緒標記可能會對整個序列的情緒產生關鍵影響。因此，與重新表述較不重要的脈絡相反，我們提出 DiffusionCLS，以利用擴散 LM 來擷取網域內知識，並透過重建與標籤相關的強標記來產生偽樣本。此方法可確保一致性和多樣性之間的平衡，避免引入雜訊並擴充資料集的關鍵特徵。DiffusionCLS 也包含一個抗雜訊訓練目標，以幫助模型進行概化。實驗證明了我們的方法在各種低資源情境中的有效性，包括特定網域和一般網域問題。消融研究證實了我們架構模組的有效性，而視覺化研究則突顯了最佳部署條件，強化了我們的結論。

##### **Bypassing DARCY Defense: Indistinguishable Universal Adversarial Triggers**
2409.03183v1 by Zuquan Peng, Yuanyuan He, Jianbing Ni, Ben Niu

Neural networks (NN) classification models for Natural Language Processing
(NLP) are vulnerable to the Universal Adversarial Triggers (UAT) attack that
triggers a model to produce a specific prediction for any input. DARCY borrows
the "honeypot" concept to bait multiple trapdoors, effectively detecting the
adversarial examples generated by UAT. Unfortunately, we find a new UAT
generation method, called IndisUAT, which produces triggers (i.e., tokens) and
uses them to craft adversarial examples whose feature distribution is
indistinguishable from that of the benign examples in a randomly-chosen
category at the detection layer of DARCY. The produced adversarial examples
incur the maximal loss of predicting results in the DARCY-protected models.
Meanwhile, the produced triggers are effective in black-box models for text
generation, text inference, and reading comprehension. Finally, the evaluation
results under NN models for NLP tasks indicate that the IndisUAT method can
effectively circumvent DARCY and penetrate other defenses. For example,
IndisUAT can reduce the true positive rate of DARCY's detection by at least
40.8% and 90.6%, and drop the accuracy by at least 33.3% and 51.6% in the RNN
and CNN models, respectively. IndisUAT reduces the accuracy of the BERT's
adversarial defense model by at least 34.0%, and makes the GPT-2 language model
spew racist outputs even when conditioned on non-racial context.

摘要：神經網路 (NN) 自然語言處理 (NLP) 分類模型容易受到通用對抗性觸發器 (UAT) 攻擊，此攻擊會觸發模型對任何輸入產生特定預測。DARCY 借用「誘捕」概念來誘導多個陷阱門，有效偵測 UAT 所產生的對抗性範例。不幸的是，我們發現一種新的 UAT 產生方法，稱為 IndisUAT，它會產生觸發器（即符號），並使用它們來製作對抗性範例，其特徵分佈與 DARCY 偵測層中隨機選擇類別中的良性範例無法區分。產生的對抗性範例會導致 DARCY 受保護模型中預測結果的最大損失。同時，產生的觸發器在文本產生、文本推論和閱讀理解的黑盒模型中是有效的。最後，NLP 任務的 NN 模型下的評估結果表明，IndisUAT 方法可以有效規避 DARCY 並滲透其他防禦措施。例如，IndisUAT 可以將 DARCY 偵測的真正陽性率至少降低 40.8% 和 90.6%，並分別使 RNN 和 CNN 模型的準確度至少降低 33.3% 和 51.6%。IndisUAT 將 BERT 對抗防禦模型的準確度降低了至少 34.0%，並讓 GPT-2 語言模型即使在非種族背景下也會產生種族主義輸出。

##### **MARAGS: A Multi-Adapter System for Multi-Task Retrieval Augmented Generation Question Answering**
2409.03171v1 by Mitchell DeHaven

In this paper we present a multi-adapter retrieval augmented generation
system (MARAGS) for Meta's Comprehensive RAG (CRAG) competition for KDD CUP
2024. CRAG is a question answering dataset contains 3 different subtasks aimed
at realistic question and answering RAG related tasks, with a diverse set of
question topics, question types, time dynamic answers, and questions featuring
entities of varying popularity.
  Our system follows a standard setup for web based RAG, which uses processed
web pages to provide context for an LLM to produce generations, while also
querying API endpoints for additional information. MARAGS also utilizes
multiple different adapters to solve the various requirements for these tasks
with a standard cross-encoder model for ranking candidate passages relevant for
answering the question. Our system achieved 2nd place for Task 1 as well as 3rd
place on Task 2.

摘要：在本文中，我們提出了一個多適配器檢索增強生成系統 (MARAGS)，用於 Meta 的綜合 RAG (CRAG) 競賽，以參加 2024 年 KDD CUP。CRAG 是一個問答資料集，包含 3 個不同的子任務，旨在實現與 RAG 相關的現實問題和回答任務，其中包含各種問題主題、問題類型、時間動態答案，以及具有不同熱門程度實體的問題。
我們的系統遵循基於 Web 的 RAG 的標準設置，它使用處理過的網頁為 LLM 提供上下文以產生生成，同時也查詢 API 端點以獲取額外資訊。MARAGS 還利用多個不同的適配器來解決這些任務的各種需求，並使用標準交叉編碼器模型對與回答問題相關的候選段落進行排名。我們的系統在任務 1 中獲得第二名，在任務 2 中獲得第三名。

##### **InfraLib: Enabling Reinforcement Learning and Decision Making for Large Scale Infrastructure Management**
2409.03167v1 by Pranay Thangeda, Trevor S. Betz, Michael N. Grussing, Melkior Ornik

Efficient management of infrastructure systems is crucial for economic
stability, sustainability, and public safety. However, infrastructure
management is challenging due to the vast scale of systems, stochastic
deterioration of components, partial observability, and resource constraints.
While data-driven approaches like reinforcement learning (RL) offer a promising
avenue for optimizing management policies, their application to infrastructure
has been limited by the lack of suitable simulation environments. We introduce
InfraLib, a comprehensive framework for modeling and analyzing infrastructure
management problems. InfraLib employs a hierarchical, stochastic approach to
realistically model infrastructure systems and their deterioration. It supports
practical functionality such as modeling component unavailability, cyclical
budgets, and catastrophic failures. To facilitate research, InfraLib provides
tools for expert data collection, simulation-driven analysis, and
visualization. We demonstrate InfraLib's capabilities through case studies on a
real-world road network and a synthetic benchmark with 100,000 components.

摘要：基礎建設系統的有效管理對於經濟穩定、永續性和公共安全至關重要。然而，由於系統規模龐大、組成元件隨機老化、部分可觀察性和資源限制，基礎建設管理面臨挑戰。儘管資料驅動方法（如強化學習 (RL)）為最佳化管理政策提供了有希望的途徑，但其在基礎建設中的應用受到合適模擬環境缺乏的限制。我們推出 InfraLib，一個用於建模和分析基礎建設管理問題的綜合架構。InfraLib 採用階層式、隨機方法，以實際方式建模基礎建設系統及其老化情況。它支援實用功能，例如建模組件不可用性、循環預算和災難性故障。為了促進研究，InfraLib 提供專家資料收集、模擬驅動分析和視覺化的工具。我們透過真實道路網路和具有 100,000 個組件的合成基準的案例研究，展示 InfraLib 的功能。

##### **Continual Skill and Task Learning via Dialogue**
2409.03166v1 by Weiwei Gu, Suresh Kondepudi, Lixiao Huang, Nakul Gopalan

Continual and interactive robot learning is a challenging problem as the
robot is present with human users who expect the robot to learn novel skills to
solve novel tasks perpetually with sample efficiency. In this work we present a
framework for robots to query and learn visuo-motor robot skills and task
relevant information via natural language dialog interactions with human users.
Previous approaches either focus on improving the performance of instruction
following agents, or passively learn novel skills or concepts. Instead, we used
dialog combined with a language-skill grounding embedding to query or confirm
skills and/or tasks requested by a user. To achieve this goal, we developed and
integrated three different components for our agent. Firstly, we propose a
novel visual-motor control policy ACT with Low Rank Adaptation (ACT-LoRA),
which enables the existing SoTA ACT model to perform few-shot continual
learning. Secondly, we develop an alignment model that projects demonstrations
across skill embodiments into a shared embedding allowing us to know when to
ask questions and/or demonstrations from users. Finally, we integrated an
existing LLM to interact with a human user to perform grounded interactive
continual skill learning to solve a task. Our ACT-LoRA model learns novel
fine-tuned skills with a 100% accuracy when trained with only five
demonstrations for a novel skill while still maintaining a 74.75% accuracy on
pre-trained skills in the RLBench dataset where other models fall significantly
short. We also performed a human-subjects study with 8 subjects to demonstrate
the continual learning capabilities of our combined framework. We achieve a
success rate of 75% in the task of sandwich making with the real robot learning
from participant data demonstrating that robots can learn novel skills or task
knowledge from dialogue with non-expert users using our approach.

摘要：持續且互動的機器人學習是一個具有挑戰性的問題，因為機器人與人類使用者同時存在，而人類使用者期望機器人能夠學習新技能，以持續解決新任務，並具有範例效率。在這項工作中，我們提出一個架構，讓機器人透過與人類使用者進行自然語言對話互動，來查詢和學習視覺運動機器人技能和任務相關資訊。先前的做法不是專注於改善指令遵循代理人的效能，就是被動地學習新技能或概念。相反地，我們使用對話結合語言技能基礎嵌入，來查詢或確認使用者要求的技能和/或任務。為了達成這個目標，我們為我們的代理人開發並整合了三個不同的元件。首先，我們提出一個新的視覺運動控制策略 ACT，具有低秩適應 (ACT-LoRA)，這讓現有的 SoTA ACT 模型能夠執行小樣本持續學習。其次，我們開發一個比對模型，將不同技能具體實例中的示範投射到一個共用嵌入中，讓我們知道何時向使用者詢問問題和/或示範。最後，我們整合了一個現有的 LLM，與人類使用者互動，以執行基礎互動式持續技能學習，來解決一個任務。我們的 ACT-LoRA 模型在僅使用五個示範訓練新技能時，就能學習到新的微調技能，準確率達到 100%，同時在 RLBench 資料集中預先訓練的技能上仍能維持 74.75% 的準確率，而其他模型的準確率則大幅下降。我們還進行了一項包含 8 位受試者的真人研究，以展示我們這個結合框架的持續學習能力。我們在三明治製作任務中達到 75% 的成功率，真實機器人從參與者的資料中學習，證明了機器人可以使用我們的方法，從非專家使用者的對話中學習新的技能或任務知識。

##### **MaterialBENCH: Evaluating College-Level Materials Science Problem-Solving Abilities of Large Language Models**
2409.03161v1 by Michiko Yoshitake, Yuta Suzuki, Ryo Igarashi, Yoshitaka Ushiku, Keisuke Nagato

A college-level benchmark dataset for large language models (LLMs) in the
materials science field, MaterialBENCH, is constructed. This dataset consists
of problem-answer pairs, based on university textbooks. There are two types of
problems: one is the free-response answer type, and the other is the
multiple-choice type. Multiple-choice problems are constructed by adding three
incorrect answers as choices to a correct answer, so that LLMs can choose one
of the four as a response. Most of the problems for free-response answer and
multiple-choice types overlap except for the format of the answers. We also
conduct experiments using the MaterialBENCH on LLMs, including ChatGPT-3.5,
ChatGPT-4, Bard (at the time of the experiments), and GPT-3.5 and GPT-4 with
the OpenAI API. The differences and similarities in the performance of LLMs
measured by the MaterialBENCH are analyzed and discussed. Performance
differences between the free-response type and multiple-choice type in the same
models and the influence of using system massages on multiple-choice problems
are also studied. We anticipate that MaterialBENCH will encourage further
developments of LLMs in reasoning abilities to solve more complicated problems
and eventually contribute to materials research and discovery.

摘要：<paragraph>針對材料科學領域的大型語言模型 (LLM) 建構了大學等級的基準資料集 MaterialBENCH。此資料集包含基於大學教科書的問題解答配對。問題有兩種：一種是自由回答類型，另一種是多選題類型。多選題問題是透過在正確答案中加入三個錯誤答案作為選項來建構，以便 LLM 能從四個選項中選擇一個作為回應。除了答案格式外，自由回答類型和多選題類型的大部分問題是重疊的。我們還使用 MaterialBENCH 對 LLM 進行實驗，包括 ChatGPT-3.5、ChatGPT-4、Bard（在實驗時）、以及使用 OpenAI API 的 GPT-3.5 和 GPT-4。針對 MaterialBENCH 測量出的 LLM 效能差異和相似性進行分析和討論。我們也研究了相同模型中自由回答類型和多選題類型之間的效能差異，以及在多選題問題中使用系統訊息的影響。我們預期 MaterialBENCH 將促進 LLM 在推理能力方面的進一步發展，以解決更複雜的問題，並最終有助於材料研究和發現。</paragraph>

##### **Debate on Graph: a Flexible and Reliable Reasoning Framework for Large Language Models**
2409.03155v1 by Jie Ma, Zhitao Gao, Qi Chai, Wangchun Sun, Pinghui Wang, Hongbin Pei, Jing Tao, Lingyun Song, Jun Liu, Chen Zhang, Lizhen Cui

Large Language Models (LLMs) may suffer from hallucinations in real-world
applications due to the lack of relevant knowledge. In contrast, knowledge
graphs encompass extensive, multi-relational structures that store a vast array
of symbolic facts. Consequently, integrating LLMs with knowledge graphs has
been extensively explored, with Knowledge Graph Question Answering (KGQA)
serving as a critical touchstone for the integration. This task requires LLMs
to answer natural language questions by retrieving relevant triples from
knowledge graphs. However, existing methods face two significant challenges:
\textit{excessively long reasoning paths distracting from the answer
generation}, and \textit{false-positive relations hindering the path
refinement}. In this paper, we propose an iterative interactive KGQA framework
that leverages the interactive learning capabilities of LLMs to perform
reasoning and Debating over Graphs (DoG). Specifically, DoG employs a
subgraph-focusing mechanism, allowing LLMs to perform answer trying after each
reasoning step, thereby mitigating the impact of lengthy reasoning paths. On
the other hand, DoG utilizes a multi-role debate team to gradually simplify
complex questions, reducing the influence of false-positive relations. This
debate mechanism ensures the reliability of the reasoning process. Experimental
results on five public datasets demonstrate the effectiveness and superiority
of our architecture. Notably, DoG outperforms the state-of-the-art method ToG
by 23.7\% and 9.1\% in accuracy on WebQuestions and GrailQA, respectively.
Furthermore, the integration experiments with various LLMs on the mentioned
datasets highlight the flexibility of DoG. Code is available at
\url{https://github.com/reml-group/DoG}.

摘要：<paragraph>大型語言模型 (LLM) 由於缺乏相關知識，在實際應用中可能會產生幻覺。相較之下，知識圖譜包含廣泛的多重關係結構，儲存大量符號事實。因此，將 LLM 與知識圖譜整合已廣泛探討，其中知識圖譜問題解答 (KGQA) 成為整合的重要試金石。此任務要求 LLM 透過從知識圖譜中擷取相關三元組來回答自然語言問題。然而，現有方法面臨兩項重大挑戰：\textit{過長的推理路徑會分散回答產生}，以及\textit{錯誤正向關係阻礙路徑精煉}。在本文中，我們提出一個反覆互動的 KGQA 框架，它利用 LLM 的互動學習能力來執行推理和圖形辯論 (DoG)。具體來說，DoG 採用子圖聚焦機制，允許 LLM 在每個推理步驟後執行答案嘗試，從而減輕冗長推理路徑的影響。另一方面，DoG 利用多角色辯論小組逐漸簡化複雜問題，減少錯誤正向關係的影響。這種辯論機制確保了推理過程的可靠性。在五個公共數據集上的實驗結果證明了我們架構的有效性和優越性。值得注意的是，DoG 在 WebQuestions 和 GrailQA 上的準確度分別比最先進的方法 ToG 高出 23.7% 和 9.1%。此外，在上述數據集上與各種 LLM 的整合實驗突顯了 DoG 的靈活性。程式碼可在\url{https://github.com/reml-group/DoG}取得。</paragraph>

##### **Addressing the Gaps in Early Dementia Detection: A Path Towards Enhanced Diagnostic Models through Machine Learning**
2409.03147v1 by Juan A. Berrios Moya

The rapid global aging trend has led to an increase in dementia cases,
including Alzheimer's disease, underscoring the urgent need for early and
accurate diagnostic methods. Traditional diagnostic techniques, such as
cognitive tests, neuroimaging, and biomarker analysis, face significant
limitations in sensitivity, accessibility, and cost, particularly in the early
stages. This study explores the potential of machine learning (ML) as a
transformative approach to enhance early dementia detection by leveraging ML
models to analyze and integrate complex multimodal datasets, including
cognitive assessments, neuroimaging, and genetic information. A comprehensive
review of existing literature was conducted to evaluate various ML models,
including supervised learning, deep learning, and advanced techniques such as
ensemble learning and transformer models, assessing their accuracy,
interpretability, and potential for clinical integration. The findings indicate
that while ML models show significant promise in improving diagnostic precision
and enabling earlier interventions, challenges remain in their
generalizability, interpretability, and ethical deployment. This research
concludes by outlining future directions aimed at enhancing the clinical
utility of ML models in dementia detection, emphasizing interdisciplinary
collaboration and ethically sound frameworks to improve early detection and
intervention strategies for Alzheimer's disease and other forms of dementia.

摘要：全球人口快速老化趨勢導致失智症病例增加，包括阿茲海默症，突顯出早期且準確的診斷方法的迫切需求。傳統的診斷技術，例如認知測驗、神經影像和生物標記分析，在敏感性、可及性和成本方面面臨重大限制，特別是在早期階段。本研究探討機器學習 (ML) 作為一種變革性方法的潛力，通過利用 ML 模型分析和整合複雜的多模式數據集，包括認知評估、神經影像和遺傳信息，來增強早期失智症檢測。對現有文獻進行了全面回顧，以評估各種 ML 模型，包括監督學習、深度學習和先進技術，例如集成學習和Transformer模型，評估其準確性、可解釋性和臨床整合的潛力。研究結果表明，儘管 ML 模型在提高診斷精度和實現早期干預方面顯示出顯著的希望，但其可概化性、可解釋性和道德部署仍然存在挑戰。本研究最後概述了旨在增強 ML 模型在失智症檢測中的臨床效用的未來方向，強調跨學科合作和道德健全的框架，以改善阿茲海默症和其他形式失智症的早期檢測和干預策略。

##### **GraphEx: A Graph-based Extraction Method for Advertiser Keyphrase Recommendation**
2409.03140v1 by Ashirbad Mishra, Soumik Dey, Marshall Wu, Jinyu Zhao, He Yu, Kaichen Ni, Binbin Li, Kamesh Madduri

Online sellers and advertisers are recommended keyphrases for their listed
products, which they bid on to enhance their sales. One popular paradigm that
generates such recommendations is Extreme Multi-Label Classification (XMC),
which involves tagging/mapping keyphrases to items. We outline the limitations
of using traditional item-query based tagging or mapping techniques for
keyphrase recommendations on E-Commerce platforms. We introduce GraphEx, an
innovative graph-based approach that recommends keyphrases to sellers using
extraction of token permutations from item titles. Additionally, we demonstrate
that relying on traditional metrics such as precision/recall can be misleading
in practical applications, thereby necessitating a combination of metrics to
evaluate performance in real-world scenarios. These metrics are designed to
assess the relevance of keyphrases to items and the potential for buyer
outreach. GraphEx outperforms production models at eBay, achieving the
objectives mentioned above. It supports near real-time inferencing in
resource-constrained production environments and scales effectively for
billions of items.

摘要：線上賣家和廣告商會收到建議關鍵字，用於其所列產品，他們會對這些關鍵字進行競標以提高銷售額。產生此類建議的一種流行範例是極端多標籤分類 (XMC)，其中涉及將關鍵字標記/對應至商品。我們概述了在電子商務平台上使用傳統的基於商品查詢的標記或對應技術來進行關鍵字建議的限制。我們引入了 GraphEx，這是一種創新的基於圖形的方法，它使用從商品標題中提取的標記排列來向賣家推薦關鍵字。此外，我們證明了在實際應用中依賴於傳統指標（例如準確度/召回率）可能會產生誤導，因此需要結合指標來評估實際場景中的效能。這些指標旨在評估關鍵字與商品的相關性以及買家外展的潛力。GraphEx 優於 eBay 上的生產模型，達到了上述目標。它支援在資源受限的生產環境中進行近乎即時的推理，並針對數十億個商品有效擴展。

##### **Well, that escalated quickly: The Single-Turn Crescendo Attack (STCA)**
2409.03131v1 by Alan Aqrawi

This paper explores a novel approach to adversarial attacks on large language
models (LLM): the Single-Turn Crescendo Attack (STCA). The STCA builds upon the
multi-turn crescendo attack established by Mark Russinovich, Ahmed Salem, Ronen
Eldan. Traditional multi-turn adversarial strategies gradually escalate the
context to elicit harmful or controversial responses from LLMs. However, this
paper introduces a more efficient method where the escalation is condensed into
a single interaction. By carefully crafting the prompt to simulate an extended
dialogue, the attack bypasses typical content moderation systems, leading to
the generation of responses that would normally be filtered out. I demonstrate
this technique through a few case studies. The results highlight
vulnerabilities in current LLMs and underscore the need for more robust
safeguards. This work contributes to the broader discourse on responsible AI
(RAI) safety and adversarial testing, providing insights and practical examples
for researchers and developers. This method is unexplored in the literature,
making it a novel contribution to the field.

摘要：這篇論文探討了一種針對大型語言模型 (LLM) 的對抗性攻擊的新方法：單回合漸強攻擊 (STCA)。STCA 建立在 Mark Russinovich、Ahmed Salem、Ronen Eldan 建立的多回合漸強攻擊之上。傳統的多回合對抗策略逐漸升級上下文，以從 LLM 引發有害或有爭議的回應。然而，這篇論文介紹了一種更有效率的方法，其中升級被濃縮成單一互動。通過仔細製作提示來模擬擴展對話，攻擊繞過典型的內容審核系統，導致生成通常會被過濾掉的回應。我透過幾個案例研究展示了這種技術。結果突顯了當前 LLM 的漏洞，並強調需要更強大的防護措施。這項工作有助於關於負責任的人工智慧 (RAI) 安全性和對抗性測試的更廣泛討論，為研究人員和開發人員提供見解和實例。這種方法在文獻中尚未探索，使其成為該領域的創新貢獻。

##### **Probing self-attention in self-supervised speech models for cross-linguistic differences**
2409.03115v1 by Sai Gopinath, Joselyn Rodriguez

Speech models have gained traction thanks to increase in accuracy from novel
transformer architectures. While this impressive increase in performance across
automatic speech recognition (ASR) benchmarks is noteworthy, there is still
much that is unknown about the use of attention mechanisms for speech-related
tasks. For example, while it is assumed that these models are learning
language-independent (i.e., universal) speech representations, there has not
yet been an in-depth exploration of what it would mean for the models to be
language-independent. In the current paper, we explore this question within the
realm of self-attention mechanisms of one small self-supervised speech
transformer model (TERA). We find that even with a small model, the attention
heads learned are diverse ranging from almost entirely diagonal to almost
entirely global regardless of the training language. We highlight some notable
differences in attention patterns between Turkish and English and demonstrate
that the models do learn important phonological information during pretraining.
We also present a head ablation study which shows that models across languages
primarily rely on diagonal heads to classify phonemes.

摘要：語音模型由於新穎的轉換器架構的準確性提升而獲得關注。雖然在自動語音辨識 (ASR) 基準中性能有顯著提升值得注意，但對於使用注意力機制進行與語音相關的任務，仍有許多未知之處。例如，雖然假設這些模型正在學習與語言無關（即通用）的語音表示，但對於模型與語言無關的意義尚未深入探討。在本文中，我們在一個小型自我監督語音轉換器模型 (TERA) 的自我注意力機制的領域中探討這個問題。我們發現即使使用小型模型，學習到的注意力頭也是多樣化的，從幾乎完全對角線到幾乎完全全局，與訓練語言無關。我們重點說明土耳其語和英語之間注意力模式的一些顯著差異，並證明模型在預訓練期間確實學習重要的音韻資訊。我們還提出一個頭部消融研究，顯示跨語言的模型主要依賴對角線頭部來分類音素。

##### **MobileUNETR: A Lightweight End-To-End Hybrid Vision Transformer For Efficient Medical Image Segmentation**
2409.03062v1 by Shehan Perera, Yunus Erzurumlu, Deepak Gulati, Alper Yilmaz

Skin cancer segmentation poses a significant challenge in medical image
analysis. Numerous existing solutions, predominantly CNN-based, face issues
related to a lack of global contextual understanding. Alternatively, some
approaches resort to large-scale Transformer models to bridge the global
contextual gaps, but at the expense of model size and computational complexity.
Finally many Transformer based approaches rely primarily on CNN based decoders
overlooking the benefits of Transformer based decoding models. Recognizing
these limitations, we address the need efficient lightweight solutions by
introducing MobileUNETR, which aims to overcome the performance constraints
associated with both CNNs and Transformers while minimizing model size,
presenting a promising stride towards efficient image segmentation. MobileUNETR
has 3 main features. 1) MobileUNETR comprises of a lightweight hybrid
CNN-Transformer encoder to help balance local and global contextual feature
extraction in an efficient manner; 2) A novel hybrid decoder that
simultaneously utilizes low-level and global features at different resolutions
within the decoding stage for accurate mask generation; 3) surpassing large and
complex architectures, MobileUNETR achieves superior performance with 3 million
parameters and a computational complexity of 1.3 GFLOP resulting in 10x and 23x
reduction in parameters and FLOPS, respectively. Extensive experiments have
been conducted to validate the effectiveness of our proposed method on four
publicly available skin lesion segmentation datasets, including ISIC 2016, ISIC
2017, ISIC 2018, and PH2 datasets. The code will be publicly available at:
https://github.com/OSUPCVLab/MobileUNETR.git

摘要：皮膚癌分割在醫學影像分析中構成一項重大挑戰。現有許多解決方案（主要是基於 CNN）面臨缺乏整體背景理解的問題。或者，一些方法訴諸於大規模 Transformer 模型來彌合整體背景差距，但犧牲了模型大小和計算複雜度。最後，許多基於 Transformer 的方法主要依賴於基於 CNN 的解碼器，而忽視了基於 Transformer 的解碼模型的優點。認識到這些限制，我們通過引入 MobileUNETR 來解決對高效輕量級解決方案的需求，其目標是克服與 CNN 和 Transformer 相關的效能限制，同時最小化模型大小，為高效影像分割邁出有希望的一步。MobileUNETR 有 3 個主要特點。1) MobileUNETR 包含一個輕量級混合 CNN-Transformer 編碼器，以有效的方式幫助平衡局部和整體背景特徵提取；2) 一個新穎的混合解碼器，在解碼階段同時利用不同解析度下的低階和整體特徵，以進行精確的遮罩生成；3) 超越大型而複雜的架構，MobileUNETR 以 300 萬個參數和 1.3 GFLOP 的計算複雜度實現了卓越的效能，分別減少了 10 倍和 23 倍的參數和 FLOP。已經進行了廣泛的實驗，以驗證我們提出的方法在四個公開可用的皮膚病變分割資料集（包括 ISIC 2016、ISIC 2017、ISIC 2018 和 PH2 資料集）上的有效性。程式碼將公開於：https://github.com/OSUPCVLab/MobileUNETR.git

##### **Better Verified Explanations with Applications to Incorrectness and Out-of-Distribution Detection**
2409.03060v1 by Min Wu, Xiaofu Li, Haoze Wu, Clark Barrett

Building on VeriX (Verified eXplainability, arXiv:2212.01051), a system for
producing optimal verified explanations for machine learning model outputs, we
present VeriX+, which significantly improves both the size and the generation
time of verified explanations. We introduce a bound propagation-based
sensitivity technique to improve the size, and a binary search-based traversal
with confidence ranking for improving time -- the two techniques are orthogonal
and can be used independently or together. We also show how to adapt the
QuickXplain (Junker 2004) algorithm to our setting to provide a trade-off
between size and time. Experimental evaluations on standard benchmarks
demonstrate significant improvements on both metrics, e.g., a size reduction of
38% on the GTSRB dataset and a time reduction of 90% on MNIST. We also explore
applications of our verified explanations and show that explanation size is a
useful proxy for both incorrectness detection and out-of-distribution
detection.

摘要：建構在 VeriX（驗證可解釋性，arXiv:2212.01051）之上，這是一個用於產生機器學習模型輸出最佳驗證解釋的系統，我們提出 VeriX+，它顯著改善驗證解釋的大小和產生時間。我們引入一個基於邊界傳播的敏感度技術來改善大小，以及一個基於二元搜尋的遍歷，並使用信心排名來改善時間——這兩種技術是正交的，可以獨立或一起使用。我們還展示如何將 QuickXplain（Junker 2004）演算法調整到我們的設定，以在大小和時間之間取得折衷。在標準基準上的實驗評估證明了這兩個指標都有顯著的改善，例如，GTSRB 資料集的大小減少了 38%，而 MNIST 的時間減少了 90%。我們還探討了驗證解釋的應用，並表明解釋大小是錯誤檢測和分佈外檢測的有用代理。

##### **Oddballness: universal anomaly detection with language models**
2409.03046v1 by Filip Graliński, Ryszard Staruch, Krzysztof Jurkiewicz

We present a new method to detect anomalies in texts (in general: in
sequences of any data), using language models, in a totally unsupervised
manner. The method considers probabilities (likelihoods) generated by a
language model, but instead of focusing on low-likelihood tokens, it considers
a new metric introduced in this paper: oddballness. Oddballness measures how
``strange'' a given token is according to the language model. We demonstrate in
grammatical error detection tasks (a specific case of text anomaly detection)
that oddballness is better than just considering low-likelihood events, if a
totally unsupervised setup is assumed.

摘要：我們提出了一種使用語言模型來偵測文本異常值的新方法（一般來說：在任何資料的序列中），這是一種完全無監督的方式。該方法考慮語言模型所產生的機率（可能性），但它並非專注於低可能性標記，而是考慮本文中介紹的新指標：奇異性。奇異性衡量給定標記根據語言模型有多「奇怪」。我們在語法錯誤偵測任務（一種特定的文本異常值偵測）中證明，如果假設完全無監督的設定，奇異性比僅考慮低可能性事件來得更好。

##### **Can Your Generative Model Detect Out-of-Distribution Covariate Shift?**
2409.03043v1 by Christiaan Viviers, Amaan Valiuddin, Francisco Caetano, Lemar Abdi, Lena Filatova, Peter de With, Fons van der Sommen

Detecting Out-of-Distribution~(OOD) sensory data and covariate distribution
shift aims to identify new test examples with different high-level image
statistics to the captured, normal and In-Distribution (ID) set. Existing OOD
detection literature largely focuses on semantic shift with little-to-no
consensus over covariate shift. Generative models capture the ID data in an
unsupervised manner, enabling them to effectively identify samples that deviate
significantly from this learned distribution, irrespective of the downstream
task. In this work, we elucidate the ability of generative models to detect and
quantify domain-specific covariate shift through extensive analyses that
involves a variety of models. To this end, we conjecture that it is sufficient
to detect most occurring sensory faults (anomalies and deviations in global
signals statistics) by solely modeling high-frequency signal-dependent and
independent details. We propose a novel method, CovariateFlow, for OOD
detection, specifically tailored to covariate heteroscedastic high-frequency
image-components using conditional Normalizing Flows (cNFs). Our results on
CIFAR10 vs. CIFAR10-C and ImageNet200 vs. ImageNet200-C demonstrate the
effectiveness of the method by accurately detecting OOD covariate shift. This
work contributes to enhancing the fidelity of imaging systems and aiding
machine learning models in OOD detection in the presence of covariate shift.

摘要：偵測非分佈~(OOD) 感測資料和協變數分佈轉移旨在識別具有不同高階影像統計資料的新測試範例，以擷取正常和分佈內 (ID) 集合。現有的 OOD 偵測文獻主要關注語意轉移，對協變數轉移幾乎沒有共識。生成模型以非監督式的方式擷取 ID 資料，使其能夠有效識別與此學習分佈顯著不同的樣本，與下游任務無關。在這項工作中，我們闡明了生成模型透過涉及各種模型的廣泛分析來偵測和量化特定領域的協變數轉移的能力。為此，我們推測僅建模高頻訊號依賴性和獨立性細節就足以偵測大多數發生的感測故障（全球訊號統計資料中的異常和偏差）。我們提出了一種新的方法，CovariateFlow，用於 OOD 偵測，特別針對使用條件正規化流 (cNF) 的協變數異質高頻影像組成。我們在 CIFAR10 與 CIFAR10-C 和 ImageNet200 與 ImageNet200-C 的結果證明了該方法的有效性，準確偵測 OOD 協變數轉移。這項工作有助於提升影像系統的保真度，並在協變數轉移的情況下協助機器學習模型進行 OOD 偵測。

##### **CLUE: Concept-Level Uncertainty Estimation for Large Language Models**
2409.03021v1 by Yu-Hsiang Wang, Andrew Bai, Che-Ping Tsai, Cho-Jui Hsieh

Large Language Models (LLMs) have demonstrated remarkable proficiency in
various natural language generation (NLG) tasks. Previous studies suggest that
LLMs' generation process involves uncertainty. However, existing approaches to
uncertainty estimation mainly focus on sequence-level uncertainty, overlooking
individual pieces of information within sequences. These methods fall short in
separately assessing the uncertainty of each component in a sequence. In
response, we propose a novel framework for Concept-Level Uncertainty Estimation
(CLUE) for LLMs. We leverage LLMs to convert output sequences into
concept-level representations, breaking down sequences into individual concepts
and measuring the uncertainty of each concept separately. We conduct
experiments to demonstrate that CLUE can provide more interpretable uncertainty
estimation results compared with sentence-level uncertainty, and could be a
useful tool for various tasks such as hallucination detection and story
generation.

摘要：大型語言模型 (LLM) 已在各種自然語言生成 (NLG) 任務中展現出卓越的熟練度。先前的研究表明，LLM 的生成過程涉及不確定性。然而，現有方法對不確定性估計主要集中在序列級別的不確定性上，忽略了序列中各個資訊片段。這些方法無法分別評估序列中每個組成部分的不確定性。為了解決這個問題，我們提出了一個用於 LLM 的概念級別不確定性估計 (CLUE) 的新框架。我們利用 LLM 將輸出序列轉換為概念級別的表示，將序列分解為個別概念，並分別測量每個概念的不確定性。我們進行實驗以證明，與句子級別的不確定性相比，CLUE 可以提供更具可解釋性的不確定性估計結果，並且可以成為各種任務（例如幻覺檢測和故事生成）的有用工具。

##### **RoboTwin: Dual-Arm Robot Benchmark with Generative Digital Twins (early version)**
2409.02920v1 by Yao Mu, Tianxing Chen, Shijia Peng, Zanxin Chen, Zeyu Gao, Yude Zou, Lunkai Lin, Zhiqiang Xie, Ping Luo

Effective collaboration of dual-arm robots and their tool use capabilities
are increasingly important areas in the advancement of robotics. These skills
play a significant role in expanding robots' ability to operate in diverse
real-world environments. However, progress is impeded by the scarcity of
specialized training data. This paper introduces RoboTwin, a novel benchmark
dataset combining real-world teleoperated data with synthetic data from digital
twins, designed for dual-arm robotic scenarios. Using the COBOT Magic platform,
we have collected diverse data on tool usage and human-robot interaction. We
present a innovative approach to creating digital twins using AI-generated
content, transforming 2D images into detailed 3D models. Furthermore, we
utilize large language models to generate expert-level training data and
task-specific pose sequences oriented toward functionality. Our key
contributions are: 1) the RoboTwin benchmark dataset, 2) an efficient
real-to-simulation pipeline, and 3) the use of language models for automatic
expert-level data generation. These advancements are designed to address the
shortage of robotic training data, potentially accelerating the development of
more capable and versatile robotic systems for a wide range of real-world
applications. The project page is available at
https://robotwin-benchmark.github.io/early-version/

摘要：雙臂機器人的有效協作及其工具使用能力在機器人技術的進步中越來越重要。這些技能在擴展機器人在各種現實世界環境中運作的能力方面發揮著重要作用。然而，進展受到專業訓練資料缺乏的阻礙。本文介紹了 RoboTwin，一個新穎的基準資料集，結合了來自數位雙胞胎的真實世界遙控操作資料和合成資料，專為雙臂機器人場景而設計。使用 COBOT Magic 平台，我們收集了有關工具使用和人機互動的各種資料。我們提出了一種創新的方法來使用 AI 生成的內容建立數位雙胞胎，將 2D 影像轉換為詳細的 3D 模型。此外，我們利用大型語言模型來產生專家級的訓練資料和面向功能的特定任務姿勢序列。我們的關鍵貢獻包括：1) RoboTwin 基準資料集，2) 一個高效的真實到模擬的管道，以及 3) 使用語言模型進行自動專家級資料生成。這些進展旨在解決機器人訓練資料短缺的問題，有可能加速開發更強大、更通用的機器人系統，以應用于廣泛的現實世界應用。專案頁面可於 https://robotwin-benchmark.github.io/early-version/ 獲得

##### **UC-NeRF: Uncertainty-aware Conditional Neural Radiance Fields from Endoscopic Sparse Views**
2409.02917v1 by Jiaxin Guo, Jiangliu Wang, Ruofeng Wei, Di Kang, Qi Dou, Yun-hui Liu

Visualizing surgical scenes is crucial for revealing internal anatomical
structures during minimally invasive procedures. Novel View Synthesis is a
vital technique that offers geometry and appearance reconstruction, enhancing
understanding, planning, and decision-making in surgical scenes. Despite the
impressive achievements of Neural Radiance Field (NeRF), its direct application
to surgical scenes produces unsatisfying results due to two challenges:
endoscopic sparse views and significant photometric inconsistencies. In this
paper, we propose uncertainty-aware conditional NeRF for novel view synthesis
to tackle the severe shape-radiance ambiguity from sparse surgical views. The
core of UC-NeRF is to incorporate the multi-view uncertainty estimation to
condition the neural radiance field for modeling the severe photometric
inconsistencies adaptively. Specifically, our UC-NeRF first builds a
consistency learner in the form of multi-view stereo network, to establish the
geometric correspondence from sparse views and generate uncertainty estimation
and feature priors. In neural rendering, we design a base-adaptive NeRF network
to exploit the uncertainty estimation for explicitly handling the photometric
inconsistencies. Furthermore, an uncertainty-guided geometry distillation is
employed to enhance geometry learning. Experiments on the SCARED and Hamlyn
datasets demonstrate our superior performance in rendering appearance and
geometry, consistently outperforming the current state-of-the-art approaches.
Our code will be released at \url{https://github.com/wrld/UC-NeRF}.

摘要：視覺化手術場景對於在微創手術中揭露內部解剖結構至關重要。新穎視圖合成是一種重要的技術，提供幾何和外觀重建，增強對手術場景的理解、規劃和決策制定。儘管神經輻照場 (NeRF) 取得了令人印象深刻的成就，但由於兩個挑戰：內視鏡稀疏視圖和顯著的光度不一致，其直接應用於手術場景會產生不令人滿意的結果。在本文中，我們提出了一種不確定性感知條件 NeRF，用於新視圖合成，以解決稀疏手術視圖中的嚴重形狀輻照度模糊性。UC-NeRF 的核心是將多視圖不確定性估計納入條件神經輻照度場，以自適應地建模嚴重的光度不一致性。具體來說，我們的 UC-NeRF 首先以多視圖立體網路的形式構建一致性學習器，以建立稀疏視圖的幾何對應關係，並生成不確定性估計和特徵先驗。在神經渲染中，我們設計了一個基於自適應的 NeRF 網路，以利用不確定性估計來明確處理光度不一致性。此外，採用不確定性引導的幾何蒸餾來增強幾何學習。在 SCARED 和 Hamlyn 資料集上的實驗證明了我們在渲染外觀和幾何方面的卓越效能，始終優於當前最先進的方法。我們的程式碼將在 \url{https://github.com/wrld/UC-NeRF} 發布。

##### **Masked Diffusion Models are Secretly Time-Agnostic Masked Models and Exploit Inaccurate Categorical Sampling**
2409.02908v1 by Kaiwen Zheng, Yongxin Chen, Hanzi Mao, Ming-Yu Liu, Jun Zhu, Qinsheng Zhang

Masked diffusion models (MDMs) have emerged as a popular research topic for
generative modeling of discrete data, thanks to their superior performance over
other discrete diffusion models, and are rivaling the auto-regressive models
(ARMs) for language modeling tasks. The recent effort in simplifying the masked
diffusion framework further leads to alignment with continuous-space diffusion
models and more principled training and sampling recipes. In this paper,
however, we reveal that both training and sampling of MDMs are theoretically
free from the time variable, arguably the key signature of diffusion models,
and are instead equivalent to masked models. The connection on the sampling
aspect is drawn by our proposed first-hitting sampler (FHS). Specifically, we
show that the FHS is theoretically equivalent to MDMs' original generation
process while significantly alleviating the time-consuming categorical sampling
and achieving a 20$\times$ speedup. In addition, our investigation challenges
previous claims that MDMs can surpass ARMs in generative perplexity. We
identify, for the first time, an underlying numerical issue, even with the
32-bit floating-point precision, which results in inaccurate categorical
sampling. We show that the numerical issue lowers the effective temperature
both theoretically and empirically, leading to unfair assessments of MDMs'
generation results in the previous literature.

摘要：遮罩擴散模型 (MDM) 已成為離散資料生成模型的熱門研究主題，這要歸功於其優於其他離散擴散模型的卓越效能，並且在語言建模任務中與自迴歸模型 (ARM) 相抗衡。簡化遮罩擴散架構的最新努力進一步導致與連續空間擴散模型和更有原則的訓練和採樣配方保持一致。然而，在本文中，我們揭示了 MDM 的訓練和採樣在理論上都不受時間變數的約束，這可以說是擴散模型的主要特徵，而等同於遮罩模型。採樣方面的關聯性是由我們提出的首次命中採樣器 (FHS) 繪製的。具體來說，我們表明 FHS 在理論上等同於 MDM 的原始生成過程，同時顯著減輕了耗時的分類採樣，並實現了 20 倍的加速。此外，我們的調查挑戰了先前的說法，即 MDM 可以超越 ARM 的生成困惑度。我們首次發現了一個潛在的數值問題，即使使用 32 位浮點精度，也會導致不準確的分類採樣。我們表明，這個數值問題在理論上和經驗上都會降低有效溫度，導致對先前文獻中 MDM 的生成結果進行不公平的評估。

##### **LongCite: Enabling LLMs to Generate Fine-grained Citations in Long-context QA**
2409.02897v2 by Jiajie Zhang, Yushi Bai, Xin Lv, Wanjun Gu, Danqing Liu, Minhao Zou, Shulin Cao, Lei Hou, Yuxiao Dong, Ling Feng, Juanzi Li

Though current long-context large language models (LLMs) have demonstrated
impressive capacities in answering user questions based on extensive text, the
lack of citations in their responses makes user verification difficult, leading
to concerns about their trustworthiness due to their potential hallucinations.
In this work, we aim to enable long-context LLMs to generate responses with
fine-grained sentence-level citations, improving their faithfulness and
verifiability. We first introduce LongBench-Cite, an automated benchmark for
assessing current LLMs' performance in Long-Context Question Answering with
Citations (LQAC), revealing considerable room for improvement. To this end, we
propose CoF (Coarse to Fine), a novel pipeline that utilizes off-the-shelf LLMs
to automatically generate long-context QA instances with precise sentence-level
citations, and leverage this pipeline to construct LongCite-45k, a large-scale
SFT dataset for LQAC. Finally, we train LongCite-8B and LongCite-9B using the
LongCite-45k dataset, successfully enabling their generation of accurate
responses and fine-grained sentence-level citations in a single output. The
evaluation results on LongBench-Cite show that our trained models achieve
state-of-the-art citation quality, surpassing advanced proprietary models
including GPT-4o.

摘要：儘管目前的長語境大型語言模型 (LLM) 已展現出根據廣泛文本回答使用者問題的驚人能力，但其回應中缺乏引文，使得使用者驗證困難，並因其潛在的幻覺而對其可信度產生疑慮。在此研究中，我們旨在讓長語境 LLM 能夠產生具有細緻句子層級引文的回應，進而提升其真實性和可驗證性。我們首先介紹 LongBench-Cite，這是一個自動化基準，用於評估目前 LLM 在長語境問答帶引文 (LQAC) 中的表現，揭露有待改進的空間。為此，我們提出 CoF（粗到細），這是一個新穎的管道，利用現成的 LLM 自動產生具有精確句子層級引文的長語境問答實例，並利用此管道建構 LongCite-45k，這是一個用於 LQAC 的大規模 SFT 資料集。最後，我們使用 LongCite-45k 資料集訓練 LongCite-8B 和 LongCite-9B，成功讓它們能夠在單一輸出中產生精確的回應和細緻的句子層級引文。在 LongBench-Cite 上的評估結果顯示，我們訓練的模型達到了最先進的引文品質，超越了包括 GPT-4o 在內的進階專有模型。

##### **LongLLaVA: Scaling Multi-modal LLMs to 1000 Images Efficiently via Hybrid Architecture**
2409.02889v1 by Xidong Wang, Dingjie Song, Shunian Chen, Chen Zhang, Benyou Wang

Expanding the long-context capabilities of Multi-modal Large Language
Models~(MLLMs) is crucial for video understanding, high-resolution image
understanding, and multi-modal agents. This involves a series of systematic
optimizations, including model architecture, data construction and training
strategy, particularly addressing challenges such as \textit{degraded
performance with more images} and \textit{high computational costs}. In this
paper, we adapt the model architecture to a hybrid of Mamba and Transformer
blocks, approach data construction with both temporal and spatial dependencies
among multiple images and employ a progressive training strategy. The released
model \textbf{LongLLaVA}~(\textbf{Long}-Context \textbf{L}arge
\textbf{L}anguage \textbf{a}nd \textbf{V}ision \textbf{A}ssistant) is the first
hybrid MLLM, which achieved a better balance between efficiency and
effectiveness. LongLLaVA not only achieves competitive results across various
benchmarks, but also maintains high throughput and low memory consumption.
Especially, it could process nearly a thousand images on a single A100 80GB
GPU, showing promising application prospects for a wide range of tasks.

摘要：擴展多模態大型語言模型 (MLLM) 的長文本能力對於影片理解、高解析度影像理解和多模態代理來說至關重要。這涉及一系列的系統性最佳化，包括模型架構、資料建置和訓練策略，特別是解決諸如「隨著影像增加而降低效能」和「高運算成本」等挑戰。在本文中，我們將模型架構調整為 Mamba 和 Transformer 區塊的混合體，使用多個影像之間的時序和空間依賴性來建置資料，並採用漸進式訓練策略。所發布的模型 \textbf{LongLLaVA}（\textbf{Long}-Context \textbf{L}arge \textbf{L}anguage \textbf{a}nd \textbf{V}ision \textbf{A}ssistant）是第一個混合 MLLM，在效率和效能之間取得更好的平衡。LongLLaVA 不僅在各種基準測試中取得競爭力的結果，還能維持高處理量和低記憶體消耗。特別是，它可以在單一 A100 80GB GPU 上處理近千張影像，展現出廣泛任務的應用前景。

##### **Multi-stream deep learning framework to predict mild cognitive impairment with Rey Complex Figure Test**
2409.02883v1 by Junyoung Park, Eun Hyun Seo, Sunjun Kim, SangHak Yi, Kun Ho Lee, Sungho Won

Drawing tests like the Rey Complex Figure Test (RCFT) are widely used to
assess cognitive functions such as visuospatial skills and memory, making them
valuable tools for detecting mild cognitive impairment (MCI). Despite their
utility, existing predictive models based on these tests often suffer from
limitations like small sample sizes and lack of external validation, which
undermine their reliability. We developed a multi-stream deep learning
framework that integrates two distinct processing streams: a multi-head
self-attention based spatial stream using raw RCFT images and a scoring stream
employing a previously developed automated scoring system. Our model was
trained on data from 1,740 subjects in the Korean cohort and validated on an
external hospital dataset of 222 subjects from Korea. The proposed multi-stream
model demonstrated superior performance over baseline models (AUC = 0.872,
Accuracy = 0.781) in external validation. The integration of both spatial and
scoring streams enables the model to capture intricate visual details from the
raw images while also incorporating structured scoring data, which together
enhance its ability to detect subtle cognitive impairments. This dual approach
not only improves predictive accuracy but also increases the robustness of the
model, making it more reliable in diverse clinical settings. Our model has
practical implications for clinical settings, where it could serve as a
cost-effective tool for early MCI screening.

摘要：雷氏複雜圖形測驗 (RCFT) 等繪畫測驗廣泛用於評估視覺空間技能和記憶力等認知功能，使其成為檢測輕度認知障礙 (MCI) 的寶貴工具。儘管它們很有用，但基於這些測驗的現有預測模型通常會受到樣本量小和缺乏外部驗證等限制，這會損害其可靠性。我們開發了一個多串流深度學習框架，它整合了兩個不同的處理串流：一個基於多頭自注意力，使用原始 RCFT 影像的空間串流，以及一個採用先前開發的自動評分系統的評分串流。我們的模型在韓國群組中 1,740 名受試者的資料上進行訓練，並在來自韓國的 222 名受試者的外部醫院資料集上進行驗證。所提出的多串流模型在外部驗證中表現出優於基準模型的效能 (AUC = 0.872，準確率 = 0.781)。空間和評分串流的整合使模型能夠從原始影像擷取複雜的視覺細節，同時也能納入結構化的評分資料，這共同增強了它檢測細微認知障礙的能力。這種雙重方法不僅提高了預測準確性，也增加了模型的穩健性，使其在不同的臨床環境中更可靠。我們的模型對臨床環境有實際的意義，它可以在其中作為早期 MCI 篩檢的具成本效益的工具。

##### **Configurable Foundation Models: Building LLMs from a Modular Perspective**
2409.02877v1 by Chaojun Xiao, Zhengyan Zhang, Chenyang Song, Dazhi Jiang, Feng Yao, Xu Han, Xiaozhi Wang, Shuo Wang, Yufei Huang, Guanyu Lin, Yingfa Chen, Weilin Zhao, Yuge Tu, Zexuan Zhong, Ao Zhang, Chenglei Si, Khai Hao Moo, Chenyang Zhao, Huimin Chen, Yankai Lin, Zhiyuan Liu, Jingbo Shang, Maosong Sun

Advancements in LLMs have recently unveiled challenges tied to computational
efficiency and continual scalability due to their requirements of huge
parameters, making the applications and evolution of these models on devices
with limited computation resources and scenarios requiring various abilities
increasingly cumbersome. Inspired by modularity within the human brain, there
is a growing tendency to decompose LLMs into numerous functional modules,
allowing for inference with part of modules and dynamic assembly of modules to
tackle complex tasks, such as mixture-of-experts. To highlight the inherent
efficiency and composability of the modular approach, we coin the term brick to
represent each functional module, designating the modularized structure as
configurable foundation models. In this paper, we offer a comprehensive
overview and investigation of the construction, utilization, and limitation of
configurable foundation models. We first formalize modules into emergent bricks
- functional neuron partitions that emerge during the pre-training phase, and
customized bricks - bricks constructed via additional post-training to improve
the capabilities and knowledge of LLMs. Based on diverse functional bricks, we
further present four brick-oriented operations: retrieval and routing, merging,
updating, and growing. These operations allow for dynamic configuration of LLMs
based on instructions to handle complex tasks. To verify our perspective, we
conduct an empirical analysis on widely-used LLMs. We find that the FFN layers
follow modular patterns with functional specialization of neurons and
functional neuron partitions. Finally, we highlight several open issues and
directions for future research. Overall, this paper aims to offer a fresh
modular perspective on existing LLM research and inspire the future creation of
more efficient and scalable foundational models.

摘要：<paragraph>大型語言模型 (LLM) 的進展最近揭示了由於需要龐大的參數而導致的計算效率和持續可擴充性的挑戰，這使得在計算資源有限的裝置上應用和演進這些模型以及需要各種能力的場景變得越來越繁瑣。受人類大腦中模組化的啟發，將 LLM 分解成許多功能模組的趨勢正在增長，允許使用部分模組進行推理和動態組裝模組來處理複雜任務，例如專家混合。為了突顯模組化方法的內在效率和可組合性，我們創造了「磚塊」一詞來表示每個功能模組，將模組化結構指定為可配置基礎模型。在本文中，我們對可配置基礎模型的構建、利用和限制提供了全面的概述和探討。我們首先將模組形式化為新興磚塊 - 在預訓練階段出現的功能神經元分割，以及自訂磚塊 - 透過額外的後續訓練來構建的磚塊，以改善 LLM 的能力和知識。基於不同的功能磚塊，我們進一步提出了四項面向磚塊的操作：擷取和路由、合併、更新和成長。這些操作允許根據指令動態配置 LLM 以處理複雜任務。為了驗證我們的觀點，我們對廣泛使用的 LLM 進行了實證分析。我們發現 FFN 層遵循模組模式，具有神經元和功能神經元分割的功能專門化。最後，我們重點介紹了幾個未解決的問題和未來研究的方向。總體而言，本文旨在對現有的 LLM 研究提供新的模組化觀點，並激勵未來創造更有效率和可擴充性的基礎模型。</paragraph>

##### **Hybrid Imitation-Learning Motion Planner for Urban Driving**
2409.02871v1 by Cristian Gariboldi, Matteo Corno, Beng Jin

With the release of open source datasets such as nuPlan and Argoverse, the
research around learning-based planners has spread a lot in the last years.
Existing systems have shown excellent capabilities in imitating the human
driver behaviour, but they struggle to guarantee safe closed-loop driving.
Conversely, optimization-based planners offer greater security in short-term
planning scenarios. To confront this challenge, in this paper we propose a
novel hybrid motion planner that integrates both learning-based and
optimization-based techniques. Initially, a multilayer perceptron (MLP)
generates a human-like trajectory, which is then refined by an
optimization-based component. This component not only minimizes tracking errors
but also computes a trajectory that is both kinematically feasible and
collision-free with obstacles and road boundaries. Our model effectively
balances safety and human-likeness, mitigating the trade-off inherent in these
objectives. We validate our approach through simulation experiments and further
demonstrate its efficacy by deploying it in real-world self-driving vehicles.

摘要：隨著 nuPlan 和 Argoverse 等開源資料集的釋出，近年來基於學習的規劃器的研究已廣泛展開。
現有系統已展現出模仿人類駕駛行為的出色能力，但仍難以保證安全閉環駕駛。
相反地，基於最佳化的規劃器在短期規劃情境中提供了更高的安全性。
為了應對這項挑戰，我們在這篇論文中提出了一種新的混合運動規劃器，它整合了基於學習和基於最佳化的技術。
最初，多層感知器 (MLP) 會產生類似人類的軌跡，然後由基於最佳化的組件加以精煉。
此組件不僅會將追蹤誤差降至最低，還會計算出在運動學上可行且不會與障礙物和道路邊界發生碰撞的軌跡。
我們的模型有效地平衡了安全性與類人化，減輕了這些目標中固有的取捨。
我們透過模擬實驗驗證了我們的做法，並進一步透過在真實世界的自動駕駛車輛中部署它來證明其效能。

##### **Historical German Text Normalization Using Type- and Token-Based Language Modeling**
2409.02841v1 by Anton Ehrmanntraut

Historic variations of spelling poses a challenge for full-text search or
natural language processing on historical digitized texts. To minimize the gap
between the historic orthography and contemporary spelling, usually an
automatic orthographic normalization of the historical source material is
pursued. This report proposes a normalization system for German literary texts
from c. 1700-1900, trained on a parallel corpus. The proposed system makes use
of a machine learning approach using Transformer language models, combining an
encoder-decoder model to normalize individual word types, and a pre-trained
causal language model to adjust these normalizations within their context. An
extensive evaluation shows that the proposed system provides state-of-the-art
accuracy, comparable with a much larger fully end-to-end sentence-based
normalization system, fine-tuning a pre-trained Transformer large language
model. However, the normalization of historical text remains a challenge due to
difficulties for models to generalize, and the lack of extensive high-quality
parallel data.

摘要：歷史拼寫的變化對歷史數位化文本的全文字搜尋或自然語言處理構成挑戰。為了縮小歷史正寫法和當代拼寫之間的差距，通常會對歷史來源資料進行自動正寫法標準化。本報告提出了一個針對德語文學文本的標準化系統，訓練資料取自一個平行語料庫，時間範圍為 1700-1900 年。所提出的系統採用使用 Transformer 語言模型的機器學習方法，結合編碼器-解碼器模型來標準化個別字詞類型，以及預先訓練的因果語言模型來調整這些標準化內容的語境。廣泛的評估顯示，所提出的系統提供了最先進的準確度，堪比一個更大規模的端到端句子式標準化系統，微調預先訓練好的 Transformer 大型語言模型。然而，歷史文本的標準化仍然是一個挑戰，因為模型難以概括，而且缺乏大量高品質的平行資料。

##### **R2GQA: Retriever-Reader-Generator Question Answering System to Support Students Understanding Legal Regulations in Higher Education**
2409.02840v1 by Phuc-Tinh Pham Do, Duy-Ngoc Dinh Cao, Khanh Quoc Tran, Kiet Van Nguyen

In this article, we propose the R2GQA system, a Retriever-Reader-Generator
Question Answering system, consisting of three main components: Document
Retriever, Machine Reader, and Answer Generator. The Retriever module employs
advanced information retrieval techniques to extract the context of articles
from a dataset of legal regulation documents. The Machine Reader module
utilizes state-of-the-art natural language understanding algorithms to
comprehend the retrieved documents and extract answers. Finally, the Generator
module synthesizes the extracted answers into concise and informative responses
to questions of students regarding legal regulations. Furthermore, we built the
ViRHE4QA dataset in the domain of university training regulations, comprising
9,758 question-answer pairs with a rigorous construction process. This is the
first Vietnamese dataset in the higher regulations domain with various types of
answers, both extractive and abstractive. In addition, the R2GQA system is the
first system to offer abstractive answers in Vietnamese. This paper discusses
the design and implementation of each module within the R2GQA system on the
ViRHE4QA dataset, highlighting their functionalities and interactions.
Furthermore, we present experimental results demonstrating the effectiveness
and utility of the proposed system in supporting the comprehension of students
of legal regulations in higher education settings. In general, the R2GQA system
and the ViRHE4QA dataset promise to contribute significantly to related
research and help students navigate complex legal documents and regulations,
empowering them to make informed decisions and adhere to institutional policies
effectively. Our dataset is available for research purposes.

摘要：<paragraph>在本文中，我們提出 R2GQA 系統，一個檢索器-閱讀器-產生器問答系統，由三個主要組成部分組成：文件檢索器、機器閱讀器和答案產生器。檢索器模組採用進階資訊檢索技術，從法律法規文件資料集中擷取文章的內容。機器閱讀器模組利用最先進的自然語言理解演算法，理解擷取的文件並擷取答案。最後，產生器模組將擷取的答案綜合成簡潔且具資訊性的回應，以回答學生有關法律法規的問題。此外，我們在大學訓練法規領域中建構了 ViRHE4QA 資料集，包含 9,758 個問題答案對，並採用嚴謹的建構程序。這是高等法規領域中第一個包含各種答案類型的越南語資料集，包括萃取式和抽象式。此外，R2GQA 系統是第一個提供越南語抽象答案的系統。本文討論了 R2GQA 系統中每個模組在 ViRHE4QA 資料集上的設計和實作，重點說明它們的功能和互動。此外，我們提供了實驗結果，證明了所提出的系統在支援高等教育環境中學生理解法律法規方面的有效性和實用性。總的來說，R2GQA 系統和 ViRHE4QA 資料集有望為相關研究做出重大貢獻，並幫助學生瀏覽複雜的法律文件和法規，讓他們能夠做出明智的決策並有效遵守機構政策。我們的資料集可供研究用途。</paragraph>

##### **Exploring Sentiment Dynamics and Predictive Behaviors in Cryptocurrency Discussions by Few-Shot Learning with Large Language Models**
2409.02836v1 by Moein Shahiki Tash, Zahra Ahani, Mohim Tash, Olga Kolesnikova, Grigori Sidorov

This study performs analysis of Predictive statements, Hope speech, and
Regret Detection behaviors within cryptocurrency-related discussions,
leveraging advanced natural language processing techniques. We introduce a
novel classification scheme named "Prediction statements," categorizing
comments into Predictive Incremental, Predictive Decremental, Predictive
Neutral, or Non-Predictive categories. Employing GPT-4o, a cutting-edge large
language model, we explore sentiment dynamics across five prominent
cryptocurrencies: Cardano, Binance, Matic, Fantom, and Ripple. Our analysis
reveals distinct patterns in predictive sentiments, with Matic demonstrating a
notably higher propensity for optimistic predictions. Additionally, we
investigate hope and regret sentiments, uncovering nuanced interplay between
these emotions and predictive behaviors. Despite encountering limitations
related to data volume and resource availability, our study reports valuable
discoveries concerning investor behavior and sentiment trends within the
cryptocurrency market, informing strategic decision-making and future research
endeavors.

摘要：本研究利用先進的自然語言處理技術，對加密貨幣相關討論中的預測性陳述、希望言論和遺憾檢測行為進行分析。我們引入一個名為「預測性陳述」的新分類方案，將評論分類為預測性遞增、預測性遞減、預測性中立或非預測性類別。採用 GPT-4o，一種尖端的巨量語言模型，我們探討了五種主要加密貨幣（Cardano、Binance、Matic、Fantom 和 Ripple）的情緒動態。我們的分析揭示了預測性情緒的不同模式，Matic 表現出明顯更高的樂觀預測傾向。此外，我們研究了希望和遺憾情緒，揭示了這些情緒與預測行為之間細微的相互作用。儘管遇到了與數據量和資源可用性相關的限制，但我們的研究報告了有關投資者行為和加密貨幣市場情緒趨勢的寶貴發現，為戰略決策制定和未來的研究工作提供信息。

##### **CMM-Math: A Chinese Multimodal Math Dataset To Evaluate and Enhance the Mathematics Reasoning of Large Multimodal Models**
2409.02834v1 by Wentao Liu, Qianjun Pan, Yi Zhang, Zhuo Liu, Ji Wu, Jie Zhou, Aimin Zhou, Qin Chen, Bo Jiang, Liang He

Large language models (LLMs) have obtained promising results in mathematical
reasoning, which is a foundational skill for human intelligence. Most previous
studies focus on improving and measuring the performance of LLMs based on
textual math reasoning datasets (e.g., MATH, GSM8K). Recently, a few
researchers have released English multimodal math datasets (e.g., MATHVISTA and
MATH-V) to evaluate the effectiveness of large multimodal models (LMMs). In
this paper, we release a Chinese multimodal math (CMM-Math) dataset, including
benchmark and training parts, to evaluate and enhance the mathematical
reasoning of LMMs. CMM-Math contains over 28,000 high-quality samples,
featuring a variety of problem types (e.g., multiple-choice, fill-in-the-blank,
and so on) with detailed solutions across 12 grade levels from elementary to
high school in China. Specifically, the visual context may be present in the
questions or opinions, which makes this dataset more challenging. Through
comprehensive analysis, we discover that state-of-the-art LMMs on the CMM-Math
dataset face challenges, emphasizing the necessity for further improvements in
LMM development. We also propose a Multimodal Mathematical LMM (Math-LMM) to
handle the problems with mixed input of multiple images and text segments. We
train our model using three stages, including foundational pre-training,
foundational fine-tuning, and mathematical fine-tuning. The extensive
experiments indicate that our model effectively improves math reasoning
performance by comparing it with the SOTA LMMs over three multimodal
mathematical datasets.

摘要：<paragraph>大型語言模型 (LLM) 在數學推理方面取得了可觀的成果，而數學推理是人類智慧的一項基礎技能。大多數先前的研究專注於改進和衡量 LLM 在基於文字數學推理資料集（例如 MATH、GSM8K）上的效能。最近，一些研究人員發布了英文多模態數學資料集（例如 MATHVISTA 和 MATH-V），以評估大型多模態模型 (LMM) 的效能。在本文中，我們發布了一個中文多模態數學 (CMM-Math) 資料集，其中包含基準和訓練部分，以評估和增強 LMM 的數學推理能力。CMM-Math 包含超過 28,000 個高品質樣本，具有多種問題類型（例如多選題、填空題等），並提供從中國小學到高中的 12 個年級的詳細解答。具體來說，視覺脈絡可能存在於問題或意見中，這使得這個資料集更具挑戰性。透過全面的分析，我們發現 CMM-Math 資料集上的最先進 LMM 面臨挑戰，強調進一步改進 LMM 開發的必要性。我們還提出了一個多模態數學 LMM (Math-LMM) 來處理多個影像和文字區段混合輸入的問題。我們使用三個階段訓練我們的模型，包括基礎預訓練、基礎微調和數學微調。廣泛的實驗表明，我們的模型透過與三個多模態數學資料集上的 SOTA LMM 進行比較，有效地改進了數學推理效能。</paragraph>

##### **Large Language Model-Based Agents for Software Engineering: A Survey**
2409.02977v1 by Junwei Liu, Kaixin Wang, Yixuan Chen, Xin Peng, Zhenpeng Chen, Lingming Zhang, Yiling Lou

The recent advance in Large Language Models (LLMs) has shaped a new paradigm
of AI agents, i.e., LLM-based agents. Compared to standalone LLMs, LLM-based
agents substantially extend the versatility and expertise of LLMs by enhancing
LLMs with the capabilities of perceiving and utilizing external resources and
tools. To date, LLM-based agents have been applied and shown remarkable
effectiveness in Software Engineering (SE). The synergy between multiple agents
and human interaction brings further promise in tackling complex real-world SE
problems. In this work, we present a comprehensive and systematic survey on
LLM-based agents for SE. We collect 106 papers and categorize them from two
perspectives, i.e., the SE and agent perspectives. In addition, we discuss open
challenges and future directions in this critical domain. The repository of
this survey is at https://github.com/FudanSELab/Agent4SE-Paper-List.

摘要：大型語言模型 (LLM) 的最新進展形塑了人工智慧代理的新典範，亦即基於 LLM 的代理。與獨立的 LLM 相比，基於 LLM 的代理透過強化 LLM 感知和利用外部資源和工具的能力，大幅擴展了 LLM 的多功能性和專業知識。迄今為止，基於 LLM 的代理已應用於軟體工程 (SE)，並展現卓越的成效。多個代理與人類互動的綜效，為解決複雜的真實世界 SE 問題帶來了進一步的希望。在這項工作中，我們針對 SE 的基於 LLM 的代理提出了一項全面且系統性的調查。我們收集了 106 篇論文，並從 SE 和代理兩個觀點對其進行分類。此外，我們討論了這個關鍵領域的開放挑戰和未來方向。這項調查的存放庫位於 https://github.com/FudanSELab/Agent4SE-Paper-List。

##### **MMMU-Pro: A More Robust Multi-discipline Multimodal Understanding Benchmark**
2409.02813v1 by Xiang Yue, Tianyu Zheng, Yuansheng Ni, Yubo Wang, Kai Zhang, Shengbang Tong, Yuxuan Sun, Ming Yin, Botao Yu, Ge Zhang, Huan Sun, Yu Su, Wenhu Chen, Graham Neubig

This paper introduces MMMU-Pro, a robust version of the Massive
Multi-discipline Multimodal Understanding and Reasoning (MMMU) benchmark.
MMMU-Pro rigorously assesses multimodal models' true understanding and
reasoning capabilities through a three-step process based on MMMU: (1)
filtering out questions answerable by text-only models, (2) augmenting
candidate options, and (3) introducing a vision-only input setting where
questions are embedded within images. This setting challenges AI to truly "see"
and "read" simultaneously, testing a fundamental human cognitive skill of
seamlessly integrating visual and textual information. Results show that model
performance is substantially lower on MMMU-Pro than on MMMU, ranging from 16.8%
to 26.9% across models. We explore the impact of OCR prompts and Chain of
Thought (CoT) reasoning, finding that OCR prompts have minimal effect while CoT
generally improves performance. MMMU-Pro provides a more rigorous evaluation
tool, closely mimicking real-world scenarios and offering valuable directions
for future research in multimodal AI.

摘要：本文介紹 MMMU-Pro，這是大規模多領域多模態理解與推理 (MMMU) 評量的強化版本。MMMU-Pro 透過以下基於 MMMU 的三步驟流程，嚴謹評估多模態模型的真正理解與推理能力：(1) 過濾出僅靠文字模型即可回答的問題，(2) 增加候選選項，以及 (3) 引入僅限視覺輸入的設定，其中問題會嵌入在影像中。此設定挑戰 AI 同時「觀看」和「閱讀」，測試人類無縫整合視覺和文字資訊的基本認知技能。結果顯示，模型在 MMMU-Pro 的表現大幅低於 MMMU，各模型的表現範圍從 16.8% 到 26.9%。我們探討 OCR 提示和思考鏈 (CoT) 推理的影響，發現 OCR 提示的影響很小，而 CoT 通常會提升表現。MMMU-Pro 提供更嚴謹的評量工具，能精確模擬真實世界的場景，並為多模態 AI 的未來研究提供有價值的方向。

##### **A hybrid FEM-PINN method for time-dependent partial differential equations**
2409.02810v1 by Xiaodong Feng, Haojiong Shangguan, Tao Tang, Xiaoliang Wan, Tao Zhou

In this work, we present a hybrid numerical method for solving evolution
partial differential equations (PDEs) by merging the time finite element method
with deep neural networks. In contrast to the conventional deep learning-based
formulation where the neural network is defined on a spatiotemporal domain, our
methodology utilizes finite element basis functions in the time direction where
the space-dependent coefficients are defined as the output of a neural network.
We then apply the Galerkin or collocation projection in the time direction to
obtain a system of PDEs for the space-dependent coefficients which is
approximated in the framework of PINN. The advantages of such a hybrid
formulation are twofold: statistical errors are avoided for the integral in the
time direction, and the neural network's output can be regarded as a set of
reduced spatial basis functions. To further alleviate the difficulties from
high dimensionality and low regularity, we have developed an adaptive sampling
strategy that refines the training set. More specifically, we use an explicit
density model to approximate the distribution induced by the PDE residual and
then augment the training set with new time-dependent random samples given by
the learned density model. The effectiveness and efficiency of our proposed
method have been demonstrated through a series of numerical experiments.

摘要：在這項工作中，我們提出了一種混合數值方法，用於通過將時有限元方法與深度神經網路合併來求解演化偏微分方程式 (PDE)。與傳統的深度學習公式不同，其中神經網路定義在時空域上，我們的技術在時間方向上利用有限元基底函數，其中與空間相關的係數定義為神經網路的輸出。然後我們在時間方向上應用 Galerkin 或搭配投影，以獲得時空相關係數的 PDE 系統，該系統在 PINN 框架中得到近似。這種混合公式的優點有兩個：避免了時間方向積分的統計誤差，並且可以將神經網路的輸出視為一組約化的空間基底函數。為了進一步緩解高維度和低規則性的困難，我們開發了一種自適應抽樣策略，用於修正訓練集。更具體地說，我們使用一個明確的密度模型來近似由 PDE residual 誘導的分配，然後使用學習到的密度模型提供的新的時間相關隨機樣本來擴充訓練集。我們提出的方法的有效性和效率已通過一系列數值實驗得到證明。

##### **Towards a Unified View of Preference Learning for Large Language Models: A Survey**
2409.02795v1 by Bofei Gao, Feifan Song, Yibo Miao, Zefan Cai, Zhe Yang, Liang Chen, Helan Hu, Runxin Xu, Qingxiu Dong, Ce Zheng, Wen Xiao, Ge Zhang, Daoguang Zan, Keming Lu, Bowen Yu, Dayiheng Liu, Zeyu Cui, Jian Yang, Lei Sha, Houfeng Wang, Zhifang Sui, Peiyi Wang, Tianyu Liu, Baobao Chang

Large Language Models (LLMs) exhibit remarkably powerful capabilities. One of
the crucial factors to achieve success is aligning the LLM's output with human
preferences. This alignment process often requires only a small amount of data
to efficiently enhance the LLM's performance. While effective, research in this
area spans multiple domains, and the methods involved are relatively complex to
understand. The relationships between different methods have been
under-explored, limiting the development of the preference alignment. In light
of this, we break down the existing popular alignment strategies into different
components and provide a unified framework to study the current alignment
strategies, thereby establishing connections among them. In this survey, we
decompose all the strategies in preference learning into four components:
model, data, feedback, and algorithm. This unified view offers an in-depth
understanding of existing alignment algorithms and also opens up possibilities
to synergize the strengths of different strategies. Furthermore, we present
detailed working examples of prevalent existing algorithms to facilitate a
comprehensive understanding for the readers. Finally, based on our unified
perspective, we explore the challenges and future research directions for
aligning large language models with human preferences.

摘要：大型語言模型 (LLM) 展現了強大的功能。其中一個成功的關鍵因素是將 LLM 的輸出與人類偏好保持一致。此調整過程通常只需要少量資料就能有效提升 LLM 的效能。雖然有效，但這方面的研究橫跨多個領域，且所涉及的方法相對複雜難懂。不同方法之間的關係尚未充分探討，這限制了偏好調整的發展。有鑑於此，我們將現有的熱門調整策略分解成不同的組成部分，並提供一個統一的架構來研究目前的調整策略，從而建立它們之間的聯繫。在此調查中，我們將偏好學習中的所有策略分解成四個組成部分：模型、資料、回饋和演算法。此統一觀點提供了對現有調整演算法的深入了解，也開啟了協調不同策略優勢的可能性。此外，我們提供了現有盛行演算法的詳細工作範例，以促進讀者全面了解。最後，根據我們的統一觀點，我們探討了與人類偏好調整大型語言模型的挑戰和未來的研究方向。

##### **An incremental preference elicitation-based approach to learning potentially non-monotonic preferences in multi-criteria sorting**
2409.02760v1 by Zhuolin Li, Zhen Zhang, Witold Pedrycz

This paper introduces a novel incremental preference elicitation-based
approach to learning potentially non-monotonic preferences in multi-criteria
sorting (MCS) problems, enabling decision makers to progressively provide
assignment example preference information. Specifically, we first construct a
max-margin optimization-based model to model potentially non-monotonic
preferences and inconsistent assignment example preference information in each
iteration of the incremental preference elicitation process. Using the optimal
objective function value of the max-margin optimization-based model, we devise
information amount measurement methods and question selection strategies to
pinpoint the most informative alternative in each iteration within the
framework of uncertainty sampling in active learning. Once the termination
criterion is satisfied, the sorting result for non-reference alternatives can
be determined through the use of two optimization models, i.e., the max-margin
optimization-based model and the complexity controlling optimization model.
Subsequently, two incremental preference elicitation-based algorithms are
developed to learn potentially non-monotonic preferences, considering different
termination criteria. Ultimately, we apply the proposed approach to a credit
rating problem to elucidate the detailed implementation steps, and perform
computational experiments on both artificial and real-world data sets to
compare the proposed question selection strategies with several benchmark
strategies.

摘要：本文提出了一種基於漸進偏好引導的創新方法，用於學習多準則排序 (MCS) 問題中潛在的非單調偏好，使決策者能夠逐步提供指派範例偏好資訊。具體而言，我們首先建構一個基於最大邊際優化的模型，以建模在漸進偏好引導過程的每次反覆運算中潛在的非單調偏好和不一致的指派範例偏好資訊。使用基於最大邊際優化的模型的最佳目標函數值，我們設計資訊量測量方法和問題選擇策略，以在主動學習的不確定性抽樣架構中精確找出每次反覆運算中最具資訊性的替代方案。一旦滿足終止準則，就可以透過使用兩個最佳化模型（即基於最大邊際優化的模型和複雜度控制最佳化模型）來確定非參考替代方案的排序結果。隨後，開發了兩種基於漸進偏好引導的演算法來學習潛在的非單調偏好，考量不同的終止準則。最後，我們將提出的方法應用於信用評級問題，以闡明詳細的實作步驟，並針對人工和真實世界資料集執行運算實驗，以將提出的問題選擇策略與多個基準策略進行比較。

##### **A Comparative Study of Pre-training and Self-training**
2409.02751v1 by Yiheng Wang, Jiayu Lin, Zuoquan Lin

Pre-training and self-training are two approaches to semi-supervised
learning. The comparison between pre-training and self-training has been
explored. However, the previous works led to confusing findings: self-training
outperforms pre-training experienced on some tasks in computer vision, and
contrarily, pre-training outperforms self-training experienced on some tasks in
natural language processing, under certain conditions of incomparable settings.
We propose, comparatively and exhaustively, an ensemble method to empirical
study all feasible training paradigms combining pre-training, self-training,
and fine-tuning within consistent foundational settings comparable to data
augmentation. We conduct experiments on six datasets, four data augmentation,
and imbalanced data for sentiment analysis and natural language inference
tasks. Our findings confirm that the pre-training and fine-tuning paradigm
yields the best overall performances. Moreover, self-training offers no
additional benefits when combined with semi-supervised pre-training.

摘要：預訓練和自訓練是半監督式學習的兩種方法。預訓練和自訓練之間的比較已經被探討過。然而，先前的研究導致令人困惑的發現：在某些電腦視覺任務中，自訓練優於預訓練，相反地，在某些自然語言處理任務中，預訓練優於自訓練，在某些無法比較的設定條件下。我們提出一個整體方法，比較並詳盡地進行經驗研究，在與資料擴充相當的一致基礎設定中，結合預訓練、自訓練和微調的所有可行訓練範例。我們對六個資料集、四種資料擴充和不平衡資料進行了情緒分析和自然語言推論任務的實驗。我們的發現證實預訓練和微調範例產生了最佳的整體表現。此外，自訓練與半監督式預訓練結合時，沒有提供額外的優點。

##### **Tractable Offline Learning of Regular Decision Processes**
2409.02747v1 by Ahana Deb, Roberto Cipollone, Anders Jonsson, Alessandro Ronca, Mohammad Sadegh Talebi

This work studies offline Reinforcement Learning (RL) in a class of
non-Markovian environments called Regular Decision Processes (RDPs). In RDPs,
the unknown dependency of future observations and rewards from the past
interactions can be captured by some hidden finite-state automaton. For this
reason, many RDP algorithms first reconstruct this unknown dependency using
automata learning techniques. In this paper, we show that it is possible to
overcome two strong limitations of previous offline RL algorithms for RDPs,
notably RegORL. This can be accomplished via the introduction of two original
techniques: the development of a new pseudometric based on formal languages,
which removes a problematic dependency on
$L_\infty^\mathsf{p}$-distinguishability parameters, and the adoption of
Count-Min-Sketch (CMS), instead of naive counting. The former reduces the
number of samples required in environments that are characterized by a low
complexity in language-theoretic terms. The latter alleviates the memory
requirements for long planning horizons. We derive the PAC sample complexity
bounds associated to each of these techniques, and we validate the approach
experimentally.

摘要：本研究探討非馬可夫環境中的一類離線強化學習 (RL)，稱為規則決策過程 (RDP)。在 RDP 中，未來觀察和獎勵對過去互動的未知依賴性可以由一些隱藏的有限狀態自動機捕獲。因此，許多 RDP 演算法會先使用自動機學習技術重建此未知依賴性。在本文中，我們證明可以克服先前 RDP 離線 RL 演算法的兩個重大限制，特別是 RegORL。這可以透過導入兩種原始技術來達成：基於形式語言開發新的偽度量，這消除了對$L_\infty^\mathsf{p}$可區分性參數的有問題依賴性，以及採用 Count-Min-Sketch (CMS) 代替天真的計數。前者減少了在語言理論術語中以低複雜度為特徵的環境中所需的樣本數量。後者減輕了長期規劃範圍的記憶體需求。我們推導出與這些技術相關的 PAC 樣本複雜度界限，並透過實驗驗證方法。

##### **Pooling And Attention: What Are Effective Designs For LLM-Based Embedding Models?**
2409.02727v2 by Yixuan Tang, Yi Yang

The significant advancements of Large Language Models (LLMs) in generative
tasks have led to a growing body of work exploring LLM-based embedding models.
While these models, employing different pooling and attention strategies, have
achieved state-of-the-art performance on public embedding benchmarks, questions
still arise about what constitutes an effective design for LLM-based embedding
models. However, these models are often trained on different datasets, using
different LLM base models or training settings. Moreover, evaluations on public
embedding benchmarks often fail to report statistical significance, making it
difficult to determine which designs truly contribute to final performance.
This complicates the process for practitioners seeking optimal training recipes
for LLM-based embedding models. In this study, we conduct a large-scale
experiment by training a series of LLM-based embedding models using the same
training data and base model but differing in their pooling and attention
strategies. The results show that there is no one-size-fits-all solution: while
bidirectional attention and an additional trainable pooling layer outperform in
text similarity and information retrieval tasks, they do not significantly
surpass simpler designs like EOS-last token pooling and default causal
attention in clustering and classification tasks. Furthermore, we propose a new
pooling strategy, Multi-Layers Trainable Pooling, which transforms the outputs
of all hidden layers, rather than just the last layer, using a cross-attention
network. This method proves to be statistically superior in text similarity and
retrieval tasks compared to existing pooling methods. Overall, this paper sheds
light on effective training strategies for LLM-based embedding models.

摘要：大型語言模型 (LLM) 在生成任務中的顯著進展，導致了越來越多研究探索基於 LLM 的嵌入模型。
雖然這些模型採用不同的匯總和注意力策略，已在公開嵌入基準測試中達到最先進的性能，但關於什麼構成了基於 LLM 的嵌入模型的有效設計，仍然存在疑問。
然而，這些模型通常在不同的資料集上訓練，使用不同的 LLM 基礎模型或訓練設定。
此外，對公開嵌入基準測試的評估通常未能報告統計顯著性，這使得難以確定哪些設計真正有助於最終性能。
這使得從業者尋求基於 LLM 的嵌入模型的最佳訓練配方變得複雜。
在本研究中，我們通過使用相同的訓練資料和基礎模型，但匯總和注意力策略不同的訓練一系列基於 LLM 的嵌入模型，進行了大規模實驗。
結果表明，沒有通用的解決方案：雖然雙向注意力和一個額外的可訓練匯總層在文本相似性和資訊檢索任務中表現出色，但它們並沒有顯著超過在聚類和分類任務中較簡單的設計，例如 EOS 最後標記匯總和預設因果注意力。
此外，我們提出了一種新的匯總策略，多層可訓練匯總，它使用交叉注意力網路轉換所有隱藏層的輸出，而不仅仅是最後一層。
與現有的匯總方法相比，這種方法在文本相似性和檢索任務中被證明具有統計優勢。
總的來說，本文闡明了基於 LLM 的嵌入模型的有效訓練策略。

##### **Pre-training data selection for biomedical domain adaptation using journal impact metrics**
2409.02725v1 by Mathieu Laï-king, Patrick Paroubek

Domain adaptation is a widely used method in natural language processing
(NLP) to improve the performance of a language model within a specific domain.
This method is particularly common in the biomedical domain, which sees regular
publication of numerous scientific articles. PubMed, a significant corpus of
text, is frequently used in the biomedical domain. The primary objective of
this study is to explore whether refining a pre-training dataset using specific
quality metrics for scientific papers can enhance the performance of the
resulting model. To accomplish this, we employ two straightforward journal
impact metrics and conduct experiments by continually pre-training BERT on
various subsets of the complete PubMed training set, we then evaluate the
resulting models on biomedical language understanding tasks from the BLURB
benchmark. Our results show that pruning using journal impact metrics is not
efficient. But we also show that pre-training using fewer abstracts (but with
the same number of training steps) does not necessarily decrease the resulting
model's performance.

摘要：領域適應是一種廣泛用於自然語言處理 (NLP) 中的方法，用於提升語言模型在特定領域中的表現。
此方法特別常在生物醫學領域中使用，該領域會定期發表許多科學文章。PubMed 是生物醫學領域中一個重要的語料庫，經常被使用。
本研究的主要目標是探討使用特定科學論文品質指標來精煉預訓練資料集，是否能提升所產生的模型的表現。
為達成此目標，我們採用兩個簡單的期刊影響力指標，並透過持續在 PubMed 完整訓練集的各種子集上預訓練 BERT 來進行實驗，然後在 BLURB 基準中的生物醫學語言理解任務上評估所產生的模型。
我們的結果顯示，使用期刊影響力指標進行剪枝並非有效率。
但我們也顯示，使用較少的摘要 (但訓練步驟數相同) 進行預訓練，並不會一定會降低所產生的模型的表現。

##### **Hallucination Detection in LLMs: Fast and Memory-Efficient Finetuned Models**
2409.02976v1 by Gabriel Y. Arteaga, Thomas B. Schön, Nicolas Pielawski

Uncertainty estimation is a necessary component when implementing AI in
high-risk settings, such as autonomous cars, medicine, or insurances. Large
Language Models (LLMs) have seen a surge in popularity in recent years, but
they are subject to hallucinations, which may cause serious harm in high-risk
settings. Despite their success, LLMs are expensive to train and run: they need
a large amount of computations and memory, preventing the use of ensembling
methods in practice. In this work, we present a novel method that allows for
fast and memory-friendly training of LLM ensembles. We show that the resulting
ensembles can detect hallucinations and are a viable approach in practice as
only one GPU is needed for training and inference.

摘要：不確定性估計是實作 AI 於高風險設定時必要的組成部分，例如自動駕駛汽車、醫學或保險。大型語言模型 (LLM) 近年來已大幅普及，但它們會出現幻覺，這可能會對高風險設定造成嚴重傷害。儘管 LLM 成功，但訓練和執行成本卻很昂貴：它們需要大量的運算和記憶體，這會在實務上阻礙使用合奏方法。在本研究中，我們提出了一種新方法，允許快速且節省記憶體地訓練 LLM 合奏。我們展示所得的合奏可以偵測幻覺，並且是一種可行的實務方法，因為訓練和推論僅需要一個 GPU。

##### **Alignment-Aware Model Extraction Attacks on Large Language Models**
2409.02718v1 by Zi Liang, Qingqing Ye, Yanyun Wang, Sen Zhang, Yaxin Xiao, Ronghua Li, Jianliang Xu, Haibo Hu

Model extraction attacks (MEAs) on large language models (LLMs) have received
increasing research attention lately. Existing attack methods on LLMs inherit
the extraction strategies from those designed for deep neural networks (DNNs)
yet neglect the inconsistency of training tasks between MEA and LLMs'
alignments. As such, they result in poor attack performances. To tackle this
issue, we present Locality Reinforced Distillation (LoRD), a novel model
extraction attack algorithm specifically for LLMs. In particular, we design a
policy-gradient-style training task, which utilizes victim models' responses as
a signal to guide the crafting of preference for the local model. Theoretical
analysis has shown that i) LoRD's convergence procedure in MEAs is consistent
with the alignments of LLMs, and ii) LoRD can reduce query complexity while
mitigating watermark protection through exploration-based stealing. Extensive
experiments on domain-specific extractions demonstrate the superiority of our
method by examining the extraction of various state-of-the-art commercial LLMs.

摘要：大型語言模型 (LLM) 上的模型萃取攻擊 (MEA) 近來受到越來越多的研究關注。現有的 LLM 攻擊方法承襲了為深度神經網路 (DNN) 設計的萃取策略，但忽略了 MEA 與 LLM 對齊之間的訓練任務不一致性。因此，它們導致攻擊效能不佳。為了解決這個問題，我們提出了 Locality Reinforced Distillation (LoRD)，這是一種專門針對 LLM 的新型態模型萃取攻擊演算法。特別是，我們設計了一種策略梯度樣式的訓練任務，它利用受害者模型的回應作為引導偏好製作本地模型的訊號。理論分析顯示，i) LoRD 在 MEA 中的收斂程序與 LLM 的對齊一致，以及 ii) LoRD 可以透過探索式竊取降低查詢複雜度，同時減輕浮水印保護。針對特定領域萃取的廣泛實驗，透過檢視各種最先進的商業 LLM 的萃取，證明了我們方法的優越性。

##### **A Data Selection Approach for Enhancing Low Resource Machine Translation Using Cross-Lingual Sentence Representations**
2409.02712v1 by Nidhi Kowtal, Tejas Deshpande, Raviraj Joshi

Machine translation in low-resource language pairs faces significant
challenges due to the scarcity of parallel corpora and linguistic resources.
This study focuses on the case of English-Marathi language pairs, where
existing datasets are notably noisy, impeding the performance of machine
translation models. To mitigate the impact of data quality issues, we propose a
data filtering approach based on cross-lingual sentence representations. Our
methodology leverages a multilingual SBERT model to filter out problematic
translations in the training data. Specifically, we employ an IndicSBERT
similarity model to assess the semantic equivalence between original and
translated sentences, allowing us to retain linguistically correct translations
while discarding instances with substantial deviations. The results demonstrate
a significant improvement in translation quality over the baseline
post-filtering with IndicSBERT. This illustrates how cross-lingual sentence
representations can reduce errors in machine translation scenarios with limited
resources. By integrating multilingual sentence BERT models into the
translation pipeline, this research contributes to advancing machine
translation techniques in low-resource environments. The proposed method not
only addresses the challenges in English-Marathi language pairs but also
provides a valuable framework for enhancing translation quality in other
low-resource language translation tasks.

摘要：機器翻譯在低資源語言配對中由於平行語料和語言資源的稀缺而面臨重大挑戰。這項研究專注於英語-馬拉提語語言配對，其中現有的資料集明顯有雜訊，阻礙了機器翻譯模型的執行。為了減輕資料品質問題的影響，我們提出一個基於跨語言句子表示的資料過濾方法。我們的做法利用多語言 SBERT 模型來過濾掉訓練資料中的有問題翻譯。具體來說，我們採用 IndicSBERT 相似性模型來評估原始句子和翻譯句子的語義等效性，讓我們得以保留語言上正確的翻譯，同時捨棄有重大偏差的實例。結果表明，使用 IndicSBERT 過濾後翻譯品質大幅提升。這說明了跨語言句子表示如何能減少資源有限的機器翻譯場景中的錯誤。藉由將多語言句子 BERT 模型整合到翻譯管道中，這項研究有助於推進低資源環境中的機器翻譯技術。所提議的方法不僅解決了英語-馬拉提語語言配對中的挑戰，也提供了一個有價值的架構，用於提升其他低資源語言翻譯任務的翻譯品質。

##### **Creating a Gen-AI based Track and Trace Assistant MVP (SuperTracy) for PostNL**
2409.02711v1 by Mohammad Reshadati

The developments in the field of generative AI has brought a lot of
opportunities for companies, for instance to improve efficiency in customer
service and automating tasks. PostNL, the biggest parcel and E-commerce
corporation of the Netherlands wants to use generative AI to enhance the
communication around track and trace of parcels. During the internship a
Minimal Viable Product (MVP) is created to showcase the value of using
generative AI technologies, to enhance parcel tracking, analyzing the parcel's
journey and being able to communicate about it in an easy to understand manner.
The primary goal was to develop an in-house LLM-based system, reducing
dependency on external platforms and establishing the feasibility of a
dedicated generative AI team within the company. This multi-agent LLM based
system aimed to construct parcel journey stories and identify logistical
disruptions with heightened efficiency and accuracy. The research involved
deploying a sophisticated AI-driven communication system, employing
Retrieval-Augmented Generation (RAG) for enhanced response precision, and
optimizing large language models (LLMs) tailored to domain specific tasks.
  The MVP successfully implemented a multi-agent open-source LLM system, called
SuperTracy. SuperTracy is capable of autonomously managing a broad spectrum of
user inquiries and improving internal knowledge handling. Results and
evaluation demonstrated technological innovation and feasibility, notably in
communication about the track and trace of a parcel, which exceeded initial
expectations. These advancements highlight the potential of AI-driven solutions
in logistics, suggesting many opportunities for further refinement and broader
implementation within PostNL operational framework.

摘要：<paragraph>生成式 AI 領域的發展為企業帶來許多機會，例如提升客服效率和自動化任務。荷蘭最大的包裹和電子商務公司 PostNL 希望使用生成式 AI 來加強包裹追蹤的溝通。實習期間，建立一個可行性最低產品 (MVP) 以展示使用生成式 AI 技術的價值，以加強包裹追蹤、分析包裹旅程並能夠以易於理解的方式進行溝通。主要目標是開發一個內部 LLM 為基礎的系統，減少對外部平台的依賴，並建立公司內專門的生成式 AI 團隊的可行性。這個多代理的 LLM 為基礎的系統旨在建構包裹旅程故事並識別後勤中斷，且效率和準確性都更高。研究涉及部署一個由 AI 驅動的先進溝通系統，採用檢索增強生成 (RAG) 以增強回應的精準度，並針對特定領域任務最佳化大型語言模型 (LLM)。MVP 成功實施了一個多代理的開源 LLM 系統，稱為 SuperTracy。SuperTracy 能夠自主管理廣泛的使用者詢問，並改善內部知識處理。結果和評估證明了技術創新和可行性，特別是在包裹追蹤的溝通方面，超出了最初的預期。這些進展突顯了 AI 驅動解決方案在物流方面的潛力，這表示有許多機會可以進一步改善並在 PostNL 的營運架構中更廣泛地實施。</paragraph>

##### **Incorporating Like-Minded Peers to Overcome Friend Data Sparsity in Session-Based Social Recommendations**
2409.02702v1 by Chunyan An, Yunhan Li, Qiang Yang, Winston K. G. Seah, Zhixu Li, Conghao Yanga

Session-based Social Recommendation (SSR) leverages social relationships
within online networks to enhance the performance of Session-based
Recommendation (SR). However, existing SSR algorithms often encounter the
challenge of ``friend data sparsity''. Moreover, significant discrepancies can
exist between the purchase preferences of social network friends and those of
the target user, reducing the influence of friends relative to the target
user's own preferences. To address these challenges, this paper introduces the
concept of ``Like-minded Peers'' (LMP), representing users whose preferences
align with the target user's current session based on their historical
sessions. This is the first work, to our knowledge, that uses LMP to enhance
the modeling of social influence in SSR. This approach not only alleviates the
problem of friend data sparsity but also effectively incorporates users with
similar preferences to the target user. We propose a novel model named
Transformer Encoder with Graph Attention Aggregator Recommendation (TEGAARec),
which includes the TEGAA module and the GAT-based social aggregation module.
The TEGAA module captures and merges both long-term and short-term interests
for target users and LMP users. Concurrently, the GAT-based social aggregation
module is designed to aggregate the target users' dynamic interests and social
influence in a weighted manner. Extensive experiments on four real-world
datasets demonstrate the efficacy and superiority of our proposed model and
ablation studies are done to illustrate the contributions of each component in
TEGAARec.

摘要：<paragraph>基於會話的社交推薦 (SSR) 利用線上網路中的社交關係來提升基於會話的推薦 (SR) 的效能。然而，現有的 SSR 演算法經常會遭遇「好友資料稀疏性」的挑戰。此外，社交網路好友的購買偏好與目標使用者之間可能存在顯著差異，降低了好友相對於目標使用者自身偏好的影響力。為了應對這些挑戰，本文引入了「志同道合的同儕」(LMP) 的概念，代表其偏好與目標使用者基於其歷史會話的當前會話相符的使用者。據我們所知，這是第一個使用 LMP 來增強 SSR 中社交影響力建模的研究。這種方法不僅可以緩解好友資料稀疏性的問題，還能有效地納入與目標使用者具有類似偏好的使用者。我們提出了一個名為 Transformer 編碼器與圖形注意力聚合器推薦 (TEGAARec) 的新模型，其中包括 TEGAA 模組和基於 GAT 的社交聚合模組。TEGAA 模組擷取並合併目標使用者和 LMP 使用者的長期和短期興趣。同時，基於 GAT 的社交聚合模組旨在以加權方式聚合目標使用者的動態興趣和社交影響力。在四個真實世界的資料集上進行的廣泛實驗證明了我們提出的模型的有效性和優越性，並進行了消融研究來說明 TEGAARec 中每個組成的貢獻。</paragraph>

##### **LLM-Assisted Visual Analytics: Opportunities and Challenges**
2409.02691v1 by Maeve Hutchinson, Radu Jianu, Aidan Slingsby, Pranava Madhyastha

We explore the integration of large language models (LLMs) into visual
analytics (VA) systems to transform their capabilities through intuitive
natural language interactions. We survey current research directions in this
emerging field, examining how LLMs are integrated into data management,
language interaction, visualisation generation, and language generation
processes. We highlight the new possibilities that LLMs bring to VA, especially
how they can change VA processes beyond the usual use cases. We especially
highlight building new visualisation-language models, allowing access of a
breadth of domain knowledge, multimodal interaction, and opportunities with
guidance. Finally, we carefully consider the prominent challenges of using
current LLMs in VA tasks. Our discussions in this paper aim to guide future
researchers working on LLM-assisted VA systems and help them navigate common
obstacles when developing these systems.

摘要：我們探討將大型語言模型 (LLM) 整合到視覺分析 (VA) 系統中，以透過直觀的自然語言互動來轉換其功能。我們調查這個新興領域中當前的研究方向，探討 LLM 如何整合到資料管理、語言互動、視覺化產生和語言產生過程中。我們重點說明 LLM 為 VA 帶來的各種新可能性，特別是它們如何改變 VA 過程，超越一般常見的用例。我們特別強調建立新的視覺化語言模型，允許存取廣泛的領域知識、多模態互動和指導機會。最後，我們仔細考量在 VA 任務中使用目前 LLM 的顯著挑戰。我們在本文中的討論旨在引導未來研究人員從事 LLM 輔助的 VA 系統，並幫助他們在開發這些系統時克服常見的障礙。

##### **Detecting Calls to Action in Multimodal Content: Analysis of the 2021 German Federal Election Campaign on Instagram**
2409.02690v1 by Michael Achmann-Denkler, Jakob Fehle, Mario Haim, Christian Wolff

This study investigates the automated classification of Calls to Action
(CTAs) within the 2021 German Instagram election campaign to advance the
understanding of mobilization in social media contexts. We analyzed over 2,208
Instagram stories and 712 posts using fine-tuned BERT models and OpenAI's GPT-4
models. The fine-tuned BERT model incorporating synthetic training data
achieved a macro F1 score of 0.93, demonstrating a robust classification
performance. Our analysis revealed that 49.58% of Instagram posts and 10.64% of
stories contained CTAs, highlighting significant differences in mobilization
strategies between these content types. Additionally, we found that FDP and the
Greens had the highest prevalence of CTAs in posts, whereas CDU and CSU led in
story CTAs.

摘要：本研究調查 2021 年德國 Instagram 選舉活動中行動呼籲 (CTA) 的自動分類，以促進對社交媒體背景中動員的理解。我們使用微調後的 BERT 模型和 OpenAI 的 GPT-4 模型分析了超過 2,208 個 Instagram 限時動態和 712 篇貼文。結合合成訓練資料的微調 BERT 模型達到了 0.93 的巨觀 F1 分數，證明了穩健的分類效能。我們的分析顯示，49.58% 的 Instagram 貼文和 10.64% 的限時動態包含 CTA，突顯了這些內容類型之間動員策略的顯著差異。此外，我們發現 FDP 和綠黨在貼文中 CTA 的盛行率最高，而 CDU 和 CSU 則在限時動態 CTA 中領先。

##### **Deconfounded Causality-aware Parameter-Efficient Fine-Tuning for Problem-Solving Improvement of LLMs**
2409.02686v1 by Ruoyu Wang, Xiaoxuan Li, Lina Yao

Large Language Models (LLMs) have demonstrated remarkable efficiency in
tackling various tasks based on human instructions, but recent studies reveal
that these models often fail to achieve satisfactory results on questions
involving reasoning, such as mathematics or physics questions. This phenomenon
is usually attributed to the uncertainty regarding whether these models could
genuinely comprehend the knowledge embedded in the text or merely learn to
replicate the token distribution without a true understanding of the content.
In this paper, we delve into this problem and aim to enhance the reasoning
capabilities of LLMs. First, we investigate if the model has genuine reasoning
capabilities by visualizing the text generation process at the attention and
representation level. Then, we formulate the reasoning process of LLMs into a
causal framework, which provides a formal explanation of the problems we
observe in the visualization. Finally, building upon this causal framework, we
propose Deconfounded Causal Adaptation (DCA), a novel parameter-efficient
fine-tuning (PEFT) method to enhance the model's reasoning capabilities by
encouraging the model to extract the general problem-solving skills and apply
these skills to different questions. Experiments show that our method
outperforms the baseline consistently across multiple benchmarks, and with only
1.2M tunable parameters, we achieve better or comparable results to other
fine-tuning methods. This demonstrates the effectiveness and efficiency of our
method in improving the overall accuracy and reliability of LLMs.

摘要：大型語言模型 (LLM) 已證明在根據人類指示處理各種任務方面具有顯著的效率，但最近的研究表明，這些模型在涉及推理的問題（例如數學或物理問題）上常常無法獲得令人滿意的結果。這種現象通常歸因於不確定性，即這些模型是否可以真正理解嵌入在文本中的知識，或者僅僅學會複製符號分佈而沒有真正理解內容。在本文中，我們深入探討這個問題，並旨在增強 LLM 的推理能力。首先，我們通過在關注和表示層面視覺化文本生成過程，來調查模型是否具有真正的推理能力。然後，我們將 LLM 的推理過程制定為因果框架，這對我們在視覺化中觀察到的問題提供了正式解釋。最後，在此因果框架的基礎上，我們提出了去混淆因果適應 (DCA)，這是一種新穎的參數高效微調 (PEFT) 方法，通過鼓勵模型提取一般問題解決技能並將這些技能應用於不同的問題，來增強模型的推理能力。實驗表明，我們的模型在多個基準上始終優於基準，並且僅使用 120 萬個可調參數，我們就獲得了比其他微調方法更好或相當的結果。這證明了我們的方法在提高 LLM 的整體準確性和可靠性方面的有效性和效率。

##### **RouterRetriever: Exploring the Benefits of Routing over Multiple Expert Embedding Models**
2409.02685v1 by Hyunji Lee, Luca Soldaini, Arman Cohan, Minjoon Seo, Kyle Lo

Information retrieval methods often rely on a single embedding model trained
on large, general-domain datasets like MSMARCO. While this approach can produce
a retriever with reasonable overall performance, models trained on
domain-specific data often yield better results within their respective
domains. While prior work in information retrieval has tackled this through
multi-task training, the topic of combining multiple domain-specific expert
retrievers remains unexplored, despite its popularity in language model
generation. In this work, we introduce RouterRetriever, a retrieval model that
leverages multiple domain-specific experts along with a routing mechanism to
select the most appropriate expert for each query. It is lightweight and allows
easy addition or removal of experts without additional training. Evaluation on
the BEIR benchmark demonstrates that RouterRetriever outperforms both
MSMARCO-trained (+2.1 absolute nDCG@10) and multi-task trained (+3.2) models.
This is achieved by employing our routing mechanism, which surpasses other
routing techniques (+1.8 on average) commonly used in language modeling.
Furthermore, the benefit generalizes well to other datasets, even in the
absence of a specific expert on the dataset. To our knowledge, RouterRetriever
is the first work to demonstrate the advantages of using multiple
domain-specific expert embedding models with effective routing over a single,
general-purpose embedding model in retrieval tasks.

摘要：資訊檢索方法通常依賴於大型通用領域資料集（例如 MSMARCO）上訓練的單一嵌入模型。雖然這種方法可以產生具有合理整體效能的檢索器，但針對特定領域資料訓練的模型通常會在其各自的領域中產生更好的結果。雖然先前的資訊檢索工作已透過多任務訓練來解決此問題，但儘管在語言模型產生中很受歡迎，結合多個特定領域專家檢索器的議題仍未被探討。在這項工作中，我們介紹 RouterRetriever，這是一個檢索模型，它利用多個特定領域專家以及路由機制來為每個查詢選擇最合適的專家。它很輕量，且允許輕鬆新增或移除專家，而無需額外訓練。在 BEIR 基準上的評估顯示，RouterRetriever 優於 MSMARCO 訓練的（+2.1 絕對 nDCG@10）和多任務訓練的（+3.2）模型。這是透過採用我們的路由機制來實現的，該機制優於語言建模中常用的其他路由技術（平均 +1.8）。此外，這種優點很好地推廣到其他資料集，即使在資料集中沒有特定專家的情況下也是如此。據我們所知，RouterRetriever 是第一個展示在檢索任務中使用多個特定領域專家嵌入模型與有效路由優於單一通用嵌入模型的優點的工作。

