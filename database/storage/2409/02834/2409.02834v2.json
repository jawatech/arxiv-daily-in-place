{"2409.02834": {"publish_time": "2024-09-04", "title": "CMM-Math: A Chinese Multimodal Math Dataset To Evaluate and Enhance the Mathematics Reasoning of Large Multimodal Models", "paper_summary": "Large language models (LLMs) have obtained promising results in mathematical\nreasoning, which is a foundational skill for human intelligence. Most previous\nstudies focus on improving and measuring the performance of LLMs based on\ntextual math reasoning datasets (e.g., MATH, GSM8K). Recently, a few\nresearchers have released English multimodal math datasets (e.g., MATHVISTA and\nMATH-V) to evaluate the effectiveness of large multimodal models (LMMs). In\nthis paper, we release a Chinese multimodal math (CMM-Math) dataset, including\nbenchmark and training parts, to evaluate and enhance the mathematical\nreasoning of LMMs. CMM-Math contains over 28,000 high-quality samples,\nfeaturing a variety of problem types (e.g., multiple-choice, fill-in-the-blank,\nand so on) with detailed solutions across 12 grade levels from elementary to\nhigh school in China. Specifically, the visual context may be present in the\nquestions or opinions, which makes this dataset more challenging. Through\ncomprehensive analysis, we discover that state-of-the-art LMMs on the CMM-Math\ndataset face challenges, emphasizing the necessity for further improvements in\nLMM development. We also propose a Multimodal Mathematical LMM (Math-LMM) to\nhandle the problems with mixed input of multiple images and text segments. We\ntrain our model using three stages, including foundational pre-training,\nfoundational fine-tuning, and mathematical fine-tuning. The extensive\nexperiments indicate that our model effectively improves math reasoning\nperformance by comparing it with the SOTA LMMs over three multimodal\nmathematical datasets.", "paper_summary_zh": "<paragraph>\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u5728\u6578\u5b78\u63a8\u7406\u65b9\u9762\u53d6\u5f97\u4e86\u53ef\u559c\u7684\u6210\u679c\uff0c\u800c\u6578\u5b78\u63a8\u7406\u662f\u4eba\u985e\u667a\u80fd\u7684\u4e00\u9805\u57fa\u790e\u6280\u80fd\u3002\u5927\u591a\u6578\u5148\u524d\u7684\u7814\u7a76\u90fd\u5c08\u6ce8\u65bc\u6539\u9032\u548c\u8a55\u91cf LLM \u5728\u57fa\u65bc\u6587\u5b57\u6578\u5b78\u63a8\u7406\u8cc7\u6599\u96c6 (\u4f8b\u5982 MATH\u3001GSM8K) \u4e0a\u7684\u8868\u73fe\u3002\u6700\u8fd1\uff0c\u4e00\u4e9b\u7814\u7a76\u4eba\u54e1\u767c\u5e03\u4e86\u82f1\u6587\u591a\u6a21\u614b\u6578\u5b78\u8cc7\u6599\u96c6 (\u4f8b\u5982 MATHVISTA \u548c MATH-V) \u4f86\u8a55\u4f30\u5927\u578b\u591a\u6a21\u614b\u6a21\u578b (LMM) \u7684\u6548\u80fd\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u767c\u5e03\u4e86\u4e00\u500b\u4e2d\u6587\u591a\u6a21\u614b\u6578\u5b78 (CMM-Math) \u8cc7\u6599\u96c6\uff0c\u5305\u62ec\u57fa\u6e96\u548c\u8a13\u7df4\u90e8\u5206\uff0c\u7528\u65bc\u8a55\u4f30\u548c\u589e\u5f37 LMM \u7684\u6578\u5b78\u63a8\u7406\u80fd\u529b\u3002CMM-Math \u5305\u542b\u8d85\u904e 28,000 \u500b\u9ad8\u54c1\u8cea\u7bc4\u4f8b\uff0c\u5177\u5099\u5404\u7a2e\u554f\u984c\u985e\u578b (\u4f8b\u5982\u591a\u91cd\u9078\u64c7\u3001\u586b\u7a7a\u7b49)\uff0c\u4e26\u63d0\u4f9b\u5f9e\u4e2d\u570b\u5c0f\u5b78\u5230\u9ad8\u4e2d\u7684 12 \u500b\u5e74\u7d1a\u7684\u8a73\u7d30\u89e3\u7b54\u3002\u5177\u9ad4\u4f86\u8aaa\uff0c\u8996\u89ba\u8108\u7d61\u53ef\u80fd\u51fa\u73fe\u5728\u554f\u984c\u6216\u610f\u898b\u4e2d\uff0c\u9019\u4f7f\u5f97\u9019\u500b\u8cc7\u6599\u96c6\u66f4\u5177\u6311\u6230\u6027\u3002\u900f\u904e\u5168\u9762\u7684\u5206\u6790\uff0c\u6211\u5011\u767c\u73fe CMM-Math \u8cc7\u6599\u96c6\u4e0a\u7684\u6700\u65b0 LMM \u9762\u81e8\u6311\u6230\uff0c\u5f37\u8abf\u9032\u4e00\u6b65\u6539\u9032 LMM \u958b\u767c\u7684\u5fc5\u8981\u6027\u3002\u6211\u5011\u9084\u63d0\u51fa\u4e86\u4e00\u500b\u591a\u6a21\u614b\u6578\u5b78 LMM (Math-LMM) \u4f86\u8655\u7406\u591a\u500b\u5f71\u50cf\u548c\u6587\u5b57\u7247\u6bb5\u6df7\u5408\u8f38\u5165\u7684\u554f\u984c\u3002\u6211\u5011\u4f7f\u7528\u4e09\u500b\u968e\u6bb5\u4f86\u8a13\u7df4\u6211\u5011\u7684\u6a21\u578b\uff0c\u5305\u62ec\u57fa\u790e\u9810\u8a13\u7df4\u3001\u57fa\u790e\u5fae\u8abf\u548c\u6578\u5b78\u5fae\u8abf\u3002\u5ee3\u6cdb\u7684\u5be6\u9a57\u8868\u660e\uff0c\u6211\u5011\u7684\u6a21\u578b\u900f\u904e\u8207\u4e09\u500b\u591a\u6a21\u614b\u6578\u5b78\u8cc7\u6599\u96c6\u4e0a\u7684 SOTA LMM \u6bd4\u8f03\uff0c\u6709\u6548\u5730\u6539\u9032\u4e86\u6578\u5b78\u63a8\u7406\u8868\u73fe\u3002</paragraph>", "author": "Wentao Liu et.al.", "authors": "Wentao Liu, Qianjun Pan, Yi Zhang, Zhuo Liu, Ji Wu, Jie Zhou, Aimin Zhou, Qin Chen, Bo Jiang, Liang He", "id": "2409.02834v2", "paper_url": "http://arxiv.org/abs/2409.02834v2", "repo": "null"}}