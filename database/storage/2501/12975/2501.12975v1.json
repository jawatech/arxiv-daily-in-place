{"2501.12975": {"publish_time": "2025-01-22", "title": "OnionEval: An Unified Evaluation of Fact-conflicting Hallucination for Small-Large Language Models", "paper_summary": "Large Language Models (LLMs) are highly capable but require significant\ncomputational resources for both training and inference. Within the LLM family,\nsmaller models (those with fewer than 10 billion parameters) also perform well\nacross various tasks. However, these smaller models share similar limitations\nto their larger counterparts, including the tendency to hallucinate. Despite\nthe existence of many benchmarks to evaluate hallucination in LLMs, few have\nspecifically focused on small LLMs (SLLMs). Additionally, SLLMs show widely\nvarying performance across different benchmarks. In this paper, we introduce\nOnionEval, a multi-layer structured framework with a specific metric called the\ncontext-influence score (CI), designed to effectively assess the\nfact-conflicting hallucination tendencies of small LLMs across different\ncontextual levels. Our experimental results reveal a key feature of SLLMs: they\nexcel in factual analysis but face challenges with context reasoning. Further\ninvestigation shows that a simple Chain-of-Thought strategy can significantly\nreduce these limitations, improving the practical usefulness of SLLMs in\nreal-world applications.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u7684\u80fd\u529b\u6975\u5f37\uff0c\u4f46\u7121\u8ad6\u662f\u5728\u8a13\u7df4\u6216\u63a8\u7406\u4e0a\uff0c\u90fd\u9700\u8981\u5927\u91cf\u7684\u904b\u7b97\u8cc7\u6e90\u3002\u5728 LLM \u5bb6\u65cf\u4e2d\uff0c\u8f03\u5c0f\u7684\u6a21\u578b\uff08\u53c3\u6578\u5c11\u65bc 100 \u5104\u500b\uff09\u4e5f\u80fd\u5728\u5404\u7a2e\u4efb\u52d9\u4e2d\u8868\u73fe\u826f\u597d\u3002\u7136\u800c\uff0c\u9019\u4e9b\u8f03\u5c0f\u7684\u6a21\u578b\u8207\u8f03\u5927\u7684\u6a21\u578b\u4e00\u6a23\uff0c\u6709\u985e\u4f3c\u7684\u9650\u5236\uff0c\u5305\u62ec\u51fa\u73fe\u5e7b\u89ba\u7684\u50be\u5411\u3002\u5118\u7ba1\u6709\u8a31\u591a\u57fa\u6e96\u4f86\u8a55\u4f30 LLM \u4e2d\u7684\u5e7b\u89ba\uff0c\u4f46\u9bae\u5c11\u5c08\u6ce8\u65bc\u5c0f\u578b LLM (SLLM)\u3002\u6b64\u5916\uff0cSLLM \u5728\u4e0d\u540c\u7684\u57fa\u6e96\u4e2d\u8868\u73fe\u5dee\u7570\u5f88\u5927\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u4ecb\u7d39\u4e86 OnionEval\uff0c\u9019\u662f\u4e00\u500b\u591a\u5c64\u7d50\u69cb\u6846\u67b6\uff0c\u6709\u4e00\u500b\u7a31\u70ba\u4e0a\u4e0b\u6587\u5f71\u97ff\u5206\u6578 (CI) \u7684\u7279\u5b9a\u6307\u6a19\uff0c\u65e8\u5728\u6709\u6548\u8a55\u4f30\u4e0d\u540c\u4e0a\u4e0b\u6587\u5c64\u7d1a\u4e2d\u5c0f\u578b LLM \u7684\u4e8b\u5be6\u885d\u7a81\u5e7b\u89ba\u50be\u5411\u3002\u6211\u5011\u7684\u5be6\u9a57\u7d50\u679c\u63ed\u793a\u4e86 SLLM \u7684\u4e00\u500b\u95dc\u9375\u7279\u5fb5\uff1a\u5b83\u5011\u5728\u4e8b\u5be6\u5206\u6790\u4e2d\u8868\u73fe\u51fa\u8272\uff0c\u4f46\u5728\u4e0a\u4e0b\u6587\u63a8\u7406\u65b9\u9762\u9762\u81e8\u6311\u6230\u3002\u9032\u4e00\u6b65\u7684\u8abf\u67e5\u986f\u793a\uff0c\u4e00\u500b\u7c21\u55ae\u7684\u601d\u8003\u93c8\u7b56\u7565\u53ef\u4ee5\u986f\u8457\u6e1b\u5c11\u9019\u4e9b\u9650\u5236\uff0c\u63d0\u9ad8 SLLM \u5728\u5be6\u969b\u61c9\u7528\u4e2d\u7684\u5be6\u7528\u6027\u3002", "author": "Chongren Sun et.al.", "authors": "Chongren Sun, Yuran Li, Di Wu, Benoit Boulet", "id": "2501.12975v1", "paper_url": "http://arxiv.org/abs/2501.12975v1", "repo": "https://github.com/sunchongren/onioneval"}}