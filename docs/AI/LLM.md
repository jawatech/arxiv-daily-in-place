
### LLM
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-05-30**|**From Zero to Hero: Cold-Start Anomaly Detection**|Tal Reiss et.al.|[2405.20341v1](http://arxiv.org/abs/2405.20341v1)|[link](https://github.com/talreiss/coldfusion)|
|**2024-05-30**|**OccSora: 4D Occupancy Generation Models as World Simulators for Autonomous Driving**|Lening Wang et.al.|[2405.20337v1](http://arxiv.org/abs/2405.20337v1)|[link](https://github.com/wzzheng/occsora)|
|**2024-05-30**|**Xwin-LM: Strong and Scalable Alignment Practice for LLMs**|Bolin Ni et.al.|[2405.20335v1](http://arxiv.org/abs/2405.20335v1)|[link](https://github.com/xwin-lm/xwin-lm)|
|**2024-05-30**|**CoSy: Evaluating Textual Explanations of Neurons**|Laura Kopf et.al.|[2405.20331v1](http://arxiv.org/abs/2405.20331v1)|[link](https://github.com/lkopf/cosy)|
|**2024-05-30**|**$\textit{S}^3$Gaussian: Self-Supervised Street Gaussians for Autonomous Driving**|Nan Huang et.al.|[2405.20323v1](http://arxiv.org/abs/2405.20323v1)|[link](https://github.com/nnanhuang/s3gaussian)|
|**2024-05-30**|**Improving the Training of Rectified Flows**|Sangyun Lee et.al.|[2405.20320v1](http://arxiv.org/abs/2405.20320v1)|[link](https://github.com/sangyun884/rfpp)|
|**2024-05-30**|**ParSEL: Parameterized Shape Editing with Language**|Aditya Ganeshan et.al.|[2405.20319v1](http://arxiv.org/abs/2405.20319v1)|null|
|**2024-05-30**|**CausalQuest: Collecting Natural Causal Questions for AI Agents**|Roberto Ceraolo et.al.|[2405.20318v1](http://arxiv.org/abs/2405.20318v1)|[link](https://github.com/roberto-ceraolo/causal-quest)|
|**2024-05-30**|**ANAH: Analytical Annotation of Hallucinations in Large Language Models**|Ziwei Ji et.al.|[2405.20315v1](http://arxiv.org/abs/2405.20315v1)|[link](https://github.com/open-compass/anah)|
|**2024-05-30**|**S3D: A Simple and Cost-Effective Self-Speculative Decoding Scheme for Low-Memory GPUs**|Wei Zhong et.al.|[2405.20314v1](http://arxiv.org/abs/2405.20314v1)|null|
|**2024-05-30**|**Large Language Models Can Self-Improve At Web Agent Tasks**|Ajay Patel et.al.|[2405.20309v1](http://arxiv.org/abs/2405.20309v1)|null|
|**2024-05-30**|**Group Robust Preference Optimization in Reward-free RLHF**|Shyam Sundhar Ramesh et.al.|[2405.20304v1](http://arxiv.org/abs/2405.20304v1)|null|
|**2024-05-30**|**DITTO-2: Distilled Diffusion Inference-Time T-Optimization for Music Generation**|Zachary Novack et.al.|[2405.20289v1](http://arxiv.org/abs/2405.20289v1)|null|
|**2024-05-30**|**Flexible SE(2) graph neural networks with applications to PDE surrogates**|Maria Bånkestad et.al.|[2405.20287v1](http://arxiv.org/abs/2405.20287v1)|[link](https://github.com/mariabankestad/se2-gnn)|
|**2024-05-30**|**Who Writes the Review, Human or AI?**|Panagiotis C. Theocharopoulos et.al.|[2405.20285v1](http://arxiv.org/abs/2405.20285v1)|null|
|**2024-05-30**|**CV-VAE: A Compatible Video VAE for Latent Generative Video Models**|Sijie Zhao et.al.|[2405.20279v1](http://arxiv.org/abs/2405.20279v1)|[link](https://github.com/ailab-cvc/cv-vae)|
|**2024-05-30**|**Length independent generalization bounds for deep SSM architectures with stability constraints**|Dániel Rácz et.al.|[2405.20278v1](http://arxiv.org/abs/2405.20278v1)|null|
|**2024-05-30**|**ROAST: Review-level Opinion Aspect Sentiment Target Joint Detection**|Siva Uday Sampreeth Chebolu et.al.|[2405.20274v1](http://arxiv.org/abs/2405.20274v1)|null|
|**2024-05-30**|**ETHER: Efficient Finetuning of Large-Scale Models with Hyperplane Reflections**|Massimo Bini et.al.|[2405.20271v1](http://arxiv.org/abs/2405.20271v1)|[link](https://github.com/mwbini/ether)|
|**2024-05-30**|**IsraParlTweet: The Israeli Parliamentary and Twitter Resource**|Guy Mor-Lan et.al.|[2405.20269v1](http://arxiv.org/abs/2405.20269v1)|null|
|**2024-05-30**|**Auto Arena of LLMs: Automating LLM Evaluations with Agent Peer-battles and Committee Discussions**|Ruochen Zhao et.al.|[2405.20267v1](http://arxiv.org/abs/2405.20267v1)|null|
|**2024-05-30**|**Evaluating Large Language Model Biases in Persona-Steered Generation**|Andy Liu et.al.|[2405.20253v1](http://arxiv.org/abs/2405.20253v1)|[link](https://github.com/andyjliu/persona-steered-generation-bias)|
|**2024-05-30**|**Towards Hierarchical Multi-Agent Workflows for Zero-Shot Prompt Optimization**|Yuchi Liu et.al.|[2405.20252v1](http://arxiv.org/abs/2405.20252v1)|null|
|**2024-05-30**|**KerasCV and KerasNLP: Vision and Language Power-Ups**|Matthew Watson et.al.|[2405.20247v1](http://arxiv.org/abs/2405.20247v1)|null|
|**2024-05-30**|**Retrieval Augmented Structured Generation: Business Document Information Extraction As Tool Use**|Franz Louis Cesista et.al.|[2405.20245v1](http://arxiv.org/abs/2405.20245v1)|null|
|**2024-05-30**|**Training-efficient density quantum machine learning**|Brian Coyle et.al.|[2405.20237v1](http://arxiv.org/abs/2405.20237v1)|null|
|**2024-05-30**|**Context Injection Attacks on Large Language Models**|Cheng'an Wei et.al.|[2405.20234v1](http://arxiv.org/abs/2405.20234v1)|null|
|**2024-05-30**|**Grokfast: Accelerated Grokking by Amplifying Slow Gradients**|Jaerin Lee et.al.|[2405.20233v1](http://arxiv.org/abs/2405.20233v1)|[link](https://github.com/ironjr/grokfast)|
|**2024-05-30**|**The Empirical Impact of Neural Parameter Symmetries, or Lack Thereof**|Derek Lim et.al.|[2405.20231v1](http://arxiv.org/abs/2405.20231v1)|null|
|**2024-05-30**|**MOFA-Video: Controllable Image Animation via Generative Motion Field Adaptions in Frozen Image-to-Video Diffusion Model**|Muyao Niu et.al.|[2405.20222v1](http://arxiv.org/abs/2405.20222v1)|null|
|**2024-05-30**|**ESG-FTSE: A corpus of news articles with ESG relevance labels and use cases**|Mariya Pavlova et.al.|[2405.20218v1](http://arxiv.org/abs/2405.20218v1)|null|
|**2024-05-30**|**Boost Your Own Human Image Generation Model via Direct Preference Optimization with AI Feedback**|Sanghyeon Na et.al.|[2405.20216v1](http://arxiv.org/abs/2405.20216v1)|null|
|**2024-05-30**|**TS-Align: A Teacher-Student Collaborative Framework for Scalable Iterative Finetuning of Large Language Models**|Chen Zhang et.al.|[2405.20215v1](http://arxiv.org/abs/2405.20215v1)|null|
|**2024-05-30**|**PostDoc: Generating Poster from a Long Multimodal Document Using Deep Submodular Optimization**|Vijay Jaisankar et.al.|[2405.20213v1](http://arxiv.org/abs/2405.20213v1)|null|
|**2024-05-30**|**Jina CLIP: Your CLIP Model Is Also Your Text Retriever**|Andreas Koukounas et.al.|[2405.20204v1](http://arxiv.org/abs/2405.20204v1)|null|
|**2024-05-30**|**One QuantLLM for ALL: Fine-tuning Quantized LLMs Once for Efficient Deployments**|Ke Yi et.al.|[2405.20202v1](http://arxiv.org/abs/2405.20202v1)|null|
|**2024-05-30**|**TAIA: Large Language Models are Out-of-Distribution Data Learners**|Shuyang Jiang et.al.|[2405.20192v1](http://arxiv.org/abs/2405.20192v1)|null|
|**2024-05-30**|**Nadine: An LLM-driven Intelligent Social Robot with Affective Capabilities and Human-like Memory**|Hangyeol Kang et.al.|[2405.20189v1](http://arxiv.org/abs/2405.20189v1)|null|
|**2024-05-30**|**A Survey Study on the State of the Art of Programming Exercise Generation using Large Language Models**|Eduard Frankford et.al.|[2405.20183v1](http://arxiv.org/abs/2405.20183v1)|null|
|**2024-05-30**|**Transformers and Slot Encoding for Sample Efficient Physical World Modelling**|Francesco Petri et.al.|[2405.20180v1](http://arxiv.org/abs/2405.20180v1)|[link](https://github.com/torchipeppo/transformers-and-slot-encoding-for-wm)|
|**2024-05-30**|**Robo-Instruct: Simulator-Augmented Instruction Alignment For Finetuning CodeLLMs**|Zichao Hu et.al.|[2405.20179v1](http://arxiv.org/abs/2405.20179v1)|null|
|**2024-05-30**|**InstructionCP: A fast approach to transfer Large Language Models into target language**|Kuang-Ming Chen et.al.|[2405.20175v1](http://arxiv.org/abs/2405.20175v1)|null|
|**2024-05-30**|**Iterative Feature Boosting for Explainable Speech Emotion Recognition**|Alaa Nfissi et.al.|[2405.20172v1](http://arxiv.org/abs/2405.20172v1)|[link](https://github.com/alaaNfissi/Iterative-Feature-Boosting-for-Explainable-Speech-Emotion-Recognition)|
|**2024-05-30**|**Reasoning about concepts with LLMs: Inconsistencies abound**|Rosario Uceda-Sosa et.al.|[2405.20163v1](http://arxiv.org/abs/2405.20163v1)|null|
|**2024-05-30**|**Heidelberg-Boston @ SIGTYP 2024 Shared Task: Enhancing Low-Resource Language Analysis With Character-Aware Hierarchical Transformers**|Frederick Riemenschneider et.al.|[2405.20145v1](http://arxiv.org/abs/2405.20145v1)|[link](https://github.com/bowphs/sigtyp-2024-hierarchical-transformers)|
|**2024-05-30**|**MSSC-BiMamba: Multimodal Sleep Stage Classification and Early Diagnosis of Sleep Disorders with Bidirectional Mamba**|Chao Zhanga et.al.|[2405.20142v1](http://arxiv.org/abs/2405.20142v1)|null|
|**2024-05-30**|**GNN-RAG: Graph Neural Retrieval for Large Language Model Reasoning**|Costas Mavromatis et.al.|[2405.20139v1](http://arxiv.org/abs/2405.20139v1)|null|
|**2024-05-30**|**LLaMEA: A Large Language Model Evolutionary Algorithm for Automatically Generating Metaheuristics**|Niki van Stein et.al.|[2405.20132v1](http://arxiv.org/abs/2405.20132v1)|null|
|**2024-05-30**|**Language Models Need Inductive Biases to Count Inductively**|Yingshan Chang et.al.|[2405.20131v1](http://arxiv.org/abs/2405.20131v1)|[link](https://github.com/zdxdsw/inductive_counting_with_lms)|
|**2024-05-30**|**A Structure-Aware Lane Graph Transformer Model for Vehicle Trajectory Prediction**|Sun Zhanbo et.al.|[2405.20121v1](http://arxiv.org/abs/2405.20121v1)|null|
|**2024-05-30**|**Fill in the Gap! Combining Self-supervised Representation Learning with Neural Audio Synthesis for Speech Inpainting**|Ihab Asaad et.al.|[2405.20101v1](http://arxiv.org/abs/2405.20101v1)|null|
|**2024-05-30**|**Divide-and-Conquer Meets Consensus: Unleashing the Power of Functions in Code Generation**|Jingchang Chen et.al.|[2405.20092v1](http://arxiv.org/abs/2405.20092v1)|null|
|**2024-05-30**|**The Fine-Tuning Paradox: Boosting Translation Quality Without Sacrificing LLM Abilities**|David Stap et.al.|[2405.20089v1](http://arxiv.org/abs/2405.20089v1)|null|
|**2024-05-30**|**Segment, Shuffle, and Stitch: A Simple Mechanism for Improving Time-Series Representations**|Shivam Grover et.al.|[2405.20082v1](http://arxiv.org/abs/2405.20082v1)|null|
|**2024-05-30**|**NoiseBoost: Alleviating Hallucination with Noise Perturbation for Multimodal Large Language Models**|Kai Wu et.al.|[2405.20081v1](http://arxiv.org/abs/2405.20081v1)|null|
|**2024-05-30**|**Student Answer Forecasting: Transformer-Driven Answer Choice Prediction for Language Learning**|Elena Grazia Gado et.al.|[2405.20079v1](http://arxiv.org/abs/2405.20079v1)|null|
|**2024-05-30**|**Spectral Mapping of Singing Voices: U-Net-Assisted Vocal Segmentation**|Adam Sorrenti et.al.|[2405.20059v1](http://arxiv.org/abs/2405.20059v1)|[link](https://github.com/mbrotos/soundseg)|
|**2024-05-30**|**Would I Lie To You? Inference Time Alignment of Language Models using Direct Preference Heads**|Avelina Asada Hadji-Kyriacou et.al.|[2405.20053v1](http://arxiv.org/abs/2405.20053v1)|null|
|**2024-05-30**|**Cross-Training with Multi-View Knowledge Fusion for Heterogenous Federated Learning**|Zhuang Qi et.al.|[2405.20046v1](http://arxiv.org/abs/2405.20046v1)|null|
|**2024-05-30**|**Applications of Generative AI (GAI) for Mobile and Wireless Networking: A Survey**|Thai-Hoc Vu et.al.|[2405.20024v1](http://arxiv.org/abs/2405.20024v1)|null|
|**2024-05-30**|**Safe Multi-agent Reinforcement Learning with Natural Language Constraints**|Ziyan Wang et.al.|[2405.20018v1](http://arxiv.org/abs/2405.20018v1)|null|
|**2024-05-30**|**Efficient LLM-Jailbreaking by Introducing Visual Modality**|Zhenxing Niu et.al.|[2405.20015v1](http://arxiv.org/abs/2405.20015v1)|null|
|**2024-05-30**|**Kernel Language Entropy: Fine-grained Uncertainty Quantification for LLMs from Semantic Similarities**|Alexander Nikitin et.al.|[2405.20003v1](http://arxiv.org/abs/2405.20003v1)|null|
|**2024-05-30**|**DP-IQA: Utilizing Diffusion Prior for Blind Image Quality Assessment in the Wild**|Honghao Fu et.al.|[2405.19996v1](http://arxiv.org/abs/2405.19996v1)|[link](https://github.com/RomGai/DP-IQA)|
|**2024-05-30**|**Video-Language Critic: Transferable Reward Functions for Language-Conditioned Robotics**|Minttu Alakuijala et.al.|[2405.19988v1](http://arxiv.org/abs/2405.19988v1)|null|
|**2024-05-30**|**A Deep Reinforcement Learning Approach for Trading Optimization in the Forex Market with Multi-Agent Asynchronous Distribution**|Davoud Sarani et.al.|[2405.19982v1](http://arxiv.org/abs/2405.19982v1)|null|
|**2024-05-30**|**A Triumvirate of AI Driven Theoretical Discovery**|Yang-Hui He et.al.|[2405.19973v1](http://arxiv.org/abs/2405.19973v1)|null|
|**2024-05-30**|**Improved Out-of-Scope Intent Classification with Dual Encoding and Threshold-based Re-Classification**|Hossam M. Zawbaa et.al.|[2405.19967v1](http://arxiv.org/abs/2405.19967v1)|null|
|**2024-05-30**|**PLA4D: Pixel-Level Alignments for Text-to-4D Gaussian Splatting**|Qiaowei Miao et.al.|[2405.19957v1](http://arxiv.org/abs/2405.19957v1)|null|
|**2024-05-30**|**HOLMES: to Detect Adversarial Examples with Multiple Detectors**|Jing Wen et.al.|[2405.19956v1](http://arxiv.org/abs/2405.19956v1)|null|
|**2024-05-30**|**GenKubeSec: LLM-Based Kubernetes Misconfiguration Detection, Localization, Reasoning, and Remediation**|Ehud Malul et.al.|[2405.19954v1](http://arxiv.org/abs/2405.19954v1)|null|
|**2024-05-30**|**MM-Lego: Modular Biomedical Multimodal Models with Minimal Fine-Tuning**|Konstantin Hemker et.al.|[2405.19950v1](http://arxiv.org/abs/2405.19950v1)|null|
|**2024-05-30**|**Learning to Discuss Strategically: A Case Study on One Night Ultimate Werewolf**|Xuanfa Jin et.al.|[2405.19946v1](http://arxiv.org/abs/2405.19946v1)|null|
|**2024-05-30**|**Learning Latent Graph Structures and their Uncertainty**|Alessandro Manenti et.al.|[2405.19933v1](http://arxiv.org/abs/2405.19933v1)|null|
|**2024-05-30**|**Exploring Diffusion Models' Corruption Stage in Few-Shot Fine-tuning and Mitigating with Bayesian Neural Networks**|Xiaoyu Wu et.al.|[2405.19931v1](http://arxiv.org/abs/2405.19931v1)|null|
|**2024-05-30**|**Open-Set Domain Adaptation for Semantic Segmentation**|Seun-An Choe et.al.|[2405.19899v1](http://arxiv.org/abs/2405.19899v1)|[link](https://github.com/khu-agi/bus)|
|**2024-05-30**|**Similarity is Not All You Need: Endowing Retrieval Augmented Generation with Multi Layered Thoughts**|Chunjing Gan et.al.|[2405.19893v1](http://arxiv.org/abs/2405.19893v1)|null|
|**2024-05-30**|**Parrot: Efficient Serving of LLM-based Applications with Semantic Variable**|Chaofan Lin et.al.|[2405.19888v1](http://arxiv.org/abs/2405.19888v1)|null|
|**2024-05-30**|**From Words to Actions: Unveiling the Theoretical Underpinnings of LLM-Driven Autonomous Systems**|Jianliang He et.al.|[2405.19883v1](http://arxiv.org/abs/2405.19883v1)|null|
|**2024-05-30**|**KNOW: A Real-World Ontology for Knowledge Capture with Large Language Models**|Arto Bendiken et.al.|[2405.19877v1](http://arxiv.org/abs/2405.19877v1)|null|
|**2024-05-30**|**Is In-Context Learning Sufficient for Instruction Following in LLMs?**|Hao Zhao et.al.|[2405.19874v1](http://arxiv.org/abs/2405.19874v1)|null|
|**2024-05-30**|**Out-of-distribution Reject Option Method for Dataset Shift Problem in Early Disease Onset Prediction**|Taisei Tosaki et.al.|[2405.19864v1](http://arxiv.org/abs/2405.19864v1)|null|
|**2024-05-30**|**DevEval: A Manually-Annotated Code Generation Benchmark Aligned with Real-World Code Repositories**|Jia Li et.al.|[2405.19856v1](http://arxiv.org/abs/2405.19856v1)|null|
|**2024-05-30**|**Deciphering Human Mobility: Inferring Semantics of Trajectories with Large Language Models**|Yuxiao Luo et.al.|[2405.19850v1](http://arxiv.org/abs/2405.19850v1)|null|
|**2024-05-30**|**Quest: Query-centric Data Synthesis Approach for Long-context Scaling of Large Language Model**|Chaochen Gao et.al.|[2405.19846v1](http://arxiv.org/abs/2405.19846v1)|null|
|**2024-05-30**|**Improve Student's Reasoning Generalizability through Cascading Decomposed CoTs Distillation**|Chengwei Dai et.al.|[2405.19842v1](http://arxiv.org/abs/2405.19842v1)|[link](https://github.com/c-w-d/cascod)|
|**2024-05-30**|**Just Rewrite It Again: A Post-Processing Method for Enhanced Semantic Similarity and Privacy Preservation of Differentially Private Rewritten Text**|Stephen Meisenbacher et.al.|[2405.19831v1](http://arxiv.org/abs/2405.19831v1)|null|
|**2024-05-30**|**Joint Selective State Space Model and Detrending for Robust Time Series Anomaly Detection**|Junqi Chen et.al.|[2405.19823v1](http://arxiv.org/abs/2405.19823v1)|null|
|**2024-05-30**|**Improving Object Detector Training on Synthetic Data by Starting With a Strong Baseline Methodology**|Frank A. Ruis et.al.|[2405.19822v1](http://arxiv.org/abs/2405.19822v1)|null|
|**2024-05-30**|**WebUOT-1M: Advancing Deep Underwater Object Tracking with A Million-Scale Benchmark**|Chunhui Zhang et.al.|[2405.19818v1](http://arxiv.org/abs/2405.19818v1)|null|
|**2024-05-30**|**Efficient Stimuli Generation using Reinforcement Learning in Design Verification**|Deepak Narayan Gadde et.al.|[2405.19815v1](http://arxiv.org/abs/2405.19815v1)|null|
|**2024-05-30**|**Unsupervised Mutual Learning of Dialogue Discourse Parsing and Topic Segmentation**|Jiahui Xu et.al.|[2405.19799v1](http://arxiv.org/abs/2405.19799v1)|null|
|**2024-05-30**|**SLM as Guardian: Pioneering AI Safety with Small Language Models**|Ohjoon Kwon et.al.|[2405.19795v1](http://arxiv.org/abs/2405.19795v1)|null|
|**2024-05-30**|**PDDLEGO: Iterative Planning in Textual Environments**|Li Zhang et.al.|[2405.19793v1](http://arxiv.org/abs/2405.19793v1)|null|
|**2024-05-30**|**From Symbolic Tasks to Code Generation: Diversification Yields Better Task Performers**|Dylan Zhang et.al.|[2405.19787v1](http://arxiv.org/abs/2405.19787v1)|null|
|**2024-05-30**|**PixelsDB: Serverless and Natural-Language-Aided Data Analytics with Flexible Service Levels and Prices**|Haoqiong Bian et.al.|[2405.19784v1](http://arxiv.org/abs/2405.19784v1)|null|
|**2024-05-30**|**Instruction-Guided Visual Masking**|Jinliang Zheng et.al.|[2405.19783v1](http://arxiv.org/abs/2405.19783v1)|null|
|**2024-05-30**|**Dataflow-Guided Retrieval Augmentation for Repository-Level Code Completion**|Wei Cheng et.al.|[2405.19782v1](http://arxiv.org/abs/2405.19782v1)|null|
|**2024-05-30**|**Enhancing Consistency and Role-Specific Knowledge Capturing by Rebuilding Fictional Character's Persona**|Jeiyoon Park et.al.|[2405.19778v1](http://arxiv.org/abs/2405.19778v1)|[link](https://github.com/jeiyoon/charactergpt)|
|**2024-05-30**|**Towards Unified Multi-granularity Text Detection with Interactive Attention**|Xingyu Wan et.al.|[2405.19765v1](http://arxiv.org/abs/2405.19765v1)|null|

#### Abstracts
##### **From Zero to Hero: Cold-Start Anomaly Detection**
2405.20341v1 by Tal Reiss, George Kour, Naama Zwerdling, Ateret Anaby-Tavor, Yedid Hoshen

When first deploying an anomaly detection system, e.g., to detect
out-of-scope queries in chatbots, there are no observed data, making
data-driven approaches ineffective. Zero-shot anomaly detection methods offer a
solution to such "cold-start" cases, but unfortunately they are often not
accurate enough. This paper studies the realistic but underexplored cold-start
setting where an anomaly detection model is initialized using zero-shot
guidance, but subsequently receives a small number of contaminated observations
(namely, that may include anomalies). The goal is to make efficient use of both
the zero-shot guidance and the observations. We propose ColdFusion, a method
that effectively adapts the zero-shot anomaly detector to contaminated
observations. To support future development of this new setting, we propose an
evaluation suite consisting of evaluation protocols and metrics.

摘要：在首次部署異常偵測系統時，例如偵測聊天機器人中的超出範圍查詢時，沒有觀察到的資料，這使得資料驅動方法無效。零次學習異常偵測方法為此類「冷啟動」案例提供了解決方案，但不幸的是，它們通常不夠準確。本文探討了現實但未充分探索的冷啟動設定，其中異常偵測模型使用零次學習指導進行初始化，但隨後會收到少量的受污染觀測值（即可能包括異常值）。目標是有效利用零次學習指導和觀測值。我們提出 ColdFusion，這是一種有效地將零次學習異常偵測器適應受污染觀測值的方法。為了支援此新設定的未來發展，我們提出一個評估套件，其中包含評估協定和指標。

##### **OccSora: 4D Occupancy Generation Models as World Simulators for Autonomous Driving**
2405.20337v1 by Lening Wang, Wenzhao Zheng, Yilong Ren, Han Jiang, Zhiyong Cui, Haiyang Yu, Jiwen Lu

Understanding the evolution of 3D scenes is important for effective
autonomous driving. While conventional methods mode scene development with the
motion of individual instances, world models emerge as a generative framework
to describe the general scene dynamics. However, most existing methods adopt an
autoregressive framework to perform next-token prediction, which suffer from
inefficiency in modeling long-term temporal evolutions. To address this, we
propose a diffusion-based 4D occupancy generation model, OccSora, to simulate
the development of the 3D world for autonomous driving. We employ a 4D scene
tokenizer to obtain compact discrete spatial-temporal representations for 4D
occupancy input and achieve high-quality reconstruction for long-sequence
occupancy videos. We then learn a diffusion transformer on the spatial-temporal
representations and generate 4D occupancy conditioned on a trajectory prompt.
We conduct extensive experiments on the widely used nuScenes dataset with Occ3D
occupancy annotations. OccSora can generate 16s-videos with authentic 3D layout
and temporal consistency, demonstrating its ability to understand the spatial
and temporal distributions of driving scenes. With trajectory-aware 4D
generation, OccSora has the potential to serve as a world simulator for the
decision-making of autonomous driving. Code is available at:
https://github.com/wzzheng/OccSora.

摘要：了解 3D 場景的演變對於有效自主駕駛非常重要。雖然傳統方法使用個別實例的動作建模場景開發，但世界模型作為生成框架出現，用於描述一般場景動態。然而，大多數現有方法採用自迴歸框架來執行下一個代幣預測，這在建模長期時間演變方面效率低下。為了解決這個問題，我們提出一個基於擴散的 4D 佔用生成模型 OccSora，模擬 3D 世界的發展以進行自主駕駛。我們使用 4D 場景分詞器為 4D 佔用輸入取得緊湊離散的時空表示，並為長序列佔用影片實現高品質重建。然後，我們在時空表示上學習擴散Transformer，並根據軌跡提示產生 4D 佔用。我們在廣泛使用的 nuScenes 資料集上使用 Occ3D 佔用註釋進行廣泛的實驗。OccSora 可以產生具有真實 3D 佈局和時間一致性的 16 秒影片，證明其理解駕駛場景時空分佈的能力。透過軌跡感知 4D 生成，OccSora 有可能作為世界模擬器，用於自主駕駛的決策制定。程式碼可在以下位置取得：
https://github.com/wzzheng/OccSora。

##### **Xwin-LM: Strong and Scalable Alignment Practice for LLMs**
2405.20335v1 by Bolin Ni, JingCheng Hu, Yixuan Wei, Houwen Peng, Zheng Zhang, Gaofeng Meng, Han Hu

In this work, we present Xwin-LM, a comprehensive suite of alignment
methodologies for large language models (LLMs). This suite encompasses several
key techniques, including supervised finetuning (SFT), reward modeling (RM),
rejection sampling finetuning (RS), and direct preference optimization (DPO).
The key components are as follows: (1) Xwin-LM-SFT, models initially finetuned
with high-quality instruction data; (2) Xwin-Pair, a large-scale, multi-turn
preference dataset meticulously annotated using GPT-4; (3) Xwin-RM, reward
models trained on Xwin-Pair, developed at scales of 7B, 13B, and 70B
parameters; (4) Xwin-Set, a multiwise preference dataset in which each prompt
is linked to 64 unique responses generated by Xwin-LM-SFT and scored by
Xwin-RM; (5) Xwin-LM-RS, models finetuned with the highest-scoring responses
from Xwin-Set; (6) Xwin-LM-DPO, models further optimized on Xwin-Set using the
DPO algorithm. Our evaluations on AlpacaEval and MT-bench demonstrate
consistent and significant improvements across the pipeline, demonstrating the
strength and scalability of Xwin-LM. The repository
https://github.com/Xwin-LM/Xwin-LM will be continually updated to foster
community research.

摘要：<paragraph>在這項工作中，我們提出 Xwin-LM，這是一個針對大型語言模型 (LLM) 的全面對齊方法套件。此套件包含多種關鍵技術，包括監督微調 (SFT)、獎勵模型 (RM)、拒絕抽樣微調 (RS) 和直接偏好最佳化 (DPO)。主要組成如下：(1) Xwin-LM-SFT，最初使用高品質指令資料進行微調的模型；(2) Xwin-Pair，使用 GPT-4 精心註解的大型多輪偏好資料集；(3) Xwin-RM，在 Xwin-Pair 上訓練的獎勵模型，開發時採用 7B、13B 和 70B 參數；(4) Xwin-Set，一個多重偏好資料集，其中每個提示都連結到由 Xwin-LM-SFT 生成的 64 個獨特回應，並由 Xwin-RM 評分；(5) Xwin-LM-RS，使用 Xwin-Set 中得分最高的回應進行微調的模型；(6) Xwin-LM-DPO，使用 DPO 演算法在 Xwin-Set 上進一步最佳化的模型。我們在 AlpacaEval 和 MT-bench 上的評估證明了整個管線的一致且顯著的改進，展示了 Xwin-LM 的強大和可擴展性。儲存庫 https://github.com/Xwin-LM/Xwin-LM 將持續更新，以促進社群研究。</paragraph>

##### **CoSy: Evaluating Textual Explanations of Neurons**
2405.20331v1 by Laura Kopf, Philine Lou Bommer, Anna Hedström, Sebastian Lapuschkin, Marina M. -C. Höhne, Kirill Bykov

A crucial aspect of understanding the complex nature of Deep Neural Networks
(DNNs) is the ability to explain learned concepts within their latent
representations. While various methods exist to connect neurons to textual
descriptions of human-understandable concepts, evaluating the quality of these
explanation methods presents a major challenge in the field due to a lack of
unified, general-purpose quantitative evaluation. In this work, we introduce
CoSy (Concept Synthesis) -- a novel, architecture-agnostic framework to
evaluate the quality of textual explanations for latent neurons. Given textual
explanations, our proposed framework leverages a generative model conditioned
on textual input to create data points representing the textual explanation.
Then, the neuron's response to these explanation data points is compared with
the response to control data points, providing a quality estimate of the given
explanation. We ensure the reliability of our proposed framework in a series of
meta-evaluation experiments and demonstrate practical value through insights
from benchmarking various concept-based textual explanation methods for
Computer Vision tasks, showing that tested explanation methods significantly
differ in quality.

摘要：深入了解深度神经網路 (DNN) 複雜本質的關鍵面向，在於解釋其潛在表徵中所學得的概念。雖然有各種方法可以將神經元連接到人類可理解概念的文字描述，但評估這些解釋方法的品質，由於缺乏統一且通用的量化評估，因此成為該領域的一項重大挑戰。在這項工作中，我們引入了 CoSy (概念合成)——一個創新的、與架構無關的架構，用於評估潛在神經元的文字解釋品質。針對文字解釋，我們提出的架構利用條件生成模型，根據文字輸入建立代表文字解釋的資料點。然後，將神經元對這些解釋資料點的反應與對控制資料點的反應進行比較，提供對給定解釋的品質評估。我們在多項後設評估實驗中確保了我們提出的架構的可靠性，並透過對各種基於概念的文字解釋方法進行電腦視覺任務基準測試的見解，展示了其實用價值，證明經過測試的解釋方法在品質上存在顯著差異。

##### **$\textit{S}^3$Gaussian: Self-Supervised Street Gaussians for Autonomous Driving**
2405.20323v1 by Nan Huang, Xiaobao Wei, Wenzhao Zheng, Pengju An, Ming Lu, Wei Zhan, Masayoshi Tomizuka, Kurt Keutzer, Shanghang Zhang

Photorealistic 3D reconstruction of street scenes is a critical technique for
developing real-world simulators for autonomous driving. Despite the efficacy
of Neural Radiance Fields (NeRF) for driving scenes, 3D Gaussian Splatting
(3DGS) emerges as a promising direction due to its faster speed and more
explicit representation. However, most existing street 3DGS methods require
tracked 3D vehicle bounding boxes to decompose the static and dynamic elements
for effective reconstruction, limiting their applications for in-the-wild
scenarios. To facilitate efficient 3D scene reconstruction without costly
annotations, we propose a self-supervised street Gaussian
($\textit{S}^3$Gaussian) method to decompose dynamic and static elements from
4D consistency. We represent each scene with 3D Gaussians to preserve the
explicitness and further accompany them with a spatial-temporal field network
to compactly model the 4D dynamics. We conduct extensive experiments on the
challenging Waymo-Open dataset to evaluate the effectiveness of our method. Our
$\textit{S}^3$Gaussian demonstrates the ability to decompose static and dynamic
scenes and achieves the best performance without using 3D annotations. Code is
available at: https://github.com/nnanhuang/S3Gaussian/.

摘要：逼真的街道場景 3D 重建是開發自動駕駛真實世界模擬器的關鍵技術。儘管神經輻照場 (NeRF) 對駕駛場景有效，但 3D 高斯飛濺 (3DGS) 由於其速度更快且表示更明確，因此成為一個有前景的方向。然而，現有的街道 3DGS 方法大多需要追蹤 3D 車輛邊界框才能分解靜態和動態元素以進行有效重建，這限制了它們在野外場景中的應用。為了促進在沒有昂貴標註的情況下進行高效的 3D 場景重建，我們提出了一種自監督街道高斯（$\textit{S}^3$高斯）方法，從 4D 一致性中分解動態和靜態元素。我們使用 3D 高斯表示每個場景以保留明確性，並進一步使用時空場網路來緊湊地建模 4D 動態。我們在具有挑戰性的 Waymo-Open 資料集上進行了廣泛的實驗，以評估我們方法的有效性。我們的 $\textit{S}^3$高斯證明了分解靜態和動態場景的能力，並在不使用 3D 標註的情況下實現了最佳性能。程式碼可於此處取得：https://github.com/nnanhuang/S3Gaussian/。

##### **Improving the Training of Rectified Flows**
2405.20320v1 by Sangyun Lee, Zinan Lin, Giulia Fanti

Diffusion models have shown great promise for image and video generation, but
sampling from state-of-the-art models requires expensive numerical integration
of a generative ODE. One approach for tackling this problem is rectified flows,
which iteratively learn smooth ODE paths that are less susceptible to
truncation error. However, rectified flows still require a relatively large
number of function evaluations (NFEs). In this work, we propose improved
techniques for training rectified flows, allowing them to compete with
knowledge distillation methods even in the low NFE setting. Our main insight is
that under realistic settings, a single iteration of the Reflow algorithm for
training rectified flows is sufficient to learn nearly straight trajectories;
hence, the current practice of using multiple Reflow iterations is unnecessary.
We thus propose techniques to improve one-round training of rectified flows,
including a U-shaped timestep distribution and LPIPS-Huber premetric. With
these techniques, we improve the FID of the previous 2-rectified flow by up to
72% in the 1 NFE setting on CIFAR-10. On ImageNet 64$\times$64, our improved
rectified flow outperforms the state-of-the-art distillation methods such as
consistency distillation and progressive distillation in both one-step and
two-step settings and rivals the performance of improved consistency training
(iCT) in FID. Code is available at https://github.com/sangyun884/rfpp.

摘要：擴散模型在影像和影片生成方面展現出極大的潛力，但從最先進的模型中進行取樣需要進行產生式 ODE 的昂貴數值積分。解決此問題的一種方法是修正流，它反覆學習較不容易受到截斷誤差影響的平滑 ODE 路徑。然而，修正流仍然需要相對大量的函數評估 (NFE)。在這項工作中，我們提出改進的修正流訓練技術，讓它們即使在低 NFE 設定下也能與知識萃取方法競爭。我們的見解在於，在現實的設定下，訓練修正流的 Reflow 演算法只需反覆運算一次就足以學習幾乎是直線的軌跡；因此，目前使用多重 Reflow 反覆運算的做法是不必要的。因此，我們提出改進修正流一輪訓練的技術，包括 U 形時間步長分佈和 LPIPS-Huber 前度量。有了這些技術，我們在 CIFAR-10 的 1 NFE 設定下，將先前 2 修正流的 FID 提升了 72%。在 ImageNet 64×64 上，我們改良的修正流在單步和兩步設定下都優於最先進的萃取方法，例如一致性萃取和漸進式萃取，並且在 FID 中與改良一致性訓練 (iCT) 的效能相匹敵。程式碼可在 https://github.com/sangyun884/rfpp 取得。

##### **ParSEL: Parameterized Shape Editing with Language**
2405.20319v1 by Aditya Ganeshan, Ryan Y. Huang, Xianghao Xu, R. Kenny Jones, Daniel Ritchie

The ability to edit 3D assets from natural language presents a compelling
paradigm to aid in the democratization of 3D content creation. However, while
natural language is often effective at communicating general intent, it is
poorly suited for specifying precise manipulation. To address this gap, we
introduce ParSEL, a system that enables controllable editing of high-quality 3D
assets from natural language. Given a segmented 3D mesh and an editing request,
ParSEL produces a parameterized editing program. Adjusting the program
parameters allows users to explore shape variations with a precise control over
the magnitudes of edits. To infer editing programs which align with an input
edit request, we leverage the abilities of large-language models (LLMs).
However, while we find that LLMs excel at identifying initial edit operations,
they often fail to infer complete editing programs, and produce outputs that
violate shape semantics. To overcome this issue, we introduce Analytical Edit
Propagation (AEP), an algorithm which extends a seed edit with additional
operations until a complete editing program has been formed. Unlike prior
methods, AEP searches for analytical editing operations compatible with a range
of possible user edits through the integration of computer algebra systems for
geometric analysis. Experimentally we demonstrate ParSEL's effectiveness in
enabling controllable editing of 3D objects through natural language requests
over alternative system designs.

摘要：透過自然語言編輯 3D 素材的能力，提供了引人注目的典範，有助於推廣 3D 內容創作的民主化。然而，雖然自然語言通常能有效傳達一般意圖，但並不適合用來指定精確的操作。為了解決這個差距，我們引入了 ParSEL，這是一個能從自然語言中控制性地編輯高品質 3D 素材的系統。給定一個分段的 3D 網格和一個編輯請求，ParSEL 會產生一個參數化的編輯程式。調整程式參數，使用者可以探索形狀變化，並精確控制編輯的幅度。為了推論與輸入編輯請求一致的編輯程式，我們利用了大型語言模型 (LLM) 的能力。然而，我們發現，雖然 LLM 在識別初始編輯操作方面表現出色，但它們通常無法推論出完整的編輯程式，而且會產生違反形狀語意的輸出。為了克服這個問題，我們引入了分析編輯傳播 (AEP)，這是一種演算法，它會用其他操作來延伸種子編輯，直到形成一個完整的編輯程式。與之前的做法不同，AEP 會透過整合電腦代數系統進行幾何分析，來搜尋與各種可能的使用者編輯相容的分析編輯操作。透過實驗，我們證明了 ParSEL 能有效地透過自然語言請求，對 3D 物件進行可控制的編輯，優於其他系統設計。

##### **CausalQuest: Collecting Natural Causal Questions for AI Agents**
2405.20318v1 by Roberto Ceraolo, Dmitrii Kharlapenko, Amélie Reymond, Rada Mihalcea, Mrinmaya Sachan, Bernhard Schölkopf, Zhijing Jin

Humans have an innate drive to seek out causality. Whether fuelled by
curiosity or specific goals, we constantly question why things happen, how they
are interconnected, and many other related phenomena. To develop AI agents
capable of addressing this natural human quest for causality, we urgently need
a comprehensive dataset of natural causal questions. Unfortunately, existing
datasets either contain only artificially-crafted questions that do not reflect
real AI usage scenarios or have limited coverage of questions from specific
sources. To address this gap, we present CausalQuest, a dataset of 13,500
naturally occurring questions sourced from social networks, search engines, and
AI assistants. We formalize the definition of causal questions and establish a
taxonomy for finer-grained classification. Through a combined effort of human
annotators and large language models (LLMs), we carefully label the dataset. We
find that 42% of the questions humans ask are indeed causal, with the majority
seeking to understand the causes behind given effects. Using this dataset, we
train efficient classifiers (up to 2.85B parameters) for the binary task of
identifying causal questions, achieving high performance with F1 scores of up
to 0.877. We conclude with a rich set of future research directions that can
build upon our data and models.

摘要：人類與生俱來就有探求因果關係的驅力。無論是出於好奇心或特定目標，我們不斷質疑事情發生的原因、它們如何相互關聯，以及許多其他相關現象。為了開發能夠應對人類對因果關係這種自然追求的人工智慧代理，我們迫切需要一個包含自然因果問題的綜合資料集。遺憾的是，現有的資料集要么只包含反映不出實際人工智慧使用場景的人工編製問題，要么對來自特定來源的問題的涵蓋範圍有限。為了解決這一差距，我們提出了 CausalQuest，這是一個來自社交網路、搜尋引擎和人工智慧助理的 13,500 個自然發生的問題的資料集。我們正式定義了因果問題，並建立了一個用於更細緻分類的分類法。透過人類註解員和大語言模型 (LLM) 的共同努力，我們仔細標記了資料集。我們發現人類提出的問題中有 42% 確實是因果關係的，其中大多數尋求理解特定結果背後的原因。使用這個資料集，我們訓練了用於識別因果問題的二元任務的高效分類器（最多 2.85B 參數），並以高達 0.877 的 F1 分數取得了高性能。我們最後提出了一組豐富的未來研究方向，這些方向可以建立在我們的資料和模型之上。

##### **ANAH: Analytical Annotation of Hallucinations in Large Language Models**
2405.20315v1 by Ziwei Ji, Yuzhe Gu, Wenwei Zhang, Chengqi Lyu, Dahua Lin, Kai Chen

Reducing the `$\textit{hallucination}$' problem of Large Language Models
(LLMs) is crucial for their wide applications. A comprehensive and fine-grained
measurement of the hallucination is the first key step for the governance of
this issue but is under-explored in the community. Thus, we present
$\textbf{ANAH}$, a bilingual dataset that offers $\textbf{AN}$alytical
$\textbf{A}$nnotation of $\textbf{H}$allucinations in LLMs within Generative
Question Answering. Each answer sentence in our dataset undergoes rigorous
annotation, involving the retrieval of a reference fragment, the judgment of
the hallucination type, and the correction of hallucinated content. ANAH
consists of ~12k sentence-level annotations for ~4.3k LLM responses covering
over 700 topics, constructed by a human-in-the-loop pipeline. Thanks to the
fine granularity of the hallucination annotations, we can quantitatively
confirm that the hallucinations of LLMs progressively accumulate in the answer
and use ANAH to train and evaluate hallucination annotators. We conduct
extensive experiments on studying generative and discriminative annotators and
show that, although current open-source LLMs have difficulties in fine-grained
hallucination annotation, the generative annotator trained with ANAH can
surpass all open-source LLMs and GPT-3.5, obtain performance competitive with
GPT-4, and exhibits better generalization ability on unseen questions.

摘要：<paragraph>降低大型語言模型 (LLM) 的「幻覺」問題對於其廣泛應用至關重要。對幻覺進行全面且細緻的測量是解決此問題的第一個關鍵步驟，但社群對此的探討卻不足。因此，我們提出了 $\textbf{ANAH}$，一個雙語資料集，提供生成式問題解答中 LLM 幻覺的 $\textbf{AN}$alytical $\textbf{A}$nnotation of $\textbf{H}$allucinations。我們資料集中的每個答案句子都經過嚴格的註解，包括檢索參考片段、判斷幻覺類型以及更正幻覺內容。ANAH 由人工迴路管道建構，包含超過 700 個主題的約 4.3k 個 LLM 回應，共約 12k 個句子層級註解。由於幻覺註解的細緻程度，我們可以定量確認 LLM 的幻覺會逐漸累積在答案中，並使用 ANAH 來訓練和評估幻覺註解器。我們對生成式和判別式註解器進行了廣泛的實驗，並表明，儘管目前的開源 LLM 難以進行細緻的幻覺註解，但使用 ANAH 訓練的生成式註解器可以超越所有開源 LLM 和 GPT-3.5，獲得與 GPT-4 相當的效能，並在未見過的問題上展現出更好的泛化能力。</paragraph>

##### **S3D: A Simple and Cost-Effective Self-Speculative Decoding Scheme for Low-Memory GPUs**
2405.20314v1 by Wei Zhong, Manasa Bharadwaj

Speculative decoding (SD) has attracted a significant amount of research
attention due to the substantial speedup it can achieve for LLM inference.
However, despite the high speedups they offer, speculative decoding methods
often achieve optimal performance on high-end devices or with a substantial GPU
memory overhead. Given limited memory and the necessity of quantization, a
high-performing model on a high-end GPU can slow down by up to 7 times. To this
end, we propose Skippy Simultaneous Speculative Decoding (or S3D), a
cost-effective self-speculative SD method based on simultaneous multi-token
decoding and mid-layer skipping. When compared against recent effective
open-source SD systems, our method has achieved one of the top
performance-memory ratios while requiring minimal architecture changes and
training data. Leveraging our memory efficiency, we created a smaller yet more
effective SD model based on Phi-3. It is 1.4 to 2 times faster than the
quantized EAGLE model and operates in half-precision while using less VRAM.

摘要：推測解碼（SD）由於其可為 LLM 推論帶來大幅加速，因此吸引了大量的研究關注。
然而，儘管推測解碼方法提供了高加速，但它們通常在高階裝置或具有大量 GPU 記憶體開銷的情況下才能達到最佳效能。由於記憶體有限且需要量化，因此高階 GPU 上效能良好的模型可能會慢上 7 倍。為此，我們提出了跳躍式同時推測解碼（或 S3D），這是一種基於同時多代幣解碼和中間層跳躍的經濟高效自推測 SD 方法。與最近有效的開源 SD 系統相比，我們的模型在需要最小的架構變更和訓練資料的情況下，達到了最佳效能記憶體比值之一。利用我們的記憶體效率，我們建立了一個基於 Phi-3 的更小但更有效的 SD 模型。它比量化的 EAGLE 模型快 1.4 到 2 倍，且在使用較少 VRAM 的情況下以半精度運作。

##### **Large Language Models Can Self-Improve At Web Agent Tasks**
2405.20309v1 by Ajay Patel, Markus Hofmarcher, Claudiu Leoveanu-Condrei, Marius-Constantin Dinu, Chris Callison-Burch, Sepp Hochreiter

Training models to act as agents that can effectively navigate and perform
actions in a complex environment, such as a web browser, has typically been
challenging due to lack of training data. Large language models (LLMs) have
recently demonstrated some capability to navigate novel environments as agents
in a zero-shot or few-shot fashion, purely guided by natural language
instructions as prompts. Recent research has also demonstrated LLMs have the
capability to exceed their base performance through self-improvement, i.e.
fine-tuning on data generated by the model itself. In this work, we explore the
extent to which LLMs can self-improve their performance as agents in
long-horizon tasks in a complex environment using the WebArena benchmark. In
WebArena, an agent must autonomously navigate and perform actions on web pages
to achieve a specified objective. We explore fine-tuning on three distinct
synthetic training data mixtures and achieve a 31\% improvement in task
completion rate over the base model on the WebArena benchmark through a
self-improvement procedure. We additionally contribute novel evaluation metrics
for assessing the performance, robustness, capabilities, and quality of
trajectories of our fine-tuned agent models to a greater degree than simple,
aggregate-level benchmark scores currently used to measure self-improvement.

摘要：<paragraph>訓練模型成為代理人，在複雜的環境中有效導航並執行動作，例如網頁瀏覽器，由於缺乏訓練資料，通常具有挑戰性。大型語言模型 (LLM) 最近已展示出一些能力，可作為代理人在新的環境中導航，以零次學習或少次學習的方式，純粹由自然語言指示作為提示。最近的研究也表明，LLM 有能力透過自我提升來超越其基本效能，即對模型本身產生的資料進行微調。在這項工作中，我們探討了 LLM 在複雜環境中使用 WebArena 基準作為代理人在長期任務中自我提升其效能的程度。在 WebArena 中，代理人必須自主導航並對網頁執行動作，以達成指定目標。我們探討了對三種不同的合成訓練資料混合進行微調，並透過自我提升程序在 WebArena 基準上實現了任務完成率比基礎模型提升 31%。此外，我們為評估微調代理人模型的效能、穩健性、能力和軌跡品質，貢獻了新穎的評估指標，其程度遠高於目前用於衡量自我提升的簡單聚合層級基準分數。</paragraph>

##### **Group Robust Preference Optimization in Reward-free RLHF**
2405.20304v1 by Shyam Sundhar Ramesh, Yifan Hu, Iason Chaimalas, Viraj Mehta, Pier Giuseppe Sessa, Haitham Bou Ammar, Ilija Bogunovic

Adapting large language models (LLMs) for specific tasks usually involves
fine-tuning through reinforcement learning with human feedback (RLHF) on
preference data. While these data often come from diverse labelers' groups
(e.g., different demographics, ethnicities, company teams, etc.), traditional
RLHF approaches adopt a "one-size-fits-all" approach, i.e., they
indiscriminately assume and optimize a single preference model, thus not being
robust to unique characteristics and needs of the various groups. To address
this limitation, we propose a novel Group Robust Preference Optimization (GRPO)
method to align LLMs to individual groups' preferences robustly. Our approach
builds upon reward-free direct preference optimization methods, but unlike
previous approaches, it seeks a robust policy which maximizes the worst-case
group performance. To achieve this, GRPO adaptively and sequentially weights
the importance of different groups, prioritizing groups with worse cumulative
loss. We theoretically study the feasibility of GRPO and analyze its
convergence for the log-linear policy class. By fine-tuning LLMs with GRPO
using diverse group-based global opinion data, we significantly improved
performance for the worst-performing groups, reduced loss imbalances across
groups, and improved probability accuracies compared to non-robust baselines.

摘要：調整大型語言模型（LLM）以執行特定任務通常涉及透過人類回饋（RLHF）進行強化學習微調，並使用偏好資料。雖然這些資料通常來自不同的標籤群組（例如，不同的人口統計、種族、公司團隊等），但傳統 RLHF 方法採用「一體適用」方法，亦即它們不加區別地假設並最佳化單一偏好模型，因此無法針對不同群組的獨特特性和需求保持穩健性。為了解決這個限制，我們提出了一種新穎的群組穩健偏好最佳化（GRPO）方法，以穩健地將 LLM 與個別群組的偏好對齊。我們的做法建立在無獎勵的直接偏好最佳化方法之上，但與先前的做法不同，它尋求一種穩健的政策，以最大化最差情況的群組效能。為了達成此目標，GRPO 會適應性地、依序地加權不同群組的重要性，優先處理累積損失較差的群組。我們從理論上探討 GRPO 的可行性，並分析其對數線性政策類別的收斂性。透過使用 GRPO 微調 LLM，並使用基於群組的多樣化全球意見資料，我們大幅改善了表現最差的群組的效能，減少了群組間的損失失衡，並與非穩健基線相比，改善了機率準確度。

##### **DITTO-2: Distilled Diffusion Inference-Time T-Optimization for Music Generation**
2405.20289v1 by Zachary Novack, Julian McAuley, Taylor Berg-Kirkpatrick, Nicholas Bryan

Controllable music generation methods are critical for human-centered
AI-based music creation, but are currently limited by speed, quality, and
control design trade-offs. Diffusion Inference-Time T-optimization (DITTO), in
particular, offers state-of-the-art results, but is over 10x slower than
real-time, limiting practical use. We propose Distilled Diffusion
Inference-Time T -Optimization (or DITTO-2), a new method to speed up
inference-time optimization-based control and unlock faster-than-real-time
generation for a wide-variety of applications such as music inpainting,
outpainting, intensity, melody, and musical structure control. Our method works
by (1) distilling a pre-trained diffusion model for fast sampling via an
efficient, modified consistency or consistency trajectory distillation process
(2) performing inference-time optimization using our distilled model with
one-step sampling as an efficient surrogate optimization task and (3) running a
final multi-step sampling generation (decoding) using our estimated noise
latents for best-quality, fast, controllable generation. Through thorough
evaluation, we find our method not only speeds up generation over 10-20x, but
simultaneously improves control adherence and generation quality all at once.
Furthermore, we apply our approach to a new application of maximizing text
adherence (CLAP score) and show we can convert an unconditional diffusion model
without text inputs into a model that yields state-of-the-art text control.
Sound examples can be found at https://ditto-music.github.io/ditto2/.

摘要：<paragraph>可控音樂生成方法對於以人為中心的 AI 音樂創作至關重要，但目前受到速度、品質和控制設計權衡的限制。特別是擴散推論時間 T 最佳化 (DITTO) 提供了最先進的結果，但速度比即時慢了 10 倍以上，限制了實際使用。我們提出蒸餾擴散推論時間 T 最佳化（或 DITTO-2），這是一種新的方法，可以加速推論時間最佳化控制，並為各種應用程式解鎖快於即時的生成，例如音樂填色、外繪、強度、旋律和音樂結構控制。我們的運作方式是 (1) 通過有效率的修改一致性或一致性軌跡蒸餾程序，蒸餾預訓練的擴散模型以進行快速取樣 (2) 使用我們蒸餾的模型進行推論時間最佳化，並使用單步取樣作為有效的替代最佳化任務 (3) 使用我們估計的雜訊潛在變數執行最後的多步取樣生成（解碼），以獲得最佳品質、快速、可控的生成。透過徹底的評估，我們發現我們的運作方式不僅將生成速度提升了 10-20 倍，同時還改善了控制遵循度和生成品質。此外，我們將我們的做法應用於最大化文字遵循度（CLAP 分數）的新應用程式，並展示我們可以將沒有文字輸入的無條件擴散模型轉換為產生最先進文字控制的模型。可以在 https://ditto-music.github.io/ditto2/ 找到聲音範例。</paragraph>

##### **Flexible SE(2) graph neural networks with applications to PDE surrogates**
2405.20287v1 by Maria Bånkestad, Olof Mogren, Aleksis Pirinen

This paper presents a novel approach for constructing graph neural networks
equivariant to 2D rotations and translations and leveraging them as PDE
surrogates on non-gridded domains. We show that aligning the representations
with the principal axis allows us to sidestep many constraints while preserving
SE(2) equivariance. By applying our model as a surrogate for fluid flow
simulations and conducting thorough benchmarks against non-equivariant models,
we demonstrate significant gains in terms of both data efficiency and accuracy.

摘要：本文提出一個新穎方法來構建圖神經網路，對 2D 旋轉和平移具有等變異性，並將其作為非網格化域上的偏微分方程代理。我們表明，將表示與主軸對齊，讓我們能夠在保持 SE(2) 等變異性的同時避開許多約束。透過將我們的模型應用為流體流動模擬的代理，並對非等變異模型進行徹底的基準測試，我們證明在資料效率和準確度方面都有顯著的進展。

##### **Who Writes the Review, Human or AI?**
2405.20285v1 by Panagiotis C. Theocharopoulos, Spiros V. Georgakopoulos, Sotiris K. Tasoulis, Vassilis P. Plagianakos

With the increasing use of Artificial Intelligence in Natural Language
Processing, concerns have been raised regarding the detection of AI-generated
text in various domains. This study aims to investigate this issue by proposing
a methodology to accurately distinguish AI-generated and human-written book
reviews. Our approach utilizes transfer learning, enabling the model to
identify generated text across different topics while improving its ability to
detect variations in writing style and vocabulary. To evaluate the
effectiveness of the proposed methodology, we developed a dataset consisting of
real book reviews and AI-generated reviews using the recently proposed Vicuna
open-source language model. The experimental results demonstrate that it is
feasible to detect the original source of text, achieving an accuracy rate of
96.86%. Our efforts are oriented toward the exploration of the capabilities and
limitations of Large Language Models in the context of text identification.
Expanding our knowledge in these aspects will be valuable for effectively
navigating similar models in the future and ensuring the integrity and
authenticity of human-generated content.

摘要：隨著人工智慧在自然語言處理中的應用日益廣泛，在各種領域中偵測 AI 生成的文字也引發了關注。本研究旨在探討這個問題，提出一個方法論來準確區分 AI 生成的書評和人類撰寫的書評。我們的做法利用了遷移學習，讓模型能夠識別不同主題中產生的文字，同時提升它偵測寫作風格和詞彙變化的能力。為了評估所提出的方法論的有效性，我們開發了一個資料集，其中包含使用最近提出的 Vicuna 開源語言模型產生的真實書評和 AI 生成的書評。實驗結果顯示偵測文字的原始來源是可行的，達到了 96.86% 的準確率。我們的努力方向是探索大型語言模型在文字辨識脈絡中的能力和限制。擴展我們在這些方面的知識，對於在未來有效地使用類似的模型，並確保人類產生內容的完整性和真實性，將是有價值的。

##### **CV-VAE: A Compatible Video VAE for Latent Generative Video Models**
2405.20279v1 by Sijie Zhao, Yong Zhang, Xiaodong Cun, Shaoshu Yang, Muyao Niu, Xiaoyu Li, Wenbo Hu, Ying Shan

Spatio-temporal compression of videos, utilizing networks such as Variational
Autoencoders (VAE), plays a crucial role in OpenAI's SORA and numerous other
video generative models. For instance, many LLM-like video models learn the
distribution of discrete tokens derived from 3D VAEs within the VQVAE
framework, while most diffusion-based video models capture the distribution of
continuous latent extracted by 2D VAEs without quantization. The temporal
compression is simply realized by uniform frame sampling which results in
unsmooth motion between consecutive frames. Currently, there lacks of a
commonly used continuous video (3D) VAE for latent diffusion-based video models
in the research community. Moreover, since current diffusion-based approaches
are often implemented using pre-trained text-to-image (T2I) models, directly
training a video VAE without considering the compatibility with existing T2I
models will result in a latent space gap between them, which will take huge
computational resources for training to bridge the gap even with the T2I models
as initialization. To address this issue, we propose a method for training a
video VAE of latent video models, namely CV-VAE, whose latent space is
compatible with that of a given image VAE, e.g., image VAE of Stable Diffusion
(SD). The compatibility is achieved by the proposed novel latent space
regularization, which involves formulating a regularization loss using the
image VAE. Benefiting from the latent space compatibility, video models can be
trained seamlessly from pre-trained T2I or video models in a truly
spatio-temporally compressed latent space, rather than simply sampling video
frames at equal intervals. With our CV-VAE, existing video models can generate
four times more frames with minimal finetuning. Extensive experiments are
conducted to demonstrate the effectiveness of the proposed video VAE.

摘要：時空影片壓縮，利用變異自編碼器 (VAE) 等網路，在 OpenAI 的 SORA 和許多其他影片生成模型中扮演關鍵角色。例如，許多類似 LLM 的影片模型會在 VQVAE 架構中學習源自 3D VAE 的離散代碼的分布，而大多數基於擴散的影片模型會擷取未經量化的 2D VAE 萃取的連續潛在分布。時序壓縮僅透過均勻的影格取樣實現，這會導致連續影格之間的動作不順暢。目前，研究社群中缺乏一個普遍使用的連續影片 (3D) VAE，可供潛在擴散式影片模型使用。此外，由於目前的基於擴散的方法通常使用預先訓練好的文字轉影像 (T2I) 模型實作，直接訓練影片 VAE 而未考量與現有 T2I 模型的相容性，將導致它們之間的潛在空間差距，即使使用 T2I 模型作為初始化，填補差距仍需耗費龐大的運算資源進行訓練。為了解決這個問題，我們提出一個用於訓練潛在影片模型的影片 VAE 的方法，即 CV-VAE，其潛在空間與給定的影像 VAE 相容，例如 Stable Diffusion (SD) 的影像 VAE。相容性是透過提出的新穎潛在空間正則化實現的，其中涉及使用影像 VAE 制定正則化損失。受益於潛在空間相容性，影片模型可以從預先訓練好的 T2I 或影片模型在真正的時空壓縮潛在空間中無縫訓練，而不用僅以相等的間隔取樣影片影格。透過我們的 CV-VAE，現有的影片模型可以產生多四倍的影格，微調幅度極小。我們進行了廣泛的實驗，以證明所提出的影片 VAE 的有效性。

##### **Length independent generalization bounds for deep SSM architectures with stability constraints**
2405.20278v1 by Dániel Rácz, Mihály Petreczky, Bálint Daróczy

Many state-of-the-art models trained on long-range sequences, for example S4,
S5 or LRU, are made of sequential blocks combining State-Space Models (SSMs)
with neural networks. In this paper we provide a PAC bound that holds for these
kind of architectures with stable SSM blocks and does not depend on the length
of the input sequence. Imposing stability of the SSM blocks is a standard
practice in the literature, and it is known to help performance. Our results
provide a theoretical justification for the use of stable SSM blocks as the
proposed PAC bound decreases as the degree of stability of the SSM blocks
increases.

摘要：許多訓練在長程序列上的最新模型，例如 S4、S5 或 LRU，是由結合狀態空間模型 (SSM) 與神經網路的序列區塊所組成。在本文中，我們提供了一個 PAC 界限，適用於具有穩定 SSM 區塊的這類架構，且不依賴於輸入序列的長度。強制 SSM 區塊的穩定性是文獻中的標準做法，且已知有助於效能。我們的結果提供了使用穩定 SSM 區塊的理論依據，因為所提出的 PAC 界限會隨著 SSM 區塊穩定程度的增加而降低。

##### **ROAST: Review-level Opinion Aspect Sentiment Target Joint Detection**
2405.20274v1 by Siva Uday Sampreeth Chebolu, Franck Dernoncourt, Nedim Lipka, Thamar Solorio

Aspect-Based Sentiment Analysis (ABSA) has experienced tremendous expansion
and diversity due to various shared tasks spanning several languages and fields
and organized via SemEval workshops and Germeval. Nonetheless, a few
shortcomings still need to be addressed, such as the lack of low-resource
language evaluations and the emphasis on sentence-level analysis. To thoroughly
assess ABSA techniques in the context of complete reviews, this research
presents a novel task, Review-Level Opinion Aspect Sentiment Target (ROAST).
ROAST seeks to close the gap between sentence-level and text-level ABSA by
identifying every ABSA constituent at the review level. We extend the available
datasets to enable ROAST, addressing the drawbacks noted in previous research
by incorporating low-resource languages, numerous languages, and a variety of
topics. Through this effort, ABSA research will be able to cover more ground
and get a deeper comprehension of the task and its practical application in a
variety of languages and domains (https://github.com/RiTUAL-UH/ROAST-ABSA).

摘要：基於面向方面的意見分析 (ABSA) 由於各種跨越多種語言和領域的共享任務而經歷了巨大的擴展和多樣化，並透過 SemEval 工作坊和 Germeval 組織。儘管如此，仍有一些缺點需要解決，例如缺乏低資源語言評估和強調句子層級分析。為了在完整評論的背景下徹底評估 ABSA 技術，本研究提出了一項新任務，即評論層級意見面向情緒目標 (ROAST)。ROAST 旨在透過在評論層級識別每個 ABSA 組成部分來縮小句子層級和文字層級 ABSA 之間的差距。我們擴展了可用的資料集以啟用 ROAST，透過納入低資源語言、多種語言和各種主題來解決先前研究中指出的缺點。透過這項努力，ABSA 研究將能夠涵蓋更多領域，並對任務及其在各種語言和領域中的實際應用有更深入的理解 (https://github.com/RiTUAL-UH/ROAST-ABSA)。

##### **ETHER: Efficient Finetuning of Large-Scale Models with Hyperplane Reflections**
2405.20271v1 by Massimo Bini, Karsten Roth, Zeynep Akata, Anna Khoreva

Parameter-efficient finetuning (PEFT) has become ubiquitous to adapt
foundation models to downstream task requirements while retaining their
generalization ability. However, the amount of additionally introduced
parameters and compute for successful adaptation and hyperparameter searches
can explode quickly, especially when deployed at scale to serve numerous
individual requests. To ensure effective, parameter-efficient, and
hyperparameter-robust adaptation, we propose the ETHER transformation family,
which performs Efficient fineTuning via HypErplane Reflections. By design,
ETHER transformations require a minimal number of parameters, are less likely
to deteriorate model performance, and exhibit robustness to hyperparameter and
learning rate choices. In particular, we introduce ETHER and its relaxation
ETHER+, which match or outperform existing PEFT methods with significantly
fewer parameters ($\sim$$10$-$100$ times lower than LoRA or OFT) across
multiple image synthesis and natural language tasks without exhaustive
hyperparameter tuning. Finally, we investigate the recent emphasis on
Hyperspherical Energy retention for adaptation and raise questions on its
practical utility. The code is available at https://github.com/mwbini/ether.

摘要：參數有效微調 (PEFT) 已廣泛用於調整基礎模型以符合下游任務需求，同時保留其泛化能力。然而，為了成功進行調整和超參數搜尋而另外引入的參數和計算量可能會快速爆炸，特別是在大規模部署以滿足大量個別請求時。為了確保有效、參數有效且超參數穩健的調整，我們提出了 ETHER 轉換系列，它透過超平面反射執行有效微調。根據設計，ETHER 轉換需要最少的參數數量，不太可能降低模型效能，並展現出對超參數和學習率選擇的穩健性。特別是，我們引入了 ETHER 及其放鬆版 ETHER+，它們在多項影像合成和自然語言任務中，以顯著更少的參數（比 LoRA 或 OFT 低 $\sim$$10$-$100$ 倍）達到或優於現有的 PEFT 方法，而無需進行窮舉式超參數調整。最後，我們探討了最近強調用於調整的超球面能量保留，並對其實用性提出疑問。程式碼可於 https://github.com/mwbini/ether 取得。

##### **IsraParlTweet: The Israeli Parliamentary and Twitter Resource**
2405.20269v1 by Guy Mor-Lan, Effi Levi, Tamir Sheafer, Shaul R. Shenhav

We introduce IsraParlTweet, a new linked corpus of Hebrew-language
parliamentary discussions from the Knesset (Israeli Parliament) between the
years 1992-2023 and Twitter posts made by Members of the Knesset between the
years 2008-2023, containing a total of 294.5 million Hebrew tokens. In addition
to raw text, the corpus contains comprehensive metadata on speakers and Knesset
sessions as well as several linguistic annotations. As a result, IsraParlTweet
can be used to conduct a wide variety of quantitative and qualitative analyses
and provide valuable insights into political discourse in Israel.

摘要：我們推出 IsraParlTweet，這是 1992-2023 年間以色列國會 (Knesset) 的希伯來語議會討論和 2008-2023 年間國會議員發表的 Twitter 帖文的全新連結語料庫，總共包含 2.945 億個希伯來語詞彙。除了原始文字外，語料庫還包含有關發言人和國會會議的綜合元數據，以及多項語言註釋。因此，IsraParlTweet 可用於進行各種定量和定性分析，並提供對以色列政治話語的寶貴見解。

##### **Auto Arena of LLMs: Automating LLM Evaluations with Agent Peer-battles and Committee Discussions**
2405.20267v1 by Ruochen Zhao, Wenxuan Zhang, Yew Ken Chia, Deli Zhao, Lidong Bing

As LLMs evolve on a daily basis, there is an urgent need for a trustworthy
evaluation method that can provide robust evaluation results in a timely
fashion. Currently, as static benchmarks are prone to contamination concerns,
users tend to trust human voting platforms, such as Chatbot Arena. However,
human annotations require extensive manual efforts. To provide an automatic,
robust, and trustworthy evaluation framework, we innovatively propose the
Auto-Arena of LLMs, which automates the entire evaluation process with LLM
agents. Firstly, an examiner LLM devises queries. Then, a pair of candidate
LLMs engage in a multi-round peer-battle around the query, during which the
LLM's true performance gaps become visible. Finally, a committee of LLM judges
collectively discuss and determine the winner, which alleviates bias and
promotes fairness. In our extensive experiment on the 17 newest LLMs,
Auto-Arena shows the highest correlation with human preferences, providing a
promising alternative to human evaluation platforms.

摘要：隨著大型語言模型每天都在進步，迫切需要一種可信賴的評估方法，能夠及時提供穩健的評估結果。目前，由於靜態基準容易受到污染問題的影響，使用者傾向於信任人類投票平台，例如 Chatbot Arena。然而，人類標註需要大量人工工作。為了提供一個自動化、穩健且可信賴的評估架構，我們創新地提出了大型語言模型的 Auto-Arena，它使用大型語言模型代理自動化整個評估過程。首先，一個審查員大型語言模型設計查詢。然後，一對候選大型語言模型圍繞查詢進行多輪點對點戰鬥，在此過程中，大型語言模型的真實性能差距變得明顯。最後，一個由大型語言模型組成的評審委員會共同討論並確定獲勝者，這減輕了偏見並促進了公平性。在我們對 17 個最新大型語言模型進行的廣泛實驗中，Auto-Arena 與人類偏好的相關性最高，為人類評估平台提供了一個有前途的替代方案。

##### **Evaluating Large Language Model Biases in Persona-Steered Generation**
2405.20253v1 by Andy Liu, Mona Diab, Daniel Fried

The task of persona-steered text generation requires large language models
(LLMs) to generate text that reflects the distribution of views that an
individual fitting a persona could have. People have multifaceted personas, but
prior work on bias in LLM-generated opinions has only explored multiple-choice
settings or one-dimensional personas. We define an incongruous persona as a
persona with multiple traits where one trait makes its other traits less likely
in human survey data, e.g. political liberals who support increased military
spending. We find that LLMs are 9.7% less steerable towards incongruous
personas than congruous ones, sometimes generating the stereotypical stance
associated with its demographic rather than the target stance. Models that we
evaluate that are fine-tuned with Reinforcement Learning from Human Feedback
(RLHF) are more steerable, especially towards stances associated with political
liberals and women, but present significantly less diverse views of personas.
We also find variance in LLM steerability that cannot be predicted from
multiple-choice opinion evaluation. Our results show the importance of
evaluating models in open-ended text generation, as it can surface new LLM
opinion biases. Moreover, such a setup can shed light on our ability to steer
models toward a richer and more diverse range of viewpoints.

摘要：人格導向文本生成的任務需要大型語言模型 (LLM) 產生反映擁有特定人格的個人觀點分佈的文本。人們有多面性的人格，但先前關於 LLM 生成意見中偏見的研究僅探討了多重選擇設定或一維人格。我們將不一致的人格定義為具有多重特質的人格，其中一個特質使其其他特質在人類調查數據中不太可能出現，例如支持增加軍費開支的政治自由派。我們發現，LLM 對不一致人格的引導力比一致人格低 9.7%，有時會產生與其人口統計資料相關的刻板立場，而不是目標立場。我們評估的模型經過人類回饋強化學習 (RLHF) 微調後，更具可引導性，特別是對與政治自由派和女性相關的立場，但呈現出明顯較少樣化的人格觀點。我們還發現 LLM 可引導性中的差異無法從多重選擇意見評估中預測。我們的結果顯示了在開放式文本生成中評估模型的重要性，因為它可以浮現新的 LLM 意見偏見。此外，這樣的設定可以闡明我們引導模型朝向更豐富、更多樣化的觀點範圍的能力。

##### **Towards Hierarchical Multi-Agent Workflows for Zero-Shot Prompt Optimization**
2405.20252v1 by Yuchi Liu, Jaskirat Singh, Gaowen Liu, Ali Payani, Liang Zheng

Large language models (LLMs) have shown great progress in responding to user
questions, allowing for a multitude of diverse applications. Yet, the quality
of LLM outputs heavily depends on the prompt design, where a good prompt might
enable the LLM to answer a very challenging question correctly. Therefore,
recent works have developed many strategies for improving the prompt, including
both manual crafting and in-domain optimization. However, their efficacy in
unrestricted scenarios remains questionable, as the former depends on human
design for specific questions and the latter usually generalizes poorly to
unseen scenarios. To address these problems, we give LLMs the freedom to design
the best prompts according to themselves. Specifically, we include a hierarchy
of LLMs, first constructing a prompt with precise instructions and accurate
wording in a hierarchical manner, and then using this prompt to generate the
final answer to the user query. We term this pipeline Hierarchical Multi-Agent
Workflow, or HMAW. In contrast with prior works, HMAW imposes no human
restriction and requires no training, and is completely task-agnostic while
capable of adjusting to the nuances of the underlying task. Through both
quantitative and qualitative experiments across multiple benchmarks, we verify
that despite its simplicity, the proposed approach can create detailed and
suitable prompts, further boosting the performance of current LLMs.

摘要：大型語言模型 (LLM) 在回應使用者問題方面已展現出極佳的進展，並允許進行大量不同的應用。然而，LLM 輸出的品質在很大程度上取決於提示設計，其中一個好的提示可能會讓 LLM 正確回答一個非常具有挑戰性的問題。因此，最近的研究已開發出許多策略來改善提示，包括手動製作和領域內最佳化。然而，它們在不受限制的情況下的效力仍有待商榷，因為前者依賴於人類針對特定問題進行設計，而後者通常無法很好地概化到未見過的場景。為了解決這些問題，我們給予 LLM 自由，讓它們根據自身設計最佳提示。具體來說，我們包含了一個 LLM 層級，首先以分層的方式建構一個包含精確說明和準確用詞的提示，然後使用這個提示來產生對使用者查詢的最終答案。我們將這個流程稱為分層多代理工作流程，或 HMAW。與先前的研究相比，HMAW 不施加任何人類限制，也不需要訓練，而且完全與任務無關，同時還能調整到底層任務的細微差別。透過多個基準的多項量化和質化實驗，我們驗證了儘管方法簡單，但提出的方法可以建立詳細且適當的提示，進一步提升當前 LLM 的效能。

##### **KerasCV and KerasNLP: Vision and Language Power-Ups**
2405.20247v1 by Matthew Watson, Divyashree Shivakumar Sreepathihalli, Francois Chollet, Martin Gorner, Kiranbir Sodhia, Ramesh Sampath, Tirth Patel, Haifeng Jin, Neel Kovelamudi, Gabriel Rasskin, Samaneh Saadat, Luke Wood, Chen Qian, Jonathan Bischof, Ian Stenbit

We present the Keras domain packages KerasCV and KerasNLP, extensions of the
Keras API for Computer Vision and Natural Language Processing workflows,
capable of running on either JAX, TensorFlow, or PyTorch. These domain packages
are designed to enable fast experimentation, with a focus on ease-of-use and
performance. We adopt a modular, layered design: at the library's lowest level
of abstraction, we provide building blocks for creating models and data
preprocessing pipelines, and at the library's highest level of abstraction, we
provide pretrained ``task" models for popular architectures such as Stable
Diffusion, YOLOv8, GPT2, BERT, Mistral, CLIP, Gemma, T5, etc. Task models have
built-in preprocessing, pretrained weights, and can be fine-tuned on raw
inputs. To enable efficient training, we support XLA compilation for all
models, and run all preprocessing via a compiled graph of TensorFlow operations
using the tf.data API. The libraries are fully open-source (Apache 2.0 license)
and available on GitHub.

摘要：我們展示 Keras 領域套件 KerasCV 和 KerasNLP，它們是 Keras API 的延伸，用於電腦視覺和自然語言處理工作流程，可以在 JAX、TensorFlow 或 PyTorch 上執行。這些領域套件旨在實現快速實驗，重點是易用性和效能。我們採用模組化、分層設計：在程式庫最低層級的抽象中，我們提供建立模型和資料預處理管線的建構模組，在程式庫最高層級的抽象中，我們提供預先訓練好的「任務」模型，用於熱門架構，例如 Stable Diffusion、YOLOv8、GPT2、BERT、Mistral、CLIP、Gemma、T5 等。任務模型具備內建預處理、預先訓練好的權重，且可以針對原始輸入進行微調。為了實現有效率的訓練，我們支援所有模型的 XLA 編譯，並使用 tf.data API 透過 TensorFlow 作業的已編譯圖形執行所有預處理。這些程式庫完全開源（Apache 2.0 授權），並在 GitHub 上提供。

##### **Retrieval Augmented Structured Generation: Business Document Information Extraction As Tool Use**
2405.20245v1 by Franz Louis Cesista, Rui Aguiar, Jason Kim, Paolo Acilo

Business Document Information Extraction (BDIE) is the problem of
transforming a blob of unstructured information (raw text, scanned documents,
etc.) into a structured format that downstream systems can parse and use. It
has two main tasks: Key-Information Extraction (KIE) and Line Items Recognition
(LIR). In this paper, we argue that BDIE is best modeled as a Tool Use problem,
where the tools are these downstream systems. We then present Retrieval
Augmented Structured Generation (RASG), a novel general framework for BDIE that
achieves state of the art (SOTA) results on both KIE and LIR tasks on BDIE
benchmarks.
  The contributions of this paper are threefold: (1) We show, with ablation
benchmarks, that Large Language Models (LLMs) with RASG are already competitive
with or surpasses current SOTA Large Multimodal Models (LMMs) without RASG on
BDIE benchmarks. (2) We propose a new metric class for Line Items Recognition,
General Line Items Recognition Metric (GLIRM), that is more aligned with
practical BDIE use cases compared to existing metrics, such as ANLS*, DocILE,
and GriTS. (3) We provide a heuristic algorithm for backcalculating bounding
boxes of predicted line items and tables without the need for vision encoders.
Finally, we claim that, while LMMs might sometimes offer marginal performance
benefits, LLMs + RASG is oftentimes superior given real-world applications and
constraints of BDIE.

摘要：商業文件資訊萃取 (BDIE) 是將非結構化資訊 (原始文字、掃描文件等) 轉換成下游系統可以解析和使用的結構化格式的問題。它有兩個主要任務：關鍵資訊萃取 (KIE) 和明細項目辨識 (LIR)。在本文中，我們主張 BDIE 最好建模為工具使用問題，其中工具是這些下游系統。然後我們提出檢索增強結構生成 (RASG)，這是一個新穎的 BDIE 通用架構，在 BDIE 基準測試的 KIE 和 LIR 任務上都達到了最先進 (SOTA) 的結果。本文的貢獻有三方面：(1) 我們透過消融基準測試顯示，具有 RASG 的大型語言模型 (LLM) 已經與沒有 RASG 的當前 SOTA 大型多模態模型 (LMM) 競爭或超越 BDIE 基準測試。(2) 我們提出了一個新的明細項目辨識指標類別，即通用明細項目辨識指標 (GLIRM)，與現有指標（例如 ANLS*、DocILE 和 GriTS）相比，它更符合實際的 BDIE 使用案例。(3) 我們提供了一個啟發式演算法，用於回推預測明細項目和表格的邊界框，而無需視覺編碼器。最後，我們聲稱，雖然 LMM 有時可能會提供邊際效能優勢，但 LLM + RASG 在現實世界的應用和 BDIE 的限制下通常是更好的。

##### **Training-efficient density quantum machine learning**
2405.20237v1 by Brian Coyle, El Amine Cherrat, Nishant Jain, Natansh Mathur, Snehal Raj, Skander Kazdaghli, Iordanis Kerenidis

Quantum machine learning requires powerful, flexible and efficiently
trainable models to be successful in solving challenging problems. In this
work, we present density quantum neural networks, a learning model
incorporating randomisation over a set of trainable unitaries. These models
generalise quantum neural networks using parameterised quantum circuits, and
allow a trade-off between expressibility and efficient trainability,
particularly on quantum hardware. We demonstrate the flexibility of the
formalism by applying it to two recently proposed model families. The first are
commuting-block quantum neural networks (QNNs) which are efficiently trainable
but may be limited in expressibility. The second are orthogonal (Hamming-weight
preserving) quantum neural networks which provide well-defined and
interpretable transformations on data but are challenging to train at scale on
quantum devices. Density commuting QNNs improve capacity with minimal gradient
complexity overhead, and density orthogonal neural networks admit a
quadratic-to-constant gradient query advantage with minimal to no performance
loss. We conduct numerical experiments on synthetic translationally invariant
data and MNIST image data with hyperparameter optimisation to support our
findings. Finally, we discuss the connection to post-variational quantum neural
networks, measurement-based quantum machine learning and the dropout mechanism.

摘要：量子機器學習需要強大、靈活且可有效訓練的模型，才能成功解決具有挑戰性的問題。在此研究中，我們提出密度量子神經網路，一種結合在可訓練酉算子集合上隨機化的學習模型。這些模型使用參數化的量子電路概括量子神經網路，並允許在表達能力和有效可訓練性之間進行取捨，特別是在量子硬體上。我們透過將形式主義應用於兩個最近提出的模型系列來證明其靈活性。第一個是可交換區塊量子神經網路 (QNN)，可有效訓練，但表達能力可能有限。第二個是正交（漢明權重保留）量子神經網路，可提供定義良好且可解釋的資料轉換，但難以在量子裝置上大規模訓練。密度可交換 QNN 改善容量，且梯度複雜度開銷最小，而密度正交神經網路承認二次到常數梯度查詢優勢，且效能幾乎沒有損失。我們對具有平移不變性的合成資料和 MNIST 影像資料進行數值實驗，並進行超參數最佳化以支持我們的發現。最後，我們討論與後變分量子神經網路、基於測量的量子機器學習和中斷機制的關聯。

##### **Context Injection Attacks on Large Language Models**
2405.20234v1 by Cheng'an Wei, Kai Chen, Yue Zhao, Yujia Gong, Lu Xiang, Shenchen Zhu

Large Language Models (LLMs) such as ChatGPT and Llama-2 have become
prevalent in real-world applications, exhibiting impressive text generation
performance. LLMs are fundamentally developed from a scenario where the input
data remains static and lacks a clear structure. To behave interactively over
time, LLM-based chat systems must integrate additional contextual information
(i.e., chat history) into their inputs, following a pre-defined structure. This
paper identifies how such integration can expose LLMs to misleading context
from untrusted sources and fail to differentiate between system and user
inputs, allowing users to inject context. We present a systematic methodology
for conducting context injection attacks aimed at eliciting disallowed
responses by introducing fabricated context. This could lead to illegal
actions, inappropriate content, or technology misuse. Our context fabrication
strategies, acceptance elicitation and word anonymization, effectively create
misleading contexts that can be structured with attacker-customized prompt
templates, achieving injection through malicious user messages. Comprehensive
evaluations on real-world LLMs such as ChatGPT and Llama-2 confirm the efficacy
of the proposed attack with success rates reaching 97%. We also discuss
potential countermeasures that can be adopted for attack detection and
developing more secure models. Our findings provide insights into the
challenges associated with the real-world deployment of LLMs for interactive
and structured data scenarios.

摘要：大型語言模型 (LLM)，例如 ChatGPT 和 Llama-2，在現實世界應用中已變得普遍，展現出令人印象深刻的文字生成效能。LLM 基本上是從輸入資料保持靜態且缺乏明確結構的場景中開發出來的。為了隨著時間互動式地執行，基於 LLM 的聊天系統必須將其他脈絡資訊（例如聊天記錄）整合到其輸入中，並遵循預先定義的結構。這篇論文探討了此整合如何讓 LLM 接收到來自不可信來源的誤導性脈絡，並無法區分系統和使用者輸入，進而讓使用者能注入脈絡。我們提出了一種系統性方法來進行脈絡注入攻擊，目的是透過引入虛構脈絡來引發不允許的回應。這可能會導致非法行為、不當內容或技術誤用。我們的脈絡捏造策略、接受引發和字詞匿名化，有效地創造出誤導性脈絡，這些脈絡可以用攻擊者自訂的提示範本來建構，並透過惡意使用者訊息來進行注入。對 ChatGPT 和 Llama-2 等現實世界的 LLM 進行的全面評估證實了所提出的攻擊的效力，成功率高達 97%。我們也討論了可以採用來進行攻擊偵測和開發更安全模型的潛在對策。我們的研究結果提供了對 LLM 在互動式和結構化資料場景中進行現實世界部署所面臨挑戰的見解。

##### **Grokfast: Accelerated Grokking by Amplifying Slow Gradients**
2405.20233v1 by Jaerin Lee, Bong Gyun Kang, Kihoon Kim, Kyoung Mu Lee

One puzzling artifact in machine learning dubbed grokking is where delayed
generalization is achieved tenfolds of iterations after near perfect
overfitting to the training data. Focusing on the long delay itself on behalf
of machine learning practitioners, our goal is to accelerate generalization of
a model under grokking phenomenon. By regarding a series of gradients of a
parameter over training iterations as a random signal over time, we can
spectrally decompose the parameter trajectories under gradient descent into two
components: the fast-varying, overfitting-yielding component and the
slow-varying, generalization-inducing component. This analysis allows us to
accelerate the grokking phenomenon more than $\times 50$ with only a few lines
of code that amplifies the slow-varying components of gradients. The
experiments show that our algorithm applies to diverse tasks involving images,
languages, and graphs, enabling practical availability of this peculiar
artifact of sudden generalization. Our code is available at
\url{https://github.com/ironjr/grokfast}.

摘要：<paragraph>機器學習中有一個令人費解的人工製品，稱為 grokking，其中延遲泛化是在對訓練資料過度擬合接近完美後，經過十倍的迭代才實現的。專注於機器學習從業者本身的長時間延遲，我們的目標是加速 grokking 現象下的模型泛化。通過將一系列訓練迭代中的參數梯度視為隨時間變化的隨機信號，我們可以將梯度下降下的參數軌跡光譜分解為兩個組成部分：變化快、產生過度擬合的組成部分和變化慢、誘導泛化的組成部分。這種分析使我們能夠僅通過幾行放大梯度中變化緩慢的組成部分的代碼，將 grokking 現象加速超過 50 倍。實驗表明，我們的演算法適用於涉及影像、語言和圖形的各種任務，使這種突然泛化的特殊人工製品具有實用的可用性。我們的代碼可在以下網址取得：\url{https://github.com/ironjr/grokfast}。</paragraph>

##### **The Empirical Impact of Neural Parameter Symmetries, or Lack Thereof**
2405.20231v1 by Derek Lim, Moe Putterman, Robin Walters, Haggai Maron, Stefanie Jegelka

Many algorithms and observed phenomena in deep learning appear to be affected
by parameter symmetries -- transformations of neural network parameters that do
not change the underlying neural network function. These include linear mode
connectivity, model merging, Bayesian neural network inference, metanetworks,
and several other characteristics of optimization or loss-landscapes. However,
theoretical analysis of the relationship between parameter space symmetries and
these phenomena is difficult. In this work, we empirically investigate the
impact of neural parameter symmetries by introducing new neural network
architectures that have reduced parameter space symmetries. We develop two
methods, with some provable guarantees, of modifying standard neural networks
to reduce parameter space symmetries. With these new methods, we conduct a
comprehensive experimental study consisting of multiple tasks aimed at
assessing the effect of removing parameter symmetries. Our experiments reveal
several interesting observations on the empirical impact of parameter
symmetries; for instance, we observe linear mode connectivity between our
networks without alignment of weight spaces, and we find that our networks
allow for faster and more effective Bayesian neural network training.

摘要：許多深度學習中的演算法和觀察到的現象似乎會受到參數對稱性影響，即神經網路參數的變換不會改變底層神經網路函數。這些包括線性模式連通性、模型合併、貝氏神經網路推論、元網路以及最佳化或損失景觀的幾個其他特徵。然而，參數空間對稱性與這些現象之間關係的理論分析很困難。在這項工作中，我們透過引入具有減少參數空間對稱性的新神經網路架構，實證探討神經參數對稱性的影響。我們開發了兩種方法（具有某些可證明保證），用於修改標準神經網路以減少參數空間對稱性。有了這些新方法，我們進行了一項全面的實驗研究，其中包含旨在評估移除參數對稱性效果的多項任務。我們的實驗揭示了參數對稱性的實證影響的幾個有趣觀察；例如，我們在沒有權重空間對齊的情況下觀察到我們的網路之間的線性模式連通性，並且我們發現我們的網路允許更快、更有效率的貝氏神經網路訓練。

##### **MOFA-Video: Controllable Image Animation via Generative Motion Field Adaptions in Frozen Image-to-Video Diffusion Model**
2405.20222v1 by Muyao Niu, Xiaodong Cun, Xintao Wang, Yong Zhang, Ying Shan, Yinqiang Zheng

We present MOFA-Video, an advanced controllable image animation method that
generates video from the given image using various additional controllable
signals (such as human landmarks reference, manual trajectories, and another
even provided video) or their combinations. This is different from previous
methods which only can work on a specific motion domain or show weak control
abilities with diffusion prior. To achieve our goal, we design several
domain-aware motion field adapters (\ie, MOFA-Adapters) to control the
generated motions in the video generation pipeline. For MOFA-Adapters, we
consider the temporal motion consistency of the video and generate the dense
motion flow from the given sparse control conditions first, and then, the
multi-scale features of the given image are wrapped as a guided feature for
stable video diffusion generation. We naively train two motion adapters for the
manual trajectories and the human landmarks individually since they both
contain sparse information about the control. After training, the MOFA-Adapters
in different domains can also work together for more controllable video
generation.

摘要：我們提出 MOFA-Video，一種進階的可控影像動畫方法，它使用各種額外的可控訊號（例如人類地標參考、手動軌跡，以及另提供的一段影片）或其組合，從給定的影像產生影片。這與先前的方法不同，後者只能在特定動作領域中運作，或在擴散之前展現出較弱的控制能力。為了達成我們的目標，我們設計了幾個領域感知動作場適配器（即 MOFA-Adapters），以控制影片生成管線中產生的動作。對於 MOFA-Adapters，我們考慮影片的時間動作一致性，並首先從給定的稀疏控制條件產生密集動作流，然後，給定影像的多尺度特徵被包裝為引導特徵，用於穩定的影片擴散生成。我們天真地訓練了兩個動作適配器，分別用於手動軌跡和人體地標，因為它們都包含稀疏的控制資訊。訓練後，不同領域的 MOFA-Adapters 也可以協同工作，以產生更多可控的影片。

##### **ESG-FTSE: A corpus of news articles with ESG relevance labels and use cases**
2405.20218v1 by Mariya Pavlova, Bernard Casey, Miaosen Wang

We present ESG-FTSE, the first corpus comprised of news articles with
Environmental, Social and Governance (ESG) relevance annotations. In recent
years, investors and regulators have pushed ESG investing to the mainstream due
to the urgency of climate change. This has led to the rise of ESG scores to
evaluate an investment's credentials as socially responsible. While demand for
ESG scores is high, their quality varies wildly. Quantitative techniques can be
applied to improve ESG scores, thus, responsible investing. To contribute to
resource building for ESG and financial text mining, we pioneer the ESG-FTSE
corpus. We further present the first of its kind ESG annotation schema. It has
three levels: a binary classification (relevant versus irrelevant news
articles), ESG classification (ESG-related news articles), and target company.
Both supervised and unsupervised learning experiments for ESG relevance
detection were conducted to demonstrate that the corpus can be used in
different settings to derive accurate ESG predictions. Keywords: corpus
annotation, ESG labels, annotation schema, news article, natural language
processing

摘要：我們提出 ESG-FTSE，這是第一個由具備環境、社會和治理 (ESG) 相關註釋的新聞文章組成的語料庫。近年來，由於氣候變遷的迫切性，投資人和監管機構已將 ESG 投資推向主流。這導致 ESG 分數的興起，用於評估投資的社會責任憑證。儘管對 ESG 分數的需求很高，但其品質卻差異很大。定量技術可應用於改善 ESG 分數，因此，負責任的投資。為了為 ESG 和財務文本探勘建立資源，我們開創了 ESG-FTSE 語料庫。我們進一步提出了第一個同類型的 ESG 註釋架構。它有三個層級：二元分類（相關與不相關的新聞文章）、ESG 分類（與 ESG 相關的新聞文章）和目標公司。進行了 ESG 相關性檢測的監督式和非監督式學習實驗，以證明該語料庫可用於不同的設定，以推導準確的 ESG 預測。關鍵字：語料庫註釋、ESG 標籤、註釋架構、新聞文章、自然語言處理

##### **Boost Your Own Human Image Generation Model via Direct Preference Optimization with AI Feedback**
2405.20216v1 by Sanghyeon Na, Yonggyu Kim, Hyunjoon Lee

The generation of high-quality human images through text-to-image (T2I)
methods is a significant yet challenging task. Distinct from general image
generation, human image synthesis must satisfy stringent criteria related to
human pose, anatomy, and alignment with textual prompts, making it particularly
difficult to achieve realistic results. Recent advancements in T2I generation
based on diffusion models have shown promise, yet challenges remain in meeting
human-specific preferences. In this paper, we introduce a novel approach
tailored specifically for human image generation utilizing Direct Preference
Optimization (DPO). Specifically, we introduce an efficient method for
constructing a specialized DPO dataset for training human image generation
models without the need for costly human feedback. We also propose a modified
loss function that enhances the DPO training process by minimizing artifacts
and improving image fidelity. Our method demonstrates its versatility and
effectiveness in generating human images, including personalized text-to-image
generation. Through comprehensive evaluations, we show that our approach
significantly advances the state of human image generation, achieving superior
results in terms of natural anatomies, poses, and text-image alignment.

摘要：透過文字轉圖像 (T2I) 方法產生高品質的人類圖像是一項重要且具有挑戰性的任務。與一般圖像生成不同，人類圖像合成必須滿足與人類姿勢、解剖結構和文字提示對齊相關的嚴格標準，這使得實現逼真的結果特別困難。基於擴散模型的 T2I 生成的最新進展已展現出前景，但仍有挑戰存在於滿足人類特定的偏好。在本文中，我們提出了一種針對人類圖像生成量身打造的新穎方法，利用直接偏好最佳化 (DPO)。具體來說，我們提出了一種用於建構專門的 DPO 資料集的有效方法，用於訓練人類圖像生成模型，而無需昂貴的人類回饋。我們還提出了一種修改後的損失函數，透過最小化人工製品並改善圖像保真度來增強 DPO 訓練流程。我們的模型展示了其在產生人類圖像方面的多功能性和有效性，包括個人化文字轉圖像生成。透過全面的評估，我們表明我們的模型顯著提升了人類圖像生成的狀態，在自然解剖、姿勢和文字圖像對齊方面取得了卓越的成果。

##### **TS-Align: A Teacher-Student Collaborative Framework for Scalable Iterative Finetuning of Large Language Models**
2405.20215v1 by Chen Zhang, Chengguang Tang, Dading Chong, Ke Shi, Guohua Tang, Feng Jiang, Haizhou Li

Mainstream approaches to aligning large language models (LLMs) heavily rely
on human preference data, particularly when models require periodic updates.
The standard process for iterative alignment of LLMs involves collecting new
human feedback for each update. However, the data collection process is costly
and challenging to scale. To address this issue, we introduce the "TS-Align"
framework, which fine-tunes a policy model using pairwise feedback data
automatically mined from its outputs. This automatic mining process is
efficiently accomplished through the collaboration between a large-scale
teacher model and a small-scale student model. The policy fine-tuning process
can be iteratively repeated using on-policy generations within our proposed
teacher-student collaborative framework. Through extensive experiments, we
demonstrate that our final aligned policy outperforms the base policy model
with an average win rate of 69.7% across seven conversational or
instruction-following datasets. Furthermore, we show that the ranking
capability of the teacher is effectively distilled into the student through our
pipeline, resulting in a small-scale yet effective reward model for policy
model alignment.

摘要：主流的大语言模型（LLM）校准方法严重依赖人类偏好数据，尤其是在模型需要定期更新时。LLM 迭代校准的标准流程包括为每次更新收集新的用户反馈。然而，数据收集过程成本高昂且难以扩展。为了解决这个问题，我们引入了“TS-Align”框架，该框架使用从其输出中自动挖掘的成对反馈数据对策略模型进行微调。这种自动挖掘过程通过大规模教师模型和小规模学生模型之间的协作有效完成。策略微调过程可以在我们提出的教师-学生协作框架内使用策略内生成进行迭代重复。通过广泛的实验，我们证明我们最终校准的策略优于基础策略模型，在七个会话或指令遵循数据集中的平均获胜率为 69.7%。此外，我们表明，教师的排名能力通过我们的管道有效地提炼到学生中，从而为策略模型校准生成了一个小规模但有效的奖励模型。

##### **PostDoc: Generating Poster from a Long Multimodal Document Using Deep Submodular Optimization**
2405.20213v1 by Vijay Jaisankar, Sambaran Bandyopadhyay, Kalp Vyas, Varre Chaitanya, Shwetha Somasundaram

A poster from a long input document can be considered as a one-page
easy-to-read multimodal (text and images) summary presented on a nice template
with good design elements. Automatic transformation of a long document into a
poster is a very less studied but challenging task. It involves content
summarization of the input document followed by template generation and
harmonization. In this work, we propose a novel deep submodular function which
can be trained on ground truth summaries to extract multimodal content from the
document and explicitly ensures good coverage, diversity and alignment of text
and images. Then, we use an LLM based paraphraser and propose to generate a
template with various design aspects conditioned on the input content. We show
the merits of our approach through extensive automated and human evaluations.

摘要：從長輸入文件產生的海報可以視為一個一頁式的、容易閱讀的多模態（文字和圖片）摘要，它展示在一個具有良好設計元素的漂亮範本上。將長文件自動轉換成海報是一個研究較少但具有挑戰性的任務。它涉及輸入文件的內容摘要，然後是範本產生和協調。在這項工作中，我們提出了一個新穎的深度次模函數，它可以在真實摘要上進行訓練，以從文件中提取多模態內容，並明確確保文字和圖片的良好覆蓋、多樣性和對齊。然後，我們使用一個基於 LLM 的同義詞改寫器，並提出根據輸入內容生成具有各種設計方面的範本。我們通過廣泛的自動化和人工評估展示了我們方法的優點。

##### **Jina CLIP: Your CLIP Model Is Also Your Text Retriever**
2405.20204v1 by Andreas Koukounas, Georgios Mastrapas, Michael Günther, Bo Wang, Scott Martens, Isabelle Mohr, Saba Sturua, Mohammad Kalim Akram, Joan Fontanals Martínez, Saahil Ognawala, Susana Guzman, Maximilian Werk, Nan Wang, Han Xiao

Contrastive Language-Image Pretraining (CLIP) is widely used to train models
to align images and texts in a common embedding space by mapping them to
fixed-sized vectors. These models are key to multimodal information retrieval
and related tasks. However, CLIP models generally underperform in text-only
tasks compared to specialized text models. This creates inefficiencies for
information retrieval systems that keep separate embeddings and models for
text-only and multimodal tasks. We propose a novel, multi-task contrastive
training method to address this issue, which we use to train the jina-clip-v1
model to achieve the state-of-the-art performance on both text-image and
text-text retrieval tasks.

摘要：對比語言圖像預訓練 (CLIP) 廣泛用於訓練模型，藉由將圖像和文字對應到固定大小的向量，將它們對齊在共同的嵌入空間中。這些模型是多模態資訊檢索和相關任務的關鍵。然而，與專門的文字模型相比，CLIP 模型在純文字任務中的表現通常較差。這會造成資訊檢索系統的低效率，因為它們為純文字和多模態任務保留了獨立的嵌入和模型。我們提出了一種新穎的多任務對比訓練方法來解決這個問題，我們使用它來訓練 jina-clip-v1 模型，以在文字圖像和文字文字檢索任務中達到最先進的效能。

##### **One QuantLLM for ALL: Fine-tuning Quantized LLMs Once for Efficient Deployments**
2405.20202v1 by Ke Yi, Yuhui Xu, Heng Chang, Chen Tang, Yuan Meng, Tong Zhang, Jia Li

Large Language Models (LLMs) have advanced rapidly but face significant
memory demands. While quantization has shown promise for LLMs, current methods
typically require lengthy training to alleviate the performance degradation
from quantization loss. However, deploying LLMs across diverse scenarios with
different resource constraints, e.g., servers and personal computers, requires
repeated training per application, which amplifies the lengthy training
problem. Given that, it is advantageous to train a once-for-all (OFA) supernet
capable of yielding diverse optimal subnets for downstream applications through
one-shot training. Nonetheless, the scale of current language models impedes
efficiency and amplifies interference from weight sharing between subnets. We
make an initial attempt to extend the once-for-all framework to large language
models. Specifically, we decouple shared weights to eliminate the interference
and incorporate Low-Rank adapters for training efficiency. Furthermore, we
observe the imbalance allocation of training resources from the traditional
uniform sampling. A non-parametric scheduler is introduced to adjust the
sampling rate for each quantization configuration, achieving a more balanced
allocation among subnets with varying demands. We validate the approach on
LLaMA2 families, and downstream evaluation confirms our ability to maintain
high performance while significantly reducing deployment time faced with
multiple scenarios.

摘要：大型語言模型 (LLM) 已迅速進步，但面臨嚴峻的記憶體需求。雖然量化已顯示出對 LLM 的前景，但目前的技術通常需要冗長的訓練，以減輕量化損失造成的效能下降。然而，在具有不同資源限制的不同情況下部署 LLM，例如伺服器和個人電腦，需要針對每個應用程式進行重複訓練，這會擴大冗長的訓練問題。有鑑於此，訓練一次性 (OFA) 超級網路是有利的，它能夠透過一次性訓練為下游應用程式產生多樣化的最佳子網路。儘管如此，目前語言模型的規模會阻礙效率，並擴大子網路之間權重共享的干擾。我們最初嘗試將一次性架構擴展到大型語言模型。具體來說，我們解耦共享權重以消除干擾，並加入低秩適配器以提高訓練效率。此外，我們觀察到傳統均勻取樣訓練資源分配的不平衡。引入非參數排程器來調整每個量化配置的取樣率，在需求不同的子網路之間實現更平衡的分配。我們在 LLaMA2 家族中驗證了這種方法，而下游評估證實了我們在面對多種情況時，能夠在顯著減少部署時間的同時，維持高性能。

##### **TAIA: Large Language Models are Out-of-Distribution Data Learners**
2405.20192v1 by Shuyang Jiang, Yusheng Liao, Ya Zhang, Yu Wang, Yanfeng Wang

Fine-tuning on task-specific question-answer pairs is a predominant method
for enhancing the performance of instruction-tuned large language models (LLMs)
on downstream tasks. However, in certain specialized domains, such as
healthcare or harmless content generation, it is nearly impossible to obtain a
large volume of high-quality data that matches the downstream distribution. To
improve the performance of LLMs in data-scarce domains with domain-mismatched
data, we re-evaluated the Transformer architecture and discovered that not all
parameter updates during fine-tuning contribute positively to downstream
performance. Our analysis reveals that within the self-attention and
feed-forward networks, only the fine-tuned attention parameters are
particularly beneficial when the training set's distribution does not fully
align with the test set. Based on this insight, we propose an effective
inference-time intervention method: \uline{T}raining \uline{A}ll parameters but
\uline{I}nferring with only \uline{A}ttention (\trainallInfAttn). We
empirically validate \trainallInfAttn using two general instruction-tuning
datasets and evaluate it on seven downstream tasks involving math, reasoning,
and knowledge understanding across LLMs of different parameter sizes and
fine-tuning techniques. Our comprehensive experiments demonstrate that
\trainallInfAttn achieves superior improvements compared to both the fully
fine-tuned model and the base model in most scenarios, with significant
performance gains. The high tolerance of \trainallInfAttn to data mismatches
makes it resistant to jailbreaking tuning and enhances specialized tasks using
general data.

摘要：<paragraph>针对特定任务的问答对进行微调是一种增强指令微调大型语言模型 (LLM) 在下游任务上性能的主要方法。然而，在某些专业领域（如医疗保健或无害内容生成）中，几乎不可能获得与下游分布匹配的大量高质量数据。为了提高 LLM 在数据稀缺且数据与领域不匹配的领域中的性能，我们重新评估了 Transformer 架构，并发现微调期间并非所有参数更新都能对下游性能产生积极影响。我们的分析表明，在自注意力和前馈网络中，只有经过微调的注意力参数在训练集分布与测试集不完全一致时才特别有益。基于这一见解，我们提出了一种有效的推理时间干预方法：\uline{T}raining \uline{A}ll parameters but \uline{I}nferring with only \uline{A}ttention (\trainallInfAttn)。我们使用两个通用指令微调数据集对 \trainallInfAttn 进行了实证验证，并在涉及不同参数大小和微调技术的 LLM 中对七个下游任务（包括数学、推理和知识理解）进行了评估。我们的综合实验表明，在大多数情况下，与经过完全微调的模型和基础模型相比，\trainallInfAttn 取得了卓越的改进，并获得了显著的性能提升。\trainallInfAttn 对数据不匹配的高度容忍性使其能够抵抗越狱调优，并使用通用数据增强专业任务。</paragraph>

##### **Nadine: An LLM-driven Intelligent Social Robot with Affective Capabilities and Human-like Memory**
2405.20189v1 by Hangyeol Kang, Maher Ben Moussa, Nadia Magnenat-Thalmann

In this work, we describe our approach to developing an intelligent and
robust social robotic system for the Nadine social robot platform. We achieve
this by integrating Large Language Models (LLMs) and skilfully leveraging the
powerful reasoning and instruction-following capabilities of these types of
models to achieve advanced human-like affective and cognitive capabilities.
This approach is novel compared to the current state-of-the-art LLM-based
agents which do not implement human-like long-term memory or sophisticated
emotional appraisal. The naturalness of social robots, consisting of multiple
modules, highly depends on the performance and capabilities of each component
of the system and the seamless integration of the components. We built a social
robot system that enables generating appropriate behaviours through multimodal
input processing, bringing episodic memories accordingly to the recognised
user, and simulating the emotional states of the robot induced by the
interaction with the human partner. In particular, we introduce an LLM-agent
frame for social robots, SoR-ReAct, serving as a core component for the
interaction module in our system. This design has brought forth the advancement
of social robots and aims to increase the quality of human-robot interaction.

摘要：在這項工作中，我們描述了我們開發智慧且強健的社交機器人系統的方法，以用於 Nadine 社交機器人平台。我們透過整合大型語言模型 (LLM) 並巧妙地利用這些類型模型強大的推理和遵循指示的能力，來達成此目標，進而實現進階的人類情感和認知能力。與目前最先進、基於 LLM 的代理程式相比，這種方法是創新的，因為它沒有實作人類長期記憶或複雜的情緒評估。社交機器人的自然性包含多個模組，高度依賴於系統中每個元件的效能和功能，以及元件之間的無縫整合。我們建構了一個社交機器人系統，能夠透過多模式輸入處理來產生適當的行為，根據辨識出的使用者提供情境記憶，並模擬機器人因與人類夥伴互動而產生的情緒狀態。特別是，我們為社交機器人引進了一個 LLM 代理程式架構 SoR-ReAct，作為我們系統中互動模組的核心元件。此設計促成了社交機器人的進步，並旨在提升人機互動的品質。

##### **A Survey Study on the State of the Art of Programming Exercise Generation using Large Language Models**
2405.20183v1 by Eduard Frankford, Ingo Höhn, Clemens Sauerwein, Ruth Breu

This paper analyzes Large Language Models (LLMs) with regard to their
programming exercise generation capabilities. Through a survey study, we
defined the state of the art, extracted their strengths and weaknesses and
finally proposed an evaluation matrix, helping researchers and educators to
decide which LLM is the best fitting for the programming exercise generation
use case. We also found that multiple LLMs are capable of producing useful
programming exercises. Nevertheless, there exist challenges like the ease with
which LLMs might solve exercises generated by LLMs. This paper contributes to
the ongoing discourse on the integration of LLMs in education.

摘要：這篇論文分析了大型語言模型 (LLM) 在程式練習產生能力方面的表現。透過一項調查研究，我們定義了目前最先進的技術，找出其優缺點，最後提出一個評估矩陣，協助研究人員和教育工作者決定哪個 LLM 最適合用於產生程式練習。我們也發現，多個 LLM 都能產生有用的程式練習。儘管如此，仍存在一些挑戰，例如 LLM 可以輕易解出由 LLM 產生的練習。這篇論文有助於持續討論在教育中整合 LLM。

##### **Transformers and Slot Encoding for Sample Efficient Physical World Modelling**
2405.20180v1 by Francesco Petri, Luigi Asprino, Aldo Gangemi

World modelling, i.e. building a representation of the rules that govern the
world so as to predict its evolution, is an essential ability for any agent
interacting with the physical world. Recent applications of the Transformer
architecture to the problem of world modelling from video input show notable
improvements in sample efficiency. However, existing approaches tend to work
only at the image level thus disregarding that the environment is composed of
objects interacting with each other. In this paper, we propose an architecture
combining Transformers for world modelling with the slot-attention paradigm, an
approach for learning representations of objects appearing in a scene. We
describe the resulting neural architecture and report experimental results
showing an improvement over the existing solutions in terms of sample
efficiency and a reduction of the variation of the performance over the
training examples. The code for our architecture and experiments is available
at https://github.com/torchipeppo/transformers-and-slot-encoding-for-wm

摘要：世界建模，即构建支配世界的规则的表示，以便预测其演变，是任何与物理世界交互的代理的基本能力。Transformer 架构最近应用于从视频输入中进行世界建模的问题，在样本效率方面显示出显着改进。然而，现有方法往往只在图像级别工作，因此忽略了环境是由相互交互的对象组成的。在本文中，我们提出了一种架构，将用于世界建模的 Transformer 与插槽注意力范例相结合，这是一种学习场景中出现的对象表示的方法。我们描述了由此产生的神经架构，并报告了实验结果，表明在样本效率方面优于现有解决方案，并减少了训练示例中性能的变化。我们架构和实验的代码可在 https://github.com/torchipeppo/transformers-and-slot-encoding-for-wm 获得

##### **Robo-Instruct: Simulator-Augmented Instruction Alignment For Finetuning CodeLLMs**
2405.20179v1 by Zichao Hu, Junyi Jessy Li, Arjun Guha, Joydeep Biswas

Large language models (LLMs) have shown great promise at generating robot
programs from natural language given domain-specific robot application
programming interfaces (APIs). However, the performance gap between proprietary
LLMs and smaller open-weight LLMs remains wide. This raises a question: Can we
fine-tune smaller open-weight LLMs for generating domain-specific robot
programs to close the performance gap with proprietary LLMs? While
Self-Instruct is a promising solution by generating a diverse set of training
data, it cannot verify the correctness of these programs. In contrast, a robot
simulator with a well-defined world can identify execution errors but limits
the diversity of programs that it can verify. In this work, we introduce
Robo-Instruct, which brings the best of both worlds -- it promotes the
diversity of Self-Instruct while providing the correctness of simulator-based
checking. Robo-Instruct introduces RoboSim to synthesize a consistent world
state on the fly by inferring properties relevant to the program being checked,
and simulating actions accordingly. Furthermore, the instructions and programs
generated by Self-Instruct may be subtly inconsistent -- such as the program
missing a step implied by the instruction. Robo-Instruct further addresses this
with InstAlign, an instruction-program alignment procedure that revises the
task instruction to reflect the actual results of the generated program. Given
a few seed task descriptions and the robot APIs, Robo-Instruct is capable of
generating a training dataset using only a small open-weight model. This
dataset can then be used to fine-tune small open-weight language models,
enabling them to match or even exceed the performance of several proprietary
LLMs, such as GPT-3.5-Turbo and Gemini-Pro.

摘要：大型語言模型 (LLM) 在透過特定於領域的機器人應用程式介面 (API) 從自然語言產生機器人程式方面展現極大的潛力。然而，專有 LLM 與較小的開放權重 LLM 之間的效能差距仍然很大。這引發了一個問題：我們可以微調較小的開放權重 LLM 以產生特定於領域的機器人程式，以縮小與專有 LLM 的效能差距嗎？雖然 Self-Instruct 透過產生多樣化的訓練資料集來提供一個有前途的解決方案，但它無法驗證這些程式的正確性。相反地，具有明確定義世界的機器人模擬器可以識別執行錯誤，但會限制它可以驗證的程式多樣性。在這項工作中，我們引入了 Robo-Instruct，它結合了兩全其美的優點——它促进了 Self-Instruct 的多樣性，同時提供了基於模擬器的檢查的正確性。Robo-Instruct 介紹了 RoboSim，它透過推論與正在檢查的程式相關的屬性，並據此模擬動作，來即時合成一致的世界狀態。此外，Self-Instruct 產生的指令和程式可能微妙地不一致——例如程式遺漏了指令暗示的步驟。Robo-Instruct 進一步透過 InstAlign 來解決這個問題，InstAlign 是一種指令程式對齊程序，它會修改任務指令以反映產生程式的實際結果。給定幾個種子任務描述和機器人 API，Robo-Instruct 能夠僅使用一個小的開放權重模型來產生訓練資料集。然後可以使用這個資料集來微調小的開放權重語言模型，使它們能夠匹配甚至超過幾個專有 LLM 的效能，例如 GPT-3.5-Turbo 和 Gemini-Pro。

##### **InstructionCP: A fast approach to transfer Large Language Models into target language**
2405.20175v1 by Kuang-Ming Chen, Hung-yi Lee

The rapid development of large language models (LLMs) in recent years has
largely focused on English, resulting in models that respond exclusively in
English. To adapt these models to other languages, continual pre-training (CP)
is often employed, followed by supervised fine-tuning (SFT) to maintain
conversational abilities. However, CP and SFT can reduce a model's ability to
filter harmful content. We propose Instruction Continual Pre-training (InsCP),
which integrates instruction tags into the CP process to prevent loss of
conversational proficiency while acquiring new languages. Our experiments
demonstrate that InsCP retains conversational and Reinforcement Learning from
Human Feedback (RLHF) abilities. Empirical evaluations on language alignment,
reliability, and knowledge benchmarks confirm the efficacy of InsCP. Notably,
this approach requires only 0.1 billion tokens of high-quality
instruction-following data, thereby reducing resource consumption.

摘要：近年來，大型語言模型 (LLM) 的快速發展主要集中在英文，導致模型只能以英文回應。為了讓這些模型適應其他語言，通常採用持續預訓練 (CP)，然後進行監督微調 (SFT) 以維持對話能力。然而，CP 和 SFT 會降低模型過濾有害內容的能力。我們提出指令持續預訓練 (InsCP)，將指令標籤整合到 CP 過程中，以防止在習得新語言時喪失對話能力。我們的實驗證明，InsCP 保留了對話和人類回饋強化學習 (RLHF) 的能力。在語言對齊、可靠性和知識基準上的實證評估證實了 InsCP 的效力。值得注意的是，這種方法只需要 0.1 億個代幣的高品質遵循指令數據，從而減少了資源消耗。

##### **Iterative Feature Boosting for Explainable Speech Emotion Recognition**
2405.20172v1 by Alaa Nfissi, Wassim Bouachir, Nizar Bouguila, Brian Mishara

In speech emotion recognition (SER), using predefined features without
considering their practical importance may lead to high dimensional datasets,
including redundant and irrelevant information. Consequently, high-dimensional
learning often results in decreasing model accuracy while increasing
computational complexity. Our work underlines the importance of carefully
considering and analyzing features in order to build efficient SER systems. We
present a new supervised SER method based on an efficient feature engineering
approach. We pay particular attention to the explainability of results to
evaluate feature relevance and refine feature sets. This is performed
iteratively through feature evaluation loop, using Shapley values to boost
feature selection and improve overall framework performance. Our approach
allows thus to balance the benefits between model performance and transparency.
The proposed method outperforms human-level performance (HLP) and
state-of-the-art machine learning methods in emotion recognition on the TESS
dataset.

摘要：在語音情緒辨識 (SER) 中，使用預定義特徵而不考慮其實際重要性可能會導致高維度資料集，其中包含冗餘且無關的資訊。因此，高維度學習通常會導致模型準確度下降，同時增加計算複雜度。我們的研究強調仔細考慮和分析特徵以建構有效 SER 系統的重要性。我們提出一個新的監督式 SER 方法，該方法基於有效特徵工程方法。我們特別注意結果的可解釋性，以評估特徵相關性並改善特徵集。這透過特徵評估迴圈反覆執行，使用 Shapley 值來提升特徵選取並改善整體架構效能。因此，我們的做法可以平衡模型效能與透明度之間的優點。所提出的方法在 TESS 資料集上的情緒辨識中優於人類等級效能 (HLP) 和最先進的機器學習方法。

##### **Reasoning about concepts with LLMs: Inconsistencies abound**
2405.20163v1 by Rosario Uceda-Sosa, Karthikeyan Natesan Ramamurthy, Maria Chang, Moninder Singh

The ability to summarize and organize knowledge into abstract concepts is key
to learning and reasoning. Many industrial applications rely on the consistent
and systematic use of concepts, especially when dealing with decision-critical
knowledge. However, we demonstrate that, when methodically questioned, large
language models (LLMs) often display and demonstrate significant
inconsistencies in their knowledge. Computationally, the basic aspects of the
conceptualization of a given domain can be represented as Is-A hierarchies in a
knowledge graph (KG) or ontology, together with a few properties or axioms that
enable straightforward reasoning. We show that even simple ontologies can be
used to reveal conceptual inconsistencies across several LLMs. We also propose
strategies that domain experts can use to evaluate and improve the coverage of
key domain concepts in LLMs of various sizes. In particular, we have been able
to significantly enhance the performance of LLMs of various sizes with openly
available weights using simple knowledge-graph (KG) based prompting strategies.

摘要：摘要和組織知識成為抽象概念的能力是學習和推理的關鍵。許多產業應用仰賴概念的一致且系統性使用，特別是在處理決策關鍵知識時。然而，我們證明，當經過有系統地質疑時，大型語言模型 (LLM) 經常顯示並展示其知識中的重大不一致性。在計算上，給定領域的概念化的基本面向可以用知識圖譜 (KG) 或本體論中的 Is-A 階層來表示，以及一些屬性或公理，這些屬性或公理能進行直接推理。我們證明，即使是簡單的本體論也能用來揭露跨多個 LLM 的概念不一致性。我們也提出領域專家可以用來評估和改善各種規模 LLM 中關鍵領域概念涵蓋範圍的策略。特別是，我們已經能夠使用基於簡單知識圖譜 (KG) 的提示策略，大幅提升各種規模 LLM 的性能，這些 LLM 使用開放可用的權重。

##### **Heidelberg-Boston @ SIGTYP 2024 Shared Task: Enhancing Low-Resource Language Analysis With Character-Aware Hierarchical Transformers**
2405.20145v1 by Frederick Riemenschneider, Kevin Krahn

Historical languages present unique challenges to the NLP community, with one
prominent hurdle being the limited resources available in their closed corpora.
This work describes our submission to the constrained subtask of the SIGTYP
2024 shared task, focusing on PoS tagging, morphological tagging, and
lemmatization for 13 historical languages. For PoS and morphological tagging we
adapt a hierarchical tokenization method from Sun et al. (2023) and combine it
with the advantages of the DeBERTa-V3 architecture, enabling our models to
efficiently learn from every character in the training data. We also
demonstrate the effectiveness of character-level T5 models on the lemmatization
task. Pre-trained from scratch with limited data, our models achieved first
place in the constrained subtask, nearly reaching the performance levels of the
unconstrained task's winner. Our code is available at
https://github.com/bowphs/SIGTYP-2024-hierarchical-transformers

摘要：歷史語言對 NLP 社群來說是一項獨特的挑戰，其中一個突出的障礙是其封閉語料庫中可用的資源有限。本文說明我們提交給 SIGTYP 2024 共享任務的受限子任務，重點在於 13 種歷史語言的詞性標記、形態標記和詞形還原。對於詞性標記和形態標記，我們採用 Sun 等人 (2023) 的階層式標記化方法，並將其與 DeBERTa-V3 架構的優點結合，讓我們的模型能夠有效率地從訓練資料中的每個字元學習。我們也展示了字元級 T5 模型在詞形還原任務上的有效性。我們的模型從有限的資料中從頭開始預先訓練，在受限子任務中獲得第一名，幾乎達到不受限任務獲勝者的效能等級。我們的程式碼可在 https://github.com/bowphs/SIGTYP-2024-hierarchical-transformers 取得

##### **MSSC-BiMamba: Multimodal Sleep Stage Classification and Early Diagnosis of Sleep Disorders with Bidirectional Mamba**
2405.20142v1 by Chao Zhanga, Weirong Cuia, Jingjing Guo

Background and Objectives: Monitoring sleep states is crucial for assessing
sleep quality and diagnosing sleep disorders. Traditional manual staging
methods are not only time-consuming but also subject to subjective judgment,
leading to inconsistent results. This study developed an automated sleep
staging and sleep disorder classification model through deep learning
technology, aimed at improving diagnostic accuracy and efficiency.
  Methods: Considering the characteristics of polysomnography (PSG) multi-lead
sleep monitoring, we designed a sleep state classification model, MSSC-BiMamba,
that combines an Efficient Channel Attention (ECA) mechanism with a
Bidirectional State Space Model (BSSM). The ECA module allows for weighting
data from different sensor channels, thereby amplifying the influence of
diverse sensor inputs. Additionally, the implementation of mamba enables the
model to effectively capture the multidimensional features and long-range
dependencies of PSG data.
  Results: The developed model demonstrated impressive performance on sleep
stage classification tasks. Furthermore, the model exhibited an accuracy of
0.952 for sleep health prediction when evaluated on a combined dataset
consisting of ISRUC and Sleep-EDF.
  Conclusion: Our model is the first to apply the bidirectional Mamba to sleep
staging with complex PSG data, showing substantial gains in computational and
memory efficiency over traditional Transformer-style models. This method not
only makes health monitoring more accessible but also broadens the reach of
advanced healthcare, thereby enhancing sleep health management with innovative
technology.

摘要：背景與目標：監控睡眠狀態對於評估睡眠品質和診斷睡眠障礙至關重要。傳統的人工分期方法不僅耗時，而且容易受到主觀判斷的影響，導致結果不一致。本研究通過深度學習技術開發了一種自動化睡眠分期和睡眠障礙分類模型，旨在提高診斷準確性和效率。
方法：考慮多導睡眠描記術 (PSG) 多導程睡眠監測的特點，我們設計了一個睡眠狀態分類模型 MSSC-BiMamba，該模型將高效通道注意 (ECA) 機制與雙向狀態空間模型 (BSSM) 相結合。ECA 模塊允許對來自不同感測器通道的數據進行加權，從而放大不同感測器輸入的影響。此外，mamba 的實現使模型能夠有效捕捉 PSG 數據的多維特徵和長程依賴性。
結果：所開發的模型在睡眠分期分類任務上表現出令人印象深刻的性能。此外，該模型在由 ISRUC 和 Sleep-EDF 組成的組合數據集上進行評估時，在睡眠健康預測方面的準確度為 0.952。
結論：我們的模型是第一個將雙向 Mamba 應用於具有複雜 PSG 數據的睡眠分期的模型，在運算和記憶效率方面顯示出比傳統 Transformer 風格模型顯著的提升。這種方法不僅使健康監測更易於使用，而且擴大了先進醫療保健的覆蓋範圍，從而通過創新技術增強睡眠健康管理。

##### **GNN-RAG: Graph Neural Retrieval for Large Language Model Reasoning**
2405.20139v1 by Costas Mavromatis, George Karypis

Knowledge Graphs (KGs) represent human-crafted factual knowledge in the form
of triplets (head, relation, tail), which collectively form a graph. Question
Answering over KGs (KGQA) is the task of answering natural questions grounding
the reasoning to the information provided by the KG. Large Language Models
(LLMs) are the state-of-the-art models for QA tasks due to their remarkable
ability to understand natural language. On the other hand, Graph Neural
Networks (GNNs) have been widely used for KGQA as they can handle the complex
graph information stored in the KG. In this work, we introduce GNN-RAG, a novel
method for combining language understanding abilities of LLMs with the
reasoning abilities of GNNs in a retrieval-augmented generation (RAG) style.
First, a GNN reasons over a dense KG subgraph to retrieve answer candidates for
a given question. Second, the shortest paths in the KG that connect question
entities and answer candidates are extracted to represent KG reasoning paths.
The extracted paths are verbalized and given as input for LLM reasoning with
RAG. In our GNN-RAG framework, the GNN acts as a dense subgraph reasoner to
extract useful graph information, while the LLM leverages its natural language
processing ability for ultimate KGQA. Furthermore, we develop a retrieval
augmentation (RA) technique to further boost KGQA performance with GNN-RAG.
Experimental results show that GNN-RAG achieves state-of-the-art performance in
two widely used KGQA benchmarks (WebQSP and CWQ), outperforming or matching
GPT-4 performance with a 7B tuned LLM. In addition, GNN-RAG excels on multi-hop
and multi-entity questions outperforming competing approaches by 8.9--15.5%
points at answer F1.

摘要：<paragraph>知識圖譜 (KG) 以三元組 (主詞、關係、賓詞) 的形式表示人工建立的事實知識，這些三元組共同形成一個圖形。在 KG 上進行問答 (KGQA) 是回答自然問題的任務，將推理基礎建立在 KG 提供的資訊上。大型語言模型 (LLM) 由於其理解自然語言的非凡能力，成為問答任務的最新技術。另一方面，圖形神經網路 (GNN) 已廣泛用於 KGQA，因為它們可以處理儲存在 KG 中的複雜圖形資訊。在這項工作中，我們介紹了 GNN-RAG，這是一種新方法，結合了 LLM 的語言理解能力和 GNN 的推理能力，採用檢索增強生成 (RAG) 的方式。首先，GNN 在一個密集的 KG 子圖中進行推理，以檢索給定問題的答案候選。其次，提取 KG 中連接問題實體和答案候選的最短路徑，以表示 KG 推理路徑。提取的路徑會被口頭化，並作為輸入提供給 LLM，以便使用 RAG 進行推理。在我們的 GNN-RAG 框架中，GNN 作為一個密集子圖推理器，用於提取有用的圖形資訊，而 LLM 則利用其自然語言處理能力進行最終的 KGQA。此外，我們開發了一種檢索增強 (RA) 技術，以進一步提升 GNN-RAG 的 KGQA 效能。實驗結果顯示，GNN-RAG 在兩個廣泛使用的 KGQA 基準 (WebQSP 和 CWQ) 中達到了最先進的效能，在使用 7B 調整後的 LLM 中超越或匹配 GPT-4 的效能。此外，GNN-RAG 在多跳和多實體問題上表現出色，在答案 F1 上比競爭方法高出 8.9--15.5%。</paragraph>

##### **LLaMEA: A Large Language Model Evolutionary Algorithm for Automatically Generating Metaheuristics**
2405.20132v1 by Niki van Stein, Thomas Bäck

Large Language Models (LLMs) such as GPT-4 have demonstrated their ability to
understand natural language and generate complex code snippets. This paper
introduces a novel Large Language Model Evolutionary Algorithm (LLaMEA)
framework, leveraging GPT models for the automated generation and refinement of
algorithms. Given a set of criteria and a task definition (the search space),
LLaMEA iteratively generates, mutates and selects algorithms based on
performance metrics and feedback from runtime evaluations. This framework
offers a unique approach to generating optimized algorithms without requiring
extensive prior expertise. We show how this framework can be used to generate
novel black-box metaheuristic optimization algorithms automatically. LLaMEA
generates multiple algorithms that outperform state-of-the-art optimization
algorithms (Covariance Matrix Adaptation Evolution Strategy and Differential
Evolution) on the five dimensional black box optimization benchmark (BBOB). The
results demonstrate the feasibility of the framework and identify future
directions for automated generation and optimization of algorithms via LLMs.

摘要：大型語言模型 (LLM)，例如 GPT-4，已展示其理解自然語言和生成複雜程式碼片段的能力。本文介紹了一種新穎的大型語言模型演算法 (LLaMEA) 架構，利用 GPT 模型自動生成和改進演算法。給定一組標準和任務定義（搜尋空間），LLaMEA 會根據執行時間評估的效能指標和回饋，反覆生成、變異和選擇演算法。此架構提供了一種獨特的方法來生成最佳化演算法，而無需廣泛的先驗專業知識。我們展示了如何使用此架構自動生成新穎的黑盒元啟發式最佳化演算法。LLaMEA 生成了多種演算法，其效能優於五維黑盒最佳化基準 (BBOB) 上的最新最佳化演算法（協方差矩陣適應演化策略和差分演化）。結果證明了此架構的可行性，並指出了透過 LLM 自動生成和最佳化演算法的未來方向。

##### **Language Models Need Inductive Biases to Count Inductively**
2405.20131v1 by Yingshan Chang, Yonatan Bisk

Counting is a fundamental example of generalization, whether viewed through
the mathematical lens of Peano's axioms defining the natural numbers or the
cognitive science literature for children learning to count. The argument holds
for both cases that learning to count means learning to count infinitely. While
few papers have tried to distill transformer "reasoning" to the simplest case
of counting, investigating length generalization does occur throughout the
literature. In the "train short, test long" paradigm of NLP, length refers to
the training sentence length. In formal language recognition, length refers to
the input sequence length, or the maximum stack size induced by a pushdown
automata. In general problem solving, length refers to the number of hops in a
deductive reasoning chain or the recursion depth. For all cases, counting is
central to task success. And crucially, generalizing counting inductively is
central to success on OOD instances. This work provides extensive empirical
results on training language models to count. We experiment with architectures
ranging from RNNs, Transformers, State-Space Models and RWKV. We present
carefully-designed task formats, auxiliary tasks and positional embeddings to
avoid limitations in generalization with OOD-position and OOD-vocabulary. We
find that while traditional RNNs trivially achieve inductive counting,
Transformers have to rely on positional embeddings to count out-of-domain. As
counting is the basis for many arguments concerning the expressivity of
Transformers, our finding calls for the community to reexamine the application
scope of primitive functions defined in formal characterizations. Finally,
modern RNNs also largely underperform traditional RNNs in generalizing counting
inductively. We discuss how design choices that enable parallelized training of
modern RNNs cause them to lose merits of a recurrent nature.

摘要：<paragraph>無論是從定義自然數的皮亞諾公理的數學角度來看，還是從兒童學習數數的認知科學文獻來看，數數都是概括化的基本範例。這兩方面的論點都認為，學習數數意味著學習無限數數。儘管很少有論文試圖將Transformer的「推理」簡化為最簡單的數數案例，但在整個文獻中確實會探討長度概括化。在 NLP 的「短訓練，長測試」範例中，長度是指訓練句子的長度。在形式語言識別中，長度是指輸入序列的長度，或由下推自動機產生的最大堆疊大小。在一般問題解決中，長度是指演繹推理鏈中的跳躍次數或遞迴深度。對於所有情況，數數對於任務成功至關重要。而且至關重要的是，歸納概括數數對於 OOD 實例的成功至關重要。這項工作提供了廣泛的實證結果，說明訓練語言模型進行數數。我們實驗了從 RNN、Transformer、狀態空間模型和 RWKV 等架構。我們提出了精心設計的任務格式、輔助任務和位置嵌入，以避免在 OOD 位置和 OOD 詞彙中概括的限制。我們發現，雖然傳統的 RNN 可以輕而易舉地實現歸納數數，但Transformer必須依賴位置嵌入才能進行域外數數。由於數數是許多關於Transformer表達能力的論點的基礎，我們的發現要求社群重新審視形式表徵中定義的原始函數的應用範圍。最後，現代 RNN 在歸納概括數數方面也遠遠不如傳統 RNN。我們討論了使現代 RNN 能夠進行並行訓練的設計選擇如何導致它們失去遞迴特性的優點。</paragraph>

##### **A Structure-Aware Lane Graph Transformer Model for Vehicle Trajectory Prediction**
2405.20121v1 by Sun Zhanbo, Dong Caiyin, Ji Ang, Zhao Ruibin, Zhao Yu

Accurate prediction of future trajectories for surrounding vehicles is vital
for the safe operation of autonomous vehicles. This study proposes a Lane Graph
Transformer (LGT) model with structure-aware capabilities. Its key contribution
lies in encoding the map topology structure into the attention mechanism. To
address variations in lane information from different directions, four Relative
Positional Encoding (RPE) matrices are introduced to capture the local details
of the map topology structure. Additionally, two Shortest Path Distance (SPD)
matrices are employed to capture distance information between two accessible
lanes. Numerical results indicate that the proposed LGT model achieves a
significantly higher prediction performance on the Argoverse 2 dataset.
Specifically, the minFDE$_6$ metric was decreased by 60.73% compared to the
Argoverse 2 baseline model (Nearest Neighbor) and the b-minFDE$_6$ metric was
reduced by 2.65% compared to the baseline LaneGCN model. Furthermore, ablation
experiments demonstrated that the consideration of map topology structure led
to a 4.24% drop in the b-minFDE$_6$ metric, validating the effectiveness of
this model.

摘要：準確預測周圍車輛的未來軌跡對於自動駕駛車輛的安全操作至關重要。本研究提出了一種具有結構感知能力的車道圖形轉換器 (LGT) 模型。它的關鍵貢獻在於將地圖拓撲結構編碼到注意力機制中。為了解決來自不同方向的車道資訊變異，引入了四個相對位置編碼 (RPE) 矩陣來擷取地圖拓撲結構的局部細節。此外，採用了兩個最短路徑距離 (SPD) 矩陣來擷取兩個可通行車道之間的距離資訊。數值結果表明，所提出的 LGT 模型在 Argoverse 2 資料集上達到了顯著更高的預測效能。具體而言，與 Argoverse 2 基準模型 (最近鄰域) 相比，minFDE$_6$ 指標下降了 60.73%，而與基線 LaneGCN 模型相比，b-minFDE$_6$ 指標下降了 2.65%。此外，消融實驗表明，考慮地圖拓撲結構導致 b-minFDE$_6$ 指標下降了 4.24%，驗證了此模型的有效性。

##### **Fill in the Gap! Combining Self-supervised Representation Learning with Neural Audio Synthesis for Speech Inpainting**
2405.20101v1 by Ihab Asaad, Maxime Jacquelin, Olivier Perrotin, Laurent Girin, Thomas Hueber

Most speech self-supervised learning (SSL) models are trained with a pretext
task which consists in predicting missing parts of the input signal, either
future segments (causal prediction) or segments masked anywhere within the
input (non-causal prediction). Learned speech representations can then be
efficiently transferred to downstream tasks (e.g., automatic speech or speaker
recognition). In the present study, we investigate the use of a speech SSL
model for speech inpainting, that is reconstructing a missing portion of a
speech signal from its surrounding context, i.e., fulfilling a downstream task
that is very similar to the pretext task. To that purpose, we combine an SSL
encoder, namely HuBERT, with a neural vocoder, namely HiFiGAN, playing the role
of a decoder. In particular, we propose two solutions to match the HuBERT
output with the HiFiGAN input, by freezing one and fine-tuning the other, and
vice versa. Performance of both approaches was assessed in single- and
multi-speaker settings, for both informed and blind inpainting configurations
(i.e., the position of the mask is known or unknown, respectively), with
different objective metrics and a perceptual evaluation. Performances show that
if both solutions allow to correctly reconstruct signal portions up to the size
of 200ms (and even 400ms in some cases), fine-tuning the SSL encoder provides a
more accurate signal reconstruction in the single-speaker setting case, while
freezing it (and training the neural vocoder instead) is a better strategy when
dealing with multi-speaker data.

摘要：<paragraph>大多數的語音自我監督學習 (SSL) 模型都是以一個預設任務來訓練，這個任務包含預測輸入訊號中遺失的部分，可能是未來的片段（因果預測）或在輸入中任何地方遮蔽的片段（非因果預測）。學習到的語音表示法可以有效地轉移到下游任務（例如，自動語音或說話者辨識）。在本研究中，我們探討使用語音 SSL 模型來進行語音填補，也就是從語音訊號的周圍語境重建遺失的部分，也就是完成一個與預設任務非常相似的下游任務。為了這個目的，我們結合一個 SSL 編碼器，也就是 HuBERT，以及一個神經音訊編碼器，也就是 HiFiGAN，扮演解碼器的角色。特別是，我們提出兩種解決方案來比對 HuBERT 輸出與 HiFiGAN 輸入，分別是凍結一個並微調另一個，反之亦然。兩種方法的效能都經過評估，在單一和多說話者的設定中，對於已知和未知填補組態（也就是遮罩的位置分別已知或未知），使用不同的客觀指標和感知評估。效能顯示，如果兩種解決方案都能正確重建長達 200ms（在某些情況下甚至 400ms）的訊號部分，微調 SSL 編碼器可以在單一說話者設定的情況下提供更準確的訊號重建，而凍結它（並訓練神經音訊編碼器）則是處理多說話者資料時更好的策略。</paragraph>

##### **Divide-and-Conquer Meets Consensus: Unleashing the Power of Functions in Code Generation**
2405.20092v1 by Jingchang Chen, Hongxuan Tang, Zheng Chu, Qianglong Chen, Zekun Wang, Ming Liu, Bing Qin

Despite recent progress made by large language models in code generation,
they still struggle with programs that meet complex requirements. Recent work
utilizes plan-and-solve decomposition to decrease the complexity and leverage
self-tests to refine the generated program. Yet, planning deep-inside
requirements in advance can be challenging, and the tests need to be accurate
to accomplish self-improvement. To this end, we propose FunCoder, a code
generation framework incorporating the divide-and-conquer strategy with
functional consensus. Specifically, FunCoder recursively branches off
sub-functions as smaller goals during code generation, represented by a tree
hierarchy. These sub-functions are then composited to attain more complex
objectives. Additionally, we designate functions via a consensus formed by
identifying similarities in program behavior, mitigating error propagation.
FunCoder outperforms state-of-the-art methods by +9.8% on average in HumanEval,
MBPP, xCodeEval and MATH with GPT-3.5 and GPT-4. Moreover, our method
demonstrates superiority on smaller models: With FunCoder, StableCode-3b
surpasses GPT-3.5 by +18.6% and achieves 97.7% of GPT-4's performance on
HumanEval. Further analysis reveals that our proposed dynamic function
decomposition is capable of handling complex requirements, and the functional
consensus prevails over self-testing in correctness evaluation.

摘要：儘管大型語言模型在程式碼產生上取得了近期的進展，
它們在符合複雜需求的程式上仍有困難。最近的研究
利用規劃和解決分解來降低複雜度，並利用自我測試來改善產生的程式。然而，事先規劃深層需求可能具有挑戰性，而測試需要準確才能達成自我改善。為此，我們提出 FunCoder，一個將分而治之策略與函式共識結合的程式碼產生架構。具體來說，FunCoder 在程式碼產生期間遞迴分支出子函式作為較小的目標，以樹狀結構表示。然後將這些子函式組合起來以達成更複雜的目標。此外，我們透過找出程式行為的相似性來形成共識來指定函式，減輕錯誤傳播。FunCoder 在 HumanEval、MBPP、xCodeEval 和 MATH 中比採用 GPT-3.5 和 GPT-4 的最先進方法平均高出 +9.8%。此外，我們的模型在較小的模型上展現出優越性：透過 FunCoder，StableCode-3b 超越 GPT-3.5 達 +18.6%，並在 HumanEval 上達到 GPT-4 效能的 97.7%。進一步的分析顯示，我們提出的動態函式分解能夠處理複雜的需求，而函式共識在正確性評估中優於自我測試。

##### **The Fine-Tuning Paradox: Boosting Translation Quality Without Sacrificing LLM Abilities**
2405.20089v1 by David Stap, Eva Hasler, Bill Byrne, Christof Monz, Ke Tran

Fine-tuning large language models (LLMs) for machine translation has shown
improvements in overall translation quality. However, it is unclear what is the
impact of fine-tuning on desirable LLM behaviors that are not present in neural
machine translation models, such as steerability, inherent document-level
translation abilities, and the ability to produce less literal translations. We
perform an extensive translation evaluation on the LLaMA and Falcon family of
models with model size ranging from 7 billion up to 65 billion parameters. Our
results show that while fine-tuning improves the general translation quality of
LLMs, several abilities degrade. In particular, we observe a decline in the
ability to perform formality steering, to produce technical translations
through few-shot examples, and to perform document-level translation. On the
other hand, we observe that the model produces less literal translations after
fine-tuning on parallel data. We show that by including monolingual data as
part of the fine-tuning data we can maintain the abilities while simultaneously
enhancing overall translation quality. Our findings emphasize the need for
fine-tuning strategies that preserve the benefits of LLMs for machine
translation.

摘要：微调大型语言模型 (LLM) 用于机器翻译已显示在整体翻译质量方面有改进。然而，目前尚不清楚微调对神经机器翻译模型中不存在的 LLM 期望行为有何影响，例如可操纵性、固有的文档级翻译能力以及生成较少直译的能力。我们对 LLaMA 和 Falcon 系列模型进行了广泛的翻译评估，模型大小从 70 亿到 650 亿个参数不等。我们的结果表明，虽然微调提高了 LLM 的一般翻译质量，但一些能力却下降了。特别是，我们观察到在执行形式操纵、通过少量示例生成技术翻译以及执行文档级翻译的能力方面有所下降。另一方面，我们观察到该模型在并行数据上进行微调后产生的直译较少。我们表明，通过将单语数据作为微调数据的一部分，我们可以在同时提高整体翻译质量的同时保持这些能力。我们的发现强调了需要微调策略来保留 LLM 对机器翻译的好处。

##### **Segment, Shuffle, and Stitch: A Simple Mechanism for Improving Time-Series Representations**
2405.20082v1 by Shivam Grover, Amin Jalali, Ali Etemad

Existing approaches for learning representations of time-series keep the
temporal arrangement of the time-steps intact with the presumption that the
original order is the most optimal for learning. However, non-adjacent sections
of real-world time-series may have strong dependencies. Accordingly we raise
the question: Is there an alternative arrangement for time-series which could
enable more effective representation learning? To address this, we propose a
simple plug-and-play mechanism called Segment, Shuffle, and Stitch (S3)
designed to improve time-series representation learning of existing models. S3
works by creating non-overlapping segments from the original sequence and
shuffling them in a learned manner that is the most optimal for the task at
hand. It then re-attaches the shuffled segments back together and performs a
learned weighted sum with the original input to capture both the newly shuffled
sequence along with the original sequence. S3 is modular and can be stacked to
create various degrees of granularity, and can be added to many forms of neural
architectures including CNNs or Transformers with negligible computation
overhead. Through extensive experiments on several datasets and
state-of-the-art baselines, we show that incorporating S3 results in
significant improvements for the tasks of time-series classification and
forecasting, improving performance on certain datasets by up to 68\%. We also
show that S3 makes the learning more stable with a smoother training loss curve
and loss landscape compared to the original baseline. The code is available at
https://github.com/shivam-grover/S3-TimeSeries .

摘要：現有的時間序列表示學習方法保持時間步驟的時間順序完整，假設原始順序最適合學習。然而，現實世界時間序列的非相鄰部分可能具有很強的依賴性。因此，我們提出了問題：時間序列是否存在替代排列，可以實現更有效的表示學習？為了解決這個問題，我們提出了一種稱為分段、洗牌和拼接 (S3) 的簡單即插即用機制，旨在改善現有模型的時間序列表示學習。S3 通過從原始序列創建非重疊段並以對手頭任務最優化的學習方式對它們進行洗牌來工作。然後，它將洗牌的段重新附接在一起，並與原始輸入執行學習加權和，以捕獲新洗牌的序列和原始序列。S3 是模組化的，可以堆疊以創建不同程度的粒度，並且可以添加到許多形式的神經架構中，包括 CNN 或 Transformer，而計算開銷可以忽略不計。通過對幾個數據集和最先進的基線進行廣泛的實驗，我們表明整合 S3 可以顯著改善時間序列分類和預測任務，在某些數據集上的效能提升高達 68%。我們還表明，與原始基線相比，S3 使學習更穩定，具有更平滑的訓練損失曲線和損失狀況。程式碼可在 https://github.com/shivam-grover/S3-TimeSeries 取得。

##### **NoiseBoost: Alleviating Hallucination with Noise Perturbation for Multimodal Large Language Models**
2405.20081v1 by Kai Wu, Boyuan Jiang, Zhengkai Jiang, Qingdong He, Donghao Luo, Shengzhi Wang, Qingwen Liu, Chengjie Wang

Multimodal large language models (MLLMs) contribute a powerful mechanism to
understanding visual information building on large language models. However,
MLLMs are notorious for suffering from hallucinations, especially when
generating lengthy, detailed descriptions for images. Our analysis reveals that
hallucinations stem from the inherent summarization mechanism of large language
models, leading to excessive dependence on linguistic tokens while neglecting
vision information. In this paper, we propose NoiseBoost, a broadly applicable
and simple method for alleviating hallucinations for MLLMs through the
integration of noise feature perturbations. Noise perturbation acts as a
regularizer, facilitating a balanced distribution of attention weights among
visual and linguistic tokens. Despite its simplicity, NoiseBoost consistently
enhances the performance of MLLMs across common training strategies, including
supervised fine-tuning and reinforcement learning. Further, NoiseBoost
pioneerly enables semi-supervised learning for MLLMs, unleashing the power of
unlabeled data. Comprehensive experiments demonstrate that NoiseBoost improves
dense caption accuracy by 8.1% with human evaluation and achieves comparable
results with 50% of the data by mining unlabeled data. Code and models are
available at https://kaiwu5.github.io/noiseboost.

摘要：多模态大型语言模型 (MLLM) 为基于大型语言模型理解视觉信息提供了一种强大的机制。然而，MLLM 以出现幻觉而著称，尤其是在为图像生成冗长且详细的描述时。我们的分析表明，幻觉源于大型语言模型固有的总结机制，导致过度依赖语言标记，而忽略了视觉信息。在本文中，我们提出了 NoiseBoost，这是一种广泛适用且简单的方法，可通过整合噪声特征扰动来减轻 MLLM 的幻觉。噪声扰动充当正则化器，促进了视觉和语言标记之间注意力权重的平衡分布。尽管其简单性，但 NoiseBoost 始终增强了 MLLM 在常见训练策略中的表现，包括监督微调和强化学习。此外，NoiseBoost 开创性地支持 MLLM 的半监督学习，释放了未标记数据的强大功能。综合实验表明，NoiseBoost 通过人工评估将密集字幕的准确性提高了 8.1%，并通过挖掘未标记数据以 50% 的数据量实现了可比的结果。代码和模型可在 https://kaiwu5.github.io/noiseboost 获得。

##### **Student Answer Forecasting: Transformer-Driven Answer Choice Prediction for Language Learning**
2405.20079v1 by Elena Grazia Gado, Tommaso Martorella, Luca Zunino, Paola Mejia-Domenzain, Vinitra Swamy, Jibril Frej, Tanja Käser

Intelligent Tutoring Systems (ITS) enhance personalized learning by
predicting student answers to provide immediate and customized instruction.
However, recent research has primarily focused on the correctness of the answer
rather than the student's performance on specific answer choices, limiting
insights into students' thought processes and potential misconceptions. To
address this gap, we present MCQStudentBert, an answer forecasting model that
leverages the capabilities of Large Language Models (LLMs) to integrate
contextual understanding of students' answering history along with the text of
the questions and answers. By predicting the specific answer choices students
are likely to make, practitioners can easily extend the model to new answer
choices or remove answer choices for the same multiple-choice question (MCQ)
without retraining the model. In particular, we compare MLP, LSTM, BERT, and
Mistral 7B architectures to generate embeddings from students' past
interactions, which are then incorporated into a finetuned BERT's
answer-forecasting mechanism. We apply our pipeline to a dataset of language
learning MCQ, gathered from an ITS with over 10,000 students to explore the
predictive accuracy of MCQStudentBert, which incorporates student interaction
patterns, in comparison to correct answer prediction and traditional
mastery-learning feature-based approaches. This work opens the door to more
personalized content, modularization, and granular support.

摘要：智慧型教學系統（ITS）透過預測學生的答案提供即時且客製化的教學，以增強個人化學習。然而，近期研究主要關注於答案的正確性，而非學生在特定答案選項上的表現，這限制了對學生思考歷程和潛在誤解的洞察。為了解決這個差距，我們提出了 MCQStudentBert，這是一個答案預測模型，它利用大型語言模型（LLM）的能力來整合學生答題記錄的脈絡理解以及問題和答案的文字。透過預測學生可能會做出的特定答案選項，從業人員可以輕鬆地將模型擴展到新的答案選項，或移除同一選擇題（MCQ）的答案選項，而無需重新訓練模型。特別是，我們比較了 MLP、LSTM、BERT 和 Mistral 7B 架構，以從學生的過去互動中產生嵌入，然後將這些嵌入整合到經過微調的 BERT 的答案預測機制中。我們將我們的管線應用於一個語言學習 MCQ 的資料集，該資料集是從一個擁有超過 10,000 名學生的 ITS 中收集的，以探討 MCQStudentBert 的預測準確性，它結合了學生的互動模式，並與正確答案預測和傳統的精熟學習基於特徵的方法進行比較。這項工作為更個人化的內容、模組化和細緻的支持開啟了大門。

##### **Spectral Mapping of Singing Voices: U-Net-Assisted Vocal Segmentation**
2405.20059v1 by Adam Sorrenti

Separating vocal elements from musical tracks is a longstanding challenge in
audio signal processing. This study tackles the distinct separation of vocal
components from musical spectrograms. We employ the Short Time Fourier
Transform (STFT) to extract audio waves into detailed frequency-time
spectrograms, utilizing the benchmark MUSDB18 dataset for music separation.
Subsequently, we implement a UNet neural network to segment the spectrogram
image, aiming to delineate and extract singing voice components accurately. We
achieved noteworthy results in audio source separation using of our U-Net-based
models. The combination of frequency-axis normalization with Min/Max scaling
and the Mean Absolute Error (MAE) loss function achieved the highest
Source-to-Distortion Ratio (SDR) of 7.1 dB, indicating a high level of accuracy
in preserving the quality of the original signal during separation. This setup
also recorded impressive Source-to-Interference Ratio (SIR) and
Source-to-Artifact Ratio (SAR) scores of 25.2 dB and 7.2 dB, respectively.
These values significantly outperformed other configurations, particularly
those using Quantile-based normalization or a Mean Squared Error (MSE) loss
function. Our source code, model weights, and demo material can be found at the
project's GitHub repository: https://github.com/mbrotos/SoundSeg

摘要：分離音樂曲目中的語音元素是音訊訊號處理中長期的挑戰。本研究探討從音樂頻譜圖中分離出不同語音元件。我們採用短時距傅立葉轉換 (STFT) 將音訊波萃取成詳細的頻率時間頻譜圖，並利用基準 MUSDB18 資料集進行音樂分離。接著，我們實作一個 U-Net 神經網路來區隔頻譜圖影像，目標是精確地描繪和萃取歌唱聲音元件。我們使用基於 U-Net 的模型在音訊來源分離方面取得顯著的成果。頻率軸正規化與 Min/Max 比例、平均絕對誤差 (MAE) 損失函數的結合，達到了最高的來源失真比 (SDR) 7.1 dB，表示在分離過程中能高度準確地保留原始訊號的品質。此設定也記錄到令人印象深刻的來源干擾比 (SIR) 和來源人工製品比 (SAR) 分數，分別為 25.2 dB 和 7.2 dB。這些數值明顯優於其他組態，特別是那些使用基於分位數的正規化或均方誤差 (MSE) 損失函數的組態。我們的原始碼、模型權重和示範資料可以在專案的 GitHub 儲存庫中找到：https://github.com/mbrotos/SoundSeg

##### **Would I Lie To You? Inference Time Alignment of Language Models using Direct Preference Heads**
2405.20053v1 by Avelina Asada Hadji-Kyriacou, Ognjen Arandjelovic

Pre-trained Language Models (LMs) exhibit strong zero-shot and in-context
learning capabilities; however, their behaviors are often difficult to control.
By utilizing Reinforcement Learning from Human Feedback (RLHF), it is possible
to fine-tune unsupervised LMs to follow instructions and produce outputs that
reflect human preferences. Despite its benefits, RLHF has been shown to
potentially harm a language model's reasoning capabilities and introduce
artifacts such as hallucinations where the model may fabricate facts. To
address this issue we introduce Direct Preference Heads (DPH), a fine-tuning
framework that enables LMs to learn human preference signals through an
auxiliary reward head without directly affecting the output distribution of the
language modeling head. We perform a theoretical analysis of our objective
function and find strong ties to Conservative Direct Preference Optimization
(cDPO). Finally we evaluate our models on GLUE, RACE, and the GPT4All
evaluation suite and demonstrate that our method produces models which achieve
higher scores than those fine-tuned with Supervised Fine-Tuning (SFT) or Direct
Preference Optimization (DPO) alone.

摘要：預先訓練的語言模型 (LM) 展現強大的零次學習和情境學習能力；然而，它們的行為通常難以控制。藉由利用人類回饋的強化學習 (RLHF)，可以微調無監督的 LM 以遵循指示並產生反映人類偏好的輸出。儘管有這些好處，但 RLHF 已被證明可能會損害語言模型的推理能力，並引入幻覺等人工製品，其中模型可能會捏造事實。為了解決這個問題，我們引入了直接偏好頭 (DPH)，這是一個微調框架，使 LM 能夠透過輔助獎勵頭學習人類偏好訊號，而不會直接影響語言建模頭的輸出分佈。我們對我們的目標函數進行理論分析，並發現與保守直接偏好最佳化 (cDPO) 有密切關聯。最後，我們在 GLUE、RACE 和 GPT4All 評估套件上評估我們的模型，並證明我們的模型產生了比僅使用監督微調 (SFT) 或直接偏好最佳化 (DPO) 微調的模型獲得更高分數。

##### **Cross-Training with Multi-View Knowledge Fusion for Heterogenous Federated Learning**
2405.20046v1 by Zhuang Qi, Lei Meng, Weihao He, Ruohan Zhang, Yu Wang, Xin Qi, Xiangxu Meng

Federated learning benefits from cross-training strategies, which enables
models to train on data from distinct sources to improve the generalization
capability. However, the data heterogeneity between sources may lead models to
gradually forget previously acquired knowledge when undergoing cross-training
to adapt to new tasks or data sources. We argue that integrating personalized
and global knowledge to gather information from multiple perspectives could
potentially improve performance. To achieve this goal, this paper presents a
novel approach that enhances federated learning through a cross-training scheme
incorporating multi-view information. Specifically, the proposed method, termed
FedCT, includes three main modules, where the consistency-aware knowledge
broadcasting module aims to optimize model assignment strategies, which
enhances collaborative advantages between clients and achieves an efficient
federated learning process. The multi-view knowledge-guided representation
learning module leverages fused prototypical knowledge from both global and
local views to enhance the preservation of local knowledge before and after
model exchange, as well as to ensure consistency between local and global
knowledge. The mixup-based feature augmentation module aggregates rich
information to further increase the diversity of feature spaces, which enables
the model to better discriminate complex samples. Extensive experiments were
conducted on four datasets in terms of performance comparison, ablation study,
in-depth analysis and case study. The results demonstrated that FedCT
alleviates knowledge forgetting from both local and global views, which enables
it outperform state-of-the-art methods.

摘要：聯合學習受益於跨訓練策略，這使模型能夠訓練來自不同來源的資料，以改善泛化能力。然而，來源之間的資料異質性可能會導致模型在進行跨訓練以適應新任務或資料來源時逐漸遺忘先前獲得的知識。我們認為，整合個人化和全球知識以從多個角度收集資訊，有可能改善效能。為了達成這個目標，本文提出了一種創新的方法，透過跨訓練方案來增強聯合學習，並納入多視角資訊。具體來說，所提出的方法稱為 FedCT，包括三個主要模組，其中一致性感知知識廣播模組旨在最佳化模型分配策略，這增強了客戶端之間的協作優勢，並實現了高效的聯合學習流程。多視角知識引導表示學習模組利用來自全球和局部視角的融合原型知識，以增強模型交換前後局部知識的保存，並確保局部和全球知識之間的一致性。基於混淆的特徵擴充模組彙總了豐富的資訊，以進一步增加特徵空間的多樣性，這使模型能夠更好地區分複雜的樣本。針對四個資料集進行了廣泛的實驗，包括效能比較、消融研究、深入分析和案例研究。結果證明，FedCT 減輕了來自局部和全球視角的知識遺忘，這使它能夠優於最先進的方法。

##### **Applications of Generative AI (GAI) for Mobile and Wireless Networking: A Survey**
2405.20024v1 by Thai-Hoc Vu, Senthil Kumar Jagatheesaperumal, Minh-Duong Nguyen, Nguyen Van Huynh, Sunghwan Kim, Quoc-Viet Pham

The success of Artificial Intelligence (AI) in multiple disciplines and
vertical domains in recent years has promoted the evolution of mobile
networking and the future Internet toward an AI-integrated Internet-of-Things
(IoT) era. Nevertheless, most AI techniques rely on data generated by physical
devices (e.g., mobile devices and network nodes) or specific applications
(e.g., fitness trackers and mobile gaming). To bypass this circumvent,
Generative AI (GAI), a.k.a. AI-generated content (AIGC), has emerged as a
powerful AI paradigm; thanks to its ability to efficiently learn complex data
distributions and generate synthetic data to represent the original data in
various forms. This impressive feature is projected to transform the management
of mobile networking and diversify the current services and applications
provided. On this basis, this work presents a concise tutorial on the role of
GAIs in mobile and wireless networking. In particular, this survey first
provides the fundamentals of GAI and representative GAI models, serving as an
essential preliminary to the understanding of the applications of GAI in mobile
and wireless networking. Then, this work provides a comprehensive review of
state-of-the-art studies and GAI applications in network management, wireless
security, semantic communication, and lessons learned from the open literature.
Finally, this work summarizes the current research on GAI for mobile and
wireless networking by outlining important challenges that need to be resolved
to facilitate the development and applicability of GAI in this edge-cutting
area.

摘要：<paragraph>近年來，人工智慧（AI）在多個學科和垂直領域的成功，促使行動網路與未來網際網路朝向 AI 整合的物聯網（IoT）時代演進。然而，大多數的 AI 技術依賴於實體裝置（例如行動裝置和網路節點）或特定應用程式（例如健身追蹤器和行動遊戲）所產生的資料。為了繞過此限制，生成式 AI（GAI），又稱 AI 產生的內容（AIGC），已成為一種強大的 AI 典範；由於它能有效率地學習複雜的資料分佈，並產生合成資料以各種形式呈現原始資料。此令人印象深刻的功能預計將轉變行動網路管理，並使目前提供的服務和應用程式多樣化。在此基礎上，本研究簡要說明 GAI 在行動和無線網路中的角色。特別是，本調查首先提供 GAI 的基礎知識和具代表性的 GAI 模型，作為理解 GAI 在行動和無線網路中應用之必要的前提。接著，本研究全面回顧網路管理、無線安全、語意溝通中 GAI 應用和最先進的研究，以及從公開文獻中學到的教訓。最後，本研究總結了目前行動和無線網路中 GAI 的研究，概述了需要解決的重要挑戰，以利於促進 GAI 在這個尖端領域的發展和應用。</paragraph>

##### **Safe Multi-agent Reinforcement Learning with Natural Language Constraints**
2405.20018v1 by Ziyan Wang, Meng Fang, Tristan Tomilin, Fei Fang, Yali Du

The role of natural language constraints in Safe Multi-agent Reinforcement
Learning (MARL) is crucial, yet often overlooked. While Safe MARL has vast
potential, especially in fields like robotics and autonomous vehicles, its full
potential is limited by the need to define constraints in pre-designed
mathematical terms, which requires extensive domain expertise and reinforcement
learning knowledge, hindering its broader adoption. To address this limitation
and make Safe MARL more accessible and adaptable, we propose a novel approach
named Safe Multi-agent Reinforcement Learning with Natural Language constraints
(SMALL). Our method leverages fine-tuned language models to interpret and
process free-form textual constraints, converting them into semantic embeddings
that capture the essence of prohibited states and behaviours. These embeddings
are then integrated into the multi-agent policy learning process, enabling
agents to learn policies that minimize constraint violations while optimizing
rewards. To evaluate the effectiveness of SMALL, we introduce the LaMaSafe, a
multi-task benchmark designed to assess the performance of multiple agents in
adhering to natural language constraints. Empirical evaluations across various
environments demonstrate that SMALL achieves comparable rewards and
significantly fewer constraint violations, highlighting its effectiveness in
understanding and enforcing natural language constraints.

摘要：在安全多智能體強化學習 (MARL) 中，自然語言約束扮演著至關重要的角色，但卻經常被忽視。儘管安全 MARL 具有廣泛的潛力，特別是在機器人和自動駕駛汽車等領域，但其潛力受到定義預先設計數學術語約束的限制，這需要廣泛的領域專業知識和強化學習知識，阻礙了其更廣泛的應用。為了解決這個限制並讓安全 MARL 更容易使用和適應，我們提出了一種名為自然語言約束安全多智能體強化學習 (SMALL) 的新方法。我們的模型利用微調的語言模型來解釋和處理自由形式的文本約束，將其轉換為語義嵌入，以捕捉禁止狀態和行為的本質。然後將這些嵌入整合到多智能體策略學習過程中，讓智能體能夠學習最小化約束違規的策略，同時優化獎勵。為了評估 SMALL 的有效性，我們引入了 LaMaSafe，這是一個多任務基準，旨在評估多個智能體遵守自然語言約束的表現。在各種環境中的經驗評估表明，SMALL 達到了可比較的獎勵，並且約束違規明顯減少，突顯了其在理解和執行自然語言約束方面的有效性。

##### **Efficient LLM-Jailbreaking by Introducing Visual Modality**
2405.20015v1 by Zhenxing Niu, Yuyao Sun, Haodong Ren, Haoxuan Ji, Quan Wang, Xiaoke Ma, Gang Hua, Rong Jin

This paper focuses on jailbreaking attacks against large language models
(LLMs), eliciting them to generate objectionable content in response to harmful
user queries. Unlike previous LLM-jailbreaks that directly orient to LLMs, our
approach begins by constructing a multimodal large language model (MLLM)
through the incorporation of a visual module into the target LLM. Subsequently,
we conduct an efficient MLLM-jailbreak to generate jailbreaking embeddings
embJS. Finally, we convert the embJS into text space to facilitate the
jailbreaking of the target LLM. Compared to direct LLM-jailbreaking, our
approach is more efficient, as MLLMs are more vulnerable to jailbreaking than
pure LLM. Additionally, to improve the attack success rate (ASR) of
jailbreaking, we propose an image-text semantic matching scheme to identify a
suitable initial input. Extensive experiments demonstrate that our approach
surpasses current state-of-the-art methods in terms of both efficiency and
effectiveness. Moreover, our approach exhibits superior cross-class
jailbreaking capabilities.

摘要：本文重点关注针对大型语言模型 (LLM) 的越狱攻击，诱使其针对有害用户查询生成令人反感的内容。与直接针对 LLM 的以往 LLM 越狱不同，我们的方法首先通过将视觉模块纳入目标 LLM 来构建多模态大型语言模型 (MLLM)。随后，我们进行高效的 MLLM 越狱以生成越狱嵌入 embJS。最后，我们将 embJS 转换为文本空间以促进目标 LLM 的越狱。与直接 LLM 越狱相比，我们的方法更高效，因为 MLLM 比纯 LLM 更容易受到越狱攻击。此外，为了提高越狱的攻击成功率 (ASR)，我们提出了一种图像文本语义匹配方案来识别合适的初始输入。大量实验表明，我们的方法在效率和有效性方面都超越了当前最先进的方法。此外，我们的方法还展示了出色的跨类越狱能力。

##### **Kernel Language Entropy: Fine-grained Uncertainty Quantification for LLMs from Semantic Similarities**
2405.20003v1 by Alexander Nikitin, Jannik Kossen, Yarin Gal, Pekka Marttinen

Uncertainty quantification in Large Language Models (LLMs) is crucial for
applications where safety and reliability are important. In particular,
uncertainty can be used to improve the trustworthiness of LLMs by detecting
factually incorrect model responses, commonly called hallucinations.
Critically, one should seek to capture the model's semantic uncertainty, i.e.,
the uncertainty over the meanings of LLM outputs, rather than uncertainty over
lexical or syntactic variations that do not affect answer correctness. To
address this problem, we propose Kernel Language Entropy (KLE), a novel method
for uncertainty estimation in white- and black-box LLMs. KLE defines positive
semidefinite unit trace kernels to encode the semantic similarities of LLM
outputs and quantifies uncertainty using the von Neumann entropy. It considers
pairwise semantic dependencies between answers (or semantic clusters),
providing more fine-grained uncertainty estimates than previous methods based
on hard clustering of answers. We theoretically prove that KLE generalizes the
previous state-of-the-art method called semantic entropy and empirically
demonstrate that it improves uncertainty quantification performance across
multiple natural language generation datasets and LLM architectures.

摘要：在大型语言模型 (LLM) 中量化不确定性对于安全性和可靠性至关重要的应用程序至关重要。具体而言，不确定性可用于通过检测事实错误的模型响应（通常称为幻觉）来提高 LLM 的可信度。至关重要的是，人们应该寻求捕捉模型的语义不确定性，即对 LLM 输出的含义的不确定性，而不是对不影响答案正确性的词法或句法变异的不确定性。为了解决这个问题，我们提出了核语言熵 (KLE)，这是一种用于白盒和黑盒 LLM 中不确定性估计的新方法。KLE 定义正半定单位迹核来编码 LLM 输出的语义相似性，并使用冯诺依曼熵量化不确定性。它考虑答案（或语义簇）之间的成对语义依赖关系，比基于答案硬聚类的先前方法提供了更细粒度的不确定性估计。我们从理论上证明，KLE 概括了以前称为语义熵的最新方法，并通过实验证明，它提高了跨多个自然语言生成数据集和 LLM 架构的不确定性量化性能。

##### **DP-IQA: Utilizing Diffusion Prior for Blind Image Quality Assessment in the Wild**
2405.19996v1 by Honghao Fu, Yufei Wang, Wenhan Yang, Bihan Wen

Image quality assessment (IQA) plays a critical role in selecting
high-quality images and guiding compression and enhancement methods in a series
of applications. The blind IQA, which assesses the quality of in-the-wild
images containing complex authentic distortions without reference images, poses
greater challenges. Existing methods are limited to modeling a uniform
distribution with local patches and are bothered by the gap between low and
high-level visions (caused by widely adopted pre-trained classification
networks). In this paper, we propose a novel IQA method called diffusion
priors-based IQA (DP-IQA), which leverages the prior knowledge from the
pre-trained diffusion model with its excellent powers to bridge semantic gaps
in the perception of the visual quality of images. Specifically, we use
pre-trained stable diffusion as the backbone, extract multi-level features from
the denoising U-Net during the upsampling process at a specified timestep, and
decode them to estimate the image quality score. The text and image adapters
are adopted to mitigate the domain gap for downstream tasks and correct the
information loss caused by the variational autoencoder bottleneck. Finally, we
distill the knowledge in the above model into a CNN-based student model,
significantly reducing the parameter to enhance applicability, with the student
model performing similarly or even better than the teacher model surprisingly.
Experimental results demonstrate that our DP-IQA achieves state-of-the-art
results on various in-the-wild datasets with better generalization capability,
which shows the superiority of our method in global modeling and utilizing the
hierarchical feature clues of diffusion for evaluating image quality.

摘要：<paragraph>影像品質評估 (IQA) 在一系列應用中扮演著挑選高品質影像和引導壓縮與增強方法的重要角色。盲式 IQA 評估包含複雜真實失真的野外影像品質，而沒有參考影像，這帶來了更大的挑戰。現有方法僅限於使用區域性區塊建模均勻分佈，並且受到低階與高階視覺之間的差距所困擾（由廣泛採用的預先訓練分類網路所造成）。在本文中，我們提出了一種稱為擴散先驗 IQA (DP-IQA) 的創新 IQA 方法，它利用預先訓練擴散模型的先驗知識，並具備優秀的能力，可以彌合影像視覺品質感知中的語意差距。具體來說，我們使用預先訓練的穩定擴散作為主幹，從升採樣過程中特定時間步長的去噪 U-Net 中萃取多層級特徵，並將其解碼以估計影像品質評分。文本和影像適配器用於降低下游任務的領域差距，並修正變異自動編碼器瓶頸所造成的資訊遺失。最後，我們將上述模型中的知識萃取到基於 CNN 的學生模型中，大幅減少參數以增強適用性，而學生模型的表現令人驚訝地與教師模型類似，甚至更好。實驗結果證明，我們的 DP-IQA 在各種野外資料集上達到了最先進的結果，並具備更好的泛化能力，這顯示了我們的方法在整體建模和利用擴散的階層式特徵線索來評估影像品質方面的優越性。</paragraph>

##### **Video-Language Critic: Transferable Reward Functions for Language-Conditioned Robotics**
2405.19988v1 by Minttu Alakuijala, Reginald McLean, Isaac Woungang, Nariman Farsad, Samuel Kaski, Pekka Marttinen, Kai Yuan

Natural language is often the easiest and most convenient modality for humans
to specify tasks for robots. However, learning to ground language to behavior
typically requires impractical amounts of diverse, language-annotated
demonstrations collected on each target robot. In this work, we aim to separate
the problem of what to accomplish from how to accomplish it, as the former can
benefit from substantial amounts of external observation-only data, and only
the latter depends on a specific robot embodiment. To this end, we propose
Video-Language Critic, a reward model that can be trained on readily available
cross-embodiment data using contrastive learning and a temporal ranking
objective, and use it to score behavior traces from a separate reinforcement
learning actor. When trained on Open X-Embodiment data, our reward model
enables 2x more sample-efficient policy training on Meta-World tasks than a
sparse reward only, despite a significant domain gap. Using in-domain data but
in a challenging task generalization setting on Meta-World, we further
demonstrate more sample-efficient training than is possible with prior
language-conditioned reward models that are either trained with binary
classification, use static images, or do not leverage the temporal information
present in video data.

摘要：自然語言通常是人類為機器人指定任務最容易、最方便的方式。然而，學習將語言轉化為行為通常需要大量的、多樣化的、在每個目標機器人上收集的語言註釋示範。在這項工作中，我們的目標是將如何完成任務的問題與如何完成任務的問題分開，因為前者可以從大量的外部觀察數據中受益，而後者僅依賴於具體機器人的具體實施。為此，我們提出了視頻語言批評家，這是一種獎勵模型，可以使用對比學習和時間排序目標對現成的跨具體實施數據進行訓練，並使用它來評分來自單獨強化學習參與者的行為軌跡。在 Open X-Embodiment 數據上進行訓練時，我們的獎勵模型使 Meta-World 任務上的策略訓練比僅使用稀疏獎勵的策略訓練效率提高了 2 倍，儘管存在顯著的領域差距。在 Meta-World 上使用領域內數據但在具有挑戰性的任務泛化設置中，我們進一步證明了比使用二元分類訓練的、使用靜態圖像的或不利用視頻數據中存在的時間信息的先前語言條件獎勵模型更有效的訓練。

##### **A Deep Reinforcement Learning Approach for Trading Optimization in the Forex Market with Multi-Agent Asynchronous Distribution**
2405.19982v1 by Davoud Sarani, Dr. Parviz Rashidi-Khazaee

In today's forex market traders increasingly turn to algorithmic trading,
leveraging computers to seek more profits. Deep learning techniques as
cutting-edge advancements in machine learning, capable of identifying patterns
in financial data. Traders utilize these patterns to execute more effective
trades, adhering to algorithmic trading rules. Deep reinforcement learning
methods (DRL), by directly executing trades based on identified patterns and
assessing their profitability, offer advantages over traditional DL approaches.
This research pioneers the application of a multi-agent (MA) RL framework with
the state-of-the-art Asynchronous Advantage Actor-Critic (A3C) algorithm. The
proposed method employs parallel learning across multiple asynchronous workers,
each specialized in trading across multiple currency pairs to explore the
potential for nuanced strategies tailored to different market conditions and
currency pairs. Two different A3C with lock and without lock MA model was
proposed and trained on single currency and multi-currency. The results
indicate that both model outperform on Proximal Policy Optimization model. A3C
with lock outperforms other in single currency training scenario and A3C
without Lock outperforms other in multi-currency scenario. The findings
demonstrate that this approach facilitates broader and faster exploration of
different currency pairs, significantly enhancing trading returns.
Additionally, the agent can learn a more profitable trading strategy in a
shorter time.

摘要：在當今的外匯市場中，交易者越來越多地轉向演算法交易，
利用電腦尋求更多利潤。深度學習技術作為機器學習中的尖端進展，
能夠識別金融數據中的模式。交易者利用這些模式來執行更有效的
交易，遵守演算法交易規則。深度強化學習方法 (DRL) 通過根據識別出的模式直接執行交易並
評估其獲利能力，提供優於傳統 DL 方法的優勢。
本研究開創了使用多主體 (MA) RL 框架與最先進的非同步優勢 Actor-Critic (A3C) 演算法的應用。所
提出的方法採用跨多個非同步工作者的並行學習，每個工作者專門從事跨多個貨幣對的交易，以探索針對不同市場條件和
貨幣對量身定制的細緻策略的可能性。提出了兩種不同的帶鎖定和不帶鎖定的 A3C MA 模型，並在單一貨幣和多貨幣上進行了訓練。結果
表明，這兩種模型在近端策略優化模型上都表現出色。帶鎖定的 A3C 在單一貨幣訓練場景中表現優於其他，而沒有鎖定的 A3C 在多貨幣場景中表現優於其他。研究結果
表明，這種方法促進了對不同貨幣對的更廣泛、更快速的探索，顯著提高了交易回報。
此外，代理可以在更短的時間內學習到更有利可圖的交易策略。

##### **A Triumvirate of AI Driven Theoretical Discovery**
2405.19973v1 by Yang-Hui He

Recent years have seen the dramatic rise of the usage of AI algorithms in
pure mathematics and fundamental sciences such as theoretical physics. This is
perhaps counter-intuitive since mathematical sciences require the rigorous
definitions, derivations, and proofs, in contrast to the experimental sciences
which rely on the modelling of data with error-bars. In this Perspective, we
categorize the approaches to mathematical discovery as "top-down", "bottom-up"
and "meta-mathematics", as inspired by historical examples. We review some of
the progress over the last few years, comparing and contrasting both the
advances and the short-comings in each approach. We argue that while the
theorist is in no way in danger of being replaced by AI in the near future, the
hybrid of human expertise and AI algorithms will become an integral part of
theoretical discovery.

摘要：近年來，人工智慧演算法在純數學和理論物理等基礎科學中的應用大幅增加。這或許有違直覺，因為數學科學需要嚴謹的定義、推導和證明，這與依賴於誤差範圍數據建模的實驗科學形成對比。在這個觀點中，我們將數學發現的方法歸類為「自上而下」、「自下而上」和「元數學」，靈感來自歷史範例。我們回顧過去幾年的部分進展，比較並對比每種方法的進步和缺點。我們認為，儘管理論家在不久的將來絕不會被人工智慧取代，但人類專家和人工智慧演算法的結合將成為理論發現中不可或缺的一部分。

##### **Improved Out-of-Scope Intent Classification with Dual Encoding and Threshold-based Re-Classification**
2405.19967v1 by Hossam M. Zawbaa, Wael Rashwan, Sourav Dutta, Haytham Assem

Detecting out-of-scope user utterances is essential for task-oriented
dialogues and intent classification. Current methodologies face difficulties
with the unpredictable distribution of outliers and often rely on assumptions
about data distributions. We present the Dual Encoder for Threshold-Based
Re-Classification (DETER) to address these challenges. This end-to-end
framework efficiently detects out-of-scope intents without requiring
assumptions on data distributions or additional post-processing steps. The core
of DETER utilizes dual text encoders, the Universal Sentence Encoder (USE) and
the Transformer-based Denoising AutoEncoder (TSDAE), to generate user utterance
embeddings, which are classified through a branched neural architecture.
Further, DETER generates synthetic outliers using self-supervision and
incorporates out-of-scope phrases from open-domain datasets. This approach
ensures a comprehensive training set for out-of-scope detection. Additionally,
a threshold-based re-classification mechanism refines the model's initial
predictions. Evaluations on the CLINC-150, Stackoverflow, and Banking77
datasets demonstrate DETER's efficacy. Our model outperforms previous
benchmarks, increasing up to 13% and 5% in F1 score for known and unknown
intents on CLINC-150 and Stackoverflow, and 16% for known and 24% % for unknown
intents on Banking77. The source code has been released at
https://github.com/Hossam-Mohammed-tech/Intent\_Classification\_OOS.

摘要：<paragraph>偵測超出範圍的使用者話語對於任務導向對話和意圖分類至關重要。目前的技術方法面臨難以預測的異常值分佈，且經常依賴於資料分佈的假設。我們提出基於門檻值的重新分類 (DETER) 的雙編碼器來解決這些挑戰。此端對端架構有效地偵測超出範圍的意圖，而不需要對資料分佈或額外的後處理步驟做出假設。DETER 的核心利用雙重文字編碼器，通用句子編碼器 (USE) 和基於 Transformer 的去雜訊自動編碼器 (TSDAE)，來產生使用者話語嵌入，這些嵌入透過分支神經架構進行分類。此外，DETER 使用自我監督產生合成異常值，並納入來自開放領域資料集的超出範圍詞組。此方法確保了超出範圍偵測的全面訓練集。此外，基於門檻值的重新分類機制可改善模型的初始預測。在 CLINC-150、Stackoverflow 和 Banking77 資料集上的評估顯示了 DETER 的效能。我們的模型優於先前的基準，在 CLINC-150 和 Stackoverflow 上已知和未知意圖的 F1 分數提高了 13% 和 5%，在 Banking77 上已知和未知意圖的 F1 分數提高了 16% 和 24%。原始碼已在 https://github.com/Hossam-Mohammed-tech/Intent\_Classification\_OOS 發布。</paragraph>

##### **PLA4D: Pixel-Level Alignments for Text-to-4D Gaussian Splatting**
2405.19957v1 by Qiaowei Miao, Yawei Luo, Yi Yang

As text-conditioned diffusion models (DMs) achieve breakthroughs in image,
video, and 3D generation, the research community's focus has shifted to the
more challenging task of text-to-4D synthesis, which introduces a temporal
dimension to generate dynamic 3D objects. In this context, we identify Score
Distillation Sampling (SDS), a widely used technique for text-to-3D synthesis,
as a significant hindrance to text-to-4D performance due to its Janus-faced and
texture-unrealistic problems coupled with high computational costs. In this
paper, we propose \textbf{P}ixel-\textbf{L}evel \textbf{A}lignments for
Text-to-\textbf{4D} Gaussian Splatting (\textbf{PLA4D}), a novel method that
utilizes text-to-video frames as explicit pixel alignment targets to generate
static 3D objects and inject motion into them. Specifically, we introduce Focal
Alignment to calibrate camera poses for rendering and GS-Mesh Contrastive
Learning to distill geometry priors from rendered image contrasts at the pixel
level. Additionally, we develop Motion Alignment using a deformation network to
drive changes in Gaussians and implement Reference Refinement for smooth 4D
object surfaces. These techniques enable 4D Gaussian Splatting to align
geometry, texture, and motion with generated videos at the pixel level.
Compared to previous methods, PLA4D produces synthesized outputs with better
texture details in less time and effectively mitigates the Janus-faced problem.
PLA4D is fully implemented using open-source models, offering an accessible,
user-friendly, and promising direction for 4D digital content creation. Our
project page:
\href{https://github.com/MiaoQiaowei/PLA4D.github.io}{https://github.com/MiaoQiaowei/PLA4D.github.io}.

摘要：隨著文字條件擴散模型 (DM) 在影像、影片和 3D 生成方面取得突破，研究社群的焦點已轉移到更具挑戰性的文字轉 4D 合成任務，這項任務引入了時間維度，以產生動態 3D 物件。在此脈絡下，我們將廣泛用於文字轉 3D 合成的技術，即分數蒸餾取樣 (SDS)，視為文字轉 4D 效能的一大阻礙，原因在於它具有雙面性和紋理不真實的問題，而且運算成本高。在本文中，我們提出文字轉 4D 高斯點繪的像素層級對齊 (\textbf{PLA4D})，這是一種新穎的方法，它利用文字轉影片的畫格作為明確的像素對齊目標，以產生靜態 3D 物件並為它們注入動作。具體來說，我們引入了焦點對齊，以校準用於渲染的相機姿勢，並利用 GS-Mesh 對比學習，從像素層級的渲染影像對比中萃取出幾何先驗。此外，我們開發了使用變形網路的動作對齊，以推動高斯變化的變化，並實作參考精煉，以產生平滑的 4D 物件表面。這些技術使 4D 高斯點繪能夠在像素層級將幾何、紋理和動作與產生的影片對齊。與先前的技術相比，PLA4D 在更短的時間內產生具有更好紋理細節的合成輸出，並有效地減輕了雙面性問題。PLA4D 完全使用開源模型實作，為 4D 數位內容創作提供了一個平易近人、友善且有前景的方向。我們的專案頁面：
\href{https://github.com/MiaoQiaowei/PLA4D.github.io}{https://github.com/MiaoQiaowei/PLA4D.github.io}。

##### **HOLMES: to Detect Adversarial Examples with Multiple Detectors**
2405.19956v1 by Jing Wen

Deep neural networks (DNNs) can easily be cheated by some imperceptible but
purposeful noise added to images, and erroneously classify them. Previous
defensive work mostly focused on retraining the models or detecting the noise,
but has either shown limited success rates or been attacked by new adversarial
examples. Instead of focusing on adversarial images or the interior of DNN
models, we observed that adversarial examples generated by different algorithms
can be identified based on the output of DNNs (logits). Logit can serve as an
exterior feature to train detectors. Then, we propose HOLMES (Hierarchically
Organized Light-weight Multiple dEtector System) to reinforce DNNs by detecting
potential adversarial examples to minimize the threats they may bring in
practical. HOLMES is able to distinguish \textit{unseen} adversarial examples
from multiple attacks with high accuracy and low false positive rates than
single detector systems even in an adaptive model. To ensure the diversity and
randomness of detectors in HOLMES, we use two methods: training dedicated
detectors for each label and training detectors with top-k logits. Our
effective and inexpensive strategies neither modify original DNN models nor
require its internal parameters. HOLMES is not only compatible with all kinds
of learning models (even only with external APIs), but also complementary to
other defenses to achieve higher detection rates (may also fully protect the
system against various adversarial examples).

摘要：深度神经网络 (DNN) 很容易被添加到图像中的一些难以察觉但有目的的噪声所欺骗，并错误地对它们进行分类。先前的防御工作主要集中在重新训练模型或检测噪声，但要么显示出有限的成功率，要么受到新的对抗性示例的攻击。我们没有关注对抗性图像或 DNN 模型的内部，而是观察到，可以根据 DNN（逻辑）的输出识别由不同算法生成的对抗性示例。逻辑可以用作训练检测器的外部特征。然后，我们提出 HOLMES（分层组织轻量级多检测器系统），通过检测潜在的对抗性示例来增强 DNN，以最大程度地减少它们在实际中可能带来的威胁。HOLMES 能够区分来自多个攻击的“看不见的”对抗性示例，并且即使在自适应模型中，其准确性也高于单个检测器系统，且误报率较低。为了确保 HOLMES 中检测器的多样性和随机性，我们使用了两种方法：为每个标签训练专用检测器，以及使用前 k 个逻辑训练检测器。我们有效且廉价的策略既不修改原始 DNN 模型，也不需要其内部参数。HOLMES 不仅与所有类型的学习模型兼容（即使仅使用外部 API），而且还补充其他防御措施以实现更高的检测率（也可能完全保护系统免受各种对抗性示例的侵害）。

##### **GenKubeSec: LLM-Based Kubernetes Misconfiguration Detection, Localization, Reasoning, and Remediation**
2405.19954v1 by Ehud Malul, Yair Meidan, Dudu Mimran, Yuval Elovici, Asaf Shabtai

A key challenge associated with Kubernetes configuration files (KCFs) is that
they are often highly complex and error-prone, leading to security
vulnerabilities and operational setbacks. Rule-based (RB) tools for KCF
misconfiguration detection rely on static rule sets, making them inherently
limited and unable to detect newly-discovered misconfigurations. RB tools also
suffer from misdetection, since mistakes are likely when coding the detection
rules. Recent methods for detecting and remediating KCF misconfigurations are
limited in terms of their scalability and detection coverage, or due to the
fact that they have high expertise requirements and do not offer automated
remediation along with misconfiguration detection. Novel approaches that employ
LLMs in their pipeline rely on API-based, general-purpose, and mainly
commercial models. Thus, they pose security challenges, have inconsistent
classification performance, and can be costly. In this paper, we propose
GenKubeSec, a comprehensive and adaptive, LLM-based method, which, in addition
to detecting a wide variety of KCF misconfigurations, also identifies the exact
location of the misconfigurations and provides detailed reasoning about them,
along with suggested remediation. When empirically compared with three
industry-standard RB tools, GenKubeSec achieved equivalent precision (0.990)
and superior recall (0.999). When a random sample of KCFs was examined by a
Kubernetes security expert, GenKubeSec's explanations as to misconfiguration
localization, reasoning and remediation were 100% correct, informative and
useful. To facilitate further advancements in this domain, we share the unique
dataset we collected, a unified misconfiguration index we developed for label
standardization, our experimentation code, and GenKubeSec itself as an
open-source tool.

摘要：<paragraph>與 Kubernetes 設定檔 (KCF) 相關的一個主要挑戰在於它們通常非常複雜且容易出錯，導致安全漏洞和作業挫折。用於 KCF 錯誤設定偵測的基於規則 (RB) 工具依賴靜態規則集，使得它們本質上受到限制，無法偵測新發現的錯誤設定。RB 工具也會受到誤判的影響，因為在編寫偵測規則時很容易出錯。最近用於偵測和修復 KCF 錯誤設定的方法在可擴充性和偵測範圍方面受到限制，或者由於它們具有很高的專業知識需求，而且無法在偵測錯誤設定的同時提供自動修復。在它們的管線中採用 LLM 的新方法依賴於基於 API 的、通用且主要是商業模式。因此，它們會造成安全挑戰、分類效能不一致，而且可能很昂貴。在本文中，我們提出 GenKubeSec，這是一種全面且適應性的基於 LLM 的方法，除了偵測各種 KCF 錯誤設定外，它還識別錯誤設定的確切位置，並提供有關錯誤設定的詳細推理，以及建議的修復措施。與三種產業標準 RB 工具進行實證比較時，GenKubeSec 達到了相當的精確度 (0.990) 和更高的召回率 (0.999)。當一位 Kubernetes 安全專家檢查 KCF 的隨機範例時，GenKubeSec 對錯誤設定定位、推理和修復的說明 100% 正確、具參考價值且有用。為了促進這個領域的進一步發展，我們分享了我們收集到的獨特資料集、我們為標籤標準化開發的統一錯誤設定索引、我們的實驗程式碼，以及 GenKubeSec 本身作為一個開源工具。</paragraph>

##### **MM-Lego: Modular Biomedical Multimodal Models with Minimal Fine-Tuning**
2405.19950v1 by Konstantin Hemker, Nikola Simidjievski, Mateja Jamnik

Learning holistic computational representations in physical, chemical or
biological systems requires the ability to process information from different
distributions and modalities within the same model. Thus, the demand for
multimodal machine learning models has sharply risen for modalities that go
beyond vision and language, such as sequences, graphs, time series, or tabular
data. While there are many available multimodal fusion and alignment
approaches, most of them require end-to-end training, scale quadratically with
the number of modalities, cannot handle cases of high modality imbalance in the
training set, or are highly topology-specific, making them too restrictive for
many biomedical learning tasks. This paper presents Multimodal Lego (MM-Lego),
a modular and general-purpose fusion and model merging framework to turn any
set of encoders into a competitive multimodal model with no or minimal
fine-tuning. We achieve this by introducing a wrapper for unimodal encoders
that enforces lightweight dimensionality assumptions between modalities and
harmonises their representations by learning features in the frequency domain
to enable model merging with little signal interference. We show that MM-Lego
1) can be used as a model merging method which achieves competitive performance
with end-to-end fusion models without any fine-tuning, 2) can operate on any
unimodal encoder, and 3) is a model fusion method that, with minimal
fine-tuning, achieves state-of-the-art results on six benchmarked multimodal
biomedical tasks.

摘要：在物理、化學或生物系統中學習整體計算表示法需要處理來自同一模型中不同分佈和模式的資訊的能力。因此，對於超越視覺和語言的多模態機器學習模型的需求急劇上升，例如序列、圖形、時間序列或表格資料。儘管有許多可用的多模態融合和對齊方法，但它們大多需要端到端訓練、隨著模態數量的增加而呈二次方擴充、無法處理訓練集中高模態不平衡的情況，或具有高度拓撲特定性，這使得它們對於許多生物醫學學習任務來說過於嚴格。本文提出了多模態樂高（MM-Lego），這是一個模組化且通用的融合和模型合併框架，可以將任何一組編碼器轉換為具有競爭力的多模態模型，而無需或只需最少的微調。我們通過引入一個單模態編碼器的包裝器來實現這一點，該包裝器在模態之間執行輕量級維度假設，並通過在頻域中學習特徵來協調它們的表示，從而實現模型合併，同時幾乎不會產生訊號干擾。我們表明 MM-Lego 1) 可以用作模型合併方法，在不進行任何微調的情況下實現與端到端融合模型具有競爭力的效能，2) 可以操作任何單模態編碼器，以及 3) 是一種模型融合方法，在最小的微調下，在六個基準多模態生物醫學任務上實現了最先進的結果。

##### **Learning to Discuss Strategically: A Case Study on One Night Ultimate Werewolf**
2405.19946v1 by Xuanfa Jin, Ziyan Wang, Yali Du, Meng Fang, Haifeng Zhang, Jun Wang

Communication is a fundamental aspect of human society, facilitating the
exchange of information and beliefs among people. Despite the advancements in
large language models (LLMs), recent agents built with these often neglect the
control over discussion tactics, which are essential in communication scenarios
and games. As a variant of the famous communication game Werewolf, One Night
Ultimate Werewolf (ONUW) requires players to develop strategic discussion
policies due to the potential role changes that increase the uncertainty and
complexity of the game. In this work, we first present the existence of the
Perfect Bayesian Equilibria (PBEs) in two scenarios of the ONUW game: one with
discussion and one without. The results showcase that the discussion greatly
changes players' utilities by affecting their beliefs, emphasizing the
significance of discussion tactics. Based on the insights obtained from the
analyses, we propose an RL-instructed language agent framework, where a
discussion policy trained by reinforcement learning (RL) is employed to
determine appropriate discussion tactics to adopt. Our experimental results on
several ONUW game settings demonstrate the effectiveness and generalizability
of our proposed framework.

摘要：溝通是人類社會的基本面向，促進人們之間的資訊和信念交流。儘管大型語言模型（LLM）有進展，但最近使用這些模型建構的代理人常常忽略對討論策略的控制，而這在溝通情境和遊戲中至關重要。作為著名的溝通遊戲狼人殺的變體，一夜終極狼人（ONUW）要求玩家制定策略性討論政策，因為潛在的角色變化會增加遊戲的不確定性和複雜性。在這項工作中，我們首先提出在 ONUW 遊戲的兩個情境中完美貝氏均衡（PBE）的存在：一個有討論，一個沒有討論。結果表明，討論透過影響玩家的信念，大幅改變玩家的效用，強調討論策略的重要性。根據從分析中獲得的見解，我們提出一個 RL 指導的語言代理人架構，其中使用透過強化學習（RL）訓練的討論政策來決定適當採用的討論策略。我們在多個 ONUW 遊戲設定上的實驗結果證明了我們提出的架構的有效性和概括性。

##### **Learning Latent Graph Structures and their Uncertainty**
2405.19933v1 by Alessandro Manenti, Daniele Zambon, Cesare Alippi

Within a prediction task, Graph Neural Networks (GNNs) use relational
information as an inductive bias to enhance the model's accuracy. As
task-relevant relations might be unknown, graph structure learning approaches
have been proposed to learn them while solving the downstream prediction task.
In this paper, we demonstrate that minimization of a point-prediction loss
function, e.g., the mean absolute error, does not guarantee proper learning of
the latent relational information and its associated uncertainty. Conversely,
we prove that a suitable loss function on the stochastic model outputs
simultaneously grants (i) the unknown adjacency matrix latent distribution and
(ii) optimal performance on the prediction task. Finally, we propose a
sampling-based method that solves this joint learning task. Empirical results
validate our theoretical claims and demonstrate the effectiveness of the
proposed approach.

摘要：<paragraph>在預測任務中，圖神經網路 (GNN) 使用關聯資訊作為歸納偏誤，以增強模型準確性。由於與任務相關的關係可能是未知的，因此提出圖結構學習方法，以便在解決下游預測任務時學習它們。在本文中，我們證明點預測損失函數（例如平均絕對誤差）的最小化並不能保證正確學習潛在關係資訊及其相關的不確定性。相反，我們證明了隨機模型輸出上的合適損失函數同時賦予 (i) 未知鄰接矩陣潛在分佈和 (ii) 預測任務的最佳效能。最後，我們提出一個基於抽樣的解決此聯合學習任務的方法。實證結果驗證了我們的理論主張，並證明了所提出方法的有效性。</paragraph>

##### **Exploring Diffusion Models' Corruption Stage in Few-Shot Fine-tuning and Mitigating with Bayesian Neural Networks**
2405.19931v1 by Xiaoyu Wu, Jiaru Zhang, Yang Hua, Bohan Lyu, Hao Wang, Tao Song, Haibing Guan

Few-shot fine-tuning of Diffusion Models (DMs) is a key advancement,
significantly reducing training costs and enabling personalized AI
applications. However, we explore the training dynamics of DMs and observe an
unanticipated phenomenon: during the training process, image fidelity initially
improves, then unexpectedly deteriorates with the emergence of noisy patterns,
only to recover later with severe overfitting. We term the stage with generated
noisy patterns as corruption stage. To understand this corruption stage, we
begin by theoretically modeling the one-shot fine-tuning scenario, and then
extend this modeling to more general cases. Through this modeling, we identify
the primary cause of this corruption stage: a narrowed learning distribution
inherent in the nature of few-shot fine-tuning. To tackle this, we apply
Bayesian Neural Networks (BNNs) on DMs with variational inference to implicitly
broaden the learned distribution, and present that the learning target of the
BNNs can be naturally regarded as an expectation of the diffusion loss and a
further regularization with the pretrained DMs. This approach is highly
compatible with current few-shot fine-tuning methods in DMs and does not
introduce any extra inference costs. Experimental results demonstrate that our
method significantly mitigates corruption, and improves the fidelity, quality
and diversity of the generated images in both object-driven and subject-driven
generation tasks.

摘要：扩散模型 (DM) 的小样本微调是一项关键进展，大幅降低了训练成本并实现了个性化 AI 应用程序。然而，我们探索了 DM 的训练动态并观察到一种意外现象：在训练过程中，图像保真度最初有所提高，然后出乎意料地随着噪声模式的出现而恶化，最后在严重的过拟合中恢复。我们将生成噪声模式的阶段称为损坏阶段。为了理解这个损坏阶段，我们首先从理论上对单次微调场景进行建模，然后将这种建模扩展到更一般的案例。通过这种建模，我们确定了这种损坏阶段的主要原因：小样本微调固有的一种狭窄的学习分布。为了解决这个问题，我们在 DM 上应用贝叶斯神经网络 (BNN)，并使用变分推理来隐式拓宽学习分布，并提出 BNN 的学习目标可以自然地视为扩散损失的期望和对预训练 DM 的进一步正则化。这种方法与当前 DM 中的小样本微调方法高度兼容，并且不会引入任何额外的推理成本。实验结果表明，我们的方法显着减轻了损坏，并提高了对象驱动和主题驱动生成任务中生成图像的保真度、质量和多样性。

##### **Open-Set Domain Adaptation for Semantic Segmentation**
2405.19899v1 by Seun-An Choe, Ah-Hyung Shin, Keon-Hee Park, Jinwoo Choi, Gyeong-Moon Park

Unsupervised domain adaptation (UDA) for semantic segmentation aims to
transfer the pixel-wise knowledge from the labeled source domain to the
unlabeled target domain. However, current UDA methods typically assume a shared
label space between source and target, limiting their applicability in
real-world scenarios where novel categories may emerge in the target domain. In
this paper, we introduce Open-Set Domain Adaptation for Semantic Segmentation
(OSDA-SS) for the first time, where the target domain includes unknown classes.
We identify two major problems in the OSDA-SS scenario as follows: 1) the
existing UDA methods struggle to predict the exact boundary of the unknown
classes, and 2) they fail to accurately predict the shape of the unknown
classes. To address these issues, we propose Boundary and Unknown Shape-Aware
open-set domain adaptation, coined BUS. Our BUS can accurately discern the
boundaries between known and unknown classes in a contrastive manner using a
novel dilation-erosion-based contrastive loss. In addition, we propose
OpenReMix, a new domain mixing augmentation method that guides our model to
effectively learn domain and size-invariant features for improving the shape
detection of the known and unknown classes. Through extensive experiments, we
demonstrate that our proposed BUS effectively detects unknown classes in the
challenging OSDA-SS scenario compared to the previous methods by a large
margin. The code is available at https://github.com/KHU-AGI/BUS.

摘要：無監督域適應 (UDA) 旨在將標籤來源域的像素級知識轉移到未標籤目標域中，用於語意分割。然而，目前的 UDA 方法通常假設來源和目標之間有共享標籤空間，這限制了它們在實際場景中的應用性，因為在目標域中可能會出現新的類別。在本文中，我們首次介紹了用於語意分割的開放集域適應 (OSDA-SS)，其中目標域包括未知類別。我們將 OSDA-SS 場景中的兩個主要問題確定如下：1) 現有的 UDA 方法難以預測未知類別的確切邊界，以及 2) 它們無法準確預測未知類別的形狀。為了解決這些問題，我們提出了邊界和未知形狀感知開放集域適應，稱為 BUS。我們的 BUS 可以使用新穎的膨脹侵蝕對比損失，以對比方式準確辨別已知類別和未知類別之間的邊界。此外，我們提出了 OpenReMix，這是一種新的域混合擴充方法，它指導我們的模型有效學習域和大小不變特徵，以改進已知和未知類別的形狀檢測。通過廣泛的實驗，我們證明與之前的許多方法相比，我們提出的 BUS 在具有挑戰性的 OSDA-SS 場景中有效檢測未知類別。程式碼可在 https://github.com/KHU-AGI/BUS 取得。

##### **Similarity is Not All You Need: Endowing Retrieval Augmented Generation with Multi Layered Thoughts**
2405.19893v1 by Chunjing Gan, Dan Yang, Binbin Hu, Hanxiao Zhang, Siyuan Li, Ziqi Liu, Yue Shen, Lin Ju, Zhiqiang Zhang, Jinjie Gu, Lei Liang, Jun Zhou

In recent years, large language models (LLMs) have made remarkable
achievements in various domains. However, the untimeliness and cost of
knowledge updates coupled with hallucination issues of LLMs have curtailed
their applications in knowledge intensive tasks, where retrieval augmented
generation (RAG) can be of help. Nevertheless, existing retrieval augmented
models typically use similarity as a bridge between queries and documents and
follow a retrieve then read procedure. In this work, we argue that similarity
is not always the panacea and totally relying on similarity would sometimes
degrade the performance of retrieval augmented generation. To this end, we
propose MetRag, a Multi layEred Thoughts enhanced Retrieval Augmented
Generation framework. To begin with, beyond existing similarity oriented
thought, we embrace a small scale utility model that draws supervision from an
LLM for utility oriented thought and further come up with a smarter model by
comprehensively combining the similarity and utility oriented thoughts.
Furthermore, given the fact that the retrieved document set tends to be huge
and using them in isolation makes it difficult to capture the commonalities and
characteristics among them, we propose to make an LLM as a task adaptive
summarizer to endow retrieval augmented generation with compactness-oriented
thought. Finally, with multi layered thoughts from the precedent stages, an LLM
is called for knowledge augmented generation. Extensive experiments on
knowledge-intensive tasks have demonstrated the superiority of MetRag.

摘要：近年來，大型語言模型 (LLM) 在各個領域都有顯著的成就。然而，知識更新的不及時和成本，加上 LLM 的幻覺問題，限制了它們在知識密集型任務中的應用，而檢索增強生成 (RAG) 可以提供幫助。儘管如此，現有的檢索增強模型通常使用相似性作為查詢和文件之間的橋樑，並遵循先檢索再閱讀的程序。在這項工作中，我們認為相似性並非萬靈丹，完全依賴相似性有時會降低檢索增強生成的性能。為此，我們提出了 MetRag，一個多層思想增強檢索增強生成框架。首先，除了現有的面向相似性的思想之外，我們採用了一個小規模的實用模型，從 LLM 中汲取監督，以獲得面向實用的思想，並通過全面結合相似性和面向實用的思想，進一步提出了更智能的模型。此外，鑑於檢索到的文件集往往龐大，孤立地使用它們難以捕捉它們之間的共性和特徵，我們建議將 LLM 作為任務適應型摘要器，以賦予檢索增強生成以面向緊湊性的思想。最後，利用前一階段的多層思想，呼籲 LLM 進行知識增強生成。在知識密集型任務上的大量實驗證明了 MetRag 的優越性。

##### **Parrot: Efficient Serving of LLM-based Applications with Semantic Variable**
2405.19888v1 by Chaofan Lin, Zhenhua Han, Chengruidong Zhang, Yuqing Yang, Fan Yang, Chen Chen, Lili Qiu

The rise of large language models (LLMs) has enabled LLM-based applications
(a.k.a. AI agents or co-pilots), a new software paradigm that combines the
strength of LLM and conventional software. Diverse LLM applications from
different tenants could design complex workflows using multiple LLM requests to
accomplish one task. However, they have to use the over-simplified
request-level API provided by today's public LLM services, losing essential
application-level information. Public LLM services have to blindly optimize
individual LLM requests, leading to sub-optimal end-to-end performance of LLM
applications.
  This paper introduces Parrot, an LLM service system that focuses on the
end-to-end experience of LLM-based applications. Parrot proposes Semantic
Variable, a unified abstraction to expose application-level knowledge to public
LLM services. A Semantic Variable annotates an input/output variable in the
prompt of a request, and creates the data pipeline when connecting multiple LLM
requests, providing a natural way to program LLM applications. Exposing
Semantic Variables to the public LLM service allows it to perform conventional
data flow analysis to uncover the correlation across multiple LLM requests.
This correlation opens a brand-new optimization space for the end-to-end
performance of LLM-based applications. Extensive evaluations demonstrate that
Parrot can achieve up to an order-of-magnitude improvement for popular and
practical use cases of LLM applications.

摘要：大型語言模型 (LLM) 的興起讓基於 LLM 的應用程式得以問世 (又稱 AI 代理或副駕駛)，這是一種新的軟體範例，結合了 LLM 和傳統軟體的優勢。來自不同租戶的多元 LLM 應用程式可以使用多個 LLM 要求來設計複雜的工作流程，以完成一項任務。然而，它們必須使用當今公開的 LLM 服務提供的過於簡化的請求層級 API，失去必要的應用程式層級資訊。公開的 LLM 服務必須盲目地最佳化個別的 LLM 請求，導致 LLM 應用程式的端對端效能不佳。
本文介紹 Parrot，一種專注於基於 LLM 的應用程式的端對端體驗的 LLM 服務系統。Parrot 提出語義變數，一種統一的抽象化，用於向公開的 LLM 服務公開應用程式層級的知識。語義變數在請求提示中註解輸入/輸出變數，並在連接多個 LLM 請求時建立資料管道，提供一種編寫 LLM 應用程式的自然方式。向公開的 LLM 服務公開語義變數，讓它可以執行傳統的資料流程分析，以找出多個 LLM 請求之間的關聯性。這種關聯性為基於 LLM 的應用程式的端對端效能開啟了一個全新的最佳化空間。廣泛的評估證明，對於 LLM 應用程式的熱門且實際的使用案例，Parrot 可以實現高達一個數量級的改進。

##### **From Words to Actions: Unveiling the Theoretical Underpinnings of LLM-Driven Autonomous Systems**
2405.19883v1 by Jianliang He, Siyu Chen, Fengzhuo Zhang, Zhuoran Yang

In this work, from a theoretical lens, we aim to understand why large
language model (LLM) empowered agents are able to solve decision-making
problems in the physical world. To this end, consider a hierarchical
reinforcement learning (RL) model where the LLM Planner and the Actor perform
high-level task planning and low-level execution, respectively. Under this
model, the LLM Planner navigates a partially observable Markov decision process
(POMDP) by iteratively generating language-based subgoals via prompting. Under
proper assumptions on the pretraining data, we prove that the pretrained LLM
Planner effectively performs Bayesian aggregated imitation learning (BAIL)
through in-context learning. Additionally, we highlight the necessity for
exploration beyond the subgoals derived from BAIL by proving that naively
executing the subgoals returned by LLM leads to a linear regret. As a remedy,
we introduce an $\epsilon$-greedy exploration strategy to BAIL, which is proven
to incur sublinear regret when the pretraining error is small. Finally, we
extend our theoretical framework to include scenarios where the LLM Planner
serves as a world model for inferring the transition model of the environment
and to multi-agent settings, enabling coordination among multiple Actors.

摘要：<paragraph>在這項工作中，從理論的角度來看，我們旨在理解為什麼大型語言模型 (LLM) 賦能的代理能夠解決物理世界中的決策問題。為此，考慮一個分層強化學習 (RL) 模型，其中 LLM 規劃器和行動者分別執行高級任務規劃和低級執行。在此模型下，LLM 規劃器通過提示反覆生成基於語言的子目標，從而導航部分可觀察馬可夫決策過程 (POMDP)。在對預訓練數據的適當假設下，我們證明了預訓練的 LLM 規劃器通過情境學習有效地執行貝葉斯聚合模仿學習 (BAIL)。此外，我們強調了探索超越 BAIL 推導的子目標的必要性，通過證明天真地執行 LLM 返回的子目標會導致線性遺憾。作為補救措施，我們在 BAIL 中引入了一個 $\epsilon$-貪婪探索策略，當預訓練誤差很小時，證明會產生次線性遺憾。最後，我們將我們的理論框架擴展到包括 LLM 規劃器作為世界模型用於推斷環境的轉換模型和多主體設置的情況，從而實現多個行動者之間的協調。</paragraph>

##### **KNOW: A Real-World Ontology for Knowledge Capture with Large Language Models**
2405.19877v1 by Arto Bendiken

We present KNOW--the Knowledge Navigator Ontology for the World--the first
ontology designed to capture everyday knowledge to augment large language
models (LLMs) in real-world generative AI use cases such as personal AI
assistants. Our domain is human life, both its everyday concerns and its major
milestones. We have limited the initial scope of the modeled concepts to only
established human universals: spacetime (places, events) plus social (people,
groups, organizations). The inclusion criteria for modeled concepts are
pragmatic, beginning with universality and utility. We compare and contrast
previous work such as Schema.org and Cyc--as well as attempts at a synthesis of
knowledge graphs and language models--noting how LLMs already encode internally
much of the commonsense tacit knowledge that took decades to capture in the Cyc
project. We also make available code-generated software libraries for the 12
most popular programming languages, enabling the direct use of ontology
concepts in software engineering. We emphasize simplicity and developer
experience in promoting AI interoperability.

摘要：我們提出了 KNOW，即世界知識導航本体，這是第一個旨在擷取日常知識以擴充大型語言模型 (LLM) 在實際生成式 AI 使用案例中的本体，例如個人 AI 助理。我們的領域是人類生活，包括其日常關切和重大里程碑。我們已將建模概念的初始範圍限制為僅建立人類普遍性：時空（地點、事件）加上社會（人、群組、組織）。建模概念的納入標準很務實，從普遍性和實用性開始。我們比較和對比先前的作品，例如 Schema.org 和 Cyc，以及知識圖譜和語言模型的綜合嘗試，並注意到 LLM 已內部編碼了許多常識性的默認知識，而這些知識花費了數十年才在 Cyc 項目中被擷取。我們還提供了 12 種最受歡迎的程式設計語言的程式碼生成軟體函式庫，讓建模概念能夠直接用於軟體工程中。我們強調簡潔性和開發人員經驗在促進 AI 互操作性中的重要性。

##### **Is In-Context Learning Sufficient for Instruction Following in LLMs?**
2405.19874v1 by Hao Zhao, Maksym Andriushchenko, Francesco Croce, Nicolas Flammarion

In-context learning (ICL) allows LLMs to learn from examples without changing
their weights, which is a particularly promising capability for long-context
LLMs that can potentially learn from many examples. Recently, Lin et al. (2024)
proposed URIAL, a method using only three in-context examples to align base
LLMs, achieving non-trivial instruction following performance. In this work, we
show that, while effective, ICL alignment with URIAL still underperforms
compared to instruction fine-tuning on established benchmarks such as MT-Bench
and AlpacaEval 2.0 (LC), especially with more capable base LMs. Unlike for
tasks such as classification, translation, or summarization, adding more ICL
demonstrations for long-context LLMs does not systematically improve
instruction following performance. To address this limitation, we derive a
greedy selection approach for ICL examples that noticeably improves
performance, yet without bridging the gap to instruction fine-tuning. Finally,
we provide a series of ablation studies to better understand the reasons behind
the remaining gap, and we show how some aspects of ICL depart from the existing
knowledge and are specific to the instruction tuning setting. Overall, our work
advances the understanding of ICL as an alignment technique. We provide our
code at https://github.com/tml-epfl/icl-alignment.

摘要：<paragraph>情境式學習 (ICL) 讓大型語言模型 (LLM) 能夠從範例中學習，而無需改變其權重，這對於潛在能從許多範例中學習的長情境 LLM 而言，是一種特別有前途的能力。最近，Lin 等人 (2024) 提出 URIAL，一種僅使用三個情境式範例來比對基礎 LLM 的方法，實現了非平凡的指令遵循效能。在這項工作中，我們證明，儘管有效，但與在既定的基準（例如 MT-Bench 和 AlpacaEval 2.0 (LC)）上進行指令微調相比，ICL 比對與 URIAL 仍然表現不佳，特別是對於功能更強大的基礎 LLM。與分類、翻譯或摘要等任務不同，為長情境 LLM 加入更多 ICL 示範並不會系統性地改善指令遵循效能。為了解決這個限制，我們推導出一個針對 ICL 範例的貪婪選擇方法，顯著改善了效能，但並未彌合與指令微調之間的差距。最後，我們提供了一系列消融研究，以更好地了解造成剩餘差距的原因，並展示 ICL 的某些方面如何偏離現有知識，並且特定於指令調整設定。總體而言，我們的研究促進了對 ICL 作為比對技術的理解。我們在 https://github.com/tml-epfl/icl-alignment 提供我們的程式碼。</paragraph>

##### **Out-of-distribution Reject Option Method for Dataset Shift Problem in Early Disease Onset Prediction**
2405.19864v1 by Taisei Tosaki, Eiichiro Uchino, Ryosuke Kojima, Yohei Mineharu, Mikio Arita, Nobuyuki Miyai, Yoshinori Tamada, Tatsuya Mikami, Koichi Murashita, Shigeyuki Nakaji, Yasushi Okuno

Machine learning is increasingly used to predict lifestyle-related disease
onset using health and medical data. However, the prediction effectiveness is
hindered by dataset shift, which involves discrepancies in data distribution
between the training and testing datasets, misclassifying out-of-distribution
(OOD) data. To diminish dataset shift effects, this paper proposes the
out-of-distribution reject option for prediction (ODROP), which integrates OOD
detection models to preclude OOD data from the prediction phase. We
investigated the efficacy of five OOD detection methods (variational
autoencoder, neural network ensemble std, neural network ensemble epistemic,
neural network energy, and neural network gaussian mixture based energy
measurement) across two datasets, the Hirosaki and Wakayama health checkup
data, in the context of three disease onset prediction tasks: diabetes,
dyslipidemia, and hypertension. To evaluate the ODROP method, we trained
disease onset prediction models and OOD detection models on Hirosaki data and
used AUROC-rejection curve plots from Wakayama data. The variational
autoencoder method showed superior stability and magnitude of improvement in
Area Under the Receiver Operating Curve (AUROC) in five cases: AUROC in the
Wakayama data was improved from 0.80 to 0.90 at a 31.1% rejection rate for
diabetes onset and from 0.70 to 0.76 at a 34% rejection rate for dyslipidemia.
We categorized dataset shifts into two types using SHAP clustering - those that
considerably affect predictions and those that do not. We expect that this
classification will help standardize measuring instruments. This study is the
first to apply OOD detection to actual health and medical data, demonstrating
its potential to substantially improve the accuracy and reliability of disease
prediction models amidst dataset shift.

摘要：機器學習正日益用於預測與生活方式相關的疾病發作，並使用健康和醫療數據。然而，預測效果會受到資料集轉移的阻礙，這涉及訓練和測試資料集之間的資料分佈差異，將分布外 (OOD) 資料分類錯誤。為了減少資料集轉移效應，本文提出用於預測的分布外拒絕選項 (ODROP)，它整合 OOD 偵測模型以排除預測階段的 OOD 資料。我們調查了五種 OOD 偵測方法 (變異自動編碼器、神經網路整體標準差、神經網路整體認識論、神經網路能量和基於神經網路高斯混合能量測量) 的效能，跨兩個資料集，弘前和和歌山健康檢查資料，在糖尿病、血脂異常和高血壓這三個疾病發作預測任務的脈絡中。為了評估 ODROP 方法，我們訓練了弘前資料的疾病發作預測模型和 OOD 偵測模型，並使用和歌山資料的 AUROC 排斥曲線圖。變異自動編碼器方法在五種情況下展現出優異的穩定性和改善幅度：在接受者操作特徵曲線 (AUROC) 下方區域中，和歌山資料的 AUROC 從糖尿病發作的 31.1% 排斥率改善到 0.90，從血脂異常的 34% 排斥率改善到 0.76。我們使用 SHAP 聚類將資料集轉移分為兩種類型，一種會顯著影響預測，另一種則不會。我們預期這種分類將有助於標準化測量儀器。這項研究首次將 OOD 偵測應用於實際的健康和醫療資料，證明了其在資料集轉移中大幅改善疾病預測模型的準確性和可靠性的潛力。

##### **DevEval: A Manually-Annotated Code Generation Benchmark Aligned with Real-World Code Repositories**
2405.19856v1 by Jia Li, Ge Li, Yunfei Zhao, Yongmin Li, Huanyu Liu, Hao Zhu, Lecheng Wang, Kaibo Liu, Zheng Fang, Lanshen Wang, Jiazheng Ding, Xuanming Zhang, Yuqi Zhu, Yihong Dong, Zhi Jin, Binhua Li, Fei Huang, Yongbin Li

How to evaluate the coding abilities of Large Language Models (LLMs) remains
an open question. We find that existing benchmarks are poorly aligned with
real-world code repositories and are insufficient to evaluate the coding
abilities of LLMs.
  To address the knowledge gap, we propose a new benchmark named DevEval, which
has three advances. (1) DevEval aligns with real-world repositories in multiple
dimensions, e.g., code distributions and dependency distributions. (2) DevEval
is annotated by 13 developers and contains comprehensive annotations (e.g.,
requirements, original repositories, reference code, and reference
dependencies). (3) DevEval comprises 1,874 testing samples from 117
repositories, covering 10 popular domains (e.g., Internet, Database). Based on
DevEval, we propose repository-level code generation and evaluate 8 popular
LLMs on DevEval (e.g., gpt-4, gpt-3.5, StarCoder 2, DeepSeek Coder, CodeLLaMa).
Our experiments reveal these LLMs' coding abilities in real-world code
repositories. For example, in our experiments, the highest Pass@1 of
gpt-4-turbo is only 53.04%. We also analyze LLMs' failed cases and summarize
their shortcomings. We hope DevEval can facilitate the development of LLMs in
real code repositories. DevEval, prompts, and LLMs' predictions have been
released.

摘要：如何評估大型語言模型 (LLM) 的編碼能力仍然是一個懸而未決的問題。我們發現現有的基準與實際的程式碼儲存庫對齊不良，不足以評估 LLM 的編碼能力。
為了解決知識差距，我們提出一個名為 DevEval 的新基準，它有三個進展。(1) DevEval 在多個面向與實際的儲存庫對齊，例如，程式碼分佈和依賴關係分佈。(2) DevEval 由 13 位開發人員註解，並包含全面的註解 (例如，需求、原始儲存庫、參考程式碼和參考依賴關係)。(3) DevEval 包含來自 117 個儲存庫的 1,874 個測試範例，涵蓋 10 個熱門領域 (例如，網際網路、資料庫)。根據 DevEval，我們提出儲存庫層級的程式碼產生，並在 DevEval 上評估 8 個熱門的 LLM (例如，gpt-4、gpt-3.5、StarCoder 2、DeepSeek Coder、CodeLLaMa)。我們的實驗揭示了這些 LLM 在實際程式碼儲存庫中的編碼能力。例如，在我們的實驗中，gpt-4-turbo 的最高 Pass@1 僅為 53.04%。我們還分析了 LLM 的失敗案例，並總結了它們的缺點。我們希望 DevEval 能促進 LLM 在實際程式碼儲存庫中的發展。DevEval、提示和 LLM 的預測已經發布。

##### **Deciphering Human Mobility: Inferring Semantics of Trajectories with Large Language Models**
2405.19850v1 by Yuxiao Luo, Zhongcai Cao, Xin Jin, Kang Liu, Ling Yin

Understanding human mobility patterns is essential for various applications,
from urban planning to public safety. The individual trajectory such as mobile
phone location data, while rich in spatio-temporal information, often lacks
semantic detail, limiting its utility for in-depth mobility analysis. Existing
methods can infer basic routine activity sequences from this data, lacking
depth in understanding complex human behaviors and users' characteristics.
Additionally, they struggle with the dependency on hard-to-obtain auxiliary
datasets like travel surveys. To address these limitations, this paper defines
trajectory semantic inference through three key dimensions: user occupation
category, activity sequence, and trajectory description, and proposes the
Trajectory Semantic Inference with Large Language Models (TSI-LLM) framework to
leverage LLMs infer trajectory semantics comprehensively and deeply. We adopt
spatio-temporal attributes enhanced data formatting (STFormat) and design a
context-inclusive prompt, enabling LLMs to more effectively interpret and infer
the semantics of trajectory data. Experimental validation on real-world
trajectory datasets demonstrates the efficacy of TSI-LLM in deciphering complex
human mobility patterns. This study explores the potential of LLMs in enhancing
the semantic analysis of trajectory data, paving the way for more sophisticated
and accessible human mobility research.

摘要：了解人類流動模式對於各種應用至關重要，從城市規劃到公共安全。個人軌跡，例如行動電話位置數據，儘管富含時空資訊，但通常缺乏語義細節，限制了其在深入流動性分析中的效用。現有方法可以從這些數據中推斷出基本的例行活動序列，缺乏對複雜人類行為和使用者特徵的深入了解。此外，它們難以獲得難以獲得的輔助資料集，例如旅行調查。為了解決這些限制，本文通過三個關鍵維度定義了軌跡語義推理：使用者職業類別、活動序列和軌跡描述，並提出了具有大型語言模型（TSI-LLM）框架的軌跡語義推理，以全面深入地利用 LLM 推斷軌跡語義。我們採用時空屬性增強數據格式（STFormat），並設計了一個包含上下文的提示，使 LLM 能更有效地解釋和推斷軌跡數據的語義。對真實世界軌跡資料集的實驗驗證證明了 TSI-LLM 在破譯複雜人類流動模式方面的效力。本研究探討了 LLM 在增強軌跡數據語義分析方面的潛力，為更精緻且易於理解的人類流動性研究鋪平了道路。

##### **Quest: Query-centric Data Synthesis Approach for Long-context Scaling of Large Language Model**
2405.19846v1 by Chaochen Gao, Xing Wu, Qi Fu, Songlin Hu

Large language models, initially pre-trained with a limited context length,
can better handle longer texts by continuing training on a corpus with extended
contexts. However, obtaining effective long-context data is challenging due to
the scarcity and uneven distribution of long documents across different
domains. To address this issue, we propose a Query-centric data synthesis
method, abbreviated as Quest. Quest is an interpretable method based on the
observation that documents retrieved by similar queries are relevant but
low-redundant, thus well-suited for synthesizing long-context data. The method
is also scalable and capable of constructing large amounts of long-context
data. Using Quest, we synthesize a long-context dataset up to 128k context
length, significantly outperforming other data synthesis methods on multiple
long-context benchmark datasets. In addition, we further verify that the Quest
method is predictable through scaling law experiments, making it a reliable
solution for advancing long-context models.

摘要：大型語言模型最初使用有限的上下文長度進行預訓練，
透過持續訓練語料庫，並延伸脈絡，可以更好地處理較長的文本。然而，由於長文件的稀少性和不同領域分布不均，因此取得有效的長脈絡資料具有挑戰性。為了解決這個問題，我們提出了一種以查詢為中心的資料合成方法，簡稱為 Quest。Quest 是一種可解釋的方法，基於以下觀察：透過類似查詢檢索的的文件相關但低重複，因此非常適合合成長脈絡資料。這種方法具有可擴充性，並且能夠建構大量的長脈絡資料。使用 Quest，我們合成了一個長達 128k 脈絡長度的長脈絡資料集，在多個長脈絡基準資料集上顯著優於其他資料合成方法。此外，我們進一步驗證了 Quest 方法透過規模定律實驗具有可預測性，使其成為推進長脈絡模型的可靠解決方案。

##### **Improve Student's Reasoning Generalizability through Cascading Decomposed CoTs Distillation**
2405.19842v1 by Chengwei Dai, Kun Li, Wei Zhou, Songlin Hu

Large language models (LLMs) exhibit enhanced reasoning at larger scales,
driving efforts to distill these capabilities into smaller models via
teacher-student learning. Previous works simply fine-tune student models on
teachers' generated Chain-of-Thoughts (CoTs) data. Although these methods
enhance in-domain (IND) reasoning performance, they struggle to generalize to
out-of-domain (OOD) tasks. We believe that the widespread spurious correlations
between questions and answers may lead the model to preset a specific answer
which restricts the diversity and generalizability of its reasoning process. In
this paper, we propose Cascading Decomposed CoTs Distillation (CasCoD) to
address these issues by decomposing the traditional single-step learning
process into two cascaded learning steps. Specifically, by restructuring the
training objectives -- removing the answer from outputs and concatenating the
question with the rationale as input -- CasCoD's two-step learning process
ensures that students focus on learning rationales without interference from
the preset answers, thus improving reasoning generalizability. Extensive
experiments demonstrate the effectiveness of CasCoD on both IND and OOD
benchmark reasoning datasets. Code can be found at
https://github.com/C-W-D/CasCoD.

摘要：大型語言模型 (LLM) 在較大的規模上表現出增強的推理能力，推動了透過教師學生學習將這些能力轉化為較小模型的努力。先前的作品僅針對教師產生的思維鏈 (CoT) 資料微調學生模型。儘管這些方法增強了領域內 (IND) 推理效能，但它們難以概化到領域外 (OOD) 任務。我們相信問題與答案之間廣泛的虛假關聯可能導致模型預設特定答案，這會限制其推理過程的多樣性和概化性。在本文中，我們提出串聯分解 CoT 蒸餾 (CasCoD) 來解決這些問題，方法是將傳統的單步驟學習過程分解為兩個串聯的學習步驟。具體來說，透過重新建構訓練目標（從輸出中移除答案並將問題與依據串聯為輸入），CasCoD 的兩步驟學習過程確保學生專注於學習依據，不受預設答案的干擾，從而提高推理概化性。廣泛的實驗證明了 CasCoD 在 IND 和 OOD 基準推理資料集上的有效性。程式碼可在 https://github.com/C-W-D/CasCoD 找到。

##### **Just Rewrite It Again: A Post-Processing Method for Enhanced Semantic Similarity and Privacy Preservation of Differentially Private Rewritten Text**
2405.19831v1 by Stephen Meisenbacher, Florian Matthes

The study of Differential Privacy (DP) in Natural Language Processing often
views the task of text privatization as a $\textit{rewriting}$ task, in which
sensitive input texts are rewritten to hide explicit or implicit private
information. In order to evaluate the privacy-preserving capabilities of a DP
text rewriting mechanism, $\textit{empirical privacy}$ tests are frequently
employed. In these tests, an adversary is modeled, who aims to infer sensitive
information (e.g., gender) about the author behind a (privatized) text. Looking
to improve the empirical protections provided by DP rewriting methods, we
propose a simple post-processing method based on the goal of aligning rewritten
texts with their original counterparts, where DP rewritten texts are rewritten
$\textit{again}$. Our results shown that such an approach not only produces
outputs that are more semantically reminiscent of the original inputs, but also
texts which score on average better in empirical privacy evaluations.
Therefore, our approach raises the bar for DP rewriting methods in their
empirical privacy evaluations, providing an extra layer of protection against
malicious adversaries.

摘要：在自然語言處理中，差分隱私 (DP) 的研究通常將文本私有化的任務視為「改寫」任務，其中敏感的輸入文本會被改寫以隱藏明確或隱含的私人資訊。為了評估 DP 文字改寫機制的隱私保護能力，通常會採用「經驗隱私」測試。在這些測試中，會模擬一個對手，其目標是推斷出（已私有化）文字背後作者的敏感資訊（例如性別）。為了改善 DP 改寫方法提供的經驗保護，我們提出一個簡單的後處理方法，其基礎是將改寫後的文字與其原始對應文字對齊，其中 DP 改寫後的文字會再次被改寫。我們的結果顯示，這種方法不僅產生在語意上更能讓人聯想到原始輸入的輸出，而且在經驗隱私評估中平均得分也較高的文字。因此，我們的做法提高了 DP 改寫方法在其經驗隱私評估中的標準，提供了一層額外的防護，以對抗惡意的對手。

##### **Joint Selective State Space Model and Detrending for Robust Time Series Anomaly Detection**
2405.19823v1 by Junqi Chen, Xu Tan, Sylwan Rahardja, Jiawei Yang, Susanto Rahardja

Deep learning-based sequence models are extensively employed in Time Series
Anomaly Detection (TSAD) tasks due to their effective sequential modeling
capabilities. However, the ability of TSAD is limited by two key challenges:
(i) the ability to model long-range dependency and (ii) the generalization
issue in the presence of non-stationary data. To tackle these challenges, an
anomaly detector that leverages the selective state space model known for its
proficiency in capturing long-term dependencies across various domains is
proposed. Additionally, a multi-stage detrending mechanism is introduced to
mitigate the prominent trend component in non-stationary data to address the
generalization issue. Extensive experiments conducted on realworld public
datasets demonstrate that the proposed methods surpass all 12 compared baseline
methods.

摘要：深度學習序列模型廣泛用於時間序列異常偵測 (TSAD) 任務中，因為它們具有有效的序列建模能力。然而，TSAD 的能力受到兩個主要挑戰的限制：(i) 建模長程依賴性的能力，以及 (ii) 在非平穩資料中存在的泛化問題。為了應對這些挑戰，提出了一個異常偵測器，它利用選擇性狀態空間模型，該模型以在各種領域中捕捉長期依賴性而聞名。此外，引入了一個多階段去趨勢機制，以減輕非平穩資料中突出的趨勢成分，以解決泛化問題。在真實世界公共資料集上進行的廣泛實驗表明，所提出的方法優於所有 12 種比較基線方法。

##### **Improving Object Detector Training on Synthetic Data by Starting With a Strong Baseline Methodology**
2405.19822v1 by Frank A. Ruis, Alma M. Liezenga, Friso G. Heslinga, Luca Ballan, Thijs A. Eker, Richard J. M. den Hollander, Martin C. van Leeuwen, Judith Dijk, Wyke Huizinga

Collecting and annotating real-world data for the development of object
detection models is a time-consuming and expensive process. In the military
domain in particular, data collection can also be dangerous or infeasible.
Training models on synthetic data may provide a solution for cases where access
to real-world training data is restricted. However, bridging the reality gap
between synthetic and real data remains a challenge. Existing methods usually
build on top of baseline Convolutional Neural Network (CNN) models that have
been shown to perform well when trained on real data, but have limited ability
to perform well when trained on synthetic data. For example, some architectures
allow for fine-tuning with the expectation of large quantities of training data
and are prone to overfitting on synthetic data. Related work usually ignores
various best practices from object detection on real data, e.g. by training on
synthetic data from a single environment with relatively little variation. In
this paper we propose a methodology for improving the performance of a
pre-trained object detector when training on synthetic data. Our approach
focuses on extracting the salient information from synthetic data without
forgetting useful features learned from pre-training on real images. Based on
the state of the art, we incorporate data augmentation methods and a
Transformer backbone. Besides reaching relatively strong performance without
any specialized synthetic data transfer methods, we show that our methods
improve the state of the art on synthetic data trained object detection for the
RarePlanes and DGTA-VisDrone datasets, and reach near-perfect performance on an
in-house vehicle detection dataset.

摘要：收集和註解真實世界資料以開發物件偵測模型是一個耗時且昂貴的過程。特別是在軍事領域，資料收集也可能很危險或不可行。在無法取得真實世界訓練資料的情況下，使用合成資料訓練模型可能是一個解決方案。然而，縮小合成資料和真實資料之間的現實差距仍然是一項挑戰。現有方法通常建立在基線卷積神經網路 (CNN) 模型之上，這些模型已證明在使用真實資料訓練時表現良好，但使用合成資料訓練時表現良好的能力有限。例如，一些架構允許微調，期望有大量的訓練資料，並且容易在合成資料上過度擬合。相關工作通常忽略物件偵測在真實資料上的各種最佳實務，例如，使用變化相對較小的單一環境中的合成資料進行訓練。在本文中，我們提出了一種方法，用於在合成資料上訓練時改善預訓練物件偵測器的效能。我們的做法著重於從合成資料中提取顯著資訊，同時不忘記從真實影像預訓練中學到的有用特徵。根據最新技術，我們結合了資料擴充方法和 Transformer 主幹。除了在沒有任何專門合成資料傳輸方法的情況下達到相對強大的效能外，我們的方法還證明了我們的方法改善了合成資料訓練物件偵測的最新技術，例如 RarePlanes 和 DGTA-VisDrone 資料集，並在內部車輛偵測資料集上達到近乎完美的效能。

##### **WebUOT-1M: Advancing Deep Underwater Object Tracking with A Million-Scale Benchmark**
2405.19818v1 by Chunhui Zhang, Li Liu, Guanjie Huang, Hao Wen, Xi Zhou, Yanfeng Wang

Underwater object tracking (UOT) is a foundational task for identifying and
tracing submerged entities in underwater video sequences. However, current UOT
datasets suffer from limitations in scale, diversity of target categories and
scenarios covered, hindering the training and evaluation of modern tracking
algorithms. To bridge this gap, we take the first step and introduce WebUOT-1M,
\ie, the largest public UOT benchmark to date, sourced from complex and
realistic underwater environments. It comprises 1.1 million frames across 1,500
video clips filtered from 408 target categories, largely surpassing previous
UOT datasets, \eg, UVOT400. Through meticulous manual annotation and
verification, we provide high-quality bounding boxes for underwater targets.
Additionally, WebUOT-1M includes language prompts for video sequences,
expanding its application areas, \eg, underwater vision-language tracking. Most
existing trackers are tailored for open-air environments, leading to
performance degradation when applied to UOT due to domain gaps. Retraining and
fine-tuning these trackers are challenging due to sample imbalances and limited
real-world underwater datasets. To tackle these challenges, we propose a novel
omni-knowledge distillation framework based on WebUOT-1M, incorporating various
strategies to guide the learning of the student Transformer. To the best of our
knowledge, this framework is the first to effectively transfer open-air domain
knowledge to the UOT model through knowledge distillation, as demonstrated by
results on both existing UOT datasets and the newly proposed WebUOT-1M.
Furthermore, we comprehensively evaluate WebUOT-1M using 30 deep trackers,
showcasing its value as a benchmark for UOT research by presenting new
challenges and opportunities for future studies. The complete dataset, codes
and tracking results, will be made publicly available.

摘要：水下目標追蹤 (UOT) 是一項基礎任務，用於識別和追蹤水下影片序列中的水下實體。然而，目前的 UOT 資料集在規模、目標類別的多樣性和涵蓋的場景上都有所限制，這阻礙了現代追蹤演算法的訓練和評估。為了彌合這一差距，我們採取了第一步，並引入了 WebUOT-1M，即迄今為止最大的公開 UOT 基準，它來自複雜且真實的水下環境。它包含從 408 個目標類別中過濾出的 1500 個影片片段中的 110 萬個影格，遠遠超過以往的 UOT 資料集，例如 UVOT400。透過細緻的手動註解和驗證，我們為水下目標提供了高品質的邊界框。此外，WebUOT-1M 包含影片序列的語言提示，擴展了其應用領域，例如水下視覺語言追蹤。大多數現有的追蹤器都是針對露天環境而設計的，這導致在應用於 UOT 時由於領域差距而導致效能下降。由於樣本不平衡和有限的現實世界水下資料集，重新訓練和微調這些追蹤器具有挑戰性。為了應對這些挑戰，我們提出了一個基於 WebUOT-1M 的新全知識萃取架構，結合了各種策略來指導學生 Transformer 的學習。據我們所知，這個架構是第一個透過知識萃取有效地將露天領域知識轉移到 UOT 模型的架構，正如在現有 UOT 資料集和新提出的 WebUOT-1M 上的結果所示。此外，我們使用 30 個深度追蹤器全面評估了 WebUOT-1M，展示了其作為 UOT 研究基準的價值，為未來的研究提供了新的挑戰和機會。完整的資料集、程式碼和追蹤結果將公開提供。

##### **Efficient Stimuli Generation using Reinforcement Learning in Design Verification**
2405.19815v1 by Deepak Narayan Gadde, Thomas Nalapat, Aman Kumar, Djones Lettnin, Wolfgang Kunz, Sebastian Simon

The increasing design complexity of System-on-Chips (SoCs) has led to
significant verification challenges, particularly in meeting coverage targets
within a timely manner. At present, coverage closure is heavily dependent on
constrained random and coverage driven verification methodologies where the
randomized stimuli are bounded to verify certain scenarios and to reach
coverage goals. This process is said to be exhaustive and to consume a lot of
project time. In this paper, a novel methodology is proposed to generate
efficient stimuli with the help of Reinforcement Learning (RL) to reach the
maximum code coverage of the Design Under Verification (DUV). Additionally, an
automated framework is created using metamodeling to generate a SystemVerilog
testbench and an RL environment for any given design. The proposed approach is
applied to various designs and the produced results proves that the RL agent
provides effective stimuli to achieve code coverage faster in comparison with
baseline random simulations. Furthermore, various RL agents and reward schemes
are analyzed in our work.

摘要：由於系統晶片 (SoC) 的設計複雜度日益提升，導致驗證面臨重大挑戰，特別是在及時達成涵蓋率目標方面。目前，涵蓋率封閉高度依賴於受限隨機和涵蓋率驅動的驗證方法，其中隨機刺激受到約束，以驗證特定情境並達成涵蓋率目標。這個流程被認為是詳盡的，且會耗費大量專案時間。本文提出了一種創新的方法，以利用強化學習 (RL) 產生有效刺激，以達成待驗證設計 (DUV) 的最大程式碼涵蓋率。此外，使用元建模建立了一個自動化架構，以針對任何給定的設計產生 SystemVerilog 測試平台和 RL 環境。將所提出的方法應用於各種設計，產生的結果證明，與基線隨機模擬相比，RL 代理程式提供了有效的刺激，可以更快達成程式碼涵蓋率。此外，我們的研究分析了各種 RL 代理程式和獎勵機制。

##### **Unsupervised Mutual Learning of Dialogue Discourse Parsing and Topic Segmentation**
2405.19799v1 by Jiahui Xu, Feng Jiang, Anningzhe Gao, Haizhou Li

The advancement of large language models (LLMs) has propelled the development
of dialogue systems. Unlike the popular ChatGPT-like assistant model, which
only satisfies the user's preferences, task-oriented dialogue systems have also
faced new requirements and challenges in the broader business field. They are
expected to provide correct responses at each dialogue turn, at the same time,
achieve the overall goal defined by the task. By understanding rhetorical
structures and topic structures via topic segmentation and discourse parsing, a
dialogue system may do a better planning to achieve both objectives. However,
while both structures belong to discourse structure in linguistics, rhetorical
structure and topic structure are mostly modeled separately or with one
assisting the other in the prior work. The interaction between these two
structures has not been considered for joint modeling and mutual learning.
Furthermore, unsupervised learning techniques to achieve the above are not well
explored. To fill this gap, we propose an unsupervised mutual learning
framework of two structures leveraging the global and local connections between
them. We extend the topic modeling between non-adjacent discourse units to
ensure global structural relevance with rhetorical structures. We also
incorporate rhetorical structures into the topic structure through a graph
neural network model to ensure local coherence consistency. Finally, we utilize
the similarity between the two fused structures for mutual learning. The
experimental results demonstrate that our methods outperform all strong
baselines on two dialogue rhetorical datasets (STAC and Molweni), as well as
dialogue topic datasets (Doc2Dial and TIAGE).

摘要：大型語言模型 (LLM) 的進步推動了對話系統的發展。與僅滿足使用者偏好的流行 ChatGPT 類型助理模型不同，任務導向對話系統也在更廣泛的商業領域面臨新的需求和挑戰。它們預計在每個對話輪次提供正確的回應，同時達成任務定義的整體目標。透過主題分割和語篇解析了解語篇結構和主題結構，對話系統可以更好地規劃以達成這兩個目標。然而，儘管這兩個結構都屬於語言學中的語篇結構，但語篇結構和主題結構大多是分開建模，或在先前的工作中一個協助另一個。這兩個結構之間的互動尚未考慮用於聯合建模和相互學習。此外，尚未充分探討用於達成上述目標的非監督式學習技術。為了填補這個空白，我們提出了一個非監督式相互學習架構，利用它們之間的全局和局部連接。我們延伸了非相鄰語篇單位之間的主題建模，以確保與語篇結構的全局結構相關性。我們還透過圖形神經網路模型將語篇結構納入主題結構，以確保局部一致性。最後，我們利用兩個融合結構之間的相似性進行相互學習。實驗結果證明，我們的模型在兩個對話語篇資料集 (STAC 和 Molweni) 以及對話主題資料集 (Doc2Dial 和 TIAGE) 上優於所有強大的基線。

##### **SLM as Guardian: Pioneering AI Safety with Small Language Models**
2405.19795v1 by Ohjoon Kwon, Donghyeon Jeon, Nayoung Choi, Gyu-Hwung Cho, Changbong Kim, Hyunwoo Lee, Inho Kang, Sun Kim, Taiwoo Park

Most prior safety research of large language models (LLMs) has focused on
enhancing the alignment of LLMs to better suit the safety requirements of
humans. However, internalizing such safeguard features into larger models
brought challenges of higher training cost and unintended degradation of
helpfulness. To overcome such challenges, a modular approach employing a
smaller LLM to detect harmful user queries is regarded as a convenient solution
in designing LLM-based system with safety requirements.
  In this paper, we leverage a smaller LLM for both harmful query detection and
safeguard response generation. We introduce our safety requirements and the
taxonomy of harmfulness categories, and then propose a multi-task learning
mechanism fusing the two tasks into a single model. We demonstrate the
effectiveness of our approach, providing on par or surpassing harmful query
detection and safeguard response performance compared to the publicly available
LLMs.

摘要：大型語言模型 (LLM) 的大多數先前安全性研究都集中在
增強 LLM 的對齊方式，以更好地符合人類的安全性要求。
然而，將此類保護功能內化到較大的模型中帶來了更高的訓練成本和意外降低
有用的挑戰。為了克服這些挑戰，採用較小的 LLM 來檢測有害使用者查詢的模組化方法被認為是
設計具有安全性要求的基於 LLM 的系統的便捷解決方案。
在本文中，我們利用較小的 LLM 進行有害查詢檢測和保護回應生成。
我們介紹了我們的安全要求和危害類別的分類，然後提出了一種多任務學習
將這兩個任務融合到一個模型中的機制。我們展示了我們方法的有效性，提供了與公開的
LLM 相比，有害查詢檢測和保護回應性能相當或超越。

##### **PDDLEGO: Iterative Planning in Textual Environments**
2405.19793v1 by Li Zhang, Peter Jansen, Tianyi Zhang, Peter Clark, Chris Callison-Burch, Niket Tandon

Planning in textual environments have been shown to be a long-standing
challenge even for current models. A recent, promising line of work uses LLMs
to generate a formal representation of the environment that can be solved by a
symbolic planner. However, existing methods rely on a fully-observed
environment where all entity states are initially known, so a one-off
representation can be constructed, leading to a complete plan. In contrast, we
tackle partially-observed environments where there is initially no sufficient
information to plan for the end-goal. We propose PDDLEGO that iteratively
construct a planning representation that can lead to a partial plan for a given
sub-goal. By accomplishing the sub-goal, more information is acquired to
augment the representation, eventually achieving the end-goal. We show that
plans produced by few-shot PDDLEGO are 43% more efficient than generating plans
end-to-end on the Coin Collector simulation, with strong performance (98%) on
the more complex Cooking World simulation where end-to-end LLMs fail to
generate coherent plans (4%).

摘要：即使對於當前模型而言，在文字環境中進行規劃已被證明是一項長期的挑戰。最近一條有前景的工作線路使用 LLM 來生成環境的形式化表示，符號規劃器可以解決該表示。然而，現有方法依賴於完全觀察到的環境，其中所有實體狀態最初都是已知的，因此可以構造一次性表示，從而導致一個完整的計畫。相比之下，我們解決部分觀察到的環境，其中最初沒有足夠的資訊來規劃最終目標。我們提出 PDDLEGO，它反覆建構一個規劃表示，該表示可以為給定的子目標產生部分計畫。通過完成子目標，可以獲取更多資訊來擴充表示，最終實現最終目標。我們表明，在 Coin Collector 模擬中，少次 PDDLEGO 產生的計畫比端到端生成計畫的效率高出 43%，在更複雜的 Cooking World 模擬中具有強勁的效能 (98%)，而端到端 LLM 無法產生連貫的計畫 (4%)。

##### **From Symbolic Tasks to Code Generation: Diversification Yields Better Task Performers**
2405.19787v1 by Dylan Zhang, Justin Wang, Francois Charton

Instruction tuning -- tuning large language models on instruction-output
pairs -- is a promising technique for making models better adapted to the real
world. Yet, the key factors driving the model's capability to understand and
follow instructions not seen during training remain under-explored. Our
investigation begins with a series of synthetic experiments within the
theoretical framework of a Turing-complete algorithm called Markov algorithm,
which allows fine-grained control over the instruction-tuning data.
Generalization and robustness with respect to the training distribution emerge
once a diverse enough set of tasks is provided, even though very few examples
are provided for each task. We extend these initial results to a real-world
application scenario of code generation and find that a more diverse
instruction set, extending beyond code-related tasks, improves the performance
of code generation. Our observations suggest that a more diverse semantic space
for instruction-tuning sets greatly improves the model's ability to follow
instructions and perform tasks.

摘要：指令微調，即針對指令輸出對微調大型語言模型，是一種有望讓模型更適應真實世界的技術。然而，驅動模型理解和遵循訓練期間未見過之指令的能力之關鍵因素仍未被充分探討。我們的調查始於在稱為馬可夫演算法的圖靈完備演算法的理論架構內進行一系列的合成實驗，這允許對指令微調資料進行細微控制。儘管每個任務提供的範例極少，但只要提供足夠多樣化的任務組，就能在訓練分佈方面產生概括性和強健性。我們將這些初步結果延伸至程式碼生成的實際應用場景，並發現更為多樣化的指令組（擴展至與程式碼相關的任務之外）能提升程式碼生成的效能。我們的觀察結果顯示，指令微調組的語意空間越多元，就能大幅提升模型遵循指令和執行任務的能力。

##### **PixelsDB: Serverless and Natural-Language-Aided Data Analytics with Flexible Service Levels and Prices**
2405.19784v1 by Haoqiong Bian, Dongyang Geng, Haoyang Li, Anastasia Ailamaki

Serverless query processing has become increasingly popular due to its
advantages, including automated hardware and software management, high
elasticity, and pay-as-you-go pricing. For users who are not system experts,
serverless query processing greatly reduces the cost of owning a data analytic
system. However, it is still a significant challenge for non-expert users to
transform their complex and evolving data analytic needs into proper SQL
queries and select a serverless query engine that delivers satisfactory
performance and price for each type of query.
  This paper presents PixelsDB, an open-source data analytic system that allows
users who lack system or SQL expertise to explore data efficiently. It allows
users to generate and debug SQL queries using a natural language interface
powered by fine-tuned language models. The queries are then executed by a
serverless query engine that offers varying prices for different service levels
on query urgency. The service levels are natively supported by dedicated
architecture design and heterogeneous resource scheduling that can apply
cost-efficient resources to process non-urgent queries. We envision that the
combination of a serverless paradigm, a natural-language-aided interface, and
flexible service levels and prices will substantially improve the user
experience in data analysis.

摘要：無伺服器查詢處理因其優勢而日益普及，包括自動化硬體和軟體管理、高彈性以及按用量計費。對於非系統專家而言，無伺服器查詢處理大幅降低了擁有資料分析系統的成本。然而，非專家使用者將其複雜且不斷變化的資料分析需求轉換為適當的 SQL 查詢，並選擇一個無伺服器查詢引擎，以提供每種類型查詢令人滿意的效能和價格，這仍然是一項重大挑戰。
本文介紹 PixelsDB，這是一個開放原始碼資料分析系統，允許缺乏系統或 SQL 專業知識的使用者有效率地探索資料。它允許使用者使用由微調語言模型驅動的自然語言介面產生和除錯 SQL 查詢。然後，由無伺服器查詢引擎執行這些查詢，該引擎提供不同服務等級的各種價格，具備查詢緊急性。服務等級由專用架構設計和異質資源排程原生支援，可應用具成本效益的資源來處理非緊急查詢。我們預見無伺服器範例、自然語言輔助介面以及彈性服務等級和價格的結合，將大幅改善資料分析中的使用者體驗。

##### **Instruction-Guided Visual Masking**
2405.19783v1 by Jinliang Zheng, Jianxiong Li, Sijie Cheng, Yinan Zheng, Jiaming Li, Jihao Liu, Yu Liu, Jingjing Liu, Xianyuan Zhan

Instruction following is crucial in contemporary LLM. However, when extended
to multimodal setting, it often suffers from misalignment between specific
textual instruction and targeted local region of an image. To achieve more
accurate and nuanced multimodal instruction following, we introduce
Instruction-guided Visual Masking (IVM), a new versatile visual grounding model
that is compatible with diverse multimodal models, such as LMM and robot model.
By constructing visual masks for instruction-irrelevant regions, IVM-enhanced
multimodal models can effectively focus on task-relevant image regions to
better align with complex instructions. Specifically, we design a visual
masking data generation pipeline and create an IVM-Mix-1M dataset with 1
million image-instruction pairs. We further introduce a new learning technique,
Discriminator Weighted Supervised Learning (DWSL) for preferential IVM training
that prioritizes high-quality data samples. Experimental results on generic
multimodal tasks such as VQA and embodied robotic control demonstrate the
versatility of IVM, which as a plug-and-play tool, significantly boosts the
performance of diverse multimodal models, yielding new state-of-the-art results
across challenging multimodal benchmarks. Code is available at
https://github.com/2toinf/IVM.

摘要：在當代 LLM 中，指令遵循至關重要。然而，當擴展到多模態設置時，它通常會在具體文本指令和圖像的目標局部區域之間出現錯位。為了實現更準確和細微的的多模態指令遵循，我們引入了指令引導視覺遮罩 (IVM)，這是一個新的通用視覺接地模型，與多種多模態模型（例如 LMM 和機器人模型）相容。通過為與指令無關的區域構建視覺遮罩，增強 IVM 的多模態模型可以有效地關注與任務相關的圖像區域，以更好地與複雜的指令保持一致。具體來說，我們設計了一個視覺遮罩數據生成管道，並創建了一個包含 100 萬張圖像指令對的 IVM-Mix-1M 數據集。我們進一步引入了一種新的學習技術，即判別器加權監督學習 (DWSL)，用於優先考慮高質量數據樣本的 IVM 優先訓練。在通用多模態任務（例如 VQA 和具身機器人控制）上的實驗結果證明了 IVM 的多功能性，作為一種即插即用工具，它顯著提升了多種多模態模型的性能，在具有挑戰性的多模態基準測試中產生了新的最先進的結果。代碼可在 https://github.com/2toinf/IVM 上獲得。

##### **Dataflow-Guided Retrieval Augmentation for Repository-Level Code Completion**
2405.19782v1 by Wei Cheng, Yuhan Wu, Wei Hu

Recent years have witnessed the deployment of code language models (LMs) in
various code intelligence tasks such as code completion. Yet, it is challenging
for pre-trained LMs to generate correct completions in private repositories.
Previous studies retrieve cross-file context based on import relations or text
similarity, which is insufficiently relevant to completion targets. In this
paper, we propose a dataflow-guided retrieval augmentation approach, called
DraCo, for repository-level code completion. DraCo parses a private repository
into code entities and establishes their relations through an extended dataflow
analysis, forming a repo-specific context graph. Whenever triggering code
completion, DraCo precisely retrieves relevant background knowledge from the
repo-specific context graph and generates well-formed prompts to query code
LMs. Furthermore, we construct a large Python dataset, ReccEval, with more
diverse completion targets. Our experiments demonstrate the superior accuracy
and applicable efficiency of DraCo, improving code exact match by 3.43% and
identifier F1-score by 3.27% on average compared to the state-of-the-art
approach.

摘要：近年来，代码语言模型 (LM) 已被部署在各种代码智能任务中，例如代码补全。然而，对于预训练的 LM 来说，在私有存储库中生成正确的补全是一项挑战。先前的研究基于导入关系或文本相似性检索跨文件上下文，这与补全目标的相关性不足。在本文中，我们提出了一种数据流引导式检索增强方法，称为 DraCo，用于存储库级别的代码补全。DraCo 将私有存储库解析为代码实体，并通过扩展的数据流分析建立它们之间的关系，形成特定于存储库的上下文图。每当触发代码补全时，DraCo 都会从特定于存储库的上下文图中精确地检索相关的背景知识，并生成格式良好的提示来查询代码 LM。此外，我们构建了一个大型 Python 数据集 ReccEval，其中包含更多样化的补全目标。我们的实验表明了 DraCo 的卓越准确性和适用效率，与最先进的方法相比，平均提高了 3.43% 的代码完全匹配和 3.27% 的标识符 F1 分数。

##### **Enhancing Consistency and Role-Specific Knowledge Capturing by Rebuilding Fictional Character's Persona**
2405.19778v1 by Jeiyoon Park, Chanjun Park, Heuiseok Lim

With the recent introduction of Assistants API, it is expected that
document-based language models will be actively used in various domains,
especially Role-playing. However, a key challenge lies in utilizing
protagonist's persona: Assistants API often fails to achieve with its search
because the information extraction part is different each time and it often
omits important information such as protagonist's backstory or relationships.
It is hard to maintain a consistent persona simply by using the persona
document as input to the Assistants API. To address the challenge of achieving
stable persona consistency, we propose CharacterGPT, a novel persona
reconstruction framework to alleviate the shortcomings of the Assistants API.
Our method involves Character Persona Training (CPT), an effective persona
rebuilding process that updates the character persona by extracting the
character's traits from given summary of the novel for each character as if the
story in a novel progresses. In our experiments, we ask each character to take
the Big Five Inventory personality test in various settings and analyze the
results. To assess whether it can think outside the box, we let each character
generate short novels. Extensive experiments and human evaluation demonstrate
that CharacterGPT presents new possibilities for role-playing agent research.

摘要：隨著助理 API 的近期推出，預計基於文件的語言模型將廣泛應用於各種領域，特別是角色扮演。然而，一個關鍵挑戰在於利用主角的人設：助理 API 經常無法透過搜尋達成，因為資訊擷取部分每次都不同，而且經常遺漏重要的資訊，例如主角的背景故事或人際關係。僅使用人設文件作為助理 API 的輸入，很難維持一致的人設。為了解決達成穩定人設一致性的挑戰，我們提出 CharacterGPT，一種新的人設重建架構，以緩解助理 API 的缺點。我們的做法包括角色人設訓練 (CPT)，這是一個有效的人設重建程序，透過為每個角色從給定的章節摘要中擷取角色特質，更新角色人設，就像小說中的故事進展一樣。在我們的實驗中，我們要求每個角色在各種設定中進行大五人格量表人格測驗，並分析結果。為了評估它是否能跳脫框架思考，我們讓每個角色產生短篇小說。廣泛的實驗和人工評估證明，CharacterGPT 為角色扮演代理研究提供了新的可能性。

##### **Towards Unified Multi-granularity Text Detection with Interactive Attention**
2405.19765v1 by Xingyu Wan, Chengquan Zhang, Pengyuan Lyu, Sen Fan, Zihan Ni, Kun Yao, Errui Ding, Jingdong Wang

Existing OCR engines or document image analysis systems typically rely on
training separate models for text detection in varying scenarios and
granularities, leading to significant computational complexity and resource
demands. In this paper, we introduce "Detect Any Text" (DAT), an advanced
paradigm that seamlessly unifies scene text detection, layout analysis, and
document page detection into a cohesive, end-to-end model. This design enables
DAT to efficiently manage text instances at different granularities, including
*word*, *line*, *paragraph* and *page*. A pivotal innovation in DAT is the
across-granularity interactive attention module, which significantly enhances
the representation learning of text instances at varying granularities by
correlating structural information across different text queries. As a result,
it enables the model to achieve mutually beneficial detection performances
across multiple text granularities. Additionally, a prompt-based segmentation
module refines detection outcomes for texts of arbitrary curvature and complex
layouts, thereby improving DAT's accuracy and expanding its real-world
applicability. Experimental results demonstrate that DAT achieves
state-of-the-art performances across a variety of text-related benchmarks,
including multi-oriented/arbitrarily-shaped scene text detection, document
layout analysis and page detection tasks.

摘要：現有的 OCR 引擎或文件圖像分析系統通常依賴於訓練不同的模型，用於在不同的場景和粒度中進行文字偵測，導致顯著的計算複雜性和資源需求。在本文中，我們介紹「偵測任何文字」(DAT)，一種先進的典範，它無縫地將場景文字偵測、版面分析和文件頁面偵測統一到一個有凝聚力的端到端模型中。這個設計使 DAT 能夠有效地管理不同粒度的文字實例，包括 *字詞*、*行*、*段落* 和 *頁面*。DAT 中的一個關鍵創新是跨粒度互動注意力模組，它通過將不同文字查詢的結構資訊相互關聯，顯著增強了不同粒度文字實例的表徵學習。因此，它使模型能夠在多個文字粒度上實現互惠的偵測效能。此外，基於提示的分割模組改進了任意曲率和複雜版面的文字的偵測結果，從而提高了 DAT 的準確性並擴展了其在現實世界中的適用性。實驗結果表明，DAT 在各種與文字相關的基準測試中都取得了最先進的效能，包括多方向/任意形狀的場景文字偵測、文件版面分析和頁面偵測任務。

