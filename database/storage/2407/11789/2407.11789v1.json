{"2407.11789": {"publish_time": "2024-07-16", "title": "Large Language Models as Misleading Assistants in Conversation", "paper_summary": "Large Language Models (LLMs) are able to provide assistance on a wide range\nof information-seeking tasks. However, model outputs may be misleading, whether\nunintentionally or in cases of intentional deception. We investigate the\nability of LLMs to be deceptive in the context of providing assistance on a\nreading comprehension task, using LLMs as proxies for human users. We compare\noutcomes of (1) when the model is prompted to provide truthful assistance, (2)\nwhen it is prompted to be subtly misleading, and (3) when it is prompted to\nargue for an incorrect answer. Our experiments show that GPT-4 can effectively\nmislead both GPT-3.5-Turbo and GPT-4, with deceptive assistants resulting in up\nto a 23% drop in accuracy on the task compared to when a truthful assistant is\nused. We also find that providing the user model with additional context from\nthe passage partially mitigates the influence of the deceptive model. This work\nhighlights the ability of LLMs to produce misleading information and the\neffects this may have in real-world situations.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u80fd\u5920\u5728\u5404\u7a2e\u8cc7\u8a0a\u641c\u5c0b\u4efb\u52d9\u4e2d\u63d0\u4f9b\u5354\u52a9\u3002\u7136\u800c\uff0c\u6a21\u578b\u7684\u8f38\u51fa\u53ef\u80fd\u5177\u6709\u8aa4\u5c0e\u6027\uff0c\u7121\u8ad6\u662f\u7121\u610f\u7684\u6216\u662f\u6709\u610f\u6b3a\u9a19\u3002\u6211\u5011\u8abf\u67e5\u4e86 LLM \u5728\u95b1\u8b80\u7406\u89e3\u4efb\u52d9\u4e2d\u63d0\u4f9b\u5354\u52a9\u6642\u5177\u6709\u6b3a\u9a19\u6027\u7684\u80fd\u529b\uff0c\u4f7f\u7528 LLM \u4f5c\u70ba\u4eba\u985e\u4f7f\u7528\u8005\u7684\u4ee3\u7406\u3002\u6211\u5011\u6bd4\u8f03\u4e86 (1) \u7576\u6a21\u578b\u88ab\u63d0\u793a\u63d0\u4f9b\u771f\u5be6\u5354\u52a9\u3001(2) \u7576\u5b83\u88ab\u63d0\u793a\u9032\u884c\u5fae\u5999\u7684\u8aa4\u5c0e\u3001\u4ee5\u53ca (3) \u7576\u5b83\u88ab\u63d0\u793a\u70ba\u932f\u8aa4\u7b54\u6848\u8faf\u8b77\u7684\u7d50\u679c\u3002\u6211\u5011\u7684\u5be6\u9a57\u8868\u660e\uff0cGPT-4 \u53ef\u4ee5\u6709\u6548\u5730\u8aa4\u5c0e GPT-3.5-Turbo \u548c GPT-4\uff0c\u8207\u4f7f\u7528\u771f\u5be6\u52a9\u7406\u76f8\u6bd4\uff0c\u5177\u6709\u6b3a\u9a19\u6027\u7684\u52a9\u7406\u5c0e\u81f4\u4efb\u52d9\u6e96\u78ba\u5ea6\u4e0b\u964d\u591a\u9054 23%\u3002\u6211\u5011\u9084\u767c\u73fe\uff0c\u70ba\u4f7f\u7528\u8005\u6a21\u578b\u63d0\u4f9b\u4f86\u81ea\u6bb5\u843d\u7684\u984d\u5916\u80cc\u666f\uff0c\u53ef\u4ee5\u90e8\u5206\u6e1b\u8f15\u6b3a\u9a19\u6027\u6a21\u578b\u7684\u5f71\u97ff\u3002\u9019\u9805\u5de5\u4f5c\u7a81\u986f\u4e86 LLM \u7522\u751f\u8aa4\u5c0e\u6027\u8cc7\u8a0a\u7684\u80fd\u529b\uff0c\u4ee5\u53ca\u9019\u53ef\u80fd\u5728\u73fe\u5be6\u4e16\u754c\u4e2d\u7522\u751f\u7684\u5f71\u97ff\u3002", "author": "Betty Li Hou et.al.", "authors": "Betty Li Hou, Kejian Shi, Jason Phang, James Aung, Steven Adler, Rosie Campbell", "id": "2407.11789v1", "paper_url": "http://arxiv.org/abs/2407.11789v1", "repo": "null"}}