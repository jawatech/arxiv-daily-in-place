{"2411.02318": {"publish_time": "2024-11-04", "title": "Evaluating the Ability of Large Language Models to Generate Verifiable Specifications in VeriFast", "paper_summary": "Static verification is a powerful method for enhancing software quality, but\nit demands significant human labor and resources. This is particularly true of\nstatic verifiers that reason about heap manipulating programs using an\nownership logic. LLMs have shown promise in a number of software engineering\nactivities, including code generation, test generation, proof generation for\ntheorem provers, and specification generation for static verifiers. However,\nprior work has not explored how well LLMs can perform specification generation\nfor specifications based in an ownership logic, such as separation logic.\n  To address this gap, this paper explores the effectiveness of large language\nmodels (LLMs), specifically OpenAI's GPT models, in generating fully correct\nspecifications based on separation logic for static verification of\nhuman-written programs in VeriFast. Our first experiment employed traditional\nprompt engineering and the second used Chain-of-Thought (CoT) Prompting to\nidentify and address common errors generated across the GPT models. The results\nindicate that GPT models can successfully generate specifications for verifying\nheap manipulating code with VeriFast. Furthermore, while CoT prompting\nsignificantly reduces syntax errors generated by the GPT models, it does not\ngreatly improve verification error rates compared to prompt engineering.", "paper_summary_zh": "\u975c\u614b\u9a57\u8b49\u662f\u589e\u5f37\u8edf\u9ad4\u54c1\u8cea\u7684\u5f37\u5927\u65b9\u6cd5\uff0c\u4f46\u5b83\u9700\u8981\u5927\u91cf\u7684\u4eba\u529b\u8207\u8cc7\u6e90\u3002\u9019\u7279\u5225\u9069\u7528\u65bc\u4f7f\u7528\u6240\u6709\u6b0a\u908f\u8f2f\u4f86\u63a8\u8ad6\u5806\u64cd\u4f5c\u7a0b\u5f0f\u7684\u975c\u614b\u9a57\u8b49\u5668\u3002LLM \u5df2\u5728\u8a31\u591a\u8edf\u9ad4\u5de5\u7a0b\u6d3b\u52d5\u4e2d\u5c55\u73fe\u51fa\u6f5b\u529b\uff0c\u5305\u62ec\u7a0b\u5f0f\u78bc\u7522\u751f\u3001\u6e2c\u8a66\u7522\u751f\u3001\u5b9a\u7406\u8b49\u660e\u5668\u7684\u8b49\u660e\u7522\u751f\uff0c\u4ee5\u53ca\u975c\u614b\u9a57\u8b49\u5668\u7684\u898f\u683c\u7522\u751f\u3002\u7136\u800c\uff0c\u5148\u524d\u7684\u5de5\u4f5c\u4e26\u672a\u63a2\u8a0e LLM \u5728\u57f7\u884c\u57fa\u65bc\u6240\u6709\u6b0a\u908f\u8f2f\uff08\u4f8b\u5982\u5206\u96e2\u908f\u8f2f\uff09\u7684\u898f\u683c\u7522\u751f\u65b9\u9762\u7684\u8868\u73fe\u5982\u4f55\u3002\u70ba\u4e86\u89e3\u6c7a\u9019\u500b\u5dee\u8ddd\uff0c\u672c\u6587\u63a2\u8a0e\u4e86\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM)\uff08\u7279\u5225\u662f OpenAI \u7684 GPT \u6a21\u578b\uff09\u5728\u70ba VeriFast \u4e2d\u7684\u4eba\u5de5\u64b0\u5beb\u7a0b\u5f0f\u7522\u751f\u5b8c\u5168\u6b63\u78ba\u7684\u57fa\u65bc\u5206\u96e2\u908f\u8f2f\u7684\u898f\u683c\u65b9\u9762\u7684\u6709\u6548\u6027\u3002\u6211\u5011\u7684\u7b2c\u4e00\u6b21\u5be6\u9a57\u63a1\u7528\u50b3\u7d71\u7684\u63d0\u793a\u5de5\u7a0b\uff0c\u800c\u7b2c\u4e8c\u6b21\u5be6\u9a57\u5247\u4f7f\u7528\u601d\u8003\u93c8 (CoT) \u63d0\u793a\u4f86\u8b58\u5225\u548c\u89e3\u6c7a GPT \u6a21\u578b\u4e2d\u7522\u751f\u7684\u5e38\u898b\u932f\u8aa4\u3002\u7d50\u679c\u8868\u660e\uff0cGPT \u6a21\u578b\u53ef\u4ee5\u6210\u529f\u7522\u751f\u898f\u683c\u4f86\u9a57\u8b49\u4f7f\u7528 VeriFast \u7684\u5806\u64cd\u4f5c\u7a0b\u5f0f\u78bc\u3002\u6b64\u5916\uff0c\u5118\u7ba1 CoT \u63d0\u793a\u986f\u8457\u6e1b\u5c11\u4e86 GPT \u6a21\u578b\u7522\u751f\u7684\u8a9e\u6cd5\u932f\u8aa4\uff0c\u4f46\u8207\u63d0\u793a\u5de5\u7a0b\u76f8\u6bd4\uff0c\u5b83\u4e26\u672a\u5927\u5e45\u6539\u5584\u9a57\u8b49\u932f\u8aa4\u7387\u3002", "author": "Marilyn Rego et.al.", "authors": "Marilyn Rego, Wen Fan, Xin Hu, Sanya Dod, Zhaorui Ni, Danning Xie, Jenna DiVincenzo, Lin Tan", "id": "2411.02318v1", "paper_url": "http://arxiv.org/abs/2411.02318v1", "repo": "null"}}