{"2411.04358": {"publish_time": "2024-11-07", "title": "Robust and Efficient Fine-tuning of LLMs with Bayesian Reparameterization of Low-Rank Adaptation", "paper_summary": "Large Language Models (LLMs) are highly resource-intensive to fine-tune due\nto their enormous size. While low-rank adaptation is a prominent\nparameter-efficient fine-tuning approach, it suffers from sensitivity to\nhyperparameter choices, leading to instability in model performance on\nfine-tuning downstream tasks. This paper highlights the importance of effective\nparameterization in low-rank fine-tuning to reduce estimator variance and\nenhance the stability of final model outputs. We propose MonteCLoRA, an\nefficient fine-tuning technique, employing Monte Carlo estimation to learn an\nunbiased posterior estimation of low-rank parameters with low expected\nvariance, which stabilizes fine-tuned LLMs with only O(1) additional\nparameters. MonteCLoRA shows significant improvements in accuracy and\nrobustness, achieving up to 3.8% higher accuracy and 8.6% greater robustness\nthan existing efficient fine-tuning methods on natural language understanding\ntasks with pre-trained RoBERTa-base. Furthermore, in generative tasks with\npre-trained LLaMA-1-7B, MonteCLoRA demonstrates robust zero-shot performance\nwith 50% lower variance than the contemporary efficient fine-tuning methods.\nThe theoretical and empirical results presented in the paper underscore how\nparameterization and hyperpriors balance exploration-exploitation in the\nlow-rank parametric space, therefore leading to more optimal and robust\nparameter estimation during efficient fine-tuning.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u56e0\u5176\u9f90\u5927\u898f\u6a21\u800c\u9700\u8981\u5927\u91cf\u8cc7\u6e90\u9032\u884c\u5fae\u8abf\u3002\u5118\u7ba1\u4f4e\u79e9\u9069\u61c9\u662f\u4e00\u7a2e\u7a81\u51fa\u7684\u53c3\u6578\u9ad8\u6548\u5fae\u8abf\u65b9\u6cd5\uff0c\u4f46\u5b83\u5c0d\u8d85\u53c3\u6578\u9078\u64c7\u5f88\u654f\u611f\uff0c\u5c0e\u81f4\u6a21\u578b\u5728\u5fae\u8abf\u4e0b\u6e38\u4efb\u52d9\u6642\u7684\u6548\u80fd\u4e0d\u7a69\u5b9a\u3002\u672c\u6587\u5f37\u8abf\u4e86\u5728\u4f4e\u79e9\u5fae\u8abf\u4e2d\u6709\u6548\u53c3\u6578\u5316\u7684\u91cd\u8981\u6027\uff0c\u4ee5\u6e1b\u5c11\u4f30\u8a08\u5668\u8b8a\u7570\u4e26\u589e\u5f37\u6700\u7d42\u6a21\u578b\u8f38\u51fa\u7684\u7a69\u5b9a\u6027\u3002\u6211\u5011\u63d0\u51fa\u4e86 MonteCLoRA\uff0c\u4e00\u7a2e\u9ad8\u6548\u7684\u5fae\u8abf\u6280\u8853\uff0c\u63a1\u7528\u8499\u5730\u5361\u7f85\u4f30\u8a08\u4f86\u5b78\u7fd2\u4f4e\u79e9\u53c3\u6578\u7684\u7121\u504f\u5f8c\u9a57\u4f30\u8a08\uff0c\u4e14\u9810\u671f\u8b8a\u7570\u4f4e\uff0c\u9019\u53ef\u4ee5\u7a69\u5b9a\u5fae\u8abf\u5f8c\u7684 LLM\uff0c\u800c\u984d\u5916\u53c3\u6578\u50c5\u70ba O(1)\u3002MonteCLoRA \u5728\u6e96\u78ba\u6027\u548c\u7a69\u5065\u6027\u65b9\u9762\u986f\u793a\u51fa\u986f\u8457\u7684\u6539\u9032\uff0c\u5728\u4f7f\u7528\u9810\u8a13\u7df4 RoBERTa-base \u7684\u81ea\u7136\u8a9e\u8a00\u7406\u89e3\u4efb\u52d9\u4e2d\uff0c\u6e96\u78ba\u5ea6\u63d0\u9ad8\u4e86 3.8%\uff0c\u7a69\u5065\u6027\u63d0\u9ad8\u4e86 8.6%\u3002\u6b64\u5916\uff0c\u5728\u4f7f\u7528\u9810\u8a13\u7df4 LLaMA-1-7B \u7684\u751f\u6210\u4efb\u52d9\u4e2d\uff0cMonteCLoRA \u8868\u73fe\u51fa\u7a69\u5065\u7684\u96f6\u6b21\u5b78\u7fd2\u6548\u80fd\uff0c\u8b8a\u7570\u6bd4\u73fe\u6709\u7684\u9ad8\u6548\u5fae\u8abf\u65b9\u6cd5\u4f4e 50%\u3002\u672c\u6587\u63d0\u51fa\u7684\u7406\u8ad6\u548c\u5be6\u8b49\u7d50\u679c\u5f37\u8abf\u4e86\u53c3\u6578\u5316\u548c\u8d85\u5148\u9a57\u5982\u4f55\u5728\u4f4e\u79e9\u53c3\u6578\u7a7a\u9593\u4e2d\u5e73\u8861\u63a2\u7d22\u8207\u958b\u767c\uff0c\u5f9e\u800c\u5c0e\u81f4\u5728\u9ad8\u6548\u5fae\u8abf\u671f\u9593\u9032\u884c\u66f4\u4f73\u4e14\u7a69\u5065\u7684\u53c3\u6578\u4f30\u8a08\u3002", "author": "Vaibhav Seth et.al.", "authors": "Vaibhav Seth, Arinjay Pathak, Ayan Sengupta, Natraj Raman, Sriram Gopalakrishnan, Tanmoy Chakraborty", "id": "2411.04358v1", "paper_url": "http://arxiv.org/abs/2411.04358v1", "repo": "https://github.com/lcs2-iiitd/monteclora"}}