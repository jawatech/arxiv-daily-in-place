{"2409.05806": {"publish_time": "2024-09-09", "title": "Benchmarking Chinese Knowledge Rectification in Large Language Models", "paper_summary": "While Large Language Models (LLMs) exhibit remarkable generative\ncapabilities, they are not without flaws, particularly in the form of\nhallucinations. This issue is even more pronounced when LLMs are applied to\nspecific languages and domains. For example, LLMs may generate nonsense\ninformation when handling Chinese ancient poetry, proverbs, or idioms, owing to\nthe lack of specific knowledge. To this end, this paper introduces a benchmark\nfor rectifying Chinese knowledge in LLMs via knowledge editing. Specifically,\nwe introduce a new Chinese dataset, CKnowEdit, by collecting seven type of\nknowledge from various sources, including classical texts, idioms, and content\nfrom Baidu Tieba Ruozhiba, thereby accounting for the unique polyphony,\nantithesis, and logical constructs inherent in the Chinese language. Through\nthe analysis of this dataset, we uncover the challenges faced by current LLMs\nin mastering Chinese. Furthermore, our evaluation of state-of-the-art knowledge\nediting techniques on this dataset unveil the substantial scope for advancement\nin the rectification of Chinese knowledge. Code and dataset are available at\nhttps://github.com/zjunlp/EasyEdit.", "paper_summary_zh": "\u5927\u578b\u8bed\u8a00\u6a21\u578b (LLM) \u867d\u7136\u8868\u73b0\u51fa\u975e\u51e1\u7684\u751f\u6210\u80fd\u529b\uff0c\u4f46\u4e5f\u5e76\u975e\u6ca1\u6709\u7f3a\u9677\uff0c\u7279\u522b\u662f\u5e7b\u89c9\u5f62\u5f0f\u7684\u7f3a\u9677\u3002\u5f53 LLM \u5e94\u7528\u4e8e\u7279\u5b9a\u8bed\u8a00\u548c\u9886\u57df\u65f6\uff0c\u8fd9\u4e2a\u95ee\u9898\u66f4\u4e3a\u660e\u663e\u3002\u4f8b\u5982\uff0c\u7531\u4e8e\u7f3a\u4e4f\u7279\u5b9a\u77e5\u8bc6\uff0cLLM \u5728\u5904\u7406\u4e2d\u56fd\u53e4\u4ee3\u8bd7\u6b4c\u3001\u8c1a\u8bed\u6216\u6210\u8bed\u65f6\u53ef\u80fd\u4f1a\u4ea7\u751f\u65e0\u610f\u4e49\u7684\u4fe1\u606f\u3002\u4e3a\u6b64\uff0c\u672c\u6587\u901a\u8fc7\u77e5\u8bc6\u7f16\u8f91\u5f15\u5165\u4e86\u4e00\u4e2a\u7528\u4e8e\u7ea0\u6b63 LLM \u4e2d\u4e2d\u6587\u77e5\u8bc6\u7684\u57fa\u51c6\u3002\u5177\u4f53\u6765\u8bf4\uff0c\u6211\u4eec\u901a\u8fc7\u4ece\u5404\u79cd\u6765\u6e90\uff08\u5305\u62ec\u7ecf\u5178\u6587\u672c\u3001\u6210\u8bed\u548c\u767e\u5ea6\u8d34\u5427\u82e5\u77e5\u516b\u7684\u7684\u5185\u5bb9\uff09\u6536\u96c6\u4e03\u79cd\u7c7b\u578b\u7684\u77e5\u8bc6\uff0c\u5f15\u5165\u4e86\u65b0\u7684\u4e2d\u6587\u6570\u636e\u96c6 CKnowEdit\uff0c\u4ece\u800c\u89e3\u91ca\u4e86\u4e2d\u6587\u8bed\u8a00\u4e2d\u56fa\u6709\u7684\u72ec\u7279\u591a\u97f3\u3001\u5bf9\u7acb\u548c\u903b\u8f91\u7ed3\u6784\u3002\u901a\u8fc7\u5bf9\u8be5\u6570\u636e\u96c6\u7684\u5206\u6790\uff0c\u6211\u4eec\u53d1\u73b0\u4e86\u5f53\u524d LLM \u5728\u638c\u63e1\u4e2d\u6587\u65f6\u9762\u4e34\u7684\u6311\u6218\u3002\u6b64\u5916\uff0c\u6211\u4eec\u5bf9\u8be5\u6570\u636e\u96c6\u4e0a\u6700\u5148\u8fdb\u7684\u77e5\u8bc6\u7f16\u8f91\u6280\u672f\u7684\u8bc4\u4f30\u63ed\u793a\u4e86\u7ea0\u6b63\u4e2d\u6587\u77e5\u8bc6\u7684\u5de8\u5927\u8fdb\u6b65\u7a7a\u95f4\u3002\u4ee3\u7801\u548c\u6570\u636e\u96c6\u53ef\u5728 https://github.com/zjunlp/EasyEdit \u83b7\u5f97\u3002", "author": "Tianhe Lu et.al.", "authors": "Tianhe Lu, Jizhan Fang, Yunzhi Yao, Xin Xu, Ningyu Zhang, Huajun Chen", "id": "2409.05806v1", "paper_url": "http://arxiv.org/abs/2409.05806v1", "repo": "https://github.com/zjunlp/easyedit"}}