{"2502.03465": {"publish_time": "2025-02-05", "title": "Seeing World Dynamics in a Nutshell", "paper_summary": "We consider the problem of efficiently representing casually captured\nmonocular videos in a spatially- and temporally-coherent manner. While existing\napproaches predominantly rely on 2D/2.5D techniques treating videos as\ncollections of spatiotemporal pixels, they struggle with complex motions,\nocclusions, and geometric consistency due to absence of temporal coherence and\nexplicit 3D structure. Drawing inspiration from monocular video as a projection\nof the dynamic 3D world, we explore representing videos in their intrinsic 3D\nform through continuous flows of Gaussian primitives in space-time. In this\npaper, we propose NutWorld, a novel framework that efficiently transforms\nmonocular videos into dynamic 3D Gaussian representations in a single forward\npass. At its core, NutWorld introduces a structured spatial-temporal aligned\nGaussian (STAG) representation, enabling optimization-free scene modeling with\neffective depth and flow regularization. Through comprehensive experiments, we\ndemonstrate that NutWorld achieves high-fidelity video reconstruction quality\nwhile enabling various downstream applications in real-time. Demos and code\nwill be available at https://github.com/Nut-World/NutWorld.", "paper_summary_zh": "<paragraph>\u6211\u4eec\u8003\u8651\u4ee5\u7a7a\u95f4\u548c\u65f6\u95f4\u4e00\u81f4\u7684\u65b9\u5f0f\u6709\u6548\u8868\u793a\u968f\u610f\u6355\u6349\u7684\u5355\u773c\u89c6\u9891\u7684\u95ee\u9898\u3002\u867d\u7136\u73b0\u6709\u65b9\u6cd5\u4e3b\u8981\u4f9d\u8d56\u4e8e\u5c06\u89c6\u9891\u89c6\u4e3a\u65f6\u7a7a\u50cf\u7d20\u96c6\u5408\u7684 2D/2.5D \u6280\u672f\uff0c\u4f46\u7531\u4e8e\u7f3a\u4e4f\u65f6\u95f4\u4e00\u81f4\u6027\u548c\u663e\u5f0f 3D \u7ed3\u6784\uff0c\u5b83\u4eec\u96be\u4ee5\u5904\u7406\u590d\u6742\u8fd0\u52a8\u3001\u906e\u6321\u548c\u51e0\u4f55\u4e00\u81f4\u6027\u3002\u4ece\u5355\u773c\u89c6\u9891\u4f5c\u4e3a\u52a8\u6001 3D \u4e16\u754c\u6295\u5f71\u4e2d\u6c72\u53d6\u7075\u611f\uff0c\u6211\u4eec\u63a2\u7d22\u901a\u8fc7\u65f6\u7a7a\u4e2d\u7684\u9ad8\u65af\u57fa\u5143\u7684\u8fde\u7eed\u6d41\u4ee5\u5176\u5185\u5728 3D \u5f62\u5f0f\u8868\u793a\u89c6\u9891\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u4eec\u63d0\u51fa\u4e86 NutWorld\uff0c\u8fd9\u662f\u4e00\u4e2a\u65b0\u9896\u7684\u6846\u67b6\uff0c\u53ef\u4ee5\u6709\u6548\u5730\u5c06\u5355\u773c\u89c6\u9891\u8f6c\u6362\u4e3a\u52a8\u6001 3D \u9ad8\u65af\u8868\u793a\uff0c\u53ea\u9700\u4e00\u6b21\u6b63\u5411\u4f20\u9012\u3002\u4ece\u672c\u8d28\u4e0a\u8bb2\uff0cNutWorld \u5f15\u5165\u4e86\u7ed3\u6784\u5316\u7684\u65f6\u7a7a\u5bf9\u9f50\u9ad8\u65af (STAG) \u8868\u793a\uff0c\u901a\u8fc7\u6709\u6548\u7684\u6df1\u5ea6\u548c\u6d41\u6b63\u5219\u5316\u5b9e\u73b0\u65e0\u4f18\u5316\u573a\u666f\u5efa\u6a21\u3002\u901a\u8fc7\u5168\u9762\u7684\u5b9e\u9a8c\uff0c\u6211\u4eec\u8bc1\u660e NutWorld \u5b9e\u73b0\u4e86\u9ad8\u4fdd\u771f\u89c6\u9891\u91cd\u5efa\u8d28\u91cf\uff0c\u540c\u65f6\u652f\u6301\u5404\u79cd\u4e0b\u6e38\u5e94\u7528\u7a0b\u5e8f\u5b9e\u65f6\u8fd0\u884c\u3002\u6f14\u793a\u548c\u4ee3\u7801\u5c06\u5728 https://github.com/Nut-World/NutWorld \u4e0a\u63d0\u4f9b\u3002</paragraph>", "author": "Qiuhong Shen et.al.", "authors": "Qiuhong Shen, Xuanyu Yi, Mingbao Lin, Hanwang Zhang, Shuicheng Yan, Xinchao Wang", "id": "2502.03465v1", "paper_url": "http://arxiv.org/abs/2502.03465v1", "repo": "null"}}