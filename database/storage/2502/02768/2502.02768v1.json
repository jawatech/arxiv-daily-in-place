{"2502.02768": {"publish_time": "2025-02-04", "title": "Planning with affordances: Integrating learned affordance models and symbolic planning", "paper_summary": "Intelligent agents working in real-world environments must be able to learn\nabout the environment and its capabilities which enable them to take actions to\nchange to the state of the world to complete a complex multi-step task in a\nphotorealistic environment. Learning about the environment is especially\nimportant to perform various multiple-step tasks without having to redefine an\nagent's action set for different tasks or environment settings. In our work, we\naugment an existing task and motion planning framework with learned affordance\nmodels of objects in the world to enable planning and executing multi-step\ntasks using learned models. Each task can be seen as changing the current state\nof the world to a given goal state. The affordance models provide us with what\nactions are possible and how to perform those actions in any given state. A\nsymbolic planning algorithm uses this information and the starting and goal\nstate to create a feasible plan to reach the desired goal state to complete a\ngiven task. We demonstrate our approach in a virtual 3D photorealistic\nenvironment, AI2-Thor, and evaluate it on real-world tasks. Our results show\nthat our agent quickly learns how to interact with the environment and is well\nprepared to perform tasks such as \"Moving an object out of the way to reach the\ndesired location.\"", "paper_summary_zh": "\u5728\u73b0\u5b9e\u4e16\u754c\u73af\u5883\u4e2d\u5de5\u4f5c\u7684\u667a\u80fd\u4ee3\u7406\u5fc5\u987b\u80fd\u591f\u5b66\u4e60\u73af\u5883\u53ca\u5176\u80fd\u529b\uff0c\u4f7f\u5b83\u4eec\u80fd\u591f\u91c7\u53d6\u884c\u52a8\u6765\u6539\u53d8\u4e16\u754c\u72b6\u6001\uff0c\u4ee5\u4fbf\u5728\u903c\u771f\u7684\u73af\u5883\u4e2d\u5b8c\u6210\u590d\u6742\u7684\u591a\u6b65\u9aa4\u4efb\u52a1\u3002\u4e86\u89e3\u73af\u5883\u5bf9\u4e8e\u6267\u884c\u5404\u79cd\u591a\u6b65\u9aa4\u4efb\u52a1\u5c24\u5176\u91cd\u8981\uff0c\u800c\u65e0\u9700\u4e3a\u4e0d\u540c\u7684\u4efb\u52a1\u6216\u73af\u5883\u8bbe\u7f6e\u91cd\u65b0\u5b9a\u4e49\u4ee3\u7406\u7684\u52a8\u4f5c\u96c6\u3002\u5728\u6211\u4eec\u7684\u5de5\u4f5c\u4e2d\uff0c\u6211\u4eec\u4f7f\u7528\u4e16\u754c\u4e2d\u5bf9\u8c61\u7684\u5b66\u4e60\u80fd\u529b\u6a21\u578b\u6765\u589e\u5f3a\u73b0\u6709\u7684\u4efb\u52a1\u548c\u8fd0\u52a8\u89c4\u5212\u6846\u67b6\uff0c\u4ee5\u4f7f\u7528\u5b66\u4e60\u6a21\u578b\u6765\u89c4\u5212\u548c\u6267\u884c\u591a\u6b65\u9aa4\u4efb\u52a1\u3002\u6bcf\u4e2a\u4efb\u52a1\u90fd\u53ef\u4ee5\u770b\u4f5c\u662f\u5c06\u5f53\u524d\u4e16\u754c\u72b6\u6001\u66f4\u6539\u4e3a\u7ed9\u5b9a\u7684\u76ee\u6807\u72b6\u6001\u3002\u80fd\u529b\u6a21\u578b\u4e3a\u6211\u4eec\u63d0\u4f9b\u4e86\u5728\u4efb\u4f55\u7ed9\u5b9a\u72b6\u6001\u4e0b\u53ef\u80fd\u91c7\u53d6\u54ea\u4e9b\u52a8\u4f5c\u4ee5\u53ca\u5982\u4f55\u6267\u884c\u8fd9\u4e9b\u52a8\u4f5c\u3002\u7b26\u53f7\u89c4\u5212\u7b97\u6cd5\u4f7f\u7528\u6b64\u4fe1\u606f\u4ee5\u53ca\u5f00\u59cb\u548c\u76ee\u6807\u72b6\u6001\u6765\u521b\u5efa\u53ef\u884c\u7684\u8ba1\u5212\uff0c\u4ee5\u8fbe\u5230\u6240\u9700\u7684\u6700\u7ec8\u72b6\u6001\u4ee5\u5b8c\u6210\u7ed9\u5b9a\u7684\u4efb\u52a1\u3002\u6211\u4eec\u5728\u865a\u62df 3D \u903c\u771f\u73af\u5883 AI2-Thor \u4e2d\u6f14\u793a\u4e86\u6211\u4eec\u7684\u65b9\u6cd5\uff0c\u5e76\u5bf9\u73b0\u5b9e\u4e16\u754c\u4efb\u52a1\u8fdb\u884c\u4e86\u8bc4\u4f30\u3002\u6211\u4eec\u7684\u7ed3\u679c\u8868\u660e\uff0c\u6211\u4eec\u7684\u4ee3\u7406\u53ef\u4ee5\u5feb\u901f\u5b66\u4f1a\u5982\u4f55\u4e0e\u73af\u5883\u4ea4\u4e92\uff0c\u5e76\u4e14\u5df2\u7ecf\u4e3a\u6267\u884c\u8bf8\u5982\u201c\u5c06\u7269\u4f53\u79fb\u5f00\u4ee5\u5230\u8fbe\u6240\u9700\u4f4d\u7f6e\u201d\u4e4b\u7c7b\u7684\u4efb\u52a1\u505a\u597d\u4e86\u5145\u5206\u7684\u51c6\u5907\u3002", "author": "Rajesh Mangannavar et.al.", "authors": "Rajesh Mangannavar", "id": "2502.02768v1", "paper_url": "http://arxiv.org/abs/2502.02768v1", "repo": "null"}}