{"2409.02555": {"publish_time": "2024-09-04", "title": "Low-Resolution Object Recognition with Cross-Resolution Relational Contrastive Distillation", "paper_summary": "Recognizing objects in low-resolution images is a challenging task due to the\nlack of informative details. Recent studies have shown that knowledge\ndistillation approaches can effectively transfer knowledge from a\nhigh-resolution teacher model to a low-resolution student model by aligning\ncross-resolution representations. However, these approaches still face\nlimitations in adapting to the situation where the recognized objects exhibit\nsignificant representation discrepancies between training and testing images.\nIn this study, we propose a cross-resolution relational contrastive\ndistillation approach to facilitate low-resolution object recognition. Our\napproach enables the student model to mimic the behavior of a well-trained\nteacher model which delivers high accuracy in identifying high-resolution\nobjects. To extract sufficient knowledge, the student learning is supervised\nwith contrastive relational distillation loss, which preserves the similarities\nin various relational structures in contrastive representation space. In this\nmanner, the capability of recovering missing details of familiar low-resolution\nobjects can be effectively enhanced, leading to a better knowledge transfer.\nExtensive experiments on low-resolution object classification and\nlow-resolution face recognition clearly demonstrate the effectiveness and\nadaptability of our approach.", "paper_summary_zh": "\u8fa8\u8b58\u4f4e\u89e3\u6790\u5ea6\u5f71\u50cf\u4e2d\u7684\u7269\u9ad4\u662f\u4e00\u9805\u5177\u6709\u6311\u6230\u6027\u7684\u4efb\u52d9\uff0c\u539f\u56e0\u5728\u65bc\u7f3a\u4e4f\u6709\u610f\u7fa9\u7684\u7d30\u7bc0\u3002\u6700\u8fd1\u7684\u7814\u7a76\u986f\u793a\uff0c\u77e5\u8b58\u84b8\u993e\u65b9\u6cd5\u53ef\u4ee5\u900f\u904e\u6bd4\u5c0d\u8de8\u89e3\u6790\u5ea6\u8868\u5fb5\uff0c\u6709\u6548\u5730\u5c07\u77e5\u8b58\u5f9e\u9ad8\u89e3\u6790\u5ea6\u6559\u5e2b\u6a21\u578b\u8f49\u79fb\u5230\u4f4e\u89e3\u6790\u5ea6\u5b78\u751f\u6a21\u578b\u3002\u7136\u800c\uff0c\u9019\u4e9b\u65b9\u6cd5\u5728\u9069\u61c9\u8fa8\u8b58\u7269\u9ad4\u5728\u8a13\u7df4\u548c\u6e2c\u8a66\u5f71\u50cf\u4e4b\u9593\u5c55\u73fe\u986f\u8457\u8868\u5fb5\u5dee\u7570\u7684\u60c5\u6cc1\u6642\uff0c\u4ecd\u7136\u9762\u81e8\u9650\u5236\u3002\u5728\u672c\u7814\u7a76\u4e2d\uff0c\u6211\u5011\u63d0\u51fa\u4e00\u500b\u8de8\u89e3\u6790\u5ea6\u95dc\u4fc2\u5c0d\u6bd4\u84b8\u993e\u65b9\u6cd5\uff0c\u4ee5\u4fc3\u9032\u4f4e\u89e3\u6790\u5ea6\u7269\u9ad4\u8fa8\u8b58\u3002\u6211\u5011\u7684\u505a\u6cd5\u8b93\u5b78\u751f\u6a21\u578b\u80fd\u5920\u6a21\u4eff\u8a13\u7df4\u826f\u597d\u7684\u6559\u5e2b\u6a21\u578b\u7684\u884c\u70ba\uff0c\u8a72\u6a21\u578b\u5728\u8fa8\u8b58\u9ad8\u89e3\u6790\u5ea6\u7269\u9ad4\u6642\u80fd\u63d0\u4f9b\u9ad8\u6e96\u78ba\u5ea6\u3002\u70ba\u4e86\u8403\u53d6\u8db3\u5920\u7684\u77e5\u8b58\uff0c\u5b78\u751f\u5b78\u7fd2\u53d7\u5230\u5c0d\u6bd4\u95dc\u4fc2\u84b8\u993e\u640d\u5931\u7684\u76e3\u7763\uff0c\u9019\u4fdd\u7559\u4e86\u5c0d\u6bd4\u8868\u5fb5\u7a7a\u9593\u4e2d\u5404\u7a2e\u95dc\u4fc2\u7d50\u69cb\u4e2d\u7684\u76f8\u4f3c\u6027\u3002\u900f\u904e\u9019\u7a2e\u65b9\u5f0f\uff0c\u53ef\u4ee5\u6709\u6548\u5730\u589e\u5f37\u6062\u5fa9\u719f\u6089\u4f4e\u89e3\u6790\u5ea6\u7269\u9ad4\u907a\u5931\u7d30\u7bc0\u7684\u80fd\u529b\uff0c\u9032\u800c\u9054\u5230\u66f4\u597d\u7684\u77e5\u8b58\u8f49\u79fb\u3002\u5728\u4f4e\u89e3\u6790\u5ea6\u7269\u9ad4\u5206\u985e\u548c\u4f4e\u89e3\u6790\u5ea6\u4eba\u81c9\u8fa8\u8b58\u4e0a\u7684\u5ee3\u6cdb\u5be6\u9a57\u6e05\u695a\u5730\u8b49\u660e\u4e86\u6211\u5011\u65b9\u6cd5\u7684\u6709\u6548\u6027\u548c\u9069\u61c9\u6027\u3002", "author": "Kangkai Zhang et.al.", "authors": "Kangkai Zhang, Shiming Ge, Ruixin Shi, Dan Zeng", "id": "2409.02555v1", "paper_url": "http://arxiv.org/abs/2409.02555v1", "repo": "null"}}