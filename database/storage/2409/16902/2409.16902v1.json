{"2409.16902": {"publish_time": "2024-09-25", "title": "Towards Underwater Camouflaged Object Tracking: An Experimental Evaluation of SAM and SAM 2", "paper_summary": "Over the past decade, significant progress has been made in visual object\ntracking, largely due to the availability of large-scale training datasets.\nHowever, existing tracking datasets are primarily focused on open-air\nscenarios, which greatly limits the development of object tracking in\nunderwater environments. To address this issue, we take a step forward by\nproposing the first large-scale underwater camouflaged object tracking dataset,\nnamely UW-COT. Based on the proposed dataset, this paper presents an\nexperimental evaluation of several advanced visual object tracking methods and\nthe latest advancements in image and video segmentation. Specifically, we\ncompare the performance of the Segment Anything Model (SAM) and its updated\nversion, SAM 2, in challenging underwater environments. Our findings highlight\nthe improvements in SAM 2 over SAM, demonstrating its enhanced capability to\nhandle the complexities of underwater camouflaged objects. Compared to current\nadvanced visual object tracking methods, the latest video segmentation\nfoundation model SAM 2 also exhibits significant advantages, providing valuable\ninsights into the development of more effective tracking technologies for\nunderwater scenarios. The dataset will be accessible at\n\\color{magenta}{https://github.com/983632847/Awesome-Multimodal-Object-Tracking}.", "paper_summary_zh": "\u5728\u904e\u53bb\u5341\u5e74\u4e2d\uff0c\u8996\u89ba\u7269\u9ad4\u8ffd\u8e64\u53d6\u5f97\u4e86\u91cd\u5927\u7684\u9032\u5c55\uff0c\u9019\u5728\u5f88\u5927\u7a0b\u5ea6\u4e0a\u8981\u6b78\u529f\u65bc\u5927\u898f\u6a21\u8a13\u7df4\u8cc7\u6599\u96c6\u7684\u53ef\u7528\u6027\u3002\n\u7136\u800c\uff0c\u73fe\u6709\u7684\u8ffd\u8e64\u8cc7\u6599\u96c6\u4e3b\u8981\u96c6\u4e2d\u5728\u9732\u5929\u5834\u666f\uff0c\u9019\u6975\u5927\u5730\u9650\u5236\u4e86\u6c34\u4e0b\u74b0\u5883\u4e2d\u7269\u9ad4\u8ffd\u8e64\u7684\u767c\u5c55\u3002\u70ba\u4e86\u89e3\u6c7a\u9019\u500b\u554f\u984c\uff0c\u6211\u5011\u63d0\u51fa\u7b2c\u4e00\u500b\u5927\u898f\u6a21\u6c34\u4e0b\u507d\u88dd\u7269\u9ad4\u8ffd\u8e64\u8cc7\u6599\u96c6 UW-COT\uff0c\u5411\u524d\u9081\u51fa\u4e86\u4e00\u6b65\u3002\u57fa\u65bc\u6240\u63d0\u51fa\u7684\u8cc7\u6599\u96c6\uff0c\u672c\u6587\u5c0d\u5e7e\u7a2e\u5148\u9032\u7684\u8996\u89ba\u7269\u9ad4\u8ffd\u8e64\u65b9\u6cd5\u548c\u5f71\u50cf\u548c\u5f71\u7247\u5206\u5272\u7684\u6700\u65b0\u9032\u5c55\u9032\u884c\u4e86\u5be6\u9a57\u8a55\u4f30\u3002\u5177\u9ad4\u4f86\u8aaa\uff0c\u6211\u5011\u6bd4\u8f03\u4e86 Segment Anything Model (SAM) \u53ca\u5176\u66f4\u65b0\u7248\u672c SAM 2 \u5728\u5177\u6709\u6311\u6230\u6027\u7684\u6c34\u4e0b\u74b0\u5883\u4e2d\u7684\u6548\u80fd\u3002\u6211\u5011\u7684\u7814\u7a76\u7d50\u679c\u7a81\u51fa\u4e86 SAM 2 \u76f8\u8f03\u65bc SAM \u7684\u6539\u9032\uff0c\u8b49\u660e\u4e86\u5176\u589e\u5f37\u4e86\u8655\u7406\u6c34\u4e0b\u507d\u88dd\u7269\u9ad4\u8907\u96dc\u6027\u7684\u80fd\u529b\u3002\u8207\u76ee\u524d\u5148\u9032\u7684\u8996\u89ba\u7269\u9ad4\u8ffd\u8e64\u65b9\u6cd5\u76f8\u6bd4\uff0c\u6700\u65b0\u7684\u5f71\u7247\u5206\u5272\u57fa\u790e\u6a21\u578b SAM 2 \u4e5f\u5c55\u73fe\u51fa\u986f\u8457\u7684\u512a\u52e2\uff0c\u70ba\u958b\u767c\u66f4\u6709\u6548\u7684\u8ffd\u8e64\u6280\u8853\u63d0\u4f9b\u4e86\u5bf6\u8cb4\u7684\u898b\u89e3\uff0c\u4ee5\u61c9\u5c0d\u6c34\u4e0b\u5834\u666f\u3002\u8a72\u8cc7\u6599\u96c6\u53ef\u4ee5\u5728\n\\color{magenta}{https://github.com/983632847/Awesome-Multimodal-Object-Tracking} \u53d6\u5f97\u3002", "author": "Chunhui Zhang et.al.", "authors": "Chunhui Zhang, Li Liu, Guanjie Huang, Hao Wen, Xi Zhou, Yanfeng Wang", "id": "2409.16902v1", "paper_url": "http://arxiv.org/abs/2409.16902v1", "repo": "https://github.com/983632847/awesome-multimodal-object-tracking"}}