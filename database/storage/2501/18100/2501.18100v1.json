{"2501.18100": {"publish_time": "2025-01-30", "title": "Panacea: Mitigating Harmful Fine-tuning for Large Language Models via Post-fine-tuning Perturbation", "paper_summary": "Harmful fine-tuning attack introduces significant security risks to the\nfine-tuning services. Mainstream defenses aim to vaccinate the model such that\nthe later harmful fine-tuning attack is less effective. However, our evaluation\nresults show that such defenses are fragile -- with a few fine-tuning steps,\nthe model still can learn the harmful knowledge. To this end, we do further\nexperiment and find that an embarrassingly simple solution -- adding purely\nrandom perturbations to the fine-tuned model, can recover the model from\nharmful behavior, though it leads to a degradation in the model's fine-tuning\nperformance. To address the degradation of fine-tuning performance, we further\npropose Panacea, which optimizes an adaptive perturbation that will be applied\nto the model after fine-tuning. Panacea maintains model's safety alignment\nperformance without compromising downstream fine-tuning performance.\nComprehensive experiments are conducted on different harmful ratios,\nfine-tuning tasks and mainstream LLMs, where the average harmful scores are\nreduced by up-to 21.5%, while maintaining fine-tuning performance. As a\nby-product, we analyze the optimized perturbation and show that different\nlayers in various LLMs have distinct safety coefficients. Source code available\nat https://github.com/w-yibo/Panacea", "paper_summary_zh": "\u6709\u5bb3\u5fae\u8abf\u653b\u64ca\u5c0d\u5fae\u8abf\u670d\u52d9\u5f15\u5165\u91cd\u5927\u7684\u5b89\u5168\u98a8\u96aa\u3002\u4e3b\u6d41\u9632\u79a6\u65e8\u5728\u63a5\u7a2e\u6a21\u578b\uff0c\u4ee5\u964d\u4f4e\u5f8c\u7e8c\u7684\u6709\u5bb3\u5fae\u8abf\u653b\u64ca\u7684\u6548\u529b\u3002\u7136\u800c\uff0c\u6211\u5011\u7684\u8a55\u4f30\u7d50\u679c\u986f\u793a\uff0c\u6b64\u985e\u9632\u79a6\u5f88\u8106\u5f31\u2014\u2014\u53ea\u9700\u5e7e\u500b\u5fae\u8abf\u6b65\u9a5f\uff0c\u6a21\u578b\u4ecd\u7136\u53ef\u4ee5\u5b78\u7fd2\u6709\u5bb3\u77e5\u8b58\u3002\u70ba\u6b64\uff0c\u6211\u5011\u9032\u4e00\u6b65\u9032\u884c\u5be6\u9a57\uff0c\u767c\u73fe\u4e00\u500b\u4ee4\u4eba\u5c37\u5c2c\u7684\u7c21\u55ae\u89e3\u6c7a\u65b9\u6848\u2014\u2014\u5728\u5fae\u8abf\u6a21\u578b\u4e2d\u52a0\u5165\u7d14\u96a8\u6a5f\u64fe\u52d5\uff0c\u53ef\u4ee5\u8b93\u6a21\u578b\u5f9e\u6709\u5bb3\u884c\u70ba\u4e2d\u6062\u5fa9\uff0c\u5118\u7ba1\u9019\u6703\u5c0e\u81f4\u6a21\u578b\u5fae\u8abf\u6027\u80fd\u4e0b\u964d\u3002\u70ba\u4e86\u89e3\u6c7a\u5fae\u8abf\u6027\u80fd\u4e0b\u964d\u7684\u554f\u984c\uff0c\u6211\u5011\u9032\u4e00\u6b65\u63d0\u51fa Panacea\uff0c\u5b83\u512a\u5316\u4e86\u5c07\u5728\u5fae\u8abf\u5f8c\u61c9\u7528\u65bc\u6a21\u578b\u7684\u81ea\u9069\u61c9\u64fe\u52d5\u3002Panacea \u4fdd\u6301\u4e86\u6a21\u578b\u7684\u5b89\u5168\u5c0d\u9f4a\u6027\u80fd\uff0c\u540c\u6642\u4e0d\u5f71\u97ff\u4e0b\u6e38\u5fae\u8abf\u6027\u80fd\u3002\u5728\u4e0d\u540c\u7684\u6709\u5bb3\u6bd4\u7387\u3001\u5fae\u8abf\u4efb\u52d9\u548c\u4e3b\u6d41 LLM \u4e0a\u9032\u884c\u4e86\u7d9c\u5408\u5be6\u9a57\uff0c\u5e73\u5747\u6709\u5bb3\u5206\u6578\u964d\u4f4e\u4e86 21.5%\uff0c\u540c\u6642\u4fdd\u6301\u4e86\u5fae\u8abf\u6027\u80fd\u3002\u4f5c\u70ba\u526f\u7522\u54c1\uff0c\u6211\u5011\u5206\u6790\u4e86\u512a\u5316\u7684\u64fe\u52d5\uff0c\u4e26\u5c55\u793a\u4e86\u5404\u7a2e LLM \u4e2d\u7684\u4e0d\u540c\u5c64\u5177\u6709\u4e0d\u540c\u7684\u5b89\u5168\u4fc2\u6578\u3002\u6e90\u4ee3\u78bc\u53ef\u5728 https://github.com/w-yibo/Panacea \u7372\u5f97", "author": "Yibo Wang et.al.", "authors": "Yibo Wang, Tiansheng Huang, Li Shen, Huanjin Yao, Haotian Luo, Rui Liu, Naiqiang Tan, Jiaxing Huang, Dacheng Tao", "id": "2501.18100v1", "paper_url": "http://arxiv.org/abs/2501.18100v1", "repo": "https://github.com/w-yibo/panacea"}}