{"2409.13094": {"publish_time": "2024-09-19", "title": "DenoMamba: A fused state-space model for low-dose CT denoising", "paper_summary": "Low-dose computed tomography (LDCT) lower potential risks linked to radiation\nexposure while relying on advanced denoising algorithms to maintain diagnostic\nquality in reconstructed images. The reigning paradigm in LDCT denoising is\nbased on neural network models that learn data-driven image priors to separate\nnoise evoked by dose reduction from underlying tissue signals. Naturally, the\nfidelity of these priors depend on the model's ability to capture the broad\nrange of contextual features evident in CT images. Earlier convolutional neural\nnetworks (CNN) are highly adept at efficiently capturing short-range spatial\ncontext, but their limited receptive fields reduce sensitivity to interactions\nover longer distances. Although transformers based on self-attention mechanisms\nhave recently been posed to increase sensitivity to long-range context, they\ncan suffer from suboptimal performance and efficiency due to elevated model\ncomplexity, particularly for high-resolution CT images. For high-quality\nrestoration of LDCT images, here we introduce DenoMamba, a novel denoising\nmethod based on state-space modeling (SSM), that efficiently captures short-\nand long-range context in medical images. Following an hourglass architecture\nwith encoder-decoder stages, DenoMamba employs a spatial SSM module to encode\nspatial context and a novel channel SSM module equipped with a secondary gated\nconvolution network to encode latent features of channel context at each stage.\nFeature maps from the two modules are then consolidated with low-level input\nfeatures via a convolution fusion module (CFM). Comprehensive experiments on\nLDCT datasets with 25\\% and 10\\% dose reduction demonstrate that DenoMamba\noutperforms state-of-the-art denoisers with average improvements of 1.4dB PSNR,\n1.1% SSIM, and 1.6% RMSE in recovered image quality.", "paper_summary_zh": "\u4f4e\u5291\u91cf\u96fb\u8166\u65b7\u5c64\u6383\u63cf (LDCT) \u964d\u4f4e\u8207\u8f3b\u5c04\u6709\u95dc\u7684\u6f5b\u5728\u98a8\u96aa\uff0c\u540c\u6642\u4f9d\u8cf4\u9032\u968e\u7684\u53bb\u566a\u6f14\u7b97\u6cd5\uff0c\u4ee5\u7dad\u6301\u91cd\u5efa\u5f71\u50cf\u7684\u8a3a\u65b7\u54c1\u8cea\u3002LDCT \u53bb\u566a\u7684\u4e3b\u6d41\u5178\u7bc4\u57fa\u65bc\u795e\u7d93\u7db2\u8def\u6a21\u578b\uff0c\u8a72\u6a21\u578b\u6703\u5b78\u7fd2\u8cc7\u6599\u9a45\u52d5\u7684\u5f71\u50cf\u5148\u9a57\uff0c\u4ee5\u5340\u5206\u5291\u91cf\u964d\u4f4e\u6240\u7522\u751f\u7684\u96dc\u8a0a\u8207\u5e95\u5c64\u7d44\u7e54\u8a0a\u865f\u3002\u81ea\u7136\u800c\u7136\uff0c\u9019\u4e9b\u5148\u9a57\u7684\u4fdd\u771f\u5ea6\u53d6\u6c7a\u65bc\u6a21\u578b\u64f7\u53d6 CT \u5f71\u50cf\u4e2d\u5ee3\u6cdb\u8108\u7d61\u7279\u5fb5\u7684\u80fd\u529b\u3002\u8f03\u65e9\u7684\u5377\u7a4d\u795e\u7d93\u7db2\u8def (CNN) \u975e\u5e38\u64c5\u9577\u6709\u6548\u64f7\u53d6\u77ed\u7a0b\u7a7a\u9593\u8108\u7d61\uff0c\u4f46\u5176\u6709\u9650\u7684\u611f\u53d7\u91ce\u6703\u964d\u4f4e\u5c0d\u8f03\u9577\u8ddd\u96e2\u4ea4\u4e92\u4f5c\u7528\u7684\u654f\u611f\u5ea6\u3002\u5118\u7ba1\u57fa\u65bc\u81ea\u6211\u6ce8\u610f\u6a5f\u5236\u7684Transformer\u6700\u8fd1\u88ab\u63d0\u51fa\u7528\u65bc\u589e\u52a0\u5c0d\u9577\u7a0b\u8108\u7d61\u7684\u654f\u611f\u5ea6\uff0c\u4f46\u7531\u65bc\u6a21\u578b\u8907\u96dc\u5ea6\u63d0\u9ad8\uff0c\u5b83\u5011\u53ef\u80fd\u6703\u56e0\u6b21\u4f73\u6548\u80fd\u548c\u6548\u7387\u800c\u53d7\u9650\uff0c\u7279\u5225\u662f\u5c0d\u65bc\u9ad8\u89e3\u6790\u5ea6 CT \u5f71\u50cf\u3002\u70ba\u4e86\u9ad8\u54c1\u8cea\u5fa9\u539f LDCT \u5f71\u50cf\uff0c\u6211\u5011\u5728\u6b64\u4ecb\u7d39 DenoMamba\uff0c\u9019\u662f\u4e00\u7a2e\u57fa\u65bc\u72c0\u614b\u7a7a\u9593\u6a21\u578b (SSM) \u7684\u5275\u65b0\u53bb\u566a\u65b9\u6cd5\uff0c\u5b83\u80fd\u6709\u6548\u64f7\u53d6\u91ab\u5b78\u5f71\u50cf\u4e2d\u7684\u77ed\u7a0b\u548c\u9577\u7a0b\u8108\u7d61\u3002DenoMamba \u63a1\u7528\u5177\u6709\u7de8\u78bc\u5668-\u89e3\u78bc\u5668\u968e\u6bb5\u7684\u6c99\u6f0f\u67b6\u69cb\uff0c\u4e26\u4f7f\u7528\u7a7a\u9593 SSM \u6a21\u7d44\u4f86\u7de8\u78bc\u7a7a\u9593\u8108\u7d61\uff0c\u4ee5\u53ca\u914d\u5099\u6b21\u8981\u9598\u63a7\u5377\u7a4d\u7db2\u8def\u7684\u65b0\u578b\u901a\u9053 SSM \u6a21\u7d44\uff0c\u4ee5\u7de8\u78bc\u5404\u500b\u968e\u6bb5\u4e2d\u901a\u9053\u8108\u7d61\u7684\u6f5b\u5728\u7279\u5fb5\u3002\u7136\u5f8c\u900f\u904e\u5377\u7a4d\u878d\u5408\u6a21\u7d44 (CFM) \u5c07\u5169\u500b\u6a21\u7d44\u4e2d\u7684\u7279\u5fb5\u5716\u8207\u4f4e\u968e\u8f38\u5165\u7279\u5fb5\u5408\u4f75\u3002\u5728\u5291\u91cf\u964d\u4f4e 25% \u548c 10% \u7684 LDCT \u8cc7\u6599\u96c6\u4e0a\u9032\u884c\u7684\u5168\u9762\u5be6\u9a57\u8b49\u660e\uff0cDenoMamba \u7684\u6548\u80fd\u512a\u65bc\u6700\u5148\u9032\u7684\u53bb\u566a\u5668\uff0c\u5728\u5fa9\u539f\u5f71\u50cf\u54c1\u8cea\u65b9\u9762\u5e73\u5747\u6539\u5584\u4e86 1.4dB PSNR\u30011.1% SSIM \u548c 1.6% RMSE\u3002", "author": "\u015eaban \u00d6zt\u00fcrk et.al.", "authors": "\u015eaban \u00d6zt\u00fcrk, O\u011fuz Can Duran, Tolga \u00c7ukur", "id": "2409.13094v1", "paper_url": "http://arxiv.org/abs/2409.13094v1", "repo": "null"}}