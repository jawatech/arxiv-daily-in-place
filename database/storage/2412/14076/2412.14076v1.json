{"2412.14076": {"publish_time": "2024-12-18", "title": "Compositional Generalization Across Distributional Shifts with Sparse Tree Operations", "paper_summary": "Neural networks continue to struggle with compositional generalization, and\nthis issue is exacerbated by a lack of massive pre-training. One successful\napproach for developing neural systems which exhibit human-like compositional\ngeneralization is \\textit{hybrid} neurosymbolic techniques. However, these\ntechniques run into the core issues that plague symbolic approaches to AI:\nscalability and flexibility. The reason for this failure is that at their core,\nhybrid neurosymbolic models perform symbolic computation and relegate the\nscalable and flexible neural computation to parameterizing a symbolic system.\nWe investigate a \\textit{unified} neurosymbolic system where transformations in\nthe network can be interpreted simultaneously as both symbolic and neural\ncomputation. We extend a unified neurosymbolic architecture called the\nDifferentiable Tree Machine in two central ways. First, we significantly\nincrease the model's efficiency through the use of sparse vector\nrepresentations of symbolic structures. Second, we enable its application\nbeyond the restricted set of tree2tree problems to the more general class of\nseq2seq problems. The improved model retains its prior generalization\ncapabilities and, since there is a fully neural path through the network,\navoids the pitfalls of other neurosymbolic techniques that elevate symbolic\ncomputation over neural computation.", "paper_summary_zh": "\u795e\u7d93\u7db2\u8def\u6301\u7e8c\u8207\u7d44\u5408\u6982\u62ec\u596e\u6230\uff0c\n\u800c\u9019\u500b\u554f\u984c\u56e0\u7f3a\u4e4f\u5927\u91cf\u7684\u9810\u8a13\u7df4\u800c\u60e1\u5316\u3002\u4e00\u7a2e\u6210\u529f\u7684\u65b9\u6cd5\u662f\u958b\u767c\u5c55\u793a\u4eba\u985e\u822c\u7d44\u5408\u6982\u62ec\u7684\u795e\u7d93\u7cfb\u7d71\uff0c\u4e5f\u5c31\u662f\u300c\u6df7\u5408\u300d\u795e\u7d93\u7b26\u865f\u6280\u8853\u3002\u7136\u800c\uff0c\u9019\u4e9b\u6280\u8853\u6703\u9047\u5230\u56f0\u64fe AI \u7b26\u865f\u65b9\u6cd5\u7684\u6838\u5fc3\u554f\u984c\uff1a\u53ef\u64f4\u5145\u6027\u548c\u5f48\u6027\u3002\u9019\u500b\u5931\u6557\u7684\u539f\u56e0\u5728\u65bc\uff0c\u6df7\u5408\u795e\u7d93\u7b26\u865f\u6a21\u578b\u5728\u6838\u5fc3\u4e0a\u57f7\u884c\u7b26\u865f\u904b\u7b97\uff0c\u4e26\u5c07\u53ef\u64f4\u5145\u4e14\u5f48\u6027\u7684\u795e\u7d93\u904b\u7b97\u964d\u7d1a\u70ba\u7b26\u865f\u7cfb\u7d71\u7684\u53c3\u6578\u5316\u3002\u6211\u5011\u7814\u7a76\u4e00\u500b\u300c\u7d71\u4e00\u300d\u7684\u795e\u7d93\u7b26\u865f\u7cfb\u7d71\uff0c\u5176\u4e2d\u7db2\u8def\u4e2d\u7684\u8f49\u63db\u53ef\u4ee5\u540c\u6642\u8a6e\u91cb\u70ba\u7b26\u865f\u548c\u795e\u7d93\u904b\u7b97\u3002\u6211\u5011\u4ee5\u5169\u7a2e\u6838\u5fc3\u65b9\u5f0f\u64f4\u5145\u4e00\u500b\u7a31\u70ba\u53ef\u5fae\u5206\u6a39\u72c0\u6a5f\u5668\u7684\u7d71\u4e00\u795e\u7d93\u7b26\u865f\u67b6\u69cb\u3002\u9996\u5148\uff0c\u6211\u5011\u900f\u904e\u4f7f\u7528\u7b26\u865f\u7d50\u69cb\u7684\u7a00\u758f\u5411\u91cf\u8868\u793a\u6cd5\uff0c\u5927\u5e45\u63d0\u5347\u6a21\u578b\u7684\u6548\u7387\u3002\u5176\u6b21\uff0c\u6211\u5011\u8b93\u5176\u61c9\u7528\u4e0d\u53ea\u9650\u65bc\u53d7\u9650\u7684\u6a39\u5c0d\u6a39\u554f\u984c\uff0c\u800c\u662f\u64f4\u53ca\u66f4\u901a\u7528\u7684\u5e8f\u5217\u5c0d\u5e8f\u5217\u554f\u984c\u3002\u6539\u826f\u5f8c\u7684\u6a21\u578b\u4fdd\u7559\u4e86\u5176\u5148\u524d\u7684\u6982\u62ec\u80fd\u529b\uff0c\u800c\u4e14\u7531\u65bc\u7db2\u8def\u4e2d\u6709\u4e00\u689d\u5b8c\u5168\u7684\u795e\u7d93\u8def\u5f91\uff0c\u907f\u514d\u4e86\u5176\u4ed6\u795e\u7d93\u7b26\u865f\u6280\u8853\u7684\u9677\u9631\uff0c\u9019\u4e9b\u6280\u8853\u5c07\u7b26\u865f\u904b\u7b97\u63d0\u5347\u81f3\u795e\u7d93\u904b\u7b97\u4e4b\u4e0a\u3002", "author": "Paul Soulos et.al.", "authors": "Paul Soulos, Henry Conklin, Mattia Opper, Paul Smolensky, Jianfeng Gao, Roland Fernandez", "id": "2412.14076v1", "paper_url": "http://arxiv.org/abs/2412.14076v1", "repo": "null"}}