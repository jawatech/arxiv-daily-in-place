{"2405.03882": {"publish_time": "2024-05-06", "title": "Trio-ViT: Post-Training Quantization and Acceleration for Softmax-Free Efficient Vision Transformer", "paper_summary": "Motivated by the huge success of Transformers in the field of natural\nlanguage processing (NLP), Vision Transformers (ViTs) have been rapidly\ndeveloped and achieved remarkable performance in various computer vision tasks.\nHowever, their huge model sizes and intensive computations hinder ViTs'\ndeployment on embedded devices, calling for effective model compression\nmethods, such as quantization. Unfortunately, due to the existence of\nhardware-unfriendly and quantization-sensitive non-linear operations,\nparticularly {Softmax}, it is non-trivial to completely quantize all operations\nin ViTs, yielding either significant accuracy drops or non-negligible hardware\ncosts. In response to challenges associated with \\textit{standard ViTs}, we\nfocus our attention towards the quantization and acceleration for\n\\textit{efficient ViTs}, which not only eliminate the troublesome Softmax but\nalso integrate linear attention with low computational complexity, and propose\n\\emph{Trio-ViT} accordingly. Specifically, at the algorithm level, we develop a\n{tailored post-training quantization engine} taking the unique activation\ndistributions of Softmax-free efficient ViTs into full consideration, aiming to\nboost quantization accuracy. Furthermore, at the hardware level, we build an\naccelerator dedicated to the specific Convolution-Transformer hybrid\narchitecture of efficient ViTs, thereby enhancing hardware efficiency.\nExtensive experimental results consistently prove the effectiveness of our\nTrio-ViT framework. {Particularly, we can gain up to\n$\\uparrow$$\\mathbf{7.2}\\times$ and $\\uparrow$$\\mathbf{14.6}\\times$ FPS under\ncomparable accuracy over state-of-the-art ViT accelerators, as well as\n$\\uparrow$$\\mathbf{5.9}\\times$ and $\\uparrow$$\\mathbf{2.0}\\times$ DSP\nefficiency.} Codes will be released publicly upon acceptance.", "paper_summary_zh": "<paragraph>\u53d7 Transformer \u5728\u81ea\u7136\u8a9e\u8a00\u8655\u7406 (NLP) \u9818\u57df\u53d6\u5f97\u5de8\u5927\u6210\u529f\u7684\u555f\u767c\uff0c\u8996\u89ba Transformer (ViT) \u5df2\u88ab\u8fc5\u901f\u958b\u767c\uff0c\u4e26\u5728\u5404\u7a2e\u96fb\u8166\u8996\u89ba\u4efb\u52d9\u4e2d\u53d6\u5f97\u986f\u8457\u6210\u6548\u3002\u7136\u800c\uff0c\u5b83\u5011\u9f90\u5927\u7684\u6a21\u578b\u898f\u6a21\u548c\u5bc6\u96c6\u904b\u7b97\u963b\u7919\u4e86 ViT \u5728\u5d4c\u5165\u5f0f\u88dd\u7f6e\u4e0a\u7684\u90e8\u7f72\uff0c\u9019\u9700\u8981\u6709\u6548\u7684\u6a21\u578b\u58d3\u7e2e\u65b9\u6cd5\uff0c\u4f8b\u5982\u91cf\u5316\u3002\u4e0d\u5e78\u7684\u662f\uff0c\u7531\u65bc\u5b58\u5728\u786c\u9ad4\u4e0d\u53cb\u5584\u4e14\u5c0d\u91cf\u5316\u654f\u611f\u7684\u975e\u7dda\u6027\u904b\u7b97\uff0c\u7279\u5225\u662f {Softmax}\uff0c\u56e0\u6b64\u8981\u5b8c\u5168\u91cf\u5316 ViT \u4e2d\u7684\u6240\u6709\u904b\u7b97\u4e26\u975e\u6613\u4e8b\uff0c\u9019\u6703\u5c0e\u81f4\u986f\u8457\u7684\u6e96\u78ba\u5ea6\u4e0b\u964d\u6216\u4e0d\u53ef\u5ffd\u8996\u7684\u786c\u9ad4\u6210\u672c\u3002\u70ba\u4e86\u61c9\u5c0d\u8207\\textit{\u6a19\u6e96 ViT}\u76f8\u95dc\u7684\u6311\u6230\uff0c\u6211\u5011\u5c07\u6ce8\u610f\u529b\u96c6\u4e2d\u5728\\textit{\u9ad8\u6548 ViT}\u7684\u91cf\u5316\u548c\u52a0\u901f\u4e0a\uff0c\u9019\u4e0d\u50c5\u6d88\u9664\u4e86\u9ebb\u7169\u7684 Softmax\uff0c\u9084\u6574\u5408\u4e86\u4f4e\u904b\u7b97\u8907\u96dc\u5ea6\u7684\u7dda\u6027\u6ce8\u610f\u529b\uff0c\u4e26\u64da\u6b64\u63d0\u51fa\u4e86\\emph{Trio-ViT}\u3002\u5177\u9ad4\u4f86\u8aaa\uff0c\u5728\u6f14\u7b97\u6cd5\u5c64\u7d1a\uff0c\u6211\u5011\u958b\u767c\u4e86\u4e00\u500b{\u91cf\u8eab\u6253\u9020\u7684\u8a13\u7df4\u5f8c\u91cf\u5316\u5f15\u64ce}\uff0c\u5145\u5206\u8003\u616e\u4e86\u7121 Softmax \u9ad8\u6548 ViT \u7684\u7368\u7279\u6fc0\u6d3b\u5206\u4f48\uff0c\u65e8\u5728\u63d0\u5347\u91cf\u5316\u6e96\u78ba\u5ea6\u3002\u6b64\u5916\uff0c\u5728\u786c\u9ad4\u5c64\u7d1a\uff0c\u6211\u5011\u5efa\u7acb\u4e86\u4e00\u500b\u5c08\u9580\u7528\u65bc\u9ad8\u6548 ViT \u7684\u7279\u5b9a\u5377\u7a4dTransformer\u6df7\u5408\u67b6\u69cb\u7684\u52a0\u901f\u5668\uff0c\u5f9e\u800c\u63d0\u5347\u786c\u9ad4\u6548\u7387\u3002\u5ee3\u6cdb\u7684\u5be6\u9a57\u7d50\u679c\u4e00\u81f4\u8b49\u660e\u4e86\u6211\u5011 Trio-ViT \u6846\u67b6\u7684\u6709\u6548\u6027\u3002{\u7279\u5225\u662f\uff0c\u5728\u8207\u6700\u5148\u9032\u7684 ViT \u52a0\u901f\u5668\u76f8\u7576\u7684\u6e96\u78ba\u5ea6\u4e0b\uff0c\u6211\u5011\u53ef\u4ee5\u7372\u5f97\u9ad8\u9054 $\\uparrow$$\\mathbf{7.2}\\times$ \u548c $\\uparrow$$\\mathbf{14.6}\\times$ FPS\uff0c\u4ee5\u53ca $\\uparrow$$\\mathbf{5.9}\\times$ \u548c $\\uparrow$$\\mathbf{2.0}\\times$ DSP \u6548\u7387\u3002}\u4ee3\u78bc\u5c07\u5728\u63a5\u53d7\u5f8c\u516c\u958b\u767c\u5e03\u3002</paragraph>", "author": "Huihong Shi et.al.", "authors": "Huihong Shi, Haikuo Shao, Wendong Mao, Zhongfeng Wang", "id": "2405.03882v1", "paper_url": "http://arxiv.org/abs/2405.03882v1", "repo": "null"}}