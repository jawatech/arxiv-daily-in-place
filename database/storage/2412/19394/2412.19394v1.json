{"2412.19394": {"publish_time": "2024-12-27", "title": "An Engorgio Prompt Makes Large Language Model Babble on", "paper_summary": "Auto-regressive large language models (LLMs) have yielded impressive\nperformance in many real-world tasks. However, the new paradigm of these LLMs\nalso exposes novel threats. In this paper, we explore their vulnerability to\ninference cost attacks, where a malicious user crafts Engorgio prompts to\nintentionally increase the computation cost and latency of the inference\nprocess. We design Engorgio, a novel methodology, to efficiently generate\nadversarial Engorgio prompts to affect the target LLM's service availability.\nEngorgio has the following two technical contributions. (1) We employ a\nparameterized distribution to track LLMs' prediction trajectory. (2) Targeting\nthe auto-regressive nature of LLMs' inference process, we propose novel loss\nfunctions to stably suppress the appearance of the <EOS> token, whose\noccurrence will interrupt the LLM's generation process. We conduct extensive\nexperiments on 13 open-sourced LLMs with parameters ranging from 125M to 30B.\nThe results show that Engorgio prompts can successfully induce LLMs to generate\nabnormally long outputs (i.e., roughly 2-13$\\times$ longer to reach 90%+ of the\noutput length limit) in a white-box scenario and our real-world experiment\ndemonstrates Engergio's threat to LLM service with limited computing resources.\nThe code is accessible at https://github.com/jianshuod/Engorgio-prompt.", "paper_summary_zh": "\u81ea\u52d5\u56de\u6b78\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u5728\u8a31\u591a\u5be6\u969b\u4efb\u52d9\u4e2d\u8868\u73fe\u5f97\u4ee4\u4eba\u5370\u8c61\u6df1\u523b\u3002\u7136\u800c\uff0c\u9019\u4e9b LLM \u7684\u65b0\u7bc4\u5f0f\u4e5f\u66b4\u9732\u4e86\u65b0\u7684\u5a01\u8105\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u63a2\u8a0e\u4e86\u5b83\u5011\u5c0d\u63a8\u7406\u6210\u672c\u653b\u64ca\u7684\u8106\u5f31\u6027\uff0c\u5728\u9019\u7a2e\u653b\u64ca\u4e2d\uff0c\u60e1\u610f\u4f7f\u7528\u8005\u6703\u88fd\u4f5c Engorgio \u63d0\u793a\uff0c\u4ee5\u6545\u610f\u589e\u52a0\u63a8\u7406\u904e\u7a0b\u7684\u904b\u7b97\u6210\u672c\u548c\u5ef6\u9072\u3002\u6211\u5011\u8a2d\u8a08\u4e86 Engorgio\uff0c\u4e00\u7a2e\u65b0\u7a4e\u7684\u65b9\u6cd5\uff0c\u4ee5\u6709\u6548\u7522\u751f\u5c0d\u6297\u6027\u7684 Engorgio \u63d0\u793a\u4f86\u5f71\u97ff\u76ee\u6a19 LLM \u7684\u670d\u52d9\u53ef\u7528\u6027\u3002Engorgio \u5177\u6709\u4ee5\u4e0b\u5169\u500b\u6280\u8853\u8ca2\u737b\u3002(1) \u6211\u5011\u63a1\u7528\u53c3\u6578\u5316\u5206\u4f48\u4f86\u8ffd\u8e64 LLM \u7684\u9810\u6e2c\u8ecc\u8de1\u3002(2) \u91dd\u5c0d LLM \u63a8\u7406\u904e\u7a0b\u7684\u81ea\u52d5\u56de\u6b78\u7279\u6027\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u65b0\u7a4e\u7684\u640d\u5931\u51fd\u6578\uff0c\u4ee5\u7a69\u5b9a\u5730\u6291\u5236 <EOS> \u4ee4\u724c\u7684\u51fa\u73fe\uff0c\u5176\u51fa\u73fe\u6703\u4e2d\u65b7 LLM \u7684\u751f\u6210\u904e\u7a0b\u3002\u6211\u5011\u5c0d 13 \u500b\u958b\u6e90 LLM \u9032\u884c\u4e86\u5ee3\u6cdb\u7684\u5be6\u9a57\uff0c\u5176\u53c3\u6578\u7bc4\u570d\u5f9e 125M \u5230 30B\u3002\u7d50\u679c\u8868\u660e\uff0cEngorgio \u63d0\u793a\u53ef\u4ee5\u6210\u529f\u8a98\u5c0e LLM \u751f\u6210\u7570\u5e38\u9577\u7684\u8f38\u51fa\uff08\u5373\uff0c\u5927\u7d04 2-13 \u500d\u9577\u624d\u80fd\u9054\u5230 90% \u4ee5\u4e0a\u7684\u8f38\u51fa\u9577\u5ea6\u9650\u5236\uff09\u5728\u767d\u76d2\u5834\u666f\u4e2d\uff0c\u6211\u5011\u7684\u771f\u5be6\u4e16\u754c\u5be6\u9a57\u8b49\u660e\u4e86 Engergio \u5c0d\u5177\u6709\u6709\u9650\u8a08\u7b97\u8cc7\u6e90\u7684 LLM \u670d\u52d9\u7684\u5a01\u8105\u3002\u7a0b\u5f0f\u78bc\u53ef\u4ee5\u5728 https://github.com/jianshuod/Engorgio-prompt \u7372\u5f97\u3002", "author": "Jianshuo Dong et.al.", "authors": "Jianshuo Dong, Ziyuan Zhang, Qingjie Zhang, Han Qiu, Tianwei Zhang, Hao Wang, Hewu Li, Qi Li, Chao Zhang, Ke Xu", "id": "2412.19394v1", "paper_url": "http://arxiv.org/abs/2412.19394v1", "repo": "null"}}