{"2412.02449": {"publish_time": "2024-12-03", "title": "BYE: Build Your Encoder with One Sequence of Exploration Data for Long-Term Dynamic Scene Understanding", "paper_summary": "Dynamic scene understanding remains a persistent challenge in robotic\napplications. Early dynamic mapping methods focused on mitigating the negative\ninfluence of short-term dynamic objects on camera motion estimation by masking\nor tracking specific categories, which often fall short in adapting to\nlong-term scene changes. Recent efforts address object association in long-term\ndynamic environments using neural networks trained on synthetic datasets, but\nthey still rely on predefined object shapes and categories. Other methods\nincorporate visual, geometric, or semantic heuristics for the association but\noften lack robustness. In this work, we introduce BYE, a class-agnostic,\nper-scene point cloud encoder that removes the need for predefined categories,\nshape priors, or extensive association datasets. Trained on only a single\nsequence of exploration data, BYE can efficiently perform object association in\ndynamically changing scenes. We further propose an ensembling scheme combining\nthe semantic strengths of Vision Language Models (VLMs) with the scene-specific\nexpertise of BYE, achieving a 7% improvement and a 95% success rate in object\nassociation tasks. Code and dataset are available at\nhttps://byencoder.github.io.", "paper_summary_zh": "\u52d5\u614b\u5834\u666f\u7406\u89e3\u5728\u6a5f\u5668\u4eba\u61c9\u7528\u4e2d\u4ecd\u7136\u662f\u4e00\u500b\u6301\u7e8c\u7684\u6311\u6230\u3002\u65e9\u671f\u52d5\u614b\u5c0d\u61c9\u65b9\u6cd5\u5c08\u6ce8\u65bc\u900f\u904e\u906e\u853d\u6216\u8ffd\u8e64\u7279\u5b9a\u985e\u5225\u4f86\u6e1b\u8f15\u77ed\u671f\u52d5\u614b\u7269\u4ef6\u5c0d\u76f8\u6a5f\u52d5\u4f5c\u4f30\u8a08\u7684\u8ca0\u9762\u5f71\u97ff\uff0c\u800c\u9019\u901a\u5e38\u7121\u6cd5\u9069\u61c9\u9577\u671f\u5834\u666f\u8b8a\u5316\u3002\u6700\u8fd1\u7684\u7814\u7a76\u4f7f\u7528\u5728\u5408\u6210\u8cc7\u6599\u96c6\u4e0a\u8a13\u7df4\u7684\u795e\u7d93\u7db2\u8def\u4f86\u89e3\u6c7a\u9577\u671f\u52d5\u614b\u74b0\u5883\u4e2d\u7684\u7269\u4ef6\u95dc\u806f\u554f\u984c\uff0c\u4f46\u5b83\u5011\u4ecd\u7136\u4f9d\u8cf4\u65bc\u9810\u5148\u5b9a\u7fa9\u7684\u7269\u4ef6\u5f62\u72c0\u548c\u985e\u5225\u3002\u5176\u4ed6\u65b9\u6cd5\u5c07\u8996\u89ba\u3001\u5e7e\u4f55\u6216\u8a9e\u7fa9\u555f\u767c\u6cd5\u7d0d\u5165\u95dc\u806f\u4e2d\uff0c\u4f46\u901a\u5e38\u7f3a\u4e4f\u7a69\u5065\u6027\u3002\u5728\u9019\u9805\u5de5\u4f5c\u4e2d\uff0c\u6211\u5011\u4ecb\u7d39\u4e86 BYE\uff0c\u4e00\u500b\u8207\u985e\u5225\u7121\u95dc\u3001\u91dd\u5c0d\u5834\u666f\u7684\u9ede\u96f2\u7de8\u78bc\u5668\uff0c\u5b83\u6d88\u9664\u4e86\u5c0d\u9810\u5148\u5b9a\u7fa9\u985e\u5225\u3001\u5f62\u72c0\u5148\u9a57\u6216\u5ee3\u6cdb\u95dc\u806f\u8cc7\u6599\u96c6\u7684\u9700\u6c42\u3002BYE \u53ea\u5728\u55ae\u4e00\u63a2\u7d22\u8cc7\u6599\u5e8f\u5217\u4e0a\u8a13\u7df4\uff0c\u5c31\u80fd\u6709\u6548\u5730\u5728\u52d5\u614b\u8b8a\u5316\u7684\u5834\u666f\u4e2d\u57f7\u884c\u7269\u4ef6\u95dc\u806f\u3002\u6211\u5011\u9032\u4e00\u6b65\u63d0\u51fa\u4e86\u4e00\u500b\u96c6\u6210\u65b9\u6848\uff0c\u7d50\u5408\u4e86\u8996\u89ba\u8a9e\u8a00\u6a21\u578b (VLM) \u7684\u8a9e\u7fa9\u512a\u52e2\u548c BYE \u7684\u5834\u666f\u7279\u5b9a\u5c08\u696d\u77e5\u8b58\uff0c\u5728\u7269\u4ef6\u95dc\u806f\u4efb\u52d9\u4e2d\u5be6\u73fe\u4e86 7% \u7684\u6539\u9032\u548c 95% \u7684\u6210\u529f\u7387\u3002\u7a0b\u5f0f\u78bc\u548c\u8cc7\u6599\u96c6\u53ef\u5728 https://byencoder.github.io/ \u53d6\u5f97\u3002", "author": "Chenguang Huang et.al.", "authors": "Chenguang Huang, Shengchao Yan, Wolfram Burgard", "id": "2412.02449v1", "paper_url": "http://arxiv.org/abs/2412.02449v1", "repo": "null"}}