{"2406.17972": {"publish_time": "2024-06-25", "title": "LABOR-LLM: Language-Based Occupational Representations with Large Language Models", "paper_summary": "Many empirical studies of labor market questions rely on estimating\nrelatively simple predictive models using small, carefully constructed\nlongitudinal survey datasets based on hand-engineered features. Large Language\nModels (LLMs), trained on massive datasets, encode vast quantities of world\nknowledge and can be used for the next job prediction problem. However, while\nan off-the-shelf LLM produces plausible career trajectories when prompted, the\nprobability with which an LLM predicts a particular job transition conditional\non career history will not, in general, align with the true conditional\nprobability in a given population. Recently, Vafa et al. (2024) introduced a\ntransformer-based \"foundation model\", CAREER, trained using a large,\nunrepresentative resume dataset, that predicts transitions between jobs; it\nfurther demonstrated how transfer learning techniques can be used to leverage\nthe foundation model to build better predictive models of both transitions and\nwages that reflect conditional transition probabilities found in nationally\nrepresentative survey datasets. This paper considers an alternative where the\nfine-tuning of the CAREER foundation model is replaced by fine-tuning LLMs. For\nthe task of next job prediction, we demonstrate that models trained with our\napproach outperform several alternatives in terms of predictive performance on\nthe survey data, including traditional econometric models, CAREER, and LLMs\nwith in-context learning, even though the LLM can in principle predict job\ntitles that are not allowed in the survey data. Further, we show that our\nfine-tuned LLM-based models' predictions are more representative of the career\ntrajectories of various workforce subpopulations than off-the-shelf LLM models\nand CAREER. We conduct experiments and analyses that highlight the sources of\nthe gains in the performance of our models for representative predictions.", "paper_summary_zh": "\u8a31\u591a\u52de\u52d5\u5e02\u5834\u554f\u984c\u7684\u5be6\u8b49\u7814\u7a76\u4f9d\u8cf4\u65bc\u4f30\u8a08\u76f8\u5c0d\u7c21\u55ae\u7684\u9810\u6e2c\u6a21\u578b\uff0c\u9019\u4e9b\u6a21\u578b\u4f7f\u7528\u57fa\u65bc\u624b\u5de5\u7279\u5fb5\u7684\u5c0f\u578b\u3001\u4ed4\u7d30\u5efa\u69cb\u7684\u7e31\u5411\u8abf\u67e5\u8cc7\u6599\u96c6\u3002\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u5728\u5927\u91cf\u8cc7\u6599\u96c6\u4e0a\u8a13\u7df4\uff0c\u7de8\u78bc\u4e86\u5927\u91cf\u7684\u4e16\u754c\u77e5\u8b58\uff0c\u53ef\u7528\u65bc\u4e0b\u4e00\u500b\u5de5\u4f5c\u9810\u6e2c\u554f\u984c\u3002\u7136\u800c\uff0c\u96d6\u7136\u73fe\u6210\u7684 LLM \u5728\u63d0\u793a\u4e0b\u6703\u7522\u751f\u5408\u7406\u7684\u8077\u696d\u8ecc\u8de1\uff0c\u4f46 LLM \u9810\u6e2c\u7279\u5b9a\u5de5\u4f5c\u8f49\u63db\u7684\u6a5f\u7387\uff0c\u4ee5\u8077\u696d\u6b77\u53f2\u70ba\u689d\u4ef6\uff0c\u901a\u5e38\u4e0d\u6703\u8207\u7279\u5b9a\u4eba\u53e3\u4e2d\u7684\u771f\u5be6\u689d\u4ef6\u6a5f\u7387\u4e00\u81f4\u3002\u6700\u8fd1\uff0cVafa \u7b49\u4eba (2024) \u4ecb\u7d39\u4e86\u4e00\u500b\u57fa\u65bcTransformer\u7684\u300c\u57fa\u790e\u6a21\u578b\u300dCAREER\uff0c\u4f7f\u7528\u5927\u578b\u3001\u975e\u4ee3\u8868\u6027\u5c65\u6b77\u8cc7\u6599\u96c6\u9032\u884c\u8a13\u7df4\uff0c\u9810\u6e2c\u5de5\u4f5c\u4e4b\u9593\u7684\u8f49\u63db\uff1b\u5b83\u9032\u4e00\u6b65\u5c55\u793a\u4e86\u5982\u4f55\u4f7f\u7528\u9077\u79fb\u5b78\u7fd2\u6280\u8853\u4f86\u5229\u7528\u57fa\u790e\u6a21\u578b\u5efa\u7acb\u66f4\u597d\u7684\u8f49\u63db\u548c\u5de5\u8cc7\u9810\u6e2c\u6a21\u578b\uff0c\u4ee5\u53cd\u6620\u5728\u5168\u570b\u4ee3\u8868\u6027\u8abf\u67e5\u8cc7\u6599\u96c6\u4e2d\u767c\u73fe\u7684\u689d\u4ef6\u8f49\u63db\u6a5f\u7387\u3002\u672c\u6587\u8003\u616e\u4e86\u4e00\u500b\u66ff\u4ee3\u65b9\u6848\uff0c\u5176\u4e2d CAREER \u57fa\u790e\u6a21\u578b\u7684\u5fae\u8abf\u88ab\u5fae\u8abf LLM \u53d6\u4ee3\u3002\u5c0d\u65bc\u4e0b\u4e00\u500b\u5de5\u4f5c\u9810\u6e2c\u4efb\u52d9\uff0c\u6211\u5011\u8b49\u660e\u4f7f\u7528\u6211\u5011\u7684\u65b9\u6cd5\u8a13\u7df4\u7684\u6a21\u578b\u5728\u9810\u6e2c\u6548\u80fd\u65b9\u9762\u512a\u65bc\u5e7e\u7a2e\u66ff\u4ee3\u65b9\u6848\uff0c\u5305\u62ec\u50b3\u7d71\u8a08\u91cf\u7d93\u6fdf\u6a21\u578b\u3001CAREER \u548c\u5177\u6709\u60c5\u5883\u5b78\u7fd2\u7684 LLM\uff0c\u5373\u4f7f LLM \u539f\u5247\u4e0a\u53ef\u4ee5\u9810\u6e2c\u8abf\u67e5\u8cc7\u6599\u4e2d\u4e0d\u5141\u8a31\u7684\u8077\u7a31\u3002\u6b64\u5916\uff0c\u6211\u5011\u8868\u660e\uff0c\u6211\u5011\u5fae\u8abf\u5f8c\u7684\u57fa\u65bc LLM \u7684\u6a21\u578b\u7684\u9810\u6e2c\u6bd4\u73fe\u6210\u7684 LLM \u6a21\u578b\u548c CAREER \u66f4\u80fd\u4ee3\u8868\u5404\u7a2e\u52de\u52d5\u529b\u5b50\u7fa4\u9ad4\u7684\u8077\u696d\u8ecc\u8de1\u3002\u6211\u5011\u9032\u884c\u5be6\u9a57\u548c\u5206\u6790\uff0c\u91cd\u9ede\u8aaa\u660e\u6211\u5011\u6a21\u578b\u5728\u4ee3\u8868\u6027\u9810\u6e2c\u6548\u80fd\u65b9\u9762\u7372\u5f97\u63d0\u5347\u7684\u4f86\u6e90\u3002", "author": "Tianyu Du et.al.", "authors": "Tianyu Du, Ayush Kanodia, Herman Brunborg, Keyon Vafa, Susan Athey", "id": "2406.17972v1", "paper_url": "http://arxiv.org/abs/2406.17972v1", "repo": "null"}}