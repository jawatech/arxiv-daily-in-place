
### LLM
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-07-17**|**OMG-Net: A Deep Learning Framework Deploying Segment Anything to Detect Pan-Cancer Mitotic Figures from Haematoxylin and Eosin-Stained Slides**|Zhuoyan Shen et.al.|[2407.12773v1](http://arxiv.org/abs/2407.12773v1)|null|
|**2024-07-17**|**LMMs-Eval: Reality Check on the Evaluation of Large Multimodal Models**|Kaichen Zhang et.al.|[2407.12772v1](http://arxiv.org/abs/2407.12772v1)|[link](https://github.com/evolvinglmms-lab/lmms-eval)|
|**2024-07-17**|**The Role of Network and Identity in the Diffusion of Hashtags**|Aparna Ananthasubramaniam et.al.|[2407.12771v1](http://arxiv.org/abs/2407.12771v1)|null|
|**2024-07-17**|**LookupViT: Compressing visual information to a limited number of tokens**|Rajat Koner et.al.|[2407.12753v1](http://arxiv.org/abs/2407.12753v1)|null|
|**2024-07-17**|**HDLCopilot: Hardware Design Library Querying with Natural Language**|Manar Abdelatty et.al.|[2407.12749v1](http://arxiv.org/abs/2407.12749v1)|null|
|**2024-07-17**|**CHOSEN: Compilation to Hardware Optimization Stack for Efficient Vision Transformer Inference**|Mohammad Erfan Sadeghi et.al.|[2407.12736v1](http://arxiv.org/abs/2407.12736v1)|null|
|**2024-07-17**|**A LLM Benchmark based on the Minecraft Builder Dialog Agent Task**|Chris Madge et.al.|[2407.12734v1](http://arxiv.org/abs/2407.12734v1)|null|
|**2024-07-17**|**RoDE: Linear Rectified Mixture of Diverse Experts for Food Large Multi-Modal Models**|Pengkun Jiao et.al.|[2407.12730v1](http://arxiv.org/abs/2407.12730v1)|null|
|**2024-07-17**|**Is Sarcasm Detection A Step-by-Step Reasoning Process in Large Language Models?**|Ben Yao et.al.|[2407.12725v1](http://arxiv.org/abs/2407.12725v1)|null|
|**2024-07-17**|**An Evaluation of Continual Learning for Advanced Node Semiconductor Defect Inspection**|Amit Prasad et.al.|[2407.12724v1](http://arxiv.org/abs/2407.12724v1)|null|
|**2024-07-17**|**Subgraph-Aware Training of Text-based Methods for Knowledge Graph Completion**|Youmin Ko et.al.|[2407.12703v1](http://arxiv.org/abs/2407.12703v1)|null|
|**2024-07-17**|**TransCAD: A Hierarchical Transformer for CAD Sequence Inference from Point Clouds**|Elona Dupont et.al.|[2407.12702v1](http://arxiv.org/abs/2407.12702v1)|null|
|**2024-07-17**|**GraphMuse: A Library for Symbolic Music Graph Processing**|Emmanouil Karystinaios et.al.|[2407.12671v1](http://arxiv.org/abs/2407.12671v1)|[link](https://github.com/manoskary/graphmuse)|
|**2024-07-17**|**Enhancing the Utility of Privacy-Preserving Cancer Classification using Synthetic Data**|Richard Osuala et.al.|[2407.12669v1](http://arxiv.org/abs/2407.12669v1)|null|
|**2024-07-17**|**Patch-Level Training for Large Language Models**|Chenze Shao et.al.|[2407.12665v1](http://arxiv.org/abs/2407.12665v1)|[link](https://github.com/shaochenze/patchtrain)|
|**2024-07-17**|**Is That Rain? Understanding Effects on Visual Odometry Performance for Autonomous UAVs and Efficient DNN-based Rain Classification at the Edge**|Andrea Albanese et.al.|[2407.12663v1](http://arxiv.org/abs/2407.12663v1)|null|
|**2024-07-17**|**Zero-shot Text-guided Infinite Image Synthesis with LLM guidance**|Soyeong Kwon et.al.|[2407.12642v1](http://arxiv.org/abs/2407.12642v1)|null|
|**2024-07-17**|**A Methodology Establishing Linear Convergence of Adaptive Gradient Methods under PL Inequality**|Kushal Chakrabarti et.al.|[2407.12629v1](http://arxiv.org/abs/2407.12629v1)|null|
|**2024-07-17**|**Domain-specific or Uncertainty-aware models: Does it really make a difference for biomedical text classification?**|Aman Sinha et.al.|[2407.12626v1](http://arxiv.org/abs/2407.12626v1)|null|
|**2024-07-17**|**Harnessing the Power of Artificial Intelligence to Vitalize Endangered Indigenous Languages: Technologies and Experiences**|Claudio Pinhanez et.al.|[2407.12620v1](http://arxiv.org/abs/2407.12620v1)|null|
|**2024-07-17**|**Missing Modality Prediction for Unpaired Multimodal Learning via Joint Embedding of Unimodal Models**|Donggeun Kim et.al.|[2407.12616v1](http://arxiv.org/abs/2407.12616v1)|null|
|**2024-07-17**|**AudienceView: AI-Assisted Interpretation of Audience Feedback in Journalism**|William Brannon et.al.|[2407.12613v1](http://arxiv.org/abs/2407.12613v1)|null|
|**2024-07-17**|**Instance-wise Uncertainty for Class Imbalance in Semantic Segmentation**|Luís Almeida et.al.|[2407.12609v1](http://arxiv.org/abs/2407.12609v1)|null|
|**2024-07-17**|**Benchmarking Robust Self-Supervised Learning Across Diverse Downstream Tasks**|Antoni Kowalczuk et.al.|[2407.12588v1](http://arxiv.org/abs/2407.12588v1)|[link](https://github.com/layer6ai-labs/ssl-robustness)|
|**2024-07-17**|**Towards Understanding Unsafe Video Generation**|Yan Pang et.al.|[2407.12581v1](http://arxiv.org/abs/2407.12581v1)|[link](https://github.com/py85252876/uvd)|
|**2024-07-17**|**E5-V: Universal Embeddings with Multimodal Large Language Models**|Ting Jiang et.al.|[2407.12580v1](http://arxiv.org/abs/2407.12580v1)|[link](https://github.com/kongds/e5-v)|
|**2024-07-17**|**The Fabrication of Reality and Fantasy: Scene Generation with LLM-Assisted Prompt Interpretation**|Yi Yao et.al.|[2407.12579v1](http://arxiv.org/abs/2407.12579v1)|null|
|**2024-07-17**|**IICPilot: An Intelligent Integrated Circuit Backend Design Framework Using Open EDA**|Zesong Jiang et.al.|[2407.12576v1](http://arxiv.org/abs/2407.12576v1)|null|
|**2024-07-17**|**Abstraction Alignment: Comparing Model and Human Conceptual Relationships**|Angie Boggust et.al.|[2407.12543v1](http://arxiv.org/abs/2407.12543v1)|[link](https://github.com/mitvis/abstraction-alignment)|
|**2024-07-17**|**Towards Collaborative Intelligence: Propagating Intentions and Reasoning for Multi-Agent Coordination with Large Language Models**|Xihe Qiu et.al.|[2407.12532v1](http://arxiv.org/abs/2407.12532v1)|null|
|**2024-07-17**|**Crafting the Path: Robust Query Rewriting for Information Retrieval**|Ingeol Baek et.al.|[2407.12529v1](http://arxiv.org/abs/2407.12529v1)|null|
|**2024-07-17**|**On the Complexity of Identification in Linear Structural Causal Models**|Julian Dörfler et.al.|[2407.12528v1](http://arxiv.org/abs/2407.12528v1)|null|
|**2024-07-17**|**Struct-X: Enhancing Large Language Models Reasoning with Structured Data**|Xiaoyu Tan et.al.|[2407.12522v1](http://arxiv.org/abs/2407.12522v1)|null|
|**2024-07-17**|**On Initializing Transformers with Pre-trained Embeddings**|Ha Young Kim et.al.|[2407.12514v1](http://arxiv.org/abs/2407.12514v1)|null|
|**2024-07-17**|**$\textit{GeoHard}$: Towards Measuring Class-wise Hardness through Modelling Class Semantics**|Fengyu Cai et.al.|[2407.12512v1](http://arxiv.org/abs/2407.12512v1)|null|
|**2024-07-17**|**MERLIN: Multimodal Embedding Refinement via LLM-based Iterative Navigation for Text-Video Retrieval-Rerank Pipeline**|Donghoon Han et.al.|[2407.12508v1](http://arxiv.org/abs/2407.12508v1)|null|
|**2024-07-17**|**Case2Code: Learning Inductive Reasoning with Synthetic Data**|Yunfan Shao et.al.|[2407.12504v1](http://arxiv.org/abs/2407.12504v1)|null|
|**2024-07-17**|**Automate or Assist? The Role of Computational Models in Identifying Gendered Discourse in US Capital Trial Transcripts**|Andrea W Wen-Yi et.al.|[2407.12500v1](http://arxiv.org/abs/2407.12500v1)|null|
|**2024-07-17**|**Evaluating Linguistic Capabilities of Multimodal LLMs in the Lens of Few-Shot Learning**|Mustafa Dogan et.al.|[2407.12498v1](http://arxiv.org/abs/2407.12498v1)|null|
|**2024-07-17**|**Test-Time Adaptation with State-Space Models**|Mona Schirmer et.al.|[2407.12492v1](http://arxiv.org/abs/2407.12492v1)|null|
|**2024-07-17**|**Pretraining Data and Tokenizer for Indic LLM**|Rahul Kumar et.al.|[2407.12481v1](http://arxiv.org/abs/2407.12481v1)|null|
|**2024-07-17**|**A Novel Dependency Framework for Enhancing Discourse Data Analysis**|Kun Sun et.al.|[2407.12473v1](http://arxiv.org/abs/2407.12473v1)|null|
|**2024-07-17**|**Characterization of Political Polarized Users Attacked by Language Toxicity on Twitter**|Wentao Xu et.al.|[2407.12471v1](http://arxiv.org/abs/2407.12471v1)|null|
|**2024-07-17**|**Continual Learning for Temporal-Sensitive Question Answering**|Wanqi Yang et.al.|[2407.12470v1](http://arxiv.org/abs/2407.12470v1)|null|
|**2024-07-17**|**Search Engines, LLMs or Both? Evaluating Information Seeking Strategies for Answering Health Questions**|Fernández-Pichel Marcos et.al.|[2407.12468v1](http://arxiv.org/abs/2407.12468v1)|null|
|**2024-07-17**|**Across Platforms and Languages: Dutch Influencers and Legal Disclosures on Instagram, YouTube and TikTok**|Haoyang Gui et.al.|[2407.12451v1](http://arxiv.org/abs/2407.12451v1)|null|
|**2024-07-17**|**Close the Sim2real Gap via Physically-based Structured Light Synthetic Data Simulation**|Kaixin Bai et.al.|[2407.12449v1](http://arxiv.org/abs/2407.12449v1)|null|
|**2024-07-17**|**Sharif-STR at SemEval-2024 Task 1: Transformer as a Regression Model for Fine-Grained Scoring of Textual Semantic Relations**|Seyedeh Fatemeh Ebrahimi et.al.|[2407.12426v1](http://arxiv.org/abs/2407.12426v1)|[link](https://github.com/sharif-slpl/sharif-str)|
|**2024-07-17**|**Navigating the Noisy Crowd: Finding Key Information for Claim Verification**|Haisong Gong et.al.|[2407.12425v1](http://arxiv.org/abs/2407.12425v1)|null|
|**2024-07-17**|**StuGPTViz: A Visual Analytics Approach to Understand Student-ChatGPT Interactions**|Zixin Chen et.al.|[2407.12423v1](http://arxiv.org/abs/2407.12423v1)|null|
|**2024-07-17**|**SafePowerGraph: Safety-aware Evaluation of Graph Neural Networks for Transmission Power Grids**|Salah Ghamizi et.al.|[2407.12421v1](http://arxiv.org/abs/2407.12421v1)|null|
|**2024-07-17**|**Proximity-based Self-Federated Learning**|Davide Domini et.al.|[2407.12410v1](http://arxiv.org/abs/2407.12410v1)|null|
|**2024-07-17**|**TurkishMMLU: Measuring Massive Multitask Language Understanding in Turkish**|Arda Yüksel et.al.|[2407.12402v1](http://arxiv.org/abs/2407.12402v1)|null|
|**2024-07-17**|**Mamba-PTQ: Outlier Channels in Recurrent Large Language Models**|Alessandro Pierro et.al.|[2407.12397v1](http://arxiv.org/abs/2407.12397v1)|null|
|**2024-07-17**|**PersLLM: A Personified Training Approach for Large Language Models**|Zheni Zeng et.al.|[2407.12393v1](http://arxiv.org/abs/2407.12393v1)|[link](https://github.com/ellenzzn/persllm)|
|**2024-07-17**|**LLM Inference Serving: Survey of Recent Advances and Opportunities**|Baolin Li et.al.|[2407.12391v1](http://arxiv.org/abs/2407.12391v1)|null|
|**2024-07-17**|**Morphosyntactic Analysis for CHILDES**|Houjun Liu et.al.|[2407.12389v1](http://arxiv.org/abs/2407.12389v1)|null|
|**2024-07-17**|**Deep Learning-based Sentiment Analysis of Olympics Tweets**|Indranil Bandyopadhyay et.al.|[2407.12376v1](http://arxiv.org/abs/2407.12376v1)|null|
|**2024-07-17**|**HIMO: A New Benchmark for Full-Body Human Interacting with Multiple Objects**|Xintao Lv et.al.|[2407.12371v1](http://arxiv.org/abs/2407.12371v1)|null|
|**2024-07-17**|**NavGPT-2: Unleashing Navigational Reasoning Capability for Large Vision-Language Models**|Gengze Zhou et.al.|[2407.12366v1](http://arxiv.org/abs/2407.12366v1)|[link](https://github.com/gengzezhou/navgpt-2)|
|**2024-07-17**|**Conversational Query Reformulation with the Guidance of Retrieved Documents**|Jeonghyun Park et.al.|[2407.12363v1](http://arxiv.org/abs/2407.12363v1)|null|
|**2024-07-17**|**ProcTag: Process Tagging for Assessing the Efficacy of Document Instruction Data**|Yufan Shen et.al.|[2407.12358v1](http://arxiv.org/abs/2407.12358v1)|[link](https://github.com/alibabaresearch/advancedliteratemachinery)|
|**2024-07-17**|**SENTAUR: Security EnhaNced Trojan Assessment Using LLMs Against Undesirable Revisions**|Jitendra Bhandari et.al.|[2407.12352v1](http://arxiv.org/abs/2407.12352v1)|null|
|**2024-07-17**|**The Better Angels of Machine Personality: How Personality Relates to LLM Safety**|Jie Zhang et.al.|[2407.12344v1](http://arxiv.org/abs/2407.12344v1)|[link](https://github.com/tmylla/Persafety)|
|**2024-07-17**|**Word Embedding Dimension Reduction via Weakly-Supervised Feature Selection**|Jintang Xue et.al.|[2407.12342v1](http://arxiv.org/abs/2407.12342v1)|null|
|**2024-07-17**|**M2DS: Multilingual Dataset for Multi-document Summarisation**|Kushan Hewapathirana et.al.|[2407.12336v1](http://arxiv.org/abs/2407.12336v1)|null|
|**2024-07-17**|**I2AM: Interpreting Image-to-Image Latent Diffusion Models via Attribution Maps**|Junseo Park et.al.|[2407.12331v1](http://arxiv.org/abs/2407.12331v1)|null|
|**2024-07-17**|**Uncertainty Calibration with Energy Based Instance-wise Scaling in the Wild Dataset**|Mijoo Kim et.al.|[2407.12330v1](http://arxiv.org/abs/2407.12330v1)|[link](https://github.com/mijoo308/energy-calibration)|
|**2024-07-17**|**Spectra: A Comprehensive Study of Ternary, Quantized, and FP16 Language Models**|Ayush Kaushal et.al.|[2407.12327v1](http://arxiv.org/abs/2407.12327v1)|null|
|**2024-07-17**|**ModalChorus: Visual Probing and Alignment of Multi-modal Embeddings via Modal Fusion Map**|Yilin Ye et.al.|[2407.12315v1](http://arxiv.org/abs/2407.12315v1)|null|
|**2024-07-17**|**MEDFuse: Multimodal EHR Data Fusion with Masked Lab-Test Modeling and Large Language Models**|Thao Minh Nguyen Phan et.al.|[2407.12309v1](http://arxiv.org/abs/2407.12309v1)|null|
|**2024-07-17**|**Any Target Can be Offense: Adversarial Example Generation via Generalized Latent Infection**|Youheng Sun et.al.|[2407.12292v1](http://arxiv.org/abs/2407.12292v1)|[link](https://github.com/vl-group/gaker)|
|**2024-07-17**|**Chip Placement with Diffusion**|Vint Lee et.al.|[2407.12282v1](http://arxiv.org/abs/2407.12282v1)|null|
|**2024-07-17**|**Turning Generative Models Degenerate: The Power of Data Poisoning Attacks**|Shuli Jiang et.al.|[2407.12281v1](http://arxiv.org/abs/2407.12281v1)|null|
|**2024-07-17**|**Multimodal Reranking for Knowledge-Intensive Visual Question Answering**|Haoyang Wen et.al.|[2407.12277v1](http://arxiv.org/abs/2407.12277v1)|null|
|**2024-07-17**|**In-Context Probing Approximates Influence Function for Data Valuation**|Cathy Jiao et.al.|[2407.12259v1](http://arxiv.org/abs/2407.12259v1)|null|
|**2024-07-17**|**Lacuna Language Learning: Leveraging RNNs for Ranked Text Completion in Digitized Coptic Manuscripts**|Lauren Levine et.al.|[2407.12247v1](http://arxiv.org/abs/2407.12247v1)|null|
|**2024-07-17**|**Conditional Quantile Estimation for Uncertain Watch Time in Short-Video Recommendation**|Chengzhi Lin et.al.|[2407.12223v1](http://arxiv.org/abs/2407.12223v1)|null|
|**2024-07-17**|**Questionable practices in machine learning**|Gavin Leech et.al.|[2407.12220v1](http://arxiv.org/abs/2407.12220v1)|null|
|**2024-07-16**|**A Language Modeling Approach to Diacritic-Free Hebrew TTS**|Amit Roth et.al.|[2407.12206v1](http://arxiv.org/abs/2407.12206v1)|null|
|**2024-07-16**|**This Probably Looks Exactly Like That: An Invertible Prototypical Network**|Zachariah Carmichael et.al.|[2407.12200v1](http://arxiv.org/abs/2407.12200v1)|[link](https://github.com/craymichael/protoflow)|
|**2024-07-16**|**Towards Interpretable Visuo-Tactile Predictive Models for Soft Robot Interactions**|Enrico Donato et.al.|[2407.12197v1](http://arxiv.org/abs/2407.12197v1)|null|
|**2024-07-16**|**MASIVE: Open-Ended Affective State Identification in English and Spanish**|Nicholas Deas et.al.|[2407.12196v1](http://arxiv.org/abs/2407.12196v1)|null|
|**2024-07-16**|**Satisficing Exploration for Deep Reinforcement Learning**|Dilip Arumugam et.al.|[2407.12185v1](http://arxiv.org/abs/2407.12185v1)|null|
|**2024-07-16**|**GPT-4V Cannot Generate Radiology Reports Yet**|Yuyang Jiang et.al.|[2407.12176v1](http://arxiv.org/abs/2407.12176v1)|[link](https://github.com/yuyangj0/gpt-4v-evaluation-radiology-report)|
|**2024-07-16**|**Beta Sampling is All You Need: Efficient Image Generation Strategy for Diffusion Models using Stepwise Spectral Analysis**|Haeil Lee et.al.|[2407.12173v1](http://arxiv.org/abs/2407.12173v1)|null|
|**2024-07-16**|**Building AI Agents for Autonomous Clouds: Challenges and Design Principles**|Manish Shetty et.al.|[2407.12165v1](http://arxiv.org/abs/2407.12165v1)|null|
|**2024-07-16**|**Subject-driven Text-to-Image Generation via Preference-based Reinforcement Learning**|Yanting Miao et.al.|[2407.12164v1](http://arxiv.org/abs/2407.12164v1)|null|
|**2024-07-16**|**Interpretability in Action: Exploratory Analysis of VPT, a Minecraft Agent**|Karolis Jucys et.al.|[2407.12161v1](http://arxiv.org/abs/2407.12161v1)|null|
|**2024-07-16**|**Predicting Emotion Intensity in Polish Political Texts: Comparing Supervised Models and Large Language Models in a Resource-Poor Language**|Hubert Plisiecki et.al.|[2407.12141v1](http://arxiv.org/abs/2407.12141v1)|null|
|**2024-07-16**|**LLMs-in-the-loop Part-1: Expert Small AI Models for Bio-Medical Text Translation**|Bunyamin Keles et.al.|[2407.12126v1](http://arxiv.org/abs/2407.12126v1)|null|
|**2024-07-16**|**A Graph-based Adversarial Imitation Learning Framework for Reliable & Realtime Fleet Scheduling in Urban Air Mobility**|Prithvi Poddar et.al.|[2407.12113v1](http://arxiv.org/abs/2407.12113v1)|null|
|**2024-07-16**|**Private prediction for large-scale synthetic text generation**|Kareem Amin et.al.|[2407.12108v1](http://arxiv.org/abs/2407.12108v1)|null|
|**2024-07-16**|**Better RAG using Relevant Information Gain**|Marc Pickett et.al.|[2407.12101v1](http://arxiv.org/abs/2407.12101v1)|null|
|**2024-07-16**|**Identifying Speakers in Dialogue Transcripts: A Text-based Approach Using Pretrained Language Models**|Minh Nguyen et.al.|[2407.12094v1](http://arxiv.org/abs/2407.12094v1)|null|
|**2024-07-16**|**GoldFinch: High Performance RWKV/Transformer Hybrid with Linear Pre-Fill and Extreme KV-Cache Compression**|Daniel Goldstein et.al.|[2407.12077v1](http://arxiv.org/abs/2407.12077v1)|[link](https://github.com/SmerkyG/GoldFinch-paper)|
|**2024-07-16**|**Does Refusal Training in LLMs Generalize to the Past Tense?**|Maksym Andriushchenko et.al.|[2407.11969v1](http://arxiv.org/abs/2407.11969v1)|[link](https://github.com/tml-epfl/llm-past-tense)|
|**2024-07-16**|**Efficient Training with Denoised Neural Weights**|Yifan Gong et.al.|[2407.11966v1](http://arxiv.org/abs/2407.11966v1)|null|
|**2024-07-16**|**NeedleBench: Can LLMs Do Retrieval and Reasoning in 1 Million Context Window?**|Mo Li et.al.|[2407.11963v1](http://arxiv.org/abs/2407.11963v1)|[link](https://github.com/open-compass/opencompass)|
|**2024-07-16**|**Motion-Oriented Compositional Neural Radiance Fields for Monocular Dynamic Human Modeling**|Jaehyeok Kim et.al.|[2407.11962v1](http://arxiv.org/abs/2407.11962v1)|null|

#### Abstracts
##### **OMG-Net: A Deep Learning Framework Deploying Segment Anything to Detect Pan-Cancer Mitotic Figures from Haematoxylin and Eosin-Stained Slides**
2407.12773v1 by Zhuoyan Shen, Mikael Simard, Douglas Brand, Vanghelita Andrei, Ali Al-Khader, Fatine Oumlil, Katherine Trevers, Thomas Butters, Simon Haefliger, Eleanna Kara, Fernanda Amary, Roberto Tirabosco, Paul Cool, Gary Royle, Maria A. Hawkins, Adrienne M. Flanagan, Charles-Antoine Collins Fekete

Mitotic activity is an important feature for grading several cancer types.
Counting mitotic figures (MFs) is a time-consuming, laborious task prone to
inter-observer variation. Inaccurate recognition of MFs can lead to incorrect
grading and hence potential suboptimal treatment. In this study, we propose an
artificial intelligence (AI)-aided approach to detect MFs in digitised
haematoxylin and eosin-stained whole slide images (WSIs). Advances in this area
are hampered by the limited number and types of cancer datasets of MFs. Here we
establish the largest pan-cancer dataset of mitotic figures by combining an
in-house dataset of soft tissue tumours (STMF) with five open-source mitotic
datasets comprising multiple human cancers and canine specimens (ICPR, TUPAC,
CCMCT, CMC and MIDOG++). This new dataset identifies 74,620 MFs and 105,538
mitotic-like figures. We then employed a two-stage framework (the Optimised
Mitoses Generator Network (OMG-Net) to classify MFs. The framework first
deploys the Segment Anything Model (SAM) to automate the contouring of MFs and
surrounding objects. An adapted ResNet18 is subsequently trained to classify
MFs. OMG-Net reaches an F1-score of 0.84 on pan-cancer MF detection (breast
carcinoma, neuroendocrine tumour and melanoma), largely outperforming the
previous state-of-the-art MIDOG++ benchmark model on its hold-out testing set
(e.g. +16% F1-score on breast cancer detection, p<0.001) thereby providing
superior accuracy in detecting MFs on various types of tumours obtained with
different scanners.

摘要：有絲分裂活動是評分多種癌症類型的一個重要特徵。
計算有絲分裂圖形 (MF) 是一項耗時且費力的任務，容易產生觀察者間的差異。對 MF 的不準確識別可能導致評分不正確，進而導致潛在的次優治療。在本研究中，我們提出了一種人工智能 (AI) 輔助方法來檢測數字化蘇木精和曙紅染色全玻片圖像 (WSI) 中的 MF。該領域的進展受到 MF 癌症數據集數量和類型有限的阻礙。在此，我們通過將軟組織腫瘤 (STMF) 的內部數據集與五個包含多種人類癌症和犬類標本的開源有絲分裂數據集（ICPR、TUPAC、CCMCT、CMC 和 MIDOG++）相結合，建立了最大的泛癌有絲分裂圖形數據集。這個新數據集識別出 74,620 個 MF 和 105,538 個類似有絲分裂的圖形。然後，我們採用了一個兩階段框架（優化的有絲分裂生成器網絡 (OMG-Net)）來對 MF 進行分類。該框架首先部署分段任何模型 (SAM) 來自動勾勒 MF 和周圍物體的輪廓。隨後訓練一個適應的 ResNet18 來對 MF 進行分類。OMG-Net 在泛癌 MF 檢測（乳腺癌、神經內分泌腫瘤和黑色素瘤）上達到 0.84 的 F1 分數，在保留測試集上大幅優於之前的最先進 MIDOG++ 基準模型（例如乳腺癌檢測的 F1 分數提高了 16%，p<0.001），從而提供了使用不同掃描儀獲得的各種腫瘤類型中檢測 MF 的更高準確度。

##### **LMMs-Eval: Reality Check on the Evaluation of Large Multimodal Models**
2407.12772v1 by Kaichen Zhang, Bo Li, Peiyuan Zhang, Fanyi Pu, Joshua Adrian Cahyono, Kairui Hu, Shuai Liu, Yuanhan Zhang, Jingkang Yang, Chunyuan Li, Ziwei Liu

The advances of large foundation models necessitate wide-coverage, low-cost,
and zero-contamination benchmarks. Despite continuous exploration of language
model evaluations, comprehensive studies on the evaluation of Large Multi-modal
Models (LMMs) remain limited. In this work, we introduce LMMS-EVAL, a unified
and standardized multimodal benchmark framework with over 50 tasks and more
than 10 models to promote transparent and reproducible evaluations. Although
LMMS-EVAL offers comprehensive coverage, we find it still falls short in
achieving low cost and zero contamination. To approach this evaluation
trilemma, we further introduce LMMS-EVAL LITE, a pruned evaluation toolkit that
emphasizes both coverage and efficiency. Additionally, we present Multimodal
LIVEBENCH that utilizes continuously updating news and online forums to assess
models' generalization abilities in the wild, featuring a low-cost and
zero-contamination evaluation approach. In summary, our work highlights the
importance of considering the evaluation trilemma and provides practical
solutions to navigate the trade-offs in evaluating large multi-modal models,
paving the way for more effective and reliable benchmarking of LMMs. We
opensource our codebase and maintain leaderboard of LIVEBENCH at
https://github.com/EvolvingLMMs-Lab/lmms-eval and
https://huggingface.co/spaces/lmms-lab/LiveBench.

摘要：大型基礎模型的進展需要廣泛涵蓋、低成本且零污染的基準。儘管持續探索語言模型評估，但對大型多模態模型 (LMM) 評估的全面研究仍然有限。在這項工作中，我們引入了 LMMS-EVAL，一個統一且標準化的多模態基準架構，包含超過 50 項任務和 10 個以上模型，以促進透明且可重現的評估。儘管 LMMS-EVAL 提供了全面的涵蓋範圍，但我們發現它在實現低成本和零污染方面仍然不足。為了解決這個評估三難困境，我們進一步引入了 LMMS-EVAL LITE，這是一個精簡的評估工具包，強調涵蓋範圍和效率。此外，我們展示了多模態 LIVEBENCH，它利用持續更新的新聞和線上論壇來評估模型在野外的概括能力，採用低成本且零污染的評估方法。總之，我們的研究強調了考慮評估三難困境的重要性，並提供了實用的解決方案來權衡大型多模態模型的評估，為更有效和可靠的 LMM 基準測試鋪平道路。我們在 https://github.com/EvolvingLMMs-Lab/lmms-eval 和 https://huggingface.co/spaces/lmms-lab/LiveBench 開源我們的程式碼庫並維護 LIVEBENCH 的排行榜。

##### **The Role of Network and Identity in the Diffusion of Hashtags**
2407.12771v1 by Aparna Ananthasubramaniam, Yufei Zhu, David Jurgens, Daniel Romero

Although the spread of behaviors is influenced by many social factors,
existing literature tends to study the effects of single factors -- most often,
properties of the social network -- on the final cascade. In order to move
towards a more integrated view of cascades, this paper offers the first
comprehensive investigation into the role of two social factors in the
diffusion of 1,337 popular hashtags representing the production of novel
culture on Twitter: 1) the topology of the Twitter social network and 2)
performance of each user's probable demographic identity. Here, we show that
cascades are best modeled using a combination of network and identity, rather
than either factor alone. This combined model best reproduces a composite index
of ten cascade properties across all 1,337 hashtags. However, there is
important heterogeneity in what social factors are required to reproduce
different properties of hashtag cascades. For instance, while a combined
network+identity model best predicts the popularity of cascades, a network-only
model has better performance in predicting cascade growth and an identity-only
model in adopter composition. We are able to predict what type of hashtag is
best modeled by each combination of features and use this to further improve
performance. Additionally, consistent with prior literature on the combined
network+identity model most outperforms the single-factor counterfactuals among
hashtags used for expressing racial or regional identity, stance-taking,
talking about sports, or variants of existing cultural trends with very slow-
or fast-growing communicative need. In sum, our results imply the utility of
multi-factor models in predicting cascades, in order to account for the varied
ways in which network, identity, and other social factors play a role in the
diffusion of hashtags on Twitter.

摘要：<paragraph>儘管行為的散播受到許多社會因素的影響，現有的文獻傾向於研究單一因素的影響——最常見的是，社群網路的特性——對最終的級聯效應。為了朝向更整合的級聯觀點邁進，本文首次針對兩個社會因素在 1,337 個流行主題標籤（代表 Twitter 上新興文化的產生）的散播中所扮演的角色進行全面性的調查：1) Twitter 社群網路的拓撲結構，以及 2) 每位使用者的可能人口統計身分的表現。在此，我們展示出級聯效應最適合使用網路和身分組合建模，而非僅使用單一因素。此組合模型最能重現所有 1,337 個主題標籤的十項級聯特性的複合指標。然而，在重現主題標籤級聯的不同特性時，社會因素需求存在著重要的異質性。例如，雖然網路加身分組合模型最能預測級聯效應的普及性，但僅網路模型在預測級聯成長方面有較佳的表現，而僅身分模型則在採用者組成方面有較佳的表現。我們能夠預測哪種類型的主題標籤最適合由各項特徵組合建模，並利用此進一步提升表現。此外，與先前關於網路加身分組合模型的文獻一致，在用於表達種族或區域身分、立場採取、討論運動，或現有文化趨勢的變體（傳播需求極慢或極快）的主題標籤中，網路加身分組合模型的表現優於單一因素的反事實。總之，我們的結果暗示了多因素模型在預測級聯效應中的效用，以說明網路、身分和其他社會因素在 Twitter 上主題標籤的散播中所扮演的角色的多種方式。</paragraph>

##### **LookupViT: Compressing visual information to a limited number of tokens**
2407.12753v1 by Rajat Koner, Gagan Jain, Prateek Jain, Volker Tresp, Sujoy Paul

Vision Transformers (ViT) have emerged as the de-facto choice for numerous
industry grade vision solutions. But their inference cost can be prohibitive
for many settings, as they compute self-attention in each layer which suffers
from quadratic computational complexity in the number of tokens. On the other
hand, spatial information in images and spatio-temporal information in videos
is usually sparse and redundant. In this work, we introduce LookupViT, that
aims to exploit this information sparsity to reduce ViT inference cost.
LookupViT provides a novel general purpose vision transformer block that
operates by compressing information from higher resolution tokens to a fixed
number of tokens. These few compressed tokens undergo meticulous processing,
while the higher-resolution tokens are passed through computationally cheaper
layers. Information sharing between these two token sets is enabled through a
bidirectional cross-attention mechanism. The approach offers multiple
advantages - (a) easy to implement on standard ML accelerators (GPUs/TPUs) via
standard high-level operators, (b) applicable to standard ViT and its variants,
thus generalizes to various tasks, (c) can handle different tokenization and
attention approaches. LookupViT also offers flexibility for the compressed
tokens, enabling performance-computation trade-offs in a single trained model.
We show LookupViT's effectiveness on multiple domains - (a) for
image-classification (ImageNet-1K and ImageNet-21K), (b) video classification
(Kinetics400 and Something-Something V2), (c) image captioning (COCO-Captions)
with a frozen encoder. LookupViT provides $2\times$ reduction in FLOPs while
upholding or improving accuracy across these domains. In addition, LookupViT
also demonstrates out-of-the-box robustness and generalization on image
classification (ImageNet-C,R,A,O), improving by up to $4\%$ over ViT.

摘要：視覺轉換器 (ViT) 已成為眾多產業級視覺解決方案的事實標準選擇。但其推理成本對於許多設定而言可能是過高的，因為它們會在每一層中計算自注意力，而自注意力會因為代幣數量而產生二次運算複雜度。另一方面，影像中的空間資訊和影片中的時空資訊通常是稀疏且冗餘的。在這項工作中，我們引入了 LookupViT，其目標是利用此資訊稀疏性來降低 ViT 推理成本。LookupViT 提供了一個新穎的通用視覺轉換器區塊，其運作方式是將來自較高解析度代幣的資訊壓縮成固定數量的代幣。這些少數壓縮的代幣會經過仔細處理，而較高解析度的代幣則會通過計算成本較低的層。這些兩個代幣集合之間的資訊共享是透過雙向交叉注意力機制啟用的。此方法提供了多項優點：(a) 透過標準高階運算子在標準 ML 加速器 (GPU/TPU) 上易於實作，(b) 適用於標準 ViT 及其變體，因此能概括到各種任務，(c) 可以處理不同的代幣化和注意力方法。LookupViT 也為壓縮的代幣提供了靈活性，讓效能與運算在單一訓練模型中進行權衡。我們在多個領域展示了 LookupViT 的效能：(a) 影像分類 (ImageNet-1K 和 ImageNet-21K)，(b) 影片分類 (Kinetics400 和 Something-Something V2)，(c) 影像標題 (COCO-Captions) 使用凍結編碼器。LookupViT 提供了 FLOP 減少 2 倍，同時維持或提升這些領域的準確度。此外，LookupViT 也在影像分類 (ImageNet-C,R,A,O) 上展示了開箱即用的穩健性和概括性，比 ViT 提升了 4%。

##### **HDLCopilot: Hardware Design Library Querying with Natural Language**
2407.12749v1 by Manar Abdelatty, Sherief Reda

Hardware design engineers routinely work with multiple Process Design Kits
(PDKs) from various fabrication labs, each containing several standard cell
libraries, optimized for specific metric such as speed, power, or density.
These libraries include multiple views such as liberty files for timing
information, LEF files for abstract layout details, and technology LEF for
process design rules. Navigating this complex landscape to retrieve specific
information about gates or design rules is often time-consuming and
error-prone. To address this, we present HDLCopilot, an LLM-powered PDK query
system that allows engineers to streamline interactions with PDKs in natural
language format, making information retrieval accurate and more efficient.
HDLCopilot achieves an accuracy of 94.23\% on an evaluation set comprised of
diverse and complex natural language queries. HDLCopilot positions itself as a
powerful assistant in the hardware design process, enhancing productivity and
reducing potential human errors.

摘要：硬體設計工程師會定期使用來自各種製造實驗室的數個處理設計套件 (PDK)，每個套件包含多個標準單元庫，針對特定指標（例如速度、功率或密度）進行最佳化。這些庫包含多種檢視，例如時序資訊的 Liberty 檔案、抽象配置詳細資料的 LEF 檔案，以及處理設計規則的技術 LEF。在這個複雜的環境中導覽以擷取閘極或設計規則的特定資訊，通常會耗時且容易出錯。為了解決這個問題，我們提出 HDLCopilot，這是一個由 LLM 驅動的 PDK 查詢系統，讓工程師能夠以自然語言格式簡化與 PDK 的互動，讓資訊擷取更準確且更有效率。HDLCopilot 在包含各種複雜自然語言查詢的評估集中，達到了 94.23% 的準確率。HDLCopilot 將自己定位為硬體設計流程中的強大助手，可提升生產力並減少潛在的人為錯誤。

##### **CHOSEN: Compilation to Hardware Optimization Stack for Efficient Vision Transformer Inference**
2407.12736v1 by Mohammad Erfan Sadeghi, Arash Fayyazi, Suhas Somashekar, Massoud Pedram

Vision Transformers (ViTs) represent a groundbreaking shift in machine
learning approaches to computer vision. Unlike traditional approaches, ViTs
employ the self-attention mechanism, which has been widely used in natural
language processing, to analyze image patches. Despite their advantages in
modeling visual tasks, deploying ViTs on hardware platforms, notably
Field-Programmable Gate Arrays (FPGAs), introduces considerable challenges.
These challenges stem primarily from the non-linear calculations and high
computational and memory demands of ViTs. This paper introduces CHOSEN, a
software-hardware co-design framework to address these challenges and offer an
automated framework for ViT deployment on the FPGAs in order to maximize
performance. Our framework is built upon three fundamental contributions:
multi-kernel design to maximize the bandwidth, mainly targeting benefits of
multi DDR memory banks, approximate non-linear functions that exhibit minimal
accuracy degradation, and efficient use of available logic blocks on the FPGA,
and efficient compiler to maximize the performance and memory-efficiency of the
computing kernels by presenting a novel algorithm for design space exploration
to find optimal hardware configuration that achieves optimal throughput and
latency. Compared to the state-of-the-art ViT accelerators, CHOSEN achieves a
1.5x and 1.42x improvement in the throughput on the DeiT-S and DeiT-B models.

摘要：視覺轉換器 (ViT) 代表機器學習方法在電腦視覺上突破性的轉變。與傳統方法不同，ViT 使用自注意力機制，該機制已廣泛用於自然語言處理中，用於分析影像區塊。儘管在建模視覺任務方面有優勢，但在硬體平台上部署 ViT，尤其是現場可程式邏輯閘陣列 (FPGA)，會帶來相當大的挑戰。這些挑戰主要源於 ViT 的非線性運算和高運算和記憶體需求。本文介紹 CHOSEN，一種軟體硬體共同設計架構，用於解決這些挑戰，並提供一個自動化架構，用於在 FPGA 上部署 ViT，以最大化效能。我們的架構建立在三個基本貢獻之上：多核心設計以最大化頻寬，主要針對多個 DDR 記憶體庫的好處、近似非線性函數，表現出最小的準確度下降，以及有效利用 FPGA 上的可用邏輯區塊，以及高效的編譯器，透過提出一個用於設計空間探索的新演算法，以最大化運算核心的效能和記憶體效率，以找到實現最佳處理量和延遲的最佳硬體配置。與最先進的 ViT 加速器相比，CHOSEN 在 DeiT-S 和 DeiT-B 模型上分別實現了 1.5 倍和 1.42 倍的處理量提升。

##### **A LLM Benchmark based on the Minecraft Builder Dialog Agent Task**
2407.12734v1 by Chris Madge, Massimo Poesio

In this work we proposing adapting the Minecraft builder task into an LLM
benchmark suitable for evaluating LLM ability in spatially orientated tasks,
and informing builder agent design. Previous works have proposed corpora with
varying complex structures, and human written instructions. We instead attempt
to provide a comprehensive synthetic benchmark for testing builder agents over
a series of distinct tasks that comprise of common building operations. We
believe this approach allows us to probe specific strengths and weaknesses of
different agents, and test the ability of LLMs in the challenging area of
spatial reasoning and vector based math.

摘要：在這項工作中，我們建議將 Minecraft 建造任務改編為 LLM 基準，以便評估 LLM 在空間定向任務中的能力，並告知建構器代理設計。先前的作品提出了具有不同複雜結構和人類書面說明的語料庫。我們反而嘗試提供一個全面的合成基準，以測試建構器代理在包含常見建構操作的一系列不同任務上。我們相信這種方法使我們能夠探討不同代理的特定優點和缺點，並測試 LLM 在空間推理和基於向量的數學這個具有挑戰性的領域中的能力。

##### **RoDE: Linear Rectified Mixture of Diverse Experts for Food Large Multi-Modal Models**
2407.12730v1 by Pengkun Jiao, Xinlan Wu, Bin Zhu, Jingjing Chen, Chong-Wah Ngo, Yugang Jiang

Large Multi-modal Models (LMMs) have significantly advanced a variety of
vision-language tasks. The scalability and availability of high-quality
training data play a pivotal role in the success of LMMs. In the realm of food,
while comprehensive food datasets such as Recipe1M offer an abundance of
ingredient and recipe information, they often fall short of providing ample
data for nutritional analysis. The Recipe1M+ dataset, despite offering a subset
for nutritional evaluation, is limited in the scale and accuracy of nutrition
information. To bridge this gap, we introduce Uni-Food, a unified food dataset
that comprises over 100,000 images with various food labels, including
categories, ingredients, recipes, and ingredient-level nutritional information.
Uni-Food is designed to provide a more holistic approach to food data analysis,
thereby enhancing the performance and capabilities of LMMs in this domain. To
mitigate the conflicts arising from multi-task supervision during fine-tuning
of LMMs, we introduce a novel Linear Rectification Mixture of Diverse Experts
(RoDE) approach. RoDE utilizes a diverse array of experts to address tasks of
varying complexity, thereby facilitating the coordination of trainable
parameters, i.e., it allocates more parameters for more complex tasks and,
conversely, fewer parameters for simpler tasks. RoDE implements linear
rectification union to refine the router's functionality, thereby enhancing the
efficiency of sparse task allocation. These design choices endow RoDE with
features that ensure GPU memory efficiency and ease of optimization. Our
experimental results validate the effectiveness of our proposed approach in
addressing the inherent challenges of food-related multitasking.

摘要：大型多模态模型 (LMM) 在各种视觉语言任务中取得了重大进展。可扩展性和高质量训练数据的可用性在 LMM 的成功中发挥着至关重要的作用。在食品领域，虽然 Recipe1M 等全面的食品数据集提供了丰富的成分和食谱信息，但它们往往无法为营养分析提供足够的数据。Recipe1M+ 数据集虽然提供了一个用于营养评估的子集，但其营养信息的规模和准确性受到限制。为了弥合这一差距，我们引入了 Uni-Food，这是一个统一的食品数据集，包含超过 100,000 张带有各种食品标签的图像，包括类别、成分、食谱和成分级别的营养信息。Uni-Food 旨在为食品数据分析提供一种更全面的方法，从而增强 LMM 在该领域的性能和能力。为了减轻在 LMM 微调过程中多任务监督所产生的冲突，我们引入了一种新颖的线性校正多元专家 (RoDE) 方法。RoDE 利用各种专家来解决不同复杂程度的任务，从而促进可训练参数的协调，即为更复杂的任务分配更多参数，反之，为更简单的任务分配更少参数。RoDE 实施线性校正联合来优化路由器的功能，从而提高稀疏任务分配的效率。这些设计选择赋予 RoDE 确保 GPU 内存效率和易于优化的特性。我们的实验结果验证了我们提出的方法在解决与食品相关的多任务处理固有挑战方面的有效性。

##### **Is Sarcasm Detection A Step-by-Step Reasoning Process in Large Language Models?**
2407.12725v1 by Ben Yao, Yazhou Zhang, Qiuchi Li, Jing Qin

Elaborating a series of intermediate reasoning steps significantly improves
the ability of large language models (LLMs) to solve complex problems, as such
steps would evoke LLMs to think sequentially. However, human sarcasm
understanding is often considered an intuitive and holistic cognitive process,
in which various linguistic, contextual, and emotional cues are integrated to
form a comprehensive understanding of the speaker's true intention, which is
argued not be limited to a step-by-step reasoning process. To verify this
argument, we introduce a new prompting framework called SarcasmCue, which
contains four prompting strategies, $viz.$ chain of contradiction (CoC), graph
of cues (GoC), bagging of cues (BoC) and tensor of cues (ToC), which elicits
LLMs to detect human sarcasm by considering sequential and non-sequential
prompting methods. Through a comprehensive empirical comparison on four
benchmarking datasets, we show that the proposed four prompting methods
outperforms standard IO prompting, CoT and ToT with a considerable margin, and
non-sequential prompting generally outperforms sequential prompting.

摘要：通過闡述一系列中間推理步驟，大幅提升大型語言模型 (LLM) 解決複雜問題的能力，因為這些步驟會促使 LLM 按順序思考。然而，人類的諷刺理解通常被認為是一種直覺且全面的認知過程，其中各種語言、語境和情緒線索整合在一起，以全面了解說話者的真實意圖，這被認為不僅限於循序漸進的推理過程。為了驗證這個論點，我們引入了一個新的提示框架，稱為 SarcasmCue，其中包含四種提示策略，即矛盾鏈 (CoC)、線索圖 (GoC)、線索袋 (BoC) 和線索張量 (ToC)，它引發 LLM 通過考慮順序和非順序提示方法來檢測人類的諷刺。通過對四個基準數據集進行全面的實證比較，我們表明所提出的四種提示方法以相當大的幅度優於標準 IO 提示、CoT 和 ToT，並且非順序提示通常優於順序提示。

##### **An Evaluation of Continual Learning for Advanced Node Semiconductor Defect Inspection**
2407.12724v1 by Amit Prasad, Bappaditya Dey, Victor Blanco, Sandip Halder

Deep learning-based semiconductor defect inspection has gained traction in
recent years, offering a powerful and versatile approach that provides high
accuracy, adaptability, and efficiency in detecting and classifying nano-scale
defects. However, semiconductor manufacturing processes are continually
evolving, leading to the emergence of new types of defects over time. This
presents a significant challenge for conventional supervised defect detectors,
as they may suffer from catastrophic forgetting when trained on new defect
datasets, potentially compromising performance on previously learned tasks. An
alternative approach involves the constant storage of previously trained
datasets alongside pre-trained model versions, which can be utilized for
(re-)training from scratch or fine-tuning whenever encountering a new defect
dataset. However, adhering to such a storage template is impractical in terms
of size, particularly when considering High-Volume Manufacturing (HVM).
Additionally, semiconductor defect datasets, especially those encompassing
stochastic defects, are often limited and expensive to obtain, thus lacking
sufficient representation of the entire universal set of defectivity. This work
introduces a task-agnostic, meta-learning approach aimed at addressing this
challenge, which enables the incremental addition of new defect classes and
scales to create a more robust and generalized model for semiconductor defect
inspection. We have benchmarked our approach using real resist-wafer SEM
(Scanning Electron Microscopy) datasets for two process steps, ADI and AEI,
demonstrating its superior performance compared to conventional supervised
training methods.

摘要：近年來，基於深度學習的半導體缺陷檢測已獲得廣泛採用，提供了一種強大且通用的方法，可在檢測和分類奈米級缺陷時提供高準確度、適應性和效率。然而，半導體製造流程持續演進，導致隨著時間推移出現新型態缺陷。這對傳統監督式缺陷偵測器構成重大挑戰，因為它們在針對新缺陷資料集進行訓練時可能會遭受災難性遺忘，進而可能損害先前學習任務的效能。另一種方法涉及持續儲存先前訓練的資料集以及預先訓練的模型版本，可在遇到新缺陷資料集時用於從頭開始（重新）訓練或微調。然而，就規模而言，堅持這種儲存範本在實務上是不切實際的，特別是在考慮高量產（HVM）時。此外，半導體缺陷資料集，尤其是那些包含隨機缺陷的資料集，通常數量有限且取得成本高昂，因此無法充分表示缺陷性的整個通用集合。這項工作引入了一種與任務無關的元學習方法，旨在解決此挑戰，它能逐步新增新的缺陷類別和規模，以建立一個更強大且通用的半導體缺陷檢測模型。我們已使用兩個製程步驟（ADI 和 AEI）的實際抗蝕劑晶圓 SEM（掃描電子顯微鏡）資料集對我們的做法進行基準測試，證明其效能優於傳統的監督式訓練方法。

##### **Subgraph-Aware Training of Text-based Methods for Knowledge Graph Completion**
2407.12703v1 by Youmin Ko, Hyemin Yang, Taeuk Kim, Hyunjoon Kim

Fine-tuning pre-trained language models (PLMs) has recently shown a potential
to improve knowledge graph completion (KGC). However, most PLM-based methods
encode only textual information, neglecting various topological structures of
knowledge graphs (KGs). In this paper, we empirically validate the significant
relations between the structural properties of KGs and the performance of the
PLM-based methods. To leverage the structural knowledge, we propose a
Subgraph-Aware Training framework for KGC (SATKGC) that combines (i)
subgraph-aware mini-batching to encourage hard negative sampling, and (ii) a
new contrastive learning method to focus more on harder entities and harder
negative triples in terms of the structural properties. To the best of our
knowledge, this is the first study to comprehensively incorporate the
structural inductive bias of the subgraphs into fine-tuning PLMs. Extensive
experiments on four KGC benchmarks demonstrate the superiority of SATKGC. Our
code is available.

摘要：微调预训练语言模型 (PLM) 最近显示出改善知识图谱完成 (KGC) 的潜力。然而，大多数基于 PLM 的方法仅对文本信息进行编码，而忽略了知识图谱 (KG) 的各种拓扑结构。在本文中，我们凭经验验证了知识图谱的结构属性与基于 PLM 的方法的性能之间的重要关系。为了利用结构知识，我们提出了一个用于 KGC 的子图感知训练框架 (SATKGC)，它结合了 (i) 子图感知的小批量处理以鼓励困难的负采样，以及 (ii) 一种新的对比学习方法，在结构属性方面更多地关注更困难的实体和更困难的负三元组。据我们所知，这是第一项将子图的结构归纳偏差全面纳入 PLM 微调的研究。在四个 KGC 基准上的广泛实验证明了 SATKGC 的优越性。我们的代码可用。

##### **TransCAD: A Hierarchical Transformer for CAD Sequence Inference from Point Clouds**
2407.12702v1 by Elona Dupont, Kseniya Cherenkova, Dimitrios Mallis, Gleb Gusev, Anis Kacem, Djamila Aouada

3D reverse engineering, in which a CAD model is inferred given a 3D scan of a
physical object, is a research direction that offers many promising practical
applications. This paper proposes TransCAD, an end-to-end transformer-based
architecture that predicts the CAD sequence from a point cloud. TransCAD
leverages the structure of CAD sequences by using a hierarchical learning
strategy. A loop refiner is also introduced to regress sketch primitive
parameters. Rigorous experimentation on the DeepCAD and Fusion360 datasets show
that TransCAD achieves state-of-the-art results. The result analysis is
supported with a proposed metric for CAD sequence, the mean Average Precision
of CAD Sequence, that addresses the limitations of existing metrics.

摘要：3D 逆向工程，在給定物理物體 3D 掃描後推斷出 CAD 模型，是一個提供許多有前途的實際應用研究方向。本文提出 TransCAD，一種端到端的基於Transformer的架構，從點雲預測 CAD 順序。TransCAD 透過使用分層學習策略來利用 CAD 順序的結構。迴圈精煉器也被引入用於回歸草圖基元參數。在 DeepCAD 和 Fusion360 資料集上的嚴謹實驗表明 TransCAD 達到了最先進的結果。結果分析得到了一個針對 CAD 順序的提議指標的支持，即 CAD 順序的平均平均精確度，它解決了現有指標的限制。

##### **GraphMuse: A Library for Symbolic Music Graph Processing**
2407.12671v1 by Emmanouil Karystinaios, Gerhard Widmer

Graph Neural Networks (GNNs) have recently gained traction in symbolic music
tasks, yet a lack of a unified framework impedes progress. Addressing this gap,
we present GraphMuse, a graph processing framework and library that facilitates
efficient music graph processing and GNN training for symbolic music tasks.
Central to our contribution is a new neighbor sampling technique specifically
targeted toward meaningful behavior in musical scores. Additionally, GraphMuse
integrates hierarchical modeling elements that augment the expressivity and
capabilities of graph networks for musical tasks. Experiments with two specific
musical prediction tasks -- pitch spelling and cadence detection -- demonstrate
significant performance improvement over previous methods. Our hope is that
GraphMuse will lead to a boost in, and standardization of, symbolic music
processing based on graph representations. The library is available at
https://github.com/manoskary/graphmuse

摘要：圖形神經網路 (GNN) 近期在符號音樂任務中獲得關注，但缺乏統一的框架阻礙了進展。為了解決這個差距，我們提出了 GraphMuse，一個圖形處理框架和程式庫，它促進了符號音樂任務的高效音樂圖形處理和 GNN 訓練。我們貢獻的核心是一個新的鄰居採樣技術，特別針對音樂樂譜中的有意義行為。此外，GraphMuse 整合了階層式建模元素，以增強圖形網路在音樂任務中的表現力和能力。使用兩個特定的音樂預測任務（音高拼寫和終止檢測）進行的實驗證明了與以前的方法相比，有顯著的效能提升。我們希望 GraphMuse 能夠提升並標準化基於圖形表示的符號音樂處理。這個程式庫可在 https://github.com/manoskary/graphmuse 取得

##### **Enhancing the Utility of Privacy-Preserving Cancer Classification using Synthetic Data**
2407.12669v1 by Richard Osuala, Daniel M. Lang, Anneliese Riess, Georgios Kaissis, Zuzanna Szafranowska, Grzegorz Skorupko, Oliver Diaz, Julia A. Schnabel, Karim Lekadir

Deep learning holds immense promise for aiding radiologists in breast cancer
detection. However, achieving optimal model performance is hampered by
limitations in availability and sharing of data commonly associated to patient
privacy concerns. Such concerns are further exacerbated, as traditional deep
learning models can inadvertently leak sensitive training information. This
work addresses these challenges exploring and quantifying the utility of
privacy-preserving deep learning techniques, concretely, (i) differentially
private stochastic gradient descent (DP-SGD) and (ii) fully synthetic training
data generated by our proposed malignancy-conditioned generative adversarial
network. We assess these methods via downstream malignancy classification of
mammography masses using a transformer model. Our experimental results depict
that synthetic data augmentation can improve privacy-utility tradeoffs in
differentially private model training. Further, model pretraining on synthetic
data achieves remarkable performance, which can be further increased with
DP-SGD fine-tuning across all privacy guarantees. With this first in-depth
exploration of privacy-preserving deep learning in breast imaging, we address
current and emerging clinical privacy requirements and pave the way towards the
adoption of private high-utility deep diagnostic models. Our reproducible
codebase is publicly available at https://github.com/RichardObi/mammo_dp.

摘要：深度學習在協助放射科醫師進行乳癌偵測方面具有巨大的潛力。然而，由於與病患隱私相關的疑慮，資料的取得與分享受到限制，這阻礙了模型達到最佳效能。由於傳統的深度學習模型可能會無意間洩漏敏感的訓練資訊，這些疑慮進一步加劇。這項研究探討並量化隱私保護深度學習技術的效用，具體來說，(i) 差分隱私隨機梯度下降法 (DP-SGD) 和 (ii) 由我們提出的惡性腫瘤條件生成對抗網路所產生的完全合成訓練資料，以解決這些挑戰。我們透過使用轉換器模型對乳房攝影腫塊進行下游惡性腫瘤分類來評估這些方法。我們的實驗結果顯示，合成資料擴充可以改善差分隱私模型訓練中的隱私效用權衡。此外，在合成資料上進行模型預訓練可獲得顯著的效能，並可透過在所有隱私保證下進行 DP-SGD 微調進一步提升。透過首次深入探討乳房影像中的隱私保護深度學習，我們解決了當前和新興的臨床隱私需求，並為採用私有高實用性深度診斷模型鋪路。我們的可複製程式碼庫已公開於 https://github.com/RichardObi/mammo_dp。

##### **Patch-Level Training for Large Language Models**
2407.12665v1 by Chenze Shao, Fandong Meng, Jie Zhou

As Large Language Models (LLMs) achieve remarkable progress in language
understanding and generation, their training efficiency has become a critical
concern. Traditionally, LLMs are trained to predict the next token in a
sequence. Despite the success of token-level training, it suffers from
considerable computational costs due to the need to process an extensive number
of tokens. To mitigate this issue, this paper introduces patch-level training
for LLMs, which reduces the sequence length by compressing multiple tokens into
a single patch. During patch-level training, we feed the language model shorter
sequences of patches and train it to predict the next patch, thereby processing
the majority of the training data at a significantly reduced computational
cost. Following this, the model continues token-level training on the remaining
training data to align with the inference mode. Experiments on a diverse range
of models (370M-2.7B parameters) demonstrate that patch-level training can
reduce overall computational costs to 0.5$\times$, without compromising the
model performance compared to token-level training. Source code:
\url{https://github.com/shaochenze/PatchTrain}.

摘要：隨著大型語言模型（LLM）在語言理解和生成方面取得顯著進展，其訓練效率已成為關鍵問題。傳統上，LLM 被訓練來預測序列中的下一個符號。儘管符號級別訓練很成功，但由於需要處理大量符號，因此會產生相當大的運算成本。為了緩解這個問題，本文引入了 LLM 的區塊級訓練，它通過將多個符號壓縮成單個區塊來縮短序列長度。在區塊級訓練期間，我們將較短的區塊序列提供給語言模型，並訓練它預測下一個區塊，從而以顯著降低的運算成本處理大部分訓練資料。在此之後，模型繼續對剩餘的訓練資料進行符號級訓練，以與推理模式保持一致。在各種模型（370M-2.7B 參數）上進行的實驗表明，區塊級訓練可以將整體運算成本降低到 0.5 倍，而不會損害模型效能，這與符號級訓練相比。原始碼：\url{https://github.com/shaochenze/PatchTrain}。

##### **Is That Rain? Understanding Effects on Visual Odometry Performance for Autonomous UAVs and Efficient DNN-based Rain Classification at the Edge**
2407.12663v1 by Andrea Albanese, Yanran Wang, Davide Brunelli, David Boyle

The development of safe and reliable autonomous unmanned aerial vehicles
relies on the ability of the system to recognise and adapt to changes in the
local environment based on sensor inputs. State-of-the-art local tracking and
trajectory planning are typically performed using camera sensor input to the
flight control algorithm, but the extent to which environmental disturbances
like rain affect the performance of these systems is largely unknown. In this
paper, we first describe the development of an open dataset comprising ~335k
images to examine these effects for seven different classes of precipitation
conditions and show that a worst-case average tracking error of 1.5 m is
possible for a state-of-the-art visual odometry system (VINS-Fusion). We then
use the dataset to train a set of deep neural network models suited to mobile
and constrained deployment scenarios to determine the extent to which it may be
possible to efficiently and accurately classify these `rainy' conditions. The
most lightweight of these models (MobileNetV3 small) can achieve an accuracy of
90% with a memory footprint of just 1.28 MB and a frame rate of 93 FPS, which
is suitable for deployment in resource-constrained and latency-sensitive
systems. We demonstrate a classification latency in the order of milliseconds
using typical flight computer hardware. Accordingly, such a model can feed into
the disturbance estimation component of an autonomous flight controller. In
addition, data from unmanned aerial vehicles with the ability to accurately
determine environmental conditions in real time may contribute to developing
more granular timely localised weather forecasting.

摘要：安全可靠的無人駕駛飛行器的開發
仰賴系統根據感測器輸入，辨識並適應當地環境的變化。最先進的區域追蹤和軌跡規劃通常使用相機感測器輸入到飛控演算法，但環境干擾（例如雨水）對這些系統效能的影響程度在很大程度上仍未知。在本文中，我們首先描述一個包含約 335k 張影像的開放式資料集的開發，以檢視七種不同類型的降水條件對這些影響的影響，並顯示最先進的視覺里程計系統 (VINS-Fusion) 可能出現 1.5 公尺的最差平均追蹤誤差。然後，我們使用該資料集訓練一組適用於行動和受限部署場景的深度神經網路模型，以確定有效率且準確地分類這些「雨天」條件的程度。這些模型中最輕量的（MobileNetV3 small）可以在僅 1.28 MB 的記憶體使用量和 93 FPS 的幀率下達到 90% 的準確度，這適用於部署在資源受限且對延遲敏感的系統中。我們使用典型的飛行電腦硬體展示了毫秒級的分類延遲。因此，這種模型可以提供給自主飛控器的干擾估計元件。此外，具有準確確定環境條件能力的無人駕駛飛行器資料，可能有助於開發更細緻及時的局部天氣預報。

##### **Zero-shot Text-guided Infinite Image Synthesis with LLM guidance**
2407.12642v1 by Soyeong Kwon, Taegyeong Lee, Taehwan Kim

Text-guided image editing and generation methods have diverse real-world
applications. However, text-guided infinite image synthesis faces several
challenges. First, there is a lack of text-image paired datasets with
high-resolution and contextual diversity. Second, expanding images based on
text requires global coherence and rich local context understanding. Previous
studies have mainly focused on limited categories, such as natural landscapes,
and also required to train on high-resolution images with paired text. To
address these challenges, we propose a novel approach utilizing Large Language
Models (LLMs) for both global coherence and local context understanding,
without any high-resolution text-image paired training dataset. We train the
diffusion model to expand an image conditioned on global and local captions
generated from the LLM and visual feature. At the inference stage, given an
image and a global caption, we use the LLM to generate a next local caption to
expand the input image. Then, we expand the image using the global caption,
generated local caption and the visual feature to consider global consistency
and spatial local context. In experiments, our model outperforms the baselines
both quantitatively and qualitatively. Furthermore, our model demonstrates the
capability of text-guided arbitrary-sized image generation in zero-shot manner
with LLM guidance.

摘要：文本引导的图像编辑和生成方法具有多样化的实际应用。然而，文本引导的无限图像合成面临着一些挑战。首先，缺乏具有高分辨率和语境多样性的文本图像配对数据集。其次，基于文本扩展图像需要全局连贯性和丰富的局部语境理解。以往的研究主要集中在有限的类别上，如自然景观，还需要在配对文本的高分辨率图像上进行训练。为了应对这些挑战，我们提出了一种新颖的方法，利用大语言模型 (LLM) 来实现全局连贯性和局部语境理解，而无需任何高分辨率文本图像配对训练数据集。我们训练扩散模型来扩展图像，该图像以 LLM 和视觉特征生成的全局和局部标题为条件。在推理阶段，给定图像和全局标题，我们使用 LLM 生成下一个局部标题以扩展输入图像。然后，我们使用全局标题、生成的局部标题和视觉特征来扩展图像，以考虑全局一致性和空间局部语境。在实验中，我们的模型在定量和定性方面都优于基线。此外，我们的模型展示了在 LLM 指导下以零样本方式进行文本引导的任意大小图像生成的能力。

##### **A Methodology Establishing Linear Convergence of Adaptive Gradient Methods under PL Inequality**
2407.12629v1 by Kushal Chakrabarti, Mayank Baranwal

Adaptive gradient-descent optimizers are the standard choice for training
neural network models. Despite their faster convergence than gradient-descent
and remarkable performance in practice, the adaptive optimizers are not as well
understood as vanilla gradient-descent. A reason is that the dynamic update of
the learning rate that helps in faster convergence of these methods also makes
their analysis intricate. Particularly, the simple gradient-descent method
converges at a linear rate for a class of optimization problems, whereas the
practically faster adaptive gradient methods lack such a theoretical guarantee.
The Polyak-{\L}ojasiewicz (PL) inequality is the weakest known class, for which
linear convergence of gradient-descent and its momentum variants has been
proved. Therefore, in this paper, we prove that AdaGrad and Adam, two
well-known adaptive gradient methods, converge linearly when the cost function
is smooth and satisfies the PL inequality. Our theoretical framework follows a
simple and unified approach, applicable to both batch and stochastic gradients,
which can potentially be utilized in analyzing linear convergence of other
variants of Adam.

摘要：自適應梯度下降最佳化器是訓練神經網路模型的標準選擇。儘管它們比梯度下降收斂得更快，而且在實務上表現出色，但自適應最佳化器不如傳統梯度下降那麼容易理解。原因在於，有助於加速這些方法收斂的學習率動態更新，也讓它們的分析變得複雜。特別是，對於一類最佳化問題，簡單的梯度下降方法以線性速度收斂，而實際上更快的自適應梯度方法卻缺乏這樣的理論保證。Polyak-{\L}ojasiewicz (PL) 不等式是最弱已知類別，已證明梯度下降及其動量變異的線性收斂。因此，在本文中，我們證明了 AdaGrad 和 Adam 這兩種著名的自適應梯度方法，在成本函數平滑且滿足 PL 不等式時，會線性收斂。我們的理論架構遵循一種簡單且統一的方法，適用於批次梯度和隨機梯度，這有可能用於分析 Adam 其他變體的線性收斂。

##### **Domain-specific or Uncertainty-aware models: Does it really make a difference for biomedical text classification?**
2407.12626v1 by Aman Sinha, Timothee Mickus, Marianne Clausel, Mathieu Constant, Xavier Coubez

The success of pretrained language models (PLMs) across a spate of use-cases
has led to significant investment from the NLP community towards building
domain-specific foundational models. On the other hand, in mission critical
settings such as biomedical applications, other aspects also factor in-chief of
which is a model's ability to produce reasonable estimates of its own
uncertainty. In the present study, we discuss these two desiderata through the
lens of how they shape the entropy of a model's output probability
distribution. We find that domain specificity and uncertainty awareness can
often be successfully combined, but the exact task at hand weighs in much more
strongly.

摘要：預訓練語言模型 (PLM) 在大量使用案例中的成功，已導致自然語言處理社群對建構特定領域基礎模型進行大量投資。另一方面，在任務關鍵設定中，例如生物醫學應用，其他面向也列入考量，其中首要考量為模型產生其自身不確定性合理估計的能力。在本研究中，我們透過模型輸出機率分佈的熵如何成形的觀點，探討這兩個理想狀態。我們發現領域特異性和不確定性意識通常可以成功結合，但具體任務在其中扮演更重要的角色。

##### **Harnessing the Power of Artificial Intelligence to Vitalize Endangered Indigenous Languages: Technologies and Experiences**
2407.12620v1 by Claudio Pinhanez, Paulo Cavalin, Luciana Storto, Thomas Fimbow, Alexander Cobbinah, Julio Nogima, Marisa Vasconcelos, Pedro Domingues, Priscila de Souza Mizukami, Nicole Grell, Majoí Gongora, Isabel Gonçalves

Since 2022 we have been exploring application areas and technologies in which
Artificial Intelligence (AI) and modern Natural Language Processing (NLP), such
as Large Language Models (LLMs), can be employed to foster the usage and
facilitate the documentation of Indigenous languages which are in danger of
disappearing. We start by discussing the decreasing diversity of languages in
the world and how working with Indigenous languages poses unique ethical
challenges for AI and NLP. To address those challenges, we propose an
alternative development AI cycle based on community engagement and usage. Then,
we report encouraging results in the development of high-quality machine
learning translators for Indigenous languages by fine-tuning state-of-the-art
(SOTA) translators with tiny amounts of data and discuss how to avoid some
common pitfalls in the process. We also present prototypes we have built in
projects done in 2023 and 2024 with Indigenous communities in Brazil, aimed at
facilitating writing, and discuss the development of Indigenous Language Models
(ILMs) as a replicable and scalable way to create spell-checkers, next-word
predictors, and similar tools. Finally, we discuss how we envision a future for
language documentation where dying languages are preserved as interactive
language models.

摘要：自 2022 年以來，我們一直在探索人工智能 (AI) 和現代自然語言處理 (NLP) 的應用領域和技術，例如大型語言模型 (LLM)，它們可促進瀕臨消失的原住民語言的使用並促進其文件編寫。我們首先討論世界語言的多樣性下降，以及使用原住民語言如何對 AI 和 NLP 構成獨特的倫理挑戰。為了應對這些挑戰，我們提出了一個基於社區參與和使用的替代開發 AI 週期。然後，我們報告了在為原住民語言開發高品質機器學習翻譯器方面令人鼓舞的成果，方法是微調最先進 (SOTA) 翻譯器，並使用極少量數據，並討論如何避免在此過程中遇到一些常見的陷阱。我們還展示了我們在 2023 年和 2024 年與巴西的原住民社區合作完成的專案中建立的原型，旨在促進寫作，並討論原住民語言模型 (ILM) 的開發，作為一種可複製且可擴展的方式來建立拼寫檢查器、下一個單詞預測器和類似工具。最後，我們討論了我們如何設想語言文件編寫的未來，其中瀕臨消亡的語言被保留為互動語言模型。

##### **Missing Modality Prediction for Unpaired Multimodal Learning via Joint Embedding of Unimodal Models**
2407.12616v1 by Donggeun Kim, Taesup Kim

Multimodal learning typically relies on the assumption that all modalities
are fully available during both the training and inference phases. However, in
real-world scenarios, consistently acquiring complete multimodal data presents
significant challenges due to various factors. This often leads to the issue of
missing modalities, where data for certain modalities are absent, posing
considerable obstacles not only for the availability of multimodal pretrained
models but also for their fine-tuning and the preservation of robustness in
downstream tasks. To address these challenges, we propose a novel framework
integrating parameter-efficient fine-tuning of unimodal pretrained models with
a self-supervised joint-embedding learning method. This framework enables the
model to predict the embedding of a missing modality in the representation
space during inference. Our method effectively predicts the missing embedding
through prompt tuning, leveraging information from available modalities. We
evaluate our approach on several multimodal benchmark datasets and demonstrate
its effectiveness and robustness across various scenarios of missing
modalities.

摘要：多模態學習通常依賴於所有模態在訓練和推理階段都完全可用的假設。然而，在現實世界場景中，由於各種因素，持續取得完整的模態數據會造成重大挑戰。這通常會導致模態缺失問題，其中某些模態的數據不存在，不僅對多模態預訓練模型的可用性造成相當大的障礙，也對它們的微調和下游任務中穩健性的維護造成障礙。為了應對這些挑戰，我們提出了一個新的框架，將單模態預訓練模型的參數有效微調與自監督聯合嵌入學習方法整合在一起。此框架使模型能夠在推理期間預測表示空間中缺失模態的嵌入。我們的技術透過提示調整有效預測缺失的嵌入，利用可用模態中的資訊。我們在幾個多模態基準資料集上評估我們的做法，並展示其在各種模態缺失場景中的有效性和穩健性。

##### **AudienceView: AI-Assisted Interpretation of Audience Feedback in Journalism**
2407.12613v1 by William Brannon, Doug Beeferman, Hang Jiang, Andrew Heyward, Deb Roy

Understanding and making use of audience feedback is important but difficult
for journalists, who now face an impractically large volume of audience
comments online. We introduce AudienceView, an online tool to help journalists
categorize and interpret this feedback by leveraging large language models
(LLMs). AudienceView identifies themes and topics, connects them back to
specific comments, provides ways to visualize the sentiment and distribution of
the comments, and helps users develop ideas for subsequent reporting projects.
We consider how such tools can be useful in a journalist's workflow, and
emphasize the importance of contextual awareness and human judgment.

摘要：了解和利用受眾回饋很重要，但對記者來說很困難，因為他們現在面臨網路上數量龐大的受眾留言。我們推出 AudienceView，這是一個線上工具，可協助記者透過利用大型語言模型 (LLM) 來分類和詮釋這些回饋。AudienceView 會找出主題和議題，將它們連結回特定留言，提供視覺化留言情緒和分佈的方式，並協助使用者為後續報導專案發展構想。我們考量此類工具如何在記者的工作流程中發揮作用，並強調情境意識和人類判斷的重要性。

##### **Instance-wise Uncertainty for Class Imbalance in Semantic Segmentation**
2407.12609v1 by Luís Almeida, Inês Dutra, Francesco Renna

Semantic segmentation is a fundamental computer vision task with a vast
number of applications. State of the art methods increasingly rely on deep
learning models, known to incorrectly estimate uncertainty and being
overconfident in predictions, especially in data not seen during training. This
is particularly problematic in semantic segmentation due to inherent class
imbalance. Popular uncertainty quantification approaches are task-agnostic and
fail to leverage spatial pixel correlations in uncertainty estimates, crucial
in this task. In this work, a novel training methodology specifically designed
for semantic segmentation is presented. Training samples are weighted by
instance-wise uncertainty masks computed by an ensemble. This is shown to
increase performance on minority classes, boost model generalization and
robustness to domain-shift when compared to using the inverse of class
proportions or no class weights at all. This method addresses the challenges of
class imbalance and uncertainty estimation in semantic segmentation,
potentially enhancing model performance and reliability across various
applications.

摘要：語意分割是一項基本的電腦視覺任務，有大量的應用。最先進的方法越來越依賴深度學習模型，已知這些模型會錯誤地估計不確定性，並且對預測過於自信，尤其是在訓練期間未見過的資料中。由於固有的類別不平衡，這在語意分割中特別成問題。流行的不確定性量化方法與任務無關，並且無法在不確定性估計中利用空間像素相關性，這對於此任務至關重要。在這項工作中，提出了一種專門為語意分割設計的新穎訓練方法。訓練樣本由一個整體計算出的實例不確定性遮罩加權。與僅使用類別比例的倒數或根本不使用類別權重相比，這被證明可以提高少數類別的性能、提升模型的泛化能力和對領域轉移的魯棒性。此方法解決了語意分割中類別不平衡和不確定性估計的挑戰，有可能在各種應用中增強模型的性能和可靠性。

##### **Benchmarking Robust Self-Supervised Learning Across Diverse Downstream Tasks**
2407.12588v1 by Antoni Kowalczuk, Jan Dubiński, Atiyeh Ashari Ghomi, Yi Sui, George Stein, Jiapeng Wu, Jesse C. Cresswell, Franziska Boenisch, Adam Dziedzic

Large-scale vision models have become integral in many applications due to
their unprecedented performance and versatility across downstream tasks.
However, the robustness of these foundation models has primarily been explored
for a single task, namely image classification. The vulnerability of other
common vision tasks, such as semantic segmentation and depth estimation,
remains largely unknown. We present a comprehensive empirical evaluation of the
adversarial robustness of self-supervised vision encoders across multiple
downstream tasks. Our attacks operate in the encoder embedding space and at the
downstream task output level. In both cases, current state-of-the-art
adversarial fine-tuning techniques tested only for classification significantly
degrade clean and robust performance on other tasks. Since the purpose of a
foundation model is to cater to multiple applications at once, our findings
reveal the need to enhance encoder robustness more broadly. %We discuss
potential strategies for more robust foundation vision models across diverse
downstream tasks. Our code is available at
$\href{https://github.com/layer6ai-labs/ssl-robustness}{github.com/layer6ai-labs/ssl-robustness}$.

摘要：大型視覺模型由於其在下游任務中前所未有的效能和多功能性，已成為許多應用程式中不可或缺的一部分。然而，這些基礎模型的穩健性主要探討的是單一任務，即影像分類。其他常見視覺任務的脆弱性，例如語意分割和深度估計，在很大程度上仍然未知。我們提出了一個全面的經驗評估，針對跨多個下游任務的自監督視覺編碼器的對抗性穩健性。我們的攻擊在編碼器嵌入空間和下游任務輸出層級中執行。在這兩種情況下，目前最先進的對抗性微調技術僅針對分類進行測試，會顯著降低其他任務的乾淨且穩健的效能。由於基礎模型的目的是同時滿足多個應用程式，我們的研究結果揭示了更廣泛地提升編碼器穩健性的必要性。我們討論了針對各種下游任務更穩健的基礎視覺模型的潛在策略。我們的程式碼可在 $\href{https://github.com/layer6ai-labs/ssl-robustness}{github.com/layer6ai-labs/ssl-robustness}$ 取得。

##### **Towards Understanding Unsafe Video Generation**
2407.12581v1 by Yan Pang, Aiping Xiong, Yang Zhang, Tianhao Wang

Video generation models (VGMs) have demonstrated the capability to synthesize
high-quality output. It is important to understand their potential to produce
unsafe content, such as violent or terrifying videos. In this work, we provide
a comprehensive understanding of unsafe video generation.
  First, to confirm the possibility that these models could indeed generate
unsafe videos, we choose unsafe content generation prompts collected from 4chan
and Lexica, and three open-source SOTA VGMs to generate unsafe videos. After
filtering out duplicates and poorly generated content, we created an initial
set of 2112 unsafe videos from an original pool of 5607 videos. Through
clustering and thematic coding analysis of these generated videos, we identify
5 unsafe video categories: Distorted/Weird, Terrifying, Pornographic,
Violent/Bloody, and Political. With IRB approval, we then recruit online
participants to help label the generated videos. Based on the annotations
submitted by 403 participants, we identified 937 unsafe videos from the initial
video set. With the labeled information and the corresponding prompts, we
created the first dataset of unsafe videos generated by VGMs.
  We then study possible defense mechanisms to prevent the generation of unsafe
videos. Existing defense methods in image generation focus on filtering either
input prompt or output results. We propose a new approach called Latent
Variable Defense (LVD), which works within the model's internal sampling
process. LVD can achieve 0.90 defense accuracy while reducing time and
computing resources by 10x when sampling a large number of unsafe prompts.

摘要：影片生成模型 (VGM) 已展示出合成高品質輸出的能力。了解它們產生不安全內容（例如暴力或令人恐懼的影片）的潛力非常重要。在這項工作中，我們提供了對不安全影片生成的全面了解。
首先，為了確認這些模型確實可以產生不安全的影片，我們選擇從 4chan 和 Lexica 收集的不安全內容生成提示，以及三個開源的 SOTA VGM 來產生不安全的影片。在過濾掉重複和產生不良的內容後，我們從 5607 個影片的原始池中建立了一個包含 2112 個不安全影片的初始集合。透過對這些已產生影片進行群集和主題編碼分析，我們識別出 5 個不安全影片類別：扭曲/奇怪、令人恐懼、色情、暴力/血腥和政治。在取得 IRB 核准後，我們招募線上參與者來協助標記已產生的影片。根據 403 位參與者提交的註解，我們從初始影片集合中識別出 937 個不安全的影片。利用標記資訊和對應的提示，我們建立了第一個由 VGM 產生的不安全影片資料集。
接下來，我們研究可能的防禦機制，以防止產生不安全的影片。現有的影像生成防禦方法著重於過濾輸入提示或輸出結果。我們提出了一種稱為潛在變數防禦 (LVD) 的新方法，這種方法在模型的內部取樣過程中運作。在取樣大量不安全的提示時，LVD 能夠達到 0.90 的防禦準確度，同時將時間和運算資源減少 10 倍。

##### **E5-V: Universal Embeddings with Multimodal Large Language Models**
2407.12580v1 by Ting Jiang, Minghui Song, Zihan Zhang, Haizhen Huang, Weiwei Deng, Feng Sun, Qi Zhang, Deqing Wang, Fuzhen Zhuang

Multimodal large language models (MLLMs) have shown promising advancements in
general visual and language understanding. However, the representation of
multimodal information using MLLMs remains largely unexplored. In this work, we
introduce a new framework, E5-V, designed to adapt MLLMs for achieving
universal multimodal embeddings. Our findings highlight the significant
potential of MLLMs in representing multimodal inputs compared to previous
approaches. By leveraging MLLMs with prompts, E5-V effectively bridges the
modality gap between different types of inputs, demonstrating strong
performance in multimodal embeddings even without fine-tuning. We propose a
single modality training approach for E5-V, where the model is trained
exclusively on text pairs. This method demonstrates significant improvements
over traditional multimodal training on image-text pairs, while reducing
training costs by approximately 95%. Additionally, this approach eliminates the
need for costly multimodal training data collection. Extensive experiments
across four types of tasks demonstrate the effectiveness of E5-V. As a
universal multimodal model, E5-V not only achieves but often surpasses
state-of-the-art performance in each task, despite being trained on a single
modality.

摘要：多模態大型語言模型 (MLLM) 在一般視覺和語言理解方面展現出有前途的進展。然而，使用 MLLM 表示多模態資訊在很大程度上仍未被探索。在這項工作中，我們引入一個新的框架 E5-V，旨在調整 MLLM 以實現通用多模態嵌入。我們的研究結果突顯了 MLLM 在表示多模態輸入方面的巨大潛力，與先前的做法相比。透過利用提示的 MLLM，E5-V 有效地彌合了不同類型輸入之間的模態差距，即使沒有微調，也能在多模態嵌入中展現強大的效能。我們為 E5-V 提出單一模態訓練方法，其中模型僅在文字對上訓練。這種方法證明了與傳統的多模態影像文字對訓練相比有顯著的進步，同時將訓練成本降低了約 95%。此外，這種方法消除了對昂貴的多模態訓練資料收集的需求。跨四種類型的任務進行的廣泛實驗證明了 E5-V 的有效性。作為一個通用的多模態模型，E5-V 不僅在每個任務中都達到，而且常常超越最先進的效能，儘管僅在單一模態上訓練。

##### **The Fabrication of Reality and Fantasy: Scene Generation with LLM-Assisted Prompt Interpretation**
2407.12579v1 by Yi Yao, Chan-Feng Hsu, Jhe-Hao Lin, Hongxia Xie, Terence Lin, Yi-Ning Huang, Hong-Han Shuai, Wen-Huang Cheng

In spite of recent advancements in text-to-image generation, limitations
persist in handling complex and imaginative prompts due to the restricted
diversity and complexity of training data. This work explores how diffusion
models can generate images from prompts requiring artistic creativity or
specialized knowledge. We introduce the Realistic-Fantasy Benchmark (RFBench),
a novel evaluation framework blending realistic and fantastical scenarios. To
address these challenges, we propose the Realistic-Fantasy Network (RFNet), a
training-free approach integrating diffusion models with LLMs. Extensive human
evaluations and GPT-based compositional assessments demonstrate our approach's
superiority over state-of-the-art methods. Our code and dataset is available at
https://leo81005.github.io/Reality-and-Fantasy/.

摘要：儘管在文字轉圖片生成方面有近期的進展，但由於訓練資料的多樣性和複雜性受限，在處理複雜且富想像力的提示時，仍存在限制。這項研究探討如何讓擴散模型能從需要藝術創意或專業知識的提示中生成圖片。我們引入了「寫實奇幻基準」(RFBench)，這是一個結合寫實和奇幻情境的全新評估架構。為了應對這些挑戰，我們提出了「寫實奇幻網路」(RFNet)，這是一種將擴散模型與 LLM 整合的免訓練方法。廣泛的人類評估和基於 GPT 的組合評估證明了我們的方法優於最先進的方法。我們的程式碼和資料集可在 https://leo81005.github.io/Reality-and-Fantasy/ 取得。

##### **IICPilot: An Intelligent Integrated Circuit Backend Design Framework Using Open EDA**
2407.12576v1 by Zesong Jiang, Qing Zhang, Cheng Liu, Huawei Li, Xiaowei Li

Open-source EDA tools are rapidly advancing, fostering collaboration,
innovation, and knowledge sharing within the EDA community. However, the
growing complexity of these tools, characterized by numerous design parameters
and heuristics, poses a significant barrier to their widespread adoption. This
complexity is particularly pronounced in integrated circuit (IC) backend
designs, which place substantial demands on engineers' expertise in EDA tools.
To tackle this challenge, we introduce IICPilot, an intelligent IC backend
design system based on LLM technology. IICPilot automates various backend
design procedures, including script generation, EDA tool invocation, design
space exploration of EDA parameters, container-based computing resource
allocation, and exception management. By automating these tasks, IICPilot
significantly lowers the barrier to entry for open-source EDA tools.
Specifically, IICPilot utilizes LangChain's multi-agent framework to
efficiently handle distinct design tasks, enabling flexible enhancements
independently. Moreover, IICPilot separates the backend design workflow from
specific open-source EDA tools through a unified EDA calling interface. This
approach allows seamless integration with different open-source EDA tools like
OpenROAD and iEDA, streamlining the backend design and optimization across the
EDA tools.

摘要：開放原始碼 EDA 工具正在快速進步，促進 EDA 社群內的協作、創新和知識分享。然而，這些工具日益複雜，特徵是大量的設計參數和啟發法，對其廣泛採用構成重大障礙。這種複雜性在積體電路 (IC) 後端設計中尤其明顯，這對工程師在 EDA 工具方面的專業知識提出了實質性的要求。為了應對這一挑戰，我們引入了 IICPilot，這是一個基於 LLM 技術的智能 IC 後端設計系統。IICPilot 自動化各種後端設計程序，包括腳本生成、EDA 工具調用、EDA 參數的設計空間探索、基於容器的運算資源分配和異常管理。通過自動化這些任務，IICPilot 大大降低了入門開放原始碼 EDA 工具的門檻。具體來說，IICPilot 利用 LangChain 的多代理架構來有效地處理不同的設計任務，從而獨立地實現靈活的增強。此外，IICPilot 通過統一的 EDA 調用介面將後端設計工作流程與特定的開放原始碼 EDA 工具分開。這種方法允許與不同的開放原始碼 EDA 工具（如 OpenROAD 和 iEDA）無縫整合，簡化了 EDA 工具中的後端設計和最佳化。

##### **Abstraction Alignment: Comparing Model and Human Conceptual Relationships**
2407.12543v1 by Angie Boggust, Hyemin Bang, Hendrik Strobelt, Arvind Satyanarayan

Abstraction -- the process of generalizing specific examples into broad
reusable patterns -- is central to how people efficiently process and store
information and apply their knowledge to new data. Promisingly, research has
shown that ML models learn representations that span levels of abstraction,
from specific concepts like "bolo tie" and "car tire" to more general concepts
like "CEO" and "model". However, existing techniques analyze these
representations in isolation, treating learned concepts as independent
artifacts rather than an interconnected web of abstraction. As a result,
although we can identify the concepts a model uses to produce its output, it is
difficult to assess if it has learned a human-aligned abstraction of the
concepts that will generalize to new data. To address this gap, we introduce
abstraction alignment, a methodology to measure the agreement between a model's
learned abstraction and the expected human abstraction. We quantify abstraction
alignment by comparing model outputs against a human abstraction graph, such as
linguistic relationships or medical disease hierarchies. In evaluation tasks
interpreting image models, benchmarking language models, and analyzing medical
datasets, abstraction alignment provides a deeper understanding of model
behavior and dataset content, differentiating errors based on their agreement
with human knowledge, expanding the verbosity of current model quality metrics,
and revealing ways to improve existing human abstractions.

摘要：抽象化——將特定範例概括為廣泛可重複使用的模式的過程——是人們有效處理和儲存資訊，並將其知識應用於新資料的核心。有希望的是，研究顯示 ML 模型學習跨越抽象層級的表徵，從「細領帶」和「汽車輪胎」等具體概念到「執行長」和「模型」等更一般的概念。然而，現有的技術孤立地分析這些表徵，將學習到的概念視為獨立的產物，而不是抽象的相互連結網路。因此，儘管我們可以識別模型用來產生其輸出的概念，但很難評估它是否學習到概念的人類對齊抽象，這些概念將概括到新的資料。為了解決這個差距，我們引入了抽象對齊，一種衡量模型學習的抽象與預期的抽象之間一致性的方法。我們透過將模型輸出與人類抽象圖形（例如語言關係或醫療疾病層級結構）進行比較來量化抽象對齊。在解釋影像模型、基準語言模型和分析醫療資料集的評估任務中，抽象對齊提供了對模型行為和資料集內容更深入的理解，根據與人類知識的一致性區分錯誤，擴展當前模型品質指標的詳細程度，並揭示改善現有人類抽象的方法。

##### **Towards Collaborative Intelligence: Propagating Intentions and Reasoning for Multi-Agent Coordination with Large Language Models**
2407.12532v1 by Xihe Qiu, Haoyu Wang, Xiaoyu Tan, Chao Qu, Yujie Xiong, Yuan Cheng, Yinghui Xu, Wei Chu, Yuan Qi

Effective collaboration in multi-agent systems requires communicating goals
and intentions between agents. Current agent frameworks often suffer from
dependencies on single-agent execution and lack robust inter-module
communication, frequently leading to suboptimal multi-agent reinforcement
learning (MARL) policies and inadequate task coordination. To address these
challenges, we present a framework for training large language models (LLMs) as
collaborative agents to enable coordinated behaviors in cooperative MARL. Each
agent maintains a private intention consisting of its current goal and
associated sub-tasks. Agents broadcast their intentions periodically, allowing
other agents to infer coordination tasks. A propagation network transforms
broadcast intentions into teammate-specific communication messages, sharing
relevant goals with designated teammates. The architecture of our framework is
structured into planning, grounding, and execution modules. During execution,
multiple agents interact in a downstream environment and communicate intentions
to enable coordinated behaviors. The grounding module dynamically adapts
comprehension strategies based on emerging coordination patterns, while
feedback from execution agents influnces the planning module, enabling the
dynamic re-planning of sub-tasks. Results in collaborative environment
simulation demonstrate intention propagation reduces miscoordination errors by
aligning sub-task dependencies between agents. Agents learn when to communicate
intentions and which teammates require task details, resulting in emergent
coordinated behaviors. This demonstrates the efficacy of intention sharing for
cooperative multi-agent RL based on LLMs.

摘要：在多智能體系統中進行有效的協作，需要在智能體之間傳達目標和意圖。當前的智能體框架通常會受到單一智能體執行的依賴，並且缺乏穩健的模組間通訊，這常常會導致次佳的多智能體強化學習 (MARL) 政策和不充分的任務協調。為了應對這些挑戰，我們提出了將大型語言模型 (LLM) 訓練為協作智能體的框架，以在合作式 MARL 中實現協調行為。每個智能體都維護一個私人意圖，其中包含其當前目標和相關的子任務。智能體會定期廣播他們的意圖，讓其他智能體推論協調任務。傳播網路將廣播意圖轉換為特定於隊友的通訊訊息，與指定的隊友分享相關目標。我們框架的架構被結構化為規劃、接地和執行模組。在執行期間，多個智能體在下游環境中互動，並傳達意圖以實現協調行為。接地模組會根據新興的協調模式動態調整理解策略，而來自執行智能體的回饋會影響規劃模組，從而實現子任務的動態重新規劃。在協作環境模擬中的結果證明，意圖傳播透過調整智能體之間的子任務依賴性，減少了協調錯誤。智能體會學習何時傳達意圖以及哪些隊友需要任務詳細資訊，從而產生新興的協調行為。這證明了基於 LLM 的合作式多智能體 RL 意圖共享的效力。

##### **Crafting the Path: Robust Query Rewriting for Information Retrieval**
2407.12529v1 by Ingeol Baek, Jimin Lee, Joonho Yang, Hwanhee Lee

Query rewriting aims to generate a new query that can complement the original
query to improve the information retrieval system. Recent studies on query
rewriting, such as query2doc (Q2D), query2expand (Q2E) and querey2cot (Q2C),
rely on the internal knowledge of Large Language Models (LLMs) to generate a
relevant passage to add information to the query. Nevertheless, the efficacy of
these methodologies may markedly decline in instances where the requisite
knowledge is not encapsulated within the model's intrinsic parameters. In this
paper, we propose a novel structured query rewriting method called Crafting the
Path tailored for retrieval systems. Crafting the Path involves a three-step
process that crafts query-related information necessary for finding the
passages to be searched in each step. Specifically, the Crafting the Path
begins with Query Concept Comprehension, proceeds to Query Type Identification,
and finally conducts Expected Answer Extraction. Experimental results show that
our method outperforms previous rewriting methods, especially in less familiar
domains for LLMs. We demonstrate that our method is less dependent on the
internal parameter knowledge of the model and generates queries with fewer
factual inaccuracies. Furthermore, we observe that Crafting the Path has less
latency compared to the baselines.

摘要：查詢改寫旨在產生一個新的查詢，可以補充原始查詢以改善資訊檢索系統。最近關於查詢改寫的研究，例如 query2doc (Q2D)、query2expand (Q2E) 和 querey2cot (Q2C)，依賴於大型語言模型 (LLM) 的內部知識來產生相關段落，以將資訊新增至查詢。儘管如此，在必要的知識未封裝在模型的內部參數中的情況下，這些方法的效能可能會顯著下降。在本文中，我們提出了一種稱為「為檢索系統量身打造路徑」的新穎結構化查詢改寫方法。打造路徑涉及一個三步驟流程，在每個步驟中建立查詢相關資訊，以尋找要搜尋的段落。具體而言，打造路徑從查詢概念理解開始，進行查詢類型識別，最後執行預期答案萃取。實驗結果顯示，我們的模型優於先前的改寫方法，特別是在 LLM 較不熟悉的主題中。我們證明了我們的模型較不依賴模型的內部參數知識，並且產生的查詢事實不正確的數量較少。此外，我們觀察到，與基準線相比，打造路徑的延遲較低。

##### **On the Complexity of Identification in Linear Structural Causal Models**
2407.12528v1 by Julian Dörfler, Benito van der Zander, Markus Bläser, Maciej Liskiewicz

Learning the unknown causal parameters of a linear structural causal model is
a fundamental task in causal analysis. The task, known as the problem of
identification, asks to estimate the parameters of the model from a combination
of assumptions on the graphical structure of the model and observational data,
represented as a non-causal covariance matrix. In this paper, we give a new
sound and complete algorithm for generic identification which runs in
polynomial space. By standard simulation results, this algorithm has
exponential running time which vastly improves the state-of-the-art double
exponential time method using a Gr\"obner basis approach. The paper also
presents evidence that parameter identification is computationally hard in
general. In particular, we prove, that the task asking whether, for a given
feasible correlation matrix, there are exactly one or two or more parameter
sets explaining the observed matrix, is hard for $\forall R$, the co-class of
the existential theory of the reals. In particular, this problem is
$coNP$-hard. To our best knowledge, this is the first hardness result for some
notion of identifiability.

摘要：學習線性結構因果模型中未知的因果參數是因果分析中的一項基本任務。此任務，稱為識別問題，要求從模型的圖形結構假設和觀察資料（表示為非因果共變異數矩陣）的組合中估計模型的參數。在本文中，我們提供了一種新的健全且完整的通用識別演算法，其在多項式空間中執行。根據標準模擬結果，此演算法具有指數執行時間，這大大改進了使用 Gr\"obner 基底方法的最新雙指數時間方法。本文還提供了證據證明，參數識別在一般情況下在計算上是困難的。特別是，我們證明了對於給定的可行相關矩陣，是否存在恰好一個或兩個或更多參數集來解釋觀察到的矩陣，這個任務對於 $\forall R$，實數存在理論的餘類，是很困難的。特別是，這個問題是 $coNP$-hard。據我們所知，這是某些可識別性概念的第一個困難度結果。

##### **Struct-X: Enhancing Large Language Models Reasoning with Structured Data**
2407.12522v1 by Xiaoyu Tan, Haoyu Wang, Xihe Qiu, Yuan Cheng, Yinghui Xu, Wei Chu, Yuan Qi

Structured data, rich in logical and relational information, has the
potential to enhance the reasoning abilities of large language models (LLMs).
Still, its integration poses a challenge due to the risk of overwhelming LLMs
with excessive tokens and irrelevant context information. To address this, we
propose Struct-X, a novel framework that operates through five key phases:
``read-model-fill-reflect-reason'' efficiently enabling LLMs to utilize
structured data. It begins by encoding structured data into a topological space
using graph embeddings, followed by filling in missing entity information with
knowledge retrieval modules, and filtering out irrelevant tokens via a
self-supervised module. The final phase involves constructing a topological
network with selected tokens to further reduce the total token length for more
effective LLM inference. Additionally, Struct-X includes an Auxiliary Module
trained to generate prompts, aiding LLMs in analyzing structured data.
Extensive experiments on benchmarks, including the knowledge graph
question-answer task and the long document reading comprehension task, show
that Struct-X notably improves LLM reasoning, demonstrating the effectiveness
of structured data augmentation in improving LLM inference with complex input
context.

摘要：結構化資料富含邏輯和關係資訊，有潛力增強大型語言模型 (LLM) 的推理能力。儘管如此，由於過多符號和無關脈絡資訊可能會讓 LLM 不堪負荷，因此整合此類資料構成了一項挑戰。為了解決此問題，我們提出 Struct-X，這是一個透過五個關鍵階段運作的新穎架構：``讀取-建模-填補-反思-推理''，有效地讓 LLM 能夠利用結構化資料。它首先使用圖形嵌入將結構化資料編碼到拓撲空間中，接著利用知識擷取模組填補遺失的實體資訊，並透過自我監督模組篩選出無關符號。最後一個階段涉及建構一個拓撲網路，其中包含選定的符號，以進一步減少總符號長度，以便更有效地進行 LLM 推論。此外，Struct-X 還包括一個輔助模組，經過訓練可以產生提示，協助 LLM 分析結構化資料。在基準上的大量實驗，包括知識圖譜問答任務和長篇文件閱讀理解任務，顯示 Struct-X 明顯改善了 LLM 推理，證明了結構化資料擴充在改善 LLM 推論時的有效性，特別是在輸入脈絡複雜的情況下。

##### **On Initializing Transformers with Pre-trained Embeddings**
2407.12514v1 by Ha Young Kim, Niranjan Balasubramanian, Byungkon Kang

It has become common practice now to use random initialization schemes,
rather than the pre-trained embeddings, when training transformer based models
from scratch. Indeed, we find that pre-trained word embeddings from GloVe, and
some sub-word embeddings extracted from language models such as T5 and mT5 fare
much worse compared to random initialization. This is counter-intuitive given
the well-known representational and transfer-learning advantages of
pre-training. Interestingly, we also find that BERT and mBERT embeddings fare
better than random initialization, showing the advantages of pre-trained
representations. In this work, we posit two potential factors that contribute
to these mixed results: the model sensitivity to parameter distribution and the
embedding interactions with position encodings. We observe that pre-trained
GloVe, T5, and mT5 embeddings have a wider distribution of values. As argued in
the initialization studies, such large value initializations can lead to poor
training because of saturated outputs. Further, the larger embedding values
can, in effect, absorb the smaller position encoding values when added
together, thus losing position information. Standardizing the pre-trained
embeddings to a narrow range (e.g. as prescribed by Xavier) leads to
substantial gains for Glove, T5, and mT5 embeddings. On the other hand, BERT
pre-trained embeddings, while larger, are still relatively closer to Xavier
initialization range which may allow it to effectively transfer the pre-trained
knowledge.

摘要：現今已普遍使用隨機初始化方案，而不是預訓練嵌入，從頭開始訓練基於Transformer的模型。事實上，我們發現來自 GloVe 的預訓練字詞嵌入，以及從語言模型（例如 T5 和 mT5）中提取的一些子字詞嵌入，與隨機初始化相比，表現要差得多。這與預訓練的眾所周知的表示和遷移學習優勢相悖。有趣的是，我們還發現 BERT 和 mBERT 嵌入比隨機初始化表現得更好，顯示了預訓練表示的優點。在這項工作中，我們假設了兩個潛在因素導致了這些混合結果：模型對參數分佈的敏感性，以及嵌入與位置編碼的交互作用。我們觀察到預訓練的 GloVe、T5 和 mT5 嵌入具有更廣泛的數值分佈。正如初始化研究中所論證的，如此大的數值初始化可能會導致訓練不佳，因為輸出飽和。此外，較大的嵌入值在相加時實際上可以吸收較小的位置編碼值，從而失去位置資訊。將預訓練嵌入標準化到一個較窄的範圍（例如由 Xavier 規定）會為 Glove、T5 和 mT5 嵌入帶來顯著的收益。另一方面，BERT 預訓練嵌入雖然較大，但仍相對接近 Xavier 初始化範圍，這可能允許其有效地轉移預訓練知識。

##### **$\textit{GeoHard}$: Towards Measuring Class-wise Hardness through Modelling Class Semantics**
2407.12512v1 by Fengyu Cai, Xinran Zhao, Hongming Zhang, Iryna Gurevych, Heinz Koeppl

Recent advances in measuring hardness-wise properties of data guide language
models in sample selection within low-resource scenarios. However,
class-specific properties are overlooked for task setup and learning. How will
these properties influence model learning and is it generalizable across
datasets? To answer this question, this work formally initiates the concept of
$\textit{class-wise hardness}$. Experiments across eight natural language
understanding (NLU) datasets demonstrate a consistent hardness distribution
across learning paradigms, models, and human judgment. Subsequent experiments
unveil a notable challenge in measuring such class-wise hardness with
instance-level metrics in previous works. To address this, we propose
$\textit{GeoHard}$ for class-wise hardness measurement by modeling class
geometry in the semantic embedding space. $\textit{GeoHard}$ surpasses
instance-level metrics by over 59 percent on $\textit{Pearson}$'s correlation
on measuring class-wise hardness. Our analysis theoretically and empirically
underscores the generality of $\textit{GeoHard}$ as a fresh perspective on data
diagnosis. Additionally, we showcase how understanding class-wise hardness can
practically aid in improving task learning.

摘要：<paragraph>最近在衡量資料硬度性質方面的進展，引導語言模型在低資源場景中進行樣本選擇。然而，在任務設定和學習中，類別特定的屬性卻被忽略了。這些屬性將如何影響模型學習，並且它是否可以在不同資料集之間進行推廣？為了回答這個問題，這項工作正式提出了「類別硬度」的概念。在八個自然語言理解 (NLU) 資料集中的實驗展示了在學習範例、模型和人類判斷中一致的硬度分佈。後續的實驗揭示了使用先前工作中的實例級別指標來衡量此類類別硬度時的一個顯著挑戰。為了解決這個問題，我們提出了「GeoHard」，用於類別硬度測量，方法是在語義嵌入空間中對類別幾何進行建模。「GeoHard」在測量類別硬度時，在「Pearson」相關性上比實例級別指標高出 59% 以上。我們的分析在理論上和經驗上強調了「GeoHard」作為資料診斷的新觀點的普遍性。此外，我們展示了理解類別硬度如何在實務上幫助改善任務學習。</paragraph>

##### **MERLIN: Multimodal Embedding Refinement via LLM-based Iterative Navigation for Text-Video Retrieval-Rerank Pipeline**
2407.12508v1 by Donghoon Han, Eunhwan Park, Gisang Lee, Adam Lee, Nojun Kwak

The rapid expansion of multimedia content has made accurately retrieving
relevant videos from large collections increasingly challenging. Recent
advancements in text-video retrieval have focused on cross-modal interactions,
large-scale foundation model training, and probabilistic modeling, yet often
neglect the crucial user perspective, leading to discrepancies between user
queries and the content retrieved. To address this, we introduce MERLIN
(Multimodal Embedding Refinement via LLM-based Iterative Navigation), a novel,
training-free pipeline that leverages Large Language Models (LLMs) for
iterative feedback learning. MERLIN refines query embeddings from a user
perspective, enhancing alignment between queries and video content through a
dynamic question answering process. Experimental results on datasets like
MSR-VTT, MSVD, and ActivityNet demonstrate that MERLIN substantially improves
Recall@1, outperforming existing systems and confirming the benefits of
integrating LLMs into multimodal retrieval systems for more responsive and
context-aware multimedia retrieval.

摘要：多媒體內容的快速擴張，使得從大型資料集中準確地檢索相關影片變得越來越具有挑戰性。最近在文字影片檢索方面的進展，一直專注於跨模態互動、大規模基礎模型訓練和機率模型，但卻常常忽略關鍵的使用者觀點，導致使用者查詢與檢索的內容之間出現差異。為了解決這個問題，我們引進了 MERLIN（透過基於 LLM 的反覆式瀏覽進行多模態內嵌式精煉），這是一個新穎、無需訓練的管線，可利用大型語言模型 (LLM) 進行反覆式回饋學習。MERLIN 從使用者的觀點精煉查詢內嵌，透過動態問答程序增強查詢與影片內容之間的一致性。在 MSR-VTT、MSVD 和 ActivityNet 等資料集上的實驗結果證明，MERLIN 大幅改善了 Recall@1，優於現有的系統，並確認了將 LLM 整合到多模態檢索系統中，以實現更具回應性且具備脈絡感知的多媒體檢索的優點。

##### **Case2Code: Learning Inductive Reasoning with Synthetic Data**
2407.12504v1 by Yunfan Shao, Linyang Li, Yichuan Ma, Peiji Li, Demin Song, Qinyuan Cheng, Shimin Li, Xiaonan Li, Pengyu Wang, Qipeng Guo, Hang Yan, Xipeng Qiu, Xuanjing Huang, Dahua Lin

Complex reasoning is an impressive ability shown by large language models
(LLMs). Most LLMs are skilled in deductive reasoning, such as chain-of-thought
prompting or iterative tool-using to solve challenging tasks step-by-step. In
this paper, we hope to focus on evaluating and teaching LLMs to conduct
inductive reasoning, that is, LLMs are supposed to infer underlying rules by
observing examples or sequential transformations. However, collecting
large-scale and diverse human-generated inductive data is challenging. We focus
on data synthesis in the code domain and propose a \textbf{Case2Code} task by
exploiting the expressiveness and correctness of programs. Specifically, we
collect a diverse set of executable programs, synthesize input-output
transformations for each program, and force LLMs to infer the underlying code
implementations based on the synthetic I/O cases. We first evaluate
representative LLMs on the synthesized Case2Code task and demonstrate that the
Case-to-code induction is challenging for LLMs. Then, we synthesize large-scale
Case2Code training samples to train LLMs to perform inductive reasoning.
Experimental results show that such induction training benefits not only in
distribution Case2Code performance but also enhances various coding abilities
of trained LLMs, demonstrating the great potential of learning inductive
reasoning via synthetic data.

摘要：大型語言模型 (LLM) 展現出令人印象深刻的複雜推理能力。大多數 LLM 都擅長演繹推理，例如思考鏈條提示或反覆使用工具來逐步解決具有挑戰性的任務。在本文中，我們希望專注於評估和指導 LLM 進行歸納推理，也就是說，LLM 應該透過觀察範例或順序轉換來推論底層規則。然而，收集大規模且多樣化的人類產生的歸納數據是一項挑戰。我們專注於程式碼領域的資料合成，並透過利用程式的表現力和正確性來提出一個 **Case2Code** 任務。具體來說，我們收集了一組多樣化的可執行程式，為每個程式合成輸入輸出轉換，並強迫 LLM 根據合成的 I/O 案例推論底層程式碼實作。我們首先在合成的 Case2Code 任務上評估具代表性的 LLM，並證明案例到程式碼的歸納對 LLM 來說具有挑戰性。然後，我們合成大規模的 Case2Code 訓練樣本，以訓練 LLM 執行歸納推理。實驗結果表明，這種歸納訓練不僅有利於分配 Case2Code 效能，還能增強訓練 LLM 的各種編碼能力，證明了透過合成資料學習歸納推理的巨大潛力。

##### **Automate or Assist? The Role of Computational Models in Identifying Gendered Discourse in US Capital Trial Transcripts**
2407.12500v1 by Andrea W Wen-Yi, Kathryn Adamson, Nathalie Greenfield, Rachel Goldberg, Sandra Babcock, David Mimno, Allison Koenecke

The language used by US courtroom actors in criminal trials has long been
studied for biases. However, systematic studies for bias in high-stakes court
trials have been difficult, due to the nuanced nature of bias and the legal
expertise required. New large language models offer the possibility to automate
annotation, saving time and cost. But validating these approaches requires both
high quantitative performance as well as an understanding of how automated
methods fit in existing workflows, and what they really offer. In this paper we
present a case study of adding an automated system to a complex and high-stakes
problem: identifying gender-biased language in US capital trials for women
defendants. Our team of experienced death-penalty lawyers and NLP technologists
pursued a three-phase study: first annotating manually, then training and
evaluating computational models, and finally comparing human annotations to
model predictions. Unlike many typical NLP tasks, annotating for gender bias in
months-long capital trials was a complicated task that involves with many
individual judgment calls. In contrast to standard arguments for automation
that are based on efficiency and scalability, legal experts found the
computational models most useful in challenging their personal bias in
annotation and providing opportunities to refine and build consensus on rules
for annotation. This suggests that seeking to replace experts with
computational models is both unrealistic and undesirable. Rather, computational
models offer valuable opportunities to assist the legal experts in
annotation-based studies.

摘要：美國法庭演員在刑事審判中所使用的語言長期以來一直被研究其偏見。然而，由於偏見的微妙性質和所需的法律專業知識，很難對高風險法庭審判中的偏見進行系統性研究。新的大型語言模型提供了自動化註解的可能性，節省了時間和成本。但是，驗證這些方法既需要高質量的定量表現，也需要了解自動化方法如何融入現有的工作流程以及它們真正提供的內容。在本文中，我們提出了將自動化系統添加到一個複雜且高風險的問題中的案例研究：識別美國死刑審判中針對女性被告的性別偏見語言。我們經驗豐富的死刑律師和 NLP 技術人員組成的團隊進行了一項三階段研究：首先手動註解，然後訓練和評估計算模型，最後將人工註解與模型預測進行比較。與許多典型的 NLP 任務不同，在為期數月的死刑審判中註解性別偏見是一項複雜的任務，涉及許多個人的判斷。與基於效率和可擴展性的標準自動化論點相反，法律專家發現計算模型在挑戰他們在註解中的個人偏見以及提供機會來完善和就註解規則達成共識方面最有幫助。這表明尋求用計算模型取代專家既不現實也不可取。相反，計算模型為法律專家提供有價值的機會，以協助基於註解的研究。

##### **Evaluating Linguistic Capabilities of Multimodal LLMs in the Lens of Few-Shot Learning**
2407.12498v1 by Mustafa Dogan, Ilker Kesen, Iacer Calixto, Aykut Erdem, Erkut Erdem

The linguistic capabilities of Multimodal Large Language Models (MLLMs) are
critical for their effective application across diverse tasks. This study aims
to evaluate the performance of MLLMs on the VALSE benchmark, focusing on the
efficacy of few-shot In-Context Learning (ICL), and Chain-of-Thought (CoT)
prompting. We conducted a comprehensive assessment of state-of-the-art MLLMs,
varying in model size and pretraining datasets. The experimental results reveal
that ICL and CoT prompting significantly boost model performance, particularly
in tasks requiring complex reasoning and contextual understanding. Models
pretrained on captioning datasets show superior zero-shot performance, while
those trained on interleaved image-text data benefit from few-shot learning.
Our findings provide valuable insights into optimizing MLLMs for better
grounding of language in visual contexts, highlighting the importance of the
composition of pretraining data and the potential of few-shot learning
strategies to improve the reasoning abilities of MLLMs.

摘要：多模態大型語言模型 (MLLM) 的語言能力對於它們在不同任務中的有效應用至關重要。本研究旨在評估 MLLM 在 VALSE 基準上的表現，重點關注少量 In-Context Learning (ICL) 和 Chain-of-Thought (CoT) 提示的效能。我們對最先進的 MLLM 進行了全面評估，這些模型在模型大小和預訓練資料集方面各不相同。實驗結果表明，ICL 和 CoT 提示顯著提升了模型效能，尤其是在需要複雜推理和語境理解的任務中。在標題資料集上預訓練的模型展現出優異的零次學習效能，而那些在交錯圖像文字資料上訓練的模型則受益於少量學習。我們的研究結果為優化 MLLM 以便在視覺語境中更好地建構語言提供了寶貴的見解，強調了預訓練資料的組成和少量學習策略在提升 MLLM 推理能力方面的潛力。

##### **Test-Time Adaptation with State-Space Models**
2407.12492v1 by Mona Schirmer, Dan Zhang, Eric Nalisnick

Distribution shifts between training and test data are all but inevitable
over the lifecycle of a deployed model and lead to performance decay. Adapting
the model can hopefully mitigate this drop in performance. Yet, adaptation is
challenging since it must be unsupervised: we usually do not have access to any
labeled data at test time. In this paper, we propose a probabilistic
state-space model that can adapt a deployed model subjected to distribution
drift. Our model learns the dynamics induced by distribution shifts on the last
set of hidden features. Without requiring labels, we infer time-evolving class
prototypes that serve as a dynamic classification head. Moreover, our approach
is lightweight, modifying only the model's last linear layer. In experiments on
real-world distribution shifts and synthetic corruptions, we demonstrate that
our approach performs competitively with methods that require back-propagation
and access to the model backbone. Our model especially excels in the case of
small test batches - the most difficult setting.

摘要：在部署模型的生命週期中，訓練和測試資料之間的分配轉移幾乎不可避免，並導致效能衰退。希望調整模型可以減輕這種效能下降。然而，調整具有挑戰性，因為它必須是無監督的：我們通常無法在測試時取得任何標籤資料。在本文中，我們提出了一個機率狀態空間模型，它可以調整因分佈偏移而受到影響的已部署模型。我們的模型學習由最後一組隱藏特徵上的分佈偏移所引發的動態。在不需要標籤的情況下，我們推斷出時間演進的類別原型，作為動態分類頭。此外，我們的做法很輕量級，僅修改模型的最後一個線性層。在真實世界分佈轉移和合成破壞的實驗中，我們證明了我們的做法與需要反向傳播和取得模型主幹的方法具有競爭力。我們的模型在小測試批次的情況下特別出色 - 這是最困難的設定。

##### **Pretraining Data and Tokenizer for Indic LLM**
2407.12481v1 by Rahul Kumar, Shubham Kakde, Divyansh Rajput, Daud Ibrahim, Rishabh Nahata, Pidathala Sowjanya, Deepak Kumar

We present a novel approach to data preparation for developing multilingual
Indic large language model. Our meticulous data acquisition spans open-source
and proprietary sources, including Common Crawl, Indic books, news articles,
and Wikipedia, ensuring a diverse and rich linguistic representation. For each
Indic language, we design a custom preprocessing pipeline to effectively
eliminate redundant and low-quality text content. Additionally, we perform
deduplication on Common Crawl data to address the redundancy present in 70% of
the crawled web pages. This study focuses on developing high-quality data,
optimizing tokenization for our multilingual dataset for Indic large language
models with 3B and 7B parameters, engineered for superior performance in Indic
languages. We introduce a novel multilingual tokenizer training strategy,
demonstrating our custom-trained Indic tokenizer outperforms the
state-of-the-art OpenAI Tiktoken tokenizer, achieving a superior token-to-word
ratio for Indic languages.

摘要：我們提出了一種用於開發多語言印度大型語言模型的資料準備新方法。我們嚴謹的資料收集涵蓋開源和專有來源，包括 Common Crawl、印度書籍、新聞文章和維基百科，確保語言表達的多樣性和豐富性。對於每種印度語言，我們設計一個自訂的前處理管道，以有效消除冗餘和低品質的文字內容。此外，我們對 Common Crawl 資料執行重複資料刪除，以解決 70% 已爬取網頁中存在的冗餘問題。本研究專注於開發高品質資料，針對我們的多語言資料集最佳化用於印度大型語言模型的標記化，參數為 3B 和 7B，旨在提升印度語言的卓越效能。我們引入一種新的多語言標記化訓練策略，證明我們自訂訓練的印度標記化器優於最先進的 OpenAI Tiktoken 標記化器，在印度語言中達成優異的詞彙標記比例。

##### **A Novel Dependency Framework for Enhancing Discourse Data Analysis**
2407.12473v1 by Kun Sun, Rong Wang

The development of different theories of discourse structure has led to the
establishment of discourse corpora based on these theories. However, the
existence of discourse corpora established on different theoretical bases
creates challenges when it comes to exploring them in a consistent and cohesive
way. This study has as its primary focus the conversion of PDTB annotations
into dependency structures. It employs refined BERT-based discourse parsers to
test the validity of the dependency data derived from the PDTB-style corpora in
English, Chinese, and several other languages. By converting both PDTB and RST
annotations for the same texts into dependencies, this study also applies
``dependency distance'' metrics to examine the correlation between RST
dependencies and PDTB dependencies in English. The results show that the PDTB
dependency data is valid and that there is a strong correlation between the two
types of dependency distance. This study presents a comprehensive approach for
analyzing and evaluating discourse corpora by employing discourse dependencies
to achieve unified analysis. By applying dependency representations, we can
extract data from PDTB, RST, and SDRT corpora in a coherent and unified manner.
Moreover, the cross-linguistic validation establishes the framework's
generalizability beyond English. The establishment of this comprehensive
dependency framework overcomes limitations of existing discourse corpora,
supporting a diverse range of algorithms and facilitating further studies in
computational discourse analysis and language sciences.

摘要：語篇結構不同理論的發展，導致了基於這些理論的語篇語料庫的建立。然而，建立在不同理論基礎上的語篇語料庫的存在，在一致且連貫的方式探索它們時產生了挑戰。本研究的主要焦點是將 PDTB 標註轉換為依賴結構。它採用經過改良的 BERT-based 語篇解析器，以測試從英語、中文和幾種其他語言的 PDTB 風格語料庫中衍生的依賴數據的有效性。通過將同一文本的 PDTB 和 RST 標註轉換為依賴關係，本研究還應用「依賴距離」度量來檢驗英語中 RST 依賴關係和 PDTB 依賴關係之間的相關性。結果表明，PDTB 依賴數據是有效的，並且這兩種類型的依賴距離之間存在很強的相關性。本研究提出了一個綜合的方法，通過採用語篇依賴關係來分析和評估語篇語料庫，以實現統一的分析。通過應用依賴關係表示，我們可以以連貫且統一的方式從 PDTB、RST 和 SDRT 語料庫中提取數據。此外，跨語言驗證在英語之外建立了該框架的普遍性。這個綜合依賴關係框架的建立克服了現有語篇語料庫的局限性，支持各種演算法，並促進了計算語篇分析和語言科學的進一步研究。

##### **Characterization of Political Polarized Users Attacked by Language Toxicity on Twitter**
2407.12471v1 by Wentao Xu

Understanding the dynamics of language toxicity on social media is important
for us to investigate the propagation of misinformation and the development of
echo chambers for political scenarios such as U.S. presidential elections.
Recent research has used large-scale data to investigate the dynamics across
social media platforms. However, research on the toxicity dynamics is not
enough. This study aims to provide a first exploration of the potential
language toxicity flow among Left, Right and Center users. Specifically, we aim
to examine whether Left users were easier to be attacked by language toxicity.
In this study, more than 500M Twitter posts were examined. It was discovered
that Left users received much more toxic replies than Right and Center users.

摘要：了解社交媒体上语言毒性的动态对于我们调查错误信息的传播和政治场景（例如美国总统选举）的回音室的发展非常重要。最近的研究使用大规模数据来调查社交媒体平台上的动态。然而，关于毒性动态的研究还不够。本研究旨在对左派、右派和中间派用户之间的潜在语言毒性流动进行首次探索。具体来说，我们的目标是检验左派用户是否更容易受到语言毒性的攻击。在这项研究中，检查了超过 5 亿条 Twitter 帖子。结果发现，左派用户收到的有毒回复比右派和中间派用户多得多。

##### **Continual Learning for Temporal-Sensitive Question Answering**
2407.12470v1 by Wanqi Yang, Yunqiu Xu, Yanda Li, Kunze Wang, Binbin Huang, Ling Chen

In this study, we explore an emerging research area of Continual Learning for
Temporal Sensitive Question Answering (CLTSQA). Previous research has primarily
focused on Temporal Sensitive Question Answering (TSQA), often overlooking the
unpredictable nature of future events. In real-world applications, it's crucial
for models to continually acquire knowledge over time, rather than relying on a
static, complete dataset. Our paper investigates strategies that enable models
to adapt to the ever-evolving information landscape, thereby addressing the
challenges inherent in CLTSQA. To support our research, we first create a novel
dataset, divided into five subsets, designed specifically for various stages of
continual learning. We then propose a training framework for CLTSQA that
integrates temporal memory replay and temporal contrastive learning. Our
experimental results highlight two significant insights: First, the CLTSQA task
introduces unique challenges for existing models. Second, our proposed
framework effectively navigates these challenges, resulting in improved
performance.

摘要：在本研究中，我们探讨了一个新兴的研究领域，即针对时间敏感问题解答 (CLTSQA) 的持续学习。以往的研究主要集中在时间敏感问题解答 (TSQA) 上，往往忽略了未来事件的不可预测性。在实际应用中，至关重要的是，模型能够随着时间的推移不断获取知识，而不是依赖于静态的、完整的数据集。我们的论文研究了使模型能够适应不断变化的信息环境的策略，从而解决了 CLTSQA 中固有的挑战。为了支持我们的研究，我们首先创建了一个新颖的数据集，将其分为五个子集，专门针对持续学习的不同阶段而设计。然后，我们提出了一个用于 CLTSQA 的训练框架，该框架集成了时间记忆重放和时间对比学习。我们的实验结果突出了两个重要的见解：首先，CLTSQA 任务给现有模型带来了独特的挑战。其次，我们提出的框架有效地解决了这些挑战，从而提高了性能。

##### **Search Engines, LLMs or Both? Evaluating Information Seeking Strategies for Answering Health Questions**
2407.12468v1 by Fernández-Pichel Marcos, Pichel Juan C., Losada David E

Search engines have traditionally served as primary tools for information
seeking. However, the new Large Language Models (LLMs) have recently
demonstrated remarkable capabilities in multiple tasks and, specifically, their
adoption as question answering systems is becoming increasingly prevalent. It
is expected that LLM-based conversational systems and traditional web engines
will continue to coexist in the future, supporting end users in various ways.
But there is a need for more scientific research on the effectiveness of both
types of systems in facilitating accurate information seeking. In this study,
we focus on their merits in answering health questions. We conducted an
extensive study comparing different web search engines, LLMs and
retrieval-augmented (RAG) approaches. Our research reveals intriguing
conclusions. For example, we observed that the quality of webpages potentially
responding to a health question does not decline as we navigate further down
the ranked lists. However, according to our evaluation, web engines are less
accurate than LLMs in finding correct answers to health questions. On the other
hand, LLMs are quite sensitive to the input prompts, and we also found out that
RAG leads to highly effective information seeking methods.

摘要：搜索引擎一直作為尋求資訊的主要工具。然而，新的大型語言模型 (LLM) 最近在多項任務中展現了非凡的能力，特別是它們作為問答系統的採用正變得越來越普遍。預計基於 LLM 的對話系統和傳統網路引擎將繼續在未來共存，以各種方式支援最終使用者。但需要對這兩種系統在促進準確資訊尋求方面的有效性進行更多科學研究。在這項研究中，我們專注於它們在回答健康問題方面的優點。我們進行了一項廣泛的研究，比較了不同的網路搜尋引擎、LLM 和檢索增強 (RAG) 方法。我們的研究揭示了有趣的結論。例如，我們觀察到，隨著我們在排名列表中向下瀏覽，潛在回應健康問題的網頁品質並不會下降。然而，根據我們的評估，網路引擎在尋找正確的健康問題答案方面不如 LLM 準確。另一方面，LLM 對輸入提示相當敏感，我們還發現 RAG 導致高度有效的資訊尋求方法。

##### **Across Platforms and Languages: Dutch Influencers and Legal Disclosures on Instagram, YouTube and TikTok**
2407.12451v1 by Haoyang Gui, Thales Bertaglia, Catalina Goanta, Sybe de Vries, Gerasimos Spanakis

Content monetization on social media fuels a growing influencer economy.
Influencer marketing remains largely undisclosed or inappropriately disclosed
on social media. Non-disclosure issues have become a priority for national and
supranational authorities worldwide, who are starting to impose increasingly
harsher sanctions on them. This paper proposes a transparent methodology for
measuring whether and how influencers comply with disclosures based on legal
standards. We introduce a novel distinction between disclosures that are
legally sufficient (green) and legally insufficient (yellow). We apply this
methodology to an original dataset reflecting the content of 150 Dutch
influencers publicly registered with the Dutch Media Authority based on
recently introduced registration obligations. The dataset consists of 292,315
posts and is multi-language (English and Dutch) and cross-platform (Instagram,
YouTube and TikTok). We find that influencer marketing remains generally
underdisclosed on social media, and that bigger influencers are not necessarily
more compliant with disclosure standards.

摘要：社群媒體上的內容變現推動了成長中的網紅經濟。
網紅行銷在社群媒體上仍有許多未揭露或揭露不當的狀況。未揭露的問題已成為全球國家和超國家機關的優先事項，他們開始對這些問題實施越來越嚴厲的制裁。本文提出了一種透明的方法，用於衡量網紅是否且如何根據法律標準遵守揭露規定。我們引入了合法充足（綠色）和合法不足（黃色）揭露之間的新區別。我們將此方法應用於一個原始資料集，反映了 150 位荷蘭網紅的內容，這些網紅根據最近推出的註冊義務在荷蘭媒體管理局公開註冊。該資料集包含 292,315 篇貼文，並且是多語言（英語和荷蘭語）和跨平台（Instagram、YouTube 和 TikTok）的。我們發現網紅行銷在社群媒體上仍然普遍未揭露，而且較大型的網紅並不一定更符合揭露標準。

##### **Close the Sim2real Gap via Physically-based Structured Light Synthetic Data Simulation**
2407.12449v1 by Kaixin Bai, Lei Zhang, Zhaopeng Chen, Fang Wan, Jianwei Zhang

Despite the substantial progress in deep learning, its adoption in industrial
robotics projects remains limited, primarily due to challenges in data
acquisition and labeling. Previous sim2real approaches using domain
randomization require extensive scene and model optimization. To address these
issues, we introduce an innovative physically-based structured light simulation
system, generating both RGB and physically realistic depth images, surpassing
previous dataset generation tools. We create an RGBD dataset tailored for
robotic industrial grasping scenarios and evaluate it across various tasks,
including object detection, instance segmentation, and embedding sim2real
visual perception in industrial robotic grasping. By reducing the sim2real gap
and enhancing deep learning training, we facilitate the application of deep
learning models in industrial settings. Project details are available at
https://baikaixinpublic.github.io/structured light 3D synthesizer/.

摘要：儘管深度學習有顯著進展，但其在產業機器人專案中的採用仍然有限，這主要是由於在資料取得和標籤化方面的挑戰。先前使用網域隨機化的 sim2real 方法需要廣泛的場景和模型最佳化。為了解決這些問題，我們引進了一個創新的基於物理結構光模擬系統，它可以產生 RGB 和物理上逼真的深度影像，超越了先前的資料集產生工具。我們建立了一個專門針對機器人產業抓取場景的 RGBD 資料集，並在各種任務中對其進行評估，包括物體偵測、實例分割，以及將 sim2real 視覺感知嵌入到產業機器人抓取中。透過縮小 sim2real 的差距並增強深度學習訓練，我們促進了深度學習模型在產業環境中的應用。專案詳細資訊可見於 https://baikaixinpublic.github.io/structured light 3D synthesizer/。

##### **Sharif-STR at SemEval-2024 Task 1: Transformer as a Regression Model for Fine-Grained Scoring of Textual Semantic Relations**
2407.12426v1 by Seyedeh Fatemeh Ebrahimi, Karim Akhavan Azari, Amirmasoud Iravani, Hadi Alizadeh, Zeinab Sadat Taghavi, Hossein Sameti

Semantic Textual Relatedness holds significant relevance in Natural Language
Processing, finding applications across various domains. Traditionally,
approaches to STR have relied on knowledge-based and statistical methods.
However, with the emergence of Large Language Models, there has been a paradigm
shift, ushering in new methodologies. In this paper, we delve into the
investigation of sentence-level STR within Track A (Supervised) by leveraging
fine-tuning techniques on the RoBERTa transformer. Our study focuses on
assessing the efficacy of this approach across different languages. Notably,
our findings indicate promising advancements in STR performance, particularly
in Latin languages. Specifically, our results demonstrate notable improvements
in English, achieving a correlation of 0.82 and securing a commendable 19th
rank. Similarly, in Spanish, we achieved a correlation of 0.67, securing the
15th position. However, our approach encounters challenges in languages like
Arabic, where we observed a correlation of only 0.38, resulting in a 20th rank.

摘要：語義文本相關性在自然語言處理中具有重要意義，可在各種領域中找到應用。傳統上，STR 的方法依賴於基於知識和統計的方法。然而，隨著大型語言模型的出現，已經發生了範式轉變，引入了新的方法。在本文中，我們深入探討了通過在 RoBERTa 轉換器上利用微調技術在軌道 A（監督）中句子級 STR 的研究。我們的研究重點是評估這種方法在不同語言中的有效性。值得注意的是，我們的研究結果表明 STR 性能有望取得進步，特別是在拉丁語中。具體來說，我們的結果證明了英語的顯著改進，相關性達到 0.82，並獲得了令人稱道的第 19 名。同樣，在西班牙語中，我們實現了 0.67 的相關性，獲得了第 15 名。然而，我們的做法在阿拉伯語等語言中遇到了挑戰，我們觀察到的相關性僅為 0.38，導致排名第 20 位。

##### **Navigating the Noisy Crowd: Finding Key Information for Claim Verification**
2407.12425v1 by Haisong Gong, Huanhuan Ma, Qiang Liu, Shu Wu, Liang Wang

Claim verification is a task that involves assessing the truthfulness of a
given claim based on multiple evidence pieces. Using large language models
(LLMs) for claim verification is a promising way. However, simply feeding all
the evidence pieces to an LLM and asking if the claim is factual does not yield
good results. The challenge lies in the noisy nature of both the evidence and
the claim: evidence passages typically contain irrelevant information, with the
key facts hidden within the context, while claims often convey multiple aspects
simultaneously. To navigate this "noisy crowd" of information, we propose EACon
(Evidence Abstraction and Claim Deconstruction), a framework designed to find
key information within evidence and verify each aspect of a claim separately.
EACon first finds keywords from the claim and employs fuzzy matching to select
relevant keywords for each raw evidence piece. These keywords serve as a guide
to extract and summarize critical information into abstracted evidence.
Subsequently, EACon deconstructs the original claim into subclaims, which are
then verified against both abstracted and raw evidence individually. We
evaluate EACon using two open-source LLMs on two challenging datasets. Results
demonstrate that EACon consistently and substantially improve LLMs' performance
in claim verification.

摘要：聲明驗證是一項任務，涉及根據多個證據片段評估聲明的真實性。使用大型語言模型 (LLM) 進行聲明驗證是一種很有前途的方法。然而，僅僅將所有證據片段提供給 LLM 並詢問聲明是否屬實並不能產生良好的結果。挑戰在於證據和聲明的嘈雜性質：證據段落通常包含無關信息，關鍵事實隱藏在上下文中，而聲明通常同時傳達多個方面。為了應對這一「嘈雜人群」的信息，我們提出了 EACon（證據抽象和聲明解構），一個旨在在證據中查找關鍵信息並分別驗證聲明中每一個方面的框架。EACon 首先從聲明中找到關鍵字，並使用模糊匹配為每個原始證據片段選擇相關關鍵字。這些關鍵字作為指南，用於提取和總結關鍵信息，形成抽象證據。隨後，EACon 將原始聲明解構為子聲明，然後分別針對抽象證據和原始證據對其進行驗證。我們使用兩個開源 LLM 在兩個具有挑戰性的數據集上評估 EACon。結果表明，EACon 持續且大幅度地提高了 LLM 在聲明驗證中的性能。

##### **StuGPTViz: A Visual Analytics Approach to Understand Student-ChatGPT Interactions**
2407.12423v1 by Zixin Chen, Jiachen Wang, Meng Xia, Kento Shigyo, Dingdong Liu, Rong Zhang, Huamin Qu

The integration of Large Language Models (LLMs), especially ChatGPT, into
education is poised to revolutionize students' learning experiences by
introducing innovative conversational learning methodologies. To empower
students to fully leverage the capabilities of ChatGPT in educational
scenarios, understanding students' interaction patterns with ChatGPT is crucial
for instructors. However, this endeavor is challenging due to the absence of
datasets focused on student-ChatGPT conversations and the complexities in
identifying and analyzing the evolutional interaction patterns within
conversations. To address these challenges, we collected conversational data
from 48 students interacting with ChatGPT in a master's level data
visualization course over one semester. We then developed a coding scheme,
grounded in the literature on cognitive levels and thematic analysis, to
categorize students' interaction patterns with ChatGPT. Furthermore, we present
a visual analytics system, StuGPTViz, that tracks and compares temporal
patterns in student prompts and the quality of ChatGPT's responses at multiple
scales, revealing significant pedagogical insights for instructors. We
validated the system's effectiveness through expert interviews with six data
visualization instructors and three case studies. The results confirmed
StuGPTViz's capacity to enhance educators' insights into the pedagogical value
of ChatGPT. We also discussed the potential research opportunities of applying
visual analytics in education and developing AI-driven personalized learning
solutions.

摘要：大型語言模型（LLM），特別是 ChatGPT，整合到教育中，準備透過導入創新的對話式學習方法來革新學生的學習體驗。為了讓學生在教育場景中充分利用 ChatGPT 的功能，對於教師而言，了解學生與 ChatGPT 的互動模式至關重要。然而，由於缺乏專注於學生與 ChatGPT 對話的資料集，以及辨識和分析對話中演化互動模式的複雜性，因此這項工作充滿挑戰。為了應對這些挑戰，我們從 48 位學生在一個學期的碩士級資料視覺化課程中與 ChatGPT 互動中收集對話資料。接著，我們根據認知層次和主題分析的文獻，開發了一個編碼架構，以分類學生與 ChatGPT 的互動模式。此外，我們提出一個視覺分析系統 StuGPTViz，用於追蹤和比較學生提示中的時間模式和 ChatGPT 回應在多個層面的品質，揭示了對教師而言重要的教學見解。我們透過與六位資料視覺化教師的專家訪談和三個案例研究驗證了該系統的有效性。結果證實了 StuGPTViz 能夠提升教育者對 ChatGPT 教學價值的見解。我們也討論了在教育中應用視覺分析和開發由 AI 驅動的個人化學習解決方案的潛在研究機會。

##### **SafePowerGraph: Safety-aware Evaluation of Graph Neural Networks for Transmission Power Grids**
2407.12421v1 by Salah Ghamizi, Aleksandar Bojchevski, Aoxiang Ma, Jun Cao

Power grids are critical infrastructures of paramount importance to modern
society and their rapid evolution and interconnections has heightened the
complexity of power systems (PS) operations. Traditional methods for grid
analysis struggle with the computational demands of large-scale RES and ES
integration, prompting the adoption of machine learning (ML) techniques,
particularly Graph Neural Networks (GNNs). GNNs have proven effective in
solving the alternating current (AC) Power Flow (PF) and Optimal Power Flow
(OPF) problems, crucial for operational planning. However, existing benchmarks
and datasets completely ignore safety and robustness requirements in their
evaluation and never consider realistic safety-critical scenarios that most
impact the operations of the power grids. We present SafePowerGraph, the first
simulator-agnostic, safety-oriented framework and benchmark for GNNs in PS
operations. SafePowerGraph integrates multiple PF and OPF simulators and
assesses GNN performance under diverse scenarios, including energy price
variations and power line outages. Our extensive experiments underscore the
importance of self-supervised learning and graph attention architectures for
GNN robustness. We provide at https://github.com/yamizi/SafePowerGraph our
open-source repository, a comprehensive leaderboard, a dataset and model zoo
and expect our framework to standardize and advance research in the critical
field of GNN for power systems.

摘要：電網是對現代社會至關重要的關鍵基礎設施，其快速演進和互連性增加了電力系統 (PS) 運作的複雜性。傳統的電網分析方法難以應付大規模再生能源 (RES) 和儲能系統 (ES) 整合的計算需求，促使採用機器學習 (ML) 技術，尤其是圖神經網路 (GNN)。GNN 已被證明可有效解決交流 (AC) 功率流 (PF) 和最佳功率流 (OPF) 問題，這些問題對於運作規劃至關重要。然而，現有的基準和資料集在評估中完全忽略了安全性和穩健性要求，而且從未考慮對電網運作影響最大的現實安全關鍵情境。我們提出 SafePowerGraph，這是第一個與模擬器無關、以安全性為導向的框架和 GNN 基準，用於 PS 運作。SafePowerGraph 整合多個 PF 和 OPF 模擬器，並在各種情境下評估 GNN 效能，包括能源價格變動和輸電線路中斷。我們廣泛的實驗強調了自監督學習和圖注意力架構對於 GNN 穩健性的重要性。我們在 https://github.com/yamizi/SafePowerGraph 提供我們的開放原始碼存放庫、一個全面的排行榜、一個資料集和模型動物園，並期待我們的框架標準化並推進電能系統 GNN 這個關鍵領域的研究。

##### **Proximity-based Self-Federated Learning**
2407.12410v1 by Davide Domini, Gianluca Aguzzi, Nicolas Farabegoli, Mirko Viroli, Lukas Esterle

In recent advancements in machine learning, federated learning allows a
network of distributed clients to collaboratively develop a global model
without needing to share their local data. This technique aims to safeguard
privacy, countering the vulnerabilities of conventional centralized learning
methods. Traditional federated learning approaches often rely on a central
server to coordinate model training across clients, aiming to replicate the
same model uniformly across all nodes. However, these methods overlook the
significance of geographical and local data variances in vast networks,
potentially affecting model effectiveness and applicability. Moreover, relying
on a central server might become a bottleneck in large networks, such as the
ones promoted by edge computing. Our paper introduces a novel,
fully-distributed federated learning strategy called proximity-based
self-federated learning that enables the self-organised creation of multiple
federations of clients based on their geographic proximity and data
distribution without exchanging raw data. Indeed, unlike traditional
algorithms, our approach encourages clients to share and adjust their models
with neighbouring nodes based on geographic proximity and model accuracy. This
method not only addresses the limitations posed by diverse data distributions
but also enhances the model's adaptability to different regional
characteristics creating specialized models for each federation. We demonstrate
the efficacy of our approach through simulations on well-known datasets,
showcasing its effectiveness over the conventional centralized federated
learning framework.

摘要：在機器學習的最新進展中，聯邦學習允許分散式用戶端網路共同開發一個全球模型，而無需分享其當地資料。此技術旨在保護隱私，對抗傳統集中式學習方法的漏洞。傳統的聯邦學習方法通常依賴於中央伺服器來協調用戶端的模型訓練，旨在在所有節點中均勻複製同一個模型。然而，這些方法忽略了廣大網路中地理和當地資料差異的重要性，可能會影響模型的有效性和適用性。此外，依賴於中央伺服器可能會成為大型網路中的瓶頸，例如邊緣運算所推廣的網路。我們的論文介紹了一種新穎的、完全分散的聯邦學習策略，稱為基於接近性的自我聯邦學習，它能根據用戶端的地理接近性和資料分佈，讓用戶端能自行組織建立多個聯邦，而無需交換原始資料。事實上，與傳統演算法不同，我們的做法鼓勵用戶端根據地理接近性和模型準確度，與鄰近節點分享和調整其模型。此方法不僅解決了不同資料分佈所造成的限制，而且還增強了模型對不同區域特性的適應性，為每個聯邦建立專業模型。我們透過在眾所周知的資料集上進行模擬，證明了我們方法的功效，展示了其相較於傳統集中式聯邦學習架構的有效性。

##### **TurkishMMLU: Measuring Massive Multitask Language Understanding in Turkish**
2407.12402v1 by Arda Yüksel, Abdullatif Köksal, Lütfi Kerem Şenel, Anna Korhonen, Hinrich Schütze

Multiple choice question answering tasks evaluate the reasoning,
comprehension, and mathematical abilities of Large Language Models (LLMs).
While existing benchmarks employ automatic translation for multilingual
evaluation, this approach is error-prone and potentially introduces culturally
biased questions, especially in social sciences. We introduce the first
multitask, multiple-choice Turkish QA benchmark, TurkishMMLU, to evaluate LLMs'
understanding of the Turkish language. TurkishMMLU includes over 10,000
questions, covering 9 different subjects from Turkish high-school education
curricula. These questions are written by curriculum experts, suitable for the
high-school curricula in Turkey, covering subjects ranging from natural
sciences and math questions to more culturally representative topics such as
Turkish Literature and the history of the Turkish Republic. We evaluate over 20
LLMs, including multilingual open-source (e.g., Gemma, Llama, MT5),
closed-source (GPT 4o, Claude, Gemini), and Turkish-adapted (e.g., Trendyol)
models. We provide an extensive evaluation, including zero-shot and few-shot
evaluation of LLMs, chain-of-thought reasoning, and question difficulty
analysis along with model performance. We provide an in-depth analysis of the
Turkish capabilities and limitations of current LLMs to provide insights for
future LLMs for the Turkish language. We publicly release our code for the
dataset and evaluation: https://github.com/ArdaYueksel/TurkishMMLU.

摘要：多選題問答任務評估大型語言模型 (LLM) 的推理、理解和數學能力。
雖然現有的基準採用機器翻譯進行多語言評估，但這種方法容易出錯，並可能引入文化偏見的問題，特別是在社會科學領域。我們引入了第一個多任務多選土耳其問答基準 TurkishMMLU，以評估 LLM 對土耳其語的理解。TurkishMMLU 包含超過 10,000 個問題，涵蓋土耳其高中教育課程中的 9 個不同科目。這些問題由課程專家編寫，適合土耳其的高中課程，涵蓋範圍從自然科學和數學問題到更具文化代表性的主題，例如土耳其文學和土耳其共和國的歷史。我們評估了 20 多個 LLM，包括多語言開源（例如 Gemma、Llama、MT5）、閉源（GPT 4o、Claude、Gemini）和土耳其改編（例如 Trendyol）模型。我們提供了廣泛的評估，包括 LLM 的零次學習和少次學習評估、思考鏈推理和問題難度分析以及模型效能。我們對當前 LLM 的土耳其語能力和限制進行了深入分析，以提供對未來土耳其語 LLM 的見解。我們公開發布我們的代碼以供資料集和評估使用：https://github.com/ArdaYueksel/TurkishMMLU。

##### **Mamba-PTQ: Outlier Channels in Recurrent Large Language Models**
2407.12397v1 by Alessandro Pierro, Steven Abreu

Modern recurrent layers are emerging as a promising path toward edge
deployment of foundation models, especially in the context of large language
models (LLMs). Compressing the whole input sequence in a finite-dimensional
representation enables recurrent layers to model long-range dependencies while
maintaining a constant inference cost for each token and a fixed memory
requirement. However, the practical deployment of LLMs in resource-limited
environments often requires further model compression, such as quantization and
pruning. While these techniques are well-established for attention-based
models, their effects on recurrent layers remain underexplored.
  In this preliminary work, we focus on post-training quantization for
recurrent LLMs and show that Mamba models exhibit the same pattern of outlier
channels observed in attention-based LLMs. We show that the reason for the
difficulty of quantizing SSMs is caused by activation outliers, similar to
those observed in transformer-based LLMs. We report baseline results for
post-training quantization of Mamba that do not take into account the
activation outliers and suggest first steps for outlier-aware quantization.

摘要：現代遞迴層正成為基礎模型邊緣部署的有前景途徑，特別是在大型語言模型 (LLM) 的背景下。將整個輸入序列壓縮成有限維表示，使遞迴層能夠建模長距離依賴關係，同時為每個符號和固定的記憶體需求維持恆定的推論成本。然而，在資源受限的環境中實際部署 LLM 通常需要進一步的模型壓縮，例如量化和剪枝。雖然這些技術已在基於注意力的模型中得到充分確立，但它們對遞迴層的影響仍然未得到充分探討。
在這項初步工作中，我們專注於遞迴 LLM 的訓練後量化，並展示 Mamba 模型展現出與基於注意力的 LLM 中觀察到的異常通道相同的模式。我們展示了量化 SSM 的難度是由於激活異常值造成的，這與在基於Transformer的 LLM 中觀察到的情況類似。我們報告了 Mamba 訓練後量化的基準結果，這些結果沒有考慮激活異常值，並建議了異常感知量化的第一步。

##### **PersLLM: A Personified Training Approach for Large Language Models**
2407.12393v1 by Zheni Zeng, Jiayi Chen, Huimin Chen, Yukun Yan, Yuxuan Chen, Zhiyuan Liu, Maosong Sun

Large language models exhibit aspects of human-level intelligence that
catalyze their application as human-like agents in domains such as social
simulations, human-machine interactions, and collaborative multi-agent systems.
However, the absence of distinct personalities, such as displaying ingratiating
behaviors, inconsistent opinions, and uniform response patterns, diminish LLMs
utility in practical applications. Addressing this, the development of
personality traits in LLMs emerges as a crucial area of research to unlock
their latent potential. Existing methods to personify LLMs generally involve
strategies like employing stylized training data for instruction tuning or
using prompt engineering to simulate different personalities. These methods
only capture superficial linguistic styles instead of the core of personalities
and are therefore not stable. In this study, we propose PersLLM, integrating
psychology-grounded principles of personality: social practice, consistency,
and dynamic development, into a comprehensive training methodology. We
incorporate personality traits directly into the model parameters, enhancing
the model's resistance to induction, promoting consistency, and supporting the
dynamic evolution of personality. Single-agent evaluation validates our
method's superiority, as it produces responses more aligned with reference
personalities compared to other approaches. Case studies for multi-agent
communication highlight its benefits in enhancing opinion consistency within
individual agents and fostering collaborative creativity among multiple agents
in dialogue contexts, potentially benefiting human simulation and multi-agent
cooperation. Additionally, human-agent interaction evaluations indicate that
our personified models significantly enhance interactive experiences,
underscoring the practical implications of our research.

摘要：大型語言模型展現出人類程度的智慧層面，催化它們在社交模擬、人機互動和協作多重代理系統等領域中作為類人代理的應用。然而，缺乏鮮明的個性，例如表現出討好行為、意見不一致和統一的回應模式，降低了 LLM 在實際應用中的效用。為了解決這個問題，在 LLM 中發展人格特質成為了解鎖其潛在能力的關鍵研究領域。使 LLM 人格化的現有方法通常涉及策略，例如採用風格化的訓練資料進行指令調整或使用提示工程來模擬不同的人格。這些方法僅捕捉到表面的語言風格，而不是人格的核心，因此不穩定。在本研究中，我們提出了 PersLLM，將人格的心理學基礎原則：社會實踐、一致性和動態發展整合到一個全面的訓練方法中。我們將人格特質直接納入模型參數中，增強模型對歸納的抵抗力、促進一致性並支持人格的動態演化。單一代理評估驗證了我們方法的優越性，因為與其他方法相比，它產生的回應更符合參考人格。多重代理溝通的案例研究突出了它在增強單一代理內意見一致性以及在對話情境中促進多重代理之間的協作創造力方面的優點，這可能有利於人類模擬和多重代理合作。此外，人機互動評估表明，我們的人格化模型顯著增強了互動體驗，強調了我們研究的實際意義。

##### **LLM Inference Serving: Survey of Recent Advances and Opportunities**
2407.12391v1 by Baolin Li, Yankai Jiang, Vijay Gadepally, Devesh Tiwari

This survey offers a comprehensive overview of recent advancements in Large
Language Model (LLM) serving systems, focusing on research since the year 2023.
We specifically examine system-level enhancements that improve performance and
efficiency without altering the core LLM decoding mechanisms. By selecting and
reviewing high-quality papers from prestigious ML and system venues, we
highlight key innovations and practical considerations for deploying and
scaling LLMs in real-world production environments. This survey serves as a
valuable resource for LLM practitioners seeking to stay abreast of the latest
developments in this rapidly evolving field.

摘要：本調查提供了大型語言模型 (LLM) 服務系統近期進展的全面概述，重點關注 2023 年以來的研究。我們特別探討了在不改變核心 LLM 解碼機制的同時，改善效能和效率的系統層級強化功能。透過選取和檢閱來自知名機器學習和系統場域的高品質論文，我們重點介紹了在實際生產環境中部署和擴充 LLM 的關鍵創新和實務考量。本調查可作為 LLM 從業人員的寶貴資源，協助他們隨時掌握這個快速演進領域的最新發展。

##### **Morphosyntactic Analysis for CHILDES**
2407.12389v1 by Houjun Liu, Brian MacWhinney

Language development researchers are interested in comparing the process of
language learning across languages. Unfortunately, it has been difficult to
construct a consistent quantitative framework for such comparisons. However,
recent advances in AI (Artificial Intelligence) and ML (Machine Learning) are
providing new methods for ASR (automatic speech recognition) and NLP (natural
language processing) that can be brought to bear on this problem. Using the
Batchalign2 program (Liu et al., 2023), we have been transcribing and linking
data for the CHILDES database and have applied the UD (Universal Dependencies)
framework to provide a consistent and comparable morphosyntactic analysis for
27 languages. These new resources open possibilities for deeper crosslinguistic
study of language learning.

摘要：語言發展研究人員有興趣比較跨語言的語言學習過程。遺憾的是，建立一個一致的量化架構來進行此類比較一直很困難。然而，人工智慧 (AI) 和機器學習 (ML) 的最新進展正在為自動語音辨識 (ASR) 和自然語言處理 (NLP) 提供新的方法，可以運用在這個問題上。使用 Batchalign2 程式 (Liu 等人，2023)，我們已經為 CHILDES 資料庫轉錄並連結資料，並應用通用依存關係 (UD) 架構來提供 27 種語言的一致且可比較的形態句法分析。這些新資源為更深入的語言學習跨語言研究開啟了可能性。

##### **Deep Learning-based Sentiment Analysis of Olympics Tweets**
2407.12376v1 by Indranil Bandyopadhyay, Rahul Karmakar

Sentiment analysis (SA), is an approach of natural language processing (NLP)
for determining a text's emotional tone by analyzing subjective information
such as views, feelings, and attitudes toward specific topics, products,
services, events, or experiences. This study attempts to develop an advanced
deep learning (DL) model for SA to understand global audience emotions through
tweets in the context of the Olympic Games. The findings represent global
attitudes around the Olympics and contribute to advancing the SA models. We
have used NLP for tweet pre-processing and sophisticated DL models for arguing
with SA, this research enhances the reliability and accuracy of sentiment
classification. The study focuses on data selection, preprocessing,
visualization, feature extraction, and model building, featuring a baseline
Na\"ive Bayes (NB) model and three advanced DL models: Convolutional Neural
Network (CNN), Bidirectional Long Short-Term Memory (BiLSTM), and Bidirectional
Encoder Representations from Transformers (BERT). The results of the
experiments show that the BERT model can efficiently classify sentiments
related to the Olympics, achieving the highest accuracy of 99.23%.

摘要：情緒分析 (SA) 是自然語言處理 (NLP) 的一種方法，透過分析觀點、感受和對特定主題、產品、服務、事件或經驗的態度等主觀資訊，來判定一段文字的情緒基調。本研究嘗試開發一個進階的深度學習 (DL) 模型進行 SA，以透過奧運會的推文來了解全球觀眾的情緒。研究結果代表了全球對於奧運會的態度，並有助於推進 SA 模型的發展。我們使用 NLP 對推文進行前處理，並使用進階的 DL 模型進行 SA 論證，這項研究提升了情緒分類的可靠性和準確性。本研究著重於資料選取、前處理、視覺化、特徵萃取和模型建構，採用基準的朴素貝氏 (NB) 模型和三個進階的 DL 模型：卷積神經網路 (CNN)、雙向長短期記憶 (BiLSTM) 和 Transformer 的雙向編碼器表徵 (BERT)。實驗結果顯示，BERT 模型能有效地分類與奧運會相關的情緒，達到 99.23% 的最高準確度。

##### **HIMO: A New Benchmark for Full-Body Human Interacting with Multiple Objects**
2407.12371v1 by Xintao Lv, Liang Xu, Yichao Yan, Xin Jin, Congsheng Xu, Shuwen Wu, Yifan Liu, Lincheng Li, Mengxiao Bi, Wenjun Zeng, Xiaokang Yang

Generating human-object interactions (HOIs) is critical with the tremendous
advances of digital avatars. Existing datasets are typically limited to humans
interacting with a single object while neglecting the ubiquitous manipulation
of multiple objects. Thus, we propose HIMO, a large-scale MoCap dataset of
full-body human interacting with multiple objects, containing 3.3K 4D HOI
sequences and 4.08M 3D HOI frames. We also annotate HIMO with detailed textual
descriptions and temporal segments, benchmarking two novel tasks of HOI
synthesis conditioned on either the whole text prompt or the segmented text
prompts as fine-grained timeline control. To address these novel tasks, we
propose a dual-branch conditional diffusion model with a mutual interaction
module for HOI synthesis. Besides, an auto-regressive generation pipeline is
also designed to obtain smooth transitions between HOI segments. Experimental
results demonstrate the generalization ability to unseen object geometries and
temporal compositions.

摘要：生成人類與物體互動 (HOI) 對於數位頭像的巨大進步至關重要。現有的資料集通常僅限於人類與單一物體互動，而忽略了對多個物體的普遍操作。因此，我們提出 HIMO，一個與多個物體互動的全人體動作捕捉大型資料集，包含 3.3K 4D HOI 序列和 4.08M 3D HOI 幀。我們還使用詳細的文字描述和時間區段對 HIMO 進行註解，對兩個新穎的 HOI 合成任務進行基準測試，這些任務以完整的文字提示或分段文字提示為條件，作為細粒度時間軸控制。為了解決這些新穎的任務，我們提出了一個具有相互互動模組的雙分支條件擴散模型，用於 HOI 合成。此外，還設計了一個自迴歸生成管道，用於在 HOI 區段之間獲得平滑過渡。實驗結果證明了對未見物體幾何形狀和時間組成的泛化能力。

##### **NavGPT-2: Unleashing Navigational Reasoning Capability for Large Vision-Language Models**
2407.12366v1 by Gengze Zhou, Yicong Hong, Zun Wang, Xin Eric Wang, Qi Wu

Capitalizing on the remarkable advancements in Large Language Models (LLMs),
there is a burgeoning initiative to harness LLMs for instruction following
robotic navigation. Such a trend underscores the potential of LLMs to
generalize navigational reasoning and diverse language understanding. However,
a significant discrepancy in agent performance is observed when integrating
LLMs in the Vision-and-Language navigation (VLN) tasks compared to previous
downstream specialist models. Furthermore, the inherent capacity of language to
interpret and facilitate communication in agent interactions is often
underutilized in these integrations. In this work, we strive to bridge the
divide between VLN-specialized models and LLM-based navigation paradigms, while
maintaining the interpretative prowess of LLMs in generating linguistic
navigational reasoning. By aligning visual content in a frozen LLM, we
encompass visual observation comprehension for LLMs and exploit a way to
incorporate LLMs and navigation policy networks for effective action
predictions and navigational reasoning. We demonstrate the data efficiency of
the proposed methods and eliminate the gap between LM-based agents and
state-of-the-art VLN specialists.

摘要：利用大型語言模型 (LLM) 的顯著進步，有一項蓬勃發展的倡議旨在利用 LLM 進行指令後續機器人導航。這種趨勢強調了 LLM 在概括導航推理和多樣化語言理解方面的潛力。然而，在將 LLM 整合到視覺和語言導航 (VLN) 任務中時，與先前的下游專家模型相比，觀察到代理效能的顯著差異。此外，語言在代理互動中解釋和促進溝通的內在能力在這些整合中常常未被充分利用。在這項工作中，我們努力彌合 VLN 專業模型和基於 LLM 的導航範例之間的鴻溝，同時保持 LLM 在產生語言導航推理方面的詮釋能力。通過在凍結的 LLM 中對齊視覺內容，我們涵蓋了 LLM 的視覺觀察理解，並探索了一種將 LLM 和導航策略網路納入考量的方法，以進行有效的動作預測和導航推理。我們展示了所提出方法的資料效率，並消除了基於 LM 的代理與最先進的 VLN 專家之間的差距。

##### **Conversational Query Reformulation with the Guidance of Retrieved Documents**
2407.12363v1 by Jeonghyun Park, Hwanhee Lee

Conversational search seeks to retrieve relevant passages for the given
questions in Conversational QA (ConvQA). Questions in ConvQA face challenges
such as omissions and coreferences, making it difficult to obtain desired
search results. Conversational Query Reformulation (CQR) transforms these
current queries into de-contextualized forms to resolve these issues. However,
existing CQR methods focus on rewriting human-friendly queries, which may not
always yield optimal search results for the retriever. To overcome this
challenge, we introduce GuideCQR, a framework that utilizes guided documents to
refine queries, ensuring that they are optimal for retrievers. Specifically, we
augment keywords, generate expected answers from the re-ranked documents, and
unify them with the filtering process. Experimental results show that queries
enhanced by guided documents outperform previous CQR methods. Especially,
GuideCQR surpasses the performance of Large Language Model (LLM) prompt-powered
approaches and demonstrates the importance of the guided documents in
formulating retriever-friendly queries across diverse setups.

摘要：對話式搜尋旨在針對對話式問答 (ConvQA) 中的問題擷取相關段落。ConvQA 中的問題會遇到省略和共指等挑戰，因此難以取得所需的搜尋結果。對話式查詢變換 (CQR) 將這些目前的查詢轉換為非脈絡化形式，以解決這些問題。然而，現有的 CQR 方法專注於改寫對人類友善的查詢，這並不一定總是能為擷取器產生最佳的搜尋結果。為了克服這個挑戰，我們引入了 GuideCQR，一個利用引導文件來精煉查詢的架構，確保它們對擷取器而言是最佳的。具體來說，我們擴充關鍵字，從重新排序的文件中產生預期答案，並將它們與過濾程序統一。實驗結果顯示，由引導文件增強的查詢優於先前的 CQR 方法。特別是，GuideCQR 超越了大型語言模型 (LLM) 提示驅動方法的效能，並證明了引導文件在跨不同設定中制定對擷取器友善的查詢的重要性。

##### **ProcTag: Process Tagging for Assessing the Efficacy of Document Instruction Data**
2407.12358v1 by Yufan Shen, Chuwei Luo, Zhaoqing Zhu, Yang Chen, Qi Zheng, Zhi Yu, Jiajun Bu, Cong Yao

Recently, large language models (LLMs) and multimodal large language models
(MLLMs) have demonstrated promising results on document visual question
answering (VQA) task, particularly after training on document instruction
datasets. An effective evaluation method for document instruction data is
crucial in constructing instruction data with high efficacy, which, in turn,
facilitates the training of LLMs and MLLMs for document VQA. However, most
existing evaluation methods for instruction data are limited to the textual
content of the instructions themselves, thereby hindering the effective
assessment of document instruction datasets and constraining their
construction. In this paper, we propose ProcTag, a data-oriented method that
assesses the efficacy of document instruction data. ProcTag innovatively
performs tagging on the execution process of instructions rather than the
instruction text itself. By leveraging the diversity and complexity of these
tags to assess the efficacy of the given dataset, ProcTag enables selective
sampling or filtering of document instructions. Furthermore, DocLayPrompt, a
novel semi-structured layout-aware document prompting strategy, is proposed for
effectively representing documents. Experiments demonstrate that sampling
existing open-sourced and generated document VQA/instruction datasets with
ProcTag significantly outperforms current methods for evaluating instruction
data. Impressively, with ProcTag-based sampling in the generated document
datasets, only 30.5\% of the document instructions are required to achieve
100\% efficacy compared to the complete dataset. The code is publicly available
at
https://github.com/AlibabaResearch/AdvancedLiterateMachinery/tree/main/DocumentUnderstanding/ProcTag.

摘要：<paragraph>最近，大型语言模型（LLM）和多模态大型语言模型（MLLM）在文件视觉问答（VQA）任务上展示了令人满意的结果，尤其是在文件指令数据集上进行训练后。一个有效的评估方法对于构建高效的文件指令数据至关重要，而这反过来又促进了 LLM 和 MLLM 对文件 VQA 的训练。然而，大多数现有的指令数据评估方法仅限于指令本身的文本内容，从而阻碍了对文件指令数据集的有效评估并限制了它们的构建。在本文中，我们提出了 ProcTag，这是一种以数据为导向的方法，用于评估文件指令数据的效力。ProcTag 创新性地对指令的执行过程进行标记，而不是指令文本本身。通过利用这些标记的多样性和复杂性来评估给定数据集的效力，ProcTag 能够对文件指令进行选择性抽样或过滤。此外，提出了一种新颖的半结构化布局感知文档提示策略 DocLayPrompt，用于有效地表示文档。实验表明，使用 ProcTag 对现有的开源和生成的文档 VQA/指令数据集进行抽样明显优于当前的指令数据评估方法。令人印象深刻的是，在生成的文档数据集中基于 ProcTag 的抽样中，仅需要 30.5% 的文档指令即可实现与完整数据集相比 100% 的效力。代码已公开发布在
https://github.com/AlibabaResearch/AdvancedLiterateMachinery/tree/main/DocumentUnderstanding/ProcTag。</paragraph>

##### **SENTAUR: Security EnhaNced Trojan Assessment Using LLMs Against Undesirable Revisions**
2407.12352v1 by Jitendra Bhandari, Rajat Sadhukhan, Prashanth Krishnamurthy, Farshad Khorrami, Ramesh Karri

A globally distributed IC supply chain brings risks due to untrusted third
parties. The risks span inadvertent use of hardware Trojan (HT), inserted
Intellectual Property (3P-IP) or Electronic Design Automation (EDA) flows. HT
can introduce stealthy HT behavior, prevent an IC work as intended, or leak
sensitive data via side channels. To counter HTs, rapidly examining HT
scenarios is a key requirement. While Trust-Hub benchmarks are a good starting
point to assess defenses, they encompass a small subset of manually created HTs
within the expanse of HT designs. Further, the HTs may disappear during
synthesis. We propose a large language model (LLM) framework SENTAUR to
generate a suite of legitimate HTs for a Register Transfer Level (RTL) design
by learning its specifications, descriptions, and natural language descriptions
of HT effects. Existing tools and benchmarks are limited; they need a learning
period to construct an ML model to mimic the threat model and are difficult to
reproduce. SENTAUR can swiftly produce HT instances by leveraging LLMs without
any learning period and sanitizing the HTs facilitating their rapid assessment.
Evaluation of SENTAUR involved generating effective, synthesizable, and
practical HTs from TrustHub and elsewhere, investigating impacts of
payloads/triggers at the RTL. While our evaluation focused on HT insertion,
SENTAUR can generalize to automatically transform an RTL code to have defined
functional modifications.

摘要：<paragraph>全球分布的 IC 供應鏈因不信任的第三方而帶來風險。風險包括無意中使用硬體木馬 (HT)、插入的智慧財產權 (3P-IP) 或電子設計自動化 (EDA) 流程。HT 可以引入隱密的 HT 行為，阻止 IC 按預期工作，或透過側信道洩漏敏感資料。為了對抗 HT，快速檢查 HT 場景是一項關鍵要求。雖然 Trust-Hub 基準是評估防禦措施的良好起點，但它們包含了在 HT 設計範圍內一小部分手動建立的 HT。此外，HT 可能在綜合過程中消失。我們提出一個大型語言模型 (LLM) 框架 SENTAUR，透過學習其規格、描述和 HT 效果的自然語言描述，為暫存器傳輸層級 (RTL) 設計產生一組合法的 HT。現有的工具和基準有限；它們需要一段學習期來建構一個 ML 模型以模擬威脅模型，而且難以複製。SENTAUR 可以透過利用 LLM 迅速產生 HT 範例，而無需任何學習期，並透過清除 HT 來促進其快速評估。SENTAUR 的評估包括從 TrustHub 和其他地方產生有效、可合成且實用的 HT，調查有效載荷/觸發器在 RTL 上的影響。雖然我們的評估重點在 HT 插入上，但 SENTAUR 可以概括為自動轉換 RTL 程式碼以定義功能修改。</paragraph>

##### **The Better Angels of Machine Personality: How Personality Relates to LLM Safety**
2407.12344v1 by Jie Zhang, Dongrui Liu, Chen Qian, Ziyue Gan, Yong Liu, Yu Qiao, Jing Shao

Personality psychologists have analyzed the relationship between personality
and safety behaviors in human society. Although Large Language Models (LLMs)
demonstrate personality traits, the relationship between personality traits and
safety abilities in LLMs still remains a mystery. In this paper, we discover
that LLMs' personality traits are closely related to their safety abilities,
i.e., toxicity, privacy, and fairness, based on the reliable MBTI-M scale.
Meanwhile, the safety alignment generally increases various LLMs' Extraversion,
Sensing, and Judging traits. According to such findings, we can edit LLMs'
personality traits and improve their safety performance, e.g., inducing
personality from ISTJ to ISTP resulted in a relative improvement of
approximately 43% and 10% in privacy and fairness performance, respectively.
Additionally, we find that LLMs with different personality traits are
differentially susceptible to jailbreak. This study pioneers the investigation
of LLM safety from a personality perspective, providing new insights into LLM
safety enhancement.

摘要：人格心理學家分析了人格與人類社會安全行為之間的關係。儘管大型語言模型 (LLM) 表現出人格特質，但 LLM 中人格特質與安全能力之間的關係仍然是個謎。在本文中，我們發現 LLM 的人格特質與其安全能力密切相關，即，根據可靠的 MBTI-M 量表，毒性、隱私和公平性。同時，安全調整通常會增加各種 LLM 的外向性、感知性和判斷性特質。根據這些發現，我們可以編輯 LLM 的人格特質並改善其安全性能，例如，將人格從 ISTJ 誘導到 ISTP，分別導致隱私和公平性表現相對提高了約 43% 和 10%。此外，我們發現具有不同人格特質的 LLM 對越獄的敏感性不同。這項研究開創了從人格角度探討 LLM 安全性的先河，為 LLM 安全性增強提供了新的見解。

##### **Word Embedding Dimension Reduction via Weakly-Supervised Feature Selection**
2407.12342v1 by Jintang Xue, Yun-Cheng Wang, Chengwei Wei, C. -C. Jay Kuo

As a fundamental task in natural language processing, word embedding converts
each word into a representation in a vector space. A challenge with word
embedding is that as the vocabulary grows, the vector space's dimension
increases and it can lead to a vast model size. Storing and processing word
vectors are resource-demanding, especially for mobile edge-devices
applications. This paper explores word embedding dimension reduction. To
balance computational costs and performance, we propose an efficient and
effective weakly-supervised feature selection method, named WordFS. It has two
variants, each utilizing novel criteria for feature selection. Experiments
conducted on various tasks (e.g., word and sentence similarity and binary and
multi-class classification) indicate that the proposed WordFS model outperforms
other dimension reduction methods at lower computational costs.

摘要：作為自然語言處理中的一項基本任務，詞嵌入將每個詞轉換為向量空間中的表示。詞嵌入面臨的挑戰是，隨著詞彙的增加，向量空間的維度也會增加，這可能會導致模型規模龐大。儲存和處理詞向量需要大量資源，特別是對於行動邊緣裝置應用程式。本文探討了詞嵌入維度縮減。為了平衡運算成本和效能，我們提出了一種高效且有效的弱監督特徵選擇方法，稱為 WordFS。它有兩個變體，每個變體都使用新穎的標準來進行特徵選擇。在各種任務（例如，詞和句子相似性以及二元和多類別分類）上進行的實驗表明，所提出的 WordFS 模型在較低的運算成本下優於其他維度縮減方法。

##### **M2DS: Multilingual Dataset for Multi-document Summarisation**
2407.12336v1 by Kushan Hewapathirana, Nisansa de Silva, C. D. Athuraliya

In the rapidly evolving digital era, there is an increasing demand for
concise information as individuals seek to distil key insights from various
sources. Recent attention from researchers on Multi-document Summarisation
(MDS) has resulted in diverse datasets covering customer reviews, academic
papers, medical and legal documents, and news articles. However, the
English-centric nature of these datasets has created a conspicuous void for
multilingual datasets in today's globalised digital landscape, where linguistic
diversity is celebrated. Media platforms such as British Broadcasting
Corporation (BBC) have disseminated news in 20+ languages for decades. With
only 380 million people speaking English natively as their first language,
accounting for less than 5% of the global population, the vast majority
primarily relies on other languages. These facts underscore the need for
inclusivity in MDS research, utilising resources from diverse languages.
Recognising this gap, we present the Multilingual Dataset for Multi-document
Summarisation (M2DS), which, to the best of our knowledge, is the first dataset
of its kind. It includes document-summary pairs in five languages from BBC
articles published during the 2010-2023 period. This paper introduces M2DS,
emphasising its unique multilingual aspect, and includes baseline scores from
state-of-the-art MDS models evaluated on our dataset.

摘要：<paragraph>在快速演進的數位時代中，隨著個人試圖從各種來源中提煉出關鍵見解，對於簡潔資訊的需求與日俱增。研究人員最近關注多文件摘要 (MDS)，已產生涵蓋顧客評論、學術論文、醫療和法律文件以及新聞文章的多樣化資料集。然而，這些資料集以英語為中心的特質，在當今全球化數位環境中造成了多語言資料集的明顯空缺，而語言多樣性在此環境中備受推崇。英國廣播公司 (BBC) 等媒體平台數十年來已以 20 多種語言傳播新聞。僅有 3.8 億人以英語為母語，約占全球人口的 5%，絕大多數人主要依賴其他語言。這些事實強調了在 MDS 研究中納入多元語言資源的重要性。有鑑於此差距，我們提出了多語言多文件摘要資料集 (M2DS)，根據我們的了解，這是第一個此類資料集。它包含 2010-2023 年期間發布的 BBC 文章中五種語言的文件摘要對。本文介紹 M2DS，強調其獨特的多語言面向，並包含在我們的資料集上評估的最新 MDS 模型的基準分數。</paragraph>

##### **I2AM: Interpreting Image-to-Image Latent Diffusion Models via Attribution Maps**
2407.12331v1 by Junseo Park, Hyeryung Jang

Large-scale diffusion models have made significant advancements in the field
of image generation, especially through the use of cross-attention mechanisms
that guide image formation based on textual descriptions. While the analysis of
text-guided cross-attention in diffusion models has been extensively studied in
recent years, its application in image-to-image diffusion models remains
underexplored. This paper introduces the Image-to-Image Attribution Maps I2AM
method, which aggregates patch-level cross-attention scores to enhance the
interpretability of latent diffusion models across time steps, heads, and
attention layers. I2AM facilitates detailed image-to-image attribution
analysis, enabling observation of how diffusion models prioritize key features
over time and head during the image generation process from reference images.
Through extensive experiments, we first visualize the attribution maps of both
generated and reference images, verifying that critical information from the
reference image is effectively incorporated into the generated image, and vice
versa. To further assess our understanding, we introduce a new evaluation
metric tailored for reference-based image inpainting tasks. This metric,
measuring the consistency between the attribution maps of generated and
reference images, shows a strong correlation with established performance
metrics for inpainting tasks, validating the potential use of I2AM in future
research endeavors.

摘要：<paragraph>大型擴散模型在影像生成領域取得重大進展，特別是透過使用交叉注意力機制，根據文本描述來引導影像生成。雖然近年來對於擴散模型中文字引導的交叉注意力分析已廣泛研究，但其在影像到影像擴散模型中的應用仍未被充分探討。本文介紹了影像到影像歸因圖 I2AM 方法，它彙總了區塊層級的交叉注意力分數，以增強潛在擴散模型在時間步長、注意力層和頭部的可解釋性。I2AM 便於進行詳細的影像到影像歸因分析，能夠觀察擴散模型如何在影像生成過程中，隨著時間和頭部的推移優先處理關鍵特徵。透過廣泛的實驗，我們首先視覺化了生成影像和參考影像的歸因圖，驗證了參考影像中的關鍵資訊已有效地整合到生成的影像中，反之亦然。為了進一步評估我們的理解，我們引入了一個新的評估指標，專門針對基於參考的影像修復任務。此指標測量生成的影像和參考影像的歸因圖之間的一致性，顯示與修復任務的既定效能指標有很強的相關性，驗證了 I2AM 在未來研究工作中的潛在用途。</paragraph>

##### **Uncertainty Calibration with Energy Based Instance-wise Scaling in the Wild Dataset**
2407.12330v1 by Mijoo Kim, Junseok Kwon

With the rapid advancement in the performance of deep neural networks (DNNs),
there has been significant interest in deploying and incorporating artificial
intelligence (AI) systems into real-world scenarios. However, many DNNs lack
the ability to represent uncertainty, often exhibiting excessive confidence
even when making incorrect predictions. To ensure the reliability of AI
systems, particularly in safety-critical cases, DNNs should transparently
reflect the uncertainty in their predictions. In this paper, we investigate
robust post-hoc uncertainty calibration methods for DNNs within the context of
multi-class classification tasks. While previous studies have made notable
progress, they still face challenges in achieving robust calibration,
particularly in scenarios involving out-of-distribution (OOD). We identify that
previous methods lack adaptability to individual input data and struggle to
accurately estimate uncertainty when processing inputs drawn from the wild
dataset. To address this issue, we introduce a novel instance-wise calibration
method based on an energy model. Our method incorporates energy scores instead
of softmax confidence scores, allowing for adaptive consideration of DNN
uncertainty for each prediction within a logit space. In experiments, we show
that the proposed method consistently maintains robust performance across the
spectrum, spanning from in-distribution to OOD scenarios, when compared to
other state-of-the-art methods.

摘要：隨著深度神經網路 (DNN) 效能的快速進步，將人工智慧 (AI) 系統部署並整合到現實世界場景中引起了極大的興趣。然而，許多 DNN 缺乏表示不確定性的能力，即使在做出不正確預測時，也常常表現出過度的信心。為了確保 AI 系統的可靠性，特別是在安全關鍵案例中，DNN 應透明地反映其預測中的不確定性。在本文中，我們研究了 DNN 在多類別分類任務背景下的穩健事後不確定性校準方法。雖然先前的研究取得了顯著進展，但它們在實現穩健校準方面仍面臨挑戰，特別是在涉及分佈外 (OOD) 的場景中。我們發現先前的模型缺乏對個別輸入資料的適應性，並且在處理從野生資料集抽取的輸入時難以準確估計不確定性。為了解決這個問題，我們引入了一種基於能量模型的新型逐例校準方法。我們的方法採用能量分數，而不是 softmax 信心分數，允許在 logit 空間中自適應地考慮每個預測的 DNN 不確定性。在實驗中，我們表明，與其他最先進的方法相比，所提出的方法在從分佈內到 OOD 場景的整個範圍內持續保持穩健的效能。

##### **Spectra: A Comprehensive Study of Ternary, Quantized, and FP16 Language Models**
2407.12327v1 by Ayush Kaushal, Tejas Pandey, Tejas Vaidhya, Aaryan Bhagat, Irina Rish

Post-training quantization is the leading method for addressing
memory-related bottlenecks in LLM inference, but unfortunately, it suffers from
significant performance degradation below 4-bit precision. An alternative
approach involves training compressed models directly at a low bitwidth (e.g.,
binary or ternary models). However, the performance, training dynamics, and
scaling trends of such models are not yet well understood. To address this
issue, we train and openly release the Spectra LLM suite consisting of 54
language models ranging from 99M to 3.9B parameters, trained on 300B tokens.
Spectra includes FloatLMs, post-training quantized QuantLMs (3, 4, 6, and 8
bits), and ternary LLMs (TriLMs) - our improved architecture for ternary
language modeling, which significantly outperforms previously proposed ternary
models of a given size (in bits), matching half-precision models at scale. For
example, TriLM 3.9B is (bit-wise) smaller than the half-precision FloatLM 830M,
but matches half-precision FloatLM 3.9B in commonsense reasoning and knowledge
benchmarks. However, TriLM 3.9B is also as toxic and stereotyping as FloatLM
3.9B, a model six times larger in size. Additionally, TriLM 3.9B lags behind
FloatLM in perplexity on validation splits and web-based corpora but performs
better on less noisy datasets like Lambada and PennTreeBank.
  To enhance understanding of low-bitwidth models, we are releasing 500+
intermediate checkpoints of the Spectra suite at
\href{https://github.com/NolanoOrg/SpectraSuite}{https://github.com/NolanoOrg/SpectraSuite}.

摘要：<paragraph>訓練後量化是解決 LLM 推論中與記憶體相關瓶頸的領先方法，但不幸的是，在 4 位元精度以下會大幅降低效能。另一種方法涉及直接在低位元寬度（例如二元或三元模型）訓練壓縮模型。然而，此類模型的效能、訓練動態和擴充趨勢尚未廣為理解。為了解決這個問題，我們訓練並公開發布 Spectra LLM 套件，其中包含 54 個語言模型，範圍從 99M 到 3.9B 個參數，並在 300B 個代幣上訓練。Spectra 包含 FloatLM、訓練後量化的 QuantLM（3、4、6 和 8 位元）和三元 LLM（TriLM）——我們改進的三元語言建模架構，其顯著優於先前提出的特定大小（以位元為單位）的三元模型，在擴充時與半精度模型相匹配。例如，TriLM 3.9B（以位元為單位）小於半精度 FloatLM 830M，但在常識推理和知識基準測試中與半精度 FloatLM 3.9B 相匹配。然而，TriLM 3.9B 也和 FloatLM 3.9B 一樣具有毒性和刻板印象，後者的模型大小是前者的六倍。此外，TriLM 3.9B 在驗證分割和基於網路的語料庫中的困惑度落後於 FloatLM，但在像 Lambada 和 PennTreeBank 這樣的低雜訊資料集上表現得更好。為了加深對低位元寬度模型的理解，我們在\href{https://github.com/NolanoOrg/SpectraSuite}{https://github.com/NolanoOrg/SpectraSuite}發布 Spectra 套件的 500 多個中間檢查點。</paragraph>

##### **ModalChorus: Visual Probing and Alignment of Multi-modal Embeddings via Modal Fusion Map**
2407.12315v1 by Yilin Ye, Shishi Xiao, Xingchen Zeng, Wei Zeng

Multi-modal embeddings form the foundation for vision-language models, such
as CLIP embeddings, the most widely used text-image embeddings. However, these
embeddings are vulnerable to subtle misalignment of cross-modal features,
resulting in decreased model performance and diminished generalization. To
address this problem, we design ModalChorus, an interactive system for visual
probing and alignment of multi-modal embeddings. ModalChorus primarily offers a
two-stage process: 1) embedding probing with Modal Fusion Map (MFM), a novel
parametric dimensionality reduction method that integrates both metric and
nonmetric objectives to enhance modality fusion; and 2) embedding alignment
that allows users to interactively articulate intentions for both point-set and
set-set alignments. Quantitative and qualitative comparisons for CLIP
embeddings with existing dimensionality reduction (e.g., t-SNE and MDS) and
data fusion (e.g., data context map) methods demonstrate the advantages of MFM
in showcasing cross-modal features over common vision-language datasets. Case
studies reveal that ModalChorus can facilitate intuitive discovery of
misalignment and efficient re-alignment in scenarios ranging from zero-shot
classification to cross-modal retrieval and generation.

摘要：多模態嵌入形成視覺語言模型的基礎，例如 CLIP 嵌入，這是最廣泛使用的文字影像嵌入。然而，這些嵌入容易受到跨模態特徵的細微失準影響，導致模型效能下降和泛化能力減弱。為了解決這個問題，我們設計了 ModalChorus，一個用於多模態嵌入的視覺探測和對齊的互動式系統。ModalChorus 主要提供一個兩階段的流程：1) 使用模態融合地圖 (MFM) 進行嵌入探測，這是一種整合度量和非度量目標的新型參數降維方法，以增強模態融合；以及 2) 嵌入對齊，允許使用者互動式地表達點集和集合對齊的意圖。針對 CLIP 嵌入與現有降維（例如 t-SNE 和 MDS）和資料融合（例如資料脈絡地圖）方法的量化和定性比較，證明了 MFM 在展示跨模態特徵方面在常見的視覺語言資料集上的優點。案例研究表明，ModalChorus 可以促進直觀地發現失準，並在從零次分類到跨模態檢索和生成等場景中進行有效的重新對齊。

##### **MEDFuse: Multimodal EHR Data Fusion with Masked Lab-Test Modeling and Large Language Models**
2407.12309v1 by Thao Minh Nguyen Phan, Cong-Tinh Dao, Chenwei Wu, Jian-Zhe Wang, Shun Liu, Jun-En Ding, David Restrepo, Feng Liu, Fang-Ming Hung, Wen-Chih Peng

Electronic health records (EHRs) are multimodal by nature, consisting of
structured tabular features like lab tests and unstructured clinical notes. In
real-life clinical practice, doctors use complementary multimodal EHR data
sources to get a clearer picture of patients' health and support clinical
decision-making. However, most EHR predictive models do not reflect these
procedures, as they either focus on a single modality or overlook the
inter-modality interactions/redundancy. In this work, we propose MEDFuse, a
Multimodal EHR Data Fusion framework that incorporates masked lab-test modeling
and large language models (LLMs) to effectively integrate structured and
unstructured medical data. MEDFuse leverages multimodal embeddings extracted
from two sources: LLMs fine-tuned on free clinical text and masked tabular
transformers trained on structured lab test results. We design a disentangled
transformer module, optimized by a mutual information loss to 1) decouple
modality-specific and modality-shared information and 2) extract useful joint
representation from the noise and redundancy present in clinical notes. Through
comprehensive validation on the public MIMIC-III dataset and the in-house FEMH
dataset, MEDFuse demonstrates great potential in advancing clinical
predictions, achieving over 90% F1 score in the 10-disease multi-label
classification task.

摘要：電子健康紀錄（EHR）本質上是多模態的，包含了像實驗室檢查等結構化表格特徵和非結構化的臨床筆記。在真實的臨床實務中，醫生使用互補的多模態 EHR 數據來源，以更清楚地了解病患的健康狀況並支持臨床決策制定。然而，大多數的 EHR 預測模型並未反映這些程序，因為它們不是專注於單一模態，就是忽略了模態間的交互作用/冗餘。在這項工作中，我們提出 MEDFuse，一個多模態 EHR 數據融合架構，它結合了遮罩實驗室測試建模和大語言模型（LLM），以有效整合結構化和非結構化的醫療數據。MEDFuse 跨兩個來源提取多模態嵌入：針對免費臨床文本微調的 LLM，以及針對結構化實驗室檢驗結果訓練的遮罩表格轉換器。我們設計了一個解糾纏轉換器模組，由一個互信息損失進行最佳化，以 1) 分離特定於模態和模態共享的信息，以及 2) 從臨床筆記中存在的雜訊和冗餘中提取有用的聯合表徵。透過在公共 MIMIC-III 資料集和內部 FEMH 資料集上進行全面的驗證，MEDFuse 證明了在推進臨床預測方面的巨大潛力，在 10 種疾病的多標籤分類任務中達到了超過 90% 的 F1 分數。

##### **Any Target Can be Offense: Adversarial Example Generation via Generalized Latent Infection**
2407.12292v1 by Youheng Sun, Shengming Yuan, Xuanhan Wang, Lianli Gao, Jingkuan Song

Targeted adversarial attack, which aims to mislead a model to recognize any
image as a target object by imperceptible perturbations, has become a
mainstream tool for vulnerability assessment of deep neural networks (DNNs).
Since existing targeted attackers only learn to attack known target classes,
they cannot generalize well to unknown classes. To tackle this issue, we
propose $\bf{G}$eneralized $\bf{A}$dversarial attac$\bf{KER}$ ($\bf{GAKer}$),
which is able to construct adversarial examples to any target class. The core
idea behind GAKer is to craft a latently infected representation during
adversarial example generation. To this end, the extracted latent
representations of the target object are first injected into intermediate
features of an input image in an adversarial generator. Then, the generator is
optimized to ensure visual consistency with the input image while being close
to the target object in the feature space. Since the GAKer is class-agnostic
yet model-agnostic, it can be regarded as a general tool that not only reveals
the vulnerability of more DNNs but also identifies deficiencies of DNNs in a
wider range of classes. Extensive experiments have demonstrated the
effectiveness of our proposed method in generating adversarial examples for
both known and unknown classes. Notably, compared with other generative
methods, our method achieves an approximately $14.13\%$ higher attack success
rate for unknown classes and an approximately $4.23\%$ higher success rate for
known classes. Our code is available in https://github.com/VL-Group/GAKer.

摘要：<paragraph>目標對抗攻擊旨在透過難以察覺的擾動，誤導模型將任何影像辨識為目標物體，已成為深度神經網路 (DNN) 弱點評估的主流工具。由於現有的目標攻擊者只學習攻擊已知的目標類別，因此無法很好地推廣到未知類別。為了解決這個問題，我們提出 $\bf{G}$eneralized $\bf{A}$dversarial attac$\bf{KER}$ ($\bf{GAKer}$)，它能夠建構對抗範例到任何目標類別。GAKer 背後的主要想法是在對抗範例產生期間製作一個潛在受感染的表示。為此，首先將目標物體提取的潛在表示注入到對抗生成器中輸入影像的中間特徵中。然後，最佳化生成器以確保與輸入影像的視覺一致性，同時在特徵空間中接近目標物體。由於 GAKer 與類別無關且與模型無關，因此可以將其視為一種通用工具，不僅可以揭示更多 DNN 的漏洞，還可以識別更廣泛類別中 DNN 的缺陷。廣泛的實驗證明了我們提出的方法在為已知和未知類別產生對抗範例方面的有效性。值得注意的是，與其他生成方法相比，我們的方法對未知類別的攻擊成功率提高了大約 $14.13\%$，對已知類別的成功率提高了大約 $4.23\%$。我們的程式碼可在 https://github.com/VL-Group/GAKer 中取得。</paragraph>

##### **Chip Placement with Diffusion**
2407.12282v1 by Vint Lee, Chun Deng, Leena Elzeiny, Pieter Abbeel, John Wawrzynek

Macro placement is a vital step in digital circuit design that defines the
physical location of large collections of components, known as macros, on a
2-dimensional chip. The physical layout obtained during placement determines
key performance metrics of the chip, such as power consumption, area, and
performance. Existing learning-based methods typically fall short because of
their reliance on reinforcement learning, which is slow and limits the
flexibility of the agent by casting placement as a sequential process. Instead,
we use a powerful diffusion model to place all components simultaneously. To
enable such models to train at scale, we propose a novel architecture for the
denoising model, as well as an algorithm to generate large synthetic datasets
for pre-training. We empirically show that our model can tackle the placement
task, and achieve competitive performance on placement benchmarks compared to
state-of-the-art methods.

摘要：巨集配置是数字电路设计中至关重要的一步，它定义了称为巨集的大量组件在二维芯片上的物理位置。配置期间获得的物理布局决定了芯片的关键性能指标，例如功耗、面积和性能。现有的基于学习的方法通常会因依赖于强化学习而表现不佳，强化学习速度慢，并且会将配置视为顺序过程，从而限制了代理的灵活性。相反，我们使用强大的扩散模型来同时放置所有组件。为了使此类模型能够大规模训练，我们提出了去噪模型的新型架构，以及生成大型合成数据集以进行预训练的算法。我们凭经验表明，我们的模型可以解决配置任务，并且与最先进的方法相比，在配置基准上实现了有竞争力的性能。

##### **Turning Generative Models Degenerate: The Power of Data Poisoning Attacks**
2407.12281v1 by Shuli Jiang, Swanand Ravindra Kadhe, Yi Zhou, Farhan Ahmed, Ling Cai, Nathalie Baracaldo

The increasing use of large language models (LLMs) trained by third parties
raises significant security concerns. In particular, malicious actors can
introduce backdoors through poisoning attacks to generate undesirable outputs.
While such attacks have been extensively studied in image domains and
classification tasks, they remain underexplored for natural language generation
(NLG) tasks. To address this gap, we conduct an investigation of various
poisoning techniques targeting the LLM's fine-tuning phase via prefix-tuning, a
Parameter Efficient Fine-Tuning (PEFT) method. We assess their effectiveness
across two generative tasks: text summarization and text completion; and we
also introduce new metrics to quantify the success and stealthiness of such NLG
poisoning attacks. Through our experiments, we find that the prefix-tuning
hyperparameters and trigger designs are the most crucial factors to influence
attack success and stealthiness. Moreover, we demonstrate that existing popular
defenses are ineffective against our poisoning attacks. Our study presents the
first systematic approach to understanding poisoning attacks targeting NLG
tasks during fine-tuning via PEFT across a wide range of triggers and attack
settings. We hope our findings will aid the AI security community in developing
effective defenses against such threats.

摘要：大型語言模型 (LLM) 的使用增加，由第三方培訓，引起了重要的安全問題。特別是，惡意行為者可以透過投毒攻擊導入後門，以產生不良的輸出。雖然這種攻擊已在影像領域和分類任務中廣泛研究，但對於自然語言生成 (NLG) 任務仍未充分探討。為了解決這個差距，我們針對透過前綴調整來鎖定 LLM 微調階段的各種投毒技術進行調查，一種參數有效微調 (PEFT) 方法。我們評估它們在兩個生成任務中的有效性：文字摘要和文字完成；並且我們也引進新的指標來量化這種 NLG 投毒攻擊的成功和隱密性。透過我們的實驗，我們發現前綴調整超參數和觸發器設計是影響攻擊成功和隱密性的最重要因素。此外，我們證明現有的流行防禦措施對我們的投毒攻擊無效。我們的研究提出了第一個系統化的方法來理解在透過 PEFT 微調期間鎖定 NLG 任務的投毒攻擊，涵蓋廣泛的觸發器和攻擊設定。我們希望我們的發現將有助於 AI 安全社群開發對抗此類威脅的有效防禦措施。

##### **Multimodal Reranking for Knowledge-Intensive Visual Question Answering**
2407.12277v1 by Haoyang Wen, Honglei Zhuang, Hamed Zamani, Alexander Hauptmann, Michael Bendersky

Knowledge-intensive visual question answering requires models to effectively
use external knowledge to help answer visual questions. A typical pipeline
includes a knowledge retriever and an answer generator. However, a retriever
that utilizes local information, such as an image patch, may not provide
reliable question-candidate relevance scores. Besides, the two-tower
architecture also limits the relevance score modeling of a retriever to select
top candidates for answer generator reasoning. In this paper, we introduce an
additional module, a multi-modal reranker, to improve the ranking quality of
knowledge candidates for answer generation. Our reranking module takes
multi-modal information from both candidates and questions and performs
cross-item interaction for better relevance score modeling. Experiments on
OK-VQA and A-OKVQA show that multi-modal reranker from distant supervision
provides consistent improvements. We also find a training-testing discrepancy
with reranking in answer generation, where performance improves if training
knowledge candidates are similar to or noisier than those used in testing.

摘要：知識密集型視覺問題回答需要模型有效地利用外部知識來幫助回答視覺問題。典型的管道包括知識檢索器和答案產生器。然而，使用局部資訊（例如影像貼片）的檢索器可能無法提供可靠的問題候選相關性分數。此外，雙塔架構也限制了檢索器的相關性分數建模，以選擇答案產生器推理的最佳候選項目。在本文中，我們引入了一個額外的模組，多模式重新排名器，以提高知識候選項在答案產生中的排名品質。我們的重新排名模組從候選項和問題中取得多模式資訊，並執行跨項目互動以進行更好的相關性分數建模。OK-VQA 和 A-OKVQA 上的實驗顯示，來自遠端監督的多模式重新排名器提供了持續的改進。我們還發現答案產生中的重新排名存在訓練測試差異，其中如果訓練知識候選項與測試中使用的候選項類似或更嘈雜，則效能會提升。

##### **In-Context Probing Approximates Influence Function for Data Valuation**
2407.12259v1 by Cathy Jiao, Gary Gao, Chenyan Xiong

Data valuation quantifies the value of training data, and is used for data
attribution (i.e., determining the contribution of training data towards model
predictions), and data selection; both of which are important for curating
high-quality datasets to train large language models. In our paper, we show
that data valuation through in-context probing (i.e., prompting a LLM)
approximates influence functions for selecting training data. We provide a
theoretical sketch on this connection based on transformer models performing
"implicit" gradient descent on its in-context inputs. Our empirical findings
show that in-context probing and gradient-based influence frameworks are
similar in how they rank training data. Furthermore, fine-tuning experiments on
data selected by either method reveal similar model performance.

摘要：資料估值量化訓練資料的價值，並用於資料歸因（即，決定訓練資料對模型預測的貢獻），以及資料選擇；這兩者對於策劃高品質的資料集來訓練大型語言模型都很重要。在我們的論文中，我們展示了透過脈絡探測（即，提示 LLM）進行資料估值，近似於用於選擇訓練資料的影響函數。我們根據Transformer模型在其脈絡輸入上執行「隱式」梯度下降，提供了關於此關聯的理論草圖。我們的實證結果顯示，脈絡探測和基於梯度的影響框架在對訓練資料進行排序的方式上很相似。此外，對由任一方法選擇的資料進行微調的實驗揭示了類似的模型效能。

##### **Lacuna Language Learning: Leveraging RNNs for Ranked Text Completion in Digitized Coptic Manuscripts**
2407.12247v1 by Lauren Levine, Cindy Tung Li, Lydia Bremer-McCollum, Nicholas Wagner, Amir Zeldes

Ancient manuscripts are frequently damaged, containing gaps in the text known
as lacunae. In this paper, we present a bidirectional RNN model for character
prediction of Coptic characters in manuscript lacunae. Our best model performs
with 72% accuracy on single character reconstruction, but falls to 37% when
reconstructing lacunae of various lengths. While not suitable for definitive
manuscript reconstruction, we argue that our RNN model can help scholars rank
the likelihood of textual reconstructions. As evidence, we use our RNN model to
rank reconstructions in two early Coptic manuscripts. Our investigation shows
that neural models can augment traditional methods of textual restoration,
providing scholars with an additional tool to assess lacunae in Coptic
manuscripts.

摘要：古代手稿經常受損，包含稱為殘缺的文本空白。在本文中，我們提出一個雙向 RNN 模型，用於預測手稿殘缺中的科普特文字元。我們的最佳模型在單一字元重建上執行 72% 的準確度，但在重建不同長度的殘缺時下降到 37%。雖然不適合明確的手稿重建，但我們認為我們的 RNN 模型可以幫助學者對文本重建的可能性進行排名。作為證據，我們使用我們的 RNN 模型對兩個早期科普特手稿中的重建進行排名。我們的調查表明，神經模型可以擴充傳統的文本修復方法，為學者提供一個額外的工具來評估科普特手稿中的殘缺。

##### **Conditional Quantile Estimation for Uncertain Watch Time in Short-Video Recommendation**
2407.12223v1 by Chengzhi Lin, Shuchang Liu, Chuyuan Wang, Yongqi Liu

Within the domain of short video recommendation, predicting users' watch time
is a critical but challenging task. Prevailing deterministic solutions obtain
accurate debiased statistical models, yet they neglect the intrinsic
uncertainty inherent in user environments. In our observation, we found that
this uncertainty could potentially limit these methods' accuracy in watch-time
prediction on our online platform, despite that we have employed numerous
features and complex network architectures. Consequently, we believe that a
better solution is to model the conditional distribution of this uncertain
watch time.
  In this paper, we introduce a novel estimation technique -- Conditional
Quantile Estimation (CQE), which utilizes quantile regression to capture the
nuanced distribution of watch time. The learned distribution accounts for the
stochastic nature of users, thereby it provides a more accurate and robust
estimation. In addition, we also design several strategies to enhance the
quantile prediction including conditional expectation, conservative estimation,
and dynamic quantile combination. We verify the effectiveness of our method
through extensive offline evaluations using public datasets as well as
deployment in a real-world video application with over 300 million daily active
users.

摘要：在短视频推荐领域，预测用户的观看时长是一项至关重要的任务，但也是一项具有挑战性的任务。现有的确定性解决方案获得了准确的去偏差统计模型，但它们忽略了用户环境中固有的不确定性。在我们的观察中，我们发现这种不确定性可能会限制这些方法在我们的在线平台上预测观看时长的准确性，尽管我们采用了众多功能和复杂的网络架构。因此，我们认为一个更好的解决方案是对这种不确定的观看时长的条件分布进行建模。
在本文中，我们介绍了一种新颖的估计技术——条件分位数估计 (CQE)，它利用分位数回归来捕捉观看时长的细微差别分布。学习到的分布考虑了用户的随机性，因此它提供了更准确和稳健的估计。此外，我们还设计了几种策略来增强分位数预测，包括条件期望、保守估计和动态分位数组合。我们通过使用公共数据集进行广泛的离线评估以及在拥有超过 3 亿日活跃用户的真实视频应用程序中进行部署，验证了我们方法的有效性。

##### **Questionable practices in machine learning**
2407.12220v1 by Gavin Leech, Juan J. Vazquez, Misha Yagudin, Niclas Kupper, Laurence Aitchison

Evaluating modern ML models is hard. The strong incentive for researchers and
companies to report a state-of-the-art result on some metric often leads to
questionable research practices (QRPs): bad practices which fall short of
outright research fraud. We describe 43 such practices which can undermine
reported results, giving examples where possible. Our list emphasises the
evaluation of large language models (LLMs) on public benchmarks. We also
discuss "irreproducible research practices", i.e. decisions that make it
difficult or impossible for other researchers to reproduce, build on or audit
previous research.

摘要：評估現代機器學習模型很困難。研究人員和公司為了報告某項指標的最新結果而產生的強烈誘因，通常會導致有問題的研究實務（QRPs）：未達研究造假的惡劣實務。我們描述 43 種此類實務，這些實務可能會破壞報告的結果，並在可能的情況下提供範例。我們的清單強調在公開基準上評估大型語言模型（LLM）。我們還會討論「無法重現的研究實務」，亦即讓其他研究人員無法重現、建立或審查先前研究的決策。

##### **A Language Modeling Approach to Diacritic-Free Hebrew TTS**
2407.12206v1 by Amit Roth, Arnon Turetzky, Yossi Adi

We tackle the task of text-to-speech (TTS) in Hebrew. Traditional Hebrew
contains Diacritics, which dictate the way individuals should pronounce given
words, however, modern Hebrew rarely uses them. The lack of diacritics in
modern Hebrew results in readers expected to conclude the correct pronunciation
and understand which phonemes to use based on the context. This imposes a
fundamental challenge on TTS systems to accurately map between text-to-speech.
In this work, we propose to adopt a language modeling Diacritics-Free approach,
for the task of Hebrew TTS. The model operates on discrete speech
representations and is conditioned on a word-piece tokenizer. We optimize the
proposed method using in-the-wild weakly supervised data and compare it to
several diacritic-based TTS systems. Results suggest the proposed method is
superior to the evaluated baselines considering both content preservation and
naturalness of the generated speech. Samples can be found under the following
link: pages.cs.huji.ac.il/adiyoss-lab/HebTTS/

摘要：我們處理希伯來語的文字轉語音 (TTS) 任務。傳統希伯來語包含變音符號，用來指示個人應該如何發音給定的字詞，然而，現代希伯來語很少使用它們。現代希伯來語中缺少變音符號導致讀者必須根據上下文推論正確的發音並了解應使用的音素。這對 TTS 系統準確地對應文字轉語音提出了根本性的挑戰。在這項工作中，我們建議採用一種無變音符號的語言建模方法來執行希伯來語 TTS 的任務。該模型運作於離散的語音表示，並以字詞切換器為條件。我們使用自然界中的弱監督數據最佳化建議的方法，並將其與多個基於變音符號的 TTS 系統進行比較。結果表明，建議的方法在考慮所產生語音的內容保留和自然性方面都優於評估的基準。範例可以在以下連結中找到：pages.cs.huji.ac.il/adiyoss-lab/HebTTS/

##### **This Probably Looks Exactly Like That: An Invertible Prototypical Network**
2407.12200v1 by Zachariah Carmichael, Timothy Redgrave, Daniel Gonzalez Cedre, Walter J. Scheirer

We combine concept-based neural networks with generative, flow-based
classifiers into a novel, intrinsically explainable, exactly invertible
approach to supervised learning. Prototypical neural networks, a type of
concept-based neural network, represent an exciting way forward in realizing
human-comprehensible machine learning without concept annotations, but a
human-machine semantic gap continues to haunt current approaches. We find that
reliance on indirect interpretation functions for prototypical explanations
imposes a severe limit on prototypes' informative power. From this, we posit
that invertibly learning prototypes as distributions over the latent space
provides more robust, expressive, and interpretable modeling. We propose one
such model, called ProtoFlow, by composing a normalizing flow with Gaussian
mixture models. ProtoFlow (1) sets a new state-of-the-art in joint generative
and predictive modeling and (2) achieves predictive performance comparable to
existing prototypical neural networks while enabling richer interpretation.

摘要：我們將基於概念的神經網路與生成式、基於流動的分類器結合到一個新穎、內在可解釋、精確可逆的監督學習方法中。原型神經網路是一種基於概念的神經網路，代表了一種令人興奮的實現人類可理解機器學習的方法，無需概念註解，但人類與機器語義差距持續困擾著當前的做法。我們發現依賴原型解釋的間接解釋功能對原型的資訊能力施加了嚴格的限制。從此，我們假設將可逆學習原型視為潛在空間上的分佈提供了更強健、更有表現力且更可解釋的建模。我們提出一個這樣的模型，稱為 ProtoFlow，透過將正規化流與高斯混合模型組合而成。ProtoFlow (1) 設定了聯合生成式和預測建模的最新技術，並 (2) 達到與現有原型神經網路相當的預測效能，同時支援更豐富的解釋。

##### **Towards Interpretable Visuo-Tactile Predictive Models for Soft Robot Interactions**
2407.12197v1 by Enrico Donato, Thomas George Thuruthel, Egidio Falotico

Autonomous systems face the intricate challenge of navigating unpredictable
environments and interacting with external objects. The successful integration
of robotic agents into real-world situations hinges on their perception
capabilities, which involve amalgamating world models and predictive skills.
Effective perception models build upon the fusion of various sensory modalities
to probe the surroundings. Deep learning applied to raw sensory modalities
offers a viable option. However, learning-based perceptive representations
become difficult to interpret. This challenge is particularly pronounced in
soft robots, where the compliance of structures and materials makes prediction
even harder. Our work addresses this complexity by harnessing a generative
model to construct a multi-modal perception model for soft robots and to
leverage proprioceptive and visual information to anticipate and interpret
contact interactions with external objects. A suite of tools to interpret the
perception model is furnished, shedding light on the fusion and prediction
processes across multiple sensory inputs after the learning phase. We will
delve into the outlooks of the perception model and its implications for
control purposes.

摘要：自主系統面臨在不可預測的環境中導航和與外部物體互動的複雜挑戰。機器人代理成功整合到現實世界的情況取決於它們的感知能力，這涉及融合世界模型和預測技能。有效的感知模型建立在融合各種感官模式以探測周圍環境的基礎上。應用於原始感官模式的深度學習提供了一個可行的選項。然而，基於學習的感知表徵難以解釋。這個挑戰在軟機器人中尤為明顯，其中結構和材料的柔順性使得預測更加困難。我們的研究通過利用生成模型來構建軟機器人的多模式感知模型，並利用本体感覺和視覺信息來預測和解釋與外部物體的接觸交互，從而解決了這種複雜性。提供了一套解釋感知模型的工具，在學習階段後闡明了跨多個感官輸入的融合和預測過程。我們將深入探討感知模型的前景及其對控制目的的影響。

##### **MASIVE: Open-Ended Affective State Identification in English and Spanish**
2407.12196v1 by Nicholas Deas, Elsbeth Turcan, Iván Pérez Mejía, Kathleen McKeown

In the field of emotion analysis, much NLP research focuses on identifying a
limited number of discrete emotion categories, often applied across languages.
These basic sets, however, are rarely designed with textual data in mind, and
culture, language, and dialect can influence how particular emotions are
interpreted. In this work, we broaden our scope to a practically unbounded set
of \textit{affective states}, which includes any terms that humans use to
describe their experiences of feeling. We collect and publish MASIVE, a dataset
of Reddit posts in English and Spanish containing over 1,000 unique affective
states each. We then define the new problem of \textit{affective state
identification} for language generation models framed as a masked span
prediction task. On this task, we find that smaller finetuned multilingual
models outperform much larger LLMs, even on region-specific Spanish affective
states. Additionally, we show that pretraining on MASIVE improves model
performance on existing emotion benchmarks. Finally, through machine
translation experiments, we find that native speaker-written data is vital to
good performance on this task.

摘要：在情感分析领域，许多 NLP 研究专注于识别数量有限的离散情感类别，通常应用于各种语言。
然而，这些基本集合很少考虑文本数据，而文化、语言和方言会影响特定情感的解读方式。
在这项工作中，我们将范围拓宽到一个实际上不受限的「情感状态」集合，其中包括人类用来描述其感受体验的任何术语。
我们收集并发布了 MASIVE，这是一个包含 1,000 多个独特情感状态的英语和西班牙语 Reddit 帖子数据集。
然后，我们为语言生成模型定义了「情感状态识别」的新问题，将其构建为一个掩码跨度预测任务。
在这个任务中，我们发现较小的微调多语言模型优于大得多的 LLM，即使在特定区域的西班牙语情感状态上也是如此。
此外，我们表明在 MASIVE 上进行预训练可以提高模型在现有情感基准上的性能。
最后，通过机器翻译实验，我们发现母语人士撰写的数据对于这项任务的良好表现至关重要。

##### **Satisficing Exploration for Deep Reinforcement Learning**
2407.12185v1 by Dilip Arumugam, Saurabh Kumar, Ramki Gummadi, Benjamin Van Roy

A default assumption in the design of reinforcement-learning algorithms is
that a decision-making agent always explores to learn optimal behavior. In
sufficiently complex environments that approach the vastness and scale of the
real world, however, attaining optimal performance may in fact be an entirely
intractable endeavor and an agent may seldom find itself in a position to
complete the requisite exploration for identifying an optimal policy. Recent
work has leveraged tools from information theory to design agents that
deliberately forgo optimal solutions in favor of sufficiently-satisfying or
satisficing solutions, obtained through lossy compression. Notably, such agents
may employ fundamentally different exploratory decisions to learn satisficing
behaviors more efficiently than optimal ones that are more data intensive.
While supported by a rigorous corroborating theory, the underlying algorithm
relies on model-based planning, drastically limiting the compatibility of these
ideas with function approximation and high-dimensional observations. In this
work, we remedy this issue by extending an agent that directly represents
uncertainty over the optimal value function allowing it to both bypass the need
for model-based planning and to learn satisficing policies. We provide simple
yet illustrative experiments that demonstrate how our algorithm enables deep
reinforcement-learning agents to achieve satisficing behaviors. In keeping with
previous work on this setting for multi-armed bandits, we additionally find
that our algorithm is capable of synthesizing optimal behaviors, when feasible,
more efficiently than its non-information-theoretic counterpart.

摘要：在強化學習演算法的設計中，一個預設的假設是決策制定者始終會探索以學習最佳行為。然而，在足夠複雜且接近真實世界廣闊性和規模的環境中，達成最佳效能事實上可能是一項完全難以解決的努力，而且一個代理人可能很少發現自己處於一個能完成識別最佳策略所需的探索位置。最近的研究利用資訊理論的工具來設計代理人，這些代理人故意放棄最佳解，轉而採用透過有損壓縮得到的足夠令人滿意或令人滿意的解。值得注意的是，此類代理人可能會採用根本不同的探索性決策，以比資料密集型最佳解更有效率地學習令人滿意的行為。雖然有嚴謹的佐證理論支持，但基礎演算法依賴於基於模型的規劃，這極大地限制了這些想法與函數逼近和高維度觀測的相容性。在這項研究中，我們透過擴充一個代理人來解決這個問題，該代理人直接表示對最佳值函數的不確定性，使其既能繞過對基於模型的規劃的需求，又能學習令人滿意的策略。我們提供了簡單但有說明性的實驗，展示我們的演算法如何讓深度強化學習代理人實現令人滿意的行為。與先前針對多臂老虎機的設定所做的研究保持一致，我們另外發現我們的演算法有能力在可行的情況下比其非資訊理論對應演算法更有效率地綜合最佳行為。

##### **GPT-4V Cannot Generate Radiology Reports Yet**
2407.12176v1 by Yuyang Jiang, Chacha Chen, Dang Nguyen, Benjamin M. Mervak, Chenhao Tan

GPT-4V's purported strong multimodal abilities raise interests in using it to
automate radiology report writing, but there lacks thorough evaluations. In
this work, we perform a systematic evaluation of GPT-4V in generating radiology
reports on two chest X-ray report datasets: MIMIC-CXR and IU X-Ray. We attempt
to directly generate reports using GPT-4V through different prompting
strategies and find that it fails terribly in both lexical metrics and clinical
efficacy metrics. To understand the low performance, we decompose the task into
two steps: 1) the medical image reasoning step of predicting medical condition
labels from images; and 2) the report synthesis step of generating reports from
(groundtruth) conditions. We show that GPT-4V's performance in image reasoning
is consistently low across different prompts. In fact, the distributions of
model-predicted labels remain constant regardless of which groundtruth
conditions are present on the image, suggesting that the model is not
interpreting chest X-rays meaningfully. Even when given groundtruth conditions
in report synthesis, its generated reports are less correct and less
natural-sounding than a finetuned LLaMA-2. Altogether, our findings cast doubt
on the viability of using GPT-4V in a radiology workflow.

摘要：GPT-4V 所謂強大的多模態能力引起了人們對使用它來自動化放射報告編寫的興趣，但卻缺乏徹底的評估。在這項工作中，我們對 GPT-4V 在兩個胸部 X 光報告數據集：MIMIC-CXR 和 IU X-Ray 上生成放射報告進行了系統評估。我們嘗試通過不同的提示策略直接使用 GPT-4V 生成報告，並發現它在詞彙指標和臨床療效指標上都表現得很糟糕。為了了解低性能，我們將任務分解為兩個步驟：1) 從圖像預測醫療狀況標籤的醫學影像推理步驟；以及 2) 從（真實）條件生成報告的報告合成步驟。我們表明，GPT-4V 在圖像推理中的表現始終低於不同的提示。事實上，模型預測標籤的分布保持不變，無論圖像上存在哪些真實條件，這表明該模型沒有有意義地解釋胸部 X 光。即使在報告合成中給出真實條件，其生成的報告也不如微調後的 LLaMA-2 正確和自然。總之，我們的發現對在放射工作流程中使用 GPT-4V 的可行性提出了質疑。

##### **Beta Sampling is All You Need: Efficient Image Generation Strategy for Diffusion Models using Stepwise Spectral Analysis**
2407.12173v1 by Haeil Lee, Hansang Lee, Seoyeon Gye, Junmo Kim

Generative diffusion models have emerged as a powerful tool for high-quality
image synthesis, yet their iterative nature demands significant computational
resources. This paper proposes an efficient time step sampling method based on
an image spectral analysis of the diffusion process, aimed at optimizing the
denoising process. Instead of the traditional uniform distribution-based time
step sampling, we introduce a Beta distribution-like sampling technique that
prioritizes critical steps in the early and late stages of the process. Our
hypothesis is that certain steps exhibit significant changes in image content,
while others contribute minimally. We validated our approach using Fourier
transforms to measure frequency response changes at each step, revealing
substantial low-frequency changes early on and high-frequency adjustments
later. Experiments with ADM and Stable Diffusion demonstrated that our Beta
Sampling method consistently outperforms uniform sampling, achieving better FID
and IS scores, and offers competitive efficiency relative to state-of-the-art
methods like AutoDiffusion. This work provides a practical framework for
enhancing diffusion model efficiency by focusing computational resources on the
most impactful steps, with potential for further optimization and broader
application.

摘要：生成式擴散模型已成為高品質影像合成的強大工具，但其反覆運算的特性需要大量的運算資源。本文提出了一種基於擴散過程影像頻譜分析的有效時間步長抽樣方法，旨在最佳化去噪過程。我們引進一種類似貝塔分布的抽樣技術，取代傳統的均勻分布時間步長抽樣，此技術優先處理過程中早期和後期的關鍵步驟。我們的假設是，某些步驟會顯著改變影像內容，而其他步驟的貢獻則很小。我們使用傅立葉轉換驗證了我們的做法，以測量每個步驟的頻率響應變化，結果顯示早期有大量的低頻變化，而後期的調整則集中在高頻。使用 ADM 和 Stable Diffusion 的實驗證明，我們的貝塔抽樣方法始終優於均勻抽樣，獲得了更好的 FID 和 IS 分數，並且相對於 AutoDiffusion 等最先進的方法提供了有競爭力的效率。這項工作提供了一個實用的架構，可透過將運算資源集中在最有影響力的步驟上來提高擴散模型的效率，並具有進一步最佳化和更廣泛應用 的潛力。

##### **Building AI Agents for Autonomous Clouds: Challenges and Design Principles**
2407.12165v1 by Manish Shetty, Yinfang Chen, Gagan Somashekar, Minghua Ma, Yogesh Simmhan, Xuchao Zhang, Jonathan Mace, Dax Vandevoorde, Pedro Las-Casas, Shachee Mishra Gupta, Suman Nath, Chetan Bansal, Saravan Rajmohan

The rapid growth in the use of Large Language Models (LLMs) and AI Agents as
part of software development and deployment is revolutionizing the information
technology landscape. While code generation receives significant attention, a
higher-impact application lies in using AI agents for operational resilience of
cloud services, which currently require significant human effort and domain
knowledge. There is a growing interest in AI for IT Operations (AIOps) which
aims to automate complex operational tasks, like fault localization and root
cause analysis, thereby reducing human intervention and customer impact.
However, achieving the vision of autonomous and self-healing clouds though
AIOps is hampered by the lack of standardized frameworks for building,
evaluating, and improving AIOps agents. This vision paper lays the groundwork
for such a framework by first framing the requirements and then discussing
design decisions that satisfy them. We also propose AIOpsLab, a prototype
implementation leveraging agent-cloud-interface that orchestrates an
application, injects real-time faults using chaos engineering, and interfaces
with an agent to localize and resolve the faults. We report promising results
and lay the groundwork to build a modular and robust framework for building,
evaluating, and improving agents for autonomous clouds.

摘要：大型語言模型 (LLM) 和 AI 代理在軟體開發和部署中使用的快速增長正在革新資訊技術領域。雖然程式碼生成受到極大關注，但影響力更大的應用在於使用 AI 代理來提升雲端服務的運作復原力，這目前需要大量的人力投入和領域知識。對 IT 運作的 AI (AIOps) 興趣日益增加，其目標是自動化複雜的運作任務，例如故障定位和根本原因分析，從而減少人為介入和客戶影響。然而，儘管有 AIOps，但要實現自主和自我修復雲端的願景，卻受到缺乏用於建構、評估和改善 AIOps 代理的標準化架構的阻礙。本願景文件透過首先建構需求，然後討論滿足這些需求的設計決策，為此類架構奠定基礎。我們還提出 AIOpsLab，這是一個原型實作，利用代理雲端介面來協調應用程式，使用混亂工程注入即時故障，並與代理介面以定位和解決故障。我們報告了有希望的結果，並奠定了建構、評估和改善用於自主雲端的代理的模組化且穩健的架構的基礎。

##### **Subject-driven Text-to-Image Generation via Preference-based Reinforcement Learning**
2407.12164v1 by Yanting Miao, William Loh, Suraj Kothawade, Pascal Poupart, Abdullah Rashwan, Yeqing Li

Text-to-image generative models have recently attracted considerable
interest, enabling the synthesis of high-quality images from textual prompts.
However, these models often lack the capability to generate specific subjects
from given reference images or to synthesize novel renditions under varying
conditions. Methods like DreamBooth and Subject-driven Text-to-Image (SuTI)
have made significant progress in this area. Yet, both approaches primarily
focus on enhancing similarity to reference images and require expensive setups,
often overlooking the need for efficient training and avoiding overfitting to
the reference images. In this work, we present the $\lambda$-Harmonic reward
function, which provides a reliable reward signal and enables early stopping
for faster training and effective regularization. By combining the
Bradley-Terry preference model, the $\lambda$-Harmonic reward function also
provides preference labels for subject-driven generation tasks. We propose
Reward Preference Optimization (RPO), which offers a simpler setup (requiring
only $3\%$ of the negative samples used by DreamBooth) and fewer gradient steps
for fine-tuning. Unlike most existing methods, our approach does not require
training a text encoder or optimizing text embeddings and achieves text-image
alignment by fine-tuning only the U-Net component. Empirically,
$\lambda$-Harmonic proves to be a reliable approach for model selection in
subject-driven generation tasks. Based on preference labels and early stopping
validation from the $\lambda$-Harmonic reward function, our algorithm achieves
a state-of-the-art CLIP-I score of 0.833 and a CLIP-T score of 0.314 on
DreamBench.

摘要：<paragraph>文字到影像生成模型最近引起了相當大的興趣，它能從文字提示中合成高品質的影像。
然而，這些模型通常缺乏從給定的參考影像中生成特定主題或在不同條件下合成新版本的的能力。
像 DreamBooth 和主題驅動文字到影像 (SuTI) 等方法在此領域取得了重大進展。
然而，這兩種方法主要專注於增強與參考影像的相似性，並且需要昂貴的設定，常常忽略了對有效率訓練和避免過度擬合參考影像的需求。
在這項工作中，我們提出了 $\lambda$-Harmonic 獎勵函數，它提供了一個可靠的獎勵訊號，並能進行早期停止以進行更快速的訓練和有效的正則化。
透過結合 Bradley-Terry 偏好模型，$\lambda$-Harmonic 獎勵函數也為主題驅動生成任務提供偏好標籤。
我們提出了獎勵偏好最佳化 (RPO)，它提供了一個更簡單的設定（只需要 DreamBooth 使用的負面樣本的 3%），並且需要更少的梯度步驟進行微調。
與現有的方法不同，我們的方法不需要訓練文字編碼器或最佳化文字嵌入，並僅透過微調 U-Net 組件來達成文字影像對齊。
根據經驗，$\lambda$-Harmonic 被證明是主題驅動生成任務中進行模型選擇的可靠方法。
基於 $\lambda$-Harmonic 獎勵函數的偏好標籤和早期停止驗證，我們的演算法在 DreamBench 上達到了最先進的 CLIP-I 分數 0.833 和 CLIP-T 分數 0.314。</paragraph>

##### **Interpretability in Action: Exploratory Analysis of VPT, a Minecraft Agent**
2407.12161v1 by Karolis Jucys, George Adamopoulos, Mehrab Hamidi, Stephanie Milani, Mohammad Reza Samsami, Artem Zholus, Sonia Joseph, Blake Richards, Irina Rish, Özgür Şimşek

Understanding the mechanisms behind decisions taken by large foundation
models in sequential decision making tasks is critical to ensuring that such
systems operate transparently and safely. In this work, we perform exploratory
analysis on the Video PreTraining (VPT) Minecraft playing agent, one of the
largest open-source vision-based agents. We aim to illuminate its reasoning
mechanisms by applying various interpretability techniques. First, we analyze
the attention mechanism while the agent solves its training task - crafting a
diamond pickaxe. The agent pays attention to the last four frames and several
key-frames further back in its six-second memory. This is a possible mechanism
for maintaining coherence in a task that takes 3-10 minutes, despite the short
memory span. Secondly, we perform various interventions, which help us uncover
a worrying case of goal misgeneralization: VPT mistakenly identifies a villager
wearing brown clothes as a tree trunk when the villager is positioned
stationary under green tree leaves, and punches it to death.

摘要：了解大型基础模型在顺序决策任务中所做决策背后的机制对于确保此类系统透明且安全地运行至关重要。在这项工作中，我们对基于视频预训练 (VPT) 的 Minecraft 扮演代理进行了探索性分析，这是最大的基于视觉的开源代理之一。我们旨在通过应用各种可解释性技术来阐明其推理机制。首先，我们分析了该代理在解决其训练任务（制作钻石镐）时的注意力机制。该代理关注六秒记忆中的最后四帧和几个关键帧。这是一种可能的机制，用于在任务需要 3-10 分钟的情况下保持连贯性，尽管记忆跨度很短。其次，我们执行了各种干预措施，这有助于我们发现一个令人担忧的目标泛化错误：当村民穿着棕色衣服站在绿树叶下的静止状态时，VPT 错误地将该村民识别为树干，并将其击打致死。

##### **Predicting Emotion Intensity in Polish Political Texts: Comparing Supervised Models and Large Language Models in a Resource-Poor Language**
2407.12141v1 by Hubert Plisiecki, Piotr Koc, Maria Flakus, Artur Pokropek

This study explores the use of large language models (LLMs) to predict
emotion intensity in Polish political texts, a resource-poor language context.
The research compares the performance of several LLMs against a supervised
model trained on an annotated corpus of 10,000 social media texts, evaluated
for the intensity of emotions by expert judges. The findings indicate that
while the supervised model generally outperforms LLMs, offering higher accuracy
and lower variance, LLMs present a viable alternative, especially given the
high costs associated with data annotation. The study highlights the potential
of LLMs in low-resource language settings and underscores the need for further
research on emotion intensity prediction and its application across different
languages and continuous features. The implications suggest a nuanced
decision-making process to choose the right approach to emotion prediction for
researchers and practitioners based on resource availability and the specific
requirements of their tasks.

摘要：本研究探討使用大型語言模型 (LLM) 來預測資源匱乏語言環境中波蘭政治文本中的情緒強度。本研究比較了多個 LLM 的效能，並與針對 10,000 則社群媒體文本的註解語料庫訓練的監督式模型進行比較，再由專家評審針對情緒強度進行評估。研究結果指出，儘管監督式模型通常優於 LLM，能提供更高的準確度和更低的變異性，但 LLM 仍提供可行的替代方案，特別是在考量資料標註相關的高昂成本時。本研究強調 LLM 在低資源語言環境中的潛力，並強調需要進一步研究情緒強度預測及其在不同語言和連續特徵中的應用。研究結果建議，研究人員和實務工作者應根據資源可用性和其任務的特定需求，採用細緻的決策制定程序，以選擇合適的情緒預測方法。

##### **LLMs-in-the-loop Part-1: Expert Small AI Models for Bio-Medical Text Translation**
2407.12126v1 by Bunyamin Keles, Murat Gunay, Serdar I. Caglar

Machine translation is indispensable in healthcare for enabling the global
dissemination of medical knowledge across languages. However, complex medical
terminology poses unique challenges to achieving adequate translation quality
and accuracy. This study introduces a novel "LLMs-in-the-loop" approach to
develop supervised neural machine translation models optimized specifically for
medical texts. While large language models (LLMs) have demonstrated powerful
capabilities, this research shows that small, specialized models trained on
high-quality in-domain (mostly synthetic) data can outperform even vastly
larger LLMs.
  Custom parallel corpora in six languages were compiled from scientific
articles, synthetically generated clinical documents, and medical texts. Our
LLMs-in-the-loop methodology employs synthetic data generation, rigorous
evaluation, and agent orchestration to enhance performance. We developed small
medical translation models using the MarianMT base model. We introduce a new
medical translation test dataset to standardize evaluation in this domain.
Assessed using BLEU, METEOR, ROUGE, and BERT scores on this test set, our
MarianMT-based models outperform Google Translate, DeepL, and GPT-4-Turbo.
  Results demonstrate that our LLMs-in-the-loop approach, combined with
fine-tuning high-quality, domain-specific data, enables specialized models to
outperform general-purpose and some larger systems. This research, part of a
broader series on expert small models, paves the way for future
healthcare-related AI developments, including deidentification and bio-medical
entity extraction models. Our study underscores the potential of tailored
neural translation models and the LLMs-in-the-loop methodology to advance the
field through improved data generation, evaluation, agent, and modeling
techniques.

摘要：<paragraph>機器翻譯在醫療保健中不可或缺，因為它能跨語言傳播全球醫療知識。然而，複雜的醫學術語對達成適當的翻譯品質和準確性構成獨特的挑戰。本研究介紹一種新穎的「迴圈中的 LLM」方法，用於開發專門針對醫學文本最佳化的監督式神經機器翻譯模型。雖然大型語言模型 (LLM) 已展現強大的能力，但本研究顯示，針對高品質領域內 (大多為合成) 資料訓練的小型特殊化模型，甚至可以超越規模更大的 LLM。
  從科學文章、合成產生的臨床文件和醫學文本編譯了六種語言的客製化平行語料庫。我們的迴圈中 LLM 方法採用合成資料產生、嚴謹評估和代理協調來提升效能。我們使用 MarianMT 基礎模型開發小型醫學翻譯模型。我們引入新的醫學翻譯測試資料集，用於標準化此領域的評估。在這個測試集中使用 BLEU、METEOR、ROUGE 和 BERT 分數進行評估，我們的 MarianMT 基礎模型優於 Google Translate、DeepL 和 GPT-4-Turbo。
  結果證明，我們的迴圈中 LLM 方法結合針對特定領域進行微調的高品質資料，使特殊化模型能超越通用和一些較大的系統。這項研究是專家小型模型系列的一部分，為未來的醫療保健相關 AI 發展鋪路，包括去識別化和生物醫學實體萃取模型。我們的研究強調了客製化神經翻譯模型和迴圈中 LLM 方法的潛力，透過改善資料產生、評估、代理和建模技術，推進這個領域的發展。</paragraph>

##### **A Graph-based Adversarial Imitation Learning Framework for Reliable & Realtime Fleet Scheduling in Urban Air Mobility**
2407.12113v1 by Prithvi Poddar, Steve Paul, Souma Chowdhury

The advent of Urban Air Mobility (UAM) presents the scope for a
transformative shift in the domain of urban transportation. However, its
widespread adoption and economic viability depends in part on the ability to
optimally schedule the fleet of aircraft across vertiports in a UAM network,
under uncertainties attributed to airspace congestion, changing weather
conditions, and varying demands. This paper presents a comprehensive
optimization formulation of the fleet scheduling problem, while also
identifying the need for alternate solution approaches, since directly solving
the resulting integer nonlinear programming problem is computationally
prohibitive for daily fleet scheduling. Previous work has shown the
effectiveness of using (graph) reinforcement learning (RL) approaches to train
real-time executable policy models for fleet scheduling. However, such policies
can often be brittle on out-of-distribution scenarios or edge cases. Moreover,
training performance also deteriorates as the complexity (e.g., number of
constraints) of the problem increases. To address these issues, this paper
presents an imitation learning approach where the RL-based policy exploits
expert demonstrations yielded by solving the exact optimization using a Genetic
Algorithm. The policy model comprises Graph Neural Network (GNN) based encoders
that embed the space of vertiports and aircraft, Transformer networks to encode
demand, passenger fare, and transport cost profiles, and a Multi-head attention
(MHA) based decoder. Expert demonstrations are used through the Generative
Adversarial Imitation Learning (GAIL) algorithm. Interfaced with a UAM
simulation environment involving 8 vertiports and 40 aircrafts, in terms of the
daily profits earned reward, the new imitative approach achieves better mean
performance and remarkable improvement in the case of unseen worst-case
scenarios, compared to pure RL results.

摘要：城市空中交通 (UAM) 的出現為城市交通領域帶來轉型變革的契機。然而，其廣泛採用和經濟可行性部分取決於在 UAM 網路中跨垂直起降機場最佳安排機隊的能力，在歸因於空域擁堵、天氣狀況變化和需求變化的不確定性下。本文提出了機隊排程問題的全面最佳化公式，同時也確定了需要備用解決方案方法，因為直接解決產生的整數非線性規劃問題在計算上對於每日機隊排程而言是禁止的。先前的研究表明使用（圖表）強化學習 (RL) 方法來訓練用於機隊排程的即時可執行政策模型的有效性。然而，此類政策在分佈外場景或邊緣情況下通常會很脆弱。此外，隨著問題的複雜性（例如，約束的數量）增加，訓練效能也會下降。為了解決這些問題，本文提出了一種模仿學習方法，其中基於 RL 的政策利用通過使用遺傳演算法解決精確最佳化而產生的專家示範。政策模型包含基於圖神經網路 (GNN) 的編碼器，用於嵌入垂直起降機場和飛機的空間、用於編碼需求、乘客票價和運輸成本曲線的 Transformer 網路，以及基於多頭注意力 (MHA) 的解碼器。專家示範是透過生成對抗模仿學習 (GAIL) 演算法使用的。與涉及 8 個垂直起降機場和 40 架飛機的 UAM 模擬環境介接，就每日獲利獎勵而言，與純粹的 RL 結果相比，新的模仿方法達到了更好的平均效能和在未見的最壞情況下的顯著改善。

##### **Private prediction for large-scale synthetic text generation**
2407.12108v1 by Kareem Amin, Alex Bie, Weiwei Kong, Alexey Kurakin, Natalia Ponomareva, Umar Syed, Andreas Terzis, Sergei Vassilvitskii

We present an approach for generating differentially private synthetic text
using large language models (LLMs), via private prediction. In the private
prediction framework, we only require the output synthetic data to satisfy
differential privacy guarantees. This is in contrast to approaches that train a
generative model on potentially sensitive user-supplied source data and seek to
ensure the model itself is safe to release.
  We prompt a pretrained LLM with source data, but ensure that next-token
predictions are made with differential privacy guarantees. Previous work in
this paradigm reported generating a small number of examples (<10) at
reasonable privacy levels, an amount of data that is useful only for downstream
in-context learning or prompting. In contrast, we make changes that allow us to
generate thousands of high-quality synthetic data points, greatly expanding the
set of potential applications. Our improvements come from an improved privacy
analysis and a better private selection mechanism, which makes use of the
equivalence between the softmax layer for sampling tokens in LLMs and the
exponential mechanism. Furthermore, we introduce a novel use of public
predictions via the sparse vector technique, in which we do not pay privacy
costs for tokens that are predictable without sensitive data; we find this to
be particularly effective for structured data.

摘要：我們提出了一種透過私人預測，使用大型語言模型 (LLM) 產生差異性私人合成文字的方法。在私人預測框架中，我們只需要輸出合成資料以滿足差異性隱私保證。這與在潛在敏感的使用者提供來源資料上訓練生成模型，並確保模型本身可以安全發布的方法形成對比。
我們提示一個預先訓練好的 LLM 與來源資料，但確保下一個代幣預測是具有差異性隱私保證的。在此範例中先前的研究報告在合理的隱私層級中產生少量的範例 (<10)，這是一個僅對下游情境學習或提示有用的資料量。相反地，我們進行了變更，讓我們能夠產生數千個高品質的合成資料點，大幅擴展潛在應用程式的集合。我們的改進來自於改良的隱私分析和更好的私人選擇機制，它利用了 LLM 中用於抽樣代幣的 softmax 層和指數機制之間的等價性。此外，我們引進了一種透過稀疏向量技術公開預測的新穎使用方式，在其中我們不會為沒有敏感資料即可預測的代幣支付隱私成本；我們發現這對於結構化資料特別有效。

##### **Better RAG using Relevant Information Gain**
2407.12101v1 by Marc Pickett, Jeremy Hartman, Ayan Kumar Bhowmick, Raquib-ul Alam, Aditya Vempaty

A common way to extend the memory of large language models (LLMs) is by
retrieval augmented generation (RAG), which inserts text retrieved from a
larger memory into an LLM's context window. However, the context window is
typically limited to several thousand tokens, which limits the number of
retrieved passages that can inform a model's response. For this reason, it's
important to avoid occupying context window space with redundant information by
ensuring a degree of diversity among retrieved passages. At the same time, the
information should also be relevant to the current task. Most prior methods
that encourage diversity among retrieved results, such as Maximal Marginal
Relevance (MMR), do so by incorporating an objective that explicitly trades off
diversity and relevance. We propose a novel simple optimization metric based on
relevant information gain, a probabilistic measure of the total information
relevant to a query for a set of retrieved results. By optimizing this metric,
diversity organically emerges from our system. When used as a drop-in
replacement for the retrieval component of a RAG system, this method yields
state-of-the-art performance on question answering tasks from the Retrieval
Augmented Generation Benchmark (RGB), outperforming existing metrics that
directly optimize for relevance and diversity.

摘要：大型語言模型 (LLM) 擴充記憶體容量的常見方式是採用檢索增強生成 (RAG)，將從較大記憶體中檢索的文字插入 LLM 的上下文視窗中。然而，上下文視窗通常限制在數千個符號內，這會限制可提供模型回應的檢索段落數量。基於此原因，透過確保檢索段落具有一定程度的多樣性，以避免佔用上下文視窗空間來儲存重複資訊非常重要。同時，資訊也應與目前的任務相關。大多數現有的方法鼓勵檢索結果的多樣性，例如最大邊際關聯性 (MMR)，會透過納入明確權衡多樣性和關聯性的目標來達成。我們提出一個新穎且簡單的最佳化指標，此指標基於相關資訊增益，也就是針對一組檢索結果，與查詢相關的總資訊機率測量。透過最佳化此指標，多樣性會自然而然地從我們的系統中產生。當用作 RAG 系統檢索元件的直接替換時，此方法在檢索增強生成基準 (RGB) 的問答任務中產生最先進的效能，優於直接最佳化關聯性和多樣性的現有指標。

##### **Identifying Speakers in Dialogue Transcripts: A Text-based Approach Using Pretrained Language Models**
2407.12094v1 by Minh Nguyen, Franck Dernoncourt, Seunghyun Yoon, Hanieh Deilamsalehy, Hao Tan, Ryan Rossi, Quan Hung Tran, Trung Bui, Thien Huu Nguyen

We introduce an approach to identifying speaker names in dialogue
transcripts, a crucial task for enhancing content accessibility and
searchability in digital media archives. Despite the advancements in speech
recognition, the task of text-based speaker identification (SpeakerID) has
received limited attention, lacking large-scale, diverse datasets for effective
model training. Addressing these gaps, we present a novel, large-scale dataset
derived from the MediaSum corpus, encompassing transcripts from a wide range of
media sources. We propose novel transformer-based models tailored for
SpeakerID, leveraging contextual cues within dialogues to accurately attribute
speaker names. Through extensive experiments, our best model achieves a great
precision of 80.3\%, setting a new benchmark for SpeakerID. The data and code
are publicly available here:
\url{https://github.com/adobe-research/speaker-identification}

摘要：我們提出了一種在對話記錄中識別說話者名稱的方法，這對於加強數位媒體檔案庫中內容的可及性和可搜尋性來說是一項至關重要的任務。儘管語音辨識技術進步，但基於文字的說話者識別 (SpeakerID) 任務卻鮮少受到關注，缺乏大規模、多樣化的資料集來進行有效的模型訓練。為了解決這些問題，我們提出了一個新穎的大規模資料集，其來源為 MediaSum 語料庫，涵蓋來自廣泛媒體來源的記錄。我們提出了針對 SpeakerID 量身打造的新型Transformer模型，利用對話中的上下文線索來準確地歸因說話者名稱。透過廣泛的實驗，我們最好的模型達到了 80.3% 的高準確度，為 SpeakerID 樹立了新的基準。資料和程式碼在此公開：
\url{https://github.com/adobe-research/speaker-identification}

##### **GoldFinch: High Performance RWKV/Transformer Hybrid with Linear Pre-Fill and Extreme KV-Cache Compression**
2407.12077v1 by Daniel Goldstein, Fares Obeid, Eric Alcaide, Guangyu Song, Eugene Cheah

We introduce GoldFinch, a hybrid Linear Attention/Transformer sequence model
that uses a new technique to efficiently generate a highly compressed and
reusable KV-Cache in linear time and space with respect to sequence length.
GoldFinch stacks our new GOLD transformer on top of an enhanced version of the
Finch (RWKV-6) architecture. We train up to 1.5B parameter class models of the
Finch, Llama, and GoldFinch architectures, and find dramatically improved
modeling performance relative to both Finch and Llama. Our cache size savings
increase linearly with model layer count, ranging from 756-2550 times smaller
than the traditional transformer cache for common sizes, enabling inference of
extremely large context lengths even on limited hardware. Although
autoregressive generation has O(n) time complexity per token because of
attention, pre-fill computation of the entire initial cache state for a
submitted context costs only O(1) time per token due to the use of a recurrent
neural network (RNN) to generate this cache. We release our trained weights and
training code under the Apache 2.0 license for community use.

摘要：我們介紹 GoldFinch，一個混合線性注意力/轉換器序列模型，它使用一種新技術，在線性時間和空間中有效生成一個高度壓縮且可重複使用的 KV 快取，相對於序列長度。GoldFinch 將我們新的 GOLD 轉換器堆疊在增強版本的 Finch (RWKV-6) 架構之上。我們訓練了 Finch、Llama 和 GoldFinch 架構中高達 1.5B 參數類別模型，並發現相對於 Finch 和 Llama，建模性能顯著提升。我們的快取大小節省隨著模型層數的增加而線性增加，比傳統轉換器快取小 756-2550 倍，即使在有限的硬體上也能推論極大的上下文長度。儘管自迴歸生成具有 O(n) 時間複雜度，因為注意力，但由於使用遞迴神經網路 (RNN) 來生成此快取，提交的上下文的整個初始快取狀態的預填充計算每個令牌只需 O(1) 時間。我們在 Apache 2.0 許可下釋出訓練後的權重和訓練程式碼，供社群使用。

##### **Does Refusal Training in LLMs Generalize to the Past Tense?**
2407.11969v1 by Maksym Andriushchenko, Nicolas Flammarion

Refusal training is widely used to prevent LLMs from generating harmful,
undesirable, or illegal outputs. We reveal a curious generalization gap in the
current refusal training approaches: simply reformulating a harmful request in
the past tense (e.g., "How to make a Molotov cocktail?" to "How did people make
a Molotov cocktail?") is often sufficient to jailbreak many state-of-the-art
LLMs. We systematically evaluate this method on Llama-3 8B, GPT-3.5 Turbo,
Gemma-2 9B, Phi-3-Mini, GPT-4o, and R2D2 models using GPT-3.5 Turbo as a
reformulation model. For example, the success rate of this simple attack on
GPT-4o increases from 1% using direct requests to 88% using 20 past tense
reformulation attempts on harmful requests from JailbreakBench with GPT-4 as a
jailbreak judge. Interestingly, we also find that reformulations in the future
tense are less effective, suggesting that refusal guardrails tend to consider
past historical questions more benign than hypothetical future questions.
Moreover, our experiments on fine-tuning GPT-3.5 Turbo show that defending
against past reformulations is feasible when past tense examples are explicitly
included in the fine-tuning data. Overall, our findings highlight that the
widely used alignment techniques -- such as SFT, RLHF, and adversarial training
-- employed to align the studied models can be brittle and do not always
generalize as intended. We provide code and jailbreak artifacts at
https://github.com/tml-epfl/llm-past-tense.

摘要：拒絕訓練被廣泛用於防止 LLM 產生有害、不受歡迎或非法的輸出。我們揭示了當前拒絕訓練方法中一個奇怪的概括差距：僅僅用過去式重新表述一個有害的請求（例如，「如何製作莫洛托夫雞尾酒？」改為「人們是如何製作莫洛托夫雞尾酒的？」）通常足以讓許多最先進的 LLM 越獄。我們使用 GPT-3.5 Turbo 作為重新表述模型，系統性地評估了這種方法在 Llama-3 8B、GPT-3.5 Turbo、Gemma-2 9B、Phi-3-Mini、GPT-4o 和 R2D2 模型上的效果。例如，這種簡單攻擊在 GPT-4o 上的成功率從使用直接請求時的 1% 增加到使用 20 次過去式重新表述嘗試對來自 JailbreakBench 的有害請求時為 88%，而 GPT-4 則作為越獄評判。有趣的是，我們還發現，未來時態的重新表述效果較差，這表明拒絕防護措施傾向於將過去的歷史問題視為比假設的未來問題更良性。此外，我們對微調 GPT-3.5 Turbo 的實驗表明，在微調數據中明確包含過去時態的示例時，可以防禦過去的重新表述。總的來說，我們的發現強調了廣泛使用的對齊技術——例如 SFT、RLHF 和對抗訓練——用於對齊所研究的模型可能是脆弱的，並且並不總是按預期的那樣概括。我們在 https://github.com/tml-epfl/llm-past-tense 提供代碼和越獄工件。

##### **Efficient Training with Denoised Neural Weights**
2407.11966v1 by Yifan Gong, Zheng Zhan, Yanyu Li, Yerlan Idelbayev, Andrey Zharkov, Kfir Aberman, Sergey Tulyakov, Yanzhi Wang, Jian Ren

Good weight initialization serves as an effective measure to reduce the
training cost of a deep neural network (DNN) model. The choice of how to
initialize parameters is challenging and may require manual tuning, which can
be time-consuming and prone to human error. To overcome such limitations, this
work takes a novel step towards building a weight generator to synthesize the
neural weights for initialization. We use the image-to-image translation task
with generative adversarial networks (GANs) as an example due to the ease of
collecting model weights spanning a wide range. Specifically, we first collect
a dataset with various image editing concepts and their corresponding trained
weights, which are later used for the training of the weight generator. To
address the different characteristics among layers and the substantial number
of weights to be predicted, we divide the weights into equal-sized blocks and
assign each block an index. Subsequently, a diffusion model is trained with
such a dataset using both text conditions of the concept and the block indexes.
By initializing the image translation model with the denoised weights predicted
by our diffusion model, the training requires only 43.3 seconds. Compared to
training from scratch (i.e., Pix2pix), we achieve a 15x training time
acceleration for a new concept while obtaining even better image generation
quality.

摘要：良好的權重初始化是減少深度神經網路 (DNN) 模型訓練成本的有效措施。如何初始化參數的選擇具有挑戰性，且可能需要手動調整，這可能會花費大量時間且容易出錯。為了克服這些限制，這項工作採取了一個創新的步驟，朝著建立一個權重生成器來合成初始化的神經權重邁進。我們以使用生成對抗網路 (GAN) 的影像轉影像轉換任務為例，因為收集涵蓋廣泛範圍的模型權重很簡單。具體來說，我們首先收集一個包含各種影像編輯概念及其對應訓練權重的資料集，這些權重稍後用於訓練權重生成器。為了應對層之間的不同特性和大量的待預測權重，我們將權重分成大小相等的區塊，並為每個區塊指定一個索引。隨後，使用包含概念文字條件和區塊索引的資料集，訓練一個擴散模型。透過使用我們的擴散模型預測的去噪權重初始化影像轉換模型，訓練僅需 43.3 秒。與從頭開始訓練 (即 Pix2pix) 相比，我們為一個新概念實現了 15 倍的訓練時間加速，同時獲得更好的影像生成品質。

##### **NeedleBench: Can LLMs Do Retrieval and Reasoning in 1 Million Context Window?**
2407.11963v1 by Mo Li, Songyang Zhang, Yunxin Liu, Kai Chen

In evaluating the long-context capabilities of large language models (LLMs),
identifying content relevant to a user's query from original long documents is
a crucial prerequisite for any LLM to answer questions based on long text. We
present NeedleBench, a framework consisting of a series of progressively more
challenging tasks for assessing bilingual long-context capabilities, spanning
multiple length intervals (4k, 8k, 32k, 128k, 200k, 1000k, and beyond) and
different depth ranges, allowing the strategic insertion of critical data
points in different text depth zones to rigorously test the retrieval and
reasoning capabilities of models in diverse contexts. We use the NeedleBench
framework to assess how well the leading open-source models can identify key
information relevant to the question and apply that information to reasoning in
bilingual long texts. Furthermore, we propose the Ancestral Trace Challenge
(ATC) to mimic the complexity of logical reasoning challenges that are likely
to be present in real-world long-context tasks, providing a simple method for
evaluating LLMs in dealing with complex long-context situations. Our results
suggest that current LLMs have significant room for improvement in practical
long-context applications, as they struggle with the complexity of logical
reasoning challenges that are likely to be present in real-world long-context
tasks. All codes and resources are available at OpenCompass:
https://github.com/open-compass/opencompass.

摘要：<paragraph>在評估大型語言模型 (LLM) 的長語境能力時，從原始長篇文件中辨識與使用者查詢相關的內容是任何 LLM 根據長文回答問題的必要先決條件。我們提出 NeedleBench，一個由一系列難度逐漸增加的任務組成的架構，用於評估雙語長語境能力，涵蓋多個長度區間（4k、8k、32k、128k、200k、1000k，以及更多）和不同的深度範圍，允許在不同的文字深度區域策略性地插入關鍵資料點，以嚴格測試模型在不同語境中的檢索和推理能力。我們使用 NeedleBench 架構來評估領先的開源模型在辨識與問題相關的關鍵資訊，以及將該資訊應用於雙語長文中推理的能力。此外，我們提出祖先追蹤挑戰 (ATC)，模擬在現實世界長語境任務中可能存在的邏輯推理挑戰的複雜性，提供一個簡單的方法來評估 LLM 在處理複雜長語境情況時的表現。我們的結果表明，目前的 LLM 在實際長語境應用中仍有很大的改進空間，因為它們難以應付現實世界長語境任務中可能存在的邏輯推理挑戰的複雜性。所有程式碼和資源都可以在 OpenCompass 取得：https://github.com/open-compass/opencompass。</paragraph>

##### **Motion-Oriented Compositional Neural Radiance Fields for Monocular Dynamic Human Modeling**
2407.11962v1 by Jaehyeok Kim, Dongyoon Wee, Dan Xu

This paper introduces Motion-oriented Compositional Neural Radiance Fields
(MoCo-NeRF), a framework designed to perform free-viewpoint rendering of
monocular human videos via novel non-rigid motion modeling approach. In the
context of dynamic clothed humans, complex cloth dynamics generate non-rigid
motions that are intrinsically distinct from skeletal articulations and
critically important for the rendering quality. The conventional approach
models non-rigid motions as spatial (3D) deviations in addition to skeletal
transformations. However, it is either time-consuming or challenging to achieve
optimal quality due to its high learning complexity without a direct
supervision. To target this problem, we propose a novel approach of modeling
non-rigid motions as radiance residual fields to benefit from more direct color
supervision in the rendering and utilize the rigid radiance fields as a prior
to reduce the complexity of the learning process. Our approach utilizes a
single multiresolution hash encoding (MHE) to concurrently learn the canonical
T-pose representation from rigid skeletal motions and the radiance residual
field for non-rigid motions. Additionally, to further improve both training
efficiency and usability, we extend MoCo-NeRF to support simultaneous training
of multiple subjects within a single framework, thanks to our effective design
for modeling non-rigid motions. This scalability is achieved through the
integration of a global MHE and learnable identity codes in addition to
multiple local MHEs. We present extensive results on ZJU-MoCap and MonoCap,
clearly demonstrating state-of-the-art performance in both single- and
multi-subject settings. The code and model will be made publicly available at
the project page: https://stevejaehyeok.github.io/publications/moco-nerf.

摘要：<paragraph>本文介绍了面向运动的合成神经辐射场 (MoCo-NeRF)，这是一个旨在通过新颖的非刚性运动建模方法执行单眼人类视频的自由视点渲染的框架。在动态着装的人类的背景下，复杂的布料动态会产生非刚性运动，这些运动本质上不同于骨骼关节，并且对渲染质量至关重要。传统方法将非刚性运动建模为空间 (3D) 偏差以及骨骼变换。然而，由于其学习复杂度高且没有直接监督，因此要达到最佳质量既耗时又具有挑战性。为了解决这个问题，我们提出了一种新颖的方法，将非刚性运动建模为辐射残差场，以受益于渲染中更直接的颜色监督，并将刚性辐射场用作先验来降低学习过程的复杂性。我们的方法利用单一的多分辨率哈希编码 (MHE) 来同时从刚性骨骼运动中学习规范的 T 姿势表示，以及用于非刚性运动的辐射残差场。此外，为了进一步提高训练效率和可用性，我们扩展了 MoCo-NeRF 以支持在单个框架内同时训练多个主体，这要归功于我们用于建模非刚性运动的有效设计。除了多个局部 MHE 之外，这种可扩展性是通过集成全局 MHE 和可学习的身份代码实现的。我们在 ZJU-MoCap 和 MonoCap 上展示了广泛的结果，清楚地展示了在单主体和多主体设置中都达到最先进的性能。代码和模型将在项目页面公开：https://stevejaehyeok.github.io/publications/moco-nerf。</paragraph>

