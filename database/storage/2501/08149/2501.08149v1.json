{"2501.08149": {"publish_time": "2025-01-14", "title": "Multiple-Input Variational Auto-Encoder for Anomaly Detection in Heterogeneous Data", "paper_summary": "Anomaly detection (AD) plays a pivotal role in AI applications, e.g., in\nclassification, and intrusion/threat detection in cybersecurity. However, most\nexisting methods face challenges of heterogeneity amongst feature subsets posed\nby non-independent and identically distributed (non-IID) data. We propose a\nnovel neural network model called Multiple-Input Auto-Encoder for AD (MIAEAD)\nto address this. MIAEAD assigns an anomaly score to each feature subset of a\ndata sample to indicate its likelihood of being an anomaly. This is done by\nusing the reconstruction error of its sub-encoder as the anomaly score. All\nsub-encoders are then simultaneously trained using unsupervised learning to\ndetermine the anomaly scores of feature subsets. The final AUC of MIAEAD is\ncalculated for each sub-dataset, and the maximum AUC obtained among the\nsub-datasets is selected. To leverage the modelling of the distribution of\nnormal data to identify anomalies of the generative models, we develop a novel\nneural network architecture/model called Multiple-Input Variational\nAuto-Encoder (MIVAE). MIVAE can process feature subsets through its\nsub-encoders before learning distribution of normal data in the latent space.\nThis allows MIVAE to identify anomalies that deviate from the learned\ndistribution. We theoretically prove that the difference in the average anomaly\nscore between normal samples and anomalies obtained by the proposed MIVAE is\ngreater than that of the Variational Auto-Encoder (VAEAD), resulting in a\nhigher AUC for MIVAE. Extensive experiments on eight real-world anomaly\ndatasets demonstrate the superior performance of MIAEAD and MIVAE over\nconventional methods and the state-of-the-art unsupervised models, by up to 6%\nin terms of AUC score. Alternatively, MIAEAD and MIVAE have a high AUC when\napplied to feature subsets with low heterogeneity based on the coefficient of\nvariation (CV) score.", "paper_summary_zh": "\u7570\u5e38\u5075\u6e2c (AD) \u5728 AI \u61c9\u7528\u4e2d\u626e\u6f14\u8457\u95dc\u9375\u89d2\u8272\uff0c\u4f8b\u5982\u5728\u5206\u985e\u3001\u4ee5\u53ca\u7db2\u8def\u5b89\u5168\u4e2d\u7684\u5165\u4fb5/\u5a01\u8105\u5075\u6e2c\u3002\u7136\u800c\uff0c\u73fe\u6709\u7684\u65b9\u6cd5\u5927\u591a\u9762\u81e8\u7531\u975e\u7368\u7acb\u540c\u5206\u4f48 (non-IID) \u8cc7\u6599\u6240\u9020\u6210\u7684\u7279\u5fb5\u5b50\u96c6\u9593\u7684\u7570\u8cea\u6027\u6311\u6230\u3002\u6211\u5011\u63d0\u51fa\u4e00\u500b\u540d\u70ba\u591a\u8f38\u5165\u81ea\u52d5\u7de8\u78bc\u5668\u7570\u5e38\u5075\u6e2c (MIAEAD) \u7684\u65b0\u7a4e\u795e\u7d93\u7db2\u8def\u6a21\u578b\u4f86\u89e3\u6c7a\u9019\u500b\u554f\u984c\u3002MIAEAD \u6703\u70ba\u8cc7\u6599\u6a23\u672c\u7684\u6bcf\u500b\u7279\u5fb5\u5b50\u96c6\u5206\u914d\u4e00\u500b\u7570\u5e38\u5206\u6578\uff0c\u4ee5\u8868\u793a\u5176\u6210\u70ba\u7570\u5e38\u503c\u7684\u53ef\u80fd\u6027\u3002\u9019\u662f\u900f\u904e\u4f7f\u7528\u5176\u5b50\u7de8\u78bc\u5668\u7684\u91cd\u5efa\u8aa4\u5dee\u4f5c\u70ba\u7570\u5e38\u5206\u6578\u4f86\u5b8c\u6210\u7684\u3002\u7136\u5f8c\u6240\u6709\u5b50\u7de8\u78bc\u5668\u6703\u540c\u6642\u4f7f\u7528\u975e\u76e3\u7763\u5f0f\u5b78\u7fd2\u9032\u884c\u8a13\u7df4\uff0c\u4ee5\u78ba\u5b9a\u7279\u5fb5\u5b50\u96c6\u7684\u7570\u5e38\u5206\u6578\u3002MIAEAD \u7684\u6700\u7d42 AUC \u6703\u91dd\u5c0d\u6bcf\u500b\u5b50\u8cc7\u6599\u96c6\u8a08\u7b97\uff0c\u4e26\u9078\u53d6\u5728\u5b50\u8cc7\u6599\u96c6\u4e2d\u7372\u5f97\u7684\u6700\u5927 AUC\u3002\u70ba\u4e86\u5229\u7528\u751f\u6210\u6a21\u578b\u7684\u5e38\u614b\u8cc7\u6599\u5206\u4f48\u5efa\u6a21\u4f86\u8b58\u5225\u7570\u5e38\u503c\uff0c\u6211\u5011\u958b\u767c\u4e86\u4e00\u500b\u540d\u70ba\u591a\u8f38\u5165\u8b8a\u7570\u81ea\u52d5\u7de8\u78bc\u5668 (MIVAE) \u7684\u65b0\u7a4e\u795e\u7d93\u7db2\u8def\u67b6\u69cb/\u6a21\u578b\u3002MIVAE \u53ef\u4ee5\u900f\u904e\u5176\u5b50\u7de8\u78bc\u5668\u8655\u7406\u7279\u5fb5\u5b50\u96c6\uff0c\u7136\u5f8c\u5728\u6f5b\u5728\u7a7a\u9593\u4e2d\u5b78\u7fd2\u5e38\u614b\u8cc7\u6599\u7684\u5206\u4f48\u3002\u9019\u5141\u8a31 MIVAE \u8b58\u5225\u51fa\u8207\u6240\u5b78\u7fd2\u5206\u4f48\u4e0d\u540c\u7684\u7570\u5e38\u503c\u3002\u6211\u5011\u5728\u7406\u8ad6\u4e0a\u8b49\u660e\uff0cMIVAE \u6240\u7372\u5f97\u7684\u5e38\u614b\u6a23\u672c\u8207\u7570\u5e38\u503c\u4e4b\u9593\u7684\u5e73\u5747\u7570\u5e38\u5206\u6578\u5dee\u7570\u5927\u65bc\u8b8a\u7570\u81ea\u52d5\u7de8\u78bc\u5668 (VAEAD)\uff0c\u5c0e\u81f4 MIVAE \u5177\u6709\u66f4\u9ad8\u7684 AUC\u3002\u5728\u516b\u500b\u771f\u5be6\u4e16\u754c\u7684\u7570\u5e38\u8cc7\u6599\u96c6\u4e0a\u9032\u884c\u7684\u5ee3\u6cdb\u5be6\u9a57\u8b49\u660e\u4e86 MIAEAD \u548c MIVAE \u512a\u65bc\u50b3\u7d71\u65b9\u6cd5\u548c\u6700\u5148\u9032\u7684\u975e\u76e3\u7763\u5f0f\u6a21\u578b\uff0cAUC \u5206\u6578\u63d0\u9ad8\u4e86 6%\u3002\u6216\u8005\uff0cMIAEAD \u548c MIVAE \u5728\u61c9\u7528\u65bc\u6839\u64da\u8b8a\u7570\u4fc2\u6578 (CV) \u5206\u6578\u5177\u6709\u4f4e\u7570\u8cea\u6027\u7684\u7279\u5fb5\u5b50\u96c6\u6642\uff0c\u5177\u6709\u5f88\u9ad8\u7684 AUC\u3002", "author": "Phai Vu Dinh et.al.", "authors": "Phai Vu Dinh, Diep N. Nguyen, Dinh Thai Hoang, Quang Uy Nguyen, Eryk Dutkiewicz", "id": "2501.08149v1", "paper_url": "http://arxiv.org/abs/2501.08149v1", "repo": "null"}}