{"2408.06598": {"publish_time": "2024-08-13", "title": "A Perspective on Large Language Models, Intelligent Machines, and Knowledge Acquisition", "paper_summary": "Large Language Models (LLMs) are known for their remarkable ability to\ngenerate synthesized 'knowledge', such as text documents, music, images, etc.\nHowever, there is a huge gap between LLM's and human capabilities for\nunderstanding abstract concepts and reasoning. We discuss these issues in a\nlarger philosophical context of human knowledge acquisition and the Turing\ntest. In addition, we illustrate the limitations of LLMs by analyzing GPT-4\nresponses to questions ranging from science and math to common sense reasoning.\nThese examples show that GPT-4 can often imitate human reasoning, even though\nit lacks understanding. However, LLM responses are synthesized from a large LLM\nmodel trained on all available data. In contrast, human understanding is based\non a small number of abstract concepts. Based on this distinction, we discuss\nthe impact of LLMs on acquisition of human knowledge and education.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u4ee5\u5176\u751f\u6210\u7d9c\u5408\u300c\u77e5\u8b58\u300d\u7684\u975e\u51e1\u80fd\u529b\u800c\u805e\u540d\uff0c\u4f8b\u5982\u6587\u5b57\u6587\u4ef6\u3001\u97f3\u6a02\u3001\u5716\u50cf\u7b49\u3002\u7136\u800c\uff0c\u5728\u7406\u89e3\u62bd\u8c61\u6982\u5ff5\u548c\u63a8\u7406\u65b9\u9762\uff0cLLM \u8207\u4eba\u985e\u7684\u80fd\u529b\u4e4b\u9593\u5b58\u5728\u8457\u5de8\u5927\u7684\u5dee\u8ddd\u3002\u6211\u5011\u5728\u4eba\u985e\u77e5\u8b58\u7372\u53d6\u548c\u5716\u9748\u6e2c\u8a66\u7684\u66f4\u5927\u54f2\u5b78\u80cc\u666f\u4e0b\u63a2\u8a0e\u9019\u4e9b\u554f\u984c\u3002\u6b64\u5916\uff0c\u6211\u5011\u900f\u904e\u5206\u6790 GPT-4 \u5c0d\u5f9e\u79d1\u5b78\u548c\u6578\u5b78\u5230\u5e38\u8b58\u63a8\u7406\u7b49\u554f\u984c\u7684\u56de\u61c9\u4f86\u8aaa\u660e LLM \u7684\u5c40\u9650\u6027\u3002\u9019\u4e9b\u7bc4\u4f8b\u986f\u793a\uff0c\u5373\u4f7f GPT-4 \u7f3a\u4e4f\u7406\u89e3\u529b\uff0c\u4f46\u5b83\u7d93\u5e38\u53ef\u4ee5\u6a21\u4eff\u4eba\u985e\u7684\u63a8\u7406\u3002\u7136\u800c\uff0cLLM \u7684\u56de\u61c9\u662f\u7531\u4e00\u500b\u8a13\u7df4\u65bc\u6240\u6709\u53ef\u7528\u8cc7\u6599\u4e0a\u7684\u5927\u578b LLM \u6a21\u578b\u7d9c\u5408\u800c\u6210\u7684\u3002\u76f8\u53cd\u5730\uff0c\u4eba\u985e\u7684\u7406\u89e3\u662f\u57fa\u65bc\u5c11\u6578\u62bd\u8c61\u6982\u5ff5\u3002\u6839\u64da\u9019\u500b\u5340\u5225\uff0c\u6211\u5011\u63a2\u8a0e LLM \u5c0d\u4eba\u985e\u77e5\u8b58\u548c\u6559\u80b2\u7372\u53d6\u7684\u5f71\u97ff\u3002", "author": "Vladimir Cherkassky et.al.", "authors": "Vladimir Cherkassky, Eng Hock Lee", "id": "2408.06598v1", "paper_url": "http://arxiv.org/abs/2408.06598v1", "repo": "null"}}