{"2408.12772": {"publish_time": "2024-08-23", "title": "Symmetric masking strategy enhances the performance of Masked Image Modeling", "paper_summary": "Masked Image Modeling (MIM) is a technique in self-supervised learning that\nfocuses on acquiring detailed visual representations from unlabeled images by\nestimating the missing pixels in randomly masked sections. It has proven to be\na powerful tool for the preliminary training of Vision Transformers (ViTs),\nyielding impressive results across various tasks. Nevertheless, most MIM\nmethods heavily depend on the random masking strategy to formulate the pretext\ntask. This strategy necessitates numerous trials to ascertain the optimal\ndropping ratio, which can be resource-intensive, requiring the model to be\npre-trained for anywhere between 800 to 1600 epochs. Furthermore, this approach\nmay not be suitable for all datasets. In this work, we propose a new masking\nstrategy that effectively helps the model capture global and local features.\nBased on this masking strategy, SymMIM, our proposed training pipeline for MIM\nis introduced. SymMIM achieves a new SOTA accuracy of 85.9\\% on ImageNet using\nViT-Large and surpasses previous SOTA across downstream tasks such as image\nclassification, semantic segmentation, object detection, instance segmentation\ntasks, and so on.", "paper_summary_zh": "\u906e\u853d\u5f71\u50cf\u5efa\u6a21 (Masked Image Modeling, MIM) \u662f\u4e00\u7a2e\u81ea\u76e3\u7763\u5b78\u7fd2\u6280\u8853\uff0c\u5176\u91cd\u9ede\u5728\u65bc\u900f\u904e\u4f30\u8a08\u96a8\u6a5f\u906e\u853d\u5340\u6bb5\u4e2d\u907a\u5931\u7684\u756b\u7d20\uff0c\u5f9e\u672a\u6a19\u7c64\u5f71\u50cf\u4e2d\u7372\u53d6\u8a73\u7d30\u7684\u8996\u89ba\u8868\u5fb5\u3002\u5b83\u5df2\u88ab\u8b49\u660e\u662f Vision Transformers (ViTs) \u521d\u6b65\u8a13\u7df4\u7684\u5f37\u5927\u5de5\u5177\uff0c\u5728\u5404\u7a2e\u4efb\u52d9\u4e2d\u7522\u751f\u4ee4\u4eba\u5370\u8c61\u6df1\u523b\u7684\u7d50\u679c\u3002\u5118\u7ba1\u5982\u6b64\uff0c\u5927\u591a\u6578 MIM \u65b9\u6cd5\u90fd\u9ad8\u5ea6\u4f9d\u8cf4\u96a8\u6a5f\u906e\u853d\u7b56\u7565\u4f86\u5236\u5b9a\u85c9\u53e3\u4efb\u52d9\u3002\u6b64\u7b56\u7565\u9700\u8981\u9032\u884c\u591a\u6b21\u8a66\u9a57\u624d\u80fd\u78ba\u5b9a\u6700\u4f73\u4e1f\u68c4\u7387\uff0c\u9019\u53ef\u80fd\u6703\u6d88\u8017\u5927\u91cf\u8cc7\u6e90\uff0c\u9700\u8981\u5c0d\u6a21\u578b\u9032\u884c 800 \u5230 1600 \u500b\u4e16\u4ee3\u7684\u9810\u8a13\u7df4\u3002\u6b64\u5916\uff0c\u6b64\u65b9\u6cd5\u53ef\u80fd\u4e26\u4e0d\u9069\u7528\u65bc\u6240\u6709\u8cc7\u6599\u96c6\u3002\u5728\u9019\u9805\u5de5\u4f5c\u4e2d\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u4e00\u7a2e\u65b0\u7684\u906e\u853d\u7b56\u7565\uff0c\u53ef\u6709\u6548\u5e6b\u52a9\u6a21\u578b\u64f7\u53d6\u5168\u5c40\u548c\u5c40\u90e8\u7279\u5fb5\u3002\u57fa\u65bc\u6b64\u906e\u853d\u7b56\u7565\uff0c\u6211\u5011\u5f15\u5165\u4e86\u7528\u65bc MIM \u7684\u5efa\u8b70\u8a13\u7df4\u7ba1\u7dda SymMIM\u3002SymMIM \u4f7f\u7528 ViT-Large \u5728 ImageNet \u4e0a\u9054\u5230\u4e86 85.9% \u7684\u65b0 SOTA \u7cbe\u5ea6\uff0c\u4e26\u5728\u5f71\u50cf\u5206\u985e\u3001\u8a9e\u610f\u5206\u5272\u3001\u7269\u4ef6\u5075\u6e2c\u3001\u5be6\u4f8b\u5206\u5272\u4efb\u52d9\u7b49\u4e0b\u6e38\u4efb\u52d9\u4e2d\u8d85\u8d8a\u4e86\u5148\u524d\u7684 SOTA\u3002", "author": "Khanh-Binh Nguyen et.al.", "authors": "Khanh-Binh Nguyen, Chae Jung Park", "id": "2408.12772v1", "paper_url": "http://arxiv.org/abs/2408.12772v1", "repo": "null"}}