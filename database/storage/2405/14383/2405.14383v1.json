{"2405.14383": {"publish_time": "2024-05-23", "title": "Perception of Knowledge Boundary for Large Language Models through Semi-open-ended Question Answering", "paper_summary": "Large Language Models (LLMs) are widely used for knowledge-seeking yet suffer\nfrom hallucinations. The knowledge boundary (KB) of an LLM limits its factual\nunderstanding, beyond which it may begin to hallucinate. Investigating the\nperception of LLMs' KB is crucial for detecting hallucinations and LLMs'\nreliable generation. Current studies perceive LLMs' KB on questions with a\nconcrete answer (close-ended questions) while paying limited attention to\nsemi-open-ended questions (SoeQ) that correspond to many potential answers.\nSome researchers achieve it by judging whether the question is answerable or\nnot. However, this paradigm is unsuitable for SoeQ, which are usually partially\nanswerable, containing both answerable and ambiguous (unanswerable) answers.\nAmbiguous answers are essential for knowledge-seeking, but they may go beyond\nthe KB of LLMs. In this paper, we perceive the LLMs' KB with SoeQ by\ndiscovering more ambiguous answers. First, we apply an LLM-based approach to\nconstruct SoeQ and obtain answers from a target LLM. Unfortunately, the output\nprobabilities of mainstream black-box LLMs are inaccessible to sample for\nlow-probability ambiguous answers. Therefore, we apply an open-sourced\nauxiliary model to explore ambiguous answers for the target LLM. We calculate\nthe nearest semantic representation for existing answers to estimate their\nprobabilities, with which we reduce the generation probability of\nhigh-probability answers to achieve a more effective generation. Finally, we\ncompare the results from the RAG-based evaluation and LLM self-evaluation to\ncategorize four types of ambiguous answers that are beyond the KB of the target\nLLM. Following our method, we construct a dataset to perceive the KB for GPT-4.\nWe find that GPT-4 performs poorly on SoeQ and is often unaware of its KB.\nBesides, our auxiliary model, LLaMA-2-13B, is effective in discovering more\nambiguous answers.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u5ee3\u6cdb\u7528\u65bc\u77e5\u8b58\u5c0b\u6c42\uff0c\u4f46\u537b\u6703\u51fa\u73fe\u5e7b\u89ba\u3002LLM \u7684\u77e5\u8b58\u908a\u754c (KB) \u9650\u5236\u4e86\u5176\u4e8b\u5be6\u7406\u89e3\uff0c\u8d85\u904e\u9019\u500b\u908a\u754c\u5f8c\uff0c\u5b83\u53ef\u80fd\u6703\u958b\u59cb\u7522\u751f\u5e7b\u89ba\u3002\u8abf\u67e5 LLM \u7684 KB \u611f\u77e5\u5c0d\u65bc\u6aa2\u6e2c\u5e7b\u89ba\u548c LLM \u7684\u53ef\u9760\u751f\u6210\u81f3\u95dc\u91cd\u8981\u3002\u76ee\u524d\u7684\u7814\u7a76\u6240\u611f\u77e5 LLM \u7684 KB\uff0c\u91dd\u5c0d\u5177\u6709\u5177\u9ad4\u7b54\u6848\u7684\u554f\u984c\uff08\u5c01\u9589\u5f0f\u554f\u984c\uff09\uff0c\u540c\u6642\u53ea\u95dc\u6ce8\u5c11\u91cf\u7684\u534a\u958b\u653e\u5f0f\u554f\u984c (SoeQ)\uff0c\u9019\u4e9b\u554f\u984c\u5c0d\u61c9\u65bc\u8a31\u591a\u6f5b\u5728\u7b54\u6848\u3002\u4e00\u4e9b\u7814\u7a76\u4eba\u54e1\u901a\u904e\u5224\u65b7\u554f\u984c\u662f\u5426\u53ef\u56de\u7b54\u4f86\u5be6\u73fe\u9019\u4e00\u9ede\u3002\u7136\u800c\uff0c\u9019\u7a2e\u7bc4\u4f8b\u4e0d\u9069\u5408\u65bc SoeQ\uff0cSoeQ \u901a\u5e38\u662f\u90e8\u5206\u53ef\u56de\u7b54\u7684\uff0c\u65e2\u5305\u542b\u53ef\u56de\u7b54\u7684\u7b54\u6848\uff0c\u4e5f\u5305\u542b\u6a21\u7a1c\u5169\u53ef\uff08\u4e0d\u53ef\u56de\u7b54\uff09\u7684\u7b54\u6848\u3002\u6a21\u7a1c\u5169\u53ef\u7684\u7b54\u6848\u5c0d\u65bc\u5c0b\u6c42\u77e5\u8b58\u81f3\u95dc\u91cd\u8981\uff0c\u4f46\u5b83\u5011\u53ef\u80fd\u6703\u8d85\u51fa LLM \u7684 KB\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u901a\u904e\u767c\u73fe\u66f4\u591a\u6a21\u7a1c\u5169\u53ef\u7684\u7b54\u6848\uff0c\u4ee5 SoeQ \u611f\u77e5 LLM \u7684 KB\u3002\u9996\u5148\uff0c\u6211\u5011\u61c9\u7528\u57fa\u65bc LLM \u7684\u65b9\u6cd5\u4f86\u69cb\u5efa SoeQ\uff0c\u4e26\u5f9e\u76ee\u6a19 LLM \u7372\u53d6\u7b54\u6848\u3002\u4e0d\u5e78\u7684\u662f\uff0c\u4e3b\u6d41\u9ed1\u76d2 LLM \u7684\u8f38\u51fa\u6a5f\u7387\u7121\u6cd5\u7528\u65bc\u5c0d\u4f4e\u6a5f\u7387\u6a21\u7a1c\u5169\u53ef\u7684\u7b54\u6848\u9032\u884c\u53d6\u6a23\u3002\u56e0\u6b64\uff0c\u6211\u5011\u61c9\u7528\u4e86\u4e00\u500b\u958b\u6e90\u7684\u8f14\u52a9\u6a21\u578b\u4f86\u63a2\u7d22\u76ee\u6a19 LLM \u7684\u6a21\u7a1c\u5169\u53ef\u7b54\u6848\u3002\u6211\u5011\u8a08\u7b97\u73fe\u6709\u7b54\u6848\u6700\u63a5\u8fd1\u7684\u8a9e\u7fa9\u8868\u793a\uff0c\u4ee5\u4f30\u8a08\u5b83\u5011\u7684\u6a5f\u7387\uff0c\u7136\u5f8c\u6211\u5011\u964d\u4f4e\u9ad8\u6a5f\u7387\u7b54\u6848\u7684\u751f\u6210\u6a5f\u7387\uff0c\u4ee5\u5be6\u73fe\u66f4\u6709\u6548\u7684\u751f\u6210\u3002\u6700\u5f8c\uff0c\u6211\u5011\u6bd4\u8f03\u57fa\u65bc RAG \u7684\u8a55\u4f30\u548c LLM \u81ea\u6211\u8a55\u4f30\u7684\u7d50\u679c\uff0c\u5c07\u76ee\u6a19 LLM \u7684 KB \u7bc4\u570d\u5916\u7684\u56db\u7a2e\u985e\u578b\u7684\u6a21\u7a1c\u5169\u53ef\u7b54\u6848\u5206\u985e\u3002\u6309\u7167\u6211\u5011\u7684\u65b9\u6cd5\uff0c\u6211\u5011\u69cb\u5efa\u4e86\u4e00\u500b\u6578\u64da\u96c6\u4f86\u611f\u77e5 GPT-4 \u7684 KB\u3002\u6211\u5011\u767c\u73fe GPT-4 \u5728 SoeQ \u4e0a\u8868\u73fe\u4e0d\u4f73\uff0c\u800c\u4e14\u5e38\u5e38\u4e0d\u77e5\u9053\u81ea\u5df1\u7684 KB\u3002\u6b64\u5916\uff0c\u6211\u5011\u7684\u8f14\u52a9\u6a21\u578b LLaMA-2-13B \u5728\u767c\u73fe\u66f4\u591a\u6a21\u7a1c\u5169\u53ef\u7684\u7b54\u6848\u65b9\u9762\u5f88\u6709\u6548\u3002", "author": "Zhihua Wen et.al.", "authors": "Zhihua Wen, Zhiliang Tian, Zexin Jian, Zhen Huang, Pei Ke, Yifu Gao, Minlie Huang, Dongsheng Li", "id": "2405.14383v1", "paper_url": "http://arxiv.org/abs/2405.14383v1", "repo": "null"}}