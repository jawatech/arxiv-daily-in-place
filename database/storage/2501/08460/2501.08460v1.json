{"2501.08460": {"publish_time": "2025-01-14", "title": "Towards Zero-Shot & Explainable Video Description by Reasoning over Graphs of Events in Space and Time", "paper_summary": "In the current era of Machine Learning, Transformers have become the de facto\napproach across a variety of domains, such as computer vision and natural\nlanguage processing. Transformer-based solutions are the backbone of current\nstate-of-the-art methods for language generation, image and video\nclassification, segmentation, action and object recognition, among many others.\nInterestingly enough, while these state-of-the-art methods produce impressive\nresults in their respective domains, the problem of understanding the\nrelationship between vision and language is still beyond our reach. In this\nwork, we propose a common ground between vision and language based on events in\nspace and time in an explainable and programmatic way, to connect\nlearning-based vision and language state of the art models and provide a\nsolution to the long standing problem of describing videos in natural language.\nWe validate that our algorithmic approach is able to generate coherent, rich\nand relevant textual descriptions on videos collected from a variety of\ndatasets, using both standard metrics (e.g. Bleu, ROUGE) and the modern\nLLM-as-a-Jury approach.", "paper_summary_zh": "\u5728\u6a5f\u5668\u5b78\u7fd2\u7684\u7576\u4ee3\uff0cTransformer \u5df2\u6210\u70ba\u5404\u7a2e\u9818\u57df\u7684\u4e8b\u5be6\u6a19\u6e96\u65b9\u6cd5\uff0c\u4f8b\u5982\u96fb\u8166\u8996\u89ba\u548c\u81ea\u7136\u8a9e\u8a00\u8655\u7406\u3002\u57fa\u65bc Transformer \u7684\u89e3\u6c7a\u65b9\u6848\u662f\u7576\u524d\u8a9e\u8a00\u751f\u6210\u3001\u5f71\u50cf\u548c\u5f71\u7247\u5206\u985e\u3001\u5206\u5272\u3001\u52d5\u4f5c\u548c\u7269\u4ef6\u8fa8\u8b58\u7b49\u6700\u65b0\u65b9\u6cd5\u7684\u9aa8\u5e79\u3002\u6709\u8da3\u7684\u662f\uff0c\u96d6\u7136\u9019\u4e9b\u6700\u65b0\u65b9\u6cd5\u5728\u5176\u5404\u81ea\u7684\u9818\u57df\u4e2d\u7522\u751f\u4ee4\u4eba\u5370\u8c61\u6df1\u523b\u7684\u7d50\u679c\uff0c\u4f46\u7406\u89e3\u8996\u89ba\u548c\u8a9e\u8a00\u4e4b\u9593\u95dc\u4fc2\u7684\u554f\u984c\u4ecd\u7136\u8d85\u51fa\u4e86\u6211\u5011\u7684\u7406\u89e3\u7bc4\u570d\u3002\u5728\u9019\u9805\u5de5\u4f5c\u4e2d\uff0c\u6211\u5011\u4ee5\u53ef\u89e3\u91cb\u4e14\u4ee5\u7a0b\u5f0f\u70ba\u57fa\u790e\u7684\u65b9\u5f0f\uff0c\u5728\u6642\u7a7a\u4e2d\u7684\u4e8b\u4ef6\u4e4b\u9593\u63d0\u51fa\u4e86\u8996\u89ba\u548c\u8a9e\u8a00\u7684\u5171\u540c\u57fa\u790e\uff0c\u4ee5\u9023\u63a5\u57fa\u65bc\u5b78\u7fd2\u7684\u8996\u89ba\u548c\u8a9e\u8a00\u6700\u65b0\u6a21\u578b\uff0c\u4e26\u63d0\u4f9b\u63cf\u8ff0\u5f71\u7247\u7684\u81ea\u7136\u8a9e\u8a00\u9577\u671f\u554f\u984c\u7684\u89e3\u6c7a\u65b9\u6848\u3002\u6211\u5011\u9a57\u8b49\u4e86\u6211\u5011\u7684\u6f14\u7b97\u6cd5\u65b9\u6cd5\u80fd\u5920\u5728\u5f9e\u5404\u7a2e\u8cc7\u6599\u96c6\u6536\u96c6\u7684\u5f71\u7247\u4e2d\u7522\u751f\u9023\u8cab\u3001\u8c50\u5bcc\u4e14\u76f8\u95dc\u7684\u6587\u5b57\u63cf\u8ff0\uff0c\u540c\u6642\u4f7f\u7528\u6a19\u6e96\u6307\u6a19\uff08\u4f8b\u5982 Bleu\u3001ROUGE\uff09\u548c\u73fe\u4ee3 LLM \u4f5c\u70ba\u8a55\u5be9\u65b9\u6cd5\u3002", "author": "Mihai Masala et.al.", "authors": "Mihai Masala, Marius Leordeanu", "id": "2501.08460v1", "paper_url": "http://arxiv.org/abs/2501.08460v1", "repo": "null"}}