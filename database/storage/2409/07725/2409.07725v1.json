{"2409.07725": {"publish_time": "2024-09-12", "title": "GRE^2-MDCL: Graph Representation Embedding Enhanced via Multidimensional Contrastive Learning", "paper_summary": "Graph representation learning has emerged as a powerful tool for preserving\ngraph topology when mapping nodes to vector representations, enabling various\ndownstream tasks such as node classification and community detection. However,\nmost current graph neural network models face the challenge of requiring\nextensive labeled data, which limits their practical applicability in\nreal-world scenarios where labeled data is scarce. To address this challenge,\nresearchers have explored Graph Contrastive Learning (GCL), which leverages\nenhanced graph data and contrastive learning techniques. While promising,\nexisting GCL methods often struggle with effectively capturing both local and\nglobal graph structures, and balancing the trade-off between nodelevel and\ngraph-level representations. In this work, we propose Graph Representation\nEmbedding Enhanced via Multidimensional Contrastive Learning (GRE2-MDCL). Our\nmodel introduces a novel triple network architecture with a multi-head\nattention GNN as the core. GRE2-MDCL first globally and locally augments the\ninput graph using SVD and LAGNN techniques. It then constructs a\nmultidimensional contrastive loss, incorporating cross-network, cross-view, and\nneighbor contrast, to optimize the model. Extensive experiments on benchmark\ndatasets Cora, Citeseer, and PubMed demonstrate that GRE2-MDCL achieves\nstate-of-the-art performance, with average accuracies of 82.5%, 72.5%, and\n81.6% respectively. Visualizations further show tighter intra-cluster\naggregation and clearer inter-cluster boundaries, highlighting the\neffectiveness of our framework in improving upon baseline GCL models.", "paper_summary_zh": "\u5716\u5f62\u8868\u5fb5\u5b78\u7fd2\u5df2\u6210\u70ba\u4e00\u7a2e\u5f37\u5927\u7684\u5de5\u5177\uff0c\u7528\u65bc\u5728\u5c07\u7bc0\u9ede\u5c0d\u61c9\u5230\u5411\u91cf\u8868\u5fb5\u6642\u4fdd\u7559\u5716\u5f62\u62d3\u64b2\uff0c\u9032\u800c\u80fd\u9032\u884c\u5404\u7a2e\u4e0b\u6e38\u4efb\u52d9\uff0c\u4f8b\u5982\u7bc0\u9ede\u5206\u985e\u548c\u793e\u7fa4\u5075\u6e2c\u3002\u7136\u800c\uff0c\u76ee\u524d\u5927\u591a\u6578\u5716\u5f62\u795e\u7d93\u7db2\u8def\u6a21\u578b\u90fd\u9762\u81e8\u9700\u8981\u5927\u91cf\u6a19\u7c64\u8cc7\u6599\u7684\u6311\u6230\uff0c\u9019\u9650\u5236\u4e86\u5b83\u5011\u5728\u6a19\u7c64\u8cc7\u6599\u7a00\u5c11\u7684\u5be6\u969b\u5834\u666f\u4e2d\u7684\u5be6\u969b\u61c9\u7528\u6027\u3002\u70ba\u4e86\u61c9\u5c0d\u9019\u4e00\u6311\u6230\uff0c\u7814\u7a76\u4eba\u54e1\u63a2\u7d22\u4e86\u5716\u5f62\u5c0d\u6bd4\u5b78\u7fd2 (GCL)\uff0c\u5b83\u5229\u7528\u589e\u5f37\u7684\u5716\u5f62\u8cc7\u6599\u548c\u5c0d\u6bd4\u5b78\u7fd2\u6280\u8853\u3002\u96d6\u7136\u6709\u524d\u666f\uff0c\u4f46\u73fe\u6709\u7684 GCL \u65b9\u6cd5\u901a\u5e38\u96e3\u4ee5\u6709\u6548\u64f7\u53d6\u5c40\u90e8\u548c\u5168\u57df\u5716\u5f62\u7d50\u69cb\uff0c\u4e26\u5e73\u8861\u7bc0\u9ede\u7d1a\u548c\u5716\u5f62\u7d1a\u8868\u5fb5\u4e4b\u9593\u7684\u6b0a\u8861\u3002\u5728\u9019\u9805\u5de5\u4f5c\u4e2d\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u900f\u904e\u591a\u7dad\u5ea6\u5c0d\u6bd4\u5b78\u7fd2\u589e\u5f37\u7684\u5716\u5f62\u8868\u5fb5\u5d4c\u5165 (GRE2-MDCL)\u3002\u6211\u5011\u7684\u6a21\u578b\u5f15\u5165\u4e86\u4e00\u7a2e\u65b0\u7a4e\u7684\u4e09\u91cd\u7db2\u8def\u67b6\u69cb\uff0c\u4ee5\u591a\u982d\u6ce8\u610f\u529b GNN \u70ba\u6838\u5fc3\u3002GRE2-MDCL \u9996\u5148\u4f7f\u7528 SVD \u548c LAGNN \u6280\u8853\u5728\u5168\u57df\u548c\u5c40\u90e8\u589e\u5f37\u8f38\u5165\u5716\u5f62\u3002\u7136\u5f8c\uff0c\u5b83\u5efa\u69cb\u4e00\u500b\u591a\u7dad\u5ea6\u5c0d\u6bd4\u640d\u5931\uff0c\u7d50\u5408\u8de8\u7db2\u8def\u3001\u8de8\u8996\u5716\u548c\u9130\u8fd1\u5c0d\u6bd4\uff0c\u4ee5\u6700\u4f73\u5316\u6a21\u578b\u3002\u5728\u57fa\u6e96\u8cc7\u6599\u96c6 Cora\u3001Citeseer \u548c PubMed \u4e0a\u9032\u884c\u7684\u5ee3\u6cdb\u5be6\u9a57\u8b49\u660e\uff0cGRE2-MDCL \u9054\u5230\u4e86\u6700\u5148\u9032\u7684\u6548\u80fd\uff0c\u5e73\u5747\u6e96\u78ba\u7387\u5206\u5225\u70ba 82.5%\u300172.5% \u548c 81.6%\u3002\u53ef\u8996\u5316\u9032\u4e00\u6b65\u986f\u793a\u51fa\u66f4\u7dca\u5bc6\u7684\u7fa4\u96c6\u5167\u805a\u5408\u548c\u66f4\u6e05\u6670\u7684\u7fa4\u96c6\u9593\u754c\u7dda\uff0c\u7a81\u986f\u4e86\u6211\u5011\u7684\u67b6\u69cb\u5728\u6539\u5584\u57fa\u6e96 GCL \u6a21\u578b\u65b9\u9762\u7684\u6709\u6548\u6027\u3002", "author": "Kaizhe Fan et.al.", "authors": "Kaizhe Fan, Quanjun Li", "id": "2409.07725v1", "paper_url": "http://arxiv.org/abs/2409.07725v1", "repo": "null"}}