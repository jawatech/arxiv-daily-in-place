{"2503.10624": {"publish_time": "2025-03-13", "title": "ETCH: Generalizing Body Fitting to Clothed Humans via Equivariant Tightness", "paper_summary": "Fitting a body to a 3D clothed human point cloud is a common yet challenging\ntask. Traditional optimization-based approaches use multi-stage pipelines that\nare sensitive to pose initialization, while recent learning-based methods often\nstruggle with generalization across diverse poses and garment types. We propose\nEquivariant Tightness Fitting for Clothed Humans, or ETCH, a novel pipeline\nthat estimates cloth-to-body surface mapping through locally approximate SE(3)\nequivariance, encoding tightness as displacement vectors from the cloth surface\nto the underlying body. Following this mapping, pose-invariant body features\nregress sparse body markers, simplifying clothed human fitting into an\ninner-body marker fitting task. Extensive experiments on CAPE and 4D-Dress show\nthat ETCH significantly outperforms state-of-the-art methods -- both\ntightness-agnostic and tightness-aware -- in body fitting accuracy on loose\nclothing (16.7% ~ 69.5%) and shape accuracy (average 49.9%). Our equivariant\ntightness design can even reduce directional errors by (67.2% ~ 89.8%) in\none-shot (or out-of-distribution) settings. Qualitative results demonstrate\nstrong generalization of ETCH, regardless of challenging poses, unseen shapes,\nloose clothing, and non-rigid dynamics. We will release the code and models\nsoon for research purposes at https://boqian-li.github.io/ETCH/.", "paper_summary_zh": "<paragraph>\u5c07\u8eab\u9ad4\u64ec\u5408\u5230 3D \u7a7f\u8863\u4eba\u9ad4\u9ede\u96f2\u662f\u4e00\u500b\u5e38\u898b\u4f46\u5177\u6709\u6311\u6230\u6027\u7684\u4efb\u52d9\u3002\u50b3\u7d71\u7684\u57fa\u65bc\u512a\u5316\u7684\u65b9\u6cd5\u4f7f\u7528\u5c0d\u59ff\u52e2\u521d\u59cb\u5316\u654f\u611f\u7684\u591a\u968e\u6bb5\u6d41\u7a0b\uff0c\u800c\u6700\u8fd1\u57fa\u65bc\u5b78\u7fd2\u7684\u65b9\u6cd5\u901a\u5e38\u96e3\u4ee5\u6cdb\u5316\u5230\u4e0d\u540c\u7684\u59ff\u52e2\u548c\u670d\u88dd\u985e\u578b\u3002\u6211\u5011\u63d0\u51fa\u4e86\u7528\u65bc\u7a7f\u8863\u4eba\u9ad4\u7684\u7b49\u8b8a\u7dca\u5bc6\u5ea6\u64ec\u5408\uff0c\u6216\u7a31 ETCH\uff0c\u9019\u662f\u4e00\u7a2e\u65b0\u7a4e\u7684\u6d41\u7a0b\uff0c\u5b83\u901a\u904e\u5c40\u90e8\u8fd1\u4f3c SE(3) \u7b49\u8b8a\u6027\u4f86\u4f30\u8a08\u5e03\u6599\u5230\u8eab\u9ad4\u8868\u9762\u7684\u6620\u5c04\uff0c\u5c07\u7dca\u5bc6\u5ea6\u7de8\u78bc\u70ba\u5f9e\u5e03\u6599\u8868\u9762\u5230\u5e95\u5c64\u8eab\u9ad4\u7684\u4f4d\u79fb\u5411\u91cf\u3002\u9075\u5faa\u6b64\u6620\u5c04\uff0c\u59ff\u52e2\u4e0d\u8b8a\u7684\u8eab\u9ad4\u7279\u5fb5\u56de\u6b78\u7a00\u758f\u7684\u8eab\u9ad4\u6a19\u8a18\uff0c\u5c07\u7a7f\u8863\u4eba\u9ad4\u64ec\u5408\u7c21\u5316\u70ba\u9ad4\u5167\u6a19\u8a18\u64ec\u5408\u4efb\u52d9\u3002\u5728 CAPE \u548c 4D-Dress \u4e0a\u9032\u884c\u7684\u5927\u91cf\u5be6\u9a57\u8868\u660e\uff0cETCH \u5728\u5bec\u9b06\u670d\u88dd\u7684\u8eab\u9ad4\u64ec\u5408\u7cbe\u5ea6 (16.7% ~ 69.5%) \u548c\u5f62\u72c0\u7cbe\u5ea6\uff08\u5e73\u5747 49.9%\uff09\u65b9\u9762\u986f\u8457\u512a\u65bc\u6700\u5148\u9032\u7684\u65b9\u6cd5\u2014\u2014\u7121\u8ad6\u662f\u5426\u8003\u616e\u7dca\u5bc6\u5ea6\u3002\u6211\u5011\u7684\u7b49\u8b8a\u7dca\u5bc6\u5ea6\u8a2d\u8a08\u751a\u81f3\u53ef\u4ee5\u5728\u4e00\u6b21\u6027\uff08\u6216\u5206\u4f48\u5916\uff09\u8a2d\u7f6e\u4e2d\u6e1b\u5c11\u65b9\u5411\u8aa4\u5dee (67.2% ~ 89.8%)\u3002\u5b9a\u6027\u7d50\u679c\u8b49\u660e\u4e86 ETCH \u7684\u5f37\u6cdb\u5316\u6027\uff0c\u7121\u8ad6\u662f\u5177\u6709\u6311\u6230\u6027\u7684\u59ff\u52e2\u3001\u672a\u898b\u904e\u7684\u5f62\u72c0\u3001\u5bec\u9b06\u7684\u670d\u88dd\u9084\u662f\u975e\u525b\u6027\u52d5\u529b\u5b78\u3002\u6211\u5011\u5c07\u5f88\u5feb\u5728 https://boqian-li.github.io/ETCH/ \u4e0a\u767c\u5e03\u7a0b\u5f0f\u78bc\u548c\u6a21\u578b\uff0c\u4ee5\u4f9b\u7814\u7a76\u4e4b\u7528\u3002</paragraph>\n", "author": "Boqian Li et.al.", "authors": "Boqian Li, Haiwen Feng, Zeyu Cai, Michael J. Black, Yuliang Xiu", "id": "2503.10624v1", "paper_url": "http://arxiv.org/abs/2503.10624v1", "repo": "https://github.com/boqian-li/ETCH"}}