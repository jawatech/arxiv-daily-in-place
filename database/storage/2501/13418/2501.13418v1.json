{"2501.13418": {"publish_time": "2025-01-23", "title": "Rethinking the Sample Relations for Few-Shot Classification", "paper_summary": "Feature quality is paramount for classification performance, particularly in\nfew-shot scenarios. Contrastive learning, a widely adopted technique for\nenhancing feature quality, leverages sample relations to extract intrinsic\nfeatures that capture semantic information and has achieved remarkable success\nin Few-Shot Learning (FSL). Nevertheless, current few-shot contrastive learning\napproaches often overlook the semantic similarity discrepancies at different\ngranularities when employing the same modeling approach for different sample\nrelations, which limits the potential of few-shot contrastive learning. In this\npaper, we introduce a straightforward yet effective contrastive learning\napproach, Multi-Grained Relation Contrastive Learning (MGRCL), as a\npre-training feature learning model to boost few-shot learning by meticulously\nmodeling sample relations at different granularities. MGRCL categorizes sample\nrelations into three types: intra-sample relation of the same sample under\ndifferent transformations, intra-class relation of homogenous samples, and\ninter-class relation of inhomogeneous samples. In MGRCL, we design\nTransformation Consistency Learning (TCL) to ensure the rigorous semantic\nconsistency of a sample under different transformations by aligning predictions\nof input pairs. Furthermore, to preserve discriminative information, we employ\nClass Contrastive Learning (CCL) to ensure that a sample is always closer to\nits homogenous samples than its inhomogeneous ones, as homogenous samples share\nsimilar semantic content while inhomogeneous samples have different semantic\ncontent. Our method is assessed across four popular FSL benchmarks, showing\nthat such a simple pre-training feature learning method surpasses a majority of\nleading FSL methods. Moreover, our method can be incorporated into other FSL\nmethods as the pre-trained model and help them obtain significant performance\ngains.", "paper_summary_zh": "\u7279\u5fb5\u54c1\u8cea\u5c0d\u65bc\u5206\u985e\u6548\u80fd\u81f3\u95dc\u91cd\u8981\uff0c\u7279\u5225\u662f\u5728\u5c0f\u6a23\u672c\u60c5\u5883\u4e2d\u3002\u5c0d\u6bd4\u5b78\u7fd2\u662f\u4e00\u7a2e\u5ee3\u6cdb\u63a1\u7528\u7684\u6280\u8853\uff0c\u7528\u65bc\u63d0\u5347\u7279\u5fb5\u54c1\u8cea\uff0c\u5b83\u5229\u7528\u6a23\u672c\u95dc\u4fc2\u4f86\u8403\u53d6\u5167\u5728\u7279\u5fb5\uff0c\u4ee5\u64f7\u53d6\u8a9e\u610f\u8cc7\u8a0a\uff0c\u4e26\u5728\u5c0f\u6a23\u672c\u5b78\u7fd2 (FSL) \u4e2d\u7372\u5f97\u986f\u8457\u7684\u6210\u529f\u3002\u5118\u7ba1\u5982\u6b64\uff0c\u76ee\u524d\u7684\u5c11\u6a23\u672c\u5c0d\u6bd4\u5b78\u7fd2\u65b9\u6cd5\u5728\u5c0d\u4e0d\u540c\u6a23\u672c\u95dc\u4fc2\u63a1\u7528\u76f8\u540c\u7684\u5efa\u6a21\u65b9\u6cd5\u6642\uff0c\u901a\u5e38\u6703\u5ffd\u7565\u4e0d\u540c\u7c92\u5ea6\u4e0b\u7684\u8a9e\u610f\u76f8\u4f3c\u6027\u5dee\u7570\uff0c\u9019\u9650\u5236\u4e86\u5c11\u6a23\u672c\u5c0d\u6bd4\u5b78\u7fd2\u7684\u6f5b\u529b\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u4ecb\u7d39\u4e00\u7a2e\u7c21\u55ae\u4f46\u6709\u6548\u7684\u5c0d\u6bd4\u5b78\u7fd2\u65b9\u6cd5\uff0c\u5373\u591a\u7c92\u5ea6\u95dc\u4fc2\u5c0d\u6bd4\u5b78\u7fd2 (MGRCL)\uff0c\u4f5c\u70ba\u9810\u8a13\u7df4\u7279\u5fb5\u5b78\u7fd2\u6a21\u578b\uff0c\u900f\u904e\u5728\u4e0d\u540c\u7c92\u5ea6\u4e0b\u4ed4\u7d30\u5efa\u6a21\u6a23\u672c\u95dc\u4fc2\u4f86\u63d0\u5347\u5c11\u6a23\u672c\u5b78\u7fd2\u3002MGRCL \u5c07\u6a23\u672c\u95dc\u4fc2\u5206\u985e\u70ba\u4e09\u7a2e\u985e\u578b\uff1a\u540c\u4e00\u6a23\u672c\u5728\u4e0d\u540c\u8f49\u63db\u4e0b\u7684\u6a23\u672c\u5167\u95dc\u4fc2\u3001\u540c\u985e\u6a23\u672c\u7684\u985e\u5167\u95dc\u4fc2\uff0c\u4ee5\u53ca\u4e0d\u540c\u985e\u6a23\u672c\u7684\u985e\u9593\u95dc\u4fc2\u3002\u5728 MGRCL \u4e2d\uff0c\u6211\u5011\u8a2d\u8a08\u4e86\u8f49\u63db\u4e00\u81f4\u6027\u5b78\u7fd2 (TCL)\uff0c\u900f\u904e\u6bd4\u5c0d\u8f38\u5165\u5c0d\u7684\u9810\u6e2c\uff0c\u4f86\u78ba\u4fdd\u6a23\u672c\u5728\u4e0d\u540c\u8f49\u63db\u4e0b\u7684\u56b4\u8b39\u8a9e\u610f\u4e00\u81f4\u6027\u3002\u6b64\u5916\uff0c\u70ba\u4e86\u4fdd\u7559\u5340\u8fa8\u6027\u8cc7\u8a0a\uff0c\u6211\u5011\u63a1\u7528\u985e\u5c0d\u6bd4\u5b78\u7fd2 (CCL)\uff0c\u4ee5\u78ba\u4fdd\u6a23\u672c\u59cb\u7d42\u6bd4\u5176\u4e0d\u540c\u985e\u6a23\u672c\u66f4\u63a5\u8fd1\u5176\u540c\u985e\u6a23\u672c\uff0c\u56e0\u70ba\u540c\u985e\u6a23\u672c\u5177\u6709\u76f8\u4f3c\u7684\u8a9e\u610f\u5167\u5bb9\uff0c\u800c\u4e0d\u540c\u985e\u6a23\u672c\u5177\u6709\u4e0d\u540c\u7684\u8a9e\u610f\u5167\u5bb9\u3002\u6211\u5011\u7684\u6a21\u578b\u5728\u56db\u500b\u6d41\u884c\u7684 FSL \u57fa\u6e96\u4e0a\u9032\u884c\u8a55\u4f30\uff0c\u7d50\u679c\u986f\u793a\u9019\u7a2e\u7c21\u55ae\u7684\u9810\u8a13\u7df4\u7279\u5fb5\u5b78\u7fd2\u65b9\u6cd5\u512a\u65bc\u5927\u591a\u6578\u9818\u5148\u7684 FSL \u65b9\u6cd5\u3002\u6b64\u5916\uff0c\u6211\u5011\u7684\u6a21\u578b\u53ef\u4ee5\u4f5c\u70ba\u9810\u8a13\u7df4\u6a21\u578b\u6574\u5408\u5230\u5176\u4ed6 FSL \u65b9\u6cd5\u4e2d\uff0c\u4e26\u5e6b\u52a9\u5b83\u5011\u7372\u5f97\u986f\u8457\u7684\u6548\u80fd\u63d0\u5347\u3002", "author": "Guowei Yin et.al.", "authors": "Guowei Yin, Sheng Huang, Luwen Huangfu, Yi Zhang, Xiaohong Zhang", "id": "2501.13418v1", "paper_url": "http://arxiv.org/abs/2501.13418v1", "repo": "null"}}