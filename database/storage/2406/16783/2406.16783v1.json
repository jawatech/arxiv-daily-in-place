{"2406.16783": {"publish_time": "2024-06-24", "title": "M2Lingual: Enhancing Multilingual, Multi-Turn Instruction Alignment in Large Language Models", "paper_summary": "Instruction finetuning (IFT) is critical for aligning Large Language Models\n(LLMs) to follow instructions. Numerous effective IFT datasets have been\nproposed in the recent past, but most focus on high resource languages such as\nEnglish. In this work, we propose a fully synthetic, novel taxonomy (Evol)\nguided Multilingual, Multi-turn instruction finetuning dataset, called\nM2Lingual, to better align LLMs on a diverse set of languages and tasks.\nM2Lingual contains a total of 182K IFT pairs that are built upon diverse seeds,\ncovering 70 languages, 17 NLP tasks and general instruction-response pairs.\nLLMs finetuned with M2Lingual substantially outperform the majority of existing\nmultilingual IFT datasets. Importantly, LLMs trained with M2Lingual\nconsistently achieve competitive results across a wide variety of evaluation\nbenchmarks compared to existing multilingual IFT datasets. Specifically, LLMs\nfinetuned with M2Lingual achieve strong performance on our translated\nmultilingual, multi-turn evaluation benchmark as well as a wide variety of\nmultilingual tasks. Thus we contribute, and the 2 step Evol taxonomy used for\nits creation. M2Lingual repository -\nhttps://huggingface.co/datasets/ServiceNow-AI/M2Lingual", "paper_summary_zh": "\u6307\u4ee4\u5fae\u8abf (IFT) \u5c0d\u65bc\u8b93\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u9075\u5faa\u6307\u4ee4\u81f3\u95dc\u91cd\u8981\u3002\u6700\u8fd1\u5df2\u63d0\u51fa\u8a31\u591a\u6709\u6548\u7684 IFT \u8cc7\u6599\u96c6\uff0c\u4f46\u5927\u591a\u6578\u90fd\u5c08\u6ce8\u65bc\u82f1\u8a9e\u7b49\u9ad8\u8cc7\u6e90\u8a9e\u8a00\u3002\u5728\u9019\u9805\u5de5\u4f5c\u4e2d\uff0c\u6211\u5011\u63d0\u51fa\u4e00\u500b\u5b8c\u5168\u5408\u6210\u3001\u65b0\u7a4e\u7684\u5206\u985e\u6cd5 (Evol) \u6307\u5c0e\u7684\u591a\u8a9e\u8a00\u3001\u591a\u8f2a\u6307\u4ee4\u5fae\u8abf\u8cc7\u6599\u96c6\uff0c\u7a31\u70ba M2Lingual\uff0c\u4ee5\u5728\u5404\u7a2e\u8a9e\u8a00\u548c\u4efb\u52d9\u4e0a\u66f4\u597d\u5730\u5c0d\u9f4a LLM\u3002M2Lingual \u7e3d\u5171\u5305\u542b 182K \u500b IFT \u5c0d\uff0c\u9019\u4e9b\u5c0d\u5efa\u7acb\u5728\u4e0d\u540c\u7684\u7a2e\u5b50\u4e0a\uff0c\u6db5\u84cb 70 \u7a2e\u8a9e\u8a00\u300117 \u500b NLP \u4efb\u52d9\u548c\u4e00\u822c\u6307\u4ee4\u56de\u61c9\u5c0d\u3002\u4f7f\u7528 M2Lingual \u5fae\u8abf\u7684 LLM \u5927\u5927\u512a\u65bc\u73fe\u6709\u7684\u591a\u8a9e\u8a00 IFT \u8cc7\u6599\u96c6\u3002\u91cd\u8981\u7684\u662f\uff0c\u4f7f\u7528 M2Lingual \u8a13\u7df4\u7684 LLM \u5728\u5404\u7a2e\u8a55\u4f30\u57fa\u6e96\u4e0a\u8207\u73fe\u6709\u7684\u591a\u8a9e\u8a00 IFT \u8cc7\u6599\u96c6\u76f8\u6bd4\uff0c\u59cb\u7d42\u80fd\u53d6\u5f97\u6709\u7af6\u722d\u529b\u7684\u7d50\u679c\u3002\u5177\u9ad4\u4f86\u8aaa\uff0c\u4f7f\u7528 M2Lingual \u5fae\u8abf\u7684 LLM \u5728\u6211\u5011\u7684\u7ffb\u8b6f\u591a\u8a9e\u8a00\u3001\u591a\u8f2a\u8a55\u4f30\u57fa\u6e96\u4ee5\u53ca\u5404\u7a2e\u591a\u8a9e\u8a00\u4efb\u52d9\u4e0a\u90fd\u53d6\u5f97\u4e86\u5f37\u52c1\u7684\u8868\u73fe\u3002\u56e0\u6b64\uff0c\u6211\u5011\u8ca2\u737b\u4e86 M2Lingual \u8cc7\u6599\u96c6\uff0c\u4ee5\u53ca\u7528\u65bc\u5efa\u7acb\u5b83\u7684 2 \u6b65\u9a5f Evol \u5206\u985e\u6cd5\u3002M2Lingual \u5b58\u653e\u5eab -\nhttps://huggingface.co/datasets/ServiceNow-AI/M2Lingual", "author": "Rishabh Maheshwary et.al.", "authors": "Rishabh Maheshwary, Vikas Yadav, Hoang Nguyen, Khyati Mahajan, Sathwik Tejaswi Madhusudhan", "id": "2406.16783v1", "paper_url": "http://arxiv.org/abs/2406.16783v1", "repo": "null"}}