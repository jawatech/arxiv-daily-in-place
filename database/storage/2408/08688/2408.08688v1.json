{"2408.08688": {"publish_time": "2024-08-16", "title": "The Fellowship of the LLMs: Multi-Agent Workflows for Synthetic Preference Optimization Dataset Generation", "paper_summary": "This paper presents and evaluates multi-agent workflows for synthetic\nPreference Optimization (PO) dataset generation. PO dataset generation requires\ntwo modules: (1) response evaluation, and (2) response generation. In the\nresponse evaluation module, the responses from Large Language Models (LLMs) are\nevaluated and ranked - a task typically carried out by human annotators that we\nautomate using LLMs. We assess the response evaluation module in a 2 step\nprocess. In step 1, we assess LLMs as evaluators using three distinct prompting\nstrategies. In step 2, we apply the winning prompting strategy to compare the\nperformance of LLM-as-a-Judge, LLMs-as-a-Jury, and LLM Debate. In each step, we\nuse inter-rater agreement using Cohen's Kappa between human annotators and\nLLMs. For the response generation module, we compare different configurations\nfor the LLM Feedback Loop using the identified LLM evaluator configuration. We\nuse the win rate (the fraction of times a generation framework is selected as\nthe best by an LLM evaluator) to determine the best multi-agent configuration\nfor generation. After identifying the best configurations for both modules, we\nuse models from the GPT, Gemma, and Llama families to generate our PO datasets\nusing the above pipeline. We generate two types of PO datasets, one to improve\nthe generation capabilities of individual LLM and the other to improve the\nmulti-agent workflow. Our evaluation shows that GPT-4o-as-a-Judge is more\nconsistent across datasets when the candidate responses do not include\nresponses from the GPT family. Additionally, we find that the LLM Feedback\nLoop, with Llama as the generator and Gemma as the reviewer, achieves a notable\n71.8% and 73.8% win rate over single-agent Llama and Gemma, respectively.", "paper_summary_zh": "\u672c\u6587\u63d0\u51fa\u4e26\u8a55\u4f30\u7528\u65bc\u5408\u6210\u504f\u597d\u6700\u4f73\u5316 (PO) \u8cc7\u6599\u96c6\u751f\u6210\u7684\u4ee3\u7406\u4eba\u5de5\u4f5c\u6d41\u7a0b\u3002PO \u8cc7\u6599\u96c6\u751f\u6210\u9700\u8981\u5169\u500b\u6a21\u7d44\uff1a(1) \u56de\u61c9\u8a55\u4f30\uff0c\u4ee5\u53ca (2) \u56de\u61c9\u751f\u6210\u3002\u5728\u56de\u61c9\u8a55\u4f30\u6a21\u7d44\u4e2d\uff0c\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u7684\u56de\u61c9\u6703\u7d93\u904e\u8a55\u4f30\u548c\u6392\u540d\uff0c\u9019\u9805\u4efb\u52d9\u901a\u5e38\u7531\u6211\u5011\u4f7f\u7528 LLM \u81ea\u52d5\u5316\u7684\u4eba\u985e\u8a3b\u89e3\u54e1\u57f7\u884c\u3002\u6211\u5011\u4f7f\u7528 2 \u6b65\u9a5f\u6d41\u7a0b\u8a55\u4f30\u56de\u61c9\u8a55\u4f30\u6a21\u7d44\u3002\u5728\u6b65\u9a5f 1 \u4e2d\uff0c\u6211\u5011\u4f7f\u7528\u4e09\u500b\u4e0d\u540c\u7684\u63d0\u793a\u7b56\u7565\u8a55\u4f30 LLM \u4f5c\u70ba\u8a55\u4f30\u54e1\u3002\u5728\u6b65\u9a5f 2 \u4e2d\uff0c\u6211\u5011\u5957\u7528\u7372\u52dd\u7684\u63d0\u793a\u7b56\u7565\u4f86\u6bd4\u8f03 LLM-as-a-Judge\u3001LLM-as-a-Jury \u548c LLM Debate \u7684\u6548\u80fd\u3002\u5728\u6bcf\u500b\u6b65\u9a5f\u4e2d\uff0c\u6211\u5011\u4f7f\u7528\u4eba\u985e\u8a3b\u89e3\u54e1\u548c LLM \u4e4b\u9593\u7684 Cohen's Kappa \u4f86\u4f7f\u7528\u8a55\u5206\u8005\u9593\u4e00\u81f4\u6027\u3002\u5c0d\u65bc\u56de\u61c9\u751f\u6210\u6a21\u7d44\uff0c\u6211\u5011\u4f7f\u7528\u5df2\u8b58\u5225\u7684 LLM \u8a55\u4f30\u54e1\u8a2d\u5b9a\u6bd4\u8f03 LLM \u56de\u994b\u8ff4\u8def\u7684\u4e0d\u540c\u8a2d\u5b9a\u3002\u6211\u5011\u4f7f\u7528\u7372\u52dd\u7387\uff08LLM \u8a55\u4f30\u54e1\u9078\u64c7\u751f\u6210\u67b6\u69cb\u70ba\u6700\u4f73\u7684\u6b21\u6578\u6bd4\u4f8b\uff09\u4f86\u6c7a\u5b9a\u6700\u4f73\u7684\u751f\u6210\u4ee3\u7406\u4eba\u8a2d\u5b9a\u3002\u5728\u627e\u51fa\u5169\u500b\u6a21\u7d44\u7684\u6700\u4f73\u8a2d\u5b9a\u5f8c\uff0c\u6211\u5011\u4f7f\u7528 GPT\u3001Gemma \u548c Llama \u5bb6\u65cf\u7684\u6a21\u578b\u4f86\u4f7f\u7528\u4e0a\u8ff0\u7ba1\u7dda\u751f\u6210\u6211\u5011\u7684 PO \u8cc7\u6599\u96c6\u3002\u6211\u5011\u751f\u6210\u4e86\u5169\u7a2e PO \u8cc7\u6599\u96c6\uff0c\u4e00\u7a2e\u7528\u65bc\u63d0\u5347\u500b\u5225 LLM \u7684\u751f\u6210\u80fd\u529b\uff0c\u53e6\u4e00\u7a2e\u7528\u65bc\u63d0\u5347\u4ee3\u7406\u4eba\u5de5\u4f5c\u6d41\u7a0b\u3002\u6211\u5011\u7684\u8a55\u4f30\u986f\u793a\uff0c\u7576\u5019\u9078\u56de\u61c9\u4e0d\u5305\u542b GPT \u5bb6\u65cf\u7684\u56de\u61c9\u6642\uff0cGPT-4o-as-a-Judge \u5728\u4e0d\u540c\u8cc7\u6599\u96c6\u4e4b\u9593\u7684\u4e00\u81f4\u6027\u8f03\u9ad8\u3002\u6b64\u5916\uff0c\u6211\u5011\u767c\u73fe LLM \u56de\u994b\u8ff4\u8def\uff08\u7531 Llama \u4f5c\u70ba\u751f\u6210\u5668\uff0cGemma \u4f5c\u70ba\u5be9\u95b1\u8005\uff09\u5206\u5225\u5c0d\u55ae\u4e00\u4ee3\u7406\u4eba Llama \u548c Gemma \u9054\u5230\u4e86\u986f\u8457\u7684 71.8% \u548c 73.8% \u7372\u52dd\u7387\u3002", "author": "Samee Arif et.al.", "authors": "Samee Arif, Sualeha Farid, Abdul Hameed Azeemi, Awais Athar, Agha Ali Raza", "id": "2408.08688v1", "paper_url": "http://arxiv.org/abs/2408.08688v1", "repo": "null"}}