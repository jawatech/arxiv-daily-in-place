{"2406.07133": {"publish_time": "2024-06-11", "title": "Translating speech with just images", "paper_summary": "Visually grounded speech models link speech to images. We extend this\nconnection by linking images to text via an existing image captioning system,\nand as a result gain the ability to map speech audio directly to text. This\napproach can be used for speech translation with just images by having the\naudio in a different language from the generated captions. We investigate such\na system on a real low-resource language, Yor\\`ub\\'a, and propose a\nYor\\`ub\\'a-to-English speech translation model that leverages pretrained\ncomponents in order to be able to learn in the low-resource regime. To limit\noverfitting, we find that it is essential to use a decoding scheme that\nproduces diverse image captions for training. Results show that the predicted\ntranslations capture the main semantics of the spoken audio, albeit in a\nsimpler and shorter form.", "paper_summary_zh": "\u8996\u89ba\u5316\u57fa\u790e\u8a9e\u97f3\u6a21\u578b\u5c07\u8a9e\u97f3\u9023\u7d50\u5230\u5716\u50cf\u3002\u6211\u5011\u900f\u904e\u73fe\u6709\u7684\u5716\u50cf\u6a19\u984c\u7cfb\u7d71\u5c07\u5716\u50cf\u9023\u7d50\u5230\u6587\u5b57\uff0c\u9032\u800c\u64f4\u5c55\u9019\u500b\u9023\u7d50\uff0c\u7d50\u679c\u7372\u5f97\u5c07\u8a9e\u97f3\u97f3\u8a0a\u76f4\u63a5\u5c0d\u61c9\u5230\u6587\u5b57\u7684\u80fd\u529b\u3002\u9019\u500b\u65b9\u6cd5\u53ef\u4ee5\u53ea\u7528\u5716\u50cf\u9032\u884c\u8a9e\u97f3\u7ffb\u8b6f\uff0c\u8b93\u97f3\u8a0a\u8207\u7522\u751f\u7684\u6a19\u984c\u4f7f\u7528\u4e0d\u540c\u7684\u8a9e\u8a00\u3002\u6211\u5011\u5728\u4e00\u500b\u771f\u6b63\u7684\u4f4e\u8cc7\u6e90\u8a9e\u8a00\uff0cYor\\`ub\\'a\uff0c\u8abf\u67e5\u9019\u7a2e\u7cfb\u7d71\uff0c\u4e26\u63d0\u51fa\u4e00\u500b Yor\\`ub\\'a-to-English \u8a9e\u97f3\u7ffb\u8b6f\u6a21\u578b\uff0c\u5b83\u5229\u7528\u9810\u5148\u8a13\u7df4\u7684\u5143\u4ef6\uff0c\u4ee5\u4fbf\u80fd\u5920\u5728\u4f4e\u8cc7\u6e90\u6a21\u5f0f\u4e2d\u5b78\u7fd2\u3002\u70ba\u4e86\u9650\u5236\u904e\u5ea6\u64ec\u5408\uff0c\u6211\u5011\u767c\u73fe\u4f7f\u7528\u7522\u751f\u591a\u6a23\u5316\u5716\u50cf\u6a19\u984c\u7528\u65bc\u8a13\u7df4\u7684\u89e3\u78bc\u65b9\u6848\u81f3\u95dc\u91cd\u8981\u3002\u7d50\u679c\u986f\u793a\uff0c\u9810\u6e2c\u7684\u7ffb\u8b6f\u638c\u63e1\u4e86\u6240\u8aaa\u97f3\u8a0a\u7684\u4e3b\u8981\u8a9e\u610f\uff0c\u5118\u7ba1\u5f62\u5f0f\u66f4\u7c21\u55ae\u4e14\u66f4\u7c21\u77ed\u3002", "author": "Dan Oneata et.al.", "authors": "Dan Oneata, Herman Kamper", "id": "2406.07133v1", "paper_url": "http://arxiv.org/abs/2406.07133v1", "repo": "null"}}