{"2405.04324": {"publish_time": "2024-05-07", "title": "Granite Code Models: A Family of Open Foundation Models for Code Intelligence", "paper_summary": "Large Language Models (LLMs) trained on code are revolutionizing the software\ndevelopment process. Increasingly, code LLMs are being integrated into software\ndevelopment environments to improve the productivity of human programmers, and\nLLM-based agents are beginning to show promise for handling complex tasks\nautonomously. Realizing the full potential of code LLMs requires a wide range\nof capabilities, including code generation, fixing bugs, explaining and\ndocumenting code, maintaining repositories, and more. In this work, we\nintroduce the Granite series of decoder-only code models for code generative\ntasks, trained with code written in 116 programming languages. The Granite Code\nmodels family consists of models ranging in size from 3 to 34 billion\nparameters, suitable for applications ranging from complex application\nmodernization tasks to on-device memory-constrained use cases. Evaluation on a\ncomprehensive set of tasks demonstrates that Granite Code models consistently\nreaches state-of-the-art performance among available open-source code LLMs. The\nGranite Code model family was optimized for enterprise software development\nworkflows and performs well across a range of coding tasks (e.g. code\ngeneration, fixing and explanation), making it a versatile all around code\nmodel. We release all our Granite Code models under an Apache 2.0 license for\nboth research and commercial use.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u63a5\u53d7\u904e\u7a0b\u5f0f\u78bc\u8a13\u7df4\uff0c\u6b63\u5728\u9769\u65b0\u8edf\u9ad4\u958b\u767c\u6d41\u7a0b\u3002\u7a0b\u5f0f\u78bc LLM \u6108\u4f86\u6108\u591a\u5730\u6574\u5408\u5230\u8edf\u9ad4\u958b\u767c\u74b0\u5883\u4e2d\uff0c\u4ee5\u63d0\u5347\u4eba\u985e\u7a0b\u5f0f\u8a2d\u8a08\u5e2b\u7684\u751f\u7522\u529b\uff0c\u800c\u57fa\u65bc LLM \u7684\u4ee3\u7406\u7a0b\u5f0f\u4e5f\u958b\u59cb\u5c55\u73fe\u51fa\u81ea\u4e3b\u8655\u7406\u8907\u96dc\u4efb\u52d9\u7684\u5e0c\u671b\u3002\u8981\u5be6\u73fe\u7a0b\u5f0f\u78bc LLM \u7684\u5168\u90e8\u6f5b\u529b\uff0c\u9700\u8981\u5ee3\u6cdb\u7684\u529f\u80fd\uff0c\u5305\u62ec\u7522\u751f\u7a0b\u5f0f\u78bc\u3001\u4fee\u6b63\u932f\u8aa4\u3001\u8aaa\u660e\u548c\u8a18\u9304\u7a0b\u5f0f\u78bc\u3001\u7dad\u8b77\u5132\u5b58\u5eab\u7b49\u7b49\u3002\u5728\u9019\u9805\u5de5\u4f5c\u4e2d\uff0c\u6211\u5011\u5f15\u5165\u4e86 Granite \u7cfb\u5217\u7684\u50c5\u89e3\u78bc\u5668\u7a0b\u5f0f\u78bc\u6a21\u578b\uff0c\u7528\u65bc\u7a0b\u5f0f\u78bc\u7522\u751f\u4efb\u52d9\uff0c\u4e26\u4f7f\u7528 116 \u7a2e\u7a0b\u5f0f\u8a9e\u8a00\u7de8\u5beb\u7684\u7a0b\u5f0f\u78bc\u9032\u884c\u8a13\u7df4\u3002Granite Code \u6a21\u578b\u7cfb\u5217\u5305\u542b\u5927\u5c0f\u5f9e 30 \u5104\u5230 340 \u5104\u500b\u53c3\u6578\u4e0d\u7b49\u7684\u6a21\u578b\uff0c\u9069\u7528\u65bc\u5f9e\u8907\u96dc\u7684\u61c9\u7528\u7a0b\u5f0f\u73fe\u4ee3\u5316\u4efb\u52d9\u5230\u88dd\u7f6e\u8a18\u61b6\u9ad4\u53d7\u9650\u4f7f\u7528\u6848\u4f8b\u7684\u5404\u7a2e\u61c9\u7528\u7a0b\u5f0f\u3002\u5c0d\u4e00\u7d44\u5168\u9762\u7684\u4efb\u52d9\u9032\u884c\u8a55\u4f30\uff0c\u8b49\u660e Granite Code \u6a21\u578b\u5728\u73fe\u6709\u7684\u958b\u6e90\u7a0b\u5f0f\u78bc LLM \u4e2d\u59cb\u7d42\u9054\u5230\u6700\u5148\u9032\u7684\u6548\u80fd\u3002Granite Code \u6a21\u578b\u7cfb\u5217\u7d93\u904e\u6700\u4f73\u5316\uff0c\u9069\u7528\u65bc\u4f01\u696d\u8edf\u9ad4\u958b\u767c\u5de5\u4f5c\u6d41\u7a0b\uff0c\u4e26\u4e14\u5728\u5404\u7a2e\u7de8\u78bc\u4efb\u52d9\uff08\u4f8b\u5982\u7522\u751f\u7a0b\u5f0f\u78bc\u3001\u4fee\u6b63\u548c\u8aaa\u660e\uff09\u4e2d\u8868\u73fe\u826f\u597d\uff0c\u4f7f\u5176\u6210\u70ba\u4e00\u6b3e\u529f\u80fd\u5f37\u5927\u7684\u5168\u65b9\u4f4d\u7a0b\u5f0f\u78bc\u6a21\u578b\u3002\u6211\u5011\u6839\u64da Apache 2.0 \u6388\u6b0a\u91cb\u51fa\u6240\u6709 Granite Code \u6a21\u578b\uff0c\u4f9b\u7814\u7a76\u548c\u5546\u696d\u7528\u9014\u3002", "author": "Mayank Mishra et.al.", "authors": "Mayank Mishra, Matt Stallone, Gaoyuan Zhang, Yikang Shen, Aditya Prasad, Adriana Meza Soria, Michele Merler, Parameswaran Selvam, Saptha Surendran, Shivdeep Singh, Manish Sethi, Xuan-Hong Dang, Pengyuan Li, Kun-Lung Wu, Syed Zawad, Andrew Coleman, Matthew White, Mark Lewis, Raju Pavuluri, Yan Koyfman, Boris Lublinsky, Maximilien de Bayser, Ibrahim Abdelaziz, Kinjal Basu, Mayank Agarwal, Yi Zhou, Chris Johnson, Aanchal Goyal, Hima Patel, Yousaf Shah, Petros Zerfos, Heiko Ludwig, Asim Munawar, Maxwell Crouse, Pavan Kapanipathi, Shweta Salaria, Bob Calio, Sophia Wen, Seetharami Seelam, Brian Belgodere, Carlos Fonseca, Amith Singhee, Nirmit Desai, David D. Cox, Ruchir Puri, Rameswar Panda", "id": "2405.04324v1", "paper_url": "http://arxiv.org/abs/2405.04324v1", "repo": "https://github.com/ibm-granite/granite-code-models"}}