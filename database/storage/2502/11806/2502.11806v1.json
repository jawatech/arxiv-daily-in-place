{"2502.11806": {"publish_time": "2025-02-17", "title": "Exploring Translation Mechanism of Large Language Models", "paper_summary": "Large language models (LLMs) have succeeded remarkably in multilingual\ntranslation tasks. However, the inherent translation mechanisms of LLMs remain\npoorly understood, largely due to sophisticated architectures and vast\nparameter scales. In response to this issue, this study explores the\ntranslation mechanism of LLM from the perspective of computational components\n(e.g., attention heads and MLPs). Path patching is utilized to explore causal\nrelationships between components, detecting those crucial for translation tasks\nand subsequently analyzing their behavioral patterns in human-interpretable\nterms. Comprehensive analysis reveals that translation is predominantly\nfacilitated by a sparse subset of specialized attention heads (less than 5\\%),\nwhich extract source language, indicator, and positional features. MLPs\nsubsequently integrate and process these features by transiting towards\nEnglish-centric latent representations. Notably, building on the above\nfindings, targeted fine-tuning of only 64 heads achieves translation\nimprovement comparable to full-parameter tuning while preserving general\ncapabilities.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u5728\u591a\u8a9e\u8a00\u7ffb\u8b6f\u4efb\u52d9\u4e2d\u53d6\u5f97\u4e86\u986f\u8457\u7684\u6210\u529f\u3002\u7136\u800c\uff0cLLM \u5167\u5728\u7684\u7ffb\u8b6f\u6a5f\u5236\u4ecd\u672a\u88ab\u5f88\u597d\u5730\u7406\u89e3\uff0c\u9019\u4e3b\u8981\u662f\u7531\u65bc\u8907\u96dc\u7684\u67b6\u69cb\u548c\u9f90\u5927\u7684\u53c3\u6578\u898f\u6a21\u3002\u70ba\u4e86\u61c9\u5c0d\u9019\u500b\u554f\u984c\uff0c\u672c\u7814\u7a76\u5f9e\u8a08\u7b97\u5143\u4ef6\uff08\u4f8b\u5982\u6ce8\u610f\u529b\u982d\u548c MLP\uff09\u7684\u89d2\u5ea6\u63a2\u8a0e\u4e86 LLM \u7684\u7ffb\u8b6f\u6a5f\u5236\u3002\u8def\u5f91\u4fee\u88dc\u7528\u65bc\u63a2\u7d22\u5143\u4ef6\u4e4b\u9593\u7684\u56e0\u679c\u95dc\u4fc2\uff0c\u6aa2\u6e2c\u5c0d\u7ffb\u8b6f\u4efb\u52d9\u81f3\u95dc\u91cd\u8981\u7684\u5143\u4ef6\uff0c\u4e26\u96a8\u5f8c\u4ee5\u4eba\u985e\u53ef\u89e3\u91cb\u7684\u65b9\u5f0f\u5206\u6790\u5b83\u5011\u7684\u884c\u70ba\u6a21\u5f0f\u3002\u7d9c\u5408\u5206\u6790\u8868\u660e\uff0c\u7ffb\u8b6f\u4e3b\u8981\u7531\u7a00\u758f\u7684\u5c08\u9580\u6ce8\u610f\u529b\u982d\uff08\u4e0d\u5230 5%\uff09\u4fc3\u9032\uff0c\u9019\u4e9b\u6ce8\u610f\u529b\u982d\u63d0\u53d6\u6e90\u8a9e\u8a00\u3001\u6307\u6a19\u548c\u4f4d\u7f6e\u7279\u5fb5\u3002MLPs \u96a8\u5f8c\u901a\u904e\u8f49\u63db\u70ba\u4ee5\u82f1\u8a9e\u70ba\u4e2d\u5fc3\u7684\u6f5b\u5728\u8868\u793a\u4f86\u6574\u5408\u548c\u8655\u7406\u9019\u4e9b\u7279\u5fb5\u3002\u503c\u5f97\u6ce8\u610f\u7684\u662f\uff0c\u6839\u64da\u4e0a\u8ff0\u767c\u73fe\uff0c\u50c5\u5c0d 64 \u500b\u982d\u9032\u884c\u6709\u91dd\u5c0d\u6027\u7684\u5fae\u8abf\uff0c\u5373\u53ef\u5be6\u73fe\u8207\u5168\u53c3\u6578\u8abf\u6574\u76f8\u7576\u7684\u7ffb\u8b6f\u6539\u9032\uff0c\u540c\u6642\u4fdd\u7559\u4e00\u822c\u80fd\u529b\u3002", "author": "Hongbin Zhang et.al.", "authors": "Hongbin Zhang, Kehai Chen, Xuefeng Bai, Xiucheng Li, Min Zhang", "id": "2502.11806v1", "paper_url": "http://arxiv.org/abs/2502.11806v1", "repo": "null"}}