{"2405.03429": {"publish_time": "2024-05-06", "title": "ReCycle: Fast and Efficient Long Time Series Forecasting with Residual Cyclic Transformers", "paper_summary": "Transformers have recently gained prominence in long time series forecasting\nby elevating accuracies in a variety of use cases. Regrettably, in the race for\nbetter predictive performance the overhead of model architectures has grown\nonerous, leading to models with computational demand infeasible for most\npractical applications. To bridge the gap between high method complexity and\nrealistic computational resources, we introduce the Residual Cyclic\nTransformer, ReCycle. ReCycle utilizes primary cycle compression to address the\ncomputational complexity of the attention mechanism in long time series. By\nlearning residuals from refined smoothing average techniques, ReCycle surpasses\nstate-of-the-art accuracy in a variety of application use cases. The reliable\nand explainable fallback behavior ensured by simple, yet robust, smoothing\naverage techniques additionally lowers the barrier for user acceptance. At the\nsame time, our approach reduces the run time and energy consumption by more\nthan an order of magnitude, making both training and inference feasible on\nlow-performance, low-power and edge computing devices. Code is available at\nhttps://github.com/Helmholtz-AI-Energy/ReCycle", "paper_summary_zh": "", "author": "Arvid Weyrauch et.al.", "authors": "Arvid Weyrauch,Thomas Steens,Oskar Taubert,Benedikt Hanke,Aslan Eqbal,Ewa G\u00f6tz,Achim Streit,Markus G\u00f6tz,Charlotte Debus", "id": "2405.03429v1", "paper_url": "http://arxiv.org/abs/2405.03429v1", "repo": "https://github.com/helmholtz-ai-energy/recycle"}}