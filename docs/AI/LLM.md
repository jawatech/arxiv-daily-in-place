
### LLM
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2025-02-06**|**Ola: Pushing the Frontiers of Omni-Modal Language Model with Progressive Modality Alignment**|Zuyan Liu et.al.|[2502.04328v1](http://arxiv.org/abs/2502.04328v1)|null|
|**2025-02-06**|**WorldSense: Evaluating Real-world Omnimodal Understanding for Multimodal LLMs**|Jack Hong et.al.|[2502.04326v1](http://arxiv.org/abs/2502.04326v1)|null|
|**2025-02-06**|**Can Grammarly and ChatGPT accelerate language change? AI-powered technologies and their impact on the English language: wordiness vs. conciseness**|Karolina Rudnicka et.al.|[2502.04324v1](http://arxiv.org/abs/2502.04324v1)|null|
|**2025-02-06**|**Variation of sentence length across time and genre**|Karolina Rudnicka et.al.|[2502.04321v1](http://arxiv.org/abs/2502.04321v1)|null|
|**2025-02-06**|**Speak Easy: Eliciting Harmful Jailbreaks from LLMs with Simple Interactions**|Yik Siu Chan et.al.|[2502.04322v1](http://arxiv.org/abs/2502.04322v1)|null|
|**2025-02-06**|**ChamaleonLLM: Batch-Aware Dynamic Low-Rank Adaptation via Inference-Time Clusters**|Kamer Ali Yuksel et.al.|[2502.04315v1](http://arxiv.org/abs/2502.04315v1)|null|
|**2025-02-06**|**BOUQuET: dataset, Benchmark and Open initiative for Universal Quality Evaluation in Translation**|The Omnilingual MT Team et.al.|[2502.04314v1](http://arxiv.org/abs/2502.04314v1)|null|
|**2025-02-06**|**Great Models Think Alike and this Undermines AI Oversight**|Shashwat Goel et.al.|[2502.04313v1](http://arxiv.org/abs/2502.04313v1)|[link](https://github.com/model-similarity/lm-similarity/tree/main/applications)|
|**2025-02-06**|**HOG-Diff: Higher-Order Guided Diffusion for Graph Generation**|Yiming Huang et.al.|[2502.04308v1](http://arxiv.org/abs/2502.04308v1)|null|
|**2025-02-06**|**ScoreFlow: Mastering LLM Agent Workflows via Score-based Preference Optimization**|Yinjie Wang et.al.|[2502.04306v1](http://arxiv.org/abs/2502.04306v1)|null|
|**2025-02-06**|**Strong Equivalence in Answer Set Programming with Constraints**|Pedro Cabalar et.al.|[2502.04302v1](http://arxiv.org/abs/2502.04302v1)|null|
|**2025-02-06**|**Beyond Prompt Content: Enhancing LLM Performance via Content-Format Integrated Prompt Optimization**|Yuanye Liu et.al.|[2502.04295v1](http://arxiv.org/abs/2502.04295v1)|null|
|**2025-02-06**|**A Methodology for Studying Linguistic and Cultural Change in China, 1900-1950**|Spencer Dean Stewart et.al.|[2502.04286v1](http://arxiv.org/abs/2502.04286v1)|null|
|**2025-02-06**|**How does a Multilingual LM Handle Multiple Languages?**|Santhosh Kakarla et.al.|[2502.04269v1](http://arxiv.org/abs/2502.04269v1)|null|
|**2025-02-06**|**Cross the Gap: Exposing the Intra-modal Misalignment in CLIP via Modality Inversion**|Marco Mistretta et.al.|[2502.04263v1](http://arxiv.org/abs/2502.04263v1)|null|
|**2025-02-06**|**Free Energy Risk Metrics for Systemically Safe AI: Gatekeeping Multi-Agent Study**|Michael Walters et.al.|[2502.04249v1](http://arxiv.org/abs/2502.04249v1)|null|
|**2025-02-06**|**TriNER: A Series of Named Entity Recognition Models For Hindi, Bengali & Marathi**|Mohammed Amaan Dhamaskar et.al.|[2502.04245v1](http://arxiv.org/abs/2502.04245v1)|null|
|**2025-02-06**|**A Theoretical Framework for Data Efficient Multi-Source Transfer Learning Based on Cram√©r-Rao Bound**|Qingyue Zhang et.al.|[2502.04242v1](http://arxiv.org/abs/2502.04242v1)|null|
|**2025-02-06**|**MAGA: MAssive Genre-Audience Reformulation to Pretraining Corpus Expansion**|Xintong Hao et.al.|[2502.04235v1](http://arxiv.org/abs/2502.04235v1)|null|
|**2025-02-06**|**A Classification System Approach in Predicting Chinese Censorship**|Matt Prodani et.al.|[2502.04234v1](http://arxiv.org/abs/2502.04234v1)|null|
|**2025-02-06**|**Dark Distillation: Backdooring Distilled Datasets without Accessing Raw Data**|Ziyuan Yang et.al.|[2502.04229v1](http://arxiv.org/abs/2502.04229v1)|null|
|**2025-02-06**|**NLP-Based .NET CLR Event Logs Analyzer**|Maxim Stavtsev et.al.|[2502.04219v1](http://arxiv.org/abs/2502.04219v1)|null|
|**2025-02-06**|**Sports and Women's Sports: Gender Bias in Text Generation with Olympic Data**|Laura Biester et.al.|[2502.04218v1](http://arxiv.org/abs/2502.04218v1)|null|
|**2025-02-06**|**Algorithmic causal structure emerging through compression**|Liang Wendong et.al.|[2502.04210v1](http://arxiv.org/abs/2502.04210v1)|null|
|**2025-02-06**|**The Best Instruction-Tuning Data are Those That Fit**|Dylan Zhang et.al.|[2502.04194v1](http://arxiv.org/abs/2502.04194v1)|null|
|**2025-02-06**|**Multi-agent Architecture Search via Agentic Supernet**|Guibin Zhang et.al.|[2502.04180v1](http://arxiv.org/abs/2502.04180v1)|null|
|**2025-02-06**|**Lexical Substitution is not Synonym Substitution: On the Importance of Producing Contextually Relevant Word Substitutes**|Juraj Vladika et.al.|[2502.04173v1](http://arxiv.org/abs/2502.04173v1)|null|
|**2025-02-06**|**UltraIF: Advancing Instruction Following from the Wild**|Kaikai An et.al.|[2502.04153v1](http://arxiv.org/abs/2502.04153v1)|null|
|**2025-02-06**|**Synthetic Datasets for Machine Learning on Spatio-Temporal Graphs using PDEs**|Jost Arndt et.al.|[2502.04140v1](http://arxiv.org/abs/2502.04140v1)|null|
|**2025-02-06**|**The Order Effect: Investigating Prompt Sensitivity in Closed-Source LLMs**|Bryan Guan et.al.|[2502.04134v1](http://arxiv.org/abs/2502.04134v1)|null|
|**2025-02-06**|**Llasa: Scaling Train-Time and Inference-Time Compute for Llama-based Speech Synthesis**|Zhen Ye et.al.|[2502.04128v1](http://arxiv.org/abs/2502.04128v1)|null|
|**2025-02-06**|**VTutor: An Open-Source SDK for Generative AI-Powered Animated Pedagogical Agents with Multi-Media Output**|Eason Chen et.al.|[2502.04103v1](http://arxiv.org/abs/2502.04103v1)|null|
|**2025-02-06**|**Efficient Few-Shot Continual Learning in Vision-Language Models**|Aristeidis Panos et.al.|[2502.04098v1](http://arxiv.org/abs/2502.04098v1)|null|
|**2025-02-06**|**LLMs to Support a Domain Specific Knowledge Assistant**|Maria-Flavia Lovin et.al.|[2502.04095v1](http://arxiv.org/abs/2502.04095v1)|null|
|**2025-02-06**|**Automatic quantification of breast cancer biomarkers from multiple 18F-FDG PET image segmentation**|Tewele W. Tareke et.al.|[2502.04083v1](http://arxiv.org/abs/2502.04083v1)|null|
|**2025-02-06**|**AttentionPredictor: Temporal Pattern Matters for Efficient LLM Inference**|Qingyue Yang et.al.|[2502.04077v1](http://arxiv.org/abs/2502.04077v1)|null|
|**2025-02-06**|**Controllable Emotion Generation with Emotion Vectors**|Yurui Dong et.al.|[2502.04075v1](http://arxiv.org/abs/2502.04075v1)|null|
|**2025-02-06**|**Predicting Large Language Model Capabilities on Closed-Book QA Tasks Using Only Information Available Prior to Training**|Changhao Jiang et.al.|[2502.04066v1](http://arxiv.org/abs/2502.04066v1)|null|
|**2025-02-06**|**Strategic Learning with Local Explanations as Feedback**|Kiet Q. H. Vo et.al.|[2502.04058v1](http://arxiv.org/abs/2502.04058v1)|null|
|**2025-02-06**|**Probe-Free Low-Rank Activation Intervention**|Chonghe Jiang et.al.|[2502.04043v1](http://arxiv.org/abs/2502.04043v1)|null|
|**2025-02-06**|**Leveraging Reasoning with Guidelines to Elicit and Utilize Knowledge for Enhancing Safety Alignment**|Haoyu Wang et.al.|[2502.04040v1](http://arxiv.org/abs/2502.04040v1)|null|
|**2025-02-06**|**Simulating the Emergence of Differential Case Marking with Communicating Neural-Network Agents**|Yuchen Lian et.al.|[2502.04038v1](http://arxiv.org/abs/2502.04038v1)|null|
|**2025-02-06**|**Exploring Imbalanced Annotations for Effective In-Context Learning**|Hongfu Gao et.al.|[2502.04037v1](http://arxiv.org/abs/2502.04037v1)|null|
|**2025-02-06**|**Generalize Drug Response Prediction by Latent Independent Projection for Asymmetric Constrained Domain Generalization**|Ran Song et.al.|[2502.04034v1](http://arxiv.org/abs/2502.04034v1)|null|
|**2025-02-06**|**Fine, I'll Merge It Myself: A Multi-Fidelity Framework for Automated Model Merging**|Guinan Su et.al.|[2502.04030v1](http://arxiv.org/abs/2502.04030v1)|null|
|**2025-02-06**|**Quantification of Biodiversity from Historical Survey Text with LLM-based Best-Worst Scaling**|Thomas Haider et.al.|[2502.04022v1](http://arxiv.org/abs/2502.04022v1)|null|
|**2025-02-06**|**Automating a Complete Software Test Process Using LLMs: An Automotive Case Study**|Shuai Wang et.al.|[2502.04008v1](http://arxiv.org/abs/2502.04008v1)|null|
|**2025-02-06**|**Online Learning of Counter Categories and Ratings in PvP Games**|Chiu-Chou Lin et.al.|[2502.03998v1](http://arxiv.org/abs/2502.03998v1)|null|
|**2025-02-06**|**Ontology-Guided, Hybrid Prompt Learning for Generalization in Knowledge Graph Question Answering**|Longquan Jiang et.al.|[2502.03992v1](http://arxiv.org/abs/2502.03992v1)|null|
|**2025-02-06**|**PGB: One-Shot Pruning for BERT via Weight Grouping and Permutation**|Hyemin Lim et.al.|[2502.03984v1](http://arxiv.org/abs/2502.03984v1)|null|
|**2025-02-06**|**Towards Unified Music Emotion Recognition across Dimensional and Categorical Models**|Jaeyong Kang et.al.|[2502.03979v1](http://arxiv.org/abs/2502.03979v1)|null|
|**2025-02-06**|**MultiFloodSynth: Multi-Annotated Flood Synthetic Dataset Generation**|YoonJe Kang et.al.|[2502.03966v1](http://arxiv.org/abs/2502.03966v1)|null|
|**2025-02-06**|**Improving the Perturbation-Based Explanation of Deepfake Detectors Through the Use of Adversarially-Generated Samples**|Konstantinos Tsigos et.al.|[2502.03957v1](http://arxiv.org/abs/2502.03957v1)|null|
|**2025-02-06**|**MAQInstruct: Instruction-based Unified Event Relation Extraction**|Jun Xu et.al.|[2502.03954v1](http://arxiv.org/abs/2502.03954v1)|null|
|**2025-02-06**|**Afrispeech-Dialog: A Benchmark Dataset for Spontaneous English Conversations in Healthcare and Beyond**|Mardhiyah Sanni et.al.|[2502.03945v1](http://arxiv.org/abs/2502.03945v1)|null|
|**2025-02-06**|**DiTAR: Diffusion Transformer Autoregressive Modeling for Speech Generation**|Dongya Jia et.al.|[2502.03930v1](http://arxiv.org/abs/2502.03930v1)|null|
|**2025-02-06**|**Adaptation of Task Goal States from Prior Knowledge**|Andrei Costinescu et.al.|[2502.03918v1](http://arxiv.org/abs/2502.03918v1)|null|
|**2025-02-06**|**Experiments with Large Language Models on Retrieval-Augmented Generation for Closed-Source Simulation Software**|Andreas Baumann et.al.|[2502.03916v1](http://arxiv.org/abs/2502.03916v1)|null|
|**2025-02-06**|**Rank Also Matters: Hierarchical Configuration for Mixture of Adapter Experts in LLM Fine-Tuning**|Peizhuang Cong et.al.|[2502.03884v1](http://arxiv.org/abs/2502.03884v1)|null|
|**2025-02-06**|**BOLT: Bootstrap Long Chain-of-Thought in Language Models without Distillation**|Bo Pang et.al.|[2502.03860v1](http://arxiv.org/abs/2502.03860v1)|null|
|**2025-02-06**|**Pursuing Better Decision Boundaries for Long-Tailed Object Detection via Category Information Amount**|Yanbiao Ma et.al.|[2502.03852v1](http://arxiv.org/abs/2502.03852v1)|null|
|**2025-02-06**|**Improving Natural Language Understanding for LLMs via Large-Scale Instruction Synthesis**|Lin Yuan et.al.|[2502.03843v1](http://arxiv.org/abs/2502.03843v1)|null|
|**2025-02-06**|**A comprehensive survey of contemporary Arabic sentiment analysis: Methods, Challenges, and Future Directions**|Zhiqiang Shi et.al.|[2502.03827v1](http://arxiv.org/abs/2502.03827v1)|null|
|**2025-02-06**|**Syntriever: How to Train Your Retriever with Synthetic Data from LLMs**|Minsang Kim et.al.|[2502.03824v1](http://arxiv.org/abs/2502.03824v1)|null|
|**2025-02-06**|**PsyPlay: Personality-Infused Role-Playing Conversational Agents**|Tao Yang et.al.|[2502.03821v1](http://arxiv.org/abs/2502.03821v1)|null|
|**2025-02-06**|**Large Language Models for Multi-Robot Systems: A Survey**|Peihan Li et.al.|[2502.03814v1](http://arxiv.org/abs/2502.03814v1)|null|
|**2025-02-06**|**Identify Critical KV Cache in LLM Inference from an Output Perturbation Perspective**|Yuan Feng et.al.|[2502.03805v1](http://arxiv.org/abs/2502.03805v1)|null|
|**2025-02-06**|**Understanding and Supporting Formal Email Exchange by Answering AI-Generated Questions**|Yusuke Miura et.al.|[2502.03804v1](http://arxiv.org/abs/2502.03804v1)|null|
|**2025-02-06**|**SoK: Benchmarking Poisoning Attacks and Defenses in Federated Learning**|Heyi Zhang et.al.|[2502.03801v1](http://arxiv.org/abs/2502.03801v1)|null|
|**2025-02-06**|**Enhancing Hallucination Detection through Noise Injection**|Litian Liu et.al.|[2502.03799v1](http://arxiv.org/abs/2502.03799v1)|null|
|**2025-02-06**|**It's All in The [MASK]: Simple Instruction-Tuning Enables BERT-like Masked Language Models As Generative Classifiers**|Benjamin Clavi√© et.al.|[2502.03793v1](http://arxiv.org/abs/2502.03793v1)|null|
|**2025-02-06**|**ExpProof : Operationalizing Explanations for Confidential Models with ZKPs**|Chhavi Yadav et.al.|[2502.03773v1](http://arxiv.org/abs/2502.03773v1)|null|
|**2025-02-06**|**A Retrospective Systematic Study on Hierarchical Sparse Query Transformer-assisted Ultrasound Screening for Early Hepatocellular Carcinoma**|Chaoyin She et.al.|[2502.03772v1](http://arxiv.org/abs/2502.03772v1)|[link](https://github.com/Asunatan/HSQformer)|
|**2025-02-06**|**Adaptive Semantic Prompt Caching with VectorQ**|Luis Gaspar Schroeder et.al.|[2502.03771v1](http://arxiv.org/abs/2502.03771v1)|null|
|**2025-02-06**|**Hierarchical Contextual Manifold Alignment for Structuring Latent Representations in Large Language Models**|Meiquan Dong et.al.|[2502.03766v1](http://arxiv.org/abs/2502.03766v1)|null|
|**2025-02-06**|**Principal Curvatures Estimation with Applications to Single Cell Data**|Yanlei Zhang et.al.|[2502.03750v1](http://arxiv.org/abs/2502.03750v1)|null|
|**2025-02-06**|**Rethinking the Residual Distribution of Locate-then-Editing Methods in Model Editing**|Xiaopeng Li et.al.|[2502.03748v1](http://arxiv.org/abs/2502.03748v1)|null|
|**2025-02-06**|**Action-Free Reasoning for Policy Generalization**|Jaden Clark et.al.|[2502.03729v1](http://arxiv.org/abs/2502.03729v1)|null|
|**2025-02-06**|**MD-BERT: Action Recognition in Dark Videos via Dynamic Multi-Stream Fusion and Temporal Modeling**|Sharana Dharshikgan Suresh Dass et.al.|[2502.03724v1](http://arxiv.org/abs/2502.03724v1)|null|
|**2025-02-06**|**Efficiently Generating Expressive Quadruped Behaviors via Language-Guided Preference Learning**|Jaden Clark et.al.|[2502.03717v1](http://arxiv.org/abs/2502.03717v1)|null|
|**2025-02-06**|**Boosting Knowledge Graph-based Recommendations through Confidence-Aware Augmentation with Large Language Models**|Rui Cai et.al.|[2502.03715v1](http://arxiv.org/abs/2502.03715v1)|null|
|**2025-02-06**|**MultiQ&A: An Analysis in Measuring Robustness via Automated Crowdsourcing of Question Perturbations and Answers**|Nicole Cho et.al.|[2502.03711v1](http://arxiv.org/abs/2502.03711v1)|null|
|**2025-02-06**|**Aggregate and conquer: detecting and steering LLM concepts by combining nonlinear predictors over multiple layers**|Daniel Beaglehole et.al.|[2502.03708v1](http://arxiv.org/abs/2502.03708v1)|null|
|**2025-02-06**|**LLM Alignment as Retriever Optimization: An Information Retrieval Perspective**|Bowen Jin et.al.|[2502.03699v1](http://arxiv.org/abs/2502.03699v1)|null|
|**2025-02-06**|**DocMIA: Document-Level Membership Inference Attacks against DocVQA Models**|Khanh Nguyen et.al.|[2502.03692v1](http://arxiv.org/abs/2502.03692v1)|null|
|**2025-02-06**|**A Comparison of DeepSeek and Other LLMs**|Tianchen Gao et.al.|[2502.03688v1](http://arxiv.org/abs/2502.03688v1)|null|
|**2025-02-06**|**Variational Control for Guidance in Diffusion Models**|Kushagra Pandey et.al.|[2502.03686v1](http://arxiv.org/abs/2502.03686v1)|null|
|**2025-02-06**|**Controlled LLM Decoding via Discrete Auto-regressive Biasing**|Patrick Pynadath et.al.|[2502.03685v1](http://arxiv.org/abs/2502.03685v1)|null|
|**2025-02-05**|**Reflection-Window Decoding: Text Generation with Selective Refinement**|Zeyu Tang et.al.|[2502.03678v1](http://arxiv.org/abs/2502.03678v1)|null|
|**2025-02-05**|**Advancing Reasoning in Large Language Models: Promising Methods and Approaches**|Avinash Patil et.al.|[2502.03671v1](http://arxiv.org/abs/2502.03671v1)|null|
|**2025-02-05**|**Unrealized Expectations: Comparing AI Methods vs Classical Algorithms for Maximum Independent Set**|Yikai Wu et.al.|[2502.03669v1](http://arxiv.org/abs/2502.03669v1)|null|
|**2025-02-05**|**Energy & Force Regression on DFT Trajectories is Not Enough for Universal Machine Learning Interatomic Potentials**|Santiago Miret et.al.|[2502.03660v1](http://arxiv.org/abs/2502.03660v1)|null|
|**2025-02-05**|**Gompertz Linear Units: Leveraging Asymmetry for Enhanced Learning Dynamics**|Indrashis Das et.al.|[2502.03654v1](http://arxiv.org/abs/2502.03654v1)|null|
|**2025-02-05**|**Looking for the Inner Music: Probing LLMs' Understanding of Literary Style**|Rebecca M. M. Hicke et.al.|[2502.03647v1](http://arxiv.org/abs/2502.03647v1)|null|
|**2025-02-05**|**Context-Preserving Gradient Modulation for Large Language Models: A Novel Approach to Semantic Consistency in Long-Form Text Generation**|Nirola Kobanov et.al.|[2502.03643v1](http://arxiv.org/abs/2502.03643v1)|null|
|**2025-02-05**|**REALEDIT: Reddit Edits As a Large-scale Empirical Dataset for Image Transformations**|Peter Sushko et.al.|[2502.03629v1](http://arxiv.org/abs/2502.03629v1)|null|
|**2025-02-05**|**The Hidden Life of Tokens: Reducing Hallucination of Large Vision-Language Models via Visual Information Steering**|Zhuowei Li et.al.|[2502.03628v1](http://arxiv.org/abs/2502.03628v1)|null|
|**2025-02-05**|**Sorting the Babble in Babel: Assessing the Performance of Language Detection Algorithms on the OpenAlex Database**|Maxime Holmberg Sainte-Marie et.al.|[2502.03627v1](http://arxiv.org/abs/2502.03627v1)|null|
|**2025-02-05**|**AdaPhish: AI-Powered Adaptive Defense and Education Resource Against Deceptive Emails**|Rei Meguro et.al.|[2502.03622v1](http://arxiv.org/abs/2502.03622v1)|null|
|**2025-02-05**|**A Novel Zero-Touch, Zero-Trust, AI/ML Enablement Framework for IoT Network Security**|Sushil Shakya et.al.|[2502.03614v1](http://arxiv.org/abs/2502.03614v1)|null|

#### Abstracts
##### **Ola: Pushing the Frontiers of Omni-Modal Language Model with Progressive Modality Alignment**
2502.04328v1 by Zuyan Liu, Yuhao Dong, Jiahui Wang, Ziwei Liu, Winston Hu, Jiwen Lu, Yongming Rao

Recent advances in large language models, particularly following GPT-4o, have
sparked increasing interest in developing omni-modal models capable of
understanding more modalities. While some open-source alternatives have
emerged, there is still a notable lag behind specialized single-modality models
in performance. In this paper, we present Ola, an Omni-modal language model
that achieves competitive performance across image, video, and audio
understanding compared to specialized counterparts. The core design of Ola lies
in its progressive modality alignment strategy that extends the supporting
modality of the language model progressively. Our training pipeline begins with
the most distinct modalities: image and text, then gradually expands the skill
sets of the model using speech data that connects language and audio knowledge,
and video data that connects all modalities. The progressive learning pipeline
also enables us to maintain a relatively small size of the cross-modal
alignment data, making developing omni-modal from existing vision-language
models easy and less costly. Moreover, to unlock an advanced interactive
experience like GPT-4o, we further design a sentence-wise decoding solution for
streaming speech generation. Extensive experiments demonstrate that Ola
surpasses existing open omni-modal LLMs across all modalities while achieving
highly competitive performance compared to state-of-the-art specialized models
of similar sizes. We aim to make Ola a fully open omni-modal understanding
solution to advance future research in this emerging field. Model weights,
code, and data are open-sourced at https://github.com/Ola-Omni/Ola.

ÊëòË¶ÅÔºö<paragraph>ËøëÊúüÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÁöÑÈÄ≤Â±ïÔºåÁâπÂà•ÊòØÂú® GPT-4o ‰πãÂæåÔºåÊøÄÁôº‰∫Ü‰∫∫ÂÄëÂ∞çÈñãÁôºÂÖ®Ê®°ÊÖãÊ®°ÂûãÁöÑËààË∂£ÔºåÈÄôÁ®ÆÊ®°ÂûãËÉΩÂ§†ÁêÜËß£Êõ¥Â§öÊ®°ÊÖã„ÄÇÈõñÁÑ∂Â∑≤Á∂ìÂá∫Áèæ‰∫Ü‰∏Ä‰∫õÈñãÊ∫êÊõø‰ª£ÊñπÊ°àÔºå‰ΩÜÂú®ÊïàËÉΩ‰∏ä‰ªçÈ°ØËëóËêΩÂæåÊñºÂ∞àÈñÄÁöÑÂñÆÊ®°ÊÖãÊ®°Âûã„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫ OlaÔºåÈÄôÊòØ‰∏ÄÂÄãÂÖ®Ê®°ÊÖãË™ûË®ÄÊ®°ÂûãÔºåÂú®ÂΩ±ÂÉè„ÄÅÂΩ±ÁâáÂíåÈü≥Ë®äÁêÜËß£ÊñπÈù¢ÔºåËàáÂ∞àÈñÄÁöÑÂ∞çÊáâÊ®°ÂûãÁõ∏ÊØîÔºåÈÅîÂà∞‰∫ÜÂÖ∑ÊúâÁ´∂Áà≠ÂäõÁöÑÊïàËÉΩ„ÄÇOla ÁöÑÊ†∏ÂøÉË®≠Ë®àÂú®ÊñºÂÖ∂Êº∏ÈÄ≤ÂºèÊ®°ÊÖãÂ∞çÈΩäÁ≠ñÁï•ÔºåË©≤Á≠ñÁï•ÈÄêÊº∏Êì¥Â±ïË™ûË®ÄÊ®°ÂûãÁöÑÊîØÊè¥Ê®°ÊÖã„ÄÇÊàëÂÄëÁöÑË®ìÁ∑¥ÊµÅÁ®ãÂæûÊúÄ‰∏çÂêåÁöÑÊ®°ÊÖãÈñãÂßãÔºöÂΩ±ÂÉèÂíåÊñáÂ≠óÔºåÁÑ∂Âæå‰ΩøÁî®ÈÄ£Êé•Ë™ûË®ÄÂíåÈü≥Ë®äÁü•Ë≠òÁöÑË™ûÈü≥Ë≥áÊñôÔºå‰ª•ÂèäÈÄ£Êé•ÊâÄÊúâÊ®°ÊÖãÁöÑÂΩ±ÁâáË≥áÊñôÔºåÈÄêÊ≠•Êì¥Â±ïÊ®°ÂûãÁöÑÊäÄËÉΩÁµÑ„ÄÇÊº∏ÈÄ≤ÂºèÂ≠∏ÁøíÊµÅÁ®ã‰πüËÆìÊàëÂÄëËÉΩÂ§†Á∂≠ÊåÅÁõ∏Â∞çËºÉÂ∞èÁöÑË∑®Ê®°ÊÖãÂ∞çÈΩäË≥áÊñôÂ§ßÂ∞èÔºåËÆìÂæûÁèæÊúâÁöÑË¶ñË¶∫Ë™ûË®ÄÊ®°ÂûãÈñãÁôºÂÖ®Ê®°ÊÖãÊ®°ÂûãËÆäÂæóÂÆπÊòì‰∏îÊàêÊú¨ËºÉ‰Ωé„ÄÇÊ≠§Â§ñÔºåÁÇ∫‰∫ÜËß£ÈéñÈ°û‰ºº GPT-4o ÁöÑÈÄ≤Èöé‰∫íÂãïÈ´îÈ©óÔºåÊàëÂÄëÈÄ≤‰∏ÄÊ≠•Ë®≠Ë®à‰∫Ü‰∏ÄÂÄãÈÄêÂè•Ëß£Á¢ºËß£Ê±∫ÊñπÊ°àÔºåÁî®Êñº‰∏≤ÊµÅË™ûÈü≥ÁîüÊàê„ÄÇÂª£Ê≥õÁöÑÂØ¶È©óË≠âÊòéÔºåOla Âú®ÊâÄÊúâÊ®°ÊÖã‰∏äÈÉΩË∂ÖË∂ä‰∫ÜÁèæÊúâÁöÑÈñãÊîæÂÖ®Ê®°ÊÖã LLMÔºåÂêåÊôÇËàáÈ°û‰ººË¶èÊ®°ÁöÑÊúÄÊñ∞Â∞àÈñÄÊ®°ÂûãÁõ∏ÊØîÔºåÈÅîÂà∞‰∫ÜÊ•µÂÖ∑Á´∂Áà≠ÂäõÁöÑÊïàËÉΩ„ÄÇÊàëÂÄëÂ∏åÊúõËÆì Ola ÊàêÁÇ∫‰∏ÄÂÄãÂÆåÂÖ®ÈñãÊîæÁöÑÂÖ®Ê®°ÊÖãÁêÜËß£Ëß£Ê±∫ÊñπÊ°àÔºå‰ª•Êé®ÂãïÈÄôÂÄãÊñ∞ËààÈ†òÂüüÁöÑÊú™‰æÜÁ†îÁ©∂„ÄÇÊ®°ÂûãÊ¨äÈáç„ÄÅÁ®ãÂºèÁ¢ºÂíåË≥áÊñôÂ∑≤Âú® https://github.com/Ola-Omni/Ola ÈñãÊ∫ê„ÄÇ</paragraph>

##### **WorldSense: Evaluating Real-world Omnimodal Understanding for Multimodal LLMs**
2502.04326v1 by Jack Hong, Shilin Yan, Jiayin Cai, Xiaolong Jiang, Yao Hu, Weidi Xie

In this paper, we introduce WorldSense, the first benchmark to assess the
multi-modal video understanding, that simultaneously encompasses visual, audio,
and text inputs. In contrast to existing benchmarks, our WorldSense has several
features: (i) collaboration of omni-modality, we design the evaluation tasks to
feature a strong coupling of audio and video, requiring models to effectively
utilize the synergistic perception of omni-modality; (ii) diversity of videos
and tasks, WorldSense encompasses a diverse collection of 1,662 audio-visual
synchronised videos, systematically categorized into 8 primary domains and 67
fine-grained subcategories to cover the broad scenarios, and 3,172 multi-choice
QA pairs across 26 distinct tasks to enable the comprehensive evaluation; (iii)
high-quality annotations, all the QA pairs are manually labeled by 80 expert
annotators with multiple rounds of correction to ensure quality. Based on our
WorldSense, we extensively evaluate various state-of-the-art models. The
experimental results indicate that existing models face significant challenges
in understanding real-world scenarios (48.0% best accuracy). We hope our
WorldSense can provide a platform for evaluating the ability in constructing
and understanding coherent contexts from omni-modality.

ÊëòË¶ÅÔºöÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄë‰ªãÁ¥π‰∫Ü WorldSenseÔºåÈÄôÊòØÁ¨¨‰∏ÄÂÄãË©ï‰º∞Â§öÊ®°ÊÖãÂΩ±ÁâáÁêÜËß£ÁöÑÂü∫Ê∫ñÔºåÂêåÊôÇÂåÖÂê´Ë¶ñË¶∫„ÄÅÈü≥Ë®äÂíåÊñáÂ≠óËº∏ÂÖ•„ÄÇËàáÁèæÊúâÁöÑÂü∫Ê∫ñÁõ∏ÊØîÔºåÊàëÂÄëÁöÑ WorldSense ÊúâÂπæÂÄãÁâπÈªûÔºö(i) ÂÖ®Ê®°ÊÖãÂçî‰ΩúÔºåÊàëÂÄëË®≠Ë®àË©ï‰º∞‰ªªÂãô‰ª•ÂëàÁèæÈü≥Ë®äÂíåË¶ñË®äÁöÑÂº∑ËÄ¶ÂêàÔºåË¶ÅÊ±ÇÊ®°ÂûãÊúâÊïàÂà©Áî®ÂÖ®Ê®°ÊÖãÁöÑÂçîÂêåÊÑüÁü•Ôºõ(ii) ÂΩ±ÁâáÂíå‰ªªÂãôÁöÑÂ§öÊ®£ÊÄßÔºåWorldSense Ê∂µËìã‰∫Ü 1,662 ÂÄãÈü≥Ë®äË¶ñË®äÂêåÊ≠•ÂΩ±ÁâáÁöÑÂ§öÊ®£ÂåñÈõÜÂêàÔºåÁ≥ªÁµ±Âú∞ÂàÜÈ°ûÁÇ∫ 8 ÂÄã‰∏ªË¶ÅÈ†òÂüüÂíå 67 ÂÄãÁ¥∞Á≤íÂ∫¶ÁöÑÂ≠êÈ°ûÂà•Ôºå‰ª•Ê∂µËìãÂª£Ê≥õÁöÑÂ†¥ÊôØÔºå‰ª•Âèä 26 ÂÄã‰∏çÂêå‰ªªÂãô‰∏≠ÁöÑ 3,172 ÂÄãÂ§öÈÅ∏È°åÂïèÁ≠îÂ∞çÔºå‰ª•ÈÄ≤Ë°åÂÖ®Èù¢ÁöÑË©ï‰º∞Ôºõ(iii) È´òÂìÅË≥™Ë®ªËß£ÔºåÊâÄÊúâÂïèÁ≠îÂ∞çÂùáÁî± 80 ‰ΩçÂ∞àÂÆ∂Ë®ªËß£ËÄÖÊâãÂãïÊ®ôË®òÔºå‰∏¶Á∂ìÈÅéÂ§öËº™Ê†°Ê≠£‰ª•Á¢∫‰øùÂìÅË≥™„ÄÇÊ†πÊìöÊàëÂÄëÁöÑ WorldSenseÔºåÊàëÂÄëÂª£Ê≥õË©ï‰º∞‰∫ÜÂêÑÁ®ÆÊúÄÂÖàÈÄ≤ÁöÑÊ®°Âûã„ÄÇÂØ¶È©óÁµêÊûúË°®ÊòéÔºåÁèæÊúâÊ®°ÂûãÂú®ÁêÜËß£ÁúüÂØ¶‰∏ñÁïåÂ†¥ÊôØÊñπÈù¢Èù¢Ëá®ÈáçÂ§ßÊåëÊà∞ÔºàÊúÄ‰Ω≥Ê∫ñÁ¢∫Â∫¶ÁÇ∫ 48.0%Ôºâ„ÄÇÊàëÂÄëÂ∏åÊúõÊàëÂÄëÁöÑ WorldSense ËÉΩÂ§†Êèê‰æõ‰∏ÄÂÄãÂπ≥Âè∞ÔºåÁî®ÊñºË©ï‰º∞ÂæûÂÖ®Ê®°ÊÖãÂª∫ÊßãÂíåÁêÜËß£ÈÄ£Ë≤´ËÑàÁµ°ÁöÑËÉΩÂäõ„ÄÇ

##### **Can Grammarly and ChatGPT accelerate language change? AI-powered technologies and their impact on the English language: wordiness vs. conciseness**
2502.04324v1 by Karolina Rudnicka

The proliferation of NLP-powered language technologies, AI-based natural
language generation models, and English as a mainstream means of communication
among both native and non-native speakers make the output of AI-powered tools
especially intriguing to linguists. This paper investigates how Grammarly and
ChatGPT affect the English language regarding wordiness vs. conciseness. A case
study focusing on the purpose subordinator in order to is presented to
illustrate the way in which Grammarly and ChatGPT recommend shorter grammatical
structures instead of longer and more elaborate ones. Although the analysed
sentences were produced by native speakers, are perfectly correct, and were
extracted from a language corpus of contemporary English, both Grammarly and
ChatGPT suggest more conciseness and less verbosity, even for relatively short
sentences. The present article argues that technologies such as Grammarly not
only mirror language change but also have the potential to facilitate or
accelerate it.

ÊëòË¶ÅÔºöËá™ÁÑ∂Ë™ûË®ÄËôïÁêÜÊäÄË°ì„ÄÅÂü∫Êñº‰∫∫Â∑•Êô∫ÊÖßÁöÑËá™ÁÑ∂Ë™ûË®ÄÁîüÊàêÊ®°ÂûãÁöÑÊôÆÂèäÔºå‰ª•ÂèäËã±Ë™û‰ΩúÁÇ∫ÊØçË™ûÂíåÈùûÊØçË™û‰∫∫Â£´‰πãÈñìÁöÑ‰∏ªË¶ÅÊ∫ùÈÄöÊñπÂºèÔºå‰ΩøÂæó‰∫∫Â∑•Êô∫ÊÖßÂ∑•ÂÖ∑ÁöÑËº∏Âá∫Â∞çË™ûË®ÄÂ≠∏ÂÆ∂‰æÜË™™ÁâπÂà•ÊúâË∂£„ÄÇÊú¨ÊñáÊé¢Ë®é‰∫Ü Grammarly Âíå ChatGPT Â¶Ç‰ΩïÂΩ±ÈüøËã±Ë™û‰∏≠ÁöÑÂÜóÈï∑ËàáÁ∞°ÊΩî„ÄÇÊú¨Á†îÁ©∂‰ª•ÁõÆÁöÑÂæûÂ±¨ÈÄ£Êé•Ë©û in order to ÁÇ∫‰æãÔºåË™™Êòé Grammarly Âíå ChatGPT Â¶Ç‰ΩïÂª∫Ë≠∞‰ΩøÁî®ËºÉÁü≠ÁöÑË™ûÊ≥ïÁµêÊßãÔºåËÄå‰∏çÊòØËºÉÈï∑‰∏îËºÉË§áÈõúÁöÑÁµêÊßã„ÄÇÂÑòÁÆ°ÂàÜÊûêÁöÑÂè•Â≠êÊòØÁî±ÊØçË™û‰∫∫Â£´Áî¢ÁîüÔºåÂÆåÂÖ®Ê≠£Á¢∫Ôºå‰∏îÊëòËá™Áï∂‰ª£Ëã±Ë™ûÁöÑË™ûË®ÄË™ûÊñôÂ∫´Ôºå‰ΩÜ Grammarly Âíå ChatGPT Âç≥‰ΩøÂ∞çÊñºÁõ∏Â∞çËºÉÁü≠ÁöÑÂè•Â≠êÔºå‰πüÂª∫Ë≠∞Êõ¥Á∞°ÊΩî„ÄÅÊõ¥Â∞ëÂÜóÈ§ò„ÄÇÊú¨ÊñáË™çÁÇ∫ÔºåÂÉè Grammarly ÈÄôÊ®£ÁöÑÊäÄË°ì‰∏çÂÉÖÂèçÊò†‰∫ÜË™ûË®ÄÁöÑËÆäÂåñÔºåÈÇÑÊúâÂèØËÉΩ‰øÉÈÄ≤ÊàñÂä†ÈÄüÈÄôÁ®ÆËÆäÂåñ„ÄÇ

##### **Variation of sentence length across time and genre**
2502.04321v1 by Karolina Rudnicka

The goal of this paper is threefold: i) to present some practical aspects of
using full-text version of Corpus of Historical American English (COHA), the
largest diachronic multi-genre corpus of the English language, in the
investigation of a linguistic trend of change; ii) to test a widely held
assumption that sentence length in written English has been steadily decreasing
over the past few centuries; iii) to point to a possible link between the
changes in sentence length and changes in the English syntactic usage. The
empirical proof of concept for iii) is provided by the decline in the frequency
of the non-finite purpose subordinator in order to. Sentence length, genre and
the likelihood of occurrence of in order to are shown to be interrelated.

ÊëòË¶ÅÔºöÈÄôÁØáË´ñÊñáÁöÑ‰∏âÂÄãÁõÆÊ®ôÊòØÔºöi) ÊèêÂá∫‰ΩøÁî®Ë™ûÊñôÂ∫´Ê≠∑Âè≤ÁæéÂúãËã±Ë™ûÔºàCOHAÔºâÂÖ®ÊñáÁâàÊú¨ÁöÑ‰∏Ä‰∫õÂØ¶ÈöõÈù¢ÂêëÔºåCOHA ÊòØËã±Ë™ûÊúÄÂ§ßÁöÑÊ≠∑ÊôÇÂ§öÈ´îË£ÅË™ûÊñôÂ∫´ÔºåÁî®ÊñºË™øÊü•Ë™ûË®ÄË∂®Âã¢ÁöÑËÆäÂåñÔºõii) È©óË≠â‰∏ÄÂÄãÂª£Ê≥õÂ≠òÂú®ÁöÑÂÅáË®≠ÔºåÂç≥Êõ∏Èù¢Ëã±Ë™ûÁöÑÂè•Â≠êÈï∑Â∫¶Âú®ÈÅéÂéªÂπæÂÄã‰∏ñÁ¥Ä‰ª•‰æÜÊåÅÁ∫åÊ∏õÂ∞ëÔºõiii) ÊåáÂá∫Âè•Â≠êÈï∑Â∫¶ËÆäÂåñÂíåËã±Ë™ûÂè•Ê≥ïÁî®Ê≥ïËÆäÂåñ‰πãÈñìÂèØËÉΩÁöÑÈóúËÅØ„ÄÇiii) ÁöÑÊ¶ÇÂøµÂØ¶Ë≠âË≠âÊòéÊòØÁî±ÈùûÈôêÂÆöÁõÆÁöÑÂæûÂ±¨Â≠êÂè• in order to ÁöÑÈ†ªÁéá‰∏ãÈôçÊâÄÊèê‰æõÁöÑ„ÄÇÂè•Â≠êÈï∑Â∫¶„ÄÅÈ´îË£ÅÂíå in order to Âá∫ÁèæÁöÑÂèØËÉΩÊÄßË¢´Ë≠âÊòéÊòØÁõ∏‰∫íÈóúËÅØÁöÑ„ÄÇ

##### **Speak Easy: Eliciting Harmful Jailbreaks from LLMs with Simple Interactions**
2502.04322v1 by Yik Siu Chan, Narutatsu Ri, Yuxin Xiao, Marzyeh Ghassemi

Despite extensive safety alignment efforts, large language models (LLMs)
remain vulnerable to jailbreak attacks that elicit harmful behavior. While
existing studies predominantly focus on attack methods that require technical
expertise, two critical questions remain underexplored: (1) Are jailbroken
responses truly useful in enabling average users to carry out harmful actions?
(2) Do safety vulnerabilities exist in more common, simple human-LLM
interactions? In this paper, we demonstrate that LLM responses most effectively
facilitate harmful actions when they are both actionable and informative--two
attributes easily elicited in multi-step, multilingual interactions. Using this
insight, we propose HarmScore, a jailbreak metric that measures how effectively
an LLM response enables harmful actions, and Speak Easy, a simple multi-step,
multilingual attack framework. Notably, by incorporating Speak Easy into direct
request and jailbreak baselines, we see an average absolute increase of 0.319
in Attack Success Rate and 0.426 in HarmScore in both open-source and
proprietary LLMs across four safety benchmarks. Our work reveals a critical yet
often overlooked vulnerability: Malicious users can easily exploit common
interaction patterns for harmful intentions.

ÊëòË¶ÅÔºöÂÑòÁÆ°ÂÆâÂÖ®Ë™øÊï¥Â∑•‰ΩúÂª£Ê≥õÔºåÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ‰ªçÂÆπÊòìÂèóÂà∞ÂºïÁôºÊúâÂÆ≥Ë°åÁÇ∫ÁöÑË∂äÁçÑÊîªÊìä„ÄÇÁèæÊúâÁ†îÁ©∂‰∏ªË¶ÅÈóúÊ≥®ÈúÄË¶ÅÊäÄË°ìÂ∞àÊ•≠Áü•Ë≠òÁöÑÊîªÊìäÊñπÊ≥ïÔºå‰ΩÜ‰ªçÊúâÂÖ©ÂÄãÈóúÈçµÂïèÈ°åÊú™ÂæóÂà∞ÂÖÖÂàÜÊé¢Ë®éÔºö(1) Ë∂äÁçÑÂõûÊáâÊòØÂê¶ÁúüÁöÑÊúâÂä©Êñº‰∏ÄËà¨‰ΩøÁî®ËÄÖÂü∑Ë°åÊúâÂÆ≥Ë°åÁÇ∫Ôºü(2) Âú®Êõ¥Â∏∏Ë¶ã„ÄÅÁ∞°ÂñÆÁöÑ‰∫∫È°û-LLM ‰∫íÂãï‰∏≠ÊòØÂê¶Â≠òÂú®ÂÆâÂÖ®ÊºèÊ¥ûÔºüÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëË≠âÊòé LLM ÂõûÊáâÂú®ÂÖ∑ÊúâÂèØÊìç‰ΩúÊÄßÂíåË≥áË®äÊÄßÊôÇÔºåÊúÄËÉΩÊúâÊïàÂú∞‰øÉÈÄ≤ÊúâÂÆ≥Ë°åÁÇ∫‚Äî‚ÄîÈÄôÂÖ©ÂÄãÂ±¨ÊÄßÂæàÂÆπÊòìÂú®Â§öÊ≠•È©ü„ÄÅÂ§öË™ûË®Ä‰∫íÂãï‰∏≠ÂºïÁôº„ÄÇÂà©Áî®ÈÄôÂÄãË¶ãËß£ÔºåÊàëÂÄëÊèêÂá∫ HarmScoreÔºåÈÄôÊòØ‰∏ÄÂÄãË∂äÁçÑÊåáÊ®ôÔºåÁî®ÊñºË°°Èáè LLM ÂõûÊáâÂ¶Ç‰ΩïÊúâÊïàÂú∞‰øÉÊàêÊúâÂÆ≥Ë°åÁÇ∫Ôºå‰ª•Âèä Speak EasyÔºå‰∏ÄÂÄãÁ∞°ÂñÆÁöÑÂ§öÊ≠•È©ü„ÄÅÂ§öË™ûË®ÄÊîªÊìäÊû∂Êßã„ÄÇÂÄºÂæóÊ≥®ÊÑèÁöÑÊòØÔºåÈÄèÈÅéÂ∞á Speak Easy Á¥çÂÖ•Áõ¥Êé•Ë´ãÊ±ÇÂíåË∂äÁçÑÂü∫Ê∫ñÔºåÊàëÂÄëÁúãÂà∞ÈñãÊ∫êÂíåÂ∞àÊúâ LLM Âú®ÂõõÂÄãÂÆâÂÖ®Âü∫Ê∫ñ‰∏≠ÁöÑÊîªÊìäÊàêÂäüÁéáÂπ≥ÂùáÁµïÂ∞çÂ¢ûÂä† 0.319ÔºåHarmScore Â¢ûÂä† 0.426„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂Êè≠Á§∫‰∫Ü‰∏ÄÂÄãÈóúÈçµ‰ΩÜÁ∂ìÂ∏∏Ë¢´ÂøΩË¶ñÁöÑÊºèÊ¥ûÔºöÊÉ°ÊÑè‰ΩøÁî®ËÄÖÂèØ‰ª•ËºïÈ¨ÜÂà©Áî®Â∏∏Ë¶ãÁöÑ‰∫íÂãïÊ®°ÂºèÈÄ≤Ë°åÊúâÂÆ≥ÊÑèÂúñ„ÄÇ

##### **ChamaleonLLM: Batch-Aware Dynamic Low-Rank Adaptation via Inference-Time Clusters**
2502.04315v1 by Kamer Ali Yuksel, Hassan Sawaf

Recent advances in large language models (LLMs) have shown remarkable
performance across diverse tasks. However, these models are typically deployed
with fixed weights, which limits their ability to adapt dynamically to the
variability inherent in real-world data during inference. This paper introduces
ChamaleonLLM, a novel framework that enables inference-time adaptation of LLMs
by leveraging batch-aware clustering and on-the-fly generation of low-rank
updates. Unlike traditional fine-tuning approaches such as Low-Rank Adaptation
(LoRA) or methods that rely on a fixed set of pre-learned uniforms (changeable
masks), our method dynamically generates adaptive modifications to the decoder
weights based on the aggregated statistics of clustered batches. By
intelligently grouping similar inputs and computing context-aware low-rank
updates via a hyper-network, ChamaleonLLM achieves significant performance
gains, outperforming conventional LoRA methods while eliminating the overhead
of maintaining multiple expert models. Our experiments highlight the potential
of our approach to serve as a versatile and highly adaptive solution for
language model inference. ChamaleonLLM is open-sourced to ensure the
reproducibility of our experiments:
https://anonymous.4open.science/r/ChamaleonLLM/

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑÊúÄÊñ∞ÈÄ≤Â±ïÂ∑≤Âú®ÂêÑÁ®Æ‰ªªÂãô‰∏≠Â±ïÁèæÂá∫ÂçìË∂äÁöÑÊïàËÉΩ„ÄÇÁÑ∂ËÄåÔºåÈÄô‰∫õÊ®°ÂûãÈÄöÂ∏∏ÊúÉ‰ª•Âõ∫ÂÆöÁöÑÊ¨äÈáçÈÄ≤Ë°åÈÉ®ÁΩ≤ÔºåÈÄôÈôêÂà∂‰∫ÜÂÆÉÂÄëÂú®Êé®ÁêÜÈÅéÁ®ã‰∏≠ÂãïÊÖãÈÅ©ÊáâÁèæÂØ¶‰∏ñÁïåË≥áÊñô‰∏≠Âõ∫ÊúâËÆäÁï∞ÊÄßÁöÑËÉΩÂäõ„ÄÇÊú¨Êñá‰ªãÁ¥π‰∫Ü ChamaleonLLMÔºå‰∏ÄÂÄãÂâµÊñ∞ÁöÑÊû∂ÊßãÔºåÂÆÉÈÄèÈÅéÂà©Áî®ÊâπÊ¨°ÊÑüÁü•ÂàÜÁæ§ÂíåÂç≥ÊôÇÁîüÊàê‰ΩéÁß©Êõ¥Êñ∞ÔºåÂØ¶Áèæ LLM ÁöÑÊé®ÁêÜÊôÇÈñìÈÅ©Êáâ„ÄÇËàáÂÇ≥Áµ±ÁöÑÂæÆË™øÊñπÊ≥ïÔºà‰æãÂ¶Ç‰ΩéÁß©ÈÅ©Êáâ (LoRA) Êàñ‰æùË≥¥ÊñºÂõ∫ÂÆöÈ†êÂÖàÂ≠∏ÁøíÁöÑÂùáÂãªÈõÜ (ÂèØËÆäÈÅÆÁΩ©) ÁöÑÊñπÊ≥ïÔºâ‰∏çÂêåÔºåÊàëÂÄëÁöÑÊ®°ÂûãÊúÉÊ†πÊìöÂàÜÁæ§ÊâπÊ¨°ÁöÑÂåØÁ∏ΩÁµ±Ë®àË≥áÊñôÔºåÂãïÊÖãÁîüÊàêÂ∞çËß£Á¢ºÂô®Ê¨äÈáçÁöÑÈÅ©ÊáâÊÄß‰øÆÊîπ„ÄÇÈÄèÈÅéÊô∫ÊÖßÂú∞Â∞áÈ°û‰ººÁöÑËº∏ÂÖ•ÂàÜÁµÑÔºå‰∏¶ÈÄèÈÅéË∂ÖÁ∂≤Ë∑ØË®àÁÆóËàáËÑàÁµ°Áõ∏ÈóúÁöÑ‰ΩéÁß©Êõ¥Êñ∞ÔºåChamaleonLLM ÈÅîÂà∞‰∫ÜÈ°ØËëóÁöÑÊïàËÉΩÊèêÂçáÔºåÂÑ™ÊñºÂÇ≥Áµ±ÁöÑ LoRA ÊñπÊ≥ïÔºåÂêåÊôÇÊ∂àÈô§‰∫ÜÁ∂≠Ë≠∑Â§öÂÄãÂ∞àÂÆ∂Ê®°ÂûãÁöÑÈñãÈä∑„ÄÇÊàëÂÄëÁöÑÂØ¶È©óÁ™ÅÈ°Ø‰∫ÜÊàëÂÄëÁöÑÊñπÊ≥ï‰ΩúÁÇ∫Ë™ûË®ÄÊ®°ÂûãÊé®ÁêÜÁöÑÈÄöÁî®‰∏îÈ´òÂ∫¶ÈÅ©ÊáâÊÄßËß£Ê±∫ÊñπÊ°àÁöÑÊΩõÂäõ„ÄÇChamaleonLLM ÊòØÈñãÊ∫êÁöÑÔºå‰ª•Á¢∫‰øùÊàëÂÄëÂØ¶È©óÁöÑÂèØË§áË£ΩÊÄßÔºö
https://anonymous.4open.science/r/ChamaleonLLM/

##### **BOUQuET: dataset, Benchmark and Open initiative for Universal Quality Evaluation in Translation**
2502.04314v1 by The Omnilingual MT Team, Pierre Andrews, Mikel Artetxe, Mariano Coria Meglioli, Marta R. Costa-juss√†, Joe Chuang, David Dale, Cynthia Gao, Jean Maillard, Alex Mourachko, Christophe Ropers, Safiyyah Saleem, Eduardo S√°nchez, Ioannis Tsiamas, Arina Turkatenko, Albert Ventayol-Boada, Shireen Yates

This paper presents BOUQuET, a multicentric and multi-register/domain dataset
and benchmark, and its broader collaborative extension initiative. This dataset
is handcrafted in non-English languages first, each of these source languages
being represented among the 23 languages commonly used by half of the world's
population and therefore having the potential to serve as pivot languages that
will enable more accurate translations. The dataset is specially designed to
avoid contamination and be multicentric, so as to enforce representation of
multilingual language features. In addition, the dataset goes beyond the
sentence level, as it is organized in paragraphs of various lengths. Compared
with related machine translation (MT) datasets, we show that BOUQuET has a
broader representation of domains while simplifying the translation task for
non-experts. Therefore, BOUQuET is specially suitable for the open initiative
and call for translation participation that we are launching to extend it to a
multi-way parallel corpus to any written language.

ÊëòË¶ÅÔºöÊú¨Ë´ñÊñáÊèêÂá∫ BOUQuETÔºåÈÄôÊòØ‰∏ÄÂÄãÂ§ö‰∏≠ÂøÉ„ÄÅÂ§öË®ªÂÜä/Á∂≤ÂüüË≥áÊñôÈõÜÂíåÂü∫Ê∫ñÔºå‰ª•ÂèäÂÖ∂Êõ¥Âª£Ê≥õÁöÑÂçî‰ΩúÂª∂‰º∏Ë®àÁï´„ÄÇÊ≠§Ë≥áÊñôÈõÜÈ¶ñÂÖà‰ª•ÈùûËã±Ë™ûË™ûË®ÄÊâãÂ∑•Ë£Ω‰ΩúÔºåÈÄô‰∫õÂéüÂßãË™ûË®Ä‰∏≠ÁöÑÊØè‰∏ÄÁ®ÆË™ûË®ÄÈÉΩ‰ª£Ë°®Ëëó‰∏ñÁïå‰∏ÄÂçä‰∫∫Âè£Â∏∏Áî®ÁöÑ 23 Á®ÆË™ûË®Ä‰πã‰∏ÄÔºåÂõ†Ê≠§ÊúâÂèØËÉΩ‰ΩúÁÇ∫Ê®ûÁ¥êË™ûË®ÄÔºåËÉΩÂØ¶ÁèæÊõ¥Ê∫ñÁ¢∫ÁöÑÁøªË≠Ø„ÄÇÊ≠§Ë≥áÊñôÈõÜÁ∂ìÈÅéÁâπÂà•Ë®≠Ë®àÔºåÂèØÈÅøÂÖçÊ±°Êüì‰∏¶ÊàêÁÇ∫Â§ö‰∏≠ÂøÉÔºå‰ª•‰æøÂº∑Âà∂Âü∑Ë°åÂ§öË™ûË®ÄË™ûË®ÄÁâπÂæµÁöÑË°®Á§∫„ÄÇÊ≠§Â§ñÔºåË≥áÊñôÈõÜË∂ÖË∂äÂè•Â≠êÂ±§Á¥öÔºåÂõ†ÁÇ∫ÂÆÉÊòØ‰ª•‰∏çÂêåÈï∑Â∫¶ÁöÑÊÆµËêΩÁµÑÁπîÁöÑ„ÄÇËàáÁõ∏ÈóúÊ©üÂô®ÁøªË≠Ø (MT) Ë≥áÊñôÈõÜÁõ∏ÊØîÔºåÊàëÂÄëÈ°ØÁ§∫ BOUQuET ÂÖ∑ÊúâÊõ¥Âª£Ê≥õÁöÑÁ∂≤ÂüüË°®Á§∫ÔºåÂêåÊôÇÁ∞°Âåñ‰∫ÜÈùûÂ∞àÂÆ∂ÁöÑÁøªË≠Ø‰ªªÂãô„ÄÇÂõ†Ê≠§ÔºåBOUQuET ÁâπÂà•ÈÅ©ÂêàÈñãÊîæË®àÁï´Ôºå‰∏¶ÂëºÁ±≤ÁøªË≠ØÂèÉËàáÔºåÊàëÂÄëÊ≠£Âú®ÂïüÂãïÂÆÉÔºåÂ∞áÂÖ∂Êì¥ÂÖÖÁÇ∫‰ªª‰ΩïÊõ∏Èù¢Ë™ûË®ÄÁöÑÂ§öÂêëÂπ≥Ë°åË™ûÊñôÂ∫´„ÄÇ

##### **Great Models Think Alike and this Undermines AI Oversight**
2502.04313v1 by Shashwat Goel, Joschka Struber, Ilze Amanda Auzina, Karuna K Chandra, Ponnurangam Kumaraguru, Douwe Kiela, Ameya Prabhu, Matthias Bethge, Jonas Geiping

As Language Model (LM) capabilities advance, evaluating and supervising them
at scale is getting harder for humans. There is hope that other language models
can automate both these tasks, which we refer to as "AI Oversight". We study
how model similarity affects both aspects of AI oversight by proposing a
probabilistic metric for LM similarity based on overlap in model mistakes.
Using this metric, we first show that LLM-as-a-judge scores favor models
similar to the judge, generalizing recent self-preference results. Then, we
study training on LM annotations, and find complementary knowledge between the
weak supervisor and strong student model plays a crucial role in gains from
"weak-to-strong generalization". As model capabilities increase, it becomes
harder to find their mistakes, and we might defer more to AI oversight.
However, we observe a concerning trend -- model mistakes are becoming more
similar with increasing capabilities, pointing to risks from correlated
failures. Our work underscores the importance of reporting and correcting for
model similarity, especially in the emerging paradigm of AI oversight.

ÊëòË¶ÅÔºöÈö®ËëóË™ûË®ÄÊ®°Âûã (LM) ËÉΩÂäõÁöÑÈÄ≤Ê≠•Ôºå‰∫∫È°ûË∂ä‰æÜË∂äÈõ£‰ª•Â§ßË¶èÊ®°Ë©ï‰º∞ÂíåÁõ£Áù£ÂÆÉÂÄë„ÄÇÊàëÂÄëÊúüÊúõÂÖ∂‰ªñË™ûË®ÄÊ®°ÂûãÂèØ‰ª•Ëá™ÂãïÂü∑Ë°åÈÄôÂÖ©È†Ö‰ªªÂãôÔºåËÄåÊàëÂÄëÁ®±‰πãÁÇ∫„ÄåAI Áõ£Áù£„Äç„ÄÇÊàëÂÄëÁ†îÁ©∂Ê®°ÂûãÁõ∏‰ººÂ∫¶Â¶Ç‰ΩïÂΩ±Èüø AI Áõ£Áù£ÁöÑÂÖ©ÂÄãÊñπÈù¢ÔºåÊñπÊ≥ïÊòØÊ†πÊìöÊ®°ÂûãÈåØË™§‰∏≠ÁöÑÈáçÁñäÊèêÂá∫‰∏ÄÂÄãÁî®Êñº LM Áõ∏‰ººÂ∫¶ÁöÑÊ©üÁéáÊåáÊ®ô„ÄÇ‰ΩøÁî®Ê≠§ÊåáÊ®ôÔºåÊàëÂÄëÈ¶ñÂÖàË°®ÊòéÔºåLLM ‰ΩúÁÇ∫Ë©ïÂØ©ÁöÑÂàÜÊï∏ÂÅèÂ•ΩËàáË©ïÂØ©Áõ∏‰ººÁöÑÊ®°ÂûãÔºåÊ¶ÇÊã¨‰∫ÜÊúÄËøëÁöÑËá™ÊàëÂÅèÂ•ΩÁµêÊûú„ÄÇÁÑ∂ÂæåÔºåÊàëÂÄëÁ†îÁ©∂ LM Ê®ôË®ªÁöÑË®ìÁ∑¥Ôºå‰∏¶ÁôºÁèæÂº±Áõ£Áù£ËÄÖÂíåÂº∑Â≠∏ÁîüÊ®°Âûã‰πãÈñìÁöÑ‰∫íË£úÁü•Ë≠òÂú®„ÄåÂº±Âà∞Âº∑Ê¶ÇÊã¨„ÄçÁöÑÂ¢ûÁõä‰∏≠ÁôºÊèÆ‰∫ÜÈóúÈçµ‰ΩúÁî®„ÄÇÈö®ËëóÊ®°ÂûãËÉΩÂäõÁöÑÊèêÈ´òÔºåË∂ä‰æÜË∂äÈõ£ÊâæÂà∞ÂÆÉÂÄëÁöÑÈåØË™§ÔºåÊàëÂÄëÂèØËÉΩÊúÉÊõ¥Â§öÂú∞‰æùË≥¥ AI Áõ£Áù£„ÄÇÁÑ∂ËÄåÔºåÊàëÂÄëËßÄÂØüÂà∞‰∏ÄÂÄã‰ª§‰∫∫ÊìîÊÜÇÁöÑË∂®Âã¢‚Äî‚ÄîÈö®ËëóËÉΩÂäõÁöÑÊèêÈ´òÔºåÊ®°ÂûãÈåØË™§ËÆäÂæóË∂ä‰æÜË∂äÁõ∏‰ººÔºåÈÄôË°®ÊòéÁõ∏ÈóúÊïÖÈöúÂ≠òÂú®È¢®Èö™„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂Âº∑Ë™ø‰∫ÜÂ†±ÂëäÂíåÊõ¥Ê≠£Ê®°ÂûãÁõ∏‰ººÊÄßÔºàÁâπÂà•ÊòØÂú®Êñ∞ËààÁöÑ AI Áõ£Áù£ÁØÑ‰æã‰∏≠ÔºâÁöÑÈáçË¶ÅÊÄß„ÄÇ

##### **HOG-Diff: Higher-Order Guided Diffusion for Graph Generation**
2502.04308v1 by Yiming Huang, Tolga Birdal

Graph generation is a critical yet challenging task as empirical analyses
require a deep understanding of complex, non-Euclidean structures. Although
diffusion models have recently made significant achievements in graph
generation, these models typically adapt from the frameworks designed for image
generation, making them ill-suited for capturing the topological properties of
graphs. In this work, we propose a novel Higher-order Guided Diffusion
(HOG-Diff) model that follows a coarse-to-fine generation curriculum and is
guided by higher-order information, enabling the progressive generation of
plausible graphs with inherent topological structures. We further prove that
our model exhibits a stronger theoretical guarantee than classical diffusion
frameworks. Extensive experiments on both molecular and generic graph
generation tasks demonstrate that our method consistently outperforms or
remains competitive with state-of-the-art baselines. Our code is available at
https://github.com/Yiminghh/HOG-Diff.

ÊëòË¶ÅÔºöÂúñÂΩ¢ÁîüÊàêÊòØ‰∏ÄÈ†ÖËá≥ÈóúÈáçË¶ÅÁöÑ‰ªªÂãôÔºå‰ΩÜÁî±ÊñºÁ∂ìÈ©óÂàÜÊûêÈúÄË¶ÅÂ∞çË§áÈõúÁöÑÈùûÊ≠êÂπæ‰ΩïÁµêÊßãÊúâÊ∑±ÂÖ•ÁöÑ‰∫ÜËß£ÔºåÂõ†Ê≠§ÂÖ∑ÊúâÊåëÊà∞ÊÄß„ÄÇÂÑòÁÆ°Êì¥Êï£Ê®°ÂûãÊúÄËøëÂú®ÂúñÂΩ¢ÁîüÊàêÊñπÈù¢ÂèñÂæó‰∫ÜÈ°ØËëóÈÄ≤Â±ïÔºå‰ΩÜÈÄô‰∫õÊ®°ÂûãÈÄöÂ∏∏ÊúÉÊ†πÊìöÁÇ∫ÂúñÂÉèÁîüÊàêË®≠Ë®àÁöÑÊ°ÜÊû∂ÈÄ≤Ë°åË™øÊï¥ÔºåÈÄô‰ΩøÂæóÂÆÉÂÄë‰∏çÈÅ©ÂêàÊçïÊçâÂúñÂΩ¢ÁöÑÊãìÊí≤Â±¨ÊÄß„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÊñ∞ÁöÑÈ´òÈöéÂºïÂ∞éÊì¥Êï£ (HOG-Diff) Ê®°ÂûãÔºåÂÆÉÈÅµÂæ™ÂæûÁ≤óÂà∞Á≤æÁöÑÁîüÊàêË™≤Á®ãÔºå‰∏¶Áî±È´òÈöéË≥áË®äÂºïÂ∞éÔºåËÉΩÂ§†ÈÄêÊ≠•ÁîüÊàêÂÖ∑ÊúâÂÖßÂú®ÊãìÊí≤ÁµêÊßãÁöÑÂêàÁêÜÂúñÂΩ¢„ÄÇÊàëÂÄëÈÄ≤‰∏ÄÊ≠•Ë≠âÊòéÔºåÊàëÂÄëÁöÑÊ®°ÂûãÊØîÁ∂ìÂÖ∏Êì¥Êï£Ê°ÜÊû∂ÂÖ∑ÊúâÊõ¥Âº∑ÁöÑÁêÜË´ñ‰øùË≠â„ÄÇÂú®ÂàÜÂ≠êÂíåÈÄöÁî®ÂúñÂΩ¢ÁîüÊàê‰ªªÂãô‰∏äÁöÑÂ§ßÈáèÂØ¶È©óË°®ÊòéÔºåÊàëÂÄëÁöÑÊ®°ÂûãÂßãÁµÇÂÑ™ÊñºÊàñËàáÊúÄÂÖàÈÄ≤ÁöÑÂü∫Ê∫ñ‰øùÊåÅÁ´∂Áà≠Âäõ„ÄÇÊàëÂÄëÁöÑÁ®ãÂºèÁ¢ºÂèØÂú® https://github.com/Yiminghh/HOG-Diff ÂèñÂæó„ÄÇ

##### **ScoreFlow: Mastering LLM Agent Workflows via Score-based Preference Optimization**
2502.04306v1 by Yinjie Wang, Ling Yang, Guohao Li, Mengdi Wang, Bryon Aragam

Recent research has leveraged large language model multi-agent systems for
complex problem-solving while trying to reduce the manual effort required to
build them, driving the development of automated agent workflow optimization
methods. However, existing methods remain inflexible due to representational
limitations, a lack of adaptability, and poor scalability when relying on
discrete optimization techniques. We address these challenges with ScoreFlow, a
simple yet high-performance framework that leverages efficient gradient-based
optimization in a continuous space. ScoreFlow incorporates Score-DPO, a novel
variant of the direct preference optimization method that accounts for
quantitative feedback. Across six benchmarks spanning question answering,
coding, and mathematical reasoning, ScoreFlow achieves an 8.2% improvement over
existing baselines. Moreover, it empowers smaller models to outperform larger
ones with lower inference costs. Project:
https://github.com/Gen-Verse/ScoreFlow

ÊëòË¶ÅÔºöËøëÊúüÁ†îÁ©∂Â∑≤Âà©Áî®Â§ßÂûãË™ûË®ÄÊ®°ÂûãÂ§ö‰ª£ÁêÜÁ≥ªÁµ±‰æÜËß£Ê±∫Ë§áÈõúÂïèÈ°åÔºåÂêåÊôÇË©¶ÂúñÊ∏õÂ∞ëÂª∫ÁΩÆÂÆÉÂÄëÊâÄÈúÄÁöÑÊâãÂãïÂ∑•‰ΩúÔºåÊé®ÂãïËá™ÂãïÂåñ‰ª£ÁêÜÂ∑•‰ΩúÊµÅÁ®ãÊúÄ‰Ω≥ÂåñÊñπÊ≥ïÁöÑÁôºÂ±ï„ÄÇÁÑ∂ËÄåÔºåÁèæÊúâÊñπÊ≥ïÁî±ÊñºË°®Á§∫ÈôêÂà∂„ÄÅÁº∫‰πèÈÅ©ÊáâÊÄß‰ª•ÂèäÂú®‰æùË≥¥Èõ¢Êï£ÊúÄ‰Ω≥ÂåñÊäÄË°ìÊôÇÂèØÊì¥ÂÖÖÊÄß‰∏ç‰Ω≥ÔºåÂõ†Ê≠§‰ªçÁÑ∂Áº∫‰πèÂΩàÊÄß„ÄÇÊàëÂÄëÈÄèÈÅé ScoreFlow ‰æÜÂõ†ÊáâÈÄô‰∫õÊåëÊà∞ÔºåScoreFlow ÊòØÂÄãÁ∞°ÂñÆ‰ΩÜÊïàËÉΩÈ´òÁöÑÊû∂ÊßãÔºåÂÆÉÂú®ÈÄ£Á∫åÁ©∫Èñì‰∏≠Âà©Áî®È´òÊïàÁöÑÂü∫ÊñºÊ¢ØÂ∫¶ÁöÑÊúÄ‰Ω≥Âåñ„ÄÇScoreFlow Êï¥Âêà‰∫Ü Score-DPOÔºåÈÄôÊòØ‰∏ÄÁ®ÆÊñ∞Á©éÁöÑÁõ¥Êé•ÂÅèÂ•ΩÊúÄ‰Ω≥ÂåñÊñπÊ≥ïËÆäÈ´îÔºåÂÆÉÊúÉËÄÉÈáèÈáèÂåñÂõûÈ•ã„ÄÇÂú®Ê∂µËìãÂïèÁ≠î„ÄÅÁ∑®Á¢ºÂíåÊï∏Â≠∏Êé®ÁêÜÁöÑÂÖ≠ÂÄãÂü∫Ê∫ñÊ∏¨Ë©¶‰∏≠ÔºåScoreFlow ËºÉÁèæÊúâÁöÑÂü∫Ê∫ñÁ∑öÊîπÂñÑ‰∫Ü 8.2%„ÄÇÊ≠§Â§ñÔºåÂÆÉËÉΩËÆìËºÉÂ∞èÁöÑÊ®°Âûã‰ª•ËºÉ‰ΩéÁöÑÊé®Ë´ñÊàêÊú¨ÂãùÈÅéËºÉÂ§ßÁöÑÊ®°Âûã„ÄÇÂ∞àÊ°àÔºö
https://github.com/Gen-Verse/ScoreFlow

##### **Strong Equivalence in Answer Set Programming with Constraints**
2502.04302v1 by Pedro Cabalar, Jorge Fandinno, Torsten Schaub, Philipp Wanko

We investigate the concept of strong equivalence within the extended
framework of Answer Set Programming with constraints. Two groups of rules are
considered strongly equivalent if, informally speaking, they have the same
meaning in any context. We demonstrate that, under certain assumptions, strong
equivalence between rule sets in this extended setting can be precisely
characterized by their equivalence in the logic of Here-and-There with
constraints. Furthermore, we present a translation from the language of several
clingo-based answer set solvers that handle constraints into the language of
Here-and-There with constraints. This translation enables us to leverage the
logic of Here-and-There to reason about strong equivalence within the context
of these solvers. We also explore the computational complexity of determining
strong equivalence in this context.

ÊëòË¶ÅÔºöÊàëÂÄëÂú®Â∏∂ÊúâÁ¥ÑÊùüÁöÑÊì¥ÂÖÖÂõûÁ≠îË®≠ÂÆöÁ®ãÂºèË®≠Ë®àÊû∂Êßã‰∏≠Ë™øÊü•Âº∑Á≠âÂÉπÁöÑÊ¶ÇÂøµ„ÄÇÂÖ©ÁµÑË¶èÂâáË¢´Ë™çÁÇ∫ÊòØÂº∑Á≠âÂÉπÁöÑÔºåÂ¶ÇÊûúÈùûÊ≠£ÂºèÂú∞Ë™™ÔºåÂÆÉÂÄëÂú®‰ªª‰ΩïÊÉÖÊ≥Å‰∏ãÈÉΩÊúâÁõ∏ÂêåÁöÑÂê´Áæ©„ÄÇÊàëÂÄëË≠âÊòéÔºåÂú®Êüê‰∫õÂÅáË®≠‰∏ãÔºåÊ≠§Êì¥ÂÖÖË®≠ÂÆö‰∏≠Ë¶èÂâáÈõÜ‰πãÈñìÁöÑÂº∑Á≠âÂÉπÂèØ‰ª•ÈÄèÈÅéÂÆÉÂÄëÂú®Â∏∂ÊúâÁ¥ÑÊùüÁöÑÊ≠§ËôïÂíåÂΩºËôïÈÇèËºØ‰∏≠ÁöÑÁ≠âÂÉπÊÄß‰æÜÁ≤æÁ¢∫ÊèèËø∞„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÊèê‰æõ‰∫Ü‰∏ÄÂÄãÂæûËôïÁêÜÁ¥ÑÊùüÁöÑÂπæÂÄãÂü∫Êñº Clingo ÁöÑÁ≠îÊ°àÈõÜÊ±ÇËß£Âô®ÁöÑË™ûË®ÄÂà∞Â∏∂ÊúâÁ¥ÑÊùüÁöÑÊ≠§ËôïÂíåÂΩºËôïË™ûË®ÄÁöÑÁøªË≠Ø„ÄÇÊ≠§ÁøªË≠Ø‰ΩøÊàëÂÄëËÉΩÂ§†Âà©Áî®Ê≠§ËôïÂíåÂΩºËôïÁöÑÈÇèËºØÂú®ÈÄô‰∫õÊ±ÇËß£Âô®ÁöÑËÉåÊôØ‰∏ãÊé®Ë´ñÂº∑Á≠âÂÉπ„ÄÇÊàëÂÄëÈÇÑÊé¢Ë®é‰∫ÜÂú®Ê≠§ËÉåÊôØ‰∏ãÁ¢∫ÂÆöÂº∑Á≠âÂÉπÁöÑË®àÁÆóË§áÈõúÂ∫¶„ÄÇ

##### **Beyond Prompt Content: Enhancing LLM Performance via Content-Format Integrated Prompt Optimization**
2502.04295v1 by Yuanye Liu, Jiahang Xu, Li Lyna Zhang, Qi Chen, Xuan Feng, Yang Chen, Zhongxin Guo, Yuqing Yang, Cheng Peng

Large Language Models (LLMs) have shown significant capability across various
tasks, with their real-world effectiveness often driven by prompt design. While
recent research has focused on optimizing prompt content, the role of prompt
formatting, a critical but often overlooked dimension, has received limited
systematic investigation. In this paper, we introduce Content-Format Integrated
Prompt Optimization (CFPO), an innovative methodology that jointly optimizes
both prompt content and formatting through an iterative refinement process.
CFPO leverages natural language mutations to explore content variations and
employs a dynamic format exploration strategy that systematically evaluates
diverse format options. Our extensive evaluations across multiple tasks and
open-source LLMs demonstrate that CFPO demonstrates measurable performance
improvements compared to content-only optimization methods. This highlights the
importance of integrated content-format optimization and offers a practical,
model-agnostic approach to enhancing LLM performance. Code will be available at
https://github.com/HenryLau7/CFPO.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Â∑≤Â±ïÁèæÂá∫ÂêÑÁ®Æ‰ªªÂãôÁöÑÈ°ØËëóËÉΩÂäõÔºåÂÖ∂Âú®ÁèæÂØ¶‰∏ñÁïå‰∏≠ÁöÑÊúâÊïàÊÄßÈÄöÂ∏∏ÂèñÊ±∫ÊñºÊèêÁ§∫Ë®≠Ë®à„ÄÇÂÑòÁÆ°ÊúÄËøëÁöÑÁ†îÁ©∂Â∞àÊ≥®ÊñºÊúÄ‰Ω≥ÂåñÊèêÁ§∫ÂÖßÂÆπÔºå‰ΩÜÊèêÁ§∫Ê†ºÂºèÂåñÁöÑËßíËâ≤ÊòØ‰∏ÄÂÄãÈóúÈçµ‰ΩÜÁ∂ìÂ∏∏Ë¢´ÂøΩË¶ñÁöÑÂ±§Èù¢ÔºåÂ∞öÊú™Áç≤ÂæóÁ≥ªÁµ±ÊÄßÁöÑÁ†îÁ©∂„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄë‰ªãÁ¥π‰∫ÜÂÖßÂÆπÊ†ºÂºèÊï¥ÂêàÊèêÁ§∫ÊúÄ‰Ω≥Âåñ (CFPO)ÔºåÈÄôÊòØ‰∏ÄÁ®ÆÂâµÊñ∞ÁöÑÊñπÊ≥ïÔºåÂèØÈÄèÈÅéÂèçË¶ÜÊîπÂñÑÁ®ãÂ∫èÔºåÂêåÊôÇÊúÄ‰Ω≥ÂåñÊèêÁ§∫ÂÖßÂÆπÂíåÊ†ºÂºè„ÄÇCFPO Âà©Áî®Ëá™ÁÑ∂Ë™ûË®ÄËÆäÁï∞‰æÜÊé¢Á¥¢ÂÖßÂÆπËÆäÂåñÔºå‰∏¶Êé°Áî®ÂãïÊÖãÊ†ºÂºèÊé¢Á¥¢Á≠ñÁï•ÔºåÁ≥ªÁµ±ÊÄßÂú∞Ë©ï‰º∞ÂêÑÁ®ÆÊ†ºÂºèÈÅ∏È†Ö„ÄÇÊàëÂÄëÂú®Â§öÈ†Ö‰ªªÂãôÂíåÈñãÊ∫ê LLM ‰∏≠ÈÄ≤Ë°åÁöÑÂª£Ê≥õË©ï‰º∞Ë≠âÊòéÔºåËàáÂÉÖÂÖßÂÆπÊúÄ‰Ω≥ÂåñÊñπÊ≥ïÁõ∏ÊØîÔºåCFPO Ë°®ÁèæÂá∫ÂèØË°°ÈáèÁöÑÊïàËÉΩÊîπÂñÑ„ÄÇÈÄôÁ™ÅÈ°Ø‰∫ÜÊï¥ÂêàÂÖßÂÆπÊ†ºÂºèÊúÄ‰Ω≥ÂåñÁöÑÈáçË¶ÅÊÄßÔºå‰∏¶Êèê‰æõ‰∫Ü‰∏ÄÁ®ÆÂØ¶Áî®ÁöÑ„ÄÅËàáÊ®°ÂûãÁÑ°ÈóúÁöÑÊñπÊ≥ï‰æÜÊèêÂçá LLM ÊïàËÉΩ„ÄÇÁ®ãÂºèÁ¢ºÂ∞áÊñº https://github.com/HenryLau7/CFPO Êèê‰æõ„ÄÇ

##### **A Methodology for Studying Linguistic and Cultural Change in China, 1900-1950**
2502.04286v1 by Spencer Dean Stewart

This paper presents a quantitative approach to studying linguistic and
cultural change in China during the first half of the twentieth century, a
period that remains understudied in computational humanities research. The
dramatic changes in Chinese language and culture during this time call for
greater reflection on the tools and methods used for text analysis. This
preliminary study offers a framework for analyzing Chinese texts from the late
nineteenth and twentieth centuries, demonstrating how established methods such
as word counts and word embeddings can provide new historical insights into the
complex negotiations between Western modernity and Chinese cultural discourse.

ÊëòË¶ÅÔºöÊú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÈáèÂåñÊñπÊ≥ïÔºåÁî®ÊñºÁ†îÁ©∂‰∫åÂçÅ‰∏ñÁ¥Ä‰∏äÂçäËëâ‰∏≠ÂúãÁöÑË™ûË®ÄÂíåÊñáÂåñËÆäÈÅ∑ÔºåÈÄôÊÆµÊôÇÊúüÂú®Ë®àÁÆó‰∫∫ÊñáÁ†îÁ©∂‰∏≠‰ªçÊú™ÂæóÂà∞ÂÖÖÂàÜÁ†îÁ©∂„ÄÇÈÄôÊÆµÊôÇÈñì‰∏≠ÂúãË™ûË®ÄÂíåÊñáÂåñÁöÑÂäáÁÉàËÆäÂåñÔºåË¶ÅÊ±ÇÊàëÂÄëÂ∞çÁî®ÊñºÊñáÊú¨ÂàÜÊûêÁöÑÂ∑•ÂÖ∑ÂíåÊñπÊ≥ïÈÄ≤Ë°åÊõ¥Ê∑±ÂÖ•ÁöÑÊÄùËÄÉ„ÄÇÈÄôÈ†ÖÂàùÊ≠•Á†îÁ©∂Êèê‰æõ‰∫Ü‰∏ÄÂÄãÂàÜÊûêÂçÅ‰πù‰∏ñÁ¥ÄÊú´Âíå‰∫åÂçÅ‰∏ñÁ¥Ä‰∏≠ÂúãÊñáÊú¨ÁöÑÊ°ÜÊû∂ÔºåÂ±ïÁ§∫‰∫ÜË©ûÂΩôË®àÊï∏ÂíåË©ûÂµåÂÖ•Á≠âÊó¢ÊúâÊñπÊ≥ïÂ¶Ç‰ΩïÁÇ∫Ë•øÊñπÁèæ‰ª£ÊÄßÂíå‰∏≠ÂúãÊñáÂåñË©±Ë™û‰πãÈñìÁöÑË§áÈõúÂçîÂïÜÊèê‰æõÊñ∞ÁöÑÊ≠∑Âè≤Ë¶ãËß£„ÄÇ

##### **How does a Multilingual LM Handle Multiple Languages?**
2502.04269v1 by Santhosh Kakarla, Gautama Shastry Bulusu Venkata, Aishwarya Gaddam

Multilingual language models have significantly advanced due to rapid
progress in natural language processing. Models like BLOOM 1.7B, trained on
diverse multilingual datasets, aim to bridge linguistic gaps. However, their
effectiveness in capturing linguistic knowledge, particularly for low-resource
languages, remains an open question. This study critically examines MLMs
capabilities in multilingual understanding, semantic representation, and
cross-lingual knowledge transfer. While these models perform well for
high-resource languages, they struggle with less-represented ones.
Additionally, traditional evaluation methods often overlook their internal
syntactic and semantic encoding.
  This research addresses key limitations through three objectives. First, it
assesses semantic similarity by analyzing multilingual word embeddings for
consistency using cosine similarity. Second, it examines BLOOM-1.7B and Qwen2
through Named Entity Recognition and sentence similarity tasks to understand
their linguistic structures. Third, it explores cross-lingual knowledge
transfer by evaluating generalization from high-resource to low-resource
languages in sentiment analysis and text classification.
  By leveraging linguistic probing, performance metrics, and visualizations,
this study provides insights into the strengths and limitations of MLMs. The
findings aim to enhance multilingual NLP models, ensuring better support for
both high- and low-resource languages, thereby promoting inclusivity in
language technologies.

ÊëòË¶ÅÔºöÂ§öË™ûË®ÄË™ûË®ÄÊ®°ÂûãÁî±ÊñºËá™ÁÑ∂Ë™ûË®ÄËôïÁêÜÁöÑÂø´ÈÄüÈÄ≤Â±ïËÄåÈ°ØËëóÊèêÂçá„ÄÇBLOOM 1.7B Á≠âÊ®°ÂûãÂú®Â§öÊ®£ÂåñÂ§öË™ûË®ÄË≥áÊñôÈõÜ‰∏äÂèóË®ìÔºåÊó®Âú®ÂΩåÂêàË™ûË®ÄÂ∑ÆË∑ù„ÄÇÁÑ∂ËÄåÔºåÂÆÉÂÄëÂú®Êì∑ÂèñË™ûË®ÄÁü•Ë≠òÁöÑÊïàËÉΩÔºåÁâπÂà•ÊòØÂ∞çÊñº‰ΩéË≥áÊ∫êË™ûË®ÄÔºå‰ªçÁÑ∂ÊòØ‰∏ÄÂÄãÈñãÊîæÊÄßÁöÑÂïèÈ°å„ÄÇÊú¨Á†îÁ©∂ÊâπÂà§ÊÄßÂú∞Êé¢Ë®éÂ§öË™ûË®ÄÁêÜËß£„ÄÅË™ûÁæ©Ë°®ÂæµÂíåË∑®Ë™ûË®ÄÁü•Ë≠òËΩâÁßª‰∏≠ÁöÑÂ§öË™ûË®ÄÊ®°ÂûãËÉΩÂäõ„ÄÇÈõñÁÑ∂ÈÄô‰∫õÊ®°ÂûãÂú®È´òË≥áÊ∫êË™ûË®Ä‰∏≠Ë°®ÁèæËâØÂ•ΩÔºå‰ΩÜÂÆÉÂÄëÂú®‰ΩéË≥áÊ∫êË™ûË®Ä‰∏≠ÂçªË°®Áèæ‰∏ç‰Ω≥„ÄÇÊ≠§Â§ñÔºåÂÇ≥Áµ±ÁöÑË©ï‰º∞ÊñπÊ≥ïÈÄöÂ∏∏ÊúÉÂøΩÁï•ÂÆÉÂÄëÁöÑÂÖßÈÉ®Âè•Ê≥ïÂíåË™ûÁæ©Á∑®Á¢º„ÄÇ
Êú¨Á†îÁ©∂ÈÄèÈÅé‰∏âÂÄãÁõÆÊ®ô‰æÜËß£Ê±∫ÈóúÈçµÁöÑÈôêÂà∂„ÄÇÈ¶ñÂÖàÔºåÂÆÉÈÄèÈÅé‰ΩøÁî®È§òÂº¶Áõ∏‰ººÂ∫¶ÂàÜÊûêÂ§öË™ûË®ÄË©ûÂµåÂÖ•ÁöÑ‰∏ÄËá¥ÊÄß‰æÜË©ï‰º∞Ë™ûÁæ©Áõ∏‰ººÊÄß„ÄÇÂÖ∂Ê¨°ÔºåÂÆÉÈÄèÈÅéÂëΩÂêçÂØ¶È´îËæ®Ë≠òÂíåÂè•Â≠êÁõ∏‰ººÂ∫¶‰ªªÂãô‰æÜÊé¢Ë®é BLOOM-1.7B Âíå Qwen2Ôºå‰ª•‰∫ÜËß£ÂÆÉÂÄëÁöÑË™ûË®ÄÁµêÊßã„ÄÇÁ¨¨‰∏âÔºåÂÆÉÈÄèÈÅéË©ï‰º∞ÂæûÈ´òË≥áÊ∫êË™ûË®ÄÂà∞‰ΩéË≥áÊ∫êË™ûË®ÄÁöÑÊÉÖÊÑüÂàÜÊûêÂíåÊñáÂ≠óÂàÜÈ°û‰∏≠ÁöÑÊ¶ÇÂåñÔºå‰æÜÊé¢Ë®éË∑®Ë™ûË®ÄÁü•Ë≠òËΩâÁßª„ÄÇ
Êú¨Á†îÁ©∂ÈÄèÈÅéÂà©Áî®Ë™ûË®ÄÊé¢Ê∏¨„ÄÅÊïàËÉΩÊåáÊ®ôÂíåË¶ñË¶∫ÂåñÔºåÊ∑±ÂÖ•‰∫ÜËß£Â§öË™ûË®ÄÊ®°ÂûãÁöÑÂÑ™ÈªûÂíåÈôêÂà∂„ÄÇÈÄô‰∫õÁôºÁèæÊó®Âú®Â¢ûÂº∑Â§öË™ûË®ÄËá™ÁÑ∂Ë™ûË®ÄËôïÁêÜÊ®°ÂûãÔºåÁ¢∫‰øùÂ∞çÈ´òË≥áÊ∫êÂíå‰ΩéË≥áÊ∫êË™ûË®ÄÊèê‰æõÊõ¥Â•ΩÁöÑÊîØÊè¥ÔºåÈÄ≤ËÄå‰øÉÈÄ≤Ë™ûË®ÄÊäÄË°ìÁöÑÂåÖÂÆπÊÄß„ÄÇ

##### **Cross the Gap: Exposing the Intra-modal Misalignment in CLIP via Modality Inversion**
2502.04263v1 by Marco Mistretta, Alberto Baldrati, Lorenzo Agnolucci, Marco Bertini, Andrew D. Bagdanov

Pre-trained multi-modal Vision-Language Models like CLIP are widely used
off-the-shelf for a variety of applications. In this paper, we show that the
common practice of individually exploiting the text or image encoders of these
powerful multi-modal models is highly suboptimal for intra-modal tasks like
image-to-image retrieval. We argue that this is inherently due to the
CLIP-style inter-modal contrastive loss that does not enforce any intra-modal
constraints, leading to what we call intra-modal misalignment. To demonstrate
this, we leverage two optimization-based modality inversion techniques that map
representations from their input modality to the complementary one without any
need for auxiliary data or additional trained adapters. We empirically show
that, in the intra-modal tasks of image-to-image and text-to-text retrieval,
approaching these tasks inter-modally significantly improves performance with
respect to intra-modal baselines on more than fifteen datasets. Additionally,
we demonstrate that approaching a native inter-modal task (e.g. zero-shot image
classification) intra-modally decreases performance, further validating our
findings. Finally, we show that incorporating an intra-modal term in the
pre-training objective or narrowing the modality gap between the text and image
feature embedding spaces helps reduce the intra-modal misalignment. The code is
publicly available at: https://github.com/miccunifi/Cross-the-Gap.

ÊëòË¶ÅÔºöÈ†êË®ìÁ∑¥ÁöÑÂ§öÊ®°ÊÖãË¶ñË¶∫Ë™ûË®ÄÊ®°ÂûãÔºå‰æãÂ¶Ç CLIPÔºåÂª£Ê≥õÁî®ÊñºÂêÑÁ®ÆÊáâÁî®Á®ãÂºè‰∏≠„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÂ±ïÁ§∫‰∫ÜÂñÆÁç®Âà©Áî®ÈÄô‰∫õÂº∑Â§ßÂ§öÊ®°ÊÖãÊ®°ÂûãÁöÑÊñáÂ≠óÊàñÂΩ±ÂÉèÁ∑®Á¢ºÂô®ÁöÑÂ∏∏Ë¶ãÂÅöÊ≥ïÔºåÂ∞çÊñºÂΩ±ÂÉèÂà∞ÂΩ±ÂÉèÊì∑ÂèñÁ≠âÊ®°ÊÖãÂÖß‰ªªÂãôËÄåË®ÄÔºåÊòØÈùûÂ∏∏Ê¨°‰Ω≥ÁöÑ„ÄÇÊàëÂÄëË™çÁÇ∫ÈÄôÊú¨Ë≥™‰∏äÊòØÂü∫Êñº CLIP È¢®Ê†ºÁöÑÊ®°ÊÖãÈñìÂ∞çÊØîÊêçÂ§±ÊâÄËá¥ÔºåÂÆÉ‰∏çÊúÉÂº∑Âà∂Âü∑Ë°å‰ªª‰ΩïÊ®°ÊÖãÂÖßÁ¥ÑÊùüÔºåÂ∞éËá¥ÊàëÂÄëÁ®±‰πãÁÇ∫Ê®°ÊÖãÂÖßÈåØ‰Ωç„ÄÇÁÇ∫‰∫ÜË≠âÊòéÈÄô‰∏ÄÈªûÔºåÊàëÂÄëÂà©Áî®‰∫ÜÂÖ©Á®ÆÂü∫ÊñºÊúÄ‰Ω≥ÂåñÁöÑÊ®°ÊÖãÂèçËΩâÊäÄË°ìÔºåÈÄô‰∫õÊäÄË°ìÂ∞áË°®Á§∫ÂæûÂÖ∂Ëº∏ÂÖ•Ê®°ÊÖãÊò†Â∞ÑÂà∞‰∫íË£úÊ®°ÊÖãÔºåËÄåÁÑ°ÈúÄ‰ªª‰ΩïËºîÂä©Ë≥áÊñôÊàñÈ°çÂ§ñË®ìÁ∑¥ÁöÑÈÅ©ÈÖçÂô®„ÄÇÊàëÂÄëÊÜëÁ∂ìÈ©óË°®ÊòéÔºåÂú®ÂΩ±ÂÉèÂà∞ÂΩ±ÂÉèÂíåÊñáÂ≠óÂà∞ÊñáÂ≠óÊì∑ÂèñÁöÑÊ®°ÊÖãÂÖß‰ªªÂãô‰∏≠Ôºå‰ª•Ê®°ÊÖãÈñìÊñπÂºèËôïÁêÜÈÄô‰∫õ‰ªªÂãôÊúÉÈ°ØËëóÊîπÂñÑÂú®Ë∂ÖÈÅé 15 ÂÄãË≥áÊñôÈõÜ‰∏äÁöÑÊ®°ÊÖãÂÖßÂü∫Ê∫ñÁöÑÊïàËÉΩ„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëË≠âÊòé‰ª•Ê®°ÊÖãÂÖßÊñπÂºèËôïÁêÜÂéüÁîüÊ®°ÊÖãÈñì‰ªªÂãôÔºà‰æãÂ¶ÇÈõ∂Ê¨°Â≠∏ÁøíÂΩ±ÂÉèÂàÜÈ°ûÔºâÊúÉÈôç‰ΩéÊïàËÉΩÔºåÈÄôÈÄ≤‰∏ÄÊ≠•È©óË≠â‰∫ÜÊàëÂÄëÁöÑÁôºÁèæ„ÄÇÊúÄÂæåÔºåÊàëÂÄëË°®ÊòéÂú®È†êË®ìÁ∑¥ÁõÆÊ®ô‰∏≠Á¥çÂÖ•Ê®°ÊÖãÂÖßË°ìË™ûÊàñÁ∏ÆÂ∞èÊñáÂ≠óÂíåÂΩ±ÂÉèÁâπÂæµÂµåÂÖ•Á©∫Èñì‰πãÈñìÁöÑÊ®°ÊÖãÂ∑ÆË∑ùÊúâÂä©ÊñºÊ∏õÂ∞ëÊ®°ÊÖãÂÖßÈåØ‰Ωç„ÄÇÁ®ãÂºèÁ¢ºÂÖ¨ÈñãÊñºÔºöhttps://github.com/miccunifi/Cross-the-Gap„ÄÇ

##### **Free Energy Risk Metrics for Systemically Safe AI: Gatekeeping Multi-Agent Study**
2502.04249v1 by Michael Walters, Rafael Kaufmann, Justice Sefas, Thomas Kopinski

We investigate the Free Energy Principle as a foundation for measuring risk
in agentic and multi-agent systems. From these principles we introduce a
Cumulative Risk Exposure metric that is flexible to differing contexts and
needs. We contrast this to other popular theories for safe AI that hinge on
massive amounts of data or describing arbitrarily complex world models. In our
framework, stakeholders need only specify their preferences over system
outcomes, providing straightforward and transparent decision rules for risk
governance and mitigation. This framework naturally accounts for uncertainty in
both world model and preference model, allowing for decision-making that is
epistemically and axiologically humble, parsimonious, and future-proof. We
demonstrate this novel approach in a simplified autonomous vehicle environment
with multi-agent vehicles whose driving policies are mediated by gatekeepers
that evaluate, in an online fashion, the risk to the collective safety in their
neighborhood, and intervene through each vehicle's policy when appropriate. We
show that the introduction of gatekeepers in an AV fleet, even at low
penetration, can generate significant positive externalities in terms of
increased system safety.

ÊëòË¶ÅÔºöÊàëÂÄëÊé¢Ë®éËá™Áî±ËÉΩÂéüÁêÜ‰ΩúÁÇ∫Ë°°Èáè‰ª£ÁêÜÁ≥ªÁµ±ÂíåÂ§ö‰ª£ÁêÜÁ≥ªÁµ±‰∏≠È¢®Èö™ÁöÑÂü∫Á§é„ÄÇÊ†πÊìöÈÄô‰∫õÂéüÁêÜÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü‰∏ÄÂÄãÁ¥ØÁ©çÈ¢®Èö™Êö¥Èú≤ÊåáÊ®ôÔºåÂÆÉÂèØ‰ª•ÈùàÊ¥ªÂú∞ÈÅ©Êáâ‰∏çÂêåÁöÑËÉåÊôØÂíåÈúÄÊ±Ç„ÄÇÊàëÂÄëÂ∞áÂÖ∂ËàáÂÖ∂‰ªñÊµÅË°åÁöÑÂÆâÂÖ® AI ÁêÜË´ñÈÄ≤Ë°åÂ∞çÊØîÔºåÈÄô‰∫õÁêÜË´ñ‰æùË≥¥ÊñºÂ§ßÈáèÊï∏ÊìöÊàñÊèèËø∞‰ªªÊÑèË§áÈõúÁöÑ‰∏ñÁïåÊ®°Âûã„ÄÇÂú®ÊàëÂÄëÁöÑÊ°ÜÊû∂‰∏≠ÔºåÂà©ÁõäÁõ∏ÈóúËÄÖÂè™ÈúÄÊåáÂÆö‰ªñÂÄëÂ∞çÁ≥ªÁµ±ÁµêÊûúÁöÑÂÅèÂ•ΩÔºåÂæûËÄåÁÇ∫È¢®Èö™Ê≤ªÁêÜÂíåÁ∑©Ëß£Êèê‰æõÁõ¥Êé•‰∏îÈÄèÊòéÁöÑÊ±∫Á≠ñË¶èÂâá„ÄÇÈÄôÂÄãÊ°ÜÊû∂Ëá™ÁÑ∂Âú∞ËÄÉÊÖÆ‰∫Ü‰∏ñÁïåÊ®°ÂûãÂíåÂÅèÂ•ΩÊ®°Âûã‰∏≠ÁöÑ‰∏çÁ¢∫ÂÆöÊÄßÔºåÂÖÅË®±ÈÄ≤Ë°åË™çË≠òË´ñÂíåÂÉπÂÄºË´ñ‰∏äË¨ôËôõ„ÄÅÁ∞°ÊΩî‰∏îÂÖ∑ÊúâÂâçÁûªÊÄßÁöÑÊ±∫Á≠ñ„ÄÇÊàëÂÄëÂú®‰∏ÄÂÄãÁ∞°ÂåñÁöÑËá™ÂãïÈßïÈßõËªäÁí∞Â¢É‰∏≠Â±ïÁ§∫‰∫ÜÈÄôÁ®ÆÊñ∞Á©éÁöÑÊñπÊ≥ïÔºåÂÖ∂‰∏≠Â§ö‰ª£ÁêÜËªäËºõÁöÑÈßïÈßõÁ≠ñÁï•Áî±ÈñòÈñÄÂì°Ë™øËß£ÔºåÈñòÈñÄÂì°‰ª•Âú®Á∑öÊñπÂºèË©ï‰º∞ÂÖ∂ÈÑ∞Âüü‰∏≠Â∞çÈõÜÈ´îÂÆâÂÖ®ÁöÑÈ¢®Èö™Ôºå‰∏¶Âú®ÈÅ©Áï∂ÊôÇÈÄöÈÅéÊØèËºõËªäÁöÑÁ≠ñÁï•ÈÄ≤Ë°åÂπ≤È†ê„ÄÇÊàëÂÄëË°®ÊòéÔºåÂç≥‰ΩøÂú®‰ΩéÊª≤ÈÄèÁéá‰∏ãÔºåÂú®Ëá™ÂãïÈßïÈßõËªäÈöä‰∏≠ÂºïÂÖ•ÈñòÈñÄÂì°‰πüËÉΩÁî¢ÁîüÈ°ØËëóÁöÑÊ≠£Â§ñÈÉ®ÊÄßÔºåÂæûËÄåÊèêÈ´òÁ≥ªÁµ±ÂÆâÂÖ®ÊÄß„ÄÇ

##### **TriNER: A Series of Named Entity Recognition Models For Hindi, Bengali & Marathi**
2502.04245v1 by Mohammed Amaan Dhamaskar, Rasika Ransing

India's rich cultural and linguistic diversity poses various challenges in
the domain of Natural Language Processing (NLP), particularly in Named Entity
Recognition (NER). NER is a NLP task that aims to identify and classify tokens
into different entity groups like Person, Location, Organization, Number, etc.
This makes NER very useful for downstream tasks like context-aware
anonymization. This paper details our work to build a multilingual NER model
for the three most spoken languages in India - Hindi, Bengali & Marathi. We
train a custom transformer model and fine tune a few pretrained models,
achieving an F1 Score of 92.11 for a total of 6 entity groups. Through this
paper, we aim to introduce a single model to perform NER and significantly
reduce the inconsistencies in entity groups and tag names, across the three
languages.

ÊëòË¶ÅÔºöÂç∞Â∫¶Ë±êÂØåÁöÑÊñáÂåñÂíåË™ûË®ÄÂ§öÊ®£ÊÄßÂú®Ëá™ÁÑ∂Ë™ûË®ÄËôïÁêÜ (NLP) È†òÂüü‰∏≠Â∏∂‰æÜÂêÑÁ®ÆÊåëÊà∞ÔºåÁâπÂà•ÊòØÂú®ÂëΩÂêçÂØ¶È´îË≠òÂà• (NER) ‰∏≠„ÄÇNER ÊòØ‰∏ÄÈ†Ö NLP ‰ªªÂãôÔºåÊó®Âú®Ë≠òÂà•‰∏¶Â∞áË©ûÂΩôÂàÜÈ°ûÂà∞‰∏çÂêåÁöÑÂØ¶È´îÁæ§ÁµÑ‰∏≠Ôºå‰æãÂ¶Ç‰∫∫Âêç„ÄÅÂú∞Èªû„ÄÅÁµÑÁπî„ÄÅÊï∏Â≠óÁ≠â„ÄÇÈÄô‰ΩøÂæó NER Â∞çÊñº‰∏ãÊ∏∏‰ªªÂãôÔºà‰æãÂ¶ÇÂü∫Êñº‰∏ä‰∏ãÊñáÁöÑÂåøÂêçÂåñÔºâÈùûÂ∏∏ÊúâÁî®„ÄÇÊú¨ÊñáË©≥Á¥∞‰ªãÁ¥π‰∫ÜÊàëÂÄëÁÇ∫Âç∞Â∫¶‰∏âÁ®ÆÊúÄÂª£Ê≥õ‰ΩøÁî®ÁöÑË™ûË®ÄÔºàÂç∞Âú∞Ë™û„ÄÅÂ≠üÂä†ÊãâË™ûÂíåÈ¶¨ÊãâÂú∞Ë™ûÔºâÂª∫Á´ãÂ§öË™ûË®Ä NER Ê®°ÂûãÁöÑÂ∑•‰Ωú„ÄÇÊàëÂÄëË®ìÁ∑¥‰∫Ü‰∏ÄÂÄãËá™Ë®ÇÁöÑËΩâÊèõÂô®Ê®°ÂûãÔºå‰∏¶ÂæÆË™ø‰∫ÜÂπæÂÄãÈ†êË®ìÁ∑¥Ê®°ÂûãÔºåÈáùÂ∞çÁ∏ΩÂÖ± 6 ÂÄãÂØ¶È´îÁæ§ÁµÑÈÅîÂà∞‰∫Ü 92.11 ÁöÑ F1 ÂàÜÊï∏„ÄÇÈÄèÈÅéÊú¨ÊñáÔºåÊàëÂÄëÊó®Âú®ÂºïÂÖ•‰∏ÄÂÄãÂñÆ‰∏ÄÊ®°Âûã‰æÜÂü∑Ë°å NERÔºå‰∏¶È°ØËëóÊ∏õÂ∞ë‰∏âÁ®ÆË™ûË®Ä‰∏≠ÂØ¶È´îÁæ§ÁµÑÂíåÊ®ôÁ±§ÂêçÁ®±ÁöÑ‰∏ç‰∏ÄËá¥ÊÄß„ÄÇ

##### **A Theoretical Framework for Data Efficient Multi-Source Transfer Learning Based on Cram√©r-Rao Bound**
2502.04242v1 by Qingyue Zhang, Haohao Fu, Guanbo Huang, Yaoyuan Liang, Chang Chu, Tianren Peng, Yanru Wu, Qi Li, Yang Li, Shao-Lun Huang

Multi-source transfer learning provides an effective solution to data
scarcity in real-world supervised learning scenarios by leveraging multiple
source tasks. In this field, existing works typically use all available samples
from sources in training, which constrains their training efficiency and may
lead to suboptimal results. To address this, we propose a theoretical framework
that answers the question: what is the optimal quantity of source samples
needed from each source task to jointly train the target model? Specifically,
we introduce a generalization error measure that aligns with cross-entropy
loss, and minimize it based on the Cram\'er-Rao Bound to determine the optimal
transfer quantity for each source task. Additionally, we develop an
architecture-agnostic and data-efficient algorithm OTQMS to implement our
theoretical results for training deep multi-source transfer learning models.
Experimental studies on diverse architectures and two real-world benchmark
datasets show that our proposed algorithm significantly outperforms
state-of-the-art approaches in both accuracy and data efficiency. The code and
supplementary materials are available in
https://anonymous.4open.science/r/Materials.

ÊëòË¶ÅÔºöÂ§öÊ∫êËøÅÁßªÂ≠¶‰π†ÈÄöËøáÂà©Áî®Â§öÊ∫ê‰ªªÂä°‰∏∫Áé∞ÂÆû‰∏ñÁïå‰∏≠ÁöÑÁõëÁù£Â≠¶‰π†Âú∫ÊôØ‰∏≠ÁöÑÊï∞ÊçÆÁ®ÄÁº∫ÊÄßÊèê‰æõ‰∫ÜÊúâÊïàÁöÑËß£ÂÜ≥ÊñπÊ°à„ÄÇÂú®Ëøô‰∏™È¢ÜÂüüÔºåÁé∞ÊúâÂ∑•‰ΩúÈÄöÂ∏∏Âú®ËÆ≠ÁªÉ‰∏≠‰ΩøÁî®Êù•Ëá™Ê∫êÁöÑÊâÄÊúâÂèØÁî®Ê†∑Êú¨ÔºåËøôÈôêÂà∂‰∫ÜÂÆÉ‰ª¨ÁöÑËÆ≠ÁªÉÊïàÁéáÔºåÂπ∂‰∏îÂèØËÉΩÂØºËá¥Ê¨°‰ºòÁªìÊûú„ÄÇ‰∏∫‰∫ÜËß£ÂÜ≥Ëøô‰∏™ÈóÆÈ¢òÔºåÊàë‰ª¨ÊèêÂá∫‰∫Ü‰∏Ä‰∏™ÁêÜËÆ∫Ê°ÜÊû∂Êù•ÂõûÁ≠î‰ª•‰∏ãÈóÆÈ¢òÔºöËÅîÂêàËÆ≠ÁªÉÁõÆÊ†áÊ®°ÂûãÊó∂ÔºåÈúÄË¶Å‰ªéÊØè‰∏™Ê∫ê‰ªªÂä°‰∏≠Ëé∑ÂèñÂ§öÂ∞ëÊúÄ‰ºòÊï∞ÈáèÁöÑÊ∫êÊ†∑Êú¨ÔºüÂÖ∑‰ΩìÊù•ËØ¥ÔºåÊàë‰ª¨ÂºïÂÖ•‰∫Ü‰∏Ä‰∏™‰∏é‰∫§ÂèâÁÜµÊçüÂ§±‰∏ÄËá¥ÁöÑÊ≥õÂåñËØØÂ∑ÆÂ∫¶ÈáèÔºåÂπ∂Âü∫‰∫é Cram√©r-Rao ÁïåÂØπÂÖ∂ËøõË°åÊúÄÂ∞èÂåñÔºå‰ª•Á°ÆÂÆöÊØè‰∏™Ê∫ê‰ªªÂä°ÁöÑÊúÄ‰ºò‰º†ËæìÈáè„ÄÇÊ≠§Â§ñÔºåÊàë‰ª¨ÂºÄÂèë‰∫Ü‰∏Ä‰∏™‰∏éÊû∂ÊûÑÊó†ÂÖ≥‰∏îÊï∞ÊçÆÈ´òÊïàÁöÑÁÆóÊ≥ï OTQMSÔºå‰ª•ÂÆûÁé∞Êàë‰ª¨ÁöÑÁêÜËÆ∫ÁªìÊûúÔºåÁî®‰∫éËÆ≠ÁªÉÊ∑±Â∫¶Â§öÊ∫êËøÅÁßªÂ≠¶‰π†Ê®°Âûã„ÄÇÂú®ÂêÑÁßçÊû∂ÊûÑÂíå‰∏§‰∏™ÁúüÂÆû‰∏ñÁïåÂü∫ÂáÜÊï∞ÊçÆÈõÜ‰∏äÁöÑÂÆûÈ™åÁ†îÁ©∂Ë°®ÊòéÔºåÊàë‰ª¨ÊèêÂá∫ÁöÑÁÆóÊ≥ïÂú®ÂáÜÁ°ÆÊÄßÂíåÊï∞ÊçÆÊïàÁéáÊñπÈù¢ÈÉΩÊòéÊòæ‰ºò‰∫éÊúÄÂÖàËøõÁöÑÊñπÊ≥ï„ÄÇ‰ª£Á†ÅÂíåË°•ÂÖÖÊùêÊñôÂèØÂú® https://anonymous.4open.science/r/Materials ‰∏≠Ëé∑Âæó„ÄÇ

##### **MAGA: MAssive Genre-Audience Reformulation to Pretraining Corpus Expansion**
2502.04235v1 by Xintong Hao, Ke Shen, Chenggang Li

Despite the remarkable capabilities of large language models across various
tasks, their continued scaling faces a critical challenge: the scarcity of
high-quality pretraining data. While model architectures continue to evolve,
the natural language data struggles to scale up. To tackle this bottleneck, we
propose \textbf{MA}ssive \textbf{G}enre-\textbf{A}udience~(MAGA) reformulation
method, which systematic synthesizes diverse, contextually-rich pretraining
data from existing corpus. This work makes three main contributions: (1) We
propose MAGA reformulation method, a lightweight and scalable approach for
pretraining corpus expansion, and build a 770B tokens MAGACorpus. (2) We
evaluate MAGACorpus with different data budget scaling strategies,
demonstrating consistent improvements across various model sizes (134M-13B),
establishing the necessity for next-generation large-scale synthetic
pretraining language models. (3) Through comprehensive analysis, we investigate
prompt engineering's impact on synthetic training collapse and reveal
limitations in conventional collapse detection metrics using validation losses.
Our work shows that MAGA can substantially expand training datasets while
maintaining quality, offering a reliably pathway for scaling models beyond data
limitations.

ÊëòË¶ÅÔºöÂÑòÁÆ°Â§ßÂûãË™ûË®ÄÊ®°ÂûãÂú®ÂêÑÁ®Æ‰ªªÂãô‰∏≠Â±ïÁèæÂá∫ÂçìË∂äÁöÑËÉΩÂäõÔºå‰ΩÜÊåÅÁ∫åÊì¥ÂÖÖÂçªÈù¢Ëá®‰∏ÄÈ†ÖÂö¥Â≥ªÁöÑÊåëÊà∞ÔºöÁº∫‰πèÈ´òÂìÅË≥™ÁöÑÈ†êË®ìÁ∑¥Ë≥áÊñô„ÄÇÈõñÁÑ∂Ê®°ÂûãÊû∂ÊßãÊåÅÁ∫åÊºîÈÄ≤Ôºå‰ΩÜËá™ÁÑ∂Ë™ûË®ÄË≥áÊñôÂçªÈõ£‰ª•Êì¥ÂÖÖ„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÁì∂È†∏ÔºåÊàëÂÄëÊèêÂá∫**M**assive **G**enre-**A**udience~(MAGA) ÊîπÂØ´ÊñπÊ≥ïÔºåÊúâÁ≥ªÁµ±Âú∞Á∂úÂêà‰æÜËá™ÁèæÊúâË™ûÊñôÂ∫´ÁöÑÂ§öÂÖÉ‰∏îËÑàÁµ°Ë±êÂØåÁöÑÈ†êË®ìÁ∑¥Ë≥áÊñô„ÄÇÈÄôÈ†ÖÂ∑•‰ΩúÊúâ‰∏âÂÄã‰∏ªË¶ÅË≤¢ÁçªÔºö(1) ÊàëÂÄëÊèêÂá∫ MAGA ÊîπÂØ´ÊñπÊ≥ïÔºåÈÄôÊòØ‰∏ÄÁ®ÆËºïÈáè‰∏îÂèØÊì¥ÂÖÖÁöÑÈ†êË®ìÁ∑¥Ë™ûÊñôÂ∫´Êì¥ÂÖÖÊñπÊ≥ïÔºå‰∏¶Âª∫Á´ã‰∏ÄÂÄã 770B ÂÄã token ÁöÑ MAGACorpus„ÄÇ(2) ÊàëÂÄë‰ΩøÁî®‰∏çÂêåÁöÑË≥áÊñôÈ†êÁÆóÊì¥ÂÖÖÁ≠ñÁï•Ë©ï‰º∞ MAGACorpusÔºåË≠âÊòéÂêÑÁ®ÆÊ®°ÂûãÂ§ßÂ∞è(134M-13B) ÈÉΩÊåÅÁ∫åÊèêÂçáÔºåÁ¢∫Á´ã‰∫Ü‰∏ã‰∏Ä‰ª£Â§ßË¶èÊ®°ÂêàÊàêÈ†êË®ìÁ∑¥Ë™ûË®ÄÊ®°ÂûãÁöÑÂøÖË¶ÅÊÄß„ÄÇ(3) ÈÄèÈÅéÂÖ®Èù¢ÁöÑÂàÜÊûêÔºåÊàëÂÄëÊé¢Ë®éÊèêÁ§∫Â∑•Á®ãÂ∞çÂêàÊàêË®ìÁ∑¥Â¥©ÊΩ∞ÁöÑÂΩ±ÈüøÔºå‰∏¶Êè≠Èú≤‰ΩøÁî®È©óË≠âÊêçÂ§±ÈÄ≤Ë°åÂÇ≥Áµ±Â¥©ÊΩ∞Ê™¢Ê∏¨ÊåáÊ®ôÁöÑÈôêÂà∂„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂È°ØÁ§∫ÔºåMAGA ËÉΩÂ§†Â§ßÂπÖÊì¥ÂÖÖË®ìÁ∑¥Ë≥áÊñôÈõÜÔºåÂêåÊôÇÁ∂≠ÊåÅÂìÅË≥™ÔºåÊèê‰æõ‰∏ÄÁ®ÆÂèØÈù†ÁöÑË∑ØÂæëÔºåËÆìÊ®°ÂûãÂú®Ë∂ÖË∂äË≥áÊñôÈôêÂà∂ÁöÑÂêåÊôÇÈÄ≤Ë°åÊì¥ÂÖÖ„ÄÇ

##### **A Classification System Approach in Predicting Chinese Censorship**
2502.04234v1 by Matt Prodani, Tianchu Ze, Yushen Hu

This paper is dedicated to using a classifier to predict whether a Weibo post
would be censored under the Chinese internet. Through randomized sampling from
\citeauthor{Fu2021} and Chinese tokenizing strategies, we constructed a cleaned
Chinese phrase dataset with binary censorship markings. Utilizing various
probability-based information retrieval methods on the data, we were able to
derive 4 logistic regression models for classification. Furthermore, we
experimented with pre-trained transformers to perform similar classification
tasks. After evaluating both the macro-F1 and ROC-AUC metrics, we concluded
that the Fined-Tuned BERT model exceeds other strategies in performance.

ÊëòË¶ÅÔºöÊú¨ÊñáËá¥Âäõ‰∫é‰ΩøÁî®ÂàÜÁ±ªÂô®Êù•È¢ÑÊµãÂæÆÂçöÂ∏ñÂ≠êÊòØÂê¶‰ºöÂú®‰∏≠ÂõΩÁöÑ‰∫íËÅîÁΩë‰∏äË¢´ÂÆ°Êü•„ÄÇÈÄöËøá‰ªé\citeauthor{Fu2021}Âíå‰∏≠ÊñáÊ†áËÆ∞ÂåñÁ≠ñÁï•‰∏≠ÈöèÊú∫ÊäΩÊ†∑ÔºåÊàë‰ª¨ÊûÑÂª∫‰∫Ü‰∏Ä‰∏™Â∏¶Êúâ‰∫åËøõÂà∂ÂÆ°Êü•Ê†áËÆ∞ÁöÑÂπ≤ÂáÄ‰∏≠ÊñáÁü≠ËØ≠Êï∞ÊçÆÈõÜ„ÄÇÂà©Áî®ÂêÑÁßçÂü∫‰∫éÊ¶ÇÁéáÁöÑ‰ø°ÊÅØÊ£ÄÁ¥¢ÊñπÊ≥ïÂØπÊï∞ÊçÆËøõË°åÂ§ÑÁêÜÔºåÊàë‰ª¨ËÉΩÂ§üÂØºÂá∫ 4 ‰∏™Áî®‰∫éÂàÜÁ±ªÁöÑÈÄªËæëÂõûÂΩíÊ®°Âûã„ÄÇÊ≠§Â§ñÔºåÊàë‰ª¨ÂØπÈ¢ÑËÆ≠ÁªÉÁöÑËΩ¨Êç¢Âô®ËøõË°å‰∫ÜÂÆûÈ™åÔºå‰ª•ÊâßË°åÁ±ª‰ººÁöÑÂàÜÁ±ª‰ªªÂä°„ÄÇÂú®ËØÑ‰º∞‰∫ÜÂÆèËßÇ F1 Âíå ROC-AUC ÊåáÊ†áÂêéÔºåÊàë‰ª¨ÂæóÂá∫ÁªìËÆ∫ÔºåÂæÆË∞ÉÂêéÁöÑ BERT Ê®°ÂûãÂú®ÊÄßËÉΩ‰∏ä‰ºò‰∫éÂÖ∂‰ªñÁ≠ñÁï•„ÄÇ

##### **Dark Distillation: Backdooring Distilled Datasets without Accessing Raw Data**
2502.04229v1 by Ziyuan Yang, Ming Yan, Yi Zhang, Joey Tianyi Zhou

Dataset distillation (DD) enhances training efficiency and reduces bandwidth
by condensing large datasets into smaller synthetic ones. It enables models to
achieve performance comparable to those trained on the raw full dataset and has
become a widely adopted method for data sharing. However, security concerns in
DD remain underexplored. Existing studies typically assume that malicious
behavior originates from dataset owners during the initial distillation
process, where backdoors are injected into raw datasets. In contrast, this work
is the first to address a more realistic and concerning threat: attackers may
intercept the dataset distribution process, inject backdoors into the distilled
datasets, and redistribute them to users. While distilled datasets were
previously considered resistant to backdoor attacks, we demonstrate that they
remain vulnerable to such attacks. Furthermore, we show that attackers do not
even require access to any raw data to inject the backdoors successfully.
Specifically, our approach reconstructs conceptual archetypes for each class
from the model trained on the distilled dataset. Backdoors are then injected
into these archetypes to update the distilled dataset. Moreover, we ensure the
updated dataset not only retains the backdoor but also preserves the original
optimization trajectory, thus maintaining the knowledge of the raw dataset. To
achieve this, a hybrid loss is designed to integrate backdoor information along
the benign optimization trajectory, ensuring that previously learned
information is not forgotten. Extensive experiments demonstrate that distilled
datasets are highly vulnerable to backdoor attacks, with risks pervasive across
various raw datasets, distillation methods, and downstream training strategies.
Moreover, our attack method is efficient, capable of synthesizing a malicious
distilled dataset in under one minute in certain cases.

ÊëòË¶ÅÔºö<paragraph>Ë≥áÊñôÈõÜËí∏È§æ (DD) ÈÄèÈÅéÂ∞áÂ§ßÂûãË≥áÊñôÈõÜÊøÉÁ∏ÆÊàêËºÉÂ∞èÁöÑÂêàÊàêË≥áÊñôÈõÜÔºå‰æÜÊèêÂçáË®ìÁ∑¥ÊïàÁéá‰∏¶Ê∏õÂ∞ëÈ†ªÂØ¨„ÄÇÂÆÉËÆìÊ®°ÂûãËÉΩÂ§†ÈÅîÂà∞ËàáÂú®ÂéüÂßãÂÆåÊï¥Ë≥áÊñôÈõÜ‰∏äË®ìÁ∑¥Áõ∏Â™≤ÁæéÁöÑÊïàËÉΩÔºå‰∏¶Â∑≤ÊàêÁÇ∫Ë≥áÊñôÂÖ±‰∫´ÁöÑÂª£Ê≥õÊé°Áî®ÊñπÊ≥ï„ÄÇÁÑ∂ËÄåÔºåDD ‰∏≠ÁöÑÂÆâÂÖ®ÁñëÊÖÆ‰ªçÊú™Áç≤ÂæóÂÖÖÂàÜÊé¢Ë®é„ÄÇÁèæÊúâÁ†îÁ©∂ÈÄöÂ∏∏ÂÅáË®≠ÊÉ°ÊÑèË°åÁÇ∫Ê∫êËá™ÊñºË≥áÊñôÈõÜÊìÅÊúâËÄÖÂú®ÊúÄÂàùÁöÑËí∏È§æÈÅéÁ®ã‰∏≠ÔºåÂ∞áÂæåÈñÄÊ≥®ÂÖ•ÂéüÂßãË≥áÊñôÈõÜ„ÄÇÁõ∏ÂèçÂú∞ÔºåÈÄôÈ†ÖÂ∑•‰ΩúÈ¶ñÊ¨°Êé¢Ë®é‰∏ÄÂÄãÊõ¥ÂØ¶Èöõ‰∏î‰ª§‰∫∫ÊìîÊÜÇÁöÑÂ®ÅËÑÖÔºöÊîªÊìäËÄÖÂèØËÉΩÊîîÊà™Ë≥áÊñôÈõÜÂàÜÁôºÊµÅÁ®ãÔºåÂ∞áÂæåÈñÄÊ≥®ÂÖ•Ëí∏È§æË≥áÊñôÈõÜÔºå‰∏¶Â∞áÂÖ∂ÈáçÊñ∞ÂàÜÁôºÁµ¶‰ΩøÁî®ËÄÖ„ÄÇÂÑòÁÆ°Ëí∏È§æË≥áÊñôÈõÜÂÖàÂâçË¢´Ë™çÁÇ∫ËÉΩÊäµÊäóÂæåÈñÄÊîªÊìäÔºå‰ΩÜÊàëÂÄëË≠âÊòéÂÆÉÂÄë‰ªçÁÑ∂ÂÆπÊòìÂèóÂà∞Ê≠§È°ûÊîªÊìä„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëË°®ÊòéÊîªÊìäËÄÖÁîöËá≥‰∏çÈúÄË¶ÅÂ≠òÂèñ‰ªª‰ΩïÂéüÂßãË≥áÊñôÂ∞±ËÉΩÊàêÂäüÊ≥®ÂÖ•ÂæåÈñÄ„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÊàëÂÄëÁöÑÂÅöÊ≥ïÊòØÊ†πÊìöÂú®Ëí∏È§æË≥áÊñôÈõÜ‰∏äË®ìÁ∑¥ÁöÑÊ®°ÂûãÔºåÁÇ∫ÊØèÂÄãÈ°ûÂà•ÈáçÂª∫Ê¶ÇÂøµÂéüÂûã„ÄÇÁÑ∂ÂæåÂ∞áÂæåÈñÄÊ≥®ÂÖ•ÈÄô‰∫õÂéüÂûãÔºå‰ª•Êõ¥Êñ∞Ëí∏È§æË≥áÊñôÈõÜ„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÁ¢∫‰øùÊõ¥Êñ∞ÂæåÁöÑË≥áÊñôÈõÜ‰∏çÂÉÖ‰øùÁïôÂæåÈñÄÔºåÈÇÑ‰øùÁïôÂéüÂßãÊúÄ‰Ω≥ÂåñËªåË∑°ÔºåÂæûËÄåÁ∂≠Ë≠∑ÂéüÂßãË≥áÊñôÈõÜÁöÑÁü•Ë≠ò„ÄÇÁÇ∫ÈÅîÊàêÊ≠§ÁõÆÁöÑÔºåÊàëÂÄëË®≠Ë®à‰∫Ü‰∏ÄÂÄãÊ∑∑ÂêàÊêçÂ§±ÂáΩÊï∏Ôºå‰ª•Â∞áÂæåÈñÄË≥áË®äÊï¥ÂêàÂà∞ËâØÊÄßÊúÄ‰Ω≥ÂåñËªåË∑°‰∏≠ÔºåÁ¢∫‰øùÂÖàÂâçÂ≠∏ÁøíÁöÑË≥áË®ä‰∏çÊúÉË¢´ÈÅ∫Âøò„ÄÇÂ§ßÈáèÁöÑÂØ¶È©óË≠âÊòéËí∏È§æË≥áÊñôÈõÜÊ•µÊòìÂèóÂà∞ÂæåÈñÄÊîªÊìäÔºåÈ¢®Èö™ÊôÆÈÅçÂ≠òÂú®ÊñºÂêÑÁ®ÆÂéüÂßãË≥áÊñôÈõÜ„ÄÅËí∏È§æÊñπÊ≥ïÂíå‰∏ãÊ∏∏Ë®ìÁ∑¥Á≠ñÁï•‰∏≠„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÁöÑÊîªÊìäÊñπÊ≥ïÂæàÊúâÊïàÁéáÔºåÂú®Êüê‰∫õÊÉÖÊ≥Å‰∏ãËÉΩÂ§†Âú®‰∏çÂà∞‰∏ÄÂàÜÈêòÁöÑÊôÇÈñìÂÖßÂêàÊàêÊÉ°ÊÑèÁöÑËí∏È§æË≥áÊñôÈõÜ„ÄÇ</paragraph>

##### **NLP-Based .NET CLR Event Logs Analyzer**
2502.04219v1 by Maxim Stavtsev, Sergey Shershakov

In this paper, we present a tool for analyzing .NET CLR event logs based on a
novel method inspired by Natural Language Processing (NLP) approach. Our
research addresses the growing need for effective monitoring and optimization
of software systems through detailed event log analysis. We utilize a
BERT-based architecture with an enhanced tokenization process customized to
event logs. The tool, developed using Python, its libraries, and an SQLite
database, allows both conducting experiments for academic purposes and
efficiently solving industry-emerging tasks. Our experiments demonstrate the
efficacy of our approach in compressing event sequences, detecting recurring
patterns, and identifying anomalies. The trained model shows promising results,
with a high accuracy rate in anomaly detection, which demonstrates the
potential of NLP methods to improve the reliability and stability of software
systems.

ÊëòË¶ÅÔºöÂú®Êú¨Êñá‰∏≠ÔºåÊàë‰ª¨Â±ïÁ§∫‰∫Ü‰∏ÄÂÄãÂü∫ÊñºËá™ÁÑ∂Ë™ûË®ÄËôïÁêÜ (NLP) ÊñπÊ≥ïÁöÑÂâµÊñ∞ÊñπÊ≥ïÔºåÁî®ÊñºÂàÜÊûê .NET CLR ‰∫ã‰ª∂Êó•Ë™åÁöÑÂ∑•ÂÖ∑„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÈáùÂ∞çÈÄöÈÅéË©≥Á¥∞‰∫ã‰ª∂Êó•Ë™åÂàÜÊûêÂ∞çËªüÈ´îÁ≥ªÁµ±ÈÄ≤Ë°åÊúâÊïàÁõ£ÊéßÂíåÊúÄ‰Ω≥ÂåñÁöÑÊó•ÁõäÂ¢ûÈï∑ÁöÑÈúÄÊ±Ç„ÄÇÊàëÂÄëÂà©Áî®‰∫Ü‰∏ÄÂÄãÂü∫Êñº BERT ÁöÑÊû∂ÊßãÔºå‰∏¶‰ΩøÁî®‰∫Ü‰∏ÄÂÄãÈáùÂ∞ç‰∫ã‰ª∂Êó•Ë™åÈÄ≤Ë°å‰∫ÜÂÆ¢Ë£ΩÂåñÁöÑÂ¢ûÂº∑ÂûãÂàÜË©ûËôïÁêÜÁ®ãÂ∫è„ÄÇÈÄôÂÄãÂ∑•ÂÖ∑‰ΩøÁî® Python„ÄÅÂÖ∂ÂáΩÂºèÂ∫´Âíå‰∏ÄÂÄã SQLite Ë≥áÊñôÂ∫´ÈñãÁôºÔºåÂÖÅË®±ÈÄ≤Ë°åÂ≠∏Ë°ìÁõÆÁöÑÁöÑÂØ¶È©óÔºå‰∏¶ÊúâÊïàËß£Ê±∫Êñ∞ËààÁöÑÁî¢Ê•≠‰ªªÂãô„ÄÇÊàëÂÄëÁöÑÂØ¶È©óË≠âÊòé‰∫ÜÊàëÂÄëÁöÑÊñπÊ≥ïÂú®Â£ìÁ∏Æ‰∫ã‰ª∂Â∫èÂàó„ÄÅÂÅµÊ∏¨ÈáçË§áÊ®°ÂºèÂíåË≠òÂà•Áï∞Â∏∏ÊñπÈù¢ÁöÑÊïàÂäõ„ÄÇË®ìÁ∑¥Â•ΩÁöÑÊ®°ÂûãÈ°ØÁ§∫Âá∫ÊúâÂ∏åÊúõÁöÑÁµêÊûúÔºåÂú®Áï∞Â∏∏ÂÅµÊ∏¨‰∏≠ÂÖ∑ÊúâÂæàÈ´òÁöÑÊ∫ñÁ¢∫Â∫¶ÔºåÈÄôË≠âÊòé‰∫Ü NLP ÊñπÊ≥ïÊîπÂñÑËªüÈ´îÁ≥ªÁµ±ÂèØÈù†ÊÄßÂíåÁ©©ÂÆöÊÄßÁöÑÊΩõÂäõ„ÄÇ

##### **Sports and Women's Sports: Gender Bias in Text Generation with Olympic Data**
2502.04218v1 by Laura Biester

Large Language Models (LLMs) have been shown to be biased in prior work, as
they generate text that is in line with stereotypical views of the world or
that is not representative of the viewpoints and values of historically
marginalized demographic groups. In this work, we propose using data from
parallel men's and women's events at the Olympic Games to investigate different
forms of gender bias in language models. We define three metrics to measure
bias, and find that models are consistently biased against women when the
gender is ambiguous in the prompt. In this case, the model frequently retrieves
only the results of the men's event with or without acknowledging them as such,
revealing pervasive gender bias in LLMs in the context of athletics.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Â∑≤Ë¢´Ë≠âÊòéÂú®ÂÖàÂâçÁöÑÁ†îÁ©∂‰∏≠Â≠òÂú®ÂÅèÂ∑ÆÔºåÂõ†ÁÇ∫ÂÆÉÂÄëÁî¢ÁîüÁöÑÊñáÂ≠óÁ¨¶ÂêàÂ∞ç‰∏ñÁïåÁöÑÂàªÊùøÂç∞Ë±°ÔºåÊàñËÄÖ‰∏çËÉΩ‰ª£Ë°®Ê≠∑Âè≤‰∏äË¢´ÈÇäÁ∑£ÂåñÁöÑÁæ§È´îÁöÑËßÄÈªûÂíåÂÉπÂÄºËßÄ„ÄÇÂú®ÈÄôÈ†ÖÁ†îÁ©∂‰∏≠ÔºåÊàëÂÄëÊèêË≠∞‰ΩøÁî®Â•ßÈÅãÊúÉÁî∑Â≠êÂíåÂ•≥Â≠êÂπ≥Ë°åË≥Ω‰∫ãÁöÑÊï∏Êìö‰æÜÊé¢Ë®éË™ûË®ÄÊ®°Âûã‰∏≠‰∏çÂêåÂΩ¢ÂºèÁöÑÊÄßÂà•ÂÅèË¶ã„ÄÇÊàëÂÄëÂÆöÁæ©‰∫Ü‰∏âÂÄãÊåáÊ®ô‰æÜË°°ÈáèÂÅèË¶ãÔºå‰∏¶ÁôºÁèæÁï∂ÊèêÁ§∫‰∏≠ÁöÑÊÄßÂà•‰∏çÊòéÁ¢∫ÊôÇÔºåÊ®°ÂûãÂßãÁµÇÂ∞çÂ•≥ÊÄßÊúâÂÅèË¶ã„ÄÇÂú®ÈÄôÁ®ÆÊÉÖÊ≥Å‰∏ãÔºåÊ®°ÂûãÁ∂ìÂ∏∏Âè™Ê™¢Á¥¢Áî∑Â≠êË≥Ω‰∫ãÁöÑÁµêÊûúÔºåËÄå‰∏çÁÆ°ÊòØÂê¶ÊâøË™çÂÆÉÂÄëÔºåÊè≠Á§∫‰∫Ü LLM Âú®Áî∞ÂæëËÉåÊôØ‰∏ãÁöÑÊôÆÈÅçÊÄßÂà•ÂÅèË¶ã„ÄÇ

##### **Algorithmic causal structure emerging through compression**
2502.04210v1 by Liang Wendong, Simon Buchholz, Bernhard Sch√∂lkopf

We explore the relationship between causality, symmetry, and compression. We
build on and generalize the known connection between learning and compression
to a setting where causal models are not identifiable. We propose a framework
where causality emerges as a consequence of compressing data across multiple
environments. We define algorithmic causality as an alternative definition of
causality when traditional assumptions for causal identifiability do not hold.
We demonstrate how algorithmic causal and symmetric structures can emerge from
minimizing upper bounds on Kolmogorov complexity, without knowledge of
intervention targets. We hypothesize that these insights may also provide a
novel perspective on the emergence of causality in machine learning models,
such as large language models, where causal relationships may not be explicitly
identifiable.

ÊëòË¶ÅÔºöÊàëÂÄëÊé¢Ë®éÂõ†ÊûúÈóú‰øÇ„ÄÅÂ∞çÁ®±ÊÄßËàáÂ£ìÁ∏Æ‰πãÈñìÁöÑÈóú‰øÇ„ÄÇÊàëÂÄëÂª∫Á´ã‰∏¶Ê¶ÇÊã¨‰∫ÜÂ≠∏ÁøíËàáÂ£ìÁ∏Æ‰πãÈñìÂ∑≤Áü•ÁöÑÈóúËÅØÔºå‰∏¶ÈÅãÁî®ÊñºÂõ†ÊûúÊ®°Âûã‰∏çÂèØË≠òÂà•ÁöÑË®≠ÂÆö‰∏≠„ÄÇÊàëÂÄëÊèêÂá∫‰∏ÄÂÄãÊû∂ÊßãÔºåÂÖ∂‰∏≠Âõ†ÊûúÈóú‰øÇÊúÉÈö®ËëóË∑®Â§öÂÄãÁí∞Â¢ÉÂ£ìÁ∏ÆË≥áÊñôËÄåÊµÆÁèæ„ÄÇÁï∂Âõ†ÊûúÂèØË≠òÂà•ÊÄßÁöÑÂÇ≥Áµ±ÂÅáË®≠‰∏çÊàêÁ´ãÊôÇÔºåÊàëÂÄëÂ∞áÊºîÁÆóÊ≥ïÂõ†ÊûúÈóú‰øÇÂÆöÁæ©ÁÇ∫Âõ†ÊûúÈóú‰øÇÁöÑÊõø‰ª£ÂÆöÁæ©„ÄÇÊàëÂÄëÂ±ïÁ§∫ÊºîÁÆóÊ≥ïÂõ†ÊûúÈóú‰øÇËàáÂ∞çÁ®±ÁµêÊßãÂ¶Ç‰ΩïÂæûÊúÄÂ∞èÂåñ Kolmogorov Ë§áÈõúÂ∫¶‰∏äÈôê‰∏≠ÊµÆÁèæÔºåËÄåÁÑ°ÈúÄÁü•ÈÅì‰ªãÂÖ•ÁõÆÊ®ô„ÄÇÊàëÂÄëÂÅáË®≠ÈÄô‰∫õË¶ãËß£‰πüÂèØËÉΩÊèê‰æõÈóúÊñºÊ©üÂô®Â≠∏ÁøíÊ®°Âûã‰∏≠Âõ†ÊûúÈóú‰øÇÊµÆÁèæÁöÑÊñ∞ËßÄÈªûÔºå‰æãÂ¶ÇÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÔºåÂÖ∂‰∏≠Âõ†ÊûúÈóú‰øÇÂèØËÉΩÁÑ°Ê≥ïÊòéÁ¢∫Ë≠òÂà•„ÄÇ

##### **The Best Instruction-Tuning Data are Those That Fit**
2502.04194v1 by Dylan Zhang, Qirun Dai, Hao Peng

High-quality supervised fine-tuning (SFT) data are crucial for eliciting
strong capabilities from pretrained large language models (LLMs). Typically,
instructions are paired with multiple responses sampled from other LLMs, which
are often out of the distribution of the target model to be fine-tuned. This,
at scale, can lead to diminishing returns and even hurt the models' performance
and robustness. We propose **GRAPE**, a novel SFT framework that accounts for
the unique characteristics of the target model. For each instruction, it
gathers responses from various LLMs and selects the one with the highest
probability measured by the target model, indicating that it aligns most
closely with the target model's pretrained distribution; it then proceeds with
standard SFT training.
  We first evaluate GRAPE with a controlled experiment, where we sample various
solutions for each question in UltraInteract from multiple models and fine-tune
commonly used LMs like LLaMA3.1-8B, Mistral-7B, and Qwen2.5-7B on
GRAPE-selected data. GRAPE significantly outperforms strong baselines,
including distilling from the strongest model with an absolute gain of up to
13.8%, averaged across benchmarks, and training on 3x more data with a maximum
performance improvement of 17.3%. GRAPE's strong performance generalizes to
realistic settings. We experiment with the post-training data used for Tulu3
and Olmo-2. GRAPE outperforms strong baselines trained on 4.5 times more data
by 6.1% and a state-of-the-art data selection approach by 3% on average
performance. Remarkably, using 1/3 of the data and half the number of epochs,
GRAPE enables LLaMA3.1-8B to surpass the performance of Tulu3-SFT by 3.5%.

ÊëòË¶ÅÔºöÈ´òÂìÅË≥™Áõ£Áù£ÂºèÂæÆË™ø (SFT) Ë≥áÊñôÂ∞çÊñºÂºïÁôºÈ†êË®ìÁ∑¥Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑÂº∑Â§ßÂäüËÉΩËá≥ÈóúÈáçË¶Å„ÄÇÈÄöÂ∏∏ÔºåÊåá‰ª§ÊúÉËàáÂæûÂÖ∂‰ªñ LLM Êé°Ê®£ÁöÑÂêÑÁ®ÆÂõûÊáâÈÖçÂ∞çÔºåÈÄô‰∫õÂõûÊáâÈÄöÂ∏∏Ë∂ÖÂá∫Ë¶ÅÂæÆË™øÁöÑÁõÆÊ®ôÊ®°ÂûãÁöÑÂàÜÂ∏É„ÄÇÂæûË¶èÊ®°‰æÜÁúãÔºåÈÄôÂèØËÉΩÊúÉÂ∞éËá¥Â†±ÈÖ¨ÈÅûÊ∏õÔºåÁîöËá≥ÊêçÂÆ≥Ê®°ÂûãÁöÑÊïàËÉΩÂíåÁ©©ÂÅ•ÊÄß„ÄÇÊàëÂÄëÊèêÂá∫ **GRAPE**Ôºå‰∏ÄÂÄãÊñ∞ÁöÑ SFT Ê°ÜÊû∂ÔºåÂÆÉËÄÉÊÖÆ‰∫ÜÁõÆÊ®ôÊ®°ÂûãÁöÑÁç®ÁâπÁâπÂæµ„ÄÇÂ∞çÊñºÊØèÂÄãÊåá‰ª§ÔºåÂÆÉÊúÉÂæûÂêÑÁ®Æ LLM Êî∂ÈõÜÂõûÊáâÔºå‰∏¶ÈÅ∏ÊìáÁõÆÊ®ôÊ®°ÂûãÊ∏¨ÈáèÊ©üÁéáÊúÄÈ´òÁöÑÈÇ£ÂÄãÔºåË°®Á§∫ÂÆÉËàáÁõÆÊ®ôÊ®°ÂûãÁöÑÈ†êË®ìÁ∑¥ÂàÜÂ∏ÉÊúÄÊé•ËøëÔºõÁÑ∂ÂæåÈÄ≤Ë°åÊ®ôÊ∫ñÁöÑ SFT Ë®ìÁ∑¥„ÄÇ
ÊàëÂÄëÈ¶ñÂÖà‰ΩøÁî®ÂèóÊéßÂØ¶È©óË©ï‰º∞ GRAPEÔºåÂú®Ë©≤ÂØ¶È©ó‰∏≠ÔºåÊàëÂÄëÂæûÂ§öÂÄãÊ®°Âûã‰∏≠ÁÇ∫ UltraInteract ‰∏≠ÁöÑÊØèÂÄãÂïèÈ°åÊé°Ê®£ÂêÑÁ®ÆËß£Ôºå‰∏¶Âú® GRAPE ÈÅ∏ÊìáÁöÑË≥áÊñô‰∏äÂæÆË™øÂ∏∏Áî®ÁöÑ LLMÔºå‰æãÂ¶Ç LLaMA3.1-8B„ÄÅMistral-7B Âíå Qwen2.5-7B„ÄÇGRAPE ÊòéÈ°ØÂÑ™ÊñºÂº∑Â§ßÁöÑÂü∫Ê∫ñÔºåÂåÖÊã¨ÂæûÊúÄÂº∑ÁöÑÊ®°Âûã‰∏≠ËêÉÂèñÔºåÁµïÂ∞çÂ¢ûÁõäÈ´òÈÅî 13.8%ÔºåÂú®Âü∫Ê∫ñ‰∏äÂπ≥ÂùáË®àÁÆóÔºå‰∏¶Âú®Ë≥áÊñôÂ§ö 3 ÂÄçÁöÑÊÉÖÊ≥Å‰∏ãÈÄ≤Ë°åË®ìÁ∑¥ÔºåÊïàËÉΩÊúÄÈ´òÊèêÂçá 17.3%„ÄÇGRAPE ÁöÑÂº∑Â§ßÊïàËÉΩÊé®Âª£Âà∞ÂØ¶ÈöõË®≠ÂÆö„ÄÇÊàëÂÄëÂØ¶È©ó‰∫ÜÁî®Êñº Tulu3 Âíå Olmo-2 ÁöÑË®ìÁ∑¥ÂæåË≥áÊñô„ÄÇGRAPE ÂÑ™ÊñºÂº∑Â§ßÁöÑÂü∫Ê∫ñÔºåÈÄô‰∫õÂü∫Ê∫ñÂú®Ë≥áÊñôÂ§ö 4.5 ÂÄçÁöÑÊÉÖÊ≥Å‰∏ãË®ìÁ∑¥ÔºåÂπ≥ÂùáÊïàËÉΩÈ´òÂá∫ 6.1%ÔºåËÄåÊúÄÂÖàÈÄ≤ÁöÑË≥áÊñôÈÅ∏ÊìáÊñπÊ≥ïÈ´òÂá∫ 3%„ÄÇÂÄºÂæóÊ≥®ÊÑèÁöÑÊòØÔºå‰ΩøÁî® 1/3 ÁöÑË≥áÊñôÂíå‰∏ÄÂçäÁöÑÊôÇ‰ª£ÔºåGRAPE ‰Ωø LLaMA3.1-8B Ë∂ÖË∂ä‰∫Ü Tulu3-SFT ÁöÑÊïàËÉΩÔºåÈ´òÂá∫ 3.5%„ÄÇ

##### **Multi-agent Architecture Search via Agentic Supernet**
2502.04180v1 by Guibin Zhang, Luyang Niu, Junfeng Fang, Kun Wang, Lei Bai, Xiang Wang

Large Language Model (LLM)-empowered multi-agent systems extend the cognitive
boundaries of individual agents through disciplined collaboration and
interaction, while constructing these systems often requires labor-intensive
manual designs. Despite the availability of methods to automate the design of
agentic workflows, they typically seek to identify a static, complex,
one-size-fits-all system, which, however, fails to dynamically allocate
inference resources based on the difficulty and domain of each query. To
address this challenge, we shift away from the pursuit of a monolithic agentic
system, instead optimizing the \textbf{agentic supernet}, a probabilistic and
continuous distribution of agentic architectures. We introduce MaAS, an
automated framework that samples query-dependent agentic systems from the
supernet, delivering high-quality solutions and tailored resource allocation
(\textit{e.g.}, LLM calls, tool calls, token cost). Comprehensive evaluation
across six benchmarks demonstrates that MaAS \textbf{(I)} requires only
$6\sim45\%$ of the inference costs of existing handcrafted or automated
multi-agent systems, \textbf{(II)} surpasses them by $0.54\%\sim11.82\%$, and
\textbf{(III)} enjoys superior cross-dataset and cross-LLM-backbone
transferability.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÔºàLLMÔºâË≥¶ËÉΩÁöÑÂ§ö‰∏ªÈ´îÁ≥ªÁµ±ÈÄèÈÅéÊúâÁ¥ÄÂæãÁöÑÂçî‰ΩúÂíå‰∫íÂãï‰æÜÊì¥Â±ïÂÄãÂà•‰∏ªÈ´îÁöÑË™çÁü•ÁïåÈôêÔºåËÄåÂª∫ÊßãÈÄô‰∫õÁ≥ªÁµ±ÈÄöÂ∏∏ÈúÄË¶ÅÂ§ßÈáè‰∫∫Â∑•Ë®≠Ë®à„ÄÇÂÑòÁÆ°ÊúâËá™ÂãïÂåñ‰∏ªÈ´îÂ∑•‰ΩúÊµÅÁ®ãË®≠Ë®àÁöÑÊñπÊ≥ïÔºå‰ΩÜÂÆÉÂÄëÈÄöÂ∏∏Â∞ãÊ±ÇË≠òÂà•‰∏ÄÂÄãÈùúÊÖã„ÄÅË§áÈõú„ÄÅ‰∏ÄÈ´îÈÅ©Áî®ÁöÑÁ≥ªÁµ±ÔºåÁÑ∂ËÄåÔºåÈÄôÁÑ°Ê≥ïÊ†πÊìöÊØèÂÄãÊü•Ë©¢ÁöÑÈõ£Â∫¶ÂíåÈ†òÂüüÂãïÊÖãÂàÜÈÖçÊé®Ë´ñË≥áÊ∫ê„ÄÇÁÇ∫‰∫ÜÊáâÂ∞çÈÄôÂÄãÊåëÊà∞ÔºåÊàëÂÄë‰∏çÂÜçËøΩÊ±ÇÂñÆ‰∏ÄÁöÑ‰∏ªÈ´îÁ≥ªÁµ±ÔºåËÄåÊòØÊúÄ‰Ω≥Âåñ„Äå‰∏ªÈ´îË∂ÖÁ∂≤Ë∑Ø„ÄçÔºå‰∏ÄÂÄãÊ©üÁéáÊÄßÁöÑ‰∏ªÈ´îÊû∂ÊßãÈÄ£Á∫åÂàÜ‰Ωà„ÄÇÊàëÂÄëÂºïÈÄ≤ MaASÔºå‰∏ÄÂÄãÂæûË∂ÖÁ∂≤Ë∑Ø‰∏≠ÊäΩÊ®£ËàáÊü•Ë©¢Áõ∏ÈóúÁöÑ‰∏ªÈ´îÁ≥ªÁµ±ÁöÑËá™ÂãïÂåñÊû∂ÊßãÔºåÊèê‰æõÈ´òÂìÅË≥™ÁöÑËß£Ê±∫ÊñπÊ°àÂíåÂÆ¢Ë£ΩÂåñÁöÑË≥áÊ∫êÂàÜÈÖçÔºà‰æãÂ¶ÇÔºåLLM ÂëºÂè´„ÄÅÂ∑•ÂÖ∑ÂëºÂè´„ÄÅ‰ª£Âπ£ÊàêÊú¨Ôºâ„ÄÇÂú®ÂÖ≠ÂÄãÂü∫Ê∫ñ‰∏äÁöÑÂÖ®Èù¢Ë©ï‰º∞Ë≠âÊòéÔºåMaAS Ôºà‰∏ÄÔºâÂÉÖÈúÄÁèæÊúâÊâãÂ∑•ÊàñËá™ÂãïÂåñÂ§ö‰∏ªÈ´îÁ≥ªÁµ± $6\sim45\%$ ÁöÑÊé®Ë´ñÊàêÊú¨ÔºåÔºà‰∫åÔºâË∂ÖË∂äÂÆÉÂÄë $0.54\%\sim11.82\%$Ôºå‰ª•ÂèäÔºà‰∏âÔºâ‰∫´ÊúâÂÑ™Áï∞ÁöÑË∑®Ë≥áÊñôÈõÜÂíåË∑® LLM È™®ÂππÁöÑÂèØÁßªÊ§çÊÄß„ÄÇ

##### **Lexical Substitution is not Synonym Substitution: On the Importance of Producing Contextually Relevant Word Substitutes**
2502.04173v1 by Juraj Vladika, Stephen Meisenbacher, Florian Matthes

Lexical Substitution is the task of replacing a single word in a sentence
with a similar one. This should ideally be one that is not necessarily only
synonymous, but also fits well into the surrounding context of the target word,
while preserving the sentence's grammatical structure. Recent advances in
Lexical Substitution have leveraged the masked token prediction task of
Pre-trained Language Models to generate replacements for a given word in a
sentence. With this technique, we introduce ConCat, a simple augmented approach
which utilizes the original sentence to bolster contextual information sent to
the model. Compared to existing approaches, it proves to be very effective in
guiding the model to make contextually relevant predictions for the target
word. Our study includes a quantitative evaluation, measured via sentence
similarity and task performance. In addition, we conduct a qualitative human
analysis to validate that users prefer the substitutions proposed by our
method, as opposed to previous methods. Finally, we test our approach on the
prevailing benchmark for Lexical Substitution, CoInCo, revealing potential
pitfalls of the benchmark. These insights serve as the foundation for a
critical discussion on the way in which Lexical Substitution is evaluated.

ÊëòË¶ÅÔºöË©ûÂΩôÊõøÊèõÊòØÂ∞áÂè•Â≠ê‰∏≠ÁöÑ‰∏ÄÂÄãÂñÆÂ≠óÊõøÊèõÁÇ∫‰∏ÄÂÄãÈ°û‰ººÁöÑÂñÆÂ≠ó„ÄÇÁêÜÊÉ≥ÊÉÖÊ≥Å‰∏ãÔºåÈÄôÂÄãÂñÆÂ≠ó‰∏ç‰∏ÄÂÆöÊòØÂêåÁæ©Ë©ûÔºå‰ΩÜ‰πüËÉΩÂæàÂ•ΩÂú∞ËûçÂÖ•ÁõÆÊ®ôÂñÆÂ≠óÁöÑÂë®ÂúçË™ûÂ¢ÉÔºåÂêåÊôÇ‰øùÁïôÂè•Â≠êÁöÑË™ûÊ≥ïÁµêÊßã„ÄÇË©ûÂΩôÊõøÊèõÁöÑÊúÄÊñ∞ÈÄ≤Â±ïÂà©Áî®‰∫ÜÈ†êË®ìÁ∑¥Ë™ûË®ÄÊ®°ÂûãÁöÑÈÅÆÁΩ©Á¨¶ËôüÈ†êÊ∏¨‰ªªÂãôÔºåÁÇ∫Âè•Â≠ê‰∏≠ÁöÑÁâπÂÆöÂñÆÂ≠óÁî¢ÁîüÊõøÊèõ„ÄÇ‰ΩøÁî®Ê≠§ÊäÄË°ìÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü ConCatÔºåÈÄôÊòØ‰∏ÄÁ®ÆÁ∞°ÂñÆÁöÑÊì¥ÂÖÖÊñπÊ≥ïÔºåÂà©Áî®ÂéüÂßãÂè•Â≠ê‰æÜÂä†Âº∑ÂÇ≥ÈÄÅÂà∞Ê®°ÂûãÁöÑ‰∏ä‰∏ãÊñáË≥áË®ä„ÄÇËàáÁèæÊúâÊñπÊ≥ïÁõ∏ÊØîÔºåÂÆÉË¢´Ë≠âÊòéÂú®ÂºïÂ∞éÊ®°ÂûãÂ∞çÁõÆÊ®ôÂñÆÂ≠óÈÄ≤Ë°åËàá‰∏ä‰∏ãÊñáÁõ∏ÈóúÁöÑÈ†êÊ∏¨ÊñπÈù¢ÈùûÂ∏∏ÊúâÊïà„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÂåÖÊã¨ÂÆöÈáèË©ï‰º∞ÔºåÈÄèÈÅéÂè•Â≠êÁõ∏‰ººÂ∫¶Âíå‰ªªÂãôÊïàËÉΩ‰æÜË°°Èáè„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÈÄ≤Ë°å‰∫ÜÂÆöÊÄßÁöÑ‰∫∫È°ûÂàÜÊûêÔºå‰ª•È©óË≠â‰ΩøÁî®ËÄÖÂÅèÂ•ΩÊàëÂÄëÁöÑÊñπÊ≥ïÊèêÂá∫ÁöÑÊõøÊèõÔºåËÄå‰∏çÊòØ‰ª•ÂâçÁöÑÊñπÊ≥ï„ÄÇÊúÄÂæåÔºåÊàëÂÄëÂú®Ë©ûÂΩôÊõøÊèõÁöÑÊµÅË°åÂü∫Ê∫ñ CoInCo ‰∏äÊ∏¨Ë©¶‰∫ÜÊàëÂÄëÁöÑÊñπÊ≥ïÔºåÊè≠Á§∫‰∫ÜÂü∫Ê∫ñÁöÑÊΩõÂú®Áº∫Èô∑„ÄÇÈÄô‰∫õË¶ãËß£‰ΩúÁÇ∫Â∞çË©ûÂΩôÊõøÊèõË©ï‰º∞ÊñπÂºèÈÄ≤Ë°åÊâπÂà§ÊÄßË®éË´ñÁöÑÂü∫Á§é„ÄÇ

##### **UltraIF: Advancing Instruction Following from the Wild**
2502.04153v1 by Kaikai An, Li Sheng, Ganqu Cui, Shuzheng Si, Ning Ding, Yu Cheng, Baobao Chang

Instruction-following made modern large language models (LLMs) helpful
assistants. However, the key to taming LLMs on complex instructions remains
mysterious, for that there are huge gaps between models trained by open-source
community and those trained by leading companies. To bridge the gap, we propose
a simple and scalable approach UltraIF for building LLMs that can follow
complex instructions with open-source data. UltraIF first decomposes real-world
user prompts into simpler queries, constraints, and corresponding evaluation
questions for the constraints. Then, we train an UltraComposer to compose
constraint-associated prompts with evaluation questions. This prompt composer
allows us to synthesize complicated instructions as well as filter responses
with evaluation questions. In our experiment, for the first time, we
successfully align LLaMA-3.1-8B-Base to catch up with its instruct version on 5
instruction-following benchmarks without any benchmark information, using only
8B model as response generator and evaluator. The aligned model also achieved
competitive scores on other benchmarks. Moreover, we also show that UltraIF
could further improve LLaMA-3.1-8B-Instruct through self-alignment, motivating
broader use cases for the method. Our code will be available at
https://github.com/kkk-an/UltraIF.

ÊëòË¶ÅÔºö<paragraph>ÈÅµÂæ™Êåá‰ª§‰ΩøÁé∞‰ª£Â§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÔºàLLMÔºâÊàê‰∏∫ÊúâÁî®ÁöÑÂä©Êâã„ÄÇÁÑ∂ËÄåÔºåÂú®Â§çÊùÇÊåá‰ª§‰∏äÈ©ØÊúç LLM ÁöÑÂÖ≥ÈîÆ‰ªçÁÑ∂ÊòØ‰∏™Ë∞úÔºåÂõ†‰∏∫ÂºÄÊ∫êÁ§æÂå∫ËÆ≠ÁªÉÁöÑÊ®°ÂûãÂíåÈ¢ÜÂÖàÂÖ¨Âè∏ËÆ≠ÁªÉÁöÑÊ®°Âûã‰πãÈó¥Â≠òÂú®Â∑®Â§ßÂ∑ÆË∑ù„ÄÇ‰∏∫‰∫ÜÂº•ÂêàËøô‰∏ÄÂ∑ÆË∑ùÔºåÊàë‰ª¨ÊèêÂá∫‰∫Ü‰∏ÄÁßçÁÆÄÂçï‰∏îÂèØÊâ©Â±ïÁöÑÊñπÊ≥ï UltraIFÔºåÁî®‰∫éÊûÑÂª∫ËÉΩÂ§üÈÅµÂæ™ÂºÄÊ∫êÊï∞ÊçÆÂ§çÊùÇÊåá‰ª§ÁöÑ LLM„ÄÇUltraIF È¶ñÂÖàÂ∞ÜÁé∞ÂÆû‰∏ñÁïå‰∏≠ÁöÑÁî®Êà∑ÊèêÁ§∫ÂàÜËß£‰∏∫Êõ¥ÁÆÄÂçïÁöÑÊü•ËØ¢„ÄÅÁ∫¶ÊùüÂíåÈíàÂØπÁ∫¶ÊùüÁöÑÁõ∏Â∫îËØÑ‰º∞ÈóÆÈ¢ò„ÄÇÁÑ∂ÂêéÔºåÊàë‰ª¨ËÆ≠ÁªÉ‰∏Ä‰∏™ UltraComposer Êù•ÁºñÂÜôÂ∏¶ÊúâËØÑ‰º∞ÈóÆÈ¢òÁöÑÁ∫¶ÊùüÁõ∏ÂÖ≥ÊèêÁ§∫„ÄÇËøô‰∏™ÊèêÁ§∫ÁºñÂÜôÂô®‰ΩøÊàë‰ª¨ËÉΩÂ§üÁªºÂêàÂ§çÊùÇÁöÑÊåá‰ª§‰ª•Âèä‰ΩøÁî®ËØÑ‰º∞ÈóÆÈ¢òËøáÊª§ÂìçÂ∫î„ÄÇÂú®Êàë‰ª¨ÁöÑÂÆûÈ™å‰∏≠ÔºåÊàë‰ª¨È¶ñÊ¨°ÊàêÂäüË∞ÉÊï¥ LLaMA-3.1-8B-BaseÔºå‰ΩøÂÖ∂Âú® 5 ‰∏™Êåá‰ª§ÈÅµÂæ™Âü∫ÂáÜ‰∏äËµ∂‰∏äÂÖ∂Êåá‰ª§ÁâàÊú¨ÔºåËÄåÊó†ÈúÄ‰ªª‰ΩïÂü∫ÂáÜ‰ø°ÊÅØÔºå‰ªÖ‰ΩøÁî® 8B Ê®°Âûã‰Ωú‰∏∫ÂìçÂ∫îÁîüÊàêÂô®ÂíåËØÑ‰º∞Âô®„ÄÇË∞ÉÊï¥ÂêéÁöÑÊ®°ÂûãÂú®ÂÖ∂‰ªñÂü∫ÂáÜ‰∏ä‰πüÂèñÂæó‰∫ÜÊúâÁ´û‰∫âÂäõÁöÑÂàÜÊï∞„ÄÇÊ≠§Â§ñÔºåÊàë‰ª¨ËøòË°®Êòé UltraIF ÂèØ‰ª•ÈÄöËøáËá™Ë∞ÉÊï¥Ëøõ‰∏ÄÊ≠•ÊîπËøõ LLaMA-3.1-8B-InstructÔºå‰ªéËÄåÊøÄÂèëËØ•ÊñπÊ≥ïÁöÑÊõ¥ÂπøÊ≥õÁî®‰æã„ÄÇÊàë‰ª¨ÁöÑ‰ª£Á†ÅÂ∞ÜÂú® https://github.com/kkk-an/UltraIF ‰∏äÊèê‰æõ„ÄÇ</paragraph>

##### **Synthetic Datasets for Machine Learning on Spatio-Temporal Graphs using PDEs**
2502.04140v1 by Jost Arndt, Utku Isil, Michael Detzel, Wojciech Samek, Jackie Ma

Many physical processes can be expressed through partial differential
equations (PDEs). Real-world measurements of such processes are often collected
at irregularly distributed points in space, which can be effectively
represented as graphs; however, there are currently only a few existing
datasets. Our work aims to make advancements in the field of PDE-modeling
accessible to the temporal graph machine learning community, while addressing
the data scarcity problem, by creating and utilizing datasets based on PDEs. In
this work, we create and use synthetic datasets based on PDEs to support
spatio-temporal graph modeling in machine learning for different applications.
More precisely, we showcase three equations to model different types of
disasters and hazards in the fields of epidemiology, atmospheric particles, and
tsunami waves. Further, we show how such created datasets can be used by
benchmarking several machine learning models on the epidemiological dataset.
Additionally, we show how pre-training on this dataset can improve model
performance on real-world epidemiological data. The presented methods enable
others to create datasets and benchmarks customized to individual requirements.
The source code for our methodology and the three created datasets can be found
on https://github.com/github-usr-ano/Temporal_Graph_Data_PDEs.

ÊëòË¶ÅÔºöË®±Â§öÁâ©ÁêÜÁ®ãÂ∫èÂèØ‰ª•Áî®ÂÅèÂæÆÂàÜÊñπÁ®ãÂºè (PDE) Ë°®Á§∫„ÄÇÊ≠§È°ûÁ®ãÂ∫èÁöÑÁúüÂØ¶‰∏ñÁïåÊ∏¨ÈáèÈÄöÂ∏∏Êî∂ÈõÜÊñºÁ©∫Èñì‰∏≠‰∏çË¶èÂâáÂàÜÂ∏ÉÁöÑÈªûÔºåÈÄôÂèØ‰ª•ÊúâÊïàÂú∞Ë°®Á§∫ÁÇ∫ÂúñÂΩ¢ÔºõÁÑ∂ËÄåÔºåÁõÆÂâçÂÉÖÊúâÂ∞ëÊï∏ÁèæÊúâË≥áÊñôÈõÜ„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂Êó®Âú®ËÆìÊôÇÂ∫èÂúñÂΩ¢Ê©üÂô®Â≠∏ÁøíÁ§æÁæ§ËÉΩÂ§†ÈÄ≤Â±ï PDE Âª∫Ê®°È†òÂüüÔºåÂêåÊôÇÈÄèÈÅéÂª∫Á´ã‰∏¶‰ΩøÁî®Âü∫Êñº PDE ÁöÑË≥áÊñôÈõÜ‰æÜËß£Ê±∫Ë≥áÊñôÁ®ÄÂ∞ëÁöÑÂïèÈ°å„ÄÇÂú®ÈÄôÈ†ÖÁ†îÁ©∂‰∏≠ÔºåÊàëÂÄëÂª∫Á´ã‰∏¶‰ΩøÁî®Âü∫Êñº PDE ÁöÑÂêàÊàêË≥áÊñôÈõÜÔºå‰ª•ÊîØÊè¥Ê©üÂô®Â≠∏Áøí‰∏≠‰∏çÂêåÊáâÁî®Á®ãÂºèÁöÑÊôÇÁ©∫ÂúñÂΩ¢Âª∫Ê®°„ÄÇÊõ¥Á≤æÁ¢∫Âú∞Ë™™ÔºåÊàëÂÄëÂ±ïÁ§∫‰∫Ü‰∏âÂÄãÊñπÁ®ãÂºèÔºå‰ª•Ê®°Êì¨ÊµÅË°åÁóÖÂ≠∏„ÄÅÂ§ßÊ∞£Á≤íÂ≠êËàáÊµ∑ÂòØÊ≥¢Á≠âÈ†òÂüü‰∏≠‰∏çÂêåÈ°ûÂûãÁöÑÁÅΩÈõ£ËàáÂç±ÂÆ≥„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÂ±ïÁ§∫‰∫ÜÂ¶Ç‰ΩïÈÄèÈÅéÂú®ÊµÅË°åÁóÖÂ≠∏Ë≥áÊñôÈõÜ‰∏äÂ∞çÂ§öÂÄãÊ©üÂô®Â≠∏ÁøíÊ®°ÂûãÈÄ≤Ë°åÂü∫Ê∫ñÊ∏¨Ë©¶Ôºå‰æÜ‰ΩøÁî®Ê≠§È°ûÂª∫Á´ãÁöÑË≥áÊñôÈõÜ„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÂ±ïÁ§∫‰∫ÜÂ¶Ç‰ΩïÈÄèÈÅéÂú®Ê≠§Ë≥áÊñôÈõÜ‰∏äÈÄ≤Ë°åÈ†êË®ìÁ∑¥Ôºå‰æÜÊîπÂñÑÊ®°ÂûãÂú®ÁúüÂØ¶‰∏ñÁïåÊµÅË°åÁóÖÂ≠∏Ë≥áÊñô‰∏äÁöÑÊïàËÉΩ„ÄÇÊâÄÊèêÂá∫ÁöÑÊñπÊ≥ïËÆìÂÖ∂‰ªñ‰∫∫ËÉΩÂ§†Âª∫Á´ãËá™Ë®ÇÊñºÂÄãÂà•ÈúÄÊ±ÇÁöÑË≥áÊñôÈõÜËàáÂü∫Ê∫ñ„ÄÇÊàëÂÄëÁöÑÊñπÊ≥ïËàá‰∏âÂÄãÂª∫Á´ãÁöÑË≥áÊñôÈõÜÁöÑÂéüÂßãÁ®ãÂºèÁ¢ºÂèØ‰ª•Âú® https://github.com/github-usr-ano/Temporal_Graph_Data_PDEs ÊâæÂà∞„ÄÇ

##### **The Order Effect: Investigating Prompt Sensitivity in Closed-Source LLMs**
2502.04134v1 by Bryan Guan, Tanya Roosta, Peyman Passban, Mehdi Rezagholizadeh

As large language models (LLMs) become integral to diverse applications,
ensuring their reliability under varying input conditions is crucial. One key
issue affecting this reliability is order sensitivity, wherein slight
variations in input arrangement can lead to inconsistent or biased outputs.
Although recent advances have reduced this sensitivity, the problem remains
unresolved. This paper investigates the extent of order sensitivity in
closed-source LLMs by conducting experiments across multiple tasks, including
paraphrasing, relevance judgment, and multiple-choice questions. Our results
show that input order significantly affects performance across tasks, with
shuffled inputs leading to measurable declines in output accuracy. Few-shot
prompting demonstrates mixed effectiveness and offers partial mitigation,
however, fails to fully resolve the problem. These findings highlight
persistent risks, particularly in high-stakes applications, and point to the
need for more robust LLMs or improved input-handling techniques in future
development.

ÊëòË¶ÅÔºöÈö®ËëóÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÊàêÁÇ∫ÂêÑÁ®ÆÊáâÁî®Á®ãÂºè‰∏≠‰∏çÂèØÊàñÁº∫ÁöÑ‰∏ÄÈÉ®ÂàÜÔºåÁ¢∫‰øùÂÆÉÂÄëÂú®‰∏çÂêåÁöÑËº∏ÂÖ•Ê¢ù‰ª∂‰∏ãÈÉΩËÉΩÂèØÈù†ÈÅã‰ΩúËá≥ÈóúÈáçË¶Å„ÄÇÂΩ±ÈüøÈÄôÂÄãÂèØÈù†ÊÄßÁöÑ‰∏ªË¶ÅÂïèÈ°å‰πã‰∏ÄÊòØÈ†ÜÂ∫èÊïèÊÑüÊÄßÔºåÂÖ∂‰∏≠Ëº∏ÂÖ•ÊéíÂàóÁöÑÂæÆÂ∞èËÆäÂåñÂèØËÉΩÂ∞éËá¥‰∏ç‰∏ÄËá¥ÊàñÊúâÂÅèÂ∑ÆÁöÑËº∏Âá∫„ÄÇÂÑòÁÆ°ÊúÄËøëÁöÑÈÄ≤Â±ïÂ∑≤Á∂ìÈôç‰Ωé‰∫ÜÈÄôÁ®ÆÊïèÊÑüÊÄßÔºå‰ΩÜÈÄôÂÄãÂïèÈ°å‰ªçÊú™ÂæóÂà∞Ëß£Ê±∫„ÄÇÊú¨ÊñáÈÄèÈÅéÂú®Â§öÈ†Ö‰ªªÂãô‰∏≠ÈÄ≤Ë°åÂØ¶È©ó‰æÜÊé¢Ë®éÈñâÊ∫ê LLM ‰∏≠È†ÜÂ∫èÊïèÊÑüÊÄßÁöÑÁ®ãÂ∫¶ÔºåÂåÖÊã¨ÊîπÂØ´„ÄÅÁõ∏ÈóúÊÄßÂà§Êñ∑ÂíåÂ§öÈÅ∏È°å„ÄÇÊàëÂÄëÁöÑÁµêÊûúÈ°ØÁ§∫ÔºåËº∏ÂÖ•È†ÜÂ∫èÊúÉÈ°ØËëóÂΩ±ÈüøÂêÑÈ†Ö‰ªªÂãôÁöÑÊïàËÉΩÔºåËº∏ÂÖ•È†ÜÂ∫èÊâì‰∫ÇÊúÉÂ∞éËá¥Ëº∏Âá∫Ê∫ñÁ¢∫Â∫¶ÊòéÈ°Ø‰∏ãÈôç„ÄÇÂ∞ëÊ¨°ÊèêÁ§∫Â±ïÁ§∫Âá∫‰∏çÂêåÁöÑÊïàÊûúÔºå‰∏¶Êèê‰æõÈÉ®ÂàÜÁ∑©Ëß£Ôºå‰ΩÜÁÑ°Ê≥ïÂÆåÂÖ®Ëß£Ê±∫ÂïèÈ°å„ÄÇÈÄô‰∫õÁôºÁèæÁ™ÅÈ°Ø‰∫ÜÊåÅÁ∫åÂ≠òÂú®ÁöÑÈ¢®Èö™ÔºåÁâπÂà•ÊòØÂú®È´òÈ¢®Èö™ÊáâÁî®‰∏≠Ôºå‰∏¶ÊåáÂá∫Êú™‰æÜÈñãÁôº‰∏≠ÈúÄË¶ÅÊõ¥Âº∑Â§ßÁöÑ LLM ÊàñÊîπÈÄ≤ÁöÑËº∏ÂÖ•ËôïÁêÜÊäÄË°ì„ÄÇ

##### **Llasa: Scaling Train-Time and Inference-Time Compute for Llama-based Speech Synthesis**
2502.04128v1 by Zhen Ye, Xinfa Zhu, Chi-Min Chan, Xinsheng Wang, Xu Tan, Jiahe Lei, Yi Peng, Haohe Liu, Yizhu Jin, Zheqi DAI, Hongzhan Lin, Jianyi Chen, Xingjian Du, Liumeng Xue, Yunlin Chen, Zhifei Li, Lei Xie, Qiuqiang Kong, Yike Guo, Wei Xue

Recent advances in text-based large language models (LLMs), particularly in
the GPT series and the o1 model, have demonstrated the effectiveness of scaling
both training-time and inference-time compute. However, current
state-of-the-art TTS systems leveraging LLMs are often multi-stage, requiring
separate models (e.g., diffusion models after LLM), complicating the decision
of whether to scale a particular model during training or testing. This work
makes the following contributions: First, we explore the scaling of train-time
and inference-time compute for speech synthesis. Second, we propose a simple
framework Llasa for speech synthesis that employs a single-layer vector
quantizer (VQ) codec and a single Transformer architecture to fully align with
standard LLMs such as Llama. Our experiments reveal that scaling train-time
compute for Llasa consistently improves the naturalness of synthesized speech
and enables the generation of more complex and accurate prosody patterns.
Furthermore, from the perspective of scaling inference-time compute, we employ
speech understanding models as verifiers during the search, finding that
scaling inference-time compute shifts the sampling modes toward the preferences
of specific verifiers, thereby improving emotional expressiveness, timbre
consistency, and content accuracy. In addition, we released the checkpoint and
training code for our TTS model (1B, 3B, 8B) and codec model publicly
available.

ÊëòË¶ÅÔºöÊúÄËøëÂú®‰ª• GPT Á≥ªÂàóÂíå o1 Ê®°ÂûãÁÇ∫È¶ñÁöÑÊñáÊú¨Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ‰∏äÁöÑÈÄ≤Â±ïÔºåÂ∑≤Ë≠âÊòé‰∫ÜÊì¥ÂÖÖË®ìÁ∑¥ÊôÇÈñìÂíåÊé®Ë´ñÊôÇÈñìÈÅãÁÆóÁöÑÊúâÊïàÊÄß„ÄÇÁÑ∂ËÄåÔºåÁõÆÂâçÂà©Áî® LLM ÁöÑÊúÄÂÖàÈÄ≤ TTS Á≥ªÁµ±ÈÄöÂ∏∏ÊòØÂ§öÈöéÊÆµÁöÑÔºåÈúÄË¶ÅÂÄãÂà•ÁöÑÊ®°ÂûãÔºà‰æãÂ¶ÇÔºåLLM ‰πãÂæåÁöÑÊì¥Êï£Ê®°ÂûãÔºâÔºåÈÄô‰ΩøÂæóÂú®Ë®ìÁ∑¥ÊàñÊ∏¨Ë©¶ÊúüÈñìÊì¥ÂÖÖÁâπÂÆöÊ®°ÂûãÁöÑÊ±∫ÂÆöËÆäÂæóË§áÈõú„ÄÇÊú¨Á†îÁ©∂ÂÅöÂá∫‰∫Ü‰ª•‰∏ãË≤¢ÁçªÔºöÈ¶ñÂÖàÔºåÊàëÂÄëÊé¢Ë®é‰∫ÜË™ûÈü≥ÂêàÊàêÁöÑË®ìÁ∑¥ÊôÇÈñìÂíåÊé®Ë´ñÊôÇÈñìÈÅãÁÆóÁöÑÊì¥ÂÖÖ„ÄÇÂÖ∂Ê¨°ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü Llasa ÁöÑÁ∞°ÂñÆÊû∂ÊßãÔºåÁî®ÊñºË™ûÈü≥ÂêàÊàêÔºåÊé°Áî®ÂñÆÂ±§ÂêëÈáèÈáèÂåñÂô® (VQ) Á∑®Ëß£Á¢ºÂô®ÂíåÂñÆ‰∏Ä Transformer Êû∂ÊßãÔºå‰ª•ÂÆåÂÖ®Á¨¶Âêà Llama Á≠âÊ®ôÊ∫ñ LLM„ÄÇÊàëÂÄëÁöÑÂØ¶È©óË°®ÊòéÔºåÊì¥ÂÖÖ Llasa ÁöÑË®ìÁ∑¥ÊôÇÈñìÈÅãÁÆóÊåÅÁ∫åÊîπÂñÑ‰∫ÜÂêàÊàêË™ûÈü≥ÁöÑËá™ÁÑ∂ÊÄßÔºå‰∏¶ËÉΩÁî¢ÁîüÊõ¥Ë§áÈõú‰∏îÊ∫ñÁ¢∫ÁöÑÈüªÂæãÊ®°Âºè„ÄÇÊ≠§Â§ñÔºåÂæûÊì¥ÂÖÖÊé®Ë´ñÊôÇÈñìÈÅãÁÆóÁöÑËßíÂ∫¶‰æÜÁúãÔºåÊàëÂÄëÂú®ÊêúÂ∞ãÊúüÈñìÊé°Áî®Ë™ûÈü≥ÁêÜËß£Ê®°Âûã‰ΩúÁÇ∫È©óË≠âÂô®ÔºåÁôºÁèæÊì¥ÂÖÖÊé®Ë´ñÊôÇÈñìÈÅãÁÆóÂ∞áÊäΩÊ®£Ê®°ÂºèËΩâÁßªÂà∞ÁâπÂÆöÈ©óË≠âÂô®ÁöÑÂÅèÂ•ΩÔºåÂæûËÄåÊîπÂñÑÊÉÖÁ∑íË°®ÈÅîÂäõ„ÄÅÈü≥Ëâ≤‰∏ÄËá¥ÊÄßÂíåÂÖßÂÆπÊ∫ñÁ¢∫ÊÄß„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÂÖ¨ÈñãÁôºÂ∏É‰∫ÜÊàëÂÄëÁöÑ TTS Ê®°Âûã (1B„ÄÅ3B„ÄÅ8B) ÂíåÁ∑®Ëß£Á¢ºÂô®Ê®°ÂûãÁöÑÊ™¢Êü•ÈªûÂíåË®ìÁ∑¥Á®ãÂºèÁ¢º„ÄÇ

##### **VTutor: An Open-Source SDK for Generative AI-Powered Animated Pedagogical Agents with Multi-Media Output**
2502.04103v1 by Eason Chen, Chengyu Lin, Xinyi Tang, Aprille Xi, Canwen Wang, Jionghao Lin, Kenneth R Koedinger

The rapid evolution of large language models (LLMs) has transformed
human-computer interaction (HCI), but the interaction with LLMs is currently
mainly focused on text-based interactions, while other multi-model approaches
remain under-explored. This paper introduces VTutor, an open-source Software
Development Kit (SDK) that combines generative AI with advanced animation
technologies to create engaging, adaptable, and realistic APAs for human-AI
multi-media interactions. VTutor leverages LLMs for real-time personalized
feedback, advanced lip synchronization for natural speech alignment, and WebGL
rendering for seamless web integration. Supporting various 2D and 3D character
models, VTutor enables researchers and developers to design emotionally
resonant, contextually adaptive learning agents. This toolkit enhances learner
engagement, feedback receptivity, and human-AI interaction while promoting
trustworthy AI principles in education. VTutor sets a new standard for
next-generation APAs, offering an accessible, scalable solution for fostering
meaningful and immersive human-AI interaction experiences. The VTutor project
is open-sourced and welcomes community-driven contributions and showcases.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑÂø´ÈÄüÊºîÈÄ≤ËΩâËÆä‰∫Ü‰∫∫Ê©ü‰∫íÂãï (HCI)Ôºå‰ΩÜËàá LLM ÁöÑ‰∫íÂãïÁõÆÂâç‰∏ªË¶ÅÈõÜ‰∏≠Âú®Âü∫ÊñºÊñáÂ≠óÁöÑ‰∫íÂãï‰∏äÔºåËÄåÂÖ∂‰ªñÂ§öÊ®°ÂºèÊñπÊ≥ï‰ªçÊú™ÂæóÂà∞ÂÖÖÂàÜÊé¢Á¥¢„ÄÇÊú¨Êñá‰ªãÁ¥π‰∫Ü VTutorÔºåÈÄôÊòØ‰∏ÄÂÄãÈñãÊ∫êËªüÈ´îÈñãÁôºÂ•ó‰ª∂ (SDK)ÔºåÂÆÉÂ∞áÁîüÊàêÂºè AI ËàáÂÖàÈÄ≤ÁöÑÂãïÁï´ÊäÄË°ìÁõ∏ÁµêÂêàÔºåÁÇ∫‰∫∫Ê©üÂ§öÂ™íÈ´î‰∫íÂãïÂâµÈÄ†‰∫ÜÂºï‰∫∫ÂÖ•Âãù„ÄÅÈÅ©ÊáâÊÄßÂº∑‰∏îÈÄºÁúüÁöÑ APA„ÄÇVTutor Âà©Áî® LLM ÈÄ≤Ë°åÂç≥ÊôÇÂÄãÊÄßÂåñÂõûÈ•ã„ÄÅÂÖàÈÄ≤ÁöÑÂîáÂΩ¢ÂêåÊ≠•‰ª•ÂØ¶ÁèæËá™ÁÑ∂ÁöÑË™ûÈü≥Â∞çÈΩäÔºå‰ª•Âèä WebGL Ê∏≤Êüì‰ª•ÂØ¶ÁèæÁÑ°Á∏´ÁöÑÁ∂≤Ë∑ØÊï¥Âêà„ÄÇVTutor ÊîØÊè¥ÂêÑÁ®Æ 2D Âíå 3D ËßíËâ≤Ê®°ÂûãÔºå‰ΩøÁ†îÁ©∂‰∫∫Âì°ÂíåÈñãÁôº‰∫∫Âì°ËÉΩÂ§†Ë®≠Ë®àÂá∫ÊÉÖÊÑüÂÖ±È≥¥‰∏îÈÅ©ÊáâËÑàÁµ°ÁöÑÂ≠∏Áøí‰ª£ÁêÜ„ÄÇÊ≠§Â∑•ÂÖ∑ÂåÖÂ¢ûÂº∑‰∫ÜÂ≠∏ÁøíËÄÖÁöÑÂèÉËàáÂ∫¶„ÄÅÂõûÈ•ãÊé•ÂèóÂ∫¶Âíå‰∫∫Ê©ü‰∫íÂãïÔºåÂêåÊôÇÂú®ÊïôËÇ≤‰∏≠ÂÆ£Â∞éÂÄºÂæó‰ø°Ë≥¥ÁöÑ AI ÂéüÂâá„ÄÇVTutor ÁÇ∫‰∏ã‰∏Ä‰ª£ APA Ë®≠ÂÆö‰∫ÜÊñ∞Ê®ôÊ∫ñÔºåÊèê‰æõ‰∫Ü‰∏ÄÂÄãÂèØÂ≠òÂèñ„ÄÅÂèØÊì¥ÂÖÖÁöÑËß£Ê±∫ÊñπÊ°àÔºå‰ª•‰øÉÈÄ≤ÊúâÊÑèÁæ©‰∏îË∫´Ëá®ÂÖ∂Â¢ÉÁöÑ AI ‰∫∫Ê©ü‰∫íÂãïÈ´îÈ©ó„ÄÇVTutor ÈÄôÂÄãÂ∞àÊ°àÊòØÈñãÊ∫êÁöÑÔºåÊ≠°ËøéÁ§æÁæ§È©ÖÂãïÁöÑË≤¢ÁçªÂíåÂ±ïÁ§∫„ÄÇ

##### **Efficient Few-Shot Continual Learning in Vision-Language Models**
2502.04098v1 by Aristeidis Panos, Rahaf Aljundi, Daniel Olmeda Reino, Richard E. Turner

Vision-language models (VLMs) excel in tasks such as visual question
answering and image captioning. However, VLMs are often limited by their use of
pretrained image encoders, like CLIP, leading to image understanding errors
that hinder overall performance. On top of that, real-world applications often
require the model to be continuously adapted as new and often limited data
continuously arrive. To address this, we propose LoRSU (Low-Rank Adaptation
with Structured Updates), a robust and computationally efficient method for
selectively updating image encoders within VLMs. LoRSU introduces structured
and localized parameter updates, effectively correcting performance on
previously error-prone data while preserving the model's general robustness.
Our approach leverages theoretical insights to identify and update only the
most critical parameters, achieving significant resource efficiency.
Specifically, we demonstrate that LoRSU reduces computational overhead by over
25x compared to full VLM updates, without sacrificing performance. Experimental
results on VQA tasks in the few-shot continual learning setting, validate
LoRSU's scalability, efficiency, and effectiveness, making it a compelling
solution for image encoder adaptation in resource-constrained environments.

ÊëòË¶ÅÔºöË¶ñË¶∫Ë™ûË®ÄÊ®°Âûã (VLM) Âú®Ë¶ñË¶∫ÂïèÈ°åËß£Á≠îÂíåÂΩ±ÂÉèÊ®ôÈ°åÁ≠â‰ªªÂãô‰∏≠Ë°®ÁèæÂá∫Ëâ≤„ÄÇÁÑ∂ËÄåÔºåVLM Á∂ìÂ∏∏ÂèóÂà∞ÂÖ∂‰ΩøÁî®È†êË®ìÁ∑¥ÂΩ±ÂÉèÁ∑®Á¢ºÂô®Ôºà‰æãÂ¶Ç CLIPÔºâÁöÑÈôêÂà∂ÔºåÂ∞éËá¥ÂΩ±ÂÉèÁêÜËß£ÈåØË™§ÔºåÈÄ≤ËÄåÈòªÁ§ôÊï¥È´îÊïàËÉΩ„ÄÇÊúÄÈáçË¶ÅÁöÑÊòØÔºåÁèæÂØ¶‰∏ñÁïåÁöÑÊáâÁî®Á®ãÂºèÈÄöÂ∏∏Ë¶ÅÊ±ÇÊ®°ÂûãÊåÅÁ∫åÈÅ©ÊáâÔºåÂõ†ÁÇ∫Êñ∞ÁöÑ‰∏îÁ∂ìÂ∏∏ÊúâÈôêÁöÑË≥áÊñôÊúÉÊåÅÁ∫åÊπßÂÖ•„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåÊàëÂÄëÊèêÂá∫ LoRSUÔºàÁµêÊßãÂåñÊõ¥Êñ∞ÁöÑ‰ΩéÁß©ÈÅ©ÊáâÔºâÔºåÈÄôÊòØ‰∏ÄÁ®ÆÂº∑ÂÅ•‰∏îÈÅãÁÆóÊïàÁéáÈ´òÁöÑÊñπÂºèÔºåÁî®ÊñºÈÅ∏ÊìáÊÄßÂú∞Êõ¥Êñ∞ VLM ‰∏≠ÁöÑÂΩ±ÂÉèÁ∑®Á¢ºÂô®„ÄÇLoRSU ÂºïÂÖ•ÁµêÊßãÂåñ‰∏îÂ±ÄÈÉ®ÂåñÁöÑÂèÉÊï∏Êõ¥Êñ∞ÔºåÊúâÊïàÂú∞‰øÆÊ≠£ÂÖàÂâçÂÆπÊòìÂá∫ÈåØË≥áÊñôÁöÑÊïàËÉΩÔºåÂêåÊôÇ‰øùÁïôÊ®°ÂûãÁöÑÊï¥È´îÂº∑ÂÅ•ÊÄß„ÄÇÊàëÂÄëÁöÑÂÅöÊ≥ïÂà©Áî®ÁêÜË´ñË¶ãËß£‰æÜË≠òÂà•ÂíåÊõ¥Êñ∞ÊúÄÈáçË¶ÅÁöÑÂèÉÊï∏ÔºåÈÄ≤ËÄåÈÅîÊàêÈ°ØËëóÁöÑË≥áÊ∫êÊïàÁéá„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÊàëÂÄëË≠âÊòé LoRSU Â∞áÈÅãÁÆóÈñãÈä∑Ê∏õÂ∞ë‰∫Ü 25 ÂÄç‰ª•‰∏äÔºàËàáÂÆåÊï¥ÁöÑ VLM Êõ¥Êñ∞Áõ∏ÊØîÔºâÔºåËÄå‰∏çÊúÉÁäßÁâ≤ÊïàËÉΩ„ÄÇÂú®Â∞ëÊ¨°Â≠∏ÁøíË®≠ÂÆö‰∏≠ÁöÑ VQA ‰ªªÂãô‰∏äÈÄ≤Ë°åÁöÑÂØ¶È©óÁµêÊûúÈ©óË≠â‰∫Ü LoRSU ÁöÑÂèØÊì¥ÂÖÖÊÄß„ÄÅÊïàÁéáÂíåÊúâÊïàÊÄßÔºå‰ΩøÂÖ∂ÊàêÁÇ∫Ë≥áÊ∫êÂèóÈôêÁí∞Â¢É‰∏≠ÂΩ±ÂÉèÁ∑®Á¢ºÂô®ÈÅ©ÊáâÁöÑÂºï‰∫∫Ê≥®ÁõÆÁöÑËß£Ê±∫ÊñπÊ°à„ÄÇ

##### **LLMs to Support a Domain Specific Knowledge Assistant**
2502.04095v1 by Maria-Flavia Lovin

This work presents a custom approach to developing a domain specific
knowledge assistant for sustainability reporting using the International
Financial Reporting Standards (IFRS). In this domain, there is no publicly
available question-answer dataset, which has impeded the development of a
high-quality chatbot to support companies with IFRS reporting. The two key
contributions of this project therefore are:
  (1) A high-quality synthetic question-answer (QA) dataset based on IFRS
sustainability standards, created using a novel generation and evaluation
pipeline leveraging Large Language Models (LLMs). This comprises 1,063 diverse
QA pairs that address a wide spectrum of potential user queries in
sustainability reporting. Various LLM-based techniques are employed to create
the dataset, including chain-of-thought reasoning and few-shot prompting. A
custom evaluation framework is developed to assess question and answer quality
across multiple dimensions, including faithfulness, relevance, and domain
specificity. The dataset averages a score range of 8.16 out of 10 on these
metrics.
  (2) Two architectures for question-answering in the sustainability reporting
domain - a RAG pipeline and a fully LLM-based pipeline. The architectures are
developed by experimenting, fine-tuning, and training on the QA dataset. The
final pipelines feature an LLM fine-tuned on domain specific data and an
industry classification component to improve the handling of complex queries.
The RAG architecture achieves an accuracy of 85.32% on single-industry and
72.15% on cross-industry multiple-choice questions, outperforming the baseline
approach by 4.67 and 19.21 percentage points, respectively. The LLM-based
pipeline achieves an accuracy of 93.45% on single-industry and 80.30% on
cross-industry multiple-choice questions, an improvement of 12.80 and 27.36
percentage points over the baseline, respectively.

ÊëòË¶ÅÔºö<paragraph>ÈÄôÈ†ÖÂ∑•‰ΩúÂ±ïÁ§∫‰∫Ü‰∏ÄÁ®ÆËá™Ë®ÇÊñπÊ≥ïÔºå‰ΩøÁî®ÂúãÈöõË≤°ÂãôÂ†±Â∞éÊ∫ñÂâá (IFRS) ‰æÜÈñãÁôºÊ∞∏Á∫åÂ†±Â∞éÁöÑÁâπÂÆöÈ†òÂüüÁü•Ë≠òÂä©ÁêÜ„ÄÇÂú®ÈÄôÂÄãÈ†òÂüü‰∏≠ÔºåÊ≤íÊúâÂÖ¨ÈñãÂèØÁî®ÁöÑÂïèÁ≠îË≥áÊñôÈõÜÔºåÈÄôÈòªÁ§ô‰∫ÜÈñãÁôºÈ´òÂìÅË≥™ÁöÑËÅäÂ§©Ê©üÂô®‰∫∫‰æÜÊîØÊè¥ÂÖ¨Âè∏ÈÄ≤Ë°å IFRS Â†±Â∞é„ÄÇÂõ†Ê≠§ÔºåÊ≠§Â∞àÊ°àÁöÑÂÖ©ÂÄã‰∏ªË¶ÅË≤¢ÁçªÁÇ∫Ôºö
  (1) ‰∏ÄÂÄãÂü∫Êñº IFRS Ê∞∏Á∫åÊÄßÊ®ôÊ∫ñÁöÑÈ´òÂìÅË≥™ÂêàÊàêÂïèÁ≠î (QA) Ë≥áÊñôÈõÜÔºåÂà©Áî®Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑÂâµÊñ∞ÁîüÊàêÂíåË©ï‰º∞ÁÆ°ÈÅì‰æÜÂª∫Á´ã„ÄÇÈÄôÂåÖÂê´ 1,063 ÂÄã‰∏çÂêåÁöÑ QA Â∞çÔºåÂèØËß£Ê±∫Ê∞∏Á∫åÂ†±Â∞é‰∏≠Âª£Ê≥õÁöÑÊΩõÂú®‰ΩøÁî®ËÄÖÊü•Ë©¢„ÄÇÊé°Áî®ÂêÑÁ®ÆÂü∫Êñº LLM ÁöÑÊäÄË°ì‰æÜÂª∫Á´ãË≥áÊñôÈõÜÔºåÂåÖÊã¨ÊÄùËÄÉÈèàÊé®ÁêÜÂíåÂ∞ëÊ¨°ÊèêÁ§∫„ÄÇÈñãÁôº‰∫Ü‰∏ÄÂÄãËá™Ë®ÇË©ï‰º∞Êû∂Êßã‰æÜË©ï‰º∞ÂïèÈ°åÂíåÁ≠îÊ°àÂìÅË≥™ÔºåÊ∂µËìãÂ§öÂÄãÈù¢ÂêëÔºåÂåÖÊã¨Âø†ÂØ¶Â∫¶„ÄÅÁõ∏ÈóúÊÄßÂíåÈ†òÂüüÁâπÂÆöÊÄß„ÄÇË≥áÊñôÈõÜÂú®ÈÄô‰∫õÊåáÊ®ô‰∏äÁöÑÂπ≥ÂùáÂàÜÊï∏ÁØÑÂúçÁÇ∫ 10 ÂàÜ‰∏≠ÁöÑ 8.16 ÂàÜ„ÄÇ
  (2) Ê∞∏Á∫åÂ†±Â∞éÈ†òÂüü‰∏≠ÂïèÁ≠îÁöÑÂÖ©ÂÄãÊû∂Êßã - RAG ÁÆ°ÈÅìÂíåÂÆåÂÖ®Âü∫Êñº LLM ÁöÑÁÆ°ÈÅì„ÄÇÈÄô‰∫õÊû∂ÊßãÊòØÈÄèÈÅéÂú® QA Ë≥áÊñôÈõÜ‰∏äÈÄ≤Ë°åÂØ¶È©ó„ÄÅÂæÆË™øÂíåË®ìÁ∑¥‰æÜÈñãÁôºÁöÑ„ÄÇÊúÄÁµÇÁöÑÁÆ°ÈÅìÂÖ∑Êúâ‰∏ÄÂÄãÈáùÂ∞çÁâπÂÆöÈ†òÂüüË≥áÊñôÂæÆË™øÁöÑ LLMÔºå‰ª•Âèä‰∏ÄÂÄãÁî¢Ê•≠ÂàÜÈ°ûÂÖÉ‰ª∂ÔºåÁî®ÊñºÊîπÂñÑË§áÈõúÊü•Ë©¢ÁöÑËôïÁêÜ„ÄÇRAG Êû∂ÊßãÂú®ÂñÆ‰∏ÄÁî¢Ê•≠‰∏äÈÅîÂà∞ 85.32% ÁöÑÊ∫ñÁ¢∫Â∫¶ÔºåÂú®Ë∑®Áî¢Ê•≠Â§öÈáçÈÅ∏ÊìáÈ°å‰∏äÈÅîÂà∞ 72.15% ÁöÑÊ∫ñÁ¢∫Â∫¶ÔºåÂàÜÂà•ÊØîÂü∫Ê∫ñÊñπÊ≥ïÈ´òÂá∫ 4.67 Âíå 19.21 ÂÄãÁôæÂàÜÈªû„ÄÇÂü∫Êñº LLM ÁöÑÁÆ°ÈÅìÂú®ÂñÆ‰∏ÄÁî¢Ê•≠‰∏äÈÅîÂà∞ 93.45% ÁöÑÊ∫ñÁ¢∫Â∫¶ÔºåÂú®Ë∑®Áî¢Ê•≠Â§öÈáçÈÅ∏ÊìáÈ°å‰∏äÈÅîÂà∞ 80.30% ÁöÑÊ∫ñÁ¢∫Â∫¶ÔºåÂàÜÂà•ÊØîÂü∫Ê∫ñÊñπÊ≥ïÊèêÈ´ò‰∫Ü 12.80 Âíå 27.36 ÂÄãÁôæÂàÜÈªû„ÄÇ</paragraph>

##### **Automatic quantification of breast cancer biomarkers from multiple 18F-FDG PET image segmentation**
2502.04083v1 by Tewele W. Tareke, Neree Payan, Alexandre Cochet, Laurent Arnould, Benoit Presles, Jean-Marc Vrigneaud, Fabrice Meriaudeau, Alain Lalande

Neoadjuvant chemotherapy (NAC) has become a standard clinical practice for
tumor downsizing in breast cancer with 18F-FDG Positron Emission Tomography
(PET). Our work aims to leverage PET imaging for the segmentation of breast
lesions. The focus is on developing an automated system that accurately
segments primary tumor regions and extracts key biomarkers from these areas to
provide insights into the evolution of breast cancer following the first course
of NAC. 243 baseline 18F-FDG PET scans (PET_Bl) and 180 follow-up 18F-FDG PET
scans (PET_Fu) were acquired before and after the first course of NAC,
respectively. Firstly, a deep learning-based breast tumor segmentation method
was developed. The optimal baseline model (model trained on baseline exams) was
fine-tuned on 15 follow-up exams and adapted using active learning to segment
tumor areas in PET_Fu. The pipeline computes biomarkers such as maximum
standardized uptake value (SUVmax), metabolic tumor volume (MTV), and total
lesion glycolysis (TLG) to evaluate tumor evolution between PET_Fu and PET_Bl.
Quality control measures were employed to exclude aberrant outliers. The nnUNet
deep learning model outperformed in tumor segmentation on PET_Bl, achieved a
Dice similarity coefficient (DSC) of 0.89 and a Hausdorff distance (HD) of 3.52
mm. After fine-tuning, the model demonstrated a DSC of 0.78 and a HD of 4.95 mm
on PET_Fu exams. Biomarkers analysis revealed very strong correlations whatever
the biomarker between manually segmented and automatically predicted regions.
The significant average decrease of SUVmax, MTV and TLG were 5.22, 11.79 cm3
and 19.23 cm3, respectively. The presented approach demonstrates an automated
system for breast tumor segmentation from 18F-FDG PET. Thanks to the extracted
biomarkers, our method enables the automatic assessment of cancer progression.

ÊëòË¶ÅÔºöÊñ∞ËæÖÂä©ÂåñÁñó (NAC) Â∑≤Êàê‰∏∫‰π≥ËÖ∫Áôå‰∏≠ÈááÁî® 18F-FDG Ê≠£ÁîµÂ≠êÂèëÂ∞ÑÊñ≠Â±ÇÊâ´Êèè (PET) ËøõË°åËÇøÁò§Áº©Â∞èÁöÑÊ†áÂáÜ‰∏¥Â∫äÂÆûË∑µ„ÄÇÊàë‰ª¨ÁöÑÂ∑•‰ΩúÊó®Âú®Âà©Áî® PET ÂΩ±ÂÉèÂàÜÂâ≤‰π≥ËÖ∫ÁóÖÂèò„ÄÇÈáçÁÇπÂú®‰∫éÂºÄÂèë‰∏Ä‰∏™Ëá™Âä®Á≥ªÁªüÔºåËØ•Á≥ªÁªüÂèØ‰ª•ÂáÜÁ°ÆÂàÜÂâ≤ÂéüÂèëÊÄßËÇøÁò§Âå∫ÂüüÂπ∂‰ªéËøô‰∫õÂå∫ÂüüÊèêÂèñÂÖ≥ÈîÆÁîüÁâ©Ê†áËÆ∞Ôºå‰ª•Ê∑±ÂÖ•‰∫ÜËß£‰π≥ËÖ∫ÁôåÂú®Á¨¨‰∏ÄÁñóÁ®ã NAC ÂêéÁöÑÊºîÂèò„ÄÇÂàÜÂà´Âú®Á¨¨‰∏ÄÁñóÁ®ã NAC ‰πãÂâçÂíå‰πãÂêéÈááÈõÜ‰∫Ü 243 ‰æãÂü∫Á∫ø 18F-FDG PET Êâ´Êèè (PET_Bl) Âíå 180 ‰æãÈöèËÆø 18F-FDG PET Êâ´Êèè (PET_Fu)„ÄÇÈ¶ñÂÖàÔºåÂºÄÂèë‰∫Ü‰∏ÄÁßçÂü∫‰∫éÊ∑±Â∫¶Â≠¶‰π†ÁöÑ‰π≥ËÖ∫ËÇøÁò§ÂàÜÂâ≤ÊñπÊ≥ï„ÄÇÂØπ 15 ‰æãÈöèËÆøÊ£ÄÊü•ÂØπÊúÄ‰ºòÂü∫Á∫øÊ®°ÂûãÔºàÂú®Âü∫Á∫øÊ£ÄÊü•‰∏≠ËÆ≠ÁªÉÁöÑÊ®°ÂûãÔºâËøõË°å‰∫ÜÂæÆË∞ÉÔºåÂπ∂‰ΩøÁî®‰∏ªÂä®Â≠¶‰π†ÂØπ PET_Fu ‰∏≠ÁöÑËÇøÁò§Âå∫ÂüüËøõË°å‰∫ÜÂàÜÂâ≤„ÄÇËØ•ÁÆ°ÈÅìËÆ°ÁÆóËØ∏Â¶ÇÊúÄÂ§ßÊ†áÂáÜÊëÑÂèñÂÄº (SUVmax)„ÄÅ‰ª£Ë∞¢ËÇøÁò§‰ΩìÁßØ (MTV) ÂíåÊÄªÁóÖÁÅ∂Á≥ñÈÖµËß£ (TLG) Á≠âÁîüÁâ©Ê†áËÆ∞Ôºå‰ª•ËØÑ‰º∞ PET_Fu Âíå PET_Bl ‰πãÈó¥ÁöÑËÇøÁò§ÊºîÂèò„ÄÇÈááÁî®Ë¥®ÈáèÊéßÂà∂Êé™ÊñΩÊù•ÊéíÈô§ÂºÇÂ∏∏ÂÄº„ÄÇnnUNet Ê∑±Â∫¶Â≠¶‰π†Ê®°ÂûãÂú® PET_Bl ‰∏äÁöÑËÇøÁò§ÂàÜÂâ≤ÊñπÈù¢Ë°®Áé∞Âá∫Ëâ≤ÔºåËææÂà∞ 0.89 ÁöÑ Dice Áõ∏‰ººÊÄßÁ≥ªÊï∞ (DSC) Âíå 3.52 ÊØ´Á±≥ÁöÑ Hausdorff Ë∑ùÁ¶ª (HD)„ÄÇÂæÆË∞ÉÂêéÔºåËØ•Ê®°ÂûãÂú® PET_Fu Ê£ÄÊü•‰∏≠ÊòæÁ§∫Âá∫ 0.78 ÁöÑ DSC Âíå 4.95 ÊØ´Á±≥ÁöÑ HD„ÄÇÊó†ËÆ∫ÊâãÂä®ÂàÜÂâ≤Âå∫ÂüüÂíåËá™Âä®È¢ÑÊµãÂå∫Âüü‰πãÈó¥ÁöÑÁîüÁâ©Ê†áËÆ∞Â¶Ç‰ΩïÔºåÁîüÁâ©Ê†áËÆ∞ÂàÜÊûêÈÉΩÊòæÁ§∫Âá∫ÈùûÂ∏∏Âº∫ÁöÑÁõ∏ÂÖ≥ÊÄß„ÄÇSUVmax„ÄÅMTV Âíå TLG ÁöÑÂπ≥ÂùáÊòæÁùÄ‰∏ãÈôçÂàÜÂà´‰∏∫ 5.22„ÄÅ11.79 cm3 Âíå 19.23 cm3„ÄÇÊâÄÊèêÂá∫ÁöÑÊñπÊ≥ïÂ±ïÁ§∫‰∫Ü‰∏Ä‰∏™Áî®‰∫é‰ªé 18F-FDG PET ÂàÜÂâ≤‰π≥ËÖ∫ËÇøÁò§ÁöÑËá™Âä®ÂåñÁ≥ªÁªü„ÄÇÁî±‰∫éÊèêÂèñ‰∫ÜÁîüÁâ©Ê†áËÆ∞ÔºåÊàë‰ª¨ÁöÑÊñπÊ≥ïËÉΩÂ§üËá™Âä®ËØÑ‰º∞ÁôåÁóáËøõÂ±ï„ÄÇ

##### **AttentionPredictor: Temporal Pattern Matters for Efficient LLM Inference**
2502.04077v1 by Qingyue Yang, Jie Wang, Xing Li, Zhihai Wang, Chen Chen, Lei Chen, Xianzhi Yu, Wulong Liu, Jianye Hao, Mingxuan Yuan, Bin Li

With the development of large language models (LLMs), efficient inference
through Key-Value (KV) cache compression has attracted considerable attention,
especially for long-context generation. To compress the KV cache, recent
methods identify critical KV tokens through heuristic ranking with attention
scores. However, these methods often struggle to accurately determine critical
tokens as they neglect the \textit{temporal patterns} in attention scores,
resulting in a noticeable degradation in LLM performance. To address this
challenge, we propose AttentionPredictor, which is the first learning-based
critical token identification approach. Specifically, AttentionPredictor learns
a lightweight convolution model to capture spatiotemporal patterns and predict
the next-token attention score. An appealing feature of AttentionPredictor is
that it accurately predicts the attention score while consuming negligible
memory. Moreover, we propose a cross-token critical cache prefetching framework
that hides the token estimation time overhead to accelerate the decoding stage.
By retaining most of the attention information, AttentionPredictor achieves
16$\times$ KV cache compression with comparable LLM performance, significantly
outperforming the state-of-the-art.

ÊëòË¶ÅÔºöÈö®ËëóÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÔºàLLMÔºâÁöÑÁôºÂ±ïÔºåÈÄèÈÅé Key-ValueÔºàKVÔºâÂø´ÂèñÂ£ìÁ∏ÆÈÄ≤Ë°åÁöÑÊúâÊïàÊé®Ë´ñÂÇôÂèóÈóúÊ≥®ÔºåÁâπÂà•ÊòØÈï∑Ë™ûÂ¢ÉÁîüÊàê„ÄÇÁÇ∫‰∫ÜÂ£ìÁ∏Æ KV Âø´ÂèñÔºåËøëÊúüÊñπÊ≥ïÈÄèÈÅéÊ≥®ÊÑèÂäõÂàÜÊï∏ÈÄ≤Ë°åÂïüÁôºÂºèÊéíÂ∫èÔºå‰æÜË≠òÂà•ÈóúÈçµ KV Ê®ôË®ò„ÄÇÁÑ∂ËÄåÔºåÈÄô‰∫õÊñπÊ≥ïÈÄöÂ∏∏Èõ£‰ª•Ê∫ñÁ¢∫Âú∞Âà§Êñ∑ÈóúÈçµÊ®ôË®òÔºåÂõ†ÁÇ∫ÂÆÉÂÄëÂøΩÁï•‰∫ÜÊ≥®ÊÑèÂäõÂàÜÊï∏‰∏≠ÁöÑ„ÄåÊôÇÈñìÊ®°Âºè„ÄçÔºåÂ∞éËá¥ LLM ÊïàËÉΩÈ°ØËëó‰∏ãÈôç„ÄÇÁÇ∫‰∫ÜÊáâÂ∞çÊ≠§ÊåëÊà∞ÔºåÊàëÂÄëÊèêÂá∫ AttentionPredictorÔºåÈÄôÊòØÁ¨¨‰∏ÄÂÄãÂü∫ÊñºÂ≠∏ÁøíÁöÑÈóúÈçµÊ®ôË®òË≠òÂà•ÊñπÊ≥ï„ÄÇÂÖ∑È´î‰æÜË™™ÔºåAttentionPredictor Â≠∏Áøí‰∏ÄÂÄãËºïÈáèÁ¥öÂç∑Á©çÊ®°Âûã‰æÜÊì∑ÂèñÊôÇÁ©∫Ê®°ÂºèÔºå‰∏¶È†êÊ∏¨‰∏ã‰∏ÄÂÄãÊ®ôË®òÁöÑÊ≥®ÊÑèÂäõÂàÜÊï∏„ÄÇAttentionPredictor ÁöÑ‰∏ÄÂÄãÂê∏Âºï‰∫∫ÁâπÈªûÊòØÂÆÉÂú®Ê∂àËÄóÊ•µÂ∞ëË®òÊÜ∂È´îÁöÑÊÉÖÊ≥Å‰∏ãÊ∫ñÁ¢∫È†êÊ∏¨Ê≥®ÊÑèÂäõÂàÜÊï∏„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÊèêÂá∫‰∏ÄÂÄãË∑®Ê®ôË®òÈóúÈçµÂø´ÂèñÈ†êÂèñÊû∂ÊßãÔºåÂÆÉÈö±Ëóè‰∫ÜÊ®ôË®ò‰º∞Ë®àÊôÇÈñìÈñãÈä∑Ôºå‰ª•Âä†ÈÄüËß£Á¢ºÈöéÊÆµ„ÄÇÈÄèÈÅé‰øùÁïôÂ§ßÈÉ®ÂàÜÊ≥®ÊÑèÂäõË≥áË®äÔºåAttentionPredictor ÈÅîÂà∞ 16 ÂÄç KV Âø´ÂèñÂ£ìÁ∏ÆÔºå‰∏¶ÂÖ∑ÊúâÁõ∏Áï∂ÁöÑ LLM ÊïàËÉΩÔºåÈ°ØËëóÂÑ™ÊñºÁèæÊúâÊäÄË°ì„ÄÇ

##### **Controllable Emotion Generation with Emotion Vectors**
2502.04075v1 by Yurui Dong, Luozhijie Jin, Yao Yang, Bingjie Lu, Jiaxi Yang, Zhi Liu

In recent years, technologies based on large-scale language models (LLMs)
have made remarkable progress in many fields, especially in customer service,
content creation, and embodied intelligence, showing broad application
potential. However, The LLM's ability to express emotions with proper tone,
timing, and in both direct and indirect forms is still insufficient but
significant. Few works have studied on how to build the controlable emotional
expression capability of LLMs. In this work, we propose a method for emotion
expression output by LLMs, which is universal, highly flexible, and well
controllable proved with the extensive experiments and verifications. This
method has broad application prospects in fields involving emotions output by
LLMs, such as intelligent customer service, literary creation, and home
companion robots. The extensive experiments on various LLMs with different
model-scales and architectures prove the versatility and the effectiveness of
the proposed method.

ÊëòË¶ÅÔºöËøëÂπ¥‰æÜÔºåÂü∫ÊñºÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑÊäÄË°ìÂú®Ë®±Â§öÈ†òÂüüÂèñÂæóÈ°ØËëóÈÄ≤Â±ïÔºåÁâπÂà•ÊòØÂú®ÂÆ¢Êúç„ÄÅÂÖßÂÆπÂâµ‰ΩúÂíåÂÖ∑Ë∫´Êô∫ÊÖßÊñπÈù¢ÔºåÂ±ïÁèæÂª£Ê≥õÁöÑÊáâÁî®ÊΩõÂäõ„ÄÇÁÑ∂ËÄåÔºåLLM ‰ª•ÈÅ©Áï∂Ë™ûÊ∞£„ÄÅÊôÇÊ©üÔºåÁõ¥Êé•ÂíåÈñìÊé•Ë°®ÈÅîÊÉÖÁ∑íÁöÑËÉΩÂäõ‰ªçÊúâ‰∏çË∂≥Ôºå‰ΩÜÂçªËá≥ÈóúÈáçË¶Å„ÄÇÈÆÆÂ∞ëÊúâÁ†îÁ©∂Êé¢Ë®éÂ¶Ç‰ΩïÂª∫Êßã LLM ÂèØÊéßÁöÑÊÉÖÁ∑íË°®ÈÅîËÉΩÂäõ„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∏ÄÂÄã LLM ÊÉÖÁ∑íË°®ÈÅîËº∏Âá∫ÁöÑÊñπÊ≥ïÔºåÊ≠§ÊñπÊ≥ïÈÄöÁî®„ÄÅÈ´òÂ∫¶ÈùàÊ¥ª‰∏îÂèØÊéßÊÄß‰Ω≥Ôºå‰∏¶ÈÄèÈÅéÂª£Ê≥õÁöÑÂØ¶È©óÂíåÈ©óË≠âÂä†‰ª•Ë≠âÊòé„ÄÇÊ≠§ÊñπÊ≥ïÂú®Ê∂âÂèä LLM ÊÉÖÁ∑íËº∏Âá∫ÁöÑÈ†òÂüüÔºå‰æãÂ¶ÇÊô∫ÊÖßÂÆ¢Êúç„ÄÅÊñáÂ≠∏Ââµ‰ΩúÂíåÂ±ÖÂÆ∂Èô™‰º¥Ê©üÂô®‰∫∫ÔºåÂÖ∑ÊúâÂª£Ê≥õÁöÑÊáâÁî®ÂâçÊôØ„ÄÇÈáùÂ∞ç‰∏çÂêåÊ®°ÂûãË¶èÊ®°ÂíåÊû∂ÊßãÁöÑÂêÑÈ°û LLM ÈÄ≤Ë°åÁöÑÂª£Ê≥õÂØ¶È©óÔºåË≠âÊòé‰∫ÜÊâÄÊèêÊñπÊ≥ïÁöÑÂ§öÂäüËÉΩÊÄßÂíåÊúâÊïàÊÄß„ÄÇ

##### **Predicting Large Language Model Capabilities on Closed-Book QA Tasks Using Only Information Available Prior to Training**
2502.04066v1 by Changhao Jiang, Ming Zhang, Junjie Ye, Xiaoran Fan, Yifei Cao, Jiajun Sun, Zhiheng Xi, Shihan Dou, Yi Dong, Yujiong Shen, Jingqi Tong, Zhen Wang, Tao Liang, Zhihui Fei, Mingyang Wan, Guojun Ma, Qi Zhang, Tao Gui, Xuanjing Huang

The GPT-4 technical report from OpenAI suggests that model performance on
specific tasks can be predicted prior to training, though methodologies remain
unspecified. This approach is crucial for optimizing resource allocation and
ensuring data alignment with target tasks. To achieve this vision, we focus on
predicting performance on Closed-book Question Answering (CBQA) tasks, which
are closely tied to pre-training data and knowledge retention. We address three
major challenges: 1) mastering the entire pre-training process, especially data
construction; 2) evaluating a model's knowledge retention; and 3) predicting
task-specific knowledge retention using only information available prior to
training. To tackle these challenges, we pre-train three large language models
(i.e., 1.6B, 7B, and 13B) using 560k dollars and 520k GPU hours. We analyze the
pre-training data with knowledge triples and assess knowledge retention using
established methods. Additionally, we introduce the SMI metric, an
information-theoretic measure that quantifies the relationship between
pre-training data, model size, and task-specific knowledge retention. Our
experiments reveal a strong linear correlation ($\text{R}^2 > 0.84$) between
the SMI metric and the model's accuracy on CBQA tasks across models of varying
sizes (i.e., 1.1B, 1.6B, 7B, and 13B). The dataset, model, and code are
available at https://github.com/yuhui1038/SMI.

ÊëòË¶ÅÔºöOpenAI ÁöÑ GPT-4 ÊäÄË°ìÂ†±ÂëäÊåáÂá∫ÔºåÂÑòÁÆ°ÊñπÊ≥ï‰ªçÊú™ÊòéÁ¢∫Ôºå‰ΩÜÂèØ‰ª•Âú®Ë®ìÁ∑¥ÂâçÈ†êÊ∏¨Ê®°ÂûãÂú®ÁâπÂÆö‰ªªÂãô‰∏äÁöÑË°®Áèæ„ÄÇÈÄôÁ®ÆÊñπÊ≥ïÂ∞çÊñºÂÑ™ÂåñË≥áÊ∫êÈÖçÁΩÆÂíåÁ¢∫‰øùË≥áÊñôËàáÁõÆÊ®ô‰ªªÂãôÁöÑ‰∏ÄËá¥ÊÄßËá≥ÈóúÈáçË¶Å„ÄÇÁÇ∫‰∫ÜÂØ¶ÁèæÈÄôÂÄãÈ°òÊôØÔºåÊàëÂÄëÂ∞àÊ≥®ÊñºÈ†êÊ∏¨ÈñâÂç∑ÂºèÂïèÁ≠î (CBQA) ‰ªªÂãôÁöÑË°®ÁèæÔºåÈÄô‰∫õ‰ªªÂãôËàáÈ†êË®ìÁ∑¥Ë≥áÊñôÂíåÁü•Ë≠ò‰øùÁïôÂØÜÂàáÁõ∏Èóú„ÄÇÊàëÂÄëËß£Ê±∫‰∫Ü‰∏âÂ§ßÊåëÊà∞Ôºö1) ÊéåÊè°Êï¥ÂÄãÈ†êË®ìÁ∑¥ÈÅéÁ®ãÔºåÁâπÂà•ÊòØË≥áÊñôÂª∫ÊßãÔºõ2) Ë©ï‰º∞Ê®°ÂûãÁöÑÁü•Ë≠ò‰øùÁïôÔºõ‰ª•Âèä 3) ÂÉÖ‰ΩøÁî®Ë®ìÁ∑¥ÂâçÂèØÂæóÁöÑË≥áË®äÈ†êÊ∏¨ÁâπÂÆö‰ªªÂãôÁöÑÁü•Ë≠ò‰øùÁïô„ÄÇÁÇ∫‰∫ÜÊáâÂ∞çÈÄô‰∫õÊåëÊà∞ÔºåÊàëÂÄë‰ΩøÁî® 56 Ëê¨ÁæéÂÖÉÂíå 52 Ëê¨ GPU Â∞èÊôÇÈ†êË®ìÁ∑¥‰∫Ü‰∏âÂÄãÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÔºàÂç≥ 1.6B„ÄÅ7B Âíå 13BÔºâ„ÄÇÊàëÂÄë‰ΩøÁî®Áü•Ë≠ò‰∏âÂÖÉÁµÑÂàÜÊûêÈ†êË®ìÁ∑¥Ë≥áÊñôÔºå‰∏¶‰ΩøÁî®Êó¢ÂÆöÊñπÊ≥ïË©ï‰º∞Áü•Ë≠ò‰øùÁïô„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü SMI ÊåáÊ®ôÔºåÈÄôÊòØ‰∏ÄÁ®ÆË≥áË®äÁêÜË´ñÊ∏¨ÈáèÔºåÁî®ÊñºÈáèÂåñÈ†êË®ìÁ∑¥Ë≥áÊñô„ÄÅÊ®°ÂûãÂ§ßÂ∞èÂíåÁâπÂÆö‰ªªÂãôÁü•Ë≠ò‰øùÁïô‰πãÈñìÁöÑÈóú‰øÇ„ÄÇÊàëÂÄëÁöÑÂØ¶È©óÊè≠Á§∫‰∫Ü‰∏ÄÂÄãÂº∑ÁÉàÁöÑÁ∑öÊÄßÁõ∏ÈóúÊÄßÔºà$\text{R}^2 > 0.84$ÔºâÔºåÂú®‰∏çÂêåÂ§ßÂ∞èÁöÑÊ®°ÂûãÔºàÂç≥ 1.1B„ÄÅ1.6B„ÄÅ7B Âíå 13BÔºâ‰∏≠ÔºåSMI ÊåáÊ®ôÂíåÊ®°ÂûãÂú® CBQA ‰ªªÂãô‰∏äÁöÑÊ∫ñÁ¢∫ÊÄß‰πãÈñì„ÄÇË≥áÊñôÈõÜ„ÄÅÊ®°ÂûãÂíåÁ®ãÂºèÁ¢ºÂèØÂú® https://github.com/yuhui1038/SMI ÂèñÂæó„ÄÇ

##### **Strategic Learning with Local Explanations as Feedback**
2502.04058v1 by Kiet Q. H. Vo, Siu Lun Chau, Masahiro Kato, Yixin Wang, Krikamol Muandet

We investigate algorithmic decision problems where agents can respond
strategically to the decision maker's (DM) models. The demand for clear and
actionable explanations from DMs to (potentially strategic) agents continues to
rise. While prior work often treats explanations as full model disclosures,
explanations in practice might convey only partial information, which can lead
to misinterpretations and harmful responses. When full disclosure of the
predictive model is neither feasible nor desirable, a key open question is how
DMs can use explanations to maximise their utility without compromising agent
welfare. In this work, we explore well-known local and global explanation
methods, and establish a necessary condition to prevent explanations from
misleading agents into self-harming actions. Moreover, with conditional
homogeneity, we establish that action recommendation (AR)-based explanations
are sufficient for non-harmful responses, akin to the revelation principle in
information design. To operationalise AR-based explanations, we propose a
simple algorithm to jointly optimise the predictive model and AR policy to
balance DM outcomes with agent welfare. Our empirical results demonstrate the
benefits of this approach as a more refined strategy for safe and effective
partial model disclosure in algorithmic decision-making.

ÊëòË¶ÅÔºöÊàëÂÄëÁ†îÁ©∂ÊºîÁÆóÊ≥ïÊ±∫Á≠ñÂïèÈ°åÔºåÂÖ∂‰∏≠‰ª£ÁêÜ‰∫∫ÂèØ‰ª•Â∞çÊ±∫Á≠ñËÄÖ (DM) ÁöÑÊ®°ÂûãÂÅöÂá∫Á≠ñÁï•ÊÄßÂõûÊáâ„ÄÇDM Â∞çÔºàÊΩõÂú®Á≠ñÁï•ÊÄßÔºâ‰ª£ÁêÜ‰∫∫ÁöÑÊòéÁ¢∫‰∏îÂèØÊìç‰ΩúÁöÑËß£ÈáãÈúÄÊ±ÇÊåÅÁ∫åÂ¢ûÂä†„ÄÇÈõñÁÑ∂ÂÖàÂâçÁöÑÁ†îÁ©∂ÈÄöÂ∏∏Â∞áËß£ÈáãË¶ñÁÇ∫ÂÆåÊï¥ÁöÑÊ®°ÂûãÊè≠Èú≤Ôºå‰ΩÜÂØ¶Èöõ‰∏äÁöÑËß£ÈáãÂèØËÉΩÂè™ÂÇ≥ÈÅîÈÉ®ÂàÜË≥áË®äÔºåÈÄôÂèØËÉΩÂ∞éËá¥Ë™§Ëß£ÂíåÊúâÂÆ≥ÁöÑÂõûÊáâ„ÄÇÁï∂È†êÊ∏¨Ê®°ÂûãÁöÑÂÆåÂÖ®Êè≠Èú≤Êó¢‰∏çÂèØË°å‰πü‰∏çÂèØÂèñÊôÇÔºå‰∏ÄÂÄãÈóúÈçµÁöÑÈñãÊîæÊÄßÂïèÈ°åÊòØ DM Â¶Ç‰Ωï‰ΩøÁî®Ëß£Èáã‰æÜÊúÄÂ§ßÂåñÂÖ∂ÊïàÁî®ÔºåËÄå‰∏çÊúÉÊêçÂÆ≥‰ª£ÁêÜ‰∫∫ÁöÑÁ¶èÂà©„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÊé¢Ë®é‰∫ÜËëóÂêçÁöÑÂ±ÄÈÉ®ÂíåÂÖ®Â±ÄËß£ÈáãÊñπÊ≥ïÔºå‰∏¶Âª∫Á´ã‰∫Ü‰∏ÄÂÄãÂøÖË¶ÅÊ¢ù‰ª∂Ôºå‰ª•Èò≤Ê≠¢Ëß£ÈáãË™§Â∞é‰ª£ÁêÜ‰∫∫Êé°ÂèñËá™ÊÆòË°åÁÇ∫„ÄÇÊ≠§Â§ñÔºåÈÄèÈÅéÊ¢ù‰ª∂ÂêåË≥™ÊÄßÔºåÊàëÂÄëÁ¢∫Á´ãÂü∫ÊñºÂãï‰ΩúÂª∫Ë≠∞ (AR) ÁöÑËß£ÈáãË∂≥‰ª•Áî¢ÁîüÁÑ°ÂÆ≥ÁöÑÂõûÊáâÔºåÈ°û‰ººÊñºË≥áË®äË®≠Ë®à‰∏≠ÁöÑÊè≠Èú≤ÂéüÂâá„ÄÇÁÇ∫‰∫ÜÊìç‰ΩúÂü∫Êñº AR ÁöÑËß£ÈáãÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÁ∞°ÂñÆÁöÑÊºîÁÆóÊ≥ïÔºå‰ª•ÂÖ±ÂêåÊúÄ‰Ω≥ÂåñÈ†êÊ∏¨Ê®°ÂûãÂíå AR Á≠ñÁï•Ôºå‰ª•Âπ≥Ë°° DM ÁµêÊûúËàá‰ª£ÁêÜ‰∫∫Á¶èÂà©„ÄÇÊàëÂÄëÁöÑÂØ¶Ë≠âÁµêÊûúË≠âÊòé‰∫ÜÈÄôÁ®ÆÊñπÊ≥ïÁöÑÂ•ΩËôïÔºå‰ΩúÁÇ∫ÊºîÁÆóÊ≥ïÊ±∫Á≠ñ‰∏≠ÂÆâÂÖ®‰∏îÊúâÊïàÁöÑÂ±ÄÈÉ®Ê®°ÂûãÊè≠Èú≤ÁöÑÊõ¥Á≤æÁ∑ªÁ≠ñÁï•„ÄÇ

##### **Probe-Free Low-Rank Activation Intervention**
2502.04043v1 by Chonghe Jiang, Bao Nguyen, Anthony Man-Cho So, Viet Anh Nguyen

Language models (LMs) can produce texts that appear accurate and coherent but
contain untruthful or toxic content. Inference-time interventions that edit the
hidden activations have shown promising results in steering the LMs towards
desirable generations. Existing activation intervention methods often comprise
an activation probe to detect undesirable generation, triggering the activation
modification to steer subsequent generation. This paper proposes a probe-free
intervention method FLORAIN for all attention heads in a specific activation
layer. It eliminates the need to train classifiers for probing purposes. The
intervention function is parametrized by a sample-wise nonlinear low-rank
mapping, which is trained by minimizing the distance between the modified
activations and their projection onto the manifold of desirable content. Under
specific constructions of the manifold and projection distance, we show that
the intervention strategy can be computed efficiently by solving a smooth
optimization problem. The empirical results, benchmarked on multiple base
models, demonstrate that FLORAIN consistently outperforms several baseline
methods in enhancing model truthfulness and quality across generation and
multiple-choice tasks.

ÊëòË¶ÅÔºöË™ûË®ÄÊ®°Âûã (LM) ÂèØ‰ª•Áî¢ÁîüÁúãËµ∑‰æÜÊ∫ñÁ¢∫‰∏îÈÄ£Ë≤´ÁöÑÊñáÂ≠óÔºå‰ΩÜÂÖ∂‰∏≠ÂåÖÂê´‰∏çÁúüÂØ¶ÊàñÊúâÊØíÁöÑÂÖßÂÆπ„ÄÇÁ∑®ËºØÈö±ËóèÊøÄÊ¥ªÁöÑÊé®ÁêÜÊôÇÈñì‰ªãÂÖ•Â∑≤Âú®ÂºïÂ∞é LM ÊúùÂêëÁêÜÊÉ≥ÁîüÊàêÊñπÈù¢È°ØÁ§∫Âá∫ÊúâÂ∏åÊúõÁöÑÁµêÊûú„ÄÇÁèæÊúâÁöÑÊøÄÊ¥ª‰ªãÂÖ•ÊñπÊ≥ïÈÄöÂ∏∏ÂåÖÂê´‰∏ÄÂÄãÊøÄÊ¥ªÊé¢Ê∏¨Âô®ÔºåÁî®ÊñºÂÅµÊ∏¨‰∏çËâØÁîüÊàêÔºåËß∏ÁôºÊøÄÊ¥ª‰øÆÊîπ‰ª•ÂºïÂ∞éÂæåÁ∫åÁîüÊàê„ÄÇÊú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÈáùÂ∞çÁâπÂÆöÊøÄÊ¥ªÂ±§‰∏≠ÊâÄÊúâÊ≥®ÊÑèÂäõÈ†≠ÈÉ®ÁöÑÁÑ°Êé¢Ê∏¨‰ªãÂÖ•ÊñπÊ≥ï FLORAIN„ÄÇÂÆÉÊ∂àÈô§‰∫ÜÁÇ∫Êé¢Ê∏¨ÁõÆÁöÑË®ìÁ∑¥ÂàÜÈ°ûÂô®ÁöÑÈúÄË¶Å„ÄÇ‰ªãÂÖ•ÂáΩÊï∏Áî±Ê®£Êú¨Á¥öÈùûÁ∑öÊÄß‰ΩéÁß©Êò†Â∞ÑÂèÉÊï∏ÂåñÔºåË©≤Êò†Â∞ÑÈÄöÈÅéÊúÄÂ∞èÂåñ‰øÆÊîπÂæåÁöÑÊøÄÊ¥ªËàáÂÖ∂Âú®ÁêÜÊÉ≥ÂÖßÂÆπÊµÅÂΩ¢‰∏äÁöÑÊäïÂΩ±‰πãÈñìÁöÑË∑ùÈõ¢‰æÜË®ìÁ∑¥„ÄÇÂú®ÊµÅÂΩ¢ÂíåÊäïÂΩ±Ë∑ùÈõ¢ÁöÑÁâπÂÆöÊßãÈÄ†‰∏ãÔºåÊàëÂÄëË°®Êòé‰ªãÂÖ•Á≠ñÁï•ÂèØ‰ª•ÈÄöÈÅéËß£Ê±∫Âπ≥ÊªëÂÑ™ÂåñÂïèÈ°å‰æÜÊúâÊïàË®àÁÆó„ÄÇÂú®Â§öÂÄãÂü∫Á§éÊ®°Âûã‰∏äÈÄ≤Ë°åÂü∫Ê∫ñÊ∏¨Ë©¶ÁöÑÁ∂ìÈ©óÁµêÊûúË°®ÊòéÔºåFLORAIN Âú®Â¢ûÂº∑Ê®°ÂûãÁúüÂØ¶ÊÄßÂíåÁîüÊàêÂíåÂ§öÈ†ÖÈÅ∏Êìá‰ªªÂãô‰∏≠ÁöÑË≥™ÈáèÊñπÈù¢ÂßãÁµÇÂÑ™ÊñºÂ§öÁ®ÆÂü∫Á∑öÊñπÊ≥ï„ÄÇ

##### **Leveraging Reasoning with Guidelines to Elicit and Utilize Knowledge for Enhancing Safety Alignment**
2502.04040v1 by Haoyu Wang, Zeyu Qin, Li Shen, Xueqian Wang, Minhao Cheng, Dacheng Tao

Training safe LLMs is one of the most critical research challenge. However,
the commonly used method, Refusal Training (RT), struggles to generalize
against various OOD jailbreaking attacks. Many safety training methods have
been proposed to address this issue. While they offer valuable insights, we aim
to complement this line of research by investigating whether OOD attacks truly
exceed the capability of RT model. Conducting evaluation with BoN, we observe
significant improvements on generalization as N increases. This underscores
that the model possesses sufficient safety-related latent knowledge, but RT
fails to consistently elicit this knowledge when addressing OOD attacks.
Further analysis based on domain adaptation reveals that training with direct
refusal causes model to rely on superficial shortcuts, resulting in learning of
non-robust representation mappings. Based on our findings, we propose training
model to perform safety reasoning for each query. Reasoning supervision
encourages model to perform more computations, explicitly eliciting and using
latent knowledge through reasoning. To achieve this, we synthesize reasoning
supervision based on pre-guidelines, training the model to reason in alignment
with them, thereby effectively eliciting and utilizing latent knowledge from
diverse perspectives. Extensive experiments show that our method significantly
improves generalization performance against OOD attacks.

ÊëòË¶ÅÔºöË®ìÁ∑¥ÂÆâÂÖ®ÁöÑ LLM ÊòØÊúÄÈáçË¶ÅÁöÑÁ†îÁ©∂ÊåëÊà∞‰πã‰∏Ä„ÄÇÁÑ∂ËÄåÔºå
Â∏∏Áî®ÁöÑÊñπÊ≥ïÔºåÊãíÁµïË®ìÁ∑¥ (RT)ÔºåÈõ£‰ª•Ê¶ÇÊã¨
ÂêÑÁ®Æ OOD Ë∂äÁçÑÊîªÊìä„ÄÇË®±Â§öÂÆâÂÖ®Ë®ìÁ∑¥ÊñπÊ≥ïÂ∑≤
Ë¢´ÊèêË≠∞‰æÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°å„ÄÇÈõñÁÑ∂ÂÆÉÂÄëÊèê‰æõ‰∫ÜÊúâÂÉπÂÄºÁöÑË¶ãËß£ÔºåÊàëÂÄëÊó®Âú®
ÈÄöÈÅéË™øÊü• OOD ÊîªÊìäÊòØÂê¶ÁúüÊ≠£Ë∂ÖÈÅé RT Ê®°ÂûãÁöÑËÉΩÂäõ‰æÜË£úÂÖÖÈÄôÊ¢ùÁ†îÁ©∂Á∑ö„ÄÇ‰ΩøÁî® BoN ÈÄ≤Ë°åË©ï‰º∞ÔºåÊàëÂÄëËßÄÂØü
Èö®Ëëó N ÁöÑÂ¢ûÂä†ÔºåÊ≥õÂåñËÉΩÂäõÈ°ØËëóÊèêÈ´ò„ÄÇÈÄôÂº∑Ë™ø
Ë©≤Ê®°ÂûãÂÖ∑ÂÇôË∂≥Â§†ÁöÑÂÆâÂÖ®Áõ∏ÈóúÊΩõÂú®Áü•Ë≠òÔºå‰ΩÜ RT
Âú®ËôïÁêÜ OOD ÊîªÊìäÊôÇÁÑ°Ê≥ïÂßãÁµÇÂ¶Ç‰∏ÄÂú∞ÂºïÂá∫ÈÄôÁ®ÆÁü•Ë≠ò„ÄÇ
Âü∫ÊñºÂüüÈÅ©ÊáâÁöÑÈÄ≤‰∏ÄÊ≠•ÂàÜÊûêË°®ÊòéÔºåÁõ¥Êé•Ë®ìÁ∑¥
ÊãíÁµïÂ∞éËá¥Ê®°Âûã‰æùË≥¥ÊñºËÜöÊ∑∫ÁöÑÊç∑ÂæëÔºåÂ∞éËá¥Â≠∏Áøí
ÈùûÁ©©ÂÅ•Ë°®Á§∫Êò†Â∞Ñ„ÄÇÊ†πÊìöÊàëÂÄëÁöÑÁôºÁèæÔºåÊàëÂÄëÂª∫Ë≠∞Ë®ìÁ∑¥
Ê®°ÂûãÁÇ∫ÊØèÂÄãÊü•Ë©¢Âü∑Ë°åÂÆâÂÖ®Êé®ÁêÜ„ÄÇÊé®ÁêÜÁõ£Áù£
ÈºìÂãµÊ®°ÂûãÂü∑Ë°åÊõ¥Â§öË®àÁÆóÔºåÈÄöÈÅéÊé®ÁêÜÊòéÁ¢∫ÂºïÂá∫‰∏¶‰ΩøÁî®
ÊΩõÂú®Áü•Ë≠ò„ÄÇÁÇ∫Ê≠§ÔºåÊàëÂÄëÊ†πÊìöÈ†êÊåáÂçóÂêàÊàêÊé®ÁêÜ
Áõ£Áù£ÔºåË®ìÁ∑¥Ê®°ÂûãËàáÂÆÉÂÄë‰øùÊåÅ‰∏ÄËá¥ÔºåÂæûËÄåÊúâÊïàÂú∞ÂºïÂá∫ÂíåÂà©Áî®
‰æÜËá™‰∏çÂêåËßÄÈªûÁöÑÊΩõÂú®Áü•Ë≠ò„ÄÇÂ§ßÈáèÁöÑÂØ¶È©óË°®ÊòéÔºåÊàëÂÄëÁöÑ
ÊñπÊ≥ïÈ°ØËëóÊèêÈ´ò‰∫ÜÂ∞ç OOD ÊîªÊìäÁöÑÊ≥õÂåñÊÄßËÉΩ„ÄÇ

##### **Simulating the Emergence of Differential Case Marking with Communicating Neural-Network Agents**
2502.04038v1 by Yuchen Lian, Arianna Bisazza, Tessa Verhoef

Differential Case Marking (DCM) refers to the phenomenon where grammatical
case marking is applied selectively based on semantic, pragmatic, or other
factors. The emergence of DCM has been studied in artificial language learning
experiments with human participants, which were specifically aimed at
disentangling the effects of learning from those of communication (Smith &
Culbertson, 2020). Multi-agent reinforcement learning frameworks based on
neural networks have gained significant interest to simulate the emergence of
human-like linguistic phenomena. In this study, we employ such a framework in
which agents first acquire an artificial language before engaging in
communicative interactions, enabling direct comparisons to human result. Using
a very generic communication optimization algorithm and neural-network learners
that have no prior experience with language or semantic preferences, our
results demonstrate that learning alone does not lead to DCM, but when agents
communicate, differential use of markers arises. This supports Smith and
Culbertson (2020)'s findings that highlight the critical role of communication
in shaping DCM and showcases the potential of neural-agent models to complement
experimental research on language evolution.

ÊëòË¶ÅÔºöÂ∑ÆÁï∞ÂåñÊ†º‰ΩçÊ®ôË®ò (DCM) ÊåáË™ûÊ≥ïÊ†º‰ΩçÊ®ôË®òÂü∫ÊñºË™ûÁæ©„ÄÅË™ûÁî®ÊàñÂÖ∂‰ªñÂõ†Á¥†ÊúâÈÅ∏ÊìáÊÄßÂú∞ÊáâÁî®ÁöÑÁèæË±°„ÄÇDCM ÁöÑÂá∫ÁèæÂ∑≤Âú®ÈáùÂ∞ç‰∫∫È°ûÂèÉËàáËÄÖÁöÑ‰∫∫Â∑•Ë™ûË®ÄÂ≠∏ÁøíÂØ¶È©ó‰∏≠Áç≤ÂæóÁ†îÁ©∂ÔºåÈÄô‰∫õÂØ¶È©óÁâπÂà•Êó®Âú®ÂçÄÂàÜÂ≠∏ÁøíËàáÊ∫ùÈÄöÁöÑÂΩ±ÈüøÔºàSmith & CulbertsonÔºå2020Ôºâ„ÄÇÂü∫ÊñºÁ•ûÁ∂ìÁ∂≤Ë∑ØÁöÑÂ§ö‰∏ªÈ´îÂº∑ÂåñÂ≠∏ÁøíÊû∂ÊßãÂ∑≤Áç≤ÂæóÈ°ØËëóËààË∂£ÔºåÁî®ÊñºÊ®°Êì¨È°û‰ºº‰∫∫È°ûÁöÑË™ûË®ÄÁèæË±°ÁöÑÂá∫Áèæ„ÄÇÂú®Êú¨Á†îÁ©∂‰∏≠ÔºåÊàëÂÄëÊé°Áî®ÈÄôÊ®£ÁöÑÊû∂ÊßãÔºåÂÖ∂‰∏≠‰∏ªÈ´îÂú®ÂèÉËàáÊ∫ùÈÄö‰∫íÂãï‰πãÂâçÂÖàÁøíÂæó‰∏ÄÁ®Æ‰∫∫Â∑•Ë™ûË®ÄÔºåÂæûËÄåËÉΩÁõ¥Êé•Ëàá‰∫∫È°ûÁµêÊûúÈÄ≤Ë°åÊØîËºÉ„ÄÇÂà©Áî®ÈùûÂ∏∏ÈÄöÁî®ÁöÑÊ∫ùÈÄöÊúÄ‰Ω≥ÂåñÊºîÁÆóÊ≥ïÂíåÊ≤íÊúâË™ûË®ÄÊàñË™ûÁæ©ÂÅèÂ•ΩÂÖàÈ©óÁ∂ìÈ©óÁöÑÁ•ûÁ∂ìÁ∂≤Ë∑ØÂ≠∏ÁøíËÄÖÔºåÊàëÂÄëÁöÑÁµêÊûúË≠âÊòéÔºåÂ≠∏ÁøíÊú¨Ë∫´‰∏¶‰∏çÊúÉÂ∞éËá¥ DCMÔºå‰ΩÜÁï∂‰∏ªÈ´îÈÄ≤Ë°åÊ∫ùÈÄöÊôÇÔºåÂ∞±ÊúÉÂá∫ÁèæÊ®ôË®òÁöÑ‰∏çÂêåÁî®Ê≥ï„ÄÇÈÄôÊîØÊåÅ Smith Âíå Culbertson (2020) ÁöÑÁôºÁèæÔºåÂº∑Ë™ø‰∫ÜÊ∫ùÈÄöÂú®Â°ëÈÄ† DCM ‰∏≠ÁöÑÈóúÈçµ‰ΩúÁî®Ôºå‰∏¶Â±ïÁ§∫‰∫ÜÁ•ûÁ∂ì‰∏ªÈ´îÊ®°ÂûãÂú®Ë£úÂÖÖË™ûË®ÄÊºîÂåñÂØ¶È©óÁ†îÁ©∂ÊñπÈù¢ÁöÑÊΩõÂäõ„ÄÇ

##### **Exploring Imbalanced Annotations for Effective In-Context Learning**
2502.04037v1 by Hongfu Gao, Feipeng Zhang, Hao Zeng, Deyu Meng, Bingyi Jing, Hongxin Wei

Large language models (LLMs) have shown impressive performance on downstream
tasks through in-context learning (ICL), which heavily relies on the
demonstrations selected from annotated datasets. Existing selection methods may
hinge on the distribution of annotated datasets, which can often be long-tailed
in real-world scenarios. In this work, we show that imbalanced class
distributions in annotated datasets significantly degrade the performance of
ICL across various tasks and selection methods. Moreover, traditional rebalance
methods fail to ameliorate the issue of class imbalance in ICL. Our method is
motivated by decomposing the distributional differences between annotated and
test datasets into two-component weights: class-wise weights and conditional
bias. The key idea behind our method is to estimate the conditional bias by
minimizing the empirical error on a balanced validation dataset and to employ
the two-component weights to modify the original scoring functions during
selection. Our approach can prevent selecting too many demonstrations from a
single class while preserving the effectiveness of the original selection
methods. Extensive experiments demonstrate the effectiveness of our method,
improving the average accuracy by up to 5.46 on common benchmarks with
imbalanced datasets.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÈÄèÈÅéÊÉÖÂ¢ÉÂ≠∏Áøí (ICL) Âú®‰∏ãÊ∏∏‰ªªÂãô‰∏≠Â±ïÁèæÈ©ö‰∫∫ÁöÑÊïàËÉΩÔºåËÄåÈÄôÈ†ÖÊäÄË°ì‰ª∞Ë≥¥ÂæûÊ®ôË®ªË≥áÊñôÈõÜ‰∏≠ÈÅ∏ÂèñÁöÑÁ§∫ÁØÑÁØÑ‰æã„ÄÇÁèæÊúâÁöÑÈÅ∏ÂèñÊñπÊ≥ïÂèØËÉΩÂèñÊ±∫ÊñºÊ®ôË®ªË≥áÊñôÈõÜÁöÑÂàÜÂ∏ÉÔºåËÄåÂú®ÁèæÂØ¶‰∏ñÁïåÊÉÖÂ¢É‰∏≠ÔºåÈÄô‰∫õË≥áÊñôÈõÜÈÄöÂ∏∏ÊúÉÂëàÁèæÈï∑Â∞æÂàÜÂ∏É„ÄÇÂú®ÈÄôÈ†ÖÁ†îÁ©∂‰∏≠ÔºåÊàëÂÄëÈ°ØÁ§∫Ê®ôË®ªË≥áÊñôÈõÜ‰∏≠‰∏çÂπ≥Ë°°ÁöÑÈ°ûÂà•ÂàÜÂ∏ÉÊúÉÈ°ØËëóÈôç‰Ωé ICL Âú®ÂêÑÁ®Æ‰ªªÂãôÂíåÈÅ∏ÂèñÊñπÊ≥ï‰∏≠ÁöÑÊïàËÉΩ„ÄÇÊ≠§Â§ñÔºåÂÇ≥Áµ±ÁöÑÂÜçÂπ≥Ë°°ÊñπÊ≥ïÁÑ°Ê≥ïÊîπÂñÑ ICL ‰∏≠È°ûÂà•‰∏çÂπ≥Ë°°ÁöÑÂïèÈ°å„ÄÇÊàëÂÄëÁöÑÊ®°ÂûãÈùàÊÑü‰æÜËá™ÊñºÂ∞áÊ®ôË®ªË≥áÊñôÈõÜËàáÊ∏¨Ë©¶Ë≥áÊñôÈõÜ‰πãÈñìÁöÑÂàÜÂ∏ÉÂ∑ÆÁï∞ÂàÜËß£ÊàêÂÖ©ÈÉ®ÂàÜÊ¨äÈáçÔºöÈ°ûÂà•Ê¨äÈáçËàáÊ¢ù‰ª∂ÂÅèÂ∑Æ„ÄÇÊàëÂÄëÊ®°ÂûãËÉåÂæåÁöÑ‰∏ªË¶ÅÊ¶ÇÂøµÊòØÈÄèÈÅéÊúÄÂ∞èÂåñÂπ≥Ë°°È©óË≠âË≥áÊñôÈõÜ‰∏äÁöÑÁ∂ìÈ©óË™§Â∑Æ‰æÜ‰º∞Ë®àÊ¢ù‰ª∂ÂÅèÂ∑ÆÔºå‰∏¶‰ΩøÁî®ÈÄôÂÖ©ÈÉ®ÂàÜÊ¨äÈáç‰æÜ‰øÆÊîπÈÅ∏ÂèñÊúüÈñìÁöÑÂéüÂßãË©ïÂàÜÂáΩÊï∏„ÄÇÊàëÂÄëÁöÑÂÅöÊ≥ïÂèØ‰ª•ÈÅøÂÖçÂæûÂñÆ‰∏ÄÈ°ûÂà•‰∏≠ÈÅ∏ÂèñÈÅéÂ§öÁ§∫ÁØÑÁØÑ‰æãÔºåÂêåÊôÇ‰øùÁïôÂéüÂßãÈÅ∏ÂèñÊñπÊ≥ïÁöÑÊúâÊïàÊÄß„ÄÇÂª£Ê≥õÁöÑÂØ¶È©óË≠âÊòé‰∫ÜÊàëÂÄëÊ®°ÂûãÁöÑÊúâÊïàÊÄßÔºåÂú®‰∏çÂπ≥Ë°°Ë≥áÊñôÈõÜÁöÑÂ∏∏Ë¶ãÂü∫Ê∫ñ‰∏äÔºåÂ∞áÂπ≥ÂùáÊ∫ñÁ¢∫Â∫¶ÊèêÂçá‰∫Ü 5.46%„ÄÇ

##### **Generalize Drug Response Prediction by Latent Independent Projection for Asymmetric Constrained Domain Generalization**
2502.04034v1 by Ran Song, Yinpu Bai, Hui Liu

The accurate prediction of drug responses remains a formidable challenge,
particularly at the single-cell level and in clinical treatment contexts. Some
studies employ transfer learning techniques to predict drug responses in
individual cells and patients, but they require access to target-domain data
during training, which is often unavailable or only obtainable in future. In
this study, we propose a novel domain generalization framework, termed
panCancerDR, to address this challenge. We conceptualize each cancer type as a
distinct source domain, with its cell lines serving as domain-specific samples.
Our primary objective is to extract domain-invariant features from the
expression profiles of cell lines across diverse cancer types, thereby
generalize the predictive capacity to out-of-distribution samples. To enhance
robustness, we introduce a latent independence projection (LIP) module that
encourages the encoder to extract informative yet non-redundant features. Also,
we propose an asymmetric adaptive clustering constraint, which clusters
drug-sensitive samples into a compact group while drives resistant samples
dispersed across separate clusters in the latent space. Our empirical
experiments demonstrate that panCancerDR effectively learns task-relevant
features from diverse source domains, and achieves accurate predictions of drug
response for unseen cancer type during training. Furthermore, when evaluated on
single-cell and patient-level prediction tasks, our model-trained solely on in
vitro cell line data without access to target-domain information-consistently
outperforms and matched current state-of-the-art methods. These findings
highlights the potential of our method for real-world clinical applications.

ÊëòË¶ÅÔºö<paragraph>Ê∫ñÁ¢∫È†êÊ∏¨Ëó•Áâ©ÂèçÊáâ‰ªçÁÑ∂ÊòØ‰∏ÄÈ†ÖËâ±ÈâÖÁöÑÊåëÊà∞ÔºåÁâπÂà•ÊòØÂú®ÂñÆÁ¥∞ËÉûÂ±§Á¥öÂíåËá®Â∫äÊ≤ªÁôÇËÉåÊôØ‰∏≠„ÄÇ‰∏Ä‰∫õÁ†îÁ©∂Êé°Áî®ÈÅ∑ÁßªÂ≠∏ÁøíÊäÄË°ì‰æÜÈ†êÊ∏¨ÂÄãÂà•Á¥∞ËÉûÂíåÊÇ£ËÄÖÁöÑËó•Áâ©ÂèçÊáâÔºå‰ΩÜÂÆÉÂÄëÈúÄË¶ÅÂú®Ë®ìÁ∑¥ÊúüÈñìÂ≠òÂèñÁõÆÊ®ôÁ∂≤ÂüüË≥áÊñôÔºåËÄåÈÄô‰∫õË≥áÊñôÈÄöÂ∏∏ÁÑ°Ê≥ïÂèñÂæóÔºåÊàñÂè™ËÉΩÂú®Êú™‰æÜÂèñÂæó„ÄÇÂú®ÈÄôÈ†ÖÁ†îÁ©∂‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∏ÄÂÄãÊñ∞Á©éÁöÑÁ∂≤ÂüüÊ¶ÇÂåñÊû∂ÊßãÔºåÁ®±ÁÇ∫ panCancerDRÔºå‰ª•ÊáâÂ∞çÈÄôÈ†ÖÊåëÊà∞„ÄÇÊàëÂÄëÂ∞áÊØèÁ®ÆÈ°ûÂûãÁöÑÁôåÁóáÊ¶ÇÂøµÂåñÁÇ∫‰∏ÄÂÄã‰∏çÂêåÁöÑ‰æÜÊ∫êÁ∂≤ÂüüÔºåÂÖ∂Á¥∞ËÉûÊ†™‰ΩúÁÇ∫ÁâπÂÆöÁ∂≤ÂüüÁöÑÊ®£Êú¨„ÄÇÊàëÂÄëÁöÑÈ¶ñË¶ÅÁõÆÊ®ôÊòØÂæû‰∏çÂêåÁôåÁóáÈ°ûÂûãÁöÑÁ¥∞ËÉûÊ†™Ë°®ÁèæÁâπÂæµ‰∏≠ËêÉÂèñÁ∂≤Âüü‰∏çËÆäÁâπÂæµÔºåÂæûËÄåÂ∞áÈ†êÊ∏¨ËÉΩÂäõÊ¶ÇÂåñÂà∞ÂàÜÂ∏ÉÂ§ñÁöÑÊ®£Êú¨„ÄÇÁÇ∫‰∫ÜÂ¢ûÂº∑Á©©ÂÅ•ÊÄßÔºåÊàëÂÄëÂºïÂÖ•‰∏ÄÂÄãÊΩõÂú®Áç®Á´ãÊäïÂΩ± (LIP) Ê®°ÁµÑÔºåÈºìÂãµÁ∑®Á¢ºÂô®ËêÉÂèñÊúâË≥áË®ä‰ΩÜÈùûÂÜóÈ§òÁöÑÁâπÂæµ„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÊèêÂá∫‰∏ÄÂÄãÈùûÂ∞çÁ®±Ëá™ÈÅ©ÊáâËÅöÈ°ûÁ¥ÑÊùüÔºåÂ∞áÂ∞çËó•Áâ©ÊïèÊÑüÁöÑÊ®£Êú¨ËÅöÈ°ûÂà∞‰∏ÄÂÄãÁ∑äÊπäÁöÑÁæ§ÁµÑ‰∏≠ÔºåÂêåÊôÇÈ©ÖÂãïÊäóËó•ÊÄßÊ®£Êú¨ÂàÜÊï£Âú®ÊΩõÂú®Á©∫Èñì‰∏≠ÁöÑ‰∏çÂêåÁæ§ÁµÑ‰∏≠„ÄÇÊàëÂÄëÁöÑÂØ¶Ë≠âÂØ¶È©óË≠âÊòéÔºåpanCancerDR ÊúâÊïàÂú∞Âæû‰∏çÂêåÁöÑ‰æÜÊ∫êÁ∂≤ÂüüÂ≠∏ÁøíËàá‰ªªÂãôÁõ∏ÈóúÁöÑÁâπÂæµÔºå‰∏¶Âú®Ë®ìÁ∑¥ÊúüÈñìÂ∞çÊú™Ë¶ãÁöÑÁôåÁóáÈ°ûÂûãÂØ¶ÁèæÊ∫ñÁ¢∫ÁöÑËó•Áâ©ÂèçÊáâÈ†êÊ∏¨„ÄÇÊ≠§Â§ñÔºåÁï∂Âú®ÂñÆÁ¥∞ËÉûÂíåÊÇ£ËÄÖÂ±§Á¥öÈ†êÊ∏¨‰ªªÂãô‰∏≠ÈÄ≤Ë°åË©ï‰º∞ÊôÇÔºåÊàëÂÄëÁöÑÊ®°ÂûãÂÉÖÂú®È´îÂ§ñÁ¥∞ËÉûÊ†™Ë≥áÊñô‰∏äË®ìÁ∑¥ÔºåËÄåÊ≤íÊúâÂ≠òÂèñÁõÆÊ®ôÁ∂≤ÂüüË≥áË®äÔºåÂßãÁµÇÂÑ™Êñº‰∏¶Á¨¶ÂêàÁï∂ÂâçÁöÑÊúÄÊñ∞ÊñπÊ≥ï„ÄÇÈÄô‰∫õÁôºÁèæÁ™ÅÈ°Ø‰∫ÜÊàëÂÄëÁöÑÊñπÊ≥ïÂú®ÂØ¶ÈöõËá®Â∫äÊáâÁî®‰∏≠ÁöÑÊΩõÂäõ„ÄÇ</paragraph>

##### **Fine, I'll Merge It Myself: A Multi-Fidelity Framework for Automated Model Merging**
2502.04030v1 by Guinan Su, Jonas Geiping

Reasoning capabilities represent a critical frontier for large language
models (LLMs), but developing them requires extensive proprietary datasets and
computational resources. One way to efficiently supplement capabilities with is
by model merging, which offers a promising alternative by combining multiple
models without retraining. However, current merging approaches rely on
manually-designed strategies for merging hyperparameters, limiting the
exploration of potential model combinations and requiring significant human
effort. We propose an Automated Model Merging Framework that enables
fine-grained exploration of merging strategies while reducing costs through
multi-fidelity approximations. We support both single and multi-objective
optimization and introduce two novel search spaces: layerwise fusion (LFS) and
depth-wise integration (DIS). Evaluating across a number of benchmarks, we find
that the search autonomously finds 1) Merges that further boost
single-objective performance, even on tasks the model has already been
finetuned on, and 2) Merges that optimize multi-objective frontiers across
tasks. Effective merges are found with limited compute, e.g. within less than
500 search steps.

ÊëòË¶ÅÔºöÊé®ÁêÜËÉΩÂäõ‰ª£Ë°®Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑÈóúÈçµÂâçÊ≤øÔºå‰ΩÜÈñãÁôºÂÆÉÂÄëÈúÄË¶ÅÂª£Ê≥õÁöÑÂ∞àÊúâÊï∏ÊìöÈõÜÂíåË®àÁÆóË≥áÊ∫ê„ÄÇÊúâÊïàË£úÂÖÖÂäüËÉΩÁöÑ‰∏ÄÁ®ÆÊñπÊ≥ïÊòØÊ®°ÂûãÂêà‰ΩµÔºåÂÆÉÊèê‰æõ‰∫Ü‰∏ÄÂÄãÊúâÂâçÈÄîÁöÑÊõø‰ª£ÊñπÊ°àÔºåÂèØ‰ª•Âêà‰ΩµÂ§öÂÄãÊ®°ÂûãËÄåÁÑ°ÈúÄÈáçÊñ∞Ë®ìÁ∑¥„ÄÇÁÑ∂ËÄåÔºåÁï∂ÂâçÂêà‰ΩµÊñπÊ≥ï‰æùË≥¥Êñº‰∫∫Â∑•Ë®≠Ë®àÁöÑË∂ÖÂèÉÊï∏Âêà‰ΩµÁ≠ñÁï•ÔºåÈôêÂà∂‰∫ÜÊΩõÂú®Ê®°ÂûãÁµÑÂêàÁöÑÊé¢Á¥¢Ôºå‰∏¶ÈúÄË¶ÅÂ§ßÈáè‰∫∫Âäõ„ÄÇÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãËá™ÂãïÂåñÊ®°ÂûãÂêà‰ΩµÊ°ÜÊû∂ÔºåÂÆÉËÉΩÂ§†Á≤æÁ¥∞Âú∞Êé¢Á¥¢Âêà‰ΩµÁ≠ñÁï•ÔºåÂêåÊôÇÈÄöÈÅéÂ§ö‰øùÁúüËøë‰ººÈôç‰ΩéÊàêÊú¨„ÄÇÊàëÂÄëÊîØÊè¥ÂñÆ‰∏ÄÂíåÂ§öÁõÆÊ®ôÊúÄ‰Ω≥ÂåñÔºå‰∏¶ÂºïÂÖ•‰∫ÜÂÖ©ÂÄãÊñ∞Á©éÁöÑÊêúÁ¥¢Á©∫ÈñìÔºöÈÄêÂ±§ËûçÂêà (LFS) ÂíåÊ∑±Â∫¶Êï¥Âêà (DIS)„ÄÇÂú®Â§öÂÄãÂü∫Ê∫ñ‰∏äÈÄ≤Ë°åË©ï‰º∞ÔºåÊàëÂÄëÁôºÁèæÊêúÁ¥¢ÊúÉËá™ÂãïÊâæÂà∞ 1) ÈÄ≤‰∏ÄÊ≠•ÊèêÂçáÂñÆ‰∏ÄÁõÆÊ®ôÊïàËÉΩÁöÑÂêà‰ΩµÔºåÂç≥‰ΩøÂú®Ê®°ÂûãÂ∑≤Á∂ìÈÄ≤Ë°åÂæÆË™øÁöÑ‰ªªÂãô‰∏äÔºå‰ª•Âèä 2) Âú®‰ªªÂãô‰∏≠ÊúÄ‰Ω≥ÂåñÂ§öÁõÆÊ®ôÂâçÊ≤øÁöÑÂêà‰Ωµ„ÄÇÂú®ÊúâÈôêÁöÑÈÅãÁÆó‰∏ãÔºå‰æãÂ¶ÇÂú®‰∏çÂà∞ 500 ÂÄãÊêúÁ¥¢Ê≠•È©üÂÖßÔºåÂ∞±ËÉΩÊâæÂà∞ÊúâÊïàÁöÑÂêà‰Ωµ„ÄÇ

##### **Quantification of Biodiversity from Historical Survey Text with LLM-based Best-Worst Scaling**
2502.04022v1 by Thomas Haider, Tobias Perschl, Malte Rehbein

In this study, we evaluate methods to determine the frequency of species via
quantity estimation from historical survey text. To that end, we formulate
classification tasks and finally show that this problem can be adequately
framed as a regression task using Best-Worst Scaling (BWS) with Large Language
Models (LLMs). We test Ministral-8B, DeepSeek-V3, and GPT-4, finding that the
latter two have reasonable agreement with humans and each other. We conclude
that this approach is more cost-effective and similarly robust compared to a
fine-grained multi-class approach, allowing automated quantity estimation
across species.

ÊëòË¶ÅÔºöÂú®Êú¨Á†îÁ©∂‰∏≠ÔºåÊàëÂÄëË©ï‰º∞‰∫ÜÈÄèÈÅéÊ≠∑Âè≤Ë™øÊü•ÊñáÂ≠ó‰∏≠ÁöÑÊï∏Èáè‰º∞Ë®à‰æÜÁ¢∫ÂÆöÁâ©Á®ÆÈ†ªÁéáÁöÑÊñπÊ≥ï„ÄÇÁÇ∫Ê≠§ÔºåÊàëÂÄëÂà∂ÂÆö‰∫ÜÂàÜÈ°û‰ªªÂãôÔºåÊúÄÂæåË°®ÊòéÈÄôÂÄãÂïèÈ°åÂèØ‰ª•Áî®Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑÊúÄ‰Ω≥ÊúÄÂ∑ÆÁ∏ÆÊîæ (BWS) ‰ΩúÁÇ∫ÂõûÊ≠∏‰ªªÂãô‰æÜÈÅ©Áï∂Âú∞ÊßãÂª∫„ÄÇÊàëÂÄëÊ∏¨Ë©¶‰∫Ü Ministral-8B„ÄÅDeepSeek-V3 Âíå GPT-4ÔºåÁôºÁèæÂæåÂÖ©ËÄÖËàá‰∫∫È°ûÂíåÂΩºÊ≠§ÈÉΩÊúâÂêàÁêÜÁöÑÂÖ±Ë≠ò„ÄÇÊàëÂÄëÂæóÂá∫ÁµêË´ñÔºåËàáÁ¥∞Á≤íÂ∫¶ÁöÑÂ§öÈ°ûÂà•ÊñπÊ≥ïÁõ∏ÊØîÔºåÈÄôÁ®ÆÊñπÊ≥ïÊõ¥ÂÖ∑ÊàêÊú¨ÊïàÁõä‰∏îÂêåÊ®£Á©©ÂÅ•ÔºåÂÖÅË®±Ë∑®Áâ©Á®ÆÈÄ≤Ë°åËá™ÂãïÊï∏Èáè‰º∞Ë®à„ÄÇ

##### **Automating a Complete Software Test Process Using LLMs: An Automotive Case Study**
2502.04008v1 by Shuai Wang, Yinan Yu, Robert Feldt, Dhasarathy Parthasarathy

Vehicle API testing verifies whether the interactions between a vehicle's
internal systems and external applications meet expectations, ensuring that
users can access and control various vehicle functions and data. However, this
task is inherently complex, requiring the alignment and coordination of API
systems, communication protocols, and even vehicle simulation systems to
develop valid test cases. In practical industrial scenarios, inconsistencies,
ambiguities, and interdependencies across various documents and system
specifications pose significant challenges. This paper presents a system
designed for the automated testing of in-vehicle APIs. By clearly defining and
segmenting the testing process, we enable Large Language Models (LLMs) to focus
on specific tasks, ensuring a stable and controlled testing workflow.
Experiments conducted on over 100 APIs demonstrate that our system effectively
automates vehicle API testing. The results also confirm that LLMs can
efficiently handle mundane tasks requiring human judgment, making them suitable
for complete automation in similar industrial contexts.

ÊëòË¶ÅÔºöËªäËºõ API Ê∏¨Ë©¶È©óË≠âËªäËºõÂÖßÈÉ®Á≥ªÁµ±ËàáÂ§ñÈÉ®ÊáâÁî®Á®ãÂºè‰πãÈñìÁöÑ‰∫íÂãïÊòØÂê¶Á¨¶ÂêàÈ†êÊúüÔºåÁ¢∫‰øù‰ΩøÁî®ËÄÖÂèØ‰ª•Â≠òÂèñÂíåÊéßÂà∂ÂêÑÁ®ÆËªäËºõÂäüËÉΩÂíåË≥áÊñô„ÄÇÁÑ∂ËÄåÔºåÈÄôÈ†Ö‰ªªÂãôÊú¨Ë≥™‰∏äÂæàË§áÈõúÔºåÈúÄË¶Å API Á≥ªÁµ±„ÄÅÈÄöË®äÂçîÂÆöÔºåÁîöËá≥ËªäËºõÊ®°Êì¨Á≥ªÁµ±ÁöÑÂ∞çÈΩäÂíåÂçîË™øÔºåÊâçËÉΩÈñãÁôºÂá∫ÊúâÊïàÁöÑÊ∏¨Ë©¶Ê°à‰æã„ÄÇÂú®ÂØ¶ÈöõÁöÑÁî¢Ê•≠ÊÉÖÂ¢É‰∏≠ÔºåÂêÑÂÄãÊñá‰ª∂ÂíåÁ≥ªÁµ±Ë¶èÊ†º‰πãÈñìÁöÑ‰∏ç‰∏ÄËá¥ÊÄß„ÄÅÊ®°Á≥äÊÄßÔºå‰ª•ÂèäÁõ∏‰∫í‰æùË≥¥ÊÄßÊßãÊàê‰∫ÜÈáçÂ§ßÁöÑÊåëÊà∞„ÄÇÊú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÂ•óÂ∞àÈñÄÁî®ÊñºËªäËºâ API Ëá™ÂãïÂåñÊ∏¨Ë©¶ÁöÑÁ≥ªÁµ±„ÄÇÈÄèÈÅéÊ∏ÖÊ•öÂÆöÁæ©ÂíåÂçÄÈöîÊ∏¨Ë©¶ÊµÅÁ®ãÔºåÊàëÂÄëËÆìÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ËÉΩÂ∞àÊ≥®ÊñºÁâπÂÆö‰ªªÂãôÔºåÁ¢∫‰øùÊ∏¨Ë©¶Â∑•‰ΩúÊµÅÁ®ãÁ©©ÂÆö‰∏îÂèóÊéß„ÄÇÂú®Ë∂ÖÈÅé 100 ÂÄã API ‰∏äÈÄ≤Ë°åÁöÑÂØ¶È©óË≠âÊòéÔºåÊàëÂÄëÁöÑÁ≥ªÁµ±ÊúâÊïàÂú∞Ëá™ÂãïÂåñ‰∫ÜËªäËºõ API Ê∏¨Ë©¶„ÄÇÁµêÊûú‰πüË≠âÂØ¶ÔºåLLM ËÉΩÊúâÊïàÁéáÂú∞ËôïÁêÜÈúÄË¶Å‰∫∫È°ûÂà§Êñ∑ÁöÑ‰æãË°åÂ∑•‰ΩúÔºå‰ΩøÂÖ∂ÈÅ©ÂêàÊñºÈ°û‰ººÁî¢Ê•≠ÊÉÖÂ¢É‰∏≠ÁöÑÂÆåÊï¥Ëá™ÂãïÂåñ„ÄÇ

##### **Online Learning of Counter Categories and Ratings in PvP Games**
2502.03998v1 by Chiu-Chou Lin, I-Chen Wu

In competitive games, strength ratings like Elo are widely used to quantify
player skill and support matchmaking by accounting for skill disparities better
than simple win rate statistics. However, scalar ratings cannot handle complex
intransitive relationships, such as counter strategies seen in
Rock-Paper-Scissors. To address this, recent work introduced Neural Rating
Table and Neural Counter Table, which combine scalar ratings with discrete
counter categories to model intransitivity. While effective, these methods rely
on neural network training and cannot perform real-time updates. In this paper,
we propose an online update algorithm that extends Elo principles to
incorporate real-time learning of counter categories. Our method dynamically
adjusts both ratings and counter relationships after each match, preserving the
explainability of scalar ratings while addressing intransitivity. Experiments
on zero-sum competitive games demonstrate its practicality, particularly in
scenarios without complex team compositions.

ÊëòË¶ÅÔºöÂú®Á´∂Áà≠ÈÅäÊà≤‰∏≠ÔºåÂÉè Elo ÈÄôÊ®£ÁöÑÂº∑Â∫¶Ë©ïÂàÜË¢´Âª£Ê≥õÁî®ÊñºÈáèÂåñÁé©ÂÆ∂ÊäÄÂ∑ßÂíåÊîØÊè¥ÈÖçÂ∞çÊ©üÂà∂ÔºåËóâÁî±ËÄÉÈáèÊäÄÂ∑ßÂ∑ÆÁï∞ÔºåË°®ÁèæÂÑ™ÊñºÂñÆÁ¥îÁöÑÂãùÁéáÁµ±Ë®à„ÄÇÁÑ∂ËÄåÔºåÊ®ôÈáèË©ïÂàÜÁÑ°Ê≥ïËôïÁêÜË§áÈõúÁöÑÈùûÈÅûÁßªÈóú‰øÇÔºå‰æãÂ¶ÇÂú®Ââ™ÂàÄÁü≥È†≠Â∏É‰∏≠ÁúãÂà∞ÁöÑÂèçÂà∂Á≠ñÁï•„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåÊúÄËøëÁöÑÁ†îÁ©∂ÂºïÂÖ•‰∫ÜÁ•ûÁ∂ìË©ïÂàÜË°®ÂíåÁ•ûÁ∂ìÂèçÂà∂Ë°®ÔºåÂÆÉÂÄëÂ∞áÊ®ôÈáèË©ïÂàÜËàáÈõ¢Êï£ÂèçÂà∂È°ûÂà•ÁµêÂêàÔºå‰ª•Âª∫Ê®°ÈùûÈÅûÁßªÊÄß„ÄÇÂÑòÁÆ°ÊúâÊïàÔºåÈÄô‰∫õÊñπÊ≥ï‰æùË≥¥ÊñºÁ•ûÁ∂ìÁ∂≤Ë∑ØË®ìÁ∑¥ÔºåÁÑ°Ê≥ïÂü∑Ë°åÂç≥ÊôÇÊõ¥Êñ∞„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÁ∑ö‰∏äÊõ¥Êñ∞ÊºîÁÆóÊ≥ïÔºåÂ∞á Elo ÂéüÂâáÂª∂‰º∏Âà∞Á¥çÂÖ•ÂèçÂà∂È°ûÂà•ÁöÑÂç≥ÊôÇÂ≠∏Áøí„ÄÇÊàëÂÄëÁöÑÊºîÁÆóÊ≥ïÂú®ÊØèÊ¨°ÊØîË≥ΩÂæåÂãïÊÖãË™øÊï¥Ë©ïÂàÜÂíåÂèçÂà∂Èóú‰øÇÔºåÂú®ËôïÁêÜÈùûÈÅûÁßªÊÄßÁöÑÂêåÊôÇÔºå‰øùÁïôÊ®ôÈáèË©ïÂàÜÁöÑÂèØËß£ÈáãÊÄß„ÄÇÂú®Èõ∂ÂíåÁ´∂Áà≠ÈÅäÊà≤‰∏≠ÁöÑÂØ¶È©óË≠âÊòé‰∫ÜÂÆÉÁöÑÂØ¶Áî®ÊÄßÔºåÁâπÂà•ÊòØÂú®Ê≤íÊúâË§áÈõúÂúòÈöäÁµÑÊàêÁöÑÂ†¥ÊôØ‰∏≠„ÄÇ

##### **Ontology-Guided, Hybrid Prompt Learning for Generalization in Knowledge Graph Question Answering**
2502.03992v1 by Longquan Jiang, Junbo Huang, Cedric M√∂ller, Ricardo Usbeck

Most existing Knowledge Graph Question Answering (KGQA) approaches are
designed for a specific KG, such as Wikidata, DBpedia or Freebase. Due to the
heterogeneity of the underlying graph schema, topology and assertions, most
KGQA systems cannot be transferred to unseen Knowledge Graphs (KGs) without
resource-intensive training data. We present OntoSCPrompt, a novel Large
Language Model (LLM)-based KGQA approach with a two-stage architecture that
separates semantic parsing from KG-dependent interactions. OntoSCPrompt first
generates a SPARQL query structure (including SPARQL keywords such as SELECT,
ASK, WHERE and placeholders for missing tokens) and then fills them with
KG-specific information. To enhance the understanding of the underlying KG, we
present an ontology-guided, hybrid prompt learning strategy that integrates KG
ontology into the learning process of hybrid prompts (e.g., discrete and
continuous vectors). We also present several task-specific decoding strategies
to ensure the correctness and executability of generated SPARQL queries in both
stages. Experimental results demonstrate that OntoSCPrompt performs as well as
SOTA approaches without retraining on a number of KGQA datasets such as CWQ,
WebQSP and LC-QuAD 1.0 in a resource-efficient manner and can generalize well
to unseen domain-specific KGs like DBLP-QuAD and CoyPu KG Code:
\href{https://github.com/LongquanJiang/OntoSCPrompt}{https://github.com/LongquanJiang/OntoSCPrompt}

ÊëòË¶ÅÔºöÁèæÊúâÁöÑÁü•Ë≠òÂúñË≠úÂïèÁ≠îÔºàKGQAÔºâÊñπÊ≥ïÂ§ßÂ§öÊòØÁÇ∫ÁâπÂÆö KG ËÄåË®≠Ë®àÁöÑÔºå‰æãÂ¶Ç Wikidata„ÄÅDBpedia Êàñ Freebase„ÄÇÁî±ÊñºÂ∫ïÂ±§ÂúñÂΩ¢Ê®°Âºè„ÄÅÊãìÊí≤ÂíåÊñ∑Ë®ÄÁöÑÁï∞Ë≥™ÊÄßÔºåÂ§ßÂ§öÊï∏ KGQA Á≥ªÁµ±ÁÑ°Ê≥ïÂú®Ê≤íÊúâË≥áÊ∫êÂØÜÈõÜÂûãË®ìÁ∑¥Ë≥áÊñôÁöÑÊÉÖÊ≥Å‰∏ãËΩâÁßªÂà∞Êú™Ë¶ãÈÅéÁöÑÁü•Ë≠òÂúñË≠úÔºàKGÔºâ„ÄÇÊàëÂÄëÊèêÂá∫ OntoSCPromptÔºåÈÄôÊòØ‰∏ÄÁ®ÆÂü∫ÊñºÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÔºàLLMÔºâÁöÑÊñ∞Âûã KGQA ÊñπÊ≥ïÔºåÊé°Áî®ÂÖ©ÈöéÊÆµÊû∂ÊßãÔºåÂ∞áË™ûÁæ©Ëß£ÊûêËàá‰æùË≥¥ KG ÁöÑ‰∫íÂãïÂàÜÈñã„ÄÇOntoSCPrompt È¶ñÂÖàÁîüÊàê SPARQL Êü•Ë©¢ÁµêÊßãÔºàÂåÖÊã¨ SPARQL ÈóúÈçµÂ≠óÔºå‰æãÂ¶Ç SELECT„ÄÅASK„ÄÅWHERE ÂíåÁº∫Â§±‰ª§ÁâåÁöÑ‰Ωî‰ΩçÁ¨¶ÔºâÔºåÁÑ∂ÂæåÁî® KG ÁâπÂÆöÁöÑË≥áË®äÂ°´ÂØ´ÂÆÉÂÄë„ÄÇÁÇ∫‰∫ÜÂ¢ûÂº∑Â∞çÂ∫ïÂ±§ KG ÁöÑÁêÜËß£ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÁî±Êú¨‰ΩìÊåáÂ∞éÁöÑÊ∑∑ÂêàÊèêÁ§∫Â≠∏ÁøíÁ≠ñÁï•ÔºåÂ∞á KG Êú¨‰ΩìÊï¥ÂêàÂà∞Ê∑∑ÂêàÊèêÁ§∫Ôºà‰æãÂ¶ÇÔºåÈõ¢Êï£ÂíåÈÄ£Á∫åÂêëÈáèÔºâÁöÑÂ≠∏ÁøíÈÅéÁ®ã‰∏≠„ÄÇÊàëÂÄëÈÇÑÊèêÂá∫‰∫ÜÂ§öÁ®ÆÁâπÂÆö‰ªªÂãôÁöÑËß£Á¢ºÁ≠ñÁï•Ôºå‰ª•Á¢∫‰øùÂú®ÂÖ©ÂÄãÈöéÊÆµ‰∏≠ÁîüÊàêÁöÑ SPARQL Êü•Ë©¢ÁöÑÊ≠£Á¢∫ÊÄßÂíåÂèØÂü∑Ë°åÊÄß„ÄÇÂØ¶È©óÁµêÊûúË°®ÊòéÔºåOntoSCPrompt Âú® CWQ„ÄÅWebQSP Âíå LC-QuAD 1.0 Á≠âÂ§öÂÄã KGQA Ë≥áÊñôÈõÜ‰∏äÂü∑Ë°åÊôÇÔºåÊïàËÉΩËàá SOTA ÊñπÊ≥ï‰∏ÄÊ®£Â•ΩÔºå‰∏îË≥áÊ∫ê‰ΩøÁî®ÊïàÁéáÈ´òÔºå‰∏¶‰∏îÂèØ‰ª•ÂæàÂ•ΩÂú∞Ê¶ÇÊã¨Âà∞Êú™Ë¶ãÈÅéÁöÑÁâπÂÆöÈ†òÂüü KGÔºå‰æãÂ¶Ç DBLP-QuAD Âíå CoyPu KG CodeÔºö
\href{https://github.com/LongquanJiang/OntoSCPrompt}{https://github.com/LongquanJiang/OntoSCPrompt}

##### **PGB: One-Shot Pruning for BERT via Weight Grouping and Permutation**
2502.03984v1 by Hyemin Lim, Jaeyeon Lee, Dong-Wan Choi

Large pretrained language models such as BERT suffer from slow inference and
high memory usage, due to their huge size. Recent approaches to compressing
BERT rely on iterative pruning and knowledge distillation, which, however, are
often too complicated and computationally intensive. This paper proposes a
novel semi-structured one-shot pruning method for BERT, called
$\textit{Permutation and Grouping for BERT}$ (PGB), which achieves high
compression efficiency and sparsity while preserving accuracy. To this end, PGB
identifies important groups of individual weights by permutation and prunes all
other weights as a structure in both multi-head attention and feed-forward
layers. Furthermore, if no important group is formed in a particular layer, PGB
drops the entire layer to produce an even more compact model. Our experimental
results on BERT$_{\text{BASE}}$ demonstrate that PGB outperforms the
state-of-the-art structured pruning methods in terms of computational cost and
accuracy preservation.

ÊëòË¶ÅÔºöÂ§ßÂûãÈ†êË®ìÁ∑¥Ë™ûË®ÄÊ®°ÂûãÔºå‰æãÂ¶Ç BERTÔºåÁî±ÊñºÂÖ∂ÈæêÂ§ßË¶èÊ®°ÔºåÊúÉÈÄ†ÊàêÊé®Ë´ñÈÄüÂ∫¶ÊÖ¢‰∏îË®òÊÜ∂È´î‰ΩøÁî®ÈáèÈ´òÁöÑÂïèÈ°å„ÄÇÊúÄËøëÂ£ìÁ∏Æ BERT ÁöÑÊñπÊ≥ï‰æùË≥¥ÊñºÂèçË¶ÜÂâ™ÊûùÂíåÁü•Ë≠òËí∏È§æÔºåÁÑ∂ËÄåÔºåÈÄô‰∫õÊñπÊ≥ïÈÄöÂ∏∏ÈÅéÊñºË§áÈõú‰∏îË®àÁÆóÂØÜÈõÜ„ÄÇÊú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÊñ∞ÁöÑÂçäÁµêÊßãÂåñ‰∏ÄÊ¨°ÊÄßÂâ™ÊûùÊñπÊ≥ïÔºåÁ®±ÁÇ∫ BERT ÁöÑÊéíÂàóÂíåÂàÜÁµÑ (PGB)ÔºåÂÆÉÂú®‰øùÊåÅÊ∫ñÁ¢∫ÊÄßÁöÑÂêåÊôÇÔºåÈÅîÂà∞‰∫ÜÈ´òÂ£ìÁ∏ÆÊïàÁéáÂíåÁ®ÄÁñèÊÄß„ÄÇÁÇ∫Ê≠§ÔºåPGB ÈÄèÈÅéÊéíÂàóË≠òÂà•Âá∫ÈáçË¶ÅÁæ§ÁµÑÁöÑÂÄãÂà•Ê¨äÈáçÔºå‰∏¶Â∞áÊâÄÊúâÂÖ∂‰ªñÊ¨äÈáçÂâ™ÊûùÁÇ∫Â§öÈ†≠Ê≥®ÊÑèÂäõÂíåÂâçÈ•ãÂ±§‰∏≠ÁöÑÁµêÊßã„ÄÇÊ≠§Â§ñÔºåÂ¶ÇÊûúÂú®ÁâπÂÆöÂ±§‰∏≠Ê≤íÊúâÂΩ¢ÊàêÈáçË¶ÅÁæ§ÁµÑÔºåPGB ÊúÉÂà™Èô§Êï¥ÂÄãÂ±§‰ª•Áî¢ÁîüÊõ¥Á∑äÊπäÁöÑÊ®°Âûã„ÄÇÊàëÂÄëÂú® BERT$_{\text{BASE}}$ ‰∏äÁöÑÂØ¶È©óÁµêÊûúË°®ÊòéÔºåPGB Âú®Ë®àÁÆóÊàêÊú¨ÂíåÊ∫ñÁ¢∫ÊÄß‰øùÊåÅÊñπÈù¢ÂÑ™ÊñºÊúÄÂÖàÈÄ≤ÁöÑÁµêÊßãÂåñÂâ™ÊûùÊñπÊ≥ï„ÄÇ

##### **Towards Unified Music Emotion Recognition across Dimensional and Categorical Models**
2502.03979v1 by Jaeyong Kang, Dorien Herremans

One of the most significant challenges in Music Emotion Recognition (MER)
comes from the fact that emotion labels can be heterogeneous across datasets
with regard to the emotion representation, including categorical (e.g., happy,
sad) versus dimensional labels (e.g., valence-arousal). In this paper, we
present a unified multitask learning framework that combines these two types of
labels and is thus able to be trained on multiple datasets. This framework uses
an effective input representation that combines musical features (i.e., key and
chords) and MERT embeddings. Moreover, knowledge distillation is employed to
transfer the knowledge of teacher models trained on individual datasets to a
student model, enhancing its ability to generalize across multiple tasks. To
validate our proposed framework, we conducted extensive experiments on a
variety of datasets, including MTG-Jamendo, DEAM, PMEmo, and EmoMusic.
According to our experimental results, the inclusion of musical features,
multitask learning, and knowledge distillation significantly enhances
performance. In particular, our model outperforms the state-of-the-art models,
including the best-performing model from the MediaEval 2021 competition on the
MTG-Jamendo dataset. Our work makes a significant contribution to MER by
allowing the combination of categorical and dimensional emotion labels in one
unified framework, thus enabling training across datasets.

ÊëòË¶ÅÔºöÈü≥Ê®ÇÊÉÖÁ∑íËæ®Ë≠ò (MER) ‰∏≠ÊúÄÈ°ØËëóÁöÑÊåëÊà∞‰πã‰∏ÄÊòØÔºåÊÉÖÁ∑íÊ®ôÁ±§Âú®Ë≥áÊñôÈõÜ‰πãÈñìÂèØËÉΩ‰∏çÁõ°Áõ∏ÂêåÔºåÈÄôÂèñÊ±∫ÊñºÊÉÖÁ∑íË°®ÂæµÔºåÂåÖÊã¨ÂàÜÈ°ûÊ®ôÁ±§Ôºà‰æãÂ¶ÇÔºöÂø´Ê®Ç„ÄÅÊÇ≤ÂÇ∑ÔºâËàáÁ∂≠Â∫¶Ê®ôÁ±§Ôºà‰æãÂ¶ÇÔºöÊïàÂÉπ-ÂñöÈÜíÔºâ„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∏ÄÂÄãÁµ±‰∏ÄÁöÑÂ§ö‰ªªÂãôÂ≠∏ÁøíÊû∂ÊßãÔºåÁµêÂêàÈÄôÂÖ©Á®ÆÊ®ôÁ±§È°ûÂûãÔºåÂõ†Ê≠§ËÉΩÂ§†Âú®Â§öÂÄãË≥áÊñôÈõÜ‰∏äÈÄ≤Ë°åË®ìÁ∑¥„ÄÇÊ≠§Êû∂Êßã‰ΩøÁî®‰∏ÄÁ®ÆÊúâÊïàÁöÑËº∏ÂÖ•Ë°®ÂæµÔºåÁµêÂêàÈü≥Ê®ÇÁâπÂæµÔºàÂç≥ÔºåÈü≥Ë™øÂíåÂº¶ÔºâÂíå MERT ÂµåÂÖ•„ÄÇÊ≠§Â§ñÔºåÁü•Ë≠òËí∏È§æÁî®ÊñºÂ∞áÂú®ÂÄãÂà•Ë≥áÊñôÈõÜ‰∏äË®ìÁ∑¥ÁöÑÊïôÂ∏´Ê®°ÂûãÁöÑÁü•Ë≠òÂÇ≥Ëº∏Áµ¶Â≠∏ÁîüÊ®°ÂûãÔºåÂ¢ûÂº∑ÂÖ∂Ë∑®Â§öÂÄã‰ªªÂãôÈÄ≤Ë°åÊ¶ÇÊã¨ÁöÑËÉΩÂäõ„ÄÇÁÇ∫‰∫ÜÈ©óË≠âÊàëÂÄëÊèêÂá∫ÁöÑÊû∂ÊßãÔºåÊàëÂÄëÂ∞çÂêÑÁ®ÆË≥áÊñôÈõÜÈÄ≤Ë°å‰∫ÜÂª£Ê≥õÁöÑÂØ¶È©óÔºåÂåÖÊã¨ MTG-Jamendo„ÄÅDEAM„ÄÅPMEmo Âíå EmoMusic„ÄÇÊ†πÊìöÊàëÂÄëÁöÑÂØ¶È©óÁµêÊûúÔºåÈü≥Ê®ÇÁâπÂæµ„ÄÅÂ§ö‰ªªÂãôÂ≠∏ÁøíÂíåÁü•Ë≠òËí∏È§æÁöÑÂä†ÂÖ•È°ØËëóÊèêÂçá‰∫ÜÊïàËÉΩ„ÄÇÁâπÂà•ÊòØÔºåÊàëÂÄëÁöÑÊ®°ÂûãÂÑ™ÊñºÊúÄÂÖàÈÄ≤ÁöÑÊ®°ÂûãÔºåÂåÖÊã¨ MediaEval 2021 Á´∂Ë≥Ω‰∏≠Âú® MTG-Jamendo Ë≥áÊñôÈõÜ‰∏äË°®ÁèæÊúÄ‰Ω≥ÁöÑÊ®°Âûã„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÈÄèÈÅéÂÖÅË®±Âú®‰∏ÄÂÄãÁµ±‰∏ÄÁöÑÊû∂Êßã‰∏≠ÁµêÂêàÂàÜÈ°ûÂíåÁ∂≠Â∫¶ÊÉÖÁ∑íÊ®ôÁ±§ÔºåÂ∞ç MER ÂÅöÂá∫ÈáçÂ§ßË≤¢ÁçªÔºåÂæûËÄåËÉΩÂ§†Ë∑®Ë≥áÊñôÈõÜÈÄ≤Ë°åË®ìÁ∑¥„ÄÇ

##### **MultiFloodSynth: Multi-Annotated Flood Synthetic Dataset Generation**
2502.03966v1 by YoonJe Kang, Yonghoon Jung, Wonseop Shin, Bumsoo Kim, Sanghyun Seo

In this paper, we present synthetic data generation framework for flood
hazard detection system. For high fidelity and quality, we characterize several
real-world properties into virtual world and simulate the flood situation by
controlling them. For the sake of efficiency, recent generative models in
image-to-3D and urban city synthesis are leveraged to easily composite flood
environments so that we avoid data bias due to the hand-crafted manner. Based
on our framework, we build the flood synthetic dataset with 5 levels, dubbed
MultiFloodSynth which contains rich annotation types like normal map,
segmentation, 3D bounding box for a variety of downstream task. In experiments,
our dataset demonstrate the enhanced performance of flood hazard detection with
on-par realism compared with real dataset.

ÊëòË¶ÅÔºöÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫ÂêàÊàêË≥áÊñôÁî¢ÁîüÊû∂ÊßãÔºåÁî®ÊñºÊ¥™Ê∞¥ÁÅΩÂÆ≥ÂÅµÊ∏¨Á≥ªÁµ±„ÄÇÁÇ∫‰∫ÜÈ´ò‰øùÁúüÂíåÂìÅË≥™ÔºåÊàëÂÄëÂ∞áÊï∏ÂÄãÁúüÂØ¶‰∏ñÁïåÂ±¨ÊÄßÁâπÂæµÂåñÂà∞ËôõÊì¨‰∏ñÁïå‰∏≠Ôºå‰∏¶ÈÄèÈÅéÊéßÂà∂ÂÆÉÂÄë‰æÜÊ®°Êì¨Ê¥™Ê∞¥ÊÉÖÊ≥Å„ÄÇÁÇ∫‰∫ÜÊïàÁéáÔºåÊàëÂÄëÂà©Áî®ÊúÄËøëÁöÑÂΩ±ÂÉèËΩâ 3D ÂíåÂüéÂ∏ÇÂêàÊàê‰∏≠ÁöÑÁîüÊàêÊ®°ÂûãÔºåËºïÈ¨ÜÂêàÊàêÊ¥™Ê∞¥Áí∞Â¢ÉÔºåÈÄôÊ®£ÊàëÂÄëÂ∞±ËÉΩÈÅøÂÖçÁî±ÊñºÊâãÂ∑•Ë£Ω‰ΩúËÄåÁî¢ÁîüÁöÑË≥áÊñôÂÅèÂ∑Æ„ÄÇÊ†πÊìöÊàëÂÄëÁöÑÊû∂ÊßãÔºåÊàëÂÄëÂª∫Á´ã‰∫Ü 5 ÂÄãÁ≠âÁ¥öÁöÑÊ¥™Ê∞¥ÂêàÊàêË≥áÊñôÈõÜÔºåÁ®±ÁÇ∫ MultiFloodSynthÔºåÂÖ∂‰∏≠ÂåÖÂê´Ë±êÂØåÁöÑË®ªËß£È°ûÂûãÔºå‰æãÂ¶ÇÊ≥ïÁ∑öË≤ºÂúñ„ÄÅÂàÜÂâ≤„ÄÅ3D ÈÇäÁïåÊ°ÜÔºåÂèØÁî®ÊñºÂêÑÁ®Æ‰∏ãÊ∏∏‰ªªÂãô„ÄÇÂú®ÂØ¶È©ó‰∏≠ÔºåÊàëÂÄëÁöÑË≥áÊñôÈõÜÂ±ïÁ§∫‰∫ÜÊ¥™Ê∞¥ÁÅΩÂÆ≥ÂÅµÊ∏¨ÁöÑÂ¢ûÂº∑ÊïàËÉΩÔºåËàáÁúüÂØ¶Ë≥áÊñôÈõÜÁõ∏ÊØîÂÖ∑ÊúâÂêåÁ≠âÁöÑÁúüÂØ¶ÊÑü„ÄÇ

##### **Improving the Perturbation-Based Explanation of Deepfake Detectors Through the Use of Adversarially-Generated Samples**
2502.03957v1 by Konstantinos Tsigos, Evlampios Apostolidis, Vasileios Mezaris

In this paper, we introduce the idea of using adversarially-generated samples
of the input images that were classified as deepfakes by a detector, to form
perturbation masks for inferring the importance of different input features and
produce visual explanations. We generate these samples based on Natural
Evolution Strategies, aiming to flip the original deepfake detector's decision
and classify these samples as real. We apply this idea to four
perturbation-based explanation methods (LIME, SHAP, SOBOL and RISE) and
evaluate the performance of the resulting modified methods using a SOTA
deepfake detection model, a benchmarking dataset (FaceForensics++) and a
corresponding explanation evaluation framework. Our quantitative assessments
document the mostly positive contribution of the proposed perturbation approach
in the performance of explanation methods. Our qualitative analysis shows the
capacity of the modified explanation methods to demarcate the manipulated image
regions more accurately, and thus to provide more useful explanations.

ÊëòË¶ÅÔºöÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÊÉ≥Ê≥ïÔºå‰ΩøÁî®Â∞çÊäóÁîüÊàêÊ®£Êú¨ÔºåÈÄô‰∫õÊ®£Êú¨ÊòØÈÄöÈÅé‰∏ÄÂÄãÊ™¢Ê∏¨Âô®Â∞áËº∏ÂÖ•ÂúñÂÉèÂàÜÈ°ûÁÇ∫Ê∑±Â∫¶ÂÅΩÈÄ†ËÄåÂΩ¢ÊàêÁöÑÔºå‰ª•ÂΩ¢ÊàêÊìæÂãïÈÅÆÁΩ©ÔºåÁî®ÊñºÊé®Êñ∑‰∏çÂêåËº∏ÂÖ•ÁâπÂæµÁöÑÈáçË¶ÅÊÄß‰∏¶Áî¢ÁîüË¶ñË¶∫Ëß£Èáã„ÄÇÊàëÂÄëÂü∫ÊñºËá™ÁÑ∂ÊºîÂåñÁ≠ñÁï•ÁîüÊàêÈÄô‰∫õÊ®£Êú¨ÔºåÊó®Âú®ÊîπËÆäÂéüÂßãÊ∑±Â∫¶ÂÅΩÈÄ†Ê™¢Ê∏¨Âô®ÁöÑÊ±∫Á≠ñÔºå‰∏¶Â∞áÈÄô‰∫õÊ®£Êú¨ÂàÜÈ°ûÁÇ∫ÁúüÂØ¶ÁöÑ„ÄÇÊàëÂÄëÂ∞áÈÄôÂÄãÊÉ≥Ê≥ïÊáâÁî®ÊñºÂõõÁ®ÆÂü∫ÊñºÊìæÂãïÁöÑËß£ÈáãÊñπÊ≥ïÔºàLIME„ÄÅSHAP„ÄÅSOBOL Âíå RISEÔºâÔºå‰∏¶‰ΩøÁî® SOTA Ê∑±Â∫¶ÂÅΩÈÄ†Ê™¢Ê∏¨Ê®°Âûã„ÄÅÂü∫Ê∫ñÊï∏ÊìöÈõÜÔºàFaceForensics++ÔºâÂíåÁõ∏ÊáâÁöÑËß£ÈáãË©ï‰º∞Ê°ÜÊû∂Ë©ï‰º∞ÊâÄÁî¢ÁîüÁöÑ‰øÆÊîπÊñπÊ≥ïÁöÑÊÄßËÉΩ„ÄÇÊàëÂÄëÁöÑÂÆöÈáèË©ï‰º∞Ë®òÈåÑ‰∫ÜÊâÄÊèêÂá∫ÁöÑÊìæÂãïÊñπÊ≥ïÂú®Ëß£ÈáãÊñπÊ≥ïÁöÑÊÄßËÉΩ‰∏≠Â§ßÂ§öÊï∏ÁöÑÁ©çÊ•µË≤¢Áçª„ÄÇÊàëÂÄëÁöÑÂÆöÊÄßÂàÜÊûêÈ°ØÁ§∫‰∫Ü‰øÆÊîπÂæåÁöÑËß£ÈáãÊñπÊ≥ïÊõ¥Ê∫ñÁ¢∫Âú∞ÂäÉÂÆöË¢´ÊìçÁ∏±ÁöÑÂúñÂÉèÂçÄÂüüÁöÑËÉΩÂäõÔºåÂæûËÄåÊèê‰æõÊõ¥ÊúâÁî®ÁöÑËß£Èáã„ÄÇ

##### **MAQInstruct: Instruction-based Unified Event Relation Extraction**
2502.03954v1 by Jun Xu, Mengshu Sun, Zhiqiang Zhang, Jun Zhou

Extracting event relations that deviate from known schemas has proven
challenging for previous methods based on multi-class classification, MASK
prediction, or prototype matching. Recent advancements in large language models
have shown impressive performance through instruction tuning. Nevertheless, in
the task of event relation extraction, instruction-based methods face several
challenges: there are a vast number of inference samples, and the relations
between events are non-sequential. To tackle these challenges, we present an
improved instruction-based event relation extraction framework named
MAQInstruct. Firstly, we transform the task from extracting event relations
using given event-event instructions to selecting events using given
event-relation instructions, which reduces the number of samples required for
inference. Then, by incorporating a bipartite matching loss, we reduce the
dependency of the instruction-based method on the generation sequence. Our
experimental results demonstrate that MAQInstruct significantly improves the
performance of event relation extraction across multiple LLMs.

ÊëòË¶ÅÔºöÊèêÂèñÂÅèÈõ¢Â∑≤Áü•Ê®°ÂºèÁöÑ‰∫ã‰ª∂Èóú‰øÇÔºåÂ∑≤Ë≠âÊòéÂ∞çÂü∫ÊñºÂ§öÈ°ûÂàÜÈ°û„ÄÅMASK È†êÊ∏¨ÊàñÂéüÂûãÂåπÈÖçÁöÑÂÖàÂâçÊñπÊ≥ïÊßãÊàêÊåëÊà∞„ÄÇÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÁöÑÊúÄÊñ∞ÈÄ≤Â±ïÂ∑≤ÈÄèÈÅéÊåá‰ª§Ë™øÊï¥Â±ïÁèæÂá∫‰ª§‰∫∫Âç∞Ë±°Ê∑±ÂàªÁöÑÊïàËÉΩ„ÄÇ‰∏çÈÅéÔºåÂú®‰∫ã‰ª∂Èóú‰øÇËêÉÂèñ‰ªªÂãô‰∏≠ÔºåÂü∫ÊñºÊåá‰ª§ÁöÑÊñπÊ≥ïÈù¢Ëá®Â§öÈ†ÖÊåëÊà∞ÔºöÊúâÂ§ßÈáèÁöÑÊé®Ë´ñÁØÑ‰æãÔºåËÄå‰∏î‰∫ã‰ª∂‰πãÈñìÁöÑÈóú‰øÇÊòØÈùûÈ†ÜÂ∫èÁöÑ„ÄÇÁÇ∫‰∫ÜÊáâÂ∞çÈÄô‰∫õÊåëÊà∞ÔºåÊàëÂÄëÊèêÂá∫‰∏ÄÂÄãÂêçÁÇ∫ MAQInstruct ÁöÑÊîπËâØÂºèÂü∫ÊñºÊåá‰ª§ÁöÑ‰∫ã‰ª∂Èóú‰øÇËêÉÂèñÊû∂Êßã„ÄÇÈ¶ñÂÖàÔºåÊàëÂÄëÂ∞á‰ªªÂãôÂæû‰ΩøÁî®Êó¢ÂÆöÁöÑ‰∫ã‰ª∂-‰∫ã‰ª∂Êåá‰ª§ËêÉÂèñ‰∫ã‰ª∂Èóú‰øÇÔºåËΩâÊèõÁÇ∫‰ΩøÁî®Êó¢ÂÆöÁöÑ‰∫ã‰ª∂-Èóú‰øÇÊåá‰ª§ÈÅ∏Âèñ‰∫ã‰ª∂ÔºåÈÄôÊ∏õÂ∞ë‰∫ÜÊé®Ë´ñÊâÄÈúÄÁöÑÁØÑ‰æãÊï∏Èáè„ÄÇÊé•ËëóÔºåÈÄèÈÅéÁ¥çÂÖ•ÈõôÂàÜÂåπÈÖçÊêçÂ§±ÔºåÊàëÂÄëÈôç‰ΩéÂü∫ÊñºÊåá‰ª§ÁöÑÊñπÊ≥ïÂ∞çÊñºÁîüÊàêÈ†ÜÂ∫èÁöÑ‰æùË≥¥ÊÄß„ÄÇÊàëÂÄëÁöÑÂØ¶È©óÁµêÊûúË≠âÊòéÔºåMAQInstruct Â§ßÂπÖÊîπÂñÑ‰∫ÜÂ§öÂÄã LLM ÁöÑ‰∫ã‰ª∂Èóú‰øÇËêÉÂèñÊïàËÉΩ„ÄÇ

##### **Afrispeech-Dialog: A Benchmark Dataset for Spontaneous English Conversations in Healthcare and Beyond**
2502.03945v1 by Mardhiyah Sanni, Tassallah Abdullahi, Devendra D. Kayande, Emmanuel Ayodele, Naome A. Etori, Michael S. Mollel, Moshood Yekini, Chibuzor Okocha, Lukman E. Ismaila, Folafunmi Omofoye, Boluwatife A. Adewale, Tobi Olatunji

Speech technologies are transforming interactions across various sectors,
from healthcare to call centers and robots, yet their performance on
African-accented conversations remains underexplored. We introduce
Afrispeech-Dialog, a benchmark dataset of 50 simulated medical and non-medical
African-accented English conversations, designed to evaluate automatic speech
recognition (ASR) and related technologies. We assess state-of-the-art (SOTA)
speaker diarization and ASR systems on long-form, accented speech, comparing
their performance with native accents and discover a 10%+ performance
degradation. Additionally, we explore medical conversation summarization
capabilities of large language models (LLMs) to demonstrate the impact of ASR
errors on downstream medical summaries, providing insights into the challenges
and opportunities for speech technologies in the Global South. Our work
highlights the need for more inclusive datasets to advance conversational AI in
low-resource settings.

ÊëòË¶ÅÔºöË™ûÈü≥ÊäÄË°ìÊ≠£Âú®ËΩâËÆäÂêÑÂÄãÈ†òÂüüÁöÑ‰∫íÂãïÔºå
ÂæûÈÜ´ÁôÇ‰øùÂÅ•Âà∞ÂÆ¢Êúç‰∏≠ÂøÉÂíåÊ©üÂô®‰∫∫Ôºå‰ΩÜÂÆÉÂÄëÂú®
ÈùûÊ¥≤Âè£Èü≥Â∞çË©±‰∏≠ÁöÑË°®Áèæ‰ªçÊú™ÂæóÂà∞ÂÖÖÂàÜÊé¢Á¥¢„ÄÇÊàëÂÄëÊé®Âá∫
Afrispeech-DialogÔºå‰∏ÄÂÄãÁî± 50 ÂÄãÊ®°Êì¨ÈÜ´ÁôÇÂíåÈùûÈÜ´ÁôÇ
ÈùûÊ¥≤Âè£Èü≥Ëã±Ë™ûÂ∞çË©±ÁµÑÊàêÁöÑÂü∫Ê∫ñË≥áÊñôÈõÜÔºåÊó®Âú®Ë©ï‰º∞Ëá™ÂãïË™ûÈü≥
Ëæ®Ë≠ò (ASR) ÂíåÁõ∏ÈóúÊäÄË°ì„ÄÇÊàëÂÄëË©ï‰º∞ÊúÄÂÖàÈÄ≤ (SOTA)
Âú®Èï∑ÁØá„ÄÅÊúâÂè£Èü≥ÁöÑË™ûÈü≥‰∏äÈÄ≤Ë°åË™™Ë©±‰∫∫ÂçÄÂàÜÂíå ASR Á≥ªÁµ±ÔºåÊØîËºÉ
ÂÆÉÂÄëËàáÊØçË™ûÂè£Èü≥ÁöÑË°®ÁèæÔºå‰∏¶ÁôºÁèæÊúâ 10% ‰ª•‰∏äÁöÑË°®Áèæ
‰∏ãÈôç„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÊé¢Ë®éÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑÈÜ´ÁôÇÂ∞çË©±ÊëòË¶Å
ÂäüËÉΩÔºå‰ª•Â±ïÁ§∫ ASR ÈåØË™§Â∞ç‰∏ãÊ∏∏ÈÜ´ÁôÇÊëòË¶ÅÁöÑÂΩ±ÈüøÔºå‰∏¶Êèê‰æõÂ∞çÊåëÊà∞ÁöÑË¶ãËß£
‰ª•ÂèäÂÖ®ÁêÉÂçóÊñπË™ûÈü≥ÊäÄË°ìÁöÑÊ©üÈÅá„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂
Âº∑Ë™øÈúÄË¶ÅÊõ¥Â§öÂåÖÂÆπÊÄßÁöÑË≥áÊñôÈõÜ‰æÜÊé®ÂãïÂ∞çË©±Âºè AI Âú®
Ë≥áÊ∫ê‰∏çË∂≥ÁöÑÁí∞Â¢É‰∏≠„ÄÇ

##### **DiTAR: Diffusion Transformer Autoregressive Modeling for Speech Generation**
2502.03930v1 by Dongya Jia, Zhuo Chen, Jiawei Chen, Chenpeng Du, Jian Wu, Jian Cong, Xiaobin Zhuang, Chumin Li, Zhen Wei, Yuping Wang, Yuxuan Wang

Several recent studies have attempted to autoregressively generate continuous
speech representations without discrete speech tokens by combining diffusion
and autoregressive models, yet they often face challenges with excessive
computational loads or suboptimal outcomes. In this work, we propose Diffusion
Transformer Autoregressive Modeling (DiTAR), a patch-based autoregressive
framework combining a language model with a diffusion transformer. This
approach significantly enhances the efficacy of autoregressive models for
continuous tokens and reduces computational demands. DiTAR utilizes a
divide-and-conquer strategy for patch generation, where the language model
processes aggregated patch embeddings and the diffusion transformer
subsequently generates the next patch based on the output of the language
model. For inference, we propose defining temperature as the time point of
introducing noise during the reverse diffusion ODE to balance diversity and
determinism. We also show in the extensive scaling analysis that DiTAR has
superb scalability. In zero-shot speech generation, DiTAR achieves
state-of-the-art performance in robustness, speaker similarity, and
naturalness.

ÊëòË¶ÅÔºöÂ§öÈ†ÖËøëÊúüÁ†îÁ©∂ÂòóË©¶ÁµêÂêàÊì¥Êï£ÂíåËá™Ëø¥Ê≠∏Ê®°ÂûãÔºåËá™Ëø¥Ê≠∏Âú∞Áî¢ÁîüÈÄ£Á∫åË™ûÈü≥Ë°®ÂæµÔºåËÄå‰∏ç‰ΩøÁî®Èõ¢Êï£Ë™ûÈü≥Á¨¶ËôüÔºå‰ΩÜÂÆÉÂÄëÁ∂ìÂ∏∏Èù¢Ëá®Ë®àÁÆóË≤†ËºâÈÅéÂ§ßÊàñÁµêÊûúÊ¨°‰Ω≥ÁöÑÊåëÊà∞„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÊèêÂá∫Êì¥Êï£ËΩâÊèõÂô®Ëá™Ëø¥Ê≠∏Ê®°Âûã (DiTAR)Ôºå‰∏ÄÂÄãÂü∫ÊñºÂçÄÂ°äÁöÑËá™Ëø¥Ê≠∏Êû∂ÊßãÔºåÁµêÂêàË™ûË®ÄÊ®°ÂûãËàáÊì¥Êï£ËΩâÊèõÂô®„ÄÇÈÄôÁ®ÆÊñπÊ≥ïÂ§ßÂπÖÂ¢ûÂº∑Ëá™Ëø¥Ê≠∏Ê®°ÂûãÂ∞çÈÄ£Á∫åÁ¨¶ËôüÁöÑÊïàËÉΩÔºå‰∏¶Ê∏õÂ∞ëË®àÁÆóÈúÄÊ±Ç„ÄÇDiTAR Âà©Áî®ÂàÜËÄåÊ≤ª‰πãÁ≠ñÁï•ÈÄ≤Ë°åÂçÄÂ°äÁî¢ÁîüÔºåÂÖ∂‰∏≠Ë™ûË®ÄÊ®°ÂûãËôïÁêÜËÅöÈõÜÁöÑÂçÄÂ°äÂµåÂÖ•ÔºåËÄåÊì¥Êï£ËΩâÊèõÂô®Èö®ÂæåÊ†πÊìöË™ûË®ÄÊ®°ÂûãÁöÑËº∏Âá∫Áî¢Áîü‰∏ã‰∏ÄÂÄãÂçÄÂ°ä„ÄÇÂ∞çÊñºÊé®Ë´ñÔºåÊàëÂÄëÂª∫Ë≠∞Â∞áÊ∫´Â∫¶ÂÆöÁæ©ÁÇ∫Âú®ÂèçÂêëÊì¥Êï£ ODE ‰∏≠ÂºïÂÖ•ÈõúË®äÁöÑÊôÇÈñìÈªûÔºå‰ª•Âπ≥Ë°°Â§öÊ®£ÊÄßÂíåÁ¢∫ÂÆöÊÄß„ÄÇÊàëÂÄë‰πüÂú®Âª£Ê≥õÁöÑÁ∏ÆÊîæÂàÜÊûê‰∏≠È°ØÁ§∫ÔºåDiTAR ÂÖ∑ÊúâÊ•µ‰Ω≥ÁöÑÂèØÊì¥ÂÖÖÊÄß„ÄÇÂú®Èõ∂Ê¨°Â≠∏ÁøíË™ûÈü≥Áî¢Áîü‰∏≠ÔºåDiTAR Âú®Á©©ÂÅ•ÊÄß„ÄÅË™™Ë©±ËÄÖÁõ∏‰ººÊÄßÂíåËá™ÁÑ∂Â∫¶ÊñπÈù¢ÈÅîÂà∞ÊúÄÂÖàÈÄ≤ÁöÑÊïàËÉΩ„ÄÇ

##### **Adaptation of Task Goal States from Prior Knowledge**
2502.03918v1 by Andrei Costinescu, Darius Burschka

This paper presents a framework to define a task with freedom and variability
in its goal state. A robot could use this to observe the execution of a task
and target a different goal from the observed one; a goal that is still
compatible with the task description but would be easier for the robot to
execute. We define the model of an environment state and an environment
variation, and present experiments on how to interactively create the variation
from a single task demonstration and how to use this variation to create an
execution plan for bringing any environment into the goal state.

ÊëòË¶ÅÔºöÊú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÂÄãÊû∂ÊßãÔºåÁî®ÊñºÂÆöÁæ©‰∏ÄÂÄã‰ªªÂãôÔºåÂÖ∂ÁõÆÊ®ôÁãÄÊÖãÂÖ∑ÊúâËá™Áî±Â∫¶ÂíåÂèØËÆäÊÄß„ÄÇÊ©üÂô®‰∫∫ÂèØ‰ª•‰ΩøÁî®Ê≠§Êû∂Êßã‰æÜËßÄÂØü‰ªªÂãôÁöÑÂü∑Ë°åÔºå‰∏¶ÈáùÂ∞çËàáËßÄÂØüÂà∞ÁöÑÁõÆÊ®ô‰∏çÂêåÁöÑÁõÆÊ®ôÔºõ‰∏ÄÂÄã‰ªçÁÑ∂Ëàá‰ªªÂãôÊèèËø∞Áõ∏ÂÆπÔºå‰ΩÜÂ∞çÊ©üÂô®‰∫∫‰æÜË™™Êõ¥ÂÆπÊòìÂü∑Ë°åÁöÑÁõÆÊ®ô„ÄÇÊàëÂÄëÂÆöÁæ©‰∫ÜÁí∞Â¢ÉÁãÄÊÖãÂíåÁí∞Â¢ÉËÆäÂåñÁöÑÊ®°ÂûãÔºå‰∏¶Â±ïÁ§∫‰∫ÜÂ¶Ç‰ΩïÂæûÂñÆ‰∏Ä‰ªªÂãôÁ§∫ÁØÑ‰∏≠‰∫íÂãïÂºèÂú∞ÂâµÂª∫ËÆäÂåñÔºå‰ª•ÂèäÂ¶Ç‰Ωï‰ΩøÁî®Ê≠§ËÆäÂåñÁÇ∫Â∞á‰ªª‰ΩïÁí∞Â¢ÉÂ∏∂ÂÖ•ÁõÆÊ®ôÁãÄÊÖãÂâµÂª∫Âü∑Ë°åË®àÁï´„ÄÇ

##### **Experiments with Large Language Models on Retrieval-Augmented Generation for Closed-Source Simulation Software**
2502.03916v1 by Andreas Baumann, Peter Eberhard

Large Language Models (LLMs) are increasingly helpful in text generation,
even writing code in programming languages based on user prompts written in
natural language. They are even applied to generate simulation models for
multibody systems from natural language. Research results suggest that LLMs
surpass the mere replication of existing code examples, where some LLMs have
been trained on an open-source multibody simulation code. However, for
closed-source simulation software, such results are not to be expected as their
ideas and concepts might differ from other publicly available ones. LLMs can
hallucinate for knowledge-intensive tasks, such as model creation, which can
lead to wrong responses. This is especially the case for the LLM unknown
closed-source simulation software. The same applies to other internal knowledge
kept private to protect intellectual property or data privacy. The
Retrieval-Augmented Generation (RAG) approach might yield a solution for these
knowledge-intensive tasks. This paper explores the application of RAG to
closed-source simulation software and presents first experiments. After a brief
introduction to LLMs, the RAG approach, and the simulation method applied by
the close-source simulation software, several examples are provided to test
LLMs' knowledge of the simulation software and the creation of simulation
models using two RAG systems. The examples show promising results indicating
the benefits of applying RAG systems to closed-source simulation software,
helping to access their knowledge. Nevertheless, they also reveal gaps in the
applied information and open questions for further research.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Âú®ÊñáÊú¨ÁîüÊàêÊñπÈù¢Ë∂ä‰æÜË∂äÊúâÂπ´Âä©ÔºåÁîöËá≥ÂèØ‰ª•Ê†πÊìö‰ª•Ëá™ÁÑ∂Ë™ûË®ÄÂØ´ÊàêÁöÑ‰ΩøÁî®ËÄÖÊèêÁ§∫ÔºåÊí∞ÂØ´Á®ãÂºèË™ûË®ÄÁöÑÁ®ãÂºèÁ¢º„ÄÇÂÆÉÂÄëÁîöËá≥Ë¢´ÊáâÁî®ÊñºÂæûËá™ÁÑ∂Ë™ûË®ÄÁî¢ÁîüÂ§öÈ´îÁ≥ªÁµ±ÁöÑÊ®°Êì¨Ê®°Âûã„ÄÇÁ†îÁ©∂ÁµêÊûúË°®ÊòéÔºåLLM Ë∂ÖË∂ä‰∫ÜÁèæÊúâÁ®ãÂºèÁ¢ºÁØÑ‰æãÁöÑÂñÆÁ¥îË§áË£ΩÔºåÂÖ∂‰∏≠‰∏Ä‰∫õ LLM Â∑≤Êé•ÂèóÈñãÊ∫êÂ§öÈ´îÊ®°Êì¨Á®ãÂºèÁ¢ºÁöÑË®ìÁ∑¥„ÄÇÁÑ∂ËÄåÔºåÂ∞çÊñºÈñâÊ∫êÊ®°Êì¨ËªüÈ´îÔºåÁî±ÊñºÂÆÉÂÄëÁöÑÊÉ≥Ê≥ïÂíåÊ¶ÇÂøµÂèØËÉΩËàáÂÖ∂‰ªñÂÖ¨ÈñãÂèØÁî®ÁöÑÊÉ≥Ê≥ïÂíåÊ¶ÇÂøµ‰∏çÂêåÔºåÂõ†Ê≠§ÁÑ°Ê≥ïÈ†êÊúüÊúâÈÄôÊ®£ÁöÑÁµêÊûú„ÄÇLLM ÂèØ‰ª•Â∞çÁü•Ë≠òÂØÜÈõÜÂûã‰ªªÂãôÔºà‰æãÂ¶ÇÊ®°ÂûãÂª∫Á´ãÔºâÁî¢ÁîüÂπªË¶∫ÔºåÈÄôÂèØËÉΩÂ∞éËá¥ÈåØË™§ÁöÑÂõûÊáâ„ÄÇÂ∞çÊñº LLM Êú™Áü•ÁöÑÈñâÊ∫êÊ®°Êì¨ËªüÈ´îÔºåÊÉÖÊ≥ÅÂ∞§ÂÖ∂Â¶ÇÊ≠§„ÄÇÈÄô‰πüÈÅ©Áî®ÊñºÂÖ∂‰ªñÂÖßÈÉ®Áü•Ë≠òÔºåÈÄô‰∫õÁü•Ë≠òÊúÉË¢´‰øùÂØÜ‰ª•‰øùË≠∑Êô∫ÊÖßË≤°Áî¢Ê¨äÊàñË≥áÊñôÈö±ÁßÅ„ÄÇÊ™¢Á¥¢Â¢ûÂº∑ÁîüÊàê (RAG) ÊñπÊ≥ïÂèØËÉΩÁÇ∫ÈÄô‰∫õÁü•Ë≠òÂØÜÈõÜÂûã‰ªªÂãôÊèê‰æõ‰∫ÜËß£Ê±∫ÊñπÊ°à„ÄÇÊú¨ÊñáÊé¢Ë®é‰∫Ü RAG Âú®ÈñâÊ∫êÊ®°Êì¨ËªüÈ´î‰∏≠ÁöÑÊáâÁî®Ôºå‰∏¶ÊèêÂá∫‰∫ÜÂàùÊ≠•ÂØ¶È©ó„ÄÇÂú®Á∞°Ë¶Å‰ªãÁ¥π LLM„ÄÅRAG ÊñπÊ≥ïÂíåÈñâÊ∫êÊ®°Êì¨ËªüÈ´îÊâÄÊáâÁî®ÁöÑÊ®°Êì¨ÊñπÊ≥ïÂæåÔºåÊèê‰æõ‰∫ÜÂπæÂÄãÁØÑ‰æã‰æÜÊ∏¨Ë©¶ LLM Â∞çÊ®°Êì¨ËªüÈ´îÁöÑ‰∫ÜËß£Ôºå‰ª•Âèä‰ΩøÁî®ÂÖ©ÂÄã RAG Á≥ªÁµ±Âª∫Á´ãÊ®°Êì¨Ê®°Âûã„ÄÇÈÄô‰∫õÁØÑ‰æãÈ°ØÁ§∫‰∫ÜÊúâÂ∏åÊúõÁöÑÁµêÊûúÔºåË°®ÊòéÂ∞á RAG Á≥ªÁµ±ÊáâÁî®ÊñºÈñâÊ∫êÊ®°Êì¨ËªüÈ´îÁöÑÂ•ΩËôïÔºåÊúâÂä©ÊñºÂ≠òÂèñÂÆÉÂÄëÁöÑÁü•Ë≠ò„ÄÇÂÑòÁÆ°Â¶ÇÊ≠§ÔºåÂÆÉÂÄë‰πüÊè≠Èú≤‰∫ÜÊáâÁî®Ë≥áË®ä‰∏≠ÁöÑÂ∑ÆË∑ùÔºå‰∏¶ÊèêÂá∫‰∫ÜÈÄ≤‰∏ÄÊ≠•Á†îÁ©∂ÁöÑÈñãÊîæÊÄßÂïèÈ°å„ÄÇ

##### **Rank Also Matters: Hierarchical Configuration for Mixture of Adapter Experts in LLM Fine-Tuning**
2502.03884v1 by Peizhuang Cong, Wenpu Liu, Wenhan Yu, Haochen Zhao, Tong Yang

Large language models (LLMs) have demonstrated remarkable success across
various tasks, accompanied by a continuous increase in their parameter size.
Parameter-efficient fine-tuning (PEFT) methods, such as Low-Rank Adaptation
(LoRA), address the challenges of fine-tuning LLMs by significantly reducing
the number of trainable parameters. Recent studies have integrated LoRA with
Mixture of Experts (MoE) architectures, leveraging multiple adapter experts and
gating mechanisms to further improve fine-tuning performance. However, existing
approaches primarily focus on adjusting the allocations of adapter experts per
layer to optimize the introduced trainable parameter size, while neglecting a
critical factor of adapters' rank. To this end, we propose a hierarchical
scheme for expert allocation and rank configuration, HILO, which dynamically
adjusts the number and rank of adapter experts across layers, matching the
varying representational complexity of model layers in adapter-granularity.
Extensive experiments on multiple benchmark tasks demonstrate that HILO
outperforms existing methods in accuracy while introducing fewer trainable
parameters, providing an efficient and practical solution for fine-tuning LLMs.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Â∑≤Âú®ÂêÑÁ®Æ‰ªªÂãô‰∏≠Â±ïÁèæÂá∫È°ØËëóÁöÑÊàêÂäüÔºåÂêåÊôÇÂÖ∂ÂèÉÊï∏Ë¶èÊ®°‰πü‰∏çÊñ∑Â¢ûÂä†„ÄÇÂèÉÊï∏È´òÊïàÂæÆË™ø (PEFT) ÊñπÊ≥ïÔºå‰æãÂ¶Ç‰ΩéÈöéÈÅ©Êáâ (LoRA)ÔºåÈÄèÈÅéÂ§ßÂπÖÊ∏õÂ∞ëÂèØË®ìÁ∑¥ÂèÉÊï∏Êï∏Èáè‰æÜËß£Ê±∫ÂæÆË™ø LLM ÁöÑÊåëÊà∞„ÄÇÊúÄËøëÁöÑÁ†îÁ©∂Â∑≤Â∞á LoRA ËàáÂ∞àÂÆ∂Ê∑∑Âêà (MoE) Êû∂ÊßãÊï¥ÂêàÔºåÂà©Áî®Â§öÂÄãÈÅ©ÈÖçÂô®Â∞àÂÆ∂ÂíåÈñòÊéßÊ©üÂà∂ÈÄ≤‰∏ÄÊ≠•ÊèêÂçáÂæÆË™øÊïàËÉΩ„ÄÇÁÑ∂ËÄåÔºåÁèæÊúâÊñπÊ≥ï‰∏ªË¶ÅËëóÈáçÊñºË™øÊï¥ÊØèÂ±§ÈÅ©ÈÖçÂô®Â∞àÂÆ∂ÁöÑÈÖçÁΩÆ‰ª•ÊúÄ‰Ω≥ÂåñÂºïÂÖ•ÁöÑÂèØË®ìÁ∑¥ÂèÉÊï∏Ë¶èÊ®°ÔºåÂêåÊôÇÂøΩÁï•ÈÅ©ÈÖçÂô®Á≠âÁ¥öÁöÑÈóúÈçµÂõ†Á¥†„ÄÇÁÇ∫Ê≠§ÔºåÊàëÂÄëÊèêÂá∫‰∏ÄÂÄãÂàÜÂ±§Â∞àÂÆ∂ÈÖçÁΩÆÂíåÁ≠âÁ¥öË®≠ÂÆöÊñπÊ°àÔºåHILOÔºåÂÆÉÊúÉÂãïÊÖãË™øÊï¥ÂêÑÂ±§ÈÅ©ÈÖçÂô®Â∞àÂÆ∂ÁöÑÊï∏ÈáèÂíåÁ≠âÁ¥öÔºåÂú®ÈÅ©ÈÖçÂô®Á≤íÂ∫¶‰∏≠Á¨¶ÂêàÊ®°ÂûãÂ±§ËÆäÂåñÁöÑË°®Á§∫Ë§áÈõúÂ∫¶„ÄÇÈÄèÈÅéÂ§öÂÄãÂü∫Ê∫ñ‰ªªÂãôÁöÑÂª£Ê≥õÂØ¶È©óË≠âÊòéÔºåHILO Âú®Ê∫ñÁ¢∫Â∫¶ÊñπÈù¢ÂÑ™ÊñºÁèæÊúâÊñπÊ≥ïÔºåÂêåÊôÇÂºïÂÖ•ËºÉÂ∞ëÁöÑÂèØË®ìÁ∑¥ÂèÉÊï∏ÔºåÁÇ∫ÂæÆË™ø LLM Êèê‰æõÈ´òÊïà‰∏îÂØ¶Áî®ÁöÑËß£Ê±∫ÊñπÊ°à„ÄÇ

##### **BOLT: Bootstrap Long Chain-of-Thought in Language Models without Distillation**
2502.03860v1 by Bo Pang, Hanze Dong, Jiacheng Xu, Silvio Savarese, Yingbo Zhou, Caiming Xiong

Large language models (LLMs), such as o1 from OpenAI, have demonstrated
remarkable reasoning capabilities. o1 generates a long chain-of-thought
(LongCoT) before answering a question. LongCoT allows LLMs to analyze problems,
devise plans, reflect, and backtrack effectively. These actions empower LLM to
solve complex problems. After the release of o1, many teams have attempted to
replicate its LongCoT and reasoning capabilities. In terms of methods, they
primarily rely on knowledge distillation with data from existing models with
LongCoT capacities (e.g., OpenAI-o1, Qwen-QwQ, DeepSeek-R1-Preview), leaving
significant uncertainties on systematically developing such reasoning
abilities. In terms of data domains, these works focus narrowly on math while a
few others include coding, limiting their generalizability. This paper
introduces a novel approach to enable LLM's LongCoT capacity without
distillation from o1-like models or expensive human annotations, where we
bootstrap LongCoT (BOLT) from a standard instruct model. BOLT involves three
stages: 1) LongCoT data bootstrapping with in-context learning on a standard
instruct model; 2) LongCoT supervised finetuning; 3) online training to further
refine LongCoT capacities. In BOLT, only a few in-context examples need to be
constructed during the bootstrapping stage; in our experiments, we created 10
examples, demonstrating the feasibility of this approach. We use
Llama-3.1-70B-Instruct to bootstrap LongCoT and apply our method to various
model scales (7B, 8B, 70B). We achieve impressive performance on a variety of
benchmarks, Arena-Hard, MT-Bench, WildBench, ZebraLogic, MATH500, which
evaluate diverse task-solving and reasoning capabilities.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM)Ôºå‰æãÂ¶Ç OpenAI ÁöÑ o1ÔºåÂ∑≤Á∂ìÂ±ïÁ§∫Âá∫ÈùûÂá°ÁöÑÊé®ÁêÜËÉΩÂäõ„ÄÇo1 Âú®ÂõûÁ≠îÂïèÈ°å‰πãÂâçÊúÉÁî¢Áîü‰∏ÄÂÄãÈï∑ÈèàÁöÑÊÉ≥Ê≥ï (LongCoT)„ÄÇLongCoT ÂÖÅË®± LLM ÂàÜÊûêÂïèÈ°å„ÄÅÂà∂ÂÆöË®àÂäÉ„ÄÅÂèçÊÄùÂíåÊúâÊïàÂõûÊ∫Ø„ÄÇÈÄô‰∫õÂãï‰ΩúË≥¶ËÉΩ LLM Ëß£Ê±∫Ë§áÈõúÁöÑÂïèÈ°å„ÄÇÂú® o1 ÁôºÂ∏ÉÂæåÔºåË®±Â§öÂúòÈöäÈÉΩÂòóË©¶Ë§áË£ΩÂÖ∂ LongCoT ÂíåÊé®ÁêÜËÉΩÂäõ„ÄÇÂú®ÊñπÊ≥ïÊñπÈù¢Ôºå‰ªñÂÄë‰∏ªË¶Å‰æùË≥¥ÊñºÂÖ∑Êúâ LongCoT ËÉΩÂäõÁöÑÁèæÊúâÊ®°ÂûãÁöÑÊï∏ÊìöÈÄ≤Ë°åÁü•Ë≠òËí∏È§æÔºà‰æãÂ¶ÇÔºåOpenAI-o1„ÄÅQwen-QwQ„ÄÅDeepSeek-R1-PreviewÔºâÔºåÂú®Á≥ªÁµ±ÊÄßÂú∞ÈñãÁôºÈÄôÁ®ÆÊé®ÁêÜËÉΩÂäõÊñπÈù¢Áïô‰∏ãÈáçÂ§ßÁöÑ‰∏çÁ¢∫ÂÆöÊÄß„ÄÇÂú®Êï∏ÊìöÈ†òÂüüÊñπÈù¢ÔºåÈÄô‰∫õÂ∑•‰ΩúÁãπÈöòÂú∞ÈõÜ‰∏≠Âú®Êï∏Â≠∏‰∏äÔºåËÄåÂÖ∂‰ªñ‰∏Ä‰∫õÂâáÂåÖÊã¨Á∑®Á¢ºÔºåÈôêÂà∂‰∫ÜÂÆÉÂÄëÁöÑÊôÆÈÅçÊÄß„ÄÇÊú¨Êñá‰ªãÁ¥π‰∫Ü‰∏ÄÁ®ÆÊñ∞Á©éÁöÑÊñπÊ≥ïÔºåÂèØ‰ª•Âú®‰∏çÂæûÈ°û‰ºº o1 ÁöÑÊ®°ÂûãÊàñÊòÇË≤¥ÁöÑ‰∫∫Â∑•Ë®ªÈáã‰∏≠ÈÄ≤Ë°åËí∏È§æÁöÑÊÉÖÊ≥Å‰∏ãÂØ¶Áèæ LLM ÁöÑ LongCoT ËÉΩÂäõÔºåÊàëÂÄëÂæûÊ®ôÊ∫ñÊåá‰ª§Ê®°Âûã‰∏≠ÂºïÂ∞é LongCoT (BOLT)„ÄÇBOLT Ê∂âÂèä‰∏âÂÄãÈöéÊÆµÔºö1) Âú®Ê®ôÊ∫ñÊåá‰ª§Ê®°Âûã‰∏äÈÄöÈÅéË™ûÂ¢ÉÂ≠∏ÁøíÂºïÂ∞é LongCoT Êï∏ÊìöÔºõ2) LongCoT Áõ£Áù£ÂæÆË™øÔºõ3) Âú®Á∑öË®ìÁ∑¥‰ª•ÈÄ≤‰∏ÄÊ≠•ÂÆåÂñÑ LongCoT ËÉΩÂäõ„ÄÇÂú® BOLT ‰∏≠ÔºåÂú®ÂºïÂ∞éÈöéÊÆµÂè™ÈúÄË¶ÅÊßãÈÄ†ÂπæÂÄãË™ûÂ¢ÉÁØÑ‰æãÔºõÂú®ÊàëÂÄëÁöÑÂØ¶È©ó‰∏≠ÔºåÊàëÂÄëÂâµÂª∫‰∫Ü 10 ÂÄãÁØÑ‰æãÔºåË≠âÊòé‰∫ÜÈÄôÁ®ÆÊñπÊ≥ïÁöÑÂèØË°åÊÄß„ÄÇÊàëÂÄë‰ΩøÁî® Llama-3.1-70B-Instruct ÂºïÂ∞é LongCoTÔºå‰∏¶Â∞áÊàëÂÄëÁöÑÊ®°ÂûãÊáâÁî®ÊñºÂêÑÁ®ÆÊ®°ÂûãË¶èÊ®°Ôºà7B„ÄÅ8B„ÄÅ70BÔºâ„ÄÇÊàëÂÄëÂú®ÂêÑÁ®ÆÂü∫Ê∫ñÊ∏¨Ë©¶‰∏≠ÂèñÂæó‰∫Ü‰ª§‰∫∫Âç∞Ë±°Ê∑±ÂàªÁöÑÊÄßËÉΩÔºåArena-Hard„ÄÅMT-Bench„ÄÅWildBench„ÄÅZebraLogic„ÄÅMATH500ÔºåÈÄô‰∫õÊ∏¨Ë©¶Ë©ï‰º∞‰∫Ü‰∏çÂêåÁöÑ‰ªªÂãôËß£Ê±∫ÂíåÊé®ÁêÜËÉΩÂäõ„ÄÇ

##### **Pursuing Better Decision Boundaries for Long-Tailed Object Detection via Category Information Amount**
2502.03852v1 by Yanbiao Ma, Wei Dai, Jiayi Chen

In object detection, the instance count is typically used to define whether a
dataset exhibits a long-tail distribution, implicitly assuming that models will
underperform on categories with fewer instances. This assumption has led to
extensive research on category bias in datasets with imbalanced instance
counts. However, models still exhibit category bias even in datasets where
instance counts are relatively balanced, clearly indicating that instance count
alone cannot explain this phenomenon. In this work, we first introduce the
concept and measurement of category information amount. We observe a
significant negative correlation between category information amount and
accuracy, suggesting that category information amount more accurately reflects
the learning difficulty of a category. Based on this observation, we propose
Information Amount-Guided Angular Margin (IGAM) Loss. The core idea of IGAM is
to dynamically adjust the decision space of each category based on its
information amount, thereby reducing category bias in long-tail datasets. IGAM
Loss not only performs well on long-tailed benchmark datasets such as LVIS v1.0
and COCO-LT but also shows significant improvement for underrepresented
categories in the non-long-tailed dataset Pascal VOC. Comprehensive experiments
demonstrate the potential of category information amount as a tool and the
generality of our proposed method.

ÊëòË¶ÅÔºöÂú®ÁõÆÊ®ôÂÅµÊ∏¨‰∏≠ÔºåÂØ¶‰æãË®àÊï∏ÈÄöÂ∏∏Áî®ÊñºÂÆöÁæ©Ë≥áÊñôÈõÜÊòØÂê¶Â±ïÁèæÈï∑Â∞æÂàÜ‰ΩàÔºå‰∏¶Èö±Âê´ÂÅáË®≠Ê®°ÂûãÂú®ÂØ¶‰æãËºÉÂ∞ëÁöÑÈ°ûÂà•‰∏äË°®Áèæ‰∏ç‰Ω≥„ÄÇÈÄôÂÄãÂÅáË®≠Â∞éËá¥Â§ßÈáèÈáùÂ∞ç‰∏çÂπ≥Ë°°ÂØ¶‰æãË®àÊï∏Ë≥áÊñôÈõÜ‰∏≠È°ûÂà•ÂÅèË™§ÁöÑÁ†îÁ©∂„ÄÇÁÑ∂ËÄåÔºåÂç≥‰ΩøÂú®ÂØ¶‰æãË®àÊï∏Áõ∏Â∞çÂπ≥Ë°°ÁöÑË≥áÊñôÈõÜ‰∏≠ÔºåÊ®°Âûã‰ªçÊúÉÂ±ïÁèæÈ°ûÂà•ÂÅèË™§ÔºåÈÄôÊ∏ÖÊ•öÂú∞Ë°®ÊòéÂØ¶‰æãË®àÊï∏Êú¨Ë∫´ÁÑ°Ê≥ïËß£ÈáãÊ≠§ÁèæË±°„ÄÇÂú®Ê≠§Á†îÁ©∂‰∏≠ÔºåÊàëÂÄëÈ¶ñÂÖà‰ªãÁ¥πÈ°ûÂà•Ë≥áË®äÈáèÁöÑÊ¶ÇÂøµÂíåÂ∫¶Èáè„ÄÇÊàëÂÄëËßÄÂØüÂà∞È°ûÂà•Ë≥áË®äÈáèËàáÊ∫ñÁ¢∫Â∫¶‰πãÈñìÂ≠òÂú®È°ØËëóÁöÑË≤†Áõ∏ÈóúÔºåÈÄôË°®ÊòéÈ°ûÂà•Ë≥áË®äÈáèÊõ¥Ê∫ñÁ¢∫Âú∞ÂèçÊò†‰∫ÜÈ°ûÂà•ÁöÑÂ≠∏ÁøíÈõ£Â∫¶„ÄÇÂü∫ÊñºÊ≠§ËßÄÂØüÔºåÊàëÂÄëÊèêÂá∫Ë≥áË®äÈáèÂºïÂ∞éËßíË£ïÂ∫¶ÔºàIGAMÔºâÊêçÂ§±„ÄÇIGAM ÁöÑÊ†∏ÂøÉÊÄùÊÉ≥ÊòØÊ†πÊìöÊØèÂÄãÈ°ûÂà•ÁöÑË≥áË®äÈáèÂãïÊÖãË™øÊï¥ÂÖ∂Ê±∫Á≠ñÁ©∫ÈñìÔºåÂæûËÄåÊ∏õÂ∞ëÈï∑Â∞æË≥áÊñôÈõÜ‰∏≠ÁöÑÈ°ûÂà•ÂÅèË™§„ÄÇIGAM ÊêçÂ§±‰∏çÂÉÖÂú®Èï∑Â∞æÂü∫Ê∫ñË≥áÊñôÈõÜÔºà‰æãÂ¶Ç LVIS v1.0 Âíå COCO-LTÔºâ‰∏äË°®ÁèæËâØÂ•ΩÔºåËÄå‰∏îÂú®ÈùûÈï∑Â∞æË≥áÊñôÈõÜ Pascal VOC ‰∏≠ÁöÑ‰ª£Ë°®ÊÄß‰∏çË∂≥È°ûÂà•‰∏ä‰πüÂ±ïÁèæÂá∫È°ØËëóÁöÑÊîπÂñÑ„ÄÇÂÖ®Èù¢ÁöÑÂØ¶È©óË≠âÊòé‰∫ÜÈ°ûÂà•Ë≥áË®äÈáè‰ΩúÁÇ∫Â∑•ÂÖ∑ÁöÑÊΩõÂäõÔºå‰ª•ÂèäÊàëÂÄëÊèêÂá∫ÁöÑÊñπÊ≥ïÁöÑÊôÆÈÅçÊÄß„ÄÇ

##### **Improving Natural Language Understanding for LLMs via Large-Scale Instruction Synthesis**
2502.03843v1 by Lin Yuan, Jun Xu, Honghao Gui, Mengshu Sun, Zhiqiang Zhang, Lei Liang, Jun Zhou

High-quality, large-scale instructions are crucial for aligning large
language models (LLMs), however, there is a severe shortage of instruction in
the field of natural language understanding (NLU). Previous works on
constructing NLU instructions mainly focus on information extraction (IE),
neglecting tasks such as machine reading comprehension, question answering, and
text classification. Furthermore, the lack of diversity in the data has led to
a decreased generalization ability of trained LLMs in other NLU tasks and a
noticeable decline in the fundamental model's general capabilities. To address
this issue, we propose Hum, a large-scale, high-quality synthetic instruction
corpus for NLU tasks, designed to enhance the NLU capabilities of LLMs.
Specifically, Hum includes IE (either close IE or open IE), machine reading
comprehension, text classification, and instruction generalist tasks, thereby
enriching task diversity. Additionally, we introduce a human-LLMs collaborative
mechanism to synthesize instructions, which enriches instruction diversity by
incorporating guidelines, preference rules, and format variants. We conduct
extensive experiments on 5 NLU tasks and 28 general capability evaluation
datasets for LLMs. Experimental results show that Hum enhances the NLU
capabilities of six LLMs by an average of 3.1\%, with no significant decline
observed in other general capabilities.

ÊëòË¶ÅÔºöÈ´òÂìÅË≥™„ÄÅÂ§ßË¶èÊ®°ÁöÑÊåáÁ§∫Â∞çÊñºË™øÊï¥Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Ëá≥ÈóúÈáçË¶ÅÔºåÁÑ∂ËÄåÔºåÂú®Ëá™ÁÑ∂Ë™ûË®ÄÁêÜËß£ (NLU) È†òÂüü‰∏≠Âö¥ÈáçÁº∫‰πèÊåáÁ§∫„ÄÇÂÖàÂâçÈóúÊñºÂª∫Êßã NLU ÊåáÁ§∫ÁöÑÁ†îÁ©∂‰∏ªË¶ÅÂÅ¥ÈáçÊñºË≥áË®äËêÉÂèñ (IE)ÔºåÂøΩÁï•‰∫ÜÊ©üÂô®Èñ±ËÆÄÁêÜËß£„ÄÅÂïèÈ°åÂõûÁ≠îÂíåÊñáÂ≠óÂàÜÈ°ûÁ≠â‰ªªÂãô„ÄÇÊ≠§Â§ñÔºåË≥áÊñôÁº∫‰πèÂ§öÊ®£ÊÄßÂ∞éËá¥Ë®ìÁ∑¥ÂæåÁöÑ LLM Âú®ÂÖ∂‰ªñ NLU ‰ªªÂãô‰∏≠ÁöÑÊ¶ÇÂåñËÉΩÂäõ‰∏ãÈôçÔºå‰ª•ÂèäÂü∫Á§éÊ®°ÂûãÁöÑÊï¥È´îËÉΩÂäõÈ°ØËëó‰∏ãÈôç„ÄÇÁÇ∫‰∫ÜËß£Ê±∫Ê≠§ÂïèÈ°åÔºåÊàëÂÄëÊèêÂá∫ HumÔºåÈÄôÊòØ‰∏ÄÂÄãÈáùÂ∞ç NLU ‰ªªÂãôÁöÑÂ§ßË¶èÊ®°„ÄÅÈ´òÂìÅË≥™ÂêàÊàêÊåáÁ§∫Ë™ûÊñôÂ∫´ÔºåÊó®Âú®Â¢ûÂº∑ LLM ÁöÑ NLU ËÉΩÂäõ„ÄÇÂÖ∑È´î‰æÜË™™ÔºåHum ÂåÖÂê´ IEÔºàÂ∞ÅÈñâÂºè IE ÊàñÈñãÊîæÂºè IEÔºâ„ÄÅÊ©üÂô®Èñ±ËÆÄÁêÜËß£„ÄÅÊñáÂ≠óÂàÜÈ°ûÂíåÊåáÁ§∫ÈÄöÊâç‰ªªÂãôÔºåÂæûËÄåË±êÂØå‰ªªÂãôÂ§öÊ®£ÊÄß„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÂºïÂÖ•‰∏ÄÁ®Æ‰∫∫Ê©üÂçî‰ΩúÊ©üÂà∂‰æÜÂêàÊàêÊåáÁ§∫ÔºåÈÄèÈÅéÁ¥çÂÖ•Ê∫ñÂâá„ÄÅÂÅèÂ•ΩË¶èÂâáÂíåÊ†ºÂºèËÆäÈ´îÔºåË±êÂØåÊåáÁ§∫ÁöÑÂ§öÊ®£ÊÄß„ÄÇÊàëÂÄëÈáùÂ∞ç 5 ÂÄã NLU ‰ªªÂãôÂíå 28 ÂÄã LLM ÁöÑ‰∏ÄËà¨ËÉΩÂäõË©ï‰º∞Ë≥áÊñôÈõÜÈÄ≤Ë°åÂª£Ê≥õÁöÑÂØ¶È©ó„ÄÇÂØ¶È©óÁµêÊûúÈ°ØÁ§∫ÔºåHum Â∞áÂÖ≠ÂÄã LLM ÁöÑ NLU ËÉΩÂäõÂπ≥ÂùáÊèêÂçá‰∫Ü 3.1%ÔºåËÄåÂÖ∂‰ªñ‰∏ÄËà¨ËÉΩÂäõÂâáÊ≤íÊúâÈ°ØËëó‰∏ãÈôç„ÄÇ

##### **A comprehensive survey of contemporary Arabic sentiment analysis: Methods, Challenges, and Future Directions**
2502.03827v1 by Zhiqiang Shi, Ruchit Agrawal

Sentiment Analysis, a popular subtask of Natural Language Processing, employs
computational methods to extract sentiment, opinions, and other subjective
aspects from linguistic data. Given its crucial role in understanding human
sentiment, research in sentiment analysis has witnessed significant growth in
the recent years. However, the majority of approaches are aimed at the English
language, and research towards Arabic sentiment analysis remains relatively
unexplored. This paper presents a comprehensive and contemporary survey of
Arabic Sentiment Analysis, identifies the challenges and limitations of
existing literature in this field and presents avenues for future research. We
present a systematic review of Arabic sentiment analysis methods, focusing
specifically on research utilizing deep learning. We then situate Arabic
Sentiment Analysis within the broader context, highlighting research gaps in
Arabic sentiment analysis as compared to general sentiment analysis. Finally,
we outline the main challenges and promising future directions for research in
Arabic sentiment analysis.

ÊëòË¶ÅÔºöÊÉÖÊÑüÂàÜÊûêÊòØËá™ÁÑ∂Ë™ûË®ÄËôïÁêÜ‰∏≠‰∏ÄÂÄãÁÜ±ÈñÄÁöÑÂ≠ê‰ªªÂãôÔºåÂÆÉÊé°Áî®Ë®àÁÆóÊñπÊ≥ïÂæûË™ûË®ÄÊï∏Êìö‰∏≠ÊèêÂèñÊÉÖÊÑü„ÄÅËßÄÈªûÂíåÂÖ∂‰ªñ‰∏ªËßÄÊñπÈù¢„ÄÇÈëëÊñºÂÆÉÂú®ÁêÜËß£‰∫∫È°ûÊÉÖÊÑü‰∏≠Ëá≥ÈóúÈáçË¶ÅÁöÑ‰ΩúÁî®ÔºåËøëÂπæÂπ¥‰æÜÊÉÖÊÑüÂàÜÊûêÁöÑÁ†îÁ©∂Ë¶ãË≠â‰∫ÜÈ°ØËëóÁöÑÂ¢ûÈï∑„ÄÇÁÑ∂ËÄåÔºåÂ§ßÂ§öÊï∏ÊñπÊ≥ïÈÉΩÊòØÈáùÂ∞çËã±Ë™ûÁöÑÔºåËÄåÂ∞çÈòøÊãâ‰ºØË™ûÊÉÖÊÑüÂàÜÊûêÁöÑÁ†îÁ©∂‰ªçÁÑ∂Áõ∏Â∞çÊú™Ë¢´Êé¢Á¥¢„ÄÇÊú¨ÊñáÂ∞çÈòøÊãâ‰ºØË™ûÊÉÖÊÑüÂàÜÊûêÈÄ≤Ë°å‰∫ÜÂÖ®Èù¢ËÄåÁï∂‰ª£ÁöÑË™øÊü•ÔºåÊâæÂá∫Ë©≤È†òÂüüÁèæÊúâÊñáÁçªÁöÑÊåëÊà∞ÂíåÂ±ÄÈôêÊÄßÔºå‰∏¶ÊèêÂá∫‰∫ÜÊú™‰æÜÁ†îÁ©∂ÁöÑÈÄîÂæë„ÄÇÊàëÂÄëÂ∞çÈòøÊãâ‰ºØË™ûÊÉÖÊÑüÂàÜÊûêÊñπÊ≥ïÈÄ≤Ë°å‰∫ÜÁ≥ªÁµ±ÁöÑÂõûÈ°ßÔºåÁâπÂà•ÈóúÊ≥®Âà©Áî®Ê∑±Â∫¶Â≠∏ÁøíÁöÑÁ†îÁ©∂„ÄÇÁÑ∂ÂæåÔºåÊàëÂÄëÂ∞áÈòøÊãâ‰ºØË™ûÊÉÖÊÑüÂàÜÊûêÁΩÆÊñºÊõ¥Âª£Ê≥õÁöÑËÉåÊôØ‰∏≠ÔºåÂº∑Ë™øÈòøÊãâ‰ºØË™ûÊÉÖÊÑüÂàÜÊûêËàá‰∏ÄËà¨ÊÉÖÊÑüÂàÜÊûêÁõ∏ÊØîÁöÑÁ†îÁ©∂Â∑ÆË∑ù„ÄÇÊúÄÂæåÔºåÊàëÂÄëÊ¶ÇËø∞‰∫ÜÈòøÊãâ‰ºØË™ûÊÉÖÊÑüÂàÜÊûêÁ†îÁ©∂ÁöÑ‰∏ªË¶ÅÊåëÊà∞ÂíåÊúâÂ∏åÊúõÁöÑÊú™‰æÜÊñπÂêë„ÄÇ

##### **Syntriever: How to Train Your Retriever with Synthetic Data from LLMs**
2502.03824v1 by Minsang Kim, Seungjun Baek

LLMs have boosted progress in many AI applications. Recently, there were
attempts to distill the vast knowledge of LLMs into information retrieval
systems. Those distillation methods mostly use output probabilities of LLMs
which are unavailable in the latest black-box LLMs. We propose Syntriever, a
training framework for retrievers using synthetic data from black-box LLMs.
Syntriever consists of two stages. Firstly in the distillation stage, we
synthesize relevant and plausibly irrelevant passages and augmented queries
using chain-of-thoughts for the given queries. LLM is asked to self-verify the
synthetic data for possible hallucinations, after which retrievers are trained
with a loss designed to cluster the embeddings of relevant passages. Secondly
in the alignment stage, we align the retriever with the preferences of LLMs. We
propose a preference modeling called partial Plackett-Luce ranking to learn LLM
preferences with regularization which prevents the model from deviating
excessively from that trained in the distillation stage. Experiments show that
Syntriever achieves state-of-the-art performances on benchmark datasets from
various domains in nDCG@$K$. The code is available at
\href{https://github.com/kmswin1/Syntriever}{https://github.com/kmswin1/Syntriever}.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ‰øÉËøõ‰∫ÜË®±Â§ö AI ÊáâÁî®Á®ãÂºèÁöÑÈÄ≤Â±ï„ÄÇÊúÄËøëÔºåÊúâ‰∫∫ÂòóË©¶Â∞á LLM ÁöÑÈæêÂ§ßÁü•Ë≠òÊèêÁÖâÂà∞Ë≥áË®äÊ™¢Á¥¢Á≥ªÁµ±‰∏≠„ÄÇÈÄô‰∫õÊèêÁÖâÊñπÊ≥ïÂ§ßÂ§ö‰ΩøÁî® LLM ÁöÑËº∏Âá∫Ê©üÁéáÔºåËÄåÈÄô‰∫õÊ©üÁéáÂú®ÊúÄÊñ∞ÁöÑÈªëÁõí LLM ‰∏≠‰∏¶‰∏çÂèØÁî®„ÄÇÊàëÂÄëÊèêÂá∫‰∫Ü SyntrieverÔºå‰∏ÄÂÄã‰ΩøÁî®‰æÜËá™ÈªëÁõí LLM ÁöÑÂêàÊàêË≥áÊñôË®ìÁ∑¥Ê™¢Á¥¢Âô®ÁöÑÊ°ÜÊû∂„ÄÇSyntriever ÂåÖÂê´ÂÖ©ÂÄãÈöéÊÆµ„ÄÇÈ¶ñÂÖàÔºåÂú®ÊèêÁÖâÈöéÊÆµÔºåÊàëÂÄë‰ΩøÁî®ÊÄùÊÉ≥ÈèàÁÇ∫Áµ¶ÂÆöÁöÑÊü•Ë©¢ÂêàÊàêÁõ∏Èóú‰∏îÁúã‰ºº‰∏çÁõ∏ÈóúÁöÑÊÆµËêΩÂíåÊì¥ÂÖÖÊü•Ë©¢„ÄÇLLM ÊúÉË¢´Ë¶ÅÊ±ÇËá™Ë°åÈ©óË≠âÂêàÊàêË≥áÊñôÊòØÂê¶ÊúâÂèØËÉΩÁöÑÂπªË¶∫ÔºåÁÑ∂Âæå‰ΩøÁî®Êó®Âú®Â∞áÁõ∏ÈóúÊÆµËêΩÁöÑÂµåÂÖ•ÂºèÂàÜÁæ§ÁöÑÊêçÂ§±ÂáΩÊï∏Ë®ìÁ∑¥Ê™¢Á¥¢Âô®„ÄÇÂÖ∂Ê¨°ÔºåÂú®Â∞çÈΩäÈöéÊÆµÔºåÊàëÂÄëÂ∞áÊ™¢Á¥¢Âô®Ëàá LLM ÁöÑÂÅèÂ•ΩÂ∞çÈΩä„ÄÇÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÂÅèÂ•ΩÊ®°ÂûãÔºåÁ®±ÁÇ∫ÈÉ®ÂàÜ Plackett-Luce ÊéíÂêçÔºå‰ª•Â≠∏Áøí LLM ÂÅèÂ•ΩÔºå‰∏¶‰ΩøÁî®Ê≠£ÂâáÂåñ‰æÜÈò≤Ê≠¢Ê®°ÂûãÈÅéÂ∫¶ÂÅèÈõ¢Âú®ÊèêÁÖâÈöéÊÆµË®ìÁ∑¥ÁöÑÊ®°Âûã„ÄÇÂØ¶È©óË°®ÊòéÔºåSyntriever Âú®‰æÜËá™ÂêÑÁ®ÆÁ∂≤ÂüüÁöÑÂü∫Ê∫ñË≥áÊñôÈõÜ‰∏äÈÅîÂà∞‰∫Ü nDCG@$K$ ÁöÑÊúÄÂÖàÈÄ≤ÊïàËÉΩ„ÄÇÁ®ãÂºèÁ¢ºÂèØÂú®
\href{https://github.com/kmswin1/Syntriever}{https://github.com/kmswin1/Syntriever} ÂèñÂæó„ÄÇ

##### **PsyPlay: Personality-Infused Role-Playing Conversational Agents**
2502.03821v1 by Tao Yang, Yuhua Zhu, Xiaojun Quan, Cong Liu, Qifan Wang

The current research on Role-Playing Conversational Agents (RPCAs) with Large
Language Models (LLMs) primarily focuses on imitating specific speaking styles
and utilizing character backgrounds, neglecting the depiction of deeper
personality traits.~In this study, we introduce personality-infused
role-playing for LLM agents, which encourages agents to accurately portray
their designated personality traits during dialogues. We then propose PsyPlay,
a dialogue generation framework that facilitates the expression of rich
personalities among multiple LLM agents. Specifically, PsyPlay enables agents
to assume roles with distinct personality traits and engage in discussions
centered around specific topics, consistently exhibiting their designated
personality traits throughout the interactions. Validation on generated
dialogue data demonstrates that PsyPlay can accurately portray the intended
personality traits, achieving an overall success rate of 80.31% on GPT-3.5.
Notably, we observe that LLMs aligned with positive values are more successful
in portraying positive personality roles compared to negative ones. Moreover,
we construct a dialogue corpus for personality-infused role-playing, called
PsyPlay-Bench. The corpus, which consists of 4745 instances of correctly
portrayed dialogues using PsyPlay, aims to further facilitate research in
personalized role-playing and dialogue personality detection.

ÊëòË¶ÅÔºöÁõÆÂâçÈóúÊñºÂÖ∑ÂÇôÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑËßíËâ≤ÊâÆÊºîÂ∞çË©±‰ª£ÁêÜ (RPCA) ÁöÑÁ†îÁ©∂Ôºå‰∏ªË¶ÅÈõÜ‰∏≠ÊñºÊ®°‰ªøÁâπÂÆöÁöÑË™™Ë©±È¢®Ê†ºÂíåÂà©Áî®ËßíËâ≤ËÉåÊôØÔºåÂçªÂøΩÁï•‰∫ÜÂ∞çÊõ¥Ê∑±Â±§‰∫∫Ê†ºÁâπË≥™ÁöÑÊèèÁπ™„ÄÇÂú®ÈÄôÈ†ÖÁ†îÁ©∂‰∏≠ÔºåÊàëÂÄëÂºïÂÖ•‰∫ÜÁÇ∫ LLM ‰ª£ÁêÜÊ≥®ÂÖ•‰∫∫Ê†ºÁöÑËßíËâ≤ÊâÆÊºîÔºåÈºìÂãµ‰ª£ÁêÜÂú®Â∞çË©±‰∏≠Ê∫ñÁ¢∫Âú∞ÊèèÁπ™‰ªñÂÄëÊåáÂÆöÁöÑ‰∫∫Ê†ºÁâπË≥™„ÄÇÁÑ∂ÂæåÊàëÂÄëÊèêÂá∫‰∫Ü PsyPlayÔºåÈÄôÊòØ‰∏ÄÂÄãÂ∞çË©±ÁîüÊàêÊû∂ÊßãÔºåÂèØ‰ª•‰øÉÈÄ≤Â§öÂÄã LLM ‰ª£ÁêÜ‰πãÈñìË±êÂØå‰∫∫Ê†ºÁöÑË°®ÈÅî„ÄÇÂÖ∑È´î‰æÜË™™ÔºåPsyPlay ËÉΩËÆì‰ª£ÁêÜÊâÆÊºîÂÖ∑Êúâ‰∏çÂêå‰∫∫Ê†ºÁâπË≥™ÁöÑËßíËâ≤Ôºå‰∏¶ÂèÉËàá‰ª•ÁâπÂÆö‰∏ªÈ°åÁÇ∫‰∏≠ÂøÉÁöÑË®éË´ñÔºåÂú®Êï¥ÂÄã‰∫íÂãïÈÅéÁ®ã‰∏≠ÂßãÁµÇÂ±ïÁèæ‰ªñÂÄëÊåáÂÆöÁöÑ‰∫∫Ê†ºÁâπË≥™„ÄÇÂ∞çÁîüÊàêÁöÑÂ∞çË©±Êï∏ÊìöÁöÑÈ©óË≠âË°®ÊòéÔºåPsyPlay ÂèØ‰ª•Ê∫ñÁ¢∫Âú∞ÊèèÁπ™È†êÊúüÁöÑ‰∫∫Ê†ºÁâπË≥™ÔºåÂú® GPT-3.5 ‰∏äÂØ¶Áèæ‰∫Ü 80.31% ÁöÑÊï¥È´îÊàêÂäüÁéá„ÄÇÂÄºÂæóÊ≥®ÊÑèÁöÑÊòØÔºåÊàëÂÄëËßÄÂØüÂà∞ËàáÊ≠£Èù¢ÂÉπÂÄºËßÄ‰∏ÄËá¥ÁöÑ LLM Âú®ÊèèÁπ™Ê≠£Èù¢‰∫∫Ê†ºËßíËâ≤ÊñπÈù¢ÊØîÊèèÁπ™Ë≤†Èù¢‰∫∫Ê†ºËßíËâ≤Êõ¥ÊàêÂäü„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÊßãÂª∫‰∫Ü‰∏ÄÂÄãÂêçÁÇ∫ PsyPlay-Bench ÁöÑÁî®ÊñºÊ≥®ÂÖ•‰∫∫Ê†ºÁöÑËßíËâ≤ÊâÆÊºîÁöÑÂ∞çË©±Ë™ûÊñôÂ∫´„ÄÇË©≤Ë™ûÊñôÂ∫´Áî±‰ΩøÁî® PsyPlay Ê≠£Á¢∫ÊèèÁπ™Â∞çË©±ÁöÑ 4745 ÂÄãÂØ¶‰æãÁµÑÊàêÔºåÊó®Âú®ÈÄ≤‰∏ÄÊ≠•‰øÉÈÄ≤ÂÄãÊÄßÂåñËßíËâ≤ÊâÆÊºîÂíåÂ∞çË©±‰∫∫Ê†ºÊ™¢Ê∏¨ÁöÑÁ†îÁ©∂„ÄÇ

##### **Large Language Models for Multi-Robot Systems: A Survey**
2502.03814v1 by Peihan Li, Zijian An, Shams Abrar, Lifeng Zhou

The rapid advancement of Large Language Models (LLMs) has opened new
possibilities in Multi-Robot Systems (MRS), enabling enhanced communication,
task planning, and human-robot interaction. Unlike traditional single-robot and
multi-agent systems, MRS poses unique challenges, including coordination,
scalability, and real-world adaptability. This survey provides the first
comprehensive exploration of LLM integration into MRS. It systematically
categorizes their applications across high-level task allocation, mid-level
motion planning, low-level action generation, and human intervention. We
highlight key applications in diverse domains, such as household robotics,
construction, formation control, target tracking, and robot games, showcasing
the versatility and transformative potential of LLMs in MRS. Furthermore, we
examine the challenges that limit adapting LLMs in MRS, including mathematical
reasoning limitations, hallucination, latency issues, and the need for robust
benchmarking systems. Finally, we outline opportunities for future research,
emphasizing advancements in fine-tuning, reasoning techniques, and
task-specific models. This survey aims to guide researchers in the intelligence
and real-world deployment of MRS powered by LLMs. Based on the fast-evolving
nature of research in the field, we keep updating the papers in the open-source
Github repository.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑÂø´ÈÄüÈÄ≤Â±ïÁÇ∫Â§öÊ©üÂô®‰∫∫Á≥ªÁµ± (MRS) ÈñãÂïü‰∫ÜÊñ∞ÁöÑÂèØËÉΩÊÄßÔºåÂØ¶Áèæ‰∫ÜÂ¢ûÂº∑ÁöÑÈÄö‰ø°„ÄÅ‰ªªÂãôË¶èÂäÉÂíå‰∫∫Ê©ü‰∫§‰∫í„ÄÇËàáÂÇ≥Áµ±ÁöÑÂñÆÊ©üÂô®‰∫∫ÂíåÂ§öÊô∫ËÉΩÈ´îÁ≥ªÁµ±‰∏çÂêåÔºåMRS ÊèêÂá∫‰∫Ü‰∏Ä‰∫õÁç®ÁâπÁöÑÊåëÊà∞ÔºåÂåÖÊã¨ÂçîË™ø„ÄÅÂèØÊì¥Â±ïÊÄßÂíåÁèæÂØ¶‰∏ñÁïåÁöÑÈÅ©ÊáâÊÄß„ÄÇÈÄôÈ†ÖË™øÊü•È¶ñÊ¨°ÂÖ®Èù¢Êé¢Ë®é‰∫Ü LLM Ëàá MRS ÁöÑÊï¥Âêà„ÄÇÂÆÉÁ≥ªÁµ±ÊÄßÂú∞ÂàÜÈ°û‰∫ÜÂÆÉÂÄëÂú®È´òÂ±§Ê¨°‰ªªÂãôÂàÜÈÖç„ÄÅ‰∏≠Â±§Ê¨°ÈÅãÂãïË¶èÂäÉ„ÄÅ‰ΩéÂ±§Ê¨°Âãï‰ΩúÁîüÊàêÂíå‰∫∫È°ûÂπ≤È†ê‰∏≠ÁöÑÊáâÁî®„ÄÇÊàëÂÄëÈáçÈªû‰ªãÁ¥π‰∫ÜÂÆ∂Â∫≠Ê©üÂô®‰∫∫„ÄÅÂª∫ÁØâ„ÄÅÁ∑®ÈöäÊéßÂà∂„ÄÅÁõÆÊ®ôË∑üËπ§ÂíåÊ©üÂô®‰∫∫ÈÅäÊà≤Á≠â‰∏çÂêåÈ†òÂüüÁöÑÈóúÈçµÊáâÁî®ÔºåÂ±ïÁ§∫‰∫Ü LLM Âú® MRS ‰∏≠ÁöÑÂ§öÂäüËÉΩÊÄßÂíåËÆäÈù©ÊΩõÂäõ„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÊé¢Ë®é‰∫ÜÈôêÂà∂ LLM Âú® MRS ‰∏≠ÈÅ©ÊáâÁöÑÊåëÊà∞ÔºåÂåÖÊã¨Êï∏Â≠∏Êé®ÁêÜÈôêÂà∂„ÄÅÂπªË¶∫„ÄÅÂª∂ÈÅ≤ÂïèÈ°åÂíåÂ∞çÂÅ•Â£ØÂü∫Ê∫ñÁ≥ªÁµ±ÁöÑÈúÄÊ±Ç„ÄÇÊúÄÂæåÔºåÊàëÂÄëÊ¶ÇËø∞‰∫ÜÊú™‰æÜÁ†îÁ©∂ÁöÑÊ©üÊúÉÔºåÂº∑Ë™øÂæÆË™ø„ÄÅÊé®ÁêÜÊäÄË°ìÂíåÁâπÂÆö‰ªªÂãôÊ®°ÂûãÁöÑÈÄ≤Â±ï„ÄÇÈÄôÈ†ÖË™øÊü•Êó®Âú®ÊåáÂ∞éÁ†îÁ©∂‰∫∫Âì°Âú® LLM È©ÖÂãïÁöÑ MRS ÁöÑÊô∫ËÉΩÂíåÁèæÂØ¶‰∏ñÁïåÈÉ®ÁΩ≤‰∏≠„ÄÇÂü∫ÊñºË©≤È†òÂüüÁ†îÁ©∂ÁöÑÂø´ÈÄüÁôºÂ±ïÔºåÊàëÂÄëÊúÉÊåÅÁ∫åÊõ¥Êñ∞ÈñãÊ∫ê Github ÂÑ≤Â≠òÂ∫´‰∏≠ÁöÑË´ñÊñá„ÄÇ

##### **Identify Critical KV Cache in LLM Inference from an Output Perturbation Perspective**
2502.03805v1 by Yuan Feng, Junlin Lv, Yukun Cao, Xike Xie, S Kevin Zhou

Large language models have revolutionized natural language processing but
face significant challenges of high storage and runtime costs, due to the
transformer architecture's reliance on self-attention, particularly the large
Key-Value (KV) cache for long-sequence inference. Recent efforts to reduce KV
cache size by pruning less critical entries based on attention weights remain
empirical and lack formal grounding. This paper presents a formal study on
identifying critical KV cache entries by analyzing attention output
perturbation. Our analysis reveals that, beyond attention weights, the value
states within KV entries and pretrained parameter matrices are also crucial.
Based on this, we propose a perturbation-constrained selection algorithm that
optimizes the worst-case output perturbation to identify critical entries.
Evaluations on the Needle-in-a-Haystack test and Longbench benchmark show our
algorithm enhances state-of-the-art cache eviction methods. Further empirical
analysis confirms that our algorithm achieves lower output perturbations in
over 92% attention heads in Llama model, thereby providing a significant
improvement over existing methods.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÂ∑≤Á∂ìÂæπÂ∫ïÊîπËÆä‰∫ÜËá™ÁÑ∂Ë™ûË®ÄËôïÁêÜÔºå‰ΩÜÁî±ÊñºTransformerÊû∂Êßã‰æùË≥¥ÊñºËá™ÊàëÊ≥®ÊÑèÔºåÁâπÂà•ÊòØÈï∑Â∫èÂàóÊé®Ë´ñÁöÑÂ§ßÂûãÈçµÂÄº (KV) Âø´ÂèñÔºåÂõ†Ê≠§Èù¢Ëá®ËëóÂÑ≤Â≠òÂíåÂü∑Ë°åÊôÇÈñìÊàêÊú¨È´òÁöÑÈáçÂ§ßÊåëÊà∞„ÄÇÊúÄËøëÈÄèÈÅéÊ†πÊìöÊ≥®ÊÑèÂäõÊ¨äÈáç‰æÜ‰øÆÂâ™ËºÉ‰∏çÈáçË¶ÅÁöÑÊ¢ùÁõÆ‰ª•Ê∏õÂ∞ë KV Âø´ÂèñÂ§ßÂ∞èÁöÑÂä™Âäõ‰ªçÁÑ∂ÊòØÁ∂ìÈ©óÊÄßÁöÑÔºå‰∏¶‰∏îÁº∫‰πèÊ≠£ÂºèÁöÑ‰æùÊìö„ÄÇÊú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÈ†ÖÊ≠£ÂºèÁöÑÁ†îÁ©∂ÔºåÈÄèÈÅéÂàÜÊûêÊ≥®ÊÑèÂäõËº∏Âá∫ÊìæÂãï‰æÜË≠òÂà•ÈáçË¶ÅÁöÑ KV Âø´ÂèñÊ¢ùÁõÆ„ÄÇÊàëÂÄëÁöÑÂàÜÊûêÈ°ØÁ§∫ÔºåÈô§‰∫ÜÊ≥®ÊÑèÂäõÊ¨äÈáç‰πãÂ§ñÔºåKV Ê¢ùÁõÆ‰∏≠ÁöÑÂÄºÁãÄÊÖãÂíåÈ†êË®ìÁ∑¥ÂèÉÊï∏Áü©Èô£‰πüËá≥ÈóúÈáçË¶Å„ÄÇÂü∫ÊñºÊ≠§ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÊìæÂãïÁ¥ÑÊùüÈÅ∏ÊìáÊºîÁÆóÊ≥ïÔºåÂÆÉÊúÄ‰Ω≥ÂåñÊúÄÂ∑ÆÊÉÖÊ≥ÅÁöÑËº∏Âá∫ÊìæÂãï‰ª•Ë≠òÂà•ÈáçË¶ÅÁöÑÊ¢ùÁõÆ„ÄÇÂú® Needle-in-a-Haystack Ê∏¨Ë©¶Âíå Longbench Âü∫Ê∫ñ‰∏äÁöÑË©ï‰º∞È°ØÁ§∫ÔºåÊàëÂÄëÁöÑÊºîÁÆóÊ≥ïÂ¢ûÂº∑‰∫ÜÊúÄÂÖàÈÄ≤ÁöÑÂø´ÂèñÈ©ÖÈÄêÊñπÊ≥ï„ÄÇÈÄ≤‰∏ÄÊ≠•ÁöÑÁ∂ìÈ©óÂàÜÊûêË≠âÂØ¶ÔºåÊàëÂÄëÁöÑÊºîÁÆóÊ≥ïÂú® Llama Ê®°Âûã‰∏≠Ë∂ÖÈÅé 92% ÁöÑÊ≥®ÊÑèÂäõÈ†≠‰∏≠ÈÅîÂà∞‰∫ÜËºÉ‰ΩéÁöÑËº∏Âá∫ÊìæÂãïÔºåÂæûËÄåÊèê‰æõ‰∫ÜÂ∞çÁèæÊúâÊñπÊ≥ïÁöÑÈ°ØËëóÊîπÈÄ≤„ÄÇ

##### **Understanding and Supporting Formal Email Exchange by Answering AI-Generated Questions**
2502.03804v1 by Yusuke Miura, Chi-Lan Yang, Masaki Kuribayashi, Keigo Matsumoto, Hideaki Kuzuoka, Shigeo Morishima

Replying to formal emails is time-consuming and cognitively demanding, as it
requires polite phrasing and ensuring an adequate response to the sender's
demands. Although systems with Large Language Models (LLM) were designed to
simplify the email replying process, users still needed to provide detailed
prompts to obtain the expected output. Therefore, we proposed and evaluated an
LLM-powered question-and-answer (QA)-based approach for users to reply to
emails by answering a set of simple and short questions generated from the
incoming email. We developed a prototype system, ResQ, and conducted controlled
and field experiments with 12 and 8 participants. Our results demonstrated that
QA-based approach improves the efficiency of replying to emails and reduces
workload while maintaining email quality compared to a conventional
prompt-based approach that requires users to craft appropriate prompts to
obtain email drafts. We discuss how QA-based approach influences the email
reply process and interpersonal relationship dynamics, as well as the
opportunities and challenges associated with using a QA-based approach in
AI-mediated communication.

ÊëòË¶ÅÔºöÂõûË¶ÜÊ≠£ÂºèÁöÑÈõªÂ≠êÈÉµ‰ª∂ÊúÉËÄóÊôÇ‰∏îÂú®Ë™çÁü•‰∏äË¶ÅÊ±ÇÂæàÈ´òÔºåÂõ†ÁÇ∫ÂÆÉÈúÄË¶ÅÊúâÁ¶ÆË≤åÁöÑÊé™Ëæ≠‰∏¶Á¢∫‰øùÂ∞çÁôº‰ª∂‰∫∫ÁöÑË¶ÅÊ±ÇÂÅöÂá∫ÈÅ©Áï∂ÁöÑÂõûÊáâ„ÄÇÂÑòÁÆ°ÂÖ∑ÂÇôÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑÁ≥ªÁµ±Ë¢´Ë®≠Ë®àÁî®ÊñºÁ∞°ÂåñÈõªÂ≠êÈÉµ‰ª∂ÂõûË¶ÜÁ®ãÂ∫èÔºå‰ΩÜ‰ΩøÁî®ËÄÖ‰ªçÁÑ∂ÈúÄË¶ÅÊèê‰æõË©≥Á¥∞ÁöÑÊèêÁ§∫ÊâçËÉΩÁç≤ÂæóÈ†êÊúüÁöÑËº∏Âá∫„ÄÇÂõ†Ê≠§ÔºåÊàëÂÄëÊèêÂá∫‰∏¶Ë©ï‰º∞‰∫Ü‰∏ÄÁ®ÆÁî± LLM È©ÖÂãï„ÄÅÂü∫ÊñºÂïèÁ≠î (QA) ÁöÑÊñπÊ≥ïÔºåËÆì‰ΩøÁî®ËÄÖÈÄèÈÅéÂõûÁ≠îÂæûÊî∂Âà∞ÁöÑÈõªÂ≠êÈÉµ‰ª∂‰∏≠Áî¢ÁîüÁöÑÁ∞°ÂñÆ‰∏îÁ∞°Áü≠ÁöÑÂïèÈ°å‰æÜÂõûË¶ÜÈõªÂ≠êÈÉµ‰ª∂„ÄÇÊàëÂÄëÈñãÁôº‰∫Ü‰∏ÄÂÄãÂéüÂûãÁ≥ªÁµ± ResQÔºå‰∏¶Ëàá 12 Âíå 8 ‰ΩçÂèÉËàáËÄÖÈÄ≤Ë°å‰∫ÜÂèóÊéßÁöÑÂíåÁèæÂ†¥ÂØ¶È©ó„ÄÇÊàëÂÄëÁöÑÁµêÊûúË°®ÊòéÔºåËàáÈúÄË¶Å‰ΩøÁî®ËÄÖË£Ω‰ΩúÈÅ©Áï∂ÁöÑÊèêÁ§∫‰æÜÂèñÂæóÈõªÂ≠êÈÉµ‰ª∂ËçâÁ®øÁöÑÂÇ≥Áµ±Âü∫ÊñºÊèêÁ§∫ÁöÑÊñπÊ≥ïÁõ∏ÊØîÔºåÂü∫Êñº QA ÁöÑÊñπÊ≥ïÊèêÈ´ò‰∫ÜÂõûË¶ÜÈõªÂ≠êÈÉµ‰ª∂ÁöÑÊïàÁéáÔºå‰∏¶Ê∏õÂ∞ë‰∫ÜÂ∑•‰ΩúÈáèÔºåÂêåÊôÇÁ∂≠ÊåÅÈõªÂ≠êÈÉµ‰ª∂ÂìÅË≥™„ÄÇÊàëÂÄëË®éË´ñ‰∫ÜÂü∫Êñº QA ÁöÑÊñπÊ≥ïÂ¶Ç‰ΩïÂΩ±ÈüøÈõªÂ≠êÈÉµ‰ª∂ÂõûË¶ÜÁ®ãÂ∫èÂíå‰∫∫ÈöõÈóú‰øÇÂãïÊÖãÔºå‰ª•ÂèäÂú® AI Â™í‰ªãÁöÑÊ∫ùÈÄö‰∏≠‰ΩøÁî®Âü∫Êñº QA ÁöÑÊñπÊ≥ïÁõ∏ÈóúÁöÑÊ©üÊúÉÂíåÊåëÊà∞„ÄÇ

##### **SoK: Benchmarking Poisoning Attacks and Defenses in Federated Learning**
2502.03801v1 by Heyi Zhang, Yule Liu, Xinlei He, Jun Wu, Tianshuo Cong, Xinyi Huang

Federated learning (FL) enables collaborative model training while preserving
data privacy, but its decentralized nature exposes it to client-side data
poisoning attacks (DPAs) and model poisoning attacks (MPAs) that degrade global
model performance. While numerous proposed defenses claim substantial
effectiveness, their evaluation is typically done in isolation with limited
attack strategies, raising concerns about their validity. Additionally,
existing studies overlook the mutual effectiveness of defenses against both
DPAs and MPAs, causing fragmentation in this field. This paper aims to provide
a unified benchmark and analysis of defenses against DPAs and MPAs, clarifying
the distinction between these two similar but slightly distinct domains. We
present a systematic taxonomy of poisoning attacks and defense strategies,
outlining their design, strengths, and limitations. Then, a unified comparative
evaluation across FL algorithms and data heterogeneity is conducted to validate
their individual and mutual effectiveness and derive key insights for design
principles and future research. Along with the analysis, we frame our work to a
unified benchmark, FLPoison, with high modularity and scalability to evaluate
15 representative poisoning attacks and 17 defense strategies, facilitating
future research in this domain. Code is available at
https://github.com/vio1etus/FLPoison.

ÊëòË¶ÅÔºöËÅîÈÇ¶Â≠¶‰π† (FL) ÂèØ‰ª•Âú®‰øùÊä§Êï∞ÊçÆÈöêÁßÅÁöÑÂêåÊó∂ËøõË°åÂçè‰ΩúÊ®°ÂûãËÆ≠ÁªÉÔºå‰ΩÜÂÖ∂ÂàÜÊï£ÁöÑÁâπÊÄß‰ΩøÂÖ∂Èù¢‰∏¥ÂÆ¢Êà∑Á´ØÊï∞ÊçÆ‰∏≠ÊØíÊîªÂáª (DPA) ÂíåÊ®°Âûã‰∏≠ÊØíÊîªÂáª (MPA)ÔºåËøô‰∫õÊîªÂáª‰ºöÈôç‰ΩéÂÖ®Â±ÄÊ®°ÂûãÊÄßËÉΩ„ÄÇËôΩÁÑ∂ËÆ∏Â§öÊèêËÆÆÁöÑÈò≤Âæ°Êé™ÊñΩÂ£∞Áß∞ÂÖ∑ÊúâÂÆûË¥®ÊÄßÁöÑÊúâÊïàÊÄßÔºå‰ΩÜÂÆÉ‰ª¨ÁöÑËØÑ‰º∞ÈÄöÂ∏∏ÊòØÂú®ÈöîÁ¶ªÁöÑÊÉÖÂÜµ‰∏ãËøõË°åÁöÑÔºåÊîªÂáªÁ≠ñÁï•ÊúâÈôêÔºåËøôÂºïÂèë‰∫ÜÂØπÂÖ∂ÊúâÊïàÊÄßÁöÑÊãÖÂøß„ÄÇÊ≠§Â§ñÔºåÁé∞ÊúâÁ†îÁ©∂ÂøΩÁï•‰∫ÜÈò≤Âæ°Êé™ÊñΩÂØπ DPA Âíå MPA ÁöÑÁõ∏‰∫íÊúâÊïàÊÄßÔºåÂØºËá¥ËØ•È¢ÜÂüüÁöÑÁ¢éÁâáÂåñ„ÄÇÊú¨ÊñáÊó®Âú®Êèê‰æõÈíàÂØπ DPA Âíå MPA ÁöÑÈò≤Âæ°Êé™ÊñΩÁöÑÁªü‰∏ÄÂü∫ÂáÜÂíåÂàÜÊûêÔºåÈòêÊòéËøô‰∏§‰∏™Áõ∏‰ºº‰ΩÜÁï•Êúâ‰∏çÂêåÁöÑÈ¢ÜÂüü‰πãÈó¥ÁöÑÂå∫Âà´„ÄÇÊàë‰ª¨ÊèêÂá∫‰∫Ü‰∏≠ÊØíÊîªÂáªÂíåÈò≤Âæ°Á≠ñÁï•ÁöÑÁ≥ªÁªüÂàÜÁ±ªÊ≥ïÔºåÊ¶ÇËø∞‰∫ÜÂÆÉ‰ª¨ÁöÑËÆæËÆ°„ÄÅ‰ºòÂäøÂíåÂ±ÄÈôêÊÄß„ÄÇÁÑ∂ÂêéÔºåÂØπË∑® FL ÁÆóÊ≥ïÂíåÊï∞ÊçÆÂºÇÊûÑÊÄßÁöÑÁªü‰∏ÄÊØîËæÉËØÑ‰º∞ËøõË°å‰∫ÜÈ™åËØÅÔºå‰ª•È™åËØÅÂÆÉ‰ª¨ÁöÑ‰∏™‰ΩìÂíåÁõ∏‰∫íÊúâÊïàÊÄßÔºåÂπ∂ÂæóÂá∫ËÆæËÆ°ÂéüÂàôÂíåÊú™Êù•Á†îÁ©∂ÁöÑÂÖ≥ÈîÆËßÅËß£„ÄÇÈöèÁùÄÂàÜÊûêÔºåÊàë‰ª¨Â∞ÜÊàë‰ª¨ÁöÑÂ∑•‰ΩúÊ°ÜÊû∂Âåñ‰∏∫‰∏Ä‰∏™Áªü‰∏ÄÁöÑÂü∫ÂáÜ FLPoisonÔºåÂÆÉÂÖ∑ÊúâÈ´òÂ∫¶ÁöÑÊ®°ÂùóÂåñÂíåÂèØÊâ©Â±ïÊÄßÔºå‰ª•ËØÑ‰º∞ 15 Áßç‰ª£Ë°®ÊÄß‰∏≠ÊØíÊîªÂáªÂíå 17 ÁßçÈò≤Âæ°Á≠ñÁï•Ôºå‰øÉËøõËØ•È¢ÜÂüüÁöÑÊú™Êù•Á†îÁ©∂„ÄÇ‰ª£Á†ÅÂèØÂú® https://github.com/vio1etus/FLPoison Ëé∑Âæó„ÄÇ

##### **Enhancing Hallucination Detection through Noise Injection**
2502.03799v1 by Litian Liu, Reza Pourreza, Sunny Panchal, Apratim Bhattacharyya, Yao Qin, Roland Memisevic

Large Language Models (LLMs) are prone to generating plausible yet incorrect
responses, known as hallucinations. Effectively detecting hallucinations is
therefore crucial for the safe deployment of LLMs. Recent research has linked
hallucinations to model uncertainty, suggesting that hallucinations can be
detected by measuring dispersion over answer distributions obtained from a set
of samples drawn from a model. While drawing from the distribution over tokens
defined by the model is a natural way to obtain samples, in this work, we argue
that it is sub-optimal for the purpose of detecting hallucinations. We show
that detection can be improved significantly by taking into account model
uncertainty in the Bayesian sense. To this end, we propose a very simple and
efficient approach that perturbs an appropriate subset of model parameters, or
equivalently hidden unit activations, during sampling. We demonstrate its
effectiveness across a wide range of datasets and model architectures.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÂÆπÊòìÁî¢ÁîüÁúã‰ººÂêàÁêÜ‰ΩÜÈåØË™§ÁöÑÂõûÊáâÔºåÁ®±ÁÇ∫ÂπªË¶∫„ÄÇÂõ†Ê≠§ÔºåÊúâÊïàÂú∞ÂÅµÊ∏¨ÂπªË¶∫Â∞çÊñº LLM ÁöÑÂÆâÂÖ®ÈÉ®ÁΩ≤Ëá≥ÈóúÈáçË¶Å„ÄÇÊúÄËøëÁöÑÁ†îÁ©∂Â∑≤Â∞áÂπªË¶∫ËàáÊ®°Âûã‰∏çÁ¢∫ÂÆöÊÄßÈÄ£ÁµêËµ∑‰æÜÔºåÈÄôË°®Á§∫ÂπªË¶∫ÂèØ‰ª•ÈÄèÈÅéÊ∏¨ÈáèÂæûÊ®°ÂûãÊäΩÂèñÁöÑ‰∏ÄÁµÑÊ®£Êú¨Áç≤ÂæóÁöÑÁ≠îÊ°àÂàÜ‰Ωà‰∏≠ÁöÑÈõ¢Êï£Â∫¶‰æÜÂÅµÊ∏¨„ÄÇÈõñÁÑ∂ÂæûÊ®°ÂûãÂÆöÁæ©ÁöÑÁ¨¶ËôüÂàÜ‰Ωà‰∏≠ÊäΩÂèñÊòØÂèñÂæóÊ®£Êú¨ÁöÑËá™ÁÑ∂ÊñπÂºèÔºå‰ΩÜÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄë‰∏ªÂºµÈÄôÂ∞çÊñºÂÅµÊ∏¨ÂπªË¶∫‰æÜË™™‰∏¶ÈùûÊúÄ‰Ω≥ÈÅ∏Êìá„ÄÇÊàëÂÄëÈ°ØÁ§∫ÔºåÈÄèÈÅéËÄÉÈáèË≤ùÊ∞èÊÑèÁæ©‰∏≠ÁöÑÊ®°Âûã‰∏çÁ¢∫ÂÆöÊÄßÔºåÂèØ‰ª•È°ØËëóÊîπÂñÑÂÅµÊ∏¨„ÄÇÁÇ∫Ê≠§ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÈùûÂ∏∏Á∞°ÂñÆ‰∏îÊúâÊïàÁéáÁöÑÊñπÊ≥ïÔºåÂú®ÂèñÊ®£ÈÅéÁ®ã‰∏≠ÊìæÂãïÊ®°ÂûãÂèÉÊï∏ÊàñÁ≠âÊïàÁöÑÈö±ËóèÂñÆÂÖÉÊ¥ªÂåñÁöÑÈÅ©Áï∂Â≠êÈõÜ„ÄÇÊàëÂÄëÂ±ïÁ§∫‰∫ÜÂÆÉÂú®ÂêÑÁ®ÆË≥áÊñôÈõÜÂíåÊ®°ÂûãÊû∂Êßã‰∏≠ÁöÑÊúâÊïàÊÄß„ÄÇ

##### **It's All in The [MASK]: Simple Instruction-Tuning Enables BERT-like Masked Language Models As Generative Classifiers**
2502.03793v1 by Benjamin Clavi√©, Nathan Cooper, Benjamin Warner

While encoder-only models such as BERT and ModernBERT are ubiquitous in
real-world NLP applications, their conventional reliance on task-specific
classification heads can limit their applicability compared to decoder-based
large language models (LLMs). In this work, we introduce
ModernBERT-Large-Instruct, a 0.4B-parameter encoder model that leverages its
masked language modelling (MLM) head for generative classification. Our
approach employs an intentionally simple training loop and inference mechanism
that requires no heavy pre-processing, heavily engineered prompting, or
architectural modifications. ModernBERT-Large-Instruct exhibits strong
zero-shot performance on both classification and knowledge-based tasks,
outperforming similarly sized LLMs on MMLU and achieving 93% of Llama3-1B's
MMLU performance with 60% less parameters. We also demonstrate that, when
fine-tuned, the generative approach using the MLM head matches or even
surpasses traditional classification-head methods across diverse NLU tasks.This
capability emerges specifically in models trained on contemporary, diverse data
mixes, with models trained on lower volume, less-diverse data yielding
considerably weaker performance. Although preliminary, these results
demonstrate the potential of using the original generative masked language
modelling head over traditional task-specific heads for downstream tasks. Our
work suggests that further exploration into this area is warranted,
highlighting many avenues for future improvements.

ÊëòË¶ÅÔºö<paragraph>ÈõñÁÑ∂Âè™ÊúâÁ∑®Á¢ºÂô®ÁöÑÊ®°ÂûãÔºå‰æãÂ¶Ç BERT Âíå ModernBERTÔºåÂú®ÁúüÂØ¶‰∏ñÁïåÁöÑËá™ÁÑ∂Ë™ûË®ÄËôïÁêÜÊáâÁî®‰∏≠ÁÑ°ÊâÄ‰∏çÂú®Ôºå‰ΩÜÂÆÉÂÄëÂÇ≥Áµ±‰∏ä‰æùË≥¥ÊñºÁâπÂÆö‰ªªÂãôÂàÜÈ°ûÊ®ôÈ°åÔºåËàáÂü∫ÊñºËß£Á¢ºÂô®ÁöÑÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Áõ∏ÊØîÔºåÂÆÉÂÄëÁöÑÈÅ©Áî®ÊÄßÂèØËÉΩÊúÉÂèóÂà∞ÈôêÂà∂„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü ModernBERT-Large-InstructÔºå‰∏ÄÂÄã 0.4B ÂèÉÊï∏Á∑®Á¢ºÂô®Ê®°ÂûãÔºåÂÆÉÂà©Áî®ÂÖ∂ÈÅÆÁΩ©Ë™ûË®ÄÂª∫Ê®° (MLM) Ê®ôÈ°åÈÄ≤Ë°åÁîüÊàêÂàÜÈ°û„ÄÇÊàëÂÄëÁöÑÂÅöÊ≥ïÊé°Áî®‰∫Ü‰∏ÄÂÄãÊïÖÊÑèÁ∞°ÂñÆÁöÑË®ìÁ∑¥Ëø¥ÂúàÂíåÊé®ÁêÜÊ©üÂà∂Ôºå‰∏çÈúÄË¶ÅÁπÅÈáçÁöÑÈ†êËôïÁêÜ„ÄÅÂ§ßÈáèË®≠Ë®àÊèêÁ§∫ÊàñÊû∂Êßã‰øÆÊîπ„ÄÇModernBERT-Large-Instruct Âú®ÂàÜÈ°ûÂíåÂü∫ÊñºÁü•Ë≠òÁöÑ‰ªªÂãô‰∏äÈÉΩË°®ÁèæÂá∫Âº∑Â§ßÁöÑÈõ∂Ê¨°Â≠∏ÁøíÊÄßËÉΩÔºåÂú® MMLU ‰∏äÂÑ™ÊñºÈ°û‰ººÂ§ßÂ∞èÁöÑ LLMÔºå‰∏¶‰ª•Â∞ë 60% ÁöÑÂèÉÊï∏ÂØ¶Áèæ‰∫Ü Llama3-1B ÁöÑ 93% MMLU ÊÄßËÉΩ„ÄÇÊàëÂÄëÈÇÑË≠âÊòéÔºåÂú®ÂæÆË™øÊôÇÔºå‰ΩøÁî® MLM Ê®ôÈ°åÁöÑÁîüÊàêÊñπÊ≥ïÂú®‰∏çÂêåÁöÑ NLU ‰ªªÂãô‰∏≠ËàáÂÇ≥Áµ±ÁöÑÂàÜÈ°ûÊ®ôÈ°åÊñπÊ≥ïÁõ∏ÂåπÈÖçÁîöËá≥Ë∂ÖË∂äÂÆÉÂÄë„ÄÇÈÄôÁ®ÆËÉΩÂäõÁâπÂà•Âá∫ÁèæÂú®Ë®ìÁ∑¥ÊñºÁï∂‰ª£„ÄÅÂ§öÊ®£ÂåñÊï∏ÊìöÊ∑∑ÂêàÁöÑÊ®°Âûã‰∏≠ÔºåËÄåË®ìÁ∑¥ÊñºËºÉ‰ΩéÂÆπÈáè„ÄÅËºÉ‰∏çÂ§öÊ®£ÂåñÁöÑÊï∏ÊìöÁöÑÊ®°ÂûãÂâáÁî¢ÁîüÁõ∏Áï∂Âº±ÁöÑÊÄßËÉΩ„ÄÇÂÑòÁÆ°ÊòØÂàùÊ≠•ÁöÑÔºå‰ΩÜÈÄô‰∫õÁµêÊûúË≠âÊòé‰∫ÜÂú®‰∏ãÊ∏∏‰ªªÂãô‰∏≠‰ΩøÁî®ÂéüÂßãÁîüÊàêÈÅÆÁΩ©Ë™ûË®ÄÂª∫Ê®°Ê®ôÈ°åËÄå‰∏çÊòØÂÇ≥Áµ±ÁöÑÁâπÂÆö‰ªªÂãôÊ®ôÈ°åÁöÑÊΩõÂäõ„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂Ë°®ÊòéÔºåÊúâÂøÖË¶ÅÈÄ≤‰∏ÄÊ≠•Êé¢Á¥¢ÈÄôÂÄãÈ†òÂüüÔºå‰∏¶Âº∑Ë™ø‰∫ÜÊú™‰æÜÊîπÈÄ≤ÁöÑË®±Â§öÈÄîÂæë„ÄÇ</paragraph>

##### **ExpProof : Operationalizing Explanations for Confidential Models with ZKPs**
2502.03773v1 by Chhavi Yadav, Evan Monroe Laufer, Dan Boneh, Kamalika Chaudhuri

In principle, explanations are intended as a way to increase trust in machine
learning models and are often obligated by regulations. However, many
circumstances where these are demanded are adversarial in nature, meaning the
involved parties have misaligned interests and are incentivized to manipulate
explanations for their purpose. As a result, explainability methods fail to be
operational in such settings despite the demand \cite{bordt2022post}. In this
paper, we take a step towards operationalizing explanations in adversarial
scenarios with Zero-Knowledge Proofs (ZKPs), a cryptographic primitive.
Specifically we explore ZKP-amenable versions of the popular explainability
algorithm LIME and evaluate their performance on Neural Networks and Random
Forests.

ÊëòË¶ÅÔºöÂéüÂâá‰∏äÔºåËß£ÈáãÊó®Âú®‰ΩúÁÇ∫‰∏ÄÁ®ÆÂ¢ûÂä†Â∞çÊ©üÂô®Â≠∏ÁøíÊ®°Âûã‰ø°‰ªªÁöÑÊñπÂºèÔºå‰∏îÈÄöÂ∏∏ÂèóÂà∞Ê≥ïË¶èÁ¥ÑÊùü„ÄÇÁÑ∂ËÄåÔºåË®±Â§öÈúÄË¶ÅËß£ÈáãÁöÑÁí∞Â¢ÉÊú¨Ë≥™‰∏äÈÉΩÊòØÂ∞çÊäóÊÄßÁöÑÔºåÈÄôÊÑèÂë≥ËëóÁõ∏ÈóúÂêÑÊñπÂà©Áõä‰∏ç‰∏ÄËá¥Ôºå‰∏¶ÊúâË™òÂõ†ÊìçÁ∏±Ëß£Èáã‰ª•Á¨¶ÂêàÂÖ∂ÁõÆÁöÑ„ÄÇÂõ†Ê≠§ÔºåÂÑòÁÆ°ÊúâÈúÄÊ±ÇÔºå‰ΩÜÂèØËß£ÈáãÊÄßÊñπÊ≥ïÂú®ÈÄôÁ®ÆÁí∞Â¢É‰∏≠ÁÑ°Ê≥ïÈÅã‰Ωú \cite{bordt2022post}„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊé°ÂèñÊé™ÊñΩÔºåÂà©Áî®Èõ∂Áü•Ë≠òË≠âÊòé (ZKPs)Ôºà‰∏ÄÁ®ÆÂØÜÁ¢ºÂ≠∏ÂéüË™ûÔºâÂú®Â∞çÊäóÂ†¥ÊôØ‰∏≠ÂØ¶ÁèæËß£ÈáãÈÅã‰Ωú„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÊàëÂÄëÊé¢Ë®é‰∫ÜÂª£Ê≥õ‰ΩøÁî®ÁöÑÂèØËß£ÈáãÊÄßÊºîÁÆóÊ≥ï LIME ÁöÑ ZKP ÂèØÁî®ÁâàÊú¨Ôºå‰∏¶Ë©ï‰º∞ÂÖ∂Âú®Á•ûÁ∂ìÁ∂≤Ë∑ØÂíåÈö®Ê©üÊ£ÆÊûó‰∏äÁöÑÊïàËÉΩ„ÄÇ

##### **A Retrospective Systematic Study on Hierarchical Sparse Query Transformer-assisted Ultrasound Screening for Early Hepatocellular Carcinoma**
2502.03772v1 by Chaoyin She, Ruifang Lu, Danni He, Jiayi Lv, Yadan Lin, Meiqing Cheng, Hui Huang, Lida Chen, Wei Wang, Qinghua Huang

Hepatocellular carcinoma (HCC) ranks as the third leading cause of
cancer-related mortality worldwide, with early detection being crucial for
improving patient survival rates. However, early screening for HCC using
ultrasound suffers from insufficient sensitivity and is highly dependent on the
expertise of radiologists for interpretation. Leveraging the latest
advancements in artificial intelligence (AI) in medical imaging, this study
proposes an innovative Hierarchical Sparse Query Transformer (HSQformer) model
that combines the strengths of Convolutional Neural Networks (CNNs) and Vision
Transformers (ViTs) to enhance the accuracy of HCC diagnosis in ultrasound
screening. The HSQformer leverages sparse latent space representations to
capture hierarchical details at various granularities without the need for
complex adjustments, and adopts a modular, plug-and-play design philosophy,
ensuring the model's versatility and ease of use. The HSQformer's performance
was rigorously tested across three distinct clinical scenarios: single-center,
multi-center, and high-risk patient testing. In each of these settings, it
consistently outperformed existing state-of-the-art models, such as ConvNext
and SwinTransformer. Notably, the HSQformer even matched the diagnostic
capabilities of senior radiologists and comprehensively surpassed those of
junior radiologists. The experimental results from this study strongly
demonstrate the effectiveness and clinical potential of AI-assisted tools in
HCC screening. The full code is available at
https://github.com/Asunatan/HSQformer.

ÊëòË¶ÅÔºöËÇùÁ¥∞ËÉûÁôåÔºàHCCÔºâÊòØÂÖ®ÁêÉÁ¨¨‰∏âÂ§ßÁôåÁóáÁõ∏ÈóúÊ≠ª‰∫°ÂéüÂõ†ÔºåÊó©ÊúüÊ™¢Ê∏¨Â∞çÊñºÊèêÈ´òÊÇ£ËÄÖÂ≠òÊ¥ªÁéáËá≥ÈóúÈáçË¶Å„ÄÇÁÑ∂ËÄåÔºå‰ΩøÁî®Ë∂ÖÈü≥Ê≥¢ÈÄ≤Ë°å HCC Êó©ÊúüÁØ©Ê™¢ÁöÑÈùàÊïèÂ∫¶‰∏çË∂≥Ôºå‰∏îÈ´òÂ∫¶‰æùË≥¥ÊîæÂ∞ÑÁßëÈÜ´Â∏´ÁöÑÂ∞àÊ•≠Áü•Ë≠òÈÄ≤Ë°åÂà§ËÆÄ„ÄÇÊú¨Á†îÁ©∂Âà©Áî®ÈÜ´Â≠∏ÂΩ±ÂÉè‰∏≠‰∫∫Â∑•Êô∫ÊÖßÔºàAIÔºâÁöÑÊúÄÊñ∞ÈÄ≤Â±ïÔºåÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÂâµÊñ∞ÁöÑÂàÜÂ±§Á®ÄÁñèÊü•Ë©¢TransformerÔºàHSQformerÔºâÊ®°ÂûãÔºåÁµêÂêà‰∫ÜÂç∑Á©çÁ•ûÁ∂ìÁ∂≤Ë∑ØÔºàCNNÔºâÂíåË¶ñË¶∫TransformerÔºàViTÔºâÁöÑÂÑ™ÈªûÔºå‰ª•ÊèêÈ´òË∂ÖÈü≥Ê≥¢ÁØ©Ê™¢‰∏≠ HCC Ë®∫Êñ∑ÁöÑÊ∫ñÁ¢∫ÊÄß„ÄÇHSQformer Âà©Áî®Á®ÄÁñèÊΩõÂú®Á©∫ÈñìË°®Á§∫ÔºåÂú®‰∏çÈúÄË¶ÅË§áÈõúË™øÊï¥ÁöÑÊÉÖÊ≥Å‰∏ãÊì∑ÂèñÂêÑÁ®ÆÁ≤íÂ∫¶Â±§Á¥öÁöÑÁ¥∞ÁØÄÔºå‰∏¶Êé°Áî®Ê®°ÁµÑÂåñ„ÄÅÂç≥ÊèíÂç≥Áî®ÁöÑË®≠Ë®àÁêÜÂøµÔºåÁ¢∫‰øùÊ®°ÂûãÁöÑÂ§öÂäüËÉΩÊÄßÂíåÊòìÁî®ÊÄß„ÄÇHSQformer ÁöÑÊïàËÉΩÁ∂ìÈÅé‰∏âÂÄã‰∏çÂêåÁöÑËá®Â∫äÂ†¥ÊôØÁöÑÂö¥Ê†ºÊ∏¨Ë©¶ÔºöÂñÆ‰∏≠ÂøÉ„ÄÅÂ§ö‰∏≠ÂøÉÂíåÈ´òÈ¢®Èö™ÊÇ£ËÄÖÊ∏¨Ë©¶„ÄÇÂú®ÈÄô‰∫õË®≠ÂÆö‰∏≠ÔºåÂÆÉÂßãÁµÇÂÑ™ÊñºÁèæÊúâÁöÑÊúÄÂÖàÈÄ≤Ê®°ÂûãÔºå‰æãÂ¶Ç ConvNext Âíå SwinTransformer„ÄÇÂÄºÂæóÊ≥®ÊÑèÁöÑÊòØÔºåHSQformer ÁîöËá≥ÂåπÈÖç‰∫ÜË≥áÊ∑±ÊîæÂ∞ÑÁßëÈÜ´Â∏´ÁöÑË®∫Êñ∑ËÉΩÂäõÔºå‰∏¶ÂÖ®Èù¢Ë∂ÖË∂ä‰∫ÜÂàùÁ¥öÊîæÂ∞ÑÁßëÈÜ´Â∏´ÁöÑË®∫Êñ∑ËÉΩÂäõ„ÄÇÊú¨Á†îÁ©∂ÁöÑÂØ¶È©óÁµêÊûúÊúâÂäõÂú∞Ë≠âÊòé‰∫Ü AI ËºîÂä©Â∑•ÂÖ∑Âú® HCC ÁØ©Ê™¢‰∏≠ÁöÑÊúâÊïàÊÄßÂíåËá®Â∫äÊΩõÂäõ„ÄÇÂÆåÊï¥Á®ãÂºèÁ¢ºÂèØÂú® https://github.com/Asunatan/HSQformer ÂèñÂæó„ÄÇ

##### **Adaptive Semantic Prompt Caching with VectorQ**
2502.03771v1 by Luis Gaspar Schroeder, Shu Liu, Alejandro Cuadron, Mark Zhao, Stephan Krusche, Alfons Kemper, Matei Zaharia, Joseph E. Gonzalez

Semantic prompt caches reduce the latency and cost of large language model
(LLM) inference by reusing cached LLM-generated responses for semantically
similar prompts. Vector similarity metrics assign a numerical score to quantify
the similarity between an embedded prompt and its nearest neighbor in the
cache. Existing systems rely on a static threshold to classify whether the
similarity score is sufficiently high to result in a cache hit. We show that
this one-size-fits-all threshold is insufficient across different prompts. We
propose VectorQ, a framework to learn embedding-specific threshold regions that
adapt to the complexity and uncertainty of an embedding. Through evaluations on
a combination of four diverse datasets, we show that VectorQ consistently
outperforms state-of-the-art systems across all static thresholds, achieving up
to 12x increases in cache hit rate and error rate reductions up to 92%.

ÊëòË¶ÅÔºöË™ûÊÑèÊèêÁ§∫Âø´ÂèñÈÄèÈÅéÈáçË§á‰ΩøÁî®Âø´ÂèñÁöÑ LLM ÁîüÊàêÁöÑÂõûÊáâ‰æÜÈôç‰ΩéÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Êé®Ë´ñÁöÑÂª∂ÈÅ≤ÂíåÊàêÊú¨Ôºå‰ª•ÂèñÂæóË™ûÊÑè‰∏äÁõ∏‰ººÁöÑÊèêÁ§∫„ÄÇÂêëÈáèÁõ∏‰ººÂ∫¶ÈáèÊï∏ÊúÉÊåáÊ¥æ‰∏ÄÂÄãÊï∏ÂÄºÂàÜÊï∏Ôºå‰ª•ÈáèÂåñÂµåÂÖ•ÂºèÊèêÁ§∫ËàáÂø´Âèñ‰∏≠ÊúÄËøëÈÑ∞Â±Ö‰πãÈñìÁöÑÁõ∏‰ººÂ∫¶„ÄÇÁèæÊúâÁöÑÁ≥ªÁµ±‰æùË≥¥ÈùúÊÖãÈñæÂÄº‰æÜÂàÜÈ°ûÁõ∏‰ººÂ∫¶ÂàÜÊï∏ÊòØÂê¶Ë∂≥Â§†È´ò‰ª•Áî¢ÁîüÂø´ÂèñÂëΩ‰∏≠„ÄÇÊàëÂÄëÈ°ØÁ§∫ÈÄôÂÄã‰∏ÄÈ´îÈÅ©Áî®ÁöÑÈñæÂÄº‰∏çË∂≥‰ª•Ê∂µËìã‰∏çÂêåÁöÑÊèêÁ§∫„ÄÇÊàëÂÄëÊèêÂá∫ VectorQÔºå‰∏ÄÂÄãÊû∂Êßã‰æÜÂ≠∏ÁøíÈÅ©ÊáâÂµåÂÖ•ÂºèË§áÈõúÊÄßÂíå‰∏çÁ¢∫ÂÆöÊÄßÁöÑÂµåÂÖ•ÂºèÁâπÂÆöÈñæÂÄºÂçÄÂüü„ÄÇÈÄèÈÅéË©ï‰º∞ÂõõÂÄã‰∏çÂêåË≥áÊñôÈõÜÁöÑÁµÑÂêàÔºåÊàëÂÄëÈ°ØÁ§∫ VectorQ Âú®ÊâÄÊúâÈùúÊÖãÈñæÂÄº‰∏äÊåÅÁ∫åÂÑ™ÊñºÊúÄÂÖàÈÄ≤ÁöÑÁ≥ªÁµ±ÔºåÂø´ÂèñÂëΩ‰∏≠ÁéáÂ¢ûÂä†Â§öÈÅî 12 ÂÄçÔºåÈåØË™§ÁéáÈôç‰ΩéÂ§öÈÅî 92%„ÄÇ

##### **Hierarchical Contextual Manifold Alignment for Structuring Latent Representations in Large Language Models**
2502.03766v1 by Meiquan Dong, Haoran Liu, Yan Huang, Zixuan Feng, Jianhong Tang, Ruoxi Wang

The organization of latent token representations plays a crucial role in
determining the stability, generalization, and contextual consistency of
language models, yet conventional approaches to embedding refinement often rely
on parameter modifications that introduce additional computational overhead. A
hierarchical alignment method was introduced to restructure token embeddings
without altering core model weights, ensuring that representational
distributions maintained coherence across different linguistic contexts.
Experimental evaluations demonstrated improvements in rare token retrieval,
adversarial robustness, and long-range dependency tracking, highlighting the
advantages of hierarchical structuring in mitigating inconsistencies in latent
space organization. The comparative analysis against conventional fine-tuning
and embedding perturbation methods revealed that hierarchical restructuring
maintained computational efficiency while achieving measurable gains in
representation quality. Structural refinements introduced through the alignment
process resulted in improved contextual stability across varied linguistic
tasks, reducing inconsistencies in token proximity relationships and enhancing
interpretability in language generation. A detailed computational assessment
confirmed that the realignment process introduced minimal inference overhead,
ensuring that representational improvements did not compromise model
efficiency. The findings reinforced the broader significance of structured
representation learning, illustrating that hierarchical embedding modifications
could serve as an effective strategy for refining latent space distributions
while preserving pre-learned semantic associations.

ÊëòË¶ÅÔºöÊΩõÂú®Á¨¶ËôüË°®ÂæµÁöÑÁµÑÁπîÂú®Ê±∫ÂÆöË™ûË®ÄÊ®°ÂûãÁöÑÁ©©ÂÆöÊÄß„ÄÅÊ¶ÇÊã¨ÊÄßËàáËÑàÁµ°‰∏ÄËá¥ÊÄß‰∏äÊâÆÊºîËëóËá≥ÈóúÈáçË¶ÅÁöÑËßíËâ≤ÔºåÁÑ∂ËÄåÔºåÂ∞çÂµåÂÖ•ÂºèÁ¥∞Á∑ªÂåñÁöÑÂÇ≥Áµ±ÊñπÊ≥ïÈÄöÂ∏∏‰æùË≥¥ÊñºÂºïÂÖ•È°çÂ§ñÈÅãÁÆóË≤†ÊìîÁöÑÂèÉÊï∏‰øÆÊîπ„ÄÇÂºïÈÄ≤‰∫Ü‰∏ÄÁ®ÆÈöéÂ±§Â∞çÈΩäÊñπÊ≥ï‰æÜÈáçÊñ∞Âª∫ÊßãÁ¨¶ËôüÂµåÂÖ•ÔºåËÄå‰∏çÊúÉÊîπËÆäÊ†∏ÂøÉÊ®°ÂûãÊ¨äÈáçÔºåÁ¢∫‰øùË°®ÂæµÂàÜ‰ΩàÂú®‰∏çÂêåÁöÑË™ûË®ÄËÑàÁµ°‰∏≠‰øùÊåÅ‰∏ÄËá¥ÊÄß„ÄÇÂØ¶È©óË©ï‰º∞È°ØÁ§∫ÔºåÂú®ÁΩïË¶ãÁ¨¶ËôüÊ™¢Á¥¢„ÄÅÂ∞çÊäóÈ≠ØÊ£íÊÄßËàáÈï∑Ë∑ùÈõ¢‰æùË≥¥ËøΩËπ§ÊñπÈù¢ÈÉΩÊúâÊâÄÊîπÂñÑÔºåÁ™ÅÈ°Ø‰∫ÜÈöéÂ±§ÁµêÊßãÂú®Ê∏õËºïÊΩõÂú®Á©∫ÈñìÁµÑÁπî‰∏ç‰∏ÄËá¥ÊÄßÊñπÈù¢ÁöÑÂÑ™Âã¢„ÄÇÈáùÂ∞çÂÇ≥Áµ±ÂæÆË™øËàáÂµåÂÖ•ÂºèÊìæÂãïÊñπÊ≥ïÁöÑÊØîËºÉÂàÜÊûêÈ°ØÁ§∫ÔºåÈöéÂ±§ÈáçÁµÑÁ∂≠ÊåÅ‰∫ÜÈÅãÁÆóÊïàÁéáÔºåÂêåÊôÇÂú®Ë°®ÂæµÂìÅË≥™ÊñπÈù¢Áç≤ÂæóÂèØË°°ÈáèÁöÑÊèêÂçá„ÄÇÈÄèÈÅéÂ∞çÈΩäÁ®ãÂ∫èÂºïÂÖ•ÁöÑÁµêÊßãÁ¥∞Á∑ªÂåñÔºåÊîπÂñÑ‰∫ÜÂêÑÁ®ÆË™ûË®Ä‰ªªÂãôÁöÑËÑàÁµ°Á©©ÂÆöÊÄßÔºåÊ∏õÂ∞ë‰∫ÜÁ¨¶ËôüÊé•ËøëÈóú‰øÇÁöÑ‰∏ç‰∏ÄËá¥ÊÄßÔºå‰∏¶Â¢ûÂº∑‰∫ÜË™ûË®ÄÁîüÊàêÁöÑË©ÆÈáãÊÄß„ÄÇË©≥Á¥∞ÁöÑÈÅãÁÆóË©ï‰º∞Ë≠âÂØ¶ÔºåÈáçÊñ∞Â∞çÈΩäÁ®ãÂ∫èÂºïÂÖ•‰∫ÜÊúÄÂ∞èÁöÑÊé®Ë´ñË≤†ÊìîÔºåÁ¢∫‰øùË°®ÂæµÊîπÂñÑ‰∏çÊúÉÊêçÂÆ≥Ê®°ÂûãÊïàÁéá„ÄÇÈÄô‰∫õÁôºÁèæÂº∑Âåñ‰∫ÜÁµêÊßãÂåñË°®ÂæµÂ≠∏ÁøíÁöÑÊõ¥Âª£Ê≥õÊÑèÁæ©ÔºåË™™ÊòéÈöéÂ±§ÂºèÂµåÂÖ•‰øÆÊîπÂèØ‰ª•‰ΩúÁÇ∫Á¥∞Á∑ªÂåñÊΩõÂú®Á©∫ÈñìÂàÜ‰ΩàÁöÑÊúâÊïàÁ≠ñÁï•ÔºåÂêåÊôÇ‰øùÁïôÈ†êÂÖàÂ≠∏ÁøíÁöÑË™ûÁæ©ÈóúËÅØ„ÄÇ

##### **Principal Curvatures Estimation with Applications to Single Cell Data**
2502.03750v1 by Yanlei Zhang, Lydia Mezrag, Xingzhi Sun, Charles Xu, Kincaid Macdonald, Dhananjay Bhaskar, Smita Krishnaswamy, Guy Wolf, Bastian Rieck

The rapidly growing field of single-cell transcriptomic sequencing (scRNAseq)
presents challenges for data analysis due to its massive datasets. A common
method in manifold learning consists in hypothesizing that datasets lie on a
lower dimensional manifold. This allows to study the geometry of point clouds
by extracting meaningful descriptors like curvature. In this work, we will
present Adaptive Local PCA (AdaL-PCA), a data-driven method for accurately
estimating various notions of intrinsic curvature on data manifolds, in
particular principal curvatures for surfaces. The model relies on local PCA to
estimate the tangent spaces. The evaluation of AdaL-PCA on sampled surfaces
shows state-of-the-art results. Combined with a PHATE embedding, the model
applied to single-cell RNA sequencing data allows us to identify key variations
in the cellular differentiation.

ÊëòË¶ÅÔºöÂñÆÁ¥∞ËÉûËΩâÈåÑÁµÑÂÆöÂ∫è (scRNAseq) È†òÂüüÂø´ÈÄüÊàêÈï∑ÔºåÁî±ÊñºÂÖ∂Ë≥áÊñôÈõÜÈæêÂ§ßÔºåÁÇ∫Ë≥áÊñôÂàÜÊûêÂ∏∂‰æÜÊåëÊà∞„ÄÇÊµÅÂΩ¢Â≠∏Áøí‰∏≠‰∏ÄÂÄãÂ∏∏Ë¶ãÁöÑÊñπÊ≥ïÂú®ÊñºÂÅáË®≠Ë≥áÊñôÈõÜ‰ΩçÊñºËºÉ‰ΩéÁ∂≠Â∫¶ÁöÑÊµÅÂΩ¢‰∏ä„ÄÇÈÄôÂÖÅË®±ÈÄèÈÅéÊì∑ÂèñÊúâÊÑèÁæ©ÁöÑÊèèËø∞Á¨¶Ôºà‰æãÂ¶ÇÊõ≤ÁéáÔºâ‰æÜÁ†îÁ©∂ÈªûÈõ≤ÁöÑÂπæ‰ΩïÂΩ¢ÁãÄ„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÂ∞á‰ªãÁ¥πËá™ÈÅ©ÊáâÂ±ÄÈÉ® PCA (AdaL-PCA)Ôºå‰∏ÄÁ®ÆË≥áÊñôÈ©ÖÂãïÁöÑÊñπÊ≥ïÔºåÁî®ÊñºÊ∫ñÁ¢∫‰º∞Ë®àË≥áÊñôÊµÅÂΩ¢‰∏äÂÖßÂú®Êõ≤ÁéáÁöÑ‰∏çÂêåÊ¶ÇÂøµÔºåÁâπÂà•ÊòØÊõ≤Èù¢ÁöÑ‰∏ªÊõ≤Áéá„ÄÇÊ≠§Ê®°Âûã‰æùË≥¥ÊñºÂ±ÄÈÉ® PCA ‰æÜ‰º∞Ë®àÂàáÁ©∫Èñì„ÄÇAdaL-PCA Âú®ÂèñÊ®£Êõ≤Èù¢‰∏äÁöÑË©ï‰º∞È°ØÁ§∫ÊúÄÂÖàÈÄ≤ÁöÑÁµêÊûú„ÄÇËàá PHATE ÂµåÂÖ•Áõ∏ÁµêÂêàÔºåÊáâÁî®ÊñºÂñÆÁ¥∞ËÉû RNA ÂÆöÂ∫èË≥áÊñôÁöÑÊ®°Âûã‰ΩøÊàëÂÄëËÉΩÂ§†Ë≠òÂà•Á¥∞ËÉûÂàÜÂåñ‰∏≠ÁöÑÈóúÈçµËÆäÂåñ„ÄÇ

##### **Rethinking the Residual Distribution of Locate-then-Editing Methods in Model Editing**
2502.03748v1 by Xiaopeng Li, Shanwen Wang, Shasha Li, Shezheng Song, Bin Ji, Jun Ma, Jie Yu

Model editing is a powerful technique for updating the knowledge of Large
Language Models (LLMs). Locate-then-edit methods are a popular class of
approaches that first identify the critical layers storing knowledge, then
compute the residual of the last critical layer based on the edited knowledge,
and finally perform multi-layer updates using a least-squares solution by
evenly distributing the residual from the first critical layer to the last.
Although these methods achieve promising results, they have been shown to
degrade the original knowledge of LLMs. We argue that residual distribution
leads to this issue. To explore this, we conduct a comprehensive analysis of
residual distribution in locate-then-edit methods from both empirical and
theoretical perspectives, revealing that residual distribution introduces
editing errors, leading to inaccurate edits. To address this issue, we propose
the Boundary Layer UpdatE (BLUE) strategy to enhance locate-then-edit methods.
Sequential batch editing experiments on three LLMs and two datasets demonstrate
that BLUE not only delivers an average performance improvement of 35.59\%,
significantly advancing the state of the art in model editing, but also
enhances the preservation of LLMs' general capabilities. Our code is available
at https://github.com/xpq-tech/BLUE.

ÊëòË¶ÅÔºöÊ®°ÂûãÁ∑®ËºØÊòØ‰∏ÄÁ®ÆÊõ¥Êñ∞Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Áü•Ë≠òÁöÑÂº∑Â§ßÊäÄË°ì„ÄÇÂÆö‰ΩçÂÜçÁ∑®ËºØÊñπÊ≥ïÊòØ‰∏ÄÈ°ûÊµÅË°åÁöÑÊñπÊ≥ïÔºåÂÆÉÊúÉÂÖàÊâæÂá∫ÂÑ≤Â≠òÁü•Ë≠òÁöÑÈóúÈçµÂ±§ÔºåÁÑ∂ÂæåÊ†πÊìöÁ∑®ËºØÈÅéÁöÑÁü•Ë≠òË®àÁÆóÊúÄÂæå‰∏ÄÂÄãÈóúÈçµÂ±§ÁöÑÊÆòÂ∑ÆÔºåÊúÄÂæå‰ΩøÁî®ÊúÄÂ∞èÂπ≥ÊñπËß£Ê≥ïÂü∑Ë°åÂ§öÂ±§Êõ¥Êñ∞ÔºåÂ∞áÊÆòÂ∑ÆÂæûÁ¨¨‰∏ÄÂÄãÈóúÈçµÂ±§ÂùáÂãªÂàÜÈÖçÂà∞ÊúÄÂæå‰∏ÄÂÄãÈóúÈçµÂ±§„ÄÇÂÑòÁÆ°ÈÄô‰∫õÊñπÊ≥ïÂèñÂæó‰∫ÜÊúâÂ∏åÊúõÁöÑÁµêÊûúÔºå‰ΩÜÂÆÉÂÄëÂ∑≤Ë¢´Ë≠âÊòéÊúÉÈôç‰Ωé LLM ÁöÑÂéüÂßãÁü•Ë≠ò„ÄÇÊàëÂÄëË™çÁÇ∫ÊÆòÂ∑ÆÂàÜÈÖçÊúÉÂ∞éËá¥ÈÄôÂÄãÂïèÈ°å„ÄÇÁÇ∫‰∫ÜÊé¢Ë®éÈÄô‰∏ÄÈªûÔºåÊàëÂÄëÂæûÁ∂ìÈ©óÂíåÁêÜË´ñÁöÑËßíÂ∫¶Â∞çÂÆö‰ΩçÂÜçÁ∑®ËºØÊñπÊ≥ï‰∏≠ÁöÑÊÆòÂ∑ÆÂàÜÈÖçÈÄ≤Ë°å‰∫ÜÂÖ®Èù¢ÁöÑÂàÜÊûêÔºåÊè≠Á§∫ÊÆòÂ∑ÆÂàÜÈÖçÊúÉÂºïÂÖ•Á∑®ËºØÈåØË™§ÔºåÂ∞éËá¥Á∑®ËºØ‰∏çÊ∫ñÁ¢∫„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåÊàëÂÄëÊèêÂá∫‰∫ÜÈÇäÁïåÂ±§Êõ¥Êñ∞ (BLUE) Á≠ñÁï•‰æÜÂ¢ûÂº∑ÂÆö‰ΩçÂÜçÁ∑®ËºØÊñπÊ≥ï„ÄÇÂú®‰∏âÂÄã LLM ÂíåÂÖ©ÂÄãË≥áÊñôÈõÜ‰∏äÈÄ≤Ë°åÁöÑÈ†ÜÂ∫èÊâπÊ¨°Á∑®ËºØÂØ¶È©óË≠âÊòéÔºåBLUE ‰∏çÂÉÖÊèê‰æõ‰∫Ü 35.59% ÁöÑÂπ≥ÂùáÊïàËÉΩÊèêÂçáÔºåÈ°ØËëóÊèêÂçá‰∫ÜÊ®°ÂûãÁ∑®ËºØÁöÑÊúÄÊñ∞ÊäÄË°ìÔºåÈÇÑÂ¢ûÂº∑‰∫Ü LLM ‰∏ÄËà¨ÂäüËÉΩÁöÑ‰øùÁïô„ÄÇÊàëÂÄëÁöÑÁ®ãÂºèÁ¢ºÂèØÂú® https://github.com/xpq-tech/BLUE ÂèñÂæó„ÄÇ

##### **Action-Free Reasoning for Policy Generalization**
2502.03729v1 by Jaden Clark, Suvir Mirchandani, Dorsa Sadigh, Suneel Belkhale

End-to-end imitation learning offers a promising approach for training robot
policies. However, generalizing to new settings remains a significant
challenge. Although large-scale robot demonstration datasets have shown
potential for inducing generalization, they are resource-intensive to scale. In
contrast, human video data is abundant and diverse, presenting an attractive
alternative. Yet, these human-video datasets lack action labels, complicating
their use in imitation learning. Existing methods attempt to extract grounded
action representations (e.g., hand poses), but resulting policies struggle to
bridge the embodiment gap between human and robot actions. We propose an
alternative approach: leveraging language-based reasoning from human
videos-essential for guiding robot actions-to train generalizable robot
policies. Building on recent advances in reasoning-based policy architectures,
we introduce Reasoning through Action-free Data (RAD). RAD learns from both
robot demonstration data (with reasoning and action labels) and action-free
human video data (with only reasoning labels). The robot data teaches the model
to map reasoning to low-level actions, while the action-free data enhances
reasoning capabilities. Additionally, we will release a new dataset of 3,377
human-hand demonstrations with reasoning annotations compatible with the Bridge
V2 benchmark and aimed at facilitating future research on reasoning-driven
robot learning. Our experiments show that RAD enables effective transfer across
the embodiment gap, allowing robots to perform tasks seen only in action-free
data. Furthermore, scaling up action-free reasoning data significantly improves
policy performance and generalization to novel tasks. These results highlight
the promise of reasoning-driven learning from action-free datasets for
advancing generalizable robot control. Project page:
https://rad-generalization.github.io

ÊëòË¶ÅÔºöÁ´ØÂ∞çÁ´ØÊ®°‰ªøÂ≠∏ÁøíÊèê‰æõ‰∫Ü‰∏ÄÁ®ÆË®ìÁ∑¥Ê©üÂô®‰∫∫ÊîøÁ≠ñÁöÑÊúâÂâçÊôØÁöÑÊñπÊ≥ï„ÄÇÁÑ∂ËÄåÔºåÊé®Âª£Âà∞Êñ∞ÁöÑË®≠ÂÆö‰ªçÁÑ∂ÊòØ‰∏ÄÂÄãÈáçÂ§ßÁöÑÊåëÊà∞„ÄÇÂÑòÁÆ°Â§ßË¶èÊ®°Ê©üÂô®‰∫∫Á§∫ÁØÑÊï∏ÊìöÈõÜÂ∑≤È°ØÁ§∫Âá∫Ë™òÂ∞éÊ¶ÇÊã¨ÁöÑÊΩõÂäõÔºå‰ΩÜÂÆÉÂÄëÂú®Êì¥Â±ïÊñπÈù¢ÈúÄË¶ÅÂ§ßÈáèË≥áÊ∫ê„ÄÇÁõ∏ÊØî‰πã‰∏ãÔºå‰∫∫È°ûË¶ñÈ†ªÊï∏ÊìöË±êÂØå‰∏îÂ§öÊ®£ÔºåÊèê‰æõ‰∫Ü‰∏ÄÂÄãÊúâÂê∏ÂºïÂäõÁöÑÊõø‰ª£ÊñπÊ°à„ÄÇÁÑ∂ËÄåÔºåÈÄô‰∫õ‰∫∫È°ûË¶ñÈ†ªÊï∏ÊìöÈõÜÁº∫‰πèÂãï‰ΩúÊ®ôÁ±§Ôºå‰ΩøÂÆÉÂÄëÂú®Ê®°‰ªøÂ≠∏Áøí‰∏≠ÁöÑ‰ΩøÁî®ËÆäÂæóË§áÈõú„ÄÇÁèæÊúâÊñπÊ≥ïÂòóË©¶ÊèêÂèñÊé•Âú∞ÁöÑÂãï‰ΩúË°®Á§∫Ôºà‰æãÂ¶ÇÔºåÊâãÈÉ®ÂßøÂã¢ÔºâÔºå‰ΩÜÁî±Ê≠§Áî¢ÁîüÁöÑÁ≠ñÁï•Èõ£‰ª•ÂΩåÂêà‰∫∫È°ûÂíåÊ©üÂô®‰∫∫Âãï‰Ωú‰πãÈñìÁöÑÂÖ∑È´îÂåñÂ∑ÆË∑ù„ÄÇÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÊõø‰ª£ÊñπÊ≥ïÔºöÂà©Áî®‰∫∫È°ûË¶ñÈ†ª‰∏≠Âü∫ÊñºË™ûË®ÄÁöÑÊé®ÁêÜ‚Äî‚ÄîÊåáÂ∞éÊ©üÂô®‰∫∫Âãï‰ΩúÁöÑÂøÖË¶ÅÊ¢ù‰ª∂‚Äî‚Äî‰æÜË®ìÁ∑¥ÂèØÊ¶ÇÊã¨ÁöÑÊ©üÂô®‰∫∫Á≠ñÁï•„ÄÇÂú®Âü∫ÊñºÊé®ÁêÜÁöÑÁ≠ñÁï•Êû∂ÊßãÁöÑÊúÄÊñ∞ÈÄ≤Â±ïÁöÑÂü∫Á§é‰∏äÔºåÊàëÂÄëÂºïÂÖ•‰∫ÜÁÑ°Âãï‰ΩúÊï∏ÊìöÊé®ÁêÜ (RAD)„ÄÇRAD ÂæûÊ©üÂô®‰∫∫Á§∫ÁØÑÊï∏ÊìöÔºàÂ∏∂ÊúâÊé®ÁêÜÂíåÂãï‰ΩúÊ®ôÁ±§ÔºâÂíåÁÑ°Âãï‰Ωú‰∫∫È°ûË¶ñÈ†ªÊï∏ÊìöÔºàÂÉÖÂ∏∂ÊúâÊé®ÁêÜÊ®ôÁ±§Ôºâ‰∏≠Â≠∏Áøí„ÄÇÊ©üÂô®‰∫∫Êï∏ÊìöÊïôÂ∞éÊ®°ÂûãÂ∞áÊé®ÁêÜÊò†Â∞ÑÂà∞‰ΩéÁ¥öÂãï‰ΩúÔºåËÄåÁÑ°Âãï‰ΩúÊï∏ÊìöÂ¢ûÂº∑‰∫ÜÊé®ÁêÜËÉΩÂäõ„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÂ∞áÁôºÂ∏É‰∏ÄÂÄãÊñ∞ÁöÑÊï∏ÊìöÈõÜÔºåÂÖ∂‰∏≠ÂåÖÂê´ 3,377 ÂÄãÂ∏∂ÊúâÊé®ÁêÜË®ªÈáãÁöÑ‰∫∫ÊâãÁ§∫ÁØÑÔºåÈÄô‰∫õË®ªÈáãËàá Bridge V2 Âü∫Ê∫ñÂÖºÂÆπÔºåÊó®Âú®‰øÉÈÄ≤Êú™‰æÜÂ∞çÂü∫ÊñºÊé®ÁêÜÁöÑÊ©üÂô®‰∫∫Â≠∏ÁøíÁöÑÁ†îÁ©∂„ÄÇÊàëÂÄëÁöÑÂØ¶È©óË°®ÊòéÔºåRAD ËÉΩÂ§†ÊúâÊïàÂú∞Ë∑®Ë∂äÂÖ∑È´îÂåñÂ∑ÆË∑ùÔºåËÆìÊ©üÂô®‰∫∫ËÉΩÂ§†Âü∑Ë°åÂÉÖÂú®ÁÑ°Âãï‰ΩúÊï∏Êìö‰∏≠ÁúãÂà∞ÁöÑ‰ªªÂãô„ÄÇÊ≠§Â§ñÔºåÊì¥Â±ïÁÑ°Âãï‰ΩúÊé®ÁêÜÊï∏ÊìöÈ°ØËëóÊèêÈ´ò‰∫ÜÁ≠ñÁï•ÊÄßËÉΩÂíåÂ∞çÊñ∞‰ªªÂãôÁöÑÊ¶ÇÊã¨„ÄÇÈÄô‰∫õÁµêÊûúÁ™ÅÂá∫‰∫ÜÁÑ°Âãï‰ΩúÊï∏ÊìöÈõÜÁöÑÂü∫ÊñºÊé®ÁêÜÁöÑÂ≠∏ÁøíÂú®Êé®ÈÄ≤ÂèØÊ¶ÇÊã¨Ê©üÂô®‰∫∫ÊéßÂà∂ÊñπÈù¢ÁöÑÂâçÊôØ„ÄÇÈ†ÖÁõÆÈ†ÅÈù¢Ôºöhttps://rad-generalization.github.io

##### **MD-BERT: Action Recognition in Dark Videos via Dynamic Multi-Stream Fusion and Temporal Modeling**
2502.03724v1 by Sharana Dharshikgan Suresh Dass, Hrishav Bakul Barua, Ganesh Krishnasamy, Raveendran Paramesran, Raphael C. -W. Phan

Action recognition in dark, low-light (under-exposed) or noisy videos is a
challenging task due to visibility degradation, which can hinder critical
spatiotemporal details. This paper proposes MD-BERT, a novel multi-stream
approach that integrates complementary pre-processing techniques such as gamma
correction and histogram equalization alongside raw dark frames to address
these challenges. We introduce the Dynamic Feature Fusion (DFF) module,
extending existing attentional fusion methods to a three-stream setting,
thereby capturing fine-grained and global contextual information across
different brightness and contrast enhancements. The fused spatiotemporal
features are then processed by a BERT-based temporal model, which leverages its
bidirectional self-attention to effectively capture long-range dependencies and
contextual relationships across frames. Extensive experiments on the ARID V1.0
and ARID V1.5 dark video datasets show that MD-BERT outperforms existing
methods, establishing a new state-of-the-art performance. Ablation studies
further highlight the individual contributions of each input stream and the
effectiveness of the proposed DFF and BERT modules. The official website of
this work is available at: https://github.com/HrishavBakulBarua/DarkBERT

ÊëòË¶ÅÔºöÂú®ÈªëÊöó„ÄÅ‰ΩéÂÖâÔºàÊõùÂÖâ‰∏çË∂≥ÔºâÊàñÊúâÈõúË®äÁöÑÂΩ±Áâá‰∏≠ÈÄ≤Ë°åÂãï‰ΩúËæ®Ë≠òÊòØ‰∏ÄÈ†ÖÂÖ∑ÊúâÊåëÊà∞ÊÄßÁöÑ‰ªªÂãôÔºåÂõ†ÁÇ∫ËÉΩË¶ãÂ∫¶Èôç‰ΩéÔºåÂèØËÉΩÊúÉÈòªÁ§ôÈóúÈçµÁöÑÊôÇÁ©∫Á¥∞ÁØÄ„ÄÇÈÄôÁØáË´ñÊñáÊèêÂá∫ MD-BERTÔºåÈÄôÊòØ‰∏ÄÁ®ÆÊñ∞Á©éÁöÑÂ§ö‰∏≤ÊµÅÊñπÊ≥ïÔºåÂÆÉÊï¥Âêà‰∫ÜË£úÂÖÖÊÄßÁöÑÂâçËôïÁêÜÊäÄË°ìÔºå‰æãÂ¶Ç‰ºΩÁë™Ê†°Ê≠£ÂíåÁõ¥ÊñπÂúñÁ≠âÂåñÔºå‰ª•ÂèäÂéüÂßãÁöÑÈªëÊöóÂΩ±ÂÉèÔºå‰ª•ÊáâÂ∞çÈÄô‰∫õÊåëÊà∞„ÄÇÊàëÂÄëÂºïÂÖ•‰∫ÜÂãïÊÖãÁâπÂæµËûçÂêà (DFF) Ê®°ÁµÑÔºåÂ∞áÁèæÊúâÁöÑÊ≥®ÊÑèÂäõËûçÂêàÊñπÊ≥ïÊì¥ÂÖÖÂ•ó‰ª∂Âà∞‰∏â‰∏≤ÊµÅË®≠ÂÆöÔºåÂæûËÄåË∑®Ë∂ä‰∏çÂêåÁöÑ‰∫ÆÂ∫¶ÂíåÂ∞çÊØîÂ∫¶Â¢ûÂº∑‰æÜÊçïÊçâÁ¥∞Á≤íÂ∫¶ÂíåÂÖ®ÂüüÊÄßÁöÑËÑàÁµ°Ë≥áË®ä„ÄÇÊé•ËëóÔºåËûçÂêàÁöÑÊôÇÁ©∫ÁâπÂæµÊúÉÁî±Âü∫Êñº BERT ÁöÑÊôÇÂ∫èÊ®°ÂûãËôïÁêÜÔºåÂÆÉÂà©Áî®ÂÖ∂ÈõôÂêëËá™ÊàëÊ≥®ÊÑèÂäõ‰æÜÊúâÊïàÊçïÊçâÈï∑Ë∑ùÈõ¢ÁöÑ‰æùÂ≠òÈóú‰øÇÂíåÂΩ±ÂÉè‰πãÈñìÁöÑËÑàÁµ°Èóú‰øÇ„ÄÇÂú® ARID V1.0 Âíå ARID V1.5 ÈªëÊöóÂΩ±ÁâáË≥áÊñôÈõÜ‰∏äÈÄ≤Ë°åÁöÑÂª£Ê≥õÂØ¶È©óÈ°ØÁ§∫ÔºåMD-BERT ÂÑ™ÊñºÁèæÊúâÁöÑÊñπÊ≥ïÔºåÊ®πÁ´ã‰∫ÜÊñ∞ÁöÑÊúÄÂÖàÈÄ≤ÊïàËÉΩ„ÄÇÊ∂àËûçÁ†îÁ©∂ÈÄ≤‰∏ÄÊ≠•Á™ÅÈ°Ø‰∫ÜÊØèÂÄãËº∏ÂÖ•‰∏≤ÊµÅÁöÑÂÄãÂà•Ë≤¢ÁçªÔºå‰ª•ÂèäÊâÄÊèêÂá∫ÁöÑ DFF Âíå BERT Ê®°ÁµÑÁöÑÊïàËÉΩ„ÄÇÈÄôÈ†ÖÂ∑•‰ΩúÁöÑÂÆòÊñπÁ∂≤Á´ôÂèØÂú®‰ª•‰∏ãÁ∂≤ÂùÄÂèñÂæóÔºöhttps://github.com/HrishavBakulBarua/DarkBERT

##### **Efficiently Generating Expressive Quadruped Behaviors via Language-Guided Preference Learning**
2502.03717v1 by Jaden Clark, Joey Hejna, Dorsa Sadigh

Expressive robotic behavior is essential for the widespread acceptance of
robots in social environments. Recent advancements in learned legged locomotion
controllers have enabled more dynamic and versatile robot behaviors. However,
determining the optimal behavior for interactions with different users across
varied scenarios remains a challenge. Current methods either rely on natural
language input, which is efficient but low-resolution, or learn from human
preferences, which, although high-resolution, is sample inefficient. This paper
introduces a novel approach that leverages priors generated by pre-trained LLMs
alongside the precision of preference learning. Our method, termed
Language-Guided Preference Learning (LGPL), uses LLMs to generate initial
behavior samples, which are then refined through preference-based feedback to
learn behaviors that closely align with human expectations. Our core insight is
that LLMs can guide the sampling process for preference learning, leading to a
substantial improvement in sample efficiency. We demonstrate that LGPL can
quickly learn accurate and expressive behaviors with as few as four queries,
outperforming both purely language-parameterized models and traditional
preference learning approaches. Website with videos:
https://lgpl-gaits.github.io/

ÊëòË¶ÅÔºöË°®ÈÅîÊÄßÁöÑÊ©üÂô®‰∫∫Ë°åÁÇ∫Â∞çÊñºÊ©üÂô®‰∫∫Âú®Á§æ‰∫§Áí∞Â¢É‰∏≠ÁöÑÂª£Ê≥õÊé•ÂèóËá≥ÈóúÈáçË¶Å„ÄÇÊúÄËøëÂú®Â≠∏ÁøíÁöÑËÖøÈÉ®ÈÅãÂãïÊéßÂà∂Âô®ÁöÑÈÄ≤Ê≠•Â∑≤Á∂ìÂØ¶Áèæ‰∫ÜÊõ¥ÂãïÊÖãÂíåÂ§öÊ®£ÂåñÁöÑÊ©üÂô®‰∫∫Ë°åÁÇ∫„ÄÇÁÑ∂ËÄåÔºåÁ¢∫ÂÆöËàá‰∏çÂêå‰ΩøÁî®ËÄÖÂú®‰∏çÂêåÂ†¥ÊôØ‰∏≠‰∫íÂãïÁöÑÊúÄ‰Ω≥Ë°åÁÇ∫‰ªçÁÑ∂ÊòØ‰∏ÄÂÄãÊåëÊà∞„ÄÇÁï∂ÂâçÁöÑËæ¶Ê≥ï‰æùË≥¥ÊñºËá™ÁÑ∂Ë™ûË®ÄËº∏ÂÖ•ÔºåÈÄôÁ®ÆËº∏ÂÖ•ÊïàÁéáÈ´ò‰ΩÜËß£ÊûêÂ∫¶‰ΩéÔºåÊàñËÄÖÂæû‰∫∫È°ûÂÅèÂ•Ω‰∏≠Â≠∏ÁøíÔºåÈÄôÁ®ÆÂÅèÂ•ΩÈõñÁÑ∂Ëß£ÊûêÂ∫¶È´òÔºå‰ΩÜÊ®£Êú¨ÊïàÁéá‰Ωé„ÄÇÊú¨Êñá‰ªãÁ¥π‰∫Ü‰∏ÄÁ®ÆÊñ∞ÊñπÊ≥ïÔºåË©≤ÊñπÊ≥ïÂà©Áî®È†êÂÖàË®ìÁ∑¥ÁöÑ LLM ÁîüÊàêÁöÑÂÖàÈ©ó‰ª•ÂèäÂÅèÂ•ΩÂ≠∏ÁøíÁöÑÁ≤æÁ¢∫ÊÄß„ÄÇÊàëÂÄëÁöÑËæ¶Ê≥ïÁ®±ÁÇ∫Ë™ûË®ÄÂºïÂ∞éÂÅèÂ•ΩÂ≠∏Áøí (LGPL)ÔºåÂÆÉ‰ΩøÁî® LLM ÁîüÊàêÂàùÂßãË°åÁÇ∫Ê®£Êú¨ÔºåÁÑ∂ÂæåÈÄöÈÅéÂü∫ÊñºÂÅèÂ•ΩÁöÑÂèçÈ•ãÂ∞çÂÖ∂ÈÄ≤Ë°åÂÑ™ÂåñÔºå‰ª•Â≠∏ÁøíËàá‰∫∫È°ûÊúüÊúõÁ∑äÂØÜ‰∏ÄËá¥ÁöÑË°åÁÇ∫„ÄÇÊàëÂÄëÁöÑÊ†∏ÂøÉË¶ãËß£ÊòØÔºåLLM ÂèØ‰ª•ÊåáÂ∞éÂÅèÂ•ΩÂ≠∏ÁøíÁöÑÊé°Ê®£ÈÅéÁ®ãÔºåÂæûËÄåÂ§ßÂπÖÊèêÈ´òÊ®£Êú¨ÊïàÁéá„ÄÇÊàëÂÄëË≠âÊòé LGPL ÂèØ‰ª•ÈÄöÈÅéÂÉÖÂõõÊ¨°Êü•Ë©¢Âø´ÈÄüÂ≠∏ÁøíÊ∫ñÁ¢∫‰∏îÂØåÊúâË°®ÁèæÂäõÁöÑË°åÁÇ∫ÔºåÂæûËÄåÂÑ™ÊñºÁ¥îË™ûË®ÄÂèÉÊï∏ÂåñÊ®°ÂûãÂíåÂÇ≥Áµ±ÂÅèÂ•ΩÂ≠∏ÁøíÊñπÊ≥ï„ÄÇÂåÖÂê´ÂΩ±ÁâáÁöÑÁ∂≤Á´ôÔºöhttps://lgpl-gaits.github.io/

##### **Boosting Knowledge Graph-based Recommendations through Confidence-Aware Augmentation with Large Language Models**
2502.03715v1 by Rui Cai, Chao Wang, Qianyi Cai, Dazhong Shen, Hui Xiong

Knowledge Graph-based recommendations have gained significant attention due
to their ability to leverage rich semantic relationships. However, constructing
and maintaining Knowledge Graphs (KGs) is resource-intensive, and the accuracy
of KGs can suffer from noisy, outdated, or irrelevant triplets. Recent
advancements in Large Language Models (LLMs) offer a promising way to improve
the quality and relevance of KGs for recommendation tasks. Despite this,
integrating LLMs into KG-based systems presents challenges, such as efficiently
augmenting KGs, addressing hallucinations, and developing effective joint
learning methods. In this paper, we propose the Confidence-aware KG-based
Recommendation Framework with LLM Augmentation (CKG-LLMA), a novel framework
that combines KGs and LLMs for recommendation task. The framework includes: (1)
an LLM-based subgraph augmenter for enriching KGs with high-quality
information, (2) a confidence-aware message propagation mechanism to filter
noisy triplets, and (3) a dual-view contrastive learning method to integrate
user-item interactions and KG data. Additionally, we employ a confidence-aware
explanation generation process to guide LLMs in producing realistic
explanations for recommendations. Finally, extensive experiments demonstrate
the effectiveness of CKG-LLMA across multiple public datasets.

ÊëòË¶ÅÔºöÂü∫ÊñºÁü•Ë≠òÂúñË≠úÁöÑÊé®Ëñ¶Âõ†ÂÖ∂Âà©Áî®Ë±êÂØåË™ûÁæ©Èóú‰øÇÁöÑËÉΩÂäõËÄåÂÇôÂèóÈóúÊ≥®„ÄÇÁÑ∂ËÄåÔºåÊßãÂª∫ÂíåÁ∂≠Ë≠∑Áü•Ë≠òÂúñË≠ú (KG) ÊòØ‰∏ÄÈ†ÖË≥áÊ∫êÂØÜÈõÜÂûã‰ªªÂãôÔºåËÄå KG ÁöÑÊ∫ñÁ¢∫ÊÄßÂèØËÉΩÊúÉÂèóÂà∞ÈõúË®ä„ÄÅÈÅéÊôÇÊàñÁÑ°ÈóúÁöÑ‰∏âÂÖÉÁµÑÁöÑÂΩ±Èüø„ÄÇÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑÊúÄÊñ∞ÈÄ≤Â±ïÁÇ∫ÊèêÈ´ò KG Âú®Êé®Ëñ¶‰ªªÂãô‰∏≠ÁöÑÂìÅË≥™ÂíåÁõ∏ÈóúÊÄßÊèê‰æõ‰∫Ü‰∏ÄÁ®ÆÊúâÂâçÈÄîÁöÑÊñπÊ≥ï„ÄÇÂÑòÁÆ°Â¶ÇÊ≠§ÔºåÂ∞á LLM Êï¥ÂêàÂà∞Âü∫Êñº KG ÁöÑÁ≥ªÁµ±‰∏≠ÊúÉÂ∏∂‰æÜÊåëÊà∞Ôºå‰æãÂ¶ÇÊúâÊïàÊì¥ÂÖÖ KG„ÄÅËôïÁêÜÂπªË¶∫Ôºå‰ª•ÂèäÈñãÁôºÊúâÊïàÁöÑËÅØÂêàÂ≠∏ÁøíÊñπÊ≥ï„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫ÂÖ∑Êúâ LLM Êì¥ÂÖÖÁöÑ‰ø°ÂøÉÊÑüÁü•ÂûãÂü∫Êñº KG ÁöÑÊé®Ëñ¶Ê°ÜÊû∂ (CKG-LLMA)ÔºåÈÄôÊòØ‰∏ÄÂÄãÁµêÂêà KG Âíå LLM ÈÄ≤Ë°åÊé®Ëñ¶‰ªªÂãôÁöÑÊñ∞Á©éÊ°ÜÊû∂„ÄÇË©≤Ê°ÜÊû∂ÂåÖÊã¨Ôºö(1) ‰∏ÄÂÄãÂü∫Êñº LLM ÁöÑÂ≠êÂúñÊì¥ÂÖÖÂô®ÔºåÁî®Êñº‰ΩøÁî®È´òÂìÅË≥™Ë≥áË®äË±êÂØå KGÔºå(2) ‰∏ÄÂÄã‰ø°ÂøÉÊÑüÁü•ÂûãË®äÊÅØÂÇ≥Êí≠Ê©üÂà∂ÔºåÁî®ÊñºÈÅéÊøæÈõúË®ä‰∏âÂÖÉÁµÑÔºå‰ª•Âèä (3) ‰∏ÄÂÄãÈõôË¶ñÂúñÂ∞çÊØîÂ≠∏ÁøíÊñπÊ≥ïÔºåÁî®ÊñºÊï¥Âêà‰ΩøÁî®ËÄÖ-È†ÖÁõÆ‰∫íÂãïÂíå KG Ë≥áÊñô„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÊé°Áî®‰∏ÄÂÄã‰ø°ÂøÉÊÑüÁü•ÂûãËß£ÈáãÁî¢ÁîüÁ®ãÂ∫èÔºå‰ª•ÂºïÂ∞é LLM ÁÇ∫Êé®Ëñ¶Áî¢ÁîüÈÄºÁúüÁöÑËß£Èáã„ÄÇÊúÄÂæåÔºåÂ§ßÈáèÁöÑÂØ¶È©óË≠âÊòé‰∫Ü CKG-LLMA Âú®Â§öÂÄãÂÖ¨ÈñãË≥áÊñôÈõÜ‰∏≠ÁöÑÊúâÊïàÊÄß„ÄÇ

##### **MultiQ&A: An Analysis in Measuring Robustness via Automated Crowdsourcing of Question Perturbations and Answers**
2502.03711v1 by Nicole Cho, William Watson

One critical challenge in the institutional adoption journey of Large
Language Models (LLMs) stems from their propensity to hallucinate in generated
responses. To address this, we propose MultiQ&A, a systematic approach for
evaluating the robustness and consistency of LLM-generated answers. We
demonstrate MultiQ&A's ability to crowdsource question perturbations and their
respective answers through independent LLM agents at scale. Our experiments
culminated in the examination of 1.9 million question perturbations and 2.3
million answers. Furthermore, MultiQ&A shows that ensembled LLMs, such as
gpt-3.5-turbo, remain relatively robust and consistent under perturbations.
MultiQ&A provides clarity in the response generation space, offering an
effective method for inspecting disagreements and variability. Therefore, our
system offers a potential framework for institutional LLM adoption with the
ability to measure confidence, consistency, and the quantification of
hallucinations.

ÊëòË¶ÅÔºöÂú®Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑÊ©üÊßãÊé°Áî®ÈÅéÁ®ã‰∏≠Ôºå‰∏ÄÂÄãÈóúÈçµÊåëÊà∞‰æÜËá™ÊñºÂÆÉÂÄëÂú®Áî¢ÁîüÁöÑÂõûÊáâ‰∏≠ÂÆπÊòìÂá∫ÁèæÂπªË¶∫„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåÊàëÂÄëÊèêÂá∫‰∫Ü MultiQ&AÔºå‰∏ÄÁ®ÆÁî®ÊñºË©ï‰º∞ LLM Áî¢ÁîüÁöÑÁ≠îÊ°àÁöÑÂÅ•Â£ØÊÄßÂíå‰∏ÄËá¥ÊÄßÁöÑÁ≥ªÁµ±ÊÄßÊñπÊ≥ï„ÄÇÊàëÂÄëÂ±ïÁ§∫‰∫Ü MultiQ&A ËÉΩÂ§†Â§ßË¶èÊ®°Âú∞ÈÄèÈÅéÁç®Á´ãÁöÑ LLM ‰ª£ÁêÜ‰æÜÁúæÂåÖÂïèÈ°åÊìæÂãïÂèäÂÖ∂ÂêÑËá™ÁöÑÁ≠îÊ°à„ÄÇÊàëÂÄëÁöÑÂØ¶È©óÊúÄÁµÇÊ™¢È©ó‰∫Ü 190 Ëê¨ÂÄãÂïèÈ°åÊìæÂãïÂíå 230 Ëê¨ÂÄãÁ≠îÊ°à„ÄÇÊ≠§Â§ñÔºåMultiQ&A È°ØÁ§∫ÔºåÈõÜÂêàÁöÑ LLMÔºà‰æãÂ¶Ç gpt-3.5-turboÔºâÂú®ÊìæÂãï‰∏ã‰ªçÁÑ∂Áõ∏Â∞çÂÅ•Â£Ø‰∏î‰∏ÄËá¥„ÄÇMultiQ&A Âú®ÂõûÊáâÁî¢ÁîüÁ©∫Èñì‰∏≠Êèê‰æõ‰∫ÜÊ∏ÖÊô∞Â∫¶ÔºåÊèê‰æõ‰∫Ü‰∏ÄÁ®ÆÊ™¢Êü•ÂàÜÊ≠ßÂíåËÆäÁï∞ÊÄßÁöÑÊúâÊïàÊñπÊ≥ï„ÄÇÂõ†Ê≠§ÔºåÊàëÂÄëÁöÑÁ≥ªÁµ±Êèê‰æõ‰∫Ü‰∏ÄÂÄãÊΩõÂú®ÁöÑÊ©üÊßã LLM Êé°Áî®Êû∂ÊßãÔºåËÉΩÂ§†Ë°°Èáè‰ø°ÂøÉ„ÄÅ‰∏ÄËá¥ÊÄßÂíåÂπªË¶∫ÁöÑÈáèÂåñ„ÄÇ

##### **Aggregate and conquer: detecting and steering LLM concepts by combining nonlinear predictors over multiple layers**
2502.03708v1 by Daniel Beaglehole, Adityanarayanan Radhakrishnan, Enric Boix-Adser√†, Mikhail Belkin

A trained Large Language Model (LLM) contains much of human knowledge. Yet,
it is difficult to gauge the extent or accuracy of that knowledge, as LLMs do
not always ``know what they know'' and may even be actively misleading. In this
work, we give a general method for detecting semantic concepts in the internal
activations of LLMs. Furthermore, we show that our methodology can be easily
adapted to steer LLMs toward desirable outputs. Our innovations are the
following: (1) we use a nonlinear feature learning method to identify important
linear directions for predicting concepts from each layer; (2) we aggregate
features across layers to build powerful concept detectors and steering
mechanisms. We showcase the power of our approach by attaining state-of-the-art
results for detecting hallucinations, harmfulness, toxicity, and untruthful
content on seven benchmarks. We highlight the generality of our approach by
steering LLMs towards new concepts that, to the best of our knowledge, have not
been previously considered in the literature, including: semantic
disambiguation, human languages, programming languages, hallucinated responses,
science subjects, poetic/Shakespearean English, and even multiple concepts
simultaneously. Moreover, our method can steer concepts with numerical
attributes such as product reviews. We provide our code (including a simple API
for our methods) at https://github.com/dmbeaglehole/neural_controllers .

ÊëòË¶ÅÔºöÁ∂ìÈÅéË®ìÁ∑¥ÁöÑÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÂåÖÂê´Ë®±Â§ö‰∫∫È°ûÁü•Ë≠ò„ÄÇÁÑ∂ËÄåÔºåË¶ÅË°°ÈáèÈÄô‰∫õÁü•Ë≠òÁöÑÂª£Â∫¶ÊàñÊ∫ñÁ¢∫ÊÄßÂæàÂõ∞Èõ£ÔºåÂõ†ÁÇ∫ LLM ‰∏¶‰∏çÁ∏ΩÊòØ„ÄåÁü•ÈÅìËá™Â∑±Áü•ÈÅì‰ªÄÈ∫º„ÄçÔºåÁîöËá≥ÂèØËÉΩÁ©çÊ•µË™§Â∞é„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÊèê‰æõ‰∫Ü‰∏ÄÁ®ÆÈÄöÁî®ÊñπÊ≥ïÔºåÁî®ÊñºÂú® LLM ÁöÑÂÖßÈÉ®ÊøÄÊ¥ª‰∏≠ÂÅµÊ∏¨Ë™ûÁæ©Ê¶ÇÂøµ„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÂ±ïÁ§∫‰∫ÜÊàëÂÄëÁöÑÊäÄË°ìÂèØ‰ª•ËºïÈ¨ÜÂú∞Ë™øÊï¥Ôºå‰ª•ÂºïÂ∞é LLM ÊúùÂêëÁêÜÊÉ≥ÁöÑËº∏Âá∫„ÄÇÊàëÂÄëÁöÑÂâµÊñ∞Â¶Ç‰∏ãÔºö(1) ÊàëÂÄë‰ΩøÁî®ÈùûÁ∑öÊÄßÁâπÂæµÂ≠∏ÁøíÊñπÊ≥ï‰æÜË≠òÂà•ÈáçË¶ÅÁöÑÁ∑öÊÄßÊñπÂêëÔºå‰ª•ÂæûÊØè‰∏ÄÂ±§È†êÊ∏¨Ê¶ÇÂøµÔºõ(2) ÊàëÂÄëÂåØÁ∏ΩÂêÑÂ±§ÁöÑÁâπÂæµÔºå‰ª•Âª∫Á´ãÂº∑Â§ßÁöÑÊ¶ÇÂøµÂÅµÊ∏¨Âô®ÂíåÂ∞éÂºïÊ©üÂà∂„ÄÇÊàëÂÄëÈÄèÈÅéÂú®‰∏ÉÂÄãÂü∫Ê∫ñ‰∏äÁç≤ÂæóÂÅµÊ∏¨ÂπªË¶∫„ÄÅÊúâÂÆ≥ÊÄß„ÄÅÊØíÊÄßÂíåËôõÂÅáÂÖßÂÆπÁöÑÊúÄÊñ∞ÁµêÊûúÔºåÂ±ïÁ§∫‰∫ÜÊàëÂÄëÊñπÊ≥ïÁöÑÂäõÈáè„ÄÇÊàëÂÄëÈÄèÈÅéÂºïÂ∞é LLM ÊúùÂêëÊñ∞ÁöÑÊ¶ÇÂøµÔºåÁ™ÅÈ°Ø‰∫ÜÊàëÂÄëÊñπÊ≥ïÁöÑÊôÆÈÅçÊÄßÔºåÈÄô‰∫õÊ¶ÇÂøµÊìöÊàëÂÄëÊâÄÁü•Ôºå‰ª•ÂâçÂ∞öÊú™Âú®ÊñáÁçª‰∏≠Ë¢´ËÄÉÊÖÆÈÅéÔºåÂåÖÊã¨ÔºöË™ûÁæ©Ê∂àÊ≠ß„ÄÅ‰∫∫È°ûË™ûË®Ä„ÄÅÁ®ãÂºèË™ûË®Ä„ÄÅÂπªË¶∫ÂèçÊáâ„ÄÅÁßëÂ≠∏‰∏ªÈ°å„ÄÅË©©ÊÑè/ËééÂ£´ÊØî‰∫ûËã±Ë™ûÔºåÁîöËá≥ÂêåÊôÇÂåÖÂê´Â§öÂÄãÊ¶ÇÂøµ„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÁöÑÊ®°ÂûãÂèØ‰ª•‰ΩøÁî®Êï∏ÂÄºÂ±¨ÊÄßÔºà‰æãÂ¶ÇÁî¢ÂìÅË©ïË´ñÔºâ‰æÜÂºïÂ∞éÊ¶ÇÂøµ„ÄÇÊàëÂÄëÂú® https://github.com/dmbeaglehole/neural_controllers Êèê‰æõÊàëÂÄëÁöÑÁ®ãÂºèÁ¢ºÔºàÂåÖÊã¨ÊàëÂÄëÊñπÊ≥ïÁöÑÁ∞°ÂñÆ APIÔºâ„ÄÇ

##### **LLM Alignment as Retriever Optimization: An Information Retrieval Perspective**
2502.03699v1 by Bowen Jin, Jinsung Yoon, Zhen Qin, Ziqi Wang, Wei Xiong, Yu Meng, Jiawei Han, Sercan O. Arik

Large Language Models (LLMs) have revolutionized artificial intelligence with
capabilities in reasoning, coding, and communication, driving innovation across
industries. Their true potential depends on effective alignment to ensure
correct, trustworthy and ethical behavior, addressing challenges like
misinformation, hallucinations, bias and misuse. While existing Reinforcement
Learning (RL)-based alignment methods are notoriously complex, direct
optimization approaches offer a simpler alternative. In this work, we introduce
a novel direct optimization approach for LLM alignment by drawing on
established Information Retrieval (IR) principles. We present a systematic
framework that bridges LLM alignment and IR methodologies, mapping LLM
generation and reward models to IR's retriever-reranker paradigm. Building on
this foundation, we propose LLM Alignment as Retriever Preference Optimization
(LarPO), a new alignment method that enhances overall alignment quality.
Extensive experiments validate LarPO's effectiveness with 38.9 % and 13.7 %
averaged improvement on AlpacaEval2 and MixEval-Hard respectively. Our work
opens new avenues for advancing LLM alignment by integrating IR foundations,
offering a promising direction for future research.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÈÄèÈÅéÂú®Êé®ÁêÜ„ÄÅÁ∑®Á¢ºÂíåÊ∫ùÈÄöÊñπÈù¢ÁöÑËÉΩÂäõÔºåÂæπÂ∫ïÈù©Êñ∞‰∫Ü‰∫∫Â∑•Êô∫ÊÖßÔºå‰∏¶Êé®ÂãïÂêÑÁî¢Ê•≠ÁöÑÂâµÊñ∞„ÄÇÂÖ∂ÁúüÊ≠£ÁöÑÊΩõÂäõÂèñÊ±∫ÊñºÊúâÊïàÂ∞çÈΩäÔºå‰ª•Á¢∫‰øùÊ≠£Á¢∫„ÄÅÂÄºÂæó‰ø°Ë≥¥‰∏îÁ¨¶ÂêàÈÅìÂæ∑ÁöÑË°åÁÇ∫Ôºå‰∏¶Ëß£Ê±∫ÈåØË™§Ë≥áË®ä„ÄÅÂπªË¶∫„ÄÅÂÅèË¶ãÂíåË™§Áî®Á≠âÊåëÊà∞„ÄÇÈõñÁÑ∂ÁèæÊúâÁöÑÂü∫ÊñºÂº∑ÂåñÂ≠∏Áøí (RL) ÁöÑÂ∞çÈΩäÊñπÊ≥ïÂá∫‰∫ÜÂêçÁöÑË§áÈõúÔºå‰ΩÜÁõ¥Êé•ÊúÄ‰Ω≥ÂåñÊñπÊ≥ïÊèê‰æõ‰∫Ü‰∏ÄÂÄãÊõ¥Á∞°ÂñÆÁöÑÊõø‰ª£ÊñπÊ°à„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÈÄèÈÅéÊé°Áî®Êó¢ÂÆöÁöÑË≥áË®äÊ™¢Á¥¢ (IR) ÂéüÂâáÔºå‰ªãÁ¥π‰∫Ü‰∏ÄÁ®ÆÊñ∞ÁöÑ LLM Â∞çÈΩäÁõ¥Êé•ÊúÄ‰Ω≥ÂåñÊñπÊ≥ï„ÄÇÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÁ≥ªÁµ±ÂåñÁöÑÊû∂ÊßãÔºåÂ∞á LLM Â∞çÈΩäÂíå IR ÊñπÊ≥ïË´ñËÅØÁπ´Ëµ∑‰æÜÔºåÂ∞á LLM ÁîüÊàêÂíåÁçéÂãµÊ®°ÂûãÂ∞çÊáâÂà∞ IR ÁöÑÊ™¢Á¥¢Âô®ÈáçÊñ∞ÊéíÂ∫èÁØÑ‰æã„ÄÇÂú®Ê≠§Âü∫Á§é‰∏äÔºåÊàëÂÄëÊèêÂá∫ LLM Â∞çÈΩä‰ΩúÁÇ∫Ê™¢Á¥¢Âô®ÂÅèÂ•ΩÊúÄ‰Ω≥Âåñ (LarPO)ÔºåÈÄôÊòØ‰∏ÄÁ®ÆÊñ∞ÁöÑÂ∞çÈΩäÊñπÊ≥ïÔºåÂèØÂ¢ûÂº∑Êï¥È´îÂ∞çÈΩäÂìÅË≥™„ÄÇÂ§ßÈáèÁöÑÂØ¶È©óÈ©óË≠â‰∫Ü LarPO ÁöÑÊúâÊïàÊÄßÔºåÂú® AlpacaEval2 Âíå MixEval-Hard ÂàÜÂà•Âπ≥ÂùáÊîπÂñÑ‰∫Ü 38.9% Âíå 13.7%„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÈÄèÈÅéÊï¥Âêà IR Âü∫Á§éÔºåÁÇ∫Êé®ÈÄ≤ LLM Â∞çÈΩäÈñãÈó¢‰∫ÜÊñ∞ÁöÑÈÄîÂæëÔºå‰∏¶ÁÇ∫Êú™‰æÜÁöÑÁ†îÁ©∂Êèê‰æõ‰∫ÜÊúâÂ∏åÊúõÁöÑÊñπÂêë„ÄÇ

##### **DocMIA: Document-Level Membership Inference Attacks against DocVQA Models**
2502.03692v1 by Khanh Nguyen, Raouf Kerkouche, Mario Fritz, Dimosthenis Karatzas

Document Visual Question Answering (DocVQA) has introduced a new paradigm for
end-to-end document understanding, and quickly became one of the standard
benchmarks for multimodal LLMs. Automating document processing workflows,
driven by DocVQA models, presents significant potential for many business
sectors. However, documents tend to contain highly sensitive information,
raising concerns about privacy risks associated with training such DocVQA
models. One significant privacy vulnerability, exploited by the membership
inference attack, is the possibility for an adversary to determine if a
particular record was part of the model's training data. In this paper, we
introduce two novel membership inference attacks tailored specifically to
DocVQA models. These attacks are designed for two different adversarial
scenarios: a white-box setting, where the attacker has full access to the model
architecture and parameters, and a black-box setting, where only the model's
outputs are available. Notably, our attacks assume the adversary lacks access
to auxiliary datasets, which is more realistic in practice but also more
challenging. Our unsupervised methods outperform existing state-of-the-art
membership inference attacks across a variety of DocVQA models and datasets,
demonstrating their effectiveness and highlighting the privacy risks in this
domain.

ÊëòË¶ÅÔºöÊñá‰ª∂Ë¶ñË¶∫ÂïèÁ≠î (DocVQA) ÂºïÈÄ≤‰∫Ü‰∏ÄÁ®ÆÊñ∞ÁöÑÁØÑ‰æãÔºåÁî®ÊñºÁ´ØÂ∞çÁ´ØÊñá‰ª∂ÁêÜËß£Ôºå‰∏¶ËøÖÈÄüÊàêÁÇ∫Â§öÊ®°ÊÖã LLM ÁöÑÊ®ôÊ∫ñÂü∫Ê∫ñ‰πã‰∏Ä„ÄÇÁî± DocVQA Ê®°ÂûãÈ©ÖÂãïÁöÑËá™ÂãïÂåñÊñá‰ª∂ËôïÁêÜÂ∑•‰ΩúÊµÅÁ®ãÔºåÂ∞çË®±Â§öÂïÜÊ•≠È†òÂüüÂÖ∑ÊúâÈ°ØËëóÁöÑÊΩõÂäõ„ÄÇÁÑ∂ËÄåÔºåÊñá‰ª∂ÂæÄÂæÄÂåÖÂê´È´òÂ∫¶ÊïèÊÑüÁöÑË≥áË®äÔºåÂºïÁôº‰∫ÜËàáË®ìÁ∑¥Ê≠§È°û DocVQA Ê®°ÂûãÁõ∏ÈóúÁöÑÈö±ÁßÅÈ¢®Èö™ÁöÑÁñëÊÖÆ„ÄÇ‰∏ÄÂÄãÈáçÂ§ßÁöÑÈö±ÁßÅÊºèÊ¥ûÔºåÁî±ÊàêÂì°Ë≥áÊ†ºÊé®Ë´ñÊîªÊìäÊâÄÂà©Áî®ÔºåÊòØÂ∞çÊâãÊúâÂèØËÉΩÁ¢∫ÂÆöÁâπÂÆöË®òÈåÑÊòØÂê¶ÁÇ∫Ê®°ÂûãË®ìÁ∑¥Ë≥áÊñôÁöÑ‰∏ÄÈÉ®ÂàÜ„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄë‰ªãÁ¥π‰∫ÜÂÖ©ÂÄãÈáùÂ∞ç DocVQA Ê®°ÂûãÈáèË∫´ÊâìÈÄ†ÁöÑÊñ∞Á©éÊàêÂì°Ë≥áÊ†ºÊé®Ë´ñÊîªÊìä„ÄÇÈÄô‰∫õÊîªÊìäË¢´Ë®≠Ë®àÁî®ÊñºÂÖ©Á®Æ‰∏çÂêåÁöÑÂ∞çÊäóÂ†¥ÊôØÔºöÁôΩÁõíË®≠ÂÆöÔºåÂÖ∂‰∏≠ÊîªÊìäËÄÖÂèØ‰ª•ÂÆåÂÖ®Â≠òÂèñÊ®°ÂûãÊû∂ÊßãÂíåÂèÉÊï∏Ôºå‰ª•ÂèäÈªëÁõíË®≠ÂÆöÔºåÂÖ∂‰∏≠Âè™ËÉΩ‰ΩøÁî®Ê®°ÂûãÁöÑËº∏Âá∫„ÄÇÂÄºÂæóÊ≥®ÊÑèÁöÑÊòØÔºåÊàëÂÄëÁöÑÊîªÊìäÂÅáË®≠Â∞çÊâãÁÑ°Ê≥ïÂ≠òÂèñËºîÂä©Ë≥áÊñôÈõÜÔºåÈÄôÂú®ÂØ¶Âãô‰∏äÊõ¥ÁÇ∫ÂØ¶ÈöõÔºå‰ΩÜÊåëÊà∞ÊÄß‰πüÊõ¥È´ò„ÄÇÊàëÂÄëÁöÑÁÑ°Áõ£Áù£ÊñπÊ≥ïÂú®ÂêÑÁ®Æ DocVQA Ê®°ÂûãÂíåË≥áÊñôÈõÜ‰∏äÂãùÈÅéÁèæÊúâÁöÑÊúÄÂÖàÈÄ≤ÊàêÂì°Ë≥áÊ†ºÊé®Ë´ñÊîªÊìäÔºåË≠âÊòé‰∫ÜÂÆÉÂÄëÁöÑÊúâÊïàÊÄßÔºå‰∏¶Á™ÅÈ°Ø‰∫ÜÊ≠§È†òÂüüÁöÑÈö±ÁßÅÈ¢®Èö™„ÄÇ

##### **A Comparison of DeepSeek and Other LLMs**
2502.03688v1 by Tianchen Gao, Jiashun Jin, Zheng Tracy Ke, Gabriel Moryoussef

Recently, DeepSeek has been the focus of attention in and beyond the AI
community. An interesting problem is how DeepSeek compares to other large
language models (LLMs). There are many tasks an LLM can do, and in this paper,
we use the task of predicting an outcome using a short text for comparison. We
consider two settings, an authorship classification setting and a citation
classification setting. In the first one, the goal is to determine whether a
short text is written by human or AI. In the second one, the goal is to
classify a citation to one of four types using the textual content. For each
experiment, we compare DeepSeek with $4$ popular LLMs: Claude, Gemini, GPT, and
Llama.
  We find that, in terms of classification accuracy, DeepSeek outperforms
Gemini, GPT, and Llama in most cases, but underperforms Claude. We also find
that DeepSeek is comparably slower than others but with a low cost to use,
while Claude is much more expensive than all the others. Finally, we find that
in terms of similarity, the output of DeepSeek is most similar to those of
Gemini and Claude (and among all $5$ LLMs, Claude and Gemini have the most
similar outputs).
  In this paper, we also present a fully-labeled dataset collected by
ourselves, and propose a recipe where we can use the LLMs and a recent data
set, MADStat, to generate new data sets. The datasets in our paper can be used
as benchmarks for future study on LLMs.

ÊëòË¶ÅÔºö<paragraph>ÊúÄËøëÔºåDeepSeek‰∏ÄÁõ¥ÊòØ‰∫∫Â∑•Êô∫ËÉΩÁ§æÁæ§ÂÜÖÂ§ñÂÖ≥Ê≥®ÁöÑÁÑ¶ÁÇπ„ÄÇ‰∏Ä‰∏™ÊúâË∂£ÁöÑÈóÆÈ¢òÊòØDeepSeek‰∏éÂÖ∂‰ªñÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÔºàLLMÔºâÁõ∏ÊØîÂ¶Ç‰Ωï„ÄÇLLMÂèØ‰ª•ÂÆåÊàêËÆ∏Â§ö‰ªªÂä°ÔºåÂú®Êú¨Êñá‰∏≠ÔºåÊàë‰ª¨‰ΩøÁî®‰ΩøÁî®ÁÆÄÁü≠ÊñáÊú¨È¢ÑÊµãÁªìÊûúÁöÑ‰ªªÂä°ËøõË°åÊØîËæÉ„ÄÇÊàë‰ª¨ËÄÉËôë‰∏§ÁßçËÆæÁΩÆÔºå‰∏ÄÁßçÊòØ‰ΩúËÄÖÂàÜÁ±ªËÆæÁΩÆÔºåÂè¶‰∏ÄÁßçÊòØÂºïÁî®ÂàÜÁ±ªËÆæÁΩÆ„ÄÇÂú®Á¨¨‰∏Ä‰∏™ËÆæÁΩÆ‰∏≠ÔºåÁõÆÊ†áÊòØÁ°ÆÂÆöÁÆÄÁü≠ÊñáÊú¨ÊòØÁî±‰∫∫ËøòÊòØ‰∫∫Â∑•Êô∫ËÉΩÁºñÂÜôÁöÑ„ÄÇÂú®Á¨¨‰∫å‰∏™ËÆæÁΩÆ‰∏≠ÔºåÁõÆÊ†áÊòØ‰ΩøÁî®ÊñáÊú¨ÂÜÖÂÆπÂ∞ÜÂºïÁî®ÂàÜÁ±ª‰∏∫ÂõõÁßçÁ±ªÂûã‰πã‰∏Ä„ÄÇÂØπ‰∫éÊØè‰∏™ÂÆûÈ™åÔºåÊàë‰ª¨Â∞ÜDeepSeek‰∏é4‰∏™ÊµÅË°åÁöÑLLMËøõË°åÊØîËæÉÔºöClaude„ÄÅGemini„ÄÅGPTÂíåLlama„ÄÇ
Êàë‰ª¨ÂèëÁé∞ÔºåÂú®ÂàÜÁ±ªÂáÜÁ°ÆÊÄßÊñπÈù¢ÔºåDeepSeekÂú®Â§ßÂ§öÊï∞ÊÉÖÂÜµ‰∏ã‰ºò‰∫éGemini„ÄÅGPTÂíåLlamaÔºå‰ΩÜÂú®ClaudeÈù¢ÂâçË°®Áé∞‰∏ç‰Ω≥„ÄÇÊàë‰ª¨ËøòÂèëÁé∞ÔºåDeepSeekÊØîÂÖ∂‰ªñÊ®°ÂûãÊÖ¢Ôºå‰ΩÜ‰ΩøÁî®ÊàêÊú¨‰ΩéÔºåËÄåClaudeÊØîÂÖ∂‰ªñÊ®°ÂûãË¥µÂæóÂ§ö„ÄÇÊúÄÂêéÔºåÊàë‰ª¨ÂèëÁé∞ÔºåÂú®Áõ∏‰ººÊÄßÊñπÈù¢ÔºåDeepSeekÁöÑËæìÂá∫‰∏éGeminiÂíåClaudeÁöÑËæìÂá∫ÊúÄÁõ∏‰ººÔºàÂú®ÊâÄÊúâ5‰∏™LLM‰∏≠ÔºåClaudeÂíåGeminiÁöÑËæìÂá∫ÊúÄÁõ∏‰ººÔºâ„ÄÇ
Âú®Êú¨Êñá‰∏≠ÔºåÊàë‰ª¨ËøòÂ±ïÁ§∫‰∫Ü‰∏Ä‰∏™Áî±Êàë‰ª¨Ëá™Â∑±Êî∂ÈõÜÁöÑÂÆåÂÖ®Ê†áËÆ∞ÁöÑÊï∞ÊçÆÈõÜÔºåÂπ∂ÊèêÂá∫‰∫Ü‰∏Ä‰∏™ÈÖçÊñπÔºåÊàë‰ª¨ÂèØ‰ª•‰ΩøÁî®LLMÂíåÊúÄËøëÁöÑÊï∞ÊçÆÈõÜMADStatÊù•ÁîüÊàêÊñ∞ÁöÑÊï∞ÊçÆÈõÜ„ÄÇÊàë‰ª¨ËÆ∫Êñá‰∏≠ÁöÑÊï∞ÊçÆÈõÜÂèØ‰ª•Áî®‰ΩúÊú™Êù•ÂØπLLMÁöÑÁ†îÁ©∂Âü∫ÂáÜ„ÄÇ</paragraph>

##### **Variational Control for Guidance in Diffusion Models**
2502.03686v1 by Kushagra Pandey, Farrin Marouf Sofian, Felix Draxler, Theofanis Karaletsos, Stephan Mandt

Diffusion models exhibit excellent sample quality, but existing guidance
methods often require additional model training or are limited to specific
tasks. We revisit guidance in diffusion models from the perspective of
variational inference and control, introducing Diffusion Trajectory Matching
(DTM) that enables guiding pretrained diffusion trajectories to satisfy a
terminal cost. DTM unifies a broad class of guidance methods and enables novel
instantiations. We introduce a new method within this framework that achieves
state-of-the-art results on several linear and (blind) non-linear inverse
problems without requiring additional model training or modifications. For
instance, in ImageNet non-linear deblurring, our model achieves an FID score of
34.31, significantly improving over the best pretrained-method baseline (FID
78.07). We will make the code available in a future update.

ÊëòË¶ÅÔºöÊì¥Êï£Ê®°ÂûãÂ±ïÁèæÂá∫Ê•µ‰Ω≥ÁöÑÊ®£Êú¨ÂìÅË≥™Ôºå‰ΩÜÁèæÊúâÁöÑÂºïÂ∞éÊñπÊ≥ïÈÄöÂ∏∏ÈúÄË¶ÅÈ°çÂ§ñÁöÑÊ®°ÂûãË®ìÁ∑¥ÔºåÊàñÂÉÖÈôêÊñºÁâπÂÆö‰ªªÂãô„ÄÇÊàëÂÄëÂæûËÆäÁï∞Êé®Ë´ñÂíåÊéßÂà∂ÁöÑËßíÂ∫¶ÈáçÊñ∞Êé¢Ë®éÊì¥Êï£Ê®°Âûã‰∏≠ÁöÑÂºïÂ∞éÔºå‰∏¶ÂºïÂÖ•Êì¥Êï£ËªåË∑°ÂåπÈÖç (DTM)ÔºåËÆìÈ†êË®ìÁ∑¥ÁöÑÊì¥Êï£ËªåË∑°ËÉΩÂ§†ÊªøË∂≥ÁµÇÁ´ØÊàêÊú¨„ÄÇDTM Áµ±‰∏Ä‰∫ÜÂª£Ê≥õÁöÑÂºïÂ∞éÊñπÊ≥ïÔºå‰∏¶ËÉΩÂØ¶ÁèæÊñ∞Á©éÁöÑÂØ¶‰æãÂåñ„ÄÇÊàëÂÄëÂú®Ê≠§Êû∂Êßã‰∏≠ÂºïÂÖ•‰∏ÄÁ®ÆÊñ∞ÊñπÊ≥ïÔºåÂú®Êï∏ÂÄãÁ∑öÊÄßÂíåÔºàÁõ≤ÔºâÈùûÁ∑öÊÄßÂèçÂïèÈ°å‰∏≠ÈÅîÊàêÊúÄÂÖàÈÄ≤ÁöÑÁµêÊûúÔºåËÄå‰∏çÈúÄË¶ÅÈ°çÂ§ñÁöÑÊ®°ÂûãË®ìÁ∑¥Êàñ‰øÆÊîπ„ÄÇ‰æãÂ¶ÇÔºåÂú® ImageNet ÈùûÁ∑öÊÄßÂéªÊ®°Á≥ä‰∏≠ÔºåÊàëÂÄëÁöÑÊ®°ÂûãÈÅîÊàê 34.31 ÁöÑ FID ÂàÜÊï∏ÔºåÂ§ßÂπÖÂÑ™ÊñºÊúÄ‰Ω≥ÁöÑÈ†êË®ìÁ∑¥ÊñπÊ≥ïÂü∫Ê∫ñÔºàFID 78.07Ôºâ„ÄÇÊàëÂÄëÂ∞áÂú®Êú™‰æÜÁöÑÊõ¥Êñ∞‰∏≠Êèê‰æõÁ®ãÂºèÁ¢º„ÄÇ

##### **Controlled LLM Decoding via Discrete Auto-regressive Biasing**
2502.03685v1 by Patrick Pynadath, Ruqi Zhang

Controlled text generation allows for enforcing user-defined constraints on
large language model outputs, an increasingly important field as LLMs become
more prevalent in everyday life. One common approach uses energy-based
decoding, which defines a target distribution through an energy function that
combines multiple constraints into a weighted average. However, these methods
often struggle to balance fluency with constraint satisfaction, even with
extensive tuning of the energy function's coefficients. In this paper, we
identify that this suboptimal balance arises from sampling in continuous space
rather than the natural discrete space of text tokens. To address this, we
propose Discrete Auto-regressive Biasing, a controlled decoding algorithm that
leverages gradients while operating entirely in the discrete text domain.
Specifically, we introduce a new formulation for controlled text generation by
defining a joint distribution over the generated sequence and an auxiliary bias
sequence. To efficiently sample from this joint distribution, we propose a
Langevin-within-Gibbs sampling algorithm using gradient-based discrete MCMC.
Our method significantly improves constraint satisfaction while maintaining
comparable or better fluency, all with even lower computational costs. We
demonstrate the advantages of our controlled decoding method on sentiment
control, language detoxification, and keyword-guided generation.

ÊëòË¶ÅÔºöÂèóÊéßÊñáÊú¨ÁîüÊàêÂÖÅËÆ∏Â∞çÂ§ßÂûãË™ûË®ÄÊ®°ÂûãËº∏Âá∫Âü∑Ë°å‰ΩøÁî®ËÄÖÂÆöÁæ©ÁöÑÁ¥ÑÊùüÔºåÈö®ËëóÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÂú®Êó•Â∏∏ÁîüÊ¥ª‰∏≠ËÆäÂæóË∂ä‰æÜË∂äÊôÆÈÅçÔºåÈÄôÊòØ‰∏ÄÂÄãË∂ä‰æÜË∂äÈáçË¶ÅÁöÑÈ†òÂüü„ÄÇ‰∏ÄÁ®ÆÂ∏∏Ë¶ãÁöÑÊñπÊ≥ï‰ΩøÁî®Âü∫ÊñºËÉΩÈáèÁöÑËß£Á¢ºÔºåÂÆÉÈÄöÈÅéÂ∞áÂ§öÂÄãÁ¥ÑÊùüÁµÑÂêàÊàêÂä†Ê¨äÂπ≥ÂùáÂÄº‰æÜÂÆöÁæ©ÁõÆÊ®ôÂàÜ‰Ωà„ÄÇÁÑ∂ËÄåÔºåÈÄô‰∫õÊñπÊ≥ïÈÄöÂ∏∏Èõ£‰ª•Âú®ÊµÅÊö¢ÊÄßÂíåÁ¥ÑÊùüÊªøË∂≥‰πãÈñìÂèñÂæóÂπ≥Ë°°ÔºåÂç≥‰ΩøÂ∞çËÉΩÈáèÂáΩÊï∏ÁöÑ‰øÇÊï∏ÈÄ≤Ë°åÂª£Ê≥õË™øÊï¥‰πüÊòØÂ¶ÇÊ≠§„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÁôºÁèæÈÄôÁ®ÆÊ¨°ÂÑ™Âπ≥Ë°°Ê∫êÊñºÂú®ÈÄ£Á∫åÁ©∫Èñì‰∏≠ÈÄ≤Ë°åÊé°Ê®£ÔºåËÄå‰∏çÊòØÂú®ÊñáÊú¨Á¨¶ËôüÁöÑËá™ÁÑ∂Èõ¢Êï£Á©∫Èñì‰∏≠ÈÄ≤Ë°åÊé°Ê®£„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåÊàëÂÄëÊèêÂá∫‰∫ÜÈõ¢Êï£Ëá™ÂõûÊ≠∏ÂÅèÂ∑ÆÔºåÈÄôÊòØ‰∏ÄÁ®ÆÂèóÊéßËß£Á¢ºÊºîÁÆóÊ≥ïÔºåÂÆÉÂú®ÂÆåÂÖ®Âú®Èõ¢Êï£ÊñáÊú¨Âüü‰∏≠ÈÅã‰ΩúÁöÑÂêåÊôÇÂà©Áî®Ê¢ØÂ∫¶„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÊàëÂÄëÈÄöÈÅéÂÆöÁæ©ÁîüÊàêÂ∫èÂàóÂíåËºîÂä©ÂÅèÂ∑ÆÂ∫èÂàó‰∏äÁöÑËÅØÂêàÂàÜ‰Ωà‰æÜÂºïÂÖ•ÂèóÊéßÊñáÊú¨ÁîüÊàêÁöÑÂÖ®Êñ∞ÂÖ¨Âºè„ÄÇÁÇ∫‰∫ÜÊúâÊïàÂú∞ÂæûÈÄôÂÄãËÅØÂêàÂàÜ‰Ωà‰∏≠ÈÄ≤Ë°åÊé°Ê®£ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄã‰ΩøÁî®Âü∫ÊñºÊ¢ØÂ∫¶ÁöÑÈõ¢Êï£ MCMC ÁöÑ Gibbs ÂÖß Langevin Êé°Ê®£ÊºîÁÆóÊ≥ï„ÄÇÊàëÂÄëÁöÑÊ®°ÂûãÈ°ØËëóÊîπÂñÑ‰∫ÜÁ¥ÑÊùüÊªøË∂≥ÔºåÂêåÊôÇÁ∂≠ÊåÅ‰∫ÜÁõ∏Áï∂ÊàñÊõ¥Â•ΩÁöÑÊµÅÊö¢ÊÄßÔºåËÄå‰∏îË®àÁÆóÊàêÊú¨Êõ¥‰Ωé„ÄÇÊàëÂÄëÂú®ÊÉÖÁ∑íÊéßÂà∂„ÄÅË™ûË®ÄËß£ÊØíÂíåÈóúÈçµÂ≠óÂºïÂ∞éÁîüÊàêÊñπÈù¢Â±ïÁ§∫‰∫ÜÊàëÂÄëÁöÑÂèóÊéßËß£Á¢ºÊñπÊ≥ïÁöÑÂÑ™Èªû„ÄÇ

##### **Reflection-Window Decoding: Text Generation with Selective Refinement**
2502.03678v1 by Zeyu Tang, Zhenhao Chen, Loka Li, Xiangchen Song, Yunlong Deng, Yifan Shen, Guangyi Chen, Peter Spirtes, Kun Zhang

The autoregressive decoding for text generation in large language models
(LLMs), while widely used, is inherently suboptimal due to the lack of a
built-in mechanism to perform refinement and/or correction of the generated
content. In this paper, we consider optimality in terms of the joint
probability over the generated response, when jointly considering all tokens at
the same time. We theoretically characterize the potential deviation of the
autoregressively generated response from its globally optimal counterpart that
is of the same length. Our analysis suggests that we need to be cautious when
noticeable uncertainty arises during text generation, which may signal the
sub-optimality of the generation history. To address the pitfall of
autoregressive decoding for text generation, we propose an approach that
incorporates a sliding reflection window and a pausing criterion, such that
refinement and generation can be carried out interchangeably as the decoding
proceeds. Our selective refinement framework strikes a balance between
efficiency and optimality, and our extensive experimental results demonstrate
the effectiveness of our approach.

ÊëòË¶ÅÔºöÂú®Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ‰∏≠Áî®ÊñºÊñáÊú¨ÁîüÊàêÁöÑËá™ÂãïËø¥Ê≠∏Ëß£Á¢ºÔºåÈõñÁÑ∂Âª£Ê≥õ‰ΩøÁî®Ôºå‰ΩÜÁî±ÊñºÁº∫‰πèÂÖßÂª∫Ê©üÂà∂‰æÜÂ∞çÁîüÊàêÁöÑÂÖßÂÆπÈÄ≤Ë°åÁ≤æÁÖâÂíå/Êàñ‰øÆÊ≠£ÔºåÂõ†Ê≠§Êú¨Ë≥™‰∏ä‰∏¶ÈùûÊúÄ‰Ω≥„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÂú®ÂêåÊôÇËÄÉÊÖÆÊâÄÊúâÊ®ôË®òÊôÇÔºåÊ†πÊìöÁîüÊàêÁöÑÂõûÊáâÁöÑËÅØÂêàÊ©üÁéá‰æÜËÄÉÊÖÆÊúÄÂÑ™ÊÄß„ÄÇÊàëÂÄëÂæûÁêÜË´ñ‰∏äÊèèËø∞‰∫ÜËá™ÂãïËø¥Ê≠∏ÁîüÊàêÁöÑÂõûÊáâËàáÈï∑Â∫¶Áõ∏ÂêåÁöÑÂÖ®Â±ÄÊúÄÂÑ™Â∞çÊáâÈ†Ö‰πãÈñìÁöÑÊΩõÂú®ÂÅèÂ∑Æ„ÄÇÊàëÂÄëÁöÑÂàÜÊûêË°®ÊòéÔºåÁï∂Âú®ÊñáÊú¨ÁîüÊàêÈÅéÁ®ã‰∏≠Âá∫ÁèæÊòéÈ°ØÁöÑ‰∏çÁ¢∫ÂÆöÊÄßÊôÇÔºåÊàëÂÄëÈúÄË¶ÅË¨πÊÖéÔºåÈÄôÂèØËÉΩÊúÉË°®ÊòéÁîüÊàêÊ≠∑Âè≤ÁöÑÊ¨°ÂÑ™ÊÄß„ÄÇÁÇ∫‰∫ÜËß£Ê±∫Ëá™ÂãïËø¥Ê≠∏Ëß£Á¢ºÂú®ÊñáÊú¨ÁîüÊàê‰∏≠ÁöÑÁº∫Èô∑ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÊñπÊ≥ïÔºåË©≤ÊñπÊ≥ïÁµêÂêà‰∫Ü‰∏ÄÂÄãÊªëÂãïÂèçÂ∞ÑË¶ñÁ™óÂíå‰∏ÄÂÄãÊö´ÂÅúÊ∫ñÂâáÔºåÈÄôÊ®£ÂèØ‰ª•Âú®Ëß£Á¢ºÈÅéÁ®ã‰∏≠‰∫§ÊõøÈÄ≤Ë°åÁ≤æÁÖâÂíåÁîüÊàê„ÄÇÊàëÂÄëÁöÑÈÅ∏ÊìáÊÄßÁ≤æÁÖâÊ°ÜÊû∂Âú®ÊïàÁéáÂíåÊúÄÂÑ™ÊÄß‰πãÈñìÂèñÂæó‰∫ÜÂπ≥Ë°°ÔºåÊàëÂÄëÁöÑÂª£Ê≥õÂØ¶È©óÁµêÊûúË≠âÊòé‰∫ÜÊàëÂÄëÊñπÊ≥ïÁöÑÊúâÊïàÊÄß„ÄÇ

##### **Advancing Reasoning in Large Language Models: Promising Methods and Approaches**
2502.03671v1 by Avinash Patil

Large Language Models (LLMs) have succeeded remarkably in various natural
language processing (NLP) tasks, yet their reasoning capabilities remain a
fundamental challenge. While LLMs exhibit impressive fluency and factual
recall, their ability to perform complex reasoning-spanning logical deduction,
mathematical problem-solving, commonsense inference, and multi-step
reasoning-often falls short of human expectations. This survey provides a
comprehensive review of emerging techniques enhancing reasoning in LLMs. We
categorize existing methods into key approaches, including prompting strategies
(e.g., Chain-of-Thought reasoning, Self-Consistency, and Tree-of-Thought
reasoning), architectural innovations (e.g., retrieval-augmented models,
modular reasoning networks, and neuro-symbolic integration), and learning
paradigms (e.g., fine-tuning with reasoning-specific datasets, reinforcement
learning, and self-supervised reasoning objectives). Additionally, we explore
evaluation frameworks used to assess reasoning in LLMs and highlight open
challenges, such as hallucinations, robustness, and reasoning generalization
across diverse tasks. By synthesizing recent advancements, this survey aims to
provide insights into promising directions for future research and practical
applications of reasoning-augmented LLMs.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Âú®ÂêÑÁ®ÆËá™ÁÑ∂Ë™ûË®ÄËôïÁêÜ (NLP) ‰ªªÂãô‰∏≠ÂèñÂæó‰∫ÜÈ°ØËëóÁöÑÊàêÂäüÔºå‰ΩÜÂÖ∂Êé®ÁêÜËÉΩÂäõ‰ªçÁÑ∂ÊòØ‰∏ÄÈ†ÖÂü∫Êú¨ÊåëÊà∞„ÄÇÂÑòÁÆ° LLM Ë°®ÁèæÂá∫‰ª§‰∫∫Âç∞Ë±°Ê∑±ÂàªÁöÑÊµÅÊö¢ÊÄßÂíå‰∫ãÂØ¶ÂõûÊÜ∂Ôºå‰ΩÜÂÆÉÂÄëÂü∑Ë°åË§áÈõúÊé®ÁêÜÔºàÂåÖÊã¨ÈÇèËºØÊé®Ë´ñ„ÄÅÊï∏Â≠∏ÂïèÈ°åËß£Ê±∫„ÄÅÂ∏∏Ë≠òÊé®ÁêÜÂíåÂ§öÊ≠•È©üÊé®ÁêÜÔºâÁöÑËÉΩÂäõÂæÄÂæÄ‰ΩéÊñº‰∫∫È°ûÁöÑÊúüÊúõ„ÄÇÈÄôÈ†ÖË™øÊü•Êèê‰æõ‰∫ÜÂ∞çÂ¢ûÂº∑ LLM ‰∏≠Êé®ÁêÜÁöÑÊñ∞ËààÊäÄË°ìÁöÑÂÖ®Èù¢ÂõûÈ°ß„ÄÇÊàëÂÄëÂ∞áÁèæÊúâÊñπÊ≥ïÂàÜÈ°ûÁÇ∫ÈóúÈçµÊñπÊ≥ïÔºåÂåÖÊã¨ÊèêÁ§∫Á≠ñÁï•Ôºà‰æãÂ¶ÇÔºåÊÄùÊÉ≥ÈèàÊé®ÁêÜ„ÄÅËá™Ê¥ΩÊÄßÂíåÊÄùÊÉ≥Ê®πÊé®ÁêÜÔºâ„ÄÅÊû∂ÊßãÂâµÊñ∞Ôºà‰æãÂ¶ÇÔºåÊ™¢Á¥¢Â¢ûÂº∑Ê®°Âûã„ÄÅÊ®°ÁµÑÂåñÊé®ÁêÜÁ∂≤Ë∑ØÂíåÁ•ûÁ∂ìÁ¨¶ËôüÊï¥ÂêàÔºâ‰ª•ÂèäÂ≠∏ÁøíÁØÑ‰æãÔºà‰æãÂ¶ÇÔºå‰ΩøÁî®ÁâπÂÆöÊñºÊé®ÁêÜÁöÑË≥áÊñôÈõÜÈÄ≤Ë°åÂæÆË™ø„ÄÅÂº∑ÂåñÂ≠∏ÁøíÂíåËá™ÊàëÁõ£Áù£Êé®ÁêÜÁõÆÊ®ôÔºâ„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÊé¢Ë®é‰∫ÜÁî®ÊñºË©ï‰º∞ LLM ‰∏≠Êé®ÁêÜÁöÑË©ï‰º∞Ê°ÜÊû∂Ôºå‰∏¶Âº∑Ë™ø‰∫ÜÈñãÊîæÂºèÊåëÊà∞Ôºå‰æãÂ¶ÇÂπªË¶∫„ÄÅÁ©©ÂÅ•ÊÄßÂíåË∑®‰∏çÂêå‰ªªÂãôÁöÑÊé®ÁêÜÊ¶ÇÂåñ„ÄÇÈÄöÈÅéÁ∂úÂêàÊúÄËøëÁöÑÈÄ≤Â±ïÔºåÈÄôÈ†ÖË™øÊü•Êó®Âú®ÁÇ∫Êú™‰æÜÁ†îÁ©∂ÂíåÊé®ÁêÜÂ¢ûÂº∑ LLM ÁöÑÂØ¶ÈöõÊáâÁî®Êèê‰æõÊúâÂ∏åÊúõÁöÑÊñπÂêëÁöÑË¶ãËß£„ÄÇ

##### **Unrealized Expectations: Comparing AI Methods vs Classical Algorithms for Maximum Independent Set**
2502.03669v1 by Yikai Wu, Haoyu Zhao, Sanjeev Arora

AI methods, such as generative models and reinforcement learning, have
recently been applied to combinatorial optimization (CO) problems, especially
NP-hard ones. This paper compares such GPU-based methods with classical
CPU-based methods on Maximum Independent Set (MIS). Experiments on standard
graph families show that AI-based algorithms fail to outperform and, in many
cases, to match the solution quality of the state-of-art classical solver KaMIS
running on a single CPU. Some GPU-based methods even perform similarly to the
simplest heuristic, degree-based greedy. Even with post-processing techniques
like local search, AI-based methods still perform worse than CPU-based solvers.
  We develop a new mode of analysis to reveal that non-backtracking AI methods,
e.g. LTFT (which is based on GFlowNets), end up reasoning similarly to the
simplest degree-based greedy approach, and thus worse than KaMIS. We also find
that CPU-based algorithms, notably KaMIS, have strong performance on sparse
random graphs, which appears to refute a well-known conjectured upper bound for
efficient algorithms from Coja-Oghlan & Efthymiou (2015).

ÊëòË¶ÅÔºöAI ÊñπÊ≥ïÔºå‰æãÂ¶ÇÁîüÊàêÊ®°ÂûãÂíåÂº∫ÂåñÂ≠¶‰π†ÔºåÊúÄËøëÂ∑≤Â∫îÁî®‰∫éÁªÑÂêà‰ºòÂåñ (CO) ÈóÆÈ¢òÔºåÂ∞§ÂÖ∂ÊòØ NP ÈöæÈóÆÈ¢ò„ÄÇÊú¨ÊñáÂ∞ÜÊ≠§Á±ªÂü∫‰∫é GPU ÁöÑÊñπÊ≥ï‰∏éÁªèÂÖ∏ÁöÑÂü∫‰∫é CPU ÁöÑÊñπÊ≥ïÂú®ÊúÄÂ§ßÁã¨Á´ãÈõÜ (MIS) ‰∏äËøõË°å‰∫ÜÊØîËæÉ„ÄÇÂØπÊ†áÂáÜÂõæÊóèÁöÑÂÆûÈ™åË°®ÊòéÔºåÂü∫‰∫é AI ÁöÑÁÆóÊ≥ïÊú™ËÉΩËÉúËøáÔºåÂπ∂‰∏îÂú®ËÆ∏Â§öÊÉÖÂÜµ‰∏ãÔºåÊú™ËÉΩÂåπÈÖçÂú®Âçï‰∏™ CPU ‰∏äËøêË°åÁöÑÊúÄÂÖàËøõÁöÑÁªèÂÖ∏Ê±ÇËß£Âô® KaMIS ÁöÑËß£ÂÜ≥ÊñπÊ°àË¥®Èáè„ÄÇ‰∏Ä‰∫õÂü∫‰∫é GPU ÁöÑÊñπÊ≥ïÁîöËá≥Ë°®Áé∞ÂæóÁ±ª‰ºº‰∫éÊúÄÁÆÄÂçïÁöÑÂêØÂèëÂºèÔºåÂü∫‰∫éÂ∫¶ÁöÑË¥™Â©™ÁÆóÊ≥ï„ÄÇÂç≥‰Ωø‰ΩøÁî®Â±ÄÈÉ®ÊêúÁ¥¢Á≠âÂêéÂ§ÑÁêÜÊäÄÊúØÔºåÂü∫‰∫é AI ÁöÑÊñπÊ≥ï‰ªçÁÑ∂ÊØîÂü∫‰∫é CPU ÁöÑÊ±ÇËß£Âô®Ë°®Áé∞ÂæóÊõ¥Â∑Æ„ÄÇÊàë‰ª¨ÂºÄÂèë‰∫Ü‰∏ÄÁßçÊñ∞ÁöÑÂàÜÊûêÊ®°ÂºèÊù•Êè≠Á§∫ÈùûÂõûÊ∫Ø AI ÊñπÊ≥ïÔºå‰æãÂ¶Ç LTFTÔºàÂü∫‰∫é GFlowNetsÔºâÔºåÊúÄÁªàÊé®ÁêÜÁ±ª‰ºº‰∫éÊúÄÁÆÄÂçïÁöÑÂü∫‰∫éÂ∫¶ÁöÑË¥™Â©™ÊñπÊ≥ïÔºåÂõ†Ê≠§ÊØî KaMIS Êõ¥Â∑Æ„ÄÇÊàë‰ª¨ËøòÂèëÁé∞ÔºåÂü∫‰∫é CPU ÁöÑÁÆóÊ≥ïÔºåÁâπÂà´ÊòØ KaMISÔºåÂú®Á®ÄÁñèÈöèÊú∫Âõæ‰∏äÂÖ∑ÊúâÂæàÂº∫ÁöÑÊÄßËÉΩÔºåËøô‰ºº‰πéÈ©≥Êñ•‰∫Ü Coja-Oghlan Âíå Efthymiou (2015) ÊèêÂá∫ÁöÑ‰∏Ä‰∏™‰ºóÊâÄÂë®Áü•ÁöÑÊúâÊïàÁÆóÊ≥ïÁöÑ‰∏äÁïåÁåúÊÉ≥„ÄÇ

##### **Energy & Force Regression on DFT Trajectories is Not Enough for Universal Machine Learning Interatomic Potentials**
2502.03660v1 by Santiago Miret, Kin Long Kelvin Lee, Carmelo Gonzales, Sajid Mannan, N. M. Anoop Krishnan

Universal Machine Learning Interactomic Potentials (MLIPs) enable accelerated
simulations for materials discovery. However, current research efforts fail to
impactfully utilize MLIPs due to: 1. Overreliance on Density Functional Theory
(DFT) for MLIP training data creation; 2. MLIPs' inability to reliably and
accurately perform large-scale molecular dynamics (MD) simulations for diverse
materials; 3. Limited understanding of MLIPs' underlying capabilities. To
address these shortcomings, we aargue that MLIP research efforts should
prioritize: 1. Employing more accurate simulation methods for large-scale MLIP
training data creation (e.g. Coupled Cluster Theory) that cover a wide range of
materials design spaces; 2. Creating MLIP metrology tools that leverage
large-scale benchmarking, visualization, and interpretability analyses to
provide a deeper understanding of MLIPs' inner workings; 3. Developing
computationally efficient MLIPs to execute MD simulations that accurately model
a broad set of materials properties. Together, these interdisciplinary research
directions can help further the real-world application of MLIPs to accurately
model complex materials at device scale.

ÊëòË¶ÅÔºöÈÄöÁî®Êú∫Âô®Â≠¶‰π†‰∫§‰∫íÂäøËÉΩ (MLIP) ÂèØÂä†ÈÄüÊùêÊñôÂèëÁé∞Ê®°Êãü„ÄÇÁÑ∂ËÄåÔºåÁõÆÂâçÁöÑÁ†îÁ©∂Â∑•‰ΩúÊú™ËÉΩÊúâÊïàÂà©Áî® MLIPÔºåÂéüÂõ†Â¶Ç‰∏ãÔºö1. ËøáÂ∫¶‰æùËµñÂØÜÂ∫¶Ê≥õÂáΩÁêÜËÆ∫ (DFT) Êù•ÂàõÂª∫ MLIP ËÆ≠ÁªÉÊï∞ÊçÆÔºõ2. MLIP Êó†Ê≥ïÂèØÈù†‰∏îÂáÜÁ°ÆÂú∞ÊâßË°å‰∏çÂêåÊùêÊñôÁöÑÂ§ßËßÑÊ®°ÂàÜÂ≠êÂä®ÂäõÂ≠¶ (MD) Ê®°ÊãüÔºõ3. ÂØπ MLIP ÁöÑÂ∫ïÂ±ÇÂäüËÉΩ‰∫ÜËß£ÊúâÈôê„ÄÇ‰∏∫‰∫ÜËß£ÂÜ≥Ëøô‰∫õÁº∫ÁÇπÔºåÊàë‰ª¨ËÆ§‰∏∫ MLIP Á†îÁ©∂Â∑•‰ΩúÂ∫î‰ºòÂÖàËÄÉËôëÔºö1. ÈááÁî®Êõ¥ÂáÜÁ°ÆÁöÑÊ®°ÊãüÊñπÊ≥ïÊù•ÂàõÂª∫Â§ßËßÑÊ®° MLIP ËÆ≠ÁªÉÊï∞ÊçÆÔºà‰æãÂ¶ÇËÄ¶ÂêàÁ∞áÁêÜËÆ∫ÔºâÔºåÊ∂µÁõñÂπøÊ≥õÁöÑÊùêÊñôËÆæËÆ°Á©∫Èó¥Ôºõ2. ÂàõÂª∫ MLIP ËÆ°ÈáèÂ∑•ÂÖ∑ÔºåÂà©Áî®Â§ßËßÑÊ®°Âü∫ÂáÜÊµãËØï„ÄÅÂèØËßÜÂåñÂíåÂèØËß£ÈáäÊÄßÂàÜÊûêÔºå‰ª•Êõ¥Ê∑±ÂÖ•Âú∞‰∫ÜËß£ MLIP ÁöÑÂÜÖÈÉ®Ëøê‰ΩúÊñπÂºèÔºõ3. ÂºÄÂèëËÆ°ÁÆóÈ´òÊïàÁöÑ MLIP Êù•ÊâßË°å MD Ê®°ÊãüÔºå‰ª•ÂáÜÁ°ÆÂª∫Ê®°ÂπøÊ≥õÁöÑÊùêÊñôÂ±ûÊÄß„ÄÇÊÄª‰πãÔºåËøô‰∫õË∑®Â≠¶ÁßëÁ†îÁ©∂ÊñπÂêëÂèØ‰ª•Â∏ÆÂä©Ëøõ‰∏ÄÊ≠•‰øÉËøõ MLIP ÁöÑÂÆûÈôÖÂ∫îÁî®Ôºå‰ª•ÂáÜÁ°ÆÂú∞Ê®°ÊãüËÆæÂ§áËßÑÊ®°ÁöÑÂ§çÊùÇÊùêÊñô„ÄÇ

##### **Gompertz Linear Units: Leveraging Asymmetry for Enhanced Learning Dynamics**
2502.03654v1 by Indrashis Das, Mahmoud Safari, Steven Adriaensen, Frank Hutter

Activation functions are fundamental elements of deep learning architectures
as they significantly influence training dynamics. ReLU, while widely used, is
prone to the dying neuron problem, which has been mitigated by variants such as
LeakyReLU, PReLU, and ELU that better handle negative neuron outputs. Recently,
self-gated activations like GELU and Swish have emerged as state-of-the-art
alternatives, leveraging their smoothness to ensure stable gradient flow and
prevent neuron inactivity. In this work, we introduce the Gompertz Linear Unit
(GoLU), a novel self-gated activation function defined as $\mathrm{GoLU}(x) = x
\, \mathrm{Gompertz}(x)$, where $\mathrm{Gompertz}(x) = e^{-e^{-x}}$. The GoLU
activation leverages the asymmetry in the Gompertz function to reduce variance
in the latent space more effectively compared to GELU and Swish, while
preserving robust gradient flow. Extensive experiments across diverse tasks,
including Image Classification, Language Modeling, Semantic Segmentation,
Object Detection, Instance Segmentation, and Diffusion, highlight GoLU's
superior performance relative to state-of-the-art activation functions,
establishing GoLU as a robust alternative to existing activation functions.

ÊëòË¶ÅÔºöÊøÄÊ¥ªÂáΩÊï∏ÊòØÊ∑±Â∫¶Â≠∏ÁøíÊû∂ÊßãÁöÑÂü∫Êú¨ÂÖÉÁ¥†ÔºåÂõ†ÁÇ∫ÂÆÉÂÄëÊúÉÈ°ØËëóÂΩ±ÈüøË®ìÁ∑¥ÂãïÊÖã„ÄÇReLU ÈõñÁÑ∂Âª£Ê≥õ‰ΩøÁî®Ôºå‰ΩÜÂÆπÊòìÁôºÁîüÁ•ûÁ∂ìÂÖÉÊ≠ª‰∫°ÂïèÈ°åÔºåËÄå LeakyReLU„ÄÅPReLU Âíå ELU Á≠âËÆäÈ´îÂ∑≤Ê∏õËºï‰∫ÜÊ≠§ÂïèÈ°åÔºåÂÆÉÂÄëËÉΩÊõ¥Â•ΩÂú∞ËôïÁêÜË≤†Á•ûÁ∂ìÂÖÉËº∏Âá∫„ÄÇÊúÄËøëÔºåÂÉè GELU Âíå Swish ÈÄôÊ®£ÁöÑËá™ÈñÄÊéßÊøÄÊ¥ªÂáΩÊï∏Â∑≤ÊàêÁÇ∫ÊúÄÂÖàÈÄ≤ÁöÑÊõø‰ª£ÊñπÊ°àÔºåÂà©Áî®ÂÆÉÂÄëÁöÑÂπ≥ÊªëÊÄß‰æÜÁ¢∫‰øùÁ©©ÂÆöÁöÑÊ¢ØÂ∫¶ÊµÅÂãï‰∏¶Èò≤Ê≠¢Á•ûÁ∂ìÂÖÉ‰∏çÊ¥ªË∫ç„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü Gompertz Á∑öÊÄßÂñÆÂÖÉ (GoLU)ÔºåÈÄôÊòØ‰∏ÄÁ®ÆÊñ∞Á©éÁöÑËá™ÈñÄÊéßÊøÄÊ¥ªÂáΩÊï∏ÔºåÂÆöÁæ©ÁÇ∫ $\mathrm{GoLU}(x) = x \, \mathrm{Gompertz}(x)$ÔºåÂÖ∂‰∏≠ $\mathrm{Gompertz}(x) = e^{-e^{-x}}$„ÄÇGoLU ÊøÄÊ¥ªÂáΩÊï∏Âà©Áî® Gompertz ÂáΩÊï∏‰∏≠ÁöÑ‰∏çÂ∞çÁ®±ÊÄßÔºåËàá GELU Âíå Swish Áõ∏ÊØîÔºåÊõ¥ÊúâÊïàÂú∞Ê∏õÂ∞ëÊΩõÂú®Á©∫Èñì‰∏≠ÁöÑËÆäÁï∞ÔºåÂêåÊôÇ‰øùÁïôÁ©©ÂÅ•ÁöÑÊ¢ØÂ∫¶ÊµÅÂãï„ÄÇÂú®ÂêÑÁ®Æ‰ªªÂãô‰∏≠ÁöÑÂª£Ê≥õÂØ¶È©óÔºåÂåÖÊã¨ÂΩ±ÂÉèÂàÜÈ°û„ÄÅË™ûË®ÄÂª∫Ê®°„ÄÅË™ûÁæ©ÂàÜÂâ≤„ÄÅÁâ©‰ª∂ÂÅµÊ∏¨„ÄÅÂØ¶‰æãÂàÜÂâ≤ÂíåÊì¥Êï£ÔºåÁ™ÅÈ°Ø‰∫Ü GoLU Áõ∏Â∞çÊñºÊúÄÂÖàÈÄ≤ÁöÑÊøÄÊ¥ªÂáΩÊï∏ÁöÑÂÑ™Áï∞ÊïàËÉΩÔºåÁ¢∫Á´ã‰∫Ü GoLU ‰ΩúÁÇ∫ÁèæÊúâÊøÄÊ¥ªÂáΩÊï∏ÁöÑÁ©©ÂÅ•Êõø‰ª£ÊñπÊ°à„ÄÇ

##### **Looking for the Inner Music: Probing LLMs' Understanding of Literary Style**
2502.03647v1 by Rebecca M. M. Hicke, David Mimno

Recent work has demonstrated that language models can be trained to identify
the author of much shorter literary passages than has been thought feasible for
traditional stylometry. We replicate these results for authorship and extend
them to a new dataset measuring novel genre. We find that LLMs are able to
distinguish authorship and genre, but they do so in different ways. Some models
seem to rely more on memorization, while others benefit more from training to
learn author/genre characteristics. We then use three methods to probe one
high-performing LLM for features that define style. These include direct
syntactic ablations to input text as well as two methods that look at model
internals. We find that authorial style is easier to define than genre-level
style and is more impacted by minor syntactic decisions and contextual word
usage. However, some traits like pronoun usage and word order prove significant
for defining both kinds of literary style.

ÊëòË¶ÅÔºöËøëÊúüÁöÑÁ†îÁ©∂È°ØÁ§∫ÔºåË™ûË®ÄÊ®°ÂûãÂèØ‰ª•Êé•ÂèóË®ìÁ∑¥Ôºå‰ª•Ë≠òÂà•ÊØîÂÇ≥Áµ±ÊñáÈ´îÊ∏¨ÈáèÊ≥ïË™çÁÇ∫ÂèØË°åÁöÑÊõ¥Áü≠ÊñáÂ≠∏ÊÆµÁöÑ‰ΩúËÄÖ„ÄÇÊàëÂÄëË§áË£Ω‰∫ÜÈÄô‰∫õ‰ΩúËÄÖË∫´ÂàÜÁµêÊûúÔºå‰∏¶Â∞áÂÖ∂Âª∂‰º∏Âà∞Ê∏¨ÈáèÊñ∞Â∞èË™™È°ûÂûãÁöÑË≥áÊñôÈõÜ„ÄÇÊàëÂÄëÁôºÁèæ LLM ËÉΩÂ§†ÂçÄÂàÜ‰ΩúËÄÖË∫´ÂàÜÂíåÈ°ûÂûãÔºå‰ΩÜÂÆÉÂÄë‰ª•‰∏çÂêåÁöÑÊñπÂºèÂÅöÂà∞ÈÄô‰∏ÄÈªû„ÄÇÊúâ‰∫õÊ®°Âûã‰ºº‰πéÊõ¥‰æùË≥¥ÊñºË®òÊÜ∂ÔºåËÄåÊúâ‰∫õÊ®°ÂûãÂâáÂæûË®ìÁ∑¥‰∏≠ÂèóÁõäÊõ¥Â§öÔºå‰ª•Â≠∏Áøí‰ΩúËÄÖ/È°ûÂûãÁöÑÁâπÂæµ„ÄÇÁÑ∂ÂæåÔºåÊàëÂÄë‰ΩøÁî®‰∏âÁ®ÆÊñπÊ≥ï‰æÜÊé¢Êü•‰∏ÄÂÄãÈ´òÊÄßËÉΩ LLM ‰ª•ÊâæÂá∫ÂÆöÁæ©È¢®Ê†ºÁöÑÁâπÂæµ„ÄÇÈÄô‰∫õÊñπÊ≥ïÂåÖÊã¨Â∞çËº∏ÂÖ•ÊñáÂ≠óÁöÑÁõ¥Êé•Âè•Ê≥ïÊ∂àËûçÔºå‰ª•ÂèäÊü•ÁúãÊ®°ÂûãÂÖßÈÉ®ÁöÑÂÖ©Á®ÆÊñπÊ≥ï„ÄÇÊàëÂÄëÁôºÁèæÔºå‰ΩúËÄÖÈ¢®Ê†ºÊØîÈ°ûÂûãÂ±§Á¥öÈ¢®Ê†ºÊõ¥ÂÆπÊòìÂÆöÁæ©ÔºåËÄå‰∏îÂèóÂà∞ËºÉÂ∞èÁöÑÂè•Ê≥ïÊ±∫Á≠ñÂíåË™ûÂ¢ÉË©ûÂΩô‰ΩøÁî®ÁöÑÂΩ±ÈüøÊõ¥Â§ß„ÄÇÁÑ∂ËÄåÔºåÊüê‰∫õÁâπÂæµÔºàÂ¶Ç‰ª£ÂêçË©û‰ΩøÁî®ÂíåË©ûÂ∫èÔºâÂ∞çÊñºÂÆöÁæ©ÈÄôÂÖ©Á®ÆÊñáÂ≠∏È¢®Ê†ºÈÉΩÈùûÂ∏∏ÈáçË¶Å„ÄÇ

##### **Context-Preserving Gradient Modulation for Large Language Models: A Novel Approach to Semantic Consistency in Long-Form Text Generation**
2502.03643v1 by Nirola Kobanov, Edmund Weatherstone, Zachary Vanderpoel, Orlando Wetherby

Maintaining semantic consistency over extended text sequences remains a
fundamental challenge in long-form text generation, where conventional training
methodologies often struggle to prevent contextual drift and coherence
degradation. A novel gradient modulation approach is introduced, designed to
adjust parameter updates dynamically in response to contextual relevance,
ensuring that generated text remains aligned with prior discourse. By
integrating a modulation function that selectively amplifies or attenuates
gradients based on learned contextual dependencies, the proposed method
enhances the stability of model-generated narratives without imposing
significant computational overhead. Comparative evaluations against baseline
models reveal improvements in coherence, contextual retention, and long-range
dependency tracking, demonstrating the effectiveness of modifying the learning
process at the gradient level. The results indicate that sentence structure
variability and lexical diversity benefit from this approach, mitigating
repetitive phrasing and improving adaptability across diverse linguistic
contexts. Statistical validation of coherence metrics further substantiates the
observed enhancements, with a significant reduction in inconsistencies emerging
as a direct consequence of the modulation mechanism. Computational efficiency
assessments confirm that the framework achieves these gains without requiring
substantial modifications to the underlying architecture, ensuring
compatibility with existing optimization workflows.

ÊëòË¶ÅÔºöÂú®Èï∑ÁØáÊñáÊú¨ÁîüÊàê‰∏≠ÔºåÁ∂≠ÊåÅË™ûÁæ©‰∏ÄËá¥ÊÄßÂú®Âª∂‰º∏ÊñáÊú¨Â∫èÂàó‰∏≠‰ªçÁÑ∂ÊòØ‰∏ÄÂÄãÂü∫Êú¨ÊåëÊà∞ÔºåÂÖ∂‰∏≠ÂÇ≥Áµ±ÁöÑË®ìÁ∑¥ÊñπÊ≥ïÈÄöÂ∏∏Èõ£‰ª•Èò≤Ê≠¢ÊÉÖÂ¢ÉÊºÇÁßªÂíåÁõ∏Âπ≤ÊÄßÈôç‰Ωé„ÄÇÂºïÂÖ•‰∫Ü‰∏ÄÁ®ÆÊñ∞Á©éÁöÑÊ¢ØÂ∫¶Ë™øË£ΩÊñπÊ≥ïÔºåÊó®Âú®Ê†πÊìöÊÉÖÂ¢ÉÁõ∏ÈóúÊÄßÂãïÊÖãË™øÊï¥ÂèÉÊï∏Êõ¥Êñ∞ÔºåÁ¢∫‰øùÁîüÊàêÁöÑÊñáÊú¨ËàáÂÖàÂâçÁöÑË™ûÁØá‰øùÊåÅ‰∏ÄËá¥„ÄÇÈÄöÈÅéÊï¥Âêà‰∏ÄÂÄãË™øË£ΩÂáΩÊï∏ÔºåÊ†πÊìöÂ≠∏ÁøíÂà∞ÁöÑÊÉÖÂ¢É‰æùË≥¥Èóú‰øÇÈÅ∏ÊìáÊÄßÂú∞ÊîæÂ§ßÊàñË°∞Ê∏õÊ¢ØÂ∫¶ÔºåÊâÄÊèêÂá∫ÁöÑÊñπÊ≥ïÂ¢ûÂº∑‰∫ÜÊ®°ÂûãÁîüÊàêÁöÑÊïò‰∫ãÁöÑÁ©©ÂÆöÊÄßÔºåËÄå‰∏çÊúÉÈÄ†ÊàêÈ°ØËëóÁöÑË®àÁÆóÈñãÈä∑„ÄÇËàáÂü∫Ê∫ñÊ®°ÂûãÁöÑÊØîËºÉË©ï‰º∞È°ØÁ§∫Âá∫Áõ∏Âπ≤ÊÄß„ÄÅÊÉÖÂ¢É‰øùÁïôÂíåÈï∑Á®ã‰æùË≥¥ÊÄßËøΩËπ§ÁöÑÊîπÈÄ≤ÔºåË≠âÊòé‰∫ÜÂú®Ê¢ØÂ∫¶Â±§Á¥ö‰øÆÊîπÂ≠∏ÁøíÈÅéÁ®ãÁöÑÊúâÊïàÊÄß„ÄÇÁµêÊûúË°®ÊòéÔºåÂè•Â≠êÁµêÊßãËÆäÁï∞ÊÄßÂíåË©ûÂΩôÂ§öÊ®£ÊÄßÂæûÈÄôÁ®ÆÊñπÊ≥ï‰∏≠ÂèóÁõäÔºåÊ∏õËºï‰∫ÜÈáçË§áÁöÑË°®Ëø∞Ôºå‰∏¶ÊèêÈ´ò‰∫ÜÂú®‰∏çÂêåË™ûË®ÄÊÉÖÂ¢É‰∏≠ÁöÑÈÅ©ÊáâÊÄß„ÄÇÁõ∏Âπ≤ÊÄßÊåáÊ®ôÁöÑÁµ±Ë®àÈ©óË≠âÈÄ≤‰∏ÄÊ≠•Ë≠âÂØ¶‰∫ÜËßÄÂØüÂà∞ÁöÑÂ¢ûÂº∑ÔºåÁî±ÊñºË™øË£ΩÊ©üÂà∂ÁöÑÁõ¥Êé•ÂæåÊûúÔºå‰∏ç‰∏ÄËá¥ÊÄßÈ°ØËëóÊ∏õÂ∞ë„ÄÇË®àÁÆóÊïàÁéáË©ï‰º∞Á¢∫Ë™çÔºåË©≤Ê°ÜÊû∂Âú®‰∏çÈúÄÂ∞çÂ∫ïÂ±§Êû∂ÊßãÈÄ≤Ë°åÂ§ßÂπÖ‰øÆÊîπÁöÑÊÉÖÊ≥Å‰∏ãÂØ¶Áèæ‰∫ÜÈÄô‰∫õÂ¢ûÁõäÔºåÁ¢∫‰øùËàáÁèæÊúâÊúÄ‰Ω≥ÂåñÂ∑•‰ΩúÊµÅÁ®ãÁöÑÁõ∏ÂÆπÊÄß„ÄÇ

##### **REALEDIT: Reddit Edits As a Large-scale Empirical Dataset for Image Transformations**
2502.03629v1 by Peter Sushko, Ayana Bharadwaj, Zhi Yang Lim, Vasily Ilin, Ben Caffee, Dongping Chen, Mohammadreza Salehi, Cheng-Yu Hsieh, Ranjay Krishna

Existing image editing models struggle to meet real-world demands. Despite
excelling in academic benchmarks, they have yet to be widely adopted for real
user needs. Datasets that power these models use artificial edits, lacking the
scale and ecological validity necessary to address the true diversity of user
requests. We introduce REALEDIT, a large-scale image editing dataset with
authentic user requests and human-made edits sourced from Reddit. REALEDIT
includes a test set of 9300 examples to evaluate models on real user requests.
Our results show that existing models fall short on these tasks, highlighting
the need for realistic training data. To address this, we introduce 48K
training examples and train our REALEDIT model, achieving substantial gains -
outperforming competitors by up to 165 Elo points in human judgment and 92
percent relative improvement on the automated VIEScore metric. We deploy our
model on Reddit, testing it on new requests, and receive positive feedback.
Beyond image editing, we explore REALEDIT's potential in detecting edited
images by partnering with a deepfake detection non-profit. Finetuning their
model on REALEDIT data improves its F1-score by 14 percentage points,
underscoring the dataset's value for broad applications.

ÊëòË¶ÅÔºöÁèæÊúâÁöÑÂΩ±ÂÉèÁ∑®ËºØÊ®°ÂûãÈõ£‰ª•ÊªøË∂≥ÁèæÂØ¶‰∏ñÁïåÁöÑÈúÄÊ±Ç„ÄÇÂÑòÁÆ°Âú®Â≠∏Ë°ìÂü∫Ê∫ñ‰∏äË°®ÁèæÂÑ™Áï∞Ôºå‰ΩÜÂÆÉÂÄëÂ∞öÊú™Âª£Ê≥õÁî®ÊñºÊªøË∂≥ÂØ¶ÈöõÁöÑ‰ΩøÁî®ËÄÖÈúÄÊ±Ç„ÄÇÈ©ÖÂãïÈÄô‰∫õÊ®°ÂûãÁöÑË≥áÊñôÈõÜ‰ΩøÁî®‰∫∫Â∑•Á∑®ËºØÔºåÁº∫‰πèËôïÁêÜ‰ΩøÁî®ËÄÖË¶ÅÊ±ÇÁúüÂØ¶Â§öÊ®£ÊÄßÁöÑË¶èÊ®°ÂíåÁîüÊÖãÊïàÂ∫¶„ÄÇÊàëÂÄëÊé®Âá∫ REALEDITÔºå‰∏ÄÂÄãÂÖ∑ÊúâÁúüÂØ¶‰ΩøÁî®ËÄÖË¶ÅÊ±ÇÂíå‰æÜËá™ Reddit ÁöÑ‰∫∫ÁÇ∫Á∑®ËºØÁöÑÂ§ßË¶èÊ®°ÂΩ±ÂÉèÁ∑®ËºØË≥áÊñôÈõÜ„ÄÇREALEDIT ÂåÖÂê´‰∏ÄÂÄã 9300 ÂÄãÁØÑ‰æãÁöÑÊ∏¨Ë©¶ÈõÜÔºåÁî®ÊñºË©ï‰º∞Ê®°ÂûãÂ∞çÁúüÂØ¶‰ΩøÁî®ËÄÖË¶ÅÊ±ÇÁöÑË°®Áèæ„ÄÇÊàëÂÄëÁöÑÁµêÊûúÈ°ØÁ§∫ÔºåÁèæÊúâÁöÑÊ®°ÂûãÂú®ÈÄô‰∫õ‰ªªÂãô‰∏äË°®Áèæ‰∏ç‰Ω≥ÔºåÁ™ÅÈ°Ø‰∫ÜÂ∞çÁúüÂØ¶Ë®ìÁ∑¥Ë≥áÊñôÁöÑÈúÄÊ±Ç„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü 48K ÂÄãË®ìÁ∑¥ÁØÑ‰æãÔºå‰∏¶Ë®ìÁ∑¥ÊàëÂÄëÁöÑ REALEDIT Ê®°ÂûãÔºåÂèñÂæó‰∫ÜÈ°ØËëóÁöÑÈÄ≤Â±ï - Âú®‰∫∫È°ûÂà§Êñ∑‰∏≠È†òÂÖàÁ´∂Áà≠Â∞çÊâãÂ§öÈÅî 165 Elo ÈªûÔºåÂú®Ëá™ÂãïÂåñ VIEScore ÊåáÊ®ô‰∏äÁõ∏Â∞çÊîπÂñÑ‰∫Ü 92%„ÄÇÊàëÂÄëÂú® Reddit ‰∏äÈÉ®ÁΩ≤ÊàëÂÄëÁöÑÊ®°ÂûãÔºåÂ∞çÊñ∞ÁöÑË¶ÅÊ±ÇÈÄ≤Ë°åÊ∏¨Ë©¶Ôºå‰∏¶Êî∂Âà∞Ê≠£Èù¢ÁöÑÂõûÈ•ã„ÄÇÈô§‰∫ÜÂΩ±ÂÉèÁ∑®ËºØ‰πãÂ§ñÔºåÊàëÂÄëÈÇÑÊé¢Á¥¢‰∫Ü REALEDIT Âú®ÂÅµÊ∏¨Á∑®ËºØÈÅéÂΩ±ÂÉèÁöÑÊΩõÂäõÔºå‰∏¶Ëàá‰∏ÄÂÆ∂ÈùûÁáüÂà©ÁöÑÊ∑±Â∫¶ÂÅΩÈÄ†ÂÅµÊ∏¨ÂÖ¨Âè∏Âêà‰Ωú„ÄÇÂú® REALEDIT Ë≥áÊñôÈõÜ‰∏äÂæÆË™ø‰ªñÂÄëÁöÑÊ®°ÂûãÔºåÂ∞áÂÖ∂ F1 ÂàÜÊï∏ÊèêÈ´ò‰∫Ü 14 ÂÄãÁôæÂàÜÈªûÔºåÁ™ÅÈ°Ø‰∫ÜË©≤Ë≥áÊñôÈõÜÂ∞çÂª£Ê≥õÊáâÁî®Á®ãÂºèÁöÑÂÉπÂÄº„ÄÇ

##### **The Hidden Life of Tokens: Reducing Hallucination of Large Vision-Language Models via Visual Information Steering**
2502.03628v1 by Zhuowei Li, Haizhou Shi, Yunhe Gao, Di Liu, Zhenting Wang, Yuxiao Chen, Ting Liu, Long Zhao, Hao Wang, Dimitris N. Metaxas

Large Vision-Language Models (LVLMs) can reason effectively over both textual
and visual inputs, but they tend to hallucinate syntactically coherent yet
visually ungrounded contents. In this paper, we investigate the internal
dynamics of hallucination by examining the tokens logits rankings throughout
the generation process, revealing three key patterns in how LVLMs process
information: (1) gradual visual information loss -- visually grounded tokens
gradually become less favored throughout generation, and (2) early excitation
-- semantically meaningful tokens achieve peak activation in the layers earlier
than the final layer. (3) hidden genuine information -- visually grounded
tokens though not being eventually decided still retain relatively high
rankings at inference. Based on these insights, we propose VISTA (Visual
Information Steering with Token-logit Augmentation), a training-free
inference-time intervention framework that reduces hallucination while
promoting genuine information. VISTA works by combining two complementary
approaches: reinforcing visual information in activation space and leveraging
early layer activations to promote semantically meaningful decoding. Compared
to existing methods, VISTA requires no external supervision and is applicable
to various decoding strategies. Extensive experiments show that VISTA on
average reduces hallucination by abount 40% on evaluated open-ended generation
task, and it consistently outperforms existing methods on four benchmarks
across four architectures under three decoding strategies.

ÊëòË¶ÅÔºöÂ§ßÂûãË¶ñË¶∫Ë™ûË®ÄÊ®°Âûã (LVLMs) ÂèØ‰ª•ÊúâÊïàÂú∞Â∞çÊñáÊú¨ÂíåË¶ñË¶∫Ëº∏ÂÖ•ÈÄ≤Ë°åÊé®ÁêÜÔºå‰ΩÜÂÆÉÂÄëÂÇæÂêëÊñºÁî¢ÁîüË™ûÊ≥ï‰∏äÈÄ£Ë≤´‰ΩÜË¶ñË¶∫‰∏äÊ≤íÊúâÊ†πÊìöÁöÑÂÖßÂÆπ„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÈÄöÈÅéÊ™¢Êü•Êï¥ÂÄãÁîüÊàêÈÅéÁ®ã‰∏≠ÁöÑ‰ª£Âπ£Â∞çÊï∏Ê¶ÇÁéáÊéíÂêçÔºåÊé¢Ë®é‰∫ÜÂπªË¶∫ÁöÑÂÖßÈÉ®ÂãïÊÖãÔºåÊè≠Á§∫‰∫Ü LVLMs ËôïÁêÜË≥áË®äÁöÑ‰∏âÂÄãÈóúÈçµÊ®°ÂºèÔºö(1) ÈÄêÊº∏ÁöÑË¶ñË¶∫Ë≥áË®äÊêçÂ§±‚Äî‚ÄîË¶ñË¶∫‰∏äÁ¥ÆÂØ¶ÁöÑ‰ª£Âπ£Âú®Êï¥ÂÄãÁîüÊàêÈÅéÁ®ã‰∏≠ÈÄêÊº∏ËÆäÂæó‰∏çÈÇ£È∫ºÂèóÊ≠°ËøéÔºå‰ª•Âèä (2) Êó©ÊúüÊøÄÂãµ‚Äî‚ÄîË™ûÁæ©‰∏äÊúâÊÑèÁæ©ÁöÑ‰ª£Âπ£Âú®ÊØîÊúÄÂæå‰∏ÄÂ±§Êõ¥Êó©ÁöÑÂ±§‰∏≠ÈÅîÂà∞Â≥∞ÂÄºÊøÄÊ¥ª„ÄÇ(3) Èö±ËóèÁöÑÁúüÂØ¶Ë≥áË®ä‚Äî‚ÄîË¶ñË¶∫‰∏äÁ¥ÆÂØ¶ÁöÑ‰ª£Âπ£ÂÑòÁÆ°ÊúÄÁµÇÊ≤íÊúâË¢´Ê±∫ÂÆöÔºå‰ΩÜ‰ªç‰øùÁïô‰∫ÜÁõ∏Â∞çËºÉÈ´òÁöÑÊé®Ë´ñÊéíÂêç„ÄÇÊ†πÊìöÈÄô‰∫õË¶ãËß£ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü VISTAÔºà‰ΩøÁî®‰ª£Âπ£Â∞çÊï∏Ê¶ÇÁéáÂ¢ûÂº∑ÁöÑË¶ñË¶∫Ë≥áË®äÂ∞éÂêëÔºâÔºåÈÄôÊòØ‰∏ÄÂÄãÂÖçË®ìÁ∑¥ÁöÑÊé®Ë´ñÊôÇÈñì‰ªãÂÖ•Ê°ÜÊû∂ÔºåÂèØÊ∏õÂ∞ëÂπªË¶∫ÔºåÂêåÊôÇ‰øÉÈÄ≤ÁúüÂØ¶Ë≥áË®ä„ÄÇVISTA ÁöÑÂ∑•‰ΩúÂéüÁêÜÊòØÁµêÂêàÂÖ©Á®Æ‰∫íË£úÁöÑÊñπÊ≥ïÔºöÂú®ÊøÄÊ¥ªÁ©∫Èñì‰∏≠Âä†Âº∑Ë¶ñË¶∫Ë≥áË®ä‰∏¶Âà©Áî®Êó©ÊúüÂ±§ÊøÄÊ¥ª‰æÜ‰øÉÈÄ≤Ë™ûÁæ©‰∏äÊúâÊÑèÁæ©ÁöÑËß£Á¢º„ÄÇËàáÁèæÊúâÊñπÊ≥ïÁõ∏ÊØîÔºåVISTA ‰∏çÈúÄË¶ÅÂ§ñÈÉ®Áõ£Áù£Ôºå‰∏¶‰∏îÈÅ©Áî®ÊñºÂêÑÁ®ÆËß£Á¢ºÁ≠ñÁï•„ÄÇÂ§ßÈáèÁöÑÂØ¶È©óË°®ÊòéÔºåVISTA Âπ≥ÂùáÂèØÂ∞áË©ï‰º∞ÁöÑÈñãÊîæÂºèÁîüÊàê‰ªªÂãôÁöÑÂπªË¶∫Ê∏õÂ∞ëÁ¥Ñ 40%Ôºå‰∏¶‰∏îÂú®ÂõõÁ®ÆÊû∂Êßã‰∏ãÁöÑÂõõÂÄãÂü∫Ê∫ñÊ∏¨Ë©¶‰∏≠ÔºåÂú®‰∏âÁ®ÆËß£Á¢ºÁ≠ñÁï•‰∏ãÂßãÁµÇÂÑ™ÊñºÁèæÊúâÊñπÊ≥ï„ÄÇ

##### **Sorting the Babble in Babel: Assessing the Performance of Language Detection Algorithms on the OpenAlex Database**
2502.03627v1 by Maxime Holmberg Sainte-Marie, Diego Kozlowski, Luc√≠a C√©spedes, Vincent Larivi√®re

Following a recent study on the quality of OpenAlex linguistic metadata
(C\'espedes et al., 2025), the present paper aims to optimize the latter
through the design, use, and evaluation of various linguistic classification
procedures based on the latest and most efficient automatic language detection
algorithms. Starting from a multilingual set of manually-annotated samples of
articles indexed in the database, different classification procedures are then
designed, based on the application of a set of language detection algorithms on
a series of corpora generated from different combinations of textual metadata
of indexed articles. At sample level first, the performance of these different
procedures for each of the main languages in the database is evaluated in terms
of precision, recall, and processing time. Then, overall procedure performance
is estimated at the database level by means of a probabilistic simulation of
harmonically aggregated and weighted scores. Results show that procedure
performance strongly depends on the importance given to each of the measures
implemented: for contexts where precision is preferred, using the LangID
algorithm on article titles, abstracts as well as journal names gives the best
results; however, for all cases where recall is considered at least slightly
more important than precision or as soon as processing times are given any kind
of consideration, use of the FastSpell algorithm on article titles only
outperforms all other alternatives. Given the lack of truly multilingual,
large-scale bibliographic databases, it is hoped that these results help
confirm and foster the unparalleled potential of the OpenAlex database for
cross-linguistic, bibliometric-based research and analysis.

ÊëòË¶ÅÔºö<paragraph>Ê†πÊìö OpenAlex Ë™ûË®ÄÂÖÉË≥áÊñôÂìÅË≥™ÁöÑÊúÄÊñ∞Á†îÁ©∂ (C\'espedes Á≠â‰∫∫Ôºå2025)ÔºåÊú¨ÊñáÊó®Âú®ÈÄèÈÅéË®≠Ë®à„ÄÅ‰ΩøÁî®ÂíåË©ï‰º∞ÂêÑÁ®ÆË™ûË®ÄÂàÜÈ°ûÁ®ãÂ∫èÔºå‰ª•ÂèäÊ†πÊìöÊúÄÊñ∞‰∏îÊúÄÊúâÊïàÁéáÁöÑËá™ÂãïË™ûË®ÄÂÅµÊ∏¨ÊºîÁÆóÊ≥ïÔºå‰æÜÊúÄ‰Ω≥ÂåñÂæåËÄÖ„ÄÇÂæûË≥áÊñôÂ∫´‰∏≠Á¥¢ÂºïÁöÑÊñáÁ´†ÊâãÂãïÊ®ôË®ªÁöÑÂ§öË™ûË®ÄÁØÑ‰æãÈñãÂßãÔºåÊé•ËëóË®≠Ë®à‰∏çÂêåÁöÑÂàÜÈ°ûÁ®ãÂ∫èÔºåÊ†πÊìö‰∏ÄÁ≥ªÂàóË™ûÊñôÂ∫´ÊáâÁî®‰∏ÄÁµÑË™ûË®ÄÂÅµÊ∏¨ÊºîÁÆóÊ≥ïÔºåÈÄô‰∫õË™ûÊñôÂ∫´ÊòØÁî±Á¥¢ÂºïÊñáÁ´†ÁöÑÊñáÂ≠óÂÖÉË≥áÊñôÁöÑ‰∏çÂêåÁµÑÂêàÁî¢Áîü„ÄÇÈ¶ñÂÖàÂú®ÁØÑ‰æãÂ±§Á¥öÔºåË©ï‰º∞ÈÄô‰∫õ‰∏çÂêåÁ®ãÂ∫èÂú®Ë≥áÊñôÂ∫´‰∏≠ÊØèÁ®Æ‰∏ªË¶ÅË™ûË®ÄÁöÑÊïàËÉΩÔºåÂåÖÊã¨Ê∫ñÁ¢∫Â∫¶„ÄÅÂè¨ÂõûÁéáÂíåËôïÁêÜÊôÇÈñì„ÄÇÊé•ËëóÔºåÈÄèÈÅéÂ∞çË™øÂíåÂΩôÁ∏ΩÂíåÂä†Ê¨äÂàÜÊï∏ÈÄ≤Ë°åÊ©üÁéáÊ®°Êì¨Ôºå‰º∞Ë®àÂú®Ë≥áÊñôÂ∫´Â±§Á¥öÁöÑÊï¥È´îÁ®ãÂ∫èÊïàËÉΩ„ÄÇÁµêÊûúÈ°ØÁ§∫ÔºåÁ®ãÂ∫èÊïàËÉΩÈ´òÂ∫¶‰ª∞Ë≥¥ÊâÄÂØ¶ÊñΩÁöÑÊØèÂÄãÊåáÊ®ôÊâÄË≥¶‰∫àÁöÑÈáçË¶ÅÊÄßÔºöÂú®ÂÑ™ÂÖàËÄÉÊÖÆÊ∫ñÁ¢∫Â∫¶ÁöÑËÑàÁµ°‰∏≠ÔºåÂ∞çÊñáÁ´†Ê®ôÈ°å„ÄÅÊëòË¶ÅÂíåÊúüÂàäÂêçÁ®±‰ΩøÁî® LangID ÊºîÁÆóÊ≥ïÊúÉÁî¢ÁîüÊúÄ‰Ω≥ÁµêÊûúÔºõÁÑ∂ËÄåÔºåÂú®ÊâÄÊúâÂè¨ÂõûÁéáË¢´Ë™çÁÇ∫Ëá≥Â∞ëÊØîÊ∫ñÁ¢∫Â∫¶Á®çÈáçË¶ÅÔºåÊàñÂú®‰ªª‰ΩïËÄÉÈáèËôïÁêÜÊôÇÈñìÁöÑÊÉÖÊ≥Å‰∏ãÔºåÂÉÖÂ∞çÊñáÁ´†Ê®ôÈ°å‰ΩøÁî® FastSpell ÊºîÁÆóÊ≥ïÊúÉÂÑ™ÊñºÊâÄÊúâÂÖ∂‰ªñÊõø‰ª£ÊñπÊ°à„ÄÇÁî±ÊñºÁº∫‰πèÁúüÊ≠£Â§öË™ûË®Ä„ÄÅÂ§ßË¶èÊ®°ÁöÑÊõ∏ÁõÆË≥áÊñôÂ∫´ÔºåÊàëÂÄëÂ∏åÊúõÈÄô‰∫õÁµêÊûúÊúâÂä©ÊñºÁ¢∫Ë™çÂíå‰øÉÈÄ≤ OpenAlex Ë≥áÊñôÂ∫´Âú®Ë∑®Ë™ûË®Ä„ÄÅ‰ª•Êõ∏ÁõÆË®àÈáèÁÇ∫Âü∫Á§éÁöÑÁ†îÁ©∂ÂíåÂàÜÊûêÊñπÈù¢ÁöÑÁÑ°ËàáÂÄ´ÊØîÊΩõÂäõ„ÄÇ</paragraph>

##### **AdaPhish: AI-Powered Adaptive Defense and Education Resource Against Deceptive Emails**
2502.03622v1 by Rei Meguro, Ng S. T. Chong

Phishing attacks remain a significant threat in the digital age, yet
organizations lack effective methods to tackle phishing attacks without leaking
sensitive information. Phish bowl initiatives are a vital part of cybersecurity
efforts against these attacks. However, traditional phish bowls require manual
anonymization and are often limited to internal use. To overcome these
limitations, we introduce AdaPhish, an AI-powered phish bowl platform that
automatically anonymizes and analyzes phishing emails using large language
models (LLMs) and vector databases. AdaPhish achieves real-time detection and
adaptation to new phishing tactics while enabling long-term tracking of
phishing trends. Through automated reporting, adaptive analysis, and real-time
alerts, AdaPhish presents a scalable, collaborative solution for phishing
detection and cybersecurity education.

ÊëòË¶ÅÔºöÁ∂≤Èá£ÊîªÊìäÂú®Êï∏‰ΩçÊôÇ‰ª£‰ªçÊòØ‰∏ÄÂÄãÈáçÂ§ßÁöÑÂ®ÅËÑÖÔºå‰ΩÜÁµÑÁπîÁº∫‰πèÊúâÊïàÁöÑÊñπÊ≥ï‰æÜËôïÁêÜÁ∂≤Èá£ÊîªÊìäÔºåËÄå‰∏çÊúÉÊ¥©Èú≤ÊïèÊÑüË≥áË®ä„ÄÇÁ∂≤Èá£‰ø°ÁÆ±Ë®àÁï´ÊòØÂ∞çÊäóÈÄô‰∫õÊîªÊìäÁöÑÁ∂≤Ë∑ØÂÆâÂÖ®Êé™ÊñΩ‰∏≠Ëá≥ÈóúÈáçË¶ÅÁöÑ‰∏ÄÈÉ®ÂàÜ„ÄÇÁÑ∂ËÄåÔºåÂÇ≥Áµ±ÁöÑÁ∂≤Èá£‰ø°ÁÆ±ÈúÄË¶ÅÊâãÂãïÂåøÂêçÂåñÔºåËÄå‰∏îÈÄöÂ∏∏ÂÉÖÈôêÊñºÂÖßÈÉ®‰ΩøÁî®„ÄÇÁÇ∫‰∫ÜÂÖãÊúçÈÄô‰∫õÈôêÂà∂ÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü AdaPhishÔºå‰∏ÄÂÄãÁî± AI È©ÖÂãïÁöÑÁ∂≤Èá£‰ø°ÁÆ±Âπ≥Âè∞ÔºåÂÆÉ‰ΩøÁî®Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÂíåÂêëÈáèË≥áÊñôÂ∫´Ëá™ÂãïÂåøÂêçÂåñ‰∏¶ÂàÜÊûêÁ∂≤Èá£ÈõªÂ≠êÈÉµ‰ª∂„ÄÇAdaPhish ÂèØÂç≥ÊôÇÂÅµÊ∏¨‰∏¶ÈÅ©ÊáâÊñ∞ÁöÑÁ∂≤Èá£Á≠ñÁï•ÔºåÂêåÊôÇËÉΩÈï∑ÊúüËøΩËπ§Á∂≤Èá£Ë∂®Âã¢„ÄÇÈÄèÈÅéËá™ÂãïÂåñÂ†±Âëä„ÄÅÈÅ©ÊáâÊÄßÂàÜÊûêÂíåÂç≥ÊôÇË≠¶Á§∫ÔºåAdaPhish ÊèêÂá∫‰∫Ü‰∏ÄÂÄãÂèØÊì¥ÂÖÖ„ÄÅÂçî‰ΩúÁöÑËß£Ê±∫ÊñπÊ°àÔºåÁî®ÊñºÁ∂≤Èá£ÂÅµÊ∏¨ÂíåÁ∂≤Ë∑ØÂÆâÂÖ®ÊïôËÇ≤„ÄÇ

##### **A Novel Zero-Touch, Zero-Trust, AI/ML Enablement Framework for IoT Network Security**
2502.03614v1 by Sushil Shakya, Robert Abbas, Sasa Maric

The IoT facilitates a connected, intelligent, and sustainable society;
therefore, it is imperative to protect the IoT ecosystem. The IoT-based 5G and
6G will leverage the use of machine learning and artificial intelligence
(ML/AI) more to pave the way for autonomous and collaborative secure IoT
networks. Zero-touch, zero-trust IoT security with AI and machine learning (ML)
enablement frameworks offers a powerful approach to securing the expanding
landscape of Internet of Things (IoT) devices. This paper presents a novel
framework based on the integration of Zero Trust, Zero Touch, and AI/ML powered
for the detection, mitigation, and prevention of DDoS attacks in modern IoT
ecosystems. The focus will be on the new integrated framework by establishing
zero trust for all IoT traffic, fixed and mobile 5G/6G IoT network traffic, and
data security (quarantine-zero touch and dynamic policy enforcement). We
perform a comparative analysis of five machine learning models, namely,
XGBoost, Random Forest, K-Nearest Neighbors, Stochastic Gradient Descent, and
Native Bayes, by comparing these models based on accuracy, precision, recall,
F1-score, and ROC-AUC. Results show that the best performance in detecting and
mitigating different DDoS vectors comes from the ensemble-based approaches.

ÊëòË¶ÅÔºöÁâ©ËÅØÁ∂≤‰øÉÈÄ≤‰∏ÄÂÄã‰∫íËÅØ„ÄÅÊô∫ÊÖß‰∏îÊ∞∏Á∫åÁöÑÁ§æÊúÉÔºõÂõ†Ê≠§Ôºå‰øùË≠∑Áâ©ËÅØÁ∂≤ÁîüÊÖãÁ≥ªÁµ±Ëá≥ÈóúÈáçË¶Å„ÄÇÂü∫ÊñºÁâ©ËÅØÁ∂≤ÁöÑ 5G Âíå 6G Â∞áÊõ¥Â§öÂú∞Âà©Áî®Ê©üÂô®Â≠∏ÁøíÂíå‰∫∫Â∑•Êô∫ÊÖß (ML/AI)ÔºåÁÇ∫Ëá™‰∏ª‰∏îÂçî‰ΩúÁöÑÂÆâÂÖ®Áâ©ËÅØÁ∂≤Á∂≤Ë∑ØÈã™Ë∑Ø„ÄÇÈõ∂Êé•Ëß∏„ÄÅÈõ∂‰ø°‰ªªÁöÑÁâ©ËÅØÁ∂≤ÂÆâÂÖ®ÊÄßÔºåÂÖ∑ÂÇô AI ÂíåÊ©üÂô®Â≠∏Áøí (ML) ÂïüÁî®Êû∂ÊßãÔºåÊèê‰æõ‰∏ÄÁ®ÆÂº∑Â§ßÁöÑÊñπÊ≥ï‰æÜ‰øùË≠∑‰∏çÊñ∑Êì¥Â±ïÁöÑÁâ©ËÅØÁ∂≤ (IoT) Ë£ùÁΩÆÈ†òÂüü„ÄÇÊú¨ÊñáÊèêÂá∫‰∏ÄÂÄãÊñ∞Á©éÁöÑÊû∂ÊßãÔºåÂü∫ÊñºÈõ∂‰ø°‰ªª„ÄÅÈõ∂Êé•Ëß∏Âíå AI/ML ÁöÑÊï¥ÂêàÔºåÁî®ÊñºÂÅµÊ∏¨„ÄÅÊ∏õËºïÂíåÈ†êÈò≤Áèæ‰ª£Áâ©ËÅØÁ∂≤ÁîüÊÖãÁ≥ªÁµ±‰∏≠ÁöÑ DDoS ÊîªÊìä„ÄÇÈáçÈªûÂ∞áÊîæÂú®Êñ∞ÁöÑÊï¥ÂêàÊû∂Êßã‰∏äÔºåÁÇ∫ÊâÄÊúâÁâ©ËÅØÁ∂≤ÊµÅÈáè„ÄÅÂõ∫Á∂≤ÂíåË°åÂãï 5G/6G Áâ©ËÅØÁ∂≤Á∂≤Ë∑ØÊµÅÈáè‰ª•ÂèäË≥áÊñôÂÆâÂÖ®ÊÄßÔºàÈöîÈõ¢Èõ∂Êé•Ëß∏ÂíåÂãïÊÖãÊîøÁ≠ñÂº∑Âà∂Âü∑Ë°åÔºâÂª∫Á´ãÈõ∂‰ø°‰ªª„ÄÇÊàëÂÄëÂ∞ç‰∫îÁ®ÆÊ©üÂô®Â≠∏ÁøíÊ®°ÂûãÈÄ≤Ë°åÊØîËºÉÂàÜÊûêÔºåÂç≥ XGBoost„ÄÅÈö®Ê©üÊ£ÆÊûó„ÄÅK ÊúÄËøëÈÑ∞„ÄÅÈö®Ê©üÊ¢ØÂ∫¶‰∏ãÈôçÂíåÂéüÁîüË≤ùÊ∞èÔºå‰∏¶Ê†πÊìöÊ∫ñÁ¢∫Â∫¶„ÄÅÁ≤æÁ¢∫Â∫¶„ÄÅÂè¨ÂõûÁéá„ÄÅF1 ÂàÜÊï∏Âíå ROC-AUC ÊØîËºÉÈÄô‰∫õÊ®°Âûã„ÄÇÁµêÊûúÈ°ØÁ§∫ÔºåÂú®ÂÅµÊ∏¨ÂíåÊ∏õËºï‰∏çÂêå DDoS ÂêëÈáèÊñπÈù¢ÔºåË°®ÁèæÊúÄ‰Ω≥ÁöÑÊòØÂü∫ÊñºÊï¥È´îÁöÑÊñπÊ≥ï„ÄÇ

