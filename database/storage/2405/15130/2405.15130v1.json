{"2405.15130": {"publish_time": "2024-05-24", "title": "OptLLM: Optimal Assignment of Queries to Large Language Models", "paper_summary": "Large Language Models (LLMs) have garnered considerable attention owing to\ntheir remarkable capabilities, leading to an increasing number of companies\noffering LLMs as services. Different LLMs achieve different performance at\ndifferent costs. A challenge for users lies in choosing the LLMs that best fit\ntheir needs, balancing cost and performance. In this paper, we propose a\nframework for addressing the cost-effective query allocation problem for LLMs.\nGiven a set of input queries and candidate LLMs, our framework, named OptLLM,\nprovides users with a range of optimal solutions to choose from, aligning with\ntheir budget constraints and performance preferences, including options for\nmaximizing accuracy and minimizing cost. OptLLM predicts the performance of\ncandidate LLMs on each query using a multi-label classification model with\nuncertainty estimation and then iteratively generates a set of non-dominated\nsolutions by destructing and reconstructing the current solution. To evaluate\nthe effectiveness of OptLLM, we conduct extensive experiments on various types\nof tasks, including text classification, question answering, sentiment\nanalysis, reasoning, and log parsing. Our experimental results demonstrate that\nOptLLM substantially reduces costs by 2.40% to 49.18% while achieving the same\naccuracy as the best LLM. Compared to other multi-objective optimization\nalgorithms, OptLLM improves accuracy by 2.94% to 69.05% at the same cost or\nsaves costs by 8.79% and 95.87% while maintaining the highest attainable\naccuracy.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u56e0\u5176\u5353\u8d8a\u7684\u80fd\u529b\u800c\u5099\u53d7\u95dc\u6ce8\uff0c\u5c0e\u81f4\u8d8a\u4f86\u8d8a\u591a\u7684\u516c\u53f8\u5c07 LLM \u4f5c\u70ba\u670d\u52d9\u63d0\u4f9b\u3002\u4e0d\u540c\u7684 LLM \u4ee5\u4e0d\u540c\u7684\u6210\u672c\u5be6\u73fe\u4e0d\u540c\u7684\u6548\u80fd\u3002\u4f7f\u7528\u8005\u9762\u81e8\u7684\u6311\u6230\u5728\u65bc\u9078\u64c7\u6700\u7b26\u5408\u5176\u9700\u6c42\u7684 LLM\uff0c\u4e26\u5728\u6210\u672c\u548c\u6548\u80fd\u4e4b\u9593\u53d6\u5f97\u5e73\u8861\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u63d0\u51fa\u4e00\u500b\u89e3\u6c7a LLM \u7684\u7d93\u6fdf\u6709\u6548\u67e5\u8a62\u5206\u914d\u554f\u984c\u7684\u67b6\u69cb\u3002\u7d66\u5b9a\u4e00\u7d44\u8f38\u5165\u67e5\u8a62\u548c\u5019\u9078 LLM\uff0c\u6211\u5011\u540d\u70ba OptLLM \u7684\u67b6\u69cb\u70ba\u4f7f\u7528\u8005\u63d0\u4f9b\u4e00\u7cfb\u5217\u6700\u4f73\u89e3\u4f9b\u5176\u9078\u64c7\uff0c\u7b26\u5408\u5176\u9810\u7b97\u9650\u5236\u548c\u6548\u80fd\u504f\u597d\uff0c\u5305\u62ec\u6700\u5927\u5316\u6e96\u78ba\u5ea6\u548c\u6700\u5c0f\u5316\u6210\u672c\u7684\u9078\u9805\u3002OptLLM \u4f7f\u7528\u5177\u6709\u4e0d\u78ba\u5b9a\u6027\u4f30\u8a08\u7684\u591a\u6a19\u7c64\u5206\u985e\u6a21\u578b\u9810\u6e2c\u5019\u9078 LLM \u5728\u6bcf\u500b\u67e5\u8a62\u4e0a\u7684\u6548\u80fd\uff0c\u7136\u5f8c\u900f\u904e\u7834\u58de\u548c\u91cd\u5efa\u76ee\u524d\u7684\u89e3\uff0c\u53cd\u8986\u7522\u751f\u4e00\u7d44\u975e\u652f\u914d\u89e3\u3002\u70ba\u4e86\u8a55\u4f30 OptLLM \u7684\u6709\u6548\u6027\uff0c\u6211\u5011\u5c0d\u5404\u7a2e\u985e\u578b\u7684\u4efb\u52d9\u9032\u884c\u5ee3\u6cdb\u7684\u5be6\u9a57\uff0c\u5305\u62ec\u6587\u5b57\u5206\u985e\u3001\u554f\u7b54\u3001\u60c5\u7dd2\u5206\u6790\u3001\u63a8\u7406\u548c\u65e5\u8a8c\u5256\u6790\u3002\u6211\u5011\u7684\u5be6\u9a57\u7d50\u679c\u8b49\u660e\uff0cOptLLM \u5728\u9054\u5230\u8207\u6700\u4f73 LLM \u76f8\u540c\u6e96\u78ba\u5ea6\u7684\u540c\u6642\uff0c\u5927\u5e45\u964d\u4f4e\u4e86 2.40% \u5230 49.18% \u7684\u6210\u672c\u3002\u8207\u5176\u4ed6\u591a\u76ee\u6a19\u6700\u4f73\u5316\u6f14\u7b97\u6cd5\u76f8\u6bd4\uff0cOptLLM \u5728\u76f8\u540c\u6210\u672c\u4e0b\u5c07\u6e96\u78ba\u5ea6\u63d0\u5347\u4e86 2.94% \u5230 69.05%\uff0c\u6216\u5728\u7dad\u6301\u6700\u9ad8\u53ef\u9054\u5230\u7684\u6e96\u78ba\u5ea6\u7684\u540c\u6642\uff0c\u7bc0\u7701\u4e86 8.79% \u548c 95.87% \u7684\u6210\u672c\u3002", "author": "Yueyue Liu et.al.", "authors": "Yueyue Liu, Hongyu Zhang, Yuantian Miao, Van-Hoang Le, Zhiqiang Li", "id": "2405.15130v1", "paper_url": "http://arxiv.org/abs/2405.15130v1", "repo": "null"}}