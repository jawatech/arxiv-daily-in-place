{"2405.04820": {"publish_time": "2024-05-08", "title": "APrompt4EM: Augmented Prompt Tuning for Generalized Entity Matching", "paper_summary": "Generalized Entity Matching (GEM), which aims at judging whether two records\nrepresented in different formats refer to the same real-world entity, is an\nessential task in data management. The prompt tuning paradigm for pre-trained\nlanguage models (PLMs), including the recent PromptEM model, effectively\naddresses the challenges of low-resource GEM in practical applications,\noffering a robust solution when labeled data is scarce. However, existing\nprompt tuning models for GEM face the challenges of prompt design and\ninformation gap. This paper introduces an augmented prompt tuning framework for\nthe challenges, which consists of two main improvements. The first is an\naugmented contextualized soft token-based prompt tuning method that extracts a\nguiding soft token benefit for the PLMs' prompt tuning, and the second is a\ncost-effective information augmentation strategy leveraging large language\nmodels (LLMs). Our approach performs well on the low-resource GEM challenges.\nExtensive experiments show promising advancements of our basic model without\ninformation augmentation over existing methods based on moderate-size PLMs\n(average 5.24%+), and our model with information augmentation achieves\ncomparable performance compared with fine-tuned LLMs, using less than 14% of\nthe API fee.", "paper_summary_zh": "\u5ee3\u7fa9\u5be6\u9ad4\u914d\u5c0d (GEM) \u65e8\u5728\u5224\u65b7\u4ee5\u4e0d\u540c\u683c\u5f0f\u8868\u793a\u7684\u5169\u500b\u8a18\u9304\u662f\u5426\u6307\u6d89\u540c\u4e00\u500b\u771f\u5be6\u4e16\u754c\u5be6\u9ad4\uff0c\u662f\u8cc7\u6599\u7ba1\u7406\u4e2d\u7684\u4e00\u9805\u57fa\u672c\u4efb\u52d9\u3002\u9810\u8a13\u7df4\u8a9e\u8a00\u6a21\u578b (PLM) \u7684\u63d0\u793a\u8abf\u6574\u7bc4\u4f8b\uff0c\u5305\u62ec\u6700\u8fd1\u7684 PromptEM \u6a21\u578b\uff0c\u6709\u6548\u5730\u89e3\u6c7a\u4e86\u5be6\u969b\u61c9\u7528\u4e2d\u4f4e\u8cc7\u6e90 GEM \u7684\u6311\u6230\uff0c\u5728\u6a19\u7c64\u8cc7\u6599\u7a00\u5c11\u6642\u63d0\u4f9b\u5f37\u5065\u7684\u89e3\u6c7a\u65b9\u6848\u3002\u7136\u800c\uff0c\u73fe\u6709\u7684 GEM \u63d0\u793a\u8abf\u6574\u6a21\u578b\u9762\u81e8\u63d0\u793a\u8a2d\u8a08\u548c\u8cc7\u8a0a\u5dee\u8ddd\u7684\u6311\u6230\u3002\u672c\u6587\u91dd\u5c0d\u9019\u4e9b\u6311\u6230\uff0c\u63d0\u51fa\u4e00\u500b\u64f4\u5145\u7684\u63d0\u793a\u8abf\u6574\u67b6\u69cb\uff0c\u5305\u542b\u5169\u500b\u4e3b\u8981\u7684\u6539\u9032\u3002\u7b2c\u4e00\u500b\u662f\u64f4\u5145\u7684\u8a9e\u5883\u5316\u8edf\u6a19\u8a18\u63d0\u793a\u8abf\u6574\u65b9\u6cd5\uff0c\u7528\u65bc\u8403\u53d6\u4e00\u500b\u5f15\u5c0e\u6027\u7684\u8edf\u6a19\u8a18\u512a\u9ede\uff0c\u4ee5\u5229 PLM \u7684\u63d0\u793a\u8abf\u6574\uff1b\u7b2c\u4e8c\u500b\u662f\u4e00\u500b\u5177\u6210\u672c\u6548\u76ca\u7684\u8cc7\u8a0a\u64f4\u5145\u7b56\u7565\uff0c\u5229\u7528\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM)\u3002\u6211\u5011\u7684\u505a\u6cd5\u5728\u4f4e\u8cc7\u6e90 GEM \u6311\u6230\u4e2d\u8868\u73fe\u826f\u597d\u3002\u5ee3\u6cdb\u7684\u5be6\u9a57\u986f\u793a\uff0c\u6211\u5011\u7684\u57fa\u672c\u6a21\u578b\u5728\u6c92\u6709\u8cc7\u8a0a\u64f4\u5145\u7684\u60c5\u6cc1\u4e0b\uff0c\u76f8\u8f03\u65bc\u57fa\u65bc\u4e2d\u7b49\u898f\u6a21 PLM \u7684\u73fe\u6709\u65b9\u6cd5\uff0c\u6709\u986f\u8457\u7684\u9032\u6b65\uff08\u5e73\u5747 5.24%+\uff09\uff0c\u800c\u6211\u5011\u7684\u6a21\u578b\u5728\u6709\u8cc7\u8a0a\u64f4\u5145\u7684\u60c5\u6cc1\u4e0b\uff0c\u4f7f\u7528\u4e0d\u5230 14% \u7684 API \u8cbb\u7528\uff0c\u9054\u5230\u4e86\u8207\u5fae\u8abf LLM \u76f8\u7576\u7684\u6548\u80fd\u3002", "author": "Yikuan Xia et.al.", "authors": "Yikuan Xia, Jiazun Chen, Xinchi Li, Jun Gao", "id": "2405.04820v1", "paper_url": "http://arxiv.org/abs/2405.04820v1", "repo": "null"}}