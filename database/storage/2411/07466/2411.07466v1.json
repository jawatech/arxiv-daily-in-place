{"2411.07466": {"publish_time": "2024-11-12", "title": "IdentifyMe: A Challenging Long-Context Mention Resolution Benchmark", "paper_summary": "Recent evaluations of LLMs on coreference resolution have revealed that\ntraditional output formats and evaluation metrics do not fully capture the\nmodels' referential understanding. To address this, we introduce IdentifyMe, a\nnew benchmark for mention resolution presented in a multiple-choice question\n(MCQ) format, commonly used for evaluating LLMs. IdentifyMe features long\nnarratives and employs heuristics to exclude easily identifiable mentions,\ncreating a more challenging task. The benchmark also consists of a curated\nmixture of different mention types and corresponding entities, allowing for a\nfine-grained analysis of model performance. We evaluate both closed- and open\nsource LLMs on IdentifyMe and observe a significant performance gap (20-30%)\nbetween the state-of-the-art sub-10B open models vs. closed ones. We observe\nthat pronominal mentions, which have limited surface information, are typically\nmuch harder for models to resolve than nominal mentions. Additionally, we find\nthat LLMs often confuse entities when their mentions overlap in nested\nstructures. The highest-scoring model, GPT-4o, achieves 81.9% accuracy,\nhighlighting the strong referential capabilities of state-of-the-art LLMs while\nalso indicating room for further improvement.", "paper_summary_zh": "\u6700\u8fd1\u5c0d\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u95dc\u65bc\u5171\u540c\u6307\u7a31\u6d88\u89e3\u7684\u8a55\u4f30\u986f\u793a\uff0c\u50b3\u7d71\u7684\u8f38\u51fa\u683c\u5f0f\u548c\u8a55\u4f30\u6307\u6a19\u4e26\u672a\u5b8c\u5168\u638c\u63e1\u6a21\u578b\u7684\u6307\u7a31\u7406\u89e3\u3002\u70ba\u4e86\u89e3\u6c7a\u9019\u500b\u554f\u984c\uff0c\u6211\u5011\u5f15\u5165\u4e86 IdentifyMe\uff0c\u9019\u662f\u4e00\u500b\u4ee5\u591a\u9078\u984c (MCQ) \u683c\u5f0f\u5448\u73fe\u7684\u63d0\u53ca\u6d88\u89e3\u65b0\u57fa\u6e96\uff0c\u901a\u5e38\u7528\u65bc\u8a55\u4f30 LLM\u3002IdentifyMe \u63a1\u7528\u9577\u7bc7\u6558\u4e8b\uff0c\u4e26\u4f7f\u7528\u555f\u767c\u6cd5\u6392\u9664\u5bb9\u6613\u8b58\u5225\u7684\u63d0\u53ca\uff0c\u5275\u9020\u66f4\u5177\u6311\u6230\u6027\u7684\u4efb\u52d9\u3002\u6b64\u57fa\u6e96\u9084\u5305\u542b\u7d93\u904e\u6574\u7406\u7684\u4e0d\u540c\u63d0\u53ca\u985e\u578b\u548c\u5c0d\u61c9\u5be6\u9ad4\u7684\u6df7\u5408\uff0c\u5141\u8a31\u5c0d\u6a21\u578b\u6548\u80fd\u9032\u884c\u7d30\u7dfb\u7684\u5206\u6790\u3002\u6211\u5011\u5728 IdentifyMe \u4e0a\u8a55\u4f30\u9589\u6e90\u548c\u958b\u6e90 LLM\uff0c\u4e26\u89c0\u5bdf\u5230\u6700\u5148\u9032\u7684\u4f4e\u65bc 10B \u958b\u653e\u6a21\u578b\u8207\u9589\u6e90\u6a21\u578b\u4e4b\u9593\u6709\u986f\u8457\u7684\u6548\u80fd\u5dee\u8ddd (20-30%)\u3002\u6211\u5011\u89c0\u5bdf\u5230\uff0c\u8868\u9762\u8cc7\u8a0a\u6709\u9650\u7684\u4ee3\u540d\u8a5e\u63d0\u53ca\u901a\u5e38\u6bd4\u540d\u8a5e\u63d0\u53ca\u66f4\u96e3\u8b93\u6a21\u578b\u89e3\u6790\u3002\u6b64\u5916\uff0c\u6211\u5011\u767c\u73fe\u7576 LLM \u7684\u63d0\u53ca\u5728\u5de2\u72c0\u7d50\u69cb\u4e2d\u91cd\u758a\u6642\uff0c\u5b83\u5011\u7d93\u5e38\u6703\u6df7\u6dc6\u5be6\u9ad4\u3002\u5f97\u5206\u6700\u9ad8\u7684\u6a21\u578b GPT-4o \u9054\u5230\u4e86 81.9% \u7684\u6e96\u78ba\u5ea6\uff0c\u7a81\u986f\u4e86\u6700\u5148\u9032 LLM \u5f37\u5927\u7684\u6307\u7a31\u80fd\u529b\uff0c\u540c\u6642\u4e5f\u8868\u793a\u4ecd\u6709\u9032\u6b65\u7684\u7a7a\u9593\u3002", "author": "Kawshik Manikantan et.al.", "authors": "Kawshik Manikantan, Makarand Tapaswi, Vineet Gandhi, Shubham Toshniwal", "id": "2411.07466v1", "paper_url": "http://arxiv.org/abs/2411.07466v1", "repo": "null"}}