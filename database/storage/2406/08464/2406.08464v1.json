{"2406.08464": {"publish_time": "2024-06-12", "title": "Magpie: Alignment Data Synthesis from Scratch by Prompting Aligned LLMs with Nothing", "paper_summary": "High-quality instruction data is critical for aligning large language models\n(LLMs). Although some models, such as Llama-3-Instruct, have open weights,\ntheir alignment data remain private, which hinders the democratization of AI.\nHigh human labor costs and a limited, predefined scope for prompting prevent\nexisting open-source data creation methods from scaling effectively,\npotentially limiting the diversity and quality of public alignment datasets. Is\nit possible to synthesize high-quality instruction data at scale by extracting\nit directly from an aligned LLM? We present a self-synthesis method for\ngenerating large-scale alignment data named Magpie. Our key observation is that\naligned LLMs like Llama-3-Instruct can generate a user query when we input only\nthe left-side templates up to the position reserved for user messages, thanks\nto their auto-regressive nature. We use this method to prompt Llama-3-Instruct\nand generate 4 million instructions along with their corresponding responses.\nWe perform a comprehensive analysis of the extracted data and select 300K\nhigh-quality instances. To compare Magpie data with other public instruction\ndatasets, we fine-tune Llama-3-8B-Base with each dataset and evaluate the\nperformance of the fine-tuned models. Our results indicate that in some tasks,\nmodels fine-tuned with Magpie perform comparably to the official\nLlama-3-8B-Instruct, despite the latter being enhanced with 10 million data\npoints through supervised fine-tuning (SFT) and subsequent feedback learning.\nWe also show that using Magpie solely for SFT can surpass the performance of\nprevious public datasets utilized for both SFT and preference optimization,\nsuch as direct preference optimization with UltraFeedback. This advantage is\nevident on alignment benchmarks such as AlpacaEval, ArenaHard, and WildBench.", "paper_summary_zh": "\u9ad8\u8d28\u91cf\u7684\u6307\u4ee4\u6570\u636e\u5bf9\u4e8e\u5bf9\u9f50\u5927\u578b\u8bed\u8a00\u6a21\u578b (LLM) \u81f3\u5173\u91cd\u8981\u3002\u5c3d\u7ba1\u67d0\u4e9b\u6a21\u578b\uff08\u5982 Llama-3-Instruct\uff09\u5177\u6709\u5f00\u653e\u6743\u91cd\uff0c\u4f46\u5176\u5bf9\u9f50\u6570\u636e\u4ecd\u7136\u662f\u79c1\u6709\u7684\uff0c\u8fd9\u963b\u788d\u4e86\u4eba\u5de5\u667a\u80fd\u7684\u6c11\u4e3b\u5316\u3002\u9ad8\u6602\u7684\u4eba\u5de5\u6210\u672c\u548c\u6709\u9650\u7684\u9884\u5b9a\u4e49\u63d0\u793a\u8303\u56f4\u963b\u788d\u4e86\u73b0\u6709\u7684\u5f00\u6e90\u6570\u636e\u521b\u5efa\u65b9\u6cd5\u6709\u6548\u6269\u5c55\uff0c\u4ece\u800c\u53ef\u80fd\u9650\u5236\u516c\u5171\u5bf9\u9f50\u6570\u636e\u96c6\u7684\u591a\u6837\u6027\u548c\u8d28\u91cf\u3002\u662f\u5426\u53ef\u4ee5\u901a\u8fc7\u76f4\u63a5\u4ece\u5bf9\u9f50\u7684 LLM \u4e2d\u63d0\u53d6\u6765\u5927\u89c4\u6a21\u5408\u6210\u9ad8\u8d28\u91cf\u7684\u6307\u4ee4\u6570\u636e\uff1f\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a Magpie \u7684\u81ea\u5408\u6210\u65b9\u6cd5\uff0c\u7528\u4e8e\u751f\u6210\u5927\u89c4\u6a21\u7684\u5bf9\u9f50\u6570\u636e\u3002\u6211\u4eec\u7684\u5173\u952e\u89c2\u5bdf\u662f\uff0c\u50cf Llama-3-Instruct \u8fd9\u6837\u7684\u5bf9\u9f50 LLM \u53ef\u4ee5\u5728\u6211\u4eec\u4ec5\u8f93\u5165\u5de6\u4fa7\u6a21\u677f\uff08\u76f4\u5230\u4e3a\u7528\u6237\u6d88\u606f\u4fdd\u7559\u7684\u4f4d\u7f6e\uff09\u65f6\u751f\u6210\u7528\u6237\u67e5\u8be2\uff0c\u8fd9\u8981\u5f52\u529f\u4e8e\u5b83\u4eec\u7684\u81ea\u52a8\u56de\u5f52\u7279\u6027\u3002\u6211\u4eec\u4f7f\u7528\u8fd9\u79cd\u65b9\u6cd5\u63d0\u793a Llama-3-Instruct \u5e76\u751f\u6210 400 \u4e07\u6761\u6307\u4ee4\u53ca\u5176\u76f8\u5e94\u7684\u54cd\u5e94\u3002\u6211\u4eec\u5bf9\u63d0\u53d6\u7684\u6570\u636e\u8fdb\u884c\u4e86\u5168\u9762\u5206\u6790\uff0c\u5e76\u9009\u62e9\u4e86 30 \u4e07\u4e2a\u9ad8\u8d28\u91cf\u7684\u5b9e\u4f8b\u3002\u4e3a\u4e86\u5c06 Magpie \u6570\u636e\u4e0e\u5176\u4ed6\u516c\u5171\u6307\u4ee4\u6570\u636e\u96c6\u8fdb\u884c\u6bd4\u8f83\uff0c\u6211\u4eec\u4f7f\u7528\u6bcf\u4e2a\u6570\u636e\u96c6\u5bf9 Llama-3-8B-Base \u8fdb\u884c\u4e86\u5fae\u8c03\uff0c\u5e76\u8bc4\u4f30\u4e86\u5fae\u8c03\u540e\u7684\u6a21\u578b\u7684\u6027\u80fd\u3002\u6211\u4eec\u7684\u7ed3\u679c\u8868\u660e\uff0c\u5728\u67d0\u4e9b\u4efb\u52a1\u4e2d\uff0c\u4f7f\u7528 Magpie \u5fae\u8c03\u7684\u6a21\u578b\u7684\u6027\u80fd\u4e0e\u5b98\u65b9\u7684 Llama-3-8B-Instruct \u76f8\u5f53\uff0c\u5c3d\u7ba1\u540e\u8005\u901a\u8fc7\u76d1\u7763\u5fae\u8c03 (SFT) \u548c\u540e\u7eed\u53cd\u9988\u5b66\u4e60\u5f97\u5230\u4e86 1000 \u4e07\u4e2a\u6570\u636e\u70b9\u7684\u589e\u5f3a\u3002\u6211\u4eec\u8fd8\u8868\u660e\uff0c\u4ec5\u5c06 Magpie \u7528\u4e8e SFT \u53ef\u4ee5\u8d85\u8d8a\u4ee5\u524d\u7528\u4e8e SFT \u548c\u504f\u597d\u4f18\u5316\u7684\u516c\u5171\u6570\u636e\u96c6\u7684\u6027\u80fd\uff0c\u4f8b\u5982\u4f7f\u7528 UltraFeedback \u7684\u76f4\u63a5\u504f\u597d\u4f18\u5316\u3002\u8fd9\u79cd\u4f18\u52bf\u5728\u5bf9\u9f50\u57fa\u51c6\uff08\u5982 AlpacaEval\u3001ArenaHard \u548c WildBench\uff09\u4e2d\u5f88\u660e\u663e\u3002", "author": "Zhangchen Xu et.al.", "authors": "Zhangchen Xu, Fengqing Jiang, Luyao Niu, Yuntian Deng, Radha Poovendran, Yejin Choi, Bill Yuchen Lin", "id": "2406.08464v1", "paper_url": "http://arxiv.org/abs/2406.08464v1", "repo": "null"}}