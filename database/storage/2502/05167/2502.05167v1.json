{"2502.05167": {"publish_time": "2025-02-07", "title": "NoLiMa: Long-Context Evaluation Beyond Literal Matching", "paper_summary": "Recent large language models (LLMs) support long contexts ranging from 128K\nto 1M tokens. A popular method for evaluating these capabilities is the\nneedle-in-a-haystack (NIAH) test, which involves retrieving a \"needle\"\n(relevant information) from a \"haystack\" (long irrelevant context). Extensions\nof this approach include increasing distractors, fact chaining, and in-context\nreasoning. However, in these benchmarks, models can exploit existing literal\nmatches between the needle and haystack to simplify the task. To address this,\nwe introduce NoLiMa, a benchmark extending NIAH with a carefully designed\nneedle set, where questions and needles have minimal lexical overlap, requiring\nmodels to infer latent associations to locate the needle within the haystack.\nWe evaluate 12 popular LLMs that claim to support contexts of at least 128K\ntokens. While they perform well in short contexts (<1K), performance degrades\nsignificantly as context length increases. At 32K, for instance, 10 models drop\nbelow 50% of their strong short-length baselines. Even GPT-4o, one of the\ntop-performing exceptions, experiences a reduction from an almost-perfect\nbaseline of 99.3% to 69.7%. Our analysis suggests these declines stem from the\nincreased difficulty the attention mechanism faces in longer contexts when\nliteral matches are absent, making it harder to retrieve relevant information.", "paper_summary_zh": "\u6700\u8fd1\u7684\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u652f\u6301\u4ece 128K \u5230 1M \u4e2a\u6807\u8bb0\u7684\u8f83\u957f\u5185\u5bb9\u3002\u8bc4\u4f30\u8fd9\u4e9b\u529f\u80fd\u7684\u4e00\u79cd\u6d41\u884c\u65b9\u6cd5\u662f\u201c\u5927\u6d77\u635e\u9488\u201d\uff08NIAH\uff09\u6d4b\u8bd5\uff0c\u5176\u4e2d\u6d89\u53ca\u4ece\u201c\u5e72\u8349\u5806\u201d\uff08\u5197\u957f\u7684\u65e0\u5173\u5185\u5bb9\uff09\u4e2d\u68c0\u7d22\u201c\u9488\u201d\uff08\u76f8\u5173\u4fe1\u606f\uff09\u3002\u8fd9\u79cd\u65b9\u6cd5\u7684\u6269\u5c55\u5305\u62ec\u589e\u52a0\u5e72\u6270\u9879\u3001\u4e8b\u5b9e\u94fe\u63a5\u548c\u4e0a\u4e0b\u6587\u63a8\u7406\u3002\u7136\u800c\uff0c\u5728\u8fd9\u4e9b\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u6a21\u578b\u53ef\u4ee5\u5229\u7528\u9488\u548c\u5e72\u8349\u5806\u4e4b\u95f4\u73b0\u6709\u7684\u5b57\u9762\u5339\u914d\u6765\u7b80\u5316\u4efb\u52a1\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\uff0c\u6211\u4eec\u5f15\u5165\u4e86 NoLiMa\uff0c\u8fd9\u662f\u4e00\u4e2a\u57fa\u51c6\uff0c\u5b83\u7528\u7cbe\u5fc3\u8bbe\u8ba1\u7684\u9488\u96c6\u6269\u5c55\u4e86 NIAH\uff0c\u5176\u4e2d\u95ee\u9898\u548c\u9488\u7684\u8bcd\u6c47\u91cd\u53e0\u5f88\u5c0f\uff0c\u9700\u8981\u6a21\u578b\u63a8\u65ad\u6f5c\u5728\u5173\u8054\u624d\u80fd\u5728\u5e72\u8349\u5806\u4e2d\u627e\u5230\u9488\u3002\u6211\u4eec\u8bc4\u4f30\u4e86 12 \u4e2a\u6d41\u884c\u7684 LLM\uff0c\u5b83\u4eec\u58f0\u79f0\u652f\u6301\u81f3\u5c11 128K \u4e2a\u6807\u8bb0\u7684\u5185\u5bb9\u3002\u867d\u7136\u5b83\u4eec\u5728\u8f83\u77ed\u7684\u5185\u5bb9\uff08<1K\uff09\u4e2d\u8868\u73b0\u826f\u597d\uff0c\u4f46\u968f\u7740\u5185\u5bb9\u957f\u5ea6\u7684\u589e\u52a0\uff0c\u6027\u80fd\u4f1a\u663e\u7740\u4e0b\u964d\u3002\u4f8b\u5982\uff0c\u5728 32K \u65f6\uff0c10 \u4e2a\u6a21\u578b\u4f4e\u4e8e\u5176\u5f3a\u52b2\u7684\u77ed\u957f\u5ea6\u57fa\u7ebf\u7684 50%\u3002\u5373\u4f7f\u662f\u8868\u73b0\u6700\u597d\u7684\u4f8b\u5916\u4e4b\u4e00 GPT-4o\uff0c\u4e5f\u4ece\u63a5\u8fd1\u5b8c\u7f8e\u7684 99.3% \u7684\u57fa\u7ebf\u4e0b\u964d\u5230 69.7%\u3002\u6211\u4eec\u7684\u5206\u6790\u8868\u660e\uff0c\u8fd9\u4e9b\u4e0b\u964d\u6e90\u4e8e\u5f53\u6ca1\u6709\u5b57\u9762\u5339\u914d\u65f6\uff0c\u6ce8\u610f\u673a\u5236\u5728\u8f83\u957f\u7684\u5185\u5bb9\u4e2d\u9762\u4e34\u7684\u56f0\u96be\u589e\u52a0\uff0c\u8fd9\u4f7f\u5f97\u68c0\u7d22\u76f8\u5173\u4fe1\u606f\u53d8\u5f97\u66f4\u52a0\u56f0\u96be\u3002", "author": "Ali Modarressi et.al.", "authors": "Ali Modarressi, Hanieh Deilamsalehy, Franck Dernoncourt, Trung Bui, Ryan A. Rossi, Seunghyun Yoon, Hinrich Sch\u00fctze", "id": "2502.05167v1", "paper_url": "http://arxiv.org/abs/2502.05167v1", "repo": "null"}}