{"2501.08566": {"publish_time": "2025-01-15", "title": "Towards Lightweight and Stable Zero-shot TTS with Self-distilled Representation Disentanglement", "paper_summary": "Zero-shot Text-To-Speech (TTS) synthesis shows great promise for personalized\nvoice customization through voice cloning. However, current methods for\nachieving zero-shot TTS heavily rely on large model scales and extensive\ntraining datasets to ensure satisfactory performance and generalizability\nacross various speakers. This raises concerns regarding both deployment costs\nand data security. In this paper, we present a lightweight and stable zero-shot\nTTS system. We introduce a novel TTS architecture designed to effectively model\nlinguistic content and various speaker attributes from source speech and prompt\nspeech, respectively. Furthermore, we present a two-stage self-distillation\nframework that constructs parallel data pairs for effectively disentangling\nlinguistic content and speakers from the perspective of training data.\nExtensive experiments show that our system exhibits excellent performance and\nsuperior stability on the zero-shot TTS tasks. Moreover, it shows markedly\nsuperior computational efficiency, with RTFs of 0.13 and 0.012 on the CPU and\nGPU, respectively.", "paper_summary_zh": "\u96f6\u6a23\u672c\u6587\u5b57\u8f49\u8a9e\u97f3 (TTS) \u5408\u6210\u5728\u900f\u904e\u8a9e\u97f3\u8907\u88fd\u6280\u8853\u9032\u884c\u500b\u6027\u5316\u8a9e\u97f3\u81ea\u8a02\u65b9\u9762\u5c55\u73fe\u51fa\u6975\u4f73\u7684\u6f5b\u529b\u3002\u7136\u800c\uff0c\u76ee\u524d\u9054\u6210\u96f6\u6a23\u672c TTS \u7684\u65b9\u6cd5\u6975\u5ea6\u4f9d\u8cf4\u5927\u578b\u6a21\u578b\u898f\u6a21\u548c\u5ee3\u6cdb\u7684\u8a13\u7df4\u8cc7\u6599\u96c6\uff0c\u4ee5\u78ba\u4fdd\u5728\u5404\u7a2e\u8aaa\u8a71\u8005\u4e4b\u9593\u6709\u4ee4\u4eba\u6eff\u610f\u7684\u6548\u80fd\u548c\u6982\u62ec\u6027\u3002\u9019\u5f15\u767c\u4e86\u5c0d\u90e8\u7f72\u6210\u672c\u548c\u8cc7\u6599\u5b89\u5168\u7684\u7591\u616e\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u63d0\u51fa\u4e00\u500b\u8f15\u91cf\u4e14\u7a69\u5b9a\u7684\u96f6\u6a23\u672c TTS \u7cfb\u7d71\u3002\u6211\u5011\u63a8\u51fa\u4e00\u7a2e\u5275\u65b0\u7684 TTS \u67b6\u69cb\uff0c\u65e8\u5728\u6709\u6548\u5730\u5efa\u69cb\u8a9e\u8a00\u5167\u5bb9\u548c\u5404\u7a2e\u8aaa\u8a71\u8005\u5c6c\u6027\uff0c\u5206\u5225\u4f86\u81ea\u539f\u59cb\u8a9e\u97f3\u548c\u63d0\u793a\u8a9e\u97f3\u3002\u6b64\u5916\uff0c\u6211\u5011\u63d0\u51fa\u4e00\u500b\u5169\u968e\u6bb5\u7684\u81ea\u84b8\u993e\u67b6\u69cb\uff0c\u7528\u65bc\u5efa\u69cb\u5e73\u884c\u8cc7\u6599\u5c0d\uff0c\u4ee5\u6709\u6548\u5730\u5f9e\u8a13\u7df4\u8cc7\u6599\u7684\u89d2\u5ea6\u89e3\u958b\u8a9e\u8a00\u5167\u5bb9\u548c\u8aaa\u8a71\u8005\u3002\u5ee3\u6cdb\u7684\u5be6\u9a57\u986f\u793a\uff0c\u6211\u5011\u7684\u7cfb\u7d71\u5728\u96f6\u6a23\u672c TTS \u4efb\u52d9\u4e2d\u5c55\u73fe\u51fa\u6975\u4f73\u7684\u6548\u80fd\u548c\u512a\u7570\u7684\u7a69\u5b9a\u6027\u3002\u6b64\u5916\uff0c\u5b83\u5c55\u73fe\u51fa\u986f\u8457\u512a\u7570\u7684\u904b\u7b97\u6548\u7387\uff0c\u5728 CPU \u548c GPU \u4e0a\u7684 RTF \u5206\u5225\u70ba 0.13 \u548c 0.012\u3002", "author": "Qianniu Chen et.al.", "authors": "Qianniu Chen, Xiaoyang Hao, Bowen Li, Yue Liu, Li Lu", "id": "2501.08566v1", "paper_url": "http://arxiv.org/abs/2501.08566v1", "repo": "null"}}