{"2405.14486": {"publish_time": "2024-05-23", "title": "RefChecker: Reference-based Fine-grained Hallucination Checker and Benchmark for Large Language Models", "paper_summary": "Large Language Models (LLMs) have shown impressive capabilities but also a\nconcerning tendency to hallucinate. This paper presents RefChecker, a framework\nthat introduces claim-triplets to represent claims in LLM responses, aiming to\ndetect fine-grained hallucinations. In RefChecker, an extractor generates\nclaim-triplets from a response, which are then evaluated by a checker against a\nreference. We delineate three task settings: Zero, Noisy and Accurate Context,\nto reflect various real-world use cases. We curated a benchmark spanning\nvarious NLP tasks and annotated 11k claim-triplets from 2.1k responses by seven\nLLMs. RefChecker supports both proprietary and open-source models as the\nextractor and checker. Experiments demonstrate that claim-triplets enable\nsuperior hallucination detection, compared to other granularities such as\nresponse, sentence and sub-sentence level claims. RefChecker outperforms prior\nmethods by 6.8 to 26.1 points on our benchmark and the checking results of\nRefChecker are strongly aligned with human judgments. This work is open sourced\nat https://github.com/amazon-science/RefChecker", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u5df2\u5c55\u73fe\u51fa\u4ee4\u4eba\u5370\u8c61\u6df1\u523b\u7684\u80fd\u529b\uff0c\u4f46\u4e5f\u6709\u4ee4\u4eba\u64d4\u5fc3\u7684\u5e7b\u89ba\u50be\u5411\u3002\u672c\u6587\u4ecb\u7d39\u4e86 RefChecker\uff0c\u4e00\u500b\u5f15\u5165\u4e86\u8072\u660e\u4e09\u5143\u7d44\u4f86\u8868\u793a LLM \u56de\u61c9\u4e2d\u7684\u8072\u660e\u7684\u6846\u67b6\uff0c\u65e8\u5728\u5075\u6e2c\u7d30\u5fae\u7684\u5e7b\u89ba\u3002\u5728 RefChecker \u4e2d\uff0c\u63d0\u53d6\u5668\u6703\u5f9e\u56de\u61c9\u4e2d\u7522\u751f\u8072\u660e\u4e09\u5143\u7d44\uff0c\u7136\u5f8c\u7531\u6aa2\u67e5\u5668\u6839\u64da\u53c3\u8003\u9032\u884c\u8a55\u4f30\u3002\u6211\u5011\u63cf\u7e6a\u4e86\u4e09\u7a2e\u4efb\u52d9\u8a2d\u5b9a\uff1a\u96f6\u3001\u96dc\u8a0a\u548c\u6e96\u78ba\u7684\u4e0a\u4e0b\u6587\uff0c\u4ee5\u53cd\u6620\u5404\u7a2e\u771f\u5be6\u4e16\u754c\u7684\u7528\u4f8b\u3002\u6211\u5011\u7b56\u5283\u4e86\u4e00\u500b\u6db5\u84cb\u5404\u7a2e NLP \u4efb\u52d9\u7684\u57fa\u6e96\uff0c\u4e26\u8a3b\u91cb\u4e86\u4e03\u500b LLM \u7684 2.1k \u500b\u56de\u61c9\u4e2d\u7684 11k \u500b\u8072\u660e\u4e09\u5143\u7d44\u3002RefChecker \u652f\u63f4\u5c08\u6709\u548c\u958b\u653e\u539f\u59cb\u78bc\u6a21\u578b\u4f5c\u70ba\u63d0\u53d6\u5668\u548c\u6aa2\u67e5\u5668\u3002\u5be6\u9a57\u8b49\u660e\uff0c\u8207\u5176\u4ed6\u7c92\u5ea6\uff08\u4f8b\u5982\u56de\u61c9\u3001\u53e5\u5b50\u548c\u5b50\u53e5\u5b50\u5c64\u7d1a\u7684\u8072\u660e\uff09\u76f8\u6bd4\uff0c\u8072\u660e\u4e09\u5143\u7d44\u80fd\u555f\u7528\u512a\u7570\u7684\u5e7b\u89ba\u5075\u6e2c\u3002RefChecker \u5728\u6211\u5011\u7684\u57fa\u6e96\u4e0a\u6bd4\u5148\u524d\u7684\u65b9\u6cd5\u9ad8\u51fa 6.8 \u5230 26.1 \u5206\uff0c\u800c RefChecker \u7684\u6aa2\u67e5\u7d50\u679c\u8207\u4eba\u985e\u7684\u5224\u65b7\u9ad8\u5ea6\u4e00\u81f4\u3002\u9019\u9805\u5de5\u4f5c\u5df2\u5728 https://github.com/amazon-science/RefChecker \u958b\u6e90", "author": "Xiangkun Hu et.al.", "authors": "Xiangkun Hu, Dongyu Ru, Lin Qiu, Qipeng Guo, Tianhang Zhang, Yang Xu, Yun Luo, Pengfei Liu, Yue Zhang, Zheng Zhang", "id": "2405.14486v1", "paper_url": "http://arxiv.org/abs/2405.14486v1", "repo": "null"}}