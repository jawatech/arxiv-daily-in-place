{"2504.20026": {"publish_time": "2025-04-28", "title": "LIRM: Large Inverse Rendering Model for Progressive Reconstruction of Shape, Materials and View-dependent Radiance Fields", "paper_summary": "We present Large Inverse Rendering Model (LIRM), a transformer architecture\nthat jointly reconstructs high-quality shape, materials, and radiance fields\nwith view-dependent effects in less than a second. Our model builds upon the\nrecent Large Reconstruction Models (LRMs) that achieve state-of-the-art\nsparse-view reconstruction quality. However, existing LRMs struggle to\nreconstruct unseen parts accurately and cannot recover glossy appearance or\ngenerate relightable 3D contents that can be consumed by standard Graphics\nengines. To address these limitations, we make three key technical\ncontributions to build a more practical multi-view 3D reconstruction framework.\nFirst, we introduce an update model that allows us to progressively add more\ninput views to improve our reconstruction. Second, we propose a hexa-plane\nneural SDF representation to better recover detailed textures, geometry and\nmaterial parameters. Third, we develop a novel neural directional-embedding\nmechanism to handle view-dependent effects. Trained on a large-scale shape and\nmaterial dataset with a tailored coarse-to-fine training scheme, our model\nachieves compelling results. It compares favorably to optimization-based\ndense-view inverse rendering methods in terms of geometry and relighting\naccuracy, while requiring only a fraction of the inference time.", "paper_summary_zh": "\u6211\u5011\u63d0\u51fa\u4e86\u5927\u578b\u9006\u5411\u6e32\u67d3\u6a21\u578b (LIRM)\uff0c\u9019\u662f\u4e00\u7a2e Transformer \u67b6\u69cb\uff0c\u53ef\u4ee5\u5728\u4e0d\u5230\u4e00\u79d2\u7684\u6642\u9593\u5167\u806f\u5408\u91cd\u5efa\u5177\u6709\u8996\u5716\u76f8\u95dc\u6548\u679c\u7684\u9ad8\u8cea\u91cf\u5f62\u72c0\u3001\u6750\u8cea\u548c\u8f3b\u5c04\u5834\u3002\u6211\u5011\u7684\u6a21\u578b\u5efa\u7acb\u5728\u6700\u8fd1\u7684\u5927\u578b\u91cd\u5efa\u6a21\u578b (LRM) \u7684\u57fa\u790e\u4e0a\uff0c\u9019\u4e9b\u6a21\u578b\u9054\u5230\u4e86\u6700\u5148\u9032\u7684\u7a00\u758f\u8996\u5716\u91cd\u5efa\u8cea\u91cf\u3002\u7136\u800c\uff0c\u73fe\u6709\u7684 LRM \u96e3\u4ee5\u6e96\u78ba\u5730\u91cd\u5efa\u770b\u4e0d\u898b\u7684\u90e8\u5206\uff0c\u4e26\u4e14\u7121\u6cd5\u6062\u5fa9\u5149\u6fa4\u5916\u89c0\u6216\u751f\u6210\u53ef\u88ab\u6a19\u6e96\u5716\u5f62\u5f15\u64ce\u4f7f\u7528\u7684\u53ef\u91cd\u65b0\u7167\u660e\u7684 3D \u5167\u5bb9\u3002\u70ba\u4e86\u514b\u670d\u9019\u4e9b\u9650\u5236\uff0c\u6211\u5011\u505a\u51fa\u4e86\u4e09\u500b\u95dc\u9375\u7684\u6280\u8853\u8ca2\u737b\uff0c\u4ee5\u69cb\u5efa\u66f4\u5be6\u7528\u7684\u591a\u8996\u5716 3D \u91cd\u5efa\u6846\u67b6\u3002\u9996\u5148\uff0c\u6211\u5011\u5f15\u5165\u4e86\u4e00\u500b\u66f4\u65b0\u6a21\u578b\uff0c\u5141\u8a31\u6211\u5011\u9010\u6b65\u6dfb\u52a0\u66f4\u591a\u8f38\u5165\u8996\u5716\u4f86\u6539\u9032\u6211\u5011\u7684\u91cd\u5efa\u3002\u5176\u6b21\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u4e00\u7a2e\u516d\u5e73\u9762\u795e\u7d93 SDF \u8868\u793a\u6cd5\uff0c\u4ee5\u66f4\u597d\u5730\u6062\u5fa9\u8a73\u7d30\u7684\u7d0b\u7406\u3001\u5e7e\u4f55\u5f62\u72c0\u548c\u6750\u8cea\u53c3\u6578\u3002\u7b2c\u4e09\uff0c\u6211\u5011\u958b\u767c\u4e86\u4e00\u7a2e\u65b0\u7a4e\u7684\u795e\u7d93\u65b9\u5411\u5d4c\u5165\u6a5f\u5236\u4f86\u8655\u7406\u8996\u5716\u76f8\u95dc\u6548\u679c\u3002\u5728\u4f7f\u7528\u5b9a\u5236\u7684\u7531\u7c97\u5230\u7cbe\u8a13\u7df4\u65b9\u6848\u7684\u5927\u898f\u6a21\u5f62\u72c0\u548c\u6750\u8cea\u6578\u64da\u96c6\u4e0a\u9032\u884c\u8a13\u7df4\u5f8c\uff0c\u6211\u5011\u7684\u6a21\u578b\u53d6\u5f97\u4e86\u4ee4\u4eba\u4fe1\u670d\u7684\u7d50\u679c\u3002\u5b83\u5728\u5e7e\u4f55\u5f62\u72c0\u548c\u91cd\u65b0\u7167\u660e\u7cbe\u5ea6\u65b9\u9762\u8207\u57fa\u65bc\u512a\u5316\u7684\u5bc6\u96c6\u8996\u5716\u9006\u5411\u6e32\u67d3\u65b9\u6cd5\u76f8\u6bd4\u6beb\u4e0d\u905c\u8272\uff0c\u540c\u6642\u53ea\u9700\u8981\u4e00\u5c0f\u90e8\u5206\u7684\u63a8\u7406\u6642\u9593\u3002\n", "author": "Zhengqin Li et.al.", "authors": "Zhengqin Li, Dilin Wang, Ka Chen, Zhaoyang Lv, Thu Nguyen-Phuoc, Milim Lee, Jia-Bin Huang, Lei Xiao, Cheng Zhang, Yufeng Zhu, Carl S. Marshall, Yufeng Ren, Richard Newcombe, Zhao Dong", "id": "2504.20026v1", "paper_url": "http://arxiv.org/abs/2504.20026v1", "repo": "null"}}