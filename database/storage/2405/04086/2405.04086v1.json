{"2405.04086": {"publish_time": "2024-05-07", "title": "Optimizing Language Model's Reasoning Abilities with Weak Supervision", "paper_summary": "While Large Language Models (LLMs) have demonstrated proficiency in handling\ncomplex queries, much of the past work has depended on extensively annotated\ndatasets by human experts. However, this reliance on fully-supervised\nannotations poses scalability challenges, particularly as models and data\nrequirements grow. To mitigate this, we explore the potential of enhancing\nLLMs' reasoning abilities with minimal human supervision. In this work, we\nintroduce self-reinforcement, which begins with Supervised Fine-Tuning (SFT) of\nthe model using a small collection of annotated questions. Then it iteratively\nimproves LLMs by learning from the differences in responses from the SFT and\nunfinetuned models on unlabeled questions. Our approach provides an efficient\napproach without relying heavily on extensive human-annotated explanations.\nHowever, current reasoning benchmarks typically only include golden-reference\nanswers or rationales. Therefore, we present \\textsc{PuzzleBen}, a weakly\nsupervised benchmark that comprises 25,147 complex questions, answers, and\nhuman-generated rationales across various domains, such as brainteasers,\npuzzles, riddles, parajumbles, and critical reasoning tasks. A unique aspect of\nour dataset is the inclusion of 10,000 unannotated questions, enabling us to\nexplore utilizing fewer supersized data to boost LLMs' inference capabilities.\nOur experiments underscore the significance of \\textsc{PuzzleBen}, as well as\nthe effectiveness of our methodology as a promising direction in future\nendeavors. Our dataset and code will be published soon on \\texttt{Anonymity\nLink}.", "paper_summary_zh": "<paragraph>\u5118\u7ba1\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u5df2\u5c55\u73fe\u51fa\u8655\u7406\u8907\u96dc\u67e5\u8a62\u7684\u80fd\u529b\uff0c\u4f46\u904e\u53bb\u8a31\u591a\u5de5\u4f5c\u90fd\u4f9d\u8cf4\u4eba\u985e\u5c08\u5bb6\u5ee3\u6cdb\u8a3b\u89e3\u7684\u8cc7\u6599\u96c6\u3002\u7136\u800c\uff0c\u9019\u7a2e\u4f9d\u8cf4\u65bc\u5b8c\u5168\u76e3\u7763\u7684\u8a3b\u89e3\u6703\u9020\u6210\u53ef\u64f4\u5145\u6027\u7684\u6311\u6230\uff0c\u7279\u5225\u662f\u5728\u6a21\u578b\u548c\u8cc7\u6599\u9700\u6c42\u589e\u52a0\u7684\u60c5\u6cc1\u4e0b\u3002\u70ba\u4e86\u6e1b\u8f15\u9019\u500b\u554f\u984c\uff0c\u6211\u5011\u63a2\u7d22\u4e86\u900f\u904e\u6700\u5c11\u7684\u4eba\u985e\u76e3\u7763\u4f86\u589e\u5f37 LLM \u63a8\u7406\u80fd\u529b\u7684\u53ef\u80fd\u6027\u3002\u5728\u9019\u9805\u5de5\u4f5c\u4e2d\uff0c\u6211\u5011\u5f15\u5165\u4e86\u81ea\u6211\u5f37\u5316\uff0c\u5b83\u5f9e\u4f7f\u7528\u4e00\u5c0f\u90e8\u5206\u8a3b\u89e3\u554f\u984c\u5c0d\u6a21\u578b\u9032\u884c\u76e3\u7763\u5fae\u8abf (SFT) \u958b\u59cb\u3002\u7136\u5f8c\uff0c\u5b83\u900f\u904e\u5f9e SFT \u548c\u672a\u5fae\u8abf\u6a21\u578b\u5728\u672a\u6a19\u8a18\u554f\u984c\u4e0a\u7684\u56de\u61c9\u5dee\u7570\u4e2d\u5b78\u7fd2\uff0c\u53cd\u8986\u6539\u9032 LLM\u3002\u6211\u5011\u7684\u505a\u6cd5\u63d0\u4f9b\u4e86\u4e00\u500b\u6709\u6548\u7684\u65b9\u6cd5\uff0c\u800c\u7121\u9700\u904e\u5ea6\u4f9d\u8cf4\u5ee3\u6cdb\u7684\u4eba\u5de5\u8a3b\u89e3\u8aaa\u660e\u3002\u7136\u800c\uff0c\u76ee\u524d\u7684\u63a8\u7406\u57fa\u6e96\u901a\u5e38\u53ea\u5305\u542b\u9ec3\u91d1\u53c3\u8003\u7b54\u6848\u6216\u4f9d\u64da\u3002\u56e0\u6b64\uff0c\u6211\u5011\u63d0\u51fa\u4e86 \\textsc{PuzzleBen}\uff0c\u4e00\u500b\u5f31\u76e3\u7763\u57fa\u6e96\uff0c\u5b83\u5305\u542b\u4e86 25,147 \u500b\u8907\u96dc\u7684\u554f\u984c\u3001\u7b54\u6848\u548c\u4eba\u985e\u7522\u751f\u7684\u4f9d\u64da\uff0c\u6db5\u84cb\u5404\u7a2e\u9818\u57df\uff0c\u4f8b\u5982\u8166\u7b4b\u6025\u8f49\u5f4e\u3001\u8b0e\u8a9e\u3001\u8b0e\u984c\u3001\u8df3\u5b57\u8b0e\u548c\u6279\u5224\u6027\u63a8\u7406\u4efb\u52d9\u3002\u6211\u5011\u8cc7\u6599\u96c6\u7684\u4e00\u500b\u7368\u7279\u65b9\u9762\u662f\u5305\u542b\u4e86 10,000 \u500b\u672a\u8a3b\u89e3\u7684\u554f\u984c\uff0c\u4f7f\u6211\u5011\u80fd\u5920\u63a2\u7d22\u5229\u7528\u66f4\u5c11\u7684\u8d85\u5927\u578b\u8cc7\u6599\u4f86\u63d0\u5347 LLM \u7684\u63a8\u7406\u80fd\u529b\u3002\u6211\u5011\u7684\u5be6\u9a57\u5f37\u8abf\u4e86 \\textsc{PuzzleBen} \u7684\u91cd\u8981\u6027\uff0c\u4ee5\u53ca\u6211\u5011\u7684\u65b9\u6cd5\u4f5c\u70ba\u672a\u4f86\u52aa\u529b\u4e2d\u4e00\u500b\u6709\u524d\u9014\u7684\u65b9\u5411\u7684\u6709\u6548\u6027\u3002\u6211\u5011\u7684\u8cc7\u6599\u96c6\u548c\u7a0b\u5f0f\u78bc\u5c07\u5f88\u5feb\u5728 \\texttt{Anonymity Link} \u4e0a\u767c\u5e03\u3002</paragraph>", "author": "Yongqi Tong et.al.", "authors": "Yongqi Tong, Sizhe Wang, Dawei Li, Yifan Wang, Simeng Han, Zi Lin, Chengsong Huang, Jiaxin Huang, Jingbo Shang", "id": "2405.04086v1", "paper_url": "http://arxiv.org/abs/2405.04086v1", "repo": "null"}}