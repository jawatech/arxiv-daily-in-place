{"2411.09539": {"publish_time": "2024-11-14", "title": "A Practical Guide to Fine-tuning Language Models with Limited Data", "paper_summary": "Employing pre-trained Large Language Models (LLMs) has become the de facto\nstandard in Natural Language Processing (NLP) despite their extensive data\nrequirements. Motivated by the recent surge in research focused on training\nLLMs with limited data, particularly in low-resource domains and languages,\nthis paper surveys recent transfer learning approaches to optimize model\nperformance in downstream tasks where data is scarce. We first address initial\nand continued pre-training strategies to better leverage prior knowledge in\nunseen domains and languages. We then examine how to maximize the utility of\nlimited data during fine-tuning and few-shot learning. The final section takes\na task-specific perspective, reviewing models and methods suited for different\nlevels of data scarcity. Our goal is to provide practitioners with practical\nguidelines for overcoming the challenges posed by constrained data while also\nhighlighting promising directions for future research.", "paper_summary_zh": "\u63a1\u7528\u9810\u5148\u8a13\u7df4\u7684\u5927\u8a9e\u8a00\u6a21\u578b (LLM) \u5df2\u6210\u70ba\u81ea\u7136\u8a9e\u8a00\u8655\u7406 (NLP) \u7684\u5be6\u969b\u6a19\u6e96\uff0c\u5118\u7ba1\u5176\u8cc7\u6599\u9700\u6c42\u5ee3\u6cdb\u3002\u5728\u5c08\u6ce8\u65bc\u4ee5\u6709\u9650\u8cc7\u6599\u8a13\u7df4 LLM \u7684\u7814\u7a76\u6700\u8fd1\u6fc0\u589e\u7684\u63a8\u52d5\u4e0b\uff0c\u7279\u5225\u662f\u5728\u4f4e\u8cc7\u6e90\u9818\u57df\u548c\u8a9e\u8a00\u4e2d\uff0c\u672c\u6587\u8abf\u67e5\u4e86\u6700\u8fd1\u7684\u9077\u79fb\u5b78\u7fd2\u65b9\u6cd5\uff0c\u4ee5\u6700\u4f73\u5316\u8cc7\u6599\u7a00\u5c11\u7684\u4e0b\u6e38\u4efb\u52d9\u4e2d\u7684\u6a21\u578b\u6548\u80fd\u3002\u6211\u5011\u9996\u5148\u63a2\u8a0e\u6700\u521d\u548c\u6301\u7e8c\u7684\u9810\u8a13\u7df4\u7b56\u7565\uff0c\u4ee5\u5728\u672a\u898b\u9818\u57df\u548c\u8a9e\u8a00\u4e2d\u66f4\u597d\u5730\u904b\u7528\u5148\u524d\u7684\u77e5\u8b58\u3002\u7136\u5f8c\u6211\u5011\u63a2\u8a0e\u5982\u4f55\u5728\u5fae\u8abf\u548c\u5c11\u6b21\u5b78\u7fd2\u671f\u9593\u6700\u5927\u5316\u6709\u9650\u8cc7\u6599\u7684\u6548\u7528\u3002\u6700\u5f8c\u4e00\u7bc0\u63a1\u7528\u7279\u5b9a\u4efb\u52d9\u89c0\u9ede\uff0c\u6aa2\u8996\u9069\u5408\u4e0d\u540c\u8cc7\u6599\u7a00\u5c11\u7a0b\u5ea6\u7684\u6a21\u578b\u548c\u65b9\u6cd5\u3002\u6211\u5011\u7684\u76ee\u6a19\u662f\u70ba\u5be6\u52d9\u5de5\u4f5c\u8005\u63d0\u4f9b\u514b\u670d\u53d7\u9650\u8cc7\u6599\u6240\u5e36\u4f86\u7684\u6311\u6230\u7684\u5be6\u7528\u6307\u5357\uff0c\u540c\u6642\u4e5f\u5f37\u8abf\u672a\u4f86\u7814\u7a76\u7684\u6709\u5e0c\u671b\u7684\u65b9\u5411\u3002", "author": "M\u00e1rton Sz\u00e9p et.al.", "authors": "M\u00e1rton Sz\u00e9p, Daniel Rueckert, R\u00fcdiger von Eisenhart-Rothe, Florian Hinterwimmer", "id": "2411.09539v1", "paper_url": "http://arxiv.org/abs/2411.09539v1", "repo": "null"}}