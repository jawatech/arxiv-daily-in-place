{"2406.17376": {"publish_time": "2024-06-25", "title": "Temporal-Channel Modeling in Multi-head Self-Attention for Synthetic Speech Detection", "paper_summary": "Recent synthetic speech detectors leveraging the Transformer model have\nsuperior performance compared to the convolutional neural network counterparts.\nThis improvement could be due to the powerful modeling ability of the\nmulti-head self-attention (MHSA) in the Transformer model, which learns the\ntemporal relationship of each input token. However, artifacts of synthetic\nspeech can be located in specific regions of both frequency channels and\ntemporal segments, while MHSA neglects this temporal-channel dependency of the\ninput sequence. In this work, we proposed a Temporal-Channel Modeling (TCM)\nmodule to enhance MHSA's capability for capturing temporal-channel\ndependencies. Experimental results on the ASVspoof 2021 show that with only\n0.03M additional parameters, the TCM module can outperform the state-of-the-art\nsystem by 9.25% in EER. Further ablation study reveals that utilizing both\ntemporal and channel information yields the most improvement for detecting\nsynthetic speech.", "paper_summary_zh": "\u6700\u8fd1\u5229\u7528 Transformer \u6a21\u578b\u7684\u5408\u6210\u8a9e\u97f3\u5075\u6e2c\u5668\u8207\u5377\u7a4d\u795e\u7d93\u7db2\u8def\u5c0d\u61c9\u9805\u76f8\u6bd4\u5177\u6709\u512a\u7570\u7684\u6548\u80fd\u3002\u9019\u500b\u9032\u6b65\u53ef\u80fd\u662f\u7531\u65bc Transformer \u6a21\u578b\u4e2d\u591a\u982d\u81ea\u6211\u6ce8\u610f (MHSA) \u7684\u5f37\u5927\u5efa\u6a21\u80fd\u529b\uff0c\u5b83\u5b78\u7fd2\u6bcf\u500b\u8f38\u5165\u6a19\u8a18\u7684\u6642\u9593\u95dc\u4fc2\u3002\u7136\u800c\uff0c\u5408\u6210\u8a9e\u97f3\u7684\u507d\u5f71\u53ef\u80fd\u4f4d\u65bc\u983b\u7387\u901a\u9053\u548c\u6642\u9593\u5340\u6bb5\u7684\u7279\u5b9a\u5340\u57df\uff0c\u800c MHSA \u5ffd\u7565\u4e86\u8f38\u5165\u5e8f\u5217\u7684\u9019\u7a2e\u6642\u9593\u901a\u9053\u4f9d\u8cf4\u6027\u3002\u5728\u9019\u9805\u5de5\u4f5c\u4e2d\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u4e00\u500b\u6642\u9593\u901a\u9053\u5efa\u6a21 (TCM) \u6a21\u7d44\uff0c\u4ee5\u589e\u5f37 MHSA \u64f7\u53d6\u6642\u9593\u901a\u9053\u4f9d\u8cf4\u6027\u7684\u80fd\u529b\u3002ASVspoof 2021 \u7684\u5be6\u9a57\u7d50\u679c\u986f\u793a\uff0c\u50c5\u4f7f\u7528 0.03M \u7684\u984d\u5916\u53c3\u6578\uff0cTCM \u6a21\u7d44\u5c31\u80fd\u5728 EER \u4e2d\u4ee5 9.25% \u7684\u8868\u73fe\u512a\u65bc\u6700\u5148\u9032\u7684\u7cfb\u7d71\u3002\u9032\u4e00\u6b65\u7684\u6d88\u878d\u7814\u7a76\u8868\u660e\uff0c\u540c\u6642\u5229\u7528\u6642\u9593\u548c\u901a\u9053\u8cc7\u8a0a\u53ef\u4ee5\u70ba\u5408\u6210\u8a9e\u97f3\u5075\u6e2c\u5e36\u4f86\u6700\u5927\u7684\u9032\u6b65\u3002", "author": "Duc-Tuan Truong et.al.", "authors": "Duc-Tuan Truong, Ruijie Tao, Tuan Nguyen, Hieu-Thi Luong, Kong Aik Lee, Eng Siong Chng", "id": "2406.17376v1", "paper_url": "http://arxiv.org/abs/2406.17376v1", "repo": "https://github.com/ductuantruong/tcm_add"}}